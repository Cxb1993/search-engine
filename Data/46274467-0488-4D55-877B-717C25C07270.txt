I以一個結合多攝影機與個人資訊進行客製化行為分析之照護系統
A Customized Human Behavior Analysis System Based on Multiple
Cameras and Personal Information for Home-Care Applications
計畫編號：NSC 95–2221–E–033–069–MY3
執行期限：95 年 08 月 01 日至 98 年 07 月 31 日
主持人：繆紹綱 中原大學電子工程系
計畫參與人員： 廖宗彥、鄭宇宏、歐季祐 中原大學電子工程系
摘要
本計畫提出一套可應用於醫療照護機構之跌倒偵測系統，旨在即時偵測出跌倒意外
並通報醫護人員，以避免延誤就醫。第一年計畫已經將老人居家看護系統之跌倒偵測部
分建構起來。第二年放在演算法的改進、輔助攝影機與硬體設備的加入，以提升本系統
的完備性與實用性。第三年在跌倒演算法方面，加入移動歷史影像；在追蹤方面，結合
DSP 板以無線傳輸方式在 PDA 上供監控；在電腦端整合電腦人機監視介面。最後與前
兩年之成果做系統上的整合，建構出一個可行的照護系統雛型。
關鍵詞：跌倒偵測、追蹤方法、個人資訊
Abstract
This study proposes a health care system that can detect a fall accident immediately,
notify medical personnel when the accident occurs, and prevent the patient from deteriorating
due to late treatment. A fall detection module of the health care system was implemented in
the first year. The work of second year focuses on the improvement of fall detection algorithm,
using an auxiliary camera and combining hardware facility to improve completeness and
practicability of the system. In the third year, we included the motion history image in fall
down detection algorithm; combined DSP board with wireless transmission function for
motion tracking and display the tracking result on a PDA monitor; and integrated a computer
human monitoring interface. Finally, the subsystem built in the third year is integrated with
the subsystems developed in the first two years, resulting in a prototype of a feasible
home-care system.
Keywords: Fall detection, Tracking Methods, Personal Information
1ㄧ、前言
由於醫療技術的精進，對於病人醫療照護的品質也隨之提升。此外，屬醫療
照護體制重要成員的一般醫院、療養院、老人院等各種的安養中心林立，相對需
要投入大量的資源以維護醫療照護的品質。因為科技進步，以軟硬體技術來輔助
看護以降低人力與醫療資源的成本並建立以病人安全為中心 (patient-centered)
的醫療照護模式已逐漸成為全球醫療管理的趨勢。
根據統計，「跌倒」是常發生的意外事件，也是受傷導致死亡的主要原因之
一，更是六十五歲以上老人事故傷害死亡的第二大原因。跌倒的發生對於年長者
生命健康造成的威脅很大，因此已成為老人看護的重要議題。據研究指出
[1][2][3]，以台灣為例，居家老人1/3 在一年中至少跌倒一次。其中8% 以上需掛
急診求醫，而其中 30-40% 需住院，並且跌倒易造成老人或慢性疾病患者喪失
自信等之心理障礙，另外跌倒也成為老年人或是慢性疾病患者的致命因素之一。
因此在跌倒事件發生後，如何在第一時間發現並且給予最快速且正確的照護是很
值得探討的。
二、研究目的
本計畫的目的主要在於發展出一套以結合多攝影機與個人資訊進行客製化
行為分析之照護系統。此系統運作如下。在療養機構的老人或病患進入看護區域
後，先經過身份辨識，並將所得到個人資訊送給醫護端的電腦，隨後開始針對環
場影像中出現之人員進行初步跌倒偵測的動作。倘若偵測到有人員跌倒之情形發
生，便控制 P/T/Z 攝影機轉向該人員的位置擷取影像。藉由此影像我們進行第二
次的行為分析以判斷該人員是否處於危險狀態，倘若分析結果是此人員有跌倒或
身體扭曲等不自然狀態，則系統會將此張影像以及該人員的個人資訊透過網際網
路通知遠方的醫護人員(可能利用 PDA、手機或遠端電腦等設備觀看)。
三、文獻探討
對於跌倒偵測國內外已經有相當多的研究，例如[4]-[6]利用特殊的感應器和
電路系統來解決此問題，但是這些系統大都必須耗費較高的硬體成本，並且所有
使用者都必須穿戴一些感應器或儀器設備在身上，既不自然也不方便。為了克服
上述的缺點，有學者提出以視訊為基礎的跌倒偵測系統，例如[7]和[8]利用攝影
機所擷取的影像來進行人類的行為或姿勢分析。但是這些系統使用的傳統攝影機
都只具有非常有限的視角。因此Greiffenhagen等人[9]提出利用一個CCD攝影機和
一個凸面鏡組合成一個可以同時環視全場(omnidirection)之新型監視系統。這種
監視系統除了可以解決上述問題外，凸面鏡所造成的非線性影像失真對個人隱私
的保護也比較理想(看不出較細緻的行為舉止)，不過相對的也提高了對影像自動
3圖1 系統架構圖
(二) 跌倒辨識
圖 2為以環場影像偵測跌倒之系統流程圖。首先選擇感興趣的區域(Region of
interest, ROI)進行看護，接著進行背景訓練。之後就開始動態物件偵測，當系統
偵測到有人員進入監護環境時，即擷取出前景物並且消除雜訊。最後，抽取出對
於跌倒分析有效的特徵，並利用這些特徵進行跌倒分析，再將結果輸出。
圖 2 系統流程圖
A. 長寬比變化偵測法[10]
此方法為取 N 張連續影像並記錄每一張影像中框選出之移動物件的長寬
比，利用連續長寬比變化判斷序列影像中，前 2/5 之影像兩兩相鄰影像間是否呈
現遞增或遞減的狀態，之後判斷序列影像中間 1/5 的相鄰長寬比變化是否大於某
一門檻值 T，若是，則代表受測者出現非正常行走的動作。最後，判斷序列影像
最終 2/5 的長寬比變化是否呈現穩定狀態(長寬比變化小，甚至無變化)，若呈現
環場攝影機
Mobile Phone
RS-232
Internet
PDA
Server PC
Client PC發警報
RFID Reader
背景建立
前景擷取
特徵抽取
跌倒?
ROI選取
通報醫護人員
偵測到
移動物?
是
否
否
環場影像輸入
跌倒判斷
是
5



N
i
i xxN 1
2)(
1 (1)
其中 N 為影像張數， ix 為單張影像內所框選物件之長寬比，x 為平均數，其計算
方式為：



N
i
ixN
x
1
1 (2)
在本方法中，如圖 5 所示，因為在一開始框選的長寬比會不穩定並且較無可
靠資訊，因此我們將前 30 張影像之長寬比捨棄不用。之後我們設定一個一次包
含 N 張影像的影像框，接著分析此框內對應的長寬比，且框與框之間有 1/4 重疊
的部分，在本圖例當中使用 N = 20 的影像框，並且每隔 5 張影像向右移動一次
影像框。
圖 5、影像框選示意圖。(a)長寬比折線圖使用影像框框選示意圖；(b)影像框框選
張數示意圖(斜線表框選之影像區間)。
如前所述，我們設定兩個門檻值，一個是代表跌倒過程中造成長寬比變化劇
烈的門檻值 max ，另一個是代表跌倒後穩定不動的 min 。對照圖之狀態圖，當影
像框內計算出的標準差大於 max 時，w = 1(狀態至 T)，但此時人員有可能是有手
揮動或蹲下等大動作造成，直到之後連續 M 個框所計算出的標準差都小於 min ，
w = 0，即進入 F 狀態時，系統才判斷跌倒。一般常見的非跌倒狀況如下：
1. 正常行走 (w = 0) 狀態 S
2. 雙手擺動伸展 (w = 0) 狀態 S
3. 正常行走後站立不動 (w = 0) 狀態 S
4. 蹲下之後又站立 (w = 1) (w = 1)狀態 S/ z = 0
5. 坐下蹲下長時間不起 (w = 1) (w = 0) (w = 0)狀態 F/ z = 1
6. 真正跌倒 (w = 1) (w = 0) (w = 0)狀態 F/ z = 1
7. 跌倒後短時間又起身 (w = 1) (w = 0) (w = 1)狀態 T/ z = 0
7圖 7 開關燈判斷狀態圖
靜態遺留物件偵測與移除
偵測靜態遺留物件與移除，最主要目的是假設被看護者在環境中放置或遺留
物件，或者是移動原先在場景中的物體，進而產生多個物件。假設被看護者只有
一人情況下，即代表只有一個移動物體，其他物件皆為靜止的物件，利用此特性
便可來偵測靜態的遺留物件。首先一樣去個別統計物件的中心位置 ),( tiC 與前一
次物件中心位置 C(i, t-1)的差值，並且當此值小於某預設門檻值 Th1 時，將計數
器加一，重複此動作，當計數器的值大於某預設門檻值 Th2 時，即是符合靜態物
體的條件，如下式(4)-(6)所示，因此會將此靜態物件融入背景影像中，當系統在
下一次進行前景物偵測時，此靜態物件便不會出現在前景物當中，因此即可達成
移除靜態遺留物件的作用。
when ||C(i, t) - C(i, t - 1))|| < Th1 (4)
1 ii TT (5)
bjectStaticThTwhen i O2  (6)
E. 移動歷史環場影像[14]
移動歷史影像
時間紀錄移動歷史影像(Motion History Image)是將相鄰兩張影像差點以時間
做為標記，可以記錄物件在一定時間內的移動資訊。如圖 8，越接近當下時間點
的影像其像素值越接近 255（8 位元影像），呈現的畫面越接近白色，反之其像素
值則越接近 0，像素值的大小隨著時間而遞減。
(a) (b)
圖 8 環場影像下的移動歷史影像圖。(a)行走狀態； (b)跌倒狀態。
9otherwise
0),(
and),(if
0
1
),,(ˆ






yxMHI
βyxθ
yxβC
i
i
i
(11)
經由上面的步驟，本系統可以紀錄經由計算得知的每一筆影像其中的移動梯
度大小與方向，並將之統計繪製成折線圖。
圖 9 為系統以折線圖表示三筆連續移動歷史影像結果，其中縱座標表示梯度
強度，橫座標為量化後的角度編號。除此之外，由於系統使用並非傳統攝影機，
因此本文嘗試將此折線圖轉化為雷達圖並將其對應於環場影像，如此可得到下面
示意圖（圖 10）。
0
1000
2000
3000
4000
5000
6000
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71
量化後角度
梯
度
強
度
M
G
M
L
第一筆移動歷史影像
第二筆移動歷史影像
第三筆移動歷史影像
圖 9 由上到下移動梯度折線圖。
圖 10 跌倒行為能量雷達圖
跌倒偵測方法
將特徵經過統計，觀察發現受測者走入測試環境後，若發生跌倒行為之可
能情況可歸納成以下三種狀態：
I. 正常步伐的穩定行走動作狀態。
II. 行走過程當中出現手部彎曲伸展揮動、步伐跨大等較大動作，或是突然蹲
下、趴倒等非穩定行走之可能將發生跌倒的暫時狀態。
11
尋到該卡號所對應到之使用者資料。當受測者進入監控環境後，系統便能夠依照
所接收到的卡號順序，依次為進入環境中之受測者標記其個人資訊。
圖 12 RFID 之讀取機與標籤。(a)讀取機；(b)標籤。
(四) 電腦端人機介面
圖 13 為系統人機介面，左上方黑色畫面，用來顯示環場攝影機所接收到的
畫面；而左下方紅色畫面，用來顯示 PTZ 所接收到的畫面。右邊為 RFID 應用的
介面，最右邊兩個按鈕，上方的是用來啟動程式開始傳送接收器接收之資訊，下
方的為結束程式。其餘部分主要用來顯示個人所持 Tag 的 ID、該 ID 持有者之個
人資料，和該 ID 持有者之個人照片。
圖 13 系統人機介面
(五) 人物移動追蹤方法
A. 於室內環場的多人追蹤(參考圖 14)
1. 利用環場攝影機的影像做多人的追蹤，並且對個別人物標記及模組化，再
(a) (b)
13
圖 15 整合環場和 PTZ 影像系統流程圖
圖 16 系統流程圖
計算距離d
及角度α、β
計算還原後
3D空間座
PTZ追蹤
輸入環場影像
座標轉換
物件擷取
跌倒判
預警報
跌倒辨識
否
是
警報與視訊
顯示開關
人工確認
跌倒與否
緊急救援
通知相關人
員
否
是
環場影像
PTZ 影像
控
制
PT
Z
攝
影
機
旋
轉
座摽轉換
利用長寬求中心點
垂直水平投影法
灰階
二值化
中值濾波
連續影像相減
環場影像輸入 PTZ 影像輸入
Yes
No判斷轉換後座
標是否為(0,0)
且轉動角度大於 1°
開始
處理後之環場影像
原始 PTZ 影像 RTSP
有線或無線
顯示器
15
實驗一
本研究採用類似醫學影像的評估方法[17] 。在本實驗中，受測資料為複雜環
境(路徑受限)下之 33 筆發生跌倒影像以及 27 筆未發生跌倒影像。使用的偵測方
法為方法一，門檻值選取採經驗法則。
表 1、路徑受限與不受限時使用方法一與二於加入個人資訊前後之實驗結果
表 2、路徑受限與不受限時使用方法一與二實驗結果之效能評估
實驗二
受測資料同實驗一，但使用方法二為主要判斷偵測的準則。由實驗結果可以
發現在未加入個人資訊時，系統正確率就已達 0.82，但在加入個人資訊之後系統
之正確率並沒有太大提升。
17
表 4 實驗結果之效能評估
環場影像 加速規 二者整合
正確率 0.92 0.95 0.97
敏感度 1.00 1.00 1.00
有效性 0.90 0.85 0.95
信賴度 0.84 0.90 0.94
C. 環場影像的品質改善及實務考量
光源自適性門檻值
如圖 18 所示，由圖結果可觀察出單一門檻值取太高導致物體破碎，而採用
動態門檻值後前景物擷取結果有明顯的改善。
圖18 二值化結果。(a)門檻值35；(b)門檻值20+動態門檻值。
開關燈判斷
此部分主要做了三個實驗，如以下說明。第一個實驗是在光源足夠情況下，
看護者覺得整個環境燈光太亮，因而關掉了部份光源。第二個實驗是被看護者覺
得整個環境燈光略顯不足，因而開燈來提昇整體亮度。第三個實驗是模擬被看護
者想要休息或睡眠時，將燈源全部關閉的情形。
第一個實驗結果影像的平均亮度與標準差如圖 19 所示，可觀察出大概在影
像編號 140 到 145 之間因關掉部份燈光平亮度從 140 左右下降至 100，並且隨即
自動啟動影像白平衡功能，將整體平均亮度拉高至 138 附近並且維持穩定不閃
爍。實驗結果如圖 20 所示，由圖中可得知此實驗可以成功偵測出開燈現象，並
且當光源不再劇烈變化之後成功的擷取出前景物。
19
輸入 背景 前景
遺
留
前
(a) (b) (c)
遺
留
後
(d) (e) (f)
移
除
後
(g) (h) (i)
圖21 遺走物件實驗結果。(a)遺留前輸入；(b)遺留前背景；(c)遺留前前景物；(d)
遺留後輸入；(e)遺留後背景；(f)遺留後前景物；(g)移除後輸入；(h)移除後背景；
(i)移除後前景物。
D. 移動歷史環場影像
本系統以梯度強度與梯度角度作為辨識之特徵並針對 38組跌倒影像與 38組
正常影像進行跌倒分析。本實驗將探討獨立使用單一特徵--梯度強度與梯度角度
以及同時使用兩種特徵之系統辨識效能。針對同一批空曠環境之影像資料進行跌
倒偵測，實驗結果列於表 5，實驗結果之效能評估列於表 6。
表 5 同時使用兩種特徵之本系統實驗結果
單獨使用梯度
強度特徵
同時使用梯度強
度與角度特徵
跌倒意外
系統判斷
發生 沒發生 發生 沒發生
發生 36 10 35 4
沒發生 2 28 3 34
21
(四) 電腦監控人機介面
人機介面呈現整合環場、PTZ 影像及人物資訊，使用者可以藉由此介面遠端
觀測受測環境情形，並得知使用者的基本資料，介面如圖 24 所示。
圖 24 電腦監控人機介面，包括環場攝影機回傳影像(左上圖)，PTZ 攝影機回傳
影像(左下圖)，以及右邊的 RFID 個人資訊等部份。
(五) PDA 顯示畫面
由於 PDA 端(使用者)不需要做影像分析，所以在 PDA 上只呈現 PTZ 攝影機
畫面，結果如圖 25 所示。
圖 25 為 PDA 呈現畫面
六、結論
本計劃成功的開發出有效且適應性高的跌倒偵測演算法。在跌倒偵測方法
上，將跌倒情況分成一般、徑向及非徑向跌倒，辨識率上都高達八成，並且結合
加速規資訊確保辨識率。在人物移動追蹤方法上，利用環場攝影機取出受測者位
置，自動控制 PTZ 攝影機觀察受測者，並且最後實現至 DSP 板上，其正確率也
23
and engineering of video monitoring system: an approach and a case study,” in 
Proc. of IEEE, vol. 89, no. 10, pp. 1498-1517, Oct. 2001.
[10] Miaou, S. G., Sung, P. H., and Huang, C. Y., “A customized human fall detection
system using omni-camera images and personal information,” in Proc. of the 1st
Distributed Diagnosis and Home Healthcare (DH2) Conference, pp. 39-42,
Arlington, Virginia, USA, April 2-4, 2006.
[11] Miaou, S. G. and Chen, Z. J., “A fall detection system based on the data fusion of
omni-directional images and acceleration, ” in Proc. of Biomed. Eng. Annual
Symposium, Dec. 14-15, 2007, Taichung, Taiwan.
[12] Huang, Y. C., Miaou, S. G., and Liao, T. Y., “A human fall detection system
using an omni-directional camera in practical environments for health care
applications,” in Proc. of Biomed. Eng. Annual Symposium, Dec. 12-13, 2008,
Taoyuan, Taiwan.
[13] Huang, Y. C., Miaou, S. G., and Liao, T. Y., “A human fall detection system
using an omni-directional camera in practical environments for health care
applications,” in Proc. of IAPR Conference on Machine Vision Applications, pp.
455-458, May 20-22, 2009, Keio University, Yokohama, Japan.
[14] Chen, Z. J., Miaou, S. G., Zheng, Y. H., and Huang, C. Y.,“A fall down behavior
detection system based on motion history of omni-directional images for health
care applications,” in Proc. of Biomed. Eng. Annual Symposium, Dec. 12-13,
2008, Taoyuan, Taiwan.
[15] Miaou, S. G., Chien, C. Y., Shih, F. C., and Huang, C. Y., “A smart surveillance
system for human fall-down detection using dual heterogeneous cameras,” Proc. 
of Int. Joint Conf. on E-Business and Telecommunications, pp. 291-299, Porto,
Portugal, July 26-29, 2008.
[16] Chien, C. Y., Miaou, S. G., and Huang, C. Y., “A real-time surveillance and
tracking system based on combining the image information obtained from
omni-directional and PTZ cameras,” in Proc. of 2008 Symposium on Digital Life
Technologies, Taina, Taiwan, June 5-6, 2008.
[17] S. Siegel and N. Castellan, Nonparametric Statistics for the Behavioral Sciences,
2nd Ed., McGraw-Hill, New York, 1988.
25
可供推廣之研發成果資料表
■ 可申請專利 ■ 可技術移轉 日期：98 年 10 月 31 日
國科會補助計畫
計畫名稱：以一個結合多攝影機與個人資訊進行客製化行為分析之
照護系統
計畫主持人：繆紹綱 中原大學電子工程系
計畫編號：NSC 95-2221-E-033-069-MY3 學門領域：醫學工程
技術/創作名稱 用於照護系統之影像跌倒辨識追蹤技術
發明人/創作人 繆紹綱
1. 在跌倒演算法方面加入移動歷史影像，以梯度強度與梯度角度
作為辨識之特徵。
2. 以環場攝影機的影像做多人追蹤。當人物重疊時，透過辨識高
斯濾波模型化物件的差異和歷史軌跡，避免標記錯誤的發生。
3. 目標物的影像，藉由有線與無線傳輸的方式，分別在電腦與 PDA
上呈現。
技術說明 1. We include motion history images in fall down detection algorithm,
and use gradient strength and gradient angle as recognition
features.
2. We use an omni-directional camera for tracking multiple people.
When overlapping of people objects occurs, erroneous ID markings
can be avoided by recognizing Gaussian filtering model objects and
motion history.
3. The target image is displayed on a computer monitor and PDA by
the wired and wireless transmission, respectively.
可利用之產業及
可開發之產品
視訊監控安全產業與醫療照護產業。
技術特點
1. PTZ 攝影機可以被架設在最佳監控範圍的任意位置處，而不需
要被限定在環場攝影機正下方，在架設上提供了許多彈性與便
利性並提供更為人性化的環境。
2. 在追蹤方面結合 DSP 板以無線傳輸方式，呈現在 PDA 監控，
在電腦端整合電腦人機監視介面，使用者可以藉由此介面遠端
觀測受測環境情形，並得知使用者的基本資料。
推廣及運用的價值 因應少子化與高齡化社會的到來，此技術可推廣到醫療照護單位或
家庭使用，以解決照護人力不足的問題。
27
附件 -- 出席國際學術會議心得報告及發表之論文
29
越來越順手。
三、建議
生活上令我感受最深的是，日本極為複雜但卻非常便捷的鐵路系統，果然是
一個高度已開發的國家，或許台灣可以當參考，以此發展更便捷的大眾運輸系
統。上下班時看到像螞蟻的大批人潮快速又有秩序地進出車站出入口，在車上像
沙丁魚般擁擠，但沒有人有不滿情緒的情景令我印象深刻。這是一個勤奮又可怕
的民族，它的進步不是沒有道理的。
31
light on and off detection scheme is shown in Figure 1. A
status indicator w will be set to 1 when the sample
standard deviation is greater than a predefined threshold,
MaxSigma. This means the system can not work
normally because the light intensity changes abruptly and
the system is in an unstable state. Therefore, the system
stops capturing the foreground and ceases to update the
background. The w will be set to 0 when the sample
standard deviation is smaller than another predefined
threshold, MinSigma. This means the system can work
normally and the light source is stable. In this case, the
system can continue to capture the foreground and update
the background.
Figure 1. The state transition diagram for on and
off light detection.
2.3 Detection and removal of static abandoned
objects
Assume only one person is in the surveillance area,
meaning that it could just have one moving object and the
others are all static objects. We utilize this characteristic
to detect static abandoned objects. First, compute the
location difference between the thi object center at
current time t , ),( tiC , and the thi object center at
previous time 1t , )1,( tiC . When the difference is
smaller than a predefined threshold 1(more specifically,
1||)1,(),(||  tiCtiC ), then a counter is incremented
by one; otherwise the counter is not updated. Take every
30 frames as a counting interval. When the counter
reading is greater than another predefined threshold 2 ,
then this object is considered a static object. The counter
will be reset to zero later on and the counting process
repeats for each counting interval.
Next, the static object detected will be blended into the
background image and become part of the background.
Therefore, when the system performs foreground
detection next time, the static object will not appear in
foreground, and the successful removal of the static
abandoned object is achieved.
2.4 Fall detection
Two types of fall down from omni-directional images
can be categorized by the anglebetween the body
vector IJ and the reference vector MI , as shown in Figure
2. A larger angle represents a non-radial fall, and a
relatively smaller angle may indicate a radial fall
(including radially inward and outward fall). The
corresponding angle threshold for fall type detection is
determined by the largest angle that can be obtained in
normal walking conditions. Using the body line
characteristic successfully detected the non-radial fall and
radially outward fall [6], but it failed to detect radially
inward fall. Therefore, we propose a tMHI (time Motion
History Image) [9] [10] solution to solve this problem.
tMHI converts the foreground pixels in adjacent
images by some time labels. It can record the object
motion information within a period of time. Using tMHI
can easily obtain the history information of continuous
movement within a time period so that it can be used to
analyze and recognize the motion behavior of a moving
object. For the convenience of viewing and processing,
we use Eq. (3) to normalize tHMI and obtain a gray scale
image of b bits per pixel:


 
otherwise
tMHIif
yxtMHI
yxMHI
ib
i
i
gray
0
0)12(
)(),(
),( 
 (3)
where  denotes current frame or time, and  is a user
specified parameter that controls the recording length of
motion information.
Figure 2. A schematic showing the body vector
IJ and reference vector MI [6].
As shown in Figure 3, three distance measures ( 1i , 2i
and 3i ) are extracted as a feature for fall detection. A
typical result of the feature is shown in Figure 4.
Figure 3. A schematic showing tMHI feature.
Figure 4. A typical result of tMHI-based feature when
radially inward fall occurs.
A radially inward fall is detected if the following four
conditions are must: (1) The standard deviation of 1i < 1 ;
(2) The standard deviation of 2i > 2 ; (3) The standard
deviation of object center displacement < 3 ; and (4)
3i >T , where the first three predefined thresholds ( 1 ,
2 , and 3 ) are not sensitive to environment conditions
and determined by experiments and the last threshold (T )
may need minor adjustment for better performance.
Figure 5 gives the system flow chart of fall detection.
33
Figure 9. The experimental results of abandoned
object detection and removal. (a) Input image
before object is abandoned. (b) Background before
object is abandoned. (c) Foreground before object
is abandoned. (d) Input image after object is
abandoned. (e) Background after object is
abandoned. (f) Foreground after object is
abandoned. (g) Input image after abandoned object
is removed. (h) Background after abandoned
object is removed. (i) Foreground after abandoned
object is removed.
3.4 Fall detection
A total of 97 sets of the omni-directional image
sequences are used in the simulation study. Those images
contain many different situations of radial fall (32 of them
are inward and 33 of them are outward) and non-radial
fall (32 sets, including 5 from real situations discussed in
Section 3). All 97 image sequences were processed for
fall detection in the experiments and the performance is
evaluated. The fall detection result is considered a success
when the system recognizes a fall event (disregard the
type of falling). A recognition error occurs when a normal
walking person is classified as being falling. The
experiment results are shown in Table 1. The system
performance is evaluated and the result is shown in Table
2.
Table 1. Experiment result and comparison.
Method proposed in
this paper
Method proposed
in [6]
Fall accident
System judgment True False True False
Positive 86 13 67 21
Negative 11 84 30 76
Table 2. Performance evaluation and comparison.
Method proposed
in this paper
Method proposed in
[6]
Accuracy 0.87 0.73
Sensitivity 0.88 0.69
Specificity 0.86 0.78
Kappa Value 0.75 0.47
The performance comparison shows that the system
proposed here substantially increases the number of
successful fall detection (from 67 to 86) and reduces the
number of erroneous detection (from 30 to 11), as shown
in Table 1. The accuracy is improved (from 0.73 to 0.87)
and the Kappa value is increased significantly (from 0.47
to 0.75), as shown in Table 2. Therefore, this paper
demonstrates an effective fall detection and recognition
system.
4 Conclusions
The proposed system is aimed at the practical factors
encountered in real environments for our daily life.
Therefore, we attempt to solve the problems such as the
occurrence of light source glimmer, turning a light on and
off, and leaving over static abandoned objects.
Experimental results show that the proposed system has
overcome the practical environmental factors of light
source glimmer and static abandoned objects. In
fall-down detection, the recognition accuracy of the fall
down system reaches 0.87 and the Kappa value [11] is up
to 0.75. These results show that the proposed fall down
detection system is quite effective.
References
[1] H. Seki, A. Kiso, and S. Tadakuma,: “Omni-directional
Vision Sensor Based Behavior Monitoring System Using
Bayesian Network,”in Proc. of IEEE Annual Conf. on
SICE, pp.764 - 769, 2007.
[2] H. Seki and S. Tadakuma, “Abnormality Detection
Monitoring System for Elderly People in Sensing and
Robotic Support Room,”in Proc. of IEEE Inter. Workshop
on Advanced Motion Control, pp.56 - 61, 2008.
[3] M. L. Wang, C. C. Huang, and H. Y. Lin, “An Inteligent 
Surveillance System Based on an Omnidirectional Vision
Sensor,”in Proc. of IEEE Conf. on Cybernetics and
Intelligent Systems, pp.1-6, 2006.
[4] J. Q. Lin, The Behavior Analysis and Detection of Falling,
Master Thesis, Department of Computer Science and
Information Engineering, National Central University,
Taiwan, 2004.
[5] Miaou, S. G., Sung, P. H., and Huang, C. Y., “A 
Customized Human Fall Detection System Using
Omni-Camera Images and Personal Information,”in Proc.
of the 1st Distributed Diagnosis and Home Healthcare
(D2H2) Conf., pp. 39-42, Arlington, Virginia, USA, April
2-4, 2006.
[6] Miaou, S. G., Shih, F. C., and Huang, C. Y., “A Smart 
Vision-Based Human Fall Detection System for Telehealth
Applications, ”in Proc. of the Third ISATED Int. Conf. on
Telehealth, Vol. 654-020, pp. 7-12, Montreal, Quebec,
Canada, May 31- June 1, 2007.
[7] K. Yamazawa and N. Yokoya, “Detecting Moving Objects 
from Omnidirectional Dynamic Images Based on Adaptive
Background Subtraction,” in Proc. of IEEE Conf. on ICIP,
vol. 2, pp. III-953-6, 2003.
[8] Y. L. Tian, M. Lu, and A. Hampapur, “Robust and 
Efficient Foreground Analysis for Real-time Video
Surveillance,”in Pro. of IEEE Conf. on CVPR, vol. 1, pp.
1182-1187, June 2005.
[9] A. Bobick and J. Davis, “Real-time Recognition of
Activity Using Temporal Templates,” inProc. of IEEE
Workshop on Application of Computer Vision, Sarasota,
Florida, pp. 39-42, Dec. 1996.
[10] M. A. R. Ahad, T. Ogata, J. K. Tan, H. S. Kim, and S.
Ishikawa, “Comparative analysis between two view-based
methods: MHI and DMHI,” inProc. of IEEE Int. Conf. on
Computer and Information Technology (ICCIT), pp. 1-6,
Dec. 2007.
[11] S. Siegel and N. Castellan, Nonparametric Statistics for the
Behavioral Sciences, 2nd Ed., McGraw-Hill, New York,
1988.
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
98 年 5 月 30 日
報告人姓名
繆紹綱
服務機構
及職稱 中原大學電子系 教授
時間
會議
地點
2009年 5月 20日到 22日
日本 Yokohama (橫濱) Keio University (慶義大學) 日吉分校
會議
名稱
The 11th IAPR Conference on Machine Applications
第 11屆 IAPR機器應用研討會
發表
論文
題目
Human Fall Detection System Using an Omni-Directional Camera in Practical
Environments for Health Care Applications
一個使用環場攝影機於真實環境下的跌倒偵測照護系統
一、參加會議經過
本次參加之研討會的名稱為 The 11th IAPR Conference on Machine Applications，會議
時間為 2009年 5月 20日到 22日，會議地點在日本之 Yokohama (橫濱)的 Keio University
(慶義大學)。本會議每兩年舉辦一次，第一次是在 1988年，所以已有超過 20年的歷史。
本次會議由MVA Organization、IAPR TC-8和 Keio University所贊助，還有 12個日本知
名的相關協會與學會參與合作。
三天的會議中每天都有一個 invited talk，一個 poster section和若干個 oral sections。
所有議程都是 sequential (沒有 parallel sections)，所以不會有遺珠之憾。在三個 invited talk
中令我印象最深刻也最感興趣的是由加拿大多倫多大學的 Prof. Kyros Kutulakos所主講
的那一場，講題是「Focal Stack Photography: High Performance Photography with a
Conventional Camera」。其基本概念是利用不同焦距所拍出影像之疊加處理可增加有各種
景深之影像清晰度。Kutulakos 教授的演講非常有條理、表達能力強，連此次與我同行
英文能力不算太強的研究生也都能抓到重點。總之這是一個精采的演講，真是值回票
價。Oral sections有的表現很好，有的就有待加強，最主要是英文表達與溝通能力稍弱
或是投影片的準備不完善。至於 poster sections 則是場場討論熱烈，欲罷不能，這是因
為此研討會有專業性(或專業領域性)，所以與會者都有極高的共同專業興趣與常用的專
業術語使用的能力，有同好一起切磋的感受。
二、與會心得
此次與會者約 200人，來自於 20多個國家與地區。日本的參加者最多，其次是台灣
(共有 15名)，再來是法國(12名)。台灣來的學者除本人外，還有清華大學的賴尚宏、中
正大學的柳金章、中華大學的連振昌、鄭芳炫、黃雅軒、亞洲大學的莊政宏以及虎尾科
技大學的黃惠俞等人。異地相見，親切感倍增。我本人和其中幾位台灣來的學者一同參
與大會在第二天晚上所安排的晚宴，由 General Chair Hideo Saito教授(Keio University)
主持。Saito 教授非常有親和力，現場氣氛輕鬆愉快。會中還頒發一個獎給予幾篇論文
98 年 5 月 30 日
報告人姓名
廖宗彥
服務機構
及職稱 中原大學電子系 碩二
時間
會議
地點
2009年 5月 20日到 22日
日本 Yokohama (橫濱) Keio University (慶義大學) 日吉分校
會議
名稱
The 11th IAPR Conference on Machine Applications
第 11屆 IAPR機器應用研討會
發表
論文
題目
Human Fall Detection System Using an Omni-Directional Camera in Practical
Environments for Health Care Applications
一個使用環場攝影機於真實環境下的跌倒偵測照護系統
參加會議經過：
這次有機會出國參加國際研討會，真的是讓我獲益良多。從去年暑假選定要投稿的
研討會之後就開始馬不停蹄的後續的規劃。一開始撰寫投稿的論文，並且依照投稿格式
用英文改寫。這段期間與老師的討論與修改真的讓我對於論文的英文寫作能力有不少的
提升。由於目前網路的發達，國際研討會的投稿也是相當的容易上手，只需要透過主辦
單位的系統就可以投稿與註冊，不用再透過書面資料的長時間往返。得知投稿論文被接
受後就要開始準備出國的大小事物，雖然不是第一次出國，但卻是第一次自己打理出國
的事物與行程的規劃，因此是一次難得的經驗。
由於有國科會與系上經費的補助，得以讓老師與我共同一起前往參加此研討會，而
不必太擔憂出國費用的負擔問題，可以專注於準備研討會的報告上。此次研討會名稱為
The 11th IAPR Conference on Machine Applications，舉辦的地點位於日本橫濱慶應大學日
吉分校，而此研討會也有一段不短的歷史，兩年一次共經舉辦了 11 屆。研討會共舉行
三天(5/20-22)，除了 oral與 poster報告之外，每天也會有一名學者 invited talk，並且每
一時段只會有單一一種報告進行，所以不用擔心要選擇性參加的問題，可以每場報告都
參與，我認為這樣的安排真的是很不錯。因此，可以選擇自己有興趣的標題參與並且不
用擔心會有參與不到的會議與活動，感受到日本人對於事務大小細節的用心規劃。
與會心得：
根據大會的分類，此次大會將投稿的論文分三類在這三天舉行，分別為 Machine
Vision、Pattern Recognition和 Application。這幾天會議中聆聽了其他投稿者的 oral報告，
對於跟本身相關的研究都充滿興趣。雖然在聆聽的過程中因為語言的關係，仍然會有許
多不懂的地方，不過當然有些是因為報告者準備不夠完善與口頭表達能力待加強。有些
聆聽報告的參加者非常踴躍的發問問題，幾乎每位報告者報告完畢都會提問，我想這是
在台灣的學生很少看到的。但是我覺得在提問的時候，應該要直接講出問題的重點，而
不要說一堆無關緊要的話，因為這次有些提問者他的冗言真的是太長了，對於會議時間
的掌控多少會有些影響，也影響到其他提問者發問的權利。
