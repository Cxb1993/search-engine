I 
 
目錄 
Abstract ............................................................................................................................................... 1 
摘要 ...................................................................................................................................................... 1 
1. Introduction ................................................................................................................................ 1 
2. The proposed method ................................................................................................................. 3 
2.1 Feature extraction ................................................................................................................. 3 
2.1.1 LBA color set extraction .................................................................................................. 3 
2.1.2 Color percentage set computation .................................................................................... 4 
2.2 Feature matching .................................................................................................................. 4 
2.2.1 Similarity between two color percentage sets .................................................................. 4 
2.2.2 Distance between two colors............................................................................................ 4 
2.2.3 Similarity between two color sets .................................................................................... 4 
2.2.4 Similarity between two regions........................................................................................ 5 
2.2.5 Similarity between two images ........................................................................................ 5 
2.3 Image Retrieval .................................................................................................................... 5 
2.4 Quick-match algorithm ........................................................................................................ 5 
2.5 Relevance feedback .............................................................................................................. 7 
3. Experiments ................................................................................................................................ 7 
3.1 Test database construction ................................................................................................... 7 
3.1.1 Database I ......................................................................................................................... 7 
3.1.2 Database II ....................................................................................................................... 8 
1 
 
行政院國家科學委員會專題研究計畫成果報告 
以非參數密度估測之顯著區域切割技術應用於區域式 
相關性回饋的自然影像檢索 
計畫編號: NSC 97-2221-E-130 -017 -MY2 
執行期限: 97 年 8 月 1 日～ 99 年 7 月 31 日 
主持人: 謝朝和教授   銘傳大學資訊傳播工程系 
共同主持人: 郭忠民教授  義守大學資訊工程系 
E-Mail: hsiehch@mail.mcu.edu.tw 
 
Abstract 
 
This research proposes an effective 
image retrieval system based on novel 
salient region segmentation and 
relevance feedback. With a good and 
fast segmentation technique, our system 
achieves a quick segmentation capability, 
which enables users to select particular 
regions for matching and feedbacks 
without waiting for image segmentation. 
Therefore, the system does not need 
complex feedback schemes to derive the 
intent of the user. The experimental 
results show that the system 
performance is greatly improved with 
this capability. Furthermore, a 
Quick-match algorithm is also presented. 
The mechanism of the Quick-match 
algorithm is to exclude from distance 
computation regions that are of low 
possibility to be the top- matches. This 
algorithm excludes most of regions from 
distance computation and therefore 
greatly cuts down the turnaround time of 
the retrieval with slightly degradation of 
precision. 
 
Keywords: salient region, image retrival, 
relevance feedback, image segmentation  
 
摘要 
 
本研究提出一個有效的影像檢索系
統，此系統係植基於嶄新的顯著區域
分割及相關性回饋兩個技術上。利用
快速的分割技術，我們的系統可以將
一影像做快速的切域分割，因此不須
複雜的回饋機制就可以推測使用者的
意圖，實驗結果顯示系統的性能獲得
大幅度的改善。此外，我們也發展出
快速比對的演算法，它排除了許多機
率低的區域，免除距離的計算，因此
大幅提高檢索的時間，但對檢索精確
度的影響極其微小。 
 
關鍵字:顯著區域，影像檢索，相關性
回饋，影像分割 
 
1. Introduction 
 
The expeditious advance of computer 
industry and the proliferation of 
Internet-based services make hundreds 
of millions of digital images available 
on the Internet for the public to access. 
With the increasing amount of images, 
the tools for image search and 
management are in great demand. For 
this reason, many image retrieval 
systems have been developed, which can 
be roughly classified into two types: 
text-based and content-based. In 
text-based approaches, images are 
manually annotated with texts, which 
are then used for image retrieval by an 
image database management system. 
However, annotating images with rich 
contents in large databases is a 
time-consuming and tedious task. 
Besides, the subjectivity of human 
perception may result in a great 
difference in annotations for an image. 
3 
 
image retrieval system with a simple 
relevance feedback scheme based on a 
novel image segmentation technique that 
we proposed earlier in [26]. This 
segmentation technique is very fast. For 
CIF format images, the segmentation 
process (single-thread mode) takes, on 
average, only 200 ms on an Intel Core 2 
Quad Q6600 CPU, @2.40GHz, with 2 
GB RAM, under Windows XP. With the 
fast segmentation technique, our system 
achieves a quick segmentation capability, 
which enables users to select particular 
regions for matching and feedbacks 
without waiting for image segmentation. 
Therefore, the system does not need 
complex feedback schemes to derive the 
intent of the user. Furthermore, we also 
propose a Quick-match algorithm to 
exclude unnecessary distance 
computation. The experimental results 
show that the system performance is 
greatly improved. 
 
2. The proposed method 
 
Although many region-based image 
retrieval systems have been proposed in 
the literature, the speed of image 
segmentation and feature matching is 
still an obstacle precluding them from 
being practical systems in the real world. 
Contrary to those approaches, we 
have developed a practical region-based 
relevance feedback image retrieval 
system with on-the-fly image 
segmentation using the novel salient 
region segmentation technique 
introduced in previous section. The 
schematic diagram is shown in Fig. 1. In 
this section, we will describe the system 
in detail. 
 
2.1 Feature extraction 
 
To speed up the matching, only color 
features are used in the system. We 
select the MPEG-7 Dominant Color 
Descriptor (DCD) as the color descriptor. 
The feature set F of the DCD can be 
simply described as follows: 
{ , }
:  dominant colors (8 colors at most) (1)
:  percentages of the dominant colors
F C P
C
P
=
 
To obtain the dominant colors, the 
Linear Block Algorithm (LBA) 
proposed by N.-C. Yang et al. [27] is 
used but with a modification to improve 
the feature matching speed. 
 
2.1.1 LBA color set extraction 
 
We briefly review the LBA in [27] as 
follows: 
As shown in Fig. 2, the RGB color 
space is equally divided into eight cubes, 
and denoted by Eq.(2): 
{ }
{ }
{ }
{ }
1
2
3
4
=  [   0  , 127 ], [   0  , 127], [   0  , 127] 
=  [   0  , 127 ], [   0  , 127], [ 128, 255] 
=  [   0  , 127 ], [ 128, 255], [   0  , 127] 
=  [   0  , 127 ], [ 128, 255], [ 128, 255] 
B r g b
B r g b
B r g b
B r g b
{ }
{ }
{ }
{ }
5
6
7
8
(2)
=  [ 128, 255 ], [   0  , 127], [   0  , 127] 
=  [ 128, 255 ], [   0  , 127], [ 128, 255] 
=  [ 128, 255 ], [ 128, 255], [   0  , 127] 
=  [ 128, 255 ], [ 128, 255], [ 128, 255] 
B r g b
B r g b
B r g b
B r g b
 For a region, the centroid of colors 
for pixels whose color is within a certain 
cube is selected as the represented color 
for the cube. Let ( , , )
r g bx x x x=   
represent the color of a pixel, and then 
the centroid ic of a cube i  can be 
computed as: 
(3)
1
i
i
x B
i
x B
x
c ∈
∈
= ∑∑  
and the color set of a region is 
represented as: 
{ }1 2 3 4 5 6 7 8, , , , , , , (4)C c c c c c c c c=  
In [27], similar colors are merged 
using weighted average agglomerative 
procedure to obtain the final dominant 
colors. If the number of pixels in a 
certain cube is less than a pre-defined 
threshold Tmin, which is empirically set 
to 3% of the region size, then the cube is 
considered as empty and the color of it 
is considered as none. 
5 
 
8
1 2 1 2
1
1 2
1 2
1( , ) min( , ), (12)
( , )1 ,  if ( , )
(13)2
0 ,  otherwise
i i i
i
i i
i i
i
SimC C C CS p p
Np
d c c d c c MaxDis
CS MaxDis
=
= ×
⎧ − <⎪= ×⎨⎪⎩
∑
 where Np  is the number of dominant 
colors, iCS  is the similarity measure 
between two colors, and the MaxDis is a 
threshold and normalizing factor, which 
is empirically set to 25, and 
the 1 2min( , )i ip p  is the same as Eq. (8). 
Since the color distance between two 
color sets may vary in a large range, it is 
hard to define the similarity between 
two colors. To normalize the distance, 
the parameter “ MaxDis ” is introduced 
in Eq.(13), which guarantees a 
normalized value between 0.5 to 1 for 
the iCS . 
 
2.2.4 Similarity between two regions 
 
Let 1 2,R R denote two regions, and 
then the similarity between 1 2and RR  
is computed as: 
( )
( )
1 2 1 2
1 2
( , ) ,
,
c
p
SimR R R w SimC C C
w SimP P P
= ×
+ ×  (14) 
Where the cw  and pw are the weights 
for color similarity and percentage 
similarity, respectively, and are 
empirically set to 0.7 and 0.3, 
respectively. 
 
2.2.5 Similarity between two images 
 
Let ,
q dI I denote a query image and a 
database image, respectively, and then 
the similarity between  and q dI I  is 
computed as: 
{ }( )1
1
( , ) max ( , ) (15)
m nq d q d
j k k
j
SimI I I SimR R R ==
= ∑
th
th
: The number of selected regions of the query image 
: The number regions of the database image 
: The  selected region of the image 
: The  region of the database image 
q
d
q q
j
d d
k
m I
n I
R j I
R k I  
2.3 Image Retrieval 
 
As shown in Fig. 1, the user provides a 
query image to the system. Subsequently, 
the query image is segmented on the fly, 
and the segmented result is displayed to 
the user. The user is allowed to select 
one or multiple regions, and then the 
region or regions are submitted to the 
system for matching. The similarities 
between the query image and each of the 
database images are computed, and then 
the top- M matched images are returned 
to the user as the results of the query. 
The graphical user interface is shown in 
Fig. 3. 
 
2.4 Quick-match algorithm 
 
In general, for the matching of a 
query region, we have to compute the 
distances between the query region and 
each of the regions of the images in the 
database. The distance computation 
process will be conducted N  times for 
a single query region, where the N  is 
the number of regions in the database. 
When the N  is large, the matching 
speed could be tremendously slowed 
down. To address this drawback, a 
Quick-match algorithm is proposed 
below. 
As mentioned in Section 2.1.1, the 
colors of a region are represented as 
follows: 
Because each color ic  in C  consists 
of three color components, the C is 
actually a 24-dimensional feature vector, 
as shown in Eq.(16). 
{ } { }
{ } { }
{ } { }
{ } { }
1 1 1 2 2 2
3 3 3 4 4 4
5 5 5 6 6 6
7 7 7 8 8 8
, , , , , ,
, , , , , ,
(16)
, , , , , ,
, , , , ,
r g b r g b
r g b r g b
r g b r g b
r g b r g b
c c c c c c
c c c c c c
C
c c c c c c
c c c c c c
⎧ ⎫⎪ ⎪⎪ ⎪⎪ ⎪= ⎨ ⎬⎪ ⎪⎪ ⎪⎪ ⎪⎩ ⎭  
To simplify the expression, Eq.(16) is 
reformulated into Eq.(17): 
7 
 
the excluded-regions tables can be 
ignored comparing with the former. 
Besides, the quick-match algorithm 
excludes about 50% to 80% of regions 
from distance computation. Hence, it 
cuts down more than 50% the retrieval 
time. 
 
2.5 Relevance feedback 
 
As shown in Fig. 3, the retrieved 
images are displayed on the right panel 
and the images that belong to the same 
category as the query image are 
highlighted with dim yellow background, 
giving a hint to the user. If the user is not 
satisfied with the results, a feedback 
scheme is provided to the user. The user 
is allowed to select one or multiple 
images as feedback. When selected, an 
image is highlighted with blue border, 
and then the system will segment the 
image on the fly and the segmented 
result will be displayed on the bottom 
left panel (see Fig. 5(a)). 
The user is allowed to select or 
deselect any region directly from the 
segmented image by clicking the region 
or checking the check boxes just below. 
If there is any region selected, the image 
will be highlighted with red border (see 
Fig. 5(b)). 
Because the user is allowed to point 
out a specific region that he or she is 
interested in, there is no need to use 
complex feedback schemes to derive the 
intent of the user. Therefore, we adopt a 
simple feedback scheme. The process of 
selecting an image and selecting 
region(s) can be repeated as many times 
as the user wants until the “Feedback” 
button is clicked. When user select more 
than one regions of interesting, the 
system will check those regions again. 
Because the selected regions might be in 
different images, for simplicity and 
efficiency, the similarities between each 
other of the selected regions will be 
computed using Eq.(14). If the similarity 
between two regions is greater than a 
threshold Ts , which is empirically set to 
0.85, the two regions are considered as 
similar and will be merged to form a 
new one. If not, they are considered as 
independent regions. Initially, each 
region is weighted equally. When two 
regions are merged, the weight of the 
new region is given to be the sum of the 
weights of the two regions. Each feature 
of the new region is calculated as the 
mean value of the features of the two 
regions. Finally, all regions are treated 
as regions of a new query image, and 
submitted to the system for retrieval 
again. 
 
3. Experiments 
 
The lack of an objective ground-truth 
image database for performance 
evaluation of image retrieval systems is 
always a common problem of 
researchers working on this field. The 
performance of a method may vary from 
database to database, and the absolute 
values of performance for different 
databases are not directly comparable. A 
method with higher absolute value on 
“database A” does not necessarily infer 
that it is better than a method with lower 
absolute value on “database B”. The 
absolute values are nothing more than a 
reference. We will construct two image 
databases, one from the Corel photo 
CDs and the other from the Internet, and 
conduct our first experiment on both 
databases to demonstrate these facts. 
Then, the rest of the experiments will 
only be conducted either on Database I 
or on Database II (crawled from the 
Internet). 
 
3.1 Test database construction 
 
3.1.1 Database I 
 
The Corel Image Database is widely 
used in the simulation of image retrieval. 
Therefore, Database I was assembled by 
using 3851 images from the Corel Image 
9 
 
If regions are not properly segmented, 
they may produce more ambiguity, 
which degrades the performance. 
Furthermore, the precisions on Database 
I  are almost twice better than that on 
Database II although the methods are the 
same. This result suggests that the 
performance is highly dependent on 
database, and therefore it is meaningless 
to compare the absolute values of 
performance between different databases. 
However, the trend is meaningful. As we 
can see in Fig. 6 (a, b), the tendencies of 
precisions are the same on both 
databases, and the precisions of Kuan’s 
method are better than that of others. 
 
3.2.2 Experiment II 
 
Although Kuan’s segmentation 
algorithm improves the precision, the 
improvement seems not significant. The 
reason is that we use only a few features, 
24 color features, for matching and do 
not adopt complex feedback schemes to 
learn the intent of the user from the 
feedback images in the retrieval system. 
We believe when users are provided 
with the ability of selecting any 
segmented region they wanted, which is 
currently not provided by most RBIR 
systems, the improvement will be 
remarkable, even with such a few 
features and simple feedback scheme. 
Therefore, we try to confirm the 
aforementioned statements by our 
second experiment and design it as 
follows. 
The second experiment is performed 
manually on Database II, using Kuan’s 
segmentation algorithm only. The option 
of selecting particular regions is enabled 
so that users are able to select any 
region(s) of query image for matching 
and any region(s) of returned images for 
feedbacks. Since there are 5876 images 
in Database II, it is time-consuming and 
tedious to manually perform the 
matching and feedback process for every 
image in the database. Therefore, in 
order to demonstrate the effectiveness of 
proposed method, the images those are 
the worst precisions for all the three 
automatic approaches in Experiment I 
are selected as the query images for the 
second experiment. Totally, there are 
378 query images in our second 
experiment. 
In Experiment I, on each match or 
feedback the top 20 matched images 
were retrieved. For the aforementioned 
378 images, only one image among the 
top 20 retrieved images belonged to the 
same category as the query image, 
which was the query image itself. 
Therefore, the feedback image is always 
the same one as the query image. 
Consequently, precisions of the 378 
images are always 0.05 from “Match” to 
“Feedback 3”. The results of Experiment 
II are show in Fig. 7. For comparison, 
the results of the three automatic 
approaches for the 378 images in 
Experiment I are also shown in Fig. 7. 
As can be seen in Fig. 7, when a user is 
provided with the ability of selecting 
particular region(s), the precision is 
tremendously improved. It is more then 
triple of others. Therefore, the 
aforementioned statement is confirmed. 
 
3.2.3 Experiment III 
 
To further evaluate the benefit of 
selecting regions of interest by users, the 
third experiment is designed as a target 
search task. We randomly select 20 
image pairs from Database II to be the 
test set. The 20 image pairs are shown in 
Fig. 8. For each image pair, one is used 
as the target image and the other is used 
as the query image. The task is to locate 
the target images from Database II via 
the query images and the process of 
feedback. Experiment III consists of two 
parts, Part-A and Part-B, and each uses 
the same test set. In Part-A, the option of 
selecting particular regions of images is 
disabled, which is the same as in 
Experiment I, whereas it is enabled in 
11 
 
that we merge the similar regions when 
feedback, which shifts the value of 
features of the new region to the mean 
value of the merged regions. The 
Quick-match algorithm may exclude 
some of the merged regions, and 
therefore decreases the precision. Using 
an adaptive _delta D  when 
performing feedback could be a solution, 
but is still under investigation. As can be 
seen in Fig. 14(a), the Quick-match 
algorithm not only speeds up the process 
but also increase the precision of global 
approach. The reason is that there is no 
region merging for global approach. In 
reality, the precision seems not so 
crucial, especially for large databases 
with many categories, for which the 
precisions are always low, and therefore 
Quick-match algorithm is valuable. 
 
4. Conclusions 
In this report, we have proposed a 
practical image retrieval system based 
on novel salient region segmentation and 
relevance feedback. With a good and 
extremely fast segmentation technique, 
our system achieves a quick 
segmentation capability, which enables 
users to select particular regions for 
matching and feedbacks without waiting 
for image segmentation. Therefore, the 
system does not need complex feedback 
schemes to derive the intent of the user. 
The experimental results show that the 
system performance is greatly improved 
with this capability. Furthermore, a 
Quick-match algorithm is also presented. 
This algorithm excludes most of regions 
from distance computation and therefore 
greatly cuts down the turnaround time of 
the retrieval with slightly degradation of 
precision. 
In general, a region-based image 
retrieval system highly relies on the 
segmentation quality. The better the 
segmentation quality is, the higher the 
retrieval performance can be achieved. 
Although our segmentation algorithm 
produces reasonable segmentation 
results for most images, inevitably it 
may fail for some images. However, this 
will not deeply affect the retrieval 
results because the human selection 
capability will compensate this defect. 
 
References: 
 
[1] C. W. Niblack, R. Barber, W. 
Equitz, M. D. Flickner, E. H. 
Glasman, D. Petkovic, P. Yanker, 
C. Faloutsos, and G. Taubin, 
"The QBIC project: Querying 
images by content using color, 
texture and shape," in Storage 
and Retrieval for Image and 
Video Databases, San Jose, CA, 
USA 1993. 
[2] J. Z. Wang, G. Wiederhold, O. 
Firschein, and S. X. Wei, 
"Wavelet-Based Image Indexing 
Techniques with Partial Sketch 
Retrieval Capability," in 
Proceedings of the Fourth Forum 
on Research and Technology 
Advances in Digital Libraries, 
1997, pp. 13-24. 
[3] R. Brunelli and O. Mich, "Image 
retrieval by examples," IEEE 
Transactions On Multimedia, vol. 
2, pp. 164-171, Sep. 2000. 
[4] I. J. Cox, M. L. Miller, T. P. 
Minka, T. V. Papathomas, and P. 
N. Yianilos, "The Bayesian 
image retrieval system, 
PicHunter: theory, 
implementation, and 
psychophysical experiments," 
IEEE Trans. Image Processing, 
vol. 9, pp. 20-37, Jan. 2000. 
13 
 
IEEE Transactions on Circuits 
and Systems for Video 
Technology, vol. 14, pp. 672-681, 
May 2004. 
[17] C.-T. Hsu and C.-Y. Li, 
"Relevance feedback using 
generalized bayesian framework 
with region-based optimization 
learning," IEEE Transactions On 
Image Processing, vol. 14, Oct. 
2005. 
[18] B. Ko and H. Byun, "FRIP: A 
Region-Based Image Retrieval 
Tool Using Automatic Image 
Segmentation and Stepwise 
Boolean AND Matching," IEEE 
Trans. Multimedia, vol. 7, pp. 
105-113, Feb. 2005. 
[19] J. M. Torres, D. Hutchison, and 
L. P. Reis, "Semantic Image 
Retrieval Using Region-Based 
Relevance Feedback," Lecture 
Notes In Computer Science, pp. 
192-206, 2007. 
[20] C.-Y. Li and C.-T. Hsu, "Image 
Retrieval With Relevance 
Feedback Based on 
Graph-Theoretic Region  
Correspondence Estimation," 
IEEE Trans. Multimedia, vol. 10, 
pp. 447-456, 2008. 
[21] T. Ojala and M. Pietikäinen, 
"Unsupervised texture 
segmentation using feature 
distributions," Pattern 
Recognition, vol. 32, pp. 
477-486, 1999. 
[22] A. Dimai, "Unsupervised 
extraction of salient 
region-descriptors for content 
based image retrieval," in 
Proceedings of the 10th 
International Conference on 
Image Analysis and Processing, 
1999, pp. 686-691. 
[23] E. J. Pauwels and G. Frederix, 
"Finding salient regions in 
images: nonparametric clustering 
for image segmentation and 
grouping," Computer Vision and 
Image Understanding, vol. 75, pp. 
73-85, 1999. 
[24] Y. Deng and B. S. Manjunath, 
"Unsupervised segmentation of 
color-texture regions in images 
and video," IEEE Transactions 
on Pattern Analysis and Machine 
Intelligence, vol. 23, pp. 800-810 
Aug 2001  
[25] R. J. O'Callaghan and D. R. Bull, 
"Combined 
morphological-spectral 
unsupervised image 
segmentation," IEEE 
Transactions On Image 
Processing, vol. 14, pp. 49-62, 
Jan. 2005. 
[26] Y.-H. Kuan, C.-M. Kuo, and 
N.-C. Yang, "Color-Based Image 
Salient Region Segmentation 
Using Novel Region Merging 
Strategy," IEEE Transactions On 
Multimedia, vol. 10, pp. 832-845, 
Aug. 2008. 
[27] N.-C. Yang, W.-H. Chang, C.-M. 
Kuo, and T.-H. Li, "A fast 
15 
 
 
 
Image 
Database
User
User operation
User
inspection
User 
operation
Query 
image
Image segmentation 
& feature extraction 
User inspection
User 
operation
Segmented 
image
Image segmentation 
& feature extraction 
Region selection 
(single or multiple)
Feature 
matching
Ranked 
images Image selection
Image segmentation 
& feature extraction 
Region selection 
(single or multiple)
No more 
relevant 
image?
no
Feature 
merging
yes
Image 
list
Image 
list
Feature 
matching
Feature 
Database
Satisfied? no
End
yes
User operation
Offline processing
Machine  
Fig. 1 The schematic diagram of the proposed region-based image retrieval system 
 
Fig. 2. The coarse division of the RGB color space 
 
 
17 
 
Array
Index
Region
ID Value
．．．
Array
Index
IndexTable
Value
FeatureTable
( sorted )
FeatureTable
( original )
Array
Index
Region
ID Value
．．．
Sorting Indexing
Transition of values
 (a)  (b)  (c) 
Fig. 4 An example of table creation for Quick-match algorithm 
 
 
19 
 
 
0.35
0.37
0.39
0.41
0.43
0.45
0.47
0.49
0.51
0.53
0.55
Pr
ec
isi
on
Global 0.4076 0.4900 0.5214 0.5331 
Weng 0.3668 0.4367 0.4425 0.4406 
Proposed 0.4042 0.5074 0.5276 0.5354 
Match Feedback1 Feedback2 Feedback3
RG
RK
RW
 
(a) on Database I 
 
0.18
0.20
0.22
0.24
0.26
0.28
0.30
Pr
ec
isi
on
Global 0.2071 0.2573 0.2738 0.2772 
Weng 0.1922 0.2234 0.2224 0.2206 
Proposed 0.2181 0.2706 0.2776 0.2770 
Match Feedback1 Feedback2 Feedback3
RG
RK
RW
 
(b) on Database II 
Fig. 6 Experimental results of Experiment I 
 
21 
 
 
 
Query Image Target Image Query Image Target Image 
23 
 
 
us
er 
1
us
er 
2
us
er 
3
us
er 
4
us
er 
5
us
er 
6
Av
era
ge
Part-A
Part-B
0.00
5.00
10.00
15.00
20.00
25.00
Part-A
Part-B
Part-A 5.00 5.00 0.00 5.00 5.00 5.00 4.17 
Part-B 20.00 15.00 20.00 20.00 20.00 25.00 20.00 
user 1 user 2 user 3 user 4 user 5 user 6 Average
Hit Rate
(%)
Hit Rate
(%)
 
Fig. 9 Comparison of Hit Rate 
 
Comparison of precision (with and without color merging)
0.35
0.38
0.40
0.43
0.45
0.48
0.50
0.53
0.55
Pr
ec
isi
on
with color merging 0.3876 0.4882 0.5052 0.5112 
without color
merging
0.4042 0.5074 0.5276 0.5354 
Match Feedback1 Feedback2 Feedback3
 
Fig. 10 Comparison of precision (with and without color merging)(Database I) 
 
25 
 
Comparison of total matching time with and without using Quick-match
(Q stands for using Quick-match)
0
1000
2000
3000
4000
5000
6000
7000
8000
Tim
e(s
)
Matching Time(s) 372.876 257.108 3264.364 1513.255 7530.617 2940.958
RG RQ(Q) RW RW(Q) RK RK(Q)
Fig. 13 Comparison of total matching time with and without using Quick-match 
 
 
 
0.17
0.19
0.21
0.23
0.25
0.27
0.29
Global 0.2071 0.2573 0.2738 0.2772 
Global(Q) 0.2234 0.2705 0.2831 0.2862 
Match FB1 FB2 FB3
Pr
ec
isi
on
RG
RG(Q)
 
0.17
0.19
0.21
0.23
0.25
0.27
0.29
Weng 0.1922 0.2234 0.2224 0.2206 
Weng(Q) 0.2004 0.2173 0.2160 0.2126 
Match FB1 FB2 FB3
Pr
ec
isi
on
RW
RW(Q)
 
0.17
0.19
0.21
0.23
0.25
0.27
0.29
Proposed 0.2181 0.2706 0.2776 0.2770 
Proposed(Q) 0.2203 0.2491 0.2536 0.2533 
Match FB1 FB2 FB3
Pr
ec
isi
on
RK
RK(Q)
(a) (b) (c) 
Fig. 14 Comparison of precision with and without using Quick-match 
 
27 
 
 
Table 2 Category names and the number of images in each category of Database II
Category # of images Category # of images 
banana 113 kangaroo 128 
black bear 191 lotus 112 
bonsai 97 monkey 208 
butterfly 195 mountain 128 
cherry blossom 133 penguin 193 
cock 169 polar bear 203 
container ship 210 pumpkin 101 
cougar 123 rose 142 
dolphin 117 sports car 311 
elephant 210 sunflower 262 
face 432 sunset 263 
flower garden 105 swan 263 
forest 138 tomato 205 
giraffe 275 waterfall 231 
horse 252 zebra 150 
hot air balloon 216   
Total : 5876 images 
 
 
29 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：   年   月   日 
一、參加會議經過 
(1) 會議緣起及介紹 
本次 ICISP1010 國際性研討會於 2010 年 6 月 29 日至 7 月 2 日為期 4 天，在加拿大魁北克市召
開。本次會議由魁北克大學主辦，IAPR、EURASIP、CPM 等著名機構支持籌辦，為第四屆舉
辦的大型國際研討會。會議的目的在提供ㄧ個專業交流，學習研討的平台。會議中涵蓋的領域
集中在影像及視訊處理上，計包括: 
1. Image and Video Processing 
2. Signal Processing 
3. Computer Graphics 
4. Applications 
會議接受發表的論文約 70 篇，另有 3 場 Keynote speech。第一場 Keynote 由 Y. Lecun 教授主講，
講題為“Learning hierarchies of visual features,＂第二場主講者為 T. Gevers 教授， 講題為
計畫編號 NSC 97-2221-E-130 -017 -MY2 
計畫名稱 以非參數密度估測之顯著區域切割技術 應用於區域式相關性回饋的自然影像檢索 
出國人員
姓名 謝朝和 
服務機構
及職稱 銘傳大學資訊傳播工程學系 教授 
會議時間 99 年 6 月 29 日至 99 年 7 月 2 日 會議地點 加拿大魁北克 
會議名稱 
(中文) 
(英文) The International Conference on Image and Signal Processing 2010 
發表論文
題目 
(中文) 
(英文) Human action recognition using keypoints displacement 
31 
 
 
圖 1、報告現場 
 
圖 2、與瑞士學者合影 
30 
 
“Image Search: State-of-the-art and future challenges＂。第三場由 L. Grady 教授主講，講題
為“Image Segmentation＂。這幾場 keynote 都非常精采，獲益良多。 
(2) 參訪經過： 
本人於研討會前一日(6 月 28 日)抵達魁北克市。會議於 6 月 29 日登場，會議地點在魁北
克大學三河校區(UQTR)，報到的專家學者十分踴躍。 
本人的論文安排在 7月 2日早上 10點 30 分到 12 點 30 分。論文題目為＂Human action recognition 
using keypoints displacement＂。這篇論文中提出一個人類動作辨識的新技術,它主要利用相鄰畫框
間特徵點(key points)的位移資訊。特徵點的計算係採用著名的 SIFT(scalable invariant feature 
transform)。首先計算每一畫框影像的特徵點(key point)，找出相鄰 2 個畫框 key point 的對應關係
(correspondence)，ㄧㄧ找到 matched pairs，計算每一 matched pair 的 motion vector，求出 motion vector
的 magnitude (movement) 與 orientation，此即所謂的 SIFT flow，統計 SIFT flow 之 histogram of orientation 
(HOG)，最後將 SIFT-HOG 特徵送入 SVM 學習，以建立 SVM 分類器，以辨識動作的類別。此一研究成
果，在會議中引起了學者的興趣並做了意見的交流。 
二、與會心得 
同一時段發表的論文共有 5 篇，作者來自世界各地，有法國、葡萄牙、瑞士、加拿大等，
論文有做 content-based thermal image retrieval, people reacquisition,3D head trajectory，
ploychromatic model for light dispersion 等等，我們這些作者也利用時間彼此做了交流，談談各
自的研究，也聊聊將來的研究趨勢。 
基於研討會中的交流，本人回國後將儘速整理這篇論文，並投稿學術期刊，同時本人也覺
得出國參予研討會能夠與國外的學者交流，是一個難得腦力激盪的機會，是很有意義的經驗。
本人也將在未來更積極的參與在國外舉辦的研討會，擴展視野，觀摩別人砥礪自己。 
本次論文已經收錄在 Lecture Notes in Computer Science (LNCS 6134),由 Springer 出版。 
三、攜回資料名稱及內容 
 1. 論文集 
 2. 大會手冊。 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
獲得下列國際會議 the best paper award  
The 3rd international on Innovative computing,information and 
control,2008 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
