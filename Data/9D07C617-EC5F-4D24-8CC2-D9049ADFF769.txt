I目錄
一. 前言 1
二. 研究計畫之背景及目的 2
三. 研究方法與結果 41
四. 計畫產出論文 80
五. 參考文獻 84
III
Abstract
The goal of this project is to design an embedded platform to
support next generation stereo video and 3-D man-machine user
interfaces for multimedia applications. The key design focus of this
platform is that it is not designed for any particular killer applications.
Instead, it is designed based on an open multimedia application
middleware, namely DVB-MHP. Therefore, any third party designer can
develop innovative applications for this platform without having to
worry about the underlying architecture, such as the type of processor or
the type of OS used to create the platform. More importantly, the
middleware provides user application accesses to highly efficient
feature-rich multimedia components, including audio-video decoding,
graphics, and 3-D video. The key technologies that will be developed in
this project include: DVB-MHP middleware with extension for stereo
video and man-machine user interface, a deeply-embedded minimal OS
designed specifically for Java runtime support, 3-D video accelerator,
3-D graphics accelerator, Java processor, and multiview video coding
technology.
Keywords: Middleware, Java Processor, Embedded OS, 3-D Video,
Disparity Estimation Accelerator, 3-D Graphics Accelerator, Multiview
Video Coding
2算法與對應的硬體架構，可根據不同的輸入規格重組不同的硬體架構，達
到系統的最佳效能。
3D 視訊壓縮與合成研究：在於深度圖因視訊壓縮所造成之量化效應
(Quantization Effect)下，利用參照影像間隱藏之深度資訊，修補失真之深
度圖。本子項提出了一個檢測單一像素之合成誤差的模型 (Per-pixel
Synthesis Distortion Model)，並發展出合成品質導向之深度圖修補演算
法，此演算法相較於現行的 MPEG FTV 標準架構下，平均多 1.2 dB，且
在主觀視覺上也較接近於原始影像。另外，本計劃根據深度圖之特性，也
提出低運算複雜度之一維深度圖壓縮演算法，在固定合成品質下，深度圖
壓縮率較 MVC 少 4~13%，運算複雜度也較 MVC 之 Intra 預測方式降低了
5~15%。
異質雙核心 Java 處理器：我們設計並實作出一個新的異質雙核心的
Java 處理器架構，主要由一個 RISC core 和一個 Java core 所組成。有別
於去國內外學界及業界所設計的 Java 處理器，我們設計的重點如下：(1)
完整支援 Java 的 object-oriented 的語言特性、 (2)對於 OS 依存度很低、(2)
易與現有硬體電路整合、(3)不使用昂貴的電路元件，如特殊的 Java Object
Cache 或者是 Java Stack Cache，以利於消費性電子產品的應用、(4) 在同
時脈下，執行效能要能跟 CVM-JIT 的技術相當或更高。而我們最後設計
完成的異質雙核心 Java 處理器，也實作在 Xilinx ML-507 平台上進行驗
證，並符合上列各項要求。
除了上述關鍵模組的設計突破之外，本計劃已整合所有關鍵模組於同
一個 Xilinx ML507 平台上，可以進行即時展示。此平台設計可供產學界
未來相關研究參考。
二. 研究計畫之背景及目的：
3-D 視訊技術的發展，在過去十多年一直沒有斷過。從 90 年初期北
大西洋公約組織主導的 Race –DISTIMA (Research on Advanced
Communications in Europe, contract R2045, “DIgital STereoscopic IMaging
and Applications) 計畫[1][2]、後來延續的 PANORAMA (Package for New
Autostereoscopic Multiview Systems and Applications, ACTS project 092) 計
畫、一直到最近的 ISO/IEC MPEG 主導的 MVC (Multiview Video Coding)
計畫[3]。這些計畫發展了許多立體視訊的內容製作、傳輸、編碼、及展
示 (render) 技術。比方說，在 RACE-DIATIMA 計畫結案時，就展示了完
4手機因為螢幕小、記憶體少、處理器也慢，所以它的公開應用程式平
台就是 MIDP 2.0，所有的影音繪圖多媒體功能都受限於 MIDP 2.0 所提
供的應用程式界面。所以不算豐富。而數位電視因為上述的限制較鬆，所
以他的應程式界面也可以比較豐富。目前互動式數位電視系統的整合和應
用界面是由 Sun 所制定的 Java Personal Basis Profile (PBP) 和由各國數
位電視聯盟分別所制定的中介軟體（middleware）所規範 [10]。雖然歐洲、
美國、和日本各有各的中介軟體標準，但他們有一個共同的中介軟體子集
合 GEM（Globally Executable Multimedia home platform）。一個應用程式
如果只用到 PBP 和 GEM 所提供的影音繪圖多媒體功能，那麼就能在世界
各地的數位電視機上盒執行。
圖 1 是一個 MHP 應用程式的執行範例。使用者在收看數位電視的
同時，可以透過電視遙控器進行訂購餐飲外賣的服務。各家和電視公司簽
約的外賣業者，會隨著廣播訊號把他們的 MHP 應用程式傳送到使用者家
中的機上盒（這些程式的傳輸和起動也可以和他們的電視廣告同步）。而
使用者只要透過遙控器就可以進行即時訂購，未來在台灣可能會利用數位
電視內建的 GPRS 晶片把訂購的資訊上傳到電視公司，再由電視公司通知
業者送貨。這樣的應用無疑可以為傳統電視增加新的商機。而這只不過是
MHP 平台的一個小小的應用範例。在圖 1 中，如果業者的圖片、影片、
或動畫能以 3-D 的方式突顯於螢幕之外，想必更能吸引消費者的目光，不
過目前的 MHP 平台並不支援 3-D 視訊。
圖1. 在台灣試播的 MHP 應用程式
目前歐規 DVB [11]的 MHP (Multimedia Home Platform) [12]算是比
較被廣為採用的公開多媒體應用平台。採用 MHP 標準的地區以歐洲、北
非、亞太地區等國家為主。另外，以 MHP 為基礎的 GEM 標準則被美國、
6圖2. 原始影像與 ground truth
視差資料估測演算法在電腦視覺領域(computer vision)已經研究達二
十年以上，各類型的演算法在[63][61]有一般化的分類。視差資料估測演
算法可區分成區域方法(local approach)、半全域方法(semi-global approach)
以及全域方法(global approach)三類，演算法流程如下圖。
圖3. Local approach / semi-global approach / global approach 演算法流程
Local approach 主要以 block-based 的方式計算像素點在不同視差的
matching cost，其 block matching 可以是 SAD(sum of absolute differences)、
ZSAD(zero-mean SAD)、CENSUS、RANK 等各種不同的方式。Semi-global
approach 主要加入了擴散(diffusion)matching cost 的機制，以反覆(iteration)
Block matching
Matching cost
Block matching
Matching cost
Diffusion
Block matching
Matching cost
Diffusion
Optimization
Disparity map
Left
image
Right
image
Left
image
Right
image
Left
image
Right
image
Disparity map Disparity map
Iterati
on Iterati
on
8從 local approach 到 global approach 的演算法在運算複雜度是隨著範
圍增大而增加，而視差資料的正確度則是隨範圍增大而提高。下圖為不同
演算法在四種測試影像以軟體程式的執行時間，前三者屬於 local approach
的演算法，中間兩者為一維最佳化的 global approach，最後四項為二維最
佳化的 global approach，其運算複雜度約是 local approach 的 20~1000 倍。
因此，在本計畫選擇適當的高正確度演算法為基礎，進而轉變為適合發揮
硬體運算特性的演算法，以達到高正確度且高運算效能的硬體架構設計。
圖6. 運算複雜度比較[63]
影像切割化演算法(image segmentation algorithm)
對於影像切割化演算法可大略可區分成三類[68]:image domain-based
techniques、feature space-based techniques 以及 physics-based techniques。
Image domain-based techniques 是以小範圍的方式，觀察空間上相鄰的像
素點間特性，當像素點的特性相近時則屬同一區塊， watershed
algorithme[69]即屬於此類。Feature space-based techniques 是以整張影像為
範圍處理，定義各種特徵空間(feature space)，接著將所有像素點轉換到特
徵空間中，以群聚(cluster)的演算法將特徵空間中的點區分成多個群，每
一群則表示一個區塊，mean-shift[24]即屬於此類。Physics-based techniques
是將物體受光反射產生顏色的物理特性描述成數學模型，根據此數學模型
推算出區塊[70]。
目 前 最 常 被 用 於 視 差 資 料 估 測 的 影 像 區 塊 演 算 法 為
mean-shift[59][60]。由於 mean-shift 在影像切割化的效果頗佳，使得達到
10
圖8. Local approach 硬體設計架構[73]
在半導體製程的進步下，單晶片中可容納的邏輯閘數量(gate count)
大增，使得更多 PE 可加入硬體設計中，增加平行運算的效能，加速視差
資料估測的處理速度。在下圖表示近來的 local approach 硬體設計朝向高
析度(high resolution)的目標推進。在 2007 年的[74]硬體設計中，已可處理
大小 1280x960 的影像，且處理速達高達 52fps，運算能力為 1993 年[71]
的 270 (18.75x14.4)倍之高。然而，如此大量 PE 的運算伴隨需要的是龐大
的暫存記憶體(memory storage)，以及極高的資料頻寬(data bandwidth)。
在先前這些設計中，多半採用 FPGA 作為主要的實現方式。FPGA 實
現方式有其優缺點，如大量的平行度與 on-chip RAM，但價格十分昂貴，
不利廣泛使用與更高計算量的應用。先前之研究由於 FPGA 含有大量的可
配置記憶體空間，故硬體設計將大部分所需之記憶體配置於 on-chip
RAM，而可成功的實作於 FPGA 中。但如此之設計未考慮一旦系統整合
時所面臨資料互相溝通之問題，而且先前之設計並未考慮龐大的資料頻寬
的問題，多為直接實現。此外，若應用於單晶片上的硬體設計，其記憶體
空間的大小會左右晶片的面積，造成可實現於 FPGA 的硬體設計架構在單
晶片的硬體設計會面臨無法實現的問題。因此，周全考慮記憶體空間與資
料頻寬的問題，並設計符合本計畫目標之需求演算法及硬體設計是本計畫
的研究重點。
12
算，但 DP 所產生的視差資料會出現垂直方向不連續的現象，其原因在於
1-D 的最佳化並未考慮垂直方向的擴散，scanline optimization 亦有相同之
情況。
圖11. Dynamic programming 演算法的軟體及硬體設計[75]
針對視差資料在垂直方向不連續之問題，[76]-[78]提出不同的 graph
model，其 graph model 採用介於 1-D 及 2-D 間的樹狀形式圖 10:TreeDP)
順利的改善 dynamic programming 的問題。然而，不規則的樹狀圖形模型
卻造成運算的不規則性，成為硬體設計的困擾。
2-D 最佳化的 graph cut 由於運算複雜度過於龐大[79]，硬體設計雖可
加速處理，但其運算量仍就過大。而 BP 在[80]研究中，採用[81]提出的
hierarchical BP 的反覆次數得以減少，並且簡化其運算複雜度，故可設計
出處理 320x240 大小，處理速度 30fps 的硬體設計。然而，此架構採用兩
個 FPGA，SRAM 的使用量高達 1.8M byte，其資料頻寬需求量極高，並
不實用，且在現今的單晶片 ASIC 硬體設計是無法實現的設計。
圖12. BP 在 FPGA 平台的硬體設計[80]
在考慮單晶片的 ASIC 硬體設計，以上所提及的相關研究皆存在外部
記憶體存取的問題。演算法大量的記憶體使用量，使得大部分的暫存資料
14
以 IP 的形式包裝我們的加速器讓總計劃能夠在嵌入式平台下整合，在這
個階段，子項目二預計提供軟硬介面的繪圖 API 設計: OpenglES 與
Java3D，以方便程式移植與開發。在硬體部分，除分別設計可重組幾何轉
換 子 系 統 (Geometry Transformation Subsystem) 包 含 Geometry
Transformation，Triangle Subdivision，Lighting 與具重組性著色子系統
(Raster Subsystem)包含 Triangle Setup，Visibility Comparison，Z buffer
compressor，Shading 等；結合上述核心重組性子系統的相關研究，將各
項子系統可重組化設計與減低其頻寬的需求的特色，進一步的整合成為智
慧型 3D 繪圖系統加速器。
子項目二目的有二: 一為提供同時提供可重組式與低頻寬需求硬體
與軟體環境，讓開發者在合理硬體成本下能針對所繪製的場景與模型特型
選擇適當的硬體組態來達成繪圖品質來滿足效能的要求；二者為此可重組
3D 繪圖加速器可讓主計畫、子項目一、子項目三、子項目四能獲得足夠
的系統頻寬與強大的 3D 運算支援且提供完整的軟硬體介面，其子項目二
提供的軟硬介面的繪圖 API 設計使各子項目能有效且方便的使用整合與
驗證，進而達到總計劃所訂定的目標。
本子項根據總計劃”支援 3D 立體視訊的數位電視多媒體平台設計”所
需要的可重組 3D 圖形加速核心為設計目標，以下國內外研究設計情況將
針對 3D 繪圖處理器架構、幾何轉換子系統(Geometry Transformation
Subsystem)與著色子系統(Raster Subsystem)與 3D 繪圖加速器軟硬體整合
介面研究等四部分之研究情形與重要參考文獻提出評述。
3D 繪圖處理器架構討論與評述
傳統 3D 繪圖管線如圖 13 包含 Geometry Subsystem 與 Raster
Subsystem 兩部份[82][83]，如上圖所示: Geometry Subsystem 負責轉換三
角形頂點的頂點座標至螢幕座標，而 Raster Subsystem 則將轉換後的三角
形實際繪製成影像供顯示器輸出。下圖的參考的架構說明了 3D 繪圖的成
像過程，實際上根據成本的考量 3D 繪圖處理器可能僅包含上面的某些單
元，例如單獨的幾何子系統或是成像子系統也可能兩個都有，端看設計者
的考量來決定，因此處理器可以定義為具有上述部份單元功能且能增加繪
圖效能的硬體，沒有限制一定要包含全部的繪圖管線。除了下圖所呈現的
傳統架構外，比較特別的架構有 M. Deering et al.[84]於 1988 年在 Proc.
SIGGRAPH 提出”The triangle processor and normal vector shader: A VLSI
system for high-performance graphics”的 Deferred Shading 架構，將打光與
貼圖的動作移到整個 frame 繪製完成後再做，避免掉不必要的打光運算與
材質存取來提高效能；以及 Microsoft 於 2006 年於 DirectX10 提出 Unified
16
圖14. 矩陣運算
 Culling & Clipping
為了減少 Raster Subsystem 的 overhead，Clipping 負責剔除不在視覺
範圍內的多邊形，而 Culling 則根據多邊形的頂點順序決定其面對觀察點
的方向，如果是正面則繼續處理，如果是反面則直接替除。
 著色器(Lighting & Shading)：
光影效果是使場景中的物體能有真實感的重要關鍵，因此此步驟在整
個繪圖管線中扮演相當重要的角色，首先根據頂點與光源幾何關係決定頂
點所呈現的顏色(打光，lighting)，進而決定三角形內所有像素的顏色
(shading)。現今主流的 shading 技術仍是 H. Gouraud 於 1971 年提出的
Gouraud Shading[86]，主要的理由是對於每個三角形他只需要對三個頂點
作打光而其餘的像素使用內插的方式來計算顏色，由於計算量較少因此在
Real-time 的需求下他成為主流的標準。但是 Gouraud Shading 的缺點在於
它會產生缺陷(Polygonal Defect)，也就是反射光的形狀會呈現多邊形的形
狀而失去真實感。其後 Phong Bui-Tuong 提出了改善 Gouraud shading 的方
式，Phong 對每個像素都內插出法向量來作打光，這個方式成功的改善
Grouaud 的缺陷故稱作 Phong Shading[97]。但 Phong 作法的缺點就是他需
要大量的正規化與打光運算而難以被 real-time或嵌入式的graphics系統使
用。
為了避免線性內插產生的法向量所需的正規化計算，Abbas et al.][88]
提出使用 Spherical Linear Interpolation(SLERP)，SLERP 內插所產生的向
量長度為一，因此可以省掉作 normalization 的動作，其後 Barrera et al. [89]
也基於 SLERP 使用不同的遞迴式來達成 Interpolation 的動作。SLERP 的
演算法重點在於把 SLERP的式子改寫成 Incremental的遞迴形式使得 Scan
Line的計算過程僅需要執行簡單的加法運算，但相對的代價就是每條 Scan
Line 需要較長的 Setup Time 來做 SLERP 的初始化動作。但目前市面上的
加速硬體尚未有支援 SLERP，主要的原因在於 SLERP 的特性並非完全適
18
圖15. LNS 運算器主要的功能單元
Mitchell 之後 LNS 的研究重心專著在對數與反對數轉換上，這兩個單
元決定了 LNS 運算器的主要面積、速度與精確度。Mitchell 所提出的對數
轉換方法僅以單一直線去逼近對數曲線，如圖 16 所示誤差的範圍非常
大，其後 Combet et al.[92], Alid et al.[93][94]針對 Mitchell 的做法提出改善
的方式，他們將對數曲線分成數個區段使用不同的直線去逼近，並配合他
們各自提出的修正方法來減少誤差。
圖16. 單一直線逼近對數曲線
圖17. 分段直線逼近對數曲線
直到現在此種 piecewise 的直線逼近計算方法仍持續被研究與探討，
如何選擇適當的分段數與分段區間的選擇以及簡單有效的修正電路設計
是這類演算法的重點。圖 17 是分段逼近的示意圖。圖 18 是 Khalid
在 ”CMOS VLSI Implementation of a Low-Power Logarithmic Converter”中
所提出的piecewise直線逼近對數轉換器的基本架構。LOD負責偵測binary
word 中第一個 1 的位置，由於 LOD 輸出 32bits 的解碼結果因此需要將他
進行編碼以給便給 Shifter 使用。Shifter 在此負責將輸入的數字 normalize
到 1 至 2 的區間以方便後續的運算。最後拿 normalize 後的 mantissa bits
20
頻寬限制而效率不如預期。接著在繪圖卡中新加一顆 DSP 晶片來實現，
但是 DSP chip 並不是為了 3D 繪圖而做最佳化設計且新增 DSP 晶片會使
繪圖卡的大小及成本增加，最後 1997 年 NVIDIA 在發行首兩代的繪圖晶
片失利後，在第三代繪圖晶片中改採用全硬體化的三角型驅動引擎及其他
相關的特殊架構，即得到市場上多數的好評與支持。由此可知三角型驅動
引擎在整個 3D 管線中所佔有的運算量之大和硬體化之後所得到大幅效能
提升。NVIDIA 在許多技術手冊上都明確的表示，三角形驅動引擎是種浮
點術處理單元，專門接收幾何運算引擎傳來的頂點(vertex)資料，利用這
些資料組合成三角形並剔除畫面中看不到的三角形(Back Face Culling)，
最後把剩下的三角形分解成繪圖引擎所需要的像素(pixel)資料並傳給之
後的繪圖引擎做其他材質貼圖或打光等更精細的計算。
而現行大部分的 3D 繪圖晶片都把三角形驅動引擎設計再靠近繪圖引
擎這端，主要是為了減少系統內單元間的頻寬負載，使經過 TSE 運算所
得到的大量像素(pixel)資訊可以直接傳給之後的繪圖引擎做更精細的運
算。圖 19 為 Ju-Ho Sohn 博士[97]等人 2006 年在 IEEE JOURNAL 發表的〝A
155-mW 50-Mvertices/s Graphics Processor With Fixed-Point Programmable
Vertex Shader〞中所提到的繪圖晶片系統架構方塊。虛線框所表示的即為
幾何運算引擎、三角形驅動引擎及繪圖引擎三者間的關係。
圖19. 圖形處理器方塊圖
Anders Kugler 博士 [98] 於 1996 年在〝The Setup for Triangle
Rasterization〞提到的 3D 繪圖管線中，也特別把三角型驅動引擎獨立出來
並分為兩個主要的部分(見圖 20)，分別是 edge walk 和 span interpolation。
22
置和顏色不會差異太大為原則，可以套用常見的預測式失真壓縮法如
DPCM 或 ADPCM 等等，將可以獲得較好的壓縮比例和效果。
在頂點的法向量壓縮方面，Michael Derring 博士[99]從人類視覺的觀
點出發，提出一個新的觀點。首先刪除人類視覺系統無法辨別的向量，把
單位圓內的向量減少至 100,000 個左右，再以單位圓分為八個象限以及一
個象限分為六等份來摺疊，如下圖 22 表示，使原本 100,000 個左右的向
量減少至 2,000 個左右來代表 1/48 的單位圓(8*6=48)，最後將這 2,000 個
向量存在表格中，可以利用 11bit 表示 index，其餘摺疊起來的部分在分別
用 3bit 去編碼。解碼時只需要正負號轉換或座標交換即可得到整個單位圓
100,000 個向量中任一個向量值。
圖22. 單位圓利用象限和數值大小關係產生的編碼法則圖
 Scan Conversion
Scan conversion 為整個三角型驅動引擎中計算最多的部分，三角型經
過 edge walk 之後得到完整的邊界像素，在每個水平掃描線上，利用兩個
端點的值分別用內插法算出其中各點的位置、顏色及法向量等必要資訊。
如下圖 23 中所表示，P0 和 Pn 分別為兩個端點，δx表示兩點的 x 差值，δz
表示兩點 z 的差值…以此類推，最後算出三角形內每個像素(pixel)的位置
(X、Y、Z)和顏色(R、G、B、α)以及法向量(N)的值傳給之後的繪圖引擎。
24
圖24. 深度緩衝區架構概要圖
其中 depth buffer compression 又有許多方法，主要可以分成 fast
z-clear，offset，plane 三種壓縮方式[106] ，包括：fast z-clear[108]，differential
differential pulse code modulation(DDPCM) [105]，Anchor encoding[113]，
plane encoding[114]，depth offset compression[111]，efficient depth buffer
compression[106]等方法，不過大多以專利的方式呈現。
Fast z-clear 可以讓我們避免去讀取目前已經是標記為是清除的 depth
tile，而直接進行 z test 來檢查是否更新 depth tile 上的 z value，因此不僅
可以使我們得到不錯的壓縮比而且也易於實做。
Differential differential pulse code modulation(DDPCM)是利用 z values
在 screen space 上為線性分佈的特性而達到壓縮的效果。圖 25 解釋
DDPCM 的計算流程。
圖25. DDPCM 的計算流程.
26
表示與 Zmin 或 Zmax 的差值為可儲存的，而且此方法最後就是儲存這些
差值而達到壓縮的目的；若是系統設計本身沒有儲存 Zmin 及 Zmax，則
可以在每個 tile 中選擇一個或兩個 reference points，這些 reference points
可視為下圖的 Zmin 及 Zmax，如此一來就跟 DDPCM 雷同；一般而言，
depth offset compression是比較適用於系統設計本身有儲存Zmin及Zmax。
圖28. Depth offset 壓縮
Efficient depth buffer compression 與 DDPCM、Anchor encoding 以及
depth offset compression 的核心概念一樣，利用儲存差值來達到壓縮的效
果，比較不同的是對差值的額外處理；下圖 29 解釋 efficient depth buffer
compression 的計算流程。
圖29. Efficient depth buffer 壓縮
圖30. 圖 18：Traversal order
由圖 29 (a)表示最初未經過壓縮的 depth tile，(b)是經過圖 30 所描述
的 traversal order 後，計算得到的差值，藉由觀察(b)可以發現，當一個 depth
tile 上的 z values 夠連續時，則差值的範圍會介於-1 到 1；若所有的差值
皆介於-1 到 0 時，此時我們將所有的差值都加上 1，而且對應的△z/△x
及△z/△y 都減去 1，則我們就可以用 1 bit 表是最後要被儲存的差值而非
(b)表示的 depth tile 需要 2 bits 儲存差值，如(c)所示，進而得到更好的壓
縮比。
28
子項目三：MVC 編碼系統中介軟體
本項目將分析多視角視訊編解碼標準，改善現有的編碼工具並提出新
的編碼工具藉以實現可任意視角觀賞之高效能多視角編解碼標準。研究方
向包含(1)多視角視訊編碼演算法效率改善，(2)視角合成 (View Synthesis)
技術開發，與(3)中介軟體定義與開發。以下說明本項目研究方向之背景
與目的。
MHP 平台上之互動式 TV 應用
歐美國家早在幾年前就開始利用數位電視的頻寬資源，提供互動性質
的服務內容，例如直播球賽中，如果看中球員身上所穿戴的廣告商贊助衣
服，可立刻利用電視下單訂購，甚至是進行場外賽局下注，而德國的電視
公司 ZDF 則是推出互動式的旅遊節目來吸引消費者，觀眾可藉由虛擬的
旅遊導覽來觀賞自己想看的資訊[124]。國內的數位互動電視服務業者中
嘉科技結合新視波公司，推出提供即時資訊、遊戲娛樂、飲食購物、金融
理財、生活休閒、文化教育等六項互動內容，稱之為「互動 TV」[125]。
至於互動內容更是令人驚艷，包括電子節目選單（EPG）、隨選視訊系統
與說明設定，如同以電視操縱電腦軟體一般，利用遙控器就能與電腦進行
互動。這些都已經成為相當受歡迎的電視機新娛樂功能。
MHP 平台結合自由視角電視(Free Viewpoint TV)應用
隨著 MHP 平台在各國的多方應用，倘若 MHP 平台能支援 3-D 視訊，
那麼在應用方面的範圍更可以多元化；比如，上述的旅遊節目，有時會因
為 2-D 的影像而顯得乏味缺，若能引進 3-D 視訊，支援多視角視訊，將
帶給使用者有如身歷其境的感覺。另外，美食節目若結合自由視角電視功
能，收視用戶不僅可以多方觀賞廚師製作佳餚時，不同角度的手勢、醬料
分量、擺盤方式等，甚至於可立刻利用電視進行購物，購買節目中的調味
料、食品原料或鍋碗瓢盆；類似的想法亦可引用於旅遊導覽系統，提供要
出外旅遊的相關景點資訊，可以在螢幕點選地圖的景點，即可進入 3-D 視
訊的景點介紹，除了可以讓觀賞者了解觀光景點的資訊外，更可以豐富其
所要介紹的內容，來增加遊玩者的旅遊欲望；基於這出發點，亦可將此功
能用於 GPS 導航系統，現階段雖有 3-D 導航，但是採用 3-D 動畫圖形的
方式呈現，雖然有別於 2-D 的地圖較易於觀看，但仍缺乏真實感，且與現
實生活中建築物、地面景物仍有一段差距，所以在 MVC 的應用下，皆可
克服此種問題，藉由多視角的視訊傳輸，可以克服傳統上狹隘的死角畫
面，搭配即時路況與導航系統，相信在未來對於駕駛而言，可以帶來諸多
便利。
自由視角電視(Free Viewpoint TV, FTV)現況
30
與(3) FTV 傳輸資料格式(FTV Data Format)(包含視訊資料，深度資訊，與
像機參數等)。
多視角視訊編碼標準(Multi-view Video Coding)現況
有鑒於三維多視角影片漸漸受到重視，Moving Picture Expert Group
(MPEG, ISO/IEC SC29/WG11)會議從 2001 年即成立一個三維視訊音訊專
家群(3D Audio and Video Group)開始探討三維音訊視訊相關技術。專家群
創立初期，日本與韓國顯示器與消費電子大廠如 Sony、Matsushita 和
Samsung 均投入大量的研究人力積極開發。在經過多年的研究，數篇貢獻
文件已於 2006 年 1 月在泰國曼谷所舉行的 Call for Proposal of Multi-View
Video Coding 中證明：「相較於以不同視角個別壓縮的方法(Simulcast)，利
用不同視角畫面的相關性來進行壓縮可以得到更好的壓縮效果」。因此，
在 2006 年 7 月，ISO/IEC JTC 1/SC 29/WG 11 MPEG 於奧地利的第 77 次
國際標準制訂研討會中正式宣佈多視角視訊壓縮編解碼 (Multi-View
Video Coding, MVC)成為國際電信聯盟(International Telecommunication
Union, ITU)與國際標準組織(International Organization for Standardization,
ISO)共同專家群(Joint Video Team, JVT)的下一個合作開發項目。
目前，多視角視訊壓縮編解碼(MVC)的開發建構在 MPEG-4 Part 10
精進視訊編碼(Advanced Video Coding)之上，並將成為暨 MPEG-4 Part 10
Amendment 3 可調視訊編碼(Scalable Video Coding)之後的另一個精進視
訊編碼(Advanced Video Coding)修正案(Amendment 4)。現階段的多視角視
訊編解碼標準草案(JMVM Joint Draft 4.0) [121]已針對 Sequence Parameter
Set (SPS)、NAL Unit Header SVC Extension 及 Reference Picture List
Reordering Syntax 提出了新的高階編碼語法(High-Level Syntax)以適應多
視角視訊的編碼架構。如在 SPS 中利用 view_level 用來指定 NAL 單元視
角可調性的層級(Level)，view_id 為視角的識別號碼，num_views_minus_1
用來指定視角(View)的數目。另外標準草案亦描述多視角視訊編解碼架構
下的解碼程序(Decoding Process)包含參照畫面串列建立(Reference Picture
List Construction)、已解碼參照畫面標記程序(Decoded Reference Picture
Marking Process)以及解碼畫面暫存器的管理 (Decoded Picture Buffer
Management) 等。此外，現階段的 Joint Multi-view Video Model (JMVM 5.0)
[122]也涵蓋多項可能標準化技術如亮度補償、Motion Skip Mode、
View-first and Time-first 編碼順序等。
多視角視訊編碼技術文獻探討(Technology Survey)
多視角視訊編解碼主要問題在於如何在不同的視角視訊之間做有效
的估測與補償。一般來說，多視角視訊的取像相機通常存在距離和角度的
差別。同時，物體表面的傾斜度亦會造成相鄰相機在成像上的差異。因此，
32
角先的編碼架構。圖 34 則為時先編碼架構，同一個時間點的所有畫面在
編碼的順序上是相鄰且連續的。經由分析，若在視角維度(View Dimension)
上採用類似多層次的雙向估測(Hierarchical B-picture Prediction)的方式來
達到視角可調性時，視角先編碼架構所需的已解碼畫面儲存器的容量需求
為
number_of_views + GOP_length*(1+log2(number_of_views))+log2(GOP_length)
而時先編碼架構所需的已解碼畫面儲存器的容量需求為
(log2(GOP_length)+1)* number_of_view+(1+log2(number_of_views))
其中， number_of_views 為視角的數目，GOP_length 為編碼的畫面
群(Group of Picture)的大小。實驗結果發現，視角先(View-First)編碼架構
縮所需的儲存器容量比時先(Time-First)編碼架構來的大。以 GOP=16 且
number_of_view=9 為例，視角先編碼架構需要 77 個儲存器容量，相對的，
時先編碼架構只需要 49 個單位容量。
圖33. 視角先(View-Fisrt)編碼架構。[122]
圖34. 時先(Time-First)編碼架構。[122]
 B.亮度補償(Illumination Compensation)
34
關性，目前的 JMVM 提供了運動略過模式 (Motion Skip Mode)使得
Macroblock在編碼時可以省略動態資訊(Motion Information)藉以提高編碼
效率。其中動態資訊包含 mb_type，reference_index 以及 mvd 都將改由參
照視角畫面推導而得。
POCcur POCBPOCA
GDVA GDVcur GDVB
Corresponding MB
Current MB
Temporal
Spatial
圖36. Global Disparity Vector 之推導。[122]
運動略過模式只作用在由 Sequence Parameter Set 所描述具有視角間
預估的視角序列，運動略過模式分為兩個主要階段。(a)全域視差向量
(Global Disparity Vector)的推導與(b)動態資訊的取得。以下分別就此兩階
段詳細描述。
(1) 全域視差向量(Global Disparity Vector)的推導
全域視差向量的目的是用來指出相同時間點的參照視角中相對應
Macroblock 的位置。首先利用最小化畫面差的殘餘訊號(residual signal)來
求出錨點畫面(Anchor Picture)間的全域視差向量，並將此向量編碼傳送至
解碼端。非錨點畫面(Non-Anchor Picture)間的全域視差向量則利用時間順
序的前一個錨點畫面與後一個錨點畫面的全域視差向量以 Bilinear方式推
導而得。如圖 9 所示，為了找出目前巨集區塊(Current MB)在參照視角中
相對應的區塊(Corresponding Macroblock)，目前畫面的全域視差向量
GDVcur 利用前一個與下一個錨點畫面的全域視差向量 GDVA 及 GDVB 推
導而得，其推導公式如方程式(3)所示。POCcur， POCA 與 POCB 分別表
示目前畫面，前一個錨點畫面與下一個錨點畫面的 Picture Order Count
(POC)。





 

 )( AB
AB
Acur
Acur GDVGDVPOCPOC
POCPOC
GDVGDV (3)
(2) 運動資訊(Motion Information)取得
36
圖37. 三維資訊重建方法之視角合成概念
三維資訊重建方法其原理是利用畫面的深度圖(Depth Map)以及相機
參數(Camera Parameters)經由針孔成像模型(Pinhole Model)把畫面二維空
間中的像素投射到三維的真實空間。同時，再根據所得的相機參數把三維
空間上的像素點重新投射到欲合成視角畫面的二維空間上即可重建出虛
擬視角的畫面。如圖 37 所示，把影像中二維的像素座標利用 Pinhole 的成
像投射公式投射到三維空間上，來重建三維資訊。接著再把重建後的三維
資訊投射到所要合成的視角畫面上，即可完成虛擬視角的合成。三維資訊
重建方式雖然可以避免物體遮蔽的問題，但是需要實際場景的深度資訊
(Depth Information)。由於深度圖(Depth Map)取得不易，同時要正確估計
的困難度高，且深度圖影響合成準確度甚鉅。因此，如何正確估出影像的
深度圖(Depth Map)成為三維資訊重建另一個重要問題。
由於人眼之成像系統是由吸收物體反射後的光線（Ray），將影像呈
現在視網膜上，不同於傳統紀錄圖像的格式 Pixel-based System，其紀錄
單一視角的固定數量之採樣點，建立 2D 的 Pixel-space Data；於本計劃
中我們採用 Ray-based System，於此系統之下，所有影像之 3D 訊息皆
以“光線（Ray）”呈現，因此可以完整保存 Sampled Ray 的所有資訊，包
括其亮度、顏色、射角、位置等，因此所有影像資料不論支援幾個視角（View
Point），皆可以 Ray-based System 來保存光線之完整資訊，建立 3D 的
Ray-space Data。
Ray-space 於空間上的表示法
令(x,y,z)為三維空間上任何一點的空間表示法，而θ與φ分別代表不
同視點間的水平轉角差與垂直仰角差，其中 -π≦θ＜π，-π/2≦φ＜π/2。以
此五維表示法(x,y,z,θ,φ)構成 Ray-space，可以清楚表達空間上的每個點的
絕對位置，與每個相異視角間的差異。Prof. Tanimoto 於 FTV（Free-view
point TV）中[131]，提供兩種不同的座標表示法來表示 Ray-space，用以
在人眼視角與攝影機視角間的切換：
 Orthogonal Ray-space：(人眼的視角)
圖 38 中，令 R 為攝影機接收到的一個 Ray，Q 為 X-Y 平面， (x,y)
代表 R 在平面 Q 上交點，而(θ,φ) 分別代表不同視點間的水平轉角差與垂
直仰角差。
38
後，執行 Filter Selection 演算法找出最佳的 Filter，而 H1~Hn 即代表各種
不同的 Filter。
圖40. (左) Ray-Space 上的 Adaptive Filter、(右)數種 Filters [134]
內差前必須先對 Orthogonal Ray-space 的 X-tanθ截平面做 Upsampling，如圖
41(左)。而右圖則為經過 Interpolation 之後的結果。
圖41. (左)內差前的 Ray-space X-tanθ截平面、(右) 內插後的 Ray-space
X-tanθ截平面[134]
Filter Selection 演算法，利用 Variance 值來選擇適當的 Filter(取
Variance 總和之最小值)，
Step 1：Row process - Variance Filter 分別對每個 Row-data 計算水平方
向的 Variance。
Step 2：Line process–沿著“目前正要內差的點”，依點中心之座標旋轉，
計算每個角度(虛線)的 Variances 之和，並取最小值之方向線為
依據，選擇適當的 Filter。
Improved Filter Selection 演算法，如圖 42 所示，P 為鄰近已完成內差
的點，C 為目前正要內差的點，P 點上的實線代表 P 點選用實現兩端點當
線性內插的參考點(圖 42 的灰色區域)，C 點上的虛線代表正在選出最佳之
Filter。因此 C 點在預測其 Filter 時(虛線)，虛線沿 C 點中心作旋轉，其選
用之參考點的連線不允許超過 P 點的實線，因為在 Ray-space X-tanθ截平
面(見圖 42) 上所看見的線段，並未直接越過前一條線段。
40
但是早期手機規格中所選用的 CLDC/MIDP 所能提供的使用者界面和功
能太過陽春，而進年來，多媒體手機的功能和螢幕大小的發展，早以遠超
過當年 CLDC/MIDP 所定義的規範，所以在高功能的多媒體手機方面，未
來遲早也會走向支援 CDC/PBP 規格的開放式應用程式平台。
最初 Java 語言及虛擬機器在定義的時後並沒有想到有一天會成為嵌
入式系統的主流語言，所以它的設計造成在嵌入系統的實作有很多效能上
的問題要解決。首先，物件導向（object-oriented）的程式需要依靠許多動
態記憶體配置的功能，而對嵌入式系統而言，這是相當沒有效率的。其次，
Java VM 基本上是一個堆疊機器（stack machine）[137]。因此在進行任何
運算時，會有不斷利用 Stack 來進行計算的中間質存取的動作，這也是非
常沒有效率的。一般而言，高效能處理器是會用 registers 來記錄運算過程
的中間結果，以提升效能。最後，大部份的嵌入式系統使用了一個頻率低
於 300MHz 的 RISC 處理器做為主處理器，這樣的架構對於執行虛擬機器
而言是很沒有效率的[138][139]。
過去，也有不少研究試圖加快 Java VM 的效能的[138]。對於嵌入式
系統而言，以軟體為主的加速技術如 Just in Time (JIT) [144][145] 編譯的
方法是比較不適當的。因為 JIT 編譯器往往需要較大的額外記憶體，而且
在應用程式執行前會有額外編譯的 overhead，由於嵌入式系統的處理器較
慢，所以這些額外的時間延遲對使用者而言會比較明顯。在[141], 一些
object-oriented 相關的動態解參考（dynamic resolution）等指令，都是用
硬體加速計算，這邊較困難的部份是要把一些 runtime 的資料結構設計的
比較適合用硬體讀寫。有些系統（如 ARM 所開發的 Jazella [143]）則是
使用 co-processor 的方式，把一些指令直接用硬體解碼及執行。也有一些
是直接設計一個硬體直譯器來進行虛擬機器碼的線上翻譯[142][153]
[154]。 也有一些是直接設計 Java 處理器[139][140]。JOP (意為 Java
Optimized Processor)是由 Schoberl [139]所開發的一個公開 RTL 碼的 Java
處理器。不過 JOP 定義了自己的 Java profile/configuration, 所以它提供的
執行環境並不支援 Sun 所定義的任何標準。不過基本上，JOP 執行環境的
規格是比較接近 CLDC。
在子項目四中，我們會設計一個 Java 處理器來支援 CDC/PBP 的完整
Java 執行環境。事實上，子計畫四團隊已經在執行過去的一項國科會建置
計畫時開發了第一代的 double-issue Java 處理器，並且在 FPGA 上驗證成
功。不過，要能支援完整的 CDC/PBP Java 執行環境，還有很多地方需要
改進。
42
整個系統的完整架構如圖 43 所示。其中的關鍵元件如下：
1. 3-D Video 計算加速核心及相關程式庫－由子項目一開發
2. 3-D Graphics/Video 成像引擎及相關程式庫－由子項目二開發
3. 3-D Video 編碼技術及相關程式庫－由子項目三開發
4. 高效率 Java 處理器及 Java 執行環境－由子項目四開發
5. 系統中介軟體及 native-code 排程核心－由總計畫開發
HW
SW
3-D Video Java Applications
Java-based Middleware
Xilinx Virtex-4I/O Devices JavaProcessor
RISC
Processor
Java CDC/PBP ClassesThin Deeply-Embedded OS
3-
D
V
id
eo
Li
b.
MHP Middleware
3-D Video
accelerator
3-
D
G
ra
ph
ic
Li
br
ar
y Application Manager
(User Interface)
MHP Extension
for
3-D Video/Graphics
3-D Graphics
accelerator
M
ul
ti-
vi
ew
V
id
eo
C
od
in
g
Li
b.
子計畫一總計畫 子計畫二 子計畫三 子計畫四
圖43. 計畫預計完成的開放式多媒體平台
以下針對上述系統的每一個子項目的研究方法及成果、以及總計畫系
統整合的幾項要點進行進一步分析和說明：
44
在發展版上驗證的過程中，受限發展版資源有限(FPGA 大小、BUS
架構和處理器速度)，一些關鍵模組將部分功能化簡，例如：3-D Graphics
只能將 germetry subsystem 以電路方式整合燒入 FPGA，另一半 renfering
subsystem則以軟體方式呈現在PowerPC上執行；另外3-D video accelerator
也折衷採用化簡後的演算法電路。但這些化簡並不會影像系統整合驗證，
並且可以輕易移植到其他設計方法上(例：ASIC)。另外，雖然在整合上有
部分化簡，但是相關的模組亦可另外獨立驗證並呈現。
FPGA
VGA
Controller
Frame
Buffer
3-D Graphics
accelerator
(Geometry Subsystem)
3-D Video
accelerator
Java
Processor
PowerPC
System Bus (100MHz)
3-
D
V
id
eo
Li
br
ar
y
3-
D
G
ra
ph
ic
Li
br
ar
y
(R
en
de
rin
g
S
ub
sy
st
em
)
3-
D
V
id
eo
S
yn
th
es
is
Li
br
ar
y
Ja
va
S
er
vi
ce
R
ou
tin
es
圖45. 總計劃整合平台架構
整合平台的執行範例程式是一隻 JAVA 3-D 人機介面程式，他透過計
畫發展的 3-D 函式庫可以畫出 3-D 顯示畫面，如圖 46。圖中下方發展版
是 ML507，我們在 Java 平台上(子項目四)執行一個 3-D UI 應用程式，可
輸出 3-D 應用畫面如螢幕所示。而畫面中 3-D 效果以紅藍眼鏡呈現。應
用中整合了 3-D 視訊應用(子項目一和子項目三)、3-D 圖學應用(子項目二)
以及一些 3-D 立體介面按鈕。
這個範例程式展示了一個標準 3-D 電視系統的雛型，所提出的平台提
供了一個很好的設計參考給未來產學界相關研究使用。接下來篇幅繼續分
述各個關鍵模組的研究方法和成果。
46
子項目一：3-D 視訊計算加速核心之設計（Design of 3D Video accelerator）
子計畫一已發展出適合硬體實現的半全域視差資料估測演算法。此演
算法基於適應性權重計算 (Adaptive Weight)演算法結合微型普查
(Mini-Census)的比對方式，以及量子化指數曼哈頓色彩距離(Quantized
Manhattan Color Distance)等技巧。演算法如圖 47 所示。
Mini-Census
Transform &
Matching
Vertical
Cost Aggregation
Left Image
Horizontal
Cost Aggregation
Weight
Generation
Winner
Takes-All
Right Image
Depth
Winner
Takes-All
Winner
Takes-All
First AggregationInitial Depth
圖47. 視差資料估測演算法
首先，由 Mini-Census 計算兩像素的比對值(matching cost)可減少運算
量，從原始的一個方型視窗的運算量轉換為六個點的運算量。其運算如圖
48 所示。Mini-Census 優點在於較原始演算法更能承受影像受光線影響的
問題。
34 3 13
5 15 23
2 54 30
0 1 1
1 X 0
1 0 0
4 68 17
61 51 4
23 3 59
1 0 1
0 X 1
1 1 0
bistream 1: 01110100 bistream 2: 10101110
Hamming Distance = 5
Census
Census Template Mini-Census Template
圖48. Mini-Census
48
0
0.2
0.4
0.6
0.8
1
1.2
0 20 40 60 80
Original
0
10
20
30
40
50
60
70
0 20 40 60 80
x64, Quantized
-20
0
20
40
60
80
0 20 40 60 80
x64, Quantized, P 2-bits
0
10
20
30
40
50
60
70
0 20 40 60 80
x 64, Quantize, P 1-bits
圖51. 比較 Color Similarity 的運算化簡
總和以上改變演算法以利於硬體設計的技巧，在個人電腦運算時間與
視差圖準確度如下表所示。對於準確度約降低 1.2%以內，而運算時間大
幅降低至原始運算的 1.9%。如此的硬體導向演算法將有利於進一步的硬
體架構設計。
Error Rate %
Method
TSUKUBA VENUS TEDDY CONES
Exec.
Time(sec)
Original 1.85 1.19 13.3 9.79 95.65
+MC+2P 3.47 0.91 14.3 11.2 4.75
+MC+2P+ Manhattan 3.08 0.59 14 10.1 3.12
+MC+2P+ Manhattan +Truc(64,2) 3.03 0.61 14 10.1 2.52
+MC+2P+ Manhattan+Truc(64,1) 3.06 0.66 13.9 10.1 1.84
在硬體架構設計方面，我們針對 Mini-Census 及 Cost Aggregation 的
運算分析各種資料對記憶體存取的方法。在 Mini-Census 有視差優先再利
用(Disparity-Order Reuse)以及像素優先再利用(Pixel-Order Reuse)之方
法。在 Cost Aggregation 有列局部再利用(Partial Column Reuse)以及行垂直
延伸再利用(Vertically Expanded Row Reuse)。考慮運算量、記憶體用量以
及頻寬用量，最後採用 Disparity-Order Reuse、Pixel-Order Reuse 與
50
Ground truth Proposed TrellisDP
HBP RealTimeBP RealTimeGPU
ReliabilityDP SepLaplacian RealDP
ReliableGPU CBiased
圖53. 視差圖比較
Design Category MDE/s TSU VEN TED CON SAW MAP
Proposed Hardware 272.5 2.80 0.64 13.7 10.1 2.11 3.21
TrellisDP [39] Hardware 294 2.63 3.44 - - 1.88 0.91
HBP [80] Hardware 73.7 2.85 1.92 - - 6.25 6.45
EffectAggr [40] CPU 18.9 2.96 3.53 10.7 4.92 - -
RealDP [41] CPU 209 2.85 6.42 - - 6.25 6.45
Cbiased [42] CPU+GPU 605 4.77 10.2 - - 0.82 0.65
SepLaplacian [43] CPU+GPU 679 13.0 - - - - -
RealTimeBP [44] CPU+GPU 19.6 3.40 1.90 13.2 11.6 - -
RealTimeGPU [45] CPU+GPU 19.6 4.22 2.98 14.4 13.7 - -
ReliableGPU [46] CPU+GPU - 1.36 1.09 - - 2.35 0.55
GradientGuided [47] CPU+GPU 117 2.48 3.91 - - 1.63 0.73
52
Baseline BP
[67]
Hierarchical
BP
[81]
Block-based
BP
[39]
Tile-based BP
[49]
Iteration T 30 5, 5, 10, 5 30 inner=8,
outer=2
Required
Throughput
(Node/Frame)
4,608,000 1,212,000 4,608,000 4,915,200
Operating
Frequency (MHz)
285 285 285 285
Number of PE 33 9 32 32
Gate Count (K) 273.9 74.7 265.6 265.6
Size of
Sliding-Bipartite
Node Plane
30x480
(image-scale)
5x480
(image-scale)
30x32
(block-scale)
8x32
(block-scale)
Memory Cost of
Messages and Data
costs (KB)
2,793 465 186 49
FPS 30.01 31.12 29.11 27.29
本子計畫亦針對 DP 演算法改善其高記憶體用量的問題，使得 global
approach 演算法可實現於總計畫的 FPGA 整合平台。原始的 DP 演算法包
含兩主要步驟:forward cost accumulation 與 backward path tracing。由於兩
步驟的運算流程，必須存取一整列的資料，導致記憶體用量過高。因此，
本子計畫提出單步驟的演算法，將原始的兩步驟合併，直接在第一步驟中
就決定 path，其流程圖如圖 56 所示。。由於大幅降低記憶體用量，DP 演
算法可順利地實現於總計畫 FPGA 的整合平台。圖 57 及圖 58 分別為本子
計畫所實現的 DP 演算法之 ASIC 與 FPGA 的硬體效能。
54
子項目二：可重組之 3D 繪圖加速器設計（Reconfigurable 3D Graphics
Accelerator）
本子項目二之研究重點為可重組之三維繪圖加速器設計如圖 59 所
示。因此我們分別在前端幾何轉換子系統中的打光運算單元以及後端繪圖
子系統中的三角形設定引擎與深度壓縮機制提出可重組式的演算法與對
應的硬體架構，根據不同的輸入規格重組不同的硬體架構，達到系統的最
佳效能。同時也已各別完成前後兩級的基本的硬體電路設計與 FPGA 模擬
驗證平台，另外也成功將前後兩級整合在一起，並已在 FPGA Xilinx
ML507 平台模擬驗證完成。
圖59. 重組式 3D 繪圖系統架構圖
本子計畫我們將各子區塊的實作情形以及研究成果分項列出，主要分
為幾何轉換子系統與著色子系統的設計與硬體實現等，最後總結整個子計
畫的實作成果。
幾何轉換子系統(Geometry Engine)
在幾何轉換子系統部分，主要是打光器的演算法與硬體實現，以下分
別深入探討其實際設計的理念。
 Approximating Phong Shading
本子計畫在打光器設計上主要有三項突破點以及實現結果，分別是：
三角型切割之演算法與其硬體設計與實現、頂點變數共用機制、邊函數修
正機制。以下分別討論之。
Reconfigur
56
割的動作是在繪圖硬體上完成則新頂點就不需要在匯流排上傳送，如此就
可省下許多的頻寬而使繪圖效能提升。傳統的切割演算法使用遞迴的方
式，但遞迴演算法不適合在硬體上實作，主要的原因在於堆疊的支援與切
割出頂點的管理。由於遞迴式演算法會在共用邊上切割出相同的頂點，管
理這些頂點所需的資料結構在硬體上實現相當複雜。但如果不使用管理頂
點的機制而直接將產生的任何頂點直接送到打光單元中，就會對相同的頂
點重複打光。打光的運算是相當耗時的，所以我們希望盡量避免重複的打
光動作，為了兼顧硬體複雜度與效能我們使用了漸增式(Incremental)切割
的方式來實作切割器。圖 63 說明漸進式切割的概念，要將一個三角形切
成四個小三角形需要計算出在各邊上中點的頂點，而 dy 與 dx 可以事先計
算，透過這種逐一加上一個向量的方式就可以循序地產生所有的頂點。由
於頂點是依序被產生因此可以直接送到打光單元進行打光而不需要擔心
重覆頂點的問題，因此也不需要額外的頂點管理機制。漸增式切割可以很
容易的進行任意數量的切割運算，如圖 64 所示，只要計算出需要的 dx
與 dy 向量並透過漸增的方式即可產生所有需要的頂點。
圖63. 漸增式切割演算法
圖64. 任意數量的漸增式切割
頂點變數共用機制:而經由切割器切割後產生的許多小三角形無疑的
會對效能造成衝擊，頂點數量增加意味著需要更多的幾何轉換，三角形的
數量增加也代表三角形準備的運算和後端著色子系統所有的效能負擔的
增加，因此前後端如何互相配合才能不影響系統效能也成為我們的研究重
58
(a) Before subdivision (b) After subdivision
(c) Rasterization result (a) (d) Rasterization result (b)
圖66. 破洞圖解說明
圖67. 消除破洞模擬結果
著色子系統(Rendering Engine)
在著色子系統部分，其系統流程圖如下圖 68，總共可以區分成三塊
主要子系統，包含 Triangle Setup Engine 負責將幾何轉換子系統的
Triangle-level 轉換成後級的 Pixel-level；Depth Testing Unit 負責測試每個
像素(pixel)的深度值，決定該像素是否需要顯示在螢幕上；Texture Mapping
Unit 負責替每個像素套上該場景下的色彩。接下來會分別深入探討三個子
60
圖69. 常用演算法和 proposed 演算法之壓縮比之比較
Texture Mapping Unit：Texture Mapping Unit 就是傳統的 Pixel
Processor，主要在於計算每個像素的色彩資訊，包含了校正機制(Correction
Unit)、像素產生器(Pixel Generator)和色彩混和器(Color Blending Unit)。校
正機制接收來自 TSE 的資料，進行校正的資料處理，而像素產生器則接
收來自深度測試原件的資料，產生相對應的像素資料，最後再利用色彩混
和器將色彩做混和的動作，並把結果傳送到 Frame Buffer。
Xilinx ML507 驗證
Table.4 為 3D 管線前後兩個子系統硬體化與整合後所使用的 FPGA 資源。
Table.4. 3D 繪圖系統所占 FPGA(ML507)資源統計表
Device : vertex-5 5vfx70tff1136-1
Resource 3D Graphic Pipeline(GE+RE) %
Slice Logic Utilization
Number of Slices Register 18536 41%
Number of Slices LUTs 13622 30%
Number used as Logic 13574 30%
IO Utilization
Number of IOs 2515 -
Number of bonded IOBs 0 -
Specific Feature Utilization
Number of BUFG/BUFGCTRLs 2 6%
Number of DSP48E 11 8%
而目前我們使用的平台和硬體架構為 Xilinx ML507 開發平台，其系
統架構如圖 70。由 FPGA 中的 PowerPC processor 啟動 FPGA 中的三維繪
圖加速器，其中的幾何轉換子系統抓取記憶體中的頂點和顏色資料運算完
後，會把處理後的三角形資料直接傳至著色子系統，而著色子系統掃描產
62
的 Bitrate Saving，但對整體的 Bitrate 來說，僅只省下 4%，然而複雜
度卻因此上升近 16 倍。
目前 MPEG 標準制定小組已出現兩篇於接收端修正深度圖的演算
法：第一篇由 Tanimoto 提出，其利用合成相鄰參照視角時的合成誤差，
以 Linear Prediction 的方式，推測出虛擬視角可能的合成誤差，最後
將此預測出來的合成誤差補回虛擬視角之合成影像；第二篇由 Sung 提
出，其利用合成虛擬視角時，來自不同參照畫面的亮度值與深度值的差
值，若此差值越過某個門檻值，則判定此深度值需要被修正；其次，此方
法為每個 Connected Component 找出一個最佳的深度值偏量，使得合成誤
差可以降到最低。然而，上述方法未考慮深度值壓縮的情況，兩者皆無法
根據不同的壓縮品質進行調整，造成修改的效能嚴重受到壓縮之品質所影
響。
圖71. 原始深度圖. 圖72. 解碼後之深度圖.
圖73. Current approach applies complex coding scheme for intensity to depth,
while it only forms a small portion of the entire bit-stream.
因此，本子項針對重建後的深度圖對虛擬影像合成的影響，提出一個
單一像素之合成誤差的檢測模型。透過此模型之分析，可有效預測出每個
像素可能造成的合成誤差。利用不同參照視角(Reference Views)畫面之間
對應點關係，找出隱藏的深度資訊，並依此修正不可靠的深度像素
64
  
2
p
p R
q p p
n
I
Z Z n

 
     
p c (4)
在 MPEG FTV 的水平相機設置的限定下，位移矩陣只含水平方向之分量，
因此可將公式(4)簡化為下式：
  
2
2 2p
p x
q p p
n
g c
Z Z n

 
     
p (5)
(1)其中 2xg p 為 RI p 的水平分量。因此，假設有真實(Ground-truth)
深度資訊的情況下，計算出合成影像誤差的條件期望值：
 
  
      
   
 
2
(2) 2
2 3 4
(2) 2
2 2 3 4
2 4 6
(2) 2
2 2 3 4
2
(2) 2
2 2
| ,
| ,
1
2 3
1
9 75
1
p p q
p
p q g
q p p
p p p
g
q p p p
n n n
g
q p p p
n
g
q p
E Z Z
n
E Z Z m c
Z Z n
E n E n E n
m c
Z Z Z Z
m c
Z Z Z Z
m c
Z Z

  

           
 
         
 
         
   
p
p
p p p
p
p
p


(6)
其中   (2) 2g xm E gp p ， 2n p 為 pn 之變異數，並假設 pn 之數值呈現常
態分布  2~ 0,p nn N  p 。透過公式(6)的推導結果得知，單一像素之合成
品質係由四個因素共同影響：Depth-error Variance、 Intensity
Variation、
Expected Synthesis Distortion
0 5 10 15 20 25 30 35 40
D
ep
th
-e
rr
or
S
en
si
tiv
ity
0
50
100
150
200
250
300
350
400
450
500
mg
(2)(p)=36
mg
(2)(p)=64333.0
249.7
Zp=30, Zq=0.5Zp
Expected Synthesis Distortion
0 5 10 15 20 25 30 35 40
D
ep
th
-e
rr
or
S
en
si
tiv
ity
0
50
100
150
200
250
300
350
400
450
500
mg
(2)(p)=36
mg
(2)(p)=64
166.5
124.8
Zp=60, Zq=0.5Zp
66
(4)比較圖(e)與(a)(c) (或是圖(f)與(b)(d))，若 pq ZZ  ，其 Depth-error Sensitivity
會比 pq ZZ  來的小。由圖 75 得知，當 1 2q p p qZ Z Z Z  ，p相對於 2q 為
一個背景的點，使用背景的點覆蓋前景的點，將產生較嚴重的合成誤差；反
之，p相對於 1q 為一個前景的點，此覆蓋情形較不會出現明顯的合成誤差。
由公式(6)的
2
2
n
pZ
 p
和 2c 可知，若虛擬視角與參照視角的距離越遠，
其 Depth-error sensitivity 也會越高。
低演算複雜度之一維深度圖壓縮
本子項壓縮演算法與 MVC Intra 模式差異處主要有三：
(1)深度值預測：MVC 採用相鄰區塊的像素深度值估測目前區塊的像素深
度值；本子項在每個區塊採用眾數演算法，挑選代表該區塊之深度值，且
不再以 MSE 作為預測模式的決策條件。
(2)資料量化器：MVC 採用純量量化器(Scalar Quantizer)精簡資料輸出值的
種類數至一個較小的集合裡；本子項則以門檻值(Threshold)設計一個簡易
的量化器，將不同於眾數之像素深度值，取代為眾數深度值。
(3)資料型態：MVC 將預測誤差值(Residual)經過離散餘弦轉換(DCT)後成
為頻率域(Frequency Domain)表示之資料型態；本子項不需任何 Transform
Coding，直接在空間域(Spatial Domain)中進行幾近無損壓縮的 Residual 編
碼。
預估區塊以 16x16 為單位分割每張深度圖，並取出每個區塊深度值之
眾數代表該區塊之深度值，稱為眾數決議預測 (Mode Determination
Prediction)，各個區塊的眾數將直接經過 Entropy Coder，以無損的方式壓
縮。本子項的深度值預測方式為眾數決議(圖 76)，一般壓縮演算法採用的
是最小均方根預測該像素值。若以平均數預測深度值，雖可滿足最小
Residual 具最小 MSE，但每個深度值都將產生些許的預估誤差，造成合成
虛擬影像不可預期之合成誤差。
次之，本子項採取門檻值量化器量化區塊中所有深度值，量化方
式如下：
1, ;
.
i
i
i
M if D M TH
D
D otherwise
  

(7)
68
圖77. (a) Line-based residual segmentation; (b) removal of isolated segments.其
中每列開頭的 0 與 1 代表此列"有/沒有"Residual Signals。
Table.5. 各種 segment coding mode 的 coding rule。
Segment Coding Mode Coding Rule
0 All the segment parameters are the same.
1 Only depth values are the same.
2 Otherwise.
中介軟體定義與開發
本項目將依據多視角視訊編解碼(MVC)之需求以及各種不同的視角
內插機制，擴展目前 MHP 之 API 並提供 3-D Video/Graphics 中介軟體。
同時我們將以 C/C++提供針對 Power PC 與其他子項硬體設計所優化之
MVC 編解碼與視角合成程式庫(Libraries)。並將以 back-door Java native
interface 形式提供給所定義之 Java API 呼叫。
子項目四：嵌入式平台的 Java 處理器設計（Java Processor Design
for Embedded Systems）
本子項目的目標在於針對嵌入式多媒體的應用，設計一個全新的異質
雙核心 Java 處理器，而我們設計的考量重點包含了以下重點：
(1)完整支援 Java 的 object-oriented 的語言特性。絻大部份已發表的
Java 處理器論文，都只是針對 Java 語言的部份特性提出新架構，有很多
甚至只是以模擬的方式來分析所提出架構的效能，並沒有真的實作出一個
完整的處理器。特別針對給嵌入式應用的 Java 處理器，多半沒有實作出
dynamic class loading 的機制。我們所實作的 Java 處理器，則包含了這些
機制。
(2)對於 OS 依存度很低。很多嵌入式 Java 執行環境，都是針對某一
個作業系統（如 Linux）設計的。我們在設計子項四的 Java 執行環境時，
特別在不影響效能的前題下，把 Java 子系統包裝成一個獨立的單元。只
要現有的作業系統可以提供 interrupt service routines 的安裝，就可以和我
們的 Java 子系統整合。
70
RISC Core
Java Core
External memory
controller
IPC (mailbox)
module
system bus
Java SoC
System software
for RISC core
On-chip memory
controller
Java dynamic
resolution tables
Method area
controller
I/O
controller
interrupt
Bytecode
execution engine
DDR-DRAM
(Java heap,
cross-reference tales,
and
class runtime images)
Dynamic symbol
resolution logic
Method
area
Java
stack
CF card
(Java system &
application classes)
Fast
Java heap
圖78. 異質雙核 Java 處理器架構。
RISC Core
Boot
Initializes Java core memory
Loads Java boot class
into method area
Activates Java core
Java Core
Boot
Executes boot class
reset
User invokes an
application?
Executes an
application class
Y
Processes
service request
Shutdown
N
Receives a
service request?
N
User requests
shutdown?
Y
N
Sends shutdown signal to RISC
shutdown
Y
圖79. Java系統啓動流程。
Java 核心微架構如圖 80 所示，我們採用了一個 four-stage pipeline
architecture。其中，translate stage 會把 Java bytecode 轉換成我們定義的微指令。
由於 Java 指令是長度可變的，為了方便讀取足夠的 instruction bytes 來提供
translate stage 和 decode stage 進行指令解碼，我們設計了一個特別的 instruction
buffer 電路。
72
buf2 only 以及 translate [upper buf1 & lower buf2]。Translate stage 則將此轉換完成
的 16-bit instruction package 以及相關資訊 pass 到 Fetch stage。
圖82. Translation form.
Fetch stage
Fetch stage 的工作主要是從傳送真正要執行的指令給 decode stage，以及控
制 Translate stage 的 instruction buffer 解讀方式。從 Translate stage pass 過來的
16bits instruction package 以及相關資訊會經由判斷邏輯分析前後 instruction 各屬
於 simple、complex、operand 哪一種，再進一步判斷是否為 ordinary case。圖 83
標示了所有 ordinary case，在這種情況下只需把 operand 代換為 nop，就能繼續
pass 到 Decode stage。若有 complex instruction，則 Fetch stage 進入 complex mode。
若為 separated case 需要拆開處理。其情況如圖 84 所示，大致可分為兩種。當兩
個 Simple instruction 發生 hazard 時或 instruction package 都不為 operand 卻含有
complex instruction。
1st
Instr.
2nd
Instr.
Output instr.
combination
S S 1stInstr. + 2ndInstr.
S O 1stInstr. + nop
O S nop + 2ndInstr.
O O nop + nop.
C O
O C
complex mode
圖83. The ordinary cases.
Output instr.
combination
1st
Instr.
2nd
Instr.
Current Next
S S
S C
1stInstr. +
nop
2ndInstr. +
3rdInstr.
C S
C C
complex
mode
2ndInstr. +
3rdInstr.
圖84. The separated cases.
74
odd entries
operand #3
operand #4
...
local var #n
...
even entries odd entries
A
B
C
operand #3
...
local var #n
...
local var #n+1
even entries
Interleaving dual-port RAM
banks as 2nd-level Java stack
sp sp–2
sp sp+2
a) Parallel execution of Load-Load instructions. b) Parallel execution of ALU-Store instructions.
Interleaving dual-port RAM
banks as 2nd-level Java stack
B
C
A
1-st level
Java stack
1-st level
Java stack
local var #n+1
operand #4
圖85. Double-issue datapath 範例。
異質雙核心的 Java 處理器整體效能分析
因為我們所設計的 Java 處理器是為嵌入式系統應用而設計的，因此當我們
要評估 JavaCore系統時，主要是利用嵌入式 Java最廣為採用的 Caffeine Mark 測
試 Benchmark 來對 JavaCore 做效能上與 CVM 及 CVM-JIT 的比較，但是因為使
用 benchmark 測試跟真實 Application 的應用其實是會有些出入，所以我們藉由
分析 caffeinemark 的指令分布，可以瞭解我們所使用的 benchmark 是否夠具代表
性，我們分析的類別主要參考自(Java runtime system: characterization an
architectural implications)，分析結果如圖 86，分析類別如圖 87 所示。
Field accesses
1.48%
Local variable
accesses
35.19%
Branch
35.18%
Stack
26.67%
ALU, 1.48%
LOGIC
Field accesses
17.93%
Local variable
accesses
43.54%
Memory
accesses
10.18%
Branch
7.83%
ALU
15.38%
Stack
5.13%
LOOP
76
經過以上分析評估後我們開始對 JavaCore、CVM、及 CVM-JIT 進行測試。
因為 CVM 和 CVM-JIT 在執行時，有 data cache 和 instruction cache，而我們的
JavaCore 並沒有 data cache，因此，我們將 JavaCore 的 heap space 放在 on-chip
BRAM 上，測試結果如圖 88 所示。
377 410
906
579
10777 75 69 67
270
671
1697
772
1092
837
0
200
400
600
800
1000
1200
1400
1600
1800
Sie
ve
At
om
Lo
op
At
om
Lo
gic
At
om
M
eth
od
At
om
Str
ing
At
om
JavaCore
CVM
CVM-JIT(score)
圖88. Caffeine Mark Score for JavaCore, CVM, and CVM-JIT.
其中，Loop 測試因為有很簡單的迴圈結構，因此 CVM-JIT 可能透過最佳
化，而把反覆的計算簡化了。另外，Method 測試只是在單純的遞迴呼叫中進
行簡單的算術計算。因此 CVM-JIT 可能把它轉成簡單的循序執行。為了驗證
我們猜測 just in time compiler 的機制，會將 recursive function call 展開成 loop
執行的 Machine Code，進而使得在作 function call 時的操作上會突顯出不公平
的現象，所以我們設計了一連串根據 input 循環呼叫的程式，使得 JIT 在 compile
階段無法決定何時會結束，進而無法展開成迴圈執行的 machine code 來避開
function call 的行為，結果如圖 89 所示，用電路執行 Java method invocation 的
效能遠遠超過 CVM-JIT。
3408
2943
643
0
1000
2000
3000
4000
CVM-JIT CVM JavaCore
(ms)
圖89. Cyclic method invocation benchmarks.
78
在 dynamic class loading 上所需的時間，分析結果如圖 92 及圖 93 所示。
Run Time Image
Size (byte)
Class size (byte)
500 1000 2000 4000
1000 3766
2000 3783 6739
4000 3760 7350 13160
8000 4937 7700 14836 26518
圖92. Class loading time.
Run Time Image
Size (byte)
Class size (byte)
500 1000 2000 4000
1000 8214
2000 8782 8271
4000 14664 10631 83894
8000 36042 31013 17466 8639
圖93. Class parsing time.
當我們建立完 class vs. runtime image size 相對關係在 dynamic class loading
機制上的影響之後，我們希望可以進一步得到一般 application 的 class File 是落
在表上的那個區間內，而這資訊未來可以作為我們在制定 JavaCore內部的method
area 的大小，這邊我們分析的方式是使用我們 PC 版本的 Parser 去分析 J2ME 的
System Class File，去統計這些 class 與 Run time image 的大小來作為代表，分析
結果如圖 94。
Item
Size(byte)
Class Run time image
0 - 1000 62.3 % 86.7 %
1000 - 2000 18.4 % 8.2 %
2000 - 3000 5.1 % 3.1 %
3000 - 4000 6.1 % 1.0 %
4000 –500 2.0 % 0.0 %
5000 –6000 3.1 % 0.0 %
6000 –7000 2.0 % 0.0 %
80
四. 計畫產出論文
已發表之論文
[1] J.-C. Chan, N. T.-C. Chang, and T.-S. Chang, “ISID: In-order scan and indexed
difusion segmentation algorithm for Stereo Vision,” in Proc. of IEEE Int.
Symposium on Circuits and Systems, Seattle, U.S., 2008.
[2] T.-H. Tsai, N. Y.-C. Chang, and T.-S. Chang, “Datareuse analysis of local stereo
matching,” in Proc. of IEEE Int. Symposium on Circuits and Systems, Seattle,
U.S., 2008.
[3] L.-Y. Ku, S.-H. Wen, N. Y.-C. Chang, and T.-S. Chang, “A low-Cost real-time
command control system based on stereo-vision and hand motion,” in Proc. of
Conf. on Computer Vision, Graphics, and Image Processing, Taiwan, 2008.
[4] J.-C. Chan, N. Y.-C. Chang, Y.-C. Tseng, and T.-S. Chang, “Local belief 
aggregation for MRF-based color image segmentation,” in Proc. of Conf. on
Computer Vision, Graphics, and Image Processing, Taiwan, 2008.
[5] Y.-C. Tseng, N. Y.-C. Chang, and T.-S. Chang, “Block-based belief propagation
with in-place message updating for stereo video,”in Proc. of IEEE Asia Pacific
Conf. on Circuits and Systems, China, Macao, 2008.
[6] N. Y.-C. Chang, Y.-C. Tseng, and T.-S. Chang, “Analysis of color space and 
similarity measure impact on stereo block matching,” in Proc. of IEEE Asia
Pacific Conf. on Circuits and Systems, China, Macao, 2008.
[7] Y.-C. Tseng, N. Y.-C. Chang, and T.-S. Chang, “Low-memory cost belief
propagation architecture for disparity estimation,” in Proc. of IEEE Int.
Symposium on Circuits and Systems, Taipei, Taiwan, 2009.
[8] P.-H. Hsu, Y.-C. Tseng, and T.-S. Chang, “Low memory cost bilateral filtering 
using stripe-based sliding integral histogram,” in Proc. of IEEE Int’l Symposium 
on Circuits and Systems, Paris, France, 2010.
[9] Y.-R. Horng, Y.-C. Tseng, and T.-S. Chang, “Stereoscopic images generation 
with directional Gaussian filter,” in Proc. of IEEE Int’l Symposium on Circuits 
and Systems, Paris, France, 2010.
[10] N. Y.-C. Chang, T.-H. Tsai, B.-H. Hsu, Y.-C. Chen, and T.-S. Chang,
“Algorithm and architecture of disparity estimation with mini-census adaptive
support weight,” IEEE Trans. on Circuits and Systems for Video Technology, vol.
20, no. 6, pp. 792-805, June 2010,
[11] Y.-C. Tseng and T.-S. Chang, “Architecture design of belief propagation for 
real-time disparity estimation,” IEEE Trans. on Circuits and Systems for Video
Technology, vol. 20, no. 11, pp. 1555-1564, Nov. 2010.
82
[23] C. C. Chen, Y. W. Chen, F. Y. Yang, and W. H. Peng, "A Synthesis-Quality-Oriented
Depth Refinement Scheme for MPEG Free Viewpoint Television (FTV)," IEEE Int’l 
Symposium on Multimedia, 2009.
[24] Y. W. Chen, T. W. Wang, Y. C. Tseng, W. H. Peng, and S. Y. Lee, "A Parametric Window
Design for Overlapped Block Motion Compensation with Variable Block-size Motion
Estimates,"IEEE Int’l Workshop on Multimedia Signal Processing, 2009.
[25] Y. W. Chen, C. H. Wu, C. L. Lee, T. W. Wang and W. H. Peng, " MB Mode with Joint
Application of Template and Block Motion Compensations,"ITU-T SG16 WP3 and
ISO/IEC JTC1/SC29/WG11 2nd meeting, JCTVC-B072, Geneva, CH, July 2010.
[26] Y. W. Chen, T. W. Wang, C. H. Chan, C. L. Lee, C. H. Wu, Y. C. Tseng, W. H. Peng, C. J.
Tsai, and H. M. Hang, " Description of video coding technology proposal by NCTU ",
ISO/IEC JTC1/SC29/WG11 and ITU-T SG16 Q.6 1st meeting, JCT-VC –A123,
Dresden, DE, April 2010.
[27] T.-F. Shen and C.-J. Tsai, “Dynamic Task Partitioning for Video Decoding on
Heterogeneous Dual-Core Platforms,”Proc. of VLSI Design/CAD, Ken-Ting,
Taiwan, Aug., 2008.
[28] K.-N. Su, H.-J. Ko, and C.-J. Tsai, “Java Runtime Environment Design for
Embedded Multimedia Services,”Proc. of VLSI Design/CAD, Ken-Ting, Taiwan,
Aug., 2008.
[29] M.-J. Wu, Y.-T. Chen, and C.-J. Tsai, “Hardware-assisted Syntax Decoding
Model for Software AVC/H.264 Decoders,”Proc. of IEEE Int. Symposium on
Circuit and System, Taipei, May 2009.
[30] K.-N. Su and C.-J. Tsai,“Fast Host Service Interface Design for Embedded Java
Application Processor,”Proc. of IEEE Int. Symposium on Circuit and System,
Taipei, May 2009.
[31] C.-N. Huwang, C.-Y. Bai, K.-N. Su, and C.-J. Tsai, “Dual-Core Java RE SoC
with Embedded GUI Middleware,”Proc. of VLSI Design/CAD, Hua-Liang,
Taiwan, Aug., 2009.
[32] C.-F. Hwang, K.-N. Su, and C.-J. Tsai,“Low-Cost Class Caching Mechanism for
Java SoC,”Proc. of IEEE Int. Symposium on Circuit and System, Paris, May
2010.
已接受之論文
[1] C.-J. Tsai, T.-F. Shen, P.-C. Liao, “Dynamic Task Partition for Video Decoding
on Heterogeneous Dual-core Platforms,”ACM Transactions on Embedded
Computing Systems, Accepted Jan. 2011.
84
五. 參考文獻
[1]. M. Ziegler, “Digital stereoscopic imaging and application, a waytoward new
dimensions, the RACE I project DISTIMA,” presented at IEE Colloq.
Stereoscopic Television, London, 1992.
[2]. M. Ziegler, “Digital stereoscopic television—State of the art of the European
project DISTIMA,” in Proc. 4th Euro. Workshop on 3DTV, Rome, 1993.
[3]. A. Vetro, P. Pandit, H. Kimata, and A. Smolic, Working Draft 3.0 of Multiview
Video Coding, MPEG Document N8966, San Jose, April, 2007.
[4]. D. Tzovaras, N. Grammalidis, and M. G.Strintzis, “Object-based Coding of
Stereo Image Sequences using Joint 3-D Motion/Disparity Compensation,”
IEEE Transactions on Circuits and Systems for Video Technology, vol. 7, no. 2,
pp. 312-327, April 1997.
[5]. A. Jacobs, J. Mather, R. Winlow, D. Montgomery, G. Jones, M. Willis, M.
Tillin, L. Hill, M. Khazova, H. Stevenson, G. Bourhill, “2D/3D Switchable
Displays,”Sharp Technical Journal, No.17, p15-18, 2003.4.
[6]. Ellen de Vries, “Philips showcases 3D display technology at SID 2004,”
PhilipsResearch Press Release, May 24, 2004.
[7]. O. Tishutin and T. Striegler, “Stereoscopic 3D and iZ3D Perception,” iZ3D
Whitepaper, March 2007.
[8]. Neovisionlabs,“iFusion,”http://www.neovisionlabs.com/
[9]. http://www.iz3d.com.tw/home.html
[10]. 交通部電信總局，「數位廣播電視系統整合之研究」，2004．
[11]. ETSI TS101 192, “Digital Video Broadcasting (DVB); Specification forData
Broadcasting”, 2000.
[12]. TS 102 812, “DVB Multimedia Home Platform (MHP) Specification1.1”, 
Nov. 2001.
[13]. D. Scharistein and R. Szeliski, “A taxonomy and evaluation of dense
two-frame stereo correspondence algorithms,”Int’l Journal of Computer
Vision, vol. 47(1/2/3), pp. 7-42, 2002.
[14]. Middlebury Stereo Vision Page, Available:
http://vision.middlebury.edu/stereo/
[15]. M. Z. Brown, D. Burschka, and G. D. Hager, “Advances in computational
stereo,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 25, no.
8, pp.993-1008, August, 2003.
[16]. H. Hirschmuler, “Stereo vision in structured environments by consistent
semi-global matching,”in Proc. of IEEE Conf. on Computer Vision and
86
stereo vision processing system in a FPGA,” in Proc. of IEEE Industrial
Electronics, IECON 2006.
[30]. A. Darabiha, W. J. MacLean, and J. Rose, “Reconfigurable hardware 
implementation of a phase-corelation stereo algorithm,” Machine Vision
Application, vol. 17, no. 2, pp. 116-132, 2006.
[31]. J. Diaz, E. Ros, R. Carilo, and A. Prieto, “Real-time system for high-image
resolution disparity estimation,” IEEE Trans. on Image Processing, vol. 16, no.
1, pp.280-285, Jan. 2007.
[32]. S. Sabihuddin, and W. J. MacLean, “Maximum-likelihood stereo
correspondence using field programmable gate aray,” in Proc. of Int’l Conf.
on Computer Vision Systems(ICCV), 2007.
[33]. O. Veksler, “Stereo correspondence by dynamic programming on a tree,” in
Proc. of IEEE Computer Vision and Pattern Recognition(CVPR), 2005.
[34]. Y. Deng and X. Lin, “A fast line segment based dense stereo algorithm using
tree dynamic programming,” in Proc. of European Conference on Computer
Vision (ECCV), 2006.
[35]. C. Lei, J. Selzer, and Y. H. Yang, “Region-tree based stereo using dynamic
programming optimization,” in Proc. of IEEE Computer Vision and Pattern
Recognition (CVPR), 2006.
[36]. N. Y. C. Chang and T. S. Chang, “A scalable graph-cut engine architecture for
stereo vision,” in Proc. VLSI Design/CAD Symposium, 2007.
[37]. S. Park and H. Jeong, “VLSI architecture for MRF based stereo matching,” in
Proc. of Inter’l Symposium on Systems, Architectures, Modeling and
Simulation (SAMOS), 2007.
[38]. P. F. Felzenszwalb and D. P. Hutenlocher, “Eficient belief propagation for
early vision,” in Proc. of IEEE Computer Vision and Pattern Recognition
(CVPR), 2004.
[39]. S. Park, H. Jeong, K. Pohang, and S. Korea, "Real-time stereo vision FPGA
chip with low error rate," Proc. of Int’l Conf. on Multimedia and Ubiquitous
Engineering, pp. 751-756, 2007.
[40]. F. Tombari, S. Mattoccia, L. Di Stefano, and E. Addimanda. “Near real-time
stereo based on effective cost aggregation,” in Proc. of IEEE Int’l Conf. on
Computer Vision and Pattern Recognition, 2008.
[41]. S. Forstmann, Y. Kanou, O. Jun, S. Thuering, and A. Schmitt, "Real-Time
Stereo by using Dynamic Programming," in Proc. of Computer Vision and
Pattern Recognition Workshop on Real-Time 3D Sensor and Their Use, , 2004,
pp. 29-29, 2004.
[42]. J. Lu, G. Lafruit, and F. Catthoor, "Fast variable center-biased windowing for
88
No. 4, June 2000, pp. 576-584.
[55]. M. Levoy and P. Hanrahan,“Light Field Rendering,”Proc. SIGGRAPH, 1996.
[56]. J. J. Labresse, MicroC/OS-II: The Real-Time Kernel, CMP Book, ISBN:
1-57820-103-9, 2002.
[57]. A. J. Massa, Embedded Software Development with eCos, Prentice Hall, ISBN
0-13-035473-2, 2002.
[58]. D. Comaniciu and P. Meer, “Mean Shift: A Robust Approach Toward Feature
Space Anaylsis,”IEEE Trans. On Pattern Analysis and Machine Intelligence,
vol. 24, no. 5, May 2002.
[59]. A. Klaus, M. Sormann and K. Karner,“Segment-based Stereo Matching Using
Belief Propagation and a Self-adapting Dissimilarity Measure,”in Proc.
International Conf. of Pattern Recognition, 2006.
[60]. Q. Yang, L. Wang, R. Yang, H. Stewenius, and D. Nister, “Stereo Matching
with Color-weighted Correlation, Hierarchical Belief Propagation and
Occlusion Handling,”in Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, 2006.
[61]. http://vision.middlebury.edu/stereo/
[62]. M. Z. Brown, D. Burschka, and G. D. Hager, “Advances in Computational
Stereo,”IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 25, no.
8, pp.993-1008, August, 2003.
[63]. D. Scharistein and R. Szeliski, “A Taxonomy and Evaluation of Dense
Two-Frame Stereo Correspondence Algorithms,”International Journal of
Computer Vision, vol. 47(1/2/3), pp. 7-42, 2002.
[64]. H. Hirschmuller, “Stereo Vision in Structured Environments by Consistent
Semi-global Matching,”in Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, 2006.
[65]. M. Gerrits and P. Bekaert, “Local Stereo Matching using Segmentation-based
Outlier Rejection,”proc. Conf. on Computer and Robot Vision, 2006.
[66]. V. Kolmogorov,; R. Zabih,”Computing visual correspondence with occlusions
using graph cuts,”in Proc. Eighth IEEE International Conference on Computer
Vision, 2001, ICCV 2001, vol.2, pp.508 - 515, July 2001.
[67]. J. Sun, N. N. Zheng, H. Y. Shum,“Stereo Matching using Belief Propagation,”
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.25, no.7 ,
pp. 787-800, July 2003.
[68]. L. Lucchese and S. K. Mitra, “Color Image Segmentation: A State-of-the-art
Survey,”in Proc. Indian National Science Academy(INSA-A), vol. 67, A, New
Delhi, India, pp.207-221, Mar. 2001.
[69]. L. Shafarenko, M. Petrou, and J. Kittler, “Automatic Watershed Segmentation
90
Jun. 2002.
[83]. D. Kim et al., “An SoC With 1.3 Gtexels/s 3-D Graphics Full Pipeline for
Consumer Applications”, IEEE JSSC, vol.41, no.1, Jan. 2006.
[84]. M.Deering et al., “The triangle processor and normal vector shader: A VLSI
system for high-performance graphics,”in Proc. SIGGRAPH, pp21-30, 1998.
[85]. David Blythe, Microsoft Corporation, “The Direct3D 10 System,” 2006.
[86]. H. Gouraud, “Continuous Shading of Curved Surfaces,” Comm. ACM, vol. 18, 
1971.
[87]. Bui Tuong Phong, “Ilumination for computer generated pictures,” Comm. 
ACM, vol.18, Jun. 1975.
[88]. A.M. Abbas, L. Szirmay-Kalos, and T. Horvath, “Hardware Implementation of 
Phong Shading Using Spherical Interpolation,” Periodica Polytechnica, vol.44,
2000.
[89]. A. Hast, T. Barera, and E. Bengtsson, “Faster Shading by Equal Angle 
Interpolation of Vectors,” IEEE Trans. on Visualization and Comp. Graphics, 
vol.10, no.2, Mar. 2004.
[90]. J.N. Mitchel Jr., “Computer Multiplication and Division Using Binary
Logarithms,” IRE Trans. Electronic Computers, vol.11, pp.512-517, Aug.
1962.
[91]. H. Kim, B.G. Nam, J.H Sohn and H.J. Yoo, “A 231MHz, 2.18mW 32-bit
Logarithmic Arithmetic Unit for Fixed-Point 3D Graphics System,” IEEE 
JSSC, vol.41, no.11, Nov. 2006.
[92]. M. Combet, H. Zonneveld, and L. Verbeek, “Computation of the Base Two 
Logarithm of Binary Numbers,” IEEE trans. Electronic Computers, vol. 14, 
Dec. 1965.
[93]. K.H. Abed and R.E. Siferd, “CMOS VLSI Implementation of a Low-Power
Logarithmic Converter,” IEEE Trans. on Computers, vol.52, no.11, Sep. 2003.
[94]. K.H. Abed and R.E. Siferd, “CMOS VLSI Implementation of a Low-Power
Antilogarithmic Converter,” IEEE Trans. on Computers, vol.52, no.11, Sep. 
2003.
[95]. Thomas A. Brubaker and John C. Becker, “Multiplication Using Logarithms
Implemented with Read-Only Memory,” IEEE Trans. on Computers, vol.24 
no.8, Aug. 1975.
[96]. F. Bensaali, A. Amira and A. Bouridane, “Accelerating matrix product on 
reconfigurable hardware for image processing applications,” IEE 
Proc.-Circuits Devices Syst., vol. 152, no. 3, pp. 236-246, Jun. 2005.
[97]. J.-H. Sohn, J.-H. Woo, M.-W. Lee, H.-J. Kim, R. Woo, and H.-J. Yoo, “A 155-mW
50-Mvertices/s Graphics Processor With Fixed-Point Programmable Vertex Shader for
92
[115]. You-Ming Tsao, Chi-Ling Wu, Shao-Yi Chien, and Liang-Gee Chen,
“Adaptive Tile Depth Filter for the Depth Buffer Bandwidth Minimization in
the Low Power Graphics Systems,” ISCAS 2006, pp. 5023-5026, May 2006.
[116]. Jonathan Corbet et al, “Linux Device Drivers, 3rd,”.
[117]. Keronos Group, “OpenGL ES 1.1.10 Specification,”2007.
[118]. OpenSceneGraph, http://www.openscenegraph.org/projects/osg, 2007.
[119]. Sun Microsystems, “The Java 3D API Specification Version 1.2,”Apr. 2000.
[120]. M. Tanimoto,“Preliminary FTV Model and Requirements”, MPEG Document
N9168, Geneva, July, 2007.
[121]. A. Vetro, P. Pandit, H. Kimata, A. Smolic, “Joint Multiview Video Model 
(JMVM) 5.0”, ISO/IEC JTC1/SC29/WG11 and ITU-T SG16 Q.6, JVT-X207,
2007.
[122]. A. Vetro, P. Pandit, H. Kimata, A. Smolic, “Joint Draft 4.0 on Multiview Video
Coding”, ISO/IEC JTC1/SC29/WG11 and ITU-T SG16 Q.6, JVT-X209.doc,
2007.
[123]. Ye-Kui Wang, Ying Chen, and Miska M. Hannuksela,” Time-first coding for
multi-view video coding,” ISO/IEC JTC1/SC29/WG11 and ITU-T SG16 Q.6,
JVT-U104.doc, 2006.
[124]. IFA: Report on IFA –2001 Consumer Electronics Show to the Members of
Digital Broadcasting Australia by Tim O´Keefe, Director of Digital Business
Consulting Pty Limited, Sept. 2001.
[125]. http://www.cns.net.tw/company_info.php
[126]. J. Oh and R. Park, ``Reconstruction of Intermediate Views from Stereoscopic
Images Using Disparity Vectors Estimated by the Geometrical Constraint,''
IEEE Trans. on Circuits Syst. for Video Technol., no. 5, 2006.
[127]. M. S. J. McVeigh and A. Jordan, ``Intermediate View Synthesis Considering
Occluded and Ambiguously Referenced Image Regions,'' Signal
Processing-Image Communications, pp. 21--28, 1996.
[128]. G. Sharma, A. Kumar, and S. Kamal, ``Novel View Synthesis Using a
Translating Camera,'' Pattern Recognition Letters, pp. 483-492, 2005.
[129]. H. Bao, L. Chen, and J. Ying, ``Non-linear View Interpolation,'' Journal OF
Visualization and Cmputer Animation, pp. 233-241, 1999.
[130]. R. Wang and Y. Wang, ``Multiview Video Sequence Analysis,
Compression,and Virtual Viewpoint Synthesis,'' IEEE Trans. on Circuits Syst.
for Video Technol., no. 3, 2000.
[131]. M. Tanimoto, “Overview of Free Viewpoint Television,”Signal Processing: 
Image Communication, vol.21, no.6, 2006, pp.454-461.
[132]. Fujii, Toshiaki; Kimoto, Tadahiko; Tanimoto, Masayuki, "Ray space
94
Realization of the JavaTM Virtual Machine. In Proceedings of the Fourth
International Symposium on Object-Oriented Real-Time Distributed
Computing, page 53. IEEE Computer Society, 2001.
[148]. PTSC. IGNITE Processor Brochure, Rev 1.0. Available at http://www.ptsc.com.
[149]. R. Zulauf. Entwurf eines Java-Mikrocontrollers und prototypische Implementierung
auf einem FPGA.Master’s thesis, University of Karlsruhe, 2000.
[150]. S.A. Ito, L. Carro, and R.P. Jacobi. Making Java Work for Microcontroller
Applications. IEEE Design & Test of Computers, 18(5):100–110, 2001.
[151]. Ramesh Radhakrishnan, Deependra Talla and Lizy Kurian John,“Alowing for ILP in 
an Embedded Java Processor,”ACM SIGARCH Computer Architecture News, pp.
294-305, 2000.
[152]. Zhilei Chai, Wenke Zhao, Wenbo Xu. System On Chip Design And Software
Supports (SODSS): Real-Time Java Processor Optimized for RTSJ, ACM
Press. March 2007
[153]. R. Radhakrishnan, Microarchitectural Techniques to Enable Efficient Java
Execution, PhD thesis, University of Texas at Austin, 2000.
[154]. C. J. Glossner. The DEFLT-JAVA Engine, Ph.D. thesis, Delft University of
Technology, 2001.
 2 
 
圖二、ISCAS 大會邀請主持 Session 之電子信函。 
 
二、與會心得 
   在大會之Keynote talk方面，個人聆聽大師Prof. Giovanni De Micheli (at EPFL Lauzanne)
之演講，主題為: Nanosystems: devices, circuits, architectures and applications。參與聆聽人
 4 
 
圖四、作者提出 Pipeline 架構圖 [2] 
 
表一、文獻比較表 [2] 
 
 
三、考察參觀活動(無是項活動者略) 
無。 
 
四、建議 
ISCAS 是國內這個領域重量級學者與年輕學者每年均會前往參與之會議，在此會議上，
可以與國外大師面談並可以參與一些重要的 Technical Committee，但參與 Technical 
Committee 需要有人引見與推薦，否則會不得其門而入，推薦後也必頇經過投票通過，
才能成為該 TC 核心成員，此次個人就是經由 Prof. Sobelman (at University of Minnesota)
推薦才有此機會。另外，低能量/低耗能/整合多功能之多媒體與通訊設計絕對是未來電子
產品呈現與溝通的設計重點，另一方面也要符合標準，後者將是產品化的門檻。歐洲與
中國大陸在多媒體與通訊方面的進展速度相當快且經費相當充裕且標準通常以他們為
主，所以我們更應該將經費投注在重點研究上。總結來說，該次大會所接受之論文絕大
部分為高水準之多媒體與通訊與 SOC 之論文研究。 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/01/28
國科會補助計畫
計畫名稱: 支援3-D立體視訊的數位電視多媒體平台設計(3/3)
計畫主持人: 蔡淳仁
計畫編號: 98-2220-E-009-012- 學門領域: 晶片科技計畫--目標導向型研究
計畫
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
目前本計劃相關人員積極參與國際標準組織 ITU-T VCEG 及 ISO/IEC MPEG，未
來有機會將本子項之技術推展到標準組織當中。另外，本計畫參與學生也以本
計畫開發之部份成果參加民國 99 年教育部主辦之嵌入式系統設計競賽獲得佳
作． 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
