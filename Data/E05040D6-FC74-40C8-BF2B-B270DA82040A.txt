and those without using network coding. We observe 
that the network coding scheme holds the best 
performance for all cases we had simulated. The trade-
offs between the network protection schemes with and 
without using network coding are also identified in 
this work.  
In the second part of the research, we focus on 
designing a new algorithm for load-balanced fast local 
protection in IP networks. In this research, we 
propose a load-balanced fast local protection scheme 
called Non-Weighted Interface Specific Routing (NISR) 
for determining the working and backup routing tables 
of IP routers. We jointly consider protection 
switching time, network survivability, and traffic 
load distribution together in the proposed scheme. 
Through numerical experiments, we delineate that the 
proposed scheme achieves a sub-optimal solution, which 
is better for its high survivability and load 
balancing at the expense of slightly raising the 
average path hop count. 
In the final part of this project, we address on 
interface specific fast failure rerouting for load 
balanced IP networks. In this work, we take the 
concept of interface specific forwarding (ISF) to 
provide more flexibility in determining load balanced 
traffic rerouting. This problem is formulated as an 
Integer Linear Programming (ILP) problem, in which 
network survivability and traffic load distribution 
are jointly considered and the traffic load on the 
most congested link is to be minimized. The numerical 
results delineate that the proposed scheme achieves 
high survivability, load balancing and lesser 
bandwidth consumption at the expense of slightly 
raising the average path hop count. 
 
protection in IP networks. As a failure occurs, the affected traffic is quickly rerouted to backup paths for a 
network performing a fast protection scheme. Such a prompt reaction is aimed to reduce the damages 
caused by a failure. However, in some cases, the rerouted traffic may cause congestion along the backup 
paths which would lead to more packet losses than purely discarded affected flows. In this research, we 
propose a load-balanced fast local protection scheme called Non-Weighted Interface Specific Routing 
(NISR) for determining the working and backup routing tables of IP routers. We jointly consider protection 
switching time, network survivability, and traffic load distribution together in the proposed scheme. In 
NISR, once a failure occurs, only the nodes adjacent to a failure divert affected traffic to backup paths. This 
local reaction process guarantees fast protection switching and reduces failure recovery time. Unlike the 
conventional IP routing, our approach relaxes the shortest path routing in computing working and backup 
routing tables. Most importantly, each interface in a router has its own routing tables. Combining the 
interface specific routing with the shortest path relaxation provides greater routing flexibility to enhance 
network survivability and load balancing. We formulate this as a mixed integer programming problem in 
which the traffic load on the most congested link is to be minimized. Since this problem is intractable by its 
NP-hard nature, we further decompose it into several sub-problems which are solved optimally and their 
solutions combined to provide a solution to the original problem. We perform experiments on some 
benchmark networks and compare the proposed scheme to several well-known schemes (including LFA, 
ECMP, OSPF, and NLB) on survivability ratio, link load distribution, and average path length for both 
normal and failure states. Through numerical results, we delineate that the proposed scheme achieves a sub-
optimal solution, which is better for its high survivability and load balancing at the expense of slightly 
raising the average path hop count. 
 
In the final part of this project, we address on interface specific fast failure rerouting for load balanced IP 
networks. In this work, we take the concept of interface specific forwarding (ISF) to provide more 
flexibility in determining load balanced traffic rerouting. This problem is formulated as an Integer Linear 
Programming (ILP) problem, in which network survivability and traffic load distribution are jointly 
considered and the traffic load on the most congested link is to be minimized. Since this is an NP-hard 
problem, we further decompose it into several sub-problems which are solved optimally and their solutions 
are combined to provide an approximate solution to the ILP problem. The numerical results delineate that 
the proposed scheme achieves high survivability, load balancing and lesser bandwidth consumption at the 
expense of slightly raising the average path hop count. 
 
 
 
關鍵詞：高存活性網路、網際網路快速重新繞行、負載平衡、網路最佳化。 
Key Words:  Survivable Networks, IP fast reroute, Optimal routing, Network optimization. 
any single link failure and single node failure. These two 
schemes take advantage of network coding to reduce the total 
bandwidth consumption, thereby lessening total cost 
consumption. The remaining two schemes are tree-based 
protection schemes that can prevent any single link failure. 
2.1 Network Coding for Single Link Failure Protection (NCL) 
According to [9], a networking coding problem is solvable if 
the Min-Cut Max-Flow bound is satisfied for all multicast 
source-receiver (SR) connections. To explain this, we give a 
multicast session in Figure 2(a) where each link has one unit 
bandwidth (i.e., BW=1). We assume that each receiver node 
needs to receive two programs (i.e., the Min-Cut Max-Flow 
bound for all SR connections ( = {(S,R1),(S,R2)}) is 2). After 
link l fails, the Max-Flow for (S,R1) is 2 and for (S,R2) is also 
2. All SR connections are still satisfying the Min-Cut Max-
Flow bound (i.e., Max-Flow (S,R1) = 2  2 and Max-Flow 
(S,R2) = 2  2). Hence, the network coding problem has a 
solution for this link l failure case in Figure 2(a). Through this 
concept, we propose a combinatorial optimization problem to 
determine routing and provisioned bandwidth with minimizing 
network cost at the same time network coding exists for any 
single link/node failure. The detailed formulation is shown in 
the next section. 
2.2 Network Coding for Node Failure Protection (NCN)  
By graph transformation, we can apply the link protection 
technique shown in the previous subsection to obtain the node 
failure protection. We depict a graph transformation example 
in Figure 3. For simplicity, only one node is transformed in the 
example. First we replace the node v with two artificial nodes 
(vin, vout), one for input and the other for output. An artificial 
link e is used to connect these two artificial nodes. All 
incoming and outgoing links are then connected to the 
artificial input and output node, respectively. By regarding a 
node failure as its artificial link e failure, the node failure can 
be viewed exactly as link failure. Due to the space limitation, 
we omit the required protocol in the network to inform the 
node failure event and the signaling for activating the network-
coding-based protection. 
2.3 Bundle Tree-Based Link Protection Scheme (BTL) 
This scheme is similar to the link restoration scheme for 
multicast communication [10]. Every working link in the 
multicast tree is constructed with a backup route to it. 
Different from the work in [10], the construction of the 
working tree and backup path are jointly determined to further 
reduce total bandwidth consumption. The bundle tree-based 
Link protection scheme (BTL) is depicted as shown in Figure 
2(b). In BTL, only one multicast tree is used to carry all video 
programs. Backup paths are reserved to protect any single link 
failure while the total cost of provisioned bandwidth is 
minimized. 
2.4 Individual Tree-Based Link Protection Scheme (ITL) 
The second tree-based scheme is called the Individual tree-
based link protection scheme (ITL), which is shown in Figure 
2(c). In ITL, each video program is delivered by an individual 
multicast tree. Therefore, a network operator has to determine 
N routing trees to carry N multicast video streams individually 
and pre-determines backup paths to protect any potential single 
link failure. Models for the two tree-based schemes are also 
presented in the next section. 
 
 
 
 
PI.3 Optimization Models 
In this section, we formulate the NCL, BTL and ITL 
problems as combinatorial optimization problems and 
determine the proposed routes and provisioned bandwidth of a 
multicast network to protect any single link failure. These 
formulations mainly focus on the minimization of total 
network costs, in which the constraints are required to satisfy 
the demand requirement, 100% survivability constraint and 
physical capacity limitation. The output of the problems 
includes the routing paths and required bandwidth on each link. 
A multicast network is modeled as a graph G(N,L), where N 
denotes the set of network nodes, and L represents the set of 
physical links. The link capacity Cl is the available bandwidth 
on link l. We assume that each video program consumes the 
same bandwidth.  
Before describing the formulations, we first list the notations 
that are common for all models.  
Common Notations: 
 l  : cost for one unit bandwidth on link l (i.e. bandwidth 
for one video program); 
 R : set of receiver nodes; 
 k : the number of video programs in the system; 
 d : bandwidth requirement to support one video program;   
program 1 program 2
Max-Flow (S, R1) = 2 ≧ 2 Max-Flow (S, R2) = 2 ≧ 2 
S
R1
R2
Coding point
Video 
Server
BW=1
BW=1
BW=1
BW=1
BW=1
BW=1
BW=1
BW=1
BW=1
BW=1
X
link l
Receiver 1
Receiver 2
S
R1
R3
Video 
Server
Program 1
Receiver
Node 3
R2
Receiver
Node 2
Receiver
Node 1
X
X
Backup Path
Program 2
Backup Path
Each video program is delivered 
by an individual multicast tree. 
R1
R2
Video 
Server
Backup Path
X
Receiver 
Node 1
Receiver
Node 3
R3
Receiver
Node 2
A multicast tree is used to carry 
all k video programs. Backup 
path is reserved to protect any 
single link failure.
S
(a) Network coding-based link 
protection scheme (NCL) 
(b) Bundle tree-based link 
protection scheme (BTL) 
(c) Individual tree-based link protection scheme (ITL)
Figure 2. Protection schemes with/without network 
coding 
v
v
evin vout
Figure 3. Illustrations of graph transformation
decision variable lt  which is 1 if link l is used by a backup 
path. Finally, Constraint (7) is the capacity constraint. 
3.3 Individual Multicast Tree-based Link Protection Model  
The notations used in ITL are shown as follows: 
Decision variables: 
 ul : the number of video programs on link l assigned for 
working paths; 
 
lu  : the number of video programs on link l assigned for 
backup paths; 
 v
rly  : =1, if link l is used to deliver video program v to 
receiver node r; =0, otherwise; 
 v
lz  : =1, if link l is used to deliver video program v; =0, 
otherwise; 
Problem (ITL): 
 


Ll
lll uu )(min   
subject to: 



Ll
nr
v
rl
Ll
v
rl
in
n
out
n
yy   NnVvRr  ,, (1)
v
l
v
rl zy   LlVvRr  ,, (2)



Ll
v
l
in
n
z 1 VvNn  ,  (3)
l
Vv
v
l uz 

 Ll  (4)
lnl
Le
le
Le
le uxx
in
n
out
n


 NnLl  ,  (5)
0eex  Le  (6)
ele ux   LeLl  ,  (7)
lll Cuud  )(  Ll  (8)
1or  0vrly  LlVvRr  ,, (9)
1or  0vlz  LlVv  ,  (10)
integerlu  Ll  (11)
integerlu  Ll  (12)
This model is similar to BTL except that each video 
program is delivered on an independent tree. Therefore, the 
decision variable yrl in BTL is replaced with vrly  here in this 
model. Constraint (1) is the routing constraint. It enforces flow 
conservation on each node for each program. Constraint (2) 
and Constraint (3) jointly determine decision variable vlz  
which is 1 if link l is used for delivering video program v. The 
bandwidth assigned to the working link l, ul , is determined in 
Constraint (4). Constraint (5) is used to determine the 
bandwidth assigned to the backup path. Constraint (6) requires 
that the working and backup paths must be link disjointed. 
Total backup bandwidth required on link e is then determined 
in Constraint (7). Finally, the capacity constraint is described 
in Constraint (8). 
 
PI.4 Experimental Results 
 We have used the optimization models to carry out a 
performance study on Bundle Tree (BTL), Individual Tree 
(ITL), and Network Coding (NCL) approaches, and drawn 
comparisons via experiments over some randomly generated 
networks. The number of nodes in each randomly generated 
network is fixed to 20. Network links are being randomly 
determined to obtain a two-edge connected network. For 
simplicity, we set link cost coefficient αl to be one for each 
link. The available capacity for each link is 100. In this work, 
we assume each video program consumes unit capacity. In 
these experiments, server and receiver nodes are randomly 
selected to provide 30 video programs in each multicast 
connection. The models are solved using CPLEX on a PC 
running Windows XP with a 4 GHz CPU. Each point being 
plotted in the following figures is an average over 90 results. 
Since we set link cost coefficient αl to be the same in these 
simulations, the total cost is equivalent to total bandwidth 
usage and the results are shown in Figure 4(a). It is clear that 
the total bandwidth consumption decreases for each scheme as 
the number of network links increases. For the number of links 
ranging from 50~80, we observe that NCL holds the best 
performance; BTL needs the most bandwidth; and ITL’s 
performance is always in between NCL and BTL. We further 
observe that the performance of ITL strongly depends on the 
network degree. As the number of links is small (50 in our 
experiments), ITL is very similar to BTL; however, as the 
number of links goes up, the results move toward NCL. 
PART II:  
Non-Weighted Interface Specific Routing for 
Load-Balanced Fast Local Protection in IP 
Networks 
Abstract—As a failure occurs, the affected traffic is quickly 
rerouted to backup paths for a network performing a fast 
protection scheme. Such a prompt reaction is aimed to reduce 
the damages caused by a failure. However, in some cases, the 
rerouted traffic may cause congestion along the backup paths 
which would lead to more packet losses than purely discarded 
affected flows. In this research, we propose a load-balanced 
fast local protection scheme called Non-Weighted Interface 
Specific Routing (NISR) for determining the working and 
backup routing tables of IP routers. We jointly consider 
protection switching time, network survivability, and traffic 
load distribution together in the proposed scheme. In NISR, 
once a failure occurs, only the nodes adjacent to a failure divert 
affected traffic to backup paths. This local reaction process 
guarantees fast protection switching and reduces failure 
recovery time. Unlike the conventional IP routing, our 
approach relaxes the shortest path routing in computing 
working and backup routing tables. Most importantly, each 
interface in a router has its own routing tables. Combining the 
interface specific routing with the shortest path relaxation 
provides greater routing flexibility to enhance network 
survivability and load balancing. We formulate this as a mixed 
integer programming problem in which the traffic load on the 
most congested link is to be minimized. Since this problem is 
intractable by its NP-hard nature, we further decompose it into 
several sub-problems which are solved optimally and their 
solutions combined to provide a solution to the original 
problem. We perform experiments on some benchmark 
networks and compare the proposed scheme to several well-
known schemes (including LFA, ECMP, OSPF, and NLB) on 
survivability ratio, link load distribution, and average path 
length for both normal and failure states. Through numerical 
results, we delineate that the proposed scheme achieves a sub-
optimal solution, which is better for its high survivability and 
load balancing at the expense of slightly raising the average 
path hop count. 
 
PII.1 INTRODUCTION 
The long packet delay and service interruption are 
unacceptable for QoS sensitive applications in IP networks. 
When a network failure occurs, the total recovery time for 
current link state routing protocols such as OSPF [1] may take 
several seconds to re-converge [2]. To mitigate the impact of 
failures, many IP fast local recovery schemes have been 
proposed in the literature. The main design principle is to pre-
compute backup routes to bypass failure components and 
guarantee no transient loops during failure recovery. We 
classify those schemes into three categories: loop-free alternate 
(LFA) based schemes [3-5], tunneling-based schemes [6-7], 
and backup routing table (BRT) based schemes [8-10]. 
In LFA-based schemes, routers adjacent to a failure link 
forward the affected packets to neighbor nodes to bypass the 
failed link or node. Routers suppress flooding topology change 
information during the recovery duration to avoid frequent 
route flipping. The selections of new next hop neighbors have 
to ensure satisfying loop-free properties. ECMP [3], LFA [4], 
and U-Turns [5] belong to these kinds of schemes. However, 
these approaches may have lower survivability if the routers 
have no alternate loop-free neighbors to repair the failure. 
In tunnel-based schemes, a tunnel is setup between the node 
that detects a failure and an intermediate node using the IP-in-
IP technique. Once the intermediate router receives these 
encapsulated packets, it decapsulates and forwards them 
according to their original destinations via normal routes. This 
intermediate router must be selected carefully to avoid routing 
loops. Tunnels [6] and Not-via addresses [7] adopt a design 
concept like this. To encapsulate and decapsulate packets leads 
to an extra burden on routers in the network. 
In BRT-based schemes, each router pre-computes backup 
routing tables (or backup configurations) before any failure 
occurs. In [8], an IP network is preplanned with multiple 
configurations and that configuration corresponds to a 
topology. Routing of a packet is determined jointly by its 
destination address and configuration mark. Thus packets can 
be rerouted to their backup paths by only changing the 
configuration marks on them. In [9-10], a protection procedure 
is triggered when a packet comes into a router through a port 
that is usually not used for that packet. However, load 
balancing was not considered, and the rerouted traffic would 
cause severe congestion on some heavily loaded links.  
To the best of our knowledge, [11] is the first one to 
consider load balancing in IP fast failure recovery. Once a 
failure happens, the routers adjacent to a non-working device 
distribute the affected traffic over multiple backup paths 
through solving a Linear Programming (LP) problem 
incrementally. The rerouted traffic is distinguished from 
normal traffic by inserting a special mark on it. The diverted 
(1,0)
(5,5)
(1,5)
2
3
1
5
4
D
D
D
(5,2
)(1,1
5)
(1,10) (1,
30)
(5,5)
Dest NH
D 4
D D(1,25)
   
(a) An example before adding      (b) Shortest Path based Routing 
      traffic of od-pairs 2-D and 3-D              (OSPF routing) 
(c)Non-weighted load balanced   (d) Non-weighted interface specific 
     routing (NLB routing [12])           routing (NISR) 
 
Fig. 1. Comparisons of different routing schemes  
In this study, we formulate the NISR problem as a mixed 
integer programming problem in which the traffic load on the 
most congested link is to be minimized. Since this problem is 
NP-hard, we further decompose it into several sub-problems. 
Each sub-problem is solved optimally and the results for these 
are combined to provide a solution to the original problem. 
 
PII.2 PROBLEM FORMULATION 
In order to achieve interface specific routing, the given 
network topology is first transformed into an extended graph. 
For each node with m input and n output, it is replaced by a 
subgraph with m artificial vertices connecting to input links, 
and another n artificial vertices connecting to n output links. 
Thus each artificial vertex is corresponding to an input 
interface or output interface. Fig. 3 depicts an example, where 
m=n=2. For simplicity, only node 1 is shown in its extension 
form. Besides, there are additional mn artificial edges 
connecting the m+n artificial vertices (i.e., vertices i1, i2, i3, 
and i4 in Fig. 3). These artificial edges describe possible 
routing combinations inside a node. In order to facilitate local 
traffic add and drop, another two artificial vertices, vertices a 
and d, are included. Vertex a and vertex d are the local add 
node and local drop node in this example.  
We formulate the NISR problem as a mixed integer linear 
programming problem based on the transformed graph. Given 
network topology G(N,L) and the demand volume for all 
origin-destination (od) pairs, the problem computes the 
working and backup routing tables of each node for normal 
state and failure states. The objective is to minimize the 
weighted sum of the maximum load on the most congested link. 
The notations used in the formulation are shown as follows.  
Given input constant values: 
N: set of nodes in the network; 
L: set of links in the network; 
in
nV : set of artificial vertices representing input interfaces in 
the node n; 
W: set of od-pairs; 
Pw: set of candidate paths for od-pair w; 
S: set of network states; Here we denote s0 as the normal 
(non-failure) state and si as the i-th failure state; 
En: set of artificial edges in the node n; 
E: set of artificial edges in the transformed graph; 

Nn
nEE

 ; 
v
nE : set of artificial edges connecting to vertex v in node n;
Es: set of artificial edges which cannot be used in the state 
s; 
Ns: set of nodes which are affected by failure state s. We 
call node i is an affected node in state s if node i 
cannot deliver packets via its normal next hop in state 
s; 
sN : set of nodes which are unaffected in state s. sN = N 
\ sN ; 
ms: a given weight for state s; 
tw: demand volume for od-pair w; 
Wk set of od-pairs whose destination is k. W={W1, W2,.., 
Wk,..,W|N|}, |N| is the amount of nodes in the network; 
δpe: =1, if path p uses artificial edge e; = 0, otherwise; 
pl : =1, if path p uses link l; = 0, otherwise; 
To help readers understand the notations, an illustration of 
sets En, vnE , 
in
nV , Ns and Es is shown in Fig. 4.  
Decision variables: 
d
esx : =1, if artificial edge e is used to transmit packets with destination d in state s; = 0, otherwise. Routing tables 
are derived from this decision variable; 
psy : =1, if path p is used to transport packets at state s; =0, 
otherwise; 
su : the maximum link load in state s; 
i
lsz : the accumulated total used capacity before solving sub-problem IPsub i ; 
The problem is formulated as follows. 
Problem (IP): 

Ss
ssummin  
subject to: 
1
w
ps
p P
y

  SsWw  ,  (1) 
1
v
n
d
es
e E
x

         NdSsNnVv inn  ,,,  (2) 
0desx  NdSsEe s  ,,  (3) 
d
es
Pp
peps xy
w


  NdWwSsEe d  ,,,  (4) 
d
es
d
es xx 0  NdSsNnEe sn  ,,,  (5) 
1or  0psy  SsWwPp w  ,,  (6) 
1or  0desx  NdSsEe  ,,  (7) 
w
ps pl w s
w W p P
y t u
 
   SsLl  ,  (8) 
The objective function is to minimize the weighted sum of 
the most loaded link’s flow amount in each state. The weight 
of each state can be designated depending on the operator’s 
engineering purposes. If state k is considered to be the most 
important state, mk is assigned a very large value to emphasize 
its importance. 
 Constraint (1) is the routing constraint to route one path for 
each od-pair under each state. Constraint (2) requires that only 
one artificial edge can be used for every input interface of each 
node. Constraint (3) limits desx = 0 if artificial edge e belongs to 
Es, which means edge e cannot be used in state s. Constraint (4) 
states that an artificial edge e can be used to carry flows for od-
the input interfaces and the first row represents the destination 
nodes. Each entry presents the determined output interface. For 
example, based on the working routing table (Fig. 6(c)), 
packets with destination 2 coming from interface i4 will be 
forwarded to interface i3. In the case of link (1,2) failing, as 
Fig. 6(d) indicates, interface i4 will result in using interface i2 
to divert packets with destination 2. 
PII.4 EXPERIMENTAL RESULTS 
We perform the proposed Greedy Algorithm of Sec. III on 
COST239, NSF, and GTE networks shown in Fig. 7. In each 
network, two adjacent nodes are connected by two opposite 
directional links. The average node degrees of NSF, GTE, and 
COST239 are 3, 4.166, and 4.727 respectively. The weight of 
normal state 
0s
u is 10 and each failure state’s weight 
is
u  is 1 
in our experiments. We assume the traffic demand between any 
two nodes is 10 Mbps. We consider a single link failure 
scenario that is the most often encountered case [13]. We 
compare some well-known existing approaches with proposed 
Greedy Algorithm to observe three performance metrics: 
network survivability, load distribution, and average path 
length. 
A. Network Survivability 
First, we examine the most important performance index- 
network survivability. We perform ECMP [3], LFA [4], LFA-
SA, NLB [12], and NISR (i.e., the proposed Greedy Algorithm) 
and made performance comparisons among them. The 
computation of survivability is defined as the total number of 
successfully rerouted routes divided by the total number of 
affected routes. A route here is regarded as an IP packet stream 
for od-pair. For LFA, we randomly set a link weight to be an 
integer in the range [1,100]. For the LFA-SA scheme, we apply 
a simulated annealing algorithm to tune link weight until the 
highest survivability is reached. For ECMP, each link weight is 
set to be 1 to increase the opportunity of multiple equal cost 
paths between router pairs.   
As shown in Fig. 8, NISR and NLB reach the highest 100% 
survivability. ECMP has the lowest survivability. LFA-SA 
strongly depends on the network topology. We discover that a 
network with a lower average degree would reduce the chance 
for ECMP and LFA to find loop-free alternate paths for traffic 
rerouting in failure states. 
B. Link Load in Normal and Failure States 
In the second set of experiments, we compare NISR, NLB, 
and OSPF to examine the link load distribution. We observe 
the performance by three kinds of statistics in the normal state 
and failure states: the carried flow on the most congested link, 
the average link load, and the variance of link load. The results 
are shown in Fig. 9, where “-n” and “-f” in the x-axis denotes 
the normal state and the failure states respectively. 
Examination of Fig. 9(a) for performance on most congested 
link, we observe that NISR outperforms NLB in all cases. In 
particular, for the NSF network, NISR can reduce the load on 
the most loaded link 10% and 10.34% more than NLB for 
network in normal and failure state. The main reason is that 
NISR uses the interface specific routing to enhance the 
flexibility of routing. Such that NISR can achieve low link 
loading even though the mean degree of the NSF network is 
low. 
The experimental results for the average link load are shown 
in Fig. 9(b). We discover that NISR has the highest values. 
That is because, in order to achieve our objective function (i.e., 
lower maximum link load), NISR needs to reroute affected 
traffic flows to longer paths. The more detailed comparison of 
path length is shown in next subsection. Longer rerouted path 
would imply larger average link load.  
The variance of the link load is shown in Fig. 9(c). NISR 
receives the lowest variance in COST239 and GTE networks. 
Only in NSF, that is the smallest degree network, OSPF has 
better performance. 
C. Working / Backup Path Length 
In the final set of experiments, we perform OSPF, NLB, and 
NISR to evaluate the average path hop count. The average path 
hop count is observed for each network in normal state and 
failure states. The computation of the average path hop count is 
defined as the sum of hop counts of overall paths divided by the 
total number of paths. Note that we set link weight to be 1 for 
each link in OSPF such that all paths have minimum hop count.  
The results are presented in Fig. 10. Since OSPF uses a 
shortest path for each od-pair, it reaches the smallest value.  
The length gap between OSPF and NISR is within one hop in 
all states of the three benchmark networks. NISR has a longer 
average path length than NLB because it uses a more flexible 
routing scheme to offer working and backup paths. The results 
indicate that the proposed NISR scheme would not incur long 
working and backup paths even though the load balance 
constraints are considered. 
PII.5 CONCLUSION OF RESEARCH PART II 
Fig. 7. Benchmark networks for performance evaluation
COST239 GTE NSF0
0.2
0.4
0.6
0.8
1
Topology
Su
rv
iv
ab
ili
ty
 
 
ECMP
LFA
LFA−SA
NLB
NISR
 
Fig. 8. Network survivability in the benchmark networks 
PART III:  
Interface Specific Fast Failure Rerouting 
for Load Balanced IP Networks 
 
Abstract—As a failure occurs, the affected traffic is quickly 
switched to backup paths for a network performing a fast IP 
rerouting. However, the rerouted traffic may cause congestion 
along the backup paths that would result in more packet losses 
than purely discarded the affected flows. In this work, we take 
the concept of interface specific forwarding (ISF) to provide 
more flexibility in determining load balanced traffic rerouting. 
This problem is formulated as an Integer Linear Programming 
(ILP) problem, in which network survivability and traffic load 
distribution are jointly considered and the traffic load on the 
most congested link is to be minimized. Since this is an NP-
hard problem, we further decompose it into several sub-
problems which are solved optimally and their solutions are 
combined to provide an approximate solution to the ILP 
problem. The numerical results delineate that the proposed 
scheme achieves high survivability, load balancing and lesser 
bandwidth consumption at the expense of slightly raising the 
average path hop count. 
 
PIII.1 INTRODUCTION 
Long delays and service interruptions are unacceptable for 
QoS sensitive applications in IP networks. When a network 
failure occurs, the total recovery time for current link state 
routing protocols (such as OSPF [1]) may take up to tens of 
seconds to re-converge [2]. To mitigate the impact of failures, 
many IP fast local recovery schemes have been proposed in the 
literature. The main design principle is to pre-compute backup 
routes to bypass failed component, and guarantee no transient 
loops during the failure recovery. The existing schemes can be 
classified into three categories: Loop-Free Alternate (LFA) 
based schemes [3-5], Tunnel based schemes [6-7], and Backup 
Routing Table (BRT) based schemes [8-11]. 
In LFA-based schemes, the affected packets carried on failed 
link are forwarded to the pre-determined alternate neighboring 
nodes so that these affected packets can be rerouted to their 
destinations without traversing the failed link. In Tunnel-based 
schemes, when a router detects an adjacent link failure, it 
selects an intermediate router as temporary destination and 
encapsulates packets to the intermediate router for bypassing 
the failed link. In BRT-based schemes, each router pre-
compute backup configurations, those are sub-topologies to the 
original network, before any failure occurs. A configuration 
can be applied to recover a failure device if it is not included in 
the network topology of the configuration.  
A new paradigm called Interface Specific Forwarding (ISF) 
is proposed in [10] to provide more flexible routing. Different 
from conventional routers using only a single routing table for 
all incoming packets, routing in ISF is enhanced by allowing 
each incoming interface has its own routing table. We find that 
ISF concept is useful not only in network survivability but also 
traffic engineering.  
In this study, we adopt ISF in developing our load balanced 
fast rerouting scheme. We first formulate the problem using an 
Integer Linear Programming (ILP) model, in which the traffic 
load on the most congested link is to be minimized. Due to the 
NP-hard property of the problem, the optimal solution is 
difficult to be obtained directly. Hence we decompose the ILP 
into several sub-problems and propose a heuristic algorithm to 
resolve the ILP. Through the heuristic algorithm, the load 
balanced backup routing paths are determined and backup 
routing tables are then pre-built in advance along these load 
balanced backup routing paths.  
PIII.2 PROBLEM FORMULATION 
We use graph transformation shown in Fig. 1 and 2 to 
facilitate our problem formulation. Fig. 1(a) is the input graph 
G. We transform G into G’, shown in Fig. 1(b). For simplicity, 
we only transform node 1 in G’. In the transformation, node 1 
in G is replaced with several artificial vertices in G’. Node 1 
has 2 input links (={(2,1), (3,1)}) and 2 output links (={(1,4), 
(1,5)}), the results will include 2 input vertices (={a,b}), 2 
output vertices (={c,d}), one local destination vertex f (i.e., the 
artificial destination vertex for node 1), and one local traffic 
generator vertex e (i.e., the artificial source vertex for node 1) 
in G’, where the dashed arrows are artificial edges used to 
connect input vertices and output vertices.  
Figure 2 shows how the survivability and load balance can 
be enhanced via the idea of ISF. Figure 2(a) gives an example 
topology and a reverse shortest path tree rooted at node E (E is 
the destination node). In Figure 2(b), we demonstrate rerouting 
processes for node using ISF to recover the traffic carried on 
the failed link (D,E). For simplicity, we only transform node D 
in Fig. 2(b). The vertex Da means the local traffic generator of 
node D, D1 is the input vertex, and D2-D4 are the output 
vertices for connecting to node C, E and F, respectively. We 
can see that the working traffic AD1D3E was rerouted 
to the path AD1D4FE, while the local generated traffic 
from node D (i.e., DaD3E) was rerouted to the path Da 
D2CE. The other unaffected working traffic flows remain 
unchanged and are not disturbed by this failure. By doing so, a 
high survivability and load balanced IP network was achieved. 
reason, we present a low complexity Heavy Demand First 
(HDF) heuristic algorithm. We first decompose the above 
Problem (IP) model into |N| sub-problems, one for each 
destination node. We then arrange these |N| sub-problems 
according to their dH  value in descending order, where d is the 
destination corresponding to the sub-problem. We denote the 
first sub-problem as IPsub 1, the second one as IPsub 2, …, and 
the last one as IPsub |N|. The algorithm then sequentially solves 
all of the |N| sub-problems according to their order. 
The model for Sub-problem IPsub i with corresponding 
destination k is as follows. The model is derived from Problem 
IP with destination fixed to k. 
min 
0\{ }
s s
s S s
u

  
subject to: 
in
k
k
es k
e E
y H

   0\s S s   (11)
0
in out
v v
k k
es es
e E e E
y y
 
       0\ , \s S s v V Src k     (12)
out
v
k
es vk
e E
y h

   0\ ,s S s v Src    (13)
1
out
v
k
es
e E
x

     0, , \innv V Src n N s S s     (14)
0kssy    0\s S s   (15)
Mk kes esy x   0, , \ne E n N s S s     (16)
0
k k
es esx x   0, , \n se E n N s S s     (17)
0
1kesx   kTe E    (18)
0 or 1kesx   , ,ne E n N s S     (19)
k
es es sy z u    0\ , \ ,ns S s e E E n N     (20)
Figure 3 depicts the complete HDF algorithm. For the i-th 
sub-problem (assume its corresponding destination node is k), 
Constraint (11) to Constraint (19) is corresponding to 
Constraint (1) to Constraint (9) in Problem IP. In Constraint 
(20), esz is the accumulated used capacity before sub-problem 
IPsub i is computed. It is calculated on line 6 of the HDF 
algorithm. The algorithm terminates when all sub-problems are 
solved.  
PIII.4 EXPERIMENTAL RESULTS 
We perform the HDF algorithm on networks shown in Fig. 4. 
In each network, two adjacent nodes are connected by two 
opposite directional links. We set the weight 
is  of each failure 
state i as 1. Traffic demand between any two nodes is 10 Mbps. 
We consider single link failure scenario in our numerical experiments. 
First, we examine network survivability, which is defined as 
the total number of successfully rerouted routes divided by the 
total number of affected routes. We made performance 
comparisons on ECMP [3], LFA [4], LFA-SA, NLB [11], and 
the proposed HDF algorithm. For LFA, we randomly set a link 
weight to be an integer in the range [1,100]. For the LFA-SA 
scheme, we apply a simulated annealing method [12] to tune 
the link weights until the highest survivability is reached. In 
ECMP, each link weight is set to be 1 to increase the chance of 
multiple equal cost paths between router pairs. As shown in 
Fig. 5, NLB and HDF reach 100% survivability, while ECMP 
has the lowest survivability. We discover that networks with 
lower average degree would reduce the chance for ECMP, 
LFA and LFA-SA to find re-routing paths. 
In the second set of experiments, we examine the link load 
distribution. We evaluate the maximum link load (i.e., the flow 
on the most congested link) and the average link load. The 
results are shown in Fig. 6, where “-n” and “-f” in the legends 
denote the normal state and the failure states respectively. The 
HDF Algorithm:  
10. Sorting demand volume for each destination node k in descending 
order and putting their node ID in priority queue Q. 
11. Set i = 1; 0esz ; 
12. While i  |N|   
13.    k = Q[i]; /*DeQueue the highest order call from Q*/ 
14.   Solve Sub-problem IPsub i with corresponding 
destination k ; 
15.   Calculate 
k
eseses yzz  ; 
16.    i = i + 1; 
17. end 
18. Output working and backup routing tables. 
Fig. 3. Heavy Demand First (HDF) algorithm 
           
(a) COST239                     (b) NSF                             (c) GTE 
Fig. 4. Benchmark networks for performance evaluation 
COST239 NSF GTE0
0.2
0.4
0.6
0.8
1
Topology
Su
rvi
va
bil
ity
 
 
ECMP
LFA
LFA−SA
NLB
HDF
 
Fig. 5. Network survivability in the benchmark networks 
COST239 NSF GTE0
50
100
150
200
250
300
Topology
M
ax
im
um
 Li
nk
 Lo
ad
ing
 (M
b/s
)
 
 
OSPF−n
NLB−n
HDF−n
OSPF−f
NLB−f
HDF−f
Fig. 6. Performance comparisons for maximum link load 
COST239 NSF GTE0
20
40
60
80
100
120
140
Topology
Av
era
ge
 Li
nk
 Lo
ad
ing
 (M
b/s
)
 
 
OSPF−n
NLB−n
HDF−n
OSPF−f
NLB−f
HDF−f
Fig. 7. Performance comparisons for Average link load 
 1
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期： 100 年11月1 日 
 
一、參加會議經過 
  IEEE Consumer Communications & Networking Conference (CCNC) 為 IEEE 通
訊學會主辦的會議之一，列在 IEEE 通訊協會之 Portfolio Events 中。此次會議由 1 月
9 日起至 1 月 12 日在美國拉斯維加斯舉行。本次參加會議的主要目的除了聽取最新
的通訊網路研發現況以外，並發表一篇名為” Optimal Routing and Bandwidth 
Provisioning for Survivable IPTV Multicasting Using Network Coding”的研究論文。論
文內容主要是探討如何使用 Network Coding 技術於 IPTV 群播網路中進行路徑規畫
以及路徑頻寬指派，設計的目標為最小化網路資源的使用，以達到不論任何鍊路發
生故障，此網路仍然能達到 100%存活率。 
二、與會心得 
  此次會議共有來自全球 43 個國家的作者發表研究成果，約三分之一來自亞太
地區，三分之一來自歐洲地區，20%來自美洲。今年主會議共有 6 項技術主軸共 305
計畫編號 NSC 99-2221-E-194 -022 
計畫名稱 IP 網路之最佳化高速抗錯修復與動態路由選擇 
出國人員
姓名 李詩偉 
服務機構
及職稱 中正大學通訊系副教授 
會議時間 100年 1月 9日至 100 年 1 月 12 日 會議地點 美國拉斯維加斯 
會議名稱 IEEE CCNC 2011 
發表論文
題目 
Optimal Routing and Bandwidth Provisioning for Survivable IPTV 
Multicasting Using Network Coding 
 3
四、建議 
  首先感謝國科會補助出國經費參與重要國際會議，此類補助對於新進研究人員
的研究工作有很重要的幫助。建議貴會可以多鼓勵國內研究學者投搞各領域中最重
要的會議，對於將發表成果於重要會議的研究人員給予額外的補助，以幫助研究成
果發表。 
五、攜回資料名稱及內容 
論文集全文電子檔 
 
Optimal Routing and Bandwidth Provisioning for 
Survivable IPTV Multicasting Using Network Coding 
Steven S. W. Lee1, Alice Chen2, and Po-Kai Tseng3 
1Department of Communications Engineering, National Chung Cheng University, Taiwan, R.O.C 
2Information and Communications Research Labs, Industrial Technology Research Institute, Taiwan, R.O.C. 
3Department of Electrical Engineering, National Chung Cheng University, Taiwan, R.O.C.  
Abstract- Network coding has been proven with the 
capability to improve the network bandwidth efficiency for 
multicast communications. Streaming based IPTV services 
provided by network operators match the paradigm of using 
network coding. However, the major research works in the 
literature focus on the selection of network codes under given 
routing paths. Few research work jointly considers routing and 
network coding together to obtain survivable multicast routing 
and minimum bandwidth provision. In this paper, we 
investigate this new research topic and propose mathematical 
models that can be used to obtain an optimal routing for 
survivable multicast communications against any single 
link/node failure. To clarify the gain from applying network 
coding, we also made performance comparisons between the 
network-coding-based protection schemes and those without 
using network coding. We observe that the network coding 
scheme holds the best performance for all cases we had 
simulated. The trade-offs between the network protection 
schemes with and without using network coding are also 
identified in this paper. 
Keywords: IPTV, Survivable Multicast Routing, Bandwidth 
Provision, Network Coding, Network Optimization. 
1. Introduction 
Nowadays more and more multicast services are deployed in 
IP networks. Such services include multicasting packetized 
video programs, video conferencing, and online games. Among 
those multicast services, the streaming based IPTV video 
multicasting is the most popular one. In Figure 1, we depict a 
generic model for delivering multicast videos through the IP 
network. An IPTV network usually consists of one video server 
and multiple receiver nodes. The receiver nodes are responsible 
for receiving all video programs sent by the server. A home user 
can determine which program to watch by tuning their IPTV 
setup box.  
In streaming based IPTV network, a routing path is 
provisioned from the video server (source) to each multicast 
receiver node (receiver). To minimize bandwidth usage, the 
collecting of those SR-pairs paths usually forms a tree-shaped 
multicast connection. This kind of video service is deployed in a 
QoS guaranteed network such as a MPLS network. A multicast 
connection might consist of tens to hundreds of video programs, 
and therefore a network failure would immediately influence on 
many customers watching these programs and incur a sudden 
drop in the service quality. 
Conventional network protection approaches for multicast 
employ extra network resources and pre-compute backup paths 
to bypass the failure link or node. However, such manners need 
to reserve spare bandwidth and backup paths via complex 
computation. Network coding is a new technique to enhance 
throughput and provide network survivability [1-4] by selecting 
some intermediate nodes performing packet encoding. These 
encoded packets are sent to next nodes and decoded at 
destination nodes to obtain original data. Some 
network-coding-based protection schemes for point-to-point 
communications have been proposed in the literature, including 
single link failure [5], multiple link failures [6,7] and single 
node failure [8]. Researchers conclude that both bandwidth 
consumption and service recovery time are reduced by applying 
network coding in point-to-point communications.  
For a multicast communication between one source node 
and N receiver nodes, an algebraic network coding approach is 
shown in [9] for network protection. They assert the network 
coding problem is solvable if, and only if, the Min-Cut 
Max-Flow bound is satisfied for all source-destination 
connections. Moreover, they have proven that there exists a 
solution for the network coding to protect a set of failure 
patterns F in a finite field mF2  with  1||log2  NRFm , 
where the |F| is the number of failure patterns and R is the 
information generating rate at the source. The results imply that 
network survivability is guaranteed if we can determine a 
routing and bandwidth provision that can satisfy Min-Cut 
Max-Flow bound for the pre-defined failure patterns.  
Figure 1. Multicast IPTV network architecture
IP Multicast Network
Multicast Receiver
Video Server
Sending out 
N TV programs Receive all
N TV programs
TV
TV
TV
Channel 1
Channel 2
Select one out 
of N programs
Multicast Receiver
Multicast 
Receiver
 individually and pre-determines backup paths to protect any 
potential single link failure. Models for the two tree-based 
schemes are also presented in the next section. 
 
3. Optimization Models 
In this section, we formulate the NCL, BTL and ITL 
problems as combinatorial optimization problems and 
determine the proposed routes and provisioned bandwidth of a 
multicast network to protect any single link failure. These 
formulations mainly focus on the minimization of total network 
costs, in which the constraints are required to satisfy the 
demand requirement, 100% survivability constraint and 
physical capacity limitation. The output of the problems 
includes the routing paths and required bandwidth on each link. 
A multicast network is modeled as a graph G(N,L), where N 
denotes the set of network nodes, and L represents the set of 
physical links. The link capacity Cl is the available bandwidth 
on link l. We assume that each video program consumes the 
same bandwidth.  
Before describing the formulations, we first list the notations 
that are common for all models.  
Common Notations: 
 l  : cost for one unit bandwidth on link l (i.e. bandwidth for 
one video program); 
 R : set of receiver nodes; 
 k : the number of video programs in the system; 
 d : bandwidth requirement to support one video program;   
 innL  : set of input links for node n; 
 outnL  : set of output links for node n; 
 
nr  : 






otherwise,0
   node if,1
nodeserver   theis  node if,1
rn
n
; 
 
nl :






otherwise,0
) enters  (i.e., link  of node head  theis  node if,1
 ) leaves  (i.e., link  of node  tail theis  node if,1
nlln
nlln
; 
In addition to the above notations, there are some other 
notations used only for separate models. They are listed right 
before the corresponding one. 
3.1 Single Link/Node Protection Using Network Coding 
Our model is developed based on the network coding theorem 
shown in [10]. It guarantees that a network can survive after any 
single link failure if the remaining capacity is still large enough 
to provide the required bandwidth after removing the failed link. 
To be precise, the maximum flow bound for each receiver must 
be greater than or equal to the demanded bandwidth in both 
normal and any single link failure state. We summarize the 
dedicated notations used in the formulation as follows: 
Decision variables: 
 xl : the number of video programs carried on link l; 
 yrl : the number of video programs carried on link l for 
destination node r; 
 zr : the total flow amount leaving from the server node to 
destination node r; 
Problem (NCL): 

Ll
ll xmin  
subject to: 



Ll
rnrrl
Ll
rl
in
n
out
n
zyy   NnRr  ,  (1) 
rlr yzk   LlRr  ,  (2) 
lrl xy   LlRr  ,  (3) 
ll Cdx   Ll  (4) 
integerrly  LlRr  ,  (5) 
integerrz  Rr  (6) 
The objective function is to minimize the total cost of 
provisioned bandwidth on each link. Constraint (1) enforces the 
flow conservation law in each node for flows coming from the 
video server to each destination node. To be more specific, the 
number of video programs that can leave the server node and 
enter destination node r is zr. For an intermediate node that is 
neither the source node nor the destination node, its input flow 
should be equal to its output flow. Constraint (2) is a 
survivability constraint. It requires that even if link l becomes 
failed, the network can still provide enough bandwidth for each 
od-pair to obtain bandwidth for more than k video programs. 
Constraint (3) determines decision variable x which is the 
bandwidth to be provisioned on link l. Constraint (4) is the 
capacity constraint. 
For the single node failure protection, we adopt the graph 
transformation technique as shown in Figure 3 and then apply 
the above model on the transformed graph. By doing so, the 
above model can be used to solve the single node protection 
problem directly. 
3.2 Bundle Multicast Tree-based Link Protection Model  
BTL requires whole traffic routing on a single working tree. 
It uses the link protection scheme to setup a backup path. This 
scheme does not apply network coding on it. We summarize the 
notations used in the formulation as follows: 
Decision variables: 
 tl : = 1, if link l is used by a working tree; = 0, otherwise; 
 
lt  : = 1, if link l is used by a backup path; = 0, otherwise; 
 xle : =1, if link e is on the backup path to protect link l; 
   =0, otherwise; 
 yrl : =1, if a working routing path for destination r goes 
through link l; =0,otherwise; 
 
Problem (BTL): 
 


Ll
lll tkkt )(min   
subject to 
 experiments), ITL is very similar to BTL; however, as the 
number of links goes up, the results move toward NCL. 
We further compare the total cost of the network coding 
approach with the one of the individual tree approach. The 
comparison is made in Ratio which is defined as the total cost of 
IDL value to NCL value in percentage. As shown in Figure 4(b), 
we observe that the ratio between these two approaches 
decreases from (19~24%) to (4~10%) when receiver nodes 
equal 2 and 10, respectively. The gain of NCL becomes smaller 
and smaller as the number of receiver nodes increases; i.e., the 
tree-based approach is suitable for operating at a multicast 
network with a large number of receiver nodes. Since it is 
typical for an IPTV network to have a small-to-medium-sized 
number of receiver nodes, our results indicate that network 
coding based approach is suitable for supporting survivable 
IPTV services. 
We further compare the total cost between these two 
tree-based approaches. The vertical axis is the ratio of the total 
cost of BTL to ITL. Numerical results are demonstrated in 
Figure 4(c). The Ratio(BTL/ITL) increases from 1%, 4~6%, 
8~10%, to 15~17% when the network links are 50, 60, 70, and 
80, respectively. We find that more network links drive the ITL 
scheme to a better performance. The results indicate that ITL is 
suitable for being applied in a dense network. However, the 
performance gap between BTL and ITL diminishes in a sparse 
network. 
 
5. Conclusions  
In this paper, we address the optimal routing and bandwidth 
provisioning problems for survivable multicast in network 
supporting IPTV services. Network-coding-based approaches 
and two tree-based approaches are formulated by integer linear 
programming. Experimental results show that the proposed 
network coding approach outperforms two tree-based 
approaches for total network costs in all test cases. Particularly, 
the performance is especially distinguished for networks with a 
small-to-medium-sized number of receiver nodes, which is the 
most common case for network supporting IPTV services. Our 
study provides a starting point for further research on the using 
network coding to provide survivable IPTV services. Since 
network-coding-based scheme needs to perform packet 
synchronization on coding points, it might introduce additional 
delay and delay jitter. How to provide QoS aware routing to 
meeting delay and delay jitter requirements in NC-based IPTV 
networks is still an open question and need to be clarified in the 
future. 
REFERENCES 
[1]  R. W. Yeung, S. Y. R. Li, N. Cai, and Z. Zhang, Network Coding 
Theory, Now Publishers Inc., 2006. 
[2]  R. Ahlswede, N. Cai, S. Y. Li, and R. Yeung, “Network Information 
Flow,” IEEE Trans. Inf. Theory, vol. 46, no. 4, pp. 1204–1216, Jul. 
2000. 
[3]  S. Y. R. Li, R. W. Yeung, and N. Cai, “Linear network coding,” 
IEEE Trans. Inf. Theory, vol. 49, no. 2, pp. 371–381, Feb. 2003. 
[4]  T. Ho, M. M´edard, R. Koetter, D.R. Karger, M. Effros, J. Shi, and 
B. Leong, “A random linear network coding approach to 
multicast,” IEEE Trans. Inf. Theory, vol. 52, no. 10, pp. 4413–4430, 
October 2006. 
[5]  S. A. Aly and A. E. Kamal. “Network protection codes against link 
failures using network coding,” in Proc. IEEE Globecom, 2008. 
[6] A. E. Kamal. “1+N protection against multiple link failures in mesh 
networks,” in Proc. IEEE ICC, 2007. 
[7]   A. E. Kamal. “A generalized strategy for 1+N protection,” in Proc. 
IEEE ICC, 2008. 
[8]  S. A. Aly and A. E. Kamal. “Network coding-based protection 
strategy against node failures,” in Proc. IEEE ICC, 2009. 
[9]  R. Koetter and M.Médard, “An algebraic approach to network 
coding,” IEEE/ACM Trans. Netw., vol. 11, no. 5, pp. 782–795, Oct. 
2003. 
[10] C. S. Wu and S. W. Lee, “Backup VP Planning for Multicast 
Connections in ATM Networks,” Computer Communications, vol. 
22, pp. 898-906, Jun. 1999.
(a) Total bandwidth consumption
2 3 4 5 6 7 8 9 10
100
200
300
400
500
600
700
800
900
1000
 
 BTL Link=50
 ITL Link=50
 NCL Link=50
 BTL Link=80
 ITL Link=80
 NCL Link=80
To
ta
l P
ro
vi
si
on
ed
 B
an
dw
id
th
Total Number of Destination Nodes
(b) Performance comparison: ratio of ITL/NCL
2 3 4 5 6 7 8 9 10
1.00
1.05
1.10
1.15
1.20
1.25
 
R
at
io
 (I
TL
/N
C
L)
Total Number of  Destination Nodes
 Link 50
 Link 60
 Link 70
 Link 80
(c) Performance comparison: ratio BTL/ITL
2 3 4 5 6 7 8 9 10
1.00
1.05
1.10
1.15
1.20
1.25
 
 
R
at
io
 (B
TL
/IT
L)
Number of Destination Nodes
 Link 50
 Link 60
 Link 70
 Link 80
Figure 4. Experimental Results
99 年度專題研究計畫研究成果彙整表 
計畫主持人：李詩偉 計畫編號：99-2221-E-194-022- 
計畫名稱：IP 網路之最佳化高速抗錯修復與動態路由選擇 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 3 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
本計畫執行已發表下列會議論文 
1.’’Interface Specific Fast Failure Rerouting for Load Balanced IP Networks,’ 
IEEE ISCC 2011. 
2.’’Non-Weighted Interface Specific Routing for Load-Balanced Fast Local 
Protection in IP Networks,’ IEEE ICC 2011. 
3.’’Optimal Routing and Bandwidth Provisioning for Survivable IPTV Multicasting 
Using Network Coding,’ IEEE CCNC 2011. 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
成果簡介: 
  本計畫執行共獲得三項成果: 
1.我們運用網路編碼技術於群播式 IPTV 網路，並研發該網路的最佳化路徑規劃與頻寬設
定，以保障網路於任何單一鍊路故障狀況下仍能達到 100%存活率。本研究成果已發表於
IEEE CCNC 2011 會議中。 
2.我們提出一種不受權值影響且具負載平衡之快速局部修復機制，以達到於任何單一鍊路
故障下，網路仍然能達到 100%存活率。不同於傳統以最短路徑為基礎的路由，我們規劃出
不受最短路徑限制之正常路徑及備用路徑並達到負載平衡的目標。一旦發生網路損壞時，
與受損壞影響之故障點的相鄰節點將會使用事先建立好的備用路由表，以達成快速局部損
壞修復。本研究成果已發表於 IEEE ICC 2011 會議中。 
3.由於將交換機的各個介面使用不同的路由表可提高網路路徑選擇的彈性，我們應用此特
性於存活性 IP 網路的設計中並使用混合型整數線性規劃技術加以模型上述問題，其目標
函數為最小化最壅塞的鏈結上的負載量，並於限制式保證 100%的存活率。該項研究的成果
