                                     1
以鳥鳴聲為基礎之鳥種辨識系統架構之研究與開發(III)  
主持人： 周智勳  
執行機構： 中華大學資訊工程學系  
執行期間： 民國98年08月01日至99年07月31日  
國科會計畫編號：NSC 98-2221-E-216-033  
 
Abstract 
In this study, an automatic birdsong recognition system based on syllable features was developed. In this system, after the 
syllables have been segmented, three syllable features, namely mean, QI and QE, were computed from the MFCCs of each 
syllable. The first feature has been applied in many studies, however, QI and QE are novel features. Adding the advantages of 
the fuzzy c-mean (FCM) clustering algorithm and the linear discriminant analysis (LDA), the presented feature vector was 
used to construct an automatic birdsong recognition system. In the experiment, the proposed system was applied to a 
birdsong database with 420 bird species and achieved an average recognition rate of 83.3%. 
Keywords: Birdsong, MFCC, syllable, linear discriminant analysis, transition matrix
1. Introduction 
 The investigation of bird species diversity is the 
key in monitoring environment and ecosystem 
recovery, and automatic bird species recognition by 
recognizing their birdsongs has become an invaluable 
study method in the long-term investigation of bird 
species. The vocalization types of bird species 
include birdsong and birdcall. Birdsong being 
complicated, varied, agreeable and pleasant to listen 
to, is usually generated by a male bird and is used to 
declare his turf or attract a mate. Birdcall, on the 
other hand, is monotonous, brief, repeated, fixed and 
sexless and is used to contact or alert companions. 
The time duration and acoustic structure of a birdcall 
are usually short and simple while the duration of a 
birdsong is longer and is composed of a succession of 
melodious musical notes. 
Although MFCCs have been well-applied in bird 
species recognition, further study on this feature is 
necessary to increase the recognition rate. In (Lee et 
al. 2003; Lee et al., 2001; Skowronski and Harris, 
2002, 2003; Bou-Ghazale and Hansen, 2000) optimal 
theories were used to obtain the center frequencies 
and bandwidths of the triangular filters. The discrete 
cosine transform (DCT) was replaced with the 
wavelet transform in (Ricotti, 2005). Filter weighting 
was applied in (Hung and Wang, 2001) to assign a 
weight for each order of MFCCs. In (Kwan et al., 
2006) the MFCCs as well as their first-order and 
second-order differences were used to form the 
feature vector. Combination of MFCCs with a lot of 
low-level descriptive parameters such as 
zero-crossing rate, short time energy, syllable length, 
spectrum centroid, bandwidth and so on was applied 
in (Somervuo, 2006) for recognizing 14 bird species.  
In this study, neither modifying the steps for 
computing the MFCCs nor combining the MFCCs 
with other types of features, three features were 
computed from the MFCCs of a syllable to form the 
syllable feature vector. The proposed method aimed 
at easy computation and small time complexity. 
Integrating with the advantages of FCM clustering 
algorithm and the LDA, the proposed system 
achieved an average recognition rate over 83% when 
recognizing the birdsongs of 420 bird species. The 
remaining of this paper is as follows: Section 2 
                                     3
jth triangular filter at frequency bin k as shown in Fig. 
2.2, jE  denotes the energy of j
th filter band, and J is 
the number of triangular filters. 
Step 3 Compute the MFCCs by Cosine 
transformation 
150 ,)(log)5.0(cos)(
1
0
10 <≤⎟⎠
⎞⎜⎝
⎛ +=∑−
=
mEj
J
mmc
J
j
ji
π , 
        (7) 
where )(mci  denotes the m
th order MFCC of the ith 
frame. 
 In the following, three features named mean, QI 
and QE computed from the MFCCs were used to 
form the feature vector of a syllable. 
2.2.2. Computing the mean, QI, and QE 
In this study, three features, namely mean, QI, 
and QE were used to form the feature vector. 
 
Feature 1: mean of MFCCs 
After computing the first 15 (order) MFCCs of 
each frame, the coefficients of the same order of all 
frames were averaged. The average of mth order 
MFCCs a(m) was obtained by the following 
equation: 
Lmmc
W
ma
W
i
i <≤= ∑
=
0  ,)(1)(
1
,  (8) 
where W is the number of frames and L = 15 is the 
order of MFCCs applied in this study. Due to the 
scale diversity between different orders of MFCCs, a 
normalization process for a(m), )(ˆ ma , is required.  
 
Feature 2: QI of MFCCs 
For saving on computation complexity, 
consecutive frames were used as a time unit to 
compute QI. The process for computing QI is 
described in the following. 
Step 1 Quantize the MFCCs of each order in all 
frames ( )(),...,(),( 21 mcmcmc W ) into Q levels (from 
level 0 to level Q-1). 
  
Q
mcmcmv )()()( minmax −= ,   (9) 
where 
Wi
i mc
,...,2,1
)(maxargmax
=
= , 
Wi
i mc
,...,2,1
)(minargmin
=
=  
and v(m) is the quantization interval of the mth order 
MFCCs. 
Step 2 Segment the W frames into S equal sections, 
then compute the mean of each order of MFCCs in 
every section. 
SsLmmc
W
Sma
SWs
SWsk
ks ≤≤<≤= ∑⋅
+⋅−=
1  ,0 ,)(  )(~
1)1(
,(10) 
where s is the section index. 
Step 3 Find the level )(mIs  at which the value 
)(~ mas  locates, where 
  
 1  ,0                                                   
),()1)(()()(~)()( min
SsLm
mvmImamamvmI sss
≤≤<≤
⋅+<−≤⋅ . 
        (11) 
Step 4 Form the sequence )(),...,(),( 21 mImImI S  
for each order of MFCCs. 
Step 5 Those sequences obtained in Step 4 for all 
the 15 orders of MFCCs form the second feature QI. 
 )1(),...,1(..., ),1(),...,1(),0(),...,0(QI 111 −−= LILIIIII SSS  
        (12) 
 
Feature 3: QE of MFCCs 
The process for obtaining QE is described in the 
following. 
Step 1 Perform the same quantization process (Step 
1) used in computing feature 2.  
Step 2 Find the level )(mIi  at which the value 
)(mci  locates, where 
 
 1  ,0                                       
),()1)(()()()()( min
WiLm
mvmImcmcmvmI iii
≤≤<≤
⋅+<−≤⋅ . (13) 
Step 3 For each order of MFCCs, record the frames 
that transit from level x to level y, 1,0 −≤≤ Qyx , 
                                     5
clustered. 
Step 3: Set the initial performance index )(tmJ , t = 0, 
as 0. 
Step 4: Calculate the c cluster centers )()(1 ,...,
t
c
t vv  
by 
 
∑
∑
=
=
⋅
= J
j
mt
ij
J
j
s
mt
ij
t
i
j
1
)(
1
)(
)(
)(
)(
μ
μ v
v , ci ,...,1= , 21 << m . (22) 
Step 5: Update the membership grade for each 
feature vector 
js
v , 
 
1
1
1
1
2)(
2)(
)1(
−
=
−
+
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
−
−= ∑c
k
m
t
ks
t
ist
ij
j
j
vv
vvμ .   (23) 
Step 6: Compute the performance index 
 ∑∑
= =
++ ⎥⎦
⎤⎢⎣
⎡ −⋅=
J
j
c
i
is
mt
ij
t
m j
J
1 1
2)1()1( )( vvμ .  (24) 
Step 7: If ε≥−+ )()1( tmtm JJ  (a threshold), then t = t + 
1, go to step 4. 
Step 8: Stop 
 Applying the FCM algorithm requires the 
determination of the optimal cluster number, that is, 
to treat the cluster validity problem. In this study, the 
WB index proposed in (Tan, 2000) was applied to 
solve it. The WB index has the purpose of finding 
cluster number c that minimizes the intra-group 
variance ),( vμW  and maximizes the inter-group 
variance ),( vμB . That is, to find optc  such that 
 
),(
),(maxargmaxarg
v
v
μ
μ
W
BWBc
ccopt
== . (25) 
The two terms ),( vμW  and B(μ,v) are defined as 
 ∑∑
= =
− −=
c
i
J
j
isi j
CW
1 1
21)(),( vvvμ ,  (26) 
 2
1
1
1 12
)(
C
1),( m
c c
m m
SSj
mjλj
c SS
B m vvv −
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+
⋅
=
−
−
= +=
∪∈∑ ∑ ∑ λ
λ λ λ
λ
μμ
μ , 
(27) 
in which 
 ci
S
C
i
J
j
ij
i ,...,2,1  ,
1
2
==
∑
=
μ
,    (28) 
where 
 { }1== iji IjS ,     (29) 
and 
 
⎩⎨
⎧ == ≤≤
otherwise,0
max if,1
1 kjckij
ijI
μμ ,   (30) 
and c2C  is a combination computation. 
 After the FCM clustering, several mean vectors 
were obtained as the feature vectors of each bird 
species. Before applying them, the LDA was applied 
again to extract the principle components of the 
feature vector and improve the recognition rate. In 
the following, the song of Pallas's Leaf Warbler was 
used as an example for the feature extraction process. 
 
2.3. Recognition 
In the recognition process, after the same feature 
extraction procedure (without the clustering process), 
as shown in Fig. 1.1, the feature vector of a testing 
syllable was matched to those of the template bird 
species. A template bird species usually has several 
syllable feature vectors and so do the matching 
degrees defined by the inverse of the Euclidean 
distance between the feature vectors of the testing 
syllable and the template syllables. The recognition 
of the testing syllable was accomplished by finding 
the template bird species that had syllable with the 
largest matching degree. 
 
3.  Experimental Results 
 The bird species vocalization database used in 
                                     7
Härmä, A., Somervuo, P., 2004. Classification of the 
harmonic structure in bird vocalization. In: IEEE 
International Conference on Acoustics, Speech, and 
Signal Processing, vol. 5. pp. V701-V704. 
He, S.N., Yu, J.B., 2002. A novel Chinese continuous 
speech endpoint detection method based on time 
domain features of the word structure. In: IEEE 
International Conference on Communications, Circuits 
and Systems and West Sino Expositions, vol. 2. pp. 
992-996. 
Hung, J.W., Tsai, W.Y., 2008. Constructing Modulation 
Frequency Domain-Based Features for Robust Speech 
Recognition. IEEE Transactions on Audio, Speech, and 
Language Processing. 16 (3), 563-577. 
Hung, W.W., Wang, H.C., 2001. On the use of weighted 
filter bank analysis for the derivation of robust MFCCs. 
IEEE Signal Processing Letters. 8, 70-73. 
Kabaya, T., Matsuda, M., 2001. The Songs & Calls of 420 
Birds in Japan. SHOGAKUKAN Inc., Tokyo. 
Kwan, C., et al., 2006. An automated acoustic system to 
monitor and classify birds. EURASIP Journal on 
Applied Signal Processing. 2006, Article ID 96706, 
1-19. 
(*)Lee, C.H., Chou, C.H., Han, C.C., Hunag, R. Z., 2006. 
Automatic recognition of animal vocalizations using 
averaged MFCC and linear discriminant analysis. 
Pattern Recognition Letters. 27 (2), 93-101. 
Lee, C.H., Hyun, D.H., Choi, E.S., Go, J.W., Lee, C.Y., 
2003. Optimizing feature extraction for speech 
recognition. IEEE Transactions on Speech and Audio 
Processing. 11, 80-87. 
Lee, S.M., Fang, S.H., Hung, J.W., Lee, L.S., 2001. 
Improved MFCC feature extraction by PCA-optimized 
filter-bank for speech recognition. In: IEEE Workshop, 
Automatic Speech Recognition and Understanding. pp. 
49-52. 
McIlraith, A.L., Card, H.C., 1997a. Bird song identification 
using artificial neural networks and statistical analysis. 
In: Canadian Conference on Electrical and Computer 
Engineering, vol. 1. pp. 63-66. 
McIlraith, A.L., Card, H.C., 1997b. Birdsong recognition 
using backpropagation and multivariate statistics. IEEE 
Transactions on Signal Processing. 45 (11), 2740-2748. 
Minh, V.D., Lee, S.Y., 2004. PCA-based human auditory 
filter bank for speech recognition. In: International 
Conference on Signal Processing and Communications, 
pp. 393-397. 
Rabiner, L.R., Sambur, M.R., 1975. An algorithm for 
determining the endpoints of isolated utterances. Bell 
System Technical Journal. 54 (2), 297-315. 
Ricotti, L.P., 2005. Multitapering and a wavelet variant of 
MFCC in speech recognition. IEE Proceedings - Vision, 
Image and Signal Processing. Feb, 29-35. 
Selouani, S.A., Kardouchi, M., Hervet, E., Roy, D., 2005. 
Automatic birdsong recognition based on 
autoregressive time-delay neural networks. In: ICSC 
Congress on Computational Intelligence Methods and 
Applications. pp. 1-6. 
Skowronski, M.D., Harris, J.G., 2002. Increased MFCC 
filter bandwidth for noise-robust phoneme recognition. 
In: IEEE International Conference on Acoustics, 
Speech, and Signal Processing, vol. 1. pp. 801-804. 
Skowronski, M.D., Harris, J.G., 2003. Improving the filter 
bank of a classic speech feature extraction algorithm. 
Circuits and Systems. 4, 281-284. 
Somervuo, P., Härmä, A., 2004. Bird song recognition 
based on syllable pair histograms. In: IEEE 
International Conference on Acoustics, Speech, and 
Signal Processing, vol. 5. pp. V825-V828. 
Somervuo, P., Harma, A., Fagerlund, S., 2006. Parametric 
Representations of Bird Sounds for Automatic Species 
Recognition. IEEE Transactions on Audio, Speech and 
Language Processing. 14, 2252-2263. 
Takiguchi, T., Ariki, Y., 2006. Robust Feature Extraction 
using Kernel PCA. In: IEEE International Conference 
on Acoustics, Speech and Signal Processing, Vol. 1, pp. 
I509-I512. 
Tan, J.H., 2000. On cluster validity for fuzzy clustering. 
Master Thesis, Applied Mathematics Department, 
Chung Yuan Christian University, Taiwan, R.O.C.. 
Wu, B.F., Wang, K.C., 2005. Robust Endpoint Detection 
Algorithm Based on the Adaptive Band-Partitioning 
Spectral Entropy in Adverse Environments. IEEE 
Transactions on Speech and Audio Processing. 13 (5), 
762-775. 
Zhang, W.J., Xie, J.Y., 2003. Endpoint detection based on 
MDL using subband speech satisfied auditory model. 
In: IEEE International Conference on Neural Networks 
and Signal Processing, vol. 2. pp. 892-895. 
 
                                     9
計畫成果自評： 
1. 研究內容與原計畫相符程度 
計畫書中，本年度欲完成之目標： 
1) 針對單一音節為單位，進行音節之MFCCs 特徵改良、開發新的音節特徵，並結
合形成音節特徵向量。 
2) 針對一段聲音為單位，進行MFCCs 特徵改良，並開發新的特徵向量。 
3) 結合上述之特徵擷取法，與前兩年計畫所研究的音節切割法及分類器，開發完整
的鳥鳴聲辨識系統。 
自評：本計劃成果確實針對 MFCC 進行改良，並以 MFCC 為基礎進行特徵擷取的研究。 
 
2. 達成預期目標情況 
自評：本計劃成果提出兩個新的特徵向量，實際應用於鳥鳴聲辨識，並提升辨識效果。 
 
3. 研究成果之學術或應用價值 
自評：本方法為一個新的觀念，計算過程簡單，對於即時的辨識應用，有相當的可行性。 
 
4. 是否適合在學術期刊發表或申請專利 
自評：目前正攥寫成投稿型式，準備投稿中。 
 
5. 主要發現或其他有關價值 
自評：MFCC 為語音辨識中，最重要的聲音特徵之ㄧ。基於 MFCC 特徵的語音辨識，
基本上可以得到某種程度的效果。本計劃針對每一階(order)MFCC，觀察其隨時
間的變化的時間序列。由時間序列的變化特性中，萃取出特徵向量。此向量結合
原本的 MFCC 係數，可以明顯的提升單純由 MFCC 所做的辨識率。 
 
表 Y04 2
  
           圖二 議場入口海報                       圖三 會議室一隅 
 
研討會第三天晚上為會議晚宴，餐廳位於十九樓，能俯視整個海參崴視野相當
不錯。食物以當地特色為主，冷盤居多，過程中播放影片介紹海參崴未來的遠景，
並邀請了提琴手及歌手前來表演，場面相當熱烈。研討會於第四天中午結束，除了
紀念品，大會也提供交通車機場接送，相當貼心。 
 
 
圖四 晚宴一隅                       圖五 與主辦單位主管合影 
 
二、與會心得 
1. 會場的佈置似乎不像國內辦研討會的熱鬧，國內辦研討會，會花不少心思在會
場佈置上，感覺比較有那麼個氣氛。 
2. 此次研討會沒有參展的攤位，不太能了解該地區的科技產業如何。 
3. 國內也常舉辦國際性研討會，可以於議程中安排半日遊，讓外國學者增加認識
台灣的機會，或於晚宴時安排有代表性的表演，如此對推展觀光也許有一些幫
助。 
4. 近年來大陸方面參加研討會的學者漸多，國內方面出國留學的學生日漸減少，
因此應該鼓勵國內的研究生，參加國際研討會。 
 
三、考察參觀活動(無是項活動者省略) 
包括海港、西伯利亞鐵路終點站、武器博物館、自然科學博物館及潛艇內部等，
算是相當特別，有歷史意義的景點。 
 
 
 
 
 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
