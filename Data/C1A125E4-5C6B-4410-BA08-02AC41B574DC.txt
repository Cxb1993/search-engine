 2
本子研究的重點。 
鑒於知識萃取方法在實際應用時，Priori Knowledge 時常扮演一個重要的角色，預測系統甚至可納入
Priori Knowledge 為主要的預測指標，也因此如何萃取出這些知識法則將是研究的重點，為配合整合型
計畫中子計畫三、四的實行，本研究子計畫將從總計劃所提及的 CI 方法中選用類神經網路（Neural 
Network）為知識萃取模型之核心，並搭配案例式推理作為輔助的系統以萃取知識法則，在每一年的計
畫中將更佳導入其他 CI 方法的應用。  
本研究子計畫之主要將整合類神經網路預測模式與總計劃所提的各種 CI 工具，進行知識萃取模式之建
立，並將此一知識萃取模式，運用在財務（Financial Mining）與醫學（Medical Mining）。 
 
2. Literature Review 
2.1. Priori Knowledge(先導知識) 
Shumeet(2002)說明先導知識可以使預測模式具有更精確的效能，不論是在參數相依甚至是資訊不
完整的情形下皆適用。Patrick Celka and Elly Gysels (2007)提出 3 種不同的方式去建構先導知識：A 
model-base、Averaging-based 與 Recursive-based，該方法特別適用於低訊號與低噪音的環境下。Marko 
Subasi 等人(2005)對於主動脈的圖像辨識是透過三個步驟完成的：1.利用主動脈外型的先導知識初步判
定；2.使用 GDM-based method；3.型態比對學。該方法對 12 個病人的影像掃描做了統計驗證，共 497
張影像，統計分析證實了此方法具有很高的辨識率。廖元甫等人(2008)在評估一個未知型號的手機的特
性時，藉由先導知識的輔助，幾乎達成最佳驗證。針對 HTIMIT 數據進行實驗，比較 ML-AKI 法與傳
統的 posteriori-adapted Gaussian mixture models，speaker 的平均識別率可從 60.0%提升到 74.6%。 
 
2.2. 類神經網路於預測方面之研究 
類神經網路（Artificial Neural Network），是指模仿生物神經網路的資訊處理系統。類神經網路是
一種計算系統，其中包括軟體與硬體，它使用大量簡單的人工神經細胞來模仿生物神經網路的能力。
人工神經元是生物神經元的簡單模擬，它從外界環境或者其他人工神經元取得資訊，並加以非常簡單
的運算，輸出其結果到外界環境或者其他人工神經元，以便用於推估、預測、決策、診斷。類神經網
路應用於股市預測方面的研究則最為常見。Liu 與 Yao(2001)的研究結果發現，以演化式神經網路預測
股價，可以明顯提高預測能力。Abraham 等(2001)的實驗結果顯示，類神經網路預測出的 RMSE 值在
3.5%以下，而模糊類神經模型也可以提供 100%的趨勢預測。Abraham 與 Yeung (2003)的實驗結果顯示，
結合兩種不同演算法的結果優於單一演算法的結果，而與 Direct 演算法進行整合可以得到最低的
RMSE、MAP 及 MAPE 值。 
 
2.3. 案例式推理於知識萃取之研究 
Chang 等(2005a)結合類神經網路中的自組織映射類神經網路與案例式推理，對新發行的書籍進行
銷售預測，以幫助書店做出最佳的訂購數量決策。實驗對象以某台灣書店的書籍銷售資料為 CBR 的資
料庫。研究結果發現，SOM/CBR 比 K-mean/CBR 可得到更佳的預測結果。Hongkyu 與 Ingoo(1996)利
用案例式推理、辨別分析及類神經網路三種演算工具，應用於預測銀行是否或倒閉的問題上。預測模
式總共分為訓練、測試、調整及預測結果四個步驟，其中有訓練、測試與歸納資料等三種輸入資料。
實驗結果證實整合此三種方法比單一方法所得到的預測準確度更為精確。Chang(2005b)將案例式推理
應用於診斷孩童發展延遲的篩選上。其使用 CBR 的概念建立一個孩童發展延遲的篩選系統，幫助醫生
能夠更精確的判斷還孩童是否有延遲發展的現象。實驗結果顯示，經由此系統的判斷，模擬案例的正
確性可達到 91%，證實此系統擁有高水準的驗證結果。Liu 與 Sin(1999)評估 Case Based Reasoning
 4
量、融資融劵、淨值市價比及本益比等七個層面，挑選出值得投資的股票進行預測。接下來針對
選出的個股將篩選其重要因子，本研究考慮的因子包含技術指標及技術指標的波動趨勢。為了瞭
解是不是每一項因子對於股價波動而言都是關鍵且不可少的因素，在此我們針對這些變數進行關
鍵因素的篩選工作。本研究所使用的工具為逐步迴歸分析（Stepwise Regression Analysis），希望藉
由此一工具的篩選結果，以較相關的因子做為預測模型的輸入變數。 
第二階段： 
第二階段的重點在於類神經網路及案例式推理兩個模組的建立。首先建立類神經網路模型，本研
究是以類神經網路中的倒傳遞神經網路作為預測工具，輸入變數為由逐步迴歸篩選出的相關因
子，輸出值為個股買賣的轉折點。由於單純以類神經網路一個模型預測出的轉折點其買賣頻率會
比較密集，因此本研究將以案例式推理系統作動態時間視窗的搜尋（Dynamic Time Window 
Search），藉以輔助類神經網路，更精確的判斷股價波動的轉折時點。 
以上兩個階段的詳細說明如下： 
 
3.1. Priori Knowledge 於資料蒐集 
z 個股選擇 
第一年計畫將以 Financial Mining 作為知識萃取模式之驗證標的，其 Priori Knowledge 主要依據
專家學者所判斷的歷史依據作為遵守原則，其中又以選股策略最為重要。因此本研究第一部分
將選出值得投資的個股，其選股採用的 Priori Knowledge 指標包含了股本、營收狀況、每股盈餘
（Earnings Per Share，EPS）、成交量、融資融劵、淨值市值比、本益比等。 
z 指標(因子)選擇 
技術指標 
本研究所採用技術指標包含：移動平均線（Moving Average，MA）、乖離率（BIAS）、隨機指標
（Stochastic Line，KD）、相對強弱指標（Relative Strength Index，RSI）、指數平滑異同移動平均
線（Moving Average Convergence and Divergence，MACD）、威廉指標（WMS%R）以及成交量
（Volume）等。 
其他指標 
本研究除了考量上一小節的技術指標之外，為了使預測結果更加精確，同時也將電子類股的技
術指標及技術指標差異量納入。此外由於本研究的研究目的主要希望預測出個股股價走勢的轉
折點。相較於股價，股價的漲跌幅更容易反映出轉折點的判斷，因此研究當中同時加入技術指
標的差異量作為輸入變數。 
 
3.2. 整合 Priori Knowledge 於案例式推理及類神經網路知識萃取模式 
z 倒傳遞神經網路整合 Priori Knowledge 之建構 
倒傳遞網路全名為「倒傳遞法則之多層前向式全連結神經網路」，是目前類神經網路中最具代表
性且應用最為廣泛的模式。倒傳遞神經網路早在 1974 年和 1982 年就由 P. Werbos 及 Parker 提出
基本觀念，直到 1985 年史丹福大學的 Rumelhart、Hinton 和 Williams 提出了傳遞學習規則
（Propagation learning rule），又稱延伸差距學習通式（Generalized delta learning rule），才將這項
理論與演算法則清楚的定義。 
本研究倒傳遞神經網路運作流程如圖 1 所示，共包含三個階段：輸入階段、訓練階段及測試階
段，其各階段說明如下： 
I. 輸入階段(匯入 Priori Knowledge) 
KD 指標交叉 
KD 線隨機指標融合了移動平均線速度的概念，形成了非常準確的買賣訊號依據。當 KD 線
 6
IV. 買賣點判斷： 
研究當中倒傳遞神經網路所訓練出的輸出值會介於-1~2 之間。為了判斷正確的買賣點，本研
究決定買賣時機的方式為：以 0.5 為界線，當輸出值下降低於 0.5 時，判定為買點；當輸出值
上升高於 0.5 時，判定為賣點 
 
3.3. 案例式推理演算法整合 Priori Knowledge 之建構 
本研究案例比對之計算步驟如下： 
 
z 設定變數 
n：總案例個數 
m：案例庫中欲比對案例之個數 
i ：動態視窗個數 
j：案例屬性個數 
z 歐幾里德距離計算 
此步驟將新案例與案例庫中之案例進行比對，比對方式為計算新舊案例之間的歐幾里德距離，
本研究歐幾里德距離之計算公式為： 
 
( )∑∑
= =
+−−+ −=
i
a
j
b
bainbmam XXDis
1 1
2
,,1   inm −=∀ ~1  
 
mDis ：第 m 筆案例與新案例之距離，m 介於 1 至 n-i 之間 
bmaX ,1−+ ：案例庫中第 a+m-1 筆案例的第 b 個屬性值 
bainX ,+− ：第 n-i+a 筆新案例的第 b 個屬性值 
z 案例套用 
依步驟二所計算出的距離當中，找出距離最小的 k 組候選案例（k=3、k=5、k=7），以加權平均
方式計算最終 n+1 日的股價。 
 
22111 YWYWY n +=+
∧
… nkYW  
k~1i           
1
=∀=
∑
=
k
i
i
i
i
Dis
Dis
W  
 
1+
∧
nY ：第 n+1 天之預測結果 
iW ：距離之權重値 
iDis ：計算所得的歐幾里德距離 
Y ：實際股價 
z 案例學習： 
將結果存回至資料庫中，提供未來決策的參考。 
 
 8
表 1 中發現有三支個股的其中一種類神經買賣點判斷方式在經過案例推理方法輔助判斷後，其投資報
酬較單以類神經判斷方式還要低，此三支個股包含：友達（隨機指標搭配移動平均線類神經買賣點判
斷）、晶電（隨機指標搭配移動平均線類神經買賣點判斷）及仁寶（K 線搭配威廉指標類神經買賣點判
斷），其中友達我們已經了解其獲利減少的原因，以下將觀察晶電及仁寶的實際交際紀錄，進一步觀察
獲利降低的原因所在。 
由上述結果證實，經由案例推理以動態時間搜尋方式輔助類神經網路判斷買賣點的方式，確實可以獲
得更好的投資報酬，同時可以減少買賣的交易次數。此外雖然只增加 0.4 元的價差，但是在考慮交易
手續費之後仍然可能賺取獲利，因此只要能夠準確預測股價的漲跌趨勢，就算小額價差，也可獲得一
定金額的投資報酬。 
為了證明本研究實驗結果的績效，此一小節將擷取報酬率前十名基金與本研究之研究個股實驗結果加
以比較，如表 2 所示： 
 
表 2 投資績效評比表 
個股/基金名稱  報酬率  排名 
晶電 282.49 1 
綠點 93.57 2 
友達 90.30 3 
聯電 78.46 4 
正崴 73.46 5 
矽統 65.20 6 
友訊 51.48 7 
神腦 46.62 8 
仁寶 37.75 9 
統一奔騰 37.09 10 
大眾科技 32.73 11 
富邦網路 32.71 12 
大華高科技 32.02 13 
盛華 2000 高科技 32 14 
群益創新科技 31.56 15 
永昌前瞻科技 31.08 16 
保誠電通網 30.73 17 
友邦網路商務 28.57 18 
彰銀安泰ｅ科技精選 28.44 19 
 
由表 2 看出，本研究建構之預測模型所預測出的 9 支個股其報酬率皆優於基金的報酬率。即使研究中
最低報酬率之個股「仁寶」（其報酬率為 37.75%）亦優於績效最佳的基金「統一奔騰」（其報酬率為
37.09%）。 
 
 
 
 10
 
參考文獻 
Abraham, A., and A. A. Yeung. “Integrating Ensemble of Intelligent Systems for Modeling Stock Indices,” In 
Proceedings of 7th International Work Conference on Artificial and Natural Neural Networks, Lecture Notes 
in Computer Science- Volume 2687, Jose Mira and Jose R. Alverez （Eds.）, Springer Verlag, Germany, 
pp.774-781, 2003. 
Abraham, A., B. Nath, and P. K. Mahanti, “Hybrid Intelligent Systems for Stock Market Analysis”, 
Proceedings of the International Conference on Computational Science-Part II, pp.337-345, 2001. 
Liu, Y. and X. Yao, “Evolving Neural Networks for Hang Seng Stock Index Forecast,” Proceedings of the 
2001 Congress, Vol1, pp.256-260, 2001. 
Shumeet Baluja, “Using a priori knowledge to create probabilistic models for optimization” School of 
Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA.Received 1 January 2002; 
accepted 1 July 2002. 
Patrick Celka and Elly Gysels, “Smoothly adjustable denoising using a priori knowledge” ,School of 
Engineering, Griffith University, Queensland Australia Control and Signal Processing Section, Swiss Center 
for Electronics and Microtechnology, Rue Jaquet Droz 1, 2007. 
Marko Subasi, Sven Loncari and Erich Sorantin, “Model-based quantitative AAA image analysis using a 
priori knowledge”,Faculty of Electrical Engineering and Computing, University of Zagreb, Croatia 
Department of Radiology, University Hospital Graz, Auenbruggerplatz 34, A-8036, Austria, 2005. 
Chang, P. C., C. Y. Lai, “A hybrid system combining self-organizing maps with case-based reasoning in 
wholesaler’s new-release book forecasting,” Expert Systems with Applications, Vol. 29,  pp.183-192, 2005a. 
Chang, C. L., “Using case-based reasoning to diagnostic screening of children with developmental delay,” 
Expert Systems with Applications, Vol. 28, pp.237-247, 2005b. 
Hongkyu, J., and H. Ingoo, “Integration of Case-Based Forecasting, Neural Network and Discriminate 
Analysis for bankruptcy Prediction,” Expert Systems with Applications, Vol.11, No. 4, pp.415-422, 1996.  
Lin, N. K., and K. Y. Sin, “Evaluating Cast-Based Reasoning and Evolution Stratifies for Machine 
Maintenance,” IEEE, pp.480-485, 1999. 
廖元甫，莊智顯，楊智合, “Maximum Likelihood A Priori Knowledge Interpolation-Based Handset Mismatch 
Compensation for Robust Speaker Identification”, Department of Electronic Engineering, Taipei University of 
Technology, Department of Communication Engineering, Chiao Tung University. 
 2
I was happy to build up possible research collaborations from researchers/educators over the world. I 
must say that this trip is very meaningful and productive in my current research. I would definitely hope 
to attend another conference, if possible, to build up international links. I appreciate NSC which has 
always been very encouraging and supportive to researchers who are willing and capable to step outside 
of Taiwan and embrace the coming of globalization for academic collaborations. 
三、攜回資料名稱及內容 
Conference Registration Invoice 
Conference Programs and Abstracts in book and CD-R 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The rest of the paper is organized as follows. Section 2 describes some literatures 
about relative fields. Section 3 introduces the proposed hybrid model. Section 4 
presents the experimental results and analysis. Section 5 provides conclusion. 
 
2. LITERATURE REVIEW 
Recently, with the development of the Artificial Intelligence techniques, several 
methods are found to have better performance than traditional models when applied to 
forecasting problems and Artificial Neural Networks (ANNs) are the most commonly 
used tools. After being trained by historical data, ANNs can be used to predict the 
sales in the future. Many researchers have successfully applied ANNs to solve 
forecasting related problems as in Refs. [2], [9], [10] and [11]. 
Ever since Ref. [18] introduces the concept of fuzzy logic, fuzzy-set theory has been 
widely applied in the industrial system controls that are very complex, uncertain and 
cannot be modeled precisely. The fuzzy controllers with many fuzzy control rules will 
capture the reasoning process of human operators. Especially, fuzzy rules based 
controller have been the most popular and easiest way to capture and represent fuzzy, 
vague, imprecise and uncertain domain knowledge. Traditionally, these FRBs are 
provided and extracted from domain experts. It is very difficult and time-consuming 
to obtain accurate and reasonable FRBs. In recent years, much research has been 
proposed to generate and produce FRBs from a set of sample data. An automated 
fuzzy knowledge base generation and tuning method is presented in [1]. Ref. [5] 
provides a method to construct membership functions for FRBs generation, while in 
[6] a way to process individual fuzzy attributes for fuzzy rule induction is given. A 
GA method to select fuzzy if-then rules for classification problems could be found in 
[7]. Ref. [8] proposes a method to generate FRBs from training data with noise for 
classification problems. Ref. [13] presents a method for the generation of fuzzy rule 
base and its optimization by using modified threshold accepting. Ref. [14] presents a 
method to optimize and simplify fuzzy rules. A fuzzy decision tree induction 
technique is proposed to generate fuzzy rules [17].  
According to the literature survey above, there are many methods that allow us to 
generate a set of FRB; however, these extracted rules are found to be far from optimal 
and sometimes redundant. Therefore, this paper focuses on the performance 
improvement of FRB by integrating Self Organizing Map (SOM) neural network, 
Genetic Algorithms (GA) and Weighted Fuzzy Rule Base (WFRB) to forecast the 
future sales of a printed circuit board factory. This hybrid model encompasses two 
new concepts: 1. Clustering WFRB into different sub-clusters, thus the interactions 
between fuzzy rules can be reduced and a more accurate prediction model can be 
established. 2. Evolving WFRB by optimizing the number of fuzzy terms of the input 
and output variables, thus the prediction accuracy of the WFRB is further improved. 
Features of the prediction model are adapted from our previous work [3]. In this paper, 
an extension of our previous work is proposed and a fuzzy rule base clustered by an 
SOM and evolved by a GA to predict the monthly sales of a PCB factory is developed. 
First, independent variables related to sales variation are collected and fed into the 
SOM for classification. Then, the corresponding fuzzy rule base with less interaction 
and more accuracy is selected and applied for sales forecasting. Genetic process is 
further applied to fine-tune the composition of the rule base. Finally, the generated 
hybrid model is applied as a tool for sales prediction in printed circuit board industry. 
 
 
 
Step 3: Adjust the weights of winning neuron c and all neighbor units 
 
)]()()[()()1( twtxthtwtw iciii −+=+  (2)
 
where  is the index of the neighbor neuron and  is an integer, the discrete time 
coordinate. The neighborhood kernel is a function of time and the distance 
between neighbor neuron  and winning neuron  defines the region of 
influence that the input pattern has on the SOM and consists of two parts: the 
neighborhood function 
i t
)(thci
i )(tchci
),( th  and the learning rate function )(tα , in Eq. (3). 
 
)(),()( ttrrhth icci α−=  (3)
 
where r  is the location of the neuron on two-dimensional map grids. In this work we 
used Gaussian Neighborhood Function. The learning rate function )(tα  is a 
decreasing function of time. The final form of the neighborhood kernel with Gaussian 
function is 
 
)(
)(2
exp)( 2 tt
rr
th icci ασ ⎟⎟⎠
⎞
⎜⎜⎝
⎛ −=  (4)
 
where )(tα  defines the width of the kernel. 
 
Step 4: Repeat steps 2 and 3 until the convergence criterion is satisfied. 
Figure 2 shows two different clustered diagrams: one in two clusters and the other in 
three clusters. 
 
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0 10 20 30 40 50 60
cluster1
cluster2
0.2
0.4
0.6
0.8
1
0 10 20 30 40 50 60
cluster1
cluster2
cluster3
 
Figure 2. Historical monthly sales Clustered by SOM into Two and Three clusters 
 
3.1. Fuzzy Rules Generating and Weights Evolving Stage 
The fuzzy modeling method proposed in [15] is applied for fuzzy rule generation. 
However, it has two major weaknesses: uniform partition of the domain space and 
arbitrary selection of the number of partitions. To rectify the second weakness, the 
Wang and Mendel (WM) method is evolved with genetic algorithms (GAs) and the 
idea is similar to evolving neural network presented in [12] and [16]. Essentially, a 
simple GA is used to determine the near-optimal number of fuzzy terms for each 
variable. Furthermore, the influences of different variables are needed to be 
considered, so we also adopt GA to evolve them. The framework of Weighted 
Evolving Fuzzy Rule Base (WEFRB) is shown in Fig. 3. And the detailed procedure 
of WEFRB is described as follows: 
Step3. Compute the objective value by WM method 
In this paper, we adopt triangle membership function in the WM method and the 
detailed procedures of WM method are described in Section 3.2. 
Step4. Compute the fitness function 
The original concept of fitness is “the larger the better”, because solutions with larger 
fitness tend to propagate to the next generation. This paper considers the minimization 
of objectives; hence it contradicts the original idea of fitness. A transformation should 
be made to reverse the minimization to maximization. For a solution s , its fitness 
equals to the maximum value minus itself. The formula is given as: 
 
)()( sgMaxsfit −=  (5)
 
Step5. Reproduction / Selection 
After the parameter design, the roulette wheel selection described in Goldberg [4] is 
applied in this research. The probability ( )sp  of each chromosome  will be 
chosen to re-produce as defined below: 
s
 
( ) ∑= )(
)(
sfit
sfitsp  (6)
  
Step6. Crossover 
After the parameter design, two-point crossover method is applied in the research. 
Step7. Mutation  
After the parameter design, one-point mutation method is applied in the research. 
Step8. Elite Strategy 
The elite strategy retains the top 10% solutions in order to keep the quality solutions 
of each generation. 
Step9. Replacement 
The new population generated by the previous steps updates the old population. 
Step10. Stopping criteria 
If the number of generations equals to the maximum generation number, then stop; 
otherwise go to step 3. 
 
3.2. The WM method 
Step 1. – Divide the Input and Output Spaces into Fuzzy Regions 
Given a set of examples with multiple inputs ( ) and single output, denoted as 
( , ) where
m
jkx ky mj ,...,1=  and nk ,...,1= . Define the universe of discourse of each 
input variable as [ , ] and the output variable as [ , ] and then divide each 
universe of discourse into 
−
jx
+
jx
−y +y
N  regions. 
The minimal and maximal values of each variable are often used to define its universe 
of discourse. That is, [ , ] = [ , ]. They are also considered to be 
the center of the left end term and the right end term, respectively.  That is, 
and . Accordingly, the other term center, , can be 
computed as follows: 
−
jx
+
jx )min( jx )max( jx
)min(1 jj xc = )max( jNj xc = ijc
 
)1/())min()(max()min( −−+= Nxxixc jjjij   1,...,2 −= Niwhere  (7)
 
4. EXPERIMENTAL RESULTS AND ANALYSIS 
Commercial NN and language software, such as Neural Work Professional II Plus by 
Neural Ware and Borland C++ Builder 6.0 by Borland, are applied in the experiments 
with an Intel Pentium 2.4 G hertz computer. 60 historical monthly sales data are 
divided into two parts: the first 48 monthly sales are for training data and the last 12 
monthly sales are for testing data. To test the performance of the hybrid model, the 
experiments are set up as described in the following sections: 
 
4.1. Comparisons of WM, EFRB, WEFRB and SOM+ WEFRB Models 
To test the effectiveness of the SOM in clustering the WEFRB, these 60 records of 
data are inputted into the SOM model and two different groups are generated: one is 
in two clusters and the other is in three clusters. Furthermore, the prediction accuracy 
before and after clustering is compared to demonstrate the performance improved by 
clustering rules.  
 
SOM+WEFRB Model (two-cluster) 
The fuzzy rule base clustered by the SOM into two clusters is applied to the testing 
data. The RMSE and MAPE of the test result are shown in Table 1. 
 
Table 1. RMSE and MAPE of Monthly Sales Prediction 
Using SOM+ WEFRB (two-cluster) Model 
SOM (2)+WEFRB 
 Cluster1 Cluster2 Total 
RMSE 33624.2 14682.4 25387.05
MAPE 0.034 0.019 0.025 
Time (Secs.) <2.0 <3.0 <5.0 
# of Rules 13 26 39 
 
SOM+WEFRB Model (three-cluster) 
The fuzzy rule base clustered by the SOM into three clusters is applied to the testing 
data. The RMSE and MAPE of the test result are shown in Table 2. 
 
Table 2. RMSE and MAPE of Monthly Sales Prediction 
Using SOM+ WEFRB (three-cluster) Model 
SOM (3)+ WEFRB 
 Cluster1 Cluster2 Cluster3 Total 
RMSE 12106.1 1076.0 32339.3 22465.84 
MAPE 0.014 0.002 0.036 0.022 
Time (Secs.) <2.0 <1.0 <2.0 <5.0 
# of Rules 16 16 9 41 
 
Through the data clustering process, the interaction between fuzzy rules can be 
reduced and the forecasted sales can be more accurately represented. From the 
experimental results shown in Table 3, the WEFRB is better than the EFRB when 
evolving the variable weights of WEFRB. Moreover, the comparison of WEFRB with 
and without the SOM clustering, the accuracy performance is improved in RMSE 
from 32832 down to 25387 (two clusters) and 22466 (three clusters) and in MAPE 
from 3.8% down to 2.5% (two Clusters) and 2.2% (three clusters). The rule clustering 
does reduce the interaction between rules and each forecasted output is better 
Engineering, 10, 55-61. 
[3] Chang P.C. & Wang Y.W. & Tsai C.Y. 2005. Evolving neural network for 
printed circuit board sales forecasting. Expert Systems with Applications 29(1), 
83-92. 
[4] Goldberg D.A. 1989. Genetic Algorithms in search, optimization, and machine 
learning. Reading, MA: Addison-Wesley. 
[5] Hong T.P. & Chen J.B. 1999. Finding relevant attributes and membership 
functions. Fuzzy Sets and Systems, 103(3), 289-404. 
[6] Hong T.P. and Chen J.B. 2000. Processing individual fuzzy attributes for fuzzy 
rule induction. Fuzzy Sets and Systems, 112(1), 127-140. 
[7] Ishibuchi H. & Nozaki K. & Yamaoto N. & Tanaka H. 1995. Selecting fuzzy 
if-then rules for classification problems using genetic algorithms, IEEE Trans. 
Fuzzy Systems, 3(3), 260-270. 
[8] Kao C.H. & Chen S.M. 2000. A new method to generate fuzzy rules from 
training data containing noise for handling classification problems. in Proc. 5th 
Conf. Artificial Intelligence and Applications, Taiwan, 323-331. 
[9] Krolzig H.M. & Toro J. 2004. Multiperiod forecasting in stock markets: a 
paradox solved. Decision Support Systems, 37, 531-542. 
[10] Kuo R.J. & Chen J.A. 2004. A decision support system for order selection in 
electronic commerce based on fuzzy neural network supported by real-coded 
genetic algorithm. Expert Systems with Application, 26, 141-154. 
[11] Luxh J.T. & Jens O. Riis, Brian Stensballe. 1996. A hybrid econometric-neural 
network modeling approach for sales forecasting. The International Journal of 
Production Economics, 43, 175-192. 
[12] Montana D. & Davis L. 1989. Training feed forward neural networks using 
genetic algorithms. Proceedings of 11th International Joint Conference on 
Artificial Intelligence, San Mateo, CA, Morgan Kaufmanns, 762-767.  
[13] Ravi V. & Reddy P.J. & Zimmermann H.J. 2001. Fuzzy rule base generation for 
classification and its minimization via modified threshold accepting. Fuzzy Sets 
and System, 120(2), 271-279. 
[14] Wang L.X. & Hong J. 1999. Learning optimization in simplifying fuzzy rules. 
Fuzzy Sets and Systems, 106(3), 349-356. 
[15] Wang L.X. & Mendel J.M. 1992. Generating fuzzy rules by learning from 
examples. IEEE Transactions on Systems, Man and Cybernetics, 22(6), 
1414-1427. 
[16] Yao X. 1999. Evolving Artificial Neural Networks. Proceedings of the IEEE, 
87(9), 1423-1447. 
[17] Yuan Y. & Shaw M.J. 1995. Induction of fuzzy decision trees. Fuzzy Sets and 
Systems, 69, 125-139.  
[18] Zadeh L.A. 1965. Fuzzy sets. Information Control, 8, 338-353. 
2 P.-C. Chang et al. 
The major contribution of this research is to take a different approach by evolving a 
piecewise linear representation method with Ensemble neural networks system to pre-
dict the future turning signals of a stock price. Turning signals identified by PLR are 
represented using a nonlinear relationship among the stock closed price, i.e., iy  and 
various technical indexes, i.e., ix and this nonlinear relationship will be studied inten-
sively through Ensemble neural network. In other words, local stock turning signals 
can be detected using PLR preprocessing technique. Later on, these turning signals 
governing the relationship among the stock closed price with various technical indexes 
will be inputted into the Ensemble neural network system for training. Then, the 
trained model can be applied as a universal predicator for predicting the future turning 
points in the set of test data. Finally, an investor then can apply these future signals as 
trading signals and make profits no matter short-term or long term trading decisions. 
The rest of the paper is divided into five sections. Section 2 reviews the literature 
in the areas of stock forecasting. Section 3 describes the development of an evolving 
PLR model and an ensemble neural network for stock trading point decision. Section 
4 is the experimental tests conducted to test the effectiveness of trading points gener-
ated by using the evolving PLR approach. Finally, conclusions and future directions 
of the research are provided. 
2   Literature Survey 
Prediction of a financial market is rather challenging due to chaos and uncertainty of 
the system. In the past, many statistics and artificial intelligence tools were applied to 
financial time series analysis. Kovalerchuk et al.(2000) XXclassifies the current 
methods into three categories: numerical models (ARIMA models, Instance-based 
learning, neural networks, etc.), rule-based models (decision tree and DNF learning, 
naive Bayesian classifier, hidden Markov model etc.), and relational data mining 
(inductive logic programming) ,among these approaches, soft computing techniques 
(including fuzzy logic, neural networks, Genetic  algorithms…..etc) becomes the most 
popular forecasting model in this area, because of their abilities to handle uncertainty 
and noise in a stock market. These soft computing techniques are used for quantitative 
inputs, like technical indices, qualitative factors, political effects…etc to automate 
stock market forecasting and trend analysis. Neural Network (NNS) have been ap-
plied to this area (refer to Aiken and Bsat(1994), Baba et al.(2000), Brown-
stone(1996), Chen(2003), Pendharkar(2001), Schapire(1990) X). However, these 
models have their limitations subjecting to the tremendous noise and complex dimen-
sionality of stock price data. The quantity of data itself and the input variables also 
interfere with each other. Therefore, the result may not be as convincing.  
Ensemble strategies have been used to solve Neural Network limitations in  
West et al. (2005)X inX. The basic concept of the ensemble method is that diverse 
perspective on different aspects of a problem can be combined to produce a high 
quality. The most important three strategies have been advanced for forming ensem-
bles of predictors. That includes Cross-validation, Bagging ensembles and Boosting. 
Cross-validation is the simplest ensemble rule which used in ensemble all methods 
are trained with the same data.  
4 P.-C. Chang et al. 
and 5. Marginal cost of capital (MCC). According to those indices, 7 stocks has been 
selected in this research.  
3.2   Generating an Initial Threshold 
An initial threshold is generated randomly for PLR in time series data segmentation. 
3.3   Use PLR to Segment the Stock data 
PLR is used to segment the selected stock data using the initial threshold generated in 
step 1. The stock data segmented will be transformed into trading signals. From the 
previous study in  Abu-Mostafa(1996) and Baba et al (2000)X, trading points of 
stocks are observed from the variation of technical indexes. This study attempts to 
develop an intelligent trading point prediction system. Investors can make a good 
trading strategy by applying this intelligent model. This study takes a different ap-
proach by using PLR to decide the trough or peak of the historical data and based on 
these trading points.The main procedures of PLR in predicting the trading point has 
been shown in our previous workX0Xand pseudo code describe as follows:(show in 
Fig2). 
 
Fig. 2. The pseudo code of the PLR 
3.4   Input Variables Selection Using Stepwise Regression Analysis (SRA) 
As shown in TABLE 1, a set of technical indices affecting the stock price movement 
have been identified by Chang, et al. (2004)(2008). These input factors will be further 
selected using Stepwise Regression Analysis (SRA) model.  
 
Procedure BuildTree (S). 
Input: A financial time series S. 
Let S be represented as x[1..n], y[1..n]. 
If (Max (y[1..n] == y[1] OR Max (y[1..n] == y[n]) 
OR Min (y[1..n] == y[1] OR Min (y[1..n] == y[n])) 
Create a node in the hierarchy for this segment; 
Draw a line between (x[1],y[1]) and (x(n), y(n)); 
Max d = maximum Euclidean distance of (x[i],y[i]) to the line; 
If (Max d < threshold ( δ )) 
This segment is good enough; no further work 
Else 
Let (x[j],y[j]) be the point with maximum Euclidean distance to the line. 
Break the segment S into S1 and S2 at the point (x[j],y[j]); 
PARENT (S1) = S; 
PARENT (S2) = S; 
BuildTree (S1); 
BuildTree (S2); 
End If 
Else 
Break the segment at the maximum and/or minimum point(s) into smaller ones S1,..., Sm; 
For i = 1 to m 
PARENT (Si) = PARENT (S); 
End For 
Delete (S); 
For i = 1 to m 
BuildTree (Si) 
End For 
End If
6 P.-C. Chang et al. 
finally, AdaBoost linearly combines all the component methods into a single final 
hypothesis f. Greater weights are given to component methods with lower training 
errors. The pseduo code of Adaboost is described as follows: 
 
Fig. 3. The pseduo code of Adaboost 
Through this process, we can keep the best models weight and earn most profit in our 
hybrid system. But how to generate profits using BPN & ENN  After generate the 
sub-segments by using PLR, the trading signals need to be transformed into 0 or 1 
before they are fed into ensemble models (includes BPN &ENN). By adopting PLR, 
the sub-segments will be divided and the trends of time series data are defined as 
follows: 
, ,iIf trend upwardC C δ≥ + =  
   
, ,iIf trend downwardC C δ≤ − =  
         
, ,i i trend steadyIf C C Cδ δ< < + =−  
(1) 
Where, iC  means the stock price of the i-th turning points; and C is the stock price of 
the current turning points; δ  means the threshold for judging the trend of stock price. 
And the trend will be transferred as output value of our BPN. If the trend changes 
from up to down, the trading signal will be changed from 0 to 0.5;  If the trend 
changes from down to up, the trading signal will be changed from 1 to 0.5; otherwise, 
the signal will not be changed. 
However, the above definition of trading signal is not quite related to the price 
variation. A trading signal should be able to reflect the price variation and provide 
more inside information for investor to make a precise decision for stock trading. 
Therefore, we redefine the trading signals according to the tendency of the stock and 
it is shown in as follows: 
If a stock is on up-trend 
1 2
1 2 1 2
min{ , , }
0.5.
max{ , , } min{ , , }
i i i i
i
i i i i i i
C C C C
t
C C C C C C
+ +
+ + + +
−
= ⋅
−
⎡ ⎤⎢ ⎥⎣ ⎦
 
(2) 
Input : D , a set of d class-labeled training tuples 
       k , the number of rounds 
       a classification 
Output : A composite model 
Method : 
(1) Initialize the weight of each tuple in D to 1/d 
(2) for i :=1 to k do 
(3)     sample D with replacement according to the tuple weights to obtain DBiB ; 
(4) use training set DBiB to derive a model , MBiB ; 
(5) computer error(MBiB) , the error rate of MBiB ; 
(6)     if error(MBiB) > 0.5 then  
(7)         reinitialize the weights to 1/d 
(8)         go back to step 3 and try again ; 
(9)     endif 
(10)     for each tuple in Di that was correctly classified do  
(11)         multiply the weight of each by error(MBiB)/(1-error(MBiB)) ; 
(12)     normalize the weight of each tuple ; 
(13) endfor
8 P.-C. Chang et al. 
All it  values will be fed into ensemble model for training the network to learn the 
best connection weights. After the training process, the outputs of ensemble models 
([0.0, 1.0]) need to be transformed into trading decision in the testing period. In this 
study, the average of it  in training stage will be regarded as the boundary when make 
a trading decision as shown in Table 2 . In the case example, 0.50 is the boundary. 
4   Numerical Examples 
Seven different stocks are selected for performance comparisons of the system in this 
study. All these stocks were chosen by Dow Jones Industrial Average (DJIA). These 
stocks span different industries and thus offer an opportunity to test our ensemble 
neural network on stock data. These companies include B.A. (Boeing, Aerospace & 
Defense), Google, C.A.T (Caterpillar, Commercial Vehicles &Trucks), D.D (DuPont 
Commodity, Chemicals), G.M (General Motors Automobiles), IBM (IBM, Computer 
Services), MSFT (Microsoft, Software) and the overall comparison of all instances 
will be presented in Table 3. In this research, we take IPLR in Chang  et al (2008) X and 
Genetic Program in Mallick et al .(2008) inas our comparison benchmarks.  
Table 3. The overall comparisons of ENNPLR, Genetic Program X0X, and IPLR X0X in Rate 
of Profit 
Stocks ENN-PLR GPX IPLRXX 
B.A 166.93% -63.79% 95.52% 
Google 39.74% N/A 25.23% 
CAT 51.49% -33.96% 45.16% 
D.D 12.69% 122.79% 10.12% 
GM 149.12% 102.93% 4.13% 
IBM 103.08% 522.36% 59.62% 
MSFT 110.65% -89.92% 62.16% 
 
Fig. 5. The trends of CAT in steady-state 
Through this table comparison, our system shows very exciting results in B.A., 
Google, MSFT. GM.The profit gains in other stocks do not perform very well and 
there are still rooms for our proposed model to improve.  The reason for this partly is 
10 P.-C. Chang et al. 
9. Chang, P.C., Wang, Y.W., Yang, W.N.: An Investigation of the Hybrid Forecasting Mod-
els for Stock Price Variation in Taiwan. Journal of the Chinese Institute of Industrial Engi-
neering 21(4), 358–368 (2004) 
10. Chen, A.S., Leung, M.T., Daouk, H.: Application of Neural Networks to an Emerging Fi-
nancial Market: Forecasting and Trading the Taiwan Stock Index. Computers and Opera-
tions Research 30, 901–923 (2003) 
11. West, D., Dellana, S., Qian, J.: Neural network ensemble strategies for financial decision 
applications. Computers and Operations Research 32(10), 2543–2559 (2005) 
12. Hansen, L.K., Salamon, P.: Neural network ensembles. IEEE Transactions on Pattern 
Analysis and Machine Intelligence 12, 993–1001 (1990) 
13. Pendharkar, P.C.: An empirical study of design and testing of hybrid evolutionary-neural 
approach for classiffcation. Omega-International Journal of Management Science 29,  
361–374 (2001) 
14. Schapire, R.E.: The strength of weak learnability. Machine Learning 1990.5, 197–227 
(19905) 
15. Henley, W.E., Hand, D.J.: A k-nearest neighbor classi&er for assessing consumer credit 
risk. Statistician 996.44, 77–95 (1990) 
16. Jensen, H.L.: Using neural networks for credit scoring. Managerial Finance 18, 15–26 
(1992) 
17. Zhou, M., Wei, H.: Face Verification Using GaborWavelets and AdaBoost. In: The Eight-
eenth International Conference on Pattern Recognition, Hong Kong, pp. 404–407 (2006) 
18. Sun, Y., Wang, Y., Wong, A.K.C.: Boosting an associative classifier. IEEE Trans. Knowl-
edge and Data Engineering 18, 988–992 (2006) 
19. Jangmin, O., Lee, J.W., Park, S.B., Zhang, B.T.: Stock Trading by Modelling Price Trend 
with Dynamic Bayesian Networks. In: Yang, Z.R., Yin, H., Everson, R.M. (eds.) IDEAL 
2004. LNCS, vol. 3177, pp. 794–799. Springer, Heidelberg (2004) 
20. Mallick, D., Lee, V.C.S., Ong, Y.S.: An empirical study of genetic programming generated 
trading rules in computerized stock trading service system. In: 5th International Confer-
ence Service Systems and Service Management - Exploring Service Dynamics with Sci-
ence and Innovative Technology, ICSSSM 2008 (2008) 
 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：劉鎮豪 計畫編號：98-2221-E-424-003- 
計畫名稱：智慧型計算於知識萃取之整合研究--子計畫一:開發基於先導知識之混合模式於知識萃取之
研究(I) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 5 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
