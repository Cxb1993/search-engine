  During these three years, four techniques based on indexing system have been developed by us 
to help biologists to solve several biological problems, such as DNA or protein signatures and 
consensus substrings finding problem, protein function prediction, protein classification and 
genome re-sequencing problem.   
 
In the first year, we surveyed a lot of papers for designing an efficient indexing algorithm by 
utilizing the mutant graph to solve Unique Signature Discovery and consensus strings finding 
problems.  The algorithm was well-defined and it has been divided into two sub-kernels, USD and 
IMUS algorithms.  USD can be used to find unique signatures out from a set of DNA sequences 
and IMUS can be used to solve the large-scale data set problem.  These two algorithms are 
generally called as USD algorithm or USD.  By using USD, it can be useful to aid biologists to 
design PCR primers in biological experiments.  Besides, due to the special characteristic of the 
mutant graph, it can be also used to search consensus substrings conveniently.  Finally, USD 
algorithm was implemented as a standalone C program and we did experiments to test the 
performance of our algorithm.  It shows that our method outperforms than other existing methods. 
 
In the secondary year, in view of protein function prediction is also the important subject for 
many molecular biologists. In this year, we had also finished proposing a novel method, called 
Geometric Suffix Tree (GST), for protein function prediction based on both sequences and 3-D 
structure information, and apply our method to actual data for enzyme prediction.  The major spirit 
of our algorithm is to build an efficient suffix tree algorithm in 3-D space to be as indexing 
structures. By using GST, we can find common 3-D structures, common longest 3-D structures, and 
any problem can be solve by using original 2-D suffix tree. By cooperating with the Tokyo 
university laboratory, we used GST to extract the 3-D motifs as features.  With these features, the 
Support Vector Machine (SVM) was utilized to obtain predictors (or models) by training the actual 
dataset and these predictors can be adopted to predict protein functions from a protein with 
unknown functions.  The results indicate our approach is better than other existing methods. 
 
As we know that protein structure classification keeps key clues for us to predict protein 
functions. Hence, in the third year, a first level indexing system, a complete network based on 
sequence identity, secondary identity, and RMSD, had been built and we utilized this network to 
develop an alignment approach based on best-hit strategy methodology to classify the TIM barrel 
protein structures.  The important contribution of this method is that our method is a simple and 
vital method to classify TIM barrel protein structures even if using only amino acid methods.  This 
method and its experimental results were published on Computational Models for Life Science 
The report for the first year project 
 
中文摘要 
 
表現序列標誌被廣泛地使用在發現新的
基因上，特別是牽涉到人類疾病過程的基因。
在表現序列標誌資料庫當中，一段子序列僅
出現在一條表現序列標誌的序列中卻沒有出
現在其他的表現序列標誌序列中，則稱此子
序列在這個表現序列標誌資料庫中是具有唯
一性。此具唯一性的子序列被看作是用來分
別EST的特徵，並且提供在應用上有價值的
資訊，例如聚合酶鏈式反應引子設計與微陣
列實驗等應用。在此期中報告中，我們設計
了IMUS與USD兩種演算法，來採擷EST資料
庫中的具唯一性特徵片段。IMUS適用在搜尋
大小足以放入記憶體中的EST資料庫，而
USD演算法則被當成核心程序來搜尋全基因
體規模的EST資料庫。除此之外，我們亦採
取一種以突變圖與頻率為基礎的過濾技術來
避免不必要的字串比對，與以前的演算法比
較，我們的方法有意義地降低了耗時的字串
比對。用一般的電腦做實驗，我們發現使用
我們方法僅需要花費35秒來找尋1.4M大小的
人類染色體Y EST中具唯一性的特徵片段，
並且僅花一天的時間來採擷156M的人類染
色體11 EST資料庫中具唯一性的特徵片段。
我們已經為此計劃採用了基本網路服務介面，
稱為基因體瀏覽器。此基因體瀏覽器是一個
很好用的視覺化工具，並且將會被應用在後
來的研究上。 
 
關鍵詞: 具唯一性特徵搜尋, 突變圖, 全基
因體表現序列標誌資料庫, 聚合酶鏈式反應
引子設計, 基因體瀏覽器。 
 
 
Abstract 
 
ESTs (Expressed Sequence Tags) are 
widely used for the discovery of new genes, 
particularly those involved in human disease 
processes. A subsequence in an EST dataset D 
is unique if it appears only in one EST 
sequence of D but does not appear in any other 
EST sequence of D. Unique subsequences can 
be regarded as signatures that distinguish an 
EST from all the others, and provide valuable 
information for many applications, such as 
PCR primer designs and microarray 
experiments. In this midterm report, we have 
designed two efficient algorithms, IMUS and 
USD, to extract unique signatures from the 
EST database. IMUS algorithm is designed for 
a small EST dataset which can be handled in 
the internal memory, while USD algorithm uses 
IMUS as a kernel routine to process the EST 
dataset of whole-genome scale. Moreover, we 
adopt a frequency-based filter to avoid 
unnecessary string comparisons. Comparing to 
the previous algorithm, the amount of costly 
string comparisons required in our methods are 
reduced significantly. Based on the 
experiments in a regular PC platform, our 
approach runs only 35 seconds to discover the 
unique signatures from human chromosome Y 
ESTs of 1.4M bases, and extracts all unique 
signatures from human chromosome 11 EST 
dataset of 156M bases in one day. Elementary 
web service interface, called Genome browser, 
has been adopted for this project. It is an useful 
and friendly tool for visualization, and will be 
utilized in the later research work. 
 
Keywords: Unique Signature Discovery, 
Mutant Graph, Whole-Genome EST Database, 
PCR Primer Design, Genome Browser. 
 
 
1. Introduction 
 
The era of high-throughput cDNA 
sequencing was initiated in 1991 by a landmark 
study from Venter and his colleagues [1]. The 
basic strategy involves selecting cDNA clones 
at random and performing a single, automated, 
sequencing read from one or both ends of their 
inserts. They introduced the term "Expressed 
Sequence Tags" (ESTs) to refer to this new 
class of sequence, which is characterized by 
being short (usually 200-700 bases). ESTs were 
found to be an invaluable resource for the 
discovery of new genes, particularly those 
involved in human disease processes [2, 3]. The 
EST databases, such as the well-known dbEST 
approach follows that used in [30]. Based on 
the fact that the maximum mismatch threshold 
in the signature-finding problem is usually 
small, e.g. 4 or 5 nucleotides, we design an 
internal memory-based discovery algorithm. 
We will use sliding windows to segment 
sequences, and utilize the frequency vector 
technique [32] to compute frequency distance 
between two segments within the internal 
algorithm in this midterm report. Our frequency 
distance is different to that in [32]. Basing on 
unique signature finding problem, we discovery 
two suitable and significant properties to build 
our frequency distance function and it will be 
shown in the following sections, and then using 
this frequency distance function with these 
properties to construct a mutant graph to filter 
out some impossible unique signature 
candidates. Its external memory-based 
extension for large-scale dataset is also 
provided. The key idea underlying our 
approach is that the unique signatures emerge 
after all non-unique ones are marked and 
eliminated. Instead of finding the unique 
signatures directly, we focus on the efficient 
identification of the non-unique patterns 
 
 
2. Research goal 
 
The goal in the midterm report is to design 
efficient algorithms to unique signature 
discovery, to collect UniGene/ESTs database 
for human, mouse, rat, yeast, and to set up 
elementary web-base platform. 
 
 
3. Research method 
 
3.1 Unique signature discovery algorithm 
 
We have designed internal and secondary 
memory-based algorithms for unique signature 
discovery. The internal memory-based unique 
signature discovery algorithm (IMUS) is the 
major kernel to extract all unique patterns from 
the given small dataset, and we propose a 
secondary memory-based unique signature 
discovery approach (USD) based on the 
internal algorithm to extract whole-genome 
EST databases. The details are discussed below. 
 
3.2 IMUS 
 
To extract all unique patterns from the 
given dataset, we propose an efficient IMUS 
method here. We call a pattern duplicated if it 
is not an unique signature. Since the unique 
patterns emerge after all duplicated ones are 
marked and eliminated, we can focus on the 
problem of identifying the duplicated patterns 
efficiently instead of finding the unique 
signatures directly. With the discovery 
efficiency on mind, we separate the dissimilar 
patterns as early as possible to guarantee the 
costly string comparisons performed only on 
the potentially similar patterns. We partition the 
patterns within the dataset into clusters in 
which the patterns share some levels of 
similarity. A directed and weighted graph 
called mutant graph is constructed over the 
clusters to indicate their neighborhood 
relationships. Based on the string frequency, 
we have established a frequency-based filter to 
further avoid the unnecessary comparisons. 
IMUS is composed of two steps, and these two 
steps are described as follows. 
 
Step 1: Convert Dataset to Mutant Graph 
 
Without loss of generality, we assume that 
l is a multiple of 2. Let p be an l-pattern. The 
notation p[i, j] is used to indicate the substring 
from the i-th character to the j-th character in p, 
where i≦j. We call p[1, l/2] the head seed of p 
and p[l/2+1, l] the tail seed respectively. The 
head and tail seeds of a pattern are the 
counterparts to each other. We call a group of 
patterns sharing the identical seed string the 
pattern cluster. The seed string s shared by the 
patterns resided in cluster v is referred to as the 
dispatch seed of v, and v is the corresponding 
cluster of s. We define cluster distance, denoted 
by CD(v, u), between two clusters v and u to 
the Hamming distance between the dispatch 
seeds of v and u. By encoding each character in 
the alphabet set Σ with a distinct 2-bit value, 
the dispatch seed of a cluster can be translated 
to an l-bit unique integer. This number is 
referred to as ID of the cluster, and denoted by 
ID(v) for the cluster v. Let R denote a 
collection of l-patterns. We say a set 
C={C1,C2, : : : ,Cn} of pattern clusters is the 
complete cluster set of R if the following 
3.4 Elementary web service interface – 
Genome Browser 
 
The generic genome browser displays 
genomic annotations as interactive web pages 
using the Bio::Graphics package. It supports 
scrolling, zooming, ID or full-text search of 
annotations, and third party annotation. It is 
equally suitable for genomes in early stages of 
sequencing, "rough draft" genomes, and 
finished genomes. It is highly configurable, and 
will remember the user's preferences between 
visits. 
The Generic Genome Browser [33] is a 
combination of database and interactive web 
page for manipulating and displaying 
annotations on genomes. The web browser has 
the following features. 
 
 (1)Visualization of plain text DNA 
sequence and genome annotation 
information. 
(2)Overview and detailed views of the 
genome. 
(3)Interactively for user scroll, zoom, 
center. 
(4)Attach arbitrary URLs to any 
annotation. 
(5)Order and appearance of tracks are 
customizable by administrator and 
end-user. 
(6)Search by annotation ID, name, or 
comment. 
(7)Supports third party annotation 
using GFF formats. 
(8)Settings persist across sessions. 
(9)DNA and GFF dumps. 
 
We have obtained NCBI UniGene [34, 35] 
resources: a largely automated analytical 
system for producing an organized view of the 
transcriptome, with organism Human and 
mouse. 
UniGene data is source from EST data, we 
could say UniGene is assemble and cluster 
result from EST with in an organism, which 
help identify gene index number and build an 
representative transcript in each gene in an 
organism, using UniGene means using unique 
transcripts in an organism, unlike EST, too 
many redundancy and overlap, which hardly 
could find signature patterns in it. 
Using generic genome browser, we could 
localize various public genome annotation 
resources into one place, integrate our biology 
knowledge together, second, signature pattern 
results should be display where it occur in a 
gene or it’s relation with gene, and the gene 
function or annotation information should be 
easily linked from the display track, third, 
dumping DNA sequence or GFF feature could 
be important for user to cross validate the result 
with other tools or annotation tools , last, 
annotation information could be set a track to 
calculate in real time fashion could facilitate 
our understanding between signature and the 
statistic. 
We feed UniGene and genome relation 
information from NCBI Genbank [36,37] 
annotation, and need to convert all Genbank 
format into GFF format, then feed into mysql 
db, like Figure 1 shows. 
 
 
4. Experiment Results 
 
Our experimental platform is a PC of Red 
Hat Linux release 9, equipped with one XEON 
2.8GHz CPU, 1GB DDR memory, and 80GB 
disk space. All programs are coded in ANSI C, 
and compiled by GCC. The datasets employed 
in our experiments are human chromosome 
ESTs from NCBI. Before discovery, we clean 
the datasets by discarding all universal 
characters, for example the 'don't care,' and the 
EST sequences that are shorter than 36 bases. 
The sizes of datasets employed in our 
experiments are listed in Table 1. 
The use of pooled oligo-probes for EST 
library, for example BAC library, screening 
generally has length from 24 to 40 bases [38]. 
Our experimental results on unique signatures 
discovery with exact-match criteria also shows 
that human EST sequences can be distinctly 
labeled by signatures of length greater than 18 
bases. Given these ranges, we focus on the 
signatures of length l=24 and 36 with the 
maximum mismatch thresholds d=4 and 5 in 
our experiments. We make simulations on 
human chromosome ESTs under different 
combinations of l and d, and measure the 
amount of costly character comparisons 
required in the USD and UO approaches. The 
5. Research result evolution 
 
In the first year, there are twelve goals for 
us to finish. About 60% works have been 
finished. We have collected and built EST 
databases for human, mouse, yeast, and 
Ganoderma lucidum. In addition, the integrated 
efficient internal-based and external-based 
unique signature discovery algorithm has been 
developed to discover unique signature, and the 
system has also been built. We have also 
designed a performance evaluation module to 
implement and evaluate our unique signature 
discovery algorithm. The elementary web 
services interface has also been framed. 
In the future, we will proceed to the 
following works. (1) Build EST signature 
databases of human, mouse, yeast, and 
Ganoderma lucidum. (2) Continue to do system 
stability testing and evaluation. (3) Study 
papers related to data indexing system. (4) 
Build data indexing system for EST database. 
(5) Libraries and Application User Interface 
designed. (6) Establish unfinished web services 
interface for unique signature discovery 
Because unique signatures can be 
considered as a landscape that distinguishes an 
EST from all the others, so an important 
application of those unique signatures is to be 
used in PCR primer design and microarray 
experiments. 
 
 
Reference 
 
[1]. M. D. Adams, J. M. Kelley, J. D. Gocayne, 
M. Dubnick, M. H. Polymeropoulos, H. 
Xiao, C. R. Merril, A. Wu, B. Olde, and R. 
F. Moreno, et al., “Complementary DNA 
sequencing: expressed sequence tags and 
human genome project,” Science, vol.252, 
1991, pp.1651-1656. 
[2]. J. M. Sikela and C. Auffray, “Finding new 
genes faster than ever,” Nat. Genet., vol.3, 
1993, pp.189-191. 
[3]. M. S. Boguski, C. M. Tolstoshev, and DE. 
JR. Bassett, “Gene discovery in dbEST,” 
Science, vol.265, 1994, pp.1993-1994. 
[4]. M. S. Boguski, T. M. Lowe, and C. M. 
Tolstoshe, “dbEST: database for “expressed 
sequence tags,” Nat. Genet., vol.4, 1993, 
pp.332-333. 
[5]. D. A. Benson, I. Karsch-Mizrachi, D. J. 
Lipman, J. Ostell, B. A. Rapp, and D. L. 
Wheeler, “GenBank,” Nucleic Acids Res., 
vol.30, 2002, pp.17-20. 
[6]. J. Burke, H.Wang, W. Hide, and D. B. 
Davison, “Alternative gene form discovery 
and candidate gene selection from gene 
indexing projects,” Genome Res., vol.8, 
1998, pp.276-290. 
[7]. D. Gautheret, O. Poirot, F. Lopez, S. Audic, 
and J. M. Claverie, “Alternate 
polyadenylation in human mRNAs: A 
large-scale analysis by EST clustering,” 
Genome Res., vol.8, 1998, pp.524-530. 
[8]. L. Picoult-Newberg, T. E. Ideker, M. G. 
Pohl, S. L. Taylor, M. A. Donaldson, D. A. 
Nickerson,and M. Boyce-Jacino, “Mining 
SNPs from EST databases,” Genome Res., 
vol.9, 1999, pp.167-174. 
[9]. A. O. Schmitt, T. Specht, G. Beckmann, E. 
Dahl, C. P. Pilarsky, B. Hinzmann, and A. 
Rosenthal, “Exhaustive mining of EST 
libraries for genes differentially expressed 
in normal and tumour tissues,” Nucleic 
Acids Res., vol.27, 1999, pp.4251-4260. 
[10]. K. Tanabe, S. Nakagomi, S. Kiryu-Seo, K. 
Kiryu, Y. Kiryu, T. Kiryu, M. Kiryu, and H. 
Kiyama, “Expressed-sequence-tag approach 
to identify differentially expressed genes 
following peripheral nerve axotomy,” Mol. 
Brain Res., vol.64, 1999, pp.34-40. 
[11]. B. M. Kiryu and C. P. Kiryu, “Rapid 
identification of Candida albicans and other 
human pathogenic yeasts by using 
oligonucleotides in a PCR,” J. Clin. 
Microbiol., vol.73, 1998, pp.1634-1641. 
[12]. R. Sandberg, G. Winberg, C. I. Branden, 
A. Kaske, I. Ernberg, and J. Coster, 
“Capturing whole-genome characteristics in 
short sequences using a naive Bayesian 
classifier,” Genome Res., vol.11, 2001, 
pp.1404-1409. 
[13]. S. Karlin and C. Burge, “Dinucleotide 
relative abundance extremes: a genomic 
signature,” Trends Genet., vol.11, 1995, 
pp.283-290. 
[14]. P. J. Deschavanne, A. Giron, J. Vilain, G. 
Vilain, and B. Fertil, “Genomic signature: 
characterization and classi_cation of 
species assessed by chaos game 
representation of sequences,” Mol. Biol. 
Evol., vol.16, 1999, pp.1391-1399. 
The report for the secondary year project 
 
中文摘要 
 
隨著 DNA 與蛋白質資料庫成指數倍數
成長以及所存取資料量的增加，對於特徵標
誌序列搜尋此重要生物問題，本計畫已完成
DNA 與蛋白質特徵標記搜尋演算法的設計
並建立出一套資料索引系統，此資料索引系
統是運用過濾方法來過濾掉不可能的候選特
徵標記，經由此過濾方法來縮短計算的時間
複雜度，以便加速後來查詢的速度。除了特
徵標記搜尋之外，蛋白質功能預測亦是許多
分子生物學家所關注的議題，在本計劃中，
我們已透過蛋白質序列以及三級結構所提供
的線索，對蛋白質功能預測提出了一個新的
方法，並應用在酵素資料的預測上，探索結
合排比方法以及運用幾何字尾樹此資料索引
結構所產生的特徵向量，來區分酵素與非酵
素資料。我們的方法是使用蛋白質序列以及
三級結構所取得的特徵值，運用支持向量機
來預測蛋白質功能。酵素與非酵素資料集的
實驗結果顯示平均精確度高於 85%，此方法
比其他僅使用序列資訊的方法還好，這亦顯
示出在蛋白質功能預測上，結合更多有價值
的蛋白質結構資訊的重要性。 
 
關鍵詞: 特徵標記搜尋、資料索引系統、蛋
白質功能預測、幾何字尾樹、支持向量機。 
 
 
Abstract 
 
With exponentially increasing sizes and 
accesses of DNA and protein databases, we 
have finished designing the algorithms and 
building a data indexing system for DNA and 
protein unique signature finding in this project. 
It utilizes the filtration approaches to filter 
impossible candidates for unique signature. By 
using the filtration approaches to reduce time 
complexity, it speeds up the query subsequently. 
In addition to the unique signature finding, 
protein function prediction is also the important 
subject for many molecular biologists. In this 
project, we have also finished proposing a 
novel method for protein function prediction 
based on both sequences and 3-D structure 
information, and apply our method to actual 
data for enzyme prediction. We explore the 
capability of telling enzymes from 
non-enzymes by combining good features of 
alignment-based method and a newly proposed 
structure-based approach utilizing Geometric 
Suffix Tree. Our method predicts protein 
functions by training the SVM (Support Vector 
Machine) with the information derived from 
these two approaches. The experiments on 
enzyme and non-enzyme dataset show that the 
average accuracy is above 85%, which is better 
than the approaches with only sequence 
information. It reveals that the importance of 
combining more valuable protein structure 
information for protein function prediction. 
 
Keywords: unique signature finding, data 
indexing system, protein function prediction, 
Geometric Suffix Tree, Support Vector 
Machine. 
 
 
1. Introduction 
 
A unique signature can be considered as a 
landscape that distinguishes an EST from all 
the others. Unique signatures are particularly 
valuable as locus-specific PCR primers for 
placement of ESTs at single positions on a 
genetic linkage map, on microarrays for studies 
of the expression of specific genes without 
signal interference from other genes, and to 
probe genomic libraries in search of specific 
genes. Specific oligonucleotides have already 
been used in a PCR method for the 
identification of 14 human pathogenic yeast 
species [1]. This raises the question of whether 
it is possible to find a short, specific DNA 
sequence for every yeast species. Such DNA 
sequences would facilitate the design of 
specific PCR primers for purpose of identifying 
yeasts. Additionally, knowledge of 
distinguishing features of yeast species at the 
molecular level may provide a deeper 
understanding of the biology of these 
organisms and the evolution of the gene being 
studied. An unique defining sequence pattern 
can thus be regarded as a sequence pattern, 
d-mutant of q (p). We use p ≈l,d q to indicate p 
and q are (l,d)-mismatched. Let D = {y1, 
y2,…,yk} denote the input dataset, where the 
generic string yi, 1 ≦  i ≦  k, is an EST 
sequence over the alphabet set Σ. An l-pattern 
p ⊆  yi is referred to as a unique signature in 
D if there is no other l-pattern q in D such that 
q is a d-mutant of p. That is, {q|q ≈l,d p, q ⊆  yj, 
yj ∈  D for i≠j} = φ;. The unique signature 
discovery is to extract all unique patterns from 
the input database. 
 
A.1 Convert Dataset to Mutant Graph 
 
Let p be an l-pattern. The notation p[i, j] is 
used to indicate the substring from the i-th 
character to the j-th character in p, where i ≦ 
j. We call p[1,l/2] the head seed of p and p[l/2 
+ 1; l] the tail seed.  
The head and tail seeds of a pattern are the 
counterparts to each other. We call a group of 
patterns sharing the identical seed string the 
pattern cluster. The seed string s shared by the 
patterns resided in cluster v is referred to as the 
dispatch seed of v, and v is the corresponding 
cluster of s. Cluster distance be denoted by 
CD(v, u), between two clusters v and u to the 
Hamming distance between the dispatch seeds 
of v and u. 
By encoding each character in the 
alphabet set Σ with a distinct 2-bit value, the 
dispatch seed of a cluster can be translated to 
an l-bit unique integer. This number is referred 
to as ID of the cluster, and denoted by ID(v) for 
the cluster v. 
Let R denote a collection of l-patterns. It is 
said a set C = {C1,C2, … ,Cn} of pattern 
clusters is the complete cluster set of R if the 
following criteria are satisfied, (1) ni 1=U Ci = R, 
(2) for each p∈R, p is in Ci if the head or tail 
seed of p is identical to the dispatch seed of Ci
∈C, (3) {s|s is a seed of p 2 R} = {t|t is the 
dispatch seed of Ci∈C} and (4) the dispatch 
seeds of Ci and Cj are not identical if Ci ≠ Cj 
and Ci, Cj∈C. The notation vu  denotes the 
directed link from cluster v to cluster u, and the 
weight of vu  is set to the cluster distance 
between v and u. A mutant graph over R is a 
directed and weighted graph consists of the 
complete cluster set of R and a link set. It 
represents the neighborhoods among the 
clusters. We use the shorthand G(C, E, l, d) to 
denote the mutant graph over R, where C is the 
complete cluster set of R and E = { vu  |CD(v, 
u) ≦ ⎣ ⎦2d ; ID(v) ≦ ID(u); and v; u∈C}. u 
is called a neighbor of v in the mutant graph 
G(C,E, l, d) if vu  exists in E. 
To construct the mutant graph, it will first 
be retrieved the set R of all l-patterns from the 
input dataset. Then, by using the head and tail 
seeds as dispatch pivots, the patterns in R will 
be filed into its complete cluster set C. Since a 
pattern contains two seeds, in general, the 
pattern will reside in two clusters at most after 
the dispatch. It is said two patterns are twins if 
they are the copies of same pattern. The link set 
E is initially empty. Assume s is the dispatch 
seed of a cluster v∈C, It will be find the set T 
of all existing dispatch seeds such that t∈T is a 
⎣ ⎦2d -mutant of s. Suppose u is the 
corresponding cluster of t∈T. If neither vu  
nor uv  exists, we compare the IDs of u and v. 
If ID(v) ≦ ID(u), a directed link vu  with 
weight HD(s,t) is established; Otherwise uv  
with weight HD(s,t) is created. We update E by 
the new link. 
 
A.2 Frequency-Based Filter 
 
Let cpF indicate the number of 
occurrences of c∈Σ in an l-pattern s, and Fs = 
{ AsF ,
C
sF ,
G
sF ,
T
sF } to denote the frequency 
vector of s. The frequency distance between 
two l-patterns p and q is defined as: 
 
2
|| cq
c
pc FFFD
−Σ= Σ∈  
where |x| = x if x ≧ 0, -x otherwise.  
 
A.3 Partition Datasets into Runs 
 
Let D = {y1, y2, …, yk} be the input 
database, where yi, 1 ≦ i ≦ k, denotes an 
EST sequence with length |yi|. A segment is a 
substring of the EST sequence of specified 
length, and a segment of length w is referred to 
as the w-segment. A run is an arranged 
partition of the input database, which consists 
substructure similar to Mi. If these two values 
are significantly different for Mi, we consider 
Mi is important. Hence we claim that Mi is valid 
if it satisfies the following expression. The 
following expression shows the log level 
probability difference between enzyme and 
non-enzyme. Ne, and Nne are the total number 
of enzyme and non-enzyme protein structures 
we used in the datasets we used. ne and nne are 
enzyme and non-eyzme structures that have 
substructures similar to Mi. θ is the heuristic 
threshold assigned manually. In the later 
experiment, we set the θ to 0.1. It is obvious 
that the probability of enzymes must be 
significant different from the probability of 
non-enzymes. If Mi satisfies the condition, then 
we claim Mi is valid. Otherwise, it is 
considered a non-valid node. 
 
θ<⎟⎟⎠
⎞
⎜⎜⎝
⎛
+
+−⎟⎟⎠
⎞
⎜⎜⎝
⎛
+
+
1
1log
1
1log
ne
ne
e
e
N
n
N
n  
 
phase (2) Removal of unnecessary nodes 
Assume that u is a node in GST. If all the 
children of u are valid, then node u is 
considered as a non-valid node. Good features 
are designed to be independent to each other in 
the SVM, so we can delete the features that are 
dependent with some other features. In the case, 
the feature of a parent node in GST can be 
predicted by the children nodes. In other words, 
if all the children nodes are valid, the parent 
node should be valid. It is the redundant 
information, so we can discard it. 
 
phase (3) The threshold for the GST depth 
It is known that the catalytic sites are not 
so long. Hence we ignore too long candidate 
3-D motifs, for example, whose length less than 
15. If the threshold is over 20, the total valid 
nodes will over ten thousand. By applying 
above three phases, the average valid node 
decreases to about six hundred. A feature vector 
created for a target structure j is represented as 
(v1,j,...,vn,j), where 1≦j≦Nts, Nts is the amount 
of target structures. vi,j represents the RMSD 
value between target structure j and Mi. 
 
B. 3 CS features 
 
The CS model proposed by [13] is shown in 
Fig. 3. They first fetch all the literature protein 
 
 
Fig. 1. 3-D motif discovery by GST. Each 
node in GST represents one 3-D motif and 
indicates one protein substructure. 
 
 
 
Fig. 2. The relation between GST and a 
target structure. Each target substructure 
needed to be computed for each node of 
GST, and we selected the small RMSDs to 
be as that 3-D motif similarity scores. Total 
number of GST nodes is n, and the structure 
length of target structure is m. The values 
above the nodes are RMSDs which are 
computed by our incremental computation 
method.
 
 
sequences (abbreviation lits) with catalytic site 
annotation from CSA (Catalytic Sites Atlas) 
database. Let lit i denote the i-th protein 
sequence in lits. They next compared the lits 
against the target sequence set with the 
PSI-BLAST with e-value threshold of 5•10-5, 
and let the Hi be the result dataset output by the 
PSI-BLAST, which they call the homologous 
dataset to lit i. Subsequently, they use the 
CLUSTALW to align lit i with the sequences in 
the Hi to check the conservation of the catalytic 
sites. If the similarity between them detected by 
the CLUSTALW is higher than some given 
threshold, the sequences in the Hi are 
considered to have catalytic sites. If the j-th 
target structure cj is included in any of the Hi, 
we set 1 to the feature cj, otherwise 0. 
RMSD between each protein in Train-A and 
3-D motifs found by the GST, we get all the 
GST 3-D motif features. The feature obtained 
by comparing the i-th motif and the j-th motif 
and the j-th target structure is designed as vi,j. 
Simultaneously, input Train-A into the CS 
model to acquire all catalytic site features cj for 
j-th target structure. Then we combine all 
features from the GST and the CS to make 
feature vectors (cj, m1,j, ..., mi,j), 1≦j≦NTrain-A, 
where NTrain-A is the total amount of protein 
structures in Train-A. In the test model (Fig. 5), 
the procedure is almost the same as the train 
model, but we don't need to construct the GST, 
because the GST is created by the train model 
already. So it can be proceeded more efficiently 
to get all features of testing set A (Test-A). The 
representation of feature vectors of the Test-A 
is fvj = (cj, m1,j, ..., mi,j), 1≦j≦NTest-A, where 
NTest-A is the total amount of protein structures 
in Test-A. 
Fig. 6 shows the final procedure flow 
chart. Through inputting the feature vectors 
which result from the train model, the SVMperf 
model can generate training model x. Then we 
input the feature vectors of Test-A and training 
model x into the SVMperf together to determine 
the function of every protein structures in 
Test-A. 
 
 
3. Result 
 
A. Unique signature finding 
 
We have designed the algorithms and built 
the data indexing system for the DNA and 
protein large-scale data set.  
 
B. Protein function prediction 
 
B.1 Dataset 
The dataset we used was supplied by [16]. 
It includes 1178 proteins which can be split into 
691 enzymes and 487 non-enzymes by 
annotation in non-redundant subset of the PDB 
and Medline abstracts. 4 enzymes and 4 
non-enzymes were excluded due to the 
incomplete function annotation. All of the test 
set we used has no overlaps with the literature 
entries. 
 
B. 2 Performance analysis: 
 
In order to estimate the performance, the 
k-fold cross-validation method was used, where 
k is the partition number of the dataset. In the 
method, one partition is taken as a testing set, 
and the other k-1 partitions will be treated as a 
training set. A half of the training set was used 
for constructing the GST. k was set to five in 
our experiments, and we shuffled the data 
before partitioning. Let TP, TN, FP, and FN are 
the numbers of true positives, true negatives, 
false positives, and false negatives respectively. 
The accuracy, precision, recall, and F1-score 
are defined as 
 
FPTP
TPf
FNFPTNTP
TNTPf precacc +=+++
+=
recprec
recprec
scoreFrec ff
ff
f
FNTP
TPf +
⋅×=+= − 21  
 
The Table 1 shows the maximum, minimum, 
and average of these values in the five 
experiments of the 5-fold cross-validation. 
With only sequence-based CS information, 
we achieved the average accuracy of 85.36%, 
and average F1-score of 86.58%. But the CS 
information is limited to the known sequence 
motifs, and there are enzymes that do not have 
such sequence motifs, which must be a reason 
for the fact that the recall (78.68%) is far lower 
than the precision (96.37%). Moreover, there 
are noises: some non-enzymes occur to have 
the motifs just by chance. To improve these, we 
need additional features independent from the 
sequence information, like the GST features. 
By adding the GST features, all the measures 
are improved: The average accuracy rises to 
85.45%, the average recall goes up by 0.24% 
and the average F1-score also rises to 86.69%. 
Moreover, the maximum accuracy goes up to 
87.72% and the highest F1-score 88.27%.  
 
 
Reference 
 
[1]. Kiryu,B.M. and Kiryu,C.P. (1998), “Rapid 
identification of Candida albicans and other 
human pathogenic yeasts by using 
oligonucleotides in a PCR,” J. Clin. 
Microbiol., 73, 1634-1641. 
 
The report for the third year project 
 
Part I: 
 
中文摘要 
 
在生物資訊領域當中，蛋白質結構分類
是基本的方法用來決定蛋白質的功能。  估
計目前在結構分類的資料庫當中，約有 10%
的已知的酵素擁有 TIM barrel 的領域。  隨
著 TIM barrel 蛋白質有著高度的序列相似度
以及多樣化的功能，TIM barrel 蛋白質變成了
蛋白質工程以及演化學科上具有吸引力的目
標。  因此，在論文當中提出了一種以最佳
擊中率為基礎的排比方法，以 SCOP 資料庫
中的超級家族與家族層次來進行 TIM barrel
蛋白質結構的分類。  這個方法也被使用來
針對酵素資料庫中的類別進行 TIM barrel 蛋
白質結構的分類。  TIM40D 與 TIM95D 兩個
測試資料集被用來評估我們提出的方法。  
分類結果顯示，針對 SCOP 資料庫中的超級家
族，整體的預測精確度高達 90.3%，針對 SCOP
資料庫中的家族，預測精確度為 89.5%，以及針
對酵素資料庫中的類別，整體預測精確度高達
70.1%。  這些結果證明了即使只有胺基酸序列
資訊，對於 TIM barrel 蛋白質結構分類，使用最
佳擊中率的排比是一個簡單且有價值的方法。  
 
關鍵字詞: 蛋白質結構分類、最佳擊中率、
排比、TIM barrel 蛋白質。 
 
 
Abstract 
 
The classification of protein structures is 
essential for their function determination in 
bioinformatics.  It has been estimated that 
around 10% of all known enzymes have TIM 
barrel domains from the Structural 
Classification of Proteins (SCOP) database.  
With its high sequence variation and diverse 
functionalities, TIM barrel protein becomes to 
be an attractive target for protein engineering 
and for the evolution study.  Hence, in this 
paper, an alignment approach with the best hit 
strategy is proposed to classify the TIM barrel 
protein structure in terms of superfamily and 
family levels in the SCOP.  This work is also 
used to do the classification for class level in 
the Enzyme nomenclature (ENZYME) 
database.  Two testing data sets, TIM40D and 
TIM95D, both are used to evaluate this 
approach.  The resulting classification has an 
overall prediction accuracy rate of 90.3% for 
the superfamily level in the SCOP, 89.5% for 
the family level in the SCOP and 70.1% for the 
class level in the ENZYME.  These results 
demonstrate that the alignment approach with 
the best hit strategy is a simple and viable 
method for the TIM barrel protein structure 
classification, even only has the amino acid 
sequences information. 
 
Keywords: Protein structural classification, 
Best Hit, alignment, TIM barrel protein. 
 
 
1. Background 
 
High technology large-scale sequencing 
projects have produced a massive number of 
proteins with putative amino acid sequences 
but much less is known in terms of their three 
dimensional (3D) structure.  Several popular 
structure databases, such as the Structural 
Classification of Proteins (SCOP, [8], release 
version 1.71) and the Class, Architecture, 
Topology, and Homologous superfamily 
(CATH, [26], release version 3.1.0), contribute 
only no more than 45000 entries in the Protein 
Data Bank (PDB, [3], released in 03-Jul. 2007).  
This number constitutes only about 20% of 
collections in the Swiss-Prot ([28], release 
version 53.2).  Physically, x-ray diffraction or 
NMR is used to determine the 3D structure for 
a protein.  However, each has its limitation 
[11].  As such, extracting structural 
information from the sequence databases 
becomes an important and complementary 
alternative, especially for swiftly determining 
protein functions or discovering new 
compounds for medical or therapeutic 
purposes. 
From the SCOP 1.71, it has been 
estimated that around 10% of all known 
proteins have no more than 95% sequence 
identity based on PDB SEQRES records.  For 
the TIM40D and the TIM95D, we exclude the 
redundant and possible mutant data in the 
ASTRAL database.  For these TIM barrel 
proteins, we can directly obtain the amino acid 
sequences and 3D structure information from 
the ASTRAL SCOP 1.71 and the PDB 
databases.  The secondary structure 
information with eight states (H, I, G, E, B, S, 
T, _) is derived from the DSSP program [16] 
first.  Then, the eight states are reduced to 
three states (H, E and C) according to the 
scheme outlined by Jones [15].  For the 
TIM40D and the TIM95D, these TIM barrel 
proteins are classified into 29 and 31 
superfamily categories in the SCOP, 76 and 80 
family categories in the SCOP and 6 classes in 
the ENZYME, respectively.  The detail 
information of the TIM40D and the TIM95D 
are shown in Tables 1, 2 and 3, which are 
derived from the SCOP and the Universal 
Protein Resource (UniProt, [2]).  Due to the 
page limitation, the names for family 
categories in Table 2 are omitted in this paper. 
 
B. Method 
 
In this paper, an alignment approach with 
the best hit strategy is proposed to solve the 
TIM barrel protein structure classification 
problem.  At first we adopt the tools, 
ClustalW, SSEA and CE, to align any two of 
proteins with amino acid sequences, secondary 
structure and 3D structure information, 
respectively, to obtain the scores of sequence 
identity, secondary structure identity and 
RMSD.  ClustalW is one of famous multiple 
sequence alignment tools based on a 
progressive pair-wise alignment method (global 
alignment) by considering sequence weighting, 
position-specific gap penalties and weight 
matrix choice.  Although ClustalW may be 
not a best choice since new tools have been 
proposed in recent years.  ClustalW still is 
suitable for this work.  There are two reasons.  
First, in this paper, we just want to obtain the 
score of sequence identity for any two of 
proteins, not alignment contents.  Hence, the 
score obtained from ClustalW is not so 
different to that obtained from new tools.  
Second, the design of most of new tools is 
focused on revising the multiple sequence 
alignment results, not improving the pair-wise 
alignment, even using the pair-wise alignment 
results by ClustalW.  SSEA is a multiple 
protein secondary structure alignment tool 
(either global or local alignment) based on 
three states, H, E and C, by capturing the 
concept of aligning entire elements of 
secondary structure shown to perform better 
than residue-based secondary structure 
alignments [19].  We use the ClustalW and the 
SSEA (global alignment version) under their 
default parameters to align any two of proteins 
in the TIM40D or the TIM95D to obtain the 
scores of the sequence and the secondary 
structure identities which are both normalized 
in the range 0-100.  CE is a pair-wise 
alignment tool (global alignment) between two 
protein 3D structures by aligning fragment pair 
of proteins rather than using the dynamic 
programming or the Monte Carlo optimization.  
We use the CE under its default parameters to 
align any two of proteins in the TIM40D or the 
TIM95D to obtain the scores of RMSD.  After 
using the ClustalW, the SSEA and the CE, we 
build an aligned-based protein-protein relation 
network with the RMSD, the sequence and the 
secondary structure identities. 
In the TIM40D or the TIM95D, each 
protein will be selected as a target protein first.  
Then we use this target protein to map all of 
remainder proteins in the TIM40D or the 
TIM95D to select the protein under a condition.  
Finally, the prediction result of target protein is 
determined according to the selected protein.  
The condition used to select the protein is very 
critical for the prediction problem.  In this 
paper, we use the best hit strategy to select the 
protein which has the best score for the target 
protein according to this network.  For the 
sequence identity or the secondary structure 
identity, the highest score is selected; for the 
RMSD, the lowest score is selected.  For n 
proteins, the time complexity is O(n2) to find 
all selected proteins in this network by using 
the best hit strategy due to the bidirectional 
property.  We use the Perl programming tool 
which supports the powerful data structures to 
implement the best hit finding program. 
We also apply the threshold concept to the 
best hit strategy.  When the threshold is given, 
such as a sequence identity or the secondary 
according to the sequence identity or the 
secondary structure identity.  Overall, we can 
see that the performance of the alignment 
approach by using the amino acid sequences 
information is worst than that by using the 
secondary structure information.  But, the 
alignment approach by using the amino acid 
sequences information is practical for the TIM 
barrel protein structure classification since most 
of proteins do not have the structure 
information.  In addition, we can see that the 
performance of the alignment approach by 
using the RMSD is poor.  It shows that the 
RMSD (global alignment) is not a feasible 
feature to do the TIM barrel protein structure 
classification by using the alignment approach.  
Besides, we can see that the threshold for using 
the sequence identity is low.  It means that the 
overall prediction accuracy will be decreased if 
a high score is given as the threshold.  In other 
words, the selected protein in the same 
category will be missed.  This implies that the 
TIM barrel proteins in the sequence level are 
very diverse.  In the same way, the TIM barrel 
proteins in the secondary structure are very 
similar since the threshold is high.  These 
results matched the observations for the TIM 
barrel proteins. 
Tables 6 and 7 show the Recall and the 
Precision for the TIM40D and the TIM95D, 
respectively.  Here, we only show the 
categories which all have more than ten 
proteins due to the page limitation.  In Tables 
6 and 7, the threshold is determined with the 
best Precision under the best Recall.  From 
Tables 6 and 7, the results show that the 
Precision with the threshold outperforms or 
equals to that without the threshold.  In Table 
6, for the superfamily categories, 
Ribulose-phoshate binding barrel, 
(Trans)glycosidases and Aldolase, they obtain 
the better accuracy than the best overall 
prediction accuracy.  However, the 
superfamily categories, FMN-linked 
oxidoreductases and Metallo-dependent 
hydrolases, obtain the worst accuracy than the 
best overall prediction accuracy.  For all of the 
family categories, they obtain the better 
accuracy than the best overall prediction 
accuracy.  Only the class category in the 
ENZYME, Transferases, obtains the worst 
accuracy than the best overall prediction 
accuracy.  Other class categories in the 
ENZYME all obtain the better accuracy than 
the best overall prediction accuracy.  These 
results show that the alignment approach is 
more useful for certain TIM barrel proteins 
than others.  In addition, for the superfamily 
category, (Trans)glycosidases, the accuracy 
derived according to the sequence identity is 
better than that according to the secondary 
structure identity.  Similarly, the family 
categories, Type II chitinase and HMGL-like, 
both have the same observations.  However, 
the accuracy derived according to the 
secondary structure identity is better than that 
according to the sequence identity for the 
family category, beta-glycanases, and the class 
category in the ENZYME, Hydrolases.  These 
results show that the alignment approach by 
using the amino acid sequences information is 
more suitable for some TIM barrel proteins 
than others. 
In Table 7, for the superfamily categories, 
FMN-linked oxidoreductases and 
Metallo-dependent hydrolases, also obtain the 
worst accuracy than the best overall prediction 
accuracy as Table 6.  Other superfamily 
categories all obtain the better accuracy than 
the best overall prediction accuracy.  As Table 
6, all family categories in Table 7 obtain the 
better or the equal accuracy than the best 
overall prediction accuracy.  Similarly, no 
class categories in the ENZYME obtain the 
worst accuracy than the best overall prediction 
accuracy.  Besides, for the superfamily 
categories, Ribulose-phoshate binding barrel 
and (Trans) glycosidases, the family category, 
Type II chitinase, and the class category in the 
ENZYME, Oxidoreductases, the accuracy 
derived according to the sequence identity is 
better than that according to the secondary 
structure identity.  These results are also 
similar to those shown in Table 6. 
 
 
5. Conclusions and future work 
 
In this paper, we have proposed an 
alignment approach by using the ClustalW, 
SSEA and CE, with the best hit strategy for 
TIM barrel protein structure classification.  
Two testing data sets, TIM40D and TIM95D, 
were extracted and built from the ASTRAL 
 
TABLE 1. Non-redundant data sets, TIM40D and TIM95D, of SCOP superfamily 
Superfamily categories Index N40D* N95D* 
Triosephosphate isomerase  1 2 14 
Ribulose-phoshate binding barrel 2 16 24 
Thiamin phosphate synthase 3 2 2 
Pyridoxine 5'-phosphate synthase 4 1 1 
FMN-linked oxidoreductases 5 13 19 
Inosine monophosphate dehydrogenase  6 2 5 
PLP-binding barrel 7 5 6 
NAD(P)-linked oxidoreductase 8 8 19 
(Trans)glycosidases 9 72 111 
Metallo-dependent hydrolases 10 16 21 
Aldolase 11 27 41 
Enolase C-terminal domain-like 12 8 19 
Phosphoenolpyruvate/pyruvate domain 13 8 21 
Malate synthase G 14 - 1 
RuBisCo, C-terminal domain 15 4 9 
Xylose isomerase-like 16 7 14 
Bacterial luciferase-like 17 7 9 
Nicotinate/Quinolinate PRTase C-terminal domain-like 18 3 4 
PLC-like phosphodiesterases 19 4 4 
Cobalamin (vitamin B12)-dependent enzymes 20 1 2 
tRNA-guanine transglycosylase 21 2 2 
Dihydropteroate synthetase-like 22 5 6 
UROD/MetE-like 23 4 4 
FAD-linked oxidoreductase 24 1 1 
Monomethylamine methyltransferase MtmB 25 1 1 
Homocysteine S-methyltransferase 26 - 1 
(2r)-phospho-3-sulfolactate synthase ComA 27 1 2 
Radical SAM enzymes 28 3 3 
GlpP-like 29 1 1 
CutC-like 30 1 1 
TM1631-like 32 2 2 
* N40D is the number of proteins in TIM40D. N95D is the number of proteins in TIM95D. 
 
TABLE 2. Non-redundant data sets, TIM40D and TIM95D, of SCOP family 
Index N40D N95D Index N40D N95D Index N40D N95D Index N40D N95D 
1.1 2 14 9.10 1 1 12.2 7 13 18.2 1 1 
2.1 2 5 9.11 1 1 13.1 - 8 19.1 1 1 
2.2 2 4 10.1 1 1 13.2 1 2 19.2 1 1 
2.3 2 4 10.2 1 1 13.3 - 1 19.3 2 2 
2.4 10 11 10.4 2 6 13.4 4 5 20.3 1 2 
3.1 2 2 10.5 4 5 13.5 2 2 21.1 2 2 
4.1 1 1 10.6 1 1 13.6 1 3 22.1 2 3 
5.1 13 19 10.7 1 1 14.1 - 1 22.2 3 3 
6.1 2 5 10.8 2 2 15.1 4 9 23.1 2 2 
7.1 4 5 10.10 1 1 16.1 1 1 23.2 2 2 
7.2 1 1 10.11 1 1 16.2 1 1 24.1 1 1 
8.1 8 19 10.12 1 1 16.3 1 1 25.1 1 1 
9.1 20 38 10.13 1 1 16.4 1 1 26.1 - 1 
9.2 22 29 11.1 15 24 16.5 2 9 27.1 1 2 
9.3 1 1 11.2 2 3 16.6 1 1 28.1 1 1 
9.4 4 10 11.3 2 4 17.1 2 2 28.2 1 1 
9.5 18 25 11.4 3 5 17.2 1 2 28.3 1 1 
9.6 3 3 11.5 3 3 17.3 2 3 29.1 1 1 
9.7 1 1 11.6 2 2 17.4 2 2 30.1 1 1 
9.8 1 2 12.1 1 6 18.1 2 3 32.1 2 2 
Table 7. The comparisons of the Recall (%) and the Precision (%) in the TIM95D 
Method 
Item 
Index Sequence identity Secondary structure identity 
Recall Precision1 Precision2 Recall Precision1 Precision2 
Superfmaily 
1 100.0 82.4 100.0 (21-44) 100.0 93.3 100.0 (80-85)
2 100.0 85.7 100.0 (20-22) 95.8 85.2 95.8 (79) 
5 84.2 80.0 100.0 (20-24) 84.2 94.1 100.0 (70-81)
8 100.0 90.5 100.0 (17-22) 100.0 100.0 100.0 (<81) 
9 93.7 94.6 94.6 (<12) 92.8 97.2 97.2 (<67) 
10 66.7 100.0 100.0 (<14) 81.0 81.0 89.5 (74) 
11 90.2 90.2 100.0 (17-22) 97.6 87.0 95.2 (76-77) 
12 94.7 81.8 100.0 (17-18 100.0 90.5 100.0 (76-80)
13 85.7 81.8 100.0 (17-26) 95.2 83.3 95.2 (72-76) 
16 78.6 100.0 100.0 (<14) 92.9 76.5 92.9 (74-75) 
Family 
1.1 100.0 93.3 100.0 (18-44) 100.0 100.0 100.0 (77-86)
2.4 100.0 84.6 100.0 (17-30) 100.0 91.7 100.0 (79) 
5.1 89.5 85.0 94.4 (17-18) 89.5 100.0 100.0 (<77) 
8.1 100.0 95.0 100.0 (17-22) 100.0 100.0  100.0 (<81) 
9.1 92.1 92.1 100.0 (17-19) 97.4 94.9 94.9 (<67) 
9.2 86.2 100.0 100.0 (<14) 93.1 93.1 93.1 (<70) 
9.4 100.0 58.8 100.0 (20-36) 100.0 100.0  100.0 (<84) 
9.5 92.0 95.8 100.0 (13-16) 88.0 95.7 100.0 (72-80)
11.1 100.0 88.9 100.0 (15-20) 100.0 88.9 96.0 (75-79) 
12.2 92.3 75.0 100.0 (17-18) 100.0 92.9 100.0 (74-80)
Class in  
ENZYME 
1 95.0 77.6 90.5 (18) 90.0 81.0 85.7 (78-79) 
2 71.4 77.8 79.5 (14) 71.4 83.3 85.4 (71-72) 
3 69.0 70.0 70.0 (<13) 70.1 69.3 70.1 (68-71) 
4 81.6 77.5 88.6 (20-22) 82.9 74.1 77.8 (73) 
5 84.2 86.5 88.9 (18) 84.2 74.4 78.0 (72-75) 
* Precision1: without the threshold. Precision2: with the threshold shown in parentheses. 
 
 
Part II:  
Abstract 
 
We have developed a re-sequencing 
program for the new sequencing machine 
Solexa.  With these high throughput 
machines, millions of short sequences will be 
generated in a short time.  A novel algorithm 
which derived from the USD algorithm has 
been designed to adapt the re-sequencing 
requirement.  With the well design of USD 
method, we can control the memory usage 
easily to be able to cope with the large-scale 
genome problem.  In the revised USD version, 
we improved the performance from O(n2) to 
O(kn) for the original USD kernel method.  
Besides, for purifying the millions of short 
sequences Solexa generates, several programs 
have been developed in the pre-processing and 
post-processing phases as well.  The method 
we proposed can be used to map short 
sequences to the large-scale genome efficiently 
while SOAP encounter the large-scale data 
problem  In this paper, the Deep sequencing 
of small RNA libraries from chicken embryo, 
Gene Expression Omnibus under accession no. 
GSE10686 and Chicken Genome (galGal3) of 
May 2006 (Kent et al. 2002; Karolchik et al. 
2003) data have been used to estimate our 
method and compare it with SOAP.  The 
results show that it can achieve high coverage 
of 99% and 86% for known miRNAs and 
novel miRNAs respectively by using our 
method. 
 
Keywords: Uinque Signature Discovery, 
re-sequencing, Solexa, miRNA, adaptor 
filtering. 
 
 
 
Adaptor sequence: 
TCGTATGCCGTCTTCTGCTTG 
 
Read A: 
AGGAAAAGGAAAAGGAAATCGTATG
CCGTCTTCTG 
 
Read B: 
TCGTTGCCGTCTTCTGCTTGTCGTATG
CCGTCTTC 
 
At the end of read A, red part 
TCGTATGCCGTCTTCTG, and at the end 
of read B blue part 
TGCCGTCTTCTGCTTG and green part 
TCGTATGCCGTCTTC, these three strings 
are substrings of the adaptor sequence. So 
we remove TCGTATGCCGTCTTCTG at 
the end of read A and remove 
TGCCGTCTTCTGCTTGTCGTATGCCGT
CTTC at the end of read B. In the above 
example, read B is the type of two 
substrings of the adaptor sequence ligating 
together. 
 
Remove reads without adaptor which are 
similar to RNA retrieved from Rfam. Because 
we want to find new mRNA and miRNA, we 
remove reads without adaptor which have 80% 
similarity with Rfam RNA we retrieved. Here 
we revise the unique signature discovery 
algorithm [1] which will introduce later to 
achieve this goal. 
 
B.2 Mapping phase 
 
After removing reads similar to Rfam 
RNA, we use the remaining reads to map to the 
genome. Note that in the step of removing 
adaptor, it causes variable length of reads from 
0 bp to 33 bp. The minimal length of reads we 
choose here is 14 bp because the number of 
reads which length is smaller than 14 bp is a 
small part of the remaining reads. And for reads 
which length is larger than 14 bp, we divide 
them into two substrings of length 14 bp which 
are head and tail of the original read after 
removing adaptor respectively. Here are two 
examples. For read A with length of 18 bp, we 
divided it into two substrings, HA and TA with 
length 14 bp. Note that HA and TA are with 10 
bp overlap. Similarly, for read B with length 33 
bp, we still partition it into HB and TB with 
length 14 bp. But, HB and TB cannot cover all 
length of read B and form a gap of 5 bp. 
 
Example 1: 
Read A of length 18 bp: 
AGGAAAAGGAAAAGGAAA.  Substring 
HA of read A: AGGAAAAGGAAAAG 
Substring TA of read A: 
AAAGGAAAAGGAAA 
HA and TA are with overlap 10 bp. 
 
Example 2: 
Read B of length 33 bp: 
AGGAAAAGGAAAAGGAAATCGTATGCC
CCAATC 
Substring HB of read B: 
AGGAAAAGGAAAAG 
Substring TB of read B: CGTATGCCCCAATC 
H and T are with gap 5 bp. 
 
Then we use these 14 bp substrings to map 
to the genome. The hamming distance of each 
14 bp substring mapping is less than or equal to 
1 bp. And still, we use revised unique signature 
discovery algorithm to complete the mapping. 
 
B.3 Post-processing phase 
 
While the mapping finished, we get 14 bp 
substrings and the corresponding positions of 
the genome. For reads which length is 14 bp, 
these positions are the mapping positions of the 
genome. Otherwise, we should combine the 
mapped positions of head substring and tail 
substring of a read. For example, , substring HA 
and TA are with 10 bp overlap of the read A, 
then if the mapped position of the read A and 
HA is (x, y), we should find the mapped 
position of TA as (x, y + 14 - 10). Similarly, HB 
and TB have 5 bp gap, if the mapped position of 
read B and HB is (i, j), the mapped position of 
TB as (i, j + 14 + 5) should be found.   
 
Example 1 
Read A of length 18 bp: 
AGGAAAAGGAAAAGGAAA 
Substring HA of read A: 
AGGAAAAGGAAAAG 
Positions mapped: (0, 1), (0, 10), (0, 30), (1, 25) 
Substring TA of read A: 
AAAGGAAAAGGAAA 
number of segment clusters is n. 
In step 3, the reason we partition every 
l-pattern into (k+1) segments is if there are k 
mismatches between two l-patterns, there must 
be one segment of these two l-patterns exact 
matches. And this can be proofed by pigeonhole 
principle. 
In step 5, we create a bit map array for 
each Pj in Ax which maps to all Ti in By. If the 
hamming distance between Pj and Ti is less than 
or equal to k, we mark 1 at position i of the bit 
map array of Pj. The bit map array can help us 
not to compute the hamming distance between 
Ti and Pj if they have already mapped, but this 
method will be memory costly. For example, if 
the number of l-patterns in runfile A and B are 
50000 and 300000 respectively, the memory 
usage of bit map array is 50000× 300000/8 = 
1875000000 bytes. Anyway, we can still control 
this memory usage by adjusting the number of 
l-patterns in runfile A and B. 
For another application which removes 
patterns or reads similar to Rfam RNA, the 
method of this application is quite similar to the 
above algorithm. Let us define the new problem: 
Given a long text T and a pattern P, find all Pj 
such that the hamming distances between Pj 
and all Ti are larger than k and k is less than or 
equal to l. And the method is simple, while we 
mark every position mapped to Pj in the above 
algorithm, we only mark once if any position 
mapped to Pj in the new one. Then, output 
l-patterns which are not marked. 
 
 
3. Results 
 
The performance comparison between our 
method and SOAP are showed in the following 
description. Both programs are carried out on a 
FreeBSD 6 32bit-x86 machine with Intel(R) 
Core(TM)2 Quad CPU Q9550 2.83GHz and 
4GB memory by using the single thread 
technique. 
In order to compare our method with SOAP, 
a fixed seed size of 7 with 2 maximum 
mismatches was taken into account to do the 
experiment.  In addition to map reads into 
forward genome, we also mapped the reverse 
reads into the genome as well as SOAP doing 
and reporting all repeat hits as well.  While we 
used a whole genome as input data with size 
about 1GB, SOAP will met a problem for 
lacking of memory. Besides, the same situation 
occurred while seed length is equal to 12 bp 
with 200MB chromosome as input data.  
However, this problem can be solved by using 
our approach even though that the execution 
time is about two times slower than SOAP with 
seed length 7.  
In Table 1 and Table 2, there are totally 202 
know miRNAs and 557 miRNAs candidates 
which are reported by [2].  After mapping all 
reads into the forward and reverse genomes, the 
results show that it covers about 99% of known 
miRNAs by using our method and about 86% 
of novel miRNAs.  These results are all better 
than the coverage rates of about 52% for 
known miRNAs and about 47% for novel 
miRNAs by using SOPA.  The reason why 
SOAP obtains a lower coverage is the 
difference of trimming adaptor between SOAP 
and our method.  In our method, trimming 
adaptor is done first before mapping reversed 
reads to genome. SOAP maybe has the 
different way to do this and cause the low 
coverage of mapping result. 
 
 
Reference 
 
[1] An efficient algorithm for unique 
signature discovery on whole-genome 
EST databases, Hsiao Ping Lee; Tzu Fang 
Sheu; Yin Te Tsai; Ching Hua Shih; Chuan 
Yi Tang, Computational Systems 
Bioinformatics Conference, 2004. CSB 
2004. Proceedings. 2004 IEEE, Volume , 
Issue , 16-19 Aug. 2004 Page(s): 650 – 
651. 
[2] A microRNA catalog of the developing 
chicken embryo identified by a deep 
sequencing approach, Genome Res. 
Glazov et al. 18: 957 
[3] http://www.ncbi.nlm.nih.gov/geo/query/ac
c.cgi?acc=GSE10686. 
[4] http://hgdownload.cse.ucsc.edu/downloads
.html#chicken. 
[5] http://www.sanger.ac.uk/Software/Rfam/. 
[6] SOAP: short oligonucleotide alignment 
program, Ruiqiang Li, Yingrui Li , 
Karsten Kristiansen and Jun Wang. 
[7] High-throughput sequence alignment 
using Graphics Processing Units, Michael 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 95-2221-E-007-031 
計畫名稱 針對生物序列近似搜尋等應用來設計與實作有效率的索引系統 
出國人員姓名 
服務機關及職稱 
林俊淵, 博士後研究員, 國立清華大學資訊工程學系 
朱家漢, 博士研究生, 國立清華大學資訊工程學系 
會議時間地點 20-24 August, Hong Kong 
會議名稱 
The 18th International Conference on Pattern Recognition 
1st IAPR Workshop on Pattern Recognition in Bioinformatics 
發表論文題目 Comparative Gene Prediction based on Gene Structure Conservation 
 
一、參加會議經過 
 
此次我們參加 ICPR2006 以及 PRIB 2006 國際會議最主要有兩個目的，第一個目的
是拓展國際觀，無論事在生活學習或知識取得方面了解目前世界生物資訊研究的概況。
另一個目的是希望能夠吸收一些有用的生物資訊技巧，並且將這些技巧轉換成有用工
具，來幫助未來的生物資訊研究。當然，還有另一個額外的優點，就是能夠去了解台灣
在生物資訊方面所缺乏的資訊，並進一步吸取這些經驗來補足缺乏的部份。 
該會議舉辦城市為香港灣仔區，一抵達就是 ICPR2006 國際論文會議的地點，灣仔
區是一個繁華的城市，跟台北沒有太大的差別，從其中無論是食、衣、住、行均無太大
差異，不過香港地價昂貴，每棟大樓均傾向於高層的建築，有點像堆的很高但面積不大
的積木組合。其中有一項比較有趣的事情，當進入計程車中，一開始還覺得是自己在開
車，因為他們的駕駛座在右邊，所以當車子轉彎或煞車，都會有想要駕駛方向盤以及踩
煞車的衝動。這邊的夜生活也是另一種與台北相似的景象。 
 
二、與會心得 
 
這幾天會議下來吸取了許多寶貴的生物資訊經驗，其中比較有吸引力的主題有(1) 
Signal and Motif Detection; Gene Selection (2) Graphical Approach to Weak Motif 
Recognition in Noisy Data Sets (3) Prediction Secondary Structure of All-Helical Proteins 
Using Hidden Markov Support Vector Machines (4) Prediction of Protein Sub-cellular 
Localizations Using Moment Descriptors and Support Vector Machine (5) Computational 
Identification of Short Initial Exons.  
這裡共有兩個重點關於上述的主題，(1) 經由生物上的訊號可以幫助偵測序列上的
motif 並且降低 false positive 的機率，其中介紹過利用 Hidden Markov Model 或 Support 
Vector Machine 進行生物訊號的偵側，可從其中萃取出一些特徵值，透過特徵值的設定可
以幫助減少 false positive 候選者的機會，其中所學習到的是如果講求的是精確度而非完
國科會補助博士生出席國際學術會議報告 
 
96 年 12 月 26 日
報告人姓名 朱 家 漢 會議時間 地點 
96 年 12 月 17-19 日
澳大利亞-布里斯班
會議 
名稱 
(中文) 2007 生命科學計算模型 國際會議 
(英文) 2007 International Symposium on Computational Models for 
Life Sciences – CMLS’07 
發表 
論文 
題目 
TIM Barrel Protein Structure Classification Using Alignment 
Approach and Best Hit Strategy 
 
一、參加會議經過 
 
  CMLS’07 是生命科學計算領域中很重要的國際會議之ㄧ，今年在澳大利亞第
三大城市布里斯班舉行，今年本會議集結了許多重要的生物科學計算領域研究，
共有 6 個 session 與 36 篇論文，包含了 Image analysis、Pattern analysis、Machine 
Learning and Mathematical Modeling、Knowledge-Based Systems, Simulation and 
Optimization、以及 Poster session。 
 
  在此會議中，提供了許多先進的生命科學計算理論與數學模型、前瞻性的研究
方向與生物醫學影像應用都在於本會議中發表與討論，在會議進行過程，除了
Oral paper 的發表之外，大會亦提供了 tutorial 以及 keynote speech，會議內容相
當豐富。參與此次會議的人員包含了國際著名大學的教授以及國際生物資訊計算
研究位的重要研究人員，亞洲以日本、香港與新加坡最為踴躍，台灣方面參與的
人並不多。 
 
  學生所發表之論文主題是”TIM Barrel Protein Structure Classification Using 
Alignment Approach and Best Hit Strategy”，探討使用簡單但極具創意的序列或結
構排比策略來進行 TIM barrel 蛋白質家族的序列與結構分類，本論文被歸類在
Pattern analysis session 進行論文內容發表。在此 Session 中的其他論文，其發表
論文的深度均在水準之上，會場中問題討論相當的踴躍與熱烈。 
 
  另外學生也參與其它 session 的論文發表，其中有幾篇論文與學生的研究息息
相關，從這些論文內容，讓學生從各種不同的角度來思考未來研究的方法與方
向，除此之外，大會亦安排了幾位不同生物科學計算領域的大師級人物，進行多
個場次的專題演講，從演講內容中可以得知目前相關領域的發展趨勢與未來研究
出席國際學術會議心得報告 
                                                             
出國人員姓名 
服務機關及職稱 
劉至善 
會議時間地點 April 26-27, 2008, Hong Kong. 
會議名稱 Asian Association for Algorithms and Computation Annual Meeting, AAAC08 
發表論文題目 Restrained and Total Restrained Domination Problems 
 
一、參加會議經過 
亞洲計算與演算法協會於 2007 年成立，以促進亞洲區在計算理論的各領域的互相交
流。本次為此協會舉辦的第一次年會，於 4 月 26 日 27 日兩天在香港大學舉行。本次會
議除了計算理論各領域(計算幾何、資訊安全、組合學、分散演算法、圖形理論..等)的相
關論文。也邀請到在計算理論領域非常著名的 Prof. Josep Diaz 與 Prof. Lance Fortnow 給
予演講，主題分別為 Dynamic Random Geometric Graphs 與 Computational Awareness。 
會議開幕後第一個演講是由 Prof. Josep Diaz 開始，簡述部份隨機圖形的定義與現有
成果及未來發展部分。隨機圖形是在空間中隨機灑出點並兩兩互連，以歐幾里德距離為
線段參數，目前在部份圖形理論探討的議題中，已在限制圖中找出數個結果(如相連性、
著色數、漢米爾頓連通性質等)。其後主題為計算幾何，其中一篇由 Prof. Siu-Wing Cheng
提出的解決兩凸多角體相似度的演算法，能夠以高機率得到較先前更為迅速的結果。 
下午參與組合學議程，本次個人與會論文為 Restrained and Total Restrained 
Domination Problems,即為組合學議程部份。論文中證明了這兩個問題在 split graph 上均
為 NP-complete，且提出了在 block graph 上的線性時間找出最佳解的演算法。之後即為
賽局理論議程。 
第二天則是由 Prof. Lance Fortnow 提出探討 Computational Awareness。當中提出
了一些現在技術帶來的影響，並探討更為現狀層面的應用等。其後參與議程分別為演算
法與圖形理論部份。 
 
二、與會心得 
這次會議內容涵括許多議程同時舉行，故只能選擇其中較感興趣的部份：演算法、
計算幾何、組合學與圖形理論參加。在資訊此較為應用的科目中偏理論的領域一直都在
摸索著當中的平衡點。太過實際的問題往往不容易模擬出最佳解，於是靠著限制在特定
的情形下，以較快（或是較高機率下極快）的方式求出答案。 
本次會議參與人數超過百人，在會議休憩時間與餐後空閒，大家都各自成群的熱烈
討論，以促進亞洲計算機理論相關領域互相交流的目標，在會議中算是初步達成。 
 
