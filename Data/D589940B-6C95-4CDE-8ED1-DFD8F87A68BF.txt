2 
 
A Novel Adaptive Steganographic Algorithm for 3D Polygonal Models Based on the 
Human Visual System 
Yuan-Yu Tsai 
Department of Information Science and Applications, 
Asia University, Taichung County 413, Taiwan 
Tel.: +886-4-23323456 ext. 20034; Fax: +886-4-23304708 
E-mail: yytsai@asia.edu.tw 
Abstract 
The emphasis of current 3D steganographic algorithms is mostly on high data capacity, low distortion and 
correct data extraction. However, their disadvantage is the existence of the same embedding capacity for 
each vertex in the 3D models. Embedding the same capacity in the vertex located on the surface with 
different properties may cause obvious distortion and thus not achieve the initial goal of information hiding 
techniques. In this paper, we propose a 3D steganographic algorithm integrating the key points of current 
techniques, geometric characteristics, and the human visual system to develop a new and adaptive algorithm. 
According to the different surface properties that each vertex is located on, different amounts of secret 
messages are embedded. Thus, the important shape features will be preserved and the visual distortion 
between the cover and stego model will be much smaller. The experimental results show our proposed 
algorithm can achieve high data capacity with acceptable distortion. Our proposed technique is demonstrated 
to be feasible in 3D steganography. 
I. INTRODUCTION 
With the rapid development of computer technologies, more and more data is being stored in digital form. 
This also causes people to strongly rely on computers for day to day activities, especially message exchange. 
The Internet has taken the place of traditional letters as the dominant communication channel between two 
4 
Fig. 1. Three main criteria for evaluating an information hiding technique 
In prior years, images were the commonest cover media for information hiding algorithms [3-5]. 
Recently, with the development of various 3D applications, such as virtual reality, games, and computer 
animation, several information hiding researches have gradually adopted three-dimensional models as their 
cover media, either for watermarking [6-10] or steganographic algorithms [11-18]. However, most 
algorithms embed an equal amount of the secret message into each vertex of the cover model. Clearly, not 
all vertices can tolerate the same amount of modification. Generally, from the aspect of human perception, 
the vertex located on a rough surface can tolerate more changes than on a smooth surface. In other words, 
the embedding capacity for the embedding vertex should be increased or decreased accompanied by the 
surface complexity. 
To the best of our knowledge, there is only one 3D steganographic algorithm [18] that considers 
adaptability. The authors use the contagious diffusion technique to efficiently produce a traversal path to 
decide the embedding order for each vertex. Besides, three different levels, including extending, sliding and 
rotating, are used to adaptively embed the secret message. The experimental results show their proposed 
algorithm can provide imperceptible distortion with adaptive message embedding. However, for estimating 
surface complexity for one vertex, utilizing more connected neighbors can lead to more accurate estimated 
results. In Cheng and Wang’s algorithm, the estimation only uses only two of the other vertices within the 
6 
are presented in Section IV. 
II. PROPOSED ALGORITHM 
In this section, we describe the proposed adaptive data embedding algorithm for 3D models. The algorithm 
consists of two procedures: the data embedding procedure and the data extraction procedure. The data 
embedding procedure contains preprocessing, model simplification and data embedding processes; while the 
data extraction procedure requires an extra registration process in the beginning. The flow chart of the 
proposed algorithm is shown in Fig. 2. The embedding procedure takes a cover model, two secret keys, and 
the secret message as input. A sequence list of embeddable vertices is then established starting from a 
user-defined vertex selection order in the model simplification process. Once the embedding order for each 
embeddable vertex is decided, the secret message is adaptively embedded by modifying the distance with 
the center of its referencing neighbors. Thereafter, the stego model is produced. Finally, for being robust 
against affine transformations, a principal component (PCA) analysis [19] will be performed on the stego 
model and some registration information will be generated. By comparison, the data extraction procedure 
takes a stego model, the secret keys and the PCA information as input. The PCA information is used to 
register the potentially attacked model before the data extraction. Since the remaining processes of the data 
extraction procedure are symmetrical, the secret message can be easily and correctly extracted using the 
method mentioned above. Most of the notations used in the paper are presented in Table I. In the following 
sections, we will discuss our proposed algorithm in detail.  
8 
A. The Data Embedding Procedure 
This section illustrates the data embedding procedure in detail. This procedure begins by preprocessing the 
topological information of the input model to generate the temporary storage ܸܰܶ௏೔. Subsequently, the 
model simplification process takes the above storage and the first secret key ܸܱܵ as input; while the input 
model is simplified iteratively. Further, the model simplification process generates the temporary storages 
ܵܧܮ௏೔, ܧܯܱ, and ܰܯܵ௏ಶ simultaneously. Finally, the data embedding process takes the above temporary 
storages, the second secret key ܧܶ and the secret message SM as input and adaptively embeds SM into each 
embeddable vertex. The stego model is then produced and a PCA analysis is performed to generate the PCA 
information of the stego model for correct data extraction. For simplicity, we illustrate the proposed 
technique using 2D vertices. However, the illustration can be extended into 3D space in a straightforward 
manner. 
1) Preprocessing Process 
In the preprocessing process, we prepare four temporary storages for efficient data embedding and data 
extraction. The first storage ܵܧܮ௏೔ records three statuses of each vertex ܸ௜ in the 3D model, including 
selected (‘S’), semi-selected (‘SS’) and non-selected (‘NS’) respectively. In the beginning, the status of each 
vertex is initialized as ‘NS’. The second storage ܸܰܶ௏೔  is a vertex neighboring table recording the 
neighboring relationship for each vertex ܸ௜ . Then, the third storage ܧܯܱ  records the 
embedding/extraction order of each embeddable vertex. Finally, the fourth storage ܰܯܵ௏ಶ records the 
referencing neighbors of each embeddable vertex ܸா following the model simplification process. Note, all 
value within the above four storages is based on the topological information of the input model. However, 
the topological information is never modified in our proposed algorithm. Therefore, four storages can be 
reconstructed with the secret key provided without any error in the data extraction procedure. After the 
10 
neighbors either in the MinNF or MaxNF order, the earlier the vertex appears in the model file, the earlier 
the vertex is selected. In our experimental results, each vertex selection order has its own advantage, either a 
high converging speed or high embedding capacity. A detailed comparison of the three vertex selection 
orders will be shown in the experimental results. Note, the vertex can be selected with the modified status ‘S’ 
must satisfy two criterions: the first is its original status must equal ‘NS’; while the second is at least one of 
the status ܵܧܮ௏ೕ equal ‘SS’ or ‘NS’ where ݆ is the index appearing in ܸܰܶ௏೔. In the same iteration, the 
vertex is an embeddable one if its status equals ‘S’; while the vertex with the status ‘SS’ will be the 
referencing neighbors for some embeddable vertex with the status ‘S’. Therefore, two criteria are used to 
find the embeddable vertex having more than one referencing neighbor. Once a vertex ܸ௜ is selected, we 
set its status ܵܧܮ௏೔ to ‘S’ and put its index ݅ into the storage ܧܯܱ to represent its embedding order. 
For example, in Fig. 3(a), the MinNF selection order is adopted to select the vertex. Therefore, we sort 
the vertex sequence according to the number of connected neighbors. The sorting result is shown in the 
MinNF column in the bottom table of Fig. 3(a). The vertex ܸଵ is selected first because of it is the first 
vertex appearing in the MinNF column and more than one of its neighbors have the status ‘NS’. Then, the 
value of ܵܧܮ௏భ is modified from ‘NS’ to ‘S’ and the index 1 is put into ܧܯܱ (see Fig. 3(b)). 
(a) (b) 
12 
neighbors of one embeddable vertex for the complexity estimation and then data embedding. Therefore, only 
the vertex with status ‘S’ can perform data embedding and no modification is permitted for the one with 
status ‘SS’ in the same iteration. Step 1 and Step 2 are repeated iteratively until no more following vertex can 
be selected. 
For example, in Fig. 3(b), the vertex ܸଵ has been selected and the indexes in the ܸܰܶ௏భ include 2, 6, 
and 9. Therefore, the values of ܵܧܮ௏మ, ܵܧܮ௏ల, and ܵܧܮ௏వ are all modified from ‘NS’ to ‘SS’; while 
indexes 2, 6 and 9 are then added into ܰܯܵ௏భ. Subsequently, in the MinNF column, vertex ܸସ is the next 
one and is selectable because the above two criteria are both met. Therefore, vertex ܸସ is selected, index 4 
is put into ܧܯܱ and ܵܧܮ௏ర is set to ‘S’. The values of ܵܧܮ௏య, ܵܧܮ௏ఱ, and ܵܧܮ௏ళ are also modified 
from ‘NS’ to ‘SS’; while indexes 3, 5 and 7 are added into ܰܯܵ௏ర. Finally, vertex ଼ܸ is selected and 
ܵܧܮ௏ఴ is set to ‘S’. No following status modification is required because all neighbors in ܸܰܶ௏ఴ have the 
status ‘SS’. Therefore, indexes 2, 3, 6, 7 and 9 are put into ܰܯܵ௏ఴ because their statuses all equal ‘SS’. 
Until now, the first iteration is terminated because no more following vertex can be selected. 
Step 3: Reinitializing the status of the left vertices. Finally, we reset the vertex with the ܵܧܮ௏೔ status ‘SS’ 
to ‘NS’ and next iteration from Step 1 to Step 3 is performed. The model simplification process is terminated 
until no more following vertex can be selected again in some iteration. This time, some vertices may be left 
because none of their neighbors have a status equal to ‘NS’ or ‘SS’. 
For the above example, the vertex with the status ‘SS’ in Fig. 3(b) is reset to ‘NS’ in Fig. 3(c). Vertex 
ܸହ and ܸଶ are selected in turn in the second iteration in Fig. 3(d). The value in ܰܯܵ௏ఱ includes 6 and 7, 
while the value in ܰܯܵ௏మ includes 3 and 9. In the third iteration in Fig. 3(e), vertex ܸଽ and ܸଷ are 
selected. The value in ܰܯܵ௏వ only includes 6, while the value in ܰܯܵ௏య includes 7 in Fig. 3(f). Finally, 
14 
calculating the center ܸ஼ and the distance d are shown in the equation (1) and (2) where ܰ௏ಶ is the 
number of the referencing neighbors for vertex ܸா; while the EC can be then calculated by equation (3) 
where ET is the embedding threshold. However, users can specify a maximum embedding capacity ߩ୉େ in 
advance and the perceptible visual distortion can be averted. 
ܸ஼ = ൫ ௫ܸ஼, ௬ܸ஼, ௬ܸ஼൯ = ቀ∑ ௫ܸ௜
ேೇಶ
௜ୀଵ ܰ௏ಶൗ , ∑ ௬ܸ௜
ேೇಶ
௜ୀଵ ܰ௏ಶൗ , ∑ ௭ܸ௜
ேೇಶ
௜ୀଵ ܰ௏ಶൗ ቁ                                (1) 
݀ = ටሺ ௫ܸா − ௫ܸ஼ሻଶ + ൫ ௬ܸா − ௬ܸ஼൯
ଶ + ሺ ௭ܸா − ௭ܸ஼ሻଶ                                                           (2) 
EC = ቐ
ECଵ = ቔlogଶቀ݀ ܧܶൗ ቁቕ                      
ECଶ = min ቀቔlogଶቀ݀ ܧܶൗ ቁቕ , ߩ୉େቁ
                                                      (3) 
Step 3: Data Embedding. After the embedding capacity EC is calculated, we derive the EC bits from the 
secret message SM2 and transform them into a decimal number SM10. Then, distance ݀ᇱ with the secret 
message embedded can be calculated by equation (4). Finally, we modified vertex ܸா along with the 
direction from ܸ஼ to ܸா to make the distance from ݀ to ݀ᇱ. The equation to derive the data-embedded 
vertex of ܸாᇲ is shown in equations (5) and (6).  
݀ᇱ = ൝ቀቔቀ
݀ ܧܶൗ − 2
୉େభቁ/2୉େቕ × 2୉େ + SMଵ଴ቁ × ܧܶ             if EC = ߩ୉େ
ሺ2୉େ + SMଵ଴ሻ × ܧܶ                                                            otherwise  
                  (4) 
ݑሬറ = ൫ݑ௫ሬሬሬሬറ, ݑ௬ሬሬሬሬറ, ݑ௭ሬሬሬሬറ൯ = ൫ ௫ܸா − ௫ܸ஼, ௬ܸா − ௬ܸ஼, ௭ܸா − ௭ܸ஼൯                                                     (5) 
ܸாᇲ = ൫ ௫ܸா
ᇲ, ௬ܸா
ᇲ, ௭ܸா
ᇲ൯ = ቀ ௫ܸ஼ +
ௗᇲ×௨ೣሬሬሬሬሬറ
‖௨ሬറ‖ , ௬ܸ
஼ + ௗ
ᇲ×௨೤ሬሬሬሬሬറ
‖௨ሬറ‖ , ௭ܸ
஼ + ௗ
ᇲ×௨೥ሬሬሬሬሬറ
‖௨ሬറ‖ ቁ                                      (6) 
B. The Data Extraction Procedure 
During the data extraction procedure, the following processes are performed sequentially. First, the 
potentially attacked stego model is analyzed using the PCA technique in the registration process and the 
received PCA information is used to perform the model registration. Second, the preprocessing process 
prepares four temporary storages for data extraction. As mentioned before, the construction of these storages 
16 
III. EXPERIMENTAL RESULTS 
This section presents the experimental results obtained from eight 3D common polygonal models, including 
‘Armadillo’, ‘Brain’, ‘Cow’, ‘Golfball’, ‘Lucy’, ‘Maxplanck’, ‘Dragon’, and ‘Hand’. The model information, 
including the number of vertices, number of faces and model size (represented by the diagonal length of the 
bounding volume, ܦܮ஻௏), of each model is shown in Table II. The algorithm was implemented in Microsoft 
Visual C++ programming language on a personal computer with an Intel Core i7 2.67 GHz processor and 3 
GB memory. The visual effect of each cover polygonal model is depicted in Fig. 5. The embedded secret 
message is a randomly generated 0/1 bit string. The distortion between the cover model and the stego model 
is measured by Root Mean Square (RMS) and Normalized Root Mean Square (NRMS) which is defined in 
the equation (10) and (11). ܥ௜ and ௜ܵ are the vertices located at the ith reading order from the cover and 
stego models, respectively. The number precision both for representing the cover and the stego model is a 
precision of six decimal digits. For the maximum embedding capacity, no restriction is performed on the 
parameter ߩ୉େ. The experimental results show there is no error in the extracted secret message. 
RMS = ට∑ ‖ܥ௜ − ௜ܵ‖ଶேೇ୧ୀଵ ௏ܰൗ                                 (10) 
NRMS = RMS/ܦܮ஻௏                                   (11) 
Table II 
The model information, the embedding capacity, and the model distortion under the embedding 
threshold ܧܶ = 3 × 10ି଺ and the MinNF vertex selection order. 
Model Name ௏ܰ ிܰ ܦܮ஻௏ ܰெௌ Capacity BitsPV BitsPEV RMS NRMS
Armadillo 172974 345944 228.80 26142 2220480 12.84 15.12 0.06961 0.0304%
Brain 294012 588032 10.02 66885 2289498 7.79 10.08 0.00452 0.0451%
Cow 46433 92864 30.48 11341 403567 8.69 11.50 0.01207 0.0396%
Golfball 122882 245760 1.73 23639 769898 6.27 7.76 0.00074 0.0427%
Lucy 262909 525814 1918.29 35062 4101995 15.60 18.00 0.61754 0.0322%
Maxplanck 49132 98260 697.49 7521 730170 14.86 17.55 0.44823 0.0643%
Dragon 437645 871414 26.69 53153 4625275 10.57 12.03 0.00995 0.0373%
Hand 327323 654666 8.41 52084 2774833 8.48 10.08 0.00215 0.0255%
This section first presents the experimental results of our proposed algorithm, including the embedding 
capacity and the visual distortion of the different input models. Second, we present the visual effect for the 
18 
  
Armadillo Brain Cow Golfball 
  
Lucy Maxplanck Dragon Hand 
Fig. 6: The visual effect of the stego model with the secret message embedded 
In Figs. 7 and 8, we present the shading effect of Armadillo and Lucy models under different 
embedding thresholds. Other test models also produced similar results. The difference between the shading 
result of the cover model and the stego model with different embedding threshold is imperceptible. The main 
reasons include not only the little distortion caused by our proposed algorithm but also the decreased 
sensibility of the human eye because of the satisfactory shading result. Therefore, for better comparison, 
close-up views of some parts of the two models with the wireframe mode are presented in Figs. 9 and 10. 
For a smaller embedding threshold, nearly each embeddable vertex can convey the secret message with 
some model distortion while the embedding capacity will also be higher. From equation (4), the value of the 
data-embedded distance is the function of the embedding capacity and the embedding threshold. With a 
higher embedding capacity, the changeable distance for the embedding vertex is also higher, even though the 
embedding threshold is small. Therefore, the model distortion is higher. Despite that, in Table III, for the 
Armadillo and Lucy models, we can see the distortion is still around 0.03 percent of ܦܮ஻௏. The data 
capacity is about 15.12 and 18.00 bits per effective vertex, respectively, under the embedding threshold 
ܧܶ = 3 × 10ି଺ . Along with the increasing embedding threshold, the embedding capacity for some 
embeddable vertices will be decreasing to less than one. Therefore, the total embedding capacity is lower, at 
20 
 
 
ET = 1 × 10ିଷ ET = 5 × 10ିସ ET = 2 × 10ିସ ET = 1 × 10ିସ 
 
ET = 5 × 10ିହ ET = 1 × 10ିହ ET = 5 × 10ି଺ ET = 3 × 10ି଺ 
Fig. 9: The close-up shading result of the Armadillo Model with the wireframe mode under different 
embedding thresholds 
 
Next, we discuss the relationship between the vertex selection order and the model simplified result for 
each iteration. Besides, the relationship between the vertex selection order and the embedding capacity is 
also discussed. Figs. 11 and 12 show the shading result for the left faces in the first three iterations of the 
model simplification process. Here, we define the converging speed as meaning no more following vertex 
 
 
ET = 1 × 10ିଷ ET = 5 × 10ିସ ET = 2 × 10ିସ ET = 1 × 10ିସ 
 
ET = 5 × 10ିହ ET = 1 × 10ିହ ET = 5 × 10ି଺ ET = 3 × 10ି଺ 
Fig. 10: The close-up shading result of the Lucy Model with the wireframe mode under different embedding 
thresholds 
22 
MaxNF 
MinNF 
Fig. 12. The first three iterations for the Lucy model using different vertex selection orders
 
Table IV 
The number of left vertices and embedding capacity comparisons under 
different vertex selection orders 
VSO 
Model 
IF MaxNF MinNF 
ܰெௌ Capacity ܰெௌ Capacity ܰெௌ Capacity 
Armadillo 28444 2199549 38899 2024475 26142 2220480 
Brain 73658 2187840 68327 2283582 66885 2289498 
Cow 12026 389877 11474 402845 11341 403567 
Golfball 38402 597293 31376 734305 23639 769898 
Lucy 43030 3981094 62633 3592618 35062 4101995 
Maxplanck 7773 734726 11080 668693 7521 730170 
Dragon 74196 4344942 103597 3927333 53153 4625275 
Hand 62092 2657518 75733 2522986 52084 2774833 
Finally, we compare our proposed technique with the single adaptive algorithm proposed by Cheng and 
Wang [18]. From the aspect of embedding capacity, our proposed algorithm can achieve as high as 6.27 to 
15.60 bits per vertex and 7.76 to 18.00 bits per effective vertex; while the algorithm proposed by Cheng and 
Wang can only provide 3 to 6 bits per vertex. From the aspect of model distortion, however, our algorithm 
can cause greater model distortion than their proposed algorithm. One reason may be the larger distortion 
caused by the larger embedding capacity. The other reason may be the problem of the number of decimal 
digits for representing a cover and stego model. In our implementation, both models reach a precision of six 
decimal digits. From their experimental results, the distortion is as low as 1.73 × 10ି଺ for the Teeth model. 
The stego model is probably represented by a precision of more than six decimal digits. Therefore, the 
24 
geometries is also an interesting that deserving investigation.  
REFERENCE 
[1] I. J. Cox, M. L. Miller, J. A. Bloom, J. Fridrich, and T. Kalker, Digital Watermarking and 
Steganography, Second Edition, Morgan Kaufmann, Burlington, 2008. 
[2] P. Petitcolas, R. J. Anderson and M. G. Kuhn, “Information hiding – a survey,” in Proceedings of the 
IEEE, Special Issue on Protection of Multimedia Content, vol. 87, 1999, pp. 1062–1078. 
[3] T. Y. Liu and W. H. Tsai, “Generic lossless visible watermarking – a new approach,” IEEE Transactions 
on Image Processing, vol. 19, pp. 1224–1235, 2010. 
[4] D. M. Thodi and J. J. Rodriguez, “Expansion embedding techniques for reversible watermarking,” 
IEEE Transactions on Image Processing, vol. 16, pp. 721–730, 2007. 
[5] H. C. Wu, C. C. Lee, C. S. Tsai, Y. P. Chu, and H. R. Chen, “A high capacity reversible data hiding 
scheme with edge prediction and difference expansion,” Journal of Systems and Software, vol. 82, pp. 
1966–1973, 2009. 
[6] D. Cotting, T. Weyrich, M. Pauly, and M. Gross, “Robust watermarking of point-sampled geometry,” in 
Proceedings of International Conference on Shape Modeling and Applications, 2004, pp. 233–242. 
[7] E. Praun, H. Hoppe, and A. Finkelstein, “Robust mesh watermarking,” in Proceedings of SIGGRAPH, 
1999, pp. 49–56. 
[8] H. Y. Lin, H. Y. Liao, C. S. Lu, and J. C. Lin, “Fragile watermarking for authenticating 3-D polygonal 
meshes,” IEEE Transactions on Multimedia, vol. 7, pp. 997–1006, 2005. 
[9] R. Ohbuchi, A. Mukaiyama, S. Takahashi, “A frequency-domain approach to watermarking 3D shapes,” 
Computer Graphics Forum, vol. 21, pp. 373–382, 2002. 
[10] S. Zafeiriou, A. Tefas, and I. Pitas, “Blind robust watermarking schemes for copyright protection of 3D 
mesh objects,” IEEE Transactions Visualization and Computer Graphics, vol. 11, pp. 596–607, 2005. 
[11] A. Bogomjakov, C. Gotsman and M. Isenburg, “Distortion-free steganography for polygonal meshes,” 
Computer Graphics Forum, vol. 27, pp. 637–642, 2008. 
[12] C. M. Wang, and P. C. Wang, “Steganography on point-sampled geometry,” Computer & Graphics, vol. 
30, pp. 244–254, 2006. 
[13] C. M. Wang and Y. M. Cheng, “An efficient information hiding algorithm for polygon models,” 
Computer Graphics Forum, vol. 24, pp. 591–600, 2005. 
[14] F. Cayre and B. Macq, “Data hiding on 3-D triangle meshes,” IEEE Transactions on Signal Processing, 
vol.51, pp. 939-949, 2003. 
[15] M. W. Chao, C. H. Lin, C. W. Yu, and T. Y .Lee, “A high capacity 3D steganography algorithm,” IEEE 
Transactions on Visualization and Computer Graphics, vol. 15, pp. 274–284, 2009. 
[16] N. C. Huang, M. T. Li and C. M. Wang, “Toward optimal embedding capacity for permutation 
steganography,” IEEE Signal Processing Letters, vol. 16, pp. 802–805, 2009. 
[17] Y. M. Cheng and C. M. Wang, “A high-capacity steganographic approach for 3D polygonal meshes,” 
The Visual Computer, vol. 22, pp. 845–855, 2006. 
[18] Y. M. Cheng and C. M. Wang, “An adaptive steganographic algorithm for 3d polygonal meshes,” The 
Visual Computer, vol. 23, pp. 721–732, 2007. 
[19] A. C. Rencher, Methods of Multivariate Analysis, Second Edition, Wiley, New York, 2002. 
98年度專題研究計畫研究成果彙整表 
計畫主持人：蔡淵裕 計畫編號：98-2221-E-468-017- 
計畫名稱：基於人類視覺系統之可適應性三維模型資訊偽裝技術 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 2 100% 
另一篇已投稿至
國際學術期刊，目
前正在審稿中。 
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
