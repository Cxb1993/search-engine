2 
中、英文摘要及關鍵詞 
本研究提出一套人臉偵測與辨識系統，此系統利用多角度影像擷取來提高人臉偵測與
辨識之可靠性。在此系統中，我們設計了不同的類神經網路來從不同視角的攝影機影像中
擷取出人臉的眼睛和鼻子，然後再抽取出完整的人臉影像。依據擷取出的眼睛和鼻子位置，
此系統可以自行判斷哪一個視角抽取出的人臉影像最適合人臉之辨識，依此得到更高之辨
識率。在實驗中，除了評估本系統在眼睛、鼻子、人臉之偵測率外，我們也採用不同的人
臉辨識引擎來評估本系統之辨識效能。實驗結果證實本文所提之方法的確可以提高系統在
人臉偵測以及辨識上的效能。 
 This thesis proposes a face detection and recognition system. The proposed system 
employs the capturing of multi-view images to raise the reliability in detecting and recognizing 
faces.  Within the system, we design different neural networks to extract eyes and noses from 
the captured multi-view images. Afterwards, the system autonomously determines the best image 
view to extract the target face for recognition. In this way, a higher recognition rate can be 
achieved. In the conducted experiments, besides the assessment of detection rates for eyes, noses, 
and faces, we also evaluate the system＇s face recognition rate using two different recognition 
engines. The results show that the proposed design does improve the performance in terms of 
both face detection and recognition. 
 
Keywords: Biometric System, Face Recognition, Neural Networks, Multi-view Capturing, 
Facial Component Detection
4 
4.2. Eigenface 特徵 ..................................................................................25 
建立特徵空間 ..........................................................................................26 
訓練樣本投影到特徵空間 ......................................................................27 
測試樣本投影到特徵空間 ......................................................................27 
4.3. Fisherface 特徵..................................................................................27 
4.4. 分類方法 ..........................................................................................29 
4.4.1. 距離函數.....................................................................................30 
4.4.2. 分類演算法.................................................................................31 
5. 實驗結果 .............................................................................................32 
實驗環境介紹................................................................................................... 32 
人臉偵測實驗................................................................................................... 32 
5.1. 眼睛偵測 ..........................................................................................32 
5.2. 鼻子偵測 ..........................................................................................33 
5.3. 人臉偵測 ..........................................................................................34 
5.4. 人臉辨識實驗 ..................................................................................35 
6. 結論與未來研究方向 .........................................................................37 
6.1. 結論...................................................................................................37 
6.2. 未來研究方向 ..................................................................................37 
參考文獻...................................................................................................39 
 
 
6 
表目錄 
表 5.1-1 眼睛偵測率效能表 ................................................................................... 33 
表 5.2-1 鼻子偵測效能表 ...................................................................................... 34 
表 5.3-1 人臉偵測效能評估 .................................................................................. 35 
表 5.4-1 人臉辨識結果 .......................................................................................... 35 
表 5.4-2 針對正臉選擇器人臉辨識結果統計 ...................................................... 36 
 
 
 
 
 
 
 
 
 
8 
你必須有著同樣多的訓練樣本，如此一來，將使得收集訓練樣本更加麻煩複
雜。針對上述兩個主要的問題，本論文提出一套新穎的人臉偵測與人臉辨識架
構，減少多角度對偵測及辨識的干擾。 
本論文的研究主要考慮多角度人臉辨識。人臉辨識系統可以分為兩個主要
部分：人臉偵測、人臉辨識。本篇論文將對此兩部分做探討研究。 
 
10 
再運用其他驗證程序做人臉區域之確認[14][16]。 
4. 樣版比對的方式( Template Matching )： 
事先收集多張人臉樣版，再用所蒐集的樣本去比對影像中是否有 
人臉區域[15]。這樣的方式將不利於即時的系統偵測，因為所耗的系 
統運算和記憶體極高。且要收集不同角度之比對樣版，將使資料庫更 
顯笨拙龐大 
2.2. 人臉辨識相關技術 
人臉辨識的技術再這幾十年來已經有不少的研究結果，尤其是統計的方
式，包括利用 Principal Component Analysis (PCA) 抽取 Eigenface 特徵的方法
以及利用 Fisher Linear Discriminant (FLD) 抽取 Fisherface 特徵的方法都是在
辨識方便有相當的成果貢獻。PCA 是用統計的方法，對所有樣本作統計分析，
但是主要用在降低資料維度，無法有效區別樣本。FLD 改良 PCA 的表示，另
外加入不同類別的區分度考量，使得 FLD 更具有辨識力的效果，可是對於同
類別中差異太大(如光線、角度)的資料影響還是有所限制。 
    這些論文在做 PCA 與 LDA 的比較探討。而特徵的選取也是許多研究探討
的重點，例如用小波轉換得到的特徵以及由紋理得到的 Gabor 特徵，這些特徵
可以增加額外的資訊來提升辨識率。另外分類方面也有多人文獻的探討，不同
分類器會造成不一樣的效果，除了傳統的統計方法，如貝氏定理(Bayes Rule)，
還有使用類神經網做分類辨識的方法，適當的網路模式與訓練方法的確可以提
升辨識率，但是如何選曲網路模式與訓練方法確實是類神經網路中的重要問
12 
人臉角度，進而選取出具有辨識資訊的人臉影像的，而且抽取出的人臉也將頭
髮以及鼻子以下的區域排除，藉此降低五官中變化最劇烈的嘴巴之影響以及經
常在改變的頭髮特徵，希望可以達到免受限制的自動人臉辨識系統。 
    本篇論文中探討的人臉偵測方法是以人臉元件(眼睛和鼻子)為基礎，利用
類神經網路找出眼睛以及鼻子的位置，進而切割出人臉的影像。在人臉辨識的
部分採用 Eigenface 和 Fisherface 兩種特徵，對於人臉偵測所得的結果去做分
類。 
3. 人臉偵測系統 
3.1. 簡介 
本章節中，我們將詳述如何從攝影機擷取到的影像中偵測人臉的位置。以
供後續辨識之進行。為了達成此一任務，我們將結合影像處理，膚色偵測，類
神經網路和幾何規則等方法，將其整合成一系列演算法，以建立一套完整的人
臉偵測系統。整個流程圖如圖 3.1-1所示。 
背景移除 
    我們從連續影像中選取一張沒有前景的影像，當做是背景的影像，如圖
2.2(a)。計算每一張輸入影像中，每一個像素點與背景影像同位置的像素點之
間 RGB 亮度值的歐基里德距離，其公式如下： 
222 )),(),(()),(),(()),(),(( yxIyxIyxIyxIyxIyxIDiff BBCBBGCGBRCR −+−+−=  (2-1) 
其中 I 表示亮度值，C 與 B 分別表示目前影像與背景影像，RGB 分別代表紅
色、綠色、藍色，(x,y)代表影像上的任一點坐標。若計算出來的差距大於一個
極限值，表示此像素點與背景不相似，因此是不屬於背景的前景。以此方法對
整張輸入影像做運算，我們就可以將前景物件的部份標記出來，如圖 2.2(b)(c)
所示。 
 
 (a) 背景影像 
     
       (b) 輸入影像                   (c) 前景影像 
圖 3.2-1 移除背景 
14 
因為白點(r=0.33, g=0.33)會在我們所定義的範圍之內，所以我們必需將之排
除。 
22 )33.0()33.0( −+−= grW   (2-4) 
判斷膚色的方法：s 表示前景物件上的任一點的膚色二元資料 
⎩⎨
⎧ ><>><=
otherwise
Wrrrfgrfgif
s
0
)0004.0(&)6.0(&)2.0(&))(2(&))(1(1
 (2-5) 
接下來我們使用形態學(Morphology)中的侵蝕運算(Erosion)及擴張運算
(Dilation)這兩個技術所衍伸的斷開運算(Opening)和閉合運算(Closing)來消除
雜訊和填補空洞。然而，斷開運算僅能消除面積較小之雜訊，其無法消除之雜
訊將利用相連元件標記排除之。 
如此，即可獲得前景物件的膚色二元資料，其結果如圖 3.2-3所示。 
    
         (a)前景區域                   (b)膚色區域 
    
(c)前景膚色區域             (d)形態學運算後結果 
圖 3.2-3 前景膚色區域標記 
16 
          (a)排除前                    (b)排除後 
圖 3.2-5 排除面積較小元件之結果 
3.3. 以臉部元件為基礎人臉偵測器 
    經由前處理可以得到影像中我們所需要的膚色區塊，接下來利用我們所提
出的人臉偵測器，從影像中擷取出人臉區域以及該區域的正臉係數(Frontal 
Face Coefficient)，簡稱 FFC，其流程如圖 3.3.1 所示。 
 
圖 3.3-1 以臉部元件為基礎人臉偵測器 
    為了偵測不同大小的人臉，首先會對前處理的結果用二次取樣
(Subsampling)建立不同大小的影像，首先利用我們所訓練的捲積眼睛偵測器
(Convolutional Eye Finder)，簡稱 CEF，利用輸入影像的灰階資訊找出眼睛的
位置，接下來使用我們所訓練的捲積鼻子偵測器(Convolutional Nose Finder)，
簡稱 CNF，同樣利用影像中灰階資訊找出鼻子的位置，最後利用眼睛與鼻子
得到人臉位置以及正臉係數。 
18 
MLP)，使用 log sigmoid 作為激發函數(activation function)，其中隱藏層有 10
個神經元，訓練演算法採用 Back-Propagation，訓練樣本由我們收集的人臉辨
識影像序列資料庫中，以人工的方式切割出 600 個眼睛樣本，非眼樣本則使
用 bootstrap 方法收集，一共產生 5016 個非眼樣本。 
3.5. 捲積鼻子偵測器 
    在章節 2.3.1 中，已經得到眼睛的資訊，因此我們利用眼睛的位置資訊訂
定捲積鼻子偵測器的搜尋範圍。將此範圍的影像擷取出來後，同樣的對它做二
次取樣，再實行以類神經網路為基礎的濾波器運算，以輸出值最高的對應視窗
作為偵測結果，流程如圖 3.5-1 所示。 
 
圖 3.5-1 捲積鼻子偵測器流程圖(CNF) 
在此採用的類神經網路模型為多層感知器(Multilayer Perceptron ,簡稱
MLP)，使用 log sigmoid 作為激發函數(activation function)，其中隱藏層有 10
個神經元，訓練演算法採用 Back-Propagation，訓練樣本由我們收集的人臉辨
識影像序列資料庫中，以人工的方式切割出 235 個眼睛樣本，非鼻樣本則使
用 bootstrap 方法收集，一共產生 883 個非眼樣本。 
20 
 圖 3.6-2 雙眼與眼部膚色區域重心特性 
    如此一來，雙眼重心與眼部膚色區域重心之距離可以作為臉部角度分析的
資訊，但是若是只以此距離參數作為準則，不同大小的臉部區域將影響此距離
參數，因此我們再加上了雙眼之間距離作為另一個參數，用來正規化，使得角
度分析不受到不同大小而影響。我們所提出的正臉係數定義如下。 
D
CC
FFC 21
−=       (2-6) 
其中 C1 為雙眼的重心之 X 軸座標，C2 為眼部膚色區域的重心之 X 軸座標，
D 為雙眼之間的距離。 
當正臉係數值越小，表示此臉部影像越接近正臉。反之，則越不接近正臉。 
 
 
 
 
 
 
22 
24 
    前置處理包含利用正臉選擇器，選出多台攝影機中最具變式資訊的臉部影
像，以及影像大小正規化。 
正臉選擇器 
    利用前述之正臉係數，從多台攝影機擷取出的人臉影像中，選擇正臉係數
最小之影像，當作辨識系統之輸入影像。 
影像正規化 
    由人臉偵測或者是人工切割所得的人臉影像，其大小規格不一定是相同
的。所以對人臉影像做大小正規化是一件必要的工作，必須使影像在相同大小
的條件下才可對其資料做分析與特徵抽取。 
    影像大小正規化是利用內插法(Interpolation)達成，包括最接近鄰居內插法
(Nearest Neighbor Interpolation)與雙線性內插法(Bilinear Interpolation)兩種。找
最接近鄰居內插法就是由輸出影像找出與輸入影像相對應的最接近鄰居的灰
階值來代表其像素灰階值。而雙線性內插法則是對原始影像的行與列分別做內
插所得到的灰階值當作轉換後的灰階值。 
    經過統計，由我們的人臉偵測器得到臉部影像，長寬比例接近 3:2，因此
我們將所有得到的臉部影像正規化成 60*40 像素的解析度，再進行後續的工
作。 
特徵抽取 
    特徵抽取對辨識系統是很重要的，如何抽出足夠代表原始樣本資料又可以
具有辨別力的特徵，是一個重要的議題。我們採用幾種人臉辨識研究常用的方
法，分別討論之。 
(Eigenvalue)與特徵向量(Eigenvector)。由非零的特徵值所對應的特徵向量(任兩
個特徵向量都是正交且正規化)就是特徵空間。 
    如何特徵抽取呢？大致上可分為三個部份：建立特徵空間、訓練樣本投影
到特徵空間、測試樣本投影到特徵空間。特徵抽取後再由測試樣本特徵去對訓
練樣本特徵做比對。以下對於 PCA 特徵抽取的三部份之流程作說明。 
建立特徵空間 
特徵空間的計算可以分為五個部分： 
I.求平均值：將訓練樣本加總起來除以個數。 
Ti
N
ii
K
i
i xxxwherex
K
m ]...[_,1 1
1
== ∑
=
         (3-1) 
K 為訓練樣本個數，N 為每一樣本之維度。 
II.Zero Mean：把所有訓練樣本剪掉平均值。 
Kwhereimxx ii ...1, =−=              (3-2) 
III.計算 Covariance Matrix： 
∑
=
=Σ
K
i
Tii xx
1
                          (3-3) 
IV.計算特徵值與特徵向量：由 Covariance Matrix 來求得特徵值與特徵向量。 
ii λφφ =∑                              (3-4) 
iφ 為所求之特徵向量，λ則為特徵值。 
V.計算特徵空間：依照計算得到的特徵值由大到小做排序，將所對應的特徵向
量組合而成特徵空間，而選取的特徵向量則為所對應的特徵值是非零的特徵向
26 
越好，SW越小越好，也就是希望同一類別的資料更集中，相對的不同類別的
資料區隔越遠越好，可以加強資料的辨別力。PCA 由於只考慮全部的
Scatter(ST)，沒有對不同類別作區分考慮，因此無法像 FLD 有效的區隔樣本，
且大量樣本間容易產生干擾。 
    FLD 的特徵抽取也是可分三部份：建立 FLD 的轉換空間、訓練樣本投影
到 FLD 的轉換空間、測試樣本投影到 FLD 的轉換空間。由 FLD 轉換後得到
的特徵來做比對。以下對於 FLD 特徵抽取的三部份的流程作說明。 
1.建立 FLD 的轉換空間 
FLD 的轉換空間可以分成幾個部分： 
I.求 Within Class 與 Between Class 的平均值：對每一個同類別的樣本計算平均
執(Within)，以及所有樣本計算平均值(Between)。 
Class Mean： cwherejxK
m
jK
j
jj ∈= ∑
=
,1
1
        (3-9) 
        Kj表示 j 類別裡的樣本個數。 
        Total Mean： ∑∑∑
===
==
c
i
i
K
j
i
c
i
KwhereTx
T
m
i
111
,1   (3-10) 
        c 代表類別個數。 
II.計算Within Class Scatter：分別計算每種類別裡面的Covariance Matrix，並且
將所有類別的Covariance Matrix 加總起來。 
∑∑
= =
−−=
c
i
K
j
T
jjjjW
i
mxmxS
1 1
))((               (3-11) 
III.計算Between Class Scatter：對每種類別的平均值與所有訓練樣本的平均值
28 
4.4.1. 距離函數 
這裡列出幾種比較常用的距離函數公式，對於辨識方面的效果也並不是都
有相同的表現。 
1. Manhattan 
曼哈頓（Manhattan）距離就是1-norm，直接計算相對應的座標之間差的絕對
值的總和。 
∑
=
−=
M
i
ii baBA
1
),(Manhattan                  (3-17) 
其中 、 。 TMaaaA ],...,,[ 21= TMbbbB ],...,,[ 21=
2. Euclidean 
歐幾里得（Euclidean）距離就是2-norm，將相對應座標軸的平方總和開根號，
是最常用於計算距離的公式。 
∑
=
−=
M
i
ii baBAEuclidean
1
2)(),(              (3-18) 
其中 、 。 TMaaaA ],...,,[ 21= TMbbbB ],...,,[ 21=
3. Mahalanobis 
Mahalanobis 距離就是在計算距離時，須考慮同一類資料間的平均值與變異
數。 
        
2
1
),( ∑
= ⎟
⎟
⎠
⎞
⎜⎜⎝
⎛ −=
M
i i
ii
B
aCAsMahalanobi σ
μ
          (3-19) 
        其中 ，μi表示類別 CB第 i 維的平均值(Mean)，σi表
示 CB 樣本第 i 維的標準差(Standard Deviation)。 
T
MaaaA ],...,,[ 21=
30 
32 
5. 實驗結果 
本章針對先前的人臉偵測以及人臉辨識演算法，分別做實驗與討論，以系
統實作之結果及數據分析，來驗證理論之可行性。第一節介紹系統的實驗環
境，第二節介紹人臉偵測的效能，第三節則是辨識的結果。 
實驗環境介紹 
我們實驗的系統環境說明如下： 
作業系統：Microsoft Windows 2000 Professional 
CPU：Inter Pentium 4 2.8GHz 
記憶體：512 MB 
攝影機：SONY DCR-PC101 
軟體設計：Microsoft Visual C++ 6.0、The Mathworks Matlab 7.0.1 
實驗用資料庫：自行拍攝之影像序列，共 15 人。 
人臉偵測實驗 
    本節將對本系統所提出的以臉部元件為基礎人臉偵測器效能做評估，由於
臉部的偵測以及定位皆是依靠臉部元件(眼睛、鼻子)的偵測，因此眼部偵測器
以及鼻子偵測器的效能評估也相當重要。 
5.1. 眼睛偵測 
    眼睛偵測在本系統占有重要的地位，人臉偵測器的偵測及定位皆需仰賴眼
睛和鼻子的偵測結果，而鼻子偵測也須在眼睛偵測成功的前提下才能運作，另
外我們所提出的正臉係數，亦是憑藉著眼睛偵測的結果得到。為了能知道眼睛
樣本編號 應偵測數 偵測數目 偵測率 偵測錯誤 偵測錯誤率
1 142 139 0.978873 1 0.72%
2 137 134 0.978102 0 0.00%
3 140 136 0.971429 1 0.74%
4 135 132 0.977778 2 1.52%
5 144 141 0.979167 0 0.00%
6 142 139 0.978873 1 0.72%
7 140 138 0.985714 0 0.00%
8 138 133 0.963768 2 1.50%
9 139 134 0.964029 0 0.00%
10 136 135 0.992647 1 0.74%
11 133 132 0.992481 3 2.27%
12 141 136 0.964539 1 0.74%
13 139 138 0.992806 1 0.72%
14 138 133 0.963768 2 1.50%
15 136 132 0.970588 0 0.00%
總計 2080 2032 0.976923 15 0.74%  
表 5.2-1 鼻子偵測效能表 
    由統計數據可知，本系統之鼻子偵測率為 97.69%，偵測錯誤率為 0.74%。 
5.3. 人臉偵測 
    在這裡我們將對整合了眼睛偵測、鼻子偵測以及正臉選擇器的人臉偵測系
統做效能評估，同樣的我們也將統計將閉眼狀況排除的偵測率。如表 5.3-13 
樣本編號 應偵測數目偵測數目 偵測率 排除閉眼偵測率p偵測錯誤率
1 150 139 92.67% 94.56% 1.44%
2 150 134 89.33% 93.06% 2.99%
3 150 136 90.67% 95.10% 1.47%
4 150 132 88.00% 91.03% 4.55%
5 150 141 94.00% 95.27% 1.42%
6 150 139 92.67% 95.86% 2.16%
7 150 138 92.00% 96.50% 2.17%
8 150 133 88.67% 94.33% 5.26%
9 150 134 89.33% 91.78% 2.24%
10 150 135 90.00% 95.07% 2.22%
11 150 132 88.00% 91.03% 5.30%
12 150 136 90.67% 95.77% 2.94%
13 150 138 92.00% 95.17% 1.45%
14 150 133 88.67% 92.36% 3.76%
15 150 132 88.00% 90.41% 2.27%
總計 2250 2032 90.31% 93.81% 2.76%  
34 
Eigenface Fisherface
正臉選擇 93.55% 95.28%
非正臉選擇 74.60% 78.76%
辨識率效能比較
 
表 5.4-2 針對正臉選擇器人臉辨識結果統計 
    由表 4.3.2 可知，無論是使用何種辨識方法，經由我們提出的正臉選擇器
可以選擇出比較具辨識力的正臉影像，驗證了我們所提出的架構，使得人臉辨
識系統在偵測方面，能擁有更寬鬆的使用者限制，而在辨識方面，有效的減低
側臉對辨識系統的干擾。 
 
 
 
36 
38 
對人臉影像做分類，與多角度人臉辨識作更緊密的結合，進而得到更好的辨識
效果。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
40 
Symposium (NORSIG 2000), June 13-15, Kolmarden , Sweden , 
P.383-386 (2000). 
 
[7] M. Störring, H. Andersen, and E. Granum , “Estimation of the 
Illuminant Colour from Human Skin Colour “ , In IEEE 
International Conference on Face & Gesture Recognition, pages 
64-69, Grenoble, France, March 2000. IEEE Computer Society. 
 
[8] A. Albiol, L. Torres, E. Delp, C. Bouman.” A Simple and Efficient 
Face Detection Algorithm for Video Database Applications “ , IEEE 
International Conference on Image Processing, Vancouver, Canada, 
September 10-13, 2000.  
 
[9] K. Schwerdt and J. L. Crowly. “ Robust Face Tracking using 
Color ”, In Proc of the International Conference on Face and 
Gesture Recognition, pages 90 - 95, Grenoble, France, 2000. 
 
[10]Haiyuan Wu , Qian Chen , and Masahiko Yachida , “ Face Detection 
From Color Images Using a Fuzzy Pattern Matching Method,” IEEE 
Trans. on Pattern Analysis and Machine Intelligence , Vol.21,No.6, 
pp.557-563,Jun,1999. 
 
[11]Ishii, H.. Fukumi, M.. Akamatsu, N. “ Face Detection Based on Skin 
Color Information in Visual Scenes by Neural Networks “, IEEE 
SMC '99 Conference Proceedings. 1999 IEEE International 
Conference on , Vol.5, pp.557-563,1999 
 
[12]D.Anifantis, "A Neural Network Method For Accurate Face 
42 
 
[20]Zhujie and Y. L. Yu, “Face Recognition with Eigenfaces”, Proc. 
IEEE Conf. on Industrial Technology, pp. 434-438, 1994 
 
[21]M. Turk and A. Pentland, “Eigenfaces for Recognition” Journal of 
Cognitive Neuroscience, Vol. 3, pp. 72-86, 1991.  
[22]Belhumeur P., Hespanha J., and Kriegman D., ”Eigenfaces vs. 
Fisherfaces: Recognition Using Class Specific Linear Projection”, 
IEEE Trans, PAMI, 19(7): 711-720. 1997 
 
[23]Weng Hang Tam , “A Human Face Tracker System Design Study 
Using the Technology of Digital Image Processing 
“ http://datas.ncl.edu.tw/theabs/00/
 
[24]Martinez, A.M.; Kak, A.C., “PCA versus LDA”, Pattern Analysis 
and Machine Intelligence, IEEE Transactions on, Volume: 23 Issue: 
2, pp. 228-233, 2001 
 
[25]Q .Chen , H . Wu, and M . Yachida , “ Face Detection by Fuzzy 
Matching “Proc. Fifth IEEE Int’l Conf. Computer Vision , 
pp.591-596,1995. 
 
[26]Zhao W., Krishnaswamy A., Chellappa R., Swets D., and Weng J., 
“Discriminant Analysis of Principle Components for Face 
Recognition”, 3rd International Conference on Automatic Face and 
Gesture Recognition, pp. 336-341, 1998 
 
[27]Richard O. Duda, Peter E. Hart, David G. Stork, Pattern 
