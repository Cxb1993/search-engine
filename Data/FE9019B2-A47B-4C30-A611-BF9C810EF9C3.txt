 2 
行政院國家科學委員會專題研究計畫成果報告 
以語音情緒辨識技術為基礎之情緒感知行動通訊服務 
 
計畫編號：NSC 96－2221－E－036－034－ 
執行期限： 96 年 8 月 1 日至 97 年 7 月 31 日  
主持人：      鄭穎懋   大同大學資訊工程學系 
計畫參與人員：徐浩元   大同大學資訊工程學系 
計畫參與人員：林明威   大同大學資訊工程學系 
計畫參與人員：李肇龍   大同大學資訊工程學系 
 
 
中文摘要 
情緒遍及於人們日常生活當中。它影
響人們的感受、行為，與想法，而這些正
是人們如何感知以及與實體世界互動之要
素。情緒與人們的行為有緊密的關聯。它
幫助人們面對不同的情況並能做出適當的
反應。此外，從人與人之間互動的角度來
看，情緒的交流是建立與維繫人們之間社
交往來關係最重要的因素。行動通訊的發
展與普及使得人與人之間的溝通能突破時
間與距離障礙。此時行動電話在某種程度
上已成為一種情感科技。也就是說行動電
話能幫助傳達人們間情緒的表現及交流以
維持彼此的關係。然科技能便於人，亦能
礙於人。或許發話者的方便會成為受話者
的干擾。於是，在此趨勢下之「殺手級」
應用必須以「人」的需求為首要考量。人
本研究方法將有助於跳脫此兩難局面。完
整調查某環境中人們的活動有助於取得技
術發展的需求。此研究計畫動機在討論語
音情緒辨識如何促進遠距社交互動。而使
用者接通電話前希望獲得更多發話方資訊
的需求趨勢也強化了本研究動機。例：使
用者藉由指定響鈴或圖像於不同對象，使
其「聽到」或「看到」時即得發話者的資
訊。潛在應用即藉由探測人們使用語音撥
號得知其情緒狀態，並轉送受話方以豐富
彼此間的交流。以下步驟將引導整體研
究：需求探勘與分析、概念設計、實做雛
型、評估。未來將完成之情緒感知行動通
訊服務也希望能成為技術與社會科學的研
究平台。 
關鍵詞：Human emotion, social interaction, 
emotion-aware/affective computing, mobile 
communication, human-centered design, speech 
recognition 
 
Abstract 
Emotion pervades our everyday activities. It affects 
how we feel, behave, and think, which are essentials 
of how we perceiving and interacting with the 
physical world. Emotion has strong connection with 
our behavior. It helps get us ready to suitably respond 
to various immediate situations. Moreover, from the 
interpersonal point of view, sharing emotions is 
utmost important for the creation and sustentation of 
social bonds. The development and proliferation of 
mobile communication services have extended the 
opportunity for social interaction between people 
without barrier in time and distance. Mobile phones 
have somewhat become affective technologies. That 
is to say, they can mediate the expression and 
exchange of emotions between people in order to 
help maintain relationships among them. However, 
technology can be a facilitator in one hand and an 
interrupter on the other. One caller’s convenience 
may be another recipient’s interruption. It is, 
therefore, building potential “killer applications” 
based on these obvious trends must put people first. 
Human-centered research approach can help smooth 
away the dilemma and structure the innovation and 
evaluation of meaningful use scenarios for future 
technologies. From the human-centered perspective, 
the existence of technologies is there to help people 
carrying out various activities in wide range of 
different contexts. Thoroughly investigating activities 
undertaking by certain types of people in specific 
contexts will help establish requirements for 
technologies. Technologies in turn provide 
opportunities to change or enhance the essence of 
people’s activities. This approach nicely 
complements and co-ordinates the multidisciplinary 
nature, especially human factor and information 
technology, of emotion-aware computing research. 
The motivation of this proposed research is by the 
question that how recognition of emotions in speech 
could be utilized for enhancing remote social 
interaction. This research is also motivated by the 
inspiration of the trend that most of the current 
mobile phones provide their users with features that 
help them gather more context about the callers 
before they pick the phones. For example, the users 
 4 
關鍵詞: Human emotion, social interaction, 
emotion-aware/affective computing, mobile 
communication, human-centered design, speech 
recognition 
1. 概述  
情緒是人與生俱來的天性，它會隨著
人所遭遇的事物而改變；人們在談話交流
時會因為對方的情緒而調整自己的態度或
談話內容，因此情緒的反應增進了人與人
之間的互動。為了要與不在身旁的人傳遞
訊息，人們有了通訊的需求；隨著時代演
進，手機成為現今人們在遠距通訊上的主
要媒介之一，且藉此媒介傳遞訊息、交流
情感。以現今手機廣泛普的角度而言，人
們的確是有利用科技產品作為媒介交流情
感 的 特 性 。 而 情 感 運 算 (Affective 
Computing)此方面的研究也因此而生[1]。
Amparo Lasen[2]亦提出，於情感科技
(Affective technologies)方面，手機和人們
的情感變動是相當緊密的。手機是人們來
闡述、展示、及分享經驗的主要媒介，並
且在通話時抒發、分享交流彼此的情感。 
在行動通訊普及的生活環境中，即時
的互動信息增進了人們的情感交流，除了
在即時的語音通話可以溝通彼此之外，其
他種類的信息亦有類似的需求以及效果。
如傳統的純文字簡訊 SMS，多媒體簡訊
MMS，以及可即時傳輸影音的 3G 影像電
話等，都是行動通訊中常見的交流情感途
徑。此外在簡訊的內容之中，除了所文字
陳述之外，人們亦常利用一些帶有表情的
人臉圖案  (Iconic Faces) [3]等情緒圖示 
(Emotional icons)[4]來強化所表達的情
感，而 emoto[5]利用使用者所傳遞之不同
顏色及形狀背景的 MMS 內容呈現使用者
的情緒狀況，而接受者除了在簡訊的內文
之外，亦可以在簡訊的背景之中了解發送
者在編輯傳遞 MMS 時的情緒，增進了彼
此之間的交流。 
行動通訊使得在不同地方的人們得以
即時同步地聯絡、溝通，就如同面對面對
談一般。而人與人在面對面對談時，除了
口語溝通的內容之外，彼此之間面部表
情、手勢、動作、以及所處之環境等都具
有情感資訊傳遞的強化輔助作用。行動通
訊排除了人們在溝通上的距離隔閡，使得
在不同地方的人也可以利用手機來即時的
溝通彼此、傳遞訊息。然而受限於科技產
品的性能，在即時傳遞的內容上可能只保
留如影像、聲音等資訊（一般手機或者 3G
手機），並不能完全如面對面般全盤了解彼
此及周遭所呈現之不同種類的情緒訊息。 
因此，利用手機這種情感媒介，擷取
人們自然而然呈現的情緒特徵、如語音、
手勢、表情等加以應用，強化在手機通訊
上的情感交流，是許多人所致力的方向。
之前所提及的 emoto，利用了配有感應器
的觸控筆，讓人們在 Smartphone 上使用觸
控筆來輸入簡訊內容，擷取在此時人們使
用觸控筆時所施展的壓力以及搖動特徵，
來對應了人們的情緒，並且以不同的簡訊
背景的呈現來強化情感，並且透過所呈現
的背景來增加簡訊的收發雙方在文字內容
之外情感互動，藉此營造出雙方同在一起
的感覺(copresence)。 
在實質的通訊內容之外，藉由感知機
制來確實的傳達使用者的情緒資訊來營造
copresence 的氛圍讓使用者擁有如面對面
般對談的感受，而手機即為情緒抒發以及
呈現的平台，藉由以額外的情緒資訊讓使
用者可以即時了解並且自然而然的連結應
對，達到增進情感互動的效果。在擷取、
感知人們的情感部份，可能有不同的方法
以及感知目標，然而在手機的情感應用
上，強化使用者彼此的情感互動是我們所
致力的方向。利用現有常見的手機通訊途
徑，增加額外的情緒訊息，營造 copresence
的氣氛來強化現有手機通訊的情感互動，
是此案的目的。 
在提案時我們以聲音撥號做為手機擷
取情緒的來源，在這部份的研究我們還在
進行中。在連續語音的情緒辨認方面，運
用了不同的分類法及特徵參數找出了 32
個具有良好辨識效果的特徵值組合，運用
這些組合在使用的資料庫具有 84％的辨
識率，並且探討特徵參數運用於不同分類
法的辨識結果[26]。然而以應用於手機的
情緒感知而言，聲音並非唯一的輸入來
源；而人們在撥號時亦不一定會以語音撥
號作為輸入方式，因此我們針對其他方式
 6 
自然而然的施展。 
 
2. 文獻探討 
由於情緒來電是一嶄新的手機服務，
為了尋找適合於此資訊的方法，對於相關
於情緒的輸入及呈現必須討論，並且針對
整體互動的情境狀況所造就的互動氛圍：
遠距溝通的雙方藉由互動方式所營造出的
同在一起的氣氛及感覺予以探討，因此情
緒來電所關注的重點方向可以歸納為下列
三個要點來探討： 
 情緒輸入及辨識 
 情緒訊息的呈現 
 互動氛圍 
2.1. 情緒輸入及辨識 
2.1.1. 情緒分類[10, 24] 
人的情緒複雜，而一般人在陳述及表
達自我情緒時，表達的程度和方式多少會
因人而異，對於同樣的情緒所感受及表達
的程度也會有所不同。針對如此問題，W. 
Parrot 舉出了 Philipp Shaver 等人蒐集了
213 組不同的情緒表達詞彙，加以分類成
六組集合，並且以樹狀表的方式做為分類
法，以三種要素來維繫：Primary emotions, 
secondary emotions, tertiary emotions (如圖 
1 所示) [10, 24]。 
 
 
圖 1. 情緒敘述分類的樹狀結構圖[10] 
 
另一方面，為了清楚表示對於某種情
緒的一些特性，情緒二維圖 (Arousal - 
Valence)[25]也是一種呈現方式，將情緒映
射在二維圖上，根據圖上的二維座標來表
達及定義此情緒的特色。Arousal (y-axis)
表達了人們的情緒激昂程度，自安靜至極
度激動之間的範圍；而 Valence (x-axis)表
達人們的正負面程度的情緒，也可說是對
於某事物是喜歡或者不喜歡的感情及心理
上的特徵，為表達情緒狀態的基本元素。
藉由此二者的組合可以表達出不同程度跟
種類的情緒，如圖 4 即為不同情緒種類於
情緒二維圖上的表示，此為顏色、圖示以
及情緒種類於二維圖上的分佈。 
 
2.1.2. 情緒手勢輸入 
2.1.2.1 常見的情緒手勢 
面對於人們複雜多變的情感方面的表
現，仍然有一些手勢是公認且可以明顯辨
識出來的，Fagerberg, P 等人[11] 根據
Laban 的理論並且請演員表演而提出了九
種代表性的情緒手勢 (圖 2) ，利用理論中
的 effort graph 陳述其特徵(圖 3)。 
 
圖 2. 九種情緒手勢 [11] 
 
 
圖 3. 利用 effort graph表現出不同手勢的特徵[11] 
 
2.1.2.2 手勢辨識的方法 
根據辨識所採用的擷取資訊不同，可
分成以下三種方法： 
 Vision-based (利用照相機捕捉影像) 
[12, 13, 14] 
 Body-sensor-based (加速度感應器) [5, 
7, 32] 
 Multi sensor (混合以上兩種裝置) [15] 
Vision-based 利用分析所捕捉到的圖
像顏色(color)以及質地(texture)來分析變
化、位移，以此來判斷部位運動的狀況，
應用於的範圍很廣，包含臉部表情、點頭
 8 
 
圖 11. 利用 Bayesian network 做手勢施展者的文
化背景分析歸納[34] 
 
2.2. 情緒訊息的呈現 
利用意義鮮明的圖案 Icon，有助於幫
助我們了解現在所呈現的狀況[4]，且在相
關的研究指出，色彩及形狀對於人們的情
緒亦有投射，Ståhl, A 等人[16]提出形狀和
顏色於人們情緒的對應(圖 4)，並且將此系
統應用於 emoto[5]的情緒資訊的呈現上。
情緒訊息的應用主要是以圖像、顏色等方
式讓人們可以更直覺性的了解情緒的表
達，Yan Li 等人提出藉由分析人們聲音的
情緒方面之特徵，並且依照所得到不同程
度及種類的情緒，以不同樣式的人臉表情
圖案呈現(圖 5) [26]。Yuasa, M[42]等人對
於一些人們在利用文字輸入簡訊時所輸入
的一些情緒臉譜圖案(Emoticon)做了相關
的解析及研究，人們會利用現有的文字所
能輸入的符號來加以組合成為臉部表情圖
示來做為交流情感的媒介圖示(圖 6) 
 
圖4. 顏色、形狀與情緒之對應[16] 
 
 
圖5. 不同程度的人臉表情變化[26] 
 
 
圖6. 利用文字符號組成的情緒表情[42] 
 
2.3. 互動氛圍 
2.3.1. Coprsence 
Zhao[28]提出 Coprsence 定義： 
 在使用者之間是處於彼此雙方實際上
所在距離相隔甚遠的狀況下，擁有著
和對方同在一起的感覺 
 使用者彼此雙方身處於一個虛擬的環
境中，然而卻有一種與對方同在一起
的感覺 
而使用者可能通過網路通訊技術進行情感
交流，來感受如兩人身處同處的感覺
(Tele-coprsence)，其中可能是實際上的言
語交流，如手機通訊等等。或者是藉由虛
擬的方式，以互動的 agent 方式來交流，
藉由模擬人們的反應情況，來做到情境模
擬的感覺。 
以營造同在一起的氣氛效果做為加強
互動的依據，建立起情緒資訊傳遞的平
台，讓使用者可以用簡單明瞭的方式了解
對方的情緒資訊。Subtle Stone[17]提供了
在課堂上，師生之間互動平台，以此讓老
師可以即時地掌握學生的學習狀態，而學
生亦可以在不用礙於同儕之間的競爭以及
打斷上課的尷尬情況下，表達自己學習的
狀況。MatchUs Board[18]利用同時的經驗
共 享 (Shared experience) 及 環 境 認 知
(Situational awareness)，讓分處兩地的伴侶
們可以藉此做共同的經驗互動，營造出雙
方有如面對面相處的氣氛。 
 10
社交、禮貌因素而不方便接電話 
 任務狀態：正在工作、或者正在進行
專注的某件事情如看電視而不想接電
話 
 情感障礙狀況：如果受話者接了這通
電話會造成一些情感方面的困擾，如
吵醒旁邊的人造成他人不悅的狀況 
 其他：別於之前狀況的一些詢問事情
或者描述情況 
 無法接通：如手機關機的狀況 
針對這些狀況進行頻率統計及探討來
電所造成的行為中斷的感覺。而他們亦探
討現行所整理出的相關類別，他們指出實
際要考量的情況比他們所歸納的來的多，
如使用者的社會地位狀況、和發話者的關
係、或者一些其他的因素綜合搭配起來都
會別於他們所整理的情況，雖然這些資訊
已經可以可供發話者有很大的參考及提供
對於發話對象的資訊掌控，但是這些訊息
要以自然且簡單的方式自受話方傳遞出去
是一個要多加探討的問題，否則會造成使
用上的負擔。 
3. 情緒來電流程及架構 
當使用者的手機因為一通來電而響起
時，會有許多資訊來幫助使用者能夠在第
一時間了解來電狀況：此通來電之電話號
碼(視覺，了解發話者為何)、手機的來電
鈴聲（聽覺，提醒電話響起以及使用者對
於特定發話者設定的專屬鈴聲來幫助確認
發話者的身份）、使用者設定的此通來電號
碼對應之名稱（視覺，如姓名、綽號、特
定店家或者稱呼）、來電大頭貼(視覺，照
片或者特定圖片幫助了解發話者身份)等
等。這些來電狀況讓受話者可以掌控來電
資訊，並且判斷此通電話接與不接，就如
同大門窺視孔的功能，藉由在接觸(接通電
話)之前的資訊掌控，來讓使用者能夠做出
對於此通來電的判斷。 
人們在日常生活中的面對面交談接
觸，可因為對於談話對象的資訊接收，迅
速的了解以及掌控狀況，此即所謂的『察
言觀色』。對於手機通話而言，人與人溝通
的實際距離因此而不受限制，然而人們對
於訊息的掌握需求就因此而消失了嘛？來
電顯示滿足了人們於通話中對於對方的身
份資訊需求，然而需求的資訊是否以經足
夠？人們在察言觀色中所見的資訊並不止
於身分，而現今的來電資訊僅於身份確
認；在面對面交談中，人的情緒特徵在視
覺上的呈現(表情、手勢)也是察言觀色中
可以見到的，在來電資訊的顯示中，這也
是可以加入的要素。 
撥號是開啟通話的第一動作，現今主
要由語音撥號(聲音)以及按手機按鈕、觸
碰(觸覺、動作)的方式來操作。人們在表
達情感時，手勢亦是一個輔助表達的管
道，將這些人們自然而然會做的情緒手
勢，融入於手機輸入的介面，可以自然的
讓使用者以此來加強表達自己的情緒資
訊，並且以視覺化的圖案方式呈現，就如
同人們會在即時通或者電子郵件的溝通上
會用圖案來加強自己的表達一般。 
手勢以及表情是人們在一般面對面對
談中自然會產生的情感表達動作，在現今
的手機通話程序上，這兩者與通話的相關
資訊是並無關聯的。手機是人們表達情感
的媒介，其打破了在溝通上的距離隔閡，
但也犧牲了許多原本面對面對談中所可以
得到的資訊，將實際的面對面對談的狀況
以手機操作和顯示方面來呈現，是情緒來
電和現在一般的手機通話狀況最大的不
同。以此加強了情緒資訊的傳遞、額外的
情緒資訊顯示讓受話者可以擁有更大的資
訊掌控感、以及營造出面對面的情境來讓
使用者之間的於情感方面的互動更為密
切。 
 
 
圖 9. 情緒來電情境及整體流程 
 
圖 9 為情緒來電的使用情境及流程，
在輸入部份加入情緒擷取的要素，系統偵
測使用者利用手勢所輸入的情緒，選擇了
符合的 Emotional icon，讓發話者可以將自
己的情緒資訊傳送出去，並且在受話者的
 12
 
從表 3 我們可以發現人們對於 Joy 以
及 Anger 的敏感程度較高，因此在選項的
出現次數相較於其他情緒就比較多；在情
緒樣本之中我們可以選出 4 種具有代表性
的情緒手勢的分類，在此實驗來說，這些
分出來的手勢是顯而易見且無異議的。就
最終選出的數量結果來說，人們在情緒種
類的判斷上分岐仍舊相當的大，因此只有
少部份的手勢是無異議的被分類出來。 
我們進一步觀察所分類出來的情緒手
勢，在 Sadness 以及 Surprise 中只有一種，
而在 Joy 和 Anger 中仍有數種不同樣子
的情緒手勢。我們希望能找出最具有代表
性的手勢動作，因此我們在 Joy 和 Anger
分類下請受測者做出第二階段的 Rank 動
作，藉由 Rank 找出最具有代表性的情緒
手勢，圖 10(a)展現了分類所選出來的四種
情緒手勢。 
 
圖 10. (a). 四種分類出的情緒手勢 
    (b). 手勢輸入的主要方向 
 
4.2. 情緒手勢的特徵 
在我們找出具有代表性的情緒手勢
後，我們透過面談，詢問受測者他們所認
為對於情緒手勢的判斷特徵依據：方向、
動作的次數、及動作的速度快慢是人們判
斷手勢的幾個特徵。表 4 歸納了不同情緒
手勢在人們視覺觀點的動作特徵以及我們
將其轉為手勢輸入方法的特徵依據，而圖
10(b) 展現了在此歸納下，使用者展現情
緒手勢時的動作方向的示意圖。方向特徵
部份，我們將手勢的方向拆為兩個部份：
Start direction 以及 Turing direction(起始方
向及轉變方向)。除了 Sadness 的手勢只有
一個方向外，其餘的都有兩個循序的動作
方向，而使用者在施展情緒手勢時，必須
自起始方向開始施展正確的情緒手勢方
向。手勢的動作次數亦是判別的條件之
一，我們判別自手勢開始至結束時施展的
動作方向是否重複（如是否重複上、下）
來判定手勢動作的次數。動作的速度亦影
響了判斷，在一個手勢動作中，其所感知
的加速度最大值是我們判斷動作速度的依
據。 
 
  Joy  Anger  Surprise Sadness 
方向 起始方向：上 轉變方向：下  
起始方向：後 
轉變方向：前 
起始方向：向
前且逐漸上舉 
轉變方向：後 
起始方向：上 
手勢
動作
次數 
兩次 一次 一次 一次 
動作
速度 快 快 快 慢 
表 4 情緒手勢的特徵 
 
4.3. 實驗一：情緒手勢輸入的辨識 
我們在手勢動作上定義了幾個其動作
特徵，當使用者展現手勢時，資料經由
Three-axis accelerometer 的感應產生出可
表明其狀況的三軸加速度值，我們藉由這
個作為觀察使用者動作特徵的依據並且分
類至所屬的手勢類別。三軸加速度值具有
定向及表現動作快慢的功用，此外其變化
的規律也是我們可以判斷動作次數的依
據；假定在數值的變化上，一上一下動作
出現了兩次，我們可以判定為連續做了兩
次的上下手勢動作，即可猜測這有可能是
Joy 的情緒手勢。 
我們利用 Wiimote（動作感應的輸入
裝置）以及 GlovePIE(紀錄 Wiimote 的所偵
測數值的程式語言) 來做為實驗工具。
Wiimote 利用藍芽做到 Wireless 的功能，
而且內建 G-sensor 可以做出施力、加速
度、手把旋轉翻滾等數值的偵測，且價格
並不昂貴，相當適合應用於手勢辨識方面
的研究[33]。在使用 Wiimote 的手勢辨識
相關研究中，Schlömer, T[33]做了辨識度
的實驗，他要求使用者利用 Wiimote 做出
特定的手勢，如正方形、圓、Z 字、手把
90 度垂直翻滾、打網球式揮舞等動作，有
著大約 85％以上的辨識成果。我們可以此
來說明，用 Wiimote 做手勢辨識的材料，
算是相當適合。 
我們邀請了 5 位受測者來驗證我們所
定義之情緒手勢輸入法的辨識程度，利用
 14
證。針對情緒來電整體架構而言，目前的
服務主要是針對受話方做情緒資訊的提
供，然而現在的受話者可能是不久之前或
之後的發話者，類似的情緒資訊一樣可以
用歷程的方式做紀錄及提供給發話者做為
參考資訊，未來我們會進一步研究這個方
式的可行性，並且透過參訪及實驗來針對
這項相關情緒來電的額外功能進行探討。 
6. 參考文獻 
[1]Picard, R. W. (1999). Affective Computing for 
HCI. In Proceedings of HCI international, (the 8th 
international Conference on Human-Computer 
interaction) on Human-Computer interaction: 
Ergonomics and User interfaces-Volume I - Volume I 
(August 22 - 26, 1999). H. Bullinger and J. Ziegler, 
Eds. Lawrence Erlbaum Associates, Mahwah, NJ, 
829-833. 
[2]Lasen, A. (2004) ‘Affective 
technologies—emotions and mobile phones’, receiver, 
no. 11, Available at: 
http://www.receiver.vodafone.com/11/ (accessed 14 
Nov. 2005). 
[3] HERAZ, A., FRASSON , C., (2006) Hidden 
Emotions in Iconic Faces. Workshop on Robots and 
Agents. International Conference on Intelligent 
Tutoring System (ITS), Jhongli , Taiwan. 
[4] Rivera, K., Cooke, N. J., and Bauhs, J. A. 1996. 
The effects of emotional icons on remote 
communication. In Conference Companion on 
Human Factors in Computing Systems: Common 
Ground (Vancouver, British Columbia, Canada, April 
13 - 18, 1996). M. J. Tauber, Ed. CHI '96. ACM, New 
York, NY, 99-100. DOI= 
http://doi.acm.org/10.1145/257089.257180 
[5] Sundström, P., Ståhl, A., and Höök, K. 2005. 
eMoto: affectively involving both body and mind. In 
CHI '05 Extended Abstracts on Human Factors in 
Computing Systems (Portland, OR, USA, April 02 - 
07, 2005). CHI '05. ACM, New York, NY, 2005-2008. 
DOI= http://doi.acm.org/10.1145/1056808.1057078 
[6] 2008. Using a mobile phone as a "Wii-like" 
controller for playing games on a large public display. 
Int. J. Comput. Games Technol. 2008, 2 (Jan. 2008), 
1-6. DOI= http://dx.doi.org/10.1155/2008/539078 
[7] Eun-Seok Choi; Won-Chul Bang; Sung-Jung Cho; 
Jing Yang; Dong-Yoon Kim; Sang-Ryong Kim, 
"Beatbox music phone: gesture-based interactive 
mobile phone using a tri-axis accelerometer," 
Industrial Technology, 2005. ICIT 2005. IEEE 
International Conference on , vol., no., pp. 97-102, 
14-17 Dec. 2005 Lasen, A. (2004) ‘Affective 
technologies—emotions and mobile phones’, receiver, 
no. 11, Available at: 
http://www.receiver.vodafone.com/11/ (accessed 14 
Nov. 2005). 
[8] Damasio, A. R. Descartes’ Error: Emotion, 
Reason and the Human Brain, Grosset/Putnam, New 
York, 1994 
[9] Davidson, R. J., Scherer, K. R., and Goldsmith, H. 
H., Handbook of Affective Sciences, Oxford, USA, 
2003 
[10] Parrott, W. (2001) Emotions in Social 
Psychology, Psychology Press, Philadelphia 
[11] Fagerberg, P., Ståhl, A. and Höök, K. Designing 
gestures for affective input: an analysis of shape, 
effort and valence, In Proceedings of Mobile 
Ubiquitous and Multimedia, MUM 2003, Norrköping, 
Sweden, 2003. 
[12] Gunes, H., Piccardi, M., and Jan, T. 2004. Face 
and body gesture recognition for a vision-based 
multimodal analyzer. In Proceedings of the 
Pan-Sydney Area Workshop on Visual information 
Processing M. Piccardi, T. Hintz, S. He, M. L. Huang, 
and D. D. Feng, Eds. ACM International Conference 
Proceeding Series, vol. 100. Australian Computer 
Society, Darlinghurst, Australia, 19-28. 
[13] Shin, G. and Chun, J. 2007. Vision-Based 
Multimodal Human Computer Interface Based on 
Parallel Tracking of Eye and Hand Motion. In 
Proceedings of the 2007 international Conference on 
Convergence information Technology - Volume 00 
(November 21 - 23, 2007). ICCIT. IEEE Computer 
Society, Washington, DC, 2443-2448. DOI= 
http://dx.doi.org/10.1109/ICCIT.2007.396 
[14] Mitra, S.; Acharya, T., "Gesture Recognition: A 
Survey," Systems, Man, and Cybernetics, Part C: 
Applications and Reviews, IEEE Transactions on , 
vol.37, no.3, pp.311-324, May 2007 
[15] Doo Young Kwon; Gross, M., "A Framework for 
3D Spatial Gesture Design and Modeling Using a 
Wearable Input Device," Wearable Computers, 2007 
11th IEEE International Symposium on , vol., no., 
pp.23-26, 11-13 Oct. 2007 
[16] Ståhl, A., Sundström, P., and Höök, K. 2005. A 
foundation for emotional expressivity. In Proceedings 
of the 2005 Conference on Designing For User 
Experience (San Francisco, California, November 03 
- 05, 2005). Designing For User Experiences, vol. 
135. AIGA: American Institute of Graphic Arts, New 
York, NY, 33. 
[17] Alsmeyer, M., Luckin, R., and Good, J. 2008. 
Developing a novel interface for capturing self 
reports of affect. In CHI '08 Extended Abstracts on 
Human Factors in Computing Systems (Florence, 
Italy, April 05 - 10, 2008). CHI '08. ACM, New York, 
NY, 2883-2888 
[18] Bhandari, S. and Bardzell, S. 2008. Bridging 
gaps: affective communication in long distance 
relationships. In CHI '08 Extended Abstracts on 
Human Factors in Computing Systems (Florence, 
Italy, April 05 - 10, 2008). CHI '08. ACM, New York, 
NY, 2763-2768. DOI= 
http://doi.acm.org/10.1145/1358628.1358758 
[19] Tollmar, K., Junestrand, S., and Torgny, O. 2000. 
Virtually living together. In Proceedings of the 3rd 
Conference on Designing interactive Systems: 
Processes, Practices, Methods, and Techniques (New 
York City, New York, United States, August 17 - 19, 
2000). D. Boyarski and W. A. Kellogg, Eds. DIS '00. 
ACM, New York, NY, 83-91. DOI= 
http://doi.acm.org/10.1145/347642.347670 
[20] Churchill, E. and Goodman, E. S. 2008. Mapchat: 
 16
on Human Factors in Computing Systems (Montréal, 
Québec, Canada, April 22 - 27, 2006). CHI '06. ACM, 
New York, NY, 1565-1570. DOI= 
http://doi.acm.org/10.1145/1125451.1125737 
 
計畫成果自評 
本研究與計畫與原計畫在目標上是相
符，目前嘗試用別於計畫所採用的方法，
以和人們日常生活中面對面交談時的情感
交流所呈現的模式，將其以情境模擬的方
式導入至現有的手機通話模式中。藉此來
彌補因為利用手機以聲音方式做遠距溝通
而犧牲的一些情感方面表達的模式。配合
手機配備加入G-sensor的風潮及趨勢，讓
人們使用手機時可以輸入的介面增加了，
利用這個配備將人們溝通的一個原始需
求：情感交流予以強化是我們最大的一個
目標，藉此亦可以增加如情緒資訊等方面
的輸出呈現，藉此更加增進人與人之間在
手機通話上的情感交流。 
 18
技術特點 
本研究計畫從人機互動中以使用者需求為中心(User-Centred 
Design)的研究方法，先從調查人們對於使用行動電話時感官上的需
求與心理習慣，得知人們使用行動電話時對於得知發話者身份與狀
態的需求，並藉由語音情緒辨識以及手勢辨識技術將發話者之情緒
傳遞至受話方，使得受話方在接聽電話前能做好心理準備以增進溝
通品質。 
推廣及運用的價值 
研究人機互動領域中情緒感知的學術研究題材以激發創意文化產
業，尤以尋找語音情緒以及手勢辨識技術之可應用性，並以使用者
為中心來探討實務面並實驗其可行性。 
 
