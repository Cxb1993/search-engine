可供推廣之研發成果資料表 
; 可申請專利  ; 可技術移轉                                      日期：96 年 5 月 20 日 
國科會補助計畫 
計畫名稱：智慧型視訊監控系統之研究與開發 
計畫主持人：謝君偉         
計畫編號：NSC95-2213-E-155-071   學門領域：資訊 
技術/創作名稱 以三角化為基礎之肢體切割技術 
發明人/創作人 謝君偉 
中文：此所發展之肢體切割技術，主要是利用到姿態三角化的
方法，自動從視訊將人體之骨架先行擷取出來，然後根據此骨架特
徵選擇最適當的分割模組進而將人體姿態的各個肢體作有效地切
割，此技術可提供重要的資訊來對視訊行為分析之細微變化作有效
的分析，可應用於家庭內之居家照護如老人跌倒或昏倒, 銀行內或
超商人之異常行為分析如舉雙手、爬櫃檯或跌倒，也可應用於社區
管理之異常行為分析如持棍棒、爬牆、跌倒、爬樹、伏地爬行等等，
也可應用於電玩之動作命令分析。 
技術說明 
英文：This presented technique can automatically segment a body posture into 
different body parts using the technique of triangulation.  Firstly, we first 
propose a triangulation-based method to triangulate a posture to different triangle 
meshes.  Then, we take advantages of a depth-first search scheme to find a 
spanning tree as its skeleton feature from the set of triangulation meshes.  The 
triangulation-based scheme to extract important skeleton features has more 
robustness and effectiveness than other silhouette-based approaches.  Then, 
different body parts can be roughly extracted by removing all the branching points 
from the spanning tree.  A model-driven technique is then proposed for more 
accurately segmenting a human body into semantic parts.  This technique uses 
the concept of Gaussian mixture model (GMM) to model different visual 
properties of different body parts.  Then, a suitable segmentation scheme can be 
driven for finely segmenting a body posture into different body parts by 
classifying these models using their skeleton features.  Experimental results have 
proved that the proposed method is robust, accurate, and powerful in body part 
segmentation.     
可利用之產業 
及 
可開發之產品 
視訊監控系統、Home Care System、互動式多媒體虛擬系統 
技術特點 
此技術可提供重要肢體資訊來對視訊行為分析之細微變化作有效
的分析，可作為多人間之行為辨識與分析，例如走路、蹲、跌倒、
搶劫、握手等等。 
推廣及運用的價值  
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位研
發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
一、計畫目的與緣由 
Human behavior analysis is an important task in various applications like video surveillance, video 
retrieval, human interaction system, medical diagnosis, and so on.  In the past, there were many 
approaches [1]-[9] proposed for analyzing human behaviors from videos.  For example, Oliver et 
al. [12] proposed a visual surveillance system to model and recognize human behaviors using 
HMMs (Hidden Markov Models) and trajectory features.  Ivanov [14] presented an automatic 
surveillance system for recognizing human gestures and behaviors using hidden Markov models.  
In addition, Wren [16] proposed a Pfinder system for tracking and recognizing human behaviors 
based on a blob model.  The challenge in human behavior analysis is the ambiguities between the 
used model and real human behaviors caused by mutual occlusions between body parts, loose 
clothes, or similar colors between body articulations.  Thus, in spite that the cardboard model [27] 
is good for modeling human motions, the requirement of body parts being well segmented makes 
it unfeasible for real applications. 
In order to solve this problem of body part segmentation, Park and Aggarwal [18] used 
dynamic Bayesian networks to segment a body to different components based on the concept of 
blobs to model region colors. In addition to regions, Weik and Liedtke [15] tracked the negative 
minimum curvatures along body contours to segment body parts and then recognized body 
postures using a modified ICP algorithm from multiple views.  Fujiyoshi et al. [11] presented a 
framework to recognize postures by extracting their skeletons along their boundary points. The 
contour-based method is simple and efficient for making a coarse classification of human postures.  
However, it is easily disturbed by noise, imperfect contour extraction, or occlusions. 
This report presents a novel approach to recognize human behaviors using the techniques of 
deformable triangulations and string matching.  Since a human behavior is an action result of a 
series of human postures appearing at different time, this report first presents a new posture 
classification scheme to classify different postures. The scheme first uses the technique of 
Delaunay triangulation [34] to decompose a body posture to different triangle meshes.  Then, a 
depth-first search is applied to obtaining a dfs spanning tree from the result of triangulation and 
thus different skeleton features can be extracted as the synthetic meanings for describing the 
analyzed posture.  Since a triangle can capture more information than a boundary pixel, the 
proposed scheme of skeleton extraction has more robustness and effectiveness than the 
silhouette-based methods [11].  In addition to skeleton features, the spanning tree also can 
provide important information for decomposing a posture to different body parts like head, hands, 
or feet.  Thus, we can define a new posture descriptor, i.e., the centroid context to describe a 
posture up to a semantic level.  The centroid context records different visual characteristics 
viewed from the centroids of the analyzed posture and its corresponding body parts.  Since the 
two descriptors are complement to each other, we can compare and classify all desired human 
postures very accurately.  According to these two descriptors, a clustering technique is further 
control points extracted along the boundary of P.  Each point in V is indexed anticlockwise and 
modulo by the size of V.  Like Fig. 2, assume that Φ  is the set of interior points of V in 2R .  
For a triangulation T ⊂ Φ , T  is said to be a constrained Delaunay triangulation of V if (a) each 
edge of V is an edge in T and (b) for each remaining edge e of T there exists a circle C such that 
the endpoints of e are on the boundary C and if a vertex in V is in the interior of C then it cannot be 
seen from at least one of the endpoints of e. Then, in Chew [34], a divide-and-conquer algorithm 
was developed to obtain the constrained Delaunay triangulation of V in O(n log n) time.  The 
algorithm performs the following four steps:  
1. Choose a starting edge ( , )i je v v . 
2. Find the third vertex kv  from V which satisfies the above conditions (a) and (b). 
3. Subdivide V into two sub-polygons: aV =  { }1 -1, , ,..., ,i k k i iv v v v v+  and bV = { }1, ,..., ,j j k jv v v v+ . 
4. Repeat Steps 1-3 on aV  and bV  until the processed polygon consists of only one triangle.  
Fig. 3 shows one example of triangulation result.  
   
(a)        (b)  
Fig. 3 Triangulation result of a body posture. 
3.1 Skeleton Extraction Using Triangulation 
    
2
Pb
0
Pb1
Pb
0n
1n
 
(a)         (b) 
Fig. 4: Body component extraction.  (a) Triangulation Result of a posture.  (b) 
A spanning tree of (a). 
Assume that P is a binary posture.  According to the technique of triangulation, P will be 
decomposed to a set PΩ  of triangle meshes, i.e., 0,1,..., -1{ } TPP i i N=Ω = Λ .  Each triangle mesh iΛ  in 
PΩ  has the centroid iCΛ .  Given two triangulation meshes iΛ  and jΛ , they are connected if 
they share one common edge.  Then, according to this connectivity, P can be converted to a 
undirected graph PG , where all centroids iCΛ  in PΩ  are the nodes in PG  and an edge exists 
between 
i
CΛ  and jCΛ  if iΛ  and jΛ  are connected.  Then, we can perform a graph searching 
scheme on PG  for extracting its skeleton feature. 
First, we seek a node H whose degree is one and position is the highest for all the nodes in 
PG .  H is defined the head of P.  Then, starting from H, we perform a depth-first search to find a 
spanning tree PbfsT .  The tree PbfsT  will capture the skeleton feature of P.  Fig. 4(a) shows the 
t) as follows: 
 , , ,
, , ,
i k i k i k
i k i k i k
H H H
H H H
cos sin x xs
t sin cos y y
θ θ
θ θ
− −⎛ ⎞⎛ ⎞⎛ ⎞ = ⎜ ⎟⎜ ⎟⎜ ⎟ ⎜ ⎟⎜ ⎟−⎝ ⎠ ⎝ ⎠⎝ ⎠
, (3) 
where (
,i kH
x ,
,i kH
y ) is the center of ,i kQ .  Thus, for each pixel v in ,i kQ , its new feature vector 
 ( ,  ,  ,vf s t r=  g, b) will form a new Gaussian model.  The new model provides more performances 
for body part segmentation.  The orientation 
,i kQ
θ  of ,i kQ  can be obtained by analyzing its 
moments. 
Once the initial values of ,i kΣ  and ,i kμ  can be obtained, the EM (Expectation maximization) 
algorithm [35] is used to find the prior probability ( )
iQ k
α φ .  Let ,={( ,i i kψ μ  , , ( ))}ii k Q kα φΣ  be the set 
of parameters of the K-component GMM.  The EM algorithm performs the E-step and M-step 
iteratively to find an accurate solution of iψ . Once the Gaussian mixture model ( )iQp v  has been 
established, we can then reclassify each pixel v in the analyzed posture P by a maximum a 
posteriori (MAP) classifier.  The MAP classifier assigns v to class l (the lth body part) when    
 ,  ( | ) ( | ) l ii l P Q v P Q v∀ ≠ ≥ . (4) 
According to the Bayesian theory, the rule of (4) to assigns v to class l can become: 
 ,   ( ) ( )
l iQ Q
i l p v p v∀ ≠ ≥ . (5) 
3.2.3 Model-driven Body Part Segmentation 
  
(a)        (b) 
Fig.5 (a) Occlusion between two legs.  (b) Models for solving the failure of body part 
segmentation.  
In practice, one body parts sometimes will occlude another one due to their similar color or 
shadows.  Like Fig.5, the two legs occlude together due to the similar color of trousers between 
them.  This project will propose a model-driven method for tackling the above occlusion problem.  
Thus, in what follows, we will first use a distance map for posture classification.  Then, a proper 
posture model can be driven chosen for well segmenting a body posture to different body parts. 
3.2.4 Model Selection Using Skeleton 
Assume that PS  and DS  are two skeletons extracted from a testing posture P  for testing and 
another posture model D  in database, respectively.  In what follows, we will use a distance 
transform to compare the similarity between PS  and DS . 
   
shows the segmentation result of (c) when the hands were occlude to the torso.  Even though 
there were some occlusions, our method still performed well to extract desired body parts.  Fig. 8 
(b) shows the result of body part segmentation from Fig. 8(a) when hands and legs had occlusions.  
Our method still works well to extract desired body parts.  Fig. 8 (d) shows the result of (c) when 
another person was handled.  Due to the similar colors of body parts, many occlusions happed 
along the boundaries of hands.  Experimental results have shown our method is superior in terms 
of accuracy, robustness, and stability in body part segmentation. 
    
Fig. 7: Body part segmentation. (a) and (c) Original images.  (b) and (d) Segmentation 
results of (a) and (c). 
       
Fig. 8: Body part segmentation. (a) and (c) Original images.  (b) and (d) 
Segmentation results of (a) and (c). 
五、計畫成果自評 
目前，研究計畫的初步成果，均已達到提案計畫，第二年預期的目標，且其內容具有
高度的學術研究價值，已有多篇論文發表於 ICPR2006 會議、ICIP2006 會議、IIHMSP2006
會議、MVA2007 會議、ICCCN2007 會議，並投稿至 IEEE Transactions on Multimedia 之期
刊，目前已被接受但須小小的更改，另有一篇期刊論文投稿至 Pattern Recognition。爾後，
正朝向第三年預期目標前進。 
參考文獻 
[1] T. B. Moeslund and E. Granum, “A survey of computer vision-based human motion capture,” 
Computer Vision and Image Understanding, vol. 81, no. 3, pp. 231-268, Mar. 2001.  
[2] R. Cucchiara, C. Grana, A. Prati, and R. Vezzani, “Probabilities posture classification for 
human-behavior analysis,” IEEE Transactions on Systems, Man, and Cybernetics-Part A: 
System and Humans, vol. 35, no. 1: pp. 42-54, Jan. 2005. 
[3] Haritaoglu, D. Harwood, and L.S. Davis, “W4: real-time surveillance of people and their 
activities,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 22, no. 8, pp. 
809-830, 2000. 
[4] S. Maybank, and T. Tan, “Introduction to special section on visual surveillance,” 
International Journal of Computer Vision, vol. 37, no. 2, pp. 173-173, 2000. 
[5] I. Mikic, et al., “Human body model acquisition and tracking using voxel data,” 
International Journal of Computer Vision, vol. 53, no. 3, pp. 199-223, 2003. 
[6] N. Werghi, “A discriminative 3D wavelet-based descriptors: application to the recognition 
of human body postures,” Pattern Recognition Letter, vol. 26, no. 5, pp.663-677, 2005. 
Society Conference on Computer Vision and Pattern Recognition, vol. 2, pp.326-333, 
2004. 
[27] S. X. Ju, M. J. Black, and Y. Yaccob, “Cardboard people: a parameterized model of 
articulated image motion,” International Conference on Automatic Face and Gesture 
Recognition, pp. 38-44, Killington, Vermont, 1996. 
[28] D. Ayers, R. Ramura, and K. Fukunaga, “Monitoring human behavior from video taken in 
an office environment,” Image and Vision Computing, vol. 19, no. 22, pp.833-846, Oct. 
2001. 
[29] E. Horowitz, S. Sahni, and S. A. Freed, Fundamentals of data structure in C, W. H. 
Freeman and Company, New York, USA. 
[30] G. Borgefors, “Distance transformations in digital images,” Computer Vision, Graphics, 
and Image Processing, vol. 34, no. 3, pp. 344-371, Feb. 1986.  
[31] M. Bern and D. Eppstein, Mesh generation and optimal triangulation, Computing in 
Euclidean Geometry, 2nd Ed., World Scientific, 1995, pp.47-123. 
[32] Chris Stauffer and Eric Grimson, “Learning patterns of activity using real-time tracking,” 
IEEE Transactions on Pattern Recognition and Machine Intelligence, vol. 22, no. 8, pp. 
747-757, 2000. 
[33] D. Chetverikov and Z. Szabo “A simple and efficient algorithm for detection of high 
curvature points in planar curves,” Proc. 23rd Workshop of the Austrian Pattern 
Recognition Group, pp.175-184, 1999. 
[34] L. P. Chew, “Constrained delaunay triangulations,” Algorithmica, vol. 4, no.1, pp.97-108, 
1989. 
[35] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classification (2nd Edition), 
Wiley-Interscience, 2000. 
 
表 Y04 
Chellappa, Dr. David Taubman, and Michael E. Phelps 做 plenary section 的 keynote 
speaker，詳細地介紹他們的研究成果，題目分別為: Pattern Recognition in Video, Efficient 
Representation and Distribution of Video and Related Media, PET Molecular Imaging 
Biomarkers of Disease，前兩位教授不僅深入簡出地介紹他們的理論技術，並廣泛地分析
比較各種方法更增添不少重要成果，讓聽者獲益良多，第三位教授則因車禍沒法出席。
二、與會心得 
 
   本人參加此次的國際影像處理研討會，會中本人發表一篇有關利用顏色與運動資訊
來作物件切割的論文，發表後獲得許多人的興趣與討論，許多人並詢問網頁上是否有
demo 的系統，可以做實驗。除了宣讀論文之外，我並與參加此次會議的各種 oral 與 poster
的議程，並與各國學者或研究員彼此互相討論，除可得知這方面最新技術的研發與進
展，並可了解目前各國在影像處理技術上的研發情況與進展，因這會議是在美國舉辦
的，大部分的學者來自美國，歐洲國家的學者也來了不少、例如英國、法國、德國、義
大利、比利時等國家，亞洲的學者也不少，例如大陸、日本等等，台灣參加的學者也很
多，例如台大的貝蘇章教授，清大的賴尚宏教授、許秋婷教授，中研院的黃文良博士等
等。在研討會中與這些學者討論與交換意見，深深的覺得在影像處理這個領域，研究重
點越來越偏向 video coding 與多媒體分析，包括 H.264 codec 的探討、浮水印
(watermarking)、視訊壓縮、多媒體檢索等等，而且今年很多研究都在探討利用統計的方
式來做影像分析，例如 HMM 來做行為分析，不過台灣的學生似乎在統計上面的訓練不
大夠，這是台灣學者需要重視的。在此會議碰到許多大陸學生與香港的學生與學者，出
來的人數與論文發表數已超過台灣了，這是過去沒見到過的，質方面也有相當不錯的進
步，因為今年是美國主辦的，所以有一大部分的論文是美國出來的研究論文，相對而言
台灣的論文數就少了許多，台灣不再加以努力，影像處理的研究將會慢慢地被其他國家
超越過去。另外值得一提的事情是今年得獎的論文幾乎都是亞洲人拿到，可見亞洲人的
聰明智慧與創意，不見得會輸給歐美等國家。 
 
三、建議 
 
    由參加這次會議，發覺許多優秀與有深度的論文都會用到許多的統計數學，但對於
統計或數學的駕馭力，多數的台灣研究生似乎都很欠缺，尤其是現補習教育的盛行，許
多研究生能考上好學校，是因從大二或大三就開始補習，對同樣的習題與科目一直磨
練，雖然研究所考試能獲得高分，但不代表真的有對應的能力來解決問題，只能說當時
的運氣及記憶力比較好，創造能力並無跟著增長，有點令人感嘆，希望國內教育能多加
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          95 年  11 月 1  日 
報告人姓名  謝君偉 
 
服務機構
及職稱 
 
 元智大學 電機系 
 副教授 
     時間 
會議 
     地點 
 2006 年 10 月 8 日至 11 日
 美國 Atlanta 
本會核定
補助文號
 95-2221-E-155-071 
 95-2622-E-006-cc3 
會議 
名稱 
 (中文) 2006 年國際影像處理會議 
 (英文) 2006 IEEE International Conference on Image Processing 
發表 
論文 
題目 
 (中文) 以核心函數與空間時間域相似度為基礎之視訊物件切割技術 
 (英文) Video Object Segmentation Using Kernel-based Models and 
Spatial-temporal Similarity 
報告內容應包括下列各項： 
一、參加會議經過 
 
本次研討會在美國的 Atlanta 舉行，安排了六個 special sections 包括: Scalable Video 
Coding, Network-Aware Multimedia Processing and Communications, Signal/Image 
Reconstruction from Sparse Measurements, Soft Computing in Image Processing: Recent 
Advances, Knowledge-Based Image Processing For Classification And Recognition in 
Surveillance Application, 3DTV: Extraction, Representation, Compression and 
Transmission，分別針對最近影像處理最熱門的問題與應用，作深入的討論。由於此研討
會主要是從事影像處理研究學者務必參加的盛會，因此匯集了全世界的知名研究學者，
例如 Rama Chellapa 等人，藉此盛會交換意見與心得，除此之外大會並提供 8 個短期課
程 (tutorials)，包括 Security of Digital Multimedia Content: Solutions with Encryption And 
Watermarking, Real-Time Image and Video Processing, Digital Color Management, Scalable 
Video Coding - Standardization and Beyond, Biometrics for Surveillance, Compressive 
Sampling: A New Framework for Imaging, Real-Time Image and Video Processing: From 
Research to Reality, Image Processing Techniques in Computer-Aided Detection and 
Diagnosis, 對當前世界熱門的研究主題加以介紹，藉以吸引更多優秀的學者投入心力，
為這些主題做出更大的突破與貢獻。 
   此會議共有 1596 篇的論文投稿，共有 854 篇論文被錄取，分別來自 61 個不同國家
的投稿，為了維持此會議的論文水準，在論文議程上的安排，共有 36 個 oral sections 及
50 個 poster sections, 在不同時間裡舉行，並邀請三位國際知名的學者, Prof. Rama 
附件三
 
