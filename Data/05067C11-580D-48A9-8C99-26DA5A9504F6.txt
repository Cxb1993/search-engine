I. INTRODUCTION
Type-2 fuzzy systems have attracted much attention in
recent years and provided an efficient solution for system
modeling problems. They also have been successfully ap-
plied to many areas, such as control, image processing,
signal processing, traffic control, communication, robotics,
etc. Compared with type-1 fuzzy systems, the significant
difference in type-2 fuzzy systems is the using of type-2
fuzzy sets in the fuzzy rules. Therefore, type-2 fuzzy systems
possess much elasticity and a more excellent representation
capability in dealing with the problems which contain much
uncertainty. However, they suffer from the problem of higher
computation complexity. Therefore, many researchers have
paid their attention to the interval type-2 fuzzy systems [7].
In the interval type-2 fuzzy systems, the type of employed
interval type-2 fuzzy sets is a special case of general type-
2 fuzzy sets. In other words, all secondary membership
function values are equal to 1 for each interval type-2 fuzzy
set. To understand further the theory of type-2 fuzzy sets
and systems, the readers can refer to the articles [5], [7], [6]
published by Mendel et al.
II. LITERATURE SURVEY
Up to now, there are some approaches proposed for
the construction and learning of the interval type-2 fuzzy
systems. Ren et al. [9] proposed an algorithm by combining
a subtractive clustering method with least squares estimation
algorithms to pre-identify a type-1 TSK fuzzy system. Then,
a TSK type-2 fuzzy system is obtained by expanding the
type-1 TSK fuzzy system through enumerative search of
optimal values for spreading percentage of cluster centers and
consequent parameters. However, the extension from type-
1 TSK fuzzy systems to type-2 TSK fuzzy systems is too
heuristic and depends heavily on the precision of type-1 TSK
fuzzy system. Uncu and Tu¨rksen [10] proposed a modeling
method based on the fuzzy C-means clustering algorithm.
The proposed discrete interval type-2 TSK fuzzy system
models are generated by a learning parameter of fuzzy C-
means, known as the level of membership, and its variation
over a specific set of values which generate the uncertainty
associated with the system structure. The generated model
possesses good approximation to the training data. However,
it suffers from the problems of over-training and large
memory space consumption. Cai et al. [2] proposed a type-
2 GA-TSK fuzzy neural network for the learning of type-2
TSK fuzzy systems. The parameters of all fuzzy rules are
encoded in one chromosome. Then, the genetic algorithm is
performed to optimize the parameters. This approach suffers
from the problems of random initialization and slow conver-
gence rate. Al-Jaafrsh and Al-Jumaily [1] proposed a learning
approach for interval type-2 fuzzy systems based on the
particle swarm optimization. All parameters related to fuzzy
rules are encoded in one particle. Then the process of particle
swarm optimization is performed to find the best solution.
The disadvantages of this approach are the same as those of
the approach proposed by Cai et al. [2]. Juang and Tsao [3]
Fig. 1. Overview of our approach.
proposed a type-2 self-organizing neural fuzzy system and its
hardware implementation. An on-line clustering algorithm is
proposed to generate rules for structure identification, while
a rule-ordered Kalman filter algorithm is proposed to tune
the consequent parameters for parameter identification. The
on-line clustering algorithm doesn’t consider the distribution
of data in each cluster well since it just calculates the mean
of each cluster and has no consideration of the spread of
each cluster.
III. RESEARCH GOAL
The goal of this project is to alleviate the problems
described above and provide a whole solution for the con-
struction and leaning for interval type-2 TSK fuzzy systems.
Therefore, we propose a self-constructing rule generation
method and a hybrid learning algorithm for the structure
identification and parameter identification, respectively.
IV. RESEARCH APPROACH
The whole process of our approach is shown in Figure 1.
In the structure identification phase, we develop a self-
constructing rule generation method to group the data into
fuzzy clusters and extract initial fuzzy rules for creating an
interval type-2 TSK fuzzy system. Then, we construct an
interval type-2 TSK fuzzy neural network in the parameter
identification phase and propose a hybrid learning algorithm
to refine the parameters of initial fuzzy rules for higher
precision. Finally, we have a set of refined fuzzy rules.
System output can be inferred from these fuzzy rules or the
fuzzy neural network for any input presented to the system.
A. Network Architecture
Suppose we are given a dataset of an unknown system
with N inputs x1, x2,. . . , xN , and one output y. We
consider the multiple-input-single-output (MISO) systems
for convenience of description. Extension to multiple-input-
multiple-output (MIMO) systems is obvious. In the structure
identification phase, we develop a self-constructing rule
generation method and obtain a set of J fuzzy clusters C1,
C2, . . . , and CJ . Then we convert each cluster to a fuzzy
rule. For cluster Cj , the corresponding fuzzy rule Rj takes
the following interval type-2 TSK form:
IF x1 IS A˜1j(x1) AND x2 IS A˜2j(x2) AND . . .AND
xN IS A˜Nj(xN ) THEN y IS
fj(~x) = ~x
′~bTj = b0j + b1jx1 + . . .+ bNjxN (1)
existing cluster Cj , 1 < j < J . We say that datum Dt
passes the input-similarity test on cluster Cj if
GIj (~pt) ≥ ρ (11)
where ρ, 0 ≤ ρ ≤ 1, is a predefined threshold. Then we
calculate GOj (qt) for each cluster Cj on which datum Dt
has passed the input-similarity test. We say that datum Dt
passes the output-similarity test on cluster j if
GOj (qt) ≥ τ (12)
where τ , 0 ≤ τ ≤ 1, is another predefined threshold.
Two cases may occur. First, there are no existing fuzzy
clusters on which pattern Dt has passed both the input-
similarity test and the output-similarity test. For this case, we
assume that datum Dt is not close enough to any existing
cluster and a new fuzzy cluster Cv , v = J + 1, is created
with
~mIv = ~pt, ~σ
I
v = ~σ
I
0 , (13)
mOv = qt, σ
O
v = σ
O
0 (14)
where ~σI0 = [σ
I
0 , σ
I
0 , . . . , σ
I
0 ] and σ
O
0 are user-defined con-
stant vector and constant. Note that the new cluster Cv
contains only one member, datum Dt, at this time. Of course,
the number of clusters is increased by 1 and the size of cluster
Cv should be initialized, i.e.,
J = J + 1, Sv = 1. (15)
On the other hand, if there are existing fuzzy clusters on
which datum Dt has passed both the input-similarity test and
the output-similarity test, let clusters j1, j2, . . . , and jf be
such clusters and let the cluster with the largest membership
degree be cluster Cs, i.e.,
GIs(~pt) = max{GIj1(~pt), GIj2(~pt), . . . , GIjf (~pt)}. (16)
In this case, we assume that datum Dt is closest to cluster
Cs and cluster Cs should be modified to include datum Dt
as its member. The modification to cluster Cs is as follows:
σIis = [
(Ss − 1)(σIis − σI0)2 + SsmIis2 + pit2
Ss
−Ss + 1
Ss
(
Ssm
I
is + pit
Ss + 1
)2]
1
2 (17)
mIis =
Ssm
I
is + pit
Ss + 1
, 1 ≤ i ≤ n, (18)
σOs = [
(Ss − 1)(σOs − σO0 )2 + SsmOs 2 + qt2
Ss
−Ss + 1
Ss
(
Ssm
O
s + qt
Ss + 1
)2]
1
2 (19)
mOs =
Ssm
O
s + qt
Ss + 1
, 1 ≤ i ≤ n, (20)
Ss = Ss + 1. (21)
Note that the derivation of above equations are based on the
statistics.
The above process is iterated until all the input-output
patterns have been processed. At the end, we have J
fuzzy clusters. Note that each cluster Cj is described as
(GIj (~x), G
O
j (y)) where G
I
j (~x) contains mean vector ~m
I
j and
deviation vector ~σIj , while G
O
j (y) contains mean m
O
j and
deviation σOj . Alternatively, we can represent cluster Cj by
an interval type-2 TSK-type fuzzy rule Rj having the form
of equation (1) with
mij1 = m
I
ij −
σIij
ξ
, mij2 = m
I
ij +
σIij
ξ
, (22)
σij = σ
I
ij , (23)
b0j = m
O
j , b1j = . . . = bnj = 0 (24)
where ξ is a predefined constant.
C. Hybrid Learning Algorithm
After the set of J initial fuzzy rules is obtained, we im-
prove the approximation precision of these rules with neural
network techniques in the phase of parameter identification.
Firstly, a four-layer fuzzy neural network is constructed from
these J initial fuzzy rules, as shown in Figure 2. Then a
hybrid learning algorithm is applied for tuning the parameters
mijl, σij , bkj , 1 ≤ i ≤ N , 1 ≤ j ≤ J , 1 ≤ l ≤ 2,
0 ≤ k ≤ N , efficiently. In particular, the particle swarm
optimization is used to optimize mijl and σij and a recursive
SVD-based least squares estimator is used to optimize bkj .
Suppose we have a total number T of training patterns. An
iteration of learning involves the presentation of all training
patterns. In each iteration of learning, we employ the particle
swarm optimization to generate a new generation of particles
each of which represents a set of antecedent parameters of all
rules. For each particle, the corresponding set of consequent
parameters of all rule are obtained by the recursive SVD-
based least squares estimator [4]. The process is iterated until
the desired number of iteration or approximation precision
is achieved.
Suppose {~Ps|1 ≤ s ≤M} denotes the set of particles we
generate in each iteration. Note that M denotes the number
of particles in a generation. Each particle ~Ps represents a set
of antecedent parameters of all rules, i.e.,
~Ps = (m
s
111,m
s
112, σ
s
11,m
s
211,m
s
212, σ
s
21, . . . ,
ms1J1,m
s
1J2, σ
s
1J , . . . ,m
s
NJ1,m
s
NJ2, σ
s
NJ). (25)
Apparently, the dimension of each particle is 3×N × J . To
initialize each particles, we set msij1, m
s
ij2, and σ
s
ij to be the
values chosen randomly from intervals [mij1−0.5σij ,mij1+
0.5σij ], [mij2−0.5σij ,mij2+0.5σij ], and [σij−0.5σij , σij+
0.5σij ], respectively. After the antecedent parameters in each
particle have been decided in each iteration, we have to
decide the corresponding consequent parameters. To obtain
the corresponding optimal consequent parameters for each
particle, we employ a recursive SVD-based least squares
estimator. For this purpose, we give the following deviation
to transform the optimization problem of bkj into a least
squares problem.
For the tth input-output datum Dt = (~pt, qt), the cor-
responding network output yt is calculated according to
TABLE I
COMPARISON ON LEARNING PERFORMANCE OF THE FOUR SYSTEMS FOR THE THREE EXPERIMENTS.
Experiment 1
No. of Ren’s System Cail’s System Uncu’s System Our System
Rules RMSE Iters Time RMSE Iters Time RMSE Iters Time RMSE Iters Time
6 0.1645 1 0.1223 0.3758 100 176.2645 0.0069 55 10.3240 0.0032 10 6.8674
9 0.0780 1 0.1305 0.3859 350 425.1311 0.0027 44 28.8658 0.0026 10 7.0886
Experiment 2
No. of Ren’s System Cail’s System Uncu’s System Our System
Rules RMSE Iters Time RMSE Iters Time RMSE Iters Time RMSE Iters Time
8 0.2171 1 0.4359 1.0359 100 675.4697 0.0481 55 126.7689 0.0128 5 21.4548
9 0.1624 1 0.4818 0.9401 200 967.5521 0.0383 44 114.6232 0.0075 6 24.7675
Experiment 3
No. of Ren’s System Cail’s System Uncu’s System Our System
Rules RMSE Iters Time RMSE Iters Time RMSE Iters Time RMSE Iters Time
3 0.0267 1 0.0771 0.0754 100 86.0157 0.0281 22 1.4309 0.0072 5 2.0852
6 0.0221 1 0.1113 0.0818 200 183.9447 0.0199 44 7.9335 0.0153 5 3.6676
TABLE II
COMPARISON ON GENERALIZATION ABILITY OF THE FOUR SYSTEMS FOR THE THREE EXPERIMENTS.
Experiment 1
No. of Ren’s System Cail’s System Uncu’s System Our System
Rules RMSE Time RMSE Time RMSE Time RMSE Time
6 0.1738 0.0248 0.3417 0.0237 0.0094 0.3073 0.0031 0.0229
9 0.0873 0.0257 0.3491 0.0267 0.0039 0.3682 0.0029 0.0252
Experiment 2
No. of Ren’s System Cail’s System Uncu’s System Our System
Rules RMSE Time RMSE Time RMSE Time RMSE Time
8 0.2166 0.0977 1.0141 0.1020 0.0558 3.7248 0.0135 0.0994
9 0.1408 0.1112 0.9399 0.1136 0.0484 4.4162 0.0069 0.1108
Experiment 3
No. of Ren’s System Cail’s System Uncu’s System Our System
Rules RMSE Time RMSE Time RMSE Time RMSE Time
3 0.0246 0.0123 0.0682 0.0103 0.0258 0.1231 0.0080 0.0102
6 0.0193 0.0135 0.0709 0.0121 0.0201 0.1270 0.0148 0.0116
(a) (b) (c) (d) (e)
Fig. 3. Experiment 1: (a) Original function; (b) Ren’s result; (c) Cai’s result; (d) Uncu’s result (e) Our result.
(a) (b) (c) (d) (e)
Fig. 4. Experiment 2: (a) Original function; (b) Ren’s result; (c) Cai’s result; (d) Uncu’s result (e) Our result.
會議心得報告： 
※ 會議規模(請勾選)：■全球性 □ 區域性。 
與會國家／人數：約____15___國／___500__人。 
2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010)
為電腦科學領域中有關人工智慧、機器學習及資料探勘等主題之著名國際會議，由國際
知名學術組織 IEEE 所舉辦，參加的學者專家來自於世界各地。本次很榮幸能夠有機會參
加，並且發表三篇論文，收穫可謂豐碩。參加會議的研習心得如下： 
1. 發表論文，獲得廣大迴響與意見回饋：本次所發表的論文共有三篇，分別為運用類神
經網路及模糊理論技術於解決掌紋生物辨識、智慧型設備監控及影像物件追蹤等問
題。這些問題在近年來極為受重視，主要是因為問題所牽涉到的資料量龐大，情況也
頗為複雜。因此，如何根據不同的條件，適當地尋找出具代表性之樣本成為相當重要
的任務。目前為止，越來越多的學者投入當中研究。本次三篇論文所提出的方法，利
用類神經網路與模糊理論技術之自動學習、仿人思考之推論、容易理解之描述方式、
高強韌性等優點，可以從訓練資料中學習出較佳之系統模型。報告過程中，受到與會
多位學者聆聽與提問，很多學者對於機器學習技術之應用感到非常有興趣，因為一般
使用統計或經驗式的方法往往遭遇到模型推導之困難，而藉助機器學習技術可以改善
此問題。而目前利用機器學習技術於解決此問題上的方法並不多，因此引起大家很大
的興趣，大部分的學者皆相當肯定我們方法的貢獻，除了提問之外，也提供他們的想
法供我參考，因此，讓我在未來的研究有幾個方向可以思考。 
2. 所發表之論文，獲邀投稿至期刊：本次所發表之論文，除了獲得與會學者的高度興趣
與肯定外，更受到與會學者的鼓勵與邀請投至機器學習相關的國際期刊。他們認為運
用類神經網路來解決掌紋生物辨識相當有潛力，而且文中所提之手掌旋轉角度偵測與
校正之方法，確實能有效解決一般掌紋生物辨識系統常遇到的問題，此方法亦可考慮
提專利。藉由此發表機會，將可以大為增加我們學校及研究團隊在機器學習與電腦視
覺技術上的研究知名度。目前我們也正在增強論文的實驗與本文描述，將投稿至人工
智慧與機器學習相關之國際期刊。 
3. 互相交流，增加研究的廣度與深度：每次參加學術會議，除了發表論文之外，透過會
議場合與來自全球各地的學者相互認識及討論，並交流學術研究成果與經驗，往往是
另一個重點。這次較特別的是認識大會的 keynote speaker，為來自英國的 Prof. 
Josef Kittler 教授，他是在智慧型計算與圖形識別領域方面相當知名的國際學者，
演講主題為有關多核心學習法及特徵空間的雜訊消除，皆為圖型識別問題中相當重要
的方法及問題。從他的演講中也啟發了我研究上的思考方向，若能將多核心學習的概
念結合我先前所提出的模糊類神經網路，應可提高網路學習的效率與正確性。他除了
提出自己對於多核心學習趨勢的看法之外，更鼓勵我們這些年輕的研究學者努力去探
索其更多的理論及應用。從交談中，我獲得不少寶貴研究經驗與方向啟發。 
4. 參加會議，獲得舉辦之經驗：本次會議屬於國際大型學術會議，從籌備、徵稿、審稿、
議程安排、會議開始及結束的整個過程與資料，我都盡可能地蒐集並了解，以作為日
後爭取並舉辦國內或國際學術研討會之參考與經驗。 
綜合上述，出席此次會議，可以發表論文以將研究成果分享給與會學者，並增加自己及
學校的國際知名度與學術地位。此外，透過與其他學者之交流與討論，將可以了解目前
國科會補助計畫衍生研發成果推廣資料表
日期:2011/04/01
國科會補助計畫
計畫名稱: 區間型Type-2神模糊經系統之建構與學習
計畫主持人: 歐陽振森
計畫編號: 98-2221-E-214-043- 學門領域: 人工智慧
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1. 參加 2009 IEEE International Conference on Fuzzy Systems，擔任 session 
chair 並發表論文。 
2. 參 加 2010 International Conference on Machine Learning and 
Cybernetics，並發表三篇會議論文。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
