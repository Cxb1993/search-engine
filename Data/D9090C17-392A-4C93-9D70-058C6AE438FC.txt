II 
 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他：（以 100 字為限） 
 
 
 
附件二 
NSC report for a method of NIDS friendly deep
packet anonymization
Abstract—Real network traffic is an important asset for
research and development in the field of network security, but
due to privacy concerns of leaking personal and host information,
acquiring real traffic is quite restricted in practice. Over the
past years, researchers have developed anonymization techniques
to specify sensitive application fields or patterns to be hidden,
but the specification will take great effort to investigate the
sensitivity of a large number of application fields beforehand,
and can be inaccurate due to the lack of patterns for some
sensitive information. This work presents an innovative method
towards automatically inferring where sensitive information is in
the application messages, while taking utility of the anonymized
traces for network intrusion detection into account by preserving
the semantics of the application fields. The method can leverage
existing application protocol parsers to locate the application
fields or optionally infer the fields by clustering and aligning
similar application messages. After that, this method can infer the
degree of sensitivity of application fields with the C4.5 decision
tree algorithm based on the three measures: entropy, diversity,
and one-to-one mapping. The experimental results demonstrate
that the inference of sensitivity is effective with low false-negative
and acceptable false-positive rates. The evaluation also finds that
the anonymization can maintain the utility of the packet traces
well.
keyword: anonymization, packet trace, application protocol,
utility.
I. INTRODUCTION
Packet traces from real network traffic are valuable assets
for network research and development. Although it is possible
to acquire network traffic using tools such as the Harpoon
traffic generator [1], the emulated traffic is usually criticized
for being unrealistic because real traces are rather versatile,
containing traffic from peer-to-peer applications, online games,
various attack vectors, besides that from common applications
such as Web and email. For characterizing network traffic,
studying malicious network behavior, comparing competing
ideas, validating the robustness of a new implementation, and
so on, acquiring real network traffic is strongly desired.
Acquiring or sharing packet traces from real network en-
vironments is usually restricted in practice due to the privacy
concerns. Two types of sensitive information can be in the
traces: (1) personal information such as passwords, Web
browsing history and email addresses, and (2) system- or
application-related information such as the OS version and the
server program on a host. The former is undoubtedly sensitive.
The latter is also considered sensitive because an attacker can
leverage the information through passive fingerprinting to find
out vulnerable targets to be attacked [2].
Packet anonymization can help to sanitize sensitive informa-
tion in the packet traces [3]. Existing methods have been effec-
tive in anonymizing the fields in the TCP/IP and the link-layer
headers [3]–[5], and some also support anonymizing the fields
in the application protocols [6]–[8]. For the latter, existing
approaches include specifying (1) the application fields that are
considered sensitive (e.g., the URL in an HTTP request) to be
anonymized, or (2) patterns of potentially sensitive information
(e.g., those of email addresses, URLs, and IP addresses) to be
searched for in the application payloads.
Manually specifying the right application fields to be
anonymized is quite an effort. First, given the large number
of application fields in real packet traces, it is non-trivial to
study the semantics of every field and find out all sensitive
ones. Second, the specification relies on accurate parsing of
application protocols to locate the right fields. Even though a
network protocol analyzer such as Wireshark (www.wireshark.
org) can support hundreds of protocol parsers, neither the fine
granularity of its protocol parsing nor the number of supported
application protocols is sufficient. For example, Wireshark can
identify an FTP response message, but the parsing does not go
down to the fields in the message, which can contain sensitive
information such as file names. Moreover, Wireshark does not
support parsing some proprietary application protocols such as
those in many on-line games, but the messages in them may
be sensitive as well.
Specifying sensitive patterns is also unreliable. For ex-
ample, there are no specific patterns to represent personal
accounts and passwords, which can be specified arbitrarily
by users. Moreover, sensitive information may be represented
in multiple ways. For example, the IP addresses in the IP
header carried in the payload of an ICMP reply are simply
represented in four bytes (see RFC 792), not in the common
dotted representation of ASCII characters. The IP address and
port number in the FTP PORT command are represented in
the form like 192,168,150,80,14,178. The first four values
are an IP address and the last two encode a port number.
This representation separates the values in an IP address with
commas, so it will be missed if an anonymization tool seeks
a dotted pattern of IP addresses.
This work proposes two methods towards solving the afore-
mentioned problems: (1) inferring the fields in the application
messages, particularly those without a fine-granular parser, and
(2) inferring whether an application field should be sensitive
or not. For the former, this work provides a clustering and
alignment method on application messages to identify the
fields. For the latter, this work studies the measures and the
classification method that help to identify potentially sensitive
application fields.
algorithm [20] to perform an alignment on two closest se-
quences derived from similarity comparisons on a global set
of sequences.
Roleplayer [21] modifies the Needleman-Wunsch algorithm
to improve its performance by adjusting the weight in aligning
two application messages to find the most appropriate align-
ment. Discoverer [22] improves the alignment method by first
breaking up a message into a sequence of tokens, and then
inferring the fields by comparing the counterparts in another
message. The alignment is based on the tokens rather than raw
byte sequences. The work in [23] tracks the program binary
implementing the protocol to further improve the precision
of protocol reverse engineering, but tracking all the binaries
for the protocols involved in large packet traces will be
extremely complicated, if feasible. This work is inspired from
Discoverer for clustering and merging application messages.
Rather than rely on the precision of tokenization and semantic
inferences, this work simplifies the process by clustering based
on similarity between constant parts (usually keywords) in the
messages. The simplification is possible since we do not need
the full functionality of protocol reverse engineering for packet
anonymization.
III. DESIGN OF THE ANONYMIZATION METHOD
Inferring sensitive application fields involves two main
steps: (1) extracting the fields in the application messages,
and (2) judging whether each field is sensitive or not. The
procedure then anonymizes the sensitive fields, while preserv-
ing their semantics and lengths. We first present an overview
of the method, and then describe the details of both steps.
A. Overview of the method
• Extracting application fields: If the parser of an
application protocol exists, we can directly rely on
it for field extraction; otherwise, we group similar
messages into a cluster to infer the fields in them.
Note that a parser may not extract the deep fields in
some application messages. For example, the parser
in Wireshark just dissects the FTP response, 150
Opening ASCII mode data connection for
W010.txt (3343 bytes), into the response code
and the subsequent text, without extracting the fields of
transfer mode, file name, and file size. Therefore, we
may also need to group such messages for inferring the
fields (e.g., the file name) in the text part.
If inferring the fields is necessary, we align the messages
in the same cluster for identifying the constant and variant
parts in them. Since a constant part appears in every
message of the same cluster, it is likely to be a keyword
of the protocol, and should be insensitive. In contrast,
a variant part is likely to be a field in the application
messages. The field will be analyzed further to judge
whether it should be anonymized or not.
• Computing the measures of sensitivity in application
fields: The concept of sensitivity is subject, so we need
to look for objective measures to judge whether a field
1) Cookie:ystat_tw_ss376223=9_16940400_234398;
2) Cookie:zynga_toolbar_fb_uid=1018132522
3) GET /2009/visuels/Metaboli_120x600_UK.gif HTTP/1.1
4) GET /2010/07/15/ipad-3hk-smv-price-hk/ HTTP/1.1
5) GET /2.3.1/build/yahoo-dom-event/yahoo-dom-event.js
HTTP/1.1
6) GET /2.5.1/build/assets/skins/sam/container.css
HTTP/1.1
7) GET /album/insertPic.php?book=6 HTTP/1.1
8) GET /album/insertPoc.php HTTP/1.1
9) GET /album/select.php HTTP/1.1
Fig. 1. An example of messages lines of HTTP requests after the sorting.
should be anonymized or not. We use entropy, diversity,
and the mapping from the source IP address of the field
values as the measures. The reasons behind the measures
will be explained later.
• Anonymizing sensitive application fields: The anonymiza-
tion replaces the sensitive fields with another semantically
equivalent ones of the same lengths. For example, a
domain name is replaced with another domain name,
an email address is replaced with another email address,
and so on. Therefore, the packet lengths and number of
packets are the same after the anonymization.
B. Extracting application fields
This work uses Wireshark for field extraction. Wireshark
supports hundreds of protocol parsers (called dissectors) in-
voked based on the port numbers to extract the fields. For
application messages that Wireshark does not parse into,
we extract the message lines from the raw packets with
tcpflow (www.circlemud.org/∼jelson/software/tcpflow) for in-
ferring the fields later. In the latter case, we sort the mes-
sage lines of identical application protocols to facilitate the
clustering based on the heuristics that the first few bytes of
a message are usually commands (e.g., the GET command
in HTTP) or reply codes of the application protocols, and
the messages of similar formats will be ranked together after
the sorting. The heuristics is largely true with few exceptions
in our experiment. Without the prior sorting, the clustering
will have to seek throughout all the application messages for
similar ones, and become inefficient. Figure 1 presents a trivial
example of message lines after the sorting.
1) Clustering: The process then groups similar messages
into clusters with the two steps: initial clustering and merging.
The former attempts to group the messages with the same
multiple common substring (MCS), which is a sequence of
longest common substrings with at least 3 characters (to avoid
too short substrings). The algorithm is described as follows.
The derivation of the MCS in this algorithm is similar to that
in Section III-B2, except that the algorithm operates only on
two messages at a time.
We use the example in Figure 1 for demonstration.
• Initial clustering: Let Si be the application message in
line i. We first find a common substring L =Cookie:
in S1 and S2, i.e., MCS(S1, S2), implying that S1 and
S2 are in the same cluster C1. The step then proceeds to
check whether S3 belongs to the same cluster using the
• Entropy: The entropy of a field f is defined as
−Σpi log pi/ log k, where pi=|vi| /m and |vi| denotes
the number of occurrences in which the value of f is
vi. Entropy implies the degree of unpredictability. If the
entropy is close to zero, it means a field’s value is nearly
predictable, and one can easily guess the value. It is
therefore ineffective to anonymize a predictable field;
otherwise, if a field’s value is unpredictable, leaving
them unanonymized means revealing the information that
is supposed to be unknown, and the analysis therefore
suggests to anonymize such a field.
• Diversity: We define the diversity of a field as k/m, where
k, as defined above, is the number of different values that
may appear in a field. If the possible values are few, it
will be easy to make a guess from the few values, and it
is ineffective to anonymize such a field.
• One-to-one mapping: Consider the mapping from the
source IP addresses to a field’s values in the above
association. If the mapping is one-to-one, only one source
IP address ever sends a certain field’s value, e.g., a
user’s account, implying that the field value is likely to
be personal information. Otherwise, multiple source IP
addresses can generate a value. In other words, the value
is shared and known by multiple users. The measure
computes the rate of field values mapped from only one
source IP address. If the value is high, a field should be
sensitive and be anonymized.
The presence of network address translation (NAT) or
dynamic host configuration protocol (DHCP) may change
the source IP addresses and distort the measures of
entropy and one-to-one mapping. To solve this problem,
we can investigate the use of NAT or DHCP in a
network environment in advance, and avoid calculating
the measures from the problematic source IP addresses.
D. Anonymizing sensitive application fields
The anonymization provides a variety of functions, includ-
ing Block Black Marker for MAC address, Prefix-Preserving
and Length-Prefix-Preserving for IP address, Length-Semantic-
Preserving for replacing application fields, Field Transforma-
tion for protocol fields without specific types, and Checksum
Adjustment for all network and transport protocols1, thereby
providing adequate functionality for each different field. These
functions are described as follows.
• Block Black Marker sets the bits in a field to all 0’s.
• Prefix-Preserving function for IP addresses (especially
in the network layer) has been common in existing
anonymization tools since the work of [4].
• Length-Prefix-Preserving (LPP) attempts to preserve the
length of an IP address, if represented in ASCII, in ad-
dition to the attempt of prefix-preserving anonymization.
• Length-Semantic-Preserving (LSP) replaces a field such
as a mail address, URL or domain name in the payload,
1Note that the Frame Check Sequence (FCS) in the data-link layer is not
included in the adjustment, since it is not part of the PCAP format.
and then substitutes another mail address, URL or domain
name of the same length for that field, thereby preserving
the semantics of the field.
• Field Transformation fills a field identified in protocol
parsing with a repeating pattern (e.g., “XXXXX”), which
can be an integer or a string.
• Checksum Adjustment keeps the checksum valid. If the
checksum is invalid, some intrusion detection systems
will drop the packets with invalid checksums.
This work attempts to preserve the characteristics of
anonymized packet traces as many as possible. For instance,
this work substitutes an application field of the same type and
length for the original one in LPP and LSP. This approach has
three main benefits. (1) Preserving the number and lengths
of the original packets allows anomaly detection and traffic
classification based on statistical characteristics to still work
after anonymization. (2) An IDS can parse the payloads for
the protocol semantics as usual; otherwise, parsing errors
will occur (e.g., finding a malformed mail address). (3)
Keeping the length of the original application fields makes
designing anonymization tools relatively simple. Otherwise,
fields such as the sequence/acknowledgement number in the
TCP header, as well as some fields of an application pro-
tocol, e.g., the HTTP Content-Length field, should be
adjusted accordingly. If not, traffic analysis that examines the
sequence/acknowledge numbers (e.g., packet reassembly in an
IDS) will result in an error. This method does not need to
recalculate the above values after anonymization.
IV. EXPERIMENTAL RESULTS
In this section, we evaluate the accuracy of anonymization
and clustering on the application messages. Before discussing
the experimental results, we first describe the data sets and
evaluation methods.
A. Accuracy of Selecting Sensitive Fields for Anonymization
1) Evaluation methods: The packet traces for the evaluation
are real network traffic from multiple sources, involving seven
application protocols, HTTP, SMTP, FTP, SSH, DNS, WOW
(World of Warcraft), and YMSG (Yahoo messenger), totally
2.6GB in size. The payloads in the protocols include ASCII
characters and binary encoded information for testing with
various types of messages. We manually label the sensitivity
of 117 fields (extractable in Wireshark) in the protocols
according to the field’s value and the interpretation in the RFC
documents. Out of 47 of the fields are labelled sensitive after
the manual inspection.
We select the C4.5 decision tree algorithm in Weka (www.
cs.waikato.ac.nz/ml/weka) for classification because the other
algorithms do not perform better after our trials. Table I
lists the performance of the classification with 10-fold cross-
validation, where the accuracy is measured with precision and
recall defined as follows:
precision =
|Is ∩ I ′s|
|I ′s|
, recall =
|Is ∩ I ′s|
|Is| , (2)
The anonymization impact of HTTP 
header fields
100% 100% 100% 100% 96% 96%
76% 76%
72%
54%
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
T
ru
e 
P
os
it
iv
e 
R
at
e
HTTP Header Field
Fig. 3. The anonymization impact of HTTP header fields.
the following four messages, the first, the third, and the fourth
messages are of similar semantics, but they are separated after
the sorting because the variant parts (i.e., the domain names),
rather than the command, are in the first few bytes in the
messages.
221 2.0.0 cannoli.messagescreen.com closing connection
221 2.0.0 closing connection 14si3295638icg.127
221 2.0.0 fbmail003.snc1.facebook.com closing connection
221 2.0.0 fmgw.net.mexline.com closing connection
The solution is searching for similar messages throughout
the entire set of messages during the clustering, but the
clustering will become inefficient in the search process, and it
is a trade-off between efficiency and accuracy.
C. Utility after anonymization
This work defines the utility after the anonymization in
the evaluation, which is evaluated with the percentage of
malicious packet traces after anonymization that can be still
detected by the the open-source signature-based IDS, Snort
2.8.5, for easily investigating and interpreting the results by
comparing Snort’s signatures with the packet traces. The
evaluation anonymizes the packet traces and replays them
again to calculate the two metrics defining the utility.
1) TPtrace denotes the set of traces with malicious sig-
natures that can be still detected by the DUT after
anonymization.
2) FNtrace denotes the set of traces with malicious sig-
natures that cannot be detected by the DUT after
anonymization.
The utility is defined as follows:
Utility =
|TPtrace|
|TPtrace|+ |FNtrace| ∗ 100%. (6)
This work uses malicious HTTP traces in the evaluation, as
plenty of them are in the collection. Figure 3 presents the
impact of the anonymized HTTP header fields on the utility.
The evaluation observes that most malicious signatures are
embedded in the host, cookie and request URI fields.
If these fields are anonymized, the traces will be unlikely to
trigger logs.
Figure 4 compares the utility of the anonymization, namely
PCAPAnon, with two other tools, anontool and tcpanon. We
Utility of Anonymization Tools
96%
16%
96%100%
93%
100%100%
25%
88%
100%
75%
100%
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
anontool tcpanon PCAPAnon
U
ti
li
ty
Anonymization Tools
http
ftp
pop3
smtp
Fig. 4. Utility of the anonymization tools.
choose the two tools for comparison because they represent
typical examples of payload anonymization by pattern substi-
tution and field transformation.
V. CONCLUSION
Due to the diversity of application protocols in real packet
traces and their rich semantics, packet anonymization is still a
highly manual and error-prone process so far. The innovative
methods presented in this work can infer the sensitivity of
application fields, and optionally infer the fields in the appli-
cation messages without a parser. The evaluation demonstrates
the recall of inferring sensitive application fields is as high as
96%, while the precision is acceptable. The utility for intrusion
detection is also better than existing tools. The inference can
save a great amount of time for the network administrators to
determine which fields should be anonymized by leveraging a
protocol analyzer such as Wireshark, which has been able to
parse hundreds of application protocols. For those application
messages without a parser, the accuracy of clustering can be
nearly 78%, but is still not high enough due to the complexity
of the SMTP reply messages from a diversity of mail servers.
We will improve the clustering algorithm to increase the
accuracy in the future work.
REFERENCES
[1] J. Sommers and P. Barfold, “Self-configuring network traffic generation,”
In Proceedings of the 4th ACM SIGCOMM conference on Internet
measurement (IMC), Oct. 2004.
[2] Know your enemy: passive fingerprinting, Honeypot Project, Mar. 2002.
[3] R. Pang, M. Allman, V. Paxson and J. Lee, “The devil and packet trace
anonymization,” Computer Communication Review, 36(1), pp. 29-38, Jan.
2006.
[4] R. Ramaswamy and T. Wolf, “High-speed prefix-preserving IP address
anonymization for passive measurement systems,” IEEE/ACM Trans.
Networking, 15(1), pp. 26-39, Feb. 2007.
[5] J. Xu, J. Fan, M. H. Ammar and S. B. Moon, “Prefix-preserving IP
address anonymization: measurement-based security evaluation and a
new cryptography-based scheme,” In Proceedings of Intl. Conf. Network
Protocols (ICNP), Nov. 2002.
[6] Tcpanon, available at http://www.ing.unibs.it/ntw/tools/tcpanon.
[7] R. Pang and V. Paxson, “A high-level programming environment for
packet trace anonymization and transformation,” In Proceedings of ACM
SIGCOMM, Aug. 2003.
[8] D. Koukis, S. Antonato, D. Antoniades, E. P. Markatos and P. Trimintzios,
“A generic anonymization framework for network traffic,” In Proceedings
of IEEE Intl. Conf. on Communications (ICC), Jun. 2006.
 1 
 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：100年 10月 29日 
                                 
一、參加會議經過 
 本計畫成果的論文目前已撰寫完畢，近日(10月底)即將投搞，而先前的成果投稿國際會議尚未
被接受，因此只得選擇參加相關的會議。在時間的考量下，選擇了今年在荷蘭阿姆斯特丹的 Eighth 
Conference on Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA)，這個會議與
網路安全的議題息息相關，而且是相關領域學者在投稿時的一個重要標的。我在 7 月 6 日抵達阿
姆斯特丹，隔日即前往 Vrije Universiteit參加本次的會議。會議結束後，在當地休息一天後隨
即返台。 
二、與會心得 
 這次會議的論文當中，雖然看到了許多與網路安全相關的論文發表，但與本計畫最息息相關的是
由UCB團隊發表的An Assessment of Overt Malicious Activity Manifest in Residential Networks。在這篇研
究當中，UCB團隊對許多網路的真實流量進行大規模的觀察，流量的來源包含20,000名歐洲地區的DSL
客戶，1,000名印度的社區網路使用者，以及一個大學宿網內數千名學生，以及在UCB之Lawrence Lab
計畫編號 NSC 99－2221－E－194－052－ 
計畫名稱 對網路型入侵偵測系統友善的深層封包匿名化方法 
出國人員
姓名 
林柏青 
服務機構
及職稱 
中正大學資訊工程系 
會議時間 
2010 年 7 月 7 日
至 
2010 年 7 月 8 日 
會議地點 
荷蘭 阿姆斯特丹 
會議名稱 
(中文)Eighth Conference on Detection of Intrusions and Malware & Vulnerability 
Assessment (DIMVA) 
(英文)第八屆入侵與惡意程式偵測及弱點評估 
發表論文
題目 
(中文) 
(英文) 
附件四 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/28
國科會補助計畫
計畫名稱: 對網路型入侵偵測系統友善的深層封包匿名化方法
計畫主持人: 林柏青
計畫編號: 99-2221-E-194-052- 學門領域: 資訊安全
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
