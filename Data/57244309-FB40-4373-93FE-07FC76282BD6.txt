 2 
行政院國家科學委員會專題研究計畫成果報告 
針對 H.264 多張參考圖框之快速運動估測法 
 Fast Multiple Reference Frame Motion Estimation for H.264 
計畫編號：NSC  95 – 2221 – E – 027 – 030  
 執行期限：95 年 8 月 1 日至 96 年 7 月 31 日 
主持人：郭天穎   國立台北科技大學電機系 
計畫參與人員：羅一中 蕭立賢 林政毅 徐俊傑  
葉錦坤 王忠信 曾世忠 蕭文海 
國立台北科技大學電機研究所 
 
一、中文摘要 
 
 多張參考圖框之運動補償機制，已被使
用在新興的視訊編碼標準 H.264 中，利用多
張參考圖框之區塊補償方式，改善了框間預
測的效能。然而，在現實運用上，此編碼流
程在運算複雜度及所耗費之時間仍具有改善
之需要。在這次計畫中，提出解決上述問題
之方法—針對 H.264 多張參考圖框之快速運
動估測法，此方法的原理是靠著連續軌跡搜
尋的初步結果限制參考圖框，並且更進一步
地排除不需執行運動估測之可變區塊模式。
實驗結果證實了我們所提出的估測機制不但
在 位元率-失真 效能的表現上接近於全搜
尋，同時也降低了運算複雜度。 
 
關鍵詞：多張參考圖框、H.264、運動估測、
可變區塊大小、區塊模式決策 
 
Abstract 
 
Multiple reference frame motion 
compensation has been adopted by the 
emerging video coding standard H.264/AVC. It 
improves the inter-frame prediction by 
compensating blocks from more than one 
reference frames. However, the process is 
computationally involved and should be sped 
up for practical realization. This work aimed to 
this problem and proposed a fast algorithm, 
called Fast Multiple Reference Frame Motion 
Estimation (FMRFME). The principle of our 
proposed FMRFME is to qualify reference 
frames by the preliminary results of the 
continuous tracking search, and only the 
qualified frames should be further tested in 
variable block size motion estimation. The 
experimental results show that the proposed 
method reduces a considerable amount of 
complexity of multiple reference frame motion 
estimation while keeping similar R-D 
performance as full search. 
 
Keywords: motion estimation, variable 
block size, multiple reference frame, frame 
selection, H.264. 
 
二、緣由與目的 
 
The latest video coding standard, 
H.264/MPEG-4 AVC [1], introduces several 
new coding tools to improve the rate-distortion 
performance of the past coding standards. The 
enhancement for inter-frame coding in H.264 
includes quarter-pixel accuracy, variable block 
size partitioning, and multiple reference frame 
motion compensation, etc. Multiple reference 
frames motion compensation allows the 
encoder to predict a picture using many stored 
pictures which had been coded previously. It 
achieves better performance in the cases of 
repetitive motions, uncovered background, 
non-integer pixel displacement, and lighting 
changes, etc. However, the computational 
complexity of motion estimation process 
increases dramatically in comparison with that 
of one reference frame, which is adopted in 
previous standards. Variable block sized 
motion compensation in H.264 supports seven 
different block sizes (16x16, 16x8, 8x16, 8x8, 
8x4, 4x8, 4x4), which are defined as mode 1 to 
mode 7 respectively. Variable block size 
motion compensation can represent the motion 
characteristic in a macroblock more accurately, 
 4 
三、研究方法 
   
The flowchart of the proposed method is 
illustrated in Fig. 1. At first, a 16x16 MB is 
disjoined into four blocks of size 8x8 (i.e., 
mode 4) to perform diamond search [14] on the 
immediate reference frame (previous frame), 
followed by the sub-pixel motion refinement to 
obtain four motion vectors, tMVs −∆  (here, the 
value of frame distance ∆  is one). If all 
1tMVs −  are zero, the MB has high possibility to 
be the static content, and our encoder will only 
have to test modes 1, 2, 3, and 4 on previous 
frame for inter prediction. On the other hand, if 
one of 1tMVs −  is non-zero, another strategy, 
continuous tracking diamond search (CTDS), 
will be exploited to search on all the rest 
reference fames for obtaining motion vectors of 
mode 4 (8x8 blocks). Based on the CTDS 
search results, we can discard the unqualified 
reference frames and modes by the 
tMVs −∆ calculation of 8x8 blocks to achieve 
multiple references frame selection (MRFS) 
and mode selection. Only the frames referred 
by CTDS will further be performed on variable 
block size mode test, and some of the test 
modes may be skipped depending on the 
variance of tMVs −∆ . If the variance of four 
tMVs −∆  is zero, it represents that the contents in 
a MB have uniform motion characteristics, and 
only larger block size modes, modes 1, 2, 3, 
and 4, on the corresponding frame are 
performed. Finally, a fast motion estimation 
approach is proposed by properly setting the 
initial search position and search range for each 
selected reference frame with valid modes. 
 
tMVs −∆
1tMVs −
 
Fig. 1 The flowchart of the proposed method. 
3.1 Various Prediction Methods in CTDS 
The purpose of CTDS is to find out the best 
motion vectors of mode 4 (block size 8x8) 
from current frame to the reference frames. The 
CTDS result is passed to our multiple reference 
frame selection scheme discussed in the next 
section. 
Our proposed CTDS combines the continuous 
tracking search (CTS) technique with diamond 
search (DS) [14]. The basic concept of CTS 
technique is to deduce a possible motion vector 
location on farther reference frames from the 
obtained results of recent reference frames. 
This deduction is reasonable because in most 
cases the moving objects in the successive 
frames are traceable. Another advantage of 
CTS is to have better chance of locating a 
larger motion vector in the farther frame 
because of the incremental motion composition 
during tracking. During tracking process, CTS 
has to refine around tracked position on each 
reference frame to accelerate the convergent 
speed of tracking, and to improve the 
accuracy of reference frame selection. In 
literature [5]-[8], all CTS variations refine 
the tracked position by refining it with a 
fixed search window. However, the range of 
search window is a serious problem in CTS. A 
small search range around the tracking motion 
vectors might be failed if the target vector has 
larger displacement away from the tracking. On 
the other hand, a large search range might be 
inefficiency if the target object is almost static. 
Therefore, instead of using a fixed search range 
of refinement, our proposed CTDS algorithm 
adopts the diamond search strategy [14] to 
adaptively refine the CTS tracked position 
while keeping the search complexity as low as 
possible. We classify various CTS approaches 
into five categories as described below. 
 
3.1.1 Clonally Tracking Motion Vector 
Prediction (CT-MVP) 
1∆=2∆=3∆=4∆=
 
Fig. 2 Motion vector correlation in successive 
reference frame. 
 6 
3.1.5 Forward Dominant Vector Selection 
(FDVS) 
Both ST-MVP and LT-MVP track motion 
vectors at the corresponding macroblock 
position across frames to compose and 
predict the search position. However, this 
idea might fail when the large motion occurs 
inside video sequence, because the moving 
objects may move away from the 
corresponding macroblock along frames and 
become not traceable using the corresponding 
position; at this situation, the motion vector of 
the neighbor block may provide the best match 
to that moving object instead of the block at 
same position. Therefore, FDVS [7] considers 
more choices from one of four blocks for 
tracking, which are the blocks pointed out by 
the incoming motion vector. Among these 
four, the one with largest covering, i.e. best 
match, to the moving object will be chosen as 
the dominant block and its vector is for use in 
tracking. As the example illustrated in Fig. 3, 
the motion vector of every block to its 
previous frame had been stored at each 
period. FDVS uses the best motion vector to 
Frame t-2 as the incoming motion vector to 
match the block in Frame t-3. The best match 
of Frame t-2 overlaps up to 4 blocks in Frame 
t-2 at period T, which can be mapped to as 
the current frame t at period T-2. The initial 
search position to Frame t-3 is composed of 
the stored motion vector of largest overlap 
block at period T-2 and the best motion 
vector to Frame t-2 in period T. For example, 
the initial search position to Frame 3 can be 
expressed as: 
1 2(3)FDVS MV MV= +               (3.7) 
1∆=2∆=3∆=4∆=
1∆=
reference frames
1∆=
t
t
t
incoming motion 
vector MV1
Block with largest overlap 
indicated by incoming 
motion vector 
Forward dominant 
motion vector MV2
for vector sum
 
Fig. 4 Forward dominant vector select 
3.2 Multiple Reference Frame Selection 
(MRFS) 
Based on the vector output of CTDS, 
multiple reference frame selection (MRFS) 
strategy can effectively drop the unqualified 
reference frames and prevent them from 
further motion search for other modes. The 
concept of the proposed MRFS is illustrated 
in Fig. 5. In the left part of Fig. 5, supposed 
that the motion vectors for four 8x8 blocks 
(mode 4) searched by CTDS are located on 
Frame t-1, t-2, and t-4. Our MRFS strategy is 
to drop the non-referred frames, Frame t-3 in 
this example, and only perform further 
motion search of all the other modes on those 
frames referred in CTDS, that is Frames t-1, 
t-2, and t-4. We expect MRFS would speed 
up the motion search for the right reference 
frames as some of unqualified frames have 
been dropped. On the other hand, we expect 
the same motion search result if we apply full 
search to all of reference frames. As shown 
on the right side of Fig. 5, where Frames t-3 
and t-4 are not referred in full search, we can 
thus claim the proposed MRFS saves the 
complexity by correctly dropping the 
unqualified Frame t-3. We measure this 
correctness by the target hit rate, which is the 
ratio of the number of the qualified frames by 
MRFS to those actually referred in full search. 
We test the average hit rate of MRFS with 
various initial search position prediction tools 
in Table 1. In Table 1, P(E8x8) denotes the 
reference frame selection hit rate of MRFS to 
the full search, for the event E8x8 with four 
8x8 motion vectors for a macroblock is used 
during CTDS search. P(E4x4) denotes the 
same meaning while using sixteen 4x4 blocks 
(i.e., mode 7) in a macroblock during CTDS 
search. Table 1 shows that the hit rate is as 
high as about 95%, and better than the case of 
4x4 block when 8x8 block is used. By the 
way, FDVS has highest hit rate to choose the 
qualified frames. Thus we design the 8x8 
block motion search in our CTDS in terms of 
both hit rate and speed. 
 8 
四、結果與討論 
 
    The proposed method was implemented 
on the H.264 reference software JM9.2 [11]. 
There are seven test video sequences adopted 
in our simulation covering from QCIF and 
CIF resolution including "Suzie (QCIF-150 
frames)", "Foreman (QCIF-400 frames)", 
"Stefan (QCIF-300 frames)", "Carphone 
(QCIF-350 frames)", "Mobile (QCIF-300 
frames)", "Tempete (CIF-260 frames)", and 
"Mobile2 (CIF-300 frames)". For all the 
simulations, we used the baseline profile and 
turned on the RDO with five QP values 
including 32, 28, 24, 20, and 16. The number 
of multiple reference frames is set to 5, and 
CABAC entropy coding is used. We encoded 
the first frame of video as an I-frame and the 
rest as P-frames, and the frame rate is 30 Hz. 
The experiment was run on the Intel® 
Pentium 4 2.7GHz with 512 MB ram and the 
OS is Microsoft® Windows XP. For 
comparison use, we implemented Li’s fast 
algorithm which was proposed recently: 
FMASS (Fast flexible Multi-frame motion 
estimation algorithm with Adaptive Search 
Strategies) [10]. FMASS had better 
performance in comparison with MVFAST 
[15], APR-3 [16], and UMHexagonS [17]. It 
should be noted that MVFAST was accepted 
by MPEG in 2000 and UMHexagonS was 
accepted by JVT in 2003. In this experiment, 
we compared the performance of the 
proposed method, FMRFME, to three 
methods. Two methods were adopted in 
JM9.2, i.e., the full search FFS and the fast 
search FME, and the other method was the 
implemented FMASS. Note that FMRFME, 
FME, and FMASS adopted the same 
algorithm CBFPS to find the fractional 
vectors. 
Since FMRFME adopts CTDS (CTS+DS) 
technique to drop the un-qualified reference 
frames from search, we would first test the 
performance of various CTS techniques 
described in Section 3.1, including CT-MVP, 
LP-MVP, ST-MVP, LT-MVP, and FDVS. 
The performance of bit rate increment and 
PSNR loss by adopting various CTS to our 
FMRFME is shown in the 3rd to 7th columns 
of Table 2, which use the full search FFS of 
JVT as the comparison benchmark. MSPSR 
is used in this test. From those columns, we 
observed ST-MVP, LT-MVP and FDVS 
outperform CT-MVP and LP-MVP as 
expected. This is consistent with the hit rate 
analysis in Table 1. However, the 
performance differences among ST-MVP, 
LT-MVP and FDVS are not obvious. This is 
because we use DS to fix the predicted 
position for each tracked frames, and this DS 
refinement minimizes the prediction 
difference among ST-MVP, LT-MVP and 
FDVS. This fact that DS can effectively fix 
the tracking to a better position supports our 
DS adoption in FMRFME. In addition, 
because FDVS is the best technique to 
predict the motion vector, it would take least 
search time to approach the best motion 
vector. We would recommend using FDVS as 
our CTS technique because of its hit rate and 
search speed, compared to ST-MVP and 
LT-MVP. 
In Table 2, we found the R-D performance 
of FDVS-FMRFME is similar to the FME of 
JVT (1st column) and Li’s FMASS (2nd 
column). We can also observe this situation 
from the R-D curves for some test sequences 
shown in Fig. 6. The R-D curve difference 
among FFS, FME, FMASS, and the proposed 
FDVS-FMRFME is negligible. In addition, as 
shown in Table 3 where the encoding time is 
used as for evaluating the speed-up, the 
average encoding speed-up of FMRFME 
using various prediction tools with RDO on 
is about 2.84 to 2.91 times over FFS in QCIF 
format, and 2.22 to 2.29 times over FFS in 
CIF format. We can further increase the 
speed-up factor by replace our implement of 
MSPSR with MFME as described in Section 
3.3.2, while keeping the similar R-D 
performance as measured in the last column 
of Table 2. This proves our FMRFME is the 
best MRFME encoder design in terms of the 
complexity reduction. Note that the speed-up 
factor of FMRFME is better than FME and 
FMASS in all cases. 
 
五、計畫成果自評 
    In this work, a fast multiple reference 
frame motion estimation, FMRFME, is 
proposed to alleviate the huge complexity 
resulting from the multiple reference frames 
and block partitions. The proposed FMRFME 
 10
參考文獻： 
 
[1] Ostermann, J., Bormans, J., List, P., 
Marpe, D., Narroschke, M., Pereira, F., 
Stockhammer, T., and Wedi, T., "Video 
coding with H.264/AVC: tools, 
performance, and complexity", Circuits 
and Systems Magazine, IEEE , Vol. 
4 , Issue 1 , 2004 pp. 7 – 28. 
[2] Joint Video Team (JVT) of ISO/IEC 
MPEG & ITU-T VCEG, "Draft ITU-T 
Recommendation and Final Draft 
International Standard of Joint Video 
Specification (ITU-T Rec. H.264 | 
ISO/IEC 14496-10 AVC)", ITU-T | 
ISO/IEC , 2003. 
[3] Wiegand, T., Sullivan, G.J., Bjntegaard, 
and G., Luthra, A., "Overview of the 
H.264/AVC video coding standard", 
Circuits and Systems for Video 
Technology, IEEE Transactions on, 
Volume 13, Issue 7, 2003 , pp. 560 – 576. 
[4] Woong IL Choi, Byeungwoo Jeon, and 
Jechang Jeong, "Fast motion estimation 
with modified diamond search for 
variable motion block sizes", Image 
Processing, 2003. Proceedings. 2003 
International Conference on, Volume 2, 
14-17 2003 pp. II - 371-4 vol.3. 
[5] Tourapis A.M., Au O.C., and Liou M.L., 
"Highly efficient predictive zonal 
algorithms for fast block-matching 
motion estimation", Circuits and  
Systems for Video Technology, IEEE 
Transactions on, Vol. 12 , Issue 10, 
2002, pp. 934-947. 
[6] Jianning Zhang, Yuwen He, Shiqiang 
Yang, and Yuzhuo Zhong, "Performance 
and complexity joint optimization for 
H.264 video coding", Circuits and 
Systems, 2003. ISCAS '03. Proceedings of 
the 2003 International Symposium on, 
Vol. 2, 2003, pp. 888 – 891. 
[7] Hanfeng Xu, Zhibo Chen, and Yun He, 
"Efficient fast ME predictions and 
early-termination strategy based on 
H.264 statistical characters", Information, 
Communications and Signal Processing, 
2003 and the Fourth Pacific Rim 
Conference on Multimedia. Proceedings 
of the 2003 Joint Conference of the 
Fourth International Conference on, Vol. 
1, 2003, pp. 218 – 222. 
[8] Zhibo Chen, Peng Zhou, and Yun He, 
"Fast Motion Estimation for JVT", 
JVT-G016, Joint Video Team (JVT) of 
ISO/IEC MPEG & ITU-T VCEG, 7th 
meeting, 2003. 
[9] JM Reference Software 9.8,      
http://bs.hhi.de/~suehring/tml/. 
[10] K.P. Lim, S. Wu, D.J. Wu, S. Rahardja, X. 
Lin, F. Pan, and Z.G. Li, "Fast Inter Mode 
Selection", JVT-I020, Joint Video Team 
(JVT) of ISO/IEC MPEG & ITU-T 
VCEG, 9th meeting, 2003 
[11] P. Yin, H.-Y.C. Tourapis, A.M. Tourapis, 
and J. Boyce, "Fast mode decision and 
motion estimation for JVT/H.264," Image 
Processing, 2003. International 
Conference on, Vol. 3, Sept. 2003, pp. 
853-856. 
[12] Yu-Kuang Tu, Jar-Ferr Yang, Yi-Nung 
Shen, and Ming-Ting Sun, "Fast 
variable-size block motion estimation 
using merging procedure with an adaptive 
threshold", Multimedia and Expo, 2003. 
ICME '03. Proceedings. 2003 
International Conference on, Volume 2, 
pp.789 – 792. 
[13] Kuo Chih-Hung, Shen Meiyin, and Kuo 
C.-C. Jay, "Fast variable-block-size 
motion compensation algorithm for 
H.264 video coding", Proc. of SPIE 
Conf. on Visual Communication and 
Image Processing, vol. 5241, 2003, pp. 
76-87 
[14] J. Lee and B. Jeon, "Pruned Mode 
Decision based on Variable Block Sizes 
Motion Compensation for H.264," Lecture 
Note in Computer Sciences, vol. 2899, 
MIPS2003, 2003 ,pp. 410-418. 
[15] W.I. Choi, J. Lee, S. Yang, and B. Jeon, 
"Fast motion estimation and mode 
decision with variable motion block 
sizes," Proc. of SPIE Conf. on Visual 
Communication and Image Processing, 
vol. 5150, 2003, pp. 1561-1572. 
[16] G. Bjontegaard, "Calculation of average 
PSNR differences between RD-curves," 
ITU-T Q6/SG16 Doc. #VCEG-M33, 2-4 
April 200 
