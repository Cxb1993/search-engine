objectives, the total completion time and the total absolute differences in completion 
times. 
To deal with this new problem, we proposed a method to solve it effectively. We first 
analyzed the parameters according to the weights on each position of the two objectives. 
Then, we matched the weights with the processing time of the jobs. So that two optimal 
sequences were obtained by this matching approach. In addition, we started to search a 
new Pareto solution located between the two new solutions. The process was repeatedly to 
search a pair of solutions until no new solutions were found. Our approach was very 
efficient to find out thte minimum set of optimal sequences (MSOS). In order to evaluate 
the proposed method, we compared it with the state-of-art multi-objective algorithm, 
MOEA/D, on numerous instances. The empirical results shown the proposed algorithm 
was effectively to find out a set of approximate solutions in a very short CPU time when it 
was compared with MOEA/D. This proposed algorithm was promising to solve the 
biceriteria scheduling problem in this research. 
Keywords: Single machine scheduling, Bi-criterion optimization problem, 
Past-sequence-dependent setup times, Learning effect, Multi-Objective Evolutionary 
Algorithms 
 
 
tail of MOEA/D and the combination with Aneja-Nair
method are explained in Section 3.7.
3.2 Problem Definitions of PSD and LE
3.2.1 Problem Definition of Past-Sequence-
Dependent Setup Times
A batch of n independent jobs to be processed on a
continuously available single machine. The machine
can process only one job at a time and job splitting
and inserting idle times are not permitted. All the jobs
are available at time zero. Each job has a processing
time pj , (j = 1, 2, ..., n). Let s[j] and p[j] be the setup
time and processing time of a job occupying position
j in the sequence respectively, and s[j] is defined as
s[j] = γ
j−1∑
i=1
p[i] j = 2, 3, ..., n s[1] = 0, (1)
where γ ≥ 0 is a normalizing constant. In the
above Eq. (1), the actual length of the setup time
depends on the value of γ. Koulamas and Kypari-
sis [8] considered the following scheduling problems
with past-sequence-dependent setup times given by
equation (1). Problem. (i): 1/spsd/Cmax; Prob-
lem. (ii):1/spsd/TC; Problem. (iii):1/spsd/TADC;
Problem.(iv):1/spsd/BC. It is shown in [8] that
the well-known shortest processing time (SPT) se-
quence is optimal for both the problems Problem. (i)
(1/spsd/Cmax) and Problem. (ii) (1/spsd/TC).
3.2.2 Problem Definition of Learning Effect
When we include the learning effect as given in [4],
the processing time of a job depends on its position in
the sequence and is given as
pjl = pjl
α (2)
In the above equation, pj is the normal processing
time of job j, and pjl is the processing time of job j if
it is in position l of the sequence, and α is the learning
index and α < 0. From the above equation (2), we
see that pj1 > pj2 > pj3... > pjn. For example, if
pj = 3 and α = −0.515, then pj1 = 3, pj2 = 2.0994,
pj3 = 1.7037, pj4 = 1.4691, pj5 = 1.3095, and so on.
3.3 Past-Sequence-Dependent Setup
Times Together with Learning Effect
After the basic problem definitions of PSD and LE
are introduced, this study explains the core of the re-
search which takes the PSD and LE into considerate.
The scheduling problem is defined in the following
manner. A set of n independent jobs to be processed
on a continuously available single machine. The ma-
chine can process only one job at a time and job split-
ting and inserting idle times are not permitted. All the
jobs are available at time zero. Each job has a normal
processing time pr, (r = 1, 2, ..., n). The processing
time of a job occupying position r in the sequence is
given by
pA[r] = p[r] ∗ ra, r = 1, 2, ..., n (3)
where a ≤ 0 is a constant learning index. Let s[r]
be the setup time of a job occupying position r in the
sequence, and s[r] is defined as
s[1] = 0
s[r] = b ∗
r−1∑
j=1
pA[j] r = 2, 3, ..., n (4)
where b ≥ 0 is a normalizing constant. In the above
Eq. (4), the actual length of the setup time depends
on the value of b and learning index a. Let Cr de-
note the completion time of job r in a sequence. It
is shown in [3] that the well-known shortest process-
ing time (SPT) sequence is optimal for both the prob-
lems Problem. (i) (1/LE, spsd/Cmax) and problem.
(ii) (1/LE, spsd/TC).
3.4 PSD and LE for the Objectives TC
and TADC
Section 3.3 already defines the processing time when
we consider the PSD and LE into together. Since
the bi-objectives studied by this project are the total
completion time (TC) and total absolute difference
in completion times (TADC), the following sections
show the formulation of the two objectives. TC is ex-
plained and then the second objective TADC is shown
later.
2
and bi-criterion single machine scheduling problem
with a learning effect should be calculated. The one
to one correspondence between the two problems are
given in Table .1 of Appendix .1 Once this is known,
the concept of Aneja-Nair method could be used to
generate the MSOS. The proposed algorithm was
shown as follows:
Notation:
• Weight1: Initial weight vector for TC
• Weight2: Initial weight vector for TADC
• X1: A solution obtained by matching the
Weight1
• X2: A solution obtained by matching the
Weight2
• Z1: The objective values of the solution X1
• Z2: The objective values of the solution X2
• Ω: A set of Pareto solutions
• δ: A set of new solutions
• Xi: A new solution found by the weight match
algorithm
Algorithm:
1: Weight1← Calculate the Weights of TC
2: Weight2← Calculate the Weights of TADC
3: X1←MatchAlgorithm(Weight1)
4: X2←MatchAlgorithm(Weight2)
5: Ω← {X1, X2}
6: CombinedWeight← UpdateWeight(ZX1 , ZX2)
7: δ←MatchAlgorithm(CombinedWeight)
8: while δ is not empty do
9: Selected a Solution (X) and a Solution (Y )
from Ω and δ, respectively
10: CombinedWeight← UpdateWeight(ZX , ZY )
11: Xi←MatchAlgorithm(Weight)
12: isNew← RedundantSolution(Xi)
13: if isNew is true then
14: δ← {Xi}
15: end if
16: Add Y to Ω if Y is compared with all solutions
in Ω, and remove Y in δ
17: end while
18: Output Ω
Line 1 and Line 2 calculated the weight vector based
of the two objectives. Once they are obtained, we
used the weight matching algorithm to obtain two se-
quences according to the weight vector in Line 3 and
Line 4. The two solutions are collected into the set
Ω. It represents the Pareto set founded by the pro-
posed algorithm. In addition, the objective values of
the two solutions are computed in Line 6. Later on,
we could find out the intermediate solution between
X1 and X2 and then have a new solution in Line 7.
During Line 8 to Line 17, it is an iterative procedure
to find out whether there is any intermediate solution
between each pair of solutions in Ω and δ. Once a
solution in δ is compared with all the solutions in Ω,
this solution is moved to Ω instead of staying in δ. As
a result, when there is no solutions in δ which could
be searched with Ω, the iterative process is terminated
and the Pareto set Ω is output in Line 18. We present a
numerical example for illustration.
Numerical Example: We now use the same 4 job
problem given in Bagchi [3], with a learning effect
(α = −0.152). We show how to apply Aneja-Nair
method and obtain the minimum set of optimal sched-
ules. The normal processing time of these jobs are
p1 = 1, p2 = 2, p3 = 3, and p4 = 4. The parameter b
is set as 0.25.
Following Aneja [1], we first obtain point 1 in the
objective space. This is obtained by minimizing z1
the first objective; i.e., the total completion time (TC).
The positional weights and the optimal sequence ob-
tained are shown in Table.1. The optimal sequence
obtained is {1 2 3 4}. The value of z1 for this se-
quence is 21.2019. The value of z2 the second objec-
tive; i.e., the total absolute differences in completion
times (TADC), is 32.8285. Hence, z(1)1 = 21.2019,
and z(1)2 = 32.8285.
Table 1: Matching algorithm for minimization of TC:
α = −0.152, b = 0.25
Position-r 1 2 3 4
w1,αr 5.5000 3.3750 1.9040 0.8100
Sequence∗ 1 2 3 4
We now obtain point 2 in the objective space. This
is obtained by minimizing z2 the second objective;
i.e., the total absolute differences in completion times
(TADC). The positional weights and the optimal se-
quence obtained are shown in Table.2. The optimal
4
The values of z1 and z2 for this sequence ({3 1 2 4})
are 26.9230 and 29.5340 respectively. We call this as
point 5 in the objective space and z(5)1 = 26.9230, and
z
(5)
2 = 29.5340.
Table 5: Matching algorithm for minimization of Eq.
(11) : α = −0.152, b = 0.25
Position-r 1 2 3 4
w1,αr 5.0833 7.1512 6.3993 3.7816
Sequence∗ 3 1 2 4
When we use the points 1 and 4, we obtain the same
optimal sequence {1 2 3 4}. When, we use the points 3
and 4, we obtain the same optimal sequence obtained
is {3 1 2 4}. When we use the points 3 and 5, we obtain
the same optimal sequence {3 1 2 4}. When we use the
points 2 and 5, we obtain the same optimal sequence
{3 2 1 4}. There are no other optimal sequences and
so the algorithm terminates.
Based on the above, the minimum set of optimal
sequences to this problem is: {1 2 3 4}, {3 2 1 4},
{3 1 2 4}, and {2 1 3 4}.
It is shown in Bagchi [3] that the cardinality of
the set MSOS is n, when the learning effect is not
considered; i.e., α = 0. Then in the author’s pre-
vious research, it indicates that the cardinality of the
set MSOS is more than n when the learning effect is
included; i.e., α 6= 0. When it comes to the PSD
and LE are considered together, the MSOS is n.
Thus, there are some interesting characteristic should
be studied.
To summarize the Aneja-Nair method to solve this
single machine scheduling problem, the first step is to
obtain the optimal solutions (Pareto) or good sequence
of each objective. After that, we will search the weight
combination of two Pareto solutions and then to sort
the new weights resulted in a new sequence. Then we
iteratively search the new sequence between the pair-
wise solutions. By using Aneja-Nair method, we can
find the MSOS efficiently since each operation needs
nlogn to do the sorting. So it is quite efficient to ob-
tain a set of Pareto solutions. When we have to obtain
CSOS, we need to apply MOEAs to do global search.
In addition, we can compare the MOEAs with Aneja-
Nair method so that we can evaluate the Aneja-Nair
method. The next section presents the approaches of
MOEAs.
3.6 MOEA/D
In this project, we propose an implementation of
MOEA/D for the bi-criteria single machine schedul-
ing problems. We discuss the choice of decomposi-
tion methods in MOEA/D first, which is the setting
of reference point and the way of updating neighbor-
ing solutions in Section 3.6.1. Later on, Section 3.6.2
presents the general framework of MOEA/D in Sec-
tion 3.6.3 and the revised version for this scheduling
problem is shown in Section 3.6.3.
3.6.1 Decomposition of Multi-Objective Opti-
mization
The multi-objective optimization problem (MOP) can
be stated as follows:
Minimize F (x) = (f1(x), . . . , fm(x))T
Subject to x ∈ Ω (12)
There are several approaches for converting the
problem of approximation of the PF into a number of
scalar optimization problems and they can be found
in the literature (e.g., [12]). The most popular ones
among them include the weighted sum approach and
Tchebycheff approach which are introduced in the fol-
lowing:
Weighted Sum Approach [12]
This approach considers a convex combination of
the different objectives. Let λ = (λ1, λ2, . . . , λm)T
be a weight vector, i.e., λi ≥ 0 for all i = 1, . . . ,m
and
∑m
i=1 λi = 1. Then, the optimal solution to the
following scalar optimization problem:
Minimize gws(x|λ) = ∑mi=1 λifi
Subject to x ∈ Ω (13)
is a Pareto optimal point to 13, where we use
gws(x|λ) to emphasize that λ is a coefficient vector
in this objective function, while x is the variables to
be optimized. To generate a set of different Pareto
optimal vectors, one can use different weight vectors
x in the above scalar optimization problem. If PF is
convex, this approach would work well. However,
not every Pareto optimal vector can be obtained by
this approach in the case of non-convex PFs [12]. To
overcome these shortcomings, Tchebysheff approach
is suggested.
6
Step 2) Update:
For i = 1, . . . , n, do
Step 2.1) Reproduction: Randomly select two in-
dexes k, l from B(i), and then generate a new solution
y from xk and xl by using genetic operators.
Step 2.2) Improvement: Apply a problem-specific
repair/improvement heuristic on y to produce y′ .
Step 2.3) Update of z: For each j = 1, . . . ,m, if
zj < fj(y
′
), then set zj = fj(y
′
)
Step 2.4) Update of Neighboring Solutions: For
each index j ∈ B(i), if gte(y′|λj, z) ≤ gte(xj|λj, z),
then set xj = y
′ and FV j = fj(y′).
Step 2.5) Update of EP:
Remove from EP all the vectors dominated by F (y′).
Add F (y′) to EP if no vectors in EP dominate F (y′).
Step 3) Stopping Criteria: If stopping criteria is
satisfied, then stop and output EP. Otherwise, go to
Step 2.
In initialization, B(i) contains the indexes of the T
closest vectors of λi. We use the Euclidean distance
to measure the closeness between any two weight vec-
tors. Therefore, λi’s closest vector is itself, and then
i ∈ B(i). If j ∈ B(i), the subproblem can be regarded
as a neighbor of the ith subproblem.
In the ith pass of the loop in Step 2, the T neigh-
boring subproblems of the ith subproblem are consid-
ered. Since xk and xl in Step 2.1 are the current best
solutions to neighbors of the ith subproblem, their off-
spring y should hopefully be a good solution to the ith
subproblem. In Step 2.2, a problem-specific heuris-
tic is used to repair/improve y in the case when y in-
validates any constraints, and/or optimize the ith gte.
Therefore, the resultant solution y′ is feasible and very
likely to have a lower function value for the neighbors
of ith subproblem. Step 2.4 considers all the neighbors
of the ith subproblem, it replaces xj with y′ if y′ per-
forms better than xj with regard to the jth subproblem.
FV j is needed in computing the value of gte(xj|λj, z)
in Step 2.4.
Since it is often very time-consuming to find the ex-
act reference point z∗, we use z, which is initialized
in Step 1.4 by a problem-specific method and updated
in Step 2.3, as a substitute z∗ for gte in Step 2.4. The
external population EP, initialized in Step 1.1, is up-
dated by the new generated solution y′ in Step 2.5. In
the case when the goal in 12 is to minimize F (x), the
inequality in Step 2.3 should be reversed.
3.6.3 MOEA/D Modifications for Single Machine
Scheduling problems
To further improve the performance of MOEA/D,
some procedures of MOEA/D are modified. First of
all, it is arguable that which decomposition method
can be used in the MOEA/D. Miettinen [12] argued
that the weighted-sum approach is good at convex
problem while Tchebysheff approach is useful when
the problem is non-convex. As a result, although our
previous work showed that Tchebysheff approach out-
performed the weighted sum approach, it is still not
sufficient enough to conclude that Tchebysheff ap-
proach will perform better for the flowshop bench-
marks.
Secondly, the z index is applied as a substitute of z∗.
Hence, the value of z is apparently larger than or equal
to that of z∗ in the minimization problem and z doesn’t
guarantee a good lower reference value when the de-
composition method normalizes the objective values.
To provide a good approximation of thez, a parameter
α is introduced and each zi is multiplied by α if zi is
improved. The setting of α is configured by Design-
of-Experiment.
Finally, once a good solution is found in the
MOEA/D, the algorithm will replace its neighbor-
hood solutions immediately. When the solution is
very good, this new solution inevitably replaces all
neighborhood solutions. This procedure enhances the
convergence of the algorithm; however, it causes the
problem of degrading the diversity of the population
abruptly. Therefore, the genetic operators are not able
to generate different offsprings since all the solutions
are identical in the T neighbors. Therefore, this paper
sets the maximum number of replaced neighborhood
solution is 1 rather than be able to replace all neigh-
bors.
There are many crossover and mutation methods.
We utilize the two-point crossover and moving posi-
tion mutation for the Crossover procedure and the Mu-
tation procedure, respectively, because [15] found both
of them were the better approaches for these two ob-
jectives. It is noted that there is no improvement or re-
pair procedure applied in this multiobjective schedul-
ing study.
Finally, we present the extensive results of
MOEA/D and the proposed method to solve the single
machine scheduling with LE and PSD. It is intro-
duced in the next section.
8
Figure 2: Reference set, MOEA/D and Aneja-Nair
Method on sks525, sks625, and sks925
References
[1] Y. Aneja and K. Nair, “Scheduling jobs with
position-dependent processing times,” Manage-
ment Science, vol. 25, pp. 73–78, 1979.
[2] A. Bachman and A. Janiak, “Scheduling jobs
with position-dependent processing times,” Jour-
nal of the Operational Research Society, vol. 55,
no. 3, pp. 257–264, 2004.
[3] U. Bagchi, “Simultaneous minimization of mean
and variation of flow time and waiting time in
single machine systems,” Operations Research,
vol. 37, no. 1, pp. 118–125, 1989.
[4] D. Biskup, “Single-machine scheduling with
learning considerations,” European Journal of
Operational Research, vol. 115, no. 1, pp. 173–
178, 1999.
[5] D. Biskup and J. Herrmann, “Single-machine
scheduling against due dates with past-sequence-
dependent setup times,” European Journal of
Operational Research, vol. 191, no. 2, pp. 586–
591, 2008.
[6] D. Biskup and D. Simons, “Common due date
scheduling with autonomous and induced learn-
ing,” European Journal of Operational Research,
vol. 159, no. 3, pp. 606–616, 2004.
[7] G. Hardy, J. Littlewood, and G. Po´lya, Inequali-
ties. Cambridge University Press, 1988.
[8] C. Koulamas and G. J. Kyparisis, “Single-
machine scheduling problems with past-
sequence-dependent setup times,” European
Journal of Operational Research, vol. 187, no. 3,
pp. 1045–1049, 2008.
[9] W. H. Kuo and D. L. Yang, “Single machine
scheduling with past-sequence-dependent setup
times and learning effects,” Information Process-
ing Letters, vol. 102, no. 1, pp. 22–26, 2007.
[10] W. Kuo and D. Yang, “Minimizing the makespan
in a single machine scheduling problem with
a time-based learning effect,” Information Pro-
cessing Letters, vol. 97, no. 2, pp. 64–67, 2006.
[11] W. Lee, “A note on single-machine scheduling
with general learning effect and past-sequence-
dependent setup time,” Computers & Mathemat-
ics with Applications, vol. 64, no. 4, pp. 2095–
2100, 2011.
10
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                             年    月    日 
報告人姓名 陳世興  
 
 
服務機構 
及職稱 
南華大學電子商務管理學系 
助理教授 
 
     時間 
會議 
     地點 
June 5-8, 2009 
Trondheim, Norway during  
本會核定 
補助文號 
Bi-criterion Single machine 
scheduling problem with a 
past-sequence-dependent setup 
times and learning effect 
會議 
名稱 
 (中文) 2011 IEEE 演化式演算法研討會 
 (英文) 2011 IEEE Congress on Evolutionary Computation (IEEE CEC 2011) 
發表 
論文 
題目 
 (中文) 雙變數人造解基因演算法解決具整備時間之單機排程問題 
 (英文) Bi-Variate Artificial Chromosomes with Genetic Algorithm for Single 
Machine Scheduling Problems with Sequence-Dependent Setup Times 
附
件
三 
  
 
May 23, 2011 
 
 
 
Shih‐Hsin Chen, PhD 
Department of Electronic Commerce Management 
Nanhua University 
No. 55, Sec. 1, Nanhua Rd., Zhongkeng, Dalin Township 
62248 Chiayi County Taiwan (R.O.C.) 
 
Dear Dr. Chen: 
 
This letter is to invite you to attend the Congress on Evolutionary Computation 
2011 (CEC 2011) held from June 5 to 8, 2011 in New Orleans, U.S.A.  Complete 
information about the conference can be found at http://cec2011.org.  We 
understand that your passport number is                   . 
 
We  look  forward  to  your  presence  at  this  conference.    I  can  be  reached  on 
smithae@auburn.edu or 1‐334‐844‐1400. 
 
Sincerely, 
 
 
 
Alice E. Smith, Ph.D., P.E. 
Professor and Chair 
CEC 2011 Conference Co‐Chair 
 
Bi-Variate Artificial Chromosomes with Genetic
Algorithm for Single Machine Scheduling Problems
with Sequence-Dependent Setup Times
Shih-Hsin Chen
Department of Electronic Commerce Management
Nanhua University
Chiayi 62248, Taiwan (R.O.C.)
Email: shihhsin@mail.nhu.edu.tw
Min-Chih Chen
Institute of Manufacturing Engineering
National Cheng Kung University
Tainan, Taiwan (R.O.C.)
Email: cthunter@mail.wfc.edu.tw
Abstract—Artificial chromosomes with genetic algorithm
(ACGA) is one of the latest Estimation of Distribution Algorithms
(EDAs). This algorithm has been used to solve different kinds
of scheduling problems successfully. However, due to its proba-
bilistic model does not consider the variable interactions, ACGA
may not perform well in some scheduling problems, particularly
the sequence-dependent setup times are considered because a
former job influences the processing time of next job. It is
not sufficient that probabilistic model just captures the ordinal
information from parental distribution. As a result, this paper
proposes a bi-variate probabilistic model added into the ACGA.
The new algorithm is named extended artificial chromosomes
with genetic algorithm (eACGA) and it is used to solve single
machine scheduling problem with sequence-dependent setup
times in a common due-date environment. Some heuristics are
also employed with eACGA. The results indicate that the average
error ratio of eACGA is one-half of the ACGA. In addition,
when eACGA works with other heuristics, the hybrid algorithm
achieves the best solution quality when it is compared with
other algorithms in literature. Thus, the proposed algorithms
are effective for solving this scheduling problem with setup
consideration.
Keywords: ACGA, Bi-Variate EDAs, Scheduling Problems,
Sequence-Dependent Setup Times, Common Due-Date
I. INTRODUCTION
In our previous studies [6], [7], [8], [9], ACGA has been
applied for solving several scheduling problems. The main
characteristic of ACGA is to alternate the EDAs and genetic
operators in each generation. Because other EDAs [3], [14],
[19], [29], [27] do not use genetic operators, this feature
distinguishes ACGA with others. This approach is beneficial
for EDAs to have a diversified population [12] where GA-EDA
[23] used similar framework.
ACGA utilizes an univariate probabilistic model which
extracts parental distribution from previous search when EDAs
operator is responsible for generating offsprings. After that, the
univariate probabilistic model is used to sample new solutions
called the artificial chromosomes. From these remarkable prior
results, ACGA is able to provide a satisfactory results.
The univariate probabilistic model of ACGA assumed that
there are no dependencies between/among variables. How-
ever, some researches pointed out when variable interactions
exist, EDAs may employ the bi-variate or even the multi-
variate probabilistic models [5], [4], [14], [22]. Most important
of all, this research is going to study the single machine
scheduling problems with sequence-dependent setup time in
a common due date environment [28]. Because a prior job
influences the processing time of the next job, there exists
interactions between the jobs. Once ACGA is used to solve
this scheduling, we may not have a satisfactory result. A
new bi-variate probabilistic model together with the univariate
probabilistic model is adopted into the proposed algorithm.
The new algorithm is named extended artificial chromosomes
with genetic algorithm (eACGA). eACGA could have better
chance to capture more accurate parental distribution from
the two probabilistic models so that it could produce better
offsprings.
The organization of the paper is shown as follows: The
Section II indicates the importance of the studied scheduling
problems and its problem definition. We start to introduce
the details of eACGA in Section III. Section IV shows the
extensive comparisons with other algorithm in literature when
they are used to solve the studied scheduling problems. Finally,
we draw the conclusions in Section V.
II. THE BACKGROUND OF THE STUDIED SCHEDULING
PROBLEMS
This research discusses the single machine scheduling prob-
lems with sequence-dependent setup time in a common due
date environment. In addition, the objective is to minimize the
total earliness and tardiness cost. To point out the importance
of this studied scheduling problems, Section II-A presents the
literature survey and the problem statement. In Section II-B,
we further explain the model of the scheduling problem.
A. Review and Problem Statements
Single-machine scheduling problems are one of the well-
studied problems by many researchers. The application of
single machine scheduling with setups can be found in mini-
mizing the cycle time for pick and place (PAP) operations in
Printed Circuit Board manufacturing company [17]; in a steel
III. METHODOLOGY
In order to capture the information of variable interactions,
we take the bi-variate probability model into considerate as
well. That is, eACGA extends from the ACGA, which not only
collect the order information of the job in the sequence but
also the variable interaction of the jobs. As a result, eACGA
could extract the parental information by using the univariate
probability model and bi-variate probability model.
The following Section III-A explains the proposed algorithm
in detail. Because the univariate and bi-variate are the core of
EDAs, they are further explained in Section III-B.
A. The procedures of eACGA
The major procedures of eACGA include population initial-
ization, selection of better chromosomes, and then to decide
whether EDAs or genetic operators is ran. After that, a
replacement strategy is used and then to test the stopping
criterion. The framework of eACGA is depicted in Fig. 2.
Population: A set of solutions
Generations: The maximum number of generations
푂푃 (푡): Univariate Probabilistic model
퐷푃 (푡): Bi-variate Probabilistic model
푡 : Generation index
푘 : The execution of the EDA interval
푠푡푎푟푡푖푛푔퐺푒푛 : The generation at which the EDA will start to
run
1: Initialize Population
2: 푡← 0
3: Initialize 푂푃 (푡) and 퐷푃 (푡)
4: while 푡 < 퐺푒푛푒푟푎푡푖표푛푠 do
5: Selection / Elitism(Population)
6: if 푔 % 푘 == 0 푎푛푑 푡 > 푠푡푎푟푡푖푛푔퐺푒푛 then
7: 푂푃 (푡+1)←BuildUnivariateProbabilityModel(Selected
Chromosomes)
8: 퐷푃 (푡+1)←BuildBiVariateProbabilityModel(Selected
Chromosomes)
9: Learning
10: Sampling new solutions into Population
11: else
12: Crossover()
13: Mutation()
14: end if
15: EvaluateFitness (Population)
16: Replacement()
17: 푡← 푡+ 1
18: end while
Fig. 2. Algorithm1: MainProcedure of eACGA()
We describe the methods in the following steps.
Step 1: Initialization
We initialize the population which consists a number of
chromosomes in Line 1. A chromosome represents a process-
ing sequence for the scheduling problem. Each chromosome
is generated randomly. In order to improve results, some
researches use heuristic to generate better initial solutions in
this step. For example, dominance properties (DP) in [10] for
this studied scheduling problem is considered to generate a
single chromosome in eACGA. Shortest Adjusted Processing
Time first(SAPT) is the other heuristic could initialize good
initial solutions. The two heuristics are employed to work with
eACGA and they are named eACGA퐷푃 and eACGA푆퐴푃푇 ,
respectively.
On the other hand, we also have to initialize the probabilistic
models used in eACGA in Line 3. No matter the univariate or
the bi-variate probabilistic models, each 푃푖푗(푡) is initialized
to be 1푛 , where 푛 is the number of jobs and 푃푖푗(푡) is the
probability of job 푖 in position 푗 in a promising solution.
Step 2: Selection and Elitism Strategy (Line 5)
Evolutionary algorithms attempt to select fitter solutions
corresponding to their objective values. The selection operator
chooses better chromosomes to be survived. For the purpose of
simplicity, the binary tournament operator is employed, which
selects the better chromosomes with lower objective values
in this minimization problem. In order to preserve elites in
the population, a proportion of better chromosomes are stored
in an external archive and to be copied into the mating pool
during the selection stage.
Step 3: Decision (Line 6)
There are two parameters control whether the EDAs or
GAs is ran, which are 푠푡푎푟푡푖푛푔퐺푒푛 and 푖푛푡푒푟푣푎푙. The first
parameter 푠푡푎푟푡푖푛푔퐺푒푛 is to determine the starting time of
generating artificial chromosomes. The main reason is that
the probabilistic model should be only applied to generate
better chromosomes when the searching process reaches a
more stable state.
The other important parameter 푖푛푡푒푟푣푎푙 sets the period of
artificial chromosomes generated. 푔 % 푘 represents that 푔
mod 푘. When the resultant value is 0, it means the current
generation reaches the 푘 interval. As a result, the algorithm
alternates EDAs and genetic operators in the whole evolution-
ary progress. When we like to execute the EDAs, constructing
the probabilistic models, the learning of parental distribution,
and then samples new offsprings from probabilistic models.
They are described in Step 4.1.1 to Step 4.1.3. On the other
hand, genetic operators contain the crossover and mutation
operator which are Step 4.2.1 and Step 4.2.2, respectively.
Step 4: Variations
Step 4.1: eACGA Segment
Step 4.1.1: Modeling (Line 7 and Line 8)
The univariate probabilistic model and the bi-variate prob-
abilistic models are built while we run the EDAs. The former
one represents all jobs at different positions referring to the
frequency count of a job at the positions. The bi-variate prob-
abilistic model is similar to a container of interaction counters
which are blocking out the similar jobs in the sequences. Fuller
step by step detail will be presented in Section. III-B.
Step 4.1.2: Learning (Line 9)
As in PBIL [5], we update the two probabilistic models
in an incremental learning way. In addition, the learning
rate determines the importance of the current and historical
diversified artificial chromosomes. The first is the assignment
sequence for each position assigned in random sequence. The
second is proportional selection which is used to mitigate the
probability of job 푖 assigned to a position 푗. The third is zero
value transformation which is used to transform 0 into 1/푛 in
dependent probability when jobs do not have any interactions.
The assignment procedure is determined as follows:
푆: A set of shuffled sequence which determines the
sequence of each position is assigned a job.
Ω: The set of un-arranged jobs.
퐽 : The set of arranged jobs. 퐽 is empty in the beginning.
휃: A random probability is drawn from 푈(0, 1).
푖: A selected job by proportional selection
푘: The element index of the set 푆
1: 푆 ← shuffled the job number [1 . . . 푛]
2: 퐽 ← Φ
3: while 푘 ∕= Φ do
4: 휃 ← 푈(0, 1)
5: Select a job 푖 satisfies 휃 ≤ 푂푃푖푘 ×
퐷푃푖퐽(푘−1)/
∑
푂푃 (푖, 푘) × 퐷푃 (푖, 퐽(푘 − 1)), where
푖 ∈ Ω
6: 퐽(푘)← 푖
7: Ω← Ω∖푖
8: 푆 ← 푆∖푘
9: end while
IV. EXPERIMENT RESULTS
The testing instances are designed by [25] and the job size
of each instance includes 10, 15, 20 and 25. The property
of the processing time range contains low, median and high,
which are based on Uniform(10, 60), Uniform(10, 110) and
Uniform(10, 160), respectively. Each combination has 15
similar instances, the total number of instance is 180 (4*3*15)
and each instance is replicated 30 times for our proposed
algorithm and the compared Algorithms. In order to configure
the parameter settings, we utilized the DOE to select the best
setting of eACGA parameters. Table. I shows the parameters
setting of the eACGA experiment. We code the algorithm in
Java and to be ran on Windows 2003 server (Intel Xeon 3.2
GHZ).
TABLE I
푒ACGA PARAMETERS SETTING
Factor Default
Crossover Rate 0.5
Mutation Rate 0.3
Starting generation 0
Interval 2
Ordinal probability learning rate 0.1
Dependent probability learning rate 0.5
Population Size 100
Generations 1000
In order to evaluate the performance of eACGA, they are
compared with some algorithms in literature. We divide these
algorithms into two groups which are stand-alone algorithms
and hybrid algorithms. To test the efficiency of our proposed
eACGA against the stand-alone algorithms, we compare the
SGA [26], ACGA [11] and SAPT [24]. We also select some
hybrid algorithms, such as SGA퐷푃 [10], ACGA퐷푃 [11] and
SA푆퐴푃푇 [24]. In addition, when eACGA works with two
heuristic algorithms DPs [10] and SAPT [24], they are called
eACGA퐷푃 and eACGA푆퐴푃푇 , respectively. Because DPs and
SAPT generate good initial solutions, eACGA takes these
solutions as the initial population. The brief information of
these algorithms is discussed as follows:
∙ SGA [26]: A standard genetic algorithm with elitism
strategy. The genetic operators include binary tournament
selection, two-point central operator and swap mutation
operator. During the selection stage, 10% of elites in the
population are reserved to the next generation. We use
the data from [10] for comparison.
∙ ACGA [11]: We mentioned that ACGA does not consider
the dependencies between/among variables. When ACGA
is used to solve the benchmark problems in this study, we
could distinguish the performance difference when we
employ the bi-variate probabilistic model together with
the univariate probabilistic model.
∙ SGA퐷푃 [10]: Dominance properties (DPs) were devel-
oped by swapping the neighborhood jobs. The DPs are
very efficient when combined with the GA. We take the
results from [10] for comparison.
∙ ACGA퐷푃 [10]: According to the research of ACGA [11]
and DPs [10], we combine both algorithms to solve the
single machine scheduling problems with setup costs.
DPs are utilized to generate a set of good initial solutions.
ACGA takes the advantage of these good initial solutions
and then continue the evolutionary progress. We expect
ACGA퐷푃 could perform better than ACGA.
∙ SAPT [24]: Shortest Adjusted Processing Time
first(SAPT) is based on a concept: Jobs with shorter
adjusted processing times to be scheduled, which shall
closer to the median position in an optimal job sequence.
They also combined SAPT with simulated annealing
(SA) algorithm, called SAPT-SA. Since the presented
data of SAPT-SA [24] is not completed and termination
condition is different from our experiments, we only
used the SAPT data from [24] for comparison.
To compare the performance of these algorithms clearly,
we employs the average relative error ratio. In literature,
the average relative error ratio is often used to evaluate the
performance of algorithms, whereby the error ratio (ER푖) of
a solution (푋푖) generated by an algorithm is calculated as
follows:
퐸푅푖 =
푂푏푗푎푣푔(푋푖)−푂푝푡푖
푂푝푡푖
∗ 100, (16)
Where 푂푝푡푖 is the objective value of the best known or op-
timal solution which is available by [28] who applied Branch-
and-Bound algorithm to derive the solution. The Obj푎푣푔(X푖) is
the 푋푖 average objective value. Table II showed the statistics
TABLE II
AVERAGE ERROR RATIO EVALUATION OF ALGORITHMS
Without hybridization With hybridization
Type Size SGA ACGA SAPT eACGA SGA퐷푃 ACGA퐷푃 eACGA퐷푃 eACGA푆퐴푃푇
low
10 0.86 0.63 2.55 0.27 0.31 0.28 0.18 0.11
15 4.21 4.05 3.59 1.85 3.13 2.93 1.40 0.77
20 9.58 8.83 3.13 3.97 6.85 6.98 3.66 1.80
25 13.18 11.81 3.21 6.10 9.44 9.55 5.15 2.06
med
10 1.89 1.29 2.80 0.18 0.93 0.94 0.26 0.36
15 7.86 6.84 5.33 3.11 4.74 4.69 2.30 0.89
20 13.93 12.53 3.93 5.74 10.06 9.86 4.90 2.25
25 20.80 18.83 5.96 9.55 14.83 15.32 8.56 4.26
high
10 1.37 1.16 2.80 0.04 0.54 0.62 0.00 0.13
15 9.70 9.35 8.22 3.42 6.38 5.66 2.44 0.69
20 21.04 18.18 5.95 7.78 13.94 13.55 6.62 3.70
25 27.88 24.74 6.83 13.09 20.22 19.78 10.88 4.84
Avg 11.03 9.85 4.53 4.59 7.61 7.51 3.86 1.82
TABLE III
AVERAGE CPU TIME EVALUATION OF ALGORITHMS
Without hybridization With hybridization
Type Size SGA ACGA SAPT eACGA SGA퐷푃 ACGA퐷푃 eACGA퐷푃 eACGA푆퐴푃푇
low
10 0.26 0.39 0.01 0.70 0.39 0.57 0.98 0.77
15 0.31 0.47 0.03 1.18 0.46 0.71 1.42 1.25
20 0.37 0.56 0.07 1.85 0.54 0.90 2.06 1.96
25 0.43 0.65 0.18 2.60 0.63 1.09 2.79 2.79
med
10 0.26 0.39 0.02 0.72 0.38 0.57 0.98 0.77
15 0.31 0.47 0.04 1.18 0.46 0.71 1.42 1.25
20 0.37 0.56 0.06 1.86 0.55 0.89 2.06 1.96
25 0.43 0.66 0.12 2.60 0.63 1.09 2.79 2.76
high
10 0.26 0.39 0.07 0.73 0.38 0.57 0.98 0.77
15 0.31 0.46 0.11 1.18 0.46 0.72 1.42 1.25
20 0.37 0.56 0.13 1.86 0.54 0.89 2.06 1.95
25 0.43 0.65 0.18 2.60 0.63 1.09 2.79 2.75
AVG 0.34 0.52 0.09 1.59 0.50 0.82 1.81 1.69
[21] P. S. Ow and T. E. Morton, “The Single Machine Early/Tardy Problem,”
Management Science, vol. 35, no. 2, pp. 177–191, 1989.
[22] M. Pelikan, D. E. Goldberg, and E. Cantu-Paz, “BOA: The Bayesian
optimization algorithm,” Proceedings of the Genetic and Evolutionary
Computation Conference GECCO-99, vol. 1, pp. 525–532, 1999.
[23] J. Pen˜a, V. Robles, P. Larran˜aga, V. Herves, F. Rosales, and M. Perez,
“GA-EDA: Hybrid Evolutionary Algorithm Using Genetic and Estima-
tion of Distribution Algorithms,” Innovations In Applied Artificial Intel-
ligence: 17th International Conference on Industrial and Engineering
Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2004,
Ottawa, Canada, May 17-20, 2004: Proceedings, 2004.
[24] G. Rabadi, G. Anagnostopoulos, and M. Mollaghasemi, “A heuristic
algorithm for the just-in-time single machine scheduling problem with
setups: a comparison with simulated annealing,” The International
Journal of Advanced Manufacturing Technology, vol. 32, no. 3, pp. 326–
335, 2007.
[25] G. Rabadi, M. Mollaghasemi, and G. Anagnostopoulos, “A branch-and-
bound algorithm for the early/tardy machine scheduling problem with
a common due-date and sequence-dependent setup time,” Computers &
Operations Research, vol. 31, no. 10, pp. 1727–1751, 2004.
[26] C. R. Reeves, “A genetic algorithm for flowshop sequencing,” Comput-
ers and Operations Research, vol. 22, no. 1, pp. 5–13, 1995.
[27] R. Santana, P. Larran˜aga, and J. Lozano, “Combining variable neighbor-
hood search and estimation of distribution algorithms in the protein side
chain placement problem,” Journal of Heuristics, vol. 14, pp. 519–547,
2008.
[28] F. Sourd, “Earliness–tardiness scheduling with setup considerations,”
Computers and operations research, vol. 32, no. 7, pp. 1849–1865, 2005.
[29] Q. Zhang, J. Sun, and E. Tsang, “An Evolutionary Algorithm With
Guided Mutation for the Maximum Clique Problem,” Evolutionary
Computation, IEEE Transactions on, vol. 9, no. 2, pp. 192–200, 2005.
99 年度專題研究計畫研究成果彙整表 
計畫主持人：陳世興 計畫編號：99-2221-E-343-002- 
計畫名稱：求解具有與過去順序相依準備時間以及學習效應之雙目標單機排程問題之研究(I) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
