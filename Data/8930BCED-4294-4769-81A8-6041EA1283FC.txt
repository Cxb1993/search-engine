 2
應用於分層影像傳輸的最佳化快取空間配置 
計畫編號: NSC 95-2221-E-110 -052 -MY2 
執行期間: 95 年 8 月 1 日 至 97 年 7 月 31 日 
主持人：李宗南   國立中山大學資訊工程系 
 
一、中文摘要 
 
這個計劃討論了 layered video 如何有效地從
伺服端，經由快取伺服器，傳迗到多個異質性和
非同步的客戶端。客戶端可以是不同的裝置，這
些裝置根據他們的特性和能力，要求不同層級的
video 品質。如果 cache 較高層級的 video，不僅
可以節省這個層級要求的傳輸成本，也可以節省
來自較低層級要求的傳輸成本。我們提出最佳化
的前端快取配置，去決定 cache 那個層級以及
cache 多少長度，可以得到最少的總傳輸成本。
我們整合快取機制和互動傳輸機制，像是
batching 和 patching，去提出一些快取輔助的
layered video 傳輸機制。我們進行一系列的模擬
來證明所提出演算法的效能。目前已得到初步成
果並投稿至國際期刊審稿中，其他與本計畫所支
援之相關研究也穫得國際期刊接受。 
 
 
關 鍵 字 ： layered video ， 快 取 伺 服 器 ，
batching，patching。 
 
 
1. INTRODUCTION 
  Streaming media services, including on-line conferences, 
distance education and movie broadcasting, have recently 
become popular on the Internet. However, bridging the gap 
between rich multimedia contents and diverse devices 
remains a challenge. Rate-adaptive video should be provided 
in efficient approaches to satisfy diverse client profiles and 
network characteristics. Additionally, the high bandwidth 
requirements and long-lived nature of digital video 
complicate adaptation tasks. Scalable video technology and 
video transcoding are both attractive and practical approaches 
of adhering to such demand. To ensure efficient delivery, 
proxy cache is generally deployed to reduce the traffic 
between the content origin and the proxies, and to decrease 
the transmission cost by caching popular videos at a proxy. In 
addition, the reactive transmission scheme is another 
approach to reduce transmission cost. How to integrate these 
approaches to provide efficient video transmission becomes 
an important issue. 
  For reactive transmission schemes, e.g., batching, patching 
and stream merging, some previous works [2]-[6][19], have 
focused on employing multicast or broadcast connections to 
transmit a popular video to multiple asynchronous clients, 
thus reducing the server load and required network bandwidth. 
Each scheme has a server only to transmit the on-demand 
video, when client requests arriving. For the batching 
transmission scheme [2], those requests arriving close 
together are batched in time, and then the server multicasts 
the stream to clients who make the requests. For the patching 
or stream tapping scheme [3]-[5], the server initializes the 
entire video transmission sequentially for the first client, 
while later clients that obtain their future playback data by 
joining an ongoing multicast stream of the same video, with 
the clients only receiving the missing prefix via a separate 
unicast stream. For stream merging [6], all streams (prefix 
and complete) are delivered via multicast, and clients can join 
an earlier multicast stream. Eager et al. [19] analyzed the 
minimum required server bandwidth for any delivery 
technique that provides immediate real-time delivery to 
clients increases logarithmically as a function of the client 
request arrival rate, and proposed a delivery technique, called 
hierarchical multicast stream merging, that is close to 
achiving the minimum required server bandwidth over a wide 
range of client request rates. 
To enable efficient delivery, a proxy cache is typically 
deployed to lower the traffic between the content origin and 
the proxies, and to decrease the latency perceived by a user 
through caching popular objects at a proxy. Caching 
streaming media is more of a challenge than caching simple 
web objects, since streaming media has a larger object size. 
When considering video caching rather than web caching, the 
video objects may be partially cached onto the proxies, such 
as video staging [7][8], prefix caching [9] and selective frame 
caching [10]. Verscheure et al. [11] studied partial caching 
based on server scheduling. Zhang et al. [12] considered 
some video prefetching algorithms in which popular video 
objects are prefetched onto the proxies to reduce the WAN 
traffic. Lee et al. [13] adopted video summaries to cache the 
media stream. Rejaie et al. [14] developed a layered video 
caching mechanism to maximize the quality of popular 
streams delivered to interested clients. Ma et al. [15] designed 
a progressive video caching policy, in which each video is 
cached at several levels according to cached data sizes and 
required WAN bandwidths. Kangasharju et al. [25] proposed 
some heuristics to determine which videos and which layers 
in the videos should be cached 
 
 
 4
requested stream. 3) If it is cache hit (cache system has 
a match version), the cache system transmits the 
requested stream based on the proposed transmission 
scheme. 4) If it is transcoding hit (cache system has a 
more detailed version), the cache system transmits the 
more detailed stream to the transcoder for transcoding 
the more detailed version into the requested version. 5) 
If it is cache miss, the cache system forwards the 
request to the RTP/RTSP client module of the proxy. 6) 
Then, the client module builds a connection with the 
RTP/RTSP server module of the server to get the 
requested stream. Finally, the RTP/RTSP server module 
of the transcoding proxy that communicates with the 
RTP/RTSP client module of the devices to deliver 
multimedia content based on the proposed transmission 
scheme. If the video is encoded into multiple layers, 
rather than multiple versions, the request procedure is 
the same, except the transcoding process is not 
necessary and the proxy does not need to be 
transcoding-enabled. We assume that clients choose the 
appropriate number of encoding layers (or the 
best-match version) for their Internet access speed such 
that the client's local access network is not a bottleneck. 
 
Both of layered and multiple-version videos are 
studied in this work. In this layered video case, assume 
video objects have been encoded using layered 
(hierarchical) encoding techniques [23][24]. With 
layered encoding, each video object is encoded into a 
base layer and one or more enhancement layers. The 
base layer includes the most essential basic quality 
information. The enhancement layers provide quality 
enhancements. A specific enhancement layer can only 
be decoded if all corresponding lower layers are 
received. Therefore, an enhancement layer is useless for 
the client if the corresponding lower layers are not 
received. In this case, the proxy may simultaneously 
cache several layers of a video. In multiple-version case, 
the server has the video with multiple versions, and 
higher versions can be transcoded into lower versions. 
The proxy can transcode a higher version into a lower 
version to meet the clients’ requirements. Thus, the 
proxy only cache one version of a video to achieve 
better cache efficiency. 
This work employs a single server and a single proxy 
to verify the proposed schemes, which can be directly 
applied to multiple-proxy content distribution networks 
where the server adopts unicast connections to the 
proxies. Each proxy serves a group of clients which do 
not overlap, and the proxies do not interact with each 
other. 
Table 1 lists the key parameters used in analysis and 
simulation. 
Table 1 
Analysis and Simulation Parameters 
Parameters Definition 
N Number of videos 
Li Length of video i (sec) 
li Cached length of video i (sec) 
li,j Cached length of layer j of video i (sec) 
bi,j Bit rate of  version j of video i (kbps) 
Bi,j Bit rate of  layer j of video i (kbps) 
u Caching grain (kbits) 
ni,j Size of version j of video i (units)  
fi Access probability of video i 
pj Access probability of version j 
Ai,j Access rate of simultaneously accessing 
layers 1- j of video i 
λi,j Access rate of version j of video i 
λ Aggregate request arrival rate 
S Proxy cache size (units)  
vi Cached version of video i 
cs Transmission cost on server-proxy path 
(per bit) 
cp Transmission cost on proxy-client path 
(per bit) 
Ci,j(li,j) Transmission cost per unit time for layer j 
of video i when a length li,j seconds prefix 
of layer j of video i is already cached at 
the proxy 
Ci(vi, li) Transmission cost per unit time for all 
versions of video i when a length li 
seconds prefix of version vi of video i is 
already cached at the proxy 
Assume that a server has a repository of N 
constant-bit-rate (CBR) videos as in [1]. Each video has 
R versions. The higher versions can be transcoded into 
lower versions. Additionally, suppose that the access 
probabilities of each version of all videos and the 
aggregate access rate to the video repository are known 
as a priori. These parameters can be obtained by 
monitoring a real system. Let fi denote the access 
probability of video i, , which is a measure 
of the relative popularity of a video. Let pj denote the 
access probability of version j, , which is 
dependent on the client device distribution (e.g. 
notebooks tend to request higher versions with better 
quality, while PDA tends to request lower versions). 
The access probability of version j of video i is 
∑
=
=
N
i
if
1
1
j
1
1
=∑
=
R
jp
ji pf × . Let ji,λ  denote the access rate of version j 
of video i, and λ  represent the aggregate access rate 
to the video repository. Thus, ji,λ = 
.R1 , jN ≤1 i ,p jfi ≤≤≤××λ  
The smallest unit of cache allocation is a caching 
grain of size u kbits, and all allocations are set to 
multiples of this unit. The size of video i and the proxy 
cache size is a multiple of a caching grain. Assume that 
version j of video i has playback bandwidth bi,j kbps. 
Version j of video i has size ni,j units and length Li 
seconds, and n ijiji Lbu ,, = . Assume that the proxy can 
store S units, also is S×u kbits. The storage vector Sv = 
(l1,l2,…, lN) specifies that a length li seconds prefix of 
video i is cached at the proxy, i=1,2,…,N. The version 
 6
video that minimizes the aggregate transmission cost. 
These transmission schemes are general and are 
applicable to any client arrival process. A Poisson 
arrival process, which is a conservative assumption for 
reactive schemes [19], is adopted to estimate the 
transmission costs. Wang et al. [1] proposed three 
schemes: (1)SBatch utilizes the video prefix cached at 
the proxy, so that multiple requests share a single 
server-to-proxy transmission to save transmission costs. 
(2)UPatch employs patching for the suffix.  
∑∑∑ ==
=
+×
+
−= ii
i
i
v
k
kikiip
v
k
kiv
k
kii
viiis
iii bLc
l
blLc
lvt
1
,,
1
,
1
,
,
1
)(
),(1cos λλ
λ
                                     
If requested version k is higher than the cached 
version vi, the proxy must immediately request an entire 
version k of video i from the server to proxy, and the 
transmission cannot be shared. In this case, the 
transmission cost per unit time for delivering version 
k(k>vi) of video i is formulated as follows.  (3)MPatch exploits prefix caching at the proxy under a multicast-enabled proxy-to-client environment. Though 
these schemes perform well for the single version or 
layer video, the multiple-version videos or layered 
videos and heterogeneous clients have not been 
considered. Therefore, new schemes are proposed here 
for multiple-version video and layered video 
transmission. In this work, the server-to-proxy path and 
proxy-to-client path are only unicast-enabled, the 
multicast-enabled proxy-to-client path is not considered 
since the transmission bottleneck is mainly from the 
WAN (Server-to-proxy path). However, it is expected 
that if proxy-to-client is multicast-enabled, the 
transmission cost can be further reduced. In addition, we 
assume that clients always request playback from the 
beginning of a video, as in [1].  
∑
+=
+=
R
vk
kikiipsiii
i
bLcclvt
1
,,)(),(2cos λ  
In summary, when the length li seconds prefix of 
version vi of video i is already cached at the proxy, the 
transmission cost per unit time for all versions of video i 
is as follows. 
Ci(vi,li) = + .  ),(1cos iii lvt ),(2cos iii lvt
 
 
4.1 Version-dominated Batching (VBatch) 
VBatch is proposed for multiple-version video 
transmission. Suppose that the first request for version k 
(k ≤ vi) of video i arrives at time 0. The length li seconds 
prefix of version vi of video i is already cached at the 
proxy. For these requests arrive in time (0,li] and 
requested versions are equal to or lower than the cached 
version vi, the proxy immediately start transcoding the 
cached version into these requested versions and 
transmitting the prefix of requested versions of video i 
to the clients as illustrated in Fig. 2. VBatch schedules 
the transmission of the suffix of version vi from the 
server to the proxy as late as possible, just in time to 
guarantee continuous playback for the clients. That is, 
the first frame of the suffix of version vi is scheduled to 
reach the proxy a little earlier than time li, which is the 
length of the prefix of version vi. Then, the proxy 
transcoding the version vi suffix into these requested 
versions and simply forwards these suffixes of 
requested versions (of length Li-li) to these requested 
clients, and no new suffix transmission is required from 
the server. Multiple requests for the suffix of video i are 
thus batched together. Note that though the first 
requested version is k (k ≤ vi), the version vi suffix, 
rather than version k,  is transmitted from server to 
proxy, since version vi can be transcoded into version k 
and can be shared by later requests for equal to or lower 
than version vi. Thus, the average transmission cost per 
unit time for delivering version k (k ≤ vi) of video i, 
based on a Poisson arrival process, is given by  
Fig. 2. Version-dominated batching with prefix caching 
(VBatch) 
 
4.2 Version-dominated Patching(VPatch) 
This section presents a VPatch scheme that utilizes 
patching for multiple-version video transmission. 
Suppose that the first request for version k (k ≤ vi) of 
video i arrives at time 0, the length li seconds prefix of 
version vi of video i is already cached at the proxy, and 
the version vi suffix reaches the proxy from the server a 
little earlier than time li as illustrated in Fig. 3. For these 
requests arrive in time (0, li] and requested versions are 
equal to or lower than the cached version vi, the 
transmission scheme is the same as the VBatch scheme. 
In another case, suppose that later request for version k 
(k ≤ vi) of video i occurs at time t2, li<t2<Li. The proxy 
can schedule a transmission of the complete suffix of 
version vi at time t2+li from the server. Alternatively, a 
patch of [li, t2) of the version k suffix can be scheduled 
 8
 
the request rate of layer j of video i is .  ∑
=
R
jk
kiA ,
Through such a transformation, the calculation of the 
transmission cost for each layer of the videos is similar 
to that of the transmission cost for each video object in 
[1].  
 
5.1 Layer Batching (LBatch) 
LBatch is proposed for layered video transmission. 
Suppose that the first request for layer j of video i 
arrives at time 0. The length li,j seconds prefix of layer j 
of video i is already cached at the proxy. The proxy 
immediately starts transmitting the prefix of layer j of 
video i to the client as illustrated in Fig. 4. LBatch 
schedules the transmission of the suffix of layer j from 
the server to the proxy as late as possible, just in time to 
guarantee continuous playback at the client. That is, the 
first frame of the suffix is scheduled to reach the proxy 
a little earlier than time li,j, which is the length of the 
prefix. When later requests for layer j of video i arriving 
in time (0, li,j] as shown in Fig. 4, the proxy simply 
forwards data from the single incoming layer j suffix (of 
length Li-li,j) to the new client, and no new suffix 
transmission is required from the server. Multiple 
requests for the suffix of layer j of video i are thus 
batched together. The average transmission cost per unit 
time for delivering layer j of video i, based on a Poisson 
arrival process, is given by  
Fig. 4. Layer batching with prefix caching (LBatch) 
 
5.2 Layer Patching(LPatch) 
∑∑ =
=
×+
+
−=
R
jk
kijiipR
jk
kiji
jiis
jiji AbLc
Al
lLc
lC ,,
,,
,
,, )
1
)(
()( ,             
This section presents an LPatch scheme that utilizes 
patching for layered video transmission. Suppose that 
the first request for layer j of video i arrives at time 0, 
the length li,j seconds prefix of layer j of video i is 
already cached at the proxy, and the suffix reaches the 
proxy from the server a little earlier than time li,j as 
illustrated in Fig. 5. For these requests of layer j of 
video i arrive in time (0, li,j], the transmission scheme is 
the same as LBatch scheme. Suppose that later request 
for layer j of video i occurs at time t2, li,j<t2<Li. The 
proxy can schedule a transmission of the complete 
suffix of layer j at time t2+li,j from the server. 
Alternatively, a patch of [li,j, t2) of the layer j suffix can 
be scheduled from the server, since segment [t2, Li] of 
layer j has already been scheduled to be transmitted and 
can be shared by the layer j request. The decision to 
transmit a complete suffix or a patch depends on a 
suffix threshold Gi,j, measured from the beginning of the 
suffix. If one request for layer j arrives within Gi,j from 
when the nearest complete transmission of the layer j 
suffix was started, then the proxy schedules a patch 
from the server for it. Otherwise, a complete 
transmission of the layer j suffix is started. The suffix 
threshold Gi,j is chosen to minimize the transmission 
cost. Assuming a Poisson arrival process, the average 
transmission cost per unit time for delivering layer j of 
video i is given by 
where  denotes the request rate of layer j of 
video i.  
∑
=
R
jk
kiA ,
Thus, the average transmission cost per unit time for 
delivering video i, based on a Poisson arrival process, is 
. ∑
=
R
j
jiji lC
1
,, )(
∑∑
∑
=
=
=
×+
++
−+
=
R
jk
kijiip
jiji
R
jk
ki
jii
R
jk
jiki
sjiji AbLc
GlA
lL
GA
clC ,,
,,,
,
2
,,
,, )
)(1
)(
2()(
,  
 10
of σ rises, the accesses become more evenly distributed 
among different versions, and required server 
bandwidth increases, since the limited cache space can 
not accommodate all popular objects when the accesses 
are dispersed. As the value of σ rises, the required 
bandwidth of batch-based schemes increases more than 
that of patch-based schemes. This is because that the 
patch-based schemes can dynamically tune up the 
threshold G according to access patterns to minimize the 
required server bandwidth.  
0
50
100
150
200
250
300
10 20 30 40 50 60 70 80 90
Proxy cache size
(% of total sizes of all minimal versions)
R
eq
ui
re
d 
se
rv
er
 b
an
dw
id
th
(M
B
/s
)
VBatch
VPatch
LBatch
LPatch
Original
 
0
50
100
150
200
250
300
0.2 0.4 0.6 0.8 1 1.2 1.4
R
eq
ui
re
d 
se
rv
er
 b
an
dw
id
th
(M
B
/s
) VBatch VPatch
LBatch LPatch
Original
  
Fig. 6. Required server bandwith ersus access patter
.2 The Impact of Proxy Cache Size 
er bandwidth of 
tra
Fig. 7. Required server bandwidth versus proxy cache 
size when λ=100/min. 
 
 
 
6.3 The Impact of Arrival Rate  
Figure 8 illustrates the required server bandwidth of 
transmission schemes as the arrival rate increases from 
10 to 100 requests/min where the cache size is 20% of 
total size of all minimal versions and the value of σ is 
set to be 1.4. Comparing the patch-based schemes with 
the batch-based schemes, the gap significantly increases 
as the arrival rate rises. When the arrival rate is 10 
request/min, the LPatch and VPatch schemes need, 
respectively, 53.5% and 65.1% of required bandwidth of 
LBatch and VBatch. When the arrival rate is 100 
requests/min, the required bandwidth of the LPatch and 
VPatch schemes become 34.7% and 29.6% of that of 
LBatch and VBatch, respectively. This finding clearly 
demonstrates that using patch-based schemes can save 
more bandwidth than batch-based schemes as the arrival 
rate increases. Also, in this experiment, the layered 
video transmission schemes still outperform the 
multiple-version transmission schemes regardless of 
arrival rates. 
σ 
 v n 
when λ=100/min. 
 
6
Figure 7 depicts the required serv
nsmission schemes under various cache sizes when λ 
= 100 requests/min, and the value of σ is set to be 1.4. 
The required bandwidth of patch-based schemes is 
clearly lower than that of batch-based schemes over all 
the range of proxy cache sizes. The patch-based 
schemes can save much bandwidth even if the cache 
size is very small. For example, when cache size = 10% 
of total sizes of all minimal versions, the VPatch and 
LPatch schemes only need 20% and 16.2% of the 
original bandwidth. The required bandwidth reduction is 
significantly less for the patch-based schemes than that 
of the batch-based schemes as the cache size increases. 
Thus, increasing cache size is more beneficial when 
adopting the batch-based transmission schemes. For 
instance, when cache size = 10% of total sizes of all 
minimal versions, the VBatch and LBatch schemes need 
77.1% and 55.3% of the original bandwidth. However, 
when cache size = 90% of total sizes of all minimal 
versions, they only need 33.1% and 21.7% of the 
original bandwidth. In addition, in this experiment, the 
layered video transmission schemes still outperform the 
multiple-version transmission schemes regardless of 
cache sizes. 
0
50
100
150
200
250
300
10 20 30 40 50 60 70 80 90 100
Arrival rate(per minute)
R
eq
ui
re
d 
se
rv
er
 b
an
dw
id
th
(M
B
/s
)
VBatch
VPatch
LBatch
LPatch
Original
 
Fig. 8. Required sever bandwidth versus arrival rate. 
 
6.4 The Impact of Version(Layer) Size 
  In this experiment, the impact of version size on 
required server bandwidth is examined. In the 
multiple-version case, the version size increases with an 
arithmetic progression instead of geometric progression 
 12
summarization,” Computer Communications, vol. 25, 
no. 4, pp. 424–435, Mar. 2002. 
[14] R. Rejaie, H. Yu, M. Handely, and D. Estrin, 
“Multimedia proxy caching mechanism for quality 
adaptive streaming applications in the internet,” in Proc. 
IEEE INFOCOM, Tel Aviv, Vol 2, pp. 980-989, Mar. 
2000. 
[15] W. Ma, and D. H. C. Du, “Design a progressive video 
caching policy for video proxy servers,” IEEE Trans. 
Multimedia, vol. 6, no. 4, pp. 599–610, Aug. 2004. 
[16] D. Eager, M. Ferris, and M. Vernon, “Optimized regional 
caching for on-demand data delivery,” in Proc. 
Multimedia Computing and Networking (MMCN ’99), 
San Jose, CA, Jan. 1999. 
[17] S. Sen, L. Gao, and D. Towsley, “Frame-based periodic 
broadcast and fundamental resource tradeoffs,” in Proc. 
IEEE Int. Performance Computing and Communications 
Conf., Phoenix, AZ, Apr. 2001. 
[18] D. Eager, M. Vernon, and J. Zahorjan, “Minimizing 
bandwidth requirements for on-demand data delivery,” 
IEEE Trans. Knowledge and Data Engineering, vol. 13, 
no. 5, pp. 742–757, Sept./Oct. 2001. 
[19] B. Shen, S. J. Lee, and S. Basu, “Caching strategies in 
transcoding-enabled proxy systems for streaming media 
distribution networks,” IEEE Trans. Multimedia, vol. 6, 
no. 2, pp. 375–386, Apr. 2004. 
[20] X. Tang, F. Zhang, and S.T. Chanson, “Streaming media 
caching algorithms for transcoding proxies,” in Proc. Intl 
Conf. on Parallel Processing, pp. 287 – 295, 2002. 
[21] S. Ramesh, I. Rhee, and K. Guo, “Multicast with cache 
(Mcache): an adaptive zero-delay video-on-demand 
service,” IEEE Trans. Circuits and Systems for Video 
Technology, vol.11, Issue 3, pp. 440 – 456, March 2001.  
[22] J. Kangasharju, F. Hartanto, M. Reisslein, and K. W. Ross, 
“Distributing Layered Encoded Video through Caches,” 
IEEE Transactions on computer, vol. 51, no. 6, pp. 622-636, 
June 2002. 
[23]P.J.Wu, C. N. Lee V. Gau, and J. N. Hwang, 
“ Overcoming Burst packet loss in Peer-to-Peer Live 
Streaming Systems”, IEEE International Symposium on 
Circuit and Systems, Seattle, USA, May 2008 
[24]Peng-Jung Wu and Chung-Nan Lee, 
“ Connection-Oriented Multi-Channel MAC Protocol for 
Ad-Hoc Network,” accepted to appear in Computer 
Communications 
 
 
表 Y04 
一、 會議經過 
本次參加 ISCAS 2008 是電路設計與系統一大盛會， 今年是由美國華盛頓
大學 在西雅圖舉行，會議時間分別從 5 月 18 日至 5月 21 日。本人於十八日抵
達西雅圖--塔科瑪機場。 
十九日為大會第一日早上有一場專題演講與兩個平行場次 ，下午有兩個場
次每個場次有11個平行 sessions，另外有論文張貼場次。早上專題演講由Dr. 
John R. Delaney主講，  演講主題為＂Engineering Challenges in an 
Environmental Renaissance: Real-time Interactions with a Dynamic Global 
Ocean from Anywhere on Earth＂ 。 Dr. John R. Delaney是華盛頓大學海洋
學院教授，演講主題是有關美國加州外海深海生態之觀測，目的則是呼籲與會
學者對海洋生態之關心，並希望海洋生態能溶入教育中 。本主題之計畫含蓋領
域相當廣， 計畫經費相當大，演講中也呈現很多精彩鏡頭包括特殊生物，海底
火山。   
    專題演講後， 本人挑選幾個有興趣的sessions來聹聽 ，包括多媒體分析
與品質評估 Encoder optimization, Picture coding hardware.  
 
第二日早上的場專題演講由, Dr. John Cohn主講，演講主題為＂ Kids these 
days - How we can inspire the next generation of Engineers and 
Scientists＂ Dr. John Cohn是 IBM Fellow演講主題是有關如何吸引孩童對工
程學科興趣， 演講內容生動有趣， 並配合做實驗 ，尤其在解釋導電就燒掉兩
隻黃瓜。 演講中也放Dilbert cartoon 中對工程師的刻板印象， 贏得滿場大
表 Y04 
二、 與會心得 
本次參加 ISCAS2008 感覺與會人士， 皆能很認真準備投影片與報告， 
很多場次皆由教授親自上場， 受益良多。由專題演講的安排， 大會相當注
重環保與教育，也是從事工程教育老師多思考之方向 。 
 
三、 考察參觀活動 
無 
四、 建議 
無。 
 
五、 攜回資料名稱及內容 
1. 大會光碟片與 IEEE 雜誌。 
 
六、 其他 
無。 
 
II. MULTI-SOURCE MULTICAST STRUCTURE
In this section, we present the proposed multi-source 
multicast structure combined with a distributed packet level 
FEC scheme for P2P video streaming. In the proposed 
structure, packets generated by the packet level FEC scheme 
are distributed by multiple sources. The benefit of multiple 
sources is that when one or few parents leave, other parents 
can still provide most remaining part of streaming video 
packets. In case that the number of leaving parents plus the 
number of dropped packets is smaller than the number of 
redundant FEC packets, all the missing packets can still be 
recovered by the FEC scheme. An example of packets 
recovery with three sources failed in an FEC(N=8,K=5)
system is shown in Fig. 1. Three redundant FEC packets are 
added every five information packets (these 8 packets 
altogether are called an ensemble). In this case, the FEC 
scheme is capable of recovering at most any three missing 
packets out of eight transmitted packets. Burst packets losses 
cannot be recovered only when more than three parents of the 
child peer leave the system at the same time. 
Figure 1. An example of packets recovery with three sources failed in 
FEC(N=8,K=5) system. 
Figure 2 shows an example of a 3-source multicast 
structure P2P system, in which each peer has three parent 
peers. Each parent peer is responsible for transmitting part of 
video streaming content (i.e., one packet per ensemble) to all 
its child peers subscribing to the same application-layer 
multicast (ALM) group. 
Figure 2. An example of three sources P2P video streaming system. 
III. PACKET LOSS PROBABILITY ANALYSIS
In this section, the analyses of packet loss probabilities of 
the multi-source multicast structures with the FEC(N,K)
scheme are presented. Consider an N-source multicast 
structure which employs the packet level FEC(N,K) scheme. A 
lost packet cannot be recovered by FEC only when less than a 
total of K packets are received from N transmitted packets. 
Since the video server never leaves the system, the probability 
that a packet is lost and cannot be recovered by FEC at depth 
1=D   can be derived as follows: 
 
»
»
¼
º
«
«
¬
ª
−¸¸¹
·
¨¨©
§ −
×= ¦
−
=
−−
=
1
0
1)1(
1
1
K
w
wNw dd
w
N
dQ
D
. (1) 
where d  denotes the probability that a packet was dropped 
during transmission. 
Different to peers at depth 1=D , peers at depth 1>D
receive packets from multiple parents. And the associated 
parents are transient, i.e., can leave any time. Let x  be the 
number of parents of a child peer have left and 
xD
q
,
 be the 
packet loss probability after recovery of depth 1>D  when x
parents of a child peer have left. xP  is defined as the 
probability that x  parents of a child peer have left the system. 
We can thus have the packet loss probability for the depth 
1>D  as follows: 
 ¦
=
×=
>
N
x
xDx qPQD
0
,1
. (2) 
To calculate xP , we model the behaviors of peers in a P2P 
system as a Continuous-Time Markov Chain (CTMC). 
Consider an N-source multicast structure, i.e., each peer has N
parent peers. Let S be the state of the CTMC representing the 
number of leaving parents of a peer. Suppose the potential 
time that a child peer needs to find a peer to replace a 
departure/failed parent peer has exponential distribution with 
mean μ/1 , and the time that a peer stays in the system 
(service time) has exponential distribution with mean λ/1 .
Assume that each time a parent peer departs; the child peer 
invokes a recovery process to find a peer for replacement; and 
multiple recovery processes can be performed simultaneously. 
The transition diagram of the system is shown in Fig. 3. 
μ μ2 μ3 μ4 μN
λ)3( −Nλ)1( −N λ)2( −N λλN
Figure 3. The transition diagram of the system. 
The balance equations for this system are 
3515
