 This research project was supported by National Science Council, Taiwan, R.O.C., under grant NSC 
95-2221-E-324-033, and has been completed successfully. The following research papers were published as a result 
of the research project, and they are listed below: 
1. Yuan-Liang Tang and Hui-Tzu Huang, "Multilayered High-Capacity Reversible Data Embedding," IASTED 
International Conference on Visualization, Imaging, and Image Processing, pp. 430-435, Palma de Mallorca, 
Spain, Aug. 28-30, 2006. 
2. Yuan-Liang Tang and Hui-Tzu Huang, "Robust Near-Reversible Data Embedding Using Histogram Projection," 
The 3rd Int. Conf. Intelligent Information Hiding and Multimedia Signal Processing, Kaohsung, Taiwan, Nov. 
26-28, 2007. 
 
very similar to the original and the image content can 
well be preserved. Such approaches are usually 
restrained in the capacity, but there is no need to embed 
the description information about the host image. 
In this paper, a novel Type-III reversible data 
embedding methods is proposed, in which exact 
recovery of the original host image is possible, very 
high embedding capacity is achievable, and the 
distortion of the image is within an acceptable range. 
The rest of this paper is organized as follows. Section 2 
explains the method of histogram stretching. Novel 
reversible data embedding and extraction methods 
based on histogram stretching are described in Sections 
3 and 4, respectively, followed by some preliminary 
experimental results shown in Section 5. The idea of 
multilayered embedding is described in Section 6, with 
experimental results illustrated in Section 7. And 
finally, Section 8 gives some concluding remarks. 
 
 
2. Histogram Stretching 
 
Contrast stretching, one of the histogram manipulations, 
tries to extend the narrow range of pixel values over a 
wider range in attempt to improve the contrast of an 
image. The stretched histogram contains many gaps, 
which are actually a missing set of particular intensities. 
Such missing intensities are used for data embedding in 
the proposed method. Fig. 1 illustrates an example of 
the idea of data embedding based on histogram 
stretching. Taking an image block as an example, the 
pixel intensities of the original histogram are stretched 
left and right one position from the peak value, 
respectively, hence creating the missing intensities. 
During data embedding, the image block is scanned in 
sequence. The pixel values associated with the 
histogram peak are kept intact, and the rest may be 
selected to embed the watermark. Fig. 1(a) shows the 
original histogram and Fig. 1(b) is the stretched version 
which contains a number of missing intensities. If the 
current watermark bit is “1”, the value of the pixel 
available for embedding is added or subtracted by “1”; 
otherwise, it is kept intact. For example, pixels of gray 
level 74 in Fig. 1(b) are available for embedding and 
gray level 75 is a missing intensity. While scanning the 
image block, if the current watermark bit is “1”, the 
pixel value 74 is added by 1; otherwise, nothing is done. 
Fig. 1(c) shows the pixel values after embedding, in 
which the number of pixels of gray levels 74 and 75 is 
equal to that of gray level 77 in the original image. The 
embedding capacity in this image block is the number 
of pixels available for embedding, i.e., the total number 
of pixels of gray levels 77, 78, 79, 81 and 82. 
 
 
 
Fig. 1: Data embedding by histogram stretching: (a) 
original histogram, (b) stretched version, (c) 
histogram after embedding. 
 
Based on the above reasoning, let b be the image 
block of size N×N and b(i, j) denotes the original pixel 
value at location (i, j), where 0 ≤ i, j ≤ N–1. The 
histogram stretching is defined as 
b' (i, j) = p + 2[b(i, j) – p] = 2b(i, j) – p, 
where b' (i, j) is the pixel value after stretching and p is 
the gray level with the highest count in the histogram. 
As grayscale values are bounded in range [0, 255], we 
have 0 ≤ b' (i, j) ≤ 255, which is equivalent to 
0 ≤ 2b(i, j) – p ≤ 255. To prevent the over/underflow 
problem (the range of shifted pixel values may be less 
than 0 or greater than 255) and the extreme value 
problem (intensity 0 or 255 exists), the pixel values in 
an image block must satisfy the following constraint: 
p/2 < b(i, j) < (p + 255)/2. 
In other words, if the pixel values satisfy the above 
condition, they could be stretched. On the contrary, 
pixels dissatisfying the above condition are stretched 
using the following equation instead without causing 
overflow or underflow: 



+>+=′
−<−=′
+≤≤−−=′
,),(  if  ,),(),(
,),(  if  ,),(),(
,),(  if  ,),(2),(
22
11
21
epjibejibjib
epjibejibjib
epjibeppjibjib
 
where e1 and e2 are the numbers of empty bins in the 
histogram from 0 to the minimum gray level and from 
the maximum gray level to 255, respectively. The 
number of the gray levels to be stretched will then be 
the number of the missing intensities clustered at one 
end of the histogram. 
If the range of grayscale values in the histogram 
covers the full possible set of values, straightforward 
histogram stretching will achieve nothing; that is, the 
histogram should have at least one gap on the left or 
right side of the peak in order to provide room for 
stretching. As a consequence, the block size should be 
carefully chosen (e.g., N < 16) in order to avoid the full 
coverage situation. For a natural image, however, the 
pixel values in an image block are usually within a 
(a) (b) (c)
77 80 82 74 80 84 74 80 84
Missing 
intensities 
Peak Peak
77 78 79
81
82
includes b''(i, j), and e1 and e2 are the original 
information which is decoded from A. Pixels 
satisfying the above condition are defined as in the 
embedding area of set E. 
(5) The watermark extraction also starts with scanning 
the image block, and then the watermark is 
extracted by 
wn = [b''(i, j) + p] mod 2. 
(6) The image restorer implements the difference 
translation according to the pixel value in L or R. 
For the pixels in the embedding area, the pixel 
values in L are restored by 


 +′′=
2
),(),( pjibjib , 
where b(i, j) is the restored pixel value, whereas 
the pixels in R would be restored by 


 +′′=
2
),(),( pjibjib . 
For the pixels not in the embedding area, the pixels 
in L and R are restored by b(i, j) = b"(i, j) + e1 and 
b(i, j) = b"(i, j) − e2, respectively. After all blocks are 
processed, the embedded watermark is extracted and 
removed from the received image, and the received 
image is restored to its original state. 
 
 
5. Preliminary Experimental Results 
 
The method described above was tested on various 
512×512 standard grayscale images, including F-16, 
Peppers, Lena, Boat, and Baboon. The images range 
from smooth images (e.g., F-16) to rough images (e.g., 
Baboon). The payload data is randomly generated. The 
relationship between the block sizes and the 
performance of the proposed algorithm is delineated in 
Fig. 2. 
C
ap
ac
ity
, b
pp
-
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
2 4 8 16 32
Block Size
F-16 Peppers Lena
Boat Baboon
 
Fig. 2: Relationship between capacity and block 
sizes. 
It is obvious that the proposed algorithm achieved a 
satisfactory and stable performance in terms of 
embedding capacity. All capacities are greater than 0.5 
bits/pixel (bpp), and the highest is 0.85 bpp. The bit 
rate difference at a same block size is always less than 
0.12 bbp, which means our method is relatively more 
stable than Celik’s method [3], in which the capacities 
for the best (F-16) and worse (Baboon) cases are 1.04 
and 0.17 bpp, respectively, with a difference of 0.87 
bbp. For smooth images (e.g., F-16), the capacity 
decreases slightly because there are lots of useless 
blocks. For rough images (e.g., Baboon), a great 
amount of data can be embedded. In addition, 
increasing the block size does not effectively increase 
the capacity, and a larger block size tends to produce 
lower image quality. Since each image block is 
stretched individually without considering the 
distribution of adjacent blocks, the block effect 
becomes apparent. The experimental results shown in 
Table 1 demonstrate that our method outperforms most 
of the existing techniques, except for Celik et al.’s 
method, in terms of the embedding capacity. However, 
it will be apparent from Section 6 that the embedding 
capacity could be made much higher using the 
multilayered embedding approach. The visual quality 
of the embedded images is shown in Figs. 3−5 for F-16, 
Lena, and Baboon, respectively. It is also obvious that 
the image quality is somewhat sacrificed for high 
embedding capacity. 
Table 1: Comparisons of embedding capacities. 
Approach Bit Rate (bpp)
Celik et al. [3] 
Tian [5] 
Xuan et al. [9] 
De Vleeschouwer et al. [11] 
Zhicheng et al. [12] 
Our method 
< 1.0 
< 0.5 
< 0.35 
< 0.06 
= 0.05 
> 0.5 
 
(a) (b) 
 
Fig. 7: The multilayered extraction process. 
Multilayered embedding is possible because of the 
fact that the redundancy in an already embedded image 
is still available and the original image can always be 
recovered exactly, provided the embedded image is not 
tampered with. During multilayered embedding, it is 
necessary to select the parameter pair (N, τ) at layer i, 
where N is the block size and τ is the embedding 
threshold. The parameter pair is regarded as a 
fixed-length header Hi. Fig. 8 illustrates the order of the 
embedding layer. 
 
Fig. 8: The relationship between the embedding 
layers and the headers. 
 
At the first embedding layer, H1 is set to 0 and it is 
combined with A1 and P1, where A1 is the reverse-aid at 
layer 1 and P1 is part of the payload, P. The watermark, 
W1, to be embedded at layer 1 becomes 
W1 = H1 ||A1 || P1. Following the same manner, the 
parameter pair, denoted by Hi+1, at layer i will be the 
header at layer i+1, and it will be combined with the 
payload to form the watermark Wi+1. The final header, 
Hf+1, will not be embedded into the image; it is 
transmitted along with the embedded image, Iw. During 
multilayered data extraction, the received Hf+1 is used 
to extract the watermark at the final embedding layer 
and to recover the image. In the same way, header Hi is 
used to extract the watermark at layer i−1. The data 
extraction and restoration process will continue until 
the header equals 0. The image will then be restored 
exactly the same as the original content if no tampering 
has ever occurred 
 
 
7. Experimental Results 
 
The performance of the multilayered method is 
compared against those of high-capacity and 
low-distortion algorithms, namely, the lossless G-LSB 
method [3] and the Difference Expansion method [5], 
as shown in Fig. 9. It is obvious that, in average, the 
proposed method outperforms the other two, in terms 
of both the embedding capacity and the quality of the 
embedded images. 
 
 
8. Conclusion 
 
In this paper, a novel multilayered data embedding 
algorithm for digital images is presented. The proposed 
technique is based on histogram stretching and uses 
multilayered approach to repeatedly embedded 
information into an image. It has the ability of 
recovering an embedded image to its original state and 
the embedding capacity is relatively high, compared 
with most of the existing methods. The proposed 
algorithm is very useful for applications that require 
high-quality images. 
 
 
0
0.2
0.4
0.6
0.8
1
1.2
1.4
20 25 30 35 40 45
PSNR (dB)
G-LSB DE Proposed
(a)
 
0
0.2
0.4
0.6
0.8
1
1.2
1.4
20 25 30 35 40 45
PSNR (dB)
G-LSB DE Proposed
(b)
 
Header, 
Hf+1 
Extracted header at ith 
embedding layer, Hi 
Received 
image, I'w 
Data Extraction 
and Image 
Restoration 
Restored image 
at ith lay r, I'i 
Hi = 0? 
No 
No 
Yes
Payload, P'
Restored 
image, I' 
000101010110
101011110001
010100000011
010001101001
001100010101
000110011100
000101010110
101011110001
010100000011
010001101001
001100010101
000110011100
Embedding Layer 1 
Embedding Layer 2 
Final Embedding 
Layer 
Original Image 
Header H1
Header H2
Header Hf 
00010101 1
10101111 0
01010000 1
010001101001
001100010101
000110011100
Robust Near-Reversible Data Embedding Using Histogram Projection 
 
 
Yuan-Liang Tang* and Hui-Tzu Huang 
Department of Information Management, Chaoyang University of Technology 
168, Jifong East Road, Wufong Township, Taichung County 41349, Taiwan (R.O.C.) 
*yltang@cyut.edu.tw 
 
Abstract 
 
Most data embedding techniques distort the original 
image as a side effect. To overcome such a problem, 
reversible data embedding is used to restore the original 
content after the removal of the embedded data. However, 
it is assumed that the embedded image is not altered and 
such a constraint is sometimes considered unnecessary 
because as long as the image can be restored to an 
acceptable level, moderate alteration on the embedded 
image should be allowed. Such a reasoning leads to a new 
category of techniques called near-reversible data 
embedding, in which the embedded image is allowed to be 
manipulated and the image can be restored to some extent 
that is very close to the original image. In this paper, a 
novel near-reversible data embedding algorithm is 
proposed based on projection histogram manipulations. 
The experimental results demonstrated that proposed 
algorithm performs very well in terms of embedding 
capacity, image fidelity, and robustness against common 
image processing operations. 
 
1. Introduction 
 
Data embedding techniques [1−6] attempt to 
imperceptibly embed one signal into another for the 
purposes of content protection, ownership assertion, data 
augmentation, etc. However, the embedding process 
usually introduces irreversible degradation of the original 
data, which is not tolerable for some applications that 
require high accuracy, for example, legal or medical images, 
remote sensing, media asset management, electronic 
diagnosis, etc. To solve such a problem, reversible data 
embedding techniques incorporate the property of 
reversibility, namely, it is possible to completely restore the 
image content after the removal of the embedded data. 
For some applications, however, exact restoration is 
sometimes considered too rigid and a new type of 
algorithms known as near-reversible data embedding is 
introduced, in which the embedded image is recovered to 
some extent that is very close to the original, but not exact. 
A number of researchers have tackled this problem; for 
instance, De Vleeschouwer et al. [5] reduced the 
salt-and-pepper visual artifact of Macq’s method by using a 
circular interpretation of the bijective transformations of 
the histogram used for the patchwork. The capacity of the 
algorithm depends on the size of the block used for the 
patchwork, and it is less than 10KB per image. Macq [7] 
extended Honsinger’s [8] and Bender et al.’s [9] methods 
for robust and reversible embedding. The algorithm suffers 
from a wrap-around effect that produces the 
salt-and-pepper visual artifact due to the modulo operation. 
In addition, each bit of the message is associated with a 
block in the image; the embedding capacity is thus 
dependent on the number of blocks and is very limited. 
Kalker et al. [10] also developed a robust reversible 
embedding technique based on error correction codes. 
In this paper, a novel near-reversible data embedding 
algorithm is proposed which is robust to common image 
processing operations. In addition, investigation is 
with its right neighbor, whereas if bit “1” is to be embedded, 
pixels at column pB of subblock B are swapped with its 
right neighbor. Figure 4 delineates such a situation, in 
which column pixels at 3 and 4 in subblock A are swapped 
to embedded “0”, and column pixels at 3 and 4 in subblock 
B are swapped to embed “1”. 
 
 
Figure 3. Block partition 
 
 
Figure 4. Embedding by swapping column pixels 
 
The detailed steps of the proposed algorithm are 
summarized in the following 
(1) Divide the original image into blocks of size N×N, 
where N is an even positive integer. 
(2) Partition each block into subblocks A and B according 
to the predefined partition pattern. And then pA and pB 
are computed. 
(3) If pA = pB, the block will be used for embedding; 
otherwise it is discarded. Let C(x) denote the set of all 
column pixels at position x in the projection histogram. 
To further ensure the condition of pA = pB, every pixel 
in C(pA) and C(pB) are added by τ1 for the purpose of 
increasing the embedding strength. 
(4) Perform data embedding:  


=+
=+
.1 if   ,1))(),((
,0 if   ,1))(),((
wpCpCswap
wpCpCswap
BB
AA  
In case pA and pB happen to be the rightmost 
position, the following is performed instead: 


=
=
,1 if   ,by    )(in    pixeleach    Add
,0 if   ,by    )(in    pixeleach    Add
2
2
wpC
wpC
B
A
τ
τ  
where τ2 is to enforce the logical relationship 
between SpA and SpB for the robustness purpose, where 
SpA and SpB are the sum of column pixel values at pA 
and pB, respectively. Note that, if the relationship 
between SpA and SpB can’t be enforced by adding τ2, 
the block is also discarded. This step is repeated until 
all payload bits are embedded or there is no more room 
for embedding 
 
5. Data Extraction and Image Restoration 
 
To extract the payload and restore the image, the 
following procedure is performed: 
(1) Repeat steps 1 and 2 of the data embedding algorithm 
on the received image. 
(2) If the block is useful (i.e., the assumption mentioned 
before is satisfied): if pA and pB are the rightmost 
position, extract the payload bit by 


=
>=
otherwise.    ,1
, if   ,0
w
SpSpw BA  
Otherwise, the payload bit is extracted by 


=
>=
otherwise.    ,1
, if   ,0
w
ppw BA  
(3) The image block is restored by first subtracting all 
pixels in C(pA) and C(pB) by τ1. And then, if pA and pB 
are at the rightmost position, the image block is 
recovered by 
Embed “1”:
Embed “0”:
Subblock A
Subblock A
Subblock B
Subblock B
pA =
pA =
pB =
pB =
P titi
Original 
S bbl k A S bbl k B
pB = pA = po = 
S bbl k A S bbl k B
Manipulation Robustness
Gaussian Blurring (0.1) Y 
Gaussian Blurring (0.2) Y 
Gaussian Blurring (0.3) N 
Sharpening (0.6) Y 
Sharpening (0.8) Y 
Sharpening (1.0) N 
JEPG compression (QF = 90%) Y 
JEPG compression (QF = 80%) N 
Noise addition (3%) Y 
Noise addition (4%) Y 
Noise addition (5%) N 
Brightness adjustment (10) Y 
Brightness adjustment (20) N 
Brightness adjustment (−10) Y 
Brightness adjustment (−20) Y 
Brightness adjustment (−30) N 
Contrast adjustment (10) Y 
Contrast adjustment (20) N 
Contrast adjustment (−40) Y 
Contrast adjustment (−60) Y 
Contrast adjustment (−80) N 
 
7. Conclusions 
 
We proposed a novel near-reversible data embedding 
algorithm in this paper. The algorithm is based on 
manipulating the projection histograms for data embedding. 
Because the projection histograms are relatively stable 
under common image operations, the attacked image can be 
restored to a level which is very close to the original image. 
The capacity of the method depends on the number of 
available image blocks because only one bit is embedded 
into one block. The experimental results indicate that the 
proposed algorithm is very robust against blurring, 
sharpening, JEPG compression, noise addition, and 
adjustment of brightness and contrast. Furthermore, the 
embedded payload can be robustly extracted. 
 
8. References 
 
[1] J. Fridrich, M. Goljan, and R. Du, “Invertible 
Authentication,” Proc. SPIE, Security and Watermarking of 
Multimedia Contents III, Vol. 3971, San Jose, California, 
2001, pp. 197−208. 
[2] J. Tian, “Reversible Data Embedding Using a Difference 
Expansion,” IEEE Trans. Circuits and Systems for Video 
Technology, 13(8), 2003, pp. 890−896. 
[3] J. Tian, “Reversible Watermarking by Difference 
Expansion,” Proc. ACM Workshop Multimedia and Security: 
Authentication, Secrecy, and Steganalysis, 2002, pp. 19−22. 
[4] A.M. Alattar, “Reversible Watermark Using the Difference 
Expansion of a Generalized Integer Transform,” IEEE Trans. 
Image Processing, 13(8), 2004, pp. 1147−1156. 
[5] C. De Vleeschouwer, J.E. Delaigle, and B. Macq, “Circular 
Interpretation of Bijective Transformations in Lossless 
Watermarking for Media Asset Management,” IEEE Trans. 
Multimedia, 5(1), 2001, pp. 97−105. 
[6] A. van Leest, M. van der Veen, and F. Bruekers, “Reversible 
Image Watermarking,” Proc. Int. Conf. Image Processing, 
Vol. 2, 2003, pp. 731−734. 
[7] B. Macq, “Lossless Multiresolution Transform for Image 
Authentication Watermark,” in Proc. EUSIPCO, Tampere, 
Finland, 2000. 
[8] C.W. Honsinger, P. Jones, M. Rabbani, and J.C. Stoffel, 
“Lossless Recovery of an Original Image Containing 
Embedded Data,” US Patent application, Docket No. 
77102/E−D, 1999. 
[9] W. Bender, D. Gruhl, N. Morinoto, and A. Lu, “Techniques 
for Data Hiding,” IBM Syst. J., 35(3-4), 1996, pp. 313−336. 
[10] T. Kalker and F.M.J. Willems, “Capacity Bounds and Code 
Constructions for Reversible Data-Hiding,” in Proc. 
Electronic Imaging, Security, and Watermarking of 
Multimedia Contents V, 2003. 
 
 
