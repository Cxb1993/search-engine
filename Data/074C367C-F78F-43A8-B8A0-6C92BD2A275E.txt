非監督式中文寫作自動評閱系統之研究 
An Unsupervised Chinese Automated Essay Scoring System 
計畫編號： 
執行期限：98 年 8 月 1 日至 99 年 8 月 31 日 
主持人：李嘉晃   國立交通大學資訊工程 
 
一、中文摘要 
    自動寫作評閱的研究，在自然語言中佔
了重要的一環，尤其是在中文研究上甚是艱
難，雖然陸陸續續已有評閱系統之研究產生，
但目前的系統皆只針對文章單一方面給分，
無法有效提供使用者在寫作技巧上哪方面較
微弱之資訊。因此本文提出一個非監督系統，
針對中文寫作評分不同面向，分別給予分數
以及分數的統整，除了給予使用者在立意取
材以及結構組織上的分數外，也根據使用者
所寫作的文章給予錯別字回饋的資訊。實驗
結果在不同面向上能有相當程度的正確率，
在分數統整上，正確率可達到 94%。此外錯
別字判斷的正確率能達到 72%，可作為老師
批閱或是學生寫作上的輔助工具。 
 
二、英文摘要 (Abstract) 
    The research of the automated essay 
scoring is important in the natural 
language, especially difficult in the 
Chinese research. Although some scoring 
systems have been proposed, all these 
systems only score the article one-way. 
They can`t provide which aspect in the 
article technique may strengthen to the 
user efficiently. Thus, the paper 
proposes an unsupervised system. This 
system could grade essays multi-face and 
give the information of misspell to the 
user. The adjacent rate in the overall 
experiment is about 94%, and in the 
misspell judgment is about 72%. 
 
三、計畫緣由與目的 
    各個國家的語言教育，皆脫離不了聽、
說、寫、讀這四個方面，而在這四個方面中，
尤其以“寫＂這一環最為重要，寫作不僅可
以培養一個人的表達能力、文學素養，甚至
可以激發、訓練一個人的組織與思考以及增
進創造、理解等能力。因此在各個語言教育
階段中，均重視語言寫作能力的訓練。 
但現階段的作文批閱的形式，皆需要耗
費大量的人力、物力以及時間，最重要的還
是批閱者的主觀不同，但除了批閱者的主觀
意識外，另一項重大的問題是批閱者如何在
長時間的作業下，還能維持一定的批閱標準。
因此單純利用人工來進行作文的批閱，很難
達到客觀以及公平性。 
在英語批閱研究中，自動作文評分
(Automated Essay Scoring ,AES)已經發展
許久，甚至已經應用在大行的語文考試中，
例如: Graduate Management Admission Test 
(GMAT）已使用E-rater作為批閱文章的輔助
工具[1]。而華語批閱研究中，也針對寫作上
由最初所提出的自動建構中文作文評分系統
[2]，到之後的貝氏[3]、SVM[4]、修辭[5]、
非監督式[6]、結構化[7]…等評分系統。 
 然而目前的中文系統無論是監督式評分
系統(指需要一定的篇數且已經過人工評定
分數的同一主題文章作為系統的訓練資料)
或者非監督式評分系統(無需訓練資料，僅需
一定數量的同一主題文章)，皆只針對單一個
面向來作評分，並不符合中文寫作的評分標
準上[8]所針對的主要四大面向立意取材、結
程，首先在3.1小節中，用ㄧ張系統架構圖來
了解系統整個運作的流程，圖中各個模組的
執行內容將在後續幾小節中做詳細的介紹。 
  
(一) 系統架構  
 
    本系統裡面共包含5個模組： 
1. 斷詞處理 
2. 特徵擷取-包含兩個部份:義元特徵、
結構化特徵 
3. 相似度(評分)系統 
4. 分數整合系統 
5. 錯別字系統 
當一定的文章數資料進入系統時，系統開始
運作。首先第一步對每篇文章進行斷詞的處
理，再經由特徵擷取取出每篇文章的義元特
徵與結構特徵當作後續相似度評分系統的評
分依據，藉由相似度內的投票演算法每個時
間修正評分的結果直到結果達到穩態為止，
在此階段結束後進入分數整合系統，即會根
據兩個方向所評出的分數、文章數進行訓練
找出ㄧ個最佳比例來進行整合。最後這些分
數會參考歷史資料的成績分配情況轉換成六
級分成績。文章在系統評出分數後也會根據
斷詞以及bigram資訊進行錯別字判斷。 
  
(二) 中文斷詞處理  
    斷詞在自然語言上是不可或缺的技術，
任何的系統只要是牽扯到語言的都必須先分
辨文章中的各個詞才能進行詞性標記、句法
分析、資訊擷取等進一步的處理。相對於英
文最顯而易見的差異，在於中文語法並沒有
空白隔開每一個詞。若斷詞結果不正確，容
易造成語意全然的不同，因此中文的自動斷
詞成為重要的工作。 
目前系統採用的斷詞法乃是長詞優先斷詞法，
雖然其正確率在現有的演算法中並不算最好，
但效果已達一定的水準，且系統進計算文章
間共同出現的材料，並不去探討文章語法，
因此對斷詞錯誤的會有較高的容忍度。 
在此利用一個簡單的例子說明此演算法: 
「 下 課 鐘 聲
響」.... .........................(1) 
這個句子可能的斷詞有下列數種詞組: 
「  ( 下 ) ( 課 ) ( 鐘 ) ( 聲 ) 
(響) 」..................(2) 
「  ( 下 課 ) ( 鐘 ) ( 聲 ) 
(響) 」.....................(3) 
「  ( 下 課 ) ( 鐘 聲 ) 
(響) 」........................(5) 
…… 
首先此演算法會針對字串中最長有意義的字
串進行判斷，因此先從(1)斷出(下課)，再由
剩餘的字串(鐘聲響)中斷出(鐘聲)以及(響)，
即為結果。  
 
(三) 詞語特徵 
    由於系統要針對文章立意取材以及結構
組織兩部份做評分，所以我們需要 
先擷取出所有文章在這兩部份的詞語特徵以
及結構特徵來當作相似度系統比較評分的依
據，再分別進行評分。因此我們在此小節以
及下一小節提到特徵如何擷取。 
首先針對詞語特徵的擷取，本系統中是利用
文章的義原來當作文章的詞語特 
徵，我們根據知網(HowNet)將所有文章中的
詞語轉化為義原。 
    在此利用一個簡單的例子說明轉化過程:
「大家的動作由緩慢轉變成快速」 
經過斷詞處理後，會變成: 
「 (大家) (的) (動作) (由) (緩慢) (轉變
 如此一來，我們就可以依據矩陣對稱格
內容得知兩個詞之間的關係，此部份我們會
在下小節提到。 
 
●概念圖  
    由 3.4.1 小節得到的詞語非對稱關係矩
陣，為了得知兩個詞語 wi、wj 從屬的情況，
經由觀察可得知當 ri,j 高於 rj,i，表在文
章中當wi 出現緊接著伴隨wj出現的機率頗
高；反之當 ri,j 低於 rj,i，表 wi 出現緊接
著伴隨 wj 出現的機率較低，因為 wi 也可能
跟別的詞出現。例如我們再 3.4 節中一開頭
所舉的例子，wi 為[合作社]；wj 為[麵包]；
ri,j 等於 0.5；rj,i 等於 1，得知當[合作社]
出現而[麵包]伴隨出現的機率為 0.5，有 0.5
會跟其他詞出現。因此[合作社]應該為[麵包]
的 superordinate。 
因此可根據下列演算法，建構出屬於此主題
的概念圖: 
Algorithm 1 : 建立概念圖演算法      
 
)()_(}
1__
,
1
;_
,,
1
{
0_
1
1
,
,
,
,,,
,,,
givenbeenhaswordiorthresholdlevelnowwhile
levelnowlevelnow
iallforprocessedathen
givenbeenhaswordofleveltheif
ntojfor
levelnowwordoflevelthethen
jallforprocessedncorrelatioteuperordinasaif
ntoifor
do
levelnow
ncorrelatioaelse
teuperordinasathenerrifelse
esubordinatathenerrif
ntojfor
ntoifor
i
ji
j
i
ji
ji
jiijji
jiijji













 
由上述演算法主要先標示陣列中每個詞的從
屬關係，接著判斷是否有一整列的陣列內容
皆不屬於 subordinate，表示這一列所代表
的詞是現階段層級最高的，於是標記
now_level ， 並 將 詞 所 對 應 的 行 標 示
processed，代表已處理過。此演算法會一直
做到所有詞語都被標記層級或者已經超過預
設的階層數。 
 
●擷取 
    利用所建立出的概念圖，對每篇文章做
結構特徵的擷取，首先必需先篩選每個段落
的 keyWord，針對每個段落所得 keyWord 對
應其概念圖所在之層級，取最高層級三層範
圍內的 keyWord 當作能代表此段意義之主要
詞語。 
篩選 keyWord 後，隨即將每兩段所取得的主
要 keyWord，做 Bi-word 的配對當作此篇文
章之結構特徵。在此部份如果我們配對取的
越長的話，在相似度系統的比較上，文章跟
文章之間就會越難比對到，因此取 Bi-word
使系統能更有彈性。 
    在此針對篩選過後的 keyWord 說明其特
徵擷取: 
某篇文章其段落為二，每個段落所篩選之
keyWord 如下所示 
 
 
        圖三、特徵擷取示意圖 
 
因此我們擷取「(k1) (k3)」、「(k1) (k1)」、
「(k1) (k4)」、「(k2) (k3)」、「(k2) (k1)」、
「(k2) (k4)」等 Bi-word，當作此篇的結構
特徵。 
 
(五) 相似度評分系統 
    此系統的基本假設為:如果一篇文章使
用的材料（詞語、結構）與高分文 
章越相似，或與低分文章越不相似，則此篇
文章為高分文章的機率越高；反之，低分的
機率越高。 
    但在系統一開始時，所有的測試文章都
不會帶任何附加資訊，因此我們並不知道文
章分數以及其分佈圖。所以我們需要在系統
一開始時，先針對每篇文章給予一個初始分
數，以便於系統能正常運作。 
    因此在系統一開始會先針對文章的成語
數、好意原數、名詞數、句號數這四個間接
特徵加總當作文章的初始分數(即公式中
)1(,, tjiZ ,t=0)。而這些特徵皆與文章分數有正
向關係。 
    在根據下列公式進行評分: 
K3 K1 K4 
K1 K2 
表篩選過後之 KeyWord， 
段落一 
段落二 
 
Pi  : 文章i所得到的誤差權重。   
Gi,now : 文章i在現在比例所評定的分數。 
Gi,w  : 文章i依比例評定的分數對
應立意取材(word)分數的文章集合。 
Gi,s   : 文章i依比例評定的分數對
應結構組織(structure)分數的文章集合。 
Pfi,w,g  : 文章i在立意取材中所在級
分(grade)的篇數。 
Pfi,s,g  : 文章i在結構組織中所在級
分(grade)的篇數。 
    在上述公式中可以得知，當一篇文章經
過整合評定出來的分數與立意取材和結構組
織評出來皆相同時，其類型落在公式(3)中。
其所得到的誤差權重會較低;反之，權重會較
高。例如: 某篇文章被整合評定為1級分，也
屬於立意取材和結構組織一級分中，其誤差
權重應該經由公式(3)得出。 
    然 而 公 式 (4) 、 (5) 前 半 項 
|||| ,,,, nowisinowiwi GGGG   主要是用來區隔
文章類型落在(4)、(5)內，但文章分數不盡
相同的誤差權重。例如:某篇文章(整合評
分:1分;立意取材:1分;結構組織:6分)，另一
篇(整合評分:1分;立意取材:1分;結構組
織:3分)，其誤差權重應該為前者較高。 
    再由已知的文章誤差權重，經過下列公
式，進行目前比例的誤差權重。 
 
  





6
1
2
i
j
ij
PratioError
 (6) 
Pi  : 文章i所得到的誤差權重。   
Error Ratio  : 目前比例誤差權重。 
在公式(6)中，內部  計算目前比例中每個
級分的誤差，而對各個級分誤差值做平方，
主要是為了讓差距能夠有所顯著，最後得到
目前比例的誤差權重。當對每個比例皆做完
誤差權重的計算後，即可得知產生越小權重
的比例，應當對文章分數及其分佈為最佳
的。  
 
(八) 文章錯別字判斷  
    文章錯別字主要分作同音異字、異音異
字兩種，而通常作文上普遍嚴重的錯 
誤通常在於同音異字上，因此本系統是針對
同音異字來做判斷。 
 
●錯別字判斷系統流程 
    在這部分系統基本假設為:當文章中存
在錯別字時，經過斷詞處理後。因無法找到
對應的詞語，而會被斷成連續的一字詞。因
此系統基本內部的判斷，會針對斷詞後被斷
成連續一字詞的做處理，其流程我們根據《國
語一字多音審訂表》將連續的一字詞轉換成
注音型式後，再將注音型式的連續字由最長
比對演算法在《國語一字多音審訂表》(以下
簡稱注音表)，中尋找對應的格式。 
    在此利用一個簡單的例子說明其基本判
斷過程: 
「 今天天汽好熱 」 
因為句子中有錯字，斷詞後會變成: 
「 (今天) (天) (汽) (好) (熱) 」  
針對連續一字詞做注音轉換如下: 
「 ㄊㄧㄢ   ㄑㄧˋ   ㄏㄠˇ   ㄖㄜˋ 」 
 最長比對演算法，由最長的字串開始在
注音表中搜尋: 
「 ㄊㄧㄢ   ㄑㄧˋ   ㄏㄠˇ   ㄖㄜ
ˋ 」    ......(1) 
「  ㄊ ㄧ ㄢ    ㄑ ㄧ ˋ    ㄏ ㄠ
ˇ 」  .................(2) 
「  ㄊ ㄧ ㄢ    ㄑ ㄧ
ˋ 」............................(3) 
 
經過搜尋後，我們經由(3)可在注音表找到對
應的組合，變轉換回國字型式「天氣」，剩餘
的字皆不做更動，基本判斷最後結果即為
「 今天天氣好熱 」。 
    由上述判斷中，可得知具有一定判斷性
效果。但之間未考慮詞與詞之間的關係，可
能會對許多原本是對的句子照成誤判的情
形。 
    在此舉一個簡單嚴重誤判例子說明: 
「 上課鐘一打 」 
斷詞後如下: 
「 (上課) (鐘) (一) (打) 」 
 針對連續一字詞做處理: 
「  ㄓ ㄨ ㄥ    ㄧ    ㄉ ㄚ
數範圍為一至六級分，再取平均並四捨五入
後當做該篇文章的評閱分數。 
  
●實驗流程  
    將所有文章先經過斷詞處理後，再從文
章擷取出結構、詞語兩部分的特徵當作系統
演算法判斷的依據並分別做相似度評分系統
的運作，當系統分別依照兩種特徵進行運作，
直到文章分數達到穩態後，最後根據其文章
的Z-Score分佈區間評定文章六級分的分
數。 
 
●評鑑方式  
    本系統之實驗所採取的評鑑方式是針對
正確率(Adjacent)以及精確率(Exact)兩項
指標當作評鑑系統之效能。 
正確率:系統、人工評分之誤差一分內之文章
數/文章總數。 
精確率:系統、人工評分必須完全相同之文章
數/文章總數。 
    因為不同評閱者的背景知識、主觀認知
不盡相同，使得對文章之評分標準也會有所
不同。因此本實驗認為誤差一分內皆屬正確
之批閱。  
 
●實驗結果  
其分別針對詞語以及結構上評分，結果如下
表所示: 
 
 
 
 
 
[二]分數整合評分系統 
 
●實驗流程  
    此部分會使用經由相似度系統分別對兩
個面向評分所得到的文章分數、各級分之文
章分佈以及文章尚未轉化成六級分之
Z-Score，做為整合評分系統之初始資料。當
所有資訊輸入系統進行比例誤差權重的計算，
根據系統所得出的最小誤差之比例，進行整
合評分，最後再根據文章 Z-Score 分佈區間
評定文章六級分的分數。其評鑑方法也是與
4.1.3 小節相同。 
 
●實驗結果  
    由系統得出之最佳比例所進行整合評分，
結果如下表所式: 
 
 
●效能比較與分析 
    目前各系統之效能如下表所示: 
●實驗結果 
    其兩個系統所得到之結果如下表所示: 
 
 
    由表七中可得知，系統經過修正後其效
果會有明顯的增加，所得結果足以證明此初
階系統之可信度，往後可做為輔助糾正文章
錯別字的工具。 
 
五、計畫成果與自評 
 
●研究總結 
    在本論文中，我們所提出的中文寫作多
面向評分系統，有別於以往的評分系統，本
系統將不再需要事前訓練資料，且不再是以
單面向、主觀的方式來給予評分，我們希望
在評分上能達到更高的可信度，因此提出了
針對多面向來進行評分的方式，根據文章的
結構、詞語…等特徵，將各分數加以統整，
在上述的實驗中，利用此方法所得之正確率
達到 94.2%，證明了多面向整合的評分方式
較為客觀，且其實驗結果之整合分數比傳統
的評分系統更足以採信；此外，針對錯別字
與各特徵都將給予回饋，使用者可藉由此回
饋資訊得知在寫作上有哪些需要改進的部份，
以提升寫作能力。 
目前成果部分，有一篇論文已經被 IEEE 
Intelligent Systems 期刊接受[10]， 兩篇
論文被 Expert Systems with Applications 
期刊接受[11][12]，另外在決策樹方面我們
提出一個簡化多值化決策樹的方法，該論文
已經被 ISICA 2008 [13] 接受，該論文也將
會收錄於 LNCS 期刊；此外關於 CAES 研究
部分，也分別發表於國際學術會議 NLPKE 
[14] 以及 APERA 2008 [15]，另外也有一篇
論文發表於相關期刊中 [16]。另外尚有一篇
論文被 ICNC＇10 Conference 接受並且已
經刊出 [17]。 
 
●未來工作 
    本論文目前雖然已針對作文寫作上四個
面向當中的立意取材及結構部分上做統整上
的評分，且在錯別字判斷中給予回饋的錯誤
資訊，但系統尚未包含中文作文評分的全部
標準，即少了遣詞造句及錯別字與格式上的
分數，因此希望未來能加入這兩個面向上的
評分，使系統更能符合人工批閱的模式。 
 
六、參考文獻 
[1] Jill Burstein. “The E-rater Scoring 
Engine: Automated Essay Scoring With 
Natural Language Processing.＂Automated 
Essay Scoring: A Cross-Disciplinary 
Perspective. pp. 113-121,2003. 
[2] 蔡沛言，「自動建構中文作文評分系統：
產生、篩選與評估」，國立交通大學，碩士
論文.( 2005) 
[3] 林信宏，「基於貝氏機器學習法之中文
自動作文評分系統」，國立交通大學，碩士
論文.( 2006) 
[4] 粘志鵬，「基於支援向量機之中文自動
作文評分系統」，國立交通大學，碩士論
文.( 2006) 
[5] 張佑銘，「中文自動作文修辭評分系統
設計」，國立交通大學，碩士論文.( 2005) 
[6] 陳彥宇，「非監督式中文寫作自動評閱
系統」，國立交通大學，博士論文.(2007) 
[7] 張 道 行 ， 「 Conceptualization 
Methodology for Chinese Automatic Essay 
Scoring」，國立交通大學，博士論文.(2007) 
[8] 國中中學學生基本學力測驗推動委員會 
URL：http://www.bctest.ntnu.edu.tw/ 
 
  
ICNC’10-FSKD’10 國際會議研討會是由中國煙台大學主辦，該會議所收錄之論
文也將會由 IEEE Xplore 以及 EI Compendex 所 index。我們這次所發表的論文
題目為「Analysis and Prediction of Trajectories Using Bayesian Network」，主
要是利用 Bayesian Network 技術對 GPS 軌跡資訊作分析以及預測。 
該會議總共舉辦三天，第一天所邀請到的 Keynote Speaker 包括 Gary G. Yen 教
授、Derong Liu 教授以及 Qiang Yang 教授。其中 Gary G. Yen 教授目前是 IEEE 
雜誌的主編，而 Qiang Yang 目前也是 IEEE Intelligent Systems 的 Associate 
Editor。其中最令我印象深刻的是 Qiang Yang 教授的演講，他目前的主要研究
方向為 Machine Learning、Data Mining 以及 Social Network 分析。我目前的研
究主題也在這方面上，所以她的演講給了我不少的啟發。在演講中，他提到目前
他的其中一個研究題目為 link prediction。這邊的 link 不僅只是一般的網路 link 
還可以延伸到 social network 上面人與人之間的 link。如何從既有的資訊中，去
更進一步的得到使用者與使用者的關係，甚至可以預測可能的關係或關連性等
等。目前 Facebook 即是大量使用了類似之技術。此外，Qiang Yang 還提到一
個 transfer learning。傳統的機器學系必須有一個假設前提，training data 以及 
testing data 甚至於未來未知的 data 必須具備相同的統計分佈。Quiang Yang 認
為該假設在實際應用上會有很大的限制，因此他們希望可以延伸，甚至於把一些
從不同資料類型中學習到的 learning model，可以套用到完全不同類型的資料中。 
未來或許可以成為我的另一研究方向。 
此外，該會議主要是著眼於智慧型系統相關技術，包括 Fuzzy、類神經網路、資
料探勘等等，在三天的研討會中，讓我從中聽到不少的新方法，收穫良多。 
 
2ŕųŢūŦŤŵŰųźġ
ŅŢŵŢ
őŰűŶŭŢųġœŦŨŪŰůġ
ņŹŵųŢŤŵŪŰů
ŃŢźŦŴŪŢůġŏŦŵŸŰųŬġ
ńŰůŴŵųŶŤŵŪŰů
ŕųŢūŦŤŵŰųźġ
ŔŦŲŶŦůŤŦġŕŰġ
œŦŨŪŰůġŔŦŲŶŦůŤŦġ
ŕųŢůŴŧŰųŮŢŵŪŰů
ŇųŦŲŶŦůŵġœŦŨŪŰůġ
ņŹŵųŢŤŵŪŰů
Fig. 1. System Flow
A. Popular Region Extraction
We adopt region concept to approximate a moving
object’s spatio location. Thus, two objects that are lo-
cated in the same region will be regarded as being
at the same location. Moreover, a moving object’s tra-
jectory sequences could be transformed into region se-
quences. For example, if there is a trajectory sequence
(x1, y1)
α
→ (x2, y2)|(x1, y1) ∈ R1 ∧ (x2, y2) ∈ R2, it could be
transformed to R1
α
→ R2.
In this paper, popular regions are adopted to approximate
a moving object trajectory information. The popular region
extraction process is based on the approach proposed by [4]
with minor modification. The whole plane could be regarded
as a grid G, which is partitioned into n×m cells. The density
of each cell G(i, j) (1 ≤ i ≤ n and 1 ≤ j ≤ m) is based on
the moving object’s trajectory information. Figure 2 shows a
moving object’s trajectory information. At time T1, its location
is at P1. It moves to location P2 at time T2. When the moving
object’s location is at position P1, the cells around P1 (cells
1− 9) will be assigned with equal weights. Meanwhile, linear
regression approximation is adopted to describe the trajectory
between two consecutive points. As shown in Figure 2, the
moving function between P1 and P2 is approximated using
a linear regression and the cells around this line should be
assigned with equal weights as well. We extend from the start
point and the virtual points will be assigned along this line.
The distance between the two virtual points is the length of
the cell. For each virtual point, the cells around this virtual
point will be assigned with equal weights as well. In addition,
each cell will be weighted once for the same moving object.
Thus, the gray cells in Figure 2 will be assigned with the
same weights. For each trajectory sequence, it will contribute
weights to the cells along the trajectory. When the process
is completed, the popular cells could be determined based
on the cell’s density. Simultaneously , follow the steps of
PopularRegions algorithm mentioned in [4], these popular
cells could be extended as much as possible along four
directions to obtain popular regions.
1 2 3
4 5 6
7 8 9
˗
˗
˕
˕
˕
Fig. 2. Trajectory Density Computation Model
Region A
Region B
Fig. 3. Transformation Between Trajectory Sequence and Region Sequence
TABLE I
DATABASE WITH FOUR TRANSACTIONS
Transaction ID Sequence
1 a b c d e
2 a b c d
3 b d
4 a b
B. Trajectory Sequence To Region Sequence Transformation
When the popular regions are extracted, the system can
obtain trajectory point’s corresponding region based on coor-
dinates information. In practice, the GPS recorder keeps track
of trajectory information every several seconds, so consecutive
points are usually located in the same area. Line 6 − 14
performs the aggregation of regions.
For example, Figure 3 shows a trajectory sequence and
it includes fourteen points. The transformation result will
be 00AAAA0000BB00, where 0 indicates that this point
is not within any region. Although this trajectory sequence
passes through Region A four times, it will be recorded once.
Meanwhile, the trajectory points that are not within popular
regions will be ignored. Furthermore, the trajectory may stay
at a region for a while, but only the entry time will be taken
into account. In other words, the trajectory in Figure 3 will be
transformed into the region sequence RA
t1−t9→ RB . When the
above step completes, the original trajectory sequence could
be approximated by the region sequence.
C. Frequent Sequential Pattern Mining
When the region sequences are obtained, Algorithm 1 (Mod-
ified PrefixSpan Algorithm), which is based on PrefixSpan [1]
algorithm, is employed to extract frequent sequential patterns.
In Algorithm 1, DatabaseScan procedure will get frequent 1-
itemsets. For example, if we have four transactions as shown
in Table I. After DatabaseScan procedure applying to the
above sequences with the minimum support of value three,
the frequent 1-itemset of the database will be a, b and d. A
queue will be created to store these frequent items. Database
TABLE II
PROJECTION RESULT
Transaction ID Sequence
1 b c d e
2 b c d
4 b
4Algorithm 2 Trajectory Bayesian Network Construction
Input: Region Sequences List (regionSequenceList)
Output: A Bayesian Network
1: for all i such that 1 ≤ i ≤ regionSequenceList.Length do
2: for all j such that 1 ≤ j ≤ regionSequenceList[i].Length do
3: e ← regionSequenceList[i][j]
4: if list.IsExist(e) is False then
5: list.add(e)
6: create a node for e
7: end if
8: end for
9: end for
10: for all i such that 1 ≤ i ≤ regionSequenceList.Length do
11: for all j such that 1 ≤ j ≤ regionSequenceList[i].Length do
12: parentNode ← regionSequenceList[i][j]
13: if regionSequenceList[i][j + 1] is not NULL then
14: childNode ← regionSequenceList[i][j + 1]
15: if there is no arc between parentNode and childNode then
16: create a arc from parentNode to childNode
17: end if
18: end if
19: end for
20: end for
Parent Node
Yes No
Yes 0.66 0.34
No 0.95 0.05
Fig. 4. Bayesian Network Structure for Region Sequences
nonetheless come up with approximations which often work
well in practice. In our experiments, inference is performed by
using MSBNx [10], which is a component-centric toolkit for
modeling and inference with Bayesian network. MSBNx uses
clique-tree propagation methods to calculate the probabilities
and it provides an extensive programming interface that makes
editing and evaluation of Bayesian Networks especially easy
from COM-friendly languages such as Visual Basic, Jscript,
and C#.
We use the trajectory data collected from GPS recorders
to construct the Bayesian network. In the data set, there are
232 trajectory sequences. These trajectory sequences will be
used to extract popular regions and the number of popular
regions is 17. As mentioned above, the trajectory sequences
does not pass through any popular region will be ignored and
the number of trajectory sequences passing through popular
regions is 120. In practice, people could choose the regions
they are interested in to perform the inference. We select 9
regions to construct the Bayesian network and Figure 5 shows
the model result. The direction of arcs could be determined
by the ordering of the regions in the sequences. For example,
we have sequences < 0, 2, 4, 1, 3, 9 > and < 0, 5, 2, 1, 3, 9 >
in the raw data, so we could construct two traversal paths:
0 → 2 → 4 → 1 → 3 → 9 and 0 → 5 → 2 → 1 → 3 → 9.
Moreover, the conditional probability table for each node could
be constructed based on empirical sequence data as mentioned
in previous section and they are presented in Figure 5.
Essentially, Bayesian network allows us to perform in-
ference and get the probabilities of all possible states of
an unobserved node under the current observed data. For
example, when we have an evidence saying that the user’s
current location is at R2, the system could further inference
user’s previous region is at R0 with a higher probability:
Pr(R0 = 1|R2 = 1) =
Pr(R0 = 1, R2 = 1)
Pr(R2 = 1)
= 0.98
Pr(R5 = 1|R2 = 1) =
Pr(R5 = 1, R2 = 1)
Pr(R2 = 1)
= 0.29
Besides, we could also derive possible reasons with a given
cause. For example, when the user’s current location is at R0,
the system could obtain the probability of arriving at R1 is
0.93 and the probability of arriving at R8 is 0.07. In general,
a Bayesian network could be designed to represent the deep
causal knowledge of a domain expert and provide probabilistic
answers to many queries by computing the posterior probabil-
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
除了三篇期刊論文 (IEEE Intelligent Systems 一篇，Expert Systems with 
Applications 兩篇)，兩篇 Conference 論文 (ISICA 2008 與 ICNC'10 )之
外，目前尚有兩篇期刊論文分別於 Information Processing &amp； Management 
與 IEEE Trans. on SMC -Part C 2nd revision 中。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
