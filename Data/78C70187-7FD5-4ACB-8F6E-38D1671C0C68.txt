                                                      未來生活互動式溝通環境 
行政院國家科學委員會補助專題研究計畫 成果報告 
 
未來生活互動式溝通環境之建置 
子計畫四：個人化認知知識庫之建構(2/2) 
 
計畫類別：□ 個別型計畫  ■ 整合型計畫 
計畫編號：NSC 99-2220-E-224-005 
執行期間：99 年 08 月 01 日至 100 年 07 月 31 日 
 
計畫主持人：黃胤傅 教授 
共同主持人：無 
計畫參與人員：張家棠，陳姝螢，楊宗憲，林亨 
 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
□ 涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
 
執行單位：國立雲林科技大學 資訊工程學系暨研究所 
 
中華民國   100  年   07  月   20   日 
                                                      未來生活互動式溝通環境 
Base)」，並藉由此知識庫的應用，提供給各
子計畫另一種高附加價值之資訊，以利於
產生更合適之服務提供，以達到「未來生
活互動式溝通環境」之實現。 
經由本計畫之實行以及搭配其它技術
所建立之「個人化認知知識庫之建構
(Constructing the Personal Perception 
Knowledge Base)」，將可針對使用者提供更
趨於個人化之服務，取得使用者腦中認知
之知識領域，自動的針對使用者篩選出可
能令使用者感到興趣及有幫助之電影，藉
以大幅減少使用者自行選擇所須之電影所
花費之時間。 
「 個 人 化 認 知 知 識 庫 之 建 構
(Constructing the Personal Perception 
Knowledge Base)」與「個人化推薦系統之
建構(Constructing the Personal Recommend 
System)」之整體架構圖如圖一所示 
 
圖一、整體架構圖 
 
本期計劃「個人化推薦系統之建構
(Constructing the Personal Recommend 
System)」利用分析多個使用者的領域知識
庫，將使用者在不同之領域裡皆進行分群
的工作，如此，當使用者在使用本推薦系
統時，本推薦系統即可針對使用者所選擇
的領域，做出合適的推薦，譬如，當使用
者選擇運動這個領域時，本推薦系統即可
針對使用者在運動這個類別中所歸屬的群
集，從這個群集中，挑選合適、可能令使
用者感到興趣的項目推薦給使用者，本推
薦系統也將伴隨著知識庫的更新，進而達
到分群調整之功能，以期提供更準確之推
薦項目。本研究計畫之實行，將其區分為
二個主要部份，分別為資訊擷取及使用者
探勘平台之建構、建立個人化推薦系統之
實現:  
 資訊擷取及使用者探勘平台之建構 
(1) 使用者溝通介面：提供一使本研究計畫
與使用者進行溝通之橋樑，並使用資料
庫集中之領域知識分類庫 (Domain 
Knowledge Categorization Database)提
供使用者可選擇之選項。 
(2) 電影擷取器：主要功用為擷取並記錄使
用者選擇之影片進行分析。 
推薦系統使用者介面見圖二 
 
圖二、推薦系統使用者介面 
 
 建立個人化推薦系統之實現 
 一 般 化 模 組 (Generalization 
Module)：根據個人化認知知識庫
之使用者資訊，將使用者在不同
之領域裡皆進行分群。 
 關聯式規則探勘模組(Association 
                                                      未來生活互動式溝通環境 
合分別為電影群集和鄰居群集，電影群集
根據電影評分分數進行降維，而鄰居群集
試著找出相似的人做為鄰居，接著，將表
中的數據進行正規化動作，代入探勘工具
進行探勘，並將結果儲存起來。最後透過
規則進行推薦，當使用者不滿意時，則開
始回饋式機制，學習使用者喜好，改善推
薦結果。 
在第一期計畫「建立個人化認知知識庫
之實現」區塊中，我們一共規劃了五個模
組，從一開始的關係摘要擷取器、相關性
矩陣產生器、概念階層建立器、精密關係
擷取器到自我學習模組每個模組皆用來取
得各種文字與文字間的各種關係與使用者
行為紀錄以及計算文字間的關聯度，並且
搭 配 使 用 四 部 網 路 免 費 辭 典
(Dictionary/thesaurus、Acronyms、Computing 
Dictionary、Wikipedia Encyclopedia)以取得
文字的其它意義，如同義詞、反義詞、相
似詞以及縮寫詞等等，並再透過 Wikipedia
以及 WordNet 這兩部辭典找出文字間 Is-A
以及 Part of 的關係以建立出這些文字的知
識 庫 (Ontology) ， 而 所 產 生 的 知 識 庫
(Ontology)即為使用者個人所專屬的。 
我們將這兩個區塊整合成一完整的系
統供使用者使用，以建立出個人的知識
庫。在每個人專屬的知識庫中涵蓋著各種
領域的知識，而這些領域的產生即為一開
始使用者在資訊擷取及使用者探勘平台中
所選擇的類別所產生，使用者在資訊擷取
及使用者探勘平台中，只會選擇自己感興
趣的類別，並且勾選自己感興趣的電影，
因此，我們將可透過收集此一類資訊，進
而透過建立個人化認知知識庫區塊而達到
建立專屬使用者在此一領域中的知識庫，
而透過此一步驟的循環工作下，我們可以
建立專屬使用者在各種領域下的知識庫，
最後，將這些知識庫整合起來，則專屬於
使用者個人的知識庫即產生。 
接下來，我們透過第二期建立的學習模
組將使用者後續的搜尋結果與勾選網頁的
行為當作學習資訊，等資訊量超過我們設
的門檻值，進行批次處理，修正我們的個
人化認知知識庫，使之能達到真正符合”個
人化”的認知知識庫。 
最後，有了完善的個人化認知知識庫
後，第三期進而建構出個人化推薦系統，
透過使用者的領域知識庫來做個一系列的
推薦，加上回饋機制，使得推薦系統不只
有推薦服務同時也可以根據使用者的喜好
做自我學習讓系統的推薦更加符合使用者
所需求。 
在本研究計畫中，主要強調於建構出各
種使用者資訊的取得、收集以及相關性回
饋機制，因此，在本期研究計畫所儲存的
各種使用者資訊，將持續增加，以其能更
完善改善個人化推薦系統的準確性，而目
前在自我學習的部份考慮到若能夠學習的
資訊量太少時又一直花費大量時間作學習
運算，會產生學習效果不佳情況(累積的學
習用資訊量不足時)，退而求其次採用批次
處理進行學習。 
五、參考文獻 
[1]. C. Boyens, R. Krishna, and R. Padman, 
“On privacy-preserving access to 
distributed heterogeneous healthcare 
information,” Proc. 37th Annual Hawaii 
International Conference on System 
Sciences, 2004, pp. 135-144. 
[2]. Chris Clifton, Murat Kantarcio Lu, 
AnHai Doan, Gunther Schadow, Jaideep 
Vaidya, Ahmed Elmagarmid, and Dan 
Suciu, “Privacy-preserving data 
integration and sharing,” Proc. 9th ACM 
                                                      未來生活互動式溝通環境 
[14]. Alexander Maedche and Steffen Staab, 
“Mining ontologies from text,” Proc. 
12
th
 European Workshop on Knowledge 
Acquisition, Modeling and Management, 
2000, pp. 189-202. 
[15]. Huang Yin-Fu and Huang Yu-Yu, “A 
Framework Automating Ontology 
Construction on Computer Science 
Documents,” Proc. of the 4th 
International Conference on Web 
Information Systems and Technologies, 
Funchal, Madeira - Portugal, May 4-7, 
Vol. 2, 2008, pp. 16-25. 
[16]. The Free Dictionary, 
http://www.thefreedictionary.com/. 
[17]. Wikipedia Categories, 
http://en.wikipedia.org/wiki/Special:Cat
egories. 
[18]. WordNet, http://wordnet.princeton.edu/. 
[19]. 張真誠, 蔡文輝, 林敏惠, “挑戰資料
庫管理系統 A Challenge to Database 
Management Systems,” 旗標出版股份
有限公司. 
[20]. 曾守正, 周韻寰, “資料庫系統之理論
與實務 ,” 華泰文化事業股份有限公
司. 
[21]. 葉良川 譯, “CRM Data Mining 應用系
統 建 置 Building Data Mining 
Applications for CRM,” 美商麥格羅.
希爾國際股份有限公司 台灣分公司. 
[22]. 曾新穆, 李建億 譯, “資料探勘（Data 
Mining A TUTORIAL-BASED 
PRIMER）,” 東華書局. 
[23]. 曾憲雄, 蔡秀滿, 蘇東興, 曾秋蓉, 王
慶堯, “資料探勘（Data Mining）,” 旗
標出版股份有限公司. 
 
報告內容應包括下列各項： 
一、參加會議經過 
2010 年 IEEE 工業電子與應用國際研討會於九十九年十月三日至十月五日在馬來西
亞檳城 Park Royal 飯店召開。Park Royal 飯店位於檳島北海岸，是一個旅遊景點區，離
檳島國際機場，乘坐計程車約一小時車程，交通不是很便利。會議地點在飯店二樓進行，
第一天是 Tutorials Program，第二天有大會開幕、和十二個 Sessions 分為三個會場同時
進行。第三天也是十二個 Sessions 分為三個會場同時進行。這次投稿論文有來自 36 個
國家 289 篇論文，但只接受 137 篇論文發表，接受率僅有 47.4%，其中來自台灣的論文
只有 2 篇。本人於第二天發表論文，跟國外學者互動熱絡。 
 
二、與會心得 
參加本次國際會議感觸良多，尤其能與來自世界各地的知名學者及專家進行學術交
流，獲益甚多。這個研討會是馬來西亞工業電子與應用方面相當重要的研討會，參與的
學者來自世界各地，這次是第三屆。這次主辦單位馬來技術大學相當熱誠款待，舉如用
餐的準備、晚宴餘興節目的安排，都盡到地主之誼，讓與會的學者都覺得不虛此行。這
次本人參與了幾個有興趣的場次，如 Communication Technology, Humanities/Computer, 
Biomedical & Bioinformatics，另外本人也擔任兩個場次的主席；其中有幾個研究主題甚
佳，可考慮作為未來研究的方向。會場大部分的發表者都有出席，而且反應熱絡，值得
國內學術單位學習。 
 
三、建議 
首先感謝國科會在本人專題研究計劃下核給出席國際會議的補助，得與國際知名學
者進行學術交流。儘管在專題研究計劃下核給出席國際會議的機會不易，在此還是建議
國科會應多鼓勵國內學者參與國際會議以增廣見聞並吸收新知；另外國內學術單位也應
積極爭取舉辦知名的國際會議以提昇國際學術知名度，當然會場地點的選擇是相當重
要，國內舉辦過的國際會議地點大多侷限在大學校院，如能在名勝風景區舉辦，則較能
吸引國際知名學者參與。 
 
四、攜回資料名稱及內容 
大會手冊、光碟論文集、及未來國際會議宣傳資料 
 
五、其他 
無 
 
represents buildings, scenery spots or specific points in the 
map. In the spatial road network, a road is represented 
with a line. The road table stores all road information such 
as road id, road full name, road length, start node, and end 
node et al. In the road intersection, an intersection is 
represented with a point. The intersection table stores the 
information of all intersected roads. In the POI, sites such 
as building, scenery spots or specific points are 
represented with points. The site table stores the site 
information. 
Although the source spatial database provides complete 
information, we need to do data preprocessing in the 
offline phase since some data in the database are not 
relevant to finding the route. Here, during the data 
processing, we used the source spatial database to create 
new data tables useful and efficient for the arrangement 
engine accessing. Data processing consists of two parts: 
Spatial Data Categorization and Route Map Generator. 
A.2 Client-end and Data Transfer Interface (Online) 
On the client-end, a user coordinate can be located by 
the GPS receiver in his/her mobile device, which acts as 
the query point in the system. The client-end provides two 
service functions for users; i.e., 1) browsing the map using 
mobile devices, and 2) selecting interesting layers and 
getting back the tour arrangement from the server. 
Data Transfer Interface plays an intermediate role 
between clients and the server. All information and 
control interchanges are through the interface. In the 
system, we used the Hypertext Preprocessor (PHP) 
webpage descriptor language to implement the interface 
which includes six tasks as follows. 
1. Taking the coordinate where users are located 
2. Offering an interface for users to specify the layers and 
diameter 
3. Integrating all information into a txt file 
4. Sending a route request to the server 
5. Receiving route results from the server 
6. Requesting the user interface to download the result file 
A.3 Server-end (Online) 
The server-end receives a route request and provides 
users the tour arrangement. Three tasks are included in the 
server; i.e., 1) spatial clustering, 2) routing, and 3) 
presentation. 
For the spatial clustering, the server creates a few 
clusters in the map according to the user coordinate, the 
selected layers, and the specified diameter. Taking the 
user coordinate as the start node, the server retrieves the 
objects from the spatial layer database based on the 
selected layers. Then, it searches and creates several 
clusters using the specified diameter. In other words, each 
of these clusters consists of all the selected layer objects. 
For the routing, the server tries to find the minimum-
distance path from these clusters. Here, we proposed an 
Efficient Tour Arrangement Path (ETAP) algorithm 
derived from the ECT algorithm [2] to obtain the 
minimum-distance path in every cluster. Then, the server 
selects the minimum-distance path among all clusters as 
the result path, and stores it into the database. 
Presentation is the last step in the server. The server 
sends a request to users for downloading the route result 
from the database, and then the route path would be 
shown in user mobile devices. 
III. TOUR ARRANGEMENT ENGINE
This section is dedicated to the details of the tour 
arrangement engine. The engine is involved with two 
major algorithms; i.e., the spatial clustering algorithm and 
routing algorithm. 
A. Spatial Clustering Algorithm 
The spatial clustering algorithm has three parts for 
finding spatial clusters; i.e., deciding moving step, 
defining stopping threshold, and finding clusters. The 
detailed steps of the spatial clustering algorithm are given 
as follows. 
Spatial Clustering Algorithm (user coordinate, selected 
objects, diameter) 
Step1. Decide moving step md.
Step2. Initialize stopping threshold td as Ќ.
Step3. With step md, find clusters in a spiral search 
manner. 
Step4. Update td if įc < įmin where įc is the distance 
from the user coordinate to the nearest object instance in 
current cluster c, and įmin is the minimum one among all 
precedent įi.
Step5. Repeat Step3 and 4 until įc > td.
In the algorithm, we used a spiral search method to find 
spatial clusters step by step, and each cluster has to 
conform to two conditions. One condition is a cluster must 
consist of at least one object instance for each specified 
layer object. The other condition is the distance from the 
user coordinate to the nearest object instance in a cluster 
must be less than or equal to a stopping threshold. In the 
algorithm, we first used a quad-tree strategy to decide the 
moving step. Then, finding spatial clusters would not 
terminate unless the stopping condition is met. 
A.1 Deciding Moving Step 
Here, deciding moving step requires computing the 
minimum distance between layer objects. Definitely, the 
minimum distance between layer objects is the optimal 
one to be used in the algorithm, if possible. However, 
finding the minimum distance between layer objects 
requires the whole objects in the map, and this would take 
us enormous execution time when the amount of object 
instances is huge. Therefore, we used a quad tree strategy 
to divide the map, then computed the amounts of object 
instances in four regions, and finally selected the region 
with the most object instances as the one to be divided in 
the next iteration. The reason is, we though, that the 
minimum distance between layer objects probably exists 
in the densest region. Thus, we repeated the process until 
each of four regions contains the same layer object. The 
procedure in deciding moving step is as follows. 
Step1. Quarter the whole map. 
Step2. Compute the amounts of object instances in the 
regions with at least two layer objects. 
Step3. Select the region with the most object instances and 
quarter it. 
Step4. Repeat Step2 till each of four regions contains the 
same layer object. 
Step5. Return to the precedent level and find the minimum 
distance between layer objects. 
323
Figure 10.  City map of a cluster Figure 11. Preliminary routing graph 
Figure 12. Object instance projection Figure 13. Routing graph 
Figure 14. Projection method 
For the preliminary routing graph generator, we use the 
route database as mentioned in Section II.A.1 to generate 
a preliminary routing graph as shown in Fig. 11. In the 
preliminary routing graph, a yellow node represents a road 
intersection, whereas a blue line means a connect relation 
between two road intersections. Here, instead of using the 
Euclidean distance, we used a real road distance to 
represent a road length. 
Next, for the object instance projection, we would 
project specified object instances to the preliminary 
routing graph and then shift these object instances onto 
road intersections, thereby generating the routing graph. 
As shown in Fig. 12, triangles, circles, and diamonds 
corresponding to 7-11, Post offices, and Banks are 
projected to the preliminary routing graph. Next, we shift 
these object instances onto road intersections, as shown in 
Fig. 13. For the projection and shifting of an object 
instance, we could explain the method using the example 
as shown in Fig. 14.  Given road nodes A and B, and an 
object instance C, first we can get the line L1: Y=X on 
which A and B are located. Then, based on L1 and C, we 
can get the perpendicular line L2: 4X+4Y=16. Next, we 
solve the simultaneous equations L1 and L2 to get D 
which is the projection node of C in L1. Finally, we find 
that road node B closer to D would be designated as what 
D is shifted onto. 
B.2 Kernel Routing 
In the section, we proposed an Efficient Tour 
Arrangement Path (ETAP) algorithm derived from the 
Efficient City Tour (ECT) algorithm [2] to find out an 
efficient path in a routing graph, according to the layer 
objects specified by users. The efficient path is defined as 
the one with the minimum distance to visit all specified 
layer objects in a cluster. For the example as shown in Fig. 
11, a user coordinate is represented with the star, and three 
specified objects are with triangles, circles, and diamonds 
corresponding to 7-11, Post offices, and Banks in the 
routing graph. 
The procedure of the ETAP algorithm is as follows. For 
each combination of specified layer objects, we would 
execute the following steps to find out an efficient path to 
visit all of them in the routing graph. First, we find all 
shortest paths from the star to each object instance in an 
indicated combination. Second, we filter out useless paths; 
i.e., 1) it is a sub-path of any other paths or 2) all nodes in 
the path have been found in the precedent iterations. 
Thirdly, we choose an efficient path with the minimum 
average cost from the remaining paths. Fourthly, we mark 
the specified layer objects on the efficient path as found. 
Fifthly, we take the last node in the efficient path as a new 
start node. Finally, we repeat the procedure till all 
specified layer objects are included in the concatenated 
path. For the efficient paths from all combinations, we 
would select the ones with the minimum distance as the 
final routes. For Step3, the average cost of a shortest path 
is defined as follows: 
the cost of a shortest pathaverage cost(shortest path) = 
the number of specified layer objects new-included
The detailed algorithm of ETAP is formally given as 
follows:
ETAP (user coordinate, cluster) 
/* Parameter definition 
Start_n: the start node, 
End_n: the set of selected object instances, 
T: the set of selected object instances not included yet, 
S: the set of all shortest paths from Start_n to the object 
instances in End_n, 
Eff_path: a close-to-minimum path including all 
selected object instances, 
Eff_subp: sub-path of a close-to-minimum path, 
selected from S */ 
For each combination of specified layer objects 
Eff_path = ø; 
Eff_subp = ø; 
S = ø; 
Do 
{
Step1. Find all shortest paths from Start_n to each 
object instance in End_n using Dijkstra 
algorithm, and add them to S. 
Step2. Filter out all useless paths from S. 
Step3. Choose an efficient sub-path Eff_subp with 
the minimum average cost in S. 
Step4. Delete the object instances on Eff_subp from 
T. 
Eff_path = Eff_path   Eff_subp; 
Step 5. Start_n = the last node in Eff_path; 
End_n = End_n – Start_n; 
Eff_subp = ø; 
S = ø; 
} While (T is not empty); 
Endfor; 
325
2. Layer object page: all objects are spread into a three-
layer hierarchy, and users can select objects at will, as 
shown in Fig. 20. 
3. Object checking page: Uses can check specified objects, 
as shown in Fig. 21. In the page, they can have three 
choices; i.e., 1) re-selecting objects, 2) deciding a 
sequence as shown in Fig. 22, and 3) going down to the 
diameter setting page as shown in Fig. 23. 
4. Route waiting page: after a diameter is set, the routing 
request would be sent to the server. Then, users wait for 
the reply as shown in Fig. 24 till they can download the 
route as shown in Fig. 25. 
B.3 Interface for Tour Arrangement Results 
The interface for tour arrangement results is activated by 
the routing presentation button stated in Section IV.B.1. 
After users download the routing results from the server, 
they  can  press  the  routing  presentation  button  and  the 
routing path would be displayed on mobile devices as 
shown in Fig. 26. 
V. CONCLUSIONS
In general, a huge number of spatial objects and a 
complicated spatial network exist in a Geographic 
Information System (GIS). It is not difficult to find an 
efficient or shortest route in the geographic information 
system if users have given explicit object instances (i.e., 
with precise locations) to be visited no matter what 
sequence of these object instances has been assigned or 
not. In the paper, with the automatic tour arrangement 
provided by our system, users can use mobile devices to 
specify layer objects to be visited of which each may have 
multiple instances in the spatial network. To reach the 
goal, two major algorithms (i.e., the spatial clustering 
algorithm and routing algorithm) were proposed to 
provide the services of efficient tour arrangement. The 
new techniques proposed here not only improved the 
drawbacks of existing GIS technique for finding a routing 
path, but also provided more generic views of schedule 
arrangement problems. 
ACKNOWLEDGMENT
This work was supported by National Science Council 
of R.O.C under Grant NSC99-2220-E-224-005. 
REFERENCES
[1] Will Bamford, Paul Coulton, Reuben Edwards, “Space-time travel 
blogging using a mobile phone,” Proc. ACM International 
Conference on Advances in Computer Entertainment Technology, 
pp. 1-8, 2007. 
[2] Yin-Fu Huang, Chao-Nan Chen, “Implementation for the 
arrangement and mining analysis of traveling schedules,” Journal 
of Information Science and Engineering, Vol. 22, No. 1, pp. 123-
146, 2006. 
[3] Bratislav Predic, Dragan Stojanovic, Slobodanka Djordjevic-
Kajan, “Developing context aware support in mobile GIS 
framework,” Proc. the 9th AGILE Conference on Geographic 
Information Science, pp. 90-97, 2006. 
[4] Gustavo Rossi, Silvia Gordillo, Cecilia Challiol, Andrés Fortier, 
“Context-aware services for physical hypermedia application,” 
OTM Workshop, pp. 1914-1923, 2006. 
[5] M. Sheleiby, M.R. Malek, A. Alesheikh, P. Amirian, “Automatic 
map scaling in car navigation systems using context-aware 
computing,” World Applied Sciences Journal, Vol. 3 (Supple 1), 
pp. 101-106, 2008. 
[6] Kharsim Yousef, Eamonn O'Neill, “Sunrise: towards location 
based clustering for assisted photo management,” Proc. the ICMI 
Workshop on Tagging, Mining and Retrieval of Human Related 
Activity Information, pp. 47-54, 2007. 
Figure 21. Object 
checking page 
Figure 19. Start location 
page 
Figure 20. Layer object 
page 
Figure 22. Deciding a 
sequence 
Figure 23. Diameter 
setting page 
Figure 24. Route 
waiting page 
Figure 25. 
Downloading the 
route 
Figure 26. Routing paths 
327
報告內容應包括下列各項： 
一、參加會議經過 
第四屆太平洋緣影像與視訊技術國際研討會於九十九年十一月十四日至十一月十
七日在新加坡南洋技術大學(NTU)召開。南洋技術大學離樟宜國際機場，乘坐地鐵約一
小時，再換搭巴士約十分鐘才能抵達學校，交通不是很便利。會議地點在學校行政中心
二樓進行，會場提供免費無線網路供與會者上網。第一天是 Tutorials Program，第二天
有大會開幕、兩場 Keynote Presentation、和五個 Sessions 只在一個會場進行。第三天一
場 Keynote Presentation、和五個 Sessions 也只在一個會場進行。第四天五個 Sessions 也
是只在一個會場進行。這次投稿論文有 154 篇論文，但只接受 71 篇論文發表，口頭發
表有 44 篇論文，接受率僅有 28.6%，其中來自台灣的論文有 4 篇，另外海報論文 27 篇，
其中來自台灣的論文有 6 篇。本人於第三天口頭發表論文，跟國外學者互動熱絡。 
 
二、與會心得 
參加本次國際會議感觸良多，尤其能與來自世界各地的知名學者及專家進行學術交
流，獲益甚多。這個研討會的創始國是台灣清華大學，雖然規模不大，但從論文接受率
看，是一個品質相當不錯的研討會，而且由於只在一個會場進行發表，所以互動相當熱
絡。直至目前，這個研討會已在台灣、智利、日本、及新加坡各地舉辦，參與的學者也
是來自世界各地，可見其知名度及影響力，明年將由韓國舉辦！這次主辦單位南洋技術
大學相當熱誠款待，舉如用餐的準備、交通的接送，都盡到地主之誼，讓與會的學者都
覺得不虛此行。這次本人參與了幾個有興趣的場次，如 Social Media Content Mining, 
Object Detection and Recognition, Multimedia Browsing and Understanding；其中有幾個研
究主題甚佳，可考慮作為未來研究的方向。會場大部分的發表者都有出席，而且反應熱
絡，值得國內學術單位學習。 
 
三、建議 
首先感謝國科會在本人專題研究計劃下核給出席國際會議的補助，得與國際知名學
者進行學術交流。儘管在專題研究計劃下核給出席國際會議的機會不易，在此還是建議
國科會應多鼓勵國內學者參與國際會議以增廣見聞並吸收新知；另外國內學術單位也應
積極爭取舉辦知名的國際會議以提昇國際學術知名度，當然會場地點的選擇是相當重
要，國內舉辦過的國際會議地點大多侷限在大學校院，如能在名勝風景區舉辦，則較能
吸引國際知名學者參與。 
 
四、攜回資料名稱及內容 
大會手冊、光碟論文集、及未來國際會議宣傳資料 
 
五、其他 
無 
 
Gaussian Mixture Model (GMM) is an efficient method 
to precisely describe the sample clustering in a feature space. 
In [17], GMM was employed to measure the similarity 
between images of different classes, and the classes are 
merged into an upper class if they are similar to each other. 
The hierarchical structure of classes could enhance the 
performance of classifications. Other applications applying 
GMM are in [23, 25]. 
III. IMAGE ANNOTATION 
In general, without the help of text information to 
annotate an image, most image annotation methods used 
content-based information to achieve the annotation. In 
addition to the main object in an image, background image 
objects and un-specific areas can be used to annotate the 
image. In order to improve annotation accuracy, the 
irrelevant areas can be eliminated from an image before 
extracting the features from the image, and then classifiers 
are built using these extracted features. 
A. System framework 
The system framework as shown in Fig. 1 consists of two 
phases: training phase and annotation phase. The training 
phase could be divided into three stages: 1) main object 
training, 2) background object training, and 3) object 
association analysis. First, a main object detection method is 
proposed to segment the main object from a training image. 
Then, the feature vectors of the main object are extracted to 
train its classifier. The classifier could determine what class 
an image belongs to. Second, we also segment training 
images and extract the features vectors from the background 
objects to train background classifiers. Finally, the main task 
is to perform the association analysis by using a probability 
model called GMM. The object association analysis is to 
find the associations between main objects (or image classes) 
and image background objects, and build the association 
knowledge base. The purpose is to eliminate the irrelevant 
model testing in the annotation phase so that annotation 
accuracy could be improved. 
 
In the annotation phase, we segment a test image and 
extract the feature vectors from a main object. The main 
object classifier would identify the class of the test image. 
Then, the system can retrieve the relevant backgrounds of the 
detected image class from the association knowledge base, 
and the relevant background classifiers would be used to 
detect whether these backgrounds appear in the test image. 
B. Main and background object training 
Here, we explain how to build main and background 
object classifiers which would be used to annotate images in 
the annotation phase. 
1) Main object detection: In the real world, an image is 
usually composed of several objects with different semantic 
meanings. Different image objects have different colors, 
textures, and shapes. Basically, some existing methods 
extract features from hole images in an image classification 
area [1, 17, 19, 20], or block an image to extract features for 
further processing [8, 14]. However, since there are still 
undefined or ambiguous areas in an image, the built 
classifiers could not be precise enough if we only extract 
feature vectors from whole images. To obtain the semantic 
areas of an image, a color image segmentation method 
called JSEG [6] is used. The segmentation result of an 
image using JSEG is shown in Fig. 2. 
 
Although the segmentation result using JSEG is 
appropriate for background objects, the main object in an 
image, in general, is over-segmented. Since the main object 
has been cut into several segments and loses the entirety, the 
feature vectors extracted from the segments of the main 
object are not specific to represent the characteristics any 
more. In order to enable deriving the main object, a Snake 
algorithm to assist the detection is used. The Snake 
algorithm was also known as an Active Contour Model 
(ACM) [9] first proposed by Witkin et al. and widely used 
in medical image analyses and two-dimensional image 
contour detection. While applying ACM, an initial contour 
for the image object and iteration time is set. The edge of 
the initial contour is dynamically altered by modifying an 
energy function. Finally, the contour converges gradually to 
the real edge of the object in an image. In fact, the contour 
alteration would stop until minimizing the energy function 
or reaching specified iteration time. 
Here, the revised ACM algorithm proposed by Lankton et 
al. [11] is adopted in this paper. The well-known defect of 
ACM is the time consuming problem. Thus, the sparse field 
method (SFM) proposed by Whitaker et al. [26] is used to 
improve the efficiency [12]. Because of the variety of 
background color images, the contour of the main object 
would not reach the best convergence if the image has 
(a) (b)
Figure 2. (a) Original image. (b) Segmentation result using JSEG.
Figure 1. System framework. 
Main 
object 
training 
Training images 
Training background images 
Association 
Knowledge 
Base 
Segmentation 
and 
main object 
detection 
Final
annotated 
images 
Training classes 
GMMs 
Feature 
extraction 
Feature 
extraction 
SVMs 
Background 
SVMs 
Segmentation
and 
main object 
detection 
Background
detection 
Test 
image
Background 
object 
training 
Object 
association 
detection 
387
backgrounds of a test image using all background SVMs is 
very inefficient because some specific main object never 
appears in certain kinds of backgrounds. The images in the 
same class have the same main object, and could have 
background consistency. For example, most images 
containing a ship as the main object would have high 
probability with “sky” and “water” in their backgrounds. 
Here, we explore the Gaussian mixture model (GMM) to 
find out the relationship between main objects and 
backgrounds, and build the association knowledge base. In 
the annotation phase, after identifying the main object in an 
image, we discriminate the backgrounds using the 
associating SVMs defined in the association knowledge 
base. 
1) Gaussian mixture model: The GMM is an efficient 
method to precisely describe the sample clustering in the 
feature space. Through the training, proper parameters could 
be obtained to fit with target statistics. The GMM can 
approximate the arbitrary smooth shape of a density 
distribution. The mixture models are a type of probability 
density models which comprise a number of component 
functions, usually Gaussian. The normal method of 
parameter estimation in the GMM is to use the Expectation-
Maximization (EM) algorithm [5], which is a well-
established maximum likelihood algorithm for fitting a 
mixture model to a set of training data. 
2) Building GMMs: The procedure of association 
analysis is shown in Fig. 6. To train the GMM parameters, 
the backgrounds of training images from all predefined 
classes are selected first. Here, sixteen backgrounds are 
defined, including building, bush, flower, grass, ground, 
hedge, macadam, mountain, rail, road, rock, sky, snow, tree, 
water, and others. In this stage, simple and representative 
features are required to approximately build the models. In 
general, color is the most representative feature, so the (Y, 
Cb, Cr) color space is used. Since some background color is 
close to one another, the spatiality of background objects 
should be also considered. The extra spatial feature 
proposed here could effectively improve GMM clustering 
accuracy. Usually the upper-bottom relation in an image is 
more important than the left-right one. For example, “sky” 
is usually located at the top of an image, whereas “road” 
usually at the bottom of an image. 
 
For each specific background, we manually choose 400 
blocks (8*8 pixels) from a set of the corresponding 
background, and calculate the average values of (Y, Cb, Cr) 
in a block as the color feature vector. To extract the spatial 
feature, we partition an image into 16 rows and mark each 
pixel with the corresponding row. Then, the spatial feature 
in a block is also calculated on average. As shown in Fig. 7, 
each block has three color features and one spatial feature. 
Finally, 128 GMMs are used to approximate the statistics of 
each background. 
 
 
 
3) Association analysis: In the association analysis, 
twenty images from each class are used to find the 
relationship between the main object (or class) and 
backgrounds. First, we employ a partition method dividing 
an image into 64 blocks. While disregarding the middle 16 
blocks (or possibly the area of the main object), the 
surrounding 48 blocks are used for background analysis, as 
shown in Fig. 8. 
 
Each pixel of the blocks is fed into the GMMs of all the 
backgrounds trained in advance. The output probability 
shows the likelihood of each pixel of how close to each 
background. Here, we use a simple maximum likelihood 
principle to decide the background for each block, and the 
determination criterion is given as follows. 
  1  2   16
1  2   16
) is
such that background  has {  1  2   16}
k
l , l , l , , ..., ij ij l ij k
,k , , ...,
n l
BG x P( x | arg max P( x )
Block m, m max BG , l , , ...,
θ
θ θ∀ =
=
⎧ ⎫
= ⎨ ⎬⎩ ⎭
= =
where ijx  is a pixel in block n, kθ  is the GMM parameter 
of background k, BGl is a set of pixels closest to background 
l, and nBlock  (n = 1, 2, …, 48) is the background 
indication of block n. The background of block n would be 
dependent on which background has the most number of 
pixels in the block. For an image with multiple 
backgrounds, the determination criterion of the backgrounds 
of the image can be given as follows. 
{ |(No. of blocks with background ) }imageType m m β= ≥  
(a) (b) 
Figure 8. (a) Original image. (b) Blocking an image.
Training 
images 
Background 
region 
selection 
feature 
collection 
GMM 
parameter 
estimation 
Background GMM Models
New image 
(from one 
certain class) 
Partition the  
new image  
into 64 
blocks 
Mark the new 
image  
with detected 
background  
Association
Knowledge 
base
Figure 6. Procedure of association analysis. 
Figure 7. Presentation of a GMM background feature space. 
389
TABLE II. MAIN OBJECT CLASSIFICATION PERFORMANCE 
 
In order to evaluate the background identification 
independently, we assume all test images are annotated with 
correct classes. Then, main objects are removed from the test 
images, and the remaining segments in the images are 
considered as backgrounds where the feature vectors are 
extracted to feed into all background models. The 
background object identification was evaluated from class 
views, as shown in Table III. The experimental results show 
that the background identification of most classes achieves 
more than 75% precision and recall. Since the background 
features of images are quite different from a bird’s eye view, 
these backgrounds are more difficult to identify, thereby 
annotating with irrelevant backgrounds, e.g., airplane and 
eagle. Besides, the background object identification was also 
evaluated from background views, as shown in Table IV. 
Overall, the precision and recall of all backgrounds lead to 
an average number of 70.59% and 88.69%, respectively. Due 
to only few ground truths in some backgrounds, the 
erroneous identification in these backgrounds causes poor 
precision, e.g., hedge and mountain. Besides, “snow” has 
also poor precision because cloudy “sky” sometimes is 
misjudged as “snow”. We found that if backgrounds have 
more specific in color and texture features, they would 
perform better than others, e.g., grass and sky. 
TABLE III. BACKGROUND OBJECT IDENTIFICATION PERFORMANCE FROM 
CLASS VIEWS 
NO. class precision recall F-measure 
1 airplane 65.78% 81.11% 72.65% 
2 building 83.89% 78.33% 81.01% 
3 bus 78.17% 95.00% 85.77% 
4 eagle 56.06% 77.78% 65.16% 
5 elephant 81.65% 93.22% 87.05% 
6 horse 86.44% 95.00% 90.52% 
7 ship 87.78% 90.83% 89.28% 
8 tiger 87.67% 88.50% 88.08% 
9 train 77.83% 86.67% 82.01% 
10 wolf 71.06% 86.67% 78.09% 
 
In order to prevent the misclassification produced in the 
main object classification from being propagated in the final 
annotation, only the images with correct classification would 
be annotated. The final annotation was evaluated as shown in 
Table V. The experimental results show that the final 
annotation of most classes achieves more than 85% precision 
and recall. Besides, they also validate that the system would 
not annotate incorrect backgrounds in an image even if its 
image class implies these backgrounds in the association 
knowledge base. Finally, we also take some annotation 
examples produced by the proposed method, as shown in 
Table VI. 
TABLE IV. BACKGROUND OBJECT IDENTIFICATION PERFORMANCE FROM 
BACKGROUND VIEWS 
Background precision recall F-measure 
1.building 55.17% 82.05% 65.98% 
2.bush 86.66% 89.65% 88.13% 
3.flower 64.70% 95.65% 77.19% 
4.grass 90.55% 92.00% 91.27% 
5.ground 87.80% 85.71% 86.74% 
6.hedge 15.38% 100.00% 26.66% 
7.macadam 80.00% 100.00% 88.89% 
8.mountain 41.17% 70.00% 51.85% 
9.rail 88.00% 81.48% 84.61% 
10.road 90.00% 85.71% 87.80% 
11.rock 71.05% 93.10% 80.59% 
12.sky 92.04% 91.52% 91.78% 
13.snow 46.66% 91.30% 61.76% 
14.tree 76.80% 90.56% 83.11% 
15.water 72.94% 81.57% 77.01% 
TABLE V. FINAL ANNOTATION PERFORMANCE 
NO. class precision recall F-measure
1 airplane 84.30% 88.89% 86.53% 
2 building 86.46% 89.58% 87.99% 
3 bus 87.35% 98.04% 92.39% 
4 eagle 75.63% 100.00% 86.12% 
5 elephant 100.00% 100.00% 100.00% 
6 horse 91.67% 100.00% 95.65% 
7 ship 91.67% 89.68% 90.66% 
8 tiger 94.44% 94.44% 94.44% 
9 train 86.36% 81.82% 84.03% 
10 wolf 80.36% 95.24% 87.17% 
TABLE VI. EXAMPLE OF FINAL ANNOTATION 
Class Airplane Building Bus 
Image 
 
Ground 
truth 
airplane, sky, 
grass, tree 
building, sky, 
road, grass 
bus, sky, tree, 
road 
Automatic 
annotation 
airplane, sky, 
grass, tree 
building, sky, 
road, grass 
bus, sky, tree, 
road 
Class Horse Ship Tiger 
Image 
Ground 
truth 
horse, tree, grass, 
hedge 
ship, sky, water, 
mountain 
tiger, grass, water
Automatic 
annotation 
horse, tree, grass, 
hedge 
ship, sky, water, 
mountain 
tiger, grass, water
NO. class accuracy NO. class accuracy 
1 airplane 66.67% 6 horse 76.66% 
2 building 46.67% 7 ship 80.00% 
3 bus 70.00% 8 tiger 76.66% 
4 eagle 83.33% 9 train 56.67% 
5 elephant 46.67% 10 wolf 60.00% 
391
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/23
國科會補助計畫
計畫名稱: 子計畫四:個人化認知知料庫之建構(2/2)
計畫主持人: 黃胤傅
計畫編號: 99-2220-E-224-005- 學門領域: 自由軟體暨嵌入式系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
