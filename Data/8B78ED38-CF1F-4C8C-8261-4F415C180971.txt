Abstract
Over the last three years of this project, we have studied nite algebraic structures par-
ticularly multivariate public-key cryptosystems that is based on algebraic geometry over
a nite eld. Targets of study was the design and security of such modern multivariates,
in particular we have managed to create a x for the broken C*- (SFLASH) idea, which
was published at ICALP 2008.
We have studied high-speed cryptographic algorithmic implementations for a long
time. We are particularly dedicated to the design and attacks of systems suitable for
small devices. After trying several years, we broke into the top conference Eurocrypt
2009, as well as CHES 2009 and 2010. Another paper has been accepted at Asiacrypt
2010.
Several other results have been published in workshops, and/or being prepared/revised
for submission. I also have other papers in preparation related to discrete structures.
Keywords: multivariate public key cryptosystem, high speed cryptography, nite eld,
graphics processing unit (GPU), algebraic cryptanalysis
Contents
1 `√£√™√ù 3
2 ¬åiW¬å¬ä√ù"T 3
3 ¬î¬å 3
4 List of Attachments 4
2
{[√ù√õD¬â√ï¬∞: √µ|√ÆKb¬∞¬•
Ph!√ù&√Ü√®¬å√ù
√ó√ç¬à?√ù√¨¬•(commitment) ]
n
√ç¬Ä: √å√üE√ç¬Ä√ù.I¬Æ√ù√ó¬∞¬å√ï
P¬Æ, ¬î¬å$3J¬ß
4 List of Attachments
!3√ç¬åi√Ü¬ï√Ñ¬Æ√ü√ù¬î
¬å(√¢Gs3@D¬∫√ù)
1. K.-M. Chung, F.-H. Liu*, C.-
J. Lu, and B.-Y. Yang, Ef-
cient String-Commitment from
Weak Bit-Commitment, to appear
at Asiacrypt 2010 (December 5-9,
Singapore) and a volume of LNCS
.
2. C. Bouillaguet, H.-C. K. Chen, C.-
M. Cheng, T. Chou, R. Niederha-
gen, A. Shamir, and *B.-Y. Yang,
Fast Exhaustive Search for Polyno-
mial Systems in F2 , CHES 2010
(12th Workshop on Cryptographic
Hardware and Embedded Systems,
August 17-20, UC Santa Barbara),
LNCS 6225, pp. 203-218.
3. C.-I Lee*, T.-C. Wu, B.-Y. Yang
and W.-G. Tzeng, New Secure
Broadcasting Scheme Realizing In-
formation Granularity, J. of Infor-
mation Sci. and Eng., 26:4(2010)
pp. 1509-1523.
4. A. I.-T. Chen, M.-S. Chen, T.-
R. Chen, C.-M. Cheng, J. Ding,
E. L.-H. Kuo, F. Y.-S. Lee, and
*B.-Y. Yang, SSE Implementation
of Multivariate PKCs on Modern
x86 CPUs, CHES 2009 (11th Work-
shop on Cryptographic Hardware
and Embedded Systems, Sept. 6-9,
Lausanne, Switzerland), pp. 33-48,
LNCS 5747.
5. D. J. Bernstein, T.-R. Chen, *C.-M.
Cheng, T. Lange, and B.-Y. Yang,
ECM on Video Cards, Eurocrypt
2009 (April 25-29, K√∂ln, Germany)
LNCS 5479, pp. 483-501.
6. J. Baena, M.-S. Chen, C. Clough*,
J. Ding, and B.-Y. Yang, Square,
a New Multivariate Encryption
Scheme, CT-RSA 2009 (April 20-
24, San Francisco), LNCS 5473, pp.
252-264.
7. A. I.-T. Chen, C.-H. O. Chen, M.-
S. Chen, C.-M. Cheng and *B.-Y.
Yang, Practical-Sized Instances of
Multivariate PKCs: Rainbow, and
`IC-derivatives, PQCrypto 2008
(Second Post-Quantum Cryptogra-
phy Workshop, Oct. 17-19, Cincin-
nati, USA) and LNCS 5299, pp. 95-
106.
8. F.-H. Liu, C.-J. Lu, and *B.-Y.
Yang, Secure PRNGs from Spe-
cialized Polynomial Maps over Any
Fq , PQCrypto'08 and LNCS 5299
(ibid.), pp. 181-202.
9. J. Ding, V. Dubois, *B.-Y. Yang,
C.-H. O. Chen, and C.-M. Cheng.
Can SFLASH be Repaired?, ICALP
2008 (35th International Collo-
quium on Automata, Languages
and Programming, July 6-13, Reyk-
javik, Iceland), LNCS 5126, pp.
691-701.
10. J. Ding, *B.-Y. Yang, C.-H. O.
Chen, M.-S. Chen, and C.-M.
Cheng, New Dierential-Algebraic
Attacks and Reparametrization of
Rainbow, ACNS 2008 (6th Applied
Cryptography and Network Secu-
rity Conference, June 3-6, New
York, USA), LNCS 5037, pp. 242-
257. Updates at ePrint 2008/108.
4
34 A.I.-T. Chen et al.
Polynomials p1, p2, . . . have (almost always) been quadratic since MPKCs came
to public notice [30]. Since this is public-key cryptography, we can let P(0) = 0.
Of course, a random P would not be invertible by the legitimate user, so
almost always P = T ‚ó¶ Q ‚ó¶ S with two affine maps S : w ‚Üí x = MSw + cS and
T : y ‚Üí z = MTy+cT , and an ‚Äúefficiently invertible‚Äù quadratic map Q : x ‚Üí y.
The public key then comprise the polynomials in P , while the private key is
M‚àí1s , cs,M
‚àí1
T , cT , plus information to determine the central map Q.
MPKCs have been touted as (a) potentially surviving future attacks using
quantum computers, and (b) faster than ‚Äútraditional‚Äù competitors ‚Äî in 2003,
sflash was a finalist for the NESSIE project signatures, recommended for
embedded use. We seek to evaluate whether (b) is affected by the evolution of
computer architecture. Without going into any theory, we will discuss the imple-
mention of MPKCs on today‚Äôs commodity CPUs. We will conclude that mod-
ern single-instruction-multiple-data (SIMD) units also make great cryptographic
hardware for MPKCs, making them stay competitive speed-wise.
1.1 History and Questions
Conventional wisdom used to be: ‚ÄúMPKCs replace arithmetic operations on large
units (e.g., 1024+-bit integers in RSA, or 160+-bit integers in ECC) by faster
operations on many small units.‚Äù But the latter means many more memory ac-
cesses. People came to realize that eventually the memory latency and bandwidth
would become the bottleneck of the performance of a microprocessor [7, 36].
The playing field is obviously changing. When MPKCs were initially proposed
[25,30], commodity CPUs computed a 32-bit integer product maybe every 15‚Äì20
cycles. When NESSIE called for primitives in 2000, x86 CPUs could compute
one 64-bit product every 3 (Athlon) to 10 (Pentium 4) cycles. The big pipelined
multiplier in an AMD Opteron today can produce one 128-bit integer product
every 2 cycles. ECC implementers quickly exploited these advances.
In stark contrast, a MOSTech 6502 CPU or an 8051 microcontroller from Intel
multiplies in F256 in a dozen instruction cycles (using three table look-ups) ‚Äî
not too far removed from the latency of multiplying in F256 in modern x86.
This striking disparity came about because the number of gates available has
been doubling every 18 to 24 months (‚ÄúMoore‚Äôs Law‚Äù) for the last few decades.
Compared to that, memory access speed increased at a snail‚Äôs pace. Now the
width of a typical arithmetic/logic unit is 64 bits, vector units are everywhere,
and even FPGAs have hundreds of multipliers built in. On commodity hardware,
the deck has never seemed so stacked against MPKCs or more friendly to RSA
and ECC. Indeed, ECC over F2k , the only ‚Äútraditional‚Äù cryptosystem that has
been seemingly left behind by advances in chip architectures, will get a new
special struction from Intel soon ‚Äî the new carryless multiplication [27].
Furthermore, we now understand attacks on MPKCs much better. In 2004,
traditional signature schemes using RSA or ECC are much slower than TTS/4
and SFLASH [1,10,37], but the latter have both been broken [17,18]. Although
TTS/7 and 3IC-p seem ok today [8], the impending doom of SHA-1 [33] will force
longer message digests and thus slower MPKCs while leaving RSA untouched.
36 A.I.-T. Chen et al.
Finally, we reiterate that, like most implementation works such as the one by
Bogdanov et al [6], we only discuss implementation issues and do not concern
ourselves with the security of MPKCs in this paper. Those readers interested in
the security and design of MPKCs are instead referred to the MPKC book [13]
and numerous research papers in the literature.
2 Background on MPKCs
In this section, we summarize the MPKC instances that we will investigate. Using
the notation in Sec. 1, we only need to describe the central map Q (MS and MT
are square and invertible matrices, usu. resp. of dim = n and m, respectively.
To execute a private map, we replace the ‚Äúminus‚Äù components if needed, invert
T , invert Q, invert S, and if needed verify a prefix/perturbation.
Most small-field MPKCs ‚Äî TTS, Rainbow, oil-and-vinegar [11, 12, 17, 29]
seem to behave the same over small odd prime fields and over F2k . Big-field
MPKCs in odd-characteristic were mentioned in [35], but not much researched
until recently. In some cases e.g., IC-derivatives, an odd-characteristic version
is inconvenient but not impossible. Most attacks on and their respective defenses
of MPKCs are fundamentally independent of the base field. Some attacks are
known or conjectured to be easier over binary fields than over small odd prime
fields [5, 19, 9, 15], but never vice versa.
2.1 Rainbow and TTS Families of Digital Signatures
Rainbow(Fq, o1, . . . , o) is characterized as follows as a u-stage UOV [14,17].
‚Äì The segment structure is given by a sequence 0 < v1 < v2 < ¬∑ ¬∑ ¬∑ < vu+1 = n.
For l = 1, . . . , u+ 1, set Sl := {1, 2, . . . , vl} so that |Sl| = vl and S0 ‚äÇ S1 ‚äÇ
¬∑ ¬∑ ¬∑ ‚äÇ Su+1 = S. Denote by ol := vl+1‚àí vl and Ol := Sl+1 \Sl for l = 1 ¬∑ ¬∑ ¬∑u.
‚Äì The central map Q has components yv1+1 = qv1+1(x), yv1+2 = qv1+2(x), . . . ,
yn = qn(x), where yk = qk(x) =
‚àëvl
i=1
‚àën
j=i Œ±
(k)
ij xixj+
‚àë
i<vl+1
Œ≤
(k)
i xi, if k ‚àà
Ol := {vl + 1 ¬∑ ¬∑ ¬∑ vl+1}.
‚Äì In every qk, where k ‚àà Ol, there is no cross-term xixj where both i and j are
in Ol. So given all the yi with vl < i ‚â§ vl+1, and all the xj with j ‚â§ vl, we can
easily compute xvl+1, . . . , xvl+1 . So given y, we guess x1, . . . xv1 , recursively
solve for all xi‚Äôs to invert Q, and repeat if needed.
Ding et al. suggest Rainbow/TTS with parameters (F24 , 24, 20, 20) and (F28 , 18,
12, 12) for 280 design security [8, 17]. According to their criteria, the former
instance should not be more secure than Rainbow/TTS at (F31, 24, 20, 20) and
roughly the same as (F31, 16, 16, 8, 16). Note that in today‚Äôs terminology, TTS is
simply a Rainbow with sparse coefficients, which is faster but less understood.
2.2 Hidden Field Equation (HFE) Encryption Schemes
HFE is a ‚Äúbig-field‚Äù variant of MPKC. We identify L, a degree-n extension of the
base field K with (Fq)
n via an implicit bijective map œÜ : L ‚Üí (Fq)n [34]. With
38 A.I.-T. Chen et al.
a form of SIMD [30]. Berbain et al. pointed out that bit slicing can be extended
appropriately for F16 to evaluate public maps of MPKCs, as well as to run the
QUAD stream cipher [2]. Chen et al. extended this further to Gaussian elimination
in F16, to be used for TTS [8].
To our best knowledge, the only mention of more advanced vector instructions
in the MPKC literature is T. Moh‚Äôs suggestion to use AltiVec instructions (only
available then in the PowerPC G4) in his TTM cryptosystem [31]. This fell into
obscurity after TTM was cryptanalyzed [21].
In this section, we describe one of the most widely deployed vector instruction
sets, namely, the x86 SIMD extensions. The assembly language mnemonics and
code in this section are given according Intel‚Äôs naming convention, which is
supported by both gcc and Intel‚Äôs own compiler icc. We have verified that the
two compilers give similar performance results for the most part.
3.1 Integer Instructions in the SSE2 Instruction Set
SSE2 stands for Streaming SIMD Extensions 2, i.e., doing the same action on
many operands. It is supported by all Intel CPUs since the Pentium 4, all AMD
CPUs since the K8 (Opteron and Athlon 64), as well as the VIA C7/Nano CPUs.
The SSE2 instructions operate on 16 architectural 128-bit registers, called the
xmm registers. Most relevant to us are SSE2‚Äôs integer operations, which treat
xmm registers as vectors of 8-, 16-, 32- or 64-bit packed operands in Intel‚Äôs termi-
nology. The SSE2 instruction set is highly non-orthogonal. To summarize, there
are the following.
Load/Store: To and from xmm registers from memory (both aligned and un-
aligned) and traditional registers (using the lowest unit in an xmm register
and zeroing the others on a load).
Reorganize Data: Various permutations of 16- and 32-bit packed operands
(ShuÔ¨Ñe), and Packing/Unpacking on vector data of different densities.
Logical: AND, OR, NOT, XOR; Shift (packed operands of 16, 32, and 64 bits)
Left, Right Logical and Right Arithmetic (copies the sign bit); Shift entire
xmm register byte-wise only.
Arithmetic: Add/Subtract on 8-, 16-, 32- and 64-bits; Multiply of 16-bit (high
and low word returns, signed and unsigned, and fused multiply-adds) and 32-
bit unsigned; Max/Min (signed 16-bit, unsigned 8-bit); Unsigned Averages
(8/16-bit); Sum-of-differences on 8-bits.
3.2 SSSE3 (Supplementary SSE3) Instructions
SSSE3 adds a few very useful instructions to assist with our vector programming.
PALIGNR (‚Äúpacked align right‚Äù): ‚ÄúPALIGNR xmm (i), xmm (j), k‚Äù shifts xmm (j)
right by k bytes, and insert the k rightmost bytes of xmm (i) in the space
vacated by the shift, with the result placed in xmm (i). Can be used to rotate
an xmm register by bytes.
40 A.I.-T. Chen et al.
4 Arithmetic in Odd Prime Field Fq
4.1 Data Conversion between F2 and Fq
The first problem with MPKCs over odd prime fields is the conversion between
binary and base-q data. Suppose the public map is P : Fnq ‚Üí Fmq . For digital
signatures, we need to have qm > 2, where  is the length of the hash, so that
all hash digests of the appropriate size fit into Fq blocks. For encryption schemes
that pass an -bit session key, we need qn > 2.
Quadword (8-byte) unsigned integers in [0, 264‚àí 1] fit decently into 13 blocks
in F31. So to transfer 128-, 192-, and 256-bit AES keys, we need at least 26, 39,
and 52 F31 blocks, respectively.
Packing Fq-blocks into binary can be more ‚Äúwasteful‚Äù in the sense that one
can use more bits than necessary, as long as the map is injective and convenient
to compute. For example, we have opted for a very simple packing strategy in
which every three F31 blocks are fit in a 16-bit word.
4.2 Basic Arithmetic Operations and Inversion Mod q
Fq operations for odd prime q uses many modulo-q. We almost always replace
slow division instructions with multiplication as follows.
Proposition 1 ( [23]). If 2n+ ‚â§ Md ‚â§ 2n+ + 2 for 2‚àí1 < d < 2, then‚åä
X
d
‚åã
=
‚åä
2‚àí
‚åä
XM
2n
‚åã‚åã
=
‚åä
2‚àí
(‚åä
X(M‚àí2n)
2n
‚åã
+X
)‚åã
for 0 ‚â§ X < 2n.
An instruction giving ‚Äútop n bits of product of n-bit integers x, y‚Äù achieves 
xy2n 
and thus can be used to implement division by multiplication. E.g.,when we take
n = 64,  = 5, and d = 31, Q =
‚åä
1
32
(‚åä
595056260442243601 x
264
‚åã
+ x
)‚åã
= x div 31, R =
x‚àí 31Q, for an unsigned integer x < 264. Note often M > 2n as here.
Inverting one element in Fq is usually via a look-up table. Often we need
to invert simultaneously many Fq elements. As described later, we vectorize
most arithmetic operations using SSE2 and hence need to store the operands in
xmm registers. Getting the operands between xmm and general-purpose registers
for table look-up is very troublesome. Instead, we can use a (q‚àí2)-th power
(‚Äúpatched inverse‚Äù) to invert a vector. For example, the following raises to the
29-th to find multiplicative inverses in F31 using 16-bit integers (short int):
y = x‚àóx‚àóx mod 31; y = x‚àóy‚àóy mod 31; y = y‚àóy mod 31; y = x‚àóy‚àóy mod 31.
Finally, if SSSE3 is available, inversion in a Fq for q < 16 is possible using one
PSHUFB, and for 16 < q ‚â§ 31 using two PSHUFB‚Äôs and some masking.
Overall, the most important optimization is avoiding unnecessary modulo op-
erations by delaying them as much as possible. To achieve this goal, we need to
carefully track operand sizes. SSE2 uses fixed 16- or 32-bit operands for most of
its integer vector operations. In general, the use of 16-bit operands, either signed
or unsigned, gives the best trade-off between modulo reduction frequency (wider
operands allow for less frequent modulo operations) and parallelism (narrower
operands allow more vector elements packed in an xmm register).
42 A.I.-T. Chen et al.
4.5 Solving Systems of Linear Equations
Solving systems of linear equations are involved directly with TTS and Rain-
bow, as well as indirectly in others through taking inverses. Normally, one runs
a Gaussian elimination, where elementary row operations can be sped up by
SSE2.
However, during a Gaussian elimination, one needs frequent modular reduc-
tions, which rather slows things down from the otherwise expected speed. Say
we have an augmented matrix [A|b] modulo 31 in row-major order. Let us do
elimination on the first column. Each entry in the remaining columns will now
be of size up to about 1000 (312), or 250 if representatives are between ¬±16.
To eliminate on the second column, we must reduce that column mod 31
before looking up the correct multipliers. Note that reducing a single column
by table look-up is no less expensive than reducing the entire matrix when the
latter is not too large due to the overhead associated with moving data in and
out of the xmm registers, so we end up reducing the entire matrix many times.
We can switch to an iterative method like Wiedemann or Lanczos. To solve
by Wiedemann an n√ón system Ax = b, one computes zAib for i = 1 . . . 2n for
some given z. Then one computes the minimal polynomial from these elements
in Fq using the Berlekamp-Massey algorithm.
It looks very counter-intuitive, as a Gaussian elimination does around n3/3
field multiplications but Wiedemann takes 2n3 for a dense matrix for the matrix-
vector products, plus extra memory/time to store the partial results and run
Berlekamp-Massey. Yet in each iteration, we only need to reduce a single vector,
not a whole matrix. That is the key observation and the tests show that Wiede-
mann is significantly faster for convenient sizes and odd q. Also, Wiedemann
outperforms Lanczos because the latter fails too often.
5 Arithmetic in Fqk
In a ‚Äúbig-field‚Äù or ‚Äútwo-field‚Äù variant of MPKC, we need to handle L = Fqk ‚àº=
Fq[t]/ (p(t)), where p is an irreducible polynomial of degree k. It is particularly
efficient if p(t) = tk ‚àí a for a small positive a, which is possible k|(q ‚àí 1) and in
a few other cases. With a convenient p, the map X ‚Üí Xq in L, becomes an easy
precomputable linear map over K = Fq. Multiplication, division, and inversion
all become much easier. See some example timing for such a tower field in Tab. 1.
Table 1. Cycle counts for various F3118 arithmetic operations using SSE2
Microarchitecture MULT SQUARE INV SQRT INV+SQRT
C2 (65nm) 234 194 2640 4693 6332
C2+ (45nm) 145 129 1980 3954 5244
K8 (Athlon 64) 397 312 5521 8120 11646
K10 (Phenom) 242 222 2984 5153 7170
44 A.I.-T. Chen et al.
5.3 Multiplicative Inverse
There are several ways to do multiplicative inverses in Fqk . The classical one is an
extended Euclidean Algorithm; another is to solve a system of linear equations;
the last one is to invoke Fermat‚Äôs little theorem and raise to the power of qk‚àí2.
For our specialized tower fields of characteristic 31, the extended Euclidean
Algorithm is slower because after one division the sparsity of the polynomial is
lost. Solving every entry in the inverse as a variable and running an elimination
is about 30% better. Even though it is counter-intuitive to compute X31
15‚àí2 to
get 1/X, it ends up fastest by a factor of 2 to 3.
Finally, we note that when we compute
‚àö
X and 1/X as high powers at the
same time, we can share some exponentiation and save 10% of the work.
5.4 Equation Solving in an Odd-Characteristic Field L = Fqk
Cantor-Zassenhaus solves a univariate degree-d equation u(X) = 0 as follows.
The work is normally cubic in L-multiplications and quintic in (d, k, lg q) overall.
1. Replace u(X) by gcd(u(X), Xq
k ‚àíX) so that u factors completely in L.
(a) Compute and tabulate Xd mod u(X), . . . , X2d‚àí2 mod u(X).
(b) Compute Xq mod u(X) via square-and-multiply.
(c) Compute and tabulate Xqi mod u(X) for i = 2, 3, . . . , d‚àí 1.
(d) Compute Xq
i
mod u(X) for i = 2, 3, . . . , k, then Xq
k
mod u(X).
2. Compute gcd
(
v(X)(q
k‚àí1)/2 ‚àí 1, u(X)
)
for a random v(X), where deg v =
deg u‚àí1; half of the time we find a nontrivial factor; repeat till u is factored.
6 Experiment Results
Clearly, we need to avoid too large q (too many reductions mod q) and too small
q (too large arrays). The choice of q = 31 seems the best compromise, since it
also allows us several convenient tower fields and easy packing conversions (close
to 25 = 32). This is verified empirically.
Some recent implementations of MPKCs over F2k are tested by Chen et al. [8]
We choose the following well-known schemes for comparison: HFE (an encryp-
tion scheme); pFLASH, 3IC-p, and Rainbow/TTS (all signature schemes). We
summarize the characteristics and performances, measured using SUPERCOP-
20090408 [4] on an Intel Core 2 Quad Q9550 processor running at 2.833 GHz, of
these MPKCs and their traditional competitors in Tab. 2. The current MPKCs
are over odd-characteristic fields except for pFLASH, which is over F16. The
table is divided into two regions: top for encryption schemes and bottom for
signature schemes, with the traditional competitors (1024-bit RSA and 160-bit
ECC) listed first. The results clearly indicate that MPKCs can take advantage of
the latest x86 vector instructions and hold their speeds against RSA and ECC.
Tab. 3 shows the speeds of the private maps of the MPKCs over binary vs. odd
fields on various x86 microarchitectures. As in Tab. 1, the C2 microarchitecture
46 A.I.-T. Chen et al.
Intel [32] graphics processors coming. The comparisons herein must of course be
re-evaluated with each new instruction set and new silicon implementation, but
we believe that the general trend stands on our side.
Acknowledgements. CC thanks the National Science Council of Taiwan for
support under grants NSC 97-2628-E-001-010- and Taiwan Information Security
Center (grant 98-2219-E-011-001), BY for grant NSC 96-2221-E-001-031-MY3.
References
1. Akkar, M.-L., Courtois, N.T., Duteuil, R., Goubin, L.: A fast and secure imple-
mentation of SFLASH. In: Desmedt, Y.G. (ed.) PKC 2003. LNCS, vol. 2567, pp.
267‚Äì278. Springer, Heidelberg (2002)
2. Berbain, C., Billet, O., Gilbert, H.: Efficient implementations of multivariate
quadratic systems. In: Biham, E., Youssef, A.M. (eds.) SAC 2006. LNCS, vol. 4356,
pp. 174‚Äì187. Springer, Heidelberg (2007)
3. Bernstein, D.J.: Faster square roots in annoying finite fields. In: High-Speed Cryp-
tography (2001) (to appear), http://cr.yp.to/papers.html#sqroot
4. Bernstein, D.J.: SUPERCOP: System for unified performance evaluation related
to cryptographic operations and primitives (April 2009),
http://bench.cr.yp.to/supercop.html
5. Billet, O., Patarin, J., Seurin, Y.: Analysis of intermediate field systems. Presented
at SCC 2008, Beijing (2008)
6. Bogdanov, A., Eisenbarth, T., Rupp, A., Wolf, C.: Time-area optimized public-
key engines: MQ-cryptosystems as replacement for elliptic curves? In: Oswald, E.,
Rohatgi, P. (eds.) CHES 2008. LNCS, vol. 5154, pp. 45‚Äì61. Springer, Heidelberg
(2008)
7. Burger, D., Goodman, J.R., K√§gi, A.: Memory bandwidth limitations of future
microprocessors. In: Proceedings of the 23rd annual international symposium on
Computer architecture, pp. 78‚Äì89 (1996)
8. Chen, A.I.-T., Chen, C.-H.O., Chen, M.-S., Cheng, C.-M., Yang, B.-Y.: Practical-
sized instances of multivariate pkcs: Rainbow, TTS, and IC-derivatives. In: Buch-
mann, J., Ding, J. (eds.) PQCrypto 2008. LNCS, vol. 5299, pp. 95‚Äì108. Springer,
Heidelberg (2008)
9. Courtois, N.: Algebraic attacks over GF (2k), application to HFE challenge 2 and
SFLASH-v2. In: Bao, F., Deng, R., Zhou, J. (eds.) PKC 2004. LNCS, vol. 2947,
pp. 201‚Äì217. Springer, Heidelberg (2004)
10. Courtois, N., Goubin, L., Patarin, J.: SFLASH: Primitive specification (second
revised version), Submissions, Sflash, 11 pages (2002),
https://www.cosic.esat.kuleuven.be/nessie
11. Ding, J., Dubois, V., Yang, B.-Y., Chen, C.-H.O., Cheng, C.-M.: Could SFLASH
be repaired? In: Aceto, L., Damgard, I., Goldberg, L.A., Halld√≥rsson, M.M., In-
g√≥lfsd√≥ttir, A., Walukiewicz, I. (eds.) ICALP 2008, Part II. LNCS, vol. 5126, pp.
691‚Äì701. Springer, Heidelberg (2008)
12. Ding, J., Gower, J.: Inoculating multivariate schemes against differential attacks.
In: Yung, M., Dodis, Y., Kiayias, A., Malkin, T.G. (eds.) PKC 2006. LNCS,
vol. 3958, pp. 290‚Äì301. Springer, Heidelberg (2006),
http://eprint.iacr.org/2005/255
48 A.I.-T. Chen et al.
30. Matsumoto, T., Imai, H.: Public quadratic polynomial-tuples for efficient signature
verification and message-encryption. In: G√ºnther, C.G. (ed.) EUROCRYPT 1988.
LNCS, vol. 330, pp. 419‚Äì545. Springer, Heidelberg (1988)
31. Moh, T.: A public key system with signature and master key function. Communi-
cations in Algebra 27(5), 2207‚Äì2222 (1999), Electronic version,
http://citeseer/moh99public.html
32. Seiler, L., Carmean, D., Sprangle, E., Forsyth, T., Abrash, M., Dubey, P., Junk-
ins, S., Lake, A., Sugerman, J., Cavin, R., Espasa, R., Grochowski, E., Juan, T.,
Hanrahan, P.: Larrabee: a many-core x86 architecture for visual computing. ACM
Transactions on Graphics 27(18) (August 2008)
33. Wang, X., Yin, Y.L., Yu, H.: Finding collisions in the full sha-1. In: Shoup, V. (ed.)
CRYPTO 2005. LNCS, vol. 3621, pp. 17‚Äì36. Springer, Heidelberg (2005)
34. Wolf, C.: Multivariate Quadratic Polynomials in Public Key Cryptography. PhD
thesis, Katholieke Universiteit Leuven (2005), http://eprint.iacr.org/2005/393
35. Wolf, C., Preneel, B.: Taxonomy of public key schemes based on the problem of
multivariate quadratic equations. Cryptology ePrint Archive, Report 2005/077, 64
pages, May 12 (2005),http://eprint.iacr.org/2005/077/
36. Wulf, W.A., McKee, S.A.: Hitting the memory wall: Implications of the obvious.
Computer Architecture News 23(1), 20‚Äì24 (1995)
37. Yang, B.-Y., Chen, J.-M.: Building secure tame-like multivariate public-key cryp-
tosystems: The new TTS. In: Boyd, C., Gonz√°lez Nieto, J.M. (eds.) ACISP 2005.
LNCS, vol. 3574, pp. 518‚Äì531. Springer, Heidelberg (2005)
204 C. Bouillaguet et al.
with the secret among the variables. This does not break AES as first advertised, but
does break KeeLoq [11], for a recent example, and find a faster collision on 58-round
SHA-1 [24].
Since the pioneering work by Buchberger [9], Gr√∂bner-basis techniques have been
the most prominent tool for this problem, especially after the emergence of faster al-
gorithms such as F4 or F5 [15,16], which broke the first HFE challenge [17]. The
cryptographic community independently rediscovered some of the ideas underlying ef-
ficient Gr√∂bner-basis algorithms as of the XL algorithm [13] and its variants. They also
introduced techniques to deal with special cases, particularly that of sparse systems
[1,23].
In this paper we take a different path, namely improving the standard and seemingly
well-understood exhaustive search algorithm. When the system consists of n randomly
chosen quadratic equations in n variables, all the known solution techniques have ex-
ponential complexity. In particular, Gr√∂bner-basis methods have an advantage on very
overdetermined systems (with many more equations than unknowns) and systems with
certain algebraic ‚Äúweaknesses‚Äù, but were shown to be exponential on ‚Äúgeneric‚Äù enough
systems in [2,3]. In addition, the computation of a Gr√∂bner basis is often a memory-
bound process; since memory is more expensive than time at the scale of interest, such
sophisticated techniques can be inferior in practice when compared to simple testing of
all the possible solutions, which uses almost no memory.
For ‚Äúgeneric‚Äù quadratic systems, experts believe [2,25] that Gr√∂bner basis methods
will go up to degree D0, which is the minimum possible D where the coefficient of tD
in (1+ t)n(1+ t2)‚àím goes negative, and then require the solution of a system of linear
equations with T 
(
n
D0‚àí1
)
variables. This will take at least poly(n)¬∑T 2 bit-operations,
assuming we can afford a sufficiently large amount of memory and that we can solve
such a linear system of equations with non-negligible probability in O(N2+o(1)) time
for N variables. For example, if we assume we can operate a Wiedemann solver on
a T √ó T submatrix of the extended Macaulay matrix of the original system, then the
polynomial is 3n(n ‚àí 1)/2. When m = n = 200, D0 = 25, making the value of T
exceeds 2102; even taking into consideration guessing before solving [6,26], we can still
easily conclude that Gr√∂bner-basis methods would not outperform exhaustive search in
the practically interesting range of m = n ‚â§ 200.
The questions we address are therefore: how far can we go, on both theoretical and
practical sides, by pushing exhaustive search further? Is it possible to design more effi-
cient exhaustive search algorithms? Can we get better performance using different hard-
ware such as GPUs? Is it possible to solve in practice, with a modest budget, a system
of 64 equations in 64 unknowns over F2? Less than 15 years ago, this was considered
so difficult that it even underlied the security of a particular signature scheme [19]. In-
tuitively, some people may consider an algebraic attack that reduces a cryptosystem to
64 equations of degree 4 in 64 F2-variables to be a successful practical attack. However,
the matter is not that easily settled because the complexity of a na√Øve exhaustive search
algorithm would actually be much higher than 264: simply testing all the solutions in a
na√Øve way results in 2 ¬∑
(
64
4
)
¬∑264 ‚âà 284 logical operations, which would make the attack
hardly feasible even on today‚Äôs best available hardware.
206 C. Bouillaguet et al.
Implications. The new exhaustive search algorithm can be used as a black box in
cryptanalysis that needs to solve quadratic equations. This includes, for instance, several
algorithms for the Isomorphism of Polynomials problem [7,22], as well as attacks that
rely on such algorithms, e.g., [8].
We also show with a concrete example that (relatively simple) computations requir-
ing 264 operations can be easily carried out in practice with readily available hardware
and a modest budget. Lastly, we highlight the fact that GPUs have been used success-
fully by the cryptographic community to obtain very efficient implementations of com-
binatorial algorithms or cryptanalytic attacks, in addition to the more numeric-flavored
cryptanalysis algorithm demonstrated by the implementation of the ECM factorization
algorithm on GPUs [5].
Organization of the Paper. Section 2 establishes a formal framework of exhaustive
search algorithms including useful results on Gray Codes and derivatives of multivari-
ate polynomials. Known exhaustive search algorithms are reviewed in Section 3. Our
algorithm to find the zeroes of a single polynomial of any degree is given in Section 4,
and it is extended to find the common zeroes of a collection of polynomials in Sec-
tion 5. Section 6 describes the two platforms on which we implemented the algorithm,
and Section 7 describes the implementation and performance evaluation results.
2 Generalities
In this paper, we will mostly be working over the finite vector space (F2)n. The canon-
ical basis is denoted by (e0, . . . , en‚àí1). We use ‚äï to denote addition in (F2)n, and +
to denote integer addition. We use i k (resp. i k) to denote binary left-shift (resp.
right shift) of the integer i by k bits.
Gray Code. Gray Codes play a crucial role in this paper. Let us denote by bk(i) the
index of the k-th lowest-significant bit set to 1, or ‚àí1 if the hamming weight of i is less
than k. For example, bk(0) = ‚àí1, b1(1) = 0, b1(2) = 1 and b2(3) = 1.
Definition 1. GRAYCODE(i) = i‚äï (i 1).
Lemma 1. For i ‚àà N: GRAYCODE(i+ 1) = GRAYCODE(i)‚äï eb1(i+1).
Derivatives. Define the F2 derivative ‚àÇf‚àÇi of a polynomial with respect to its i-th vari-
able as ‚àÇf
‚àÇi
: x ‚Üí f(x+ ei) + f(x). Then for any vector x, we have:
f(x+ ei) = f(x) +
‚àÇf
‚àÇi
(x) (1)
If f is of total degree d, then ‚àÇf
‚àÇi
is a polynomial of degree d ‚àí 1. In particular, if f is
quadratic, then ‚àÇf
‚àÇi
is an affine function. In this case, it is easy to isolate the constant
part (which is a constant in F2) : ci = ‚àÇf‚àÇi (0) = f(ei) + f(0). Then, the function
x ‚Üí
‚àÇf
‚àÇi
(x) + ci is by definition a linear form and can be represented by a vector
Di ‚àà (F2)
n
. More precisely, we have Di[j] = f (ei + ej) + f (ei) + f (ej) + f (0).
Then equation (1) becomes:
f(x+ ei) = f(x) +Di ¬∑ x+ ci (2)
208 C. Bouillaguet et al.
using a Gray Code, i.e., an ordering of the elements of (F2)n such that two consecutive
elements differ in only one bit. This leads to the algorithm shown below.
1: function INIT(f, _, _)
2: i‚Üê 0
3: x‚Üê 0
4: y‚Üê f(0)
5: For all 0 ‚â§ k ‚â§ n‚àí 1,
initialize ck and Dk
6: end function
1: function NEXT(State)
2: i‚Üê i+ 1
3: k = b1(i)
4: z‚Üê VECTORVECTORPROD(Dk,x)‚äï ck
5: y ‚Üê y ‚äï z
6: x‚Üê x‚äï ek
7: end function
(a) Initialize (b) Update
We believe this technique to be folklore, and in any case it appears more or less ex-
plicitly in the existing literature. Each call to NEXT requires n ANDs, as well as n+ 2
XORs, which makes a total bit operation count of 2(n+1). This is about n/4 times less
than the naive method. Note that when we describe an enumeration algorithm, the vari-
ables that appear inside NEXT are in fact implicit functions of State. The dependency
has been removed to lighten the notational burden.
4 A Faster Recursive Algorithm for Any Degree
We now describe one of the main contributions of this paper, a new algorithm which is
both asymptotically and practically faster than standard exhaustive search in enumer-
ating the solutions of one polynomial equation, as summarized by Theorem 1 below.
Theorem 1. All the zeroes of a single multivariate polynomial f in n variables of de-
gree d can be found in essentially d ¬∑ 2n bit operations (plus a negligible overhead),
using nd‚àí1 bits of read-write memory, and accessing nd bits of constants, after an
initialization phase of negligible complexity O (n2d).
The proof is given in the full version.
Construction of the Recursive Enumeration Algorithm. We will construct an enu-
meration algorithm in two stages. First, if f is of degree 0, then we only need to ‚Äúenu-
merate‚Äù through all vectors by updating with x‚Üê x‚äï eb1(i) at the i-th step.
When f is of higher degree, we need a little more effort. The main idea is that in the
folklore differential algorithm of Sec. 3, the computation of z essentially amounts to
evaluate ‚àÇf
‚àÇk
on something that looks like a Gray Code. We may then use the enumera-
tion algorithm recursively on ‚àÇf
‚àÇk
, since it is a polynomial of strictly smaller degree. The
resulting algorithm is shown below.
It is not difficult to see that the complexity of NEXT isO (d), where d is the degree of
f . The temporal complexity of INIT is nd times the time of evaluating f , which is itself
upper-bounded by nd and its spatial complexity is also of order O
(
nd
)
. This means
that the complexity of the algorithm is O
(
d ¬∑ 2n + n2d
)
. When d = 2, this is about n
times faster than the algorithm described in Sec. 3.
210 C. Bouillaguet et al.
6 A Brief Description of the Hardware Platforms
6.1 Vector Units on x86-64
The most prevalent SIMD (single instruction, multiple data) instruction set today is
SSE2, available on all current Intel-compatible CPUs. SSE2 instructions operate on 16
architectural xmm registers, each of which is 128-bit wide. We use integer operations,
which treat xmm registers as vectors of 8-, 16-, 32- or 64-bit operands.
The highly non-orthogonal SSE instruction set includes Loads and Stores (to/from
xmm registers, memory ‚Äî both aligned and unaligned, and traditional registers), Pack-
ing/Unpacking/Shuffling, Logical Operations (AND, OR, NOT, XOR, Shifts Left,
Right Logical and Arithmetic ‚Äî bit-wise on units and byte-wise on the entire xmm
register), and Arithmetic (add, substract, multiply, max-min) with some or all of the
arithmetic widths. The interested reader is referred to Intel and AMD‚Äôs manuals for de-
tails on these instructions, and to references such as [18] for throughput and latencies.
6.2 G2xx-Series Graphics Processing Units from NVIDIA
We choose NVIDIA‚Äôs G2xx GPUs as they have the least hostile GPU parallel program-
ming environment called CUDA (Compute Unified Device Architecture). In CUDA,
we program in the familiar C/C++ programming language plus a small set of GPU
extensions.
An NVIDIA GPU contains anywhere from 2‚Äì30 streaming multiprocessors (MPs).
There are 8 ALUs (streaming processors or SPs in market-speak) and two super func-
tion units (SFUs) on each MP. A top-end ‚ÄúGTX 295‚Äù card has two GPUs, each with
30 MPs, hence the claimed ‚Äú480 cores‚Äù. The theoretical throughput of each SP per cy-
cle is one 32-bit integer or floating-point instruction (including add/subtract, multiply,
bitwise AND/OR/XOR, and fused multiply-add), and that of an SFU 2 floating-point
multiplications or 1 special operation. The arithmetic units have 20+-stage pipelines.
Main memory is slow and forms a major bottleneck in many applications. The read
bandwidth from memory on the card to the GPU is only one 32-bit read per cycle per
MP and has a latency of > 200 cycles. To ease this problem, the MP has a register file
of 64 KB (16,384 registers, max. of 128 per thread), a 16-bank shared memory of 16
KB, and an 8-KB cache for read-only access to a declared ‚Äúconstant region‚Äù of at most
64 KB. Every cycle, each MP can achieve one read from the constant cache, which can
broadcast to many thread at once.
Each MP contains a scheduling and dispatching unit that can handle a large number
of lightweight threads. However, the decoding unit can only decode once every 4 cycles.
This is typically 1 instruction, but certain common instructions are ‚Äúhalf-sized‚Äù, so two
such instructions can be issued together if independent. Since there are 8 SPs in an
MP, CUDA programming is always on a Single Program Multiple Data basis, where
a ‚Äúwarp‚Äù of threads (32) should be executing the same instruction. If there is a branch
which is taken by some thread in a warp but not others, we are said to have a ‚Äúdivergent‚Äù
warp; from then on only part of the threads will execute until all threads in that warp
are executing the same instruction again. Further, as the latency of a typical instruction
is about 24 cycles, NVIDIA recommends a minimum of 6 warps on each MP, although
it is sometimes possible to get acceptable performance with 4 warps.
212 C. Bouillaguet et al.
or above, then fill in a few blanks. This avoids most of the indexing calculations and all
the calculations involving the most commonly used differentials.
We wrote similar Python scripts to generate unrolled loops in C and CUDA code.
Unrolling is even more critical with GPU, since divergent branching and memory ac-
cesses are prohibitively expensive.
7.2 GPU Enumeration Kernel
register usage. Fast memory is precious on GPU and register usage critical for CUDA
programmers. Our algorithms‚Äô memory complexity grows exponentially with the de-
gree d, which is a serious problem when implementing the algorithm for cubic and
quartic systems, compounded by the immaturity of NVIDIA‚Äôs nvcc compiler which
tends to allocate more registers than we expected.
Take quartic systems as an example. Recall that each thread needs to maintain third
derivatives, which we may call dijk for 0 ‚â§ i < j < k < K, where K is the number of
variables in each small system. For K = 10, there are 120 dijk‚Äôs and we cannot waste
all our registers on them, especially as all differentials are not equal ‚Äî dijk is accessed
with probability 2‚àí(k+1).
Our strategy for register use is simple: Pick a suitable bound u, and among third
differentials dijk (and first and second differentials di and dij ), put the most frequently
used ‚Äî i.e., all indices less than u ‚Äî in registers, and the rest in device memory (which
can be read every 8 instructions without choking). We can then control the number of
registers used and find the best u empirically.
fast conditional move. We discovered during implementation an undocumented fea-
ture of CUDA for G2xx series GPUs, namely that nvcc reliably generates conditional
(predicated) move instructions, dispatched with exceptional adeptness.
...
xor.b32 $r19, $r19, c0[0x000c] // d_y^=d_yz
xor.b32 $p1|$r20, $r17, $r20
mov.b32 $r3, $r1
mov.b32 $r1, s[$ofs1+0x0038]
xor.b32 $r4, $r4, c0[0x0010]
xor.b32 $p0|$r20, $r19, $r20 // res^=d_y
@$p1.eq mov.b32 $r3, $r1
@$p1.eq mov.b32 $r1, s[$ofs1+0x003c]
xor.b32 $r19, $r19, c0[0x0000]
xor.b32 $p1|$r20, $r4, $r20
@$p0.eq mov.b32 $r3, $r1 // cmov
@$p0.eq mov.b32 $r1, s[$ofs1+0x0040] // cmov
...
...
diff0 ^= deg2_block[ 3 ]; // d_y^=d_yz
res ^= diff0; // res^=d_y
if( res == 0 ) y = z; // cmov
if( res == 0 ) z = code233; // cmov
diff1 ^= deg2_block[ 4 ];
res ^= diff1;
if( res == 0 ) y = z;
if( res == 0 ) z = code234;
diff0 ^= deg2_block[ 0 ];
res ^= diff0;
if( res == 0 ) y = z;
if( res == 0 ) z = code235;
...
(a) decuda result from cubin (b) CUDA code for a inner loop fragment
Consider, for example, the code displayed above right. According to our experi-
mental results, the repetitive 4-line code segments average less than three SP (stream-
processor) cycles. However, decuda output of our program shows that each such code
segment corresponds to at least 4 instructions including 2 XORs and 2 conditional
moves [as marked in above left]. The only explanation is that conditional moves can
be dispatched by the SFUs (Special Function Units) so that the total throughput can
exceed 1 instruction per SP cycle. Further note that the annotated segment on the right
corresponds to actual instructions far apart because an NVIDIA GPU does opportunis-
tic dispatching but is nevertheless a purely in-order architecture, so proper scheduling
must interleave instructions from different parts of the code.
214 C. Bouillaguet et al.
Since most of the time, there are exactly two candidate solutions, we expected the Gray
code enumeration to go two-thirds of the way through the subsystem. Merge remaining
candidate solutions with those of Case 2+3, collate for checking in a larger subsystem
if needed, and pass off to the same routine as used in the CPU above. Not unexpectedly,
the runtime is dominated by the thread-check case, since those does millions of cycles
for two candidate solutions (most of the time).
7.4 Partial Evaluation
The algorithm for Partial Evaluation is for the most part the same Gray Code algorithm
as used in the Enumeration Kernel. Also the highest degree coefficients remain constant,
need no evaluation and and can be shared across the entire Enumeration Kernel stage.
As has been mentioned in the GPU description, these will be stored in the constant
memory, which is reasonably cached on NVIDIA CUDA cards. The other coefficients
can be computed by Gray code enumeration, so for example for quadratics we have
(n‚àí s)+2 XOR per w bit-operations and per substitution. In all, the cost of the Partial
Evaluation stage for w‚Ä≤ equations is ‚àº 2s w
‚Ä≤
8
((
n‚àís
d‚àí1
)
+ (smaller terms)
)
byte memory
writes. The only difference in the code to the Enumerative Kernel is we write out the
result (smaller systems) to a buffer, and check for a zero constant term only (to find
all-zero candidate solutions).
Peculiarities of GPUS. Many warps of threads are required for GPUs to run at full
speed, hence we must split a kernel into many threads, the initial state of each small
system being provided by Partial Evaluation. In fact, for larger systems on GPUs, we
do two stages of partial evaluation because
1. there is a limit to how many threads can be spawned, and how many small systems
the device memory can hold, which bounds how small we can split; but
2. increasing s decreases the fast memory pressure; and
3. a small systems reporting two or more candidate solutions is costly, yet we can‚Äôt
run a batch check on a small system with only one candidate solution ‚Äî hence, an
intermediate partial evaluation so we can batch check with fewer variables.
7.5 More Test Data and Discussion
Some minor points which the reader might find useful in understanding the test data, a
full set of which will appear in the extended version.
Candidate Checking. The check code is now 6‚Äì10% of the runtime. In theory (cf.
Sec. 3) evaluation should start with a script which hard-wires a system of equations into
C and compiling to an excutable, eliminating half of the terms, and leading to
(
n‚àís
d
)
SSE2 (half XORs and half ANDs) operations to check one equation forw = 128 inputs.
The check code can potentially become more than an order of magnitude faster. We do
not (yet) do so presently, because compiling may take more time than the checking
code. However, we may want to go this route for even larger systems, as the overhead
from testing for zero bits, re-collating the results, and wasting due to the number of
candidate solutions is not divisible by w would all go down proportionally.
216 C. Bouillaguet et al.
As the Degree d increases. We plot how many cycles is taken by the inner loop (which
is 8 vectors per core for CPUs and 1 vector per SP for GPUs) on different architectures
in Fig. 1. As we can see, all except two architectures have inner loop cycle counts that
are increasing roughly linearly with the degree. The exceptions are the AMD K10 and
NVIDIA G200 architectures, which is in line with fast memory pressure on the NVIDIA
GPUs and fact that K10 has the least cache among the CPU architectures.
More Tuning. We can conduct a Gaussian elimination among the m equations and such
thatm/2 selected terms inm/2 of the equations are all zero. We can of course make this
the most commonly used coefficients (i.e., c01, c02, c12, . . . for the quadratic case). The
corresponding XOR instructions can be removed from the code by our code generator.
This is not yet automated and we have to test everything by hand. However, this clearly
leads to significant savings. On GPUs, we have a speed up of 21% on quadratic cases,
18% for cubics, and 4% for quadratics. [The last is again due to the memory problems.]
Table 2. Efficiency comparison: cycles per candidate tested on one core
n = 32 n = 40 n = 48 Testing platform
d = 2 d = 3 d = 4 d = 2 d = 3 d = 4 d = 2 d = 3 d = 4 GHz Arch. Name USD
0.58 1.21 1.41 0.57 1.27 1.43 0.57 1.26 1.50 2.2 K10 Phenom9550 120
0.57 0.91 1.32 0.57 0.98 1.31 0.57 0.98 1.32 2.3 K10+ Opteron2376 184
0.40 0.65 0.95 0.40 0.70 0.94 0.40 0.70 0.93 2.4 C2 Xeon X3220 210
0.40 0.66 0.96 0.41 0.71 0.94 0.41 0.71 0.94 2.83 C2+ Core2 Q9550 225
0.50 0.66 1.00 0.38 0.65 0.91 0.37 0.62 0.89 2.26 Ci7 Xeon E5520 385
2.87 4.66 15.01 2.69 4.62 17.94 2.72 4.82 17.95 1.296 G200 GTX280 n/a
2.93 4.90 14.76 2.70 4.62 15.54 2.69 4.57 15.97 1.242 G200 GTX295 500
Notes and Acknowledgements
C. Bouillaguet thanks Jean Vuillemin for helpful discussions. The Taiwanese authors
thank Ming-Shing Chen for assistance with programming and fruitful discussion,
Taiwan‚Äôs National Science Council for partial sponsorship under grants NSC96-2221-
E-001-031-MY3,98-2915-I-001-041,and 98-2219-E-011-001(Taiwan Information Se-
curity Center), and Academia Sinica for the Career Development Award. Questions and
esp. corrections about the extended version should be addressed to by@crypto.tw.
References
1. Bard, G.V., Courtois, N.T., Jefferson, C.: Efficient methods for conversion and solution
of sparse systems of low-degree multivariate polynomials over GF(2) via SAT-solvers,
http://eprint.iacr.org/2007/024
2. Bardet, M., Faug√®re, J.-C., Salvy, B.: On the complexity of Gr√∂bner basis computation of
semi-regular overdetermined algebraic equations. In: Proc. Int‚Äôl Conference on Polynomial
System Solving, pp. 71‚Äì74 (2004) INRIA report RR-5049
218 C. Bouillaguet et al.
22. Patarin, J., Goubin, L., Courtois, N.: Improved algorithms for Isomorphisms of Polynomi-
als. In: Nyberg, K. (ed.) EUROCRYPT 1998. LNCS, vol. 1403, pp. 184‚Äì200. Springer,
Heidelberg (1998); Extended ver.: http://www.minrank.org/ip6long.ps
23. Raddum, H.: MRHS equation systems. In: Adams, C., Miri, A., Wiener, M. (eds.) SAC 2007.
LNCS, vol. 4876, pp. 232‚Äì245. Springer, Heidelberg (2007)
24. Sugita, M., Kawazoe, M., Perret, L., Imai, H.: Algebraic cryptanalysis of 58-round SHA-1.
In: Biryukov, A. (ed.) FSE 2007. LNCS, vol. 4593, pp. 349‚Äì365. Springer, Heidelberg (2007)
25. Yang, B.-Y., Chen, J.-M.: Theoretical analysis of XL over small fields. In: Wang, H.,
Pieprzyk, J., Varadharajan, V. (eds.) ACISP 2004. LNCS, vol. 3108, pp. 277‚Äì288. Springer,
Heidelberg (2004)
26. Yang, B.-Y., Chen, J.-M., Courtois, N.: On Asymptotic Security Estimates in XL and Gr√∂b-
ner Bases-Related Algebraic Cryptanalysis. In: L√≥pez, J., Qing, S., Okamoto, E. (eds.) ICICS
2004. LNCS, vol. 3269, pp. 401‚Äì413. Springer, Heidelberg (2004)
484 D.J. Bernstein et al.
Keywords: Factorization, graphics processing unit, modular arithmetic,
elliptic curves, elliptic-curve method of factorization, Edwards curves.
1 Introduction
The elliptic-curve method (ECM) of factorization was introduced by Lenstra
in [34] as a generalization of Pollard‚Äôs p‚àí 1 and Williams‚Äô p+ 1 method. Many
speedups and good choices of elliptic curves were suggested and ECM is now the
method of choice to find factors in the range 1010 to 1060 of general numbers.
The largest factor found by ECM was a 222-bit factor of the 1266-bit number
10381 + 1 found by Dodson (see [49]).
Cryptographic applications such as RSA use ‚Äúhard‚Äù integers with much larger
prime factors. The number-field sieve (NFS) is today‚Äôs champion method of find-
ing those prime factors. It was used, for example, in the following factorizations:
integer bits details reported
RSA‚Äì130 430 at ASIACRYPT 1996 by Cowie et al. [16]
RSA‚Äì140 463 at ASIACRYPT 1999 by Cavallar et al. [12]
RSA‚Äì155 512 at EUROCRYPT 2000 by Cavallar et al. [13]
RSA‚Äì200 663 in 2005 posting by Bahr et al. [4]
21039 ‚àí 1 1039 (special) at ASIACRYPT 2007 by Aoki et al. [2]
A 1024-bit RSA factorization by NFS would be considerably more difficult than
the factorization of the special integer 21039 ‚àí 1 but has been estimated to be
doable in a year of computation using standard PCs that cost roughly $1 billion
or using ASICs that cost considerably less. See [43], [35], [19], [22], [44], and [29]
for various estimates of the cost of NFS hardware. Current recommendations for
RSA key sizes‚Äî2048 bits or even larger‚Äîare based directly on extrapolations
of the speed of NFS.
NFS is also today‚Äôs champion index-calculus method of computing discrete
logarithms in large prime fields, quadratic extensions of large prime fields, etc.
See, e.g., [26], [27], and [5]. Attackers can break ‚Äúpairing-friendly elliptic curves‚Äù
if they can compute discrete logarithms in the corresponding ‚Äúembedding fields‚Äù;
current recommendations for ‚Äúembedding degrees‚Äù in pairing-based cryptogra-
phy are again based on extrapolations of the speed of NFS. See, e.g., [30].
NFS factors a ‚Äúhard‚Äù integer n by combining factorizations of many smaller
auxiliary ‚Äúsmooth‚Äù integers. For example, the factorization of RSA-155 ‚âà 2512
generated a pool of ‚âà 250 auxiliary integers < 2200, found ‚âà 227 ‚Äúsmooth‚Äù inte-
gers factoring into primes < 230, and combined those integers into a factorization
of RSA-155. See [13] for many more details.
Textbook descriptions of NFS state that prime factors of the auxiliary integers
are efficiently discovered by sieving. However, sieving requires increasingly intol-
erable amounts of memory as n grows. Cutting-edge NFS computations control
their memory consumption by using other methods‚Äîprimarily ECM‚Äîto dis-
cover large prime factors. Unlike sieving, ECM remains productive with limited
amounts of memory.
486 D.J. Bernstein et al.
the fastest known ECM implementation to date. For more recent improvements
of bringing together ECMwith the algorithmic advantages of Edwards curves and
improved curve choices we refer to [8] by Bernstein et al.
2.1 Overview of ECM
ECM tries to factor an integer m as follows.
Let E be an elliptic curve over Q with neutral element O. Let P be a non-
torsion point on E. If the discriminant of the curve or any of the denominators
in the coefficients of E or P happens not to be coprime with m without being
divisible by it we have found a factor and thus completed the task of finding
a nontrivial factor of m; if one of them is divisible by m we choose a different
pair (E,P ). We may therefore assume that E has good reduction modulo m. In
particular we can use the addition law on E to define an addition law on EÀú, the
reduction of E modulo m; let PÀú ‚àà EÀú be the reduction of P modulo m.
Let œÜ be a rational function on E which has a zero at O and has non-zero
reduction of œÜ(P ) modulo m. In the familiar case of Weierstrass curves this
function can simply be Z/Y . For elliptic curves in Edwards form a similarly
simple function exists; see below.
Let s be an integer that has many small factors. A standard choice is s =
lcm(1, 2, 3, . . . , B1). Here B1 is a bound controlling the amount of time spent
on ECM. The main step in ECM is to compute R = [s]PÀú . The computation of
the scalar multiple [s]PÀú on EÀú is done using the addition law on E and reducing
intermediate results modulo m.
One then checks gcd(œÜ(R),m); ECM succeeds if the gcd is nontrivial. If this
first step‚Äîcalled stage 1‚Äîwas not successful then one enters stage 2, a postpro-
cessing step that significantly increases the chance of factoring m. In a simple
form of stage 2 one computes R1 = [pk+1]R,R2 = [pk+2]R, . . . , R = [pk+]R
where pk+1, pk+2, . . . , pk+ are the primes between B1 and another bound B2,
and then does another gcd computation gcd(œÜ(R1)œÜ(R2) ¬∑ ¬∑ ¬∑œÜ(R),m). There
are more effective versions of stage 2. Stage 2 takes significantly less time than
stage 1 when ECM as a whole is optimized.
If q is a prime divisor of m, and the order of P modulo q divides s, then
œÜ([s]PÀú ) ‚â° 0 (mod q). If œÜ([s]PÀú ) ‚â° 0 mod m we obtain a nontrivial factor of
m in stage 1 of ECM as gcd(m,œÜ([s]PÀú )). This happens exactly if there are two
prime divisors of m such that s is divisible by the order of P modulo one of them
but not modulo the other. Choosing s to have many small factors increases the
chance ofm having at least one prime divisor q such that the order of P modulo q
divides s. Note that it is rare that this happens for all factors ofm simultaneously
unless s is huge.
Similar comments apply to stage 2, with s replaced by spk+1, spk+2, etc.
Trying a single curve with a large B1 is usually less effective than spending
the same amount of time trying many curves, each with a smaller B1. For each
curve one performs stage 1 and then stage 2.
488 D.J. Bernstein et al.
Along with the G80 series of GPUs, NVIDIA introduced CUDA, a parallel
computing framework with a C-like programming language specifically intended
for compilation and execution on a GPU. In this section we describe current
NVIDIA graphics cards used for our implementations, give some background in-
formation on CUDA programming, and compare NVIDIA GPUs to AMD GPUs.
3.1 The NVIDIA Cards Used for CUDA
An NVIDIA GPU contains many streaming multiprocessors (MPs), each of
which contains the following elements:
‚Äì a scheduling and dispatching unit that can handle many lightweight threads;
‚Äì eight (8) ‚Äúcores‚Äù (often called streaming processors, or SPs) each capable of a
fused single-precision floating-point multiply-and-add (MAD), or otherwise
one 32-bit integer add/subtract or logical operation every cycle;
‚Äì two (2) ‚Äúsuper function units‚Äù that each can do various complex computa-
tions like 32-bit integer multiplications, floating-point divisions, or two (2)
single-precision floating-point multiplications per cycle;
‚Äì for the more advanced GT2xx GPUs, additional circuitry that in conjunction
with the SPs can do double-precision floating-point arithmetic, albeit with
a lower throughput (roughly 1/6 of that of single-precision counterpart);
‚Äì fast local shared memory, 16 banks of 1 kB each;
‚Äì controllers to access uncached thread-local and global memory;
‚Äì fast local read-only cache to device memory on the card, up to 8 kB;
‚Äì fast local read-only cache on, and access to, a texture unit (2 MPs on a G8x
or G9x, and 3 MPs on a GT2xx form a cluster sharing a texture unit);
‚Äì a file of 8192 (for G8x or G9x) or 16384 (for GT2xx) 32-bit registers.
Uncached memory has a relatively low throughput and long latency. For example,
the 128 SPs on a GeForce 8800 GTX run at 1.35 GHz, and the uncached memory
provides a throughput of 86.4 GB/s. That may sound impressive but it is only a
single 32-bit floating-point number per cycle per MP, with a latency of 400‚Äì600
cycles to boot.
The GPU can achieve more impressive data movement by broadcasting the
same data to many threads in a cycle. The shared memory in an MP can deliver
64 bytes every two cycles, or 4 bytes per cycle per SP if there is no bank conflict.
Latencies of all caches and shared memories are close to that of registers and
hence much lower than device memories.
G8x/G9x Series. The chip used in the GeForce 8800 GTX is a typical NVIDIA
G80-series GPU, a 90nm-process GPU containing 128 SPs grouped into 16 MPs.
G92 GPUs are a straightforward die shrink of the G80 to a 65nm process and
were used in the GeForce 8800 GTS 512 (16 MPs, not to be confused with the
‚Äú8800 GTS 384‚Äù, a G80) and 9800-series cards, e.g., the 9800 GTX (16 MPs)
and 9800 GX2 (two 9800 GTX‚Äôs on a PCI Express bridge).
GPUs codenamed G84/G85/G86 are NVIDIA‚Äôs low-end parts of the G80
series, with the same architecture but only 1‚Äì4 MPs and much lower memory
490 D.J. Bernstein et al.
executed by a single MP. It takes four cycles for an MP to issue an instruction for
a warp of threads (16 if the instruction is to be executed by the super function
units). To achieve optimal instruction throughput, the threads belonging to the
same warp must execute the same instruction, for there is only one instruction-
decoding unit on each MP. We may hence regard an MP as a 32-way SIMD
vector processor.
We note that the GPU threads are lightweight hardware threads, which incur
little overhead in context switch. In order to support fast context switch, the
physical registers are divided among all active threads. This creates pressure
when programming GPUs. For example, on G80 and G92 there are only 8192
registers per MP. If we were to use 256 threads, then each thread could only use
32 registers, a tight budget for implementing complicated algorithms. The situ-
ation improved with the GT2xx family having twice as many registers, relieving
the register pressure and making programming much easier.
To summarize, the massive parallelism in NVIDIA‚Äôs GPU architecture makes
programming on graphics cards very different from sequential programming on
a traditional CPU. In general, GPUs are most suitable for executing the data-
parallel part of an algorithm. Finally, to get the most out of the theoretical
arithmetic throughput, one must minimize the number of memory accesses and
meticulously arrange the parallel execution of hardware threads to avoid resource
contention such as bank conflict in memory access.
3.3 Limitations and Alternatives
Race Conditions and Synchronization. A pitfall frequently encountered
when programming multiple threads is race conditions. In CUDA, threads are
organized into ‚Äúblocks‚Äù so that threads belonging to the same block execute on
the same MP and time-share the SPs on a per-instruction, round-robin fashion.
Sometimes, the execution of a block of threads will need to be serialized when
there is resource contention, e.g., when accessing device memory, or accessing
shared memory when there is a bank conflict. Synchronization among a block
of threads is achieved by calling the intrinsic syncthreads() primitive, which
blocks the execution until all threads in a block have reached the same point in
the program stream. Another use of this primitive is to set up synchronization
barriers. Without such barriers, the optimizing compiler can sometimes reorder
the instructions too aggressively, resulting in race conditions when the code is
executed concurrently by a block of threads.
Pressure on Fast On-die Memories. A critically limited GPU resource is
memory‚Äî in particular, fast memory‚Äî including per-thread registers and per-
MP shared memory. For example, on a G8x/G9x/G2xx GPU the per-SP working
set of 2 kB is barely enough room to hold the base point and intermediate point
for a scalar multiplication on an elliptic curve without any precomputation. To
put this in perspective, all 240 SPs on a gigantic (1.4 √ó 109 gates) GTX 280
have between them 480 kB fast memory. That is less than the 512 kB of L2
cache in an aged Athlon 64 (1.6 √ó 108 gates)! Unfortunately, CUDA requires
492 D.J. Bernstein et al.
ECM‚Äôs storage pressure makes GeForce cards more suitable than Radeon cards
for ECM.
4 High-Throughput Modular Arithmetic on a GPU
Modular arithmetic is the main bottleneck in computing scalar multiplication
in ECM. In this section we describe our implementation of modular arithmetic
on a GPU, focusing specifically on modular multiplication, the rate-determining
mechanism in ECM. We will explain the design choices we have made and show
how parallelism is used on this level.
4.1 Design Choices of Modular Multiplication
For our target of 280-bit integers, schoolbook multiplication needs less inter-
mediate storage space and synchronization among cooperative threads than the
more advanced algorithms such as Karatsuba. Moreover, despite requiring a
smaller number of word multiplications, Karatsuba multiplication is slower on
GPUs because there are fewer pairs of multiplications and additions that can be
merged into single MAD instructions, resulting in a higher instruction count. It
is partly for this reason that we choose to implement the modular multiplier us-
ing floating-point arithmetic as opposed to 32-bit integer arithmetic, which does
not have the fused multiply-and-add instruction; another reason is that floating-
point multiplication currently has a higher throughput on NVIDIA GPU than
its 32-bit integer counterpart.
We represent an integer using L limbs in radix 2r, with each limb stored as
a floating-point number between ‚àí2r‚àí1 and 2r‚àí1. This allows us to represent
any integer between ‚àíR/2 and R/2, where R = 2Lr. We choose to use Mont-
gomery representation [37] of the integers modulo m, where m is the integer
to be factored by ECM, and thus represent x mod m as x‚Ä≤ ‚â° Rx (mod m).
Note that our limbs can be negative, so we use a signed representative in
‚àím/2 ‚â§ (x‚Ä≤ mod m) < m/2. In Montgomery representation, addition and sub-
traction are performed on the representatives as usual. Let m‚Ä≤ be the unique
positive integer between 0 and R such that RR‚Ä≤ ‚àí mm‚Ä≤ = 1. Given x‚Ä≤ ‚â° Rx
(mod m) and y‚Ä≤ ‚â° Ry (mod m) the multiplication is computed on the repre-
sentatives as Œ± = (x‚Ä≤y‚Ä≤ mod R)m‚Ä≤ mod R followed by Œ≤ = (x‚Ä≤y‚Ä≤ + Œ±m)/R. Note
that since R is a power of 2, modular reductions modulo R correspond to taking
the lower bits while divisions by R correspond to taking the higher bits. One
verifies that ‚àím < Œ≤ < m and Œ≤ ‚â° R(xy) (mod m).
The Chosen Parameters. In the implementation described in this paper we
take L = 28 and r = 10. Thus, we can handle integers up to around 280 bits. To
fill up each MP with enough threads to effectively hide the instruction latency,
we choose a block size of 256 threads; together such a block of threads is in
charge of computing eight 280-bit arithmetic operations at a time. This means
that we have an 8-way modular multiplier per MP. Each modular multiplication
494 D.J. Bernstein et al.
Step MAU 1 MAU 2
1 A=X21 B=Y
2
1 S
2 X1=X1 + Y1 C=A+ B a
3 X1=X
2
1 Z1=Z
2
1 S
4 X1=X1 ‚àí C Z1=Z1 + Z1 a
5 B=B ‚àí A Z1=Z1 ‚àí C a
6 X1=X1 √ó Z1 Y1=B √ó C M
7 A=X1 √óX1 Z1=Z1 √ó C M
8 Z1=Z
2
1 B=Y
2
1 S
9 Z1=Z1 + Z1 C=A+ B a
10 B=B ‚àí A X1=X1 + Y1 a
11 Y1=B √ó C X1=X1 √óX1 M
12 B=Z1 ‚àí C X1=X1 ‚àíC a
13 Z1=B √ó C X1=X1 √óB M
4M+3S+6a
Fig. 1. Explicit formulas for DBL-DBL
The CPU first prepares the curve parameters (including the coordinates of
the starting point) in an appropriate format and passes them to the GPU for
scalar multiplication, whose result will be returned by the GPU. The CPU then
does the gcd computation to determine whether we have found any factors.
Our implementation of modular arithmetic in essence turns an MP in a GPU
into an 8-way modular arithmetic unit (MAU) that is capable of carrying out
8 modular arithmetic operations simultaneously. How to map our elliptic-curve
computation onto this array of 8-way MAUs on a GPU is of crucial importance.
We have explored two different approaches to use the 8-way MAUs we have
implemented. The first one is straightforward: we compute on 8 curves in parallel,
each of which uses a dedicated MAU. This approach results in 2 kB of working
memory per curve, barely enough to store the curve parameters (including the
base point) and the coordinates of the intermediate point. Besides the base point,
we cannot cache any other points, which implies that the scalar multiplication
can use only a non-adjacent form (NAF) representation of s. So we need to
compute log2 s doublings and on average (log2 s)/3 additions to compute [s]PÀú .
In the second approach, we combine 2 MAUs to compute the scalar multipli-
cation on a single curve. As mentioned in Sections 2 and 4, our implementation
uses Montgomery representation of integers, so it does not benefit from multipli-
cations with small values. In particular, multiplications with the curve coefficient
d take the same time as general multiplications. We provide the base point and
all precomputed points (if any) in affine coordinates, so all curve additions are
mixed additions. Inspecting the explicit formulas, one notices that both addition
and doubling require an odd number of multiplications/squarings. In order to
avoid idle multiplication cycles, we have developed new parallel formulas that
pipeline two group operations. The scalar multiplication can be composed of the
building blocks DBL-DBL (doubling followed by doubling), mADD-DBL (mixed
addition followed by doubling) and DBL-mADD. Note that there are never two
496 D.J. Bernstein et al.
Step MAU 1 MAU 2
1 A=X21 B=Y
2
1 S
2 X1=X1 + Y1 C=A + B a
3 X1=X
2
1 Z1=Z
2
1 S
4 X1=X1 ‚àí C Z1=Z1 + Z1 a
5 B=B ‚àí A Z1=Z1 ‚àí C a
6 X1=X1 √ó Z1 Y1=B √ó C M
7 Z1=Z1 √ó C A=X1 √ó Y1 M
8 B=x2 √ó Z1 C=y2 √ó Z1 M
9 E=X1 ‚àíB F=Y1 + C a
10 X1=X1 + C Y1=Y1 + B a
11 E=E √ó F Z1=B √ó C M
12 F=A + Z1 B=A‚àí Z1 a
13 E=E ‚àíB Z1=X1 a
14 A=Z1 √ó Y1 X1=E √ó F M
15 A=A‚àí F a
16 Z1=E √ó A Y1=A√óB M
6M+2S+8a
Fig. 3. Explicit formulas for DBL-mADD
space. With these precomputations we can use a signed-sliding-window method
to compute [s]PÀú . This reduces the number of mixed additions to an average of
(log2 s)/6 (and worst case of (log2 s)/5).
6 Experimental Results
We summarize our results in Tables 2 and 3. Our experiments consist of running
stage-1 ECM on the product of two 140-bit prime numbers with B1 ranging
from 210 to 220 on various CPUs and GPUs. For CPU experiments, we run
GMP-ECM, the state-of-the-art implementation of ECM, whereas for GPU ex-
periments, we run our GPU ECM implementation as described in Sections 4
and 5.
The first column of each table lists the coprocessors. The next three columns
list their specifications: number of cores, clock frequency, and theoretical maxi-
mal arithmetic throughput (Rmax). Note that the Rmax figures tend to underes-
timate CPUs‚Äô computational power while overestimating GPUs‚Äô because CPUs
have wider data paths and are better at exploiting instruction-level parallelism.
Also, in calculating GPUs‚Äô Rmax, we exclude the contribution from texture pro-
cessing units because we do not use them. The next two columns give the actual
performance numbers derived from our measurements.
Table 2 includes an extra row, the first row, that does not correspond to
any experiments we have performed. This row is extrapolated from the result of
Szerwinski and Gu¬®neysu published in CHES 2008 [46]. In their result, the scalar
in the scalar multiplications is 224 bits long, whereas in our experiments, it is
11797 bits long. Therefore, we have scaled their throughput by 224/11797 to fit
498 D.J. Bernstein et al.
Table 3. Price-performance results of stage-1 ECM
Coprocessor
Component-wise System-wise
Cost performance/cost Cost performance/cost
(Ôú§) (1/(sec¬∑ Ôú§)) (Ôú§) (1/(sec¬∑ Ôú§))
8800 GTS (G80) 119 0.48 1005 0.1140
8800 GTS (G92) 178 0.59 1123 0.1855
GTX 260 275 0.43 1317 0.1808
GTX 280 334 0.46 1435 0.2164
Core 2 Duo E6850 172 0.44 829 0.0907
Core 2 Quad Q6600 189 0.66 847 0.1472
Core 2 Quad Q9550 282 0.50 939 0.1541
GTX 260 (parallel) 275 0.60 1317 0.2515
GTX 280 (parallel) 334 0.65 1435 0.3021
GTX 295 (parallel) 510 0.79 2001 0.4005
Q6600+GTX 295√ó2 1210 0.77 2226 0.4160
modular multiplication consumes about 27454 floating-point operations, which
can be delivered in 13727 GPU instructions. Given that 32 threads are dedicated
to computing one singlemodularmultiplication, each thread gets to execute about
429 instructions per modular multiplication. This number is about 60%more than
what we have estimated.We believe that the difference is due to the fact that there
are other minor operations such as modular additions and subtractions, as well as
managerial operations like data movement and address calculations.
Table 3 shows price-performance figures for different ECM coprocessors. For
each coprocessor, the next column shows the cheapest retail price pulled from
on-line vendors such as NewEgg.com as of January 23, 2009, which in turn gives
the per-US-dollar scalar-multiplication throughput listed in the next column.
This price-performance ratio can be misleading because one could not com-
pute ECM with a bare CPU or GPU‚Äîone needs a complete computer system
with a motherboard, power supply, etc. In the last column we give the per-US-
dollar scalar-multiplication throughput for an entire ECM computing system,
based on the advice given by a web site for building computer systems of good
price-performance ratio [6]. The baseline configuration consists of one dual-PCI-
Express motherboard and one 750 GB hard drive in a desktop enclosure with a
built-in 430-Watt power supply and several cooling fans. For CPU systems, we
include the CPU, 8 GB of ECC RAM, and a low-price graphics card. In contrast,
for GPU systems we include two identical graphics cards (since the motherboard
can take two video cards). We also add a 750-Watt (1200-Watt in the case of
GTX 295) power supply in order to provide enough power for the two graphics
cards, plus a lower-priced Celeron CPU and 2 GB of ECC RAM. This is justi-
fied because when we use GPUs for ECM computation, we use the CPU only
for light, managerial tasks. Finally, the configuration in the last row has both
CPU and GPU working on ECM, which achieves the best price-performance ra-
tio since the cost of the supporting hardware is shared by both CPU and GPUs.
500 D.J. Bernstein et al.
13. Cavallar, S., Dodson, B., Lenstra, A.K., Lioen, W., Montgomery, P.L., Murphy,
B., te Riele, H., Aardal, K., Gilchrist, J., Guillerm, G., Leyland, P., Marchand, J.,
Morain, F., Muffett, A., Putnam, C., Putnam, C., Zimmermann, P.: Factorization
of a 512-Bit RSA Modulus. In: EUROCRYPT 2000 [41], pp. 1‚Äì18 (2000) (Cited in
¬ß1, ¬ß1)
14. Cook, D.L., Ioannidis, J., Keromytis, A.D., Luck, J.: CryptoGraphics: Secret Key
Cryptography Using Graphics Cards. In: CT-RSA 2005 [36], pp. 334‚Äì350 (2005)
(Cited in ¬ß3)
15. Debra, L., Cook, A.D.: CryptoGraphics: Exploiting Graphics Cards For Security.
In: Advances in Information Security, vol. 20. Springer, Heidelberg (2006) (Cited
in ¬ß3)
16. Cowie, J., Dodson, B., Elkenbracht-Huizing, R.M., Lenstra, A.K., Montgomery,
P.L., Zayer, J.: A World Wide Number Field Sieve Factoring Record: On to 512
Bits. In: ASIACRYPT 1996 [28], pp. 382‚Äì394 (1996) (Cited in ¬ß1)
17. Dwork, C. (ed.): CRYPTO 2006. LNCS, vol. 4117. Springer, Heidelberg (2006) See
[27]
18. Edwards, H.M.: A normal form for elliptic curves. Bulletin of the American
Mathematical Society 44, 393‚Äì422 (2007),
http://www.ams.org/bull/2007-44-03/S0273-0979-07-01153-6/home.html
(Cited in ¬ß2.2)
19. Franke, J., Kleinjung, T., Paar, C., Pelzl, J., Priplata, C., Stahlke, C.: SHARK:
A Realizable Special Hardware Sieving Device for Factoring 1024-Bit Integers. In:
CHES 2005 [42], pp. 119‚Äì130 (2005) (Cited in ¬ß1, ¬ß1)
20. Gaj, K., Kwon, S., Baier, P., Kohlbrenner, P., Le, H., Khaleeluddin, M., Bachi-
manchi, R.: Implementing the Elliptic Curve Method of Factoring in Reconfigurable
Hardware. In: CHES 2006 [23], pp. 119‚Äì133 (2006) (Cited in ¬ß1)
21. Galbraith, S.D. (ed.): Cryptography and Coding 2007. LNCS, vol. 4887. Springer,
Heidelberg (2007) See [38]
22. Geiselmann, W., Shamir, A., Steinwandt, R., Tromer, E.: Scalable Hardware for
Sparse Systems of Linear Equations, with Applications to Integer Factorization.
In: CHES 2005 [42], pp. 131‚Äì146 (2005) (Cited in ¬ß1)
23. Goubin, L., Matsui, M. (eds.): CHES 2006. LNCS, vol. 4249. Springer, Heidelberg
(2006) See [20]
24. Hess, F., Pauli, S., Pohst, M. (eds.): ANTS 2006. LNCS, vol. 4076. Springer, Hei-
delberg (2006) See [48]
25. Hisil, H., Wong, K., Carter, G., Dawson, E.: Faster group operations on elliptic
curves (2007), http://eprint.iacr.org/2007/441 (Cited in ¬ß2.2)
26. Joux, A., Lercier, R.: Improvements to the general number field sieve for discrete
logarithms in prime fields. A comparison with the Gaussian integer method, Math-
ematics of Computation 72, 953‚Äì967 (2003) (Cited in ¬ß1)
27. Joux, A., Lercier, R., Smart, N.P., Vercauteren, F.: The Number Field Sieve in the
Medium Prime Case. In: CRYPTO 2006 [17], pp. 326‚Äì344 (2006) (Cited in ¬ß1)
28. Kim, K.-c., Matsumoto, T. (eds.): ASIACRYPT 1996. LNCS, vol. 1163. Springer,
Heidelberg (1996) See [16]
29. Kleinjung, T.: Cofactorisation strategies for the number field sieve and an estimate
for the sieving step for factoring 1024-bit integers. In: Proceedings of SHARCS
(2006), http://www.math.uni-bonn.de/people/thor/cof.ps (Cited in ¬ß1, ¬ß1)
30. Koblitz, N., Menezes, A.: Pairing-Based Cryptography at High Security Levels. In:
Coding and Cryptography [45], pp. 13‚Äì36 (2005) (Cited in ¬ß1)
31. Kurosawa, K. (ed.): ASIACRYPT 2007. LNCS, vol. 4833. Springer, Heidelberg
(2007) See [2], [10]
Practical-Sized Instances of Multivariate PKCs:
Rainbow, TTS, and `IC-derivatives
Anna Inn-Tung Chen1, Chia-Hsin Owen Chen2, Ming-Shing Chen2,
Chen-Mou Cheng1, and Bo-Yin Yang2???
1 Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan
2 Institute of Information Science, Academia Sinica, Taipei, Taiwan
Abstract. We present instances of MPKCs (multivariate public key
cryptosystems) with design, given the best attacks we know, and im-
plement them on commodity PC hardware. We also show that they can
hold their own compared to traditional alternatives. In fact, they can be
up to an order of magnitude faster.
Keywords: Gro¬®bner basis, multivariate public key cryptosystem
1 Introduction
MPKCs (multivariate public key cryptosystems) [15,31] are PKCs whose public
keys are multivariate polynomials in many small variables. It has two properties
that are often touted: Firstly, it is considered a significant possibility for Post-
Quantum Cryptography, with potential to resist future attacks with quantum
computers. Secondly, it is often considered to be faster than the competition.
Extant MPKCs almost always hide the private map Q via composition with
two affine maps S, T . So, P = (p1, . . . , pm) = T ‚ó¶ Q ‚ó¶ S : K
n ‚Üí Km, or
P : w = (w1, . . . , wn)
S
7‚Üí x = MSw + cS
Q
7‚Üí y
T
7‚Üí z = MTy + cT = (z1, . . . , zm)
(1)
The public key consists of the polynomials in P. P(0) is always taken to be zero.
In any given scheme, the central map Q belongs to a certain class of quadratic
maps whose inverse can be computed relatively easily. The maps S, T are affine
(sometimes linear) and full-rank. The xj are called the central variables. The
polynomials giving yi in x are called the central polynomials; when necessary
to distinguish between the variable and the value, we will write yi = qi(x).
The key of a MPKC is the design of the central map because, solving a generic
multivariate quadratic system is hard, so the best solution for finding w given z
invariably turns to other means, which depend on the structure of Q.
1.1 Questions
Four or five years ago, it was shown that instances of TTS and C‚àó‚àí, specifically
TTS/4 and SFLASH, are faster signature schemes than traditional competition
? E-mails addresses: {anna1110,mschen,owenhsin,doug,by}@crypto.tw
?? Official correspondence to BY (also at by@moscito.org)
Rainbow, TTS, and `IC-derivative 3
Scheme result SecrKey PublKey KeyGen SecrMap PublMap
PMI+(136, 6, 18, 8) 144b 5.5 kB 165 kB 350.8 Mclk 335.4 kclk 51.4 kclk
PMI+(136, 6, 18, 8)64b 144b 5.5 kB 165 kB 350.4 Mclk 333.9 kclk 46.5 kclk
rainbow (28, 18, 12, 12) 336b 24.8 kB 22.5 kB 110.7 Mclk 143.9 kclk 121.4 kclk
rainbow (24, 24, 20, 20) 256b 91.5 kB 83 kB 454.0 Mclk 210.2 kclk 153.8 kclk
rainbow (24, 24, 20, 20)64b 256b 91.5 kB 83 kB 343.8 Mclk 136.8 kclk 79.3 kclk
TTS (28, 18, 12, 12) 336b 3.5kB 22.5kB 11.5 Mclk 35.9 kclk 121.4 kclk
TTS (24, 24, 20, 20) 256b 5.6kB 83kB 175.7 Mclk 64.8 kclk 78.9 kclk
2IC+i (128,6,16) 144b 5 kB 165 kB 324.7 Mclk 8.3 kclk 52.0 kclk
2IC+i (128,6,16)64b 144b 5 kB 165 kB 324.9 Mclk 6.7 kclk 46.9 kclk
2IC+i (256,12,32) 288b 18.5 kB 1184 kB 4119.7 Mclk 26.7 kclk 385.6 kclk
2IC+i (256,12,32)64b 288b 18.5 kB 1184 kB 4418.2 Mclk 23.0 kclk 266.9 kclk
3IC-p(24, 32, 1) 380b 9 kB 148 kB 173.6 Mclk 503 kclk 699 kclk
pFLASH 292b 5.5 kB 72 kB 86.6 Mclk 2410 kclk 879 kclk
DSA/ElGamal 1024b 148B 128B 1.08 Mclk 1046 kclk 1244 kclk
RSA 1024b 148B 128B 108 Mclk 2950 kclk 121 kclk
ECC 256b 96B 64B 2.7 Mclk 2850 kclk 3464 kclk
Table 2. Comparison on One core of an Intel Core 2 (C2)
Scheme result SecrKey PublKey KeyGen SecrMap PublMap
PMI+(136, 6, 18, 8) 144b 5.5 kB 165 kB 425.4 Mclk 388.8 kclk 63.9 kclk
PMI+(136, 6, 18, 8)64b 144b 5.5 kB 165 kB 424.7 Mclk 393.3 kclk 60.4 kclk
rainbow (28, 18, 12, 12) 336b 24.8 kB 22.5 kB 234.6 Mclk 297.0 kclk 224.4 kclk
rainbow (24, 24, 20, 20) 256b 91.5 kB 83 kB 544.6 Mclk 224.4 kclk 164.0 kclk
rainbow (24, 24, 20, 20)64b 256b 91.5 kB 83 kB 396.2 Mclk 138.7 kclk 83.9 kclk
TTS (28, 18, 12, 12) 336b 3.5kB 22.5kB 20.4 Mclk 69.1 kclk 224.4 kclk
TTS (24, 24, 20, 20) 256b 5.6kB 83kB 225.2 Mclk 103.8 kclk 84.8 kclk
2IC+i (128,6,16) 144b 5 kB 165 kB 382.6 Mclk 8.7 kclk 64.2 kclk
2IC+i (128,6,16)64b 144b 5 kB 165 kB 382.1 Mclk 7.5 kclk 60.1 kclk
2IC+i (256,12,32) 288b 18.5 kB 1184 kB 5155.5 Mclk 31.1 kclk 537.0 kclk
2IC+i (256,12,32)64b 288b 18.5 kB 1184 kB 5156.1 Mclk 26.6 kclk 573.9 kclk
3IC-p(24, 32, 1) 380b 9 kB 148 kB 200.7 Mclk 645 kclk 756 kclk
pFLASH 292b 5.5 kB 72 kB 126.9 Mclk 5036 kclk 872 kclk
DSA/ElGamal 148B 148B 128B 0.864 Mclk 862 kclk 1018 kclk
RSA 1024b 148B 128B 150 Mclk 2647 kclk 117 kclk
ECC 256b 96B 64B 2.8 Mclk 3205 kclk 3837 kclk
Table 3. Comparison on One Core of an Opteron/Athlon64 (K8)
Rainbow, TTS, and `IC-derivative 5
‚Äì To invert Q, determine (usu. at random) x1, . . . xv1 , i.e., all xk, k ‚àà S1. From
the components of y that corresponds to the polynomials p‚Ä≤v1+1, . . . p
‚Ä≤
v2
, we
obtain a set of o1 equations in the variables xk, (k ‚àà O1). We may repeat
the process to find all remaining variables.
For historical reasons, a Rainbow type signature scheme is said to be a TTS
[33] scheme if the coefficients of Q are sparse.
2.1 Known Attacks and Security Criteria
1. Rank (or Low Rank, MinRank) attack to find a central equation with least
rank [33].
Clow rank ‚âà
[
qv1+1m(n2/2‚àím2/6)/
]
m.
Here as below, the unit m is a multiplications in K, and v1 the number
of vinegars in layer 1. This is the ‚ÄúMinRank‚Äù attack of [25]. as improved
by [8, 33].
2. Dual Rank (or High Rank) attack [9, 25], which finds a variable appearing
the fewest number of times in a central equation cross-term [19,33]:
Chigh rank ‚âà
[
qon‚àív
‚Ä≤
n3/6
]
m,
where v‚Ä≤ counts the vinegar variables that never appears until the final seg-
ment.
3. Trying for a direct solution. The complexity is roughly as MQ(q;m,m).
4. Using the Reconciliation Attack [19], the complexity is as MQ(q; vu,m).
5. Using the Rainbow Band Separation from [19], the complexity is determined
by that of MQ(q;n,m+ n).
6. Against TTS, there is Oil-and-Vinegar Separation [26,27,30], which finds an
Oil subspace that is sufficiently large (estimates as corrected in [33]).
CUOV ‚âà
[
qn‚àí2o‚àí1o4 + (some residual term bounded by o3qm‚àío/3)
]
m.
o is the max. oil set size, i.e., there is a set of o central variables which are
never multiplied together in the central equations, and no more.
2.2 Choosing Rainbow Instances
First suppose that we wish to use SHA-1, which has 160 bits. It is established
by [19] that using GF(28) there is no way to get to 280 security using roughly
that length hash, unpadded.
Specifically, to get the complexity ofMQ(28,m,m), to above 280 (the direct
attack) we need about m = 24. Then we needMQ(28, n, n+m) to get above 280
(the Rainbow Band Separation), which requires at least n = 42. This requires
an 192-bit hash digest plus padding and a signature length of 336 bits with the
vinegar sequence (18, 12, 12)
Rainbow, TTS, and `IC-derivative 7
3 The `-Invertible Cycle (`IC) and Derivatives
The `-invertible cycle [18] can be best considered an improved version or ex-
tension of Matsumoto-Imai, otherwise known as C‚àó [28]. Let‚Äôs review first the
latter.
Triangular (and Oil-and-Vinegar, and variants thereof) systems are some-
times called ‚Äúsingle-field‚Äù or ‚Äúsmall-field‚Äù approaches to MPKC design, in con-
trast to the approach taken by Matsumoto and Imai in 1988. In such ‚Äúbig-field‚Äù
variants, the central map is really a map in a larger field L, a degree n extension
of a finite field K. To be quite precise, we have a map Q : L ‚Üí L that we can
invert, and pick a K-linear bijection œÜ : L ‚Üí Kn. Then we have the following
multivariate polynomial map, which is presumably quadratic (for efficiency):
Q = œÜ ‚ó¶ Q ‚ó¶ œÜ‚àí1. (2)
then, one ‚Äúhide‚Äù this map Q by composing from both sides by two invertible
affine linear maps S and T in Kn, as in Eq. 1.
Matsumoto and Imai suggest that we pick a K of characteristic 2 and this
map Q
Q : x 7‚àí‚Üí y = x1+q
Œ±
, (3)
where x is an element in L, and such that gcd(1 + qŒ±, qn ‚àí 1) = 1. The last
condition ensures that the map Q has an inverse, which is given by
Q
‚àí1
(x) = xh, (4)
where h(1 + qŒ±) = 1 mod (qn ‚àí 1). This ensures that we can decrypt any secret
message easily by this inverse. Hereafter we will simply identify a vector space
K
k with larger field L, and Q with Q, totally omitting the isomorphism œÜ from
formulas.
`IC also uses an intermediate field L = Kk and extends C‚àó by using the
following central map from (L‚àó)` to itself:
Q : (X1, . . . , X`) 7‚Üí (Y1, . . . , Y`) (5)
:= (X1X2, X2X3, . . . , X`‚àí1X`, X`X
qŒ±
1 ).
For ‚Äústandard 3IC‚Äù, ` = 3, Œ± = 0. Invertion in (L‚àó)3 is then easy.
Q‚àí1 : (Y1, Y2, Y3) ‚àà (L
‚àó)3 7‚Üí (
‚àö
Y1Y3/Y2,
‚àö
Y1Y2/Y3,
‚àö
Y2Y3/Y1, ). (6)
Most of the analysis of the properties of the 3IC map can be found in [18] ‚Äî
the 3IC and C‚àó maps has a lot in common. Typically, we take out 1/3 of the
variables with a minus variation (3IC‚àí).
For encryption schemes, ‚Äú2IC‚Äù or ` = 2, q = 2, Œ± = 1 is suggested.
Q2IC : (X1, X2) 7‚Üí (X1X2, X1X
2
2 ), Q
‚àí1
2IC : (Y1, Y2) 7‚Üí (Y1/Y
2
2 , Y2/Y1). (7)
Rainbow, TTS, and `IC-derivative 9
is bilinear and symmetric in its variables a and x. Let Œ∂ be an element in the
big field L. Then we have
DQ(Œ∂ ¬∑ a, x) +DQ(a, Œ∂ ¬∑ x) = (Œ∂q
Œ±
+ Œ∂)DQ(a, x).
Clearly the public key of C‚àó‚àí inherits some of that symmetry. Now not every
skew-symmetric action by a matrix MŒ∂ that corresponds to an L-multiplication
that result in MTŒ∂ Hi + HiMŒ∂ being in the span of the public-key differential
matrices, because S := span{Hi : i = 1 ¬∑ ¬∑ ¬∑n ‚àí r} as compared to span{Hi :
i = 1 ¬∑ ¬∑ ¬∑n} is missing r of the basis matrices. However, as the authors of [20]
argued heuristically and backed up with empirical evidence, if we just pick the
first three MTŒ∂ Hi +HiMŒ∂ matrices, or any three random linear combinations of
the form
‚àën‚àír
i=1 bi(M
T
Œ∂ Hi +HiMŒ∂) and demand that they fall in S, then
1. there is a good chance to find a nontrivial MŒ∂ satisfying that requirement;
2. this matrix really correspond to a multiplication by Œ∂ in L;
3. applying the skew-symmetric action of this MŒ∂ to the public-key matrices
leads to other matrices in span{Hi : i = 1 ¬∑ ¬∑ ¬∑n} that is not in S.
Why three? There are n(n‚àí 1)/2 degrees of freedom in the Hi, so to form a
span of n‚àír matrices takes n(n‚àí3)/2+r linear relations among its components
(n‚àí r and not n because if we are attacking C‚àó‚àí, we are missing r components
of the public key). There are n2 degrees of freedom in an n√ó n matrix U . So, if
we take a random public key, it is always possible to find a U such that
UTH1 +H1U, U
TH2 +H2U ‚àà S = span{Hi : i = 1 ¬∑ ¬∑ ¬∑n‚àí r},
provided that 3n > 2r. However, if we ask that
UTH1 +H1U, U
TH2 +H2U, U
TH3 +H3U ‚àà S,
there are many more conditions than degrees of freedom, hence it is unlikely to
find a nontrivial solution for truly randomHi. Conversely, for a set of public keys
from C‚àó, tests [20] shows that it almost surely eventually recovers the missing r
equations and break the scheme.
Similarly, [24] and the related [29] shows a similar attack (with a more
complex backend) almost surely breaks 3IC‚àí and any other `IC‚àí. For the
`IC case, the point is the differential expose the symmetry for a linear map
(X1, X2, X3) 7‚Üí (Œæ1X1, Œæ2X2, Œæ3X3). Exactly the same symmetric property is
found enabling the same kind of attacks.
It was pointed out [16] that Internal Perturbation is almost exactly equal to
both Vinegar variables and Projection, or fixing the input to an affine subspace.
Let s be one, two or more. We basically set s variables of the public key to be
zero to create the new public key. However, in the case of signature schemes,
each projected dimension will slow down the signing process by a factor of q. A
differential attack looks for an invariant or a symmetry. Restricting to a subspace
of the original w-space breaks a symmetry. Something like the Minus variant
destroys an invariant. Hence the use of projection by itself prevents some attacks.
Rainbow, TTS, and `IC-derivative 11
4.2 Operating on Tower Fields
During working with the inversion of the central map, we operate the big-field
systems using as much of tower fields as we can. We note that firstly, GF(2) =
{(0)2, (1)2}, where (¬∑)2 means the binary representation. Then t
2 + t + (1)2 is
irreducible over GF(2). We can implement GF(22
i
) recursively. With a proper
choice of Œ±i, we let GF(2
2i) = GF(22
i‚àí1
)[ti]/(t
2
i + ti + Œ±i).. One can also verify
that Œ±i+1 := Œ±iti will lead to a good series of extensions.
For a, b, c, d ‚àà GF(22
i‚àí1
), we can do Karatsuba-style
(ati + b)(cti + d) = [(a+ b)(c+ d) + bd]ti + [acŒ±i + bd]
where the addition is the bitwise XOR and the multiplication of expressions of
a, b, c, d and Œ±i are done in GF(2
2i‚àí1). Division can be effected via (ati+ b)
‚àí1 =
(ati + a+ b)(ab+ b
2 + a2Œ±i)
‚àí1.
While most of the instances we work with only looks at tower fields going
up powers of two, a degree-three extension is similar with the extension being
quotiented against t3+t+1 and similar polynomials, and a three-way Karatsuba
is relatively easy. We can do a similar thing for raising to a power of five.
4.3 Bit-sliced GF(16) Rainbow Implementations
It is noted in [4] that GF(4) and GF(16) can be bitsliced for good effect. Actually,
any GF(2k) for small k can be bitsliced this way. In particular, it is possible to
exploit the bitslicing to evaluate the private map.
1. Invert the linear transformation T to get y from z. We can use bitslicing
here to multiply each zi to one columne of the matrix M
‚àí1
T .
2. Guess at the initial block of vinegar variables
3. Compute the first system to be solved.
4. Solve the first system via Gauss-Jordan elimination with bitslice.
5. Compute the second system to be solved.
6. Solve the second system via Gauss-Jordan elimination with bitslice. We have
computed all of x.
7. Invert the linear transformation S to get w from x.
Note that during the bitslice solving, every equation can be stored as four bit-
vectors (here 32-bit or double words suffices), which stores every coefficient along
with the constant term. In doing Gauss-Jordan elimination, we use a sequence
of bit test choices to multiply the pivot equation so that the pivot coefficient
becomes 1, and then use bit-slicing SIMD multiplication to add the correct
multiple to every other equation. Bit-Sliced GF(16) is not used for TTS since
the set-up takes too much time.
Rainbow, TTS, and `IC-derivative 13
2. M. Bardet, J.-C. Fauge`re, and B. Salvy. On the complexity of Gro¬®bner basis
computation of semi-regular overdetermined algebraic equations. In Proceedings
of the International Conference on Polynomial System Solving, pages 71‚Äì74,
2004. Previously INRIA report RR-5049.
3. M. Bardet, J.-C. Fauge`re, B. Salvy, and B.-Y. Yang. Asymptotic expansion of
the degree of regularity for semi-regular systems of equations. In P. Gianni,
editor, MEGA 2005 Sardinia (Italy), 2005.
4. C. Berbain, O. Billet, and H. Gilbert. Efficient implementations of multivariate
quadratic systems. In E. Biham and A. M. Youssef, editors, Selected Areas in
Cryptography, volume 4356 of Lecture Notes in Computer Science, pages 174‚Äì187.
Springer, 2007.
5. D. J. Bernstein, P. Birkner, M. Joye, T. Lange, and C. Peters. Twisted edwards
curves. In S. Vaudenay, editor, AFRICACRYPT, volume 5023 of Lecture Notes
in Computer Science, pages 389‚Äì405. Springer, 2008.
6. D. J. Bernstein and T. Lange. Faster addition and doubling on elliptic curves. In
K. Kurosawa, editor, ASIACRYPT, volume 4833 of Lecture Notes in Computer
Science, pages 29‚Äì50. Springer, 2007.
7. D. J. Bernstein and T. Lange. Inverted edwards coordinates. In S. Boztas and
H. feng Lu, editors, AAECC, volume 4851 of Lecture Notes in Computer Science,
pages 20‚Äì27. Springer, 2007.
8. O. Billet and H. Gilbert. Cryptanalysis of rainbow. In Security and Cryptography
for Networks, volume 4116 of LNCS, pages 336‚Äì347. Springer, September 2006.
9. D. Coppersmith, J. Stern, and S. Vaudenay. The security of the birational
permutation signature schemes. Journal of Cryptology, 10:207‚Äì221, 1997.
10. N. Courtois, L. Goubin, and J. Patarin. SFLASH: Primitive specification (second
revised version), 2002. https://www.cosic.esat.kuleuven.be/nessie,
Submissions, Sflash, 11 pages.
11. N. T. Courtois, A. Klimov, J. Patarin, and A. Shamir. Efficient algorithms for
solving overdefined systems of multivariate polynomial equations. In Advances in
Cryptology ‚Äî EUROCRYPT 2000, volume 1807 of Lecture Notes in Computer
Science, pages 392‚Äì407. Bart Preneel, ed., Springer, 2000. Extended Version:
http://www.minrank.org/xlfull.pdf.
12. J. Ding. A new variant of the Matsumoto-Imai cryptosystem through
perturbation. In Public Key Cryptography ‚Äî PKC 2004, volume 2947 of Lecture
Notes in Computer Science, pages 305‚Äì318. Feng Bao, Robert H. Deng, and
Jianying Zhou (editors), Springer, 2004.
13. J. Ding, V. Dubois, B.-Y. Yang, C.-H. O. Chen, and C.-M. Cheng. Could
SFLASH be repaired? In L. Aceto, I. Damgard, L. A. Goldberg, M. M.
Halldo¬¥rsson, A. Ingo¬¥lfsdo¬¥ttir, and I. Walukiewicz, editors, ICALP (2), volume
5126 of Lecture Notes in Computer Science, pages 691‚Äì701. Springer, 2008.
E-Print 2007/366.
14. J. Ding and J. Gower. Inoculating multivariate schemes against differential
attacks. In PKC, volume 3958 of LNCS. Springer, April 2006. Also available at
http://eprint.iacr.org/2005/255.
15. J. Ding, J. Gower, and D. Schmidt. Multivariate Public-Key Cryptosystems.
Advances in Information Security. Springer, 2006. ISBN 0-387-32229-9.
16. J. Ding and D. Schmidt. Cryptanalysis of HFEv and internal perturbation of
HFE. In Public Key Cryptography ‚Äî PKC 2005, volume 3386 of Lecture Notes in
Computer Science, pages 288‚Äì301. Serge Vaudenay, ed., Springer, 2005.
Rainbow, TTS, and `IC-derivative 15
32. B.-Y. Yang and J.-M. Chen. All in the XL family: Theory and practice. In ICISC
2004, volume 3506 of Lecture Notes in Computer Science, pages 67‚Äì86. Springer,
2004.
33. B.-Y. Yang and J.-M. Chen. Building secure tame-like multivariate public-key
cryptosystems: The new TTS. In ACISP 2005, volume 3574 of Lecture Notes in
Computer Science, pages 518‚Äì531. Springer, July 2005.
34. B.-Y. Yang, J.-M. Chen, and Y.-H. Chen. TTS: High-speed signatures on a
low-cost smart card. In CHES 2004, volume 3156 of Lecture Notes in Computer
Science, pages 371‚Äì385. Springer, 2004.
also has the drawback of leaking the invariant properties of the internal function. When-
ever such invariant properties can be used in order to devise a cryptanalytic attack (for
instance, unusual elimination properties of the variables allowing efficient Gro¬®bner basis
computation), one has to use additional transformations to destroy them. These additional
transformations can be different depending on the encryption/signature usage intended.
SFLASH is a signature scheme proposed by Patarin, Goubin and Courtois [20], following
a design they had introduced at Asiacrypt‚Äô98 [18]. The easy-to-invert internal function of
SFLASH is defined from a single variable polynomial over some field extension Fqn and
turned into a function from (Fq)
n to itself by using the linear structure of Fqn over Fq.
To allow efficient inversion, this function has a specific shape as a polynomial over Fqn ,
namely this is a monomial which is inverted by raising to the inverse exponent, like in RSA.
The basic McEliece-type hiding, i.e. using two linear bijections, of such a function was the
initial proposal ‚Äì known as the C* cryptosystem ‚Äì of Matsumoto and Imai [14], but it
was later seen by Patarin [17] that the hidden monomial structure implies some algebraic
properties of the public function which can be exploited by an attack to invert it without the
secret key. However, Patarin, Goubin and Courtois later showed [18] that algebraic attacks
can be very easily avoided by simply deleting a few coordinates of the public function; this
additional transformation, initially used by Shamir [19], is often referred to as the minus
transformation. Schemes obtained from the application of minus to C* are termed C*‚Äì
schemes; they are suitable for signature. SFLASH is a C*‚Äì scheme chosen as a candidate for
the selection organized by the NESSIE European consortium [1], and accepted in 2003 [16].
Recently, Dubois, Fouque, Shamir and Stern discovered a new property of C* monomials
which is almost not affected by the minus transformation, and which can be used to recover
missing coordinates of the public function [6,5]. As a consequence, all practical parameters
choices for C*‚Äì schemes, including those of SFLASH, were shown insecure. The attack found
by Dubois et al. is the most effective development of a new kind of cryptanalysis which
targets geometrical properties of multivariate functions. It is the obvious demonstration
that much structure might still be accessed even when algebraic attacks are ineffective.
Consequences of this attack are of course a reevaluation of related cryptosystems and a
more careful study of the properties of the internal functions being used. However it seems
that the mere design principle of multivariate schemes is here in question : can we effectively
hide a particular function such as a C* monomial using linear maps ?
Our results. In this paper, we review the recent cryptanalysis of SFLASH and we notice that
its weaknesses can all be linked to the fact that the cryptosystem is built on the structure
of a large field. As the attack demonstrates, this richer structure can be accessed by an
attacker by using the specific symmetry of the internal C* function that can be perceived
from even a small number of public polynomials. In fact, this raises the general remark that,
since the large field structure is only necessary to perform the secret operations, it indeed
should not be encapsulated in the public key. Then, we study the effect of restricting this
large field to a purely linear subset, and we find that the symmetries exploited by the attack
are no longer present. Indeed the symmetries of the C* monomial are fundamentally linked
to the large field multiplication and do not hold when restricted to a non-multiplicative
subset; we provide mathematical proofs explaining this phenomenon in detail. As we will
see, this result conveys additional perspective on the general design of multivariate schemes.
2
redundancy between coordinates of the input and output of F , arising as a consequence of
the structural specificity of the transformation made from one to the other; it appears as
a common drawback of most internal functions used to design multivariate cryptosystems.
Later, effective ways to destroy these algebraic invariants were investigated.
2.2 SFLASH
To avoid an attacker to possibly reconstruct existing algebraic relations on the pairs (x, y),
a simple idea is not to provide the entire description of how these variables are related.
The most easy way to realize this was used by Shamir in 1993 [19] and consists in simply
removing a few coordinate-polynomials of the public key, say the last r ones where r is an
additional parameter. When this modification is applied, the original pairs (x, y) should
only be accessible at the cost of exhaustive search on the last r coordinates of y for each
considered value of x. Furthermore, Patarin, Goubin and Courtois showed in 1998 [18] that
for a C* scheme, the degree of algebraic relations between x and the partial y is quickly
growing with the parameter r. Of course, the resulting scheme is no longer bijective but
it remains surjective and it can still be used for signature without a performance loss.
This family of signature schemes was introduced as C*‚Äì schemes by Patarin, Goubin and
Courtois [18]. The public key of a C*‚Äì scheme consists of the n‚àí r first coordinates
P
‚àí = (p1, . . . , pn‚àír)
of an initial C* public key P = T ‚ó¶F ‚ó¶S with T and S as the secret key. A rationale for the
parameter r is provided in [18] based on an attack method which attempts to derive linear
equations on the coefficients of the missing coordinates ; choosing r with qr ‚â• 280 is then
required for a 280 security level. Besides, no algebraic attack is expected to succeed when r
is not too small in regards to n, the initial number of polynomials.
SFLASH is a C*‚Äì scheme chosen by Patarin, Goubin and Courtois as a candidate for
the selection of cryptographic primitives organized by the NESSIE consortium in 2001 [1].
A first version of SFLASH featured a tweak to decrease the size of the public key; however
this rendered the scheme insecure as shown by Gilbert and Minier [11]. A standard version
was then proposed, with parameters q = 27, n = 37, Œ∏ = 11 and r = 11; the signature
length is 239 bits and the public key size is 15 Kbytes. This second version was accepted
by NESSIE in 2003. A third, more conservative version was also proposed in 2003 [3].
3 The Symmetry in SFLASH
The design of SFLASH was aimed at resisting algebraic attacks and stood challenging for
almost ten years. However, in the last four years, a new kind of cryptanalysis for multi-
variate schemes has been developed based on geometrical properties of the so-called dif-
ferential [10,7,8]. As defined in the initial paper by Fouque, Granboulan and Stern [10],
the differential transforms a quadratic function P (x) into its bilinear symmetric associate,
denoted DP (a, b). The differential of P can be obtained by substituting monomials xixj
by aibj + ajbi in the expression of P (if P is not homogeneous, terms of degree 1 and 0
are discarded). The interest of doing so is that DP is linear separately in a and b and its
4
define for any linear map M , the skew-symmetric action of M over DF as the bilinear
symmetric function
Œ£[M ](a, b) = DF (M(a), b) +DF (a,M(b))
Our basic identity infers that in the special case of multiplication maps, we have
Œ£[MŒæ](a, b) =MŒ∂ ‚ó¶DF (a, b)
where MŒ∂ is the multiplication by Œæ + Œæ
qŒ∏ . As a consequence, for any element Œæ of Fqn ,
the coordinate-polynomials of the bilinear symmetric function Œ£[MŒæ](a, b) are linear com-
binations of the coordinate-polynomials of DF . Therefore, expressed in geometrical terms,
multiplication maps have the specific property to leave unchanged under skew-symmetric
action the subspace spanned by the coordinate-polynomials of DF . Note that this property
is very strong because the subspace spanned by the n coordinates of DF has dimension at
most n while for a random linear map M , the coordinates of Œ£[M ] might be any polynomi-
als in the whole space of bilinear symmetric polynomials of dimension n(n ‚àí 1)/2 and are
very unlikely to all be confined in the tiny subspace spanned by the coordinates of DF .
The public key P of a C* scheme of course inherits of the above properties; the only
difference is that since the variables of F are transformed from the variables of P by the
linear bijection S, the linear maps that play with regards to P the role of multiplications
with regards to F are the conjugates S‚àí1 ‚ó¶MŒæ ‚ó¶ S. Now, a crucial point is : although the
latter maps depend on the secret bijection S, they can be computed from their characteristic
property with regards to the public key P . Indeed, let us show this for the simpler skew-
symmetry condition; we want to find the linear maps M which satisfy the equation
DP (M(a), b) + DP (a,M(b)) = 0
Since M appears linearly in the above expression, this clearly defines a set of linear equa-
tions in the coefficients of M . Furthermore, for each coordinate of DP , the equation
expresses the vanishing of a bilinear symmetric polynomial whose coefficients are linear
expressions in the coefficients of M ; each coordinate of DP therefore provides us with
n(n‚àí 1)/2 linear conditions on the n2 coefficients of M . As confirmed in practice [6], even
a marginal number of coordinates of the public key is sufficient to solve the space of skew-
symmetric maps. This means that the skew-symmetric maps can be determined from even
severely truncated C*‚Äì public keys without any special difficulty. Solving the more general
skew-symmetry condition follows similar principles although more theory is involved; we
refer the reader to the original paper [5] for the details.
3.2 Consequences
The properties described above allow an attacker to compute from a C*‚Äì public key conju-
gates S‚àí1‚ó¶MŒæ ‚ó¶S of multiplications mapsMŒæ. This of course is very annoying because these
maps depend on the secret bijection S and were initially considered as secret information.
Furthermore, as shown in [6], the nature of these maps is an additional problem: they give
access from the public world to the internal field multiplication. Indeed, once a conjugate
6
Let us now show that our expectation is correct using mathematical arguments.
First, we characterize the linear maps MH which are skew-symmetric with respect to
DFH by transforming the above condition (2) in a condition with respect to DF . That is,
we embed the above condition over H in a condition over Fqn . We can embed MH into a
linear map M¬ØH which is MH over H and zero elsewhere. The same way, we can embed the
Identity over H into the projection map to H, denoted piH . Then, (2) is equivalent to :
DF (M¬ØH(a), piH(b)) +DF (piH(a), M¬ØH(b)) = 0 , a, b ‚àà Fqn
Therefore, the linear maps M¬ØH are special solutions to the condition
DF (M(a), piH(b)) +DF (piH(a),M(b)) = 0 , a, b ‚àà Fqn (3)
They are those solutions M which are left unchanged by composition with piH :
M =M ‚ó¶ piH = piH ‚ó¶M
Our method to determine the linear maps M¬ØH is then clear : we first find the solutions M
to the condition (3), and then find those which are left unchanged by composition with piH .
Before we do this, let us note an alternative characterization of the linear maps M¬ØH : they
are the common solutions of the two conditions
DF (M ‚ó¶ piH(a), piH (b)) +DF (piH(a),M ‚ó¶ piH(b)) = 0 ,
DF (piH ‚ó¶M(a), piH (b)) +DF (piH(a), piH ‚ó¶M(b)) = 0 ,
a, b ‚àà Fqn (4)
The first condition is the skew-symmetry condition with respect to DF only considered for
elements of H. The second condition is the skew-symmetry with respect to DF (piH , piH).
Both conditions have additional degrees of freedom compared to the skew-symmetry with
respect to DF , and are simultaneously satisfied by the only linear maps M¬ØH .
The Solutions to Condition 3. As we can see, obvious solutions to Condition 3 are the
mapsMŒæ‚ó¶piH whereMŒæ is skew-symmetric with respect toDF . Since our condition is greatly
overdetermined, we do not expect any other solutions. This is confirmed experimentally. In
the most simple case when H is a hyperplane, we can actually give it a mathematical proof.
Lemma 1. Let H be a hyperplane of Fqn and DF be the differential of a bijective C*
monomial. The linear maps M which satisfy the condition
DF (M(a), piH(b)) +DF (piH(a),M(b)) = 0 , a, b ‚àà Fqn
are of the form MŒæ ‚ó¶ piH where MŒæ is skew-symmetric with respect to DF .
Proof. The idea of the proof is to replace M and piH by their expressions as sums of q-
powerings, and to express our condition as the vanishing of a polynomial in a, b over Fqn .
We have M(a) =
‚àën‚àí1
i=0 ¬µi a
qi and piH can be expressed as the projection orthogonally to
some element u, where the orthogonality is defined relatively to the trace product (see [13]
for a definition). Recalling tr(a) =
‚àën‚àí1
i=0 a
qi and that tr(a) is an element of Fq, we have
8
number of degenerate subspaces of dimension s in Fqn is dominated by the latter quantity
considered for the smallest common factor r of n and s. Since the smallest possible value of
r is 2, the proportion of degenerate subspaces of dimension s in Fqn is at most of the order
of q‚àís(n‚àís)/2. Since s(n ‚àí s) is minimal for s = 2 (2 is a common factor of s and n), the
searched proportion is dominated by q‚àí(n‚àí2) and therefore q‚àín asymptotically. uunionsq
Application to the General Skew-Symmetry Property of C*‚Äì schemes. In the
preceding paragraphs, we have shown that restricting the internal function F to some proper
subspace H of Fqn destroys the simple skew-symmetry property (2). In this paragraph, we
consider the general skew-symmetry property of C*‚Äì schemes. This property expresses that
there exists non-trivial linear maps which leave the space spanned by the coordinates of
DF unchanged under skew-symmetric action. The linear maps satisfying this condition are
the whole space of multiplications. Using similar techniques as before, we can show that
this property considered for the restricted function FH admits only trivial solutions. We
refer the reader to the appendix for the details.
4.2 Experimental verifications
We checked experimentally, for various C* parameters n and Œ∏, the effect of restricting the
internal function to a randomly chosen subspace H of various dimensions s. For instance,
for parameters n = 36 and Œ∏ = 4 (which are more interesting than those of SFLASH since
they are not prime numbers), we obtain the following dimension for the solution space of the
general skew-symmetry condition as the number of coordinate-wise conditions increases.
# conditions s = 0 s = 1 s = 2 s = 3 s = 4 s = 9 s = 18
1 1296 1225 1156 1089 1024 769 324
2 708 669 632 598 564 414 207
3 168 145 124 109 104 99 90
4 36 1 1 1 1 1 1
5 36 1 1 1 1 1 1
6 36 1 1 1 1 1 1
...
...
...
...
...
...
...
...
5 Projected C*‚Äì schemes
Based on the results of the preceding section, we are led to define a new family of schemes
that we call projected C*‚Äì schemes. As we will see, these schemes actually consists in hiding
a C* monomial using non-bijective linear maps. We next define the (ad-hoc) computational
problems on which the security of these schemes is based. Finally, we discuss possible choices
of parameters and suggest one concrete choice with performances comparable to SFLASH.
Description. A projected C*‚Äì scheme is defined as follows. Let n and Œ∏ define a bijective
C* monomial F (x) = x1+q
Œ∏
, x in Fqn . Given a representation of Fqn , F is identified with
a quadratic function from (Fq)
n to itself. Let r and s be two integers between 0 and n.
10
the public key and is stopped when it is no more the case. Then, we realize that, indeed,
one might not hope to hide effectively a particular function defined on a large field using
linear bijections; this might at most be achievable in some security range using compressive
linear maps. But then, is it still possible to build a practical cryptosystem in this setting ?
At the present state, we can still define a modified family of C* -based schemes which
is of practical interest. Analysis of this most simple case would probably yield additional
understanding of the ways to distinguish a specifically-built multivariate function and would
provide further insight on the very possibility to obfuscate such a function using linear maps.
References
1. European project IST-1999-12324 on New European Schemes for Signature, Integrity and Encryption.
http://www.cryptonessie.org.
2. N. Courtois. The Security of Hidden Field Equations (HFE). In D. Naccache, editor, CT-RSA, volume
2020 of Lecture Notes in Computer Science, pages 266‚Äì281. Springer, 2001.
3. N. T. Courtois, L. Goubin, and J. Patarin. Sflashv3 - a fast asymmetric signature scheme - revised
specification of sflash, version 3.0.
4. C.Wolf and B.Preneel. Taxonomy of Public Key Schemes based on the problem of Multivariate Quadratic
equations. Cryptology ePrint Archive, Report 2005/077, 2005. http://eprint.iacr.org/.
5. V. Dubois, P.-A. Fouque, A. Shamir, and J. Stern. Practical Cryptanalysis of SFLASH. In A. Menezes,
editor, CRYPTO, volume 4622 of Lecture Notes in Computer Science, pages 1‚Äì12. Springer, 2007.
6. V. Dubois, P.-A. Fouque, and J. Stern. Cryptanalysis of SFLASH with Slightly Modified Parameters.
In Proceedings of Eurocrypt 2007, volume LNCS 4515, pages 264‚Äì275, 2007.
7. V. Dubois, L. Granboulan, and J. Stern. An Efficient Provable Distinguisher for HFE. In M. Bugliesi,
B. Preneel, V. Sassone, and I. Wegener, editors, ICALP (2), volume 4052 of Lecture Notes in Computer
Science, pages 156‚Äì167. Springer, 2006.
8. V. Dubois, L. Granboulan, and J. Stern. Cryptanalysis of HFE with Internal Perturbation. In Proceed-
ings of PKC 2007, volume LNCS 4450, pages 249‚Äì265. Springer, 2007.
9. J.-C. Fauge`re and L. Perret. Polynomial Equivalence Problems: Algorithmic and Theoretical Aspects.
In S. Vaudenay, editor, EUROCRYPT, volume 4004 of Lecture Notes in Computer Science, pages 30‚Äì47.
Springer, 2006.
10. P.-A. Fouque, L. Granboulan, and J. Stern. Differential Cryptanalysis for Multivariate Schemes. In
R. Cramer, editor, EUROCRYPT, volume 3494 of Lecture Notes in Computer Science, pages 341‚Äì353.
Springer, 2005.
11. H. Gilbert and M. Minier. Cryptanalysis of SFLASH. In L. R. Knudsen, editor, EUROCRYPT, volume
2332 of Lecture Notes in Computer Science, pages 288‚Äì298. Springer, 2002.
12. J. Goldman and G.-C. Rota. The Number of Subspaces of a Vector Space. In W.T.Tutte, editor, Recent
Progress in Combinatorics, pages 75‚Äì83. Academic Press, 1969.
13. R. Lidl and H. Niederreiter. Finite Fields, volume 20 of Encyclopedia of Mathematics and its applications.
Cambridge University Press, 1997.
14. T. Matsumoto and H. Imai. Public Quadratic Polynominal-Tuples for Efficient Signature-Verification
and Message-Encryption. In EUROCRYPT, pages 419‚Äì453, 1988.
15. R. J. McEliece. A Public-Key Cryptosystem based on Algebraic Coding Theory. In JPL DSN Progress
Report, pages 114‚Äì116, California Inst. Technol., Pasadena, 1978.
16. NESSIE. Portfolio of Recommended Cryptographic Primitives. http://www.nessie.eu.org.
17. J. Patarin. Cryptanalysis of the Matsumoto and Imai Public Key Scheme of Eurocrypt‚Äô88. In D. Cop-
persmith, editor, CRYPTO, volume 963 of Lecture Notes in Computer Science, pages 248‚Äì261. Springer,
1995.
18. J. Patarin, L. Goubin, and N. Courtois. C*-+ and HM: Variations Around Two Schemes of T. Mat-
sumoto and H. Imai. In K. Ohta and D. Pei, editors, ASIACRYPT, volume 1514 of Lecture Notes in
Computer Science, pages 35‚Äì49. Springer, 1998.
19. A. Shamir. Efficient Signature Schemes Based on Birational Permutations. In D. R. Stinson, editor,
CRYPTO, volume 773 of Lecture Notes in Computer Science, pages 1‚Äì12. Springer, 1993.
20. Specifications of SFLASH. Final Report NESSIE, pages 669‚Äì677. 2004.
12
B Projection Also Breaks the General Skew-Symmetry Property
As before, we denote FH the restriction of the C* function F to a proper subspace H
of Fqn . Note that FH is a function from H to Fqn . A linear map MH from H to itself
satisfies the general skew-symmetry property with respect to DFH if and only if there
exists an associated linear map NMH from Fqn to itself such that
DFH(MH(h), k) +DFH(h,MH(k)) = NMH ‚ó¶DFH(h, k) , h, k ‚àà H (9)
As before, we can embed this identity over H into an identity over Fqn . We denote M¬ØH the
linear map from Fqn to itself which is MH over H and zero elsewhere. We denote piH the
projecion to H. Identity (9) is equivalent to
DF (M¬ØH(a), piH (b)) +DF (piH(a), M¬ØH (b)) = NMH ‚ó¶DF (piH(a), piH(b)) , a, b ‚àà Fqn
The linear maps M¬ØH are special solutions to the condition
DF (M(a), piH(b)) +DF (piH(a),M(b)) = NM ‚ó¶DF (piH(a), piH (b)) , a, b ‚àà Fqn (10)
They are those solutions M which are left unchanged by composition with piH :
M =M ‚ó¶ piH = piH ‚ó¶M
Obvious solutions to Condition (10) are the maps MŒæ ‚ó¶ piH where MŒæ is multiplication
by an element Œæ of Fqn . Since Condition (10) is greatly overdetermined, we do not expect
any parasitic solutions, and this is confirmed in practice. When H is a hyperplane, we can
actually give it a mathematical proof (see below). Then, the maps MŒæ ‚ó¶ piH which are left
unchanged by composition with piH are those for which H is closed by multiplication by Œæ.
We know from Lemma 2 that except for negligibly sparse choices of H, the only elements Œæ
which satisfy this property are the scalar multiples of 1.
Lemma 3. Let H be a hyperplane of Fqn and DF be the differential of a bijective C*
monomial. The linear maps M for which there exists a linear map NM such
DF (M(a), piH (b)) +DF (piH(a),M(b)) = NM ‚ó¶DF (piH(a), piH(b)) , a, b ‚àà Fqn
are of the form MŒæ ‚ó¶ piH where MŒæ is multiplication by an element Œæ of Fqn.
Proof. The proof is analogous to the proof of Lemma 1. To simplify, we also consider u = 1.
Let us also recall that bijective C* monomials only exist in characteristic 2. We rewrite our
condition A(a, b)‚àíB(a, b) = C(a, b)‚àíD(a, b) where A(a, b) and B(a, b) are the same as in
the proof of Lemma 1, and
C(a, b) = N(DF (a, b))
D(a, b) = tr(a)N(DF (b, 1)) + tr(b)N(DF (a, 1))
14
Getting back to the Œ≥i‚Äôs, we obtain Œ≥i = Œ∑ for all i but 0 and Œ∏, and Œ∑ = Œ≥0 + Œ≥Œ∏. It
results that all ¬µi for i 6= ‚àíŒ∏, 0, Œ∏ are equal; we call Œæ this constant, we have:
Œ∑ = Œæ + Œæq
Œ∏
We are left at finding ¬µ‚àíŒ∏, ¬µ0 and ¬µŒ∏. After simplifications, we get from (B) and (D):{
Œæ + Œ≥0 = ŒΩ0
Œæq
Œ∏
+ Œ≥Œ∏ = ŒΩ0
which implies Œ≥0 = Œæ
qŒ∏ , Œ≥Œ∏ = Œæ and ŒΩ0 = Œæ + Œæ
qŒ∏ = Œ∑. From (A) and (C) we get:
¬µ‚àíŒ∏ + ¬µ0 + ¬µŒ∏ = 0
Then, replacing Œ≥0 by its value Œ∑ + Œ≥Œ∏ in (C) we obtain: ¬µ‚àíŒ∏ + ¬µŒ∏ + ¬µ
qŒ∏
0 = 0. Using this
equation with (E), and joining equation (A), we get:{
¬µ‚àíŒ∏ + ¬µ
qŒ∏
Œ∏ = Œ∑
¬µŒ∏ + ¬µ
qŒ∏
‚àíŒ∏ = Œ∑
which implies ¬µŒ∏ = ¬µ‚àíŒ∏ and therefore ¬µ0 = 0. Finally, from (B) and (D), we get:
¬µ‚àíŒ∏ = ¬µŒ∏ = Œæ
The searched maps M are therefore:
M(a) = Œæ(a‚àí tr(a)) =MŒæ ‚ó¶ piH(a)
and their respective N are MŒ∑ where Œ∑ = Œæ + Œæ
qŒ∏ . uunionsq
16
 Can we prove a similar result to [7] allowing for more eÔ¨Éciently evaluated specialized systems?
 What do we know about how these specializations aÔ¨Äect complexity of system-solving?
1.1 Our New Ideas and Main Results
Instead of MQ, we investigate a class SMP(q, d, n,m, (Œ∑2, . . . , Œ∑d)) of sparse polynomials systems with
arbitrary aÔ¨Éne parts and terms at other degrees with speciÔ¨Åed density. I.e., S = (P1(x), P2(x), ¬∑ ¬∑ ¬∑ , Pm(x)) ‚àà
SMP(q, d, n,m, (Œ∑2, . . . , Œ∑d)) consists of m polynomials of degree d in the variables x = (x1, x2, . . . , xn); each
Pi is a degree-d polynomial such that exactly Œ∑i = Œ∑i(n) nonzero degree-i terms are present for each i ‚â• 2.
The aÔ¨Éne terms (coeÔ¨Écients) are totally randomly chosen. Also all the operations and coeÔ¨Écients are in Fq.
To rephrase, the i-th polynomial we can be written as Pi(x) =
‚àëd
j=2 Q
(i)
j (x) +
‚àë
1‚â§j‚â§n aijxj + ci where
each Q
(i)
j (x) can be written in the form
‚àë
1‚â§œÉ(1)‚â§œÉ(2)‚â§¬∑¬∑¬∑‚â§œÉ(j)‚â§n a(œÉ(1),œÉ(2),...,œÉ(j))xœÉ(1)xœÉ(2) . . . xœÉ(j), or the
sum of Œ∑j monomials with degree j. A random system from SMP(q, d, n,m, (Œ∑2, . . . , Œ∑d)) then has a
probability distribution as follows: all aij , ci are uniformly chosen from Fq. To determine each Q
(i)
j (x), we
Ô¨Årstly uniformly choose Œ∑j out of
(
n+j‚àí1
j
)
coeÔ¨Écients to be nonzero, then uniformly choose each of these
nonzero coeÔ¨Écients from F
‚àó
q := Fq \ {0}. All the others coeÔ¨Écients wil be zero.
We now propose a probabilistic one-wayness assumption to base a security theorem on.
Assumption SMP : For given q, d, and for n,m, Œ∑2, . . . , Œ∑d such that m/n = k+ o(1) and Œ∑i/n = ki+ o(1)
(where k, k2, k3, . . . are constants) there is no probabilistic algorithm which can solve (in poly(n)-time)
any Ô¨Åxed Œµ > 0 proportion of instances S(x) drawn from SMP((q, d, n,m, (Œ∑2, . . . , Œ∑d)), and a vector
b = (b1, b2, . . . , bm) drawn from S(Un), where Un is uniform distribution over (Fq)
n
such that S(x) = b.
In Secs. 23 Assumption SMP is shown to yield a secure PRNG (and hence a probably secure stream
cipher), for any q. The key to this extension to general Fq involves a reconstruction over linear polynomials,
which is a non-trivial generalization of the Goldreich-Levin hard core bit by Goldreich-Rubinfeld-Sudan [21].
We then check that SMP instances are hard to solve on average (i.e., not just worst case) via the
known fastest generic (cf. Sec. 4 and the Appendix B) and special-purpose algorithms. Finally we discuss
their practical use. Preliminary implementations of our SPELT (Sparse Polynomials, Every Linear Term)
can achieve 5541 and 11744 cycles per byte for a SMP-based secure stream cipher over F16 (quartic, 108
variables) and F2 (cubic, 208 variables) respectively. The former is at least twice as fast as any other stream
ciphers provably secure at the same parameters (cf. Sec. 5.2).
1.2 Previous Work
There had been provably secure PRNGs based on discrete log [20], or on hardness of factorization (as in
Blum, Blum, and Shub [10]) or a modiÔ¨Åcation thereof [29], orMQ [7]. But the security proofs always require
impractically high parameters for provable security, which limit their utility. For example:
 The BBS stream generator at commonly used parameters is not provably secure [23, Sec. 6.1].
 With [29], the speciÔ¨Åed security level was 270, today's cryptographers usually aim for 280 (3DES units).
 Similarly with QUAD there is a gap between the recommended instances and the provably secure instances
(i.e., the tested instances were unprovable or unproven [33]).
 PRNGs based on decisional DiÔ¨Ée-Hellman assumption have almost no gap between the hardness of
breaking the PRNG and solving the underlying intractable problem, but known primitives based on
DDH and exponentiation in Zp [22, 16] are generally slower than those based on other assumptions.
The generic types of methods for solving polynomial systems  Faug√®re's F4-F5 and XL-derivatives
 are not aÔ¨Äected drastically by sparsity. In the former, sparsity is quickly lost and tests show that there
is no substantial diÔ¨Äerence in timing when solving SMP instances. Recent versions of XL [33] speeds up
proportionally to sparsity. We therefore surveyed the literature for recent results on solving or attacking
specialized systems in crypto, listed below. These results do not contradict our hardness assumption.
2
2.1 From Distinguisher to Predictor
In fact, the following two results are valid for any K = Fq. In [7], the proofs were covered only in the F2 case.
However, the generalization is nontrivial but straitforward. Therefore, for simplicity, we put the generalized
propositions here, though this section is for the F2 case.
Proposition 1 ([7]) Take a stream cipher with Q : Kn ‚Üí Kn and P : Kn ‚Üí Kr as the update and output
Ô¨Ålter functions and random initial state x0, that is, starting from the initial state x0, at each step we update
with xi+1 = Q(xi) and output yi = P(xi).
x0 //
¬≤¬≤
x1 = Q(x0) //
¬≤¬≤
x2 = Q(x1) //
¬≤¬≤
x3 = Q(x2) //
¬≤¬≤
¬∑ ¬∑ ¬∑
(state)
y0 = P(x0) y1 = P(x1) y2 = P(x2) y3 = P(x3) ¬∑ ¬∑ ¬∑ (output)
If we can distinguish between its Ô¨Årst Œª blocks of output (y0,y1, . . . ,yŒª‚àí1) and a true random vector in
KŒªr with advantage ¬≤ in time T , then we can distinguish between the output of a true random vector in Kn+r
and the output of S = (P,Q) in time T + ŒªTS with advantage ¬≤/Œª. [Standard Proof is in Appendix A.]
Proposition 2 (an extention of [7]) Let K = Fq. Suppose there is an algorithm A that given a system
S(: Kn ‚Üí Km) chosen from SMP(q, d, n,m, (Œ∑2, . . . , Œ∑d)) distinguishing S(Un) from a uniform random
distribution Um, (where Ur means uniform distribution over K
r
for the r,) with advantage at least ¬≤ in time
T . Then there is an algorithm B that, given (1) a system S : Kn ‚Üí Km from SMP(n,m), (2) any Kn ‚Üí K
linear form R, and (3) y = S(b), where b is an secret input value randomly chosen from Kn, predicts R(b)
with success probability at least (1 + ¬≤/2)/q using at most T + 2TS operations.
Proof. Without loss of generality, we may suppose that A has probability at least ¬≤ higher to return 1 on an
input distribution (S,S(Un)) than on distribution (S, Um). DeÔ¨Åne a recentered distinguisher
A‚Ä≤(S,w) :=
{
A(S,w), probability 12
1‚àíA(S,u), u ‚àà Km uniform random, probabilty 12
then A‚Ä≤ returns 1 with probability 1+¬≤2 on input (S,S(Un)) and with probability
1
2 on input (S, Um).
Now, given an input S and y ‚àà Km, the algorithm B Ô¨Årst randomly chooses a value v ‚àà K (representing
a guess for R(b)), then randomly chooses a vector u ‚àà Km, and form S‚Ä≤ := S + Ru : Kn ‚Üí Km. This is
equal to S plus a random linear polynomial (see above for the meaning of random linear form) and is hence
of SMP(n,m). DeÔ¨Åne algorithm B as following:
B(S,y, R) :=
{
v, if A‚Ä≤(S‚Ä≤,y + vu) = 1;
uniformly pick an element from K\{v}, if A‚Ä≤(S‚Ä≤,y + vu) = 0.
If v = R(b), y + vu = S‚Ä≤(b), else y + vu is equal to S‚Ä≤(b) plus a nonzero multiple of the random vector u,
hence is equivalent to being uniformly random. The probability that B := B(S,S(b), R) is the correct guess
is hence
Pr(B = R(b)) = Pr(B = v|v = R(b)) Pr(v = R(b)) + Pr(B = R(b)|v 6= R(b)) Pr(v 6= R(b))
=
1
q
(
1
2
+
¬≤
2
)
+
(
q ‚àí 1
q
)
1
2
(
1
q ‚àí 1
)
=
1
q
(
1 +
¬≤
2
)
.
Note: We see that the reasoning can work this way if and only if S‚Ä≤ = S+Ru have the same distribution as
S. Otherwise, we cannot guarentee the distinguisher A‚Ä≤ will output the same distribution.
4
Proposition 6 ([25] and our contribution) If S = (P,Q) is an instance drawn from a SMP(n, n+ r),
where P : Fnq ‚Üí F
r
q, Q : F
n
q ‚Üí F
n
q are the stream cipher as in Prop. 1, then if we can distinguish between Œª
output blocks of the stream cipher and uniform distribution in T time, we can invert S(b) with probability
at least
¬≤
4qŒª in time
T ‚Ä≤ = 215
nq6Œª5
¬≤5
log2
(
2qnŒª
¬≤
)
(T + (Œª+ 2)TS) +
(
1‚àí
1
q
)2
4q2Œª2
¬≤2
TS (2)
This is a straightforward combination of Props. 1, 2, and 5. In the remainder of this section, we give a
proof to Prop. 5 by a variation of the procedure used by Goldreich-Rubinfeld-Sudan [21, Secs. 2 and 4], to
give it concrete values that we can derive security proofs from.
3.1 Conversion to a Modern (IV-Dependent Stream) Cipher
This paper mostly deals with the security of PRNGs, which are essentially old-fashioned stream ciphers. If
we have a secure PRNG S‚Ä≤ = (s0, s1), where both s0, s1 are maps from K
n ‚Üí Kn  note that S‚Ä≤ can be
identical to S  then the following is a standard way to derive the initial state x0 ‚àà K
n
from the bitstream
(key) c = (c1, c2, . . . , cKL) ‚àà {0, 1}
KL
and an initial u ‚àà Kn, where KL is the length of the key:
x0 := scKL(scKL‚àí1(¬∑ ¬∑ ¬∑ (sc2(sc1(u))) ¬∑ ¬∑ ¬∑ )).
This is known as the tree-based construction. From an old-fashioned provably secure stream cipher (i.e.,
the key is the initial state), the above construction achieves security in the resulting IV-dependent stream
cipher, at the cost of some additional looseness in the security proof. A recent example of this is [6].
Thus, all our work really applies to the modern type of stream ciphers which require an IV-dependent
setup, except that the security parameters may be slightly diÔ¨Äerent.
3.2 Hardcore Predicate and Learning Polynomials
Let x = (x1, x2, . . . , xn), b = (b1, b2, . . . , bn), and xi, bi are elements in a Ô¨Ånite Ô¨Åeld K = Fq. Given an
arbitrary strong one way function h(x), then F (x,b) = (h(x),b) is also a one way function. Claim x ¬∑ b is
the hard-core bit of F (x,b), where x ¬∑ b means their inner product.
Supposed we have a predictor P which predicts its hardcore x ¬∑ b given (h(x),b) with probability more
than
1
q + ¬≤, then we can write in the math form:
Pr
b,x
[P (h(x),b) = x ¬∑ b] >
1
q
+ ¬≤.
By Markov inequality, we know there must be more than ¬≤/2 fraction of x such that Prb[P (h(x),b) = x¬∑b] >
1
q +
¬≤
2 . For this fraction of x, we are trying to Ô¨Ånd the inverse of h(x) (F (x) as well) through the predictor.
Also x ¬∑ b can be written as
‚àë
bixi, then
Pr
b
[
P (h(x),b) =
‚àë
bixi
]
>
1
q
+
¬≤
2
.
What this means in English is that, if we can Ô¨Ånd a polynomial which almost matches an arbitrary
function P , a predictor function, then we can eventually invert x from F (x) a non-negligible portion of the
time. Now we try to reconstruct such linear polynomials through the access of the predictor, largely following
the footsteps of [21].
6
3.4 Giving Concrete Values to Order of Polynomially Many
Since there are ¬≤/2 fraction of suÔ¨Éx s such that Ps(œÉ) ‚â•
1
q+
¬≤
2 , we can randomly choose the suÔ¨Éx polynomially
many times (k1 times) to ensure that we would select such s with high probability. Also, for such s, if we
choose polynomially many times (k2 times) of r, there would be high probability that we would Ô¨Ånd some
Œ± for at least 1q +
¬≤
3 fraction. We are estimating how the polynomially many should be as the following:
Pr [ TestPreÔ¨Åx fails ] ‚â§
Pr[no such s is chosen ] + Pr
[
no single element exists more than
1
q
+
¬≤
3
fraction
]
Pr [ no such s is chosen] ‚â§ (1‚àí ¬≤/2)k1 ‚â§ e‚àí
k1¬≤
2 ‚â§
1
2
¬≤(
1‚àí 1q
)2
¬≤‚àí2 nq
So, we take k1 as O(
1
¬≤ log(
n
¬≤ )) ‚âà 3
1
¬≤ log(
n
¬≤ ). On the other hand, we want to estimate the probability of there
are no œÉ's with fraction at least 1q +
¬≤
3 . For a correct suÔ¨Éx s, we know for uniform r, we get that œÉ with
probability more than
1
q +
¬≤
2 . Let Xi be the random variable with value 1 if the i-th trial of r gets the correct
œÉ, 0 otherwise. Then we have Pr[Xi = 1] ‚â•
1
q +
¬≤
2 . Suppose we do k2 trials:
Pr
[
no single element exists more than
1
q
+
¬≤
3
fraction
]
‚â§ Pr
[
k2‚àë
1
Xi < (
1
q
+
¬≤
3
)k2
]
‚â§ Pr
[‚à£‚à£‚à£‚à£‚à£
‚àëk2
i=1 Xi
k2
‚àí
(
1
q
+
¬≤
2
)‚à£‚à£‚à£‚à£‚à£ ‚â• ¬≤6
]
,
since these Xi's are independent, then by ChernoÔ¨Ä's bound we have
Pr
[‚à£‚à£‚à£‚à£‚à£
‚àëk2
i=1 Xi
t
‚àí (
1
q
+
¬≤
2
)
‚à£‚à£‚à£‚à£‚à£ ‚â• ¬≤6
]
‚â§ 2e‚àí
k2¬≤
2
2√ó36 ‚â§
1
2
¬≤(
1‚àí 1q
)2
¬≤‚àí2 nq
,
k2 = O(
log(n/¬≤)
¬≤2 ) ‚âà 216
log(n/¬≤)
¬≤2 is suÔ¨Écient to make the inequality hold. Thus, we have
Pr [ TestPreÔ¨Åx fails ] ‚â§
¬≤(
1‚àí 1q
)2
¬≤‚àí2 nq
.
Also, Pr [ Algorithm 2 fails ] ‚â§ Pr [ one TestPreÔ¨Åx fails ] ‚â§
‚àë
all TestPreÔ¨Åx run
Pr [ TestPreÔ¨Åx fails ]
‚â§
((
1‚àí
1
q
)2
¬≤‚àí2 nq
)
¬≤(
1‚àí 1q
)2
¬≤‚àí2 nq
= ¬≤
Therefore, the algorithm will work with high probability. The worst case running time of algorithm 2
should be: k1k2(1‚àí
1
q )
2 1
¬≤2nq = O(
n
¬≤5 log
2(n¬≤ )) . 2
10
(
nq
¬≤5
)
log2(n¬≤ ).
Note:
(
1‚àí 1q
)2
¬≤‚àí2 is the maximum number of candidates which pass in each round.
8
know of recent new attempts on solving or attacking specialized systems in crypto, and show that our results
are consistent with these new results and somewhat complements them.
 Aumasson-Meier [1] presented several ideas to attack primitives built on sparse polynomials systems,
which we sketch separately in Sec. 4.3 below.
 Raddum-Samaev [27, 28] attacks what they term sparse systems, where each equation depend on a
small number of variables. Essentially, the authors state that for systems of equations in n bit variables
such that each equation depends on only k variables, we can solve the system in time roughly proportional
to 2(1‚àí
1
k
)n
using a relatively small memory footprint. Since XL for cubics and higher degrees over F2 is
more time-consuming than brute-force, this is fairly impressive. However, the sparsity deÔ¨Åned by the
authors is closer to input locality and very diÔ¨Äerent from what people usually denote with this term.
The attack is hence not applicable to SMP-based stream ciphers.
In a similar vein is the purported XSL attack on AES [13]. While the S was supposed to stand for Sparse,
it really requires Structure  i.e., each equation depending on very few variables. So, whether that attack
actually works or not, it does not apply to SMP-based systems.
 Bard-Courtois-JeÔ¨Äerson [2] use SAT solvers on uniformly sparse F2 equations and give experimental
numbers. According to the authors, the methods takes up much less memory than F4 or derivatives, but
is slower than these traditional methods when they have enough memory.
Some numbers for very overdeÔ¨Åned and very sparse systems shows that converting to a conjunctive
normal form and then running a SAT solver can have good results. This seems to be a very intriguing
approach, but so far there are no theoretical analysis especially for when the number of equations is a
few times the number of variables, which is the case for SMP (or SRQ) constructions.
4.3 Solutions and Collisions in Sparse Polynomial Systems
Aumasson-Meier recent published [1] some quite interesting ideas on Ô¨Ånding solutions or collisions for prim-
itives using sparse polynomial systems (e.g., hashes proposed in [15]).
They showed that which implies that using sparse polynomials systems of uniform density (in every
degree) for Merkle-Damg√•rd compression will not be universally collision-free. Some underdeÔ¨Åned systems
that are sparse in the higher degrees can be solved with lower complexity. Their results do not apply to
overdetermined systems in general. We summarize relevant results below.
1. Overdetermined higher-degree maps that are sparse of uniform density, or at least sparse in the linear
terms, is shown to have high probability of trivial collisions and near-collisions.
It seems that everyone agrees, that linear terms should be totally random when constructing sparse poly-
nomial systems for symmetric primitives.
2. Suppose we have an underdetermined higher-degree map sparse in the non-aÔ¨Éne part, i.e.,
P : Fn+r2 ‚Üí F
n
2 , P(x) = b+Mx+Q(x)
where Q has only quadratic or higher terms and is sparse. Aumasson-Meier suggests that we can Ô¨Ånd
P‚àí1(y) as follows: Ô¨Ånd a basis for the kernel space of the augmented matrix [M ;b + y]. Collect these
basis vectors in a (n+r+1)√ó(r+1) matrixM ‚Ä≤ as a linear code. For an arbitrary w ‚àà Fr+12 , the codeword
x¬Ø = M ‚Ä≤w will represent a solution to y = Mx+b if its last component is 1. Use known methods to Ô¨Ånd
relatively low-weight codewords for the code M ‚Ä≤ and substitute into Q(x), expecting it to vanish with
non-negligible probability.
Aumasson-Meier proposes to apply this for collisions in Merkle-Damg√•rd hashes with cubic compressor
functions. It does not work for Ô¨Åelds other than F2 or overdetermined systems. Its exact complexity is
unknown and requires some further work.
3. Conversely, it has been suggested if we have an overdetermined higher-degree map
P : Fn2 ‚Üí F
n+r
2 , P(x) = b+Mx+Q(x)
10
Stream Cipher Block Storage Cycles/Byte Security Level
SPELT (2,3,208,208,[480,20]) 208b 0.43 MB 11744 282 Proven
SPELT (16,4,108,108,[20,15,10]) 864b 48 kB 5541 280 Proven
QUAD (2,320,320) 320b 3.92 MB 13646 282 Proven
QUAD (2,160,160) 160b 0.98 MB 2081 2140 Best Attack
SPELT (16,4,32,32,[10,8,5]) 128b 8.6 kB 1244 2152 Best Attack
Table 3. Point-by-Point, SPELT vs. QUAD on a K8 or C2
is a good complement to the approach of using polynomial maps for symmetric primitives introduced by
Berbain-Gilbert-Patarin.
We hasten to add that our programming is quite primitive, and may not match the more polished
implementations (e.g., [5]). We are still working to improve our programming and parameter choices. Also,
in hardware implementations, the power of sparsity should be even more pronounced.
5.3 For Possible Use in Hashes
In [8] Billet et al proposes to use two-staged constructions with a random 192-bit to 464-bit expanding
quadratic map followed by a 464-bit to 384-bit quadratic contraction. They show that in general a PRNG
followed by a one-way compression function is a one-way function.
In [15] the same construction is proposed but with SRQ quadratics (see Appendix C) and no proof. Now
we see that the abovementioned results from [8] and Prop. 6, which justify the design up to a point. This is
an area that still takes some study, and perhaps require extra ideas, such as having a hybrid construction
with a sparse polynomial expansion stage and a diÔ¨Äerent kind of contraction stage.
References
1. J.-P. Aumasson and W. Meier. Analysis of multivariate hash functions. In K.-H. Nam and G. Rhee, editors,
ICISC, volume 4817 of Lecture Notes in Computer Science, pages 309323. Springer, 2007.
2. G. V. Bard, N. T. Courtois, and C. JeÔ¨Äerson. EÔ¨Écient methods for conversion and solution of sparse systems
of low-degree multivariate polynomials over gf(2) via sat-solvers. Cryptology ePrint Archive, Report 2007/024,
2007. http://eprint.iacr.org/.
3. M. Bardet, J.-C. Faug√®re, and B. Salvy. On the complexity of Gr√∂bner basis computation of semi-regular
overdetermined algebraic equations. In Proceedings of the International Conference on Polynomial System Solving,
pages 7174, 2004. Previously INRIA report RR-5049.
4. M. Bardet, J.-C. Faug√®re, B. Salvy, and B.-Y. Yang. Asymptotic expansion of the degree of regularity for
semi-regular systems of equations. In P. Gianni, editor, MEGA 2005 Sardinia (Italy), 2005.
5. C. Berbain, O. Billet, and H. Gilbert. EÔ¨Écient implementations of multivariate quadratic systems. In E. Biham
and A. M. Youssef, editors, Selected Areas in Cryptography, volume 4356 of Lecture Notes in Computer Science,
pages 174187. Springer, 2007.
6. C. Berbain and H. Gilbert. On the security of IV dependent stream ciphers. In Biryukov [9], pages 254273.
7. C. Berbain, H. Gilbert, and J. Patarin. QUAD: A practical stream cipher with provable security. In S. Vaudenay,
editor, EUROCRYPT, volume 4004 of Lecture Notes in Computer Science, pages 109128. Springer, 2006.
8. O. Billet, M. J. B. Robshaw, and T. Peyrin. On building hash functions from multivariate quadratic equations.
In J. Pieprzyk, H. Ghodosi, and E. Dawson, editors, ACISP, volume 4586 of Lecture Notes in Computer Science,
pages 8295. Springer, 2007.
9. A. Biryukov, editor. Fast Software Encryption, 14th International Workshop, FSE 2007, Luxembourg, Luxem-
bourg, March 26-28, 2007, Revised Selected Papers, volume 4593 of Lecture Notes in Computer Science. Springer,
2007.
10. L. Blum, M. Blum, and M. Shub. Comparison of two pseudo-random number generators. In R. L. Rivest,
A. Sherman, and D. Chaum, editors, CRYPTO'82, pages 6178, New York, 1983. Plenum Press.
11. B. Buchberger. Ein Algorithmus zum AuÔ¨Énden der Basiselemente des Restklassenringes nach einem nulldimen-
sionalen Polynomideal. PhD thesis, Innsbruck, 1965.
12
A Proof of Prop. 1
Proof. We introduce hybrid probability distributions Di(S) over K
L
(L := Œªr):
For 0 ‚â§ i ‚â§ Œª respectively associate with the random variables
ti(S,x) :=
(
w1, w2, . . . ,wi, P(x), P(Q(x)), . . . , P(Q
Œª‚àíi‚àí1(x))
)
where the wj and x are random independent uniformly distributed vectors in K
n
and we use the notational
conventions that (w1, w2, . . . , wi) is the null string if i = 0, and that(
P(x), P(Q(x)), . . . , P(QŒª‚àíi‚àí1(x))
)
is the null string if i = Œª. Consequently D0(S) is the distribution of the L-unit keystream and DŒª(S) is the
uniform distribution over KL. We denote by pi(S) the probability that A accepts a random L-long sequence
distributed according to Di(S), and pi the mean value of pi(S) over the space of sparse polynomial systems
S. We have supposed that algorithm A distinguishes between D0(S) and DŒª(S) with advantage , in other
words that |p0 ‚àí pŒª| ‚â• ¬≤.
Algorithm B works thus: on input (x1,x2) ‚àà K
n+r
with x1 ‚àà K
r
, x2 ‚àà K
n
, it selects randomly an i
such that 0 ‚â§ i ‚â§ Œª‚àí 1 and constructs the L-long vector
t(S,x1,x2) := (w1, w2, . . . , wi,x1,P(x2), P(Q(x2)), . . . , P(Q
Œª‚àíi‚àí1(x2))).
If (x1,x2) is distributed accordingly to the output distribution of S, i.e. (x1,x2) = S(x) = (P(x),Q(x)) for
a uniformly distributed value of x, then
t(S,x1,x2) :=
(
w1, w2, . . . ,wi, P(x), P(Q(x)), . . . , P(Q
Œª‚àíi‚àí1(x))
)
is distributed according to Di(S). Now if (x1,x2) is distributed according to the uniform distribution, then
t(S,x1,x2) =
(
w1, w2, . . . ,wi, x1, P(x2), P(Q(x2)), . . . , P(Q
Œª‚àíi‚àí2(x2))
)
which is distributed according to Di+1(S). To distinguish between the output of S from uniform, algorithm
B calls A with inputs (S, t(S,x1,x2)) and returns that same return value. Hence‚à£‚à£‚à£‚à£Pr
S,x
(B(S,S(x)) = 1‚àí Pr
S,x
(B(S,S(x1,x2)) = 1
‚à£‚à£‚à£‚à£
=
‚à£‚à£‚à£‚à£‚à£ 1Œª
Œª‚àí1‚àë
i=0
pi ‚àí
1
Œª
Œª‚àí1‚àë
i=0
pi
‚à£‚à£‚à£‚à£‚à£ = 1Œª |p0 ‚àí pŒª| ‚â• ¬≤Œª .
B XL and F4-F5 Families for System-Solving
The XL and F4-F5 families of algorithms are spiritual descendants of Lazard's idea [24]: run an elimination
on an extended Macaulay matrix (i.e., extending the resultant concept to many variables) as an improvement
to Buchberger's algorithm for computing Gr√∂bner bases [11].
Since we cannot discuss these methods in detail, we try to describe them brieÔ¨Çy along with their projected
complexities. Again, suppose we have the system P1(x) = P2(x) = ¬∑ ¬∑ ¬∑ = Pm(x) = 0, where Pi is a degree-di
polynomial in x = (x1, . . . , xn), coeÔ¨Écients and variables in K = Fq.
Method XL [12]: Fix a degree D(‚â• maxPi). The set of degree-D-or-lower monomials is denoted T = T
(D)
.
|T (D)| is the number of degree ‚â§ D monomials and will be denoted T = T (D). We now take each equation
Pi = 0 and multiply it by every monomial up to D‚àí di to get an equation that is at most degree D. Collect
all such equations in the set R = R(D) :=
‚ãÉm
i=1{(uPi = 0) : u ‚àà T
(D‚àídi)}. We treat every monomial in T as
independent and try to solve R as a linear system of equations.
14
The idea behind SRQ is that any quadratic map can be written as f ‚ó¶L, where f is a standard form and
L is an invertible linear map. Now we will choose L to be sparse. A standard form for characteristic 2 Ô¨Åelds
is the rank form which for full-rank quadratics is
P0(x) = x1x2 + x3x4 + ¬∑ ¬∑ ¬∑xn‚àí1xn.
Clearly, by taking a random c and b, we can give P0(x+ c)+ b any random aÔ¨Éne part. Since each x
(i)
is
related to x = x(0) by an invertible aÔ¨Éne map, this holds for every component Pi. This means that results
pertaining to sparsity of the linear terms such as [1] (cf. Sec. 4.3) never apply, and hence it is plausible for
SRQ to form a one way function class.
In Fig. 1, the samples labelled sparse non-random are SRQ tests. It seem as if their behavior under
MAGMA's F4 is no diÔ¨Äerent than normal quadratics.
In this SRQ construction, even if h = 3 (the rotation matrices M (i) have only three entries per row),
the number of cross-terms in each equations still quickly increases to have as many terms as totally random
ones, so point 2 in Sec. 4.3 does not apply here. Indeed, since a quadratic over F2 of rank 2k has bias 2
‚àík‚àí1
,
the SRQ form acts exactly like a random quadratic under point 3 in Sec. 4.3.
16
Square, a New Multivariate Encryption Scheme
Crystal Clough1, John Baena1,2, Jintai Ding1,4,
Bo-Yin Yang3, and Ming-shing Chen3
1 Department of Mathematical Sciences,
University of Cincinnati,
Cincinnati, OH, 45220, USA
{baenagjb,cloughcl}@email.uc.edu,ding@math.uc.edu
http://math.uc.edu
2 Universidad Nacional de Colombia
Carrera 65, Medell¬¥ƒ±n, Colombia
http://www.unalmed.edu.co/~dirmate/
3 Institute of Information Science,
Academia Sinica
Taipei, Taiwan
4 College of Sciences,
South China University of Technology
Guangzhou, China
Abstract. We propose and analyze a multivariate encryption scheme
that uses odd characteristic and an embedding in its construction. This
system has a very simple core map F (X) = X2, allowing for efficient
decryption. We also discuss ways to make this decryption faster with
specific parameter choices. We give heuristic arguments along with ex-
perimental data to show that this scheme resists all known attacks.
1 Introduction
Multivariate public-key cryptosystems (MPKCs) are considered viable options
for post-quantum cryptography. This is because they are based on the problem of
solving a system of multivariate polynomial equations, a problem which seems
just as hard for a quantum computer to solve as any other computer [12,20].
There are a few MPKCs that are believed secure and practical. We propose and
analyze a new encryption scheme that is both efficient and secure.
One tool used in several systems is the ‚Äúbig field‚Äù idea. While the public keys
of MPKCs are polynomial maps kn ‚Üí kn for some finite field k, some are con-
structed using maps over a ‚Äúbig field‚Äù K ‚àº= kn, using vector space isomorphisms
to go back and forth between the spaces. This approach is a two-edged sword in
the sense that the field structure of K can make decryption easier but can also
be utilized by attackers.
Until recently, the systems based on the ‚Äúbig field‚Äù idea (such as the original
MPKC C‚àó proposed by Matsumoto and Imai, HFE proposed by Patarin, and
their many variants) had other commonalities. All used characteristic 2 fields,
M. Fischlin (Ed.): CT-RSA 2009, LNCS 5473, pp. 252‚Äì264, 2009.
c¬© Springer-Verlag Berlin Heidelberg 2009
254 C. Clough et al.
K
F
 K
œÜ

kn
L1

Public Key P
k
n 
œÜ‚àí1

kn
L2
 kn
Fig. 1. The MI and HFE systems
or their variants could be relevant to the new system, so we will describe both
HFE and C‚àó here.
Refer to Figure 1. In either system, the plaintext is a vector of length n over
k, a field of q elements where q is a power of 2. Since there is a field K of the
same size as kn, we can utilize a nonlinear core map F : K ‚Üí K. In fact, the
public key is P = L2 ‚ó¶ œÜ ‚ó¶ F ‚ó¶ œÜ
‚àí1 ‚ó¶ L1, where L1 and L2 are linear maps and
œÜ is a vector space isomorphism K ‚Üí kn. P is a collection of n polynomials
pi(x1, . . . , xn) in n variables. The decomposition, in particular L1 and L2, is the
private key.
In the case of C‚àó, F (X) = Xq
Œ∏+1 for an appropriate Œ∏. In the case of HFE,
for some D
F (X) =
‚àë
0‚â§i<j<n
qi+qj‚â§D
aijX
qi+qj +
‚àë
0‚â§i<n
qi‚â§D
biX
qi + c. (1)
2.2 Linearization Equations Attack
In the original attack on C‚àó, Patarin noticed that if Y = Xq
Œ∏+1, then XY q
Œ∏
‚àí
Xq
2Œ∏
Y = 0 [17]. This equation forces plaintext-ciphertext pairs from C‚àó systems
to satisfy linearization equations
n‚àë
i,j=1
aijxiyj +
n‚àë
j=1
bjxj +
n‚àë
j=1
cjyj + d = 0,
where (y1, . . . , yn) = P (x1, . . . , xn). Such equations are extremely useful for an
attacker because given a ciphertext, the linearization equations yield linear equa-
tions satisfied by the plaintext. Also, linearization equations can be found easily
from the public key, so an attacker has access to them.
Diene et al showed that the space of linearization equations satisfied by a
C‚àó public key has dimension at least n in most cases [4]. Furthermore Patarin
showed that for a given nonzero ciphertext, the space of linear equations satisfied
by the correspoding plaintext is at least n‚àí gcd(n, Œ∏) [17].
Note that in the original C‚àó construction, Œ∏ = 0 cannot be chosen since X2
is a linear map when q = 2.
256 C. Clough et al.
2.5 Kipnis-Shamir Style Attacks
The Kipnis-Shamir attack against HFE exploits the ‚Äúbig field‚Äù structure. It uses
the following facts, all found in [14]:
‚Äì LetFqn be thefieldof q
n elements. IfG ‚àà Fqn [X ] such that the q-Hamingweight
of all monomials is 2 (ie, G(X) =
‚àë
aijX
qi+qj ), then ‚àÉG ‚àà Mn√ón(Fqn) such
that
G(X) =
(
X Xq ¬∑ ¬∑ ¬∑ Xq
n‚àí1
)
G
Ô£´
Ô£¨Ô£¨Ô£¨Ô£≠
X
Xq
...
Xq
n‚àí1
Ô£∂
Ô£∑Ô£∑Ô£∑Ô£∏ .
‚Äì If G is such a matrix for G, S is a linear map Fqn ‚Üí Fqn , and F = S ‚ó¶ G,
then
F =
n‚àë
j=0
sjG
‚àój ,
where the sj are the coefficients of S and the G
‚àój are obtained from G via
permutations and Frobenius maps (x ‚Üí xq
j
for 0 ‚â§ j ‚â§ n‚àí 1).
‚Äì If G is such a matrix for G, S is a linear map Fqn ‚Üí Fqn , and F = G ‚ó¶ S,
then
F =WGWT ,
where W is obtained from the coefficients of S.
Kipnis and Shamir noted that in the case of HFE, by ‚Äúlifting‚Äù the public key
to an extension L ‚àº= Fqn via some isomorphism œà : L‚Üí k
n and considering the
quadratic part, we can find corresponding matrices whose rank must be no more
than D. Though L is not necessarily the K used to construct the public key, we
still have a decomposition P = œà ‚ó¶S ‚ó¶F ‚ó¶T ‚ó¶œà‚àí1 where S and T are linear and
F is some HFE core map.
Using the facts above, Kipnis and Shamir were able to find such a decom-
position [14]. The success depends on solving the MinRank problem: Given a
collection of matrices, find a linear combination of them that has minimal rank.
In general, this problem is NP-complete [3].
3 Design of Square
Having seen what a multivariate encryption scheme is up against, we now de-
scribe a new system Square.
See Figure 2. Let k be a field of size q, where q ‚â° 3 mod 4. Plaintexts will be
vectors in kn. Let K ‚àº= k[y]/„Äàg(y)„Äâ be a degree n + l extension of k, where l is
such that n+ l is odd. The public key will be built up from the following maps:
‚Äì œï : K ‚Üí kn+l, the vector space isomorphism given by
an+ly
n+l‚àí1 + ¬∑ ¬∑ ¬∑+ a2y + a1 ‚Üí (an+l, . . . , a1)
258 C. Clough et al.
Table 2. Encryption and decryption times, in seconds, for Square systems. 10 public
keys tested and 100 messages encrypted and decrypted per key.
q n l Average Encrypt Time Average Decrypt Time
31 20 3 0.00022 0.001527
31 32 3 0.00033 0.006781
31 34 3 0.000423 0.003651
43 20 3 0.000234 0.001783
43 34 3 0.000495 0.008135
4 Security Analysis
Let us now present our case for the security of this design. We will explain our
motivation and then dig into the specific reasons why each of the aforementioned
attacks does not work.
But first, we provide a more thorough comparison to the very similar system
proposed by Patarin [20]. His systemD‚àó also uses a square core map, and Patarin
brokeD‚àó himself. He did so by finding a way to recover ‚Äúbig field‚Äù multiplications
without having the big field. As we will see below in Section 4.4, the embedding
makes it very hard to recover the multiplicative structure of K. In particular,
Patarin‚Äôs attack on D‚àó relies on the ability to find pairs of linear maps (C,D)
such that for all x1, x2 ‚àà k
n,
C(F (x1 + x2)‚àí F (x1 ‚àí x2)) = F (D(x1) + x2)‚àí F (D(x1)‚àí x2).
When L1 is invertible, the collection of such pairs forms a vector space of di-
mension at least n (exactly n according to [20]) which is required for Patarin‚Äôs
attack. In our case, L1 is a map k
n ‚Üí kn+l and thus cannot be invertible.
4.1 Motivation for the Design
All of the ideas used in Square have been seen before; what makes this system
novel is that these ideas are combined in such a way that they work.
First, the use of odd characteristic was shown to be a good idea for thwarting
algebraic attacks in [6]. This seems to be because the attacker knows that a
plaintext (x1, . . . , xn) satisfies not only the public key equations (2) but also the
Fq field equations x
q
i ‚àí xi = 0. When q is small, this additional information is
very useful, and feeding the field equations into MAGMA along with (2) allows
for more efficient solving. However, as discussed in [6], for larger q the field
equations do not simplify the algorithm and in fact F4 runs faster without them.
Secondly, the use of a low-degree core map was inspired by [2], where an odd-
characteristic signature scheme with low-degree core map was proposed. It was
natural to ask if this idea could be used for encryption as well. However, the
signature scheme in [2] uses a vinegar construction, which is not well-suited for
encrytion.
260 C. Clough et al.
Fig. 3. Algebraic attack for q=31, l = 3, varying n
To inform our choice of q, we tested the effect of changing q while fixing n and
l. Our results can be found in Table 4.3 and Figure 4.3. These attacks were done
without using field equations xqi ‚àíxi = 0 for the reasons described in Section 4.1.
From this data we see that beyond small values of q, the size of the field does
not seem to impact F4‚Äôs running time or memory usage. This was expected in
light of the results of [2] and [6], and justifies the choice of q = 31 for a practical
system. Another reason to choose q = 31 is that such a choice makes good use
of memory, in the sense that the elements of k will require 5 bits to be stored
and any larger field will require more bits to store an element.
Table 4. Algebraic attack for n = 12, l = 3 and varying q
q Average F4 Memory
Running Time Usage
3 0.011 6
7 7.082 22
11 9.092 24
19 16.502 26
23 16.308 26
31 15.973 26
43 15.685 26
47 15.618 26
4.4 SFlash-Style Attack
Our public keys are maps kn ‚Üí kn+l. We have constructed the public key P by
emebedding the space of plaintexts into a larger space, but one could imagine P
as coming from a larger C‚àó scheme by setting the last l components of the input
to 0. Effectively, P is the public key for a (non-embedded) C‚àó scheme with all
monomials involving xn+1, . . . , or xn+l deleted.
From this point of view, it is important to study the attack on SFlash since its
purpose was to recover missing coefficients of the public key (ie, the coefficients
262 C. Clough et al.
the original efficiency claims [13]. We tested this attack in the Square case and
found that even with the ‚Äúbaby‚Äù case of q = 5, n = 2, l = 1, the system that
arises from this attack involves 18 cubic equations in 14 variables and solving it
exceeded the memory of our computer. We also tried using 2√ó2 minors as a way
to generate equations from the rank condition, but this yields quartic equations
with a savings of only 2 variables. This method also exceeded the memory of
our computer with q = 5, n = 2, l = 1. Considering this, it is not plausible that
such an attack would be dangerous for realistic parameter choices.
5 Parameter Suggestions and Implementations
Based on the security analysis above, an Square system with the following pa-
rameter choices will be viable:
Square-34
‚Äì q = 31
‚Äì n = 34
‚Äì l = 3
‚Äì Average encryption time: 0.000423 seconds
‚Äì Average decryption time: 0.003651 seconds
‚Äì Public key size: 15 KB
‚Äì Best known attack: > 280 computations.
A system with these parameters will be secure and have relatively fast decryption
using the power forumla mentioned in Section 3. Of course, these numbers are
very conservative. If we are concerned for speed and not so much for portability,
there are ways to get the implementation much faster.
Square Roots. Since we are always dealing with a pre-determined field, pre-
computation is not a problem. If (field size) ‚àí 1 = 2a √ó (odd number o),
taking square roots is always possible via raising to the power of o‚àí12 using
a pre-computed table with 2a elements (the Tonelli-Shanks method [21]).
Consider the case n = 51, l = 3. Since n+ l = 54 is even, during decryp-
tion we cannot use the formula X = ¬±Y
qn+l+1
4 as in the Square-34 case.
However, via raising to a power of 1128 (31
54‚àí65), we see that square roots in
1 (mod 4) and 3 (mod 4) field sizes does not differ much, since the number
of ‚Äútotal multiplications‚Äù does not increase much (at most 1.5√ó in all our
experiments).
Choice of Field. We should choose a field with a ‚Äúgood‚Äù irreducible polyno-
mial. For example, for k = F31, only certain (x
h ‚àí Œ±) can be irreducible
which makes things very fast. Values of h above 34 that is of interest to us
here are 45 and 54. and in fact F3145 ‚àº= k[x]/(x
45‚àí3), F3154 ‚àº= k[x]/(x
54‚àí3).
Which in and of itself is very simple. But there is a further trick as in the
following:
264 C. Clough et al.
7. Dubois, V., Fouque, P.-A., Shamir, A., Stern, J.: Practical cryptanalysis of
SFLASH. In: Menezes, A. (ed.) CRYPTO 2007. LNCS, vol. 4622, pp. 1‚Äì12.
Springer, Heidelberg (2007)
8. eBACS: ECRYPT benchmarking of cryptographic systems,
http://bench.cr.yp.to
9. Fauge¬¥re, J.-C.: A new efficient algorithm for computing Gro¬®bner bases (F4). J.
Pure Appl. Algebra 139(1-3), 61‚Äì88 (1999); effective Methods in algebraic geometry
(Saint-Malo) (1998)
10. Fauge`re, J.-C.: A new efficient algorithm for computing Gro¬®bner bases without
reduction to zero (F5). In: Proceedings of the 2002 International Symposium on
Symbolic and Algebraic Computation, pp. 75‚Äì83. ACM, New York (2002)
11. Fauge`re, J.-C., Joux, A.: Algebraic cryptanalysis of Hidden Field Equation (HFE)
cryptosystems using Gro¬®bner bases. In: Boneh, D. (ed.) CRYPTO 2003. LNCS,
vol. 2729, pp. 44‚Äì60. Springer, Heidelberg (2003)
12. Garey, M.R., Johnson, D.S., et al.: Computers and Intractability: A Guide to the
Theory of NP-completeness. W.H Freeman, San Francisco (1979)
13. Jiang, X., Ding, J., Hu, L.: Public Key Analysis-Kipnis-Shamir Attack on HFE
Revisited. In: Pei, D., Yung, M., Lin, D., Wu, C. (eds.) Inscrypt 2007. LNCS,
vol. 4990, pp. 399‚Äì411. Springer, Heidelberg (2008)
14. Kipnis, A., Shamir, A.: Cryptanalysis of the HFE public key cryptosystem by
relinearization. In: Wiener, M. (ed.) CRYPTO 1999. LNCS, vol. 1666, pp. 19‚Äì30.
Springer, Heidelberg (1999)
15. The MAGMA computational algebra system home page,
http://magma.maths.usyd.edu.au/magma
16. Matsumoto, T., Imai, H.: Public quadratic polynomial-tuples for efficient signature-
verification and message-encryption. In: Gu¬®nther, C.G. (ed.) EUROCRYPT 1988.
LNCS, vol. 330, pp. 419‚Äì453. Springer, Heidelberg (1988)
17. Patarin, J.: Cryptanalysis of the Matsumoto and Imai public key scheme of EU-
ROCRYPT 1988. In: Coppersmith, D. (ed.) CRYPTO 1995. LNCS, vol. 963, pp.
248‚Äì261. Springer, Heidelberg (1995)
18. Patarin, J.: Hidden fields equations (HFE) and Isomorphisms of Polynomials (IP):
Two new families of asymmetric algorithms. In: Maurer, U.M. (ed.) EUROCRYPT
1996. LNCS, vol. 1070, pp. 33‚Äì48. Springer, Heidelberg (1996)
19. Patarin, J., Courtois, N.T., Goubin, L.: FLASH, a fast multivariate signature al-
gorithm. In: Naccache, D. (ed.) CT-RSA 2001. LNCS, vol. 2020, pp. 298‚Äì307.
Springer, Heidelberg (2001)
20. Patarin, J., Goubin, L.: Trapdoor one-way permutations and multivariate poly-
nominals. In: Han, Y., Quing, S. (eds.) ICICS 1997. LNCS, vol. 1334, pp. 356‚Äì368.
Springer, Heidelberg (1997)
21. Shanks, D.: Five numbertheoretic algorithms. In: Thomas, R.S.D., Williams, H.C.
(eds.) Proceedings of the Second Manitoba Conference on Numerical Mathematics,
pp. 51‚Äì70 (1972)
2 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
 DiÔ¨Äerentials also helps with randomized brute-force searches for S and T .
 We can assess how Rainbow-like schemes needs to be amended in view of
recent developments.
 The results are in line with experiments run on small scale systems.
In Sec. 2 we recap Rainbow-like multivariates and what is known about the secu-
rity of MPKC before the appearance of Rainbow in Sec. 3. In Sec. 4, we describe
the new diÔ¨Äerential attack, which is related to the high-rank attack, and in Sec. 5
we present new paramters for Rainbow construction, we tabulate what we know
about the security of Rainbow-like schemes, in particular, the security against
the two new recent attacks specially targeted against the Rainbow schemes, and
we design schemes with new parameters for practical applications. Finally, in
Sec. 6, we present the conclusion.
2 Rainbow-like Multivariate Signatures
We characterize a Rainbow type PKC with u stages:
 The segment structure is given by a sequence 0 < v1 < v2 < ¬∑ ¬∑ ¬∑ < vu+1 = n.
For l = 1, . . . , u+ 1, set Sl := {1, 2, . . . , vl} so that |Sl| = vl and S0 ‚äÇ S1 ‚äÇ
¬∑ ¬∑ ¬∑ ‚äÇ Su+1 = S.
 Denote by ol := vl+1 ‚àí vl and Ol := Sl+1 \ Sl (i.e., vl < k ‚â§ vl+1 if k ‚àà Ol)
for l = 1 ¬∑ ¬∑ ¬∑u. The central map Q : x = (x1, . . . , xn) 7‚Üí y = (yv1+1, . . . , yn),
where each yi := qi(x) is a quadratic polynomial in x of the following form
qk =
‚àë
i<j‚â§vl
Œ±
(k)
ij xixj +
‚àë
i‚â§vl<j<vl+1
Œ±
(k)
ij xixj +
‚àë
i<vl+1
Œ≤
(k)
i xi, if vl < k ‚â§ vl+1.
In every qk, k ‚àà Ol, there is no cross-term xixj where both i and j are in
Ol at all. So given all the yi with vl < i ‚â§ vl+1, and all the xj with j ‚â§ vl,
we can compute xvl+1, . . . , xvl+1 .
 To expedite computations, some coeÔ¨Écients Œ±ijk's may be Ô¨Åxed (e.g., set to
zero), chosen at random (and included in the private key), or be interrelated
in a predetermined manner.
 To invert Q, determine (usu. at random) x1, . . . xv1 , i.e., all xk, k ‚àà S1. From
the components of y that corresponds to the polynomials qv1+1, . . . qv2 , we
obtain a set of o1 equations in the variables xk, (k ‚àà O1). We may repeat
the process to Ô¨Ånd all remaining variables.
In this form, we can see that Rainbow can only be a signature scheme. We
can see a good example of what can go wrong in [15] if we try to construct an
encryption scheme, where the initial vinegar variables is determined through an
initial block of equations.
4 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
 The EIP problem where C is the set of homogeneous quadratic maps is
easy [13]. Equivalently, if Q is homogeneous (e.g., as in SFLASH=C‚àó‚àí) we
can set cS = cT = 0.
If Q fundamentally involves a map in a Ô¨Åeld L = Kk that is of a size signif-
icantly bigger than K, we call the scheme big Ô¨Åeld or dual Ô¨Åeld. This order
includes derivatives of Matsumoto-Imai (C‚àó) and Hidden Field Equations. Oth-
erwise we call the scheme a true multivariate (sometimes single Ô¨Åeld). This
includes the Unbalanced Oil-and-Vinegar and stagewise triangular structures.
One of the biggest concerns of multivariate cryptography is the lack of prov-
able security results. Today security in MPKC is still very much ad hoc. Proposed
schemes are evaluated against known attacks security estimates obtained for var-
ious parameters. The designers then tries to juggle the system parameters so as
to have some requisite security level under every known attack.
With that, we list the standard attacks known for MPKCs today:
1. Rank (or Low Rank, MinRank) attack, which Ô¨Ånds a central equation with
least rank [25].
C
low rank
‚âà
[
qrdm/nem(n2/2‚àím2/6)/¬µ
]
m.
Here as below, the unit m is a multiplications in K, and r is that lowest
rank (MinRank, [14]). ¬µ is the number of linear combinations of central
equations [25] at that minimal rank.
2. Dual Rank (or High Rank) attack [5, 14], which Ô¨Ånds a variable appearing
the fewest number of times in a central equation cross-term. If this least
number is s, [25] gives
C
high rank
‚âà
[
qsn3/6
]
m.
3. Oil-and-Vinegar Separation [16, 17, 22], which Ô¨Ånds an Oil subspace that is
suÔ¨Éciently large (estimates as corrected in [25]).
C
UOV
‚âà
[
qn‚àí2o‚àí1o4 + (some residual term bounded by o3qm‚àío/3)
]
m.
o is the max. oil set size, i.e., there is a set of o central variables which are
never multiplied together in the central equations, and no more.
4. Trying for a direct solution (i.e., going for theMQ as opposed to the EIP or
structural problem). Best known methods are the Lazard-Faug√®re family
of solvers (the Gr√∂bner Bases methods F4-F5 or XL) whose complexities
[6, 9, 10, 24] are very hard to evaluate; some recent asymptotic formulas can
be found in [1, 2, 24].
4 New DiÔ¨Äerential attacks
One key point of our new attack is to use the diÔ¨Äerentials (Ô¨Årst used, as far as
we know, with MPKC in [18] and recently to break SFLASH [8]).
6 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
We call any polynomial in Pl an l-th layer Oil and Vinegar polynomial. Clearly
we have Pi ‚äÇ Pj for i < j. Let Wi be the space of linear functions of variables
x1, ..., xvi . Then we have
W1 ‚äÇ P1 ‚äÇW2 ‚äÇ P2 ¬∑ ¬∑ ¬∑ ‚äÇWu ‚äÇ Pu ‚äÇWu+1.
Now we present the new attack:
Algorithm 1 The Improved High-Rank Attack using diÔ¨Äerentials:
1. Pick random c, c‚Ä≤ ‚àà Kn, compute P(w+c)‚àíP(w)‚àíP(c), and we will denote
its components as (t1, t2, . . . , tm). Similarly we compute (t
‚Ä≤
1, t
‚Ä≤
2, . . . , t
‚Ä≤
m) =
P(w + c‚Ä≤)‚àí P(w)‚àí P(c‚Ä≤), then
U = span(t1, t2, . . . , tm) ‚à© span(t
‚Ä≤
1, t
‚Ä≤
2, . . . , t
‚Ä≤
m).
2. Guess at a linear form f ‚àà U ; Ô¨Ånd coeÔ¨Écients ai and a
‚Ä≤
i such that f =‚àë
aiti =
‚àë
a‚Ä≤it
‚Ä≤
i.
3. Use ai and a
‚Ä≤
i as the guessed Œ±i in the High Rank Attack (Algorithm 0) above.
Proposition 1. The expected complexity of Algorithm 1 is ‚àº qd¬∑(cubic-time elimination)
where (the last block of equations is the ones whose solutions gives Ou)
d ‚â§ s‚àí [# vars appearing in crossterms only in the last block]. (2)
Proof. Let
F = (F1, . . . , Fm) = Q ‚ó¶ S
be the mapping from x 7‚Üí z. Let
F (x + b)‚àí F (x)‚àí F (b) := G = (G1, G2, . . . , Gn),
where b = (b1, b2, . . . bi, . . . , bn) is randomly chosen. Pick another b
‚Ä≤
and form
H = (H1, . . . , Hn) = F (x + b
‚Ä≤)‚àí F (x)‚àí F (b‚Ä≤),
then
1. if i ‚àà Oj , then Gi,Hi ‚ààWj+1;
2. W j+1 := span{Gi}i‚ààOj ‚äÇ Wj+1, and similarly WÃÇj+1 := span{Hi}i‚ààOj ‚äÇ
Wj+1;
3. W 2 ‚äÇ ... ‚äÇWu+1 and WÃÇ2 ‚äÇ ... ‚äÇ WÃÇu+1.
Clearly (WÃÇu
‚ãÇ
Wu) ‚äÇ (WÃÇu+1
‚ãÇ
Wu+1), and we observe that: if the dimen-
sions of the two subspaces diÔ¨Äer by d, then we can break the system with
‚àù qd ¬∑ (one guess) computations.
How so? Because the relationship between P and F , is the same as that
between the w-space and x-space, i.e., the linear transformation S. So there is
a 1-in-qd chance that both
‚àë
aizi and
‚àë
a‚Ä≤izi correspond to a linear form in
8 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
5 New Rainbow Parameters for Practical Applications
For practical applications, we will propose the following Rainbow Structures.
1. (20, 10, 4, 10), where the public key has 44 variables and 24 polynomials.
2. (18, 12, 12), where the public key has 42 variables and 24 polynomials.
3. (20, 14, 14), where the public key has 48 variables and 28 polynomials.
We will Ô¨Årst formalize a twist on the regular Rainbow construction, which
is somewhat more general. In the previous constructions, in each new layer,
previously appeared variables will only be Vinegar variables, the new variables
appearing only as Oil variables. We can also consider adding new Vinegar vari-
ables as we add Oil variables. This also implies that in the signing process, we
guess at the new vinegar variables as they appear, while in the previous Rainbow
construction, we only guess the Vinegar variables in the Ô¨Årst layer once. In this
case, we can also write for each layer two parameters, (v‚Ä≤i, oi), where the v
‚Ä≤
i counts
the new vinegar variables we introduce. In this layer, we will have vi+v
‚Ä≤
i Vinegar
variables (where vi counts the number of all previous appearing variables) and
oi the number of Oil variables.
If all the v‚Ä≤i are zero, this is precisely the original Rainbow construction. We
might call this new construction the extended Oil-Vinegar construction. From
the viewpoint of the attacker we can see this as a specialization of the Rainbow
construction, since the new vinegar variables might as well have been part of
the initial block of vinegar variables, but simply never have been used before.
However, it is diÔ¨Äerent in an operative sense, in that if we use the new vinegar
variables properly, we could always Ô¨Ånd a signature, as implicitly used in TTS
constructions earlier.
So, in this language, we would propose scheme: ((15, 10), (4, 4), (1, 10)), ((17, 12), (1, 12)),
and ((19, 14), (1, 14)).
For these new schemes, we could also choose to use the generic sparse poly-
nomials or special sparse polynomials as in the case of TTS [25]. For generic
sparse polynomials, we think it is a good idea to choose 3Li terms for each layer,
where Li is the sum of number of Oil and vinegar variables in each layer.
For these new schemes, we need to take into two new recent special attacks
against Rainbow.
5.1 The Reconciliation Attack
In the following attack we attempt to Ô¨Ånd a sequence of change of basis that let
us invert the public map. In this sense it can be considered an improved brute
force attack.
Suppose we have an oil-and-vinegar structure, then the quadratic part of each
component qi in the central map from x to y, when expressed as a symmetric
10 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
Algorithm 2 (UOV Reconciliation) The following gives the Reconciliation Attack
against a UOV scheme with o oil and v = n‚àí o vinegar variables (which has the
smaller indices):
1. Perform basis change wi := w
‚Ä≤
i ‚àí Œªiw
‚Ä≤
n for i = 1 ¬∑ ¬∑ ¬∑ v, wi = w
‚Ä≤
i for i =
v + 1 ¬∑ ¬∑ ¬∑n. Evaluate z in w‚Ä≤.
2. Let all coeÔ¨Écients of (w‚Ä≤n)
2
be zero and solve for the Œªi. We may use any
method such as F4/F5 or FXL. There will be m equations in v unknowns.
3. Repeat the process to Ô¨Ånd Pn‚àí1. Now we set w
‚Ä≤
i := w
‚Ä≤‚Ä≤
i ‚àíŒªiw
‚Ä≤‚Ä≤
n‚àí1 for i = 1 ¬∑ ¬∑ ¬∑ v,
and set every (w‚Ä≤‚Ä≤n‚àí1)
2
and w‚Ä≤‚Ä≤nw
‚Ä≤‚Ä≤
n‚àí1 term to zero (i.e., more equations in the
system) after making the substitution. This time there are 2m equations in
v unknowns.
4. Continue similarly to Ô¨Ånd Pn‚àí2, . . . , Pv+1 with more and more equations.
Given what we know about system-solving today, we can expect the complexity
to be determined in solving the initial system. Hence, if v < m, solving m
equations in v variables will be easier than m equations in n equations, and we
achieve a simpliÔ¨Åcation.
Proposition 2. The Reconciliation Attack works with probability ‚âà
(
1‚àí 1q‚àí1
)
.
Proof (Sketch). Provided that lower-right o√óo submatrix of MS is non-singular,
we can see that the construction of Pn will eliminate the quadratic term in the
last variable. Pn‚àí1 will eliminate all quadratic terms in the last two variables,
and so on, and each sequential construction will not disturb the structure built
by the prior transformations. The number of nonsingular k√ó k matrices in over
GF(q) is (qk ‚àí 1)(qk ‚àí q)(qk ‚àí q2) ¬∑ ¬∑ ¬∑ (qk ‚àí qk‚àí1), because the Ô¨Årst row has 1
possibility to be zero, the second row q possibilities to be a multiple of the Ô¨Årst,
the third row q2 possibilities to be dependent on the Ô¨Årst two, etc., so the chance
that the above attack works is roughly(
1‚àí
1
q
)(
1‚àí
1
q2
)
¬∑ ¬∑ ¬∑
(
1‚àí
1
qk
)
> 1‚àí
(
1
q
+
1
q2
+ ¬∑ ¬∑ ¬∑+
1
qk
)
> 1‚àí
1
q ‚àí 1
.
Here we will use formulas from [26] for all our estimates as shown below.
Example 4. We attack enTTS(20,28) as in Eq. 1. Originally we must solve a 20-
equation, 20-variable (we can guess 8 out of the original 28) MQ system. With
vu = 19, the rate-determining step of the Reconciliation Attack is a 20-equation,
19-variable system. This is easier by a factor of exactly 28 if we are using FXL
or FF4 [1, 24], since we will guess exactly one fewer variable.
Since we expect a direct attack on enTTS(20,28) to have ‚àº 272 complexity,
Alg. 2 should take ‚àº 264. The construction process and odds as given above
have been tested and veriÔ¨Åed on miniature versions (cf. [25]) of TTS schemes
such as enTTS(16,22) as well as other Rainbow-like instances.
Example 5. TRMS [20] can be reduced to 264 via the same attack (a faster attack
given below) because it has rainbow layer parameters of (8, 6, 2, 3, 9), with a last
block of the same size as TTS.
12 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
most of the time only the lower right entry as zero. But if we take any o+ 1 of
those last columns, there will be a non-trivial linear dependency. We can verify
that by setting one of those columns as the linear combination as the other o,
the resulting equations are still quadratic!
Algorithm 3 (Rainbow Band Separation) Reconciliation may be extended
for a Rainbow scheme where the Ô¨Ånal stage has o oil and v = n ‚àí o vinegar
variables (which has the smaller indices):
1. Perform basis change wi := w
‚Ä≤
i ‚àí Œªiw
‚Ä≤
n for i = 1 ¬∑ ¬∑ ¬∑ v, wi = w
‚Ä≤
i for i =
v + 1 ¬∑ ¬∑ ¬∑n. Evaluate z in w‚Ä≤.
2. Find m equations by setting all coeÔ¨Écients of (w‚Ä≤n)
2
to be zero; there are v
variables in the Œªi's.
3. Set all cross-terms involving w‚Ä≤n in z1 ‚àí œÉ
(1)
1 zv+1 ‚àí œÉ
(1)
2 zv+2 ‚àí ¬∑ ¬∑ ¬∑ ‚àí œÉ
(1)
o zm
to be zero and Ô¨Ånd n‚àí1 more equations. Note that (w‚Ä≤n)
2
terms are assumed
gone already, so we can no longer get a useful equation.
4. Solve m + n ‚àí 1 quadratic equations in o + v = n unknowns. We may use
any method (e.g., F4 or XL).
5. Repeat the process to Ô¨Ånd Pn‚àí1. Now set w
‚Ä≤
i := w
‚Ä≤‚Ä≤
i ‚àí Œªiw
‚Ä≤‚Ä≤
n‚àí1 for i = 1 ¬∑ ¬∑ ¬∑ v,
and set every (w‚Ä≤‚Ä≤n‚àí1)
2
and w‚Ä≤‚Ä≤nw
‚Ä≤‚Ä≤
n‚àí1 term to zero after making the substitu-
tion. Also set z2‚àí œÉ
(2)
1 zv+1‚àí œÉ
(2)
2 zv+2‚àí ¬∑ ¬∑ ¬∑ ‚àí œÉ
(2)
o zm to have a zero second-
to-last column. This time there are 2m+ n‚àí 2 equations in n unknowns.
6. Continue in the same vein to Ô¨Ånd Pn‚àí2, . . . , Pv+1.
The idea was mentioned by Mr. Yu-Hua Hu to one of the authors in a con-
versation, for which we are indebted. And this attack explains why the current
parameter set suggested looks like that in Sec. 5.
Example 8. We run the attack on an instance of enTTS(16, 22) [25] which has the
shape (6, 7, 1, 1, 7). The algebraic portion of the attack results in a system with
22 variables and 37 equations. This with XL at degree DXL = 6 can be solved
using 400MB (actually 415,919,856 bytes) of memory and 123,257 seconds on a
16-core, 2.2GHz Opteron machine with a total of 1,877,572 seconds of K8-CPU
time. The number of multiplications is about 247, or ‚àº 16 cycles a multiplication.
On a single core, a K8 machine running XL-Wiedemann can average one multi-
plication in GF(28) in about 9 cycles. The slowdown comes from the communi-
cations requirement between cores.
Example 9. The attack on an instance of enTTS(20, 28) [25] should result in a
system with 22 variables and 37 equations. This with XL at degree DXL = 7
should be solvable in 15GB of main memory and about 256 multiplications. This
is under the design complexity of 272.
We are also testing the prowess of other system-solving methods like Magma's
F4.
14 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
 There should be enough equations to avoid direct solution via a Lazard-
Faug√®re solver.
Current estimate [24] is that 20 underdetermined equations in GF(28) achieves
272; 24 equations achieves 282; each extra equation roughly gives a factor
& 22.5 to the complexity [24].
We conclude that all three Rainbow like schemes we propose below have security
levels above 280 elementary operations. The best attack is with Algorithm 3, and
the expected complexity in GF(28) multiplications is 284, 287, 280 respectively.
1. Rainbow (20,10,4,10), in the extended form ((15, 10), (4, 4), (1, 10))
2. Rainbow (18,12,12), in the extended form ((17, 12), (1, 12))
3. Rainbow (20,14,14), in the extended form ((19, 14), (1, 14)).
Of course, without using the extended form, the security level would not be any
lower, the extended form merely guarantees the existence of a signature always.
We hasten to add that the form given above is not much slower in signing
than the previous TTS. In preliminary runs, a single signature for (20,10,4,10)
version averages to about 157¬µs, still way faster than any competitor.
6 Conclusion
In this paper, we present a new diÔ¨Äerential attack and a new Rainbow construc-
tions. We design new schemes for practical applications.
With these constructions, we note that the design security of the system
would still go up exponentially as the length of the hash in both generic (rain-
bow) and sparse (TTS) variants. Perhaps, we might even say that the kinks of
this approach is being ironed out, and multivariate cryptographers are Ô¨Ånally
beginning to understand Rainbow-like Multivariate Signatures
Another development that aÔ¨Äects Rainbow-like schemes is the fact that SHA-
1 is being phased out in the wake of recent results [21]. This means that hashes
and hence signatures might become longer in a hurry. ECC is aÔ¨Äected in much the
same way, because 163- or 191-bit ECC may be obsoleted when everyone switches
to SHA-2 (no one really wants to use a truncated hash if it can be helped). Even
such state-of-the-art work as [3] would force the slightly uncomfortable SHA-
224. With multivariate signature schemes, an additional problem is the large
(and sometimes redundant, cf. [23]) keys. One might look toward other base
Ô¨Åelds such as GF(16) to help with the key size problem, but this would also pose
new challenges in optimization. Another way is to look for a safe TTS (built on
the similar layer structures as speciÔ¨Åed above), now that hash sizes has gotten
longer. Though the new attacks are found on Rainbow schemes, these attacks
can be easily prevented by adjusting the parameter. All in all, we think that
multivariates including Rainbow-like schemes still deserve a good look as the
age of quantum computers approaches.
16 J. Ding, B.-Y. Yang, Owen Chen, M.-S. Chen, and C.-M. Cheng
12. Michael R. Garey and David S. Johnson. Computers and Intractability  A Guide
to the Theory of NP-Completeness. W.H. Freeman and Company, 1979. ISBN 0-
7167-1044-7 or 0-7167-1045-5.
13. W. Geiselmann, R. Steinwandt, and Th. Beth. Attacking the aÔ¨Éne parts of SFlash.
In Cryptography and Coding - 8th IMA International Conference, volume 2260 of
Lecture Notes in Computer Science, pages 355359. B. Honary, editor, Springer,
2001. Extended version: http://eprint.iacr.org/2003/220/.
14. Louis Goubin and Nicolas T. Courtois. Cryptanalysis of the TTM cryptosystem.
In Advances in Cryptology  ASIACRYPT 2000, volume 1976 of Lecture Notes in
Computer Science, pages 4457. Tatsuaki Okamoto, editor, Springer, 2000.
15. Antoine Joux, S√©bastien Kunz-Jacques, Fr√©d√©ric Muller, and Pierre-Michel Ri-
cordel. Cryptanalysis of the tractable rational map cryptosystem. In PKC [19],
pages 258274.
16. Aviad Kipnis, Jacques Patarin, and Louis Goubin. Unbalanced Oil and Vinegar
signature schemes. In Advances in Cryptology  EUROCRYPT 1999, volume
1592 of Lecture Notes in Computer Science, pages 206222. Jacques Stern, editor,
Springer, 1999.
17. Aviad Kipnis and Adi Shamir. Cryptanalysis of the oil and vinegar signature
scheme. In Advances in Cryptology  CRYPTO 1998, volume 1462 of Lecture
Notes in Computer Science, pages 257266. Hugo Krawczyk, editor, Springer, 1998.
18. Jacques Patarin and Louis Goubin. Trapdoor one-way permutations and multivari-
ate polynomials. In International Conference on Information Security and Cryp-
tology 1997, volume 1334 of Lecture Notes in Computer Science, pages 356368. In-
ternational Communications and Information Security Association, Springer, 1997.
Extended Version: http://citeseer.nj.nec.com/patarin97trapdoor.html.
19. Serge Vaudenay, editor. Public Key Cryptography  PKC 2005, volume 3386 of
Lecture Notes in Computer Science. Springer, 2005. ISBN 3-540-24454-9.
20. Lih-Chung Wang, Yuh-Hua Hu, Feipei Lai, Chun yen Chou, and Bo-Yin Yang.
Tractable rational map signature. In PKC [19], pages 244257. ISBN 3-540-24454-
9.
21. Xiaoyun Wang, Yiqun Lisa Yin, and Hongbo Yu. Finding collisions in the full
sha-1. In CRYPTO, volume 3621 of Lecture Notes in Computer Science, pages
1736. Victor Shoup, editor, Springer, 2005. ISBN 3-540-28114-2.
22. Christopher Wolf, An Braeken, and Bart Preneel. EÔ¨Écient cryptanalysis of
RSE(2)PKC and RSSE(2)PKC. In Conference on Security in Communication
Networks  SCN 2004, volume 3352 of Lecture Notes in Computer Science, pages
294309. Springer, September 810 2004. Extended version: http://eprint.iacr.
org/2004/237.
23. Christopher Wolf and Bart Preneel. SuperÔ¨Çuous keys in Multivariate Quadratic
asymmetric systems. In PKC [19], pages 275287. Extended version http://
eprint.iacr.org/2004/361/.
24. Bo-Yin Yang and Jiun-Ming Chen. All in the XL family: Theory and practice.
In ICISC 2004, volume 3506 of Lecture Notes in Computer Science, pages 6786.
Springer, 2004.
25. Bo-Yin Yang and Jiun-Ming Chen. Building secure tame-like multivariate public-
key cryptosystems: The new TTS. In ACISP 2005, volume 3574 of Lecture Notes
in Computer Science, pages 518531. Springer, July 2005.
26. Bo-Yin Yang, Owen Chia-Hsin Chen, Daniel J. Bernstein, and Jiun-Ming Chen.
Analysis of QUAD. In Fast Software Encryption  FSE 2007, volume 4593 of Lecture
Notes in Computer Science, pages 290307. Alex Biryukov, editor, Springer, 2007.
workshop record available.
1 Introduction
1.1 Security Amplification for Commitment Schemes
Security amplification for weak cryptographic primitives is a basic question that has been stud-
ied since the seminal work of Yao [Yao82]. This question has been extensively studied in recent
years for a variety of primitives in various settings. To name a few, amplification has been stud-
ied for encryption schemes [DNR04, HR05], commitment schemes [DKS99, Wul07, HR08], oblivious
transfer [DKS99, Wul07], message authentication codes (MACs), digital signatures, and pseudoran-
dom functions (PRFs) [DIJK09]. Some of these works consider information-theoretic security (e.g.,
[DKS99]), and others consider computational security. The various security properties of primitives
present different interactive settings, for example, commitment schemes are more interactive than
encryption schemes, and the chosen-message-attack for MACs introduces a different type of interac-
tion. Proving amplification results tend to be more challenging in an interactive and computational
setting.
In this paper, we continue the study of security amplification for commitment schemes, which was
previously studied in [DKS99, Wul07, HR08]. We focus on black-box security amplification in the
computational setting, where the security holds against probabilistic polynomial time (PPT) active
adversaries. Namely, the starting point is a (weak) bit-commitment scheme Com0 that is p-hiding in
the sense that no PPT adversarial receiver, who may deviate from the prescribed protocol arbitrarily,
can guess the committed bit correctly with probability better than (1 + p)/2, and q-binding in the
sense that no PPT adversarial sender can open in two ways with probability better than q, and the
goal is to transform Com0 to a secure commitment scheme Com that makes black-box calls to Com0
and achieves negligible security for both properties.
Previous works focus on feasibility results. Namely, for what values of p and q is the security
amplification achievable. In the information-theoretic setting (i.e., the security holds for unbounded
adversaries), DamgÀöard, Kilian and Salvail [DKS99] showed that a black-box transformation is possible
if and only if p + q ‚â§ 1 ‚àí 1/poly(s), where s is the security parameter. Halevi and Rabin [HR08]
analyzed the transformation of [DKS99] in the computational setting and proved that a black-box
transformation is possible whenever p + q ‚â§ 1 ‚àí 1/polylog(s). Recently and independent of our
work, Holenstein and Schoenebeck [HS10] improved the result to optimal. They showed that in
the computational setting, black-box security amplification is achievable if and only if p + q ‚â§
1‚àí 1/poly(s).
However, the existing transformations are not very efficient. To measure the efficiency, let us
consider the number of black-box calls to Com0 that Com makes when p and q are constants with
p+ q < 1. Note that the number of black-box calls affects not only the communication complexity,
but also the round complexity of the resulting protocol, because in the computational setting, each
black-box call needs to be done sequentially.1 All existing solutions requires œâ(log2 s) black-box calls
to securely commit a single bit. At a high level, the reason is that they amplify the hiding and
binding property separately. Amplifying each property from constant to negligible seems to require
œâ(log s) black-box calls, which is the case of the existing constructions and results in œâ(log2 s) black-
box calls in total. On the other hand, the existing constructions give bit commitment schemes, but
there are applications that require string commitment schemes. Since it requires œâ(log s) black-box
calls to amplify the security anyway, perhaps we can obtain a string commitment scheme instead of
just committing to a single bit, which also improves efficiency in terms of the rate, i.e., the number
of black-box calls per committed bit. These motivate us to ask the following question.
1In general, the commit stage of can consist of multiple rounds. If the black-box calls are done in parallel, one can
show by modifying the counter example of Bellare, Impagliazzo, and Naor [BIN97] for interactive arguments that the
security may not be amplified at all.
1
Weakly Verifiable Dynamic Weakly Verifiable Two-Phase
Direct Product [CHS05] [DIJK09], Ours [HR08]
Chernoff-type [IJK07, Jut10], Ours [DIJK09], Ours Ours
Hardness Degradation [HR08] Ours‚àó [HR08]
Full-Spectrum Ours Ours‚àó Ours
Figure 2: Summary of results on different types of puzzle systems. ‚ÄúOurs‚Äù means that either we
obtain new results or we improve bounds over previous ones. Our hardness degradation and full-
spectrum results hold only for a variant of the dynamic weakly verifiable puzzle systems (see Section
5 for details).
rate, which are useful to deduce security amplification results [CHS05, IJK07, DIJK09, Jut10]. In
general, hardness amplification results for one puzzle systems do not imply the same results for
another puzzle systems. Furthermore, for general interactive protocols, which can be viewed as
‚Äúinteractive puzzle systems,‚Äù there are counter examples (under reasonable assumptions) showing
that the hardness may not be amplified at all under parallel repetition [BIN97, PW07].
Previous Results. For weakly-verifiable puzzle systems, Canetti, Halevi, and Steiner [CHS05]
prove a tight Direct Product Theorem, saying that solving n puzzles is Œ¥n-hard2 if solving a single
puzzle is Œ¥-hard, and Impagliazzo, Jaiswal, and Kabanets [IJK07] prove a more general Chernoff-
type Theorem, saying that solving at least (1.1) ¬∑ Œ¥ ¬∑ n out of n puzzles is 2‚àí‚Ñ¶(Œ¥¬∑n)-hard if solving
a single puzzle is Œ¥-hard. The bound of [IJK07] was recently improved by Jutla [Jut10] to nearly
optimal. Dodis, Impagliazzo, Jaiswal, and Kabanets [DIJK09] extend the Chernoff-type Theorem
to dynamic weakly-verifiable puzzle systems, and use it to achieve security amplification for MACs,
digital signatures, and PRFs. However, the proof techniques of [IJK07, DIJK09, Jut10] seem not
applicable to the two-phase puzzle systems.
To analyze their transformations for security amplification for commitment schemes, Halevi and
Rabin [HR08] prove a Hardness Degradation Theorem for two-phase puzzle systems (without formally
defining the model), saying that solving at least one out of n puzzles is (1‚àí (1‚àí Œ¥)n)-hard if solving
a single puzzle is Œ¥-hard (matching the bound for independent events).
Our Results. We show that the three types of hardness results (Direct Product, Chernoff-type,
Hardness Degradation) actually hold for the three aforementioned puzzle systems (weakly-verifiable
puzzles, dynamic weakly-verifiable puzzles, and two-phase puzzles.) We establish a Full-Spectrum
Amplification Theorem, which essentially says that the hardness of solving at least r puzzles out of n
puzzles matches the bound of independent events if solving a single puzzle is Œ¥-hard for some constant
Œ¥. Note that such a bound is optimal, since a solver can always solve each puzzle independently. In
particular, our bounds improve those of Dodis et al. [DIJK09], which implies efficiency improvement
for security amplification for MACs, digital signatures, and PRFs, since the construction can take
less number of repetition. A summary of our results and previous results can be found in Figure 2.
We prove the Full-Spectrum Amplification Theorem by a single reduction algorithm that is
applicable to all three puzzle systems. The reduction algorithm can be viewed as a generalization of
the reduction algorithm of Canetti, Halevi, and Steiner [CHS05].
Historical Notes. The work of Holenstein and Schoenebeck [HS10] and our work were done in-
dependently, but have significant overlap. We briefly compare the results and make some historical
2We omit the negligible slackness in this informal discussion.
3
3 Definitions and Main Theorems
3.1 Commitment Schemes
In this section, we formally define commitment schemes and present our main theorem. We con-
sider a standard model where the communication is over the classical noiseless channel and the
decommitment is non-interactive [Gol01, HR08].
Definition 4 (Commitment Scheme) A commitment scheme is an interactive protocol Com =
(S,R) with the following properties:
1. Scheme Com consists of two stages: a commit stage and a reveal stage. In both stages, the
sender S and the receiver R receive a security parameter 1s as common input.
2. At the beginning of the commit stage, sender S receives a private input v ‚àà {0, 1}t, which
denotes the string to which S is supposed to commit. The commitment stage results in a joint
output, which we call the commitment x = output((S(v), R)(1s)), and a private output for
S, which we call the decommitment string d = outputS((S(v), R)(1
s)). Without loss of
generality, x can be taken to be the full transcript of the interaction between S and R, and d
to be the private coin tosses of S.
3. In the reveal stage, sender S sends the pair (v, d), where d is the decommitment string for
string v. Receiver R accepts or rejects based on v, d, x.
4. Both sender S and receiver R are efficient, i.e., both run in probabilistic polynomial time in
the security parameter s.
5. R will always accept with probability 1‚àíngl if both the sender S and the receiver R follow their
prescribed strategy. If R accepts with probability 1, we say Com has perfect correctness.
6. When the commit string v is just a bit in {0, 1}, we call Com a bit-commitment scheme.
Otherwise, we call Com a t-bit string-commitment scheme.
Remark 5 The assumption of non-interactive reveal stage is essential in both our work and the
previous work [HR08]. This assumption can be made without loss of generality as long as no ad-
ditional property (e.g., if the sender wants to decommit in a zero-knowledge manner) is required,
because in the reveal stage, the sender S can send his coin tosses to the receiver R, who can check
the consistency and simulate the protocol. On the other hand, the assumption of perfect correctness
can be relaxed to (1‚àí ngl)-correctness in both works.
We proceed to define the hiding and binding properties of commitment schemes. To facilitate
the presentation of our results and analysis, we are precise about the adversary‚Äôs running time in
the definition and define the binding property in terms of binding games.
Definition 6 (p-hiding against time T ) A commitment scheme Com = (S,R) is p-hiding against
uniform time T if for every probabilistic time T cheating receiver R‚àó, the distributions (viewR‚àó(S(Ut), R
‚àó), Ut)
and (viewR‚àó(S(Ut), R
‚àó), U ‚Ä≤t) are p-indistinguishable for time T , where U
‚Ä≤
t is an i.i.d. copy of Ut. That
is, for every probabilistic time T distinguisher D,
|Pr[D(viewR‚àó(S(Ut), R
‚àó), Ut) = 1]‚àí Pr[D(viewR‚àó(S(Ut), R
‚àó), U ‚Ä≤t) = 1]| ‚â§ p/2
We say Com is p-hiding if Com(1s) is p-hiding against time sc for every constant c, and sufficiently
large security parameter s.
5
Definition 12 (Two-Phase Puzzle System) A two-phase puzzle system P = (G,V ) consists
of a PPT (interactive) puzzle generator G and a deterministic polynomial time puzzle verifier V . Let
S be a solver for P. The interaction of „ÄàS,P„Äâ consists of two phases, where the first phase corresponds
to the puzzle generation phase, and the second is the puzzle solving phase. More precisely,
‚Ä¢ In the first phase, the solver and the generator jointly generate a puzzle p ‚Üê „ÄàS, G(c)„Äâ(1s),
where c is the private coins of G. The generation of p may take polynomially many rounds.
‚Ä¢ In the second phase, S sends an answer a = S(p) to P
‚Ä¢ In the end of the protocol, P verifies the answer using V and accepts iff V (c, a) = 1 (i.e., the
answer a is correct).
Note that S does not know the coins c of G, so S may not be able to verify the correctness of an
answer a.
Definition 13 (Hardness of Solving a Puzzle) A two-phase puzzle system P is Œ¥-hard against
time T if for every time T solver S, the success probability of S, denoted by succP[S], satisfies
succP[S] ‚â§ Œ¥. We say P is Œ¥-hard if P is Œ¥-hard against time s
c for all constant c.
Interested in relating the hardness of solving (at least) r out of n puzzles to the hardness of
solving a single puzzle, we proceed to define (n, r)-repetition of a two-phase puzzle system.
Definition 14 ((n, r)-Repetition of a Two-Phase Puzzle System) Let P = (G,V ) be a two-
phase puzzle system. We define the (n, r)-repetition of P to be a two-phase puzzle system Pn,r =
(Gn, V n,r) such that (1) in the first phase, Pn,r sequentially generates n puzzles with a solver, and
(2) accepts the n-fold answer received from the solver in the second phase if at least r out of n answers
are correct. More precisely, let Sn be a solver for Pn,r. The interaction of „ÄàSn,Pn,r„Äâ is defined below.
‚Ä¢ In the first phase, „ÄàSn,Pn,r„Äâ generates n puzzles (p1, . . . , pn) sequentially by running „ÄàS
n, G(ci)„Äâ(1
s)
for i = 1, 2, . . . , n, where ci‚Äôs are G‚Äôs secret coins to generate pi.
‚Ä¢ In the second phase, Sn sends a n-fold answer ~a = (a1, . . . , an)‚Üê S
n(~p) to Pn,r.
‚Ä¢ In the end of the protocol, Pn,r accepts iff at least r copies of V (ci, ai) accept.
Although in the above definition, the puzzles are generated sequentially, it captures the parallel
repetition of weakly verifiable puzzle systems considered in [CHS05]. In our model, the solver starts
to solve the puzzles after all of them are generated. Thus, when the puzzles are generated solely
by P, which is the case of the weakly-verifiable puzzle systems, parallel generation and sequential
generation are equivalent. We remark that in order to obtain hardness amplification results, we
cannot consider parallel repetition in the (interactive) puzzle generation phase. Indeed, the counter
example of Bellare, Impagliazzo, and Naor [BIN97] for interactive arguments can be adapted to our
model, showing that the hardness may not be amplified for the case of parallel puzzle generation.
As an example, we argue that the hardness of two-phase puzzle systems captures the binding
property of a commitment scheme Com0 = (S,R) as follows. The solver S plays the role of a cheating
sender S‚àó and the generator G plays the role of the honest receiver R. Then the puzzle is the view of
S‚àó generated jointly by S and G according to the commitment scheme Com0. A valid answer for the
puzzle is a pair of decommitment strings ((v, d), (v‚Ä≤, d‚Ä≤)) that are accepted by the receiver R. Thus,
Com0 being q-binding against time T corresponds to the puzzle system begin q-hard against time
7
Intuitively, this transformation improves the hiding property, since an adversarial R‚àó needs to
learn all bits b1, . . . , bn to recover b, but hurts the binding property, since an adversarial S
‚àó
only needs to cheat on any single bit bi to decommit in two ways. Indeed, Halevi and Rabin
proved that if Com0 is (p, q)-secure, then Com is (p
n, 1‚àí (1‚àí q)n)-secure.3
‚Ä¢ Repetition transformation. Let Com0 be a bit commitment scheme, and n ‚àà N be a
parameter. The transformation gives a bit commitment scheme Com = (S,R) as follows. To
commit a bit b ‚àà {0, 1} to R, S sequentially uses Com0 n times to commit to the same bit b to
R.
Intuitively, this transformation improves the binding property, since an adversarial S‚àó needs
to cheat on all copies of Com0 to decommit in two ways, but hurts the hiding property, since
an adversarial R‚àó can learn the bit b from any copy of the commitments. Indeed, Halevi and
Rabin proved that if Com0 is (p, q)-secure, then Com is (1‚àí (1‚àí p)
n, qn)-secure.
Halevi and Rabin showed that, as long as p and q satisfy p + q ‚â§ 1 ‚àí 1/polylog(s), then given
a (p, q)-secure (weak) bit commitment scheme Com0, one can apply the above two transformations
alternately to obtain a secure bit commitment scheme Com. To measure the efficiency, consider
the case where both p and q are constants with p + q < 1. Since improving either hiding or
binding property from constant to negligible requires œâ(log s) invocations to Com0, and the above
transformations improve two properties separately, the construction of Halevi and Rabin requires at
least œâ(log2 s) black-box calls to Com0.
Remark 18 Independent of our work, Holenstein and Schoenebeck [HS10] present a different con-
struction that improves the result of Halevi and Rabin in the following sense.For any (p, q)-secure
bit commitment scheme Com0 with p + q ‚â§ 1 ‚àí 1/poly(s), their construction gives a secure bit
commitment scheme Com using poly(s) black-box calls to Com0. Their construction uses Valiant‚Äôs
monotone formula for majority [Val84] to improve both properties. However, a closer inspection
shows that their construction is equivalent to applying the secret sharing transformation and a vari-
ant of repetition transformation (with the same effect on the parameters) alternately. Hence, in
terms of the efficiency, their construction also requires at least œâ(log2 s) black-box calls to amplify a
(p, q)-secure weak commitment scheme with constant p and q to a secure one.
To bypass the œâ(log2 s) barrier of the existing constructions, our main idea is to use error-
correcting codes and randomness extractors to amplify both hiding and binding properties simulta-
neously. For intuition, we give an informal description of our transformation first. Let us informally
use Com0(b) to denote a commitment of a bit b, and let C : {0, 1}
n ‚Üí {0, 1}n
‚Ä≤
be an error-correcting
code with minimum distance at least Œ¥ ¬∑n‚Ä≤, and Ext : {0, 1}n√ó{0, 1}d ‚Üí {0, 1}t a strong randomness
extractor. Our transformation uses Com0, C and Ext to commit to a string v ‚àà {0, 1}
t as follows
(recall that we obtain string commitment schemes as opposed to bit commitment schemes of other
existing constructions).
‚Ä¢ Commit Stage: the sender S samples a message m ‚ààR {0, 1}
n uniformly at random, and
sequentially commits to each bit of the codeword C(m) using Com0, which generates commit-
ments Com0(C(m))
def
= (Com0(C(m)1), . . . ,Com0(C(m)n‚Ä≤)). Then S samples a uniform seed
z ‚ààR {0, 1}
d, and sends the seed z with v‚äïExt(m, z) to the receiver R. In sum, the commitment
is Com(v) = (Com0(C(m)), z, v ‚äï Ext(m, z)).
‚Ä¢ Reveal Stage: the sender S sends the value v, the message m and reveals each committed bit
of C(m) to R, who checks consistency and accepts or rejects accordingly.
3We omit the negligible slackness in the informal discussion.
9
4.1 Efficient Security Amplification in the Known-Security Setting
In this section, we present a transformation that converts a (p, q)-secure bit commitment scheme
Com0 to a (s
‚àíc, s‚àíc)-secure O(log s)-bit string commitment scheme Com using O(log s) black-box
calls to Com0, where c is an arbitrary constant. Our transformation uses error-correcting codes
and randomness extractors to amplify both hiding and binding properties simultaneously. The
transformation requires to use a systematic code with good distance and the ‚ÄúGoldreich-Levin‚Äù
extractor. We will discuss the reason when we prove the security below. A formal description of our
transformation can be found in Figure 3.
Transformation T (Com0, n, `, t):
‚Ä¢ Inputs. A bit commitment scheme Com0, and parameters n, `, t ‚àà N.
‚Ä¢ Outputs. A t-bit string-commitment scheme Com = (S,R) defined as follows.
‚Ä¢ Commit Stage. Let v ‚àà {0, 1}t be the string to which S is committing to.
1. R samples a uniformly random matrix A‚Üê {0, 1}`√ón, and sends A to S.
/* i.e., R selects a random systematic linear code C(m)
def
= (m,Am). */
2. S samples the following uniformly at random: a message m ‚Üê {0, 1}n and a matrix
Z ‚Üê {0, 1}t√ón.
/* Z is a random seed for a (strong) randomness extractor Ext(m,Z)
def
= Zm.*/
3. S uses Com0 to commit to each bit of m and each bit of Am to R sequentially. Let
~x = (x1, . . . , xn) and ~y = (y1, . . . , y`) denote the commitment of each bit respectively.
/* i.e., S commits to each bit of the codeword C(m). */
4. S sends (Z, v ‚äï Zm) to R, where v ‚äï Zm is the bit-wise xor of v and Zm.
/* i.e., S uses Ext(m,Z) as a one-time pad to hide the commit string v. */
In sum, the commitment of v is (A, ~x, ~y, Z, v ‚äï Zm).
‚Ä¢ Reveal Stage. S sends v and its coin tosses r to R, and R checks that v and r are
consistent with the honest sender‚Äôs algorithm.
Figure 3: Our black-box transformation T (Com0, n, `, t).
We will show that if Com0 is a (p, q)-secure bit commitment scheme for small constants p, q, then
by setting n, `, t = O(log s), the resulting string commitment scheme is (s‚àíc, s‚àíc)-secure for some
constant c. Note that both parties in Com run in time polynomial in n, `, t, and the running time of
Com0, which is efficient. Formally, we prove the following theorem.
Theorem 19 The following holds for all sufficiently small constants p, q ‚àà (0, 1), and k = O(log s):
Suppose there exists a (p, q)-secure (weak) bit commitment scheme Com0, then there exists a (2
‚àík, 2‚àík)-
secure t = ‚Ñ¶(k)-bit string-commitment scheme Com that makes O(k) black-box calls to Com0. Specif-
ically, Com = T (Com0, n, `, t) for appropriate n, ` = O(k), and t = ‚Ñ¶(k).
We formalize the aforementioned intuition to analyze the hiding and binding properties in the
below subsections.
11
We instead take an alternative approach. We argue that it is very hard for R‚àó to predict the whole
messagem after he sees the n+` commitments, and hence one can apply the Goldreich-Levin theorem
to extract pseudo-random bits. This is why our transformation requires to use the Goldreich-Levin
extractor. To argue that m is hard to predict from the commitments (~x, ~y), we first argue that m
is hard to predict from ~x. Again, we can view predicting n sequentially committed message bits
of m from the commitments ~x as (n, n)-repetition of a two-phase puzzle system. By Full-Spectrum
Amplification Theorem (Theorem 15, or Direct Product Theorem of Halevi and Rabin [HR08]), the
success probability of R‚àó is at most ((1+p)/2)n (up to a negligible factor). Observing that ~y contains
at most ` bits of information about m, the success probability of R‚àó to predict m from (~x, ~y) is at
most 2` ¬∑((1+p)/2)n. Hence, by the Goldreich-Levin theorem, we can extract ‚Ñ¶(log(2` ¬∑((1+p)/2)n))
pseudorandom bits.
Formally, we prove the following lemma, which essentially says that we can extract ‚Ñ¶(log(2` ¬∑((1+
p)/2)n)) pseudorandom bits. Again, we formulate the lemma in concrete parameters for preciseness,
and we use parameter Œ± = 1 ‚àí p for clarity. For intuition, think of n, ` = Œò(k), k = O(log s),
T0 = poly(s), and T = s
œâ(1).
Lemma 21 (Hiding) There exist universal constants c2 such that the following holds. For every
Œ± ‚àà (0, 1), n, k, `, t, T0, T ‚àà N satisfying (i) 2c2 ¬∑ k/Œ± ‚â• n ‚â• c2 ¬∑ k/Œ±, (ii) `, t ‚â§ Œ±n/12, if Com0 =
(S0, R0) with runtime T0 is a (1‚àíŒ±)-hiding against time T , then Com = T (Com0, n, `, t) is 2
‚àík-hiding
against time T ‚Ä≤ = T/poly(2k, T0).
We leave the proof in Appendix B.
4.1.3 Proof of Theorem 19
Theorem 19 follows by applying Lemma 20 and 21 with properly chosen parameters.
Proof. (of Theorem 19) We set the parameters n, k, ` as follows: n = max{ c1kq ,
c2k
1‚àíp} = Œò(k),
` = d0(3q) log(3q) ¬∑ n, and t =
(1‚àíp)n
12 = ‚Ñ¶(k), where c1, c2, d0 are the constants in the Lemma 2, 20,
and 21. The theorem follows directly from Lemma 20 and 21.
4.2 Security Amplification for String Commitment Schemes
In this section, we generalize the transformations of Halevi and Rabin [HR08] to the case of string
commitment schemes, with the goal of amplifying the (s‚àíc, s‚àíc)-secure string commitment scheme
obtained from our transformation to achieve negligible security. This is a simpler task, and can
be done by applying a secret-sharing transformation first and then a repetition transformation. A
formal description of the transformations can be found in Figure 4.
We proceed to analyze the binding and hiding properties of the resulting commitment schemes of
the two transformations. For the binding property, the analysis is essentially the same as in [HR08]:
for repetition, it requires to break all u commitments of Com0, and for secret-sharing, it requires to
break only 1 out of u commitments of Com0, which correspond to solving (u, u)-repetition and (u, 1)-
repetition of two-phase puzzles. The Direct Product Theorem and Hardness Degradation Theorem of
Halevi and Rabin [HR08] (or our Full-Spectrum Amplification Theorem) imply the following lemma.
Lemma 22 ([HR08]) Let Com0 be a t-bit string-commitment scheme, u = u(s) ‚â§ poly(s) a effi-
ciently computable function, and q ‚àà (0, 1) a constant. Suppose Com0 is q-binding, then R(Com0, u)
is (qu + ngl)-binding, and SS(Com0, u) is (1‚àí (1‚àí q)
u + ngl)-binding.
On the other hand, analyzing the hiding property is tricker. For the secret-sharing transformation,
we need a string version of XOR Lemma to show that the hiding property is amplified. Maurer
13
Final Construction.
‚Ä¢ Inputs. A (p, q)-secure bit commitment scheme Com0 with p+ q < 1.
‚Ä¢ Outputs. A secure t-bit string-commitment scheme Com with t = ‚Ñ¶(log s).
1. Apply the transformations of Halevi and Rabin alternately to obtain a (p‚Ä≤, q‚Ä≤)-secure bit
commitment scheme Com1 with sufficiently small constants p
‚Ä≤, q‚Ä≤.
2. Apply our transformations T (Com1, n, `, t) to obtain a (s
‚àíc, s‚àíc)-secure t-bit string com-
mitment scheme Com2, where n, ` = O(log s), t = ‚Ñ¶(log s), and c is some constant.
3. Let a be an arbitrary œâ(1) function. Apply SS(Com2, a) to obtain a (ngl, a¬∑s
‚àíc+ngl)-secure
t-bit string commitment scheme Com3.
4. Apply R(Com3, a) to obtain a secure t-bit string commitment scheme Com.
Figure 5: Efficient security amplification of commitment schemes.
primitives, and proved Chernoff-type Theorem for the puzzle system. To illustrate their ideas, let us
take signature schemes as an example.
We briefly recall the syntax of signature schemes: a signature scheme consists of three efficient
algorithms Œ† = (Gen, Sig,Ver), where Gen(1s) generates a public key pk and a secret key sk, Sig uses
sk to sign a given message m (denoted by œÉ ‚Üê Sigsk(m)), and Ver verifies the validity of a message-
signature pair (m,œÉ) using pk (denoted by Verpk(m,œÉ)). Dodis et al. considers the following security
of signature schemes: S is Œ¥-secure if for any efficient adversary A who gets oracle access to Sig can
only succeed in forging a valid signature for a ‚Äúfresh‚Äù message m (i.e., A does not query m to the
Sig oracle) with probability at most Œ¥.
The above security of a signature scheme can be viewed as a puzzle system P as follows. The
puzzle is (pk, sk) generated by Gen, where pk is public but sk is kept secret. The valid answers to
this puzzle are valid message-signature pairs (m,œÉ)‚Äôs, where m is from some message space M . In
addition to the puzzle pk, a solver S is allowed to query a ‚Äúhint oracle‚Äù Sig, who provides valid answers
(m,œÉ)‚Äôs for the messages m‚Äôs that S queries, and S succeeds if S outputs a valid answer (m‚àó, œÉ‚àó)
for a fresh message m‚àó. Dodis et al. formalize the above puzzle system as dynamic weakly-verifiable
puzzle systems.6 Observe that Œ† is Œ¥-secure iff the corresponding puzzle system is Œ¥-hard.
A natural way to amplify the security of a weak signature scheme Œ† is by repetition. Namely, we
consider a new scheme Œ†n,r that consists of n independent keys (pk1, . . . , pkn; sk1, . . . , skn) of Œ† for
some parameters n, r. A signature of a message m consists of the concatenation of all n individual
signatures (œÉ1, . . . , œÉn) = (Sigsk1(m), . . . , Sigskn(m)) of Œ†, and the verification accepts if at least r
out of the n signatures œÉi‚Äôs of Œ† are valid.
7 This can be viewed as a ‚Äú(n, r)-repetition‚Äù Pn,r of the
corresponding puzzle system P: The puzzle is (pk1, . . . , pkn; sk1, . . . , skn), and the valid answers to
this puzzle are tuples (m,œÉ1, . . . , œÉn)‚Äôs with m ‚ààM and at least r our of n valid answers (m,œÉi). A
solver Sn can query m ‚ààM to the hint oracle, who replies (m,œÉ1, . . . , œÉn). S
n succeeds if Sn outputs
a valid answer (m‚àó, œÉ‚àó1, . . . , œÉ
‚àó
n) for a fresh message m
‚àó.
Dodis et al. proved a Chernoff-type Theorem for dynamic weakly-verifiable puzzle systems, which
6In general, the model of Dodis et al. consists of a verification oracle that S can query to verify the validity of an
answer (m,œÉ). We skip this detail in the above informal discussion.
7The motivation for considering the threshold verification in [DIJK09] is to deal with the case where Œ† has imperfect
correctness.
15
References
[BIN97] Mihir Bellare, Russell Impagliazzo, and Moni Naor. Does parallel repetition lower the
error in computationally sound protocols? In FOCS, pages 374‚Äì383, 1997.
[CHS05] Ran Canetti, Shai Halevi, and Michael Steiner. Hardness amplification of weakly verifiable
puzzles. In TCC, pages 17‚Äì33, 2005.
[DIJK09] Yevgeniy Dodis, Russell Impagliazzo, Ragesh Jaiswal, and Valentine Kabanets. Security
amplification for interactivecryptographic primitives. In TCC, pages 128‚Äì145, 2009.
[DKS99] Ivan DamgÀöard, Joe Kilian, and Louis Salvail. On the (im)possibility of basing oblivious
transfer and bit commitment on weakened security assumptions. In EUROCRYPT, pages
56‚Äì73, 1999.
[DNR04] Cynthia Dwork, Moni Naor, and Omer Reingold. Immunizing encryption schemes from
decryption errors. In EUROCRYPT, pages 342‚Äì360, 2004.
[GL89] Oded Goldreich and Leonid A. Levin. A hard-core predicate for all one-way functions. In
STOC, pages 25‚Äì32, 1989.
[Gol01] Oded Goldreich. Foundations of Cryptography. Basic tools. Cambridge University Press,
2001.
[HR05] Thomas Holenstein and Renato Renner. One-way secret-key agreement and applications
to circuit polarization and immunization of public-key encryption. In CRYPTO, pages
478‚Äì493, 2005.
[HR08] Shai Halevi and Tal Rabin. Degradation and amplification of computational hardness. In
TCC, pages 626‚Äì643, 2008.
[HS10] Thomas Holenstein and Grant Schoenebeck. General hardness amplification of predicates
and puzzles. CoRR, abs/1002.3534, 2010.
[IJK07] Russell Impagliazzo, Ragesh Jaiswal, and Valentine Kabanets. Chernoff-type direct prod-
uct theorems. In CRYPTO, pages 500‚Äì516, 2007.
[Imp95] Russell Impagliazzo. Hard-core distributions for somewhat hard problems. In FOCS, pages
538‚Äì545, 1995.
[Jut10] Charanjit S. Jutla. Almost optimal bounds for direct product threshold theorem. In
Daniele Micciancio, editor, TCC, volume 5978 of Lecture Notes in Computer Science,
pages 37‚Äì51. Springer, 2010.
[MT09] Ueli Maurer and Stefano Tessaro. Computational indistinguishability amplification: Tight
product theorems for system composition. In Shai Halevi, editor, Advances in Cryptology
‚Äî CRYPTO 2009, volume 5677 of Lecture Notes in Computer Science, pages 350‚Äì368.
Springer-Verlag, August 2009.
[PW07] Krzysztof Pietrzak and Douglas Wikstro¬®m. Parallel repetition of computationally sound
protocols revisited. In TCC, pages 86‚Äì102, 2007.
[Val84] Leslie G. Valiant. Short monotone formulae for the majority function. J. Algorithms,
5(3):363‚Äì366, 1984.
17
For simplicity, we assume an ideal case where there is no estimation or sampling error in the whole
process of S. In the real case when there are errors, we can still carry through the analysis in a more
involved way using sampling techniques and Chernoff bound. Here we first sketch the high level idea
for the the Direct Product Theorem [CHS05]. The solver S firstly uses the transformation iteratively
to find a good prefix. Let E i(k) be the event that S
n solves exactly k puzzles over {pi, pi+1, . . . , pn},
and Pr[E i(k)] is the probability that this event happens with the randomness over the rest of the
puzzles {pi, pi+1, . . . , pn}. Starting from prefix i = 1, ~p = ‚àÖ, S iteratively extends ~p by the condition:
if there exists a puzzle pi such that Pr[E i+1(n ‚àí i)] ‚â• Œ¥
n‚àíi, then ~p = ~p ‚ó¶ {pi}, i = i + 1 and it
repeats the transformation process. We observe that when the algorithm recurs, we have obtained a
smaller solver Sn‚àíi that has success probability Œ¥n‚àíi over pi+1, . . . , pn. On the other hand, when the
condition does not hold, we claim ~p is the good prefix such that the bad correlation explained above
does not happen. With this prefix, the solver S embeds the puzzle from the P, then he samples a
suffix conditioning on the event E i+1(n ‚àí i ‚àí 1), which means conditioning on S
n solves all of the
puzzles in the suffix, the algorithm outputs Sn‚Äôs answer to the real puzzle.
For the case where r = 1 considered by Halevi and Rabin [HR08], they used the same framework
with a modified strategy of S. More precisely, starting from prefix i = 1, ~p = ‚àÖ, S iteratively extends
~p by the condition: if there exists a puzzle pi such that Pr[E i+1(n ‚àí i)] ‚â• 1 ‚àí (1 ‚àí Œ¥)
n‚àíi, then
~p = ~p ‚ó¶ {pi}, i = i + 1 and it repeats. On the other hand, when the condition does not hold, the
solver S embeds the puzzle from the P, and then samples a suffix conditioning on the event E i+1(0).
This means conditioning on Sn solves none of the puzzles in the suffix, the algorithm outputs Sn‚Äôs
answer to the real puzzle.
In this work, we find the correct transformation and the corresponding conditional event that
the algorithm believes the answer to be correct. We slightly modify the previous recursion that
in the generalized case, it occurs with either of the following two facts holds: for n ‚àà N, r ‚àà [n],
starting from the empty prefix ~p = ‚àÖ, i = 1, the algorithm checks if there exists a pi such that (1)
Pr[E i(‚àó, k)|~p, pi] ‚â• P (n ‚àí i, r, Œ¥), or (2) Pr[E i(‚àó, k ‚àí 1)|~p, pi] ‚â• P (n ‚àí i, r ‚àí 1, Œ¥), then the algorithm
repeats with ~p = ~p ‚ó¶ pi, i = i+ 1 (to the case that the condition holds). If both conditions fail, then
it claims ~p is the good prefix, and it believes the answer from Sn if it solves exactly r ‚àí 1 puzzles in
the remaining puzzles, i.e. conditioning on the event E i(‚àó, r ‚àí 1).
In the following, we are going to argue the above scheme succeeds with probability more than Œ¥
given the Sn has success probability more than P (n, r, Œ¥).
A.2 Formal Proofs
Here we first give a formal definition of the events and the main theorem as follows:
Definition 28 Let n, r, i, t ‚àà N, b ‚àà {0, 1, ‚àó}, P be a two-phase puzzle system and Pn,r the corre-
sponding (n, r)-repetition two-phase puzzle system. Let Sn be the solver to Pn,r. Given an n-fold
puzzle (p1, p2, . . . , pn) from P
n,r, define the following events:
1. E i(‚â• t): S
n solves at least t puzzles over {pi, pi+1, . . . , pn}.
2. E i(t): S
n solves exactly t puzzles over {pi, pi+1, . . . , pn}
3. E i(b,‚â• t): S
n solves at least t puzzles over {pi+1, pi+2, . . . , pn}; and it solves pi if b = 1; it does
not if b = 0; else b = ‚àó, E i(‚àó,‚â• t) = E i(1,‚â• t) ‚à™ E i(0,‚â• t).
4. E i(b, t): S
n solves exactly t puzzles over {pi+1, pi+2, . . . , pn}; and it solves pi if b = 1; it does
not if b = 0; else b = ‚àó, E i(‚àó, t) = E i(1, t) ‚à™ E i(0, t).
19
In particular, for all TÀú (~p ‚ó¶ pi,j ; E i(‚àó,‚â• r)), we have
Pr
[‚à£‚à£‚à£TÀú (~p ‚ó¶ pi,j‚àó ; E i(‚àó,‚â• r))‚àí T (~p ‚ó¶ pi,j‚àó ; E i(‚àó,‚â• r))
‚à£‚à£‚à£ < P (n‚àí i, r, Œ¥)
Œ∑2
]
> 1‚àí
Œ¥
8Œ∑nM
,
and for all TÀú (~p ‚ó¶ pi,j ; E i(‚àó,‚â• r ‚àí 1)), we have
Pr
[‚à£‚à£‚à£TÀú (~p ‚ó¶ pi,j‚àó ; E i(‚àó,‚â• r ‚àí 1))‚àí T (~p ‚ó¶ pi,j‚àó ; E i(‚àó,‚â• r ‚àí 1))
‚à£‚à£‚à£ < P (n‚àí i, r ‚àí 1, Œ¥)
Œ∑2
]
> 1‚àí
Œ¥
8Œ∑nM
.
Proof of claim: This is by Chernoff Bound since we take Mi = 6Œ∑
2
i log(8Œ∑nM/Œ¥) inde-
pendent samples. And by union bound, we know with probability at least 1 ‚àí Œ¥4Œ∑nM ,
the estimations of both E i(‚àó,‚â• r) and E i(‚àó,‚â• r ‚àí 1) will be accurate within error
P (n‚àíi,r,Œ¥)
Œ∑2
, P (n‚àíi,r‚àí1,Œ¥)
Œ∑2
respectively. 2
We can bound the total number of estimations in the algorithm by Mn since for each i ‚àà [n] the
algorithm takes M independent estimations. Thus, by union bound and the claim above, we have
with probability 1‚àí Œ¥4Œ∑ , all the estimations at loop i have precision
P (n‚àíi,r,Œ¥)
Œ∑2
. We define this event
as Good 1 , and we have Pr[Good 1 ] > 1‚àí Œ¥4Œ∑ .
Claim 32 Let i ‚àà [n], ~p = (p1, p2, . . . , pi‚àí1) be the prefix found in the algorithm in the round i, and
E i(‚àó,‚â• r), E i(‚àó,‚â• r ‚àí 1) be the events that it is going to estimate. Define B(i, ~p, E i(‚àó,‚â• r)) = {pi :
T (~p ‚ó¶ pi; E i(‚àó,‚â• r)) ‚â• (1 + 1/Œ∑
2) ¬∑ P (n ‚àí i, r, Œ¥)}, and C(i, ~p, E i(‚àó,‚â• r ‚àí 1)) = {pi : T (~p ‚ó¶ pi; E i(‚àó,‚â•
r ‚àí 1)) ‚â• (1 + 1/Œ∑2) ¬∑ P (n‚àí i, r ‚àí 1, Œ¥)}.
Then for a given i, conditioning on the event Good 1 , with probability 1‚àí Œ¥4Œ∑n over the randomness
of the algorithm, we have the following facts. (1) Suppose for all j ‚àà [M ], the estimations TÀú (~p ‚ó¶
pi,j ; E i(‚àó,‚â• r)) ‚â§ P (n‚àí i, r, Œ¥), then we have Prpi [pi ‚àà B(i, ~p, E i(‚àó,‚â• r))] <
Œ¥
2Œ∑ . (2) Also suppose for
all j ‚àà [M ], the estimations TÀú (~p ‚ó¶ pi,j ; E i(‚àó,‚â• r ‚àí 1)) ‚â§ P (n ‚àí i, r ‚àí 1, Œ¥), then we have Prpi [pi ‚àà
C(i, ~p, E i(‚àó,‚â• r‚àí1))] <
Œ¥
2Œ∑ . For a given i such that these two facts hold, we call this event Good 2 (i).
Proof of claim: By symmetry, we only need to prove with probability 1‚àí Œ¥8Œ∑n the fact
(1) holds, and the same reasoning goes through for the fact (2). Then by union bound,
we know that with probability 1‚àí Œ¥4Œ∑n , both (1) and (2) hold.
To show fact (1), it is equivalent to prove that conditioning on the event Good 1 ,
with probability 1‚àí Œ¥8Œ∑n over the randomness of the algorithm, suppose we have Prpi [pi ‚àà
B(i, ~p, E i(‚àó,‚â• r))] ‚â•
Œ¥
2Œ∑ , then we have at least one j such that TÀú (i, ~p ‚ó¶ pi,j ; E i(‚àó,‚â• r)) ‚â•
P (n‚àí i, r, Œ¥).
Since we condition on the event Good 1 , which means all the estimations are within
precision errors at most P (n‚àíi,r,Œ¥)
Œ∑2
, then given a pi ‚àà B(i, ~p, E i(‚àó,‚â• r)), the algorithm
will correctly identify this. Thus suppose Prpi [pi ‚àà B(i, ~p, E i(‚àó,‚â• r))] ‚â•
Œ¥
2Œ∑ , then taking
M = 2Œ∑Œ¥ log(8Œ∑n/Œ¥) samples without hitting any set element is at most (1‚àí
Œ¥
2Œ∑ )
M = Œ¥8Œ∑n .
Thus hitting at least one element has probability at least 1‚àí Œ¥8Œ∑n , as desired.
2
Let the event Good 2 to be: for all i event Good 2 (i) holds. From the claim above and
by union bound, we have Pr[Good 2 |Good 1 ] > 1 ‚àí Œ¥4Œ∑ . Also by the previous claim we have
Pr[Good 1&Good 2 ] = Pr[Good 2 |Good 1 ] ¬∑ Pr[Good 1 ] > (1‚àí Œ¥4Œ∑ )
2 > 1‚àí Œ¥2Œ∑ .
Then we are going to calculate the success probability that the algorithm outputs conditioning
on the both events Good 1 and Good 2 .
21
Theorem 34 (Full-Spectrum Amplification Theorem (Theorem 15 restated)) For any con-
stants Œ≥, Œ¥, Œ± ‚àà (0, 1) and efficiently computable functions n, r ‚àà N ‚Üí N with 1 ‚â§ r(s) ‚â§ n(s) ‚â§
poly(s), the following holds. Let P = (G, V )(1s) be a two-phase puzzle system. Suppose P is Œ¥-hard,
then:
1. The (n, r)-repetition Pn,r is (P (n, r, (1 + Œ±) ¬∑ Œ¥) + ngl)-hard
2. If r ‚â• (1 + Œ≥)Œ¥n (i.e., the Chernoff-type regime), then Pn,r is (P (n, r, Œ¥) + ngl)-hard,
where P (n, r, Œ¥) = Pr[
‚àën
i=1Xi ‚â• r], with Xi‚Äôs being i.i.d. Bernoulli random variables and E[Xi] = Œ¥.
Proof. We first prove the second case where r ‚â• (1 + Œ≥)Œ¥n (the Chernoff-type regime), and then
the first case for general r.
Given Œ≥, Œ¥, and we want to prove the contrapositive argument. Suppose Pn,r is not P (n, r, Œ¥)-
hard, i.e. there exists a solver Sn with success probability greater equal than P (n, r, Œ¥) +  for some
noticeable function , then we want to construct a single puzzle solver S with success probability
greater equal than Œ¥, which means that P is not Œ¥-hard.
Suppose n = O(log s), then Lemma 16 already gives us a reduction algorithm that runs in
poly(n, r, Œ¥‚àír, (1‚àíŒ¥)‚àí(n‚àír)) = poly(s) since Œ¥, (1‚àíŒ¥) are constants and cn = poly(s) for any constant
c. Thus we are done.
For larger n = œâ(log s), we take the following strategy. Let C = 12
(Œ≥2/4)(1+Œ≥/3)Œ¥
be a constant,
n‚Ä≤ = C log(n ) = O(log s) since n/ = poly(s), and t = n/n
‚Ä≤, r‚Ä≤ = r/t. First we observe that from
Sn we can construct a solver SÀú
n‚Ä≤
to the system Pn
‚Ä≤,r‚Ä≤ with success probability P (n,r,Œ¥)+t . This can
be done by a simple average argument where SÀú
n‚Ä≤
first randomly samples i‚Üê [t‚àí 1], then samples a
prefix (i ¬∑ n‚Ä≤ puzzles) by simulating the (in‚Ä≤, ir‚Ä≤)-repetition of puzzle system Pin
‚Ä≤,ir‚Ä≤ , then embeds the
n‚Ä≤ puzzles from Pn
‚Ä≤,r‚Ä≤ , and finally samples the suffix for the solver Sn.
Let Œ¥‚Ä≤ be the parameter such that P (n‚Ä≤, r‚Ä≤, Œ¥‚Ä≤) = P (n,r,Œ¥)+t holds. Given SÀú
n‚Ä≤
, by Lemma 16,
we can construct a solver S that solves a single puzzle with success probability greater equal than
Œ¥‚Ä≤(1 ‚àí 1/Œ∑), running time in poly(n‚Ä≤, r‚Ä≤, Œ¥‚àír
‚Ä≤
, (1 ‚àí Œ¥)‚àí(n
‚Ä≤‚àír‚Ä≤)) = poly(s). Our goal is to show that
Œ¥‚Ä≤ ‚â• (1 + Œ≥/3)Œ¥. Then we choose Œ∑ = Œ≥/4 in the Lemma 16, and thus the success probability of S
will be Œ¥‚Ä≤(1‚àí 1/Œ∑) ‚â• (1‚àí Œ≥/4)(1 + Œ≥/3)Œ¥ ‚â• Œ¥, which completes the proof.
Let œÅ = (1 + Œ≥/3)Œ¥, and then we will have r‚Ä≤ ‚â• (1 + Œ≥)Œ¥n‚Ä≤ ‚â• (1 + Œ≥/2)œÅn‚Ä≤. Then by standard
Chernoff bound we have P (n‚Ä≤, r‚Ä≤, œÅ) ‚â§ e‚àí(Œ≥/2)
2œÅn‚Ä≤/3 = /n < P (n,r,Œ¥)+t = P (n
‚Ä≤, r‚Ä≤, Œ¥‚Ä≤). Since we know
that P (n‚Ä≤, r‚Ä≤, ¬∑) is an increasing function for fixed n‚Ä≤, r‚Ä≤, and thus we have Œ¥‚Ä≤ ‚â• œÅ = (1 + Œ≥/3)Œ¥ as
desired.
For general (n, r)-repetition, first we claim that without lost of generalization, we assume 1 ‚àí
P (n, r, (1 + Œ±) ¬∑ Œ¥) > e‚àíŒ±
2(1+Œ±)Œ¥n/18. Otherwise, solver Sn being not P (n, r, (1 + Œ±) ¬∑ Œ¥) + ngl hard
means Sn has success probability P (n, r, (1 + Œ±) ¬∑ Œ¥) +  for some noticeable . However this means
P (n, r, (1 + Œ±) ¬∑ Œ¥) +  > 1, and thus no solver Sn will meet this condition, which trivializes the
statement.
Starting from the assumption that 1 ‚àí P (n, r, (1 + Œ±) ¬∑ Œ¥) > e‚àíŒ±
2(1+Œ±)Œ¥n/18, we claim that r ‚â•
(1 +Œ±/2) ¬∑ Œ¥n. Otherwise, r < (1 +Œ±/2) ¬∑ Œ¥n implies (1‚àíŒ±/3) ¬∑ (1 +Œ±)Œ¥n > (1 +Œ±/2) ¬∑ Œ¥n > r. Thus
by standard Chernoff bound, we have 1‚àí P (n, r, (1 + Œ±) ¬∑ Œ¥) < e‚àí(Œ±/3)
2(1+Œ±)Œ¥n/2 = e‚àíŒ±
2(1+Œ±)Œ¥n/18, a
contradiction.
Then we use the similar argument as above. We consider the case where n = œâ(log s), and let
C = 108
Œ±2(1+Œ±/4)Œ¥
, n‚Ä≤ = C log(n ), t = n/n
‚Ä≤, r‚Ä≤ = r/t. Then we can construct a solver SÀú
n‚Ä≤
with success
probability P (n‚Ä≤, r‚Ä≤, Œ¥‚Ä≤)
def
= P (n,r,(1+Œ±)¬∑Œ¥)+t for some noticeable . By lemma 16, we can construct a
23
B.2 Proof of Lemma 21
Proof. We prove the contrapositive statement. Suppose Com is not 2‚àík-hiding against time T ‚Ä≤,
then there exists a time T ‚Ä≤ cheating receiver R‚àó, and a time T ‚Ä≤ distinguisher D such that
|Pr[D(viewR‚àó(S(Ut), R
‚àó)(1k), Ut) = 1]‚àí Pr[D(viewR‚àó(S(Ut), R
‚àó)(1k), U ‚Ä≤t) = 1]| > 2
‚àík
Let us understand the view of R‚àó better. In the commit stage, R‚àó tosses some coins r, sends some
0-1 matrix A to S, and reaches some configuration œÉ. We can assume without loss of generality that
œÉ contains r and A. Next, the honest sender S plays the role of S0 in Com0, and commits to n
random bits m ‚Üê {0, 1}n, and ` parity bits Am. Again, let C : {0, 1}n ‚Üí {0, 1}n+` be the linear
code defined by C(m) = (m,Am). In each interaction i = 1, . . . , n+ `, R‚àó plays a cheating receiver
R‚àó0,i, and gets a view xi
def
= viewR‚àó
0,i
(S0(C(m)i), R
‚àó
0,i). Let ~x = (x1, . . . , xn+`). Finally, R
‚àó receives a
random matrix Z, and s‚äï Zm, where s is the string that S commits to. In sum, the view of R‚àó in
(S(s), R‚àó)(1k) can be described by (œÉ, ~x, Z, s‚äï Zm). Thus, we have,
|Pr[D((œÉ, ~x, Z, Ut ‚äï Zm), Ut) = 1]‚àí Pr[D((œÉ, ~x, Z, Ut ‚äï Zm), U
‚Ä≤
t) = 1]| > 2
‚àík
This implies the existence of time T ‚Ä≤ +O(t) distinguisher D‚Ä≤ such that9
|Pr[D‚Ä≤((œÉ, ~x, Z, Zm) = 1]‚àí Pr[D‚Ä≤((œÉ, ~x, Z, Ut) = 1]| > 2
‚àík
Let Z = (z1, . . . , zt), where each zi is a row of Z. We can write Zm as (z1 ¬∑m, . . . , zt ¬∑m). By the
equivalence of pseudorandomness and next-bit unpredictability, there is a time T ‚Ä≤ + O(t) next-bit-
predictor P such that
Pr[P (œÉ, ~x, Z, z1 ¬∑m, . . . , zi‚àí1 ¬∑m) = zi ¬∑m] > 1/2 + 2
‚àík/t
where the probability is also taken on a random choice of i ‚àà [t].
For convenience, let Z‚àíi = (z1, . . . , zi‚àí1, zi+1, . . . , zt), and write (œÉ, ~x, Z, z1 ¬∑ m, . . . , zi‚àí1 ¬∑ m) as
(œÉ, ~x, Z‚àíi, z1 ¬∑m, . . . , zi‚àí1 ¬∑m, zi) (i.e., move zi to the last coordinate). By a Markov argument, with
probability at least 2‚àík/2t over random (i, œÉ, ~x, Z‚àíi, z1 ¬∑m, . . . , zi‚àí1 ¬∑m),
Pr
zi
[P (œÉ, ~x, Z‚àíi, z1 ¬∑m, . . . , zi‚àí1 ¬∑m, zi) = zi ¬∑m] > 1/2 + 2
‚àík/2t
We can view P (œÉ, ~x, Z‚àíi, z1 ¬∑ m, . . . , zi‚àí1 ¬∑ m, ¬∑) as a corrupted Hadamard encoding of m. By the
Goldreich-Levin Themrem (Lemma 3), if Przi [P (œÉ, ~x, Z‚àíi, z1 ¬∑m, . . . , zi‚àí1 ¬∑m, zi) = zi ¬∑m] > 1/2 +
2‚àík/2t, we can make O(n ¬∑ 22k) queries to P (œÉ, ~x, Z‚àíi, z1 ¬∑m, . . . , zi‚àí1 ¬∑m, ¬∑) and guess m correctly
with probability ‚Ñ¶((2‚àík/t)2). Therefore, there exists a time (T ‚Ä≤+O(t)) ¬∑O(n ¬∑ 22k) algorithm B such
that
Pr[B(œÉ, ~x, Z‚àíi, z1 ¬∑m, . . . , zi‚àí1 ¬∑m) = m] ‚â• (2
‚àík/2t) ¬∑ ‚Ñ¶((2‚àík/t)2) = ‚Ñ¶((2‚àík/t)3)
Now, suppose we only get input œÉ and x1, . . . , xn, we claim that we can still guess m correctly
with probability at least 2‚àí(`+t‚àí1) ¬∑ ‚Ñ¶(2‚àí3k/t3). The idea is try to generate the rest of the input
(xn+1, . . . , xn+`, Z‚àíi, z1 ¬∑m, . . . , zi‚àí1 ¬∑m) with correct distribution, and feed it to B. Observe that
xn+1, . . . , xn+` are generated by the interaction of a honest S, who plays the role of S0 to commit
each bit of (Am), and a cheating receiver R‚àó, who has the view (œÉ, x1, . . . , xn) and plays a cheating
sender R‚àó0,i. Since we have the view (œÉ, x1, . . . , xn) of R
‚àó, if we can guess (Am) correctly, then we
9On input (œÉ, ~x, Z, a), D‚Ä≤ simply samples a fresh copy of uniform bits U ‚Ä≤t , and feeds ((œÉ, ~x, Z, U
‚Ä≤
t ‚äï a), U
‚Ä≤
t) to D.
If a is drawn from Zm, then D gets distribution ((œÉ, ~x, Z, U ‚Ä≤t ‚äï Zm), U
‚Ä≤
t), and if a is drawn from Ut, then D gets
((œÉ, ~x, Z, U ‚Ä≤t ‚äï Ut), U
‚Ä≤
t) = ((œÉ, ~x, Z, Ut ‚äï Zm), U
‚Ä≤
t).
25
Claim 35 (Com0(Ut), . . . ,Com0(Ut), Ut) ‚âàc (Com0(U
1
t ), . . . ,Com0(U
u
t ), Ut).
Proof of claim: (sketch) Observe that (Com0(Ut), Ut) ‚âàc (Com0(Ut), U
‚Ä≤
t) is equivalent
to (Com0(Ut), Ut) ‚âàc (Com0(U
‚Ä≤
t), Ut). We claim that this implies
(Com0(Ut), . . . ,Com0(Ut), Ut) ‚âàc (Com0(U
1
t ),Com0(Ut), . . . ,Com0(Ut), Ut).
Intuitively, this is because that given either (Com0(Ut), Ut) or (Com0(U
1
t ), Ut), one can ef-
ficiently generate the rest u‚àí1 copies of Com0(Ut)‚Äôs, so a distinguisher for (Com0(Ut), . . . ,Com0(Ut), Ut)
v.s. (Com0(U
1
t ),Com0(Ut), . . . ,Com0(Ut), Ut) can be used to distinguish (Com0(Ut), Ut)
and (Com0(U
1
t ), Ut). To be a bit more formal, suppose there is an advesarial R
‚àó such that
the corresponding (Com0(Ut), . . . ,Com0(Ut), Ut) and (Com0(U
1
t ),Com0(Ut), . . . ,Com0(Ut), Ut)
are distinguishable, then by letting R‚àó0 simulate the first coordinate of R
‚àó, we have R‚àó0
generates distinguishable (Com0(Ut), Ut) and (Com0(U
1
t ), Ut), a contradiction. Iteratively
applying this argument, we have
(Com(Ut), . . . ,Com(Ut), Ut) ‚âàc (Com(U
1
t ), . . . ,Com(U
u
t ), Ut).
2
Now, observe that the previous claim implies
(Com(Ut), . . . ,Com(Ut)) ‚âàc (Com(U
1
t ), . . . ,Com(U
u
t )),
which implies
(Com0(Ut), . . . ,Com0(Ut), U
‚Ä≤
t) ‚âàc (Com0(U
1
t ), . . . ,Com0(U
u
t ), U
‚Ä≤
t).
Hence, we have
(Com0(Ut), . . . ,Com0(Ut), Ut) ‚âàc (Com0(U
1
t ), . . . ,Com0(U
u
t ), Ut) ‚âàc (Com0(Ut), . . . ,Com0(Ut), U
‚Ä≤
t),
as desired.
B.4 Sketch Proof of Lemma 25
Proof. (sketch) We claim that our reduction for two-phase puzzle systems can be implemented
in the dynamic weakly-verifiable puzzle systems, and thus exactly the same analysis in the proof of
Theorem 15 proves this lemma.
Recall that our proof of Theorem 15 consists of two reductions. The first one is the core reduction
(Definition 30) that is used to prove Lemma 16, and the second one reduces the number of repetition
n (i.e., converts a solver Sn to another solver Sn
‚Ä≤
with smaller n‚Ä≤) which is implicit in the proof of
Theorem 15. We inspect both reduction algorithms and argue that it can be implemented in the
dynamic weakly-verifiable puzzle systems as follows.
‚Ä¢ At a high level, in the core reduction (Definition 30), the solver S interacts with P by simulating
the interaction of Sn and Pn,r with the real P embedded in some i-th coordinate of Pn,r =
(P1, . . . ,Pn) as follows: (1) S generates i ‚àí 1 puzzles p1, . . . , pi‚àí1, (2) S embeds p = pi to the
i-th coordinate, (3) S randomly samples pi+1, . . . , pn, and simulates S
n to generates answers
a1, . . . , an, and (4) S decides whether to output ai as his answer for p. In other words, S
simulates Sn and P1, . . . ,Pi‚àí1,Pi+1, . . .Pn by himself, and let P simulate Pi. The hint oracle of
Pn,r can be simulated by simulating the hint oracle of P1, . . . ,Pi‚àí1,Pi+1, . . .Pn, and querying
the hint oracle of P to obtain the response of the i-th coordinate. Furthermore, since Sn is
canonical, whenever Sn succeeds on the i-th coordinate and S decides to output ai, S succeeds as
well. Thus, the reduction can be implemented in the dynamic weakly-verifiable puzzle system.
27
Âá∫ÂúãÂ∑ÆÊóÖÂ†±ÂëäÊõ∏
2009/8/17-2009/8/20 ÂèÉÂä†ÁæéÂØÜÂ§ßÊúÉ (Crypto) 
2009/8/24-2009/8/26 ÂèÉÂä†Ê©¢ÂúìÊõ≤Á∑öÂØÜÁ¢ºÁ≥ªÁµ±Á†îË®éÊúÉ
Â†±Âëä‰∫∫ÔºöÊ•äÊüèÂõ†
‰∏≠Â§ÆÁ†îÁ©∂Èô¢Ë≥áË®äÁßëÂ≠∏ÊâÄ ÂâØÁ†îÁ©∂Âì°
Ê∞ëÂúã 98 Âπ¥ 9 Êúà 2 Êó•
Âá∫Â∑ÆÊúüÈñìÔºö98 Âπ¥ 8 Êúà 16 Êó•Ëá≥ÂêåÂπ¥ 8 Êúà 28 Êó•
‰∫ãÁî±Ôºö ÂèÉÂä†ÁæéÂØÜÂ§ßÊúÉÊñº UC Santa Barbara (Crypto, 8/16-20)Ôºå
ÂèÉÂä†Ê©¢ÂúìÊõ≤Á∑öÂØÜÁ¢ºÁ≥ªÁµ±Á†îË®éÊúÉÊñº U of Calgary (ECC, 8/24-8/26)
Âá∫Â∑ÆÊôÇÈñìË°®  : 
8/16 Êó©‰∏äÁî±Âè∞ÁÅ£Ê°ÉÂúíÊ©üÂ†¥Êê≠‰πòÊó•Ëà™ (JL)ÔºåÁ∂ìÂ§ßÈò™ËΩâÊê≠ËÅØÂêàËà™Á©∫ (UA) Áè≠Ê¨°
ÊñºÊó©‰∏äÊôÇÈ£õÊäµÁæéÂúãËàäÈáëÂ±± (San Francisco)„ÄÇÂÜçËΩâÊ©üËá≥ Santa 
Barbara ÊäµÈÅî UCSB (Âä†Â∑ûÂ§ßÂ≠∏ Santa Barbara  ÂàÜÊ†°)„ÄÇ
8/17-20 ÂèÉÂä†ÁæéÂØÜ (Crypto 2009) Êñº UCSB 
8/21-23 Êê≠Ê©üËá≥Êù±Â≤∏ÂÄã‰∫∫Ë°åÁ®ãÔºå‰∏¶Êñº 8/23 ‰∏ãÂçàÊê≠Ê©üÁ∂ìËäùÂä†Âì•Ëá≥Âä†ÊãøÂ§ß‰∫û‰ºØÊâò 
(Alberta) È¶ñÂ∫úÂç°Áàæ‰Ω≥Èáå (Calgary) ËΩâËªäÊäµÂç°Áàæ‰Ω≥ÈáåÂ§ßÂ≠∏„ÄÇ
8/24-26 ÂèÉÂä†Ê©¢ÂúìÊõ≤Á∑öÂØÜÁ¢ºÁ≥ªÁµ±Á†îË®éÊúÉ (ECC 2009) Êñº U of Calgary 
8/27 Êê≠Ê©üÂõûÂè∞, ÊñºÊ¨°Êó•ÊäµÈÅî
1„ÄÅ ÂèÉÂä†ÁæéÂúãÂä†Â∑ûÂ§ßÂ≠∏ËÅñÂ°îËä≠Ëä≠ÊãâÂàÜÊ†° (UC Santa Barbara) ÁöÑCrypto 2009
Â∞çË®àÁÆóËÉΩÂäõÂèóÈôêÁöÑÊîªÊìäËÄÖ (Mironov-Pandey-Reingold-Vadhan ÁöÑË´ñÊñá)„ÄÇ
ÈÄ±‰∫å(28) Êó©Â†¥ÁöÑ‰∏ªÈ°åÊòØÂ∞çÁ®±ÂºèÂØÜÁ¢ºÁöÑÁ†¥ÂØÜÔºåÊàëÂêàÁêÜÂú∞Áõ∏‰ø°ÈÄô‰∏ÄÁØÄÊòØÂÖ®Â§ßÊúÉÊúÄÂèóÁüöÁõÆÁöÑ‰∏ÄÁØÄ„ÄÇ
Á¨¨‰∏ÄÂ†¥Â±±Êù±Â§ßÂ≠∏ÁéãÂ∞èÈõ≤ÂúòÈöäÁöÑÊñ∞Á†îÁ©∂ÔºåÊåáÂá∫Êüê‰∫õÁî® AES ÁöÑÁØÄÂáΩÊï∏ÂÅö‰∏≠ÂøÉÊ≠•È©üÁöÑ MAC 
(message authentication code, Ë®äÊÅØÈ©óË≠âÁ¢º) ÊòØÊúâÁº∫Èô∑ÁöÑÔºå‰∏çÈÅé‰ªñÂÄë‰∏¶Ê≤íÊèêÂá∫ 280 ‰ª•‰∏ã
Ë§áÈõúÂ∫¶ÁöÑÊîªÊìä„ÄÇÁ¨¨‰∫åÂ†¥ÊòØÊú¨Ê¨°ÊúÄÈáçË¶ÅÁöÑË´ñÊñá‰πã‰∏ÄÔºöÁõßÊ£ÆÂ†°ÁöÑ Biryukov Á≠â‰∫∫ÊèêÂá∫‰∫Ü 2154 Ë§á
ÈõúÂ∫¶ (2-119 ÁöÑÊ©üÁéáÊàêÁ´ãÁöÑÁõ∏ÈóúÈáëÈë∞ÂàÜËæ®ÂáΩÊï∏ÔºåÊúâ 2-35 ÁöÑÊàêÂäüÊ©üÁéá) Â∞çÂÆåÊï¥ AES-256 ÁöÑÊîª
Êìä„ÄÇÊúÄÂæåÔºå‰∏πÈ∫•ÁßëÂ§ßÁöÑ Julia Borghoff Á≠â‰∫∫ÊèêÂá∫Â∞ç C2 (Cryptomeria) ÁöÑÂÆåÊï¥Á†¥Ëß£ÔºåC2 
ÊòØÂ∞ç DVDÈåÑÈü≥Á¢üÁâáÂíå SD Âç°ÈÄ≤Ë°åÊï∏‰ΩçÂÖßÂÆπÊ¨äÈôêÊéßÁÆ° (DRM) ‰ΩøÁî®ÁöÑÂçÄÂ°äÂØÜÁ¢ºÁ≥ªÁµ±ÔºåÁî± IBM, 
Intel, Êùæ‰∏ãÂíåÊù±ËäùÊèêÂá∫Ôºå‰ΩøÁî® 64‰ΩçÂÖÉÁöÑÂçÄÂ°äÂíå 56 ‰ΩçÂÖÉÁöÑÈáëÈë∞ÔºåËÄåÂÖ∂ÈóúÈçµ‰∏≠ÂøÉÈÉ®‰ªΩÊúâÂÄãÁßò
ÂØÜÁöÑ‰ª£ÊèõÂáΩÊï∏ (S-Box)„ÄÇBorghoff Á≠âËß£ÈáãÂ¶Ç‰ΩïÂú® 255 Ê¨°Âä†ÂØÜ‰∏≠Á†¥Ëß£Êï¥ÂÄã C2 ‰∏¶ÂÜçÂ∫¶Ë≠âÊòé
‰∫ÜÂØÑÊúõÊñº‰øùÊåÅÁßòÂØÜ‰æÜ‰øùË≠∑Ë≥áÊñôÊòØÁÑ°ÊïàÁöÑ„ÄÇ
Êé•‰∏ã‰æÜÁöÑ‰∏ÄÂ†¥ÊòØÊ©¢ÂúìÊõ≤Á∑ö„ÄÇÁõßÊ£ÆÂ†°ÁöÑ Thomas Icart Ë∑üÂ§ßÂÆ∂Ë¨õËß£Â¶Ç‰ΩïÊää hash function ÊúÄ
Â•ΩÁöÑÂ∞çÊáâÂà∞Ê©¢ÂúìÊõ≤Á∑ö‰∏ä„ÄÇÁÑ∂ÂæåÊàëÁöÑËÄÅÂèã Dan Bernstein Ë¨õÂπ≥Ë°åÁöÑ ECC Êìç‰ΩúÁöÑÊúÄÊñ∞ÁôºÊòé: 
Âú® GF(2k) ‰∏äÁöÑ Edwards curve„ÄÇ‰∏ãÂçàË∑ü‰ª•Ââç‰∏çÂêåÁöÑÊúâÂè¶Â§ñ‰∫åÂ†¥ÊºîË¨õÔºå‰∏ªÈ°åÊòØ hardness, 
ÁÑ∂ÂæåÊòØ‰ºëÊÅØÂíåÁ§æ‰∫§ÊôÇÈñì„ÄÇ
Á¨¨‰∫åÊó•ÊôöÈñìÊòØËá™Áî±ÁôºË°®ÊúÉ (Rump Session)„ÄÇEran Tromer ÊèêÂá∫‰∫ÜÂ∑≤Ë¢´Êé•ÂèóÂà∞ ACM-
CCS (computer & communications security symposium) 2009 ÁöÑÁµêÊûúÔºå‰ªñÊåáÂá∫Èõ≤Á´ØË®à
ÁÆó‰∏≠‰πüÂ≠òÂú®ÔºåÂçÄÂçÄÂπæÂçÉÂ°äÈå¢ÁæéÈáëÁöÑ‰ª£ÂÉπÁôºÁèæ‰∫Ü Amazon ÁöÑ EC2 Èõ≤Á´ØÂπ≥Âè∞ÁöÑË≥áÊ∫êÈÖçÁΩÆË¶è
ÂâáÔºå‰∏¶ÊàêÂäüÁöÑ‰ΩøÁî® cache timing attack Âæû‰∏çÂêåÁöÑËôõÊì¨Ê©üÂô®ÊîªÊìä„ÄÇ
Âú®ÈÄôË£°‰∏ÄÂÆöË¶ÅÊèêÂèäÔºåÂú®Êú¨Ê¨°ÁöÑ Rump Session ‰∏ä AES ÂèóÂà∞‰∫ÜÂáåÂé≤ÁöÑÁ†≤ÁÅ´ÊîªÊìäÔºåÁâπÂà•ÊòØ
Áî± Orr Dunkelman Á≠â‰∫∫ÊèêÂá∫ÁöÑÊñ∞ÊîªÊìäÔºåÂèØ‰ª•Á†¥Ëß£ 10-round ÁöÑ AES-256„ÄÇÈÄôËÆìÂú®Â†¥ÁöÑ 
NIST [ÁæéÂúãÂúãÂÆ∂Ê®ôÊ∫ñÂ±Ä] ÁöÑ‰∫∫Âì°Ë¢´Â§ßÂÆ∂ÂèñÁ¨ë‰∫ÜÂæà‰πÖ„ÄÇ
Rump Session ÁöÑ‰∏ÄÂÄãÊèíÊõ≤ÊòØ Vielhaber ÂèàÈÅ†ÂæûÊô∫Âà©Ë∑ë‰æÜÂ†±Âëä‰∫Ü‰ªñÊúÄËøëÁöÑÊàêÊûúÔºå‰∏¶‰∏îÁõ¥Êé•
ÊåáÊéß Dinur-Shamir ÊäÑË•≤„ÄÇ‰∏çÈÅéÊúâÈëëÊñºÊ≠êÂØÜÂ§ßÊúÉ‰∏ä„ÄÇShamir Â∑≤Á∂ìÊàêÂäüÊêûÂÆö‰∫ÜÈÄôÂ†¥È¢®Ê≥¢Ôºå
Áï∂ÊôÇÂæπÂ∫ïË¢´ÊìäÊïóÁöÑ Vielhaber Ê≤íÊúâÂºïËµ∑Â§ßÂÆ∂Â§™Â§ßÁöÑËààË∂£„ÄÇÂà∞Êôö‰∏ä 11 Èªû, Rump Session 
Âú®Êñ∞Èä≥Â≠∏ËÄÖ, MIT ÁöÑ Eran Tromer‰ΩúË©û, Bernstein ÁöÑÂ≠∏ÁîüÂÄëÁöÑÂêâ‰ªñÂΩàÂî±‰∏ãÂäÉ‰∏ãÂè•Èªû„ÄÇ
Á¨¨‰∏âÂ§©ÂèàÊòØ‰∏ÄÂÄãÊï¥Â§©ÔºåÊó©Â†¥ÁöÑË™≤È°åÊòØÊØîËºÉÂ∞ëË¶ãÁöÑÂØÜÁ¢ºÂ≠∏: Merkle Èõ£È°å, ÊàëÁâπÂà•ÊúâËààË∂£ÁöÑ: 
‰ª•‰ΩçÁΩÆÁÇ∫ÁßòÂØÜÁöÑÂØÜÁ¢ºÂ≠∏ÔºåÂíåÈáèÂ≠êÂØÜÁ¢ºÈÄöË®äÂçîÂÆöÁöÑÊîπÈÄ≤„ÄÇ‰ºëÊÅØ‰πãÂæåÊòØÁ†¥ÂØÜÁöÑË™≤È°å: ISO-
9796-2 Ê®ôÊ∫ñÁî± Medhi Tibouchi Â†±Âëä, Âíå Random Oracle Model ÁöÑÂº±ÈªûÁî± Gaetan 
Leurent Â†±Âëä„ÄÇÁÑ∂ÂæåÊòØÁ¨¨ 2 Â†¥Â§ßÊúÉÊºîË¨õ: Ueli Maurer ‰∏ªË¨õ„ÄéÂØÜÁ¢ºÂ≠∏‰∏≠ÁöÑÊäΩË±°Âåñ„Äè„ÄÇÈÄôÂÄãÂ∞ç
ÊàëÂØ¶Âú®Â§™ÊäΩË±°ÁöÑÊù±Ë•ø„ÄÇÊàëÂ∞±ÂØ¶Âú®ËÅΩËÄÖÈÇàÈÇà‰∫Ü„ÄÇÂçàÈ§êÂæåÁöÑ‰∏ªÈ°åÊòØ Multi-party, ÈÄô‰πüÊòØ‰∏çÈÅ©Âêà
ÁöÑÁ†îÁ©∂ÊàêÊûú„ÄÇÈ•íÊïôÊéàÁÇ∫ÁæéÂúãÂìà‰ΩõÂ§ßÂ≠∏Ê†°ÂèãÔºå ‰ªñÊºîË¨õÊàëÂÄë‰∏äÂâçË´áË©±ÔºåÁôºÁèæ‰ªñÊõæË∑üÊàëÂÄëÊúâÂæà
Â§öÂÖ±ÂêåÁ∂ìÈ©óÔºåÂÖ∂ÂæåÈ•íÊïôÊéà‰∏¶ÊáâÂÖÅÂπ¥Â∫ïË®™Âè∞ÔºåËàáÂúãÂÖßÂ≠∏ËÄÖÂ∞àÂÆ∂ÂàáÁ£ã‰∫§ÊµÅÔºåÁ≠ÜËÄÖÂ∞çÊ≠§ÊÑüÂà∞‰∏çËôõ
Ê≠§Ë°å„ÄÇ‰∏ãÂçàÁ¨¨‰∏ÄÂ†¥ÊºîË¨õÂâáÊòØÁî±ÈõôÂ∫ïÊï∏Á≥ª (double-base number systems) ÁöÑÂ∞àÂÆ∂„ÄÅÂç°ÁàæÂä†Âà©Â§ß
Â≠∏ÁöÑËø™Á±≥Â§öÂ§´ÊïôÊéà (Professor Vassil Dimitrov) ÊâÄË¨õËø∞„ÄÅÈóúÊñºÈõôÂ∫ïÊï∏Á≥ªÁ†îÁ©∂ÊúÄÊñ∞ÁöÑÁôºÂ±ï„ÄÇÊé•
ËëóÂú®‰∏ãÂçàËå∂‰ºëÊÅØÂæåÔºåÂâáÊòØÁî±ÈÑ≠ÊåØÁâüÊïôÊéà‰ª£Ë°®Á≠ÜËÄÖËàá‰ªñ„ÄÅÁæéÂúã‰ºäÂà©Ë´æÂ§ßÂ≠∏ËäùÂä†Âì•ÂàÜÊ†°ÁöÑÊú¨ÊñØ
Ê±ÄÊïôÊéà (Professor Daniel J. Bernstein, University of Illinois at Chicago, USA)„ÄÅ‰ª•ÂèäËç∑Ëò≠ËâæÂõ†
Â§öÂàÜÁßëÊäÄÂ§ßÂ≠∏ÁöÑËò≠Ê†ºÊïôÊéà (Professor Tanja Lange, Technische Universiteit Eindhoven, The 
Netherlands) ÊâÄÁµÑÊàêÁöÑÁ†îÁ©∂ÂúòÈöäÔºåÂêëËàáÊúÉËÄÖÂ†±ÂëäÊàëÂÄëÂú®È°ØÁ§∫Âç°‰∏äÈÄ≤Ë°åÈ´òÈÄüÊ©¢ÂúìÊõ≤Á∑öË≥™Âõ†Êï∏
ÂàÜËß£Ë®àÁï´ÁöÑÁ†îÁ©∂ËøëÊ≥Å„ÄÇÈö®ÂæåÁî±Â∑¥Ë•øÂùéÂù∑Á¥çÊñØÂ∑ûÁ´ãÂ§ßÂ≠∏ (State University of Campinas, Brazil) 
ÁöÑÁæÖÂüπÁéÜÊïôÊéà (Professor Julio Lopez) ÊºîË¨õÂ¶Ç‰ΩïÂú®Ë®àÁÆóË≥áÊ∫êÊúâÈôêÁöÑÊÑüÊáâÂô®Á∂≤Ë∑ØÁØÄÈªû‰∏äÂØ¶‰ΩúÊ©¢
ÂúìÊõ≤Á∑öÂØÜÁ¢ºÁ≥ªÁµ±ÔºåÂÄºÂæóÂúãÂÖßÂª£Â§ßÁöÑÊÑüÊáâÂô®Á∂≤Ë∑ØÁ†îÁ©∂Á§æÁæ§ÂÄüÈè°„ÄÇÊôö‰∏äÂâáÊòØÂ§ßÊúÉÊ≠°ËøéÈÖíÊúÉÂèäËá™
Áî±ÁôºË°®ÊúÉ (rump session)ÔºåÂÖ∂‰∏≠Á≠ÜËÄÖÁôºË°®‰∫ÜÁ∞°Áü≠ÊºîË™™ÔºåÂêëËàáÊúÉËÄÖÂ†±Âëä‰∫ÜÊú¨Á†îÁ©∂ÂúòÈöäËøëÊúüÂú®
x86ËôïÁêÜÂô®‰∏äÈÄ≤Ë°åÈ´òÈÄüÊ©¢ÂúìÊõ≤Á∑öË≥™Âõ†Êï∏ÂàÜËß£Ë®àÁï´ÁöÑÁ†îÁ©∂ËøëÊ≥ÅÔºåÁç≤Âæó‰∫ÜÂæàÂ•ΩÁöÑËø¥Èüø„ÄÇ
Êó©‰∏ä 9:00ÈñãÂßãÔºåÁî±Á≠ÜËÄÖÈï∑ÊúüÁöÑÂêà‰Ωú‰ºô‰º¥„ÄÅÊú¨ÊñØÊ±ÄÊïôÊéàÈóúÊñºÂæåÈáèÂ≠êÂØÜÁ¢ºÂ≠∏ÁöÑÁ≤æÂΩ©ÊºîË¨õÂ±ïÈñãÁ¨¨
‰∫åÂ§©ÁöÑË≠∞Á®ã„ÄÇÂèóÂà∞ÈáèÂ≠êÈõªËÖ¶Â∞çÂÇ≥Áµ±ÂØÜÁ¢ºÁ≥ªÁµ±ÁöÑÂ®ÅËÑÖÔºåËøëÂπ¥‰æÜÂæåÈáèÂ≠êÂØÜÁ¢ºÂ≠∏ÈÄêÊº∏ÂèóÂà∞ÂØÜÁ¢ºÂ≠∏
ÁïåÁöÑÈáçË¶ñÔºåÂÄºÂæóÂúãÂÖßÂØÜÁ¢ºÂèäË≥áË®äÂÆâÂÖ®Á†îÁ©∂Á§æÁæ§ÈÄ≤‰∏ÄÊ≠•ÊäïË≥á„ÄÇÁ¨¨‰∫åÂ§©ÁöÑÊºîË¨õÂåÖÊã¨ÈºéÈºéÂ§ßÂêç„ÄÅ
‰æÜËá™ÁæéÂúãÂä†Â∑ûÂ§ßÂ≠∏ËÅñÂú∞ÁâôÂì•ÂàÜÊ†° (University of California at San Diego, USA) ÁöÑ Professor 
Daniel Micciancio„ÄÅÊ≥ïÂúãÊ≥¢ÁàæÂ§öÁ¨¨‰∏ÄÂ§ßÂ≠∏ (Universite Bordeaux I, France) ÁöÑ Dr. Guilhem 
Castagnos„ÄÅÊ≥ïÂúãÂ∑¥ÈªéÁ∂úÂêàÁêÜÂ∑•Â§ßÂ≠∏ (Ecole Polytechnique, France) ÁöÑ Luca De Feo„ÄÅËç∑Ëò≠Êï∏Â≠∏
ËàáË®àÁÆóÊ©üÁßëÂ≠∏‰∏≠ÂøÉ (Centrum Wiskunde & Informatica, the Netherlands) ÁöÑ Dr. Eike Kiltz„ÄÅ‰ª•
ÂèäÈ´òÈΩ°‰πùÂçÅ‰∫îÊ≠≤ÁöÑÊï∏Ë´ñÂ≠∏ÂÆ∂„ÄÅÂç°ÁàæÂä†Âà©Â§ßÂ≠∏ÁöÑÁêÜÊü•ÔºéËìãÊïôÊéà (Professor Richard K. Guy) ÁöÑ
Á≤æÂΩ©ÊºîË¨õ„ÄÇMicciancio ÊïôÊéàÊòØ lattice-based cryptography ÊñπÈù¢ÂÖ®ÁêÉÊï∏‰∏ÄÊï∏‰∫åÁöÑÂ∞àÂÆ∂Ôºå‰ªñÁöÑÊºî
Ë¨õÊ∑±ÂÖ•Ê∑∫Âá∫Ôºå‰ª§Á≠ÜËÄÖÁç≤ÁõäËâØÂ§ö„ÄÇÈõñÁÑ∂Êó©Â∑≤ËøëÁôæÔºåËìãÊïôÊéà‰æùÁÑ∂Á•ûÈááÂ•ïÂ•ïÔºå‰ªñÁöÑÊºîË¨õÂçöÂæó‰∫ÜÂÖ®
È´îËÅΩÁúæÁöÑÁÜ±ÁÉàÈºìÊéå„ÄÇÊôö‰∏äÂâáÊòØÂ§ßÊúÉÊôöÂÆ¥„ÄÇ
8/26 Êó©‰∏ä 9:00Âà∞‰∏ãÂçà 12:20 ÊòØÊúÄÂæå‰∏ÄÂ§©ÁöÑË≠∞Á®ãÔºåÊºîË¨õËÄÖÂåÖÊã¨‰æÜËá™ÁæéÂúãÈ∫ªÁúÅÁêÜÂ∑•Â≠∏Èô¢ (Mas-
sachusetts Institute of Technology, USA), Á≠ÜËÄÖÁöÑËÄÅÂêåÂ≠∏ËòáÁâπËò≠ÂçöÂ£´ (Dr. Andrew Sutherland)„ÄÅ
Êó•Êú¨Êù±‰∫¨Â∑•Ê•≠Â§ßÂ≠∏ (Tokyo Institute of Technology) ÁöÑ‰ΩêËó§Â≠ùÂíåÊïôÊéà (Professor Takakazu 
Satoh)„ÄÅ‰ª•ÂèäÂç°ÁàæÂä†Âà©Â§ßÂ≠∏ÁöÑÂÇëÂÖãÂ∏ÉÊ£Æ‰∫å‰∏ñÊïôÊéà (Professor Michael J. Jacobson, Jr.)„ÄÇÂÖ∂‰∏≠‰Ωê
Ëó§ÊïôÊéàÊìçËëó‰∏çÁîöÊµÅÂà©ÁöÑËã±ÊñáÔºå‰ªãÁ¥πËëó‰ªñÂú® hyperelliptic curves ÊñπÈù¢ÁöÑÊúÄÊñ∞Á†îÁ©∂ÊàêÊûúÔºåË¥èÂæó
‰∫ÜÊªøÂ†¥ÂñùÈááÔºåË≠âÊòé‰∫ÜËã±Êñá‰∏çÂ•Ω‰∏¶‰∏çÊßãÊàêÂ≠∏Ë°ì‰∫§ÊµÅÁöÑÈöúÁ§ôÔºåÂÄºÂæóÂúãÂÖßÁ†îÁ©∂Á§æÁæ§Ê∑±ÊÄùËàáÊïàÂ∞§„ÄÇ
8/27 Êó©‰∏äÊàëÂÄëÊê≠Ê©üÁ∂ìËàäÈáëÂ±±ËàáÊù±‰∫¨ÊñºÊ¨°Êó•ËøîÊäµÂè∞ÁÅ£„ÄÇ
ÂúãÁßëÊúÉË£úÂä©Ë®àÁï´Ë°çÁîüÁ†îÁôºÊàêÊûúÊé®Âª£Ë≥áÊñôË°®
Êó•Êúü:2010/11/01
ÂúãÁßëÊúÉË£úÂä©Ë®àÁï´
Ë®àÁï´ÂêçÁ®±: ÊáâÁî®ÁöÑÁµÑÂêà„ÄÅ‰ª£Êï∏ËàáÂØÜÁ¢ºÂ≠∏
Ë®àÁï´‰∏ªÊåÅ‰∫∫: Ê•äÊüèÂõ†
Ë®àÁï´Á∑®Ëôü: 96-2221-E-001-031-MY3 Â≠∏ÈñÄÈ†òÂüü: Ë≥áË®äÂÆâÂÖ®
ÁÑ°Á†îÁôºÊàêÊûúÊé®Âª£Ë≥áÊñô
ÂÖ∂‰ªñÊàêÊûú 
(ÁÑ°Ê≥ï‰ª•Ô•æÂåñË°®ÈÅî‰πãÊàê
ÊûúÂ¶ÇËæ¶Ôß§Â≠∏Ë°ìÊ¥ªÂãï„ÄÅÁç≤
ÂæóÁçéÈ†Ö„ÄÅÈáçË¶ÅÂúãÈöõÂêà
‰Ωú„ÄÅÁ†îÁ©∂ÊàêÊûúÂúãÈöõÂΩ±Èüø
Ô¶äÂèäÂÖ∂‰ªñÂçîÂä©Áî¢Ê•≠ÊäÄ
Ë°ìÁôºÂ±ï‰πãÂÖ∑È´îÊïàÔ®ó‰∫ã
È†ÖÁ≠âÔºåË´ã‰ª•ÊñáÂ≠óÊïòËø∞Â°´
Ô¶ú„ÄÇ) 
ÁçéÈ†Ö: ‰∏≠Á†îÈô¢ÂâçÁûªË®àÂäÉ (Academia Sinica Career Development Award) 
 
Á†îÁ©∂ÊàêÊûúÂúãÈöõÂΩ±ÈüøÔ¶ä/Ëæ¶Ôß§Â≠∏Ë°ìÊ¥ªÂãïÔºö 
Áç≤ÈÇÄË´ãÁÇ∫ PQCrypto Á≥ªÔ¶úÁ†îË®éÊúÉÊåáÂ∞éÂßîÂì°ÊúÉ (Steering Committee) ÊàêÂì°, 
PQCrypto 2011 Â§ßÊúÉ‰∏ªÂ∏≠, 
Springer ÂæåÔ•æÂ≠êÂØÜÁ¢ºÂ≠∏Â∞àÊõ∏ÈÇÄË´ã‰∏ªÊåÅ‰∫∫ÁÇ∫Á´†‰ΩúËÄÖ 
 
ÈáçË¶ÅÂúãÈöõÂêà‰Ωú 
ËàáÂæ∑Âúã Darmstadt ÁßëÂ§ß Buchmann Èô¢Â£´, Ëç∑Ô§ü Eindhoven ÁßëÂ§ß Tanja Lange 
ÊïôÊéà, EU FP7 Project ECRYPT II Associate Member 
 ÊàêÊûúÈ†ÖÁõÆ Ô•æÂåñ ÂêçÁ®±ÊàñÂÖßÂÆπÊÄßË≥™Á∞°Ëø∞ 
Ê∏¨È©óÂ∑•ÂÖ∑(Âê´Ë≥™ÊÄßËàáÔ•æÊÄß) 0  
Ë™≤Á®ã/Ê®°ÁµÑ 0  
ÈõªËÖ¶ÂèäÁ∂≤Ô§∑Á≥ªÁµ±ÊàñÂ∑•ÂÖ∑ 0  
ÊïôÊùê 0  
ËàâËæ¶‰πãÊ¥ªÂãï/Á´∂Ë≥Ω 0  
Á†îË®éÊúÉ/Â∑•‰ΩúÂùä 0  
ÈõªÂ≠êÂ†±„ÄÅÁ∂≤Á´ô 0  
Áßë 
Êïô 
Ëôï 
Ë®à 
Áï´ 
Âä† 
Â°´ 
È†Ö 
ÁõÆ Ë®àÁï´ÊàêÊûúÊé®Âª£‰πãÔ•´ËàáÔºàÈñ±ËÅΩÔºâ‰∫∫Ô•© 0  
