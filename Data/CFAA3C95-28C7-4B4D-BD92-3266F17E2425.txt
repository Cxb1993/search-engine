 I
目錄 
目錄...................................................................................................................................................I 
中文摘要......................................................................................................................................... II 
英文摘要........................................................................................................................................ III 
I. 簡介.......................................................................................................................................... 1 
II. 方法.......................................................................................................................................... 3 
III. 實驗.................................................................................................................................... 13 
IV. 結論.................................................................................................................................... 27 
參考資料........................................................................................................................................ 28 
計畫成果自評................................................................................................................................ 30 
可供推廣之研發成果資料表........................................................................................................ 31 
 
 III
英文摘要 
People with hearing/speech impairment from some inborn or acquired courses will suffer 
from the difficulties on learning and daily communication. Therefore they will loose the interests 
in learning due to the incapability and become a heavy burden on their families and government. 
For lack of assistive applications in hearing/speech impairment communication, this project 
proposes to develop a Chinese to sign language translation and an image-based sign video 
synthesis system for sign language learning. This project also proposes to establish a sign 
language translation and learning web site for the hearing-impaired. 
In the first year, following the on-going project we focus on (1) TSL video tagging for 
building the component database of the TSL videos, (2) Building a parse tree based Chinese/TSL 
translation system, and (3) design of digital sign language teaching materials. 
In the second year, we will focus on (1) Integrating translation model and video composition 
techniques to form a TSL learning system, (2) Building the interface for TSL teaching/learning, 
and (3) evaluation on the whole system. 
The expected outcome of this project is to develop a domestic assistive technology, which 
can be used for educational training and evaluation for the hearing impaired and the able-bodies. 
 
Keyword: Hearing impairment, assistive technology, Taiwanese Sign Language, sign language 
translation, computer-aided instruction 
 2
 
圖 2 direct translation 
 
 
圖 3 interlingual translation 
 
 
圖 4 transfer translation 
 
統計式做法必須收集大量雙語語料(Bilingual Corpus)，Brown 等學者(1988,1990,1993)
最早提出之嚴謹翻譯架構，其中依據詞彙、片語、語句等對應模型(Alignment Model)所考
量的情況不同，而分成數種衍生模型(IBM model-1,2,3,4,5)，用以估測其翻譯對應機率
(Alignment Probability)；Och 學者(1999, 2000, 2002)採用片語樣版以及詞彙類別在句法結構
中作對翻機制，以詞彙類別層次上的對應提供文脈資訊(Context Information)來提升對譯的
準確度；Herman Ney(2000)限制可能的相對位置來降低詞序排列計算量，以動態規劃演算
法(Dynamic Programming)去尋找在限制範圍內的最佳對應位置；張俊盛教授(2002)考量每
一字的翻譯目標位置與其他字的翻譯位置有高度的相關性，進一步修正 IBM model 3，以整
體的對應一併考慮找出片語的對應關係；Verbmobil 系統亦提出類似之片語及語句翻譯模
型。架構上仍以 IBM 及 Verbmobil 提出的翻譯模型為主，方法上乃因應詞、片語及語句等
不同層次的處理，修正或各自提出其對應模型中的失真估測及距離量度方法。 
 4
將整合實驗室既有之 CKIP 詞庫(約 80000 詞)，標記有詞與中研院簡明詞性、HowNet 詞庫(約
30000詞)，標記有詞，簡單詞性及語意屬性以及從TreeBank語料庫中粹取出的詞庫(約 34000
詞)，標記有詞，詞性與詞意角色，本計畫以詞與詞性為主並加入其它相關資訊整合為一個
包涵了詞性、詞義等相關資訊的詞庫，並利用這個詞庫來完成斷詞程式，並依照該詞庫完
成之後生成中文剖析樹的剖析器。 
本計畫分析 CKIP、HowNet 及 treebank 這三種不同結構的詞庫語料，並定義資料結構
來整合不同詞庫，以 TreeBank 語料的詞庫為主，先後加入 CKIP 詞庫與 HowNet 詞庫的詞，
以詞性分類的詳細程度決定整合順序，另加入 TreeBank 的語意角色還有 HowNet 所定義的
特徵，以利日後應用 semantic 為翻譯資訊，完成整合詞庫以完成斷詞程式及其它應用，詞
庫相關資料結構定義如下： 
詞性(POS)：以各詞庫定義 
TreeBank：依據中研院 TreeBank 語料庫中的詞性定義，從 TreeBank 語料庫中擷取出
來，此詞性為詳細分類。 
CKIP：依據中研院詞性定義，運用 CKIP AutoTag 系統剖析詞彙及語句的詞性語句法結
構，屬簡化詞性。 
HowNet：包括主要特徵及次要特徵，建立其語意屬性之間的關連性，屬精簡詞性。 
詞義角色：依據中研院 TreeBank 語料庫中的詞義角色定義 
本計畫以 TreeBank 詞庫為主，先加入 CKIP 詞庫，將 CKIP 詞庫中的詞與 TreeBank 詞庫比
對，如果 TreeBank 詞庫中不存在，便將該詞加入 TreeBank 詞庫之中，再來以同樣的方法
比對 HowNet 詞庫，如果該詞存在於 TreeBank-CKIP 詞庫之中，便將該詞之語意屬性加入
該詞的語意屬性欄位，如果不存在，便將 HowNet 詞庫中，該詞資訊：詞、詞性及語意屬
性加入 TreeBank-CKIP 詞庫中，如此來完成詞庫的整合，整合之欄位如圖 6 所示： 
 
圖 6 整合詞庫之欄位示意 
B. 建立中文／手語平行語料庫 
對照語料收集/標記 
本階段無完整之中文/手語之對照語料庫，因此彙整了本實驗室歷年收集的國小課文語
料 (教育部頒訂之啟聰學校教材，約八千句)、對話語料(取自長期觀察聽語障學童日常生活
用語並考量課程教材彙整出約一千句的對話語料)、手語故事書、網路文章等文字語料，委
請中正大學語言所手語專家及研究生、台南啟聰學校老師、中華民國聾人協會及成功大學
手語社同學協助標記所收集之中文語料，來對應文法式以及台灣自然手語，標記內容有：
文法式手語詞序，自然式手語詞序及情緒特徵…等，以便日後研究之用，圖 7 所示為標記
完成之對照語料，另外中正大學語言所蔡老師持續標記並建立手語文法資料庫。 
 6
 
圖 10 斷詞/詞性決定示意圖 
 
建立剖析樹剖析器 
圖 11 為剖析樹的示意圖，說明來源語言之語句之剖析樹如何經由剖析器處理，來輸出標語
言的語句剖析樹，由於本計畫為建立中文/手語的翻譯機制，因此 TreeBank 語料便擔任了建
立中文之句法剖析樹的責任，TreeBank 語料特性如下圖所示，除了本計畫之前提到的詞性
及語義角色外，尚包含了句法之樹狀結構，如圖 11 所示，可從此樹狀結構得到該語料之
Context Free Grammar(CFG)，並統計其在 TreeBank 語料中出現機率，可得到 Probabilitic 
Context Free Grammar(PCFG)。 
 
 
圖 11 TreeBank 示意圖 
 
 
圖 12 剖析器程式介面 
 
此部份完成一個中文剖析器如圖 12，主要將輸入之中文句斷詞後產生的詞性序列輸入
後配合 TreeBank 語料中訓練出的 CFG rule 及其機率，建立該中文句之剖析結果，經由不同
的 CFG rule 組合，其剖析結果亦會有歧異，因此利用 PCFG 來計算剖析樹生成的得分，來
找出最適當的中文剖析樹。 
當輸入一句中文句 S，經由斷詞程式可得到一 word sequence： },....,{ 121 NN WWWW − ,而各斷詞 W 再
分別對應到一個 POS 集合： 
 8
成手語剖析樹的建立並記錄如圖 13，可得到與該中文剖析樹對應之手語句剖析樹，並從中
訓練中文/手語的對應之轉換資訊與機率，如圖 13，兩棵剖析樹經由比對之後，我們可發
現其中有一條 rule 改變：NP→D+N=>NP→N+D，因此記錄下這條 rule 的變化以及它的機
率，用於未來的翻譯系統之中。 
 
圖 13 中文/手語剖析樹轉移對應資訊 
 
第二年工作分為兩大部份，手語翻譯技術之發展以及，手語影帶之串接與合成技術，分別
說明如下： 
E. 建立手語翻譯機制 
本階段完成一以文句結構為基礎之統計式句法剖析轉譯機制，其主要概念是以句法結
構來剖析中文句，建構出中文句之詞組結構剖析樹，然後由詞組結構規則依據句法結構作
規則轉換動作，轉移成手語句之詞組結構規則，再依據結構轉移後之詞組結構規則建構出
手語句之詞組結構剖析樹，然後針對手語句詞組結構剖析樹作解構動作，即可得到翻譯後
之手語句。以圖 14 為例，針對中文句「一朵花」建構出中文句詞組結構剖析樹 Tc，Tc 是
由詞組結構規則集合 CR 所組成，針對 CR 裡之每一詞組結構規則，考量其他詞組結構規則
之句法結構關係，作規則轉移動作，當所有規則轉移完畢，便可得到手語句詞組結構規則
集合 SR，再根據 SR 建構出手語句詞組結構剖析樹 Ts，最後作解構之動作，取其樹葉節點
(Leaf Node)便可得到手語句「花 一」。整個轉譯機制透過詞組結構規則考量結構之關係作
轉移動作，如 CR 其中之三組詞組結構規則因轉移產生變動，便能使詞組結構剖析樹產生
結構改變的效果，進而產生文句結構的變化，換句話說，即使由來源語言之文句結構轉移
至符合目標語言之文句結構，來達到詞句刪除及詞序變換之目的，完成手語翻譯之工作。
主要概念是以單一詞組結構剖析樹作轉譯架構之說明，目的在於方便闡述轉譯機制利用文
句結構概念之精神，而實際上在翻譯過程裡，是多個詞組結構剖析樹在同時進行，如同前
一節所述，每一文句可能有多個詞組結構剖析樹來表達其文句結構。因此，整個轉譯架構
之概觀圖如圖 15 所示。 
 10
( ) ( )
( ) ( ) ( ) ( )
( ) ( ) ( )
( ) ( ) ( ) ( )
( ) ( ) ( )
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ arg max |
arg max | | |
arg max | | ,
arg max | | |
arg max | , |
S
C C S S
S
C C S S
S
C C S S S
S
C C S S
S
S P C S P S
P C T P T T P T S P S
P C T P T T P T S
P C T P T T P S T P T
P C T P T T P S T
=
=
=
=
=
   
   
    
   
 
其中 P(C|Tc)代表中文句詞組結構剖析樹之建構機率，而 P(Ts,Tc)代表詞組結構剖析樹結構
轉移之機率，最後 P(S|Ts)則代表手語句詞組結構剖析樹之驗証機率，圖 16 為系統示意圖。 
 
圖 16 台灣手語翻譯系統 
 
F. 手語影像合成技術 
 本研究將提出一個全新影像處理與合成技術，來建立手語影像合成機制，利用影像元
件的概念並計算影帶合成之間的移動，來合成出之間的 frame 使得影帶經由串接後也不會
有明顯的差異，圖 17 為本文所提之影像串接處理流程。 
 
圖 17 部份影像資料庫建立 
 
 12
 
圖 20 手語影帶串接斷點決定 
 
∑
=
+−−=
+=
k
r
rrrr
yx
uuuuangle
k
ccS
yxDyxScc
1
1121
),(
21
),(
1
1),(
)),(),((maxarg),(
 
 
 
圖 21 斷點串接軌跡生成 
 
 
圖 22 Bezier Curve 
 
 
圖 23 影像串接之影帶生成 
 14
為文法式手語與中文之語法結構相同，在翻譯之處理上較為單純，但也因此較無法涵蓋實
際手語翻譯之情況，所以，以下階段之翻譯成效評估皆只針對中文句翻譯自然式手語進行
實測與分析。 
AER(Alignment Error Rate)評估 
AER(Alignment Error Rate)為由 Och 等學者所提出之一套機器翻譯評估標準，其準則內
容為： 
2
1
A G
AER
A G
∩= − +  
其中 A代表由翻譯系統針對測試語料進行手語翻譯之轉譯結果，其內容為手語翻譯結果之
集合。而G 則代表測試語料包含於對照語料中之手語翻譯結果，其內容為測試句所對應手
語句之集合。而 AER 愈低則代表翻譯結果愈正確。舉例來說明：某測試句為「一朵花」，
而對照語料中之正確手語句為「花 一」，若翻譯結果也為「花 一」，則 2A = ， 2G = ，
2*21 0
2 2
AER = − =+ ，代表錯誤率為 0，即百分之百正確。反之，若翻譯結果為「花 一 朵」，
則 3A = ， 2G = ， 2*21 0.2
3 2
AER = − =+ ，即錯誤率為 0.2。 
本實驗針對中文句轉譯自然式手語進行評估，同時以 IBM Model 3 作比較，對照語料
中，取 80%作翻譯訓練語料，約 1,700 句，其餘 20%作測試語料，共約 400 句，平均句長
5.2。其轉譯結果之評量則針對翻譯系統所轉譯出來之語句，形成集合 A，與對照語料之標
記答案為標準，將之形成集合G ，進而估算出 AER，實驗結果如圖 25 所示。 
 
 
圖 25 AER 評估分析圖 
 
由實驗結果可得知，本研究所提出之翻譯機制在中文句轉譯手語之翻譯成效上，與 IBM 
Model 3 相比較，擁有較好之翻譯成效。另外，因為對照語料之緣故，使得 IBM Model 3
在文字對應之機率統計資訊較為不足，而導致 AER 值有相當程度之落差。 
TOP-N 轉譯結果測試實驗 
 16
 
圖 27 MOS 評估分析圖(手語社學生) 
 
 
圖 28 MOS 評估分析圖(聽語障生) 
 
觀察實驗結果，可發覺大部份之測試語句都能達到正確或相近地翻譯結果，而短句在
翻譯結果的正確比率上，佔有較佳之成果，其原因不外乎短句的手語變化較為單純與容易
歸納，相對地長句則較為複雜；另外，兩組評估對象所評估出來之結果，可發現聽語障生
對於手語翻譯結果之標準較為嚴格，幾乎以日常手語用法來作標準，因此在很好(Good)與
普通(Fair)之評估分佈情況與手語社學生之評估結果有相許之落差，這也顯現出聾人與聽人
之間，對於手語用法之認知差距。最後，若以「普通」為基準，評估「很好」及「普通」
皆視翻譯結果為可理解範圍的話，其語意理解程度為 81%。 
 
B. 影像串接比較 
本實驗主要分別針對「生成軌跡」、「串接影帶軌跡」與「原始拍攝手語句」分析手勢
軌跡在空間上橫軸與縱軸位置的串接走勢。在這裡先針對「生成軌跡」與「串接影帶軌跡」
兩名詞作說明，「生成軌跡」為本研究提出之機制所產生之動作軌跡，而「串接影帶軌跡」
為利用「生成軌跡」的位置資訊來針對影帶資料庫搜尋最相似影帶所產生的串接軌跡，因
此「串接影帶軌跡」為最後實際輸出之影帶串接序列。在實驗的測試句中，利用我們影帶
資料庫先前未切割的原始整句手語影片來進行 Inside Test；另外，再使用其他任意拍攝的手
語影帶進行 Outside Test。 
 
 18
 
圖 29 串接軌跡比較(X 軸、Inside) 
 20
原始手語句
0
20
40
60
80
100
120
140
160
180
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57
X軸
生成軌跡
0
20
40
60
80
100
120
140
160
180
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57
X軸
串接影帶
0
20
40
60
80
100
120
140
160
180
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57
X軸
肥皂 鐵
Frame  
圖 31 串接軌跡比較(X 軸、Inside) 
 22
Duration 的因素去掉來作觀察，則可看出整個軌跡走勢的起伏其實是相當具有一致性，在
串接區段軌跡走勢的對照上也相當符合，表示本文提出之方法確實能自然且平順的將任意
手語詞作整句式的串接合成。 
 
圖 33 串接軌跡比較(X 軸、Outside) 
 24
原始手語句
0
50
100
150
200
250
1 4 7 10 13 16 19 22 25 28 31 34 37
Frame
X軸
串接影帶
0
50
100
150
200
1 4 7 10 13 16 19 22 25 28 31 34 37 40
X軸
生成軌跡
0
50
100
150
200
1 4 7 10 13 16 19 22 25 28 31 34 37 40
X軸
名字 什麼
 
圖 35 串接軌跡比較(X 軸、Outside) 
 26
0
20
40
60
80
100
120
140
160
180
200
220
240
0 40 80 120 160 200 240 280 320
水平座標
垂
直
座
標
前一段影片結尾時的手勢
軌跡
後一段影片開頭時的手勢
軌跡
位置
方向
位置+方向
位置+串接軌跡轉移角度量
 
圖 37 串接考量軌跡比較 
由此實驗可得知，本文所提出之方法（位置與串接軌跡轉移角度量上的考量）可決定出最
適當的串接點與串接路徑。 
手語影像串接效果實驗  
選取十名正常人與五名聾生進行個案效果實測，實驗主要分為三類：1.相似度評分、
2.理解度評分、3.流暢度評分 
1. 相似度評分 
所有人(包括聽人及聾人)測試者，針對每個測試之原始句與合成句的相似度評分(0～
5)。 
 
圖 38 相似度評分 
 
2. 理解度評分 
聾人(懂手語的)測試者對每個合成後的測試句評分(看不出來：0 ～ 可完全理解：5)。 
 
圖 39 理解度評分 
3. 流暢性評分 
測試合成過程每個參數的作用，針對每個參數改變，給每個受測者評分結果(1.0～5.0)。 
 28
以將手語清楚流利的呈現，另外，可以用以解決手語教學人力不足的問題，使用者只要連
上網路進入網站便可有順序的開始手語學習過程。另外可利用數位化的特點，來達到互動
學習的目的，傳統之手語教材只能是學習者被動的去學習，學習者得有一定的手語理解程
度或是有人帶領的學習才有辦法靠自己去從傳統教材中學習手語，但學習者不一定了解教
材代表之意義，而經由數位化的設計，我們可以考慮到教材與使用者之間的互動，根據使
用者的情況如：聽人/聾人、 識字/不識字、手語理解程度…等來規畫不用的學習流程，因
此同樣的教材會以不同的呈現方式來導引使用者有順序的以最適合的方式來學習手語，了
解手語的涵意，不是只有學到手形，手勢等表面，而是可以學到手語真正的意涵及精神。 
 
參考資料 
[1]. David, R. B. and Mirendan, Pat,  "Augmentative and Aternative 
Communication", Paul H. Bookes Publishing Co., 1992. 
[2].  Demasco, P.,  et.  al. ,  ”Towards More Intelligent AAC Interfaces: The Use of 
Natural Language Processing”, The12th Annual Conference of RESNA, 1989. 
[3].  Bonnie J. Dorr, Pamela W. Jordan, John W. Benoit,  “A Survey of Current 
Paradigms in Machine Translation,” 2000. 
[4].  Kenji Yamada and Kevin Knight, “A Syntax-based Statistical Translation Model,” ACL 
2001: 523-530 
[5]. Wayne H. Smith, Morphological Characteristics of Verbs in Taiwan Sign Language. Ph.D. 
dissertion, Indiana University, 1989. 
[6]. David, R. B. and Mirendan, Pat,  "Augmentative and Aternative 
Communication", Paul H. Bookes Publishing Co., 1992. 
[7].  Demasco, P.,  et.  al. ,  ”Towards More Intelligent AAC Interfaces: The Use of 
Natural Language Processing”, The12th Annual Conference of RESNA, 1989. 
[8].  Bonnie J. Dorr, Pamela W. Jordan, John W. Benoit,  “A Survey of Current 
Paradigms in Machine Translation,” 2000. 
[9].  Kenji Yamada and Kevin Knight, “A Syntax-based Statistical Translation Model,” ACL 
2001: 523-530 
[10].  Wayne H. Smith, Morphological Characteristics of Verbs in Taiwan Sign 
Language. Ph.D. dissertion, Indiana University, 1989. 
[11].  Matas, J. ,  Mathy-Laikko, P.,  Beukelman, D., & Legresley, K., 
“Identifying the non-speaking population: A demographic study,” 
Augmentative and Alternative Communication, Vol. 1, pp.17-31, 1985. 
[12].  內政部，身心障礙人口數統計，民國 92 年。  
[13].  陳勝良，”語言溝通障礙者數位溝通輔具系統之研發 ”，國立成功大學，
醫學工程研究所，碩士論文，民國 90 年。  
[14].  Peter F. Brown, Stephen A. Della Pietra, Vincent J.  Della Pietra, Robert L. 
Mercer, “The Mathematics of Statistical Machine Translation: Parameter 
Estimation,” Computational Linguistics, Vol. 19, No. 2, pp,263-311, 1993. 
[15].  Franz Josef Och ,”An Efficient Method for Determining Bilingual Word 
Classes,” In Proc. of the Ninth Conf. of the Europ. Chapter of the Association 
 30
計畫成果自評 
 
聽語障人士由於先天或後天的因素而喪失聽力，造成學習上的困難與溝通上的障礙，
使其學習情緒及意願低落，因而成為社會及其家庭相當大的負擔，鑑於台灣目前缺乏對於
聽語障人士相關溝通輔具，教學輔助及訓練系統，因此，本計畫的研究目的在於建立一個
數位化之手語翻譯及合成教學系統及學習網站，提供一般人與聾人的手語教學輔助，本計
畫兩年為期如下述： 
第一年工作主要著重於中文/手語翻譯機制的建立及發展手語影像之串接合成技術，並完成
下列工作： 
 建立以剖析樹為基礎的翻譯架構 
 手語影帶之標記、分析與處理 
 建立手語影像元件資料庫 
 文句/文章翻譯系統的建立 
 數位手語學習教材之設計 
第二年工作主要為著重教學介面設計、系統之整合以及本計畫之評估，並完成下列工作： 
 整合手語翻譯機制與手語影像串接合成 
 配合手語數位教材規畫手語學習流程 
 手語教學介面建立 
 系統測試 
 32
可供推廣之研發成果資料表 
□ 可申請專利  ■ 可技術移轉                                      日期： 年 月 日 
國科會補助計畫 
計畫名稱：聽語障手語翻譯及合成教學輔助系統之研究 
計畫主持人：吳宗憲 
計畫編號：NSC 94-2614-E-006 -073 學門領域： 
技術/創作名稱 手語影像合成技術 
發明人/創作人 吳宗憲 
中文： 
手語之呈現方式主要為兩大類，三維人形呈現與真人影像，而真人
影像之呈現較為一般大眾接受，而真人影像呈現最大問題為句性之
彈性受限，因此本研究提出一個以手語影像為單元之影帶串接技
術，以完成有限資源下之大量手語句之合成。 
技術說明 英文： 
Sign language expressions have two types, 3-D avatar and real 
video based synthesis. Real video is more familiar than 3D 
avatars to people, but real video is hard to cope with all 
sentences. This study propose a sign video based synthesis 
for produce variant combinations for different sentence from 
a set of sign videos. 
可利用之產業 
及 
可開發之產品 
 
技術特點 
1. 手語影像平衡語料庫選取及拍攝 
2. 手語合成單元擷取及處理 
3. 手語詞彙影帶串接技術 
 
推廣及運用的價值 
1. 可應用於手語影像電話之發展 
2. 手語序列之合成可提供手語教學一個直覺介面，讓學習者可以
由影像學習完整之手語句表達 
3. 手語字幕之呈現，搭配手語翻譯技術，預先將文字字幕翻譯並
串接即可應用於影像之上 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
第九屆口述語言處理國際會議(Interspeech2006)報告 
吳宗憲 
成功大學資訊工程學系 
 
(一) 參加會議經過 
 
     第九屆口述語言處理國際會議於 9月 17日至 9月 21日在美國匹茲堡舉辦，此會議今年是
由國際語音通訊學會舉辦，是每二年舉辦一次之國際研討會。此一會議為語音與口述語言處理
方面最大且最被肯定會議之一。本會議討論之主體包括語音處理、語言處理及口述語言理解等
約 75個議程，大會共發表六百多篇論文，其中來自中華民國之專家學者約有十幾位。 
     此次會議論文發表分口頭與海報兩種方式，筆者有一篇口頭論文發表；題目為「Stochastic 
Vector Mapping-based Feature Enhancement Using Prior Model and Environment Adaptation for 
Noisy Speech Recognition」被安排於九月十八日上午發表。此次會議中與多位在美國、日本、大
陸、香港及新加坡等地之學者或專家做經驗交流，彼此分享在語音與口述語言處理方面之研究
心得，實為一難得之機會。 
 
(二) 與會心得 
 
     此次會議議題相當廣泛，大家參與會議時討論亦非常熱烈，大會安排多場海報式發表，
使得大家可以針對自己興趣之主題充分與發表者深入討論，因此收獲相當多。此次會議中華民
國參加之人員約十幾位，比以往參加人數較少，雖然在國外，大家亦可交換心得及了解目前在
各個領域之研究情形。經由這次會議的參與，不但得以認識一些相關領域之學者，互相交換研
究心得，而且可吸收最新資訊，對日後之研究將有所助益。 
此外，本人亦參與多場 Plenary Lectures 如  
1. What a study of sound can tell us about human speech perception  
2. Creating speech interface for mass market applications 
3. Statistical language learning in human infants and adults 
4. Speech recognition: The unfinished agenda  
另外, 本人亦參加多場論文發表如: 
Stochastic Vector Mapping-based Feature Enhancement Using Prior Model and 
Environment Adaptation for Noisy Speech Recognition 
Chia-Hsin Hsieh, Chung-Hsien Wu and Jun-Yu Lin 
Department of Computer Science and Information Engineering 
National Cheng Kung University, Tainan, Taiwan, R.O.C. 
{ ngsnail, chwu, adversary}@csie.ncku.edu.tw 
 
Abstract 
 
This paper presents an approach to feature enhancement for 
noisy speech recognition. Three prior models are introduced to 
characterize clean speech, noise and noisy speech respectively 
using sequential noise estimation based on noise-normalized 
stochastic vector mapping. Environment adaptation is also 
adopted to reduce the mismatch between training data and test 
data. For AURORA2 database, the experimental results 
indicate that a 0.77% digit accuracy improvement for 
multi-condition training and 0.29% digit accuracy 
improvement for clean speech training were achieved without 
stereo training data compared to the SPLICE-based approach 
with recursive noise estimation. For MAT-BN Mandarin 
broadcast news database, a 2.6% syllable accuracy 
improvement for anchor speech and 4.2% syllable accuracy 
improvement for field report speech were obtained compared 
to the MCE-based approach. 
Index Terms: noisy speech recognition, feature enhancement, 
environment adaptation, prior model 
 
1. INTRODUCTION 
 
The state-of-the-art speech recognizers can achieve very high 
recognition rate under clean environment, while the 
recognition rate generally degrades drastically under noisy 
environment. Therefore, noise-robust speech recognition has 
become an important task for noisy speech recognition. Recent 
research on noise-robust speech recognition mostly focused on 
two directions: (1) Remove the noise from the corrupted noisy 
signal in signal or feature space, such as spectral subtraction, 
and model-based feature enhancement: SPLICE [1]; (2) Model 
compensation in model space, such as PMC [7]. 
The stochastic vector mapping (S.V.M.) [1-2] with 
sequential noise estimation-based noise normalization [1,3,5] 
have been proposed and achieved high improvement in noisy 
speech recognition. However, there still exist some drawbacks 
and limitations. First, the performance of sequential noise 
estimation will decrease when the noisy environment vary 
drastically. Second, the environment mismatch between 
training data and test data still exists and results in performance 
degradation. Third, the maximum-likelihood-based stochastic 
vector mapping (SPLICE) required annotation of environment 
type and stereo training data. Nevertheless, the stereo data are 
not available for most noisy environments. In order to 
overcome the insufficiency of tracking ability in sequential EM, 
the prior models are introduced to provide more information in 
sequential noise estimation. Furthermore, an environment 
adaptation is constructed to reduce the mismatch between the  
Noise 
estimation
K-means
Clustering
Training phase 
Environment 
Model 
Training
Prior 
Noise
model
Prior 
clean 
speech
model
Noisy 
Speech
MCE 
Training
for
N.N. S.V.M.
& HMM 
Prior 
noisy 
speech
model
Environment adaptation
eΩ ( )eΘn
 
Testing phase
Noisy speech 
N.N.-S.V.M.
Speech 
enhancement
Acoustic 
model
LVCSR TranscriptionNoise estimation
Prior 
noise
model
Prior 
clean 
speech
model
Prior 
noisy
speech
model
xn
eΩ( )eΘ
 
 
Figure 1: Detailed flowchart of the training and testing phase 
 
training data and test data. Finally, MCE-based approach [2] is 
employed without the stereo training data and an unsupervised 
frame-based auto-clustering is adopted to automatically detect 
the environment type of the training data. 
 
2. NOISE-NORMALIZED STOCHASTIC 
VECTOR MAPPING FOR FEATURE 
ENHANCEMENT  
 
2.1 Stochastic Vector Mapping (S.V.M.) 
 
Figure 1 shows the frameworks of the proposed S.V.M.-based 
feature enhancement approach in training, adaptation and 
testing phases. The S.V.M.-based feature enhancement 
approach estimates the clean speech feature x  from noisy 
speech feature  through an environment-dependent 
mapping function 
y
( )( ); eF y Θ , where  denotes the mapping 
function parameters and e  denotes the corresponding 
environment of the noisy speech . 
( )eΘ
y
Assuming that the training data of the noisy speech Y can 
be partitioned into K different noisy environments, the feature 
of Y under an environment  can be modeled by a Gaussian e
 
3.3 Sequential Noise Estimation 
 
In [1,3,5], sequential expectation-maximization (EM) 
algorithm is employed for sequential noise estimation. In this 
study, the prior clean speech, noise and noisy speech model is 
involved to construct a robust noise estimation procedure. 
Based on the sequential EM algorithm, the estimated 
noise is obtained using . In the E-step, 
an objective function is defined first as: 
1 n
n arg max (nt Q+ = 1 )t+
1 1
1 1 1 1
1 1 1 1(n) ln ( , , | n) | , n
t t t t t
tQ E p y M C y
+ + + +
+ ⎡ ⎤⎣ ⎦      (9) 
where 1
1
tM +  and  denotes the mixture indexes of the 
clean speech model and noise model to which the noisy speech 
 occurs from frame 1 to t+1. In the M-step, the iterative 
stochastic approximation and a forgetting factor are introduced. 
Finally, a sequential noise estimation function is derived. 
1
1
tC +
y
 
4. ENVIRONMENT ADAPTATION 
  
Because the prior models are usually not complete enough to 
represent the universal data, the environment mismatch 
between training data and test data will result in the 
degradation on feature enhancement performance. In this study, 
an environment adaptation strategy is proposed before testing 
phase to deal with the problem. Figure 3 shows the 
environment adaptation flowchart. The environment adaptation 
procedure contains two parts: The first one is model parameter 
adaptation on noise prior model 
n
 and noisy speech prior 
model  and the second is on noise-normalized S.V.M. 
function  and environment model 
eΩ . 
Φ
yΦ
( )eΘ
 
4.1 Model Adaptation on Noise and Noisy Speech Prior 
Models 
 
For noise and noisy speech prior model adaptation, MAP 
adaptation [8] is applied to the noise prior model 
nΦ  first. 
The adaptation equation for the noise prior model parameters 
given T frames of the adaptation data is defined as: z
i ( ) ( ), ,
1 1 1 1
1 1
T C C T
c c c t c
t c c t
w dν ν
= = = =
= − + − +∑ ∑ ∑∑ c td                    
i
,
1 1
Tn
c c c c t t c c t
t t
d y dμ τ ρ τ
= =
= + ⋅ +∑ ,T∑                   (10) 
j i( ) i( ) i( ) i( ) ( )1 , ,
1 1
T TT Tn n n nn
c c c cc c c t t t c c c c c t
t t
d z z p dυ μ μ τ ρ μ ρ μ α−
= =
Σ = + − − + − − − +∑ ∑  
  
where the conjugate prior density of the mixture weight is the 
Dirichlet distribution with hyper-parameter of  and the joint 
conjugate prior density of mean and variance parameters is the 
Normal-Wishart distribution with hyper-parameter of 
cv
, , ,  and c c c cτ ρ α υ .  
After adaptation of noise prior model, the noisy speech 
prior model 
yΦ  is then adapted using the newly adapted 
noise prior model  according to Eq. nΦ (8). 
 
4.2 Model Adaptation of Noise Normalized Stochastic 
Vector Mapping 
Adaptation phase (unsupervised)
Adaptation data
(A set of noisy 
speech ) 
Noise 
estimation
Prior 
noise
model
Prior 
clean 
speech
model
N.N. S.V.M 
model 
adatpation
Prior 
noisy
speech
model
Environment adaptation
N.N. S.V.M 
speech 
enhancement
xn
eΩ( )eΘ
 
 
Figure 3: Detailed flowchart of the adaptation phase 
 
For noise-normalized S.V.M. adaptation, model parameters 
eΩ   
and mapping function parameters in  need to be 
adapted in the adaptation phase and testing phase, respectively. 
( ( ); eF y Θ )
First, adaptation of model parameter 
e
 is similar to that of 
noise prior model. Second, the adaptation of 
Ω
{ }( ) ( )
1
Ke e
k k
r =Θ =  is 
an iterative procedure. While { }( ) ( )
1
Ke e
k k
r =Θ =  is not a random 
variable and does not follow any conjugate prior density, an 
ML-based adaptation which is similar to the correction vector 
estimation of SPLICE is employed as: 
j ( ) i( ) ( )( ) | - , - | - ,ek t t t t
t t
r p k y n e x y p k y n=∑ ∑ e      (11) 
where the temporally estimated clean speech itx  are 
estimated using the un-adapted noise-normalized stochastic 
mapping function in Eq.(4) . 
 
 
5. EXPERIMENTAL RESULTS 
 
5.1 Training, Adaptation and Test Sets 
 
In this study, two corpora were introduced for evaluation. The 
first database is the famous benchmark—AURORA2 database 
[8] for noisy speech recognition evaluation. One fifth of the 
default test data were extracted for adaptation. The HTK 
speech recognizer was introduced and the digit recognition 
accuracy was used to measure the performance.  
The second is the MAT-BN corpus [9] which consists of 
Mandarin TV News. The news content is collected from 
anchors, field reporters and interviewers. One hundred and 
twenty hours news audio were extracted for training, 
adaptation and testing. The speech recognizer [7] was 
constructed without any language model and the syllable 
accuracy was used to measure the performance. 
 
5.2 Experiments on AURORA2  
 
Table 1 shows the experimental results of the proposed 
approach on AURORA2 database. Two results of previous 
research were referenced for comparison and three experiments 
were conducted for different experimental conditions: no 
denoising (BASELINE) [8], SPLICE with recursive EM using 
stereo data (SPLICE+R_EM) [1], proposed approach using 
manual annotation without adaptation (N.N._S.V.M.+MA-AD), 
 
