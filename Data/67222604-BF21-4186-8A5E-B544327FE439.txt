譯。這一方面的工作成果發表於 DC1 和 DC5。目前也已將部
份成果投稿於國際學術研討會。 
在過去一年中，本研究計畫最顯著的成果在於結合自然語言
處理技術與機器學習技術來處理美國財報中的文字與數據的
關連性。我們利用自然語言技術抽取財報中的質性判斷的主
觀陳述，並且利用統計模型來比對這一些意見與經營數據的
關聯性。本研究成果榮獲 2011 年計算語言學會的碩士論文佳
作獎與 IEEE ICEBE 2011 年最佳論文獎。這一研究的成果目
前發表於 IC1 和 IC2。在達成這一文字意見探勘之前，本研
究計畫已經進行一些比較先導的探索工作，研究個人微網誌
中的情緒分析，並且將成果發表於 DC2 和 DC6。 
本研究計畫所研究的核心技術雖然集中於自然語言處理與機
器學習技術的綜合應用，但是要為個別研究撰寫目的、研究
方法與成果之細節，因此謹以上述的綜合摘要報告本研究案
的綜合成果。個別研究成果的細節，煩請參閱所發表之論
文，如若無法下載論文，請與計畫主持人連繫索取論文。我
們僅附上所發表之 ACM 期刊論文和 IEEE ICEBE 論文作為代表
作品。 
 
中文關鍵詞： 漢字學習輔助、閱讀認知歷程、意見分析、財報內容分析 
英 文 摘 要 ：  
英文關鍵詞：  
 
中文摘要 (Chinese abstract) 
本年度之工作重點在於應用倉頡碼來判別形體相似的漢字，配合語音相近漢字的資訊來建
構一個有用的漢字學習輔助系統。在計算語言學方面，我們繼續探索一些與機器翻譯相關
的研究議題。在自然語言處理技術的應用方面，我們觸及美國財報的意見分析與個人網誌
上的情緒分析。為了建構好的電腦輔助教學系統，了解學習者的文字辨識、認知歷程是很
相關的議題，因此我們也與心理學家進行一些合作的研究並且發表一些相關的論文。 
在本年度計畫期間之內(2010 年 8 月到 2011 年 7 月；7 月到 12 月期間為等待參與國際
學術研討會與經費核銷)合計發表一篇 ACM 期刊論文、四篇國際會議論文與五篇國內學術
會議論文。另有受本研究計劃之部分補助，目前已經被接受但未正式發表之兩篇國際學術
會議論文與一篇國內學術會議論文。審稿中之論文有：國際學術會議論文三篇與國內學術
會議論文三篇。 
以下就各主要研究方向摘要說明工作內容與相關成果。 
延續過去一兩年的努力，我們持續於去年度擴大倉頡詳碼的應用。我們把倉頡詳碼的
概念延伸到簡體漢字，並且建立一個雛型軟體。比較重要的成果是我們終於回頭整理過去
幾年發表於 ACL 和 COLING 的論文，並且把論文投稿於 ACM 的 TALIP 且獲得接受。這
一部分的論文發表是：J1、IC5 和 IC6 (請參考文末之論文清單)。 
我們延伸形音相近漢字的基礎研究，建構一個有心理認知理論基礎的漢字學習遊戲，
這一遊戲能夠真實的協助學童學習漢字，目前已經實際用於台北市兩個國小。相關研究成
果發表於 IC3 和 DC3。 
除了漢字遊戲之外，我們也嘗試研究一些認知與教育相關的議題。我們研究漢字母與
使用者的眼動軌跡，企圖了解眼動軌跡與中文斷詞的關連，雖然沒有驚人的發現，但是已
經將成果發表於 IC4。我們結合文字分析技術與機器學習技術，企圖分析高中一年級與二
年級的英文閱讀測驗的文本難度，結果尚稱不錯，研究過程與結果發表於 DC4。 
雖然機器翻譯目前仍然不是我們的研究的主要目標，但是透過以機器翻譯作為假想目
標，來培養實驗室的基礎研發能力，卻是一個不錯的手段。過去幾年我們陸續在這一方面
有一些努力。包含與師範大學曾元顯教授參與 NTCIR9 的 PatentMT 工作坊的競賽，雖然我
們沒有全心、長期投入，但是也沒有因此落入最後一名；甚至翻譯效果也沒有輸給沒有適
當訓練語料的一般翻譯軟體。在機器翻譯相關的議題方面，過去一年我們建立詞彙對列的
經驗，並且結合過去的相關經驗，開始嘗試比較接近機器翻譯議題的動詞名詞組的翻譯。
這一方面的工作成果發表於 DC1 和 DC5。目前也已將部份成果投稿於國際學術研討會。 
在過去一年中，本研究計畫最顯著的成果在於結合自然語言處理技術與機器學習技術
來處理美國財報中的文字與數據的關連性。我們利用自然語言技術抽取財報中的質性判斷
的主觀陳述，並且利用統計模型來比對這一些意見與經營數據的關聯性。本研究成果榮獲
2011 年計算語言學會的碩士論文佳作獎與 IEEE ICEBE 2011 年最佳論文獎。這一研究的成
果目前發表於 IC1 和 IC2。在達成這一文字意見探勘之前，本研究計畫已經進行一些比較
For computer assisted Chinese learning, we also worked on the classification of short essays 
used in the reading comprehension of high school students. The goal was to judge the grades of 
the short essays that were used in the first four semesters of grade 10 and 11. We did not find a 
method that perfectly find the correct answer, but have attempted to improve from the very first 
version. Please be referred to DC4 for details. 
Machine translation (MT) may be too tough for a small research group like ours. However, 
targeting at MT issues, at least sometimes, helps us maintain the ambition and technical 
competence. Working with Professor Yuen-Hsien Tseng of the National Taiwan Normal 
University, we participated in the NTCIR9 PatentMT task in 2011. Although we did not spend a 
lot of time and energy on the task, we did not perform poorly in the task, and was able to beat 
another team. Interestingly, according to the estimation of the task organizers, our results would 
have beaten Google, given that Google did not have the training data that we obtained from the 
task organizers. Besides our participation in the NTCIR task, we nurtured our competence in MT 
regularly, and had experience in word alignment and translation of verb-noun pairs. The results 
had been published in DC1 and DC5, and some recent findings have been submitted for possible 
publication in international conferences. 
The most salient research results of our group are the mining of opinion mining in US 
financial statements. We integrated techniques for natural language processing and machine 
learning to find the opinion patterns in US financial statements in the form of multiple word 
expressions (MWEs). Statistical models were then utilized to examine the relationships between 
the MWEs and the financial ratios in the statements. This work received a 2011 Honorable 
Mention Award for Master’s thesis by the Association for Computational Linguistics and Chinese 
Processing, and results were published in IC1 and IC2. Before we completed this work, we had 
started some explorative work. We analyzed the emotional ingredients in the short statements in 
personal micro-blogs, and the results were published in DC2 and DC6. 
Due to the wide variety of our work, we could not report the details of each of our projects 
as demanded by the standard formats of the NSC final reports. Instead, we summarized the goals 
and accomplishments of each projects above only, and provided our ACM and IEEE ICEBE 
papers as the representative achievements. If the readers are interested in any of our projects, 
please be referred to the papers listed in References. If papers cannot be downloaded easily, 
please contact the principal investigator for the papers. 
計畫成果自評 (Self evaluation) 
整體來說，以一個一年期的研究計畫新台幣 58 萬的研究經費來說，以上的成果應該算是超
過勉強交差的程度。在論文發表數量與質量兩方面都有中上的水準，並且建立一個真實可
國內學術會議 (domestic conferences) 
DC1. 莊怡軒、王瑞平、蔡家琦及劉昭麟。英文技術文獻中一般動詞與其受詞之中文翻譯的語境效用 
(Collocational influences on the Chinese translation of non-technical English verbs and their objects in 
technical documents)，第廿三屆自然語言與語音處理研討會論文集 (ROCLING XXIII)，即將出版。 
臺灣，臺北，2011 年 9 月 8-9 日。(中文內容) (NSC-99-2221-E-004-007) (NSC-100-2221-E-004-014) 
DC2. 莊怡軒、陳建良、劉昭麟及劉吉軒。失戀被動分手者情感挫折偵測之初探，第十五屆人工智慧與應
用研討會論文集 (TAAI'10)，論文光碟。臺灣，新竹，2010 年 11 月 18-20 日。(中文內容) 
(NSC-97-2221-E-004-007-MY2) (NSC-99-2221-E-004-007) 
DC3. 李嘉玲、張裕淇、李佳穎及劉昭麟。結合認知理論之電腦輔助漢字教學遊戲，2010 台灣網際網路
研討會論文集 (TANET'10)，論文光碟。臺灣，臺南，2010 年 10 月 27-29 日。(中文內容) 
(NSC-97-2221-E-004-007-MY2) (NSC-99-2221-E-004-007) 
DC4. 黃昭憲、郭韋狄、李嘉玲、蔡家琦及劉昭麟。以語文特徵為基之中學閱讀測驗短文分級 (Using 
linguistic features to classify texts for reading comprehension tests at the high school levels)，第廿二屆自
然語言與語音處理研討會論文集 (ROCLING XXII)，98ԟ112。臺灣，南投，2010 年 9 月 1-2 日。(中
文內容) (NSC-97-2221-E-004-007-MY2) (NSC-99-2221-E-004-007) 
DC5. 黃昭憲、張裕淇、劉昭麟及曾元顯。以共現資訊為基礎增進中學英漢翻譯試題與解答之詞彙對列 
(Using co-occurrence information to improve Chinese-English word alignment in translation test items for 
high school students)，第廿二屆自然語言與語音處理研討會論文集 (ROCLING XXII)，128ԟ142。
臺灣，南投，2010年 9月 1-2日。(中文內容) (NSC-97-2221-E-004-007-MY2) (NSC-99-2221-E-004-007) 
DC6. 孫瑛澤、陳建良、劉峻杰、劉昭麟及蘇豐文。中文短句之情緒分類 (Sentiment classification of short 
Chinese sentences)，第廿二屆自然語言與語音處理研討會論文集 (ROCLING XXII)，184ԟ198。臺
灣，南投，2010 年 9 月 1-2 日。(中文內容) (NSC-97-2221-E-004-007-MY2) (NSC-99-2221-E-004-007) 
附錄：發表論文之代表作 
Chien-Liang Chen(陳建良), Chao-Lin Liu, Yuan-Chen Chang(張元晨), and Hsiangping Tsai(蔡湘萍). Exploring 
relationships between annual earnings and subjective expressions in US financial statements, Proceedings of the 
IEEE International Conference on e-Business Engineering 2011 (ICEBE'11), 1-8. Beijing, China, 19-21 October 
2011. (EI) (NSC-99-2221-E-004-007) (NSC-100-2221-E-004-014) （最佳論文獎） 
 
 
晚上的晚宴在清華大學的餐廳進行。原本是要頒發最佳論文獎，但是因故拖延到二十日的午宴。
晚宴中，大會頒發感謝狀給主辦單位的許多老師。也介紹了明年的會議地點與主辦單位。 
十月二十日：上午持續有兩階段的論文報告，中午則是午宴與頒獎。 
上午的論文報告的出席者多為國際學者，這或許是為了方便這一些學者先來參與晚宴，然後再次
日報告。報告內容的英文優於昨日下午，技術層次則約略相同。 
午宴中頒發這一次最佳論文獎，入圍與得獎論文合計有五篇，政大的論文有幸脫穎而出，獲得唯
一的最佳論文獎。午宴持續到接近下午兩點才結束。 
二、 考察參觀活動(無是項活動者略) 
由於返國的班機預訂在八點起飛，而二十日中午的午宴到接近兩點才結束，因此實際上不可能參
與任何遠距的參觀活動。在搭機之前只有到天安門廣場旁邊參觀。當天中國國家博物館與三點就
閉館，因此改變原訂的參觀計畫；改到旁邊的中山公園。中山公園中正在展出辛亥革命百年紀念
的資料。可以靠到許多關於中國國民黨的資料。這樣的資料在過去或許不容易在天子腳下的北京
市看到，但是現在這些陳列似乎是很平常的，就好像我們在歷史課本中讀明史、清史一樣。 
三、建議 
四、攜回資料名稱及內容 
會議論文光碟、最佳論文獎獎狀 
五、其他 
 
Exploring the Relationships between Annual Earnings and Subjective Expressions 
in US Financial Statements 
Chien-Liang Chen Chao-Lin Liu Yuan-Chen Chang Hsiang-Ping Tsai 
Dept. of Computer Science Dept. of Computer Science Dept. of Finance Dept. of Finance 
National Chengchi University National Chengchi University National Chengchi University Yuan Ze University 
Taipei, Taiwan Taipei, Taiwan Taipei, Taiwan Taoyuan, Taiwan 
g9813@cs.nccu.edu.tw chaolin@cs.nccu.edu.tw yccchang@nccu.edu.tw hptsai@saturn.yzu.edu.tw 
 
 
Abstract—Subjective assertions in financial statements 
influence the judgments of market participants when they 
assess the value and profitability of the reporting corporations. 
Hence, the managements of corporations may attempt to 
conceal the negative and to accentuate the positive with 
"prudent" wording. To excavate this accounting phenomenon 
hidden behind financial statements, we designed an artificial 
intelligence based strategy to investigate the linkage between 
financial status measured by annual earnings and subjective 
multi-word expressions (MWEs). We applied the conditional 
random field (CRF) models to identify opinion patterns in the 
form of MWEs, and our approach outperformed previous 
work employing unigram models. Moreover, our novel 
algorithms take the lead to discover the evidences that support 
the common belief that there are inconsistencies between the 
implications of the written statements and the reality indicated 
by the figures in the financial statements. Unexpected negative 
earnings are often accompanied by ambiguous and mild 
statements and sometimes by promises of glorious future. 
Keywords-Natural language processing, opinion mining, 
financial text mining, sentiment analysis, information extraction 
I.  INTRODUCTION 
In recent years, researchers have implemented quantitative 
methods to investigate the relationships between financial 
performance and the textual content of the press. Loughran and 
McDonald developed positive and negative single-word lists, 
that better reflected the tone of U.S. financial statements (10-K 
filings), and they examined the linkage between textual 
statements and financial figures [15]. Antweiler and Frank 
studied the influence of the discussions on Internet message 
boards about 45 companies, which list in the Dow Jones 
Industrial Average, and their stock prices. They concluded that 
stock messages could help predict market volatility but not stock 
returns [1]. Li relied on the information in the texts of annual 
financial statements to examine the implications of risk 
sentiment of corporation's 10-K filings for stock returns and 
future earnings. Li found that risk sentiment is negatively 
correlated with future earnings and future stock returns [13]. 
Tetlock et al. used negative words contained in the financial 
press about the S&P 500 to show that the negative words are 
useful predicators for both earnings and returns [27]. 
Some researchers in opinion mining have employed 
different machine learning techniques. Pang et al. utilized the 
concept of naive Bayes, maximum entropy classification, and 
support vector machines to classify the sentiment of movie 
reviews at the document level [19]. Weibie et al. classified 
subjective sentences based on syntactic features such as the 
syntactic categories of the constituents [28]. Kim and Hovy used 
syntactic features to identify the opinion holders in the MPQA 
corpus by a ranking algorithm that considered maximum 
entropy [11]. Choi et al. adopted a hybrid approach that 
combined CRF and the AutoSlog information extraction 
learning algorithm to identify sources of opinions in the MPQA 
corpus [4]. 
Unlike traditional models that considered individual words 
(unigrams) and "bag of words" [17], we attempt to 
automatically extract MWEs which could capture the subjective 
evaluations of the financial status of the corporation more 
precisely. Opinion patterns include opinion holders and 
subjective multi-word expressions (MWEs). For instance, the 
opinion patterns in the sentence "The Company believes the 
profits could be adversely affected" include opinion holder "The 
Company" and two subjective expressions: "believe" and "could 
be adversely affected".  
Our leading contribution is to link positive and negative 
financial status with subjective multi-word expressions and to 
propound that the managements of the companies have an 
incentive to hide negative information but to promote positive 
information. First, we propose a computational procedure to 
model the text in financial statements which uses conditional 
random field models to identify opinion patterns. Second, we 
trained and tested the models with the annotated MPQA corpus 
[18] to tune and evaluate the CRF models. Third, we employed 
the best-performing CRF model that we found from a sequence 
of experiments to extract subjective opinion patterns in U.S. 
financial statements. Fourth, we employed multinomial logistic 
regression to verify whether the opinion patterns were indicative 
of the earnings of the corporations, and also designed a 
discriminative strategy to quantify the linkages between annual 
earnings and the use of subjective MWEs. Finally, using the 
algorithmically-identified MWEs, we examined whether 
companies indeed expressed different strengths of positivity and 
negativity for different earning outcomes, and we found that the 
companies inclined to use weaker expressions when mentioning 
negative results.  
II. FINANCIAL DATA AND CORPORA 
The financial statements used in this work are U.S. SEC 10-
K filings of public companies downloaded from the EDGAR 
database [6]. We also used annual quantitative information 
about the companies from the Compustat database [23]. Opinion 
patterns were extracted from the financial statements of 324 U.S. 
companies for the years between 1996 and 2007, and we 
merged two different data sources (EDGAR and Compustat) by 
matching company names and dates (The matching table is 
provided by Sufi [25]). After eliminating the data with missing 
values, the number of data items was reduced from 2102 to 
1421 to produce what may be describe as a "small dataset". In 
robustness test, we expanded our sample size from 1421 to 
22780 which sample included reports of 6534 U.S. companies 
of parent phrase is such leaf node. For example in Figure 1, 
because the head word of the NP “some bold decisions” is 
“decisions” and the head of the VP “make some bold decisions” 
is “make”, the noun “decisions” would be the phrase type only 
NNS and NP without VP. In contrast, the verb “make” contains 
VB, VP and VP in sequence. Syntactic path and partial path 
(f12): the path helps predict the semantic labels. The syntactic 
path feature describes the syntactic relation from constituent to 
the predicate in the sentence with the syntactic categories of the 
node which is passed through. In Figure 1, the path from “We” 
to “decides” can be represented as either 
“PRP↑NP↑S↓VP↓VBD” or “NP↑S↓VP↓VBD” depending on 
whether the syntactic type is PRP or NP of word “We”. The 
partial path is the part of the syntactic path which contains the 
lowest common ancestor of the constituent and predicate (e.g., 
the lowest common ancestor is S in the sentence, so the partial 
path can be reduced to “PRP↑NP↑S”). 
Based chunk (f13): the based chunk feature is a partial 
parsing structure. We represent the based chunk in IOB format 
which makes the segmentation of phrase boundary more precise. 
Subordinate noun clause followed verb and noun phrase before 
verb phrase (f14): since our phrase type feature is only three 
levels of syntactic category from the parents of parse tree leaf 
nodes, the macro syntactic structure information may be omitted 
if the parse tree is constructed deeply. In sentence “The 
management believed that …,” the subordinate noun clause 
following the verb “believed” is usually embedded with 
subjective expressions. We used the Stanford tregex toolkit to 
extract such patterns from the parse tree [24]. Syntactic 
dependency (f15): the feature is to capture the grammatical 
relation that includes three types of grammar dependency 
“subject relationship”, “modifying relationship” and “direct-
object relationship”. The Subject relationship includes the 
“nominal subject” and the “passive nominal subject”, which 
correspond to the noun that is the syntactic subject of the active 
and passive clause; the modifying relationship consists of 
adjectival modifier or adverbial modifier, which can be any an 
adjectival (adverb) word that modifies the meaning of the noun 
(verb or adjective). The direct-object relationship indicates the 
noun that is the direct object of the verb. We utilized the 
Stanford dependency parser to get the dependency parse tree for 
the dependency features [24]. The opinion holders, opinion 
words in subjective expressions and opinion targets are 
correlated with the subject, modifying and direct-object 
relationship individually. In Figure 1, the label of the phrase “to 
make some bold decisions” is “expressive-subjectivity”, and we 
can observe that the opinion word in the phrase is “bold” with 
an adjective POS that modifies the noun “decisions”. Since the 
word “we” is the subject of verb “decides”, the identification of 
the relationship of the subject with the verb can be used to 
predict the opinion holders. 
E. Simple semantic features 
Named entity recognition (NER, f16): when utilizing the 
syntactic features, it is hard to distinguish the entity name from 
the other noun phrases. The NER can better identify the name of 
a person, who may be the opinion holder or the opinion target. 
Stanford NER [24] was employed to label the name of persons, 
organizations and locations. Subjective word and its polarity 
(f17): the subjective words which appear in sentences can help 
not only judging whether the sentence is an opinion sentence but 
also detect the opinion words in the labels “expressive-
subjectivity” and “direct-subjective”. The subjective words can 
be classified by two aspects which are the strengths of the 
subjectivity and the polarity. According to different levels of 
subjectivity, the strength can be either one of objective, weak 
subjectivity or strong subjectivity. Moreover, the weak and 
strong subjectivity can be further divided into positive, negative 
or neutral. The subjective word dictionary was manually 
collected by Wiebe [29]. Verb-clusters of predicate (f18): verbs 
with similar semantic meanings might appear together in the 
same document. In order to arrange the semantically-related 
verbs into one group, we use verb clusters to avoid the 
occurrence of the presence of rare verbs which would 
deteriorate the model performance. The ASSERT toolkit adopts a 
probabilistic co-occurrence model to cluster the co-occurrence 
of a verb into 64 clusters. The frame of the predicate in 
FrameNet (f19): We used the FrameNet [7] to query the name 
of the frame which a particular predicate belonged. 
IV. LINKAGES BETWEEN EARNINGS AND SUBJECTIVE MWES 
We aim to investigate whether the subjective MWEs in the 
U.S. financial statements reflected the trend of firm’s earnings. 
We used multinomial logistic regression (Stata [26]) to explain 
the relationship between annual earnings and subjective MWEs 
and to infer its economic meaning. 
A. Dependent variable: standardized unexpected earnings 
Our main concern in regard to the financial status of the 
company is each firm’s standardized unexpected earnings (SUE) 
which capture the trend of the firm’s earnings (following Li [13] 
and Tetlock et al. [27]). The SUE is viewed as the dependent 
variable of our research. The SUE for each firm in year t is 
calculated as, 
 ܷܧ௧ ൌ ܧ௧ െ ܧ௧ିଵ                                                        (1) 
 ܷܵܧ௧ ൌ ௎ா೟ିఓೆಶ೟ఙೆಶ೟                                                         (2) 
Where ܧ௧ is the earnings of the firm in year t, and the mean and 
volatility of unexpected earnings (UE) are equal to the mean 
(ߤ௎ா೟) and standard deviation (ߪ௎ா೟) of the unexpected earnings 
of each firm within a period of 12 years unexpected earnings. 
We transformed the SUE into three categories (Y) which are 
positive (1), no changed (0) and negative (-1), and the criteria is 
described as, 
 ܻ ൌ ቐ
1, if  ܷܧ௧ ൒ ሺߤ௎ா೟ ൅ ݃ ൈ ߪ௎ா೟ሻ  
െ1, if ܷܧ௧ ൑ ൫ߤ௎ா೟ െ ݃ ൈ ߪ௎ா೟൯
0, otherwise.
                      (3) 
Where ݃  is a constant that we set to 0.5. The reason for 
transforming the Y from a numeric dependent variable into a 
categorical variable is to avoid any minor changes in SUE 
disturbing the empirical results. 
B. Explanatory variables: MWEf-idf and control variables 
The main explanatory variables in this study, an information 
retrieval weighting schema, was employed to quantify the 
MWEs. Moreover, other factors that have been traditionally 
considered as correlated with earnings are employed as control 
variables1. Further, the frequency of the occurrence of the multi-
                                                           
1 The control variables were the financial factors that relate with the SUE. The control 
variables include lag SUE (SUE of the previous year), BM ratio (natural log of 
dividing book value by market value), ROE (return on equity), accruals (earnings 
minus operating cash flow), size (natural log of market value), Dividend (cash 
dividend divided by book value) and Bankruptcy Score (Z-score) [23]. 
preprocessed the MPQA corpus for making sure that they could 
be parsed by the syntactic parser and were consist with IOB 
format. Secondly, we used the linguistic features discussed in 
Section III to extract the feature values. Thirdly, we chose 
feature sets by different linguistic characteristics and 
transformed them into CRF data format. Finally, we trained and 
evaluated the CRF with different data sets and parameters. 
The CRF models were implemented using the MALLET 
toolkit [16]. We trained and tested the CRF models with feature 
set as previously discussed in Section II using 10325 sentences 
from the MPQA corpus, and the evaluation was performed on 
30% of the holdout test data. The training iteration was 500 and 
the Gaussian variance was 10 with first-order CRF used. The 
model was evaluated with respect to token accuracy (a), 
precision (p), recall (r) and ࡲ૚ measure. The correct prediction 
of opinion labeling was defined as an exact match between the 
CRF predicted label and the MPQA annotated label of specific 
phrase sequentially. The definition of precision (p), recall (r) 
and ࡲ૚ measure is as fallowing,  
p= the proportion of opinion labels predicted by the model is 
correct. 
r= the proportion of correct opinion labels is predicted by the 
model. 
ࡲ૚ ൌ ૚ࢻ ቀ૚࢖ቁାሺ૚ିࢻሻ ቀ૚࢘ቁ
                                                                    (7) 
While ߙ is the weight that controls the contribution percentage 
of precision and recall ( ߙ = 0.5). Another loose performance 
metrics is token accuracy (a) which compares whether the 
predicted label and annotated label of a single token are the 
same at token-level without considering the other tokens. 
B. Experimental results 
The feature set selection was applied to train and test the 
CRF models (Table 3). Since there may be more than one 
predicate in a sentence and some of the feature values related to 
different predicates may be different, we expanded one instance 
(i.e., one sentence data record) of the data (Panel A) into many 
instances with different feature values when there were more 
than one predicate in a sentence (Panel B).  
We can observe from the feature set B (only orthographical 
features) that has the lowest token accuracy, and that there is a 
significant decrease in the recall about 6% in feature set H 
(orthographical feature added) when compared with feature set 
G. On the other hand, what orthographical feature can capture 
could be rendered by NER features and POS of token. Hence, 
all the other feature sets are excluded the orthographical features 
with the exception of set B and H. Although recall of J (phrase 
type) is unfavorable among the feature sets, its relatively higher 
precision is the reason why it is reserved for use in the following 
trials. The feature set K (head feature) has the lowest ࡲ૚ 
measure among all single feature sets which comprise tokens 
(f1) plus single feature in Panel A; besides, feature set S, which 
has excluded the head feature, enhanced the recall promisingly, 
but was also accompanied by a drop in precision; accordingly, 
the head is not a good indicator for detection of the phrase 
boundary; to use the head feature would allow the model to be 
conservative in predicting but would resulting in the lower recall 
when head feature included, so releasing the head feature (set S) 
makes the recall soar up. 
In summary, we can conclude that feature sets with lemma, 
orthography, POS, phrase type and head are relatively inferior to 
feature sets with NER, syntactic dependency and based chunk 
by observing the ࡲ૚ measures among feature set A, B, C, F, J 
and K when the features consist of f1 plus another feature. By 
comparing the performance among feature set G, H and I, the 
inclusion of feature f14 is better than inclusion of orthographical 
features under the condition that there is no predicate-argument 
structure situation. The ࡲ૚ measure of full feature set (V) is not 
significantly different from sets R, Q and T, but is explicitly 
higher than P, S and U; we can thus draw the conclusion that the 
exclusion of feature in NER and path from the full set would not 
affect the performance of the system but that the exclusion of 
the feature in head would. 
In summary, we can conclude that feature sets with lemma, 
orthography, POS, phrase type and head are relatively inferior to 
feature sets with NER, syntactic dependency and based chunk 
by observing the ࡲ૚ measures among feature set A, B, C, F, J 
and K when the features consist of f1 plus another feature. By 
comparing the performance among feature set G, H and I, the 
inclusion of feature f14 is better than inclusion of orthographical 
features under the condition that there is no predicate-argument 
structure situation. The ࡲ૚ measure of full feature set (V) is not 
significantly different from sets R, Q and T, but is explicitly 
higher than P, S and U; we can thus draw the conclusion that the 
exclusion of feature in NER and path from the full set would not 
affect the performance of the system but that the exclusion of 
the feature in head would. 
VI. EMPIRICAL STUDY OF EARNINGS AND SUBJECTIVE MWES 
A. Extraction of opinion patterns from financial statements 
The main purpose of this section is automatically extracting 
the opinion holders and the subjective expressions in the 
financial statements by CRF models trained by the MPQA. We 
preprocessed the filings to extract footnote section and to 
remove redundant information: first, we removed the HTML 
tags, pictures, tables, front and sending matters and exhibitions 
and retained the useful item sections; next, we dropped the 
lines containing too many white spaces, symbols, numbers or 
non-meaning words (e.g., fragments left after elimination) by 
Table 3 Results of “agent” identification crossing feature sets
Feature set a p r ࡲ૚
Panel A no predicate-argument structure feature set
A f1+f2(lemma) 67.64 56.6 29.48 38.77
B f1+f3~f5(orthographical) 63.76 53.49 22.49 31.67
C f1+POS 64.03 66.42 16.85 26.88
D f1+POS+f16(NER) 71.92 58.66 39.69 47.35
E f1+POS+f15(dependency, dep.) 71.22 62.71 42.36 50.57
F f1+f13(based chunk) 71.16 57.05 41.83 48.27
G f1+f2+POS+f13+f15~f17 66.01 66.67 25.35 36.74
H f1~f5+POS+f13+f15~f17 65.77 69.77 19.22 30.14
I f1+f2+POS+f13+f14~f17 65.79 69.09 27.92 39.77
J f1+f11(phrase type) 70.89 69.36 17.32 27.72
K f1+f10(head) 70.67 27.07 4.27 7.37
L f1+f11+f12(phrase type and head) 70.64 65.09 16.99 26.94
Panel B expanded sentences by multiple predicates
M f1+f12(only path) 71.14 62.52 15.07 24.29
N f1+f10+f12(path and head) 71.04 60.05 16.59 26
O f1+f10+f11(phrase type and path) 71.02 68.92 21.14 32.36
P f1,f2,f6~f19(dep. excluded) 70.71 64.01 50.6 56.52
Q f1,f2,f6~f19(NER excluded) 70.88 69.91 35.91 47.45
R f1,f2,f6~f19(path excluded) 71.23 68.62 35.73 46.99
S f1,f2,f6~f19(head excluded) 71.04 64.69 48.25 55.27
T f1,f2,f10~f17(predicate excluded) 71.04 69.4 38.02 49.12
U f1,f2,f6~f19(path, dep. excluded) 70.64 67.9 32.15 43.63
V f1,f2,f6~f19(full) 70.93 69.96 36.45 47.93
W f1,f2,f6~f19(no “target” label) 76.97 70.84 38.28 49.7
controls the range of the no change SUE, more positive MWEs 
(e.g., the strongly positive MWE “can successfully”) became 
insignificant when the threshold g went up from 0.5 to 1. The 
possible Accounting explanation is that the information 
disclosures in the financial statements shall obey the 
“conservatism principle” whereby the company will not 
disclose too much positive information until the good news is 
certain but do its best to leak the negative information 
immediately when the bad news may possibly happen. (3) The 
significance of the control variables exclusive of “Bankruptcy 
z-score” remain the same. The reason why the coefficients of 
“Bankruptcy z-score” became insignificant while the threshold 
g went up from 0.5 to 1 is that the increase in the threshold 
makes it impossible to correlate the positive SUE with the 
bankruptcy, which is a reasonable finding. (4) Instead of 
diminishing the pseudo Rଶ of the linear regression when g went 
up from 0.5 to 1, the increasing number of insignificant 
coefficients multiplied the pseudo Rଶ  from 0.0387 to 0.0612. 
This result illustrates the “curse of dimensionality” where the 
presence of too many explanatory variables, which might arise 
from the presence of too many irrelevant explanatory variables 
or from the problem of collinearity in that the variable inter-
dependency occurs between explanatory variables, may reduce 
the fitness or performance of the model. (5) Although not every 
MEW’s coefficient significance ranks R(c) in the small dataset 
is the same as in the large dataset, the relative ordinal relation 
between coefficients still exists. (6) The auditor’s strongly 
negative opinion “doubt about ability to continue as a going 
concern” became more significant when g went up from 0.5 to 
1. It is a reasonable interpretation that an auditor would only 
state a strongly negative opinion only when the financial status 
of a company was clearly dire. 
D. Analysis of the economic meaning of subjective MWEs 
In Table 8, we inferred the economic meaning of the MWEs 
by comparing different aspects which included comparing (1) 
the company’s opinions (self-opinions) and the auditor’s 
opinions (opinions of the third party), (2) the various orders of 
R(c) given the same polarity of expressions and c, and (3) how 
R(c) explains the strength of negative subjective MWEs 
decreases while SUE is negative (c = -1), respectively. 
Furthermore, we were able to find the observations that the 
literal meaning of the subjective MWEs are not really reflected 
the true financial status of the companies in some cases. 
Given a scenario of positive SUE (c = 1), the company 
would be more likely to use strongly positive MWEs than to 
use weakly positive MWEs, e.g., including the word “assured” 
with the meaning of assurance and its R(c) is 2nd where the 
economic meaning is that the company tends to use strongly 
positive subjective statements when the financial status of the 
company is excellent. In the similar view point that the 
auditor’s positive MWE is a relatively higher R(c), so the 
auditor tends to state the positive opinions. 
However, the story is totally different when the SUE (c = -1) 
is negative. If the financial status of the company is obviously 
negative, the company used weaker negative MWEs with the 
uncertain words “could” and “adversely” to describe adverse 
events so as to try to weaken the impact on the company of 
reporting the weak financial status by inferring from the 2nd 
order of R(c). On the other hand, the stronger negative adverb 
“materially” decline the strength of R(c) from 2nd to 3rd, which 
is an indirect indicator that leads to a decay in the correlation 
between strongly negative MWEs and negative SUE (c = -1). 
In an extreme situation, the use of the strongest negative MWE 
“seriously harmed” would make the relationship between the 
negative MEW and the negative SUE (c = -1) insignificant; the 
reason why R(c) declined was resulted from the condition that 
the management would seek to avoid making a declaration of 
its negative financial status by using too strongly negative 
MWEs. Again, the relatively weaker R(c) of the auditor’s 
negative opinion when compared with the R(c) of the auditor’s 
positive opinion is not just a coincidence. Since varying to 
conservative thresholds would increase the significance of 
R(c), we can conclude that the auditor would give a negative 
opinion only if the recession is very obviously reflected in the 
earnings. 
Moreover, certain literal meaning of the MWEs does not 
matching with the financial status of the company instinctively, 
the inference to be made about the use of such kind of MWEs 
are that one should be aware of the problem of possible 
spurious correlations and missing latent variables, i.e., such as 
that the strongly positively MWE “will be successful” is 
positively correlated with the negative SUE (c = -1) and that 
the obviously negative MWE “may be uncollectible” is 
positively correlated with the positive SUE (c = 1). The 
phenomena are explained as (a) the MWE “will be successful” 
is a promise about future performance that also implies that the 
financial status might be worse now. (b) That the MWE “may 
be uncollectible” is negative without a doubt, but there is a 
latent variable “Earnings management”, which the company 
manipulates the earnings by selling the sale with too much 
account receivables that will make it “uncollectable” in the 
future [22]. We can conclude that the missing of an important 
latent variable could cause a spurious correlation happening. 
VII. DISCUSSIONS AND CONCLUSIONS 
Our convincing empirical results have pioneered to indicate 
that the managements of the companies incline to hide certain 
negative information and to highlight positive information, and 
that the managements might use different strengths of 
Table 7  Robustness test with g=1 
Number of observation : 22780, Pseudo Rଶ= 0.0612 
Explanatory variables    c = -1 c = 1 R(c)
Significant coefficients of the MWEf-idf  variables
reasonably assured (v120) -.34146 
(0.512) 
1.181172
(0.007) 
2nd 
did not contain an adverse opinion or 
disclaimer of opinion (v49) 
1.758158 
(0.640) 
7.388588
(0.017) 
2nd 
could adversely affect our business (v23) 1.286628 
(0.038) 
.0006553
(0.999)
2nd 
could be materially adversely affected
(v33) 
-1.649413 
(0.004) 
.0669491
(0.898) 
3rd
may adversely impact our business (v77) -7.300539 
(0.037) 
-2.962487
(0.276) 
3rd 
doubt about ability to continue as a going 
concern (v51) 
-.3814305 
(0.942) 
-94.4483
(0.000) 
3rd 
will be successful (v157) 1.139275 
(0.008) 
.1799093
(0.687)
2nd 
may be uncollectible (v90) 6.30679 
(0.163) 
15.48972
(0.002) 
2nd 
Insignificant coefficients of the MWEf-idf  variables
can successfully (v13) 1.17039 
(0.360) 
2.11568
(0.096) 
5th
may be successful (v88) -4.867306 
(0.316) 
-4.318219
(0.334)
5th
seriously harmed (v122) .823166 
(0.153) 
1.086291
(0.059) 
5th 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
 
 
 
一、參加會議心得 
 
十二月十四日： 
 
上午一天清早六點趕到桃園機場報到後，搭乘 7:40 的長榮飛機離開台灣，一共飛了約四個小時，於
12:10 抵達新加坡，由於新加坡地鐵發達，於是買了一張 ez-card，類似台北悠遊卡，搭乘地鐵到飯
店安頓行李，到處熟新加坡。 
 
新加坡的地鐵相當發達，遍布整個新加坡，且轉運中心也建置完善，讓人一目瞭然，不會迷路。且
新加坡環境與台灣相似，語言也通英文、中文和台語都可以通。 
 
十二月十六日： 
 
一大早從飯店出發，走路到最近的地鐵站武吉市搭乘，約搭乘了 45 分鐘後，到文禮站轉巴士到南
洋理工大學到達會場。 
 
第一天，來參加會議的人其實不是很多，但是在開會的現場，大家都很踴躍發問討論，會議氣氛不
錯。這次共有 125 篇論文投稿到大會，正式論文共錄取 50 篇約 40%，海報論文為 25 篇約 20%。 
 
計畫編號 NSC-99-2221-E-004-007 
計畫名稱 整合及開發人工智慧與語言科技以輔助語文教學活動 
出國人員
姓名 蔡家琦 
服務機構
及職稱 國立政治大學資訊科學系兼任研究助理 
會議時間 100 年 12 月 16 日至 100 年 12 月 18 日 會議地點 南洋理工大學,新加坡 
會議名稱 
(中文) 
(英文) 25th Pacific Asia Conference on Language, Information and Computation 
 
發表論文
題目 
(中文) 
(英文) Translating Common English and Chinese Verb-Noun Pairs in Technical 
Documents with Collocational and Bilingual Information 
 
在海報論文的旁邊如果可以有一個螢幕讓報告者展示成果，可以有助於增進報告者與聽眾間的互動。 
 
四、攜品資料名稱及內容 
 
會議論文隨身碟 
 
五、其它 
Spring Cleaning and Grammar Compression: Two Techniques for Detection o
Grammars 
Antske Fokkens, Yi Zhang and Emily M. Bender
Automatic identification of words with novel but infrequent senses 
Paul Cook and Graeme Hirst
Automatic Error Analysis Based on Grammatical Questions 
Tomoki Nagase, Hajime Tsukada, Katsunori Kotani, Nobutoshi Hatanaka and 
Named Entity Disambiguation in Sentence 
Doba Vincent and Zhu Xiaoyan
A Listwise Approach to Coreference Resolution in Multiple Languages 
Oanh Thi Tran, Bach Xuan Ngo, Minh Le Nguyen and Akira Shimazu
Building and Annotating the Linguistically Diverse NTU-MC (NTU-Multilingual 
Liling Tan and Francis Bond
Combining Dependency and Constituent-based Syntactic Information for Ana
in Coreference Resolution 
Fang Kong and Guodong Zhou
A Hybrid Extraction Model for Chinese Noun/Verb Synonymous bi-gram Collo
Wanyin Li and Qin Lu
The L1 Acquisition of the Imperfective Aspect markers in Korean: a Comparis
Ju-Yeon Ryu
Improving Chinese Event Construction Extraction With Lexical Relation Pairs 
Liou Chen, Qiang Zhou and Hongxian Wang
A Graph-based Bilingual Corpus Selection Approach for SMT 
WenHan Chao
The Effect of Answer Patterns for Supervised Named Entity Recognition in Th
Nutcha Tirasaroj and Wirote Aroonmanakun
Verbal Inflection in Hindi: A Distributed Morphology Approach 
Smriti Singh and Vaijayanthi M Sarma
Word classes in Indonesian: A linguistic reality or a convenient fallacy in natu
Meladel Mistica, Timothy Baldwin and I Wayan Arka
Maximum Entropy Based Lexical Reordering Model for Hierarchical Phrase-ba
Zhongguang Zheng, Yao Meng and Yu Hao
Predicting Part-of-Speech Tags and Morpho-Syntactic Relations using Similar
Samuel Chan
Word-order and argument-marking: Japanese vs Chinese vs Naxi 
Paul Law
Logical Information Processing of Possibility and Negation: Cases from Taiwa
Chiou-shing Yeh and Huei-ling Lai
Quantification and the Garden Path Effect Reduction: The Case of Universally
Akira Ohtani
Context Resolution of Verb Particle Constructions for English to Hindi Translat
Niladri Chatterjee and Renu Balyan
Plural Problems in the Nominal Morphology of Marathi 
Shalmalee Pitale
Dependency-based Analysis for Tagalog Sentences 
Erlyn Manguilimotan and Yuji Matsumoto
A Study of Sense-Disambiguated Networks Induced from Folksonomies 
Hans-Peter Zorn and Iryna Gurevych
Translating English Names to Arabic Using Phonotactic Rules 
Faisal Alshuwaier and Ali Areshey
The Co-occurrence of Two Delimiters: An Investigation of Mandarin Chinese R
Jingxia Lin and Chu-Ren Huang
Exploring Emotional Words for Chinese Document Chief Emotion Analysis 
Yunong Wu, Kenji Kita, Fuji Ren, Kazuyuki Matsumoto and Xin Kang
A Simple Surface Realizer for Filipino 
Ethel Ong, Stephanie Abella, Lawrence Santos and Dennis Tiu
The Order of Mandarin Chinese Motion Morphemes and the “Scalar Specificity
Jingxia Lin
Derived Head-Final Compound Event Nouns in Mandarin Chinese 
Shan Wang and Chu-Ren Huang
NERSIL - the Named-Entity Recognition System for Iban Language 
Yong Soo Fong, Bali Ranaivo-Malanco and Alvin Yeo Wee
Translating Non-Technical English and Chinese Verb-Noun Pairs in Technical 
Collocational and Bilingual Information 
Yi-Hsuan Chuang, Chao-Lin Liu and Jing-Shin Chang
Supervised and Semi-supervised Methods based Organization Name Disambi
Shu Zhang and Hao Yu
Improving PP Attachment Disambiguation in a Rule-based Parser 
Yoon-Hyung Roh, Ki-Young Lee and Young-Gil Kim
Verbs and (sub)Event Structure: A Case Study from Italian 
Francesca Strik Lievers
Progressive Aspect in English State and Achievement Verbs 
Heng-Ming Carlos Kang
An English-Chinese Cross-lingual Word Semantic Similarity Measure Exploring
Lin Dai And Heyan Huang
Learning-to-Translate Based on the S-SSTC Annotation Schema 
Enya Kong Tang, Zaharin Yusoff and Christian Boitet
 
© 2006  Nanyang Technological University 
Last modified on 28-Sep-2009
Copyrigh
and compared the translation quality achieved by using different combinations of contextual and 
bilingual information. 
Figure 1 shows how the VN pairs were extracted from the 1 million parallel sentences, which 
we obtained from the NTCIR 9 PatentMT task in 20111. The process started from the left of the 
figure. Most of the original sentences were very long. A sentence has 34 words on average, and 
the longest sentence has 141 words. Since our goal was to extract VN pairs from the corpus, not 
doing a full-scale research in machine translation, we choose to segment the sentences into 
shorter parts at commas and periods. Normally, VN pairs will not cross the punctuations, and, 
even if some VN pairs did, we afforded to neglect them because we had 1 million pairs of long 
sentences.  
We then re-aligned the short English and Chinese segments with a sentence aligner (Tien et 
al., 2009) that we implemented based on the concept of Champollion (Ma, 2006). We treated 
the original long sentence pairs as aligned paragraphs, and ran our aligner on the sentences. Like 
the Champollion, we computed probabilistic scores for the sentence pairs, so we could choose 
those pairs with higher scores to achieve higher confidence on the aligned pairs. More specifi-
cally, we kept only the leading 33% of the short sentence pairs, and obtained 1148632 short sen-
tence pairs.  
We employed the Stanford Chinese segmenter2 to segment the Chinese text. This segmenter 
allows us to mark the technical terms so that the segmenter will treat the words belonging to 
technical terms as a unit, preventing them from being segmented again. In addition, currently, 
our technical terms are nouns, so they are annotated accordingly. When there were more than 
one possible ways to mark the technical terms in a string, we preferred the longer choices. Eng-
lish texts were tokenized by the Stanford parser3. Technical phrases and compound words in 
English were also marked and would not be treated as individual words either. The special terms 
came from the glossary that will be explained in Section  4.1. 
Based on these short sentence pairs, we aligned VN pairs with the method to be explained in 
Section  3. This process employed an English-Chinese glossary for technical terms, which we 
will discuss in Section  4.1, and a bilingual dictionary enhanced with Chinese near synonyms, 
which we will discuss in Section  4.2. In the end, we accepted 35811 VN pairs for experiments at 
the second stage. 
During the second stage of our work, we split the VN pairs into training and test data. Useful 
statistics were collected from the training data, and were applied to select Chinese translations 
for the English words in question. 
3 VN Pair Alignment 
We employed the Stanford parsers (SPs, henceforth) for English and Chinese to compute the 
dependency trees for the parallel texts. We extracted the dobj relations from the trees and align 
the VN pairs. 
                                                          
1 http://ntcir.nii.ac.jp/PatentMT/ 
2 http://nlp.stanford.edu/software/segmenter.shtml, version 1.5 
3 http://nlp.stanford.edu/software/lex-parser.shtml, version 1.6.5 
35811
VN pairs1M NTCIR
English
sentences
1M NTCIR
Chinese
sentences
1.15M short
Chinese
 sentences
1.15M short
English
sentences
1.15M  Chin.
dependency
trees
1.15M  Eng.
dependency
trees
Separate sentences
into segments and
align the segments
Separate sentences
into segments and
align the segments
Lexicon: English
technical terms
Lexicon: Chinese
technical terms
Stanford parser
(englishPCFG)
Near
synonym
dictionary
Eng.-Chin.
dictionaries
VN aligner
Stanford Parser
(chineseFactored)
Stanford Chinese
segmenter (chirs6)
Mark
technical terms
Mark
technical terms
Figure 1: The flow for extracting VN pairs from the original corpora 
494
We downloaded 138 different kinds of domain technical term pairs from Taiwan National 
Academy for Educational Research4. The files were stored in excel format, and the total file size 
is 177MB. 
The format of English-Chinese technical term pairs is not always in one-to-one relationship; 
some English technical terms have more than one translation in Chinese. We converted such 
pairs into multiple one-to-one pairs, and acquired 804068 English-Chinese technical term one-
to-one pairs. 
To validate the reliability of the glossary, we conducted a small experiment; that is, to seg-
ment patent sentences with the glossary. The results showed that the coverage of these “technic-
al term” pairs was too broad, and almost all of words were considered as technical terms.  
We alleviated this problem with E-HowNet5 (Chen et al., 2005) and WordNet6. Treating the 
words listed in E-HowNet and WordNet as ordinary words, we used them to identify normal 
words in our technical term pairs. If the original pairs contained any normal Chinese or English 
words, then the pairs would be removed.  
 As a result, we removed 14% of the original pairs, and kept 690640 technical term pairs. 
4.2 The English-Chinese Dictionary and Near Synonyms 
As announced in Section  3.2, we built a bilingual dictionary and enhanced it with information 
about near synonyms to improve the recall rates of the VN pair alignment.  
A good English-Chinese dictionary is the basis for the task of VN pair alignment. We col-
lected and combined the Chinese translations of English words in the Concise Oxford English 
Dictionary and the Dr.eye online dictionary7, and acquired 99805 pairs of English words and 
their translations.  
As we explained in Section  3.2, the Chinese translations listed in the dictionaries might not 
be complete, so we enhanced the merged dictionary with information about near synonyms. We 
employed two sources of relevant information to obtain near synonyms in this study. 
The Web-based service of Word-Focused Extensive Reading System8  (Cheng, 2004) is 
maintained by the Institute of Linguistics of the Academia Sinica in Taiwan. The service allows 
us to submit queries for the near synonyms of Chinese words for free, so we collected the near 
synonyms from the web site.  
Given an entry in our bilingual dictionary, we queried the near synonyms for each of the 
Chinese translations of an English word, and added the results to the Chinese translations of the 
English word. 
 E-HowNet is another source that we could compute and obtain near synonyms. E-HowNet 
is a lexicon for Chinese. The lexicon contains two levels of detailed semantic information for 
words: TopLevelDefinition and BottomLevelExpansion. The semantic definitions provided in 
these two entries come from the E-HowNet Ontology9, and can be used to compute similarity 
scores between word senses. 
We determine whether two Chinese words are near synonyms with the following procedure. 
Given a Chinese word, CW, we looked up the E-HowNet for its senses. Let Si(CW) be one of 
CW’s senses. We combined the semantic definitions listed in the TopLevelDefinition and Bot-
tomLevelExpansion of Si(CW), which might include multiple words. Denote this set by Ui(CW), 
and let CWWij be a word in Ui(CW). We looked up the E-HowNet for the senses of CWWij. Let 
Sk(CWWij) denote one of the senses of the CWWij, and Vijk(CWWij) denote the combined se-
mantic definitions listed in the TopLevelDefinition and BottomLevelExpansion of Sk(CWWij). 
Finally, we computed the union of Ui(CW) and Vijk(CWWij) as a sense vector of CW. Note that 
                                                          
4 http://terms.nict.gov.tw/ 
5 http://ckip.iis.sinica.edu.tw/taxonomy/taxonomy-edoc.htm 
6 http://wordnet.princeton.edu/ 
7 http://www.dreye.com/index_en.html 
8 http://elearning.ling.sinica.edu.tw/c_help.html 
9 http://ckip.iis.sinica.edu.tw/taxonomy/taxonomy-edoc.htm  
496
tional probabilities to determine the Chinese trans-
lation of English words. 
Table 3 lists four possible ways to choose a 
Chinese translation for an English verb in a VN 
pair. Equation (1) is the most simplistic. Let EV 
denote a specific English verb, and CVi be one of 
EV’s translations observed in the training data. 
Given the English verb, the equation chooses the 
CVi that maximizes the conditional probability. Namely, it prefers the most frequent Chinese 
translation of EV in the training data.  
We could obtain the conditional probability Prሺܥ ௜ܸ|ܧܸሻ by dividing the frequency of ob-
serving the VN pair (EV, CVi) in the training data by the frequency of observing EV in any VN 
pairs. Using the data for “add” that we mentioned in Section  5.1 for example, we observed 135 
occurrences of “add”. Therefore, Pr(“增加” | “add”) = 48/135=0.356 and Pr(“加上” | “add”) = 
2/135=0.015. 
Let EN be a specific English noun, Equation (2) considers the object of the verb when choos-
ing the verb’s translation. Let C(•) denote the frequency of a given event.  The conditional 
probability in Equation (2) is defined below. 
),(
),,(
ENEVC
CVENEVC i      (5) 
The remaining equations, (3) and (4), take an extreme assumption. We assumed the availa-
bility of the Chinese translation of the English object at the time of translation, and used this 
special information in different ways. Equation (3) considers the words EV, EN, and CN. In a 
strong contrast, Equation (4) considers only EV and CN to determine the translation of the Eng-
lish verb. The conditional probabilities in Equations (3) and (4) were calculated using Equation 
(6) and (7), respectively. 
),,(
),,,(
CNENEVC
CNCVENEVC i         (6) 
),(
),,(
CNEVC
CVCNEVC i                 (7) 
We considered the exploration of using the information about the Chinese translation of the 
English noun is interesting. Would the information about CN provide more information, given 
we had information about EV and EN? How would we achieve when we had information about 
only EV and CN but not EN? 
In all of the experiments, we used 80% of the available aligned VN pairs as the training data, 
and the remaining 20% as test data. The training data were randomly sampled from the available 
data.  
As a consequence, it was possible for us to encounter the zero probability problems. Take 
Equation (6) for example. If, for a test case, we needed C(EV, EN, CN) in (6), but we happened 
not to have observed any instances of (EV, EN, CN) in the aligned VN pairs in the training data, 
then we would not be able to compute (6) for the test case. When such cases occurred, we chose 
to allow our system to admit that it was not able to recommend a translation, rather than resort-
ing to the smoothing technologies. 
6 Experimental Results 
Using the formula in Table 3 would allow our systems to recommend only one Chinese transla-
tion. In fact, we relax this unnecessary constraint by allowing our systems to consider that larg-
est k conditional probabilities and to recommend k translations. 
Although we have been presenting this paper with the 1 million parallel sentences in NTCIR 
PatentMT data as the example, we have run our experiments with the English-Chinese bilingual 
Table 3: Translation decisions 
)|Pr(maxarg EVCViCVi  (1)
),|Pr(maxarg ENEVCViCVi  (2)
),,|Pr(maxarg CNENEVCViCVi  (3)
),|Pr(maxarg CNEVCViCVi  (4)
498
Using Eq1 is sufficiently robust in that the 
conditional probabilities would not be zero, 
unless the training data did not contain any 
instances that included the English verb. 
Hence, in our experiments, the rejection rates 
for “Eq2+Eq1”, “Eq3+Eq1”, and “Eq4+Eq1” 
became zero. In other words, our systems re-
sponded to all test cases when we used these 
combined methods by allowing all methods to 
recommend up to k candidates. 
We compare the performance of these 
combined methods with the best performing 
methods in Tables 7 and 8. We copy the inclu-
sion rates of Eq1 from Table 4 to Table 7 to 
facilitate the comparison, because Eq1 was the 
best performer, on average, in Table 4. The combined methods improved the inclusion rates, 
although the improvement was marginal.  
Moreover, we copy the average ranks for Eq1 and Eq3 from Table 6 to Table 8. Using Eq1 
and using Eq3 led to the worst and the best average ranks in Table 6, respectively. Again, using 
the combined methods, we improve the average ranks marginally over the results of using Eq1. 
Statistics in Table 7 suggest that using machine-assisted approach to translating verbs in 
common VN pairs in the PatentMT data is feasible. Providing the top five candidates to a hu-
man translator to choice will allow the translator to find the recorded answer s nearly 98% of the 
time.  
It is interesting to find that using Equation (2) and Equation (4) did not lead to significantly 
different results in Tables (4) through (8). The results suggest that using either the English 
nouns or the Chinese nouns as a condition contributed similarly to the translation quality of the 
English verbs. More specifically, the translation of the English verb may be conditionally inde-
pendent of the information about the noun’s Chinese translation given the English verb and the 
English noun. This does not imply that the translation of the English verb is unconditionally 
independent of the information of the English noun’s translation. That Eq4 performed better 
than Eq1 in Table 6 offered a reasonable support. 
6.3 Results for the Most Challenging 22 Verbs in Patent Documents 
We repeated the experiments that we con-
ducted for the top 100 verbs for the most chal-
lenging 22 verbs (cf. Section  5.1). Tables 9 
through 13 correspond to Tables 4 through 8, 
respectively. The most noticeable difference 
between Table 9 and Table 4 is the reduction 
of the inclusion rates achieved by Eq1 when 
k=1. Although the inclusion rates reduced no-
ticeably when we used Eq2, Eq3, and Eq4 as 
well, the drop in the inclusion rate for Eq1 
(when k=1) was the most significant.  
Although we did not define the challenging 
index of verbs based on their numbers of poss-
ible translations, comparing the corresponding 
numbers in Table 10 and Table 5 suggest that 
the challenging verbs also have more possible 
translations in the NTCIR data. 
Corresponding numbers in Table 11 and 
Table 9: Inclusion rates for 22 challenging verbs 
inclusion k=1 k=3 k=5 
Eq1 0.449 0.865 0.923 
Eq2 0.561 0.818 0.820 
Eq3 0.564 0.827 0.829 
Eq4 0.550 0.827 0.829 
Table 10: Average number of recommendations 
recommend k=1 k=3 k=5 
Eq1 1.000 2.977 4.756 
Eq2 1.000 2.090 2.364 
Eq3 1.000 2.022 2.230 
Eq4 1.000 2.106 2.411 
Table 11: Average ranks of the answers 
ranking k=1 k=3 k=5 
Eq1 1.000 1.607 1.773 
Eq2 1.000 1.365 1.373 
Eq3 1.000 1.374 1.383 
Eq4 1.000 1.394 1.400 
Table 8: Average ranks of the correct answers 
(combined methods) 
ranking k=1 k=3 k=5 
Eq1 1.000 1.241 1.310 
Eq3 1.000 1.151 1.168 
Eq2+Eq1 1.000 1.240 1.301 
Eq3+Eq1 1.000 1.234 1.294 
Eq4+Eq1 1.000 1.233 1.296 
Table 7: Inclusion rates (combined methods) 
inclusion k=1 k=3 k=5 
Eq1 0.768 0.953 0.975 
Eq2+Eq1 0.772 0.960 0.979 
Eq3+Eq1 0.778 0.960 0.979 
Eq4+Eq1 0.776 0.959 0.978 
500
Additional and analogous experiments were conducted with the PatentMT data. In these new 
experiments, we aimed at the translations of the nouns in the English VN pairs, given different 
combinations of the bilingual and contextual information. Again, we observed that, after putting 
the English verb and English noun in the conditions in the attachment decision formulas (ana-
logous to but slightly different with those in Table 3), the Chinese translations of the English 
verbs did not offer extra help. In addition, using  (1) the English verb and the English noun or (2) 
the Chinese verb and the English noun achieved similar experimental results.  
Acknowledgments 
The work was supported in part by the funding from the National Science Council in Taiwan 
under the contracts NSC-99-2221-E-004-007 and NSC-100-2221-E-004-014. The authors are 
obliged to the anonymous reviewers for their valuable comments because we could not respond 
satisfactorily to all comments due to the page limits on this paper. 
References  
Bundanitsky, A. and G. Hirst. 2006. Evaluating WordNet-based measures of lexical semantic relatedness. 
Computational Linguistics, 32(1):14–47. 
Carpuat, M., P. Fung and G. Ngai. 2006. Aligning word senses using bilingual corpora. ACM Trans. on 
Asian Language Information Processing, 5(2):89–120. 
Chang, J.-S. and S.-J. Chiou. 2010. An EM algorithm for context-based searching and disambiguation 
with application to synonym term alignment. Proc. of the 23rd Pacific Asia Conf. on Language, In-
formation and Computation, 2:630–637. 
Chang, Y. C., J. S. Chang, H. J. Chen and H. C. Liou. 2008. An automatic collocation writing assistant for 
Taiwanese EFL learners: A case of corpus-based NLP technology. Computer Assisted Language 
Learning, 21(3):283–299. 
Cheng, C. C. 2004. Word-focused extensive reading with guidance. Selected Papers from the 13th Inter-
national Symposium and Book Fair on English Teaching, 24-32. 
http://elearning.ling.sinica.edu.tw/WordFocused%20Extensive%20Reading%20with%20Guidance.pdf  
Chuang, T. C., J.-Y. Jian, Y.-C. Chang and J. S. Chang. 2005. Collocational translation memory extraction 
based on statistical and linguistic information. Int’l J. of Computational Linguistics and Chinese Lan-
guage Processing, 10(3):329–346. 
Chen, A., H. Jiang and F. Gey. 2000. Combining multiple sources for short query translation in Chinese-
English cross-language information retrieval. Proc. of the 5th Int’l Workshop on Information Retrieval 
with Asian Languages, 17–23. 
Chen, K.-J., S.-L. Huang, Y.-Y. Shih and Y.-J. Chen. 2005. Extended-HowNet: A representational frame-
work for concepts. Proc. of the 2005 IJCNLP Workshop on Ontologies and Lexical Resources, 1–6. 
Dorr, B. J., G.-A. Levow and D. Lin. 2002. Construction of a Chinese-English verb lexicon for machine 
translation and embedded multilingual applications. Machine Translation, 17:99–137. 
Koehn, P., F. J. Och and D. Marcu. 2003. Statistical phrase-based translation. Proc. of the 2003 Conf. of 
the North American Chapter of the Association for Computational Linguistics on Human Language 
Technology, 48-54.  
Lapata, M. and C. Brew. 2004. Verb class disambiguation using informative priors. Computational Lin-
guistics, 30(1):45–73.  
Lu, B., B. K. Tsou, T. Jiang, O. Y. Kwong and J. Zhu. 2010. Mining large-scale parallel corpora from mul-
tilingual patents: An English-Chinese example and its application to SMT. Proc. of the 1st CIPS-
SIGHAN Joint Conf. on Chinese Language Processing. 
Ma, X. 2006. Champollion: A robust parallel text sentence aligner. Proc. of the 5th Int’l Conf. of the Lan-
guage Resources and Evaluation, 489–492. 
Seneff, S., C. Wang and J. Lee. 2006. Combining linguistic and statistical methods for bi-directional Eng-
lish Chinese translation in the flight domain. Proc. of the 7th Conf. of the Association for Machine 
Translation in the Americas, 213–222. 
Tien, K.-W., Y.-H. Tseng and C.-L. Liu. 2009. Sentence alignment of English and Chinese patent docu-
ments, Proc. of the 21st Conf. on Computational Linguistics and Speech Processing, 85–99. 
Yokoama, S. and M. Okuyama. 2009. Translation disambiguation of patent sentences using case frames. 
Proc. of the 3rd Workshop on Patent Translation, in Machine Translation Summit XII, 33–36. 
502
99 年度專題研究計畫研究成果彙整表 
計畫主持人：劉昭麟 計畫編號：99-2221-E-004-007- 
計畫名稱：整合及開發人工智慧與語言科技以輔助語文教學活動 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 6 6 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100% ACM Transaction
研究報告/技術報告 0 0 100%  
研討會論文 6 6 100% 
篇 IEEE ICEBE 最佳
論文獎；TAAI 國
際議程最佳論文
入圍獎 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
