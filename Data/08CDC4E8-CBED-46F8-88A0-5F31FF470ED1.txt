調整過程中不會改變到教育的本質或是編輯者
的意圖。特別是不恰當的調整有可能引起負面的
影響，嚴重地降低它的教育品質和學習者的學習
意願。因此，我們的主要目的列舉如下 :  
(1)我們提出了一個網路應用程式(Web-Based 
Application)的內容調整工具。  
(2)透過調整樣板(Adaptation Template)的參
數，如果使用者或教材編輯者不滿意自動調整後
的結果，他們可以很容易地操作此系統並且影響
調整後的結果。 
(3)此工具允許使用者預覽調整後的內容並且
決定它是否適合在手持裝置上來閱讀。在這樣
的規劃之下，教材的編輯者同時也扮演一個監
督的角色，這樣就可以確保調整後的內容是否適
合發佈在手持裝置上進行學習。 
(4)最後，調整工具將記錄編輯者所有的修改和
調整。這些修改的參數是有價值的，並且可提供
我們進一步的研究與改進。 
 
2.相關資料與研究 
隨著行動通訊設備的普及，和這些設備逐漸
地被廣泛利用至越來越多的領域，從事教育活動
的人，也慢慢利用更多的行動通訊裝置來輔助其
教學活動。期望能藉由新技術的加入，使得教學
品質或效率能更加提升。 
早期，由於電腦的普遍性及其影音特長，不
少教學課程開始移至電腦播放。但是由於電腦互
動性較低，所以往往只能擔任輔助教學的角色。
幾年之後，手持裝置逐漸一般化。加上手持裝置
與其使用者能有較高的互動性，因此，期待利用
手持裝置的互動性及性，提高學習者學習的意願
與成效。近年，手持裝置日益普遍，功能也較以
往強大。在這樣的環境下，就發展出了遠距教學
的相關技術。希望能利用網路，使得學習者能夠
得到更即時且更有效的學習或評量環境。 
 
3.調整學習內容之模組 
我們提出的調整架構是由三個主要調整模組所
組成。第一個，原文的調整模型負責處理使用者
感到困惑或是在有限制的小螢幕上閱讀時所漏
失複雜的原文內容。明確地來說，我們的內容調
整工具將原文的內容標出摘要並且逐漸地去呈
現原文的內容。我們引用 Buyukkokten 的方法來
逐漸地呈現內容，結合關鍵字和摘要去幫助呈現
出原先的內容， 對於平均 I/O 的輸出和他們在
做試驗的工作完成時間有最大的改善，如圖 3.1
所示 
   
 
 
  
 
 
 
 
    圖 3.1  PU 在 3 個逐漸呈現正文狀態 
 
其次，當在一台手持裝置上展示它時，圖像調整
模組應考慮到調整圖像尺寸的要求。簡單來說， 
如果它太大以致於不能顯示在一台手持裝置
上，一幅圖像將會被自動縮小，如果它太小，則
會延伸變大。 最後，排版調整模組能正確地根
據不同便攜式設備的螢幕去重新配置調整元素
的排版。但是有一些與之前敘述相關的問題。是
哪些原文的內容需要做綱要？我們如何評估並
且決定是否一張照片需要縮小或是放大？然
而，在討論調整模組的細節之前，我們必須先介
紹表示單位(PU)以及螢幕單位(SU)。 
 
3.1 表示單位(PU)以及螢幕單位(su) 
  調整程序是以劃分內容到表示單位(PU)開
始。一頁的內容將被分成幾個 PU，而不是在實際
HTML 裡提出,每個表示單位(PU)都是在一個段落
周遭的長方形、列舉、表格、圖像,等等。因此，
 2
封包中出現的頻率。  
 
圖 3.2 架構一本加權重單字的字典 
 
圖3.2顯示我們從學習內容儲存裝置中所建造加
權字典的每個步驟。它從儲存裝置中抓取學習課
程並且從課程內容取出全部的單字，除非像
是＂is＂ ＂and＂那樣無用的單字等，再來，利
用計數器模組隨著單字發生的頻率來貼標籤，之
後，在每句中選出唯一的單字。一旦計數完成
了，這些單字發生的頻率如果少於課程中所選取
的臨界值則會被消除。因為它取決於課程儲存庫
的大小，所以此臨界值要求繼續調整，它將臨界
值太多且無意義的價值作轉換。反之，除去的少
用單字是有可能成為關鍵字。剩下的單字經過一
個拼字的程式，最後，有相同的語法的單字合併
成單人的字典模式。例如適合和被適應的，將合
用在字典裡的一個應用。因此，字典的尺寸將連
續縮小。  
  當關鍵字必須從表示單位(PU)中選取出來
時，則在表示單位(PU)裡的全部單字被停止。對
每個單字來說，模組將搜尋字典去尋找在課程中
出現的單字頻率。在包含表示單位(PU)課程中搜
尋字出現的頻率會透過即時系統來掃描課程。最
後，這 些權重被用 TF/IDF 來計算。在被選擇的
門檻以外會有權重的單字被選擇。  
當一個單字不在字典裡時，一種特別的情形會出
現，因為它被我們在字典的階段丟棄或者從未在
其他學習內容過程中顯示，這是一個具體的單
字。  這樣的話是很可能比其他更稀有，而且被
歸入字典。因此這些單字在這門課程上認為是特
別的關鍵字和我們保留的任何單字一樣重要。  
  最後，注意到我們的直接選取和儲存的單字是
重要的，如果他們設法用粗體，斜體，不同的顏
色，具體的標點符號，等等來做強調。 
 
3.2.1 摘要句的選取  
我們只能挑選重要的句子來代表原文的摘要，而
不是自動尋找且標出原文摘要。 因為要是使用
者在表示單位(PU)裡看到有興趣的關鍵字可以
點擊之，點進去後即可看到摘要部份。如果一個
句子裡頭出現了不只一個關鍵字，我們便可合理
判斷此句是很重要的。  因此，選出摘要句子的
方法是基於觀察關鍵字的結果。 
 
 
圖 3.3 學習的內容適應的處理 
 
選取摘要句子的過程如圖 3.3 中所示。系統裡會
有個管理句子的功能，會挑選出何者為重要句
子，然後再傳給摘要產生器。同時，之前所選出
的關鍵字也透過摘要得知是在哪個每句子選出
並且列舉相關的關鍵字，雖然這種方法可以迅速
 4
系統根據使用者提供的參數自動地完成這個模
組所要求的調整。4.2 圖顯示出基於 html 的內
容已經正確地被在表示單位(PU)裡展示並且以
一個預設欄位給予配置。下一步，使用者能手動
刪除那些使用者確認為相對不重要內容的表示
單位(PU)。利用樣本的參數去進行調整的動作，
如圖 4.2 左邊所示。使用者可以調整參數，能手
動改變配置包括 TID 的值，表示單位(PU)的大小
和重新安排表示單位(PU)。 
 
圖 4.3 重新配置 PU 預覽圖 
 
而且，重新安排表示單位(PU)的位置如同圖 4.3 
說明，允許使用者改變表示單位(PU)呈現的配
置。例如，可能選了幾項相關的表示單位(PU)要
呈現，使用者可以把表示單位(PU)移到最上方，
使得學習者第一眼就能看見。使用者也可以任意
地決定何者為重要的表示單位(PU)和配置它直
到滿意且合適的欄位呈現。最後，我們提供一個
掌上電腦模擬器讓使用者瀏覽被改編後的內容
並且模擬在真正的掌表示單位(PU)上型電腦上
閱讀的環境(圖 4.4 顯示)。 
 
 
圖 4.4 預覽被調整學習內容的與口袋 PC 模擬器學習
內容 
 
參考文獻 
[1] R. H. Katz. Adaptation and mobility in 
wireless information systems. IEEE 
Personal Communications, 1(1):6–17, 
1994. 
[2] T. Kindberg and A. Fox. System software 
for ubiquitous computing. IEEE 
Pervasive Computing, 1(1), Jan. 2002. 
[3] Y. Chen, W.-Y. Ma, and H.-J. Zhang. 
Detecting web page structure for 
adaptive viewing on small form factor 
devices. In WWW ＇03: Proceedings of the 
12th international conference on World 
Wide Web, pages 225–233, 2003. 
[4] E. de Lara, D. S. Wallach, and W. 
Zwaenepoel. Puppeteer: Component-based 
adaptation for mobile computing. In 
Proceedings of the 3rd USENIX Symposium 
on Internet Technologies and Systems, 
Mar. 2001. 
[5] L. Ramaswamy, A. Iyengar, L. Liu, and F. 
Douglis. Automatic detection of 
fragments in dynamically generated web 
pages. In WWW ＇04: Proceedings of the 
13th international conference on World 
Wide Web, pages 443–454, 2004. 
[6] E. Kaasinen et al. Two Approaches to 
Bringing Internet Services to WAP 
Devices,＂ In Proceedings of the 9th WWW 
Conf., pages 231-246, 2000 
[7] WAP Forum. Wireless application 
protocol architecture specification, 
Apr. 1998. Available at: 
http://www.wapforum.org/what/technica
l/arch-30-apr-98.pdf. 
[8] R. Han, P. Bhagwat, R. LaMaire, T. 
Mummert, V. Perret, and J. Rubas. 
Dynamic adaptation in an image 
transcoding proxy for mobile web 
browsing. IEEE Personal Communications, 
5(6):8–17, 1998.  
[9] D. Narayanan, J. Flinn, and M. 
Satyanarayanan. Using history to 
improve mobile application adaptation. 
 6
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                             97 年 12 月 10 日 附件三
 
報告人姓名 洪啟舜 Jason C. Hung 服務機構及職稱 
僑光技術學院資訊科技系 
助理教授 
 會議時間 
     地點 
2008/12/4~2008/12/7 
越南,河內 
本會核定
補助文號
NSC 97-2221-E-240-003-  
 
會議 
名稱 
 (中文) 太平洋鄰里協會 2008 年年會暨聯合會議
 (英文) Pacific Neighborhood Consortium, Technology Enhanced 
Learning Conference 2008 (TELearn 2008) 
發表 
論文 
題目 
 (中文) 在編輯系統中學習資源的擷取 
 (英文) Learning Resources Retrieval in Authoring System
報告內容應包括下列各項： 
一、參加會議經過 
12 月 4 日會議開始，各國學者陸續來到。 
在 TELearn2008 中總共有二場 Keynote Speech:第一場是 Prof. Philip Barker, University of 
Teesside, UK，講題是 Using Technology to Enhance Human Performance；第二場則是 Prof. 
Gwo-Dong Chen, National Central University , Taiwan ，講題是 From Digital Learning 
System toward Empathetic Virtual Teachers，接著大會開始進行論文的發表，晚上是晚宴，
欣賞了越南當地的表演。 
12 月 5 日繼續參與會議的進行，在中途休息時也與不少學者交換意見，對於遠距及數位
學習的議題有更深入的討論 
12月 6日本人於上午 10點發表論文、會中有許多學者給予指教，下午 5:30更有一場 Panel 
Discussion，大家對於無所不在的學習(Ubiquitous Learning)有著熱烈的討論。 
12 月 7 日一早至機場搭機返台。 
 
二、與會心得 
在會議中與不少學者有進一步的討論，互相切磋，可說是獲益良多，大致上對於一些有
關數位學習相關的新研究主題，有不少新的看法，這對本人在教學與研究上有更多的啟
發。 
 
三、考察參觀活動(無是項活動者省略) 
 
四、建議 
建議國科會可多多補助國內學者參與此會議，相信也會有一些很好的收穫。 
 
五、攜回資料名稱及內容 
論文集光碟 
 
六、其他 
 
 
表 Y04 
retrieval of learning resources is getting more and more convenient, and instructors could get any types of 
learning resources on internet environment. However it’s hard for instructors to extract the most useful resources 
related to the course they are editing. This issue is urgent to be solved. In order to achieve the need we 
mentioned, there are two essential ways we have to get into consider. The first is the information about the 
course that instructors are editing now, and the other one is the search result from the learning object repository. 
 
 In this paper, we proposed a re-ranking mechanism for calculating the similarity between the learning 
resources retrieved from repository and the editing learning materials to assist instructors in collecting useful 
learning resources to increase the quality of the learning materials. The proposed mechanism could be regarded 
as an external service named search wrapper and could easily integrate with the existing authoring system we 
developed before. 
 
 The remainder organizations of this paper are as follows. Section 2 introduces some relative research 
issues, including some acknowledged e-learning standards and relative matching mechanism we utilized in our 
work. Section 3 illustrates our proposed system architecture and the ranking mechanism. Section 4 shows the 
implementation and the ranking result from our formula. And we’ll make a brief conclusion and the future work 
in Section 5. 
 
II. Related Works 
The current state of distance learning environment becomes more and more diverse. With the 
improvement of IT (Information Technologies), multimedia learning resources are easier to be shared over the 
world. Instructors are able to create learning contents in various kinds. With respect to the development of 
courseware authoring systems that could help generate these multimedia learning resources, many organizations 
and communities tried to standardize the disharmony of e-learning resources. The most famous one is the IEEE 
LOM specification. Lots of distance learning standard are generated based on this specification. We would like 
to introduce the metadata component of IEEE LOM first to realize the background of learning objects. In 
addition, we will also discuss the similarity formula that was widely used in the IR (Information Retrieval) 
environment. 
 
IEEE Learning Object Metadata 
IEEE LTSC (Learning Technology Standard Committee) proposed a five-level architecture to describe the 
possible information for available learning resources. For instance, in the third level, they focus on the precise 
definition of system components and the related learning content database. They also introduced the IEEE LOM 
(Learning Object Metadata) to provide a unified description of learning resources. Metadata can be considered 
as a sort of information about information. By using the IEEE LOM, the learning resources can be retrieved and 
acquired easily among the e-learning society to realize a “standardized diverse world.” The IEEE LOM (IEEE 
1484.12.1-2002 LOM v1.0) is now serving as the principal standard internationally to specify learning objects. 
Some acknowledged e-learning specifications are also based on the IEEE LOM. The IEEE LOM mainly 
comprised of 9 categories as follows: General, Life Cycle, Meta-Metadata, Technical, Education, Rights, 
Relation, Annotation and Classification, to annotate learning contents in a comprehensive perspective. Besides, 
each category has its own classification to describe the learning resources in detail; the architecture of the 
classification is shown in Figure 1. 
 
 
Figure 1. The elements of IEEE LOM 
 
Figure 3. The system architecture of our previous works. 
 In this paper, we aim at the learning materials generated based on IEEE LOM specification. When 
instructors log in the authoring system and choose the specific learning materials to edit, the authoring system 
would extract the learning materials first and then get the “imsmanifest.xml” (the description of the content 
package) inside the learning materials. After getting the “imsmanifest.xml”, we could easily analyze what the 
content of learning materials is. 
 
 In order to realize what the most relevant learning resources to the uploaded learning materials are, the 
metadata description inside the “imsmanifest.xml” is used to serve this goal. The metadata elements of IEEE 
LOM are illustrated in the section 2. But not all of these elements are useful to the analysis results. We selected 
several elements form the metadata description which is essential to our works. The information of selected 
elements is show in Table 1. 
 
Table 1. The selected elements from IEEE LOM metadata 
Number Name Description 
1.0 General 
1.2 Title The name given to this learning object 
1.3 Language The primary human language or languages used within this learning object to communicate to the intended user 
1.5 Keyword A keyword or phrase describing the topic of this learning object 
1.6 Coverage The time, culture, geography or region to which this learning object applies 
5.0 Educational 
5.2 Learning Resource Type Specific kind of learning object 
5.7 Typical Age Range Age of the typical intended user 
5.8 Difficulty How hard it is to work with or through this learning object for the typical intended target audience 
5.9 Typical Learning Time Approximate or typical time it takes to work with or through this learning object for the typical intended target audience 
 
 In the category 1.0, the metadata element here groups the general information that describes this learning 
object as a whole. We use these elements to realize the overview of the learning resources. In the category 5.0, it 
describes the key educational or pedagogic characteristics of this learning resource. We could make use of these 
two essential category groups to define the similarity among different learning resources. After integrating the 
IEEE LOM metadata, we still have to make use of the profile of instructors and analyze the information inside 
it. 
 
 In order to define the relevance between the learning materials edited by instructor and the resources in 
repository precisely, the profile of instructors recorded according to the IMS LIP (Learner Information 
Packaging) is also an essential part in our works. Fortunately, the IMS LIP generator has been developed in our 
previous works. After collecting the essential information, the processing flow of our proposed search wrapper 
is show in Figure 4. 
 
 
Figure 5. The interface of authoring system. 
While editing the learning materials, instructors may search for some relevant resources to refine the 
editing learning materials and fit the learning objective. They may input specific keywords to retrieve the 
repository, and the repository would then return the result list as shown in Figure 6. Besides, the category under 
the search textbox is automatically generated from the metadata description of learning resources. The 
instructors could utilize it to do the advanced re-ranking process. 
 
 
Figure 6. The original search result from repository. 
In order to get the most relevant learning resources, we would like to re-calculate the author expect value 
and then get the new ranking value. Figure 7 shows the ranking list after the calculation process according to the 
proposed ranking mechanism. Besides, the instructors could change the alpha value (as the threshold) to change 
the weight from repository or author expects value. 
 
 
Figure 7. The result list after the re-ranking calculation. 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                             98 年 8 月 30 日 附件三
 
報告人姓名 洪啟舜 Jason C. Hung 服務機構及職稱 
僑光科技大學資訊管理系 
副教授 
 會議時間 
     地點 
2009/8/25~2009/8/27 
澳門 
本會核定
補助文號
NSC 97-2221-E-240-003-  
 
會議 
名稱 
 (中文) 2009 年複合式學習國際研討會 
 (英文) International Conference on Hybrid Learning (ICHL2009) 
發表 
論文 
題目 
 (中文) 對學習資源的重序機制 
 (英文) Re-Ranking Mechanism for Learning Resources 
報告內容應包括下列各項： 
一、參加會議經過 
8 月 25 日會議開始，各國學者陸續來到。在 ICHL2009 中有場 Keynote Speech:是 Prof. 
Timothy K. Shih, Asia University, Taiwan，講題是 Repository and Search Based on Distance 
Learning Standards。 
8 月 26 日繼續參與會議的進行，在中途休息時也與不少學者交換意見，對於遠距及數位
學習的議題有更深入的討論，晚上則是晚宴。 
8 月 27 日本人於上午 9 點發表論文、會中有許多學者給予指教，大家對於數位學習技術
(Technologies in E-Learning)有著熱烈的討論。 
8 月 27 日於發表結束後至機場搭機返台。 
 
二、與會心得 
在會議中與不少學者有進一步的討論，互相切磋，可說是獲益良多，大致上對於一些有
關數位學習相關的新研究主題，有不少新的看法，這對本人在教學與研究上有更多的啟
發。 
 
三、考察參觀活動(無是項活動者省略) 
 
四、建議 
建議國科會可多多補助國內學者參與此會議，相信也會有一些很好的收穫。 
 
五、攜回資料名稱及內容 
論文集 
 
六、其他 
 
 
表 Y04 
90      Jason C. Hung, Neil Y. Yen, and Louis R. Chao 
 
students to interact with each other (learning management system: LMS), and the 
database for storing the learning object (Learning Object Repository: LOR). 
The learning objects could be considered as the basic components like web pages, 
multimedia files or text files in the e-learning environment. In the aspect of teachers, 
they could make use of these learning resources to generate vivid learning materials 
for his/her students. In the aspect of students, they could get more advanced 
information or knowledge through these learning objects. As stated above, we could 
define learning objects as a kind of reference data for pushing the learning activities 
ahead and for bringing the convenience. 
Although teachers and students could directly benefit from the learning objects 
stored in the LOR, still lots of learning resources in the LOR are not relevant to the 
working materials at all. That is because anyone easily creates learning objects 
through any kinds of tools. In order to make resources deliver and to communicate 
with other distance learning systems, the utilization of a common standard seems to 
be the optimal solution. 
In our previous works [1], we’ve already developed a LOR for stored the learning 
objects based on IEEE LOM (Learning Object Model). We focus on the learning 
objects in web page (Hyper-Text Markup Language: HTML) format. According to 
our previous LOR, we utilized the metadata to classify the learning resources. Besides 
the storage process, our LOR would calculate the importance of the learning resources 
based on the Google Page Rank [2] mechanism. 
In our LOR, the users could only get the resources in citation order. However, the 
most cited resources might not be the most relevant one for the current usage. It will 
cause that the relevant resources might appeared in the lower order. According to this 
situation, how to assist the users in getting the most relevant resources would become 
the challenge. In the authoring aspect, teachers would like to get the relevant learning 
resources to create the learning materials. In the learning aspect, students could get 
more extra information by utilizing the relevant learning resources. 
In this article, we would like to propose a ranking mechanism added on the 
previous LOR system. The mechanism would firstly calculate the relevance value 
between resources from LOR and the material which was using now by teachers or 
students that we called “User Expect Value”. Then our proposed mechanism would 
also take the citation value originated from LOR into consider. After the calculation 
process, we could list the query results in the order of sum of citation value and 
relevance value. That is, the teacher and students could get the most useful learning 
resources and reduce the cost of time in sieving the information. 
The remainder organizations of this paper are as follows. Section 2 introduces 
some relative research issues, including some acknowledged e-learning standards, 
similarity calculation mechanism we utilized in our work. Section 3 illustrates our 
proposed system architecture and the ranking mechanism. Section 4 will illustrate the 
implementation and the evaluation our mechanism to prove it is down-to-earth. And 
we’ll make a brief conclusion and talk about the future works in Section 5. 
92      Jason C. Hung, Neil Y. Yen, and Louis R. Chao 
 
2.2 Similarity Computing Mechanism 
In the research of IR domain [3, 4, 5, 6], the common method is to use the keywords 
that authors set for each document to be the attribute of it. There are lots of methods 
to achieve this goal like Simple matching, Jaccard coefficient,  and so on. All of the 
methods we mentioned above could calculate the similarity between different 
documents through the keywords of them. In comparison with Simple matching 
coefficient, the Jaccard coefficient has taken the standardization into account. In this 
situation, it seems to be the optimal calculation mechanism. Hence, Jaccard 
coefficient becomes the widely used mechanism in this domain. 
As regards the automatically classification, it utilizes the similarity between each 
document and classifies them into several classification groups. The document in the 
same group will have higher similarity. In other words, the similarity value of 
documents will be low in the different groups. A correct classification mechanism 
could help users to find relevant resources and could also reduce the cost in filtering a 
large number of resources. It is impossible to classify those resources manually 
because many mistakes and problems are always made. Therefore, the calculation 
mechanism would cause the results of the classification. We have to adopt the suitable 
mechanism for specific types to get the optimal classification result. There are five 
main mechanisms to calculate the similarity between resources, including Simple 
matching coefficient, Dice coefficient, Jaccard coefficient, Overlap coefficient, and 
Cosine coefficient. In the following paragraph, we will introduce the similarity 
calculation mechanisms stated above in the specific example and shown in Table 1. 
Table 1. The definition of the similarity calculation mechanisms 
Definition: 
Assumed that there are N documents in our database and each of them (Dn) could represent as 
a vector in the space model. The vector of document Dn will be Dn=(w1, w2, w3, …, wn) and 
the w are the numbers of keywords. The |Dn| represents the value of the vector Dn. 
Calculation 
Mechanisms 
Description Formula 
Simple 
matching 
coefficient 
Simple matching coefficient is useful 
when both positive and negative values 
carried equal information. In other word, 
the simple matching coefficient for two 
presence/absence distributions on a set 
of sites simply counts the number of 
sites which have the same status 
(presence or absence) in both 
distributions. 
( ) 2121, DDDDSimsmc ∩=
 
Jaccard 
coefficient 
The Jaccard index, also known as the 
Jaccard similarity coefficient is a 
statistic used for comparing the 
similarity of sample sets. It’s defined as 
the size of the intersection divided by 
the size of the union of the sample sets. 
Jaccard's coefficient indicates maximum 
similarity when Sim is 1.0 and 
maximum dissimilarity when Sim is 0. 
( )
21
21
21, DD
DD
DDSim jacc
∪
∩
=
 
94      Jason C. Hung, Neil Y. Yen, and Louis R. Chao 
 
keywords W1 and the document D2 has keywords W2, so the similarity between D1 
and D2 will be calculated by the following formula. It scales the similarity by the 
geometric mean of the number of "1" bits in the two rows: 
∑∑
∑
==
=
=
⋅
=
n
i i
n
i i
n
i ii
WW
WW
DD
DDDDSim
1
2
2,1
2
1,
1 2,1,
21
21
21 ),(
 
In this situation, we conclude that the Cosine coefficient measure achieves better 
performance than the Dice, Overlap and Jaccard measures in our scenario. In the next 
section, we will introduce the system architecture in our works and introduce the 
ranking mechanism we utilized to calculate the similarity among learning resources. 
3. Proposed Methodology 
Our aim is to provide a common way to the users who are not experts or are first time 
to get in touch with the e-learning systems. Through our LOR, we could get the value 
of specific learning resource through calculating the citation links from other 
resources. After that, when users access to the LOR and request for a query result 
through our search UI, our system would list the results in the order of the value that 
we named it “citation value”. That is the common method that every search engines 
and systems do. In this situation, users still have to spend lots of time to filter the 
search results and then get the items that he/she really need. In order to reduce the 
complexity when searching the reference information through the authoring system or 
LMS, we propose a novel mechanism added on our LOR system. Besides, we also 
developed a simple run-time on both authoring and learning sides for the usability 
evaluation. 
The three-tier system architecture of our LOR includes the client systems, search 
user interface (UI), and the system repository. The detail is shown in Fig. 3. 
 
Fig. 3. The system architecture of our previous LOR 
96      Jason C. Hung, Neil Y. Yen, and Louis R. Chao 
 
 
Table 2. The selected elements from IEEE LOM metadata 
1.0 General 
Number Name Description 
1.2 Title The name given to this learning object 
1.3 Language The primary human language or languages used within this learning object to communicate to the intended user 
1.5 Keyword A keyword or phrase describing the topic of this learning object 
1.6 Coverage The time, culture, geography or region to which this learning object applies 
5.0 Educational 
Number Name Description 
5.2 LearningResourceType Specific kind of learning object 
5.5 IntendedEndUserRole Who will be the end user to take this resource (author, learner, …) 
5.7 TypicalAgeRange Age of the typical intended user 
5.8 Difficulty How hard it is to work with or through this learning object for the typical intended target audience 
5.9 TypicalLearningTime 
Approximate or typical time it takes to work with or 
through this learning object for the typical intended target 
audience 
In the category 1.0, the metadata element here groups the general information that 
describes this learning object as a whole. We use these elements to realize the 
overview of the learning resources. In the category 5.0, it describes the key 
educational or pedagogic characteristics of this learning resource. 
In Figure F, the original search process is that users input the keywords or selected 
requirements to LOR then system would list the search results in order of citation 
value. The results in the list might not be suitable or relevant to the learning materials 
selected when users logged in. The most important thing we have to solve is to find 
out the similarity between selected learning materials and resources stored in the 
LOR. To meet this situation, we propose a calculation formula named UEValue (User 
Expect Value). After that, we add citation value and UEValue together to be the new 
ranking list (RL). The list would show relevant resources in higher order and 
irrelevant ones in lower order. 
To prove our formula, we would take following as an example. Supposed that there 
are N elements of IEEE LOM that we want to calculate similarity between the 
“imsmanifest.xml” file in selected learning materials and the metadata of the 
resources in LOR, we defined a match list (ML) to represent it. We also defined a 
response item (RI) to represent the metadata of learning resources from the search 
result list. After those two items, we have to define a match item (MI) to represent the 
element array that contains the number of matching items among original 
“imsmanifest.xml” file and learning resources. In the formula, we assumed selected 
material (Ds) and resources in LOR (Dr) would have a similarity value. We refined the 
Cosine coefficient mechanism and the proposed formula of UEValue is shown below: 
98      Jason C. Hung, Neil Y. Yen, and Louis R. Chao 
 
 
Fig. 5. The interface of our system 
When users search for some relevant resources to make themselves realize the 
content deeply, they could press the search function in the top of central panel. The 
common way is that users input specific keywords to retrieve the resources from 
LOR, and LOR would then return the results and list them in order of the importance 
value of them. Based on our proposed mechanism, the user could utilize the alpha 
parameter in the scroll bar to change the original order. That is, the users could make 
the results in the order of original importance or the relevance. The Fig. 6(a) indicates 
the original search results by inputting the keywords “introduction”. The Fig. 6(b) 
shows the re-rank result based on our mechanism when alpha parameter value equals 
to 0.5. 
 
Fig. 6(a). The original search results                   Fig. 6(b). After re-ranking results 
Through our proposed mechanism, the users could get the resources based on the 
original citation value or the relevance degree that users set to the alpha value. Our 
aim is not to provide a recommendation but to let users could make their own choice 
in retrieving the resources. In this works, we also evaluate the mechanism in the beta 
of UEValue and the alpha of the RL. 
