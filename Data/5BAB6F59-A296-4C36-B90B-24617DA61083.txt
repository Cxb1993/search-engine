retrieve the 3D shape. The projected fringes on the 
image are blurred by motion. Theoretical analysis 
shows that objects moving within one period of the 
projected fringe can be directly described by the 
projected fringe profilometry. On the other hand, the 
blurred fringes supply additional information to 
describe the speed of motion. Thus, shape deformation 
can be determined by production of the moving speed 
and the exposure time. Among all the speed tracking 
algorithms, the presented method provides a robotic 
and compact setup to describe not only the moving 
direction on a 2D plane but also the moving vector in 
a depth axis. Only one shot measurement is required. 
This makes it a convenient tool to describe the 3D 
shape and speed of motion at the same time. In 
addition, we provide a scheme to eliminate the 
intensity disturbance caused by fringe projection. 
Thus, to retrieve the 3D image color as well as the 
3D shape for a dynamic object is desirable. 
英文關鍵詞： 3D shape sensing, velocity detection, color 
restoration, trace of the object, optical inspection, 
fringe projection, phase-shifting, Fourier transform 
method, phase-to-depth relation, 3D image processing 
 
中文摘要：
本計畫開發一套低成本的條紋投影系統，只需擷取一張影像，即可同時獲得動態物體
的瞬間形貌、三維移動速率、三維形變量、以及動態物體的瞬間色彩分佈。若搭配閃頻式
光源，則能進一步量測其三維移動軌跡與移動方向。不須作縱向掃瞄或深度變焦，即可進
行全域的量測。本計畫為一嶄新構想，國內外尚未發展相關的研究。
本年度計畫為三年期計劃的第一年，研究成果除了能描繪物體的三維形貌，亦能濾除
動態物體上的條紋分佈、並呈現其色彩分佈。目前已知的條紋投影輪廓儀，無法描繪量測
範圍內的色彩分佈，然而在醫學影像與三維顯示領域中，忠實呈現待測物及周遭環境的色
彩分佈亦十分重要。對動態物體而言，欲從瞬間獲得的資訊中，描述其形貌以及色彩分佈
有其困難性。本年度計畫提出一套影像處理技術，不僅能精準描述動態物體的形貌，亦能
濾除動態物體上的條紋分佈，進一步呈現物表上的色澤。
另外，為了精準地呈現影像應有的色彩，以及配減少量測速度造成的誤差，計畫內容
特別設計、製作了條紋明晰度(visibility)為 1 的弦狀條紋，有助於精確值的提升。
開發本計畫的優勢在於：
1. 此裝置為全域式的光學系統，不須額外提供掃瞄機組，故結構簡單輕便，對於可攜
式的形貌量測系統，提供極佳的便利性。
2. 搭配過去幾年研發成果—transmittance-encoded fringe projection 技術，可進行表面深
度有大落差(surfaces with large depth discontinuities)的量測。
3. 搭配本計畫提出的校正技術，可解決 perspective distortion 所產生的誤差。
關鍵詞：三維形貌量測，速度量測，形變量量測，原色重建，軌跡追蹤，光學量測，條紋
投影技術，phase-shifting技術，Fourier transform method，「相位－縱深」關係式，三維影像
處理。
英文摘要：
A 3D optical method for 3D shape sensing, velocity detection, shape deformation, and color
restoration is presented. Trace of the motion and its moving direction can be identified as well. A
fringe pattern is illuminated onto the dynamic object, and a CCD camera is used to record the
fringe distribution. Fringes on the obtained image are deformed by the topography of the object,
and are analyzable to retrieve the 3D shape. The projected fringes on the image are blurred by
motion. Theoretical analysis shows that objects moving within one period of the projected fringe
can be directly described by the projected fringe profilometry. On the other hand, the blurred
fringes supply additional information to describe the speed of motion. Thus, shape deformation
can be determined by production of the moving speed and the exposure time. Among all the
speed tracking algorithms, the presented method provides a robotic and compact setup to describe
not only the moving direction on a 2D plane but also the moving vector in a depth axis. Only one
shot measurement is required. This makes it a convenient tool to describe the 3D shape and speed
of motion at the same time. In addition, we provide a scheme to eliminate the intensity
disturbance caused by fringe projection. Thus, to retrieve the 3D image color as well as the 3D
shape for a dynamic object is desirable.
前言
本年度(99 年度)計畫「動態物體之多功能檢測技術及原色重建 I」之研究重點，除了
描繪物體的三維形貌外，特別著重於動態物體之原色重建、以及弦狀條紋的製作。第一年
計畫完成之進度：
1. 已完成量測系統之建構
2. 已能描繪動態物體之瞬時三維形貌
3. 提出三種濾除投影條紋的演算法，並且比較其執行成果
4. 原色重建之影像處理軟體已編寫完成
5. 已製作條紋明晰度(visibility)為 1 的弦狀條紋
本年度計畫執行成效豐碩。主要有：
1. 二篇國際期刊(SCI)的發表[14, 15]。
2. 參與國際研討會的發表，計 4 篇[16-19]。其中，論文“Color retrieval for fringe projection
techniques”為 invited paper。
3. 參與國內研討會的發表，計 9 篇[20-28]。其中，論文“Using a liquid-crystal spatial light
modulator to extend the depth measuring range of a 3D shape sensing system”為 invited talk。
4. 二位碩士班研究生依此計劃於 2011 年六月順利畢業，碩士班畢業論文計 2 篇[29, 30]。
1. Introduction
In optical 3D sensing, techniques based on fringe-projected methods have the properties of
nondestructive detection, high depth accuracy, fast measurement speed, and full-field inspection
[1-4]. It consists of a fringe projection system and an image acquisition system. The inspected
surface is illuminated by a fringe pattern from the projection system. Fringes distorted by the
surface are recorded by the image acquisition system at a different viewpoint. With triangulation
methods or suitable calibrations, distribution of the projected pattern is analyzable to retrieve the
3D shape [5-11]. However, color on the inspected object might be damaged due to the fringe
projection.
In this paper, we investigate three approaches to recover the color distribution. 3D profile of the
inspected object can be retrieved as well. This makes it possible to enhance the performance of
3D image vision.
2. Principle of the fringe reduction
Various fringe reduction algorithms are investigated, including (1) the bandpass filtering
algorithm, (2) the identification for the mean function to the image, and (3) the bidimensional
empirical mode decomposition (BEMD) [12].
The frequency components 2/),/1(~ yTf xx B and 2/),/1(
~* yTf xx B can be carried out with a
suitable band-pass filter. Fringes are therefore reduced with the band-pass filter. The dc
gray-level is carried out with the inverse Fourier transforms of ),( yf xA , as given by
 },{),( 1 yfyxA xA , (4)
Figure 2 illustrates the performance of the band-pass filtering algorithm.
Figure 2. Fringe reduction with a band-pass filter.
2.2 Fringe reduction by finding the mean function
The upper envelope of Eq. (1) and the lower envelope of Eq. (1) are defined as
),(),(),(upper yxByxAyxI  , and (5a)
),(),(),(lower yxByxAyxI  , (5b)
respectively. Thus, the dc gray-level can be carried out by finding the mean of the upper envelope
and the lower envelope, as given by
 2/),(),(),( lowerupper yxIyxIyxA  . (6)
The upper envelope and the lower envelope can further be determined by interpolating the local
maxima and the local minima of the intensity distribution, respectively. Figure 3 shows the result,
in which the cubic spline interpolation was used.
Figure 4. Flow diagram of the EMD.
Figure 5. Fringe reduction by the BEMD.
To identify the extreme points on a 2D image, a window mask with 3x3 pixels is employed. The
central point within the mask is a maximum or a minimum if its neighbor points are always
smaller or larger than itself. In our setup, we used triangle-based cubic spline interpolation to
4. Conclusion
In this paper, three fringe reduction algorithms have been investigated, including (1) the bandpass
filtering algorithm, (2) the identification for the mean function to the image, and (3) the
bidimensional empirical mode decomposition (BEMD). It seems that the bandpass filtering
algorithm removes most of the fringes from the image. However, the images’fine detail was
damaged by the artificial filtering algorithm, especially on the edge of the object. On the other
hand, the approach which reduces the fringes by finding the mean of the upper and lower
envelope is very sensitive to noise. Errors also occur when the fringe contrast is too low. It is
found that the BEMD provided a better performance for fringes with higher frequency, but failed
to remove fringes with lower frequency.
5. References
[1] M. Takeda and K. Mutoh, “Fourier transform profilometry for the automatic measurement
of 3-D object shaped,” Appl. Opt. 22, 3977-3982 (1983).
[2] V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of
3-D difuse objects,” Appl. Opt. 23, 3105-3108 (1984).
[3] K. G. Larkin and B. F. Oreb, “Design and assessment of symmetrical phase-shifting
algorithms,”J. Opt. Soc. Am. A 9, 1740-1748 (1992).
[4] V. Y. Su, G von Baly, and D. Vukicevic, “Phase-stepping grating profilometry: utilization
of intensity modulation analysis in complex objects evaluation,”Opt. Commun. 98,
141-150 (1993).
[5] Y. Surrel, “Design of algorithms for phase measurements by the use of phase stepping,”
Appl. Opt. 35, 51-60 (1996).
[6] W. S. Zhou and X. Y. Su,“A direct mapping algorithm for phase-measuring profilometry,”
J. Mod. Opt. 41, 89-94 (1994).
[7] J. L. Li, X. Y. Su, H. J, Su, and S. S. Cha, “Removal of carrier frequency in phase-shifting
techniques,”Opt. Lasers Eng. 30, 107-115 (1998).
[8] L. Salas, E. Luna, J. Salinas, V. Garcia, and M. Servin,“Profilometry by fringe projection,”
Opt. Eng. 42, 3307-3314 (2003).
[9] W. S. Zhou and X. Y. Su,“Adirect mapping algorithm for phase measuring profilometry,”
J. Mod. Opt. 41, 89-94 (1994).
[10] H. Liu, W. H. Su, K. R., and S. Yin, “Calibration-based phase-shifting projected fringe
profilometry for accurate absolute 3D surface profile measurement,” Opt. Commun. 216,
65-80 (2003).
[11] W. H. Su, H. Liu, K. Reichard, S. Yin, and F. T. S. Yu, “Fabrication of digital sinusoidal 
gratings and precisely conytolled diffusive flats and their application to highly accurate
projected fringe profilometry,” Opt. Eng. 42, 1730-1740 (2003).
photopolymerizable silica glass for holographic hecording,”IPC2010國際光電科技研討
會 (2011).
[28] Chen-Wei Lee, Wei-Hung Su, Chao-Kuei Lee, “Speckle-reduction for interference patterns
based on the empirical mode decomposition method,” 第 29屆光譜技術與表面科學研討
會 (2011/7/21 ~ 2011/7/23).
[29] 曾昭瑜，「利用多重數位影像重建高解析度影像」國立中山大學光電工程學系研究所
碩士論文(2011)。
[30] 陳廷維，「利用二維經驗模態分解法消除干涉條紋的雷射光斑」國立中山大學光電工
程學系研究所碩士論文(2011)。
計畫成果自評
本計劃研究內容與原計畫十分相符，並且於期限內達成預期目標。本計畫執行成效豐碩，
主要有：
1. 二篇國際期刊(SCI)的發表[14, 15]。
2. 參與國際研討會的發表，計 4 篇[16-19]。其中，論文“Color retrieval for fringe projection
techniques”為 invited paper。
3. 參與國內研討會的發表，計 9 篇[20-28]。其中，論文“Using a liquid-crystal spatial light
modulator to extend the depth measuring range of a 3D shape sensing system”為 invited talk。
4. 二位碩士班研究生依此計劃於 2011 年六月順利畢業，碩士班畢業論文計 2 篇[29, 30]。
出席國際會議研究心得報告及發表論文
中文姓名/英文
姓名
蘇威宏/
Wei-Hung Su
服務機構/職稱 國立中山大學/副教授
會議地點/時間
San Diego, LA/21
- 25 August 2011
計畫編號 NSC 99-2221-E-110 -069 -
會議名稱 SPIE Optics and Photonics
會場職務 Session Chair, in Conference 8120 ·Session4
發表論文題目 1. Wei-Hung Su, “Color retrieval for fringe projection
techniques,”Proc. SPIE 8120 (2011).
2. Wei-Hung Su, and Cho-Yo Kuo, “Trace and profile
measurements for dynamic objects,”Proc. SPIE 8120 (2011).
3. Wei-Hung Su, Chao-Kuei Lee, and Cheng-Wei Lee,
“Speckle-reduction for fringe patterns using the 1D empirical
mode decomposition,”Proc. SPIE 8120 (2011).
4. Wei-Hung Su, Chieng-Feng Hung, and Wei-Chia Su,
“Real-time profilometry using double fringe projection
techniques: a compact design for endoscopes,”Proc. SPIE
8120 (2011).
心得：
晚學於 2011年 8月底參加 SPIE會議，並且擔任 Conference 8120·Session 4之會
議主席，過程十分順利。
(http://spie.org/Documents/ConferencesExhibitions/OP11-final-L.pdf)
晚學於此次會議發表四篇論文。其中，論文“Color retrieval for fringe projection
techniques”為invited paper。會議期間並與Prof. Yin Shizhuo、Prof. Ruyan Guo交換
心得，啟發甚大。
台灣學者在此次會議發表的論文眾多，並且踴躍發言、討論熱列。例如，許根玉
教授、孫慶成教授、林烜輝教授、汪啟茂教授等多位國內知名學者，在此次會議
皆發表數篇重量級論文，顯示台灣學者在此領域有佔有極高的學術地位。
會議後晚學與諸位教授約 20人於 Prof. Francis T. S. Yu家中餐敘，進行生涯歷程
與學術研究的經驗分享，使晚學受益良多。
會議之部份照片如下一頁所示。
論文被接受發表之大會證明文件
發表之四篇論文如附件所示。
Figure 1. Appearance of the projected fringes on the object.
Shown in Fig. 1 is the appearance of a ball projected with a sinusoidal fringe pattern. A CCD camera
with 10241024 pixels at 12-bit pixel resolution is used to observe the fringe distribution. Gray-level
of the image can be described as
)],(cos[),(),(),( yxyxByxAyxI  , (1)
where A(x, y) is the dc gray-level, B(x, y) is the modulation amplitude, andis the phase of the fringes.
This image is then employed to evaluate the performance of the fringe-reduction techniques. Once
fringes are removed, the dc gray-level is carried out.
2.1 Fringe reduction with a band-pass filter
The gray-level shown in Eq. (1) can be rewritten as
        xx T
x
j
T
x
j
eyxBeyxByxAyxI
 2
*
2
,~
2
1
,~
2
1
,,

 , (2)
where
),(
2
1
),(),(~
yxZ
T
j
zeyxByxB

 , and“*”denotes the conjugate operation.
The one-dimensional Fourier transform of Eq. (2) with respect to x-axis is realized as
    ),1(~
2
1
),
1
(~
2
1
,},{ * y
T
fy
T
fyfyxI
x
x
x
xx  BBA , (3)
where   ),(},{ yfyxA xA , and   ),(~},~{ yfyxB xB .
The frequency components 2/),/1(~ yTf xx B and 2/),/1(
~* yTf xx B can be carried out with a
suitable band-pass filter. Fringes are therefore reduced with the band-pass filter. The dc gray-level is
carried out with the inverse Fourier transforms of ),( yf xA , as given by
Figure 3. Fringe reduction by finding the mean of the upper envelope and the lower envelope.
2.3 Fringe reduction by the bidimensional empirical mode decomposition
A one-dimensional data set when performing the EMD can be expressed as



n
i
i xrxcxI
1
)()( , (7)
where ci(x) is the intrinsic mode functions (IMFs), and r(x) is the residue of the data. For images
recorded by a CCD camera, x is a discrete variable, which represents the pixel position. These IMFs are
regarded as the basis of the expansion, which can be linear or nonlinear as dictated by the data.
The IMFs are obtained from the signal be means of an algorithm called the shifting process. Figure 4
illustrates such a process. In Fig. 4, the standard deviation SDij is defined as

 








 

X
x ji
ijji
ij xh
xhxh
SD
1
2
)1(
2
)1(2
)(
)()( . (8)
envelope and the lower envelope [13]. The performance of fringe reduction evaluated by the BEMD is
depicted as Fig. 5.
3. EXPERIMENT ANALYSIS
A comparison for the fringe reduction is shown as Fig.6. It seems that the bandpass filtering algorithm
removes most of the fringes from the image. However, it failed to reduce fringes with large periods.
The images’fine detail was also damaged by the artificial filtering algorithm, especially on the edge of
the object. On the other hand, the approach which reduces the fringes by finding the mean of the upper
and lower envelope is very sensitive to noise. Errors also occur when the contrast of the fringes is too
low. The empirical mode decomposition (the EMD) is a promising tool to extract signals because there
is no artificial filtering algorithm applied. Signals are therefore not damaged by any artificial filtering
function. It is found that the BEMD provided a better performance for fringes with higher frequency,
but failed to remove fringes with lower frequency.
Fig. 2. (a) 1D intensity distribution for fringes projected on the object. A CCD camera with 10241024
pixels at 12-bit pixel resolution is used to observe the fringe distribution. (b) Fringe reduction
performed with a band-pass filter. (c) Retrieved dc-gray-level by finding the mean of the upper
envelope and the lower envelope. (d) Fringe reduction performed by the BEMD.
4. CONCLUSION
In this paper, three fringe reduction algorithms have been investigated, including (1) the bandpass
filtering algorithm, (2) the identification for the mean function to the image, and (3) the bidimensional
empirical mode decomposition (BEMD). It seems that the bandpass filtering algorithm removes most
Trace and profile measurements for dynamic objects
Wei-Hung Su and Cho-Yo Kuo
Department of Material Science and Optoelectronic Engineering, National Sun
Yat-Sen University
Kaohsiung 804, Taiwan
ABSTRACT
A fringe projection technique for finding the absolute shape at a sequence of time for a dynamic object
is proposed. This method makes it possible to simultaneously identify the trace and the speed of the
dynamic object.
Keywords: fringe projection, projected fringe profilometry, sinusoidal grating
1. INTRODUCTION
Trace detection and speed sensing in 3D coordinates have become an interesting topic in computer
vision and automatic optical inspection [1-3]. However, it is a challenge to analyze the dynamic 3D
problems just from a set of 2D images. Depth positions and moving vectors in the depth axis cannot be
described directly by the 2D images. One solution is to describe the 3D profile of the dynamic object in
absolute coordinates at a sequence of time. Trace and moving speed is then defined by the change in
positions with reference to the associated points.
To achieve the 3D profile measurement and simultaneously to trace the motion in the world
coordinates, the Fourier transform profilometry [4] combined with a video camera is a desirable
approach. A sinusoidal fringe pattern is projected onto the dynamic surface. Fringes are observed by
the video camera at a different viewpoint. With the Fourier transform method, phase of the fringes in
each image frame can be extracted to retrieve the 3D shape. The retrieved 3D shapes obtained at a
sequence of time are therefore analyzable to describe the trace or speed of the object.
When the inspected object moves with a higher speed, or rotates with a higher frequency, the image
acquisition time is required to be short enough that the observed image is not blurred by motion. As a
result, the image intensities might not be high enough to extract the phases. An alternated approach is
using a high power strobe lamp which generates periodic pulses as the light source. Fringes are
illuminated periodically by the high power strobe lamp and then projected onto the dynamic object in a
sequence of time. The duration of each pulse is so short that the dynamic object seems static in each
image frame. Fringes frozen in each image frame by the pulsed illumination are therefore available to
retrieve the 3D shape. Unfortunately, this approach still fails for ultra-fast moving objects, because the


M
T
t o , (1)
wheret is the duration time of the pulses, To is the fringe period observed on the image sensing array,
M is the magnitude of the projection lens, andis the moving vector which is normal to the projected
fringes.
Image acquisition should be performed in such a way that different pulsed illuminations do not
interfere with each other. Thus, to avoid objective images overlapped by double exposure, the interval
between two pulses in time domain should be large enough, as represented as

L
t  , (2)
where t is the intervallic time between two sequent pulses, L is the width of the object along the
moving vector. The exposure time of the CCD camera should be much larger thant that the trace of
the object could be observed.
Figure 1. Schematic setup of the projected fringe profilometry.
3. DESIGN OF THE FRINGE PATTERN
Figure 2(a) shows an example of the encoded fringe pattern. This fringe pattern consists of a set of
binary-encoded stripes and a set of sinusoidal fringes. Appearances of the sinusoidal fringe and the
encoded stripes are shown as Fig. 2(b) and 2(c), respectively. Transmittances of the stripes are
quantized into two intensity levels: 0.5 and 1. The two quantized transmittances are further denoted
with two digital numbers, 0 and 1, respectively. As shown in Fig. 2, there are 8 binary stripes in a
period, in which the stream of the digital numbers is arranged as [0 1 0 1 1 1 0 0]. They are arranged in
a manner that three adjacent stripes form a group. The adjacent groups are overlapped with two stripes.











01
01
0
bzby
azax
cz n
N
n
n
, (2)
where ai, bi, and ci are undetermined parameters. The functional form of Eq. (2) and all the coefficients
involved must be found prior to the 3D measurement. Several calibration schemes have been proposed
to find out these parameters [14-16]. Once these parameters are known, one can first identify the depth
value z from the deformed phase on the inspected object. Then the corresponding transverse positions
can be carried out by the depth value.
5. EXPERIMENT
A ball with approximately 40mm in diameter was chosen as the inspected sample. A sinusoidal fringe
pattern was illuminated by a strobe lamp and then projected onto the sample. A CCD camera with
10241024 pixels at 12-bit pixel resolution was used to record the fringe distribution. As shown in Fig.
3(a), the exposure time was large enough that five illuminations were recorded in one image frame.
Phase-extraction was performed with the Fourier transform method [4]. Figure 3(b) shows the
computed phases, which were within the interval between–and. Unwrapping was an inevitable
procedure to eliminate the discontinuities. Figure 3(c) illustrates a phase map unwrapped with
Goldstein’s algorithm [5]. It is apparently that error occurred to identify the fringe orders between two
adjacent illuminations. With the binary-encoded fringe pattern, fringe orders were addressed without
ambiguity, as shown in Fig. 3(d).
With Eq. (2), the shape of the dynamic object could be described in absolute coordinates. Figure 4
depicts the retrieved profile measure at a sequence of time.
6. CONCLUSION
A fringe projection technique with pulsed illuminations for finding both the trace and the shape of a
dynamic object has been proposed. Moving vectors in absolute coordinates could be analyzed as well.
This technique used a binary-encoded fringe pattern to describe the shape of the object in absolute
coordinates, and employed a strobe lamp to periodically illuminate this fringe pattern to perform the
profile measurements in a sequence of time. The trace and the moving speed were then defined by the
change in positions with reference to the associated points. With the proposed binary-encoded fringe
pattern, phases could be unwrapped without ambiguity, even though the inspected object was colorful.
Only one image frame with multi-pulsed illuminations was required for performance. The
environmental vulnerability was therefore greatly reduced. Only one phase measurement is required for
operation. We believe that the low computation cost makes it possible for industrial application.
REFERENCES
[1] N. A. Thacker, and J. E. W. Mayhew, “Optimal combination of stereo camera calibration from 
arbitrarystereo images,” Image & Vision Comput. 9, 27-32 (1990).
[2] R. A. Lane, N. A. Thacker, and N L Seed, “Stretch-correlation as a real-time alternative to
feature-based stereo matching algorithms,” Image & Vision Comput. 12, 203-212 (1994)
[3] M. Minou, T. Kanade, and T. Sakai, “A method of time-coded parallel planes of light for
depth measurement,” Trans. IECE Japan 64, 521-528 (1981).
[4] M. Takeda, and K. Mutoh, “Fourier transform profilometry for the automatic measurement of 
3-D object shaped,” Appl. Opt. 22, 3977-3982 (1983).
[5] E. Zappa, and G. Busca, “Comparison of eight unwrapping algorithms applied to 
Fourier-transform profilometry,” Opt. Lasers Eng. 46, 106-116 (2008).
[6] J. M. Huntley, and H. O. Saldner, “Temporal phase-unwrapping algorithm for automated
inteferogram analysis,”Appl. Opt. 32, 3047-3052 (1993).
[7] H. O. Saldner, and J. M. Huntley, “Profilometry using temporal phase unwrapping and a
spatial light modulator-based fringe projector,”Opt. Eng. 36, 610-615 (1997).
[8] D. R. Burton, and M. J. Lalor, “Multichannel Fourier fringe analysis as an aid to automatic
phase unwrapping,”Appl. Opt. 33, 2939-2948 (1994).
[9] Y. Hao, Y. Zhao, and D. Li, “Multifrequency grating projection profilometry based on the
nonlinear excess fraction method,”Appl. Opt. 38, 4106-4110 (1999).
[10] E. B. Li, X. Peng, J. Xi, J. F. Chicharo, J. Q. Yao, and D.W. Zhang, “Multi-frequency and
multiple phase-shift sinusoidal fringe projection for 3D profilometry,”Opt. Express 13,
1561-1569 (2005).
[11] M. Takeda, Q. Gu, M. Kinoshita, H. Takai, and Y. Takahashi, “Frequency-multiplex
Fourier-transform profilomery: a single-shot three-dimensional shape measurement of objects
with large height discontinuities and/or surface isolations,” Appl. Opt. 36, 5347-5354 (1997).
Speckle-reduction for fringe patterns using the 1D empirical
mode decomposition
Wei-Hung Sua, Chao-Kuei Leeb, Chen-Wei Leeb
a Department of Material Science and Optoelectronic Engineering, National Sun
Yat-Sen University
Kaohsiung 804, Taiwan
b Department of Photonics, National Sun Yat-Sen University
Kaohsiung 804, Taiwan
ABSTRACT
We present a database system based on the empirical mode decomposition (EMD) to automatically
reduce the speckle in a fringe pattern. With reference to the database, speckles on the fringe pattern
can be efficiently and robotically reduced. Percentage of the removed speckles can be predicted as
well.
Keywords: fringe analysis, speckle, coherent illumination, empirical mode decomposition, fringe
projection
1. INTRODUCTION
MOIREÉ gauging [1], projected fringe profilometry [2,3], speckle pattern interferometry [4,5], and
shearography [6] are well-known techniques for the measurement of surface profiles. With a
phase-shifting or Fourier transform method, the surface profile is represented in the form of a phase
map. However, speckle noises could be introduced when a coherent source is used. Speckle-reduction
must be dealt with in order to retrieve the surface profile.
The Empirical Mode Decomposition (EMD) [8] provides a desirable solution to reduce speckles for a
fringe pattern. It decomposes the measured signal into several intrinsic mode functions (IMFs), from
high frequency modes to low frequency modes. Speckles are then reduced by removing some IMFs
which contain higher frequency bands. Without using any predetermined filter function, it decomposes
the signal empiricaly by the local characteristic scale of the data. The image’sdetail structure is
therefore not damaged by any artificial filter function. Recently, Bernini et al. [9] employed the 1-D
EMD to reduce speckles in computer-simulated fringes. It had been shown that the empirical mode
decomposition (EMD) has been a promising tool to reduce speckles in a fringe pattern.
most by one. Thus the local maxima of the data set are always positive and the local minima are
negative, respectively. Next, the mean value of the envelope defined by the local maxima and the
envelope defined by the local minima is zero. This ensures that the data frequency does not contain
unwanted fluctuations as induced by asymmetric waveforms.
3. DESIGN OF THE COMPUTER GENERATED SIGNAL
Before evaluating the performance of speckle-reduction by the EMD, a simulated signal to represent
the speckle-introduced image is generated. It is designed based on the fact: The root mean square of the
speckles is proportional to the illuminating intensity. Thus, a computer generated signal for one image
row is expressed as



N
xN
xIxI o
)(
)( , (2)
where Io(x) is the illuminating intensity of the coherent wave, N(x) is the speckle function, and <N> is
the mean of N(x).
The function N(x) is designed with reference to the histogram of the measured speckles P(N), as given
by
 )}({Random NPxN  , (3)
where Random{} denotes the spatially random-distributed operation, and P(N) is the histogram of
speckles when illuminating a coherent source onto the inspected object. Therefore, the histogram of the
simulated speckles is calibrated with that of the measured speckles. This ensures the computer
generated signal performing well to address the characteristics of speckles.
The measured histogram P(N) is intensively related to the mode numbers of the laser cavity, the
roughness of the surface, the polarization of the laser wave, and the spatial-correlation effect from the
optical system. Goodman [10] had demonstrated several types of histograms for objective speckles and
subjective speckles. These histograms are statistically expressed in the form of exponential functions.
Consequently, we use a fitting function in the form of gamma distributions to represent the observed
histogram. The fitting function in the form of probability density is given by
 )exp(
)!1(
1





N
N
Nm
N
NP m
m
, (4)
where m is an integer. Shown in Fig. 2 is the fitting function with different m values. A larger m
implies that the signal-to-noise ratio is relatively higher. Thus, the parameter m plays a key role to
signify the signal-to-noise ratio.
CCD camera with 10241360 pixels at 12-bit pixel resolution was used to obtain this image. The
computer generated signal is very similar to the obtained image. Thus, the signal created by Eq. (5) can
be employed to evaluate the performance of speckle-reduction.
100 200 300 400 500 600 700 800
0
1000
2000
3000
4000
In
te
ns
ity
Pixel
Simulation
0 100 200 300 400 500 600 700 800
0
1000
2000
3000
In
te
ns
ity
Pixel
Michelson
(a) (b)
Figure 4. (a) A computer generated signal, in which N(x) is randomly distributed with reference to the fitting
function at m = 6. (b) A one-dimensional intensity distribution of the projected fringes when a coherent source is
used.
4. SPECKLE REDUCTION FOR VARIOUS FRIGE PERIODS
The speckle-reduction is performed by removing a suitable number of IMFs, as expressed as



l
i
i
l xcxIxS
1
)( )()( , (6)
where l denotes the number of removed IMFs. Figure 5(a) shows the retrieved signals computed by Eq.
(6). In this case, S(4)(x) has the lowest standard deviation.
Performance of the speckle-reduction is evaluated by the standard deviation, which is mathematically
expressed as
 


X
x
ll xSxS
X
SD
1
2)()( )()(
1 . (7)
To statistically identify the optimized value l, the simulation was repeated with randomly distributed
speckles N(x) more than 20 times. The minimum of the standard deviation was S(4)(x) = 188.1822, as
depicted in Fig. 5(b).
100 200 300 400 500 600 700 800
0
1000
2000
3000
4000
In
te
ns
ity
Pixel
1 IMF Removed
100 200 300 400 500 600 700 800
0
1000
2000
3000
4000
In
te
ns
ity
Pixel
2 IMFs Removed
100 200 300 400 500 600 700 800
0
1000
2000
3000
4000
In
te
ns
ity
Pixel
3 IMFs Removed
100 200 300 400 500 600 700 800
0
1000
2000
3000
4000
In
te
ns
ity
Pixel
4 IMFs Removed
5. SPECKL-REDUCTION FOR VARIOUS SPECKLE SIZES
A Michelson interferometer was constructed to identify the number of removed IMFs for various
speckle sizes. The configuration is depicted as Fig. 7. The fringes on the screen were formed by
interference of two plane waves. A CCD camera was used to observe the fringe pattern. The fringe
period and the speckle size could be changed by modulating
Figure 7. Configuration of a Michelson interferometer for experimental identifying function of EMD to
speckle reduction.
the angle between the two incident waves and by tuning the aperture on the camera lens, respectively.
The observed fringe patterns with various speckle sizes and various fringe periods were then evaluated
by the EMD. Speckles were reduced in such a way that the fringe pattern was firstly divided into
several 1D image rows, and then each 1D image was decomposed by the EMD to several IMFs.
Speckles in each 1D image were reduced by removing specific IMFs which contains the speckle
content. A noiseless 2D fringe pattern was finally formed by reassembling the whole denoised 1D
image rows.
Figure 8 shows one of the results, in which the fringe period is 60 pixels. Appearances of the average
speckle size shown in Fig. 8(a), 8(b), and 8(c) are 1, 2, and 4 pixels, respectively. It shows that the
speckles were intensively reduced at l = 4, even though the pixel sizes were different. We repeated the
speckle reduction with fringe periods ranging from15 to 210 pixels. The result indicated that speckle
size was not sensitive to the number of removed IMFs.
6. DENOISE PROCEDURE BASED ON THE DATABASE
The previous sections indicate that the number of removed IMF is dependent to the fringe period, but
not sensitive to the parameter m and the speckle size. Consequently, the number of removed IMFs can
be described as a function of the period. Based on Fig. 6, l can be expressed as
   
    .8008.1048966.0103194.2
104662.5109441.4
0
2
0
4
3
0
74
0
10




TT
TTl (9)
Once the fringe period on a speckle pattern is known, speckles can be reduced by the EMD, with a
number of removed IMFs identified by Eq. (9).
The denoise process is described as follows:
1. Separate the interference pattern into a set of 1-D images along a desired direction.
2. Perform the EMD onto the 1-D images.
3. Determine the fringe period for each 1-D image.
4. Evaluate the number of removed IMFs for each 1-D image with reference to the polynomial
function as describe in Eq. (9).
5. For each image pixel, reduce speckle noises by removing a couple of IMFs suggested by Eq. (9).
7. EXPERIMENTS: APPLICATION OF THE DATABASE TO FRINGE
ANALYSIS
An interference pattern produced by a Michelson interferometer was selected as the evaluated data.
Appearance of the fringe pattern is shown as Fig. 10(a). A CCD camera with 1024 1024 pixels at 12-bit
pixel resolution was used to record the image.
(a) (b) (c) (d) (e)
(f) (g) (h) (i)
[5] A. Andersson, A. Runnemalm, and M. Sjodahl,“Digital speckle-pattern interferometry:
Fringe retrieval for large in-plane deformations with digital speckle photography,”Appl. Opt.
38, 5408-5412 (1999).
[6] N. K. Mohan, H. O. Saldner, and N. E. Molin, “Electronic shearography applied to static and 
vibrating objects,” Opt. Commun. 108, 197-202 (1994).
[7] A. Davila, G. H. Kaufmann, and D. Kerr,“Scale-space filter for smoothing electronic speckle
pattern interferometry fringes,”Opt. Eng. 35, 3549-3554 (1996).
[8] N. E. Huang, Z. Shen, R. L. Steven, M. C. Wu, H. S. Shih, Q. A. Zheng, N. C. Yen, C. C.
Tung, and H. H. Liu, “The empirical mode decomposition and Hilbert spectrum for nonlinear
and non-stationary time series analysis,” Proc. R. Soc. Lond., Ser. A 454, 903-995 (1998).
[9] M. B. Berninia, G. E. Galizzia, A. Federicob, and G. H. Kaufmann, “Evaluation of the 1D 
empirical mode decomposition method to smooth digital speckle pattern interferometry
fringes,” Opt. Lasers Eng. 45, 723-729 (2006).
[10] J. W. Goodman, [Laser Speckle and Related Phenomena], J. C. Dainty, Ed. New York:
Springer-Verlag, 1975.
An alternative solution is the utilization of interference projection. Fringes are formed by means of the
so-called Young’s setup in which interference between two plane waves are inclined at a small angle to
each other. The projection system is therefore simplified by using a two-slit device. Unfortunately, it is
still a challenge to analyze surfaces with lots of discontinuities. Phase unwrapping [12], the inevitable
procedure to remove the phase jumps in order to recover the absolute phase, will encounter ambiguity
to distinguish the local fringe order. Two or several different projected spatial frequencies can be used
to increase the range of measured depth. However, these systematic configurations become
complicated again and are still impractical in application to endoscopes.
In this paper, we investigate the use of a fringe pattern generated by launching a laser beam into a
diffraction grating. The projection system is simplified by using a diffraction element instead of a
projection lens or interference components. This makes it possible to perform 3D shape measurements
using endoscopes. The field of view of this measurement system can be wider than 60°, depending on
requirement of the working distance and measurement scale of the tested object. The high spatial
coherence from the diffraction grating allows it to generate a large depth-of-focus projection. The
fringes are encoded with binary stripes. Thus, surfaces with large depth discontinuities can be
identified without ambiguity. In addition, we use two fringe projections from two different viewpoints
for finding the absolute shape of an object is proposed. Shadowing caused by tilted fringe projection
can be eliminated. Only one measurement frame is required to inspect surfaces. Thus, it is feasible to
describe the shape of the dynamic objects inside a body cavity.
2. FABRICATION OF THE DIFFRACTION COMPONENT FOR FRINGE
PROJECTION
As shown in Fig. 1, a standard holographic setup is proposed, as shown in Fig. 1. The setup is mainly
composed of (1) a laser with good temporal coherence, (2) a convergent reference wave, (3) a
convergent object wave, and (4) a hologram, which is used as a diffraction element. An objective lens
forms the object wave from a two-frequency pattern. The reference wave and the object wave interfere,
resulting in an intensity distribution in the hologram.
The two-frequency pattern is the combination of two sets of fringes with different frequencies: one
frequency is P (P = 3, 4,5 …)times larger than the other. Its transmittance is represented as
 )cos( 22121 xxt d , (1)
where d is the period of the high frequency. We have proposed a method to fabricate an accurate
two-frequency pattern [8]. An example of the pattern is shown in Fig. 2. In this pattern, the period of
the low-frequency fringes and the high-frequency fringes was 960m and 192m, respectively.
The distance do between the fringe pattern and the objective lens is slightly smaller than the focal length
of the objective lens. It implicates that the objective lens forms an enlarged virtual image of the
two-frequency pattern. For a coaxial system, the imaged position is approximately given by
Figure 3. Binary encoded fringe pattern when 3 sequent stripes are used to form a group.
As shown in Fig. 2(c), transmittance of the stripes is quantized into two intensity levels, 0.5 and 1.
There are 10 binary stripes in a period. The sequence of any three adjacent transmittances within one
period does not appear elsewhere. Thus, any stripe in that period can be identified without ambiguity.
For example, three adjacent stripes with sequent transmittances of 0.5, 1.0, and 0.5 are utilized to
represent the 1st, 2nd, and 3rd stripe in that period, respectively. Stripes are therefore discernible with
reference to its neighbors.
The transmittance of this encoded pattern is mathematically represented as
 2.0)]cos(4.04.0[)( 2  xxBxt d , (1)
where d is the period of sinusoidal fringes, and B(x) is the transmittance distribution of binary stripes,
as shown in Fig. 2(c). Figure 3(b) shows the distribution of the sinusoidal fringes, with transmittance
ranging from 0.2 to 1.0.
4. PRICIPELE OF THE 3D PROFILE MEASUREMENTS
Figure 4 illustrates the configuration of the 3D shape sensing system. The inspected object is projected
with two fringe patterns at the same time from two different viewpoints. Each pattern is produced by
launching a laser beam into the diffraction element. In our setup, we employed a red laser and a blue
laser as the light sources. Consequently, a set of red fringes and a set of blue fringes were projected
onto the inspected object. A color CCD camera was used to record the projected fringes. Shown in Fig.
5 is the recorded image, in which a flat surface was projected with two sets of color fringes. The
recorded image was separately to three color channels: the red, green, and blue. Figure 6(a) and (b)
illustrates the images separated in the red channel and blue channel, respectively. For surfaces with
depth discontinuities, phases can be unwrapped without ambiguity with reference with the
binary-encoded stripes. Lost data caused by shadows on edges of the depth discontinuities can be
retrieved by comparison of the separated images, too.
5. CALIBRATION
Figure 7 shows the geometrical arrangement of a typical non-collimated fringe projection. An
area-encoded pattern designed on a computer is projected to the objects by the LCD projector.
The deformed fringe pattern on the objects is then recorded by a color CCD camera at a different view
angle. To evaluate the phase distribution, the color-encoded grids should be displayed in gray intensity
levels. It is a simple task for image processing. In our setup, phases of the projected fringes are
evaluated by Fourier transform method [1]. Unwrapping is then performed with reference to the
area-encoded stripes, as described in section 3.
Of course, a correspondence between the world coordinates and retrieved unwrapped phases on the
inspected objects must be established. The mathematical relationship can be expressed as











01
01
0
bzby
azax
cz n
N
n
n , (2)
where ai, bi, and ci are undetermined parameters. The functional form of Eq. (2) and all the coefficients
involved must be found prior to the 3D measurement. Several calibration schemes have been proposed
to find out these parameters [9-11]. Once these parameters are known, one can first identify the depth
value z from the deformed phase on the inspected object. Then the corresponding transverse positions
can be carried out by the depth value.
Figure 7. Prejected fringe profilometry using a hologram to produce a fringe pattern.
6. EXPERIMENT
A cubic object with approximately with size 4mm x 4mm was chosen as the inspected sample. Large
step discontinuities occurred between the background and the cubic object. Two fringe patterns
Figure 10. Retrieved 3D shape of the inspected object.
7. CONCLUSION
We have presented a projected fringe profilometry using two diffracted binary-encoded patterns with
an endoscope to perform the 3D shape sensing for a cubic object. The two projected fringe patterns
were used to eliminate shadowing caused by the tilted fringe projection. The binary-encoded fringe
pattern was used to identify surfaces with large depth discontinuities. The usage of the diffraction
elements made the projection system simple and compact. It requires only one measurement frame to
inspect discontinuous surfaces. This makes it possible to describe the 3D shape if a dynamic object
inside a body cavity..
REFERENCES
[1] M. Takeda and K. Mutoh, “Fourier transform profilometry for the automatic measurement of
3-D object shaped,” Appl. Opt. 22, 3977-3982 (1983).
[2] V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of 3-D
difuse objects,” Appl. Opt. 23, 3105-3108 (1984).
[3] K. G. Larkin and B. F. Oreb, “Design and assessment of symmetrical phase-shifting
algorithms,”J. Opt. Soc. Am. A 9, 1740-1748 (1992).
[4] V. Y. Su, G von Baly, and D. Vukicevic, “Phase-stepping grating profilometry: utilization of
intensity modulation analysis in complex objects evaluation,”Opt. Commun. 98, 141-150
(1993).
[5] Y. Surrel,“Design of algorithms for phase measurements by the use of phase stepping,”Appl.
Opt. 35, 51-60 (1996).
[6] W. S. Zhou and X. Y. Su,“A direct mapping algorithm for phase-measuring profilometry,”J.
Mod. Opt. 41, 89-94 (1994).
國科會補助計畫衍生研發成果推廣資料表
日期:2012/01/31
國科會補助計畫
計畫名稱: 動態物體之多功能檢測技術及原色重建
計畫主持人: 蘇威宏
計畫編號: 99-2221-E-110-069- 學門領域: 資訊光學
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1. 擔任 IPC 2011 國際光電科技研討會『資訊光電與光機電系統』之議程委員。
其中論文「Using a liquid-crystal spatial light modulator to extend the 
depth measuring range of a 3D shape sensing system」為 invited paper。
2. SPIE Optics & Photonics 2011 Session Chair, in Conference 8120 •
ession4。其中論文「Color retrieval for fringe projection techniques」
為 invited paper。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
