 1
資料串流上連續型查詢處理技術之研究(2/3) 
Research on Continuous Query Processing Techniques over Data streams 
 
計畫編號：95-2221-E-004-016- 
執行期間：95 年 08 月 01 日至 96 年 07 月 31 日 
計畫主持人：陳良弼 
執行單位：國立政治大學資訊科學系 
 
中文摘要 
由於資料串流異於傳統資料庫之特性，
加上其應用十分之廣泛，因此，在目前資料
工程(data engineering)領域中，是十分熱門的
研究範疇，相關的應用系統雛形，及理論研
究，皆在知名國際會議及期刊中，大量曝光。
本計畫將以研究 DSMS 的核心技術⎯連續型
查詢(continuous query, CQ)之處理為主軸，發
展此核心技術所需之關鍵技術，如表格資料
之 連 續 型 查 詢 處 理 (Relational CQ 
Processing)、查詢與資料串流之監控(Query 
and Data stream Monitoring)等。於第一年的研
究成果中，除了原本僅考慮資料串流環境
外，我們更將研究觸角延伸至探討有關感測
器網路（sensor network）下之多查詢處理技
術。因此，在本年度計畫執行過程中，我們
持續發展在感測器網路上之查詢處理技術，
提出了實際考慮感測器特性之相關研究報
告，並發展一實作系統，將使用者介面與底
層技術分離，使得使用者可利用親切介面，
透過該系統指揮感測器網路之工作。另外在
於查詢與資料串流之監控研究議題上，我們
透過計算移動總和(moving sums)來提供資料
串流之統計值概算，並提出一新式演算法，
在考慮記憶體空間限制下，於資料串流環境
上作高頻式樣(frequent itemsets)探勘。 
關鍵詞 
資料串流、連續型查詢、感測器網路、高頻
式樣探勘、統計值概算 
Abstract 
Progress of high technologies including 
communication and computation leads to a 
more convenient life and also brings huge 
amounts of commercial benefits. However, 
rapid speed of the communication and powerful 
capability of the computation generate data as a 
form of continuous data streams rather than 
static persistent datasets, raising the complexity 
of data management. A data stream is an 
unbounded sequence of data continuously 
generated at a high speed. Such applications as 
network traffic management, web log analysis, 
sensor network system and traffic management 
system may need to handle different categories 
of data streams. Recently, a new type of data 
management system, named data stream 
management system (DSMS), has become one 
of the most popular research areas in data 
engineering field. One of the kernel 
technologies in DSMS, named continuous 
query processing, is developed in this project. 
The continuous query processing technology 
includes some key techniques such as 
relational continuous query processing and 
query and data stream monitoring. In the past 
one year, we have proposed some query 
processing techniques in the sensor network 
systems which are important applications on 
DSMS. Moreover, we also develop a sensor 
network system, named MAKE DB, used to 
provide a friendly interface for helping users to 
access the sensor network system without 
directly using the detailed underlying 
techniques. To the research area of "query and 
data stream monitoring," we propose an 
approach of calculating moving sums over data 
 3
的前提下，越是接近伺服器端的節點，必須
負責傳遞越多下端子節點的封包；因此，所
需消耗的能量將隨著子節點的數目而增加。
其次在於針對使用者所要求的特定條件，其
所需消耗能量的多寡若超出原先統計分析的
估計值時，如何重新排程以求盡可能達到原
先預定使用期限。為此，我們設計了一套能
有效管理感測排程的查詢系統，針對各種不
同的變因得出最佳的排程，並回覆使用者，
根 據 此 排 程 結 果 執 行 的 可 靠 度
(Confidence)，來決定此查詢的可行性，或得
知應當需要如何修正，該系統架構如圖一所
示。 
本方法假設網路分布狀態和密度皆為已
知，且節點均勻分佈於監測區域，原因在於
均勻分佈下能平均回收各地區的資料，使得
資料的代表性較高。首先我們依據過去的統
計值資訊，假設資料為常態分佈 (normal 
distribution)，對突發事件的機率和平均耗電
量做一估計，接著保留估計期望值加上 X 倍
的容許偏差範圍內之電量後，將剩餘電量依
據節點數和階層數做平均分配。 
假設各節點在初始時，電力皆相同的情
況下，因為越上層的節點其負責傳遞的資料
量相對越多，因此，上層的節點則成為整個
系統執行時間的瓶頸(bottleneck)。在期望取
得的資料有區域代表性的前提下，我們希望
能平均取得各個單位區域的資料，故最佳結
果應是各節點回收的資料筆數差異度最小的
情形，而又同時能將電量盡量耗盡，以達到
最高的資料總量。因此，在保留突發事件處
理的電量之後，剩餘電量會依據上列最佳解
的定義來分配使用，並求出各階層節點的任
務週期(duty cycle)。而後根據統計之機率和
標準差使用 Chebyshev’s Inequality 來估計此
一系統成功執行的可靠度，並視使用者對此
可靠度滿意與否，來決定是否要增加保留給
突發事件之電量，已達到更高的可靠度，或
是犧牲部分可靠度來換取較高的偵測頻率
(Sample rate)，來得到較多的資料筆數。 
System Model
query topology energy
Sample rate for 
each node
Confidence
Evaluate fitness 
Compute confidence 
past statistic
Satisfied with 
the confidence?
Execute 
Compute sample rate
圖一：無線感測器感測排程技術之系統架構
2、以趨勢分析為基礎之感測省電技術： 
研究目的 
近來由於微機電系統及通訊技術的發
達，使得無線感測器的外觀越趨迷你、製造
成本降低、感測功能增強，這也使得它的運
用相對廣泛，舉凡軍事、醫學、環境監測、
居家照顧等都是無線感測器網路的相關應
用。通常無線感測器是使用電池作為電量來
源，由於受限於所處環境之因素，因此，通
常一旦電量耗盡，即失去功能無法再行充
電，當在無法開源(增加電源供應)的狀況下，
如何節流(節省電量消耗)，是無線感測器網路
研究範疇中，相當重要的課題之一。 
先前的感測器資料管理系統，如 TinyDB
與 TAG，其收集資料的方式為定期地偵測環
境變數，並且回傳到資料管理系統，而其偵
測週期是由管理者直接下達指定。若偵測時
間設定較長，則較節省能源，但相對得到較
少的環境資訊；若偵測時間設定過短，則相
對應得到較多資訊，但卻十分耗電。在一般
的感測應用中，如溫度監測等，一段時間內，
如一天內的溫度變化，常具有週期性，那麼
過份密集的偵測，其實並無意義，既耗電且
得到的資訊皆是我們所能預期。有鑑於此，
我們將利用一週期探勘的演算法，針對感測
器所偵測之歷史資料進行分析，探勘這些資
料的週期資訊，並利用所找出的週期特性，
來動態調整偵測時間，以期達到省電的目的。 
研究方法 
 5
下，樹狀式資料遞送擁有精確的查詢結果，
多路徑式資料遞送則僅能提供近似(或錯誤)
的結果。而在網路狀況不佳的條件下，樹狀
式資料遞送將會遺失大部分的感測結果，而
多路徑式資料遞送則保有較佳的容錯能力，
並提供一個較佳的查詢結果。有鑒於此，我
們將提出一個在多路徑式資料遞送方式下，
有效避免聚合查詢重複計算的資料摘要結構
與演算法，並提供一個有誤差保證的近似查
詢結果。 
多路徑式資料遞送方式產生近似結果的
原因，來自於對相同的一筆感測值進行多次
的重複計數(Double Counting)。這樣的問題類
似於傳統資料庫中，針對表格(Relation)中某
個屬性 (Attribute)進行相異值數量 (Distinct 
Value)的估算問題。因此，我們引用線性計算
速寫技術 (Linear Counting Technique)來避免
相同感測器被重覆讀取的問題。 
線性計算速寫技術主要包含一個隨機的
(Randomized)雜湊資料結構。線性計算速算
技術主要用來估算一個多重集合(multi-set)
中，相異值的數量。給定一個多重集合，線
性計算速算技術的使用方法如下。首先，產
生一個長度為 m，初始值為零的位元陣列。
同時引入一個均勻散佈且獨立的雜湊函式，
該函式將給定之多重集合中的元素對應至所
產生的位元陣列，並將所對應到的位址設定
為一。接下來，將所有多重集合中的元素，
對應至位元陣列。最後，計算位元陣列中，
所有非零的位址數目。並利用非零的位址數
目(Vn)，進行相異值的估算。相異值 nˆ ，可利
用下列估算子(estimator)計算: )ln(*ˆ nVmn −= 。 
我們的估算子，可利用統計機率分析的方
式，證明查詢結果擁有極高的近似保證。除
此之外，我們的估算子可根據使用者所給定
的允許誤差進行雜湊資料結構空間的調整，
兼具查詢的準確率與節省資料結構空間使用
的。 
在模擬實驗中，我們使用與[CLK04]相同
的實驗設定，同時實作我們所提出的方法
(LC)，並以 TAG[MFH02]與 ASSTD[CLK04]
為實驗的比較對象。在模擬的環境中我們下
達 Count(*)的聚合查詢，比較調整通訊錯誤
(communication link failure rate)來觀察各方
法的容錯能力。圖三為我們實驗結果，圖中
橫軸為通訊錯誤率，而縱軸為平方根標準錯
誤誤差(RMS)。從圖中可以看到我們的方法
明顯的擁有錯誤容錯率。並且比現階段的方
法擁有更高的準確度。 
4、MAKE DB 感測查詢系統： 
研究目的 
為了提供使用者親切的web-based介
面，利用和SQL相似的(SQL-like)的查詢語
言，來對無線感測器網路下查詢，作資料蒐
集，我們擬設計一系統將底層的低階語言與
上層的使用者介面分開，讓使用者不需要接
觸底層架構即可利用友善介面下查詢，因而
開發了MAKE DB感測查詢系統。同時，此一
系統更可提供我們在無線感測器網路相關研
究上的資料蒐集。 
研究方法 
圖四、MAKE DB 系統架構圖 
0
0.2
0.4
0.6
0.8
1
1.2
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45
ASSTD
LC
TAG2
TAG1
圖三、實驗結果 
 7
method)，在本方法中，每經過 t 個時間，我
們就會計算此時間段中各資料來源流入的資
料，因此，在長度為 W 的移動視窗中，共有
W/t 個不同的資料片段，如圖六所示。當視
窗移動的時候，只需把最舊的 t 時間內的總
和資料移除，再記錄新進的總和資料即可。
二、連續方法(The continuous method)，在本
方 法 中 ， 使 用 指 數 統 計 圖 (exponential 
histogram)的技術，記錄目前最近的移動視窗
中，所有流入資料的時間戳記(timestamp)與
其數值，如圖七所示。並藉由指數統計圖內
資料的時間戳記，刪除已離開目前移動視窗
的資料，來確保指數統計圖內的資料一定是
最近 W 時間內的資料，再利用記錄之數值來
計算移動總和。 
圖六、每 t 個時間點的 CM sketches 
 
圖七、CM sketches 記錄指數統計圖資訊 
2、高頻式樣探勘 
研究目的 
在許多的應用上，如網路監控，無線感
測器網路之資料收集等，都必須處理串流型
態的資料。同時，如同以往在傳統資料庫上
的資料探勘一樣，在串流型態的資料中作資
料探勘，也可能發現許多有用的知識；因此，
在資料串流中的資料探勘研究，儼然成為資
料探勘領域中，非常熱門的研究之一。在本
研究中，我們將在資料串流上作資料探勘的
議題，縮小至高頻式樣探勘(frequent itemsets 
mining)的議題。在資料串流上探勘高頻式樣
的研究中，大部分的方法，都是將原始資料
串流，建立成為一個概要(synopsis)，並假設
此概要能儲存於系統中，而忽略了非高頻式
樣(non-frequent itemset)所佔用的空間，可能
會造成系統資源大幅度地降低，因此我們在
此研究中，結合了 Lossy Counting [MM02]和
hCount [JQS03]的原理，提出了一個新式的概
要結構，使得原始的資料串流可以儲存在此
一固定空間的概要結構中。 
研究方法 
在 Lossy Counting 的方法中，其概要必
須將支持度(support)大於使用者定義之錯誤
容許參數(error parameter)的所有式樣儲存下
來，以達到式樣的估計支持度跟真正支持度
的差異，能保證在小於錯誤容許參數之內。
但因為錯誤容許參數遠小於最小支持度
(minimum support)，使得真正支持度落於錯
誤容許參數和最小支持度之間的式樣數量，
太過龐大，進而造成概要所需儲存空間過
大。相對而言，在 hCount 的方法中，提出一
略圖(sketch)，來將原始資料串流的資訊壓縮
於一個固定空間內，並在回答高頻項目
(frequent items)時，將所有項目一一檢查。因
此，若將 hCount 的方法直接延伸來處理高頻
式樣探勘的問題，在利用該略圖檢查每個式
樣的支持度是否大於最小支持度時，會耗費
相當多的時間。因此針對上述兩個方法的缺
點，我們設計一新式概要，如圖八所示，此
概要由兩個部分組成： 
 
1、雜湊表格(hash table)：利用一雜湊函數
(hash function)將原始串流資料中每個式樣的
資訊，完整記錄在此雜湊表格中，2、高頻節
點(frequent node)：將所有高頻式樣的資訊，
圖八：新式概要結構 
Total_Access 
Nlast_access 
Hash table 
Link 
Itemset
Surplus_Estimate 
True Count 
Node Link
Entry 
Frequent node 
