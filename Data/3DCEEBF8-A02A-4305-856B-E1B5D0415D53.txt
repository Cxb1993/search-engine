  Emulate Large Sensor Array of Handheld Digital Camera  
Tsungnan Lin1, 2, Yennan Shen2 
1Dept of Electrical Engineering and 2Graduate Institute of Communication Engineering,  
National Taiwan University 
Taipei, Taiwan 
 Abstract 
 
The digital cameras can be easily integrated with other 
handheld devices in one single chip. For hardware size and cost 
consideration, the camera sensor array of the PDAs or the 
cellular phones is therefore limited. However, as the demanding 
of better image quality is increasing, the producer needs to 
employ large sensor array for higher image resolutions. 
Therefore, how to emulate large sensor array to raise resolutions 
is a key problem to these devices. In this paper, a novel 
enlargement method on Bayer pattern has been presented. We 
introduce a unified image processing scheme which effectively 
interpolates the sensor array directly for a higher resolution. The 
unified image processing scheme can also lead to efficient 
hardware implementations. Unlike traditional enlargement 
methods which operate only within a color plane, our method 
utilizes the relationship between the distinct channel color 
differences of neighbors and the non-cross weighting-based 
approach. Experimental results indicate the proposed method has 
the ability to emulate efficiently larger sensor array from the 
relation of color difference over local region and edge-sensing 
weight coefficients. The proposed algorithm gives sharp edges 
over the enlarged image without color-bleeding artifacts. Both 
subjective visual evaluation and objective performance 
measurement demonstrate the effectiveness of the proposed 
method. 
I. INTRODUCTION 
HE digital camera gradually becomes the basic equipment 
of the cellular phone and PDA for its portability. Consider 
lowering the hardware cost over the handhelds, the digital 
camera [3] always adopts one sensor rather than 3-sensors to 
capture one single channel for only luminance or chrominance 
information per spatial location. Then the interpolation method 
of demosaicking [4, 10] is used to recover a full-color image. 
The most popular Color Filter Array (CFA) known as Bayer 
pattern [8] is shown in Fig. 1.  
If we add more sensors in one chip, we can get larger CFA 
and get better resolution of a full color image after demosaicking. 
The problem is that it is rather difficult to add more sensors on 
these tiny handheld devices due to the hardware cost and 
compact requirement and, therefore, the way to emulate the large 
sensor [6] is an important issue to the development of the digital 
camera. Although this goal could be achieved by digital zooming 
[9] after demosaicking, the color bleeding artifacts around sharp 
                                                          
This work was supported in part by Taiwan National Science Council 
under grant 94-2622-E-002-006-CC3 and 94-2219-E-002-017. 
or fine edges are amplified. However, if we enlarge the CFA 
directly instead of zooming after the pre-process module of 
eliminating high frequency, we can deal with the information      
 
Figure 1. The CFA data with Bayer pattern.  
 
which is directly obtained from hardware sensors and thus 
generate visually pleasing images. Unlike zooming in the 24-bit 
color image which each plane is interpolated independently with 
respect to each other, CFA zooming needs using cross-channel 
color information to estimate the missing pixels. In addition, 
performing CFA zooming before demosaicking can reduce 
overall computational complexity [5]. 
Lukac [5] performs CFA zooming based on the constant 
color-ratio model which hypothesizes that the quotient of two 
color channels (R/G, B/G) is slowly varying within a local image 
region. By interpolating the hue value, hues are allowed to 
change only gradually.  
In this paper, we develop a cost-effective method to enlarge 
CFA for simulating a large sensor array. We extend the 
non-cross weight [4] in the sensor enlargement domain to keep 
the sharp edges. According to the local image structure, the 
weights are determined based on the approach of 
directional-based signal distance. The idea is to interpolate along 
instead of across the edge boundary. Additionally, we choose to 
interpolate over color difference domain which hypothesizes the 
red and blue channels are perfectly correlated to green channels 
over the extent of the interpolation pixel neighborhood. 
Experimental results indicate the proposed method can 
reconstruct the missing pixel values better and, at the same time,  
preserve the sharp edge information without color-bleeding 
artifacts. Both of the subjective visual evaluation and objective 
performance measurement show the proposed method 
outperforms other existing methods. 
The rest of the paper is organized as follows: next section we 
briefly introduce the non-cross weighting approach; Section III 
presents our method step by step; the experimental results show 
the effectiveness of the proposed method in Section IV and 
Section V concludes the paper. 
T 
 neighboring G components. (d) Interpolate the G components of 
the square center by the color difference between neighboring R 
and B components (e) The enlarged array. 
B. Demosaicking Algorithm 
The enlarged CFA image is then processed similarly into a full 
color image. Demosaicking steps reported previously [4] are 
unified with the CFA zooming procedures in that the weights, 
determined based on the approach of directional-based signal 
distance, are capable of adapting to the local image structure 
which the interpolation is performed in the color difference 
domain instead of the original pixel domain. The unified system 
can only utilize a small number of hardware modules which are 
reused with different parameters.  
  To see the advantages of the proposed mechanism, we analyze 
the interpolated error on a simple image in the following.  
C. Error Analysis of a Simple Geometry 
We [4] have proposed the non-cross weighting approach 
which suggests that the weights should not be calculated cross 
the center point to keep the image edges sharp. Lukac [5] 
determines the weights based on the differences between any of 
the four neighbors around the missing point and the other three 
neighbors. Here we will show a simple example to illustrate the 
difference. Assume a CFA image with a diagonal edge like this: 
R11 G12 R13 G14 R15
G21 BB22 G23 B G25B24
R31 G32 R33 G34 R35
G41 B42 G43 B G45B44
R51 G52 R53 G54 R55
 
Based on the calculation method in [5], the missing g33 over R33 
is calculated as  
{ }
{ }
{ }
{ } ⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
−+
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
−+×
=
∑ ∑
∑ ∑
∈
∈≠
∈
∈≠
43,34,32,23
43,34,32,23,
43,34,32,23
43,34,32,23,
33
1
1
1
1
i
jij
ji
i
jij
ji
i
GG
GG
G
g . 
Our non-cross method generates 
( )( ){ }
( ){ }∑
∑
∈
∈ −×+
−+
−+
×
=
53,35,31,13
2
33
43,34,32,23
2
3323333
33
1
1
1
1
i i
i i
i
RR
RR
G
g , 
where the error can be easily represented as G33-g33. Assume the 
color difference along the diagonal edge is Δ and the image is 
a gray image (R=G=B) with diagonal edge. We can derive the 
error of the weight calculation in [5] as Δ/2 and our proposed 
method has the error about 2Δ/(2 + 2Δ) when Δ>> 1. Fig.3. 
shows the comparative result where x-axis is Δ and y-axis is 
the error. It can be easily seen the traditional weighted sum 
approach is capable of exploiting either horizontal or vertical 
edge efficiently, but fails to detect other-degree edges. While the 
proposed approach is capable of detecting local structure with all 
orientations. 
 
0
20
40
60
80
100
120
140
1 51 101 151 201 251
delta
er
ro
r
Lukac[5]
proposed
 
Fig. 3 The errors of the two methods. Δ is the signal gradient 
along the diagonal edge.  
IV. EXPERIMENT RESULTS 
To evaluate the effectiveness of the proposed algorithm, we test 
on two synthetic images and 20 natural images of Kodak 
PhotoCD. The synthetic images are generated to examine the 
artifacts around the sharp edges. Part A inspects an image with a 
diagonal edge. Part B examines the edges of the enlarged text 
image. Part C examines a number of color images to evaluate the 
proposed digital zooming framework (see Fig. 6).   
We also take two existing methods for comparison. One is the 
digital zooming based on the unified CFA interpolation [5], 
which is based on constant ratio assumption that the R/G and 
B/G is constant over the local region. The other one is the CIZ 
method [5] which uses bilinear interpolation followed by bilinear 
full color image zooms. 
A. Enlargement test for the classical edges 
This experiment applies the CFA zooming algorithm over an 
image with diagonal edges. We retrieve the CFA of the original 
image, enlarge the CFA pattern, and finally demosaick the CFA 
to get the 24-bit full resolution image.  
 
 
    
(a)         (b)          (c)           (d) 
Fig. 4 (a) original test edge; (b) proposed; (c) Luakc [5]; (d) 
CIZ[5]  
The original image with resolution 64×64is shown in Fig. 4(a). 
The enlarged images are with resolution 128×128. We can see 
from Fig. 4(b) that the proposed mechanism can successfully 
keep sharp edges. The artifact in Fig. 4(c) is serious because the 
color ratios over edges change too fast. 
B. Enlargement test for text images 
We then test on text images with the same workflow as A. 
This experiment is to check if our algorithm can keep the 
non-regular edges intact. The text is a complicated image, not 
limit to traditional vertical, horizontal, and diagonal edges. We 
can see from Fig.5 that our method produces the least 
DIRECTIONAL WEIGHTING-BASED DEMOSAICKING ALGORITHM FOR NOISY CFA 
ENVIRONMENTS* 
 
Hung-Yi Lo1, Tsung-Nan Lin1, 2, Chih-Lung Hsu2, and Cheng-Hsien Lee1
 
1Department of Electrical Engineering, 2Graduate Institute of Communication Engineering 
National Taiwan University, Taipei, Taiwan 
 
ABSTRACT 
 
Captured CFA data by image sensors like CCD/or CMOS are often 
corrupted by noises. To produce high quality images acquired by 
CCD/CMOS digital cameras, the problem of noise needs  
addressing. In this paper, we propose a novel demosaicking 
algorithm with the ability to handle noisy CFA data directly. By 
utilizing the proposed spatial filter which can characterize the 
similarity likelihood in local structure accurately, the noisy pixel is 
then filtered depending on the degree of similarity between the 
current pixel and a weighted average of its neighboring pixels. 
Therefore the edge information can be preserved without the 
blurring artifacts while the capacity of noise reduction can be 
adjusted to the maximum degree in the smooth region. Our 
algorithm is the first one that can accomplish the demosaicking 
processing and noise removal simultaneously, which contributes to 
the reduction of hardware cost since one module can achieve two 
functions efficiently at the same time.  
 
1. INTRODUCTION 
 
Most digital still cameras capture images by using color 
filter array (CFA), organized in a mosaic pattern.  The 
most commonly used CFA is Bayer pattern [1] (Fig. 1).  
Observe that green pixels are sampled twice than red or blue 
ones. To obtain full-resolution color images, missing color 
pixels must be estimated from neighboring captured data.  
This process is known as demosaicking. 
  Various demosaicking techniques have been proposed 
[2-7,14].  All of these techniques observed the drawbacks 
of using the traditional bilinear interpolation, which 
introduces visible color bleeding artifacts, referred to as the 
zipper effect, around sharp or fine edges. Zipper effect is 
caused when the used demosaicking scheme cannot 
adaptively estimate the missing pixels according to the local 
image structure. Schemes [12] are proposed to exploit 
spatial correlation of images and to interpolate missing 
colors by a weighted-sum approach. The weights should be 
adaptively changed according to the image local structure as 
the edge indicator. However existing methods are capable of 
detecting either vertical or horizontal edge but fail to detect 
other sophisticated edges efficiently. In addition, existing 
methods’ discussion is limited to the assumption of 
noise-free environment, which is evidently not the case in 
real situations. To produce high quality images acquired by 
CCD/CMOS digital cameras, the problem of noise needs 
addressing. Noise is caused mainly by mean dark current 
and shot/read noise produced during the exposure process.  
Basically the statistic characteristic of such noise can be 
modeled as zero mean additive white Gaussian noise 
(AWGN), as pointed by Khaled et al [8]. 
  
Figure 1: Bayer CFA pattern.  Figure 2 Adaptiveness of the 
noise reduction filter.  
 
Kalevo [10] tried to use multistage median filter and 
median rational hybrid filters to solve this problem.  
However, their approach did not take the demosaicking 
algorithm into account and cannot generate high-quality 
color images.  
  In this paper, our focus is geared toward designing a 
demosaicking algorithm with the ability to handle noisy 
CFA data directly. We have previously reported [9] an 
adaptive spatial filter that can exploit local image structures 
more efficiently compared to other existing methods [2-5]. 
We extend previous filter design to estimate the missing 
color pixels by taking more captured pixels into account. 
The accuracy of the estimation can be improved accordingly 
because more information is utilized. Additionally, the 
weighting function is modified based on the noise statistical 
characteristics [12]. Therefore, to our best knowledge, our 
algorithm is the first one that can accomplish the 
demosaicking processing and noise removal simultaneously, 
which contributes to the reduction of hardware cost since 
one module can achieve two functions efficiently at the 
same time. Simulation results demonstrate the effectiveness 
of the proposed algorithm.  
 * This work was supported in part by Taiwan National Science Council 
under grant 94-2622-E-002-006-CC3 and 94-2815-C-002-070-E. 
 
2. AN ADAPTIVE FILTER OF DETECTING ALL 
Use equation (2), and then use the following equation to 
find B(m,n) on existing R(m,n) : 
∑
∑
=
=
−⋅
−= 8
5
8
5
15 )(
),(),(
i
i
i
iii
W
BGW
nmGnmB          (6) 
where Gi5 have the same values as BBi1 for all i.  Existing 
blue pixels follow similar way. 
  Step 3: Interpolate R and B values on existing green 
pixels: Find R(r,s) and B(r,s) on G(r,s). 
4
)(
),(),(
4
1
21∑
=
−⋅
−= i
iii RGW
srGsrR            (7) 
The values of v and h for Gi1 are the same as listed in Table 
1.  Ri2 has the same value as Gi1.  Blue value follows the 
same way. 
3. NOISY BAYER IMAGE 
 
3.1. Noise Removal in CFA  
Captured CFA data by image sensors like CCD/or CMOS 
are often corrupted by noises. Noises are mainly brought 
about by the dark current, read noise, and the variation of 
pixel output voltage associated with the variation in the 
diode capacitance [8]. Such a disturbance is commonly 
referred as granular noise. Basically the statistical 
characteristic of such noise can be modeled as zero mean 
additive white Gaussian noise [12] as follows 
]
2
)(exp[
2
1)( 2
2
σπση
zz −=              (8) 
, where z is the image level and σ is the standard deviation. 
      The simplest noise-reduction filter is the arithmetic 
mean filter. However, the smooth filter degrades the image 
quality by blurring the sharp edges and fine details. In this 
paper, we propose an adaptive noise removal filter. The 
weighting function introduced in Section 2.2 accurately 
characterizes the similarity likelihood in the local structure. 
The noisy pixel is then filtered depending on the degree of 
similarity between the current pixel and a weighted average 
of its neighboring pixels. Additionally, the noise-reduction 
process is applied directly in the captured CFA data as 
follows:  
)),()(,(),(),( MjiXjiWjiXjiX −−=∧       (9) 
 
Where X is the captured color pixels (R,G, B) in CFA data, 
W is the weighting function calculated according to 
Eq.(1)~(2), and M is the planar expected value calculated 
according to Eq.(3)~(5). From Eq. 9, it is easily observed 
that the proposed filter is equivalent to the arithmetic 
smooth filter when the W(i,j) is equal to one, which occurs 
when the pixel X and planar expected value M  have high 
degree of similarity.  
    Since the similarity of the local image structure is 
based on the weighting function, it is important to modify 
the function according to the statistical characteristic of the 
granular noise. According to Eq. 1 and 2, the value of the 
weight is calculated based on the distance function between 
R(m,n) and Ri in a noise-free environment. However, in a 
noisy environment, the distance may not be zero, due to the 
noise, even when the two pixels are the same. Therefore, the 
curve of the weighting function should be increased to 
compensate the phenomenon that the distance is caused by 
the noise, not the image structure. The adaptive approach of 
the proposed filter is clearly visible in Fig. 2 where the light 
gray zones represent heavily filtered areas and the dark gray 
zones represent lightly filtered areas. After the noisy CFA 
data is filtered, the 24-bit full resolution image can be 
obtained based on the procedures of Sec 2.2.  
 
 
4. EXPERIMENTAL RESULTS 
Twenty benchmark images from the Kodak photo sampler 
are evaluated for both noise-free and noisy environments. 
These images are first sampled with Bayer CFA to produce 
mosaic images, and then used as the input for interpolation. 
For noise simulation, the noise (with standard deviation 
from 1 to 15) is added into the CFA data. In the noise-free 
environments, the PSNR results and its comparison with 
other existing methods [5] are shown in Table 2. We 
compare results of3 best pre-filter mechanisms discussed in 
[10] for the noisy environments. Fig 4 shows the proposed 
mechanism outperforms the methods [10] in all R, G, B 
planes in the noisy environments. The results of real images 
comparison with the noise (σ=10) are demonstrated in Fig. 5 
and Fig. 6. 
 
5. CONCLUSION 
 
In this paper, we propose a novel demosaicking algorithm 
with the ability to handle noisy CFA data directly. By 
utilizing the proposed spatial filter which can characterize 
the similarity likelihood in local structure, the noisy pixel is 
then filtered depending on the degree of similarity between 
the current pixel and a weighted average of its neighboring 
pixels. Therefore the edge information can be preserved 
without the blurring artifacts while the capacity of noise 
reduction can be adjusted to the maximum degree in the 
smooth region. Simulation results demonstrate the 
effectiveness of the proposed mechanism for both noise-free 
and noisy environments.  
 
REFERENCES 
[1] B. E. Bayer, “Color Imaging Array,” U.S.Patent, no. 3,971,065, 1976. 
[2] S.C. Pei and I.K. Tam, “Effective Color Interpolation in CCD Color 
Filter Arrays Using Signal Correlation,” IEEE Transactions on Circuits and 
Systems for Video Technology, Vol.13, pp. 503-513, No.6, June 2003. 
[3] Lukac, R.; Plataniotis, K.N., "Color filter arrays: design and 
performance analysis," IEEE Transactions on Consumer Electronics, 
Volume 51, Issue 4, pp.1260 - 1267, Nov. 2005. 
[4] Xiaomeng Wang, Weisi Lin, and Ping Xue;, “Demosaicing with 
Improved Edge Direction Detection,” IEEE International Symposium 
on Circuits and Systems, pp. 2048-2051, May 2005.
