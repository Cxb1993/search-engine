0A Practical Design of Digital Video Watermarking
for Content Authentication
Po-Chyi Su, Member, IEEE, Ing-Fan Chen and Chun-Chieh Chen
Abstract—In this research, we propose a practical digital
watermarking scheme under the framework of H.264/AVC.
The scheme is mainly used for the authentication of digital
videos to ensure the correct content order. The watermark
signal is embedded into quantization indices of intra-coded
frames to not only ensure the effectiveness of watermark-
ing but also maintain the compact size of video data. The
coding procedure of H.264/AVC is taken into account in the
design of watermark embedding/detection. The luminance
masking of Watson’s visual model is employed to guarantee
the imperceptibility of watermark signal and to achieve a
practical implementation. In order to extract the hidden
information from a given video segment, key frames are
selected from the investigated video and a distortion-
resilient hash value will be attained to help determine
the random sequence used for scrambling the watermark
signal. The experimental results demonstrate the feasibility
of the proposed video authentication system.
Index Terms— Digital watermark, H.264/AVC, authentica-
tion, scene change, hash.
I. INTRODUCTION
THE authentication of multimedia data [1], [2]has drawn tremendous attention in these years
due to the fact that digital data can be manipu-
lated easily by convenient editing facilities. The
conventional methods to authenticate digital data
involve calculating a cryptographic checksum or
a digest from the digital message and sent along.
The authenticator calculates the digest and com-
pares it with the received one to determine if the
message has been modified. Although the con-
ventional authentication techniques perform well
when we require bit-by-bit accuracy, the scenario
for multimedia data may be different. Multimedia
P.-C. Su and I.-F. Chen are with the Department of Computer
Science and Information Engineering, National Central University,
Jongli, Taiwan, e-mail: pochyisu@csie.ncu.edu.tw. C.-C. Chen is
with the Graduate Institute of Networking and Multimedia, National
Taiwan University, Taipei, Taiwan.
This research was supported in part by the National Science
Council in Taiwan, under Grant 96-2221-E-008-098-
users care more about whether the meaning of data
has been intentionally modified, instead of sparse
binary errors, which may be caused by transmission,
storage or necessary data processing procedures. For
example, the lossy compression is usually applied
on multimedia data and should thus be viewed as
an allowed data modification since the content is
not changed to affect the usage of the multimedia
data. In many proposed multimedia authentication
schemes, the ability of locating the tampered por-
tion of data is also required to help identify the
attackers’ motivation. Among the multimedia data,
digital videos play an increasingly important role
nowadays in many aspects. Therefore, we focus on
further ensuring the authenticity of digital videos in
this research.
The most common manipulations on digital
videos are such editing processes as deleting, insert-
ing, replacing or repeating video shots. The careful
editing will change the content or meaning of the
video significantly and unnoticeably. Our objectives
are detecting the attack and further identifying the
way of frame/shot manipulation. Generally speak-
ing, there are two major methodologies of mul-
timedia authentication: signature-based and digital
watermarking approaches. The signatured-based ap-
proaches are similar to conventional methodologies
in that the digest or signature is generated and ap-
pended to the data for authentication. Nevertheless,
the extracted digest will be resilient to the lossy
compression but sensitive to malicious attacks. The
major advantage of the signature-based approaches
is that the multimedia content will not be affected
at all. Beside, the encrypted digest is assumed to be
reliable for checking the authenticity. By sophisti-
cated designs, the digest size can be kept small to
avoid increasing the total data volume. For digital
videos, although the signature-based approaches can
detect the appearance of attacks and even locate
the tampered pixels within a video frame, the loss
of synchronization between the video frames and
2the multiple functions [5], increasing the security
[6], the advanced detector [7], [8] or the robust
embedding to resist H.264/AVC lossy compres-
sion [9]. The issues of the increased watermarked
video size and/or the synchronization problem in
the watermark detection from the cropped video
are sometimes ignored or not emphasized in some
existing researches. In our opinions, a feasible video
watermarking scheme should take these issues into
serious consideration. Besides, as the research of
digital watermarking is quite application-oriented.
The lack of a specific objective is one of the short-
comings in the existing watermarking schemes. In
this research, we will take the coding procedure
of H.264/AVC into account to develop a practical
watermarking scheme, which is targeted at authen-
ticating H.264/AVC compressed videos.
III. WATERMARK EMBEDDING
The flowchart of watermark embedding with the
H.264/AVC encoder is shown in Fig.1. The embed-
ding process is demonstrated within the bounding
box. We first discuss the data selected for water-
marking. As in many existing digital watermark-
ing schemes, the watermark will be embedded in
transform coefficients. To better combine the water-
marking and coding procedures, the watermark is
embedded into quantization indices to avoid being
affected by the lossy quantization step. Besides, we
only embed the digital watermark in I-slices, or
actually I-frames. As predicted frames make use of
the temporal prediction for efficient compression,
the data rate will be substantially lower and the
watermark embedding in these predicted frames
will increase the data volume radically and may
affect the normal usage of video. This problem
may become even more serious when we choose
to modify the quantization indices of residuals. To
be more specific, we will embed the serial number
into I frames and the detection of the wrong serial
number will inform us of a possible tampering.
Since our target application is to authenticate digital
videos, there may exist concerns that embedding the
watermark in I frames may protect these frames
only, instead of the entire video. In our opinions,
intra-coding frames have to appear periodically to
maintain a good video quality. Under a typical
setting of video coding, any meaningful video edit-
ing should affect at least one or two I frames
so ensuring these I frames in the correct order
should be sufficient. One may also question that
the tampering applied on predicted frames without
modifying the content in I frames may pass the
authentication checking. However, the video always
has to be visually acceptable by the human eyes
and it should be challenging to produce a useful
or meaningful video copy by this attack. If the
authentication on predicted frames is necessary in
certain cases, we may suggest to embed the water-
mark in intra-coded macroblocks in these predicted
frames to avoid affecting the video severely. Several
predicted frames will be required for one watermark
detection to ensure the acceptable false positive and
negative rates [8]. By considering that the values
represented by the watermark signal will change
after a fixed period of time in our application to
reflect the video content order and that the compact
size of compressed videos should be maintained, we
do not think embedding the watermark in predicted
frames is worthwhile.
Fn-1
Fn
Scene Change
(SC) detection
SC frame
buffer
VQ-based hash
generation
Shot order
sequences
Luminance
masking
Watermark
signal
Shot order
number
Watermark
embedding
ME
MCF’n-1
Intra
prediction
T Q
intra
inter
FilterF’n
+
-
T-1 Q-1
Entropy 
encoder
+
+uF’n
Choose Intra
prediction
JND to
Quan. Index
NAL
+ +
0
Intra
frame
inter
frame
Qp
Fig. 1. The flowchart of watermark embedding process.
Because a DCT-like transform is used in
H.264/AVC, our watermark embedding will be
based on Watson’s perceptual model [10] to meet
the requirement of imperceptibility. Watson’s per-
ceptual model helps in determining the amount
of watermark energy or Just Noticeable Difference
(JND) that is allowed to be embedded into each
coefficient. The model basically takes two masking
effects into account, i.e. the luminance masking and
contrast masking. The luminance masking refers
to the dependency of the visual threshold and the
mean luminance of the local image region while the
contrast masking indicates that the threshold for a
4by
q′i,j,k =
{
0,
ei,j,k
qi,j,k
≤ −1
qi,j,k + ei,j,k, otherwise.
(5)
When ei,j,k
qi,j,k
≤ −1, we prevent qi,j,k and q′i,j,k to be
of different signs by assigning 0 to q′i,j,k.
It is worth noting that using a fixed r in the entire
video may raise certain security concerns. To be
more specific, the attacker may choose to average
several visually different frames to determine the
hidden sequence and then apply the reverse embed-
ding to weaken the hidden signal. Although using
different scrambling sequences will help to increase
the difficulty of “guessing” the watermark sequence
by attackers, it may also complicate the watermark
detection process. For example, if only one segment
of the investigated video is chosen for watermark
detection, it will be difficult to know exactly which
scrambling sequence is used in a specific frame. In
our scheme, the scrambling sequence r is generated
by using a hash-like value , h, as the seed. h
will be calculated from the video content to make
the scrambling sequence content-adaptive. The other
advantage of this strategy is to avoid the so-called
“copy attack” [14], in which the attacker can extract
the noises, which may contain watermark signals,
from the video frame, tamper the frame content and
then put the noises back to the tampered frame to
make a fake frame that can pass the authentication
process. Unlike the traditional hashing algorithm,
in which the hash value will be different even
when one bit error happens, a compression resilient
hash is derived to accommodate the applications of
digital watermarking. We choose to extract the key
frames, which are the frames of shot boundaries, for
calculating the hash value used for generating the
scrambling sequence in an entire shot. We apply
the scene change detection from the raw frames in
the investigated video before watermark embedding.
The histograms of adjacent frames will be com-
pared. In other words,
Zm =
Nbins∑
b=1
|Hm(b)−Hm−1(b)|, (6)
where Nbins is the total number of bins in the
luminance, and Hm is the histogram associated with
the frame, m. If Zm is larger than a threshold, Tc,
the scene change is ruled as happening in the frame
m. The hash value calculated from the frame of
scene change will be used in watermarking a future
I frame. It should be noted that we do not make the
scrambling sequence depend on every single frame
since the scrambling sequence is also required in
the decoder side and we do not expect the decoder
to extract all the frames for watermark detection.
Given the frame of scene change, we will gen-
erate a hash according to this frame content and it
will be used in an entire shot. We use our previously
proposed approach [15] of generating the feature
code in a signature-based authentication scheme.
For a 352 × 288 video frame, we down-sample it
to 22 × 18 and extract the central 16 × 16 block.
We then apply singular value decomposition on this
mean-removed block, X, to decompose it as
X = UΛVT =
16∑
i=1
λ
1
2
i uiv
T
i , (7)
where ui, vi are columns of U, V, representing
eigenvectors of XXT and XTX, respectively, and
Λ is a diagonal matrix with eigenvalues λ1 ≥
λ2 ≥ . . . ≥ λm on the diagonal line. We choose
the first eigenvectors, u1 and v1 as the extracted
feature of the block. We use the maximum distance
approach [16] to train the Vector Quantization (VQ)
codebooks of Cu for u1 and Cv for v1. The codebook
indices for u1 and v1 will then be used as a seed
to generate the scrambling sequence.
As mentioned before, the first frame of the scene
will be picked to calculate the shot hash value.
However, it should be worth noting that, given that
there are three shots, Si, Sj and Sk and the scene
change frame between Si and Sj is Fi,j , we will
use Fi,j to generate the scrambling sequence for Sk,
instead of Sj, so that we can link the adjacent shots
to avoid misses of detections if replacing or deleting
shots has been applied. This design shows that we
aim at ensuring the “shot order” in the video, instead
of the “frame order” because we think the order of
shots is more important. Therefore, in Fig.1, a scene
change buffer is used to store the previous frame of
scene change to generate the hash for the next shot.
IV. WATERMARK DETECTION
The flowchart of watermark detection with the
H.264/AVC decoder is shown in Fig.3. Again, the
watermark detection is shown within the bounding
box. The watermark detection is applied on quanti-
zation indices directly and is based on the following:
ρNt =
1
‖ qˆ ‖
∑
qˆi,j,k 6=0
qˆi,j,k × (rn × sNtn × pi,j), (8)
6TABLE I
THE COMPARISONS OF THE ORIGINAL AND WATERMARKED
VIDEOS
Original H.264 video Watermarked H.264 video
Video Bit-rate PSNR Bit-rate PSNR
Monitor 423Kbps 37.91dB 433Kbps 37.56dB
Stefan 1469Kbps 35.58dB 1504Kbps 35.04dB
Foreman 547Kbps 37.07dB 566Kbps 36.69dB
Akiyo 381Kbps 38.42dB 399Kbps 37.83dB
by Pm, is chosen and Pr(I)pm is compared to the
other threshold TP . If Pr(I)pm > TP , we expand Pm
and compare its histogram with those of Ii and
Ij to determine the actual scene change. Else, we
expand the frame right before Ij and compare the
histograms to determine the exact frame of shot
boundary. In other words, only the I frames and
predicted frames with possible scene change will
be expanded to the full frame size for hash-value
calculation. Since the number of such frames is
not large, in terms of efficiency, this procedure
should be acceptable. It is worth noting that the
major challenge here is to make the watermark
embedder and detector select the same frame of
scene change for hash-value calculation. As we have
to determine the scene change by checking the intra-
prediction modes in I frames, the number of intra-
coded macroblocks in P frames and sometimes have
to expand the full frame to calculate the histogram
difference, the watermark detection will not proceed
on the fly with the decoding process. In other words,
the quantization indices of frames have to be stored
for the subsequent watermark detection.
V. EXPERIMENTAL RESULTS
In the experiments, we adopt the H.264/AVC
baseline mode to make the encoding faster. One I
frame is followed by 9 P frames so the watermark
is embedded every ten frames. The PSNR drop
and video size increase are shown in Table.I. Four
CIF videos with 300 frames are tested. It should
be noted that we do not turn on the rate control
and set QP=28 so that we can see the effects of
watermarking more clearly. The results are satisfac-
tory as the bit-rate increase and quality degradation
are limited. Since only the luminance masking of
Watson’s model is used in weighting the embedded
watermark, the perceptual quality is not severely
affected.
Next, we will test the robustness of the watermark
against the allowable transcoding procedures and
then apply manipulations of frames to demonstrate
the ability of locating tampered frames in the
proposed scheme. Two transcoding processes are
considered, including the change of QP and the
different number of consecutive P frames follow-
ing an I frame. The results are shown in Fig.4.
The circles marked in Fig.4(a) indicate the peak
values of watermark detection responses in each
frame without any transcoding and the watermark
is correctly detected. Then we change the QP from
28 to 30 and 32 and the peak values are shown as
diamond and square marks, respectively. Again the
watermark can be detected easily. It may be a bit
surprising that larger QP values, which will decrease
the video sizes, may have even larger responses
as shown in Fig.4(a). The larger responses come
from the use of normalization factor, ‖ qˆ ‖, as
shown in Eq.(8). We then change the number of
P frames during transcoding. Here we change, in
MPEG language, the GOP size from 10 to 15 and
Fig.4(b) shows that the responses of GOP=15 in
multiples of 10 frames (marked as diamonds) are
high enough to detect the correct serial numbers.
0 20 40 60 80 100
0
5
10
15
20
25
30
35
40
45
Frame Number
W
at
er
m
ar
k 
D
et
ec
tio
n 
R
es
po
ns
e
Change of QP
 
 
QP=28
QP=30
QP=32
(a)
0 20 40 60 80 100
0
5
10
15
20
25
30
35
40
45
50
Frame Number
W
at
er
m
ar
k 
D
et
ec
tio
n 
R
es
po
ns
e
Change of Consecutive P frames
 
 
GOP=10
GOP=15
(b)
Fig. 4. The watermark detections for transcoding by (a) changing
the QP and (b) changing the GOP size.
8REFERENCES
[1] B. Zhu, M. Swanson, and A. Tewfik, “When seeing isn’t believ-
ing - current multimedia authentication technologies and their
applications,” in IEEE Signal Processing Magazine, vol. 21,
Mar. 2004, pp. 40–49.
[2] F. Bartolini, A. Tefas, M. Barni, and I. Pitas, “Image authenti-
cation techniques for surveillance applications,” in Proc. IEEE,
vol. 89, no. 10, Oct. 2001, pp. 1403–1418.
[3] J. Zhang, A. Ho, G. Qiu, and P. Marziliano, “Robust video
watermarking of H.264/AVC,” in IEEE Transactions on Circuits
and System-II: Express Briefs, vol. 54, no. 2, February 2007,
pp. 205–209.
[4] M. Yang and N. Bourbakis, “A high bitrate information hiding
algorithm for digital video content under H.264/AVC compres-
sion,” in IEEE Int. Sym. On Circuits and Systems, vol. 2, August
2005, pp. 935–938.
[5] G. Qiu, P. Marziliano, A. Ho, D. He, and Q. Sun, “A hybrid
watermarking scheme for H.264/AVC video,” in Proceedings
of the 17th International Conference on Pattern Recognition,
ICPR, vol. 4, August 2004, pp. 865–868.
[6] M. Noorkami and R. M. Mersereau, “Compressed-domain
video watermarking for H.264,” in Proceedings of the Interna-
tional Conference on Image Processing, ICIP, vol. 2, September
2005, pp. 890–893.
[7] ——, “A framework for robust watermarking of H.264-encoded
video with controllable detection performance,” in IEEE Trans.
Inf. Forensics Security, vol. 2, no. 1, Mar. 2007, pp. 14–23.
[8] ——, “Digital video watermarking in P-frames with controlled
video bit-rate increase,” in IEEE Trans. on Information Foren-
sics and Security, vol. 3, no. 3, Sep. 2008, pp. 441–455.
[9] G.-Z. Wu, Y.-J. Wang, and W.-H. Hsu, “Robust watermark
embedding/detection algorithm for H.264 video,” in Journal of
Electronic Imaging, vol. 14, Jan.-Mar. 2005.
[10] A. B. Watson, “DCT quantization matrices visually optimized
for individual images,” in Proc. SPIE, Human Vision, Visual
Processing, and Digital Display, vol. 1913, Bellingham, WA,
1993, pp. 202–216.
[11] A. J. Ahumada and H. A. Peterson, “Luminance-model-based
DCT quantization for color image compression,” in Proc. SPIE,
vol. 1666, San Jose, CA, 1992, pp. 365–374.
[12] C. I. Podilchuk and W. Zeng, “Image-adaptive watermarking
using visual models,” IEEE Journal on Selected Areas in
Communications, vol. 16, no. 4, May 1998.
[13] D. Simitopoulos, S. A. Tsaftaris, N. V. Boulgouris, and M. G.
Strintzis, “Compressed-domain video watermarking of MPEG
streams,” in IEEE Int. Conf. Multimedia and Expo., vol. 1, no. 1,
2002, pp. 569–572.
[14] C.-S. Lu, H.-Y. M. Liao, and M. Kutter, “Denoising and
copy attacks resilient watermarking by exploiting knowledge at
detector,” in IEEE Transatctions on Image Processing, vol. 11,
no. 3, 2002.
[15] P.-C. Su, C.-C. Chen, and H.-M. Chang, “Towards effective
content authentication for digital videos by employing feature
extraction and quantization,” in IEEE Trans. on Circuits and
Systems for Video Technology, to appear.
[16] I. Katsavounidis, C.-C. Kuo, and Z. Zhang, “A new initialization
technique for generalized Lloyd iteration,” in IEEE Signal
Processing Letters, vol. 1, Oct. 1994, pp. 144–146.
not be significantly increased. I was questioned by Prof. Kuo about the weakness of 
using the luminance masking of watermark embedding. I replied that, although the 
embedded watermark maybe weaker, the use of luminance masking in Watson’s 
visual model can help to integrate the scheme in H.264/AVC coding flow and the 
targeted objective of video authentication can still be achieved. 
♦ “Fragile Video Watermarking Technique by Motion Field Embedding with 
Rate-distortion Minimization,” Tien-Ying Kuo, Yi-Chung Lo, and Chen-I Lin, 
National Taipei University of Technology, Taiwan 
Mr. Lo presented this paper. The idea is to divide the motion estimation modes into 
groups by experiments. The embedded information will force the motion estimation 
to be restricted to certain groups. By the careful design, the video rate may not be 
significantly affected as the rate-distortion minimization is considered. I think the 
work is well-presented. 
♦ “A Novel Watermarking Method For Wyner-Ziv Video Coding,” Ning Zhu, 
Guiguang Ding, Yaguang Yin, and Jianmin Wang, Tsinghua University, China. 
Ms. Zhu presented the paper. The proposed scheme integrates the Wyner-Ziv video 
coding with digital watermarking. I raised a question regarding to the application 
since, in my personal opinions, digital watermarking is an application-oriented field 
so we always have to take the applications into account to ensure that the proposed 
ideas are practical. 
 
In fact, there are other two papers in this session. 
However, the authors didn’t show up probably because 
the traveling expense was quite high in China in that 
period of time since Beijing Olympic was held at the 
same time. 
 
There are several sessions in this 3-day conference. 
I attended some sessions related to multimedia security. 
But I think the key-note speeches may be a better part in 
this conference:  
 
The speaker of Keynote Speech(I) is Professor Ton Kalker, the Distinguished 
Technologist at Hewlett-Packard Labs in Palo Alto. Prof. Kalker is a pioneer in the field of 
digital watermarking. I know Prof. Kalker quite early, back to 1999 when he led the 
"Millennium" team of Philips to compete for the standardization of video watermarking for 
DVD copy protection and I helped to review. The title of his talk in IIHMSP is "The State of 
Reversible Watermarking." The ideas of Reversible Watermarking are quite interesting. The 
methodology can fully reconstruct the original host media to avoid the concern that the host 
media and the associated applications may be affected by the watermarking processes. The 
overview of the development is given, starting from simple schemes and ending with 
