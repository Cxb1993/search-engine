 1
行政院國家科學委員會專題研究計畫報告 
考量實際擺放位置改善壓降現象之測試樣本產生研究 (2/2) 
計畫編號：NSC 99-2221-E-007-116-MY2 
執行期間：100 年 8 月 1 日至 101 年 7 月 31 日 
主持人：黃婷婷 清華大學資訊工程系 教授
 
一、 中英文摘要: 
隨著製程技術的進步和晶片複雜度的提升，延遲
錯誤測試(delay-fault test)越來越受到重視。主要的
原因來自在 0.13um 以下更先進製程中，製造瑕
疵(defect)對晶片帶來的影響大多與時序(timing)
有關。為了確保電路能正常運作，同速測試
(at-speed test)技術廣泛的使用在時序相關缺
陷的偵測，其中在同速測試的技術中，最普遍採
用為 scan-test launch-off-capture 的架構。同速測
試主要的方法就是引發邏輯閘(gate)的電位切換
(switching)，來驗證這些電位切換所經過的路徑延
遲(path-delay)是否違反晶片要求。因此在測試過
程中，受測電路會產生高於一般運作時的電位切
換。進而引起較嚴重的壓降(IR-drop)現象，而壓
降則會增加路徑延遲進而導致測試錯誤，這種因
為測試所導致的晶片不正常動作則是一種誤判
(falsefailures)，進而有可能導致測試失敗使得良率
降 (yield-loss)。近年來，為了改善壓降的問題，
post-ATPG X-bit filling(X-filling)是一個用且有效
的方法，我們將在這個計畫的第一年研究一個新
的 X-filling 方法，相較於較早的研究，我們的方
法將會考量邏輯閘實際擺放位置考量(physical 
location aware) ， 並 且 提 出 一 個
backward-propagation 的 filling 方法來取代先前
基於機率的 forwarding-propagation 方法，使其能
更有效的利用 x-bit 降低壓降。 
此外 X-filling 改善壓降的效果會限制於原始測
試樣本(test pattern)中 x-bit 的分布形，這是因為測
試樣本中的 x-bit 無法影響壓降嚴重區域的邏輯
閘的值。因此，在計畫的第二年，我們將提出一
個新的 X-identification 的方法來尋找 x-bit 其訊
號傳遞的路徑可以經過壓降較嚴重的區塊，使得
X-filling 可以利用而進一步改善壓降。 
 
關鍵詞 : 同速掃描測試，壓降改善，忽略位元填 
 
充，忽略位元辨別，實體位置考量。 
 
二、 研究計畫之背景及目的 
 
隨著製程技術的進步和晶片複雜度的提升，延遲
錯誤測試(delay-fault testing)越來越受到重視。主
要的原因來自在 0.13um 以下更先進製程中，製
造瑕疵 (defect)對晶片帶來的影響大多與時序
(timing)有關。為了確保電路能正常運作，同速測
試(at-speed test)技術廣泛的使用在時序相關缺陷
的偵測。舉例說明：Swanson 和 Lange [1] 指出
在傳統的固定錯誤測試中(stuck-at fault test)中，加
入同速測試可以降低約 30%到 70%的 defects per 
million (DPM)。而 Gatej 等作者 [2] 則提出在
0.18um 的晶片測試流程內，若將同速測試在程式
樣本中移除，則會增加 3%的 escape rate。同時，
也因為電路速度邁向千兆赫 (GHz)和測試成本的
提高，測試速度也不斷的提升，在 ITRS [3] 的報
告中指出自動測試設備 (ATE) 在延遲錯誤測試
的環境下，已經可以成功達到 6Gb/s 的測試速
度。延遲錯誤測試在高速運作的晶片中更顯得重
要。 
在同速測試的技術中，以掃描串基處(scan-based)
的延遲錯誤測試分為兩大類 : (1)觸發後位移 
(Launch-off-shift, LOS) 和 (2) 觸 發 後 擷 取 
(Launch-off-capture, LOC)，由於觸發後擷取電路
訊號切換不需要太高的頻率且成本較低，故本次
計畫使用觸發後擷取來當作延遲錯誤測。其執行
的程序簡單說明如下：我們將 launch-off-capture 
架構的時序圖表是在圖一上圖中，而下圖中 FF、
FF’、FF”則分別代表 last-shift、launch、capture 三
個 cycle 完成時所對應正反器(flip-flop)的值，三
個 cycle 分別說明如下： 
1. last-shift cycle: 測試樣本(test pattern)的測試資
料已經全部都移至對應的正反器(FF)中，而這些
測 試 資 料 將 會 經 過 邏 輯 路 徑 (combinational 
logic)，回到正反器的輸入，等待下一個 cycle 發
生。 
 3
X-filling 並不一定能影響到需要減少電位切換的
邏輯閘，尤其是經過越長的邏輯路徑才能到達的
邏輯閘，另一方面，未考慮區域所計算的壓降
(IR-drop)與實際的壓降有很大的差異。因此，我
們 將 研 究 一 個 新 的 實 際 擺 放 位 置 考 量
(physical-location-aware)減少壓降的 X-filling 方
法。 
此外，X-filling 改善壓降(IR-drop)的效果與 x-bit 
的數量和訊號傳遞路徑息息相關，因此利用
X-identification[13][14]的方法，去增加或改變x-bit 
數量對於改善壓降的影響也是一個重要的方法。
因為測試樣本(test pattern)中所測試的目標錯誤
(target fault)不同，所擁有的 x-bit 數量、位置也隨
之不相同，而這些 x-bit 比例也會因為測試樣本的
壓縮(test pattern compression)而改變，舉例來說，
我們使用 TetraMAX 產生並經過壓縮的測試樣本
(test pattern)，呈現於三角形代表於圖二中。我們
可以觀察到前面部分的測試樣本其 x-bit 比例
(X-ratio)較低，這是由於測試樣本進行壓縮過程
時，會盡量將目標錯誤向較前產生的測試樣本做
合併，使得前面部分的測試樣本含有較少的 x-bit
以及要偵測較多的延遲錯誤(delay fault)。因此
Kohei Miyase 等作者 [14] 提出 DC-XID 方法來
改表一變所有測試樣本的 x-bit 比例，他們使所有
的測試樣本的 x-bit 比例盡量平均分配，由圖二所
示， 
圖二 
我們可以發現經過 DC-XID 方法處理之後，在每
一個測試樣本中的 x-bit 的分布較原始測試樣本
平均，因此在 X-filling 的過程中可以更有彈性的
進行。 
然而，在改善壓降(IR-drop)主要仍受限於原測試
樣本(test pattern)的 x-bit 分布情形及 hot spot 的位
置，在 DC-XID 方法中只針對 x-bit 比例而處理，
這樣的方法無法直接解決壓降(IR-drop)問題。舉
例來說，如果測試樣本有發生如圖三所示的狀
況：假設測試樣本為 { X1, X2, X3, …, Xn }，若
Xi 填值 (0 or 1) 後 Xi 訊號能傳遞的所有路徑都
無法經過壓降較嚴重的地方(Hot Spot)，則此 Xi 
無法有效改善壓降。換句話說，若測試樣本的 x-bit 
均無法控制位於壓降嚴重的區域的邏輯閘，則利
用 X-filling 改善此測試樣本的壓降問題將會較不
顯著。 
圖三 
在此種狀況發生時，我們可以在 X-filling 之後，
保留已改善的壓降效果下，進一步的使用
X-identification 將測試樣本找出可繼續改善壓降
的 x-bit。主要的動機便是選出新的 x-bit 其訊號
傳遞的路徑可以經過壓降較嚴重的區塊，使得
X-filling 可以利用而進一步改善壓降。因此本計
劃的目的將提出針對上述的問題，對下列兩項問
題加以研究: 
 
(一)、考量實際擺放位置利用 X 填滿降低壓降現
象(physical-location-aware X-filling for IR-drop 
minimization) (第一年部分已於 100 年完成) 
(二)、考量實際擺放位置利用 X 分布降低壓降現
象 (physical-location-aware X-identification for 
IR-drop minimization)  
 
三、 研究方法及進行步驟 
 
(一)、考量實際擺放位置利用 X 填滿降低壓降現 
圖四為第一年度 X-filling 降低壓降現象流程圖。
(此為第一年度計畫已於 100 年完成) 
 5
的輸出，對壓降影響的關係。我們以圖五來舉例，
在圖五中我們將測試樣本中 Sa 和 Sb 兩個
specified-bit，其 launch-cycle 和 capture-cycle 所
傳遞的路徑都進行模擬，我們可以發現 Sb 沒有經
過壓降較嚴重的區域(hot spot)而 Sa 有經過，我們
可以使用這樣的模擬方式給予選擇 Sa 和 Sb 成為
新的 x-bit 時對於改善壓降的影響評估。其詳細的
評估方式可參閱附件論文。 
 
圖五 
 
(3) Recovery of fault coverage 
 
由於 X-identification 會利用移除目標錯誤(target 
fault)來增加 x-bit 數量，若移除的目標錯誤為主
要錯誤(essential fault)，這樣會造成測試錯誤涵蓋
率(fault coverage)降低。因此，我們需要產生額外
的測試樣本(test pattern)去偵測這些遭到移除的主
要錯誤。而增加測試樣本就會增加測試時間，因
此，我們的方法要考慮額外產生的測試樣本越少
越好。我們將依據以上的發現來設計一個新的 
X-identification 的方法如圖六所示: 
 
 
圖六 
圖六中，(F1, F2, F3, F4, F5)為考慮壓降所產生完畢
的測試樣本，首先我們會將可以合併的測試樣本
間建立關係如圖六(a)所示，接下來再利用這些建
立好的關係計算每一個關係所得到的 cost 然後紀
錄至每一測試樣本上，例如:F1(V1)由於 F1分別和
F2及 F3有相同位置X-bit個數為 1和 2故給予 cost
為 3。因此，若 cost 越大，故我們可以將 cost 最
小的測試樣本移除，達到測試樣本個數降低的目
的如圖六(c)所示，我們由原本 5 組降低為 3 組。 
 
四、 結論 
 
(a)實驗結果 
在 本 年 度 為 主 的 研 究 (physical-location-aware 
X-bit reduction for maximum IR-drop reduction) 
我們針對測試樣本的特性以及壓降的區域分析，
透過演算法 (Fault Removal)達到降低壓降的目
的。為了達到精確的壓降結果，我們利用電壓模
擬工具 RedHawk 來表示演算法改善壓降現象的
效果。表四中說明 PB-based X-filling 方法對於部
分電路無法有效降低(粗體部分)，這是由於此類電
路壓降嚴重區塊已無 X-bit 可給予處理，故
X-filling 方法皆無法處理。 
表四 
 
 
由實驗結果表四可以觀察 b14、b20、b21 和 b22
的進步結果較不顯著，其原因以 b14 為例，將 b14
經由測試樣本傳遞，我們將壓降影響最高的十個
區塊選出，表五為此十個區塊觀察資料，表中
Original WSA、Reduced WSA、#cell、#X at Before 
Launch Cycle和#X at After Launch Cycle分別代表
原壓降影響、經處理後壓降、區塊內邏輯閘個數、
launch-cycle 中區塊內 x-bit 個數和 capture-cycle
內區塊內的 x-bit 個數。從表中可以觀察出壓降影
響並沒有顯著改善原因在於區塊內的 x-bit個數不
 7
and Exhibition, pp.622-627, Mar. 2008. 
 
[6]  N. Ahmed, M. Tehranipoor, and V. Jayaram, 
“A novel framework for faster-than-at-speed 
delay test considering IR-drop effects,” in 
Proceedings of the IEEE/ACM International 
Conference on Computer Aided Design, 
pp.198-203, Nov. 2006. 
 
[7]  J. Saxena, K.M. Butler, V.B. Jayaram, S. 
Kundu, N.V. Arvind, P. Sreeprakash, and M. 
Hachinger, “A case study of IR-drop in 
structured atspeed testing,” in Proceedings of 
the International Test Conference, pp. 
1098-1104, Sep. 2003. 
 
[8]  S. Ravi, “Power-aware test: challenges and 
solutions,” in Proceedings of the International 
Test Conference, pp.1-10, Oct. 2007. 
 
[9]  S. Remersaro, X. Lin, Z. Zhang, S.M. Reddy, I. 
Pomeranz and J. Rajski, “Preferred fill: a 
scalable method to reduce capture power for 
scan based designs,” in Proceedings of the 
International Test Conference, pp. 1-10, Oct. 
2006. 
 
[10] X. Wen, Y. Yamashita, S. Morishima, S. 
Kajihara, L.T. Wang, K.K. Saluja, and K. 
Kinoshita, “Low-capture-power test 
generation for scan-based at-speed testing,” in 
Proceedings of the International Test 
Conference, pp. 1019-1028, Nov. 2005. 
 
[11]  X. Wen, K. Miyase, T. Suzuki, Y. Yamato, S. 
Kajihara, L.T. Wang, and K.K. Saluja, “A 
highly-guided x-filling method for effective 
lowcapture-power scan test generation,” in 
Proceedings of the International Conference on 
Computer Design, pp. 251-258, Oct. 2006. 
 
[12] X. Wen, K. Miyase, T. Suzuki, S. Kajihara, Y.  
Ohsumi, and K.K. Saluja, “Critical-Path-Aware 
X-filling for effective IR-drop reduction in 
at-speed scan testing,” in Proceedings of the 
Design Automation Conference, pp. 527-532, 
Jun. 2007. 
 
[13] K. Miyase , K. Noda, H. Ito, K. Hatayama, T. 
Aikyo, Y. Yamato, H. Furukawa, X. Wen, and 
S. Kajihara. “Effective IR-drop reduction in 
at-speed scan testing using 
Distribution-Controlling X-Identification,” 
International Conference on Computer Aided 
Design (ICCAD) , pp. 52-58 ,2008 
 
[14] K. Miyase and S. Kajihara, “XID: Don't Care 
Identification of Test Patterns for 
Combinational Circuits,” IEEE Trans. on 
Computer-Aided Design, Vol. 23, No. 2, pp. 
321-326, Feb. 2004.
 附 錄: 
A Physical-Location-Aware X-Bit 
Redistribution for Maximum IR-Drop 
Reduction 
2256 IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS, VOL. 20, NO. 12, DECEMBER 2012
Fig. 1. Waveform of launch-off-capture scheme.
higher than a threshold value, the fault is removed from the test
vector to reduce switching activity in critical area. However, if
a fault is covered by only one test vector (essential fault), the
fault is not touched. We found that in many cases, this conser-
vative removing approach cannot reduce switching activity in
the critical area.
In this paper, based on transition delay fault model, we pro-
pose an algorithm to identify faults that cause IR-drop in hot re-
gions and redistribute -bits in a test vector. Instead of blindly
balancing the ratio of -bit in each test vector, we carefully
characterize the care-bits of faults and redistribute -bits based
on the locations and the propagation paths of the faults. As com-
pared to K. Enokimoto’s work [10], our method classifies faults
into different types. If IR-drop in critical area cannot be reduced
by removing non-essential fault, we will remove essential fault.
At the end of our proposed algorithm, if some faults are dropped,
we will add new test vectors to cover the dropped faults. More-
over, our algorithm is applied after performing physical design
so that more accurate layout information can be used.
The rest of this paper is organized as follows. In Section II, we
introduce our test model and state ourmotivation by an example.
Section III presents our proposed physical-location-aware algo-
rithm to redistribute -bits so that the maximum IR-drop is re-
duced. Section IV shows our experimental results. Finally, we
conclude this paper in Section V.
II. TEST MODEL AND MOTIVATION
A. At-Speed Test Model
Before describing the motivation of our work, we introduce
at-speed test model first. In our work, launch-off-capture
scheme for at-speed scan-based delay test is adopted. Fig. 1
shows an example waveform.
In this model, after a test vector is loaded into the scan chain
(at last-shift pulse), two clock pulses are applied in capture
mode. The first pulse launches the transition at target terminal,
which is always the flip-flop output and the second pulse cap-
tures the response from the flip-flop input at a scan cell. It can
be regarded as two time frames. The input vector of the first
time frame comes from the primary input and scan flip-flops
(before launch cycle). Then, the output vector of the first time
frame becomes the input vector of the second time frame (after
launch cycle) as shown in Fig. 2.
Since the false delay path occurs between the launch pulse
and the capture pulse, our goal is to minimize the impact of
IR-drop effect during this test cycle. In other words, our goal
is to minimize the switching-activity of gates between the last-
shift cycle (before launch cycle) and the launch cycle (after
launch cycle).
Fig. 2. Time frames of launch-off-capture scheme.
B. Motivational Example
Research [8], [9], [12], and [13] has been proposed using
X-filling method to reduce IR-drop. For them, X-filling is to
fill -bits of test vectors with suitable logic values (1 or 0).
The effectiveness of X-filling is determined by the number
and the characteristic of -bits. Namely, first, a test vector to
be filled should have enough -bits. Second, the propagation
of -bits will reach hot regions of IR-drop, i.e., the signals
in hot region are not already assigned. To solve this -bit
distribution problem, distribution-controlling X-identification
(DCXID)[11] was proposed to distribute -bits evenly in all
test vectors so that a fully-specified test vectors can reduce
IR-drop after X-filling method is applied. DCXID can effi-
ciently balances the distribution of -bits in every test vector.
However, we observe that the maximum IR drop may not be
reduced because the propagation path of a signal and physical
location of transition gates are not considered.
To verify our observation, we conduct the following ex-
periment for circuit, ITC99 benchmark b14 [16]. First, test
vector sequences produced by TetraMAX [14], DCXID and
our method are generated. The test sequence produced by
TetraMAX is the original sequence which is used as input
for DCXID and our method to redistribute -bits. The -bit
distributions of the three methods are drawn as shown in
Fig. 3(a), where -axis indicates the test vector ID and -axis
is the percentage of -bit ratio. From this figure, we can see
that DCXID can indeed balance the distribution of -bits.
Next, we perform X-filling method and estimate the maximum
IR drop by computing the maximum switching-activity in
each region. The X-filling method proposed by Hsieh et al.
[8] is adopted because the method takes physical location
into consideration. The result is shown in Fig. 3(b), where
-axis indicates the test vector ID and -axis is the maximum
switching-activity. For each method, the regions with the top
five highest switching-activity are found among all regions and
all test vectors. For TetraMAX and DCXID, four out of five
regions and their corresponding test vectors are common. For
TetraMAX and our method, all five regions are different and
the switching-activity of the top five regions by our method are
much smaller than those by TetraMAX. From this example,
we follow that simply balancing the distribution of -bits
is not enough because many faults propagating through the
same region may still lead to IR-drop no matter how -bit
is distributed evenly in the test vector. Therefore, an -bit
redistribution algorithm should take into consideration the
location of a fault and the propagation path of a fault.
2258 IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS, VOL. 20, NO. 12, DECEMBER 2012
TABLE I
TOGGLE TYPE OF GATES
regions for all test vectors are first calculated. The test vec-
tors which result in high switching-activity regions are selected
as target vectors for processing. For each test vector, regions
with high switching-activity (target region) are processed one
by one. For each target region, candidate faultswhich either are
in the target region or propagate through it are selected because
these faults lead the components in the target region to switch.
With these candidate faults, we perform fault_removal to reduce
excessive switching-activity in the target region. Then, we col-
lect the dropped faults and generate make-up test vectors to re-
tain the same fault coverage in the step ofmake-up_vector_gen-
eration. Finally, X-filling is performed to generate fully speci-
fied test vector. The details of target_vector_selection, fault_re-
moval and make-up_vector_generation steps are described in
the following subsections.
C. Target Vector Selection
This step is to recognize the test vector that results in
high switching-activity regions (target region). In order to
discriminate target regions from other regions, a cost func-
tion—weighted switching-activity (WSA) [8] with modification
is adopted. Note that, in order to speed up the computation,
we use a simplified model. To compute WSA of each region,
we assume that IR-drop in each region is independent to each
other. However, in the experiment, IR-drop is reported by
RedHawk [19]. The cost function, WSA(region) is defined to
represent the IR-drop impact of each region. For a region , its
is defined as follows:
(1)
represents whether is on critical path and defined as
if is on critical paths.
otherwise
where is a weight used to emphasize the importance of
if is on the critical path. in (1) represents type of
toggle for . Switching weight of toggle type representing
the preference and flexibility to assign a specific transition is
shown in Table I. The higher the value, the less the preference
(flexibility) is. Note that the computation of WSA in this step is
only for types and because all bits are specified in a test
vector.
Then, for all test vectors and for all regions, we compute
their WSA. Among all regions, the regions with the top 15%
Fig. 6. Flow of fault removal.
Fig. 7. Fault table.
highest WSA(region) are viewed as hot regions, i.e., target re-
gions. These WSA values will be used as our threshold to select
target regions to be processed. Next, a test vector that has at
least one hot region, i.e., target regions, is selected for fault re-
moval (i.e., the step of identifying more -bits).
D. Fault Removal
For a target vector and a target region, fault removal is per-
formed. Its flow chart is shown in Fig. 6. We describe each step
in detail in following subsections.
1) Care Bit Identification: For a target vector, a number of
faults are covered by running this vector in circuit. Certain bits,
care-bits, must be set in order to cover these faults. Therefore,
after selecting a target vector for X-identification, the first step,
care-bit identification, in fault removal is to identify care-bits
for faults covered by the test vector. Care bits which either
control the value or propagate value of faults to be observed
are identified. Without implementing fault simulation, we use
TetraMAX to run fault simulation. We set each care-bit to
one by one for the test vector. For each setting, fault simulation
is performed. After this step, care-bits corresponding to each
individual fault are known. With the information, a fault table
is constructed where row and column indices are fault IDs and
inputs, respectively. An entry in the fault table is 1 if
the setting of the care-bit in to -bit will result in the
removal of the fault in . Fig. 7 shows a fault table where
there are three faults and four inputs. is covered when
and are set and is covered when , , and
are set. Similarly, is covered when and are
set. This table will be used in the steps of fault_classification,
pseudo_non-essential_fault_and _essential_fault_removal and
reclaim_unused_care_bit.
2) Fault Classification: For a test vector and a target region,
we select candidate faults for fault removal. Candidate fault is
2260 IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS, VOL. 20, NO. 12, DECEMBER 2012
Fig. 9. Reclaim care-bits.
generation. Notice that, setting a care-bit to and reclaiming
unused care-bit (described in the next subsection) may result in
new non-essential fault. Hence, after setting one care-bit, the
flow goes back to the removal of non-essential fault.
5) Reclaim Un-Used Care Bit: After identifying one care-bit
and set it to , we should reclaim other unused care-bits. We
explain why reclaiming unused care-bit is necessary by an ex-
ample in Fig. 9. In this figure, , , and are set to
sensitize faults— , , , and . When is reset to
(faults, , , , and , are removed from the coverage
of the current test vector), it is not necessary to set the value of
and any more and and can be reclaimed to
value.
Reclaiming unused care-bit proceeds as follows. First, re-
call that, in the step of care_bit_identification, a fault table that
records coverage of fault by care-bit is constructed. This fault
table is utilized to reclaim unused care-bit. Suppose that a care-
bit, , in column is set to to remove the coverage of
. Then, all will not be covered if for
. For a fault, , that is not covered, if its
care-bit is not required by any other faults, the care-bit can be
reclaimed.
Take the fault table in Fig. 7 as an example. Suppose that
is to be removed. is selected to be set to . After
setting to , will not be covered any more. In this
case, care-bits, and , are not required for any
more. However, is still required for . Hence, only
can be reclaimed.
E. Make-Up Vector Generation
Removal of pseudo non-essential and essential fault reduces
the fault coverage. To recover the dropped faults, the last step,
make-up vector generation, is performed. Fig. 10 shows the
overall flow. The first part of the procedure (lines 4–15) is to
check if any test vector in the remaining test set can cover a
dropped fault without violating the IR drop constraint. For one
dropped fault, , we select one vector, , from the remaining
test set. If the care-bits of and are consistent and no re-
gion violates the constraint after setting care-bits for ,
we select to cover fault, . This checking is performed for
all dropped faults. Note that if a fault can be recovered in this
step, no extra test vector is generated.
Fig. 10. Make-up_Vector_Generation algorithm.
In the second part of the procedure (lines 17–24), we will
generate extra test vectors to cover the dropped faults, i.e., un-
covered is not empty. First, for each fault, we generate one test
vector. Next, to have less number of test vectors, we need to
merge test vectors. For this purpose, a compatibility-relation
graph, , is constructed, where a vertex , in de-
notes an uncovered fault (i.e., a test vector), , and an edge con-
necting vertices and , denotes that the cares bits of faults
and are consistent. These two faults can be covered by
one single test vector. Next, in order to have as few as make-up
test vectors, we find the maximum clique in the graph. The ver-
tices in the clique correspond to faults that can be covered by
one single vector. Before we select this test vector, we need to
check if the application of this test vector exceeds the IR-drop
constraint. If yes, we need to remove some fault from the cov-
erage of this vector.
2262 IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS, VOL. 20, NO. 12, DECEMBER 2012
Fig. 12. Overall flow of the experiment.
on all ITC’99 benchmark [16] except and .
and are all small circuits whose gate counts are smaller than
1000 after synthesis. Fig. 12 presents our experimental flow.
The circuits are described in VHDL and synthesized by Syn-
opsys Design Compiler [17] with TSMC 90-nm cell library.
Six kinds of gates including BUFFER, INVERTER, NAND, NOR,
AND, and OR are used for synthesis. XOR gate is not included
in the algorithm because paths propagate through it remain the
same sensitizability, which causes more time to complete the
computation. The gate-level netlist and the test protocol in STIL
format are generated. The input to SoC Encounter (SoCE) [18]
is the netlist and the output is a layout design with detailed
physical location and the timing information after floorplaning,
placement, and routing. Then the netlist and the test protocol
are fed into TetraMax to generate test vectors with unspecified
bits. In this generation process, transition delay fault model is
taken. Meanwhile, the timing information is used as input file
for PrimeTime [20] to produce critical paths information. Here,
the critical paths we used in this paper are the most critical
paths reported by PrimeTime with annotated timing information
after routing. The value of should be large enough to include
TABLE II
DESCRIPTIONS OF CIRCUITS AND TEST VECTORS
TABLE III
RESULTS OF -FILLING
Difficult circuit
Maximum improvement is not significant
critical and near-critical paths so that IR-drop effect on critical
paths and near-critical paths can be considered. This path criti-
cality information is used in (1) to estimate the criticality
of a region. In our experiments, is selected to be 1000. Our
algorithm will take the netlist of layout design , the test
vector with unspecified bits, the test vector after X-filling [8]
and the critical paths information as input files, identifies some
care-bits, and relaxes them as -bits for X-filling [8]. After our
algorithm andX-filling, we can obtain fully specified test vector.
Table II shows the descriptions of benchmark circuits and test
vectors generated from TetraMAX. The columns labeled #PI,
#FF, #Gate, #Vec, Fault Cov.(%), and -bit(%) represent the
number of primary input, the number of scan-chain flip-flop,
the total number of gate count, the total number of test vectors,
fault coverage, and average -bit ratio(%) of all test vectors,
respectively. Note that the fault coverage of and are
relatively low. It is because is composed of and
and the fault coverage of is relatively low. Similarly,
is composed of two s. Therefore, its fault coverage is also
relatively low. The numbers of vertical stripes and rows used to
divide a layout into regions are listed in columns 5 and 6.
Table III shows the maximum and average for
random-filled (labeled random-filled) and physical-loca-
tion-aware -filling method (labeled PB-based) [8]. PB-based
method is a post-ATPG X-filling method taking into consider-
ation layout information. The slacks of circuits, , , ,
and , reported by PrimeTime are 0.5417, 0.4513, 0.5728,
and 0.3146, respectively. The columns labeled and
represent the maximum and average
of all regions for all test vectors, respectively. The column
ReR(%) is the reduction ratio of PB-basedmethod as compared
with random-filled. Although the average of for all
2264 IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS, VOL. 20, NO. 12, DECEMBER 2012
TABLE VII
COMPARISON OF OUR METHOD AND TETRAMAX FOR FULLY SPECIFIED TEST VECTOR
the make-up vector generation is performed to recover the fault
coverage. We estimate IR-drop using RedHawk tool and the ex-
periment results show that we have an average of 9.42% more
reduction of maximum IR-drop as compared to a previous work
which redistributes -bits evenly in all test vectors with 2.73%
overhead of extra test vectors.
REFERENCES
[1] B. Swanson and M. Lange, “At-speed testing made easy,” EE Times,
Jun. 3, 2004 [Online]. Available: http://www.eetimes.com/electronics-
news/4154986/At-speed-testing-made-easy
[2] J. Gatej, L. Song, C. Pyron, and R. Raina, “Evaluating ATE features in
terms of test escape rates and other cost of test culprits,” in Proc. Int.
Test Conf. (ITC), 2002, pp. 1040–1049.
[3] L. T. Wang, C. W. Wu, and X. Wen, VLSI Test Principles and Archi-
tectures: Design for Testability. San Francisco, CA: Elsevier, 2006.
[4] N. Ahmed, M. Tehranipoor, and V. Jayaram, “A novel framework for
faster-than-at-speed delay test considering IR-drop effects,” in Proc.
IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), 2006, pp.
198–203.
[5] J. Xiong, V. Zolotov, C. Visweswarish, and P. A. Habitz, “Optimal
margin computation for at-speed test,” in Proc. Design, Autom. Test
Euro. Conf. (DATE), 2008, pp. 622–627.
[6] J. Saxena, K. M. Butler, V. B. Jayaram, K. M. Butler, V. B. Jayaram,
S. Kundu, N. V. Arvind, P. Sreeprakash, and M. Hachinger, “A case
study of IR-drop in structured at-speed testing,” in Proc. Int. Test Conf.
(ITC), 2003, pp. 1089–1104.
[7] S. Ravi, “Power-aware test: Challenges and solutions,” in Proc. Int.
Test Conf. (ITC), 2007, pp. 1–10.
[8] W.-W. Hsieh, S.-L. Chen, I.-S. Lin, and T. Hwang, “A physical-lo-
cation-aware X-filling method for IR-drop reduction in at-speed test,”
IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. (TCAD), vol.
29, no. 1, pp. 289–298, Jan. 2009.
[9] X. Wen, K. Miyase, T. Suzuki, S. Kajihara, Y. Ohsumi, and K. K.
Saluja, “Critical-path-aware X-filling for effective IR-drop reduction
in at-speed scan testing,” in Proc. ACM/IEEE Design Autom. Conf.
(DAC), 2007, pp. 527–532.
[10] K. Enokimoto, X. Wen, Y. Yamato, K. Miyase, H. Sone, S. Kajihara,
M. Aso, and H. Furukawa, “CAT: A critical-area-targeted test set modi-
fication scheme for reducing launch switching activity in at-speed scan
testing,” in Proc. Asian Test Symp. (ATS), 2009, pp. 99–104.
[11] K. Miyase, K. Noda, H. Ito, K. Hatayama, T. Aikyo, Y. Yamato, H.
Furukawa, X. Wen, and S. Kajihara, “Effective IR-drop reduction in
at-speed scan testing using distribution-controlling X-identification,”
in Proc. Int. Conf. Comput.-Aided Design (ICCAD), 2008, pp. 52–58.
[12] X. Wen, K. Miyase, S. Kajihara, T. Suzuki, Y. Yamato, P. Girard, Y.
Ohsumi, and L. T. Wang, “A novel scheme to reduce power supply
noise for high-quality at-speed scan testing,” in Proc. Int. Test Conf.
(ITC), 2007, pp. 1–10.
[13] J. Li, Q. Xu, Y. Hu, and X. Li, “iFill: An impact-oriented X-filling
method for shift- and capture-power reduction in at-speed scan-based
testing,” in Proc. Design, Autom., Test Euro. Conf. (DATE), 2008, pp.
1184–1189.
[14] Synopsys, Inc., San Jose, CA, “TetraMAX ATPG,” 2006.
[15] N. Ahmed, M. Tehranipoor, and V. Jayaram, “A novel framework for
faster-than-at-speed delay test considering IR-drop effects,” in Proc.
IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), 2006, pp.
198–203.
[16] Univ. Texas at Austin, Austin, “ITC99 Benchmark Circuits Suite,”
1999. [Online]. Available: http://www.cerc.utexas.edu/itc99-bench-
marks/bench.html
[17] Synopsys, Inc., San Jose, CA, “Design Compiler,” 1999.
[18] Cadence Design Systems, Inc., San Jose, CA, “SoC Encounter,” 2006.
[19] Apache Design Solution, Inc., San Jose, CA, “RedHawk,” 2007.
[20] Synopsys, Inc., San Jose, CA, “PrimeTime,” 2006.
Fu-Wei Chen received the B.S. degree in computer
science and information engineering from Fu Jen
Catholic University, Taipei, Taiwan, in 2006, and the
M.S. degree in computer science from Yuan Ze Uni-
versity, Chung-Li, Taiwan, in 2008. He is currently
pursuing the Ph.D. degree from the Department of
Computer Science, National Tsing Hua University,
Hsinchu, Taiwan.
His research interests include physical design and
testing for VLSI design.
Shih-Liang Chen received the B.S. degree in com-
puter science from Chung Yuan Christian University,
Chungli, Taiwan, in 1999, and theM.S. and Ph.D. de-
grees in computer science from National Tsing Hua
University, Hsinchu, Taiwan, in 2001 and 2010, re-
spectively.
From 2001 to 2005, he was with Macronix
International Company, Ltd., Hsinchu, Taiwan,
where he served as a Principal Engineer and co-led
a system-on-a-chip project for Smart Card platform.
In 2010, he joined MediaTek Inc., Hsinchu, Taiwan,
as a Senior Engineer. He currently joins the project of front-end design
methodology development for advanced process node. His research interests
include reliability and security for VLSI design, and related computer-aided
design techniques.
Yung-Sheng Lin received the B.S. degree in com-
puter science from National Chung Cheng Univer-
sity, Chia-Yi, Taiwan, in 2007, and the M.S. degree
in computer science from National Tsing Hua Uni-
versity, Hsinchu, Taiwan, in 2009.
He is currently an Engineer with Taiwan Semi-
conductor Manufacturing Company, Ltd., Hsinchu,
Taiwan. He currently joins the project of design
technology development for layout post process. His
research interests include computer-aided design of
both VLSI circuits and layout post process.
TingTing Hwang (M’90) received the B.S. degree
in political science from the National Taiwan Univer-
sity, Taipei, Taiwan, in 1981, and the M.S. and Ph.D.
degrees in computer science from Pennsylvania State
University, University Park, in 1986 and 1990, re-
spectively.
From 1990 to 1996, she was a Vice-Professor with
the Department of Computer Science, National Tsing
Hua University, Hsinchu, Taiwan, where she is cur-
rently a Full Professor of computer science. She is the
author of over 80 research papers in related areas. Her
research interests include logic synthesis/optimization and high-level synthesis.
1Clock Tree Synthesis with Methodology of Re-use in 3D IC
Fu-Wei Chen, TingTing Hwang
Department of Computer Science
National Tsing Hua University, Hsinchu, Taiwan 30013, R.O.C.
{fwchen, tingting}@cs.nthu.edu.tw
Abstract
IP reuse methodology has been used extensively in SoC (System
on Chip) design. In this reuse methodology, while design and imple-
mentation cost is saved, manufacturing cost is not. To further reduce
the cost, this reuse concept has been proposed at mask and die level
in three-dimension integrated circuit (3D IC). In order to achieve
manufacturing reuse, in this paper, we propose a new methodology
to design a global clock tree in 3D IC. The objective is to extend
an existing clock tree in 2D IC to 3D IC taking into consideration
the wirelength, clock skew and the number of TSVs. Compared with
NNG-based method, our proposed method reduces the wirelength of
the new die and skew of the global 3D clock tree, on an average,
47.16% and 5.85%, respectively.
Categories and Subject Descriptors
B.7.2 [Integrated Circuits]: Design Aids—Placement and routing;
J.6 [Computer-Aided Engineering]: Computer-aided design (CAD)
General Terms
Design, Algorithms
Keywords
Clock tree synthesis, Through-silicon-via, 3D IC, Clock network
I. INTRODUCTION
Global interconnection has become a major performance and
power consumption bottleneck for advanced VLSI technology as
more functional devices are accommodated in one single chip. Three
dimensional integrated circuit (3D-IC) technology solves this problem
using through-silicon-via (TSV) by connecting signals among mul-
tiple stacked dies. Moreover, 3D-IC technology gives more design
ﬂexibility by heterogeneous integration [1].
Intellectual Property (IP) based design methodology has been
extensively used to reduce design cost in SoC design. In this re-
use methodology, while design and implementation cost is saved,
manufacturing cost is not. To further reduce the cost, this re-use
concept has been proposed at mask and die level in 3D-IC. For
example, Alam et al. [2] proposed the reciprocal design symmetry
(RDS) to reuse one mask set for 3D-ICs. Besides RDS, Hung and
Lin proposed Chipsburg architecture in manufacturing reuse [3], [4].
Figure 1 shows an example of Chipsburg architecture. Figure 1(a)
shows a traditional 2D SoC design applications, where IP2 and IP4
are used by all applications. Designers have to implement and verify
them once for each application. Figure 1(b) shows an implementation
in 3D-IC, where common IP, IP2 and IP4, are placed in the platform
This work is supported in part by the National Science Council of Taiwan under Grant
NSC-100-2221-E-007-043-MY3.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior speciﬁc permission and/or a fee.
DAC 2012, June 3-7, 2012, San Francisco, California, USA.
Copyright 2012 ACM 978-1-4503-1199-1/12/06...$10.00
IP1
IP4
IP3
IP2
IP5
Application a
Application b
IP1
IP4
IP3
IP2
IP5
ASIC b
ASIC a
Platform layer
Fig. 1. Comparison between (a) traditional SoC design and (b) Chipsburg [5]
layer, and remaining IPs of each application are placed in its own
ASIC layer. Platform layer is designed and manufactured once for all.
Then, each application can perform its intended function by integrat-
ing the platform layer with its own ASIC layer in 3D-IC. In Chipsburg
methodology [3], designers can change functionality of application by
changing new ASIC layer. Due to this manufacturing reuse technique,
the non-recurring engineering (NRE) costs of the platform layer and
the ASIC layer are shared and reduced, respectively. Therefore, the
overall cost can be reduced.
With 3D-IC integrated technique, clock tree in 3D-IC has drawn
much attention recently. Jacob Minz et al. [6] proposed a thermal-
aware buffered clock tree for two stacked dies. Zhao et al. [7] and
Kim et al. [8] generated 3D clock tree taken into consideration the
number of TSVs. Zhao et al. [9] and Kim et al. [10] proposed 3D-IC
clock tree design taking pre-bond testability into account. Although a
lot of research has been studied on 3D-IC clock tree construction, it
can not be applied directly for manufacturing reuse in 3D-ICs because
platform layer is fabricated and its clock tree is already constructed.
An intuitive methodology is to construct clock tree for an ASIC
layer optimally and then to ﬁnd the shortest distance between internal
nodes of platform layer and ASIC layer for connection. Connection
is kept added until the whole sub-trees in ASIC layer are connected
to the platform layer. The following example demonstrates that using
this intuitive method without considering the clock tree of platform
layer when constructing the clock tree in ASIC layer can not produce
good results. In Figure 2, there are six clock sinks in both ASIC
and platform layers and these clock sinks do not distribute the same
way in the two layers. Initially, the clock tree on platform layer has
been synthesized and then the clock tree on ASIC layer starts to be
designed. Figure 2 (a) is the results based on NNG (nearest neighbor
graph) -based method [12] to generate the topology of clock tree in
ASIC layer without taking the existing clock tree on platform layer
into account. Note that, NNG uses nearest neighbor clock sinks to
do clustering. Then, DME method is used to construct clock tree
in bottom-up fashion [11]. After the clock tree is synthesized in
ASIC layer, connections between platform layer and ASIC layer are
established by ﬁnding shortest distance between internal nodes in
platform layer and ASIC layer greedily. Figure 2 (b) is the results
considering the sinks in the ASIC layer and possible connecting nodes
in the existing clock tree on platform layer simultaneously when tree
topology in ASIC layer is generated. Then, the same DME method
is used to construct clock tree. The clock skews in Figure 2 (a) and
(b) are 69.7ps and 35.4ps, respectively. Figure 2 (b) is better than
Figure 2 (a) because the second method is able to balance downstream
capacitance in platform layer and ASIC layer when generating the
3Pre-fabricated_TSV-
buffer_information
Density_calculation
3D-IC clock tree is 
generated
Pre-fabricated_TSV-
buffer_projection
Clock_sub-tree_
topology_construction
NO
All pre-fabricated 
TSV-buffers have been 
processed ? 
Initial_clock_tree_topology_construction
Clock_tree_construction
YES
Adjust_global_tree_
topology
Fig. 5. Design ﬂow
III. ALGORITHM
We propose a global clock tree construction algorithm in 3D-IC
given a pre-designed clock tree in one die. Our main objective is to
construct the clock tree with minimization of wirelength and clock
skew.
A. Overview of Our Proposed Method
Figure 5 is the overview of our proposed 3D-IC clock tree construc-
tion algorithm. The ﬁrst step, pre-fabricated TSV-buffer information
is to collect locations, downstream capacitance and delay data of
pre-fabricated TSV-buffers placed on platform layer.
Then, the next step, initial clock tree topology construction, is
performed to generate an initial clock tree topology in ASIC layer
by projecting location of pre-fabricated TSV-buffer in platform layer
into ASIC layer, creating clusters for all clock sinks on ASIC layer,
and assigning a pre-fabricated TSV-buffer in platform layer to each
cluster. Note that, each cluster represents a sub-tree topology. After
this step, we use adjust global tree topology to obtain a complete
global clock tree topology in 3D-IC.
In the last step, we perform clock tree construction to route our
3D-IC clock tree network based on the tree topology generated in the
previous steps. The details of pre-fabricated TSV-buffer information,
clock sub-tree topology construction, adjust global tree topology,
and clock tree construction are described in the following sections.
B. Pre-fabricated TSV-buffer Information
In this step, besides location of pre-fabricated TSV-buffer, down-
stream capacitance and the maximum delay of the parent node of
pre-fabricated TSV-buffer in platform layer are collected. To compute
the maximum delay, we take Figure 4 (b) as an example. Let node VF
represent the parent node of a pre-fabricated TSV-buffer, andDVF ,V1 ,
DVF ,V2 , DVF ,V3 , and DVF ,V4 represent downstream delay from VF
to V1, V2, V3, and V4 in platform layer, respectively. Then, for node
VF , the downstream delay of parent node of the pre-fabricated TSV-
buffer is the maximum value among DVF ,V1 , DVF ,V2 , DVF ,V3 , and
DVF ,V4 . This maximum delay is used to reduce the clock skew in
ASIC layer in the later step.
C. Initial Clock Tree Topology Construction
Clock sinks are merged to generate clock tree topology taking
into pre-fabricated TSV buffer account in bottom-up fashion in
ASIC layer. Initial Tree topology construction procedure is shown
in Figure 6. Initially, each sink in ASIC layer forms a tree and
Stree = {all sinks in ASIC layers}, current h is set to the min-
imum height of all pre-fabricated TSV-buffers (lines 1 and 2). While
current h is less than and equal to the tree height in platform layer,
Algorithm: Initial tree topology construction
htree : the tree height of the clock tree in platform layer;
h(bi) : the height of pre-fabricated TSV-buffer bi;
Begin
1 Stree = set of roots of sub-trees in ASIC layer;
2 current h = min{h(bi)}, ∀bi ∈ pre-fabricated TSV-buffer;
3 while current h ≤ htree
4 SB = set of pre-fabricated TSV-buffers with current h;
5 density calculation(Stree);
6 pre-fabricated TSV-buffer projection(SB );
7 Stree = clock sub-tree topology construction(current h, Stree);
8 current h++;
End
Fig. 6. Initial Tree Topology Construction procedure
clock sink
voronoi edge
delaunay triangulation edge
projected node
V1
V2 V3
V4
V5
V6
V7
e1
e2 e3
e4
e5
e6
n1
n2
d1
d2
Fig. 7. Voronoi diagram construction
iterations continue (line 3). In each iteraction, pre-fabricated TSV-
buffers with the same current h form a set SB . The density among
the roots of current sub-trees is computed in density calculation (line
4). Next, the locations of buffers in SB will be projected to ASIC
layer in pre-fabricated TSV-buffers projection step (line 5). Then,
based on the projected location and density function, the next higher
level sub-trees are searched in clock sub-tree topology construction
(lines 6 and 7). After one loop is completed, the iteration continues
with new current h, with increasement of one and new Stree. The
iterations continue until current h is larger than the tree height,
htree. The details of three sub-steps are described in the following
subsections.
1) Density Calculation: In this step, voronoi diagram is to analyze
the distribution and density of clock sinks in ASIC layer. We observe
that if a clock sink i in a region where clock sinks density is high, the
area of clock sink i, area(i) surrounded by voronoi edges is small.
For example, in Figure 7, clock sink V1 and V7 represent clock sinks
in high and low clock sinks density area, respectively. Besides the
distribution information, we consider the average distance from a sink
to its adjacent sinks. For a sink i, we say that sink j is adjacent to
sink i if there exists a delaunay triangulation edge between them.
For example, in Figure 7, adjacent sinks of sink V7 are sinks, V1,
V2, V3, V4, V5 and V6, and the length of edges, e1, e2, e3, e4, e5
and e6, are collected as the distance information for sink V7. After
voronoi diagram is constructed, we can obtain the area and distance
information for each sink. The sparse function sparse(i) for sink i
is deﬁned as follows,
sparse(i) = α×
√
area(i) + β ×
∑m
j=1
dis(i, j)
m
where m is the number of delaunay triangulation edges incident to
clock sink i, and dis(i, j) represents distance between sinks i and
j. α and β are weight factor. Figure 7 shows that sparse function,
sparse(V7), for sink V7 is α×
√
area(V7)+β×
∑
6
k=1
dis(V7,Vk)
6
.
Note that, the lower the value of sparse(i), the denser area the
node is located.
5Algorithm: Clock sub-tree topology constrcution(current h, L)
Lsuccess : list of sub-tree nodes succeed in merging with an
unpaired sub-tree node;
Begin
1 Lp = list of sub-tree nodes with height current h paired with
projected nodes in increasing order;
2 Lup = list of sub-trees with height current h which is not
paired with any projected nodes, which is L− Lp;
3 while Lp is not empty
4 t = the ﬁrst element in Lp;
5 p = the projected node paired with t;
6 a = min{dist(t, upi)}, upi ∈ Lup;
7 if clustercap(t, a, p) ≤ γ then
8 merge t and a using p;
9 generate new sub-tree node m(t, a);
10 assign m(t, a) to Lsucess;
11 delete a from Lup;
12 end if
13 delete t from Lp;
14 end while
15 if current h == 1 then
16 Lfail = { all single sink that has height = 1};
17 endif
18 return Lsuccess;
End
Fig. 8. clock sub-tree topology construction procedure
p
1
2
3
4
t
(a)
2
p
t
m(t, a2, p)
voronoi edge
sub-tree node
projected node
TSV
pre-fabricated
TSV-buffer(b)
a
a
a
a
a
Fig. 9. An example of clock sub-tree topology construction
current h by one and setting Lfail = Lnewfail (lines 17-20). If the
current h is equal to hmin, there are still some sinks that are not
able to be merged with a sub-tree. Then, we will relax the clustering
constraint by a factor of γ (lines 21-22). The new iteration starts with
current h = hmax (line 23).
E. Clock Tree Construction
After global tree topology construction, the next step is to con-
struct the actual clock tree in step clock tree construction. In this
step, we adopt DME-based zero-skew tree construction [6], [11] and
buffer insertion [14] to construct our clock tree. Finally, we can obtain
a complete 3D buffered clock tree for mask reuse.
IV. EXPERIMENT
We implemented the proposed method using C++/STL program-
ming language on Linux environment with 2.4GHz processor and
4GB memory. Our experimental results were performed on ISPD’09
clock tree contest benchmark. In our experiments, we use technology
parameters based on the 45nm Predictive Technology Model [10],
[16]. We use 10um × 10um via-last TSVs with thinned die height
of 20um. The parasitic resistance and capacitance of unit wire
length (TSV) are 0.1Ω/um (0.035Ω) and 0.2fF /um (15.48fF ),
respectively. The intrinsic delay, input capacitance and output driving
resistance of a buffer are 18ps, 14fF and 51Ω, respectively. Our
Algorithm: Adjust global tree topology(Stree , Lfail)
h(ti) : the tree height of sub-tree ti;
Begin
1 hmax = max{h(ti)}, ti ∈ Stree;
2 hmin = min{h(ti)}, ti ∈ Stree;
3 current h = hmax;
4 for each sub-tree node f ∈ Lfail begin
5 LH = list of the sub-tree nodes with height currenth
in increasing order;
6 while LH is not empty
7 st = the ﬁrst element in LH ;
8 if clustercap(st, f, p) ≤ γ then
9 merge(st, f);
10 delete f from Lfail;
11 end if
12 end while
13 if f is not merged with any sub-tree with height current h then
14 put f in Lnewfail;
15 endif
16 end for
17 if Snewfail 6= ∅ and current h 6= hmin then
18 current h−−;
19 Lfail=Lnewfail;
20 goto line 4;
21 else if Lfail 6= ∅ and current h == hmin then
22 γ = γ × δ;
23 goto line 3;
24 end if
End
Fig. 10. Adjust global tree topology procedure
clock frequency is set to 1GHz with supply voltage 1.2V . Our
weight factors, α, β, γ, and δ, are set 0.5, 0.5, 1.4, and 1.05,
respectively. For pre-bond testing, the redundant tree is constructed
to connect each sub-tree on ASIC layer and TG (transmission gate)
is used to connect and disconnect redundant tree [9]. In order to
minimize routing area of control signals, in this paper, we use the
RMST-pack [13]. Finally, clock skew is reported based on SPICE
simulation [17].
First, we compare two global 3D-IC clock trees constructed by
NNG-based and ours methods. Note that, NNG-based method uses
nearest neighbor graph to do clustering without pre-fabricated TSV-
buffer projection step, and then clock sub-tree construction and ad-
just global tree topology steps are performed to generate a whole
3D-IC clock tree topology. After the topologies are constructed by
two methods, the same DME method [11] is used to build 3D-IC
clock tree design.
Table I shows the clock skew of these two methods before the clock
sub-trees in ASIC layer are inserted with buffer. Finally, the next
experiment is to compare results after buffers are inserted. The same
modiﬁed buffer insertion method [14] is applied. From the table I, the
average improvement of clock skew of ours method as compared with
NNG-based is 49%. Table II shows the results, where WLP , WLA,
WL3D, Skew, #BUF and #TSV represent the wirelength of the
clock tree in platform layer, the wirelength of the new clock tree in
ASIC layer, total wirelength of the global 3D-IC clock tree, the clock
skew of the global 3D-IC clock tree, the number of buffers and the
number of TSVs, respectively. In Table II, the average improvement
of total wirelength of the global 3D-IC clock tree, the wirelength of
ASIC layer, clock skew, and the number of buffers of our method as
compared with NNG-based method are 2.22%, 5.85%, 47.16%, and
5.72%, respectively.
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/23
國科會補助計畫
計畫名稱: 考量實際擺放位置改善壓降現象之測試樣本產生方法研究
計畫主持人: 黃婷婷
計畫編號: 99-2221-E-007-116-MY2 學門領域: 積體電路及系統設計
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
