1. Introduction
A speech recognition system basically contains extraction of features and clas-
sification of an utterance of an acoustical word. The measurements made on the
speech waveform include energy, zero crossings, extrema count, formants, LPC cep-
strum (LPCC) [1-4] and the Mel frequency cepstrum coefficient (MFCC) [5-8]. The
LPC method provides a robust, reliable and accurate method for estimating the
parameters that characterize the linear, time-varying system which is recently used
to approximate the nonlinear, time-varying system of the speech waveform. The
MFCC method uses the bank of filters scaled according to the Mel scale to smooth
the spectrum, performing a processing that is similar to that executed by the hu-
man ear. The filters with Mel scales spaced linearly at low frequencies and loga-
rithmically at high frequencies are used to capture phonetically the characteristics
of speech [8]. For recognition, Davis and Mermelstein [5] used the dynamic time
warping algorithm to show that the performance of the MFCC was better than the
LPCC.
In this paper, we use a simple technique [9] for speech data compression of the
sequence of MFCC vectors and the sequence of LPCC vectors to obtain a matrix
of feature values respectively. For speech recognition, we simply use a simplified
Bayes decision rule with weighted variance, where each step is a simple calculation
and which has the minimum probability of misclassification. In our study, there
are two speech recognition experiments. In the first experiment, since both LPCC
and MFCC are said to be robust and reliable to noise and estimation errors, our
speech experiment is implemented in a noisy environment to test which feature is
better on speech recognition. Pick up 9 female and 10 male students and each
pronounces 10 digits once using a common (not high-quality) microphone. Some
2
by
R(τ) = inf
d∈D
R(τ, d) (2.2)
A decision rule dτ which satisfies (2.2) is called the Bayes decision rule with respect
to the prior distribution τ and is given in (2.3) [10]. We state the Bayes decision
rule in the follwing theorem.
Theorem 2.1. [10] The Bayes decision rule with respect to τ is defined by
dτ (x) = ci if θi f(x|ci) > θj f(x|cj) (2.3)
for all j 6= i, i.e., Γi = {x|θi f(x|ci) > θj f(x|cj)} for all j 6= i.
Note that if θi = 1/m, i = 1, ...,m, the Bayes decision rule (2.3) becomes a
ML classifier.
3. Feature Extraction
3.1. Preprocessing Speech Signal
Since our speech recognition experiment is implemented in a noisy environment,
the speech data must contain noise. We propose two simple methods to eliminate
noise. One way is to use the sample variance of a fixed number of sequential samples
to detect the real speech signal, i.e., the samples with small variance does not contain
speech signal. Another way is to compute the sum of the absolute values of difference
of two consecutive samples in a fixed number of sequential speech samples, i.e., the
speech data with small absolute value do not contain real speech signal. In our
speech recognition experiment, the latter provides slightly faster and more accurate
speech recognition.
3.2. Mel-Frequency Cepstrum Coefficient (MFCC)
4
where B(f) = 1125 ln(1 + f/700) and B−1(b) = 700(e(b/1125) − 1). The log-energy
is computed by
S[m] = ln{
N−1∑
k=0
|X[k]|2H[m, k]}, 0 < m ≤M. (3.4)
The MFCC is then the discrete cosine transform of the M filters outputs:
c(n) =
M−1∑
m=0
S[m]cos(pin(m− 0.5)/M) 0 ≤ n < M (3.5)
For speech recognition, normally, the number M of filters is from 10 to 20 and the
MFCC produced from the first few filters are the most effective in recognition. In
our experiment, we use M =12
3.3. Linear Predict Coding Cepstrum (LPCC)
The MFCC was proved to be better than the LPC cepstrum for recognition
by using the dynamic time warping (DTW) method [5], but the computational
complexity for the MFCC is much heavier than that of the LPC cepstrum. The
LPC coefficients can be easily obtained by Durbin’s recursive procedure [11,12] and
their cepstra can be quickly found by another recursive equations [11,12] without
computing the discrete Fourier transform (DFT) and the inverse DFT, which are
computationally complex and time consuming.
The LPC method can also provide a robust, reliable and accurate method
for estimating the parameters that characterize the linear and time-varying system
[3,11,12]. The following is a brief discussion of LPC method. It is assumed [12]
that the sampled speech waveform sˆ(n) can be linearly predicted from the past p
samples of s(n). Let
sˆ(n) =
p∑
k=1
aks(n− k) (3.6)
6
Our method to extract the feature from LPCC (MFCC) is quite simple. Let
x(k) = (x(k)1, ..., x(k)p), k = 1, ..., n, be the LPCC (MFCC) vector of size p = 12
for the k-th frame of a speech waveform, where n is the length of the LPCC (MFCC)
sequence and p is the number of LPC coefficients in each frame. Normally, if a
speaker does not intentionally elongate pronunciation, a mandarin syllable has 30-
70 vectors of LPCC (MFCC).
Since an utterance of a syllable is composed of two basic parts: stable part and
feature part. In the feature parts, the vectors have a dramatic change between two
consecutive vectors, representing the unique characteristics of the syllable utterance
and in the stable parts, the vectors stay about the same. Even if the same speaker
utters the same syllable, the duration of stable parts of the sequence of LPCC
(MFCC) vectors changes every time with nonlinear expansion and contraction and
hence the duration of the portion of feature vectors and duration of stable parts
are different every time. Therefore, the duration of stable parts is contracted such
that the compressed speech waveform has about the same length of the sequence of
the vectors. Li [9] proposed several simple compression techniques to contract the
stable parts of the sequence of vectors. We state a simple one with good recognition
rate as follows:
Let x(k) = (x(k)1, ..., x(k)p), k = 1, ..., n, be the k-th vector of a LPCC
(MFCC) sequence with n vectors, which represents a mandarin syllable. Let the
difference of two consecutive vectors be denoted by
D(k) =
p∑
i=1
|x(k)i − x(k − 1)i|, k = 2, ..., n. (3.8)
In order to accurately identify the syllable utterance, a compression process must
first be performed to remove the stable and flat portion in the sequence of vectors.
8
The digit recognition is implemented in a noisy environment, a classroom with
windows open, which has noise from students inside classroom and from students
and autos on the street outside classroom. The database of 10 mandarin digits is
created by 19 persons (9 female and 10 male students) who pronounce 10 digits
(0-9) once. The speech signal of a mandarin monosyllable is sampled at 10kHz. A
Hamming window with a width of 25.6 ms is applied every 12.8 ms for our study.
A 256 point Hamming window is used to select the data points to be analyzed.
In our experiments, we use this database to produce the LPCC (MFCC) and
obtain a 12x10 matrix for each digit sample. On the average, the time to produce
a MFCC using FFT and formula in Section 3.2 is 5.5 times as much as to produce
a LPCC. Among 19 samples (pronounced by 19 students) of each mandarin digit,
pick up one sample (from one student) for recognition and the rest of 18 samples
(from the other 18 students) of the digit is used for training, i.e., the rest of 18
samples of this digit is used to estimate the parameters which represent the digit.
Hence each of 19 students has to be tested, i.e., there are 19 testing samples for
each digit.
Since the average value of samples tends to be normally distributed. In or-
der to reduce computation for classification, we assume that all elements in the
12x10 matrix of feature values are stochastically independent. It was proved [14]
that using weighted variance in the Bayes decision rule for each class may increase
the recognition rate. Hence, the conditional normal density given syllable ci with
weighted variance c can be represented as
f(x1, ..., xk|ci) =
[
k∏
l=1
1√
2picσil
]
e
− 12
∑k
l=1
(
xl−µil
cσil
)2 (4.1)
where i = 1, ...,m = 10, k = 12x10 and c is a weighted factor for the variance.
10
(95.3%) (93.7%) (95.8%) (94.2%)
total testing samples=100
10 students 100 96 100 96
(pronounce (100%) (96%) (100%) (96%)
most clearly)
Table 4.1 also shows the misclassified digits pronounced by the 10 students who
pronounce most clearly and distinctly. Since all mandarin syllables are monosylla-
bles, the speech wave for each monosyllable is short. If the monosyllables are not
pronounced clearly, it is difficult to recognize by the human ear. Hence, to test the
recognition ability of the Bayes decision rule, which should not be damaged by the
ambiguous pronunciation, we selete 10 students (4 female and 6 male) among 19
students, who pronounce most clearly and distinctly. As in the first speech experi-
ment, 10 digits pronounced by each student are used for testing and 90 samples (9
samples for each digit) from the other 9 students are used for training the means
and the variances of each digit. There are 10 testing samples for each digit. From
the classification in digits, the LPCC for speech recognition is lightly better than
the MFCC for two criteria (absolute and squared differences). After compression
of a sequence of LPCC and MFCC vectors, the two compression criteria give about
the same recognition rates, but the squared difference criterion takes less time to
compute. The same speech recognition experiment was implemented in a quiet en-
vironment [14] and gave the correct digit recognition rate 98.6%. For the robustness
to the noise, our results show that the LPCC gives a recognition rate no less than
the MFCC. This contradicts to the results obtained by Davis and Mermelstein [5]
in a quiet environment.
4.2. The Speech Recognition
12
syllables with a total 1523 samples to be tested in speech recognition, i.e., each of
1523 samples is used for testing and the remain of 1522 samples are used to train 91
different syllables. The recognition rates are increased to 0.9140 for the LPCC and
0.8188 for the MFCC. The recognition results for 91 syllables are shown in Table
4.2.
The above recognition rates all show that the LPCC feature is a little higher
than the MFCC. Hence we make a statistical hypothesis testing in our study. We
adopt two nonparametric methods (McNemar test and Cochran Q-test) [15] to
test if the LPCC is better than the MFCC. The McNemar test is to compare two
rates provided by the LPCC and MFCC individually. We obtain the appproximate
standard normal z−value 7.4593 for 102 syllables and 7.3899 for 91 syllables. Both
are strongly significant at the level α = 0.0001.
The Cochran Q-test is to compare two features (MFCC and LPCC) if they are
equally effective in classification. We obtain the approximate Chi-square (df=1) Q
value 55.6411 for 102 syllables and 54.6104 for 91 syllables, which are both strongly
significant at the level α = 0.0001. Both tests show in Table 4.3. Obviously, the
two nonparametric tests make a decision to favor the LPCC.
14
into a matrix of LPCC (MFCC) values, which tend to have a normal distribution.
Using the Bayes decision rule, we have found that in the first digit experiment, the
mandarin digit recognition rate using LPCC feature is no less than the rate using
the MFCC feature. In the second speech recognition experiment, we build a large
amount of mandarin syllables, which are the most commonly used in usual conver-
sations. From the nonparametric statistical analysis, the LPCC has a significant
higher ability in classification than the MFCC. Furthermore, the LPCC feature
needs much less computational time to be extracted from speech signal waveform
than the MFCC.
References
[1] S. S. McCandless, ”An algorithm for automatic formant extraction using linear
prediction spectra”, IEEE Trans. Acoust., Speech, Signal Processing, ASSP-
22(2), 135-141, 1974.
[2] B. S. Atal and S. L. Hanauer, ”Speech analysis and synthesis by linear predic-
tion of the speech wave”, J. Acoust. Soc. Amer., 50, 637-655, 1971.
[3] J. Makhoul and J. Wolf, Linear Prediction and the Spectral Analysis of Speech,
Bolt, Baranek, and Newman, Inc., Cambridge, Mass., Rep. 2304, 1972.
[4] J. Tierney, ”A study of LPC analysis of speech in additive noise”, IEEE Trans.
Acoust., Speech, Signal Processing, 28(4), 389-397, 1980.
[5] S. B. Davis and P. Mermelstein, ”Comparison of parametric representations for
monosyllabic word recognition in continuously spoken sentences”, IEEE Trans.
Acoust., Speech, Signal Processing, 28(4), 357-366, 1980.
[6] W. Q. Zhang, L. He, Y. L. Chow, R. Z. Yang, and Y. P. Su, ”The study on
distributed speech recognition system”, IEEE 2000 ICASSP, 1431-1434.
[7] T. Fukuda, M. Takigawa, and T. Nitta, ”Peripheral feature for HMM-based
16
