 original clean speech. P.563 [6], standardized in 2004, is the state-of-the-art non-intrusive algorithm 
at present. In this 2-year project, we will propose both intrusive and non-intrusive algorithms. In the 
first year, we start from building an intrusive measure and the findings from this study will be 
utilized in developing a non-intrusive measure next year. 
In this study, we utilize a joint spectro-temporal perceptual auditory model to objectively 
estimate subjective MOS by comparing the perceptual differences between the clean and degraded 
speech. These perceptual differences are derived from the joint spectro-temporal modulations of the 
speech. Such modulations are assumed to be perceived by human brains and certain ranges are 
presumed to be related to speech quality [7]. The remainder of this report is organized as follows. 
We will first give a brief overview of the ITU-T standard, PESQ, and the perceptual multiresolution 
spectro-temporal auditory model. We next derive the intrusive measure and conduct computer 
simulations. The comparison between clean and degraded speech signals provides us some expected 
results and hence the verification. At the end, we finalize our subjective MOS estimation by using 
the multiple regression analysis to map our proposed perceptual differences to the subjective MOS. 
 
2. OVERVIEW OF PESQ 
 
PESQ (Perceptual Evaluation of Speech Quality), an intrusive, objective speech quality 
measurement, is released by ITU-T in 2001. It is suitable for 3.1 KHz handset telephony and 
narrow-band speech codec. It evolved from the PSQM [8], which was proposed in 1998 and makes 
use of MFCC (Mel-Frequency Cepstrum Coefficient), combined with the time-alignment algorithm 
in PAMS (Perceptual Analysis Measurement System). It mainly focuses on the evaluation of speech 
codecs and the impacts of one-way speech distortion and noise on speech quality. Therefore, there 
are many effects which can not be effectively evaluated, such as echo, loudness loss, etc. Due to the 
fact that it consists of a time-align algorithm, any errors from the time alignment would definitely 
impair the performance of the PESQ seriously. 
PESQ is the standard intrusive speech quality measurement nowadays. Its MOS estimate 
achieves more than 90% correlation with the subjective MOS in many conditions. The basic 
concept of PESQ is illustrated in Fig.1. First, it performs the time-alignment between the clean and 
degraded speech, then transforms both signals through a perceptual model into some internal 
representations along the hearing pathway. It finally computes the differences (distances) between 
those time-frequency domain internal representations and estimates the objective MOS based on 
these distances. 
 
 
Fig.1. Basic concept of PESQ 
2 
 “missing” components. At the end, silence detection is performed to put more weights on the 
distortions from silent parts of the speech. The resulting values of DAn and Dn must be accumulated 
throughout the whole speech. The effectiveness of PESQ has been tested through lots of 
experiments. The standard documents list all factors that can or can not be effectively tested as in 
Table 1. From the table, usual distortions present within two-way communications are not 
accounted for in PESQ algorithm, hence, they will not be accounted for in our algorithm either. To 
sum up from Fig.2, major perceptual properties considered in PESQ are (1) non-linear frequency 
selectivity of the cochlea (Bark scale); (2) non-linear mapping between intensity and loudness; (3) 
asymmetry weightings on “additive” or “missing” frequency components and (4) asymmetry 
temporal weightings on voiced or silent parts of speech. The properties (1) and (2) stem from the 
low-level physiological functions of hearing, while properties (3) and (4) are from high-level 
cognitive functions. 
 
Factors that can be tested (experimentally proved): 
Test factors: 
Speech input levels to a codec 
Transmission channel errors 
Packet loss and packet loss concealment with CELP codecs 
Bit rates if a codec has more than one bit-rate mode 
Transcodings 
Environmental noise at the sending side  
Effect of varying delay in listening only tests 
Short-term time warping of audio signal 
Long-term time warping of audio signal 
Coding technologies 
Waveform codecs, e.g. G.711; G.726; 
 G.727CELP and hybrid codecs ≥4 kbit/s, e.g. G.728, G.729, G.723.1 
Other codecs: GSM-FR, GSM-HR, GSM-EFR, GSM-AMR, CDMA-EVRC, TDMA-ACELP, 
TDMA-VSELP, TETRA 
Application 
Codec evaluation 
Codec selection 
Live network testing using digital or analogue connection to the network 
Testing of emulated and prototype networks 
Factors that can＇t be tested (experimentally proved): 
Test factors 
Listening levels 
Loudness loss 
Effect of delay in conversational tests 
Talker echo 
Sidetone 
Coding technologies Replacement of continuous sections of speech making up more than 
25% of active speech by silence (extreme temporal clipping) 
Applications 
In-service non-intrusive measurement devices 
Two-way communications performance 
Table 1. Factors that can or can not be tested by PESQ 
 
3. PHYSIOLOGY BASED AUDITORY MODEL 
 
The auditory model used in this study is based on biophysical, psycho-acoustical and 
4 
  ( , ) ( )* ( ; )coch ty t x s t h t x= ,    (1) 
 ( , ) ( ( , ))* ( )AN t coch ty t x g y t x w t= ∂ ,    (2) 
 ( , ) max( ( , ),0)LIN x ANy t x y t x= ∂ ,    (3) 
                       ( , ) ( , )* ( ; )final LIN ty t x y t x tµ τ= ,                  (4) 
where  denotes convolution operation in time. The is called an auditory spectrogram 
which represents the auditory nerve activity in the time-log. frequency domain. Details of the 
known biophysical basis and anatomical structures in this early stage are available in [9][10] and 
the two-dimensional auditory spectrogram has been shown to be an enhanced and noise-robust 
estimate of a traditional spectrogram [11].  
t∗ ( , )finaly t x
 
3.2 The cortical stage: spectrogram analysis 
 
Fig. 4. Multi-resolution representation of speech in the cortical stage. 
 
The processes of the cortical stage are demonstrated in Fig. 4. This stage mimics the action of 
the primary auditory cortex (AI). The auditory spectrogram, shown on the left panel in Fig. 4, is 
analyzed by a bank of 2-D filters which are selectively tuned to different spectro-temporal 
modulation parameters. One of the parameters is temporal modulation that defines how fast the 
signal energy decreases or increases along the time axis at a given (time, frequency) instant and is 
regarded as rate or velocity (ω  in hertz). The other parameter is the spectral modulation that 
defines how broad the signal energy distributes along the frequency axis at a given (time, frequency) 
instant and is referred to as scale or density (Ω  in cycles/octave). Each directional selective 
spectro-temporal response field (STRF) corresponds to the most responsive patterns of a single 
neuron in the AI. The output from each neuron is computed by convolving the input spectrogram 
with its STRF and can be reduced to a four-dimensional complex-valued representation. Afterwards, 
the cortical representation is a four-dimensional pattern along the time ( t ), frequency ( x ), rate (ω ) 
and scale (Ω ) axes. The cortical response (r) produced by the STRF analysis of the auditory 
spectrogram is defined as: ( , )y x t
                    ( , ; , ) ( , ) ( , ; , )t xr x t y x t STRF x tω ωΩ = ∗ Ωi ,                (5) 
where denotes convolution with respect to and multiplication with respect tot x∗ i t x . 
Various views of the cortical representations can be observed by integrating all filters’ output 
along one or more dimensions. For example, the average scale-rate plot of a speech, shown on the 
right panel in Fig. 4, can be obtained by averaging over all frequencies (128 cochlear channels) and 
a given duration in the time domain. The average scale-rate plot is simply defined as: 
6 
 the PESQ algorithm, the perceptual difference (distance) was computed between clean and 
degraded scale-rate representations, which account for the joint spectro-temporal modulations of the 
auditory spectrograms. Note, only the additive noise conditions were considered here, so 
time-alignment process was not required. The scale-rate distances were then modified by an offset 
sigmoid function, which reflects human cognitive behaviors on the saturation of large distances. 
The saturated scale-rate distances were then mapped to the PESQ_MOS by simple regression 
functions. Our estimated MOS after the regression function is referred to as NSLtool_MOS.  
The mean and variance of PESQ_MOS and NSLtool_MOS are shown in Table 2. The 
correlation between PESQ_MOS and NSLtool_MOS is as high as 96.94% by using a linear 
regression function. The correlation between the two would be up to 97.07% if a pure quadratic 
regression function is used.  
The simulation was extended to include 5 sentences from each of 10 female and 10 male 
speakers randomly chosen from dialect region 1 and 2 of TIMIT corpus. It was to investigate the 
dependency of our measures on gender or speech. The correlation between our measure and 
PESQ_MOS is 95.72% by a pure quadratic regression function. These high correlations indicate our 
proposed intrusive measure is equivalent to the ITU-T standard, PESQ, in assessing speech quality 
under additive white noise degradation.  
 
SNR (in dB) PESQ_MOS Var. NSLtool_MOS Var. 
-10 0.8617 0.1542 1.1 0.0001 
-5 1.0149 0.153 1.1011 0.0007 
0 1.2441 0.1282 1.1257 0.0191 
5 1.5555 0.1237 1.3222 0.1049 
10 1.9212 0.1137 1.8358 0.1699 
15 2.2991 0.1028 2.4237 0.1438 
20 2.6876 0.1174 2.8524 0.0911 
25 3.0654 0.1522 3.0948 0.0471 
30 3.4271 0.1669 3.221 0.0234 
 
 
 
 
 
 
 
 
 
Table 2. PESQ estimated MOS and NSLtool estimated MOS comparison (Using pure 
quadratic regression) 
 
5.  DISCUSSIONS AND FUTURE WORKS 
 
Our measure is derived from a detailed biophysical auditory model. Such model is able to address 
more perceptual properties than those considered in PESQ, thus, presumably gives a more similar 
measure as human behaviors. Here, we further discuss some observations and future works 
associated with this study. 
1. Perceptual properties in PESQ and our measure: (1) the Bark scale used in PESQ is 
similar to the constant-Q cochlear filterbank used in our model; (2) loudness scale instead 
of intensity scale used in PESQ is accounted for by the non-linear compression of hair 
cells in our model; (3) asymmetry weightings on “additive” or “missing” frequency 
components considered in PESQ can be addressed by the offset sigmoid function which is 
used to modify the distances of the scale-rate representation. This sigmoid function causes 
NSLtool_MOS very close at 0, -5 and -10 dB, unlike the PESQ_MOS. This phenomenon 
is actually closer to human behavior on speech with bad quality, for that there are no 
“worse” or “worst” quality beyond “bad” quality. The only perceptual property in PESQ, 
but not in our model is the asymmetric temporal weighting, which is closely affected by 
8 
 計畫成果自評 
    此研究內容與原計畫書大致相符、也達成預期目標（1.證明我們的聽覺運算模型可客觀
地量測語音品質，2.其效能與目前之侵入式客觀語音品質量測之標準－PESQ 相當)。雖然原本
第二年之計畫是要發展 model-based 的非侵入式語音品質量測(建立乾淨語音之統計模型，將
骯髒語音與預估之乾淨語音做比較)，但從今年的研究中給了我們新的想法，似乎我們的聽覺
運算模型可以試著評估一些語音品質的感知特性，例如理解度、清晰度及自然度，進而發展 
parameter-based 的非侵入式語音品質量測。這種parameter-based 的語音品質量測的想法更
直觀且更自然。我們未來將對此兩類方法分別進行研究，其成果應可投稿於國際學術研討會或
期刊。 
10 
