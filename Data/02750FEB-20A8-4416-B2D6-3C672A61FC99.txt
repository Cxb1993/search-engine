 1
行政院國家科學委員會專題研究計畫成果報告 
計畫編號：NSC99-2221-E-150-064 
執行期限：99 年 8 月 1 日至 100 年 7 月 31 日 主持人：黃惠俞   
執行機構及單位名稱：國立虎尾科技大學資訊工程系 
計畫參與人員：徐世航 (國立虎尾科技大學資工系碩士生)、 
          黃智慧 （國立中正大學資工系博士生） 
 
                    
一、中文摘要 
 
人臉識別是一種基於人的臉部特徵信息進
行身份認證的生物特徵識別技術之一。然
而人臉影像的取得常在一般的環境下透過
數位相機或攝影機器具拍攝所獲得，其重
要的五官特徵經常會受到一些遮罩物或特
別偽裝所掩蓋，大大增加辨識的困難點及
準確度，但這問題卻是一項重要且需要透
過技術處理克服的。因此，本研究希望重
現遮蔽物下的臉型特徵，研究設計一系列
的處理方法，並結合生物特徵建立人臉模
版及比對技術，達到自動化且有效辨識認
證的系統。讓系統不因人臉照片受到外在
因素的影響而降低辨識的能力。 
本研究的主要目的是設計出一有效針
對臉部被遮罩下之人臉表情重現及識別之
系統。將基於主動外觀模組演算法為主要
設計主軸，並利用生物統計學的原理進行
人臉生物特徵的分析及數學模型的建立，
即人臉特徵模板的建立。依據外型模組的
人臉三角化網狀圖取得內部紋理資訊，配
合主成份分析作特徵擷取，進而匹配擬合
出適當的外觀資訊以重建出可靠的臉部資
訊。而後將依據這資料進行一系列的辨識
處理，既使當臉部被遮罩或偽裝時也能有
效的辨識出。 
經實驗證明本計畫所建置之處理程序
可成功擬合出相似的臉部表情以及在人臉
辨識過程中，在處於少量樣本下也能具有
高水準的辨識程度，達到本計畫之目標。 
關鍵詞：主動外觀模組，支撐向量機分類 
 
Abstract 
Face recognition is based on persons’ facial 
features information for authentication of 
biometric identification technology. 
However, the acquisition of face images in 
the general environment often through the 
digital camera or film camera equipment 
acquired, the important facial features are 
often masked by some kinds of accessories 
or special camouflage concealed which will 
greatly increase the difficulties of 
recognition and accuracy. These problems 
are serious and need to overcome. Therefore, 
this study is to design a series of processing 
methods to reconstruct face pattern under 
the face-masked and combined the biometric 
 3
術，達到自動化且有效辨識認證的系統。
讓系統不因人臉照片受到外在因素的影響
而降低辨識的能力。 
 
三、文獻探討 
為了能順利處理臉部的五官特徵，採用熱
門 Viola–Jones(V-J)[1]人臉偵測法定位技
術，並由 Cootes 等人發展的主動外觀模
型 (Active Appearance Models ， 簡 稱
AAM)，利用統計的方式將具有形狀及紋
理變異的影像物件模型化[2,3]。主動式外
觀模組包含了三大部分：外形模組的貼
齊、紋理模組的建立以及外觀模組的合
成。此模型可藉由一個搜尋演算法達到影
像分析的效果，以特徵資訊描述紋理、膚
色及表情的變化，其計算運算式定義如
(3-1)式。 
X X M c= + ⋅  (3-1) 
 
其中 M 代表訓練好的外觀模型搭配外觀
變動向量 c 再加上平均模型 X 即為新的臉
部影像。而 c 可形容臉部的表情或姿態。
目前 AAM 已成功地被應用於各個領域，
如人臉的模型化[4]，醫學影像的分割[5]，
人臉表情辨識[6]，及物件追蹤[7]。 
基於此本研究計畫將採用以可靠的外
形資訊及擷取到的特徵訊息去推算對應的
紋理資訊，進而重建出一張具有表情的人
臉外觀。 
 
四、研究方法： 
圖 4-1 為本系統之架構圖。首先以手動標
定特徵點，再對全部樣本尺度正規化並求
出平均模型以及轉置矩陣所形成的外形模
組。接著使用三角化方式規劃人臉區域，
再以分段仿射變形方式對三角形內作紋理
及色彩的填補動作，最後再合成出一張近
似原始影像的人臉。 
 
 
圖 4-1 系統架構圖。 
 
4.1 形狀模組 (Shape model) 
主 動 形 狀 模 組 (active shape models, 
ASM)[8]為一種基於模型的特徵匹配方
 5
 
在調整完所有特徵點後，再利用全域形狀
模型的適應型仿射轉換  (adaptive affine 
transform，AT)如(4-6)式，以更新標定特徵
點到更貼切的位置。藉此，能讓下一次搜
尋的初始位置更加靠近應該被定位的位
置，同時能修正形狀參數 b，讓形狀模型
更符合更新後的特徵點位置。透過上述動
作，反覆迭代到模型參數收斂為止，即定
位出符合當前目標的形狀。以下為適應型
仿射 AT 轉換：首先需得知 cs 與 cθ 分別為參
考影像 imagex 與待測影像 imagey 以仿射轉換得
出的尺度因子與旋轉角度。而 cx 與 cy 分別
為 imagex 與 imagey 兩者重心的差值。 
( )cos( ) ( ) sin( )
,
( )sin( ) ( ) cos( )
t c c c c c
c c c ct c
x
AT
y
x x s s s s s x
s s s s sy y y
θ θ θ θ
θ θ θ θ
⎛ ⎞ =⎜ ⎟⎝ ⎠
+ ⋅ + ⋅ +⎡ ⎤ ⎡ ⎤ ⎡ ⎤+⎢ ⎥ ⎢ ⎥ ⎢ ⎥− ⋅ + ⋅ ++ ⎣ ⎦⎣ ⎦⎣ ⎦
 
(4-6)
其中對當前特徵點位置 ( , )x y 而言， cθ θ+ 為
旋轉角度， cs s⋅ 為尺度因子，位移單位為
( )t tx x+ 與 ( )t ty y+ 。接著，以四層多解析度
金字塔(4-level multi-resolution pyramid)計
算其影像特徵點位置，並搜尋矩形邊的採
樣點數，同時更新形狀參數 b 直到能貼合
(fit)模型而形成新的一點。直到超過 95%
的特徵點能在 1/2 圖像中被發現，即收
斂；或是已達到最大迭代次數，迭代次數
可以人為設定終止條件，其預設值為 24
次。 
 
4.2 紋理模型(Texture model) 
紋理資料會因為人臉形狀上的不同再同一
區域中其灰階值數目不盡相同(如五官表
情、臉形等的差異，同一區域中灰階值數
目不相同)，需要紋理資料擷取數目上的校
正。我們需要利用形狀上的資訊，由於形
狀標定點內部即為我們需要的紋理資訊，
將形狀標定點作三角形化如圖 4-4(右)所 
示，得到一個人臉的三角形化網狀圖。如
此以來，對於不同的人臉我們都可以得到
相同數量的三角形，再利用一個一般表情
的人臉來定義出每個三角形內部應該取出
紋理資訊的點數與相對位置。即可將人臉
紋理特徵點大小值確定。 
    
     (a)         (b) 
圖 4-4 (a)臉部標定點。(b)人臉三角形化網
狀圖。 
 
為捕捉人臉紋理，首先將形狀模組之
平均形狀利用 Delaunay Triangulation 演算
法作臉部區域三角化[9]，針對訓練影像對
應的三角化臉部區域內，收集三角形內的
像素值，以雙線性內插法方式將包含的像
素填滿。如此便捕捉到一個臉部片段的紋
理資訊，如下圖 4-5。 
 7
 
圖 4-7 分段仿射變形演算法示意圖 
 
則 X 在右邊三角形中之對應點 W(X)表示： 
 
( ) ( )
[ ] [ ]
,
.
T
i iW X x y
D E D F Dα β
=
= + − + −  (4-10) 
如此便定義了兩個三角形內部任意一點之
對應關係。 
4.4 人臉辨識 (Face recognition) 
使用徑向基底(Radial basis function, RBF)
核函數，在模組調校上只需調整成本函數
c 和測試核函數 Gamma，也由於輸入向量
值介於 0~1，降低操作複雜性且具有較高
的預測能力。然而為了避免不當的選取參
數將使模型容易陷於過度擬合的發生，將
評估分類演算法的績效表現通常採用
Kohavi [11]所提出的 K 次交叉驗證(K-fold 
cross-validation)的衡量方式進行改良。將
所有樣本分為訓練集合與測試集合兩部
分，訓練集合則做為該演算法的學習資
料，用以建構分類法則；測試集合的樣本
則是做為衡量分類法則績效的測試資料。 
 
五、實驗結果與討論 
本章將對本論文所提出的方法進行驗
證。利用公開的 AR 人臉資料庫[12]，在
具有表情變化、穿戴眼鏡、留鬍子、劉海
或是頭部姿勢微偏等因素下，包含 75 位男
性以及 46 位女性單一背景之正面臉像進
行人臉特徵點定位及擬合與人臉識別三大
部分作分析與結果比較。如表 4-1，對資
料庫樣本數，類別個數以及單類張數，其
總樣本數為原始資料庫圖像加上主動外觀
模組對資料庫作擬合後的合成影像，使得
單類樣本數增加為兩倍。而分類器方面以
十次交叉驗證法方式拆分訓練樣本以及測
試樣本，並對支撐向量機進行評估。 
 
表 5-1  Dataset with database 
Dataset Original 
Image 
Fitting  
result 
Total 
samples
Samples 242 242 484 
Individual
s 
121 121 121 
Sample in 
a class 
2 2 4 
 
其中將全部樣本切割為 10 等分，依序將其
中 的 9 等 分 作 為 訓 練 樣 本 (training 
samples)，而剩下的 1 等分作為一次的辨
識驗證的測試樣本(testing samples)以求其
十次結果作平均。 
 
5.1 評估定位效能之方法 
為評估外形模型的定位效能，以計算平均
定位差(average localization error, E) 如計
算式(5-1)式來計算原始影像與合成後影像
兩者特徵點位置，方可明顯比較出差距。 
 9
 
圖 5-3 良好的外觀表情合成結果範例。 
 
然而當外形模組定位的特徵點位置有
失真的現象會直接導致紋理資訊填補動作
錯誤，使得合成的外形明顯扭曲變形。基
於三角化區域填補的方式，使得將要合成
的片段紋理資訊邊界會有不平滑的菱角痕
跡，產生不合理的外觀雜訊。再者，基於
主成份分析以平均模型為參考，導致眼部
區域可能會有合成誤差產生，使原本沒有
配戴眼鏡的待測人臉在擬合後的合成臉像
可能會出鏡框殘影的現象。如圖 5-4 臉部
外觀合成失敗的案例。 
 
 
圖 5-4 臉部外觀合成失敗的案例。 
 
z 人臉辨識分析 
藉由徑向基底核函式處理非線性資料，搭
配主成份分析作特徵擷取，以少數張量下
的支撐向量機分類作人臉資料庫辨識動
作。如何評估分類性能有兩點，目標樣本
正確分類的樣本個數比例(True Positive 
Rate, TPR)，二為非目標樣本被分類成錯誤
樣本個數比例(False Positive Rate, FPR)。
TPR 可稱為靈敏度(sensitivity)，而(1-FPR)
稱為明確性(specificity)。本研究以靈敏度
以及明確性來表示 ROC_I 曲線。然而，
若以辨識系統考量，理想應該降低 FAR 
值以排斥不應該進來的人，同理卻會造成
允許進來的人門檻值提高，亦是 FRR 值
 11
好的辨識率。因此，其結果大致上達到預
期的目標。本研究之部分成果已發表在重
要的國際會議論文上[13-15]。 
對於未來的工作，將針對眼鏡物件的
遮蔽物修飾能更加平滑自然，合成後的人
臉影像做擬合的動作也需要更加的自然，
不然很容易就看出有處理過後的痕跡，雖
然這些雜訊對辨識處理上沒有直接的關
係。最重要的，還是頭部姿勢偏移的問題，
由於外形模組只針對正面人臉影像作特徵
點貼齊動作，假若偏移量過大，所定位的
外形很敏感的就出現失真的情形，也直接
導致在紋理模組在填充資訊的過程中置入
錯的區域，使得人臉扭曲變形。而表情變
化方面，除非是遇上誇張的表情使得模板
匹配的過程中陷入局部最小化這個潛在的
情況，就一般自然的表情而言是可以容許
外形定位上的小偏差。往後研究課題將針
對這些問題進行系統之改良。 
 
七、參考文獻 
[1]. P. Viola and M. Jones, “Robust 
real-time object detection,” 
International Journal of Computer 
Vision, Vol. 57, No. 2, pp. 137-154, 
2004. 
[2]. T.F Cootes, G. J. Edwards, and C. J. 
Taylor, “Active appearance models,” In 
Proc. 5th European Conference on 
Computer Vision, Vol. 2, pp 484-498, 
1998. 
[3]. T. Cootes, G. Edwards, and C. Taylor, 
“Active Appearance Models,” IEEE 
Transactions on Pattern Analysis and 
Machine Intelligence, Vol. 23, no. 6, 
pp.681-685 , 2001. 
[4]. G. Edwards, C. Taylor, and T. Cootes, 
“Interpreting face images using active 
appearance models,” In Proc. IEEE 
Int’l Conf. Automatic Face and Gesture 
Recognition, pp. 300-305, 1998. 
[5]. S. C. Mitchell, J. G. Bosch, B. P. F. 
Lelieveldt, R. J. van der Geest, J. H. C. 
Reiber, and M. Sonka, “3-D active 
appearance models : Segmentation of 
cardiac MR and ultrasound images,” 
IEEE Trans. Medical Imaging, Vol. 21, 
no. 9, pp.1167-1178, 2002. 
[6]. Simon Lucey, Iain Mattews, Chango 
Hu, Zara Ambadar, Fernando de la 
Torre, and Jeffry Chon, “AAM Derived 
Face Representations for Robust Facial 
Action Recognition,” Int. Conf. on 
Automatic Face and Gesture 
Recognition, pp.155-160, 2006. 
[7]. M. B. Stegmann, “Object tracking 
using active appearance models,” in 
Proc. 10th Danish Conf. Pattern 
Recognition and Image Analysis, Vol.1, 
pp. 54–60, 2001. 
[8]. S. Marcel and J. Keomany, “Robust to 
illumination face localization using 
active shape models and local binary 
patterns,” IDIAP Research Report, pp. 
6-47, 2006. 
[9]. C.Y. Chen, A Hierarchical Spatial 
Clustering Algorithm Based on 
Delaunay Triangulation Master Thesis, 
Feng Chia University, 2005. 
[10]. I. Matthews and S. Baker, “Active 
Appearance Models revisited,” Int. 
Journal of Computer Vision, Vol.60, no. 
2, pp. 135-164, 2004. 
[11]. R. Kohavi, “A study of cross-validation 
and bootstrap for accuracy estimation 
and model selection,” in Proc. of 
Fourteenth Int. Joint Conf. on Artificial 
Intelligence, pp. 1137-1143, 1995. 
[12]. A. M. Martinez, and R. Benavente, 
“The AR Face Database,” CVC 
Technical Report #24, June 1998. 
[13]. (EI) H. Y. Huang* and S. H. Hsu, “An 
efficient landmark localization for face 
occlusion,” in ICMLC2011 Invited 
Session: Intelligent Systems: 
Methodologies and Applications, pp. 
表 Y04 1
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                     一百年五月十八日 
報告人姓名 黃惠俞 
Hui-Yu Huang 
 
服務機構
及職稱 
國立虎尾科技大學 
資訊工程學系 助理教授 
  時間 
會議 
     地點 
100 年 4 月 10 日至 4月 17
日  
法國 巴黎 
本會核定
補助文號
NSC99-2221-E-150-064 
會議 
名稱 
 (中文) 2011 IEEE計算機智慧系列研討會 
 (英文)2011 IEEE Symposium series on Computational Intelligence 
發表 
論文 
題目 
 (中文) (1)基於搜尋樣型與預測器之區塊移動估測 
(2)一個以 9/7 小波為基的無失真資料隱藏 
 (英文) (1)Block motion estimation based on search pattern and predictor 
(2)A 9/7 wavelet-based lossless data hiding 
報告內容應包括下列各項： 
一、參加會議經過 
在本次的 IEEE workshops 中我有兩篇論文分別被選為以口頭報告及海報方式進行發表，
並安排在四月十三日的 oral presentation 及整天的 poster section。由於本大會有相當的多會議
在本次大會中聯合進行學術發表，因此，在會議舉行的期間每天都有不同的
symposia/workshops 同時進行，而我所屬的 workshops 是 “2011 IEEE Symposium on 
Computational Intelligence for Multimedia, Signal, and Vision Processing, CIMSIVP’2011” ，且被
安排在四月十三日整天的時間進行會議。所有的 oral presentation 及 Keynotes 皆在一間大型
的階梯教室舉行，而 poster 則在 2 大間的 coffee break rooms 中進行，供來賓與展示之學者
有著更輕鬆及直接的接觸共同分享研究成果。 
當然為本次亦製作一大張 A0 大小之海報資料攜至大會會場及 oral presentation 資料。於會
議舉行前搭乘長榮航空飛抵開會地點法國戴高樂國際機場 (Roissy Charles de Gaulle 
Airport)。會議舉行之地點是位在 Université Denis Diderot (Paris 7) 大學內舉行。此次大會有
相當多的 workshops 聯合舉行會期共 5 天，會議議程時間安排是相當緊湊。 
二、與會心得 
此 IEEE workshops 會議(SSCI2011)為期五天(四月十一號至十五日)在法國巴黎舉行。我的
論文在會議中是以口頭報告及海報方式進行論文報告及成果展示。與會的人員有來自世界各
附件三
 
表 Y04 3
四、建議 
無 
五、攜回資料名稱及內容 
本次會議主要攜回論文拇指碟一枚。論文數目眾多，因此僅對所屬相關會議進行統計共
有兩場 keynote speaks、oral papers and poster papers 共 18 篇等全文論文。其主要目錄依日期
分列，如附錄二。 
六、其他 
  附上會議之舉行地點及會場照片如下。 
 
大會會址       大會會場 
 
大會會場(場外、場內) 
Symposium Series on Computational Intelligence
IEEE SSCI 2011 April 11 – 15, 2011 Paris, France
CALL FOR PAPERS
This international event promotes all aspects of the theory and applications of Computational Intelligence. With its 
hosting of over thirty technical meetings in one location, it is bound to attract lead researchers, professionals and 
students from around the world.  Sponsored by the IEEE Computational Intelligence Society, the 2011 edition 
follows in the footsteps of the SSCI 2007 meetings held in Honolulu and of the SSCI 2009 series held in Nashville. 
The event will take place in the magic town of Paris.
Symposia and Workshops
Acronym and Title Chairs
ADPRL 2011 Symposium on Adaptive Dynamic 
Programming and Reinforcement Learning 
Jagannathan Sarangapani, Missouri Univ. of Science and Techn., USA. Zhang Hua-
guang, Northeastern Univ., China. Marco Wiering, Univ. of Groningen, Netherland.
CCMB 2011 Symposium on Computational 
Intelligence, Cognitive Algorithms, Mind, and Brain.
Leonid Perlovsky,  Harvard University and Air  Force  Research Laboratory,  USA. 
Robert Kozma, Memphis University, USA. Damien Coyle, University of Ulster, UK 
CIASG 2011 Symposium on Computational 
Intelligence Applications in Smart Grid
Ganesh  Kumar  Venayagamoorthy,  Missouri  University  of  Science  and 
Technology, USA
CIBCB 2011 Symposium on Computational 
Intelligence in Bioinformatics and Computat. Biology 
Clare Bates Congdon, University of Southern Maine, USA
CIBIM 2011 Workshop on Computational 
Intelligence in Biometrics and Identity Management
Qinghan  Xiao,  Defence  R&D,  Canada.  David  Zhang,  Hong  Kong  Polytechnic 
University, China. Fabio Scotti, University of Milan, Italy
CICA 2011 Symposium on Computational 
Intelligence in Control and Automation
Xiao-Jun Zeng, University of Manchester, UK
CICS 2011 Symposium on Computational 
Intelligence in Cyber Security 
Dipankar Dasgupta, University of Memphis, USA. Justin Zhan, National Center of 
Infrastructure Protection, USA
CIDM 2011 Symposium on Computational 
Intelligence and Data Mining
Nitesh  Chawla,  University  of  Notre  Dame,  USA.  Irwin  King,  The  Chinese 
University of Hong Kong, China. Alessandro Sperduti, Padova University, Italy
CIDUE 2011 Symposium on Computational 
Intelligence in Dynamic and Uncertain Environments
Yaochu Jin, University of Surrey, UK.  Shengxiang Yang, Brunel University, UK. 
Robi Polikar, Rowan University, USA 
CIFEr 2011 Symposium on Computational 
Intelligence for Financial Engineering & Economics 
Han La Poutre, CWI, Netherlands. Ronald R. Yager, Iona College, USA.  Robert 
Golan, Dbmind Technologies, USA
CII 2011 Symposium on Computational Intelligence 
in Industry
Yaochu Jin, University of Surrey, UK. Piero P. Bonissone, GE Global Research, 
USA. Jennie Si, Arizona State University, USA
CIMI 2011 Workshop on Computational Intelligence 
in Medical Imaging
Gerald  Schaefer,  Dpt.  Of  Computer  Science,  Loughborough  University,  UK.  . 
Sergio Damas, European Center for Soft Computing, Mieres, Asturias, Spain
CIMR 2011 Workshop on Computational Intelligence 
for Mobile Robots: Air-, Land-, and Sea-Based
Lyle N. Long, Pennsylvania State University, USA. 
CIMSIVP 2011 Symposium on Computational 
Intellig. for Multimedia, Signal and Vision Processing
Khan  M  Iftekharuddin,  University  of  Memphis,  USA.  Salim  Bouzerdoum, 
University of Wollongong, Australia
CIPLS 2011 Workshop on Computational 
Intelligence in Production and Logistic Systems
Bülent Çatay, Sabanci University, Turkey. Raymond Chiong, Swinburne Univ. of 
Technology, Australia. Patrick Siarry, Univ. Paris XII Val de Marne, France
CISched 2011 Symposium on Computational 
Intelligence in Scheduling
Rong Qu, University of Nottingham, UK. Ender Ozcan, University of Nottingham, 
UK. Michel Gendreau, École Polytechnique de Montréal, Canada
CISDA 2011 Symposium on Computational 
Intelligence for Security and Defence Applications 
Slawo Wesolkowski, DRDC, Canada.  Nur Zincir-Heywood, Dalhousie University, 
Canada,  James R. Dankert,  BAE Systems - AIT,  USA,  Rami Abielmona,  Larus 
Technologies, Canada
Acronym and Title Chairs
CIVI 2011 Workshop on Computational Intelligence 
for Visual Intelligence
Guilherme N. DeSouza,  University of  Missouri,  USA.  Yuanqiang (Evan)  Dong, 
University of Missouri, USA
CIVTS 2011 Symposium on Computational 
Intelligence in Vehicles and Transportation Systems
Danil Prokhorov, Toyota, USA. Dimitar Filev, Ford, USA 
CompSens 2011 Workshop on Merging Fields of 
Computational Intelligence and Sensor Technology
Ivo  Bukovsky,  Czech  Technical  University  in  Prague,  Czech  Republic.  Torsten 
Wagner, Tohoku University, Japan
EAIS 2011 Workshop on Evolving and Adaptive 
Intelligent Systems
Plamen  Angelov,  Lancaster  University,  UK.  Dimitar  Filev,  Ford,  USA.  
Nikola Kasabov, Auckland University of Technology, New Zealand
FOCI 2011 Symposium on Foundations of 
Computational Intelligence
Manuel Ojeda-Aciego, University of Malaga, Spain.  Carlos Cotta,  University of 
Malaga, Spain. Francisco Veredas, University of Malaga, Spain    
GEFS 2011 International Workshop on Genetic and 
Evolutionary Fuzzy Systems 
Rafael  Alcala,  University  of  Granada,  Spain.  Yusuke  Nojima,  Osaka  Prefecture 
University, Japan
HIMA 2011 Workshop on Hybrid Intelligent Models 
and Applications 
Patricia Melin, Tijuana Institute of Technology, Mexico
IA 2011 Symposium on Intelligent Agents Hani Hagras, University of Essex, UK. Vincenzo Loia, University of Salerno, Italy
IEEE ALIFE 2011 Symposium on Artificial Life Terry  Bossomaier,  Charles  Sturt  University,  Australia.  Hiroki  Sayama,  
State  University  of  New  York,  USA.  Chrystopher  Nehaniv,  University  of 
Hertfordshire, UK
IEEE MCDM 2011 Symposium on Computational 
Intelligence in Multicriteria Decision-Making
Carlos  A.  Coello  Coello,  CINVESTAV-IPN,  Mexico.  Piero  P.  Bonissone,  GE 
Global Research, USA. Yaochu Jin, University of Surrey, UK
MC 2011 Symposium on Memetic Computing Zexuan  Zhu,  Shenzhen  University,  China.  Maoguo  Gong,  Xidian  University, 
China.  Ji  Zhen,  Shenzhen  University,  China.  Yew-Soon  Ong,  Nanyang 
Technological University, Singapore
OC 2011 Workshop on Organic Computing Rolf Wuertz, Ruhr-Universität Bochum, Germany
RiiSS 2011 Workshop on Robotic Intelligence in 
Informationally Structured Space 
Honghai Liu, University of Portsmouth, UK. Naoyuki Kubota, Tokyo Metropolitan 
University, Japan
SDE 2011 Symposium on Differential Evolution Janez Brest, University of Maribor, Slovenia. Swagatam Das, Jadavpur University, 
India. P. N. Suganthan, Nanyang Technological University, Singapore
SIS 2011 Symposium on Swarm Intelligence Yuhui Shi, Xi'an Jiaotong-Liverpool University, Suzhou, China
T2FUZZ 2011 Symposium on Advances in Type-2 
Fuzzy Logic Systems
Hani  Hagras,  University  of  Essex,  UK.  Jerry  Mendel,  University  of  Southern 
California, USA. Bob John, De Montfort University, UK
WACI 2011 Workshop on Affective Computational 
Intelligence
Pau-Choo (Julia) Chung, National Cheng Kung University, Taiwan. Marie-Jeanne 
Lesot, LIP6-UPMC, France. Jean-Claude Martin, University Paris Sud, France
General Chair Bernadette Bouchon-Meunier, LIP6, CNRS-Univ. P. et M. Curie, Paris, France
Honorary Chair Vincenzo Piuri, University of Milan, Italy
Finance Chair Piero Bonissone, General Electrics, USA
Local Arrangement Chair Maria Rifqi, LIP6, Université Panthéon-Assas, Paris, France
Publication Chair Sylvie Galichet, Université de Savoie, France
Registration Chair Anne Laurent LIRMM Université Montpellier 2, France
Web Master Christophe Marsala, LIP6, Université Pierre et Marie Curie, Paris, France
Publicity Co-chairs Pau-Choo (Julia) Chung, National Cheng Kung University, Taiwan
Martine De Cock, Ghent University, Belgium
Slawo Wesolkowski, DRDC, Canada
Tutorial, Keynote and Panel
Co-chairs
Marios Polycarpou, University of Cyprus, Cyprus
Ali M.S. Zalzala, Hikma Group Limited, Dubai, UAE
Posters & Local Organization Marcin Detyniecki, LIP6, CNRS-Université P. et M. Curie, Paris, France
Secretary Adrien Revault d'Allonnes, LIP6, Université Pierre et Marie Curie, Paris, France
 IMPORTANT DATES 
 Paper Submission Due: Oc to b e r  31, 2010
 Notification to Authors: December 15, 2010
 Camera-Ready Papers Due: J a n u a r y  15, 2011
Please visit  www.ieee-ssci.org
or contact ssci2011@poleia.lip6.fr for
submission information and additional details
iv 
Environmental sound extraction and incremental learning approach for real time concepts  
identification ........................................................................................................................................................... 33 
Issam Feki (University of Sfax, Tunisia) 
Anis Ben ammar (University of Sfax, Tunisia) 
Adel M. Alimi (University of Sfax, Tunisia) 
 
Context-Based Image Re-ranking for Content-Based Image Retrieval ............................................................. 39 
Jiyi Li (Kyoto University, Japan) 
 
 
11:00 - 12:40 
 
S75: Video Image Processing and Indexing 
Chair: Thomas Miconi (CNRS, France) 
 
Block motion estimation based on search pattern and predictor ..................................................................... 47 
Hui-Yu Huang (National Formosa University, Yun-Lin, Taiwan) 
Shih-Hsu Chang (Dayeh University, Taiwan) 
 
Dynamic Vision Sensor Camera Based Bare Hand Gesture Recognition ........................................................ 52 
Eun Yeong Ahn (The Pennsylvania State University, USA) 
Jun Haeng Lee (Samsung Electronics, Korea) 
Tracy Mullen (The Pennsylvania State University, USA) 
John Yen (The Pennsylvania State University, USA) 
 
Multimodal Fuzzy Fusion System for Semantic Video Indexing ....................................................................... 60 
Mohamed Zarka (University of Sfax, Tunisia) 
Anis Ben Ammar (University of Sfax, Tunisia) 
Adel M. Alimi (University of Sfax, Tunisia) 
 
New Frame Rate Up-Conversion Based on Foreground/Background Segmentation ..................................... 67 
Mehmet Mutlu Cekic (Istanbul Technical University, Turkey) 
Ulug Bayazit (Istanbul Technical University, Turkey) 
 
Semantic Concepts Categorization Based on Pseudo-Sentences Representation ........................................ 71 
Nizar Elleuch (University of Sfax, Tunisia) 
Anis Ben Ammar (University of Sfax, Tunisia) 
Adel M. Alimi (University of Sfax, Tunisia) 
 
 
14:00 - 15:00 
 
S76: CIMSIVP - Keynote 
Chair: Khan Iftekharuddin (University of Memphis, USA) 
 
How to make a robot that feels 
Kevin O'Regan (Université Paris Descartes, France) 
 
 
vi 
Combination of closest space and closest structure to ameliorate non-local means method .................... 134 
Quoc Bao Do (University of Paris 13, France) 
Azeddine Beghdadi (Universite Paris 13, France) 
Marie Luong (Universite Paris 13, France) 
 
Color Image Cryptosystem using Chaotic Maps ............................................................................................... 142 
Sahar Mazloom (Qazvin Islamic Azad University, Iran) 
Amir-Masud Eftekhari-Moghadam (Qazvin Islamic Azad University, Iran) 
 
AUTHOR INDEX ............................................................................................................................................... 148 
A 9/7 wavelet-based lossless data hiding   
 
Hui-Yu Huang 
Department of Computer Science and Information Science 
National Formosa University 
Yunlin 632, Taiwan 
Email: anne.huang@ieee.org  
Shih-Hsu Chang 
Department of Computer Science and Information Science 
Dayeh University 
Dacun, Changhua 515, Taiwan 
Email: shchang@mail.dyu.edu.tw
 
 
Abstract—In this paper, a lossless data-hiding approach is 
presented based on quantized coefficients of discrete wavelet 
transform (DWT) in the frequency domain to embed secret 
message. Using the quantized coefficients for 9/7 wavelet filter in 
DWT, we embed secret data into the successive zero coefficients 
of the medium-high frequency components in each reconstructed 
block for 3-level 2-D DWT of a cover-image. The procedures of 
the proposed system include embedment, extraction, and 
restoration. Experimental results show that the proposed method 
can achieve high embedding capacity and acceptable image 
quality of stego-image, and data reversibility. 
Keywords-Discrete wavelet transform (DWT); 9/7 wavelet filter; 
lossless data hiding, stego-image. 
I.  INTRODUCTION 
Data hiding results in distortion of the original image. In 
other words, the original image is not lossless and reversible, 
resulting in a permanent distortion of the original image, the 
hidden data, or both. Although some embedding distortion is 
admissible, for example in military, legal, and medical images, 
permanent loss of signal fidelity is undesirable. Lossless data 
embedding, which is also called reversible data embedding, 
involves embedding invisible data into a digital image. The 
quality of the image used for embedding should be reasonably 
high. At the same time, it must be possible to restore the 
original image exactly after extracting the embedded message. 
This research focuses on lossless data embedding using a 
DWT to improve data-hiding capacity and retain good stego-
image quality. Many reversible data-hiding techniques have 
been reported in the literature. These techniques can be 
classified into two categories: algorithms performed in the 
spatial domain [1-3] and in the frequency domain [4-7].  
In the spatial domain, the secret message is inserted directly 
into the pixels. The most common methods are histogram-
based and least-significant bit (LSB) techniques in the spatial 
domain. Tian [5] presented a high-capacity, low-distortion 
reversible data-embedding algorithm using difference 
expansion (DE). The authors explored the potential of 
redundancies in the digital image to achieve high capacity and 
to keep distortion low. Ni et al. [2] proposed a histogram-based 
method for data hiding, which used the zero and peak points of 
an image histogram to embed a message and to recover the 
original image after extraction of the embedded data. This 
approach is quite simple and creates only slight distortion; the 
capacity for embedded data is approximately 5K for a 
512 512 8× × -bit image. 
In the frequency domain, the common well-known methods 
for data hiding are discrete cosine transformation (DCT)-based, 
discrete wavelet transformation (DWT)-based, or based on 
similar mechanisms. The cover image is first transformed using 
one of these transformations, and then the secret data are 
combined with the appropriate coefficients obtained by image 
transformation to achieve embedding. Fridrich et al. [4] 
proposed the so-called RS scheme, which is a lossless data-
embedding method that achieves high capacity by embedding 
bits of a message into status information on groups of pixels. 
Chang et al. [5] presented a steganographic method in the 
JPEG domain to embed a secret message into the medium-
frequency coefficients of a DCT-transformed cover image. 
Other than DCT domain schemes, several wavelet techniques 
that combine histogram- or LSB-based methods to achieve 
lossless data hiding have been reported [6–7]. 
In this paper, the aim of our proposed method is to embed 
secret data into the coefficients after quantizing and rearranged 
in the quantization factors using 9/7 wavelet filter method for a 
cover image, and to recover the original image. 
The reminder of the paper is organized as follows. In 
Section 2, we review the related technologies. Section 3 
described the proposed system. The experimental results 
present in Section 4. Finally, conclusions give in Section 5. 
II. RELATED TECHNOLOGIES 
A. 2-D wavelet transform 
Digital wavelet transform (DWT) represents an image as a 
sum of wavelet functions with different locations and scales 
[8]. Any decomposition of an image into wavelet involves a 
pair of waveforms: the high frequencies corresponding to the 
detailed parts of an image and the low frequencies 
corresponding to the smooth parts of an image. DWT for an 
image as a 2-D signal can be derived from a 1-D DWT. 
According to the characteristic of the DW decomposition, 
an image can be decomposed to four subband images through a 
1-level 2-D DWT. These four subband images can be mapped 
to four subband elements representing LL, HL, LH, and HH, 
respectively. 
B. 9/7 filter for DWT 
A 2-D DWT is mainly composed of the mutilate filters 
because invasive computation is involved in practical DWT 
applications such as image compression or edge detection. 
978-1-4244-9914-4/11/$26.00 ©2011 IEEE 1
 
(a) 
 
64
63 62 61 60 59 58
57
31
30
29
28
44434241
50
49
48
47
46
45
56
55
53
54
4
2
3 40
51
52
39
38
37 36 35 34 33
32
17 16 15
14
13
1211
10
987
65
27
26
25
24
2322212019
18
R1
R12
R11
R10
R9
R8
R7
R6
R5
R4
R3
R2
 
(b) 
 
Figure 2 (a) A tree decomposition of a 3-level 2D DWT. (b) A 
rearranged block. 
First, the value of ,2iz  is used to indicate the hidden secret 
bit in set iR  (1 12)i≤ ≤ .The embedding operations are 
described as follows: 
Case 1 : If 2ib <  and ,1iz  and ,2iz  do not exit, there are not 
secret bits can be hidden in a set iR .  
Although there are not secret bits can be hidden in a set iR  
according to Case 1 condition, some ambiguous conditions 
may happen and cause the receivers to extract a fault secret bit. 
The possible ambiguous conditions and their corresponding 
corrective strategies are depicted in the following. 
I. Ambiguous conditions and its corrective strategy 
If the coefficient sequences in set iR  are given the cases 
,( ,0, , )ii kx r"  or ,(0, ,0, , )ii kx r" , the values of ,1ir  and 
,2ir  are changed according to the responding Eqs. (2) and (3) 
respectively, expressed as follows: 
Case I ,( ,0, , )ii kx r" :  
 ,1 ,1',1
,1 ,1
1, where 0,
1, where 0.
i i
i
i i
r r
r
r r
+ >⎧
= ⎨
− <⎩
            (2) 
Case II ,(0, ,0, , )ii kx r" :  
,2 ,2'
,2
,2 ,2
1, where 0,
1, where 0.
i i
i
i i
r r
r
r r
+ >⎧
= ⎨
− <⎩
            (3) 
Case 2: If 2ib ≥ , the value of ,2iz  is modified to embed 
secret bit which is expressed as  
 ,2
0, when  is 0,
1 or 1, when  is 1,
i
i
i
s
z
s
⎧
= ⎨
−⎩
           (4) 
where 1 or -1 are randomly selected. 
According to the previously rules, the secret data can 
embed into the cover image. However, we need eliminate 
possibly any ambiguous conditions before hiding data. The 
ambiguous conditions and the modification strategy are 
described as follows. 
 
II. Ambiguous condition and its corrective strategy 
If the coefficient sequence of set iR  is represented as 
(0,0, , ,0)x"  and the coefficients of ,1 ,2 , 2( , , , )i i i jr r r −"  
are zeros, where 0,  4 ix j k≠ ≤ ≤ . According to our 
definition, ,2iz  is , 3i jr − . Suppose that secret bit is  is 1 and x 
is 1 or -1, it will cause that the receiver may make a false 
decision when the hidden data extracted from the set Ri. Figure 
3 illustrates an example of an ambiguous condition for j = 6 
and x = 1 or -1. To guarantee that the original coefficients can 
be restored, it is necessary to detect and modify the ambiguous 
conditions; the coefficient is changed using Eq. (5), before 
hiding the secret bit:  
, 1 , 1'
, 1
, 1 , 1
1, when 0,
 where 4 .
1, when 0,
i j i j
i j i
i j i j
r r
r j k
r r
− −
−
− −
+ >⎧
= ≤ ≤⎨
− <⎩
 
                                         (5) 
 
 
Figure 3 Example of an ambiguous situation. 
3
the different tables and the DWT-based method (L=12) with 
different quantization factors are shown in Table 3. 
 
Table 2 PSNR2 for stego-images when L=9 for using the standard and 
modified quantization tables in the DCT. 
 
Cover 
image 
Std. 
quantized 
(dB) 
9/7 for 
std. (dB) 
Modified 
quantized 
(dB) 
9/7 for 
mod. (dB)
Boats 27.49 28.74 29.75 31.41 
Jet 27.73 28.49 29.98 27.84 
Lena 28.13 29.68 30.34 33.08 
 
Table 3 The maximum hiding capacities compared with a DCT-based 
method (L=9) and our proposed method (L=12). 
 
 Cover 
image 
Std. 
quantized 
(L=9) 
(Bits) 
9/7 for 
std. 
(L=12) 
(Bits) 
Modified 
quantized 
(L=9) (Bits) 
9/7 for 
mod. 
(L=12) 
(Bits) 
Boats 36817 38948 36710 39151 
Jet 36852 39445 36817 39462 
Lena 36861 39706 36850 39869 
 
For Table 2, under the same hiding capacity when L=9, the 
PSNR2 for three stego-images compared the proposed method 
with Chang et al method, on average, the PSNR2 for our 
proposed method are higher than that of Chang et al. method in 
the standard quantization table used. The 9/7 filter using the 
modified quantization factor is still superior to the modified 
DCT-based method. For Table 3 about modified quantization 
table, averagely, this scheme still can embed 39494 bits for 9/7 
filter in the DWT method superior to 36792 bits for Chang et al. 
method. In contrast with employing the modified quantization 
table as shown in Table 3, averagely, this scheme can offer 
1.07 times for hiding capacity higher than Chang et al. method. 
Tables 4 and 5 present the hiding capacities and the 
corresponding PSNR2 of three stego-images for the 9/7 filter 
in the DWT method when the standard quantization table in 
the DCT is used, respectively. Although the PSNR2 are not 
very high, the image quality for stego-images shown in Fig. 5 
is still visually acceptable for the human vision system. Using 
the modified quantization factors in the DWT method, Tables 
6 and 7 present the hiding capacities and the corresponding 
PSNR2 for stego-images by means of 9/7 filter respectively. 
The correspoinding stego-images are shown in Fig. 6. 
V. CONCLUSIONS 
This paper has proposed a lossless data-hiding method 
based on 9/7 wavelet filter in DWT. Using the appropriate 
quantization factors for the DWT, this scheme can offer high 
hiding capacity and preserve the good quality of stego-images. 
The original image can be recovered losslessly when the secret 
data had been extracted from stego-images. Experimental 
results confirm that our proposed method can obtain high 
capacity and good the visual quality of stego-image. 
 
 
 
Figure 4 Test images. 
 
 
 
Figure 5 Three stego-images when L=12 for the quantization factors 
of the 9/7 filter in the DWT using the standard quantization table in 
the DCT, and the corresponding PSNR2.(a)Boats (28.74dB), (b)Jet 
(28.49 dB), and (c) Lena (29.68 dB). 
 
 
 
Figure 6 Three stego-images when L=12 for the quantization factors of 
the 9/7 filter in the DWT using the modified quantization table in the 
DCT, and the corresponding PSNR2.(a)Boats (31.41dB), (b)Jet (27.84 
dB), and  (c) Lena (30.08 dB). 
REFERENCES 
 
[1] J. Tian, “Reversible data embedding using a difference 
expansion,” IEEE Trans. on Circuits and Systems for Video 
Technology, vol. 13, no. 8, pp. 890-896, 2003.  
[2] Z. Ni, Y. Q. Shi, N. Ansari, and W. Su, “Reversible data 
hiding,” in Proc. of 2003 Int. Symposium on Circuits and 
Systems, vol. 2, pp.II-912-915, 2003. 
[3] T. D. Kieu and C. C. Chang, “A high stego-image quality 
steganographic scheme with reversibility and high payload 
using multiple embedding strategy,” Journal of Systems and 
Software, vol. 82, no. 10, pp. 1742-1752, 2009. 
[4] J. Fridrich, M. Goljan, and R. Du, “Lossless data embedding-
new paradigm in digital watermarking,” EURASIP Journal on 
Applied Signal Processing, vol. 2, pp. 185-196, 2002. 
[5] C. C. Chang, T. S. Chen, and L. Z. Chung, “A steganographic 
method based upon JPEG and quantization table modification,” 
Information Sciences, vol. 141, pp. 123-138, 2002. 
[6] G. Xuan, Y. Q. Shi, C. Yang, Y. Zhang, D. Zou, and P. Chai, 
“Lossless data hiding using integer wavelet transform and 
threshold embedding technique,” in Proc. of IEEE Int. Conf. on 
Multimedia and Expo, pp. 1520-1523, 2005. 
[7] Y. K. Chan, W. T. Chen, S. S. Yu, Y. A. Ho, C. S. Tsai, and Y. 
P. Chu, “A HDWT-based reversible data hiding method,” 
Journal of Systems and Software, vol. 82, pp. 411-421, 2009. 
5
Block motion estimation based on search pattern and 
predictor 
Hui-Yu Huang 
Department of Computer Science and Information Science 
National Formosa University 
Yunlin 632, Taiwan 
Email: anne.huang@ieee.org 
Shih-Hsu Chang 
Department of Computer Science and Information Science 
Dayeh University 
Dacun, Changhua 515, Taiwan 
Email: shchang@mail.dyu.edu.tw 
 
 
Abstract—In this paper, a fast motion estimation algorithm 
combined hybrid predictor and search pattern (called HPS) is 
proposed to find the best motion vector (MV). Block-based 
motion estimation (ME) and pattern searching strategy are used 
to detect the fast vector motion. The advantages of the approach 
can improve the performance of existing fast ME algorithm and 
can efficiently use to video compression. In addition, we also 
adopt the early termination strategy into this search method to 
speed up on searching motion vectors (MVs). The experimental 
results demonstrate that the proposed algorithm is faster than 
diamond search (DS) and hexagon-based search (HS), and the 
image quality, on average, is raised to 0.2dB superior to those of 
search method, and can effectively improve the reconstructed 
frame quality and be suitable for real-time applications. 
Keywords-Motion vector; motion estimation. 
I.  INTRODUCTION  
Block-matching ME is a cardinal and inextricable process 
for many motion compensated video coding standards [1, 2], 
such as H.261, H.263, H.264, MPEG-1/2/4, in which temporal 
redundancy between successive frames are efficiently 
removed. However, the ME could be very computation 
intensive and can consume up to 80% of computational power 
of the encoder if exhaustively evaluating all possible candidate 
blocks. The main aim of any of ME algorithm is to find 
temporal correlation.  
The purpose of block-matching ME is to find the best match 
for the partitioned blocks in an image inside a reference frame. 
Then the best match is used to predict the current block, 
whereas the displacement between the two blocks defines a 
motion vector (MV), which is associated with the current 
block. If we can estimate the set of MVs that map the previous 
frame to the current frame, then the encoder is only necessary 
to send the MVs.  
Many researches about estimating MV work have been 
reported. These search methods can be classified into two 
parts: block-matching search method [1, 3, 4] and predictive 
vector search method [5-8]. For block-matching search 
algorithm (MBSA), some of the well-known algorithms are 
three-step search (TSS) [9], new three-step search (NTSS) [10], 
efficient three-step search (E3SS) [11], four-step search (4SS) 
[12], hexagon-based search (HS) [13], cross search [14], 
diamond search (DS) [15], etc. Most of BMSAs make the 
assumption that the matching distortion criterion is decided by 
a monotonic property within a search window. The TSS 
algorithm performs MV used coarse-to-fine searching to 
reduce the number of search points. The DS, NTSS, and 4SS 
use the center-biased search patterns to adopt the center-biased 
global minima distribution. Although these methods can 
reduce the searching points, its resultant may be trapped in 
local minima. However, for video sequences with large 
motions, these methods usually result in significant loss in 
visual quality. Hence, they are appropriate to small motion 
video sequences.  
Many video compression standards, such MPEG-x and 
H.26x, recommended block-based motion compensation 
technique. The MPEG-4 part 7 adopted MV field adaptive fast 
search technique (MVFAST) [5], predictive MVFAST 
(PMVAST) [7] as a recommended ME algorithm. Most of 
important technologies in the compression field are motion 
estimation which can reduce the temporal redundancies 
between frames of video sequences. MVFAST also considered 
the MVs of spatially adjacent block in order to improve the DS 
algorithm, by selecting the best candidate and then achieved a 
modified DS pattern using this MV as the center. PMVAST [7] 
significantly improved on the concepts of zonal based 
technique, by introducing and combining MV predictor 
technique with adaptive threshold criteria. These methods are 
to reduce computational load and checking points, and to find 
a good set of initial points for a search process.  
In this paper, we propose an algorithm that combines 
predictor and search pattern for finding the MVs with a faster 
speed. This approach not only speeds up the search time for 
finding the MVs but has a high accuracy in estimating the 
MVs. This method takes advantage of the correlation between 
MVs in both spatial and temporal domains, predictor, search 
pattern, and early termination strategy to achieve the best MV 
estimation. 
The rest of the paper is organized as follows. In Section 2, 
we review the related technologies. Section 3 describes the 
proposed algorithm. Experimental results are given in Section 4. 
Finally, Section 5 concludes the paper. 
II. RELATED TECHNOLOGIES 
Generally, the most common ME algorithm is block-based 
method, in which each frame is first divided into subblocks 
(called macroblocks, MBs) of size N×N pixels and a search 
978-1-4244-9914-4/11/$26.00 ©2011 IEEE 47
B. PMVFAST algorithm 
A predictive motion vector field adaptive search technique 
(PMVFAST) [7] derived from MVFAST improves on the 
concepts of zonal-based technique by combining MV predictor 
technique with adaptive thresholding criteria. PMVFAST can 
essentially be seen as the direct improvements over MVFAST. 
The predictive motion vector (PMV) is used as the initial 
predictor. The search stops if the PMV satisfies the stopping 
criterion. PMVFAST computes the SAD of some highly 
probable MVs and stops if the minimum SAD satisfies the 
stopping criterion. That is also recommended in the MPEG-4 
standard.  Below summaries the PMVFAST search algorithm. 
z Step 1 Starting: Set thresholding parameter T. If the 
center position located at (0, 0) gives the minimum SAD 
that is less than T, the center point is the MV, and the 
search stops. 
z Step 2 Predictor selection: a set of predictors is 
examined, which includes the median predictor, the 
MVzero (0, 0), three spatial adjacent candidates (MVA, 
MVB, MVC). The median predictor for these MVs is 
defined as 
( )MV median MV , MV , MV , MVmedian A B C zero=        (5) 
For instance, if ( )MV 2,3 ,A = ( )MV 4, 2 ,B =  
( )MV 1,0 ,C =  and ( )MV 0,0 ,zero =  then 
( )MV 2,1median = . 
z Step 3: Calculate SADs for all 
predictors ( )MV , MV , MV , MV , MVA B C zero median , 
the minimum SAD is found from the five MVs as an 
initial predictor. If the current minimum distortion is 
small enough, the search stops and the current MV is 
selected as the best MV; otherwise, the best predictor is 
used as the center of a diamond pattern search. Then, the 
diamond pattern search is used. 
III. SELECTION OF THE PREDICTIVE VECTORS 
Our proposed method, which combines hybrid predictive 
vector and search pattern (called as HPS), is described in the 
following subsection. 
A. Selecting the predictive vectors 
First, we define the predictor set (G) that consists of the 
MVs in the region of support (ROS) from the previous frame 
( 1tI − ) and the current frame ( tI ), the zero MV ( MVzero ), and 
the median MV ( MVmedian ) for MVs of the current frame. The 
MVs in the ROS include the spatially adjacent MVs 
( )MV , MV , MVA B C  for the current frame ( tI ), as shown in 
Fig. 2. The MVmedian  is expressed as 
( )MV median MV ,MV ,MV .median A B C=                     (6) 
The best predictor can find in the set G as the current MV 
( MVcurrent ). If the best predictor that yields the minimum 
SAD is less than the early termination threshold (T), the current 
MV is the final solution of the MV; otherwise, we choose the 
other search methods depending on the L value to find the best 
MV. The L is expressed as  
( )max MV , MV , MV , MV .A B C DL =                             (7) 
 
 
Figure 2 Illustration of the predictive vectors. The MVs in the region 
of support consist of MVA, MVB, and MVc for the current frame (It). 
 
B. Dynamic cross search 
Based on the L value, we can decide the search method in the 
next step. If the L value is less than MV_TH1(=2), we employ 
the small cross search (SCS). The point yields the minimum 
SAD in the set G as the initial search point of the SCS, and all 
the checking points of SCS are tested. If the center position of 
SCS gives the minimum SAD, then the center represents the 
MV and the search stops. If L value is greater than or equal to 
MV_TH2(=7), we utilize the large cross search (LCS) from the 
center point at (0, 0) to four search points at ( ),  L L± ± . If 
the center position of LCS yields the minimum SAD, the 
center represents the MV and the search stops. 
 
C. Predictive pattern region search (PPRS) 
Based on the proposed HPS algorithm, if the search area (L) 
states in the range of [ ]_ 1,  _ 2MV TH MV TH , then we 
use the predictive pattern region search (PPRS) to estimate the 
MV, as shown in Fig. 2. The PPRS algorithm can be 
summarizes as follows. 
z Step 1 (Starting): Figure 3 depicts a basic predictive 
search-point configuration used in PPRS. It consists of 
nine candidate search points. A minimum SAD is found 
from the nine candidate search points of the predictive 
pattern located at the center (x, y) of search window. If 
the minimum SAD point is found to be at the center (x, y) 
of the PPRS, go to Step 3; otherwise go to Step 2.  
z Step 2 (Searching):If the minimum SAD point in the 
previous search step is located at one of eight search 
points as a new center, then go to Step 3; otherwise this 
step is repeated again.  
z Step 3 (Ending): With the minimum SAD point is the 
previous step as the center, a new PPRS pattern is 
49
where ijC and ijR  denote the gray-level value of the current 
frame and the previous frame, H and W are the height and 
width of a frame, respectively.  
To evaluate the computing efficiency in searching process 
for this approach, we also estimate the search time compared 
with some search methods for each frame. Table 1 shows the 
average PSNR values for the test sequences. For Table 1, the 
proposed method can raise the PSNR value that is superior to 
DS and HS methods. It is because the initial search point can 
be efficiently decide and the searching of the optimum motion 
vectors in search pattern can avoid presenting in the minimum 
region by means of this proposed method. Tables 2 and 3 
show the comparison results for the number of search blocks 
and the search times. It is clear that the number of search 
blocks can be reduced and the search time can be decreased 
compared with other methods. 
Table 1. Comparison of the PSNR value. (Unit: dB) 
Sequences DS HS HPS 
Akiyo 
Coastguard 
Foreman 
Hall-Monitor 
42.78 
30.25 
30.97 
34.66 
42.45 
30.21 
30.45 
34.60 
42.76 
30.28 
31.65 
34.63 
Average 34.67 34.43 34.83 
Table 2. Comparison of the number of search blocks. 
Sequences DS HS HPS 
Akiyo 
Coastguard 
Foreman 
Hall-Monitor 
13.74 
21.74 
27.93 
14.91 
11.69 
17.84 
20.25 
12.09 
4.04 
8.23 
7.62 
4.22 
Average 19.58 15.47 6.03 
Table 3. Comparison of the search time. (Unit: ms/frame) 
Sequences DS HS HPS 
Akiyo 
Coastguard 
Foreman 
Hall-Monitor 
28.59 
43.07 
53.13 
31.36 
24.53 
35.00 
38.70 
25.83 
11.61 
22.29 
21.46 
13.44 
Average 39.04 31.02 17.2 
 
V. CONCLUSIONS 
An efficient block-based motion estimation technology 
combined hybrid predictor and search pattern method (HPS) 
has been proposed. This method can reduce the search time for 
block matching and retain a good quality of the previous frame. 
Using the context relationships and the variance of the 
neighborhood blocks, MVs of the current frame can easily 
predict. In addition, using the search pattern, the best MV 
within those of MVs can be found to further estimate vector 
motion in the frame. Experimental results demonstrate that the 
proposed method can fast estimate MV based on the 
redundancy between frames. Compared with DS method and 
HS method, the resultants of our proposed method for the 
number of search blocks and frame quality are superior to 
those methods. 
 
REFERENCES 
[1] A. N. Netravali and J. D. Robbins, “Motion compensated 
television coding,” Part I, BeNSyst. Tech. J. vol. 58, pp. 631-670, 
1979. 
[2] Joint Video Team (JVT) of ISO/IEC MPEG & ITU-T VCEG, 
Draft ITU-T recommendation and final draft international 
standard of joint video specification (ITU-T Rec. H.264 ISO/IEC 
14496-10 AVC), ITU-T, Doc. #JVT-G050r1, 2003. 
[3] J. R. Jain and A. K. Jain, “Displacement measurement and its 
application in interframe image coding,” IEEE Trans. on Com., 
vol. 29, pp. 1799-1080, 1981.  
[4]V. A. Nguyen and Y. P. Tan, “Efficient block-matching motion 
estimation based on integral frame attributes,” IEEE Trans. on 
Circuits Syst. for Video Technol. no. 16, pp. 375-385, 2006. 
[5] P. J. Hosur and K. K. Ma, “Motion vector field adaptive fast 
motion estimation,” in Proc. of the 2nd Int. Conf on Info. Comm. 
Signal Processing, 1999. 
[6] MPEG-4 optimization model version 3.0, ISO/IEC 
JTC1/SC29/WG11, vol. N4344, 2001. 
[7] A. M. Tourapis, O. C. Au, and M. L. Liou, “Highly efficient 
predictive zonal algorithms for fast block-matching motion 
estimation,” IEEE Trans. on Circuits and Syst. for Video 
Technol., vol. 12, pp. 934-947, 2002. 
[8] H. Nisar and T. S. Choi, “Multiple initial point prediction based 
search pattern selection for fast motion estimation,” Pattern 
Recognition, vol. 42, pp. 475-486, 2009. 
[9] T. Koga, K. Iinuma, A. Hirano, Y. Iijima, and T. Ishiguro, 
“Motion compensated interframe coding for video conferencing,” 
in Proc. Nat Telecommunications Conf., pp. G5.3.1-G.5.3.5., 
1981. 
[10] R. Li, B. Zeng, and M. L. Liou, “A new three-step search 
algorithm for block motion estimation,” IEEE Trans. on Circuits 
and Syst. for Video Technol., vol. 4, pp.  438-443, 1994. 
[11] X. Jing and L. P Chau. “An efficient three-step search algorithm 
for block motion estimation,” IEEE Trans. on Multimedia, vol. 6, 
pp. 435-438, 2004. 
[12]L. M. Po and W. C. Ma, “A novel four-step search algorithm for 
fast block motion estimation,” IEEE Trans. on Circuits and Syst. 
Video Technol., vol. 6, pp. 313-317, 1996. 
[13] C. Zhu, X. Lin and L. P. Chau, “Hexagon-based search pattern 
for fast block motion estimation,” IEEE Trans. on Circuits and 
Syst. for Video Technol., vol. 12, pp.  349-355, 2002. 
[14]A. M. Tourapis, O. C. Au, and M. L. Liou, “Highly efficient 
predictive zonal algorithms for fast block-matching motion 
estimation,” IEEE Trans. on Circuits and Syst. for Video 
Technol., vol. 12, pp. 934-947, 2002. 
[15] J. Y. Tham, S. Ranganath, M. Ranganath, and A. A. Kassim, “A 
novel unrestricted center-biased diamond search algorithm for 
block motion estimation,” IEEE Trans. on Circuits and Syst. for 
Video Technol., vol. 8, pp. 369-377, 1998. 
[16] H. Lee, and J. Jeong, “Early termination scheme for binary block 
motion estimation,” IEEE Trans. on Consumer Electronics., vol. 
53, pp. 1682-1686, 2007. 
[17]W. Lin, K. Panusopone, D. Baylon, and M. T. Sun, “A new class-
based early termination method for fast motion estimation in 
video coding,” in Proc. of SPIE, vol. 7128, pp. 625-628, 2009. 
 
51
99 年度專題研究計畫研究成果彙整表 
計畫主持人：黃惠俞 計畫編號：99-2221-E-150-064- 
計畫名稱：偽裝人臉圖像之臉部表情重現及辨識之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
國外 論文著作 
研討會論文 3 3 100% 
篇 
1. H. Y. Huang 
and S. H. 
Hsu, ’An 
efficient 
landmark 
localization for 
face 
occlusion,’ in 
ICMLC2011 
Invited Session: 
Intelligent 
Systems: 
Methodologies 
and 
Applications
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
