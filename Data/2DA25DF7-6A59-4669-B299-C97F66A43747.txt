can effectively deal with quantum-wave 
dynamics input data and adjusts membership 
degree of microarray data with large 
dimensions. 
 
 
Keywords：clustering , basis vectors machine, 
principle component analysis, iterative 
quantum neural network, microarray 
 圖一 微陣列(cDNA)影像 
(1)研究動機與目的  
(2)主成份分析 當今全球的人類基因組計畫之目的，
即為完全解讀人類 23 對染色體中，總計約
30 億個核苷酸之排列順序。而生物的遺傳
物質 DNA(Deoxyribonucleic Acid)中包含
大量的基因序列，因此以 DNA 定序技術
解讀生物 DNA 中 T、A、C、G 四種核苷
酸的排列順序，即能獲得該生物的遺傳基
因之相關資訊；再輔以 DNA 微陣列科技
(DNA Microarray technology，如圖一)，使
近年生物研究人員擁有在短時間內觀察一
系列基因組 [9]並予以分析的能力。但由
於人類的基因排序如無序字母排列之文
章，至於如何逐步找出字、句乃至完全了
解其意義則需研發高效率的資料處理及分
析技術，其能自大量基因表現序列與微陣
列基因表現資料庫中，藉叢集分析等方法
萃取訊息以找出契合目標生物特性的基
因。故吾人在此使用新型叢集分析方法係
藉 主 成 份 分 析 (Principle Component 
Analysis, PCA)針對 sample-based微陣列做
簡化以降低多變量資料的維度，再由資料
轉換技術 (Basis Vectors Machine, BVM) 
有效地將有用之訊號與雜訊分開，後以一
迭代式量子神經網路 (Iterative Quantum 
Neural Network, IQNN)達到分群的目的。 
(Principle Component Analysis, 
PCA) 
經由微陣列取得之資料會因實驗機制
(如人為因素，實驗誤差等)而產生有異於
一般資料的極端值(Outlier)，又或是在資料
取得的過程中有雜訊產生而影響原來資訊
的表現；這些極端值及雜訊會影響後續統
計分析的精確性及增加計算複雜度。因
此，去除極端值及雜訊在資訊分析的前置
工作上實為一重要課題。 
主成份分析所著重的在於如何「轉換」
原始資料使之成為一些互相獨立的線性組
合變數，而且經由線性組合而得的主成分
仍保有原資料最多的資訊，其關鍵在「變
異數」取決問題，吾人可利用求特徵值
(Eigenvalues)及特徵向量 (Eigenvector)之
方法，過濾出佔有最大變異數的型態，在
本計畫中為簡化多變量資料的維度並以解
釋原有資料變異達 90% 以上為原則，以
避免喪失部分微陣列資訊的問題。吾人在
此採用Stanford MicroArray Database 上
之微陣列資料以進行實驗分析；在3000筆
微陣列資料，擷取每筆微陣列資料維度為
21的情況下，藉由主成分分析可得知第一
主成分與第二主成分即包含了90%以上之
資料變量，因此可藉由主成分分析將其多
變量微陣列資料簡化並以二維空間表示，
實驗結果如圖二。 

http://smd.stanford.edu/index.shtml, Serum stimulation Vascular 
Smooth Muscle cells, exp. ID: 45338, experiment: Coronary SM 
Serum St, 1 hr. 
 學習至近似於原始資料之對應位置，換句
話說，資料中第一主成份值小於-2×104 的
稀疏散佈之資料點並不足以達到成功地訓
練網路。由上述訓練的結果可知，經由
BVM 產生之函數會在原始資料點密集處
產生極大的斜率變化，亦即為成功學習；
藉此可將未被成功學習的資料點去除，其
稀疏散佈並且難以影響學習結果的特性即
為雜訊點的表徵。 圖三 修整化感知器網路架構 
 明顯地，以一對一變數之網路訓練方
法仍有些的缺點，如圖四中 X 軸值為-2×
104 右側的不規律震盪表現即難以加以分
析，其與初始網路訓練時所隨機選取資料
點有密切關係，再加上微陣列資料大量的
筆數容易造成X軸及Y軸形成一對多的函
數；有鑑於此，吾人擬在後續的計畫中延
續開發二對二變數之網路架構予以訓練，
並期能成功改善並分析上述情況。 
 
其中V 表示r ( )sDr1−σ ，T 表示 ，網路架
構圖如圖三。 
ts MM ⋅−1
圖四為 BVM 以函數逼進(Function 
approximation)學習之結果，其函數表示從
X 軸值為-2×104 之後即有一急速上升之陡
坡，相對於圖二中 X 軸值為-2×104 右側的
資料點數相當密集，故可將訓練後之函數 
 
 
 
(4)迭代式量子神經網路  
(Iterative Quantum Neural 
Network, IQNN) 
經由 PCA 及 BVM 擷取出欲分析之微
陣列資料後，吾人藉由量子領域之基礎研
究[4][5][6]，進而利用相似度加權及量子重
疊態之特性以解決複雜之分群問題； 
IQNN 之原理來自於全像術[7]，其利用同
調 光 的 干 涉 (interfere) 以 記 錄 底 片
(Recording film)紀錄自物體反射之光波振
幅(amplitude)和相位(phase)，如圖五。經
過干涉之後，記錄底片上各點依曝光量相
異而有不同之穿透率，其再經顯影步驟後
便是所謂的全像片。但僅有全像片並無法
見 到 紀 錄 的 影 像 ， 因 此 要 有 重 建
(Reconstruct)的過程。 
(a) 
 
(b) 
圖四 藉由 BVM 學習主成分微陣列資料
的分佈；(a)、(b)為對同樣資料分別兩次訓
練之結果 
(5)結果與討論 來的輸出，而當像素資訊差異越大，此權
重會將相似度低的微陣列資料給予極小的
加權值。 
本計畫已成功研發出一個新的分群技
術—結合PCA與BVM完成濾除雜訊，後以
IQNN達到快速分群，其具有下列優點：(1) 
PCA過濾出佔有最大變異數的型態，簡化
多變量微陣列資料的維度得以後續步驟可
快速分析微陣列資料之結構；(2)類神經網
路的大量平行處理能力、適應性、學習功
能使BVM與IQNN得以快速消除雜訊並執
行分群，實驗證實BVM能消除人為造成誤
差及雜訊，IQNN能快速有效地進行資料間
歸屬度之調整，藉以降低隨機選取之群中
心對最終分群數目的影響。 
因此，對於 PCA 及 BVM 簡化後之微
陣列資料(2892 筆, 21 維度)，吾人設計隨
機挑選其中 2 筆微陣列資料作為初始群中
心，並於分群結果中藉由加權後的 值判
斷各個微陣列資料所屬群。由於每筆微陣
列資料對於隨機給予之初始群中心都有各
自加權後之歸屬度(即為 )，故分群判定
方式為：取出每個資料點對於初始群中心
之歸屬度最大之值，若其值大於 0.8(預設
判別值)則將此資料點分屬於該群；且第一
次迭代後，若仍有未分群的微陣列資料，
則在其未分群之微陣列資料中再度隨機選
取兩筆資料作為群中心，重複上述的訓練
步驟，直到未分群的微陣列資料都有歸屬
的分群。圖七中顯示此此實驗中之微陣列
資料可分為 15 群，且其微陣列資料標示點
為方便表示故比例稍大，並非該群包含大
量且重複之微陣列筆數。吾人並由實驗過
程中發現隨機選取群中心的方式對於最終
群數的影響甚小，即是以權重調整即可找
出較佳歸屬度之分群，而以上利用權重與
相似度間之相互關係以改良[1]並做迭代
分群的過程，即為吾人於本計畫中提出之
IQNN。 
c
k
jγ
然而，BVM與IQNN仍有各自需再研
發改進的部分，譬如依據BVM基礎架構開
發二對二變數之網路架構以對微陣列資料
點分佈做更近似之學習，並使微陣列資料
更為精簡；IQNN則需使可調變之權重具備
依微陣列資料與參數不同而自動調整的功
能，以及對於判別值與整體分群效果之相
互關係做進一步探討。期能在後續研究計
畫中得以順利開發並實現於FPGA硬體實
作。 
 
(6)參考文獻 
[1] C. K. Loo, M. Perus, H. Bischof, 
“Computer Simulations of Quantum 
Image Recognition,” CVWW'04, pp. 
215-224, Piran, Slovenia, Feb. 4-6, 
2004. 
0 500 1000 1500 2000 2500 3000
0
5
10
15
Jt
h 
cl
us
te
r
Ith microarray data  
[2] Jie-Yu Zhao, “Implementing 
Associative Memory with Quantum 
Neural Network,” Proc of 3rd 
International Conference on Machine 
Learning and Cybernetics, Shanghai, 
26-29, 2004. 
[3] M. R. G. Meireles, P. E. M. Almeida, 
and M. G. Simoes, “A comprehensive 
review for industrial applicability of 
artificial neural networks,” IEEE Trans. 
圖七 每筆微陣列資料與所屬群數之對應
關係 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 95-2221-E-019-029 
計畫名稱 應用量子神經網路於微陣列資料分析 
出國人員姓名 
服務機關及職稱 
王榮華/海洋大學電機系/專任教授 
會議時間地點 Tokyo Institute of Technology, September 20-24, 2006 
會議名稱 
（中文）2006第三屆軟性計算暨第七屆智能系統國際研討會 
（英文）2006 3rd International Conference on Soft Computing and Intelligent 
Systems and 7th International Symposium on advanced Intelligent Systems 
發表論文題目 
1.（中文）刻度收縮轉換及其應用 
（英文）Scale Shrinking Transformation and Applications 
2.（中文）融合神經網路應用於影像分割 
（英文）Image Segmentation Via Fusion Neural Network 
 
一、參加會議經過 
本次會議為 3rd International conference of Soft Computing and Intelligent System，其主辦單
位為日本東京工業大學，於其校園內舉辦會議，於九月二十日至九月二十四日，期間亦有 7th 
International Symposium on advanced Intelligent Systems授課與討論，包含有十餘個議程主題及
約百餘個子主題於四天會議中分開討論。會議進行中，同時間進行的議程多達十數個，分別
在不同演講廳與會議室進行，與會者可依其專長及感興趣的題目自由參與會議。 
日本的東京工業大學(Tokyo Tech)成立於1881年，由Ookayama、Suzukakedai 和Tamachi
校園組成，是世界上最優秀的理工大學之一。且於2006十月七日由Times Higher Education 
Supplement (THES)之統計排名，位列世界優秀的理工大學第 18名  (資料來源：
http://newshub.nus.edu.sg/headlines/0610/ranking_07oct06.htm) 
該校擁有機械和宇航工程學院的太空系統實驗室（LSS）基於大規模的靈活多體動力學
和控制，致力於新型太空機器人系統的研究和開發。他們進行了可重構太空系統的研究工作，
如即將在國際空間站日本實驗艙實驗的可重構機器人手臂系統、機器人衛星群系統和宇航員
的智能助手設備。此外，東京工學院也積極參加了小型衛星系統的國際大學合作開發。 
東 京 工 業 大 學 從 1995 年 起 迄 今 每 年 皆 舉 辦 Supercomputing Programming Contest 
(http://www.gsic.titech.ac.jp/supercon/)，予高中生參加，對於莘莘學子之栽培不遺餘力，且校
Yasue Mitsukura, Minoru Fukumi 
13:40 100332 
Personal authentication using fingerprints 
Keiji Fukuda, Stephen Karungaru, Norio Akamastu, Minoru 
Fukumi 
14:00 100370 
A graininess suppression method for color Image restoration 
Seiki Yoshimori, Yasue Mitsukura, Minoru Fukumi, Norio 
Akamatsu 
14:20 100355 
A cognitive computational model to demonstrate the 
importance of eye-movements in edge detection 
Andras Roka, Adam Csapo, Barna Resko, Peter Baranyi, 
Hideki Hashimoto 
此議題與會人士約有十數人，報告結束後台下先進學者踴躍的提問與討論，點出此篇論文可
改進之缺點使其更臻於完善。個人報告結束後，也參與了數場其他作者的報告，吸收生物資
訊以及與 microarray data相關領域當中，一些較新穎的想法與概念。 
 
二、與會心得 
此次會議雖以模糊理論與智能計算為主題，但十數個不同議程亦讓與會者能多方採擷不
同的新知與創見。國際研討會實為現代學術界一項重要的交流管道，經由面對面的演講及交
談來交換學術意見，並溝通對於直接閱讀文章時產生的疑惑，提出之見解及辯答不僅讓發問
者釐清疑惑，亦讓作者於想法上有更大的突破。自準備報告的過程到與提問者的交流，全然
不同的環境卻提供了一個明確的舞台，可以英文表達論文裡的核心思想，更進一步與學界前
輩交談。與會中，無論是參與別人論文發表，或是本身論文發表，都可吸收不同國界對事情
不同角度看法，雖然很多研究方法部分曾經操作過，但在此可以觀察到不同切入點，而有不
同結果，雖然研討會結束，由於資訊無國界特性，仍然能繼續互相研討。  
出席此次國際會議收穫良多，不僅可以與各國相關領域的學者討論並交換研究結果與心
得，也於國際場合發表了自己的研究成果並接受與會者的指教與建議，將研究過程與成果介
紹給與會的學者專家瞭解，可算是用來驗收自己研究結果的最好機會。在我們的研究過程中，
常會遇到許多的瓶頸與困難，而答案並不是那麼的容易尋得。如果能多參與這種針對專業主
題所舉辦的研討會，答案常常在無意中自然得到，並且能對整個世界新的研究趨勢有一程度
的了解，有助我們掌握新的研究方向，以契合國際學界潮流。 
校方近年來積極鼓勵師生參與國際會議或是進行短期學術交流，無非是希望學生能更加
積極主動參與國際活動與國際接軌。參加此次國際性的研討會，不但在學術上能與各國學者
交換彼此的想法意見，也可學習新的研究方法及知識。 
此次會議結束回國後，更因與會時表現優異，榮獲 Journal of Advanced Computational 
Intelligence and Intelligent Informatics 邀稿，將融合神經網路應用於影像分割 (Image 
Segmentation Via Fusion Neural Network)此篇論文撰寫為期刊論文，將原有之技術擴充為可處
Scale Shrinking Transformation and Applications  
 
Yu-Chen Chen, Keng-Hsuan Wu, Jyun-Ting Lai, and Jung-Hua Wang1
Department of Electrical Engineering, National Taiwan Ocean University 
2 Peining Rd. Keelung, Taiwan 
email: jhwang@mail.ntou.edu.tw 
 
Abstract—this paper presents a novel information processing 
technique called scale shrinking transformation (SST). SST 
comprises three steps: initialization, matrix transformation, and 
using the column vectors of the transformed matrix as the new 
input vectors. The essence of SST is that the structural 
correlation between original inputs can be obtained. More 
significantly, the transformed matrix contains elements with 
much smaller scale variation. When applied to existing 
feedforward neural networks, it can alleviate problems 
commonly encountered in tasks of function approximation, 
separating nonlinearly classes, and noise filtering. When the 
column vectors are used as the new input to a feedforward 
network that comprises hidden layers, training speed can be 
reduced. The input scale divergence problem that plagues 
higher-order neural networks can also be alleviated with SST. 
 
Keyword: Shrinking Transformation, Feedforward Neural Networks, 
Scale Divergence, Function Approximation. 
 
I. INTRODUCTION 
 
Feedforward neural networks such as single-layer 
perceptron networks (SLP) [1], multi-layer perceptron 
networks (MLP) [2], radial-basis function networks (RBFN) 
[3], higher-order neural networks (HONN) [4], and support 
vector machines (SVM) [5][6], have been studied for decades. 
One thing shared by RBFN, HONN, and SVM is that they all 
involve the use of a nonlinear transformation to cast the 
original input vectors into a higher-dimension space. 
Analogous to SLP that has a single layer of trainable weighs, 
RBFN can be trained with the simple error-correction 
algorithm [7]. However, in some training algorithms [8] that 
aim to optimize classification accuracy, the number of hidden 
neurons must be increased in proportion to the number of 
training data, not to mention the need to pre-specify centers 
for each basis function prior to training [7]. Latest 
development in classification research has focused more on 
SVM than on RBFN, because SVM generally can deliver 
better classification accuracy than the other existing 
classification algorithms. SVM is also characterized by the 
choice of kernel functions, and it can be extended to allow for 
nonlinear problems by projecting the original inputs in a 
higher dimensional feature space and by formulating the 
linear separable problems in the feature space. Nevertheless, 
SVM suffers two serious drawbacks. That is, the time taken to 
carry out model selection for SVM could be unacceptably 
long, with complexity of O(m3) where m denotes the number 
of training data. And the key parameters of kernel functions 
are quite sensitive for some contemporary applications. 
Unlike aforementioned RBFN and SVM, in HONN the 
tedious parameter-selection for kernel functions is not 
necessary. This is supported by a large body of theoretical 
work demonstrating enhanced performance in networks 
involving higher-order or multi-neuron interaction. The 
computational power in HONN is gained from product or 
higher-order interactions between neurons. Nevertheless, they 
suffer the proliferation problem, namely the product terms can 
be any possible combinations of the raw input, adding input 
dimension or network order will rapidly increase the total 
number of product terms. Worse, this input combinatorial 
explosion will in turn increase the number of connection 
weights, and the values of some combinatorial higher-order 
terms may be nearly zeros while the rest excessively large. 
The greater network order is more likely to incur greater scale 
difference among inputs, making the training more difficult. 
This problem is commonly referred to as the input scale 
divergence. 
In light of forgoing observations, this paper presents a 
novel technique called scale shrinking transformation (SST). 
Through various application demonstrations, we show that 
SST can avoid problems of training difficulty and annoying 
parameters selection. When applied to a three-layer perceptron 
feedforward network, SST can greatly improve training 
efficiency. A filter based on SST is also proposed by 
representating input vectors by the linear combination of basis 
vectors. Analogous to two dimensional Weighted 
Savitzky-Golay filter (2D-WSGF) [9], the filter also takes 
advantage of polynomial curve fitting in noise reduction. 
Instead of sampling all the image data from sub image, it only 
requires relatively few pixels for approximating the image 
function. Since the approximation needs not involve large 
amount of image pixels, the computation load can be reduced. 
The rest of this paper is organized as follows. 
Implementation of SST will be elaborated in Section Ⅱ. In 
Section Ⅲ , we apply SST to an exemplar three-layer 
perceptron network and a noise filter to demonstrate the 
applicability of SST. Results will be shown in Section Ⅳ to 
verify the effectiveness of SST in performing tasks of function 
approximation, classification, and noise reduction. 
Comparison results with Pi-Sigma Network (PSN) [16] are 
also provided. Finally, conclusions are given in Section Ⅴ. 
 
Ⅱ. SCALE SHRINKING TRANSFORMATION 
 
For easy undersatnding, we first present the First order SST 
that has (d+1)-dimension and network order K=1. Then we 
will describe SST that can deal with general cases of 
transforming the raw input vector into nbs-dimension, where 
nbs>(d+1). 
 
1The correspondent author 
TH-C5-1 SCIS&ISIS2006 @ Tokyo, Japan (September 20-24, 2006)
- 698 -
B. Generalizing SST 
One can increase nbs if necessary. The initialization scheme 
is different from the first order SST in that the raw input 
vectors will be transformed into higher-order forms. That is,  
d1iL1j
xxxxxxxxxz TKjd
2
2j2j1j
2
1jjd2j1j0jj
...,...
,])(,...,)(,,)(,, ...,,, [
==
⋅=r       (9) 
Here, our primary concern is not the number of higher-order 
terms nh. As nbs is keenly related to nh, the rule of deciding nbs 
and nh is as follows: 
(1) First, nbs is specified (by user, say nbs=9 when d=2). 
(2) Find from Table 1 the number nh that is as near to nbs 
as possible (e.g. 6 or 10, if nbs=9) or estimating by 
Eq.(10), locate the value K accordingly (e.g. K=2 if 
nh=6, K=3 if nh=10), then set up Zt and Z. 
(3) Because nbs must be equal to nh, one has to delete some 
vectors from Zt if nbs is larger than nh (e.g. delete 3 
vectors if nh=6), and adding some vectors into Zt if 
otherwise (e.g. add 1 vector if nh=10).  
                       (10) ⎟⎟⎠
⎞
⎜⎜⎝
⎛ +=⎟⎟⎠
⎞
⎜⎜⎝
⎛ −+=∑
= K
dK
i
1id
n
K
0i
h
 
Table 1 Number of higher-order terms nh  
d 
K 
 
1 
 
2 
 
3 
 
4 5
 
6 
 
7 8
1 2 3 4 5 6 7 8 9
2 3 6 10 15 21 28 36 45
3 4 10 20 35 56 84 120 165
4 5 15 35 70 126 210 330 495
5 6 21 56 126 252 462 792 1287
6 7 28 84 210 462 924 1716 3003
7 8 36 120 330 792 1716 6462 6435
8 9 45 165 495 1287 3003 6435 12870
 
For explanation simplicity, we use 1-d input and assume L=4, 
nbs=3, i.e., K=2. Therefore,  
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
2
31
2
21
2
11
312111
2
31
2
21
2
1t
2
11
31211t11t
xxx
xxx
111
Z   ,
xxxx
xxxx
1111
Z  
As before, define  
31
3
21
2)(
a
a
a
aa ttt ⋅≡ϕ                                (11) 
Thus, T = can be written as  t
1 ZZ ⋅−
],,,[
)()()()(
)()()()(
)()()()(
4321
33423332131
32422322121
31421312111
tttt
zzzz
zzzz
zzzz
T
t
t
t rrrr
rrrr
rrrr
rrrr
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
ϕϕϕϕ
ϕϕϕϕ
ϕϕϕϕ
  (12) 
Select nh basis vectors from Zt, and conduct the matrix 
transformation,  
[ ] ]...,,[)()()( 21211 LLt tttzzzZZT rrrrLrr ==⋅= − ϕϕϕ   (13) 
∏
∏
≠
=
≠
=
−
−
= ik
nk
ik
ik
nk
jk
ij
h
h
xx
xx
~1
11
~1
11
)(
)(
ϕ                            (14) 
∑ ∑
= =
===
h hn
1i
n
1i
jijijijj L...1j for ,1)z(  ,z)z(t
rrrr ωϕ       (15) 
Note that the above derivations are merely used to illustrate 
the theoretical correctness and to shed some light in 
understanding the feasibility of SST in applications to be 
presented in the following sections. 
 
Ⅲ. APPLICATIONS OF SST  
A. Applying SST to Neural Networks 
Fig. 2 shows a feedforward perceptron network that 
comprises three layers, where HNi denotes the ith hidden 
neuron, and nHN the total number of hidden neurons. 
Determining an appropriate hidden-layer size for a three-layer 
perceptron (TLP) network has been widely studied [12][13], as 
redundant hidden neurons often lead to overfitting and making 
the network more computationally demanding. On the other 
hand, a too small hidden-layer size is unable to rightfully 
model the input distributions. Therefore, it is desirable to 
reduce the number of hidden neurons while without sacrificing 
the level of performance. We can achieve this goal by applying 
SST to TLP, the result is called PPN (Pruned Perceptron 
Network). Fig.3 shows the architecture for which the input is 
transformed by applying SST. Here, our goal is not to pursue 
the optimal number of hidden neurons, there are already some 
well-done reports in this regard. [12][13]. Note that because 
the difference between the original TLP and PPN is the sizes 
of input-layer and hidden-layer, it is easy to see that the 
Back-Propagation algorithm [7] commonly employed in the 
former network can be applied to the latter too. Due to the 
space transformation, the number of hidden neurons in the 
network can be reduced while delivering the same level of 
performance. Results are shown in the next section. 
 
Fig. 2  Architecture of a three-layer perceptron network. 
- 700 -
Ⅳ. SIMULATION RESULTS 
A. Classification for Multivariate Data   
The input test data used the three 2-D Gaussian data sets, CR, 
CG, and CB. The means of CB R, CG, and CBB are = [80,80] 
= [50,200] and = [180,180], respectively. The SST 
degree K = 3, and 10 data points were sampled randomly from 
the pool of training patterns. Table 2 shows the performance 
difference made due to the space transformation by SST. 
Applying SST to the raw input indeed can achieve faster 
training, despite the fact that the transformed input-layer size is 
the same as the original TLP. Table 2 also shows results of 
testing Pi-Sigma Network (PSN) [16]. Clearly, PSN has a 
training problem, that is, convergence to a minimum cannot be 
guaranteed if all the weights are update synchronously in an 
epoch. That is why PSN consumed more training computation 
time. 
Ru
r
Gu
r
Bu
r
We also tested higher-dimensional d Gaussian sets for 
verifying the effectiveness of SST (i.e. the same input-layer 
size). And the means for every input dimension in the three 
classes are =[80] =[200] and =[180], where 
i=1…d. To see how increasing d affects SST performance, we 
add some hidden neurons while increasing the dimension of 
Gaussian data sets.  Fig. 4 shows that the number of training 
epochs in PPN (dashed line) is still less than the original TLP 
(solid line), verifying the feasibility of applying SST to 
improve training efficiency. 
Riu
r
Giu
r
Biu
r
 
B. Function approximation 
The Gabor function was approximated. Formula of the 
well-known function is given by  
 
Table 2 Comparison of Training Performance 
 
Network MSE Epochs Time (sec.) 
TLP(nHN =5) 0.05 112 0.2824 
PPN(K=3, nHN =5) 0.05 71 0.2290 
PSN(K=3, nHN =5) 0.05 238 0.6840 
 
 
 
Fig. 4  Comparison of TLP and PPN when varying d. 
 
)(22
)/(
2
002
22
2
1),( yvxuj
yx
eeyxh +
+− ⋅⋅= πσ
λ
πλσ  
The parameters are set as λ =1, σ=5, (u0, v0) = (1, 1). To 
generate training patterns and test patterns, 256 points were 
picked from 16×16 grid on -0.5≦x≦0.5 and -0.5≦y≦0.5. 
We selected 128 points out of 256 points as training pattern, 
and the rest as test patterns. The output activation function 
used the hyperbolic tangent function.  
To see the effect of SST, particularly the performance 
difference it can make, we tested PPN and TLP using various 
numbers of hidden neurons. Table 3 reveals that the number of 
training epochs may decrease with the increasing hidden 
neurons. But increasing number of hidden neurons will 
inevitably incur more computation time. The first row in Table 
3 says that a TLP with 5 hidden neurons is incapable of 
approximating the Gabor function at hand. Generally speaking, 
benefits brought by applying SST to TLP are twofold: (1) 
requiring less number of hidden neurons (can use only 5 
hidden neurons) (2) better approximation accuracy (Minimum 
Squared Error, MSE=0.005). Finally, the last row of Table 3 
indicates that one can instead utilize first-order SST (i.e. with 
K=1 and the same input-layer size) in order to accelerate the 
training procedure. 
 
Table 3  Performance Comparisons 
Network tested 
MSE 
training 
MSE 
testing 
Epochs
Time  
in sec 
(1) TLP(nHN=5) NA NA NA NA 
(2) TLP(nHN =10) 0.005 0.0069 1299 7.04 
(3) TLP(nHN =20) 0.005 0.0064 615 7.32 
(4) PPN(K=2, nHN =5) 0.005 0.0065 133   0.42 
(5) PPN(K=1, nHN =10) 0.005 0.0070 936 5.64 
 
 
C. Speckle Noise Reduction 
It is widely known that speckle noise is multiplicative, and 
it can be defined as 
uniformspeckleuniformspeckle or nppnnpn ⋅+=⋅=    (22) 
where nspeckle, nuniform, and p are intensity quantity for   
speckle noise, uniform noise with mean = 0, and pixels on the 
synthetic image, respectively. By Eq.(22), when p = 0, the 
pixel is noiseless; when p = 255, the gray level of the noisy 
pixel could be originally greater than 255. Hence, prior to 
adding speckle noise into the test image, we purposely set the 
gray level between 0 and 204 to prevent the gray level from 
overflowing. In terms of image quality and the computational 
efficiency, we compare the proposed FAF, and the 2D-WSGF 
in removing speckle noises. In order to see their performance 
differences, we used the 256×256 synthetic image as the test 
- 702 -
Image Segmentation via Fusion Neural Networks 
  
Sih-Yin Shen, Ya-Yun Jheng, Chun-Shun Tseng, and Jung-Hua Wang 
Electrical Engineering Department, National Taiwan Ocean University 
2 Peining Rd. Keelung, Taiwan 
emall:jhwang@mail.ntou.edu.tw 
 
Abstract-This paper presents a self-organizing fusion 
neural network (SOFNN) which is effective in performing 
fast image segmentation. Based on a counteracting 
learning strategy, SOFNN employs two parameters that 
together control the learning rate in a counteracting 
manner to achieve free of over-segmentation and 
under-segmentation. Regions comprising an object are 
identified and merged in a self-organizing way, and the 
training process will be terminated without manual 
intervention. Because most training parameters are 
data-dependent, implementation of SOFNN is simple. 
Unlike existing methods that sequentially merge regions, 
all regions in SOFNN can be processed in parallel fashion, 
thus providing great potentiality for a fully parallel 
hardware implementation. In addition, not only the 
immediate neighbors are used to calculate merging 
criterion, but the neighboring regions surrounding the 
immediate regions are also referred. Such extension in 
adjacency helps achieve more accurate segmentation 
results. 
 
Keyword: Neural networks, image segmentation, extended 
adjacency, counteracting learning, watershed Analysis. 
 
Ⅰ.INTRODUCTION 
 
Image segmentation plays a preliminary yet essential role in 
most image analysis tasks. Improper or inaccurate 
segmentation often make impossible the follow-up 
recognition or analysis tasks. The goal of segmentation is to 
identify objects of interest that satisfy certain pre-defined 
homogeneity criteria, whereas the primary objective of 
clustering [1] is to partition a given set of data or objects into 
clusters (subsets, groups, classes). This partition should have 
the following properties: 1) Homogeneity within the clusters, 
i.e., data that belongs to the same cluster should be as similar 
as possible and 2) Heterogeneity between clusters, i.e., data 
that belongs to different clusters should be as different as 
possible. This concept has been found useful [2, 3, 4] in 
realizing image segmentation wherein a raw image is taken as 
the input data, then clustering operates on the feature space to 
label sufficiently similar and adjacent pixels. After the 
clustering process, the labeled results are mapped onto the 
image plane to obtain the final segmented objects.  
On the other hand, in hybrid-based segmentation methods 
[5], a pre-process is initially invoked to dissect the input 
image into a set of small primitive regions referred to as initial 
image tessellation. One well known such pre-process is the 
morphological watershed transform [6, 7] which has drawn 
great attentions from researches for two main reasons: its 
easiness in implementation, and more importantly, it generates 
a completely closed contour. However, due to its nature of 
dividing input image according to its belief, there exists the so 
called over-segmentation problem, namely, too many small 
primitive regions.  
There has been a great deal of literature aiming to solve the 
over-segmentation problem, e.g. the fast nearest neighbor 
region merging graph (NNG) [8]. But they adopt sequential 
strategy [9, 10] in that the two most similar regions are 
searched globally for merging. This inevitably requires a 
time-consuming sorting procedure, not to mention that after a 
region pair is merged the graph structure needs to be updated. 
Another shortcoming of sequential merging is the lack of 
spatial information needed for estimating the merging 
criterion, resulting in false contours and less accurate 
segmentation. Obviously, this undesired effect will be further 
deteriorated by the more number of initial primitive regions. 
To deal with the aforementioned problems and to further 
improve merging accuracy, we propose a novel approach 
called self-organizing fusion neural network (SOFNN) to 
achieve image segmentation. Unlike k-means algorithm [4], 
SOFNN does not need to pre-specify the final number of 
clusters. Initially each primitive region is taken as an 
individual neuron, and based on similarity and adjacency 
measures regions are clustered in feature space. Like other 
neural network models, SOFNN simultaneously updates 
weights of neurons, which greatly improves the computation 
efficiency over the sequential merging. Another essential 
feature of SOFNN is the association of each target neuron Ri 
with two statistical parameters αi and βi, each favors merging 
and splitting, respectively. During the training process, local 
statistics are collected to calculate αi and βi , which in turn are 
used to adjust the learning rate. With the counteracting effect 
between αi and βi the learning dynamics can be stabilized and 
both over-clustering (corresponding to over- segmentation) 
and under-clustering (under-segmentation) can be prevented.  
Furthermore, in order to further improve segmentation 
accuracy, we propose the extended adjacency strategy and use 
it to update the similarity measure for each Ri. The strategy 
emphasizes that not only the immediate regions of the target 
region but their neighboring regions are also accounted for. 
After updating, features of regions will be blended to each 
other, hence the name fusion. Regions satisfying a 
well-defined statistical criterion will be merged.  
 
 
 
FR-F3-1 SCIS&ISIS2006 @ Tokyo, Japan (September 20-24, 2006)
- 1135 -
41α =
12α =
33α =14α =
15α =
26α =
1maxE
2maxE
3maxE
4maxE
5maxE
6maxE
 
 
Fig.1 Similarity flow diagram. 
 
   Another parameter βi in Eq.(4) provides, however, just the 
opposite effect. The rationale of βi is explained as follows. 
Consider the case when R3 is distinctively different from its 
surrounding regions {R1, R2, R4}, namely E13, E23, E43 are 
rather small, in this case it is desired to inhibit the merge of R3 
to R1. Nonetheless, as described previously, α1 will be 
increased by 1 since Max(E13, E23, E43)= E13, no matter how 
small values of E13, E23, E43! Therefore, in order to counteract 
the effect caused by αi and prevent under-segmentation, 
another statistical parameter βi defined as the sum squared 
differences between Ri and its adjacent regions, i.e. Σ[w(Ri)- 
w(Rj)]2 is incorporated into Eq.(4). The larger βi is, the smaller 
the learning rate εi will be. The use of βi advantageously 
prevents regions with distinct dissimilarity from being merged, 
hence avoiding under-segmentation.  
  Using the input image “peppers”, Fig.2 shows values of 
/T
t
avα α  and / T
t
avβ β  which are defined as the average of 
/T
t
iα α  and / T
t
iβ β  over all regions in iteration t. We can see 
that / T
t
avβ β  is monotonically increased, in contrast, /T
t
avα α  
always decreases. The result clearly demonstrates that αi and 
βi together in Eq.(4) has the effect of avoiding 
over-segmentation and under-segmentation. 
 
0 2 4 6 8 10 12 14 16 18 20
0
1000
2000
0
0.005
0.01
0.015
T
t
av
α
α
t
av
T
β
β
t
av Tβ β
t
T avα α
Iteration t
  
 
Fig.2 /T
t
avα α  and / T
t
avβ β  in each iteration 
Inputs (image plane)
Parallel fusion 
  and merge
Outputs
  
(a) 
 
Input (feature space)
Parallel feature- update 
and clustering     
Clustering result
 
(b) 
 
Fig.3 Illustration of SOFNN (a) image space (b) feature space 
 
Illustrations of how SOFNN performs merging in image 
space and feature space are given in Fig.3 (a) and Fig.3 (b), 
respectively. We take each circle as an individual neuron, then 
update features and merge neurons in feature space using 
Eq.(3) and Eq.(7), which result in parallel fusion and merging 
regions in image plane, respectively. The arrows in Fig.3 (b) 
indicate the direction to which a neuron move from its 
original position (dotted circle) to a new position in feature 
space. The bold circle in Fig.3 (b) represents a merged neuron, 
corresponding to the two regions marked with the arrow in 
Fig.3 (a). The number of remaining neurons stands for the 
number of regions left when the merging process is 
terminated. 
 
C. The Merging Criterion 
 
To conduct merging, an important parameter is introduced 
as follow  
 
( ) ( )
( )
1 11
j i
t t
i j
R N R
R w R
n
ζ + +
∈
= ∑         (5) 
 
For an arbitrary region Ri, besides the intra-regional 
parameter wt(Ri) that measures the average intensity of pixels 
in Ri, the inter-regional parameter ζt(Ri) is useful in 
characterizing overall intensity of area surrounding Ri. Thus, 
the value of ∣ζt(Ri)-ζt(Rj)∣in a sense stands for the 
dissimilarity (in feature space) between two areas centered at 
Ri and Rj, respectively. And the mean difference between and 
those of regions adjacent to Ri is written as  
 
- 1137 -
0 2 4 6 8 10 12 14 16 18 20
0
500
1000
1500
2000
Iteration t
N
um
be
r 
of
 re
gi
on
s
 
 
Fig.5 Merging rate in input image “peppers” 
 
0 20 40 60 80 100 120 140 160 180 200
0.015
0.02
0.025
0.03
0.035
0.04
Iteration t
avε
(a) 
 
0 5 10 15 20
0.015
0.02
0.025
0.03
0.035
0.04
avε
Iteration t
 
(b) 
 
Fig.6 (a) the average learning rate εav of each iteration (b) the 
zoom-in of Fig.7 (a) during the beginning 20 iterations 
 
IV. CHARACTERIZATION 
 
Results in Section III have shown that the proposed 
SOFNN indeed performs well. We conjecture its effectiveness 
roots in the extended adjacency which offers sufficient 
neighborhood information to the target region in measuring 
similarity degree. Each threshold is evaluated by taking into 
account the weight of immediate neighbor as well as their 
adjacent regions. It provides a more objective spatial measure 
for target region in judging whether to merge its adjacent 
regions. 
In conventional segmentation algorithms where the basic 
unit to be processed is one region or a pixel, most often the 
immediate neighbors are used for measuring 
similarity/homogeneity. In contrast, SOFNN explores the 
inter-regional information; and the merging process is actually 
conducted in unit of regional cluster, not region nor pixel. 
That is, the local threshold is obtained by examining not only 
the immediate neighbors of target region but the neighboring 
regions surrounding them. This attribute not only offers much 
more adjacency information to the target region, but provides 
more tolerance to input noise. Two types of noise are tested, 
namely, impulsive (salt-and-pepper) and Gaussian. Fig.7 (a) is 
the test input “house”. Fig.7 (b) and (c) is corrupted by 20% 
salt-and-pepper noise, and Gaussian noise (zero mean and 
variance=0.01), respectively. Fig.7 (d) is the tessellation of 
Fig.7 (c) (after filtering by a mean filter and watershed 
analysis).  
Using the input image corrupted by the salt-and-pepper 
noise (after applying a 3×3 median filter), Fig.7 (e) and (f) 
show the segmentation result via SOFNN and SRM [12], 
respectively. In the case of Gaussian noise, Fig.7 (g) and (h) 
shows the results via SOFNN and SRM, respectively. We can 
easily spot several false contours in Fig.7 (f) and (h). This 
result verifies that SOFNN indeed is robust to input noise.   
It is worthy noting that although proper extended adjacency 
information can provide an objective local threshold, 
excessive extension could incur a meaningless threshold such 
as a nearly globe threshold that certainly cannot work as a 
“local” threshold. This is analogous to an excessive mask size 
in a mean filter. 
 
 
 
    
(a)                       (b) 
 
    
(c)                      (d) 
 
- 1139 -
Self-Organizing Fusion Neural Networks
Paper: jc11-6-2962:2007/5/10
Self-Organizing Fusion Neural Networks
Jung-Hua Wang, Chun-Shun Tseng, Sih-Yin Shen, and Ya-Yun Jheng
Electrical Engineering Department, National Taiwan Ocean University
2 Peining Rd. Keelung, Taiwan
E-mail: jhwang@mail.ntou.edu.tw
[Received January 16, 2007; accepted March 20, 2007]
This paper presents a self-organizing fusion neural
network (SOFNN) effective in performing fast clus-
tering and segmentation. Based on a counteract-
ing learning scheme, SOFNN employs two parame-
ters that together control the training in a counteract-
ing manner to obviate problems of over-segmentation
and under-segmentation. In particular, a simultane-
ous region-based updating strategy is adopted to fa-
cilitate an interesting fusion effect useful for identify-
ing regions comprising an object in a self-organizing
way. To achieve reliable merging, a dynamic merg-
ing criterion based on both intra-regional and inter-
regional local statistics is used. Such extension in ad-
jacency not only helps achieve more accurate segmen-
tation results, but also improves input noise tolerance.
Through iterating the three phases of simultaneous
updating, self-organizing fusion, and extended merg-
ing, the training process converges without manual
intervention, thereby conveniently obviating the need
of pre-specifying the terminating number of objects.
Unlike existing methods that sequentially merge re-
gions, all regions in SOFNN can be processed in paral-
lel fashion, thus providing great potentiality for a fully
parallel hardware implementation.
Keywords: neural networks, image segmentation, clus-
tering, counteracting learning, watershed
1. Introduction
The goal of image segmentation is to identify objects
of interest that satisfy certain pre-defined homogeneity
criteria, whereas the primary objective of clustering [1]
is to partition a given set of data or objects into clusters
(subsets, groups, classes). This partition should have the
following properties: 1) Homogeneity within the clusters,
i.e., data that belongs to the same cluster should be as
similar as possible and 2) Heterogeneity between clusters,
i.e., data that belongs to different clusters should be as
different as possible. This concept has been found useful
[2–4] in realizing image segmentation wherein a raw im-
age is taken as the input data, then clustering operates on
the feature space to label sufficiently similar and adjacent
pixels. After the clustering process, the labeled results
are mapped onto the image plane to obtain the final seg-
mented objects.
On the other hand, in hybrid-based segmentation meth-
ods [5] or the so called split-and-merge techniques, a pre-
process is initially invoked to dissect the input image into
a set of small primitive regions referred to as initial image
tessellation. One well known such pre-process is the mor-
phological watershed transform [6, 7] which has drawn
great attentions from researches for two main reasons:
its easiness in implementation, and more importantly, it
generates a completely closed contour. However, due to
the keen sensitivity to local variance the technique suffers
a major drawback known as over-segmentation problem
[6], hence an effective merging process is needed in order
to achieve valid segmentation. To this end, Vincent et al.
[8] used an undirected RAG (Region Adjacency Graph)
[9] to sequentially merge small regions pre-generated by
watershed analysis. Two regions having the minimum
edge are searched globally and merged. Such sequential
operation is rather time-consuming. Haris et al. [10] pro-
posed the nearest neighbor graph (NNG) region merging
method. Unlike the work of Vincent et al. [8], not all
RAG is kept in the heap; instead only a small portion of
it is needed. But the improvement is still rather limited
as NNG also conducts merging in a sequential fashion.
Another shortcoming of sequential merging is the lack of
spatial information needed for estimating the merging cri-
terion, resulting in false contours and less accurate seg-
mentation. Obviously, this undesired effect is further de-
teriorated by the more number of initial primitive regions.
To overcome the aforementioned shortcomings en-
countered in conventional split-and-merge techniques,
and to further improve merging accuracy while resolv-
ing the time consuming problem, we propose a novel
approach called self-organizing fusion neural network
(SOFNN) to achieve image segmentation in a parallel
fashion. Unlike k-means algorithm [4], SOFNN does not
need to pre-specify the final number of objects. Each in-
dividual neuron is associated with a working feature to
characterize its gray or color features. Another key at-
tribute of SOFNN is the association of each target neu-
ron with two statistical parameters α i and β i which are
used to adjust the learning rate in a counteracting manner,
namely one favors region-merging while the other favors
region-splitting. After counteracting learning, the work-
ing features are simultaneously updated, and features of
Vol.11 No.6, 2007 Journal of Advanced Computational Intelligence 1
and Intelligent Informatics
Self-Organizing Fusion Neural Networks
where λ (t is a time-varying function defined as
λ  t  ninit
nt
. . . . . . . . . . . . . . (2)
where ninit denotes the number of initial regions generated
by watershed transform, nt is the number of regions at
iteration t. Note that because It Ri of all regions are time-
varying, the weight defined in Eq. (2) is also time-varying.
Although Eq. (1) quantitatively calculates the weight
between two adjacent regions, using it alone is not ade-
quate in practical implementations. The main difficulty
arises from the fact that regions subjectively perceived by
human eyes as belonging to an object might not possess
the similarity sufficient to be identified as the same object
through a thresholding scheme in ordinary computer al-
gorithms. In fact, a universal threshold for sufficient sim-
ilarity is very difficult, if not impossible, to be specified.
Thus, instead of using a pre-set global threshold [11], we
employ a statistical merging criterion based on a homoge-
neous measure using local statistics. Furthermore, prior
to merging, regions are subjected to a simultaneously up-
dating process each iteration and checked if some of them
have become homogeneous. The iterative update equation
for It Ri is given as
It1  Ri  It  Ri εti
 
It  Ri Itav  N  Ri

. . (3)
where Itav  N  Ri 
∑
R jN R j
It  R jwti j  R j
n

N Ri denotes the set of adjacent regions surrounding to
Ri in RAG, including Ri itself. N Ri is also referred
to as the immediate neighbors of Ri. We will elaborate
the learning rate ε i in the next section. The parame-
ter Itav N Ri represents the average working feature of
N Ri weighted by the connection weight.
The beauty of iteratively applying Eq. (3) is that it can
facilitate systematic identification of which adjacent re-
gions to be merged. To see this, we first note that after
applying watershed operation, the primitive small regions
that compose an object should be quite similar in a lo-
cal sense. The update by Eq. (3) tends to force the re-
gion and its adjacent regions to become more alike, col-
lectively appearing as a fusion phenomenon taking place
among the adjacent regions. Very soon the features of
adjacent regions become similar enough to be identified
as candidates for merging. However, after some begin-
ning iterations, updating should be made more gradual
by increasing λ (t in order to avoid regions with distinct
dissimilarity are erroneously merged into a bigger region
(i.e. under-segmentation). This purpose is easily served
by the design of Eq. (2), where nt normally decreases as
the number of primitive regions cannot be increased as
iterating continues.
Following the update, adjacent regions are compared to
a statistical merging criterion to check if they are qualified
as the comprising components of an object. If so, they will
be merged into a bigger region. Just like the weights of all
regions are simultaneously updated, the region merging in
SOFNN can be conducted in parallel fashion. In subsec-
Fig. 2. Similarity flow diagram.
tion 2.3, we will discuss the merging criterion in detail.
2.2. The Counteracting Learning
For the learning rate parameter ε i in Eq. (3), we define
two counteracting parameters. First, a statistical param-
eter α i is defined as the number of adjacent regions that
“see” Ri as their most similar region. The initial value
of αi  1 for i  1      nt , nt is the number of regions
at iteration t. The rationale of using α i is best explained
with the directed similarity flow diagram in Fig. 2. The
directed arrow, say, the one pointing from R3 to R1 repre-
sents that among the adjacent regions of R3, namely  R1,
R2, R4, R1 is seen by R3 as the most similar region, i.e.,
w3max  Max w13 w23 w43  w13. On the other hand,
besides R1 itself there are three regions  R3,R5,R6 that
see R1 as their most similar region, thus α1  1 3  4.
The learning rate εi of region Ri is prescribed as
εt1i  εinit  exp


 β ti
βT 
αT
αti

. . . . (4)
αT 
nt
∑
i1
αti and βT 
nt
∑
i1
β ti
where εinit is the initial learning rate. If otherwise spec-
ified, εinit  0017. Examining Eq. (4) clearly indicates
that a larger αi  1 will increase the learning rate. That
in turn, according to Eq. (3), encourages fusion (and
hence merging) to occur.
Another parameter βi in Eq. (4) provides, however, just
the opposite effect. The rational of βi is explained as fol-
lows. Consider the case when R3 is distinctively differ-
ent from its surrounding regions  R1, R2, R4, namely
w13, w23, w43 are rather small, in this case it is de-
sired to inhibit the merge of R3 to R1. Nonetheless, as
described previously, α 1 will be increased by 1 since
Max w13 w23 w43  w13, no matter how small values of
w13, w23, w43! Therefore, in order to counteract the effect
caused by α i and prevent under-segmentation, another
statistical parameter β i defined as the sum squared differ-
ences between Ri and its adjacent regions, i.e. Σ[I Ri
Vol.11 No.6, 2007 Journal of Advanced Computational Intelligence 3
and Intelligent Informatics
Self-Organizing Fusion Neural Networks
culation of dt Ri only uses a small portion of the total
computation load. Furthermore, if some regions and their
adjacent regions are not merged at present iteration, their
average discrepancy parameters will not be recalculated
in the subsequent iterations. This also helps lessen com-
putation load, especially in the case of huge number of
initial regions. In fact, the speed of merging is fast during
the beginning iterations, but as more regions are merged,
it will slow down as the number of identified objects be-
come close to the number of actual objects in the image.
This property is useful as it provides a plausible way of
manually setting the terminating condition for SOFNN.
Namely, the iterative operation will be terminated when
there are no more regions to be merged. In subsection 4.1,
the convergence proof of SOFNN will be provided.
It is not unusual to see that some regions get merged
and some don’t at certain iteration. To proceed to the next
iteration, the updated values of connection weights and
RAG will be recalculated for the merged regions along
with the intact regions. In short, SOFNN mainly con-
sists of three phases: counteracting learning, fusion, and
merging, they perform image segmentation in a manner
of relay race. Finally, it is worthy noting that the num-
ber of neuron is fixed throughout the training process of
Self-Organizing Map (SOM) [12], whereas the number of
neurons in SOFNN decreases during the iterative training
process, and the final number of objects corresponding to
the number of neurons when SOFNN converges or manu-
ally terminated.
3. Experimental Result
3.1. Image Segmentation
We use the benchmark image “peppers” (256256, 256
gray levels) shown in Fig. 4(a) as the input. The result af-
ter applying watershed pre-process is shown in Fig. 4(b).
The over-segmentation phenomenon is quite vivid as the
total number of initial regions is 1566. After applying
Eq. (3) to blend the working features of adjacent regions.
Larger regions are generated by the merging process us-
ing Eqs. (5), (6) and (7). And Fig. 4(c) illustrates the
179 objects painted with weights updated at the 1st iter-
ation. After termination at iteration 5, Fig. 4(d) shows
the final result of 103 merged objects painted with their
corresponding original pixel intensities, the total compu-
tation time is 0.328 sec. It is reasonable to conjecture that
the parallel fashion indeed drastically reduce the compu-
tation time. Fig. 5 shows the merging rate in “peppers”,
it confirms that merging is fast during the beginning itera-
tions, but slows down as the number of identified objects
become close to the number of actual objects in the image
3.2. Noise Tolerance
In conventional segmentation algorithms where the ba-
sic unit to be processed is region or pixel, often only
the immediate neighbors are used for measuring similar-
ity/homogeneity. In contrast, SOFNN explores the inter-
(a) (b)
(c) (d)
Fig. 4. (a) Input image “peppers”, (b) over-segmentation af-
ter applying the watershed analysis, (c) segmentation result
of SOFNN, 179 regions at the 1st iteration, (d) result of 103
regions when terminated at the 5th iteration.
Fig. 5. Merging rate of using input image “peppers”.
regional information; and the merging process is actually
conducted in unit of regional cluster. That is, the lo-
cal threshold is obtained in a wider sense by examining
not only the immediate neighbors of target region but the
neighboring regions surrounding them. This attribute not
only offers a more reliable merging criterion, but provides
more tolerance to input noise. Two types of noise are
tested, namely impulsive and Gaussian. Fig. 6(a) is the
test input “house”. Figs. 6(b) and (c) are the corrupted im-
ages by adding 20% impulsive and Gaussian noise (zero
mean and variance0.01), respectively. Fig. 6(d) is the
tessellation result from applying median filter and water-
shed analysis to Fig. 6(c). Using the output of apply-
ing mean-filtered and watershed analysis to Fig. 6(b) as
test input, Fig. 6(e) shows the segmentation result via
SOFNN. Using the output of applying mean-filtered to
Vol.11 No.6, 2007 Journal of Advanced Computational Intelligence 5
and Intelligent Informatics
Self-Organizing Fusion Neural Networks
(a)
(b) (c)
(d) (e)
Fig. 7. (a) Graphical output of a cluster analysis as the
original gene expression data input, (b) extracting the green
component treated as a grey image in (a), (c) result of filter-
ing using input (b), (d) result of SOFNN using input (c), (e)
clustering result using input (d).
separated clusters using Fig. 7(d) as input, wherein the
number 1, 2, 3 represent the clustering label. These la-
beled results clearly reveal that the outcome of SOFNN
exactly corresponds to separate Gastric tumor lymph node
and non-tumor Gastric tissues in Fig. 7(a), verifying the
effectiveness of SOFNN in grouping the similar regions.
The curves of Figs. 8(a) and (b) represent the grey level
distribution of 255th(green)/256th(blue), 254th (red)/255th
(green) conditions in Fig. 7(a), respectively. In naked
eyes, the variation between two curves 255th/256th in
Fig. 8(a) seems quite vivid, but the two curves are actu-
ally more similar in shape. On the other hand, though the
(a) (b)
(c) (d)
Fig. 8. (a) Grey level distribution of 255th (green)/256th
(blue), (b) grey level distribution of 254th (red)/255th
(green), (c) grey level distribution of 255th/ 256th after ap-
plying filtering and SOFNN, (d) grey level distribution of
254th / 255th after applying filtering and SOFNN.
variation between two curves of 254th / 255th in Fig. 8(b)
looks smaller, the two curves are actually less alike in
shape. In fact, by examining the zoom-in of Fig. 7(a),
we can readily obtain the same separation with naked
eyes. Therefore, the proposed SOFNN indeed is capa-
ble of reducing the variation between 255th/256th, and
can achieve more accurate clustering result. This is ver-
ified by the almost overlapped curves in Fig. 7(c), i.e.,
columns of 255th/256th are classified to the same cluster,
yet columns of 254th /255th are classified as two different
clusters, as shown in Figs. 8(c) and (d), respectively. The
results demonstrate that fusion provides desirable effect
of reducing the variation of multi-dimensional data such
as gene-expression data to achieve better clustering.
4. Characterizations
This section characterizes SOFNN in order to reveal
other important properties and gain more in-depth under-
standing of the method. First, the issue of stability analy-
sis is addressed. We will also show how the parameter α i
and β i affects the learning rate in further improving the
performance of SOFNN.
4.1. Stability Analysis
It is widely acknowledged that judging whether a fi-
nal segmentation result is the best is pointless due to the
lacking of objective metric. Nevertheless, in region-based
techniques gauges such as maximum likelihood or least
square error have been developed to address the issue of
segmentation quality. Our goal here is to study the dy-
namics of SOFNN and prove SOFNN would converge to
a stable state corresponding to a sensible segmentation.
Vol.11 No.6, 2007 Journal of Advanced Computational Intelligence 7
and Intelligent Informatics
Self-Organizing Fusion Neural Networks
will be terminated without manual intervention, thereby
conveniently obviating the need of pre-specifying the ter-
minating number of objects. Another major advantage of
SOFNN is that all regions are processed in parallel fash-
ion, thus providing great potentiality for a fully parallel
hardware implementation such as FPGA [19].
To compare, we note that another self-organizing neu-
ral network, the Grow Cell Structure (GCS) [20] adopts
a competitive learning to update only the best-matching
unit and its neighborhood cells. In contrast, SOFNN un-
dergoes a counteracting learning, and all neurons are si-
multaneously updated. Furthermore, the number of neu-
rons in SOFNN will only decrease after each merging;
it never increases, whereas GCS regulates the number of
neurons to increase or decrease during the training. In
the future, we will consider generalizing SOFNN to al-
low the increase in the number of neurons intermittently
(e.g. in splitting the erroneous merging), we conjecture
that by doing so more accurate and reliable segmentation
results can be obtained. We also attempt to apply SOFNN
to color images, and examine the performance of SOFNN
under different color spaces. Furthermore, in order to pro-
cess various input data with a dimension number higher
than 2D image data, the definition of a region should be
generalized to a high-dimensional sphere.
Acknowledgements
This research was supported by the National Science Council of
Taiwan under grant NSC 94-2213-E-019-014.
References:
[1] F. Hoppner, F. Klawonn, R. Kruse, and T. Runkler, “Fuzzy Cluster
Analysis,” New York, Wiley, 1999.
[2] A. W. C. Liew, H. Yan, and N. F. Law, “Image Segmentation Based
on Adaptive Cluster Prototype Estimation,” IEEE Trans. Fuzzy Sys-
tems, 13-4, Aug., 2005.
[3] A. M. Bensaid, L. O. Hall, J. C. Bezdek, L. P. Clarke, M. L.
Silbiger, J. A. Arrington, and R. F. Murtagh, “Validity-Guided
(Re)Clustering with Applications to Image Segmentation,” IEEE
Trans. Fuzzy Systems, 4-2, May, 1996.
[4] C. W. Chen, J. Luo, and K. J. Parker, “Image Segmentation via
Adaptive K-Mean Clustering and Knowledge-Based Morphologi-
cal Operations with Biomedical Applications,” IEEE Trans. Image
Processing, 7-12, Dec., 1998.
[5] S. A. Hojjatoleslami and J. Kitter, “Region Growing: A New Ap-
proach,” IEEE Trans. Image Processing, 7-7, pp. 1079-1084, July,
1998.
[6] R. C. Gonzalez and R. E. Woods, “Digital Image Processing,” 2nd
Ed., Prentice-Hall, 2002.
[7] D. Hagyard, M. Razaz, and P. Atkin, “Analysis of Watershed Al-
gorithms for Greyscale Images,” IEEE Proc. Int. Conf. Image Pro-
cessing, pp. 41-44, 1996.
[8] L. Vincent and P. Soille, “Watersheds in Digital Spaces: An Ef-
ficient Algorithm Based on Immersion Simulations,” IEEE Trans.
Pattern Anal. Machine Intell., 13-6, pp. 583-598, June, 1991.
[9] T. Pavlidis, “Structural Pattern Recognition,” New York, Springer,
1980.
[10] K. Haris, S. N. Efstratiadis, N. Maglaveras, and A. K. Katsagge-
los, “Hybrid image segmentation using watersheds and fast region
merging,” IEEE Trans. Image Process., 7, (12), pp. 1684-1699,
1998.
[11] A. P. Mendonca and E. A. B. da Silva, “Segmentation Approach
Using Local Image Statistics,” Electronics Letters, 36, 14, pp. 1199-
1201, July 6, 2000.
[12] T. Kohonen, “The Self-Organizing Map,” Proc. of IEEE, 78, 9,
pp. 1464-1480, 1990.
[13] R. Nock and F. Nielsen, “Statistical Region Merging,” IEEE Trans.
Pattern Analysis and Machine Intelligence, 26, 11, pp. 1452-1458,
Nov., 2004.
[14] C. T. Zahn, “Graph-Theoretical Methods for Detecting and Describ-
ing Gestalt Clusters,” IEEE Trans. on Computers, 20, pp. 68-86,
Jan., 1971.
[15] C. F. Bazlamacci and K. S. Hindi, “Minimum-weight Spanning Tree
Algorithms – A Survey and Empirical Study,” Computers & Oper-
ations Research, 28, pp. 767-785, 2001.
[16] K. A. Ross and C. R. B. Wright, “Discrete Mathematics,” Prentice-
Hall, New Jersey, 1999.
[17] S. Y. Leung, X. Chen, K. M. Chu, S. T. Yuen, J. Mathy, J. Ji, A. S.
Chan, R. Li, S. Law, O. G. Troyanskaya, I. P. Tu, J. Wong, S. So, D.
Botstein, and P. O. Brown, “Phospholipase A2 group IIA Expres-
sion in Gastric Adenocarcinoma is Associated with Prolonged Sur-
vival and Less Frequent Metastasis,” Proc. of the National Academy
of Science, 99, 25, pp. 16203-16208, Dec., 2002.
[18] D. Jiang, C. Tang, and A. Zhang, “Cluster Analysis for Gene Ex-
pression Data: A Survey,” IEEE Trans. Knowledge and data engi-
neering, 16-11, Nov., 2004.
[19] B. Zeidman, “Designing with FPGAs and CPLDs,” CMP Books,
Sep., 2002.
[20] B. Fritzke, “Growing Cell Structure: A Self-organizing Network
for Unsupervised and Supervised Learning,” Neural Networks, 7-9,
pp. 1441-1460, 1994.
Name:
Jung-Hua Wang
Affiliation:
Professor, Soft-computing Lab, Department of
Electrical Engineering, National Taiwan Ocean
University
Address:
Rm-503, Bldg. EE-1, 2, Pei-Ning Road, Keelung, Taiwan 20224, R.O.C.
Brief Biographical History:
1983- Chung-Shan Institute of Science and Technology (CSIST)
1985- Texas Instrument
1991- Industrial Technology Research Institute (ITRI)
1998-present Taiwan Intellectual Property Office (TIPO)
1991-present Department of Electrical Engineering, National Taiwan
Ocean University
Main Works:
  Image Processing, Neural Networks, Pattern Recognition
Membership in Academic Societies:
  Institute of Electrical and Electronics Engineers (IEEE)
  Optical Society of America (OSA)
Vol.11 No.6, 2007 Journal of Advanced Computational Intelligence 9
and Intelligent Informatics
