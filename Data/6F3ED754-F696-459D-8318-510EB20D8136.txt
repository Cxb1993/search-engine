中文摘要：
本計畫(九十五年度) 「體積全像應用於三維形貌量測之研究 II」承繼九十四年度之國科會
計畫申請案，繼續開發以繞射元件三維形貌量測系統－ Calibration-Based Projected Fringe
Profilometry。主要原理是將繞射元件(體積全像片)產生之 diffracted sinusoidal fringe pattern
投影在待測物體上，其條紋扭曲程度和待測物體的縱深有關，稱為「相位－縱深」關係式
(phase-to-depth relation)，找到此關係式即可進一步得到物體表面的三維座標。此 sinusoidal
pattern 將由體積式繞射元件的影像重建所產生，而影像重建所需之光源則是雷射光源。本
計畫重點在於設計一灰階特殊分佈之 fringe pattern，以此 pattern 作為物光，紀錄於體積全
像元件中，再利用雷射光源所重建出的影像，投射在待測物表面。因此第二年計畫除了針
對體積全像元件本身作特性分析外，物光圖形的設計與製作亦是一大重點。以繞射元件取
代條紋投影系統的主要優點在於：1. 可避免光學透鏡組造成的像差，如 distortion、
astigmatism、field curvature 等，對於超大尺寸的形貌量測(如大尺寸液晶顯示器件的平整度
量測)，提供極佳的便利性；2. 此繞射元件的體積甚小(<500μm3)，搭配內視鏡等小型的
image sensor 可形成一完整的光學微機電形貌量測系統，適用於生物體腔內部之 3D 檢測；
3. 相較於目前各式的形貌量測系統，包括傳統的 holographic interferometry，此計畫的量測
裝置更加輕便、簡單，而且避免了像差因素，故而降低了電腦演算及系統校正成本；4. 由
於光源的同調性甚佳，故投影系統有甚大的景深(depth of focus)，待測物的縱深量測範圍亦
因此增加；5. 由於影像擷取系統只需要擷取一次資料，因此可進行動態物體的三維形貌量
測。
關鍵詞：條紋投影技術，弦波光柵，三維形貌量測系統，繞射元件
英文摘要：
A projected fringe profilometry using a diffraction element for finding the absolute shape of an
object with large depth discontinuities is proposed. The projection system is simplified by using a
diffraction element to produce a two-frequency fringe pattern instead of the typical fringe
projection scheme. The proposed method offers following major advantages: The main
advantages of Calibration-based Projected Fringe Profilometry are: (1) Calibration-based
Projected Fringe Profilometry is capable of sampling the entire surface simultaneously with
minimum requirements to the mechanical fixture. (2) It employs the conventional one-camera
and one-projector configuration, which enables higher flexibility in measurements and more
compactness in hardware implementation. (3) The high spatial coherence from the diffractive
element makes it possible to generate a large depth of field projection.
Keywords: projected fringe profilometry, 3D imaging and vision, 3D profile measurement,
diffraction element
projection. Fringes are formed by means of the so-called Young’s setup in which interference
between two plane waves are inclined at a small angle to each other. The projection system is
therefore simplified by using a two-slit device. Unfortunately, it is still a challenge to analyze
surfaces with lots of discontinuities. Phase unwrapping [11-14], the inevitable procedure to
remove the phase jumps in order to recover the absolute phase, will encounter ambiguity to
distinguish the local fringe order. Two or several different projected spatial frequencies can be
used to increase the range of measured depth [15-24]. However, these systematic configurations
become complicated again and are still impractical in application to endoscopes.
In this paper, we investigate the use of a fringe pattern generated by launching a laser beam
into a diffraction grating. The projection system is simplified by using a diffraction element
instead of a projection lens or interference components. This makes it possible to perform 3D
shape measurements using endoscopes. The field of view of this measurement system can be
wider than 60°, depending on requirement of the working distance and measurement scale of the
tested object. The high spatial coherence from the diffraction grating allows it to generate a large
depth-of-focus projection. In addition, only one measurement frame is required to inspect
surfaces. Thus, it is feasible to perform a single-shot measurement of dynamic objects.
To distinguish the depth discontinuities, the diffraction grating forms a two-frequency fringe
pattern in which one frequency is five times larger than the other. The low frequency is more
tolerant to physical discontinuities, whereas the higher one can refine the result. Therefore, phase
jumps of the high frequency while phase unwrapping can be corrected with reference to the
low-frequency phases. The unwrapped high-frequency phases are then used to retrieve the 3D
information. Therefore, the overall system is compact for specific detections in many severe
circumstances, especially for 3D inspections using an endoscope for dynamic surfaces with large
depth discontinuities.
2. Fabrication of the diffraction component for fringe projection
To produce the two-frequency projection using a diffraction element, a standard holographic
setup is proposed, as shown in Fig. 1. The setup is mainly composed of (1) a laser with good
temporal coherence, (2) a divergent reference wave from a single-mode fiber, (3) a convergent
object wave, and (4) a hologram, which is used as a diffraction element. An objective lens
forms the object wave from a two-frequency pattern. The reference wave and the object wave
interfere, resulting in an intensity distribution in the hologram.
The two-frequency pattern is the combination of two sets of fringes with different frequencies:
one frequency is P (P = 3, 4,5 …)times larger than the other. Its transmittance is represented as
 )cos()cos( 24124121 xxxt Pdd   , (1)
where d is the period of the high frequency. We have proposed a method to fabricate an accurate
two-frequency pattern [8]. An example of the pattern is shown in Fig. 2. In this pattern, the period
Fig. 3. Projected fringe profilometry using a diffracted two-frequency pattern by
launching a reading beam to the hologram. An endoscope combined with a CCD
camera is used to record fringes
4. Phase-extraction and unwrapping
Phases of the two-frequency pattern are evaluated by Fourier transform method [3]. The
intensity distribution with distorted fringes of a two-frequency pattern obtained by the CCD
sensor array can be represented as
           yxyxlyxyxhyxayxI lh ,cos,,cos,,,   , (3)
where a(x, y) is the intensity bias at location (x, y) in the CCD detection plane, h(x, y) and l(x, y)
are the fringe modulation, and h and l are absolute phases of the high frequency and low
frequency, respectively. Note that the high frequencyh is P (P = 3, 4,5 …)times larger than the
low frequencyl, even though they are distorted.
Compute the one-dimensional Fourier transform of Eq. (7) and obtain the Fourier spectra.
With a suitable band-pass filter, the spectra are filtered to pick up the fundamental components.
By applying the inverse Fourier transform to the fundamental components, two complex signals
can be recovered,
      yxjyxhyxs hh ,exp,,  , (4a)
    )],(exp[,, yxjyxlyxs ll  . (4b)
Phase distribution of the higher frequency from Eq. (8a) is then given by
      



 
x,ys
x,ys
yx
h
h
h Re
Im
tan, 1 , (5a)
and that of the lower one according to Eq. (8b) is
      



 
x,ys
x,ys
yx
l
l
l Re
Im
tan, 1 . (5b)
Fig. 4. Coordinate systems in a non-telecentric projected fringe measurement
system.
5. Experiments
5.1 3D shape measurements
An experimental setup was constructed to test the projection system, as shown in Fig. 3. An
endoscope was utilized to guide the acquired image. The obtained information was then recorded
by a monochrome sensor array with 10241024 pixels at 12-bit pixel resolution. A He-Ne laser
with an output power of 10mW at 632.8nm was employed to be the light source. A film hologram
was used as the diffraction component. Its diffraction efficiency was measured approximately 20
%. The focal length of the objective lens used to form an image of the two-frequency pattern was
100mm. In this fringe pattern, the period was 960m. A flat plate was selected as the testing
sample. Large step discontinuities occurred between the fan blade and the cubic object.
Shown in Fig. 5 is the recorded image in which the diffracted pattern was projected on this testing
object. Figure 6 is the reconstructed shape.
5.2 Error analysis
Errors of the system, in the case of our experiment, were mainly raised from the uncertainty
of phase evaluation using Fourier transform method, speckle noise of the diffraction pattern, and
the spatially sampling density of image acquisition system. If a fiber endoscope was employed,
the systematic accuracy would be worse. The major reason comes from that the spatially
sampling density of the fiber endoscope is generally lower than that of a CCD camera.
grating. A method to fabricate this diffraction element has been presented. A two-frequency
projection was employed, and therefore it was robust to analyze surfaces with discontinuities.
The high spatial coherence from the diffraction grating allows it to generate a large
depth-of-focus projection. Thus, the depth’s measuring range could be very large. The field of
view of this measurement system could be wider than 60°, depending on requirement of the
working distance and measurement scale of the tested object. Since only one phase measurement
was needed for operation, it was practical for 3D measurements of dynamic objects. The
projection system was simplified by using a diffraction element instead of a projection lens or
interference components. Thus, the overall system was very compact. This makes it possible to
perform 3D shape measurements using the diffraction grating built into an endoscope for
dynamic surfaces with large depth discontinuities.
9. Reference
1. G. Indebetouw,“Profile measurement using projection of running fringes,”Appl. Opt. 17,
2930-2933 (1978).
2. V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of
3-D difuse objects,” Appl. Opt. 23, 3105-3108 (1984).
3. M. Takeda and K. Mutoh, “Fourier transform profilometry for the automatic measurement 
of 3-D object shaped,” Appl. Opt. 22, 3977-3982 (1983).
4. X. Su, and W. Chen, “Fourier transform profilometry: a review,”Opt. Lasers Eng. 35,
263-284 (2001).
5. K. G. Larkin and B. F. Oreb, “Design and assessment of symmetrical phase-shifting
algorithms,” J. Opt. Soc. Am. A9, 1740-1748 (1992).
6. Y. Surrel, “Design of algorithms for phase measurements by the use of phase stepping,”
Appl. Opt. 35, 51-60 (1996).
7. F. Chen, G. M. Brown, and M. Song, “Overview of three-dimensional shape measurement
using optical methods,” Opt. Eng. 39, 10-22 (2000).
8. W. H. Su, H. Liu, K. Reichard, S. Yin, and F. T. S. Yu, “Fabrication of digital sinusoidal 
gratings and precisely conytolled diffusive flats and their application to highly accurate
projected fringe profilometry,” Opt. Eng. 42, 1730-1740 (2003).
9. H. Liu, W. H. Su, K. R., and S. Yin, “Calibration-based phase-shifting projected fringe
profilometry for accurate absolute 3D surface profile measurement,” Opt. Commun. 216,
65-80 (2003).
10. Wei-Hung Su, Karl Reichard, Hongyu Liu, and Shizhuo Yin, “Integration of segmented 
3D profiles measured by calibration-based phase-shifting projected fringe profilometry
(PSPFP),” Optical Memory & Neural Networks, 12, 51-63 (2003).
27. W. C. Su, W. H. Su, and H. J. Kao, “Correlator-aided alignment of phase key in encrypted
holographic storage systems,” Opt. Commun. (accepted)
28. C. K. Lee, and W. H. Su, “Correlator-aided alignment of phase key in encrypted
holographic storage systems,” submitedto Opt. Express.
29. W. H. Su, “Projected fringe profilometry using the transmittance-encoded algorithm for
spatially isolated dynamic objects,”submitted to Opt. Express.
30. W. H. Su, and C. Y. Kuo, " Time resolved profile measurements for ultra-fast vibrating
objects," Proceedings of SPIE 6698, (2007).
31. W. H. Su, and C. Y. Kuo, "3D shape reconstruction using multiple projections: a method
to eliminate shadowing for projected fringe profilometry," Proceedings of SPIE 6698,
(2007).
32. W. H. Su, G. L. Chen, and C. Y. Kuo, " Speckles removal from 3D images by empirical
mode decomposition," Proceedings of SPIE 6698, (2007).
33. W. H. Su, C. K. Lee and C. Y. Kuo, " 3D shape reconstruction using projected fringe
profilometry for an image blurred by linear motion," Proceedings of SPIE 6698, (2007).
34. Jun-Shan Huang and Wei-Hung Su, “Projected fringe profilometry for micro-scale
measurements,”OPT2006 光電科技研討會 (2006).
35. 黃俊善, “條紋投影輪廓儀從事動態微小元件之量測研究,”中山大學材料科學研究所
碩士論文 (2007).
36. 陳冠融, “以經驗模態分解法消除二維影像之雷射光斑之可行性分析,”中山大學光電
工程研究所碩士論文 (2007).
計畫成果自評
本計劃研究內容與原計畫十分相符，並且於期限內達成預期目標，本計畫執行成效豐碩。
主要有：
1. 一篇國際期刊的發表[26]；
2. 一篇國際期刊的已投稿並且已接受[27]；
3. 二篇國際期刊已投稿並且待審中[28-29]；
4. 參與國際研討會 SPIE 的發表，計 4 篇[30-33]，其中[30]為 invited paper；
5. 部分成果已發表於 2006 光電年會[34]；
6. 二位碩士班研究生依此計劃於 2007 年六月順利畢業，碩士班畢業論文計兩篇[35-36]；
7. 研究成果之學術或應用價值如下頁所示。
interferometry，此計畫的量測裝置更加輕便、簡單，而且避免
了像差因素，故而降低了電腦演算及系統校正成本；
4. 搭配本人提出的 dual-frequency、multi-frequency projected fringes
投影系統，可從事外觀複雜或深度變化有甚大落差的 3D 形狀
量測；
5. 由於光源的同調性甚佳，故投影系統有甚大的景深(depth of
focus)，待測物的縱深量測範圍亦因此增加；
6. 由於影像擷取系統只需要擷取一次資料(one-shot
measurement)，因此可進行動態物體的三維形貌量測。
推廣及運用的價值
形貌檢測 (Profile Inspection) 在工業界的應用日趨廣泛。實際的例
子，在國防工業如飛彈、魚雷、機翼與螺旋槳等形貌之鑑定，醫學
工程如生物細胞，電子產業如 PC 板面，機械製造如齒輪形狀探測
等，皆需要對待測物之三維形貌作精密的檢定。故發展精確的形貌
量測技術已成為產業界的重大課題之一。
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
※ 3.本表若不敷使用，請自行影印使用。
Projected fringe profilometry using holographic techniques
for large-scale measurements
Wei-Hung Su, Wei-Jen Chen, Hung-Jei Kao, and Chia-Jeng Huang
Department of Material Science and Optoelectronic Engineering,
National Sun Yat-Sen University
Kaohsiung 804, Taiwan
ABSTRACT
A technique using diffractive elements for finding the absolute shape of a large-scale object is
proposed. It is found that an accurate projected fringe profilometer can be built by applying the
holographic technique in the system. The advantages of using the presented technique for projected
fringe profilometry are: (1) a large depth of field; (2) very fringe distortion (even for a large field of
view); and (3) a very compact design for the measurement system.
Keywords: fringe projection, projected fringe profilometry, phase-shifting, sinusoidal grating,
hologram, diffractive element
1. INTRODUCTION
Projected fringe profilometry is a powerful tool for the 3D surface profile inspection of rough
engineering surfaces [1-6]. It is notable for its non-contact nature, system simplicity, fast
measurement speed, high profile sampling density, and low environmental vulnerability. The entire
surface is sampled simultaneously with minimum requirements to the mechanical fixture. Accuracy
better than one part in ten thousandths of the field of view can be achieved even with excessive
image noise [6].
Profile measurements by projected fringe methods are commonly used either in a comparative
mode, in which a surface is compared to another surface and the difference is measured; or in an
absolute mode, in which the depth of a single surface is desired. Both modes require a sinusoidal
fringe pattern projected onto the inspected surface in order to demodulate the distorted fringe values
into the corresponding depths. When an accurate 3D shape measurement is required, a careful
calibration of the optical system’s distortion characteristics must be performed.In many previously
reported works, image lateral geometry has often been used to approximate object lateral geometry
[7][8]. Such an approach fails when the imaging system sustains considerable amount distortion,
which is unfortunately true for most off-the-shelf cameras. Furthermore, the depth measuring range
is basically limited by the depth of field of a projection system. When a profile measurement for
3.1 Phase-to-depth calibration
A standard optical flat is applied to perform phase-to-depth calibration of the optical system. The
diffracted sinusoidal fringe pattern is projected onto an optical flat surface perpendicular to the z
direction via the projection optics, as shown in Fig. 3. The resultant phase distribution on the flat
surface can be computed using the Fourier Transform algorithm [10]. The phase measurement is
repeated as the flat is successively translated to different depth position (at plane izz  ) and stops
when certain limit position is reached. The phase maps measured in this way are unwrapped first
along the transverse directions and then the depth direction to recover phase continuity information.
After this processing, a series of absolute phases and the associated depths are then obtained at each
pixel location ready for the subsequent curve fitting.
For fitting the curve, the estimation can be represented by the expansion of polynomials [11]



N
n
n
ncZ
0
 , (1)
where Z and  is unwrapped depth and phase, and nc is coefficient of the polynomial. The
coefficients of the polynomial can be determined by a set of sufficient phase values and their
corresponding depth values. In general, algorithms become more accurate as the order of the
polynomial, n, increases. This is accomplished, however, at the cost of an increasing
computational complexity, as well as increased data acquisition.
Once phase-to-depth relation Z at each pixel is determined, we are in a position for lateral calibration.
3.2 Lateral calibration
In the procedure of lateral calibration, two mutually orthogonal sinusoidal gratings are used as
known objects. These two sinusoidal gratings with their fringes parallel to the X and the Y directions
are sequentially placed at the plane izz  in front of the imaging system to form a virtual grid
pattern. Assembling the images of these temporally separated but spatially overlapped gratings
yields a virtual grid pattern, which serves as a metric standard in the transverse calibration. The
setup is depicted schematically in Fig. 4, but only a diffracted pattern with their fringes parallel to
the X direction is shown. The image of the diffracted pattern is captured by a CCD camera. When a
number of virtual grids are successively generated and measured at different depth positions, lines
of sight of different pixels are traced out. The intersection point of these fringes in the virtual grid
represents the origin of the XY plane.
Consider the center of an arbitrary pixel in which unwrapped phases x and y are measured
4. QUANTITATIVE ANALYSES
First we investigate the performance of the reconstructed pattern on the tested object. A fan blade
was used as the tested object. Coherent noise is inevitably introduced by the laser source. To
eliminate the speckles on the fringes, the Fourier Transform algorithm was applied. The phase
distribution was shown in Fig. 6.
To compute the unwrapped phase, the phase map is normalized by subtracting the phase at one
reference fringe, as shown in Fig.7. Since a series of absolute phases and the associated depths had
been obtained at each pixel location ready for the subsequent curve fitting, which has been
described in section 3.1, the unwrapped phase at each pixel can be translated to the corresponding
depth value. By the same procedure, a series of lateral position and the associated depths had been
obtained at each pixel location then ready for the subsequent curve fitting. The corresponding
lateral position can be determined from the depth value. Fig. 8 showed the profile demodulated by
this calibration scheme.
5. CONCLUSION
In this paper, we investigated a unique calibration-based projected fringe profilometry using holographic techniques for
finding the absolute shape of objects. The depth of field of the diffractive projection system was analyzed. It was
found that a large depth of field could be obtained by the conjugate reading illumination. The advantages of using the
reconstructed fringe pattern in the system were discussed, including (1) a large depth of field, (2) easiness with
calibration, and (3) very low fringe distortion aberration (even for a large field of view); and (4) a very compact design
for the measurement system. Finally, the system model underlying the calibration process encompasses the case in
which the detection plane is not perpendicular to the optical axis of the imaging lens. This makes the current
technique especially adaptable to some specially configured measurement systems such as precision gear gauging and
large scale profile inspections. We believe that a robust, accurate projected fringe profilometry can be realized by using
the diffractive projection system, which may have a variety of applications such as rough 3D surface measurement.
Figure 1 Schematic diagram of a holographic system.
Figure 2 Schematic diagram of a projected fringe profilometric system using the reconstructed fringe
pattern by launching a conjugate reading beam to the hologram.
Figure 4 Lateral calibration for a projected fringe profilometry. The tested surface is replaced by a grating with fringes parallel to the
X direction. In the detection plane, each pixel obtains two phase values from depth 1zz and 2zz .
Figure 7 Unwrapped phase map on the fan blade.
125
250
375
500
625
750
875
250 375 500 625 750 875
0
100
200
300
400
500
Figure 8 Measured 3D surface profile of the fan blade.
correlation technique and its variants cannot cope with local distortion effects of the optical system. 3) The algorithms
based on the image intensity are very sensitive to radiometric distortions and image noise. 4) The algorithms based on
a global nonlinear optimization are computationally expensive and typically need good initial guesses to ensure correct
convergence. 5) The achievable accuracy of these algorithms is usually 5-10 times lower than required in the
high-accuracy three-dimensional measurements [10].
In an effort to overcome these problems, we had presented a fringe projection scheme in which uses a fringe pattern
projected on to the overlapped region to accurately identify the correspondences during two segmented measurements
[11]. The projected pattern fixes their position relative to the tested object. Thus, a pair of absolute phase values can
uniquely represent each point in the overlapped region. Finding two matched surface points becomes a problem of
searching for two identical phases in the fused data sets. Accuracy of the registration scheme can be achieved as high as
one part in one hundredth of one pixel. [12]
The fringe projection scheme is basically limited by the depth of field of a projection system. One possible way to
extend the depth of the field is to use a laser as the projection light source. The high spatial coherence (i.e., a point
source) of a laser source provides a near infinite depth of focus projection system. Unfortunately, speckle noise which is
harmful to the measurement accuracy is also inevitably introduced by the temporal coherence of the laser source.
To maintain the large depth of the field and eliminate the speckle noise of the laser sources used in the fringe projection
scheme, in this paper, we investigate the use of a supercontinuum light generated by launching ultra short laser pulses
into a highly nonlinear photonic crystal fiber in the projected fringe profilometry [13-16]. The ultra high spatial
coherence (~ 1 micron, determined by the core diameter of the photonic crystal fiber) and low temporal coherence (ultra
wide spectral range from UV to near infrared) make it possible to achieve long depth of field projection without speckle
noise.
2. PROJECTED FRINGE PROFILOMETRY USING SUPERCONTINUUM LIGHT
ILLUMINATION
To illustrate the projected fringe profilometry using the supercontinuum light illumination, a
standard phase-shifting projected fringe system was built, as shown in Fig. 1, which were mainly
composed of (1) a highly nonlinear photonic crystal fiber, (2) a collimating lens, (3) a sinusoidal
fringe pattern set on the top of a moving stage, (4) a projecting lens based imaging system, (5) a
testing object, and (6) a CCD camera system used to record the projected fringes on the testing
object.
In the experiment, the supercontinuum light was generated by launching femtosecond pusles from a
mode locked Ti: Sapphire laser into a highly nonlinear photonic crystal fiber (manufactured by
Crystal Fibre, model number: NL-2.0-770) [16]. Since the effective area of this fiber was very small
(around 1 micron in diameter), the supercontinuum light can be generated within this short (around
10 cm) photonic crystal fiber via several nonlinear effects, including four wave mixing and Raman
scattering. At the output end of the fiber, an almost perfect white light point source (around 1
micron diameter) was obtained. The light beams from this point source were collimated by a
collimating lens and the collimated beams were employed to illuminate a sinusoidal fringe pattern.
Then, the sinusoidal fringe pattern was projected onto the surface of the testing object. Finally, a
CCD camera system was used to record the projected fringes on the testing object.
To measure the 3D surface profile, a standard four-step phase shifting method was utilized [7]. Four projected fringe
patterns, 1 2( , ), ( , ), ( , ),oI c r I c r I c r and 3( , )I c r with a / 2 phase shifting step between adjacent patterns
were recorded by the CCD camera system, as given by
3. SYSTEM SETUP OF SEGMENTED MEASUREMENTS FOR 3D IMAGE INTEGRATION
A fan blade was used as the tested object. Figs. 4(a) ans (b) showed two segmented measurements
implemented by moving the detection system from position 1 to 2. Their corresponding 3D surface
profiles were calculated as described in section 2. Figs. 5(a) and (b) showed the computed 3D
shapes.
To study the integration method using the supercontinuum light illumination, a standard phase-shifting projected fringe
system was built, as shown in Fig. 6. Two small surface patches were recoded by the CCD camera system one at a time
for the later assembly into a mosaic of profile maps. The object surface was segmented in such a way that different
regions overlapped with each other. The overlapped regions provided useful information for estimating the changes in
the orientation and the position of the inspection system. Two sinusoidal gratings with respective fringes orthogonal to
each other are sequentially projected onto the overlapped region represented by the hatched square. The projected
gratings fix their position relative to the tested object during two segmented measurements. After segmented phase
measurements, each point in the overlapped region can be uniquely represented by a pair of absolute phase values.
Finding two matched surface points becomes a problem of searching for two identical phases in the fused data sets.
Once the matched surface points in coordinated system 1 and coordinated system 2 were identified, the relationship
between them was given by the following coordinate transform,
T
z
y
x
R
t
t
t
z
y
x
rrr
rrr
rrr
z
y
x
z
y
x






















































1
1
1
1
1
1
333231
232221
131211
2
2
2
. (4)
The matched surface points provided sufficient information to determine the rotation matrix R and the translation vector
T [11]. Thus, the transformed data sets can then be assembled together in the same reference system.
Fig. 7 showed the integrated surface by combining Figs. 5 (a) & (b) by using the supercontinuum light illumination.
4. CONCLUSION
In summary, we investigated a unique projected fringe profilometry based on the supercontinuum light illumination.
First, it was found that a large depth of field could be obtained by the point light source illumination. Second, the
advantages of using the supercontinuum light illumination in the projected fringe profilometric system were discussed,
including (1) a large depth of field, (2) easiness with calibration, and (3) no coherent noise. Finally, the theoretically
predicted advantages of using the supercontinuum light illumination were experimentally confirmed. A fan blade was
chosen as a testing object. The 3D surface profile of the fan blade was precisely measured across the entire surface of
the fan blade. There were no noticeable errors at any location of the fan blade, regardless of its depth.
We also presented a method to integrate segmented 3D profiles to an entire shape using a fringe projection scheme via
supercontinuum light illumination. This method is useful for the vision of intelligent robot systems because of the
following advantages: 1) This scheme accurately integrates 3D images encompasses the case of scale, rotation,
Figure 1 Schematic diagram of a phase-shifting projected fringe profilometric system using
the supercontinuum light illumination
Figure 2 Fringes projected on a an blade via supercontinuum light illumination.
125
250
375
500
625
750
0 125 250 375 500 625 750
05
1015
2025
125
250
375
500
625
750
250 375 500 625 750 875
05
1015
2025
30
(c) (b)
Figure 5 Measured 3D surface profile of the fan blade (a) at position 1, and (b) at position 2.
Figure 6 Schematic diagram of two segmented profile measurements.
