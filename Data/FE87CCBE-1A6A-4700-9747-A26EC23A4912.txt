行政院國家科學委員會專題研究計畫成果報告 
整合的資料挖礦架構之發展與應用(I) 
A hybrid framework of data mining:  
development and application 
計 畫 編 號：NSC 97-2221-E-030-018- 
執 行 期 限：97 年 8 月 1 日至 98 年 7 月 31 日 
主 持 人：陳麗妃   輔仁大學 經營管理碩士學程 
共同主持人：楊建炘   僑光科技大學 工業工程與管理系 
計畫參與人員：李建賢   輔仁大學 商研所博士班 
              方曉琪、林國豐、李文伽    輔仁大學經營管理碩士學程 
 
一、中文摘要 
對於分類預測問題，除了要求其精確度
之外，是否能提供簡明易懂的規則來探求相
關的管理意義，通常也是決策者的重要考量
之一。在資料挖礦(data mining)的分類預測問
題中，約略集合論 (RST)、支援向量機 (SVM) 
與決策樹 (DT) 等技術受到許多學者的青
睞。約略集合論與DT可以產生規則，而SVM
則無此能力。另一方面，RST的屬性選取能
力令人矚目，而SVM與DT則以其預測能力受
到重視。本計畫將結合此三項技術的優點，
發展整合的資料挖礦架構以改善預測的準確
度並提升規則產生的品質，所欲發展的整合
架構包括四個主要階段。結果顯示本計畫所
提出的方法能夠有效改善預測的準確度並提
升規則產生的品質，同時其績效較傳統的
RST、SVM與DT為佳。 
關鍵字: 資料挖礦、分類、約略集合論、支援
向量機、決策樹、特徵選取 
Abstract 
Support vector machine (SVM), rough set 
theory (RST) and decision tree (DT) are 
methodologies applied to various data mining 
problems, especially for classification 
prediction tasks. Studies have shown the ability 
of RST for feature selection while SVM and 
DT are significantly on their predictive power. 
DT and RST can generate such rules, however, 
SVM can not offer such function. This project 
aims to integrate the advantages of SVM, RST 
and DT approaches to develop a hybrid 
framework to enhance the quality of class 
prediction as well as rule generation. The 
proposed framework will cover four main 
stages. For validation, a case of prediction 
model in UCI data sets be studied using the 
proposed hybrid data mining framework. 
Implementation results will show that the 
proposed approach is effective and has a better 
performance than that of traditional SVM, RST 
and DT. 
Key words: Data mining, Classification, Rough 
set theory, Support vector machine, Decision 
tree, Feature selection. 
二、緣由與目的 
1 
enhance performance of prediction accuracy and 
rule extraction.  
a 
 
 
 
 
 
 
Figure 1. The concept of proposed hybrid 
approach 
The hybrid data mining approach are with 
following steps. First and the most critical step 
for data mining is to understand and define the 
right problem. The objectives also need to be set 
up in this step. Data must be collected and 
prepared carefully for further analysis. Data 
preparation processes consist of checking the 
data distribution and outliers, dealing with 
empty or missing values, enriching data, and 
transforming data into analyzable formats were 
employed to improve data quality and to thus 
enable effective data mining. 
After data collection, RST is applied on the 
full training data set to generate reducts. The 
reducts would be used for feature selection to 
find the minimal subset of the features from 
original data set. The next step is to reduce 
instances. SVM is employed as a preprocessor 
of the data set. We perform n-fold cross 
validation on the data set. Each case in every 
testing set would be checked to see if it can be 
predicted correctly using the trained model. 
Those correctly predicted cases would be chosen. 
These processes would be repeated until all the 
n subsets are tested.  Finally, all the cases that 
can be correctly predicted are collected to form 
a new data set. Through the above steps, the new 
data set with less noise is then used for the 
further analysis, that is, to construct prediction 
model by DT. Decision rules with the form 
“if…then…else…” can also be developed.  
Classification Screen attributes 
by RST 
The constructed model should be reviewed 
and evaluated before it can be used for decision 
support. The testing data set is used to check the 
validity of the candidate rules. Data mining 
results should be interpreted and assessed 
according to the experience and knowledge of 
domain experts in order to justify the meaning 
of extracted knowledge. 
The discovered knowledge can be the basis 
for decision support to generate required 
management strategies. It can also be used to 
improve related management activities. 
Furthermore, since the empirical model derived 
from data mining has its life cycle and thus need 
to be reviewed periodically to maintain its 
validity. 
A simple example, “Teaching assistant 
evaluation (TAE)”, one of the data sets from 
UCI data bank (http://www.ics.uci.edu/~mlearn) 
was used to illustrate our proposed approach. 
The data consists of 151 instances which can be 
described by six attributes. We compared the 
performance of the model constructed by our 
proposed approach with original DT and the 
comparison result is listed in Table 1. We found 
that our proposed approach outperforms the 
original DT in both model accuracy and the 
number of rules generated. With our proposed 
approach, although the number of training 
instances and the attributes were decreased, 
however, the model accuracy was increased 
about 9.8% while the number of the generated 
rules could become almost doubled to the 
Original 
data 
set 
New 
data 
set 
Screen instances 
by SVM 
Rule set 
Generate rules 
and class 
prediction by DT 
Adjust 
imbalance class 
by RST 
3 
Knowledge and Data Engineering, 8(6), 
866-883. 
[11] Chien, C. F., Hsiao, A. & Wang, I. (2004). 
Constructing semiconductor manufacturing 
performance indexes and applying data 
mining for manufacturing data analysis, 
Journal of the Chinese Institute of Industrial 
Engineers, 21(4), 313-327. 
[12] Chien, C. F., Wang, W. C. & Cheng, J. C. 
(2007). Data mining for yield enhancement 
in semiconductor manufacturing and an 
empirical study, Expert Systems with 
Applications, 33(1). 
[13] Cristianini, N. & Shawe-Taylor, J. (2000). 
An Introduction to Support Vector Machines, 
Cambridge University Press. 
[14] de Souza, J. T., Matwin, S. & Japkowicz, N. 
(2006). Parallelizing feature selection, 
Algorithmica, 45(3), 433-456. 
[15] Dorffner, G. and Porenta, G. (1994). On 
using feedforward neural networks for 
clinical diagnostic tasks. Artificial 
Intelligence in Medicine, 6, 417-435. 
[16] Dunham, M. H. (2003). Data mining: 
Introductory and advanced topics, Prentice 
Hall. 
[17] Fayyad, U., Piatesky-Shapiro, G., & Smyth, 
P. (1996). The KDD process for extracting 
useful knowledge from volumes of data, 
Communications of the ACM, 39, 27-34. 
[18] Fogel, D. B., Wasson, E. C. III, Boughton, 
E. M., Porto, V. W. (1998). Evolving 
artificial neural networks for screening 
features from mammograms, Artificial 
Intelligence in Medicine, 14, 317-326. 
[19] Folland, R., Hines, E., Dutta, R., Boilot, R. 
and Morgan, D. (2004). Comparison of 
neural network predictors in the 
classification of tracheal-bronchial breath 
sounds by respiratory auscultation, Artificial 
Intelligence in Medicine, 31, 211-220. 
[20] Furey, T. S., Cristianini, N., Duffy, N., 
Bednarski, D. W., Schummer, M. & Haussler, 
D. (2000). Bioinformatics, 16 (10), 906-914. 
[21] Ge, M., Du, R., Zhang, G. C. & Xu, Y. S. 
(2004). Fault diagnosis using support vector 
machine with an application in sheet metal 
stamping operations, Mechanical Systems 
And Signal Processing, 18 (1), 143-159   
[22] Harik-Khan, R.I., Wise, R.A. and Fleg, J.L. 
(2001). The effect of gender on the 
relationship between body fat distribution 
and lung function, Journal of Clinical 
Epidemiology, 54, 399-406. 
[23] He, J. Hu, H., Harrison, R., Tai, P. C. & Pan, 
Y. (2006). Rule generation for protein 
secondary structure prediction with support 
vector machines and decision tree, IEEE 
Transactions on Nanobioscience, 5(1), 
46-53. 
[24] Hu, R., Yu, D.& Xie, Z. (2006). 
Informative-preserving hybrid data reduction 
based on fuzzy-rough techniques, Pattern 
Recognition Letters, 27, 414-423. 
[25] Kukar, M., Kononenko, I., Grošelj, C., 
Kralj, K. and Fettich, J. (1999). Analysing 
and improving the diagnosis of ischaemic 
heart disease with machine learning, 
Artificial Intelligence in Medicine, 16, 
25-50. 
[26] Kusiak, A. (2001). A data mining tool for 
semiconductor manufacturing, IEEE 
Transactions on Electronics Packaging 
Manufacturing, 24 (1), 44-50. 
[27] Li, P. & Wang, Z. (2004). Mining 
classification rules using rough sets and 
neural networks, European Journal of 
Operational Research, 157, 439-448. 
[28] Li, S.T., Shiue, W. & Huang, M. H. (2006). 
The evaluation of consumer loans using 
5 
 出席國際學術會議報告書 
姓    名 陳麗妃 職稱 助理教授 服務單位 經營管理碩士學程 
會議名稱 
中  文 2009 年國際機器學習與控制研討會 
英  文 International Conference on Machine Learning and Cybernetics (ICMLC) 
2009 
會議日期 98 年 7 月 12 日～98 年 7 月 15 日 會議地點 中國 保定 
會後感想及建議： 
International Conference on Machine Learning and Cybernetics (ICMLC)自 2002 年起結合在機器學習領
域的國際優秀學者與產業專家相互交流，ICMLC 2008 已被 EI 索引，足見其在學術上受到的肯定。此次
ICMLC 研討會安排於中國保定舉辦。本人於 7/11 日早上出發，搭乘 BR1716 上午 9:25 起飛之長榮航空
飛抵北京首都國際機場，搭乘出租車至北京車站，抵達保定後再轉車至研討會地點錦江電谷國際酒店。 
本次研討會投稿相當踴躍，共計有 1384 篇，經過嚴格的審核後，接受了 677 篇。本次研討會中，大
會安排的 Keynote Speaker 為 Prof. Witold Pedrycz，其演講主題為”Publish or perish: how to successfully 
publish your research”。本次研討會所發表論文涵蓋許多與 data mining and knowledge discovering 等相關的
主題，其依不同論文主題於三天中分 12 個時段、5 個平行 Sessions 進行 270 個口頭發表，各國學者共聚
一堂相互研討。本人的論文＂Improve class prediction performance using a hybrid data mining approach＂於
7/13 下午 1:00~2:45 時段發表。除了個人的論文口頭發表之外，亦選擇與研究興趣關聯性較高之場次進行
聆聽。 
整體而言，透過此次研討會，與國內外學者有良好交流，因此瞭解了一些國際學者在機械學習相關
領域之研究方向，頗有收穫。會中與各國學者交流可以感受到，雖然受到文化背景不同的影響，文辭表
達上略有差異，但是對於追求研究嚴謹性，仍保有一致性的態度。除了會議的討論之外，亦作了一些工
作上、教學上的交流與經驗分享，整體而言，個人覺得本次活動的獲益匪淺，實為一次良好的學術文化
交流，由衷感謝 NSC 及學校對於本次活動的經費支持。 
另外，北京國際化的速度也是令人刮目相看的。這個城市的新與舊並陳，雖然有時也會偶而穿插一
些讓人傻眼的誆騙或傲慢的服務場景，但大體上北京仍是一個極具魅力的城市。順道一提，此次在偶然
的機緣下，還從胡同巷弄中不經意逛到了輔大在北京的創校原址，雖然現在那裡已經是北京師範大學的
校地了，對外也不開放參觀，還是讓身為輔大人的我感到十分驚喜。據當地人說當時的輔大比北大和清
華還要好，可說是人人稱羨的最高學府。在台灣復校的我們，可得好好加油。 
下列圖片為研討會會場的情形： 
 
 
 
  
 
IMPROVE CLASS PREDICTION PERFORMANCE USING A HYBRID 
DATA MINING APPROACH 
LI-FEI CHEN 
Graduate Program of Business Management, Fu-Jen Catholic University, Taipei, Taiwan 
E-mail: 075033@mail.fju.edu.tw 
Abstract: 
Rough set theory (RST), support vector machine (SVM), 
and decision tree (DT) are brightly data mining methodologies 
for classification prediction tasks. While the accuracy for class 
prediction is highly emphasized, the ability to generate rules 
for decision support is also important in some practical 
applications. Studies have shown the ability of RST for feature 
selection while SVM and DT are significantly on their 
predictive power. Moreover, the ability of DT for rule 
generation is an attractive function. This study intents to 
integrate the advantages of RST, SVM and DT approaches to 
develop a hybrid data mining approach to improve the 
performance of class prediction as well as rule generation.  
Keywords: 
data mining; classification; rule generation; support 
vector machine; rough set theory; decision trees 
1. Introduction 
Data mining is recognized as one of the most salient 
topics for decision support. Data mining involves various 
techniques including neural networks (NN), decision tree 
(DT), genetic algorithm (GA), support vector machine 
(SVM), rough set theory (RST) and visualization 
techniques that have been developed over the years. The 
performance of data mining techniques can be classified 
into two. Some researchers emphasize the prediction 
accuracy of the constructed model while the others stress 
the need to reveal data patterns or rules that are valid, 
useful, simple, understandable, significant and interesting 
[1].  
RST, SVM, and DT are methodologies applied to 
various data mining problems, especially for classification 
prediction tasks. While RST is attractive for its ability of 
feature selection, DT is favorable in rule induction for it can 
generate rules that are easily interpreted and understanding 
for the decision makers to compare with their domain 
knowledge for validation and justify their decisions. On the 
other hand, SVM are attracting increasing attention for the 
properties such as based on a solid theoretical foundation, it 
guarantees about the performance to produce a solution that 
is always unique and globally optimum. It is neither 
affected by local minima nor does it suffer from the curse of 
dimensionality. However, it can not provide rules for 
decision makers. In addition to build up a classification 
model with acceptable accuracy, the capability to explain 
and explore how the decision made with simple, 
understandable and useful rules is a critical issue.  
This study aims to integrate the advantages of RST, 
SVM and DT approaches to develop a hybrid approach to 
enhance the accuracy of class prediction as well as the 
quality of rule generation. The major concept consists of 
three main stages. The first stage is to screen most 
important attributes. RST is applied to eliminate the 
redundant and irrelative attributes without loss of any 
information about classification. The second stage is to 
reduce noisy objects, which can be accomplished by cross 
validation through using SVM. Through the stages 
described above, a data set with fewer dimensions and 
higher degree of purity could be screened out with similar 
class distribution. Finally, the new dataset is used to 
construct prediction model and generate rules by using DT.  
2. Literature review 
Data mining refers to the extraction of useful patterns 
or rules from a large database through an automatic or 
semi-automatic exploration and analysis of data [2] and [3]. 
Classification problem is a key problem in data mining. 
Particularly, algorithms for classification have the abilities 
to predict the class of new instance after having been 
trained on data representing the past experience in 
classifying instances [4]. Techniques such as discriminant 
analysis, K-nearest-neighbor classifier, Naïve Bayes 
 equation is satisfied with the equality sign are called 
support vectors.  
Consider the situation that the set S cannot be 
separated by any hyperplane. Hence, to find an optimal 
hyperplane that minimizes the probability of average 
classification error over the training set is the objective. In 
practice, it could be easier to find a separating hyperplane 
by mapping the original space onto a higher-dimensional 
feature space Z via a transformation function ϕ . The 
problem of finding the optimum hyperplane in the new 
space can be written as 
max ∑∑∑
= ==
ϕ⋅ϕαα−α m
i
m
i
j
T
ijiji
m
i
i yy
1 11
)()(
2
1 xx            (5) 
subject to     0
1
=α∑
=
m
i
ii y
miCi ,...,2,1,0 =≤α≤ , 
Instead of computing )( ixϕ  explicitly, the concept of 
inner product kernel is introduced to reduce the complexity 
of calculation as follows: 
)()(),( j
T
ijiK xxxx ϕ⋅ϕ=                     (6) 
Depends on different cases, we can choose any 
function that satisfies the Mercer’s theory as the kernel 
function. For example, Radial basis function (RBF), 
Polynomial function and sigmoid function are the popular 
kernel functions. 
Rule generation is another important topic for decision 
making in data mining. Decision tree is a data mining 
approach that is often used for classification and rule 
generation. Decision tree has the advantages of easy 
interpretation and understanding for the decision makers to 
compare with their domain knowledge for validation and 
justify their decisions. It can analyze various data without 
requiring the assumptions about the underlying distribution. 
DT is able to handle a high number of records with a high 
number of fields with predictable response times, and it can 
handle both symbolic and numerical data well [14]. Several 
algorithms such as CHAID [15], CART [16], ID3 [17], and 
C4.5 [18] have been developed for decision tree induction. 
In particular, CHAID (i.e., Chi-squared automatic 
interaction detection) is a non-binary decision tree that is 
designed specifically to deal with categorical variables and 
can determine the best multi-way partitions of the data on 
the basis of significance tests [15]. CART (i.e., 
classification and regression tree) is a binary decision tree 
with the Gini index of diversity as the splitting criterion, 
and pruning by minimizing the true misclassification error 
estimate [16]. CART can deal with categorical and 
continuous variable. C4.5 is a variant and extension of a 
well-known decision tree algorithm, ID3 [18]. The splitting 
criterion of C4.5 algorithm is gain ratio that expresses the 
proportion on information generated by a split. The 
error-based pruning is used for pruning in C4.5. In general, 
the objective of these algorithms is to maximize the 
distance between classes. These algorithms can be 
distinguished in terms of different distance measurements, 
pruning methods, missing value disposition, the number of 
branches at each node, and the data type they could handle.  
3. Proposed approach 
In order to improve the efficiency of the task of class 
prediction accuracy and the performance of rule generation, 
we integrate the advantages of RST, SVM and DT to 
construct a hybrid data mining approach. The main idea of 
the proposed approach is shown in Figure 1 and described 
as follows.  
First, we remove unnecessary attributes. It can be 
accomplished through feature selection by applying RST. 
The reducts generated by RST can help to choose the 
attributes with less amount but more important. Second, we 
eliminate noisy instances by performing cross validation 
using SVM. Through the process of selecting new data set 
from the correct result of SVM as the inputs for DT, we 
believe that redundant or impurities instances of the 
original data could be dropped. In other words, the new 
data set selected by SVM might be better than the original 
training data set for rule generation. This is the reason why 
SVM is used as a preprocess of DT. 
After these two stages described above, we can gain 
more representative learning instances with fewer 
dimensions and higher degree of purity to construct the 
prediction model. The new data set is used to generate the 
rules by using DT which complete the last stage. Figure 1 
shows the concept of the proposed hybrid approach. The 
four main stages approach would be embedded into data 
mining approach to enhance performance of prediction 
accuracy and rule extraction.  
 
 
 
 
 
Original 
data 
set 
New 
data 
set 
Screen attributes 
by RST 
Screen instances 
by SVM 
Classification 
model
Generate rules 
and class 
prediction by DT 
Rule set 
 
