 2 
1. INTRODUCTION 
Designers of real-time systems are often concerned with the worst case execution time 
(WCET) of applications.  Such systems often use a task scheduler to assign a fixed amount 
of time to each process.  It is therefore important to determine if each task’s WCET is less 
than its allotted time.  If a process is not able to finish execution within the allotted time, 
then the process is aborted.  The effect of such an abort varies between different systems. In 
hard real-time systems, a missed deadline will crash the entire system. But in soft real-time 
systems, a missed deadline will only cause an undesirable transient effect (such as a missed 
picture frame in a video stream).   
In studying compiler techniques for WCET performance, we have so far focused on memory 
allocation algorithms for scratchpad memory (SPM). SPM is an alternative to a cache. Like 
caches, SPMs store frequently-used data in fast memory (SRAM). Unlike caches, however, 
SPMs do not have special hardware to manage the SRAM. Instead, the SRAM is managed 
through the compiler’s explicit allocation and de-allocation of variables to and from it.  
Because the management strategy is determined at compile time, the variables present in 
SRAM are predictable. With caches, in contrast, it is difficult to predict the data that is present 
in the cache. The predictability of memory access times in SPM-based systems allows for 
better WCET measurement, and better WCET performance. SPMs are therefore popular in 
real-time embedded systems. 
Unfortunately, it is nearly impossible to derive the actual worst case execution time, WCETact, 
of industry-sized applications. Instead, designers rely on approximate analyses. These analyses 
can be divided into two categories: measurement-based methods and static methods.  Both 
methods face serious challenges and neither method can, in general, find the actual WCET.  For 
more information, several recent surveys or extended discussions are available. [1, 2, 3, 4, 5] 
1.1 MEASUREMENT-BASED ANALYSIS 
The measurement-based approach obtains WCETmeas by running a variety of input sequences 
and identifying the worst of the observed execution times.  These test inputs are called profiles, 
and the use of test runs is called profiling.  Profiling has been widely used to estimate the 
average-case execution time (ACET) of programs.  But using this method to derive the WCET 
is problematic, because the worst measured execution time is only a lower bound on the actual 
worst possible execution time (i.e.: WCETmeas ≤  WCETact). 
There are two reasons why the WCETmeas is often less than the WCETact.  First, the input 
sequence that exhibits the worst case execution time may not have been in the set of tested 
inputs.  This often occurs because programs are too complex to identify the worst input a 
priori, and because there are too many input variations to allow for exhaustive testing.  Second, 
even if the worst-case input is identified, the actual WCET is still unknown because of 
nondeterministic behavior in the runtime environment, such as caching effects, interrupts, and 
DRAM refreshes. 
Since WCETmeas is a lower bound on WCETact, efforts are made to tighten this bound.   A 
naïve approach is to randomly generate additional profiles so as to increase the probability of 
finding the true worst-case input.  A better approach is to employ a genetic algorithm, as in [1, 
6, 7].  Nonetheless, WCETmeas remains only a lower bound.  But hard real-time systems 
require an upper bound, so to guarantee that each process always finishes on time.  
In an effort to provide such an upper bound, the measurement approach must be adapted to 
estimate values larger than WCETmeas (and therefore, it is hoped, larger than WCETact).  The 
 4 
 
FIGURE 1.  A comparison of measurement and static execution-time analyses for a hypothetical 
program.  The actual average-case and worst-case execution times of this program are indicated below the 
time axis.  Since the average execution time is smaller than the worst execution time, ACETact is shown to the 
left of WCETact on the time axis.  Above the axis, the estimated average execution time, ACETmeas is depicted 
as being near the value of ACETact; the dotted lines indicate that the measured value could be either lager or 
smaller than the actual value.  The empirically measured WCET is shown to the left of the actual WCET, 
indicating that WCETmeas ≤  WCETact.  The statically analyzed WCET is shown to the right of WCETact, since 
WCETstat ≥  WCETact.  Finally, the precision of the static analysis is indicated by the distance between 
WCETstat and WCETact. 
2. RELATED WORK 
Real-time system engineers routinely use WCET analysis to verify that tasks meet their timing 
deadlines.  These analysis results determine the system requirements and thereby impact the 
system design. Methods that reduce the WCET of an application are highly-desirable, therefore, 
because they can either increase the safety of real-time systems, or, alternatively, allow for 
systems with less-expensive or lower-power components.  Such methods for reducing an 
application’s WCET should not be confused with methods to reduce the WCET prediction of 
the analyzer.  In this section the WCET analyzer is assumed to be fixed. 
WCET-reducing methods can be grouped into three categories: 1) hardware methods, such as 
replacing the cache with an SPM [11], 2) programming-practice methods, such as choosing 
algorithms for their worst-case performance [12] and avoiding dynamic memory allocation [13], 
and 3) compiler methods.  As the focus of this proposal is the development of new compiler 
optimizations for reducing WCET, only this third category will be discussed here. We further 
divide these compiler methods into three categories: 1) methods that attempt to prevent 
compiler optimizations from increasing the WCET, 2) methods that propose new compiler 
optimizations targeted for reducing the WCET, and 3) SPM allocation strategies. 
PREVENTING COMPILER OPTIMIZATIONS FROM INCREASING THE WCET.  Most standard 
compiler optimizations have been developed for desktop computers, where ACET is more 
important than WCET. So it is not surprising that many of these optimizations can potentially 
increase the WCETact. [11, 14, 15] For example, consider code compression.  Since only a small 
portion of an application’s code accounts for most of its runtime (eg., heavily-nested inner 
loops), we and others have proposed a variety of methods to compress the non-critical portions 
of code. [16, 17]  Since most code is typically non-critical, large compressions are possible 
with only a small impact on the ACET.  The impact on the WCET may be greater, however, 
since the worst-case execution path will likely include additional portions of the compressed 
code.  The problem is not that code compression is harmful to real-time systems, but rather 
that current compressors target the ACET and should by modified to target the WCET. 
DEVELOPING NEW COMPILER METHODS SPECIFICALLY FOR IMPROVING THE WCET.  Only a 
few (mostly recent) papers have begun to consider how compiler optimizations can target 
ACETact WCETact 
WCETmeas ACETmeas WCETstat 
precision
 
time 
 6 
significant improvements in the ACET performance of programs using its allocation method, 
despite the need for the second stack pointer.  Because [26] employs an ILP formulation, 
however, it tends to have long compile times for large programs.  To address this concern, [26] 
also considers a greedy method for SPM allocation – still using a second stack pointer.  It is 
found that the greedy strategy produces results that are nearly as good, and which compile much 
faster. 
More recently, the Maryland research group has considered several dynamic SPM allocation 
strategies, where multiple live variables may use the same SPM address. [27, 28]  Despite their 
dynamic nature, these strategies are predictable because the compiler manages the SPM.  First, 
in [27], global variables, stack variables, and code segments are all dynamically allocated to SPM.  
Like a cache, all variables have a home address in DRAM and are only brought into the SRAM 
when needed.  Also like a cache, bringing a variable into SRAM may evict another variable 
that must be sent back to DRAM.  Unlike a cache, however, variables that are dead do not 
need to be copied back to memory.  Also unlike a cache, the compiler manages the SRAM 
contents by inserting instructions into the executable; these instructions perform the moving of 
data between SRAM and DRAM.  So, even though the location of a variable changes between 
DRAM and SRAM during execution, its memory location is well-defined at any point in the 
object code—making memory access times 100% predictable by the static analyzer.  [27] 
optimizes for the ACET, because variables are chosen for placement into the SPM based on 
their profiled frequency of use. 
3. OUR PROGRESS OVER THE PAST YEAR 
In this section, we will first describe the unexpected challenges that we met in the first year, and 
then we will describe what was accomplished. 
3.2 CHALLENGES AND SOLUTIONS 
CHALLENGE 1: FEWER STUDENTS THAN ANTICIPATED JOINED THE LABORATORY, INITIALLY.  
As a new faculty, the proposal was prepared before students had finished selecting advisors. The 
initial expectation was that perhaps 4 masters students would join the research group. But, in the 
end, only two did. In hindsight, this is not surprising, since the research laboratory was not yet 
open, and since the language barrier would discourage some students.  To make matters even 
more difficult, one of the two students changed research topics and advisors after one semester. 
These personnel difficulties certainly slowed the research progress. 
SOLUTION 1: BETTER ADVERTISING.  
With just one student, I took a direct role in programming with him, since there was too much 
work for one student. And, in spring and summer 2008, we were more aggressive in marketing 
the research laboratory, and 5 new students joined. So, the personnel problem has been 
resolved. Nonetheless, the new students have needed to be trained and only just finished taking 
the compiler course. So the research progress is expected to increase in the coming year, 
especially as more students will join this summer (one is already signed up). 
CHALLENGE 2: INFRASTRUCTURE PROBLEMS WITH THE UNIVERSITY OF MARYLAND 
INFRASTRUCTURE.  
As part of our collaboration with the SCAL lab at the University of Maryland, they have shared 
their SPM allocation infrastructure. As we have previously reported, we were able to 
successfully install this infrastructure, and to port it to the newest stable version of gcc. The 
problem has not been the SPM allocator codes, but the variable-usage profiling code. At the 
 8 
3.2 ACCOMPLISHMENTS 
Over the past year, we have implemented our first-cut SPM allocation algorithm. It is a novel 
algorithm, the first to permit non-escaping variables to copy into DRAM to increase the 
available SPM space, without requiring whole variables to be copied. An escaping variable is 
one for which as pointer is passed to the callee function. Thus, the callee function has direct 
access to the escaping variable (ie, it escapes the function in which it was declared.) By reverse 
logic, therefore, non-escaping variables cannot be accessed by callee functions. Figure 1 
clarifies the basic idea. 
It is also a novel SPM allocation strategy because it targets WCET allocation. WCET allocation 
is more complex than ACET allocation, because of three key differences. First, the static 
analyzer has information about infeasible paths that can permit a finer-grained concept of access 
frequency.  A variable’s access frequency may be dependent upon the specific CFP.  Second, 
the static analyzer has information about loop bounds and the depth of recursion that can bound 
the size of data structures and the stack, which can help determine whether variables fit in the 
SPM. Third, the compiler should not over-optimize the worst-case control flow path (CFP).  
Optimization can improve this path so much that it ceases to be the slowest path.  Once this 
happens, it should not be optimized further; optimizations should instead target the new 
worst-case path.  ACET-targeted methods do not have this problem.   
Figure 2 helps to clarify how a path can be over-optimized.  In Figure 2(a) we see a function.  
A quick analysis of the function reveals that only three execution sequences are possible, as 
illustrates in Figure 2(b-d).  Among these sequences, (d) is the longest. It follows that, if none 
of the variables are SPM, (d) will be the slowest.  Now, if there were space for 5 integers in the 
 
 
FIGURE 1.  An example of reusing the non-escaping stack space.  Time (a) corresponds to the beginning 
of program execution, where only global objects are allocated.  In this example, some of these global objects 
are placed in the SPM.  At time (b), the program is in the middle of executing, and some local objects have 
been created.  Some of these local objects have been assigned to the SPM.  Inside of the SPM, local variables 
are pushed onto one of two virtual stacks.  The upper stack is for escaping objects – those objects that are 
available to callee functions, via pointer references.  The lower stack is for non-escaping objects – those objects 
that can only be accessed within the function that they are local to.  At a later time (c), the program has reached 
a point where the SPM is nearly full.  Soon afterwards, at time (d), another function call is made.  This callee 
function has a new reachable stack object, “X”, that would benefit from SPM storage.  But the object is too 
large, so that it would cause the upper stack to grow into the lower stack.  But by copying the non-escaping 
stack to DRAM, the allocation becomes legal so long as the non-escaping stack is restored upon return to the 
caller. 
 
global objects 
(a) 
global objects 
escaping 
stack objects 
 
non-escaping 
stack objects 
(b) 
global objects 
escaping 
stack objects 
 
 
 
non-escaping 
stack objects 
(c) 
global objects 
escaping 
stack objects 
 
(d) 
New object X 
 
 10
● As for obtaining conference-publishable results, we are now targeting the Conference on 
Compilers, Architecture, and Synthesis for Embedded Systems (CASES), which has an 
early April deadline. This is several months behind schedule, due to the challenges listed 
above, particular the personnel problems. And yet, even if the research had progressed 
somewhat faster, we still would be submitting this spring, since the two premier 
conferences in this area, LCTES and CASES, both have spring-semester submission 
deadlines. 
Beyond these stated anticipated outcomes, we have several other accomplishments. We have 
obtained new students and new funding for the now-current year, to continue this research into 
two different directions: 1) development of an open-source SPM allocator with a gcc to SWEET 
converter tool, and 2) development of SPM allocation techniques for systems that also contain 
cache, targeting a soft real-time 3-D graphics processor. One student also expects to obtain a 
masters thesis on this work this spring.  
 
REFERENCES 
[1] R. Kirner and P. Puschner, “Classification of WCET Analysis Techniques”, in Proc. of the 8th IEEE International Symposium 
on Object-Oriented Real-Time Distributed Computing (ISORC), Seattle, Washington, USA, May 2005. 
[2] R. Kirner, I. Wenzel, B. Rieder, and P. Puschner, “Using Measurements as a complement to static worst-case execution time 
analysis”, Intelligent Systems at the Service of Mankind, vol. 2, December 2005.  
[3] R. Kirner, “Extending Optimising Compilation to Support Worst-Case Execution Time Analysis”, Ph.D. Thesis, Institut für 
Technische Informatik, Technischen Universität Wien, May 2003.  
[4] J. Engblom, A. Ermedahl, M. Sjödin, J. Gustafsson, and H. Hansson, “Worst-case execution time analysis for embedded 
real-time systems”, International Journal on Software Tools for Technology Transfer, volume 4, p 437-455, 2003. 
[5] Peter Puschner and Alan Burns, “A review of worst-case execution-time analysis”, Journal of Real-Time Systems, 
18(2/3):115–128, May 2000. 
[6] J. Wegener and M. Grochtmann, “Verifying Timing Constraints of Real-Time Systems by Mean of Evolutionary Testing”, 
Real-Time Systems, vol. 15, no. 3, p. 275-298, November 1998.  
[7] P. Atanassov, “Experimental assessment of worst-case program execution times”, PhD Thesis, Technischen Universität Wien. 
May 2003.  
[8] G. Bernat, A. Colin, S. M. Petters, “WCET analysis of probabilistic hard real-time systems”, in Proc. of the 23rd Real-Time 
Systems Symposium (RTSS), Austin, Texas. Dec 2002. 
[9] http://www.tidorum.fi/bound-t/ 
[10] J. Gustafsson, A. Ermedahl, C. Sandberg, and B. Lisper, “Automatic derivation of loop bounds and infeasible paths for 
WCET analysis using abstract execution”, in Proc. of the IEEE Real-Time Systems Symposium, Rio de Janeiro, Brazil, p. 57–66. 
December 2006. 
[11] L. Wehmeyer and P. Marwedel, “Influence of Onchip Scratchpad Memories on WCET Prediction”, in Proc. of the 4th 
International Workshop on Worst-Case Execution Time Analysis (WCET), Catania, Sicily, Italy, May 2004.  
[12] P. Puschner, “Algorithms for dependable hard real-time systems”, in Proc. of the 8th IEEE International Workshop on 
Object-Oriented Real-Time Dependable Systems (WORDS), Guadalajara, Mexico, p. 26-31. January 2003. 
[13] A. Coen-Porisini, G. Denaro, C. Ghezzi, and M. Pezzè, “Using symbolic execution for verifying safety critical systems”, in 
8th European Software Engineering Conference, Vienna, Austria, September 2001. 
[14] G. Bernat and N. Hosti, “Compiler support for WCET analysis: a wish list”, in Proc. of the 3rd International Workshop on 
WCET Analysis (WCET), Porto, Portugal, July 2003. 
[15] S. Marlowe. “Safe optimization for hard real-time programming”, in Special Session on Real-Time Programming, 2nd 
International Conference on Systems Integration, p. 438–446, Morristown, New Jersey. June 1992. 
 12
ATTACHED PUBLICATIONS 
In the past year, I was involved in one conference publication: 
 
Liang-Bi Chen, Tsung-Yu Ho, Ing-Jer Huang, Yun-Nan Chang, Steve W. Haga, Jin-Hua Hong, 
Shen-Fu Hsaio, Shiann-Rong Kuang, Ko-Chi Kuo, and Chung-Nan Lee, "The Development 
of an Energy-awared Mobile 3D Graphics SoC with Real-time Performance/Energy 
Monitoring and Control", Proceedings of the IEEE International SoC Design Conference 
(IEEE ISOCC'08), Busan, Korea, Vol. I, pp.234-237, Nov. 2008. (Invited Paper) 
 14
 
 16
 
 
But in soft real-time systems, engineers often use measurement to estimate the WCET, in 
a way that is not a guaranteed lower bound. Our discussions produced the concept that 
our SPM allocator can be used to reduce the chance of missed deadlines even in soft-real 
time systems. 
 We discussed the potential of adding WCET support into SCAL’s binary rewriting tools. 
We are implementing our work in gcc, and configuring it to work with the SWEET static 
WCET analyzer. But the SWEET analyzer is also designed to work with binaries. Thus, it 
is possible to improve the WCET of a binary, by rewriting its memory allocations. We are 
still considering the ways to achieve this at a more-reasonable cost. 
 We discussed methods for improving our collaboration. Included in this is the planned 
visiting of students in 2009. It also involved designing a more-effective agenda for our 
interactions. 
 
