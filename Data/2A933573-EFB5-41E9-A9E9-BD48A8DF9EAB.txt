i 
摘要 
在進入數位資訊的時代中，科技日新月異，數位電視，手機，Webcam 等多種 3C
產品中皆有影像播放功能，平面影像已經漸漸不符合大眾所需求。目前市場上需要多元
化的應用以及能為移動用戶帶來更多附加價值的服務，立體顯示便是其中之一。在一般
人的觀念中，3D 與立體影像是相同的東西，其實不然，3D 是擁有正確的深度值，立體
成像則是人們觀看具有立體感稱之為立體影像。立體影像並不需要絕對的深度值，只需
擁有相對的深度值即可。為了使立體顯示可大眾化，本計畫是從單張影像中尋找消失線
與消失點去估測深度，再利用原圖及深度圖計算左右雙眼影像給予立體顯示器使用。在
實驗結果部分雖說有些缺點，但是在估測深度方法上已提供了一個基礎的方法。從實驗
結果得知, 求出的深度圖已經可以大部分估測出相對的深度，而錯誤的部分是由於光
線、或者影像清晰度等問題所造成的影響。我們利用所做出的深度圖以及原圖去計算出
雙眼影像配合 3D 立體顯示器去顯示立體影像，所呈現的效果非常不錯，也間接證明了
我們所估測的深度圖有一定的準確性。計畫中我們亦設計了一個利用單眼影像所相對應
的影像深度地圖產生雙眼立體影像的硬體架構。我們使用 DIBR 的演算法來產生出雙眼
影像，再使用簡化的影像填補演算法填補產生的空洞。實驗中我們以 150MHz 的時脈效
能就可達到即時的運算(320 x 240 @30 fps)。整個設計所使用的邏輯暫存器(logic registers)
個數一共有 264,924 個邏輯暫存器。 
關鍵字：消失點，消失線，立體影像，深度圖，影像填補，深度為基礎之影像重繪。 
 
Abstract 
In entering the age of digit information, most of 3C products such as digit TV, the 
cell-phone, and cameras have built-in display function. Since the function of display is mainly 
applied on 2D image, it is unable to fulfill the user’s requirement at present. It needs 
pluralistic application and more additional value of service for the mobile subscriber on the 
market, e.g. the stereo image. In people's knowledge, 3D and stereo image are mis- 
recognized as the same things. In fact, 3D image has correct depth information and stereo 
image only has relative depth information. In order to make stereo image more popular, we 
focus on how to estimate depth information from single image in this project. We utilize 
original image and depth map to calculate the binocular image and use 3D LCD to display the 
stereo image. The concept of vanishing point is used to estimate the depth information. From 
the experimental results, the estimation of depth map is not perfect but it indeed offers the 
idea of depth estimation. Some defects of depth map estimation are due to the illumination 
and sharpness problems. By combining the depth map and 2D image to generate the binocular 
image and then display on a 3D LCD monitor, the stereo image appearance is satisfactory. 
This proves the feasibility of the proposed method. In order to achieve real time application, 
an image inpainting technique with its hardware design is also developed in this project. 
Keyword: Vanishing point, Vanishing line, Stereo image, Depth map, Image inpainting, 
DIBR (depth-image-based rendering). 
1 
1. 前言 
近年來，影像的品質、效果越來越讓人們注重，在科幻電影中通話以及許多有關影
像的播放皆以立體影像方式呈現，在現實的生活中我們還是生活在平面影像，人們便漸
漸的開始追求更立體的影像視覺。 
立體影像的應用十分廣泛，特別是應用在許多產業中例如航太工業、生物醫學、軍
事演習、地質探勘、環境探勘、建築行銷、汽車展示等。配合立體影像的環境能創造出
更加具有效果的服務，如醫學上醫生可藉由多方面的角度觀察病因以提供更好的醫療，
軍事演習上擁有立體的圖像可達到多方面考量，因此立體影像一定是未來的趨勢之一。
目前市面上的立體顯示必須有特殊的器材與特殊的資料才可以呈現立體影像的效果，因
此如何大眾化、便利化是本計畫的重點之一。 
立體成像的形成是利用人的視覺原理，人類的雙眼就像兩台照相機，各自拍攝形成
影像，成像落於視網膜中。視網膜就像照相機的底片，人的雙眼是高度相同且平行的。
雙眼距離相差約 6-10 公分，所以左右眼中的景色不太相同。從一張圖片來說，以左眼
而言，圖片最左邊某部分是右眼所沒有的，而右眼所看到的最右邊某部分是左眼所看不
到，這個部分稱之為視差[1]。左右雙眼中相同景色的部分也會因為雙眼的距離差異而在
左右眼中的成像位置也不同，人們的大腦中便是利用這些差異讓我們所看到的景色成為
立體影像。目前在市場上許多立體顯示器是利用以上所敘述的原理所製造出來的，因此
資料的輸入部分至少需要 2 張不同的圖片再藉由硬體的特殊設計所去呈現出立體影像。 
擁有立體顯示功能的產品目前有很多種，最早的技術為紅藍眼鏡。現階段在市面上
最常見的立體顯示器是以兩台的單槍配合特殊的立體轉換器，並且需要兩台攝影器材在
固定的角度及距離下拍攝才可以顯示，而觀看者必須配戴特殊的立體眼鏡才可觀看到立
體影像。在幾年前如 DTI、SHARP 等大公司已經成功研發出裸眼觀看立體影像的液晶
螢幕，其原理如圖一所示，在液晶面版前面加上光柵（遮光棒），讓左眼只能看到左眼
影像，右眼只能看到右眼影像，配合眼睛的視差讓大腦產生立體影像。 
 
 
 
圖 1-1 為裸眼立體顯示器設計原理 
          
3 
3. 文獻探討 
立體成像的原理主要分成主動式與被動式兩種： 
主動式：透光切換眼鏡（shutter glasses）是以兩片 LCD 膜片來製作，利用 LCD 通電與
否能產生膜片透光與否的特性，並且讓眼鏡與影片播映端都以高速交替切換左右畫面的
方式，同步放映（同步訊號校準利用有線或紅外線感應無線方式），即當螢幕播映左眼
畫面時剛好讓眼鏡的左眼透光，反之播映右眼畫面時剛好眼鏡的右眼透光；如此利用視
覺殘留讓左右眼看到不同的畫面而產生立體感。 
被動式：主要運用偏極光濾片將投影之光束分成水平或垂直兩種方向，將兩種角度不同
的濾片分別裝在兩台投影機的鏡頭前，配合以兩片偏極光膜片製作的偏光眼鏡；而只讓
水平偏極光的那一眼看到水平偏極光那一台投影出的畫面，讓垂直偏極光那一眼看到垂
直偏極光那一台投影出的畫面，再運用視差方式而產生立體影像。 
估測深度的方法可以分很多種，目前研究主要可分為三種： 
1.以多張的圖片去估測深度 
2.以動態影像估測 
3.取得相機參數 
當我們得到這些深度的資訊後，就可利用深度資訊來做各種的應用，例如虛擬雙眼
立體影像、建立 3D 立體模組….等。而一個深度地圖的表示方式如圖 3-1 所示。 
              
圖 3-1 影像深度地圖表示圖，一張影像中物體的遠近關係，我們可以用灰階值的大小來
表示，當物體離觀看人越近，則灰接值越大，反之則越小 
3.1 以多張的圖片去估測深度 
在 2D 影像中關於深度資訊是非常少的，若可獲得稍有差異的圖片便可從中估測深
度，因此有人利用視角相同和焦距不同拍攝影像從中估測深度值。在[2]、[3]、[4]、[6]
這些論文中即是用相同角度及不同焦距所拍攝的圖片去估測深度。[2]是利用清晰與模糊
兩張影像中邊緣的粗細與輪廓鮮明度並且取得焦距來估測深度值。我們可以知道當焦距
不同時在每點的 Pixel 的清晰度就不一樣，尤其時物體邊緣的部分，若可以得知焦距那
麼每點的清晰度的變化便可配合焦距去計算出來，再配合物體邊緣的清晰度便可以判斷
每區塊的深度相對值。[3]是使用模糊理論（Fuzzy Logic），而[4]論文中是使用拓樸，[3][4]
          
5 
當物體在兩個攝影機的焦點上時，物體會失去立體的效果；當兩個攝影機焦距的距離與
播放距離的比例如果沒有設定好，會造成影像物體比實際物體大或小的結果。而 Toe-in
攝影機設定的示意圖如圖 3-2 所示。 
 
圖 3-2 Toe-in 法之虛擬攝影機設定，鏡頭向內拍攝物體 
 
Off-axis ： 
兩個攝影機有相同固定與對稱的孔徑，鏡頭以平行的方式設置。而 Off-axis 攝影機
設定的示意圖如圖 3-3 所示。 
 
圖 3-3 Off-axis 法之虛擬攝影機設定，鏡頭平行拍攝物體 
 
 當我們選定好立體攝影機的模型後，就可以用 DIBR 來產生出虛擬的立體影像了。
DIBR (depth-image-based rendering)[12~13]是以原始影像所相對應的影像深度地圖為基
          
7 
3.4.2 影像填補 
當我們產生出虛擬的立體影像後，所衍生的空洞問題必須用影像填補將空洞都填補
起來，成為一個完整的虛擬立體影像，而影像填補演算法[14~20]基本的概念為從空洞區
域周圍尋找填補方塊並將它們的內容複製至空洞區域。在圖 3-5(a)中，Ω為目標區域，
也就是空洞區域；δΩ為目標區的輪廓；Φ為來源區域。在圖 3-5(b)中，我們要合成由
中心點為 p 的填補方塊 p 所包含的區域，在圖 3-5 (c)中，最相像的的填補方塊很可能
出現在兩塊不同顏色或紋路的邊界上，如 p  與 p  。圖 3-5 (d) 為找到最相似填補方塊
後，將其相對位置的像素複製至 p 中。 
     
(a)                        (b) 
     
(c)                          (d) 
圖3-5 填補演算法示意圖 (a) 原始影像 (b) 目的填補區塊(c) 
搜尋來源填補區塊 (d) 填補後的結果 
 
步驟 1: 計算優先權     ppP ，以找出目標區域的輪廓上各像素優先填補順
序。 
步驟 2: 找出來源填補方塊 q 且擁有  qpd  , 最小值，將其影像資料從 q
複製至
p 。 
          
9 
 
3.4.3 相關硬體設計 
 Hong-Ming Wang 提出了一個對於不同紋理背景以子區塊紋理合成與加權內差法來
填補移除的區域[21]。子區塊紋理合成可一次填補一排的目標填補區域，而加權內差法
可將區塊平滑化。並且分析整個演算法的效能，來設計填補搜尋的積體電路，將其以
pipeline 的方法讀入欲計算的像素，來提升搜尋時的計算速度。整體搜尋的時間如下 
     lclkhNnumberCycle  15                          (3-7) 
其中的 5 是因為一個計算必須經過五個時脈週期，N 是代表所要比對的點數，h*k 為影
像的大小，l*c 為空洞的大小，l 為空洞的行數。其 pipeline 架構的設計方式如下圖 3-7
所示。 
 
圖 3-7 搜尋區塊的 pipeline 結構圖[21] 
 
 Wan-Yu Chen 提出了一個即時 DIBR 的硬體架構[22~23]，首先會對影像深度地圖
做 Edge-dependent gaussian filter，讓深度的變化比較連續，來減少空洞的數量。由於使
用 Edge-dependent gaussian filter 而讓計算量上升，為了提升運算速度，所以以 pipeline
的方式來設計 Edge-dependent gaussian filter 的計算，以提升計算速度，使整個設計符合
ATTEST(720 x 576 @25fps)的標準，並且以一個 80MHz 的時脈效能就可以達到即時的運
算。而其中所使用的影像填補方式，是以空洞旁的像素來向內填補的一個簡單的方式來
做填補。其硬體架構圖如下圖 3-8 所示。 
          
11 
在圖三中除了地平線之外還有另外六條線，這六條線互相交錯且與地平線交錯於一點，
而且是在地平線上，這些線就是延伸所有平行於地平面的線，這裡面包括了任何有直線
邊緣，稜角，形狀的東西，像是樓房、牆、畫框、鐵道、家具、地面、人、車等等許多
東西。由這些所構成的線都會與平行線交錯且會交於同一點上，圖 4-2 中的這六條線是
由下列三對線條;1.延伸虛擬的天花板／牆面交界之線，2.畫框頂緣 3.牆面／地面交界之
線所構成，且又與平行線交錯於同一點上，因此交錯的點稱為消失點，此點為圖片中最
遠的一點。 
圖 4-2 是虛擬的室內示意圖[7]，在敘述若不考慮物體大小時，假設物體大小一樣時，
越近觀看者，觀看者所看到的物體則越大，反之則越小。圖中所畫的線是消失線，雖說
實際上我們可尋找的到的，可是無法像圖中這麼準確。 
 
 
圖 4-1，繪圖中主軸線與消失線示意圖 
 
 
 
圖 4-2，室內消失線與消失點示意圖 
 
          
13 
中也可能在圖之外。一般來說知道消失點後可以大概確定整張圖的深度走向，若消失點
在圖片的右方那麼可以大概得知圖的左邊比較近圖的右邊比較遠，深度的走向由左向右
漸遠，因此我們可以依照消失點的方向做出深度漸層圖。我們將深度漸層圖以灰階圖來
表示，越白表示越近越黑表示越遠。若灰階值為 256 階，且消失點在圖右邊，則圖中最
右邊的灰階值為 0 向左遞增，每向左移動一個 Pixel 點則增加 255/Width，其中 255 為灰
階最大值，Width 為圖片的寬度，所以漸層圖會成為長條狀的漸層圖。圖 4-4 是由本方
法所估測出的深度漸層圖及與參考文獻[7]之比較。 
 
(a) 
 
(b) 
 
(c) 
圖 4-4 (a)參考文獻(7)測試圖片 (b)採用本計畫方法所做出的深度漸層圖 (c) 採用參考文
獻(7)所做出的深度漸層圖 
          
15 
第六步是做 7x7 大小的平滑化(Smoothing) 
在某些點因為亮度的因素使得之前所進行的區塊判斷錯誤，給予錯誤的深度值。為
了減少這部分的錯誤因此做平滑化。平滑化可以使區塊內的深度值均化，使得給予錯誤
深度值的點可以減少誤差值，而有正確深度的點不會因為平滑化後而錯誤。 
 
4.6 硬體設計及架構 
 
4.6.1 整體架構 
整個系統簡單的架構是利用深度地圖由原始影像產生雙眼立體影像，接著再各自做
影像的填補，填補完畢後將雙眼立體影輸出。系統架構圖如圖 4-5 所示。 
 
圖 4-5 系統架構圖 
我們整個系統的流程是，首先利用 DIBR 的方法產生出雙眼立體影像，接著利用 3 x 3
的 mask 來填補因為深度連續變化時所產生的細小空洞區域，填補完細小的空洞區域
後，再計算影像的梯度方向，以便接下來的影像填補法來使用，接著再搜尋空洞邊緣的
參考點，找到邊緣參考點後再以邊緣參考點為顏色基礎，以方向性搜尋顏色最接近的填
補參考點，再以填補參考點的方向性的點做為填補的點填補回邊緣點旁的空洞內，重覆
搜尋與填補的動作直到沒有空洞為止，最後將填補完畢的影像輸出，流程圖如圖 4-6 所
示。我們會在接下來的小節內分別介紹每個步驟的電路設計方式與電路動作流程。 
          
17 
Left  ： 


 
Z
ft
Z
ftu c
c
c
22
      Right ： 


 
Z
ft
Z
ftu c
c
c
22       (4-3) 
我們以方程式(4-3)來設計 3D 影像位移產生器(圖 4-7 中的 3D image warping)的功能。此
區塊電路動作的流程是將位址產生器(圖 4-7 中的 Address Generator)所產生的位址輸入
給 3D 影像位移產生器， 3D 影像位移產生器將所輸入的位址加上計算的位移量，接著
將輸入的像素儲存到對應的記憶體位址內。此區塊電路如圖 4-7 所示。 
 
CLK Addr_R_out
Addr_C_out
Clock_in
RGB_data_in
Depth_data_in
Camera_separation_data_in
Focal_length_data_in
inCLK
outCLK
inAddr_R
outAddr_R
DATA_in
we
DATA_out
outAddr_C
inAddr_C
inCLK
outCLK
inAddr_R
outAddr_R
DATA_in
we
DATA_out
outAddr_C
inAddr_C
CLK
RGB_in
Zc
tx
hRGB_out
Addr_R_out_l
Addr_R_out_r
Addr_C_out
We_l
over
f
Addr_R_in
Addr_C_in
We_r
9
3
8
8
8
24
25
3
9
9
9
3
9
3
Address Generator
3D image warping
Right Memory
Left Memory
25
25
 
圖 4-7 立體影像產生區塊電路圖 
 
          
19 
5.2.2 影像填補 
我們以六種不同背景類型的影像做結果的分析，分為人工背景影像、天空背景影
像、棋盤事背景影像、前景物件互相遮蓋影像、室內照片影像、以及戶外自然風景。 
 
人工背景的影像 
 來源影像為保齡球及保齡球瓶放置於木製球道上，球道上各木片的顏色及紋路皆不同。
我們可以看到填補結果的顏色與紋路大致都是正確的，但是邊園的木板紋理會有一點偏移的
狀況，這是由於我們將填補演算法化簡的關係。 
 
     
(a)                                         (b) 
     
(c)                                         (d) 
          
21 
天空背景的影像 
 我們選擇了一個生物飛行於天空中的影像，背景是屬於自然不規則的影像。我們可
以明顯的看出背景的填補較人工背景好，這是因為背景是屬於不規則的背景，所以填補
優先順序的影響較小。我們可以看到翅膀附近以及兩腳中間處有些地方填補不完美，這
是因為翅膀附近的前景區域非常的窄造成這種填補錯誤的現象，以及兩腳中間區域的背
景參考點太少，以至於填補錯誤。 
 
      
(a)                                     (b) 
     
(c) (d) 
 
          
23 
棋盤式背景的影像 
 我們選擇了棋盤背景的影像，棋盤影像是由深色及淺色的方塊所組成。我們可以看
出填補還是有偏移的情形。 
 
     
(a)                                     (b) 
     
(c) (d) 
 
 
 
 
          
25 
前景物件相互遮蓋的影像 
 我們選擇了一個有蘋果和柳橙重疊的影像，蘋果旁的空洞區域包含了背景及柳橙。
我們可以看出紋裡還是有一點點的偏移，以及柳橙的結果沒有那麼圓，但基本上顏色都
是正確的。 
 
     
(a)                                     (b) 
     
(c) (d) 
 
 
 
          
27 
室內照片的影像 
 我們以一個實際拍攝的室內照片為實驗影像。我們可以看出只有邊緣的填補結果有一點
偏移，但整體的效果是很好的。 
     
(a)                                     (b) 
     
(c) (d) 
 
 
 
 
 
          
29 
戶外自然風景照片的影像 
我們以一個戶外自然風景照片為實驗影像。我們可以看出只有邊緣的填補結果有一點偏
移，尤其是欄杆的部分特別明顯，但整體的效果是很好的。 
     
(a)                                     (b) 
     
(c) (d) 
 
 
 
 
 
          
31 
5.3 結論與建議 
在本計畫所做的主體是以單張照片為主。以單張的2D影像來說可獲得相關的深度資
訊是非常稀少的，而只能從單張圖片中搜尋有關深度的資訊來估測相對的深度值。在本
計畫中所做的只是初步去估測單張圖片的深度值，尚有許多地方待改進。 
例如本計畫所估測的深度圖是在相同物件中給予相同深度值。而基本上物體有輪廓以及
背景拍攝有角度時應是一邊較近而另一邊則較遠，而本計畫中都是給予相同的深度值。
另環境因素會影響到判斷，以及物體的陰影所造成的判斷錯誤等地方仍需加以改善。大
多估測深度的研究都是以獲得不同照片或獲取相機等設定的參數去進行研究，因此本計
畫的重點是在於如何從單張影像中估測其深度值。 
所以所估測的深度圖只是初步的結果，而在實驗結果部分配合本實驗室另一位學長
的研究中利用原圖以及深度圖做出的雙眼影像配合立體顯示器(Sharp 的)所呈現的立體
影像效果非常好。當然還是有許多缺點得改進，而主要改善的地方我們大概可以分為幾
點。第一判斷區塊的正確性應予提高，我們所做的實驗室皆以單純的背景做實驗，因此
在背景複雜時估測錯誤便會增加許多，這是因為在區塊判斷上面判斷錯誤，因此區塊判
斷的正確性可以提高深度的準確性。第二必須去除陰影，物體在光線照射下一定會有陰
影的部分，而在陰影的部分中會誤認為是不同的區塊，因此去除陰影是其中一項可以改
進的工作。第三本計畫中給予同一物件或區塊是相同的深度值，因此在判斷上面得能分
辨物體上是同一平面或是有深淺應給予不同的深度值，以及背景是平面或是斜面。這部
分可用清晰度、銳利度等方法來加以改進。第四點是在於環境的許多因素，如最常見的
光線照射以及亮度等問題，這部分影響最大，因此未來最主要的工作也在於此。第五照
片中清晰與模糊的部分判斷。在照片中清晰的地方大多為主體部分，而背景大多為模糊
部分，因此在模糊部分的判斷上面就更加困難。而清晰的部分又得區分其深淺。 
以上五點是大略總結歸於本計畫未來必須改進的地方度的領域。立體影像是未來的
趨勢，因此如何利用大眾中多數擁有的單眼拍攝器材去估測深度必定是未來主要研究的
課題之一。由於立體影像的產生使人們之間不但可從聲音獲得對方的訊息更可藉由立體
影像增進與對方的互動，而科幻電影中不再是科幻而是實際的生活了。 
          
33 
[13] C. Fehn. “A 3D-TV Approach Using Depth-Image-Based Rendering (DIBR)” In 
Proceedings of 3rd IASTED Conference on Visualization, Imaging, and Image 
Processing , pp. 482-487, Benalmádena, Spain, Sep. 2003. 
[14] Marcelo Bertalmio, Guillermo Sapiro, Vincent Caselles, Coloma Ballester, “Image inpainting”, 
International Conference on Computer Graphics and Interactive Techniques, 
Proceedings of the 27th annual conference on Computer graphics and interactive 
techniques, Pages: 417- 424, 2000. 
[15] Bertalmio, M., Bertozzi, A.L., Sapiro, G., “Navier-stokes, fluid dynamics, and image 
and video inpainting”, Computer Vision and Pattern Recognition, 2001. CVPR 2001. 
Proceedings of the 2001 IEEE Computer Society Conference, Volume 1, page(s): I-355- 
I-362 vol.1, 2001. 
[16] Bertalmio, M., Vese, L., Sapiro, G., Osher, S., “Simultaneous structure and texture image 
inpainting”, Image Processing, IEEE Transactions, Volume 12, Issue 8, page(s): 882- 889, 
Aug. 2003. 
[17] Antonio Criminisi, Patrick Pérez, and Kentaro Toyama, “Region filling and object removal 
by exemplar-based image inpainting”, Image Processing, IEEE Transactions on, 
Volume 13,  Issue 9, page(s): 1200-1212, Sept. 2004. 
[18] BianRu Li, Yue Qi, XuKun Shen, “An image inpainting method”, Computer Aided 
Design and Computer Graphics, 2005. Ninth International Conference, page(s): 6 pp.-, 
7-10 Dec. 2005. 
[19] Shantanu D. Rane, Guillermo Sapiro, and Marcelo Bertalmio , “Structure and Texture 
Filling-In of Missing Structure and Texture Filling-In of Missing Compression 
Applications”, Image Processing, IEEE Transactions on Volume 12,  Issue 3, page(s): 
296- 303, March 2003. 
[20] Tauber, Z., Ze-Nian Li, Drew, M.S., “Review and Preview: Disocclusion by Inpainting 
for Image-Based Rendering”, Systems, Man, and Cybernetics, Part C: Applications and 
Reviews, IEEE Transactions, Volume 37, Issue 4, page(s): 527-540, July 2007. 
[21] Hong-Ming Wang, Jhing-Fa Wang, “Object Removal AlgorithmHardware in Image 
Processing”, 國立成功大學 電機工程學系碩士論文 2004. 
[22] Wan-Yu Chen, Yu-Lin Chang, Shyh-Feng Lin, Li-Fu Ding, and Liang-Gee Chen, 
“Efficient Depth Image Based Rendering with Edge Dependent Depth Filter and 
Interpolation”, Multimedia and Expo ,2005.ICME 2005, IEEE International Conference 
on July 2005 
[23] Wan-Yu Chen, Yu-Lin Chang, Hsu-Kuang Chiu, Shao-Yi Chien, and Liang-Gee Chen, 
          
35 
可供推廣之研發成果資料表 
■可申請專利  ■ 可技術移轉                                     日期：98 年 8 月 25 日 
國科會補助計畫 
計畫名稱：三維立體深度估測技術開發及其晶片設計 
計畫主持人：鄭芳炫       
計畫編號：NSC 96-2221-E-216-039-MY2  學門領域：資訊工程
技術/創作名稱 1. 二維影像深度估測技術 2. 影像填補技術及其硬體設計 
發明人/創作人 鄭芳炫 
中文： 
1. 本研究是從單張影像中尋找消失線與消失點去估測深度，再利
用原圖及深度圖計算左右雙眼影像給予立體顯示器使用。 
2. 左右雙眼影像所產生之影像空洞填補技術及其硬體架構之晶片
設計 
技術說明 英文： 
1. In order to make stereo image more popular, we focus on how to 
estimate depth information from single image in this project. We 
utilize original image and depth map to calculate the binocular 
image and use 3D LCD to display the stereo image. The concept of 
vanishing point is used to estimate the depth information. 
2. An image inpainting technique with its hardware architecture and 
chip design is developed to achieve real time application.. 
可利用之產業 
及 
可開發之產品 
光電產業, 顯示器產業, 電視產業 
立體數位相框, 三維立體顯示器, 三維立體電視 
技術特點 
1. 利用所做出的深度圖以及原圖去計算出雙眼影像配合 3D 立體
顯示器去顯示立體影像 
2. 利用硬體設計達到即時左右雙眼影像空洞填補以完成真實 3D
立體影像顯示 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          98 年  5 月 27  日 
報告人姓名 鄭芳炫 服務機構
及職稱 
中華大學資工系教授 
 時間 
會議地點 
2009/5/19~2009/5/23 
日本橫濱 慶應大學 
本會核定
補助文號
NSC96-2221-E-216-039-MY2 
會議 
名稱 
 (中文) 2009 年國際圖形識別聯盟機器視覺應用研討會 
 (英文) 2009 IAPR Conference on Machine Vision Applications 
發表 
論文 
題目 
 (中文) 針對新一代視訊編碼的畫框間模式決定演算法 
 (英文) Inter Mode Decision Algorithm For Advanced Video Coding 
一、參加會議經過 
會議的開幕典禮由主辦單位與會議的委員會主席簡單的致歡迎詞後，隨即展開。由於本
會議為一個專業之研討會, 為了讓與會之學者專家不會錯過任何一個場次之研討, 會議
只安排一個場地進行。本屆會議由於受到新流感的影響參加人數比上屆少, 共有 144 篇
論文投稿, 經過嚴格的審查後, 最後通過 122 篇論文, 其中 39 篇安排口頭報告(oral), 而
83 篇為海報展示(poster)。大會安排了三天的會議議程, 共分為十五個 section, 其中安排
了三個場次之專題報告: (1) Large Scale Image Search (2) Focal Stack Photography: 
High-Performance Photography with a Conventional Camera (3) Integration of Earth 
Observation Data: Challenge of GEOSS (Global Earth Observation System of Systerms)，分
別由 Dr. Cordelia Schmid, INRIA, France，Prof. Kyros Kutulakos, University of Toronto, 
Canada 以及 Prof. Ryosuke Shibasaki, The University of Tokyo, Japan 做精彩的專題報告。
本人之論文『Inter Mode Decision Algorithm For Advanced Video Coding』被安排在第一天
的下午 section 3 之場次以海報的方式發表, 如下圖所示。本次會議尚有台灣之其他論文
發表, 也大都是以海報的方式發表。經過三天完整會議研討,與會者均有豐富的收穫。 
 
 
 
附件三
 
Inter Mode Decision Algorithm For Advanced Video Coding
Fang-Hsuan Cheng
Department of Computer Science & Information
Engineering, Chunag Hua University
Hsinchu, Taiwan 300
fhcheng@chu.edu.tw
Yea-Shuan Huang
Department of Computer Science & Information
Engineering, Chunag Hua University
Hsinchu, Taiwan 300
Abstract
Variable block size used for inter coding is one of the key
technologies in H.264/AVC. When different objects contained
in the same macroblock have different motions, smaller block
sizes probably achieve better predictions. However, this
feature results in extremely high computational complexity
when all the block sizes are considered to decide a best one.
This paper proposes a new inter mode decision algorithm to
reduce the number of inter modes that has to be checked, and
then encoding time is reduced. We use the co-located
macroblock in previous frame and its neighbors as
candidates, and check whether an edge of moving object is
crossing the middle of these candidates by using the score
given to the modes. The experimental results show that the
proposed algorithm is able to reduce 31%-41% total
encoding time and about 41%-54% motion estimation time
with a negligible PSNR loss of 0.05 dB and bit-rate increment
of 2% on the average.
Keyword:Variable Block Size; Motion Estimation; Mode
Decision
1. Introduction
Video Compression plays an important role in digital video
communication, transmission and storage. H.264/AVC [1-4] is
the latest video coding standard developed by the JVT (Joint
Video Team) of ISO/IEC Moving Picture Experts Group
(MPEG) and ITU-T Video Coding Expert Group (VCEG).
While the H.264 belongs to H.26L family of VCEG and the
AVC (Advanced Video Coding) belongs to MPEG-4 part 10.
This standard has been designed in order to provide higher
coding efficiency and network adaptation, which includes a
Video Coding Layer (VLC) and a Network Abstraction Layer
(NAL). While the VCL represents the video content, and the
NAL provides a network-friendly interface.
Comparing to the previous video coding standards,
H.264/AVC achieves significant improvement in coding
efficiency. This is due to the fact that a number of new
techniques are adopted in this standard such as variable block
size (VBS) motion estimation, multiple reference frames,
quarter-pixel motion estimation, directional prediction of intra
coded blocks, in-loop deblocking filter, integer DCT
transform and context-based adaptive binary arithmetic coding
(CABAC) etc.. As a result, H.264 can save over half bitrate
compared with that of MPEG-2 under the same quality.
Motion estimation (ME) is used as a main method for
removing the redundantly information between frames in
many video coding standards. H.264, like other video
encoders, adopts block-based motion estimation to find a best
block matching from a pre-defined search area, and performs
variable block size motion estimation to indicate individual
motion object in a macroblock. Figure 1 shows the seven
block sizes and corresponding mode number/symbol in H.264.
We can divide these seven block sizes into two levels which
are macroblock level and sub-macroblock level. In
macroblock level, there are four inter modes and an additional
skip mode (mode 0) which uses the same size with mode 1. If
the macroblock is processed in sub-macroblock level, it can be
further partitioned into 8x8, 8x4, 4x8 and 4x4 block sizes. The
same works will be done in the four sub-macroblocks, and the
order of process is from left to right and top to bottom even in
mode 2 or 3.
Figure 1. Variable block sizes and corresponding mode
number.
According to the new technique described above,
H.264/AVC achieves higher coding efficiency than prior
video coding standards. However, the large amount of
computation makes the encode time extremely increase, thus,
it is difficult to be used in practical applications especially in
real-time environment. It can be seen that inter modes still
take the biggest part of computation. For the reason, we
propose a new inter mode decision algorithm to reduce the
encoding time with negligible loss of coding efficiency.
The rest of this paper is organized as follows. Section 2
introduces some related works of inter mode decision in
H.264. The proposed new inter mode decision algorithm is
described in Section 3. The experimental results are shown in
Section 4. And a conclusion will be given in Section 5.
MVA2009 IAPR Conference on Machine Vision Applications, May 20-22, 2009, Yokohama, JAPAN3-7
54
mode and the large ones are 16x16, 16x8 and 8x16. The latter
is used to divide the 16x16 mode from the three ones. The
algorithm is shown below:
According to experimental results, the upper value is set to
8 and the lower value is set to 2 will obtain the best
performance. It means that there must be more than two P8x8
macroblock in the MB set which has the maximum
center_value, and there must be at most one 16x16
macroblock in the MB set respectively.
Here we discuss all the possible combinations of the three
neighbors that belong to the same MB set. If the center_value
is greater than upper_thd, there are three situations which are
9, 10 and 12. Note that the value of center_value is impossible
to be 11 under this score of modes. When 9, there must be two
P8x8 (or Intra) macroblocks and one 16x16 macroblock.
When 10, there must be two P8x8 (or Intra) and one 16x8 or
8x16, because the scores of mode 2 or mode 3 are the same.
When 12, there must be three P8x8 (or Intra). On the other
hand, if the center_value is smaller than lower_thd, there are
two situations which are 0 and 1. When 0, it means that all the
three neighbors must be skip mode. When 1, only one 16x16
macroblock in the MB set is allowed.
4. Experimental Results
The proposed mode decision method is implemented in
H.264 reference software JM12.2 [16]. We select seven QCIF
sequences which are commonly used for video compression
testing in our experiments. The form of QCIF is 176 pixels in
width and 144 pixels in height, that is, there are eleven
macroblocks in width and nine macroblocks in height, and
totally ninety nine macroblocks contained in one frame. The
first 100 frames of every sequence are tested by our method.
The GOP (Group of Picture) structure is IPPP, i.e. the first
picture is coded as I-picture and remaining pictures are coded
as P-pictures. The Full Search algorithm is used in all
experiments with a ±16 pixels search window.
Firstly, total encoding time and total motion estimation time
derived from the JM reference software for each sequence are
listed in Table II. The total encoding time is counted all the
needed time from the first frame to the last one for encoding,
and the total motion estimation time is just only counted the
time performing motion search in P-frame. The main
difference of them is the time performing the reconstruction of
macroblock for mode decision which includes inter modes and
intra modes. From the table, we can observe that the time of
motion estimation is about 50%-60% of total encoding time
and not the 80% as we known in the prior standard. This may
be caused by the amount of intra modes in H.264 and the
improvement of Full Search.
In the second experiment, we inspect the PSNR change, bit
rate change in percentage and time change in percentage. The
experimental results are shown in Table III. The positive
values mean increments whereas negative values mean
decrements. In the time change, we list both total encoding
time and motion estimation time. For the comparison, we also
implement the Wus method [6] and list the results in Table III.
These changes are calculated by the following equations.
%100(%)
%100(%)
)(







reference
referenceproposed
reference
referenceproposed
referenceproposed
Time
TimeTime
Time
Bitrate
BitrateBitrate
Bitrate
PSNRPSNRdBPSNR
	
Table 2. Total Encoding Time and ME Time
Time
Sequences
Total Encoding Time
(sec)
Total ME Time
(sec)
Akiyo 127.686 52.030
Coastguard 207.802 119.152
Container 153.245 76.112
Foreman 169.844 89.693
M & D 138.190 64.234
Silent 153.073 73.527
Suzie 156.942 86.407
We can observe that the time saving of total encoding time
in our proposed method exceeds 30% in all sequences with
negligible quality loss and bit rate increase. The increase of
bit rate in Akiyo is a little high because the motion of this
sequence is too small. In fact, at the beginning of this
Table 3. Changes of PSNR, Bitrate and Time
Wus Proposed
sequences 
(dB)
Bitrate
(%)
Total Encoding
Time (%)
ME
Time(%)
PSNR
(dB)
Bitrate
(%)
Total Encoding
Time (%)
ME
Time(%)
Akiyo -0.02 0.71 -24.73 -32.80 -0.07 2.17 -36.22 -49.81
Coastguard -0.02 1.28 -26.82 -36.01 -0.03 1.13 -33.59 -44.57
Container -0.01 1.44 -20.69 -21.09 -0.05 1.46 -41.36 -54.14
Foreman -0.09 2.14 -27.13 -33.31 -0.08 2.84 -31.39 -41.32
M & D -0.08 0.75 -37.90 -48.35 -0.08 0.46 -36.41 -47.30
Silent -0.06 2.46 -26.36 -37.23 -0.04 4.14 -36.53 -50.82
Suzie -0.04 2.18 -35.89 -47.37 -0.01 2.75 -33.71 -43.87
if center_value > upper_thd
disable mode 1, 2 and 3
else if center_value < lower_thd
disable mode 2, 3 and P8x8
else
disable mode P8x8
56
