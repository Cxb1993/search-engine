 II
摘要 
本計畫主要針對學童在家自主學習時候，學習狀態的監督機制研究，由於社會發展，
許多父母無法陪同學童進行課後學習活動，卻又擔心學童自己學習時，自制能力較差，學
習效果不如預期，因此本研究透過網際網路，利用 Webcam 擷取影像，運用影像偵測方式，
建立學童在家自主遠距學習自動監護系統，為遠距學習系統機制之發展提供新的思維方
向。利用分散式的偵測機制及網路傳遞功能，在學童電腦端建置偵測機制，並將偵測結果
傳回系統伺服器，建構一個具備「自主學習狀態自動監護服務」的遠距學習介面，記錄學
童的學習行為，進而提供父母或老師查詢功能，以準確掌握學童在家學習狀況。本計畫主
要針對學習狀態偵測的偵測機制、學習行為評估方式和記錄整合性系統，克服學童在家自
主學習的自我約束問題，提供良好的學童在家學習照護服務。 
關鍵詞: 模糊邏輯、學習專注分析、影像偵測 
 
Abstract 
Because of the development of society, many parents can not always keep abreast with 
children, and do the learning activities. But they are afraid of the uncontrolled children and 
ineffective learning. The research will propose a new direction for distance learning system, to 
construct an "Auto Detection and Monitor Mechanism" for children self-learning at home by 
utilizing Internet, Webcam and Image Detection. 
To be the distance learning interface with Auto Detection and Monitor Service Mechanism, a 
distributed detection interface will be built on children computer, and then the detected results 
will be delivered to system server. The server can record the learning behavior of children, and 
provide searching function for parents and teachers to get children learning situation. This project 
focuses on the design of a complete system with detection mechanism, behavior evaluating 
method and recording. It will solve the issue about the problems of self-discipline of children 
when they are self-learning at home, and provide good learning care service. 
Keyword: Fuzzy logic, Learning attending analysis, Image detection 
 2
3. Relate Work 
3.1 遠距教學的互動及觀察 
有學者開始針對遠距學習學生的學習態度進行分析，尤其在評估遠距教學的各種成效時，學生的學習行為
列為評估的重點之一。互動及觀察紀錄是達到情意領域教學目標的重要關鍵，因此也有許多遠距教學的相關
研究，開始將學生遠距學習狀態的互動性列為評估的重點之一，評估學生學習滿意度時，互動性是影響滿意
度一個重要因素，並且針對互動性，特別進行深入探討，或者在類似 BBS 的學習環境中，分析學生的互動[12]。 
評估學生的學習行為時，許多學者則利用遠距教學中，互動及觀察記錄進行研究，透過互動的次數紀錄，
評估學生課堂參與的情況[9]。所以有許多學者探討透過討論的教學課程，提高遠距學習的參與情況，透過各
種討論方式或討論工具，增加遠距教學的互動，並且在研究中提出，增加互動的工具和方法[13]。或者讓老
師在課程互動過程中，使用鼓勵及增強的方式，例如在 Web-based learning 中，經由老師的增強鼓勵或者督促，
可以提高學生參與課程的意願[14, 15]，並且對學生學習行為有更強的影響[16]，透過互動的控制方式，改變
學生線上學習的行為，達到督促的方式，或是透過討論課程，提高學生參與度[17]。 
從這些研究可以看出，利用互動性較高的討論方式，可以督促學生學習行為，是遠距學習課程督促學習的
方法之一，但是利用討論區或者討論的教學方式，提高學生互動，督促學生學習，並不適用在所有課程中，
尤其許多遠距教學課程，以視訊影片配合教材的講述教學方式或自主操作學習，而不是以討論教學方式為主，
這樣的學習方式，討論活動較少，就無法透過討論的互動來督促學生，也無法從互動的觀察來評量學生的學
習行為。 
大部分遠距教學課程是採用視訊及網頁的教材，學童的主要學習活動是觀看教學視訊，通常一段課程視訊
將近幾十分鐘，學童如果學習很專心，在這幾十分鐘過程裡，反而不會有任何網頁點選動作產生，在這種情
況之下，系統能夠收集到學生的點閱紀錄很少，想要透過這些紀錄，分析評估學生真正的學習行為會更困難，
不能只利用這些紀錄來評量學生是否達到情意目標。 
其他研究中，也有學者採用前面教學研究所提到的自評方式，來評估學生學習狀態[18-20]。但是前面許多
教學研究也提到，自評方式必須要能確保學習者能誠實回答，如果只根據學生的自評結果，作為遠距教學的
情意領域教學目標唯一的評量依據，並不適當。 
從這些研究來看，如果只根據這些點選瀏覽的記錄，並不足夠，不能完全只依賴這些紀錄，作為情意目標
評量依據，相對於課堂中的老師，能夠直接從課堂隨時而且完整的觀察學生反應和行為，遠距自主學習系統
還需要更完整的觀察紀錄機制。 
3.2 影像偵測運用 
數位影像是由二維函數 f(x, y)定義，x, y 是 spatial coordinates，f 在任意座標的大小，稱為該點的強度
(intensity)，數位影像處理則是利用數位電腦處理數位影像。圖形識別(Pattern recognition)則是透過事物表現於
外的特徵，來推斷隱含的本質。圖形識別的流程，首先必須先有判斷的事物，稱為(Sample)，而這些 Sample
表現於外的特色便稱為(feature)，擷取這些 feature 之後，最後根據這些 feature 加以分類。 
臉部的偵測及辨識可以廣泛運用在許多領域，例如安全監控，門禁系統等。要偵測及辨識人臉，首先必須
要能夠找到影像中，人臉的區域範圍，並且追蹤人臉的移動特性。為了找出影像中的人臉區域，近幾年許多
研究，利用彩色影像的特性來偵測人臉，利用膚色的顏色區域，分析膚色的顏色區域範圍，然後區隔影像中，
屬於這個範圍的像素，找出影像中的膚色區域，這類研究有使用 NRGB, YCrCb, Hsu 等色域轉換[21-24]，但
是膚色很容易受到光線影響而變化，或者受到複雜背景干擾，而產生偵測錯誤，如果膚色區域的定位錯誤，
將會嚴重影響到後續的偵測準確率。為了更準確定位膚色區域，去除錯誤的部份，有學者採用統計的方式，
採用高斯函數，找出更準確的膚色區域[25]，或是透過相鄰區域的相似特性，計算不同的膚色區域，區分膚
色的區域，或利用 fuzzy Integral 合併多種偵測方式，找出最可能的顏色區域範圍。 
如果是在動態的影像中，除了定位出特徵位置之外，還要能適應頭部的轉動，從不同的角度中，偵測臉部
區域，並且加以辨識，也可以建立臉部模組的資料庫[26]，直接比對臉部資料，來判斷人員。為了減輕系統
效能，可以透過持續追蹤頭部或者眼睛特徵的追蹤方式，從前一個 frame 來縮小眼睛偵測的範圍，直接找到
眼睛的方向，而不需要重新計算膚色[27-29]。 
利用眼睛的特性，則可以提高眼睛偵測的準確率[30]，或是利用眼睛結構的紋理特性，偵測人臉並且定位
眼睛[31]，或是利用小波(Wavelet)轉換的方式，建立臉部辨識系統[32]，或者結合嘴巴偵測及追蹤[33]。 
這樣的臉部偵測辨識，可以判斷所偵測的這個人，他的精神狀態，目前有許多研究，將這樣的技術運用在
行車駕駛的監控上[34]，從眼睛張開的程度，或者眨眼睛的頻繁度[35]，來推測駕駛是不是精神不佳，另外也
有研究，進一步的結合駕駛的臉部追蹤或頭部移動[36, 37]，以及張嘴打哈欠的偵測情況[38]，來綜合判斷駕
駛者的精神狀態。利用影像偵測技術，來判斷人臉的精神狀態，也可以運用在遠距學習系統上，偵測學習者
的精神狀態，但是由於偵測的環境不同，條件限制也不同，而且所要偵測的學習行為，不只包含精神不佳，
還需要加上不專心的狀態，才能完整觀察學童的學習狀態。 
 
4. System Design and Methodology 
根據文獻探討，課堂教學中，老師對於學生的學習狀態，主要從學生參與課程的立即狀態觀察得知，透過
課程活動，和學生的互動情況，或直接觀察學生的反應行為，掌握學生的學習狀態，根據這些學習狀態，來
視訊則需要 windows media encoder，本研究利用 VB.NET 程式語言撰寫，結合在同一個 form 當中，因此老師
端除了安裝本研究程式之外，還需要事先安裝 Microsoft .NET Framework 2.0。學生端的程式，在教材的瀏覽
上，需要使用 IE 瀏覽器，臉部影像的擷取偵測，則使用 Webcam 取得臉部畫面，然後呼叫 Matlab Function
進行處理，本研究利用 VB.NET 程式語言，結合在同一個 form 中，所使用的 Matlab Function 則必須事先
complier 成為標轉 com 函式庫，因此學生端電腦除了安裝本研究程式之外，也需要事先安裝 Microsoft .NET 
Framework 2.0，以及 Matlab Compiler Runtime 。 
 
4.2 Detection Model 
根據情意領域教學目標的階段，在課堂中所能達到的情意領域教學目標，主要在注意及反應階段，要評
量學生是否達到課堂的情意領域教學目標，老師必須透過學生參與課程的過程，觀察得知，所觀察的目標行
為，則在於學生是否達到注意及反應階段的目標行為，因此定義主要觀察行為分成注意及反應兩大類(Fig. 2)。
注意目標的行為主要要求學生必須專心於學習，因此必須偵測所有不專心的行為，包含離開座位、轉頭、打
瞌睡及操作其他程式等行為。 
 
4.3 Attending Detection 
專心階段目標的偵測，主要透過學生的臉部影像，偵測學生的學習行為。偵測的目標行為包含離開座位、
轉頭以及打瞌睡等行為，透過臉部特徵的偵測，利用動態偵測、膚色區域偵測、眼睛偵測以及嘴唇偵測，再
配合滑鼠和鍵盤的動態偵測，將偵測結果歸納處理，判斷學生是否產生不專心行為。 
4.3.1 Skin Detection 
膚色區域的偵測，先將 RGB 色彩空間轉換為 RGB 正規化，從 Soriano 所提出的膚色分佈模型中，定義
出膚色像素的上邊界及下邊界(see eq. (1) and (2))，再排除白色部分(eq. (3))，最後綜合三個方程式，定義出膚
色區域(see eq. (4))[24]。 
 
BGR
R ,1452.00743.13769.1 2 ++=++−=+ rrrQ ,  (1)
BGR
R ,1766.05601.0776.0 2 ++=++−=− rrrQ  (2)
BGR
G ,
BGR
R ,)33.0()33.0( 22 ++=++=−+−= grgrW  (3)
BGR
G, 
)004.0(&)(&)(
0
1
y) (x, ++=
>><
⎩⎨
⎧= −+ g
otherwise
WQgQgif
S
　
 (4)
找出膚色區域之後，使用 Dilation and Erosion 方式，使分開的區域能夠連接，並且去除雜訊區域，偵測
出來結果，如果膚色區域太小，則表示臉部可能距離電腦較遠，如果膚色區域夠大，只能代表有可能是臉部
的區域，仍然需要進入眼睛及嘴巴偵測才能進一步確定。 
4.3.2 Eye Detection 
眼睛的偵測，主要從眼睛的 template，偵測一開始，先選取眼睛的 template 範圍區域，作為比對的範本，
接著利用 template 比對臉部區域影像，找出眼睛區域。計算眼睛 template 區域灰階值，取出陣列平均值，以
及臉部區域影像，轉成灰階值之後的陣列平均值，掃描整個臉部區域，比對 template 和臉部區域的 normalized 
cross-correlation[39](see eq. (5))，算出兩者相關係數，取出相關係數值較高的區塊，就可能是屬於眼睛區塊。 
{ }0.5
y x, y x,
22
p u,
y x, p u,
]t-v)-y u,-[t(x]f-y) [f(x,
]t-v)-y u,-][t(xf-y) [f(x,
 v)(u, ∑ ∑
∑=γ  (5)
y) f(x, : image pixel value, t : the mean of the template 
p u,f : the mean of in the region under the template y) f(x,
從比對結果，定位出可能的眼睛區域，如果算出的區塊都低於某個門檻值，則表示所定位的區域是眼睛
的機會比較低，則學生可能不專心，如果定位的眼睛區域多於兩個，則可能產生誤判需要重新設定 templage
或者調整門檻值。 
如果能正確定義出一個或者兩個眼睛位置，則進一步的計算眼睛定位的位置和臉部區域邊界的距離，如
果眼睛定位位置距離臉部區域邊界太接近，則可能有轉頭動作。 
4.3.3 Lip Detection 
嘴唇的偵測，同樣利用嘴唇顏色的特性，和膚色比較起來嘴唇顏色比較偏紅色，根據Soriano所提的膚色
區域，嘴唇的顏色落在膚色區域以下部分，因此利用這個方式來運算(see eq. (1))，加入R-G>15 的條件，形成
最後比對的方程式(see eq. (6))，目的是要留下紅色系影像，接著使用Dilation and Erosion方式，使分開的區域
 4
 
Fig. 3 System interface 
影像處理以及模糊邏輯分析演算，主要利用 Matlab 撰寫，再將函式封裝成 DLL 檔案，透過程式介面呼叫
DLL 執行，並將執行結果傳回介面中，並且呈現在介面上，學童的臉部影像可以透過 IP-Camera 或者安裝於
電腦上的 Webcam 擷取，將影像傳入程式中，執行運算。 
本研究機制實際進行模擬測試，擷取臉部影像，進行測試分析。 
A. 模擬限制: 模擬環境的背景，盡量不要出現膚色香觀顏色，光線也必須充足. Webcam 對準臉部，距離約
40-50 公分。因為眼鏡的反光會影響眼睛的偵測，因此模擬對象不可戴眼鏡。 
B. 模擬目標: 眼睛及嘴唇位置能自動準確偵測，不專心行為能正確判斷。 
C. 模擬影像數量: 每個不專心行為均擷取 30 張影像，透過系統進行測試。  
模擬結果如下: 
(1). 正常情況: 正常情況下，模擬者呈現一般正常臉部情況。(Fig. 4) 
   
Fig. 4 Normal face image       Fig. 5. Drowsiness simulation image 
從 Table 1 顯示出偵測的結果。嘴唇的偵測根據嘴唇的定位及區域大小，如果嘴唇定位正確，顯示區域大於
20 pixel，則判定這個偵測是正確。眼睛的偵測則根據眼睛的定位以及偵測到的數量。30 張影像有 60 隻眼睛
進行偵測，如果專心程度超過 80，則判定偵測結果是正確的。(Table 1) 
Table 1 
Simulation results of Normal situation 
 Lip 
(30 frames) 
Eye 
(60 eyes) 
Attention  
Correct Results 28 48 29 
False Acceptance 0 5 0 
Correct Detection Rate 93% 80% 96.7% 
(2). 離開: 離開行為產生時候，學生臉部影像會完全離開偵測區域。  
如果嘴唇和眼睛的偵測區域都為零，則判定偵測正確。(Table 2) 專心程度也會判斷為零。由於模擬環境
控制在白色背景的環境，且無包含其他不相干物件，因此偵測的準確度非常高。 
Table 2 
Simulation results of second kind: Leaving 
 Lip 
(30 frames) 
No Eye  
(30 frames) 
Attention  
Correct Results 30 30 30 
Correct Detection Rate 100% 100% 100% 
 6
 8
行為產生，例如離開座位、打瞌睡、轉頭或發呆等，造成遠距學習許多的問題，也使得遠距學習學生不良的
學習態度，本研究利用影像處理技術，透過臉部影相特徵的偵測，從臉部特徵的變化、移動的距離，特徵與
臉部邊界的距離等，透過模糊積分方式，判斷學生是否產生本研究所定義不專心的行為。實作本研究系統，
並經過模擬測試，模擬的結果顯示，本研究系統可以正確偵測本研究所定義不專心的行為，利用本研究機制，
可以在學生自主遠距學習時，立即偵測學生不專心型為。  
未來研究中，可以在系統中結合警告或督促機制，針對不專心型為加以督促，並通知家長或老師。另外
本系統偵測機制，主要透過膚色偵測定位，膚色偵測容易受到背景顏色或者環境光線變化影響，未來研究則
可以探討其他臉部偵測定位的方法，運用在本研究系統，以克服背景或者光線變化產生的影響。. 
 
7. 成果 
7.1 原計畫相符程度:  
A. Research of Face Image Detection Methodology 
在Behavior classification步驟中，利用兩種判斷方法，貝氏網路以及模糊邏輯分析。其他步驟與原計畫相同。 
B. Implementation of image capture and Attending Auto-Detection Mechanism 
與原計畫相同，完成學生端影像擷取及偵測機制。 
C. Integration of student learning, and records database of management platform 
與原計畫相同，完成老師端的設定及記錄查詢機制。 
 
7.2 達成預期目標情況: 
預期完成之工作項目: 
(a)學童在家自主遠距學習自動監督服務系統 
系統製作完成並發表 Conference paper:  
K.-A. Hwang, C.-H. Yang, and C.-R. Wang, "Assessment for Attending and Responding stages of Affective 
Teaching Goal in Distance Learning Based on Fuzzy Fusion," in 2009 International Forum on Information 
Technology and Applications, Chengdu, China, 2009. (EI)
(b)系統評估 
完成學生測試使用意見反映評估，並發表 journal paper: 
K.-A. Hwang and C.-H. Yang, "Automated Inattention and Fatigue Detection system in Distance Education for 
Elementary School Students," Journal of Educational Technology & Society, vol. 12(2), pp. 22-35, 2009. 
(SSCI)
完成系統的模擬偵測準確性評估，並發表 journal paper: 
K. A. Hwang and C. H. Yang, "Learner Attending Auto-Monitor in Distance Learning using Image Recognition and 
Bayesian Networks " Expert Systems with Applications, vol. 36(9), 2009, pp. 11461-11469. (SCI, EI)
(c)創建家庭學習照護服務系統 
整個系統製作完成，分成學生端及老師端程式。 
然目前僅於電腦上安裝執行，未來應研究是否能移植嵌入式系統方式，以方便於家庭使用。 
 
7.3 對於學術研究，國家發展之貢獻 
(a)本計劃的完成，可提供學童在家自主學習一個很好的狀態自動偵測機制 
本研究系統透過學童使用評估，在學習過程中確實能夠提高學生參與的程度。 
(b)提昇雙薪家庭父母學習照護服務的可行性 
本系統目前僅以電腦安裝執行，若能在未來研究中移植於嵌入式系統執行，其可行性將大為提高，然受限於
研究時間不足，此一部分仍有待未來進一步研究。 
 
Reference 
[1] P. Eggen and D. P. Kauchak, Educational Psychology: classroom connections. New York: Merrill, 1992. 
[2] R. E. Mayer, Educational Psychology: acognitive approach. Boston: Little, Brown, 1987. 
[3] C. Huang, J. Li, and H. Shi, "An intelligent streaming media video service system," in IEEE Region 10 
Conference on Computers, Communications, Control and Power Engineering, 2002, pp. 5-10. 
[4] S. Huang and H. Hu, "Integrating Windows Streaming Media Technologies Into a Virtual Classroom 
Environment," in IEEE International Symposium on Multimedia Software Engineering, 2000, pp. 411-418. 
[5] E. Sillence and C. Baber, "Integrated digital communities: combining web-based interaction with text 
 10
[25] M. J. Jones and J. M. Rehg, "Statistical Color Models with Application to Skin Detection," International 
Journal of Computer Vision, vol. 46, pp. 81-96, 2002. 
[26] A. J. O'Toole, J. Harms, S. L. Snow, D. R. Hurst, M. R. Pappas, J. H. Ayyad, and H. Abdi, "A Video 
Database of Moving Faces and People," IEEE Transactions on Pattern analysis and machine intelligence, 
vol. 27, pp. 812-816, 2005. 
[27] P. Fieguth and D. Terzopoulos, "Color-Based Tracking of Heads and Other Mobile Objects at Video Frame 
Rates," in 1997 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 
1997, pp. 21-27. 
[28] V. Bakic and G. Stockman, "Real-time Tracking of Face Features and Gaze Direction Determination," in 
Fourth IEEE Workshop on Applications of Computer Vision, 1998, pp. 256-257. 
[29] P. Wang, L. C. Tran, and Q. Ji, "Improving Face Recognition by Online Image Alignment," in The 18th 
International Conference on Pattern Recognition, 2006, pp. 311-314. 
[30] P. Wang, M. B. Green, Q. Ji, and J. Wayman, "Automatic Eye Detection and Its Validation," in The 2005 
IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2005, pp. 164-172. 
[31] W. Huang and R. Mariani, "Face Detection and Precise Eyes Location," in 15th International Conference 
on Pattern Recognition, 2000, pp. 722-727. 
[32] A. Amira and P. Farrell, "An Automatic Face Recognition System Based on Wavelet Transforms," in 2005 
IEEE International Symposium on Circuits and Systems, 2005, pp. 6252-6255. 
[33] A. Caplier, "Lip Detection and Tracking," in 11th International Conference on Image Analysis and 
Processing, 2001, pp. 8-13. 
[34] T. Brandt, R. Stemmer, and A. Rakotonirainy, "Affordable Visual Driver Monitoring System for Fatigue and 
Monotony," in 2004 IEEE International Conference on Systems, Man and Cybernetics, 2004. 
[35] T. Ito, S. Mita, K. Kozuka, T. Nakano, and S. Yamamoto, "Driver Blink Measurement by the Motion Picture 
Processing and its Application to Drowsiness Detection," in The IEEE 5th International Conference on 
Intelligent Transportation Systems, 2002, pp. 168-173. 
[36] H. Gu, Q. Ji, and Z. Zhu, "Active Facial Tracking for Fatigue Detection," in The 6th IEEE Workshop on 
Applications of Computer Vision, 2002, pp. 137-142. 
[37] J. C. Popieul, P. Simon, and P. Loslever, "Using Driver's Head Movement Evolution as a Drowsiness 
Indicator," in IEEE Intelligent Vehicles Symposium, 2003, pp. 616-621. 
[38] T. Wang and P. Shi, "Yawing detection for determining driver drowsiness," in 2005 IEEE International 
Workshop on VLSI Design and Video Technology, 2005, pp. 373-376. 
[39] R. M. Haralick and L. G. Shapiro, Computer and Robot Vision vol. 2nd: Addison-Wesley, 1992. 
[40] A. Soria-Frisch, "Color Seal Extraction from Documents: Robustness through Soft Data Fusion," EURASIP 
Journal on Advances in Signal Processing, vol. 2005, pp. 2146-2152, 2005. 
 
 
朝陽科技大學資訊科技研究所補助學生出席國際會議報告 
                                                             98 年  5 月  22 日 
報告人姓名 王傳仁 系所/學號 資訊工程所 
9627643 
     時間 
會議 
     地點 
98.05.15-17 
中國大陸，成都 
本院核定
補助編號
TJ4-97D103 
會議名稱 2009 International Forum on Information Technology and Applications 
發表論文 
題目 
 Assessment for Attending and Responding stages of Affective Teaching 
Goal in Distance Learning Based on Fuzzy Fusion 
報告內容應包括下列各項： 
一、參加會議經過 
因為在前往成都的機票直航方面到達時間已經超過研討會的報到時間，所以需以轉機方
式，由於在研討會舉辦前一天的機票已無座位，所以在機票的訂購上選擇前兩天到達，在研
討會開始前兩天就已進駐研討會所舉辦的地點：金沙世紀酒店，5 月 13 日就從桃園機場搭機，
由於是第一次出國，所以在時間上提早了一個多小時到達機場。之後到達澳門機場轉機，由
於 H1N1 的情形，所以在整個的流程上有寫些健康的資料，隨身行李必須再檢查一次，坐上
飛機之後，出了機場大約三點半左右，在機場的海關，被問了許多相關的健康問題，也看到
一些旅客被叫到旁邊抽血，一出機場就聽照旅行社的建議搭計程車前往酒店，於是在等出租
車時候有非營業的出租車來攔客，由於價位上有比較便宜所以就搭乘，到晚上四點半到達預
定的飯店，稍微準備一下就出去吃晚餐，雖然是第一次出國，許多事情都是問人才知道如何
進行，但是總算是順利到達預定的飯店，至少不會延誤到整體行程。 
研討會當天早上九點半起來，準備一下然後吃個早餐，吃了幾塊麵包，因為研討會第一
天為報到日期所以第一天早上就完成報到手續，在報到時因為這個研討會由國外參與的不
多，所以主辦人就過來跟我聊天，不過在當地的語言，雖然是有些相同，但是有一些話語真
的有點難以聽懂，在等收據時有跟主辦人聊天，有提到說他想要來台灣促進學術交流，希望
可以來台舉辦研討會，於是我就建議可以來朝陽科大舉辦之類的話。下午就自由時間到處逛
逛，本篇並非上台報告，研討會第二天研討會開始，在演討會的後兩天，有請來演講的講員，
和一些投稿的先進們報告，在聽之於老實說對台上報告的講員的話，蠻多地方聽不懂的不過
大致上了理論可以猜測到。 
 
 
Assessment for Attending and Responding stages of Affective Teaching Goal in 
Distance Learning Based on Fuzzy Fusion 
 
Kuo-An Hwang1,2     Chia-Hao Yang3     Chuan-Ren Wang1  
1Department of Computer Science and Information Engineering, Chaoyang University of Technology, Taichung County, 
Taiwan 
2Graduate Institute of Networking and Communication Engineering, Chaoyang University of Technology, Taichung County, 
Taiwan 
3Graduate Institute of Informatics, Doctoral program, Chaoyang University of Technology, Taichung County, Taiwan 
s9433901@cyut.edu.tw; kahwang@cyut.edu.tw, leo_man1985@hotmail.com
 
 
ABSTRACT: Distance learning is a learning style that can 
overcome the limitation of time and space. Because of the 
distance, teachers can not assess the achievement of Affective 
Domain teaching goal. If teachers can know the student's 
affective state through the learning system, they can overcome 
the difficult. The research applies the image recognition 
technologies to capture the face images of students and analyzes 
their participation in discussion to evaluate the student's 
affective state by Fuzzy Integral. Finally, teachers can assess the 
student's achievement in Affective Domain teaching goal. 
KEYWORDS: Affective Computing1; Computer Application 
Technology2;Graph and Image Processing3 
I.  INTRODUCTION 
Teaching goals could be classified into three domains: 
cognitive domain, knowledge; affective domain, attitude; 
and psychomotor domain, skills. [1] After the instructional 
procedures are completed, students must be assessed whether 
they have achieved the teaching goals or not. [2, 3] In the 
class, when the instruction procedure is processing, the 
teacher always applies many kinds of teaching skills or asks 
questions to urge students to be attentive for achievement of 
affective domain teaching goals. Most of these skills and 
methods are the way of interaction. [3]  
E-learning has developed rapidly in past years, and 
became a trend of learning. [4] For assessing students’ 
levels, E-learning system should be designed with the 
assessment function.[5] The most convenient assessment 
method in distance education is on-line testing.  [5, 6] 
However, most teaching courses merely lay stress on 
knowledge impartation, namely, the cognitive domain, and 
neglect students’ learning attitudes and the affective domain 
teaching goals. [7] In an attempt to understand the student’s 
learning condition, many researches focus on computing the 
number of times in interacting in the discussion or the hours 
of participating in the course as the base for evaluating the 
student’s participation. [8] However, the number of times is 
unequal to the quality of discussion content. A student with a 
high participation frequency is not equivalent to a student 
who really participates attentively. [9] 
In distance education, teacher and students are place in 
different places, and the communication is in textual model, 
which can not display students’ real situation. [10] It is not 
sufficient enough for the teacher to handle the students’ 
situation and assess the achievement of affective domain 
teaching goals in distance education. In the normal distance 
education given in didactic instruction, students usually post 
questions in discussion board only when they have questions. 
This kind of distance education instruction does not have 
much interaction. The digital video surveillance system has 
been widely applied in many fields, but the Image 
Processing technology is affected by the changing of 
environment easily. Therefore, the system combines 
participation in discussion with the attention from facial 
image.  
In this research, Affective Domain Teaching Goal and 
assessment theory are explored. Base on these theories and 
practical situation in class, the assessment methods of 
participation in discussion for Affective Domain Teaching 
Goals are adopted, and facial detection technologies are 
combined by Fuzzy fusion. 
II. RELATED WORK 
Teaching goals could be classified into three domains: 
cognitive domain, knowledge; affective domain, attitude; 
and psychomotor domain, skills. [1] Although teaching goals 
are classified into three domains, they are correlated to each 
other, and many objects are not limited to only one domain 
alone. According to the gradation, affective Domain teaching 
goals can be divided into five stages [11]: The first is 
Receiving or Attending; the second is Responding; the third 
is Valuing; the fourth Organization; the fifth is 
Characterization. [12] 
For assessing students' achievement of the affective 
domain teaching goals, many researches proposed the 
methods of assessment. The first method is to observe the 
participation and learning of students in class from long-term 
recording. Teacher can handle students' learning attitude 
through the natural presentation in class. [13] Therefore, the 
interaction and observation recording is very important that it 
can assess the achieving of Affective Domain Teaching 
Goal. Many distance education courses take the frequency of 
interaction discussion as the base of students’ participation 
evaluation to assess the students’ participation in interaction. 
[14] 
