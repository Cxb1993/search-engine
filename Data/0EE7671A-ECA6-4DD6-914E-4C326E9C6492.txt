二、計畫緣由與目的 
隨著人類與電腦之間的互動日漸頻
繁以及視訊設備的普及，運用電腦視覺的
技術進行辨識工作，成了重要的研究課
題，由影像中擷取使用者資訊的研究及應
用亦相對重要，其中包含最多使用者資訊
的部分不外乎就是人臉，而主要的人臉相
關研究可分為 4 項 : (1)人臉偵測(Face 
Detection)[1-3]，主要在影像中尋找屬於人
臉 的 位 置 ； (2) 人 臉 辨 識 (Face 
Recognition)[4-5]，根據人臉的特徵做進一
步的分析，可用於身分辨識；(3)人臉特徵
擷取(Facial Feature Extraction)[6-8]，主要
將人臉中的特徵(如眉、眼、鼻、口等)自
人臉範圍中尋找出來並標示其位置，此項
亦為本研究的實驗目的； (4)人臉表情
(Facial Expression)[9-10]，根據特徵點位置
之間的關係，判斷出人臉中的表情資訊。 
 2
科技的進步，讓以往的理論逐漸實作
出來，使電腦更加貼近使用者。然而在一
般家庭，人臉相關的研究成果並未普及於
生活中，其最大因素在於一般使用者並非
使用高階的影像擷取裝置，而是較廉價的
低階影像設備(如網路攝影機、手機內建攝
錄功能等)，除了清晰度及飽和度不佳外，
還會因光影的影響讓特徵擷取不易，進而
使得人臉偵測失敗。因此，本研究目的在
於使用較低階之擷取影像裝置，如網路攝
影機(Notebook built-in webcam)來建立自
動化擷取人臉系統。將人臉辨識研究更實
用於一般使用者，未來亦可以運用在行為
分析、安全監測等電腦視覺技術，增進電
腦與使用者之間的互動。 
 
三、研究方法與過程 
本研究之自動化擷取人臉系統，主要
包含兩大部分：人臉偵測及特徵擷取。人
臉偵測部分，流程如圖 3.1 所示。首先擷
取網路攝影機的影像，利用光線補償解決
網路攝影機的自動白平衡以及光線所造
成的陰影，使影像中的色彩能貼近原始色
彩，接著將 RGB 色彩空間轉換成 YCbCr
空間，依據 CbCr 膚色分布資訊進行膚色
分割，將影像分割為膚色區域以及非膚色
區域。並利用 Connected Component 及閥
值的設定，從膚色區域中找尋可能的臉部
區塊，並選出可能的眼睛位置，進而作為
人臉存在與否的判斷。若判定眼睛存在，
則會根據兩眼間距以及角度來分割人臉
區域，藉此達到人臉偵測。 
而特徵擷取部分將針對人臉各部位的
特徵做分析，其中包括眉毛、眼睛、鼻子
和嘴。將這些人臉特徵分成 17 個特徵點，
如 3.2 圖所示，各個特徵相對位置是固定
的(ex:眉比眼高，眼比鼻高，鼻比嘴高)，
根據這些相對位置，可將不同特徵位置大
略劃分以便簡化處理。本研究大多使用
Local Thresholding 強化特徵，再根據不同
部位的特性找出最符合特徵組合，並標示
其特徵點位置，其流程如圖 3.3 所示。本
系統結合人臉偵測及特徵擷取兩部分，將
可偵測網路攝影機影像中的人臉部份，並
可標示出人臉特徵。 
 
圖 3.1 人臉偵測流程圖 
 4
五、計畫成果自評 
本研究針對網路攝影機開發出自動
化臉部偵測與特徵擷取的系統，提供一個
快速簡單的方法，讓使用者能使用低廉的
影像擷取裝置來實現人臉特徵及擷取，促
使人臉特徵應用能更為普及、便利。根據
研究結果及資料庫的選用，顯示本系統通
用性佳，且針對不同人種、環境下亦能正
常運作，尤其當影像從網路攝影機換成數
位相機影像，人臉偵測正確率由 80.1%大
幅提升至 88.0%。在未來的應用上，可將
人臉特徵點結合類神經網路加以分析，取
得個人面部資訊，以作為生物安全辨識；
或者將特徵點的相對位置換算為人的表
情資訊，並結合電腦系統，讓使用者與電
腦的互動更具效率。 
 
六、參考文獻 
1. J. R. Casas, A. P. Sitjes and P. P. Folch, 
“ Mutual feedback scheme for face 
detection and tracking aimed at density 
estimation in demonstrations, ” IEE 
Proc.-Vis. Image Signal Process, vol. 
152, no. 3, June 2005. 
2. F. Tsalakanidou, S. Malassiotis, and M. 
G. Strintzis, “ Face Localization and 
Authentication Using Color and Depth 
Images, ” IEEE Transactions on Image 
Processing, vol. 14, no. 2, February 
2005. 
3. M. H. Yang, D. J. Kriegman, and N. 
Ahuja, “ Detecting Faces in Images: A 
Survey, ” IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. 
24, no. 1, January 2002. 
4. X. Chai, S. Shan, and X. Chen, 
“ Locally Linear Regression for 
Pose-Invariant Face Recognition, ” 
IEEE Transactions on Image 
Processing, vol. 16, no. 7, July 2007. 
5. J. G. Wang, E. Sung, and R. 
Venkateswarlu, “ Registration of 
Infra-red and Visible-spectrum Imagery 
for Face Recognition, ” Proceedings of 
the Sixth IEEE International 
Conference on Automatic Face and 
Gesture Recognition, pp. 638-644, 
May 2004. 
6. M.A. Grudin, P.J.G. Lisboa, and D.M. 
Harvey, “ Selection of localised salient 
features from a single facial image, ” 
IEE Proc.-Vis. Image Signal Process, 
vol. 153, no. 4, August 2006. 
7. K. H. Lin, K. M. Lam, W. C. Siu, 
“ Locating the eye in human face 
images using fractal dimensions, ” IEE 
Proc.-Vis. Image Signal Process, vol. 
148, no. 6, December 2001. 
8. Y. Tian, T. Kanade, and J. Cohn, 
“ Robust Lip Tracking by Combining 
Shape, Color, and Motion, ” Proc. 
Asian Conf. Computer Vision, pp. 
1040-1045, 2000. 
9. M. Yeasin, B. Bullot, and R. Sharma, 
“ Recognition of Facial Expressions 
and Measurement of Levels of Interest 
From Video, ” IEEE Transactions on 
Multimedia, vol. 8, no. 3, June 2006. 
10. Y. L. Tian, T. Kanade, and J. F. Cohn, 
“ Recognizing Action Units for Facial 
Expression Analysis, ” IEEE 
Transactions on Pattern Analysis and 
Machine Intelligence, vol. 23, no. 2, 
February 2001. 
11. Markus Weber’s face database, 
http://www.vision.caltech.edu/archive.
html, June 2007. 
12. CMU AMP face database, 
http://amp.ece.cmu.edu/projects/FaceA
uthentication/#Download, June 2007. 
   
   
   
   
   
圖 4.2  M.W. Dataset 人臉偵測結果。 
 
 
 
 
 
 
 
 6
