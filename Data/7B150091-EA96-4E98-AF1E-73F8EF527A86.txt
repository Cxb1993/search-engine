元分割不完全等，若偵測的文字區塊是錯誤的區塊，
更會造成第二階段文字字元無法分割，甚至造成後續
研究無法辨識的大問題。圖 1為文字擷取的基本架構流
程圖（以新聞影像為例）。 
 
圖 1文字擷取的基本架構流程圖 
影像文字區塊偵測 
文字偵測的主要目的在於找出文字位於畫面中的位
置，也就是文字區塊的所在，偵測的方法則是針對文
字在影像中所呈現的特徵來進行設計。一般而言有下
列幾種方法： 
1. 以紋理（Texture）為基礎的演算法 
根據文字有相似的方向和頻率的資訊，因此文字可被
視為是一種特殊的材質。文字區塊的紋理特徵，與背
景間通常有較明顯的對比存在。文字與文字之間通常
也會留有一定的間距，所以利用這些區域的密度變
化，可以找出一些排列變化。因此，可以透過紋理的
特徵將文字區域找出來。 
2. 以顏色相似度（Color Similarity）為基礎的方法 
此種方法的前提，在於擷取的字幕文字需有相似的顏
色，因此處理背景僅能為全黑或全白的字幕文字，對
於場景文字以及位於複雜背景中的字幕文字，將無法
正確的被偵測出來。若依顏色相似度偵測出位置後，
再使用連接元件（Connected Component）方法將大小
相似、具水平排列的可能文字連接成一個字串。如 A. 
K. Jain[8]處理彩色影像的方法以及 R. Lienhart[4]。 
3. 以邊緣（Edge）為基礎的方法 
在檢測數位影像中有三種基本灰階不連續類型：點、
線、以及邊緣的技術，而根據文字具有多筆畫（即多
邊緣）以及邊緣聚集的特性，若能偵測出邊緣的資訊
（Edge Map），再利用各種合併方法如連接元件法來
連接相近的文字像素點，或者利用如型態學運算
（Morphological Operations）來連接相近的文字區塊，
便能處理出不論背景單純或複雜的字幕文字；而場景
文字方面，僅能處理高對比度且文字周圍為單純背景
的情形，不過此種方法容易將一群小物件誤認為是文
字區塊，這是因為很多聚集的小物件也會呈現多邊緣
且邊緣叢聚的特色，容易造成高錯誤偵測率的結
果。。 
影像文字字元切割 
做字體辨識的時候，通常都是一個字元做一次辨識，
而不是一整串文字一起進去做辨識，所以必須要有文
字字元切割的動作。在此切割文字字元所使用的方法
有下列幾種： 
1. 區塊化（Labeling algorithm）分割演算法 
區塊化[5]顧名思義就是將影像中連結在一起的像素視
為一個區塊，對影像區分成數個區塊。越複雜的影
像，區塊可能越多，而這樣的處理，在一般的影像處
理中，是針對影像的前景來作區塊化的處理。連結情
形的判斷基本上有兩種方式，一種是四連結（ 4-
connect），另一種是八連結（8-connect），四連結的
方式，即像素與其上下左右四個方向的相鄰像素才稱
為鄰居。而八連結的方式，是除了四連結的鄰居之
外，在加上左上、左下、右上、右下等斜對角四個方
向的相鄰像素。而區塊化演算法步驟有三： 
1.獨立搜尋影像每個水平像素的連結情形，記錄每個水
平區塊的起始位置和終止位置。 
2.以記錄的區塊為主，逐次由影像的上端往下搜尋，比
較每個區塊與其上一水平的所有區塊的相鄰情形，若
符合四連結的相鄰情形，這將兩相鄰區塊標為同一區
塊。 
3.當影像搜尋完後，整理記錄，即可分出多個區塊，並
為每個區塊作編號。 
2. 投影量法 
通常與背景形成對比的文字，在其上面邊緣與下面邊
緣應該會有大的垂直密度變化，因此我們預期水平文
字行會有高的垂直頻率。而針對每個可能的單一文字
字元區域，必須確定有足夠強烈明顯且密集的邊緣資
訊，若為真正的單一文字字元區域，則在每個字的列
都具有高的投影量，而且也應該有強烈明顯且密集的
邊緣資訊，字元與字元間會產生峰谷的現象，因此我
們使用水平投影量的方法來偵測峰谷現象，進而分割
文字字元。以車牌字元切割為例[6]，利用車牌垂直列
的黑色點分佈來判斷字元的分割位置。以車牌的特性
而言，字元與字元之間會有一些空白，而這些空白在
垂直投影下會出現最少黑色點，利用此特性可找出字
元間的分界。如下圖 2所示： 
           
 
圖 2車牌字元投影分割示意圖 
實驗架構 
1x1
2x2
4x4
NxN
N/2 x N/2
Level 0
Level 1
Level 2
Level i
Level i-1
 
圖 3金字塔紋理分析架構圖 
於類神經網路紋理分析結合金字塔紋理分析方法流
程，是利用金字塔紋理分析後將不同尺寸的影像利用
紋理視窗掃瞄並且個別對應至個別不同架構的類神經
網路，接著紋理視窗掃瞄到的每一個像素值分別作為
類神經網路的輸入向量。視窗則以滑動的模式由左至
右做水平的掃瞄影像，視窗大小則分別使用 55× 、
、 像素點三種不同的尺寸作為紋理視窗，
使用紋理視窗結合金字塔紋理分析的方法可使影像中
大小不一的字體更容易的被偵測到。如圖 4。 
77× 99×
Level i
Level i-1
Level i-2
金字塔影像分解 紋理視窗 類神經網路 輸出結果
圖 4金字塔紋理分析示意圖 
不同的紋理經過網路的計算則會有不同的效果，故在
紋理視窗的選擇將會使得後續的分割有不同的結果。
統計式紋理分析作法則直接對紋理視窗掃瞄到的像素
點作運算，並設一門檻值來衡量是否有文字存在此位
置，而紋理視窗的不同對統計式紋理分析也造成影
響。本研究採用「十」字型紋理[進行研究，此紋理字
型在對於新聞影像的處理有較好的文字偵測結果[1]。 
3. 形態學處理 
至前一個步驟為止，經過金字塔影像解析處理與紋理
視窗比對之後，在不同大小的金字塔紋理分析中會產
生許多可能的候選文字區塊，若我們將這些不同大小
的候選文字區塊以 AND 或 OR 合併會發現，使用 OR
方法合併後會得到較多的候選文字區塊。然而候選區
塊越多表示所找到不同大小的文字越多，但後選區塊
越多，相對的錯誤率可能也會隨之提高。相較於 AND
方法作為合併基礎，候選文字區塊影像合併後則會得
到較少的文字區塊，由於使用 AND 與 OR 方法合併，
兩者結果差異性太大，所呈現出來的效果並不使人滿
意，故我們轉而使用三分之二法則，作為第一次合併
的方式。 
第一次合併之後的統計式和類神經網路兩種不同演算
法中，產生兩種各有其特性的區塊，如表 1。使用傳統
式演算法會產生容易受雜訊影響的區塊，故我們對其
作侵蝕處理，去除一些因雜訊而產生的小區塊。而類
神經演算法具有強大的容錯能力，不易受雜訊所干
擾，但也因其訓練方式較為嚴格，有可能將文字區塊
所忽略，且偵測出來的區塊較不連續，故我們對其作
膨脹處理，將其區塊完整化。經過侵蝕與膨漲處理後
的區塊，在第二次的影像合併中使用 OR方法，影像合
併後再進行下一階段的分割文字區塊。 
4. 文字區塊切割 
文字偵測的最後階段為文字區塊切割，此階段是將經
過形態學處理並且透過 OR合併後的二值化影像，利用
像素標記法為基礎，分割出影像中包含文字的區塊 
[7]。 
文字字元分割 
在上述文字偵測系統中已經可以將影像文字區塊偵測
出來，我們將在這個部分把文字區塊中的各字元作字
元切割的動作。本系統文字字元切割流程分兩階段：1.
高斯低通濾波處理、2.投影量分析。以下對此架構作詳
細說明。 
1. 直方圖均等化處理 
在文字切割第一階段中，首先將文字偵測系統所偵測
出來的文字區塊加入直方圖均等化處理，如此可將已
偵測出來的區塊對比度提高，有助於我們後續使用投
影量分析來作字元切割的處理。 
2. 投影量分析 
在已偵測的文字區塊中，此研究分割字元的方式是以
投影量為分割的基礎。我們先對上階段經過高斯低通
濾波處理後的文字區塊進行投影量分析，圖 6投影量分
析圖中 X 軸代表受分析的文字區塊 X 座標位置，Y 軸
代表在受分析的文字區塊 X 座標中，像素點灰階值的
總合，故在文字呈現亮度較高的情況之下，是文字的
部分，其 X 座標的投影量必定較高，而在字元與字元
分隔的位置則會呈現投影量極低，甚至為 0的情況，我
們把此位置稱為投影量分析圖上的「峰谷」，以峰谷
作為文字切割的切割點。 
 
圖 6投影量分析圖 
實驗結果與分析 
本研究實驗中最主要的部份為：文字擷取系統兩部分
階段實驗。本章節即以細述說明此實驗系統，並對實
驗的結果進行討論。此系統根據本研究所提出之架構
來撰寫，共分兩個部分，1.可自動偵測影像中的文字區
塊，2.可將偵測出的文字區塊切割其各字元。 
由上面圖片可以觀察出，在未加入高斯低通濾波處理
前，文字偵測所切割出來的效果並不理想，偵測出來
的區塊很容易受到背景的干擾，連結成一大片的偵測
區塊，此結果在後續文字切割的進行中，將會產生很
多問題。而在加入高斯低通濾波處理之後，偵測區塊
易受背景干擾此問題，便得到大幅的改善。 
文字字元分割實驗 
以下為文字字元分割的實驗結果。 
 
圖 14文字字元分割結果(1) 
 
 
 
 
圖 15文字字元分割結果(2) 
垂直投影量法對於文字切割具有不錯的效果，對於英
文字串也能正確的分割出來，但是在某些特別的中文
字，如：“位＂、“川＂，等容易因為垂直投影量的
特性而將此種類型的中文字分成兩部份或三部份，
如：“位＂切割成“人字旁＂與“立＂等問題，我們
就必須加入其他演算法來使字元分割系統更完整。 
非文字區塊投影量分析 
在本系統第一階段文字偵測的過程中，會偵測到許多
非文字的區塊，此類區塊在第二階段的字元切割中，
經過投影量分析後的圖形會與正確的文字區塊大不相
同。正確的文字區塊具有規律性，峰頂之間的高度並
沒有很大的差別，而在非文字區塊的投影量圖中則呈
現不規律性，且各峰頂之間的差異很大，依照這些特
性，未來我們可以構思出一個演算法來過濾非文字區
塊，使我們的系統更完善。 
結論與未來研究 
本研究意在發展一種能從連續影片中自動擷取影像文
字的演算法。自動擷取影像文字的演算法可以在連續
的影片中擷取影像中文字的資訊，進而將資訊儲存至
資料庫中以供查詢。此項功能對於龐大繁雜的影片管
理有很大的貢獻，該方法使我們在眾多的影片中能有
效率地搜尋到我們需要的影片片段，省下許多搜尋的
時間，預估不單只是對資訊搜尋的使用者有很大的助
益，對於新聞節目的管理更具改革式的進步。在文字
偵測階段，遺失率為文字偵測系統性能好壞最重要的
一個指標。遺失率過高會造成此系統無法優化發展，
理想狀態中，每一文字區塊都必須被偵測到，才能確
保資訊的滴水不漏。能將遺失率控制到最低，對於後
續資訊系統資料庫的完整性是相當重要的一個關鍵。
在研究中發現，在文字偵測部份加入高斯低通濾波
器，改善了複雜背景的干擾，對於破碎的文字字元也
能有修復的作用，在實驗中也確實證明了在加入高斯
低通濾波器後，對部份類型的樣本有改善文字區塊偵
測效果。而在文字分割部份中，未來我們希望能夠尋
找到更適合的演算法，藉由投影量字元分割的方法來
過濾掉一些錯誤偵測的文字區塊，如此便可在錯誤率
高但遺失率低的情況之下，保留更多的重要資訊。本
研究發展一套可以自動偵測文字區塊，並進行文字字
元分割的文字擷取系統，未來若能與文字辨識系統及
資料庫結合，便可以推進影像數位典藏技術的發展。 
參考文獻 
[1] J. H. Liu, “A hybrid system for automatic text 
extraction in images using neural- and statistic-based 
information processing” A Thesis Submitted to 
Institute of Information Management I-Shou 
University in Partial Fulfillment of the Requirements 
for the Master Degree in Information Management, 
June. 2006. 
[2] S. J. Liang, “The Caption-based Highlight Event 
Detection and Classification for Baseball Videos” A 
Thesis Submitted to Institute of Information 
Engineering I-Shou University in Partial Fulfillment of 
the Requirements for the Master Degree in 
Information Engineering, June. 2006. 
[3] K. S. Lin, “Caption Extraction and Recognition for 
Sports Videos” A Thesis Submitted to Institute of 
Information Engineering I-Shou University in Partial 
Fulfillment of the Requirements for the Master Degree 
in Information Engineering, June. 2005. 
