of the probability distribution. In the experiment, 
we validate our proposed approach by using some 
videos. 
英文關鍵詞： Particle Filtering, Skin-Color Segmentation, Contour 
Detection, Fingertip Positioning, Tracking 
 
 2
而人機互動介面(Human-Computer Interface: HCI)
是一門研究使用者如何設計、實行以達成與機器
設備間溝通的領域，其涵蓋電腦科學、心理學、
語言學、人類學以及人工智慧等相關學門，其主
要在達成人性化、親和性、智慧型以及個人化等
目的。歐美各國均十分重視人機介面互動技術，
美國 MIT 於 1999 年所提出之「活氧計劃」，即研
究如何透過語音辨識技術作為操控介面。 
    人機互動介面研究領域中，感測技術扮演舉
足輕重的角色，其主要目的透過裝置擷取與分析
使用者操作意志，以作為機器設備作動之依據，
感測技術依所採用之觸控裝置之差異而有所不
同，一般而言可分為:紅外線式、電阻式、電容式、
表面音波式、光學影像式、影像辨識式、電磁式、
光點式以及超音波式，而上述相關技術比較如下
表所術。然而，近年來隨著相機製造技術的提升
及價格成本不斷降低，其已被廣泛應用於諸多裝
置中，因此如何運用影像資訊作為人機介面之輸
入，用以取代傳統人機互動介面，例如:滑鼠、鍵
盤、搖桿或觸控式螢幕等，以提供更方便與人性
化之操控介面，日前已廣泛受到各領域重視。 
    因此，本計畫主要提出一個影像式之手部動
態感測技術，取代資料手套之缺點，並能夠用於
感測 3 維空間中之手部動態資訊。此技術於文獻
上基本可分為三大研究主題 :1) 指尖定位
(Fingertip Positioning) 、 2) 軌跡辨識 (Trajectory 
Classification) 以 及 3) 手 勢 辨 識 (Gesture 
Recognition)。一般而言，指尖定位與軌跡辨識主
要探討如何偵測指尖於影像中座標，並追蹤與辨
識其運動軌跡種類；手勢辨識則為分析手掌外觀
差異以作為分類的依據。本計畫於今年主要提出
一個基於粒子濾波器(Particle Filtering)以整合膚
色資訊(Skin Color)與輪廓資訊(Contour)之指尖定
位系統，達成在複雜背景下使用者指尖位置定位
(Positioning)與追蹤(Tracking)。 
三、指尖定位問題探討與定位推論架構 
    然而如何有效定位影像中指尖位置並持續追
蹤，於電腦視覺研究領域當中仍有一定困難度，
其主要的挑戰與原因可歸納為下列幾項：亮度差
異 (Illumination Variance) 、複雜背景 (Complex 
Environment)、手勢姿態變化(Hand Pose Variance) 
以及運動模糊化(Motion Blurring)。光源變化為所
有影像辨識常見問題之一，於不同光源情況下，
影像中物體會呈現不同色彩變化，例如:手勢膚
色、牆壁亮度或物體反光，會導致相同手部影像
呈現不同顏色變化。複雜背景為不同環境場景
下，影像中背景會隨著相機所拍攝角度與方向而
改變，試圖於此種情況下區分出前景與背景存在
一定難度，主要原因為背景中存在類似手部膚色
區域或手指輪廓區域。手勢姿態變化為人之手指
與手掌為高維度(High-Degree of Freedom)變化之
物體，手勢於連續影像中所呈現之外觀變化極為
豐富，因此如何達到有效之手部偵測演算法實屬
不易。運動模糊化為手勢移動過程中，可能為移
動速度過快進而導致手勢模糊化，以至於遺失手
勢外觀輪廓資訊。 
3.1 文獻探討 
    目前指尖定位研究方法可分成三種類型，第
一類方法為以膚色切割為基準，切割膚色手勢
後，再經由型態學處理[2][5][6]、樣板比對[4]、橢
圓逼近手指[3]等方式進行指尖定位。其於一般情
況下可正確切割出手勢區域，並提升辨識率與加
快程式執行速度，然而人體皮膚易受環境光源變
化與複雜背景影響。第二類方法主要以輪廓分析
為基準，指尖定位方式主要透過背景相減取得手
勢輪廓[12]、尋找曲線與一對平行線的手指輪廓等
方式[9][10]。這類方法單純使用邊緣化影像來分
析手指輪廓特徵，因為不需要色彩資訊，所以可
適應光源變化，但是對於紋路複雜的背景來說容
易發生錯誤偵測。第三類方法是整合膚色與輪廓
分析，以膚色資訊與手勢輪廓資訊互相輔助，提
升手勢的判斷[11]。這類方法同時參考膚色與輪廓
資訊，膚色與輪廓各自有權重值，根據兩者機率
分佈來判斷最有可能存在之手勢區域，結合兩者
特性可互相輔助以提高辨識率與降低錯誤偵測
率。藉由上述分析與討論，本研究主要概念為整
合膚色與輪廓分析來定位與追蹤指尖。膚色資訊
部分以事先訓練的 Skin Model 來取得膚色機率分
佈，輪廓資訊部分以 Sobel 邊緣演算法取得邊緣
分佈。 
 4
來決定，此設計主要概念為參考前一時間點之手
勢大小來推測指尖可能活動範圍，為考量手勢之
移動速度，指尖座標需要較大預測範圍(變異數設
定為 3 倍)，而於正常固定手勢姿態情況下，通常
手部大小與方向之變化較小，固預測範圍較小(變
異數設定為 1 倍)。而經由上述方式所產生的粒
子，會集中散佈在上一次時間點附近。 
)3(0,  11 t-tt sN~x,xxx             
)3(0,  11 t-tt sN~y,yyy           
)(0,  11 t-tt sN~s,sss               
)(0,  11 t-tt sN~,          (4) 
而在預測階段中，首先所有粒子會依據前一
時間點之權重大小排序，而權重值較低之 10%粒
子將被排除，並經由隨機方式重新產生新粒子，
此方式一方面可有效提升粒子估算事後機率之效
能，另一方面可偵測新進入影像之手部指尖。而
權重值前 70%粒子將產生 90%之粒子狀態，權重
越高之粒子越可能成為預測階段所參考之粒子狀
態，圖三為連續時間之粒子散佈情況，圖中紅色
顆粒即為粒子所在位置，綠色方框即為估測指尖
位置。 
 
圖三、 預測結果示意圖 
然而傳統粒子濾波器常見問題主要為，部分
粒子可能會散佈於實際機率比較低之參數空間。
而此些權重值低之粒子通常於重新取樣階段會被
移除，導致計算時間浪費。此問題於文獻上被稱
為「衰減現象」[14]。為了克服「衰減現象」的問
題，本研究參考 Caifeng Shan [13]所提出之架構，
結合 Mean-Shift 演算法於粒子濾波器架構中，藉
以降低散佈在可能性低之粒子，減少「衰減現象」
情況發生。Mean Shift 是一種用在追蹤高機率密度
分佈的傳統方法，主要概念為於一個機率分佈中
尋找一定範圍內平均中心點，接著往平均中心點
移動後再重複上述步驟，主要目的用以逼近真實
之機率分佈。因粒子濾波器是以隨機散佈方式來
預測追蹤目標的位置，因此當粒子沒有散佈在目
標附近時，就容易收斂至區域機率分佈最大值
(Local Maximum)，而結合 Mean Shift 於粒子濾波
器架構後，每個粒子會往高機率分佈移動，使粒
子能夠有效逼近上述定義之事後機率，提高粒子
定位效率，並可達到降低粒子使用數量，達到加
快執行速度並同時維持高定位率，關於 Mean Shift
將詳述於下面章節中。圖四為本計畫所提出整合
膚色與輪廓分析方式，以達到指尖定位與追蹤之
系統架構圖。 
Input Video
Skin-Color 
Measurement
Contour 
Measurement
Skin-Color 
Modeling
Particle Filtering
Hand Samples
Result
Offline Training
 
圖四、指尖定位之系統架構圖 
四、可能性評估 
    經由觀察手勢移動影片，可明顯發現手勢膚
色資訊與手指兩邊之平行線輪廓於一般情況下通
常清晰可見，例如手勢在快速移動時，手勢輪廓
會變模糊，但手指兩邊之平行線輪廓依然可以由
肉眼察覺，而且膚色不會因為快速移動而消失，
固本研究藉由觀察膚色分佈與手指輪廓之存在有
無來估測指尖可能性。 
4.1 膚色可能性評估 
Skin Model 是藉由學習經由事先人工切割之
膚色樣本，將影像每個 RGB pixel 轉換成對應膚
色訓練樣本之可能性機率，進而得到一張灰階梯
度的膚色可能性分佈影像，越接近膚色之像素點
其可能性機率越高(灰階值越亮)。本計畫採用正規
化 RGB 色彩空間[16]以訓練膚色模型。根據參考
文獻分析[17]，人體膚色中藍色成分較少，所以膚
 6
角度分成四類型，每個類型對應至兩個顛倒之指
尖樣板。本計畫採用 Sobel 邊緣影像作為輪廓資
訊，基於粒子所在座標為中心，於邊緣影像上利
用最小平方法計算一個小範圍( mask 99  )內之邊
緣線之角度，再以角度判斷需要挑選之指尖樣板。 
 
圖八、 樣板角度分類 
   正常手指長度與手的大小有一定比例 fpr ，本
研究設定其為 0.7。藉由指尖( x, y)到 M 點之距離
s 與手指長度  比例值，可反推手指長度  的大
小，並以  大小設定尋找平行線的範圍。本計畫
使用 Sobel 偵測影像邊緣點作為平行線偵測依
據，藉由散佈於影像上各粒子狀態，可判斷所測
量之影像是否有平行線資訊。以粒子位置(指尖)
往 M 點方向延伸  距離，每延伸一個像素點則往
左右兩側搜尋 pW 範圍(設定 pW 為 0.4 倍  )，在範
圍內尋找所有與粒子角度為垂直關係之邊緣點，
且於其中挑選一個亮度最大之邊緣點，垂直角度
容許誤差範圍為 10 度。當尋找到梯度與粒子
方向垂直之最大邊緣亮度點時，納入最小平方法
之統計並記錄與 Line_  直線距離
qiW (其中
q=1,2，i=1,…,  )；反之若沒有找到梯度方向與粒
子方向垂直之最大邊緣亮度點時，則不統計最小
平方法與記錄距離。上述符號之定義如圖九所示。 
 
圖九、平行線掃描範圍示意圖 
為提升手指輪廓判斷速度，以手指寬度與長度比
例做為事先過濾之規則，以刪去不可能為手指平
行線之狀況，計算所有平行線段之寬度平均值 w
大小與  之比例值，平行線判斷依據如下方程式:  
0)(Pr /    / Line21  tt HIthworwthif    (9) 
然而上述方式，於背景紋路複雜的情況下會
發生線段為非連續直線之可能(如圖十所示)，進而
導致錯誤偵測。為避免此一情況發生，本研究分
別統計兩邊符合條件之邊緣點與 Line_  之距離
平均，再計算各邊緣點距離與平均距離之誤差絕
對值，當超過一半之邊緣點距離與平均距離誤差
超過設定之小門檻值(5 pixels)，則判斷為不具有
連續直線之可能，同時也不具有手指平行線之可
能性(如公式(10))。 







otherwise  0
pixel5 if 1 1
,count
|
W
W|,countcount j
qj
qi 

   
1,2    ,~1   qi         
0)(Pr  5.0 if Line  tt HIcount   (10) 
 
圖十、非連續線段可能示意圖 
當平行線平均寬度符合設定範圍，且不為非
連續線段，接著兩條平行線以最小平方法(公式
(11))分別計算其線段之斜率角度 q ，兩線段所
形成之方向與粒子方向作比較，分別計算兩線段
與粒子角度之誤差絕對值，如公式(12)所示，以兩
線段角度之誤差值作為平行線機率之評估依據，
為進一步降低錯誤偵測情況，同平行線偵測設定
一個門檻值 0.5，以排除可能性低之粒子。 
 8
))(p(max arg  
50
1i
skinskin 

 ki
k
z   (14) 
))(p(max arg  
50
1i
contourcontour 

 ki
k
z   (15) 
kiz ki  of lineon  Point   , 359 ~ 0 ：k
  
otherwise       
45 if  
2  
skin
contourskin
contourskin





,
,shift
t 
 (16) 
)N(0,0.5~ ts         
六、實驗與分析 
為初步測試驗證本研究所提出之指尖定位演
算法，本研究採用自行拍攝之影片當作影像測試
資料庫，其中包含 10 個使用者(如圖十三所示)以
食指指尖連續描畫數字 0～9。針對每個使用者拍
攝四段影片，主要將背景(單調與複雜)與手部姿態
變化(固定與不固定)程度分別分為兩類，其中固定
手勢是以維持食指朝上且其他四指握緊之狀態
下，移動整個手勢來描繪數字，非固定手勢是以
食指可以依使用者任意旋轉方向且其他四指握緊
之狀態下，以自然姿態用食指指尖描繪數字每一
段影像中。為分析與統計指尖定位之精準度，每
段影片先以人工方式註記畫面中之指尖座標。而
表 6-1 為執行本研究提出演算法之硬體配備。 
 
圖十三、影片資料庫:共包含十個使用者 
表 6-1 實驗硬體設備與環境 
項目 內容 
作業系統 Window XP 
工具 Visual C++ And OpenCV 2.1 
CPU Intel (R) Core(TM)2 Quad 2.40GHz 
記憶體 2G DRAM 
Camera Logitech QuickCam 
Resolution 640x480 
    本研究實驗之指尖定位之精準度主要定義
為，以粒子濾波器評估之指尖座標，與人工標註
之指尖座標間之直線距離 D 作為評估依據，公式
(17)為所定義之定位精準評斷分數方式，而每段影
片則以平均分數作為定位準確之衡量依據。 







(pixel) 60    40 if 10
(pixel) 40    20 if 50
(pixel) 20   if 1
D,.
D,.
D,
scoret  (17) 
 6.1 定位準確度分析 
在本實驗中，主要比較三種方法論：(1)有無
整合 Mean Shift 之比較、(2)整合膚色與輪廓資訊
與單純使用膚色資訊之比較以及(3)傳統樣板比對
方式與本研究辨識率之比較，圖十四為八個所採
用之指尖樣板。以複雜背景固定姿態測試影片探
討 Mean Shift 整合之指尖定位結果，其中表 6-2
與表 6-3 為兩種演算法分別在三種不同粒子數
125、250、500 之指尖定位結果。由數據中可明
顯推論出，無整合 Mean Shift 之演算法需使用 500
個粒子才能獲得與整合 Mean Shift 演算法 250 個
粒子之定位準確率。 
   表 6-2 無整合 Mean Shift 之定位準確率 
 Time
Particle
1 2 3 4 5 
125 0.122060 0.123518 0.146453 0.120797 0.135860
250 0.275121 0.376385 0.377745 0.256171 0.216035
500 0.843052 0.650729 0.891156 0.621672 0.834500
表 6-3 整合 Mean Shift 之定位準確率 
 Time
Particle
1 2 3 4 5 
125 0.162935 0.179592 0.151691 0.167846 0.171254
250 0.755005 0.816812 0.802138 0.771914 0.866084
500 0.966764 0.984257 0.980456 0.953546 0.948721
 
    
圖十四、八個指尖樣板 
    第二個實驗主要測試整合輪廓資訊之效果，
測試影片為複雜背景之固定姿態，粒子總數為
 10
可提升一倍左右的粒子效率，且整合了輪廓資訊
確實可於複雜背景情況下提升定位率。另外，於
所有測試實驗中，本研究之膚色模型是針對影片
使用者進行學習與調整，而膚色切割結果將對後
續指尖定位有決定性影像，因此未來如何進一步
提高膚色切割為一個重要課題。另外，於實驗結
果中發現，Mean Shift 調整尚未達到理想效果，主
要原因為為目前僅對座標與方向進行修正，未來
應提出一個修正大小 s 之策略，以進一步提升效
能。 
七、參考文獻 
[1] Noor Shaker, M. Abou Zliekha, Real-time Finger 
Tracking for Interaction, 5th International Symposium on 
image and Signal Processing and Analysis, pp. 41—145, 
2007. 
[2] Sze, M.M., Dy, A.L., Sarmenta, L.F., Inexpensive 
Camera based Gestural Interface for PC's, 4th Philippine 
Computing Science Congress, 2004. 
[3] Taehee Lee, Tobias H¨ollerer, “Handy AR: Markerless 
Inspection of Augmented Reality Objects Using 
Fingertip Tracking”, IEEE International Symposium on 
Wearable Computers, pp.83—90, 2007. 
[4] Jong-Min Kim , Woong-Ki Lee, “Hand Shape 
Recognition using Fingertips”, International Conference 
on Fuzzy Systems and Knowledge Discovery, pp.44—48, 
2008. 
[5] Sung Kwan Kang, Mi Young Nam , Phill Kyu Rhee, 
“Color Based Hand and Finger Detection Technology for 
User Interaction”, International Conference on 
Convergence and Hybrid Information Technology, 
pp.229—236, 2008 
[6] Zhi-Wei Chen, Yu-Cheng Lin and Cheng-Chin Chiang, 
“The Design of a Vision-based Fingertip Writing 
Interface”, The 18th International Conference on Pattern 
Recognition, pp.104—107, 2006. 
[7] Sylvia M. Dominguez, Trish Keaton, Ali H. Sayed, “A 
Robust Finger Tracking Method for Multimodal 
Wearable Computer Interfacing”, IEEE Transactions on  
Multimedia, vol. 8, no. 5, pp.104—107, 2006 
[8] Elmezain, M., Al-Hamadi, A., Appenrodt, J., Michaelis, 
B. , “A Hidden Markov Model-Based Continuous 
Gesture Recognition System for Hand Motion 
Trajectory”, IEEE International Conference on Pattern 
Recognition, pp.1—4, 2008. 
[9] Caglar, M.B., Lobo, N., “Open Hand Detection in a 
Cluttered Single Image using Finger Primitives”, IEEE 
Conference on Computer Vision and Pattern Recognition 
Workshop, pp.148—153, 2006. 
[10] Schwarz, C., da Vitoria Lobo, N., "The Camera-Driven 
Interactive Table ", IEEE Workshop on Applications of 
Computer Vision, pp.50—55, 2007. 
[11] Bretzner, L., Laptev, I., Lindeberg, T., "Hand gesture 
recognition using multi-scale colour features, 
hierarchical models and particle filtering", IEEE 
International Conference on Automatic Face and Gesture 
Recognition, pp.423—428, 2002. 
[12] Lianwen Jin, Duanduan Yang; Li-Xin Zhen, Jian-Cheng 
Huang, "A Novel Vision based Finger-writing Character 
Recognition System", IEEE International Conference on 
Pattern Recognition, pp.1104—1107, 2006. 
[13] Caifeng Shan, Yucheng Wei, Tieniu Tan, Fr é d é ric 
Ojardias, “Real Time Hand Tracking by Combining 
Particle Filtering and Mean Shift”, IEEE International 
Conference on Automatic Face and Gesture Recognition, 
pp.669—674, 2004 
[14] S. Maskell and N.Gordon, “A Tutorial on Particle Filters 
for On-line Nonlinear/Non-Gaussian Baysian Tracking”, 
in IEEE Transactions on Signal Processing, 
pp.174—188, 2002. 
[15] J. MacCormick and M. Isard. “Partitioned sampling, 
articulated objects, and interface-quality hand tracking.” 
European Conference on Computer Vision, pp.3–19, 
2000. 
[16] J. C. Terrillon, M. N. Shirazi, H. Fukamachi, S. 
Akamatsu. “Comparative Performance of Different Skin 
Chrominance Models and Chrominance Spaces for the 
Automatic Detection of Human Faces in Colour Images”, 
IEEE International Conference on Automatic Face and 
Gesture Recognition, pp. 54-61, 2000. 
[17] Y. P. Lew, A. R. Ramli, S. Y. Koay, R. Ali and V. 
Prakash, "A Hand Segmentation Scheme Using 
Clustering Technique in Homogeneous Background", 
Student Conference on Research and Development, 
pp.305—308, 2002.
 
三、考察參觀活動(無是項活動者略) 
略 
四、建議 
無 
 
五、攜回資料名稱及內容 
1.會議手冊 
2.會議論文集光碟片 
100年度專題研究計畫研究成果彙整表 
計畫主持人：黃世勳 計畫編號：100-2221-E-327-042- 
計畫名稱：應用於人機介面之影像式手勢語意辨識研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
