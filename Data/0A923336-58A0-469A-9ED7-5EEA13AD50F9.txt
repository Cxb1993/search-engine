centimeter. Finally, a graphic-based user interface 
is designed and implemented under a NI LabView 
environment. This interface creates an indoor map and 
users can plan the motion trajectory control via 
common input devices such as mouses. Essential case 
studies have been successfully performed to 
demonstrate the applicability for controlling and 
monitoring the position information of indoor mobile 
robots via such an interface. In the future, it is 
possible to further incorporate with task planning in 
computer sciences or artificial intelligence to 
realize the indoor mobile robot applications in 
various aspects of intelligent life, smart building 
technology, and home-patient care. 
英文關鍵詞： E-life, dynamic architecture, wireless network, 
indoor localization, wiimote, omni-wheel robot 
 
 I 
 
摘要 
近幾年人類對於生活品質要求的提升，已逐漸把資訊科技帶入日常生活環境，因此家
用機器人及小型電動載具因而蓬勃發展，以處理家庭中各項繁雜事務或警衛功能，因此本
計畫擬利用一創新型之自走式壓電致動器，結合無線操控電路 IC化模組及感測網路系统，
應用於智慧型居住空間元件，如虛擬實境、擴增實境、及情境互動等。 本子計畫主要負
責壓電載具及智慧建築之感測系統設計與整合部分.  包括壓電載具之空間定位, 姿態決
定, 回授控制, 以及智慧建築表層之各式感測, 如溫度, 溼度, 光線等之感測器網路, 以及
壓電載具於智慧建築之運動規劃及分散式控制等.  本計劃在技術上最大的創新乃是引入
遊戲機 Wiimote 作為室內定位系統, 並發展創新之平面定位演算法. 除此之外, 結合室內
定位, 無線感測網路, 移動式機器人控制, 以及智慧感測器, 本計劃之成果亦可應用於
E-Life 智慧生活領域, 配合 e 化概念來實現家庭自動化與數位化，以提升居家生活之便利
性。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 III 
 
 
目錄 
摘要 ......................................................................................................... I 
Abstract ................................................................................................ II 
目錄 ...................................................................................................... III 
表目錄 .................................................................................................. IV 
圖目錄 .................................................................................................... V 
第一章  緒論 .........................................................................................8 
第三章 Wiimote 2D定位系統與全向移動載具控制 .......................... 23 
第四章 全向移動載具控制與使用者介面之整合應用 ....................... 37 
第五章 以Wiimote為基礎之無線感測與智慧控制應用於E-Life智慧生活之研
究 ........................................................................................................... 52 
第六章  結論 ....................................................................................... 64 
  
  
 V 
 
圖目錄 
圖 2.1   應用於智慧建築之表層機器人 ............................................. 17 
圖 2.2   Wiimote camera感應距離與感測角度 ................................ 18 
圖 2.3   於Wiimote電路中處理室內定位與姿態偵測之重要元件 . 18 
圖 2.4   IR定位系統之軟硬體架構圖 ............................................... 19 
圖 2.5   實驗儀器與設備 .................................................................... 20 
圖 2.6   將Wiimote架設於線性馬達上測試其定位線性度與重現性21 
圖 2.7   Multi-zone定位之軟硬體架構圖 ......................................... 21 
圖 2.8   多重定位區域整合示意圖 .................................................... 22 
圖 2.9   定位線性度─像數變化轉換位置變化之數據圖 ................. 23 
圖 2.10  不同的感測距離所對應之解析度 ......................................... 23 
圖 2.11   Wiimote電路板上的四個 SMD LEDs ............................... 24 
圖 2.12   IR定位系統、驅動器與壓電致動器實際整合照片 .......... 24 
圖 2.13   Wiimote無線訊號傳輸與運動控制示意圖 ........................ 25 
圖 2.14   動態結構於軌道之運動控制示意圖 ................................... 25 
圖 2.15  Wiimote與全向輪平台之應用示意圖 ................................. 26 
圖 3.1   Wiimote外觀與內部元件 ..................................................... 30 
圖 3.2   Wiimote camera感應距離與感測角度 ................................ 31 
圖 3.3   Wiimote偏轉與 Camera座標圖之關係示意圖 .................. 32 
圖 3.4   Wiimote 2D定位程式流程圖 ............................................... 32 
 VII 
 
圖 4.11   全向移動載具軌跡追蹤實驗架構圖 ................................... 53 
圖 4.12   矩形軌跡追蹤結果 .............................................................. 54 
圖 4.13   矩形軌跡追蹤結果 .............................................................. 55 
圖 4.14   使用者介面設計概念示意圖 ............................................... 56 
圖 4.15   操作介面實績測試結果 ...................................................... 56 
圖 5.1   感測系統於 E-Life智慧建築之應用情境示意圖................. 58 
圖 5.2   整合Wiimote系統於智慧生活之情境設計 ......................... 59 
圖 5.3   Wiimote內部之重要元件模組 ............................................. 60 
圖 5.4   Wiimote智慧搖控應用之無線傳輸與運動控制示意圖 ...... 61 
圖 5.5   改造Wiimote控制器之 SMD LEDs接點以擷取電位差訊號61 
圖 5.6   利用Wiimote SMD LEDs電路作為觸發訊號源之架構示意圖 62 
圖 5.7   智慧控制之構想示意圖 ........................................................ 63 
圖 5.8   由手勢變化進行智慧搖控之人機介面 ................................. 64 
圖 5.9   以 LabVIEW程式平台進行遠端監控示意圖 ..................... 65 
圖 5.10   Wiimote結合擴充控制器進行改造之感測應用 ................ 66 
圖 5.11   Wiimote系統之各種環境感測人機介面 ............................ 66 
圖 5.12   Wiimote結合 Nunchuk之環境感測程式碼(VI) ............... 67 
圖 5.13   Wiimote系統於智慧生活之遠端監控與感測觸發機制方塊圖 68 
 9 
 
任務。 
 
    而機器人與使用者之間的互動能力，以及透過賦予機器人智能行為模
式與完善的使用者介面，皆是重要課題，在第四章將會詳細說明此部分的
研究成果。 
 
    最後在第五章中將會展現我們在 E-Life 智慧生活上的研究成果與概念，
利用資通訊技術、控制技術、及建築技術，配合 e化概念來實現家庭自動
化與數位化，以提升居家生活之便利性。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 11 
 
 
 
2.2.2  室內定位精度與運動控制之目標 
以本研究之表層動態結構(如圖 2.1)其室內定位的要求至少必須在釐米
等級才能準確地控制動態結構的分佈位置與群體移動的目標，本實驗室所
發展的 IR定位系統其定位精度遠優於一般的定位技術。經過線性馬達實驗
測試後，其精準度可達毫米等級。目前此系統之定位精度經過驗證之後符
合原先預期的目標，接下來在運動控制的部分，首先必須把 IR定位系統與
驅動電路結合，也就是將我們所設計的 LabVIEW program控制指令經由藍
芽無線傳輸至Wiimote，而Wiimote電路板上的四個 SMD LEDs之負端接
點將訊號發送至後級的驅動電路與壓電致動器來執行各種動作，此時也需
要加入閉回路回授控制的功能來修正誤差。 
 
2.3  Wiimote技術、定位控制與無線傳輸 
2.3.1  簡介Wiimote 
Wiimote是任天堂遊戲主機Wii的主要控制器。外型為棒狀，就如同電
視遙控器一樣，可單手操作。上面有幾個簡單按鈕與一個十字鍵，中間還
有一個揚聲器，搖桿內具備三向動態感應裝置，徹底改變以往玩家坐在沙
發上動的拇指的操作模式，而是要玩家全身動起來，降低遊戲操作難度，
真正讓電視遊樂器成為一個全民的娛樂活動。除了像一般遙控器可以用按
鈕來控制，它還有兩項功能：指向定位及動作感應。前者就如同光線槍或
滑鼠一般可以控制螢幕上的游標，後者可偵測三維空間當中的移動及旋轉，
結合兩者可以達成所謂的「體感操作」。 
 
(a) (b) 
圖 2.1  應用於智慧建築之表層機器人 
(a) 動態表層單元 (b)整體表層之圖形變化 
 
 13 
 
2.3.4  以Wiimote為基礎之室內定位與運動控制系統 
一般 IR室內定位技術的原理是 IR標識發射調製的紅外射線，通過安裝
在室內的光學感測器接收進行定位，必須在每個房間、走廊安裝接收天線，
造價較高，而且容易被螢光燈或者房間內的燈光干擾，在精確定位上有局
限性。本實驗室所發展的 IR室內定位系統相較於上述傳統的技術的創新之
處在於不受室內光線與室外陽光影響。此外，因為我們採用的方式是將 IR 
LEDs固定於天花板或牆壁上，就像街上的路標(Landmarks)，可以藉以確認
自己的位置與方向，成本也相對比較低廉。 
 
 
圖 2.4  IR定位系統之軟硬體架構圖 
 
如圖 2.4所示，IR定位系統以Wiimote為核心，當系統開始運作時，
Wiimote前端的 CMOS影像感測器會偵測視距範圍內所有的 IR LEDs。當
Wiimote移動時，影像感測訊號馬上由Wiimote上的 Bluetooth chip無線傳
輸至電腦的程式語言 LabVIEW，由 LabVIEW的使用者介面可以觀察到即
時的定位資訊。舉例來說，當Wiimote向左移動時，因為所有 IR LEDs的
位置固定，所以在 LabVIEW介面會看到 LED光點是往右邊移動，也就是
真實Wiimote的移動方向要乘以一個負號。當電腦知道Wiimote的確切位
置時，再利用 LabVIEW把控制指令傳送至Wiimote使其依照使用者命令移
動至指定位置或改變姿態。當系統移動或改變姿態時必定有誤差存在，我
們在程式中加入回授命令修正誤差。 
 
2.4  Wiimote定位精度實驗 
2.4.1  實驗系統之建立 
為了確保實驗的準確性與可靠性，因此要建立測試平台進行校準。如圖2.5，
有關Wiimote系統的動態實驗都以雙軸線性馬達與防震精密光學桌為測試
平台。首先，將Wiimote與 IR LED分別固定於線性馬達與光學桌上，彼此
之間的距離依實驗性質不同會有所變化。 
最初發展Wiimote定位技術時希望能藉由在線性馬達上的實驗證明其
 15 
 
 
圖 2.6  將Wiimote架設於線性馬達上測試其定位線性度與重現性 
 
(a)                        (b) 
   
圖 2.7  Multi-zone定位之軟硬體架構圖 
(a) Multi-zone定位於線性馬達上之實驗 
(b) LabVIEW program (GUI) 
 
經過線性馬達的測試之後，我們將Wiimote設至全向輪機器人平台
(Omnidirectional vehicle )，架測試此 IR定位系統於居家服務型機器人的應
用。圖 2.8為多重定位區域整合之示意圖，將數個彼此間隔 1.2公尺的 IR 
LEDs固定於天花板，IR LEDs與全向輪上的Wiimote camera距離2.25公尺。
此型號的 IR LED發射紅外光的角度大約 33.8度，使得整體紅外光的照射
範圍形成部分重疊，順利在一維方向整合三個定位區域，一維空間的定位
範圍可增加至四公尺。當全向輪平台移動時，Wiimote將定位資訊由藍芽晶
片傳回電腦的 LabVIEW定位程式，於使用者介面的上半部為 Local 
coordinate，下半部為 Global coordinate。在 Local coordinate會顯示每個單
一 IR LED的位置資訊，所有移動的距離包含∆X、∆Y與∆Ө都會累加至
Global coordinate得到全域的絕對做標位置。 
 17 
 
 
圖 2.9 定位線性度─像數變化轉換位置變化之數據圖 
 
如圖 2.10可以得知，當Wiimote camera與 IR LED之間的感測距離改變
時定位解析度會隨著改變，其趨勢呈現線性的變化。換言之，我們可以直
接經由內插法的計算得知在任意的感測距離之下所對應的系統定位解析度。
本研究之 IR定位系統目前應用於智慧建築的天花板軌道上的動態結構， 
Wiimote camera與 IR LED之間的感測距離大概在 40至 50公分，其解析度
大約是 0.35至 0.4mm。此外，經過實驗測試，線性馬達的速度由 5 cm/s變
化至 30 cm/s，證明載具的速度不同對於定位解析度與線性度沒有影響。 
 
圖 2.10  不同的感測距離所對應之解析度 
 
2.5  Wiimote紅外線定位系統之應用 
2.5.1  Wiimote無線訊號傳輸與周邊系統控制  
2.5.1.1 設計構想 
在Wiimote電路板的尾端有四個 SMD LEDs，如圖 2.11，原本在Wiimote
的功能為顯示電量以及代表遊戲進行中玩家的順序。我們將四個 SMD 
LEDs解焊後，希望可以直接使用由 SMD LEDs正負接點位置所產生高低
準位的數位訊號。將每個負端接地，正端焊上導線之後接到 16個 Channels
的多工器，換句話說，這四個接點所產生訊號的組合由多工器的 de- coder
 19 
 
 
圖 2.13  Wiimote無線訊號傳輸與運動控制示意圖 
 
 
圖 2.14  動態結構於軌道之運動控制示意圖 
 
2.5.2  結合全向輪平台與Wiimote之運動控制展示 
2.5.2.1 整體系統之建立 
藉由控制Wiimote的訊號傳輸展示，除了可以實現運動控制機制，甚至
進一步延伸至多媒體與環境感測，如圖 2.13，4個 SMD LED代表 4 bits，
換言之代表 16種指令，所以我們可以配合 16 channels多工器，型號為 ADI
所生產的 ADG 406來達到 16種與居家環境關係密切的應用，於 2.6.1敘述
目前已達成之功能，並舉例說明可能之延伸應用。 
 
 
 
 
 
 
 
 
 21 
 
的感測器來控制機器人的動作，例如居家保全與老人照護監控、自動沖泡
咖啡或飲料並送至主人面前等等服務動作都是居家機器人的應用功能。 
 
2.6.3  本研究之展示功能與智慧建築應用之結合 
本研究結合綠色科技的概念並且應用在智慧建築中。本文所提到的互動
式空間牆面主要功能為調節內部環境以及空間彈性使用，一組可回應環境
的智慧型表層單元，可感知環境與使用者的狀態，改變自身型態或移動位
置，以壓電致動器及相關無線感測與定位技術為主，開發互動牆面表層模
組，並規劃應用於互動式窗簾或拉門。將感測器與致動器結合到空間牆體
的設計，研發建築空間中：1. 自走變形的趴趴走空間精靈。2. 太陽能充電
的空間精靈。多組空間機器人將組合成一機器建築，具有：1. 動態的牆。
2. 流動的牆。3. 會發光的牆。4. 會呼吸的牆。 
 
2.6.4  困難挑戰與未來工作 
目前定位技術可以涵蓋二維的空間，其範圍大小取決於 IR LED與
Wiimote camera之間的距離，X軸方向已經成功發展多重區域定位技術，
距離擴增至 4公尺，但是 Y軸方向多重區域定位的 LabVIEW程式尚未完
成，因為二維方向的定位區域整合比一維的複雜度增加許多，必須考慮許
多其它因素，例如 X軸與 Y軸之間的影響。此外，目前正致力於數個
Wiimotes，也就是多個載具的定位整合程式，嘗試在同一個人機介面就可
以有效掌控多個載具的動向，並且能夠以自動控制與遙控的方式精準地移
動至指定的位置，以上都是目前必須突破的挑戰。目前在 LabVIEW人機介
面所得到的定位資料是針對四個 IR LEDs所涵蓋的區域，往後定位範圍擴
增勢必要利用多重飛航管制區的概念，將每個區域的定位畫面整合，並且
在人機介面上能夠正確地辨別每個Wii- mote。此外，繼續加強 16種運動
指令的變化性與實用性，並且實現環境感測與遠端監控照護功能。 
 
2.7  結論  
本研究目前所展示的功能歸納為以下三點：1.多重區域精準定位之技術。 
2.利用Wiimote所產生的訊號傳輸至驅動電路使壓電致動器載具運動。 3.
機器人跟隨光源移動。以上功能均建構於室內環境中，實現智慧化生活空
間。自動化的建築表層結構整合感測功能不僅可以使家庭環境更加舒適便
利，也同時兼顧居家安全的考量，而建築空間表層的圖形變化，更能突顯
科技所帶來的力量與美感。 
 
2.8  參考文獻  
T. Aytac, B. Barshan, Optics Communications 210 (2002) 25–27. 
K. H. Lee, J. H. Kim, Robotics and Autonomous Systems 54 (2006) 193–204. 
 23 
 
第三章 Wiimote 2D定位系統與全向移動載具控制 
3.1 前言 
近年來，隨著科技進步，位置感知技術( location aware technology )的發
展與人們日常生活息息相關。全球衛星定位系統(Global Position System, 
GPS)即為現今最普遍的位置感知系統，GPS是針對戶外環境的定位技術，
其最大的限制在於須與衛星系統保持通視(Line Of Signt；LOS)，透過與衛
星系統通訊進而達到定位之目的，GPS提供人們交通上的便利，然而人們
大部分的時間是處於室內環境中，倘若在室內或建築物中，定位訊號將會
被建築物所遮蔽，導致無法正確定位工作，雖然有人嘗試以 GPS做室內定
位系統，使用昂貴的設備來達到定位目的，卻無法提供需求的定位準確度，
因此室外定位技術未必適用於室內定位，故發展室內定位系統(Indoor 
Positioning System；IPS)成為一個新的研究議題。室內定位必須考慮到室內
環境擺設複雜以及運用上需具備高精準度，在實作上困難許多，常見的定
位系統如 RFID、超音波定位，以及新興的無線感測網路技術，例如WiFi、
ZigBee、Bluetooth和 UWB等廣泛地被應用。除了以上提及的定位技術，
還有基於電腦視覺、光跟蹤定位、基於圖像分析、磁場以及信標定位等。
此外，還有基於圖像分析的定位技術、信標定位、三角定位等，以上的技
術都還處於研究試驗階段。接下來是與本研究相關的紅外線室內定位技術，
其定位的原理是藉由紅外線 IR標發射調制的紅外射線，透過裝設在室內的
光學傳感器接收進行定位。Wiimote定位系統[1]主要是將Wiimote架置在
移動機器人載台上，並由其 CMOS影像感測器觀測布置在天花板的 IR LED
陣列，經過LabVIEW程式演算後得到定位資訊，配合載具偏轉角度修正法，
可及時提供被定位載具座標及旋轉角度資訊，在定位效果上具有良好的準
確度，然而該定位系統工作範圍僅適用於 1D帶狀區域，無法有效提供 2D
大範圍定位資訊，在實際應用上受到限制。本文主要依據Wiimote定位系
統[1]進行改善工作，利用其載具偏轉角度修正法，延伸發展Wiimote 2D定
位系統，有效提升該整體定位系統之定位範圍，最後並結合全向移動機器
人平台進行軌跡追蹤控制，將可有效操作載具進行不同之軌跡追蹤任務。 
 
3.2 背景介紹  
3.2.1  Wiimote簡介與特色 
Wiimote是任天堂遊戲主機Wii的主要控制器。外型為棒狀，就如同電
視遙控器一樣，可單手操作，如圖 3.1。本研究展示的定位技術，主要是利
用Wiimote與 IR LED之間的相對運動來決定待測物體的空間位置，透過其
 25 
 
 
圖 3.2  Wiimote camera感應距離與感測角度 
 
3.2.2  載具偏轉角度修正法 
Wiimote定位系統之載具角度修正法主要是透過觀測 IR LED陣列變化
情形以辨識載具偏轉角度，並將偏轉角度補償至 Camera座標，利用旋轉座
標軸的方式達到修正效果。首先令布置在天花板的 IR LED 1D陣列之排列
方向與 Global座標系統 YG軸平行，接著模擬Wiimote於偏轉角度 θ下觀
測 IR LED之情形如圖 3.3所示，其中綠色線條為兩顆 IR LED之連線，灰
色虛線為 Global座標之 YG軸方向。由圖可知隨著偏轉角度 θ改變，Camera
座標之 IR LED陣列斜率亦會隨之改變，因此可以透過觀測綠色線條的斜率
來計算此時Wiimote之偏轉情形，而觀測綠色線條的先決條件就是必須令
Wiimote可以同時觀測兩顆以上之 IR LED，透過任兩顆 IR LED之相對位
置方可計算出綠色線條斜率；接著將 IR LED之 Camera座標( Cx , Cy )代入
修正方程式(2)，可得修正之 Camera座標( Cx , Cy )，式中 XC 、 YC 為載具
旋轉中心對應在 Camera座標上之 pixel值。 
 
( ) ( )
( ) ( )
cos sin
sin cos
C C X C Y X
C C X C Y Y
x x C y C C
y x C y C C
θ θ
θ θ
= − − − +
 = − − − +                  (2) 
 
 27 
 
3.3.1  IR LED取樣 
本文提出之 2D平面定位系統在定位中必須藉由至少兩顆 IR LED進行
計算得到角度以及位移量，這表示我們需要確保兩個通道可正確提供 IR 
LED資訊，首先我們以程式判斷四個通道傳回值是否為(0,0)來區別 IR LED
的存在與否，接著將通道順序進行重新排列動作，捨棄掉錯誤資訊，正確
取出Wiimote觀測的 IR LED訊息，考慮圖 3.5左側之情形，經由程式處理
可以得知二號通道及三號通道並無座標傳回值，故我們將 IR4由原來的四
號通道往前遞補至二號通道，使得定位程式能夠藉由 IR1以及 IR4完成定
位，倘若Wiimote在任一時刻下均能觀測到兩顆以上之 IR LED，則透過取
樣法則處理後，可以確保一號通道以及二號通道傳回值資訊之正確性，進
而完成角度計算。 
 
 
圖 3.5  IR LEDs之取樣示意圖 
 
3.3.2 角度辨識與載具偏轉角度修正 
我們希望將布置在參考平面之 IR LED以特殊的方式排列，提供Wiimote
觀測上更多的資訊。本節將 IR LED以長短邊的方式編排成 2D陣列如圖 3.6
所示，分別定義短邊 a對應 Global座標 XG軸，而長邊 b則對應 Global座
標 YG軸，同時我們希望更有效的利用該 IR LED陣列所能提供的資訊，再
定義斜邊 c作為第三者參考方向，而本實驗架構下各邊長 a b c之長度比例
為 3：4：5，藉由燈與燈之間長度的不同來區分之，並配合載具初始角度的
定義達到任一瞬間的偏轉角度辨識：我們考慮兩顆 IR LED的相對位置長度，
並辨識出該組燈號所屬之邊長 a b c，參考圖 3.7之對應邊常幾何關係表示
即可得到各種可能象限角度情況，而由於任兩顆 IR LED不具有方向性，故
在計算上還應同時考慮兩種角度，如圖 3.8所示，透過上述角度計算方式，
在任一時刻下皆能得到多組可能角度，如方程式(3)所示；在此考慮到載具
在移動中其偏轉角度變化具有連續性，故我們將所有計算所得之可能角度
與前一時刻之觀測角度進行比較，取出最接近者做為新的觀測角度；最後
將載具偏轉角度以及觀測座標代入(2)式，即可完成 Camera座標軸修正。 
 29 
 
 
圖 3.7  偏轉角度之可能情形 
 
 
圖 3.8  計算偏轉角度之可能情形 
 
 31 
 
行進間的同時利用無線藍芽將Wiimote觀測之 IR LED資訊傳輸至 PC端，
以 LabVIEW程式進行定位演算並記錄下Wiimote系統定位數據，實驗架構
配置如圖 3.10所示。為了方便布置 IR LED陣列，我們定義地板為參考平
面來擺設 IR LED，並且以 28.1 cm 對應 XG方向，37.5 cm 對應 YG方向
的方式來擺設 IR LED陣列，作為辨識 Global座標軸之指標。在此我們將
Wiimote與精密旋轉平台固定於線性馬達上，並找出載具旋轉中心為
(376,561) pixel，接著令Wiimote朝下觀測地面的 IR LED陣列，而平台上
方放置水平儀藉以確保Wiimote垂直於地面，防止因 camera鏡頭歪斜而導
致誤差產生，其感測距離為 102 cm。定位程式參數相關設定則如表 3.1所
示。 
 
圖 3.10  Wiimote 2D定位系統定位實驗架構圖 
 
表 3.1  Wiimote 2D定位系統參數設定 
 設定值 單位 
XG方向單位像素長度 0.0769 cm 
YG方向單位像素長度 0.0769 cm 
旋轉中心 X座標 CX 376 pixel 
旋轉中心 Y座標 CY 561 pixel 
程式單位迴圈時間 10 ms 
單位迴圈時間最大位移量 Vmax 20 pixel 
 
3.4.1  三角波運動路徑定位實驗 
三角波運動路徑是令線性馬達朝 YG方向前行 80 cm，並同時令馬達於
XG方向移動，範圍為 25公分，當 YG方向每移動 10 cm時，馬達 XG方
向移動則改變方向一次，路徑總長 215.4 cm。實驗結果如圖 3.11所示，由
圖可知定位系統在任一偏轉角度下均可對三角波運動路徑正確定位，而測
 33 
 
3.4.2  方波運動路徑定位實驗 
方波運動路徑是令線性馬達先以 YG方向移動 10 cm，接著再以 X方向
移動25 cm，而YG方向位移為20 cm時，馬達再以XG方向反向移動25 cm，
如此進行四次，路徑總長 280 cm。實驗結果如圖 3.12所示，由圖可知定位
系統在任一偏轉角度下均可對方波運動路徑正確定位，在此的方波路徑緊
密排列，用意是測試Wiimote 2D定位系統在平面上任意位置皆能正確定位，
圖中顯示定位路徑與實際運動路徑相差不大，沒有明顯誤差成長趨勢。 
 
 
 
 
圖 3.12  不同偏轉角度之方波運動路徑定位結果  
(a)0° (b)30° (c)330° 
0 10 20 30 40 50 60 70 80
-30
-25
-20
-15
-10
-5
0
5
Y  pos it ion(c m )
X 
po
si
tio
n(
cm
)
 
 
10 c m /s 15 c m /s 20 c m /s 25 c m /s A c tual m oving path(a)
0 10 20 30 40 50 60 70 80
-30
-25
-20
-15
-10
-5
0
5
Y  pos it ion(c m )
X 
po
si
tio
n(
cm
)
 
 
10 c m /s 15 c m /s 20 c m /s 25 c m /s A c tual m oving path(b)
0 10 20 30 40 50 60 70 80
-30
-25
-20
-15
-10
-5
0
5
Y  pos it ion(c m )
X 
po
si
tio
n(
cm
)
 
 
10 c m /s 15 c m /s 20 c m /s 25 c m /s A c tual m oving path(c)
 35 
 
移動過程中，偏轉角度 θ誤差量約控制在±2o內，而隨著移動速度上升，
則誤差量有較大的趨勢。由於全向移動載具底部特殊機構，我們知道在只
要令任兩顆馬達分別以等速正轉與逆轉，就能使載具進行直線運動，然而
當馬達與地面打滑時，載具就會因而偏轉方向導致逐漸偏離直線軌道，圖
中無控制結果代表我們給予馬達固定控制電壓使載具以 10 cm/s進行移動
之軌跡圖，由圖可知在無控制情形下，載具則會因逐漸偏轉而導致偏離行
進方向的情形發生。  
 
 
 
圖 3.14  直線軌跡追蹤實驗比較圖  
(a)平面軌跡圖 (b)角度變化圖 
 
 
 
 
0 0 .5 1 1 .5 2 2 .5 3 3 .5 4 4 .5
-0 .5
-0 .4
-0 .3
-0 .2
-0 .1
0
0 .1
0 .2
0 .3
0 .4
0 .5
Y  position (m )
X 
po
sit
io
n(
m
)
 
 
0 .1 m /s
0 .2 m /s
0 .3 m /s
0 .1  m /s ( 無控制)
(a)
0 0 .5 1 1 .5 2 2 .5 3 3 .5 4 4 .5
-20
-15
-10
-5
0
5
10
15
Y  position (m )
An
gl
e(
de
g)
 
 
0 .1 m /s
0 .2 m /s
0 .3 m /s
0 .1  m /s ( 無控制)
(b)
 37 
 
第四章 全向移動載具控制與使用者介面之整合應用 
4.1 前言 
近年來由於電子科技、電腦與控制技術之快速發展，各種機器人應運而
生。根據國際機器人協會(International Federation of Robotics; IFR)之定義，
機器人可分為工業用機器人與服務用機器人兩大類，其中工業用機器人僅
應用於產業上的精密製造，其發展市場已日趨飽和，未來成長空間相當有
限；反觀多數已開發國家正邁進高齡化、少子化社會，對於老年人的居家
照護、兒童的教育娛樂與家庭勞務服務、保全的需求日益殷切，因而促進
智慧型服務用機器人的市場逐漸成形，未來在開發居家服務型機器人將有
高幅度的成長空間。為了使智慧型機器人走入人們的日常生活中，機器人
除了本身必備之基礎功能外，尚需要增加與使用者之間的互動能力，透過
賦予機器人智能行為模式以及完善的使用者介面都將有助於使用者順利熟
悉並操作機器人，進而提升人們對於智慧型機人的需求度。而在使用者介
面之發展上，則以人性化為主，提供使用者簡單易懂的機器人操作介面，
並且配合互動式設計使得人們在操作上不再單調乏味，良好的使用者介面
將可以讓使用者有效率的操作機器人，並且改善操作錯誤的情形。考量到
針對室內環境所開發之機器人，在設計上則應考慮室內環境地形複雜以及
機器人本身之於環境的機動性能力，在各種形式之機器人中以輪式機器人
具有結構簡單以及穩定性較高等特性，故在室內環境上的應用方面又以輪
式機器人居多，常見的如：導覽機器人、清潔機器人、保全機器人等。這
類型的機器人在執行任務時經常要四處移動，因此要如何使機器人知道現
在所處之位置也就格外的重要，此時則必須藉由一套定位系統來提供機器
人定位資訊，而隨著定位系統之精度越高，將有助於提升機器人的工作效
率。本文將結合全向移動載具作以及Wiimote 2D定位系統[1]發展載具之軌
跡追蹤控制器，參考文獻[2]建立載具系統數學模型及 PID控制器設計兩部
分，透過Wiimote 2D定位系統高定位經度特性，將可有效操作載具進行不
同之軌跡追蹤任務；最後，本文亦會針對全向移動載具控制系統設計一套
使用者介面，以圖像顯示與物件式操作的方式提供使用者更直覺的互動模
式。 
 
4.2 背景介紹  
4.2.1  Wiimote 2D定位系統 
Wiimote 2D定位系統[1]運作原理主要是利用Wiimote前端內建之
CMOS影像感測器觀測 IR標的進行定位演算，首先將 IR LED設置於天花
 39 
 
 
圖 4.2  全向輪實體圖 
 
 
圖 4.3  全向移動載具底部架構圖 
 
4.2.3  LabVIEW圖形使用者介面(GUI)介紹 
圖形使用者介面(GUI)是採用圖形方式顯示的電腦操作用戶介面，其發
展概念就是透過所謂的「見感」(look and feel)介面，讓使用者可以輕易且
方便的經由圖形介面操作程式，如此能免除使用者以往需記憶一大串指令
的困擾，藉以縮短使用者學習程式的時間並減少使用者操作錯誤的機會。
本文之程式演算處理皆在 LabVIEW虛擬儀控平台上進行，配合 LabVIEW
之 GUI完成程式設定工作以及資訊觀測，而 LabVIEW所提供的 GUI則稱
為前面板(Front panel)，其前面板具備完整的控制元件與表示元件，可讓使
用者針對本身應用需求建立合適的操作介面，同樣也能藉由建立在前面板
之虛擬儀表即時觀測系統資訊，以提高使用者在設定量測作業與處理資料
的速度。圖 4.4為 LabVIEW前面板之控制元件與表示元件，圖中顯示
LabVIEW 具備標準 OS控制元件，如數字/字串顯示、按鈕、幻燈片、進度
條，與分頁等，且包括科學與工程應用等特殊的控制元件與表示元件，提
供使用者可以仿照自己熟悉的實體儀器，在前面板建立虛擬儀表以便操作；
LabVIEW亦具備圖表功能，可顯示類比與數位波形圖，當使用者在擷取或
產生資料之後，若資料已儲存於檔案或資料庫中，則可透過圖表來呈現所
需的資料。 
 
 41 
 
 
圖 4.5  全向移動載具底部架構圖 
 
4.3.1  全向移動載具之運動數學模型 
我們在本節中將推導全向移動載具機構部分之數學模型。圖 4.6為本實驗之
全向移動載具之系統受力圖，其底盤由三個全向輪互相夾 120o所構成，並
且以三顆直流馬達分別驅動之，使得載具可在二維平面上任意平移以及轉
動。我們使用兩個座標系統分別表示 Global座標系(XG, YG)以及載具座標
系(XM, YM)，而載具座標下之 f1、f2、f3代表各個全向輪與地面之摩擦力，
f與M則為整體載具之受力和總力矩；δ為全向輪 2與 XM軸之夾角，其
大小為 30o；θ表示 XM與 XG之夾角，即為全向移動載具在 Global座標下
之偏轉角度。由圖 4.6我們可以得到載具座標系之受力關係(1)式與 Global
座標轉換關係(2)式。其中 Gx 與 Gy 分別表示載具加速度在 XG軸及 YG軸
方向之分量。 
 
1 1
2 2
3 3
1 11 2 2
3 30 2 2
x
y
f f f
f f K f
M f fL L L
 −
      
       = − =      
           
                     (1) 
 
cos( ) sin( ) 0
sin( ) cos( ) 0
0 0 1
x x x
G
y y M y
F f f
F f T f
M M M
θ θ
θ θ
−       
       = =       
                               (2) 
 
 43 
 
1
1
2
3
1 XGT G
M YG
v
K T v
R
ω
ω
ω θ
−
   
   = ⋅   
                                       (4) 
 
 
圖 4.7  各個全向輪速度分解圖 (a)1號 (b)2號 (c)3號 
 
 
圖 4.8  全向輪轉動示意圖 
 
最後則是針對馬達部分建立數學模型，本文使用永磁式直流馬達，其結
構可分為電氣與機械部分，如圖 4.9所示，其中 Ra與 La分別為電樞電阻
及電樞電感；Eb為反電動勢；Cm為黏滯阻尼係數；Jm為轉子慣性矩；σm
與 ωm代表轉子之旋轉角度與角速度；τ為馬達輸出力矩。由直流馬達之簡
化數學模型[2]，我們可以得到馬達輸出力矩 τ與馬達控制電壓 u及轉子角
速度 ωm之關係式，如(5)式所示，其中 Kb為反電動勢常數。 
 45 
 
 
其中 
 
2 2
1 12
2 2 2
22 2
3
2 2
  ;   
3
b b
a a
bb
z az a
n k nka b
R mR RmR
nk Ln k L ba RI RR I R
 − = =  
 
−  ==
   
 
4.3.2  PID軌跡追蹤控制器設計 
為求方便表示，我們將整體系統(7)式表示為 ( )G G G G CP A P B Uφ= +
 
，
並且定義誤差函數  ( ) ( ) ( )d te t P t P t= −
  ，其中 ( )dP t 為欲設計追蹤之命令軌
跡函數，將整體系統代入可得方程式(8)。 
 
( )d G G G Ce P A P B Uφ = − +                                 (8) 
 
(8)式中  ( )e t 為誤差函數，我們將其定義為控制系統之輸入 U(  e U= )，而
由於我們需要藉由控制器來計算給予三顆馬達的控制電壓，故將(8)式整理
後得控制電壓為： 
1( )C G d G GU B P A P Uφ
−  = − − 
 
                            (9) 
 
我們希望設計適當的 U來使得誤差 ( ) 0e t → ，也就是控制電壓 UC令
全向移動載具追蹤軌跡命令。考慮到PID控制具有成本以及不錯的強健性，
故本文選擇以比例-積分-微分控制器(PID controller)來控制輸入 U，藉由調
整 PID控制器的參數(Kp、Ki、Kd)提升載具追蹤軌跡時的效能。故我們將
PID控制器表示為
 p d iU K e K e K edt∫= − − − ⋅ ，將其帶入(9)式即可得 PID
軌跡追蹤控制器，如(10)式。 
 
 47 
 
 
 
圖 4.11  全向移動載具軌跡追蹤實驗架構圖 
 
表 4.1  全向移動載具系統之參數設定 
 
設定
值 
單位 
全向移動載具轉動慣量 IZ 0.4 kg-m2 
反電動勢常數 Kb 0.0172 V/(rad/sec) 
載具底盤中心至全向輪距離 L 0.2 m 
電樞電阻 Ra 0.85 Ω 
全向輪半徑 R 0.05 m 
全向移動載具總質量 m 10 kg 
馬達齒輪比 n 61  
程式單位迴圈時間 30 ms 
 
4.4.1  矩形命令軌跡追蹤實驗 
我們設計矩形命令軌跡先以 YG方向移動 120 cm，接著再以 XG方向移動
120 cm，以此作為矩形邊長環繞一周回到原點位置，路徑總長 480 cm，並
且分別以 10 cm/s與 20 cm/s之行進速度控制載具移動，藉以討論全向移動
載具在直線軌跡上的追蹤能力。結果如圖 4.12所示，可知載具可以確實追
蹤不同速度之矩形軌跡，然而在各個轉角處則具有較大的超越量產生；而
載具在 20 cm/s之命令軌跡中，θ誤差量較大約在±5o，而在 10 cm/s下，則
 49 
 
 
圖 4.13  矩形軌跡追蹤結果  
(a)平面軌跡圖 (d) θ角度-時間圖 
 
4.5 應用-設計使用者介面 
本節針對全向移動載具控制系統在 LabVIEW前面板上開發使用者介面，
並進行實機測試來驗證介面操作性能，其設計概念如圖 14所示，透過使用
者介面可有效簡化載具追蹤之令命軌跡定義方式，我們可以於地圖上利用
拖曳載具圖式或點選目標位置以操作載具移動，藉此取代原本使用設定數
值座標位置的方式，如此使用者便能更靈活的操作全向移動載具行進。而
操作方法住要是先根據室內地形繪出精確尺度之平面地圖，並以固定比例
縮小至面板可觀測範圍，接著使用滑鼠繪出命令軌跡，透過軌跡追蹤控制
器即可有效操作載具移動，且能大幅降低指定命令軌跡之複雜性，關於詳
細設計內容請詳閱[1]。 
 
-0 .1 0 0 .1 0 .2 0 .3 0 .4 0 .5 0 .6 0 .7
-0 .3
-0 .2
-0 .1
0
0 .1
0 .2
0 .3
P ath (m)
X  position (m )
Y 
po
sit
io
n(
m
)
 
 
定義軌跡
T=5s
T=10s
T=15s
T=20s
(a)
0 5 10 15 20 25 30
-10
-5
0
5
10
15
20
25
30
35
40
time(s)
An
gl
e(
de
g)
 
 
T=5s T=10s T=15s T=20s
(b)
 51 
 
出轉速的能力範圍內，皆能正確追蹤到命令軌跡之速度，然而隨著載具追
蹤速度越大，整體系統之追蹤性能也會相對降低；而在互動地圖面板除了
能以圖像顯示的方式提供使用者關於載具移動的資訊外，使用者更可以直
接在地圖上繪出命令軌跡，並經由軌跡追蹤控制器來使載具跟隨我們繪出
的命令軌跡，精實機測試結果顯示載具可以確實追蹤到我們以手繪方式定
義的命令軌跡，並且保持微小追蹤誤差。 
 
4.7 參考文獻  
顧迪, "發展Wiimote室內定位技術與全向移動載具軌跡追蹤控制器與其於
智慧生活之應用," 國立成功大學機械工程系碩士論文, 2007. 
翁義清, "全向移動機器人之路徑追蹤," 國立成功大學機械工程系碩士論文, 
2007. 
Omni wheel, http://en.wikipedia.org/wiki/Omni_wheel 
National Instruments Inc., http://www.ni.com/ 
J. A. Vazquez, M. Velasco-Villa, "Computed-torque control of an 
omnidirectional mobile robot," International Conference on Electrical and 
Electronics Engineering, pp. 274-277, 2007. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 53 
 
5.2  E-Life智慧生活之簡介與應用 
5.2.1  E-Life人本智慧生活簡介 
智慧生活包含數位家庭、自動化醫療照護、以及公共場所之智慧型裝置
與功能，其原理乃是利用微處理電子技術，集中管理與自動控制電子電器
產品及系統，其系統架構由前端控制介面和後台控制主機組成，使用者經
由前端介面下達控制命令，再透過後台控制主機來驅動各項設備。而系統
整合在智慧生活應用中扮演相當關鍵的角色，以智慧居家生活為例，由於
家用產品涉及眾多不同領域的產品，包括燈光、冷氣、音響、電視、電動
百葉窗、電動窗簾等，如果系統未經適當整合，住宅內就會有多支遙控器，
或是複雜的人機控制介面，只會讓使用者感到眼花撩亂；因此，使用者介
面必須操作簡單且功能多元，並且結合無線技術才能實現智慧化居家生
活。 
 
5.2.2  整體研究計畫與方法 
本研究導入Wiimote作為感測硬體核心，由 LabVIEW虛擬圖控平台所
設計之使用者介面以及智慧化遙控方式掌控未來的居家生活。如圖 5.2所示，
機器人身上整合Wiimote控制器與感測元件，作為動態感測載具；感測器
也可以佈置在空間中特定的區域，構成無線感測器網路[4]，所有感測資訊
經由無線閘道器(Gateway)匯整後由 RS-232傳輸至電腦，而Wiimote感測訊
號經由 Bluetooth傳回電腦，統一由演算程式處理各種輸入訊號，將所有資
訊顯示於人機介面。在主控端電腦之軟體程式分成兩部份，一個是所有感
測資訊的顯示與紀錄並在介面上輸入簡單的指令，另一個是較為複雜的計
算與進階的控制功能。而人機介面的環境感測與其它監控資訊皆可透過
web server發佈至 Internet，由遠端用戶或手持設備即可進行操控。 
 
圖 5.2 整合Wiimote系統於智慧生活之情境設計 
 
 
 55 
 
5.3.4  以Wiimote為基礎之無線感測與智慧控制系統 
5.3.4.1  設計原理與應用情境 
本研究係以Wiimote控制器為核心，由主控端電腦輸入指令，經 Bluetooth
傳送至Wiimote，並且由Wiimote內建電路元件之 I/O埠所產生的訊號搭配
多工器，讓使用者可以有更多的指令選擇，訊號經由多工器輸出後觸發後
級裝置。以Wiimote遙控器或手勢變化操控各種裝置，包含機器人之運動
控制與服務動作、開關燈與門窗，未來可結合無線感測器網路來實現家電
與多媒體裝置之開關控制。其設計概念與原理如圖 5.4所示，由遙控器
Wiimote 1 (智慧遙控手把)將控制指令傳回 LabVIEW圖控程式平台，接著
訊號經由電腦下達至Wiimote 2 (Wiimote電路板)，所有訊號傳輸工作都是
以 Bluetooth無線收發，此訊號經由多工器至 BJT電路放大電流後進入驅動
電路駛家用載具或服務機器人開始運動，或操控家中各種裝置。 
 
圖 5.4 Wiimote智慧搖控應用之無線傳輸與運動控制示意圖 
 
 
圖 5.5 改造Wiimote控制器之 SMD LEDs接點以擷取電位差訊號 
 
在Wiimote電路板尾端有 4個 SMD LEDs，原本的功能為顯示Wiimote
控制器的電量，以及代表遊戲進行時玩家的順序。我們將Wiimote內部可
 57 
 
5.4  E-Life應用之實驗展示 
5.4.1  智慧控制之應用展示─以手勢操控全向輪平台為例 
5.4.1.1  設計構想 
目前常見的手勢與動作辨識相關文獻研究，大部分是利用 camera直接
拍攝動作，經過影像處理技術後，藉由電腦辨識待測物姿態所代表的意義
來進行後續指定的動作；或是利用加速規感測器的輸出訊號來判別動作，
經過辨識動作特徵之演算程序，並建立動作軌跡資料庫進行比對識別。如
圖 5.7所示，智慧控制可分成不同的形式，除了以Wiimote直接遙控，以及
利用遠端的方式來操控；本研究發展手勢操控的方式，利用Wiimote camera
感測手指上的 IR光源，經由電腦判斷光源數目以及光源所在的區域進行編
碼，各識別碼代表不同的指令，因此可藉由手勢的變化來控制或觸發生活
週遭的裝置。 
 
 
圖 5.7 智慧控制之構想示意圖 
 
5.4.1.2  實驗展示 
本研究製作在手指上裝有 IR LED的手套，由架設於空間中的Wiimote
來感測手指代表的數字與所在區域，圖 5.8是利用手勢變化實現智慧搖控之
人機介面，在介面右端是代表 16種指令的布林值(Boolean)，演算原理是將
Wiimote camera所觀測之解析度範圍 1024×768像素分割為 4個區域(Ⅰ, Ⅱ, 
Ⅲ, Ⅳ)，在每個區域裡使用者的手指最多能夠顯示 4個 IR LEDs，在 4個
區域總共可以產生 16種變化，因此藉由手指的變化即可產生 16種不同的
指令，使用者只需動一動手指就能無線操控機器人或載具運動，進行服務
性質的工作，例如老人之服務照護、從事簡單的家事工作、或是開關多媒
體與家電裝置等。 
本研究進行的實驗展示是由Wiimote辨識手勢的變化，當使用者的手指在
Wiimote camera的Ⅰ區顯示 1(手指比出 1的動作)，全向輪平台開始前進，
 59 
 
 
圖 5.9 以 LabVIEW程式平台進行遠端監控示意圖 
 
5.4.3  Wiimot系統之擴充感測功能─以Nunchuk控制器整合溫度感測元件
為例 
5.4.3.1  設計構想 
Wiimote控制器內部有一些可以利用的 I/O埠，我們藉由 4個 SMD LEDs
進行驅動與觸發的應用展示。接下來針對 Nunchuk控制器內建的加速度感
測器進行探討與實驗測試。Nunchuk控制器內部的動作辨識感測器是 ST 
Microelectronics生產的 LIS3L02AL三軸加速規，我們希望將此內建加速規
置換為其它應用的感測器，例如溫度、溼度、光度、二氧化碳等用途的感
測元件，首先將此加速規解焊，另外焊上導線連接感測元件與原本加速規
的引腳連接點。 
 
5.4.3.2  實驗展示 
加速規晶片的引腳連接點(Pin connection)主要是 X、Y、與 Z共三軸方
向的電壓輸出 channel可以供其它感測器使用，以本研究的展示是使用
National Semiconductor所生產之 LM35溫度感測元件為展示的例子，圖 5.10
為可擴充之感測系統，本實驗所應用的溫感元件的電壓類比訊號經由 X 
channel輸出，由Wiimote內建 Bluetooth無線傳輸至電腦 LabVIEW程式，
在人機介面上可以觀察到不同類型的感測訊號；如圖 5.11所示，由溫度感
測的人機介面則會顯示目前的溫度相對值，並且可以觀察三個 channels輸
出的感測訊號曲線。 
 
 61 
 
 
圖 5.12 Wiimote結合 Nunchuk之環境感測程式碼(VI) 
 
5.5  結果與討論 
5.5.1  Wiimote系統於智慧生活之延伸應用與情境展示 
本文發展之Wiimote系統可進行多元的智慧生活應用，包含服務機器人
之運動控制、利用手勢控制載具或機器人運動、遠端監控功能、以及結合
Nunchuk控制器之感測元件應用等。以本研究之展示為基礎，能延伸更加
多元完整之未來智慧生活情境與應用。首先，本研究展示利用手勢的變化
完成全向輪平台之運動控制，使用者能輸入 16種不同的運動指令，代表我
們可以利用結合更多 channels之多工器以延伸其它的功能。 
另一方面，本文展示初步之遠端監控功能，將 LabVIEW人機控制與資料顯
示介面發佈於網際網路，使用者能利用遠端電腦或行動上網裝置同步觀測
感測與定位資訊，也可以進一步由遠端操縱控制，因此該展示除了可以讓
使用者不需在家就能操控家中的裝置，掌握環境感測的資訊，另外也可應
用於老人或行動不便者的健康照護功能，Wiimote與 Nunchuk控制器都有
內建 3軸加速規，當控制器本身產生運動或姿態變化，都能在 LabVIEW人
機介面得到加速度變化的資訊，因此假設將Wiimote控制器置於老人與行
動不便之使用者身上，如果使用者因為突發狀況而倒下，其親屬或照護中
心都可以在遠端電腦或行動裝置如 PDA、手機等得知目前發生的狀況，並
且在第一時間緊急救援。 
本研究展示擴充環境感測之應用，將 Nunchuk控制器內建之三軸加速規置
換為溫度感測元件 LM35為展示的例子，本實驗所設計之應用情境是當
LM35感測室內環境溫度超過警示指標時，Wiimote系統自動觸發全向輪機
器人移動至指定區域，因此未來可以置換為使用者所需之感測元件，並且
在程式演算上可以設計不同的回應動作，例如溫度過高或發生火災時，觸
發警報器或蜂鳴器告知住戶，甚至打開自動灑水系統，或是當Wiimote系
統感測室內二氧化碳濃度過高時，自動觸發馬達或致動器將窗戶打開通
風。 
 63 
 
於 2V，因此必須選擇特定規格之感測器以符合控制器原本的電路，也就是
最大的輸出電壓約為 2V；或是利用額外的電路來調整輸出電壓，將電壓工
作範圍能維持於 2V之內。 
本研究進行Wiimote系統整合遠端監控之初步展示，未來希望將遠端監控
之人機介面於 PDA或手機上顯示與操控，該行動裝置必須與 LabVIEW圖
控虛擬平台或其它編譯程式相容，利用客製化的應用模組程式，例如
LabVIEW PDA Module之搭配使用才能真正實現完整終端行動裝置的顯示
監控功能。此外，假設使用者希望利用手機進行遠端監控，必須經由 Android
或Windows mobile平台編譯遠端監控應用程式，始能順利連結Web server
進行遠端監控。 
 
5.6  結論 
本文以Wiimote控制器為基礎，配合感測與遙控演算程式進行人本智慧
生活與居家生活照護等相關應用展示，首先透過實驗驗證其可行性，並說
明Wiimote系統於目前 E-Life應用展示的基礎架構下，未來能夠延伸至完
整的智慧感測系統，工作內容包含家用機器人之運動控制與服務動作、老
人或行動不便者之健康照護、無線環境感測、以及更多元的家庭自動化與
智慧控制技術等，由遠端即可掌握居家狀況，實現更舒適便利的居家生活。 
 
5.7  參考文獻 
陳柏維, "Wiimote紅外線室內定位技術與運動控制應用於機器建築與智慧
生活之研究," 國立成功大學奈米科技暨微系統工程研究所碩士論文, 2010. 
廖珮君, "智慧家庭核心從自動控制技術開始," 全亞文化, pp. 42-45, 2009. 
M. Addlesee, et al., "Implementing a sentient computing system," Computer, vol. 
34, pp. 50-56, 2001. 
J. Yick, et al., "Wireless sensor network survey," Computer Networks, vol. 52, 
pp. 2292-2330, 2008. 
J. C. Lee, "Hacking the Nintendo Wii Remote," Pervasive Computing, IEEE, 
vol. 7, pp. 39-45, 2008. 
LC2MOS±15V 16 Channel High Performance Analog Multiplexer ADG406, 
Analog Device Inc., http://www.analog.com/ 
 
 
 
 
 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 97-2221-E-006-152-MY3 
計畫名稱 模組化無線感測與致動器設計及其智慧化居住空間之應用--子計畫二：壓電載具與智慧化居住空間之感測系統設計 
出國人員姓名 
服務機關及職稱 
陳國聲  國立成功大學機械工程學系 教授 
陳名薪  國立成功大學機械工程學系 兼任助理 
會議時間地點 2011/09/13-18, Tokyo, Japan 
會議名稱 
The 50th Annual Conf. of the Society of Instrument and Control Engineers of 
Japan (SICE 2011) 
發表論文題目 
1. Analysis, Simulation, and Experimental Investigations of a One 
Dimensional Touch Panel Based on Strain Sensing 
2. Wireless Group Manipulation of Autonomously Guided Mobile Robots for 
Smart Living Space Applications 
一、 參加會議經過 
SICE conference的主辦單位為 The Society of Instrument and Control Engineers (SICE), 
Japan。此會議每年都會舉辦一次，而本人之研究生(陳柏維)在去年第一次參加此會議並發表
論文，當時是在台北圓山飯店舉行，經研究生口述後得知獲益良多。今年則在東京早稻田大
學舉行，本人與一名研究生(陳名薪)參與此會議，並發表兩篇論文進行口頭報告。時間是 9
月 13日~ 9月 18日，由高雄國際機場出發至成田機場，再搭乘當地交通工具至新宿，期間往
返早稻田大學參與會議，會議結束後，經由成田機場返國。 
本人發表的時段在 9月 16日(五)下午，發表之論文 Analysis, Simulation, and Experimental 
Investigations of a One Dimensional Touch Panel Based on Strain Sensing，以 oral方式呈現，與
現場有興趣之與會各國先進有相當的討論，也身受肯定。整體而言，各先進的意見與指正，
對於本人在相關後續研究方面，有相當重要的幫助。本篇論文預計經擴展後, 投稿於國際知
名期刊 Mechatronics. 
本人之研究生發表的時段在 9月 16日(五)下午，發表之論文Wireless Group Manipulation 
of Autonomously Guided Mobile Robots for Smart Living Space Applications，亦以 oral方式呈
現，在現場被主持人與有興趣之先進問了許多相關問題並有相當的討論。此舉為鼓勵學生參
與國際會議，增進國際視野，並對日後研究有所幫助。本篇論文預計經擴展後, 投稿於期刊 
International Journal of Automation and Smart Technology (AUSMT). 
三、 附件 
 
陳國聲 教授 
 
 
陳名薪 兼任助理 
 
 
 
 
 
 
 
 
 
 
 
Paper Number: 078 
Paper Title : Wireless Group Manipulation of Autonomously Guided Mobile Robots for Smart 
Living Space Applications 
Authors : Ming-Hsin Chen, Kuo-Shen Chen 
  
Dear Mr. Ming-Hsin Chen 
  
It is our pleasure to inform you that the paper referenced above, for which you are listed as the 
corresponding author, has been accepted for presentation at SICE2011, SICE Annual Conference, to 
be held in Tokyo, JAPAN, September 13-18, 2011. 
  
Presentation Style: Oral 
The session that your paper is allotted to can be seen in the advanced program that will be released 
in the middle of July. 
  
Reviewers' comments and Track chairs' summary are attached below. The final manuscript (PDF) 
must be prepared in accordance with their comments. In particular, any critical comments should be 
adequately addressed. 
  
Electronic submission of the final paper is due by June 20, 2011 through the website: 
<https://www.gakkainet.org/SICE2011/> 
Final submission and registration sites will open on June 5. 
  
The acceptance is made provided that the final paper submission is done adequately. Otherwise the 
paper will not be included in the final program. 
  
The standard length of the final paper should be 6 pages. But, 2 to 10 page papers are also allowed. 
Papers of more than 6 pages require extra page charges of 10,000JPY for each extra page. 
  
Any final PDF paper that exceeds 10 pages and/or 4MB will not be accepted by the submission web 
site. The final submission process also requires you to input the brief abstract (plain text) within 100 
words directly to the text box at the submission site. 
  
Note the following important points when submitting your final manuscript. 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Analysis, Simulation, and Experimental Investigations of  
a One Dimensional Touch Panel Based on Strain Sensing 
Chia-Hsing Pi, Kuang-Shun Ou, Ming-Hsin Chen and Kuo-Shen Chen 
Department of Mechanical Engineering, National Cheng-Kung University, Tainan, Taiwan 
(Tel: +886-6-275-7575 ext. 62192; E-mail: kschen@mail.ncku.edu.tw) 
 
Abstract:In this work, a 1-D touch panel based on strain sensing has been designed and realized as a preliminary test 
protocol for evaluating smart floor tilesconcept used for indoor localization.  By integrating the strain sensing 
technique and elementary beam theory, it is possible to estimate the force-applied location based on strain gauge outputs.  
Detail 3D finite element analyses have been conducted to evaluate the design concept and to quantify the influence of 
various possible practical considerations such as boundary conditions and sensor gain differences, as well as attachment 
and alignment errors during assembly.  It is found that the 1-D beam design approach agrees with the 3D finite element 
simulations very well except the portions near both beam ends.  The experimental results indicated that under an 
applied force of 1N, the effective zone is near 70% and the spatial resolution is between ±0.21 ~ ±0.37 cm. This 
resolution is sufficient for a finger touch device and is much higher for smart floor applications. Currently, with the 
lesson learned, investigations on a 2D strain sensing panel is currently proceeded to serve as the basis for more realistic 
smart floor tile designs currently underway for smart building applications. 
Keywords: Touch panels, strain sensing, localization, beam theory, finite element analysis 
 
1. INTRODUCTION 
Touch panels have been widely used in many 
applications as an interface between machines and 
operators for enhancing the user friendliness. By utilizing 
sensing mechanisms such as resistive and capacitive type 
transductions and using modern microfabrication 
technology, touch sensors have been miniaturized and 
integrated into a sensing array on a panel for accurate 
localization for human-machine interface of mobile 
electronic devices [1,2,3]. 
Strain sensing is a typical resistive sensing scheme and 
has been extensively used for structural health monitoring 
and force transducers.  The elastic deformation caused 
by an external load changes the resistance of strain 
gauges attached on the structure. As schematically shown 
in Figure 1, in conjunction with subsequent Wheatstone 
bridges, as well as the associate amplification and 
filtering circuits, it is possible to measure the local 
stress/strain status[4]. By integrating the strain sensing 
technology with solid mechanics, a strain sensing-based 
touch panel concept is proposed and demonstrated. 
Previous example utilized strain-gauge based load cells to 
monitor the reaction force and subsequently to estimate 
the location and has been successfully demonstrated [3].  
However, in that design, the reaction moment is not 
allowed due to restrictions from the rigid body model and 
this implies that the boundary support may not be 
sufficient.In this approach, the force-applied location is 
estimated by the strain gauge outputs based onmechanics 
of materials and can handle more complicated boundary 
conditions or designs.Although this methodcannot match 
the resolution of the state-of-the-art array type panels, its 
simpler structure and the ability of being applied in larger 
area implies that this method could be possibly used in 
intelligent life related applications[5] such as smart floors 
smart for floor-based indoor localization applications, 
where the resolution is not a critical concern due to its 
larger length scales and the state-of-the-art sensing array 
based technology adequate for mobile electronics are 
 
Fig. 2 Schematic plot of a fixed-fixed beam subjected to a 
concentrated loading to show the bending moment of 
both ends. 
 
Using this manipulation, the force applied location can 
be determined. This result is independent from the level 
of force applied. It is convenient to define the voltage 
ratio in Eq. (6) as a dimensionless variable Θ for use as 
the performance index, i.e.,Θ≡VB/VA+VB and a Θ*, 
denoted as complementary Θ, hereafter as 
Θ∗ = 1 −Θ = 𝑉𝐴
𝑉𝐴+𝑉𝐵
.              (7) 
forthe purpose of future performance evaluation.  By 
using Θ and Θ*, the location to be found can be 
expressed as  
a=LΘ(8a) 
or 
a=L(1-Θ*).   (8b) 
Eq. (8) serves as the fundamental basis of the 1-D 
touch panel design.  Theoretically, using the output of 
the two strain gauges and Eq. (8), the load applied 
location can be determined, independently of the level of 
force applied. 
The above relationships are developed based on 
elementary beam theory.  In reality, the complicated 3D 
stress distribution as well as the possible stress 
concentration near both ends could make the beam 
theory’s prediction deviates considerably from the real 
scenario. In addition, the possible gain differences and the 
alignment errors of the strain gauges could also provide 
additional sources of error for the above model.  As a 
result, extensive 3D finite element analyses (a model 
shown in Figure 3) have been conducted to evaluate the 
feasibility of the design concept [7].  Figure 4 shows the 
relationship between Θ and the nondimensional 
force-applied location x* (i.e., x/L). It can be seen that 
once the location is away from both ends, the FE 
simulation results agrees with Eq.(8) very well and this 
implies that the above design methodology is adequate.  
On the other hand, as the force-applied location moves 
toward both ends, the beam assumption is not longer 
valid and the model described above breaks down. 
Meanwhile, although not shown in this work, the 
simulation results also shown that the gain and alignment 
errors of strain gauges only induce minor influence on the 
final performance.  
(a) 
 
(b) 
 
Fig. 3 Schematic plots of the finite element models (a) 
mesh schematic (b) σxx contour (deformation scale up 
with a factor of 5). 
On the other hand, the spatial resolution is also an 
important performance index, which can be evaluated 
based on the uncertainty propagation of Θ and is 
schematically shown in Figure 8a.  The uncertainty of Θ 
mainly comes from the signal to noise ratio of the strain 
gauge outputs.  By treating those outputs as random 
variables and finding the corresponding standard 
deviations, followed by standard error propagation 
analysis [4], the standard deviation of Θ can be obtained.  
In this work, a ± two standard deviation zone (i.e., 95% 
confidence level) is selected for evaluating the spatial 
resolution. As shown in Figure 8b, the spatial resolutions 
at center and edge can be found as ±0.21 and ±0.37 cm, 
respectively. Such a resolution should be sufficient for 
finger touch application and should be able to satisfy the 
requirement for future smart floor applications, where the 
panel size is much larger but the required spatial 
resolution is also less critical. 
(a) 
 
(b) 
 
Fig. 8 (a) Schematic plot for determining the device 
spatial resolution and (b) The experimental output index 
with 90% confidence level versus load applied locations 
4. DISSCUSSION 
In this work, the strain sensing-based touch sensing is 
analyzed, designed, and realized via a 1-D test panel. The 
effective length is approximately 70% based on a 
reasonable touch force.  With a spatial resolution of 
±0.21- ±0.37 cm, this design should be useful for simple 
touch screen application and the future smart floor 
applications. 
Based on the same approach in this work, a 2D strain 
sensing-based touch panel is currently underway.  As 
shown in Figure 9, this design utilizes the sensor outputs 
of four strain gauges and uses plate theory[8]to inversely 
estimate the force-applied location.  In this work, 
however, we found that the geometric nonlinearity of 
clamped plate restricts the achievable spatial resolution 
and a recursive numerical analysis scheme is proposed to 
enhance the spatial resolution of the 2D touch panel.  
Finally, a smart floor concept design is proposed in 
Figure 10, this smart floor consists of numerous floor tiles, 
each containing a few sensors.  Once an object is located 
on a tile, its global location can be determined by 
examining the location of the responding tile and its 
location within the tile (i.e., the local location) by strain 
sensing. 
 
Fig. 9 A picture of the 2D touch panel test system. 
 
Wireless Group Manipulation of Autonomously Guided Mobile Robots for Smart Living 
Space Applications 
M.-H. Chen, D. Gu, Y.-D. Fu, C.-H. Pi, K.-S. Ou, and K.-S. Chen 
Department of Mechanical Engineering, National Cheng-Kung University, Tainan, Taiwan 
(Tel: +886-6-2757575 ext.62192; E-mail: kschen@mail.ncku.edu.tw ) 
Abstract: In this work, by integrating omni-wheel mobile robots with X-Bee communication protocol, Arduino control, 
IR range finders, and CMOS camera, as well as wiimote multi-zone localization, tasks such as obstacle and collision 
avoidances, following, autonomously movement, and indoor localization of group robots are implemented as the first 
step toward an autonomously control of group robots for smart living space applications. In conjunction with hardware 
design, novel algorithms are developed for successfully realizing and demonstrating these tasks. With these key issues 
being solved, more realistic scenario can be designed for achieving the real group robot applications for indoor service 
in the future. 
Keywords: Autonomously Guided Motion Control, Mobile Robots, Arduino, X-Bee, Group Manipulation 
1. INTRODUCTION 
To understand and utilize the advantage of group 
movement and cooperation of biological system are long 
term pursuit by researchers in different aspects. For 
robotics and artificial intelligence fields, by coordinating 
and cooperating of large individual robots, complicate 
tasks can be fulfilled. In addition, through proper 
networking and communication, these robots can 
exchange their information and learned from peers and 
the environment for tackling more complicated tasks, 
which cannot be done by single or ungrouped robots.  
Consequently, it is possible to gain particular advantages 
by applying the bio-inspired nature into the field. As a 
result, several research laboratories have been deeply 
engaged into the study for autonomously manipulation of 
robot groups for specific applications by investigating in 
virtually all aspects of mobile robots including remote 
motion control, navigation, and speech recognition. 
Previously, Rooker and Birk [1] utilized wireless 
communications between two robots to establish 
environmental map for robot manipulations. The ability 
to manipulate a robot group enables new applications for 
automatic indoor landscape arrangement and human 
machine interactions, or for the smart architectural 
technology; it might require coordination and group 
manipulation of multiple mobile robots. This work is 
inspired by the behavior of natural biological animal 
groups, in which the individual member could either have 
their own intelligent and information to perform motion 
and decision making based on their own information or to 
exchange information and perform group motion for 
finishing a cooperative task. The bio-mimic approach 
could potentially leads to a large scale integration of 
robotic members to form a massive group for performing 
complicated tasks. 
In order to pursue the goal mentioned above, several 
important fundamental tasks must be established and 
realized. These fundamental issues including: collision 
avoidance, global localization, obstacles avoidance, and 
group manipulations. For obstacle avoidance, most 
widely used technique is to utilize the information 
observed by external-mounted CCD cameras for 
subsequent trajectory planning [2,3] or by sensor 
mounted on robots themselves [4]. Both approaches have 
their own advantages and disadvantages. For example, the 
former approach can obtain the global status of the robot 
group but it cannot mimic the autonomous behavior of 
individual elements. On the other hand, the latter one can 
of object recognition. Next, wiimotes and their 
corresponding IR LEDS are also installed on the ceiling 
and the robots for globally monitoring the absolutely 
location of these robots.  In together with the multi-zone 
localization technique developed by us [5], this provides 
the global position information for external supervisor on 
future task planning and control. Finally, the interaction 
between the robot group and the external human 
supervisor is established between the host computer and 
either the master robot (group mode) or all robots 
(individual mode) by using a graphic user interface 
written under a LabVIEW environment. The entire 
functional block diagram is shown in Figure 2. 
 
Fig. 2 The functional block diagram of the entire work. 
3. EXPERIMENTALSETUPAND 
ALGORITHMS DEVELOPMENT 
Various fundamental benchmark problems have been 
experimentally demonstrated to allow us to evaluate the 
overall performance and to examine the possible faults in 
recognition and communications between objects, as well 
as to refine the manipulation schemes. By such efforts, 
the above mentioned tasks are successfully demonstrated. 
The performance measured and lesson learned could be 
very valuable for future large scale integration. 
Obstacle avoidance: 
As mentioned earlier, an algorithm is proposed to 
perform the obstacle avoidance. The algorithm is briefly 
illustrated in Figure 3, the mobile robot is initially motion 
in a straight manner and the IR range finders scan with a 
rotating speed approximately 33.33 rpm to continuously 
search for possible obstacles. The scanned area was 
divided into four zones and the coordinates of the 
possible obstacles are (di, θi) (i=1~4). If there are any di 
less than its pre-defined threshold value dti, the obstacle 
avoidance mode is then activated. A weighting index pi 
(i=1~4) is then assigned based on di and it reflects the 
obstacle presence distributions. Based on pi and θi, the 
algorithm determines the velocity gains g1and g2 and the 
possible orientation modification for the next step. By 
such a dynamic scanning manner, the trajectory of the 
robots will be evaluated and updated after each motion 
step. Previous work[4] used ultrasonic sensor for obstacle 
detection but it cannot precisely determine the obstacle 
location and the robots would be difficult for making 
following up decisions. On the other hand, this approach 
can precisely determine the obstacle location and 
promptly response it during the next step. 
Fig. 3 Brief flowchart of the obstacle avoidance 
algorithm. 
Following: 
As mentioned earlier, each robot equips with a set of 
IR LEDs and a CMOS IR camera with a resolution of 
1024×768 for detecting the presence of nearby robots. By 
recognizing the image pattern of IR LEDs, each robot can 
distinguish its neighborhood. Also, by evaluating the 
coordinates of these LEDs, it is possible to calculate the 
relative distance and orientation between two robots and 
performing following motions. A following algorithm is 
developed and briefly illustrated in Figure 4. The first 
phase is to search the master robot. We divide the visible 
area of the CMOS camera to five zones, denoted as qi, 
i=1~5. Meanwhile, the motor scanning angles are also 
partitioned into three different sets j, j=1~3. Hence the 
total visible area is organized as 15 zones and a weighting 
index Cij is assigned for each zone. Once an object is 
(a)  
(b)
 
Fig. 6 Obstacle avoidance demonstrations 
Collision avoidance between two robots: 
In a multi-robot workspace, collisions between two or 
more robots must be prohibited and this issue is 
investigated here. This can be treated as a dynamic 
situation of the above obstacle avoidance problem. As 
shown in Figure 7a, two mobile robots approach each 
other. Once the relative distance is within the threshold, 
both robots will make decisions to avoid collisions based 
on the obstacle avoidance algorithm addressed above. 
Following: 
Following between a group of slave robots and a 
master robot is a fundamental technical ability for 
subsequent realization in autonomous motion control of 
group robots. Figure 7b demonstrates the results of our 
algorithm in robot following. The master robot performs a 
general planar motion and followed by a slave robot. As 
one can see, the slave robot follows the path of the master 
robot very well. 
(a)
 
(b)
 
Fig. 7 Interactions between two robots (a) collision 
avoidance and (b) following motion 
External group control: 
In this experiment, the host broadcasts a massage to all 
three mobile robots and asks them moves toward their 
corresponding destinations. The results are successfully 
shown in Figure 8 and the result indicates that it is 
possible to simultaneously control a large number of 
robots for real applications (such as smart building 
elements) by just sending an information package while 
the bandwidth can still be maintained. This would be very 
useful for smart building applications where a large 
number of building element must be moved to specific 
locations for fulfilling the functional requirements.  
 
Fig. 8 An external group control demonstration 
Autonomously movement: 
Finally, autonomously movement experiments are 
performed based on the above established technical 
capabilities. Four our mobile robots are designed to 
perform three tasks. First, we allow these four robots 
moves freely with collision free in the workspace as 
shown in Figure 9a. Next, as shown in Figure 9b, with 
one robot serves as the master, all other slave robots 
moves toward the master once they are asked. Finally, 
these slave robots follow the master to form a following 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/12/21
國科會補助計畫
計畫名稱: 子計畫二：壓電載具與智慧化居住空間之感測系統設計
計畫主持人: 陳國聲
計畫編號: 97-2221-E-006-152-MY3 學門領域: 其他自動化技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
2009 年首爾國際發明展金牌及三國特別獎. 
 
2009 年東元創意競賽亞軍 
 
2009 年立委創意優選 
 
2011 意法半導體校園創意競賽亞軍 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
