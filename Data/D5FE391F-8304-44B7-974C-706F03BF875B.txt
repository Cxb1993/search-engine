 1
行政院國家科學委員會專題研究計畫成果報告 
結合粒子群最佳化資料挖掘和近似分析技術的全域最佳化方法 
Global optimization using particle swarm optimization, data mining and approximate 
analysis technique  
計劃編號：NSC96-2221-E-005-079 
執行期限 : 96 年 8 月 1 日至 97 年 7 月 31 
主持人：陳定宇 教授 國立中興大學機械工程學系 
一、中文摘要 
粒子群演算法對各類問題，皆能表現出一定
的求解能力，而且它的觀念簡單易用且程式撰寫
容易，為多個粒子同時搜尋，所以有較大的機會
找到全域最佳解。雖然粒子群演算法具備了上述
幾項優點，但是，由於每代皆需計算各粒子的適
應值，計算次數繁多，而且對於參數的設定非常
地敏感。有鑑於此，本計畫針對粒子群演化法之
流程參考相關文獻並稍作改變，使得粒子群演算
法在結果的收斂上更具優勢，本計畫的主要改進
的方法包括：應用均勻設計的概念使得初始的粒
子可以更均勻地分佈在空間上；利用突變增加粒
子之間的差異性與多樣性；利用適當控制的最大
速度限制及慣性權重控制，達到區域搜尋與全域
搜尋的效果；利用區域強化搜尋針對粒子附近地
區，再作進一步的搜索以得到更佳之結果；將各
種方法綜合後配合粒子群演算法使用，可以得到
不錯的結果。 
另外，由於一般的粒子群演算法，求解最佳
化設計問題時，作完一次完整的搜尋，只能得到
一個解；為了處理多極值問題，本計畫也發展出
多極值搜尋機制，使得粒子群演算法對多極值問
題也可以從一次求解中得到多個解，以彌補一般
粒子群演法在此方面的不足。 
關鍵詞：粒子群演算法、全域最佳化 
 
Abstract 
The particle swarm optimization (PSO) 
method has good performance and is easy to be 
programmed. Since it uses multiple particles to 
search the optimum solution, it has the better 
chance to find the global solution. Although it has 
those advantages mentioned, it consumes a lot of 
computational time to compute the fitnesses of 
particles. In addition to that, some parameters in 
PSO may affect the solution significantly. 
According to this understanding, this project tries to 
modify PSO algorithm in order to improve its 
quality of solutions. The main approaches include: 
using uniform design to ensure the uniform 
distribution of initial particles in the design space, 
adding mutation operation to increase the diversity 
of particles, decreasing the maximum velocity 
limitation and the velocity inertia automatically to 
balance the local and the global search efforts, and 
 3
)1()()1( ++=+ kvkxkx dididi            (2) 
本計畫利用 Liang 等人[6,7]的文獻中所用的
粒子群演算法的流程作為主體，並配合本計畫所
討論的幾項方法，進行題目的測試與分析，其流
程大致如圖 1 所示。本文將介紹以下幾個方法配
合粒子群演算法使用： (A)均勻設計，(B)突變概
念的應用，(C)最大速度限制與權重係數之控制，
(D)區域搜尋之應用與控制，(E)多極值搜尋機制。 
( )1( 1) ( ) 1 ( ) ( )d d d d di i i i iv k v k c rand pbest k x kω+ = × + × × −
( 1) ( ) ( 1)d d di i ix k x k v k+ = + +
( )max max( 1) min ,max( , ( 1)d di iv k V V v k+ = − +
( )2 2 ( ) ( )d d di ic rand gbest k x k+ × × −
d D<
i ss<
( ) ( )( 1) ( )i iFit x k Fit pbest k+ < ( 1) ( 1)i ipbest k x k+ = +
( 1) ( 1)igbest k x k+ = +
( ) ( )( 1) ( )iFit x k Fit gbest k+ <
圖 1 粒子群演算法流程圖 
(A) 均勻設計 
均勻設計是由 Fang 和 Wang 於 1980 年所提
出[8]，二十多年來，這個理論已經被成功地利用
在諸多如：化學、化學工程、製藥、品質工程等
不同的領域上。均勻設計是一種實驗設計的方
法，適用在具有多變數(factor)、多水準(level)的
設計實驗場合，它強調實驗點的「均勻分散」性
質，也就是說各實驗點可以均勻地分佈在預設的
高維度空間裡，讓有限的數據也可以達到令人信
賴的結果，因此可以大幅減少實驗的次數。 
由 Zhang 等人[9]的文獻，假設有一個均勻矩
陣 ( )sNU q ，令 1 2( , ,..., )i i i isu u u u= (1 i N≤ ≤ )，即矩陣中的元
素值，藉由公式(3)可以得到介於 0 ~ 1 之間的一
組數值 1 2, ,..., Nz z z 。 
1 2 2 12 1 2 1, ,...,  ; 1
2 2 2
ii i
i suu uz i N
q q q
⎛ ⎞−− −= ≤ ≤⎜ ⎟⎝ ⎠
         (3) 
利用這一組數值，可以應用在設定初始值的
步驟上，N 個實驗點的初始位置 1x , 2x ,…, Nx ，可以
表示成(3.4)式的型式： 
1 2
1 1 1 2 2 2
2 12 1 2 1( ), ( ),..., ( )
2 2 2
        ; 1
ii i
i s
s s s
uu ux lb ub lb lb ub lb lb ub lb
q q q
i N
⎛ ⎞−− −= + − + − + −⎜ ⎟⎝ ⎠
≤ ≤
   (4) 
其中， slb 及 sub 分別代表各變數的上、下限
值， s 為設計變數的數目， q 為分割變數範圍的
水準數，如圖 2 所示為在[0, 1]之間的設計變數範
圍，分割為 5 個水準的示意圖。粒子群演算法的
初始值透過均勻設計的概念，產生粒子初始的位
置，依據相應的均勻矩陣 ( )sNU q 以及公式(3)、公
式(4)式，產生粒子初始的位置 0x 。均勻設計的概
念主要應用在產生粒子的初始位置，旨在力求各
粒子的均勻分散性。 
表 1 為應用均勻設計產生初始粒子之粒子群
演算法與應用 Liang 等人[6,7]的文獻中所用的亂
數產生初始粒子之粒子群演算法(Modified PSO)
所作的比較。 
 
 
圖 2 水準分割示意圖 
表 1 均勻設計粒子群演算法之初始參數設定 
 
 5
表 3 均勻設計粒子群演算法應用突變機制
的最佳化結果 
 
表 4 均勻設計粒子群演算法應用突變機制
的最佳化結果 
Function crP = 0.01 crP = 0.0001 
Branin RCOS 0.39789E+00 ± 
0.00000E+00 
0.39789E+00 ±
0.00000E+00 
Shubert -0.18673E+03 
± 0.77628E-13 
-0.18673E+03 
± 0.50203E-13 
Michalewicz -0.18013E+01 
± 0.12863E-14 
-0.18013E+01 
± 0.13019E-14 
Colville 0.18742E-02 ± 
0.17988E-02 
0.16567E-02 ±
0.15891E-02 
Spherical 0.23454E-25 ± 
0.77061E-25 
0.59149E-29 ±
0.19415E-28 
Quadric 0.36337E-06 ± 
0.73292E-06 
0.97486E-07 ±
0.24580E-06 
Rosenbrock 0.43147E+01 ± 
0.12836E+01 
0.39837E+01 ±
0.11051E+01 
Griewank 0.87894E-01 ± 
0.27405E-01 
0.67174E-01 ±
0.27187E-01 
Rastrigin 0.45772E+00 ± 
0.69531E+00 
0.93526E+00 ±
0.12959E+01 
Schwefel 0.39638E+03 ± 
0.16730E+03 
0.44415E+03 ±
0.14878E+03 
 
(C) 最大速度限制與慣性權重之控制 
最大速度限制 maxV 與慣性權重ω在粒子群演
算法的過程中，兩者對最後結果有一定程度的影
響力，透過適當的設定 maxV 和ω，將可以使粒子
群演算法達到全域搜尋或區域搜尋這兩種不同的
結果。在理想狀態下， maxV 在粒子群演算法的搜
尋過程中，必需呈現為遞減的狀態。假設以等比
遞減的型式而言，倘若 maxV 在搜尋的流程當中每
一代皆遞減一次，這將導致 maxV 收縮得太快而很
趨近於 0，因此粒子群很快地停滯不前，反而阻
礙了搜尋。Fourie 和 Groenwold[10]提出了以下的
方法： 
(1) 設定初始的最大速度限制
0max
V 。 
 
0max ub
( )lbV x xγ= × −                 (5) 
其中，百分常數 1γ < ， ubx 、 lbx 為變數的上、
下限值。 
(2) 每隔 h代，更新完 gbest 之後，將目前的
gbest 的適應值與前h代 gbest 的適應值互
相比較，如果沒有改善，則依照(3.7)式進
行縮減 maxV 。 
                              
                                  (6) 
 
其中，β為 0 ~ 1 之間的常數，用以縮減 maxV ，
為了避免 maxV 縮減的速度過快， β 的值應該設定
在 0.9 以上。 
Function crP = 0.1 crP = 0.01 
Branin RCOS 0.39789E+00 ± 
0.24853E-06 
0.39789E+00 ± 
0.00000E+00 
Shubert -0.18673E+03 ± 
0.74392E-03 
-0.18673E+03 ± 
0.95879E-13 
Michalewicz -0.18013E+01 ± 
0.32464E-06 
-0.18013E+01 ± 
0.11542E-14 
Colville 0.12352E+00 ± 
0.93283E-01 
0.87533E-02 ± 
0.81858E-02 
Spherical 0.23033E+01 ± 
0.11620E+01 
0.46770E-08 ± 
0.12419E-07 
Quadric 0.19339E+02 ± 
0.77294E+01 
0.40318E-02 ± 
0.38739E-02 
Rosenbrock 0.73006E+01 ± 
0.12718E+01 
0.48818E+01 ± 
0.11339E+01 
Griewank 0.92509E+00 ± 
0.76627E-01 
0.10484E+00 ± 
0.58565E-01 
Rastrigin 0.16294E+02 ± 
0.53982E+01 
0.29101E+00 ± 
0.55723E+00 
Schwefel 0.40637E+03 ± 
0.17147E+03 
0.33281E+03 ± 
0.12033E+03 
1max max
 ( ( )) ( ( ))
     
k k
if F gbest k F gbest k h then
V Vβ+
≥ −
= ×
 7
(D) 區域搜尋之應用與控制 
粒子群演算法搜尋的過程中，常有粒子停滯
不前的現象產生，此種狀況可能是因為粒子受到
gbest 落入區域極值的影響，或者是因為粒子的速
度趨近於 0 所造成，有鑑於此，必需設法找出讓
粒子重新活動的方法。為了增加粒子群演算法的
搜尋能力，與增加各粒子之間的變異性，本文將
利用「常態分布」的亂數，分別於各粒子附近的
位置作較密集的搜尋，嘗試是否能找出比目前位
置擁有更佳適應值的位置。 
常態分佈(Normal distribution)，又可稱為高
斯分佈 (Gaussian distribution)，是一種連續性
(continuous)的亂數分佈[12]，常態分佈的特性為
大部分的實驗值落在平均值附近，僅有極少數的
極端值。常態分佈的機率密度函數(probability 
density function)如公式(11)所示。 
2
2
( )
21( )           
2
x
f x e x
μ
σ
σ π
−−= −∞ < < ∞        (11) 
 
其中， x為一連續變數， μ−∞ < < ∞， 0σ > ,一
般表示成 2( , )N μ σ ，μ為隨機變數的平均值，又稱
為數學期望值，σ 為隨機變數的標準差。依據公
式(11)可以畫出常態分佈的圖形，如圖 3 所示，
常態分佈曲線為左右對稱，且呈現鐘形 (bell 
shape)，其中實線為標準的常態分佈(期望值為
0，標準差為 1)。 
 
圖 3 常態分布亂數機率密度函數圖 
區域強化搜尋主要是為了因應粒子群的
gbest 在經過了若干代都沒有改善的情況下，將常
態分佈的亂數應用在搜尋粒子附近的地區，除了
可以增加變異性之外，也可能改善 gbest 停滯不
動的情形。具體的作法如下： 
(1) 若經過 h代 gbest 都不見改善，則依照公式
(12)，利用常態分佈的亂數在各個粒子附
近的區域產生m個新粒子。 
 
( , ) = ( , )
 ( , ) 0.3
p
p
x i d x i d x
x NR x i d
+Δ
Δ = × ×              (12) 
其中， px 為粒子原始的位置， NR 為常態
分佈亂數。 
(2) 計算這m個新粒子所在位置的適應值，並
與原始粒子所處位置的適應值比較，如果
m個粒子中有一個粒子的適應值比原始粒
子還要好，那麼就將原始粒子替換成這個
擁有最佳適應值的粒子，否則，保留原始
粒子。 
(3)如果原始粒子被取代了，原始的粒子速度
依照公式(13)稍作修改，成為目前粒子的
速度。 
max max
( , )  ( , )  ( ( , ) -  (1, ))
             - ( , )
pv i d v i d x i d x d
V v i d V
= +
< <
        (13) 
其中， (1, )px d 為被取代掉的原始粒子。 
(4)將新粒子之適應值與被取代的原始粒子之
pbest 適應值及粒子群的 gbest 適應值作比
較，並更新 pbest 與 gbest。 
利用常態分佈亂數來搜尋粒子週邊的區域，
於(12)式中亂數 NR 乘上粒子的位置之後再乘上
0.3 的緣故，是因為標準的常態分佈亂其分佈範圍
為[-3, 3]，雖然大部分的數值集中在 0 附近，但難
免有極端的數值產生，為了避免喪失於粒子附近
搜尋的本意，所以最後再乘上 0.3 作調整，因此
經過公式(12)的運算過後，粒子將不會脫離原來
的位置太遠。 
在公式(13)中，新粒子的速度並非採隨機產
生，而是以被取代掉的原始粒子之速度稍作修
改，原因是想保留原始粒子速度部分特性，以避
免太大之改變，初始參數設定如表 8 所示。 
 
 9
( )
( )
1
2
( 1) ( ) 1 ( ) ( )
                                2 ( ) ( )
d d d d d
i i i i i
d d d
i c i
v k v k c rand pbest k x k
c rand gbest k x k
ω+ = × + × × −
+ × × −
(2)針對每一個粒子，計算它目前所處位置的
適應值。 
(3)分別將每個粒子目前位置的適應值，與它
的 pbest 適應值作比較，如果目前位置的
適應值比它的 pbest 適應值還要好，那麼
就將 pbest 的位置代換成這個粒子目前所
處的位置，並且記錄下來。 
(4)將所有粒子的 pbest 之適應值由最佳至最
差排序，選出前 gN 個擁有最佳適應值的粒
子，即 gN 個 gbest，找出其相對應索引號
碼(index)，並更新 gbest。 
(5)更新粒子的速度與它們的位置之前，計算
各粒子與所選出來的 gN 個 gbest 的距離，
並讓粒子選擇跟隨距離最近的 gbest。將
決定跟隨的 gbest 記為 ( )dcgbest k ，並利用公
式(14)及公式(15)來更新粒子的速度及位
置。 
                                   (14) 
 
)1()()1( ++=+ kvkxkx dididi             (15) 
(6)若繁衍代數已到達 bk ，則每隔h代開始比較
gN 個 gbest 適應值之間的差值，由於 gbest
是經由排序過程所選出來的，所以當第 j
個 gbest 適應值與第 1j + 個 gbest 的適應
值，兩者的差值超過了所設定的 err 值，
那麼就只留下前 j 個 gbest 應用到下一次
的速度與位置更新，如公式(16)所示。 
1  ( ) ( )    
  
j j
g
if fit gbest fit gbest err then
N j
+ − >
=
    (16) 
(7)如果達成收斂條件(如：目前適應值與前幾
代相比，誤差小於預先設定的數值，或者
經已達到最大的繁衍代數)，搜尋即告終
止；若尚未達到收斂之條件，則回到步驟
(2)繼續搜尋之工作，一直到達成收斂條件
為止。 
多極值搜尋機制的流程大致上可以圖 4 所
示，接下來將針對 Branin RCOS Function 與
Shubert Function 作測試與討論。 
 
( )
( )
1
2
( 1) ( ) 1 ( ) ( )
                               2 ( ) ( )
d d d d d
i i i i i
d d d
i c i
v k v k c rand pbest k x k
c rand gbest k x k
ω+ = × + × × −
+ × × −
( 1) ( ) ( 1)d d di i ix k x k v k+ = + +
( )max max( 1) min ,max( , ( 1)d di iv k V V v k+ = − +
d D<
i ss<
bk errgN
bk k≥
cgbest
1  ( ) ( )    
                  
j j
g
if fit gbest fit gbest err then
N j
+ − >
=
 
圖 4 多極值搜尋機制之粒子群演算法流程 
 
利用均勻設計的粒子群演算法為主體，應用
多極值搜尋的機制，對 BraninRCOS Function 與
Shubert Function進行10次的測試，並將最後 gN 個
gbest 與其適應值列出，初始參數設定如表 10 所
示。 
 
 
 
 
 
 11
 
 
 
 
 
1 
5.482864 
-7.708314 
5.482864 
-7.708314 
-7.708314 
-7.708314 
-7.708314 
5.482864 
-7.708314 
-7.708314 
-1.425128 
-1.425128 
-1.425128 
-7.708314 
4.858057 
-7.083506 
4.858057 
-7.083506 
-7.083506 
-7.083506 
-7.083506 
4.858057 
-7.083506 
-7.083506 
5.482864 
5.482864 
5.482864 
-7.083506 
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
-0.186731E+03
 
表 12(b) 多極值搜尋之 Shubert Function 測
試結果 
Simulations 解的個數 最終 gN 數 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
3 
3 
3 
2 
4 
2 
5 
3 
3 
4 
20 
20 
20 
20 
20 
20 
20 
20 
20 
20 
 
表 12(a)與表 12(b)為 Shubert Function 之測試
結果，10 次測試裡所有 gbest 的適應值，皆收斂
到 * -186.7309f = ，當最後所留下來各 gbest 位置的
差值不超過千分之一，即認定為同一個解。因此，
有一次找到其中五個解的，找到其中四個解的有
二次，找到其中三個解的有五次，而有二次找到
二個解；另外 gN 的數量也維持在 20 個。由於
Shubert Function 共有 18 個極值，而 gbest 的數量
定在 20 個，不能保證可以找到所有的解之位置。 
由表 11(b)及表 12(b)，其最終的 gN 數目皆等
於最初所設定的 gN 值，這可能表示 err 的數值給
得過大的緣故。而且兩個題目皆在約莫 50 代內就
已經收斂至最佳解附近，所以也表示 bk 可能設定
得過大。因此可以考慮將此兩項參數適度地減
小，除了 err 的值設定要小之外， bk 的大小則需
考慮搜尋的代數到達一定程度之後，再進行縮減
gbest 的個數，多極值搜尋的效果才能有所發揮。 
 
四、結論 
粒子群演算法對於各種類型的問題，皆有一
定程度的求解能力，而且觀念容易理解，程式撰
寫簡單，但是適應值計算的次數過多，是其缺點
之一，而且粒子群演算法對其參數設定過於靈
敏，導致難以找出可以適應所有條件並改善粒子
群演算法的機制。本計畫所討論的幾種方法，如：
改變原始粒子群演法 gbest 的更新方式、最大速
度限制與慣性權重的控制，可以改善粒子群演算
法的收斂速度；為了加強粒子群演算法的搜尋能
力，應用了區域強化搜尋與多極值搜尋的機制；
均勻設計和突變機制主要是為了增加粒子之間的
變異性與多樣性。將所討論的幾種方法綜合應用
於粒子群演算法中，對於各個測試題目之結果皆
有改善，根據以上各章的討論及題目測試，將結
論與心得歸納如下： 
1.均勻設計的概念使得產生初始位置，可以更均
勻地分散在搜尋空間裡，增加了找到全域最佳解
的機會，針對多峰函數的效果尤其顯著；突變機
制可以增加粒子之間的變異性，使各粒子不會太
快往 gbest 靠近，在處理多峰函數上有不錯的表
現；適當控制最大速度與慣性權重的遞減，可以
影響粒子群演算法的搜尋模式，而且粒子群演算
法對此兩參數特別的靈敏；區域強化搜尋可以增
加粒子跳脫區域極值的機會，也使得找到全域極
值的機會增加；多極值搜尋提供粒子跟隨不同的
gbest，除了可以增加粒子之間的變異性，對於處
行政院國家科學委員會補助國內專家學者出席國際學術會
議報告 
                                                      96 年 9 月 19 日 
報告人姓名  陳定宇 服務機構及職稱 
 
國立中興大學機械系教授 
 
     時間 
會議 
     地點 
96 年 9 月 15 日至 96 年 9 月
17 日 
中國北京 
本會核定
補助文號
NSC96-2221-E-005-079 
會議 
名稱 
 (中文) 第七屆 WSEAS 模擬建模和最佳化國際會議 
 (英文) 7th International Conference on Simulation, Modeling and 
optimization 
發表 
論文 
題目 
 (中文)使用混合方式的全域最佳化方法 
 (英文)Global optimization using hybrid approach 
附件三
 
Global Optimization Using Hybrid Approach 
TING-YU CHEN, YI LIANG CHENG 
Departmant of Mechanical Engineering 
National Chung Hsing University 
250 Kuo Kuang Road 
Taichung, Taiwan 40227 
REPUBLIC OF CHINA 
tyc@dragon.nchu.edu.tw 
 
Abstract: - The paper deals with a global optimization algorithm using hybrid approach. To take the advantage of 
global search capability the evolution strategy(ES) with some modifications in recombination is used first to find 
the near-optimal solutions. The sequential quadratic programming(SQP) is then used to find the exact solution 
from the solutions found by ES. One merit of the algorithm is that the solutions for multimodal problems can be 
found in a single run. Ten popular test problems are used to test the proposed algorithm. The results are 
satisfactory in quality and efficiency. 
 
Key-Words: -Global optimization algorithm, hybrid approach 
 
1  Introduction 
The global optimization has been a hot research topic 
for a long time. With the progress of evolutionary 
computation, many global optimization algorithms 
have been developed using various evolutionary 
methods. Tu and Lu[1] proposed a stochastic genetic 
algorithm(StGA) to solve global optimization 
problems. They divided the search space dynamically 
and explored each region by generating five offspring. 
The method was claimed to be efficient and robust. 
Toksari[2] developed an algorithm based on ant 
colony optimization(ACO) to find the global solution. 
In his method each ant searches the neighborhood of 
the best solution in the previous iteration. Liang et 
al.[3] used particle swarm optimization (PSO) to find 
global solutions for multimodal functions. Their 
method modified the original PSO by using other 
particles’ historical best data to update the velocity of 
a particle. In doing so, the premature convergence can 
be avoided. Zhang et al.[4] proposed a method called 
estimation of distribution algorithm with local 
search(EDA/L). This method used uniform design to 
generate initial population in the feasible region. The 
offspring are produced by using statistical 
information obtained from parent population. The 
local search is used to find the final solution. 
  Chen and Hsu[5] developed an algorithm called 
rank-niche evolution strategy(RNES) to find 
Pareto-optimal solutions for multi-objective 
optimization problems. The algorithm was based on 
evolution strategy(ES) incorporated with a novel 
fitness function. Since the algorithm is pretty simple 
and generates many Pareto optimal solutions in a 
single run, it is modified to solve global optimization 
problems with single or multiple solutions in this 
paper. Ten widely used test functions are employed to 
test against the algorithm. The global solutions for all 
test problems are found. 
 
2  Brief Review of ES 
The evolution strategy(ES) was developed by 
Rechenburg[6] and extended later by Schwefel[7]. 
There are three evolutionary steps in ES. The first one 
is recombination and it is executed by one of the 
following formulas. 
     
,
, ,
'
, ,
, ,
, ,
(A) no recombination
 or (B) discrete
0.5( )    (C) intermediate
 or (D) global, discrete
0.5( ) (E) global, intermediate
i i
i i
a i
a i b i
a i b ii
a i b i
a i b i
x
x x
x xx
x x
x x
⎧⎪⎪⎪ += ⎨⎪⎪ +⎪⎩
  (1) 
where 'ix  is the new ith design variable. iax ,  
and ibx ,  are the ith design variables of two 
individuals a  and b  randomly chosen from μ  
parent individuals, respectively. These two parents are 
used to generate a specific new individual for 
operations (B) and (C). iaix ,  and ibix ,  are  the ith 
design variables of two individuals randomly chosen 
from μ  parent individuals. In operations (D) and (E) 
each new design variable may come from two 
different parents. The number of so generated new 
individuals isλ and this value is usually several times 
ofμ .  
In addition to the five formulas given by Schwefel, 
Chen[8] developed another three formulas as follows: 
 
ibiai xtxtx ,1,1
' )1( +−=  
]1,0[1 ∈t                           (2) 
  where ),( jid eli is the normalized distance 
between elite i and elite j. elikix ,  and 
eli
kjx , are the kth 
design variable for the ith and the jth elites, 
respectively. Ukx  and 
L
kx are the upper and lower 
bound for the kth design variable, respectively. eliε  
is a user defined  smallest distance between two 
different elites. 
(7) Based on objective function value and constraint 
violation, select the best μ individuals to enter the 
next generation. For unconstrained optimization 
problems, put the λ individuals in ascending order 
based on their objective function values. The first μ individuals are chosen to enter next generation. For 
constrained optimization problems, the selection rules 
will be discussed in the next section. 
(8) If the maximum number of generation is reached, 
go to step (9). Otherwise, go to step (2). 
(9)Use sequential quadratic programming(SQP) to 
find the final solutions. The starting points for SQP 
are those individuals saved in the external elite pool. 
The best solution or solutions resulted from SQP or 
ES search are taken as the global solutions. 
 
4 Selection Steps for Constrained 
Problems  
The selection rules for constrained problems are 
executed in the following order. 
(1)Select feasible solution to enter the next generation 
first. If the number of feasible solution is greater 
than μ , select the best μ individuals according to 
their objective function values. If the number of 
feasible solution is less than μ , select all feasible 
solutions first and go to rule (2). 
(2)For infeasible solutions compute the normalized 
violation for each violated constraint. Divide the 
infeasible solutions into several ranks based on the 
domination check of constraint violation. The 
domination check proceeds as follows: For any two 
individuals A and B, if every constraint violation of A 
is less than that of B, then B is dominated by A. 
Otherwise, A and B do not dominate each other.  
Perform domination check on all infeasible 
solutions using the normalized violations to find the 
non-dominated ones. These infeasible solutions are 
assigned to the first rank. Repeat the domination 
check for the rest infeasible solutions to allocate 
individuals to other ranks. The higher the rank is, the 
less the overall constraint violation. 
(3)Select infeasible individuals from rank one first. If 
the number of individuals in rank one is less than the 
required number to fill upμ , go to rank two and 
repeat this process until the required number μ is 
reached. If the number of individuals in the lowest 
rank used to fill up μ is greater than the required 
number, use objective function values to determine 
the ones to be selected.  
 
5  Numerical Examples 
Ten test problems including five unconstrained and 
five constrained problems are used to test the 
proposed algorithm. The global solutions are found 
for all test problems. Due to limited space only four 
of them are shown in this paper. The first one is the 
Rastrigin function [9]. The second one is the Bumpy 
equation[10]. The first two problems are for 
unconstrained optimization. The third one is 
C-Bumpy equation[10]. The last one is Himmeblau 
equation[11]. The last two problems are for 
constrained optimization.  
 
Problem 1: Rastrigin function[9] 
   The optimization problem is formulated as 
follows.   
55
55 
)]2cos()2[cos(1020)(
.min
2
1
21
2
2
2
1
≤≤−
≤≤−
+−++=
x
xtosubject
xxxxxF ππv
   (9) 
Fig. 1 shows the multimodal nature of the 
problem. Table 1 lists the solutions found by the 
proposed algorithm and other papers. It is clear that 
the proposed method finds the best solution compared 
with other methods. Also the cpu time spent for the 
proposed method is less than those of the other two 
methods.  
 
       Fig. 1 Rastrigin function 
 
Table 1 Optimum solutions of problem 1  
Exact Solution[9] ES+SQP Lee[12] GA [12]
1x  0.0 -0.15E-08 -0.002167 -0.000153
2x  0.0 0.37E-07 -0.000214 0.000580
OBJ 0.0 0.00E+00 0.00094 0.00007
No.e NA* 2000 1400 2500 
time(s) NA* <1 109 1 
No.e is No. of function evaluations, time(s) is CPU 
time(sec), NA* is not available 
 
Problem 2: Bumpy equation[10] 
Table 4 Optimum solutions of problem 4 
ES+SQP Lee[12] Himmeblau[11] Homaifar[13]
1x  78.000 79.293 78.62 78.000 
2x  33.000 34.186 33.44 33.000 
3x  29.995 31.186 31.07 29.995 
4x  45.000 39.920 44.18 45.000 
5x  36.776 36.195 35.22 36.776 
OBJ -30665.45 -30225.7 -30373.9 -30665.6 
No.e 800 1650 NA NA 
time(s) <1 138 NA NA 
 
6  Conclusion 
The proposed global optimization algorithm using 
hybrid approach of ES plus SQP has been proved to 
be successful in solving 10 test problems. For most 
test problems the proposed method not only finds the 
best solution compared with other methods but also 
spends the least computational time. 
 
References: 
[1]Z. Tu and Y. Lu, A robust stochastic genetic 
algorithm(StGA) for global numerical 
optimization, IEEE Transactions on Evolutionary 
Computation, Vol. 8, No. 5, 2004, pp. 456-470. 
[2]M. D. Toksari, Ant colony optimization for finding 
the global minimum, Applied Mathematics and 
Computation, vol. 176, 2006, pp. 308-316. 
[3]J.J. Liang, A.K. Qin, P.N. Suganthan and S. Baskar, 
comprehensive learning particle swarm optimizer 
for global optimization of multimodal functions, 
IEEE transactions on Evolutionary Computation, 
Vol. 10, No. 3, 2006, pp. 281-295.  
[4] Q. Zhang, J. Sun, E. Tsang and J, Ford, Hybrid 
estimation of distribution algorithm for global 
optimization, Engineering Computations, Vol. 21, 
No. 1, 2004, pp. 91-107. 
[5]T.Y. Chen and Y.S. Hsu, A Multiobjective 
optimization solver using rank-niche evolution 
strategy, Advances in Engineering Software, Vol. 
37, 2006, pp. 684-699. 
[6]I. Rechenberg, Evolutionsstrategie: Optimierung 
technisher systeme nach prinzipien der 
biologischen evolution, Frommann-Holzboog 
Verlag, Stuttgart, 1973. 
[7]H.-P. Schwefel, Numerical optimization of 
computer models, John Wiley & sons Ltd, 
Chichester, U.K, 1977. 
[8]H.C. Chen, Discrete and mixed-variable evolution 
strategy, Master’s thesis, Department of 
Mechanical Engineering, National Chung Hsing 
University, Taiwan, 2006. 
[9]D. Buche, N.N. Schraudolph and P. Koumoutsakos, 
Accelerating evolutionary  algorithms with 
Guassian process fitness function models, IEEE 
transactions on Systems, Man, and 
cybernetics-Part C: applications and Reviews, Vol. 
35, No. 2, 2005, pp. 183-194. 
[10]A.J. Keane, Experiences with optimizers in 
structural design, Proceeding of Adaptive 
Computing in Engineering Design and control, 
1994, pp. 14-27. 
[11]D.M. Himmebleau, Applied nonlinear 
programming, McGraw-Hill, New York, 1972. 
[12]C.C. Lee, Reproducing kernel approximation 
method for structural optimization using genetic 
algorithms, Ph D dissertation, National Taiwan 
University, 2006. 
[13]A. Homaifar, S.H.Y. Lai and X. Qi, Constrained 
optimization via genetic algorithms, Simulation, 
Vol. 62, No. 4, 1994, pp. 242-254. 
