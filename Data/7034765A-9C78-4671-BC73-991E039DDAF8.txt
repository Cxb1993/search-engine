The main goal of this project is to design generic 
architectures for reconfigurable systems and to use 
an operating system to integrate the hardware and 
software in each architecture. Mainly, we are 
developing three architectures, including Slot-based 
System Architecture (SSA), Module Sequencer 
Architecture (MSA), and Network-on-Chip System 
Architecture (NSA). The corresponding programming 
models are based on the Layered Reconfigurable 
Operating System (LROS) for SSA, the Chained Program 
Operating System (CPOS) for MSA, and the Network-on-
Chip Operating System (NCOS) for NSA. All of these 
architectures are being implemented on Xilinx Virtex 
4 to Virtex 7 FPGA devices that can support runtime 
partial reconfiguration. 
英文關鍵詞： Reconfigurable system, Slot-based System 
Architecture, Module Sequencer Architecture, Network-
on-Chip System Architecture 
 
models are based on the Layered Reconfigurable Operating System (LROS) for SSA, the Chained 
Program Operating System (CPOS) for MSA, and the Network-on-Chip Operating System (NCOS) for 
NSA. All of these architectures are being implemented on Xilinx Virtex 4 to Virtex 7 FPGA devices that 
can support runtime partial reconfiguration. 
. 
Keywords: Reconfigurable system, Slot-based System Architecture, Module Sequencer Architecture, 
Network-on-Chip System Architecture 
 
前言與研究目的 
隨著科技技術不斷地進步，相對於較缺乏彈性的 ASIC，現場可編程邏輯陣列 (Field 
Programmable Gate Arrays, FPGA) 的彈性化已受到越來越多系統設計者的青睞，且 FPGA已具有動
態與部分重組的能力，如 Xilinx Virtex II/II Pro、Virtex 4、Virtex 5、Virtex 6 和 Virtex 7 與 Altera公
司所提供的 Stratix V FPGAs 皆能利用其可即時部分重組系統電路的特性來獲得更高的系統效能，
並提供更多元的設計彈性供程式開發者利用在不同的程式開發環境；此外，越來越大的閘容量可使
得在單一 FPGA 晶片上能同時執行更多的硬體工作，並讓越多的硬體工作可以和在微處理器上與
軟體工作互動。另一方面，因為具備動態可部分重組的能力，使得系統能夠在執行時期即時改變部
分硬體電路功能而不影響其它電路的運作，例如行動網路(Mobile networking)、普及計算(Ubiquitous 
computing)、可穿著式計算(Wearable computing)、網路內嵌系統(Networked embedded systems)等就
可利用 FPGA的特性發揮更大的系統效能並廣泛的運用在日常生活中。 
然而，傳統的 von Neumann 架構中，因為大量的資料必須透過記憶體傳輸，在資料導向的應
用上有傳輸上的瓶頸。這會使得現今高時脈的 CPU，因為其運算速度遠大於記憶體傳輸的速度，
在資料輸入與輸出時，發生 CPU 閒置的情況。這使得瓶頸的問題越來越嚴重。為因應以上問題，
本計畫將利用以 FPGA為基礎架構，來解決這類大量運算資料傳輸瓶頸的問題。我們在Xilinx FPGA
晶片上開發、實作與驗證三種可重組式架構與其對應的三種作業系統，並適用於一般性可重組式系
統硬體溝通架構，這三種架構分別為 Slot-based System Architecture (SSA)、Module Sequencer 
Architecture (MSA)及 Network-on-Chip System Architecture (NSA)。對應的三種作業系統分別為
Layered Reconfigurable Operating System (LROS) for SSA, Chained Program Operating System (CPOS) 
for MSA, 及 Network-on-Chip Operating System (NCOS) for NSA。 
此外，我們也深入的探討有關上述系統在現實生活中的應用層面[5-7][10][11]，以及探討在晶
片式系統(System-on-Chip, SoC)發展蓬勃的今日，由於大量的晶片模組製造於同一個晶片中，其在
晶片網路中(Network-on-Chip, NoC)所傳遞資料與溝通時，所發生的信號干擾等實際議題，並提出
其相對應的解決方法[8-9][13]。 
 
研究方法 
在階層式可重組式系統之作業系統(OS4RS)(如圖一所示) Communication階層中，Slot-based 
System Architecture是一種簡單的一般性架構，在可重組式硬體模組中會直接透過匯流排溝通介面來
連接OPB匯流排，SSA需要最少的資源但是它的彈性卻是最小的，因為它必須與其他周圍的設備一
起競爭OPB匯流排的使用權。本計畫提出一個針對動態部分可重組式系統之硬體資源虛擬化的技術，
     
 
圖二、硬體虛擬化機制 
 
當系統接受到Application要求依序存取HW1和HW2時，系統將啟動硬體裝置虛擬化的機制。
如圖二(b)所示，系統會將原本連接HW1的kernel module再連到HW2，透過這樣的方式，HW1的結
果可以直接透過kernel module傳到HW2，不用再經過kernel和user space這樣loading很大資料搬移的
過程，最後再利用HW2對應的裝置節點(/dev/comm2)將結果存回user space，達到應用加速的效果。
透過這個硬體虛擬化的機制，device nodes、kernel modules和on-demand可重組式硬體功能將可以依
據不同的系統應用需求動態連結，不再是以前的一對一關係。在一個動態可重組式的網路安全系統
中，相對於使用一般Linux的方法，硬體資源虛擬化的機制將可以讓更多的軟硬體應用在OS4RS中
執行，並降低最多至26%的時間。 
隨著科技的進步，製程技術也不斷地提升。在相同體積下的晶片，電晶體密度以及積體電路複雜性
也因而快速成長。一個系統中將會包含越來越多的硬體處理器以及硬體矽智財；由此可知，晶片中
的溝通架構將變得愈益重要。由於傳統的共享式匯流排及專線溝通架構已經漸漸不敷使用，為了處
理如此的情形，晶片網路(Network-on-Chip)被視為是一個可以解決不斷成長的溝通需求的溝通架構
(如圖三所示)。相較於共享式匯流排，晶片網路更適用於大規模硬體之間的溝通；而與專線相比，
則擁有更高的線路可重覆使用性。晶片網路的各種研究在這幾年內不斷進行、發展，包括晶片網路
的拓樸、路由器的設計、封包交換機制、功率消耗、線路干擾、以及應用程式與晶片網路的對應等
議題。而其中應用程式與晶片網路之間的對應關係對一個晶片網路的效率尤為重要。在應用程式與
晶片網路的對應關係中，任務之間的溝通與任務計算需求的排程，以及任務跟計算單元的對應，兩
者必須搭配，才可以避免晶片網路上的封包雍塞現象。因此，本計畫在作業系統階層提出兩個方法，
其一為動態任務排程並搭配壅塞推測[15]；透過我們提出的壅塞推測，不僅可為應用程式中每一個
任務找到最適合的計算單元，還能避免壅塞的情形發生。基於線路使用率(Link Utilization)的概念，
且透過我們的推測模型，可推測出在每一次任務與任務之間的溝通，所需要的最短及最長的封包傳
輸延遲，並將此與計算單元選擇搭配使用。圖四(a)中，未考慮壅塞推測機制，其會導致資料傳輸
(a) Logic Virtualization            (b) HW Device Virtualization 
 圖四、排程(a)未考慮壅塞推測機制； 
      (b)考慮壅塞推測機制 
 
 
圖五、候選處理單元之排程順序 
應用需求將需要的硬體電路連結至而不影響 NoC 上其它運算單元的執行，藉此提高系統的彈性以
及硬體資源的有效利用。同時，利用動態載入和應用需求相對應的編碼方法，藉此降低傳輸過程中
因為複雜的電位變化而造成的能源消耗及電路干擾。 
PE
O
P
B
DDR
SDRAM
MicroBlaze
RS232Terminal
HWICAPICAP
PE
Send commands to PRESSNoC 
(control signal and data)
Receive Data from PRESSNoC   
(packets and PRESSNoC status)
Encoder/
Decoder
Encoder/
Decoder
Switch 
box
CLB
Slice
Switch 
box
CLB
Bus macro
(input)(output)
Reconfigurable part
Static part
OS for PRESSNoC Reconfigurable part
Router
Router
Router
Router
Router
Router
PEPE
Encoder/
Decoder
Encoder/
Decoder
Reconfigurable part
Reconfigurable
Region
NIC NICStatic 
part
NIC NICStatic 
part
  
圖七、PRESSNoC 架構圖 
 
為了管理這樣具備動態可重組式的 NoC 架構，我們提供一個具備學習能力的管理架構
(REasoning And Learning (REAL) framework)來根據不同的需求管理底層硬體電路的重新組態，藉此
來充分發揮動態部分可重組技術的功能。我們在執行動態部分可重組的決策將取決於各程式資料傳
輸的不同、本身程式所需要維持的品質(QoS)、編解碼模組的硬體花費及效能上的額外負擔、動態
重組的時間以及使用環境等不同方面來加以考量。 
和一般傳統非動態可重組式 NoC 相比較，本計畫提出的 PRESSNoC 在硬體資源部分約可以節
(Hardware Virtualization)[11]與硬體可搶先機制 (Hardware Preemption)[10]。 
SAHA 支援的硬體可虛擬化機制有兩種，分別為 Logic Virtualization 和 Hardware Device 
Virtualization。不需透過 Device Node 開啟與關閉的動作，Logic Virtualization可以讓一個可部分重
組式硬體模組虛擬化而交錯被兩個以上的 Service Suppliers 存取。利用 Hardware Device 
Virtualization，一個可部分重組式硬體模組的輸出的結果可以透過 Kernel Module 送到另一個可部
分重組式硬體模組，不用再經過 Kernel Space 和 User Space 資料傳遞的動作，以減少傳遞資料時所
造成的時間浪費。此外，透過 Hardware Preemption 的能力，SAHA可以中斷已燒錄在 FPGA的可
部分重組式硬體模組，讓高優先權的可部分重組式硬體模組能燒錄在 FPGA中並且執行。Observer
是用來感知目前服務應用的特徵，並且與 System Manager合作來決定要啟動 Logic Virtualization、
Hardware Device Virtualization和 Hardware Preemption哪一種機制。如圖九所示，當 Service Supplier
所要求且具有高優先權的硬體功能不在系統中，SAHA便會啟動 Hardware Preemption機制。若要
求的硬體功能來自相同的 Service Supplier，便會啟動 Hardware Device Virtualization，反之便會啟動
Logic Virtualization。因此，透過 Observer的使用，SAHA將可以自我感知來選擇合適的機制來提
升系統的效能。 
 
  
圖九、Self-aware System Adaption 
 
除上述應用至普及計算領域之外，我們另將可重組式技術應用至生活上的實例，提出一個動態
可重組式快速傅立葉轉換(Fast Fourier Transform, FFT)架構(如圖十)，藉由共享管線資源來提供多個
應用程式同時並且有效率的計算 FFT，以及利用有限資源將常見的且有需要做 FFT的通訊協定應
  “SAHA: A Self-Adaptive Hardware/Software System Architecture for Ubiquitous Computing 
Applications,” Demo/Exhibition Program at the 7th International Conference on Ubiquitous 
Intelligence and Computing (UIC), 2010. 
 “PRESSNoC: Power-Aware and Reliable Encoding Schemes Supported Reconfigurable 
Network-on-Chip Architecture,” Accepted in University Booth at DATE 2010. 
 [Best Paper Award] PRESSNoC: Power-Aware and Reliable Encoding Schemes Supported 
Reconfigurable Network-on-Chip Architecture, Proceedings of the Fourth International Conference on 
Embedded and Multimedia Computing (EM-Com), 2009 (Acceptance Rate: 35/123 = 28.4%) 
 “Model-Based Verification and Estimation Framework for Dynamically Partially Reconfigurable 
Systems,” 「中華民國電腦學會優良論文獎」資訊工程類 – 優等, 2010.  
 
結論與建議 
本計畫主要的目標是利用可重組式系統之作業系統(OS4RS)整合軟硬體架構開發三種適用於
一般性可重組式系統硬體溝通架構的撰寫模型，分別為 Slot-based System Architecture、Module 
Sequencer Architecture 與 Network-on-Chip System Architecture，並讓這三種架構可實現於任何具有支
援動態部分可重組能力的 FPGA裝置上。當使用者透過撰寫模型提出客製化需求時，這三種架構
便可利用其所對應之撰寫模型，提供屬於該架構的設計流程，這能讓一般可重組式設計者能輕易的
客製化並滿足使用者所提出的軟硬體需求。 
參考文獻 
1. C.-H. Huang, P.-A. Hsiung, and J.-S. Shen, "UML-Based Hardware/Software Co-Design Platfo rm for Dynamically 
Partially Reconfigurable Network Security Systems," Journal of Systems Architecture (JSA), Vol. 56, No. 2-3, pp. 
88-102, February 2010. 
2. C.-H. Huang and P.-A. Hsiung, "Model-Based Verificat ion and Estimation Framework for Dynamically Part ially 
Reconfigurable Systems," IEEE Transactions on Industrial Informatics (TII), Vol. 7, No. 2, pp. 287-301, May 2011. 
3. C.-H. Huang, P.-A. Hsiung, and J.-S. Shen, “Model-Based Plat form-Specific Co -Design Methodology for Dynamically 
Partially Reconfigurable Systems with Hardware Virtualization and Preemption,” Journal of Systems Architecture (JSA), 
Vol. 56, No. 11, pp. 545-560, November 2010. 
4. P.-A. Hsiung, C.-H. Huang, J.-S. Shen, and C.-C. Chiang, "Scheduling and Placement of Hardware/Software Real-Time 
Relocatable Tasks in  Dynamically Part ially Reconfigurable Systems," ACM Trans. on Reconfigurable Technology and 
Systems (TRETS), vol. 4, no. 1, December 2010. 
5. P.-A. Hsiung and C.-H. Huang, "SAHA: A Self-Adaptive Hardware/Software System Architecture fo r Ubiquitous 
Computing Applications," Proceedings of the International Conference on Engineering of Reconfigurable Systems and 
Algorithms (ERSA), July 2011.  
6. C.-H. Huang, J.-S. Shen, and P.-A. Hsiung, "A Self-Adaptive Hardware/Software System Arch itecture for Ubiquitous 
Computing Applications," Proceedings of the 7th International Conference on Ubiquitous Intelligence and Computing 
(UIC), LNCS Vol. 6406, pp. 382-396, October 2010. 
7. C.-H. Huang, J.-S. Shen, and P.-A. Hsiung, "Self-Adaptive Hardware-Software Architecture for Embedded and 
Ubiquitous Systems," Proceedings of the VLSI Design / CAD Symposium, August 2010. 
21. P.-A. Hsiung, C.-H. Huang, and Y.-H. Chen, "Hardware Task Scheduling and Placement in Operating Systems for 
Dynamically Reconfigurable SoC," Journal of Embedded Computing (JEC), Vol. 3, No. 1, IOS Press, The Netherlands, 
2009. 
22. C.-H. Huang, " Virtualizab le and Preemptible Hardware/Software Run-Time Environment for Dynamically Part ially 
Reconfigurable Systems," Student Forum at the 15th Asia and South Pacific Design Automation Conference (ASP-DAC), 
Jan. 2010. 
23. C.-H. Lu, H.-W. Liao, and P.-A. Hsiung, "Multi-objective p lacement of reconfigurable hardware tasks in real-time 
system," International Journal of Embedded Systems (IJES), Vol. 4, Nos. 3/4, pp. 195-203, Inderscience Publishers, 
2010. 
24. P.-A. Hsiung and M. D. Santambrogio, Reconfigurable System Design and Verificat ion, CRC Press, USA, February 
2009. 
25. H.-L. Chao, Y.-R. Chen, P.-A. Hsiung, and S.-J. Chen, "Congestion-Aware Scheduling for NoC-based Reconfigurable 
Systems," Proceedings of the the Design, Automation & Test in Europe (DATE), Dresden, Germany, March 2012. 
26. J.-S. Shen, W.-T. Su, and P.-A. Hsiung, "Network-on-Chip Router Design with Buffer-Stealing," Proceedings of the 
Asia and South Pacific Design Automation Conference (ASP-DAC, Yokohama, Japan), January 2011 
27. C.-H. Huang, J.-S. Shen, and P.-A. Hsiung, "A Self-Adaptive Hardware/Software System Architecture fo r Ubiquitous 
Computing Applications," Proceedings of the 7th International Conference on Ubiquitous Intelligence and Computing , 
(UIC 2010, Xi'an, China), LNCS Volume No. 6406, Springer Verlag, October 2010. 
28. K.-J. Shih, H.-Y. Sun, and P.-A. Hsiung, "Dynamic Hardware-Software Task Switch ing and Relocation Mechanisms fo r 
Reconfigurable Systems," Proceedings of the IET International Conference on Frontier Computing -- Theory, 
Technologies and Applications, Taichung, Taiwan, August 2010. 
29. C.-H. Lu, K.-C. Chiang, and P.-A. Hsiung, "Round-based Priority Arbitration for Predictable and Reconfigurable 
Network-on-Chip," Proceedings of the International Conference on Field-Programmable Technology (FPT), December 
2009. 
30. C.-H. Lu, H.-W.Liao, and P.-A. Hsiung, "Multi-Objective Placement of Reconfigurable Hardware Tasks in  Real-Time 
System," Proceedings of the International Workshop on Reconfigurable and Multicore Embedded Systems , (WoRMES, 
Vancouver, Canada), IEEE CS Press, August 2009. 
31. W.-W. Lin, “Reconfigurable NoC with OS Management” M.S. thesis, Department of Computer Science and Information 
Engineering, National Chung Cheng University, Chiayi, Taiwan, June 2009. 
32. C.-T. Lan, “Hardware Mediator for Reconfigurable Hardware -Software Systems” M.S. thesis, Department of Computer 
Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan, June 2009. 
 
IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS, VOL. 7, NO. 2, MAY 2011 287
Model-Based Verification and Estimation Framework
for Dynamically Partially Reconfigurable Systems
Chun-Hsian Huang, Student Member, IEEE, and Pao-Ann Hsiung, Senior Member, IEEE
Abstract—Unified Modeling Language (UML), an industry
de-facto standard, has been used to analyze dynamically partially
reconfigurable systems (DPRS) that can reconfigure their hard-
ware functionalities on-demand at runtime. To make model-driven
architecture (MDA) more realistic and applicable to the DPRS
design in an industrial setting, a model-based verification and
estimation (MOVE) framework is proposed in this work. By
taking advantage of the inherent features of DPRS and consid-
ering real-time system requirements, a semiautomatic model
translator converts the UML models of DPRS into timed au-
tomata models with transition urgency semantics for model
checking. Furthermore, a UML-based hardware/software co-de-
sign platform (UCoP) is proposed to support the direct interaction
between the UML models and the real hardware architecture.
The two-phase verification process, including exhaustive func-
tional verification and physical-aware performance estimation, is
completely model-based, thus reducing system verification efforts.
We used a dynamically partially reconfigurable network security
system (DPRNSS) as a case study. The related experiments have
demonstrated that the model checker in MOVE can alleviate the
impact of the state-space-explosion problem. Compared to the
synthesis-based estimation method having inaccuracies ranging
from 43.4% to 18.4%, UCoP can provide accurate and efficient
platform-specific verification and estimation through actual time
measurements.
Index Terms—Dynamically partially reconfigurable systems,
unified modeling language (UML), verification and estimation.
I. INTRODUCTION
W ITH the increase in user requirements for system func-tionalities, and the trend of low profit in the electronic
industry, the dynamic partial reconfiguration technology in
field programmable gate array (FPGA) devices [15], [18], [22]
becomes a very attractive approach to further enhance system
flexibility and performance. Using the partial reconfiguration
technique, multiple combinations of hardware functions can
be accommodated on an FPGA device at different time points,
without sacrificing the performance and possible parallelism of
ASICs. FPGA devices such as Xilinx FPGAs, that is, the most
popular FPGA devices in the industry, can be partially recon-
figured at runtime. This means that one part of the FPGA can
Manuscript received October 09, 2009; revised April 10, 2010, August 30,
2010, December 13, 2010, and February 23, 2011; accepted February 23, 2011.
Date of publication March 22, 2011; date of current version May 06, 2011. This
work was supported in part by the Research Project NSC98-2221-E-194-049-
MY3, National Science Council, Taiwan. Paper no. TII-09-10-0252.
The authors are with the Department of Computer Science and Information
Engineering, National Chung Cheng University, Chiayi 621, Taiwan (e-mail:
huang@cs.ccu.edu.tw; hpa@computer.org).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TII.2011.2123901
be reconfigured, while other parts remain operational without
being affected by reconfiguration. Xilinx FPGA devices have
already been incorporated in new electronic products, such as
the LED controller in the ASTRI’s television and SANYO’s
monitoring camera VCC-WD390. Integrating FPGA devices
into consumer electronics product is becoming a future main-
stream.
A hardware/software embedded system realized with an
FPGA device with the capability of partial reconfiguration is
called a Dynamically Partially Reconfigurable System (DPRS),
which enables more applications to be accelerated in hardware,
and thus reduces the overall system execution time. A network
security embedded system is a typical example that can leverage
the benefits of partial reconfiguration technology as described
in the following. Owing to the popular use of the network,
the need for data security and authentication is getting more
and more important. Many industrial products for embedded
network security, such as the NITROX PX security processor
family developed by Cavium Networks Incorporation, and the
NFR7500 network appliance platform developed by VIA Incor-
poration, are widely used to ensure the security of data transfers
on the network. However, cryptographic algorithms are usually
computation-intensive, have hard real-time requirements, and
are nonadaptive to changing network conditions. The real-
ization of these algorithms also result in different tradeoffs
between security and complexity. To allow multiple tradeoffs
and to adapt to changing network conditions at runtime, a data
protective process needs a high-speed and flexible embedded
system. Thus, a DPRS architecture is desired for a network se-
curity system such that it can dynamically adapt to changes and
provide hardware acceleration for the computation-intensive
cryptographic functions. For example, the system can negotiate
with a receiver on the network to use the same cryptographic
algorithm, and then dynamically configure the required crypto-
graphic hardware function into the system to meet the network
security needs. However, this new dimension of dynamic
hardware reconfigurability has also made the design of such
an embedded system become more complex than before, since
it includes not only the traditional software applications and
hardware devices, but also reconfigurable hardware functions.
To analyze such a flexible and scalable DPRS, the Unified
Modeling Language (UML), an industry de-facto standard pro-
moted by the Object Management Group (OMG), is used for
modeling and development [1], [19]. Through system modeling,
the functional interactions between the system and the applica-
tions can be easily described and analyzed. Further, the Model
Driven Architecture (MDA) approach is also adapted to the do-
main of DPRS design to separate the applications from the plat-
form, which thus facilitates the retargeting of the applications to
1551-3203/$26.00 © 2011 IEEE
HUANG AND HSIUNG: MODEL-BASED VERIFICATION AND ESTIMATION FRAMEWORK FOR DPRS 289
TABLE I
COMPARISON OF DIFFERENT VERIFICATION METHODS FOR DPRS
N/A: Not applicable.
state machines. As a result, an appropriate specification of time
constraints can be supported in platform independent models
for hard real-time systems.
Besides the functional verification of a hardware IP using
RTL simulation, the interactions among all DPRS components
are usually simulated and then verified using the SystemC
language. Raabe et al. [21] proposed an extension to SystemC
called ReChannel to overcome these limitations without ac-
tually changing the underlying simulation kernel. It provided
maximum freedom in the description of reconfiguration be-
havior and its control, while featuring simulation of runtime
configuration, removal, and exchange of custom modules. In-
stead of system verification using only simulation, an integrated
design and verification methodology called Symbad [3] was
proposed for reconfigurable systems. A reconfigurable system
was first described using SystemC for functional simulation,
and then the system descriptions using SystemC were ab-
stracted for formal verification to exhaustively validate system
correctness.
Different from the functional verification of a DPRS, the
physical-aware system verification requires estimating the
hardware configuration and execution time. A commonly used
method to evaluate physical-aware parameters of a DPRS is
the synthesis-based estimation method [10]. The configura-
tion time was evaluated based on the size of the synthesized
hardware function in terms of the FPGA resource usage, while
the hardware execution time was evaluated based on hardware
simulation and the synthesis results. We will show in this work
how more accurate timings can be determined through the
proposed accurate measurement-based method in MOVE.
Table I gives a brief comparison between the above existing
verification methods and MOVE in terms of the system spec-
ification, the functional PIV, and the physical-aware PSV for
design space exploration. The research work [1], [19] focus on
the system modeling and the functional code generation and
not design space exploration, such as the validation of system
correctness and the estimation of system performance. The
system verification in these UML-based design methodologies
[1], [19] only simulated the functional interactions between
a user-specified application and a DPRS without considering
physical constraints. As a result, the physical design correctness
of the system could be verified only after the UML models
were synthesized into concrete system designs.
In contrast to the above mentioned methods, the verification
and estimation methods [10], [21] try to simulate DPRS but
lack high-level system modeling. Rechannel [21] uses Sys-
temC simulation, a non-exhaustive verification technology,
so if it was directly applied to an existing UML-based de-
sign methodology [1], [19], the design process could be very
time-consuming due to the large number of refinement itera-
tions required from system modeling to implementation (a kind
of semantic gap between model and implementation). Symbad
[3] could exhaustively validate the system correctness using
model checking; however, translating the SystemC descriptions
of a DPRS into formal models for model checking is not
intuitive enough because they are based on different design
points of view, and thus more design efforts are required for
model translation. Furthermore, the partial reconfiguration
technology was not considered in Symbad. For PSV, although
the estimation results using the synthesis-based method [10]
are quite close to the actual measured ones, the small amount
of errors in time estimation, including both underestimations
and overestimations, could still cause correctness problems,
especially when hard real-time constraints are violated.
In this work, the primary goal in MOVE is to bridge the gap
between model and implementation. MOVE provides reusable
UML models which can be customized into user-specific
DPRS designs. By taking advantage of the inherent features of
DPRS and considering real-time system requirements, a model
translator then semiautomatically converts the UML models
of DPRS into timed automata models with transition urgency
semantics [8] for model checking. As a result, the PIV phase
in MOVE can exhaustively verify the DPRS functionalities
that change with time and environment, thus overcoming the
problem of incomplete functional validation using simulation.
Furthermore, UCoP [11] enables the UML models of DPRS
to directly interact with the real hardware architecture at the
system modeling level. As a result, the PSV phase in MOVE is
accurate and physical-aware. Thus, MOVE effectively bridges
the gap between system modeling and implementation. In
summary, MOVE not only provides a complete and efficient
verification and estimation mechanism for DPRS, but also
makes the MDA more realistic and applicable to the DPRS
design in an industrial setting. The details of MOVE will be
introduced in Section IV.
III. PRELIMINARIES
Before introducing the model-based verification and estima-
tion (MOVE) framework, we first introduce the related back-
ground knowledge, including model checking and the design of
a dynamically partially reconfigurable system (DPRS).
A. Model Checking
Model checking [5], [20] is a formal verification technique for
finite concurrent systems. It has been adopted in some world-
wide corporations, such as IBM and Microsoft. In this work,
system behaviors are modeled by Extended Timed Automata
(ETA), and system specifications are given in a propositional
temporal logic called Computation Tree Logic (CTL) [7]. The
ETA and CTL specifications are then input to a model checker.
A model checker exhaustively searches the state space of the
design, and shows if the system satisfies a user-specified prop-
erty or violates it by giving a counterexample. CTL properties,
such as , , , , can all be defined [7], and their brief
HUANG AND HSIUNG: MODEL-BASED VERIFICATION AND ESTIMATION FRAMEWORK FOR DPRS 291
Fig. 2. DPRS development process using MOVE.
allow a sender and a receiver to use the same cryptographic and
hash algorithms for data transfer. The detailed case study of
DPRNSS using MOVE will be given in Section V.
A. System Specification
To effectively analyze the possible DPRS behaviors, MOVE
takes as input four standard UML models, including class dia-
grams for architecture modeling, state machine diagrams for be-
havior modeling, sequence diagrams for interaction modeling,
and deployment diagrams for deployment modeling. Recall that
as described in Section III-B, the UML models in MOVE are
classified into three categories, namely, hardware configuration
models, system management models, and software application
models. By such a classification of DPRS models, different user
software applications, hardware functions, system platforms can
be separately customized in MOVE for system verification and
estimation, without being restricted to a specific DPRS design.
Based on the three categories of UML models, MOVE
provides basic UML model patterns for designers to model
their DPRS architecture and applications. As illustrated by the
class diagram of MOVE in Fig. 3, the hardware configuration
models include the and classes, the
system management models include the and
classes, and the software application models
include the and classes. The
and classes are responsible for config-
uring the hardware functions into the PRRs and the static area,
respectively, in an FPGA. The and
classes are responsible for providing the interactive interface
between software applications and hardware functions, and the
user-defined application, respectively. The
class is responsible for all FPGA configurations, and is thus
associated with the and classes. The
Fig. 3. Class diagram of MOVE framework.
Fig. 4. State machine diagram for the System Manager class.
class is responsible for managing all control
and data transfers in a DPRS, and is thus individually associated
with the , , and
classes. In the system specification phase, the class diagram
is used to only model the association between all system
components. In the PSV phase, the variables and functions
required by each system component will be implemented in
the corresponding class, so that the software executables can
be generated.
Besides modeling the functional relationships in a DPRS
using the class diagram, MOVE also provides users the
state machine diagrams for the classes ,
, and to model the detailed oper-
ations. Because the typical semantics of UML state machines is
not sufficient for the detail DPRS specification, we thus further
refine the semantics for DPRS. Fig. 4 shows the state machine
diagram for the class, where the states ,
, and and their related incoming and
outgoing transitions are all from the basic state machine dia-
grams provided by the MOVE framework. The semantics of the
states , , and indicate a DPRS
starts, initializes all system parameters, and configures the
basic hardware functions into the FPGA, respectively. As for
the state, it is a user-defined state used to model
user-defined applications. As a result, a DPRS needs to be
specified by only customizing the three categories of reusable
UML models, and the high-level functional analysis can thus
be performed. The initial UML models are used to describe the
functional behaviors of a DPRS without the platform-related
HUANG AND HSIUNG: MODEL-BASED VERIFICATION AND ESTIMATION FRAMEWORK FOR DPRS 293
Fig. 5. Translated extended timed automata for system manager.
Second, the transitions in ETA are semiautomatically adapted
to fit the DPRS features and real-time system requirements
using the model extensions. Here, the clock variables need
to be manually assigned by users. The process of transition
adaptation in ETA is as described in the following.
• If the type of a transition in the UML state machine dia-
gram is reconfiguration, the triggering condition of the cor-
responding transition in ETA is defined as True for direct
triggering; otherwise, the triggering event and the guard of
a transition in the UML state machine diagram are mapped
to the triggering condition of the corresponding transition
in ETA. By making the reconfiguration transitions nonde-
terministic, all possible functional combinations of a DPRS
are verified.
• If the type of a transition in the UML state machine di-
agram is reconfiguration, the corresponding transition in
ETA is associated with the eager urgency type, so that
real-time reconfiguration is correctly modeled.
After the model translation process, all translated ETA are
merged as a global state graph by applying parallel composition
[24], while users need to specify the CTL formulas to exhaus-
tively validate the global system behaviors.
For the DPRNSS example, Fig. 5 shows the corresponding
ETA translated from the state machine diagram of the
class in Fig. 4. By applying the flattening
scheme, being an OR state the state is ab-
stracted or flattened. Further, being an AND (parallel) state the
state in Fig. 4 is transformed into two component
ETA by introducing two new initial modes and ,
while the outgoing transitions for and are syn-
chronized. By applying the proposed model translation process,
the conditions of transitions and ,
as shown in Fig. 4, are modified as True, as shown in Fig. 5,
for direct triggering and the transitions are associated with the
eager urgency type [8], because they are triggered by depending
on the partial reconfiguration requests. The detailed case study
of DPRNSS for PIV will be given in Section V-B.
C. Platform Specific Verification
The PSV phase focuses on verifying the system correctness
and application performance of a user-specified DPRS on a spe-
cific target platform. The generated software executables and
Fig. 6. UML-based HW/SW co-design platform and PR template. (a) UML-
based HW/SW co-design platform. (b) Example of integration between the RSA
function and PR template.
hardware bitstreams are validated to ensure that they can be cor-
rectly executed on the target platform. Besides the functional
requirements, PSV also tries to verify physical-aware system
requirements, for example, the configuration time of a cryp-
tographic hardware function must be less than 1000 ms. Such
timing requirements must be validated through accurate mea-
surements which are achieved in PSV using UCoP [11] as illus-
trated in Fig. 6(a). The interactive UML models used in UCoP
consist of the functional UML models, platform APIs, software
executables, and hardware bitstreams, where the platform APIs
and the hardware bitstreams may change when the hardware
platform and architecture is changed. During the simulation of
UML models, the interactive UML models can communicate
directly with the hardware functions in FPGA. For example,
as shown in Fig. 4, the highlighted states
and in the state machine diagram can illustrate
the current execution status in the actual system hardware plat-
form. This hardware-in-the-model verification strategy effec-
tively bridges the abstraction gap between models and actual
implementations in UCoP. The accurate time measurements can
be performed and used at the system level, instead of only sim-
ulating the functional interactions between applications and a
DPRS.
To accommodate hardware functions with different I/O in-
terfaces, a partially reconfigurable hardware task template (PR
template) is proposed to ease the integration of user-designed
hardware functions into UCoP for system verification and esti-
mation. To use a newly developed hardware function in UCoP,
a designer has to simply integrate the new hardware function
HUANG AND HSIUNG: MODEL-BASED VERIFICATION AND ESTIMATION FRAMEWORK FOR DPRS 295
Fig. 8. ETA for DPRNSS. (a) ETA for configuration manager. (b) ETA for interactor. (c) ETA for negotiator.
SGM. The physical architecture constraints for partial reconfig-
uration, including mutual exclusion and no invalid access, as
illustrated in Section III-B, and user-given properties are spec-
ified as CTL properties for model checking. The SGM model
checker would give users a log file, in which the trace that incurs
system errors is recorded. Because the translation from the state
machine diagrams to ETA is semiautomatic, most information
in the state machine diagrams, such as the state and transition
names and the variables, are all preserved, except for the infor-
mation modified by the flattening scheme, such as the OR and
AND state names, and the proposed transition adaption, such
as True conditions. Users can use the log file to find the com-
putation path that incurs system errors in the functional UML
model. When all properties are validated and all functional er-
rors are corrected by analyzing the counterexamples, the veri-
fied UML models are then input to the platform specific verifier.
However, similar to the simulation-based verification, the diffi-
culty in correcting system errors depends on the complexity of
a DPRS design.
For the platform specific verifier, MOVE adopts UCoP that
can directly interact with the real DPRS architecture at a high
abstraction level. UCoP integrates the related APIs for the
FPGA reconfiguration and communication directly into the
software code generator of the UML modeler, so that the gap
between application models and system architecture constraints
is effectively bridged. All reconfigurable hardware functions
are integrated with the PR template and then the corresponding
bitstreams are generated by the PR script file. The bitstreams
are associated with the hardware configuration models, while
software executables are associated with the software appli-
cation models. Furthermore, the related APIs for the FPGA
reconfiguration and communication are integrated into the
system management models. Due to such an integration, UCoP
can allow accurate time measurements of hardware execution
and configuration and real-time debugging. When all system
requirements are satisfied, the software executables, platform
APIs, and hardware bitstreams used in UCoP are then inte-
grated in the physical system architecture, and a feasible DPRS
design can be thus obtained, as illustrated in Fig. 2.
V. EXPERIMENTS
To demonstrate the practicability of MOVE, this section will
adopt the DPRNSS design as described in Section IV as a case
study. In the following sections, we will introduce the experi-
mental setup of MOVE, the function-oriented PIV for DPRNSS,
the physical-aware PSV for DPRNSS, the final DPRNSS gen-
eration, and the applicability of MOVE.
A. Experimental Setup
In our current implementation of MOVE, we adopt the Rhap-
sody modeling tool running on the Windows XP OS as the UML
modeler, which has the powerful capability for code generation
in C, C++, Java, and Ada. Furthermore, we use the XMI toolkit
in Rhapsody to export the functional UML models in the XMI
format. For PIV, we use SGM, which runs on an Intel Pentium
4 CPU 3.00 GHz with 8 GB RAM, to validate the functional in-
teractions among all system components. For PSV, UCoP was
implemented on a reference board, that is, the XtremeDSP De-
velopment Kit-II from Nallatech. The Field Upgradeable Sys-
tems Environment (FUSE) APIs and the PCI driver are provided
by the XtremeDSP Development Kit-II to facilitate the FPGA
reconfiguration and communication over the PCI bus. To enable
the UML models to directly interact with actual hardware func-
tions in the FPGA, UCoP integrates FUSE APIs and PCI driver
directly into the software code generator of the Rhapsody mod-
eling tool.
B. PIV for DPRNSS
After successfully modeling DPRNSS using the functional
UML models described in Section IV-A, the proposed model
translation process as described in Section IV-B is used to
transform the UML state machine diagrams into ETA models,
as shown in Figs. 5 and 8. However, the sequence of functional
interactions could be incorrect, if timing is fully neglected,
we thus introduce the abstract timing constraints in PIV for
verifying the DPRNSS design. To model the temporal features
(timing constraints), three different clock variables ,
, and are used in DPRNSS to represent
the times required by a hardware iteration for performing a cryp-
tographic or hash operation, a software iteration for detecting
partial reconfiguration requests, and a partial reconfiguration
iteration for configuring a cryptographic or hash hardware
function, respectively. According to our experiment results in
the target XtremeDSP Development Kit-II platform, the ratio
between the average times required by , ,
and is 2:5:9. Thus, the largest constants of clock
HUANG AND HSIUNG: MODEL-BASED VERIFICATION AND ESTIMATION FRAMEWORK FOR DPRS 297
verifying the full combination of all hardware functions. This is
architecture-specific reduction. Further, model checking being a
control-oriented verification method, abstracts data-oriented be-
haviors. When different hardware functions are configured into
a DPRS, the control behaviors of the system does not change.
Take the translated ETA for the System Manager in Fig. 5
as an example. Before parallel composition, the total number of
modes increases with the number of PRRs, where the additional
mode is in the ETA. For example, when the
DPRS design has two PRRs, an additional mode
will be inserted into the ETA in Fig. 5. Since
partial reconfiguration is managed by the configuration man-
ager, during applying parallel composition of the models, only
the modes of the ETA are merged with the ad-
ditional modes in the ETA. Further, though
the number of modes increases when clock variables are used
in system verification, the additional modes are mainly related
to the ETA. This also shows that after parallel
composition, only the number of modes of the
ETA increases linearly with the number of the additional modes
in the ETA (the number of PRRs).
For the DPRNSS design, the number of modes of the global
state graphs without timing constraints in Fig. 9(a) and with
timing constraints in Fig. 9(b) can be given by two linear func-
tions and , respectively.
This confirms that, by using the model translation process as
described in Section IV-B, the state space size of the DPRNSS
checked using model checking is linear in the number of PRRs,
while the number of clock variables is restricted to at most
three. Thus, the DRPNSS architecture abstraction and data ab-
straction in the model checking problem itself results in allevi-
ating the state-space-explosion problem. For the verification of
a DPRS design using model checking, this work is also the first
to show the reasons why the model checking problem for DPRS
does not encounter state-space explosion, as long as data are
abstracted for the reconfigurable hardware functions. Further,
this also demonstrates our theoretical analysis that the model
checking problem itself can alleviate the state-space-explosion
problem.
2) SGM Experimental Analysis: Besides the state-space ex-
plosion problem can be alleviated by the proposed model trans-
lation process, the SGM model checker in MOVE can further re-
fine the numbers of modes for the DPRNSS designs. As shown
in Fig. 9(b), the number of modes of the global state graph with
three clock variables is very close to that with only two clock
variables. This is because SGM can remove dead states and sup-
ports symbolic representation of transition urgency semantics
[8], instead of discrete representation. Both the above operations
provided by SGM reduce the state space size and do not affect
the verification results. Thus, the memory usage and the verifi-
cation time can be reduced.
For the most complex DPRNSS design with nine PRRs and
thre clock variables, the number of modes using a conventional
model checking method is theoretically calculated as 1,316,700
(the worst case); however, the number of modes using the
SGM model checker is only 248. Because the search space
is positively relative to the number of modes, for the most
complex DPRNSS design, this experimental result also shows
that MOVE can speed up PIV by around 1469 times compared
to using the conventional model checking method.
Since data is abstracted and control behavior is covered by
the UML model patterns provided by MOVE, application spe-
cific behavior modeled by a designer generally does not change
with the complexity of a DPRS design (number of PRRs). As a
result, the analysis results presented here are representative of
most applications. Note that MOVE illustrates that two factors
allow alleviation of the state-space-explosion problem, namely:
1) DPRS verification problem structure, and 2) data abstrac-
tion. However, if the detailed system functionalities, such as the
HTTP and FTP protocols which include SSL, which in turn in-
cludes all the cryptographic and hash functions, are modeled,
then the state-space-explosion problem could still occur.
C. PSV for DPRNSS
The PIV phase abstracts data-oriented behaviors and mainly
verifies control-oriented behaviors. The data-oriented behaviors
for the DPRNSS design are then verified using UCoP in the PSV
phase. Due to the resource limitations of the DPRNSS imple-
mentation, we implemented only a small with 576 slices
to configure the hash hardware functions, including CRC32,
CRC64, and CRC128, and a large with 8704 slices to con-
figure the cryptographic hardware functions, including RSA,
DES, 3DES, and AES, on a Xilinx Virtex-II XC2V3000 FPGA
with 14,336 slices. Note that based on the EA PR flow [15] from
Xilinx, the slice counts of a PRR must be enough to individu-
ally configure each hardware function designed for configuring
in the PRR, even though some slices may be wasted (internal
fragmentation), when a hardware function with lower usage is
configured in the PRR.
To perform the physical-aware PSV, all cryptographic and
hash hardware functions of DPRNSS are integrated with the PR
template as described in Section IV-C for generating the corre-
sponding partial bitstreams, which are then incorporated with
the hardware configuration models of MOVE. Through the an-
imation mode of Rhapsody, the functional interactions among
the interactive UML models and the real DPRNSS hardware ar-
chitecture can be, step by step, dynamically traced in the se-
quence diagrams and the state machine diagrams. Thus, accu-
rate verification and estimation can be achieved at a high ab-
straction level.
1) Resource Usage and Power Consumption Analysis:
Compared to a conventional network security system (NSS)
that requires all the seven functions to be implemented and
integrated into the system design, a DPRNSS can support all
the seven functions by implementing only two different sized
PRRs, namely, a small and a large . As shown in
Table III, a conventional NSS with all the seven hardware
functions needs 16,444 slices (114.7%) in terms of the Xilinx
Virtex-II XC2V3000 FPGA device (the sum of slice counts for
all the seven hardware functions in Table III), without including
the switch circuits between all the hardware functions. Note
that here we assume the floorplan area optimization technology
[23] is not used, so that resources cannot be shared between dif-
ferent hardware functions. However, the DPRNSS needs only
9280 slices (64.7%) in terms of the Xilinx Virtex-II XC2V3000
HUANG AND HSIUNG: MODEL-BASED VERIFICATION AND ESTIMATION FRAMEWORK FOR DPRS 299
Fig. 10. Execution time for DPRNSS.
UCoP of MOVE can be calculated by deducting the register ac-
cess latency (the time to receive the done signal) from the orig-
inally measured time. Here, the average time to access a reg-
ister is 5.7 microseconds obtained from the experimental results
over the PCI bus. As shown in Table IV, the estimated execution
times for 128 128 pixel image cryptographic and hash opera-
tions using the synthesis-based estimation method are compared
with the measured execution times using MOVE. The results of
the synthesis-based estimation method [10] have inaccuracies
ranging from 43.4% (DES encryption) to 18.4% (RSA en-
cryption). The underestimation is because though the maximum
frequency used for the synthesized hardware functions in UCoP
of MOVE is adopted in the synthesis-based estimation method,
the actual frequency is always lower due to the synchronization
of data transfers among all system components. The overestima-
tion is because after the synthesis phase, the performance of a
hardware function in both the place and route phase and the bit-
stream generation phase can be still improved, and thus the exe-
cution frequency evaluated in the synthesis phase is not always
the most ideal. If the frequency was evaluated after a post-layout
simulation, instead of after the synthesis phase, the problem of
overestimation and underestimation may be alleviated.
For a networked multimedia application, the DPRNSS must
be able to process fifty 128 128 pixel images using the crypto-
graphic and hash hardware functions with a QoS requirement of
total 15 s. Fig. 10 compares the evaluation of the execution time
of cryptographic and hash operations applied to 50 image data
using MOVE and the synthesis-based estimation method [10].
When the RSA encryption is used, the design results based on
the synthesis-based estimation method shows that the RSA en-
cryption for 50 images needs 16.302 s, that is, the QoS cannot be
achieved; however, in reality it can be achieved as measured in
MOVE (the RSA encryption for 50 images needs 13.763 s). The
time inaccuracy could cause a very serious problem, especially
when hard real-time constraints are violated. In contrast to the
inaccurate synthesis-based estimation method, MOVE provides
the exact measured timing results.
For PSV, using inaccurate time estimation methods may also
result in incorrect design choices and wrong decisions. Thus,
designers are forced to perform additional iterations to rectify
the system design until all system requirements are satisfied.
Without loss in generality, let us assume that the inaccuracy in
execution time estimation using the synthesis-based method
is more than 5% for each of the 11 hardware operations in
the DPRNSS example. Thus, a designer needs at least 11
more iterations to reintegrate the 11 reconfigurable hardware
functions into the DPRNSS, and then verify and estimate them
again. According to our implementation experience, when a
new hardware function is integrated into an existing DPRS
design, it would approximately need 0.5 working day. As a
result, due to the exact measured timing results using MOVE,
it needs only 5.5 working days to integrate 11 hardware func-
tions into the DPRNSS. However, compared to MOVE, the
synthesis-based estimation method would need at least extra
5.5 working days for the DPRNSS design due to its inaccurate
time estimation. This shows that, compared to the existing
synthesis-based method, MOVE can speed up the PSV of the
DPRNSS design by at least two times. Further, because the
DPRS verification and estimation using MOVE are mainly
model-based, the previous work [1], [19] have demonstrated
that the model-based method is very helpful to the development
and design of a DPRS.
D. DPRNSS Generation
As described in Fig. 2, after the PSV phase, the software ex-
ecutables, the platform APIs, and the hardware bitstreams are
thus integrated into the target system platform to generate the
final DPRNSS. Based on the two-phase verification and estima-
tion process of MOVE and the tradeoffs in term of strength and
performance for each reconfigurable hardware function, the re-
configuration policy of DPRNSS needs to be defined.
As described in Table IV, the time for configuring the hash
hardware functions into are approximately the same,
and that for configuring the cryptographic hardware functions
into are also approximately the same. As a result, the
performance of each reconfigurable hardware function depends
on its execution time. Based on the execution time measured by
MOVE in Table IV for each reconfigurable hardware function,
we classify the cryptographic and hash hardware functions
individually into different performance levels. From the high-
to low-performance levels, the corresponding cryptographic
hardware functions are AES, 3DES, DES, and RSA in order,
while the corresponding hash hardware functions are CRC128,
CRC64, and CRC32 in order. Based on the strengths in en-
suring data security and data integrity, the cryptographic and
hash hardware functions, respectively, can be also classified
individually into different strength levels. From the high to
low strength levels, the corresponding cryptographic hardware
functions are AES, 3DES, DES, and RSA in order, while the
corresponding hash hardware functions are CRC128, CRC64,
and CRC32 in order. Both the orders of performance levels
and strength levels for the cryptographic and hash hardware
functions are the same in the DPRNSS.
To both ensure data security on the network and to provide
better performance of data encryption and decryption, when the
DPRNSS receives a request from a receiver on the network,
it negotiates with the receiver from the highest performance
and strength levels of the cryptographic and hash functions to
the lowest ones, until both the DPRNSS and the receiver can
use the same cryptographic and hash algorithms. Then, the re-
quired cryptographic and hash hardware functions are config-
ured on-demand into the FPGA device of DPRNSS. When the
DPRNSS receives more than two requests, it would first nego-
tiate with the high-priority receiver and then configure the re-
quired hardware functions into the FPFA device. Here, the pri-
HUANG AND HSIUNG: MODEL-BASED VERIFICATION AND ESTIMATION FRAMEWORK FOR DPRS 301
[4] S. Burmester, H. Giese, and W. Schafe, “Model-driven architecture for
hard real-time systems: From platform independent models to code,”
in Proc. 1st Eur. Conf. Model Driven Architecture—Foundations and
Applications (ECMDA-FA), Oct. 2005, vol. 3748, LNCS, pp. 25–40.
[5] E. M. Clarke and E. A. Emerson, “Design and sythesis of synchroniza-
tion skeletons using branching time temporal logic,” in Proc. Logics of
Programs Workshop, May 1981, vol. 131, LNCS, pp. 52–71.
[6] A. DeHon, Y. Markovsky, E. Caspi, M. Chu, R. Huang, S. Perissakis,
L. Pozzi, J. Yeh, and J. Wawrzynek, “Stream computations organized
for reconfigurable execution,” Microprocess. Microsyst., vol. 30, no. 6,
pp. 334–354, Mar. 2006.
[7] T. A. Henzinger, X. Nicollin, J. Sifakis, and S. Yovine, “Symbolic
model checking for real-time systems,” Inform. Comput., vol. 111, no.
2, pp. 394–406, Jun. 1992.
[8] P.-A. Hsiung, S.-W. Lin, Y.-R. Chen, C.-H. Huang, C. Shih, and W. C.
Chu, “Modeling and verification of real-time embedded systems with
urgency,” J. Syst. Softw., vol. 82, no. 10, pp. 1627–1641, Oct. 2009,
10.1016/j.jss.2009.03.013.
[9] P.-A. Hsiung, S.-W. Lin, C.-H. Tseng, T.-Y. Lee, J.-M. Fu, and W.-B.
See, “VERTAF: An application framework for the design and verifi-
cation of embedded real-time software,” IEEE Trans. Softw. Eng., vol.
30, no. 10, pp. 656–674, Oct. 2004.
[10] C.-H. Huang and P.-A. Hsiung, “Software-controlled dynamically
swappable hardware design in partially reconfigurable systems,”
EURASIP J. Embedded Syst., 2008, 10.1155/2008/231940, Article ID
231940.
[11] C.-H. Huang and P.-A. Hsiung, “UML-based hardware/software co-de-
sign platform for dynamically partially reconfigurable network security
systems,” in Proc. 13th IEEE Asia-Pacific Comput. Syst.s Architecture
Conf. (ACSAC), Aug. 2008, 10.1109/APCSAC.2008.4625436.
[12] C.-H. Huang and P.-A. Hsiung, “On the use of a UML-based HW/SW
co-design platform for reconfigurable cryptographic systems,” in Proc.
IEEE Int. Symp. Circuits Syst. (ISCAS), May 2009, pp. 2221–2224.
[13] J. Kim, I. Kang, J.-Y. Choi, and I. Lee, “Timed and resource-oriented
statecharts for embedded software,” IEEE Trans. Ind. Informat., vol. 6,
no. 4, pp. 568–578, Nov. 2010.
[14] M. Kloetzer, C. Mahulea, C. Belta, and M. Silva, “An automated
framework for formal verification of timed continuous petri nets,”
IEEE Trans. Ind. Informat., vol. 6, no. 3, pp. 460–471, Aug. 2010.
[15] P. Lysaght, B. Blodget, J. Mason, J. Young, and B. Bridgford, “En-
hanced architectures, design methodologies and CAD tools for dy-
namic reconfiguration of Xilinx FPGAS,” in Proc. Int. Conf. Field Pro-
grammable Logic and Appl. (FPL’06), Aug. 2006, pp. 12–17.
[16] G. Madl, S. Pasricha, N. Dutt, and S. Abdelwahed, “Cross-abstraction
functional verification and performance analysis of chip multiprocessor
designs,” IEEE Trans. Ind. Informat., vol. 56, no. 3, pp. 241–256, Aug.
2009.
[17] R. Manevich, J. Field, T. A. Henzinger, G. Ramalingam, and M. Sagiv,
“Abstract counterexample-based refinement for powerset domains,” in
Proc. Program Anal. Compilation, Theory and Practice, 2007, vol.
4444, LNCS, pp. 273–292.
[18] E. Monmasson and M. N. Cirstea, “FPGA design methodology for in-
dustrial control systems—A review,” IEEE Trans. Ind. Electron., vol.
54, no. 4, pp. 1824–1842, Aug. 2007.
[19] I. R. Quadri, S. Meftali, and J.-L. Dekeyser, “High level modeling of
dynamic reconfigurable FPGAs,” Int. J. Reconfigurable Computing,
2009, 10.1155/2009/408605, Article ID 408605.
[20] J. P. Queille and J. Sifakis, “Specification and verification of concurrent
systems in CESAR,” in Proc. Int. Symp. Program., Apr. 1982, vol. 137,
LNCS, pp. 337–351.
[21] A. Raabe, P. A. Hartmann, and J. K. Anlauf, “ReChannel: Describing
and simulating reconfigurable hardware in systemC,” ACM Trans. De-
sign Autom. Electron. Syst., vol. 13, no. 1, pp. 1–18, Jan. 2008.
[22] J. J. Rodriguez-Andina, M. J. Moure, and M. Valdes, “Features, design
tools, and application domains of FPGAs,” IEEE Trans. Ind. Electron.,
vol. 54, no. 4, pp. 1810–1823, Aug. 2007.
[23] T.-Y. Sun, S.-T. Hsieh, H.-M. Wang, and C.-W. Lin, “Floorplanning
based on particle swarm optimization,” in Proc. IEEE Comput. Soc.
Annu. Symp. VLSI, 2006, pp. 7–11.
[24] F. Wang and P.-A. Hsiung, “Efficient and user-friendly verification,”
IEEE Trans. Comput., vol. 51, no. 1, pp. 61–83, Jan. 2002.
Chun-Hsian Huang received the B.S. degree in in-
formation and computer education from the National
TaiTung University, TaiTung, Taiwan, and the Ph.D.
degree in computer science and information engi-
neering from the National Chung Cheng University,
Chiayi, Taiwan, in 2004 and 2011, respectively.
His research interests include reconfigurable
computing and system design, hardware/software
codesign and coverification, UML-based em-
bedded system design methodology, NoC-based
architecture design, ubiquitous computing,
and formal verification.
Pao-Ann Hsiung (SM’07) received the Ph.D. degree
in electrical engineering from the National Taiwan
University, Taiwan, in 1996.
He is currently a Full Professor in the Department
of Computer Science and Information Engineering,
National Chung Cheng University, Chiayi, Taiwan.
He has published more than 200 papers in interna-
tional journals and conferences. His main research in-
terests include reconfigurable computing and system
design, multicore programming, cognitive radio ar-
chitecture, system-on-chip (SoC) design and verifica-
tion, embedded software synthesis and verification, real-time system design and
verification, hardware-software codesign and coverification, and component-
based object-oriented application frameworks for real-time embedded systems.
Dr. Hsiung is a senior member of the ACM, and a life member of the
IICM. He was a recipient of the 2010 Outstanding Research Award, the 2004
Young Scholar Research Award, National Chung Cheng University, and the
2001 ACM Taipei Chapter Kuo-Ting Li Young Researcher for his significant
contributions to design automation of electronic systems. He also received the
Advisor Awards for Best Master Thesis for nine continuous years (2002–2009),
embedded system competitions, and RFID design competitions. He has been
included in several professional listings such as Marquis’ Who’s Who in the
World, etc. He is an editorial board member of six International Journals and
has been on the program committee of more than 80 international conferences.
He served as organizer for PDPTA’99, RTC’99, DSVV’2000, PDES’2005,
WoRMES’2009, ITNG’2010, ITNG’2011, AVTA’2011, and ERSA’2011.
9: 2 · P.-A. Hsiung et al.
ACM Reference Format:
Hsiung, P.-A., Huang, C.-H., Shen, J.-S., and Chiang, C.-C. 2010. Scheduling and placement of
hardware/software real-time relocatable tasks in dynamically partially reconfigurable systems.
ACM Trans. Reconfig. Techn. Syst. 4, 1, Article 9 (December 2010), 32 pages.
DOI: 10.1145/1857927.1857936. http://doi.acm.org/10.1145/1857927.1857936.
1. INTRODUCTION
Embedded systems such as hand-held mobile devices typically consists of a
microprocessor running software and some IC chips for hardware execution.
Such systems are restricted in computing power and usable energy. On one
hand, if most applications are executed on the microprocessor to reduce energy
consumption, the system will have unacceptably low performance. On the other
hand, if most applications are executed by hardware chips to increase comput-
ing power, the system will have unacceptably high energy consumption. With
the rapid progress in digital convergence through integration of complex appli-
cations, it has become increasingly difficult to achieve a good tradeoff between
computing power and energy consumption.
Hardware is characterized by high computing power with high energy con-
sumption, while software is characterized by low computing power with low en-
ergy consumption. Under this observation, achieving a good trade-off between
computing power and energy consumption simply amounts to trading off be-
tween hardware and software. However, conventional embedded systems have
fixed hardware and software, which makes this trade-off difficult. As a solution
to this issue, runtime reconfigurable logic devices such as FPGA has made pos-
sible the dynamic switching between hardware and software implementations
of the same function. This is the general motivation for this work on scheduling
tasks that can dynamically switch between their hardware and software imple-
mentations. With increasing system workload, a multimedia task that requires
high computing power can switch from software to hardware. With decreasing
battery energy, a network application that requires high energy consumption
can switch from hardware to software.
With the advent of the runtime partial reconfiguration technology in FPGA
devices such as Xilinx Virtex series, hardware designs can now be preempted
and restored just like software tasks. The gradually fading distinction between
hardware and software has made possible for a function to be executed both
as software on microprocessors and as hardware in reconfigurable logic. As
a result, the hardware-software partitioning of a system can be dynamically
changed through task relocation, which preempts a hardware task and restores
it as a software task with the same functionality, or vice versa. For task reloca-
tion, system architectural support such as a common unified communication
interface is required among hardware and software tasks. A typical state-
of-the-art example is the POSIX threads API that is used by both software
pthreads and hardware hthreads [Andrews et al. 2008; Peck et al. 2006]. How-
ever, task relocation requires hardware reconfigurations that take a significant
amount of time, probably affecting the schedulability of the tasks, and also
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 4 · P.-A. Hsiung et al.
Fig. 2. Relocatable tasks.
column of logic blocks that span the height of the chip, such as a CLB column
in Xilinx FPGAs. Based on the reconfiguration model, 1D RRA is further clas-
sified into paged or segmented, which corresponds semantically to the memory
management schemes often found in operating systems. In the paged scheme,
also known as slot-based architecture, RRA is divided into fixed size slots and
a hardware task must occupy one or more slots, possibly resulting in internal
fragmentation. In the segmented scheme, parts of the RRA are allocated and
freed as and when required, which could result in both internal and external
fragmentation. In 2D RRA, the area is divided into rows of tiles and each tile
consists of several columns that span the height of the tile. Examples of 1D
RRA and 2D RRA include Xilinx Virtex II Pro and Virtex 4 or 5, respectively.
In a DPRS, as shown in Figure 2, a task is said to be relocatable if it has
at least one hardware implementation and one software implementation such
that both are preemptible with at least one pair of matching preemption points.
Two preemption points are said to be matching if they belong to two different
implementations of the same function and they occur at the same step of com-
putation such that switching from one implementation to another at the pre-
emption points allows continued correct execution of the function. In Figure 2,
state S in software and state T in hardware constitute a pair of matching pre-
emption points. For example, a Discrete Cosine Transform (DCT) function
could be designed, in both hardware and software, to preempt after process-
ing a block of 8× 8 pixels, but before the full image is transformed. In DPRS, a
hardware implementation could be a partial bitstream that is used to configure
the desired function into Xilinx FPGA devices, and a software implementation
is simply an executable program.
Informally, our target problem can be stated as follows. Given a dynam-
ically partially reconfigurable system with a reconfigurable resource area of
limited size and a set of relocatable tasks with real-time constraints, we need
to find a runtime feasible schedule for the tasks such that all task-related and
architecture constraints are satisfied and the hardware resource utilization is
maximized. In proposing a solution to this problem, the main issues are as
follows.
—How do we determine the initial system partitioning into hardware and soft-
ware tasks?
—How do we identify the scheduling points at which the system partitioning
may have to be modified?
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 6 · P.-A. Hsiung et al.
method which uses the concept of servers to reserve area and execution
time for tasks. Hsiung and Liu [2007] proposed a two-phase energy-efficient
hardware-software coscheduling algorithm that can reduce power consumption
of dynamically reconfigurable systems through dynamic voltage scaling for
software and common-hardware reuse.
Besides the pure scheduling methods, most schedulers for reconfigurable
systems are tightly integrated with placers that allocate a portion of RRA for
hardware tasks. Such schedulers/placers are also briefly described as follows.
Steiger et al. [2004] proposed horizon and stuffing techniques. The horizon
scheduler maintains an execution list, a reservation list, and a scheduling
horizon list. The execution list contains all currently executing tasks. The
reservation list stores all scheduled but not yet executing tasks. The schedul-
ing horizon list consists of elements hi = ([x1, x2]@tr), where [x1, x2] denotes
an interval in the x-dimension and tr is the least release time. When a
new task arrives, the horizon scheduler will find a suitable width from the
scheduling horizon list for the task. Different from the horizon scheduler, the
stuffing scheduler employs a free space list instead of the scheduling horizon
list. The free space list is a set of intervals [x1, x2] that identifies currently
unused resource intervals. When a task arrives, the stuffing scheduler will
find a suitable space from the free area. The stuffing technique has better
performance than the horizon method.
An improved version of stuffing called classified stuffing was proposed by
Chen and Hsiung [2005] to reduce fragmentation in RRA. In this technique,
two lists were used to record placement information, namely task list and space
list. The task list stores information of tasks placed into FPGA, and the space
list provides information for the placer to find a suitable free space for a task.
Based on the RRA space utilization ratio (SUR), tasks were classified into two
types. The placer used different placement strategies for the two types of tasks.
This technique shows significant benefits in both a shorter schedule and a com-
pact placement.
As far as pure placement strategies are concerned, existing methods usually
target different goals, including the reduction of RRA fragmentation such
as in best-fit placement [Bazargan et al. 2000], adjacency-based heuristic
and fragmentation-based heuristic placements [Tabero et al. 2004], and
fragmentation-aware placement [ElFarag et al. 2007], the minimization of
average routing costs for communicating hardware tasks [Ahmadinia et al.
2004a, 2004b, 2005], the efficiency in placing a task such as in first-fit and
bottom-left placements [Bazargan et al. 2000], and the reduction of configu-
ration overhead such as in least-interference-fit [Ahmadinia and Teich 2003].
A multi-objective hardware placement method [Liao 2007] was also proposed
recently to target at satisfying multiple goals at the same time, including the
minimization of fragmentation, minimization of the routing resources, and
minimization of the time for location selection.
Besides the above fitting strategies, the efficiency of resource management
has also become a major concern because it is quite time consuming to
maintain the data structures such as the task list, the free space list, and
the reserved space list during dynamic placement. Well-known methods
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 8 · P.-A. Hsiung et al.
to the bus. Figure 1 illustrated the architecture of DPRS. Tasks will be par-
titioned and scheduled. Software tasks will run on the microprocessor, while
hardware tasks will be placed, configured by the reconfiguration controller, and
then executed in the RRA.
3.1 DPRS System Model
Our target DPRS system model can be formalized as follows.
Definition 1. DPRS System Model. The DPRS system model is formally de-
fined by the tuple 〈Smp, Ssw,Carch,Cintf , Rtype, Rctrl, Rarea, Rplace, Rswitch〉, where
—Smp is the embedded microprocessor. In RHSS, we choose the PowerPC 405
microprocessor which is embedded in Xilinx Virtex II Pro FPGA.
—Ssw is the scheduling algorithm for software tasks. In RHSS, we choose the
earliest deadline first (EDF) algorithm for scheduling software tasks.
—Carch is the on-chip communication architecture. In RHSS, we choose the IBM
CoreConnect bus architecture, which includes a Processor Local Bus (PLB)
and an On-chip Peripheral Bus (OPB).
—Cintf is the unified communication interface for hardware and software tasks.
In RHSS, we consider the POSIX threads API for both software tasks
(Pthreads) and hardware tasks (Hthreads) [Andrews et al. 2008; Peck et al.
2006].
—Rtype is the type of reconfiguration technology. This could be paged 1D (slot-
based), segmented 1D, or 2D. In RHSS, we choose the segmented 1D model
because that is the most flexible reconfiguration technique available for Vir-
tex II Pro FPGAs.
—Rctrl is the reconfiguration controller. In RHSS, we choose the Xilinx ICAP
reconfiguration controller.
—Rarea is the size of the RRA, which is the maximum amount of reconfigurable
resources available for hardware tasks. The units could be columns of CLB
(Configurable Logic Blocks) for 1D reconfiguration as in Xilinx II Pro FPGA
or tiles of CLB for 2D reconfiguration as in Xilinx 4 and 5 series of FPGAs.
—Rplace is the placement algorithm used for hardware tasks. We will discuss
the low-fragmentation placer implemented in RHSS in Section 4.4.
—Rswitch is the method for hardware preemption and for context save and re-
store. We adopt the generic wrapper design model [Huang et al. 2007; Huang
and Hsiung 2008] for hardware preemption, context saving, and restoring.
The software, the hardware, and the communication characteristics of a
DPRS system model directly influence how relocatable tasks are to be sched-
uled because without the support of the operating system having a software
task scheduler and a hardware task placer, the hardware preemption tech-
niques, and the unified task communication interfaces, scheduling relocat-
able tasks becomes impossible. Nevertheless, when all the parameters of the
system model have taken appropriate values, the scheduling of relocatable
tasks becomes feasible. We further define the task model as follows.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 10 · P.-A. Hsiung et al.
Table I. Example Task Set
Ti ai di pi ki SEi Ui = SEi/pi HEi HCi HSi Pi = Ui/HSi
T1 0 16 16 7 6 3/8 4 10 1 3/8
T2 0 24 24 3 12 1/2 10 20 2 1/4
T3 0 48 48 3 6 1/8 6 20 2 1/16
T4 40 8 8 8 2 1/4 1 5 2 1/8
T5 58 12 12 5 7 7/12 3 9 3 7/36
In this problem, hi = 1 denotes the task Ti is scheduled as hardware, hi = 0
denotes software, and the summation
∑
1≤i≤n hiHSi represents the total amount
of reconfigurable resource area required by the hardware tasks. In fact, this is
the same as the well-known 0-1 knapsack problem [Pellizzoni and Caccamo
2006], which is an NP-complete problem, but can be solved using dynamic
programming in pseudo-polynomial time complexity of O(nRarea) and space
complexity of O(Rarea). However, this solution is optimal or feasible only for
the initial case of a fully empty RRA. At runtime, when hardware tasks are
being (re)configured into the RRA, dynamic programming is not only time-
consuming, but may also not provide a feasible or optimal solution.
3.4 Illustration Example
This is a simple example to illustrate the DPRS system model and the re-
locatable task model. The system is S = 〈PPC405, EDF, CoreConnect,
Pthreads/Hthreads, segmented 1D, ICAP, 5 columns, RHSS placer, Hardware
Wrapper〉. In this system, we need to schedule a set of five relocatable tasks
T = {T1,T2,T3,T4,T5} as shown in Table I. The task attributes (ai,di, pi,ki, Pi),
the software implementation characteristics (SEi,Ui), and the hardware imple-
mentation characteristics (HEi, HCi, HSi) are all given. The software utiliza-
tion (Ui = SEi/pi) and task priority (Pi = Ui/HSi) are calculated as described in
the previous subsection. Here, we assume that the matching preemption points
occur only between two jobs (instances) of a task. For example, for a 8× 8 DCT,
preemption can occur only between the transformation of two blocks and not
within a block. This is a valid assumption that is supported by multimedia and
communication functions.
From this small example, we can already observe that it is neither straight-
forward nor easy to check if the set of tasks T is schedulable in the system
S or not. This also shows the motivation for our work. The complexity in
schedulability checking is mainly due to two reasons, namely the dynamic
reconfigurability of the system and the relocatability of the tasks. The schedul-
ing results for this system will be illustrated in Section 4 after we propose the
RHSS method.
3.5 System Architecture
To support hardware-software task relocation, we now present a physically fea-
sible system that fits the DPRS system model given in Definition 1. Figure 3
illustrates a reconfigurable system implemented on the Xilinx ML310 platform
containing a Virtex II Pro XC2VP30-FF896 FPGA device, two PowerPC (PPC)
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 12 · P.-A. Hsiung et al.
Fig. 4. Relocatable hardware-software scheduling flow.
4. RELOCATABLE HARDWARE-SOFTWARE SCHEDULING
To solve the target scheduling problem of a set of relocatable tasks in a DPRS
system, we propose a Relocatable Hardware-Software Scheduler (RHSS). As
shown in Figure 4, RHSS requires a supporting infrastructure. Given the
DPRS system configurations and a set of relocatable tasks, RHSS tries to
find an initial hardware-software partitioning such that the software tasks are
scheduled by an EDF scheduler on the microprocessor and the hardware tasks
are placed on the FPGA for execution. At two different scheduling points, in-
cluding when a new task arrives and when a hardware task terminates, the
RHSS is invoked again. Task relocation further requires the support of two
more mechanisms, including context saving and restoring for both hardware
and software tasks and a common hardware-software task interface such that
a relocated task can resume communication with other tasks.
In the rest of this section, we will describe three algorithms used in RHSS,
namely the initial scheduling, the rescheduling, and the new task scheduling.
Initial scheduling will partition a set of relocatable tasks into hardware tasks
and software tasks such that all space and time constraints are met while hard-
ware resource utilization is maximized greedily. The rescheduling algorithm
will be invoked when a hardware task terminates and RRA space is released.
One or more software tasks will be relocated to RRA, if possible. The new task
scheduling algorithm is invoked when a new task arrives.
4.1 Initial Scheduling Algorithm
As described in Section 3.3, initially it is basically a 0-1 knapsack problem,
which is NP-complete. It can be solved using dynamic programming; how-
ever, it is too time-consuming. Thus, a greedy algorithm [Pellizzoni and
Caccamo 2006] was proposed, which is a near-optimal solution and is shown in
Algorithm 1.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 14 · P.-A. Hsiung et al.
and thereby incurring a lot of reconfigurations with context switching, our
rescheduling algorithm merely tries to find one or more software tasks that can
be placed into the RRA area released by the just terminated hardware task.
We can thus avoid a lot of reconfigurations and context switches. Algorithm 2
takes a finished task Ti and all the software tasks are sorted in decreasing
order of priorities in the list Ts. The software tasks are checked in this order
such that tasks with higher priorities will be checked and placed first. Though
there may be some software tasks with priorities higher than some hardware
tasks, however in general, there are very few such tasks because we usually
try to place the higher priority tasks into RRA first. With this observation, we
avoid performing a system-wide reshuffling and groupwise relocations as in
the AHSA method [Pellizzoni and Caccamo 2006]. The algorithm complexity
will be discussed in Section 4.5 and it will be illustrated in Section 3.4.
Algorithm 2: Rescheduling at Hardware Task Termination
input: finished-task Ti
begin
RemoveFromHwTaskQueue(Ti)
foreach Tj ∈ Ts do
if SearchEnoughArea(Tj) = true then
PlaceTask(Tj)
else
StayInSw(Tj)
end
end
end
4.3 New Task Scheduling Algorithm
Another scheduling point is when a new task Ti arrives. Algorithm 3 is the
scheduling algorithm applied when a new task arrives. First, we check whether
there is enough area for the new task or not. If there is not enough area avail-
able, the scheduler will check to see if there is any hardware task with prior-
ity lower than that of the new task. If there exists a hardware task Tj with
lower priority (Pj < Pi), its area HSj is not smaller than that of the new task
(HSj ≥ HSi), and Uj +Ucpu ≤ 1, then Tj is replaced by the new task Ti. Note
that from the above 3 conditions, Uj < Ui. However, if no single task can be
replaced by the new task, the scheduler will try to find a set of tasks to be
replaced. Algorithm 4 is the algorithm for the function FindSwitchTaskSet().
It scans through the hardware tasks to remove all tasks with priorities higher
than that of the new task, and puts the remaining into a list. It continues scan-
ning through the list to remove all tasks in contiguous areas that are smaller
than that of the new task. Then, it selects a task set R with the most suitable
area (best-fit) that at the same time satisfies the feasibility conditions given in
Definition 3, which specifies that the sum of the utilization of task set R and
the original utilization on the microprocessor must not exceed 1 because this
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 16 · P.-A. Hsiung et al.
Algorithm 4: FindSwitchTaskSet(Ti)
input : a place list Q of all placed tasks, arrived-task Ti
output: switch task set R
begin
RemoveHighPriority(Q,Ti)
RemoveSmallArea(Q,Ti)
while Q 	= null do
R ← SelectSuitableArea(Q,Ti)
if CheckFeasibility(R,Ti) = true then
return R
else
RemoveTaskSet(Q, R)
end
end
end
Ucpu+Ui ≤ 1 then Ti is executed in software for the first 
(trel + HCi + HEi)/pi
periods, after which it is executed as hardware.
4.4 Placement Algorithm
The placement algorithm proposed in this section implements the
PlaceTask(Ti) function in Algorithms 2 and 3. Since placement depends
on the type of reconfiguration technology, namely Rtype in Definition 1, we will
discuss the currently supported segmented 1D model of reconfiguration in
RHSS. The other types will be supported later and do not affect the correctness
of the proposed scheduling algorithms.
The segmented 1D model has the problem of external fragmentation, that is,
the free area in RRA is fragmented into several small ones such that the place-
ment of a large task becomes infeasible even if its area requirements is less
than the total available. As described in this section, we propose a segmented
1D placement algorithm that can help to alleviate this problem.
The placer uses two lists to record the allocation situations in the RRA. The
free area list L free is used to record the free areas in RRA, and the task area list
Ltask is used to record areas currently occupied by tasks. Initially, L free = {A0}
and Ltask = {}, where A0 is the full RRA, that is, |A0| = Rarea and |A| is the size
of a free area A in terms of columns. The new tasks are placed in the RRA
starting from the left side, that is, from the leftmost CLB column. After the
scheduler determines that a task Ti is ready to be placed in the RRA, the placer
will select a free contiguous area A j that is at least as large as and best fits the
size of the task, that is A j ∈ {Ak | |Ak| = min|A|≥HSi(A ∈ L free)}. The placer
removes the selected free area A j from the free area list and adds a new free
area A ′, such that |A ′| = |A j| − HSi, that represents the area left over after Ti
is placed. The free area list is thus updated as follows: L free = L free\{A j}∪{A ′}.
Specifically, if |A j| = HSi, then L free = L free\{A j}. Further, the placer also adds
the newly allocated task area to the occupied list, that is, Ltask = Ltask ∪ {A j}.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 18 · P.-A. Hsiung et al.
Fig. 6. After reduced fragmentation placement.
one that considers temporal behavior of adjacent tasks. Thus, the fragmenta-
tion is reduced even further by RFP over a length of time.
4.5 Complexity
As far as time complexity of our RHSS method is concerned, if we do not con-
sider the a priori sorting of software tasks that takes O(n logn), then the three
algorithms all take linear time complexity, where n is the number of tasks.
Note that Algorithm 4 can be implemented in O(n), so the time complexity of
Algorithm 3 is also O(n). This linear time complexity of RHSS shows the ef-
ficiency of our scheduler when compared to the quadratic time complexity of
the AHSA method proposed in Pellizzoni and Caccamo [2006]. We can reduce
the time complexity to linear because we do not perform groupwise system-
wide reshuffling of all hardware and software tasks. Nevertheless, we can still
achieve higher hardware resource utilizations as evident from the experiment
results in Section 5.
It is important to note that the given complexity analysis for both RHSS
and AHSA assumes that task placements can be performed in O(1) constant
time. However, as described in Section 4.4, we see that our proposed RFP takes
O(n) linear time complexity. Further, PlaceTask(Ti) is invoked in the foreach
loop over the software tasks in Algorithm 2 and in the foreach loop over the
hardware tasks in Algorithm 3. Thus, considering the linear complexity of
placement, the actual complexity of RHSS becomes O(n2). Similarly, if the
task placement was explicitly considered in AHSA and if the placement was at
least linear in complexity, then the actual complexity of AHSA would become at
least O(n3).
4.6 Scheduling Illustration Example
We applied our relocatable hardware-software scheduling algorithm to the
illustration example introduced in Section 3.4. Recall that the system is
S = 〈PPC405, EDF, CoreConnect, Pthreads/Hthreads, segmented 1D, ICAP,
5 columns, RFP, Hardware Wrapper〉 and the set T of 5 tasks was specified in
Table I. The RHSS and AHSA scheduling results are shown in Figures 7 and 8,
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 20 · P.-A. Hsiung et al.
consider placement restrictions explicitly, we impose the same restriction on
AHSA for a fair comparison. The three tasks are placed in order of decreasing
priority, that is, T1,T2,T3, and they occupy the full RRA of 5 columns.
At time 40, when task T4 arrives, there is no hardware task executing in
RRA that has priority lower than than of T4, hence Algorithm 3, the new task
scheduling algorithm in RHSS, decides that T4 should execute as software.
However, as shown in Figure 8, AHSA performs another greedy allocation at
time 40, which results in task T3 being preempted while it was still under con-
figuration (not yet started execution), and task T4 is configured starting from
time 40. Thus, task T3 is executed as software in its second period [48,54] in
AHSA, while as hardware in RHSS.
At time 58, two things happen as follows: (1) Task T2 terminates because
k2 = 3, and (2) Task T5 arrives. In this situation, RHSS does the following.
The area occupied by T2 is first released and then the new task scheduling
algorithm (Algorithm 3) is executed followed finally by the rescheduling
algorithm (Algorithm 2). Since the priority P5 = 7/36 is higher than
P3 = 1/16 and HS3 + 2 = 4 < HS5 (2 columns were released by T2 after
termination), task T3 is the candidate victim to be replaced by T5. Further,
U3 +Ucpu = U3 +U4 = 1/8 + 1/4 = 3/8 < 1 and U3 < U5; hence, the feasibility
conditions in Definition 3 are all satisfied and task T3 is selected to be swapped
out from RRA into a software task. Task T5 is then placed into RRA and
executes as a hardware task. Finally, when the rescheduling algorithm is ap-
plied, it is found that there is only 1 column free in the RRA, whereas both the
software tasks T3 and T4 need 2 columns each. Hence, the system continues
executing with tasks T3 and T4 as software and tasks T1 and T5 as hardware.
At time 58, AHSA performs another greedy allocation and finds that the set
of tasks {T1,T5} should be executed as hardware and the set {T3,T4} should be
executed as software. Thus, a group swapping takes place between hardware
and software for task sets {T4} and {T5}, which results in task T4 being swapped
from hardware to software and task T5 configured as hardware.
For this illustration example, we compared the results of applying AHSA
[Pellizzoni and Caccamo 2006] with that of our proposed RHSS algorithm. Ini-
tially, both AHSA and RHSS give similar results, but at the future scheduling
time points 40 and 58, there are some differences. Detailed comparisons are as
follows.
—ConfigurationModel. AHSA assumes that RRA adopts the paged 1D (slotted)
model, where each task occupies a multiple of some fixed area size (number
of columns). RHSS assumes that the RRA adopts the segmented 1D model,
which is more flexible than the paged model because there is no restriction
on the sizes of tasks. More importantly, AHSA does not consider hardware
configuration time and placement restrictions explicitly, which results in a
nonrealistic configuration model. On the other hand, RHSS explicitly con-
siders both configuration time and placement restrictions.
—Performance. The time complexity of AHSA is O(n2), while that of our RHSS
algorithm is O(n), where n is the number of tasks. Our algorithm performs
and scales better when the number of tasks is very large. For the simple
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 22 · P.-A. Hsiung et al.
Table II. Six Cases of Random Task Sets
Case |T| pi SEi HEi HCi HSi
A Varying [80,100] 3 × HEi [1,5] 5 × HSi [1,5]
B 50 Varying 3 × HEi [1,5] 5 × HSi [1,5]
C 50 [80,100] Varying [1,5] 5 × HSi [1,5]
D 50 [80,100] 3 × HEi Varying 5 × HSi [1,5]
E 50 [80,100] 3 × HEi [1,5] Varying [1,5]
F 50 [80,100] 3 × HEi [1,5] 5 × HSi Varying
Varying: 10 different value ranges.
varied all the other 6 features of the tasks, namely |T|, pi, SEi, HEi, HCi,
and HSi, one at a time, as described in the following six cases, respectively,
where 10 random task sets were generated for each case. The cases are all
summarized in Table II.
—Case A. Varying Number of Tasks: The number of tasks in a task set was
varied as follows: |T| ∈ {5,10,20,40,60,80,100,150,200,300}. The other
5 attributes were as follows: pi ∈ [80,100], HEi ∈ [1,5], SEi = 3 × HEi,
HCi = 5 × HSi, and HSi ∈ [1,5].
—Case B. Varying Average Task Utilization: The average task utilization (AU),
defined as
∑
i Ui/|T|, was varied by choosing 10 different period ranges pi ∈
[1,50], [51,100], . . . , [451,500] such that AU was gradually decreased from
0.322 to 0.019. The other 5 attributes were as follows: |T| = 50, HEi ∈ [1,5],
SEi = 3 × HEi, HCi = 5 × HSi, and HSi ∈ [1,5].
—Case C. Varying Software Task Execution Time: The software execution time
was defined as an integer multiple of the hardware execution time, that is,
SEi = c × HEi, c > 0. Ten different values of the multiple c were chosen,
that is, c ∈ {1,2,3,5,10,15,20,30,50,100}, which covers a wide range of
possibilities. The other 5 attributes are as follows: |T| = 50, pi ∈ [80,100],
HEi ∈ [1,5], HCi = 5 × HSi, and HSi ∈ [1,5].
—Case D. Varying Maximum Hardware Task Execution Time: The hard-
ware execution time was varied by setting 10 different maximum values as
in {[1,1], [1,2], [1,5], [1,10], [1,15], [1,20], [1,30], [1,50], [1,100], [1,200]}.
The other 5 attributes were as follows: |T| = 50, pi ∈ [80,100], SEi = 3×HEi,
HCi = 5 × HSi, and HSi ∈ [1,5].
—Case E. Varying Hardware Task Configuration Time: The hardware task
configuration time was assumed to be a multiple of the hardware task size,
that is, HCi = m × HSi. This is a valid assumption for segmented 1D re-
configuration, where the reconfiguration time is directly proportional to the
number of RRA columns to be configured. We varied the multiple as follows:
m ∈ {1,2,5,10,20,30,50,80,100,200}. The other 5 attributes are as follows:
|T| = 50, pi ∈ [80,100], SEi = 3 × HEi, HEi ∈ [1,5], and HSi ∈ [1,5].
—Case F. Varying Maximum Hardware Task Size: The maximum hardware
task size (Max HS), defined as maxi(HSi), was varied in increments of 5
columns, that is, HSi ∈ [1,5], [1,10], . . . , [1,50]. The other 5 attributes
are as follows: |T| = 50, pi ∈ [80,100], SEi = 3 × HEi, HEi ∈ [1,5], and
HCi = 5 × HSi.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 24 · P.-A. Hsiung et al.
Fig. 9. Varying total number of tasks |T| (Case A).
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 26 · P.-A. Hsiung et al.
Fig. 11. Hardware utilizations and improvements in Cases (E)–(F).
maximum hardware execution time HEi. However, in case C, HU decreases
rapidly with the increasing software execution time SEi. Further, in Cases E
and F, HU is basically unaffected by either increasing hardware configura-
tion time HCi or increasing hardware task size HSi. All of the above results
conform to our expectations because HU is related to only the task execution
time and period represented by AU, HEi, and SEi.
—In 87% of the task sets, the scheduling results of RHSS demonstrated a
higher average hardware utilization HU, which shows that RHSS can
make better utilization of the limited RRA hardware resources than AHSA.
Further, from the HU curves on the right-hand-side RHSS vs. AHSA Im-
provements (%) graphs, we can observe that RHSS can increase HU by more
than 40% compared to AHSA. The increase in hardware utilization by RHSS
becomes significant, that is more than 8% compared to AHSA, in each of the
following situations: (a) large number of tasks |T| ≥ 40 (Case A), (b) high
average task utilization AU ≥ 0.08 (Case B), (c) limited software execution
time SEi = c × HEi, c ∈ [1,5] (Case C), (d) limited hardware execution time
8 ≤ HEi ≤ 20 (Case D), (e) moderate configuration time HCi = m × HSi,
m ∈ [10,70], HSi = [1,5] (Case E). (f) small and large maximum hardware
task sizes, Max HS∈ [5,25] ∪ [40,45] (Case F).
—As far as the number of task rejections is concerned, out of the total 60
experiments performed, in 43 experiments RHSS and AHSA rejected the
same number of tasks. However, in 16 experiments, RHSS rejected more
tasks than AHSA to achieve a better hardware utilization and to make
ACMTransactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 28 · P.-A. Hsiung et al.
Table III. Task Attributes of Real Tasks
Function SEi (ns) HEi (ns) HCi (ns) HSi (columns)
MD5 200 190 132,800 4
SHA-1 670 190 166,000 5
DES 990 60 66,400 2
Triple-DES 1,960 70 199,200 6
AES 910 220 33,200 1
Table IV. Ten Cases of Real Tasks
|Ti| |T|Case Task set feature (Ti)
MD5 SHA-1 DES Triple-DES AES (total)
A Uniform, few 20 20 20 20 20 100
B Uniform, many 92 92 92 92 92 460
C Large diff, many 30 40 130 180 80 460
D Large diff, few 180 130 45 35 70 460
E Large size, many 100 140 35 160 25 460
F Large size, few 75 55 140 30 160 460
G Large SEi, many 20 60 100 200 80 460
H Large SEi, few 200 130 50 30 50 460
I Large HEi, many 125 125 25 35 150 460
J Large HEi, few 50 50 155 180 25 460
Uniform: Ti = Tj, Large diff: SEi >> HEi, Large size: HSi is large.
few: |Ti| is small, many: |Ti| is large.
(SEi >> HEi), large sized tasks (HSi is large), large SEi, or large HEi. We
believe these ten cases represent most types of realistic application scenarios.
Figure 12 shows the results of applying RHSS and AHSA to the ten cases
of dynamically reconfigurable network security system task set. In contrast to
the random task experiments, the real task experiments show that RHSS is not
only consistently superior to AHSA in terms of lower scheduling time and lower
memory usage, but can also achieve much higher hardware utilization. We
observe that compared to AHSA, RHSS achieves the following improvements:
(a) the hardware utilization is improved by at least 22% (in Case F) to at most
117.8% (in Case B), (b) the scheduling time is reduced by at least 59.7% (in
Case J) to at most 68.6% (in Case A), and (c) the memory usage is reduced by
at least 70% (in Case B) to at most 93.1% (in Case A). The numbers of tasks
rejected by RHSS and by AHSA are not shown because they are all 0.
As far as the relationship between the task set features and the hardware
utilization is concerned, we observe that the hardware utilization is relatively
high (HU > 0.1% in RHSS) for five of the ten cases, namely Cases A, B, E, H,
and I, which, respectively, represent the features of few and many tasks with
uniform distribution, many large sized tasks, few tasks with large software
execution time SEi, and many tasks with large hardware execution time HEi.
From this observation, we can conclude that the hardware utilization can be
enhanced if we have more large sized tasks, fewer tasks with large software
execution time, and more tasks with large hardware execution time.
Compared to the random task experiments, RHSS can achieve much higher
hardware utilization in the real task experiments. For random tasks, RHSS
increased HU by at most 40%, whereas for real tasks, RHSS increased HU by
ACMTransactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 30 · P.-A. Hsiung et al.
more than 68% in 8 out of the 10 cases, achieving a maximum of 117.8% in
Case B (many tasks with uniform distribution). This shows that RHSS works
well not only with random tasks, but also for real task sets under several dif-
ferent application scenarios, and especially for those cases in which there are
many tasks with large sizes and large hardware execution time.
6. CONCLUSIONS
A relocatable hardware-software scheduling method with a reduced fragmen-
tation placement method were proposed for, respectively, scheduling and plac-
ing relocatable tasks in dynamically partially reconfigurable systems such that
the task timing constraints and the architecture constraints are met, while
the hardware resource utilization is maximized. Compared to the adaptive
hardware-software allocation method, our proposed method is lower in time
complexity (linear instead of quadratic), uses lesser memory space (by as much
as 93%), and most importantly generates schedules and placements that have
significantly higher hardware resource utilizations (by as much as 117.8%).
The proposed methods were implemented and applied to 60 random task sets
and 10 real task sets, covering a wide range of possible application scenar-
ios. The experimental results prove the superiority of our methods in terms
of higher hardware utilization, lesser scheduling time, and lesser memory us-
age. A limitation of the proposed work is the slightly higher number of task
rejections. The future work will consist of reducing the number of task rejec-
tions, the integration of the proposed scheduling and placement methods into
an operating system for reconfigurable systems, and the enhancement of the
proposed scheduler with more sophisticated placement methods. The unified
hardware-software communication interface will also be a direction for extend-
ing the proposed methods.
REFERENCES
ABENI, L. AND BUTTAZZO, G. 1998. Integrating multimedia applications in hard real-time sys-
tems. In Proceedings of the 19th IEEE Real-Time Systems Symposium. IEEE Computer Society,
4–13.
AHMADINIA, A. AND TEICH, J. 2003. Speeding up online placement for Xilinx FPGAs by reduc-
ing configuration overhead. In Proceedings of the IFIP International Conference on VLSI-SoC.
118–122.
AHMADINIA, A., BOBDA, C., BEDNARA, M., AND TEICH, J. 2004. A new approach for on-line
placement on reconfigurable devices. In Proceedings of the International Parallel and Distributed
Processing Symposium. IEEE CS Press, 134.
AHMADINIA, A., BOBDA, C., FEKETE, S. P., TEICH, J., AND VAN DER VEEN, J. C. 2004. Optimal
routing-conscious dynamic placement for reconfigurable devices. In Proceedings of the 14th Inter-
national Conference on Field-Programmable Logic and Applications. Lecture Notes in Computer
Science, vol. 3203. Springer, 847–851.
AHMADINIA, A., BOBDA, C., AND TEICH, J. 2005. Online placement for dynamically reconfigurable
devices. Int. J. Embed. Syst. 1, 3–4, 165–178.
ANDREWS, D., SASS, R., ANDERSON, E., AGRON, J., PECK, W., STEVENS, J., BAIJOT, F., AND
KOMP, E. 2008. Achieving programming model abstractions for reconfigurable computing. IEEE
Trans. VLSI Syst. 16, 4, 34–44.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
9: 32 · P.-A. Hsiung et al.
PORRMANN, M., KALTE, H. G. L., AND RU¨CKERT, U. 2005. Replica: A bitstream manipulation
filter for module relocation in partial reconfigurable systems. In Proceedings of the 12th Recon-
figurable Architectures Workshop.
STEIGER, C., WALDER, H., PLATZNER, M., AND THIELE, L. 2003. Online scheduling and place-
ment of real-time tasks to partially reconfigurable devices. In Proceedings of the 24th IEEE In-
ternational Real-Time Systems Symposium. IEEE Computer Society Press.
STEIGER, C., WALDER, H., AND PLATZNER, M. 2004. Operating systems for reconfigurable em-
bedded platforms: Online scheduling of real-time tasks. IEEE Trans. Comput. 53, 11, 1393–1407.
TABERO, J., SEPTIEN, J., MECHA, H., AND MOZOS, D. 2004. A low fragmentation heuristic for
task placement in 2D RTR HW management. In Proceedings of the International Conference on
Field-Programmable Logic and Applications. Springer Verlag, 241–250.
WALDER, H. AND PLATZNER, M. 2003. Online scheduling for block-partitioned reconfigurable de-
vices. In Proceedings of the Conference on Design, Automation and Test in Europe (DATE). IEEE
Computer Society, 10290–10295.
WALDER, H., STEIGER, C., AND PLATZNER, M. 2003. Fast online task placement on FPGAs: Free
space partitioning and 2d-hashing. In Proceedings of the International Parallel and Distributed
Processing Symposium. Vol. 17. IEEE Computer Society Press.
Received May 2008; revised April 2009; accepted August 2009
ACM Transactions on Reconfigurable Technology and Systems, Vol. 4, No. 1, Article 9, Pub. date: December 2010.
III. PRESSNOC WITH REAL FRAMEWORK
Three different types of reconfiguration are supported by
PRESSNoC, namely PE reconfiguration, router reconfigura-
tion, and encoding scheme reconfiguration. PE reconfiguration
allows different PEs to be connected to the NoC at run-time
to support versatile applications. As a result, the bandwidth
requirements change over time, which cannot be satisfied by
routers with fixed buffer sizes. Thus, PRESSNoC also supports
router reconfiguration. The encoding method associated with
each PE-router pair can also be reconfigured to meet the run-
time requirements of reliability and power efficiency instead
of pre-integrating all encoding strategies into an NoC at design
time. The overheads in terms of hardware resources and power
consumption are thus reduced by PRESSNoC.
In the following, we first introduce the software/hardware
support for PE reconfiguration and the process of router
reconfiguration. After that, we describe the proposed encoding
strategies for reliability and dynamic power efficiency. Finally,
we will describe the reasoning and learning framework of
PRESSNoC.
A. Reconfiguration of Processing Elements and Routers
For supporting versatile applications, the PEs can be cus-
tomized to the required functionality for applications. To stan-
dardize the software/hardware intercommunication, we utilize
the Intellectual Property Interface (IPIF) provided by Xilinx to
connect the PRESSNoC and the host system. The PRESSNoC
IPIF wrapper provides a register bank to store the commands
for packet read/write operations and for reconfiguration con-
trol including individual PE reset control and destination PE
address modification.
Router reconfiguration is required for supporting different
bandwidth requirements of PEs; however, to prevent packet
loss during router reconfiguration, the PRESSNoC router
utilizes a Buffer checker and a NACK controller
to monitor the packets in buffers and to disable it from
receiving packets, respectively. Figure 1 shows the process
of router reconfiguration. If there is a router which needs to
be reconfigured, the Reconfiguration preparation
signal will be asserted (high) and then the router will start
to monitor the header_out signal. In Figure 1 (a), a
neighbor router sent a packet to the router which needs to
be reconfigured. We can see the header flit of the packet
is already in the router which needs to be reconfigured thus
the neighbor router asserts the head_out signal. However,
in Figure 1 (b), the neighbor router starts to process the
new packet and deasserts the header_out signal because
the header flit is still in the neighbor router. After that,
the NACK controller in the router which needs to be
reconfigured will deassert the Ack_Tx signal so the neighbor
router cannot send the new packet to it. At this time, the
router which needs to be reconfigured can send packets to
other routers until its input buffers are empty. When the flits
in the input buffers are depleted, the Buffer checker will
assert the Reconfiguration ready signal to enable the
reconfiguration.
d: data flith: header flit c: counter flit
Tx = 1 (1 bit)
Flit (8 bits)
Ack_Tx = 1 (1 bit)
header_out = 1 (1 bit)
Neighbor Router
1 2 3 4
d d d h c
0
The router needs to be 
reconfigured
0 1 2 3
d d
4
dh c
(a) Scenario 1 for preparing router reconfiguration
A basic buffer unit which is 
equal to the size of a flit.
NACK
controller
Buffer
checker
Reconfiguration preparation
Tx = 1 (1 bit)
Flit (8 bits)
Ack_Tx = 0 (1 bit)
header_out = 0 (1 bit)
Neighbor Router
1 2 3 40
The router needs to be 
reconfigured
0 1 2 3
d d
4
dd d d ddh c
Tx = 1 (1 bit)
Flit (8 bits)
Ack_Tx = 0 (1 bit)
header_out = 0 (1 bit)
Neighbor Router
1 2 3 40
The router needs to be
reconfigured
0 1 2 3
d
4
dd d d ddh c
(b) Scenario 2 for preparing router reconfiguration
(c) Scenario 3 for preparing router reconfiguration
Reconfiguration ready
NACK
controller
Buffer
checker
NACK
controller
Buffer
checker
Fig. 1. Process of router reconfiguration.
B. Run-time Adaptive Encoding Strategies for Reliability and
Dynamic Power Efficiency
A higher reliability means fewer transition patterns that
induce crosstalk such as two adjacent transitions (↑↓ or ↓↑)
and two aggressors (↓ H ↓ or ↑ L ↑), where the symbol
“↑” denotes a signal switch from low to high; “↓” denotes
a signal switch from high to low; and “L” and “H” for a
line that is steady low and steady high, respectively. Other
patterns that induce crosstalk such as three adjacent transitions
and three aggressors have similar definitions. Further, dynamic
power efficiency is achieved through the reduction of self bit
transitions in a wire. To provide different degrees of reliability
and power consumption, we propose four encoding strategies
namely DUCE, TAE, SAFE, and DAFE.
1) Dual Cycle Encoding: DUal Cycle Encoding (DUCE) is
basically a temporal encoding that can completely eliminate all
crosstalk-inductive patterns on the wires by decomposing each
data flit transfer into two-phase transmissions. Figure 2 shows
the integration between the DUCE encoder and PRESSNoC.
A packet arriving at the DUCE encoder is separated into a
header flit and several data flits. The nWordSend signal uses
three bits to record the number of data flits in a packet. The
Downcounter counts from three to zero to dispatch the four
data flits sequentially. The kernel of the DUCE encoder is com-
posed of two Three-bit encoders and one Two-bit
encoder. The Two/Three-bit encoder consists of
two modules: a Two-phase mapping module for mapping
one 8-bit data flit into two 8-bit encoded data flits and a
Two/Three-bit buffer for recording the encoded flit
from the previous cycle. From the two-phase mapping of
DUCE in Figure 2, we can find that there are no adjacent
bit transitions or aggressors in these patterns. Hence, DUCE
can guarantee the highest reliability. To prevent the source PE
from continually sending packets to the DUCE encoder, the
Environment
sensors
Weight_Table index[0]
System
Characteristic
User
Preferences
Weight_Table index[1]
Weight_Table index[2:3]
Application
Query
Weight_Table index[2:3]
(AP_Domain)
Weight_Table
Index
[0:1]
Index
[2:3]
Expected
goal
Weight
array
Weight
array
Expected
goal
Equal ?
No
Yes or
Time out
Weight Modification Loop Process
Encoding schemes
reconfiguration
Weight_Table
index[2:3]
(AP_IPI)
ANN
process
Goal
comparator
Weight
Modifier
Configuration
Decision
Environment
Verifier
Index
ConverterApplication
information System Time
Constraints
Application information:
Data flow
Control flow
<ReliabilityAP@Encoding >
<Power_reductionAP@Encoding >
<Ap_IPI>
<Ap_Domain>
Weight Table:
Normal
Environment
Harsh
Environment
System
Characteristic
Application
Domain
IPI
Multimedia
00
Security
01
Network
11
Embedded
00
RealͲTime
01
Desktop
11
High
00
Median
01
Low
11
Reliability & 
Performance
Reliability
Performance & 
Resource
Power & 
Performance
Reliability & 
Performance
Performance &
Resource
Reliability
Reliability & 
Performance
Performance,
Power, Resource
Wmultimedia
Wsecurity
Wnetwork
Wembedded
WrealͲtime
Wdesktop
Whigh_IPI
Wmedium_IPI
Wlow_IPI
Index [0:1] Index [2:3] Expected
goal
[ wreliability
wpower
wperformance
wResource ]
0
1
0
1
X
Fig. 3. REAL framework.
TABLE I
COMPARISONS OF ENCODING SCHEMES
Encoder Decoder No. of Additional
Methods 2TR 2AR DPR HWR HWR flits transmitted
(%) (%) (%) (# of slices) (# of slices) per packet (#)
DUCE 100.00 100.00 12.12 27 80 4
TAE 47.77 53.89 3.59 107 18 1
SAFE 35.92 5.57 11.13 21 61 1
DAFE 72.92 18.04 18.34 24 160 2
1. 2TR: 2-transition reduction.
2. 2AR: 2-aggressor reduction.
3. DPR: Dynamic power reduction in a 64-byte input buffer router.
4. HWR: Hardware resources.
among the four encoding strategies; while SAFE achieves
11.13% reduction in dynamic power at smaller overheads
in performance and hardware resource utilization. We lever-
age these characteristics to explore the possible encoding
methods appropriate for different scenarios and requirements
instead of integrating all encoding methods in one architecture.
PRESSNoC can thus use lesser hardware resource, while
still maintaining high flexibility. In the following section, we
will introduce how the four proposed encoding strategies are
selected.
C. REAL: REasoning And Learning Framework
REAL uses a Benefit-Overhead (B/O) metric to choose
an appropriate encoding scheme. From Equation (1), we can
observe that the B/O metric is a ratio of the weighted sum of
benefits to that of overheads, where the benefits include nor-
malized rates of crosstalk interference reduction (Reldegree)
and dynamic power reduction (Powdegree) for each applica-
tion by using the four proposed encoding strategies, while the
overheads include normalized performance overhead (Flitadd)
and hardware resource utilization (Resuti) of the encoding
strategies. Normalization is required due to the different units
of the factors in the B/O metric. More precisely, some factors
with larger values will influence the impact degree of other
factors with smaller values so the normalization is needed. A
higher B/O value represents a better encoding strategy for a
given application, which means more benefits are gained from
the encoding strategies at the same overhead.
B/O =
(Wrel ×Reldegree +Wpow × Powdegree)
(Wper × Flitadd +Wres ×Resuti) (1)
Figure 3 shows the flow chart of the REAL framework.
Each application is profiled and an Interference Per Instruction
(IPI) count is evaluated, where IPI is the ratio of the total
number of interference patterns to the number of instructions
in an application. Environment sensors are used to detect
whether the current environment is harsh. If it is, then based
on the IPI count, the weights are modified accordingly. If the
environment is more friendly, then the user makes preference
as to whether to consider the Application Domain (AD) or
the System Characteristic (SC). Three application domains are
supported currently in REAL, namely multimedia, security,
and network search. Three system characteristics are also
supported, namely embedded systems, real-time systems, and
desktop systems. Different classifications of ADs or SCs will
influence the selection of encoding strategies. For example,
multimedia applications focus on high performance, while
embedded systems emphasize power efficiency. To support
all of the above goals, a weight table records the different
combinations of weights for reliability, dynamic power reduc-
tion, performance overhead, and hardware resource utilization.
The adaptation of weights is performed through an Artificial
Neural Network (ANN) to adapt to new applications and
environments. ANN is adaptive to change its structure based
on external or internal information during the learning phase.
A supervised learning strategy is supported currently in REAL.
In the supervised learning strategy, the main idea is to find a
group of weights including Wrel, Wpow , Wper , and Wres to
generate an appropriate selection of encoding methods to sat-
isfy our requirements. More precisely, the weight modification
process is used to reduce the influence of the factors that are
non-dominating. For example, we can avoid using a power-
efficient encoding method such as DAFE in a scenario which
requires high reliability.
IV. EXPERIMENTS
We used the Mibench set of 21 benchmark applications to
evaluate the proposed PRESSNoC architecture based on the
architecture. Given a set of applications, the sum of B/O (SBO)
is the aggregate of all B/O values. SBO is used as a metric
to compare the proposed architecture with the conventional
architecture. In our experiments, the conventional architecture
uses a fixed TAE scheme since the hardware components of
the conventional architecture cannot be changed or modified
at run-time. Figure 7 shows that the normalized SBO of
the proposed architecture is greater than that of the con-
ventional architecture by 71%, 32%, and 277% when we
consider the individual requirements of interference rate per
instruction, application domains, and system characteristics,
respectively. In the case of embedded systems, PRESSNoC
performs significantly better due to its ability to meet the
requirement of power efficiency, while the TAE scheme in the
conventional architecture does not focus on power reduction
and its architecture cannot be changed at run-time, so the
benefit gained from the conventional architecture is low.
Architectures Interferencerate
perinstruction
(IPI)
Application
Domain
1.Multimedia
2. Security
3.Networksearch
Systemcharacteristics
Embedded RealͲtime Desktop
SBO NSBO SBO NSBO SBO NSBO SBO NSBO SBO NSBO
Conventional
architecture
54.69 1 41.53 1 31.99 1 18.26 1 10.58 1
PRESSNoC
architecture
93.29 1.71 54.84 1.32 120.64 3.77 32.40 1.77 22.95 2.17
1.SBO= ,higherSBOisbetter.
2.NSBO:normalizedSBO,theNSBOofconventional architecture=1,
andtheNSBOofPRESSNoC architecture=SBO_P/SBO_C,
whereSBO_C=SBOofconventional architecture,andSBO_P=SBOofPRESSNoC architecture.
20,)/(
0
 ¦
 
nOB
n
i
i
Fig. 7. PRESSNoC vs. TAE-based conventional NoC.
To fully support all the four encoding schemes, a conven-
tional NoC needs to implement all the schemes at the same
time. Figure 8 compares the hardware resource requirements of
a conventional NoC with that of PRESSNoC on a Xilinx Virtex
4 XC4VFX60-FF1152 FPGA chip. From Figure 8, we can
observe that the Virtex4 FPGA chip can only accommodate a
conventional 4×4 NoC with 16 full-fledged encoding modules,
each of which is a pair of encoder and decoder. In contrast,
the chip with the same amount of resources can accommodate
a 5 × 5 PRESSNoC that can support the same encoding
strategies with the same degree of flexibility. More precisely,
PRESSNoC required 25.5% lesser number of Virtex4 FPGA
slices compared to the conventional NoC.
Slices
0
20
40
60
80
100
120
140
2x2+4EM 3x3+9EM 4x4+16EM 5x5+25EM
O
cc
up
ie
d
ha
rd
w
ar
e
re
so
ur
ce
s
(%
)
PRESSNoCwithreconfigurable encodingstrategies
0
20
40
60
80
100
120
140
2x2+4EM 3x3+9EM 4x4+16EM 5x5+25EM
O
cc
up
ie
d
ha
rd
w
ar
e
re
so
ur
ce
s
(%
)
ConventionalNoCwithfullͲfledgedencoding strategies
LUTs FlipFlops
Fig. 8. Comparison: Hardware resources.
The above experiment results have shown the superiority
of PRESSNoC in terms of both flexibility and better hard-
ware resource utilization. As a last remark, a cross analysis
of how PRESSNoC meets the three different requirements,
we found that 81% of the benchmark applications required
different encoding strategies to meet different requirements.
This demonstrates the need for a dynamically reconfigurable
NoC that supports hardware encoding strategy selection at run-
time for each individual application.
V. CONCLUSIONS AND FUTURE WORK
To meet the time-varying reliability and power require-
ments, we developed four data encoding strategies, namely
DUCE, TAE, SAFE, and DAFE, which differ in the provision
of reliability, power efficiency, hardware resource overhead,
and performance overhead. Further, to allow run-time selection
of an encoding scheme for each scenario, we propose a novel
dynamically reconfigurable NoC architecture, namely PRESS-
NoC, along with a reasoning and learning (REAL) framework.
Experiment results have demonstrated the extreme flexibility
in meeting IPI, application domain, and system requirements
and better hardware resource utilization of PRESSNoC. In
the future, we will attempt to develop an NoC with dynami-
cally reconfigurable topology that supports removal of unused
routers for power reduction. Related issues will include the
communication control between neighboring routers, dynamic
routing strategy, and deadlock avoidance.
REFERENCES
[1] B. Ahmad, A. T. Erdogan, and S. Khawam, Architecture of a dynamically
reconfigurable NoC for adaptive reconfigurable MPSoC, Proceedings of
the First NASA/ESA Conference on Adaptive Hardware and Systems,
IEEE Computer Society, June 2006, pp. 405–411.
[2] E. Carvalho, N. Calazans, and F. Moraes, Heuristics for dynamic task
mapping in NoC-based heterogeneous MPSoCs, Proceedings of the
18th IEEE International Workshop on Rapid System Prototyping, IEEE
Computer Society, May 2007, pp. 34–40.
[3] M. R. Guthaus, J. S. Ringenberg, D. Ernst, T. M. Austin, T. Mudge, and
R. B. Brown, Mibench: A free, commercially representative embedded
benchmark suite, IEEE International Workshop on Workload Character-
ization, Dec. 2001, pp. 3–14.
[4] T. Marescaux, J.-Y. Mignolet, A. Bartic, W. Moffat, D. Verkest, S. Ver-
nalde, and R. Lauwereins, Networks on Chip as hardware components
of an OS for reconfigurable systems, Proceedings of the International
Conference on Field Programmable Logic and Applications, Lecture
Notes in Computer Science, vol. 2778, Springer, September 2003,
pp. 595–605.
[5] L. Mo¨ller, I. Grehs, N. Calazans, and F. Moraes, Reconfigurable systems
enabled by a Network-on-Chip, Proceedings of the International Con-
ference on Field Programmable Logic and Applications, IEEE, August
2006, pp. 1–4.
[6] V. Nollet, T. Marescaux, D. Verkest, J.-Y. Mignolet, and S. Vernalde,
Operating-system controlled Network on Chip, Proceedings of the 41st
Design Automation Conference, ACM, June 2004, pp. 256–259.
[7] M. Palesi, S. Kumar, R. Holsmark, and V. Catania, Exploiting communi-
cation concurrency for efficient deadlock free routing in reconfigurable
NoC platforms, Proceedings of the 21th International Parallel and
Distributed Processing Symposium, IEEE, March 2007, pp. 1–8.
[8] T. Pionteck, C. Albrecht, and R. Koch, A dynamically reconfigurable
packet-switched Network-on-Chip, Proceedings of the Conference on
Design, Automation and Test in Europe, European Design and Automa-
tion Association, Leuven, Belgium, March 2006, pp. 136–137.
[9] M. P. Ve´stias and H. C. Neto, Router design for application specific
Networks-on-Chip on reconfigurable systems, Proceedings of the Inter-
national Conference on Field Programmable Logic and Applications,
IEEE, August 2007, pp. 389–394.
[10] Xilinx, Early access partial reconfiguration user guide, 2006.
2 
Verification for Embedded Systems、session 4.2 Routing Solutions for Upcoming 
NoC Challenges、 session 5.6 Scheduling and Allocation、 session 6.4 Basic 
Techniques for Improving the Formal Verification Flow、session 10.6 Cyber-Physical 
Systems、session 11.2 The Quest for NoC Performance、session 12.2 The Frontier of 
NoC Design。但是，最後那個 session 的時間與我要報告的 session 時間有衝突，
所以我沒有去聽那場，而是去報告論文。我們的論文發表於 Session 12.5 
Architecture and Networks for Adaptive Computing。此 session 共有四篇論文報
告。我們是最後一篇。報告完有相當多的發問，顯示此領域的學者和學生對我
們做的研究成果相當感興趣。甚至，會後有韓國的著名學者找我討論，希望未
來可以合作。參加此會議，獲益良多。 
總而言之，本次參加此頂尖會議，報告論文以及參與各種討論會，確實獲
益良多，也獲得一些合作的機會，實屬難得。 
三、考察參觀活動(無是項活動者略) 
本會議並無參觀活動。 
四、建議 
目前國科會補助博士生出國的經費越來越少，教育部也取消這部分的經
費，真的這樣的作法對國家的競爭力會有很大的影響。其他國家想盡辦法讓自
己的學生出國開會，拓展視野，增進國際觀，然而我卻這樣做限縮，真的不是
一種明智的做法。 
五、攜回資料名稱及內容 
本次攜回的有會議論文集的光碟。其他相關資料在網頁上均可下載。 
scheduling as shown in Fig. 1(b), the tile B with the idle IP
core X can be reconfigured to the IP core V . As a result,
DT3 chooses the right-top position of NoC to reconfigure IP
core V . Finally, the contention between DT2 and DT3 can be
eliminated.
One important design issue for an efficient NoC is applica-
tion mapping optimization, which is the mapping and schedul-
ing of both computation and communication over the NoC,
while optimizing certain metrics such as communication delay
or throughput [4]. In this work, we present an efficient run-
time congestion-aware scheduling algorithm (CWS) that focus
on communication delay minimization by avoiding communi-
cation congestion. The proposed CWS algorithm that maps
an incoming application task graph onto an underlying NoC
and schedules both the computation and the communication
demand of the tasks according to the link utilization and the
resource utilization.
The article is organized as follows. Section II introduces the
related work. The NoC-based reconfigurable system architec-
ture is described in Section III. Section IV is the problem
formulation and proposed algorithm. The experiments are
shown in Section V. Finally, Section VI summarizes our
contributions and outlines some directions for future work.
II. RELATED WORK
Communication-aware scheduling contains two main parts:
the first part is mapping tasks to computation nodes, and the
second is scheduling communication on the links [4]. For a
parallel communication platform such as NoC, communication
delay is an important factor to be considered. Several static
methods [5]–[9] have been proposed for an optimal placement
of tasks onto a NoC. Hu et al. [5] presented a branch and
bound algorithm to map IP cores onto a tile-based NoC
architecture such that the goal to minimize the total commu-
nication energy consumption under some given performance
constraints is guaranteed through bandwidth reservation.
Work extended from [5] considered packet routing flexibility
and communication time constraints during the scheduling
process [6]. Raina et al. [9] proposed a simulated annealing
algorithm to map the application onto a NoC architecture by
keeping track of the network traffic. Chou et al. [8] proposed
an integer linear programming method to minimize the inter-
tile network contention. However, the order of incoming
applications varies during system execution, thus the resource
requirements of tasks may exceed that available. Further,
since link utilization is not known at design time, congestion
may occur due to the HoL blocking problem. As a result,
it is necessary to schedule dynamically the link utilization
with resource management. Carvalho et al. [10] proposed
some run-time strategies for mapping applications to a NoC,
where the communication congestion in a NoC is taken into
consideration based on the current link utilization. However,
the traffic patterns may change dynamically throughout the
system execution due to tasks continually changing in a NoC.
It is necessary to predict the future traffic pattern of used
links to avoid communication congestion.
Fig. 2. NoC-based Reconfigurable System Architecture
III. NOC ARCHITECTURE
A NoC-based reconfigurable system realized on a DPR
platform is illustrated in Fig. 2, where a NoC is used to
interconnect different tiles. Each tile contains a Partially Re-
configurable Region (PRR) connected to a router via a Network
Interface (NI). By using the dynamic partial reconfiguration
technique, it becomes possible to load a required IP core on-
the-fly to a tile, with flexibility just like a general-purpose
processor. The connections between tiles is called links.
The NoC architecture can be described by following graph
structure.
Definition 1: NoC Architecture Graph
A NoC architecture graph (T , L) is a directed graph, where
T is a set of tiles and L ⊆ T × T . Each vertex tu ∈ T
represents a tile u in the architecture, and each edge lu,v ∈ L
represents a link from vertex tu to vertex tv.
The notation tiu represents the status, i.e., used or unused, of
tile tu in time slot i. A time slot is a pre-specified time period
for execution. Communication between tiles involves sending
data over a sequence of links from the tile with source IP
core to the tile with destination IP core. The transfer delay
through a link is denoted as td. A sequence of links through
the architecture graph is called a route and is defined formally
as follows.
Definition 2: Route
Given a NoC architecture graph (T , L), a route r : t1
l1,2→
t2
l2,3→ · · · ln−1,n→ tn is a path in (T , L) specified by a given
routing scheme, where t1 ̸= tn, t1 is the tile with source IP
core (called source tile) and tn is the tile with destination IP
core (called destination tile). The length of a route r is denoted
as |r|, which is equal to the number of links in the path.
The notation liu represents the status, i.e., used or unused,
of the link lu in time slot i. A flit is transferred over a link in a
single time slot. In this work, the X-Y routing scheme is used
to direct packets across a 2D mesh NoC. In such 2D mesh,
the routing scheme will first route packets along the X-axis;
once it reaches the column wherein lies the destination tile,
then the packets routes along the Y-axis. Obviously, the X-Y
routing is a deadlock-free minimal path routing scheme [11].
To manage the resources in a NoC, we assume that the tiles
have the capability to control at what time to start the execution
of a given task and at what time to start a traffic. Such
capability is usually already provided by the OS [12]. To
Algorithm 1: Congestion-aware scheduling algorithm
input : An application: Aexe and its arrival time: tat;
output: A scheduling entity: e
tileidle : A set of tiles that can be reconfigured or
contains the required IP core;
tiledst : A ordered set of tiles that can be reconfigured or
contain the required IP core based on the Manhattan
Distance (MD) from the source tile;
if a new application arrives then
for each traffic ∈ Aexe do
Calculate the start time according to tat
Sort the traffics of the application according to
the dependency and test
if could not find a tile ∈ tileidle then
Defer the start time until at least two tiles is
available with the MD as 1
for each tile ∈ tiledst do
Select a tile whose route utilization is
minimal according to the cost function
return e
application includes two traffics DT1 and DT2 in a 2×2 2D
mesh topology NoC. We assume that the application arrives
in the time slot 1, and thus adjust the start time of each traffic
by adding a 1 to it. As shown in Fig. 3(a), the scheduling
order of traffics is based on BFS traversal and is sorted by
the start times. Thus, it start to schedule the traffic DT1, the
tile A is selected for the source IP core first. However, for
the destination IP core, because there is not any available tile
whose MD equals to one in the tile set tileidle, the tile D
whose MD equals to two is thus selected to configure as the
destination IP core. In next step, all tiles are busy so there
is not enough tiles for traffic DT2 to be accommodated. As
shown in Fig. 3(b), the CWS algorithm defers the start time
of the traffic DT2, until they finish their jobs and can be
reconfigured. As shown in Fig. 3(c), after the start time of
the traffic DT2 is deferred by 1, when tiles B and C are
available, the routing paths from A to B and from A to C
can be selected. For the routing path from A to B, the routing
utilization is 15 , because the traffic DT2 needs 5 time slots
ideally to transmit the packets, and 1 time slot to transmit the
packets via the link between A and B. As shown in Fig. 3(d),
the routing path between A and C is selected because the route
utilization is zero, that is less than that of the routing path A
to B.
V. EXPERIMENTS
We implemented the congestion-aware scheduling algorithm
and then integrated it into Noxim [14], a flit-accurate simula-
tor developed in SystemC. To evaluate the effectiveness of
Fig. 3. Application scheduling with a given NoC
the proposed algorithm, a random benchmark generated by
TGFF [15] was used in the experiments. The NoC size varied
from 4×4 to 8×8. Each task was transmiting 1 to 500 packets,
with a size varying from 1 to 13 flits. To compare with the
proposed CWS, three existing algorithms proposed in [10]
were also implemented, including First Fit (FF), Nearest
Neighbor (NN), and Path Load (PL). The strategies of the
contemporary algorithm for selecting the source or destination
tiles are briefly described as follows, where NN and PL are
congestion-aware algorithms.
• First Fit: The FF algorithm starts at tile 0, which is
located at the top-left of the NoC and traverses the NoC
column by column, top to bottom. For either the source
or the destination tile, FF selects the first idle tile, without
taking other metrics into consideration. FF may generate
the worst results when compared to the other algorithms.
• Nearest Neighbor: To avoid congestion, the NN algorithm
only considers the shortest distance between a source tile
and a destination tile. Once the source tile is selected,
NN tries to search for an idle tile able to execute the task
near the source tile. The search space includes all n-hop
neighbors, where n varies between 1 and the NoC size,
and the search will stop when the first idle tile to execute
the link utilization not only in the current time but also predicts
it for the future time slots. Hence, as shown in Fig. 4(d),
the average throughput using the CWS algorithm was always
better than that using the FF, NN, and PL algorithms, where
the improvement by CWS was up to 32% of that by the other
three algorithms.
Fig. 5. Execution time overhead
As shown in Fig. 4(e), by using CWS the energy consump-
tion was reduced by up to 23% of that by using the other
congestion-aware algorithms on a NoC with a size varying
from 4×4 to 8×8. However, when the size of NoC increases,
the improvement of energy consumption using the the CWS
was thus lowered. This is because the number of tiles becomes
larger and can accommodate all the applications. Thus each
traffic can have its own pair of tiles, and traffic contentions
will occur more rarely.
The next experiment evaluates the efficiency of CWS by
varying the communication volume in a 4×4 NoC topology.
As shown in Fig. 4(f), when the communication volume grad-
ually increases, the average delay using the CWS algorithms
was always less than that using the other three algorithms,
where the reduced average communication delay was reached
up to 66%. This is because the CWS algorithms can predict the
future link utilization in a NoC and communication congestion
can be avoided.
The execution time overhead in performing the CWS al-
gorithm on a NoC with a size varying from 4×4 to 8×8
is shown in Fig. 5. We can observe that the execution time
increases, when the topology size decreases. This is because
a smaller size of topology includes fewer tiles. When the
available resources are getting fewer and fewer, the time
for finding a feasible scheduling entity becomes longer and
longer. However, this is an acceptable time overhead, since
the reduction of overall system execution time is more than
the additional execution time overhead.
VI. CONCLUSION
In a parallel communication infrastructure such as NoC, to
reduce the execution time, communication congestion should
be avoided. In this work, we have addressed the issue of
scheduling the traffics of applications by reducing the com-
munication delay. By predicting the traffic pattern based on
the link utilization on a reconfigurable NoC infrastructure,
the proposed run-time congestion-aware scheduling algorithm
can reduce the overall congestion, instead of only improving
the current packet blocking situation. Experimental results
showed that the proposed algorithm obtained up to 66% of
average communication delay reduction, while the execution
time was reduced by up to 32%. At the same time, the average
throughput was improved by up to 32%.
Future work will consist of supporting other routing
schemes, prediction mechanisms, and taking energy consump-
tion into consideration for mapping and scheduling application
tasks onto NoCs.
ACKNOWLEDGMENT
The authors would like to thank the National Science
Council, Taiwan, ROC, for financial support of this research
under project numbers NSC 98-2221-E-194-049-MY3.
REFERENCES
[1] B. Towles and W. J. Dally, Principles and Practices of Interconnection
Network, Morgan Kaufmann, 2004
[2] L. Moller, I. Grehs, E. Carvalho, R. Soares, N. Calazans, and F. Moraes,
A NoC-based Infrastructure to Enable Dynamic Self Reconfigurable Sys-
tems, Proceedings of the 3rd International Workshop on Reconfigurable
Communication-centric Systems-on-Chip, pp. 23-30, June 2007.
[3] W. J. Dally and C. L. Seitz, The torus routing chip, Journal of Parallel
and Distributed Computing, vol. 1, no. 4, pp. 187-196, June 1986.
[4] U. Y. Ogras, J. Hu, and R. Marculescu, Key Research Problems in
NoC Design: A Holistic Perspective, Proceedings of the International
Conference on Hardware-Software Codesign and System Synthesis, pp.
69-74, September 2005.
[5] J. Hu and R. Marculescu, Energy-aware mapping for tile-based NoC
architectures under performance constraints, Proceedings of the Asia and
South Pacific Design Automation Conference, pp. 233-239, January 2003.
[6] J. Hu and R. Marculescu, Exploiting the routing flexibility for energy/per-
formance aware mapping of regular NoC architectures, Proceedings of the
Design, Automation and Test in Europe Conference and Exhibition, pp.
688 - 693, March 2003.
[7] C. Marcon, A. Borin, L. Carro, and F. Wagner, Time and Energy Efficient
Mapping of Embedded Applications onto NoCs, Proceedings of the Asia
and South Pacific Design Automation Conference, pp. 33-38, January
2005.
[8] C. Chou and R. Marculescu, Contention-aware application mapping
for Network-on-Chip communication architectures, Proceedings of the
26th International Conference on Computer Design, pp.164-169, October
2009.
[9] A. Raina and V. Muthukumar, Traffic Aware Scheduling Algorithm for
Network-on-Chip, Proceedings of the Sixth International Conference on
Information Technology: New Generations, pp.877-882, April 2009.
[10] E. Carvalho and F. Moraes, Congestion-aware Task Mapping in Het-
erogeneous MPSoCs, Proceedings of the International Symposium on
System-on-Chip, pp. 34-40, November 2008.
[11] C. J. Glass and L. M. Ni, The Turn Model for Adaptive Routing,
Proceedings of the 19th Annual International Symposium on Computer
Architecture, pp. 278-287, May 1992.
[12] V. Nollet, T. Marescaux, D. Verkest, J. Mignolet, and S. Vernalde,
Operating-system controlled network on chip, Proceedings of the 41st
Annual Design Automation Conference, pp. 256-259, June 2004.
[13] M. D. Santambrogio, M. Redaelli, and M. Maggioni, Task graph
scheduling for reconfigurable architectures driven by reconfigurations
hiding and resources reuse, Proceedings of the 19th ACM Great Lakes
Symposium on VLSI, pp. 21-26, May 2009.
[14] F. Fazzino, M. Palesi, and D. Patti, , Noxim: Network-on-Chip Simulator,
http://noxim.sourceforge.net, 2010.
[15] R. P. Dick, D. L. Rhodes, and W. Wolf, TGFF: task graphs for free,
Proceedings of the 6th International Workshop on Hardware/Software
Codesign, pp. 97-101, March 1998.
98年度專題研究計畫研究成果彙整表 
計畫主持人：熊博安 計畫編號：98-2221-E-194-049-MY3 
計畫名稱：動態可重組式軟硬體系統之架構設計與程式模型建構 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 3 100%  
博士生 2 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 4 100% 
篇 
 
論文著作 
專書 1 2 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本研究計畫已提出數個演算法並以實際需求為考量，這些方法皆順利發表在國際期刊與國
際會議中。相關的研究成果已接受論文發表 International Journal 7 篇、International 
Conference 13 篇、博士論文 1篇、碩士論文 6篇、及書籍著作 2本。 
 
另外，我們也利用此計畫的研究成果參加一些國內外的競賽與參展，相關得獎情形如下：
 
[1]Third Award, Hardware-Software Integration Group, National Contest on Embedded 
System Design, sponsored by the Ministry of Education, Taiwan, 2009. (Title: 
Hierarchical Operating System Model for Dynamically Self-Reconfigurable Systems) 
[2]J.-S. Shen, C.-H. Lu, and W.-W. Lin ＇Reliable and Power-Aware Reconfigurable 
Network-on-Chip with Operating System Management,＇ 2009年全國嵌入式軟體設計競
賽，獲得軟硬體整合組佳作 
[3]C.-H. Huang, ＇＇Virtualizable and Preemptible HW/SW Runtime Environment for 
Reconfigurable Computing Systems,＇＇ ACM Student Research Competition at the 47th 
Design Automation Conference (DAC), June 2010. (初賽通過) 
[4]＇＇SAHA: A Self-Adaptive Hardware/Software System Architecture for Ubiquitous 
Computing Applications,＇＇ Demo/Exhibition Program at the 7th International 
Conference on Ubiquitous Intelligence and Computing (UIC), 2010. 
