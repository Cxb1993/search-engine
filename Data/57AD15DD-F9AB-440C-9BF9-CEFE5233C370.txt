1報 告 內 容
一、前言
根據摩爾定律，積體電路內的電晶體數目每十八個月就會增加一倍，效
能也跟著提升一倍，但價錢卻下降一半。半導體製程技術的進步與時脈的受
限，激勵硬體設計師朝向Multi-core平台邁進，進而促進Multi-core system的
發展。更多科學模擬與高品質多媒體演算法，需求更大量、複雜的運算；然
而整體運算的時間卻要求必須更短、執行更快，助長愈來愈多平行技術與程
式設計理念如雨後春筍般冒出，使得parallel programming的理念可以更加容
易實現，因此，資訊科技得以不斷的進步，其應用以及產品也不斷的推陳出
新，現代的人們對於資訊產品的功能以及品質要求日益增加。易於攜帶且外
型新穎手持式裝置以無法滿足使用者之需求，手持式裝置還需要有卓越的效
能，才能在這個市場佔穩並成功的脫穎而出。
然而手持式裝置需要有卓越的效能且易於攜帶意味著必須要在最小的
的空間將其組件做最有效的整合，此外其電力的供應也是主要的問題，不能
夠長久使用的產品勢將被市場淘汰。也因為大小以及電力的限制，效能表現
通常是有其瓶頸的。將每個要求盡可能達成是嵌入式系統努力達成的目標。
就以上多點考慮，嵌入式多核心系統的設計成為了一個可行的方案。由
多個較為低階的核心來分擔運算工作。從控制流程(Function partition)或是資
料層面(Data partition)上將之有效分配，使其達到負載平衡。因此，本計畫
利用了國內自行研發的PAC Duo平台，其主要的特色是擁有三個異質核心，
包括了一顆ARM9 MPU以及兩個處理多媒體資料的PAC DSP。為了貼近其
硬體架構設計優點，本計畫從多媒體編解碼的運算處理著手，適當地分配工
作給三顆核心。
採用國內自行研發的PAC Duo平台，除了主要的ARM核心，還搭載兩
顆專為多媒體運算而設計的PAC DSP。就硬體層面來說，其運算資源是相當
豐富的。然而，在實際使用的過程之中，多媒體的編解碼卻不能利用到這些
硬體資源。因為Android OS將多媒體編解碼的工作全部交由ARM 核心來運
算。以播放H.264影片的情況為例，播出的畫面不僅速度過慢，還會產生碎
裂的區塊。顯然地，這樣的工作對於一顆ARM核心來說過於沈重，而且又
閒置了另外兩顆DSP的運算資源。因此，本計畫希望能夠解決這一個資源運
用不合理的問題，充分利用嵌入式異質多核心平台的運算資源，使H.264編
解碼的工作能夠達到效能的提升。
除了異質多核心的平台選用之外，因為市面上手持式行動裝置及MID平
台百家爭鳴，各異其趣，且互不相容，造成開發者與使用者的不便，Google
3二、研究目的：
本計畫目標是針對於開發者而言，手持式行動裝置上的多媒體應用程式
的研發一直是一項繁雜困難的事情，姑且不論各家業者的手機平台迥異，即
便是同一家廠商的不同機款，也常需要大量的修改調整，方能正常運作，程
式碼無法有效再利用，這不啻是一種資源的浪費。有此現象，肇因於手持式
行動裝置上一直沒有一適當的多媒體框架來幫助程式設計者架構起一道分
層的圍牆，使得開發者除致力於應用程式的設計外，還須兼顧硬體層面上各
種難解的問題。
有鑑於此，許多公司團體合作訂定OpenMAX此專為嵌入式系統設計的
多媒體框架標準，架構出三種層次的領域：AL、IL與DL，以協助各種層面
的工作者可以專心致志地處理專屬於自己的問題，而不必再兼顧所有層面，
忙於解決非自己領域的工作，本計畫除了沿續此框架目的提供多媒體應用軟
體開發者一個足夠容易開發的環境，之外本計畫所研發之多媒體框架另加入
協助隱藏異質性多核心硬體平台的複雜性之外，再藉由實作一掌管平台資源
的元件（Resource Manager Component）來因應多核心平台的多變性。通常，
在異質性多核心平台上架構多媒體框架需要考量一些問題：（1）要能夠提
供給使用者一個容易開發的模式，使開發者可以專心在軟體高階設計上，而
非專注在硬體細節上面；此外，還必須考量到原始碼的重覆使用率。（2）
多媒體程式大多需要比較好的即時性，雖然不需要以hard real-time的標準嚴
苛要求，但是至少要能保證整個播放過程的流暢度。以上兩點關係到整個平
台資源的管控，包含運算資源的管理、執行優先權的考量以及溝通管道的暢
通等。（3）在多核心平台架構底下，這些核心（core）的組合會因開發者
喜好而有所不同（例如MPU加上多個硬體加速器或者是MPU搭配DSPs與硬
體加速器），為了切入市場時機的考量，多媒體框架的設計必須將硬體的變
化也列入考量使其更加有彈性。
本計畫本著能夠促進異質多核心多媒體框架的發展，以協助嵌入式系統
上的多媒體應用程式的開發者完成繁複的開發作業，更且希望能與Android
多媒體框架和異質多核心平台進行系統結合，以利開發出的軟體能充分利用
多核心硬體架構的優勢，增進國內多核心的技術優勢。本計畫預計以PAC
Duo為主要發展平台，輔以IBM Cell為測試平台，以此來發展異質多核心多
媒體框架技術。
5<圖3.1 H.264 Decoder Functional decomposition>
Data decomposition是將資料量做切割，平均分配給各個CPU來執行，也
就是SPMD(the same program and multiple data)的架構，如<圖3.2>。
<圖3.2 H.264 Decoder Data decomposition>
Functional decomposition的實作，由於執行緒之間要傳輸的資料量很
大，Processor之間的溝通與同步有著極大的bottleneck；且每個Processor上的
Loading都不同，很難有效的利用多核心的硬體資源，以上缺點會嚴重的影
響Performance，所以我們採取Data decomposition的演算法。
Data decomposition依照H.264的資料結構，如<圖3.3>，分為GOP-level
Parallelism、Frame-level Parallelism、Slice-level Parallelism及Macroblock-level
7會互相參考。
缺點：Frame中若分割成太多Slice，bit-rate會上升，PSNR值會下降，
降低資料壓縮的效率。
(3) Frame-level Parallelism
優點：在一連串的frame中，若frame解碼順序如<圖3.6>，因為B-frame
不會被參考到，且B-frame不會參考到6，所以圖中的6、1、2
三張frame就可以同一時間平行處理。
缺點：不支援base-line profile等沒有B-frame的影片格式。
<圖3.6 IPBBPBBP解碼順序>
(4) GOP-level Parallelism
優點：GOP-level(Group of Picture)的結構每個GOP的第一張frame為
IDR，GOP之間不會互相參考，遇到下一張IDR frame，等於
重新開始新的解碼序列，此機制的設計是用來防止錯誤的延
續；GOP-level Parallelism的優點是thread間可完全獨立作業，
data-dependency為最小(幾乎沒有)，可將同步、溝通的overhead
降至最低，且thread數量可以依照處理器數目彈性增減(前述之
演算法會因為資料相依性而限制住thread的數量)來達到充分
利用多核心資源來做Load Balance的目的。以上優點是本計畫
選擇實作GOP-level平行演算法的最大原因。
缺點：GOP-level為Coarse Grain parallelism的演算法，在記憶體的使
用量會因為要存多張ref-frame而升高；本計畫為了改善此
點，開發了相對應的Memory Management機制for Embedded
System，對記憶體使用量來做最有效的控管。
9硬體或者軟體的任何結合，其特點是對用戶端完全透明。如果沒有
這種標準化的界面，Codec開發者必須針對特有的不同介面（通常
是封閉的，不是開放的標準）來整合Mobile Device。IL主要目的是
給予Codecs一種系統抽象的自由度，可以彈性使用平台上的Media
components；整合各種Codec到不同的平台上，藉以解決在許多不
同媒體上的可攜性（portability）問題。
(4) 介於IL與DL之間的是Codec層，像是MP3、AMR、H.264和MPEG4
等等。
(5) 第五層是OpenMAX DL（Development Layer）。這是主要的核心開
發部分。OpenMAX DL定義了一組API，其中包含了綜合的Audio、
Video和Imaging functions。此API可以在不同的處理器上被實作且
最 佳 化 。 Codec 賣 主 可 以 使 用 編 碼 來 擴 大 原 本 的 codec
functionality。它包含FFTs等聲音訊號處理函式，並且提供filters；
影像部分的image color space conversion；以及MPEG-4、H.264、
MP3、AAC和JPEG等video processing primitives。OpenMAX使用IL
的construct與DL來添加非同步的interface在DL API上達成同步加
速。
(6) 最底層是硬體部分的Media Engines，像是CPU與DSP這些常見的硬
體元件，主要的計算與編解碼部分的核心處理器。
OpenCORE是PacketVideo（PV）為Android研發出來的多媒體框架
（Multimedia Framework），它為設備提供了播放一般影音檔案、播放
標準串流檔（streaming standard formats）、通信（3G communication）
及影像錄製(images and video recording)這些基本的多媒體功能。
有了OpenCORE，開發人員可以在設備上建構應用程式，來支援音
樂程式的應用、影像錄製及播放、視訊電話（video telephony）及網路
串流檔的即時播放（real-time streaming）…等。
11
● 硬體平台
(1) Andes AG101
晶心科技ADP-AG101嵌入式平台來當作我們的開發板，適合應用
在智慧型手機、可攜式多媒體播放器和行動上網裝置。 (如<圖4.3>所
示) 而其硬體規格如下：
i. AndesCore™N1213 generic SoC chip（400 MHz）
ii. CPU 時脈 400MHz 而 AHB 工作時脈50MHz
iii. Comprehensive on-chip peripherals
iv. On-board 128MB SDRAM
v. 5" touch panel
AndeShape™開發實驗版提供高效能及低成本的處理器開發環
境，並且適用於目前大部分的嵌入式軟體開發。藉由與AndeSight™開
發工具配合，我們將可以開發嵌入式軟體（H.264 Codec）Component
於Andes的實驗板上。
<圖4.3 Andes AG101 Platform>
(2) PAC Duo
PAC Duo為異質多核心平台（參照<圖4.4>），搭載一個ARM926
與兩個專門為多媒體處理所設計的32-bit PAC DSP，可以廣泛應用於多
媒體撥放器、智慧型手機及行動上網裝置等。細節部份如下：
i. ARM926 RISC embedded processor (Real Chip: 200~300Mhz)
ii. Two 32-bit DSP cores (Real Chip: 200~300Mhz)
iii. Dual DRAM channel architecture (SDRAM + DDR2 SDRAM)
iv. High performance AMBA 3.0 AXI on-chip bus for DSP subsystem
13
將H.264 Codec 整合到Android OpenCORE平台上。在Android
Media Framework中是採用PacketVideo（PV）所研發出來的多媒體框架
（Multimedia Framework），OpenCORE，它為設備提供了播放一般影
音檔案、播放標準串流檔（streaming standard formats）、通信（3G
communication）及影像錄製(images and video recording)這些基本的多媒
體功能。
故我們在設計H.264 code component會先參考其方法，以及將我們
的元件依照OpnMAX的標準來實現，如<圖4.5>所示，OpenMAX
Integration Layer(IL) API System Components Core API具有針對
component的dynamic loading與dynamic unloading功能，可擴大系統的彈
性；而Component API可以讓user直接與component溝通。Port在
communication中扮演傳輸通道的角色，
IL的communication type分為兩種：
i. Non-tunneled：component之間的溝通要經過IL client。如<圖4.5>
所示，source component與host component之間溝通
必頇經過IL client。
ii. Tunneling：直接由components互相傳遞，components之間互相建
立一個通訊管道。（例如<圖4.5>的Host component
與Accelerator component之間）。
而IL的component type可分成四類：
i. Source：one output，專職輸入部分。
ii. Sink：one input，即輸出。
iii. Host：主處理器稱為host component。
iv. Accelerator：附屬的加速處理器。
15
進行改寫，以增進我們在Andes AG-101平台上的Performance。
(5) Benchmarking, performance analysis
最終，我們將依照Android開發AP的流程來進行我們的Media player
的開發，並顯示出我們的Benchmarking，並可以由此知道我們設計的
H.264 codec元件在Andes platform上的表現。
經過測試後其數據，Format：MPEG 4，Frames：924 Frames，
Execution time：80Second ，Resolution：176 * 144，FPS:11.55 FPS。多
媒體H.264編解碼功能正常。
本計畫於第一個研究方法實做驗證成功後將其流程及架構優化之多媒
體函式庫移植至PAC異質多核心的平台上，並在異質多核心平台上再次進行
優化之工作，使得整個多媒體架構可以完善利用異質多核心的運算資源。
● 異質多核心多媒體函式庫優化
本計畫的構想是希望利用PAC DSP作為影片編解碼的處理，必須從
Android的OpenCORE中找出Component從何處將需要編解碼的資料傳到底
層去做編解碼處理，以及如何將編解碼處理完成的資料回傳。
在OpenCORE中，如<圖4.6>左邊所示，上層的Player AP會透過Engine
去驅動下層各種Node的連結，而OpenMAX component被實作在PVMF Node
之下，透過OpenMAX component來連結到真正的decoder，因此如果要將PAC
版本的decoder整合進OpenCORE中就必須修改OpenMAX component及真正
的decoder之間的Interface(紅色虛線圈起處)。
<圖4.6 OpenCORE Player / Author Dataflow>
Encoder的Dataflow也類似Decoder Dataflow，請看<圖4.6>的右邊。上層
的Author AP會透過Engine去驅動下層各種Node的連結，再透過OpenMAX
17
Dequeue一個OutputBuffer使用，並呼叫AvcDecodeVideo_OMX。
5. 如果沒有End_of_Frame flag，要先呼叫AvcBufferMgmtWithoutMarker作
reassemble buffer的動作，再呼叫AvcDecodeWithoutMarker ，此函式中會
Dequeue一個OutputBuffer使用，並呼叫AvcDecodeVideo_OMX 。
6. 呼叫AvcDecodeVideo_OMX進行解碼。
觀察整個component的流程後，我們修改BufferMgmtFunction，把資料從
此處傳至DSP，修改後的流程如<圖4.8>所示。
<圖4.8 修改後的Component解碼流程>
判斷Input Queue是否有可使用的buffer，若沒有則跳至判斷Output Queue
是否有可使用的buffer。
1. 當Input Queue中有可使用的Inputbuffer，Dequeue Inputbuffer來使用。
2. 將此需要解碼的Inputbuffer從ARM的memory “SDRAM”傳到DSP的
19
目前已完成OpenCORE H.264之decoder部分的整合及驗證，以下為測量
不同解析度影片的FPS(Frames Per Second)，藉此觀察實際播出影片速度是否
有增加。
<圖5.1 .Performance result_1>
<圖5.1>中顯示了單用CPU (也就是ARM) 以及 CPU+DSP 兩種方式的
FPS數比較，可以明顯看出有DSP的幫助，影片解碼的效果有明顯的改善，
尤其是對於一些需要大量計算的影片，CPU+DSP解碼的表現幾乎都可達25
以上的FPS，以人眼觀看都是非常流暢的。
<圖5.2 Performance result_2>
由以上<圖5.1>及<圖5.2>兩張圖片所列即可知道我們的確有善用了異
質多核心豐富的運算資源來達成OpenCORE多媒體函式庫H.264 Codec在異
質多核心平台上編解碼效能之增進。
本計畫目前也正在進行H.264 Encoder在異質多核心平台上的效能優
化，也如之前所說的利用與Decoder整合相同之手法將Encoder整進異質多核
21
參考文獻：
[1]. Thomas Wiegand, Gary J. Sullivan, Gisle Bjontegaard, and Ajay Luthra
“Overview of the H.264 / AVC Video Coding Standard”, IEEE 
TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO
TECHNOLOGY, JULY 2003
[2]. “ARM11 MPCore Technical Manual” 
[3]. Cor Meenderinck · Arnaldo Azevedo · Ben Juurlink · Mauricio Alvarez Mesa ·
Alex Ramirez, “Paralel Scalability of Video Decoders”. 
[4]. Arnaldo Azevedo1, Cor Meenderinck1, Ben Juurlink1, Andrei Terechko2, Jan
Hoogerbrugge2, Mauricio Alvarez3, Alex Ramirez3,4, Mateo Valero3,4, “Paralel 
H.264 Decoding on an Embedded Multi-core Processor” 
[5]. Cor Meenderinck1, Arnaldo Azevedo1, Mauricio Alvarez2, Ben Juurlink1, and
Alex Ramirez3, “Paralel Scalability of H.264”. 
[6]. “Pthreads Tutorial. htp:/www.lnl.gov/computing/tutorials/pthreads/” 
[7]. Jihong Kim for the degree of Master of Science in Electrical and
ComputerEngineering presented on June 3, 2008. “Power Efficient H.264 Video 
Decoding in Embedded Multiprocessor” 
[8]. Jonghan Park , Soonhoi Ha ,” Performance Analysis of Parallel Execution of
H.264 Encoder on the Cel Processor”, ESTIMedia 2007 
[9]. Troy Brant, Jonathan Clark, Brian Davidson, Nick Merryman Advisor: David
Bader, “Porting an MPEG-2 Decoder to the Cel Architecture”. 
[10]. ” DUI0351B_PB11MPCore_UserGuide” 
[11]. 畢厚杰主編, “新一代視訊壓縮編碼標準” 2004 
[12]. ITU-T Recommendation “H.264 Advanced video coding for generic audiovisual 
services”, 03/2005 
[13]. OpenMP Architecture Review Board. “The OpenMP specification for paralel 
programming,” cited November 2007, http://openmp.org/
[14]. Y. Chen, E. Li, X. Zhou and S. Ge, “Implementation of H.264 enoder and 
decoder on personal computers”, http://www.sciencedirect.com
23
計畫結果與自評：
根據摩爾定律與製程的進步，同樣的一顆晶片已經可以容納多顆CPU，日後不
管是一般PC或者嵌入式系統必定朝向Multi-core發展平台的趨勢邁進，甚至是
Many-core。
在嵌入式手持裝置中，又以多媒體運算處理方面的議題最被廣泛討論及研究，
隨著人們的需求，更多複雜的演算法問世，傳統單核心處理器或者ASIC已經不能滿
足如此耗時的運算。
綜合以上兩點，我們發展出一套建構在異質多核心平台上的H.264多媒體解碼
器，在整個開發過程中，我們目前將焦點放在如何以Coarse-grain的GOP-Level平行
化來達到充分利用多核心資源以獲得效率提升，以及整體系統的記憶體管理機制上
的最佳化，目前已有不錯的成果出爐，本計畫藉著此研究的實作在99年全國大學校
院嵌入式系統設計競賽獲得了兩個佳作，分別是「High Performance H.264 Codec
Design for Google Android on PAC Duo Platform」以及「The Porting and
Optimization of Google Android OpenCORE Multimedia Framework with H.264
Encoder/Decoder on ANDES Platform」。
未來我們會將異質多核心平台上Power Consumption的議題納入本專案來研究
探討，發展出一個可以滿足High Performance 及 Low Power需求的手持式多媒體
系統。
98年度專題研究計畫研究成果彙整表 
計畫主持人：石維寬 計畫編號：98-2220-E-007-004- 
計畫名稱：前瞻異質多核心系統開發工具研發--子計畫三：異質多核心平台之無線多媒體應用程式開
發(3/3) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
