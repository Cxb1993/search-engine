 I 
目錄 
目錄 ………………………………………………………………. I 
報告內容 …………………………………………………………. 1 
一、 前言 ………………………………………………… 1 
二、 研究目的 …………………………………………… 1 
三、 文獻探討 …………………………………………… 2 
四、 研究方法 …………………………………………… 3 
五、 結果與討論 ………………………………………… 6 
  
參考文獻 ………………………………………………………… 7 
計畫成果自評 …………………………………………………… 10 
出席國際學術會議心得報告 …………………………………… 11 
附錄 ……………………………………………………………… 12 
 A VLSI Progressive Coding for Wavelet-based Image Compression  
 A Cardinal Image Compression for Capsule Endoscope 
 High-Quality Image Compression for Gastrointestinal Endoscope 
 On VLSI Design of Rank-Order Filtering using DCRAM Architecture  
 A 2.5-V 14-bit, 180-mW Cascaded Sigma-Delta ADC for ADSL2+ 
Application 
 An Accurate Lithium-Ion Battery Gas Gauge Using Two-Phase STC 
Modeling 
 High-Quality Image Compression for Gastrointestinal Endoscope 
 A Modified H.264 Intra-frame Video Encoder for Capsule Endoscope 
 A Wireless Narrow-Band Imaging Chip for Capsule Endoscope 
  
 2 
合宜（battery-friendly）的技術應可改善功率短缺的問題[11][13][15-16]。因此，
本計畫的目標有三： 
1.設計低功耗之診斷目標偵測電路：膠囊開始進入食道時便僅開啟部分光源
與目標偵測電路，直到偵測疑似診斷目標時才開啟全部光源與影像擷取
與壓縮電路。如此將可大幅節省電池用量與醫師判讀時間。該診斷目標
偵測電路將採取仿生物特性之視網膜晶片實現，因為視網膜晶片具高動
態範圍與低功率影像強化功能[19-26]。 
2. 開發適用於 GI影像之影像擷取電路與壓縮演算法：基於 GI影像之特性，
改良 CMOS影像感測電路掃描與 RGB佈建，同時對特殊的 RGB佈建發展新
式靜/動態影像壓縮技術。 
3. 發展功率意識管理機制：設計可倍乘/除(Scalable)的影像壓縮演算法，
以利於功率意識電路彈性切換操作模式。當電池電量充裕時使影像品質為
最佳, 而當電池電量不足時微量犧牲影像品質切換成較低功率消耗模
式。建立適應性的控制機制，使得功率的控制可以精準的掌握。因此, 暫
態功率可以隨環境條件改變而精確調整。所謂環境條件是指溫度變異與影
像內容等。 
 
三、 文獻探討 
1. 目前已發展出的無線膠囊內視鏡技術中，以 Given Image這家公司所發展的
PillCam 膠囊內視鏡最為普遍使用，此膠囊內視鏡所拍攝的腸胃道影像畫面
為 256x256的彩色影像，以每秒兩張畫面的方式來拍攝腸胃道影像畫面[3]。
雖然 Pillcam可以協助醫生診斷疾病並且有效舒緩患者的不適，但是 PillCam
本身存在兩個主要的缺點有待改善，其一為 PillCam 不能控制它本身行進和
移動的方向，這樣的缺點將會造成影像在補捉上有死角，而使得出現病徵的
部位沒辦法順利被拍攝到。其二是由於受限於電池功率，所拍攝影像的解析
度仍嫌不足，使得醫生往往在放大影像觀察時會受影像失真困擾判讀。國外
 4 
果全程完整擷取影像，將是耗電又缺乏效率。因此，我們將利用矽視網膜電路
在微弱光源情形下擷取運動邊緣或紅色區塊，偵測可能病變目標如出血、大片
紅色血印等。一旦偵測出診斷目標時才啟動所有光源與彩色影像擷取壓縮電
路。如此一來將可節省大量電能，使得畫質能有效提升以及讓有機電池或 RF
感應等電源變為可行。 
 
(2) 影像壓縮電路 
本計畫目標在於設計供膠囊內視鏡用之影像處理晶片。近年來, 膠囊內視鏡已
經成為醫療科技重要的發展技術。其中, 影像壓縮扮演相當關鍵的角色。理由
有三: 影像壓縮的品質將影響影像輸出的判讀，影像壓縮的結果必須滿足無線
資料傳輸的頻寬限制，影像壓縮晶片需維持低功率消耗以保證足夠長的電池壽
命。因此, 在膠囊內視鏡的應用中，影像壓縮晶片的主要考量為維持影像品質，
降低資料的傳輸量及延長電池的用電壽命。然而這三個考量卻往往無法兼顧。
利用時尚的影像壓縮技術固然可以因高壓縮比而大幅降低資料的傳輸量，但是
大量的運算處理卻造成電池電能的短缺。而利用犧牲影像品質以減少運算量的
快速演算法卻可能造成醫療影像的失真。因此，我們希望提出一個能兼顧影像
品質及電池壽命的影像壓縮處理晶片。 
 
目前影像壓縮技術大多針對多媒體應用開發。重點在於處理各種影像資料同時
考慮聲音與資料的同步。基於無線通訊與網際網路的需求，時尚的影像壓縮技
術特別強調高壓縮比與低傳輸率。然而在既存的技術文件中很難發現專門的影
像壓縮技術是針對極低耗能、低影像變化率的生醫應用發展的。首先，我們可
以發現這 512*512大小內視鏡測試畫面皆呈現紅色居多，而在畫面中幾乎不見
藍色。因此我們認為在壓縮膠囊內視鏡腸道影像時，這個特性將有助於減少運
算量進而節省耗電。為了印證我們的假設，我們試著分析每張測試畫面，對每
張測試畫面做其畫面內容的 8-by-8的二維離散餘弦轉換的平均 DC值分析，其
 6 
0
100
200
300
400
500
600
700
800
1 2 3 4 5 6 7 8 9 10 11 12
Test Picture ID
A
ve
ra
ge
 A
C
 V
ar
ia
nc
e
G1
G2
R
B
 
圖六：  R、G1、G2、B 子畫面像素於二維 8x8離散餘弦轉換之 AC值變異數分析 
2-D
8-by-8 
DCT
Quantization
R-table
Compression
Image for R
Compression
Image for G1
Compression
Image for G2
Non-compression
Image for B
Raw
Image
Entropy
Coding
R
G1
G2
B
2:1
Subsample
2:1
Subsample
4:1
Subsample
Entropy
Coding
Entropy
Coding
Zig-Zag
Scan
2-D
4-by-4 
DCT
Quantization
G-table
Zig-Zag
Scan
2-D
4-by-4 
DCT
Quantization
G-table
Zig-Zag
Scan
 
圖七：膠囊內視鏡影像壓縮進階演算法架構 
 
 
五、 結果與討論 
過去三年之研究成果已發表三篇期刊論文與七篇國際會議論文，表列如下： 
1. Meng-Chun Lin, Lan-Rong Dung, and Ping-Kuo Weng, “A Cardinal Image 
Compression for Capsule Endoscope,” BioCAS 2006, November 29-December 1, 2006. 
2. Tsung-Hsi Chiang and Lan-Rong Dung, “High-Quality Image Compression for 
Gastrointestinal Endoscope,” ISOBME 2006, December 15-16, 2006. 
3. Meng-Chun Lin and Lan-Rong Dung, ”An Improved Ultra-Low-Power 
Subsample-based Image Compressor for Capsule Endoscope,” MIST 2006, October 
27-30, 2006.  
4. Tsung-Hsi Chiang and Lan-Rong Dung, “A VLSI Progressive Coding for Wavelet-based 
Image Compression,” IEEE Transactions on Consumer Electronics, May 2007. 
 8 
[8] J.Ziv and A. Lempel, “A universal algorithm for sequential data compression,” 
IEEE Trans. On  Inform. Theory, vol. 23, pp. 337-343, May 1977. 
[9] Shin Arn Hwang and Cheng Wen Wu, “Unified VLSI Systolic array design 
for LZ data compression,” IEEE Trans. On VLSI, vol. 9, pp. 489-498, August 
2001. 
[10] M. Fu, G.A. Jullien, V.S. Dimitrov*, M. Ahmadi, “A low-power DCT IP code 
based on 2D algebraic integer encoding,” IEEE International Symposium on 
Circuit and Systems. vol. 2, pp.765-768, May 2004. 
[11] O. S. Unsal and I. Koren, “System-Level Power-Aware Design Techniques in 
Real-Time Systems,” Proceedings of the IEEE , Vol. 91, Iss. 7, July 2003, pp. 
1055-1069. 
[12] A. P. Chandrakasan, M. Potkonjak, R. Mehra, J. Rabaey, and R. W. Brodersen, 
“Optimizing Power Using Transformations,” IEEE transactions on CAD, Vol. 
14, No. 1, January 1995, pp. 12-31. 
[13] David Linden, Handbook of Batteries, Second Edition, McGraw-Hill, Inc., 
1995. 
[14] Rafael C. Gonzalez and Richard E. Woods, Digital Image Processing, 
Addison Wesley, Sep. 1993. 
[15] Praveen Raghavan and Chaitali Chakrabarti, “Battery-friendly design of signal 
processing algorithms,” in IEEE Workshop on Signal Processing Systems, 
Aug. 2003, pp. 304–309. 
[16] Hsien-Wen Cheng and Lan-Rong Dung, “A Content-based Methodology for 
Power-Aware Motion Estimation Architecture,” IEEE Transactions on 
Circuits and Systems II, October, 2005, pp.631-635. 
[17] Meng-Chun Lin, Lan-Rong Dung, and Ping-Kuo Weng, “Study on 
Ultra-Low-Power Image Compressor for Capsule Endoscope,” Accepted by 
BioMedical Engineering OnLine. 
[18] Lan-Rong Dung, Meng-Chun Lin, Tai-You Chen, Yue-Zhang Song, and 
Ping-Kuo Weng,  “Implementation of Ultra-Low-Power Image Compressor 
for Capsule Endoscope,” the 16th VLSI Design/CAD Symposium, August, 
2005. 
[19] J. E. Dowling, The Retina: An Approachable Part of the Brian, Cambridge, 
MA: Harvard University Press, 1987. 
[20] B. Roska and F. S. Werblin, “Vertical Interations across Ten parallel Stacked      
Representations in Mammalian Retina, ” Nature, Vol. 410, pp. 583-587. 
[21] B. Roska, E. Nemeth, L. Orzo, F. S. Werblin, “Three Levels of Lateral 
Inhibition:    A Space-time Study of the Retina of the Tiger Salamander,” J. 
of Neuroscience: 1942-1951, 2000. 
 10 
計畫成果自評 
本計畫已與台北醫學大學合作分析內視鏡影像，提出腸道與胃之環境偵測方
法，並修正現有視網膜晶片電路，調整出嵌入於內視鏡晶片之光源控制電路。在
影像處理部份，已開發影像強化處理晶片，移除 CMOS感測電路之米粒雜訊。另
外，利用影像偏紅特性發展出兼顧色差最佳化之進階壓縮演算法。在電池管理部
分，已建立鋰電池之電量估測技術，將搭配鋰鈕扣電池用於將膠囊中。本計畫之
研究成果已發表或已接受發表為下列三篇期刊論文與七篇會議論文： 
 Meng-Chun Lin, Lan-Rong Dung, and Ping-Kuo Weng, “A Cardinal Image 
Compression for Capsule Endoscope,” BioCAS 2006, November 29-December 1, 2006. 
 Tsung-Hsi Chiang and Lan-Rong Dung, “High-Quality Image Compression for 
Gastrointestinal Endoscope,” ISOBME 2006, December 15-16, 2006. 
 Meng-Chun Lin and Lan-Rong Dung, ”An Improved Ultra-Low-Power 
Subsample-based Image Compressor for Capsule Endoscope,” MIST 2006, October 
27-30, 2006.  
 Tsung-Hsi Chiang and Lan-Rong Dung, “A VLSI Progressive Coding for Wavelet-based 
Image Compression,” IEEE Transactions on Consumer Electronics, May 2007. 
 Meng-Chun Lin and Lan-Rong Dung, 2008, “On VLSI Design of Rank-Order 
Filtering using DCRAM Architecture,” Integration, the VLSI Journal, Vol.41, 
pp.193-209, February, 2008. 
 Teng-Hung Chang and Lan-Rong Dung, “A 2.5-V 14-bit, 180-mW Cascaded 
Sigma-Delta ADC for ADSL2+ Application, ” IEEE Journal of Solid State Circuits, 
Vol.42, No.11, pp.2357-2368, November, 2007. 
 Hsueh-Chih Yang and Lan-Rong Dung, 2007, June, “An Accurate Lithium-Ion Battery 
Gas Gauge Using Two-Phase STC Modeling,” ISIE 2007. 
 Lan-Rong Dung and Tsung-Hsi Chiang, “High-Quality Image Compression for 
Gastrointestinal Endoscope,” BioCAS 2007, November 27-30, 2007. 
 Lan-Rong Dung, Yin-Yi Wu, Hsin-Cheng Lai, and Ping-Kuo Weng, “A Modified 
H.264 Intra-frame Video Encoder for Capsule Endoscope,” BioCAS 2008, 
November 20-22, 2008 
 Lan-Rong Dung, Yin-Yi Wu, and Ping-Kuo Weng, “A Wireless Narrow-Band 
Imaging Chip for Capsule Endoscope,” BioCAS 2009, November 26-28, 2009. 
 
另外，部分研究成果正投稿于 IEEE 相關期刊。經由本計畫之執行已培養三名博
士生及五位碩士生從事於影像處理相關之研究領域。 
 
11 
 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 95-2221-E-009-337-MY3 
計畫名稱 膠囊內視鏡用之腸胃道影像處理整合晶片設計 
出國人員姓名 
服務機關及職稱 
董蘭榮 
國立交通大學電機與控制工程學系副教授 
會議時間地點 96.11.20-96.11.22 美國巴爾地摩 
會議名稱 2008 IEEE Biomedical Circuits and Systems Conference (BioCAS 2008) 
發表論文題目 A Modified H.264 Intra-frame Video Encoder for Capsule Endoscope 
 
一、參加會議經過 
1. 十一月十九日抵達美國巴爾地摩。 
2. 十一月二十日上午抵達會場註冊報到 
3. 十一月二十日至十一月二十二日選擇性全天出席研究相關之會議 Sections及參與討論。 
4. 十一月二十日下午發表論文” A Modified H.264 Intra-frame Video Encoder for Capsule 
Endoscope”。 
5. 十一月二十二日下午至機場搭機前往台北。 
 
二、與會心得 
此次參加會議主要是了解目前學術界有關生醫相關晶片設計之現況與未來趨勢。本人第一篇
發表的論文創新地提出改良式之低位元率影像壓縮技術已達到提昇低位元率腸胃道影像壓縮
之畫質提高臨床診斷之可靠度，引起不錯的迴響。個人從中啟發出未來的研究改進與創新主
意。此次參與之會議為為全世界生醫電路與系統設計的最重要年度會議，會中有國際級的演
講者、課程、展示、以及論文發表。本人強烈建議國內學者積極參與是項會議，與國際研究
接軌互動。 
 
 
2II. BACKGROUND
A. Progressive Image Transmission
A key for the progressive image transmission is to apply
multi-resolution decomposition on the target image. The multi-
resolution decomposition provides multi-resolution represen-
tation of an image. At different resolution, the details of an
image characterize different physical structures of the scene.
At a coarse resolution, these details correspond to the larger
structures which provide the image content. It is therefore
natural to analyze the image details at a coarse resolution
first and then gradually increase the resolution. Usually, multi-
resolution decomposition defines a set of orthonormal basis,
such as the Haar basis [11] in wavelet-decomposition. By
applying decomposition-transformation, it is possible to rep-
resent an image based on the coefficients in an orthonormal
basis expansion.
Let pi,j be a two-dimensional image, where i and j are the
indices of pixel coordinates. The multi-resolution decomposi-
tion of image pi,j is written as
c = Ω(p). (1)
Where Ω(.) is a transformation of multi-resolution decom-
position. Two-dimensional coefficient array c has the same
dimensions as image p, and each element ci,j is the transfor-
mation coefficient of p at coordinate (i, j). In a progressive
image transmission, receiver updates received reconstruction
coefficient ĉ according to the coded message until approximate
or exact amount coefficients have been received. Then, the
decoder can obtain a reconstructed image by applying inverse
transformation
pr = Ω−1(cr). (2)
Where pr is the reconstructed image, and cr are progres-
sively received coefficients. Image distortion of reconstructed
image pr from original image p can be measured using Mean
Squared Error (MSE), that is
DMSE (p− pr) = DMSE (c− cr)
= 1MN
∑
i
∑
j
(ci,j − cr i,j)2. (3)
Where MN is the total number of all image pixels. In a
progressive image transmission process, the transmitter rear-
ranges the details within the image in the decreasing order of
the importance. From Equation (3), it is clear that if an exact
value of the transform coefficient cr i,j is sent to the decoder,
then the MSE decreases by |ci,j |2/MN [5]. This means that
the coefficients with larger magnitude should be transmitted
first because they have a larger content information.
B. Embedded Zerotree Wavelet Algorithm
Embedded Zerotree Wavelet (EZW) algorithm was sug-
gested by Shapiro in 1993 [4]. Shapiro uses a simple and
general model to describe the distribution of the wavelet coef-
ficients obtained from a Discrete Wavelet Transformed (DWT)
image. The DWT decomposes the input image into a set of
subbands in multiple resolutions. Generally, most of the energy
in an image is concentrated in the low-frequency region.
When an image is subjected to n-level decomposition using
DWT, the n-th level would correspond to the lowest frequency
subband and would correspond to the coarsest resolution.
Thus, when one moves from higher levels to lower levels
of subband decomposition, there would be a decrease in the
energy content of the subband. In each decomposition level,
the coarse subband is a low-pass approximation of the original
image, and the other subbands are finer scale refinement. Every
coefficient in each decomposition level, expect the highest
frequency, can be related to a set of coefficients of similar
orientation at the next finer scale level. The coefficient at the
coarse scale is called the parent, and all coefficients at the
same spatial location of similar orientation at the next finer
scale level are called the children.
To rearrange the wavelet coefficients in the decreasing order
of the importance, Shapiro defines the insignificant concept
and a data structure zerotree. A wavelet coefficient x is said to
be insignificant with respect to a given threshold T if |x| < T .
The zerotree is a tree structure based on the hypothesis that
if a wavelet coefficient at a coarse scale is insignificant with
respect to a given threshold T , then all wavelet coefficients of
the same orientation in the same spatial location at finer scales
are also significant with respect to T . To coding wavelet coef-
ficients, EZW algorithm uses zigzag-scanning coding subband
by subband. The scanning order of wavelet coefficients begins
from the lowest frequency subband and continuously searches
with the breadth-first-search (BFS) to the higher frequency
subbands. Parents are scanned before any of their children,
but after all neighboring parents have been scanned. Each
coefficient is compared against the current threshold T . A
coefficient is significant if its amplitude is greater than T .
A significant coefficient is then encoded using one of the
symbols NS (negative significant) or PS (positive significant).
The ZTR (zerotree root) symbol is used to signify a insignif-
icant coefficient. The IZ (isolated zero) symbol signifies a
coefficient below T but with at least one child not below T .
For significant coefficients, EZW further encodes coefficient
values using a successive approximation quantization (SAQ)
scheme. SAQ uses to provide a multiresolution representation
of the coefficients and to facilitate the embedded coding. Then,
coding is done bit-plane by bit-plane.
C. Set Partitioning in Hierarchical Tree
Set Partitioning In Hierarchical Tree (SPIHT) is an image
coding algorithm suggested by Said and Pearlman in 1996
[5]. Based on EZW [4] concept framework, SPIHT algorithm
provides a better performance and less complexity implemen-
tation than EZW. The EZW coding is essential to compress
the ordering information as conveyed by the results of the
significance tests. In SPIHT algorithm, the ordering data is
not explicitly transmitted. Instead, SPIHT coding algorithm
uses a partitioning of trees in a manner that it tends to keep
insignificant coefficients together in large subsets. Herein,
the subset partitioning is so effective, and the significance
4LSP list except those included in the last sorting pass.
To implement coding algorithm on a chip, SPIHT needs
more hardware control and more memory space to store
extra information in refinement pass. However, there is
no precedence relation between the sorting pass and the
refinement pass. A better approach proposed in TSIHT
is to put refinement pass before the sorting pass. Thus,
TSIHT does not need to store last address or information
of the refinement pass and is more efficient than SPIHT
coding.
3) Efficient depth-first-search (DFS)
The spatial orientation tree is defined on the hierarchical
pyramid. In the sorting pass, SPIHT coding algorithm
uses breadth-first-search (BFS) to traverse all the nodes
in the tree structure. In order to access each node
in the tree, an input buffer is needed to hold all the
ancestor-descendant relations of the coefficients. Thus,
the location addresses of the four immediate descendants
of a node can be calculated systematically. As showing
in Figure 3, it is easily to calculate the addresses from
root node to the descendants within the first three
steps. However, while proceeding to step 4, there is
no more ancestor-descendant relations to calculate node
addresses. In proposed TSIHT algorithm, we use depth-
first-search (DFS) [12] method instead. As showing in
Figure 4, the DFS method searches the root node and
each one of the branching to the immediate descendants
until it reaches the leaves. By using DFS method, the ad-
dress generation of the ancestor-descendant coefficients
is more efficient than SPIHT coding.
root
1
2 3
4
5 6 7
Next root
8
Fig. 3. BFS traversal in SPIHT coding
root
1
2
3
4
5 7
Next root
8
6
Fig. 4. DFS traversal in TSIHT coding
Proposed TSIHT coding is based on SPIHT algorithm ex-
tended by using above principles. Besides, in our experimental
result, it shows that TSIHT also keeps low bit rate quality as
SPIHT does, even better. In the following section, we will
discuss the implementation detail of TSIHT coding.
IV. SOFTWARE IMPLEMENTATION
Let TSP, TIP and TST be the two-dimensional binary arrays,
whose entries are either ’0’ or ’1’. The overall TSIHT coding
algorithm includes six steps as follows.
1) Initialization: output n = blog2 (max {|ci,j |})c; set
each value of all entries in TSP, TIP and TST arrays
to ’0’.
2) Refinement output:
a) for each entry (i, j) in the TSP do:
i) if TSP=1 then output the n-th most significant
bit of |ci,j |;
3) TIP testing:
a) for each entry (i, j) in the TIP do:
i) if TIP=1 and Sn(ci,j) = 1 then
A) output ’1’ and output sign of ci,j ;
B) set values TIP := 0 and TSP := 1;
ii) otherwise, if TIP=1 and Sn(ci,j) = 0 then
output ’0’;
4) TST update:
a) for each entry (k, l) ∈ O(i, j) do:
i) if TST=0 and Sn(k, l) = 1 then set value
TST:=1;
5) Spatial orientation tree encoding:
a) for each entry (i, j) using DFS method do:
i) if TSP=0 and TIP=0 then
A) if Sn(i, j) = 1 then output ’1’, sign of ci,j
and the value of TST; set value TSP := 1;
B) otherwise, if Sn(i, j) = 0 then output ’0’
and the value of TST; set value TIP := 1;
6) Quantization-step update: decrease n by 1 and go to
Step 2.
In Step 1, TSIHT coding first calculates initial threshold
and sets the values of three tag flags TSP, TIP and TST to ’0’
initially. In Step 2, the entry marked with TSP=1, which is
evaluated in the last Step 5, is significant. The entry, TIP=1,
tested as insignificant in last Step 5 may be significant in
Step 3 due to the different threshold. Thus, the algorithm
performs TIP testing to update TIP value in Step 3. In Step
4, it updates TST value of each coefficient except the leave
nodes and prepares to perform tree encoding in next Step.
If a node is TST=0, its descendants are all insignificant; in
the other words, the tree leading by that node, TST=0, is a
zerotree. The algorithm searches those nodes, TST=0, using
depth-first-search (DFS) method and outputs an ’0’ in Step 5
to keep low bit rate as SPIHT coding does. At last, it decreases
quantization step n by 1 and go to Step 2 iteratively.
Proposed TSIHT coding algorithm is the same as what the
SPIHT coding does but using different data structures. For
instance, in the refinement output and TIP testing steps, TSIHT
uses tag flags TSP and TIP to indicate whether a node is
significant or not. Then, TSIHT can output and encode the
image stream by investigating the TSP and TIP tags. On the
6L
L
L
L
L
Level
M
u
x
_
b
L
F1
F2
F3
F4
F5
C1
C2
M
u
x
_
a
AG_controller
reset
clk
FF
It_flag
Addr
TST sig
Fig. 8. Address Generator architecture
most peripheral starting at the star mark toward the
inner nodes of every scanning line. Let c col and c row
be the current column and row addresses; n col and
n row be the next column and row addresses. Assuming
tmp size is the coordinate boundary in each level. The
flowchart of the F1 address generation is illustrated
in Figure 10. Note that, as showing in Figure 10, next
address is obtained from current address depends on
different boundary conditions.
B
o
tto
m
 -
u
p
Fig. 9. Bottom-up searching direction
2) F2: Ancestor address generation
In TST update step, for each entry (k, l) ∈ O(i, j), if it
finds that a descendant coefficient, (k, l), with TST=0
is significant, the TST value of the parent, (i, j), is
assigned to TST=1. To locate the ancestor address from
its descendant coefficient, bitwise-shifting operation on
descendant coordinate is used. For instance, Figure 11
illustrates the ancestor-descendant relations labeled with
row and column address. The ancestor address can
be obtained by right-shifting one bit on each of its
descendant coordinate.
3) F3: Descendant address generation
In spatial orientation tree encoding step, TSIHT uses
If
c_col = tmp_size
If
c_row = tmp_size
yes
n_col = c_col + 1;
n_row = c_row;
no
n_col = '00000000';
n_row = tmp_size × 0.5;
yes
If
c_row < 0.5 × tmp_size
no
n_col = '00000000';
n_row = c_row + 1;
yes
no
n_col = tmp_size × 0.5;
n_row = c_row + 1;
Fig. 10. The flowchart of F1 address generator
parent
child 1
child 2
child 3
child 4
parent
child 1
child 2
child 3
child 4
(row, col)
(62, 24)
(124, 48)
(124, 49)
(125, 48)
(125, 49)
row
00111110
01111100
01111100
01111101
01111101
col
00011000
00110000
00110001
00110000
00110001
Fig. 11. Ancestor-descendant relations of node coordinates
DFS method to traverse all the nodes of the spatial
orientation tree. It first searches the root node and each
one of its branching to its immediate descendants until to
the leaves. As similar to F2, the descendant address may
be obtained by left-shifting one bit with adding certain
necessary values.
4) F4: General linear counter
Within the first three steps of the TSIHT coding algo-
rithm, AG behaves a general two-dimensional counter.
When AG works in mode F4, the address of scanning
line is generated row-by-row and column-by-column
sequentially.
5) F5: Neighbor address generation
The addresses of the four neighbor nodes originated
from the same ancestor have the same property that
their row or column addresses are identical except the
last bit. And, their address pairs (row, col) of the last
bit are variety with following sequence (0, 0) → (0, 1)
→ (1, 0) → (1, 1). When AG works in mode F5, the
neighbor addresses of each node can be generated by
using such principle. Since, each iteration of TSIHT
coding algorithm ends at F5, after PIE finishes working
at mode F5, an iteration flag signal It flag is produced
to notify other control units.
When PIE performs TSIHT coding algorithm, AG gener-
ates the addresses of the coefficients with coordinate pair
(row, col) using one of above function units to access the
coefficient or tag memory. Only one function unit is allowed
to read input data and execute its task each time. At the front
of each function unit, a latch is added to reduce the power
consumption as showing in Figure 8. Besides, before entering
8TAU
read
TAU
read
clk3
clk2
clk1
TAU
read
TAU
read
TAU
read
write TSP write TSP write TSP
valid address
Fig. 16. Three different working clocks
VI. VLSI IMPLEMENTATION
A. Synthesis Result
A prototype of an 256 × 256 gray-scale image PIE core
for progressive image transmission has been designed using
standard cells in a semi-custom methodology. The PIE core
has been synthesized with VHDL based top-down design flow
and implemented by using a 0.35-µm one-poly-four-metal
CMOS technology. The chip has an area of 550µm× 450µm
= 247500µm2, where the AG accounts for 66% of the total
surface. Figure 17 illustrates the IC layout of the PIE core. The
gate count statistics of each circuit component is illustrated in
Table. I. The hardware characteristics of PIE core are shown
in Table. II.
AG
controller
TAGTG
BG
CD
Fig. 17. PIE core layout
TABLE I
GATE COUNT STATISTICS
AG TG TAU FSM BG CD Total
#. 1687 264 264 255 56 34 2560
% 66% 10% 10% 11% 2% 1%
B. Performance
Tab. III lists the latency of the critical path and the gate count
of the proposed PIE core and other encoders. The gate count
of EZT encoder in [13] is reported about 5k gates, it is almost
twice as proposed PIE core. The gate count of EZW encoder
in [14] is about 3889 gates, and the latency of the critical path
is 16.53 ns. Although, the handling image size of proposed
TABLE II
HARDWARE CHARACTERISTICS OF PIE CORE
Property Result
Technology 0.38µm 1P4M CMOS
Area 247500 µm2
Total gate count 2560
Latency 6.32ns
Max. working freq. 158MHz
Image size 256× 256
pin count 90
PIE is less than others. While considering larger image size
implementation, PIE core only increases the memory size but
few the gate count of the circuit. Moreover, the latency of the
PIE core is less than EZT in [13] and EZW encoder in [14].
Thus, PIE core is a faster and simpler architecture than others.
TABLE III
PERFORMANCE COMPARISON
EZT [13] EZW [14] PIE
Image size 352× 288 720× 480 256× 256
Latency N/A 16.53ns 6.32ns
Gate count 5000 3889 2560
While considering memory usage, as illustrating in Tab. IV,
both SPHIT [4] and intraband partitioning [15] need more than
one hundred Kbytes memory. The proposed TSIHT coding
only occupies about 18Kbytes, which is less than other coding
algorithms.
TABLE IV
MEMORY USAGE
SPIHT [4] Karam’s [15] TSIHT
Image size 256× 256 256× 256 256× 256
Memory 250Kbytes 312.5Kbytes 18Kbytes
VII. CONCLUSION
Although, SPIHT [4] coding is approved that it is the most
efficient algorithm to implement EZW coding, the problem of
large amount memory occupied may restrict its applications.
In this work, proposed TSIHT coding using tag flags can
effectively reduce amount of memory usage. For a typical
256 × 256 gray-scale image, TSIHT only needs 18Kbytes,
while SPIHT needs 250Kbytes memory, which is almost 13.9
times the proposed TSIHT coding. The VLSI implementation,
PIE core, also provides a lower gate count (about 2560),
smaller area (247500 µm2) and higher speed (158MHz at
Max.) circuit, which is convenient to be integrated into other
image compression systems.
VIII. REFERENCE
REFERENCES
[1] ISO/IEC, JPEG 2000 Committee Draft version 1.0, cd15444-1 edition,
Dec. 1999.
[2] C. Christopoulos, A. Skodras, and T. Ebrahimi, “The jpeg2000 still
image coding system: An overview,” IEEE Transactions on Consumer
Electronics, vol. 46, pp. 1103–1127, Nov. 2000.
A Cardinal Image Compressor for Capsule
Endoscope
Meng-Chun Lin
National Chiao Tung University
Electrical and Control Engineering
Hsinchu, Taiwan
Email: asurada.ece90g@nctu.edu.tw
Lan-Rong Dung
National Chiao Tung University
Electrical and Control Engineering
Hsinchu, Taiwan
Email: lennon@faculty.nctu.edu.tw
Ping-Kuo Weng
Chung-Shan Institute of Science and Technology
Solid-State Devices Section
Lung-Tan, Tao-Yuan, Taiwan
Email: lennon@nctu.edu.tw
Abstract— This paper intends to reduce the power dissipation
of the GICam image compressor for capsule endoscope or
swallowable imaging capsules while the gastrointestinal images
are cardinal. In order to further extend the battery life of capsule
endoscope, we firstly attempt to analyze the energy distribution
and variation of DC/AC coefficients in 2D-DCT domain for twelve
tested GI images. According to the analysis results, we can
efficiently take advantages of the subsample technique to reduce
the memory requirements of green and blue components and
hence propose an improved ultra-low-power subsample-based
GICam image compressor, called SGICam, to reduce the power
dissipation of compression process. Simulation results have been
shown that the SGICam image compressor can significantly save
38.5% power dissipation than GICam image one and the average
PSNR is 32.18 dB , while the compression ratio can be as low
as 4:1.
I. INTRODUCTION
Gastrointestinal (GI) endoscopy has been popularly applied
for the diagnosis of diseases of the alimentary canal includ-
ing Crohn’s Disease, Celiac disease and other malabsorption
disorders, benign and malignant tumors of the small intestine,
vascular disorders and medication related small bowel injury.
There exist two classes of GI endoscopy; wired active en-
doscopy and wireless passive capsule endoscopy. The wired
active endoscopy can enable efficient diagnosis based on
real images and biopsy samples; however, it causes patients
discomfort and pain to push flexible, relatively bulky cables
into the digestive tube. To relief the suffering of patients,
wireless passive capsule endoscopes are being developed
worldwide [1], [2], [3], [4]. The capsule moves passively
through the internal GI tract with the aid of peristalsis and
transmits images of the intestine wirelessly. The state-of-the-
art is the commercial wireless capsule endoscope product,
the PillCam capsule, developed by Given Imaging Ltd. The
PillCam capsule transmits the GI images at the resolution of
256-by-256 8-bit pixels and the frame rate of 2 frames/sec (or
fps). The PillCam has been successfully utilized to diagnose
diseases of the small intestine and alleviate the discomfort and
pain of patients.
However, based on clinical experience; the PillCam still
has some drawbacks. First, the PillCam cannot control its
heading and moving direction itself. This drawback may cause
image oversights and miss a disease. Second, the resolution
of demosaicked image is still low, and some interesting spots
may be unintentionally omitted. Especially, the images will
be severely distorted when physicians zoom images in for
detailed diagnosis. The first drawback is the nature of passive
endoscopy. Some papers have presented approaches for the
autonomous moving function [5], [6]. Very few papers address
the solutions of the second drawback. Increasing resolution
may alleviate the second problem; however, it would result
in significant power consumption in RF transmitter. Hence, to
overcome the second drawback, our previous work [7] has
been successfully attached an ultra-low-power image com-
pressor, called GICam, to the CMOS sensor to deliver a
compressed 512-by-512 image while the RF transmission rate
is at 2 frames per second. The experimental results shows
that the GICam image compressor consumes 14.92 mW, and
reduces the image size by 75% at least. Although the GICam
image processor can successfully solve the second drawback,
we expect to further reduce the power dissipation of GICam
image processor itself in order to extend the battery life of
capsule endoscope. Therefore, in this paper, we proposed a
subsample-based GICam image compressor, called SGICam,
to reduce the power dissipation of compression process. The
SGICam mainly uses the subsample technique to pick out the
necessary image pixels into the compression process for green
and blue signals respectively.
The rest of the paper is organized as follows. In section
II, we briefly review the previous work about the GICam
algorithm. Section III illustrates the analysis results of dis-
crete cosine transform for gastrointestinal image. Section IV
describes the SGICam algorithm in detail. Section V shows the
experimental performance of the proposed algorithm. Finally,
section VI concludes our contribution and merits of this work.
II. THE REVIEW OF GICAM IMAGE COMPRESSION
ALGORITHM
Fig.1 illustrates the system diagram of the proposed capsule
endoscope. We attached an ultra-low-power image compressor
to the CMOS sensor to deliver a compressed 512-by-512
image while the RF transmission rate is at 2 frames per second.
To reduce the buffer size between the CMOS sensor and the
image compressor, the scanline controller is dedicated to scan
out R, G1, G2, and B signals in a certain order. Traditional
0100
200
300
400
500
600
700
800
Test Picture ID
A
ve
ra
ge
 A
C
 V
ar
ia
nc
e
G1
G2
R
B
1 2 3 4 5 6 7 8 9 10 11 12
˃
˅˃˃
ˇ˃˃
ˉ˃˃
ˋ˃˃
˄˃˃˃
˄˅˃˃
˄ˇ˃˃
˧˸̆̇ʳˣ˼˶̇̈̅˸ʳ˜˗
˔
̉˸
̅˴
˺˸
ʳ˗
˖ ˚˄
˚˅
˥
˕
0
200
400
600
800
1000
1200
1400
Test Picture ID
A
ve
ra
ge
 D
C G1
G2
R
B
1 2 3 4 5 6 7 8 9 10 11 12
(a)
(b)
Fig. 3. (a) The avegage values of all DC coefficients for 12 tested GI images.
(b) The average variance values of all AC coefficients for 12 tested GI images.
IV. THE SUBSAMPLE-BASED GICAM IMAGE
COMPRESSION ALGORITHM
Fig.4 illustrates the SGICam compression algorithm. For
a 512×512 raw image, the raw image firstly divides into
four parts, namely, R, G1, G2, B components and each of
R, G1, G2, and B components has 256×256 pixels. For the
R component, the incoming image size to the 2D-DCT is
256×256×8 bits, in which, the incoming image datum are
completely compressed because of the importance itself in
GI images. Except the R component, the SGICam algorithm
can use the appropriate subsample ratio to pick out the
necessary image pixels into the compression process for G1,
G2 and B components and Eq.1 and Eq.2 are formulas for
the subsample technique. Where, SM16:2m is the subsample
mask for the subsample ratio 16-to-2m as shown in Eq.1
and the subsample mask SM16:2m is generated from basic
mask as shown in Eq.2. The type of subample direction
is block-based, when certain of positions in the subsample
mask are one, their pixels in the same position will be
compressed, otherwise they are not processed. For the G1
and G2 components, the low subsample ratio needs to be
assigned because of considering their secondary importance
in GI images. Thus, the 2:1 subsample ratio is the candidate
one and the subsample pattern is shown in Fig.5 (a). Finally,
for the B component, the 4:1 subsample ratio is assigned and
the subsample pattern is shown in Fig.5 (b). In the SGICam
image compression algorithm, the 8-by-8 2D-DCT is still used
to transfer the R component. However, the 4-by-4 2D-DCT
is used for G1 and G2 components because the incoming
datum are reduced by subsample technique. Moreover, the
G quantization table is also further modified and shown in
the Fig.6. Finally, the B component is directly transmitted;
not be compressed, after extremely decreasing the incoming
datum. Due to non-compression for the B component, the 8-
by-8 and 4-by-4 Zig-Zag scanning techniques are added into
the SGICam to further increase the compression rate for R, G1
and G2 components before entering the entropy encoding. In
the SGICam, the Lempel-Ziv (LZ) coding [9] is also employed
for the entropy coding because of non-look-up tables and low
complex computation.
Raw Image
R
G1
G2
B
2:1
Subsample
2:1
Subsample
4:1
Subsample
2-D
4-by-4
DCT
Entropy
Coding
Compression
Image For G1
2-D
4-by-4
DCT
Entropy
Coding
Compression
Image For G2
Non-compression
Image For B
2-D
8-by-8
DCT
Entropy
Coding
Compression
Image For R
4-by-4
Quantization
G-table
4-by-4
Quantization
G-table
Quantization
R-table
4-by-4
Zig-Zag
Scan
4-by-4
Zig-Zag
Scan
8-by-8
Zig-Zag
Scan
Fig. 4. The SGICam image compression algorithm.
SM16:2m (i, j) = BM16:2m (i mod 4, j mod 4)
m = 1, 2, 3, 4, 5, 6, 7, 8. (1)
BM16:2m =

u (m− 1) u (m− 5) u (m− 2) u (m− 6)
u (m− 7) u (m− 3) u (m− 8) u (m− 4)
u (m− 2) u (m− 5) u (m− 1) u (m− 6)
u (m− 7) u (m− 3) u (m− 8) u (m− 4)


where u(n) is a step function,u (n) =
{
1, for n ≥ 0
0, for n < 0.
(2)
v
Fig. 5. (1) 2:1 subsample pattern. (2) 4:1 subsample pattern.
Fig. 6. The modified G quantization table.
V. EXPERIMENTAL RESULTS
In section IV, we have been particularly introduced how to
efficiently decrease the incoming datum with the subsmaple
technique in the SGICam compression algorithm and then the
SGICam compressor will be experimentally analyzed the per-
formance about the compression rate, the quality degradation
and the ability of power saving. First of all, the target com-
pression performance of the SGICam image compression is to
reduce image size by 75% at least. To meet the specification,
we have to exploit the cost-optimal LZ coding parameters.
腸胃道內視鏡影像之高品質影像壓縮技術 
HIGH-QUALITY IMAGE COMPRESSION for 
GASTROINTESTINAL ENDOSCOPE 
江宗錫(Tsung-Hsi Chiang1) 董蘭榮(Lan-Rong Dung1) 
1 National Chiao Tung University 
 
 
一、中文摘要 
 
在本篇論文，我們提出一個兼具效率與高影
像品質的影像壓縮方法，主要應用於腸胃道內視
鏡影像。我們所提出的 DEWC 編碼方式，節省了
傳統影像壓縮技術常會用到的影像前處理的計
算，例如像素預測或顏色空間轉換等；並直接以
小波轉換的 SPECK 編碼技術，個別應用在 R、G
和 B 等由 CMOS 影像所擷取的原始影像上。一般
在以紅色環境為背景的腸胃道中，比起綠色和藍
色，紅色會分佈在較低頻的頻率上；另一方面，
比起藍色和紅色，綠色分布在較高的頻率上。
DEWC 技術可以節省紅色位元編碼數，並且增加
綠色或藍色的位元編碼數。因此，在固定壓縮比
例下，這種非勻稱的位元數分配能夠得到較好的
影像品質。另一方面，為了能夠量化非勻稱的位
元編碼技術所造成的顏色差異，我們提出以CIE94
色差公式，作為色彩失真的衡量標準。根據色彩
失真和位元數編碼差異分析，我們推導出最佳/次
佳影像位元分布的線性方程式，根據方程式的
解，用以決定各個顏色組成的編碼位元數。從最
後的實驗數據我們發現，比起一般的 JPEG2000
編碼技術，我們所提出的 DEWC 編碼要比
JPEG2000 的效率快，並且有效好的影像品質。 
 
關鍵詞：內視鏡影像; DWT; JPEG2000 
 
Abstract 
 
In this paper, we propose an efficient framework 
of high-quality image compression method for upper 
Gastrointestinal tract endoscopy images. The 
proposed DEWC coding method saves traditional 
image preprocessing computations, such as 
demosaicking and color-space transformation, and 
directly utilizes raw image data acquired from 
CMOS sensor. R, G and B band image are then 
separately encoded by wavelet-based SPECK coding. 
In a cardinal GI tract environment, the spatial 
frequency distribution of red component is lower 
than green or blue, and green component is 
relatively high while compared to blue and red 
components. DEWC coding saves more bits on red 
band while allocating more bits on green and blue 
bands. Therefore, under a fixed compression ratio, 
such non-uniform bit-rate allocation may earn a 
better image quality. To measure quality-loss in 
non-uniform bit-rate allocation, a quality quantified 
measurement called color-distortion based on CIE94 
color-difference formula is also proposed. By using 
analytical result of color-distortion in bit-rate and 
bit-rate-difference analysis, an optimal/suboptimal 
bit-rate allocation scheme can be found by solving 
linear equations derived from the relationship of 
color-distortion and bit-rate-difference. When 
comparing to general JPEG2000 compression 
standard, the experimental result shows that 
proposed DEWC coding has a better image quality 
in color-distortion measurement and more efficient 
performance in execution time. 
 
Keywords: Endoscope image; DWT; JPEG2000 
 
二、Purposes 
A high-quality endoscope image 
compression method called DEWC (Delta-E 
Wavelet Coding) method is proposed in this 
paper, where Delta-E means the CIE94 
color-difference formula ΔE. Figure 1 illustrates 
the flow chart for the proposed DEWC coding 
method. Each 512×512 8-bit GI tract raw image 
is directly acquired by the CMOS image sensor 
with the most commonly utilized Bayer color 
filter [1]. In each acquired raw image, each pixel 
contains only one of the R, G and B primary 
color in it. Traditionally, two missing color 
components are first estimated from adjacent 
pixels by using demosaicking process [2,3], and 
the RGB-to-YCbCr color space transformation 
is applied before image encoding. However, 
demosaicking process may induce twice 
redundant data as many as original raw image 
[4,5], and color-space transformation also 
requires the calculation of inner products. It is 
not worth performing both image preprocessing 
steps unless we can really gain image quality 
from those redundant computations. 
Unlike traditional image compression 
technique, proposed DEWC coding method 
starts from raw image in the form of Bayer 
pattern and processes each R, G1, G2 and B 
allocation problem is modeled by linear equations. 
By solving linear equations, a bit-rate allocation 
scheme for high-quality compression can be found. 
 
Fig. 4 (a) Color-distortion and bit-rate-difference 
for various bit-rates (sample image 04); (b) The 
relationship between color-distortion DΔE and bit-rate 
difference. 
 
Based on the analytical result, linear equations 
are derived in this section in finding a better bit-rate 
allocation scheme. For convenience, three variables 
are firstly defined which indicate distinct 
bit-rate-differences: δBG = rB – rG, δBR = rB – rR, and 
δGR = rG – rR. These variables also have current or 
previous prefix depending on the notation δ or δ’ 
respectively. The same representation is also used on 
distortion functions and bit-rate variables. 
According to analytical result in Figure 6(b) 
and considering red and blue curves, minimal values 
of color-distortion are almost located at the same 
place. Therefore, current δBG and δGR can be found 
from previous function β’r'R and β’r'B Equation 1. 
'' ( ) 0RrBR
d x
x
dx
βδ ⎧ ⎫⎪ ⎪= =⎨ ⎬⎪ ⎪⎩ ⎭
, '' ( ) 0BrGR
d x
x
dx
βδ ⎧ ⎫⎪ ⎪= =⎨ ⎬⎪ ⎪⎩ ⎭
    Eq.1 
Then, coding bit-rates for rR, rG and rB are 
found by solving linear equation as given following: 
0 1 1
1 1 0 , 4
1 2 1 32 /
R BG
G GR
B
r
r
r
δ
δ ρ
ρ
−⎡ ⎤ ⎡ ⎤ ⎡ ⎤⎢ ⎥ ⎢ ⎥ ⎢ ⎥− = ≤⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦
.  Eq.3 
 
Note that, β is the compression ratio of an 
original image related to its restored image defined 
by Equation 4. 
CFA raw image size in bits
total encoding/decoding bits
ρ =     Eq.4 
The acquired CFA raw image size is 
512×512×8 bits, i.e. 2 Mega bits. A boundary 
condition of an 4:1 compression ratio to a restored 
image is given by Equation 5. In an CFA raw image, 
each 2×2-pixel block contains four bytes (or 32 bits) 
including R, G1, G2 and B components in that. 
Therefore, for a restored image with 4:1 
compression ratio, it only needs 8 bits in each 
2×2-pixel block. 
2 32 / 8R G Br r r ρ+ + = =  
, for (4:1) compression ratio        Eq.5 
If compression ratio ρ is larger than 4, the 
solution to Equation 3 may lead a negative bit-rate 
which means a non-valid solution. According to 
analytical result, we can see that function βrR does 
not have large variety while red band ranging from 
rR=0.1 to 3.0bpp. Herein, a modification can be 
made by directly assigning rR to an average value 
Rr . As a result, another equation is given in 
Equation 6 while compression ratio ρ > 4. 
0 1 1
1 0 0 , 4
1 2 1 32 /
R BG
G R
B
r
r r
r
δ
ρ
ρ
−⎡ ⎤ ⎡ ⎤ ⎡ ⎤⎢ ⎥ ⎢ ⎥ ⎢ ⎥= >⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦
   Eq.6 
Therefore, before encoding an CFA raw image, 
current δBG and δGR are found from previous function 
β’ rR’ and β’ rB’ by using Equation 2(a)-(b). A desired 
bit-rate allocation scheme (rR,rG,rB) is solved by 
using Equation 3 or 6. Then, image encoding is 
applied to image bands with desired bit-rate. At last, 
function βrR, βrG and βrB are updated for next image 
compression. 
 
三、Experimental result 
 
Table 1 compares the color-distortion and 
luminance PSNR obtained for GI tract images at 
various compression ratio with proposed DEWC 
coding method and general JPEG2000 [9] 
compression. For each ρ=4, 8 or 16 in DEWC 
coding, bit-rate combinations (rR,rG,rB) for GI 
images are computed by calculating Equation 3 and 
6. On the other hand, JPEG2000 compression is also 
applied on GI images with the same compression 
ratio as DEWC coding. We can see that DEWC 
coding has a better quality than JPEG200 
compression in luminance PSNR while ρ=4, but 
DEWC coding loses a little quality in luminance 
PSNR while ρ=16. As mentioned in previous section, 
INTEGRATION, the VLSI journal 41 (2008) 193–209
On VLSI design of rank-order ﬁltering using DCRAM architecture
Meng-Chun Lin, Lan-Rong Dung
Department of Electrical and Control Engineering, National Chiao Tung University, Hsinchu City 300, Taiwan, ROC
Received 6 November 2006; received in revised form 15 March 2007; accepted 9 May 2007
Abstract
This paper addresses on VLSI design of rank-order ﬁltering (ROF) with a maskable memory for real-time speech and image processing
applications. Based on a generic bit-sliced ROF algorithm, the proposed design uses a special-deﬁned memory, called the dual-cell
random-access memory (DCRAM), to realize major operations of ROF: threshold decomposition and polarization. Using the memory-
oriented architecture, the proposed ROF processor can beneﬁt from high ﬂexibility, low cost and high speed. The DCRAM can perform
the bit-sliced read, partial write, and pipelined processing. The bit-sliced read and partial write are driven by maskable registers. With
recursive execution of the bit-slicing read and partial write, the DCRAM can effectively realize ROF in terms of cost and speed. The
proposed design has been implemented using TSMC 0:18mm 1P6M technology. As shown in the result of physical implementation, the
core size is 356:1 427:7mm2 and the VLSI implementation of ROF can operate at 256MHz for 1.8V supply.
r 2007 Elsevier B.V. All rights reserved.
Keywords: CMOS memory integrated circuits; Coprocessors; Image processing; Median ﬁlters; Nonlinear ﬁlters
1. Introduction
Rank-order ﬁltering (ROF), or order-statistical ﬁltering,
has been widely applied for various speech and image
processing applications [1–7]. Given a sequence of input
samples fxik; xikþ1; . . . ; xi; . . . ; xiþlg, the basic operation
of ROF is to choose the rth largest sample as the output yi,
where r is the rank-order of the ﬁlter. This type of ROF is
normally classiﬁed as the non-recursive ROF. Another type
of ROF is called the recursive ROF. The difference between
the recursive ROF and the non-recursive ROF is that the
input sequence of the recursive ROF is fyik; yikþ1;
. . . ; yi1; xi; . . . ; xiþlg. Unlike linear ﬁltering, ROF can
remove sharp discontinuities of small duration without
blurring the original signal; therefore, ROF becomes a key
component for signal smoothing and impulsive noise
elimination. To provide this key component for various
signal processing applications, we intend to design a
conﬁgurable rank-order ﬁlter that features low cost and
high speed.
Many approaches for hardware implementation of ROF
have been presented in the past decades [8,10–24]. Many of
them are based on sorting algorithm [11,22,23,25–28]. They
considered the operation of ROF as two steps: sorting and
choosing. Papers [10,19] have proposed systolic architec-
tures for ROF based on sorting algorithms, such as bubble
sort and bitonic sort. These architectures are fully pipelined
for high throughput rate at the expense of latency, but
require a large number of compare-swap units and
registers. To reduce the hardware complexity, papers
[8,12,14,15,29–32] present linear-array structures to main-
tain samples in sorted order. For a sliding window of size
N, the linear-array architectures consist of N processing
elements and require three steps for each iteration: ﬁnding
the proper location for new coming sample, discarding the
eldest one, and moving samples between the newest and
eldest one position. The three-step procedure is called
delete-and-insert (DI). Although the hardware complexity
is reduced to OðNÞ, they require a large latency for DI
steps. Paper [31] further presents a micro-programmable
processor for the implementations of the median-type
ARTICLE IN PRESS
www.elsevier.com/locate/vlsi
0167-9260/$ - see front matter r 2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.vlsi.2007.05.002
Corresponding author.
E-mail addresses: asurada.ece90g@nctu.edu.tw (M.-C. Lin),
lennon@cn.nctu.edu.tw (L.-R. Dung).
Consequently, the rth order value can be obtained by
recursively iterating the steps bit-by-bit. The following
pseudo code illustrates the generic bit-sliced ROF algo-
rithm:
Given the input samples, the window size N ¼ l þ k þ 1,
the bitwidth B and the rank r, do:
Step 1: Set b ¼ B  1.
Step 2 (Bit counting): Calculate Zb from fubik; ubikþ1;
. . . ; ubi ; . . . ; u
b
iþlg.
Step 3 (Threshold decomposition): If ZbXr; vbi ¼ 1;
otherwise vbi ¼ 0.
Step 4 (Polarization): If ubjav
b
i ; u
m
j ¼ ubj for 0pmpb  1
and i  kpjpi þ l.
Step 5: b ¼ b  1.
Step 6: If bX0 go to Step 2.
Step 7: Output yi.
Fig. 1 illustrates a bit-sliced ROF example for N ¼ 7,
B ¼ 4, and r ¼ 1. Given that the input samples are
7ð01112Þ, 5ð01012Þ, 11ð10112Þ, 14ð11102Þ, 2ð00102Þ,
8ð10002Þ, and 3ð00112Þ, the generic algorithm will produce
14ð11102Þ as the output result. At the beginning, the ‘‘Bit
counting’’ step will calculate the number of 1’s at MSBs,
which is 3. Since the number of 1’s is greater than r, the
‘‘Threshold decomposition’’ step sets the MSB of yi to ‘1’.
Then, the ‘‘Polarization’’ step will consider the inputs with
u3j ¼ 1 as candidates of the ROF output and polarize the
lower bits of the others to all 0’s. After repeating the above
steps with decreasing b, the output yi will be 14ð11102Þ.
3. The dual-cell RAM architecture for ROF
As mentioned above, the generic ROF algorithm
generates the rank-order value bit-by-bit without using
complex sorting computations. The main advantage of this
algorithm is that the calculation of ROF has low
computational complexity and can be mapped to a highly
parallel architecture. In the algorithm, there are three main
tasks: bit counting, threshold decomposition, and polariza-
tion. To have these tasks efﬁciently implemented, this
paper presents an ROF processor based on a novel
maskable memory architecture, as shown in Fig. 2. The
memory structure is highly scalable with the window size
increasing, by simply adding memory cells. Furthermore,
with the instruction decoder and maskable memory, the
proposed architecture is programmable and ﬂexible for
different kinds of ROFs.
The dual-cell random-access memory (DCRAM) plays a
key role in the proposed ROF architecture. In the
DCRAM, there are two ﬁelds for reusing the input data
and pipelining the ﬁltering process. For the one-dimen-
sional (1-D) ROF, the proposed architecture receives one
sample at a time. For the n-by-n two-dimensional (2-D)
ROF, the architecture reads n samples into the input
window within a ﬁltering iteration. To speed up the process
of ROF and pipeline the data loading and ﬁltering
calculation, the data ﬁeld loads the input data while the
computing ﬁeld is performing bit-sliced operations. Hence,
the execution of the architecture has two pipeline stages:
data fetching and rank-order calculation. In each iteration,
the data fetching ﬁrst loads the input sample(s) into the
data ﬁeld and then makes copies from the data ﬁeld to the
computing ﬁeld. After having the input window in the
computing ﬁeld, the rank-order calculation bitwisely
accesses the computing ﬁeld and executes the ROF tasks.
The computing ﬁeld is in the maskable part of DCRAM.
The maskable part of DCRAM performs parallel reads for
bit counting and parallel writes for polarization. The read-
mask register (RMR) is conﬁgured to mask unwanted bits
ARTICLE IN PRESS
7
5
11
14
2
8
3
0 1 1 1
0 1 0 1
1 0 1 1
1 1 1 0
0 0 1 0
1 0 0 0
0 0 1 1
1:
Threshold
decomposition
0 0 0 0
0 0 0 0
1 0 1 1
1 1 1 0
0 0 0 0
1 0 0 0
2:
Polarization
0 0 0 0
yi 1 X X X
0 0 0 0
1 0 1 1
1 1 1 0
0 0 0 0
1 0 0 0
0 0 0 0
0 0 0 0
3:
Threshold
decomposition
0 0 0 0
1 0 0 0
1 1 1 0
0 0 0 0
1 0 0 0
0 0 0 0
0 0 0 0
4:
Polarization
0 0 0 0
1 0 0 0
1 1 1 0
0 0 0 0
1 0 0 0
0 0 0 0
0 0 0 0
yi 1 1 1 X
5:
Threshold
decomposition
0 0 0 0
1 0 0 0
1 1 1 0
0 0 0 0
1 0 0 0
0 0 0 0
0 0 0 0
6:
Polarization
0 0 0 0
1 0 0 0
1 1 1 0
0 0 0 0
1 0 0 0
0 0 0 0
0 0 0 0
7:
Threshold
decomposition
yi 1 1 1 0
yi 1 1 X X
Fig. 1. An example of the generic bit-sliced ROF algorithm for N ¼ 7,
B ¼ 4, and r ¼ 1.
d_in
Data
Field
Computing
Field
instruction
addr wr
done
cp wm rm rank
c_d
d_out
sr[0]
c_wlc_in
DCRAM
c_in
en
ren
clock
clk
rst
A
dd
re
ss
 D
ec
od
er
Reset
Circuit
reset
Instruction Decoder
RMRWMR
PS
Shift Register
Level-
Quantizer
OUTR
RR
en
sen
Fig. 2. The proposed rank-order ﬁltering architecture.
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 195
Doing so, the proposed architecture is able to pipeline the
iterations for high-performance applications.
4. Implementation of DCRAM
Fig. 5 illustrates a basic element of DCRAM. Each
element has two cells for data ﬁeld and computing ﬁeld,
respectively. The data cell is basically an SRAM cell with a
pair of bitlines. The SRAM cell is composed of INV1 and
INV2 and stores a bit of input sample addressed by the
wordline ‘‘d_wl[i]’’. The computing cell performs three
tasks: copy, write, and read. When the copy-line ‘‘cp’’ is
high, through INV5 and INV6, the pair of INV3 and INV4
will have the copy of the 1-bit datum in the data cell. The
copy operation is unidirectional, and the pair of INV5 and
INV6 can guarantee this directivity. When the one-bit
value stored in the computing cell needs to be polarized,
the ‘‘wm[j]’’ and ‘‘c_wl[i]’’ will be asserted, and the
computing cell will perform the write operation according
to the pair of bitlines ‘‘c_bl[j]’’ and ‘‘c_bl½j’’. When the
ROF reads the bit-sliced value, the computing cell uses an
NMOS, gated by ‘‘rm[j]’’, to output the complement value
of the stored bit to the dataline ‘‘c_d½i’’. The datalines of
computing cells of each word will be then merged as a
single net. Since the RMR is one-hot conﬁgured, each word
has only a single bit being activated during the read
operation.
As shown in Fig. 6, the dataline ‘‘c_d½i’’ ﬁnally goes to
an inverter to pull up the weak ‘‘1’’, which is generated by
the ‘‘rm[j]’’-gated NMOS, and hence the signal ‘‘c_d[i]’’ has
the value of the ith bit of each bit-slice. Because the ROF
algorithm polarizes the non-candidate words with either all
zeros or all ones, the bitline pairs of computing cells are
merged as a single pair of ‘‘c_in’’ and ‘‘c_in’’.
Fig. 7 illustrates the implementation of DCRAM with the
ﬂoorplan. Each Di  Ci pair is a maskable memory cell
where Di denotes D_cell(i) and Ci denotes C_cell(i). Each
word is split into higher and lower parts for reducing the
memory access time and power dissipation [38]. The control
block is an interface between control signals and address
decoder. It controls wordlines and bitlines of DCRAM.
When the write signal ‘‘wr’’ is not asserted, the control block
will disassert all wordlines by the address decoder.
5. Instruction set of proposed ROF processor
The proposed ROF processor is a core for the impulsive
noise removal and enabled by an instruction sequencer.
Fig. 8 illustrates the conceptual diagram of the ROF
processor. The instruction sequencer is used for the
generation of instruction codes and the control of input/
output streams. The instruction sequencer can be a
microprocessor or dedicated hardware.
Fig. 9 lists the format of the instruction set. An
instruction word contains two subwords: the data ﬁeld
instruction and the computing ﬁeld instruction. Each
instruction cycle can concurrently issue two ﬁeld instruc-
tions for parallelizing the data preparation and ROF
execution; hence, the proposed processor can pipeline ROF
iterations. When one of the ﬁeld instructions performs ‘‘no
operation’’, DF_NULL or CF_NULL will be issued. All
registers in the architecture are updated a cycle after
instruction issued.
ARTICLE IN PRESS
d_bl[ j] d_bl[ j]
d_wl[i]
c_bl[ j] c_bl[ j]
c_wl[i]
cp wm[ j]
c_d[i]
rm[ j]Data Cell Computing Cell
INV1
INV2
INV6
INV5
INV3
INV4
Fig. 5. A basic element of DCRAM.
D_cell
(n-1)
cp
d_wl[i]
c_wl[i]
c_d[i]
d_bl[n-1]
d_bl[n-1]
rm[n-1]
c_bl[n-1]
c_bl[n-1]
wm[n-1]
C_cell
(n-1)
D_cell
(n-2)
d_bl[n-2]
d_bl[n-2]
rm[n-2]
c_bl[n-2]
c_bl[n-2]
wm[n-2]
C_cell
(n-2)
D_cell
(0)
d_bl[0]
d_bl[0]
rm[0]
c_bl[0]
c_bl[0]
wm[0]
C_cell
(0)
c_d[i]
c_wl[i]
c_in
c_in
Fig. 6. A DCRAM word mixing data ﬁeld and computing ﬁeld. D_cell(i) denotes the data ﬁeld of ith bit and C_cell(i) denotes the computing ﬁeld of ith
bit.
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 197
below. The instructions other than ‘‘SET 3;’’ will be
repeatedly sent to the instruction decoder.
SET 3;
LOAD 0000, P_READ 00000001;
COPY, P_READ 10000000;
DONE, P_WRITE 01111111;
P_READ 01000000;
P_WRITE 00111111;
P_READ 00100000;
P_WRITE 00011111;
P_READ 00010000;
P_WRITE 00001111;
P_READ 00001000;
P_WRITE 00000111;
P_READ 00000100;
P_WRITE 00000011;
P_READ 00000010;
P_WRITE 00000001;
LOAD 0001, P_READ 00000001;
COPY, P_READ 10000000;
DONE, P_WRITE 01111111;
P_READ 01000000;
P_WRITE 00111111;
P_READ 00100000;
P_WRITE 00011111;
P_READ 00010000;
P_WRITE 00001111;
P_READ 00001000;
P_WRITE 00000111;
P_READ 00000100;
P_WRITE 00000011;
P_READ 00000010;
P_WRITE 00000001;
... ... ...
LOAD 1000, P_READ 00000001;
COPY, P_READ 10000000;
DONE, P_WRITE 01111111;
P_READ 01000000;
P_WRITE 00111111;
P_READ 00100000;
P_WRITE 00011111;
P_READ 00010000;
P_WRITE 00001111;
P_READ 00001000;
P_WRITE 00000111;
P_READ 00000100;
P_WRITE 00000011;
P_READ 00000010;
P_WRITE 00000001;
LOAD 0000, P_READ 00000001;
COPY, P_READ 10000000;
DONE, P_WRITE 01111111;
... ... ...
Since the instruction set is in the format of LIW, the data
fetching and ROF computing can be executed in parallel.
So, the generated instruction stream can pipeline the ROF
iterations, and the data fetching is hidden in each ROF
latency. Fig. 11 shows the reservation table of the 1-D
ROF example. As seen in the reservation table, the ﬁrst and
second iterations are overlapped at the 17–19th clock steps.
At the 17th clock step, the second iteration starts with
loading a new sample while the ﬁrst iteration processes the
LSB bit-slice. At the 18th clock step, the second iteration
copies samples from the data ﬁeld to the computing ﬁeld
and reads the MSB bit-slice. At the same time, the ﬁrst
iteration prepares the ﬁrst ROF result for OUTR. At the
19th clock step, the ﬁrst iteration sends the result out while
the second iteration performs the ﬁrst polarization. Thus,
the iteration period for each iteration is 15 cycles.
6. Application of the proposed ROF processor
In Section 5, we use 1-D non-recursive ROF as an
example to show the programming of the proposed ROF
processor. Due to the programmable design, the proposed
ROF processor can implement a variety of ROF applica-
tions. The following subsections will illustrate the opti-
mized programs for three examples: 1-D RMF, 2-D non-
recursive ROF, and 2-D RMF.
6.1. 1-D recursive median filter
The recursive median ﬁltering (RMF) has been proposed
for signal smoothing and impulsive noise elimination. It
can effectively remove sharp discontinuities of small
duration without blurring the original signal. The RMF
recursively searches for the median results from the most
recent median values and input samples. So, the input
window of RMF can be denoted as fyik; yikþ1; . . . ;
yi1; xi; . . . ; xiþlg, where yik; yikþ1; . . . ; yi1 are the most
recent median values and xi; . . . ; xiþl are the input samples,
and the result yi is the dðl þ k þ 1Þ=2eth value of the input
window.
ARTICLE IN PRESS
2 3 4 5 6 7 8 9 10 11Cycle Time
RR
DF of DCRAM
CF of DCRAM
RMR
Level Quantizer
WMR
PS
Shift Register
OUTR
12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
The first iteration The second iteration The third iteration
1
Fig. 11. Reservation table of the 1-D non-recursive ROF.
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 199
6.2. 2-D non-recursive rank-order filter
Fig. 15 illustrates the block diagram for the 2-D non-
recursive ROF. From Fig. 16, each iteration needs to
update three input samples (the pixels in the shadow
region) for the 3 3 ROF; that is, only n input samples
need to be updated in each iteration for the n  n ROF. To
reuse the windowing data, the data storage is arranged as
shown in Fig. 17. So, for the 2-D ROF, the data reusability
of our process is high; each iteration updates only n input
samples for an n  n window. Given a 2-D n  n ROF
application with n ¼ 3 and r ¼ 5, the optimized reservation
table can be scheduled as Fig. 18.
6.3. 2-D recursive median filter
Similar to the 1-D RMF, the 2-D n-by-n RMF ﬁnds the
median value from the window formed by some previous-
calculated median values and input values. Fig. 19(a)
shows the content of the 3 3 window centered at ði; jÞ. At
the end of each iteration, the 2-D 3 3 RMF substitutes
the central point of the current window with the median
value. The renewed point will then be used in the next
iteration. The windowing for 2-D RMF iterations is shown
in Fig. 19(b), where the triangles represent the previous-
calculated median values and the pixels in the shadow
region are updated at the beginning of each iteration.
According to the windowing, Fig. 20 illustrates the data
storage for high degree of data reusability. Finally, we can
implement the 2-D RMF as the block diagram illustrated
in Fig. 21. Given a 2-D 3 3 RMF application, the
optimized reservation table can be scheduled as Fig. 22.
7. The fully pipelined DCRAM-based ROF architecture
As seen in Section 6, the reservation tables are not tightly
scheduled because the dependency of bit-slicing read,
threshold decomposition, and polarization forms a cycle.
The dependency cycle limits the schedulability of ROF
tasks. To increase the schedulability, we further extended
the ROF architecture to a fully pipelined version at the
expense of area. The fully pipelined ROF architecture
interleaves three ROF iterations with triple computing
ﬁelds. As shown in Fig. 23, there are three computing ﬁelds
which process three tasks alternatively. To have the tightest
schedule, we pipelined the level-quantizer into two stages,
LQ1 and LQ2, so the loop (computing ﬁeld, level-
quantizer, shift register) has three pipeline stages for the
highest degree of parallelism. The LQ1 is the FA/HA tree
and the LQ2 is the carry generator.
Since there exist three iterations being processed
simultaneously, a larger memory is required for two more
iterations. Hence, we extended the DCRAM to an
ðN þ 2dÞ-word memory, where N is the window size of
ROF and d is the number of updating samples for each
iteration. The value of d is 1 for 1-D ROF, and n for 2-D n-
by-n ROF. To correctly access the right samples for each
iteration, the signal ‘‘cm’’ is added to mask the unwanted
samples during the copy operation. In each computing
ﬁeld, the unwanted samples are stored as all zeros. Doing
so, the unwanted samples will not affect the rank-order
results. Fig. 24 illustrates the modiﬁed computing cell for
fully pipelined ROF. The INV5 and INV6 are replaced
with GATE1 and GATE2. When ‘‘cm[i]’’ is ‘‘0’’ the
computing cell will store ‘‘0’’; otherwise, the computing cell
ARTICLE IN PRESS
2 3 4 5 6 7 8 9 10 11Cycle Time
RR
DF of DCRAM
CF of DCRAM
RMR
Level Quantizer
WMR
PS
Shift Register
OUTR
12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
The first iteration The second iteration The third iteration
1
Fig. 14. Reservation table of the 1-D RMF.
Instruction
Sequencer
Programmable
Rank-Order
Filter d_out
pixel input
Scan Line
Scan Line
done
8
8 instruction
d_in
8
D
D
D
2
input_sel
8
00
01
10
N-1 words
N-1 words
Fig. 15. Block diagram of the 2-D non-recursive ROF with 3-by-3
window.
0 1 2 3 4 5 6 7 254 255
0
1
2
3
4
254
255
current window
previous window
i
j
Fig. 16. The windowing of the 3 3 non-recursive ROF.
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 201
r ¼ 4, 5, and 6, the denoise results are shown in Fig.
27(b–d), respectively. Fig. 28(a) is a noisy ‘‘Lena’’ image
corrupted by 9% of impulsive noise. After being processed
by the 2-D 3 3 RMF, the denoise result is shown in Fig.
28(b). The results are the same as those of Matlab
simulation.
Upon verifying the proposed ROF processor using the
cycle-accurate behavior model, we then implemented the
processor in the fully custom design methodology. Because
of high regularity of memory, the proposed memory-based
architecture saves the routing area while comparing with
the logic-based solutions. Fig. 29(a) shows the overall chip
layout and the dash-lined region is the core. The die size is
1063:57 1069:21mm2 and the pinout count is 40. Fig.
29(b) illustrates the detail layout of the ROF core. The core
size is 356:1 427:7mm2 and the total transistor count is
3942. Fig. 29(c) illustrates the ﬂoorplan and placement.
The physical implementation has been veriﬁed by the post-
layout simulation. Table 1 shows the result of timing
analysis, obtained from NanoSim. As seen in the table, the
critical path is the path 3 and the maximum clock rate can
be 290MHz at 3.3V and 256MHz at 1.8V. As the result of
post-layout simulation, the power dissipation of the
proposed ROF is quite low. For the 1-D/2-D ROFs, the
average power consumption of the core is 29mW at
290MHz or 7mW at 256MHz. The performance sufﬁ-
ciently satisﬁes the real-time requirement of video applica-
tions in the formats of QCIF, CIF, VGA, and SVGA. The
chip is submitted to Chip Implementation Center (CIC),
Taiwan, for the fabrication.
Furthermore, we have successfully built a prototype
which is composed of a FPGA board and DCRAM chips
to validate the proposed architecture before fabricating the
custom designed chip. The FPGA board is made by Altera
and the FPGA type is APEX EP20K. The FPGA board
can operate at 60MHz at the maximum. The DCRAM
chip was designed by full-custom CMOS technology.
Fig. 30(a) shows the micrograph of the DCRAM chip.
The chip implements a subword part of DCRAM and the
Fig. 30(b) illustrates the chip layout. The fabricated
DCRAM chip was layouted by full-custom design ﬂow
using TSMC 0.35 2P4M technology. As shown in Fig. 31,
with the supply voltage of 3.3 V, the DCRAM chip can
operate at 25MHz. Finally, we successfully integrated the
FPGA board and the DCRAM chips into a prototype as
shown in Fig. 32. The prototype was validated with ROF
algorithms mentioned above.
9. Comparison of existing ROF architectures
Since this paper is the ﬁrst one that uses SRAM-like
memory as the kernel of the ROF processor, it is hard to
quantitatively compare the proposed memory-based archi-
tecture with existing logic-based architecture. Therefore,
we qualitatively make comparisons with the other ROF
ARTICLE IN PRESS
Address Address
AddressAddress
AddressData Field Data Field
Data FieldData Field
Data Field
0000 x (3,3)
0001 x (2,3)
0010 y(1,3)
0011 x (3,1)
0100 y(2,1)
0101 y(1,1)
0110 x (3,2)
0111 x (2,2)
1000 y(1,2)
0000
0001
0010
0011
0100
0101
0110
0111
1000
0000
0001
0010
0011
0100
0101
0110
0111
1000
. . .
x (3,3)
x (2,3)
y(1,3)
x (3,4)
x (2,4)
y(1,4)
x (3,2)
y(2,2)
y(1,2)
x (3,3)
y(2,3)
y(1,3)
x (3,4)
x (2,4)
y(1,4)
x (3,5)
x (2,5)
y(1,5)
0000
0001
0010
0011
0100
0101
0110
0111
1000
x (3,6)
x (2,6)
y(1,6)
x (3,4)
y(2,4)
y(1,4)
x (3,5)
x (2,5)
y(1,5)
0000
0001
0010
0011
0100
0101
0110
0111
1000
x (3,6)
x (2,6)
y(1,6)
x (3,7)
x (2,7)
y(1,7)
x (3,5)
y(2,5)
y(1,5)
The  symbols " " point to positions
point to positions
for the newest input samples
The symbols " "
for the windowing median values
(2) (3)(1)
(4) (5)
Fig. 20. The data storage of 2-D RMF.
Instruction
Sequencer
Programmable
Rank-Order
Filter
d_out
pixel input
Scan Line
done
8
8 instruction
d_in
8
D
D
2
input_sel
8
Scan Line
00
01
10
11
N-2 words
N-1words
Fig. 21. Block diagram of the 2-D RMF with 3-by-3 window.
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 203
elements and repeatedly executes the DI procedure, called
DI. The DI contains three steps: ﬁnding the proper
location for new coming sample, discarding the eldest
one, and moving samples between the newest and eldest
one position. Although the linear sorting array can reduce
the hardware complexity to O(N), it requires a large latency
for DI steps and has the latency complexity of O(N).
Obviously, our architecture outperforms most of linear
sorting arrays. Paper [20] presents a shiftable memory,
called SCAM, for reducing the latency complexity, but the
reduction is true only when applying their architecture for
1-D applications. For a window of size n-by-n, the SCAM
processor needs n DI procedures for each ﬁltering
computation because each iteration of the 2-D ROF
updates at least n samples. To have an efﬁcient 2-D rank-
order ﬁlter, papers [12,27] present the linear sorting arrays
for 2-D ROF at the expense of area. Comparing with them,
our approach has higher degree of ﬂexibility for 1-D and
2-D applications while the hardware cost is low.
Based on the bit-sliced algorithm, the bit-serial logic
network can bitwisely select the ranked candidates and
generates the ranked result one bit at a time. The bit-serial
logic network recursively executes two steps: majority
calculation and polarization. This type of ROFs can reduce
the latency complexity to O(B); however, many of them use
complex logic networks to implement the majority
calculation. Paper [21] uses an inverter as a voter for
majority calculation. It signiﬁcantly improves both hard-
ware cost and processing speed; nevertheless, the noise
margin will become narrow as the number of inputs
increases.
The proposed architecture basically takes the advantages
of the bit-sliced algorithm: (1) the latency is independent of
the window size, and (2) the result can be obtained without
exhaustive comparisons. Comparing with the bit-serial
logic network, the proposed architecture has higher degree
of ﬂexibility and regularity because of the DCRAM
structure. The DCRAM structure reduces not only the
complexity of the majority calculation, but also the routing
area between components.
Another major strength of the proposed ROF processor
is the programmability. Paper [31] is one of the pioneer on
programmable ROF processor; however, their application
is limited to median ﬁltering. Thanks to the DCRAM
structure, the proposed ROF processor is ﬂexible with the
variation of the rank order r and algorithms. As shown in
Section 6, our ROF processor can be programmed for any
rank order r and diverse applications. Furthermore, the
ARTICLE IN PRESS
Cycle Time
RR
DF of DCRAM
CF3 of DCRAM
RMRS
LQ1
WMRS
PS
Shift Register
OUTR
The first iteration The second iteration The third iteration
LQ2
CF1 of DCRAM
CF2 of DCRAM
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
The fourth iteration The fifth iteration The sixth iteration
Fig. 26. Reservation table of the 1-D non-recursive ROF for fully pipelined ROF architecture.
Fig. 27. Simulation results of a 2-D ROF application. (a) The noisy
‘‘Lena’’ image corrupted by 8% of impulsive noise. (b) The ‘‘Lena’’ image
processed by the 3 3 4th-order ﬁltering. (c) The ‘‘Lena’’ image processed
by the 3 3 5th-order ﬁltering. (d) The ‘‘Lena’’ image processed by the
3 3 6th-order ﬁltering.
Fig. 28. Simulation results of a 2-D RMF application. (a) The noisy
‘‘Lena’’ image corrupted by 9% of impulsive noise. (b) The ‘‘Lena’’ image
processed by the 3 3 RMF.
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 205
consumption can be as low as 7mW at 256MHz. The
processing speed can meet the real-time requirement of
image applications in the QCIF, CIF, VGA, or SVGA
formats.
Acknowledgments
This work was supported by the National Science
Council, ROC, under the Grant no. NSC 94-2220-E-009-
023. We gratefully acknowledge the implementation work
made by Shih-Jay Huang.
Appendix A
Given a 2-D n  n ROF application with n ¼ 3 and r ¼ 5
and the following is the pseudo-code:
SET 5;
i ¼ 0; - - IS
start loop; - - IS
input_sel ¼ 0; - - IS
LOAD i, P_READ 00000010;
input_sel ¼ 1; - - IS
LOAD i+1, P_WRITE 00000001;
input_sel ¼ 2; - - IS
LOAD i+2, P_READ 00000001;
COPY, P_READ 10000000;
DONE, P_WRITE 01111111;
P_READ 01000000;
P_WRITE 00111111;
P_READ 00100000;
P_WRITE 00011111;
P_READ 00010000;
P_WRITE 00001111;
P_READ 00001000;
P_WRITE 00000111;
P_READ 00000100;
P_WRITE 00000011;
i++; - - IS
i ¼ 3*(i mod 3); - - IS
end loop; - - IS
Given a 2-D 3 3 RMF application, the pseudo-code is
written as follows:
SET 5;
i ¼ 0; - - IS
start loop; - - IS
ARTICLE IN PRESS
Fig. 30. (a) The micrograph of DCRAM chip. (b) The layout of the
DCRAM chip.
Fig. 31. Measured waveform of the DCRAM chip.
Fig. 32. The system prototype of rank-order ﬁltering processor.
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 207
[38] S. Singh, S. Azmi, N. Agrawal, P. Phani, A. Rout, Architecture and
design of a high performance SRAM for SOC design, IEEE
International Symposium on VLSI Design, January 2002,
pp. 447–451.
Meng-Chun Lin was born in 1978. He received
the B.S. degree and the Best Student Award in
Electronics Engineering from Fu Jen Catholic
University, Taipei, Taiwan, ROC, in 2001, and
the M.S. degree in the Electrical and Control
Engineering, National Chiao Tung University
Hsinchu, Taiwan, ROC, in 2003. He is currently
working toward the Ph.D. degree in the Electrical
and Control Engineering, National Chiao Tung
University. His research interests are image
processing, video processing, VLSI architecture
and memory circuit design.
Lan-Rong Dung was born in 1966. He received a
BSEE and the Best Student Award from Feng
Chia University, Taiwan, in 1988, an MS in
Electronics Engineering from National Chiao
Tung University, Taiwan, in 1990, and Ph.D. in
Electrical and Computer Engineering from Geor-
gia Institute of Technology, in 1997. From 1997
to 1999 he was with Rockwell Science Center,
Thousand Oaks, CA, as a Member of the
Technical Staff. He joined as the faculty of
National Chiao Tung University, Taiwan, in
1999 where he is currently an Associate Professor in the Department of
Electrical and Control Engineering. He received the VHDL International
Outstanding Dissertation Award in Washington DC in October, 1997. His
current research interests include VLSI design, digital signal processing,
hardware–software codesign, and system-on-chip architecture. He is a
member of Computer and Signal Processing societies of the IEEE.
ARTICLE IN PRESS
M.-C. Lin, L.-R. Dung / INTEGRATION, the VLSI journal 41 (2008) 193–209 209
2358 IEEE JOURNAL OF SOLID-STATE CIRCUITS, VOL. 42, NO. 11, NOVEMBER 2007
Fig. 1. Resonator-based second-order tri-level modulator.
dynamic range of 86 dB and a peak signal-to-noise and distor-
tion ratio (SNDR) of 78 dB. It costs an active area of 2.8 mm
and consumes 180 mW from a 2.5-V supply voltage.
This paper is organized as follows. Section II describes the
system-level design and architectural decisions of the proposed
ADC with nonideality analysis. Section III provides circuit
details for the implementation of the proposed modulator.
Section IV reports the measured results of the fabricated chip.
Finally, Section VI concludes our work in terms of chip features.
II. ARCHITECTURAL CONSIDERATION
The cascaded architecture has been widely used for low OSR
modulator to solve the stability problem of high-order modula-
tion. In this paper, we adopt the cascaded 2-1-1 to design the
proposed modulator for two reasons. First, in practical, the
modulator will approach the limitation of performance when the
order is higher than four [10]. The fifth or higher order
modulators will not provide significant improvement than the
fourth-order modulator. Second, the paper [13] presents an
in-depth study on comparison of 2-1-1 and 2-2 architectures and
shows that the 2-1-1 architecture practically outperforms the 2-2
one for low OSR design.
As mentioned in Section I, the design of cascaded architec-
ture requires tradeoffs among power dissipation, resolution, and
bandwidth. When making the tradeoffs, there exist several ar-
chitectural decisions to be made in the design of the cascaded
modulator. The following subsections will describe the archi-
tectural considerations of our study.
A. Topology Design of the First Stage
Since the first stage processes the input signal and generates
the quantization noise to the succeeding stages, the performance
of the entire modulator is bounded by behaviors of the first-
stage topology, such as noise-shaping capability, linearity, and
tone behavior. To design a high-dynamic-range, low-power
modulator for ADSL2+ application, a resonator-based second-
order modulator is used in the first stage, as shown in Fig. 1. It
uses a low-Q resonator-based loop filter that introduces a pair
of zeros into noise transfer function (NTF). The NTF of the
resonator-based modulator can be expressed as
(1)
where , , and . Note that is
the loop gain of the resonator and is the gain of the quantizer.
The zeros of NTF create a notch around the edge of signal band
and hence suppress the in-band quantization noise. The suppres-
sion can significantly improve the signal-to-noise ratio (SNR) of
modulators, especially for a low OSR modulator [10]. The feed-
forward path from input to the adder followed by the quantizer is
used to reduce the distortion caused by integrator nonidealities
[12]. The following equation shows the signal transfer function
(STF) induced by the feedforward path:
(2)
Based on (2), the error signal becomes
(3)
In (3), the term can be treated as the impact factor of
to . Obviously, the smaller the impact factor is, the
less sensitive the loop filter is to the input signal. When is
a unity, the does not have the component and the
integrators of the loop filter will only process the quantization
noise . In this case, the distortion caused by integrator non-
idealities can be significantly reduced [11]. Unfortunately,
cannot be a unity in practical design because there always exists
quantization error between the input and output of a quantizer.
In the case of using the single-bit quantizer, varies with the
input signal of the quantizer, and its value can be much greater
than unity. The variation of causes the sensitivity of the loop
filter to the input signal to be high. To take advantage of making
unity, one can use the multibit quantizer to lower the sen-
sitivity as much as possible [12]. Nevertheless, when using the
multibit quantizer, the modulator requires the data-weighted av-
eraging (DWA) algorithm to compensate for the nonlinearity
of the multibit DAC. Here we replace multibit quantizer with
a tri-level one in that the variation of tri-level quantizer can
be reduced and the performance is improved as compared with a
single-bit quantizer. Although the tri-level DAC introduces dis-
tortion, the 14-bit linearity can be achieved by careful sizing
of the transistors composing the OTA and symmetrical layout
without using the DWA circuitry. The next subsection will de-
tail the design of the tri-level quantizer.
2360 IEEE JOURNAL OF SOLID-STATE CIRCUITS, VOL. 42, NO. 11, NOVEMBER 2007
Fig. 4. Block diagram of RMASH 2-1-1 .
where is the quantization noise of the tri-level quantizer
in the third stage and is the inverse of . Obviously,
the can be improved by tuning parameters, , , and
. With the careful selection of the resonator loop gain ,
the NTF zeros can produce a notch near the edge of the signal
band to suppress the quantization noise over the desired signal
band. According to [15], the NTF zeros are placed at the corner
frequency of the signal band, and the value of can be chosen
by the following expression:
(8)
At an OSR of 16, with in-band zeros, the fourth-order NTF can
improve the SNDR by 14 dB.
Furthermore, we applied two pairs of reference voltages
(TPRVs) for the proposed modulator: a pair of 0.9V for
the tri-level quantizer of the first stage and another pair of
0.45V for the quantizers in the second and third stages. The
high-voltage pair can have the first stage operating at high
dynamic range while the low-voltage pairs can reduce the
output swing of the second stage and the power of . The
reason why we tried to reduce the output swing of the second
stage is because the reduction implies the scaling of and the
SNDR can be improved by reducing .
Given the OSR of 16 and the of 2, Fig. 5 shows the NTFs
of the proposed RMASH 2-1-1 with TPRVs and conven-
tional MASH 2-1-1 without TPRVs. We can see the perfor-
mance gain of 20 dB in the shadow region. Fig. 6 illustrates the
SNDR versus OSR in comparison to the modulators. The single-
loop modulator with 4-bit quantizer ideally has the best SNDR;
however, it usually requires additional power-consuming costly
Fig. 5. TQN plots of RMASH 2-1-1 with TPRVs and MASH 2-1-1
without TPRVs.
DWA circuitry to improve the linearity of a multibit DAC. At
an OSR of 16, the proposed RMASH 2-1-1 has an SNDR of
over 90 dB and outperforms the traditional MASH 2-1-1 with a
3-bit quantizer in the last stage.
In general, the leakage quantization noise is the major con-
cern in the design of a cascaded modulator. The leakage
quantization noise is mainly caused by the finite OTA gain
and capacitor mismatching of the first-stage integrators. In the
RMASH 2-1-1 , the capacitor mismatching is especially
critical because the SNR improvement mainly relies on the
2362 IEEE JOURNAL OF SOLID-STATE CIRCUITS, VOL. 42, NO. 11, NOVEMBER 2007
Fig. 9. Plots of simulated SNDR versus capacitor mismatch. (OSR = 16).
Fig. 10. Plot of simulated dynamic range versus OTA offset voltages.
where , , and denote the offset voltage of the OTA,
the reference voltage, and output of a tri-level quantizer, respec-
tively. As shown in (9), the nonideality of a tri-level DAC mainly
depends on the offset voltage of the OTA for a given reference
voltage. Fig. 10 shows the simulated dynamic range of RMASH
2-1-1 as a function of offset voltage of the OTA. To target the
dynamic range of 90 dB, an offset voltage of 5 mV is required.
The offset voltage of 5 mV is achievable by carefully sizing and
paying attention to the layout of the input differential pairs of
the OTA.
E. Digital Decimation Filter
Since the digital output of the modulator is an oversam-
pled noise-shaped signal, the complete ADC chip requires a dig-
ital decimation filter to perform down-sampling and out-band
noise filtering. In this study, we designed a three-stage decima-
tion filter to meet the linearity requirement of ADSL2+. The
design of the decimation filter determines the filter types and
coefficients by considering the finite word-length effect and the
SNDR requirement and results in a three-stage digital filter.
Fig. 11 shows the block diagram of the three-stage decimation
filter. The first stage is a fifth-order cascaded integrator-comb
Fig. 11. Block diagram of the three-stage decimation filter.
Fig. 12. Frequency response of the fifth-order CIC filter.
Fig. 13. Frequency response of the 31-tap FIR filter.
(CIC) filter with the down-sampling ratio of 4, and its transfer
function is shown as follows:
(10)
Fig. 12 illustrates the frequency response and circuit imple-
mentation of CIC filter. Following the CIC filter, the second
stage is a 31-tap finite impulse response (FIR) filter with a down-
sampling ratio of 2. Fig. 13 shows its frequency response with
finite word-length effect. Finally, the third stage is an infinite im-
pulse response (IIR) filter with a down-sampling ratio of 2. The
IIR filter is synthesized by the fourth-order Chebyshev Type II
topology. The frequency response of the IIR filter is shown in
Fig. 14.
2364 IEEE JOURNAL OF SOLID-STATE CIRCUITS, VOL. 42, NO. 11, NOVEMBER 2007
Fig. 17. Circuit implementation of the first-stage modulator.
circuits, dissipates 15 mW from a 2.5-V supply and achieves
a GBW of 300 MHz with a capacitive loading of 5 pF, while
the phase margin is 75 . The total thermal noise contribution
over the 2.2-MHz signal bandwidth is about 12.6 V. The SC
common-mode feedback is used for the designed OTA because
it does not dissipate the static power. The capacitors used in the
common-mode feedback (CMFB) circuitry are properly chosen
to maximize the gain bandwidth and thus avoid the settling error.
We also used a similar OTA for other stages, and it dissipates 0.7
times the power consumption that the first-stage OTA consumes.
C. First-Stage Circuit
Fig. 17 illustrates the circuit diagram of the first-stage mod-
ulator. Since the dynamic range of the modulator is targeted at
90 dB at the sampling rate of 70.4 MHz, the sampling capac-
itor is chosen to be 1.5 pF and, accordingly, the integrating and
resonator feedback capacitors are 3 and 0.375 pF, respectively.
The closed-loop bandwidth of the front-end integrator is about
255 MHz, which is larger than three times the sampling fre-
quency. Because the feedback gain of the tri-level DAC is equal
to one, we can use the share-capacitor switching technique to
eliminate coefficient mismatch. The share-capacitor switching
technique is to have the input sampling and feedback DAC share
a common sampling capacitor [17]. However, the depen-
dent load on the reference voltage may cause harmonic distor-
tion. In our work, we used a dummy SC network to reduce the
distortion [18]. The output two-bit code of the tri-level quantizer
is used to switch , , and at the integrating phase.
The summing circuit in front of the quantizer is implemented
by using a passive SC network to avoid the use of an additional
OTA and save the power dissipation. The summed signal can be
expressed as
(11)
where , , and are the capacitors for feedfor-
ward gains. According to behavioral simulation, the feedfor-
ward gains are not critical and can tolerate the variation up to
2%. This allows the use of small capacitance to implement the
feedforward gains. We set the values of , , and
to 0.125, 0.25, and 0.5 pF, respectively. Note that the summed
signal is scaled down by 1/7 when comparing with the parame-
ters of Table I and Fig. 1. In order not to affect the desired per-
formance of the modulator, the reference voltages of the quan-
tizers must be scaled down by a factor of 1/7 from the nominal
value. This also scales down the quantizer step size and, hence,
increases the requirement of the comparator resolution. In our
case, the required step size of the tri-level quantizer is about
150 mV. This requirement is feasible because, in practice, the
CMOS comparator with preamplifier can provide a resolution
better than 50 mV.
D. Tri-Level Quantizer Circuit
The circuit diagram of the tri-level quantizer is shown in
Fig. 18. As mentioned above, the SC network must scale down
the reference voltages, VR+ and VR-, by a factor of 1/7. So,
we set the values of the capacitors and to 0.125 and
0.75 pF, respectively. In our design, we used a high-speed
high-accuracy CMOS comparator with a preamplifier which
is presented by [19]. The clock is used to control the
generation of , , and . Because of the time-delay of
AND gates, the nonoverlapping interval of is limited to
1 2 ns when we have a sampling rate of 70.4 MHz.
E. Cancellation Filter and Decimation Filter Circuit
The implementation of the digital cancellation filter and dec-
imation filter is based on the cell-based synthesis flow. Ac-
cording to the coefficients listed in Table I, the transfer functions
2366 IEEE JOURNAL OF SOLID-STATE CIRCUITS, VOL. 42, NO. 11, NOVEMBER 2007
Fig. 20. Chip microphotograph.
printed circuit board to separate the analog signal from the
digital signal and hence reduce the crosstalk. The input clock
is generated from an external 70.4-MHz low-jitter crystal with
independent power supply voltages to avoid the switching-noise
coupling. With a sampling rate of 70.4 MHz, the ADC achieves
a dynamic range of 86 dB and a peak SNDR of 78 dB. Note
that the overall power dissipation of the ADC can be further
reduced by synthesizing the digital decimation filter with lower
supply voltage. Fig. 21 illustrates the measured SNR and
SNDR against input level for the ADC. The measured output
spectrum for a 500 kHz sinusoidal input is shown in Fig. 22,
and, accordingly, the SFDR is 89 dB. To quantitatively evaluate
the efficiency among power dissipation, dynamic range, and
conversion rate, we use the formulas for the effective number
of bits (ENOB) of the ADC and the figure-of-merit (FOM) as
shown below [20]:
(16)
Fig. 23 shows the FOM distribution of our work and existing
wideband ( 1 MHz) SC modulators. Table III summarizes
the measured performance and specifications of the proposed
modulator and compares with the other wideband SC mod-
ulators as well.
V. CONCLUSION
This paper addresses a low-power, high-linearity cascaded
ADC architecture appropriate for ADSL2+ application.
This study uses three approaches to improve performance and
reduce power consumption: using the resonator-based topology,
applying the tri-level quantization, and using two pairs of ref-
erence voltages. The proposed modulator has been fabricated
Fig. 21. Plots of measured SNDR and SNR versus input signal level.
Fig. 22. Measured output PSD of proposed RMASH 2-1-1 ADC.
Fig. 23. FOM distribution of wideband SC  modulators with respect to
conversion rate.
in TSMC 0.25- m 1P5M CMOS technology. As shown in
the experimental result, the designed ADC can achieve a peak
SFDR of 89 dB, a dynamic range of 86 dB, and a peak SNDR
of 78 dB.
2368 IEEE JOURNAL OF SOLID-STATE CIRCUITS, VOL. 42, NO. 11, NOVEMBER 2007
Jwin-Yen Guo received the B.S.E.E. degree in
electrical engineering from National Taiwan Univer-
sity, Taipei, Taiwan, R.O.C., in 1985, and the M.S.
and Ph.D. degrees in electronics from the Institute
of Electronics, National Chiao Tung University
(NCTU), Hsinchu, Taiwan, R.O.C., in 1987 and
1994, respectively.
His research while with NCTU were on the design,
modeling and characterization of deep-submicrom-
eter SOI MOSFETs. He is currently with Richtek
Technology Corporation, where he is responsible for
the development of highly integrated, high-efficiency dc–dc converters and
HV power amplifiers. In his previous tenure with Trendchip Technologies,
Hsinchu, Taiwan, R.O.C., he was responsible for high-performance xDSL
analog front-end development. His current research interest is in the design and
integration of HV ICs, data converters, and related analog/mixed-signal ICs.
Kai-Jiun Yang received the B.S. degree in electrical
engineering from Tamkang University, Taipei,
Taiwan, R.O.C., in 1999, and the M.S. degree
in electrical engineering from the University of
Southern California, Los Angeles, in 2001.
Since 2001, he has been with Trendchip Tech-
nologies, Hsinchu, Taiwan, R.O.C., currently as a
Senior Engineer with the Department of Digital IC.
His research interests include DMT engine on xDSL
system and IC design.
if given a chance to rest during periods of reduced load. The
discharge curve with dynamic current loads can be estimated
by carrying out a set of current load tests and cooperating with
surface fitting and interpolation techniques.
II. MODEL DESCRIPTION
The objective of this section is to explain the proposed
battery model for the gas-gauging strategy and parameterize
the discharge operating conditions.
A. Description of the discharge characteristics
A typical discharge voltage versus time characteristic for
a Li-ion battery is given in Fig. 1. Clearly there are four
distinct regions; two nonlinear regions (Region 1 and Region
3) and two linear regions (Region 2 and Region 4). From an
user point of view the linear regions are the most important.
The Region 1, occurring at the start of discharge, typically
occupies a small proportion of the total discharge duration.
By observing Fig. 1, the discharge curve can be divided into
two parts shown in Fig. 3: an exponential voltage decay of the
first phase characterized by discharging a fully charged single
time constant resistor-capacitor circuit (STC RC circuit) with
a long time constant, τ , as described by
τ = RC (1)
and a linear change of the second phase characterized by
discharging a small capacitor. Therefore, we conclude that
a Li-ion battery can be modeled as a two-phase component
as shown in Fig. 2 where an internal resistance Rint has
two components R1 and R2. The exponential decay can be
expanded as a Taylor series where t is time.
1
τ
e
−t
τ =
1
τ
∞∑
n=0
(−tτ )
n
n!
(2)
Since t  τ , the first phase, then, was approximated as a linear
change. Consequently, applying the approximation combining
two straight lines (L1 : at + b) and (L2 : ct + d) agrees well
with the measured data. We named the intersection "Knee"
where the voltage was specified as VK , thereby being aware of
the curve entering the second phase. Briefly, we focus attention
on statistics of the slopes of two straight lines and VK to
characterize the curve of terminal voltage during constant-
current discharge at constant temperature.
Observing Fig. 4, for the first 800 sec the discharge current
was 0.5A. Then, the current load was reduced to 0.4A. Under
this condition, the battery recovers its voltage and afterward,
discharges in a manner of exhibiting the same behavioral trend
of the discharge curve under 0.4A till the end of discharge.
B. Determining model parameters
To validate the proposed equivalent model, the model pa-
rameters of a specific battery must be identified experimentally
first. We use the battery emulator which was presented in
[7] to obtain the discharge curves under a set of constant
discharge rates (0.2A, 0.3A, 0.4A, and 0.5A) and a set of
two-stage constant discharge rates. The major objective of
0 200 400 600 800 1000 1200 1400 1600 1800 2000
3
3.1
3.2
3.3
3.4
3.5
3.6
3.7
3.8
3.9
Time (sec)
Ba
tte
ry
 V
ol
ta
ge
 (V
)
Region 1
Region 2
Region 3
Region 4
Fig. 1. Typical discharge voltage versus time characteristic illustrating the
four regions.
CR1
R2
Fig. 2. Equivalent circuit representation of lithium-ion battery.
0 200 400 600 800 1000 1200 1400 1600 1800 2000
3
3.1
3.2
3.3
3.4
3.5
3.6
3.7
3.8
3.9
Time (sec)
Ba
tte
ry
 V
ol
ta
ge
 (V
) Discharge with long
RC time constant
Discharge with
small capacitor
Knee
Fig. 3. Typical discharge voltage versus time characteristic divided into two
phase with an intersection Knee.
867
0.20 0.25 0.30 0.35 0.40 0.45 0.50
3.55
3.60
3.65
3.70
3.75
3.80
3.85
 V
K
Battery Discharge Rate (A)
B
at
te
ry
 V
ol
ta
ge
 (V
)
-2.5x10 -4
-2.0x10 -4
-1.5x10 -4
-1.0x10 -4
-5.0x10 -5
0.0
 a
Sl
op
e 
of
 L
1 
(V
/se
c)
0.20 0.25 0.30 0.35 0.40 0.45 0.50
-0.008
-0.007
-0.006
-0.005
-0.004
-0.003
-0.002
-0.001
 
 
Sl
op
e 
of
 L
2 
(V
/se
c)
Battery Discharge Rate (A)
 c
(a) (b)
Fig. 5. (a) Parameters VK and a for a set of constant discharge rates. (b) Parameter c for a set of constant discharge rates.
(a) (b)
0.2
0.3
0.4
0.5
0.2
0.3
0.4
0.5
-3
-2
-1
0
1
2
3
x 10 -3
The first discharge rate (A)The second discharge rate (A) 0.2
0.3
0.4
0.5
0.2
0.3
0.4
0.5
-2
-1
0
1
2
3
4
x 10 -4
The first discharge rate (A)The second discharge rate (A)
0.2
0.3
0.4
0.5
0.3
0.4
0.5
-4
-3
-2
-1
0
1
2
3
4
x 10 -4
The first discharge rate (A)The second discharge rate (A)
0.2
0.3
0.4
0.5
0.3
0.4
0.5
-4
-2
0
2
4
6
8
x 10 -5
The first discharge rate (A)The second discharge rate (A)
(c) (d)
Fitted surface
Fitted surface
Fig. 6. (a) S_VK(I1, I2) = −0.0089I1 +0.0072I2 +0.0008, fitted surface of ∆VK . (b) Fitting error of ∆VK . (c) S_L2(I1, I2) = 10−3(−0.8541I1 +
0.8369I2 + 0.3229), fitted surface of ∆L2. (d) Fitting error of ∆L2.
869
START
STOP
Measurement
Voltage slope
calculation
Slope gradient
< TH1 ?
Voltage slope
 > TH2 ?
Slope gradient
> 0 ?
Knee estimationVoltage slope
estimation
Service lifetime
estimation (B)
Discharge in the second phase (Region 4)
Current load
changed ?
Cut-off voltage
detected ?
Discharge in the first phase (Region 2)
Service lifetime
estimation (C)
YesNo
Yes
No
No
Knee estimation
Voltage slope
estimation
Service lifetime estimation (A)
Knee
compensation
Voltage slope
compensation
Yes Yes (Region 3)
No
YesNo
(Region 1)
Fig. 9. Flowchart of estimating present remaining capacity and residual service lifetime.
Time (sec)
Lo
ad
 
Cu
rr
en
t (
A) IP
IQ
IR
TP TQ
Fig. 10. Dynamic load current profile example.
estimate the remaining discharge time with high degree of
accuracy.
REFERENCES
[1] (Oct. 2006). Advanced Configuration and Power Interface Specifica-
tion, Revision 3.0b. [Online]. Available: http://www.acpi.info/spec.htm
[2] T.F. Fuller, M. Doyle, and J. Newman, “Modeling of galvanostatic charge
and discharge of lithium-ion insertion cells,” J. Electrochem. Soc., vol. 141,
no. 1, pp. 1–9, Jan. 1994.
[3] (May 2005). FORTRAN Programs for Simulation of Electrochem-
ical Systems. [Online]. Available: http://www.cchem.berkeley.edu/ js-
ngrp/fortran.html
[4] S. Gold, “A PSPICE macromodel for lithium-ion batteries,” in Proceed-
ings of the 12th Battery Conference, pp. 9–15, 1997.
[5] L. Benini, “Discrete-time battery models for system-level low-power
design,” IEEE Trans. Very Large Scale Integr. (VLSI) Syst., vol. 9, no.
5, pp. 630–640, Oct. 2001.
TABLE I
COMPARISON RESULTS.
TP TQ IP IQ IR [7](sec) proposed(sec) err%
200 300 0.8 0.4 0.4 1741 1764 1.31
300 300 0.8 0.4 0.4 1624 1532 -6.71
100 300 0.8 0.5 0.5 1151 1128 -1.98
400 300 0.8 0.5 0.5 912 838 -8.16
300 300 0.8 0.6 0.6 724 703 -2.90
100 300 0.6 0.4 0.4 1881 1927 2.44
500 300 0.6 0.4 0.4 1649 1490 -9.67
300 300 0.6 0.8 0.8 562 557 -0.92
200 300 0.4 0.5 0.5 1250 1172 -6.21
600 300 0.4 0.5 0.5 1347 1344 -0.23
700 300 0.4 0.6 0.6 1113 1159 4.17
200 300 0.5 0.4 0.4 1879 1855 -1.30
600 300 0.5 0.4 0.4 1760 1670 -5.13
200 300 0.5 0.8 0.8 557 524 -5.87
400 300 0.5 0.8 0.8 648 659 1.76
200 300 0.2 0.4 0.4 2001 2059 2.92
600 300 0.2 0.4 0.4 2187 2259 3.27
100 300 0.2 0.8 0.8 553 524 -5.22
400 300 0.2 0.8 0.8 790 782 -1.06
400 400 0.5 0.4 0.3 3265 3197 -2.08
500 400 0.5 0.4 0.3 3196 3275 2.48
500 500 0.5 0.4 0.3 3147 3264 3.72
[6] D. Rakhmatov and S.B.K. Vrudhula, “An analytical high-level battery
model for use in energy management of portable electronic systems,” in
Proc. IEEE Int. Conf. Comput.-Aided Des., pp. 488–493, Nov. 2001.
[7] C. Park, and J. Liu, and P.H. Chou, “B#: a battery emulator and
power profiling instrument,” The International Symposium on Low Power
Electronics and Design (ISLPED), pp. 288–293, Aug. 2003.
[8] R. Casas and O. Casas, “Battery sensing for energy-aware system design,”
Computer, vol. 38, no. 11, pp. 48–54, Nov. 2005.
871
 147 
 2
appropriate bit-rate allocation scheme for GI images is to 
allocate the most bits to green band and a few portions to red 
band. Therefore, under a fixed compression ratio, DEWC 
coding method reserves some bits from red band and allocates 
more portions to green or blue band, therefore, we may obtain a 
higher image quality in less color-distortion in it. However, 
someone may allocate too much bit-rate on green band than on 
others, it may result serious color-distortion on a restored 
image. In clinic diagnosis, color or appearance abnormality 
detection can help clinician to diagnose the digestive 
symptoms. 
 
 
Therefore, color-distortion should be considered and 
quantified in image quality measurement. The second problem 
comes up when we determine measurement of the image 
quality. Traditionally, the quality measurement of PSNR (Peak 
Signal-to-Noise Ratio) [8] is commonly used in image 
compression. Nevertheless, PSNR is only focus on the 
luminance rather on the color information, thus, it can not be 
used to measure the color-distortion of a restored image. Two 
restored images may have the same image quality in luminance 
PSNR; however, they may have different degree quality loss in 
color-distortion. To overcome these crucial problems, the 
color-distortion D∆E measurement based on CIE94 formula 
∆E*94 is proposed in this paper. 
The result of bit-rate and color distortion analysis in Fig. 
3(b)-3(d) shows that color-distortion provides more 
information than bit-rate and MSE distortion analysis. Another 
analysis of color-distortion and bit-rate difference in Fig. 
4(a)-4(b) provides a quantified measurement of color-distortion 
and bit-rate-difference between two arbitrary color bands. It 
reflects the degree of color-distortion due to non-uniform 
bit-rate allocation. Based on analytical result of 
color-distortion and bit-rate-difference, bit-rate allocation 
problem is modeled by linear equations. By solving linear 
equations, a bit-rate allocation scheme for high-quality 
compression can be found. 
 
 
Fig.4. (a) Color-distortion and bit-rate-difference for various bit-rates (sample 
image 04); (b) The relationship between color-distortion D∆E and bit-rate 
difference. 
 
 Fig.3.  The rate-distortion curves for D∆E . (a) The GI image clip#4. (b) 
D∆E at rR=0.5bpp. (c) D∆E at rG=0.5bpp. (d) D∆E at rB=0.5bpp. 
Fig. 2. The rate-distortion curve of the GI image clip #2.  (a) The GI image 
#2.  (b) the rate-distortion curves. 
 149 
 4
 
IV. CONCLUSION 
General JPEG2000 standard is an image compression 
providing superior compression at the expense of greater 
computation required. We have developed the DEWC coding 
method which saves image preprocessing computing and 
directly utilizes CFA raw image acquired from CMOS sensor 
on wavelet SPECK coding. R, G and B color bands are encoded 
separately with high-quality issue in color-distortion 
measurement based on CIE94 ∆E*94 formula. The analytical 
result of color-distortion and bit-rate difference provides us 
guidance for finding a better bit-rate allocation scheme while 
applying image coding. According to the experimental result, 
we also show that proposed DEWC coding has a better image 
quality while comparing to general JPEG2000 compression. 
Additionally, DEWC coding performance is also better than 
general JPEG2000 compression. 
 
ACKNOWLEDGMENT 
This work was supported in part by the National Science 
Council, Taiwan, under the grant number NSC 
95-2221-E009-337-MY3 and Chung-Shan Institute of Science 
and Technology, Taiwan, under the project BV94G10P.  The 
authors would like to thank National Chip Implementation 
Center (CIC) for technical support.  
 
REFERENCES 
[1] Bryce E. Bayer, Color imaging array, U.S. Patent 3971065, 1976. 
[2] J. E. Adams and J. E. Hamilton, Design of practical color filter array 
interpolation algorithms for digital cameras, Proc. SPIE, vol.3028, 
pp.117-125, 1997. 
[3] R. Kimmel, Demosaicing: Image reconstruction from color CCD 
samples, IEEE Trans. on IP, vol.8, no.9, pp. 1221-1228, 1999. 
[4] C.C. Koh, J. Mukherjee and S. K. Mitra, New efficient methods of image 
compression in digital cameras with color filter array, IEEE Trans. on CE, 
vol.49, no.4, pp. 1448-1456, 2003. 
[5] S.Y. Lee and A. Ortega, A novel approach of image compression in 
digital cameras with a Bayer color filter array, IEEE ICIP, vol.3, pp. 
482-485, 2001. 
[6] W.A. Pearlman, A. Islam, N.N. and A. Said, Efficient, low-complexity 
image coding with a set-partitioning embedded block coder, IEEE Trans. 
on CSVT, vol.14, no.11, pp. 1219-1228, 2004. 
[7] Y. Konomura and T. Tsuruoka, Image data compressing device for 
endoscope, US. Patent, no. 4,845,553, 1989. 
[8] M.C. Lin and L.R. Dung and P.K. Weng, An ultra-low-power image 
compressor for capsule endoscope, BioMedical Engineering OnLine, 
vol.5, no.14, 2006. 
[9] OpenJPEG, Communications and remote sensing Laboratory, Universite 
catholique de Louvain, Belgium, http://www.openjpeg.org 
 
 
Fig.5. Comparison of execution times between DEWC and JPEG 2000 
 II. THE PROPOSED INTRA-FRAME VIDEO COMPRESSION 
FOR CAPSULE ENDOSCOPE 
Traditional image compression algorithms use the YCbCr 
image to reduce compressed image size while the visual 
distortion is low. In order to prepare YCbCr image, the typical 
image compression requires two preprocessing steps which 
are demosaicking and the color space transformation.  
However, the demosaicking step requires weighted sums for 
color interpolation and the color space transformation requires 
calculation of inner products. Considering the wireless capsule 
endoscope which we are using, it is not worthwhile to waste 
power on both preprocessing steps as long as the compression 
quality and ratio are acceptable. The measure of compression 
quality is the peak signal-to-noise ratio (PSNR). The 
calculation of PSNR is formulated as (1), where MSE is the 
mean square error of the decompressed image.  
 PSNR = 10 log  
2552
MSE
  
The compression ratio (CR) is defined as the ratio of the 
raw image size to the compressed image size. The measure of 
the compression ratio is the compression rate. The formula of 
the compression rate is calculated by (2).  
 Compression rate =  1 − CR−1 × 100% 
First of all, the proposed image compression directly 
processes raw images without demosaicking and color space 
transform. For a 512x512 image, each pixel is an 8-bit datum 
and each of R, G1, G2, and B components has 256x256 pixels.  
Since the image size after preprocessing in the traditional 
compression is 512x512x8x3 bits, the image size of the 
proposed compression is reduced by the factor of 3. 
The conventional AVC/H.264 video compression employs 
the YCbCr for intra-frame prediction to gain significant 
compression ratio while the visual distortion is minimized, 
based on the factors related to the human visual system (HVS) 
sensitivity. However, to save the power consumption, the 
proposed compression uses the RGB intra-frame prediction to 
save the computation of demosaicking and color space 
transform. Therefore, the advantage of applying RGB intra-
frame prediction is two-fold: saving the power dissipation on 
preprocess steps and reducing the computing load of the intra-
frame compression. 
Because the GI tract environment is cardinal, we made 
three simplifications.  First, the intra-prediction mode is fixed 
to 4-by-4 DC mode.  The second modification is to turn off 
rate-distortion optimization (RDO).  These simplifications are 
based on experimental results.  The R-D curves of colors with 
RDO and without RDO are shown in Figure 1 and Figure 2, 
respectively. According to Figure 1, the fixed 4-by-4 macro-
block mode is better than the fixed 8-by-8 macro-block mode 
while the quality degradation is little, comparing with variable 
block size mode (or all-mode).  From Figure 2, the  
compression rate of R component is 87% when the PSNR is 
40 dB.  The compression rate is higher than the target rate 
75%.  Therefore, the RDO is not necessary to be turned on and 
the intra-prediction mode can be fixed to DC mode only. 
 
Figure 1.  R-D curves of the four color components with RDO:  (a) G1; (b) 
B; (c) R; and (d) G2 
 
 
Figure 2.  R-D curves of the four color components without RDO:  (a) G1; 
(b) B; (c) R; and (d) G2 
Another simplification is to reuse the intra-prediction of 
G1 for G2.  From the experimental results shown in Figure 1 
and Figure 2, G1 and G2 components are highly correlated 
Thus, in the proposed algorithm, we use reconstructive G1 to 
predict G2. We can also learn the reuse approach outperforms 
the fixed 4-by-4 DC mode on G2 component from Figure 3.  
Besides, the power dissipation in G2 reconstructive processes 
is reduced for less register/memory access ticks. 
 
 
 
 
TABLE II.  EXPERIMENTAL RESULTS. 
 
 
III. ARCHITECTURE OF PROPOSED GI IMAGE COMPRESSION 
The architecture of GICam Intra-frame video Encoder is  
shown in Figure 6. The GICam Intra-frame Encoder image 
processes the image in the order of R, G1, G2 and B. Because 
the data stream from the image sensor is block-based, the 
GICam Intra-frame Encoder requires intermediate memory 
units to hold each block of data. Since the Intra-frame 
Encoder is a row-column recursive structure, its input data 
are queued by a set of ping-pong buffers. 
 
Figure 6.  The architecture of proposed GI image compression. 
To validate the GICam intra-frame encoder, we used the 
FPGA board of Altera APEX20KE to demonstrate the 
function of the GICAM intra-frame encoder. Test result 
matches the MATLAB golden results. After FPGA 
verification, we used the TSMC 0.18 μm 1P6M process to 
implement the GICam intra-frame encoder. The logic part is 
synthesized by using Synopsys Design Analyzer. The gate 
count of DCT, RC/Q, IDCT/IQ, G1 register, boundary DC 
register, intra  prediction, CAVLC and 4x4 Ping-Pong buffer 
are 60 K gates. There is only one 4MHz clock in the chip. 
When operating at 1.8 V, the power consumption of logic 
part is 0.9 mW which is estimated by using PrimePower. 
Figure 7 illustrates the layout of the GICam intra-frame 
encoder. 
 
Figure 7.  The implementation result of proposed GI image compression. 
IV. CONCLUSION 
In this paper, we present an ultra-low-power H.264 Intra-
frame video encoder for capsule endoscope or swallowable 
imaging capsules. Considering the characteristics of the 
capsule endoscopy system, the design is a compromise 
between battery life and performance. Instead of applying 
complicated operation, the proposed H.264-based intra-frame 
algorithm significantly reduces the size of the memory and 
computational load. By simplifying the traditional video 
compression and H.264 intra algorithm, we use DC and G1 
prediction mode to promote performance and save power. The 
developed video compressor for 51-by-512 image sensor and 
2 Mbits/sec RF transmitter costs 60k gates and consumes 
0.9161mW power at 2 frames/sec while the average 
compression rate can be 82%. 
REFERENCES 
[1] F. Gong. P. Swain, and T. Mills, ”Wireless endoscopy,” 
Gastrointestinal Endoscopy, vol.51, no. 6, pp. 725-729, June 2000. 
[2] http://www.givenimaging.com/Cultures/en-US/given/english 
[3] M. Sendoh, k. Ishiyama, and K.-I. Arai, ”Fabrication of Magnetic 
Actuator for Use in a Capsule Endoscope,” IEEE Trans. On Magnetics, 
vol. 39, no. 5, pp. 3232-3234, September 2003. 
[4] Federico Carpi, Stefano Galbiati, and Angelo Carpi, ”Controlled 
Navigation of Endoscopic Capsules:Concept and Preliminary 
Experimental Investigations,” IEEE Trans. On Biomedical Engineering, 
vol. 54, no. 11, November 2007. 
[5] M.-C. Lin, L.-R. Dung, and P.-K. Weng, “A Cardinal Image 
Compression for Capsule Endoscope,” BioCAS 2006, November 2006. 
[6] Sheu-Chih Cheng and Hsueh-Ming Hang, ”The impact of rate control 
Algorithms on video codec hardware design” International Conference 
on Image Processing. vol. 2, pp.807-810 Oct.1997. 
 
B image G image R image
415nm 540nm 600nm
Fig. 1. NBI principle (Olympus Corporation, Japan)
Monochromic CCD 
Tissue 
NBI filter 
Xenon Lamp 
Fig. 2. Configuration of Olympus SPECTRUM
band images. Because the absorption band of hemoglobin is
415nm [1], the microvasculature of its mucosal surface can
be seen clearly. Another absorption band of hemoglobin is
540nm. The 415nm light can not reach the depth where the
vessels presented on the 500nm because of multiple scattering
effect in tissue. Therefore, in the synthesized image, we can
see vessels on both superficial and deeper tissue.
The proposed wireless NBI capsule endoscope system is
composed of a capsule, a portable data recorder, a real-time
monitor, an computer with image viewer, and a DICOM
Gateway which is given in Fig. 3. The portable data recorder
receives the image raw data via RF receiver and saves in
large volume flash memory. Meanwhile, real-time monitor can
display the image of digestive tract during routine examination.
After inspection, the received image raw data can be uploaded
to computer through a USB port. The white light image(NBI)
and narrow band image(WLI) image are then synthesized and
shown by software on the computer. The DICOM gateway
provides a standard for handling, storing, printing, and trans-
mitting information in medical imaging.
Inside the wireless NBI capsule, a narrow band LED light
source, a 512-by-512 dual-mode CMOS image sensor, and a
RF transmitter are adopted as illustrated in Fig. 4. Two oxide
batteries and an antenna are also installed for power and RF
transmitter. The narrow band LED light source comprises six
LEDs : three white LEDs for WLI and three 430nm blue LEDs
for narrow NBI. The wireless RF transmitter designed by our
RF team furnishes FSK modulation with 8 Mbps for image
data transmitting which operates in 416MHz ISM band.
Capsule
Endoscope
Data
Recorder
Real-Time
Monitor
Image
Viewer
DICOM
Gateway
Target
Keyboard
Keyboard
Keyboard
Mouse
LCD
Monitor
Mouse
Mouse
LCD
Monitor
LCD
Monitor
Ethernet
Contral
Message
Contral
Message
Contral
Message
˖̂̀̀˴́˷
˂ʳ˗˴̇˴
˖̂̀̀˴́˷
˂ʳ˗˴̇˴
˖̂̀̀˴́˷
˂ʳ˗˴̇˴
Processing image
/ Information
Processing image
/ Information
Processing image
/ Information
Non-DICOM
Image
DICOM
Image
Light
Signal
RF
Signal
RF
Signal
Raw
Image
Fig. 3. The System description of NBI Capsule Endoscope.
3
2
14567
White Light LED 
Narrow Band LED 
Fig. 4. The structure of NBI Capsule Endoscope (1: Len; 2:LEDs; 3: LEDs;
4: CMOS sensor; 5: Battery; 6: RF transmitter; 7: Antenna)
III. DESIGN OF NARROW BAND CMOS IMAGE SENSOR
The design challenge of NBI capsule endoscope concen-
trates on the narrow band image acquisition and its power
consumption. Fig. 5 shows the block diagram of the CMOS
sensor. Each pixel contains three transistors and a photo diode.
Charge pumping produces higher voltage for pixel resetting
to increase output signal swing. Correlated double sampling
circuit is used for low-power noise canceling at the column.
The sampled charges are transferred to video amplifier by
horizontal shift register. The designed flash ADC generates
a 8-bit digital output with very low power consumption. To
acquire proper image intensity and decrease the power con-
sumption of LEDs, a auto expose control ASIC is integrated.
The PISO/Randomizer links the RFIC and image sensor. The
analog and digital circuits inside the chip are supplied by
bandgap reference and regulators.
Color filter array is one of the most singular hardware
elements in a single monochrome sensor to acquire color
CMOS APS
Imaging Area 
(512x512) 
Column CDS Circuits 
Horizontal Shift Register 
PISO
/Randomizer
Auto Expose Ctrl 
V
e
rt
ic
a
l 
S
h
if
t 
R
e
g
is
te
r 
T
im
in
g
 
G
e
n
.
A/D
Video Amp. 
BandGap
Reference 
Charge
Pumping
To RFIC
Regulator
Fig. 5. Block diagram of CMOS sensor
P
ix
el a
rra
y
 5
1
2
x
1
5
2
 
A
D
C
D
ig
ita
l co
re
Vertical Shift Register
Vertical Shift Register
C
o
lu
m
n
 C
D
S
 a
n
d
 H
o
rizo
n
ta
l S
h
ift
R
eg
ister
Fig. 7. Chip photomicrograph.
the sake of power, effective low power techniques need to
be utilized in the design to guarantee long working time.
With 3V power supply, implementation results show the sensor
consumes only 2mA at 2 frame/s and the entire wireless NBI
capsule that dissipates nearly 7∼8 mA can work for 6∼8
hours consecutively. Experiment results on backside mucosa
of a human tongue and pig’s small intestine demonstrate that
NBI capsule endoscope is a beneficial tools for discriminative
diagnosis by providing contrast-enhanced image of vascular
and white light image.
TABLE I
CHIP SPECIFICATIONS
Technology 0.25µm 1P4M CMOS
Chip Size 3.7mm x 3.95mm
Format 512x512
Pixel size 5.6µmx5.6µm
Fill Factor 47%
ADC resolution 8bit
Frame rate 2Hz
Power Consumption 2mW@3V
ACKNOWLEDGMENT
This work was supported by Chung-Shan Institute of Sci-
ence and Technology, Taiwan. The authors would like to thank
Dr. Shien-Ming Wu for his technical support and funds.
REFERENCES
[1] K. Gono, “Multifunctional endoscopic imaging system for support of
early cancer diagnosis,” IEEE Journal of Selected Topics in Quantum
Electronics, vol. 14, no. 1, pp. 62–69, Jan/Feb. 2008.
[2] K. Gono, T. Obi, M. Yamaguchi, N. Ohyama, H. Machida, Y. Sano,
S. Yoshida, Y. Hamamoto, and T. Endo, “Appearance of enhanced tissue
features in narrowband endoscopic imaging,” J. Biomed. Opt., vol. 9,
pp. 568V577, May/Jun. 2004.
[3] K. Gono, K. Yamazaki, N. Doguchi, T. Nonami, T. Obi, M. Yamagichi,
N. Ohyama, H.Machida, Y. Hamamoto Y. Saono S.Yoshida, and T. Endo,
“Endoscopic observation of tissue by narrowband illumination,” Opt.
Rev., vol. 10, pp. 211V215, 2003.
[4] Manabu Muto, Chikatoshi Katada, Yasushi Sano, and Shiegaki Yoshida,
“Narrow band imaging: A new diagnostic approach to visualize an-
giogenesis in superficial neoplasia,” Clinical Gastroenterology and
Hepatology, vol. 3, no. 7, pp. 3:S16–S20, 2005.
WLI
WLI
Color NBI 1 
Color NBI 1 
Fig. 8. WLI and synthesized NBI of live pig’s duodenum in inter-illumination
mode.
Fig. 9. The NBI Capsule Endoscope (Top Left: NBI Capsule Endoscope;
Top Right: LED module; Bottom Left: Receiver and Data Recorder; Bottom
Right: Image Viewer )
[5] Prateek Sharma, “Narrow band imaging in barrett’s esophagus,” Clinical
Gastroenterology and Hepatology, vol. 3, no. 7, pp. 3:S21–S22, 2005.
[6] G. Iddan, G. Meron, and A. Glukhovsky et al., “Wireless capsule
endoscopy,” Nature, vol. 405, pp. 417–418, May 25 2000.
[7] XinKai Chen, Xiaoyu Zhang, Linwei Zhang, Xiaowen Li, Nan Qi,
Hanjun Jiang, and Zhihua Wang, “A wireless capsule endoscope system
with low-power controlling and processing asic,” IEEE Trans. on
Biomedical and Systems, vol. 3, no. 1, pp. 11–22, Feb. 2009.
[8] Xiang Xie, Guolin Li, Xinkai Chen, Xiaowen Li, and Zhihua Wang,
“A low-power digital ic design inside the wireless endoscopic capsule,”
IEEE Journal of Solid-State Circuits, vol. 41, no. 11, pp. 2390–2400,
Nov. 2006.
[9] Jonathan Macdonald, Victoria Porter, and Deirdre McNamara, “Negative
capsule endoscopy in patients with obscure gi bleeding predicts low
rebleeding rates,” GASTROINTESTINAL ENDOSCOPY, vol. 68, no. 6,
pp. 1122–1127, 2008.
[10] Larry H. Lai, “Obscure gi bleeding: is capsule endoscopy sufficient?,”
GASTROINTESTINAL ENDOSCOPY, vol. 68, no. 6, pp. 1128–1130,
2008.
[11] OLYMPUS [Online], Available:http://www.olympus-europa.com.
[12] Rastislav Lukac and Konstantinos N. Plataniotis, “Color filter arrays
: Design and performance analysis,” IEEE Transactions on Consumer
Electronics, vol. 51, no. 4, Nov. 2005.
A Wireless Narrow-Band Imaging Chip for Capsule
Endoscope
Lan-Rong Dung and Yin-Yi Wu
Department of Electrical Engineering
National Chiao Tung University
Hsinchu, Taiwan
Email: lennon@faculty.nctu.edu.tw
Ping-Kuo Weng
Chung-Shan Institute of Science Technology
Tao-Yuan, Taiwan
Abstract— NBI endoscope has been shown to be a superior
diagnostic tool for early stage lesion detection, equally wireless
capsule endoscope has been proven a effective means of gastroin-
testinal tract diagnosis. In this paper, we present the first narrow
band imaging wireless capsule endoscope. The dedicated dual-
mode COMS sensor can offer both white light and narrow band
images. Implementation results show that the designated 512- by-
512 CMOS sensor consumes only 2mA at 3V power supply. The
average current of the NBI capsule with a 8Mbps RF transmitter
is nearly 7 mA that can work for 6 to 8 hours with two 1.5V
80mA button batteries while the frame rate is 2 fps.
I. INTRODUCTION
This paper presents a dual-mode wireless capsule endoscope
that features both visible and narrow band image acquisition.
Early detection and treatment of digestive tract cancers has
become an important work. Although numerous gastrointesti-
nal endoscopes pass through the entire alimentary canal, it
is still difficulty to detect an early cancer during the routine
endoscopic examination. Because the lesions in the early stage
are relatively asymptomatic, effective screening methods to
detect an earlier lesion would be of the great benefit to such
patients. Early pathological change of these lesions often has
significant increment in microvessel density. This results mor-
phologic changes of microvessels in the superficial neoplasm.
Capillary patterns beneath the epithelium in these regions
will also be different from surrounding area. Utilizing this
property, chromo-endoscopy, magnify endoscopy, endoscopic
ultrasonography and narrow band imaging (NBI) endoscopy
have been developed. Chromoendoscopy uses a biocompatible
dye to enhance the image of capillary patterns and it is
very difficulty to achieve complete and uniform coating of
dyes. Furthermore, the maintenance of chromoendoscopy is
hard. Magnify endoscopy also examine the structure pattern
of mucosa by using dye to improve image contrast. This
method still has some problems such as difficulty to acquire
proper field of vision and operate. To overcome the draw-
backs of traditional endoscope, K. Gono et al. proposed the
narrow band technology, i.e., NBI [1], [2], [3]. NBI is an
innovative optical technology using the center wavelengths
of 415nm and 540nm to clearly visualize the microvascular
structure of the organ surface. K. Gono provides images of
the backside mucosa of human tongue exposed to different
center wavelengths of narrow band light. The vessel images
change greatly according to the center wavelength. Many
investigations have been reported on the diagnosis of head and
neck region, bronchus, esophagus, stomach, colon and early
gastric cancer [4]-[5] by using NBI technology on the basis
of the vascular irregularities. Nowadays, endoscopy combine
NBI has been popularly used because of its less invasive, and
capable of early stage lesion detection. However, there is no
NBI technology for the wireless capsule endoscope (CE) [6]
[7] [8]. As mentioned in [9], wireless capsule endoscope is a
highly effective means of examining the entire small bowel.
Its clinical use as a diagnostic tool in patients with obscure GI
bleeding (OGIB) has been proven in several prospective trials.
Nevertheless, the reliability of CE is challenged by [10] in the
investigation of OGIB. We believe that NBI capsule endoscope
could be a new and reliable diagnostic of early gastrointestinal
disease, such as obscure GI bleeding.
In this paper, we proposed a NBI capsule endoscope that
is composed of a narrow band LED light source, a 512-by-
512 dual-mode CMOS image sensor, and a 8 Mbits/sec RF
transmitter. The image sensor associates with the light source
can acquire both visible and narrow band images during the
period of treatment. The presented dual-mode image sensor
acquires one narrow band image and one visible image per
second under inter illumination mode. In intra illumination
mode, visible and narrow band image are both acquired at a
frame rate of 2 fps. The sensor consumes only 2 mA at 3V
power supply. Implementation results shows the NBI capsule
endoscope can work about 6∼8 hour at 2 fps with two button
batteries.
II. NARROW BAND IMAGE AND SYSTEM ARCHITECTURE
According to basic physical principles, the penetration depth
of light is dependent on its wavelength. The longer the
wavelength, the deeper the penetration depth it can pierce.
Olympus lunched the first endoscope system ”EVIS LUCERA
SPECTRUM” that offers narrow band imaging [11]. As illus-
trated in Fig. 2, the system has a xenon lamp and rotation
disk with three NBI filters instead of 3 RGB optical filters for
narrow band image. The spectrum of the three NBI filters are
415±30nm, 445±30nm, and 500±30nm. A charged-coupled
device is then used to capture the 3 band images. After that, the
NBI image is synthesized by video processor using the three
Inter-illumination Mode                                                 White 
Intra-illumination Mode
white B1 G1
R1 Y
B2
N2
Narrow-BW NBI
Broad-BW NBI
G1 B2 N2  => NBI 
1 1 1 => WLI 
blue
G B Rframe n+1 
frame n
white
blue
B1 G1
R1 N1frame n 
G1 B1 N1 => NBI 
G1 N1 R1 => WLI 
WLIdemosaic
light
NB
light
Color 
NBI
combine
NBIdemosaic
WLI
White demosaic
light
NB
light
Color 
NBI
combine
NBI
Fig. 6. Sensor Illumination Mode
information of the image scene [12]. To obtain NBI and
WLI on the same sensor, a dedicated color filter array is
presented as depicted in Fig. 6. The color filter array acquires
the narrow-band image on a quincunx grid (B filter and clear
pixel N) and the R and G images on rectangular grids. When
blue LEDs light up, the broad-bandwidth NBI is measured
by clear pixel (≃445nm) while the narrow-bandwidth NBI
is measured by B filter (≃415nm). The G filters (≃540nm)
can provide green color for WLI and NBI when white LEDs
turn on. The CMOS sensor can operate in two different
illumination modes. In inter-illumination mode, we can
acquire R, G, B, and Y (clear pixel) images when white
LEDs turn on. In next frame, the blue LEDs turn on, B and
clear pixels (N) are obtained for narrowband image. The
white and blue LEDs are taking turn to light up frame by
frame. Accordingly, WLI and NBI images are acquired using
RGB and BN respectively. To produce a full-color image,
the missing components can be estimated from available
neighboring components using CFA demosaicking. In intra-
illumination mode, the white and blue LEDs are actuated
at the same frame but the clear pixel is disabled while the
white LEDs light up. Hence, the clear pixels contain only
narrow-band information. By utilizing this arrangement, NBI
image can be established using GBN.
IV. IMPLEMENTATION AND EXPERIMENT RESULTS
The dual-mode CMOS image sensor is fabricated in 0.25um
single-poly four-metal CMOS technology with an area of
3.7mm x 3.95mm. It consumes 2mA at 2 frame/s with 3V
power supply while the ADC and Video Amplifier waste
0.5mA individually. Fig. 7 shows a photo-micrograph of the
image sensor. The timing generator, P/S, randomizer, and auto
expose control circuit are all integrated into digital core. The
specifications is summarized in Table I. Fig. 8 are captured
images of live pig’s duodenum using the dedicated CMOS
image sensor at 2 f/s in inter-illumination mode. In this
experiment, the image data stream is transmitted by conduction
line and been demodulated to reconstruct the raw image. After
CFA demosaicking, the color NBI images are synthesized by
assigning previous G image to red plane and N and B images
to either blue or green plane respectively. This demonstrates
that the designed CMOS sensor provides white light image
and enhanced contrast of micro vessel pattern.
A wireless NBI capsule endoscope system that has been
described in section II is developed. Due to limited print circuit
board area, the sensor and RFIC are bound to PCB by chip on
board (COB) technology. Other on-board components such as
resistors and capacitors are used with SMD package. As shown
in Fig. 9, the narrow band LED module, wide FOV lens, dual
mode NBI CMOS sensor, batteries, RF transmitter, magnetic
switch and antenna are all capsuled into a pill. The RF receiver
dissipates less than 0.5A@5V while the sensitivity is lower
than -80 dBm. The data recorder can store more than 4 GB
and meantime the image viewer displays the received images
through USB port. The average current of the capsule is
nearly 7∼8 mA when the RF transmitter works at 8Mbps and
the sensor works at 2fps. With two 1.5V 80mA silver oxide
button batteries, experiments show that the capsule continuous
working for 6∼8 hours.
V. CONCLUSION
In this paper, a novel narrow band imaging capsule en-
doscope is presented. Compared with standard wireless cap-
sule endoscope, the dedicated dual-mode 512-by-512 COMS
sensor in the NBI capsule can offer both WLI and NBI
images by comprehending the optical properties of tissue and
controlling the illumination wavelength and procedure. For
