two motion clips and could automatically select the 
transition key frames. Animators can use this 
approach to produce a new move sequence. The main 
contribution of our study is that we directly utilize 
the amount of makers in motion capture equipment as 
the clusters in clustering method to avoid the 
drawback of assigning the thresholds of fuzzy 
clusters by hand. In order to simplify and accelerate 
the efficiency of motion blending, each motion clip 
is selected only one frame, as the key frame, to 
represent all time frames of that motion. This key 
frame retains the important characteristic of that 
motion clip.  We use the characteristics of k-mean 
clustering algorithm to find out the key frame of 
each motion clip. After that, we do the motion 
blending by linear interpolation between the two 
representational key frames. We also use the 4 stages 
of linear interpolation to replace the time wrapping 
process. To evaluate the effectiveness of the 
proposed method, we implemented a series of action 
mixed experiments. The results show that our method 
is effective in smoothly blending between two motion 
sequences. 
英文關鍵詞： Motion Capture System, Motion Blending 
 
 1
行政院國家科學委員會專題研究計畫成果報告 
動作混合與動作合成之研究 
A Generative Model for Motion Blending and Motion Synthesis 
  
計畫編號：NSC 99-2221-E-262-025- 
執行期限：99 年 08 月 01 日至 100 年 07 月 31 日 
計畫主持人：王榮英 副教授  龍華科技大學遊戲系 
計畫參與人員： 李瑋翰       龍華科技大學電子所 
李冠賢       龍華科技大學電子所 
 
 
一、中文摘要 
 
許多數位內容之應用需要自然流暢、
擬真與高質感的角色動畫。如：電影和電
玩遊戲等數位娛樂，更是倚賴於虛擬的世
界中呈現各式各樣生動的角色擬真。然欲
大量的產出生動的角色動畫，是即費時費
力又昂貴的。然隨著數位內容產業之迅速
發展，動作擷取系統 (motion capture)技術
之成熟，使得利用它來直接擷取真實人類
動作的資料，越來越普遍，且已累積了相
當多的各種動作之動作資料庫。然而我們
如何重複使用這些已存在的各種動作並將
其混合或合成，使其產生無縫的接軌且自
然的動畫呢？ 
本計畫提出一個能快速及平順的混合
各種動作之動作混合系統，使用者可以根
據動畫的需求，直接將兩種或兩種以上的
動作做混合，以達到所需要的效果。主要
的貢獻在我們直接以動態擷取設備之光標
點數目做為聚類演算法之類別數目，明確
的解決了以往以聚類方法進行動作混合之
研究時，需任意給定一門檻值而產生類別
數之缺點。另一方面，為簡化與加快動作
混合的效率，我們利用聚類演算法之特
性，分別尋找出欲混合之兩個動作中，據
起承轉合之代表性動作之關鍵影格，以其
進行線性內插獲得兩動作間之混合。至於
時間軸扭曲(time warpping)方面，我們則以
4 段的內插法來取代。為驗證本研究所提
出之動作混合方法，我們以一系列的動作
混合實作驗證之，結果顯示我們所提的方
法可快速及平順的完成兩相異動間動作間
之動作混合。 
 
關鍵詞：人類運動姿勢辨識、動作捕捉系
統、動作混合 
 
Abstract 
Many digital content applications 
require realistic, high-quality character 
animation. Applications as diverse as 
simulation, movies, and video games depend 
upon natural-looking motion to increase the 
believability of virtual worlds. It is 
time-consuming and expensive to produce 
motion data in large quantities. Motion 
capture provides a cost effective solution to 
realism as life-like motion is easily acquired 
and large libraries of motion are available 
for use. However, to provide realistic results, 
multiple sequences need to be blended 
together resulting in a seamless and life-like 
animation. Furthermore, recorded animation 
lacks the variability of natural motion and 
repeating a motion can look false due to its 
學動畫，更為自然與擬真。但若欲重覆的
利用已存在之動作資料合成出自然流暢的
動畫時，便需進行所謂的動作混合（Motion 
Blending ），藉由已存在的動作片段
（Motion Clip），合成出所需之新動作。
在做動作混合時，一般的做法為把要混合
的兩段動作，經過權重的分配後，再經由
移動視窗找出最適當的動作混合片段，而
後進行動作的合成。而為達到順暢地連接
兩段動作資料之目的，常需透過所謂時間
軸扭曲(time warping)的技術[12][13]，將兩
段欲混合之動作做對齊之工作，如前一個
動作為左腳向前，而欲混合的動作其下一
個影格為右腳向前，若未進行時間軸扭
曲，則串接兩動作後在播放時將產生不連
續的感覺。 
動作分割 
實際動作代表性關鍵 
影格之選取 
動作混合 
建立三維動作資料庫 
 
圖一 動作混合系統架構圖 
 
建立三維動作資料庫 
我們使用由 12 台攝影機所建構的被
動式光學多媒體動態擷取系統，如圖二所
示，其最高攝影速度可達每秒 500 影格
(frames)。透過分佈於人體上之 41 個光標
點，我們以每秒 120 影格之擷取速度，建
立本研究所需之人類各種運動之三維動作
資料庫。本研究預先定義的 41 個人體光標
點，其分布於人體之正面配置圖，如圖三
所示，背面配置圖，如圖四所示。由於影
像資料中所取得之各點的三維座標，會受
到攝影機校正的誤差、光標點不精確等因
素的影響，因此還必須經過軟體的修正，
由動作中間的關鍵影格配合人體的各光標
點活動的範圍，可以從影格前後估算出被
遮蔽住而不見的動作。於本研究中我們主
要以擷取人類各種原地運動之動作為主。
為擷取到較具代表性之高品質之動作，以
提供動畫、遊戲與研究等使用。我們要求
每個單一的動作(如原地跑步)皆需重覆的
做 30 秒，而後各去除初始與結束之前後各
5 秒，已避免起始與收尾時動作之不確定
性。 
本計畫有別於一般動作混合之方法，
以探討如何快速及平順的混合原地運動之
各種動作混合為主。主要的貢獻在我們直
接以動態擷取設備之光標點數目為聚類演
算法之類別數目，明確的解決了以往以聚
類方法進行動作混合之研究時[8][9]，需任
意給定一門檻值而產生類別數之缺點。為
加快我們混合的時間效率，我們利用聚類
演算法之特性，分別尋找出欲混合之兩個
動作中，據起承轉合之代表性動作之關鍵
影格，以其進行線性內插獲得兩動作間之
混合。至於時間軸扭曲方面，我們則以 4
段的內插法來取代。由實驗證明我們所提
出之方法，能有效與順暢的完成兩相異動
作間之動作混合。 
而本研究所提出的人體動作混合方法其系
統架構圖，如圖一所示。可分為以下幾個
主要的步驟：(1)建立三維動作資料庫 (2)
動作分割(Motion Segmentation) (3)實際動
作代表性關鍵影格之選取 (4)動作混合。
以下將分別敘述之。 
 
 3
然此動作之代表性關鍵影格並非構成
真實動作之影格，為達擬真與自然的混合
效果，故我們進一步的將上述影格與構成
該動作片段之所有影格逐一進行比對，利
用最近距離法(此處採歐幾里得距離計算
之)，找出最接近 k-mean 演算法尋獲結果
之真實動作之代表性關鍵影格，為我們混
合兩動作時之起始端點之代表性關鍵影
格。故當兩欲混合動作之真實動作起始端
點代表性關鍵影格選取完成後，我們便可
開始進行兩動作之混合。  
 
圖五 大字跳動作 
 
 
 
動作混合 
於動作混合之實作部分，一般的做法
為把要混合的兩段動作，一端稱為來源動
作端(S)，另一端稱為目標動作端(T)。而兩
端間之動作混合，最常使用的為線性內插
法。做法為以 S 端及 T 端兩端之權重值作
調節轉換，S 端之權重值逐漸由 1.0 下降
至 0.0，而 T 端之權重值逐漸由 0.0 上升至
1.0，如此可完成內差之工作，如圖七所
示。對大多數的動作與動作間混合，此簡
單且未考慮任何物理的方法，即可產生不
錯的結果[14]。本研究為簡化與加速系統
之混合效率將採用此法。 
圖六 重複動作分割成 10 組單次的動作示
意圖 
 
實際動作代表性關鍵影格之選取 
因動作混合之目的為流暢與無縫的接
合兩不同動作，故如何由構成某動作之許
多影格中，自動的找到具有起承轉合之某
一個單一影格，來代表我們整段動作之關
鍵影格，使其能夠快速與平滑的與另一動
作進行混合，且能順暢的和原動作之循環
接軌，為本研究希望解決的主要問題。於
此我們提出以 k-mean 聚類的演算法，自動
找出某實際動作代表性關鍵影格之方法來
解決上述問題。詳細的實做方法描述如下。 
假設我們已知兩動作片段 M1(t) 和
M2(t)，而混合完成的動作為 M＇(t)，則兩
動作間的轉換可以利用(1)式之線性內插
方法來達成，其中 t 為時間，而 w(t) 為內
插權重。 
當上一個步驟完成動作之分割後，為
提昇處理之效率與標準化程序，我們挑選
時間最短的單次動作片段(motion clips)，
做為實際動作代表性關鍵影格之選取片
段，此片斷乃由許多單張的影格所組成。
我們利用 k-mean 演算法，且令聚類之類別
數等於我們動作擷取系統之光標點數(41
個)，即：我們找出所有 41 個光標點之每
個光標點隨時間運動軌跡之重心值，此找
到之 41 個光標點之重心值，即為此動作之
代表性關鍵影格。 
)())(1()()()(M 21 tMtwtMtwt    (1) 
由於在上一個步驟中已分別找到代表
兩個動作其真實動作之代表性關鍵影格，
故於此我們可以開始進行動作之混合。此
部分依序需完成四個部分的動作混合。為
方便說明起見，我們分別以中間段動作混
合、前段動作混合與後段動作混合表示
之。為提高處理的速度免除時間對齊等操
 5
於此選取我們資料庫中的一些動作單
元做兩相異之動作混合之實作，包括原地
走路接原地跑步、原地走路接原地跳、原
地打棒球接原地踢足球、原地跳接原地大
字跳、原地跳接原地跳繩和原地轉圈揮手
接原地往上拍手共六種組合。而每一種單
一動作都有十組以上的循環樣本，皆 20
秒長度。經本研究所提之混合方法實作
後，結果如圖十至圖十五所示。因局限於
圖文的表示方式，於此所有的動作混合結
果，僅以相對應的影格來呈現。上述之混
合結果亦歡迎以 e-mail 方式向作者索取
影片檔，作更進一步的觀察與驗證。由混
合結果之影片檔，顯示我們所提的方法可
快速及平順的完成兩相異動間動作間之動
作混合。且利用 4 段式的快速內插法，可
有效的免除進行較費時與複雜的時間軸扭
曲之程序。 
線性內插 
(中間段動作) 
中間段動作 
線性內插 
(前段加中間段動作) 
線性內插 
(後段加中間段動)作)
前段動作 後段動作 
線性內插 
(前段加後段動作) 
動作混合完成 
選擇欲混合之動作 
 
圖九 動作混合流程圖 
  
  圖十 原地走路接原地跑步 圖十二 原地打棒球接原地踢足球 
  
  
圖十三 原地跳接原地大字跳 圖十一 原地走路接原地跳 
  
 7
 9
[6]. Arikan, O. and Forsyth, D. A.  “Interactive 
motion generation from examples”, In 
SIGGRAPH 2002, ACM Press, New York, NY, 
USA,     483–490(2002). 
[7]. Molina-Tanco, L. and Hilton, A. “Realistic 
synthesis of novel human movements from a 
database of motion capture examples”, In 
Workshop on Human Motion, 137–142(2000).  
[8]. Xiangbin, Z. “A novel motion blending 
approach based on fuzzy clustering”,  
Proceedings of the 9th Pacific Rim 
international conference on Artificial 
intelligence, (2006). 
[9]. Chen, Z and Zhu, X. “A Motion Blending 
Approach Based on Unsupervised Clustering”, 
In Proceedings of 16th International 
Conference on Artificial Reality and 
Telexistence (ICAT), (2006). 
[10]. Li, Y., Wang, T. and Shum, H. Y. “Motion 
texture: a two-level statistical model for 
character motion synthesis”, In 29th annual 
conference on Computer graphics and 
interactive techniques, ACM Press, 
465–472(2002).  
[11]. Bruderlin, A. and Williams, L. “Motion signal 
processing”, In Proceedings of ACM 
SIGGRAPH 1995, ACM Press, 97–104(1995).  
[12]. Heck, R., Kovar, L. and Gleicher, M. “Splicing 
Upper-Body Actions with Locomotion”, 
Computer Graphics Forum, Volume 25, Issue 
3, 459-466 (2006). 
[13]. Keogh, E. “Exact indexing of dynamic time 
warping”, In VLDB 2002, Proceedings of 28th 
International Conference on Very Large Data 
Bases, 406–417(2002). 
[14]. Safonova, A. and Hodgins, J. K. “Analyzing 
the physical correctness of interpolated human 
motion”, In Proceedings of the 2005 
Symposium on Computer animation, ACM 
Press, New York, NY, USA, 171-180(2005). 
 11
本次會議邀請來大陸，香港，臺灣，美國，法國，英國，加拿大，韓國，日本，
新加坡，馬來西亞，澳大利亞，巴基斯坦，印度，泰國等近15個國家的200名專家學
者與會。與會期間部分與會者對於本次IITA 2010 的用心給予相當正面的評價。深深
感受本次會議的嚴肅、認真的態度。 
整體說來，此次會議的內容既充實，而且高水準。與會的專家都準備充分，而且
報告的內容也都切中主題。這次的國際會議，與會專家們研究的態度，報告時的台風，
都讓我學習良多，希望日後還有機會再參與同樣高水準的國際會議，並且學習到更多
的知識和經驗。 
 
三、 攜回物品 
 
本人此次攜回 IITA 2010論文集一份及紀念背包一個。 
 
者與會。與會期間部分與會者對於本次IITA 2010 的用心給予相當正面的評價。深深
感受本次會議的嚴肅、認真的態度。 
整體說來，此次會議的內容既充實，而且高水準。與會的專家都準備充分，而且
報告的內容也都切中主題。這次的國際會議，與會專家們研究的態度，報告時的台風，
都讓我學習良多，希望日後還有機會再參與同樣高水準的國際會議，並且學習到更多
的知識和經驗。 
 
三、 攜回物品 
 
本人此次攜回 IITA 2010論文集一份及紀念背包一個。 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：王榮英 計畫編號：99-2221-E-262-025- 
計畫名稱：動作混合與動作合成之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際
已達成數)
本計畫
實際貢
獻百分
比 
單位 
備註（質化說明：如
數 個 計 畫 共 同 成
果、成果列為該期刊
之封面故事...等）
期刊論文 1 1 100% 
Human Motion Blending 
by Using the Markers 
of Motion Capture as 
Clusters,’  
Jung-Ying Wang, 
Tsung-Han Tu, 
Fang-Cheng Hsu, 
Journal of Computer 
Science and 
Application, 6, 
105-118, 2010. 
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
1.  ’’動態路徑搜尋
演算法－應用於遊戲人
工 智 慧 上 之 研
究 ’’，王榮英，林雍
斌，2011 數位生活科技
研討會，台灣，雲林 ，
2011年 7月 7日~ 8日。
2. ’’電子與設計類
背景學生入學後專業科
目學業成就之比較-以
多媒體與遊戲系不分組
教學為探討標的’’，
王榮英，李冠賢，2011
資訊技術應用及管理研
討會，台灣，高雄市，
2011 年 6 月 25 日。  
3.  ’’考慮個別化情
緒之群體行為模擬－使
用支持向量機’’，王
榮英，李瑋翰， 2011 第
六屆智慧生活科技研討
會 (ILT2011))，台灣，
台中，2011年 6月 3日。
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
國內 
技術移轉 件數 0 0 100% 件  
博士生 0 0 100%  
博士後研究員 0 0 100%  
（外國籍） 
專任助理 0 0 100%  
其他成果 
(無法以量化表達之
成果如辦理學術活
動、獲得獎項、重要
國際合作、研究成果
國際影響力及其他協
助產業技術發展之具
體效益事項等，請以
文字敘述填列。) 
本研究提出一個能快速及平順的混合各種動作之動作混合系統，使用者可以根據
動畫的需求，直接將兩種或兩種以上的動作做混合，以達到所需要的效果。主要
的貢獻在我們直接以動態擷取設備之光標點數目做為聚類演算法之類別數目，明
確的解決了以往以聚類方法進行動作混合之研究時，需任意給定一門檻值而產生
類別數之缺點。可提供遊戲及動畫之開發使用。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
