 2
These architectures can support 
high-performance computing by reducing 
the performance gap between the processor 
and the memory. Although these 
architectures have been developed during 
these years, many researches still focused on 
hardware development bus less mentioned 
about how to generate suitable softwares for 
these platforms. In the past years, we 
presented and implemented several 
parallelization and scheduling mechanisms 
to improve performance or reduce power 
consumption of the transformed applications 
targeted on Processor-in-Memory platforms. 
Based on the results we have done, we plan 
using five students and two years to expand 
our original prototype. In this project, we 
will design a novel automatic parallelizing 
system, Octans, to fit the capability 
difference between the host and memory 
processors. 
To make our draft Octans become a 
complete system, extending from the basic 
analysis stages that we develop in last NSC 
project, we will focus on two major topics. 
The first is to design two scheduling 
mechanisms, CMS (Couple-Matching 
Scheduling) and SFPAS (Speed-First 
Power-Aware Scheduling), for the purpose 
of high performance and low power 
consumption. The second is to propose 
several optimization mechanisms for 
Processor-in-Memory architectures, 
including Loop Splitting Refinement, 
Processor-in-Memory Blocking, and 
Processor-in-Memory Operation 
Recognition. Then we will integrate the 
above schemes into the Octans system such 
that the processors in each level can achieve 
their best performance and power 
consumption. 
Finally, we will evaluate our new 
Octans system using the standard 
benchmarks such as NAS, SPEC2000 and 
Perfect Benchmark to obtain the real 
performance results for the 
Processor-in-Memory platform. The 
execution of this project not only can 
enhance the practicability and 
popularization of the Processor-in-Memory 
but also can offer a reference for other 
researchers who intend to develop new 
parallelizing and optimization strategies for 
MPSoC (Multi-Processor System-on-a-Chip) 
architectures. 
 
Keywords: Processor-in-Memory, Octans, 
Couple-Matching Scheduling, Speed-First 
Power-Aware Scheduling, 
System-on-a-Chip(SoC). 
 
二、緣由與目的 
本 實 驗 室 先 前 曾 針 對
Processor-in-Memory 架構提出了一個新的
程式平行化系統雛形，稱為 Octans，並且
發展了一些演算法與分析轉換機制
[1][2][4][5]。在去年的計劃發展下的基礎
之上，我們將針對此一新的分析轉換最佳
化系統，發展兩項主要的排程機制與數個
最佳化模組。有別於以往使用迴圈輪次
(Loop Iteration)為基本分析單位，Octans
使用陳述(Statement)為基本分析單位，它
可分析原始程式碼(Source Codes)，透過陳
述分割(Statement Splitting)將程式切分為
許多區塊，並依其相依關係，產生一對應
之權重分割相依圖 (Weighted Partition 
Dependence Graph，WPG)，再決定每一區
塊的權重值。在去年的計劃實現上述的程
式基本單位分析與分割之後，今年我們設
計所需之程式效能最佳化排程與耗能最佳
化排程，並嘗試開發數種最佳化技術，整
合至 Octans 系統，使之具有更強大的功
能，更有效的分析轉換 Source Program。 
在效能最佳化排程機制中，我們計劃
發 展 一 排 程 技 術 ， 稱 為 CMS 
(Couple-Matching Scheduling)，此技術可提
高先前所發展之平行排程機制，依不同的
處理器能力與程式行為，選擇最好的工
作，以增加其平行化分析之能力，並針對
Processor-in-Memory 架構不同於傳統計算
機結構之特點，予以特殊的最佳化轉換。 
在低耗能最佳化部份，我們計劃發展
一低耗能最佳化技巧，SFPAS (Speed-First 
Power-Aware Scheduling)，根據使用者不
 4
行，而每一配對區塊（Couple Blocks）依
序執行。在同一個配對區塊（Couple 
Blocks）中的兩個區塊(Block)之選擇依
據，不僅分別適合主處理器(P.Host)與記憶
體處理器 (P.Mem)執行，考慮主處理器
(P.Host)與記憶體處理器(P.Mem)執行所花
的時間，達到很好的負載平衡（Load 
Balance）。詳細內容請參閱[2]。 
在 SFPAS (Speed-First Power-Aware 
Scheduling)模組中，其計算核心為本計劃
今年主要研發之低耗能排程演算法。首先
定義 Speedup =(效能改善前的執行時
間)/(效能改善後的執行時間)，若小於 1 表
示效能改善的效果不佳，越大於 1 的數值
則表示效能改善效果越好，因此(Speedup
－1)這個數值表示執行速度改善量。
SFPAS (Speed-First Power-Aware 
Scheduling)允許使用者減少執行速度改善
量，容許比較長的執時間，把工作分配給
執行時間較長，但更省電的處理器來執行。 
在此選項中，使用者必須先輸入一個
百分比參數值，它代表著使用者能夠容許
執行速度改善量(Speedup－1)減少的量，
如使用者輸入的百分比參數值為 30%，則
新的 Speedup 為 1＋(Speedup－1)* (1－
30%)，而 (改善前的執行時間 )/(新的
Speedup)表示使用者想得到之(改善後的
執行時間)，本演算法會在不可低於新的
Speedup 限制下排程並且僅可能的降低耗
能。 
依照延遲權重值，將同一波前的區塊
分為適合 P.Host 執行或 P.Mem 執行的兩
個部分，由大至小的排序，並且計算 P.Host
執行此波前所有區塊所需的時間。再來如
同 OCTANS 中依照效能為考量的排程方
法排程一次，累加求得 P.Host 與 P.Mem
的執行時間，最大者就是本波執行所需的
時間。由以二個資訊，我們可計算出程式
的 Speedup，配合使用者輸入的百分比參
數值，計算出每一波，使用者容許的最大
執行的時間，在演算中我們稱它為
Deadline。將每一波前中的區塊依照他們
的能量權重值，分成適合 P.Host 和 P.Mem
執行的二個部份，由大到小排序：先由適
合 P.Mem 執行的部份排定一個區塊給
P.Mem，然後檢查 P.Mem 的延遲權重值是
否小於 Deadline，如果是的話則此區塊可
被排入 P.Mem 執行，再檢查 P.Mem 的能
量權重值是否大於 P.Host 的能量權重值，
若大於則將 Token 設定為 P.Host，反之
Token 設定為 P.Mem 。若 P.Mem 的延遲
權重值大於 Deadline，則 Token 設定為定
為 P.Host，換邊排程。 
Token 設定為 P.Host，代表由適合
P.Host 執行的部份排定一個區塊給
P.Host，方法同上所述，直到所有區塊皆
排完為止。詳細內容請參閱演算法一。 
 
最後我們在 SGI Origin 200 上安裝了
SGI IRIX 6.5 MIPS Pro Fortran 77、C/C++ 
相關套件並以 SPEC95、Perfect Benchmark
等測試程式，並設計各項實驗參數，仔細
驗證 Octans 系統與 SFPAS 模組在不同情
況下之正確性。真實測試程式之實驗數據
請見表一與圖二。在 Octans 系統與 SFPAS
機制的排程下，我們可以獲得將近 30.84%
的耗能減少與 2.055 倍之效能提升，足見
本系統與排程方法的功效。 
 
四、計劃結果自評 
 
在今年的計劃裡，我們發展 Octans 系
統 與 SFPAS 排 程 演 算 法 。 在
Processor-in-Memory 模擬器上，驗證
SFPAS 演算法的功能。在實際撰寫程式實
作 SFPAS、測試模組間的資料傳遞、與實
驗模擬系統安裝時，我們學到許多原本我
們所忽略到的知識；相關參與這項研究計
劃的學生們也能夠藉此學習研究的方法與
作學問的態度。本計劃的初期研究成果，
已發表在國際會議[1] [2]。 
 
五、參考文獻：  
[1][2][3]為本國科會計畫補助之研究
成果。 
 
 6
In Proceedings of the 25th Annual 
International Symposium on Computer 
Architecture, (1998), pp. 192-203. 
[18] Patterson, D., Anderson, T., Cardwell, N., 
Fromm, R., Keeton, K., Kozyrakis, C., 
Tomas, R., and Yelick, K.: A Case for 
Intelligent DRAM. IEEE Micro, Mar./Apr., 
(1997), pp. 33-44. 
[19] Press, W. H., Teukolsky, S. A., Vetterling, 
W. T., and Flannery, B. P.: Numerical 
Recipes in Fortran 77. Cambridge 
University Press, (1992). 
[20] Snip, A. K., Elliott, D.G., Margala, M., 
Durdle, N. G.: Using Computational RAM 
for Volume Rendering. In Proceedings of 
13th Annual IEEE International Conference 
on ASIC/SOC, (2000), pp. 253 –257 
[21] Swanson, S., Michelson, K., Schwerin, A. 
and Oskin, M.: WaveScalar. MICRO-36, 
Dec.  (2003). 
[22] Veenstra, J., and Fowler, R.: MINT: A 
Front End for Efficient Simulation of 
Shared-Memory Multiprocessors. In 
Proceedings of MAS-COTS’94, Jan. (1994), 
201-207 
[23] Wang, K. Y.: Precise Compile-Time 
Performance Prediction for 
Superscalar-Based Computers, In 
Proceedings of ACM SIGPLAN '94 
Conference on Programming Language 
Design and Implementation, (1994), pp. 
73-84Zhou, Y., Wang, L., Clark, D., Li, K.: 
Thread Scheduling for Out-of-Core 
Applications with Memory Server on 
Multicomputers; In Proceedings of the Sixth 
Workshop on I/O in Parallel and Distributed 
Systems, May (1999). 
 8
end if 
if  ph_d_wei(j) ≥ pm_d_wei(j) 
Token = PM 
else 
Token = PH 
end if 
end while 
end for 
/* Calculate each wavefront deadline */ 
Origin_weight = 0 
Optimize_weight = 0 
for j = 1 to max_wf 
Origin_weight = Origin_weight + PHDW_origin(j) 
Optimize_weight = Optimize_weight + max(ph_d_wei(j), pm_d_wei(j)) 
end for 
speedup = Origin_weight/ Optimize_weight 
new_speedup = (speedupu – 1) * (1 – Percent) + 1 
for j = 1 to max_wf 
  Deadline(j) = PHDW_origin(j)/ new_speedup 
end for 
/* Lower power scheduling */ 
for j=1 to max_wf 
wf_tmp = ph_tmp= pm_tmp ={φ} 
store all of bi whose Oi = j  in wf_tmp 
h = m = 0 
for each  bi∈ wf_tmp 
if  PHEW(bi ) - PMEW(bi) ≤ 0 
h = h + 1 
Store bi in ph_tmp (h) 
else 
m = m + 1 
Store bi in pm_tmp (m) 
end if 
Sort ph_tmp (h) in decreasing order by PHEW(bi )  
Sort pm_tmp (m) in decreasing order by PMEW(bi)  
end for 
end for 
Token = PM 
ph_sch = pm_sch = {φ} 
p = q = ph_e_wei = pm_e_wei = ph_d_wei(j) = pm_d_wei(j) =0 
while p ≤ h  OR  q ≤ m 
if  Token = PH  
if  p < h      /* ph_tmp is not empty */ 
p = p + 1 
ph_d_wei(j) = ph_d_wei(j) + PHDW ( ph_tmp(p)) 
if  ph_d_wei(j) ≤ Deadline(j) 
ph_sch = ph_sch + {ph_tmp(p)} 
ph_e_wei = ph_e_wei + PHEW ( ph_tmp(p)) 
if  ph_e_wei ≥ pm_e_wei 
Token = PM 
else 
Token = PH 
end if 
else 
Token = PM 
ph_d_wei(j) = ph_d_wei(j) - PHDW ( ph_tmp(p)) 
p = p - 1  
endif 
else   /* ph_tmp is empty, then use pm_tmp to achieve load-balance */ 
q = q +1 
ph_d_wei(j) = ph_d_wei(j) + PHDW ( pm_tmp(q)) 
 10
 
 
