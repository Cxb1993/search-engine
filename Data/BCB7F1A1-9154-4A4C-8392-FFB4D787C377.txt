 
(三)報告內容：包括前言、研究目的、文獻探討、研究方法、結果與討論（含
結論與建議）等。 
 
3.1前言 
在此計畫中，為了在擁擠場景中偵測個別的目標物以及分析群體移動所產生
的軌跡資訊，我們提出兩個方法分別在擁擠環境中偵測、追蹤個別的目標物，以
及將群體運動軌跡進行偵測分類。第一個子系統所提出的方法是以 corner 特徵
點為基礎，發展由粗糙至細緻的獨立目標物切割演算法。在這個方法中，首先利
用 C-Means 演算法將特徵點做粗略的分群，接著透過時空最小生成樹
(spatial-temporal shortest spanning tree)在每一個移動分群內切割出更精確的個體，
最後運用 corner 特徵點繼承的概念來追蹤所有移動個體目標物。第二個子系統
所提出的方法為應用 longest common subsequences 演算法自動估算人群運動軌
跡間之相似性，逐一地被分類到最適當的類別中。所有特徵點軌跡相似性量測是
透過空間及時間上的相似性做測量。 
 
3.2研究目的及文獻探討 
在傳統 blob-based 物件偵測系統有一些提取移動中目標的方法，例如:背景
相減法 (background subtraction )[2]，光流法(optical flow )[3, 9-10]，畫面差異分析
法(frame difference analyses)[4]和編碼模型法(codebook model )[5]。在[2]，用背景
相減法(background subtraction )在區域中可以準確的抓取移動中的目標物，但是
它對於照明的變化和不斷變化的動態背景過於敏感。在[3, 9-10]，光流法(optical 
flow )是用於獨立追蹤各別之目標，但是其計算量過於龐大。應用畫面差異分析[4]
可以適應照明的變化，但當目標移動緩慢時，目標物的偵測會不完整。在[5]，編
碼法(codebook model )可以克服背景改變和照明變化的問題，但這個方法在擁擠
的人群中要發現和追蹤目標物是很困難的。 
在一般的影像監控應用當中，具有挑戰性之一的問題就是在 Fig.1 這種擁擠
的鏡頭中進行目標的追蹤。一般來說，嚴重的遮蔽現象會使傳統 blob-based物件
偵測/追蹤的方法失敗。例如，追蹤的目標物在擁擠的車站或廣場，被追蹤的人
有部分被其他人遮住，只有部分區域可以被作為追蹤的線索。因此，在擁擠的人
群中追蹤一個單獨的目標我們可能會面臨兩個主要的問題: 1)當我們在監視較大
空間中人群的移動，目標物可能太小 2)頻繁的遮蔽使得目標分割非常困難。因
此，特徵點偵測及追蹤經過評估後，認為適用於解決在人群中追蹤目標的問題。
即使在擁擠的場面中，可能仍然有一些區域的特徵點沒有被遮蔽。在 Fig.2-(b),
的例子中為利用 blob-based物件偵測的方法偵測目標物的圖例。很明顯的，在前
景區域幾個合併的目標難以被分割。相反的，在 Fig.2-(c)中，顯示出特徵點
(point-based)方法適用在人群中偵測與追蹤獨立目標的可能性。根特徵點追蹤相
同的概念，Brostow 跟 Cipolla[7]提出 Bayesian clustering algorithm 可以分割人群
中每個獨立的個體與時空距離和軌跡的一致性。然而，執行效能並不高。在本計
劃中，我們提出了一個新的方法來偵測和追踪人群中的個別目標物。 
在此計畫中，為了在擁擠場景中偵測個別的目標物以及分析群體移動所產生
的軌跡資訊，我們提出兩個方法分別在擁擠環境中偵測、追蹤個別的目標物，以
及將群體運動軌跡進行偵測分類。第一個子系統所提出的方法是以 corner 特徵
[10] H. Bay, A. Ess, T. Tuytelaars, and L. V. Gool, “Speeded-Up Robust Features (SURF),” 
Proceedings of the 9th European Conference on Computer Vision, Vol. 3951, May 2006, pp. 
404-417. 
[11] O. J. Morris, M. J. Lee, A. G. Constantinides, “Graph theory for image analysis: an approach 
based on the shortest spanning tree,” IEE Proceedings F. Communications, Radar and Signal 
Processing, Vol. 133, No. 2, Aprrl 1986, pp. 146-152. 
[12] T. Zhao and R. Nevatia. “Tracking Multiple Humans in Complex Situations,” IEEE Transactions 
on Pattern Analysis and Machine Intelligence, Vol. 26, No. 9, Sep. 2004, pp. 1208-1221. 
 
3.3研究方法 
一般來說，傳統在人群中的目標偵測的在分割過程可能有幾個問題。第一，
用背景相減法(background subtraction )[1]在擁擠的鏡頭中很難找到準確的邊界。
第二，以監督式學習(supervised learning)特定的背景模型(subject-specific model) 
[5]需要花費較大之訓練計算量。第三，在壅擠人群中移動的物體可能有不同的移
動方向，但分分合合的情形非常頻繁。為了解決這些問題，我們提出一種以 corner
特徵點為基礎發展一項從粗糙到細緻的目標物分割技術以解決在人群中的目標
偵測及追蹤技術。首先利用 C-means 演算法將落在移動物體上之動態特徵點做
初步概略性之分群，然後利用時空中最短的生成樹 (spatial-temporal shortest 
spanning tree)以及行人幾何特徵執行獨立目標物之分割。獨立目標物之分割之後，
持續更新特徵點與持續追蹤特徵點以追蹤每一個所切割出來之獨立目標物。 
在此計畫中，為了在擁擠場景中偵測個別的目標物以及分析群體移動所產生
的軌跡資訊，我們提出兩個方法分別在擁擠環境中偵測、追蹤個別的目標物，以
及將群體運動軌跡進行偵測分類。第一個子系統所提出的方法是以 corner 特徵
點為基礎，發展由粗糙至細緻的獨立目標物切割演算法。在這個方法中，首先利
用 C-Means 演算法將特徵點做粗略的分群，接著透過時空最小生成樹
(spatial-temporal shortest spanning tree)在每一個移動分群內切割出更精確的個體，
最後運用 corner 特徵點繼承的概念來追蹤所有移動個體目標物。第二個子系統
所提出的方法為應用 longest common subsequences 演算法自動估算人群運動軌
跡間之相似性，逐一地被分類到最適當的類別中。本計畫所提出之系統流程圖如
Fig. 3所示，以下逐一說明此計畫之研究步驟。 
 
All tracks compared with 
predefined tracks in LCSS 
algorithm
Display the output based on 
the classification of 
trajectory
C-means 
clustering
Construct a spatial 
shortest spanning tree in 
all clusters
 Individual segmentation 
with spatial-temporal 
relationship
Tracking result
Classified 
trajectories
Video
sequence
Feature points 
detection
Trajectory length
filtering
Static feature 
points
Dynamic  
feature points
　> LT　
　< LT　
Feature points’ 
tracking
Record feature 
points’ 
trajectories
 
KLT point 
tracking
 
Static & noise 
points’ 
filtering
  
 
Fig. 3 系統流程圖。左半邊描述群眾運動軌跡分類，右半邊描述人群中目標物切割及追蹤技術 
(B) 特徵點粗略的分割 
經過仔細的觀察，我們發現落在每個個體上之特徵點會呈現出較高的時空關聯性。
利用空間相關測量(spatial correlation)以及幾何關係，我們可以粗略分群所偵測到
之特徵點是否屬於同一個目標物；另外也考量時間相關量測(temporal correlation)，
也就是評估偵測到之特徵點的軌跡是否一致，從而判斷這些特徵點是否屬於同一
個目標物。在本計畫裡，我們先應用 C –mean 演算法將具有空間相關性的動態特
徵點做粗略的分群。 
(C)個體分割與時空最短生成樹 
基於在 C-mean 群集上的目標物粗略的分割，每一群特徵點集合可能包括數
個目標物。考量一般目標物(行人)幾何特徵，於一個個體上，特徵點之橫向距離
會比縱向距離短。因此於這個階段，我們要建立時空最短生成樹，計算節點與節
點之連接距離時，橫向距離比重需比縱向距離比重高。因此在粗略的分割群集後，
我們首先建立個體分割所需要之空間最短生成樹 (spatial shortest spanning 
tree)[11]，此方法描述如下： 
1. 在每一群特徵點群集 Ci = {p1, p2…, pN}建立一個空間最短生成樹，並按
下列公式計算節點與節點加權距離。 
   





  NjNippppd j
y
i
yy
j
x
i
xxij
,,2,1,,,2,1,
22
 　　  
其中 βx, βy 分別為 x 和 y 方向的權重。 
2. 根據在第 1步節點與節點加權距離的計算，建構空間最短生成樹(spatial 
shortest spanning tree)順序。 
除了考量特徵點在空間中之鄰近關係外，在時間軸上數個動態特徵點若落在同一
個移動物體上，則這些特徵點所呈現出之移動軌跡原則上應該會非常一致。因此
加上考量移動軌跡的相關性，我們將空間最短生成樹構建 (spatial shortest 
spanning tree)改良變成時空最短生成樹 (spatial-temporal shortest spanning 
tree.)。 
若有兩個特徵點所產生之移動軌跡 Tu 和 Tv，其移動軌跡的相關性可由下式
描述： 
 
 
,
,1
1
,
vu
vu
TTVariance
TTnCorrelatio
　　
　　　

  
結合空間中之鄰近關係，我們可以建立一個空間與時間一致性的測量標準： 
   
 
.1,1,,2,1,
 , 
22


 ijNi
TTnCorrelatio
pppp
eConformanc
ji
j
y
i
yy
j
x
i
xx
　　 

 
如果上述公式所計算出之數值大於所設定之臨界值，表示兩點不屬於同一個目
標。但同時，我們可能面臨一個當兩目標物交錯經過時，目標 A 的特徵點可能
錯位於目標 B的情況。因此，在下一節我們將計畫研發一個軌跡投票(voting)的
方法來驗證特徵點的屬性。 
 
(D)目標物交錯移動之錯植特徵點過濾方法 
雖然以特徵點為基礎之(point-based)物體偵測追蹤的方法，可以解決一些在
擁擠鏡頭中追蹤的問題，但是仍存在一些例外的情形，例如當當兩目標物交錯經
過時，目標 A的特徵點可能錯位於目標 B，此情況如 Fig. 5 所顯示。當兩個人交
錯的時候，很多特徵點可能會被做錯誤的分群。為了克服上述這個情形，我們提
 
    ,,,2,1,,,2,1,22












  NjNiCpCpDistance j
x
i
yy
j
x
i
xx
 　　  
其中 αx 和 αy為相似於 C-mean群集過程 x軸跟 y軸的權重。 
2. 當我們增加新的點到最近的群集之後，群集的中心需要重新計算。若數
個目標物一起移動時，個體分割必須再次執行。獨立個體分割是基於一
般正常人身體的寬度。首先，我們計算集群的寬度： 
.ryLeftBounda - aryRightBound  
yy
thClusterWid  
如果群集的寬度大於預定的大小 TWIDTH(評估正常人身體的寬度)，那麼群
集需要被切割。新的切割群集將會給它一個新的編號。Fig. 7 描述需要重
新分割的情況。 
3. 如果一些新的點沒有被分類到任何存在的族群，然後我們會將這些點分
類成新的族群 P’NEW = {p’1, p’2… p’N}和設成新的移動目標。Fig. 8 描述
已存在的群集（存在的目標）和新的群集（新目標）。 
4. 整合新舊群集資訊。 
5. 檢查每個群集中所有點之一致性和執行時空最短生成樹(spatial-temporal 
shortest spanning tree)之個體分割。Fig. 9顯示最終個體分割結果。 
 
 
Fig. 7紅線寬度表示群集，藍線表示正常寬度的人體。 
 
 
Fig. 8 (a)綠色點是從這些遠離其他存在紅群集新生成的點。(b)群集的結果。 
 
 
Fig. 9目標追踪的最終結果 
  
(a)         (b) 
  
(c)         (d) 
Fig. 12 Classification of the points’trajectories. (a) The case of few people walks separately. (b) Crowds 
walk closely. (c), (d) The trajectories of the moving car is detected. 
 
3.4結果與討論 
3.4.1 移動目標物切割分析 
兩個測試影片“Commons01” 和 “Tunnel-A125”是用於獨立個體的分割和目
標追蹤的效果評估。Fig. 13 顯示特徵點目標追蹤的實驗結果。在 Fig. 13，有數
個人靠近走在一起且有嚴重的遮蔽問題。這個提出的方法可以分割每個單獨的人
甚至遮蔽問題。為了評估提出系統的正確性，我們把提出的方法與最近幾年提出
的方法做比較。Table 1 列出這些方法之比較，可以看出我們的方法優於其他的
方法。 
 
Fig. 13.分割與追蹤目標群集 
Table 1 The accuracy analysis for the methods of Brostow & Cipolla, Zhao & Nevatia, and ours. 
 Brostow & Cipolla Zhao & Nevatia Ours 
distinct detections 144 8466 1319 
correctly detected 136 7881 1254 
missed detections 8 585 65 
false detections 33 291 56 
detection rate 94% 93.09% 95.07% 
miss detection rate 22.9% 6.91% 4.92% 
false detection rate 5.6% 3.43% 4.25% 
 
 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                     日期：   年   月   日 
                                 
一、參加會議經過 
這一次赴希臘參加 IIHMSP會議，首先聆聽 Prof. Demetri Terzopoulos所演講之”Virtual Vision: Computer 
Vision in Virtual Reality”，對於日後於電腦視覺方面之研究有所啟發。以下為其演講之摘要及影像紀
錄。 
Prof. Demetri Terzopoulos, IEEE Fellow, Computer Science, University of California, USA 
( http://www.cs.ucla.edu/~dt/ ) 
Title: Virtual Vision: Computer Vision in Virtual Reality 
Abstract: 
Realistic virtual worlds can serve as software laboratories within which vision researchers may efficiently 
develop and evaluate sophisticated, active machine perception systems. Known as "Virtual Vision", this 
unorthodox philosophy posited at the intersection of the fields of computer vision and computer graphics, 
enables virtual reality to subserve computer vision research and development. In the context of the virtual 
vision paradigm, this talk will focus on the rapid development and evaluation of distributed smart-camera 
sensor networks and intelligent surveillance systems that can persistently monitor humans in large-scale urban 
environments. The visually realistic virtual environments exploited in this work are populated by autonomous 
virtual humans, which are the product of a comprehensive, artificial life approach to multi-human simulation. 
計畫編號 
NSC 100-2221-E-216 -030 -  
計畫名稱 於擁擠人群中以特徵點為基礎的目標物追蹤系統 
出國人員
姓名 
連振昌 
服務機構
及職稱 
中華大學資訊工程學系 副教授 
會議時間 
101年 7 月 17日至 
101年 7 月 19日 會議地點 希臘 雅典 
會議名稱 
 (中文)第八屆國際智慧資訊隱藏及多媒體訊號處理會議 
 (英文) The Eighth International Conference on Intelligent Information Hiding and     
        Multimedia Signal Processing 
發表題目 
(中文)使用最低相關之 LBPH特徵之瞌睡辨識 
(英文) Drowsiness Recognition using the Least Correlated LBPH 
 
 四、建議 
無 
五、攜回資料名稱及內容 
論文光碟片 
六、其他 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：連振昌 計畫編號：100-2221-E-216-030- 
計畫名稱：於擁擠人群中以特徵點為基礎的目標物追蹤系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備註（質化說明：
如數個計畫共同
成果、成果列為
該期刊之封面故
事...等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 1 1 100% 件 
本技術已與 123 視
科技完成委託研究
簽約，依其需求修改
方法，以符合該公司
之應用情境。 
 
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100% 
Cheng-Chang Lien 
and Ming-Hsiu 
Tsai, ＇Vehicle 
Counting without 
Background 
Modeling,＇ 
accept to publish 
in Journal of 
Marine Science and 
Technology. (SCI, 
EI) 
研究報告/技術報告 0 0 100%  
國外 論文著作 
研討會論文 2 2 100% 
篇 
[1]Chun-Yuan Lee, 
Cong-Wei Huang, 
and Cheng-Chang 
Lien, ＇Kodaly 
Musical Hand Signs 
Recognition 
without Visual 
Background
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
(1)初期成果已發表如下: 
Shin-Ji Lin, Cheng-Chang Lien, Wei-Hsin Kan and Hsiao-Hu 
Tan, ＇Feature-Point-Based Target Tracking in the Crowd＇, APSIPA Annual 
Summit and Conference, December 14 - 17, 2010, Biopolis, Singapore . (EI)
(2)本年度研究成果已發表 SCI 期刊一篇，EI 國際研討會論文二篇 
(3)本技術已與 123 視科技完成委託研究簽約，依其需求修改方法，以符合該公
司之應用情境。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
