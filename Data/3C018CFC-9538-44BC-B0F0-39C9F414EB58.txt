combine resources that are distributed in different 
locations into one. 
In this sub-project, we will utilize the main feature 
of cloud computing, using virtualization in cloud 
computing to construct a social network＇s 
infrastructure. Using virtualized internet connection 
to combine with physical network. We also combine 
storage resources that are distributed into social 
network＇s storage space with virtualization 
technique.  
This project will dig deep into storage 
virtualization in cloud computing, virtualizing one 
or multiple storage providers＇ physical storage 
equipment. These storage equipments can be of the 
same or different types. All can be combined into one 
host＇s multiple storage space and remote hosts 
provide space into virtualized storage disk and 
system environment. After these storage spaces had 
been virtualized, user can access it as a storage 
space of the same type. 
The project also develops unified storage access 
interface to reduce the complexity of accessing 
different storage equipment. Furthermore, we also 
provide different users with different storage 
resource control tools to access control data 
informant in social network. With auto block 
migration mechanism and thin-provisioning based on 
data＇s access rate, we can provide modifiable 
storage dispatch tool for a better utilized resource 
usage rate and finally load balance for social 
networks. 
 
英文關鍵詞： social network services, cloud computing, 
virtualization, load balance 
 
 II 
 
摘要 
 
社群網路是需要大量網路連線與儲存空間的網路服務，網路連線的品質以及
資料存取的效能、安全性，都是架構社群網路的重要技術。而雲端計算的重要技
術之一就是虛擬化，將許多分散在各地的底層資源，利用虛擬化的技術結合成一
巨大的資源。在本子計畫中，我們應用雲端計算的特性，以雲端計算的虛擬化技
術建置社群網路服務的架構。計畫中將實體網路整合，研發透過虛擬化網路連結，
以及將分散的儲存資源，同樣透過虛擬化技術，整合成社群網路的網路儲存機
制。 
在本子計畫的第一年當中，我們開發了自有的社群網路平台，而因網路平台
的架構建設在雲端計算上，也跟以往的研究皆不相同。讓使用者可以透過網路連
結到社群網路主機以及各項社群網路服務，並訂定了統一帳號操作介面，且對各
計畫網路連線及網路需求做統整，讓開發者能方便控制傳輸品質與功能。 
第二年將著重於網路虛擬化技術之研究，經由建置雲端計算網路架構，即虛
擬連線架構和虛擬路由器架構，並遵循雲端網路通訊協定來達成網路虛擬化。另
外同時設計路徑選擇演算法來節省雲端能源傳輸。第三年將深入研究利用雲端計
算中的儲存虛擬化技術，使一個單位內的一個或是多個資源提供的實體儲存設備
進行虛擬化。這些實體儲存設備可能是單一儲存設備或是異質性的儲存設備，而
虛擬的儲存空間是透過整合單一機器上的多個實體磁碟空間以及單位內的其他
遠端磁碟所提供的儲存空間，形成虛擬磁碟的虛擬系統環境。經過虛擬化之後的
儲存設備，可以在使用上看起來像是存取同質性的儲存設備一樣，藉由統一的儲
存設備存取介面提供存取方式，減少存取異質儲存設備的複雜度。接著，根據不
同的使用需求提供儲存資源的管理工具，讓社群網站服務的資料可依其需求設定
相關存取機制，亦可依據實際資源的使用情況研發自動化的區塊遷移機制以及精
簡配置的功能，藉此將提供可設定化的儲存資源調度功能並提升資源的使用率，
最終目標為達到社群網路的負載平衡最佳化。 
 
關鍵詞: 社群網路、雲端計算、虛擬化、負載平衡 
 
 IV 
 
目錄 
一、前言........................................................................................................................ 1 
二、研究目的................................................................................................................ 1 
三、文獻探討................................................................................................................ 2 
四、研究方法................................................................................................................ 5 
五、結果與討論............................................................................................................ 9 
六、參考文獻.............................................................................................................. 10 
 
 
 
  
 2 
 
將不同於現有一般實體網路。在此環境下，利用現有的網路技術，使用者在進行
網路通訊時，需要將網路功能加入且包裝於資料封包中，然而，使用者並不清楚
網路之拓樸與狀況，無法使得網路的利用率最佳化，因此我們計畫使用虛擬之網
路功能，來管理虛擬網路。 
在本期計畫中，我們將社群網路服務建置在雲端計算的架構上，主要以虛擬
化網路連結，以及虛擬化網路儲存為主。並建置一使用者介面，提供社群網路服
務開發者方便設定其傳輸品質與功能。為適合雲端傳輸模式，亦將於二、三期研
究與發展相關傳輸協定，我們計畫帶入雲端計算研究中虛擬物件(virtualized 
object)之定址方式，用來發展雲端路由演算法。本計畫利用管理網路虛擬化以達
到網路通訊的負載平衡。同時研發且利用雲端計算的另一虛擬化功能：儲存虛擬
化(Storage Virtualization)技術，使一個單位內的一個或是多個資源提供的實體儲
存設備進行虛擬化。這些實體儲存設備可能是單一儲存設備或是異質性的儲存設
備，並且存放在各個不同的地理位置，利用雲端技術中儲存虛擬化的方式，各種
伺服器與儲存設備均虛擬化來提供多工的服務，一個實體電腦中可以提供多個虛
擬設備，然而這些提供服務的虛擬設備是動態的。同時在關於網路安全的問題上，
利用建立防火牆以滿足網路安全的基本需求。另外，因雲端計算之特性，本子計
畫在研發過程中亦探討容錯的機制，與滿足不同資料流量的網路服務品質之設
計。 
 
三、 文獻探討 
 Hinet hicloud 
中華電信提供了 Hicloud CaaS 服務[1]，如圖一所示，它採用雲端虛擬化技
術所開發之雲端伺服器服務。它提供了真實的虛擬運算環境，可以在多種作業系
統(Windows、Linux等作業環境)上使用服務介面，並讓使用者可載入自訂的應用
環境，執行自己所要提供的網路服務。 
 
 4 
 
示，節點 9為邊界虛擬節點，其有三個虛擬路徑到虛擬節點 6，分別為 z11、z21、
z31。如果傳送資料對於先後次序甚為敏感，則可使用單一路徑傳送。 
圖二、There are three paths between two virtual nodes 9 and 6. 
 
 假設有 N個虛擬網路使用 k標示，k=1到 N，在虛擬網路下，許多的虛擬節
點分享單一實體節點的 CPU，記憶體等，每一虛擬節點必須計算路徑 j上的 zj(k)i，
其中 k 為虛擬網路，i 為實體節點，zj(k)i值代表有多少的流量經由路徑 j，路徑 j
的頻寬由 yl(k)表示，實體連線 l 監控每個虛擬線路的負載量並且計算 λl(k)值，這
個值代表虛擬網路對於實體線路分配給其頻寬的滿意度，如圖三所示，實體線路
將 λl(k)導入至 link coordinator 中做計算，link coordinator週期性的計算分享的頻
寬並需保證 Σk yl(k)=Cl，Cl為實體線路總頻寬。DaVinci虛擬網路架構主要包含有
虛擬路由器、虛擬線路、與 non-work-conserving 排程，其最主要之創新在於如
何分享頻寬而求得系統最大之傳輸效能（aggregate performance）。 
 
 
 
 
 
 
 
 
 
 6 
 
擬化技術來充分使用實體資源之目標。 
圖四、 NIT Social Network UI 
圖五、System Architecture 
 入口網站的帳號操作介面與統一帳號操作介面之整合 
 8 
 
以下介紹本系統的系統效能以及平台的事件紀錄。圖八為系統的網路流量趨
勢圖，而圖九為系統的處理器使用率，此台虛擬機器為 Hadoop 架構中的 name 
node，負責分配工作給系統中的 data node（架構中的其他虛擬機器），藉此達成
系統中的負載平衡。 
圖八、網路流量趨勢 
圖九、處理器使用率 
 10 
 
面轉換到不同子計畫帳號的程式開發、入口網站的帳號操作介面與統一帳號操作
介面之整合、系統效能監視及事件紀錄功能。由結果可見，本計畫所提出的研究
方法對於架構一個雲端計算的網路環境是可行的，並結合學術理論與實務開發，
研究成果對於不只對國內外雲端計算的推廣，對於實體網路研究亦具有極高的參
考價值。 
 
六、 參考文獻 
[1] HiCloud CaaS  hicloud.hinet.net 
[2] ELGG www.elgg.org 
[3] Hadoop  hadoop.apache.org/ 
[4] T. Miyamoto, M. Hayashi, and H. Tanaka, “Customizing Network Functions for 
High Performance Cloud Computing,” Proceedings of Eighth IEEE 
International Symposium on Network Computing and Applications, 2009, pp. 
130-133. 
[5] Y. Zhu, R Z. S., S. Rangarajan, and J. Rexford,” Cabernet: Connectivity 
Architecture for Better Network Services,” Proceedings of ReArch’08, Dec. 9, 
2008, Madrid, SPAIN 
[6] J. He, Z. S. Rui, Ying Li, C. Y. Lee, J. Rexford, and M. Chiang, "DaVinci: 
Dynamically Adaptive Virtual Networks for a Customized Internet," 
Proceedings of CoNext, December 2008 
[7] J. C. C., Restrepo, C. G. Gruber, and C. M. Machuca, “ Energy Profile Aware 
Routing,” Proceedings of IEEE International Conference on Communications 
Workshops 2009, pp. 1-5. 
 
 
Simplifying MapReduce Data Processing 
 
Jin-Ming Shih, Chih-Shan Liao 
Dept. of Computer Science and Information 
Engineering 
National Dong Hwa University 
Hualien, Taiwan 
gmozomg@gmail.com, toptom@mail.ndhu.edu.tw 
Ruay-Shiung Chang 
Dept. of Computer Science and Information 
Engineering 
National Dong Hwa University 
Hualien, Taiwan 
rschang@mail.ndhu.edu.tw
 
 
Abstract—MapReduce is a programming model developed by 
Google for processing and generating large data sets in 
distributed environments. Many real-world tasks can be 
implemented by two functions, map and reduce. MapReduce 
plays a key role in Cloud Computing, since it decreases the 
complexity of the distributed programming and is easy to be 
developed on large clusters of common machines. Hadoop, an 
open-source project, is used to implement Google MapReduce 
architecture. It is wildly used by many applications such as 
FaceBook, Yahoo, Twitter, and so on.  
However, it is difficult to decouple an application into 
functions of map and reduce for common users. In this paper, we 
develop a web-based graphic user interface for ordinary users to 
utilize MapReduce without the real programming. Users only 
have to know how to specify their tasks in target-value-action 
tuples. Real examples are provided for demonstration.  
Keywords - MapReduce; Hadoop; Cloud Computing; 
Web-based Graphic User Interface 
I. INTRODUCTION 
In recent years, cloud computing and the services it 
provides were deploying rapidly. One of the technologies in 
cloud computing is the MapReduce [1] programming model. 
MapReduce [1] is devised by Google for processing a large 
amount of data to generate useful information. In 
MapReduce, the complexity of distributed programming is 
decreased substantially by hiding details of the distributed 
computing system. The MapReduce process shown in Fig. 1 
splits input data into a lot of Map operation nodes and 
produces a set of output containing key/value pairs. Reduce 
operation nodes group together all intermediate values with 
the same intermediate key.  
An example is WordCounter [1]: an application that 
counts the number of times a word appears in a collection of 
documents. Map emits a key/value pair, (word, 1). Reduce 
combine the value from the same word and we can get the 
number of times a word appears. 
MapReduce computation is used in many applications 
[2-4] such as Distributed Grep, Count of URL Access 
Frequency, Reverse Web-Link Graph, Term-Vector per Host, 
Inverted Index, Distributed Sort, Security Enhanced DNS 
Group, Journey Dynamics and other real world applications. 
Even in the Google new search engine technology, 
Percolator [5], Google still uses MapReduce to analyze and 
produce the initial search index. 
 
 
 
Figure 1.  MapReduce data flow 
Although the MapReduce model can simplify the 
complexity of programming for distributed computing,  
MapReduce is still not easy to implement. If users want to 
use MapReduce to compute a large-scale data set, they have 
to set up their machine's MapReduce environments first. 
Then they have to write the real MapReduce programs. 
Without suitable background and training, it is nearly 
impossible for people to implement MapReduce.  
In this paper, we present a Web-based GUI for 
MapReduce Data Processing. The GUI can let users design 
their MapReduce workflow intuitively and conveniently 
without the need of implementing a MapReduce system and 
actually writing the programs. Therefore, the use of 
MapReduce data processing is simplified so that users can 
easily process large data sets using MapReduce through the 
Web-based GUI on any device. The development time will 
be decreased and the MapReduce paradigm can be adopted 
more widely.  
II. RELATED WORK 
A. Hadoop MapReduce 
Hadoop [6] is an open-source project implementing 
Google's MapReduce architecture by Apache. Hadoop 
MapReduce is a software framework for process large-scale 
will not be outputted to Reduce phase. The Compare 
operations are only responsible for filtering data in dataflow, 
so there is no return value.  
The Merge operations expect the text input. It will 
combine the text input. There are four different Merge 
operations: Merge_Unique, Merge_Duplicate, Size of 
(Merge_Unique) and Size of (Merge_Duplicate). Size of 
(Merge_Unique) and Size of (Merge_Duplicate) will return 
the cardinality of the result set. Table 3 shows Merge 
examples. 
TABLE I.  THE MERGE EXAMPLES 
Input: 
A 
A 
B 
C 
C 
D 
Operations Return 
Merge_Unique (A,B,C,D) 
Merge_Duplicate (A,A,B,C,C,D) 
Size of(Merge_Unique) 4 
Size 
of(Merge_Duplicate) 
6 
 
The Math operations expect an integer input. Sum_Each 
and Multiply_Each expect multi-column inputs. 
Merge_Group_Sum and Merge_Group_Multiply expect a 
columns pair input in the Value where one is the text and the 
other is the integer. The text will be merged and the value 
will be summed or multiplied .  
Therefore, Merge_Group_Sum and 
Merge_Group_Multiply output the groups which consist of 
text results and integer results. Then the Target in 
Target-Value-Action can only accepts text, and the Value 
accepts only integer. If there is more than one columns pair 
with the same Target (text string) in Merge_Group_Sum or 
Merge_Group_Multiply, the column pairs will be summed or 
multiplied. 
If there is only one columns pair with same Target, the 
single pair will be ignored. Table 4 shows an example of 
Merge_Group_Sum. 
TABLE II.  THE MERGE_GROUP_SUM EXAMPLES 
Word (Target) User (Value) Score (Value) 
A User1 2 
A User3 3 
B User1 4 
B User2 0 
B User3 1 
After Merge_Group_Sum , the Outputs 
[Group(1),Group(2)] are: 
[(User1,User3) , 5] (for A) 
[(User1,User2) , 4], [(User1,User3) , 5], [(User2,User3) , 1] 
(for B) 
 
C. Layer 
In Hadoop, developers define each Job input and output 
path by means of the FileInputFormat or FileOutputFormat 
classes. Developers can set other Job’s output as input. If a 
Job pull the data from other Job output as the input, then 
they are chained MapReduce Jobs. In our Web-based GUI, 
chained MapReduce Jobs were controlled by “Layers”. 
Each Layer consists of single or a set of 
Target-Value-Action and Container. Layers can accept other 
Layers’ output or the original data as the input. Fig. 3 shows 
the dataflow in Layers. The input of Layer 1 and Layer 2 is 
original data. Layers 3 can use the output from Layer1 and 
Layer 2 as the input. In our GUI, users directly assign the 
input by choosing the output from other Layers. 
 
 
Figure 3.  The dataflow of Layers 
Therefore, the Layer concept in Web-based GUI makes 
chained MapReduce Jobs graphically visible and easy to 
control. 
D. Container 
“Container” integrates different outputs into the same set 
with multi-column. It can make the output dataflow visible 
and convenient while operating the inputs from different 
Layers with different outputs. The maximum number of 
Containers in each Layer is two: default Container and 
output Container. The original data is split into the user 
defined columns in the default Container. The user then 
define the mappings from the default container to the output 
container. Fig. 4 shows the dataflow of Container. Even if 
there are two different outputs, the two outputs can be 
combined into the same output Container. Users can assign 
any column from operation results to the output Container in 
each Layer. 
 
 
Figure 4.  Container example 
E. System Architecture 
The Web-based GUI for MapReduce Data Processing is 
based on a Web-based GUI and a Hadoop cluster. Fig. 5 
shows our proposed system architecture and the workflow. 
Our proposed GUI sends the control information from client 
to Hadoop Cluster. The information will be analyzed and 
split to the processors. The processed result is stored in 
(wt, d) with the same Target. The Merge_Group actions 
ignore the single pair. We choose the group (1) as the Target 
and group (2) as the Value. Finally, we sum the weight and 
get the Pairwise Document Similarity result.  
TABLE III.  THE PAIRWISE SIMILARITY DETAILS IN OUR 
PRESENTED METHODS 
Pairwise Document Similarity 
Layer1,inp
ut is origin 
data 
column: 
[word] 
Target Value Action 
word, 
doc 
name 
1 Sum 
Layer 
2,input is 
Layer 1’s 
output 
column: 
[word], 
[doc_name
], [weight] 
Target Value Action 
word 
doc 
name, 
weight 
Merge_Group_Muti
ply 
group(
1) group(2) Sum 
 
 
Figure 7.  Formalize the columns for Container_PDS 
Using our methods, processing Pairwise Document 
Similarity becomes simple, convenient and visible compared 
to direct programming in MapReduce. We don't have to deal 
with the details in MapReduce programming.  
V. CONCLUSIONS AND FUTURE WORK 
In this paper, we present a Web-based GUI for 
MapReduce data processing. We also present three abstract 
data processing building blocks to hide the programming 
details from Map and Reduce. Users just choose some 
objects as targets; give each object a value and take actions. 
The Layer and Container make the input/output visible and 
easy to control. The presented methods are suitable for a 
Web-based GUI since the complexity of the MapReduce 
data processing has been decreased. Therefore, users do not 
need to install Hadoop in their computers and they can use 
any device at anywhere to process their data through the 
Web-based GUI. User can also directly drop and drag the 
operation components to process large-scale data using 
MapReduce. In the future, we will enrich the operation 
components and management functions. If users can store, 
reuse and share their used operation components structure, 
our method can be more powerful. We will also make the 
GUI friendlier.  
 
Acknowledgements: This research is supported in part ROC 
NSC under contract number 99-2631-S-259-001. 
REFERENCES 
[1] Jeffrey Dean and Sanjay Ghemawat, "MapReduce: Simplified Data 
Processing on Large Clusters", Symposium on Operating Systems 
Design and Implementation, 2004 
[2] Hadoop: The Definitive Guide, Tom Wbite, 2010 
[3] Hadoop in Action, Chuck Lam, 2010 
[4] NCHC Cloud Computing Research Group website, 
http://trac.nchc.org.tw/cloud 
[5] Daniel Peng and Frank Dabek, "Large-scale Incremental Processing 
Using Distributed Transactions and  Notifications", Operating 
Systems Design and Implementation, Oct. 2010 
[6] The Apache Hadoop project website, http://hadoop.apache.org/ 
[7] Cascading website, http://www.cascading.org/ 
[8] Tamer Elsayed,Jimmy Lin, and Douglas W. Oard, "Pairwise 
Document Similarity in Large Collections with MapReduce", 46th 
Annual Meeting of the Association for Computational Linguistics on 
Human Language Technologies, 2008 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/28
國科會補助計畫
計畫名稱: 子計畫二：利用雲端計算的社群網路架構與建置(I)
計畫主持人: 張瑞雄
計畫編號: 100-2221-E-259-011- 學門領域: 計算機網路與網際網路
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
舉辦 SuComs 2011, ICS 2012 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
