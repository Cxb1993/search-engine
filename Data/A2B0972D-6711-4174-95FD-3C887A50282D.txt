 2
行政院國家科學委員會專題研究計畫成果報告 
具意圖分析之醫療資訊 QA 問答引擎研發與實作   
計畫編號：NSC 95-2221-E-006-321 
執行期間：95 年 8 月 1 日至 96 年 7 月 31 日 
主持人：蔣榮先    國立成功大學資訊工程學系 
電子信箱(Email): jchiang@mail.ncku.edu.tw 
 
 
一、 前言與研究目的: 
QA 問答系統可視為目前以文件擷取為主之資訊搜尋系統的成功應用，在過去以關鍵字
作搜尋的方式，並沒有針對字詞語意作分析，因此當查詢中的字詞有一字多義的情形時，
會導致搜尋所得文件數過於龐大，而不同文件的內容敘述卻南轅北轍，差異性很大。相較
於分散且不具語意相依性的關鍵字，問答系統則是以問句作查詢，問句中的字詞彼此有相
依關係並提供較多語意資訊，若能適當分析其意圖，對於提高擷取文件相關度與答案之精
確率皆有很大的幫助。由於本研究是利用網路上搜尋引擎作為擷取答案來源文件的工具，
因此對於搜尋引擎本身的特色如查詢語法及文件索引數量之研究也是一項重要的課題。在
本計畫中我們設計了一個分析問句之字詞及語句結構的功能模組，以達到意圖分析之目
的。判定問句之詢問目標及所求資訊，並依片語資訊進行更精細的問題所求答案分類，以
利於在後續處理階段中建立相對應答案類別之最佳處理程序。 
 
二、 文獻探討 
START Question Answeing System 
由 MIT Computer Science and Artificial Intelligence Laboratory 所開發的 START 問答系
統，是網路上運行相當久的一個問答系統，該系統的特色是採用網路上編輯完善的資料庫
作為答案萃取來源，這些資料庫包括有電影資料庫 IMDB、世界各國的國情資料庫 CIA 
World Factbook 等，藉由整合這些資料庫，當使用者輸入問句後，START 問答系統會將問
 4
訊萃取（Information Extraction）等，分別利用於處理文件中句子之語句結構分析，及
進行答案之萃取。最後擷取出的所有候選答案還需要依其正確性作排序（answer 
ranking）。 
 
三 研究方法 
 
在本研究中，我們建構了一個以網路文件資源作為答案文件庫之自然語言問答系統
CKQA（Cheng Kung Question Answering），本系統主要由五個模組所建構成：（1）Question 
Analyzer，（2）Query Formulator，（3）Document Retrieval，（4）Answer Extractor，（5）Answer 
Ranking。第一個模組主要功能在於利用自然語言處理工具，進行輸入問句之字詞資訊分析
及答案類型分類，以決定後續查詢建構及答案找出之處理策略。第二個模組則以問句分析
後所得之資訊配合查詢樣板庫，建構基於 Google 搜尋語法之查詢。第三個模組則是採用
Google Web APIs 處理建構好的查詢，進行網路文件之擷取。第四個模組則是負責從擷取出
之相關文件中作候選答案之萃取。第五個模組則是對候選答案進行過濾及整合，並輸出排
序過的答案作為最終的結果。圖一及圖二分別為本系統 CKQA 之架構圖與處理流程圖。 
 
 
 
 
 
 
 
 
 
 
 
(2) Query Formulator
Formulate Query
(3) WEB Document Retrieval
Sending formulated query to
Google Search Engine
(4) Answer Extractor
Extract candidate answers
Query Pattern Bank
Answer Extraction
Rule
Natural Language
Processing tools
WEB Documents
(5) Answer Ranking
Filtering and ranking candidate
answer
Answer Type Classification
Question Information Parsing
(1) Question Analyzer
Question
Answer
 6
四  實驗結果及計畫成果自評 
4.1 實驗設計 
在本實驗中將透過與 Google 搜尋引擎及網路上運行的 START、NSIR 及 AnswerBus 等
線上問答系統，針對問答之表現作比較與分析。 
4.1.1 節中為本實驗所使用之問題資料集介紹，4.1.2 節則是詳細的實驗設計細節及問答
系統之評比標準說明。最後在 4.2 節中將對實驗所得結果數據作分析，並針對不同系統之
問答表現作探討。 
 
4.1.1 實驗資料介紹 
本系統所採用的實驗資料來源是 TREC 2003 所提供的問題集（TREC Question Set）。
在 TREC 2003 年的問題集中共含有問題 500 句，以下是該問題集所含問題依不同句首分類
的問句數分布情況： 
0
50
100
150
200
250
300
How In List Name On What When Where Which Who
問句數
 
圖三 各種不同句首之問句數分佈統計圖 
  
從圖三中可以清楚發現 What 所佔有的問句數最多，高達 265 句，其餘的問句則以句首較為
常見的 How、Who、When、Which 及 Where 等疑問詞佔有多數，因此在本系統中，主要處
理重心在於較常見的幾個疑問詞為句首之問句上，包括 What、How、Who、When、Which
及 Where。本實驗從 TREC 2003 問題集裡含有以上句首的 484 個問句中隨機抽取 40 句問
 8
How many counties are in California? 0.00 0.40 
How many moons does Neptune have?  0.30 0.63 
[HOWMANY_HAVE] 
How many electoral votes does Tennessee have? 0.20 0.75 
How many Earth days does it take for Mars to orbit the sun? 0.10 0.70 
[HOWMANY_VERB] How many home runs did Henry "Hank" Aaron hit in his 
major league career? 
0.40 1.00 
What continent is the world's largest desert on?  0.40 1.00 
[CONTINENT] 
What continent is India on?  0.10 0.83 
How far is the distance for a free throw?  0.00 1.00 
How far is the moon from Earth in miles?   0.00 0.33 [LENGTH] 
How close is Mercury to the sun?  0.20 1.00 
What movie won the Academy Award for best picture in 
1989?  
0.00 0.00 
What player has been the home run champion of the national 
league seven times? 
0.00 0.00 [ALLOBJECT] 
What band did the music for the 1970's film "Saturday Night 
Fever"? 
0.00 0.00 
 Total： 9.5 24.29 
 
由表 4-1 的實驗結果中可發現，問句透過本系統 CKQA 的查詢轉換後確實提高了含有
答案之文件的出現率及其排序順位。本系統中表現比較好的答案類別，主要有下兩大類： 
（1） 當詢問 DATE、BIRTHDATE 及 DIEMANER 等答案類型實，藉由將介係詞如“on”和
“of”等加入建構的查詢中，提高了相關文件之擷取率。 
（2） 當詢問答案類型屬於可計量的答案時，如 HEIGHT、DEPTH 及 LENGTH 等類型的
答案，系統藉由加入如“feet”、“ft”、“miles”及“meter”等計量單位詞於查詢中，同樣
使得本系統擷取的文件精確度較 Google 為高，獲取更多相關的文件。 
 
 
 
 
 10
How many Earth days does it take for Mars to orbit the 
sun?  
0.00 0.00 1.00 1.00 
[HOWMANY_VERB] 
How many home runs did Henry "Hank" Aaron hit in his 
major league career? 
1.00 0.00 0.00 1.00 
What continent is the world's largest desert on?  0.00 1.00 0.00 1.00 
[CONTINENT] 
What continent is India on?  0.20 1.00 1.00 1.00 
How far is the distance for a free throw?  0.00 0.00 0.00 1.00 
How far is the moon from Earth in miles?   1.00 0.00 1.00 1.00 [LENGTH] 
How close is Mercury to the sun? 0.00 0.00 1.00 1.00 
What movie won the Academy Award for best picture in 
1989?   
0.00 0.00 1.00 0.00 
What player has been the home run champion of the 
national league seven times? 
0.00 0.00 0.00 0.00 [ALLOBJECT] 
What band did the music for the 1970's film "Saturday 
Night Fever"? 
0.00 0.00 0.00 0.00 
 Total： 10.36 10.16 22.00 32.33 
 
在實驗二作比較的三個線上問答系統中，AnswerBus 的輸出是呈現含有可能答案的字
串，因此在答案正確與否的判斷上，是以字串中是否出現正確答案來判定。在本研究所開
發之問答系統 CKQA，確實能藉由自然語言處理技術的協助，幫助系統對問句中的重要資
訊作分析，並透過答案類型的定義，將不同問句作分類而建構最佳之處理策略。在查詢建
構的處理上，亦提高了擷取結果中相關文件的排序順位，進而使得答案萃取之正確率提高。
唯一美中不足的是在實驗過程中，一直無法取得足夠的醫療相關問答集以作為測試之用，
故而採用目前全世界最常使用的標準 TREC 資料集作為實驗之用。 
 
 
參考文獻 
 
Ellen Riloff, Janyce Wiebe, “Learning Extraction Patterns for Subjective Expressions”. In 
Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing 
(EMNLP-03), 2003. 
