3) We generate the upper envelope by interpolating the 
local maxima, denoted )(thupper , and the lower 
envelope by interpolating the local minima, denoted 
)(thlower ; 
4) Compute the envelope mean, 
)(1 tm j- = 2/))()(( thth lowerupper + ; 
5) Compute )()()( 11 tmthth jjj -- -= ; 
6) Repeat steps 2-5 and set j=j+1 until )(th j  is an IMF; 
7) )()( thtimf ji = and compute the residue 
)()()( 1 timftrtr iii -= - ; 
8) Repeat steps 2-7 and set i=i+1 until )(tri is 
monotonic. When )(tri is monotonic, we have 
accomplished the EMD, and set )()( trtr iL = . 
The original signal )(tf can be expressed as the sum 
of IMFs and the last residue as follow: 
å
=
+=
L
i
Li trtimftf
1
)()()(  
The stopping criterion, SD, used to know whether hj is 
an IMF, is defined as, 
TtmSD
T
t
j /|)(|
0
1å
=
-=  
In other words, the sifting process stops when SD is 
smaller than some predefined constant C. 
 
 
 
Fig. 1. The flow chart of EMD for one dimensional 
signal.  
 
3. BIDIMENSIONAL EMPIRICAL MODE 
DECOMPOSITION 
 
Texture analysis and multiscale structure are important 
techniques in image processing. BEMD is a new 
technique proposed to extract two-dimensional IMFs 
from images [5][6][7][8][9][10]. BEMD is better than 
Fourier or wavelet, and the other multi-scale structure 
when extracting features of textures or filtering images, 
because it is local, adaptive and suitable for non-linear, 
non-stationary data analysis. This section introduces 
two methods of BEMD. The first method is proposed in 
[5] called BEMD-1 and it is real 2D method. The 
second method called BEMD-2 is the proposed method 
using 1D EMD in two or four directions to approach 
the real 2D method. 
 
3.1. BEMD-1[5] 
 
The steps of 2D-sifting process are described as follows: 
1) Identify the local maxima and minima of the image I 
by neighboring window. 
2) Generate the 2D ‘envelope’ by interpolating maxima 
points (respectively, minima points) by thin-plate 
smoothing spline. 
3) Determine the local envelope mean m1 by averaging 
the two envelopes. 
4) Since IMF should have zero local mean, subtract out 
the mean from the image: I-m1=h1. 
5) Repeat steps 2-4 until h1 is an IMF 
Repeat steps 1) to 5) after subtracting precedent IMF 
from input image until the residue has no more IMF, 
just like the algorithm of one-dimensional EMD. 
 
3.2. BEMD-2 
  
This method is proposed to decompose images by 1D 
EMD and form 2D IMFs. Before doing the following 
steps, we find two orthogonal directions respectively: 
1q and 2q . Then we apply 1D EMD to image I(x,y) in 
two direction, 1q or 2q ,respectively. In other words, we 
do steps as follows: 
1) Initialize 1qq = ,  
),(),(),( 11 yxIyxhyxr ji == --
q . 
2) Apply one-dimensional EMD to each line in the 
first direction of the image. 
3) Get residue ),(1 yxrq and several IMFs. 
PDF created with pdfFactory trial version www.pdffactory.com
residue. Third row: IMF1, IMF2, IMF3, IMF4, 
using BEMD-2. 
 
 
    
     
Fig. 4. First row: Brodatz D101 [11], IMF1, 
IMF2, and residue using BEMD-1. Second 
row: sum of all IMFs, sum of IMF1 and IMF3, 
sum of IMF2 and IMF4, residue. 
 
 
 
 
 
  
Fig. 5. Original images: Lena, Baboon, and 
Barbara. 
 
4.2. For natural images 
 
We use three natural images, Lena, Baboon, and 
Barbara (Fig. 5.) for bidimensional empirical mode 
decomposition. First, we apply BEMD-1 to Lena image 
and get 2D IMFs of them (Fig. 6.). Secondly, we apply 
EMD to each row and each column of Lena image to 
form 2D IMFs (Fig. 7.), and compare with the results of 
BEMD-2 in four directions (0°, 45°, 90°,and 135°) 
shown in (Fig. 8.). From the experimental results of 
natural images, we can find that 2-D IMFs using 1D 
EMD in four directions or more directions will 
approximate 2D IMFs using BEMD-1 further. 
Therefore, Fig. 9 shows the results of Baboon, and 
Barbara decomposed by BEMD-2 in four directions and 
we compare them with BEMD-1’s first IMF. The first 
IMF is like the image extracted the uneven illumination. 
We only show several IMFs due to other IMFs have 
little information. 
In addition to approximating the first IMF of 
BEMD-1, BEMD-2 is faster and more suitable for 
extracting fine directional textures. Fig. 10 shows the 
parts of Barbara and Baboon, we can see the small 
directional textures are extracted from the images. 
 
 
  
   
 
Fig 6. Lena image decomposition using BEMD-
1. First row: IMF1, IMF2. Second row: IMF3 
and residue. 
 
5. CONCLUSION 
 
In this paper, a new algorithm for BEMD is proposed 
using 1D EMD. The experimental results show that the 
proposed approach can effectively decompose both 
textures and natural images into 2D IMFs. These 2D 
IMFs are multi-scale images having similar frequencies 
locally and these features can help image recognition or 
texture analysis. The proposed BEMD not only extracts 
clear fine directional textures but also maintains local 
contrast when adding some IMFs. However, the IMFs 
generated by the proposed BEMD have small vertical 
lines or horizontal lines because using 1D interpolation 
method makes the inconsistent amplitude between row 
by row or column by column.  
Compared with BEMD-1, the results of BEMD-1 
are smooth in all directions, but BEMD-1 costs too 
much time to interpolate the 2D envelopes and 
decomposes the image into more fine scale with 
difficulty. Also, our BEMD only needs low 
computational cost because of line-based EMD and can 
approximate the results of BEMD-1 with high 
computational cost. The cost time of BEMD-1 is 
probably 2 hours for the image of size 256X256 pixels 
and SD=10.  However, our method only costs several 
minutes with the same SD. In addition, BEMD-1 needs 
much more memory than ours.  
There are still some boundary problems with our 
algorithm, and they will be left to the future work. 
 
 
 
 
PDF created with pdfFactory trial version www.pdffactory.com
REFERENCES 
 
[1] N.E. Huang, Z. Shen, S.R. Long, M.L. Wu,H.H. Shih, Q. 
Zheng, N.C. Yen, C.C. Tung and H.H. Liu, “The empirical 
mode decomposition and Hilbert spectrum for nonlinear and 
nonstationary time series analysis.” Proc. Roy. Soc.London A, 
Vol. 454, pp. 903–995, 1998. 
 
[2] G. Rilling, P. Flandrin and P. Goncalves, Empirical Mode 
Decomposition As a Filter Bank, IEEE Signal Processing 
Letters, vol. 11, no. 2, pp. 112-114, 2004. 
 
[3] G. Rilling, P. Flandrin and P. Goncalves, Detrending and 
Denoising with Empirical Mode Decomposition EUSIPCO-
04,Wien. 
 
[4] Rilling, G., Flandrin, P., and Goncalves, P., “On 
empirical mode decomposition and its algorithms.” Pro. 
IEEE-EURASIP Workshop on Nonlinear Signal and Image 
Processing, 2003. 
 
[5] A. Linderhed, Compression by Image Empirical Mode 
Decomposition, Proceedings of  International Conference on 
Image Processing, ICIP-05 Genoa (I), September 11-14  2005, 
pp: 553-556. 
 
[6]http://www.icg.isy.liu.se/~anna/emdcoding.html. 
 
[7] J. C. Nunes, Y. Bouaoune, E. Delechelle, O. Niang and 
Ph. Bunel, “Image analysis by bidimensional empirical mode 
decomposition” Image and Vision Computing, Vol.21,Issue 
12, pp.1019-1026, Nov 2003. 
 
[8] J. C. Nunes, S. Guyot, E. Delechelle, “Texture analysis 
based on local analysis of the Bidimensional empirical mode 
decomposition” Machine Vision and Applications 16, pp.177-
188, 2005. 
 
[9] Z. X. Lin, S. L. Peng, “Texture segmentation using 
directional Empirical Mode Decomposition.” IEEE 
International Conference on Image Processing (ICIP) October 
24–27, 2004,Singapore. 
 
[10] Z. X. Lin, S. L. Peng, “Boundary processing of 
bidimensional EMD using texture synthesis” IEEE Signal 
Processing Letters,Vol.12.No 1.Jan 2005. 
 
[11] http://www.ux.uis.no/~tranden/brodatz.html 
 
PDF created with pdfFactory trial version www.pdffactory.com
 2 
 
 
 
 
Fig 1.Skin color distribution and boundary box in CbCr 
color space in Ref [1]. 
Considering only color information, a pixel will be 
classified as skin if both of its color components are 
within each of these ranges. So, the technique used for 
the racial recognition and face segmentation consists of 
defining maximum and minimum thresholds for each 
of the two chromatic components. 
 
2.2 YCgCr color space 
     There is another useful color coordinate: YCgCr, a 
novel color space based on YCbCr, was mainly 
proposed in [1, 2] for face segmentation. It is based on 
YCbCr, but it differs on the use of the Cg color 
component instead of Cb. The color spaces used in 
television systems (YUV, YCbCr) are transmission 
oriented, so in order to minimize the encoding 
decoding errors, they use the biggest color differences: 
(R-Y) and (B-Y). The YCgCr color uses the smallest 
color difference (G-Y) instead of (B-Y). 
The YCgCr components can be obtained in a 
similar way than the YCbCr equations described in the 
ITU Rec. BT. 601 and expressed in terms of Y’, G’-Y’, 
R’-Y’ components defined in the [0,1] range using the 
following matrix expression: 
16 219 'Y Y= + ´ , 
' 0.299 ' 0.413 ' 0.144 'Y R G B= ´ + ´ - ´   ...Eq(1) 
1128 112 [ ( ' ')]
1 0.587
Cg G Y= + ´ -
-
………Eq(2) 
1128 112 [ ( ' ')]
1 0.299
Cr R Y= + ´ -
-
……….Eq(3) 
 
Luminance and chrominance are coded in 8 bits. 
Y has an range of 219 and an offset of 16. The 
chromatic components are defined in the rage [16,240], 
with range of ± 112 and an offset of 128. Each 
component is coded in 8 bits. Expressed in matrix form, 
R’G’B’ components can be easily transformed to 
YCgCr components: 
 
16 0.257 0.504 0.098
128 0.316 0.439 0.121
128 0.439 0.368 0.071
Y R
Cg G
Cr B
é ù é ù é ù é ù
ê ú ê ú ê ú ê ú= + - -ê ú ê ú ê ú ê ú
ê ú ê ú ê ú ê ú- -ë û ë û ë û ë û
…..Eq(4) 
 
According to [2], most skin pixel color 
distribution can be detected in the chrominance 
bounding box in CgCr domain shown in Fig 11. A 
pixel will be considered as skin if both of its color 
components are within each of the ranges defined by 
the maximum and minimum thresholds of the 
chrominance plane coordinates Cg and Cr. Where (Cg 
min, Cg max)=[76, 125] and (Cr min, Cr max)=[136, 
202]. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 2.Skin color distribution and boundary box in CgCr 
color space in Ref[2]. 
Consider the skin color distribution depicted in Fig 
2, it is possible to achieve a better performance of the 
face segmentation in the YCgCr color space by defining 
a boundary box in the direction of the line that connects 
the Red and Cyan colors, where most of the skin values 
are concentrated. 
     New decision thresholds constituting a 
nonrectangular region (the black region inside the 
boundary box shown in Fig 2) can be defined, so that 
the Cr thresholds are the same vertical limits of the 
boundary box, while the Cg thresholds, Cg min and Cg 
max lines, are parallel to the Red-Cyan line. Hence the 
Cr min and Cr max thresholds and the Cg min and Cg 
max lines, according to the following equations: 
min maxCr Cr Cr£ £ …………..…….Eq(5) 
(Cr min, Cr max)= [136, 202]. 
(305 ) min 1.38 max
1.38 1.38
Cr Cr Cr CrCg- + ´ -£ £ Eq(6) 
Instead of using two binary masks for face 
segmentation based on the Cg and Cr thresholds of the 
boundary box, in the case of a nonrectangular decision 
region, for every Cr value, a binary mask is used for 
each Cg min and Cg max pair of Cg thresholds. The 
final mask for face segmentation is obtained as the 
intersection of all the binary masks. 
 
2.3 The reasons of choosing YCgCr 
     The black cluster of Fig 1 and 2 represent the 
majority of human skin chrominance in different 
domains. Fig 1 displays human skin chrominance of 
CbCr and Fig2 represents that of CgCr. Compare Fig 1 
to Fig 2, the shape of black cluster of Fig 2 in CgCr 
domain is more regular than that of Fig 1. The human 
PDF created with pdfFactory trial version www.pdffactory.com
 4 
 
 
 
 
 
Fig 5.Skin color distribution in YCg and Y Cr domain. 
In Fig 5, there are two figures which show the 
experiment result of distributions in Y-Cg and Y-Cr 
domain. They show that Negroid really has less 
brightness than Caucasian and Mongoloid. 
Furthermore, Mongoloid has the widest distribution of 
luminance; we will consider the effect of illumination 
in GMM analysis. 
3. GAUSSIAN MIXTURE MODEL 
 
GMM (Gaussian mixture model) which is the 
extension of single model Gaussian probability function 
is a conventional method to analyze non-uniform 
distributed data and is among the most statistically 
mature methods for clustering (though they are also 
used intensively for density estimation. In this tutorial, 
we introduce the concept of clustering, and see how one 
form of clustering in which we assume that individual 
data points are generated by first choosing one of a set 
of multivariate Gaussians and then sampling from them 
can be a well-defined computational operation.  
Mixture models are a semi-parametric alternative 
to non-parametric histograms (which can also be used 
as densities) and provide greater flexibility and 
precision in modeling the underlying statistics of 
sample data. They are able to smooth over gaps 
resulting from sparse sample data and provide tighter 
constraints in assigning object membership to color-
space regions. Such precision is necessary to obtain the 
best results of optimum means, covariance and 
weighting possible from color-based pixel classification 
for qualitative segmentation requirements.  
We then see how to learn such a thing from data, 
and we discover that an optimization approach not used 
in any of the previous Andrew Tutorials can help 
considerably here. This optimization method is called 
Expectation Maximization (EM). We'll spend some 
time giving a few high level explanations and 
demonstrations of EM, which turns out to be valuable 
for many other algorithms beyond Gaussian Mixture 
Models. 
 1-D data for example in Fig 6, we can see that 2-3 
clusters occupy separate sub-space and the probability 
of mixture clusters reveals Gaussian like distribution. 
We can use EM algorithm to find out optimum mean, 
co variance and weighting value of each cluster. 2-D 
data for example in Fig 7 also can be estimated by EM 
algorithm. 
 
 
 
 
 
 
 
 
 
Fig 6. The compare of original 1-D data and GMM 
fitted. (a)The fitting 2 components of GMM. (b) The 
fitting 3 components of GMM. 
 
 
 
 
 
 
 
Fig 7. 2D data with 3-components of GMM fitted 
We applied 3-components Gaussian mixture 
models to the cluster of each race, Fig 8 for example. 
Each component of Gaussian model has its optimum 
mean, covariance and weighting which are obtained by 
EM algorithm. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
PDF created with pdfFactory trial version www.pdffactory.com
 6 
Thus using the Bayes formula we obtain the a 
posteriori probability of Cj, j=1, 2. It follows that the 
Bayes decision rule is then: 
              Choose C1 if ( 1 | ) ( 2 | )P C x P C x
® ®
>  
        Or more generally, index of chosen class = 
arg max ( | )
j
P Cj x
®  which is known as the maximum a 
posteriori decision rule. It must be noted that p(x) is not 
required for making the decision. Thus the decision 
rule becomes:  
arg max ( | ) ( )
j
P x Cj P Cj
® .  
Intuitively, the decision machine will make fewer 
mistakes when using more observations vectors. Thus 
in practice, multiple observation vectors are used: X= 
xi, i=1…n. Assuming that the observation vectors are 
independent and identically distributed (iid), then the 
joint likelihood is: 
1
( | ) ( | ) ( )
n
i
iP X Cj P Cj P Cjx
=
®
= Õ . 
       In practice, the true form of the pdf ( | )P X Cj  is 
unknown, hence a parametric representation,
~
( | )P X Cj , 
estimated from training data, is used instead. Since 
~
( | )P X Cj is only an approximation, a correction 
function, ( | )P X Cj
»
, is required. 
~
1
( | ) ( | ) ( | ) ( )
n
i
i iP X C j P C j P C j P C jx x
»
=
® ®
= Õ  
                         
 
 
        Taking into account the multiple observation 
vectors and rewriting arg max ( | ) ( )
j
P Cj x P Cj
®  into ratio 
test yields: 
Choose class =
~
~
~
~
( | 1) ( | 2) ( 2)1
( | 2) ( | 1) ( 1)
( | 1) ( | 2) ( 2)2
( | 2) ( | 1) ( 1)
P X C P X C P CC if
P X C P X C P C
P X C P X C P CC if
P X C P X C P C
»
»
»
»
>
<
 
       Due to precision issues in computational 
implementation, it is more convenient to use a 
summation rather than series of multiplications. Since 
log(.) is a monotonically increasing function, the 
decision rule can be modified to: 
Choose class =
~
~
( | 1) ( | 2) ( 2)1 log( ) log( )
( | 2) ( | 1) ( 1)
2
P X C P X C P CC if
P X C P X C P C
C if others
»
»>
 
which translates to: 
Choose class = 
~ ~ ( | 2) ( 2)1 log( ( | 1)) ( ( | 2)) log( )
( | 1) ( 1)
2
P X C P CC if P X C log P X C
P X C P C
C if others
»
»- >
 
Where, for clarity, ~ ~
1
log ( | ) log ( | )
n
i
iP X Cj P Cjx
=
®
= å  
Due to practical considerations described later, the 
number of observation vectors needs to be taken 
account.  
Choose class = 
~ ~1 1 ( | 2) ( 2)1 [log( ( | 1)) ( ( | 2)] log( )
( | 1) ( 1)
2
P X C P CC if P X C log P X C
n n P X C P C
C if others
»
»- >
 
Let us define 
~ ~1 1( | ) log( ( | )) log( ( | ))
n
i n
L X Cj P X Cj P x i Cj
n n
®
=
= = å  
This can be interpreted as the average log likelihood of 
X. Thus we can choose class = 
1 ( | 2) ( 2)1 ( | 1) ( | 2) log( )
( | 1) ( 1)
2
P X C P CC if L X C L X C
n P X C P C
C if others
»
»- >  
Let us define ( ) ( | 1) ( | 2)x L X C L X CL = -  
 
      Since the true form of the pdf p(x|Cj) is unknown, 
the correction function, ( | )P X Cj
»
, is also unknown; 
moreover, in real life situations the a priori 
probabilities P(C1) and P(C2) are often unknown. Thus 
in practice, 1 ( | 2) ( 2)log( )
( | 1) ( 1)
P X C P C
n P X C P C
»
»
 is replaced with an 
experimentally found threshold, t. 
Choose class = 1 ( )
2
C if x t
C if others
L >   , t=0, usually. 
 
       Strictly speaking, the normalization factor 1/n is 
not necessary to make a decision. However, in practical 
situations variable length observations are often 
encountered. Since ( )xL  is observation length 
independent, it allows the approximation of the 
distributions of ( )xL  for true clients and known 
impostors, which in turn simplifies the selection of the 
threshold. 
 
4.2 Block diagram of decision procedure 
 
 
 
 
 
 
PDF created with pdfFactory trial version www.pdffactory.com
