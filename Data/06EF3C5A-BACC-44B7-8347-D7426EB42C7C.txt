表 Y04 
 
三、 應用原理 
1  ART 
ART 是由 Grossberg 在 1976 年所提出的。
他將靜態的競爭式學習神經網路改變成為
具動態架構的神經網路，又引進了回授機
構（feedback mechanism），用以產生由上
而下的期望（top-down expectation），因此
神經元在贏得競爭之後還必須符合這個期
望，才有資格進行學習；此時，順向路徑
與回授路徑所產生的交互作用，會使得神
經元的輸出圖樣重複地出現，此即共振狀
態（resonant state），這個理論因而被稱為
適應共振理論。 
 
2 彈性可適尺寸結構(FAST) 
Pruning
<
<
Distance 
calculation
W T
Learning
Comparator
Comparator
Random Number 
Generator
Weight Vector Threshold
Cluster 
On/OffInput
圖 1、FAST 架構圖 
 
FAST 是由 Perez & Sanchez 在 1996 年 
所提出。它是一種非監督式學習類神經網
路，由 ART 衍生而來，可用來解決動態分
類 (Dynamic Categorization) 或稱即時分
群 (Online Clustering)的功能，且併入了
Alpaydin 所提出的動態警戒值 (Dynamic 
Vigilance Parameters) 觀念及即時刪除機
制(Online Pruning Mechanism) 的功能來實
現類神經網路分類。在 FAST 的類神經網
路中，每個神經元裡有一個 W (權重值) 與
外面鍵結、T (臨界值) 決定神經元感知域 
(Sensitivity Region) 大小。當有輸入樣本進
入時，會將每一筆的輸入樣本進行分類，
計算是進入那一個神經元的感知域；若此
輸入樣本不在感知域的範圍內，則新增一
個神經元產生新類別儲存此輸入樣本。樣
本進入類別時，動作中的神經元會依每次
學習後動態更新 W 及 T 值、並且若輸入樣
本一次進入多個類別時，會適當的對多個
有重覆感知域的神經元進行刪除的動作，
FAST 網路架構圖如圖 1 所示。 
1由圖 1中可得知當一筆輸入樣 P進入
運算時，會與來自 Learning 部份的神經元
中之方塊 W，也就是權重值 (Weight Vector) 
在 Distance中算出曼哈頓距離 ( )jWPD ,  (例
如平面上兩點的座標分別為 p1 在 (x1, y1) 
及 p2 在 (x2, y2), 則它們的曼哈頓距離為  
圖 2、FAST 神經元的中心點調整 
 
|x1 - x2| + |y1 - y2 | )，而此時方塊 W 及 T 會依
下列演算法進行更新： 
1. 首先計算出輸入樣本 P與 j個神經元間
的曼哈頓距離 ( )jWPD , 。 ( ) jiinij WPWPD −∑= =1,        (1) 
2. 若 ( )jWPD , 與每一個來自 Learning 部
份神經元的 T 值均比較過後，發現( ) jj TWPD >, ，則產生出一個新的神經
元 j + 1，並將此神經元初始化，它的
權重值為 Wj+1 = P、臨界值 T j+1 = Tini、
刪除機率初始值 Prj+1 = 1。 
3. 若， ( ) jj TWPD <, 則進入第 j 個神經
元，此時更新 jW 與 jT 值，更新公式如
下，  
( ) ( ) ( ))(1 tWPTtWtW jijjjiji −+=+ α    (2) 
( ) ( ) ( )( )min1 TtTtTtT jjj −−=+ γ     (3) 
   式中的 α 與 γ為 FAST 的學習常數 
4. 若此筆輸入資料同時進入好幾個類
別，則這些類別的刪除機率值 Pr 與亂
數產生器所產生的亂數(0~1)做比較，刪
去其中一個具感知域重覆性的神經
(a) (b)
(c) (d)
W0
P1 P2
P3 P4 = P1
W0＇
W0
W0 W0
W0＇
W0＇
表 Y04 
偏移。(d)表示當輸入樣本 P4 (實際上其值
與 P1 相同)輸入時，因中心點偏移太遠，已
落在 W0 神經元的接受域之外。致使系統無
法參考到之前的學習經驗，降低系統的控
制效能。故神經元的學習速率必須降低，
即式(2)中的α值不可太大，使 ARM 能夠明
確的將相似的類別做歸類，提供適當的歸
類結果給 Q 學習作為控制的依據。 
 
c 刪除機制 
 FAST 的刪除機制是由被激發的次數
來決定被刪除的機率：當激發次數越多，
被刪除的機率也就越高。但從原理得知，
越是經常被激發的神經元，最有可能被刪
除。導致系統一方面在刪除常用的神經元
時，很可能又會新增同樣的神經元，因而
造成系統的不穩定；另一方面其他不常用
的神經元卻不會被刪除，造成系統的資源
浪費。故我們重新擬定刪除的機制，將常
被激發的神經元保留住，將其他不常用的
神經元做刪除的動作。 
我們將刪除機制更改如下：當神經元
被激發時，則將此神經元的 Pr 值設為 1，
而未被激發的神經元的 Pr 值依(4)式更
新。我們設定神經元個數的上限為 K，當
神經元數達到 K 時，則啟動刪除機制，偵
測每個神經元的 Pr 值，當 Pr 值小於亂數
rnd 時，則將此神經元刪除。 
將 FAST 做以上的修正後，整個 ARM
的流程如下： 
1. 將輸入樣本 P 做正規化，如式(6)。 
2. 計算出輸入樣本 P與 j個神經元間的距
離差 ( )jWPD , 。 
3. 若 ( )jWPD , 與每個神經元的臨界值 T均
比較過後，發現 ( ) jj TWPD >, ，則產生
出一個新的神經元 j + 1，並將此神經
元初始化它的權重值為 Wj+1 = P、臨界
值 Tj+1 = Tini、刪除機率初始值 Prj+1 = 1 
4. 若 ( ) jj TWPD <, ，則歸類為第 j 個神經
元的類別，將 Prj設為 1，並更新 Tj 值，
更新公式如(2)、(3)。未被激發的神經
元依(4)式做調整。 
5. 當神經元達到 K 時，找出最小的 Prj
值，將此神經元刪除。 
6. 回步驟 1，等待下一筆輸入。 
 
2 修正的 Q 學習 
為了配合 ARM 的多狀態激發，故需要
將本來適用於單一激發狀態的 Q 學習做些
微修改。 
在選擇行為部分，原先的 BOX Q 只需
在被激發的 BOX 中從 Q table 挑選出最大
Q 值作為期望值 V 所採取的行為。在 ARM 
Q 中，我們在被激發的神經元中，根據
ARM 的曼哈頓距離 D 的大小當成計算期
望值 V 的權重值，曼哈頓距離 D 越小，所
佔的權重也越大。 
⎪⎩
⎪⎨
⎧
=
≠∑×−
∑ −
=
 . ,                                0.1
;  ,
)1(
1 when n 
  1nwhen
distancen
distancedistance
w
i
i  (7) 
 
其中， iw 是被激發的神經元 i 所佔的權重
值；而 n 是本次被激發的神經元數：
∑ distance 是所有被激發的神經元 distance的
和； idistance 是被激發神經元 i 的 distance。 
期望值 V 的計算方式如下： 
∑= ),(max asQwV ii
a
t           (8) 
其中 tV 為時間 t 時的期望值。而 Q 的更新
方式如下： 
)),(                  
(),(),(
1
1
asQwV
rasQasQ
tt
ttt
−
−
−×
++=
γ
β       (9) 
 
五、 模擬結果 
受控倒單擺系統的數學模型，如式 
(10) 與 (11)所示，我們以四階 Runge-Kutta
在個人電腦上進行模擬。 
]
cos
3
4[
]
)sgn(sin
[cossin
2
2
mm
m
l
mlmm
xmlF
g
c
t
tp
c
cttt
tt
t
+−
−+
+−−+
= θ
θµµθθθθ
θ
&&&
&&
   (10) 
mm
xmlF
x
c
tcttttt
t +
−−+= )sgn(]cossin[
2 &&&&&& µθθθθ   (11) 
 
式中 g 為重力常數 9.8 m/s2；mc為馬達重 1 
kg；mp 為桿重 0.1 kg；l 為桿長的一半，也
就是 0.5 m；µp 為桿對馬達的摩擦係數；µc 
為馬達對軌道的摩擦係數；Ft 由控制器送
出的力。在此模擬中，我們忽略摩擦力，
以理想的真空狀態來進行模擬，而推力以
正負 10 牛頓為單位。 
我們將模擬方式訂定如下：將倒單擺
進行 500 次測試，而每次測試如下：倒單
擺初始角度為 0 度，滑車初始位置為 0m。
當倒單擺的角度超過正負12度或是滑車位
