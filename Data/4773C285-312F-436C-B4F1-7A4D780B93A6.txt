 
英文關鍵詞： 2D to 3D, Colonoscopy, Optical flow, Depth image 
based rendering 
 
 2 
可供推廣之研發成果資料表 
□ 可申請專利  □ 可技術移轉                                      日期： 年 月 日 
國科會補助計畫 
計畫名稱：三維大腸鏡系統研發(1/3) 
計畫主持人：蔣以仁 
計畫編號：NSC100-2221-E-038-009 學門領域：資訊二 
技術/創作名稱  
發明人/創作人  
技術說明 
中文：  
英文： 
可利用之產業  
及  
可開發之產品  
 
 
技術特點 
 
推廣及運用的價值 
 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
※  
 4 
provide a visual diagnosis on the inner lining 
of patients’ rectum and colon not only to find 
out ulcers, polyps, tumors, and areas of 
inflammation or bleeding, but also grants the 
opportunity for biopsy or removal of 
suspected colorectal cancer lesions. If cancer 
is already present, finding it early, before it 
causes symptoms or spreads, can increase 
your chances of a full recovery [3,4]. 
Colonoscopy is a highly sensitive, fully 
structural screening examination on the 
continuous “fly-through” images of the entire 
colon interior in the procedure of intravenous 
sedation [5]. Minimally invasive surgery 
(MIS) by using 3D larparoscopic 
examination has already demonstrated to be 
useful for most appendectomy, gastric bypass, 
gallbladder removal, and several others [6,7]. 
Stereoscopic endoscopy [8,9] with two CCDs, 
two light bulbs, and the biopsy channel, 
provided a computer- implemented stereopsis 
(visual depth through seeing with both eyes) 
and dynamic exploration (being able to 
continuously change one’s viewpoint with 
respect to the objects in real- time) has proved 
to be very useful for surgeons to investigate 
symptoms, execute treatment [10], and 
significantly beneficial to anatomical 
learning, especially for subjects of low 
visual-spatial ability [11]. The main aim of 
this research is to develop a 3D colonoscopy 
system directly reconstructing 3D images 
from 2D fly- through images from the 
original one CCD camera colonoscopy. 
In order to design a colonoscopic 2D to 
stereo 3D conversion, we are based on the 
binocular disparity to build our algorithm. 
Animals gather information derived from the 
different projection of objects onto each 
retina of their eyes to judge depth. To obtain 
a high degree of accuracy by triangulating 
the distance to an object from two images of 
same scene obtained from slightly different 
angles. As seen in Figure. 1, the binocular 
disparity to an object perceived by the brain.  
If done properly, greatly improving the 
immersive effect while viewing stereo video 
in comparison to 2D video.  However, the 
conversion should be done with sufficient 
accuracy and correctness. To recover surface 
geometry, the visual system must correctly 
classify features as tither disparities or 
half-occluded regions. 
 
 
Figure 1 [13]. The nearer surface differentially  
occludes the more distance surface in the two eyes, 
which generates features that are visible to only one of 
the two eyes (“half-occlusions”). The red line in the 
figure delimit the regions of the more distance surface 
visible to the right eye, and the blue lines delimit  the 
regions visible to the left  eye. The surface regions 
visible to both eyes support disparity computations 
whereas the half-occluded regions do not. 
 
The stereo method of binocular vision to 
capture information of an object in 3D vision 
based on disparity among number of images 
[12,13].  Disparity refers to the difference in 
the visual direction of two or more points in 
space. When two points are situated at 
different depths from the observer, their 
angular separation will be different in the two 
eyes. The difference between these 
separations is the disparity of images features, 
which can be used to infer their depth.  To 
compute disparity, the visual system has to 
determine which features in the two eyes 
correspond to a common surface feature in 
the 3D world. 
 
二、Methods and Results 
  The depth information is the missing 
information that is important to be 
reconstructed from monocular image/video 
input and synthesizes virtual stereoscopic 
view.  A lot of depth generation methods 
[14-20] were proposed to retrieve the depth 
map from different kind of image/video. To 
perfectly recover the real depth is still 
difficult. However, in terms of 2D-to-3D 
conversion, a pseudo 3D can be generated by 
perceptual depth. 
 6 
colonoscopy tube in colon is steady and 
almost constant, which create the depth 
perception. We use depth perception to build 
depth map for the continuous images 
gathered from colonoscopy. 
 Our experiences have tested on single 
colon image and multiple consecutive colon 
images.  Anaglyph 3D method has been 
used to generate stereoscopic 3D effect 
encoding each eye’s image using filters of 
chromatically opposite colors (red and blue). 
The visual cortex of the brain fusses this 
image through the “color-coded” glasses into 
perception of 3D scene. Viewing anaglyphs 
through spectrally opposed glasses or gel 
filters enables each eye to see independent 
left and right images from within a single 
anaglyphic image. 
 
 
(a) 
 
(b) 
Figure. 5. A colon image snap-shot from colonoscopy. 
 
Consider two colon images (Figure. 5) 
snap-shot from colonoscopy.  Figure. 6 
demonstrates the images results converted 
from anaglyph 3D method, individually. For 
non-moving video display, anaglyph images 
are suitable. Even more advanced 3D 
solutions are available. So far, anaglyph 
images provide a cheap and comfortable way 
to view scientific visualizations. 
 
 
(a) 
 
(b) 
Figure. 6. A red-cyan anaglyph colon image from 
Figure. 5. 
 
 Consider two eyes’ images shown in 
Figure.7. A 3D scene images on them are 
shown in Figure. 8. 
 
 
(a) 
 8 
De Maio, Comparison of the stress response after 
laparoscopic and open cholecystectomy, Surg 
Endosc, 14:1136-41, 2000. 
7. H. R. H. Patel, M. J. Ribal, M. Arya, R. 
Nauth-Misir, and J. V. Joseph. Is it worth 
revisiting larparoscopic three-dimensional 
visualizat ion? A validated assessment. Urology, 
70(1): 47-49, 2007. 
8. H. Becker. 3D endoscope with optical switch and 
prism arrangement. 1997, US Patent 5944655. 
9. T. Susumu. Stereoscopic endoscope. 1993, US 
Patent 5557454.. 
10. M. F. Catalano, J. V. Dam, R. Bedford, R. M. 
Cothren, and M. V. Sivak Jr. Preliminary  
evaluation of the prototype stereoscopic 
endoscope: precise three-dimensional 
measurement system. Gastrointestinal Endoscopy, 
39(1):23-28, 1993. 
11. J. Luursema, W. Verwey, P. Kommers, and J. 
Annema. The role of stereopsis in v irtual 
anatomical learning Interact. Comput.  20, 
455-460, 2008. 
12. T. Hu and M. Huang. A  new stereo matching 
algorithm for binocular v ision. International 
Journal of Hybrid Information Technology, 3(1), 
2010. 
13. B. L. Anderson. Stereovision: beyond disparity 
computations. Trends in Cognitive Sciences, 2(6): 
214-222, 1998. 
14. Y. J. Jung, A. Baik, J. Kim, and D. Park. A novel 
2D-to-3D conversion technique based on relative 
height depth cue. Proceedings of SPIE, 2009. 
15. Q. Wei. Converting 2D to 3D: A Survey. 
Information and Communicat ion Theory Group, 
Delft University of Technology, the Netherlands, 
2005. 
16. J. Ko, M. Kim and C. Kim. 2D-To-3D 
Stereoscopic Conversion: Depth-Map Estimation 
in a 2D Single-View Image. Proceedings of SPIE, 
Vol. 6696, 2007. 
17. S. Battiato, A. Carpa, S. Curti and M. La Cascia. 
3D Stereoscopic Image Pairs by Depth-Map 
Generation. Proceedings of 3DPVT, 2004. 
18. W. Tam and L. Zhang. 3D-TV Content 
Generation: 2D-To-3D Conversion. Proceedings 
of IEEE ICME, 2006. 
19. S. Valencia and R. Dagnino. Synthesizing Stereo 
3D Views from Focus Cues in Monoscopic 2D 
Images. Proceedings of SPIE, 2003. 
20. Y. Matsumoto, H. Terasaki, K. Sugimoto, and T. 
Arakawa, “Conversion system of monocular 
image sequence to stereo using motion parallax,” 
SPIE Photonic West 3012, pp. 108–115, 1997. 
21. S. Moezzi, A. Katkere, D. Y. Kuramura, and R. 
Jain. Immersive v ideo. In: Proceedings of the 
1996 Virtual Reality Annual International 
Symposium. Silver Spring, MD: IEEE Computer 
Society Press; 17–24, 1996. 
22. R. Szeliski. Rapid  octree construction from image 
sequences. CVGIP: Image Understanding. 
58(1):23–32, 1993. 
23. R. Carceroni, and K. Kutulakos. Mult i-view scene 
capture by surfel sampling: from video streams to 
non-rigid 3D motion, shape & reflectance. In: 
Proceedings of the Seventh International 
Conference on Computer Vision, IEEE Press, 
60–7, 2001. 
24. S. Würmlin, E. Lamboray, M. Gross. 3D video 
fragments: dynamic point samples for real-t ime 
free-v iewpoint video. Computers & Graphics. 
28:3-14,2004. 
25. D. Kim, D. Min, and K. Sohn. A stereoscopic 
video generation method using stereoscopic 
display characterization and motion analysis . 
IEEE Trans. Broadcasting, 54(2):188-197, 2008. 
26. K. N. Ogle. Researches in binocular vision. W. B. 
Saunders, Oxford, England, 1950.
The Report of IPHIE 2012 program 
I-Jen Chiang 
Graduate Institute of Biomedical Informatics  
Taipei Medical University 
 
 
The IPHIE is defined as “an international initiative on forming a cooperation for 
students’ and teachers’ exchange between dedicated programs in health and medical 
informatics.”  The IPHIE partnership was established in 1998, consisting of several 
famous institutes (their names and ranks are listed in Table 1). 
 
Table 1. The partnership of IPHIE 
 
 
QS2010 QS2011 ARWU2010 ARWU2011 
AMC, University of Amsterdam 56 63 101-150 101-150 
UMIT Austria N/A N/A N/A N/A 
Universities of 
Heidelberg/Heilbronn 51 53 63 62 
University of Minnesota 96 102 28 28 
University of Utah 306 288 82 79 
University of Washington 55 56 16 16 
 
Activities include yearly Master classes, workshops on International Medical 
Informatics Congresses and active exchange of both students and faculty among 
IPHIE partner universities.  A two-week long Summer School has taken for advanced 
medical students from all over the world.  Taiwan is the first time to have an 
institute to be invited to join IPHIE partnership with those high-rank health and 
medical informatics institutes.   
 
After a long flight, we arrived at Minneapolis.  After taking one day off, we 
registered and joined the partnership workshop.  We are proud that all partners 
suggest TMU to host the IPHIE 2014 and continue our contribution to the 
international society because our faculties and students (Figure 1) who joined IPHIE 
2012 are able to show our great contributions on medical informatics in our country 
and some other developing countries.  Besides, all partners of IPHIE 2012 are willing 
to be sister school with us due to we demonstrated a complete and different HIT 
experiences to the IPHIE partners and such experiences can properly provide some 
 Figure 2. The IPHIE 2012 schedule 
 
presentations include Taiwan HIT in patient participation, “Overcrowding in 
Emergency Departments of Taiwanese Hospitals – The Impact of Demographic 
Changes” , and “Using Mobile Health Information Technology in Resource-Poor 
Setting: An Experience of Taiwan Medical Mission in African Country” that 
mentioned about the Lab Push and Swazi-EMR. 
 
All the faculties of IPHIE (Figure 3) in those few days were collaborated to discuss 
some issues: the trend and important issues of HIT, the continued work of IPHIE, and 
so on. Some important concepts have been established. The IPHIE faculties will 
continue to contribute their effects on the development of Healthcare and Medical 
Inofrmatics. 
procedural training and assessment needs of medical professionals  through 
leadership in the use and development of simulation resources.  A 3D simulation 
environment (Figure 5 and Figure 6) associated with some special Hollywood effects, 
such as blood, temperature, pulse, and so on, let the trainees much more close to 
real-world situations. A lot of simulated scenes assist trainees face to different 
challenges and then overcome them.  By the way, the aspects of trainees just 
provide good judgments and evaluations for them to fine tune themselves gradually.  
That will enable them to become qualified physicians. 
 
 
Figure 5. Laparoscope operation 
 
The Report of IPHIE 2012 program 
I-Jen Chiang 
Graduate Institute of Biomedical Informatics  
Taipei Medical University 
 
 
The IPHIE is defined as “an international initiative on forming a cooperation for 
students’ and teachers’ exchange between dedicated programs in health and medical 
informatics.”  The IPHIE partnership was established in 1998, consisting of several 
famous institutes (their names and ranks are listed in Table 1). 
 
Table 1. The partnership of IPHIE 
 
 
QS2010 QS2011 ARWU2010 ARWU2011 
AMC, University of Amsterdam 56 63 101-150 101-150 
UMIT Austria N/A N/A N/A N/A 
Universities of 
Heidelberg/Heilbronn 51 53 63 62 
University of Minnesota 96 102 28 28 
University of Utah 306 288 82 79 
University of Washington 55 56 16 16 
 
Activities include yearly Master classes, workshops on International Medical 
Informatics Congresses and active exchange of both students and faculty among 
IPHIE partner universities.  A two-week long Summer School has taken for advanced 
medical students from all over the world.  Taiwan is the first time to have an 
institute to be invited to join IPHIE partnership with those high-rank health and 
medical informatics institutes.   
 
After a long flight, we arrived at Minneapolis.  After taking one day off, we 
registered and joined the partnership workshop.  We are proud that all partners 
suggest TMU to host the IPHIE 2014 and continue our contribution to the 
international society because our faculties and students (Figure 1) who joined IPHIE 
2012 are able to show our great contributions on medical informatics in our country 
and some other developing countries.  Besides, all partners of IPHIE 2012 are willing 
to be sister school with us due to we demonstrated a complete and different HIT 
experiences to the IPHIE partners and such experiences can properly provide some 
 Figure 2. The IPHIE 2012 schedule 
 
presentations include Taiwan HIT in patient participation, “Overcrowding in 
Emergency Departments of Taiwanese Hospitals – The Impact of Demographic 
Changes” , and “Using Mobile Health Information Technology in Resource-Poor 
Setting: An Experience of Taiwan Medical Mission in African Country” that 
mentioned about the Lab Push and Swazi-EMR. 
 
All the faculties of IPHIE (Figure 3) in those few days were collaborated to discuss 
some issues: the trend and important issues of HIT, the continued work of IPHIE, and 
so on. Some important concepts have been established. The IPHIE faculties will 
continue to contribute their effects on the development of Healthcare and Medical 
Inofrmatics. 
procedural training and assessment needs of medical professionals  through 
leadership in the use and development of simulation resources.  A 3D simulation 
environment (Figure 5 and Figure 6) associated with some special Hollywood effects, 
such as blood, temperature, pulse, and so on, let the trainees much more close to 
real-world situations. A lot of simulated scenes assist trainees face to different 
challenges and then overcome them.  By the way, the aspects of trainees just 
provide good judgments and evaluations for them to fine tune themselves gradually.  
That will enable them to become qualified physicians. 
 
 
Figure 5. Laparoscope operation 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2013/02/19
國科會補助計畫
計畫名稱: 三維大腸鏡系統研發
計畫主持人: 蔣以仁
計畫編號: 100-2221-E-038-009- 學門領域: 醫學資訊
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
獲邀至 6th Anniversary of World Cancer Congress (WCC-2013) May 23 to May 
25, 2013 in Xi＇an, China 及 BIT＇s Major Diseases Clinical Summit-2013 
held in Warsaw, Poland from November 5-7, 2013 專題演講. 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
