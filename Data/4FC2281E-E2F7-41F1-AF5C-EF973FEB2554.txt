 2 
 
中 文 摘 要 
本研究為三年期的計畫，計畫目的在於提出一個適用於大範圍網路（亦即涵蓋
許多公司或單位的網路）的資安警訊分享與警訊關聯分析機制，此機制一方面可以
讓一般公司或個人放心地提供資安警訊給外面的資安管理專業單位（即使該公司對
後者不具信賴關係也無妨），另一方面就是允許後者在對除掉敏感資訊後的警訊仍能
進行分析並將分析結果回饋給警訊提供者。本計畫第三年的重點在於提出可彈性符
合資訊安全隱私政策之警訊分享機制。企業將公司內部產生的警訊交給資訊安全營
運管理中心 (Security Operation Center，以下簡稱 SOC) 處理，難免會暗藏一些公司
內部網路資訊，因每家企業的資訊安全政策不同，所要求的隱私防護程度也不同，
所以如何提供一個可隨企業安全政策不同而調整的警訊分享機制，便成為一個很重
要的安全議題。針對此議題，本研究探討對資安警訊封包標頭做模糊化隱私防護處
理，進而評估警訊封包經處理後影響因素，包括警訊封包 IP 位址模糊化轉換區間大
小與警訊關聯性，警訊封包隱私防護與原始警訊封包資訊的資訊含量 (entropy) 變
化關係，以及警訊封包模糊化後的警訊關聯能力。本研究透過將原始警訊封包的 IP
位址資訊模糊化來計算警訊封包經隱私防護後的資訊含量，再由 SOC 警訊關聯分
析。本研究提供量化指標讓企業依據資訊安全政策可彈性調整其警訊內容隱私防護
程度以達到隱私保護與警訊關聯正確性之間的最佳平衡。 
 
關鍵字：警訊分享、隱私保護、警訊關聯、資訊安全政策 
 
 4 
 
目錄 
中文摘要------------------------------------------------- 2 
英文摘要 ------------------------------------------------ 3 
目錄 ---------------------------------------------------- 4 
一、 前言 ----------------------------------------------- 5 
 
二、 相關研究  
2.1. 資訊隱私防護--------------------------------------------- 7 
2.2. 警訊關聯 ------------------------------------------------ 7 
 
三、 研究方法 
3.1. 警訊封包 IP位址模糊化轉換區間方法------------------------ 9 
3.2. 評估警訊資訊含量 (Entropy)------------------------------- 9 
3.3. 警訊經模糊化後之關聯 ------------------------------------- 10 
 
四、 實驗與結果分析  
4.1. 模擬攻擊警訊---------------------------------------------12 
4.2. 實驗分析-------------------------------------------------12 
 
五、 結論與未來研究方向 ----------------------------------15 
 
參考文獻 ------------------------------------------------ 16 
 
附錄 A: -------------------------------------------------18 
國際會議論文『Outsourcing Data Mining Tasks to Cloud While 
Preserving Customer Privacy 』 , Proc. Of 2010 Business 
Intelligence And Data Warehouse, Singapore, July, 2010.  
 
附錄 B: -------------------------------------------------28 
國際會議論文『TLMS: A Novel DRM Scheme for Multimedia 
Sharing in P2P Networks』, Proc. of the Fifth International 
Conference on Intelligent Information Hiding and Multimedia 
Signal Processing (IIHMSP-2009), Kyoto, Japan, September,  
2009  
 
 6 
圖一的警訊封包模糊化處理是指落在某一區間的 IP 值都以某一代表值來取
代，如此就讓若干個不同的 IP值變為相同，從資訊理論來說，就指指這些封包的資
訊含量降低。顯然地，資訊含量低的封包產生的關聯勢必較原本的封包產生的關聯
來得不精確，因此我們可用圖二來表達 IP轉換區間、資訊含量與關聯正確性間的關
係，如圖二。當分享者隱私保護安全政策門檻提高 ，例如：其警訊封包模糊化轉換
區間由 20改變為 45，相對模糊化後的警訊資訊含量會由 5減至 2，其警訊關聯正確
率則從 99.18%降至 97.53%。我們假設每個網路都有如圖二這樣的特性曲線，若我們
事先得可得知每個網路的特性曲線，則分享者可依資訊安全政策彈性調整對警訊封
包內容模糊化程度。 
 
圖二：警訊模糊化後關聯分析指標 
 
本報告分為五節與兩個附錄，第二節簡述相關參考文獻與技術，第三節介紹本
研究對警訊模糊化方法之關聯能力分析。第四節為實驗結果分析，最後於第五節列
出結論與未來研究方向。兩個附錄都是由本計畫所補助的相關研究，成果都已發表
在國際會議上。 
 8 
條件規則建立不完整，將造成關聯錯誤，因此影響關聯警訊結果好壞，關鍵在於因果
條件建立的完整與否。只針對事先建立攻擊情境中的攻擊行為做關聯警訊，面對未知
的攻擊手法並未能建立攻擊情境的行為，無法找出其警訊關聯性。 
第二種為計算警訊相似程度方法分析警訊關聯 [17]，藉由警訊特徵資料進行警
訊特徵相似度的計算，並且利用機器學習或資料探勘的方式，找出有關聯性之警訊，
經由找出的規則，再進一步對應到欲做關聯的警訊，從大量警訊中找出有關聯的警訊。
此類型透過警訊特徵相似程度進行關聯，但因警訊資料集出現頻率的差異性與未出現
過的攻擊，關聯分析時會被忽略，進而影響警訊關聯的結果。 
在上述警訊關聯技術，無論是利用機器學習或資料探勘，或是事先建立的攻擊情
境或條件等方式，目的皆為找出有警訊之間關聯性，但除了警訊對應的名稱關係外，
尚需考慮警訊含有的特徵資訊，例如 Source IP、Destination IP、Port 、攻擊類型及時
間等資訊，皆需要對警訊之間的資訊做相似程度的比對或計算，才能找出正確有關聯
的警訊。於此本研究將採近似於因果關聯分析概念，其確保警訊關聯結果的正確性。 
警訊隱私防護與關聯分析相關研究中，各學者所探討警訊封包標頭之隱私屬性如
何透過匿名方法達到保護效果，並且進行關聯分析。然而相關研究中皆未探討警訊內
容隱匿程度與警訊關聯分析之間影響關係，缺乏量化指標參數，分享者該對警訊資料
模糊化多少，對警訊關聯分析的結果影響為何?本研究將提出量化評估指標，使分享者
能透過量化指標參數調整警訊匿名程度。 
 10 
多，模糊化程度較低。本研究將針對警訊封包標頭 IP 位址做資訊隱匿處理，由來源
與目的 IP位址可分析出分享者連線位址內容，因此將 IP位址視為一敏感屬性欄位，
將部分資訊隱匿尚可保有效資訊供日後分析警訊關聯。 
接著將以 Entropy (2) 式的定義，分別計算出 Src_IP 和 Des_IP 屬性的資
訊含量值。由原始警訊經模糊化處理後可得到 Src_IP 與 Des_IP屬性其資訊含量，再
將兩屬性 Entropy做加總即可代表由原始警訊資料經模糊化處理後資訊含量，本研究
將個別屬性資訊含量總和作為整體警訊資訊含量代表。 
若將警訊模糊化轉換區間 r設為 100，資訊含量為 0.63；r設為 60，資訊含量
為 0.99。警訊經模糊化處理以 Entropy 評估得到的資訊含量值，當轉換區間較小，
其 Entropy值較大，表示含有原始警訊資訊較高，反之，則代表含有原始警訊資訊較
低，以此資訊含量評估對事後警訊關聯正確有何影響。 
 
3.3  警訊經模糊化後之關聯 
 
SOC目的將各種資安裝置所收集得到大量低階警訊做過濾關聯處理。由於我們所
研究的警訊是經過模糊化處理，因此警訊屬性資料透過轉換區間方式來達到隱匿資
訊效果，與一般原始警訊有所差異。然而警訊關聯分析採用近似因果關係推論方式，
藉由警訊封包內容的 IP來源與目的位址屬性欄位，尋找其多步驟攻擊的警訊關連。
當第 i 筆警訊目的 IP時間與第 j 筆警訊時間差小於 t 秒之內，而第 j 筆警訊來源
IP 與第 i筆警訊目的 IP相同，即視為一攻擊警訊關聯 。 
然而將所有資料逐一尋找關聯，最後將與原始警訊所找到的關聯警訊進行比
對，以便取得正確警訊關聯數量。以簡易規則判斷警訊關聯是否正確如下表 I。 
 
表 I .  警訊關聯判斷規則 
True Positive 
(TP) 
原始警訊有關聯，模糊化後警
訊也有關聯 
False Positive 
(FP) 
原始警訊沒有關聯，但模糊化
後警訊卻有關聯 
True Negative 
(TN ) 
原始警訊沒有關聯，模糊化後
警訊也沒有關聯 
False Negative 
(FN ) 
原始警訊有關聯，但模糊化後
警訊卻沒有關聯  
 
經由警訊關聯規則計算警訊關聯的誤報 (FP) 與漏報 (FN) 及正確警訊關聯 
(TP) 數量，便可以計算警訊模糊化後警訊關聯的正確率 (3) 式與誤報率 (4) 式如
下。 
 
 
 P. F. P T
P. T
     Rate     Precision 

  
(3) 
 12 
 
 
四、實驗結果分析 
4.1  模擬攻擊警訊 
 
本研究可針對各種資安設備警訊資料做隱私防護處理，並且將其警訊屬性欄位
正規化，進行後續關聯處理需求，自行設計符合所需情境，設計模擬程式來產生實驗
資料集。 以下圖三簡述模擬攻擊警訊程式流程。 
 
模擬攻擊警訊程式流程 
Input：攻擊 IP 為 W個來源 IP、弱點 IP 為 H個、隨機亂數間隔 T
秒發動攻擊 
Output: 產生 M 筆警訊資料記錄 
Process:  
1.  隨機亂數產生 H個弱點 IP  
2.  For( i = 0 ~ W) 
     2.1 隨機亂數產生來源 IP 
     2.2 亂數產生間隔 T秒，為下個攻擊發生時間; 
        3. 目的 IP以亂數機率決定： 
          3.1 有 P的機率以同一個 C class 的 IP為跳板 
          3.2 有 Q的機率以不同 class C 的 IP為跳板 
          3.3 有 (1 – P − Q) 的機率則以外部 IP 為跳板 
if ( 目的 IP == 弱點 IP) then 
儲存攻擊警訊記錄； 
將目的 IP設為來源 IP； 
隨機亂數產生時間戳記; 
End if 
     End for 
4. 重複執行步驟 1~3，將攻擊封包依序處理 
圖三：模擬攻擊警訊程式流程 
 
實驗首先透過模擬攻擊程式個別模擬產生 20萬、10萬和 5萬個 Source IP 攻
擊的資料集，然而模擬攻擊參數不同所模擬產生資料量有所差異。為產生較多攻擊警
訊，將弱點 IP參數設定為 32,768 個。模糊化轉換區間範圍從 1到 255，在此無法逐
一實驗，則分別以 30、60、100和 200為不同警訊模糊化轉換區間設定參數值，最後
以因果警訊關聯方法進行關聯分析。 
 
4.2 實驗分析 
 
 14 
勢線的準確性，R2 值是介於 0 與 1 之間的數字，當趨勢線的 R2 值等於或接近 1，
則此時趨勢線為最可靠。將趨勢線放到資料上時，Excel 會自動根據公式計算其 R2
值。若要得到最正確的預測結果，必須選擇最適合資料的趨勢線。 警訊模糊化後評
估資訊含量對警訊關聯正確是關鍵影響因素。如分享者將模糊化區間設定為 60，則
資訊含量值為 4.4，其警訊關聯正確率 98.79%，警訊關聯誤報率 2.39%。 
  
(a) Entropy與 Range指數函數 
 
(b) Entropy 與 Precision rate 多項式函數 
  
(c) Entropy 與 False alarm rate 多項式函數 
圖七：Entropy與 Range (a)、Precision rate (b)、 False alarm rate (c) 
  
由實驗結果可知警訊封包內容模糊化轉換區間方法的可行性，且透過模擬攻擊
警訊產生測詴資料，加以驗正警訊經過隱匿處理尚還可保有資訊進行警訊之間關聯分
析，然而原始警訊與模糊化警訊透過關聯分析結果進行比較。例如：分享者將警訊模
糊化轉換區間為設 30，其 Entropy 值落於 6.3，相對應的警訊關聯分析正確率為
99.3%；若分享者因資訊安全政策改變，隱私防護需求提高，必須調整對警訊模糊化
轉換區間設定較大值為 200，則轉換後警訊的 Entropy 值落於 1.5，警訊關聯正確率
為 98.7%。警訊 IP 位址轉換區間小，使得警訊的 Entropy 值較大，其意指含有原始
警訊資訊較高，進行警訊關聯所得到的 Precision Rate會較高，而警訊的 False Alarm 
Rate 較小；反之，當轉換區間設定較大，所得到的模糊化警訊資訊含量相對較低，
如圖二。 
 16 
 
 
參考文獻 
[1] 樊國楨、林樹國、歐崇明，“資安監控中心之終極目標：資訊分享與分析中心初探”，
資通安全分析專論T95002，2006。 
[2] 曾俊豪、陳奕明，“具隱私防護與分析能力之網路封包酬載轉換機制”，台灣網際
網路研討會 (TANET)，2009。 
[3] 林昶志，“具隱私防護與關聯能力之資安警訊轉換機制研究”，國立中央大學資訊
管理學系碩士論文，2008。 
[4] 陳玉佩，”可調適符合資安隱私政策之大範圍網路警訊分享機制”， 國立中央大學
資訊管理學系碩士論文，2010。 
[5] S. E. Coull, C. V. Wright, A. D. Keromytis, F. Monrose, M. K. Reiter, “ Taming the Devil: 
Techniques for Evaluating Anonymized Network Data,” In Proceedings of the 15th 
Annual Network and Distributed System Security Symposium, 2008. 
[6] B. Ribeiro, W.Chen, G. Miklau, D. Towsley, “Analyzing Privacy in Enterprise Packet 
Trace Anonymization,” In Proceedings of the 15 th Network and Distributed Systems 
Security Symposium, 2008. 
[7] M. Burkhart, D. Brauckhoff, E.  Boschi, “The risk-utility tradeoff for IP address 
truncation,”  Conference on Computer and Communications Security , Proceedings of 
the 1st ACM workshop on Network data anonymization, 2008. 
[8] J. King, “A Taxonomy, Model, and Method for Secure Network Log Anonymization,”  
Master's Thesis, University of Illinois at Urbana-Champaign, Apr., 2008.  
[9] R. Ramaswamy, T. Wolf, “High-Speed Prefix-Preserving IP Address Anonymization for 
Passive Measurement Systems,” IEEE/ACM transactions on NETWORKING,  Vol. 15, 
No. 1, 2007. 
[10] P. Ning, Y. Cui, D. S. Reeves, “Constructing Attack Scenarios through Correlation of 
Intrusion Alerts,” in Proceedings of the 9th ACM Conference on Computer & 
Communications Security, Nov.  2002. 
[11] U. Flegel, “Privacy-Respecting Intrusion detection,” Vol. 35 in Advances in Information 
Security, Springer, Page(s):107-325, 2007. 
[12] L. Sweeney, “k-anonymity: A model for protecting privacy,” International Journal on 
Uncertainty, Fuzziness and Knowledge-based Systems, 2002. 
[13] G. Loukides, J. Shao, “Capturing Data Usefulness and Privacy Protection in 
K-Anonymisation,”  SAC07, March 11-15, 2007. 
[14] R. C. W. Wong, J. Li, A. W. C. Fu, K. Wang, “(α,k)-Anonymity: An 
Enhanced-Anonymity Model for Privacy-Preserving Data Publishing,”  KDD’06, 
2006.  
[15] D. Xu, P. Ning, “Privacy-Preserving Alert Correlation: A Concept Hierarchy Based 
Approach,” Annual Computer Security Applications Conference, 2005. 
                                                                                      
 
附錄 A:  
國際會議論文『Outsourcing Data Mining Tasks to Cloud While Preserving Customer 
Privacy』, Proc. Of 2010 Business Intelligence And Data Warehouse, Singapore, July, 
2010.  
                                                                                      
 
To resolve the issues mentioned above, many 
methods have been proposed for privacy 
preserving data mining in recent years. The 
proposed methods can be classified into three 
categories: data hiding, data perturbation and 
secure multiparty computation. With data hiding, 
the sensitive data are removed from the data 
before the data sent to the cloud. It is hard to 
justify how much information should be removed. 
Too much information removed may lead to the 
useless of the mined results. With data 
perturbation methods [4], under the restriction 
that the statistical properties of the data are 
retained, the raw data is modified by adding 
random noise so that it no longer reveals privacy 
related information. The disadvantage of these 
methods is that they may have unpredictable 
impacts on data mining precision. On the other 
hand, secure multiparty computation[5][6] works 
only in distributed data sharing environment 
where multiple parties participate in a protocol so 
as to share their own pieces of private data, and 
cooperate to get the final results. This approach 
has the drawback of high computational cost that 
has discouraged its widespread adoption in most 
large-scale data mining tasks. 
In contrast to the three approaches mentioned 
above, in this paper, we propose a BKM 
approach which has the following characteristics: 
1. Without the use of cryptographic encryption. 
So that no complicated key management is 
necessary in our approach. 
2. Promise of complete privacy. It means neither 
the cloud service provider nor other clients can 
learn the contents of a client’s private data.  
3. Keeping as much as possible of information to 
be mined by cloud. This is different from some 
privacy preserving approach which just mask 
out some data from the cloud. 
4. The knowledge mined from the transformed 
data is as general as possible, so that it can be 
adapted to various applications in the client 
side. 
Our idea is to use the bloom filter to transform 
the source data sent from clients. Then all of the 
transformed data are sent to the cloud to be 
mined in which the transformed data are 
clustered. With the clusters of transformed data 
and the statistics within each cluster are feed 
backed to the clients, the clients can compare the 
transformed data with its original data, then 
he/she can learn more of  the overall picture of 
the whole data. 
Some previous works, such as [7][8] and [9],  
also use the bloom filters in their model, but their 
purpose are different from us. For example, in [7], 
its model is used to mine the frequency term set 
of a transaction database. Furthermore, it assumes 
the central database server and the client belong 
to the same organization and the central database 
contains all of the source data of clients. In [9], 
the central database, like our design, also stores 
the transformed data. But the purpose of its 
database is to support user queries while 
protecting the details of the queries. This is 
different from our model, for our model is not 
used for database query, but to be used in cloud 
computing services where the service providers 
provide the aggregated statistic data to the clients 
to use. 
The organization of this paper is divided into 5 
sections. In Section 2, we briefly introduce the 
key mechanisms of our model: bloom filter, 
K-means and Maximal Frequent Term Set 
(MFTS). Section 3 formally defines the problem, 
gives assumptions and presents the design of 
mechanisms which implements our approach. To 
validate our idea, two experiments with a set of 
security alerts adopted from the DARPA dataset 
are presented in Section 4. In Section 5, we make 
conclusion and give some future research 
directions. 
BACKGROUND 
 Bloom Filter 
Bloom ﬁlter [10] is a computationally efﬁcient 
hash-based probabilistic scheme that can 
represent a set of objects with minimal memory 
requirements. Given an n-element set S  = 
{s1,s2 , … , sn}and k hash functions H1,H2,…, Hk 
of range m, the Bloom ﬁlter of S, denoted as B(S), 
is a binary vector of length m that is constructed 
                                                                                      
 
frequent term set (MFTS), if S is frequent term 
set and for∀(R ⊆ T∧ S ⊆ R) , Supp(R) < 
min_supp. 
The MFTS are clustered based on the 
K-mismatch. The k-mismatch term set of term set  
is defined as follows: 
 
 
 
 
Figure 2: Operations of BKM model 
For example, let P= {140, 115, 83, 254, tcp}, Q= 
{140, 83, 254, tcp, smtp},R= {115, smtp, pop3, 
110} and k is 2, then Q is P’s k-mismatch term 
set because Q only has one term “smtp” that 
doesn’t present in P, but R is not P’s k-mismatch 
term set. Longer term sets which contain more 
terms may indicate more specific topic, so the 
supporting documents are more likely belonged 
to one cluster. The algorithm iteratively picks the 
longest term set P, group P and P’s k-mismatch 
term sets into a cluster and then remove P and P’s 
k-mismatch term sets from MFS. When the 
length of remained longest term set is less than a 
threshold h (usually k=2k), the procedure is 
terminated. 
BKM MODEL 
The purpose of our model is to allow each client 
to contribute his/her owner data to the cloud and 
get the new information generated by the cloud, 
which has the privilege to obtain all data from 
every client, so has the overall  picture  of the  
whole data which is impossible to be owned by 
any one client. All of these operation are under 
one strict restriction: no client’s privacy should 
be leaked during the process. 
Take Figure 2 as an example, assume Client A, B, 
and C has a set of security alerts respectively. 
After they send data to the cloud and the cloud do 
mining task on these data, they may discover 
some information that he/she doesn’t know 
before. For example, a minor attack type 
occurred in the networks of client A in fact has 
prevailed in the networks of other clients. This 
information implies that his/her network is well 
defended against this attack type or the attacker 
has not targeted at his/her network. In either 
                                                                                      
 
that a . There are m
r+1
 
possible such sequences. 
4. Do hash function ha with ha(x) = 
 mod m  
After obtaining the 44 bits, we further transform 
the 44 bits string to a string of integers for 
K-means and MFTS algorithms are more easily 
to process  string of integers than a string of 0s 
and 1s. Figure 3 shows  a transformed example. 
Step 2: K-means operation 
As we have described in the assumption, the 
cloud know the number pattern types Kw of the 
whole data. So when the cloud get the 
transformed date from client, it starts to do the 
k-means operation as described in Section 2. 
Figure 4 shows a K-means operation example 
where the value of K is assumed to be 7. 
 
Figure 3. Transform bloom filter 
to decimal intergers  
 
Figure 4: The operation results of 
K-means 
From Firgure 4 we can see that all 
the same or similar transformed data are 
clutered into the same group,  so that 
we can use the MFTS to find the longest 
common pattern in each group.  
Step 3: Use MFTS to find out the common 
pattern in each group 
As we have transformed the bit string into 
decimal integers, it is easy to apply the MFTS to 
find out the common pattern in each group which 
are clustered in Step 2.  Figure 5 is one example 
of this operation. 
 In a data set to be processed by MTFS, every 
data in data set should be clustered into different 
groups and the transformed data in the same 
group could be extracted their common pattern. 
For example, in Figure 
{5,2,1,2,x,8,8,x,1,1,0,x,1,3,2} is the longest 
common pattern in Group 7. The operation of 
MFTS is as follows: 
 If we set k=3 in Group 1(refer to Figure 5), 
MFTS will set the first data 
{0,13,10,8,10,4,2,0,0,0,2} as an anchor point to 
start the search of  the longest term set, as the 
second data item,  {0,13,11,8,10,2,2,0,0,0,2}, 
has only two terms, ”11”、”4”,  different, so the 
MFTS will start search again from the second 
data until the end of data. In this example , MFTS 
find the last data has 3-mismatch , so the longest 
term set is {x,13,11,8,10,x,x,0,0,2}.  
 
Figure 5: Using MFTS to find out 
the common pattern in each group 
EXPERIMENTS 
To validate the usefulness of our proposed 
                                                                                      
 
Table 4. Analysis result with Data set D2 in 
Experiment 1    
14 attack types Proportion 
of original 
alerts  
Proportion 
of cloud 
mining 
Correction 
ratio 
2,1,11,3,8,X,X,4,12,11,X 
(pod) 
5% 2% 63% 
X,2,1,11,12,X,1,X,6,3,12 
(satan) 
4% 3% 58% 
X,3,X,12,10,X,X,0,X,1,2 
(multihop) 
5% 3% 69% 
14,X,X,3,4,16,X,X,1,3,12 
(teardrop) 
6% 12% 70% 
16,X,X,5,6,19,22,X,X,1,X,3 
(perl) 
6% 2% 58% 
12,3,14,X,1,X,9,X,7,11,X 
(portsweep) 
5% 9% 62% 
X.X.11.4.3.X.X,1,7,8,10 
(smurf) 
6% 3% 67% 
X,13,11,8,10,X,X,0,0,2  
(nmap) 
10%  7% 65% 
X,1,2,2,X ,X,0,2,1,X,1,0 
(ipsweep) 
5%  11%  71% 
X,8,3,8,8,X,3,3,0,0,X 
(BOF) 
11%  7%  69% 
2,X,X,X,9,0,6,0,6,1,0 
(GuessPassword)  
11%  8%  57% 
4,6,7,X,3,0,0,1,X,X,X (FTP 
Write) 
5%  12%  67% 
X,1,X,5,X,3,1,2,4,12,10 
(spy) 
9%  1% 70% 
3,12,3,X,X,1,1,0,0,12,X 
(rootkit)  
11%  19%  71% 
 
The purpose of Experiment 2 is to investigate that 
if the cloud service provider doesn’t know the 
exact number of attack types, what the effects of 
the wrong guess of k values? 
In Table 5 and Table 6, the average correction 
ratio is defined as the average correction ration of 
all groups while the false classification ration = 
1-correction ratio.  
Table 5. Analysis result of Experiment 2 using 
Data set D1 
D1 K 6 7 8 
Average correction 
ratio 
57% 76% 63% 
Average false 
classification ratio 
43% 24% 37% 
 
Table 6.Analysis result of Experiment 2 using 
Data set D2 
D2 K 13 14 15 
Average correction 
ratio 
44% 63% 59% 
Average false 
classification ratio 
56% 37% 41% 
 
From above two tables, we can find that if the K 
is not correct, either lower or higher than the 
correct one, the classification correction results 
will be drop. The lower value is worse than the 
higher value because some minor attack type (i.e. 
the attack type that has less number of alerts) 
might be classified to some other group which 
will decrease the correct ratio of all groups. 
Therefore, the application of BKM is more 
suitable to the pre-known value of data types.  
CONCLUSION 
How to preserve the privacy of 
customers in the cloud computing era 
has become an important issue. In this 
paper, we present an approach which 
allows clients to use the benefits of cloud 
computing while without worrying about 
the leakage of privacy. This is achieved 
by the bloom filter which is performed in 
the client side. Accompanied by the 
K-means and MFTS techniques applied 
in the cloud site, the clients can obtain 
the mined results without the 
disadvantages of previous work, such as 
the complex encryption and key 
management. The contributions of this 
paper are as follows: 
1. A new approach in data clustering in 
cloud computing has been proposed. 
2. A framework to implement the data 
clustering with the property of privacy 
preservation has been presented. 
3. The proposed approach has been tested by 
two experiments of security application. 
The results give a promising application 
of this approach. 
28 
 
 
附錄 B:  
國際會議論文『TLMS: A Novel DRM Scheme for Multimedia Sharing in P2P Networks』, 
Proc. of the Fifth International Conference on Intelligent Information Hiding and 
Multimedia Signal Processing (IIHMSP-2009), Kyoto, Japan, September,  2009 
30 
 
Abstract 
 
A Three Layer Multimedia Sharing (TLMS) for managing access right of user in a P2P network is proposed in this 
paper. The features of TLMS include: 1) a novel DRM scheme for P2P networks, 2) a digital content protection without the 
need of an on-line server, and 3) low communication and computation cost. In addition to introducing the operation of 
TLMS model, we also compare its performance and security with Zhang et al’s design in the context.. 
Keywords—P2P, DRM, Group Key, Threshold Scheme, Digital Content Sharing  
 
1. Introduction 
 
As multimedia content can be efficiently distributed among peer users, using Peer-to-Peer (P2P) 
network communication to distribute large volume contents have increased in recently years [3]. 
However, P2P file sharing is infamous for copyright infringement. Therefore, several papers talked 
about Digital Right Management (DRM) on P2P network have been published [1-2, 6-7] to address 
these issues for achieving more functionality. This authors of [6] categorizes three types of DRM for 
P2P network. The first type uses existing DRM system architecture. In other words, this type of 
architecture only uses P2P networks for content distribution. The second type is distributed P2P 
architecture. In this architecture, although all of the DRM functions are executed by the peer node, for 
the reason of encapsulation permits and content flow control, a static DRM server is needed. The third 
type is semi-distributed P2P architecture. It is similar to distributed P2P architecture. But user 
authentication functions exist on the DRM server for the sake of greater security. Unfortunately, both 
[2] and [6] only talk about the system architecture; little is discussed with respect to the DRM 
mechanism. 
Recently, Zhang et al. [7] proposed a novel scheme based on an asymmetric key algorithm to implement DRM 
mechanisms in BitTorrent (BT). They give a detail about the operation of DRM on BT. But as they adopt the asymmetric 
key approach and either encryption or decryption must link up with Tracker Site (TS) to obtain keys. Their DRM solution 
would be inefficient and the TS may become a bottleneck when the number of peer users increased. 
To overcome the problems of related work mentioned above, this paper proposes a three layer scheme which uses the 
Group Diffie-Hellman (GDH) protocol to generate a group key (First Layer) for protection of Shadow Key (Second Layer), 
which in turn can recover Master Key (Third Layer) to allow peers in a group to secretly share multimedia stream. 
Considering the dynamic nature of P2P networks where peers come and go frequently, we extend the traditional GDH 
protocol for efficiency.  
The remainder of this paper is organized as follows. Section 2 briefly introduce Zhang et al.’s scheme. Section 3 
introduces our scheme. In Section 4, we compare the performance of our schemes against Zhang et al. [7] and analyze the 
various aspects of security in our scheme. Finally, we conclude this paper and indicate future research directions in Section 6. 
 
2. Zhang’s  Scheme 
 
Figure 1 shows Zhang’s scheme and their proposed protocol for a transmission of the digital 
content between peers. The components are similar to those in a typical original BT system, except 
that there is a peer table maintained by the TS to different peer and different pieces of file. For 
32 
 
Step 2. Digital content encryption: the CP generates Master Key (a random number). To protect Master Key, the CP 
uses Shamir A.’s (t, n) threshold scheme [4] to hide Master Key by shadow key which is generated for each registered 
peers. The details of these operations are described in Section 3.2.  
Step 3. Group Key Agreement: Peers generate Group Key to protect Shadow Key. The reason why and how to generate 
group key are described in Section 3.3. 
Step 4. Digital content accessing: After receiving encrypted digital content from other peers, the receiving peer can use 
Group Key to retrieve Shadow Key. With Shadow Key, the peer can recover the Master Key to decrypt the protected 
contents. The details are described in Section 3.4. 
 
3.2 Shadow Key Generation 
 
Let KDCj be the secret Master Key of jth piece of digital content (Notated as DCj for abbreviation) and is randomly 
generated by the CP.  
First, CP generates KDCj  for DCj to be shared among peers. Second, the CP choses a large prime p. Third, the CP 
selects t−1 random, independent coefficients a1,DCj, … , at-1,DCj, 0 ≤ aj,DCj≤ p−1, to define the random (t − 1) degree 
polynomial f (x) over GF(p).  In other words, fj (x) = ∑ ai,DCj x
i
, where 0 ≤ i ≤ t-1. So for digital content DCj, it will have a 
polynomial as below: 
 
fj(x) = at-1,DCj x 
t-1 + at-2,DCj x 
t-2 + … + a1,DCj x + a0,DCj mod p 
……  (1) 
Here we assume a constant term a0,DCj = KDCj 
 
Finally, assume every peer user Ui has distinct identified number U.  The CP computes the Ui’s Shadow Key of DCj, 
si,DCj = fj(U) mod p, (1 ≤ Ui ≤ p−1). 
 
Example 1: Assume U1, U2, U3 and U4  are registered in CP to purchase DC2, popularity value t 
1 is set to 3 and 
Master Key is 13. Then, the CP selects 2 random numbers: 2 and 10. Then for DC2, we can generate 2 degree polynomial 
f2(x) according to (1) as follows: 
  
f2(x)=2 x
2+10 x
1+13 mod 17 
 
Suppose the identified U1=1, U2=2, U3=3 and U4=5, respectively, then their Shadow Keys are computed by the 
polynomial functions:  
 
s1,DC2 = f2(1) mod 17=8 
s2,DC2 = f2(2) mod 17=7 
s3,DC2 = f2(3) mod 17=10 
s4,DC2 = f2(5) mod 17=11 
 
                                                 
1 Popularity value t means there are at least t peers on-line so that they can exchange digital content. 
34 
 
group key GKn = α(n+CP ).  
  
3.4 Digital Content Accessing 
 
When a peer Ui wants to access the digital content DCj, he/she follows the steps 
Step 1: Derive a Group Key 
In the step 4 of last subsection, Ui  got α(n+CP－i) from CP, so by powering α(n+CP－i) with Ni, 
Ui can obtain the GKn which is equal to α(n+CP). 
Step 2: Retrieve Shadow Keys 
Using group key to make an exclusive operation with Ø  si,DCj and α(n+CP) to derive the Shadow 
Keys.  
 
Ø  si,DCj≨GKn≨α(n+CP)
 
= Ø  si,DCj  
=si,DC1 || si,DC2 || si,DC3||…. || si,DCj ..........(2) 
 
Step 3: Using Shadow Keys to derive the Master Key KDCj for the digital content DCj.  
Any group of t or more users provides t distinct points (x, y) = (Ui, si,DCj) allowing computation of 
the coefficients ak,DCj , 1 ≤ k ≤ t−1 of fj(x) by Lagrange interpolation. The secret is recovered by noting 
fj(0)=a0=KDCj. 
The coefficients of an unknown polynomial fj(x) of degree less than t, defined by points (xi, yi), 1 ≤ i 
≤ t, are given by the Lagrange interpolation formula:  
 
 
 
Since fj (0) = a0 = KDCj, the Master Key may be expressed as:  
 
 
 
 
Example 2: Based on example 1, Any 3 users in (1,8), (2,7), (3,10), (5,11) can re-acquire polynomial f2(x). Suppose 
(1,8), (2,7) and (5,11) are selected, f2(x) is acquired as following: 
 
 
 
 
 
 
Step 4: Decrypt encryption message 
A legal peer user decrypts these messages EKDCj(Bjm) to obtain m streaming media blocks Bjm of 
digital content DCj. Here EKDCj(Bjm) is secure symmetric cryptosystem using the secret key KDCj to 
 
 


t
i
ijtj ji
j
i p
X
Xx
yxf
1
,1
mod
X
)(
 
 

t
i
ijtj ji
j
iDCj p
X
X
yfK
1
,1
mod
X
)0(
17mod13102
)3)(1)(8(11)5)(1)(4(10)5)(3)(8(8
8
)3)(1(
11
4
)5)(1(
10
8
)5)(3(
8
)35)(15(
)3)(1(
11
)53)(13(
)5)(1(
10
)51)(31(
)5)(3(
8
17mod
X
)(
2
111
1
,1
























 
xx
xxxxxx
xxxxxx
xxxxxx
X
Xx
Yxf
t
i
ijtj ji
j
i
36 
 
Need an on-line Authentication Server Tracker Site  Not Need 
Adjustable on-line member access. Not Solved Yes, presents the popularity value t. 
Cryptography Asymmetric encryption 
using TS key and secret key 
Symmetric encryption using group key and 
shadow key 
Computation costs High Low 
 
5. Conclusions 
 
In this paper, we propose a Three Layer scheme for Multimedia Sharing (TLMS) among a closed 
group of users within P2P networks. This scheme is derived from the GDH protocol. But considering 
the varied popularity of different multimedia content, we extended the conventional GDH by Shamir’s 
(t, n) threshold scheme in the protection of Master Key. Compared with  Zhang et al.’s research, our 
advantages includes: an on-line authentication server is unnecessary, adjustable on-line member access 
and lower computation costs. Our future research direction includes more detailed comparison of our 
scheme with traditional DRM technologies and the adaptation of a BT program to implement this 
scheme. 
 
6. References 
 
[1] C-C Chu, X. Su, B.S. Prabhu, R. Gadh, S. Kurup, G. Sridhar and V. Sridhar, Mobile DRM for Multimedia Content Commerce in 
P2P Networks. IEEE CCNC. 2:1119-1123 (Jan. 2006). 
[2] T. Iwata, T. Abe, K. Ueda, H. Sunaga, A DRM system suitable for P2P content delivery and the study on its implementation. The 
9th Asia-Pacific Conference on Communications. 2:806-811 (2003). 
[3] S. G. M. Koo, C. S. G. Lee, and K. Kannan, "Using P2P to distribute large-volume contents - research problems, solutions and 
future directions," in Proceedings of the 9th World Multi-Conference on Systemics, Cybernetics and Informatics (WMSCI 2005), 
Orlando, FL, July 10-13 2005. 
[4] A. Shamir, How to share a secret. Comm. ACM. 22:612-613 (1979). 
[5] M. Steiner, G. Tsudik and M. Waidner, CLIQUES: A New Approach to Group Key Agreement. ICDCS 380-387 (1998) 
[6] Jae-Youn Sung, Jeong-Yeon Jeong, Ki-Song Yoon, "DRM Enabled P2P Architecture", The 8th International Conference Advanced 
Communication Technology 2006, Vol 1, pp.487-490 
[7] X. Zhang, D. Liu, S. Chen, and R. Sandhu, Towards Digital Rights Protection in BitTorrent-like P2P Systems. In the 15th 
SPIE/ACM MMCN (2008). 
雖然這是他第一次在國際會議以英文發表，而且會議廳頗大(約可容納 150 人，參見下面
圖二各論文報告人在 session 開始前的準備情形），但是幸好該場會議主持人是中央警察
大學資管系的王旭正教授，在他幽默輕鬆的主持氣氛下，消除了大部分上台報告者面對
大量聽眾以及用英語發表的緊張。由於主持人嚴格控制每篇論文只能使用 15 分鐘時間，
所以吳威震先生報告完後，由於時間已用完，當場並無聽眾提出問題。倒是本人利用此
次參加會議機會聽到一些有趣的研究成果，例如一篇題目名稱為『Adaptation of 
Agent-based Non-Repudiation Protocol for Mobile DRM』的論文，因為也是和探討 DRM
有關，雖然該論文是應用在行動網路和吾人論文應用於 P2P 網路不同，但仍引起本人的
興趣。作者正好是國內開南大學的歐崇明教授，本人在會議當場雖然沒有時間仔細發問，
會後卻有不少時間向其請教相關的密碼協定問題，感覺收穫良多，有不虛此行之感。 
 
 
圖一：IIHMSP 2009 會場門口，由本人與博
士生吳威震先生合照。 
圖二：會議開始前，各論文報告人事先上
載投影片至大會電腦。 
 
大會在 9 月 13 日晚上舉行晚宴，現場除舉行頒發最佳論文獎等活動之外，主辦單位
還特別安排日本茶道表演，並邀請現場來賓參與，可以說是藉此國際研討會順便為日本
文化又做了一次成功的宣傳。 
 
二、與會心得 
本次會議除了台灣本身有不少學者參加之外，大陸有更多學者與會，例如此次大會的
三位 Keynote speaker 之中，就有一位大陸浙江大學的譚建榮教授做『Multimodal 
Information Fusion in the Virtual environment and Its Applications in Produce 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/11/14
國科會補助計畫
計畫名稱: 下一代具有隱私保護與攻擊情境預測能力之大範圍網路安全防禦機制研究
計畫主持人: 陳奕明
計畫編號: 96-2628-E-008-008-MY3 學門領域: 資訊安全
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
