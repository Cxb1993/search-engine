 
 
 
 
行政院國家科學委員會專題研究計畫成果報告 
題目: 針對 (巡迴型與非巡迴型) 屬性樹的通用計算系統 (第三年度) 
計畫編號：NSC 96-2628-E-009 -014 -MY3 
執行期限：96 年 8 月 1 日至 99 年 7 月 31 日(第三年度) 
計畫主持人：楊武教授       國立交通大學資訊工程學系 
 
Abstract 
There are many automatic code 
generation techniques for a compiler. A 
tree-pattern matching algorithm with 
dynamic programming called BURS is 
one of the most popular. However, in 
this project, pattern matching is 
performed as a parsing process for code 
generation. The set of 
machine-instruction patterns are 
expressed as production rules in an 
instruction grammar, which is a 
context-free grammar. A generalized LR 
(GLR) parser is used to do the matching 
work with the transformed instruction 
grammar since the grammar is usually 
ambiguous. Each pattern rule in the 
transformed grammar is equipped with a 
numeric cost. This cost criterion is used 
to select a least-cost parsing among all 
the legal parsing results and is also used 
to reduce the overhead of the parsing 
process. 
中文摘要 
編譯器設計的文獻上有許多產生
指令的技術藉以產生指令，其中又以 
BURS 技術為代表，BURS 技術使用
樹狀範本來比對 IR ，藉以產生指
令。本研究使用文法剖析的技術，藉
以產生指令。Processor的 Instruction set 
architecture 以指令文法來描述，但是
一般的指令文法都是模糊文法，所以
必須用推廣型的文法剖析演算法來處
理，我們發展了一套推廣型的文法剖
析演算法，並且將其製作於著名的
Bison程式內，由此產生一套推廣型的
文法剖析器，並將此文法剖析器嵌入
於 CVM (嵌入式系統的 Java Virtual 
Machine)，以進行各項實驗，實驗結果
甚佳。 
 
1. Introduction 
There are many automatically code 
generation techniques for a compiler. A 
tree-pattern matching algorithm with 
dynamic programming called BURS is 
one of the most popular. However, 
pattern matching can be performed 
alternatively with a parsing procedure. 
We investigate this parsing alternative 
for automatic code generation in this 
project. 
An instruction grammar, which is a 
context-free grammar, is used  
matching with dynamic programming. 
Its dynamic programming can be done 
when its code generator is constructed at 
compile-compile time.  
When a BURS code generator is 
constructed, the BURS tree automaton is 
also constructed. The tree automaton is a 
state-transition machine that can be used 
to find out an optimum instruction  
sequence through looking up in a BURS 
table based on each IR node’s operator 
information and its all children’s state 
information at run time. 
At run time, BURS needs two passes 
over the IR trees. The first pass uses a 
bottom-up traversal over the IR to assign 
a numeric state to each IR node. Each 
numeric state can represent the set of 
possible partial and full rules matches of 
the subtree rooted at the IR node. This 
first pass can recognize the optimal 
instruction sequence by labeling the tree 
with dynamic programming information. 
The second pass uses a top-down 
traversal over the IR trees to generate an 
optimal target-platform code based on 
information gathered in the first pass. 
 
3. GLR parser algorithm 
In this section, we will describe our 
GLR parser. 
3.1 Choose Bison as the Basis 
In the implementation of our GLR 
parser, we modify Bison, which is a 
parser generator, as the basis to develop 
our GLR parser.  
Bison has its own ability to handle 
ambiguous grammars. So its standard 
LR parser does not need to solve the 
ambiguity problem. However, we want 
the parser to try out all possible parsing 
of the input. Bison is modified to 
generate a general parser. 
 
3.2 Our GLR Parsing Algorithm 
The modified Bison builds a 
two-dimensional array called 
ActionTable, which maintains the input 
grammar’s finite-state machine. Other 
implementation techniques in our GLR 
parser are described in the following 
paragraphs: 
(a)Maintaining each stack’s top 
There exists a data structure called 
FrontierSet , which contains each parse 
stack’s top in the GSS. For each element 
of FrontierSet, the related  
parse stack will be viewed as an 
independent parse stack and will be 
processed by our GLR parser one by 
one. 
(b)A Pair of Numbers and 
ParentArray 
A pair of numbers (state_num, 
state_count) is used to address each 
node in the GSS, and an array called 
ParentArray is used to maintain the 
parent-child relationship among the 
nodes 
(c)Rule List 
Since we want to find out the 
least-cost parse stack among all the 
parse stacks, maintaining each parse 
stack’s executed rules is needed. So, an 
adjacency list called RuleList is used to 
maintain each parse tree’s executed rules 
29.       } 
30.       FrontierSet=TempSet; 
31.       if (T is the last token in the input string) break; 
32.    } 
33. }   
 
34. int DoReduceAction(state_number S1, token T) 
35. { 
36.    Search the entry ActionTable[S1, T] to find what the reduce rule R  
should be executed; 
Add the rule R into this parse stack’s RuleList; 
37.    NT：＝ Left hand side non-terminal of rule R; 
38.    L：＝ the length of Right hand side of rule R ; 
39.    for i：＝1 to L { 
40.       Use the ParentArray to find the state S1’ s parent state P; 
41.       S1：＝ P; 
42.    } 
43.    Search the entry ActionTable[P, NT] to find out the  
new stack-top state S2. 
44.    Add the new parent-child relationship “S2 is P’s parent”  
to the ParentArray; 
45.    return S2; 
46. } 
Figure 2 GLR parser’s algorithm
In the above GLR parser algorithm, the 
code between line 25 to line30 is the 
R/R conflict-solving procedure, which 
will be described in detail later. 
 
3.3 Cost Concept 
When our GLR parser parses an input 
sentence according to an instruction 
grammar, more than two parse trees may 
exist at the same time. Then, a cost 
mechanism is provided to make a choice 
between them. 
A numeric cost is added to each rule 
in the input grammar. Each rule’s cost 
may represent the instruction counts or 
machine cycles for the rule’s generated 
machine instructions or other reasonable 
measurements of the generated code. 
These numeric costs can help our GLR 
parser to calculate each parse tree's total 
cost and then a minimal-cost parse tree 
can be chosen. 
 
3.4 Conflict-solving Techniques 
If an input grammar is ambiguous, 
there may be many S/R and R/R 
conflicts in the parse table of the 
grammar. So, a new approach is 
Output: If one of G‘s S/R conflict can be solved, the S/R conflict can be solved by 
the shift action or the reduce action. 
Method:  
1. PreprocessSRconflict(G)                                           
2. { 
3.   for each S/R conflict in LR(1) parse table {                                             
5.      int Flag := -1;  // Flag=0 represents shift action, Flag=1 represents reduce action. 
6.       int Flag2 := -1;  
7.  Find out all of the corresponding shift rules and reduce rules;   
8.  for each shift rule RuleS do { 
9.     if (Flag2 == 0) break; 
10.     for each reduce rule RuleR do { 
11.        if (Flag2 == 0) break;  
12.        for each parent rule RuleP of RuleR do {  
13.           Compare RuleS’s RHS symbols with RuleP’s RHS symbols,   
from left to right to see if each two symbol is the same. If not, 
stop comparing; 
14.           Symbol1 := RuleP’s symbol; 
15.           Compare RuleS’s RHS symbols with RuleP’s RHS symbols,                
from right to left to see if each two symbol is the same. If not 
the same, stop comparing; 
16.           Symbol2 := RuleP’s symbol; 
17.           if (Symbol1 == Symbol2) { 
18.              if (Symbol1 == RuleR’s LHS non-terminal) { 
19.                 Use the RuleR’s RHS to replace that LHS non-terminal   
in RuleP’s RHS;           
20.              } 
21.           } 
22.           if (ruleS’s RHS == RuleP’s RHS) { 
23.              if (RuleS’s LHS non-terminal = RuleP’s LHS non-terminal  
               or one non-terminal can become the same with another 
through using chain rules or  
the two can become the same through using chain rules) 
24.              { 
25.                 Flag2 :=1; 
26.                 Calculate all the shift action’s rules’ total costs; 
27.                 Calculate all the reduce action’s rules’ total costs; 
28.                 if (shift action’s cost <reduce action cost) { 
CVM’s JIT compiler. CVM is a Java 
virtual machine suited for embedded 
environments. It includes a JIT compiler 
to speed up the execution of the Java 
program. CVM runs in an embedded 
Linux on the Andes platform. Figure (4) 
describes the JIT compiler’s architecture. 
The JIT grammar is the so-called 
instruction grammar. 
Since we want to use our GLR 
parser to do instruction selection, we 
integrate it into the CVM’s JIT 
compiler’s back-end to replace its 
original BURS-instruction-selection 
mechanism. Figure (5) describes this 
situation the overall structure. 
 
 
 
 
 
 
 
 
Figure 4 JIT Compiler’s original architectur 
 
 
the rules) are the same as those 
generated by the JIT compiler. That is, 
the JIT compiler already generates the 
best code sequences.  
For the second experiment, we record  
 
the runtime of our GLR parser when it  
processes each test case without any 
conflict-resolution technique and with 
one and/or two solving techniques 
turned on, respectively. Since our GLR 
parser’s mechanism is based on string 
pattern matching, not tree-pattern 
matching, it does not work on IR-tree, 
but on IR string. So before each test case 
is fed into our GLR parser, we should 
transform each test case’s original IR 
tree into an IR string through the 
preorder traversal of the IR tree. This 
experiment is done in the PC with CPU 
3.4GHz, memory 2GB, and OS is 
Ubuntu. 
 
 
Total 
Time 
Total Time with 
R/R technique 
Total Time with 
S/R technique 
Total Time with S/R 
+R/R technique 
Test Case 1 
 
25.43 15.73(61.86%) 
(No R/R conflict) 
15.73(61.86%) 
 
15.73 (61.86%) 
(No R/R conflict) 
Test Case 2 
 
783.65
 
516.64(65.92%) 
 
783.65(100%) 
(No S/R conflict) 
516.64(65.92%) 
(No S/R conflict) 
Test Case 3 127.55 99.42(77.94%) 111.61(87.5%) 84.32(66.1%) 
Test Case 4 84.37 
 
54.3 (64.36%) 
 
84.37 (100%) 
(No S/R conflict) 
54.3 (64.36%) 
(No S/R conflict) 
Test Case 5 92.62 77.37 (83.53%) 73.94(79.83%) 57.3 (61.87%) 
5. Conclusion   
The application of the Generalized LR 
parsing algorithm is expanded into the 
area of code generation. When 
processing the test cases, our GLR 
parser generates the same instruction 
sequences as the BURS-based approach.  
From the results of the second 
experiment, we find out our 
conflict-resolution techniques can 
decrease the parsing time. But the 
techniques still need improvements. The 
future work of this part can focus on 
analyzing more grammars, trying to find 
out more S/R conflicts that can be 
processed at build time, and 
transforming (part of) the R/R 
conflict-resolution technique’s work into 
build time.  
 
References 
[1]Alfred V. Aho, Mahedevan Ganapathi, 
and Steven W. K. Tjiang. “Code 
generation using tree matching and 
dynamic programming”, ACM 
Transactions on Programming 
Languages and Systems, 
11(4):491-516, October 
1989. 
[2]Eduardo Pelegri-Llopart. Rewrite 
Systems, “Pattern Matching, and 
Code Generation”, Ph.D. Thesis, 
參加 2010 年第五屆 ICSOFT 國際會議 會議報告 
 
 
國立交通大學資訊工程系 
 
楊武 
 
中華民國九十九年七月二十九日 
 
 
一、 參加會議經過 
  本年度(二零一零年) 第五屆 International Conference on Software and Data 
Technologies 國際會議 (ICSOFT 2010)於民國九十九年七月二十二日至二十四日在希臘
雅典市的 University of Piraeus 舉行。ICSOFT 2010 會議的主題囊括五大主題: 
Enterprise Software Technology 
Software Engineering  
Distributed Systems 
Data Management 
Knowledge-Based Systems 
領域橫跨近年來從學術到產業界軟體工程與分散式系統的研究與發展，而除了核心的技
術議程(Program)外，同時有兩項 workshops 同時舉行(Architectures, Concepts and 
Technologies for Service Oriented Computing (ACT4SOC) 及 Data Management and 
Information Analytics (DMIA))。該兩項 workshops 在星期五同時同地舉行，各有論文
發表。 
此外，本次會議邀請五位專家學者發表主題演說(Keynote speech)，包括 Peri 
Loucopoulos (Loughborough University, U.K.) 、Stephen J. Mellor (Freeter, U.K.) 、
David Marca (University of Phoenix, U.S.A.) 、Nikolaos Bourbakis (Wright State 
HEAP GARBAGE COLLECTIONWITH REFERENCE COUNTING
Wuu Yang, Huei-Ru Tseng, and Rong-Hong Jan
Computer Science Department, National Chiao-Tung University, Hsinchu, Taiwan, Republic of China
wuuyang@cs.nctu.edu.tw, hueirutseng@googlemail.com, rhjan@cs.nctu.edu.tw
Keywords: closed cluster; cyclic garbage; depth-first search; graph theory; garbage collection; reference count
Abstract: In algorithms based on reference counting, a garbage-collection decision has to be made whenever a pointer
x→ y is about to be destroyed. At this time, the node y may become dead even if y’s reference count is not
zero. This is because y may belong to a piece of cyclic garbage. Some aggressive collection algorithms will
put y on the list of potential garbage regardless of y’s reference count. Later a trace procedure starting from
y will be initiated. Other algorithms, less aggressive, will put y on the list of potential garbage only if y’s
reference count falls below a threshold, such as 3. The former approach may waste time on tracing live nodes
and the latter may leave cyclic garbage uncollected indefinitely. The problem with the above two approaches
(and with reference counting in general) is that it is difficult to decide if y is dead when the pointer x→ y
is destroyed. We propose a new garbage-collection algorithm in which each node maintains two, rather than
one, reference counters, gcount and hcount. Gcount is the number of references from the global variables and
from the run-time stack. Hcount is the number of references from the heap. Our algorithm will put node y on
the list of potential garbage if and only if y’s gcount becomes 0. The better prediction made by our algorithm
results in more efficient garbage collectors.
1 INTRODUCTION
Garbage collection algorithms can be classified into
two broad categories: (1) some algorithms mark all
live nodes and consider the rest as dead and (2) oth-
ers attempt to identify dead nodes directly. Tradi-
tional mark-sweep-compact collectors (Fischer and
LeBlanc, 1991) belong to the first category. This ap-
proach suffers from the long interrupt to normal com-
puter operations because the entire virtual memory
must be examined. Given today’s increasingly large
virtual memory, the interrupts become quite intolera-
ble.
Algorithms in the second category make use of
other information, mostly reference counts of various
kinds, to identify dead nodes directly (Collins, 1960;
Jones and Lins, 1996). Usually, there is a counter in
every node in the heap which keeps the number of ref-
erences that point to that node. When a node’s counter
falls to zero, it becomes a piece of garbage.
A problem with reference counting is that cyclic
garbage is difficult to collect. In addition to exam-
ining nodes’ counters, a part of the virtual memory
still needs to be scanned in order to identify cyclic
garbage.
In algorithms based on reference counting
(Collins, 1960; Jones and Lins, 1996; Lins et al.,
2007), a garbage-collection decision has to be made
whenever a pointer x→ y is about to be destroyed. At
this time, the node y may become dead even if y’s ref-
erence count is not zero. This is because y may belong
to a piece of cyclic garbage.
The problem with the above two approaches (and
with reference counting in general) is that it is dif-
ficult to decide if y is dead when the pointer x→ y
is destroyed. We propose a new collection algorithm
in which each node maintains two, rather than one,
reference counts, called gcount and hcount. Gcount
is the number of references from the global variables
and from the run-time stack. Hcount is the number
of references from the heap. Our algorithm will put
node y on the list of potential garbage if and only if
1. global int currentrun := 0;
1. procedure CalculateCC(x : node)
2. currentrun := currentrun+1;
3. d f sdead(x); /* x is the starting node, i.e., the root
of the dfs tree. */
4. hcount(x) := hcount(x)+1;
5. search(x);
6. hcount(x) := hcount(x)−1;
7. collect(x); /* The collect call is optional. */
8. end CalculateCC
1. procedure d f sdead(y : node)
2. if lastvisit(y)< currentrun then begin
3. /* This is the first visit to node y. */
4. lastvisit(y) := currentrun;
5. β(y) := 1;
6. if gcount(y) = 0 then begin
7. status(y) := dead; /* Assume y is dead
initially. */
8. for each outgoing edge of y (say y→ z) do
d f sdead(z);
9. end
10. else begin /* gcount(y)> 0, which means y is
definitely live. */
11. status(y) := live;
12. for each outgoing edge of y (say y→ z) do
d f slive(z);
13. end
14. else β(y) := β(y)+1; /* lastvisit(y)= currentrun
*/
15. end d f sdead
1. procedure d f slive(y : node)
2. if lastvisit(y) = currentrun and status(y) = live
then return;
3. lastvisit(y) := currentrun;
4. status(y) := live;
5. for each outgoing edge of y (say y → z) do
d f slive(z);
6. end d f slive
Figure 2: The CalculateCC algorithm.
During the execution of a program, garbage col-
lection may be activated several times. Because
information gathered in different garbage-collection
runs is mixed together, we use the global variable
currentrun to distinguish information gathered in dif-
ferent runs. This variable saves the trouble of erasing
the information after a collection run.
Each node y (in the heap) maintains two refer-
ence counters: gcount and hcount. Gcount(y) con-
tains the number of references from the global area
to y. Hcount(y) contains the number of references
from the heap to y. Since our algorithm will perform
depth-first traversals in the heap, each node (in the
heap) may be visited more than once. Each node y
maintains a counter β(y), which records the number
of times y is visited during the depth-first traversal in
the current run of garbage collection.
Every node also contains a status variable, which
could be dead, live, or notvisitedyet. Every node
contains a lastvisit variable, which is the run number
when the node was visited for the last time.
When a pointer g → h is about to be deleted
and gcount(h) will become 0 after the deletion, h is
a candidate for garbage collection. The procedure
CalculateCC(h) will be invoked. The node h will be
called the root of the new run of garbage collection.
The set of nodes that are reachable from the root of
a collection run is called the span of the run. Note
that a complete depth-first traversal, starting from the
root, of a span will visit each edge in the span exactly
once. The traversal will high-light a depth-first tree
(dfs-tree) in the span. The span of the current run is
called the current span.
The CalculateCC(x) procedure first increments
currentrun, then calls d f sdead(x) to perform a depth-
first traversal, starting from node x, calls search(x)
to look for dead nodes, and finally calls collect(x)
to free the dead nodes. Because every node in the
dfs-tree except the root x has an incoming pointer,
hcount(x) is temporarily incremented by 1 before the
search(x) call. Hcount(x) is decremented by 1 after
the search(x) call.
Example. Figure 4 shows a snapshot of a com-
puter’s memory. The numbers under the node name
are the node’s gcount and hcount, respectively. For
instance, gcount(a) = 0 and hcount(a) = 2. Suppose
the edge q→ a is about to be deleted. The garbage
collector CalculateCC(a) will invoke d f sdead(a).
d f sdead(a) will traverse the span, marking nodes
a,b,c,d,e, f ,g,h (we assume that these nodes are vis-
ited in this order) as dead. When node i is visited,
d f slive(i) will be invoked since gcount(i)> 0. d f s(i)
will mark nodes i, j, f ,g as live. Note that nodes f
and g are visited in both d f sdead(a) and d f slive(i).
d f sdead and d f slive together will perform a com-
plete depth-first traversal plus some overlapped por-
tion in the span, which, in this example, contains
nodes f and g. The overlapped portion also depends
on the order nodes are visited during the d f sdead(a)
call. 
無研發成果推廣資料 
