 
 
摘要 
此篇論文中，最新的乘法器是利用有限場GF(2୫)的位
移雙重基底表示法，實現平行位元心臟收縮電路架構。我們
證明三項式位移雙重基底乘法器可以表示成兩個漢克矩陣
乘法運算。新的平行位元心臟收縮乘法器是由一個漢克乘法
器和一個 2m-1位元的加法器所組成。我們所知密碼系統的
核心運算電路是乘法器，為了防止駭客利用錯誤攻擊法破解
密碼系統，我們將乘法演算法結合循環碼，以實現即時錯誤
偵測的乘法器。當與原乘法器相比較，此新的即時錯誤偵測
乘法器只增加兩個脈波周期。在GF(2ଶଷଷ)場中，新的即時錯
誤偵測的乘法之額外電路複雜度只占 7.2%。 
 
1.介紹 
在錯誤更正碼和密碼學[1,2]中，有限場是非常重要且
實用的，因此設計有限場運算受到多方的關注與研究。在密
碼應用上，密碼演算法需要有限場的大小可以從 160到 2048
個位元，且乘法為密碼演算法之重要的運算。從實際硬體實
現上，平行位元乘法器需要超過數百萬個電晶體，且在系統
的正常運作中，難免會有一至多個電晶體損毀而導致場錯誤
的運算輸出。基於此理由，許多研究者正在研究如何使用最
少的成本達到具即時錯誤偵測(concurrent error detection, 
CED)的數位電子電路，尤其是密碼的應用上，密碼硬體需
要可靠的運算設計。 
在GF(2୫)場中，元素的表示法通常由三個基底表示，
分別是多項式基底(polynomial basis, PB)，正規基底(normal 
basis, NB)，以及雙重基底(dual basis, DB)。[3,4,5,6,7]中提到
許多不同的GF(2୫)乘法器，包括串列位元、平行位元和數
位串列結構。在硬體實現上，雙重基底和正規基底乘法器需
要額外的硬體基底之轉換電路，但多項式乘法器不需要基底
轉換。現存的GF(2୫)乘法器結構，著重於如何使時間和空
間複雜度縮減到最小。但是，這些電路主要的缺點為不能提
供錯誤偵測或錯誤更正之能力。在參考相關論文[12,13,14]
中，利用奇偶檢測設計成具密碼裝置，以防止駭客入侵密碼
系統。奇偶檢測法之基本原理是將實際的奇偶數與預測的奇
偶數做比較，若結果是一樣，則表示電路為遭受到入侵攻擊，
反之，我們可偵測到駭客攻擊。 
植基於奇偶檢測法，Fenn[9]提出CED串列位元GF(2୫)
乘法器。Reyhani-Masoleh和 Hasan[10]提到如何在二位元場
GF(2୫)之多項式基底乘法器中，使用平行位元以及連續位
元去偵測錯誤。最近，Lee[8]中提出具位元串列式正規基底
乘法器。然而，使用單一奇偶檢測法的缺點為需要很長的延
遲時間去計算奇偶預測值。他們的電路之設計奇偶預測函數
是利用二位元樹 XOR運算，最少需ڿlogଶ mۀXOR閘的延遲
時間。為了克服這個問題，Lee et al. [11]提出利用雙重基底
表示法具 CED平行位元心臟收縮乘法器。 
線性碼的理論已廣泛地應用於通訊系統上，其能力可
提供錯誤偵測與錯誤更正能力。 (2୫ − 1, 2୫ − m)漢明碼[19]
最為有名的單一錯誤更正線性區塊碼。通常，線性碼依賴最
小漢明距離d୫ିଵ來實現錯誤偵測能力，即e = d୫୧୬ − 1。此
外，如資訊的數字太大，則此解碼器的線性碼需要很高的時
間和空間複雜度。最近，[20,21]提出使用單一錯誤更正(single 
error-correcting , SEC)線性碼實現具 CED PB乘法器。 
在此篇文章中，在GF(2୫)上，我們提出新的平行位元
心臟收縮乘法器具 CED能力。這個乘法器電路是結合循環
碼的特性，並可實現任何GF(2୫)乘法器上，提供錯誤偵測
之能力。本論主要的貢獻如下：新的奇偶檢測電路是以碼的
生成多項式為基礎，達到高效率的 CED結構。在平行位元
結構方面，[20]中傳統的 CED乘法器它的空間複雜度高達
52.9%，而新的結構之額外電路複雜度大約只需 7.2%。 
 
2.漢克矩陣-向量乘法器 
定義一：一個滿足 H(p ,q)=H(p-1,q+1)的 m*m矩陣 H
被稱為漢克矩陣，其中1 ≤ p, q < ݉ − 1，然而 H(p ,q)代表
在矩陣 H中(p ,q)的位置。例如一個矩陣被定義在第一列和
第一排。 
H =
ۏ
ێ
ێ
ێ
ێ
ۍ h଴hଵ
hଶ
⋮
h୫ିଶ
h୫ିଵ
  
hଵ
hଶ
hଷ
⋮
h୫ିଵ
h୫
  
⋯
⋰
⋰
⋰
⋰
⋯
  
h୫ିଷ
⋰
⋰
⋰
⋰
hଶ୫ିସ
  
h୫ିଶ
h୫ିଵ
⋰
⋰
h୫
hଶ୫ିଷ
  
h୫ିଵ
h୫
h୫ାଵ
⋮
hଶ୫ିଷ
hଶ୫ିଶے
ۑ
ۑ
ۑ
ۑ
ې
     (1) 
由定義 1的性質，一個 m*m的漢克矩陣藉由向量
H = [h଴, hଵ, hଶ, … , hଶ୫ିଶ]定義在有限場 GF(2)中。
A = [a଴, aଵ, aଶ,…,a୫ିଵ]為一個向量，而且 C=HA，其中 H為
向量H = [h଴, hଵ, hଶ, … , hଶ୫ିଶ]所組成的 m*m漢克矩陣。乘
積 C=[c଴, cଵ, cଶ, … , c୫ିଵ]可由通式c୧ = ∑ a୨h୧ା୨୫ିଵ୨ୀ଴ 表示。 
範例一：這是一個由H = [h଴, hଵ, hଶ, hଷ, hସ, hହ, h଺, h଻, h଼]
向量所組成的 5*5漢克矩陣 
H =
ۏ
ێ
ێ
ێ
ۍh଴hଵ
hଶ
hଷ
hସ
    
hଵ
hଶ
hଷ
hସ
hହ
    
hଶ
hଷ
hସ
hହ
h଺
    
hଷ
hସ
hହ
h଺
h଻
    
hସ
hହ
h଺
h଻
h଼ے
ۑ
ۑ
ۑ
ې
 
這個向量 C=HA的每個位元可被表示成如下： 
c଴ = h଴a଴ + hଵaଵ + hଶaଶ + hଷaଷ + hସaସ 
其中 
P෡୶షభ = x୬ି୫ xିଵmod G = x୬ି୫ିଵmod G 
         P෡୶ౣషభ = x୬ି୫ x୫ିଵmod G = x୬ିଵmod G 
很明顯地，方程式(9)中P෡୶షభ和P෡୶ౣషభ定義為一個固定的
多項式。舉一個例子，在G = xଷ + x + 1產生的(7,4)碼下，我
們獲得P෡୶షభ = xଶ和P෡୶ౣషభ = xଶ + 1。如果P෡ୌ౟షభ為已知的，那
麼我們可以計算出方程式(9)中的P෡ୌ౟。 
根據方程式(4)和(9)，我們可以得到C的奇偶預測位元
如下： 
        P෡ୡ = a଴P෡ୌబ + aଵP෡ୌభ + ⋯ + a୫ିଵP෡ୌౣషభ         (10) 
根據圖一中的漢克矩陣結構，C୧為漢克矩陣的第i୲୦輸出，我
們使用C୧來編碼，可得到碼字V୧如下方程式(11a) 
         V୧ = P෡େ౟ + x୬ି୫C୧           (11a) 
其中 
              P෡େ౟ = P෡େ౟షభ + a୧P෡ୌ౟             (11b)  
使用方程式(9)和(11b)，我們定義出一個PCG୧單元去運
算 P෡ୡ౟，此 PCG୧單元如下圖 4。當不可分解的三項式
G = x୬ି୫ + x୩ + 1產生循環碼時，在圖4中的ଵ୶模數只需要兩
個XOR閘。”⊗”和”⊕”分別代表第(n-m)位元的乘法器和加法
器。因此PCG單元的空間和時間複雜度如下： 
空間複雜度： 
XOR gate:2n-2m+2 
AND gate:2n-2m+1 
1-bit latch:3n-3m+1 
 
延遲時間：T୅ + 2Tଡ଼ + T୐ 
 
圖4 PCG୧單位中詳細的電路 
3.3 錯誤偵測(ED)模組 
假設循環碼(n,m)是由 n-m 次方的生成多項式所產生的錯誤
更正碼。以此碼為基礎，我們得到 ED模組部分的結構。令
V = v଴ + vଵx + ⋯ + v୬ିଵx୬ିଵ為一個被V = Pେ + x୬ି୫C編碼
的碼字，其中Pେ為 C 的基偶檢測位元。令圖 3 中的
R = r଴ + rଵx + ⋯ + r୬ିଵx୬ିଵ為組合邏輯電路和奇偶檢測位
元產生器的輸出碼字。當攻擊者使用次頻攻擊模組去入侵組
合邏輯電路時，R就會與 V不同。這個多項式的和為    
    E = R + V = e଴ + eଵx + ⋯ + e୬ିଵx୬ିଵ             (12) 
此為n維排列的多項式，其中若e୧ = 1則r୧ ≠ v୧如果e୧ = 0，
則r୧ = v୧。多項式E為錯誤型態。由方程式(12)我們可得到接
收多項式R為碼字V和錯誤型態E的和，如下方程式(13) 
   R=V+E         (13) 
因為碼字V是由生成多項式G所構成，所以我們可以藉由分
割G找到碼字V，例如V=QG，那麼我們可以得到由生成多項
式G所分割的R為： 
   R=QG+S        (14) 
方程式(14)的餘數S稱為特徵多項式，此特徵多項式的次方為
n-m-1或小於n-m-1。 
範例2：令生成多項式G = 1 + x + xଷ產生(7,4)循環碼，R為
接收碼。那麼，我們可得到特徵方程式S = s଴ + sଵx + sଶxଶ中
的元素s଴，sଵ和sଶ如下： 
s଴ = r଴ + rଷ + rହ + r଺ 
sଵ = rଵ + rଷ + rସ + rହ 
sଶ = rଶ + rସ + rହ + r଺ 
在上面提到，由生成方程式G所產生的接收碼R = P෡େ +
x୬ି୫C可得到特徵方程式的值S為 
S = R mod G 
  = P෡ୡ + x୬ି୫(c଴ + cଵx + ⋯ + c୫ିଵx୫ିଵ)mod G      (15a) 
  = P෡ୡ + Pୡ             
其中 
    Pୡ = c଴Pଵ + cଵP୶ + ⋯ + c୫ିଵP୶ౣషభ               (15b) 
    P୶౯ = x୬ି୫ି୷mod G, for0 ≤ y ≤ m − 1           (15c) 
Pେ為實際的奇偶檢測位元。當圖一產生乘積 C時，我們使用
方程式(15b)定義 m個W單元去運算Pେ。圖 5(a)為W單元的
詳細電路，其中W單元由一個 x模組，(n-m)個 AND閘，
(n-m)個 XOR閘和(2n-2m+1)個一位元的門閂組成。因此我
們可得到下推論。 
推論 1：如果設計好的碼是使用一個 t位元的錯誤更正碼，
那麼新的 CED乘法器具有 2個錯誤偵測能力。 
推論 2：以推論一為基礎，假設在新的 CED乘法器中錯誤
數量超過 2t個，那麼特徵值 S具以下的論點： 
(i) 如果 S=0，則乘法器沒被注入錯誤。  
(ii) 如果 S≠0，則乘法器被注入錯誤。 
推論 2可以藉由乘法器中的零計數器(zero counter, ZC)偵測
錯誤。這個零計數器的結構由一個 OR樹和一個反向器所組
成。利用推論 2和方程式(15a)，下面的圖 5(b)可以達到在乘
法器中的錯誤更正Eୡ = ZC(P෡େ + Pୡ)能力。如果Eୡ = 1表示此
乘法器被加入錯誤；如Eୡ = 0則表示此乘法器為正確的。 
α5 = α3 + 1 
使用方程式(20)，我們獲得如下： 
bି3 = b2 + b0 
bି2 = b3 + b1 
bି1 = b4 + b2 
b5 = b3 + b0 
假設元素 A,B屬於GF(25)場，其中A = ∑ aiαiି34iୀ0 ，
B = ∑ bi4iୀ0 βi和C = AB = ∑ ci4iୀ0 βi。利用方程式(19)，A和 B
的乘積可表示如下： 
 
從上面的矩陣-向量表示法，我們可分別使用向量
B0 = [b2, b3, b4, b0, b1, b2, b3, b4, b0]和
B1 = [b0, b1, b2, 0,0,0,0,0, b3]去定義矩陣B0തതത和B1തതത。應用在圖 6
中的 CED漢克乘法器結構，提出新的 CED SDB乘法器如
下列結構。 
 
圖 7 提出新的 CED SDB乘法器 
5 時間和空間複雜度 
在第 4個部分中，使用循環碼提出具有 CED能力的 SDB乘
法器。這個在圖 6中被提出來的GF(2k)乘法器取決於漢克矩
陣-向量乘法器。從圖 1的結構，我們得到一個由m2個 AND
閘，m2 + m個 XOR閘，和2m2個一位元的門閂。在圖 7中，
使用(n,m)碼去了解，在GF(2k)上的 CED SDB乘法器。表一
中列出 SDB乘法器具即時錯誤偵測和沒有同時錯誤偵測的
複雜度。在有限場GF(2233)中，使用不可分解多項式
F = x233 + x74 + 1。假設使用(239,233)碼，推算圖 7的時間
與空間複雜度。我們使用(239,233)碼組成多項式x6 + x+1。
在表一中，我們使用循環碼的 CED SDB乘法器，它的額外
空間複雜度大約 7.2%，而且額外延遲時間只多了兩個脈波
周期。 
 
表 1. 比較在GF(2m)中具即時錯誤更正和沒有及時錯誤更正
的漢克乘法器 
乘法器 圖 1 圖 7 
結構 平行位元心臟收縮 平行位元心臟收縮 
Latency  2m-1 2m+1 
每個周期的延遲時間 TA + TX + TL TA + 2TX + TL 
空間複雜度 #AND閘：m2 
#XOR閘：m2 + m 
#門閂：2m2 
#AND閘：m2+3(n-m)m+m
#XOR閘：m2 + 4m +
(n − m)(4m + 1) 
#門閂: 2m2+5(n-m)m+2m 
零計數計：1 
錯誤偵測 不行 可以 
 
最近， Bayat-Saramdi-Hasan(BSH) 在[20]提出用循環碼發展
CED乘法器。Lee et al.[11]提出在GF(2m)場上使用奇偶檢測
模組偵測輸出錯誤的平行位元雙重基底乘法器。我們將 
[20,11]的複雜度和新的結構做比較列出了下面的表 2。當 
[20]中的 BSH乘法器需要 52.9%的額外空間複雜度時，提出
的 CED乘法器大約只需要 7.2%的額外空間複雜度。延遲時
間方面，當 BSH乘法器需要 1.84%的額外延遲時，新的 CED
乘法器只增加兩個脈波周期。 
 
表 2.在GF(2m)上比較相關的 CED乘法器 
乘法器 [20] [11] 圖 7 
基底 多項式基底 雙重基底 位移雙重基底 
結構 位元串列 平行位元心臟收縮 平行位元心臟收縮
額外空間複
雜度 
52.9% 39% 7.2% 
額外時間複
雜度 
1.84% 兩個脈波周期 兩個脈波周期 
 
6 結論 
這個平行位元心臟收縮 SDB 乘法器中的錯誤更正碼被討論，
而且得到相對應的結構。這證明了我們提出使用循環碼的
CED乘法器只多出兩的脈波周期。然而，我們提出的平行
位元乘法器的額外空間複雜度只需要 7.2%。因此，我們提
出的容錯結構是很適合應用於防止駭客利用錯誤植入法攻
擊密碼系統。 
References 
BଵB଴ 
C
A 
CED 漢克乘法 
  如圖六所示 
計畫成果自評部份 
在本計畫中，我們研究內容與原計畫相符、達成預期的目標-提出的乘法具偵測錯誤能力是依據線性
碼來設計的。依據本計畫所提出的理論概念，將可發展及設計成VLSI晶片，且很適合應用於橢圓曲線
密碼系統，以防止駭客利用錯誤植入法入侵密碼系統。在本計畫中，研究成果已經撰寫成論文，投稿
至國際期刊及相關國際會議如下。 
1. Chiou-Yng Lee, “Concurrent error correction in bit-parallel systolic and scalable multipliers for shifted 
dual basis of GF(2m) using cyclic code approach,” (under review) IEEE Transaction on Computers (SCI) 
2. Chiou-Yng Lee, “Concurrent Error Detection in Systolic Array AB2 Multiplier over GF(2m), “(under 
review) IEEE Transaction on VLSI (SCI) 
3. Chiou-Yng Lee,Pramod Kumar Meher, and Chia-Chen Fan, "Fault-Tolerant Bit-Parallel Multiplier 
for Polynomial Basis of GF(2m) ," Journal of Electronic Science and Technology, Vol.7, No.4, 
pp.343-347 2009. (EI) 
4. 范家禎、李秋瑩，利用循環碼來設計位移雙重基底GF(2m)乘法器具即時錯誤偵測能力，2010 第四
屆ISC 智慧型系統工程應用研討會  
 
專題競賽 
1. 范家禎、李秋瑩，利用循環碼來設計位移雙重基底GF (2୫)乘法器具即時錯誤偵測能力，98年度龍華科
技大學大學生專題製作競賽第三名 
2. 范家禎、李秋瑩，研究GF(2m)蒙哥馬利乘法器具即時錯誤偵測能力，98年度龍華科技大學大學生創意
專題製作競賽第二名 
 
 2
Navigation、Learning、Visual Servo & Tracking、Formation & SLAM、Biomimetics、
Robot Learning & Control、Sensor Networks、Grasping、Information Acquisition、
Reconstruction、Control & Stability、Modeling and Task Planning、Manipulation、Flying 
Robots、Image Processing、Service Robots、Smart Actuators、Vision, Sensing & 
Intelligent Systems、Manipulators、Visual Human-Robot interaction、Intelligent System、
Medical Sensor & Monitoring、Kinematics、Underwater Robots、Fish Robots、
Humanoid Robot、Motion Planning、Sensor Applications、Robust & Intelligent Control、
Industrial Applications、Mobile Robots & Legged Robotics、Modeling & Control、
Surgical Robots、System Controls、Control, Optimization, Interface & Applications、
Mobile Robot Control & Planning、Active Recognition、Capsule Endoscope以及Robot 
Application等分組，如此多的議題，包羅萬象，每一個場次大約有3~4篇論文，共
計四天會議。綜合分析這些研討會的議題包含了電腦視覺、智慧型系統、感測器
融合、模糊邏輯、類神經網路、機器學習、智慧型行為、智慧型社交等。另外，
還有一場次的座談會，與會的專家無不提出他們的卓越見解，在此亦學會了這類
會議的價值以及對個人衝擊。整體而言，第一次參與此類僅有25篇論文的會議除
了壓力很大，但獲益更是良多。 
 
本人幸獲學校補助註冊費及機票，前往參加 RIBIO2009 並發表論文，在各方
面均有相當豐富之收穫。近年來我一直致力於具各項機電整合之題目研究論文，
由於此一領域須跨足多項領域，不論是機械、電機、電子或資訊，都一一接觸與
有所應用。從最小的電子電路到嵌入式系統，到資料整合的資料庫設計，都是我
的研究範圍。因此與會期間除了向國外學者學習智慧型機器人相關研究方法及未
來研究方向，以加強自己的研究深度，並增廣見聞。對於某些較具應用價值之方
法，則於該作者發表完後，利用中場休息時間與作者討論，藉此，除可對某些作
法深一層認識外，亦可利用機會與國外學者建立友誼關係。 
 
其中在會議的第三天，12月 7日。由 Karray教授探討機器人的現況及未來挑
戰。對於動態的環境中，具有學習能力的智慧型機器人才是我們所需求的未來機
器人。在人的認知能力上並不只是學習還包含了相當多的環境認知能力，所以在
機器人的設計不得不對這些訊息的處理有一番好的研究。在世界上目前認知研究
上分成二組: 理論組及分散式模組研究。在機器認知的研究上包含了人與機器人的
互動、機器人與機器人的互動以及人與人的互動。在這個領域的研究或許從 60年
 4
 
2. 參加此類國際會議，除了參與者受益外，也使得參與者可以將與會的經驗，帶
回校內，並可加強本校教師在舉辦國際性及區域性的研討會，有一良好的參考
模式。 
 
 
3. 若能再有此類的機會我們當會鼓勵研究生參與研討會並發表論文以展示自己
的研究成果，如此不但可讓與會者了解各校之研究內容或水平，亦可讓學生有
機會向各地之專家學者請益，以提升或改進自己的論文或水平。 
 
 
 
 
II. SYSTEM DESIGN 
The proposed remote autonomous robot can navigate in 
a complex environment. The hardware of the robot includes a 
wheeled mobile robot platform (UBot), a body with 1 DOF 
arm, and a head with CCD eyes. The software can be 
separated into two parts: one is the locomotion controller in 
the wheeled robot, another is the virtual reality based 
behavior controller and virtual scene implementation in the 
remote computer (MR Host). The system architecture is 
shown in Fig. 1. 
 
Virtools Engine Matlab  Fuzzy Controller
UbotVision And Voice 
Recognition
Network
Wireless Wireless
Interactive Robot
PC
 
Fig. 1.  System Architecture  
A. The Hardware Platform 
The proposed mobile robot is composed of a wheeled robot, 
an interactive computer, and a head.  The wheeled robot has 8 
sonar sensors at front and at rear of the wheeled robot body, 
respectively. The emergency stop procedure is implemented 
by the mechanism of the front end bumper sensor and wheels 
overload events.  This mobile robot is controlled by a 
DSP+FPGA board, and can communicate with remote 
commander through wireless LAN.  Inside the body of the 
robot, an interactive computer is installed.  This computer is 
used to implement the vision and sound detection and 
processing algorithm.  The vision and sound information will 
be processed in this computer; afterwards, the abstract 
information is sent to the VR host. The robot’s head with two 
DOF can pan and tilt.  The head motors can take the CCDs to 
face to the designate direction; for example, implementation 
of face tracking behavior.    
 
The interactive computer is used to implement the vision 
recognition and voice detection. The VR host is a high 
performance computer; both the Virtools engine and Matlab 
engine are executed on this computer.  The Virtools engine is 
introduced to implement the VR scheme and to develop the 
robot’s behaviors in this study. Through the LAN local host, 
the Virtools engine communicates with the Matlab engine, 
and through the wireless LAN it can communicate with the 
remote robot. 
 
B. The Software Platform 
 The Virtools engine is introduced to construct our 
laboratory scene in the VR platform. On the other hand, the 
virtual mobile robot model is created by Maya 3D tool. The 
major characters in the VR scene are: the virtual mobile robot, 
the obstacles, and static furniture. It should be mentioned that 
the obstacles are dynamically placed on the VR floor 
according to the sonar sensors' feedback. Fuzzy rules are 
implemented in Matlab engine, and the sensors’ inputs and 
the controller’s outputs are queried from and sent to physical 
world robot over TCP/IP protocol, respectively.  The vision 
recognition algorithm is implemented by OpenCV library, 
which can automatically detect the human face and 
immediately feedback the human face coordinates to VR 
engine for face tracking control. The voice detection rules are 
used to detect where there is a sound in the local area nearby 
the robot. If there is a sound detected then the robot will be 
waked up; after that, the robot will move its head to search the 
human face. The VR scene and the picture of the experimental 
environment are shown in Fig 2. The software integration 
structure include VR engine, Matlab engine, interactive 
sensors platform, mobile robot controller is shown in Fig. 3. 
 
 
Fig. 2.  The VR scene and physical world laboratory scene 
 
Fuzzy Controllers
MR Scene
Sensors Feedback
Motion Command
LAN
Matlab Engine
Virtools Engine
Remote PC
Wireless LAN
Mobile Robot
UBot Mobile Robot
Motion
Status
Motion
Command
Wireless LAN Module
UART
OpenCV Based
Vision Detector
Vision
Status
Wireless LAN Module
IPC
 
Fig. 3.  The Software integration structure 
III. THE KINEMATICS MODELING 
The kinematics modeling of the mobile robot can be shown 
in the following equations. The center velocity of the mobile 
robot, cV , is defined in (1) and the mobile robot rotation 
speed is defined in (2) , respectively.   
 
 
2
R L
c
V VV  .        (1) 
 
81
 
 
 
+x 
+y 
-x 
-y 
 
Fig. 6. The definition of the mobile robot central position 
 
B. The Behaviors Arbitrator Design 
There are three behaviors have been implemented in the 
opposed interactive mobile robot. The first behavior is target 
navigation, which can lead the mobile robot to the target spot 
under fuzzy control rules. Under the different fuzzy 
knowledge base design, the fuzzy control rules are also been 
conducted on another two behaviors. The second behavior is 
obstacle avoidance behavior, which can take the mobile robot 
pass through the obstacles on the way to target spots. The 
third behavior is face tracking, which may ask the mobile 
robot to follow the human beings and keep a comfortable 
distance from human beings. Even just a mobile robot, it has 
the most important mission must execute at every moment. 
Therefore, the priority of the robot choosing behavior can 
refer to human beings behavior. The obstacle avoidance 
behavior takes the highest priority, and the face tracking 
behavior takes the second priority, and the target navigation 
has the lowest priority. Then the fuzzy controller switch can 
be designed by the following rule, 
 
TFo PPP        (11) 
 
where oP  is the priority of the obstacle avoidance behavior, 
FP  is the priority of the face tracking behavior, and TP  is the 
priority of the target navigation behavior.  The system 
behavior control block diagram is shown in Fig. 7. 
 
Start
Get distance-
Err ,Degree-Err, 
S ,face position from 
VR system
Get velocity and 
steering angle
Send velocity and 
steering angle to 
VR system
Target Fuzzy Control
Switch Fuzzy 
Arbitrator
Obstacle avoidance
Fuzzy Control
Face tracking
Fuzzy Control
 
Fig.7. System behavior control block diagram. 
 
C. The Fuzzy Controller Design 
The rule table of the face tracking mode is shown in Table I 
and Table II. The output of the face tracking controller is 
shown in Fig. 8. The design concept of the rule tables is base 
on the PD controller, which can get the higher performance of 
the response time. On the other hand, the moving forward 
velocity of the mobile robot is zero, when the orientation error 
is at the state of big value. The controller has been designed in 
Table I/II , however, because the controller tries to adjust the 
orientation error to be close to zero. And after that, the 
controller tries to take the highest speed to move to the target 
spot.   
Table I 
Rules table of the velocity of the mobile robot 
ed  
cV  ZR PS PM PB PVB 
NB ZR ZR ZR ZR ZR 
NS ZR PS PS PS PS 
ZR ZR PS PM PB PVB 
PS ZR PS PS PS PS 
e
PB ZR ZR ZR ZR ZR 
Table II 
Rules table of the angular velocity of the mobile robot. 
ed    
ZR PS PM PB PVB
NB ZR NB NB NB NB
NS ZR NS NS NS NS 
ZR ZR ZR ZR ZR ZR 
PS ZR PS PS PS PS 
e
PB ZR PB PB PB PB 
 
 
Fig. 8.  Fuzzy controller output in the face tracking mode. 
 
 There are 28 fuzzy rules for the navigation mode. The 
mobile robot moving forward velocity is at the maximum 
speed, when the orientation error is near to zero. It is, 
therefore, the velocity output of the fuzzy controller is higher 
than others, shown in Fig. 9 (a).  
 
 
        (a) Velocity output             (b) Angular velocity output 
Fig. 9. Fuzzy controller output in the navigation mode.  
83
 
 
 
0 100 200 300 400 500 600 700
-150
-100
-50
0
50
100
150
X(cm)
Y
(c
m
)  Start
 Target
 
 
 Navigation Mode
 Obstacle Avoidance Mode
 Face tracking Mode
 Obstacle
 
Fig. 13. Robot orientation, x-axis bias, and obstacle events curves  
0 50 100 150 200 250
-100
0
100
200
300
400
500
600
time(s)
 
 
Distance(cm)
Orientation(degree)
 
Fig. 14. The position error and the orientation error of target navigation  
 
0 50 100 150 200 250
-200
-100
0
100
200
300
400
time(s)
 
 
V(mm/s)
 (0.1/s)
 
Fig. 15. Robot orientation, x-axis bias, and obstacle events curves 
 
0 50 100 150 200 250
-100
-50
0
50
100
150
200
250
300
350
time(s)
 
 
mode
Face-Y
Sonar
 
Fig. 16. Robot orientation, x-axis bias, and obstacle events curves 
 
 
Fig. 17.  Experiment photos 
VI. CONCLUSION 
This paper proposed an interactive mobile robot. The 
proposed mobile robot processes three behaviors that mimic 
from human beings. It is far to say, the mobile robot is an 
intelligent robot, but it can charge the three behaviors and use 
them to finish the given missions. The fuzzy controllers can 
be used to implement the mobile controller in a practice way.    
On the other hand, the mixed reality offers a great platform, 
which can play the motion simulation and behavior 
algorithms off line. It would not damage the physical mobile 
robot even we practice thousand times for finding the 
intelligent algorithms. Since this interactive mobile robot is 
developed on the mixed reality technique, the system may 
keep the study continuously.  Finally, the platform was built 
under the architecture of the internet network.  The command 
of the system and the sensor information of the system are 
transferred through the LAN and wireless LAN.  We should 
pay more attention on the time delay issues for designing a 
robust mobile robot over internet.  The future works are of 
implementing more behaviors to let the interactive mobile 
robots can work at same time. 
REFERENCES 
[1] P. Vadakkepat, P. Lim, L. C. De Silva, J. Liu, and L. Li Li, "Multimodal 
Approach to Human-Face Detection and Tracking," Industrial 
Electronics, IEEE Transactions on, vol. 55, pp. 1385-1393, 2008. 
[2] H. Zender, P. Jensfelt, and G. J. M. Kruijff, "Human- and 
Situation-Aware People Following," in Robot and Human interactive 
Communication, 2007. RO-MAN 2007. The 16th IEEE International 
Symposium on, 2007, pp. 1131-1136. 
[3] Y. Kuno, K. Sadazuka, M. Kawashima, S. Tsuruta, K. Yamazaki, and A. 
Yamazaki, "Effective Head Gestures for Museum Guide Robots in 
Interaction with Humans," in Robot and Human interactive 
Communication, 2007. RO-MAN 2007. The 16th IEEE International 
Symposium on, 2007, pp. 151-156. 
[4] H. C. Shin, E. G. Lim, and D. H. Hwang, "Real-Time Face Tracking for 
Tele-Operated Mobile Robot with an Embedded System," in 
SICE-ICASE, 2006. International Joint Conference, 2006, pp. 
2985-2988. 
[5] Y. Jong Il, A. Kyoung Kwan, C. Yong Rae, N. Tran Hai, T. Dinh Quang, 
and J. Woo Keun, "A study on face tracking in real-time for robot," in 
Control, Automation, Robotics and Vision, 2008. ICARCV 2008. 10th 
International Conference on, 2008, pp. 2182-2187. 
[6] S. Kai-Tai, H. Jwu-Sheng, T. Chi-Yi, C. Chung-Min, C. Chieh-Cheng, 
L. Wei-Han, and Y. Chia-Hsing, "Speaker attention system for mobile 
robots using microphone array and face tracking," in Robotics and 
Automation, 2006. ICRA 2006. Proceedings 2006 IEEE International 
Conference on, 2006, pp. 3624-3629. 
[7] Y. Nishina, T. Joo Kooi, K. Hyoung Seop, and S. Ishikawa, 
"Development of an autonomous robot for face tracking," in Control, 
Automation and Systems, 2007. ICCAS '07. International Conference 
on, 2007, pp. 1178-1181. 
[8] T. Kooijmans, T. Kanda, C. Bartneck, H. Ishiguro, and N. Hagita, 
"Accelerating Robot Development Through Integral Analysis of 
Human Robot Interaction," Robotics, IEEE Transactions on, vol. 23, pp. 
1001-1012, 2007. 
[9] E. Pacchierotti, H. I. Christensen, and P. Jensfelt, "Design of an 
Office-Guide Robot for Social Interaction Studies," in Intelligent 
Robots and Systems, 2006 IEEE/RSJ International Conference on, 2006, 
pp. 4965-4970. 
[10] A. Ohta and N. Amano, "Vision-based human behavior recognition by a 
mobile robot," in SICE, 2007 Annual Conference, 2007, pp. 3047-3051. 
[11] S. Thongchai, S. Suksakulchai, D. M. Wilkes, and N. Sarkar, "Sonar 
behavior-based fuzzy control for a mobile robot," in Systems, Man, and 
Cybernetics, 2000 IEEE International Conference on, 2000, pp. 
3532-3537 vol.5. 
[12] A. Ramirez-Serrano and M. Boumedine, "Real-time navigation in 
unknown environments using fuzzy logic and ultrasonic sensing," in 
Intelligent Control, 1996., Proceedings of the 1996 IEEE International 
Symposium on, 1996, pp. 26-30. 
[13] [F. Abdessemed, K. Benmahammed, and E. Monacelli, "A fuzzy-based 
reactive controller for a non-holonomic mobile robot," Robotics and 
Autonomous Systems, vol. 47, pp. 31-46, 2004. 
[14] M. Wang and J. N. K. Liu, "Interactive control for Internet-based mobile 
robot teleoperation," Robotics and Autonomous Systems, vol. 52, pp. 
160-179, 2005. 
85
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
  
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本計畫是植基於線性碼之錯誤偵測與錯誤更正機制,在 GF(2^m)上，我們提出新的平行位元
心臟收縮乘法器具 CED 能力中偵測錯誤而提出了錯誤解碼模組。這個乘法器電路模組是結
合循環碼的特性為基礎，並且可實現任何 GF(2^m)乘法器上，提供錯誤偵測之能力。本計
畫主要的貢獻如下：新的的奇偶檢測電路是以碼的生成多項式為基礎，達到高效率的 CED
結構。新的結構使空間複雜度大幅縮減。在平行位元結構方面，在傳統的 CED 乘法器它的
空間複雜度高達 52.9%，而新的結構之額外電路複雜度大約只需 7.2%。 
橢圓曲線密碼系統及錯誤更正碼廣泛應用於有限場。一般 ECC 的運算是根據質數場 GF(p)
或二位元場 GF(2^m)，且乘法演算法是橢圓曲線密碼系統的核心運算。本計畫所發展的 CED
乘法器被應用於橢圓曲線密碼系統時,密碼系統可防止駭客利用植入錯誤攻擊法機制入侵
密碼系統。 
