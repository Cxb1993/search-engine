 
中 文 摘 要 ： 分割前景背景一直是個電腦視覺領域上探討很久的問題，有
許多的方法被提出來，但是都還是沒能快速即時地做得很
好。在 Kinect 上市之後，為這個問題的解法帶來一道曙光，
因為它除了用提供高解析度影像攝影機外，還提供了物體的
深度資訊攝影機。有了深度資訊之後，便可以更輕易地提供
大量的前景背景資訊。 
 
雖然如此，但現有 Xbox 360 Kinect 相關研究，都共同存在
三個問題，一是在兩個不同性質攝影機的校正問題，二是前
景物體的左側邊緣破洞問題，三是物體週圍都有破碎問題。
本計畫的目的是希望能設計一套方法，將這些問題解決。第
一個問題主要解決方法是使用改良性的立體視覺匹配校正，
第二個問題主要解決方法是使用改良的 grabcut 及 matting
方法，第三個問題可以使用類似 inpainting 的方法。 
 
我們針對所提出的系統，進行線上測試及分析。這樣的成果
將可以提供給視覺化辨識、影像視訊檢索與搜尋、3D立體電
視輸入及互動操控等。本計畫在三種不同的平台上實作，使
用包含 AlexP 的 driver、Kinect SDK 1.6 及 OpenNI 2 等，
六項模組並已完成實作，包含影像校正模組、前景背景分割
模組、特徵點追蹤模組、邊緣破碎調整模組、破洞調整模
組、Grabcut 模組等，並且皆已開放源碼於 GitHub 網站。 
 
中文關鍵詞： Kinect sensor, OpenNI, background/foreground 
segmentation, hole filling, inpainting, grabcut 
英 文 摘 要 ： Foreground/background segmentation is studied for a 
long time in computer vision and many methods were 
proposed. However, the announcement of Kinect sensor 
for Xbox 360 changes the world. Not only high quality 
RGB color camera but also depth camera is providing 
new opportunities to solve many problems.  
 
Currently many researches using Kinect sensor meet 
three problems: the RGB-D calibration problem, the 
left-silhouette occlusion problem, and the broken 
mesh problem. So we propose a modified stereo 
matching/calibration method, a modified grabcut and 
matting method, and a modified inpainting method. 
 
We have constructed and analyzed our system to seek 
1 
(一) 中文摘要 
分割前景背景一直是個電腦視覺領域上探討很久的問題，有許多的方法被提出來，但是都還是
沒能快速即時地做得很好。在 Kinect 上市之後，為這個問題的解法帶來一道曙光，因為它除了用提
供高解析度影像攝影機外，還提供了物體的深度資訊攝影機。有了深度資訊之後，便可以更輕易地
提供大量的前景背景資訊。 
 
雖然如此，但現有 Xbox 360 Kinect 相關研究，都共同存在三個問題，一是在兩個不同性質攝影
機的校正問題，二是前景物體的左側邊緣破洞問題，三是物體週圍都有破碎問題。本計畫的目的是
希望能設計一套方法，將這些問題解決。第一個問題主要解決方法是使用改良性的立體視覺匹配校
正，第二個問題主要解決方法是使用改良的 grabcut 及 matting 方法，第三個問題可以使用類似
inpainting 的方法。 
 
我們針對所提出的系統，進行線上測試及分析。這樣的成果將可以提供給視覺化辨識、影像視
訊檢索與搜尋、3D 立體電視輸入及互動操控等。本計畫在三種不同的平台上實作，使用包含 AlexP 
的 driver、Kinect SDK 1.6 及 OpenNI 2 等，六項模組並已完成實作，包含影像校正模組、前景背景
分割模組、特徵點追蹤模組、邊緣破碎調整模組、破洞調整模組、Grabcut 模組等，並且皆已開放源
碼於 GitHub 網站。 
 
關鍵詞：Kinect sensor, OpenNI, background/foreground segmentation, hole filling, inpainting, 
grabcut 
(二) 英文摘要 
Foreground/background segmentation is studied for a long time in computer vision and many 
methods were proposed. However, the announcement of Kinect sensor for Xbox 360 changes the 
world. Not only high quality RGB color camera but also depth camera is providing new 
opportunities to solve many problems.  
 
Currently many researches using Kinect sensor meet three problems: the RGB-D calibration 
problem, the left-silhouette occlusion problem, and the broken mesh problem. So we propose a 
modified stereo matching/calibration method, a modified grabcut and matting method, and a 
modified inpainting method. 
 
We have constructed and analyzed our system to seek the opportunities to help the visual 
recognition, video retrieval, 3D TV interaction. This project is implemented based on three different 
Kinect related frameworks, including AlexP’s driver, Microsoft Kinect SDK 1.6, OpenNI 2. We 
finished 6 different modules as our proposal described. The six modules include (1) image 
calibration module, (2) foreground/background segmentation module, (3) feature tracking module, 
(4) occlusion refinement module, (5) hole filling module, and (6) grabcut module. All those modules 
are released as an open source project in GitHub server. 
 
 
Keywords: Kinect sensor, OpenNI, background/foreground segmentation, hole filling, inpainting, 
grabcut 
3 
全世界第一位破解 Kinect 裝置的，是在上市後的第三天完成破解的 AlexP，他也是在之前破解
Sony PS3 Eye 的高手，使高解析度、高 frame rate 的 PS3 Eye 能在 Windows 中使用。ＡlexP 屬於
NUI  Group (Natural User Interface Group) 的一份子，而 NUI Group 的目的是希望能做出比較自然
直覺的使用者介面。在 NUI Group 社群中，主要的著重重點在多點觸控(Multi-touch)的技術，所以包
含觸控螢幕(touch screen)，觸控桌(touch table)、IR 攝影機(IR camera)、投影機(Projector)等多種
不同的硬體及對映技術(如紅外線反射、光學結構、攝影機投影機校正定位)與應用(包含遊戲、電腦
操作、互動藝術等)，都是這個社群所在意的課題。目前對 Kinect 的應用主要是在 Window 平台當成
是多點觸控的輸入裝置。 
 
第二個社群，是 OpenKinect.org 社群。這個社群是在 Kinect 裝置出現才凝聚起來的，主要是第
一位破解 Kinect 的 AlexP 雖然大方地提供特別的 driver 供 Kinect 在 Window 平台中使用，但並沒有
將 driver source code 開放出來，所以幾天之後另外一位高手 Hector Martin 在 2010/11/10 公開他在
Linux 平台上對 Kinect 的破解[11]，Hector Martin 將其破解的 driver 以 open source 的 libfreenect 專
案公開[12]，並在 2010/11/15 移到 openkinect.org 網站[13]。因為有 Open Source 的加持，這個社
群成長的速度極快，有大量的研究團隊都認冋並投靠這個陣營，所以許多開發多年已有相當成果的
研究都以這個方式將 Kinect 裝置應用在其研究上。原本這個社群以 Linux 為起始點，很快速地在
Mac OS X 也有了大量的研究成果。像在互動藝術使用當相多的 openFrameworks，也在這時候加入
openkinect.org 社群，使用這個裝置來當互動藝術的界面。因此這個社群主要是跨 Linux 及 Mac 的
作業平台為主， 
 
第三個社群，是 ROS.org 社群[14]。ROS (Robot Open-Source/Operation-System)是以機器人
相關課題為主，跨平台的 open-source 的機器人平台，[15]本身有完整的函式庫，想要成為機器人學
的底層作業系統，當這個 ROS 系統能跨平台時，以此為基礎的機器人系統便能運行順暢。在這社群
中，可以看到很多學者以及這方面的專家在互相討論分享討論機器人學相關技術及分享原始碼。
ROS 社群使用 Kinect 的方法，是開發 ROS OpenNI 系統。OpenN[16]I 是以業界領導，不以營利為
目的組織，裡面包含 PrimeSense[17] (擁有 Kinect 內部關鍵技術的公司)及 WillowGarage[18] (繼
Intel 之後維護開發 OpenCV 的公司)及 Kick-Side[19] (專長 Motion Control 的遊戲開發公司)等。它們
所訂定的 API 包含了如視覺和聲音感應器(如 Kinect 及其他 PrimeSense sensors)、計算機視覺和追
蹤視覺等。OpenNI 的成立時間是 2010 年 11 月，也是在 Xbox360 Kinect 上市的時間點，並且也趕
上了 open source 的潮流，提供 open source 的 OpenNI PrimeSense driver (算是官方正式的 driver)，
也就可以讓 Kinect 來跨平台使用。 
 
第四個社群，是 TUIO 社群[20]。TUIO protocol [21]是 multi-touch gesutres 的一個開放性架構，
主要是由奧地利(Austria) Interface Culture Lab 的 Martin Kaltenbrunner 所提出，目前照著實作的系
統相當多，可讓 TUIO tracker (camera)及 TUIO client application (projector)互相溝通。對映的程式
包含 tracker 實作 20 多種(包含 touchlib, tuikinect 等)而 TUIO client 實作也有 20 多種，使用不同的
語言平台，讓包含藝術創作、互動裝置及研究學者都能方便採用。在歐洲的大學用比較多，也有一
些大學課程中教學使用。其中的 tuiokinect 計畫[22]，是 Martin Kaltenbrunner 使用
OpenFramework/ofxKinect 範例(底層是 OpenKinect/libfreenect)做出簡單的 TUIO 手部追蹤。
tuiokinect 是使用 depth 去設定前後的範圍，以便切出最適當的手部位置。 
 
5 
映到不同的深度值。像人臉(距離約 70cm)呈現藍色，手部的距離比較近(50cm),呈現淺藍色，背景的
牆或沙發距離比較遠(100cm)呈現綠色及黃色。其中特別值得注意的是，黑色的部分，是沒有量測到
值的部分，也就是 Kinect 無法量測到其測度值。經過分析，我們會發現如果物體距離太近的話，會
有得不到值的狀況。 
6.2 前置實驗二：紅外線雷射散斑實驗 
在下圖的實驗中，我們使用 Kinect 的紅外線攝影機，對相同場景進行兩次獨立攝影。左邊是沒
有發射紅外線雷射散斑(IR Laser speckle)的狀況，我們可以發現窗外看到天空時，對應位置的像素
點已有紅外線亮度值存在，右圖是發射 IR Laser speckle 之後的狀況，可以發現人的身上會有特別的
亮點光斑。經過實驗發現，只要光斑能良好地被量測攝影到,便能將正確地深度值量測出來。 
 
值得一題的是，環境光源的影響很重要。因為陽光是全光譜的光源(包含紅外光源)，能量很強，
所以容易蓋掉原來 Kinect 裝置的紅外光電射光斑的光源。所以在做用時，這裡需要特別注意。 
 
  
另外如果待測物體擺放過近時，投影出來的光斑太近，亮度過亮，容易發生過飽和的狀況，導
致無法正確地判斷深度值。下圖將這個現象進行簡單比較分析。下圖左方是將 Kinect 以正常模式開
啟，可發現距離較近的手掌是呈現過飽和的狀況。下圖右方則是將 Kinect 以近距離模式(Near-mode)
開啟，很明顯地發現 Near-mode 的將紅外線光斑的亮度減低而讓近物體的光斑不會過亮度飽和而無
法比對。 
 
Default mode 
 
near-mode 
7 
沒有問題。而對映的原始資料階數為 2048 階。在前導實驗中，我們使用了兩種方法來量測 Kinect 的
曲線，首先是使用傳統的距離量測方法，也就是使用尺的取樣來量測距離，並對 Kinect 所得到的深
度值進行量測。在下圖中我們發現 Kinect 得到的原始數據對映實際用尺量測的距離並不是直線線性
對映關係。 
 
 
我們也對不同時期購買的 Kinect 感測器進行量測比較，發現我們接著使用另外一台 Kinect 裝置
進行更完整的量測。將兩者資料合併繪出後，可以發現雖然是兩台不同的 Kinect 裝置，但其距離曲
線有重疊在一起的趨勢。而且看起來有斜率漸漸增加的趨勢。 
 
 
實
際
量
測
到
的
距
離
(c
m
) 
Kinect量測到的原始數據(2 bytes) 
量測資料一 
371
396
475
486
541
603
671
718
實
際
量
測
到
的
距
離
(c
m
) 
Kinect量測到的原始數據(2 bytes) 
量測資料合併 
量測資料二 
量測資料一 
9 
 
 
接下來我們分析現有遊戲及網路上正在進行中的研究結果。大量試玩目前市面上的 Xbox 360 
Kinect 遊戲，發現都有存在這樣的問題。網路上目前有的各式獨立研究的影片中，我們也都有發現
這樣的問題。這就會造成很不美觀的破碎問題。所以確定這是個值得研究的潛在題材 
 
6.5 邊緣破碎問題的解決作法 
在傳統影像處理中，要分割出前景及背景是長久以來的問題，也都有一些制式的解法，像是
Blue Screen, Background Difference 及其對映的各式變型，像是在影片中重建出背景後，再切割出
前景區域。因為如果只是純 2D 圖片，資訊或許不夠多，但也有出現像是 Bayesian Matting, Video 
Matting, Poisson Matting 或 magic wand, magnetic lasso[24], Graph cut[25], Lazy snapping[26], 
Grabcut [27], 等等方式來分割出前景背景。今天突然有了 Kinect 這樣的裝置能得到 RGB 之外加上
Depth 的資訊，也就是 RGB-D Camera，原本困難的問題就變得比較容易解決。 
 
關於將破碎區域解決掉，也有一些方法，像是 Inpainting 技術[28]，就能將一些畫面中破損區域
修復。不過在我們這個研究課題中，因為受損的部分剛好是最重要的邊界部分，所以如果使用
Inpainting 的技術想要保持特徵是很困難的。 
 
所以我們採行的方法，是將深度值及 RGB 色彩圖結合，使用正確得到的 depth 資訊來推算出
foreground 及 background 的已知區域，對映到 RGB 色彩圖的地方，所以如果標注是前景的區域，
就是安全的前景，標注是背景的區域，就是 100%的背景，而所缺的部分，則是交給 Matting 演算法
來解決。 
 
6.6 第二個問題(深度值校正、對映)及解決方法 
但是我們發現有第二個問題發生，使得問題沒有這麼直覺簡單。原因是 RGB Color 影像對映的
攝影機，與 Depth 深度質對映的紅外線攝影機，鏡心的位置並不相同。而且兩個影像是由兩個完全
不同的攝影機所攝得，所以對映的攝影機內部參數(intrinsic parameters)及外部參數(extrinsic 
parameters)是不相同的。照相機相對於空間座標系統的旋轉矩陣與平移矩陣，因為鏡心位置無法重
疊，所以無法相同。Color camera 及 IR camera 也是兩種不同的攝影機，所以內部參數也需要各自
獲得。 
 
傳統得到攝影機的內部參數、外部參數的方法，是使用拿黑白分明的棋盤格圖案來做校正[29]。
使用傳統棋盤格圖案的優勢，就是能簡單地先將彩色影像轉成灰階影像後，經由簡單的動態門檻值
(Adaptive Threshold)去找出梯度變化性質很強的角點(corner)，也就是兩個黑色方塊相接的頂點。如
11 
 
上面引用 Learning OpenCV [32]書裡面的三張圖，來表示運用 stereo camera 所要解決的問題，
最終的目的，是要算出兩個攝影機的對映關係。有了這樣的對映關係，在 Kinect 裝置，會有一個更
巧妙的應用。 
 
以前傳統 stereo camera 所得到的，是兩張為一組的 stereo image pair，但是現在 Kinect 的其
中一組攝影機所得到的，不是 2D image,而是 range image,也就是有深度值的資訊。我們可以由深度
值的資訊(也就是每個 pixel 都會有一個 z 的深度值)可以重建出 3D 座標，也就是每個像素點加上深度
值，那可以看成是以紅外線 depth 攝影機鏡心為空間座標原點的 3D model。那另外一個彩色攝影機
便可以將色彩資訊投影到 3D model 中。那我們就有了非常便宜的即時 3D 掃瞄器(realtime 3D 
scanner)。因為是即時可以得到資訊，所以以後也能延伸成簡單動作捕捉器(Motion Capture)。 
 
 
6.7 自動找尋對映點的方法 
但是問題出在 depth image，因為其工作原理是將紅外線光的特殊圖樣打在物體上，再由另外一
個紅外線 camera 攝得特殊圖樣後，推算出深度值。因為棋盤格圖案(chessboard)本來就是在同一個
平面上，所以的到的深度值就都會是同一平面，那麼就沒有辦法做剛剛所提到的校正。而且不同台
的 Kinect 裝置是各自在工廠做裝配的，所以每一台 Kinect 裝置的鏡心位置也可能有些微的不同，所
以我們需要有另外一種簡單的方法，讓每個人都有能力在自己的電腦做校正。不能用傳統的棋盤格，
那要怎麼辦呢? 
13 
 
 
但是 Oliver Kreylos 的方法需要手動找對映點，不是很方便。我們有想到第四種方法來能在
depth image 的地方偽裝為棋盤格。我們觀察 Kinect 的原理後，發現 depth image 是由投射的紅外
線 pattern 在物體上反射來完成，如果能找到一種質材不會反射剛提到的紅外線，那便能拿來應用。
不過我們發現一般窗戶的玻璃其實在特定角度(接近垂直)會反射光線，所以不合用。經過實驗，我們
挑選一般辦公室常見的透明投影片(transparent slides)其實很適合拿來使用。 
 
 
15 
 
6.8 關於雜訊及平滑化 
在下面實驗中，我們將頭部的深度值影像，以不同的平滑化方式來分析，包含簡單平滑化(blur,
相鄰像素點平均)、中位數法平滑化(median blur)、高斯平滑化(Gaussian blur)、雙向平滑化(Bilateral blur)。 
 
   
 
  
 
在下圖的實驗中，我們將量測到的深度值經過 median 平滑化後，以 3D 的方式來呈現。這裡使
用的是 3x3 的 median filter。 
 
  
其中值得注意的是過飽和(Saturation)的狀況，也就是當光斑的亮度過亮時，會有原本類似高斯
分布的亮度值，變成像被砍頭的狀況 。 
6.10 Leap Motion 裝置嘗試開發 
下面是 Leap Motion Controller 裝置的試用狀況，Leap 是一台 10cm*3cm*1.5cm 大小的裝置，
使用 USB 與電腦進行連結，目前尚未上市。可以運用深度值感測，來近距離推算出手部位置、手指
的指尖位置等。 
17 
  
  
19 
  
 
另外本計畫成果亦陸續將原始碼釋出(release)於 GitHub 中，請見 https://github.com/jsyeh 及下
圖所示。 
 
 
 
 
最後摘錄本計畫發表論文的部分成果如後所示。 
 
21 
 
23 
 
25 
 
 
27 
[29] Z. Zhang, "A flexible new technique for camera calibration," Pattern Analysis and Machine 
Intelligence, IEEE Transactions on, vol. 22, pp. 1330-1334, 2002. 
[30] ROS-Wiki. (2010, Dec 31). camera_calibration/ Tutorials/ MonocularCalibration/ Available: 
http://www.ros.org/wiki/camera_calibration/Tutorials/MonocularCalibration 
[31] ROS.org. (2010, Dec 31). camera_calibration/Tutorial/StereoCalibration. Available: 
http://www.ros.org/wiki/camera_calibration/Tutorials/StereoCalibration 
[32] G. Bradski and A. Kaehler, Learning OpenCV: Computer vision with the OpenCV library: 
O'Reilly Media, 2008. 
[33] O. Kreylos. (2010, Nov 26). Software Release and Kinect Camera Calibration. Available: 
http://www.youtube.com/watch?v=7TGF30-5KuQ 
[34] 曾俞豪, 陳品如, 馬萍蓴, 黃竹政, and 葉正聖, "Kinect-based Virtual Sculpture," in Computer 
Graphic Workshop (CGW2012), 2012. 
[35] 曾俞豪, 陳品如, 馬萍蓴, 黃竹政, and 葉正聖, "3D Modeling by Hand," in International 
Conference on Digital Content, 2012. 
[36] 鄭雅軒, 張家薰, and 葉正聖, "Kinect Head Tracking Transform to VR Scene," in International 
Conference on Digital Content (ICDC2012), 2012. 
[37] 鄭雅軒, 張家薰, and 葉正聖, "Kinect in Arbitrary Position for VR Display," in Computer 
Graphics Workshop (CGW2012), 2012. 
[38] 蕭維廷 and 葉正聖, "Kinect-based 3D Facial Model Reconstruction," in Computer Graphic 
Workshop (CGW2012), 2012. 
[39] 馬珝皓, 葉正聖, and 謝朝和, "Kinect 追蹤框控制家電系統," in 第十一屆離島資訊技術與應用研
討會, 2012. 
[40] 馬珝皓、葉正聖, "OmniKinect: Hands-free Motion Control System," in Computer Graphics 
Workshop (CGW2012), 2012. 
[41] 馬珝皓, 葉正聖, and 劉孝皇, "Kinect-based Intelligent Appliance Control," in Computer 
Graphis Workshop 2011, 2011. 
[42] 馬珝皓, OmniKinect: Hands-free Appliances Control System, 銘傳大學資訊傳播工程所碩士
論文, 2012. 
 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：葉正聖 計畫編號：100-2221-E-130-018- 
計畫名稱：結合 Kinect 與電腦圖學技術用於 3D 前景背景分割之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 9 9 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 ■申請中 □無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
1. 4 篇 Kinect 相關論文於國內 Computer Graphics Workshop 2012 發表,2 篇(CGW論文
延伸)於國內 ICDC 發表,1 篇 Kinect 於離島研討會發表。 
2. 參加 CVGIP 2012 產學研發成果發表會,有兩項技術參加發表,其中一項申請專利中。
3. 指導學生 Kinect 體感互動相關 6件作品參加教育部顧問室『網路通訊科技人才培育先
導型計畫』101年度成果發表會(互動多媒體教學推動聯盟中心成果發表)。 
4. 指導學生參加微軟創意盃(Microsoft Imagine Cup 2012)國際比賽的 Kinect Fun Labs 
Challenges 競賽,全世界 531 隊參賽,入圍前 100 名。台灣僅 2隊入圍。 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本計畫申請時(2010 年底),恰巧遇到微軟發表 Kinect 體感裝置,故時機點非常好,也讓研
究團隊能在第一時間投入 Kinect 相關研究。從最早的 AlexP 以非官方方式破解 driver,
到後來的 OpenNI 及各個版本的 Kinect SDK,都有進行相關的接觸嘗試及研發。 
使用嘗試過的開發環境及配合的工具,包含 Dev C++, Visual C++, Visual C#, Unity 3D, 
GAK, FAAST, OpenCV, OpenGL, OpenNI, Arduino, Processing 等,都有不同的專案以排
列組合的方式利用到這些工具,並參加不同的競賽、在國內研討會發表、並有不同的發表
展示機會。相關程式及成果亦陸續以開源的方式分享。 
 
相關技術參加的競賽包含: 
1. 指導學生參加微軟創意盃(Microsoft Imagine Cup 2012)國際比賽的 Kinect Fun Labs 
Challenges 競賽,全世界 531 隊參賽,入圍前 100 名。台灣僅 2隊入圍。 
2. 指導學生參加 2012 華碩 Xtion Pro 競賽,全國 64 隊參賽,入圍前 16 名。 
