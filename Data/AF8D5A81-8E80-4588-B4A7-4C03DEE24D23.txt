video coding topics. The entire duration of this 
project is 3 years. This is the third-year report. 
There are three parts in this report: (1) Direction 
Alignment Algorithm for Direction-Adaptive Discrete 
Wavelet Transform, (2) Fast HEVC Coding Unit Decision 
Algorithm, and (3) Depth Coding using Coded Boundary 
Patterns. 
2-D discrete wavelet transform (2-D DWT) represents 
non-vertical or non-horizontal edges inefficiently. 
Direction-adaptive discrete wavelet transform (DA-
DWT) solves this problem by filtering along the 
directions of textures. The block partition and 
direction information need to be transmitted as side 
information. A conventional DA-DWT often produces 
inconsistent directions of neighboring blocks and 
thus results in large amount of side information. In 
this report, we proposed a bottom-up direction 
alignment algorithm to align the block directions in 
local areas. Our algorithm can reduce 50% or more in 
side-information bits at the cost of negligible 
prediction error increase. 
In HEVC, the coding unit quadtree structure is added. 
With flexible CU size selection, the coding 
efficiency increases, while the complexity becomes 
higher. To reduce computational complexity, we 
propose a faster algorithm, which includes the 
splitting decision and the termination decision 
processes. It can efficiently build the CU quadtree. 
Our proposed method averagely saves about 43% 
encoding time, and the BD rate only increases by 
about 2.2% for the HD test sequences. 
One of the current trends in 3D technology 
development is to synthesize one or more virtual 
views based on the received or recorded views and 
their associated depth information. In this part, we 
propose a new method to code a depth map for the 
purpose of virtual view synthesis. The main idea is 
to use H.264/AVC to represent the rough shape 
(including depth values) of a depth map and then 
additional information is transmitted to improve the 
depth values around the object boundaries. Our 
collected data show that these proposed tools offer 
1 
 
行政院國家科學委員會補助專題研究計畫■ 成 果 報 告   □期中進度報告 
 
前瞻可調視訊編碼技術之研究(3/3) 
A Study of Advanced Scalable Video Coding Techniques (3/3) 
 
計畫類別：■個別型計畫  □整合型計畫 
計畫編號： NSC 98-2221-E-009 -076 -MY3 
 
執行期間： 100 年 8 月 1 日至 101 年 7 月 31 日 
 
計畫主持人：杭學鳴 國立交通大學電子工程學系教授 
計畫參與人員：許維哲、洪朝雄、劉哲瑋、陳彥宇、李政憲、尤基峰、
楊葆崧、謝男鑫、陳信宏、許夏銘  國立交通大學電子工程學系
研究生 
 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
 
 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
           
          
執行單位：國立交通大學電子工程學系 
 
中 華 民 國 101 年 10 月 15 日 
 
3 
 
碼效率或是合成出來的虛擬視點影像品質都能夠有一定程度的改善。 
 
關鍵字: 小波轉換，方向可調整性數位小波轉換，方向一致化，影像編碼，高效率視訊
編碼，三維視訊編碼，景深圖，景深編碼 
 
 英文摘要 
This project, A Study of Advanced Scalable Video Coding Techniques, investigates the 
topics of advanced video coding topics. The entire duration of this project is 3 years. This is 
the third-year report. There are three parts in this report: (1) Direction Alignment Algorithm 
for Direction-Adaptive Discrete Wavelet Transform, (2) Fast HEVC Coding Unit Decision 
Algorithm, and (3) Depth Coding using Coded Boundary Patterns. 
2-D discrete wavelet transform (2-D DWT) represents non-vertical or non-horizontal 
edges inefficiently. Direction-adaptive discrete wavelet transform (DA-DWT) solves this 
problem by filtering along the directions of textures. DA-DWT partitions images into many 
blocks and finds the most suitable direction of each block. The block partition and direction 
information need to be transmitted as side information. A conventional DA-DWT often 
produces inconsistent directions of neighboring blocks and thus results in large amount of side 
information. In this report, we proposed a bottom-up direction alignment algorithm to align 
the block directions in local areas. Our algorithm can reduce 50% or more in side-information 
bits at the cost of negligible prediction error increase. 
In HEVC, the coding unit quadtree structure is added. With flexible CU size selection, 
the coding efficiency increases, while the complexity becomes higher. To reduce 
computational complexity, we propose a faster algorithm, which includes the splitting 
decision and the termination decision processes. It can efficiently build the CU quadtree. Our 
proposed method averagely saves about 43% encoding time, and the BD rate only increases 
by about 2.2% for the HD test sequences. 
One of the current trends in 3D technology development is to synthesize one or more 
virtual views based on the received or recorded views and their associated depth information. 
Consequently, the depth information plays an essential role in the virtual-view (or 
free-viewpoint) 3D video systems. In this part, we proposed 
 a new method to code a depth map for the purpose of virtual view synthesis. The main 
idea is to use H.264/AVC to represent the rough shape (including depth values) of a depth 
map and then additional information is transmitted to improve the depth values around the 
object boundaries. Our collected data show that these proposed tools offer advantages in 
either coding efficiency or image quality improvement and some tools work best on simple 
images while the others work best on complex images. With proper parameter setting, the 
overall quality of virtual view rendering is noticeably improved. 
 
5 
 
(megablock)的方式來編碼邊際訊息，如此也可以降低邊際訊息的量，但影像各部分的
內容不同，應該各別區域分開處理一致化。 
C.  研究方法 
  
 圖 1.[1]所採用的候選方向，“-4” ~ “4”是方向索引(direction index)。 
  
 圖 2. 每個畫素表示 8×8 大小的 block 的最佳方向，方向索引“-4” ~ “4”對應於圖 1，方
向索引“5”之後會用到。(a)(b)分別為測試影像 Barbara 和 Lena。 
    我們採用[1]的候選方向給 DA-DWT，如圖 1 所示。圖 2 表示基於最小預測誤差所
選出的方向，可以看出相鄰區塊的方向並不一致，如此會造成很大的邊際訊息。我們
採用位元-失真成本函式(rate-distortion cost function，Lagrangian cost function)來一致化
相鄰區塊的選擇方向。 
  
C.1.  一致化位於類似花紋的區域中的區塊的方向 
  
 圖 3. GB(m, n)的四條掃瞄路徑。 
  
 圖 4. 經過步驟 E.1 後的方向，“5”表示不確定區塊，countd = 2，(a)(b)分別為測試影像
Barbara 和 Lena。 
  
     我們首先把影像分成大小為 BH×BW 且不重疊的區塊，我們假設整張影像可以分成
-4 -3 -2
-1
0
1
2 3 4
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
horizontal block index horizontal block index(a) (b)
ver
tica
l bl
ock
 ind
ex
ver
tica
l bl
ock
 ind
ex
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
horizontal block index horizontal block index(a) (b)
ver
tica
l bl
ock
 ind
ex
ver
tica
l bl
ock
 ind
ex
7 
 
  
 圖 6. 經過步驟 E.2 後的方向，(a)(b)分別為測試影像 Barbara 和 Lena。 
     我們一開始使用(4)來設定每個 UB(i, j)的方向為其最佳方向 ( , )LBd i j ，結果如圖 5 所
示，圖 5 可以很明顯地看出，有些 B(i, j)的方向跟其週圍的 B(i, j)並不一致，我們調整
它們的方向如下。 
     每個 B(i, j)有四個鄰近區塊，B(i-1, j)，B(i+1, j)，B(i, j-1)，B(i, j+1)。如果有某個
B(i, j)的方向和其四個鄰近區塊的方向都不一樣，我們定義其為孤立區塊(isolated 
block)IB(i, j)。我們使用(7)來從 IB(i, j)的四個鄰近區塊的方向中，選出一個能令(6)成立
的方向，當作此 IB(i, j)的方向。 
( , ) arg min{ ( , ; ) }IB dd i j D i j d R  (6) 
( , ) { ( 1, ), ( 1, ), ( , 1), ( , 1)}IB B B B Bd i j d i j d i j d i j d i j      (7) 
    圖 6 表示經過此一步驟後的結果，IB(i, j)的方向已經跟其鄰近區塊一致化，有些
B(i, j)形成一個小聚集(small cluster)且它們的方向和它們的鄰近區塊不一致，也因此我
們使用步驟 E.3 來一致化它們的方向。 
 
C.3.  調整小聚集的區塊的方向 
  
 圖 7. 經過步驟 E.3 後的方向，Citeration = 4，(a)(b)分別為測試影像 Barbara 和 Lena。 
     某些 B(i, j)會形成長而且細(只有一個區塊寬度)的範圍，稱為小聚集(small cluster)，
如果 B(i, j)屬於這個小聚集，我們使用(7)來重新選出它的方向，但限制在其他三個不屬
於小聚集的區塊的方向。此一步驟可能會產生新的 IB(i, j)，我們可以用(7)再來調整這
些 IB(i, j)的方向。我們重覆上述的步驟 Citeration次。 
     圖 7 表示經過此一步驟後的結果，很多的小聚集已經消失了。圖 7 中經過方向一
致化後的區域比圖 6 更方正，如此可以減少邊際訊息，我們使用[7]的方法使區塊合併
成巨大區塊並編碼巨大區塊的方向。 
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
horizontal block index horizontal block index(a) (b)
ver
tica
l bl
ock
 ind
ex
ver
tica
l bl
ock
 ind
ex
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
 
 
10 20 30 40 50 60
10
20
30
40
50
60
-4
-3
-2
-1
0
1
2
3
4
5
horizontal block index horizontal block index(a) (b)
ver
tica
l bl
ock
 ind
ex
ver
tica
l bl
ock
 ind
ex
9 
 
 
圖 8. 不同編碼方法的 PSNR。. 
 
第二部分 用於高效率視訊編碼之編碼單元快速決策演算法 
A.  研究背景與動機 
由於高解析度影像應用的需求，視訊編碼在 3C 產品中是不可或缺的技術，例如行
動電話、高畫質電視、藍光光碟機。進階視訊編碼(Advanced Video Coding, AVC/H.264)
是目前商業產品中，廣泛採用的壓縮標準格式。為了達到更高的編碼效率，國際組織
JCT-VC 正在進行下一代標準的制定[10]，即高效率視訊編碼(High Efficiency Video 
Coding, HEVC)。高效率視訊編碼在傳統的編碼流程中，增加了編碼單元四元分割樹
(CU quad-tree)的構造。彈性的編碼單元設計提升了編碼效率，但相較於進階視訊編碼
傳統的巨區塊(Macroblock, MB)結構而言，編碼複雜度提升不少，因此我們設計快速演
算法以有效率地建造出編碼單元四元分割樹。 
B.  文獻探討 
B.1.  高效率視訊編碼之編碼單元定義 
編碼單元(Coding Unit, CU)是一個 2N×2N 的區塊[11]，其中 2N 可以是 64、32、16、
8。其中最大的編碼單元稱為大編碼單元(Large Coding Unit, LCU)。當編碼器要編碼一
張畫面時，它先將一張畫面切成很多區段(Slice)，再把區段以大編碼單元為單位進行處
理，畫面處理的順序是由左到右、再由上到下(Raster Scan)。在大編碼單元中，可以遞
迴地切割下去至最小的編碼單元，此四元分割樹的深度為四。在同一層深度裡，編碼
單元會嘗試各種可能的預測單元(Prediction Unit, PU)如圖 9 所示，然後與原始區塊進行
相減後得到殘餘區塊，再將殘餘區塊用轉換單元(Transform Unit, TU)處理，以評估編碼
率-失真成本(-Distortion cost)。在同一層深度中，編碼器會選擇成本最小的模式為最佳
模式；在不同深度中，編碼器是以 G-BFOS 的方法進行比較[12]，所以整體的編碼處理
30.5
31.5
32.5
33.5
34.5
35.5
36.5
37.5
38.5
39.5
0 0.2 0.4 0.6 0.8 1
PS
N
R
bit per pixel
Lena
JPEG2000
DA‐DWT+EBCOT
DA‐DWT‐A+EBCOT
26.8
27.8
28.8
29.8
30.8
31.8
32.8
33.8
34.8
35.8
0 0.2 0.4 0.6 0.8 1
PS
N
R
bit per pixel
Pentagon
JPEG2000
DA‐DWT+EBCOT
DA‐DWT‐A+EBCOT
20.5
22.5
24.5
26.5
28.5
30.5
32.5
34.5
36.5
0 0.2 0.4 0.6 0.8 1
PS
N
R
bit per pixel
Spoke
JPEG2000
DA‐DWT+EBCOT
DA‐DWT‐A+EBCOT
25
27
29
31
33
35
37
0 0.2 0.4 0.6 0.8 1
PS
N
R
bit per pixel
Barbara
JPEG2000
DA‐DWT+EBCOT
DA‐DWT‐A+EBCOT
(a) (b)
(c) (d)
11 
 
速演算法。 
C.1.  編碼單元快速判斷 
編碼單元的快速判斷機制包含了切割決策(Splitting decision)和終止決策(Termination 
decision)。這些機制的判斷方式是基於[16]的編碼單元層級的演算法，用參考編碼單元
大小的資訊，預先判斷現在處理編碼單元的深度是否需要計算。 
由於鄰近的區域通常會有相似的紋理和移動向量，所以編碼單元的大小有區域的相似
性存在。如圖 10 所示，編碼單元的參考來源除了同一張畫面鄰近的 L 型區域外，也包
含了上一張畫面的共同位置編碼單元(Co-located CU)，即此參考編碼單元的位置和大小
與編碼器要處理的編碼單元完全相同。順道一提，我們所提出的快速判斷會在編碼單
元的 2N 為 64、32、16 進行運作。 
 
 
圖 10.  參考的編碼單元之相對位置和大小 
     
    切割決策是用於防止運算過大的編碼單元。當每次編碼單元要開始進行各種預測
單元的運算之前，就會先進行切割決策。若以下條件皆滿足的話，則切割決策發動；
此時編碼單元只會處理較小的預測單元(N×2N、2N×N)，接下來即進行切割，以計算更
小的編碼單元。 
切割決策的條件： 
1. 共同位置編碼單元內有更小的編碼單元存在。 
2. 所有鄰近的編碼單元都有更小的編碼單元存在。 
3. 此張畫面不可以是畫面內預測的畫面(Intra Frame)。 
 
    終止決策是用於防止運算過小的編碼單元。當每次編碼單元已經完成目前深度的
預測單元運算時，就會進行終止決策。若以下條件皆滿足的話，則終止決策發動；此
時編碼單元只會處理至目前深度為止，不會切割成更小的編碼單元。 
終止決策的條件： 
1. 共同位置編碼單元內沒有更小的編碼單元存在。 
2. 超過兩個鄰近的編碼單元沒有更小的編碼單元存在。 
3. 此張畫面不可以是畫面內預測的畫面。 
13 
 
C.3.  減少預測單元數目於切割決策後 
     我們從表 3發現低QP的時間節省不夠多，主要原因是：在切割決策後，編碼器在
當前的深度保留了兩個預測單元。因此我們將對附近的編碼單元進行觀察，進而減少
一個預測單元。當切割決策發生後，編碼器會進一步地去觀察正上方和正左方的參考
編碼單元；假如正左方包含較多的小編碼單元，即在當前深度只執行 2N×N的預測單元，
若是正上方較多小編碼單元，則是只執行N×2N的預測單元。此方法將平均節省時間提
升 3%到 4%，而且沒增加額外的編碼損失。 
  
D.  結果與討論 
在本節，我們將測試我們演算法的效能，時間節省的定義如同式子(9)，然後和
HM5.0[11]中快速演算法工具的 ECU[13]和 CFM[14]進行比較並且結合使用。首先，我
們使用 HM5.0 當作實驗平台，參數設定陳列於表 4，測試影片檔是使用標準測試影片中
的 B 級別(1920×1080)和 E 級別(1280×720)，總共 8 組的影片檔(每組測試影片皆編碼 100
張)，以測試我們的演算法效能，對照組為原始的 HM5.0，結果列於表 5。 
 
表 4 實驗環境參數 
Configuration: Low delay P with low complexity 
MaxCUsize: 64 64  
MaxCUdepth: 4 
Search mode: EPZS pattern 
Search range: 64  
Reference frame: The previous frame 
Group of Picture (GOP): 1 
Used QP values : 22, 27, 32, and 37 
Sequence type: IPPP (Only the first frame is I frame.) 
MRG: 1, FEN: 1, ECU: 0/1, CFM: 0/1. 
 
 
 
( ) ( )
( ) 100%
( )
 tested referenced
referenced
Time QP Time QP
TS QP
Time QP
 (9) 
 
 
 
 
15 
 
像相關的研究也如雨後春筍般冒出。基本上 3D 影像可分為下列兩大種類 : 
 
(a) 傳統 3D 影像 
    利用特殊的立體成像裝置，同時傳送人類左眼及右眼分別應該接收到的資訊，搭
配使用者戴上的特殊偏振片眼鏡，使得左眼及右眼分別接收到各自視角應該看到的影
像進而產生立體影像的效果。 
 
(b) 裸視 3D 影像 
    雖然同樣需要利用特殊的立體成像裝置，然而使用者卻不需要帶上偏振片眼鏡來
分離所接收到不同視角的資訊。換句話說，使用者能夠在特定的角度範圍內看到任意
視角該看到的立體影像。 
 
    現今的 3D 影像相關研究主要是針對與裸視 3D 影像的部分進行更深入的探討與開
發，本研究題目也是針對裸視 3D 影像來進行相關的演算法開發。 
A.1.  何謂景深資訊 ? 
    所謂的景深( Depth )就是指被相機拍攝的物體距離相機的遠近資訊。那為甚麼我們
需要景深資訊才有辦法營造出立體影像的效果呢? 先來介紹另一項與景深有緊密相關
的資訊---視差( Disparity ) ，視差是指同一個畫素( Pixel )在不同的視角成像上的位移
量。 
 
圖 11. 視差資訊與立體影像 [18] 
    由圖11可以清楚看出視差資訊與立體影像的緊密關聯性。當Disparity < 0時，眼睛
對於該畫素的聚焦位置會在螢幕的前方；反之，當 Disparity >0 時，眼睛對於該畫素的
聚焦位置便會在螢幕的後方；而當 Disparity = 0 時，眼睛對於該畫素的聚焦位置就會剛
好在螢幕上。如此一來，螢幕上的每個畫素會在不同視角上對應到不同的視差值，進
而讓使用者在觀看影像時產生立體視覺的效果。 
 
    然而產生立體影像資訊所需的視差值是可以由景深資訊轉換而來的，轉換公式及
17 
 
  
圖 13. (a)分割後的景深圖 (b)方塊數、失真及編碼率之統計表 [2] 
 
    圖 13 (a)是將 MPEG 所提供的測試影像” Ballet ”切為許多方塊，若該方塊內資訊較
為複雜則會繼續向下切割。由圖 13 (b)可以看出整張影像有超過 80%的區域是較為平滑
的區域，只有不到 20%的區域是較為複雜的區域。然而卻有超過一半的失真是發生在
這些為數較少的複雜區域，而且這些區域還花了超過 70%的編碼率。這些數據顯示了
景深壓縮一個很重要的特色 :  
景深圖內的前景物件邊緣是產生編碼失真最嚴重的部分，也是耗費最多位元編碼的地
方，因此景深壓縮主要的處理對象即為物體的邊緣處，必須要想辦法在解碼端保留或
重建正確的邊緣資訊以提升合成影像的品質。 
 
B.  文獻探討 
    景深壓縮有兩種主要研究方向 : 其一方向之目的為提升壓縮完的景深圖品質，只
考慮壓縮景深的編碼效率；另一方向之目的為盡可能提升使用壓縮完的景深圖所合成
的虛擬視點影像品質，即便壓縮完的景深圖品質或是景深壓縮的編碼效率都並非最好。
而本研究之最終目的則與後者相同。 
 
現有的景深壓縮相關研究主要可以粗略分為下面幾個種類 : 
(a) 既有編碼方法 
(b) 前置處理 
(c) 後置處理 
(d) 特定模型 
 
(a) 既有編碼方法 
    目前最被廣泛使用之影像編碼方式即為 H.264/AVC，其編碼對象主要是針對全彩
的原始影像。當然 H.264/AVC 也可以針對景深資訊做壓縮，但是由於景深資訊擁有與
原始影像不同的特性，所以會造成壓縮效果不如預期。首先是 H.264/AVC 壓縮必須考
19 
 
(d) 特定模型 
    由於景深圖絕大部分的區域皆為平滑區域，只有在物件邊緣的地方會發生劇烈的
深度值變化，因此P. Merkle等人[22]提出了用下列四種數學模型來對應景深圖上的所有
區域，其後進行四元樹的拆解，最後再做量化編碼的動作。 
 
1 0
2 0 1 2
ˆConstant Function: f (x,y) α                                                                   (11) 
ˆLinear Function: f (x,y) β +β x+β y                                                       (12)  
We


0A
3
0B
0A 1A 2A
4
0B 1B 2B
γ    (x,y) Aˆdgelet Function: f (x,y)                                            (13) γ    (x,y) B
θ +θ x+θ y   (x,y) AˆPlatelet Function: f (x,y)                     θ +θ x+θ y   (x,y) B
  
  
        (14) 
 
C.  研究方法 
    本研究主要遵循 MPEG 3DVC [23]的標準規範，在相同的條件下設計傳送景深資訊
的 codec 以及相關演算法。MPEG 3DVC 的整體架構圖如下: 
 
 
圖 15.  3DVC 架構示意圖 [18] 
    首先針對影像做景深估測的動作用以產生相對應的景深圖，接著將 MVD 格式的資
訊編碼並傳送至解碼端解碼，最後利用這些接收到的 MVD 資訊進行虛擬視點影像合成
的動作，產生比相機個數還要多的視角，藉以使顯視器能夠產生立體視覺的效果。 
(a) 景深估測 
    這個部分我們是直接採用 MPEG 提供的測試景深影像來作為本研究所提出之演算
21 
 
便是要將這些所謂的”真正前後景之交界處”萃取出來。 
 
圖 17. 前後景交界處示意圖 
 
STEP 2  代表性景深值決策 ( Significant Depth Value Decision) 
    經由STEP 1的動作可以得到一張只具有前後景交界處有值的圖，我們稱它為”不連
續層(Discontinuity Layer)”，此步驟先將”不連續層”切割為 3*3 的方塊( 註:當寬或高不
為 3 的倍數時，我們將捨棄最靠近圖片左右或上下兩側的列或行並保持對稱性 )，然後
我們針對每一個方塊找出出現最多次且連結性最高的景深值並將其定為該方塊之代表
性景深值( Significant Depth Value )。 
 
STEP 3  模型對應 ( Modeling ) 
    針對上述之每一個方塊，將景深值等於該方塊之代表性景深值的位置設為 1 ( 圖
18 之黑點 )，其餘設為 0 ( 圖 18 之白點 )，如此一來便可以形成一個二位元方塊
( Binary Block )，再將此二位元方塊與預先建置好的模型堆進行對應的動作，並將對應
到的模型引數( Index )記錄下來，我們一共提出了 128 個模型堆。 
 
128 個模型堆的其中 8 個如下圖所示: 
 
 
 
圖 18.  8 個對應模型堆 
( 註:每個模型堆內還包含所有可能的方向性，本圖僅列出 8 個模型堆裡的一種 ) 
 
STEP 4  編/解碼 ( Encode/Decode ) 
利用下面之 syntax (17)來進行編/解碼的動作。 
23 
 
 
圖 20. 流程圖 
    其中我們設計了兩個方法來利用解碼後的旁路資訊去校正景深圖。Boundary 
Enhancement (BE)主要的概念是將旁路資訊的非零景深值拿去替換利用 H.264/AVC 解回
來的景深圖上相對應位置的景深值。而 Enhanced Region Expansion (ERE) 則是利用
Dilation 的技巧並以類似 BE 的原理擴大校正範圍以期能更有效率的利用旁路景深資
訊。 
 
(c) 虛擬視點影像合成 
    關於在虛擬視點影像合成的部份我們是採用 MPEG 所提供的 View Synthesis 
Reference Software ( VSRS ) [24]來合成。該參考軟體需要餵入兩個視角的完整影像資訊
以及相對應之景深影像資訊來產生虛擬視角之影像。而使用本演算法所重建出來的景
深影像資訊即可搭配原始影像資訊直接餵入給 VSRS，並針對合成出來之虛擬視角影像
進行品質評估。 
 
影像品質評估方式 
    我們會計算利用 VSRS 所合成出來的虛擬視點影像的峰值訊雜比(客觀評估)，並同
時用特定裸式立體成像顯示器播放，藉以進行使用者主觀視覺上的評估。 
 
D.  結果與討論 
    在我們的實驗中一共將所提出的演算法分為四個模式來操作: Mode 1 和 Mode 2 分
別是在景深資訊校正的時候採用 BE 以及 ERE 的方式處理，而 Mode 3 和 Mode 4 是將
一開始輸入 main path (H.264/AVC)的原始景深圖先做 downsampling(factor: 0.5)，然後針
對 H.264/AVC 壓縮過的景深圖做 upsampling(factor:2)的動作回覆原本的尺寸，最後各自
用和 Mode 1 和 Mode 2 相同的景深資訊校正方式來校正景深圖。 
 
我們針對不同測試影像的實驗結果如下所示: 
25 
 
表 7 Newspaper 
Ground Truth JM 18.0 Only 
Mode 2 Mode 4 
 
表 8 Lovebird1 
Ground Truth JM 18.0 Only 
Mode 2 Mode 4 
 
 
27 
 
Reconstruction Filter for 3-D Video Systems,” IEEE Tran.on Circuits and Systems for 
Video Technology, vol. 21, no. 3, Mar. 2011  
[20] D. V. S. X. De Silva, W. A. C. Fernando, and S. T. Worrall, “Intra Mode Selection 
Method for Depth Maps of 3D Video Based on Rendering Distortion Modeling, ” IEEE 
Tr a n .  O n  C o n s u m e r  E l e c t r o n i c s ,  v o l .  5 6 ,  i s s u e  4 ,  N o v.  2 0 1 0 
[21] Qiuwen Zhang, Ping An, Yan Zhang, Qian Zhang, and Zhaoyang Zhang, “Reduced 
Resolution Depth Compression for Multiview Video plus Depth Coding,” IEEE 
International Conference on Signal Processing, 2010  
[22] P. Merkle, Y. Morvan, A. Smolic, D. Farin, K. Muller, P.H.N. de With and T. Wiegand, 
“The Effects of Multiview Depth Video Compression on Multiview rendering,” IEEE 
Signal Process. Mag: Image Communication 24 (2009) 73-88.  
[23] ISO/IEC JTC1/SC29/WG11 N12036, “Call for Proposals on 3D Video Coding 
Technology,” Mar. 2011 
[24] ISO/IEC JTC1/SC29/WG11 N11631, “Report on Experimental Framework for 3D Video 
Coding,” Oct. 2010 
 
 
 
 
 
 
 
 
 
 
計畫成果自評 
本計畫有以下幾類成果。第一類為開發出 SVC coding, interframe wavelet coding, 
directional wavelet coding 等技術及實驗成果。這些成果多與國際 MPEG 標準及業界產品
相關，極具實用價值，可促進國內工業技術研發。第二類為為計畫執行過程所獲得之
研究成果論文，已發表於(含接受)國內外學術會議及國外期刊。其三，參與計畫之同學
可獲得國際多媒體最先進的 MPEG 相關技術及多媒體系統設計經驗，畢業後進入產業，
直接有助於產業界開發新產品，提昇我國工業技術能力，達到人才培育之目的。 
綜合評估：本計畫產出相當多具有學術與應用價值的成果，特別是直接參與國際
標準會議，在國際上展示成果。並培育高科技人才培育，整體成效可稱良好。已發表
學術論文 8 篇，以及博士學位論文 1 冊與碩士學位論文 2 冊如下表。 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/14
國科會補助計畫
計畫名稱: 前瞻可調視訊編碼技術之研究
計畫主持人: 杭學鳴
計畫編號: 98-2221-E-009-076-MY3 學門領域: 訊號處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
參與國際標準會議 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
