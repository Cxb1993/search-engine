2中文摘要
本研究計畫『以影像與視訊內涵為基礎的行動搜尋』旨在延續前一年度的國科會計畫『在網路分
類目錄對影像內容做物件偵測與概念學習來改進影像搜尋』，除了進一步研究以特定物件類別偵測的方
式，來達到以物件為基礎的影像搜尋，並且強調在手持式行動裝置上的應用，以使用者最方便的影像
與視訊輸入為介面，達到無所不在的行動搜尋。以下研究報告以「經濟部智慧財產局」商標檢索為應
用，在當今全球化經濟中智慧財產權已日益重要，為了保護當事人的權益，我們利用三種特徵，主要
目的要找出在此資料庫中有最好效能的特徵子，分別為 SIFT、PCA-SIF 和 SURF 特徵在影像之間進行
比對，以搜尋和監看是否有仿冒或盜用商標的情況；在智產局的資料庫中有著相當大的影像數量，而
影像中所包含的影像資訊亦非常多，因此在處理與搜尋時造成費時的情況，為了加快搜尋的速度，我
們利用了字彙樹作為影像搜尋的方法，但是當速度變快時，相對的準確率也會降低，因此要在準確率
與速度之間取得一個平衡。最後分別利用貪婪的 N 條最佳路徑搜索和幾何校正提升準確率。
關鍵詞：內容式影像檢索、局部特徵子、行動搜尋。
英文摘要
This project aims to develop an image and video-based mobile visual search application. Users capture a
photo or video using the camera-equipped mobile device, then search related information via the wireless
network without keying any text. Nowadays, intellectual property right in the globalization economy has
received much attention, and watch for infringed trademarks is one of the most important issues. One
application of our research focuses on figurative trademark search on the image database collected at the
Ministry of Economic Affairs Intellectual Property Bureau, Taiwan. To search for similar trademarks using
image content, we make use of three kinds of features including SIFT, PCA-SIFT and SURF for matching
between the images. The first goal is to find out which feature is most suitable for the trademark database.
Because of the large amount of features extracted from the images, the off-line training and on-line processing
both spend a lot of time to finish. To improve the performance, we use the vocabulary tree for reducing the
search time. While the search efficiency is improved, the search accuracy becomes slight poor. For this
purpose, two modifications of the greedy N-best paths search and geometric rectification are used for
reclaiming the accuracy. In the experiments, 200 images are used as queries for searching 27,610 images in
database, and the accuracy of the performance can be up to 90% or so.
Keywords: content-based image retrieval, local descriptors, mobile search
報告內容
1. 前言
目前各機關組織和企業皆有專屬的圖像商標，而商標對於工商業的發展扮演著舉足輕重的角色，
此商標的信譽價值之形成絕對非一蹴而就，往往需要十代甚至十幾代的傳承，才能創造此老字號的商
標信譽，我國的商標法即是為了維護這些擁有此商標的公司或個人而存在。隨著日子如流水般快速逝
去，商標局的圖像商標以漸漸形成龐大的資料庫，若使用文字為影像進行分類，往往無法搜尋到最好
的結果，即因為文字無法詮釋某些圖的概念和意境；商標局主要將這些大量的圖像商標以人工的方式
進行分類，透過大量人工的方法，儘量將商標影像分至圖形分類路徑，但所耗費的時間和人力，加上
影像標註者主觀的想法和圖文關聯度的高低，將會增加系統的建置成本和時程，以及影響搜尋的準確
4圖 1：資料庫建立流程
3.2 系統運作方式
接下來要說明系統運作的整個流程，如圖 2 所示，在輸入了查詢影像之後，分別對查詢影像擷取
SIFT、PCA-SIFT 和 SURF 特徵，然後分別對各自建立好的字彙樹之影像字或節點進行距離的運算，藉
以決定它屬於哪一個影像字或節點，對此一影像字或節點所隸屬的影像加權，然後進行排序的動作，
最後將影像結果回傳。
圖 2：系統運作流程圖
4. 影像特徵擷取
本論文所使用的影像擷取方法分別是 SIFT、PCA-SIFT 和 SURF 特徵，將於以下依序介紹。
4.1 SIFT特徵 [4]
SIFT (Scale-invariant feature transform）是一種在計算機視覺中對影像做檢測和描述局部特徵的演
算法，此演算法由 David Lowe 於 1999 年提出，而後 Mikolajczyk 在 2005 年時針對包括 SIFT 特徵等十
幾種局部特徵子製作了不變性的實驗，在實驗中可證實 SIFT 特徵比其他局部特徵子具有較強的強健
性。SIFT 特徵生成的方法大致分為四個步驟：
Step 1：Scale-space extrema detection
SIFT 主要改進哈里斯角點檢測 (Harris corner detector) 不具尺度 (scale) 不變性的特性，理論上必
須從所有可能的尺度去找尋穩定的特徵，但是事實上並不可能將所有的尺度皆找盡，因此採用高斯差
分過濾器在尺度空間取樣的方法，因為高斯差分是一個計算上方便快速且穩定度高的過濾器。利用影
像金字塔的方式在尺度空間上進行高斯差分計算，顯示於圖 3 左半部份。在各個尺度的每一個樣本點
會進行比對，與此樣本點的上下左右共有 26 個鄰居相比較，包括上一個尺度的九個點、此尺度的八個
點以及下一個尺度的九個點，此一極值必須是局部最大值或者局部最小值。經過此過程後，便可以把
所有的局部極值挑選出來，作為特徵候選點，如圖 3 右所示。
6PCA (Principle Component Analysis) 是一個標準的降低維度技術，已經被廣泛的應用於電腦視覺
的問題上，包括特徵選擇、物件辨識以及人臉辨別。PCA-SIFT 特徵是 SIFT 特徵的變形，與 SIFT 特徵
擁有相同的特徵點位置、尺度以及主要方向 (dominant orientations) 偵測方式，相異之處在於改變 SIFT
特徵的第四步驟計算特徵子。特徵子是影像向量梯度在水平和垂直方向作區域計算，此梯度空間取樣
41 × 41 個區塊，去除區塊的上下左右邊界即為 39 個區塊，因此向量維度為 39 × 39 × 2 = 3042 維，再
將此向量維度降成 n 維，n 的決定是實驗結果而來，實驗顯示好的特徵空間維度的數值，是當 n = 36
時達到了最佳的匹配效能。
4.3 SURF特徵 [6]
SURF (Speeded up robust features) 是一個強大的影像偵測器和描述局部特徵的演算法，此方法由
Herbert Bay 於 2006 年提出，可運用於電腦視覺中的物件辨識或者 3D 重建。主要的靈感來源是自 SIFT
特徵，此 SURF 特徵比對速度較 SIFT 特徵快，並且宣稱在比對不同影像轉換時比 SIFT 更加強健。SURF
特徵生成的方法大致分為四個步驟：
Step 1：Detection of scale-space extrema
SURF 的偵測器是以海賽矩陣 (Hessian matrix) 和海賽行列式矩陣 (determinant of the Hessian
matrix, DoH) 為基礎，因為它在計算時間以及準確度上有良好的表現，主要改進海賽拉普拉斯的快速
海賽來檢測極值。一般而言高斯對於尺度空間分析是最優秀的，但是高斯需要離散 (discrete) 和裁切
(cropped)，顯示於圖 6(a)(b)，因此作者進一步地使用了盒子濾波器(box filters)，顯示於圖 6(c)(d)(e)，
這些近似高斯二階導數，並且可以快速的評估採用的積分圖像，其性能相當於一個使用了離散和裁切
的高斯濾波器。
(a) 高斯二階導數
y 方向
(b) 高斯二階導數
xy 方向
(c) 盒子濾波器 x 方向 (d) 盒子濾波器 y 方向 (e) 盒子濾波器 xy 方
向
圖 6: 高斯與盒子濾波器 [6]
將近似值計算出來後的步驟相同於 SIFT 特徵的作法，即為 pixel (x,y)位置點周圍的八個點，以及
上下各九個點，若此像素值為這些 26 個點中的極值，就作為特徵點。
Step 2：Orientation assignment
為了能夠擁有旋轉不變性的特性，必須確定特徵點的方向，首先計算哈爾小波 (Haar-wavelet) 的
x 和 y 方向，並且在此特徵候選點周圍圓半徑 6 倍的區域畫圓，顯示於圖 7(a)，其中使用於 SURF 的哈
爾小波型態顯示如圖 7(b)。主要方向的判斷是在滑動視窗覆蓋π/ 3 的角度計算所有的總和，得到主要
方向之後，繪出一個圍繞著特徵點的正方形區域，此視窗大小是 20 倍的邊長，顯示於圖 7(c)，特徵子
在不同的尺度之下顯示出不同的視窗大小。
(a) 圓形區域
(b) 哈爾
小波型態
(c) 矩形區域
圖 7：特徵子的尺度區域 [6]
Step 3：Descriptor Components
將上述的每一個正方形切割為 n × n 個區域，並把哈爾小波轉換結果的水平、垂直分別累加以及絕
對值再做累加的動作，即如圖 8 所示。圖 8 顯示出特徵子在三種區域中截然不同的強度模式之特性，
第一種是齊性區域 (homogeneous region)，所有的值都相當的低，顯示於圖 8(a)；第二種則是頻率出現
在 x 的方向，只有Σ|dx|的值是高的，其他的值皆保持低的狀態，顯示於圖 8(b)；最後一種是Σdx 和Σ
|dx|的值是高的，顯示於圖 8(c)。
8徵點即可受到加權，而其餘的資料庫特徵點將不予加權，經過此一方法後，實驗證實可提高執行準確
率。
5.3 利用幾何校正重新排序
使用字彙樹進行影像搜尋之後，提升了搜尋的速度，不過相對的準確率方面也受到微幅降低的影
響，為了挽回那些因此受到影響而影像排序的名次掉至後半段的影像，本研究的解決方法是對前m張
影像和查詢影像做幾何校正 (Geometric verification) [11]以達到重新排序的目的。
一般影像比對使用特徵子的 128 維向量作比對，很有可能找到對應的特徵點相似度高，但是此特
徵點卻與查詢特徵點無幾何對應的關係，此時可將此特徵點認定為非相似特徵點。例如：圖 12 所示，
其中黑色框線代表影像，黑色框線中的圓形、倒三角形、六角形、菱形以及正方形皆代表影像中的特
徵，淺藍色相連線代表兩張影像有比對的特徵，從圖 10 中可明顯看出雖然有比對到特徵點，但是這些
特徵在本身影像的位置與另一張影像上特徵的位置毫無對應關係，即所謂無幾何關係。
圖 10：特徵子之幾何關係說明
6. 影像相似度計算
一般而言，使用者在使用搜尋引擎查詢資料時，只會觀看搜尋結果的前幾頁，且每一頁所放置的
影像張數因網路傳輸速度而受限，所以若傳送未經過處理的影像結果給使用者，會使得使用者很困難
找尋想要的答案，因此我們需要考慮到影像相似度的問題，利用相似度排序影像查詢後的結果，使得
使用者想要的答案排在頁面的最前面。
6.1 Count Match
Count Match 主要運用於基本的比對實驗中，用以確保 SIFT、PCA-SIFT 和 SURF 特徵運用在我們
的資料庫上能有好的執行效能。當一張查詢影像與一張資料庫影像進行比對時，首先各自擷取影像特
徵，然後將兩張影像的影像特徵一一比對，當查詢影像的某一個特徵與資料庫影像的所有特徵計算距
離之後，第一近的距離必須小於第二近的距離乘上 0.6，此動作的目的是為了確保第一近的距離與第二
近的距離之間不會過於接近而造成模稜兩可的情況發生，其中此距離比率設定為 0.6，是在 SIFT 作者 [4]
經過實驗而得的結果。若符合以上的條件，那麼此張資料庫影像即被加上一分，待此張查詢影像與此
張資料庫影像的所有特徵皆經過距離計算並加權後，此張資料庫影像最後被加權的分數即為它的 Count
Match 數目。
6.2 Binary Match
接下來說明 Binary 的相似度計算方法，查詢特徵與字彙樹的群中心計算後決定落於某個影像字或
節點上，則此葉節點所隸屬的特徵點之影像皆被加上一分；反之，其他沒有被此查詢特徵選擇的影像
字或節點的特徵點之影像皆為零分，因為其相似度的加權值不是一即為零，因而取名為 Binary Match。
6.3 L1、L2距離
在影像搜尋時，首先計算特徵子與影像字之間的相似度，確定此特徵子落於哪一個影像字之下，為了
分析此特徵子在此影像字的重要性多寡，必須給予影像字權重，而後將計算後的距離分數加總在影像
上，即為影像的得分。距離計算方式分別使用 L1 與 L2 距離公式。
7. 實驗與討論
7.1 實驗環境
實驗的影像來源皆由經濟部智慧財產局商標檢索系統抓取而得，主要實驗的範圍為尼斯第一大類
「工業用化學品、科學用化學品、化學試劑」底下的維也那第十二大類「抽象幾何圖形」，圖像商標總
數量為 27,610 張，部份影像顯示於圖 11，而在此資料庫中影像最大的大小為 200 × 200 像素，格式包
10
稱此些樣本特徵點仍然可達到好的效能，即為 SURF 以及 PCA-SIFT 擷取。以 SURF 擷取影像特徵一
共有 2,458,803 個特徵，平均一張影像有 89.05 個特徵，特徵數量較 SIFT 特徵少 49%；以 PCA-SIFT
擷取影像特徵一共有 2,612,396 個特徵，平均一張影像有 94.6 個特徵，特徵數量較 SIFT 特徵少 52%，
實驗結果顯示於表 2。
表 2：另外兩種特徵於 Count Match 比對的準確率
特徵 TOP TOP 1 TOP 2 TOP 3
SURF 特徵 74.5% 80.5% 82%
PCA-SIFT 特徵 83% 89.5% 90%
7.3.3實驗三
在經過上述兩個實驗之後，可以發現無論是 SIFT、PCA-SIFT 或是 SURF 特徵，使用 Count Match
計算相似度皆能達到八成左右的準確率。
為了加快搜尋速度，我們使用了字彙樹，因此必須決定多少層(L)以及多少個群中心(k)。在字彙樹
的原文中，字彙樹作者 [7]利用了很多不同的參數，藉此找尋最好的效果，其中 k 選擇 10 時（L 的挑
選由特徵數量及 k 決定），得到了最好的結果，於是我們延用測試出得最好參數。而後各別對此三個特
徵進行 Binary、L1-norm 和 L2-norm 的相似度計算實驗，表 3 為實驗結果。
表 3：SIFT、PCA-SIFT 和 SURF 特徵使用 Binary、
L1-norm 和 L2-norm 等相似度計算方法的準確率
TOP
特徵與相似度 TOP 1 TOP 2 TOP 3
Binary 83% 86.5% 91%
L1-norm 44% 57% 635%
SIFT
特徵
L2-norm 43% 54% 64%
Binary 58.5% 66.5% 69.5%
L1-norm 32% 41% 435%
PCA-SIFT
特徵
L2-norm 30% 40% 46%
Binary 52.5% 58.5% 61.5%
L1-norm 28.5% 34.5% 41%
SURF
特徵
L2-norm 27% 32.5% 38%
綜合以上三個實驗的結果以圖表方式呈現於圖 13。由圖可知，SIFT 特徵在使用 Binary Match 方法
時，與 SIFT 特徵和 PCA-SIFT 特徵使用 Count Match 方法有不相上下的準確率，甚至於勝過 SURF 特
徵使用 Count Match 方法的情況，然而其他效能評估的方法之準確率皆低於七成五。因此對於我們的
資料庫，SIFT 特徵有較好的執行效能，而且在使用了 Binary 的情況之下，能使準確率高達九成左右，
因此以下的實驗皆以 SIFT 特徵在 Binary 方法之上進行改進實作。
0.25
0.35
0.45
0.55
0.65
0.75
0.85
0.95
TOP 1 TOP 2 TOP 3 TOP 4 TOP 5
Top N Precision
pe
rf
or
m
an
ce
(Exhausted) SIFT
(Binary) SIFT
(L1) SIFT
(L2) SIFT
(Exhausted) PCA-SIFT
(Binary) PCA-SIFT
(L1) PCA-SIFT
(L2) PCA-SIFT
(Exhausted) SURF
(Binary) SURF
(L1) SURF
(L2) SURF
圖 13：SIFT、PCA-SIFT 和 SURF 特徵使用 Count Match、Binary、L1-norm 和 L2-norm 等相似度計算
方法之比較
7.3.4實驗四
雖然上述的實驗已經有很不錯的實驗結果，但是在評估方法中提及，經過相似度的計算後，會有
一些影像有同分的情況發生，此種情況若發生在前面的名次(第一、二或三名)，將可能造成第三名的影
像被排至網頁的第二頁或更後面的情況。為了讓使用者能在網頁的前面或者第一頁的頁面中即可看到
12
0.82
0.84
0.86
0.88
0.9
0.92
0.94
TOP 1 TOP 2 TOP 3 TOP 4 TOP 5
Top N Precision
pe
rf
or
m
an
ce
Exhausted-
Count Match(SIFT)
Vocabulary tree-
Binary(SIFT)
Vocabulary tree-
Binary+Geometric(SIFT)
圖16：將Count Match、Binary和Binary加上幾何校正之比較
8. 結論
本論文使用三種特徵擷取方法的影像進行比較，由實驗可明顯得知，在我們的資料庫 SIFT 和
PCA-SIFT 特徵於基本比對實驗中，有差不多的準確率，而 SURF 特徵則比前兩者特徵略於遜色，由此
可見，SIFT 特徵確實比其他特徵更強健性。
由於，基本比對的實驗會花費過多的時間，於是我們使用字彙樹，以減少搜尋時間。但速度增快
後，準確率亦受到影響而下降，因此必須在準確率與速度之間取折衷，於是我們修改了貪婪的 N 條最
佳路徑搜索以及利用幾何校正將影像重新排序，皆成功的挽回失去的準確率。
目前的查詢影像是從搜尋引擎中找尋圖樣商標影像，如圖12所示，而運用在讓使用者可隨時查詢
的應用情境時，使用的查詢影像應該是讓使用者隨拍隨傳的自然影像，如圖17所示。若我們拿一整張
自然影像當做查詢影像，必定會產生過多不必要的雜訊，因而影響執行結果，因此必須知道使用者想
要查詢的圖樣商標在此影像中的哪個位置。其中一種方法是讓使用者自行圈選圖樣商標的正確位置，
另一種方法是未來可進行的方向，就是自動偵測圖樣商標的位置 [14][15]。
圖17：存在於自然影像中的圖樣商標
9. 參考文獻
[1] J. Schietse, J. P. Eakins, and R. C. Veltkamp, “Practice and Challenges in Trademark Image Retrieval,” Proceedings of International
Conference on Imgae and Video Retrieval, Pages 518-524, July 2007.
[2] M. Flickner, H. Sawhney, W. Niblack, J. Ashley, Q. Huang, B. Dom, M. Gorkani, J.Hafner, D. Lee, D. Petkovic, D. Steele, and P. Yanker,
“Query by Image and Video Content the QBIC System,”In IEEE Computer, volume 28, issue 9, pages 23-32, 1995.
[3] J. R. Smith, and S. F. Chang, “An Image and Video Search Engine for the World-wideweb,” In IS&T/SPIE Symposium on Electronic 
Imaging: Science and Technology (EI'97) - Storage and Retrieval for Image and Video Databases, 1997.
[4] D.G. Lowe, “Distinctive Image Features from Scale-Invariant Keypoints,”. International Journal of Computer Vision,Volume 60, Issue 2,
pages 91-110, 2004.
[5] Y. Ke, and R. Sukthankar, “PCA-SIFT: A More Distinctive Representation for Local Image Descriptors,” IEEE Computer Society 
Conference on Computer Vision and Pattern Recognition, pages 511-517, 2004.
[6] H. Bay, T. Tuytelaars, and L. V. Gool, “SURF: Speeded Up Robust Features,” Proceedings of the ninth European Conference on Computer
Vision, May 2006.
[7] D. Nister, and H. Stewenius, “Scalable Recognition with a Vocabulary Tree,” Computer Vision and Patern Recognition, Volume 2, pages 
2161-2168, 2006.
[8] M. Muja,and D.G. Lowe, “Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration,” In VISSAPP, Volume 60, pages 
331-340, 2009.
[9] A. K. Jain, “Data Clustering: 50 Years Beyond K-Means,” Patern Recognition Leters,Volume 31, pages 651-666, 01 June 2010.
[10] Grant Schindler, Mathew Brown, and Richard Szeliski, “City-Scale Location Recognition,”In Conference on Computer Vision and Pattern
Recognition, pp. 1-7, June 2007..
[11] A. Berg and J. Malik. “Geometric Blur forTemplate Matching,” In Proceedings ofIEEE Conference on Computer Vision and Pattern
Recognition, pages 607–614, 2001.
[12] R. Baeza-Yates, B. Ribeiro-Neto. “Modern Information Retrieval. ACM Press,” ISBN:020139829, 1999.
[13] van Rijsbergen, C.V.: Information Retrieval. London; Boston. Butterworth ISBN: 0-408-70929-4, 2nd Edition 1979.
[14] Raymond Phan , Dimitrios Androutsos. “ Content-based Retrieval of Logo and Trademarks in Unconstrained Color Image Databases using
Color Edge Gradient Co-occurence Histograms,” Computer Vision and Image Understanding, ISSN: 10773142,Volume 114, Issue 1, Pages
66-84, January 2010.
[15] A. Joly, O. Buisson. “Logo Retrieval with A Contrario Visual Query Expansion,” Proceedings of the seventeen ACM international 
conference on Multimedia, October 19-24, 2009.
14
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限）
學術成就：
此計畫所研究的影像搜尋技術，應用在拍賣影像搜尋、書背影像搜尋以及商
標影像搜尋，目前相關影像資料庫都已經抓取，在初步的實驗都能獲得不錯
的搜尋效能。已經陸續發表會議論文。若能在大型影像資料庫加速以及提升
搜尋準確度，應可發表不錯的期刊論文。
會議論文：
許耀仁, 梁尹蓁, 劉震昌, “基於物件偵測技術的行動視覺搜尋”, TANET,
Taiwan, 2009
劉震昌, 周秉宜, 王健駿, “以影像為基礎的書店自動化盤點系統”, NCS,
Taiwan, 2009
技術創新：
在書背搜尋的技術上，可以應用於圖書館的自動盤點系統，可以加速盤點與
減少人力，目前正在申請專利。
2別辨識從 Caltech 101 的論文之後有長足的進展，基本上還是需要收集適當的影像資料庫才能在學
術研究上有一致的必較，此次 Torralba 等人更近一步開始 ImageNet 的計畫，預計收集近 15,000
個影像類別。
在其他 session 個人比較有興趣的論文是: On Feature Combination for Multiclass Object
Classification，多類別物件的辨識正式個人目前研究的重點之一，此作者提供了相關軟體的網址:
http://people.ee.ethz.ch/~pgehler/。另外一個有趣的研究提到使用 Amazon 的 mechanical turk 機
制，可以付費讓使用者幫忙做一些人工的標註等，這是利用 crowd sourcing 的研究方式，可以讓
研究資料不會侷限在實驗室人力所能，而可以進行更大規模的資料集的收集與實驗。清大陳煥宗
教授是台灣少數有 Oral presentation 的發表者，他的論文 Landmark-Based Sparse Color
Representations for Color Transfer是關於在影像中找到重要影像的顏色 landmarks，如此可以有一些
有趣的應用:例如將一張影像的顏色，套用在另外一張影像上。此方法可以考慮使用在彩色影像壓
縮，或者是彩色影像搜尋上，當作重要的空間性顏色特徵。
二、與會心得
電腦視覺研究領域的學者真的很用功，此次會議的 Oral presentation 整個大會場在每一場都幾
乎坐滿了人。在 Poster session 海報前也不乏提問者，ICCV 不愧是高水準的會議，大家都抱持著
學習的心態來參加。
另外在國際上可以看到許多合作的範例，比如 Li Fei-Fei 是 Stanford，Torralba 是 MIT 的，
他們卻可以有實際的合作研究，這是值得國內學者學習的。因為電腦視覺領域進展很快，而且實
驗需要大量的資料集與相關的程式，才能進行比較，如果國內學者在相關領域的研究者可以互相
合作，貢獻出自己研究領域的程式集，形成研究群，這樣才有機會與國外競爭。如果大家都怕自
己的成果或程式被人家使用而搶先發表論文，這樣就沒有進步的空間，只能進行小規模或者局部
的研究，無法進行像是 ImageNet 等前瞻的研究。
四、建議
ICCV 會議因為接受率低，以往國內學者論文比較不易被接受，較無參加的機會。最近國科會
開放參加國際會議不用一定要論文被接受，這個改變個人覺得是好的。可以鼓勵國內學者參加較
優秀的國際會議，學習目前國際上研究的趨勢與新的方法，這樣才不會因為沒有辦法得知新的研
究趨勢而使用一些舊的技術，一般新的方法多會先發表在會議論文，一、兩年後才會刊登在期刊，
國科會應該鼓勵各研究人員多參加此類較尖端的研究會議。
五、攜回資料名稱及內容
ICCV 會議光碟片。
98年度專題研究計畫研究成果彙整表 
計畫主持人：劉震昌 計畫編號：98-2221-E-260-030- 
計畫名稱：以影像與視訊內涵為基礎的行動搜尋 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 0 70%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 8 0 100%  
博士生 1 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
