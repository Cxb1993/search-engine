 I 
少?守傳師-守傳說勵師? 
少?守傳說勵師? 
守?守?師?傳?少?：?李?師y科?說?少?少?師?UML 整點少?守敘稿i勵 識?忠2都?：?訊?整?李?師y勇?觀?對?：?UML 勇?對?李?守?守I科?權)
李?守說李?勇科科?傳n李?勇?對?李?：?守?李?守?守?忠2都?少?李r守?忠都傳?勵敘勇?守說李守：?忠o對?忠?勵?識?勇?訊置勇?：?師g守?李?師y識置忠?忠?守?
勇?勵?少?對?李?勇?渺r李U訊?稿z：?忠o傳?李H都?少?傳?科?勇?少?權)：?敘?傳?敘?勵?少?對?李?識置忠?李?師y稿 師?勇?訊?稿z：?忠?忠?勇都權?少?
權)少?守?師?對?李?勇?訊?稿z守?傳?傳?李H守旻對?：?李z守P敘?忠?渺?科T勇?勵?識?傳G勇?：?守?忠2都?少?勵?點?守?勇,守P守?敘?忠?忠?守?勇?守?
置?傳?傳?勇?勵?少?：?忠?守)勵?識?勇?守說勇c對g少?勇?李?科?識?渺A李識訊置：?守?稿?傳G勇?守?都?守?勇?少?守?勇?勵?識?都?科?91.24%：? 
守?守e：?李?師y少?渺?守?少?少?師?整點少?勇?稿?識?守敘稿i勵?識?忠2都?：?稿?識?科?守?忠o訊?勵?稿?李勵勇?少?忠?：?李a李勵師?敘?守?忠?
勇,渺?李a說?守?科?師b稿?：?整T守傳少?：?李?師y忠?守?說?守?訊?少?科?守?勇?訊?稿i守說勇c：?李r守?守?傳?對?都?守?守?師b稿?都?對?：?李?傳?
對?勇?訊?稿z李識少?說?：?敘?科?：?都?李敘少?敘v守?對?李?守?少?守說守?：?守P守?忠o勵?識?守?李?傳?對?勇都權?權)科?：?守?敘?忠?都?守?李敘勇都
稿 師?勇?師b稿?都?對?：?守?忠2都?守渺渺?敘v守?渺?李a稿 師?少?守?都?師b稿?都?對?：?勵?識?都?科?98.35%：?忠?守)渺?忠m守說勇?少?李?傳R
勇?稿?識?師?李?守C訊?：? 
 
權?點?守?：?守敘稿i：?師b稿?都?對?：?都?少?置?稿?說?忠A 
 
 
 
 
Abstract 
In this project, we construct an online handwritten recognition system of UML diagrams. We use a 
decision tree to do recognition. According to our observation, the shapes of the notations of UML diagrams 
almost look like rectangles or diamonds. Based on this characteristic, an input notation is first classified to the 
correct category. Then some notation features are extracted from the input notation and used to do final 
recognition. The advantages of our system are that we can accept free style input and our method is simpler 
and more efficient than previous methods. The recognition rate of the top three choices is 91.24%. 
We also present an online handwritten system for music score recognition. Music score is used to record 
a music song. People often used to compose a music score on the sheet of paper. In our system, we propose 
the pen based writing method and use multi-strokes to form a music notation. We extract the height, shape and 
direction from a stroke as the features and recognize it as a symbol. Then the symbol is combined with other 
symbols to form a music notation. The system is robust for a general use and supports enough music notations 
for composition. The recognition rate is 98.35%.  
 
Keyword: handwritten, music score, UML 
 2 
can help the original recognizer to select the best interpretation. This method can be adapted to any notation 
besides UML diagrams and has high recognition rate. However, a troublesome problem for this method is 
how the grammars train for new notations. 
2. UML NOTATION DATABASE 
UML diagrams have thirteen different types and more than forty different notations. However, some of 
these notations are used rarely and their shapes are more complex. In the project, we choose 23 notations 
based on UML concepts and the frequency of usage to recognize. These 23 notations are shown in Figure 2.1. 
In the project, we invite 20 persons to draw the 23 notations ten times for each and collect the ink data 
they draw. We randomly choose half of the ink data for training, and the rest for testing. 
 
 
Figure 2.1 Supported notations of the system. 
 
3. PROPOSED METHOD 
 The proposed method is based on a decision tree and shown in Figure 3.1. The whole process consists of 
four major phases： geometric feature extraction, category classifier, notation feature extraction (NFE), and 
final classifier. In the geometric feature extraction phase, some geometric features, such as convex hull, 
bounding rectangle, PA ratio and Area ratio, are extracted from the input notation. In the category classifier 
phase, the features extracted in the previous phase are used to classify the input notation to the belonging 
category. In the notation feature extraction phase, the input notation is divided into primitives and then we 
extract features like direction, location and distance from these primitives. In the final classifier phase, based 
on the extracted features, a similarity measure is provided. Based on the similarity measure, the result notation 
that is most similar to the input notation is determined. 
 4 
convex hull of an input notation “Actor”. 
3.1.2 Bounding Rectangle 
The bounding rectangle is the minimum rectangle containing the input notation. We scan all points of 
input notation to find the minimum values of x and y coordinates, and the maximum values of x and y 
coordinates. After finding these coordinates, we use them to establish the bounding rectangle of the input 
notation. Figure 3.3 shows an example of the bounding rectangle of an input notation “Actor”. The bounding 
rectangle is shown by red lines. After finding the bounding rectangle, we compute its perimeter and area. 
These values will be used in the following section. 
 
 
Figure 3.3 An example of the bounding rectangle of an input notation “Actor”.  
3.1.3 PA Ratio 
PA ratio proposed by Kimura [6] is defined as：          
CH
2
CH /AreaPerimeter  ratio =PA
,                             (1) 
where PerimeterCH denotes the perimeter of the convex hull of the input notation, and AreaCH denotes the area 
of the convex hull of the input notation. Note that the perimeter and area partly define the shape of an object. 
This ratio will be a constant for some kinds of shape. For instance, PA ratio = 16 for any square rectangle 
and PA ratio = 4π for any circle. Size independent is the main advantage of PA ratio. In the project, PA ratio 
is used to classify circle and line. 
 
3.1.4 Area Ratio 
Area ratio is also proposed by Kimura [6]. The ratio is defined as： 
BRCH/AreaArea  ratio =Area
 ,                                (2) 
where AreaBR is the area of the bounding rectangle of an input notation. 
Area ratio also has the property of size independent. In the project, we use this ratio to distinguish the 
rectangle and the diamond shape. 
 
3.2 Category Classifier 
After extracting geometric features, we use these features to classify the input notation to the correct 
category. The 23 supported notations are separated to five categories including circle, line, rectangle, diamond, 
and others. The classification of each notation is shown in Figure 3.4. Four different filters, namely circle 
 6 
 
Figure 3.5 The flowchart of the category classifier. 
3.2.2 Line Filter 
If the input notation does not belong to the circle category, it will be checked by the line filter. Here, we 
use PA ratio for line filter. Due to the PerimeterCH of a line is close to twice of the length of input notation and 
the AreaCH of a line is closed to the product of the length of input notation and ∆h which is the maximum 
distance between input stroke and its convex hull, the PA ratio of a line can be approximated by 
h
l
hl
l
ratioPA
∆
=
∆×
≈
4)2(
 
2
. Since ∆h << l the PA ratio should be large. Here, we take 120 as a threshold value 
obtained by training. Figure 3.6 shows two examples to explain why the PA ratio is greater than a threshold. 
In Figure 3.6, the black line is user’s input and the red line is the convex hull. To avoid the error of dividing 
zero, we set the PA ratio equal to 200 when the area of the convex hull of a line is equal to zero.  
 
Figure 3.6 Two examples to show the PA ratios of lines.  
Is Circle? 
Input 
Is Line? 
Is Rectangle? 
Is Diamond? 
Circle Filter 
Line Filter 
Rectangle Filter 
Diamond Filter 
Others Category 
 Rectangle Category 
Line Category 
Circle Category Yes 
Yes 
Yes 
 Diamond Category Yes 
No 
No 
No 
No 
 8 
category. In our experiments, after category classification the others category contains Actor and several 
rectangle notations which are ill-written. 
3.3 Notation Feature Extraction 
After the input notation is classified to a category, some notation features will be extracted for the final 
classification. Before extracting notation features, we will first segment the notation into several primitives, 
which will be described in the following subsection. The notation features extracted include the number of 
primitives, the direction of each primitive, the location of each primitive, the length of each primitive, and the 
hollowness of the notation. In the following subsections, we will describe how to extract features. 
3.3.1 Primitive 
A primitive is defined to be the minimum unit of a notation, which may be a line or an arc. The 
advantage of segmenting a notation to primitives is that it is much easier for the shape matching procedure to 
find the matching notation. All the notation features are extracted in primitive level except hollowness. 
To divide a notation to many primitives, we use 4-way chain code and the curvature of each point. The 
4-way chain code is shown in Figure 3.9. First we compute the chain code for each point. Then we compute 
the curvature of each point by 
)
))1()1(())1()1((
)1()1((cos  r
22
1-
p i
+−−++−−
+−−
=
iyiyixix
ixixC
 ,                (4) 
where x(i), y(i) denotes the x, y coordinates of point pi and Crpi is the curvature of point pi. After 
computing the curvature, we evaluate the curvature difference between two neighboring points to find the 
dominate points, which have curvature difference greater than a threshold. Finally, the notation is divided into 
several segments using the dominate points as cut points, each segment is considered as a primitive of the 
notation. When the notation is segmented to many primitives, we take the number of primitives, N, as the first 
feature. Note that we have two kinds of primitives: line and curve, which are decided by the sequence of chain 
codes of the primitive. To decide what kind of a primitive is, we evaluate the chain code difference between 
each two neighboring points in the chain code sequence and sum all of them. If the summation is larger than a 
threshold, we will decide that it is a curve; otherwise, it is a line. 
 
 
Figure 3.9 4-way chain codes 
 
1 
2 
3 
4 
 10 
3.3.3 Length Feature 
The length feature is a binary value which represents that a primitive is long or short. To extract this 
feature, we first find the longest primitive in a notation. Then each primitive is compared to the longest one. If 
the length of the primitive is larger than half of the longest one, it is considered as a long primitive; otherwise, 
it is a short one. The length feature is calculated by 




<
=
otherwise,2
        len(j)max
2
1
     len(i)  1)( jifiLEN
                     (5) 
where len(i) denotes the length of the ith primitive, and max len(j) denotes the length of the longest primitive 
in the notation. 
3.3.4 Hollowness 
The hollowness feature is the only feature extracted in the notation level. Hollowness means whether the 
shape is a solid one or not. A hollow shape has a property that there are no points near the gravity center of 
the shape. According to this property, we locate a rectangle with size 60% of the convex hull, and the center 
of the located rectangle is the same as that of the convex hull. If the number of points inside the rectangle is 
smaller than a threshold, the notation is considered as a hollow shape. Otherwise, the notation is not a hollow 
shape. Figure 3.11 shows examples of hollowness. Figure 3.11 (a) is a hollow shape, and Figure 3.11 (b) is a 
solid shape. The hollowness feature, H, is also a binary value and defined by 


 <
=
otherwise,2
  t        P If   1 recH
                                      (6) 
where Prec denotes the number of points inside the located rectangle, and t is a threshold value.  
        
Figure 3.11 Examples of hollowness. (a) A hollow shape. (b) A solid shape 
3.4 Final Classifier 
Feature vectors extracted from the operations described above, including N, DIR, LEN, and H, are taken 
for pattern matching at this phase. 
In order to obtain the most likely notation for the input notation, we use the inverse of 
sum-of-absolute-difference (SAD) as the similarity measure. Let notations T and T’ be the database notation 
and the input notation respectively, the similarity between T and T’ is calculated by 
∑
=
−
=
4
1
'
)(
i i
ii
K
FF
TSAD
 ,  
)(
1)(
TSAD
TS =
   ,                    (7) 
(a) (b) 
gravity center 
located rectangle 
 12 
Table 1. The recognition rate of top 1 choice and top 3 choices. 
Shape Top 1 Accuracy% Top 3 Accuracy% 
Activity 73(73/100) 86(86/100) 
Aggregation 88.78(87/98) 91.84(90/98) 
Activationbar 87.78(79/90) 88.89(80/90) 
Actor 87.78(79/90) 92.22(83/90) 
Branch 90.91(90/99) 100(99/99) 
Class 84.44(76/90) 92.22(83/90) 
Component 73.81(62/84) 86.9(73/84) 
Communication 100(98/98) 100(98/98) 
Dependency 81(81/100) 86(86/100) 
End 92(92/100) 92(92/100) 
Fork 89.29(75/84) 89.29(75/84) 
Generalize 97.96(96/98) 98.98(97/98) 
Initial 77(77/100) 81(81/100) 
Interface 78.65(70/89) 85.39(76/89) 
Lifeline 100(89/89) 100(89/89) 
Node 72.22(65/90) 86.67(78/90) 
Object 87.78(79/90) 88.89(80/90) 
Package 75.56(68/90) 92.22(83/90) 
State 71(71/100) 84(84/100) 
Swimlane 80.9(72/89) 91.01(81/89) 
Transition 94(94/100) 97(97/100) 
Use Case 89.89(80/89) 96.63(86/89) 
Total 84.62 (1816/2146) 91.24 (1958/2146) 
 
 14 
Second Year: An Online Handwritten Recognition System of Music Score 
1. Introduction 
Music score is a handwritten or printed form of music notations, and it is often used in music 
composition and music representation. It consists of staff, clefs, notes, rests, and signatures …, etc.  
The common way to record a music score is to write the score on sheets of papers by pencil or pen. As 
the computer technology grows rapidly, Musicians use computer to aid their composition. In early period, 
optical music recognition (OMR) is used to recognize the music score which is scanned to an image. However, 
the error rate of OMR system is relatively high and the editing work of the music score is slow and tedious 
[15]. Due to the inconvenience of OMR, the online music editing system is proposed. The system can directly 
output the editing resultant to musicians. Besides, more convenient systems are rapidly developing for user to 
write on the tablet. One is the “point and click” system, such as MagicScore Maestro [16] and Allegro [17], 
which selects music notations from menus or icons. Hence, the system can directly input the music notations 
without recognizing them. Nevertheless, the input processes are tedious and complicated due to many pen and 
mouse movements [18]. 
In order to reduce the tedious input processes, gesture-based music score recognition systems are 
developed. Musicians could use specific gestures to represent specific notations defined by systems. Forsberg 
et al. [19] proposed such a system which uses gesture and voice to input the music notations. In the gesture 
part, it combines Calligrapher system [20], Rubine’s gesture recognition system [21] and their recognizer to 
recognize the input gesture. The supported music notations are limited and are not sufficient for professional 
music editors, and some gestures are irrelative to the shapes of the corresponding music notations. This makes 
learning curve long and difficult. Anstice et al. [15] also proposed a gesture-based system called Presto. After 
that, Ng et al. [22] proposed an improved version denoted as Presto2, which improves both usability and 
speed of input, but the gestures in the system have little relation with the actual writing. The recognition 
accuracy of gesture-based system may be acceptable. However, in the gesture-based systems, users must learn 
and remember these miscellaneous gestures. Therefore, the gesture-based system is often very constraining 
for the user. 
Instead of learning miscellaneous gestures, pen-based handwritten systems are developed to catch the 
human writing styles. The characteristic of pen-based systems is that the writing styles is as the same as on 
sheets of papers. There are several methods proposed, like neural network, context-free grammar and SVM. In 
2003, George et al. [18] proposed such a system with artificial neural networks. They used a multi-layer 
perception to learn music notations and extract the features. The inputs of these handwriting systems are 
natural and direct for users, but the error rate may be alarmingly high. Subsequently, music notations can be 
recognized by the trained neural networks. Taubman et al. [23] proposed a handwritten music recognition 
system based on statistical moments. Nevertheless, the current system is not stable and not robust enough for 
a general use. In 2005, Macé et al. [24] proposed a generic method which recognizes the music score by 
context-free grammars and lots of recognizers. Unfortunately, the user must follow the writing orders and 
writing locations that are defined by professional musicians, and it is not friendly for the users that are not 
familiar with the music theory. Miyao and Maruyama [25] proposed a handwritten system based on time 
series data and image features. Their system uses dynamic programming and SVM algorithm to recognize 
handwritten music notations. However, only a small part of music notations is supported in the system. In 
 16 
 
3. The Proposed Method 
In this system, we recognize the input stroke as a symbol and then combine the symbol with other 
symbols to form a music notation.  
The flow diagram of the symbol recognition is shown in Fig. 3.1. The whole process consists of 4 major 
phases: preprocessing, simple symbol classifier, feature extraction and complex symbol classifier.  
 
After the symbol recognition, the notation recognition is conducted. Based on the semantic information, 
the output symbol would be combined with other existed symbols to form a notation. Finally, the system 
outputs the printed music notation and puts it at the exact location on staff. 
3.1 Preprocessing 
Table 2.2 Supported music notations.  
 (a) Bar line  
 
 
 
 
 
(b) Group    
 
 
   
(c) Determinable note 
 
 
 
 
 
(d) Uncertain note 
 
 
 
 
 
(d) Uncertain note 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Fig. 3.1 Flow diagram of the symbol recognition. 
 18 
and recognize it as HLine, VLine, Slash or UHook according to its slope. Once the stroke is recognized as a 
simple symbol, it would be output and exit the symbol recognition. 
3.3 Feature Extraction 
If a stroke is not classified as a simple symbol, we will do feature extraction from the stroke. Here, we 
take three kinds of features: height, shape and direction. 
3.3.1 Height 
Notations in music theory have height limitation. Since notations are formed by symbols, symbols also 
have the height limitation. We could extract the height of a stroke as a feature for rough classification. 
3.3.2 Shape 
As described in Section 3.1.3, each stroke will be divided into several segments. Every segment has its 
special shape. The number of shapes would be useful for classifying stroke. There are 7 kinds of basic shapes 
shown in Table 3.1.  
 
By the linearity and slopes mentioned in Section 3.2, we could determine if a segment is a horizontal line, 
vertical line, slash or backslash. If the segment does not belong to straight line, it may be a clockwise curve, a 
counter-clockwise curve, or a circle.  
The difference between the straight line and the curve is that the curve changes its direction very often. We 
could accumulate the direction change value to detect what kind of curve the segment is like.  
The last step is to calculate the number of every kind of shapes in the stroke. The vector of dimension 7 
containing numbers of seven shapes is viewed as a shape feature. 
3.3.3 Direction 
The direction is the sequence of writing direction in time order, and it could reflect the writing style of a 
symbol. The direction extracted from the stroke could help us clarify the difference among some symbols with 
similar shapes. We use the 8 way chain codes to represent the direction. We could extract the direction by 
eliminating the duplicate chain codes in the same direction. Note that the dimensions of the direction features 
of different strokes may be different. 
3.4 Complex Symbol Classifier 
Symbols except simple symbols are complex symbols. Features extracted from a stroke, including height, 
shape and direction, are taken for complex symbol matching at this phase. 
Based on these three features, we construct three classifiers separately, including height classifier, shape 
classifier and direction classifier. Because some symbols in some classifiers are similar and are hard to 
separate them, we build a three level decision tree to deal with this problem. The first level is the height 
classifier which roughly classifies symbols by the height feature. The second is the shape classifier which 
classifies symbols by the shape feature. The third level is the direction classifier which classifies symbols by 
Table 3.1 The 7 basic shapes. (1) Horizontal line. (2) Vertical line. (3) Slash.  
 (4) Backslash. (5) Clockwise curve. (6) Counter-clockwise curve.  
 (7) Circle. 
 
 
 
 
 
 
 
(1) (2) (3) (4) (5) (6) (7) 
 
 20 
 
3.4.3 Direction Classifier 
In the third level of the decision tree, we would find most likely symbol according to the direction feature. 
We measure the distance between the direction feature of the stroke and the direction templates in database. 
Because the direction features are variable in dimension, the distance measure could be considered as the 
string matching problem. We apply the dynamic programming to obtain the distance. 
Let {a1, a2,.., aI} denotes the direction feature and {bk1, bk2,…, bkJ} denotes the kth template in database. 
The accumulated distance gk(i,j) is calculated as follows: 
Initial values:
       
 





∞=
∞=
=
),0(
,   )0,(
0)0,0(
jg
ig
g
k
k
k
 
(3)
 
Recurrence formula: 
( )
),,(differnece                
)1,( ),,1( ,)1,1(min),(
kji
kkkk
ba
jigjigjigjig
+
−−−−=
 (4) 
where the difference is the chain code difference between chain code ai and chain code bkj. The difference is 
defined in Table 3.2.  
 
Table 3.2 Difference between two chain codes. 
ai \bkj 0  1  2  3  4  5  6  7  
0 0  1  2  3 4 3 2 1  
1 1  0  1 2 3 4 3 2 
2 2  1  0  1 2 3 4 3 
3 3  2 1  0  1 2 3 4 
4 4 3 2 1  0  1 2 3 
5 3 4 3 2 1  0  1 2 
6 2 3 4 3 2 1  0  1 
7 1 2 3 4 3  2 1  0  
 
      
  (a)                                 (b) 
Fig. 3.4 Groups in the shape classifier. (a) For low group. (b) For high group. 
 22 
 
3.6.3 Group Level 
In music theory, when two or more notes with filled head and flags appear successively, we could group 
them using a beam to replace the flags. When playing the music score, the notes with beam should be more 
connected than non-beamed notes. As writing, users always draw a horizontal line across the notes to 
represent the grouping action. In the group level, we group the notes to form a beamed note.  
Table 3.4 List of notes with the set of symbols forming them . 
Note name Type Components 
Determinable 2 Dots, 1 FClefArc  FClef 
Determinable 1 FClefArc  
Determinable 2 HLines, 2 VLines 
Determinable 2 Slashes, 2 VLines 
Determinable 1 HLine, 1 Slash, 2 VLines  
Determinable 2 UHooks, 2 VLines  
Determinable 1 HLine, 1 UHook, 2 VLines 
Sharp 
Determinable 1 Slash, 1 UHook, 2 VLines 
GClef Determinable 1 GClef  
1 LCheck, 1 NaturalRt  Natural Determinable 
1 LCheck, 1 8Rest 
Flat Determinable 1 Flat  
Whole note  Uncertain 0 or more Dot(s), 1 or more WHead(s) 
Half note  
 
Uncertain 0 or more Dot(s), 1 VLine, 1 or more 
WHead(s)  
Note with filled head 
 
Uncertain 1 or more BHead(s), 0 or more Dot(s), 
0 or more UHook(s), 1 VLine, 0 or 
more Slash(es)  
 Uncertain 1 or more BHead(s), 0 or more Dot(s), 
0 or more Slash(es), 1 VLine, 0 or 
more UHook (s) 
 Uncertain 1 or more BHead(s), 0 or more Dot(s), 
1 StUHook, 0 or more Uhook(s), 0 or 
more Slash(es) 
 Uncertain 1 or more BHead(s), 0 or more Dot(s), 
1 Lcheck, 0 or more Slash(es), 0 or 
more UHook(s) 
Whole rest  Uncertain 0 or more Dot(s), 1 WRest  
Half rest  Uncertain 0 or more Dot(s), 1 HRest  
Eight rest  
 
Uncertain 1 8Rest, 0 or more Dot(s), 0 or more 
HLine(s) 
Quarter rest  Uncertain 0 or more Dot(s), 1 QRest 
 
 24 
 
 
From the misclassified strokes, we find that the misclassification is due to that some users do not have 
any domain knowledge about the music theory, and they are not familiar with writing music notations. 
Sometimes they ignore the detail about the difference between symbols, like the curvature or the corners in a 
stroke. It makes some strokes ambiguous as trying to recognize. For example, if the user ignores the curvature 
between the slash and circle in BHead, the stroke is easily to be recognized as a WHead. 
For the misclassified strokes, we provide the semantic correction to correct the mistakes. There are two 
rules defined in note level of notation recognition. First, while a WHead is misclassified to BHead and 
combine with a Half note, the system would convert BHead to WHead and do the combination. Second, while 
a BHead is misclassified to WHead and combine with Note with filled head, the system would convert 
WHead to BHead and do the combination. By the semantic correction, the precisions of WHead and BHead 
raise to 99.48% and 99.38%. 
The total time of processing the 7292 testing data is about 157.38 seconds. Thus, the average processing 
time is about 0.0216 seconds per stroke. This is faster than Miyao-Maruyama’s method which takes 0.0731 
seconds per stroke by a PC (Pentium 4 CPU; 1.8GHz; 512MB memory). Thus, a user takes less waiting time 
while writing. Furthermore, our method is more suitable to migrate to the handheld devices with touched 
screen which have low computing power, and the user could compose a music score everywhere. 
Table 4.1 Precision of each symbol. (continued). 
Symbol name  Our method (%) 
Miyao- Maruyama’s 
method(%) 
Dot 100.00 99.73 
HLine 97.73 87.31 
VLine 100.00 100.00 
Slash 96.52 96.52 
UHook 100.00 93.85 
GClef 98.80 99.71 
FClefArc 98.55 93.68 
LCheck 99.71 90.81 
NatureRt 97.87 100.00 
Flat 98.69 100.00 
WHead 98.46 97.49 
BHead 96.70 99.85 
StUHook 96.90 99.78 
WRest 99.72 99.72 
HRest 100.00 100.00 
QRest 96.41 99.70 
8Rest 95.88 100.00 
Average 98.35 97.54 
 26 
USA, pp. 329-337, Jul. 1991. 
[22] E. Ng, T. Bell and A. Cockburn, “Improvements to a Pen-Based Musical Input System,” OzCHI’98: The 
Australian Conference on Computer-Human Interaction, Adelaide, South Australia, pp. 178-185, Dec. 
1998. 
[23] G. Taubman, “MusicHand: A Handwritten Music Recognition System,”Honor thesis, Brown University, 
2005. 
[24] S. Macé, E. Anquetil and B. Coüasnon, “A generic method to design pen-based systems for structured 
document composition : Development of a musical score editor,” In Proceedings of the 1st Workshop on 
Improving and Assessing Pen-Based Input Techniques, Edinburgh, Scotland, pp. 15-22, Sep. 2005. 
[25] H. Miyao and M. Maruyama, “An Online Handwritten Music Score Recognition System,” In 
Proceedings of the 17th International Conference on Pattern Recognition (ICPR 2004), Cambridge, 
United Kingdom, pp. 461-464, Aug. 2004. 
[26] S. Connell and A.K. Jain, "Template-based Online Character Recognition," Pattern Recognition 34(1), pp. 
1-13. 2001. 
[27] X. Li and N. S. Hall, “Corner detection and shape classification of on-line handprinted Kanji strokes,” 
Pattern Recognition 26(9), pp. 1315-1334. 1993. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 28 
3. 整M忠h整?都?李敘渺h：?李?都?渺?置d：?勇?置m稿x權?傳:守說師?：?傳?李?科?忠1李敘勇?少?整?都?勇科點科守?稿?
師u－對識?師?敘?師I李敘勇?勇都守?勇?少?置?對?：?稿?師u：?稿x權?勇科傳?少?忠：傳?師?少?守P訊?勇守－說－對守?
500 守?科?師?－說 
守?師?傳?少?李?師y少?李少渺?守?少?UML 整點少?守敘稿i勵?識?忠2都?守?少?整點少?勇?稿?識?守敘稿i勵?識?忠2都?：?守?
UML 整點少?守敘稿i勵?識?忠2都?少?：?訊?整?李?師y勇?觀?對?：?UML 勇?對?李?守 守I科?權)李?守說李?勇科科?傳n李?勇?對?李?：?
守?李?守?守?忠2都?少?李r守?忠都傳?勵敘勇?守說李守：?忠o對?忠?勵?識?勇?訊置勇?：?師g守?李?師y識置忠?忠?守?勇?勵?少?對?李?勇?渺r
李U訊?稿z：?忠o傳?李H都?少?傳?科?勇?少?權)：?敘?傳?敘?勵?少?對?李?識置忠?李?師y稿 師?勇?訊?稿z：?忠?忠?勇都權?少?權)少?守?
師?對?李?勇?訊?稿z守?傳?傳?李H守旻對?：?李z守P敘?忠?渺?科T勇?勵?識?傳G勇?：?守?忠2都?少?勵?點?守?勇,守P守?敘?忠?忠?守?勇?
守?置?傳?傳?勇?勵?少?：?忠?守)勵?識?勇?守說勇c對g少?勇?李?科?識?渺A李識訊置：?守?稿?傳G勇?守?都?守?勇?少?守?勇?勵?識?都?科?
91.24%：? 
敘?整點少?勇?稿?識?守敘稿i勵?識?忠2都?稿?識?科?守?忠o訊?勵?稿?李勵勇?少?忠?：?李a李勵師?敘?守?忠?勇,渺?李a說?守?科?師b
稿?：?整T守傳少?：?李?師y忠?守?說?守?訊?少?科?守?勇?訊?稿i守說勇c：?李r守?守?傳?對?都?守?守?師b稿?都?對?：?李?傳?對?勇?訊?
稿z李識少?說?：?敘?科?：?都?李敘少?敘v守?對?李?守?少?守說守?：?守P守?忠o勵?識?守?李?傳?對?勇都權?權)科?：?守?敘?忠?都?守?李敘
勇都稿 師?勇?師b稿?都?對?：?守?忠2都?守渺渺?敘v守?渺?李a稿 師?少?守?都?師b稿?都?對?：?勵?識?都?科?98.35%： 忠 )渺 忠m
守說勇?少?李?傳R勇?稿?識?師?李?守C訊?：? 
渺?科T李?師y勇都傳?師?勇?忠2都?：?守P忠m整?訊?勇,敘?整?忠?守?：?守?守e勇都科?傳?勇?勵?識?守說勇c：?少?守P忠m守?勇,守敘
科l對7置?少?李r守?：?!
!











 30 
! 都?少?少?：?少?少?少?少? 22 點?守I：?守? PNC2 勇?渺P李?少?傳?勇?少?李?少?勇?整T守傳：?識?守?科? Ijejoh!ebub!jo!Ufusjt：
對?渺P李?勇?守?師?科?守?觀?科?李?少?整?勇?整?勇3忠?敘?敘?：?少?科?都?少?少?守?師e勵稿少?說?識?勇?忠?李N整?守?勇?科o整?敘?敘?：?
守?勇,勇?忠?少?渺h少?置?李識對w少?少?少?敘N：?守?渺S李?勇?對w傳2少?少?少?少?忠c說?敘?勇?置A權y：?科O傳?李r守?敘?渺S李?李?李敘：?
對?渺P李?傳G李?科T：?整?敘?敘?忠?忠?少?少?渺?少?少?少?敘a識?說?科?權?：?勇?敘?置A點?整?敘?敘?勇?對?勵?：?!
! 都?守c少?：?科?少?對u忠?少?守?訊?勇?忠?傳m勇?李3師?：?觀敘忠?李3師?說?守3守?勇?守?守?訊F科?少?整?整?守?李v都?敘?敘?：?科?少?
守?科?點?敘?師?置?渺?渺S李?勇?權?勇?：?勇都守?訊勵傳?守旻對g守E李忠：?少?渺h忠稿李識科?稿?勵稿置m說?忠?李3師?敘?識P：?少?少?勇?權?傳2
傳G李?少?科T：?都：少?對?忠?李3師?少?敘忠守?傳?：?都?少?少?少?忠?李?守?勇?勇?科?忠1守說守?：?少?說?識?少?忠?李3師?勇?整?守?：?都d
置o科O守?李少少?科T：?守?科?訊?置m都?稿?勇?渺P守?對8：?守?李?對u忠?守?訊?勇?李3師?：?守科對8忠?對?李識勇?敘?守?勇?置A權z：?!
! 都?少?少?：?少?李對說?科:少?傳2守?傳?敘?敘?少?敘忠守O守?李對勵?訊勵：?守?勵?觀y守n對u少?渺敘勵?勇3敘?敘?：?守?傳2李3師?勇?少?都?
少?：?說?渺敘勵?勇3李3師?少?敘忠守?勵?：?師?傳?：?李?李識渺?少?李?勇?科o整?敘?敘?科?渺敘科?稿?李3師?：?渺敘勵?勇3敘?敘?勇?科O傳?守科
守?說?守3對?渺敘科?稿?李3師?科?守?勇:少?：?忠?對?守?守?傳?勇?：?李?少?少?置?觀敘渺敘科?稿?李3師?守?李?渺?敘忠渺敘勵?勇3敘?敘?：?師?
守?守?整?師?科?訊?置m勇?對w傳2少?都?忠稿李識科?稿?勵稿置m說?識?：?訊?守?渺?科T說?渺敘勵?勇3敘?敘?少?敘忠守?傳?：?忠?守)敘?忠?敘?敘?
勇?科?權?說?對?勵?：?訊?勇?科?點?李?勇?渺?渺?勇?置?觀L少?：?!
少?：?說?置m守科敘?!
! 訊?敘?敘U說?都?說?少?科?勇?科?訊?置m：?渺?少?勇?整A點對科?置A忠?忠?李?少?勇?渺?少?：?科?忠?都?師?守?科?少?李識都?稿?守?勇?少?
傳?勇?少?都?稿?守?勇?整T守傳：?訊?勇?置m觀b少?權y敘?整?訊F傳守都0：?敘c置勇科?忠?：?李?科?說?李?守?訊勵：?李識都?稿?守?少?都?守?整?
都?科?忠1少?勵?李w少?：?守?守科少?忠?對?少?忠?忠?少?都?守?勇?對?說?說?勵?勵?：?!
! 李?李?科?訊?置m少?：?對u忠?少?都?守?科O守?勇?李3師?：?守D科s傳2守?傳?敘?敘?：?忠?傳m勇?敘?敘?：?整?勇3忠?敘?敘?：?渺敘勵?勇3
敘?敘?：?忠－少?李N李3師?都?傳N少?少?李?都?守?勇?敘?整?說?科?權?：?李?守科少?守9說G少?置A勵?：?少?少?忠?置m敘?守?李N李3師?勇?忠?
李?稿傳訊?守?守科：?!
都?科?李?都?少?李?渺A勵0勇?忠?敘U守B敘n稿?科?訊?置m：?守?勇?對?傳?守?對?觀L科:勇?忠?守3守?整?少?敘忠敘U說?科?訊?置m：?少?守?
稿?勇?訊勵傳?都?科?對?守?對?觀L科:勇?少?科?都?：?渺h少?守P訊?李識都?稿?識e渺c勇?觀N觀L說?李置識?：?守?敘n守?科T忠?說?守?守科少?敘忠
守?勇?置A敘N少?科O李?都科傳?對?傳N忠?守3勇?整?李?忠?師y：?守?勇?守P守?勇?對H：?李?少?少?師?少?守O敘U說?都?說?科?訊?置m：?置B勵?
勇c守?敘N說?識?少?忠c科?忠1稿?敘?少?勇?守?傳?：?守3師y訊?勇?訊?敘?傳N李?師y科O守?科O守?勇?勇?李?：?!
渺?科T：?置A點?渺敘科?稿?李3師?勇?對?勵?：?科o整?：?守?少?傳N李?都?師?勵稿置m守?師?敘U守B李?李?勇?勵稿整?整?都?說?敘?忠?敘n稿?
科?訊?置m：?置A點?敘n科?置m傳N少?置?傳?少?勇?守渺科l：?置A點?對?觀L科:對8勇?守?整?：?守?少?勇都李識傳N少?忠?李v說?點李李忠對w勇?少?
師y：?觀b李?敘?忠?少?少?師?權I傳?勇?置?觀L：?勇?敘?點?點?少?師?：?!
少?：?李?對?敘U觀?科?敘N)傳守科?傳?科?敘N勇?都b*!
守c：?科?權?!
! 守?守?說?置m守科敘?少?勇都渺?少?勇?：?渺A勵0少?少?守?師?敘n稿?科?訊?置m勇?置?觀L勇?敘?權I傳?：?李識勇?訊:勵0李?勇?忠?勇?整?守?
點科對?忠?忠?對?勵?：?李?李H說?識?少?少?李N渺?傳?科?李?少?整?勇?說y少?守?：?守3少?少?勵0李?勇?忠?敘U說?科?訊?置m：?點科對?科?師?
說?訊?守?整?勇?整?守?：?李?科?科李守?李識敘?忠?李3師?勇?對?李v：?都?少?置?傳?點?師?李?李H師C整?：?科?敘忠忠o忠?對?點?觀?忠?忠?勇?：?
少?勇?對o傳?置m訊?李?科W李?：?對?勇,勵0李H勇?整?守?：?守?忠?科?說y少?守?：?守?置?傳?少?傳N少?對g守?勇?對?李v：?守?少?科?權?：?
整M傳?渺A李N敘U李?：?!
少?：?權?守?對?訊說守?說?少?少?師?!
! ! Qsphsbn!gps!Joufsobujpobm!Dpogfsfodf!po!3122!Nbdijof!Mfbsojoh!boe!Dzcfsofujdt-!
Joufsobujpobm!Dpogfsfodf!po!3122!Xbwfmfu!Bobmztjt!boe!Qbuufso!Sfdphojujpo：?科?訊?置m訊勵傳2
 32 
! !
權?守?對?訊說：?置m權?訊勵傳2! 權?守?對?訊說：?置m權?整T守傳傳?!

 2 
守?勇,勇?忠?少?渺h少?經?束識對w少?少?少?敘N：?守?渺S束?勇?對w傳2少?少?少?少?忠c說?敘?勇?經A攜y：?科O傳?束r守?敘?渺S束?束?束敘：?
對?渺P束?傳G束?科T：?整?敘?敘?忠?忠?少?少?渺?少?少?少?敘a識?說?科?攜?：?勇?敘?經A點?整?敘?敘?勇?對?勵?：?!
! 都?守c少?：?科?少?對u忠?少?守?訊?勇?忠?傳m勇?束3師?：?觀敘忠?束3師?說?守3守?勇?守?守?訊F科?少?整?整?守?束v都?敘?敘?：?科?少?
守?科?點?敘?師?經?渺?渺S束?勇?攜?勇?：?勇都守?訊勵傳?守?對g守E束忠：?少?渺h忠歐束識科?歐?勵歐經m說?忠?束3師?敘?識P：?少?少?勇?攜?傳2
傳G束?少?科T：?都：少?對?忠?束3師?少?敘忠守?傳?：?都?少?少?少?忠?束?守?勇?勇?科?忠1守說守?：?少?說?識?少?忠?束3師?勇?整?守?：?都d
經o科O守?束少少?科T：?守?科?訊?經m都?歐?勇?渺P守?對8：?守?束?對u忠?守?訊?勇?束3師?：?守科對8忠?對?束識勇?敘?守?勇?經A攜z：?!
! 都?少?少?：?少?束對說?科?少?傳2守?傳?敘?敘?少?敘忠守O守?束對勵?訊勵：?守?勵?觀y守n對u少?渺敘勵?勇3敘?敘?：?守?傳2束3師?勇?少?都?
少?：?說?渺敘勵?勇3束3師?少?敘忠守?勵?：?師?傳?：?束?束識渺?少?束?勇?科o整?敘?敘?科?渺敘科?歐?束3師?：?渺敘勵?勇3敘?敘?勇?科O傳?守科
守?說?守3對?渺敘科?歐?束3師?科?守?勇?少?：?忠?對?守?守?傳?勇?：?束?少?少?經?觀敘渺敘科?歐?束3師?守?束?渺?敘忠渺敘勵?勇3敘?敘?：?師?
守?守?整?師?科?訊?經m勇?對w傳2少?都?忠歐束識科?歐?勵歐經m說?識?：?訊?守?渺?科T說?渺敘勵?勇3敘?敘?少?敘忠守?傳?：?忠?守)敘?忠?敘?敘?
勇?科?攜?說?對?勵?：?訊?勇?科?點?束?勇?渺?渺?勇?經?觀L少?：?!
少?：?說?經m守科敘?!
! 訊?敘?敘U說?都?說?少?科?勇?科?訊?經m：?渺?少?勇?整A點對科?經A忠?忠?束?少?勇?渺?少?：?科?忠?都?師?守?科?少?束識都?歐?守?勇?少?
傳?勇?少?都?歐?守?勇?整T守傳：?訊?勇?經m觀b少?攜y敘?整?訊F傳守都0：?敘c經勇科?忠?：?束?科?說?束?守?訊勵：?束識都?歐?守?少?都?守?整?
都?科?忠1少?勵?束w少?：?守?守科少?忠?對?少?忠?忠?少?都?守?勇?對?說?說?勵?勵?：?!
! 束?束?科?訊?經m少?：?對u忠?少?都?守?科O守?勇?束3師?：?守D科s傳2守?傳?敘?敘?：?忠?傳m勇?敘?敘?：?整?勇3忠?敘?敘?：?渺敘勵?勇3
敘?敘?：?忠－少?束N束3師?都?傳N少?少?束?都?守?勇?敘?整?說?科?攜?：?束?守科少?守9說G少?經A勵?：?少?少?忠?經m敘?守?束N束3師?勇?忠?
束?歐傳訊?守?守科：?!
都?科?束?都?少?束?渺A勵0勇?忠?敘U守B敘n歐?科?訊?經m：?守?勇?對?傳?守?對?觀L科?勇?忠?守3守?整?少?敘忠敘U說?科?訊?經m：?少?守?
歐?勇?訊勵傳?都?科?對?守?對?觀L科?勇?少?科?都?：?渺h少?守P訊?束識都?歐?識e渺c勇?觀N觀L說?束經識?：?守?敘n守?科T忠?說?守?守科少?敘忠
守?勇?經A敘N少?科O束?都科傳?對?傳N忠?守3勇?整?束?忠?師y：?守?勇?守P守?勇?對H：?束?少?少?師?少?守O敘U說?都?說?科?訊?經m：?經B勵?
勇c守?敘N說?識?少?忠c科?忠1歐?敘?少?勇?守?傳?：?守3師y訊?勇?訊?敘?傳N束?師y科O守?科O守?勇?勇?束?：?!
渺?科T：?經A點?渺敘科?歐?束3師?勇?對?勵?：?科o整?：?守?少?傳N束?都?師?勵歐經m守?師?敘U守B束?束?勇?勵歐整?整?都?說?敘?忠?敘n歐?
科?訊?經m：?經A點?敘n科?經m傳N少?經?傳?少?勇?守渺科l：?經A點?對?觀L科?對8勇?守?整?：?守?少?勇都束識傳N少?忠?束v說?點束束忠對w勇?少?
師y：?觀b束?敘?忠?少?少?師?攜I傳?勇?經?觀L：?勇?敘?點?點?少?師?：?!
少?：?束?對?敘U觀?科?敘N)傳守科?傳?科?敘N勇?都b*!
守c：?科?攜?!
! 守?守?說?經m守科敘?少?勇都渺?少?勇?：?渺A勵0少?少?守?師?敘n歐?科?訊?經m勇?經?觀L勇?敘?攜I傳?：?束識勇?訊?勵0束?勇?忠?勇?整?守?
點科對?忠?忠?對?勵?：?束?束H說?識?少?少?束N渺?傳?科?束?少?整?勇?說y少?守?：?守3少?少?勵0束?勇?忠?敘U說?科?訊?經m：?點科對?科?師?
說?訊?守?整?勇?整?守?：?束?科?科束守?束識敘?忠?束3師?勇?對?束v：?都?少?經?傳?點?師?束?束H師C整?：?科?敘忠忠o忠?對?點?觀?忠?忠?勇?：?
少?勇?對o傳?經m訊?束?科W束?：?對?勇,勵0束H勇?整?守?：?守?忠?科?說y少?守?：?守?經?傳?少?傳N少?對g守?勇?對?束v：?守?少?科?攜?：?
整M傳?渺A束N敘U束?：?!
少?：?攜?守?對?訊說守?說?少?少?師?!
! ! Qsphsbn!gps!Joufsobujpobm!Dpogfsfodf!po!3122!Nbdijof!Mfbsojoh!boe!Dzcfsofujdt-!
Joufsobujpobm!Dpogfsfodf!po!3122!Xbwfmfu!Bobmztjt!boe!Qbuufso!Sfdphojujpo：?科?訊?經m訊勵傳2
勇?：?敘?識?說?點?說?整T守傳勇?說勵師?：?!
! ! Qspdffejoht!pg!3122!Joufsobujpobm!Dpogfsfodf!po!Nbdijof!Mfbsojoh!boe!Dzcfsofujdt：?
 4 
! !
攜?守?對?訊說：?經m攜?訊勵傳2! 攜?守?對?訊說：?經m攜?整T守傳傳?!
 
98 年度專題研究計畫研究成果彙整表 
計畫主持人：陳玲慧 計畫編號：98-2221-E-009-117-MY2 
計畫名稱：應用手寫辨識於 UML 與樂譜作曲之系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 5 5 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
Z. H. Ou and L. H. 
Chen, 
2011, ’’Hiding 
Data in 
Tetris’’, 
International 
conference on 
Machine Learning 
and Cybernetics 
2011, Guilin 
China, 10-13 
July. 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
博士後研究員 0 0 100% 
人次 
 
 
