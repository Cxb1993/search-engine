halftone image when compared to the 
previously published five algorithms. 
 
計畫緣由、結果與討論 
 
半調子技術[1]是將色階較多的影
像轉成色階較少的影像，現下主要用於
列印裝置與壓縮上。傳統的半調子技術
經常是原影像透過錯誤擴散的方式產
生。但是一旦我們將灰階影像轉換成半
調子影像後，便無法直接在半調子影像
上進行相關的影像處理。因此當我們想
要進行半調子影像處理時，必須先將半
調子影像轉成灰階影像。接著，在灰階
影像上進行相關的影像處理動作，最
後，再將處理過的影像利用錯誤擴散轉
換回半調子影像。而將半調子影像回復
成灰階影像的過程就是半調子影像回
復。傳統的做法上，主要可分為兩種：
第一種作法是將濾波器作用在半調子影
像來還原半調子影像的原始灰階值。第
二種作法是透過分群與學習的機制，從
大量的訓練樣本中找出半調子影像中黑
白像素的排列方式與灰階值之間的對應
關係。ㄧ般的情況下，當半調子影像回
復技術產生的灰階影像品值越接近原始
影像時，最後得到的半調子影像的品質
也會越好。因此，如何能設計出一個高
品質的半調子影像回復技術是一個相當
實用的課題。本計劃針對半調子影像相
關技術，提出以下兩個成果。 
 
 
(1) 植基於向量與紋理查表法的半調子
影像回復演算法 [2]： 
 
我們提出了兩個透過向量與紋理來
提昇半調子影像回復演算法的品
質。如圖(1)所示，在第一個演算法
中，不同於前人以每個像素的亮度
值來建立查詢表，我們所提出向量
式查詢表採用每個像素的亮度與它
周圍八個相鄰像素的亮度值來建立
向量查詢表。如圖(2)所示，在第二
個演算法中，我們結合第一個演算
法與基於離散餘弦轉換的學習機
制，來構成一個新的紋理式查表
法。我們選用了三十張訓練影像來
建構向量查詢表以及紋理式向量查
詢表以及另外五張常用的測試影像
來進行效能的評估。實驗結果顯
示，與先前所提出的三種半色調影
像回復演算相比之下[3-5]，可得到
最佳的 PSNR(Peak signal-to-noise 
ratio)影像品質。(本研究成果已並刊
登於 Expert Systems With Applica-
tions 期刊)。 
 
(2) 植基於梯度資訊並具有強邊效果的
可調式誤差擴散方法[6]： 
 
為了提昇半調子影像的對比度並維
持原有的影像品質，我們提出一個植
基於梯度資訊並具有強邊效果的可
調式誤差擴散方法。在我們的方法
中，如圖(3)所示，我們針對輸入影 
 
像中每個像素G(x,y)及其周邊像素
的灰階值及梯度值來進行動態的調
整二值化的門檻值 ( )T x y∆ , ，如此將
可使得半調子影像在保持影像品質
的條件下提昇邊緣區域的視覺對比
度。除此之外，如圖(4)所示，為了
進一步銳化邊緣，我們亦根據各個像
素中的梯度方向，來動態調整誤差擴
散的權重。透過不同的誤差擴散權
重，可將量化誤差沿著邊的方向擴散
給鄰近的像素，進而達到影像銳化的
效果。在六張典型的測試影像中，實
驗結果顯示我們所提出的植基於梯
度下並具有強邊效果的可調式誤差
擴散法與Floyd-Steinberg誤差擴散法
[7]、Eschbach and Knox所提出的方
法[8]、Hwang所提出的方法[9]、Feng
所提出的方法[10]以及Li所提出的
方法[11]相較之下，我們的方法雖然
需要一些額外時間的消耗，但所產生
的半調子影像可兼具增強邊資訊的
效果以及影像品質。(本研究成果已
並刊登於Expert Systems With Ap-
plications 期刊)。 
 
 
 
RULE_1: (for determining the modulated term ( )T x y∆ , ) 
if ( )G x y,  is an edge pixel then 
if ( )G x y,  is smaller than all neighboring pixels then 
( )T x y∆ ,  is set to a suitable positive value. 
else 
( )T x y∆ ,  is set to a suitable negative value. 
else 
( )T x y∆ ,  is set to zero. 
圖(3) 動態門檻值的決定 
 
RULE_2: (for determining the weights of error diffusion filter)  
If there is an edge crossing the current pixel ( )G x y,  then  
For each neighboring pixel ( )G x u y v+ , +  where 
 ( ) {(0 1) (1 1) (1 0) (1 1)}u v, ∈ , , , − , , , ,   
      The quantization error quantity diffused to   
   ( )G x u y v+ , +  is proportional to the edge   
       strength between ( )G x u y y+ , +  and   
     ( )G x y, .  
else  
diffuse the quantization error by using the traditional 
Floyd–Steinberg model. 
圖(4) 植基於踢度方向的錯誤擴散法 
 
 
This article appeared in a journal published by Elsevier. The attached
copy is furnished to the author for internal non-commercial research
and education use, including for instruction at the authors institution
and sharing with colleagues.
Other uses, including reproduction and distribution, or selling or
licensing copies, or posting to personal, institutional or third party
websites are prohibited.
In most cases authors are permitted to post their version of the
article (e.g. in Word or Tex form) to their personal website or
institutional repository. Authors requiring further information
regarding Elsevier’s archiving and manuscript policies are
encouraged to visit:
http://www.elsevier.com/copyright
Author's personal copy
In this paper, two improved LiH algorithms are presented. We
ﬁrst presented a vector- and lookup table-based (VLUT-based) IH
algorithm, called the VLIH algorithm, to improve the image quality
of the previous LiH algorithm. Different from the previous LiH algo-
rithm which only considers the gray value of each pixel to con-
struct the LUT, our proposed VLIH algorithm considers both the
gray value of each pixel and its eight neighboring pixels to con-
struct the VLUT. The proposed VLIH algorithm has better image
quality when compared to the previous LiH algorithm. Combining
the proposed VLIH algorithm and the DCT-based learning scheme,
an efﬁcient texture-based VLUT (TVLUT) is built up and it consti-
tutes the main part of our proposed second IH algorithm, called
TVLIH algorithm, to reconstruct gray images with higher quality.
In our implementation, thirty training images are used to build
up the VLUT and TVLUT; ﬁve popular 512  512 testing images
are used to justify the quality performance of our proposed VLIH
and TVLIH algorithms. Experimental results demonstrate that with
satisfactory execution-time performance, the proposed two IH
algorithms have the highest image quality performance when
compared to the previously published three LiH algorithms (Chang
et al., 2001; Mese & Vaidyanathan, 2001; Chung & Wu, 2005;
Huang et al., 2008).
The rest of this paper is organized as follows. In Section 2, the
revelent works are surveyed. In Section 3, the proposed ﬁrst VLIH
algorithm is presented. The proposed second TVLIH algorithm is
presented in Section 4. In Section 5, some experimental results
are demonstrated to show the image quality improvement of our
proposed algorithm. Some concluding remarks are addressed in
Section 6.
2. Relevant past works
In this section, ﬁve relevant past works, namely the LiH algo-
rithm (Chang et al., 2001; Mese & Vaidyanathan, 2001), the TLIH
algorithm (Mese & Vaidyanathan, 2001), the NNIH algorithm
(Huang et al., 2008), the parallel-based IH algorithm (Siddiqi & Sait,
2008), and the ELIH algorithm (Chung &Wu, 2005), are outlined. In
these ﬁve past LiH-based works, the LiH algorithmwill be surveyed
in detail.
Fig. 1 shows a 4  4 template T used by the LiH algorithm
(Chang et al., 2001;Mese & Vaidyanathan, 2001) and the kernel
symbol X denotes the estimated/reconstructed pixel. Template T
is used as a sliding window to build up the LUT. According to the
constructed LUT, the gray image can be reconstructed from the in-
put halftone image.
Before building up the LUT, suppose that initially we have a set
of M training image pairs {(Gm,Hm)j1 6m 6M} where Gm denotes
the mth original gray image and Hm is the corresponding halftone
image of Gm. The training halftone image Hm is obtained by apply-
ing the existing halftoning algorithm (Ulichney, 1987) to the origi-
nal gray image Gm. The LUT is realized by the array LUT[ ] to map
the input halftone image to the gray image. In each window sliding
step, the subimages of Gm and Hm covered by T are denoted as Sg
and Sh, respectively. Sh15; S
h
14; . . . ; S
h
1, and S
h
0 are the 16 binary values
of Sh, and Sh is encoded by
I ¼
X15
k¼0
2kShk ; ð1Þ
where I, 0 6 I < 216, is used as a mapping address of LUT.
Sg15; S
g
14; . . . ; S
g
1, and S
g
0 are the 16 gray values of S
g, and Sg10 is used
as the T-mapped gray value of Sh. In the LiH algorithm, the training
process to build up the LUT is described as follows:
 Step 1. Given M training image pairs {(Gm,Hm)j1 6m 6M}, the
template T is initially put at left-upper corner of G1 and H1. Ini-
tially, we have m = 1.
 Step 2. For each subimage Sh in Hm covered by T, the corre-
sponding mapping address I is calculated by Eq. (1).
Fig. 1. A 4  4 template T used in the LiH algorithm.
Fig. 2. The reconstructed results of the LiH algorithm. (a) and (b) 64  64 subimage of Barbara. (c) and (d) Halftone version of (a) and (b). (e) and (f) Reconstructed subimages
obtained by LiH algorithm. (g) and (h) Reconstructed subimages obtained by VLIH algorithm.
15574 Y.-H. Huang et al. / Expert Systems with Applications 38 (2011) 15573–15581
Author's personal copy
3. The proposed ﬁrst IH algorithm: vector- and lookup table-
based inverse halftoning (VLIH)
Before presenting our proposed ﬁrst IH algorithm, the VLIH
algorithm, let us point out the quality degradation problem in
the previous LiH algorithm. We take a 512  512 Barbara image
and its halftone image as the training pair to build up the LUT.
Figs. 2(a) and (b) show two 64  64 gray subimages. Figs. 2(c)
and (d) show the halftone subimages of Figs. 2(a) and (b), respec-
tively. Figs. 2(e) and (f) are two reconstructed gray subimages of
Figs. 2(c) and (d), respectively, by using the LiH algorithm. From
Figs. 2(a) and (e), it is observed that the LiH algorithm results in
some spot-like noises in the smooth region. In addition, Figs. 2(b)
and (f) show that for the non-smooth region, the textural content
is blurred by the LiH algorithm. Although we can perform postpro-
cess, such as the anisotropic ﬁlter (Yang, Burger, & Underwood,
1996), on the reconstructed gray images to improve the image
quality by removing noises; however, the textural content in the
non-smooth region will be blurred again.
Now, a modiﬁed vector- and LUT-based (VLUT-based) IH algo-
rithm, called the VLIH algorithm, is presented. Before presenting
the proposed VLIH algorithm, let us demonstrate its quality advan-
tage. Figs. 2(g) and (h) are the reconstructed results of the pro-
posed VLIH algorithm and we can observe that the proposed
VLIH algorithm can improve the image quality by suppressing
Fig. 5. Two halftone images and two corresponding gray images. (a) and (b) Two
halftone images. (c) and (d) The corresponding gray images of (a) and (b).
Template T Gray 
Subimage
Sg
Mean Gray 
Subimage
28182
TVLUT
DCT coefficients
Texture 
Type
0
0
3
3
1
Halftone 
Pattern
0
1
65535
65534
Training
Image
Pairs
Training 
Halftone 
Images
Template T
Halftone
Subimage
Sh
Training
Gray 
Images
Template T Gray 
Subimage
Sg
4x4 DCT
Texture-Based 
Classification
Fig. 6. The block diagram of the DCT-based learning process to build up the TVLUT.
Fig. 7. Sixteen basis vectors of 4  4 DCT.
15576 Y.-H. Huang et al. / Expert Systems with Applications 38 (2011) 15573–15581
Author's personal copy
4. The proposed second texture-based VLIH (TVLIH)
After presenting our proposed ﬁrst improved LiH algorithm, the
VLIH algorithm, in this section, we present a texture-based VLUT
(TVLUT) to reconstruct gray values with higher quality. According
to the DCT-based texture classiﬁcation scheme, we classify the
training set into several kinds of subsets, and then a TVLUT is con-
structed. Now we tale an example to illustrate why the proposed
TVLUT has quality advantage. Two 4  4 halftone subimages cov-
ered by T are shown in Figs. 5(a) and (b), and the corresponding
two 3  3 gray subimages covered by the template T0 are shown
in Figs. 5(c) and (d), respectively; by Eq. (1), we have
I1 = I2 = 3338. Although the two mapping address I1 and I2 are
equivalent, Figs. 5(c) and (d) are different, one with smooth texture
and the other with vertical texture. It indicates the quality
degradation problem of the VLUT. In what follows, the proposed
TVLUT is presented.
As shown in Fig. 6, a set of 4  4 training gray subimages Sg’s are
extracted from the training gray image G by T. For each Sg, we use
the 4  4 DCT (Ahmed, Natarjan, & Rao, 1974) to obtain its texture
feature which is given by
Fði; jÞ ¼ 1ﬃﬃﬃﬃﬃﬃ
2N
p CðiÞCðjÞ
X3
x¼0
X3
y¼0
f ðx; yÞcos ð2xþ 1Þip
8
cos
ð2yþ 1Þjp
8
ð6Þ
for 0 < i 6 4 and 0 < j 6 4. For i = 0(i– 0), we set CðiÞ ¼ 1ﬃﬃ
2
p ðCðiÞ ¼ 1Þ;
for j = 0(j– 0), we set CðjÞ ¼ 1ﬃﬃ
2
p ðCðjÞ ¼ 1Þ. The value of F(0,0) (i = 0
and j = 0) is called the DC coefﬁcient and the others are called the
AC coefﬁcients. Fig. 7 shows the sixteen basis vectors for 4  4
DCT. Applying these sixteen basis vectors to each 4  4 gray
Fig. 9. Visual effects for Lena’s face part. (a) Original face part. (b) The result by using the LiH. (c) The result by using the ELIH. (d) The result by using our proposed algorithm.
Fig. 10. Visual effects for pepper’s stem part. (a) Original stem part. (b) The result by using the LiH. (c) The result by using the ELIH. (d) The result by using our proposed
algorithm.
15578 Y.-H. Huang et al. / Expert Systems with Applications 38 (2011) 15573–15581
Author's personal copy
Step 2. Put the 4  4 template T at the left–upper corner of both
Hm and Gm to obtain the halftone subimage Sh and the gray
subimage Sg, respectively; put the 3  3 template T0 at the
left–upper corner of Gm to obtain the gray subimage S
g0 .
For subimages Sh,Sg, and Sg
0
, perform Steps 3–4.
Step 3. Perform the 4  4 DCT on Sg and compute Ea,Ev, and Eh by
Eqs. (7)–(9), respectively. If Ea < Ta, Sg is a STS and we set
J = 0; if Ev > Eh and Ev/(Eh + 1) > TR, Sg is a VTS and we
set J = 1; if Ev < Eh and Eh/(Ev + 1) > TR, Sg is a HTS and we
set J = 2; otherwise, Sg is a DTS and we set J = 3. The index
J denotes the texture type of Sg.
Step 4. Compute the mapping address I of Sh by Eq. (1). According
to I and J, perform
N½I; J ¼ N½I; J þ 1;
TVLUT½I; J;K ¼ TVLUT½I; J;K þ Sg0K for 0 6 K 6 8;
where array N[,] is used as a counter; Sg
0
0 ; S
g0
1 , . . ., and S
g0
8
constitute Sg
0
.
Step 5. Move T and T0 to the left-top corner of next subimage pair
and perform Steps 2–4 until all subimage pairs in the mth
image pair have been processed.
Step 6. Perform m =m + 1 and read the next training image pair.
Perform Steps 2–5 until all given training image pairs are
processed.
Step 7. For each encoded index pair (I, J), 0 6 I < 216 and 0 6 J < 4,
perform
TVLUT½I; J;K ¼ TVLUT½I; J;K
N½I; J for 0 6 K 6 8
to obtain the mean gray value of TVLUT[I, J,K]. Equivalently,
TLUT[I, J,⁄] does record the 3  3 mean gray subimage. Con-
sequently, the ﬁnal TVLUT has been constructed.
From the constructed TVLUT, the block diagram of reconstruct-
ing process in our proposed TVLIH algorithm is shown in Fig. 8.
From the input image H, the base gray image B is ﬁrst obtained
by applying the LiH method to H since we do not have the original
gray image to provide the texture features. Let G denote the recon-
structed gray image and each pixel in G is initialized to 0. By using
the 4  4 template T as a sliding window on B and H, at each time,
we have a base gray subimage Sb and a halftone subimage Sh.
Simultaneously, the 3  3 template T0 is used to obtain the gray
subimage Sg
0
each time. The 4  4 DCT is applied to Sb, and then
the texture classiﬁcation process is performed to obtain the value
of J. From the subimage Sh, the value of I can be calculated directly.
According to the values of I and J, the 3  3 mean gray subimage
can be gotten from TLUT[I, J,⁄]. Based on the Gaussian-based esti-
mation mentioned in previous section, the gray subimage Sg
0
is ob-
tained by
Sg
0
k ¼ Sg
0
K þ TVLUT½I; J;K WK ;0 6 K 6 8; ð10Þ
where Sg
0
K denotes the Kth gray value of S
g0 and W0 ¼ 116 ; W1 ¼
2
16 ; W2 ¼ 116 ; W3 ¼ 216 ; W4 ¼ 416 ;W5 ¼ 216 ; W6 ¼ 116 ; W7 ¼ 216, and
W8 ¼ 116. Following the movements of the template, the ﬁnally
reconstructed gray image can be obtained.
5. Experimental results
In this section, some experimental results are demonstrated to
show the quality performance comparison in the concerned ﬁve
IH algorithms, the LiH algorithm (Chang et al., 2001;Mese &
Vaidyanathan, 2001), the ELIH algorithm (Chung & Wu, 2005),
the NNIH algorithm (Huang et al., 2008), and our proposed VLIH
algorithm and TVLIH algorithm. The template size used in the
LiH algorithm, the ELIH algorithm, the VLIH algorithm and the
TVLIH algorithm is 4  4. For the NNIH algorithm, a 7  7 template
is used in the 49-49-1 radial-basis function-based neural network
for realizing the LUT. All the concerned experiments are performed
on the IBM compatible Pentium IV microprocessor with 3.2 GHZ
and 1 GB RAM. The operating system is MS-Windows XP and the
program developing environment is Borland C++ Builder 6.0.
The PSNR deﬁned in Section 3.2 is used to evaluate the quality of
the reconstructed gray image.
In our experiment, the Floyd error diffusion scheme (Ulichney,
1987) is performed on thirty 768  512 gray training images from
the Mese’s website to obtain thirty halftone images. After creating
the LUT, the ELUT, the radial-basis function in the neural network,
Fig. 13. Visual effects for airplane’s tail part. (a) Original tail part. (b) The result by using the LiH. (c) The result by using the ELIH. (d) The result by using our proposed
algorithm.
15580 Y.-H. Huang et al. / Expert Systems with Applications 38 (2011) 15573–15581
This article appeared in a journal published by Elsevier. The attached
copy is furnished to the author for internal non-commercial research
and education use, including for instruction at the authors institution
and sharing with colleagues.
Other uses, including reproduction and distribution, or selling or
licensing copies, or posting to personal, institutional or third party
websites are prohibited.
In most cases authors are permitted to post their version of the
article (e.g. in Word or Tex form) to their personal website or
institutional repository. Authors requiring further information
regarding Elsevier’s archiving and manuscript policies are
encouraged to visit:
http://www.elsevier.com/copyright
Author's personal copy
gradient magnitude and orientation of the current pixel and the
neighboring pixels of the current pixel. After the current pixel is
quantized to a halftone pixel by using the determined threshold,
an adaptive error diffusion ﬁlter whose weights are determined
adaptively is used to diffuse the quantization error to neighboring
pixels properly. In order to evaluate the edge enhancement and im-
age quality performance of the concerned error diffusion methods,
the Gaussian lowpass ﬁlter (Gonzalez and Woods, 2002) is used to
reconstruct the gray image from the resultant halftone one. Based
on the reconstructed gray image, the edge correlation and the peak
signal-to-noise ratio (PSNR) are used to measure the edge enhance-
ment effect and image quality effect, respectively. Based on six typ-
ical testing images, experimental results demonstrate that our
proposed GAED method has better edge enhancement perfor-
mance while preserving the smoothness effect when compared
to Floyd–Steinberg error diffusion method, the method by Esch-
bach and Knox, the method by Hwang et al., the method by Feng
et al., and the second variant by Li. Furthermore, experimental
results also show that the PSNR performance of the proposed GAED
method is better than that of the method by Eschbach and Knox,
the method by Hwang et al., the method by Li, and the method
by Feng et al., but only has some degradation when compared to
Floyd–Steinberg error diffusion method.
The remainder of this paper is organized as follows. In Section 2,
we review the Floyd–Steinberg error diffusion method. In Section
3, our proposed GAED method is presented. In Section 4, some
experimental results are carried out to demonstrate the compro-
mised advantage of our proposed GAED method between the im-
age quality and the edge enhancement effect. In Section 5, some
concluding remarks are addressed.
2. Survey of Floyd–Steinberg error diffusion method
Before introducing Floyd–Steinberg error diffusion model, some
notations are deﬁned. Let the input gray image and output halftone
image be denoted by G and H, respectively, where the pixel located
at (x, y) in G is denoted by G(x, y); the pixel located at (x, y) in H is
denoted by H(x, y). For convenience, the gray value of G(x, y) is nor-
malized to [0, 1] and the value of H(x, y) is quantized to 0 or 1. In
addition, W(x, y) denotes the weights of the error diffusion ﬁlter.
Fig. 1 shows the block diagram of Floyd–Steinberg error diffu-
sion method. The ﬁxed weights of the error diffusion ﬁlter in
Floyd–Steinberg model are shown in Fig. 2 where the pixel located
at (x, y) denotes the current pixel and the neighboring weights are
Wðx; yþ 1Þ ¼ 716,Wðxþ 1; y 1Þ ¼ 316,Wðxþ 1; yÞ ¼ 516, andWðxþ 1;
yþ 1Þ ¼ 116. Based on the row-major scanning order, Floyd–
Steinberg error diffusion method consists of the following three
steps:
Step 1 : According to the threshold T, the halftone pixel H(x, y)
can be determined by
Hðx; yÞ ¼ 0; if Gðx; yÞ < T
1; if Gðx; yÞP T

Step 2 : Calculate the quantization error e(x, y) by
eðx; yÞ ¼ Gðx; yÞ  Hðx; yÞ
Step 3 : Diffuse the quantization error e(x, y) to neighboring pix-
els based on the following equation:
Gðxþ k; yþ lÞ ¼ Gðxþ k; yþ lÞ þ eðx; yÞ Wðxþ k; yþ lÞ
where (k, l) 2 {(0, 1), (1, 1), (1, 0), (1, 1)}. If the current
pixel is the last pixel in the scanned image then stop the
algorithm; otherwise, go to Step 1.
3. Proposed gradient-based adaptive error diffusion (GAED)
method
After introducing Floyd–Steinberg error diffusion method, this
section presents the proposed GAED method with a good compro-
mise between the image quality and the edge enhancement effect.
We ﬁrst introduce how to apply Sobel edge detector (Gonzalez and
Woods, 2002) to the input gray image to extract the gradient and
the orientation information. The two 3  3 masks of Sobel operator
are shown in Fig. 3a and b, respectively, for obtaining the vertical
gradient and the horizontal gradient. Based on the two obtained
gradients rxG(x, y) and ryG(x, y) for G(x, y), the gradient magni-
tude MG(x, y) and the gradient orientation OG(x,y) can be com-
puted by
MGðx; yÞ ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ðrxGðx; yÞÞ2 þ ðryGðx; yÞÞ2
q
and
OGðx; yÞ ¼ tan1 rxGðx; yÞryGðx; yÞ :
In the proposed GAED method, all the gradient magnitudes of
the current pixel and the neighboring pixels are used to determine
the modulated threshold of the current pixel. After the current pix-
el is quantized to a halftone pixel by using the determined modu-
lated threshold, an adaptive error diffusion ﬁlter, whose weights
are determined by using the gradient magnitudes and gradient
( , )H x y( , )G x y
Weight error
( , )W x y
Threshold
T
( , )e x y
Fig. 1. The block diagram of Floyd–Steinberg error diffusion.
( , )x y ( , 1)x y
( 1, 1)x y( 1, )x y( 1, 1)x y
e 7
16
5
16
3
16
1
16
Fig. 2. The ﬁxed weights of the error diffusion ﬁlter in Floyd–Steinberg model.
-1 -2 -1
121
0 0 0
-1 1
1-1
0 2-2
0
0
Fig. 3. Two 3  3 Sobel masks. (a) The mask Gx for obtaining vertical gradient.
(b) The mask Gy for obtaining horizontal gradient.
1592 K.-L. Chung et al. / Expert Systems with Applications 38 (2011) 1591–1601
Author's personal copy
the resultant halftone image without degrading the quality of
smooth regions.
3.2. Determination of adaptive error diffusion ﬁlter
After the current pixel G(x, y) has been quantized to a halftone
pixel H(x, y), the quantization error will be diffused to neighboring
pixels based on the following rule to achieve the edge enhance-
ment effect for neighboring pixels.
RULE_2: (for determining the weights of error diffusion ﬁlter)
If there is an edge crossing the current pixel G(x, y) then
for each neighboring pixel G(x + u, y + v) where
(u, v) 2 {(0, 1), (1, 1), (1, 0), (1, 1)}
The quantization error quantity diffused to G(x + u, y + v)
is proportional to
the edge strength between G(x + u, y + y) and G(x, y).
else
diffuse the quantization error by using the traditional
Floyd–Steinberg model.
When the current pixel is in the smooth region, the weights of
the proposed adaptive error diffusion ﬁlter are the same as the
Floyd–Steinberg model in order to preserve the smoothness effect
in the resultant halftone image. To preserve the edge effect in the
resultant halftone image, for the case that there is an edge crossing
the current pixel, the weights of the error diffusion ﬁlter are
adjusted according to the edge direction in order to achieve edge
enhancement effect among the four neighboring pixels,
G(x + u, y + v) for (u, v) 2 {(0, 1), (1, 1), (1, 0), (1, 1)}. In order to
determine the weights of error diffusion ﬁlter, the function R
deﬁned as follows is ﬁrst used to measure the edge strength
between G(x + u, y + y) and G(x, y).
0
1
OG
DOG
π/2 π
Fig. 7. The gradient orientation degree function DFOG.
(x, y) R(x, y+1)
=0.32
R(x+1, y-1)
=0.17
R(x+1, y)
=0.12
R(x+1, y+1)
=0.65
7
16
5
16
3
16
1
16
(x, y)
Fig. 8. Determination of the adaptive error diffusion ﬁlter. (a) The R values of
G(x + u, y + v)’s for (u, v) 2 {(0, 1), (1, 1), (1, 0), (1, 1)}. (b) The weights of the error
diffusion ﬁlter corresponding for (a).
Fig. 9. Six testing gray images. (a) Boats. (b) Bridge. (c) Airplane. (d) Peppers. (e)
NTUSTlogo. (f) ESPLlogo.
Table 1
Edge enhancement effect comparison in terms of edge correlation.
Image Floyd Knox Hwang Li(1) Li(2) Feng GAED(1) GAED(2) GAED
Boats 92.6 113.2 105.2 164.2 97.9 109.2 119.7 96.9 131.3
Bridge 177.9 224.6 190.7 257.3 183.3 192.3 249.9 184.6 267.5
Airplane 102.9 122.7 115.7 167.2 102.2 123.9 131.9 107.2 144.6
Peppers 68.3 78.8 77.5 98.4 65.0 83.1 81.8 70.1 86.9
Average 110.4 134.8 122.3 171.8 112.1 127.1 145.8 114.7 157.6
NTUSTlogo 305.2 318.8 307.9 375.2 279.7 307.3 321.3 309.7 326.0
ESPLlogo 612.8 610.9 612.1 676.6 597.9 611.0 613.8 612.7 618.0
Average 459.0 464.9 460.0 525.9 438.8 459.2 467.5 461.2 472.0
1594 K.-L. Chung et al. / Expert Systems with Applications 38 (2011) 1591–1601
Author's personal copy
where rOG is set to p3 empirically. The value of DFOG is ranged from 0
to 1 where ‘0’ indicates that the gradient orientation of G(x, y) and
that of G(x + u, y + v) are perpendicular to each other and ‘1’
indicates that the gradient orientation of G(x, y) is equal to that of
G(x + u, y + v). The relationship between OG(x + u, y + v) and
DFOG(x + u, y + v) is shown in Fig. 7.
By Eqs. (6) and (7), suppose R(x, y + 1), R(x + 1, y  1), R(x + 1, y),
and R(x + 1, y + 1) have been computed. Based on the four edge
strength values, the four weights in Floyd–Steinberg model will
be adjusted to diffuse proper quantization errors to neighboring
pixels in order to preserve the edge enhancement or the smooth-
ness effect. Thus, the weight 716 is assigned to the neighboring pixel
whose edge strength, i.e. the R value, is maximal. By the same way,
the remaining three weights, 516 ;
3
16, and
1
16, are assigned to the pix-
els with the second maximal R value, the third maximal R value,
and the minimal R value, respectively. For example, in Fig. 8a, we
have R(x, y + 1) = 0.32, R(x + 1, y  1) = 0.17, R(x + 1, y) = 0.12, and
R(x + 1, y + 1) = 0.65. Form the four R values, Fig. 8b shows the four
adjusted weights of the proposed adaptive error diffusion ﬁlter, i.e.
Wðx; yþ 1Þ ¼ 516, Wðxþ 1; y 1Þ ¼ 316, Wðxþ 1; yÞ ¼ 116, and
Wðxþ 1; yþ 1Þ ¼ 716. Since the four weights are determined by
using gradient magnitudes and gradient orientations, the proposed
adaptive error diffusion ﬁlter can diffuse the quantization error
along the edge to achieve the edge enhancement effect.
3.3. Proposed GAED method
From the threshold-modulation scheme and the adaptive error
diffusion ﬁlter mentioned in the pervious two subsections, the pro-
posed formal GAED method consisting of the following seven steps
is presented to obtain halftone images with edge enhancement ef-
fect while preserving the smoothness effect.
Step 1: Given an input gray image G, scan G from the left-top cor-
ner to the bottom-right corner. For each scanned pixel
G(x, y) in G, calculate the modulated term DT(x, y) by
Eqs. (2)–(5).
Fig. 11. Visual effect for the subimage of halftone bridge image. (a) Floyd–Steinberg error diffusion method. (b) The error diffusion method by Eschbach and Knox. (c) The
error diffusion method by Hwang et al. (d) The ﬁrst error diffusion variant by Li. (e) The second error diffusion variant by Li. (f) The error diffusion method by Feng et al. (g)
Our proposed threshold-modulation scheme. (h) Our proposed adaptive error diffusion ﬁlter. (i) Our proposed GAED method.
1596 K.-L. Chung et al. / Expert Systems with Applications 38 (2011) 1591–1601
Author's personal copy
threshold-modulation scheme, the proposed adaptive error diffu-
sion ﬁlter, and the proposed GAED method. All the experiments
are implemented by using the AMD Athlon Processor 2.20 GHz
and 1.50 GB RAM. The operating system used is the MS-Windows
XP and the program developing environment is the Borland C++
builder 6.0. In our experiments, six testing images are used to com-
pare the edge enhancement effect, the image quality effect, and the
execution-time required in the current nine methods. Among the
six testing images, four popular natural gray images, boat, bridge,
airplane, and peppers, are shown in Fig. 9a–d, respectively; two
artiﬁcial gray images, NTUSTlogo and ESPLlogo, are shown in
Fig. 9e–h, respectively.
Here, two evaluation metrics, the edge correlation (Hwang
et al., 2004) and the peak signal-to-noise ratio (PSNR), are used
to evaluate the edge enhancement effect and the image quality ef-
fect of the halftone images obtained by running the current nine
halftoning methods on gray images, respectively. For calculating
the edge correlation measurement and the PSNR measurement
for each resultant halftone image, the Gaussian lowpass ﬁlter is
applied to the halftone image to reconstruct a gray image. From
the reconstructed gray image, the edge correlation measurement
is calculated by
ECGZ ¼ 1M  N
XM1
x¼0
XN1
y¼0
ECGZðx; yÞ
ECGZ ¼
X1
k¼1
X1
k¼1
Wðk; lÞDGðx; y; k; lÞDZðx; y; k; lÞ
DGðx; y; k; lÞ ¼ Gðx; yÞ  Gðx k; y lÞ
DZðx; y; k; lÞ ¼ Zðx; yÞ  Zðx k; y lÞ
ð8Þ
where G and Z denote the original gray image and the reconstructed
gray image, respectively; the matrix W is deﬁned by
W ¼
0:1035 0:1465 0:1035
0:1465 0 0:1465
0:1035 0:1465 0:1035
0
B@
1
CA ð9Þ
Fig. 13. Visual effect for the subimage of halftone airplane image. (a) Floyd–Steinberg error diffusion method. (b) The error diffusion method by Eschbach and Knox. (c) The
error diffusion method by Hwang et al. (d) The ﬁrst error diffusion variant by Li. (e) The second error diffusion variant by Li. (f) The error diffusion method by Feng et al. (g)
Our proposed threshold-modulation scheme. (h) Our proposed adaptive error diffusion ﬁlter. (i) Our proposed GAED method.
1598 K.-L. Chung et al. / Expert Systems with Applications 38 (2011) 1591–1601
Author's personal copy
proposed GAED method has the best edge enhancement effect
among the current methods except the ﬁrst variant of Li’s method,
and has better image quality effect than all the six previous edge
enhanced error diffusion methods listed from the second column
to the seventh column. Overall, Tables 1 and 2 have demonstrated
that our proposed GAED has a good compromise between the edge
enhancement effect in the halftone image and the image quality ef-
fect when compared to Floyd–Steinberg error diffusion method,
the method by Eschbach and Knox, the method by Hwang et al.,
the method by Li, and the method by Feng et al.
Besides edge enhancement effect and the image quality, Figs.
10–15 show the visual effect of resultant halftone images for the
current nine methods. From Figs. 10–15, it is observed that Knox
and Eschbach’s method and our proposed GAED method has better
visual effect among the current nine methods and it is in agree-
ment with the edge enhancement effect and the image quality ef-
fect as shown in Tables 1 and 2. Finally, Table 3 illustrates the
execution-time required in the current nine methods; our pro-
posed GAED method requires more execution-time than the other
methods.
5. Conclusion
This paper has presented the proposed GAED method for half-
toning gray images and diffusing the quantization error of the cur-
rent pixel to neighboring pixels efﬁciently. In the proposed GAED
method, the edge enhancement effect and the image quality effect
can be achieved by modulating the threshold in halftoning and
determining the weights of the error diffusion ﬁlter adaptively. Un-
der six testing images, experimental results have demonstrated
that with some execution-time degradation, the proposed GAED
method has good compromised advantage between the edge
enhancement effect and the image quality/visual effect when com-
pared to Floyd–Steinberg error diffusion method, the method by
Eschbach and Knox, the method by Hwang et al., the method by
Li, and the method by Feng et al.
Acknowledgements
K.-L. Chung was supported by the National Science Council of
ROC under Contract NSC99-2221-E011-078-MY3.
Fig. 15. Visual effect for the halftone ESPLlogo image. (a) Floyd–Steinberg error diffusion method. (b) The error diffusion method by Eschbach and Knox. (c) The error diffusion
method by Hwang et al. (d) The ﬁrst error diffusion variant by Li. (e) The second error diffusion variant by Li. (f) The error diffusion method by Feng et al. (g) Our proposed
threshold-modulation scheme. (h) Our proposed adaptive error diffusion ﬁlter. (i) Our proposed GAED method.
Table 3
Execution-time comparison in terms of second.
Figure Floyd Knox Hwang Li(1) Li(2) Feng GAED(1) GAED(2) GAED
Boats 0.016 0.031 0.078 0.047 0.093 0.094 0.578 0.203 0.625
Bridge 0.016 0.032 0.094 0.047 0.078 0.094 0.547 0.219 0.641
Airplane 0.015 0.032 0.094 0.063 0.078 0.093 0.531 0.188 0.61
Peppers 0.016 0.031 0.078 0.063 0.062 0.094 0.547 0.203 0.609
Average 0.0016 0.032 0.086 0.0550 0.0778 0.0938 0.551 0.203 0.621
NTUSTlogo 0.001 0.016 0.031 0.016 0.031 0.047 0.188 0.062 0.219
ESPLlogo 0.001 0.016 0.015 0.015 0.016 0.031 0.171 0.047 0.188
Average 0.001 0.016 0.023 0.016 0.024 0.039 0.180 0.055 0.204
1600 K.-L. Chung et al. / Expert Systems with Applications 38 (2011) 1591–1601
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/19
國科會補助計畫
計畫名稱: 植基於邊特徵的高品質半調子影像回復技術
計畫主持人: 黃詠淮
計畫編號: 99-2221-E-228-006- 學門領域: 影像處理
無研發成果推廣資料
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100%  
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
