1 
摘要 
由於視訊監視系統的普及，分析監視系統取得之視訊內容的應用也越來
越普遍。本計劃主要目的在開發一套人類異常行為分析系統，可針對固定式監
視系統取得之視訊內容，自動偵測是否有人類異常行為發生。此系統主要包
括：監視系統修正、物件分割、物件追蹤、動作追蹤、與異常行為識別等過程。
監視系統修正過程用於去除鏡頭所造成的陰影現象以及修正影像色調曲線的
非線性特性；物件分割過程可由輸入畫面中分割出有興趣的物件；物件追蹤過
程負責在連續畫面中追蹤物件；動作追蹤過程依物件移動軌跡，物件外形變
化，及物件內部變化產生適當的動作集合；最後，所產生的動作集合再與人類
異常行為動作集合做比對，以確定該物件的行為是否符合人類異常行為。本計
劃成果適合居家照護，保全監測，或犯罪行為偵測等應用，可自動偵測人類異
常行為，適時提出警訊。本計劃第一年已完成一套快速物件分割方法的開發及
實作，相關研究成果也已在多個研討會 [1-3]發表。  
關鍵字：背景估測，物件分割  
 
Abstract 
Due to the popularity of the surveillance systems, using these systems to analyze captured 
video stream are becoming more and more popular. This project is planned to develop a system 
for detecting abnormal human behaviors for fixed surveillance systems. Five processes are 
included in this system: the correction process of surveillance systems, object segmentation 
process, object tracking process, action tracking process, and abnormal behavior identification 
process. The correction process is used to remove the shading effect caused by lens and linearize 
the tone curves of captured images. In the object segmentation process, the interested objects are 
separated from an image. The isolated objects are then tracked and their moving paths are 
recorded in the object tracking process. To identify the behavior of an object, its action set is 
generated in the action tracking process according to the moving path, variations of contours 
and contents. Finally, the behavior of an object is determined by comparing its action set with 
abnormal action sets. The proposed method can detect abnormal human behavior from the video 
streams of surveillance systems and is especially useful in the in-home caring, security guarding, 
and criminal detection applications. In the first year of this project, we have developed and 
implemented an effective fast object segmentation approach. Some results of this project have 
published in some conferences [1-3]. 
Keywords: Background Estimation, Object Segmentation 
3 
 
圖一．背景抑制方法處理流程 
3.2 背景估測方法 
目前有許多學者[9]-[11]提出不同的背景畫面估測或更新的方式。Chien 等人[9]使用背
景註冊方法估測背景。Spagnolo 等人[10]計算目前影像與背景影像的像素平均亮度增益值，
然後再利用像素平均亮度增益值更新背景影像，使背景影像能反映光源變化。Colombari
等人[11]則記錄像素於一連串畫面中的值，再據以找出最適合作為背景的像素值。現有背景
估測方法主要問題在於當物件進入畫面並停留一段長時間後，物件會取代原先背景成為新
背景，而當物件離開後，需要一段時間才能回復原有的背景；很明顯的，在背景回復期間，
由於可用的背景資訊不足，會提高物件分割的錯誤率。 
3.3 陰影去除方法 
為了去除陰影區域對物件分割的不良影響，有許多改良式背景抑制物件分割方法
[9,12-14]被提出。Chien 等人[9]除了提出背景註冊方法外，為了避免光源變化與陰影的影
響，改用目前畫面與背景畫面的邊緣強度資訊做為背景抑制方法的輸入找出物件邊緣像
素，然後再利用後置處理方法填滿物件內部空洞。Stauder 等人[12]分析陰影的行為，將陰
影分成均勻的陰影與半陰影兩種，然後利用像素於目前畫面與前張畫面的差異值、比值、
與邊緣強度等資訊識別及去除陰影區域。Xu 等人[13]針對室內環境，使用目前畫面與背景
畫面的差異值、邊緣強度差異值、以及陰影成長方法找出及去除陰影區域。Jacques 等人[14]
則使用正規化相關值(Normalized Cross-Correlation, NCC)找出目前畫面與背景畫面中符合
陰影特性的像素（稱為陰影候選像素）。陰影候選像素及其周圍像素於目前畫面與背景畫面
之比值的變異數小於給定門檻值且陰影候選像素於目前畫面的值小於其於背景畫面的值
時，可被視為陰影像素去除。以上所提陰影去除方法中，Stauder 與 Xu 的方法需要花費較
多運算時間，不適合即時應用。Chien 與 Jacques 等人提出的方法則具有較快的執行速度，
但物件分割錯誤率也較高。 
4.研究方法 
為了降低物件分割錯誤率以及縮短物件分割執行時間，本計劃分別提出一個多層式背
景估測方法[1,15]以及一個具陰影去除能力之快速物件分割方法[2-3,16]。這兩個方法分別說
明如下： 
4.1 多層式背景估測方法 
為了降低背景回復期間所造成的背景錯誤情況，本計劃提出一個多層式背景估測方
Current Frame Ic 
Previous Frame Ip 
or Background Frame Ib
Frame Difference
Object Mask
Thresholding 
Post-processing
Id
CDM
5 
小於 T1，則靜止累積次數加 1，若靜止累積次數小於 T2(條件 C5)，此位置仍維持在檢
查新背景狀態(S2)；若靜止累積次數等於 T2(條件 C6)，則設定此位置的狀態為建立新背
景狀態(S3)。 
 建立新背景狀態(S3) 
此狀態處理過程為，若此位置的目前背景總使用層數小於最大可用層數，則設定背景總
使用層數加 1，然後將每一層背景往下一層搬，所空出的最上層背景(作用中背景)設定
為新背景（此位置於目前畫面的像素值），新背景建立完成(條件 C7)，設定此位置的狀
態為背景狀態(S1)。 
 檢查原背景狀態(S4) 
檢查此位置於原背景(最上層背景)的像素是否與目前畫面中的像素相同(差異值小於
T1)，如果是(條件 C15)，則將最上層的背景像素設定為目前影像中的像素，並且設定此
像素的狀態為背景狀態(S1)；否則(條件 C14)，設定此位置的狀態為檢查舊背景狀態(S5)。 
 檢查舊背景狀態(S5) 
檢查除了最上層之外的其它層背景是否與目前畫面中的像素相同(差異值小於 T1)，檢
查順序為由上至下檢查。如有找到符合的背景，即差異值小於 T1(條件 C10)，將狀態設
為取出舊背景狀態(S6)；否則轉移狀態至檢查新背景狀態(C9)並設定靜止累積次數為 0。 
 取出舊背景狀態(S6) 
將符合的背景層上方各層往下搬，然後將最上層背景設定為此位置於目前畫面中的像素
值，再設定目前像素狀態為背景狀態(S1)，完成取出舊背景工作(條件 C11)。 
 
使用上述方法所產生的背景，會受雜訊與光源變化的影響，導致當背景改變時，舊背
景無法完整回復，而產生如圖三所示的結果。 
   
 (a) (b) 
圖三‧背景影像：(a)Hall, (b)Block. 
為了改善上述問題，產生背景畫面後，再對背景畫面進行中位數濾波(median filter)處
理（使用 3×3 遮罩），處理後的結果如圖四所示。 
   
 (a) (b) 
圖四‧中位數濾波處理後的背景影像：(a) Hall, (b) Block. 
4.2 具陰影去除能力的快速物件分割方法 
為了有效且快速的去除陰影區域分割物件，本計劃利用去掉平均值之目前畫面與去掉
7 
為縮短執行時間，在去除目前畫面的平均值時，只計算 CDMd 中值為 1 的區域。 
 Shadow Removal 
此功能主要目的在去除CDM中物件區域的陰影像素，首先計算CDM中每個物件像素與
其周圍像素所組成區塊於Ic’與於Ib’中的區塊差異值(計算公式如公式(3)所示)，區塊差異
值小於給定門檻值TH2者即為陰影像素。其中，區塊大小為(2d+1)×(2d+1)，TH2與d的值
需透過實驗決定。 
[ ]2),(),(),( ∑∑
−= −=
++′−++′=
d
dj
d
di
bc jyixIjyixIyxD  (3) 
 Dilation 與 Erosion 
本物件分割方法利用像素與其周圍像素於目前畫面所組成之區塊與於背景畫面所組成
之區塊的區塊差異值來判斷像素是否為陰影。此作法在陰影與物件交接處由於有部份物
件像素被包含在陰影像素的周圍像素區塊內，以致這類像素通常會被當成物件而無法有
效去除。為解決此問題，我們在 Shadow Removal 之前先做 Dilation，將物件邊緣膨脹，
陰影區域被膨脹出去的像素位於背景區域，可被當成背景除去，物件區域被膨脹出去的
像素雖位於背景區域，因周圍像素區塊包含物件區域，通常無法被當成背景像素去除。
因此，在 Shadow Removal 之後，整個物件周圍將會多出一圈背景區域，此時可再使用
Erosion 運算將物件邊緣縮回。其中 Dilation 與 Erosion 運算的球大小固定為 3×3。 
 Post-processing 
此功能主要目的在去除物件遮罩中的小面積區域、雜點、小洞、及平滑邊緣。處理順序
為，先利用型態學閉合(close)運算將斷掉的邊緣連結起來，接著使用傳統元件連接方法
[17]計算並去除小面積白色與黑色獨立區域，最後利用型態學斷開(open)運算去除雜
訊，其中，型態學運算的球大小為 3×3。 
5.結果與討論 
為了比較所提方法與現有方法的好壞，我們分別將兩個方法與現有方法做比較，主要
比較項目為物件分割錯誤率，公式定義如下： 
一張畫面像素個數
錯誤像素個數錯誤率 =  (4) 
為求得錯誤像素個數，本計劃以手工分割測試影像，產生一組參考物件遮罩，然後計
算待測試之物件分割方法所產生的物件遮罩與參考物件遮罩中不同的像素個數。實驗中，
各物件分割方法的參數設定方式以得到最佳錯誤率為主，也就是所設定的參數可讓該物件
分割方法產生最佳錯誤率的結果。 
5.1 多層式背景估測方法 
為了解所提背景估測效果的好壞，我們比較了多層式背景估測方法(Proposed)與 Chien
等人[9]所提的背景估測方法(Chien)。實驗使用 Hall 和 Block 兩組測試影片，Hall 與 Block
畫面大小分別為 360x240 與 320x240，Hall 與 Block 的測試影像總張數分別為 110 張與 597
張。在我們的方法中，針對 Hall 與 Block 兩組測試影片，T1 與 T2 的值分別設定為(10, 20)
與(20, 50)。實驗開發環境為 MATLAB 7.1。圖六與圖七分別列出使用 Chien 與我們的方法
9 
表二可見，當我們的方法只有一層背景時效果也比 Chien 的方法好(錯誤率 2.84%)，主要原
因是我們的方法有對背景做中位數濾波而 Chien 的方法沒有。 
表二‧使用不同背景估測方法所產生之背景畫面進行物件分割的錯誤率比較表 
 Chien Proposed 
Hall 2.84% 1.71% 
Block 7.91% 6.35% 
5.2 具陰影去除能力的快速物件分割方法 
為了比較所提具陰影去除能力之快速物件分割方法與現有方法在分割效果與執行時間
上的差異，本實驗使用 Hall 與 Frank[9] (如圖八所示）前 90 張畫面做為測試影片，Hall 與
Frank 畫面大小分別為 360x240 與 320x240。為了降低背景畫面對物件分割方法的影響，兩
段影片的第一張畫面被用作背景畫面。此實驗比較我們的方法(Proposed)、Chien [9]、與
Jacques [13]等三種物件分割方法。在我們的方法中，針對 Hall 與 Frank 兩段測試影片(d, TH1, 
TH2)參數分別設定為(2, 25, 625)與(2, 55, 400)。所有實驗均在同一台個人電腦下執行，電腦
配備為 Pentium D 2.8 GHz CPU、1GB 記憶體、作業系統為 Microsoft Windows XP 
Professional、程式開發環境為 Microsoft Visual C++ 6.0。 
   
 (a) (b) 
圖八．測試影片：(a) Hall (b) Frank 
表三列出各物件分割方法處理 Hall 與 Frank 兩組測試影像的執行時間與錯誤率，表三
內所有時間皆為執行 10 次的平均值，時間單位為毫秒(ms)。從執行時間來看，我們所提出
的方法速度最快。與 Chien 的方法相比，我們的方法執行時間提昇了大約 47%~58%。與
Jacques 的方法相比，我們的方法執行時間提昇了大約 7%~39%。從物件分割錯誤率來看，
我們的方法也比其他方法來的好。 
表三、各物件分割方法平均每張畫面執行時間與錯誤率 
 Chien Jacques Proposed 
 執行時間 錯誤率 執行時間 錯誤率 執行時間 錯誤率 
Hall 21.51 ms 0.719% 9.84 ms 0.610% 9.13 ms 0.544% 
Frank 17.63 ms 0.426% 15.13 ms 0.459% 9.27 ms 0.412% 
5.3 結論 
本計劃本年度已開發完成一套適用於固定式監視系統的物件分割方法，所開發的物件
分割方法包括多層式背景估測與具陰影去除能力之快速物件分割兩部份。多層式背景估測
部份可存放多層背景，當畫面背景物件移動時，所顯露出來的背景區域可使用多層背景畫
面中的內容來更新，加快背景畫面回復速度，提昇估測得之背景畫面的可用性。實驗結果
顯示，當背景改變時，所提方法比現有方法可更快速的回復背景。使用所產生的背景畫面
進行視訊物件分割，也可明顯降低物件分割的錯誤率。在具陰影去除能力之快速物件分割
部份，使用去掉平均值之目前畫面與去掉平均值之背景畫面的差異值來分割物件，由於去
11 
計畫成果自評 
 原計畫相符程度與達成預期目標情況 
本計劃本年度預計完成工作項目有監視器校正與視訊內容物件分割兩部份，在監視器
校正部份，我們已實作一套監視器校正方法可校正監視器色調曲線與鏡頭所造成的畫面不
均勻現象[1][2]。在視訊內容物件分割部份，我們也開發實作了一個多層式背景估測方法[3,4]
以及一個具陰影區域去除能力之快速物件分割方法[5,6,7]。所從事的研究內容與計劃內容完
全相符，計劃所訂定的目標也全數達成。 
 研究成果之學術或應用價值 
本計劃研究成果已在多個研討會[3,5,6]發表，其中多層式背景估測方法[3]發表於台南
大學舉辦的數位內容管理與應用研討會，具陰影區域去除能力之快速物件分割方法則發表
至北台科技學院所舉辦的通訊應用研討會[5]以及 IASTED 所舉辦的訊號與影像處理研討會
[6] 。研究成果除了投稿至學術研討會之外，為了提昇研究成果的應用價值，我們也跟本實
驗室的另一補助單位工研院資通所合作申請專利[8]，希望能讓研究成果發揮最大的效益。 
 影像處理人才培育 
本計劃執行人員，主要包括三位碩士班學生以及多位大學部學生，碩士班學生主要負
責實作本計劃所提的多層式背景估測方法[4]與具陰影區域去除能力之快速物件分割方法[7]
以及多個相關方法，對其實作能力的提昇有很大的幫助。大學部學生則幫忙處理計劃管理
相關事務以及準備實驗所需視訊資料與手動分割物件遮罩資料，參與人員對計劃與實驗的
進行方式，都有更深入的了解。 
 參考資料 
[1] Yi-Ching Liaw, "Implementation of digital still camera ICC profile generator," PICS 2001, Quebec, 
Canada, April 2001. 
[2] Yi-Ching Liaw, Chao-Hua Wen, Chun-Yen Chen, Jim Z. C. Lai, "Lightness equalization algorithm 
for tone curves unknown input device," CVGIP2001, KenDing, Taiwan, Aug. 2001. 
[3] 廖怡欽、陳易顯、黃崇仁、與賴榮滄 "針對視訊串流之多層式背景估測方法," The Second 
conference on Digital Content Management and Applications, Tainan, Taiwan, June 2007.  
[4] 陳易顯, 針對視訊串流之多層式背景估測方法, 南華大學資訊管理系, 碩士論文, 2007 年 6 月. 
[5] 廖怡欽、邱舶軒、黃崇仁、與賴榮滄 "去均值影像之視訊內容物件分割方法," The 5th conference 
on Communication Applications, Taipei, Taiwan, March 2007. 
[6] Yi-Ching Liaw, Bo-Shuan Chiu, Jim Z. C. Lai, and Patrick Huang, "A fast approach of object 
segmentation for video sequence," The Ninth IASTED International Conference on Signal and Image 
Processing, Honolulu, USA, August 2007. (EI) 
[7] 邱舶軒, 使用去均值影像之物件分割方法, 南華大學資訊管理系, 碩士論文, 2007 年 6 月. 
[8] 黃崇仁, 李政旻, 廖怡欽, 與賴榮滄, "視訊物件分割方法," 2006/12 申請. 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 95-2221-E-343-006 
計畫名稱 適用於監視系統之人類異常行為自動偵測 
出國人員姓名 
服務機關及職稱 
廖怡欽 
南華大學助理教授 
會議時間地點 民國 96 年 8 月 20 日至民國 96 年 8 月 22 日 
會議名稱 第九屆 IASTED 訊號與影像處理會議(Signal and Image Processing 2007) 
發表論文題目 A fast approach of object segmentation for video sequence 
 
一、參加會議經過 
 
此次出國主要目的是至美國檀香山 Signal and Image Processing 2007 會議（附件一）
發表論文(附件二)，本人報告時間為民國 96 年 8 月 22 日早上 Session 10：Video processing 
and coding II 的最後一場。此會議由國際科學與科技開發協會(IASTED)舉辦，會議文章
接受率大約 38%，會議文章也被 EI 所收錄，是一個很好的會議；會議地點在檀香山喜來
登威基基飯店，開會地點氣候風景皆宜人，可有效調節開會氣氛及舒緩報告人的緊張心
情。 
會議 8 月 20 日(一)開始，本人搭乘華航班機 8/19（日）早上大約 6 點半到，對開會
地點週遭環境及會議室的分佈先做個了解，會議地點旁邊就是沙灘，風景宜人，雖然太
陽很大，但很涼爽。 
會議第一天(8 月 20 日)早上 8:00 報到，人很多，排了大約半小時才完成報到，拿到
一個背包，內含一份會議議程及論文光碟。報告完成後，進 Niihou 廳聽大會主席介紹信
號及影像處理的現況及未來展望，隨後聽取 Illinois 大學香檳分校的 Dr. Nahrstedt 介紹他
們開發的一套浸入式互動系統，該系統可在不同地點佈置立體取像裝置(由四個攝影機組
成，一個彩色三個黑白)，然後將所擷取到的人像於電腦中合成，不過仍有許多問題有待
克服。接著，進 Honolulu 廳聽 Filters and wavelets I，由於第三天我也是在這間房間報告，
可以先熟悉一下報告環境。由於附近有工程進行，Honolulu 廳的報告受到很大的影響，
坐在底下聽不到報告人的聲音，有點可惜。下午則是一場關於如何建立一個自動程式產
生器的演講，演講者介紹現有多種自動程式產生器的建構方法，以及介紹一個簡單的自
動程式產生器開發過程。今天與多個相關專家交談才知道 IASTED 在同一會場同時有五
場會議進行，所以遇到了不同領域的專家，大部份是網路專家，也有生醫與水資源及工
業工程的專家。 
會議第二天(8 月 21 日) 早上安排加州理工學院 Prof. Emmanuel Candes 介紹他們做
的研究，該研究有關於如何在取樣過程中去除無意義的訊號，降低資訊量，演講中展示
許多證據證明許多取樣訊號可在取樣時期就被丟棄，不會造成訊號太大的失真；不過，
這個作法似乎與常用的訊號壓縮方法類似，因此受到許多質疑。隨後，又到 Honolulu 廳
聽 Session 4: Video processing and coding I。 
 附件一：會議議程 
 
 MONDAY, AUGUST 20, 2007  
07:00 – 08:30 REGISTRATION  
08:30 – 09:00 WELCOME ADDRESS  
09:00– KEYNOTE ADDRESS – “INTERNET AND MULTIMEDIA SYSTEMS CHALLENGES IN NEXT 
GENERATION TELE-IMMERSIVE ENVIRONMENTS”  
10:00 – 10:30 COFFEE BREAK  
10:30 – SESSION 1 – DIGITAL IMAGE AND PROCESSING 
10:30 – SESSION 2 – FILTERS AND WAVELETS I 
14:00 TUTORIAL PRESENTATION – “BUILDING A MULTI-PURPOSE GENERATOR ENGINE 
AUDITION”  
15:30 – 16:00 COFFEE BREAK 
16.00 – TUTORIAL CONTINUED 
 TUESDAY, AUGUST 21, 2007  
09:00 – SIP KEYNOTE PRESENTATION – “COMPRESSIVE SENSING” 
10:00 – 10:30 COFFEE BREAK 
10:30 – SESSION 3 –SPEECH PROCESSING AND ACOUSTICS I 
10:30 – SESSION 4 – FILTERS AND WAVELETS I 
10:30 – SESSION 5 – COMPUTER VISION AND IMAGING I 
14:00 – SESSION 6 – VIDEO PROCESSING AND CODING I 
14:00 – SESSION 7 – SIGNAL PROCESSING AND APPLICATIONS 
14:00 – SESSION 8 – IDENTIFICATION, DETECTION, AND ESTIMATION 
15:30 – 16:00 COFFEE BREAK 
16:00 – SESSION 6, 7 AND 8 CONTINUED 
 WEDNESDAY, AUGUST 22, 2007  
09:00 – SESSION 9 – SPEECH PROCESSING AND ACOUSTICS II  
09:00 – SESSION 10 – VIDEO PROCESSING AND CODING II  
09:00 – SESSION 11 – MEDICAL IMAGE AND PROCESSING I 
10:00 – 10:30 COFFEE BREAK 
10:30 – SESSIONS 9, 10 AND 11 CONTINUED 
13:30 – SESSION 12 – BIOMETRICS AND HUMAN IMAGING 
13:30 – SESSION 13 – COMPUTER VISION AND IMAGING II 
13:30 – SESSION 14 – MEDICAL IMAGE AND PROCESSING II 
14:30 – 15:00 COFFEE BREAK 
16:00 - SESSIONS 12, 13 AND 14 CONTINUED 
 
 
difference of a pixel is greater than the threshold value, 
the corresponding pixel in the current frame is determined 
as an object pixel. Otherwise, it is a background pixel. In 
the thresholding process, the change detection mask 
(CDM), which records 1s for object pixels and 0s for 
background pixels, of the current frame will be generated. 
Finally, the post-processing process is applied to remove 
unwanted small regions and noisy pixels and generates 
the object mask for the current frame. 
  
Object Mask
Thresholding
Post Processing
previous frame or
background frame
current frame
CDM
difference frame
Frame Difference Calculation
 
Figure 1. The procedure of BSS method 
 
Figure 2 uses the video stream “Hall” as an example to 
illustrate the current frame, referenced frame, CDM, and 
object mask, where the referenced frame is the 
background frame of the video sequence. 
 
 
 (a) (b) 
 
 (c) (d) 
Figure 2. An example of the (a) current frame, (b) 
referenced frame, (c) CDM, and (d) object mask. 
 
The BSS method as described above is easily influenced 
by the variation of lighting condition on the background 
region of current frame. That is, the light variation on the 
background region may result in poor segmentation using 
BSS. Once the light condition is changed, the gray level 
of background region will be changed accordingly. This 
will misclassify a background pixel as an object pixel. To 
solve this problem, many modified BSS methods are 
proposed [6-9]. In this paper, a new fast approach of 
object segmentation is presented in Section III. 
 
 
3.  Proposed Object Segmentation Method 
 
In this section, we will present our proposed object 
segmentation approach. The proposed method extracts 
objects for video streams using the difference information 
between the mean-removed current frame and background 
frame. Since the mean-removed version of a frame 
reduces the influence of light variation on background 
region and reserves the texture information of the frame, 
we can extract objects more accurately from video 
streams and remove shadow area from object regions 
using mean-removed frames instead of using the original 
frames. The major procedure of the proposed algorithm is 
depicted in Fig. 3. A more detail explanation is given in 
the following subsections. 
 
OMi
Mean Removal Dilation
Shadow Removal
Post-processing
Erosion
Mean Removal
Background frame Ib Current frame Ic
OMf
OMp
CDMd
CDMi
I'b I'c
CDM Generation
 
Figure 3. Procedure of object segmentation using 
mean-removed frames 
 
3.1 CDM Generation 
 
In the process of generating CDM (change detection 
mask), the gray level difference between a pixel in the 
current frame Ic and its corresponding pixel in the 
background frame Ib is calculated and is used to determine 
whether the pixel is an object or a background pixel. If the 
difference is less than a given threshold TH1, the pixel is 
classified as a background pixel and the CDM of this 
pixel is set to 0. Otherwise, it is of an object pixel and the 
corresponding CDM is set to 1. Finally, the initial change 
detection mask CDMi for the current frame is generated. 
 
3.2 Mean Removal 
 
This process is to remove the mean value of each pixel in 
the input frame. Let I(x,y) be the gray level of the pixel at 
position (x,y) in frame I, the mean value of gray level for 
the pixel at position (x,y) is defined as 
 
