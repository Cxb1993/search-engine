 
 
II 
 
中文摘要 
為了讓電腦藉由各項數位服務提供人類更好的生活品質，本計畫將研究如何建構一個具
備多重感測能力及多重互動方式的智慧型環境作為提供數位服務的平台，並在平台上發展一
個具備高度整合能力的系統，此即導致建構一「人性化電腦整合智慧型環境」的終極目標。 
為達此目標，須先達成數項技術指標，首先，以電腦視覺為基礎之人形偵測系統，係涵
蓋所有智慧型環境空間，以達到多目標無間隙追蹤（Seamless Tracking）與定位（Localization）
為其目的；於此部分透過貝氏網路整合背景模型(Background Modeling)與運動資訊(Motion 
Information)，有效在不受光線變化影響下，成功將影像前景切割出來。接著透過階層式人形
資料庫的架構，經由 Hausdorff 樣板比對的技術，智慧型環境中的人可以被快速且成功偵測
出來，最後，我們採用貝氏濾波技術(Bayesian Filtering)為基礎的多目標物追蹤技術，並且在
量測影像相似度上考慮接合影像相似度(Joint Image Likelihood)，作為解決目標在影像觀測上
重疊時的判斷，以達成所謂多目標物之追蹤。 
其次，對於空間中的人體姿態的視覺辨識，係提供使用者友善的「人機互動介面」與「行
為分析」兩課題裡的重要一環，即輔助電腦對使用者行為作適當的理解與描述另一方面，透
過 RJMCMC 的搜尋技術以及資料驅動的方式，有效率達到估算人體姿態，做為分析與理解
使用者於智慧型環境之行為模式。另一方面，為求姿態估算之精準度、效能以及減少遮蔽現
象之影響，我們更進一步整合多台相機，透過整合運動資訊以及多樣板的技術來達成姿態估
算，以提供系統做為提供服務的重要依據。首先，藉著比較從兩台相機中擷取之的剪影
(Silhouette)和資料庫的範例(Examples)來做靜態辨識，資料庫儲存多樣化的人物動作組態和
相對於相機的 2D 人物外型，比對範例並選取最相似的範例作為答案候選人。接著，透過推
算出運動資訊，然後這些運動資訊被用來推算哪一個結果比較好。 
再者，為了達到人性化之目的，本計畫亦將建立有效的多種感測資料收集系統、使用者
喜好模型、即時運算使用者目前狀況並事先提供服務、多人環境偵測、動態調整使用者喜好
模型，經由所提出了三階層的模型(Model)來達成推論出應該提供給整個群體的服務，而其中
第一層負責處理從感測器傳來的原始資料，第二層負責每個居住者個體的喜好模式，最高的
第三層負責處理多位使用者之間的關係。最後，除了建置智慧型環境、取得環境資訊之外，
我們針對上述問題探討智慧型環境中人機互動服務的機制，並提出一個整合數位服務的平台，
讓系統除了能夠觀察環境中的資訊，適應使用者的行為，還可以依據不同的需求及特性來組
織系統的資訊呈現系統的狀態，針對環境資源的變化動態調整自己的架構，進而將更佳的互
動服務提供給使用者，在此我們依據 OSGi 架構設計出一套以服務為導向(Service-Oriented)之
系統來達成上述的功能。 
 
關鍵詞：無間隙追蹤、多感測器、背景模型，運動資訊，RJMCMC，姿態辦識、服務客制化、
智慧型環境、智慧型空間。   
 
 
IV 
 
causes many problems. Mobile devices and dynamic services cause the dynamically changing 
environment, which can result in very difficult interaction. In addition, how to provide services 
efficiently and appropriately is always an important issue for a smart home. To solve the problems 
caused by traditional architectures, to deal with the dynamic environment, and to provide 
appropriate service, we propose a service-oriented architecture for smart home environments, based 
on OSGi and mobile agent technology. This architecture is a Peer-to-Peer model based on multiple 
OSGi platforms, in which service-oriented mechanisms are used for system components to interact 
with one another, and mobile agent technology is applied to augment the interaction mechanisms. 
 
Keywords: Tracking, Bayesian Filtering, RJMCMC, Posture Estimation, Intelligent 
Environment, Bayesian Network, OSGi. 
 
   
 
 
1 
 
第一章、計畫緣由 
「人性化電腦整合智慧型環境」是當前人類利用電腦整合目前先進光、電、通訊、資訊
等科技以提昇所處環境的智慧性之主要研究課題，不僅為現今研究主流，預期成果對人類生
活的影響亦相當的大，本計劃在研究如何建構一個具備多重感測能力及多重戶動方式之智慧
型環境，以作為數位服務提供平台。而隨著電腦影像技術之進步，我們期望透過電腦視覺達
到涵蓋智慧型環境空間之人形偵測與追蹤，以達到多目標無間隙追蹤與定位，並進一步空間
中之人形進行姿態的視覺辨識，提供使用者友善之人機互動介面及行為分析。 
再者，為達到人性化之目的，本計劃亦須建立有效的多種感測資料收集系統、使用者喜
好模型、即時運算使用者目前狀況並事先提供服務、多人環境偵測、動態調整使用者喜好模
型；最後，除了建置智慧型環境、取得環境資訊之外，我們針對上述問題探討智慧型環境中
人機互動服務的機制，並提出一個整合數位服務的平台。綜言之，本計畫主要針對以下四項
重點子題之相關背景及目的進一步詳細說明，此四個子題主要包含：(1)無間隙人形追蹤系統；
(2)人體姿態辨識；(3) 使用者喜好與多感測器之客制化服務；(4) 智慧型環境建制與整合。 
第一節、研究背景 
(一) 無間隙人形追蹤系統 
    無間隙追蹤系統可同時整合了多個相機的觀測範圍，形成一組在廣大區域的目標偵
測系統，系統擴大的偵測範圍取決於同時設置並啟用的相機個數，相機個數越多可以創造出
越大的偵測範圍。無間隙追蹤系統的好處在於，應用此種影像系統在人性化電腦整合智慧型
環境中，可使系統偵測到環境中人形目標物的確切位置、姿態甚至運動軌跡，另外當目標進
行大範圍的運動，即使由一個相機的視野切換至另一個相機的視野當中，該系統仍然可以透
過辨識目標物特徵的機制，判定相鄰兩相機視野中的目標為同一個目標物，一般而言，廣大
區域的目標追蹤會有多個目標物需同時追蹤，無可避免的，更由於目標物間彼此會有交互重
疊的情形，因此問題的複雜度比單一目標物的追蹤要來的困難，需要發展不同於單一目標追
蹤的演算法方能達此目的。影像系統與其他感測系統最大的差異在於，能夠完整偵測人形在
環境中之位置與行為姿態，在多目標無間隙人形追蹤系統中，我們預期利用多個影像設備，
以涵蓋所有智慧型環境空間，並進一步有效偵測與追蹤多個人形在環境中之位置與運動軌跡，
整個系統架構如圖一所示。 
 
圖一：多相機無間隙追蹤系統示意圖 
 
 
3 
 
 
圖五: 旋轉強度之統計長條圖 
   
圖六:Mohan et al. 人形偵測架構圖                  圖七:Edgelet 特徵點 
然而上述之技術，主要想法是將人於影像中所呈現外觀視為一完整物體(Object)，經由比
對的方式來達到人形偵測的目的。但這種方式的主要缺點在，其無法克服人形與影像中彼此
遮蔽(Occlusion)的問題，因此目前有許多研究提出基於透過辨識人體各個部份肢體(Body Part)
的方式，最後根據人體幾何結構性(Geometric Property)或其他特性，來達到人形辨識的目的。
Mohan A. et al. [12] 提出了一個階層式架構分類器，Adaptive Combination of Classifiers(ACC)，
首先在影像中偵測身體各部位，最後再用一個 SVM 結合各個部位以辨識出人形，圖六為其
人形偵測之架構圖。D. Ramanan et al. [13] 提出一個以人體各部位為基礎的姿態模型，再針
對各種人體姿態在影像中比對是否有符合此人體姿態的人形，再藉由偵測每一張影像中的模
型做到追蹤人形的功能。Wu 與 Nevatia [14]使用所謂的 Edgelet(如圖七所示)去表示人形部分
外觀，在偵測每個人體部分後，採用貝氏機率架構結合各分類器所偵測的結果。Leibe et al. [15] 
則採用一個 Implicit Shape Model (ISM)去描述人形不同肢體與人體中心點的關係，透過投票
的演算法來偵測人形。 
2. 以運動為主之人形偵測 
第二類為以運動為主之人形偵測，其主要運用原理是根據觀察人於影像中通常會造成影
像變化。此類技術最直接的方式是去學習人形運動所造成之影像圖形(Pattern)，Viola et al. [16] 
採用連續兩張影像之間上下左右位移影像差，作為人移動時之特徵，其計算方式如下方程式
所示，而學習的過程則採用 Adaboost。 
)( 1+−=∆ tt IIabs     )( 1 ↑−= +tt IIabsU  
)( 1 ←−= +tt IIabsL   )( 1 →−= +tt IIabsR  
)( 1 ↓−= +tt IIabsD  
 
 
5 
 
等都曾被使用於此範疇。 
2、擁有明確形狀模型的二維方法： 
為克服精準描述的上述問題，很多研究者傾向提供一明確人體模型來作為偵測的輔助工
具，這方面的研究主要在追蹤身體每個區段於影像中的位置。利用事先形狀模型的知識可以
提供我們人體運動上的限制資訊，減低搜尋空間與錯誤判斷率。在此人體模型通常藉由一些
簡單的幾何形狀來表現人體各個部位，也可能僅使用一些簡單的線段或曲線來表達，然遮蔽
的問題是其先天無法克服的缺陷。此類方法能於 [23] 中找到更詳細的說明。 
3、三維方法： 
三維的方法本質上類似於上個類別，需要使用者提供一明確三維模型來輔助辨識，程式
透過模型 3D 投影與所擷取的影像來擷取匹配的人體或手勢姿態。然在此方法中利用多台相
機追蹤人體，可以賦予事先我們對動作的知識。因此這類的演算法大部分包含幾項重要的步
驟：人體模型的建立、特徵點對應的尋找與三維人體姿態的攫取與持續追蹤。O'Rourke [26] 與
Badler 給予這項研究一個主要的方法，他們將辨識系統分為一些重要的元件，如圖十所示。 
 
圖十：三維演算法架構圖 
(三)  使用者喜好與多感測器之客制化服務 
『智慧型家庭系統』的研究領域包括系統架構設計、資訊家電、家庭看護等等，但是的
目前的這些研究都是屬於被動的提供服務而不是主動的提供服務，並且目前這些研究的領域
都過於專注於對於服務的提供，但卻沒有進一步的了解使用者為什麼想要這個服務。於是系
統中便少了人機之間的互動，也少『智慧型家庭系統』中最重要的部分，就是如何在適當的
時間提供適當的服務給使用者。最重要的就是要讓『智慧型家庭系統』充分了解使用者的使
用習性，並且在了解使用者的喜好習慣後可以進一步的事先提供服務給他。 
Mozer [27]基於類神經網路的技術，建構一個類神經網路家庭(Neural Netwok Home)用以
控制空調、燈光以及熱水。另一個由 Georgia Institute of Technology 所建構的 Aware Home [28]，
經由感測居住者的喜好來達到輔助居住者的目的。麻省理工學院(MIT)提出所謂 House_n 的
構想[29][30]，著重在於如何整合現有之技術，使系統能夠依據環境變化而具有動態(Dynamic)
以及逐步調整(Evloving)的能力。MavHome 於[31]所提出，主要整合多種不同的感測器，以提
供居住者適當的服務。雖然這個觀念是智慧型家庭系統的中心思想，目前其他國家也有相關
 
 
7 
 
第二節、研究目的 
顧名思義，「人性化電腦整合智慧型環境」，即是希望能塑造一個環境，使用者無論在環
境中的何處「彈指之間」及可取得所需要之服務，達到“服務無所不在”(Ubiquitous Service)之
境界，為達此，須首先解決四項子題之研究工作，分別為：『多目標無間隙人形追蹤系統』、『人
體姿態辨識』、『使用者喜好與多感測器之客制化服務』、『智慧型環境建制與整合』，以下即
針對各項子題之目的作一詳細之描述： 
(一) 無間隙人形追蹤系統 
多目標無間隙人形追蹤系統的主要在利用多個影像設備，以涵蓋所有人形之運動空間，
並進一步有效偵測與追蹤多個人形在智慧型環境的位置與運動軌跡。綜言之，在此計畫中，
人形追蹤系統主在到以下目標： 
 即時（Real-time）監控與追蹤：影像系統能夠快速的分析影像，使系統不至於出現
延遲與停頓的現象。 
 多人追蹤：在一般的應用環境中，通常不侷限於單一使用者，在這樣的考量下，此
系統需能夠在同一時間同時追蹤多個使用者。 
 多台相機追蹤：為追蹤使用者在系統所預先設定運動空間之位置，相機需能涵蓋所
有使用者之運動空間。 
 人形（Identity）身分的識別：在多相機的室內環境中，進行多人之偵測與監控，
系統需能夠標示出不同人形的身分，並保持此目標物身分的前後一致性
（Consistence）。當有新的人出現在運動空間中，系統需動態的識別並透過多相機對
其識別與追蹤。 
 能在辨識與追蹤受到部分遮蔽（Partial Occlusion）與不同姿態（Posture）的人形：
當人在運動的過程中，難免會與其他的人產生彼此互動的行為，此會導致影像中遮
蔽現象的產生。另一方面，人形在影像中所呈現的姿態並非固定不動的，系統需能
夠容忍這兩種人形變動的因素，以有效的偵測並追蹤人形的軌跡與位置。 
(二)  人體姿態辨識： 
人體姿態估算可以被應用來感測使用者的意圖(Intension)，然而由於人形外形與姿態
的變化非常複雜，因此如何有效的偵測出人形是一件不易的工作，因此如何克服下列所列之
主要挑戰(Challenges)為此計畫之主要目的。 
 衣服穿著(Clothing): 行人所穿著的顏色與樣式非常多變，因此透過建構顏色模型來
達到偵測行人的目的。 
 遮蔽(Occlusion): 由於人體有許多的自由度(Degree of Freedom)，因此會造成身體
有些部分無法成像於影像上。 
 複雜背景(Complex Background):在一般自然行車場景中，影像通常會有著複雜的背
景，提高行人偵測的複雜度。 
 動作複雜度(Articulated-Deformation):由於人體的四肢有諸多自由度，因此會產生
許多姿態。  
 
 
 
9 
 
環境必須讓使用者的溝通方式不必受限於電腦前，提供可以讓使用者在環境中移動
並同時溝通的方式，甚至以一般的自然模式與系統溝通。 
 監控環境資源： 
智慧型環境除了能夠控制環境中的資源與使用者進行溝通之外，還必須能夠知道系
統中這些提供服務的各項資源狀況，供智慧型環境對本身系統進行評估與分析，作
為系統調整資源分配的參考資料。 
 學習使用者資訊： 
除了與使用者進行互動之外，智慧型環境還會觀察使用者與環境資源的互動行為，
記錄使用者在系統中的狀態，評估使用者與系統的互動情形，作為改進服務的依據。 
 動態調整架構 
因應環境中的外在因素，系統中內部資源的改變，或是適應使用者的行為，智慧型
環境將動態調整本身的系統架構，提供最適合目前狀態的服務。 
   
 
 
11 
 
 
圖十一：IPPR 測試影像一 
 
圖十二：IPPR 測試影像二 
(二)人形辨識  
在這個計畫中，主要是利用人形樣版來偵測人形於影像中之存在，由於人形影像隨著其
姿的不同而會有不同的影像外觀，因此我們需要建構一個人形樣版資料庫作為人形比對之用。
而為使人形之比對更有效率，使人形辨識能夠達到即時的效果，我們將資料庫之人形樣版做
有系統的建構，所採用的方法為基因演算法（GA Algorithm），圖十三為所建構後之部分人形
樣板資料庫。 
 
圖十三：人形階層資料庫 
 
 
13 
 
外觀相同的目標物， tz 代表 t時刻的觀測影像，而 0:tz 則代表由初始時刻累積至 t時刻的觀測影
像歷史。 ( )|t tz Xtp 為結合相似度(Joint Likelihood)，當目標物在影像當中沒有互相重疊之時，
此式可以拆解成為 
( ) ( ) ( )1, M,| | |t t t t t t= ⋅⋅⋅z z x z xXtp p p , 
並且套用分隔式重要性取樣(Separated Importance Sampling)的方法，將對此外觀之目標
物所求得之重要性函數 ( )q x ，利用上一刻的追蹤結果，分隔此重要性函數為 
( ) ( )
1
( )
M
d m
m
q q q
=
= +∑x x x  
其中 ( ){ ,  1,..., }mq m M=x 為對第 m 個目標物的重要性函數，而 ( )dq x 為扣除 ( )mq x 之區域
所構成之目標物偵測重要性函數，如下圖所示。 
           
( )q x
( )dq x
( )tq x
( ) ( ){ }1 ,..., mq qx x ( ) ( ){ }1 ,..., mq qx x
( ) ( ){ }1 | ,..., |mp px z x z
( ) ( ){ }1 ,..., mq qx x
( )|dp x z
( )dq x
 
圖十四：分隔式重要性函數示意圖            圖十五：多目標物追蹤系統架構 
 
套用分隔式重要性取樣，我們可以得到下式 
( ) ( )( ), ( )( )0: , , ,
11
|
m
m
NM
i qi
t t m t m t m t
im
w Kα
==
≅ −∑∏ xz x xXtp  
然而，上述式子所代表的意義即為分別對個別目標物量測影像相似度，但此情形只限於目標
物無相互接觸、重疊或阻擋(Occlusion)的情況下，換言之，當目標物相互阻擋時，結合相似
度便無法如上式拆解，不同目標物相互重疊時相似度必須結合考慮，因此在這裡我們採用一
判斷機制，判斷目標物間的重要性函數是否重疊，藉此判斷是否需切換至結合影像相似度的
量測，因此系統的總體架構如圖十五所示。 
( )1q X ( )2q X
( )dq X
 
 
15 
 
在剪影為基礎的方法中，我們使用兩台相機當作輸入。原因是因為剪影只有一個物體 2D
外型的資訊而沒有了 3D 結構的資訊。為此我們利用不同角度的相機去觀察使用者，如此使
用者的姿態較容易被辨認出。例如圖十七，在圖十七(a)中我們很難利用剪影去判斷人左臂的
位子，但是如果我們有另一個在不同角度相機所觀察到的剪影如圖十七(b)，我們可以很容易
知道左臂是否有伸直。但是，當手臂靠近身體的時候，有可能兩台相機的視野皆被遮蔽到，
這是仍然很難判斷位置，我們將利用動作的資訊去解決這個問題。圖十八為我們方法的流程。
首先描述剪影的階段，我們從輸入的影像擷取出剪影，剪影的外型再經由 shape contexts 來
描述。然後，我們在利用輸入的剪影去跟範例做剪影比對。為了節省時間，我們在選取答案
候選人時使用串接方式。一開始我們比對第一台相機，刪去比對分數太高的範例。之後再比
對第二台相機，一樣刪去分數太高的範例。最後剩下的範例當作答案候選人供之後估算。 
 
(a) (b) 
圖十七：不同視角之兩台相機影像擷取圖 
 
圖十八：靜態辨識的流程圖 
(三) 以運動為基礎的辨識方法 
雖然剪影對於人類動作的辨認提供豐富和直覺的資訊，並已經被廣泛應用在人體姿態估
算技術上，然而其卻忽略了剪影內部的資訊(如圖十九所示)，在影像中左前臂在身體區域，
雖然在兩張影像中左前臂的位置是不一樣的，但是再剪影中卻看起來一樣。因為有許多候選
人有相似的剪影而他們似乎都是適合的答案，這個問題將會造成以剪影為基礎地辨識方法不
能夠找到真正的姿勢。基於上述考量，我們提出一個方法利用運動資訊的演算法來克服這個
問題，如圖十九所示，僅使用剪影，前臂的位置是無法被正確估算出來。然而，假設我們知
道從上一張影像到目前這張影像的動作，我們可以使用這些資訊來估計現在的動作，例如圖
二十，我們可以很容易區分出有相同剪影的兩個不同動作。假設姿勢在前一張影像是一樣的，
而之後兩個姿勢的動作不同，因為動作的資訊是從影像顏色強度改變所，而這部份被剪影捨
 
 
17 
 
 
圖二十一：以運動為基礎辨識方式的流程. 
(四) 姿態估算結果整合 
在獲得靜態辨識和以動作為基礎的辨識之後，下一個步驟極為如何從辨識結果中找最適
合現在姿勢的答案。最直覺的方法就是使用以動作為基礎辨識系統的具有最小動作距離的範
例。因為以動作為基礎的辨識只比較利用靜態辨視所選出的答案候選人，因此在動作為基礎
的辨識方式中最好的答案，應該在靜態辨識中也是好的答案。在某些情形下，若只使用以動
作為基礎的辨識方式，不能夠辨識出正確的姿勢，例如：當超過一個範例有相同且最小的動
作距離，因此我們想要使用靜態辨識的結果來幫助找到較好的答案，亦或輸入影像所觀測到
的動作資訊不足，導致無法辨識姿勢，而且太少的動作資訊很容易雜訊影響，導致上一張辨
識結果有一些錯誤發生，那麼將會影響姿態估算之正確性，因此結合靜態和以動作為基礎的
兩種辨識會是比較好的方式。一種簡單的整合方法，是假設兩類辨識結果是獨立的，在這種
假設下，我們可以兩類辨識所得到的距離加起來，數值最小的當作我們的結果。然而，並非
所有情形下，兩種辨識系統重要性皆相同。因此我們給予不同辨識方法和相機的結果不同權
重，使用權重和的方式整合結果。 
為計算目前影像中一種辨識方法在一台相機上的結果有多可靠，我們引入一個評量標準
稱為可靠度(Reliability)。可靠度值介於 0到 1之間，他表示使用這個辨識方法的辨識結果為
真實姿勢的機率。既然我們有兩種方法和兩台相機，對每一張影像可以得到四個辨識結果 1r 、
2r 、 3r 和 4r 。 給定在現在時間影像的辨識結果 kr ，我們想要估測可靠度 kR 。我們的想法是最
好的結果範例和輸入影像的距離可以表示辨識結果的可靠度。例如，假設在靜態辨識中，若
最好的辨識結果 Ar 的範例跟輸入剪影有很小的剪影距離 10，和另一個最好的辨識結果 Br 的範
例跟輸入剪影有很大的剪影距離 200，我們認為 Ar 較為可靠，因為它跟輸入的剪影很相似。
如果最好範例跟 Br 一樣距離很大，這種情形代表在資料庫中沒有跟輸入相似的範例，有可能
是不好的剪影擷取或者是某些身體部位有遮蔽的情形，因此我們用在結果中最小的距離來估
計靜態辨識的可靠度。我們想要估計的可靠度函數可以表示成 min( )static dΓ ， mind 為在 kr 中 ,k jd 最
小的值。估算以動態為基礎的辨識方式地結果可靠度，不能僅僅考慮最小的動作距離，還要
考慮從輸入影像中擷取出來的動作向量個數。這是因為動作資訊多寡可能會影響動態辨識結
 
 
19 
 
圖二十三： 我們方法的結果，這張圖顯示兩台相機的輸入和辨識的結果 
第三節、使用者喜好與多感測器之客制化服務 
「自動化個人喜好學習系統」的主要目的，是找出使用者的「個人喜好資料檔」，並建
立「個人喜好模型」，學習預測多居住者的喜好並且提供服務的建議給他們，使他們感到舒適
與放鬆，但是在家中，多位居住者和各種環境資訊間有很複雜的關係，環境資訊包含了人、
事、時、位置和物件等等。居住者的習慣也有時間上的特性，所以，要恰當的學習出居住者
的喜好必須將整個連續的互動加入考慮。 
為達成上述目標，我們提出了三階層的模型(Model)，第一層負責處理從感測器傳來的
原始資料，第二層負責每個居住者個體的喜好模式，最高的第三層負責處理多位使用者之間
的關係，而推論出應該提供給整個群體的服務。使用階層架構的好處主要在於：1)各層的學
習和推論可以分開處理，若環境的佈置改變了，我們只需重新訓練最下面那層，不用改變其
他層的喜好模型。例如，客廳的佈置改變了，居住者的看電視行為的活動路徑也跟著改變了，
但是多居住者之間的互動並沒有改變，所以只需重新訓練最下那層，其餘不用改變。2)階層
式的架構將多使用者的喜好模型切成多個部份，較下面的階層處理各子問題，而最上面的階
層統合下層所推論的結果。在本研究中，我們先將多位居住者的整體喜好問題切成各個居住
者獨立的喜好問題，然後在最高的階層使用一個貝氏網路﹙Bayesian Network﹚來統合每個
居住者喜好模型所獨立推論出來的結果，整個系統架構圖如下圖所示。 
 
圖二十四： 三階層推論系統模型 
 
 
21 
 
(三) 多使用者互動模型(Multiple User Interaction Model) 
 
圖二十六：  互動模型系統概觀圖 
上圖為多使用者互動模型(Multiple User Interaction Model)的概觀，在這層中，我們使用
貝氏網路(BNs)來整合所有居住者所喜好的服務而滿足所有人的需求，我們把這個問題想成是
學習並預測 K 個居住者的喜好，我們假設位在不同房間的居住者並不會互相影響並且我們都
可以得知每個居住者的身分，感測器所量測到的資料中，若無法區分是屬於哪個居住者的，
則屬於同房間的所有居住者，例如，聲音和溫度資料是屬於同房間的所有居住者的。我們認
為群體的服務和每個居住者個別的服務、環境資訊及時間資訊有關，所以使用貝氏網路(BNs)
把這些因素關聯起來，節點為那些影響因素，節點之間的相連是以本領域的一般知識來決定
的，本貝氏網路(BNs)所包含的有： 
z G：表示所要推論的群體服務。 
z 1 2, , , KID ID IDL 為 K個居住的的身分識別。 
z (1) (2) ( ), , , KC C CL 是第二層分別為 K個使用者所推論出的喜好。 
z  T：表示時間資訊。 
如圖二十七，環境中有兩位居住者，父親和母親，時間是早上，父親想要打開電視和電燈，
母親想要開音樂和電燈，根據以往資料所學習出的他們兩個的互動模式，系統推論出音樂打
開而電視關掉是比較適合整體的服務。 
 
圖二十七： 多人互動模型推論範例 
 
 
23 
 
(三) 資源的彈性配置及卸載 
在智慧型環境中，為了使用者的便利性及維持系統的運作，資源需要與系統架構保持彈
性。這些資源通常是那些會偶爾離開系統，又會在某個其他地方或某個時間重新連上系統的
裝置。而藉由「行動代理人程式」的能力，智慧型環境就可以彈性地對這些資源進行配置及
卸載，而不會產生不好的影響。舉例而言，智慧型系統中的某個「代理人程式平台」是一部
筆記型電腦，且其主要工作是為系統提供其運算資源。則這部筆記型電腦會使用 UPnP[14]向
系統資料庫註冊自己的資源，以讓系統中其他的「代理人程式平台」可以從資料庫發現其存
在並向其尋求運算資源上的協助。接著，考慮使用者將這部筆記型電腦從智慧型環境中帶離
的狀況，則執行在這部筆記型電腦上的「行動代理人程式」就會暫停工作，然後轉移到其他
的「代理人程式平台」繼續其工作。若是智慧型環境並非架構於「行動代理人程式」，則執行
在筆記型電腦上的未完成工作就會因筆記型電腦離開智慧型環境的架構而遺失其運算結果。 
考慮另一個例子，當智慧型環境中的可攜式電腦周邊或可攜式資訊家電在環境中的不同
空間中移動的時候。當某個空間缺乏與 Jini 裝置溝通的能力時，則當某個 Jini 裝置轉移到該
空間時，智慧型環境將無法控制轉移至該空間的 Jini 裝置，甚至無法發現該裝置存在於該空
間。然而，在我們的架構中，可以藉由從系統的程式資料庫中啟動具備 Jini 溝通能力的「裝
置管理代理人程式」，然後轉移至該空間對該 Jini 裝置進行管理，讓智慧型環境可以對該裝置
繼續進行相關管理控制。這樣做的優點是「代理人程式平台」可以在有需要時動態地下載「裝
置管理代理人」來應付空間中的新資源，又可以在不需要這份支援時將其移除，藉此減輕「代
理人程式平台」的儲存空間負擔，而這一點對於執行「代理人程式平台」的嵌入式系統是一
件很重要的事情，因為在資源相對缺乏的嵌入式系統中，記憶體的儲存空間是很重要的。 
(四)高容錯性 
除了提供資源的彈性配置，系統資料庫還在「容錯機制」中扮演了一個相當重要的角色。
在我們的智慧型環境架構中，只要各代理人程式運作正常，就會將自己的狀態以及系統的狀
態做非同步的更新。因此，一旦有某個代理人程式因為硬體錯誤而運作失效，則當相關硬體
修復後，代理人程式就可以根據自己先前儲存於系統資料庫的狀態進行回復。而若是運作失
效的代理人程式所執行的工作與硬體無關，如：計算相關的工作，則這個因為代理人程式失
效而中斷的工作並不需要等待硬體修復，其他的「代理人程式平台」就可以啟動另一個代理
人程式，並根據失效的代理人程式先前儲存於系統資料庫的運算結果而繼續這個運算工作。
此外，若是代理人程式的失效與「代理人程式平台」無關，則「代理人程式平台」就會重新
啟動一個代理人程式繼續其中斷的工作。至於代理人程式儲存於系統資料庫的內容，則沒有
一定的內容，而與代理人程式各自的需求有關。由於智慧型環境中所有的系統狀態，代理人
程式狀態，以及代理人程式的程式碼，都儲存在系統資料庫中，因此智慧型環境的確會因為
資料庫的失效而遭受到嚴重的破壞。然而，在代理人程式的架構下，智慧型環境的各部分功
能仍然能夠正常運作及反應，只是無法產生新的支援功能。而且這項缺點可以藉由資料庫方
面的技巧予以改進，像是在系統中進行多個資料庫的互相支援及備份。相對於須對整個系統
進行備份以達到容錯，以「行動式代理人程式」為基礎的架構對於智慧型系統是相當適合的。
  
 
 
25 
 
第四章、計畫成果自評 
於電腦影像應用方面，我們提出一套有效之演算法以達遮蔽狀況下之前景切割、人體追
蹤與適用於不同服式顏色之姿態估算，且有多篇論文發表於相關國際會議與期刊上[51, 52, 
53]。於系統平台與喜好推論方面，我們設計出一套彈性且方面之系統平台，且能夠正確分析
所獲得之資料與喜好推論，所獲得之成果，也發表於國際著名期刊上[54,55]。 
 
  
 
 
27 
 
[13] D. Ramanan, D. A. Forsyth, and A. Zisserman, “"Tracking People by Learning Their 
Appearance," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29, pp. 
65—81, 2007. 
[14] B. Wu and R. Revatia, “Detection and Tracking of Multiple, Partially Occluded Humans by 
Bayesian Combination of Edgelet Based Part Detector,” International Journal of Computer Vision, 
2007. 
[15] B. Leibe, E. Seemann, and B. Schiele, “Pedestrian Detection in Crowded Scenes,” IEEE 
Conference on Computer Vision and Pattern Recognition, vo.1, pp. 878—885, 2005. 
[16] P. Viola, M. J. Jones, and D. Snow, “Detecting Pedestrians Using Patterns of Motion and 
Appearance,” IEEE International Conference on Computer Vision, 2003. 
[17] J. J. Little and J. E. Boyd, “Recognizing People by Their Gait: The Shape of Motion,” Journal 
of Computer Vision Research, pp. 1—32, 1998. 
[18] B. Heisele and C. Wohler, “Motion-Based Recognition of Pedestrians,” IEEE International 
Conference on Pattern Recognition, pp. 1325—1330, 1998. 
[19] D. Cunado, M. S. Nixon, and J. N. Carter, “Automatic Extraction and Description of Human 
Gait Models for Recognition Purposes,” Computer Vision and Image Understanding, vol. 90, pp. 
1—41, 2003. 
[20] S. A. Niyogi and E. H. Adelson, “Analyzing and Recognizing Walking Figures inXYT,” IEEE 
Conference on Computer Vision and Pattern Recognition, pp. 469—474, 1994. 
[21] Y. Ran, Q. Zheng, I. Weiss, L. S. Davis, W. A. Almageed, and L. Zhao, “Pedestrian 
Classification From Moving Platforms Using Cyclic Motion Pattern, “ IEEE International 
Conference on Image Processing, vol. 2, pp. 854—857, 2005. 
[22] Y. Ran, I. Weiss, Q. ZHeng, and L. S. Davis, “Pedestrian Detection via Periodic Motion 
Analysis,” International Journal of Computer Vision, vol. 71, no. 2, pp.143—160, 2007. 
[23] D. M. Gavrila, “The Visual Analysis of Human Movement: A Survey,” Computer Vision and 
Image Understanding, vol. 73, no. 1, pp. 82—89, 1999. 
[24] J. K. Aggarwal and Q. Cai, “Human Motion Analysis: A Review,” Computer Vision and 
Image Understanding, vol. 73, no. 3, pp. 428—440, 1999. 
[25] T. B. Moeslunand and E. Granum, “A Survey of Computer Vision-Based Human Motion 
Capture, “ Computer Vision and Image Understanding, vol. 83, pp.231—268, 2001.  
[26] J. O’Rourke and N. Badler, Model-Based Image Analysis of Human Motion Using Constraint 
Propagation, IEEE Trans. Pattern Anal. Mach. Intell. 2(6), 1980, 522–536. 
 
 
29 
 
[40] Le Gal, C.; Martin, J.; Lux, A.; Crowley, J.L.; “SmartOffice: design of an intelligent 
environment”, Intelligent Systems, IEEE , Volume: 16 Issue: 4 , July-Aug. 2001. 
[41] Krumm, J.; Harris, S.; Meyers, B.; Brumitt, B.; Hale, M.; Shafer, S.; “Multi-camera 
multi-person tracking for EasyLiving”, Visual Surveillance, 2000. Proceedings. Third IEEE 
International Workshop on , 1 July 2000  
[42] Hedberg, S.R.; “After desktop computing: a progress report on smart environments research”, 
Intelligent Systems, IEEE [see also IEEE Expert] , Volume: 15 Issue: 5 , Sept.-Oct. 2000 
[43] Trivedi, M.; Huang Kohsia; Mikic, I.; “Intelligent environments and active camera networks”, 
Systems, Man, and Cybernetics, 2000 IEEE International Conference on , Volume: 2 , 8-11 Oct. 
2000. 
[44] Mikic, I.; Huang, K.; Trivedi, M.; “Activity monitoring and summarization for an intelligent 
meeting room”, Human Motion, 2000. Proceedings. Workshop on , 7-8 Dec. 2000 
[45] Kynan Eng; Bdbler, A.; Bernardet, U.; Blanchard, M.; Costa, M.; Delbrilck, T.; Douglas, R.J.; 
Hepp, K.; Klein, D.; Manzolli, J.; Mintz, M.; Roth, F.; Rutishauser, U.; Wasserman, K.; Whatley, 
A.M.; Wittmann, A.; Wyss, R.; Verschure, P.F.M., “Ada - intelligent space: an artificial creature for 
the swiss Expo.02”, Robotics and Automation, 2003. Proceedings. ICRA '03. IEEE International 
Conference on , Volume: 3 , Sept.14-19, 2003. 
[46] Mozer, M.C.; “An Intelligent Environment Must Be Adaptive”, Intelligent Systems, IEEE [see 
also IEEE Expert] , Volume: 14 Issue: 2 , March-April 1999. 
[47] Z. Chen, "Bayesian Filtering: From Kalman Filters to Particle Filters, and Beyond," 
http://soma.crl.mcmaster.ca//homepage.htm, 2003. 
[48] C. Rasmussen, "Joint Likelihood Methods for Mitigating Visual Tracking Disturbances," IEEE 
International Conference on Computer Vision and Pattern Recognition, 2001. 
[49] P. F. Fezenszwalb, “Pictorial Structures for Object Recognition”, International Journal of Computer 
Vision, 61(1):55—79, 2005. 
[50] A. Agarwal and B. Triggs, “3D Human Pose Estimation from Silhouettes by Relevance Vector 
Regression”, IEEE Computer Society Conference on CVPR, 2:882—888, 2004. 
[51] Shih-Shinh Huang, Li-Chen Fu, and Pei-Yung Hsiao, “Region-Level Motion-Based 
Background Modeling and Subtraction Using MRFs,” IEEE Trans. on Image Processing (SCI) Vol. 
16, No. 5, pp. 1446-1456, May 2007. 
[52] Shih-Shinh Huang, Li-Chen Fu, and Pei-Yung Hsiao, “A Bayesian Network for Foreground 
Segmentation in Region Level,” Asian Conference on Computer Vision, 2007. 
