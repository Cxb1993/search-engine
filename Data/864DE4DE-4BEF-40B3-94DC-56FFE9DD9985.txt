                                                                             2
For flame detection, gray-scale image 
processing schemes are used for black and 
white cameras to detect fire regions [1,2]. 
With the increasing use of color cameras, color 
features of video frames are used to identify 
fire pixels [3,4], and the motion variation of 
fire regions in the contiguous frames is also 
examined [5,6,7]. However, the 
aforementioned methods to locate fire regions 
and analyze their variations are complicated, 
and none of them can distinguish the burning 
intensity of the fire. Though Hong et al. [8] 
used the variation of flame contours to 
estimate the burning intensity of fire flames, 
two thresholds must be carefully selected. The 
decision functions of RGB color and gray 
value [6] and wavelet transform [9] are used 
for smoke detection. However, there are still a 
high rate of false smoke alarm and constraints 
on the background of camera scenes. 
To address the aforementioned problems, 
this paper presents a video-based early fire 
alarm detection method for vessels to detect 
dangerous flames and smoke. For flame 
detection, first, the dominant flame color 
lookup table (DFCLT) is created using the 
fuzzy c-means clustering algorithm. Then, the 
changed video frames are automatically 
selected, and the changed regions are deduced 
from these frames. Finally, we announce 
elementary, medium, or emergency flame 
alarms by comparing the pixels of changed 
regions with the DFCLT. For smoke detection, 
also, the changed video frames are selected, 
automatically, and the changed regions are 
deduced from these frames. If the shape of the 
changed region conforms to the characteristic 
where the top area is wider than the bottom 
area, a smoke alarm is announced. The 
experimental results indicate that the proposed 
fire detection approach can detect dangerous 
flames and smoke effectively and efficiently. 
2. Related Works 
Most of the video-based fire detection 
approaches apply the features of video, such as 
colors [3,4,6], shapes [10], textures [9,11], 
spatial relationships [3], and boundaries [7], 
and the characteristics of variation among 
contiguous frames, such as growth and 
disorder [6]. 
For flame detection, Cappellini et al. 
[12] designed an intelligent system for 
automatic fire detection in forests using 
cameras and sensors. Noda and Ueda [1] 
developed a histogram comparison method to 
detect fires in tunnels using black and white 
TV cameras. Foo [2] presented methods for 
detecting fire in aircraft dry bays and engine 
compartments from gray-scale images. Color 
cameras are increasingly being used. Color 
constitutes powerful visual information and 
can be used for video-based flame detection 
algorithms. Healey et al. [3] proposed a fire 
detection system using color video input for a 
pre-allocated view on some ideal conditions. 
However, because the process of camera 
initialization is difficult, the camera must be 
stationary. Once the distance of the portions of 
a scene from the camera has been changed, the 
rectangles must be manually re-created. 
Yamagishi and Yamaguchi [4] also presented 
a flame detection algorithm for color images 
based on the HSV color space and artificial 
neural networks. However, false fire alarms 
could occur while moving objects with the 
same color as fire. To reduce false fire alarms, 
in addition to the color feature, the 
characteristic of variation among contiguous 
frames is also considered. Phillips et al. [5] 
used color and motion information to locate 
fire. They created a Gaussian-smoothed color 
histogram and used the characteristic of 
temporal variation of pixels to find the actual 
fire pixels, then employed an erode operation 
and region growing method to improve the 
results of fire detection. Liu et al. [10] 
proposed algorithms for video based fire 
detection making use of spectral, spatial, and 
temporal properties of fire regions. They used 
Fourier coefficients representing the 
boundaries of fire regions, and autoregressive 
model parameters as features of each fire 
region for a classifier that recognizes fire 
regions. Chen et al. [6] applied the decision 
rule method of RGB color space to distinguish 
fire pixels, and used the characteristics of 
growth and disorder of fire pixels to raise a 
fire alarm. In [7], a color histogram is used to 
detect moving fire pixels, and a wavelet 
                                                                             4
 
(c1)       (r9)       (c2)       (r10)      (c3)      (r11)        (c4)      (r12) 
(c) 
 
(d1)       (r13)      (d2)       (r14)      (d3)       (r15)      (d4)      (r16) 
(d) 
 
(e1)      (r17)       (e2)      (r18)        (e3)      (r19)       (e4)      (r20) 
(e) 
Fig. 2. The firing images and regions of (a)paper (b)sawdust (c)pillows (d)gasoline (e)diesel fuel. 
 
3.3 Fuzzy Color Clustering Phase 
In this phase, the fuzzy c-means (FCM) 
algorithm is used to group pixels into clusters 
[9] according to RGB color features. The 
FCM_based clustering procedure iteratively 
minimizes the criterion function as shown in 
(A1). A detailed description of the clustering 
algorithm is given as follows: 
The FCM Clustering Procedure 
// The input values are RGB color features. 
// The output values are clusters with pixels. 
// c represents the number of clusters, w the 
exponential 
 weight, and 
//μik ‘s (i=1,…,c, k=1,…,n) the membership 
values 
1 Initialize parameters c and w; and then 
assign values to μik ‘s using either a random 
function or an approximation method. 
2 Do 
3   For each cluster c, update center using 
(A3) and  
4   μik ‘s using (A2); 
5 Until (all centers are stabilized) 
6 Assign pixels to one cluster according to 
μik’s. 
In the simulation, w is 1.5, and c is set 
from 5 to 12. To distinguish the elementary, 
medium, or emergency fire-alarm, and to 
concern the computational complexity, five 
clusters (i.e. dominant fire colors) are 
accommodated to the proposed method. Table 
1 demonstrates the DFCLT for vessels. 
Table 1. The DFCLT for vessels. 
 
 
4. The Dangerous Flame Detection 
 
Fig. 3 shows the process of the proposed 
dangerous flame detection approach. First, the 
changed video frames are automatically 
selected. Then, the changed regions are figured 
out from these frames. Finally, we announce 
elementary, medium, or emergency dangerous 
flames by comparing the pixels of changed 
regions with the DFCLT. Detail processes are 
described as follows: 
Frame
Selection Phase
Region
Selection Phase
Fire Color
Measure Phase
Video
Sequences DFCLTs
Dangerous
Fire Alarms
 
                                                                             6
5. Experimental Results And Analysis 
 
The experimental environment is depicted 
as follows: 
− Personal Computer : CPU-Pentium III 
3.0G, RAM=1GB, Hard Disk=200GB 
− Operating System : Window XP 
− Development Tool : Matlab 7.0 
− Image and Video Editing Tools : 
Photoshop 7 and Premiere Pro 1.5 
− Camera : Single Static Camera, SONY 
PC-350 
The experimental database consists of 16 
video sequences which the frame rate is 30 
frames per second, and the size is 720 by 480 
pixels. To verify the early flame detection of 
the proposed method, the content of test firing 
video sequences must record the complete 
process of burning. However, these fire video 
sequences are not easily acquired. Most of the 
test video sequences are captured by ourselves 
under safety control. Only the video of 
burning Christmas tree is referred to [10]. The 
distance between the camera and the flame is 
at least three meters. The key-frames of the 12 
video sequences for flame alarm detection are 
depicted as Fig. 6. Video sequences (a), (b), 
and (c) are made from the burning of gasoline, 
diesel fuel, and paper in a vessel, respectively. 
Video sequences (d), (e), and (f) are made 
from the burning of gasoline, diesel fuel, and 
paper in an indoor room, respectively. The 
content of video sequence (g) is the burning 
Christmas tree obtained form [10]. Video 
sequences (h), (i), (j), (k), and (l) are made 
from lighting up a candle and a lighter, turning 
on an electric radiator and a bulb, and a 
walking person with a red coat, respectively.  
 
 
(a)                  (b)                   (c)                  (d) 
 
(e)                  (f)                   (g)                  (h) 
 
(i)                   (j)                   (k)                  (l) 
Fig. 6. The key-frames of the 12 video sequences for flame alarm detection. 
 
For the proposed method, the elementary, 
medium, or emergency flame alarm is issued 
while the pixels of changed regions conform to 
3, 4, or 5 dominant flame colors of DFCLT. 
The dangerous flame detection results of the 
proposed method for the 12 video sequences 
as shown in Fig. 6 are depicted in Fig. 7. 
The comparison of the proposed method 
and the decision rule method [5] for flame 
detection is shown in Table 2. For the 
dangerous firing video sequences 1 to 7, the 
proposed method can all distinguish flame 
alarm to elementary, middle, or emergency 
level of fire except the video sequence 4. 
Because the burning process of gasoline in the 
video sequence 4 is violent, the middle fire 
                                                                             8
Table 2. The comparison of the proposed method and the decision rule method for dangerous 
flame detection. 
The proposed method Video 
sequenc
es 
Length 
of 
Video  
Elementa
ry flame 
alarm 
Middle 
flame 
alarm 
Emergen
cy flame 
alarm 
Decision 
rule 
method
[5] 
Video description 
1 500 275 284 290 X Burning of gasoline in a vessel 
2 1500 453 494 502 871 Burning of diesel fuel in a vessel 
3 400 202 331 339 X Burning of paper in a vessel 
4 500 X 261 262 X 
Burning of gasoline in an indoor 
room 
5 2000 710 769 772 241 
Burning of diesel fuel in an indoor 
room 
6 250 148 115 181 X 
Burning of paper in an indoor 
room 
7 550 170 172 207 311 Burning of a Christmas tree 
8 900 X X X 882 Turn on a warmer 
9 95 X X X X Light a candle 
10 65 X X X X Light a lighter 
11 110 X X X X Lighting a lamp 
12 250 X X X X People walking with a red coat 
“X” represents no dangerous flame alarm 
6. Conclusion 
 
In this paper, we proposed the FCM 
clustering algorithm to create the DFCLT for 
dangerous flame detection in a vessel, and 
three degree of flame alarms, elementary, 
middle, and emergency, are issued. The 
proposed method outperforms the decision 
rule method for the reducing of false flame 
alarms, and detecting of flame alarms, early 
and correctly. 
Here we would like to mention the 
following areas of investigation which may 
merit further study. 
1) Adjust the proposed method for panned 
cameras or multiple cameras to extend the 
detection area. 
2) Combine the characteristics of color, 
shape, texture, and spatial relationships to 
improve the performance. 
3) Apply the proposed method to other 
applications, such as to distinguish the ion 
of burning metal according to the burning 
flame color in Chemistry. 
 
計畫成果自評 
本文利用模糊聚類分群法，對艦艇上
可能燃燒物質的火焰像素分類，建立主要
火焰顏色量化表，做為選取區域像素顏色
比對之用。其比對結果符合 3、4、5 種主
要火焰顏色即分別判定具有初級、中度、
高度等三種等級火警。本文之方法比僅利
用單一火燄顏色的規則判斷法能更正確地
偵測出危險性火焰，降低火警誤判之機率。 
本研究成果與原計畫相符，達成預期目
標。計畫成果如[17][18][19]所列。 
 
Appendix. Fuzzy C-Means 
The purpose of FCM [21] is to minimize the 
object function J(U,V): 
Vx ik−∑∑= ==
2
1 1
),(
c
i
n
k
w
ik
VUJ μ               (A1) 
