In this project, we plan to use theoretical and 
empirical study to have an in-depth of the 
construction of Multiple Classifier System, and we 
will focus on the Multiple Classifier Systems built 
on heterogeneous classification algorithms. This 
project could make practical contributions to 
research and applications of Multiple Classifier 
System, and part of the results have been published 
on professional international conferences. 
英文關鍵詞： Multiple Classifier System, Multi-Classifier System, 
Ensemble, Diversity, Classifier Combination 
 
I 
 
目錄 
中文摘要 ................................................................................................................................... II 
Abstract .................................................................................................................................... III 
前言 ........................................................................................................................................... 1 
研究目的 ................................................................................................................................... 1 
文獻探討 ................................................................................................................................... 2 
研究方法 ................................................................................................................................... 3 
結果與討論 ............................................................................................................................... 4 
參考文獻 ................................................................................................................................. 14 
計畫成果自評 ......................................................................................................................... 18 
附錄：出席國際學術會議心得報告與已發表之論文全文 ................................................. 20 
 
 
  
III 
 
Abstract 
The purpose of this project is to develop theory and practice of the 
construction of Multiple Classifier System. Recently, in the data mining 
field, Multiple Classifier System has been an increasingly attractive 
research topic and been applied to various domains. However, we still lack 
a comprehensive understanding of its foundation. We may know which 
Multiple Classifier System is effective but we are not clear why it is 
effective, and we have limited knowledge of how to effectively construct 
an effective Multiple System. Although there are many success cases, there 
are even more cases where Multiple Classifier System is not considered 
success. Therefore, being able to explain why a Multiple Classifier System 
is unsuccessful is equally important to being able to explain why a 
Multiple Classifier System is successful. Furthermore, most systems are 
ad-hoc designs, i.e. they are designed specifically to some problems or 
data sets, while such designs severely restrict their possible extensions 
and applications. For that reason, a critical research topic is how to 
design a general-purpose Multiple Classifier System. In this project, we 
plan to use theoretical and empirical study to have an in-depth of the 
construction of Multiple Classifier System, and we will focus on the 
Multiple Classifier Systems built on heterogeneous classification 
algorithms. This project could make practical contributions to research 
and applications of Multiple Classifier System, and part of the results 
have been published on professional international conferences. 
 
Keywords: Multiple Classifier System, Multi-Classifier System, Ensemble, 
Diversity, Classifier Combination 
 
 
2 
 
和運作有更廣、更深的理解，而這正是本計畫的目的。 
在許多利用資料探勘解決實務問題的競賽中，大部分的得獎作品使用多分類
器系統，甚至在某些競賽中，名列前茅的作品都是使用多分類器系統，而且這個
趨勢在近年來越發明顯。我們可以從這趨勢看到多分類器系統熱門程度以及研究
潛力已經超越單一分類演算法。然而，在這些資料探勘競賽當中，大多數的多分類
器系統採取特別設計，也就是說這些系統是針對特定分類問題或資料集所做的設計。
此種特別設計的並不具有可攜性，針對某分類問題或資料集所設計多分類器系統並
不適合用來解決其他分類問題或是分析其他資料集，所以實務上我們常常需要針對
不同的問題去設計不同的多分類器，而且因為目前並沒有一套指引，所以我們常常
花費大量時間在設計與嘗試錯誤的迴圈裡面。部分的多分類器系統是由泛用型的演
算法建制而來，具有可攜性而非針對特定分類問題或資料集。但是就像目前沒有所
謂最好的或最適用的單一分類演算法，目前也沒有最好的或最適用的多分類器系統
演算法。諸多成功實例顯示了多分類器系統的潛力，但上述關於設計多分類器系統
的現況點出了關於多分類器系統的研究空間。 
總結來說，在目前學術研究以及實務應用上，我們目前對多分類器系統是『知
其然而不知其所以然』，本計畫的最終目的就是要『知其所以然』。從另一方面來
說，雖然為數眾多的多分類器系統展示了諸多成功案例，但是另有更多的多分類
器系統並沒有特別優異的表現。本計畫的一部分研究不僅是要能解釋為什麼某些
多分類器系統有好的表現，還要能解釋為什麼另外某些多分類器系統沒有好的表
現。 
文獻探討 
與本計畫有關之理論分析的研究情況與重要參考文獻可分為兩大類，第一大類
著重於如何產生一組有效的成員分類器 (成員函數) ，第二大類著重於如何整合成
員分類器 (成員函數) 的分類結果。 
第一大類研究的標的是具有差異性的成員分類器，例如 Melville利用人工添加
的訓練資料樣本來增加差異性[9]，而 Tsymbal針對用隨機子空間法所建立的多分類
器系統裡面成員分類器之間的差異性做探討[10]。差異性度量的提出有兩個目的，
一是協助成員分類器的選擇 (例如，用這些度量去篩選掉相似的成員分類器) ，另
一是評量分類器整合方法或是策略 (例如，用這些度量去檢視分成員分類器整合前
後的差異性變化) [11, 12]。Tang提出差異性度量的分析[13]，而 Chung研究多個
差異性度量之間的關係[14]。Tsang針對大的資料集研究如何將差異性引入以支持向
量機為基礎的多分類器系統[15, 16]。Shi利用特徵或屬性選取以及差異性度量來
建置多分類器系統[17]。Torres-Sospedra將訓練資料樣本或記錄做重新排序來增加
差異性[18]。Brown探討用多數投票法所建立的多分類器系統裡面好的與不好的差異
性[19]。Wang針對多分類器系統的建置去探討類神經網路和決策樹之間的差異性
4 
 
四、 延伸多分類器系統的概念，提出一個可以產生一組人們能輕易看得懂的分類規
則的分類器的建置演算法，並探討一個用於串流資料分析的概念飄移偵測模
組。 
結果與討論 
圖 1呈現多分類器系統的訓練與使用 (或測試) 。目前學者已體認到成員分類
器 (成員函數) 之間的差異性對多分類器系統 (或分類器集成) 整體效能的影響，
因此本計畫以多分類器系統中的成員分類器之間的差異性為基礎去探討多分類器系
統的建置，更進而藉此發展一套指引。首先，我們要先瞭解成員分類器之間差異性
的來源。 
一個分類演算法可以視為一個藍圖，因為它並不是一個函數，而是一個描述如
何利用一組計算和邏輯規則來尋找或建立函數的方法流程。分類器是一個分類演算
法的實體，它代表一個可以直接拿來使用的函數，它是一個分類演算法具體化之後
的結果。如果用物件導向設計的概念來說，分類演算法是『類別』而分類器則是『物
件』。所以，一個分類器的基本構成要素是它所依據的分類演算法。 
對多分類器系統來說，成員分類器也可稱為基底分類器 (因為它們是構成多分
類器系統的基本構成要素) ，而成員分類器所依據的分類演算法稱為基底演算法。
另一個分類器的基本構成要素是資料，更精確地說是資料集：對很大一部分的分類
演算法而言，在訓練階段 (尋找適當的函數的階段) 資料集會被分析並藉以用來建
立分類器；對另一部份的分類演算法而言，更具體地說是對記憶型的分類演算法 (譬
如最近鄰居演算法) 而言，在訓練階段資料集會被直接儲存而後在分類資料樣本或
記錄時資料集會被參考、利用。資料集裡面的每一個資料樣本或記錄會是存在於特
徵空間裡面的一個點。 
 
6 
 
代表一個資料樣本或記錄，而一個行代表一個屬性或特徵，那麼第二個方面就是
指差異性的有無可以取決於是否對資料矩陣的列做取樣，而第三個方面就是指差
異性的有無可以取決於是否對資料矩陣的行做取樣。 
 
 
 
我們用 A 代表分類演算法，用 S 代表資料樣本或記錄 (亦即，資料矩陣的
列) ，用 F 代表資料樣本或記錄的特徵空間 (亦即，資料矩陣的行) 。從這三方
面來考慮，我們歸納整理出七大類將差異性引入成員分類器的方法，或是建立不
同的成員分類器的方法。這是一種新的分類方式。我們藉由 A、S、F 的改變來
將多分類器系統歸納整理為七大類。 
一、 改變 A，其餘不變。使用不同的基底演算法去建立不同的成員分類器，但是不對
資料矩陣做任何的取樣。對每個成員分類器而言，作為訓練或是參考用的資料
樣本或記錄是一樣的，而且作為訓練或是參考用的資料樣本或記錄所在的特徵
空間也是一樣的。部分特別設計的演算法可歸為此類。 
二、 改變 S，其餘不變。對每個成員分類器而言，作為訓練或是參考用的資料樣本或
記錄是不一樣的，但是基底演算法是一樣的，而且作為訓練或是參考用的資料
樣本或記錄所在的特徵空間是一樣的。Boosting[48]、Bagging (bootstrap 
aggregating) [49]，以及 DECORATE (Diverse Ensemble Creation by 
Oppositional Relabeling of Artificial Training Examples) [9, 36]，可
歸為此類。DECORATE利用人造資料，或稱為人工添加資料，去產生不同的訓練
資料集，並藉此將差異性引進多分類器系統當中[9, 36]。 
三、 改變 F，其餘不變。對每個成員分類器而言，作為訓練或是參考用的資料樣本或
RSM
使用相同(0)或
不同(1)的訓練
資料樣本(記錄)
使用相同(0)或不同(1)
的分類演算法
使用相同(0)或不
同(1)的特徵(屬性)
Bagging、 
Boosting、
DECORATE
Random Forest
Stacking，還有本計畫產
出之會議論文 “Hybrid 
Ensembles of Decision 
Trees and Artificial 
Neural Networks”
0 1
1
1
圖 2：三個跟分類器差異性的產生或引入有關的面向。 
8 
 
 
 
關於多分類器系統的第二個研究主題，亦即，如何整合成員分類器的分類結果，
常見方法如下： 
一、 代數法。只要分類器能夠輸出連續數值，譬如是會針對某一資料樣本給出其屬
於某類別的機率，或是會給出該分類的信心程度，則分類器的組合可以透過這
些數值的代數運算來達成。 
二、 投票法或表決法。採用普通 (不加權) 多數表決法的多類器系統演算法包括
Bagging和隨機森林，而採用加權多數表決法的多分類器系統演算法包括
Boosting。本計畫產出之會議論文“Hybrid Ensembles of Decision Trees and 
Artificial Neural Networks”[52]採用普通 (不加權) 多數表決法。 
三、 選擇法或篩選法。各成員函數會相互比較，最好的那一個，會被拿來對新資料
進行分類或預測。本計畫產出之會議論文“A Rule-Based Classification 
Algorithm: A Rough Set Approach”[55]，與基於該論文的碩士論文[56]，
採用選擇法：這兩篇論文所提出的方法會產生數條分類規則，而一條分類規則
訓練資料
集 1
訓練資料
集 j
訓練資料
集 T
... ...
成員分類
器 1&1
分類演算
法 1
成員分類
器 i&j
成員分類
器 m&T
... ...
資料集
整合
... ...
分類演算
法 i
分類演算
法 m
...
...
訓練資料
集 2
訓練資料
集 T-1
成員分類
器 1&T-1
成員分類
器 m&2
 
圖 3：本計畫產出之會議論文“Hybrid Ensembles of Decision Trees and 
Artificial Neural Networks”[52]所採用的多分類器系統架構。 
10 
 
4  設定 prunning 的信
心門檻值為 0.2 
 每個樹葉的最小樣
本數量為 5 
 使用 supervised 
discretization 去處
理數值特徵 
 設定最近鄰居數為
5 
 以 1-鄰居距離作為
加重權值 
5  使用 prunning 
 僅使用二元分裂 
 每個樹葉的最小樣
本數量為 5 
 使用 supervised 
discretization 去處
理數值特徵 
 設定 k 為 5 
 在訓練集上使用
hold-one-out 評估法
去選擇1到k的數當
作最近鄰居數 
 當考慮數值預測時
使用最小 mean 
squared error 而不是 
mean absolute error 
 
表 2：在人造資料集上，針對不同分類演算法及參數設定，同質演算法建立
的分類器之間的差異性顯示於淺色列，異質演算法建立的分類器之間的差異
性顯示於深色列；箭號表示差異性評量指標的值是高或低代表較佳的差異
性。 
資料集 實驗 演算法 Q↓ ρ↓ DIS↑ DF↓ E↑ KW↑ κ↓ θ↓ GD↑ CFD↑ 
A 
Set 1 
J48+J48 1.00  1.00  0.00  0.05  0.00  0.00  1.00  0.19  0.00  0.00  
J48+NB 0.72  0.21  0.15  0.02  0.15  0.04  0.69  0.12  0.76  0.87  
Set 2 
J48+J48 1.00  1.00  0.00  0.05  0.00  0.00  1.00  0.19  0.00  0.00  
J48+IBk 0.77  0.17  0.06  0.01  0.06  0.02  0.87  0.18  0.80  0.89  
Set 3 
NB+NB 1.00  1.00  0.00  0.15  0.00  0.00  1.00  0.14  0.00  0.00  
NB+J48 0.72  0.21  0.15  0.02  0.15  0.04  0.69  0.12  0.76  0.87  
Set 4 
NB+NB 1.00  1.00  0.00  0.15  0.00  0.00  1.00  0.14  0.00  0.00  
NB+IBk 0.70  0.16  0.15  0.02  0.15  0.04  0.69  0.13  0.84  0.91  
Set 5 
IBk+IBk 1.00  1.00  0.00  0.03  0.00  0.00  1.00  0.20  0.00  0.00  
IBk+J48 0.77  0.17  0.06  0.01  0.06  0.02  0.87  0.18  0.80  0.89  
Set 6 
IBk+IBk 1.00  1.00  0.00  0.03  0.00  0.00  1.00  0.20  0.00  0.00  
IBk+NB 0.70  0.16  0.15  0.02  0.15  0.04  0.69  0.13  0.84  0.91  
B 
Set 1 
J48+J48 1.00  1.00  0.00  0.32  0.00  0.00  1.00  0.08  0.00  0.00  
J48+NB 0.14  0.06  0.47  0.17  0.47  0.12  0.06  0.02  0.58  0.73  
Set 2 
J48+J48 1.00  1.00  0.00  0.32  0.00  0.00  1.00  0.08  0.00  0.00  
J48+IBk 0.76  0.37  0.25  0.12  0.25  0.06  0.50  0.05  0.51  0.67  
Set 3 
NB+NB 1.00  1.00  0.00  0.49  0.00  0.00  1.00  0.06  0.00  0.00  
NB+J48 0.14  0.06  0.47  0.17  0.47  0.12  0.06  0.02  0.58  0.73  
Set 4 
NB+NB 1.00  1.00  0.00  0.49  0.00  0.00  1.00  0.06  0.00  0.00  
NB+IBk 0.12  0.05  0.48  0.09  0.48  0.12  0.04  0.03  0.72  0.84  
Set 5 
IBk+IBk 1.00  1.00  0.00  0.17  0.00  0.00  1.00  0.13  0.00  0.00  
IBk+J48 0.76  0.37  0.25  0.12  0.25  0.06  0.50  0.05  0.51  0.67  
Set 6 
IBk+IBk 1.00  1.00  0.00  0.17  0.00  0.00  1.00  0.13  0.00  0.00  
IBk+NB 0.12  0.05  0.48  0.09  0.48  0.12  0.04  0.03  0.72  0.84  
C 
Set 1 
J48+J48 1.00  1.00  0.00  0.14  0.00  0.00  1.00  0.14  0.00  0.00  
J48+NB 0.35  0.13  0.32  0.06  0.32  0.08  0.36  0.05  0.71  0.83  
Set 2 
J48+J48 1.00  1.00  0.00  0.14  0.00  0.00  1.00  0.14  0.00  0.00  
J48+IBk 0.86  0.32  0.13  0.03  0.13  0.03  0.74  0.13  0.68  0.81  
Set 3 
NB+NB 1.00  1.00  0.00  0.31  0.00  0.00  1.00  0.08  0.00  0.00  
NB+J48 0.35  0.13  0.32  0.06  0.32  0.08  0.36  0.05  0.71  0.83  
Set 4 
NB+NB 1.00  1.00  0.00  0.31  0.00  0.00  1.00  0.08  0.00  0.00  
NB+IBk 0.22  0.05  0.31  0.02  0.31  0.08  0.37  0.07  0.89  0.94  
Set 5 
IBk+IBk 1.00  1.00  0.00  0.05  0.00  0.00  1.00  0.19  0.00  0.00  
IBk+J48 0.86  0.32  0.13  0.03  0.13  0.03  0.74  0.13  0.68  0.81  
Set 6 IBk+IBk 1.00  1.00  0.00  0.05  0.00  0.00  1.00  0.19  0.00  0.00  
12 
 
IBk+NB 0.74  0.29  0.18  0.05  0.18  0.05  0.64  0.10  0.64  0.78  
diabetes 
Set 1 
J48+J48 1.00  1.00  0.00  0.22  0.00  0.00  1.00  0.11  0.00  0.00  
J48+NB 0.85  0.51  0.18  0.15  0.18  0.04  0.65  0.06  0.38  0.55  
Set 2 
J48+J48 1.00  1.00  0.00  0.22  0.00  0.00  1.00  0.11  0.00  0.00  
J48+IBk 0.68  0.30  0.22  0.08  0.22  0.05  0.57  0.07  0.59  0.74  
Set 3 
NB+NB 1.00  1.00  0.00  0.24  0.00  0.00  1.00  0.10  0.00  0.00  
NB+J48 0.85  0.51  0.18  0.15  0.18  0.04  0.65  0.06  0.38  0.55  
Set 4 
NB+NB 1.00  1.00  0.00  0.24  0.00  0.00  1.00  0.10  0.00  0.00  
NB+IBk 0.73  0.34  0.22  0.09  0.22  0.05  0.57  0.07  0.56  0.72  
Set 5 
IBk+IBk 1.00  1.00  0.00  0.14  0.00  0.00  1.00  0.14  0.00  0.00  
IBk+J48 0.68  0.30  0.22  0.08  0.22  0.05  0.57  0.07  0.59  0.74  
Set 6 
IBk+IBk 1.00  1.00  0.00  0.14  0.00  0.00  1.00  0.14  0.00  0.00  
IBk+NB 0.73  0.34  0.22  0.09  0.22  0.05  0.57  0.07  0.56  0.72  
kr-vs-kp 
Set 1 
J48+J48 1.00  1.00  0.00  0.01  0.00  0.00  1.00  0.22  0.00  0.00  
J48+NB 0.81  0.12  0.13  0.00  0.13  0.03  0.74  0.15  0.94  0.97  
Set 2 
J48+J48 1.00  1.00  0.00  0.01  0.00  0.00  1.00  0.22  0.00  0.00  
J48+IBk 0.91  0.18  0.04  0.00  0.04  0.01  0.93  0.20  0.85  0.92  
Set 3 
NB+NB 1.00  1.00  0.00  0.13  0.00  0.00  1.00  0.15  0.00  0.00  
NB+J48 0.81  0.12  0.13  0.00  0.13  0.03  0.74  0.15  0.94  0.97  
Set 4 
NB+NB 1.00  1.00  0.00  0.13  0.00  0.00  1.00  0.15  0.00  0.00  
NB+IBk 0.71  0.18  0.13  0.02  0.13  0.03  0.73  0.14  0.82  0.90  
Set 5 
IBk+IBk 1.00  1.00  0.00  0.03  0.00  0.00  1.00  0.20  0.00  0.00  
IBk+J48 0.91  0.18  0.04  0.00  0.04  0.01  0.93  0.20  0.85  0.92  
Set 6 
IBk+IBk 1.00  1.00  0.00  0.03  0.00  0.00  1.00  0.20  0.00  0.00  
IBk+NB 0.71  0.18  0.13  0.02  0.13  0.03  0.73  0.14  0.82  0.90  
sick 
Set 1 
J48+J48 1.00  1.00  0.00  0.01  0.00  0.00  1.00  0.22  0.00  0.00  
J48+NB 0.89  0.17  0.07  0.00  0.07  0.02  0.87  0.18  0.89  0.94  
Set 2 
J48+J48 1.00  1.00  0.00  0.01  0.00  0.00  1.00  0.22  0.00  0.00  
J48+IBk 0.94  0.23  0.02  0.00  0.02  0.01  0.95  0.20  0.79  0.88  
Set 3 
NB+NB 1.00  1.00  0.00  0.07  0.00  0.00  1.00  0.18  0.00  0.00  
NB+J48 0.89  0.17  0.07  0.00  0.07  0.02  0.87  0.18  0.89  0.94  
Set 4 
NB+NB 1.00  1.00  0.00  0.07  0.00  0.00  1.00  0.18  0.00  0.00  
NB+IBk 0.82  0.20  0.07  0.01  0.07  0.02  0.86  0.17  0.80  0.89  
Set 5 
IBk+IBk 1.00  1.00  0.00  0.02  0.00  0.00  1.00  0.21  0.00  0.00  
IBk+J48 0.94  0.23  0.02  0.00  0.02  0.01  0.95  0.20  0.79  0.88  
Set 6 
IBk+IBk 1.00  1.00  0.00  0.02  0.00  0.00  1.00  0.21  0.00  0.00  
IBk+NB 0.82  0.20  0.07  0.01  0.07  0.02  0.86  0.17  0.80  0.89  
 
從顯示於表 2和表 3的實驗結果來看，使用異質演算法的確能增加成員分類器
之間的差異性。接下來，我們比較異質多分類器系統建置演算法 (Bagging DT+NB) 
和數個常用的多分類器系統建置演算法在實際資料集上的分類錯誤率，如表 4所
示。 
 
表 4：實際資料集的特性，以及異質多分類器系統建置演算法 (Bagging DT+NB) 
和數個常用的多分類器系統建置演算法在這些資料集上的分類錯誤率；粗體數字
表示在一個實際資料集上的最低分類錯誤率。 
資料集 
樣本數 特徵數 Bagging AdaBoost Random 
Forests 
DECORATE StackingC 
  DT+NB DT NB DT NB DT NB DT+NB 
Anneal_U 898 38 0.0212 0.0089 0.0913 0.0067 0.0223 0.0045 0.0089 0.0835 0.0089 
Biomed 209 8 0.0813 0.0861 0.0957 0.0861 0.1148 0.0909 0.1100 0.1053 0.0957 
14 
 
結論與建議：主持人認為，唯有對多分類器系統的組成和運作有通盤的理解，
在實務上我們才能更有效地設計和應用多分類器系統，故建議國科會能繼續補助
關於多分類器系統的研究。 
參考文獻 
 
1. Opitz, D. and Maclin, R. 1999. Popular ensemble methods: An empirical 
study. Journal of Artificial Intelligence Research, 11:169–198. 
2. Dietterich, T. 2000. Ensemble methods in machine learning. In Proc. 
of the 1st International Workshop on Multiple Classifier Systems 
(MCS) ,1-15. 
3. Polikar, R. 2006. Ensemble based systems in decision making. IEEE 
Circuits and Systems Magazine, 6 (3) :21-45. 
4. Ranawana, R. and Palade, V. 2006. Multi-classifier systems: Review 
and a roadmap for developers. International Journal of Hybrid 
Intelligent Systems, 3 (1) :35-61. 
5. Brown, G. 2010. Ensemble learning, Encyclopedia of Machine Learning. 
Springer. 
6. Rokach, L. 2010. Ensemble-based classifiers. Artificial Intelligence 
Review, 33 (1-2) :1–39. 
7. Kuncheva, L. 2004. Combining Pattern Classifiers: Methods and Algorithms. 
John Wiley and Sons. 
8. Melville, P., Shah, N., Mihalkova, L., and Mooney, R. 2004. Experiments 
on ensembles with missing and noisy data. In Proc. of the 5th 
International Workshop on Multiple Classifier Systems (MCS) , 293-302. 
9. Melville, P. and Mooney, R. 2003. Constructing diverse classifier 
ensembles using artificial training examples. In Proc. of the 
International Joint Conference on Artificial Intelligence (IJCAI) , 
505-510. 
10. Tsymbal, A., Pechenizkiy, M., and Cunningham, P. 2004. Diversity in 
random subspacing ensembles. In Proc. of the International Conference 
Data Warehousing and Knowledge Discovery (DaWaK) , 309-319. 
11. Kuncheva, L. and Whitaker, C. 2001. Ten measures of diversity in 
classifier ensembles: limits for two classifiers. In Proc. of the 
Workshop on Intelligent Sensor Processing, 1-10. 
12. Kuncheva, L. 2003. That elusive diversity in classifier ensembles. 
16 
 
24. Diplaris, S., Tsoumakas, G., Mitkas, P., and Vlahavas,I. 2005. 
Protein classification with multiple algorithms. In Proc. of the 10th 
Panhellenic Conference on Informatics (PCI) , 448-456. 
25. Bian, S. and Wang, W. 2007. On diversity and accuracy of homogeneous 
and heterogeneous ensembles. International Journal of Hybrid 
Intelligent Systems, 4 (2) :103-128. 
26. Jacobs, R., Jordan, M., Nowlan, S., and Hinton, G. 1991. Adaptive 
mixtures of local experts. Neural Computation, 3:79-87. 
27. Nowlan, S. and Hinton, G. 1991. Evaluation of adaptive mixtures of 
competing experts. In Proc. of the 1990 Conference on Advances in 
Neural Information Processing Systems 3 (NIPS-3) , 774–780. 
28. Jordan, M. and Xu, L. 1995. Convergence results for the EM approach 
to mixtures of experts architectures. Neural Networks, 8:1409–1431. 
29. Kuncheva, L., Whitaker, C., Shipp, C., and Duin, R. 2003. Limits on 
the majority vote accuracy in classifier fusion. Pattern Analysis and 
Applications, 6 (1) :22-31. 
30. Ruta, D. and Gabrys, B. 2005. Classifier selection for majority voting. 
Information Fusion, 6 (1) :63-81. 
31. He, H., Cao, Y., Wen, J., and Cheng, S. 2008. A boost voting strategy 
for knowledge integration and decision making. In Proc. of the 5th 
International Symposium on Neural Networks: Advances in Neural 
Networks (ISNN) , 472-481. 
32. Orrite, C., Rodriguez, M., Martinez, F., and Fairhurst, M. 2008. 
Classifier ensemble generation for the majority vote rule. In Proc. 
of the 13
th
 Iberoamerican congress on Pattern Recognition: Progress 
in Pattern Recognition, Image Analysis and Applications (CIARP) , 
340-347. 
33. Abreu, M. and Canuto, A. 2007. An experimental study on the importance 
of the choice of the ensemble members in fuzzy combination methods. 
In Proc. of the 7th International Conference on Intelligent Systems 
Design and Applications (ISDA) , 723-728. 
34. Zanda, M., Brown, G., Fumera, G., and Roli, F. 2007. Ensemble learning 
in linearly combined classifiers via negative correlation. In Proc. 
of the 7th International Workshop on Multiple Classifier Systems (MCS) , 
440-449. 
35. Brown, G., Yao, X., Wyatt, J., Wersing, H., Sendhoff, B. 2002. 
Exploiting ensemble diversity for automatic feature extraction. In 
Proc. of the 9th International Conference on Neural Information 
18 
 
48. Schapire, R. 1990. The strength of weak learnability. Machine 
Learning, 5:197-227. 
49. Breiman, L. 1996. Bagging predictors. Machine learning, 24 
(2) :123-140. 
50. Wolpert, D. 1992. Stacked generalization. Neural Networks, 5 
(2) :241-259. 
51. Seewald, A. 2002. How to make stacking better and faster while also 
taking care of an unknown weakness. In Proc. of the 19th International 
Conference on Machine Learning (ICML) , 554-561. 
52. Hsu, Kuo-Wei. 2012. Hybrid Ensembles of Decision Trees and Artificial 
Neural Networks. In IEEE International Conference on Computational 
Intelligence and Cybernetics (CYBERNETICSCOM) . 
53. Lu, Z., Wu, X., and Bongard, J. 2009. Active learning with adaptive 
heterogeneous ensembles. In Proc. of the 19th International Conference 
on Data Mining (ICDM) , 327-336. 
54. Breiman, L. 2001. Random forests. Machine learning, 45 (1) :5-32. 
55. Liao, Chia-Chi Liao, and Hsu, Kuo-Wei. A Rule-Based Classification 
Algorithm: A Rough Set Approach. In IEEE International Conference on 
Computational Intelligence and Cybernetics (CYBERNETICSCOM) . 
56. 廖家奇. 2012. 以規則為基礎的分類演算法：應用粗糙集. 碩士論文,國立
政治大學, 資訊科學學系. (學生畢業論文)  
57. Lin, Hong-Che and Hsu, Kuo-Wei. 2012. An Empirical Study of Applying 
Data Mining Techniques to the Prediction of TAIEX Futures, in Proc. 
of IEEE International Conference on Granular Computing (GrC) -- 
International Symposium on Foundations and Frontiers of Data Mining 
(FFDM) , 334-339. 
58. Ting, K. and Witten, I. 1999. Issues in stacked generalization. 
Journal of Artificial Intelligence Research, 10:271–289. 
59. Kuncheva, L. and Whitaker, J. 2003. Measures of Diversity in 
Classifier Ensembles and Their Relationship with the Ensemble 
Accuracy. Machine Learning, 51 (2) , pp. 181-207. 
計畫成果自評 
研究內容與原計畫大致相符。本計畫共有三篇論文發表於兩個 IEEE國際會
議。主持人以計畫經費出席其中一個國際會議並口頭報告其中兩篇論文，另外，
主持人自費出席另一國際會議並口頭報告另一篇論文。本計畫也幫助一位碩士班
20 
 
附錄：出席國際學術會議心得報告與
已發表之論文全文 
for Assistive Technology，其內容著重在如何將機器學習的技術應用於輔助器具
的開發，包括智慧居家、導航系統、提示系統，還有透過 BCI (brain-computer 
interface) 控制的輪椅。Michael Lightner教授曾任 IEEE主席。接下來是韓國 Seoul 
National University 的 Byeong Gi Lee 教授的演講，講題是 Convergence of 
Communications towards Smart Era，其內容在回顧並展望通訊系統的發展，並提
出未來的科技發展應要協助人們建立智慧且環保的社會，使得人們可以過著智慧且
環保的生活。Byeong Gi Lee教授為 IEEE Fellow。最後是土耳其 Erciyes University
的 Mehmet Emin Yuksel 教授的演講，講題是 Digital Image Restoration Operators 
Based on Neuro-Fuzzy Techniques，其主要內容是在介紹神經模糊技術於影像處理
的應用，包括雜訊過濾、雜訊偵測，還有邊緣抽取。Mehmet Emin Yuksel為 IEEE Senior 
Member。下午是論文報告的 session。本人應邀擔任一個以人工智慧為主題的 session
的主持人，並口頭發表論文一。7月 13日，本人再次應邀擔任一個以人工智慧為主
題的 session 的主持人，並口頭發表論文二。本會議與 2012 IEEE International 
Conference on Communications, Network and Satellite (COMNETSTAT 2012) 合
辦，而 7/14 的主題為通訊、網路，以及衛星技術。會議於 7月 14日結束。 
 
二、與會心得 
 
這雖然是一個新的國際會議，且在投稿系統、註冊系統，以及議程安排方面都還有
待改善，但主辦單位仍是安排數個資深且有名望的學者擔任主題演講的講者，讓資
淺者如本人從中獲益良多。這個會議的參與者大多來自亞洲，使得會議的國際化程
度不如預期，但若考慮大多數亞洲國家正在快速發展，且對應用科技有強烈的需求，
 論文二摘要：Ensemble learning is inspired by the human group decision making 
process, and it has been found beneficial in various application domains. 
Decision tree and artificial neural network are two popular types of 
classification algorithms often used to construct classic ensembles. 
Recently, researchers proposed to use the mixture of both types to construct 
hybrid ensembles. However, researchers use decision trees and artificial 
neural networks together in an ensemble without further discussion. The focus 
of this paper is on the hybrid ensemble constructed by using decision trees 
and artificial neural networks simultaneously. The goal of this paper is not 
only to show that the hybrid ensemble can achieve comparable or even better 
classification performance, but also to provide an explanation of why it 
works. 
 
四、建議 
 
本人認為此類新興國際會議或可幫助推廣自己的研究的應用，例如替自己的研究找
到使用者，且能提升台灣的國際聲望，故希望日後仍有機會獲得國科會補助參與此
類會議。 
 
五、攜回資料名稱及內容 
1. 會議議程手冊，內含各主題演講的摘要與講者簡歷，還有各論文的題目、作者，
  
Class = CHOOSE(ClassSet)  
 SEPERATE&CONQUER(Class,TrainData):  
RuleSet =∅  
while POSITIVE(TrainData)≠∅  
Rule=[null→Class]  
Covered=COVER(TrainData,Rule)  
while NEGATIVE(Covered)≠∅  
GROW(Rule,Covered) 
Covered= COVER(Covered ,Rule)  
RuleSet=RuleSet ∪{Rule}  
TrainData=TrainData \ Covered 
return RuleSet 
The rest of this paper is organized is the following way: 
Section 2 will give the preliminaries, and the proposed 
classification algorithm will be introduced in Section 3. The 
experimental results are presented in Section 4. The paper will 
be concluded in Section 5 with potential directions for future 
work. 
II. PRELIMINARY 
A. Rule-based classification algorithm 
Rule learning is to learn rules from the given training data, 
and a rule-based classification algorithm uses the learned rules 
to classify unseen data records. For classification, a decision 
rule is a logic statement with the following form: 
condition1 ∧ condition2 ∧…→class, 
where a condition is usually an attribute-value pair indicating a 
certain value of a certain attribute that is required to trigger the 
condition. 
If a training data record matches all conditions of the rule, 
we say that the rule covers the data record; if the rule covers a 
data record and classify the data record to the right class, we 
say that the rule explains the data record. 
RIPPER [3] is a popular rule-based classification algorithm. 
It has two stages: The generation stage and the optimization 
stage. The classification algorithm proposed in this paper 
competes with it in the generation stage. 
B. The Rough Set Theory 
The rough set theory is first introduced by Zdzisław I. 
Pawlak in 1982 as a mathematical tool to characterize 
imprecise knowledge [11][12]. As shown in Figure 1 (a) and 
(b), the main difference between a rough set and a classic set is 
the appearance of a boundary “region” (not just a boundary), 
where the uncertain elements exist, in a rough set. The fuzzy 
set theory [17] is another tool to characterize imprecise 
knowledge. The main difference between a fuzzy set and a 
rough set is that a fuzzy set needs a membership function to the 
degree of an element’s participation in it. Practically speaking, 
such a membership function is defined under some 
assumptions and on a case-by-case basis. Nevertheless, a rough 
set needs no membership function, since the uncertain elements 
are located in the boundary region in a rough set. 
Given a decision table A=(U,C∪D), as shown in Figure 1 
(c), where U={x1,x2,x3,x4,x5,x6,x7,x8} is the universe or the 
training data, C={a1,a2} is the condition or the attribute set of 
the training data, and D={d} is the decision or the set of class 
labels of the training data. A rough set of d=y is shown in 
Figure 1 (d). Since there is no difference between the condition 
of x4 and that of x5, they are in the boundary region. 
For data records x1 and x2, if the values of all their attributes 
are the same, we say that x1 and x2 are indiscernible. The set of 
all data records including x that are indiscernible by the 
attribute set C is denoted by C(x). Below are definitions for Y 
corresponding to the set of d=y: 
The positive region of Y: 
POSA (Y) = {x⎪C(x) ⊆ Y}. 
The negative region of Y:  
NEGA (Y) = {x|C(x) ∩ Y=∅}. 
The boundary region of Y: 
BOUNDA (Y) = Y − POSA (Y) − NEGA (Y). 
Figure 1.  (a) Classic set. (b) Rough set. (c) Decision table A=(U,C∪D). (d) 
Rough set of d=y. 
III. THE PROPOSED METHOD 
A.  Separate-and-Conquer 
The separate and conquer strategy first builds a rule that 
explains a part of the training data, separates them, and 
conquers the rest recursively until no data remain. It ensures 
that every data record is at least covered by one rule. Figure 2 
gives the separate and conquer algorithm, the core of the 
proposed classification algorithm in this paper. Before the 
algorithm begins, one of the classes is chosen. POSITIVE 
chooses the data that should be classify to the chosen class, and 
NEGATIVE chooses the others. Every Rule is empty in the 
beginning, and continues to grow until no negative data is 
covered by it. 
 
Figure 2.  The SEPERATE&CONQUER algorithm. 
 
 
 
 
 
 
 
 
          (a)    (b) 
 U a1 a2 d 
 x1 1 2 y 
x2 2 1 y 
x3 2 2 y 
x4 3 2 y 
x5 3 2 n 
x6 3 3 n 
x7 3 4 n 
x8 4 3 n 
           (c)    (d) 
negative 
positive 
negative 
boundary 
positive 
x6, x7, x8 
 x4, x5 
 x1, x2, x3 
2
 BUILD_CLASSIFIER( ):  
build a ClassList by ascending frequency or
for each Class in ClassList: 
RuleSet=SEPERATE&CONQUER(Clas
 concatenate the RuleSet to the bottom
return RuleList 
ROUSER generates set of rules for each cl
rule set is generated, it is concatenated to the b
list. The BUILD_CLASSIFIER algorithm 
shown in Figure 7. The class list is sorte
frequency order in order to prevent the 
distribution problem. For an unseen case, RO
down the rule list and uses the first rule that c
classify it. 
Figure 7.  The BUILD_CLASSIFIER alg
ROUSER ignores missing value when eva
The reason is simple: missing value cannot be 
rule. In some situations, the PotBound of an a
with all missing value, which means that this
valid value in the PotBound. This attribute sho
since missing value gives no power to discern 
IV. EXPERIMENT AND RESUL
In this section, we discuss experiment
ROUSER with ID3, J48 (an implementation o
JRip (an implementation of RIPPER [3]),
provided by WEKA [7]. 
TABLE I.  THE DATA SETS USED FOR EXP
UCI 
data 
set 
Data description 
Data name #instances #attributes Class dis
1 
 
audiology 
 
226 69 
2 
 
car evaluation 
 
1728 6 
3 
 
chess 
 
3196 36 
4 
 
mushroom 
 
8124 22 
5 
molecular biology: 
spice gene 
sequences 
3190 61 
6 
molecular biology: 
promotor gene 
sequences 
106 58 
7 
 
nersery 
 
12960 8 
8 
 
tic-tac-toe 
 
958 9 
9 
 
voting-records 
 
435 16 
der 
s,TrainData)  
 of the RuleList
ass. As soon as a 
ottom of the rule 
of ROUSER is 
d by ascending 
imbalance class 
USER searches 
overs the case to 
orithm. 
luating DiscPow. 
chosen to grow a 
ttribute are filled 
 attribute has no 
uld be removed, 
data. 
TS 
s that compare 
f C4.5 [14]) and 
 which are all 
ERIMENTS. 
tribution missing value 
yes 
no 
no 
yes 
no 
no 
no 
no 
yes 
The data sets used for experim
UCI Machine Learning Repository 
They are collected from different ap
biology, gaming, politics, and mark
attributes ranges from 6 to 69; th
ranges from 2 to 24; for some of th
are imbalanced; and some data sets 
some attributes. 
We use 10-fold cross-valid
classification performance. The 
summarized in Table II. The numb
accuracy rates in percentage. The 
ROUSER provides comparable 
performance. Some results for ID3 
limitations. On two data sets, JRip
but it is outperformed by ROUSER
that ROUSER performs well on da
attributes and data sets where t
imbalanced. However, ROUSER do
data sets 2 (car evaluation) and 5
think that there is no optimization st
is in RIPPER) to reduce errors a
deeper investigation of this will b
Furthermore, ROUSER does not 
expected on the data sets 1 (audiolo
We think that ROUSER needs a mo
handle missing values. An improvem
the future work. 
TABLE II.  EXPERIMENT RESULT
UCI 
data set 
Classific
ROUSER 
1 71.0 
2 84.1 
3 99.3 
4 100.0 
5 82.0 
6 85.8 
7 98.8 
8 96.9 
9 94.5 
V. CONCLUSIONS AND
A rule-based classification algo
proposed. It is designed to process 
human understandable decision rul
set approach as its search heuristi
method of ROUSER is based on
strategy. 
As a prototype without the 
pruning stage to reduce errors, 
classification performance compa
accurate on the data sets 3, 4, 7, a
least 4% more accurate on the data s
rule-based or tree-based classificatio
experiments. Since the search heuri
different from the search heuristics
Gain) used by the other three algori
the proposed PotBound and DiscP
ents are all available from 
[18], as shown in Table I. 
plication domains, such as 
eting; the number of their 
e number of their classes 
em, the class distributions 
are with missing values on 
ation to evaluate the 
experimental results are 
ers reported in Table II are 
numbers are highlighted if 
or better classification 
are not available due to its 
 outperforms J48 and ID3, 
. The results also indicate 
ta sets that are with more 
he class distributions are 
es not perform well on the 
 (molecular biology). We 
age in ROUSER (but there 
nd over fitting occurs. A 
e part of the future work. 
perform as well as we 
gy) and 9 (voting-records). 
re sophisticated strategy to 
ent on this will be part of 
S IN ACCURACY RATES (%). 
ation algorithms
J48 ID3 JRip 
77.0 x 74.0 
92.4 89.4 86.7 
99.4 99.7 99.2 
100.0 x 100.0 
94.4 89.5 94.1 
81.1 76.4 78.3 
97.1 98.2 97.0 
85.1 83.2 97.8 
96.3 x 96.1 
 FUTURE WORK 
rithm named ROUSER is 
nominal data and generate 
es. ROUSER uses a rough 
c, and the rule generation 
 the separate-and-conquer 
optimization stage or the 
ROUSER still provides 
rable (2% more or less 
nd 9) to or even better (at 
et 6) than that given by the 
n algorithms considered in 
stics of ROUSER is totally 
 (Entropy and Information 
thms, the results imply that 
ow are useful. This also 
4
Hybrid Ensembles of Decision Trees and Artificial
Neural Networks
Kuo-Wei Hsu
Department of Computer Science
National Chengchi University
Taipei 11605, Taiwan (R.O.C.)
Email: hsu@cs.nccu.edu.tw
Abstract—Ensemble learning is inspired by the human group
decision making process, and it has been found beneficial in
various application domains. Decision tree and artificial neural
network are two popular types of classification algorithms often
used to construct classic ensembles. Recently, researchers pro-
posed to use the mixture of both types to construct hybrid ensem-
bles. However, researchers use decision trees and artificial neural
networks together in an ensemble without further discussion. The
focus of this paper is on the hybrid ensemble constructed by using
decision trees and artificial neural networks simultaneously. The
goal of this paper is not only to show that the hybrid ensemble
can achieve comparable or even better classification performance,
but also to provide an explanation of why it works.
Index Terms—Machine learning, classification, neural nets
I. INTRODUCTION
For classification tasks, an ensemble trains and uses a group
of member classifiers. Given a data record whose class label
is unknown, an ensemble will use its member classifiers to
generate individual classifications and then aggregates these
classifications to generate an overall classification. Ensemble
learning is inspired by the human group decision making
procedure.
Diversity among member classifiers plays a significant role
in the success of most ensembles. Some ensemble construction
approaches use sampling techniques to generate different data
sets for training and further diverse member classifiers; some
use different classification algorithms to create diverse member
classifiers, and we can view these ensemble construction
approaches as the ones that transform heterogeneity between
classification algorithms into diversity between member clas-
sifiers.
We focus on ensembles that are variants of bagging (boot-
strap aggregating) [1], a popular ensemble construction ap-
proach that uses the bootstrap procedure to manipulate the data
set for training and further to create diverse member classifiers
[2]. Decision tree and artificial neural network are the favorite
classification algorithms in the machine learning community,
and they are often used to construct ensembles [3].
Ensembles of decision trees have been applied to various
problems in many application domains. Sun uses ensembles
of decision trees in pitch accent prediction [4]. Tong et al.
apply a combination of multiple decision trees to the problem
of classifying a new chemical [5]. Mare´e et al. use ensembles
of decision trees along with another technique in biomed-
ical image classification [6]. Ensembles of artificial neural
networks have been applied to various problems in many
application domains, too. Giacinto and Roli apply them to the
image classification problem [7]. Yao et al. apply them to the
telecommunication traffic flow prediction problem [8]. Zhou
et al. apply them to the lung cancer cell identification problem
[9]. Shu and Burn study ensembles of artificial neural networks
in pooled flood frequency analysis [10]. Maqsood study them
in weather forecasting [11]. West et al. apply them to the
financial decision problem [12]. Gu¨lera and ¨Ubeylıb apply
them to the electrocardiogram beats classification problem
[13].
Recently, researchers proposed the use of the mixture of
these two types of classification algorithms to construct hy-
brid ensembles (and the those mentioned earlier are called
classic or non-hybrid ensembles). Lu and Bongard start from
an observation that “some classifiers are more suitable for
different data sets than others” and propose an algorithm to
train an ensemble composed of decision trees and artificial
neural networks [14]. Lu et al. discuss sampling techniques
along with ensembles composed of decision trees and artificial
neural networks for active learning [15]. Hsu and Srivastava
demonstrate that ensembles composed of decision trees and
artificial neural networks together could outperform ensembles
composed of either of them alone [16]. However, researchers
use decision trees and artificial neural networks together in
an ensemble without further discussion. If we additionally
consider hybrid ensembles composed of other types of classi-
fication algorithms, we can find various applications of hybrid
ensembles, such as credit scoring [17], risk assessment [18],
medical databases [19], activity recognition [20], and energy
consumption forecasting [21]. The insights gained from this
paper can have a potential impact on these applications.
The rest of this paper is organized as follows: Section II
gives a the analysis based on bias-variance decomposition.
Section III describes experimental settings and reports exper-
imental results. Section IV presents the discussion. Section V
concludes this paper and suggests possible extensions of this
paper.
978-1-4673-0890-8/12/$31.00 ©2012 IEEE 25 COMNETSAT 2012
are accurate or more member classifiers that are less accurate
by using a classification algorithm with high bias, we can
have an ensemble achieving low error rate or high accuracy
(as the member classifiers work together) if the classification
algorithm used by us is also with high variance or if the
member classifiers built using the classification algorithm are
diverse. In such a case, when some member classifiers make an
error, others diverse or different from these member classifiers
would have a chance to correct the error so that the ensemble
composed of them would generate a correct classification. This
holds when noise appears in the data set, since noise may
“accidentally” correct an error made by some or even most
member classifiers.
III. EXPERIMENTS
Algorithm 1 presents the construction of a hybrid ensemble
of decision trees and artificial neural networks, and it is
implemented by modifying the implementation of bagging
[1] provided by WEKA [23]. In experiments, we compare it
with classic ensembles of decision trees or artificial neural
networks. These classic ensembles are constructed by using
the implementation of bagging [1] provided by WEKA [23]
without modifications. We use the implementation of the
C4.5 algorithm [24] (with default parameters) provided by
WEKA [23] to build a decision tree. Similarly, we use the
implementation of the multilayer perceptron algorithm (with
default parameters) provided by WEKA [23] to build an
artificial neural network.
Input: 𝐷 is the given data set for training, and 𝑁 is the
number of member classifiers
Output: 𝐸 is the resulting ensemble, i.e. a set of
member classifiers
initialize 𝐸 = ∅;
for 𝑖 = 1; 𝑖 ≤ 𝑁 do
𝑆𝑖 ← Bootstrap(D);
if 𝑖 is even then
specify 𝐴𝑖 as a decision tree algorithm;
else
specify 𝐴𝑖 as an artificial neural network
algorithm;
end
𝐶𝑖 ← BuildClassifier(𝑆𝑖, 𝐴𝑖);
𝐸 ← 𝐸 ∪ 𝐶𝑖;
end
return 𝐸;
Algorithm 1: The construction of a hybrid ensemble of
decision trees and artificial neural networks.
In Algorithm 1, Bootstrap() performs sampling with re-
placement. Bootstrap is a procedure that replaces an unknown
distribution with a known distribution to compute statistics
in which we are interested. When performing classification
tasks in real-world applications, we hardly know the under-
lying distribution but have the distribution of observed or
collected samples. We can also use the bootstrap procedure
when training samples are limited or when we use ensem-
ble approaches that require diverse training samples drawn
from different distributions. Furthermore, in Algorithm 1,
BuildClassiﬁer() constructs a classifier 𝐶𝑖 using the given
training set 𝑆𝑖 and the specified classification algorithm 𝐴𝑖,
and 𝐶𝑖 will be a member classifier in the resulting ensemble.
What makes Algorithm 1 different from bagging is the if-then-
else statement. Algorithm 1 alternately selects one between
the decision tree algorithm and the artificial neural network
algorithm, but does not bagging. Algorithm 1 is simple but
we find that it yields good results. Similar findings are also
reported by others, as mentioned earlier.
All the data sets considered in experiments are available on
the web 1, and most are derived from the data sets available
on the UC Irvine Machine Learning Repository [25]. Every
data set is either originally for a binary classification task or
transformed from a multi-class classification task into a binary
one. Table I summarizes the characteristics of the data sets
considered in experiments. In Table I, each row is for a data
set, while the first column is its name, the second column is
its number of data records, the third column is its number
of attributes, and the fourth column is the percentage of the
majority class of the data set.
TABLE I
THE SUMMARY OF DATA SETS.
data set size dim. maj. (%)
sonar 208 60 53
ionosphere 351 34 64
colic 368 22 63
vote 435 16 61
credit 490 15 56
boston 506 13 74
hprice 546 11 50
credit-a 690 15 56
credit-g 1000 20 70
halloffame 1340 16 91
Table II summarizes experimental results 2. The values
of bias and variance (var) are given by the bias-variance
decomposition method [26], provided by WEKA [23], with
the number of iterations set to 100 and the percentage of
data for training set to 50. In Table II, each row reports the
result of applying a classification model (a single classifier
or an ensemble of classifiers) to a data set, the first column
is the name of the data set, the second column is the name
of the classification model, the third column is the value of
bias, the fourth column is the value of variance, and the fifth
column is the error rate. Notations for the classification models
considered in experiments are as follows: DT is for a single
decision tree, MLP is for a single artificial neural network,
B-DT is for a classic ensemble of ten decision trees, B-MLP
is for a classic ensemble of ten artificial neural networks, and
B-DT+MLP is a hybrid ensemble of five decision trees and
1http://tunedit.org/
2The details are omitted due to the page limit.
27
Group 1 in which we replace MLP with DT, then we introduce
DT with lower variance into the ensemble, and then the error
rate is lower when variance is lower according to Equation 1.
If there is noise, 𝑁 > 0, and if we think this group closer to
Group 2 in which we replace DT with MLP, then we introduce
MLP with higher variance into the ensemble of DT, and then
the error rate is lower when there is noise and variance is
high according to Equation 2. This is what credit-g in Table
III shows us.
Group 4. B-DT, B-MLP, and B-DT+MLP perform equally
well. If we think that this group closer to Group 1 where DT
is introduced into an ensemble of MLP, and if the introduced
DT is with high bias but the same variance, as shown to us by
hprice in Table III, then we speculate that noise appears but
has surprisingly positive effect according to Equation 2. If we
think this group closer to Group 2 where MLP is introduced
into an ensemble of DT, and if the introduced MLP is with
low bias but the same variance, as shown to us by halloffame
in Table III, then more test data records are made correctly
classified by MLP but their positive effect is shifted by noise
according to Equation 1. No matter we think that this group
closer to Group 1 or Group 2, if the introduced DT or MLP
is with the same bias and the same variance, as what happens
on halloffame, then we speculate that noise appears but has
surprisingly positive effect according to Equation 2.
V. CONCLUSIONS
In this paper, we study the hybrid ensemble constructed
by using decision trees and artificial neural networks si-
multaneously. Ensemble learning is to construct a classifier
composed of several classifiers, and it has been found bene-
ficial by researchers and practitioners. Both decision tree and
artificial neural network are popular types of classification
algorithms often used to construct classic ensembles. Re-
cently, researchers proposed to use the combination or mixture
of these two types of classification algorithms to construct
hybrid ensembles. However, researchers use decision trees
and artificial neural networks together in ensembles without
further discussion. The goal of this paper is to have a better
understanding of the hybrid ensemble. We not only show that
the hybrid ensemble can achieve comparable or even better
classification performance but we also provide an explanation
of why it works. As part of the future work, we plan to
investigate the hybrid ensemble composed of classifiers other
than decision trees and artificial neural networks. We also plan
to apply the analysis to other types of ensembles.
ACKNOWLEDGMENT
The National Science Council of Taiwan (R.O.C.) supported
this work under Grant NSC 100-2218-E-004-002. The support
is gratefully acknowledged. The author would also like to
thank anonymous reviewers for their valuable time.
REFERENCES
[1] L. Breiman, “Bagging predictors,” Machine learning, vol. 24, no. 2, pp.
123–140, 1996.
[2] P. Tan, M. Steinbach, V. Kumar et al., Introduction to data mining.
Pearson Addison Wesley Boston, 2006.
[3] J. Ghosh, “Multiclassifier systems: Back to the future,” in Proc. of
International Workshop on Multiple Classifier Systems, vol. 3, 2002,
p. 1.
[4] X. Sun, “Pitch accent prediction using ensemble machine learning,”
in Seventh International Conference on Spoken Language Processing,
2002.
[5] W. Tong, H. Hong, H. Fang, Q. Xie, and R. Perkins, “Decision
forest: Combining the predictions of multiple independent decision tree
models,” J. Chem. Inf. Comput. Sci, vol. 43, pp. 525–531, 2003.
[6] R. Mare´e, P. Geurts, J. Piater, and L. Wehenkel, “Biomedical image
classification with random subwindows and decision trees,” Computer
Vision for Biomedical Image Applications, pp. 220–229, 2005.
[7] G. Giacinto and F. Roli, “Design of effective neural network ensembles
for image classification purposes,” Image and Vision Computing, vol. 19,
no. 9-10, pp. 699–707, 2001.
[8] X. Yao, M. Fischer, and G. Brown, “Neural network ensembles and their
application to traffic flow prediction in telecommunications networks,”
in Proc. of International Joint Conference on Neural Networks, vol. 1,
2001, pp. 693–698.
[9] Z. Zhou, Y. Jiang, Y. Yang, and S. Chen, “Lung cancer cell identification
based on artificial neural network ensembles,” Artificial Intelligence in
Medicine, vol. 24, no. 1, pp. 25–36, 2002.
[10] C. Shu and D. Burn, “Artificial neural network ensembles and their ap-
plication in pooled flood frequency analysis,” Water Resources Research,
vol. 40, no. 9, p. W09, 2004.
[11] I. Maqsood, M. Khan, and A. Abraham, “An ensemble of neural
networks for weather forecasting,” Neural Computing & Applications,
vol. 13, no. 2, pp. 112–122, 2004.
[12] D. West, S. Dellana, and J. Qian, “Neural network ensemble strategies
for financial decision applications,” Computers & operations research,
vol. 32, no. 10, pp. 2543–2559, 2005.
[13] I. Gu¨lera and E. ¨Ubeylıb, “Ecg beat classifier designed by combined
neural network model,” Pattern Recognition, vol. 38, pp. 199–208, 2005.
[14] Z. Lu and J. Bongard, “Exploiting multiple classifier types with active
learning,” in Proc. of Annual Conference on Genetic and Evolutionary
Computation, 2009, pp. 1905–1906.
[15] Z. Lu, X. Wu, and J. Bongard, “Adaptive informative sampling for active
learning,” in Proc. of SIAM International Conference on Data Mining,
2010, pp. 894–905.
[16] K. Hsu and J. Srivastava, “An empirical study of applying ensembles of
heterogeneous classifiers on imperfect data,” New Frontiers in Applied
Data Mining, pp. 28–39, 2010.
[17] N. Hsieh and L. Hung, “A data driven ensemble classifier for credit
scoring analysis,” Expert Systems with Applications, vol. 37, no. 1, pp.
534–545, 2010.
[18] G. Wang and J. Ma, “A hybrid ensemble approach for enterprise credit
risk assessment based on support vector machine,” Expert Systems with
Applications, 2011.
[19] B. Verma and S. Hassan, “Hybrid ensemble approach for classification,”
Applied Intelligence, vol. 34, no. 2, pp. 258–278, 2011.
[20] J. Min and S. Cho, “Activity recognition based on wearable sensors
using selection/fusion hybrid ensemble,” in Proc. of IEEE International
Conference on Systems, Man, and Cybernetics, 2011, pp. 1319–1324.
[21] L. Tang, L. Yu, S. Wang, J. Li, and S. Wang, “A novel hybrid ensemble
learning paradigm for nuclear energy consumption forecasting,” Applied
Energy, 2012.
[22] P. Domingos, “A unified bias-variance decomposition for zero-one and
squared loss,” in Proc. of National Conference on Artificial Intelligence,
2000, pp. 564–569.
[23] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and
I. Witten, “The weka data mining software: an update,” ACM SIGKDD
Explorations Newsletter, vol. 11, no. 1, pp. 10–18, 2009.
[24] R. Quinlan, C4.5: Programs for Machine Learning. San Mateo, CA:
Morgan Kaufmann Publishers, 1993.
[25] A. Frank and A. Asuncion, “UCI machine learning repository,” 2010.
[Online]. Available: http://archive.ics.uci.edu/ml
[26] R. Kohavi and D. Wolpert, “Bias plus variance decomposition for zero-
one loss functions,” in Proc. of International Workshop on Machine
Learning, 1996, pp. 275–283.
29
• Being ready to generate results at any point of time. 
We consider the TAIEX Futures data as streaming data 
because of the following reasons. First, every one of its 
transaction records should be referenced only once, because a 
transaction would not be traded under the same condition at 
two time points. Second, we are not able to save all trading 
information in the memory. In other words, the memory space 
is not unbounded. Third, we want to predict the rising or falling 
of price at any time point. Consequently, we have sufficient 
reasons to support that one should treat the TAIEX Futures data 
as streaming data (and further that one should use data stream 
mining techniques on the TAIEX Futures data). 
Moreover, an important issue that a data stream mining 
technique is expected to handle is concept drift. Concept means 
the underlying data distribution, and in most cases in the real 
world it is not always fixed but usually changes (or “drifts”) as 
time passes. As a result, we have sufficient reasons to assume 
that there probably exists concept drift in a stream of TAIEX 
Futures data (and accordingly that we should use a method that 
can detect concept drift). Concept drift will cause the 
decreasing of the accuracy of a mining model, or a 
classification model in this paper, built using techniques 
developed under the assumption of the fixed data distribution. 
In order to deal with this issue, we employ a data stream 
mining toolkit, Massive Online Analysis, abbreviated as MOA 
[2], designed for data streaming mining and extended from a 
widely employed data mining toolkit, Waikato Environment 
for Knowledge Analysis, abbreviated as WEKA [3]. Our 
findings could be concluded as follows:  
• The performance of data stream mining techniques or 
algorithms with the concept drift detection method 
(DDM) is significantly better than those without DDM. 
• Complex estimators do not necessarily correspond to 
better performance. 
In the following sections, we first discuss studies related to 
applying data mining techniques on stocks or futures, and we 
give an overview of methods proposed by others. Next, we 
introduce the steps and methods used in experiments. Then, we 
discuss our experimental results. Finally, we give conclusions 
and discuss potential directions for future work. 
II. RELATED WORK 
In this section, we briefly review related work and give a 
comparison of related work, as shown in Table I. In Table I, a 
column represents a paper related to the topic of this paper and 
a row represents a data mining technique. A cell of the table 
indicates that if the paper corresponding to a column uses the 
method corresponding to a row. If yes then it is marked by “V”. 
For example, the cell in the upper right corner indicates that the 
paper [4] uses non-streaming decision tree (and so do the 
papers [5] and [6]) and the second right cell in the second row 
indicates that the paper [9] uses sequential pattern mining. For 
decision tree, we listed various versions used in related work. 
According to Table I, we can see that the popular methods 
include decision tree, Support Vector Machine (SVM), and 
neural network. 
 
TABLE I.  A COMPARISON OF RELATED WORK. 
Methods\papers 
Non-streaming streaming 
[4] [5] [6] [7] [8] [9] This paper 
Decision tree V1 V2 V1    V3 
Sequential 
pattern mining      V
4  
Adaboost     V   
SVM  V      
Neural network  V      
Fuzzy-based rule    V    
k-means   V V    
Association rule   V     
Note: 1. C5.0 Tree; 2. Unknown (not specified by the authors); 3. Hoeffding Tree; 4. ICspan, IAspam. 
A. Non-streaming methods 
Data of stocks or futures is naturally streaming data. When 
we use data mining techniques designed for non-streaming data, 
it is important to transform a data stream into a set of data 
samples by using a time frame. 
In [4], 5-minute time frame is selected for TAIEX Futures 
forecasting. The paper uses C5.0 decision tree with two models: 
One is trained for rising or waiting, and it is named rising 
model; the other is trained for falling or waiting, and it is 
named falling model. These two models can be used with 
majority vote. To use majority vote, it would need a decision 
matrix, as the one shown in Table II. The row of the table is the 
decision of rising model, and the column is the decision of 
falling model. The cell of table is the joint decision given by 
majority vote.  
TABLE II.  DECISION MATRIX USED IN PAPER [4]. 
Rising\Falling Waiting Falling 
Waiting Waiting Falling 
Rising Rising Waiting 
 
The paper [5] compares methods for forecasting Taiwan IC 
Stocks. It compares SVM, SVM with Genetic Algorithm (GA-
SVM), decision tree, and Back-Propagation Network (BPN). 
Differing from other papers, it trains a model by financial 
indexes of accounting rather than the records of transactions.  
The paper [6] uses data mining techniques such as 
classification, clustering, and association rule to forecast the 
trend of stocks in the future. It analyzes the financial account of 
a company, and in order to examine whether the stock of a 
company is worth to hold, it uses C5.0 decision tree to train 
models. 
The paper [7] uses TSK fuzzy model for forecasting rather 
than classifying the TAIEX. Combining clustering method, 
TSK fuzzy model is better than BPN and multiple regression 
analysis for forecasting TAIEX in the paper. The data types in 
the paper are technical indexes which are statistical or 
calculated information of transactions. Because there are many 
technical indexes, factor selection is a problem discussed in the 
paper. Using the groups of data clustered by K-means, the 
paper sets up simplified fuzzy rules and trains the parameters.  
335
A. Prepairing Data  
TAIEX Futures data used in experiments, downloaded from 
Taiwan Stock Exchange Corporation web, includes transaction 
between January 1st in 2000 and December 31th in 2011, and 
the size of the time frame is set to 1 day. In order to train a 
model that can be used in the future, we remove all absolute 
timestamps and instead use relative timestamps.  
Labeling also becomes a problem since we do not have real 
settlement values for futures. So, we label each record with a 
closest value. Furthermore, to avoid confusion, we remove 
instances having 0 on the volume attribute. 
The attributes of data are listed below: 
• Relative Timestamp: The number of months from the 
trading date to the due date. 
• Open Value: The open price of a trading day. 
• Close Value: The close price of a trading day. 
• Highest and Lowest Value: The highest and lowest 
price traded in a trading day. 
• Volume: How many transactions of a trading day. 
• Settlement Value: The settlement price of a trading day. 
• Remains: How many remaining contracts in a trading 
day. 
• Last Buy: The last price to buy at close time in a 
trading day. 
• Last Sell: The last price to sell at close time in a trading 
day. 
• Trading Time: In the format of Year/Month/Day. 
• Class: Higher or lower, compared to the close price of 
the final settlement day with the close price of a trading 
day. 
Currently we select attributes by heuristics, and using some 
feature selection algorithms or statistical approaches will be 
part of our future work. Furthermore, we remove attributes that 
are directly related to the class label. For example, we use 
Close Value in the settlement day to tag the class label, so we 
remove it in the experiments. We also select attributes through 
experiments. Consequently, after testing some subsets of these 
attributes, we decide to use only Relative Timestamps, Open 
Value, Highest Value, Lowest Value, Volume, Remains, and 
Class.  
The distributions of attributes are shown in Figure 2. Each 
subfigure in Figure 2 corresponds to an attribute. In the bottom 
is the attribute name. The x-axis is the set of values of the 
attribute, and the number in the top in each subfigure is the 
number of instances of the corresponding attribute value  
The number of instances of each class is similar. We 
observe that the attributes Volume and Remains have 
imbalanced distributions with respect to Class (or the target 
class label).   
 
 
Figure 2.  Distribution of each atrributes: 
V1 = 1-6409, V2 = 134589-140998, V3 = 275587-281996, 
 R1 = 4-3677, R2 = 36743-40417, and R3 = 77156-80830. 
B. Massive Online Analysis 
Massive Online Analysis3, MOA, is proposed by A. Bifet et 
al [2]. It is based on Waikato Environment for Knowledge 
Analysis4, WEKA [3], and written in Java5 (an object-oriented 
and cross-platform programming language), and it supports a 
Graphical User Interface (GUI) and a command line interface. 
MOA offers a large set of functions to control the data mining 
process for data streams. For evaluation, MOA offers 
Prequential Evaluation, which tests each instances first and 
then trains a model using them; and it also offers Periodic Held 
Out Test, which tests instances by a (static) trained model and 
outputs results for the evaluation period. For controlling data, 
MOA includes artificial data generation functions and, of 
course, it supports the use of data provided by users. 
C. Result of experiment 
In the experiment, we classify instances with the default 
settings. For Hoeffding Tree, the settings include 95% 
confidence, information gain and 200 instances for grace 
period. Additionally, 30 instances ignored for DDM.  
We mainly use Hoeffding tree for evaluation and use Naïve 
Bayes as the control group. One of the reasons that we consider 
Naïve Bayes is that it is one of the most popular algorithms in 
the field of data mining [14] and it could be used in data stream 
mining. Furthermore, another major reason of using Naïve 
Bayes as the control group is that there are many references, 
such as [15][16][17][18], where Naïve Bayes is used in finance 
data mining. Nevertheless, using other algorithms as the control 
group will be part of our future work. 
We present experimental results in Figures 3-6, each of 
which uses accuracy in percentage as the y-axis and 
timestamps as the x-axis. It is shown in Figure 3 that the three 
algorithms achieve the average accuracy higher than 50%. We 
also could find that Hoeffding Tree and Hoeffding Adaptive 
                                                           
3 http://moa.cs.waikato.ac.nz/ 
4 http://www.cs.waikato.ac.nz/ml/weka/ 
5 http://www.java.com 
337
There still is an interesting observation that there is a 
significant decrease and increase between the 3rd season of 
2006 and the 3rd season of 2009 for Naïve Bayes. It was the 
time during financial tsunami. However, this phenomenon does 
not occur if the algorithm with DDM is used. Furthermore, 
there might be a relationship between accuracy and the trend of 
the stock. The bottom of accuracy of Naïve Bayes without 
DDM is in the 3rd season of 2007, in which the stock began to 
decrease heavily, and the stock began to increase when 
accuracy had increased to the same level which prior to the 
decrease. 
V. CONCLUSIONS 
The importance of extracting useful knowledge from 
massive data is undeniable. Data miming has been one of 
popular research fields, and recently data stream mining has 
become a popular subfield of data mining since in the real 
world data usually comes in a form of a stream. In this paper, 
we present our study of applying data stream mining 
techniques to the prediction of the rising or falling of the short-
term futures of Taiwan Stock Exchange Capitalization 
Weighted Stock Index Futures (TAIEX Futures). First, we give 
an overview of related studies. Next, we model the problem as 
a binary classification problem and then describe the toolkit, 
data pre-processing steps, and methods for experiments. Finally, 
we observe from the experimental results that using the drift 
detection method has significant impact on accuracy. Therefore, 
we assume that there exists concept drift in the Futures market. 
In this paper, we also see that applying data stream mining 
techniques on data from the futures market is useful and worth 
further investigation. 
There are many possible directions to extend the work 
presented in this paper. First, we use only transaction records 
for classification. However, more data sources may help us find 
better results. Hence, we can combine data from multiple 
sources to extend the base of data samples. Furthermore, 
feature selection will become more important when multiple 
data sources are considered. Additionally, how to retrieve 
association of different attributes of various data sources is a 
practical problem. Of course we can alternatively model the 
problem as a multi-class classification problem or a regression 
problem. Nevertheless, there still is an issue on which we can 
concentrate -- how to explain the associations between the time 
points of concept drift observed from experimental results and 
the trend of the stock in the real world. 
ACKNOWLEDGMENT 
The National Science Council of Taiwan (R.O.C.) 
supported the work presented in this paper under Grant NSC 
100-2218-E-004-002. The support is gratefully acknowledged. 
The authors would also like to thank anonymous reviewers for 
their precious time and valuable comments. 
REFERENCES 
[1] Handling Concept Drift: Importance, Challenges & Solutions, PAKDD
́2011 Tutorial. http://www.cs.waikato.ac.nz/~abifet/PAKDD2011/ 
[2] Albert Bifet, Geoff Holmes, Richard Kirkby, Bernhard Pfahringer. MOA 
- Massive Online Analysis. Journal of Machine Learning Research 11. 
[3] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. 
Witten, "The WEKA data mining software: an update," SIGKDD 
Explor. Newsl., vol. 11, pp. 10-18, 2009. 
[4] Data mining techniques to identify the direction of Taiwan Stock Index 
Futures day trading. Shih Hsiao Cheng. PhD Thesis, Department of 
Financial Engineering and Actuarial Mathematics of Soochow 
University. 2011. (in Chinese) 
[5] Application of Data Mining Technologies for IC Stock Category. Chia-
Hsien Chiu, Zne-Jung Lee. Digital Technology Information 
Management. 2009. (in Chinese 
[6] Data Mining for Analysis of Choosing Stocks from Taiwan Stock 
Market. 2009 International Conference on Advanced Information 
Technologies (AIT). (in Chinese 
[7] A TSK type fuzzy rule based system for stock price prediction. Pei-
Chann Chang , Chen-Hao Liu. Department of Information Management 
& Department of Industrial Engineering and Management, Yuan-Ze 
University. 2008, Expert Systems with Applications. 
[8] Using Adaboost for Taiwan Stock Index Future Intraday Trading System. 
Tien-Nan Lin. Master Thesis, Graduae Institute of Network and 
Multimedia college of Electrical Engineering and computer Science, 
National Taiwan University. 2008. (in Chinese) 
[9] Application of Multiple Data Streams Sequential Pattern Mining on 
Taiwan Stock Market. Ching-Ming Chao, Huei-Wen Yang. Journal of 
Information Management, Vol. 12, No.2, June. 2010. (in Chinse 
[10] Pedro Domingos and Geoff Hulten. Mining high-speed data streams. In 
Knowledge Discovery and Data Mining, pages 71–80, 2000. 
[11] Albert Bifet and Ricard Gavald`a. Adaptive parameter-free learning 
from evolving data streams. In 8th International Symposium on 
Intelligent Data Analysis, 2009. 
[12] Holmes, G., Kirkby, R., Pfahringer, B.: Stress-testing hoeffding trees. In: 
Jorge, A.M., Torgo, L., Brazdil, P.B., Camacho, R., Gama, J. (eds.) 
PKDD 2005. LNCS (LNAI), vol. 3721, pp. 495–502. Springer, 
Heidelberg (2005) 
[13] J. Gama, P. Medas, G. Castillo, and P. Rodrigues. Learning with drift 
detection. In SBIA Brazilian Symposium on Artificial Intelligence, 
pages 286-295, 2004. 
[14] X. Wu, V. Kumar, J.R. Quinlan, J. Ghosh, Q. Yang, H. Motoda, G.J. 
McLachlan, A.F.M. Ng, B. Liu, P.S. Yu, Z.-H. Zhou, M. Steinbach, D.J. 
Hand, and D. Steinberg, “Top 10 Algorithms in Data Mining,” 
Knowledge and Information Systems, vol. 14, no. 1, pp. 1-37, 2008. 
[15] Kirkos S., Spathis C., Manolopoulos Y., Data Mining techniques for the 
detection of fraudulent financial statements, Expert Systems with 
Applications., 2006. 
[16] Ou, P., Wang, H. Prediction of Stock Market Index Movement by Ten 
Data MiningTechniques. Modern Applied Science 3, 2009. 
[17] B. Rosenberg and W. McKibben. "The Prediction of Systematic and 
Specific Risk in CommonStocks." Journal of Financial and Quantitative 
Analysis, 1973. 
[18] Gidofalvi, G., Using News Articles to Predict Stock Price Movements. 
2001, University of California, San Diego: Department of Computer 
Science and Engineering. 
 
339
for Assistive Technology，其內容著重在如何將機器學習的技術應用於輔助器具
的開發，包括智慧居家、導航系統、提示系統，還有透過 BCI (brain-computer 
interface) 控制的輪椅。Michael Lightner教授曾任 IEEE主席。接下來是韓國 Seoul 
National University 的 Byeong Gi Lee 教授的演講，講題是 Convergence of 
Communications towards Smart Era，其內容在回顧並展望通訊系統的發展，並提
出未來的科技發展應要協助人們建立智慧且環保的社會，使得人們可以過著智慧且
環保的生活。Byeong Gi Lee教授為 IEEE Fellow。最後是土耳其 Erciyes University
的 Mehmet Emin Yuksel 教授的演講，講題是 Digital Image Restoration Operators 
Based on Neuro-Fuzzy Techniques，其主要內容是在介紹神經模糊技術於影像處理
的應用，包括雜訊過濾、雜訊偵測，還有邊緣抽取。Mehmet Emin Yuksel為 IEEE Senior 
Member。下午是論文報告的 session。本人應邀擔任一個以人工智慧為主題的 session
的主持人，並口頭發表論文一。7月 13日，本人再次應邀擔任一個以人工智慧為主
題的 session 的主持人，並口頭發表論文二。本會議與 2012 IEEE International 
Conference on Communications, Network and Satellite (COMNETSTAT 2012) 合
辦，而 7/14 的主題為通訊、網路，以及衛星技術。會議於 7月 14日結束。 
 
二、與會心得 
 
這雖然是一個新的國際會議，且在投稿系統、註冊系統，以及議程安排方面都還有
待改善，但主辦單位仍是安排數個資深且有名望的學者擔任主題演講的講者，讓資
淺者如本人從中獲益良多。這個會議的參與者大多來自亞洲，使得會議的國際化程
度不如預期，但若考慮大多數亞洲國家正在快速發展，且對應用科技有強烈的需求，
 論文二摘要：Ensemble learning is inspired by the human group decision making 
process, and it has been found beneficial in various application domains. 
Decision tree and artificial neural network are two popular types of 
classification algorithms often used to construct classic ensembles. 
Recently, researchers proposed to use the mixture of both types to construct 
hybrid ensembles. However, researchers use decision trees and artificial 
neural networks together in an ensemble without further discussion. The focus 
of this paper is on the hybrid ensemble constructed by using decision trees 
and artificial neural networks simultaneously. The goal of this paper is not 
only to show that the hybrid ensemble can achieve comparable or even better 
classification performance, but also to provide an explanation of why it 
works. 
 
四、建議 
 
本人認為此類新興國際會議或可幫助推廣自己的研究的應用，例如替自己的研究找
到使用者，且能提升台灣的國際聲望，故希望日後仍有機會獲得國科會補助參與此
類會議。 
 
五、攜回資料名稱及內容 
1. 會議議程手冊，內含各主題演講的摘要與講者簡歷，還有各論文的題目、作者，
  
100年度專題研究計畫研究成果彙整表 
計畫主持人：徐國偉 計畫編號：100-2218-E-004-002- 
計畫名稱：多分類器系統建構之理論與實務 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
