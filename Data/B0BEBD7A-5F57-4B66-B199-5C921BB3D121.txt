better field of view. Traditional calibration methods 
were designed for lens with fixed focal length. If 
focal length is changed, the calibration process has 
to be performed again. Real-time disotortion 
correction of a zoomable lens is impossible by using 
traditional calibration methods. In this project, we 
derive a formula of wide-angle distortion and focal 
length and construct the relationship between image 
boundary and focal length. Hence, we can estimate 
focal length on-line and achieve real-time distortion 
correction. 
英文關鍵詞： Endoscopic image, Wide-angle distortion correction, 
Zoomable lens calibration 
 
  
行政院國家科學委員會研究計畫成果報告 
寬廣視野內視鏡矯正計畫 
計畫編號：NSC 99-2622-E-007-019-CC2 
執行期限：99 年 12 月 1 日至 100 年 11 月 30 日 
計畫主持人： 賴尚宏教授    國立清華大學資訊工程(所) 
摘要 
微創手術是一個巨大的革新，它給病患帶來很大的利益。然而在微創手術上技術是更
困難的。因為外科醫生失去了觸覺的回饋，失去了深度的感受，並且只有有限的視角。小
的視角將造成外科醫生使用內視鏡時需要花費長時間探索以確認器官位置及狀態。這個計
畫的目的是讓外科醫生可以使用廣角鏡頭的內視鏡，但卻沒有廣角變形的缺點。此計畫中
我們發展了一個即時的去除變形的程序。去除變形的過程分成兩部份：包含了鏡頭校正與
即時的影像內插。我們發展了全自動的以霍氏轉換為基礎的校正方法，其校正結果與經典
的手動校正方式可以匹敵。在即時影像校正的部分，我們利用圖形處理單元(GPU)平行地
進行影像內插。手術進行時，醫生可能需要變焦以改變視野，傳統校正僅能針對固定焦距
的鏡頭，焦距一改變則需重新校正，這樣將無法達成即時校正的要求。我們推導出廣角鏡
頭變形與焦距的公式，並建立鏡頭的邊緣與焦距的關係，因此能即時的估計焦距並即時產
生校正影像。 
關鍵詞：內視鏡影像、廣角變形校正、可變焦鏡頭校正。 
Abstract 
Minimally invasive surgery (MIS) is a revolution in surgery that brings great benefits to the patient. 
However, technical procedures in MIS are more difficult since the surgeons don’t have the haptic 
feedback and depth perception, and the field of view of the endoscopic camera is quite limited. This 
small field of view causes the surgeon to take a long exploration phase to localize the organ’s position. 
The goal of this project is to allow surgeons to see wide-angle mages in the endoscopic camera 
without the drawback of lens distortion. In this project, we developed a real-time image undistortion 
process. The undistortion process can be divided into two main steps: the lens calibration and real-
time image interpolation. The calibration step is to estimate a set of parameters describing the optical 
lens distortion properties. We developed fully automatic Hough-based calibration method and 
calibration results are comparable to classic manual calibration method. To achive real-time distortion 
correction, we use graphics processing unit (GPU) to interpolate image in parallel. When surgeons 
perform operation, they could change focal length of lens to obtain better field of view. Traditional 
calibration methods were designed for lens with fixed focal length. If focal length is changed, the 
calibration process has to be performed again. Real-time disotortion correction of a zoomable lens is 
impossible by using traditional calibration methods. In this project, we derive a formula of wide-angle 
distortion and focal length and construct the relationship between image boundary and focal length. 
Hence, we can estimate focal length on-line and achieve real-time distortion correction. 
Keywords: Endoscopic image, Wide-angle distortion correction, Zoomable lens calibration. 
  
The pin-hole camera model has been widely used in 
computer vision and photogrammetry. Optical distortion can 
be easily incorporated into the model. Two kinds of optical 
distortions, radial distortion and tangential distortion were 
modeled in [4]. The radial distortion of a point is a 
displacement along the direction of the point to the camera 
center. The tangential direction is perpendicular to the radial 
direction. However, low tangential distortion could be 
compensated by estimating the distortion center [5]. The 
relationship between the distorted radius of an image point 
and the undistorted radius is approximated by a low-degree 
polynomial. Many researchers have found that the higher-
order terms could be ignored [6]. In addition, Fitzgibbon [7] 
suggested a division model which uses a low-order 
polynomial in the denominator instead of the numerator. 
Camera calibration usually uses two kinds of markers, 
corners and straight lines. A popular calibration toolbox [8] 
uses corners of chessboards for constructing correspondence. 
Although some existing camera calibration methods work 
well based on automatic chessboard detection [9], their 
performance usually depends on subtle implementation. The 
line-based camera calibration is another popular approach 
[10-13]. In structured environments or straight-line patterns, 
using line features could be a more suitable option. The 
projected lines without distortion should be straight; hence, 
Figure 1. An example of Colonscopic (Source [21]): (a) The original chessboard image. (b) The corrected image of 
the chessboard image. (c) The original colonscopic image. (d) The corrected colonscopic image. 
(a)                                                              (b) 
(c)                                                          (d) 
Figure 2. 3D Reconstruction of Colon Segments (Source [23]): (a) The original image. (b)(c) Reconstructed colon 
model. (c) The original colonscopic image. (d) The corrected colonscopic image. 
(a)                                                      (b)                                                    (c) 
  
range of distortion parameters and the possible regions of 
image center are selected. A uniform sampling is performed 
in this 3D parameter space. For each candidate parameter 
triplet (cx, cy, λ), all edge points are undistorted as follows: 
 y
d
yd
ux
d
xd
u c
r
cy
yc
r
cx
x 






22 1
,
1 
 
Based on these undistorted points, a Hough map H is 
obtained and normalized by dividing the total number of all 
votes. The entropy of the normalized Hough map is 
calculated with the following entropy formula.  



Hi
ii ppent ln  
Finally, the parameter triplet with the minimum entropy 
is selected as the best distortion parameter and image center.  
D. Gradient estimation 
Figure 3 illustrates the degenerate problem occurred in 
Hough entropy method. When the distortion parameter is 
large, the undistorted image will decrease its size. Hence, 
the zero counters in Hough map will increase and entropy 
decrease. 
The modified version of Hough entropy method is to use 
image center and distortion parameter to estimate the 
orientation of an edge point in undistorted image. 
Undistorting an image costs too much computation power, 
because our method examines many candidates in the 
parameter space. Hence, we derive how to use the image 
gradient in the division model to simplify the computation 
in the Hough transform. 
For estimating the orientation, we first calculate image 
gradient on distorted image by using Sobel mask.  Let us 
focus on the edge point (xd, yd). The normalized gradient on 
the distorted image is denoted by (gx
d, gy
d). A neighboring 
point (xd’, yd’) along a curved line direction (perpendicular 
to gradient) is (xd, yd)+ε(-gy
d, gx
d), where ε is small number. 
By using the division model, we can obtain undistorted 
positions of these two points by using the undistortion 
formula. 
     dyxddxyddd gcxgcyrr   2222  

y
d
yd
ux
d
xd
u c
r
cy
yc
r
cx
x 






22 1
,
1 
 
The gradient on the undistorted image, (gx
u, gy
u), can be 
estimated by the following equation.  

 
















 uu
uu
u
y
u
x
xx
yy
g
g
0
lim~

 
By letting ε approach to zero, we can obtain the gradient 
estimation formula by l’Hospital rule. 
    
    

















2
2
1
1
~
d
d
yxd
d
d
xyd
u
y
u
x
rgcxA
rgcyA
g
g



where     dyxddxyd gcxgcyA  2: 
Figure 4.  Captured images with different focal length, 18mm, 26mm, 35mm, 48mm, and 65mm. The second row 
contains the sub-images of original five images. The linear approximated sub-images are presented in the third row. All 
approximated images are generated by image (a).  
(a) 18mm (e) 65mm (d) 48mm (c) 35mm (b) 26mm 
Sub-regions of (a), (b), (c), (d), and (e) 
Linear approximated sub-regions of (a), (b), (c), (d), and (e) 
  
of visible region is another good measure for estimating 
focal length. If the boundary is not available, a simple 
modification for endoscopy can realize the estimation step. 
For example, a small marker could be put behind fisheye 
lens, and then is recognized online. 
The misalignment is another issue. The center of 
zoomable device and the distortion center of frontend 
fisheye lens may not be perfectly aligned. For solving this 
problem, we add the linear prediction for distortion center 
(cx, cy) for compensating the slight misalignment. 
 
IV. THE SYSTEM OF REAL-TIME ZOOMABLE WIDE 
ANGLE LENS CORRECTION 
In this section, we illustrate the whole system. First, we 
introduce wide-angle endoscopy distortion correction 
system with fixed focal length. Then, the extended system 
is shown in subsection B. 
A. Fixed focal length 
The system is divided into two part, calibration and 
rendering. The calibration could be operated offline. We 
just need take a single image which contains calibration 
pattern, and then perform our proposed single-image 
Hough-based autocalibration. The distortion parameters are 
used for correcting distortion.  
 
B. Zoomable lens 
For extending the system to a zoomable lens, we have to 
sample several different focal lengths. We add two 
components, focal length estimation component and 
distortion parameter table. The focal length estimation need 
be applied in each frame, so it must a lightweight and 
efficient component. We use distortion parameter table to 
implement our quadratic prediction mentioned in previous 
section. 
C. Correction part 
Given distortion parameters, the image have to be real-
time corrected. The algorithm of correction part is very 
regular. It consists of corresponding pixel computation for 
each undistorted pixel and bilinear interpolation. However, 
the large amount of computation makes real-time 
processing on CPU impossible. We use GPU to speed up 
the computation. First, the corresponding coordinates are 
computed on GPU in parallel. Secondly, we use texture 
memory to store distorted image. Because distorted image 
is just used for read-only and all threads can efficiently 
access texture memory, the bilinear interpolation can also 
be in parallel finished. 
 
V. EXPERIMENTAL RESULTS 
A. Qunantitative measure and Related methods 
We implement Wang’s line-based method [13] and 
Hough Transform-based method for Radial Lens Distortion 
Correction (HTRDC) [14] for experimental comparison. We 
use synthetic datasets and real images captured from fisheye 
lens and wide-angle endoscopy in our experiments. Wang’s 
method requires the user to select lines. In HTRDC, the user 
needs to select a region of interest that contains a single 
curve. The performance of these two methods depends on 
the user selection of lines. Our automatic method is based 
on Hough transform to aggregate the undistorted edge points 
and uses the undistorted image gradient to discount many 
error-prone votes. The results show the accuracy and 
efficiency of the Hough entropy method is considerably 
improved by properly using the image gradient information. 
Even if the lines are carefully selected in the other two 
methods, our method provides comparable results. 
For evaluating different methods, we select several 
curved lines in the distorted images. After the correction, 
undistorted points located in the same line are fitted with a 
straight line by using the total least squares. The root mean 
square of the distance of undistorted points to regression 
line is served as the quantitative measure RMSE. Our 
Hough entropy method with and without gradient estimation 
are denoted by HEwG and HEwoG, respectively. The 
HTRDC was proposed in [15], and Wang’s method was 
proposed in [13]. 
B. Synthetic datasets 
We also generate two synthetic datasets, syn1c (ground 
truth λ=-5.25E-06) and syn2c (ground truth λ=-8.85E-06). 
Because HTRDC needs to know the distortion center in 
advance, we compare the RMSE given different distortion 
centers. The distortion center is given by (x+Δ, y+Δ) where 
(x, y) is correct distortion center. The RMSE of HEwG and 
HTRDC are shown in Figure 9. In our method, we try to use 
different size of Sobel operator to reduce the gradient 
estimation error. Our method with 21x21 Sobel filters in all 
the experiments has the best results.  
Figure 8. The flowchart of the proposed distortion correction 
system for a zoomable fisheye lens of wide-angle endoscopy.. 
Figure 7. The flowchart of the distortion correction 
system for fixed focal length in wide-angle endoscopy. 
  
In this project, we have reached convincing results and 
demonstrated it is possible to correct wide-angle optical 
distortion from images acquired from a zoomable lens in 
real time. The system is proved to achieve the expected 
accuracy and efficiency. 
REFERENCES 
[1] C. Hughes, M. Glavin, E. Jones, and P. Denny, “Wide-angle camera 
technology for automotive applications: a review,” IET Intelligent 
Transport Systems, vol. 3, pp.19-31., March 2009. 
[2] C. Zhang, J.P. Helferty, G. Mclennan, and W.E. Higgins, “Nonlinear 
Distortion Correction in Endoscopic Video Images,” In ICIP, 2000. 
[3] Y. Xu and D. Song, “Systems and algorithms for autonomously 
simultaneous observation of multiple objects using robotic PTZ 
cameras assisted by a wide-angle camera,” In Proc. IROS, 2009. 
[4] D.C. Brown, “Decentric distortion of lenses,” Photogramm. Eng. 
Remote Sens. 32(3), 444-462, 1966. 
[5] G.P. Stein, "Internal camera calibration using rotation and  geometric  
shapes,"  M.Sc  Thesis,  Massachusetts Institute of Technology, 1993. 
[6] R. Tsai, "A versatile camera calibration technique for high-accuracy 
3D machine vision metrology using off-the-shelf TV cameras and 
lenses," IEEE J. Robot. Autom., 3, (4), pp. 323–344, 1987, 
[7] A.W. Fitzgibbon, "Simultaneous linear estimation of multiple view 
geometry and lens distortion", In: CVPR, pp. 125-132, 2001. 
[8] Bouguet, J.Y. Camera calibration toolbox for Matlab. Available 
online: www.vision.caltech.edu/bouguetj/calib_doc/ . 
[9] M. Rufli, D. Scaramuzza, and R. Siegwart, “Automatic Detection of 
Checkerboards on Blurred and Distorted Images,” International Conf. 
on Intelligent Robots and Systems, 3121-3126, Sep. 2008. 
[10] S. Chen and W. Tsai, "A systematic approach to analytic determine 
the camera parameters by line features," Pattern Recogn. 23, 859-877, 
1991. 
[11] B. Prescott and G. F. McLean, “Line-based correction of radial lens 
distortion,” Graph. models image proc., vol. 59,  pp. 39–47, Jan. 
1997. 
[12] F. Devernay and O. Faugeras. Automatic calibration and removal of 
distortion from scenes of structured environments.  In SPIE, vol. 
2567, July 1995. 
[13] A. Wang, T. Qiu, and L. Shao, "A Simple Method of Radial 
Distortion Correction with Centre of Distortion Estimation," J Math 
Imaging Vis, vol. 35, 165-172, 2009. 
[14] P.V.C. Hough, “Methods and means for recognizing complex 
patterns,” US Patent Specification 3,069,654, 1962. 
[15] R. Cucchiara, C. Grana, A. Prati, and R. Vezzani, “A Hough 
transform-based method for radial lens distortion correction,” Intern. 
Conf. on Image Analysis and Processing, pp. 182–187, 2003. 
[16] K. Ehrenfried, “Processing calibration-grid images using the Hough 
transformation,”  Meas. Sci. Technol., vol. 13, 2002. 
[17] R.T. Collins and J.R. Beveridge, “Matching perspective views of 
coplanar structures using projective unwarping and similarity 
matching,” In Proc. CVPR, 1993. 
[18] T. Tuytelaars, L. Van Gool, M. Proesmans, and T. Moons, "The 
cascaded Hough transform as an aid in aerial image interpretation. In 
Proc. ICCV, pp. 67–72, Jan. 1998. 
[19] A.F. Habib and M.F. Morgan, “Automatic calibration of low-cost 
digital cameras,” Optical Engineering, vol. 42, Apr. 2003. 
[20] D. Xu, Y.F. Li, and M. Tan, “Method for calibrating cameras with 
large lens distortion, ” Optical Engineering, vol. 55, Apr. 2006. 
[21] W. Li, S. Niea, M. Soto-Thompsona, C.-I Chenb, and Y. I. A-Rahim. 
Robust distortion correction of endoscope. In Proc. SPIE, 2008. 
[22] T. Stehle, D. Truhn, T, Aach, C. Trautwein, and J. Tischendorf. 
Camera Calibration for Fish-Eye Lenses in Endoscopywith An 
Application to 3D Reconstruction. In ISBI 2007. 
[23] DH Hong, JH Oh, and P.C. de Groen. 3D Reconstruction of Colon 
Segments from Colonoscopy Images. In ICBB 2009. 
[24]  J.P. Helferty, C. Zhang, G. McLennan, and W.E. Higgins. 
Videoendoscopic Distortion Correction and Its Application to 
Virtual Guidance of Endoscopy. In IEEE Trans. on Medical Imaging, 
2001. 
[25] J. Kannala and S.S. Brandt. A Generic Camera Model and 
Calibration Method for Conventional, Wide-Angle, and Fish-Eye 
Lenses. IEEE Trans. Pattern Analysis and Machine Intelligence, 
2006. 
Wang HEwG HTRDC Original HEwoG 
Figure 10.  Comparison of distortion correction results on the s5c image by using different methods. 
Figure 11.  Some snapshots of pairs of original (left) and corrected (right) images, including in-vivo evaluation, calibration, 
and training. 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：賴尚宏 計畫編號：99-2622-E-007-019-CC2 
計畫名稱：寬廣視野內視鏡影像矯正計畫 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 1 100%  專利 已獲得件數 0 1 100% 件  
件數 0 1 100% 件  
技術移轉 
權利金 0 300 100% 千元  
碩士生 3 3 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 1 100%  專利 已獲得件數 0 1 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
