一、報告內容
中文摘要
本報告中提出了一個能夠快速比對中文文字影像的方法，此方法基於文字的形狀特徵值，能
夠進行影像取樣點的一對一配對。由於文字的形狀特徵值主要描述取樣點空間上的相互關係
我們可以利用代數運算達成旋轉不變，大小不變，位移不變的特性，使得比對的精確度不會
受到字體大小及排版的影響。此外，由於中文字的複雜度高，書寫方式多樣化，我們利用文
字的區域特徵，使得文字在輕微扭曲的情形下，無須進行非線性轉換，仍可以快速的方法配
對。我們以1014個中文字的報紙影像進行實驗， 在不同字體及字型大小的情形下，平均比
對精確度為95%。在比對的速度方面，以Intel 1.6GHz的CPU，取樣點為40點的情形下，比對
速度平均值皆小於0.1秒(任兩個文字影像)。
關鍵詞： 文字影像比對, 形狀內容特徵, 文件影像處理, 資訊擷取。
Abstract
We present a shape context based approach for matching Chinese characters in a 
document image. The document image is represented as binary and the text regions 
are extracted for searching purpose. Based on the keyword entered, we measure 
the similarity between the image of keyword and the word image in the document. 
A ranking is returned where the most probable contexts of the document image are 
included. The keyword is matched as opposed to be recognized since the OCR 
method would be computational demanding if the document image volume gets large. 
Besides, character deformation due to scanning noise or handwriting may cause 
OCR failed. By using the shape context, we can gain certain invariance under 
transformations  such  as  scaling,  rotation  and  translation.  In  addition,  by 
selecting appropriate local appearance for the matching characters, the shape 
context can resist small non-linear transformations such as font change and 
italic. We performed the matching experiment on Chinese document images with 
different fonts and sizes among Chinese characters. The result is satisfactory 
with  95%  in  average  precision  and  the  average  CPU  time  for  matching  two 
characters can be below 0.1 seconds without training on a 1.6 GHz processor.
Keywords:  word  image  matching,  shape  context,  document  image  processing, 
information retrieval.
                    
historical manuscripts. The manuscript has difficulty in seg-
menting the words handwritten in English. The feature ex-
tracted makes the 2D image matching problem as a 1D fea-
ture sequence that can be matched with the Dynamic Time
Warp (DTW) algorithm. The DTW algorithm can align
two images with local warping resulted from handwriting.
One drawback of DTW is that it can only loosely match
the image along one dimension and ignore the variations in
the other dimension. 2D-DTW should be a good solution,
however, it would be NP-complete. Another matching tech-
nique developed by [5] used dynamic programming on the
edit distance between two image objects. The image was
encoded as a sequence of symbols by disassembling each
English alphabet into primitive strings. The match of prim-
itive strings can be partial and thus results in partial (or in-
exact) match of English letters. The variation in fonts and
letters is quite limited and therefore the algorithm can only
be applied to well-printed documents.
In contrast to English, previous works on matching with
Chinese characters are rare. One shape match technique,
Hausdroff distance, that was introduced in Chinese charac-
ter matching is in [7]. In realizing that the four corners of
a Chinese character weight more than the other parts, the
weighted Hausdroff distance (WHD), with the four corners
giving more contributions, makes a similarity measure be-
tween two character images. In spite of the simple distance
measure, the algorithm can process Chinese characters in
both horizontal and vertical direction without layout anal-
ysis. No character transformation and deformation were
mentioned in [7]. More earlier works used simpler mea-
sures. For example, [4] presented a content-based indexing
and retrieval method for Chinese document images. The
method was carried out based on the stroke density codes.
Recent development on the retrieval of multimedia objects
makes use of different pattern matching techniques. Of the
pattern matching techniques, the shape context [2] is good
at matching 3D objects, handwritten digits, structured im-
age objects such as trademarks and characters. As we will
discuss in the following sections, we can achieve various
degree of invariance under transformations using shape con-
texts. In additions, the matching will be economical without
training compared to the OCR method. Last, the method is
promising for similar languages, e.g., Korean and Japanese,
as long as one can correctly segment each character in the
preprocessing.
This paper is organized as follows: we review the shape
context and matching techniques in Section 2. Invariance
under transformation of character image is discussed in Sec-
tion 3. Experiment on Chinese document images and per-
formance measures are given in Section 4. We conclude in
Section 5.
2. MATCHING WITH SHAPE CONTEXT
In this section, we briefly review the shape descriptor—
shape context for characterizing an image object, followed
by the algorithm for matching two image objects by estab-
lishing point-to-point correspondence.
2.1. The Shape Context
The shape context proposed in [3] makes use of the lo-
cal/global histogram for the characterization of image ob-
jects. The image is represented by taking N randomly sam-
ple points on the boundary of the image black pixels. The
number N depends on the complexity of the image object.
Various degree of image preprocessing may be applied be-
fore the sampling really happens. In our experiment, la-
beling connected components and merging adjacent sub-
characters to properly segment each character are necessary.
Then, morphological operations for thinning the stroke of
Chinese character are applied.
In Fig. 1(a), the Chinese character and its sample pixels
are shown. For each sample pixel, we make a histogram by
measuring its relative position to the other pixels on the im-
age, as shown in Fig. 1(b). Let S denotes the set of sample
pixels, V denotes the set of all image pixels, the histogram
for a sample point ~si ∈ S can be expressed as
hi(r, θ) = #{~v : r = ‖~v − ~si‖, θ = 6 (~v − ~si), ~v ∈ V }
(1)
where r is the Euclidean distance between ~v and ~si, θ is the
angle of ~v−~si relative to the positive x-axis. The histogram
measured on the polar coordination in Fig. 1(c) exhibits po-
sitional information of the sample pixel to the other pixels.
Since both r and θ are continuous variables, we normalize
r and θ to be within the range of [0, 1] and 0 ◦—360 ◦ re-
spectively to reduce the large amount of information. Then
r and θ are divided into a fixed number of bins which can
be equally spaced or log-scaled. The collection of polar his-
tograms resulted from each sample pixel is called the shape
context whose dimension depends on the number of bins
chosen. We select more bins for more complex characters
in order to capture the detail of image structure. In Fig. 1(e),
we select 5 bins for radius r and 12 bins for angle θ. The
number of sample pixels N is 50. The shape context of the
character in Fig. 1(a) is shown in Fig. 1(f) whose dimension
is N by 60 since we flatten the polar histogram of each sam-
ple pixel into a 1×60 vector and concatenate all vectors into
an N × 60 matrix. To illustrate that the shape context can
uniquely identify its original image, in Fig. 1(d) the original
character image is re-constructed from its shape contexts.
Note that more bins in r and θ are required to differentiate
the detail of image structure.
sample points for the two images is equal. In order to re-
duce the amount of image pixels, morphological operations
for thinning the stroke of Chinese character are applied be-
fore the matching begins.
Figure 2: The matching of two Chinese characters with
point-to-point correspondence for illustrating the scale in-
variance of shape context. The number of sample points is
60 for each character and the sample points are taken ran-
domly, 10 selected point pairs are shown for illustrating the
correspondence.
3.2. Rotation
Rotational invariance can be achieved by measuring the an-
gle θ in (1) relative to the tangent angle at each sample point.
The relative angle computed in this way was referred to as
the relative frame in [3]. The shape context now becomes
completely rotational invariant. However, for some cases
the tangent angle is difficult to calculate, for examples, at
the turning point or the intersection of multiple strokes, in
which cases the matching will become imprecise.
We propose an approach which measures the angle of ro-
tation first, and do the matching based on the rotational an-
gle. Consider the circular shift operation on the histogram
hi(r, θ): Since hi(r, θ) is two dimensional, we sum up the
entries along the radius bin r and result in an one dimen-
sional histogram, hi(θ) =
∑
r hi(r, θ). The circular shift
operation on hi(θ) is defined by
hτi (θ) ≡ hi(θ)À τ (6)
where À means circular shift right by τ degree. Here we
divide θ into |θ| bins, the rotational angle τ can only be an
integer multiple of 360|θ| . The circular shift right operationÀ
on a sample array is shown in Fig. 3, where τ = 60 ◦ since
θ is equally divided into 12 bins. The modified chi-square
distance c˜i,j between hi(θ) and hj(θ) is defined as
c˜i,j =
1
2
min
τ
|θ|∑
θ=1
(hτi (θ)− hj(θ))2
hτi (θ) + hj(θ)
(7)
The matrix C˜ ≡ [c˜i,j ], similar to the matrix C in (4), is used
as the input to the Kuhn-Munkres algorithm to find the opti-
mal permutation for establishing point-to-point correspon-
dence. Note that in (7), we have an angle τ resulting in a
minimum of distance for each pair of points ~si, ~sj . With the
optimal permutation piopt, we have N angles τ1, τ2, . . . , τN
representing all possible angles that rotate the character. For
consistency, we can employ a voting scheme for choosing
the majority of τ1, τ2, . . . , τN as the angle of rotation.
Figure 3: The circular shift right operation on a sample ar-
ray hi(θ). The angle θ is equally divided into 12 bins, with
30 ◦ for each bin. The circular shift right operation on the
histogram above is equivalent to rotate the corresponding
character image by 60 ◦.
3.3. Local Appearance
In this subsection, we incorporate the local histogram as
part of the features for matching points on a character im-
age. Recall that in Section 2.2, the Ci,j is obtained by a
linear combination of ci,j and di,j , where di,j is the cost for
matching local appearance. We mean local appearance by
estimating local features such as local orientation, illumina-
tion and local histogram nearby a sample point. For the Chi-
nese character in Fig. 4(a), the structure inside the character
makes its histogram indiscernible unless a histogram with
much higher resolution is generated at each sample point.
To avoid such a formidable histogram, we consider using
the local histogram as the local appearance to differentiate
the details of image structure. The local histogram h¯i(r, θ)
for ~si ∈ S is created by pre-defining a rectangle R sur-
rounding ~si and counting the number of image pixel in R
that falls in each (r, θ) bin of polar coordination, i.e.,
h¯i(r, θ) = #{~v : r = ‖~v − ~si‖, θ = 6 (~v − ~si), ~v ∈ R}
(8)
The cost di,j for matching local histograms h¯i(r, θ) and
h¯j(r, θ) is the same as in (2) by flattening h¯i(r, θ) and
h¯j(r, θ) into h¯i(k) and h¯j(k) respectively and calculating
the chi-square distance between h¯i(k) and h¯j(k).
The resulting effect by incorporating the local histogram
in Ci,j is twofold: (1) Increase the resolution of shape con-
text as we match two points from different images, the ci,j
is the cost for matching image profile and the di,j is the cost
for matching local appearance. For a more complex char-
acter, we give di,j more weight to account for the detail of
image structure. (2) The shape context is more tolerant of
small deformations such as italic and font change, since if
we look closer, the change will become smaller and can be
negligible by the shape context.
Figure 7: The top 5 matching characters for each of the 11
queries.
5. CONCLUSIONS
We have presented an efficient approach for matching Chi-
nese characters in a document image. The character be-
ing matched is represented by its shape contexts and certain
invariance under transformations such as translation, scale
and rotation can be obtained. In addtion, we include more
shape contexts as the local appearance to resist small non-
linear transformations such as italic and font change. Exper-
imental results on a document image with 1014 characters
show that the average accuracies for 11 queries are 95% (av-
erage precision), 87.5% (R-precision) and 94.5% (preci-
sion@5). Since the matching process consumes most of the
computational power after the necessary preprocessing, we
measure the average CPU time for matching two characters
as 0.09, 0.21, 0.37(secs) for N = 40, 60, 80 respectively.
Without intensive training, the shape context approach is
also promising for matching handwritten texts as well as
characters in other languages such as Korean and Japanese.
ACKNOWLEDGEMENT
This research is supported by National Science Council of
Taiwan under grant number NSC 96-2221-E-431-002.
REFERENCES
[1] T. M. Rath and R. Manmatha, Word Image Match-
ing Using Dynamic Time Warping, Proc. of the Conf.
on Computer Vision and Pattern Recognition (CVPR),
Madison WI, vol. 2, pp. 521-527, June 2003.
[2] S. Belongie, J. Malik and J. Puzicha, Shape Matching
and Object Recognition using Shape Contexts, IEEE
trans. on Pattern Analysis and Machine Intelligence,
24:24 pp. 509-522, 2002.
[3] S. Belongie, J. Malik, Matching with Shape Contexts,
Proceedings of IEEE Workshop on Content-based Ac-
cess of Image and Video Libraries, pp. 20-26, 2000.
[4] Y. He, Z. Jiang, B. Liu and H. Zhao, Content-based In-
dexing and Retrieval Method of Chinese Document Im-
ages, Proc. of the 5th International Conference on Doc-
ument Analysis and Recognition, pp. 685-688, 1999.
[5] Y. Lu and C. L. Tan, Information Retrieval in Document
Image Databases, IEEE trans. on knowledge and data
engineering, vol. 16, no. 11, pp. 1398-1410, 2004.
[6] Y. Lu and C. L. Tan, Word Spotting in Chinese
Document Images without Layout Analysis., Interna-
tional Conference on Pattern Recognition, Quebec City,
Canada, August 11-15 2002, vol.3, pp. 57-60. 2002.
[7] Y. Lu, C. L. Tan, W. Huang and L. Fan, An Approach
to Word Image Matching Based on Weighted Hausdorff
Distance, The 6th International Conference on Docu-
ment Analysis and Recognition, Seattle, USA, pp. 921-
925, 2001.
[8] C. Papadimitriou and K. Stieglitz, Combinatorial Op-
timization: Algorithms and Complexity, Prentice Hall,
1982.
[9] Ricardo Baeza-Yates and Berthier Ribeiro-Neto, Mod-
ern information Retrieval, Addison Wesley, 1999.
[10] D. Sankoff and J. B. Kruskal, Time Warps, String Ed-
its, and Macromolecules: The Theory and Practice of
Sequence Comparison, Addison-Wesley, MA, 1983.
[11] R. S. Caprari, Duplicate Document Detection by Tem-
plate Matching, Image and Vision Computing, Vol. 18,
pp. 633-643, 2000.
[12] S. Kuo and O. F. Agazzi, Keyword Spotting in Poorly
Printed Documents using Pseudo 2D Hidden Markov
Models, IEEE trans. Pattern Analysis and Machine In-
telligence, vol. 16, No. 8, pp. 842-848, 1994.
[13] F. R. Chen, L. D. Wilcox and D. S. Bloomberg,
Word Spotting in Scanned Images using Hidden Markov
Models, Proc. of the International Conference on
Acoustics, Speech and Signal Processing, vol. 5, pp. 1-
4, 1993.
