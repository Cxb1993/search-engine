整合式感測控制網路之效能最佳化
Performance Optimization for Sensor and Actuator networks
施吉昇 Chi-Sheng Shih
中文摘要
在現代人的日常生活中,通訊和網際網路的相連性越來越重要。無論是在企業中	或
者	日常居家生活中,人們倚賴各種數位設備從個人電腦,筆記型電腦到手持式	設備,電
話,數位式儲存設備和遊戲機等來完成各種不同的活動。這些設備可以	很自然地在家
庭中或者辦公室的網狀網路(Mesh	Network)上形成一個整合式感	測控制網路(Integrated
Sensor	Actuator	Network)。	這項研究的目的是探索	在整合式感測控制網路中即時系統
資源管理的相關問題,尤其,本研究將以數位	家庭網路中的點對點網狀網路為研究標地,
進行相關的研究與效能測試。
在數位家庭網路中,家庭網路閘道負責連結所有數位設備。一個家庭網路閘道在	數
位	家庭網路中扮演兩個重要的角色:(1)	將數位設備之間彼此連結起來和	(	2	)	把數位
設備和其他網路和伺服器連接起來。大多數市場研究報告預估在未	來數年家庭網路
閘道將有相當大的需求,出貨量和營收也將大幅增加。例如, In-Stat/MDR 的報告預估,
在	2005	年所有在數位家庭網路中的網路連結設備	的總產值將增長到超過	110	億美元,
其中	39	億美元屬於閘道類型設備。雖然	數位化設備在家庭環境中的銷售量保持不斷
的成長,但是,一個影響這些設備銷	售的重要因素是這些設備是否可以提供一個穩定的
使用效能或者是可預測的效	能。其中最重要的便是網路通訊性能。目前在市場上已
有類似的產品,例如:Slim	Devices	的	Squeezebox,Icube	的	Play@TV NMP-4000,Prismiq	的
MediaPlayer	和	Creative	的	Sound	Blaster	Wireless	Music	Adapter。這些產品可以作為個
人電腦與影音設備之間的閘道	或連結的橋樑。但是,這些產品都無法提供使用者滿意的
性能。
在這個研究中,我們從閘道的觀點研究相關的問題。典型網路設備,例如網路	路由器
及閘道,其主要功能為提供高平均資料流量並且盡量減少系統使用時,因	為提升效能所
需所需消耗的(時間以及硬體)成本。	不過,在數位家庭網路中的	點對點網狀網路閘道有
不同的效能要求,除了資料傳輸外,還必需提供多媒體影	音串流資料的傳輸,數位家電的
控制訊號以及家庭環境中感測器資料與控制器訊	號的傳輸,這些不同的通訊模式都有不
同的資料特性以及效能要求。在數位家庭	網路內,網路節點的數量是有限的,但是它必
需對家庭中的各種不同數位設備提	供服務,例如:環境感測器,家電用品,個人電腦類的數
位設備,數位影音設備等。	為了在異質性網狀網路上提供可預測的性能,我們將研究目
標分三年規劃不同的	目標。在第一年,我們探討感測器和控制器在數位家庭網狀網路
裡的同步問題以	及感測器和控制器中的通訊流量模型。在第	2	年,我們繼續探討多媒
體閘道的	研究並且開始研究可在數位家庭網狀網路中控制數位家電設備的家庭控制閘
道。	在最後一年,我們探討如何實作數位家庭網狀網路中的家庭控制閘道。
1
Contents
1 Overview 5
2 Clock	Free	Data	Streams	Alignment	for	Sensor	Networks 6
2.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.2 Formal	Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.3 Clock	Free	Data	Streams	Alignment . . . . . . . . . . . . . . . . . . . . . . . . . . 9
2.4 Constant	Interval	Synchronization	Signals . . . . . . . . . . . . . . . . . . . . . . . 11
2.4.1 Period	Assignment	for	Known	Maximum	Transmission	Delay . . . . . . 11
2.4.2 Period	Assignment	for	Known	Maximum	Clock	Drift . . . . . . . . . . . . 13
2.5 Variable	Interval	Synchronization	Signals . . . . . . . . . . . . . . . . . . . . . . . 15
2.5.1 Synchronization	Signal	Schedule	Design . . . . . . . . . . . . . . . . . . . 15
2.5.2 Determining	Synchronization	Set	and	Identifier	Length . . . . . . . . . . . 16
2.5.3 Determining	Synchronization	Round . . . . . . . . . . . . . . . . . . . . . . 18
2.5.4 Data	Stream	Alignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.5.5 Error	Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3 Dynamic	Real-Time	Bandwidth	Management	over	Wireless	Network 20
3.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
3.2 Objectives	and	Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
3.3 Background	and	Formal	Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
3.3.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
3.4 Related	Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
3.4.1 Peer-to-Peer	System	for	Real-time	Media	Streaming . . . . . . . . . . . . . 22
3.5 Wireless	Transmission	for	Media	Streaming . . . . . . . . . . . . . . . . . . . . . 23
3.6 Formal	Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
3.7 Algorithms	for	Dynamic	Real-Time	Bandwidth	Management . . . . . . . . . . . . 26
3.7.1 Bandwidth	Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
3.7.2 Dynamic	Sampling	Frequency	Adjustment	Algorithm . . . . . . . . . . . 27
3.7.3 Available	Bandwidth	Estimation	Method . . . . . . . . . . . . . . . . . . . 29
3.8 Bandwidth	Allocation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.8.1 Bandwidth	Management	for	Periodic	Streaming . . . . . . . . . . . . . . . 29
3.8.2 Bandwidth	Management	for	Background	Traffic . . . . . . . . . . . . . . 30
3.9 Traffic	Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
4 P2P Scalable	Video	Streaming	based	on	Imprecise	Computation	Scheduling 30
4.1 Peer-to-Per	Streaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
4.2 Real-Time	Scheduling	for	Imprecise	Computation . . . . . . . . . . . . . . . . . . . 32
4.3 QoS-based	Resource	Allocation	Model . . . . . . . . . . . . . . . . . . . . . . . . . 33
4.4 Resource	Management	Mechanism	for	Scalable	Video	Streaming . . . . . . . . . . 33
4.4.1 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
4.4.2 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
3
1 Overview
In this project, we target the problems from the viewpoint of gateways. Typical network devices such as network routers
and switches aim at providing high average throughput and eliminating the quality of service control mechanism to
reduce the run-time overhead. However, the goal of the gateways in digital home network is different. In digital home
networks, the number of network connections is limited but it is essential for providing the quality of service for various
home applications. In the three year periods, we designed and implemented several resource management protocols
for digital home networks to provide predictable performance.
In the ﬁrst year, we focus on the workload modeling and design the clock synchronization protocols over feder-
ated sensors and actuator networks. We design a Clock Free Data Streams Alignment for Sensor Networks [1]. The
developed mechanism makes use of the built-in counters on sensors and external synchronization signals to align data
streams. The data server broadcasts out-of-channel synchronization signals with constant or variable intervals. The
sensor data streams are aligned when received on the server. Only one way communication is used so as to reduce the
communication overhead and clock synchronization overhead on sensors nodes. In addition, the developed mechanism
is scalable thanks to one way communication. The synchronization error is bounded by the maximum sampling period
of the sensors, and is independent of the number of the nodes in the network. Our analysis also shows the required
awake time for sensors to tolerate different clock drifts and signal lost.
Based on the accomplishment on the ﬁrst year, we continue to work on the resource management for multimedia
streaming in peer-to-peer home networks. In a peer-to-peer media streaming system, we need bandwidth that satisﬁes
playback rate to transmit media data from supplying peers. There are two challenges to provide high quality playback
over wireless network: (1) available bandwidth of each client is time-varying. It is difﬁcult to implement a peer-
to-peer media streaming system with QoS support if we treat the bandwidth as constant value. (2) Users might use
other network applications and network trafﬁc of these applications might affect media streaming. In this project, we
investigate two problems: (1) how to dynamically estimate available bandwidth and (2) how to dynamically manage
bandwidth according to QoS parameters. We propose a bandwidth management system to solve these problems. The
system is an underlying part of a peer-to-peer media streaming system. It provides approximate bandwidth information
and bandwidth management service to upper layer QoS management. By managing bandwidth according to available
bandwidth dynamically, a peer-to-peer system can select appropriate supplying peers dynamically to provide QoS
support. It also prevents media streaming being affected by other network trafﬁc. Thus, high quality playback can be
achieved over wireless network.
P2P network can be employed in a video streaming system to improve the system scalability with lower cost. In
the last year of the project, to achieve jitter-less video playback on the requesting peer, it requires both the requesting
policy on the requesting peer and the scheduling policy on each sending peer. Earlier works for dedicated streaming
servers, however, are not suitable for P2P streaming. In this project, we propose a resource management mechanism
for the sending peers in P2P scalable streaming. The workload model and real-time scheduling algorithm are based on
imprecise computation. The resource allocation algorithm exploits the utilization of available bandwidth by consid-
ering data dependency and maximizing the utility enhancement of optional tasks. We use test clips encoded in H.264
SVC in the experiments. The results show that our algorithm utilizes the available bandwidth and the gain in playback
quality is better than dual priority scheduling algorithm when the bandwidth is insufﬁcient to receive the whole high
quality stream.
In this subproject, we developed an integrated framework for performance optimization for sensor and actuator
networks. Speciﬁcally, we use multimedia streaming as the example application. The framework consists of clock free
synchronization protocol, resource allocation, and resource management protocol to achieve the goal.
5
In several sensor networks, some of the sensor nodes or data servers can act as intermediate nodes to aggregate
or collect the data streams and send the streams to the servers later. It is sufﬁcient that the data streams are aligned on
the intermediate nodes and is not necessary to synchronize the clock on the sensors if there are any. In this paper, we
propose to align the received sensor data in a passive manner. In our approach, the clocks on sensors if any are not
adjusted at all. After the data streams are received on intermediate nodes or data server, the data streams are aligned
and time-stamped. The data streams are aligned based on the embedded synchronization information in the streams.
For different sensor network applications, we develop different mechanisms. When the network delay is short and
energy consumption is not a critical concern, synchronization information are constantly generated. We prove that the
synchronization error is bounded by the maximum sampling period of the sensors and is independent of the number
of nodes in the network. When the network delay is long or energy consumption is one of the critical concerns,
synchronization signals are generated with variable intervals to tolerate longer propagation delay. The synchronization
error is also bounded by the length of synchronization signal.
2.2 Formal	Model
Thus far, we have used the terms used in wireless sensor network, and embedded systems literture and formally deﬁne
them below. Sensor, denoted by Oi where 1 ≤ i ≤ N and N is the number of sensors in an area of interests, is an
analogue/digital device which can monitor certain physical events such as images or sound, and transmits the sampled
events in digital form to a data server. We assume that there may be no real-time clocks but simple counters are
always available on sensors. The sensors may transmit the sampled events via RF radio or wired network such as CAN
[16], bus token-ring, and µITRON [17]. Hence, we assume that there is an upper bound for the transmission delay.
Data server is a device which receives the data streams from sensors, and analyzes the data streams to discover the
interested events. The data server may or may not have real-time clocks. When it has real-time clocks, it time-stamps
the received data; When there is no real-time clock, the data server marks the data with non-decreasing counters. For
the sake of representation, we assume that there is a real-time clock on data server. Note that our approach is still
applicable when real-time clocks are not available on data servers. A sensor group consists of at most N sensors
and one data server. The data server is referred to sensor O0 in one sensor group. A sensor network consists of a
set of sensor groups. We assume that, in this paper, data alignment is conducted for one sensor group but our approach
can be easily extended for sensor networks.
Each sensor samples at a constant time interval to record the acoustic events, visual events, or the other physical
signals. We denote the samples for sensor Oi by Si,1, Si,2, etc. The sample period for sensor Oi, denoted by spi,
is the minimal time interval between every two consecutive samples for sensor Oi. Sample time for sample Si,j ,
denoted by sti,j , is the time instant at which sensor Oi conducts the j-th sample. Because there may be no real-time
clocks on the sensors, the sample times are not available in practice. We will use the sample times as the reference to
evaluate the accurancy for clock synchronization algorithms. When the data server receives a sample Si,j , it estimates
the time instance at which the sample might occur. The time instance is called estimated sample time, denoted by
sˆti,j for sample Si,j . By determining estimated sample time for every sample, the data server maps estimated sample
times for all samples into one time domain, which could be either a real time clock or a logic clock.
After the sensor samples at one period, it may not immediately send the samples to the server. In practice, the
sensor will buffer the sample data, waits for a certain amount of time or having enough data to send, and sends to the
collected samples to the server. So, it can reduce the communication overhead and energy consumption. Buffering
time for sample Si,j , denoted by bi,j , is the time interval between sample time sti,j and the time instant at which
the sample data is sent out. Because the sample period is a constant, the difference of the buffering time for every
7
arrival time (     )
Event of intereted
st i,j
4 9 110 1 2 3 5 6 7 8 10 12
sp1,1 sp1,2 sp1,4 sp1,5 sp1,6 sp1,7
sp2,1 sp2,2 sp 2,3 sp2,4 sp2,5
sp3,1 sp 3,2 sp3,3 sp3,4
O 1
O 2
O3
1,3sp
(a) Samples over real−time clock sample time (      )
st i,j
^
3O
sp2,4
sp1,1 sp1,6sp1,2 sp1,4 sp1,5
sp3,3
sp2,1
sp 3,2
sp 2,3sp2,2
ai,j
4 9 110 1 2 3 5 6 7 8 10 12
O 1
O 2
O3
sp 1,3
sp 2,2
sp 3,2
(c) Samples after clock synchronization
estimated sample time (      )
4 9 110 1 2 3 5 6 7 8 10 12
O 1
O 2
sp3,1
1,3sp
(b) Samples before clock synchronization
Figure 1: An	Example	of	Stream	Alignment	Problem
time. Figure 1 (b) shows the sample times computed by the data server before stream alignment. In this example, the
data server may consider that there are two events in the interested area: one starts at time 3 and ends at time 7, and
the other starts at time 9 and ends at time 11. Figure 1 (c) shows the estimated sample times after stream alignment.
The estimated sample times for sample O2,i are aligned with that for sample O1,j and O3,m. Consequently, the data
sever considers that there is only one event starting at time 2 and ending at time 7. In this example, the synchronization
error is one unit of time.
In this paper, we assume that the sensor network only aligns data streams on request. This is because it is not
necessary to align the data streams when every signal is sampled. When the data server ﬁnds one interested event on
some data stream, it starts to align the data streams to conﬁrm the event. In other words, the data server starts to collect
necessary information after the request arrives. Hence, the proposed approach has low space and time complexity to
align the data streams.
2.3 Clock	Free	Data	Streams	Alignment
To align the data streams, we propose to use synchronization signals. When a sensor receives the synchronization
signals, it uses a different representation to distinguish a synchronization signal from other events. After receiving the
data streams from the sensors, the data server identiﬁes the synchronization signals in the data streams and uses the
temporal information for synchronization signals to align the data streams. By so doing, the data streams from different
sensors are aligned to one reference time-line, which is the real-time clock or logic clock on the data server, but there
is no need to adjust the clocks on sensors.
The proposed approach is closedly related to the one developed in FireFly project [15]. However, in FireFly
project, the sensors have to wake up at right time to listen to the sensors in the neighborhood, listen to the server, and
9
assign the HappenTogether relations between these two samples. Then, we begin to assign estimated sample time
for other samples. Suppose si,j is recorded in Si,k, and Sm,s for sm,nm . We set ti,p = ti,k + (p− k)× spi
and tm,q = tm,nm + (q − nm)× spm. So, we can map all samples for all sensors to a single time axis.
With above three steps, the data server ﬁnds out samples representing the same synchronization signal, and sets the
same estimated sample time for these samples having HappenTogether relation. Because the length of synchronization
signal must be longer or equal to the longest sample period in all sensors, the synchronization signal length is set as
the maximum sampling period.
2.4 Constant	Interval	Synchronization	Signals
The simplest policy is to generate the synchronization signals at a constant rate. In other words, the synchronization
server generates the signals with a constant interval. We propose two policies for generating constant interval syn-
chronization signal schedule: simple constant interval and constant interval with different signals. In the
following, we discuss how to determine the synchronization period and how to determine the temporal order of data
streams. We design two period assignment algorithms: one for the case that maximum transmission delay dt is known
in advance and the other one is for the case that the maximum clock drift dc is known in advance. In the follow-
ing, synchronization period, denoted by p, is the minimal time interval within which the synchronization signal
schedule does not repeat. In this section, the synchronization period is equal to the synchronization signal period.
2.4.1 Period	Assignment	for	Known	Maximum	Transmission	Delay
When there is an upper bound dt of all samples transmission delays and the length of one synchronization signal is l, we
set the synchronization period to dt+ l units of time (i.e., synchronization signals are generated for every dt+ l units
of time). While the period is used, we claim that the synchronization error is bounded by the length of synchronization
signals, i.e., l.
The requirements for assigning the synchronization period is that the data server shall be able to determine the
temporal order of the received data streams and assign the estimated sample time for every sample. When the maximum
transmission delay is dt, for any sample Si,m whose arrival time is ai,m, we know that the sample time must be in
the time interval (ai,m − dt − l, ai,m). The right end of the interval represents the case that the sensor samples the
end of the signal and it takes almost no time to transmit the message. The left end of the range represents the case
that the sensor samples the beginning of the synchronization signal and it takes the maximum transmission delay to
send the message. Because the synchronization period is dt + l, there is one and only one signal in time interval
(ai,m − dt − l, ai,m).
Figure 2 shows an example in which the maximum transmission delay is eight units of time and synchronization
signal length is two units of time. In the ﬁgure, the dark circle and gray circle represent the ﬁrst and second syn-
chronization signals received by the sensors. According to the known maximum transmission delay and the length
of synchronization signals, we know that the ﬁrst synchronization signal and second synchronization signal will be
received in interval (0, 10) and (10, 20), respectively. For the stream, we choose the sample Si,k which samples
the synchronization signal and whose arrival time is the maximal. Suppose the arrival time for sample Si,k is ai,k,
the time to broadcast the sampled signal must be in the range (ai,k − dt − l, ai,k). Suppose the time instance to
broadcast the signal received in the range (ai,k − dt − l, ai,k) is tb, the estimated sample time sˆti,k is set as tb.
Finally, we assign estimated sample times to other samples by adding/subtracting its sample period spi. The Clock
Free	Alignment	with	Known	Maximum	Transmission	Delay algorithm is shown in Algorithm 1.
11
Step 2 of this algorithm takes ni units of time to ﬁnd a sample whose synchronization signal is in the worst case.
Step 3 takes constant time to ﬁnd the corresponding synchronization signal. Step 5 is also in constant time. Hence, the
complexity is O(n), where n is the total input size.
We claim that at the start of each iteration of the iterative loop, we assign estimated sample times for D1, . . . ,
Di−1, and 0 ≤ sˆtj,m − stj,m ≤ l for 1 ≤ j ≤ i − 1. Before the ﬁrst iteration of the loop, there is no
streams in D1, . . . , Di−1. Hence, the loop invariant holds. If the loop invariant holds after the i-th iteration, in the
i+ 1-th iteration we will assign estimated sample time for Di+1. Because we assign the time instance at the start of
synchronization signal to the estimated sample time, the estimated sample time is no later than the sample time, and
difference is bounded by l. The loop invariant holds after the i+1-th iteration. After all iteration, for any two sample
Si,m and Sj,n, |(sti,m − sˆti,m) − (stj,n − sˆtj,n)| ≤ |sti,m − sˆti,m| − |stj,n − sˆtj,n| ≤ l. In other word,
the synchronization error is bounded by l.
We claim that by the algorithm, the synchronization error is at most l units of time. The main idea is that in the
above procedure, we assign the estimated sample time to a stream by shifting the sample time of the stream. The
displacement of each stream is in the range from 0 to−l. Hence, the synchronization error is at most l. The proof for
the claim follows.
Theorem	1 Given a set of data stream, the maximum transmission delay, length of synchronization
signal, Clock	Free	Alignment	with	Known	Maximum	Transmission	Delay algorithm assigns the
estimated sample time for each sample in the data streams such that the synchronization error is
bounded by l.
Proof: Due to the space limit, the proof can be founded at [18].
For the remainder of this paper, the analysis of synchronization error is similar to the above. Hence, we will only
discuss how to assign the estimated sample times and will not repeat the proof.
2.4.2 Period	Assignment	for	Known	Maximum	Clock	Drift
In this subsection, we are concerned with the case that the maximum clock drift dc is known. As a reminder, the
maximum clock drift dc is the maximum difference between any two transmission delays. In other words, | di,m −
dj,n |< dc for all i, j, m, n. When the maximum clock drift is dc, the synchronization period is set as 2(dc + l).
We claim that the synchronization error is also bounded by the length of synchronization signal, i.e., l.
Before we present the algorithm to align the data streams, we deﬁne a sequence of interval Ti ≡ ((2i−1)(dc−
l), (2i+1)(dc− l)) for the algorithm. We claim that for two samples of which the arrival time is ai,m and aj,n, if
aj,n − ai,m is in Ti, and Si,m samples the p-th signal, it implies that the Sj,n samples the p+ i-th signal.
Corollary	2.2 Given two samples Si,m and Sj,n of which the arrival time is ai,m and aj,n, aj,n− ai,m
is in Ti, and Si,m samples the p-th signal, Sj,n samples the p+ i-th signal.
Proof: Due to the space limit, the proof can be founded at [18].
Clock	Free	Alignment	with	Maximum	Clock	Drift algorithm determines the estimate sample times for
the stream and is listed in Algorithm 2.
Step 8 in this algorithm is also in constant time. The other steps are the same as the steps in Algorithm 1. Hence,
the total time complexity is also O(n1 + ...+ nN). The time complexity is O(n).
13
2.5 Variable	Interval	Synchronization	Signals
The constant interval synchronization signal approach allows the system to align data streams without real-time clocks.
This approach is suitable for the system in which the transmission delay and clock drift are short. When the delay and
drift are long, the constant interval synchronization approach become not practical thanks to its long least awake time.
To shorten the least awake time, we develop the approach in which the time intervals between consecutive signals are
not constant. The rationale of this scheme is to determine the temporal order of the sensor data streams by comparing
the sequence of signal intervals in streams to the complete sequence. By so doing, each sensor only needs to be awake
for a short time interval but the system can tolerate the same amount of clock drifts.
For sake of presentation, we assume that the length of synchronization signal is zero in this section. (Our approach
is still applicable when the length of synchronization signal is not zero.) Figure 4 illustrates the rationale for variable
synchronization intervals. Suppose that the complete sequence of signal interval is < 1, 1, 2, 2, 3, 3, 2, 1, 3 > and
Synchronization Sequence by
1
O2 =<    ...       3  2>
=<...  2  2  3>
 1  1  2  2  3  3  2  1  3Complete Synchronization Sequence
Synchronization Sequence by O
Figure 4: An	Example	for	Variable	Interval	Synchronization	Signals
two buffered data streams for sensorO1 andO2 are< . . . , 2, 3 > and< . . . , 3, 2 >. The synchronization period
is 18, which is the sum of the intervals in the schedule. When the maximum clock drifts for the two sensors are less than
half of the synchronization period, which is 9 in this example, we know that the last signal received by sensor O2 is
two signals late than that by sensorO1. The reason is that both subsequences< 2, 3 > and< 3, 2 > appear exactly
once in the complete sequence. Subsequence < 2, 3 > represents the fourth to the sixth signals and subsequence
< 3, 2 > represents the sixth to the eighth signal in the complete sequence. In this example, each sensor only needs to
be awake 8 unit of time which is equal to the three greatest synchronization intervals to sample three synchronization
signals. However, when constant intervals are used, the least awake time is 18 units of time.
2.5.1 Synchronization	Signal	Schedule	Design
Before we present how to generate the sequence of synchronization signals with variable intervals, we deﬁne the terms
which we will use in this section. Synchronization interval set, denoted by S = {s1, s2, . . . , sk} where k is
the number of different synchronization intervals in the set, is the set of synchronization intervals. We assume that the
synchronization intervals are indexed in the ascending order. In other words, si < sj for 1 ≤ i < j ≤ k. On the
other hand, n-synchronization interval set, denoted by S
n
= {1, 2, . . . , n}, is the set of positive intergers which
are no greater than n. Synchronization identiﬁer or identiﬁer for short is a sequence of synchronization intervals,
each of which is in the synchronization interval set S. The number of intervals in a synchronization identiﬁer is denoted
byLs. Synchronization round is a sequence of synchronization intervals, in which every synchronization identiﬁer
is unique. The synchronization period p for the synchronization round is the sum of the synchronization intervals in
the round. Synchronization counter for a synchronization identiﬁer is the number of counters relative to the start
of the synchronization round where the identiﬁer appears. Its value is the sum of synchronization intervals before the
identiﬁer in the round.
We use the example shown in Figure 4 to illustrate the terms. In this example, synchronization interval set S is
S = {1, 2, 3} and its synchronization identiﬁer length Ls is 2. The synchronization round is the synchronization
15
According to the deﬁnitions, the following theorem states that a synchronization set which has minimal least awake
time is the union of a n-synchronization set and another integer which is greater than n.
Theorem	2 Given an identiﬁer length Ls and synchronization period p, synchronization set S = Sa∪
{b} is the synchronization interval set which minimizes the least awake time when the two integers
a and b satisfy (1) 1 ≤ a < b, (2) b is the minimum integer such that Sb meets the synchronization
period constraint for p, and (3) given b, a is the minimum integer such that Sa ∪ {b} meets the
synchronization period constraint for p.
Proof: Due to the space limit, the proof can be founded at [18].
Synchronization	Set	and	Synchronization	Identifier	DeterminationAlgorithm shown in Algorithm 3
determines the synchronization set and identiﬁer length. The algorithm has an iterative loop. It starts with the identiﬁer
Algorithm	3 Synchronization	Set	and	Synchronization	Identifier	Determination	Algorithm
Input: The	maximum	clock	drift dc
Output: Synchronization	set	S and	synchronization	identifier	length Ls
1: Let Ls ← 1, and D ←∞.
2: Find L′s which	is	the	minimal	integer	satisfying 2Ls × 3 ≥ 2dc + 1
3: repeat
4: Find S = Sa∪{b} defined	in	Theorem	2 which	meets	the	synchronization	period	constraint
for 2dc + 1.
5: if Ls × b+ a < D then
6: S∗ ← S
7: L∗s ← Ls
8: D ← Ls × b+ a
9: end if
10: Ls ← Ls + 1
11: until Ls × 2 + 1 ≥ D or Ls > L′s
12: output L∗s and S∗
lengthLs = 1. In every iteration, it ﬁnds a set S of which the least awake time is optimal for a givenLs, and increases
the identiﬁer length by 1. If the least awake time is less than optimal result D, it replaces the optimal set S∗ by current
set S. The algorithm terminates when there is not any solution of which the least awake time is less than D.
At the beginning of the k-th iteration in Step 3-11, we ﬁnd a constant L∗s and a S
∗
where 1 ≤ Ls < k to
minimize the least awake time. After the last iteration of the loop, one of the following two conditions must be hold.
The ﬁrst condition is that Ls with {1, 2} can not obtain a better least awake time than D. The other condition is that
Ls > L
′
s. The reason is thatL
′
s is the minimalLs satisfying the synchronization period with {1, 2}. Hence, for any
Ls > L
′
s, it is impossible to ﬁnd a set S such that the least awake time of Ls with S is smaller than L
′
s with {1, 2}.
That implies the L∗s and S
∗
are the optimal solution.
Step 2 computes the minimal synchronization lengthL∗s in constant time: L
∗
s = ⌈lg((2d+1)/3)⌉. The goal of
Step 3 is solving the equation nLs−1(1+n)n/2 = 2d+1. The solution is between the solution of nLs−1n2/2 =
2d + 1 and that of nLs−1n2 = 2d + 1. In other words, Ls is an integer in [
Ls+1
√
4d+ 2, Ls+1
√
2d+ 1].
We can use binary search in the interval to ﬁnd the solution. Suppose d ≥ 3. Then, the time spent by Step 3 is
17
2.5.4 Data	Stream	Alignment
When the data server receives the request to align the data streams, it starts to buffer the data streams. For each stream,
the data server needs to buffer the data streams in which there are Ls + 1 signals, i.e., at least one synchronization
identiﬁer. With the identiﬁer, the data server computes the synchronization counter for each stream and apply Clock
Free	Alignment	with	Known	Maximum	Clock	Drift shown in Algorithm 2 to determine the temporal order
of n data streams.
The following is one example. Suppose there are three data streams: S1, S2, and S3 and the maximum clock drift
dc is 9. The synchronization set S is {1, 2, 3} and the synchronization round is < 1, 1, 2, 2, 3, 3, 2, 1, 3 >. The
received synchronization streams are: S1 =< · · · 3, 2, 1 >, S2 =< · · · 3, 1, 1 >, and S3 =< · · · 2, 1, 3 >.
The data server ﬁrst computes the synchronization intervals for the last synchronization signal. For each data stream, the
data server searches the location of the ﬁrst two intervals in synchronization round. The ﬁrst two intervals in Stream S1
is< 3, 2 >, which indicates the ﬁrst signal sampled SensorO1 is the fourth signal from the end of the synchronization
round. Hence, its synchronization counter is 9. Similarly, the synchronization counter for Stream S2 and S3 is 15 and
12. Figure 6(a) illustrates the location of the last synchronization signal in the stream. In the stream, synchronization
counter 0 represents the start of one synchronization round. Suppose the arrival time of the ﬁrst sample of S1, S2, and
S3 are the same. Because the maximum clock drift is 9, we can determine the temporal order of the data streams is S1,
S3, and S2 as shown in Figure 6(b). This example shows that to align the data streams in which the maximum clock
=<...    12 14 15>
1
S2
S3
(b)(a)
S1
S2
S3
=<...  9 12 14>
=<... 12 14 15>
=<...  9 12 14>
=<... 15  0  1> =<...          15  0  1>
S
Figure 6: An	example	for	data	stream	alignment
drift is 9, the sensor only needs to be awake for 8 units of time in the worst case. However, when a constant interval is
used, the sensor needs to be awake for 18 units of time in the worst case.
2.5.5 Error	Detection
In sensor networks, the sensor may miss synchronization signals because of the noise or interference. A good scheme
should allow the data server to detect the lost signals. However, the synchronization round generated by Synchro-
nization	Set	and	Synchronization	Identifier	DeterminationAlgorithm may be difﬁcult to detect lost signals.
The following is one example. Suppose that < 1, 1, 2, 2, 3, 3, 2, 1, 3 > is the synchronization round. The
data server receives < 2, 1 > from Sensor O1 and < 3, 3 > from Sensor O2. However, it could be wrong. When
SensorO1 misses second signal in the identiﬁer, it also transmits< 3, 3 > to the data server. In other words, when the
sensors may miss synchronization signals, the synchronization round generated by Euler circuit may lead to wrong data
stream alignment. When the sensors in the network miss at most one signal in a row, the sum of any two consecutive
synchronization intervals must be not equal to any of the interval. In the above example, the sum of two consecutive
intervals, i.e., 1 and 2, is equal to another interval, i.e., 3, and, hence, the data server cannot detect the lost signals in
the synchronization round.
When there are no L successive signals lost, we can replace interval si for 1 < i ≤ k in synchronization set S
by L× si−1 + 1 for i > 1. For instance, when there are no two successive signals lost, we can replace interval si
for 1 < i ≤ k in synchronization set S by 2× si−1+1. As a result, the synchronization set is< 1, 3, 7 > and the
synchronization round is< 1, 1, 3, 3, 7, 7, 3, 1, 7 >. When SensorO1 misses the third signal in the identiﬁer, it will
19
capacity of the system would not increase but reduce due to packet congestion. In a practical case, there is not only
network trafﬁc of streaming data that consuming bandwidth. People could use any network applications such as FTP
and browser, and these applications may exhaust network bandwidth so that real-time streaming would be affected
signiﬁcantly. Many people have experience like this: somebody downloads ﬁle with high transmission rate and other
people feel the network is very slow. We cannot forbid people from using other network applications. So that we
have to ﬁnd a mechanism to control network trafﬁc. From above issues, we can see that bandwidth management is an
important technology to for real-time media streaming.
Current P2P systems suffers these issues. To provide a high quality real-time P2P multimedia streaming system
with QoS support over wireless network, we propose a dynamic real-time bandwidth management system that can
deal with the two issues. The system is an underlying part of a P2P system. To solve the ﬁrst issue, it estimates
available bandwidth of each client dynamically and provides bandwidth information to upper layer QoS mechanism.
To solve the second issue, It provides services of bandwidth allocation service and trafﬁc control to upper layer resource
management.
3.2 Objectives	and	Contributions
Although the research of adaptive video streaming over wireless network has increased in recent years and many P2P
applications have been developed in last decade, they did not focus on dynamic bandwidth management. We present a
bandwidth management system that can assist P2P streaming providing QoS support over wireless network. The system
has three purposes: (a) to estimate available bandwidth of each client dynamically, so we can use these information
to provide more accurate resource management; (b) to provide bandwidth management for P2P video streaming over
wired/wireless mixed network; (c) to be compatible with existing network and transmission protocol (TCP, UDP...etc).
There are two issues that need to be solved to achieve our purposes; the primary research issues to be addressed in this
work are as follows:
Bandwidth	Measurement The available bandwidth of a wireless link is time-varying because the network conditions
such as signal quality, network trafﬁc and transmission power change over time. Therefore, we have to measure the
available bandwidth dynamically. The network conditions are different for each client and available bandwidth of each
client should be measured individually. Even in one device, the upstream bandwidth and downstream bandwidth might
not be equal and we should measured them separately. We designed a bandwidth estimating mechanism that measures
bandwidth by sending probing packet and measuring packet round-trip time between BS and wireless devices. It would
be costly when too many clients connect to the BS. In our approach, we trades the unnecessary accurate of the available
bandwidth off for less overhead. We propose a dynamic sampling frequency adjustment algorithm to achieve this goal.
The measured bandwidth is always ﬂuctuating and it is not suitable to be used by bandwidth management directly. We
estimate available bandwidth by averaging measured bandwidth. We use the estimated bandwidth to execute bandwidth
management and we provide it to high-level QoS management.
Traffic	Control To ensure that clients would not overuse the bandwidth, trafﬁc control is necessary mechanism of our
solution. We classify network trafﬁc into two types: periodic streaming for data of real-time streaming and background
trafﬁc for data of other applications. Periodic streaming is sent by our streaming application so we can control the
sending rate. Background trafﬁc is sent by other applications and we have no way to control it at application layer. In
our approach, we ﬁlter background trafﬁc on link layer of OS and drop packets that affecting real-time streaming.
21
multisender selection method, the inference of approximate network topology and an aggregation-based P2P streaming
mechanism. PROMISE is a peer-to-peer media streaming system based on CollectCast. It inherits the features of
CollectCast. The system determines the end-to-end available bandwidth by measuring end-to-end delay. It is a costly
procedure and not suitable to time-varying wireless network.
Bandwidth for clients is an important factor that affects system capacity and QoS management policy in a P2P
streaming system. In this work, we do not study the problems of lookup service, data replication management that are
investigated by a number of studies. Instead, to provide sufﬁcient QoS support and maintain streaming stability over
wireless network, we focus on dynamic bandwidth estimation and dynamic bandwidth allocation.
3.5 Wireless	Transmission	for	Media	Streaming
There are a number of differences between wired and wireless networks. In wired networks, the maximum bandwidth is
almost constant and most packet loss is caused by congestion. In wireless network, the maximum bandwidth bandwidth
is much lower and signal is not stable. Clients can temporarily disconnect and packet loss could happen due to bad
signal. These reasons cause high bit-error rates and unstable bandwidth in wireless network. In addition, wireless
devices can be moved at anytime and this also makes signal unstable. Because of high bit-error rates, some protocols
such as TCP cause a signiﬁcant performance degradation over wireless network. They cannot differentiate wireless loss
from congestion loss, thus many solutions were proposed to solve the problem. Snoop [26] improves performance of
TCP transmission between wired and wireless client. It caches packets from wired device and performs retransmission
to wireless device to prevent unnecessary congestion control mechanism. On the other hand, Snoop also generates
negative ACK to wireless devices to help retransmit packet quickly. It implements major functions at base station
and modiﬁes less at wireless device to improve TCP performance without changing wired client and applications.
TCP Westwood [27] provides another method to improve TCP performance over wireless network. It measures the
transmission rate of TCP source by monitoring the rate of returning ACK to performs fast recovery. The modiﬁcation of
TCP congestion control algorithm is implemented at sender-side. These solutions focus on improving TCP performance
over wireless network. However, media streaming is delay-sensitive and TCP is not a suitable protocol for it. The
bandwidth estimation protocols in our solution is based on UDP. The client program an application-level program and
compatible with existing network. It needs to be installed at each client.
3.6 Formal	Model
In this section, we deﬁne the terms which we will use in this work:
Network	Systems	and	Devices
• Base station (BS) is an access point that wireless clients connect to and it is the edge device of the network.
We assume that BSs can connect to each other through a wired internal network. A BS provides services of
bandwidth estimation, bandwidth allocation and trafﬁc control. Furthermore, It communicates with all clients
to estimate upstream and downstream bandwidth dynamically.
• Client Device is a wireless device that connects to a BS. Supplying peers are clients that can supply media
sources and requesting peers are clients that want to download and play a media stream. We assume that a
media stream can be offered by more than one supplying peers.
23
• Estimated bandwidth, denoted by bˆk, is the bandwidth that derived from measured bandwidth at time
t = tk.
• Playback rate of ith requesting peer, denoted by ri, is the amount of data that is needed to satisfy real-time
playback per second.
• Probing packet size, denoted by S, is the constant size of a probing packet that is used for bandwidth
measurement.
• Sampling frequency, denoted by fk, is the frequency which used by BS for measuring bandwidth of a client
at time t = tk. When fk is high, estimated bandwidth would be more accurate but also causes higher overhead.
• Bandwidth estimation overhead, denoted by ok, is the averaged bandwidth that consumed by bandwidth
estimation procedure per second at time t = tk. It can be simply derived by fk × S.
• Periodic streaming is a network connection that transmits media data at a constant bit rate.
• Background trafﬁc is network connections that used by other network applications to transmits application
data.
The wireless hardware of BS is different from clients so that they have different quality of signal. Hence, we
assume that downstream bandwidth might not equal to upstream bandwidth for each client. They should be estimated
separately.
Problem	Definitions We try to solve following problems in our bandwidth management system:
Definition	3.1	(Sampling	Frequency	Adjustment	Problem) The problem is to ﬁnd a mechanism to adjust
bandwidth estimating frequency fk dynamically of each client so that the bandwidth estimation
overhead ok is bounded but still maintain estimated bandwidth accurate enough.
Definition	3.2	(Bandwidth	Utilization	Problem) Clients share the bottleneck link, but estimated band-
width for each client might not be equal due to different network conditions. The problem is to
ﬁnd a bandwidth management mechanism that dynamically maintains the stability of transmission
rate for periodic streaming, and utilize time-varying free bandwidth to transmit background trafﬁc.
The ﬁrst problem is important because we have to consume some bandwidth to measure the packet round-trip time.
If the bandwidth estimation overhead is too high, we would not have enough bandwidth for periodic streaming when
too many clients exist. The second problem considers coexistence of periodic streaming and background trafﬁc. It is
important in most practical cases. The mechanism for second problem works according to estimated bandwidth and it
should also consider the bandwidth estimation error.
25
by the same way. Besides the queuing delay, there are some other events can affect measured result including collision
avoidance control and RTS-CTS handshaking. These events only happen when the wireless network card initiating a
transmission, thus we observed that the measured bandwidth is more accuracy when the probing packet size is larger.
3.7.2 Dynamic	Sampling	Frequency	Adjustment	Algorithm
First, we deﬁne terms that will be used in the algorithm:
• L : Link capacity of the network.
• tk : The kth time point, t0 = 0 and tk = tk−1 + 1fk−1 , where k = 0, 1, 2....
• fk : Sampling frequency at time t = tk.
• bk : Measured bandwidth at time t = tk.
• vk : Bandwidth variation from time tk−1 to tk, vk = |bk−bk−1|L .
• Fmax : The upper bound of sampling frequency. fk cannot be higher than Fmax
• Fmin : The lower bound of sampling frequency. fk cannot be lower than Fmin
• V : Variation threshold. It is a given parameter that is used for testing frequency adjustment condition, where
0 < V < 1.
• α : Frequency adjustment factor. It is a given parameter that is used to controls the frequency increasing/
decreasing speed, where α > 1.
• C : Frequency decreasing counter. It is a given parameter that is used for testing frequency decreasing condi-
tion, where C > 1.
We know the available bandwidth bk for each client is time-varying and we have to measure it periodically. When
signal quality becomes less stable, we have to increase fk to maintain the accuracy of estimated bandwidth; when signal
quality becomes more stable, we should decrease the frequency to reduce estimation overhead. Thus we propose the
Dynamic	Sampling	Frequency	Adjustment	Algorithm 4. We use vk to test stability of bandwidth. The
goal of this algorithm is to ﬁnd a minimal frequency that keeps vk less than V . When we start to estimate bandwidth,
we measure bk and vk every
1
fk
second. We execute the algorithm every time that we get bk and vk.
In this algorithm, we can see that the estimation overhead upper bound is S×Fmax and the estimation overhead
lower bound is S × Fmin. The estimation overhead is affected by algorithm parameters. Parameter V controls
frequency increasing condition. Higher V value makes frequency more difﬁcult to increase. It reduces estimation
overhead but causes higher estimation error. Parameter C controls frequency decreasing condition. Lower C makes
frequency easier to decrease. It also reduces estimation overhead but causes higher error. Furthermore, the overhead
reducing behavior of C is different from V . We can see the detailed difference at next chapter. The last parameter
α controls frequency adjustment speed. It controls both frequency increasing speed and frequency decreasing speed.
Therefore, it does not have obvious relationship between overhead and error.
27
 0
 0.5
 1
 1.5
 2
 2.5
 3
 3.5
 4
 0  20  40  60  80  100
M
B/
s
Time(sec)
Measured Bandwidth
Figure 10: Measured	bandwidth	with	network	traffic	of	500KB/s
3.7.3 Available	Bandwidth	Estimation	Method
In above sections, we know how to get measured bandwidth bk. But bk is always ﬂuctuating even if the signal quality
is good. Excepts the effect of signal quality, many other reasons affect bk signiﬁcantly. For example, network trafﬁc
is the most serious one. Before a network card sending a packet, it must wait until nobody is using the network.
Another example is the transmission power control function of network cards. They adjust transmission power and
speed according to battery state-of-charge and network usage. From ﬁgure 9 and 10, we can see that bk is not suitable
to be used directly for bandwidth allocation.
To provide bandwidth information that is suitable for bandwidth management, we employ a method which that is
introduced in TCP Westwood[26] to derive estimated bandwidth from measured bandwidth. It is a low-pass ﬁlter to
average sampled bandwidth:
bˆk =
2τ
tk − tk−1−1
2τ
tk − tk−1 +1
bˆk−1 +
bk + bk−1
2τ
tk − tk−1 +1
Where
1
τ
is the cut-off frequency of the ﬁlter. bˆk is ﬁltered bandwidth at the time t = tk that is derive from history
data and last two samples of measured bandwidth. We use bˆk as estimated bandwidth for bandwidth management.
3.8 Bandwidth	Allocation
3.8.1 Bandwidth	Management	for	Periodic	Streaming
Wireless clients that connected to the BS could have different signal quality and hardware capacity. They transmit and
receive data at different speed. These clients share the bottleneck link and any trafﬁc over the link will affect estimated
bandwidth of all clients. To manage bandwidth resource, each client must allocates bandwidth from the BS for periodic
streaming. A client allocates and uses bandwidth at a constant rate to play media streaming of CBR format. Due to
29
With the success of Skype in VoIP service, P2P networks are becoming increasingly popular as a communication
alternative to client-server architecture for web applications. Clients participating in the same video streaming session
can be logically viewed as a P2P network. It has been shown that the bandwidth cost of streaming servers can be
signiﬁcantly reduced if the P2P network is used to assist video streaming [32]. P2P network has been widely investigated
in content distribution networks for ﬁle sharing applications such as Gnutella and BitTorrent. For ﬁle replication using
P2P network, the performance relies on the strategies to decide which piece to download and which peer to download
from. BitTorrent uses rarest ﬁrst and choke algorithm for piece and peer selection [33]. It has also been shown in
[33] that rarest ﬁrst algorithm guarantees a close to ideal entropy on the piece distribution among all peers, and choke
algorithm fosters reciprocation and is robust to free riders.
Streaming over a P2P network, however, is a challenging issue due to the timing constraints posed in video play-
back. Consider the case that in a P2P network there exists several peers with different upload bandwidths, and a peer
is requesting different parts of a scalable video stream from other peers available for providing the stream. The re-
questing peer may make a requesting policy according to the upload bandwidth of each sending peer to improve the
download efﬁciency. Even though the requesting policy works well in downloading a ﬁle, the requesting peer may still
suffer from jitters in video playback. For example, suppose some consecutive frames are requesting from a sending
peer with an upload bandwidth lower than the video bit rate, which is a typical case in common P2P network. If the
peer sequetially sends the requested parts, like in ﬁle sharing, then the playback jitters occur because the video content
cannot be received in time. Buffering techniques, such as prefetching, can be employed to work around, but this is not
a silver bullet as long as the available resource ﬂuctuates and is hard to predict. As a result, to achieve good playback
quality on the requesting peer in the presense of insufﬁcient resource, an algorithm for real-time resource management
is required for all sending peers.
Recently, many approaches and techniques on P2P video streaming have been proposed. Receiver-driven mecha-
nism is adopted in previous approaches more than sender-driven mechanisms because in P2P networks the number of
senders and available bandwidth of each sender are difﬁcult to know as a priori. Thus the coordination of sending peers
results in less overhead in a receiver-driven mechanism than in a sender-driven one. In receiver-driven streaming sys-
tems, especially from multiple senders, the system design focuses on the adaptive packet assignment on the requesting
peer, i.e., the policy to decide a packet-to-sender mapping according to the available bandwidth of each sender [34].
Therefore, both the requesting policy on the requesting peer and the sending policy on a sending peer are important to
guarantee the playback quality. However, few studies the resource management problem on the sending peers working
together to provide scalable streaming for a requesting peer. A rate-distortion optimized scheduling algorithm called
EDBS [35] has been proposed for streaming scalable media from a server. This approach estimates the importance of
each packet in the transmission buffer by calculating the expected runtime distortion using the retransmission times
and loss probability of all packets. Although EDBS is shown to be applicable for real-time streaming from a single
server [35], it is not designed to be used in a distributed environment. If EDBS is adopted in a P2P streaming system
for each sending peer to decide its sending schedule, we think the synchronization overhead among sending peers due
to packet dependency will probably lead to low utilization of the aggregated bandwidths of sending peers.
We propose a distributed resource management mechanism for P2P streaming network. Our goal is to maximize
the playback quality metric by allocating available resource to the packet transmission tasks of different layers on each
sending peer in a real-time fashion. For sending peers, a task model and scheduling algorithm based on imprecise
computation is presented for scalable streaming, and a resource allocation algorithm based on the algorithm proposed
in Q-RAM [36] is developed to utilize the available bandwidth. The scheduling algorithm is similar to EDF, except that
there may be some tasks discarded by the resource allocation algorithm before they are executed. The resource alloca-
31
real-time tasks for servicing soft tasks. There are three priority levels used in this approach, upper, middle, and lower.
An upper band priority is higher than any priority in the middle or lower band. Upon release, a hard real-time task is
assigned a lower band priority, while a soft real-time task executes with a middle band priority. However, to guarantee
the timing constraints of a hard real-time task, the priority of a hard real-time task is promoted to the upper band at
a pre-determined time offset from release. DPS provides better performance than the Extended Priority Exchange
algorithm [41] in the simulation results. Compared to the dynamic Slack Stealing approach [42], DPS reqires less
computational cost and is easier to implement.
4.3 QoS-based	Resource	Allocation	Model
In a real-time system based on imprecise computation techniques, an application provides an acceptable quality of
service as long as it is assigned certain processor time required to complete all the important tasks in time. Besides,
the performance can be enhanced by assigning additional processor time to the task. However, the available resource
in the system may not be sufﬁcient to saﬁsfy the demands of all tasks simultaneously. QoS-based Resource Allocation
Model (Q-RAM) [36][43] is designed for QoS management along multiple dimensions such as timeliness, security,
and data quality. The purpose of Q-RAM is to help make resource allocations to individual tasks in multiple concurrent
applications such that the system utility is maximized. They have shown that ﬁnding the optimal resource allocation
along multiple QoS dimensions is a NP-hard problem. The polynomial algorithm presented in Q-RAM takes advantage
of the marginal utility of each task to allocate resource. According to computational geometry, ﬁnding a solution within
a provably ﬁxed and very short distance from the optimal allocation is allowed using their algorithm. In [43], they also
study and solve the problem of apportioning multiple resources to satisfy a single QoS dimension.
4.4 Resource	Management	Mechanism	for	Scalable	Video	Streaming
To stream scalable video over peer-to-peer network with good quality, we focus on the resource management mecha-
nism adopted on sending peers. By good quality streaming, we mean the video can be viewed with minimized distortion
and jitter. For a sending peer, we address the problem that how to decide a transmission order of the requested packets
adapting to the available bandwidth. In other words, when the available bandwidth is not sufﬁcient to satisfy the timing
constraints of all requests, we want to design a scheduler to exploit the bandwidth.
4.4.1 Assumptions
We make several assumptions for the system architecture and workload:
• The video streams are encoded with H.264 SVC encoder in the JSVM reference software [44]. Each stream is
composed of a base layer substream and an enhancement layer substream.
• The enhancement layer substream is scalable and can be partitioned into a ﬁxed number of enhancement layers
determined by the video encoder. Each partition of the enhancement layer substream is not scalable.
• The video ﬁles are not fully duplicated on every sending peer, but at least one complete copy of the requested
video exists in the network.
• The quality gain by decoding each enhancement layer is known as a priori.
33
For the whole video stream, our target utility function to maximize is thus as follows:
U(F ) =
∑
f∈F
Uf (3)
We choose PSNR to be the quality metrics for Qi(x). For the degradation factor, we measure the decoding time
difference between fi and its last frame decoded. If no jitter occurs, the factor should be 1, which means no quality
degradation. When jitter increases, the factor should monotonically decrease. In our experiment, we use
Di(δ) =
∆i − δ
∆i
(4)
as an appropriate function for the degradation factor. In Equation 4, ∆i is the maximum tolerable jitter of fi.
Finding the optimal resource allocation to maximize playback utility can be mapped to an inexact 0-1 knapsack
problem [45]. The inexact 0-1 knapsack problem is NP-hard and is formulated as follows:
Maximize
∑n
i=1 vi
Subject to:
n∑
i=1
Ri ≤ R
where there are n objects each with size Ri and value vi, and R is the size of the knapsack. Consider the following
special case of our problem. Suppose the enhancement layer substream contains only one enhancement layer, then the
utility function of fi becomes
Ui(x) =
{
ui0 if si0 ≤ x < si0 + si1
ui1 if x ≥ si0 + si1
where the playback utility is enhanced by (ui1−ui0) if and only if the ﬁrst enhancement layer is completely decoded.
Let vi be (ui1 − ui0), and let Ri be (si0 + si1). The total available resource is R. Thus the inexact 0-1 knapsack
problem is transformed into a special case of our problem.
4.5 Algorithm	Design
Our resource management mechanism for scalable video streaming is described in this section. The design goal is to
maximize the overall playback utility deﬁned in Equation 3. Our algorithm for resource management is composed of
a Task Scheduling Algorithm and a Resource Allocation Algorithm. The Task Scheduling Algorithm determines an
order of task execution to meet the timing constraints of each task. The Resource Allocation Algorithm ﬁnds out an
appropriate allocation of the available bandwidth for optional tasks to achieve the design goal.
4.5.1 Task	Scheduling	Algorithm
Basically, we adopt Earliest Deadline First (EDF) in this algorithm for both mandatory and optional tasks. In the
environment without predictable bandwith, to prevent mandatory tasks from missing deadline due to poor link quality,
it makes sense to let mandatory taks be executed earlier than optional tasks, such as the algorithm in [46]. However,
this purpose can also be fulﬁlled by calculating the deadline more conservatively in scheduling using EDF, such as
35
the layer with the least marginal utility. However, frame fi has a higher utility than fj does not imply the utility of oik
is higher than ojk for all possible k. In addition, in our streaming system, an enhancement layer and the other layers it
depends on may come from different sending peers, so a received enhancement layer may become "valueless" simply
because its predecessor is discarded by another sending peer, no matter how much this layer contributes in playback
utility. As a result, in the absence of synchonization among sending peers, we propose a method considering both the
data dependency and the marginal utility of each enhancement layer instead of the ideal solution mentioned above.
We use a few examples to illustrate our idea. Assume fi and fj are independently decodable, and u
′
i1 < u
′
j1 <
u′i2 < u
′
j2. Consider the case li1 and lj1 are requested, but one of them must be discarded. When we want to
select a victim from li1 and lj1, i.e., the lowest enhancement layer of the two frames, the victim is simply determined
by the marginal utility of oi1 and oj1 because the ﬁrst enhancement layer only depends on the base layer, and li0
and lj0 are both guaranteed to be completed. Hence in this case li1 is killed. Now consider the case li1 and lj2 are
requested. Unfortunately, the same method cannot be applied here because we are not sure whether oj1 is guaranteed
to be completed. Even though u′j2 is larger than u
′
i1, lj2 is valueless if lj1 is discarded. Therefore, in this case lj2 is
selected as victim. In our distributed algorithm, the data dependency is considered ﬁrst so that the available resource
will not be wasted. If in the second case oj1 is also requested, then li1 would be chosen as the victim.
4.5.3 Analysis
If all enhancement layers of a frame is requested from the same sending peer, i.e., no packet dependency in a frame
exists, we prove the optimality of RAA in this section.
A feasible schedule is a schedule in which every mandatory task is completed by its deadline. An optional task
oi is more valuable than oj if the ratio of playback utility enhancement to execution time of completing oi is greater
than that of completing oj . In other words, in our algorithm the value of doing an optional task is determined by the
marginal utility of the enhancement layers it contains.
Assume di is earlier than dj and oj is terminated before completion.
Lemma	1 In a feasible schedule S, if oj is allowed to steal some execution time from oi, then the
schedule is also feasible.
Lemma	2 In a feasible schedule S, let some execution time of oi be stolen by oj and call the new
schedule S ′. S ′ is also feasible and the playback utility enhancement of S ′ is better than S if and
only if oj is more valuable than oi.
Lemma	3 In RAA, oj is truncated instead of oi if and only if oi is more valuable than oj .
Theorem	3 The schedule produced by RAA maximizes the playback utility enhancement of a feasible
schedule.
Proof: Let S be a schedule produced by RAA, and S ′ is another feasible schedule derived by letting oj steal some
execution time from oi (Lemma 1). Suppose the utility enhanced by S
′
is more than S. According to Lemma 2, oj is
more valuable than oi. However, this contradicts with our algorithm because the enhancement layers in oi should be
discarded earlier than those in oj if oj is more valuable than oi 3. Thus the utility enhanced by S
′
must be less than
S.
37
Table 3: The	results	of	each	frame	set	in	scenario	1, 1	to	1	with	2400kbps.
RAA DPS
Frame	set Throughput Utility AU Throughput Utility AU
0	-	31 337232 205.6541 0.61 337232 205.6541 0.61
31	-	62 401767 252.3773 0.64 401767 252.3773 0.64
62	-	86 225884 168.8985 0.77 225884 168.8985 0.77
86	-	96 79527 64.8188 0.83 79527 64.8188 0.83
94	-	97 23855 19.5165 0.84 23855 19.5165 0.84
97	-	125 188062 160.1635 0.87 166594 142.1749 0.87
125	-	155 292902 193.3851 0.68 315644 186.1218 0.60
155	-	183 288762 159.0059 0.56 268131 105.1706 0.40
183	-	209 231770 123.0028 0.54 231563 80.8043 0.36
209	-	237 220170 114.4354 0.53 242590 84.3340 0.36
237	-	263 229442 124.8144 0.56 213430 76.5806 0.37
263	-	275 85285 42.3027 0.51 87717 31.1262 0.36
275	-	301 186110 76.2716 0.42 164842 40.9377 0.25
301	-	329 175410 66.4832 0.39 220734 59.1395 0.27
329	-	355 170743 70.2459 0.42 186888 60.8590 0.33
355	-	381 128223 34.4083 0.27 140353 25.4552 0.19
381	-	410 151335 38.7561 0.26 160555 24.7732 0.16
410	-	436 149535 69.3511 0.47 170584 37.0011 0.22
436	-	464 256916 163.2804 0.65 238874 121.9298 0.52
464	-	490 221078 111.7733 0.52 228461 81.1709 0.36
490	-	491 6744 1.9477 0.30 6744 1.9477 0.30
491	-	519 228491 163.5287 0.73 249541 125.9073 0.52
519	-	530 96046 62.0547 0.66 93212 42.4041 0.47
530	-	556 241910 163.2701 0.69 230781 112.9709 0.50
556	-	557 14308 9.6608 0.69 6047 2.0639 0.35
557	-	568 96905 63.4891 0.67 100332 49.0931 0.50
568	-	594 233936 155.7276 0.68 220563 109.2660 0.51
594	-	595 13879 9.2608 0.68 9910 4.5420 0.47
595	-	622 225232 144.0748 0.66 234179 110.2031 0.48
622	-	649 227419 146.7320 0.66 229814 105.9443 0.47
649	-	675 239000 155.6722 0.67 237731 116.8615 0.50
675	-	702 220684 136.9867 0.64 220481 95.4306 0.44
702	-	728 220038 91.2782 0.42 225740 59.4597 0.27
728	-	755 194516 87.1494 0.46 200249 61.0278 0.31
755	-	781 221723 145.6775 0.67 221664 103.8891 0.48
781	-	808 228429 144.5718 0.65 230762 99.1383 0.44
808	-	834 225276 138.4105 0.63 224750 95.1073 0.43
834	-	861 204676 115.1825 0.58 224183 81.5173 0.37
861	-	872 115993 66.9735 0.59 99038 42.2802 0.44
872	-	898 212907 143.0785 0.69 230996 113.8864 0.50
total 7523646 4409.79 0.5861 7609004 3403.41 0.447339
Table 7: The	results	in	scenario	2, 3	to	1	with	800kbps	each, frame	410	to	436.
Utility Throughput AU
RAA 60.30 135.7KB 0.44
DPS 36.26 154.9KB 0.23
 0
 2
 4
 6
 8
 10
 12
 14
 410  415  420  425  430  435
PS
NR
frame no.
RAA
DPS
All
Figure 11: The	enhanced	PSNR by	each	scheduling	algorithm	in	scenario	2.
41
 0
 10
 20
 30
 40
 50
 410  415  420  425  430  435
PS
NR
frame no.
Expected
Resultant
Figure 13: The	difference	between	the	expected	utility	of	RAA and	the	resultant	utility.
 0
 10
 20
 30
 40
 50
 410  415  420  425  430  435
PS
NR
frame no.
Expected
Resultant
Figure 14: The	difference	between	the	expected	utility	of	DPS and	the	resultant	utility.
43
[6] D. L. Mills, ``Precision synchronization of computer network clocks,'' ACM/IEEE Transactions on Net-
working, vol. 6, no. 5, pp. 505 -- 514, 1998.
[7] C. Liao, M. Martonosi, and D. W. Clark, ``Experience with an adaptive globally-synchronizing clock algorithm,''
in ACM SPAA, June 1999, pp. 106--114.
[8] F. Cristian, ``Probabilistic clock synchronization,'' Distributed Computing, vol. 3, no. 146 -- 158, 1989.
[9] A. Ramanathan, K. G. Shin, and R. W. Butler, ``Fault-tolerant clock synchronization in distributed systems,''
IEEE Computer, pp. 33 -- 42, October 1990.
[10] H. Dai and R. Han, ``Tsync: A lightweight bidirectional time synchronization service for wireless sensor net-
works,'' in ACM SIGMOBILE Mobile Computing and Communications Review, 2004.
[11] J. Elson, L. Girod, and D. Estrin, ``Fine-grained time synchronization using reference broadcasts,,'' in Proceed-
ings of the 5th Symposium on Operating Systems Design and Implementation, December 2002,
pp. 147 -- 163, rBS.
[12] S. Ganeriwal, R. Kumar, and M. Srivastava, ``Timing-sync protocol for sensor networks,'' in Proceedings of
the 1st International Conference on Embedded Networked Sensor Systems, November 2003, pp.
138 -- 139.
[13] M. Maroti, B. Kusy, G. Simon, and A. Ledeczi, ``The ﬂooding time synchronization protocol,'' in Proceedings
of the 2nd international conference on Embedded networked sensor systems, Baltimore, MD,
USA, 2004.
[14] N. Ukita and T. Matsuyama, ``Real-time multi-target tracking by cooperative distributed active vision agents,'' in
AAMAS, Bologan, Italy, July 2002, pp. 829 -- 838.
[15] A. Rowe, R. Mangharam, and R. Rajkumar, ``RT-Link: A Time-Synchronized Link Protocol for Energy Con-
strained Multi-hop Wireless Networks,'' Department of Electrical and Computer Engineering, Carnegie Mellon
University, Tech. Rep., August 2005.
[16] P. Richardson, L. Seih, and P. Haniak, ``A real-time control network protocol for embedded systems using con-
troller area network(CAN),'' in IEEE Elestronics and Information Technology Conference, June 2001.
[17] H. Mori, Y. Mano, H. Takada, and K. Sakamura, ``µITRON bus: a real-time control lan for open network envi-
ronment,'' in Third International Workshop on Real-Time Computing Systems Application, 1996,
pp. 227--234.
[18] Guo-Liang Lee and Chi-Sheng Shih, ``Clock free data streams alignment for sensor networks,'' NEWS Lab.,
National Taiwan University, Taipei, Taiwan, Tech. Rep. Technical Report No. TR-IIS-05-008, June 2007.
[19] BitTorrent Home Page. http://www.bittorrent.com.
[20] eMule Home Page. http://www.emule-project.net.
45
[37] C. Wu and B. Li, ``rStream: resilient peer-to-peer streaming with rateless codes,'' in Proceedings of the 13th
annual ACM international conference on Multimedia, 2005.
[38] Jean-Paul Wagner, Jacob Chakareski, and Pascal Frossard, ``Streaming of scalable video from multiple servers
using rateless codes,'' in International Conference on Multimedia and Expo, 2006.
[39] J.W.S. Liu, W.-K. Shih, K.-J. Lin, R. Bettati, and J.-Y. Chung, ``Imprecise computations,'' in Proceedings of
the IEEE, vol. 82, 1994.
[40] Robert Davis and Andy Wellings, ``Dual priority scheduling,'' in Proceedings of the 16th IEEE Real-Time
Systems Symposium, 1995.
[41] B. Sprunt, J. Lehoczky, and L. Sha, ``Exploiting unused periodic time for aperiodic service using the extended
priority exchange algorithm,'' in Real-Time Systems Symposium, 1988.
[42] R. I. Davis, K. W. Tindell, and A. Burns, ``Scheduling slack time in ﬁxed priority pre-emptive systems,'' in
Proceedings Real-Time Systems Symposium, 1993, pp. 222--231.
[43] R. Rajkumar, C. Lee, J. Lehoczky, and D. Siewiorek, ``Practical solutions for QoS-based resource allocation
problems,'' in IEEE Real-Time Systems Symposium, 1998.
[44] JVT of the ISO/IEC MPEG and the ITU-T VCEG, ``JSVM reference software 9.8,'' Oct. 15, 2007.
[45] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein, Introduction to Algorithms,
2nd ed. the MIT Press, 2002.
[46] Kui Gao, Wen Gao, Simin He, and Yuan Zhang, ``Real-time scheduling based on imprecise computation for
scalable streaming media system over the internet,'' Real-Time Imaging, 2004.
47
 
This year of RTCSA follows the tradition to have parallel tracks program and two 
keynote speeches. The conference invited submissions of papers presenting a high 
quality original research and development in the following three topics: (1) Real-time 
Systems, (2) Ubiquitous Computing, and (3) Embedded Systems. In this year, the 
program committee received 146 papers, which is 45% more than last year. The 
papers come from 24 countries including Austria, Austria, China, Denmark, France, 
Germany, Hong Kong, India, Iran, Italy, Japan, Macau, Malaysia, Norway, Pakistan, 
Portugal, Korea, Singapore, Spain, Sweden, Switzerland, Taiwan, United Kingdom, 
and USA. Overall, the best 63 among 146 submissions are selected: 42 for regular 
papers (28%) and 21 for short papers (43%). In addition, the conference invited 4 key 
research papers. As a keynote speech, the conference invites Dr. Wu and Dr. Lothar 
Thiele for their prestigious speeches. 
 
In this year of RTCSA 2009, Prof. Chi-Sheng Shih with National Taiwan University, 
represent National Taiwan University to attend the conference and present parts of our 
research works. One paper is presented in the conferences: “Zero-Buffer Inter-Core 
Process Communication for Protocol for Heterogeneous Multi-core Platforms”. 
 
The summary of the paper presented by Prof. Shih is the following. 
 
With multi-core platforms, there are many means to increase system throughput. Two 
typical approaches are data parallelism and functional parallelism. Data parallelism is 
usually adapted in homogeneous multi-core platforms for data intensive applications. 
In this approach, the input data are divided into numbers of equal-sized data subset 
and the data subsets are then processed by different cores in parallel. Image rendering 
for video/image display is one typical application for this approach. Nevertheless, 
functional parallelism is usually adapted in heterogeneous multi-core platforms for 
computation intensive applications. In this approach, one application is decomposed 
into several functions which are executed in pipelined manner on different cores to 
complete the work. Video encoding/decoding is one typical application for this 
approach. 
 
In this work, we are interested in performance enhancement for pipelined executed 
applications on heterogeneous multi-core platforms. In comparison to single-core 
processor architecture, multi-core architecture greatly enhances the parallelism, 
increases system throughput, and shortens the response time. When the pipelined 
schedules are carefully designed, the major trade-off and performance bottleneck 
 
Prof. Chi-Sheng Shih served the Program Co-Chair of UCS 2009. UCS 2009 is an 
interdisciplinary field of study that includes pervasive, wireless, embedded, wearable 
and/or mobile technologies that bridge the gaps between the digital and physical 
worlds, practical applications that incorporate these technologies, infrastructures that 
effectively support them, human activities and experiences these technologies 
facilitate, and conceptual overviews that help us understand or challenge our 
understanding of the impact of these technologies. The aim of the symposium is to 
stimulate interactions between participants through them. UCS 2009 focuses on the 
emerging area of ubiquitous computing. This emergence is an outcome of the rapid 
evolution in smart appliances and devices, as well as tremendous advances in wireless 
networks and mobile computing. The symposium offers the opportunity for in-depth 
exploration of the most recent research and development findings in the field of 
ubiquitous computing. 
 
Computing devices are now popularly used by untrained users and are embedded in 
the environment to provide the best services for human and society using the sensors. 
However, most modern computing system design including hardware and software 
aims on trained users and lead to the machine-centric systems. When such systems are 
used by untrained users, many errors occur. To allow the untrained users to safely 
operate the system and to compute the work, the design for ubiquitous systems should 
be designed with users in mind. The new use scenario brings grand challenges to 
several research communities including embedded system design, computer networks, 
hardware sensor design, machine-human interactions, security, and software 
architecture.   
 
We invite researchers, practitioners, educators and students, and others interested in 
ubiquitous computing to participate in the Fifth International Symposium on 
Ubiquitous Computing Systems (UCS 2009) held in Beijing, China in August, 2009. 
We encourage contributions describing innovative work on ubiquitous computing 
systems. Areas of interest include, but not limited to: Interface Design for elderly, 
User-Centric Design Methodology, Security and Privacy for Ubiquitous Computing, 
Study on social impacts for Ubiquitous Computing, Robots, users, and intelligent 
appliance, Gaming applications for ubiquitous computing environment, Infrastructure 
for ubiquitous computing, Enabling Technologies for Ubiquitous and Pervasive 
Computing, User-centric Design Methodology for Ubiquitous Computing, 
Infrastructure for Ubiquitous Computing, Intelligent Home and Office Appliances, 
Portable Devices and Wearable Computers, Wireless Networks, Home Network and 
