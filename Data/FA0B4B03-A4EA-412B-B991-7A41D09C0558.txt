中文摘要：
本計畫(九十七年度) 「體積全像應用於體腔內部之三維動態形貌量測 II」承繼九十六年度
之國科會計畫申請案，繼續開發以繞射元件為核心，並且利用內視鏡進行動態、大深度落
差的三維形貌檢測系統。主要原理是將繞射元件產生之 diffracted sinusoidal fringe pattern 投
影在待測物體上，其條紋扭曲程度和待測物體的縱深有關，稱為「相位－縱深」關係式
(phase-to-depth relation)，找到此關係式即可進一步得到物體表面的三維座標。本計畫重點
在於設計一灰階特殊分佈之 fringe pattern，以此 pattern 作為物光，紀錄於全像元件中，再
利用雷射光源所重建出的影像，投射在體腔內部之待測物表面，其條紋扭曲程度透過內視
鏡記錄於影像擷取器中，最後再由「相位－縱深」關係式還原動態物體的三維形狀。
相較於傳統的條紋投影方式，開發本計畫的優勢在於：1. 此繞射元件的體積甚小(<500
μm3)，搭配內視鏡等小型的 image sensor 可形成一完整的微形系統，適用於生物體腔內部
之 3D 檢測；2. 相較於目前各式的形貌量測系統，包括傳統的 holographic interferometry，
此計畫的量測裝置更加輕便、簡單，而且避免了像差因素，故而降低了電腦演算及系統校
正成本；3. 由於光源的空間同調性甚佳，故投影系統有甚大的景深(depth of focus)，待測物
的縱深量測範圍亦因此增加；4. 繞射條紋以灰階編碼的方式投射在待測物表面，可進行大
深度落差的三維形貌檢測；5. 本系統採用兩套條紋投影系統，分別自內視鏡的左右兩側，
將條紋投影至待測物體上，可避免陰影所導致的信訊息短缺；6. 由於影像擷取系統只需要
擷取一次資料，因此可進行動態物體的三維形貌量測。
關鍵詞：條紋投影技術，弦波光柵，三維形貌量測系統，繞射元件，內視鏡
英文摘要：
A projected fringe profilometry using a diffraction element embedded into an endoscope for
finding the absolute shape of an object with large depth discontinuities is proposed. The
projection system is simplified by using a diffraction element to produce an area-encoded fringe
pattern instead of the typical fringe projection scheme. The proposed method offers following
major advantages: (1)) a very compact design for the measurement system, (2) very low fringe
distortion (even for a large field of view), (3) a large depth of focus in the projection system, (4)
reliable phase unwrapping to complex objects, especially for surfaces with large depth
discontinuities, (5) double projections from two different viewpoints to avoid null data sets
caused by shadows, and (6) robust performance to analyze dynamic objects.
Keywords: fringe projection, sinusoidal grating, projected fringe profilometry, diffraction
element, endoscopes
become complicated again and are still impractical in application to endoscopes.
In this paper, we investigate the use of a fringe pattern generated by launching a laser beam
into a diffraction grating. The projection system is simplified by using a diffraction element
instead of a projection lens or interference components. This makes it possible to perform 3D
shape measurements using endoscopes. The field of view of this measurement system can be
wider than 60°, depending on requirement of the working distance and measurement scale of the
tested object. The high spatial coherence from the diffraction grating allows it to generate a large
depth-of-focus projection. only one measurement frame is required to inspect surfaces. Thus, it is
feasible to perform a single-shot measurement of dynamic objects.
To distinguish the depth discontinuities, the diffraction grating forms an area-encoded fringe
pattern in which the sinusoidal fringes are encoded with binary stripes. The binary stripes play a
key role to identify the local fringe order, while the sinusoidal fringes are employed to reconstruct
the 3D shape. Even though the inspected surfaces are colorful, the proposed encoding scheme can
still identify the local fringe orders.
In addition, the measurement is performed with two projections from different viewpoints.
Consequently, lost data caused by shadows on the edge area can be retrieved by integration of the
separated measurements. Compared with our previous work, this developed technique provides a
more reliable performance to since it employs multiple fringe projections from different
viewpoints. The overall system is compact for specific detections in many severe circumstances,
especially for 3D inspections using an endoscope for dynamic surfaces with large depth
discontinuities.
2. Fabrication of the diffraction component for fringe projection
To perform fringe projection using a diffraction element, a standard holographic setup is
proposed, as shown in Fig. 1. The setup is mainly composed of (1) a laser with good temporal
coherence, (2) a divergent reference wave from a single-mode fiber, (3) a convergent object wave,
and (4) a hologram, which is used as a diffraction element. An objective lens forms the object
wave from an area-encoded pattern. The reference wave and the object wave interfere, resulting
in an intensity distribution in the hologram.
The projected fringes are encoded with binary stripes. The transmittance of this encoded pattern
is mathematically represented as
 2.0)]cos(4.04.0[)( 2  xxBxt d , (1)
where B(x) is the transmittance of binary stripes, and d is the period of sinusoidal fringes. Figure
2(a) and (b) show the distribution of binary stripes and sinusoidal fringes, respectively.
(a) (b)
Fig. 3. Sinusoidal fringes encoded with binary stripes.
The binary stripes play a main role to identify the local fringe order. Thus, this encoding
scheme is not sensitive to noises from the color.
For a coaxial system, the imaged position di is approximately given by
oi dfd
111  , (2)
where f is the focal length of objective lens, do is the distance between the fringe pattern and the
objective lens.
As shown in Fig. 4, when a reading beam from the single-mode fiber is launched into the
hologram, a diffracted area-encoded pattern is reconstructed on which the image is formed, at
distance di away from the hologram. Since the diameter of the core of the single-mode fiber is in
micron-scale, an almost perfect point source is obtained. This also makes it possible to
reconstruct an image with a large depth of focus at distance di away from the hologram. The
diffracted fringes on the inspected object are recorded by the image acquisition system in which
consists of an endoscope and a CCD camera. Phase distribution is then analyzed to reconstruct
the 3D shape.
Fig. 4. Projected fringe profilometry using a diffracted area-encoded pattern by
launching a reading beam to the hologram. An endoscope combined with a CCD
camera is used to record the distorted fringes
evaluated by Fourier transform method for the images in red channel and green channel,
respectively. Note that phase evaluation gives principle valuesranging from–andand has
discontinuities with 2phase jumps. t needs to be unwrapped to obtain the absolute phases. In
our experiment, we useGoldstein’s algorithm [25] to restore the absolute phases.
Its 3D profile could be computed by Eq. (9). Shadow occurred on the edge of the lid, both to
the red channel and the green channel. Figure 10 shows the meshed data sets in which the
uncorrected ones caused by shadowing had been thrown away.
Fig. 6. Schematic diagram of multiple projections.
Fig. 7. Appearance of two projected fringe patterns projected on the inspected object.
Fig. 10. Measured 3D surface profile reconstructed by the corrected absolute phase map.
5. Experiments
5.1 3D shape measurements
An experimental setup was constructed to test the projection system, as shown in Fig. 11. A
ball was used as the inspected object. This inspected object was projected with two fringe
patterns from two different viewpoints. The two fringe patterns were produced by launching two
laser beams into the holograms. Diffraction efficiency of the holograms was measured
approximately 20 %. A green laser beam and a blue laser beam were selected as the light sources.
A color CCD camera was used to record the projected fringes. An endoscope was utilized to
guide the acquired image. The recorded image was separately to three color channels: the red,
green, and blue. Figure 12(a) and 12(b) illustrate the images separated in the green channel and
blue channel, respectively. For surfaces with depth discontinuities, phases can be unwrapped
(a) (b)
Fig. 13. Phase map evaluated by Fourier transform method for (a) the green channel, and (b) the
blue channel.
Fig. 14. Measured 3D surface profile.
very compact. This makes it possible to perform 3D shape measurements using the diffraction
grating built into an endoscope for dynamic surfaces with large depth discontinuities.
9. Reference
1. G. Indebetouw,“Profile measurement using projection of running fringes,”Appl. Opt. 17,
2930-2933 (1978).
2. V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of
3-D difuse objects,” Appl. Opt. 23, 3105-3108 (1984).
3. M. Takeda and K. Mutoh, “Fourier transform profilometry for the automatic measurement 
of 3-D object shaped,” Appl. Opt. 22, 3977-3982 (1983).
4. X. Su, and W. Chen, “Fourier transform profilometry: a review,”Opt. Lasers Eng. 35,
263-284 (2001).
5. K. G. Larkin and B. F. Oreb, “Design and assessment of symmetrical phase-shifting
algorithms,” J. Opt. Soc. Am. A9, 1740-1748 (1992).
6. Y. Surrel, “Design of algorithms for phase measurements by the use of phase stepping,”
Appl. Opt. 35, 51-60 (1996).
7. F. Chen, G. M. Brown, and M. Song, “Overview of three-dimensional shape measurement
using optical methods,” Opt. Eng. 39, 10-22 (2000).
8. W. H. Su, H. Liu, K. Reichard, S. Yin, and F. T. S. Yu, “Fabrication of digital sinusoidal 
gratings and precisely conytolled diffusive flats and their application to highly accurate
projected fringe profilometry,” Opt. Eng. 42, 1730-1740 (2003).
9. H. Liu, W. H. Su, K. R., and S. Yin, “Calibration-based phase-shifting projected fringe
profilometry for accurate absolute 3D surface profile measurement,” Opt. Commun. 216,
65-80 (2003).
10. Wei-Hung Su, Karl Reichard, Hongyu Liu, and Shizhuo Yin, “Integration of segmented 
3D profiles measured by calibration-based phase-shifting projected fringe profilometry
(PSPFP),” Optical Memory & NeuralNetworks, 12, 51-63 (2003).
11. D. C. Ghiglia and L. A. Romero, "Robust two-dimensional weighted and unweighted
phase unwrapping that uses fast transforms and iterative methods," J. Opt. Soc. Am. A 11,
107- (1994).
12. K. A. Stetson, J. Wahid, and P. Gauthier, “Noise-immune phase unwrapping by use of
calculated wrap regions,”Appl. Opt. 36, 4830-4838 (1997).
13. A. Collaro, G. Franceschetti, F. Palmieri, and M. S. Ferreiro, "Phase unwrapping by means
of genetic algorithms," J. Opt. Soc. Am. A 15, 407-418 (1998).
14. J.-J. Chyou, S.-J. Chen, and Y.-K. Chen, "Two-Dimensional Phase Unwrapping with a
Multichannel Least-Mean-Square Algorithm," Appl. Opt. 43, 5655-5661 (2004).
30. W. C. Su, C. Y. Huang, J. Y. Chen, and W. H. Su,“Efect of recording-beam ratio on
diffraction efficiency of polarization holographic gratings in dye-doped liquid-crystal
films”Opt. Letters 35(3), (2010).
31. Wei-Hung Su, “Projected fringe profilometry using the area-encoded algorithm for
spatially isolated and dynamic objects,” Proc. SPIE7056, (2008)
32. Wei-Hung Su, Chun-Chieh Wang, and Chung-Fan Tu, “A 3D shape sensing system using
multiple fringe projections from different partial views to form an entire shape,”Proc.
SPIE 7056, (2008).
33. Wei-Hung Su, Chao-Kuei Lee, and Cheng-Wei Lee, “Speckles removal from interference
patterns illuminated by coherent light using empirical mode decomposition,”Proc. SPIE
7056, (2008).
34. Wei-Hung Su, and Chi-Hung Shao, “Projected fringe profilometry using a holographic
technique: a compact design for endoscopes,” Proc. SPIE 7056, (2008).
35. Wei-Chia Su, Wei-Hung Su, Chung-Shang She,“Extended Depth of field projected fringe
profilometry using a phase mask,”15th Microoptics Conference, Oct. 25-28 (2009).
36. Chengwei Lee, Wei-Hung Su, and Chao-Kuei Lee, “Speckle-reduction using the
empirical mode decomposition for fringe analysis,” OPT2008光電科技研討會 (2008).
37. 李成偉, 劉僑原, 李晁逵, 蘇威宏, “利用條紋投影法進行快速移動物體之瞬間形貌量
測技術,” 2009物理年會 (2009).
38. Wei-Hung Su, “Speckle-reduction using the empirical mode decomposition for fringe
analysis,” Hilbert-Huang Transform研討會 (2009).
39. 許俊翔，「利用相位光罩增加透鏡景深之研究」國立中山大學材料與光電科學硏究所
碩士論文(2009) 。
40. 李成偉，「利用經驗模態分解法消除干涉條紋的雷射光斑」國立中山大學光電工程硏
究所碩士論文(2009) 。
41. 蘇威宏, 陳煒仁,「三維形貌量測系統」, 中華民國專利 I309294 (2009).
計畫成果自評
本計劃研究內容與原計畫十分相符，並且於期限內達成預期目標。本計畫執行成效豐碩，
主要有：
1. 五篇國際期刊(SCI)的發表[26-30]；
2. 參與國際研討會的發表，計 5 篇[31-35]；
3. 參與國內研討會的發表，計 3 篇[36-38]；
4. 兩位碩士班研究生依此計劃於 2009 年六月順利畢業，碩士班畢業論文計 2 篇[39, 40]；
5. 中華民國專利一篇[41]。
6. 研究成果之學術或應用價值如下頁所示。
3. 由於光源的同調性甚佳，故投影系統有甚大的景深(depth of
focus)，待測物的縱深量測範圍亦因此增加；
4. 繞射條紋以灰階編碼的方式投射在待測物表面，可進行大深度
落差的三維形貌檢測；
5. 本系統採用兩套條紋投影系統，分別自內視鏡的左右兩側，將
條紋投影至待測物體上，可避免陰影所導致的信訊息短缺；
6. 由於影像擷取系統只需要擷取一次資料(one-shot
measurement)，因此可進行動態物體的三維形貌量測。
推廣及運用的價值
形貌檢測 (Profile Inspection) 在工業界的應用日趨廣泛。實際的例
子，在國防工業如飛彈、魚雷、機翼與螺旋槳等形貌之鑑定，醫學
工程如生物細胞，電子產業如 PC 板面，機械製造如齒輪形狀探測
等，皆需要對待測物之三維形貌作精密的檢定。故發展精確的形貌
量測技術已成為產業界的重大課題之一。
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
※ 3.本表若不敷使用，請自行影印使用。
Projected fringe profilometry using the area-encoded
algorithm for dynamic and complex objects
Wei-Hung Su
Department of Material Science and Optoelectronic Engineering,
National Sun Yat-Sen University,
Kaohsiung 804, Taiwan
ABSTRACT
We present a discussion on how an area-encoded fringe pattern is applied to describe
the 3D shape of complex objects that have spatially isolated surfaces or large depth
continuities. Compared with conventional fringe projection techniques, the proposed
scheme is relatively reliable and robust to identify the fringe order. Only one phase
measurement is required. This makes it possible to analyze dynamic objects.
Keywords: fringe projection, projected fringe profilometry, sinusoidal grating,
structured light
1. INTRODUCTION
Projecting a fringe pattern onto an inspected object and then observing the deformation at a different
view angle to retrieve the 3D shape is a popular method for 3D sensing techniques [1-3]. They are
advantageous for the non-scanning nature and full-field performance. Therefore, to inspect dynamic
objects is desirable. In such a situation, phases are usually evaluated by Fourier transforms method [1]
rather than by phase-shifting approaches [2]. The reason is that only one shot-measurement is required
for Fourier transform method to perform the phase-extraction. The phase-shifting approaches are not
appropriate because any movement between two subsequent measurements would result in erroneous
identification. However, when objects of interest are too complicated, part of the inspected surfaces
cannot offer sufficient information to reconstruct the 3D shapes. It is difficult to retrieve the absolute
phases for spatially isolated surfaces, such as a group of fishes. Phase unwrapping [4, 5] will encounter
scheme provides a more reliable performance to identify the fringe orders since it is not sensitive to the
observed colors.
2. PROPERTIES OF AREA ENCODED SINUSOIDAL FRINGES
The projected fringes are encoded with colors and binary stripes. Figure 1 shows such an example. This
pattern can further divided to three parts, including: (a) a set of color grids, (b) a set of binary stripes,
and (c) a set of sinusoidal fringes.
The transmittance of this encoded pattern is mathematically represented as
 2.0)]cos(4.04.0[)()( 2  xxBxCxt d , (1)
where C(x) is the distribution of color grids, B(x) is the transmittance of binary stripes, and d is the
period of sinusoidal fringes. Figure 2(a), (b), and (c) show the distribution of binary stripes, color grids,
and sinusoidal fringes, respectively. Note that the width of color grids is equal to 10 times that of
binary stripes, while the period of sinusoidal fringe is equal to the width of encoded strips.
As shown in Fig. 2(a), transmittance of the stripes is quantized into two intensity levels, 0.5 and 1.
There are 10 binary stripes in a period. The sequence of any three adjacent transmittances within one
period does not appear elsewhere. Thus, any stripe in that period can be identified without ambiguity.
For example, three adjacent stripes with sequent transmittances of 0.5, 1.0, and 0.5 are utilized to
represent the 1st, 2nd, and 3rd stripe in that period, respectively. Stripes are therefore discernible with
reference to its neighbors.
To increase the number of fringes in one period, stripes can further be assigned with desired colors. As
shown in Fig. 2(b), seven colors are selected to address the pattern. These colors are: red, green, blue,
white, yellow, magenta, and cyan. In such an encoding way, 10 binary stripes in a period are
considered as one group. Each group is then identified with a specific color. For example, fringes from
the 1st one to the 10th are encoded with the blue color. Fringes from the 51st to the 60th are encoded with
the yellow. Thus, searching for the sequence of the groups is simplified as to find out the distribution of
the colors. The entire stripes shown in Fig. 2(a) becomes distinguishable with reference to the color
grids. There are 70 stripes in one period, which is large enough for most measurements. Finally, as
depicted in Fig. 1, each sinusoidal fringe becomes distinguishable with reference to the binary stripes
and the colors.
Figure 2(c) shows the distribution of the sinusoidal fringes, with transmittance
ranging from 0 to 0.8. A combination of the binary stripes and sinusoidal fringes in
The inverse Fourier transform of the fundamental component is expressed as,
     ],
2
[
2
1 ,
2
1
),(
~
2
1
)},
1
(
~
2
1
{,
yxx
d
jx
d
j
x eyxbeyxbyd
fByxs
   . (7)
Phase distribution from Eq. (7) is then given by
    



 
}{Re
}Im{
tan, 1
x,ys
x,ys
yx , (8)
where Im{} and Re{} represents the image part and real part of the complex signal.
Note that phase evaluation gives principle values ranging from–andand has
discontinuities with 2phase jumps. t needs to be unwrapped to obtain the absolute
phases xd. After a process of so-called phase unwrapping [11], the absolute
phase values can be identified as
 Unwrap . (9)
4. EXPERIMENTS
Two fish were selected as the measured sample. An area-encoded pattern designed on
a computer is projected to the objects by the LCD projector. The fringe pattern used to
perform the measurement is depicted in Fig. 5. The minimum transmittance of this
pattern was 0.2. Thus, all the color stripes were observable.
A color CCD camera with 1024768 pixels at 24-bit pixel resolution was used to
record the projected fringes. The recorded image in which an area-encoded pattern
was projected on the objects is shown as Fig. 6(a). Phase distribution evaluated by the
Fourier transform method is depicted as Fig. 6(b). Fringe orders were discernible with
reference to the encoded stripes. Thus the phases were unwrapped without ambiguity.
Figure 6(c) illustrates the distribution of the absolute phases. The profile of isolated
objects was retrieved according to Eq. (2). Shown in Fig. 6(d) is the reconstructed 3D
shape.
Calibration procedures can be found in the reference paper [21]. In our setup, the
calibrated dimensions were approximately 20cm, 15cm, and 10cm in x-, y-, and z-axis,
respectively. Errors form parameter identification in Eq. (2) was minimized as
sufficient data sets were obtained. The highest order of z() was n = 5. Parameters in
each formula, i.e. z(), x(z), or y(z), were determined with 20 measurements. Since the
5. X. Su and W. Chen,“Reliability-guided phase unwrapping algorithm: a review,”Opt. Lasers Eng.
42, 245-261 (2004).
6. J. M. Huntley and H. O. Saldner, “Temporal phase-unwrapping algorithm for automated
inteferogram analysis,”Appl. Opt. 32, 3047-3052 (1993).
7. D. R. Burton and M. J. Lalor, “Multichannel Fourier fringe analysis as an aid to automatic phase
unwrapping,”Appl. Opt. 33, 2939-2948 (1994).
8. H. Zhao, W. Chen, and Y. Tan, “Phase-unwrapping algorithm for the measurement of
three-dimensional object shapes,”Appl. Opt. 33, 4497-4500 (1994).
9. W. Nadeborn, P. Andrä, and W. Osten, “A robust procedure for absolute phase measurement,”
Opt. Lasers Eng. 24, 245-260 (1996).
10. H. O. Saldner and J. M. Huntley,“Temporal phase-unwrapping: application to surface profiling of
discontinuous objects,”Appl. Opt. 36, 2770-2775 (1997).
11. Y. Hao, Y. Zhao, and D. Li, “Multifrequency grating projection profilometry based on the
nonlinear excess fraction method,”Appl. Opt. 38, 4106-4110 (1999).
12. E. B. Li, X. Peng, J. Xi, J. F. Chicharo, J. Q. Yao, and D.W. Zhang, “Multi-frequency and
multiple phase-shift sinusoidal fringe projection for 3D profilometry,”Opt. Express 13,
1561-1569 (2005).
13. M. Takeda, Q. Gu, M. Kinoshita, H. Takai, and Y. Takahashi, “Frequency-multiplex
Fourier-transform profilomery: a single-shot three-dimensional shape measurement of objects
with large height discontinuities and/or surface isolations,”Appl. Opt. 36, 5347-5354 (1997).
14. W. H. Su, and H. Liu, “Calibration-based two frequency projected fringe profilometry: a robust,
accurate, and single-shot meaurement for objects with large depth discontinuities,”Opt. Express
14, 9178-9187 (2006).
15. P. Vuylsteke and A. Oosterkinck, “Range image acquisition with a single binary-encoded light
pattern,”IEEE Trans. Pattern Anal. Mach. Intell. 12, 148-164 (1990).
16. W. Liu, Z. Wang, G. Mu, and Z. Fang, “Color-coded projection grating method for shape
measurement with a single exposure,”Appl. Opt. 39, 3504-3508 (2000).
17. S. Y. Chen and Y. F. Li, “Self-recalibration of a colour-encoded light system for automated
three-dimensional measurements”Meas. Sci. Technol. 14, 33-40 (2003).
18. W. H. Su, “Color-encoded fringe projection for 3D shape measurements,”Opt. Express 15,
13167-13181 (2007).
19. W. S. Zhou and X. Y. Su, “Adirect mapping algorithm for phase measuring profilometry,”J.
Mod. Opt. 41, 89-94 (1994).
20. Q. Hu, P. S. Huang, Q. Fu, F. P. Chiang, “Calibration of a three-dimensional shape measurement
system,”Opt. Eng. 42, 487-493 (2003).
21. H. Liu, W. H. Su, K. R., and S. Yin, “Calibration-based phase-shifting projected fringe
profilometry for accurate absolute 3D surface profile measurement,”Opt. Commun. 216, 65-80
(2003).
Figure 1 Appearance of a transmittance-encoded fringe pattern.
(a)
(b)
(c)
Figure 2 Color arrangement of the encoding scheme.
(a) (b)
(a) (b)
Figure 7 3D shape sensing for a standard flat plate. (a) Retrieved
shape. (b) One-line surface plot of the retrieved shape.
(a)
A 3D shape sensing system using multiple fringe projections
from different partial views to form an entire shape
Wei-Hung Su, Chun-Chieh Wang+, and Chung-Fan Tu+,
Department of Material Science and Optoelectronic Engineering,
National Sun Yat-Sen University
Kaohsiung 804, Taiwan
+ Center for Measurement Standards, Industrial Technology Research Institute
Hsinchu 300, Taiwan
ABSTRACT
A 3D sensing method to describe an entire shape from many segmented
measurements performed by projected fringe profilomety is presented. Unlike
conventional algorithms, image registration is not required in this setup. Among all
other integration schemes, this method is superior since it offers many major
advantages, including: (1) very low computation cost for the data fusion, (2) reduced
computational time, and (3) very high integration accuracy.
Keywords: fringe projection, projected fringe profilometry, sinusoidal grating, data
fusion
6. INTRODUCTION
3D sensing measurements using fringe projection schemes [1-5] are one of the
well-known methods because of its non-scanning and full-field nature. It uses a fringe
pattern projected onto the inspected object and evaluates the phase distribution from
another viewpoint. The distorted fringes contain depth information and therefore are
desirable to retrieve the inspected shape. However, when objects of interested are too
complicated, shading and obstruction appears. Data points on that area are therefore
lost. It is difficult to inspect the entire surface from one viewpoint. Segmented
Figure 1 shows the optical setup of the 3D shape sensor, which is used for segmented 3D
measurements. A one-dimensional fringe pattern that lies in the xg-yg plane with fringes normal to
xg-axis is projected to the inspected object. Phase distribution can be mathematically expressed as









0
2/  d
y
x
g
g , (1)
where d is the period of the fringes.
Shape of the tested object is identified in the world coordinate system (x, y, z). The
relationship between the fringe coordinates and the world coordinates is given by













































)(
3
)(
2
)(
12
)(
32
)(
22
)(
12
)(
31
)(
21
)(
11
0 p
p
pd
p
p
p
p
p
p
t
t
t
r
r
r
r
r
r
zz
yy
xx  . (2)
where rij are coefficients signified with magnification and coordinates rotation, and ti
are shifting parameters. The superscript (p) denotes a projector parameter. Distortion
from the projection lens is addressed withx,y, andz.
Fringe deformation on the object is then imaged to the detection plane, which is
located in the coordinate system (xd, yd). A similar relationship between the detector
coordinates and the world coordinates is represented as



























)(
2
)(
1
)(
23
)(
22
)(
21
)(
13
)(
12
)(
11
c
c
ccc
ccc
dd
dd
t
t
z
y
x
rrr
rrr
yy
xx . (3)
The superscript (c) denotes a camera parameter. For a fixed detection location, the
terms on the left side of Eq. (3) are two constants. Equation (3) is therefore simplified
as the following expression:





zbby
zaax
10
10 , (4)
where ai and bi are constants, and can be determined with a proper calibration scheme.
Substituting (4) into Eq. (2), the variable z can be represented as a function of phase.
Even though distortions of the projection lens are taken into account, it still can be
approximately expressed as
n
N
n
ncz 


0
. (5)
The parameters ci can be carried out with a proper calibration scheme. In Section 2.2,
a calibration procedure is described.











zbby
zaax
cz
ll
ll
N
n
nll
n
)(
1
)(
0
)(
1
)(
0
0
)()( )(
, (7)
where the superscript (l) denotes a parameter from the lth sensing system.
Calibration procedures described in section 2.2 are employed to identify the
parameters in each sensing system. Setups to determine the -to-z conversion and
z-to-x (or y) conversion are shown in Fig. 4 and Fig. 5, respectively. The calibration
tool (either the optical flat or the 2D pattern) is placed at the known plane z = zi.
Distribution of fringes on the calibration tool is recorded by all the CCD cameras at
the same time. The phase measurement is repeated at different z positions and stops
when enough measurements are obtained to execute the curve-fitting algorithm. Thus,
for each sensor system, a series of absolute phases and the associated depths are
obtained at each pixel location. The relationships between(l) and z, z and x, and z
and y in each sensor system are determined. Parameters )(lia ,
)(l
ib , and
)(l
ic are then
identified by the curve-fitting algorithm.
All the sensing systems are calibrated with the same calibration tools, which are
placed in the world coordinates (x, y, z). Thus, all the segmented profiles are retrieved
in the same coordinate system. Integration becomes a simple task to display all point
clouds in the coordinate system. Once all the sensing systems are calibrated, all the
optical elements should be rigid to ensure the repeatability of data fusion.
10. EXPERIMENTS
In our setup, a bowl with approximately 120 mm in diameter and 40 mm in depth was
chosen as the inspected sample. Two 3D sensing systems located at different
viewpoints were used to perform the segmented measurements. In each system, the
projected fringes were observed by a CCD camera with 10241024 pixels at 12-bit
pixel resolution. The recorded images from two viewpoints are shown in Fig. 6(a) and
(b), respectively. Data on the edge of the bowl were lost because of shading.
Phases are evaluated using the phase-shifting technique. Figure 7(a) and (b) show the computed phases,
which were within the interval between–and. Phase unwrapping was then performed to eliminate
the discontinuities. In our experiment, we useGoldstein’s algorithm [10] to restore the absolute phases.
6. REFERENCES
1. M. Takeda, and K. Mutoh, “Fourier transform profilometry for the automatic measurement of
3-D object shaped,” Appl. Opt. 22, 3977-3982 (1983).
2. V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of 3-D
difuse objects,” Appl. Opt. 23, 3105-3108 (1984).
3. D. R. Burton and M. J. Lalor,“Multichannel Fourier fringe analysis as an aid to automatic phase
unwrapping,”Appl. Opt. 33, 2939-2948 (1994).
4. W. H. Su, and H. Liu,“Calibration-based two frequency projected fringe profilometry: a robust,
accurate, and single-shot meaurement for objects with large depth discontinuities,”Opt. Express
14, 9178-9187 (2006).
5. W. H. Su, “Color-encoded fringe projection for 3D shape measurements,”Opt. Express 15,
13167-13181 (2007).
6. A. W. Gruen, “Geometrically constrained multiphoto matching,”Photogramm. Eng. Remote
Sens. 54, 633-641 (1988).
7. L. G. Brown, “A survey of image registration techniques,” ACM Comput. Surveys 24, 325-376,
(1992).
8. C. Reich, R. Ritter, and J. Thesing, “3-D shape measurement of complex objects by combining
photogrammetry and fringe projection,”Opt. Eng. 39, 224-231 (2000).
9. A. Dipanda, S. Woo, F. Marzani and J. M. Bilbault, “3-D shape reconstruction in an active
stereo vision system using genetic algorithms”Pattern Recog. 36, 2143-2159 (2003).
10. E. Zappa, and G. Busca, “Comparison of eight unwrapping algorithms applied to
Fourier-transform profilometry,”Opt. Lasers Eng. 46, 106-116 (2008).
Figure 3 Segmented measurements performed by projected fringe profilometries.
Figure 4 Configuration to identify parameters of the-to-z relationship.
(a) (b)
Figure 7 Phase-extraction using the phase-shifting technique for the sensing system
at (a) the left point of view, and (b) the right point of view
(a) (b)
Figure 8 Appearance of unwrapped phases obtained by the sensing system at (a) the
left point of view, and (b) the right point of view.
Speckles removal from interference patterns illuminated by coherent light using
empirical mode decomposition
Wei-Hung Su, Chao-Kuei Lee, and Cheng-Wei Lee
Department of Material Science and Optoelectronic Engineering,
National Sun Yat-Sen University
Kaohsiung 804, Taiwan
ABSTRACT
The speckle that is formed in coherent illumination confuses efforts to record an
object’s fine details. The confusion is particularly severe in optical metrology and
microscopy. In this paper, a scheme using the empirical mode decomposition (EMD)
to remove speckles is proposed. This makes it possible to accurately evaluate phases
from a fringe pattern illuminated by a coherent light source.
Keywords: fringe analysis, speckle, coherent illumination, empirical mode
decomposition
12. INTRODUCTION
Speckles that are formed in coherent illumination confuse efforts to record an object’s
fine details. The confusion is particularly severe in optical metrology and microscopy.
For example, it is a challenge to perform phase-extraction with the phase-shifting
algorithms [1] for an interference pattern. Speckle noises are introduced to each
phase-shifted pattern and add uncertainty to evaluate the phase values. Many filter
algorithms, such as Kuan Filter [2], Enhanced Frost Filter [3], and Gamma Filter [4],
have been extensively studied to remove the speckles. However, signal might be lost
or distorted while performing these algorithms.
In this paper, we use the Empirical Mode Decomposition (EMD) to reduce the
speckle effects caused by such kind of light sources. The EMD was first introduced by
Huang [4], and has been well developed to analyze noises in time domain. For signals
image. Intensity distribution across one line and the related intrinsic mode functions
are shown in Fig. 2(b). The EMD decomposes the intensity distribution into a finite
number of the intrinsic mode functions (IMFs). It separates the intrinsic mode
functions (IMFs) from the obtained data one by one, until the residue is monotonic.
One can see that the 1st IMF c1(x) signifies most of the speckle information. Some
other IMFs, such as c2(x), c3(x) and c4(x), more or less contain some speckle
information.
14. SIMULATION
A sinusoidal curve with randomly distributed speckles is used as an example. It is mathematically
expressed as
 )()2cos()()( xNx
T
BAxNxSxI
O
  , (3)
where S(x) is the sinusoidal signal, and N(x) is the noise. An example of I(x) is shown in Fig. 3(c), in
which A = 2000, B = 1000, and To = 60. Speckle noise N(x) is randomly distributed with values ranging
from -1000 to 1000. The EMD decomposes the intensity distribution into a finite number
of the IMFs, as illustrated in Fig. 4. It is obvious that the 1st IMF c1(x) signifies most of
the noise information. Thus, a desired signal S(1)(x) can be obtained by getting rids of the
1st IMF, as expressed as
 )()( 1)1( xcxIxS  . (4)
Unfortunately, not all the speckles can be fully described by c1(x), i.e., N(x) ≠c1(x). Some other
IMFs such as c2(x) and c3(x) still involve speckle information. Therefore, part of the
speckle noises still appears in S(1)(x). In order to obtain the more noiseless data, a repeated
processing is then applicable, which can be recursively expressed as



l
i
i
l xcxIxS
1
)( )()( . (5)
The superscript (l) denotes the lth repeated processing. This procedure can be repeated and stopped
until the deviation between S(l)(x) and S(x) reaches a minimum value. A flow diagram to illustrate this
processing is shown as Fig. 5.
Since a smaller value of deviation SD(l) implies that the refined data S(l)(x) is more
similar to the ideal signal S(x), finding the noiseless signal becomes a problem of
searching for the optimized number l. Figure 6(a) shows the retrieved signals
computed by Eq. (4) and Eq. (5). Their corresponding deviations are depicted as Fig.
6(b). In this case, S(4)(x) has the lowest standard deviation.
Phase of the fringe pattern is therefore retrievable by Eq. (12). The intensity
distribution described in Fig. 3(c) is used again as the example. Its five phase-shifted
distributions with random noises are shown as Fig. 8. Figure 9(b) shows the phase
retrieved from the five noisy patterns using Eq. (12). Phase distribution of the
noise-free function is shown as Fig. 9(a). Compared with Fig 9(a), enormous errors
appear on Fig. 9(b). Our goal is to accurately retrieve the phase of the sinusoidal
signal from the noisy data. The EMD is used again to remove most of the noise.
Statistic simulation illustrated in Fig. 7 shows that l is approximately 3.7 at To = 60
and SNR=1. Thus, it predicts that S(4)(x) is the most similar one to the sinusoidal shape.
Phase retrieved from the EMD processed data is expressed as

















4
0
)(
4
0
)(
1)(
)5/2cos(),(
)5/2sin(),(
tan),(
n
l
n
n
l
n
l
nyxS
nyxS
yx


 . (13)
Figure 10 shows the retrieved phases. Indeed,(4)(x) is more similar tos(x), which is
complied with our prediction.
16. EXPERIMENTS
A ball was chosen as the inspected sample. A sinusoidal pattern illuminated by a coherent light source
was projected onto this object. Fringe distribution was recorded by a CCD camera with 10241360
pixels at 12-bit pixel resolution. Figure 11(a) shows the recorded image. The comparison using the
incoherent illumination is shown as Fig. 11(b). A halogen was selected as the light source. Intensity
distributions across a line of the images are shown in Fig. 11(c) and 11(d), respectively. Fringe periods
on the inspected object were mainly ranging from 20 to 50 pixels. Coherent noise was inevitably
introduced by the laser source. Compared with Fig. 11(d), amplitude of the speckle noise in Fig. 11(c)
was very large, resulting in a low signal-to-noise ratio. Figure 12(a) and 12(b) shows the spectrum of
Fig. 11(c) and 11(d), respectively. For coherent illuminated patterns, speckles appear everywhere in the
frequency domain. Thus, it is difficult to remove all the speckles just by a bandpass filtering algorithm.
The amplitude of speckles had the same order as the signal. Therefore, the
signal-to-noise ratio was approximately 1. Our simulation model shown in Fig. 7
suggests that l = 3 when SNR=1 and T0=20~50. Figure 13 shows the refined data
performed by the EMD. Indeed, it was found that S(3) removes most noises from the
fringes.
17. V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of 3-D
difuse objects,” Applied Optics, 23 (18), 3105-3108 (1984).
18. Hongyu Liu, Wei-Hung Su, Karl Reichard, and Shizhuo Yin, “Calibration-based phase-shifting
projected fringe profilometry for accurate absolute 3D surface profile measurement,” Optics
Comm. 216, Issues 1-3, February 1, 2003, p.65-80.
Figure 1 Flow diagram of the shifting process.
(a)
Figure 4 The IMF components of Fig. 3(c).
Figure 5 Flow diagram of the refining process.
Figure 8 Five phase-shifted sinusoidal functions introduced with noises.
(a) (b)
Figure 9 Phase distributions of (a) the sinusoidal curve, and (b) the noisy data.
Figure 10 Phase retrieved from the five-step phase-shifting algorithm.
(c) (d)
Figure 13 Noise removal performed by the EMD: (a) l=1, (b) l=2, (c) l=3, and (d) l=4.
(a) (b)
(c) (d)
Figure 14 Phase distribution computed by the 5-step phase-shifting algorithm: (a)
phase map retrieved by Fig. 9(a); (b) phase map retrieved by Fig. 9(a); (c)
one-line plot of Fig. 15(a); and (d) one-line plot of Fig. 15(b).
Projected fringe profilometry using a holographic technique:
a compact design for endoscopes
Wei-Hung Su, and Chi-Hung Shao
Department of Material Science and Optoelectronic Engineering,
National Sun Yat-Sen University
Kaohsiung 804, Taiwan
ABSTRACT
We propose a projection scheme using a diffraction element for finding the absolute
shape of an object with large depth discontinuities. Its application built into an
endoscope to retrieve an object inside a body cavity is presented as well. Among all
existing fringe projection schemes, this proposed method is notable for its compact
design. Only one phase measurement is required. To inspect a dynamic object is
desirable.
Keywords: fringe projection, projected fringe profilometry, sinusoidal grating,
endoscope
18. INTRODUCTION
Projected fringe profilometry is one of the popular non-contact and non-scanning methods for 3D
shape inspection [1-5]. It has been widely used for industry monitoring, biomedicine, and defect
marking. The entire surface is sampled simultaneously with minimum requirements to the mechanical
fixture. In addition to its full-field measurement capability, it is also notable for the non-contact nature,
fast measurement speed, high profile sampling density, and low environmental vulnerability [6-10].
Projected fringe profilometry consists of a projection system and an image acquisition system. The
projection system generates a sinusoidal fringe pattern from a projection lens onto the inspected surface.
Phases of the fringes recorded by the image acquisition system at a different viewpoint are analyzed to
reconstruct the 3D shape. With proper phase-extraction schemes [3-6] and calibrations, depth accuracy
The two-frequency pattern is the combination of two sets of fringes with different frequencies: one
frequency is P (P = 3, 4,5 …)times larger than the other. Its transmittance is represented as
 )cos( 22121 xxt d , (1)
where d is the period of the high frequency. We have proposed a method to fabricate an accurate
two-frequency pattern [8]. An example of the pattern is shown in Fig. 2. In this pattern, the period of
the low-frequency fringes and the high-frequency fringes was 960m and 192m, respectively.
The distance do between the fringe pattern and the objective lens is slightly smaller than the focal length
of the objective lens. It implicates that the objective lens forms an enlarged virtual image of the
two-frequency pattern. For a coaxial system, the imaged position is approximately given by
oi dfd
111  , (2)
where f is the focal length of objective lens, and di is the distance between the image and objective lens.
As shown in Fig. 3, when a conjugate reading beam from a single-mode fiber is launched into the
hologram, a diffracted two-frequency pattern is reconstructed on which the virtual image is formed, at
distance di + f away from the hologram. Since the diameter of the core of the single-mode fiber is in
micron-scale, an almost perfect point source is obtained. This makes it possible to reconstruct an image
with a large depth of focus at distance di + f away from the hologram.
The diffracted fringes on the inspected object are recorded by the image acquisition system in which
consists of an endoscope and a CCD camera. Phase distribution is then analyzed to reconstruct the 3D
shape.
20. PHASE-EXTRACTION AND UNWRAPPING
Phases of the two-frequency pattern are evaluated by Fourier transform method [3]. The intensity
distribution with distorted fringes of a two-frequency pattern obtained by the CCD sensor array can be
represented as
           yxyxlyxyxhyxayxI lh ,cos,,cos,,,   , (3)
where a(x, y) is the intensity bias at location (x, y) in the CCD detection plane, h(x, y)
and l(x, y) are the fringe modulation, and h and l are absolute phases of the high
frequency and low frequency, respectively. Note that the high frequencyh is P (P = 3,
4,5 …)times larger than the low frequencyl, even though they are distorted.
It has been shown that a point (x, y, z) on the tested object can be expressed as [9]












n
n
n
o
o
cz
bzby
azax

1
1 , (9)
where a1, ao, b1, and bo can be carried out by obtaining a set of depth values and
corresponding transverse positions. The coefficient cn of the polynomial can be
determined with a sufficient data set of phase values and their corresponding depth
values.
22. EXPERIMENTS
An experimental setup was constructed to test the projection system, as shown in Fig. 5. In the image
acquisition system, an endoscopes combined with a monochrome sensor array with 10241024 pixels
at 12-bit pixel resolution was used. A He-Ne laser with an output power of 10mW at 632.8nm was
employed to be the light source. A film hologram was used as the diffraction component. Its diffraction
efficiency was measured approximately 20 %. The focal length of the objective lens used to form an
image of the fringe pattern was 100mm. In this fringe pattern, the period of the fringes was 192m.
Figure 6(a) shows appearance of the inspected object inside a plastic pipe with diameter of 0.5-inch.
The size of this object was approximately 5mm5mm. Shown in Fig. 6(b) is the recorded image in
which the diffracted pattern was projected on this inspected object. Figure 7 shows the reconstructed
shape. Errors of the system, in the case of our experiment, were mainly raised from the spatially
sampling density of image acquisition system, uncertainty of phase evaluation using Fourier transform
method, and speckle noise of the diffraction pattern.
To investigate errors caused by speckle noise, a 8mm8mm standard flat plate with roughness
approximately 2m was used as the testing object. Figure 11 shows the 3D shape measured by our
proposed method. Depth accuracy of the profile was approximately 260m.
From the experimental data, it indicated that the diffraction grating is indeed practical on 3D shape
reconstruction for surfaces. Its simplified structure and compact design potentially allow performing
3D inspections using endoscopes.
31. H. Liu, W. H. Su, K. R., and S. Yin, “Calibration-based phase-shifting projected fringe
profilometry for accurate absolute 3D surface profile measurement,” Opt. Commun. 216, 65-80
(2003).
32. Wei-Hung Su, Karl Reichard, Hongyu Liu, and Shizhuo Yin, “Integration of segmented 3D 
profiles measured by calibration-based phase-shifting projected fringe profilometry (PSPFP),” 
Opt. Mem. & Neural Net. 12, 51-63 (2003).
33. D. C. Ghiglia and L. A. Romero, "Robust two-dimensional weighted and unweighted phase
unwrapping that uses fast transforms and iterative methods," J. Opt. Soc. Am. A 11, 107- (1994).
Figure 4 Coordinate systems in a non-telecentric projected fringe measurement system.
Figure 5 Schematic diagram of a projected fringe profilometry using a diffracted
two-frequency pattern by launching a reading beam to the hologram.
Figure 7 3D profile of the sample measured from the proposed scheme.
