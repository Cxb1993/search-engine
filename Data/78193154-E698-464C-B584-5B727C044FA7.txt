 1 
目錄 
目錄 ............................................................................................................................... 1 
1.緒論 ............................................................................................................................ 2 
1.1 研究目的............................................................................................................ 2 
第二章 文獻探討 ......................................................................................................... 2 
第三章 隱蔽型垃圾網頁與轉址型垃圾網頁之偵測 ................................................. 3 
3.1 資料蒐集.................................................................................................................. 3 
4.2 使用不同瀏覽器下載網頁...................................................................................... 3 
4.3 偵測垃圾網頁流程.................................................................................................. 4 
4.3.1 隱蔽型垃圾網頁之偵測...................................................................................... 4 
4.3.2 轉址型垃圾網頁之偵測...................................................................................... 6 
4.4 驗證方式.................................................................................................................. 8 
第四章 結論與未來研究 ............................................................................................. 8 
6.1 結論.......................................................................................................................... 8 
6.2 未來研究................................................................................................................. 9 
參考文獻 ....................................................................................................................... 9 
  
 3 
3. 隱蔽型垃圾網頁與轉址型垃圾網頁之偵測 
3.1 資料蒐集 
 本研究著重於判斷中文的 Web 垃圾網頁，所以在蒐集資料的部份就以國內
較熱門且較為大家所使用的搜尋引擎來進行實驗，取 Yahoo、MSN 以及 Google
等搜尋引擎 2008 年的「熱門查詢關鍵字」前幾名來當實驗的資料集。使用 2008
年熱門關鍵字的原因為： 
(1) 2008 年度的熱門關鍵字是累積一整年使用者的搜尋動作， 代表 2008 年使
用者在這一整年度最關心的事。 
(2) 這些關鍵字或許不是在 2008 年中的每一天都非常熱門，也可能是因為某些
事件因此而突然爆紅。 
(3) 一些網站設計者可能會使用這些在搜尋引擎上較常被查詢的熱門關鍵字放
入自己的網站當中，藉此增加網站在搜尋引擎的排名以及曝光率。 
故本研究在 Yahoo 取了前 20 名的「熱門查詢關鍵字」、在 MSN 取了前 20 名的
「熱門查詢關鍵字」以及在 Google 取了前 10 名的「熱門查詢關鍵字」，總共蒐
集了 50 個熱門關鍵字。 
但這 50 個關鍵字中有重複出現的關鍵字，故去除掉重複的關鍵字後只剩下
44 個「熱門關鍵字」，在 Google 中查詢並得到每個「熱門關鍵字」前一百名查
詢結果的 URL，再利用 Wget 軟體下載所蒐集到的網頁檔案。 
3.2 使用不同瀏覽器下載網頁 
 對於 Cloaking 網頁的手法，很多都是提供給搜尋引擎爬行器和使用者所使
用的一般瀏覽器不同的網頁。在提供給搜尋引擎爬行器時，提供了充滿很多關鍵
字的網頁，讓搜尋引擎爬行器在做索引時可以將此網頁加入，但是在給一般網路
 5 
其視為非隱蔽型的垃圾網頁；若 HTML 檔案轉換成純文字檔後其內容也相同，
則視其為非隱蔽型的垃圾網頁，故本研究所使用的步驟則包含這兩項的定義規則
並且再加入一項判斷的規則，共三個步驟如下：  
一、偵測不同瀏覽器下，HTML 檔內容是否相同。 
 隱蔽型網頁在一般瀏覽器(B1)以及搜尋引擎爬行器模擬器(C1)下，判斷其內
容是否相同，所以先針對最原始的 HTML 檔案內容作簡單的比對，由 Wget 軟體
所下載的原始 HTML 檔中可以分為標籤(<tag>)、屬性以及文字內容部份，根據
其內容來判斷 B1 和 C1 之 HTML 內容是否相同，若所有的內容文字都一樣，即
可判斷為非隱蔽型的垃圾網頁，若其 HTML 檔案內容不相同，即可以先將此網
頁設定為隱蔽型垃圾網頁之候選頁。 
因為對於給予搜尋引擎爬行器之網頁，在網頁當中不需要加入一些 Javascrip
的語法來讓版面更加美化，所以可能會造成網站設計者在設計網站時，設計了不
同版本的網頁，一種網頁是專門給搜尋引擎爬行器做索引的簡易版本網頁，而另
一種網頁則是給網路使用者看的經過版面美化之網頁。但事實上，網頁所要呈現
的內容是一樣的，在網頁當中可能沒有加入任何製作垃圾網頁的技術，所以本研
究再進行下一步的分析。  
二、將 HTML 檔轉換成純文字作比對。 
 HTML 檔可能會隱藏許多文字在內，所以本研究會將 HTML 檔轉換成文字
檔，並且將 HTML 的標籤拿掉，比對純文字在一般瀏覽器(B1)以及搜尋引擎爬行
器模擬器(C1)所下載的檔案是否相同，若完全相同則可將這些網頁歸類為非隱蔽
型的垃圾網頁，若不相同，這些網頁仍為隱蔽型垃圾網頁的候選頁。 
三、觀察在不同瀏覽器與不同時間下關鍵字在網頁中出現的次數。 
關鍵字就是與網頁內容最相關的文字，本研究針對所得到的網頁來計算其關
 7 
 本研究使用 Wget 軟體下載一般瀏覽器完整的網頁內容，使用瀏覽器程式
檢視網站使否使用轉址的語法。轉址的HTML語法有很多種，所以有許多研究也
提出一些偵測轉址內容包含了<META HTTP-EQUIV="Refresh"...>、<Javascript: 
location.replace>等較簡易的語法，並且使用程式去檢視HTML原始碼是否有包含
這些轉址的語法。但是並非所有使用轉址語法的網頁，都一定是轉址型的垃圾網
頁，有些網站在使用轉址的語法是用在網站搬家時，當網路使用者連至原本的舊
網頁時，可以更快速讓網路使用者可以連結至新的網站。當然也有些網頁製作者
會因為想要提昇自己網站在搜尋引擎結果中的排名，因此加入這些手法。要如何
判斷這些不當得手法，是我們研究所要探討的問題。： 
一、判斷網頁中是否有使用轉址的語法 
 本研究乃是針對轉址型的垃圾網頁做偵測，首先找出其是否有使用一些網頁
轉址的語法，此舉可以先將龐大的網頁資料過濾掉，並將含有轉址型語法的網頁
設定成轉址型垃圾網頁候選頁，再將這些轉址型垃圾網頁候選頁進行進一步的探
討。 
二、分析轉址前的網頁內容 
 為了辨識轉址型網頁是否為垃圾網頁，在此階段會對於網頁在轉址前的內容
進行分析。因為許多網站管理者會在網頁中置入大量的文字來充當網頁的內容文
字，因此而提昇網站在搜尋引擎上的排名。本研究整理出可能影響轉址型網頁的
條件如下： 
(1) 網頁轉址前所含的URL數； 
(2) 網頁轉址前的網頁大小； 
(3) 網頁轉址前的網頁標題所含的字元數。 
利用這三個條件來對於這些所含有轉址性語法的網頁進行分析。 
 9 
頁當中，其網頁大小在10KB以內所含的Meta Keyword字元數是無法當成轉址型
垃圾網頁 的判斷依據。根據此判斷依據後，精確度有88％，但是由於訓練樣本
較小，相對的精準度就比較高。 
4.2 未來研究 
 本研究主要是針對中文的網頁進行研究，但在網際網路之上並非所有的網頁
皆為中文的網頁，故本研究希望可以將這些規則帶入不同語言的網頁進行垃圾網
頁之偵測，並且研究這些規則帶入不同語言的網頁後是否也可以符合。 
 本研究的樣本空間僅只有4017筆的網頁，故未來可以加入更多的網頁來進行
分析與討論，增加更高的準確率。 
 本研究在抓取樣本空間時僅針對搜尋引擎上的熱門關鍵字來進行搜尋，所以
未來可以針對一些較特殊性的搜尋分類來進行研究，例如：商業性的分類、法律
性的分類、娛樂性的分類等等。利用這些不同的搜尋分類找出更加合適的偵測垃
圾網頁方法。 
參考文獻 
[1] M. Cafarella and D. Cutting, “Building Nutch: Open Source”, ACM QUEUE, 
vol. 2, 2004. 
[2] Zolt a´n Gy o¨ngyi, Hector Garcia-Molina, Jan Pedersen, “Combating Web Spam 
with TrustRank”, the 30th International VLDB Conference, pp. 576 - 587, 2004. 
[3] Zolt a´n Gy o¨ngyi, Hector Garcia-Molina, “Web Spam Taxonomy”, First 
International Workshop on Adversarial Information Retrieval on the Web 
(AIRWeb), 2005. 
[4] M. R. Henzinger, R. Motwani, and C. Silverstein, “Challenges in Web Search 
Engines”, SIGIR Forum, vol. 36, no. 2, Fall 2002. 
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳育亮 計畫編號：98-2622-E-128-002-CC3 
計畫名稱：網站轉換最佳化--偵測 Cloaking 與 Redirection 垃圾網頁之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
