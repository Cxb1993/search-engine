-2- 
Using Artificial Neural Networks to Automatically 
Construct Rule Base for Forecasting Taiwan Electronic 
Companies’ Stock Return and ROE Performance 
Brandt Tso† and Shad S. Jiang 
 
Abstract 
 
   The stock returns and ROE are meaningful to the shareholders to realize the level of 
investment feedbacks and companies’ profitability. The accurate forecasts for both 
factors thus can be very important to the investors. Instead of consulting to the financial 
experts, this study proposes an approach by decoding artificial neural networks (ANN) 
to automatically construct a rule base for performing forecasts. The ANN being 
implemented is the so-called back-propagation neural network. The algorithm known as 
TREPAN is introduced to uncover the hidden knowledge from ANN for building the 
relationship between company’s current financial indices and the probable performance 
in the next season. The study uses Taiwan stock market electronic companies in the time 
period from years 2000 to 2005 as basis for carrying out experiments. The inputs for the 
ANN in this preliminary study are only concerned with the fundamental factors. It is 
expected that, through this empirical study, one may accelerate the rule base 
construction for the financial expert systems and to provide the more clear traces to 
improve the diagnosis to the companies. The results reveal that, using fundamental 
factors as inputs, the ANN can perform up to 70.68% accuracy in the experiments. In 
terms of TREPAN algorithm, the knowledge of companies’ financial performance can 
be successfully extracted from ANN, though the minor error may occur. Some 
interesting discoveries are also addressed.  
 
Keywords: ANN, stock return, ROE, TREPAN, expert system 
 
 
 
                                                 
†
 Associate Professor, Department of Information Management, Management College, NDU, 70, Sec. 2, 
Central N. Rd., Bei-Tou, Taipei 11258, Taiwan 
Tel:+886 2 28986600 ext 228365. E-MAIL: brandttso@yahoo.com.tw (B. Tso)  
 
-4- 
Using Artificial Neural Networks to Automatically 
Construct Rule Base for Forecasting Taiwan Electronic 
Companies’ Stock Return and ROE Performance 
 
I  Introduction 
 
As the world’s economy continuously grows and thanks to the advances in 
information technology, the financial markets today have thus hold closer impact to the 
people around the world. Among a variety of financial markets, the stock market is one 
of the most popular fields for the researchers and investors to perform their researches 
and investment business, respectively (Chen & Chen, 2006). Normally, the stock market 
can be regarded as a window reflecting a nation’s economy situation. It can be observed 
that usually the better the nation’s economy grows, the higher the stock indices (such as 
Russell 2000 or NASDAQ) will be. The stock indices are thus a measure of average 
stock prices, which are numeric gauges of broad market performance. Sometimes, to the 
investors, who may not only keep his eyes on the stock indices, but are also more 
interested on tracing individual company’s stock performance. In such a way, if some 
individual stocks are carefully chosen and dealt within appropriate time period, the 
higher return on stock investment can be expected and may outperform stock indices 
(Murthi, Choi, & Desai, 1997). How to identify those potential stocks (companies) in 
stock exchange is thus an interesting issue worth our attention.    
From the investment perspective, if higher stock return is the main interest to an 
investor, then one direct way to select such stocks can be straightforwardly based on 
stock return forecast. The investors may directly consult to financial experts, or 
implement certain tools (see, for instance, Kavajecz & Odders-White (2004), and Chen, 
-6- 
ANN being implemented is the so-called back-propagation neural network. 
Among the numerous symbolic learning algorithms to uncover the hidden 
knowledge from ANN, currently the methods being frequently applied may roughly 
categorized into two types known as decomposition (Towell & Shavlik, 1993; Andrews 
& Geva, 1994; Duch, Craven, 1996, Adamczak, & Grabczewski, 2001) and pedagogical 
(Craven, 1996; Schmitz, Aldrich, & Gouws, 1999; Taha and Ghosh, 1999) methods, 
respectively. The basic concept of decomposition methods is to perform searching 
process for mapping a well trained ANN into IF-THEN rules. Such kind of methods 
could suffer a serious computational loading issue as the dimension of input vector 
grows the computational time complexity will be exponentially increasing and thus 
requiring a pruning procedure for down-sizing the tree structure. The methods known as 
SUBSET (Towell & Shavlik, 1993), RULEX (Andrews & Geva, 1994), and 
C-MLP2LN (Duch, Adamczak, & Grabczewski, 2001) all belong to this field. 
Pedagogical approaches, however, treat the trained ANN as a black box, and extracting 
rule from ANN in terms of observing the relationship between both the ANN inputs and 
outputs. The typical methods within this family may be referred to TREPAN (Craven, 
1996), ANN-DT (Schmitz, Aldrich, & Gouws, 1999), and BIO-RE (Taha and Ghosh, 
1999).  
According to the studies shown by Ford, Browne, & Whitley (2000), Milaré, 
Carvalho, & Monar (2002), and Browne, Hudsonb, Whitley, Fordb, & Pictonc (2004), 
from the perspectives of both accuracy and the understandability to the resulting 
decision tree structure, TREPAN algorithm is the better candidate for solving the rule 
extraction issue, and therefore will be the one implemented in this study to accompany 
the ANN to proceed the experiments. It should be also noted that the ANN tested in this 
study is the so-called feed-forward neural network (FNN) with back-propagation 
-8- 
namely, the input layer, the hidden layer (there may be more than one hidden layer), and 
the output layer. These layers are connected by the interconnection weights. During the 
training stage, the data is fed into the input layer, and each neuron performs a mapping 
function which transforms the received data. The prompt output from the neuron is then 
multiplied by the connected weights, and delivered to the corresponding neuron in the 
next layer until the output layer is reached. When each forward pass is complete, the 
values generated by the neurons in the output layer will be compared with the 
corresponding expected outputs. The resulting differences between the actual output and 
the expected output are treated as network error. This error is distributed (starting at 
output layer) through the FNN by a backward pass, which updates the weights. The 
forward and backward processes are continued until the network has been well trained. 
Please note that this article does not provide detailed introduction to the FNN, but 
instead referred the interested readers to Tso & Mather (2001) for further detailed 
discussions. One of the exemplar FNN (structured by 6x5x1) used in this study is shown 
in Figure 1. 
 
Input Layer
Hidden Layer
Output Layer
 
 
Figure 1. The artificial neural network used in this study. 
 
 
-10- 
TREPAN simultaneously maintains a queue of leaf nodes according to corresponding 
priority, and successively expands the node at the head of the queue into a father node 
with two children. Also during the decision tree forming process, new child nodes of 
non-zero priorities are added into the queue. The process terminates under the certain 
circumstances previously being defined have been reached.  
    Another distinct feature of TREPAN is that it implements a so-called oracle to 
determine the class predicted by the neural network for each instance presented to it. 
Specifically, TREPAN generated additional input patterns by sampling the empirical 
distributions of the original training data and applies oracle to determine class labels for 
the tree leaves and to choose splits for creating tree’s internal nodes. The generation of 
new input patterns is based on the marginal distributions of the instances, and disregards 
the correlations among the instances. These newly generated training instances are used 
alongside the original training data to subject to the decision tree expanding process. 
Once a node is created, it will guarantee that sufficient training instances are generated 
so that a pre-specified minimum number of instances can reach the node. This distinct 
feature of TREPAN makes it have superior advantage over other decision tree methods 
in which, as the tree grows, the number of training instances reaching a node decreases, 
until there are inadequate instances to expand the decision tree further.  
    TREPAN has been used to extract rules from neural networks trained in a variety 
of problem domains including gene identification in DNA, telephone-circuit fault 
diagnosis, exchange-rate prediction, and elevator, etc. (see, for instance, Browne et al., 
2004, and Chen & Li, 2006). However, the potentials of TREPAN accompanied with 
FNN in stock return relating prediction issues are quite seldom and worth putting more 
study effort to investigate this interesting field. 
 
-12- 
III Design of Experiments 
1. The experiments domain 
As stated in previous, the main objectives of this study is to conduct the 
companies’ stock return and ROE predictions, respectively. The data set being used is 
according to the database provided by ‘Taiwan Economic Journal-TEJ’ (2006), which 
provides Taiwan (also Asia) financial data analysis and contains the details about the 
companies’ up to date information in the market of stock exchange. The companies 
being selected from the database for this study all belongs to the category of electronic 
companies in Taiwan stock exchange. The study periods cover 20 seasons in total, from 
the third season of year 2000 to the end of second season of year 2005. Overall, 166 
electronic companies satisfying the information demand within the defined period are 
selected, and are shown in Table 1. It is noted that, in recent years, the production value 
made by the electronic companies in Taiwan have continuously been in the leading 
place over the world. Also, the electronic companies trading volume in Taiwan stock 
exchange normally covers at least 70% of the total daily trading volume and values. 
These electronic companies certainly not only play a major role in Taiwan economy, but 
also hold close relationship with investors, and thus trigger our study interest. 
2. FNN input and output variables 
To conduct companies’ stock return and ROE predictions in terms of FNN, there 
are a variety of variables can be used as inputs, such as the variables relating to global 
economic indices, financial ratios, and technical indices, etc. Only fundamental factors 
are taken into concern in this preliminary study. Particularly, financial ratios reflect 
companies’ accounting aspect, which are also more directly relating to companies’ 
fundamental situation (Lev & Thiagarajan, 1993). This study thus mainly concentrates 
-14- 
time period of the 3rd season of year 2000 to the 4th season of year 2003 are chosen as 
training samples, while the rest 6 seasons are treated as test samples. Specifically, the 
test samples are of 996 (166 companies by 6 seasons) in total, and overall 249 
companies samples (top 25% ROE) are of interest. In the second stage of experiment, 
the aim is to discover if the companies’ stock returns outperform the average stock 
returns (i.e. Taiwan Electronics-TRI in our case) (TSEC, 2006). The ways of selecting 
training and test samples are similar to the experiment one, except that the ROE is 
added as one more input variable to FNN for stock return predictions. After the FNN 
completes the training, the TREPAN algorithm is then applied to FNN to conduct rule 
extraction task. The result of decision tree output by TREPAN will be compared with 
FNN to evaluate the performance of both methods.  
 
IV Experimental Results and Discussions 
 
For predicting the companies which hold top 25% ROE upon the next season, the 
FNN with the structure 6x5x1 (Figure 1) specified in previous is built and trained. After 
the FNN is converged, the test samples are then fed into the FNN to evaluate the 
accuracy. It reveals that, for predicting the companies of top ROE, a total of 70.68% 
(176 among the total 249 samples being correctly identified) of accuracy is achieved. 
Please note that the accuracy evaluated in this stage only takes the companies with top 
25% ROE into account, rather than use overall accuracy (i.e., including all the 996 test 
samples). It is believed that, in such a way, the accuracy shown will not be over 
estimated and thus be more objective.  
The TREPAN algorithm is also used to extract binary decision tree from the 
completely trained FNN. Result of the decision tree formed by TREPAN algorithm is 
-16- 
partially fulfilled (i.e. 2 of 3, in this case). This is a particular characteristic hold by 
TREPAN to generate compact expression of a decision tree. Somehow, in the case of 
node 1 and 9, if one would like to apply more strict conditions to identify top ROE 
companies, one may eliminate lower threshold (i.e. delete the condition of ROA < 
0.6945 in node 1 and PBR < 0.272 in node 9) so as to make the condition fulfillment 
simpler, but the overall accuracy of predictions may not identical to that output by FNN, 
because some traces may be misleading. Based on Figure 2, to identify the companies 
of top 25% ROE, it can be in terms of 3 traces as shown in Table 2. For the companies 
being outside the top 25% ROE can be inferred in the similar way.  
 
Table 2. The three traces for identifying companies of top 25% ROE. .  
 
No Trace Rule description 
 
1. 
 
1→3→5→7 
IF (ROA>0.695 & EPS>0.585) and EPS>0.521 
and ROA>0.763 THEN ROE is Top. 
 
 
2. 
1→3→5→6→
14→21 
 
IF (ROA>0.695 & EPS>0.585) and EPS>0.521 
and ROA<0.763 and GP<0.663 and PBR>0.336 
THEN ROE is Top. 
 
 
3 
 
1→2→9→11
→17→19 
 
IF 2 of {ROA<0.695, EPS<0.585, ROA<0.763} 
and ROA>0.644 and (PBR>0.272 & Foreign> 
0.288) and EPS>0.408 and Debt>0.362 THEN  
ROE is Top. 
 
 
For evaluating the prediction accuracy performed by TREPAN decision tree, 
totally 996 samples are fed again, and the overall accuracy of 61.84% (154 samples are 
-18- 
not, according to seven input variables and structure (7x5x1) as specified in previous. 
Please note that the numbers of companies out-performing Electronics-TRI at each 
season are different. The accuracy analyzed in this stage will be calculated from all the 
996 test samples. After all, totally 61.75% (615 out of 996 test samples) accuracy is 
achieved. The resulting TREPAN decision tree is shown in Figure 3. Please note that, 
within the decision tree, nodes number from 14 to 19 have been automatically 
eliminated by the TREPAN algorithm, because those six nodes, during the stage of 
decision tree evolving process, all are the descendants of leaf nodes. Although there are 
totally seven inputs feeding into the FNN, the decision tree generated by TREPAN 
algorithm only takes four variables, namely PBR, EPS, ROE, and Foreign, while the 
variables GM, TD/TA, and ROA are not considered by the TREPAN. At the end, eight 
decision rules are formed to predict the companies’ stock returns.  
 
Table 3. The results of Logistic regression for sequentially selecting variables. 
 
Step 
No. 
Selected 
Variables 
Parameters 
Estimated 
Standard 
Error 
Wald 
Chi-Square 
Significance 
 
1 
 
PBR 
Intercept 
1.946 
-0.852 
0.179 
0.071 
118.398 
145.935 
y 
y 
 
2 
EPS 
PBR 
Intercept 
-1.539 
2.855 
-0.361 
0.255 
0.239 
0.106 
36.307 
142.745 
11.507 
y 
y 
y 
3 
 
EPS 
PBR 
ROE 
Intercept 
-2.999 
2.823 
2.220 
-1.085 
0.356 
0.242 
0.360 
0.160 
70.822 
136.359 
38.134 
45.746 
y 
y 
y 
y 
4 
 
Foreign 
EPS 
PBR 
ROE 
Intercept 
1.087 
-3.341 
2.549 
2.156 
-0.983 
0.195 
0.364 
0.245 
0.360 
0.161 
30.953 
84.187 
107.840 
35.814 
37.186 
y 
y 
y 
y 
y 
-20- 
The four exemplar rules and traces for identifying better stock return companies 
are shown in Table 4. The 996 test samples are fed into decision tree and to evaluate the 
accuracy. Interestingly, the overall of 62.35% (621 out of 996 samples) precision is 
achieved, which is even higher than the result obtained by the FNN. After the 
comparison, the results correctly classified by both methods hold 83.53% identicalness. 
From the both experiments for ROE and stock return predictions shown in this study, it 
is proved that TREPAN algorithm is an ideal tool to extract rules from FNN, since the 
results performed by FNN and TREPAN hold around 80% similarities, the rules 
expressed in terms of TREPAN are quite in a compact form. Both predictions for ROE 
and stock return using ANN and rule base inducted by TREPAN are summarized in 
Figure 4. This study indeed shows that to translate FNN ‘Black Box’ into transparent 
knowledge is possible for financial issues predictions. The results will be valuable to 
improve the speed and correctness of building financial expert systems for investors’ 
reference and consultancy. 
 
70.68
61.7561.84
62.35
79.22
83.53
0
20
40
60
80
100
ROE Stock Return
Subject of Prediction
P
er
ce
n
ta
g
e(
%
)
ANN
Rule Base
Similarity
 
Figure 4. The comparisons of performances between back-propagation ANN and TREPAN 
algorithm for both ROE and stock return predictions, respectively. 
-22- 
Appendix ─ Introduction to Financial Variables 
(http://www.investopedia.com/dictionary) 
1. Total Debt to Total Assets (TD/TA): Used to measure a company's financial risk by 
determining how much of the company's assets have been financed by debt. 
Calculated by adding short-term and long-term debt, and then dividing by a 
company's total assets. 
2. Return on Assets (ROA): A useful indicator of how profitable a company is relative 
to its total assets. Calculated by dividing a company's annual earnings by its total 
assets, ROA is displayed as a percentage. Sometimes this is referred to as Return on 
Investment. 
3. Earning per Share (EPS): Total earnings divided by the number of shares 
outstanding. 
4. Price to Book Ratio (PBR): A stock's capitalization divided by its book value. The 
value is the same whether the calculation is done for the whole company or on a 
per-share basis. This ratio compares the market's valuation of a company to the 
value of that company as indicated on its financial statements. The higher the ratio, 
the higher the premium the market is willing to pay for the company above its hard 
assets. A low ratio may signal a good investment opportunity. 
5. Gross Margin (GM): The gross profit margin gives an indication on whether the 
average mark up on goods and services is sufficient to cover expenses and make 
profit. It does give a good indication of financial health. It is calculated by 
company's total sales revenue minus cost of goods sold, divided by the total sales 
revenue, expressed as a percentage. 
6. Foreign: The percentage of total shares outstanding hold by non-Taiwan companies. 
Such company with securities trading on Taiwan market. 
7. Stock Return: The rate of return on stock is equal to the increase in the share price, 
plus the dividend yield. 
8. Return on Equity (ROE): A measure of a corporation's profitability, calculated as 
Net Income divided by Shareholder’s equity. Essentially, ROE reveals how 
much profit a company generates with the money shareholders have invested in it. 
 
 
 
 
 
-24- 
Deng, Z., B. Lev and Narin, F., 1999, “Science and Technology as Predictors of Stock 
Performance,” Financial Analysts Journal 55, 20-32. 
Duch, W., R. Adamczak, and K. Grabczewski, 2001, “A new methodology of extraction, 
optimization and application of crisp and fuzzy logical rules,” IEEE Transactions on 
Neural Networks 11, 1-31. 
Dunis, C. L., and J. Jalilov, 2001, “Neural Network Regression and Alternative 
Forecasting Techniques for Predicting Financial Variables,” Neural Network world 
12, 113-139. 
Ford, M., A. Browne and D. Whitley, 2000, “A comparison of Neural Network and 
Symbolic Techniques,” BBSRC Bioinformatics Grantholders Workshop, Wellcome 
Trust Genome Campus, Hinxton, http://www.cmd.port.ac.uk/biomine/. 
George, J. H., P. Miller and R. Kerber, 1996, “Stock selection using rule induction,” 
IEEE Transactions on Intelligent System 11, 52-58. 
Hüsken, M. and P. Stagge, 2003, “Recurrent Neural Networks for Time Series 
Classification,” Neurocomputing 50, 223-235. 
Jasic, T. and D. Wood, 2004, “The profitability of daily stockmarket indices based on 
neural network predictions,” Applied Financial Economics 14, 285-297. 
Jiang, S. S., 2006, “Rule Extraction from Neural Networks－A Study for Financial 
Performance Prediction of Taiwan Listed Companies,” unpublished Master 
dissertation, National Defense Management College, Taiwan.  
Kavajecz, K. A. and E. R. Odders-White, 2004, “Technical analysis and liquidity 
provision,” Review of Financial Studies 17, 1043-1071. 
Lev, B., and R. Thiagarajan, 1993, “Fundamental Information Analysis,” Journal of 
Accounting Research 31, 190-215. 
