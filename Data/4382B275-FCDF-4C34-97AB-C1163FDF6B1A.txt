 2
 
???????????????????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????? 
 
?????????????????????
(SpchAUD)??????????????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????
????????????? 
 
 
????????? 
 
3-1???????????? 
 
???????????????????????
???????????????????????
?????????? [Douglas, 2001]??????
???????????????????????
???????????????????????
???????????????????????
???????????????????????
???????????? 2x2?????????
?????? 
Asx =        (1) 
 
Source S1 
Source S2 
Mic X1
Mic X2 
Matrix A 
 
??  ?????????? 
 
???????????????????????
???????????? 
dAsx +=      (2) 
??d???????0????????????
? s?????????????????????
?B????????? sˆ????? s 
Bxs =ˆ       (3) 
? ? ? ? ? ? ? ? ? ? ? ? ? (Independent 
Component Analysis , ICA) [Comon, 1994]??????
??????????????????? 0???
?? 1 ????????????????
(Centering)??????????????????
??? 0???????????(Whitening)???
?x???????????? x~????????
?(uncorrelated)????? 1?????? 
Ixx =}~~{ TE        (4) 
??????? Eigen-value decomposition?????
???x?????? 
TTE VDVxx =}{               (5) 
V??????? eigenvector???D????? 
},...,,{ 21 nddddiag=D    (6) 
???????? 
sAAsVVDxVVDx ~~ 2/12/1 === −− TT  
                             (7) 
? 
IAIAAssAxx === TTTT EE ~~~}{~}~~{  (8) 
???????B?? 
TAB ~=                      (9) 
 
???????????????????????
???????????????????????
??????????????????? 
][][][ nnn shx ∗=     (10) 
????????? 
)()()( ωωω SHX =     (11) 
 
???????????????????????
???????????????????????
??????????????????????
??????????????????(dilation)?
??(permutation)????????????????
?????????Murata???[Murata, 1998]?
???????????????????????
????????????????????0??
??????????????????0????
?????????????? 
 
?????????????(sign-to-interference 
Ratio, SIR)??????????????????
????????????(1)?????????(2)
????????(3)????????????? 
[Tong, Soon, Huang, and Lin, 1990] ????????
?????????????????? 
 
 4
( ) ( )( )l
ll
,~
,
,~ 2
min
2
k
kX
k σγ =
    (24) 
( ) ( )( )l
ll
,~
,~,~
min
2
k
kk xσ
σζ =     (25) 
?????????????? 



<<<
−−
<≤
=
otherwise
kk
k
kk
kp
,0
),(~,),(~1
),1/(),(~(
),(~,1),(~,1
),(
11
11
1
ζζγγ
γγγ
ζζγ
ll
l
ll
l  
        (26) 
???? 6.1,0.3 11 == ζγ ? ????? xα ?? 

 <=
otherwise
kkkx ,1
)(),(~,8.0),( δζα ll   (27) 



≤<
≤<
≤≤
=
HM
ML
L
kkk
kkk
kk
k
,5
,3
0,3.1
)(δ   (28) 
HML kkk ,, ?????? 1 kHz?3 kHz?? 8 kHz? 
 
???????????????????????
???????????????????????
????(Log-spectral amplitude, LSA) [Ephraim and 
Malah, 1985] [Marin, 2001] ???????????
????????? SNR????????????
????????????????? 
 
??  SNR???? 
 ???? ???? ????
?????? -5.5 dB -5.4 dB -4.8 dB 
?????? 2.2 dB 2.1 dB 2.8 dB 
?????
(MCRA??
??+???
?)????? 
4.7 dB 5.1 dB 5.6 dB 
?????
(MCRA??
??+LSA) ?
???? 
7.6 dB 8.2 dB 8.4 dB 
 
  
(a) ?????? 
 
  
(b) ?????? 
 
  
(c) ?????(MCRA????+????) ????? 
 
  
(d) ?????(MCRA????+LSA) ????? 
??  ?????????????? 
 
3-3???????? 
 
???????????????????????
????????????????????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????
??????????????????????
(silence)???(sonorant)?????(obstruent)???
???????????????????????
???????????????? [Sung and Wang, 
2006]?????????????????????
??????????????????????
???????????????????????
?????????? 
 
????????????????? SpchMOD?
??????????????????????
???????? 
(1) ????????????????????? 
(2) ?????????????? 
(3) ?????????????? 
(4) ????????????? 
(5) ????????????????????? 
???????????????????????
???????????????????????
??????????? 
 
1. ????? 
??????? Direct X????????SpchMOD?
????????????? 
Windows Installer – KB893803-v2-x86.exe 
dotnet fx.exe 
directX_apr2007_redist.exe 
???????????????? SpchMOD ?
?? 
 
2. ?? SpchMOD ??????????????
????????? 
(1) ?????????????????????
 6
 
 
??  ?????????? 
 
??????? 
 
???????????????????? 
 
1. ?????????????????????
?????????????????????
?????????????? 
2. ?????? MCRA ???????????
?????????????????????
?? 
3. ??????????(??? SpchMOD)??
?????????????????????
?????????????????????
?????????????????????
??????????? 
4. ?????????(SpchAUD)??????
???????????????????
SpchMOD????????????????
???????????? 
 
???????????????????????
???????????????????????
???????????????????????
?????????????????????
SpchAUD? SpchMOD?????????????
??????? SpchAUD ???????????
???????????????????????
???????????????????????
???????????????????????
???????????????????????? 
 
 
???????? 
 
???????????????????????
???????????????????????
???????????????????????
???????????????? SpchAUD ??
??????????????????????
???????????????????????
?????????????????? 
 
 
?????? 
 
[1] Cohen and B. Berdugo, “Speech enhancement for 
non-stationary noise environments,” Speech 
Processing, vol. 81, pp. 2403-2418, 2001. 
[2] Cohen and B. Berdugo, “Noise estimation by 
minima controlled recursive averaging for robust 
speech enhancement,” IEEE Signal Processing 
Letters, vol. 9, pp. 12-15, 2002.  
[3] P. Comon, “Independent component analysis – A 
new concept?,” Signal Processing, vol. 36, pp. 
287-314, 1994. 
[4] S. C. Douglas, “Blind separation of acoustic 
signals,” in Microphone arrays (Eds. M. Brand 
stein and D. Ward), pp. 355-380, Springer, 2001. 
[5] Y. Ephraim and D. Malah., "Speech enhancement 
using a minimum mean-square error log-spectral 
amplitude estimator,"  IEEE Trans. Acoustics, 
Speech, and Signal Processing, vol. 33, 443-445, 
1985. 
[6] J. E. Greenberg and P. M. Zurek, “Microphone 
array hearing aids,” in Microphone arrays (Eds. M. 
Brand stein and D. Ward), pp. 229-253, Springer, 
2001. 
[7] Hoshuyama and A. Sugiyama, “Robust adaptive 
beamforming,” in Microphone arrays (Eds. M. 
Brand stein and D. Ward), pp. 87-109, Springer, 
2001. 
[8] Pei-Fen Huang, Kuei-Chun Huang, Hsiao-Chuan 
Wang, and Huei-Mei Liu (2006), “Using a speech 
audiometry system to improve the ability of speech 
discrimination and pronunciation in children with 
hearing impairment,” Bulletin of Special Education, 
vol. 31, pp. 115-137, 2006.  
[9] R. Marin, “Noise power spectrum density 
estimation based on optimal smoothing and 
minimum statistics,’ IEEE Trans. Speech and 
Audio Processing, vol. 9, 504-512, 2001. 
[10] N. Murata, S. Ikeda, and A. Ziehe, “An approach 
to blind source separation based on temporal 
structure of speech signals,” Proc. IEEE Int. Conf. 
Artificial Neural Networks, 1998. 
[11] L. Tong, V.C. Soon, Y.F. Huang, and R. Lin, 
“AMUSE: A new blind identification algorithm,” 
Proc. IEEE International Symposium on Circuits 
and Systems, New Orleans, 1990, pp. 1784-1787. 
[12] K. T. Sung and H. C. Wang, “A Study of 
knowledge-based features for obstruent detection 
and classification in continuous Mandarin speech,” 
Proc. ISCSLP 2006, Singapore, 2006.  
 
?????? 1998??????????????????????????
???????????????????????????????????
???????????????????????????????????
?????????? Advance in Chinese Spoken Language Processing??World 
Scientific???????? 23???CSLP Corpora ad Language Resources???
???????? 183???????????? 74??? Springer-Verlag?
?Lecture Notes in Artificial Intelligence, LNAL 4274????????????A 
Study of Knowledge-Based Features for Obstruent Detection and Classification in 
Continuous Mandarin Speech??????? 
 
 
?????? 
 
Oriental COCSDA???????????????????????????
?????????????????????????????? 1997??
???????????????????????????????????
???????????????????????????????????
??????????????????? 2006?? Oriental COCSDA???
??????????????????? 
 
ISCSLP??????????????????????????????
???????????????????????????????????
???????????????????????????????????
???????????????????????????????????
???????????????????????????????????
??????????????????????????????????
???????????????????????????? 
 
 
???? 
 
Oriental COCOSDA Workshop??????????????????????
???????????????????????????????????
?????????????1999????? Oriental COCOSDA Workshop??
???????????????????? 
 
ISCSLP???????????????????????????????
???(2002?)???????????????????????????? 
A Study of Knowledge-based Features for 
Obstruent Detection and Classification 
in Continuous Mandarin Speech 
Kuang-Ting Sung , Hsiao-Chuan Wang 
 
Department of Electrical Engineering,  
National Tsing Hua University, Hsinchu, Taiwan 
g935925@oz.nthu.edu.tw, hcwang@ee.nthu.edu.tw  
Abstract. A study on acoustic-phonetic features for the obstruent detection and classification 
based on the knowledge of Mandarin speech is proposed. Seneff auditory model is used as the 
front-end processor for extracting acoustic-phonetic features. These features are rich in their 
information content in a hierarchical decision process to detect and classify the Mandarin 
obstruents. The preliminary experiments showed that accuracy of obstruent detection is about 84%. 
An algorithm based on the information of feature distribution is applied to further classify the 
obstruents into stops, fricatives, and affricates. The average accuracy of obstruent classification is 
about 80%. The proposed approach based on the feature distribution is simple and effective. It 
could be a very promising method for improving the phone detection in continuous speech 
recognition. 
Keywords: knowledge based approach, obstruent detection, obstruent classification 
1   Introduction 
In typical Automatic Speech Recognition (ASR), a set of features is defined to specify 
the characteristics of speech in each frame. This set of features is used for recognizing 
all speech units. The statistical models based on this set of features are generated 
using speech databases. However, the corpus-based speech recognition approach 
cannot catch the specific characteristics of each individual phone, so that the 
performance of ASR is far from the performance of human speech recognition. 
Toward the next generation ASR, a paradigm integrating the knowledge sources with 
the recognition system was proposed [1][2]. This approach is based on the knowledge 
of articulatory phonetics and acoustic landmarks. Obstruents are the potential 
landmarks for ASR. Due to their noisy, dynamic, relatively short, weak, speaker- and 
context-dependent nature, the automatic detection and classification of obstruents are 
the most challenging tasks. 
This study concerns the extraction of acoustic-phonetic features for the detection 
output and the synchrony detector (SD) output. Each output is a set of 40 components 
corresponding to 40 Bark-scale filters. The envelope detector (ED) output is the 
mean-rate output which enhanced sharpness of onset and offset of speech segments. 
The synchrony detector (SD) output can be modified to the Average Localized 
Synchrony Detector (ALSD) output [5] which enhances spectral peaks due to vocal 
tract resonances. Our system is designed to use two kinds of outputs, ED and ALSD, 
for the extraction of acoustic-phonetic features. Fig. 2 demonstrates the example of 
ED output and ALSD output. 
 
 
 
Fig. 2. An example of the outputs of ED and ALSD. 
3   Detection of Obstruents 
To perform the obstruent detection, we categorize speech signal into three kinds of 
events, i.e., silences, sonorants, and obstruents. Fig. 3 shows the training phase and 
the testing phase of the obstruent detection. The 3-stage process starts with silence 
detection and follows by sonorant detection and obstruent detection. Finally, it uses 
continuity constraints to obtain the detection results.  
 
 
 
A frame is said to be a silence if either one of the following criteria is satisfied. 
(1) Both jEDABNE ,  and jALSDABNE ,  are less than their corresponding thresholds.  
(2) jEDHBNE ,  is less than the threshold. 
 
 
Fig. 4. Histograms of features used for silence detection. 
 
3.2   Sonorant Detection 
Next step is to detect sonorants in the speech signal. Three features are designed for 
the sonorant detection; the low-band energy from ALSD ( jALSDLBE , ), the all-band 
energy from ALSD ( jALSDABE , ), and the largest spectral peak location from ALSD 
( jALSDLSPL , ). 
8
,
1
ALSD j ij
i
LBE ALSD
=
= ∑  (4) 
40
,
1
ALSD j ij
i
ABE ALSD
=
= ∑  (5) 
}max{arg, ij
i
jALSD ALSDLSPL =  (6) 
 
Fig. 5 shows the histograms of three features. The threshold of equal error rate 
(EER) for for each feature in discriminating the sonorant is marked. 
 
 
40 10
,
31 1
( ) /( )ED j ij ij
i i
HLR ED ED
= =
= ∑ ∑  (9) 
 
Fig. 6 shows the histograms of five features with the thresholds for discriminating 
the obstruent. 
A frame is said to be an obstruent if either one of the following criteria is satisfied. 
(1) jALSDLBE ,  is less than the threshold 
(2) Both jALSDLSPL ,  and jEDSCG ,  are greater than their corresponding 
thresholds. 
(3) jEDHLD ,  is greater than the threshold. 
(4) jEDHLR ,  is greater than the threshold. 
 
 
 
Fig. 6. Histograms of features used for obstruent detection. 
3.4   Post Processing 
When a frame does not belong to any of three categories, an additional process is 
required to assign the undefined frame to a category of its closest neighbor frames. 
Other criteria for adjusting the detection result are based on the phonetic knowledge 
of Mandarin speech; (a) The duration of sonorant must be longer than three frame 
shifts (32 ms), (b) A segment must be ended with a sonorant, and (c) A single 
obstruent can not be a segment. An example of the obstruent detection is shown in Fig. 
Fig. 8. System flow chart of obstruent classification. 
 
Six features are used in GMM classifier. They are the segment duration ( DUR ), the 
average zero crossing rate ( jAZCR ), the spectral center of gravity from ED ( jEDSCG , ), 
the energy difference between high-band and low-band from ED ( jEDHLD , ), the 
energy ratio of high-band to low-band from ED ( jEDHLR , ), and the 
rate-of-rise-to-duration ratio (RRDR). The RRDR is computed by the following 
equations [6]; 
DUR
RR
RRDR
jj
}{max
=  (10) 
where 
}{max
)(
jj
jjj RE
NSCGCCSDRERR ×+=  (11) 
)()()( jjjj HBECCSDMBECCSDLBECCSDRE ++=  (12) 
13
,
1
ED j ij
i
LBE ED
=
= ∑  (13) 
27
,
10
ED j ij
i
MBE ED
=
= ∑  (14) 
40
,
37
ED j ij
i
HBE ED
=
= ∑  (15) 
))(()( •=• differencesmoothedclippingcenterCCSD  (16) 
 
Fig. 9 shows the histogram of six features.  
 
obstruent 2.7 12.9 84.4 
 
Table 3.  Accuracy of obstruent classification (%).  
 detected as stop detected as affricate detected as fricative 
stop 92.2 5.2 2.6 
affricate 8.6 74.3 17.1 
fricative 10.9 19.6 69.5 
 
From Table 2 we can find that the error rate of obstruent detection is about 15.6%. 
Table 3 shows that the average accuracy rate of obstruent classification is about 80%. 
Among the obstruents, stops get highest accuracy (92.2%). 
6   Conclusions 
This paper presents a preliminary study on the features for obstruent detection and 
classification in Mandarin Chinese. A method based on the combination of 
acoustic-phonetic knowledge and statistical models is proposed to detect silences, 
sonorants, and obstruents in the continuous Mandarin speech. The GMM method is 
applied to classify the obstruents into stops, affricates, and fricatives. The 
computation is simple and efficient. However, the accuracy rate of the proposed 
method is still low. To get more improvement, other feature selections and front-end 
processors need to be investigated. 
 
Acknowledgments. This research was partially sponsored by the National Science 
Council, Taiwan, under contract number NSC94-2213-E007-021. 
References 
1. Chin-Hui Lee, "From Knowledge- Ignorant to Knowledge-Rich Modeling: A New Speech Research 
Paradigm for Next Generation Automatic Speech Recognition", in International Conference on 
Spoken Language Processing, ICSLP2004, Plenary Session , Jeju, Korea. 
2. Kenneth N. Stevens, "Toward a model for lexical access base on acoustic landmarks and distinctive 
features", in J. Acoust. Soc. Am. 111 (4), pp. 1872-1891, April 2002. 
3. Seneff, S., "A Joint Synchrony/ Mean Rate Model of Auditory Speech Processing", J. Phonetics, 16, 
pp. 55-76, 1988. 
