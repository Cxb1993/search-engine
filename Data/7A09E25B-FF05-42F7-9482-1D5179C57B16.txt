 -2- 
求，資料儲存節點會將資料傳遞給發出查詢請求之節
點，感測節點不只要將感測資料傳遞至資料儲存點，
另外也要幫忙傳遞查詢請求之封包。使用 DCS 機制
感測節點可以找尋到其資料儲存節點，而當查詢請求
之頻率高於資料儲存節點之負荷時，資料儲存節點需
要耗費更多能量進行處理所有請求之查詢。因此，大
量的查詢請求會引起資料儲存節點之能量快速用
盡，而這現象我們稱為查詢熱點(query hotspot)之問
題。 
而為了解決查詢熱點之問題，在本計畫中提出利
用資料複本的方法來解決，而該方法為可動態資料複
本(Adjustable Data Replication, ADR)之方法。ADR是
以網格(grid)為基礎的資料複本的方法，它可減緩大流
量之查詢熱點問題產生，資料儲存節點會收集統計其
鄰居節點傳遞來的查詢封包頻率並且當資料儲存節
點的流量頻率較高時，會將資料儲存節點的資料複製
傳遞至其他節點，使其結點包含相同的儲存資料，而
接收到相同資料之節點，我們稱為複本節點。而當複
本節點只接受到少許的查詢請求時，本計畫所提出的
ADR 可以動態刪除複本節點並且將所複本節點組成
建立路由樹(routing tree)，該方式可以節省更多能量的
消耗。 
貳、文獻探討 
在 DSC 路由協定中，查詢請求資料節點強調於
資料儲存與資料複本的建置[9] [17]。而感測節點為了
將大量資料傳遞到下一節點使其資料更靠近查詢請
求節點是需要耗費更多的能量。為了將資料傳遞至查
詢請求節點是應用感測節點之通訊範圍經其他感測
節點進行傳遞，而靠近查詢請求節點之鄰近節點為了
彙集其他節點傳遞給查詢請求節點的資料進行傳遞
會造成能量快速的消耗，我們稱該現象為 sink-hole之
問題[5] [14]。相關資料儲存節點為目標的查詢請求之
研究，已有些研究已經提出不同的解決方法。 
Grid-based Data Replication(GDR) [4]方法是用來
減緩資料儲存資料節點之流量。在 GDR 裡，資料儲
存節點會計算出該負責之邊界節點並且計算通過邊
界節點進行資料儲存節點請求查詢之頻率。而當請求
查詢頻率高於所設定之門檻值，資料儲存節點會產生
出一複本節點，而新的複本節點與資料儲存節點會重
新計算其該負責之邊界節點，然後資料儲存節點與複
本節點負責之邊界節點會根據請求查詢的頻率是否
再產生複本節點。 
Dynamic Replica Arrangement on Concentric Cir-
cular Arcs (DRACA) [10]是基於同心圓方式進行建立
新的複本節點，而複本節點的位置會越來越靠近經常
請求查詢之節點。複本節點建立後並且會在圓弧上建
立指標節點(pointers)並且當請求查詢封包傳遞至指
標節點會將封包傳遞路徑指向複本節點。當複本節點
接收到請求查詢之要求即會將其資料傳遞至請求查
詢節點，而請求查詢節點即會利用最小的能量來查詢
請請資料與接收資料。DRACA 的複本節點是根據查
詢頻率的地理分布來建立，新的複本節點與指標節點
會根據查詢頻率的增減來進行建立。 
DRACA 優點的部分是在於安排複本節點在位置
接近請求查詢節點頻繁發送查詢。GDR的第一個複本
節點可以減緩了近一半的查詢頻率。但 DRACA 和
GDR也有一個主要缺點是，當複本節點不使用，他們
不能立即刪除。DRACA 複本節點是在最外面的位置
並直到最外層的節點，複本節點才可以被移除。
GDR，因為後面製作複本節點是基於邊界前的複製，
因此，建立複本必須不斷改變邊界節點，重新建立了
邊界節點。在移除部份，GDR必須由最新的複本節點
來決定是否刪除全部的複本節點上之資料。但通常在
外部的複本節點往往是重要的分攤責任且分散請求
查詢之流量並且減少請求查詢節點距離。 
參、研究方法 
一、 研究假設與網路架構 
以下為本計畫所做的基本假設： 
 在我們監測的區域是部署大量無線感測節點，並
且節點和節點是可以互相溝通。 
 無線感測節點是靜止不動，能源是有限的並且不
可補充，資料的傳輸、接收和計算是最主要的能
源損耗。 
 每個無線感測節點都是同質性的，無線傳輸通道
是雙向的且對稱的，且知道地理位置，可以使用
GPS[6]或者是其他的方法得知[2] [15]。 
 每個感測節點存儲的資料和查詢方法是基於
Geographic Hash Table (GHT) [17]存儲方式，且資
料封包的發送與接收是使用 Greedy Perimeter 
Stateless Routing (GPSR) [11]之方式進行。 
 在本計畫中，任何的行動節點(使用者移動設備，
例如 PDA)皆可進行查詢請求感興趣之資料。而我
們的方式皆於其他 DCS之方法一樣。 
本計畫系統模型利用地理資訊將無線感測網路
分為許多的網格(virtual grids)。地理資訊的獲得可以
利用全球定位系統(GPS)提供這項服務。每個 GPS 衛
星傳送信號到地面上的無線感測器上並且指出他目
前的位置和時間。每個感測器透過估計的信號的到達
所花費的時間的並且利用 GPS 衛星估計距離。當感
測節點收到來自 4 個 GPS 衛星的距離被接收計算，
感測器就可以利用 3 維的方式計算自己的位置。而在
本計畫中，我們利用 GPS定位的方式讓每個節點精確
的知道它的實體位置以及同步的時間。再來我們將所
要佈署感測網路的區域，規劃虛擬的網格(virtual grids)
位置，首先我們在設計虛擬網格的長度，我們考量到
無線感測器實際傳輸溝通的範圍，因此我們為確保相
鄰網格間的感測器能夠彼此溝通，保證相鄰網格間最
遠的對角線的節點間，通訊範圍必須彼此能夠覆蓋
到，因此我們設定感測器的傳輸範圍為 R，R為有效
的傳輸範圍，d 為網格的長度如圖一所示。任何兩個
 -4- 
之時間。 
二、 動態資料複本之方法 
我們使用虛擬格網來構建無線感測網路之環
境，每個格網內有一個管理節點並且負責同一個格網
內所有節點感測資料之收集和儲存資料，但本計畫方
法並不考慮收集資料的方式。在無線感測網路內如果
一個節點有感測資料並廣播至所有無線感測節點使
其知道，而當有些節點對其感測資料感興趣時，會發
送出請求查詢之封包給其格網之管理者。當管理者收
到請求查詢之封包時，這些管理者就是查詢發送節
點。查詢發送節點使用 GPSR之方式發送和接收其請
求查詢之封包，經由其他虛擬格網的管理者。然而，
當有很多節點向同一個資料儲存節點進行請求查詢
會耗費大量的能量耗費且會造成處理時間延遲，而為
了減少資料儲存節點之處理時間與能量之花費，所以
我們將作出複本節點。複本節點具有與資料節點相同
的資料。另外，在我們的計劃方法中，建立複本節點
盡可能靠近較多的請求查詢封包之地區。 
第一節  周圍邊界節點 
ADR中，為了計算資料儲存節點或複本節點的被
請求查詢頻率，我們需要知道周圍邊界節點位置。當
節點發送請求查詢封包給資料儲存節點或複本節點
的時候必定會通過邊界節點。邊界節點的範圍必須可
以覆蓋資料儲存節點和複本節點也要可以改變請求
查詢封包之路由路徑到新的複本節點。因此，通過邊
界節點的查詢次數即可了解資料儲存節點或複本節
點的查詢頻率。邊界節點根據無線感測網路環境，可
設置 K1 x K2的大小( k1, k2 3  and k1, k2 N ) 
當邊界節點建成後，總共分為八個部分並且分為
八個部分個別計算請求查詢之頻率。而這八個部分邊
界節點都包含四個單一網格：Grid(X-1, Y-1), Grid(X-1, 
Y+(k2-2)), Grid(X+(k1-2), Y-1), Grid(X+(k1-2), Y+ 
(k2-2))，和四邊網格： Grid(X, Y-1) 到 Grid (X+ (k1-3), 
Y-1) 的總和 , Grid(X, Y+(k2-2)) 到 Grid(X+(k1-3), 
Y+(k2-2)) 的總和, Grid(X-1, Y) 到 Grid(X-1, Y+(k2-3)) 
的總和, Grid(X+(k1-2), Y) 到 Grid(X+(k1-2), Y+(k2-3))
的總和。八個部分的邊界節點對應了來自八個方向的
請求查詢，如圖四。 
Grid(X-1, Y-1)
Grid(X-1, Y+k2-2)
Grid(X+k2-2, Y-1)
Grid(X+k1-2, Y+k2-2)
Grid(X-1, Y)
to
Grid(X-1, Y+k2-3)
Grid(X+k1-2, Y)
to
Grid(X+k1-2, Y+k2-3)
Grid(X, Y+k2-2)
to
Grid(X+k1-3, Y+k2-2)
Grid(X, Y-1)
to
Grid(X+k1-3, Y-1)
Grid(X, Y)
 
圖四 邊界節點之示意圖 
邊界節點已建成。下一步是選擇八個主要網格來
進行請求查詢頻率之計算。四個邊角網格(Corner Grid)
各只計算一個網格，因此每個邊角(Corner)之網格都
被選擇來當該方向之計算網格。另外，由於四邊的邊
界大小不一樣，資料儲存節點或複本節點選擇四個方
向為主要網格來計算，如圖五所示。 
 
 
k1
k2
A
B
C
D
 
圖五 挑選四邊之計算格網 
第二節  周圍邊角節點 
在我們計畫的方法中，八個部分的邊界進行計算
請求查詢之數量來建立複本節點，然而網格並不是圓
的，所以八個部分對應著不同的區域。所以需要在各
部分進行不同的設置。在每個部分的不同，可歸納為
兩種情況：邊角和側邊。側邊的情況是一個方向的總
和，並扣除了邊角的網格。所以我們必須先處理邊角
之部分，當資料儲存節點或複本節點產生一個新的複
本節點產生於邊角方向是不太可行的。所以為了避免
這個問題，我們設置一個機制，用來改善這樣的問
題。當一個複本節點所產生的邊角部分，我們將計算
邊角以外的三個節點查詢頻率，如圖六(a)。如果大多
數查詢頻率來自邊角外部的邊角節點，複本將建立於
邊角之方向，如圖六(b)。如果大多數查詢頻率來自邊
角兩個側邊節點，複本節點將建立於相應的方向，如
圖六(c)。 
Y
1 2 3
1
2
3
0
0
4
4
5
6
5 6
X
Y
1 2 3
1
2
3
0
0
4
4
5
6
5 6
X
Y
1 2 3
1
2
3
0
0
4
4
5
6
5 6
X
Data node
Replica node
Boundary node of data node
Boundary node of grid with 
a greatest number of packet
Boundary node of replica node
(a) (b)
(c)
Query Direction
r1
r1
r1
 
圖六 三種邊角請求查詢之情形 
 -6- 
(a) Flat (b) Spot
 
圖十 兩種請求查詢感測節點分布類型 
0
2
4
6
8
10
12
14
16
18
20
22
24
26
28
30
32
5 10 15 20 25 30
Time (sec)
R
ep
lic
a 
no
de
s 
(n
um
be
r)
GPSR
GDR
DRACA
GDR
 
圖十一 請求查詢於平面分布之比較 
 如圖十一所示，我們比較了在 GPSR, GDR, 
DRACA和 ADR上的複本節點之數量。因為 GPSR無
法使用複製方法，所以沒有複本數量。在 GPSR、
GDR、DRACA上，ADR則放置全部複本節點在高請
求查詢頻率的方向。然而，在 GDR，如果複本節點無
請求詢問則無法移除。事實上，大多數的請求查詢封
包來自於邊界感測節點的外緣。在邊緣上的複本節點
和靠近中心的複本節點減輕了不同的查詢封包。因為
DRACA 的第二層和第三層結構很相似，第二層的複
本節點無法減輕相同的其他複本節點的請求查詢封
包。因此 ADR比 GDR減少了請求查詢封包平面分佈
的複本節點約 70%，比 DRACA減少了約 60%。 
0
2
4
6
8
10
12
14
16
5 10 15 20 25 30
R
ep
li
ca
 n
od
es
 (
nu
m
be
r)
Time (sec)
GPSR
GDR
DRACA
ADR
 
圖十二 請求查詢點分佈之比較 
如圖十二所示，我們比較複本節點在請求查詢感
測節點之點平面上的數量。因為 ADR 在請求查詢感
測節點附近放置複本節點和移除額外的複本節點，
ADR比 GDR減少了複本節點約 65%，比 DRACA減
少了約 15%。 
三、 封包流量影響 
我們採用了相同的拓撲與相同網路設定去比較
GDR和 DRACA請求查詢路由協定在 ADR上，全部
網路感測節點每秒隨機產生 0至 4個封包請求查詢資
料儲存節點。因為請求查詢頻率在網路衝擊可能性大
於其他模擬情況，所以當連續請求查詢數量增加時，
在 ADR、DRACA和 GDR上執行減輕傳輸流量。 
0
10
20
30
40
50
60
70
80
90
100
GPSR GDR DRACA ADR
P
ac
ke
t f
ol
w
 (
%
)
 
圖十三 平面分佈之封包流量 
如圖十三所示，我們比較 GPSR、DRACA、ADR
和 GDR 之平面分佈流量。當請求查詢封包大於資料
儲存節點的複製門檻值，開始 ADR、DRACA和 GDR
演算法。我們注意 ADR、DRACA 和 GAR 會減輕資
料儲存節點的封包流量，然而，在 ADR 裡，最後的
封包流量更少於其他方法。那是因為在 GDR 的複本
節點數多於在 ADR 的複本節點數，並且在邊界節點
和複本節點之間的路徑很長。DRACA和 ADR的封包
流量很可能是一樣的，然而 ADR 執行在最後階段可
能請求查詢之節點可能一步即可到達複本節點取得
資料，所以 ADR之流量會少 DRACA之流量。 
四、 能量消耗影響 
0
10
20
30
40
50
60
70
80
90
100
GPSR GDR DRACA ADR
E
ne
rg
y 
co
ns
um
pt
io
n 
(%
)
 
圖十四 平面分佈之能量消耗 
我們比較 GPSR、GDR、DRACA和 ADR之平面
分佈的能量消耗，如圖十四所示，全部能量包含了更
新封包。每個 hop 計算資料封包是 0.01J 和其他封包
是 0.001J，比較 ADR 和其他方法，全部能量消耗降
低至 33％。 
我們比較 GPSR、GDR、DRACA和 ADR之點分
佈的能量消耗，並且發現 ADR 減輕全部能量消耗約
55%。如圖十五所示。 
0
10
20
30
40
50
60
70
80
90
100
GPSR GDR DRACA ADR
E
ne
rg
y 
co
ns
um
pt
io
n(
%
)
 
圖十五 點分佈之能量消耗 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
日期： 100 年 7 月 30 日 
計畫編號 NSC-99-2221-E-024-006 
計畫名稱 無線感測網路資料儲存、查詢處理與資料散播技術之研究 
出國人員
姓名 
陳宗禧 
服務機構
及職稱 
國立臺南大學資訊工程學系教授 
會議時間 
100 年 7 月 3 日
至 
100年 7 月 11 日 
會議地點 土耳其、伊斯坦堡 
會議名稱 
(中文) 2011 年無線通訊與行動計算國際會議 
(英文) 2011 The International Wireless Communications and Mobile 
Computing Conference (IWCMC 2011) 
發表論文
題目 
(中文)視訊感測網路中預測基礎的物件追蹤與覆蓋之研究 
(英文) Prediction-based Object Tracking and Coverage in Visual 
Sensor Networks 
                                 
參加「2011 年無線通訊與行動計算國際會議」 
2011 The International Wireless Communications and Mobile Computing 
Conference (IWCMC 2011) 
出席國際會議報告 
July 3-11, 2011 
 
一、 參加會議經過 
2011 The International Wireless Communications and Mobile Computing Conference, (IWCMC 
2011), Istanbul, Turkey, July 4-8, 2011，IEEE 於土耳其伊斯坦堡舉辦的一個探討無線通訊、網
路與行動計算的重要國際會議之ㄧ。IWCMC 2011 會議場面浩大，聆聽演講專家學者與貴賓
十分踴躍。 
IWCMC 2011 參與會議的專家學者非常踴躍，IWCMC 2011 共舉辦五天，共有 8 個
Symposium: 
(1) General Symposium 
(2) Communication and Information Theory Symposium 
(3) Trust, security and privacy Symposium 
(4) Mobile Computing Symposium 
(5) Multimedia over Wireless Symposium 
(6) Vehicular Communications 
(7) Wireless Networking Symposium 
(8) Wireless Sensor Networks Symposium 
 
以及三個Workshops、五個 Special Sessions與三場國際知名學者演講，會議議程 overview
請參閱附件一。Parallel Technical Paper Sessions 非常多，每一 Session 約有 5~7 篇論文發表，
主題橫跨最新最熱門的無線通訊與網路等重要研究議題。 
IWCMC 國際會議為第七年舉辦，其 Program Committee 皆網羅國際知名的研究學者與先
進，也受到各國學者教授在該研究領域的重視，同時與會的專家學者也都是該領域的佼佼者，
之目的。 
會議圓滿結束後，逛逛伊斯坦堡做文化新知之吸收與觀摩。最後，7 月 10 日滿懷著一顆
愉快的心踏上歸途並攜帶會議資料(含會議論文集 CD)回台灣。歸途心想學術、研究、教學、
服務不再是小範圍的思索而是敞開大門吸收新知與接受外來刺激，交流不是一個口號而是轉
為實際行動，此次至法國參加國際會議使我增長不少，希望有機會能至各國參加各類大型的
國際會議，增廣見聞。最後，非常感謝國科會的支持與補助，使我有機會參加 IEEE IWCMC 
2011 國際會議。底下為參與該會議的照片，開會地點一角以及在會場與 Wireless 
Communications and Mobile Computing 期刊主編(Editor-in-Chief) Prof. Mohsen Guizani 合照。 
 
      
           IWCMC 2011 開會的會場                      本人(右)與 Prof. Mohsen Guizani(左)合照 
  
 
附件二： 
 
以下論文被 IWCMC 2011 接受證明 email。 
T.-S. Chen, J.-J. Peng, D.-W. Lee, and H.-W. Tsai, "Prediction-based Object Tracking and Coverage in 
Visual Sensor Networks," Proceedings of The 7th International Wireless Communications and Mobile 
Computing Conference (IWCMC 2011), pp. 278-284, Istanbul, Turkey, July 5-8, 2011. 
 
The proposed method is used to activate only the useful portion of the network to track the target and decrease the 
energy consumption. 
 
> *** Weaknesses: Comments to the author: what are the weak aspects of the paper? 
 
The language of the paper is very poor. There are lots of grammar and syntax mistakes. The sentences are 
unnecessarily long and they are combined to each other using comma. They should be divided into smaller parts and 
written using shorter and understandable sentences. A few examples from the paper: 
 
For example, we can put the visual sensor in the mills and combine the sensor to mobile robot, so we can dispatch 
some robots to more dangerous area, using robot’s mobility and the visual sensor’s vision, we not only can get the 
information about some special region, but also prevent disasters and accidents. 
--> This sentence is not clear and has grammar errors in it. 
 
 
It not only prevent more visual sensors awaking and track the 
mobile visual sensor together, but also saving the energy consumption of additional visual sensor nodes, on the other 
hand, if we find minimum cover set to track the mobile object, the information that captured by visual sensor node is 
continuing and not overlapping, so, it can reduce the complexity of calculation. 
--> Same as above. 
 
Filed Of View --> Field Of View 
 
The communication range is 25 meter and focal distance of camera is varies 15, 20, 25m, we also consider the FOV 
of cameras is varies 20, 30, 40 degrees,... --> 'is varies' is wrong. There are many 'and's in the following sentence. 
 
These are just some of the mistakes, the paper's language needs an extensive review. 
 
The related work section is very weak. Visual sensor networks and wireless multimedia sensor networks are hot 
research topics. The mentioned references are generally from the 2003-2006 era. More extensive literature study will 
probably give better related studies. 
 
The authors propose target tracking prediction system based on the Kalman filter and propose the notification of 
sensors on the predicted track. The Kalman filter and track prediction is a well-studied topic in radar systems. The 
difference of radar systems and WSNs with respect to the proposed method should be expressed clearly.  
 
Given simulation parameters are not very realistic. The dimensions of the field is 200m x 200m and target speed 
varies between 5 m/s and 20 m/s. This results a very short travel time within the field even with random waypoint 
model. It should be noted that frequently direction changing target has bad effects on the proposed prediction system. 
This means an average travel time of 10-40 secs within the field. The cameras have a FOV of 20-40 degrees and focal 
distance of 15-25m. This means the length of path crossing the FOV is much smaller, thus shorter detection time. 
This situation arises questions about the applicability of the proposed method. The cameras are assumed to be rotating 
360 degrees but the time required to align itself for the proper detection angle may not be enough for such fast targets 
within a limited FOV. 
 
There are 20 figures and 2 tables within a 8-page paper. Especially the quality of the figures in the Experimental 
Results section is not good. The text font in these figures is very small. The first paragraph of the B. Simulation 
Environment is only a repetition of tables 1 and 2. Either the tables or the paragraph is redundant.  
 
The results of some heuristics are better than the proposed POTC. The advantage of the POTC over the heuristics 
should be expressed better. 
 
> *** Recommended Changes: Comments to the author: Please indicate any changes that should be made to the 
paper if it is accepted. 
 
There are too much errors in the grammar and syntax. It will be better if the paper is revised by a native English 
speaker. 
 
The applicability of simulation parameters in the real life, especially the detection, and the notification of further 
sensors with fast moving targets is not very plausible. They may be modified to represent a more realistic simulation 
b第 2 頁 (共 3 頁)(B)
2011/6/7(B)b
  
 
附件三： 
 
參加 IWCMC 2011 發表之論文 
T.-S. Chen, J.-J. Peng, D.-W. Lee, and H.-W. Tsai, "Prediction-based Object Tracking and Coverage in 
Visual Sensor Networks," Proceedings of The 7th International Wireless Communications and Mobile 
Computing Conference (IWCMC 2011), pp. 278-284, Istanbul, Turkey, July 5-8, 2011. 
 
 
 
 
The remainder of this paper is organized as follows. In 
Section II, we review some related works concerning tracking 
and coverage problems. Section III presents our problem 
statement and network model. In Section IV, we describe the 
proposed prediction-based object tracking and coverage 
algorithms. In Section V, we present our simulation results. 
Finally, we conclude our work in Section VI. 
II. RELATED WORK 
    In recent years, tracking mobile objects in visual sensor 
networks has gained a great deal of attention. It can classified 
into five methods: tree-based tracking, cluster-based tracking, 
prediction-based tracking, mobicast message-based tracking 
and hybrid methods. These models assume that moving objects 
maintain their current speed and direction for the next few 
moments, and processes historical data to deduce subsequent 
movement of the mobile object. 
Multiple sensor area coverage is also known as the k - 
Coverage problem, and many researchers have been studying it 
[6]. Huang and Tseng [6] formulated a coverage problem as a 
decision problem, the goal of which is to determine whether 
every point in the service area of the sensor network is covered 
by at least k sensors. 
Soro and Heinzelman [10] also studied the coverage 
problem in video-based sensor networks. Video cameras have 
the unique feature of capturing images of objects, which are not 
necessarily near the cameras, and may in fact be at some 
remove. In video-based sensor networks, the range of sensor 
nodes is replaced by the camera's field of view (FOV). In this 
work, it is assumed that all the camera nodes are mounted on a 
plane, directed towards the service plane.  
To save energy, prediction-based methods [13][15] are 
used to predict the upcoming location of mobile objects 
[13][14]. 
Huang et al. [7], proposed a “Face-Aware Routing” (FAR) 
mobicast protocol. This protocol exploits ideas adapted from 
existing applications of face routing to achieve reliable 
mobicast delivery. The key feature of the protocol is the 
presentation of a routing strategy, using information confined 
solely to a node’s immediate spatial neighborhood and a 
forwarding schedule, employed only to recall topological 
information. 
III. NETWORK MODEL AND PROBLEM STATEMENT 
Face routing [9] has been integrated in our proposed 
protocol for wireless visual sensor networks to provide correct 
routing in the presence of a dead-end. 
Visual sensors know the accurate location of the object. 
When a mobile object enters the field of view, the location is 
determined by calculating the distance according to the frame 
captured by the camera. Visual sensor nodes have two modes, 
active and sleep. Each node knows its location, which can be 
acquired from global positioning system (GPS) or other 
mechanisms, such as triangulation [15]. 
The communication and sensory range are the same for 
each node. The right-hand rule is used to traverse the interior of 
a closed polygonal region (a face) in clock-wise edge order. 
Each node knows the location of all of the nodes in the same 
face. 
Below is the brief protocol, including five steps for 
tracking the movement of objects. 
Step 1: We build up a planar graph for the visual sensor 
network, employing the Gabriel Graph to achieve planarity [5]. 
Step 2: When the target moves, the nearest sensor nodes detect 
the mobile object and use a Kalman Filter [2] to predict 
information related to the mobile target  
Step 3: When the nearest sensor node makes a prediction of the 
location and direction of the mobile object, it wakes up visual 
sensors in advance, readying them to track the mobile object 
before it arrives. 
Step 4: All of the information of each visual sensor node is 
collected to predict nodes, whereupon the predicted node 
calculates the coverage of characteristic points, choosing the 
minimum cover set required to track the mobile object 
cooperatively, while the other visual sensors that are not 
tracking the mobile object switch to sleep mode. 
Step 5: Because the movement model of the mobile object has 
a random waypoint, if the mobile object changes direction or 
velocity suddenly, it wakes up all of the visual sensor nodes 
contained in the face. 
Assumptions 
(1) The object is mobile and moving with a random waypoint. 
(2) Cameras are adjusted to a suitable focal distance. 
(3) Each camera has the same field of view (FOV). 
(4) Camera nodes are randomly distributed and static in the 
network. 
(5) Cameras can rotate 360° to cover the object. 
(6) The object and each camera node know its physical 
location. 
The Kalman filter [2] was originally designed for aircraft 
navigation and research and development, and has been 
successfully applied in many areas. It is based on linear 
dynamic systems in the time domain. It is modeled on 
a Markov chain built on linear operators perturbed by Gaussian 
noise. The state of the system is represented as a vector of real 
numbers. At each discrete time increment, a linear operator is 
applied to the state to generate the new state, with some noise 
mixed in, and optionally, some information from the controls of 
the system if they are known. Another linear operator is then 
mixed with more noise to generate the observed outputs from 
the true state. 
In our method, the prediction model can be presented as 
the following equation: 
)()()()()1( 1 kWkXkXkX k                       (1) 
where 
)(kX : state vector. 
)( k : state transition matrix. 
)(kW : process node. 
)1( kX : position, velocity, acceleration of mobile object in 
previous time slot. 
We set the state vector as )(kX  = 
T
yxyxyx 

 ...... , and 
denote the position, velocity, and acceleration of the mobile 
object in the proper order, as the following matrix: 
279
 
 
Waking up the boundary face in the first phase is 
insufficient. In object tracking, if we have too many visual 
sensor nodes with which to track the mobile object, we can find 
much better cover set for object tracking. Therefore, all of the 
crossed nodes awaken the current face including itself. Thus, it 
not only wakes up the face across the movement path, but also 
wakes up all of the faces containing crossed nodes, to provide 
choices for better cover sets in tracking the mobile object. 
In the second phase, all of the boundary nodes use face 
routing to wake up faces including itself. We set some 
conditions to prevent a loop in face routing. If the boundary 
node receives a face routing message from the boundary node, 
then it ignores the message. If the node is not a boundary node 
and receives a face routing message from the boundary node, 
the node will change mode from sleep to active, and become a 
extended boundary node. In this manner, we can prevent the 
repeated transmission of a message, resulting in excessive 
energy consumption. 
As mentioned previous, face routing enables us to awaken 
the face connected to the boundary face, and call these faces 
extended boundary faces. In this phase, we awaken F7, F8, F9, 
F10, F11, F12, F13, F14, F15, F16, F17, as shown in Fig. 5. 
Wake nodes
Cross nodes
Face edge
Cross edge
Moving path
Mobile object
Routing path
F7 F8
F9 F10
F11
F12
F14
F16
F17
Already wake
Nearest nodes
F13
F15
 
Fig. 5: All awakened faces containing cross nodes. 
B. Covered Range 
Chow, Lui, and Lam [4] described how the range of 
coverage is defined as the portion of the perimeter of the object 
covered by a sensor node. Our study differs somewhat, due to 
the mobility of the object and the fact that our camera does not 
focus on the perimeter of the object. In our method, the camera 
focuses on specific characteristic points and follows them. In 
this manner, the coverage is a segment of the movement path of 
the mobile object. In Fig. 6, we show the coverage of a mobile 
object by the camera sensor. 
Camera Sensor
Mobile Object
Characteristic Point
Moving Path
Covered Segment  
Fig. 6: Coverage of mobile object. 
The relative position and distance between the visual 
sensor node and mobile object also influences the coverage of 
characteristic points. In Fig. 6, the mobile object has only one 
characteristic point, but if multiple characteristic points exists, 
it generates a different result, as shown in Fig. 7. 
In Fig. 7(a), the visual sensor is too far from the mobile 
object, so it can only capture one characteristic point. In Fig. 
7(b), the lower characteristic point remains within the focal 
distance of the camera, enabling the camera to cover two 
characteristic points at the same time. In Fig. 7(c), it can also 
cover two characteristic points simultaneously; however, 
according to our assumptions, the camera will follow only 
specific characteristic points. In Fig. 7(c), we find it still covers 
one characteristic point. We therefore need visual sensor nodes 
to cooperate in tracking the mobile object, to determine the 
minimum cover set and ensure the maximum coverage of 
characteristic points. 
Mobile Object Characteristic Point
Camera SensorMoving Path
(a) (b) (C)
 
Fig. 7: Coverage of objects with multiple characteristic points. 
C. Single Characteristic Point 
We focus on a specific point moving randomly; therefore, in 
some time slots, the coverage provided is the movement path of 
the characteristic point, and camera rotates according to this 
characteristic point, as shown in Fig. 8. 
Mobile Object Characteristic Point
Camera SensorMoving Path  
Fig. 8: Camera rotation according to characteristic point. 
Because the camera can rotate 360°, the coverage of the 
characteristic point can be considered a secant of a circle, as 
shown in Fig. 9. 
Mobile Object
Characteristic Point
Camera Sensor
Moving Path
Covered Segment
 
Fig. 9: Coverage of single characteristic point. 
In the view of the entire visual sensor network, every 
visual sensor has its own coverage of mobile objects, from 
predicting the start point to the end point. Many sensors 
surround the movement path and all of the information 
regarding the tracking and coverage of characteristic points of 
objects is collected in the original prediction node using face 
routing. In addition, all of the calculation related to coverage is 
centralized in predicting nodes, until the calculation finishes. 
The prediction node sends a wakeup message to sensor nodes to 
prepare to track a mobile object using face routing. 
We marked all of the segment coverage of visual sensor 
nodes. Every segment overlaps to certain extent. In our method, 
281
 
 
sensors nodes is just two nodes, there is an increase in the 
probability of losing the object. 
Heuristic ROUTE: When the current node informs the 
destination node, many visual sensor nodes are awakened en 
route from the current node to the destination node. This 
heuristic wake up mechanism assumes that the movement path 
of the mobile object is estimated correctly but the probability 
remains that the mobile object will be missed, resulting in 
prediction error. This approach awakens many visual sensor 
nodes on the route, and even if the speed of the mobile object 
changes, the object can be tracked efficiently. 
Heuristic ALL_NBR: In addition to the nodes on the 
route and the destination node, the current node also informs 
the neighboring nodes surrounding the route, the current node, 
and the destination. This heuristic wake up mechanism assumes 
that the movement path and movement speed are observed and 
differ from the actual values. Thus, waking up more visual 
sensor nodes can reduce the rate of missing objects. 
B. Simulation Environment 
Our simulation environment included 300 sensors, 
deployed randomly in a 200m × 200m square region. The 
communication range was 25 meters and the focal distance of 
the cameras varied at 15, 20, or 25m. We also considered the 
FOV of the cameras varying at 20, 30, or 40 degrees. In the 
energy model, the initial battery was 30J, the transmission 
power was 700 mW and the received power was 360mW. The 
power of camera rotation was 360 mW, and the power in sleep 
mode of visual sensor was 0.9mW. The power used by the 
visual sensor in active mode was 23 mW, and the movement 
model of the mobile object was a random waypoint. The 
velocity of the mobile object varied at 5, 10, 15, or 20 meter/sec. 
Each simulation run lasted110 seconds. From 0~10 seconds, 
the sensor network created the face topology, and in the 10th 
second, the mobile object began its movement. Because each 
camera node was aware of its own orientation, it was able to 
determine whether the object could be covered or not. 
Simulation parameters are depicted in Table 1. 
Table 1: Simulation parameters. 
Network Area 200m × 200m 
Focal Distance 15, 20, 25 (m) 
Filed Of View 20, 30, 40 (degrees) 
Object Speed 5, 10, 15, 20 (m/s) 
Number of Visual Sensor Nodes 300 
Communication Range 25m 
Initial Battery 30J 
We have evaluated four key performance metrics: (i) Finally 
awake visual sensor nodes; (ii) energy consumption between 
different fields of view; (iii) energy consumption between 
different focal distances; (iv) energy consumption between 
POTC and ALL_NBR. The parameters of energy consumption 
are depicted in Table 2. 
Table 2: Energy consumptions of visual sensor nodes. 
Component Mode Energy Consumption (mw) 
Camera Rotation 360 
Sensor Active 23 
Sensor Sleep 0.9 
Radio Transmission 700 
Radio Receiving 360 
 
C. Ratio of Awake Nodes 
 In Fig. 13, we compare the Heuristic DESTINATION, 
Heuristic ROUTE, Heuristic ALL_NBR and POTC with four 
different velocities varying at 5, 10, 15, and 20 meter/sec. The 
FOV of visual sensor nodes were 30, the focal distance of 
visual sensor nodes was 20. In each ten seconds, each bar in the 
figure presents the ratio of finally awake nodes in four different 
wake up mechanisms. Because we predicted the position of the 
mobile object after five seconds, in the 6th second, whether the 
visual sensor captured the mobile object or not, it would change 
mode from active to sleep. We therefore calculated the number 
of finally awakened nodes and compared the ratio with our 
method. 
Ratio of Finally Awake Nodes
0
0.5
1
1.5
2
2.5
3
3.5
4
5 10 15 20
Object Speed (m/s)
Co
nsu
me
d 
En
erg
y (
J)
DESTINATION ROUTE ALL NBR POTC  
Fig. 13: Performance with FOV = 30, focal distance = 20. 
D. Consumed Energy 
We compare the energy consumption between ALL NBR 
and POTC, because DESTINATION and ROUTE lead to an 
increased rate of missed objects and fails to provide full 
coverage of the mobile object. Relatively, only ALL_NBR and 
POTC are capable of covering and tracking the mobile object; 
therefore, we compared the energy consumption of POTC and 
ALL_NBR, with the field of view set to 30 degrees, the focal 
distance set at 20 meters, and the velocity of the mobile object 
varied at 15, 20, and 25 meter/sec, respectively. Because 
ALL_NBR just wake up visual sensor nodes without applying 
other sleep mechanisms, POTC uses fewer visual sensor nodes 
to cover and track mobile objects, as shown in Fig. 14. 
FOV = 30 (degrees), Radius = 20 (m), and Object Speed = 10 (m/s)
0
100
200
300
400
10 15 20
Object Speed (m/s)
C
on
su
m
ed
 E
ne
rg
y 
(J
)
ALL NBR POTC  
Fig. 14: Energy consumption between ALL_NBR and POTC. 
We compare the energy consumption between different 
focal distances, adjusting the focal distance of the cameras to be 
15, 20, or 25 meter respectively, with the field of view set to 30 
degrees, and the velocity of mobile object varying at 10, 15, or 
20 meter/sec, respectively.  In the figure below, we present the 
energy consumption between different focal distances per ten 
seconds. As the focal distance increased, the numbers of visual 
sensor nodes decreased, leading to a decrease in energy 
consumption. In other words, when the focal distance was long 
283
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/24
國科會補助計畫
計畫名稱: 無線感測網路資料儲存、查詢處理與資料散播技術之研究
計畫主持人: 陳宗禧
計畫編號: 99-2221-E-024-006- 學門領域: 計算機網路與網際網路
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
