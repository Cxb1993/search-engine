i 
 
摘要 
本計畫提出輔以先進三維操控之三維模型變形技術，除了針對表面細微構造
保留，也以傳統建立骨架技術作基礎，對於骨架位置與權重來作變形最佳化求解, 
以獲得理想結果。其中，為了求更自然的變形效果，加上了高階限制：重心、長
度、關節角度、剛體形變，並提出新穎的串流最佳求解法，達到即時操縱呈現變
形成果。其次, 我們加入先進三維人機介面操控技術本技術(如 Wii controller 等), 
使得動畫之操作簡便及自然. 最後, 加入物體與環境互動, 如水中運動, 以便達
成如在水中游泳等有異於一般空氣中的動畫效果. 除上述功能外, 本計畫成果尚
可以發揮在多方應用，如模型間變形轉移(deformation transfer)、行為轉移(motion 
retargeting)，未來研究成果相當實用。 
  
2
iii 
 
本計畫近兩年所有相關發表之論文列表如下 
1. 陳愷軒, “以動感強化器操作之三維模型形變系統”, 國立臺灣大學碩士論文, 
2010 
2. Chen Kai-Hsuan, Cheng Yi-Shan, Ho Shing-Han, Ouhyoung Ming, “A Three Di-
mensional Mesh Deformation System Using Wii-MotionPlus”, Proceedings of 
ChinaGraph 2010, Nanking, China, October 2010. 
3. Che-Hua Yeh, Yuan-chen Ho, Brian A. Barsky, Ming Ouhyoung, “Personalized 
Photo Ranking and Selection System”, to appear as a full paper, ACM Multiedia 
2010, Italy, October 2010. 
4. Che-Hua Yeh, Wai-Seng Ng, Brian A. Barsky, Ming Ouhyoung,  “An Esthetics 
Rule Based Ranking System for Amateur Photos”, Sketches, ACM SIGGRAPH 
Asia 2009, December, Japan, 2009. 
5. Ken-Yi Lee, Yung-Yu Chuang, Bing-yu Chen, Ming Ouhyoung, “Video Stabiliza-
tion using Robust Feature Trajectories”, Proceedings of IEEE Conference on 
Computer Vision (ICCV 2009), pp. 1397-1404, September, Kyoto, Japan. 
6. Che-Hua Yeh, Pei-Ruu Shih, Yin-Tzu Lin, Kuan-Ting Liu, Huang-Ming Chang, 
Ming Ouhyoung, “A Comparison of Three Methods of Face Recognition for 
Home Photos”, poster, ACM SIGGRAPH, New Orleans, August 2009. 
7. Virginia Tzeng, Yu Liang, Yi-Ting Cheng, Yung-Yu Chuang, Bing-Yu Chen, Ming 
Ouhyoung, “Face Replacement in Video”, poster, ACM SIGGRAPH, New Or-
leans, August 2009. 
  
4
1 
 
（一）研究計畫之背景及目標 
1. 背景、動機及重要性 
在人機介面方面，近年有相當大的技術突破,如熱賣的 Wii 遊戲機的三維操
控，與 Apple iPhone/iTouch 之 Multi-touch 技術。另外本人的作品[11]曾在國際一
流會議 SIGGRAPH2006“Emerging Technology”現場展示 "Hand Shadow Illu-
sions and 3D DDR Based on Efficient Model Retrieval", video demo (1) 
3D_DDR :http://3d.csie.ntu.edu.tw/s2006etech/ddr.mpg (2) Hand Shadow Illusions: 
http://3d.csie.ntu.edu.tw/s2006etech/shadow.mpg , Boston, July, USA, 2006. (台灣的
第一次在此項目被接受)。這台跳舞機不用遙控器，讓人站在網路攝影機前，跟
著螢幕動作全身舞動即可。這台跳舞機 2006 年除獲得美國 Siggraph 邀請參展，
網路迴響極為熱烈，2007 年更獲法國 Laval Virtual 虛擬實境會議邀請參展。跳舞
機抓住影像之後，能將人與背景分離，並比對人的動作是否正確，未來可應用在
模型建模與動畫,醫學復健、舞蹈學習與減肥運動。 
 
在模型建模與動畫方面，之前國科會專題計畫有實作出一些關於臉部建模與
動畫的技術。臉部表情之模擬，應用兩面鏡子放在人臉側面，用攝影機同時拍攝
三個動態說話的畫面，並即時追蹤嘴唇及臉部五十個至兩百個特徵點，演算法用
到了鏡面全對稱的特性，將一般兩個攝影機六個自由度的演算法，簡化為空間中
平面方程式的四個自由度，所以更容易收斂，且準確度高出傳統方法[13, 14]。
然後以更穩定而快速的方法，算出表情及嘴唇在三維運動的軌跡，並做出幾可亂
真的動畫。之後, 又發展了骨架的自動產生方法[8], 與幾種基於骨架變形的簡單
產生動畫的方法[11]。除此之外，國內成大李同益教授曾有利用形變產生動畫的
方法[6,7]發表，在國外方面更是熱門研究之一[1,15]。因此，結合先進人機介面
與模型形變動畫技術，促成了以下的計畫。 
 
2. 目標 
結合先進人機介面與模型形變動畫技術, 促成了以下的計畫，我們的研究主
要期盼達到的目標如下： 
1. 模型變形後骨頭長度的不變。 
2. 模型變形後關節角度可以有限制(如最多 45 度)。 
3. 模型變形後重心平衡的保持。 
4. 使用者操縱介面便利化，加入先進三維人機介面操控技術本技術, 如：
以 Wii controller 作控制。 
 
 
6
3 
 
提供的方法作拆解，最後再求解。其最大的缺點在於，一個三維模型可
能包數千或數萬個頂點，因此建出來的矩陣會非常的大，雖然這個矩陣
相當的稀疏，但 GSL 並沒有提供儲存稀疏矩陣的資料結構，也並沒有對
稀疏矩陣的運算作最佳化，因此速度上並不理想，對於頂點數目太大的
模型而言，可能也會發生矩陣過大而記憶體不足的問題（對於一個頂點
數目上萬的模型，其矩陣大小也會為上萬乘以上萬）。 
 
(3) Sparse Linear Solver: Taucs 
Taucs 是用 C 實做的 sparse linear solver，是一個針對稀疏矩陣求解的程
式庫。和 GSL 不同的是，其提供了一個專門用於儲存稀疏矩陣的資料結
構，Compressed Column Storage (CCS)，並在矩陣求解的過程中，針對稀
疏矩陣作矩陣的重新排序，將其壓縮到密度較高以後，再做矩陣拆解（其
實做 Cholesky factorization、LU factorization、multifrontal factorization、
left-looking factorization 等多種拆解方法）。用此針對稀疏線性矩陣求解
的程式庫來求解稀疏矩陣，速度明顯的較前兩者快上許多。另外，使用
這個程式庫的方法可以是，我們在拖動某些固定的點時，先對其矩陣作
重新排序、拆解，以後便只更新被拖動的點的座標，用 back-substitution
求解，如此一來，在對一個包含數千個頂點的模型，在前運算完成後，
接著便可以達到即時形變的速度。 
 
解法速度比較 
 
Solver 
不同模型的求解時間 (單位：ms) 
馬 (502 個頂點，1000
面三角形) 
恐龍 (7146 個頂點，
14288 面三角形) 
Levmar 收斂誤差：1e-2 120~750，平均約 437 記憶體不足 
收斂誤差：1e-4 650-1050，平均約 945 記憶體不足 
GSL 2451 記憶體不足 
TAUCS 75 2 2654 45 
實驗環境：Intel Core Duo T2400@1.83GHz，3GB RAM 
 
 Levmar 此程式庫採用的是 Levenberg-Marquardt 此遞迴收斂的演算法，故可
調整其收斂停止條件來達到不同的速度。在 levmar 和 GSL 此兩個程式庫中，在
恐龍的形變測試，都會記憶體不足而無法運算。在 TAUCS 中，因為使用壓縮格
式儲存矩陣，故並不會發生記憶體不足的問題。另外，TAUCS 在圖表中分為兩
個不同的運算時間，第一步是重新排序與拆解矩陣，第二步為更新拖動點的座標，
作 back-subsititution。如同先前的介紹，在固定與拖動的點不變時，我們只需要
作第二步的運算，故在數千個頂點的模型運算上（如恐龍），仍然可以有每秒二
8
5 
 
 
圖二、第一張為 Armadillo 原圖，其餘為變形結果 
 
 
 
 
10
7 
 
我們將我們設計的 Wii 控制介面，來讓使用者跟滑鼠操作方式來比較，觀察
利用 Wii 控制器來對 3D 模型做形變是否能減少使用者控制的時間。實驗結果如
下表，從結果我們可以看到我們提出的系統可以讓使用者加快 9%~23%的速度。 
 
(介面\控制時間) T1 恐龍模型 T2 馬匹模型 T3 Armadillo 
滑鼠 28.56 秒 36.75 秒 27.97 秒 
Wii 控制器 21.94 秒 33.28 秒 21.88 秒 
加速比例 23.18 % 9.52 % 21.77 % 
 
（三）結論與討論 
在這計畫中，我們提出了一個創新且有效的使用者介面來加速三維模型的形
變。在三維模型的形變技術上，我們已經到達了即時的運算，搭配直覺操作的
Wii 控制器，降低了使用者操作形變的時間。透過這樣直覺的操作方式，更可以
創作出即時的動畫。 
相關發表論文 
8. 陳愷軒, “以動感強化器操作之三維模型形變系統”, 國立臺灣大學碩士論文, 
2010 
9. Chen Kai-Hsuan, Cheng Yi-Shan, Ho Shing-Han, Ouhyoung Ming, “A Three Di-
mensional Mesh Deformation System Using Wii-MotionPlus”, Proceedings of 
ChinaGraph 2010, Nanking, China, October 2010. 
10. Che-Hua Yeh, Yuan-chen Ho, Brian A. Barsky, Ming Ouhyoung, “Personalized 
Photo Ranking and Selection System”, to appear as a full paper, ACM Multiedia 
2010, Italy, October 2010. 
11. Che-Hua Yeh, Wai-Seng Ng, Brian A. Barsky, Ming Ouhyoung,  “An Esthetics 
Rule Based Ranking System for Amateur Photos”, Sketches, ACM SIGGRAPH 
Asia 2009, December, Japan, 2009. 
12. Ken-Yi Lee, Yung-Yu Chuang, Bing-yu Chen, Ming Ouhyoung, “Video Stabiliza-
tion using Robust Feature Trajectories”, Proceedings of IEEE Conference on 
Computer Vision (ICCV 2009), pp. 1397-1404, September, Kyoto, Japan. 
13. Che-Hua Yeh, Pei-Ruu Shih, Yin-Tzu Lin, Kuan-Ting Liu, Huang-Ming Chang, 
Ming Ouhyoung, “A Comparison of Three Methods of Face Recognition for 
Home Photos”, poster, ACM SIGGRAPH, New Orleans, August 2009. 
14. Virginia Tzeng, Yu Liang, Yi-Ting Cheng, Yung-Yu Chuang, Bing-Yu Chen, Ming 
Ouhyoung, “Face Replacement in Video”, poster, ACM SIGGRAPH, New Or-
leans, August 2009. 
 
12
9 
 
[12] Wan-Chun Ma, Sung-Hsiang Chao, Yung-Yu Chuang, Chun-Fa Chang, Bing-Yu 
Chen, Ming Ouhyoung, Level-of-Detail Representation of Bidirectional Texture 
Functions for Real-Time Rendering, Proc. of ACM Interactive 3D Graphics and 
Games 2005 (I3D05), pp. 187-194, Washington, D.C., USA, 2005. 
[13] I-Chen Lin, Ming Ouhyoung, "Mirror MoCap: Automatic and Efficient Capture 
of Dense 3D Facial Motion Parameters from Video", Vol. 12, No. 6, pp.355-372, 
The Visual Computer, July, 2005 
[14] I-Chen Lin, Jeng-Sheng Yeh, Ming Ouhyoung, "Extracting 3D facial animation 
parameters from multi-view video clips", pp. 72-80, IEEE Computer Graphics 
and Applications, Vol. 22, No. 6 , Nov., 2002. 
[15] Ilya Baran, Jovan Popovici, Automatic Rigging and Animation of 3D Characters, 
ACM SIGGRAPH 2007, ACM Transactions on Graphics (TOG) Volume 26, Is-
sue 3, July 2007.  
 
 
附錄一、ChinaGraph 2010 論文全文 
14
  
    
 
1   Introduction 
Making a 3D model to deform naturally is essential in 3D animation and modeling, which is important in game 
and movie industry. Traditionally, it's achieved by lots of animators' tweaks. Because this work is time-consuming 
and tedious, we observe that there are two directions that might help to speed up this process. First direction is a 
better user interface, and the second one is the help of high level deformation constraints.  
The present modeling and animation software such as Maya and 3dx Max will control the rotation of a model 
through an arcball interface. Ideally, one should be able to rotate one, two, or three axes simultaneously. By dividing 
the screen into some parts, a user observes a 3D model in different direction in the same time and can use the mouse 
to modify the model in one of the divided screens. Because the mouse is basically a two dimensional device, the 
mapping between a mouse and the three dimensional rotation is a 2D to 3D mapping. Therefore, to avoid this 
constraint, we propose a new user interface that provides a 1-1 mapping of three-axis rotation by exploiting the Wii 
Remote MotionPlus. This interface directly maps the user control to 3D rotation, and that means, the model is 
rotated to the same direction as the Wiimote that a user holds. Moreover, translation can able be controlled 
simultaneously during the three-axis rotation by our interface, which is difficult for the traditional mouse and 
keyboard interface.  
Wiimote, abbreviated from Wii Remote, was released by Nintendo in the end of 2006. This controller contains 
a three-axis accelerator that can sense the acceleration in three axes. Its drawback is that it can't sense the uniform 
motion without acceleration, hence we can't properly detect the real 3D direction of Wiimote. Recently, Nintendo 
released the extension of Wiimote, Wii MotionPlus. Wii MotionPlus contains a gyroscope. By connecting this 
extension to the original Wiimote, we can read the relative rotation of Wiimote, even under the motion of uniform 
speed. After we calibrate it, we can calculate the exact direction of Wiimote relative to original direction, and make 
precise control of three dimensional rotations possible. Therefore, we utilize Wiimote and its extension, Wii 
MotionPlus, to build our user interface.  
Modifying an existing model is much easier than creating a new model, and that's the reason why deformation 
method is worth to research. Many methods have been proposed to deform a 3D model. 
Besides the user interface, we build a 3D mesh deformation system that provides convenient editing operations. 
In the editing process, users usually anticipate a model to deform according to certain physical rules, like preserving 
rigidity and geometric details. In our system, users just need to fix certain vertices in the mesh and dragging other 
vertices in the mesh, and the intermediate parts of the mesh will be deformed automatically based on constraints. 
Our implementation is based on Sorkine et al. [2, 3]. 
There is a standard editing procedure for our system. First, a user have to assign two parts of a model, the fixed 
parts and a moving part, by selecting certain desired vertices. Our system provides a handle of the fixed part, and a 
user can rotate and/or move the handle to drive the moving part. The position of those vertices between the fixed and 
moving parts will be optimized during the editing process by our system.  
As conclusions, we present an interactive deformation system uses high level constraints, including details and 
rigidity constraints to speed up the tedious adjustment of animators, and an intuitive user interface by Wiimote 
MotionPlus. The whole deformation system not only makes the deformation process more intuitive but also reduces 
the time of modifying a model. 
2   Related Work 
In these section, we will discuss the works relate to mesh deformation and user interface respectively. And the 
related literatures of the user interface include two classes of works. First, the works related to Wii Remote. Second, 
16
  
    
 
to control a virtual biped character. A user's movements, include walking, jumping, and running, are mapped to a 
virtual character. This mapping enhances the emergence of users. 
Since traditional interfaces, such as mouse and tablet, are 2D devices, it's a challenge to design a 3D geometric 
modeling and deformation interface. The most common modeling software, like 3ds Max and Maya, still use mouse 
as the controlling device. Some works attempt to achieve 3D modeling conveniently using 2D interface. Teddy 
system [14] is a tablet-based sketching interface for 3D freeform design, and it generates a 3D model that fits 
common people's prediction. Teddy system is enough to design rough models in concept design or playing, but it's 
not adequate to design complex models. FiberMesh system [15] is a system similar to Teddy system, but adding 
more modeling operations. However, a user is not able to design sophisticate models using FiberMesh system. 
2D-sketch-based interfaces [16, 17] are another approach for mesh editing systems. Nealen et al. [12] modifies 
a model by a handle, which is determined by silhouette selection or cropping, or directly drawing on the model 
surface. In [17], users draw a line or curve on a model, where the curve acts like a bone of this mesh, and bending 
this curve will drive the neighboring mesh to deform. Gingold et al. [19] presented a shading-based surface editing 
system that allows a user to modify a shape by changing its rendered image. The 2D user input is translated to 3D 
model transformation. In some modeling cases, this system is easier to achieve the deformation goal than standard 
deformation approaches. 
3   Mesh deformation algorithm 
Our goal of mesh deformation algorithm is to preserve geometric details and rigidity during modeling 
operations, and this algorithm should be fast enough for user to manipulate interactively. This goal is achieved by an 
iterative two-step method based on [2, 3]. Generally speaking, during each deformation, we first compute a rough 
deformation as an initial guess using Naïve Laplacian coordinates [2], and iteratively refine it using [3].  
3.1   Initial deformation 
It's fundamental to preserve geometric details during modeling operations, and we achieve this goal by 
converting vertices from absolute coordinates to differential coordinates. Differential coordinates captures the 
relative relation, known as details of mesh, between vertices. Absolute Euclidean coordinates changes during 
transformations, such as translation, rotation and scaling, nevertheless, differential coordinates like Laplacian 
coordinate retains its value during transformations. For free-form deformation, we set an object function that 
penalizes changes of value of Laplacian coordinates in all vertices in the targeting mesh, and finding the best mesh 
after deformation by minimizing this object function. 
The Laplacian representation of a vertex I, wi, is shown as below, and N(i) represent one-ring neighboring 
vertices of vertex i in mesh M. 
    

|	
|

 
 
The transformation from absolute Euclidean coordinates to Laplacian coordinates, a forward transformation, 
can be represented in matrix form,    . I is an identity matrix, D is a diagonal matrix with   |	
|, 
and A is the adjacency matrix of mesh M. If we write all vertices in mesh M in a vector V, we can get   . 
Assume we write all vertices in absolute coordinates in a vector V', we can solve    to get the best position. 
We solve this equation in three dimensions separately.  
18
  
    
 
Fig.3 Pitch, Roll, Yaw rotation 
on Wiimote. These rotations are 
local and used to describe the 
rotation in each single time 
interval. 
the pointer position on the screen, which is often used in game interface and shooting game. 
 Wii accelerator device provides a way to capture acceleration from three 
axes. In most sport games the accelerator captures the strength of user’s action, 
like striking the balls, and simulating the action in the game. In most games it 
seems to work well, but actually the precise orientation is still missing; it works 
whether we strike the ball by waving from the right to the left or from the top to 
the bottom. The accelerator is good when asking for the strength of the motion 
only, but bad in detecting the accurate motion of the Wiimote controller. 
In 2009 Nintendo announced Wii-MotionPlus. The MotionPlus device 
contains a small gyroscope, which is often placed on ships to maintain the 
orientation. A mechanical gyroscope is essentially a spinning wheel or disk whose 
axis is free to take any orientation. MotionPlus takes advantage of the function and helps us to detect the precise 
motion of Wiimote in any orientation.   
 For the Wiimote controller local rotation, Pitch is the rotation by X 
axis, Roll is by Y axis, and Yaw is the rotation by Z axis. The following X, 
Y, Z axes are relative and local coordinate of Wiimote itself, so it is more 
precise to describe them as Pitch, Roll and Yaw.  
The main feature of Wii-MotionPlus is that it returns the local 
changing amount of Pitch, Roll, and Yaw at every single time interval, but not the global angle of rotation. Namely 
we have to accumulatively sum the values to guess the global 3D rotation. This property may trigger some 
accumulation error, and certain calibration method must be involved. 
Initialization: 
At the beginning we must correct errors from tiny vibration. Even if we put the controller on the table, the 
small signal errors may still sum up to a visible amount. When initializing, we choose the average value in 300 clock 
time to be the base value, and every forward movement value will be normalized by the base value. In some new 
Wii-Motion-Plus- based games announced by Nintendo, the players also need to calibrate the controller by holding 
it statically for a moment to ensure the quality of the game. 
Getting Wiimote Orientation by MotionPlus: 
 After initialization we can start summing the angular momentum of Pitch, Roll and Yaw. It is a problem to 
directly map the Pitch, Roll and Yaw to three axes rotation. The x-y-z coordinates system acts globally but the 
roll-pitch-yaw coordinates are local; in addition, some coordinate transformation problem and 3D rotation problem 
exists. We have to map the local rotation to global x-y-z rotation. To avoid coordinate transforming problem, we 
have to rotate the coordinate base on Pitch-Roll -Yaw angle for every single movement. 
 Although at the beginning we calibrate the controller and get average error when it is placed at static place, 
there are still small errors exist due to the unstable signal. It will cause an obvious drift in the long run. We need a 
threshold to filter the small movement to avoid the drift, but in this way some tiny movement may go undetected - 
such as the moment wii-controller starts to accelerate or slow down, and therefore accuracy goes down after a period 
of time. There is no effective way to ignore tiny signal errors when silence and keep those tiny movements when 
moving as while, and the situation will get even worse in accumulative system. One Solution is to do calibration 
frequently, like in certain Wii games the players have to re-calibrate the controller orientation in every round. Our 
solution is to re-calibrate the Wiimote controller by its own accelerators. 
20
  
    
 
the result of the “face” vector, rotate 90 degree along the “right” vector (like elevate the vector), and finally rotate 
along the rolling angle around face direction. The rolling angle can be obtained from the ratio of Gx and Gz. 
Knowing that the =1* @ =>* value will be a constant when rolling, we can compute local rolling angle: 
 
      A"$0 !
B1 B2 B>  
1 2 >! 0#0"C4D#! B9
2 1 4 
       779:#9:7"   ;9<.
 EF|
EFEG|  
      

B1 B2 B>  
B1 B2 B> 0#0" 779:#9:7"#! B9
1 2 > 
 
 At last, we use the “face” vector and “up” vector to get the “Right” vector.  
 
      
!1H !2H !>H   
B1H B2H B>H! 0#0"C4D#! B9
1 2 > 
 
 Now we know the face, up and right vectors of the controller by MotionPlus and Accelerator. At the initial 
calibration, the controller is placed flat toward the screen; that is, the face vector, the up vector and the right vector 
are (0,1,0), (0,0,1) and (1,0,0). We can then form a rotation matrix between the old and the new vectors: 
 
      
3/|A|56   3/|A|5 
      6  3/|A|5<.3/|A|5 
 
 Hence we get re-estimate new rotation matrix M’. 
 Self Calibration method can solve the drifting problem, but two issues must be considered: first, calibration 
can correct the drift error only in two axes, while the drifting on x-y plane cannot be solved. Second, the accelerator 
detects pure gravity when static but heavy pulses when waving the controller. The self calibration algorithm only 
works when computing mere gravity, and therefore it fails when the user is waving the controller. Consequently, in 
our work we only do self calibration when user stops waving the controller. 
 Besides the method that is mentioned above, we find that the accumulation error can be avoided by the 
operation design of our system. In our experiment, we find that users usually rotate the model no more than fifteen 
seconds. Therefore we decide to design in a press-and-rotate operation manner. The user can rotate the model by 
pressing a special button on the Wiimote, and stop the rotation by releasing it. Every period of rotation isn’t long 
enough to cause serious error accumulation. 
5   Experiment and Result 
With the above deformation system which uses Wii Remote and MotionPlus as the user interface, we 
conducted three experiments to demonstrate the advantages of our interface over the mouse. 
We found ten users to participate our experiments as subjects, and designing three deformation tasks for 
subjects to complete. All of the tasks involved both translation and rotation operations. Before the experiment, we 
would take fifteen minutes to train the subject to be familiar with these two interfaces, and let them to exercise for a 
simple task. Then the subject was requested to complete these three tasks with traditional mouse interface and Wii 
MotionPlus interface, respectively. The completion time in seconds for each task was recorded, as shown in Table 1. 
 
 Task 1: Dinosaur Task 2: Horse Task 3: Armadillo 
22
  
    
 
Our deformation algorithm is a cell-based iterative algorithm. At first, we will compute an initial guess using 
the naive Laplacian algorithm. Based on the initial guess, we compute the local rotations relative to the original 
mesh of each cell, and optimizing the mesh using these local rotations.  The two-step computation is kept going 
until convergence, which is usually less than three iterations. Although the cells in this algorithm are surface-based, 
the experiment result is visually convincing. 
In conclusion, our deformation system provides an innovative user interface. We integrate the Nintendo Wii 
Remote MotionPlus to our system for 3D rotation manipulation that is 1-1 mapping. In the inner deformation loop, 
we adopt an algorithm that preserves rigidity during mesh deformations. And the high level rigidity constraint helps 
users to achieve the desired results easier and more efficiently. 
 In the future, we wish to adopt an algorithm that provides different levels of rigidity. In the user interface, we 
believe that the multi-touch technique is another possible option which is appropriate for common users, especially 
for children to have fun playing with. 
References:  
[1]   Sorkine O, Cohen-Or D, Lipman Y, Alexa M. Laplacian Surface Editing. ACM International Conference Proceeding Series Vol. 71, 
2004. 
[2]   Alexa M. Differential coordinates for local mesh morphing and deformation. The Visual Computer, 2003 – Spring. 
[3]   Sorkine O, Alexa M. As-Rigid-As-Possible Surface Modeling. ACM International Conference Proceeding Series, Vol. 257, 2007. 
[4]   Lipman Y, Sorkine O, Levin D and Cohen-Or D. Linear rotation-invariant coordinates for meshes. ACM SIGGRAPH 2005.  
[5]   Botsch M, Kobbelt L. An intuitive framework for real-time freeform modeling. ACM SIGGRAPH, 2004. 
[6]   Yu Y, Zhou K, Xu D, Shi X, Bao H, Guo B, Shum HY. Mesh editing with poisson-based gradient field manipulation.ACM 
SIGGRAPH 2004. 
[7]   Toledo S, Chen D, Rotkin V. TAUCS: a Library of Sparse Linear Solvers. Tel Aviv University, 2003. 
[8]   Botsch M, Pauly M, Gross M, Kobbelt L. PriMo: coupled prisms for intuitive surface modeling. ACM International Conference 
Proceeding Series; Vol. 256, 2006. 
[9]   Shi X, Zhou K, Tong Y, Desbrun M, Bao H, Guo B. Mesh puppetry: cascading optimization of mesh deformation with inverse 
kinematics. ACM SIGGRAPH, 2007. 
[10]   Schlömer T, Poppinga B, Henze N, Boll S. Gesture recognition with a Wii controller. Tangible and embedded interaction, 2008. 
[11]   3D input for 3D worlds, Sreedharan S, Zurita ES, Plimmer B. OZCHI, Vol. 251, Proceedings of the 19th Australasian conference on 
Computer-Human Interaction: Entertaining User Interfaces, 2007. 
[12]   Schou T, Gardner HJ. A Wii Remote, a game engine, five sensor bars and a virtual reality theatre. OZCHI, Vol. 251, Proceedings of 
the 19th Australasian conference on Computer-Human Interaction: Entertaining User Interfaces, 2007.  
[13]   Takaaki S, Jessica KH. Accelerometer-based user interfaces for the control of a physically simulated character. ACM Transactions 
on Graphics, 2008 
[14]   Igarashi T, Matsuoka S, Tanaka H. Teddy: a sketching interface for 3D freeform design. ACM SIGGRAPH, 2007. 
[15]   Nealen A, Igarashi T, Sorkine O, Alexa M. FiberMesh: designing freeform surfaces with 3D curves. ACM Transactions on 
Graphics, 2007. 
[16]   Botsch M, Pauly M, Gross M, Kobbelt L. A sketch-based interface for detail-preserving mesh editing. ACM International 
Conference Proceeding Series; Vol. 256, 2006. 
[17]   Kho Y, Garland M. Sketching mesh deformations. ACM SIGGRAPH, 2007. 
[18]   Gingold Y, Zorin, D. Shading-based surface editing, ACM Transactions on Graphics, 2008. 
 
24
 前   言 
 
ACM SIGGRAPH 國際會議為全世界電腦圖學甚至是包含了所有圖像方面研究
領域的最重要且最頂級的國際會議，除了從事電腦圖學領域的研究人員外，關於
圖像方面的研究人員，如電腦視覺、影像處理、人機互動等亦十分重視此一國際
會議甚至將其列為重要指標之一。由於近年亞洲地區的研究風氣日漸興盛，亞洲
地區所發表的論文品質與數量亦日漸提升，因此，ACM SIGGRAPH 協會決定於
去（2008）年起，除每年夏天於北美洲地區舉辦的 ACM SIGGRAPH 國際會議外，
每年年底亦於亞洲地區舉辦 ACM SIGGRAPH Asia 國際會議，去年則是首次舉
行，會議地點為新加坡，今（2009）年的會議地點則是日本橫濱，往後將定期於
亞洲舉辦，明（2010）年的會議地點為韓國首爾，後（2011）年則暫定於中國香
港，其審稿程序完全比照 ACM SIGGRAPH 國際會議，直接刊登於頂尖期刊 ACM 
Transactions on Graphics（SCI impact factor = 3.413，ranking = 1/84）。因此，已
名列頂尖國際會議之一。 
為配合本校邁向頂尖大學計畫、提昇國際競爭力、增進國際能見度，值此見證亞
洲崛起的重大事件，本學群亦由從事電腦圖學領域的兩位研究人員代表，帶領著
碩、博士班的同學們共同組團前往觀摩，並瞭解與徵詢未來承辦此一國際會議之
可行性。此外，本學群歐陽明教授為此會議之營運委員（Steering Committee），
陳炳宇副教授及莊永裕副教授亦獲邀擔任此會議之技術論文委員（Technical 
Papers Committee），陳炳宇副教授亦另外擔任此會議之速寫及海報論文委員
（Sketches and Posters Committee）且亦擔任兩場論文主持人（Session Chair），
因此，在參加此一國際會議時，亦分別肩負了不同的任務，且因此亦更能深入此
國際會議之核心，掌握承辦此一國際會議之可行性。此外，本校今年亦有兩篇論
文及一項互動裝置將於此國際會議中發表及展示。 
今年組團前往參加 ACM SIGGRAPH Asia 國際會議的研究團隊，除了我們代表
本校參加之外，成功大學李同益教授亦率領四名博士班學生前往，交通大學莊榮
宏教授與林文杰教授等人亦共同與會。 
由於此次組團前往參加 ACM SIGGRAPH Asia 國際會議的目的之一乃為瞭解與
徵詢未來承辦此一國際會議之可行性。其中，大部分主導 ACM SIGGRAPH Asia
國際會議人士均十分期待某一年可以移師台北舉辦此一盛會，而主辦此一會議時
ACM SIGGRAPH 總會似乎會負責大部份的籌備工作，當地的承辦單位似乎工作
量並不是那麼的大，也因此，更增強了一些我們承辦此一國際會議之信心。 
ACM SIGGRAPH 國際會議與 ACM SIGGRAPH Asia 國際會議除了一般的論文
（Technical Papers）發表之外，更有許多新奇有趣的學術活動，如每年 ACM 
SIGGRAPH 國際會議的 Art Gallery 以及 Emerging Technology 都會帶來許多創
意，這些創意都讓人眼睛為之一亮。對於這些跳脫框架的創意正是我們研究上面
所需要的 — 用不同的角度來思考事情。 
 
 Webcam Clip Art: Appearance and Illuminant Transfer from Time-lapse 
Sequences 
 
  
這篇論文想做的是讓被 webcam 照下來的一連串場景，形成一個大型資料庫，接
著使用者可以利用這些當做其他數位內容的資源。所以他們的主要三個貢獻，1.
一個高品質的戶外場景資料庫。2. 在不同場景，不同光照之間的光影轉換。3. 提
供 HDR 影像生成的新演算法。 
 
 
 
Optimized Image Resizing Using Seam Carving and Scaling 
 
 
 
這篇論文要解決的是當我們 resize 影像時，因為在長寬不同比例的放大或縮小時
所造成內容的比例變形問題，從 2007 的 seam carving 提出之後就有陸續許多相
關的 paper。這篇的做法就是利用 seam carving 技術加上影像的 scaling，利用他
們定義出來的 distance function，找到一組最好的 seam carving 和 scaling 參數，
以達到 content-aware 的 resizing。由他們的結果看來效果的確不錯，不過缺點就
是無法達到 real time 的 resizing。 
 Interactive Reflection Editing 
 
 
 
這篇論文探討的問題就是如何有效的改變場景，尤其是改變物理模擬出來的結
果。一般做光影模擬都會利用物理方式來達成，可是有時藝術家不想要單純的物
理效果時會需要動手改變，這篇論文提供了一個即時有效的互動式編輯內容工
具，來提供快速產生數位內容。 
 
 
3D Polyomino Puzzle 
 
 
 
這篇論文想研究的題目是如何利用電腦來幫忙設計 3D 積木遊戲。他們的方法是
先利用積木的原型將表面分好，之後找出表面和物體中心的差距段，之後利用積
木來組合出這段差距。這中間可能遇到的問題包括在圓形部分可能會有不確定的
狀況產生，以及如何將這些積木牢固的組合在一起，他們提出了相關的解法。 
紹動畫裡用到”Dutch Camera”的手法，同樣的場景重複的出現確有不同的意義。 
光線效果(Lighting)則是介紹場景的打光，在不同的打光下會產生出不同的效果。
主要講解的主題有「UP 視覺上的宣言(UP Look Manifesto)」、「箝制(Clamping)」、「具
方向性的陰影(Directable Shadows)」、「選擇性的細節(Selective Details)」、「背景複
雜性(Background Complexity)」、「物體的特殊打光(Object Specific Lighting)」、「純
剪影 (Pure Silhouettes)」。課程裡頭提及模型 (Model)、光線 (Light)及複雜度
(Complexity)的控制，以及動畫裡採用得打光風格—「單一戲劇效果(Theatrical 
Simplexity)」，展現在顏色(color)、彩度(value)、線(Line)、形狀(Shape)、質地(Texture)
等上面的效果。 
角色設計(Characters)則是介紹 UP 裡四個主要角色的設計理念，因為在一部好的
動畫裡，角色的鮮明度是相當重要的。 
最後的場景特效(Set)則是講解整個場景在製作的設計方式，分為三大主軸：「大
小規模(Scale)」、「形狀(Shape)」、「質地(Texture)」。每個主題分「細節(Detail)」、「自
然線索(Natural Cues)」、「並列(Juxtaposition)」三個部分說明。 
 
課程非常的紮實、有趣，對於動畫的至作者而言應該會有相當的啟發，即便不是
做動畫的聽眾也會有相當大的收穫。 
What’s Your Story? 
什麼是你的故事？你能解釋它在一
個句子？如果中心思想你的電影不
是那麼清楚你，怎麼能與您的受
眾？你的故事可以通過「誰在乎」
的測詴嗎？而且你知道最重要的不
 
同項鍊一般小的裝置。而這個裝置有投影機以及攝相機，藉由攝相機來辨別手
勢，或是辨別眼前的實體物體，然後將資訊打在實體物體上面。 
Scope 
 
 
 
Scope 這個研究非常有趣，它利用追蹤人眼的視線來達到操做虛擬選單的效果。
使用者會配帶一個簡單的具有顯示效果眼鏡，而在眼鏡的上方則是有小小的攝相
機來偵測桌上的 Pattern。藉由這些二維的 Pattern，就可以顯是一些虛擬的 3D
特效或是 3D Model 在空間之中。更有趣的是，選擇這些特效或是 3D Model 時，
所使用的是眼睛定位的方式，只要朝某一個選項盯久一點，就會啟動那個選項的
功能。 
 
 
Kaidan: Japanese Horror Experience in Interactive Mixed Reality 
 
 
 
Kaidan 這個研究主要是展示 Interactive Mixed Reality 的可能性。他們利用鬼屋的
素材來讓使用者體驗虛擬實境，使用者只要戴上頭盔式的顯示裝置就可以在真實
的三維空間中進行打鬼的行動。其所體驗的感官，包括了聲音、影像回饋之外，
連地板都會隨著情境的變化而震動。 
 
 Tangible 
 
 
 
Tangible 是一個很有趣的作品。主要想表達的概念是實體世界中的物體跟虛擬世
界中的物體的互動狀況。而虛擬世界中的物體就是物體的陰影。藉由這些陰影的
動畫，來表現靜態物體的動態世界。 
 
 
scoreLight 
 
 
scoreLight 主要是希望能夠藉由偵測到使用者所繪畫出來的線條來產生聲音。兒
所產生的聲音是藉由視覺化出來的小點點來圍繞著所繪出來的線條而產生聲
音。藉此來達到互動的效果。 
 
 
  
 
 
Motion Capture 系統 
另外一個熱門展覽項目是動態捕捉系統 - motion capture，傳統的動態捕捉系統
需要攝影機和使用者身上裝上感應器來完成動作捕捉，ZeroCSeven 他們的系統提
供了兩種不同的解決方案。第一種是 Xsens MVN，如下面的照片所示，使用者穿
上特殊的感應服裝後，便可以捕捉到使用者的動作，完全不需要用到攝影機。 
 
 
97年度專題研究計畫研究成果彙整表 
計畫主持人：歐陽明 計畫編號：97-2221-E-002-110-MY2 
計畫名稱：以多重限制為主的網格形變動畫輔以先進之三維操控 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
