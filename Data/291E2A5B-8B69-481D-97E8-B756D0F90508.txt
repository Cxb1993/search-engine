introduce some serious artifacts or 
corrupt the original video seriously, and 
that could be a problem if the degraded 
video is unacceptable. Therefore, the 
focus of SR algorithms has been 
gradually shifted from uncompressed 
video sequences to compressed video 
problems because of the prosperity of 
video compression. 
   A critical factor that affects the 
result of SR is the estimate of motion 
vectors describing the original 
displacements. The motion vectors for 
the LR observations can be found during 
the compression process, these vectors 
will provide the knowledge of the true 
motion field because they can be 
regarded as the degraded version of the 
actual displacements. In this project, we 
extended the cross-diamond-hexagonal 
search (CDHS) for motion estimation 
employed in the uncompressed 
sequences to the compressed one and 
incorporate a qualification strategy into 
the estimating process to help eliminate 
the unqualified motion vectors and 
therefore strengthen the reliability of 
these suboptimal solutions. 
    To evaluate the performance of the 
proposed method, compressed video 
sequences were used in the experiments. 
We subsampled the high resolution (HR) 
sequence by a factor of 2 in both the 
horizontal and vertical direction. The 
subsampled LR sequence is compressed 
with an H.264 encoder. We run the 
encoder at both high and low bit rate to 
produce the sequences which are 
corrupted by different levels of 
quantization noises. Next the coded 
sequences are decompressed by the 
decoder, and the decoded sequences are 
used to reconstruct the HR raw sequence 
prior to the subsampling operation. The 
experiments demonstrate that the 
proposed MAP-based method outperforms 
the conventional image interpolation 
methods in both visual and quantitative 
comparisons and saves most of the 
processing time of the traditional SR 
method. The improvements of PSNR over 
the three image interpolation methods are 
3.13dB, 1.24dB, and 0.65dB, respectively. 
The proposed method performs slightly 
better than the original Bayesian MAP SR 
method but saves about 50% of the 
processing time for the compressed video. 
 
一.  緣由與目的 
Super resolution (SR) is a signal 
processing algorithm that endeavors to 
increase spatial or temple resolution of 
images from a set of low resolution (LR) 
observations. The more available low 
resolution observations provided, the 
more accurate SR reconstruction could 
be achieved. Restoration [3,7,11,28] and 
interpolation [14,15,24,40] are two 
related problems to super resolution. 
The former is just to recover the 
degraded images without changing sizes 
and the other has a difficulty of 
recovering high frequency of images. 
Thus they really can not be considered 
as super resolution techniques.  
   Today, compression version of video 
is then {1,2, , }W w  . The size of 
each HR frame is qMqN , where q is 
the magnifying factor, and that means 
each LR frame has the size of MN 
pixels. When the frames are closely 
spaced in time, then it is reasonable to 
assume that frame l can be accurately 
predicted from frame k through the use 
of a motion vector. As we signify these 
images by terms of column vectors, LR 
frames and HR frames are (MN1) 
and (qM  qN)  1 column vectors, 
respectively. Then the relationship 
between HR frames to be reconstructed 
can be depicted in the following notation 
[5]. 
        , ,( )l l k k l kf C d f n              (1) 
where ,( )l kC d   indicates the motion 
compensation procedure in matrix form 
mapping frame kf   to frame lf   , and 
the matrix is of size 
(qM  qN)  (qM  qN) ; vector ,l kd  
stands for the motion vector describing 
the motion information between frame 
kf   and frame lf   in the HR field, and 
,l kn   is the registration noise with the 
size of (qM  qN)  1 . If the motion 
compensation is represented with pixel 
accuracy, then ,( )l kC d   is a permutation 
matrix, with each entry equal to either 
zero or one. And the entries of ,( )l kC d  
are real numbers when sub-pixel motion 
is considered. On the other hand, the 
representation connecting HR and LR 
frames is denoted as 
                      l lg Hf l W                  (2) 
where H is a (M  N)  (qM  qN) 
sub-sampling matrix contains 2p values 
of 21/ p in each row, corresponding to 
the number of pixels in each 
neighborhood [31]. 
    The LR frames are compressed 
before transmission, the compression 
techniques that have some crucial 
impact on the problem formation could 
be referred to [34, 39]. Here we specify 
the relationship between the inter-coded 
frame and the uncompressed LR frame 
as [38] 
 1 1 ,
,
( )
      ( )  ,  ,
l l l k k
l k k
y T Q Q T g C v y
C v y l k W
        
 
 
                                                            (3) 
where ly   is the compressed frame, 
[ ]T    represents the discrete cosine 
transform (DCT) operation, 
and 1[ ]T     is its inverse counterpart. 
[ ]Q    and 1[ ]Q    are the quantization 
and inverse quantization procedures, 
respectively, and ,( )l k kC v y   represents 
the motion compensated prediction 
version of current frame l . It is noted 
 ,d ,  l kd l W    , the decoded frames 
in W are denoted by  y ,  ly l W    ,  
and the LR motion vectors are expressed 
as  ,v ,  l kv l W  . Now the concern is 
how to maximize the a posteriori 
probability ( ,d | y, v)kP f . By applying 
Bayes’theorem, we have 
(y, v | ,d) ( ,d)( ,d | y, v)
(y, v)
k k
k
P f P fP f
P
 (7) 
The distribution (y, v)P   is independent 
of the estimate for kf   and d , hence the 
estimate becomes 
 
,d
ˆ ˆ,d=arg max log ( ,d) (y, v | ,d)
k
k k kf
f P f P f
(8) 
Where kˆf   and dˆ   are the estimated 
version of kf   and d . Suppose that the 
decompressed LR frames y and the 
motion vectors v are independent of 
each other. Therefore, the distributionis 
given by  
,
(y, v | ,d) (y | ,d) (v | ,d,y)
                    ( | ,d) ( | ,d,y)
k k k
l k l k k
l
P f P f P f
P y f P v f
 
  
(9) 
dˆ is searched while we assume kˆf  
has already been estimated for the time 
being, and then kˆf   is searched by 
assuming that accurate dˆ   has been 
found. Thus 
 ( 1) ( )
d
ˆ ˆd arg max log (d) (y, v | ,d)kP P f
    
                             (10) 
where ( 1)dˆ     is the ( 1)  th estimate 
of the displacement and ( )kˆf
   is the 
 th estimate of the HR frame. After that, 
the pixel intensity is estimated with the 
assumption that the previously estimated 
displacement ( 1)dˆ     is correct. We have 
 ( 1) ( 1)ˆ ˆarg max log ( ) (y, v | ,d )
k
k k kf
f P f P f  
                             (11) 
By repeatedly evaluating (10) and 
(11), the final result comes out till both 
of them reach satisfying convergence. In 
(10), the first term (d)P   is usually 
assumed to be a constant value because 
it provides the estimation of d with no 
information. Hence, by combination 
(10), (9), (7), and (5), the iterative 
estimation for any ,l kd   in d is 
   
,
( 1)
,
( ) 1 ( )
, ,
2
( )
, ,
ˆ
ˆ ˆarg min ( ) ( )
ˆ( ) ( )
l k
l k
T
l l k k Q l l k kd
l k k l k k
d
y HC d f K y HC d f
C v y HC d f

 




 
 
 
(12) 
The solution of (12) can be found by 
using the block-based motion estimation 
technique. Namely, (12) becomes the 
block-matching cost function used in the 
motion estimation process to replace the 
original block-matching criterion. 
Most of the video compression 
have the right to discard the motion 
estimation result corresponding to it. 
The SAD value for each block is 
calculated. We normalize both of them 
by the number of involved pixels 
respectively, i.e., qMqN for the MFD 
and x yN N , 16*16 macroblock, for 
the SAD. After comparing these two 
parameters, if the later is greater than the 
former by a rather large number, the 
estimated displacement is then said to be 
acceptable. This criterion can be briefed 
as 
            1
x y
SAD MFD
N N qM qN       (17) 
where   is a parameter saying that the 
normalized SAD, also recognized as the 
mean square error (MSE) of the current 
block, must be at least    times less 
than the normalized MFD term. By this 
way, it helps us get rid of those 
occlusion problems and poor motion 
estimation. Moreover, the selection for 
the eligible motion vectors helps to 
compensate for the possible inaccuracy 
of the fast BMA. The general value for  
  roughly ranges from 1.0 ~ 1.5 , 
which depends on the attribute of the 
video sequence. 
The corresponding flow chart of the 
proposed SR reconstruction algorithm is 
showed as Fig. 2. 
 
Fig. 2 The corresponding flowchart of 
the proposed SR reconstruction 
algorithm. 
 
三.  研究結果 
To evaluate the performance of the 
proposed compressed sequence SR 
reconstruction, compressed video 
sequences are used for the following 
experiment. We first subsample the whole 
HR sequence by a factor of 2 in both the 
horizontal and vertical direction. Later, 
the subsampled LR sequence is 
compressed with an MPEG-4 encoder. We 
run the encoder at both high and low bit 
rate to produce the sequences which are 
corrupted by different levels of 
quantization noise. Next the coded 
sequences are decompressed by the 
decoder, and the decoded sequences are 
used to reconstruct the HR raw sequence 
prior to the subsampling operation. The 
“ Simultaneous Multi-Frame MAP 
Super-Resolution Video Enhancement 
using Spatio-Temporal Priors, ”  in 
Proc. 1999 IEEE Int. Conf. Image 
Processing, Vol. 3, pp. 469-473, 
Kobe, Oct. 1999. 
[6] N. K. Bose, S. Lertrattanapanich, 
and J. Koo, “ Advances in 
Superresolution Using L-curve,” in 
Proc. Int. Symp. Circuits and Systems, 
Vol. 2, pp. 433-436, 2001. 
[7] K. R. Castleman, Digital Image 
Processing. NJ: Prentice Hall, 1996. 
[8] C. H. Cheung and L. M. Po, “Novel 
Cross-Diamond-Hexagonal Search 
Algorithms for Fast Block Motion 
Estimation ” , IEEE Trans. 
Multimedia, Vol. 7, No. 1, pp. 16-22, 
February 2005. 
[9] Y. Altunbasak, A. J. Patti, and R. 
M. Mersereau, “ Super-resolution 
still and video reconstruction from 
MPEG-coded video,” IEEE Transa. 
Circuit Syst. Video Technol., Vol. 12, 
pp. 217-226, Apr. 2002. 
[10] B. K. Gunturk, Y. Altunbasak, 
and R. M. Mersereau, “Bayesian 
resolution enhancement 
framework for transform-coded 
video,”  in Proc. IEEE Int. Conf. 
Image Processing, 2001, Vol. 2, pp. 
41- 44. 
[11] R. C. Gonzalez and R. E.Woods, 
Digital Image Processing, 2nd. NJ: 
Prentice Hall, 2002. 
[12] Y. Altunbasak, and A. J. Patti, 
“A Maximum A Posteriori Estimator 
for High Resolution Video 
Reconstruction from MPEG Video,” 
in Proc. IEEE Int. Conf. Image 
Processing, 2000, Vol. 2, pp. 
649-652. 
[13] M. C. Hong, M. G. Kang, and A. 
K. Katsaggelos, “ An Iterative 
Weighted Regularized Algorithm 
for Improving the Resolution of 
Video Sequences,” in Proc. Int. 
Conf. Image Processing, Vol. 2, 
pp.474-477, 1997. 
[14] K. P. Hong, J. K. Paik, H. J. Kim, 
and C. H. Lee, “ An 
Edge-Preserving Image 
Interpolation System for a Digital 
Camcorder, ”  IEEE Trans. 
Consumer Electronics, Vol. 42, No. 
3, pp. 279-284, August 1996. 
[15] H. S. Hou and H. C. Andrews, 
“ Cubic Splines for Image 
Interpolation and Digital Filtering,” 
IEEE Trans. Acoust. Speech, Signal 
Proc., Vol. ASSP-26, pp. 508-517, 
December 1978. 
[16] 11aM. A. Robertson and R. L. 
Stevenson, “ DCT Quantization 
Noise in Compressed Images,” in 
Proc. IEEE Int. Conf. Image 
Processing, 2001, Vol. 1, pp. 
185-188. 
[17] D.G. Luenberger, Linear and 
Nonlinea Programming. Reading, 
MA: AddisionWesley, 1984. 
[18] M. G. Kang and A. K. 
Katsaggelos, “ Simultaneous 
Iterative Image Restoration and 
Evaluation of the Regularization 
Parameter,” IEEE Trans. Signal 
Process., Vol. 40, No. 9, pp. 
2329~2334, Sept. 1992. 
