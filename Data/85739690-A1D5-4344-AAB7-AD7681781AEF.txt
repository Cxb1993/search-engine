Real-time Target Recognition and Tracking in Visible
Spectrum Using Matlab Platform
F.Y. Hsiao∗
Abstract
In this research we study the application of MATLAB in real-time target recognition and detection. The
researches of machine vision are more and more popular in these years, and have wider and wider applications.
However, the conventional algorithms require the thresholds for image processing to be setup manually. This
research introduces the concept of statistics, and define the one-σ region as the threshold. Image momentum
are also introduce to define the shape of an object. Collaborated with color manipulation, the computer success-
fully detect the real-time selected objects. Experiments are also provided to demonstrate the robustness of our
algorithm.
I. INTRODUCTION
Machine vision has wider and wider applications in the modern world. With the commercialization
of more powerful computer and cheaper vision equipment, machine vision is applied to various fields,
including auto-detection of human face in camera, auto-detection of defection in manufacturing process,
vision-based navigation in automobile or unmanned aerial vehicles. However, to apply machine vision
in these field requires object-feature determination in advance. That is, in order to detect a certain
object, people have to determine the features of the object in advance, and “teach” the computer by
pre-assigning these parameters. In some cases, however, this procedure is not realistic.
Consider the following scenario, which is very frequently shown in movies. A commander stare at
the video sent back by an aircraft or an unmanned aerial vehicle (UAV), which circles above a field.
Then a target shows up, and the commander decide to track this target. The operator double click on
the screen and the aircraft starts to lock it on. In this scenario, the target is selected at the instance
when the commander sees it. Therefore, we cannot assign the parameters of features to the onboard
computer since we even don’t know what we are going to track. As a result, the capability of analyzing
the feature of an object in real time and identifying the object with the obtained parameters is very
important in this scenario.
More and more researches are dedicated to machine vision, as in [1] – [7], in which face recognition
are explored. Some researches employ neural networks to determine the face features [8] – [10]. In [10]
machine vision is employed to recognize hand gesture. In [11], [12], [13] machine vision are employed
to navigate and guide a UAV, or to acquire the attitude of a micro aerial vehicle.
In this research, we try to mimic the human logic in identifying a target. If the target has different
color from background, human usually track the target by its color. If the color is similar, the target
is identified and tracked by its shape. As a result, in this research we first filter the potential objects
by their color. If more than one object is filtered out, their image moment [14] is compared with the
chosen one and the one with the smallest error is identified as the target. Considering the movement of
the object, we update the parameters of the target for comparison at every instant. Computation speed
is another concern since the goal of this study is real time. Experimental results are provided to show
the validity of our algorithm.
Fu-Yuen Hsiao is with faculty of Aerospace Engineering, Tamkang University, Tamsui 251, Taiwan, ROC
fyhsiao@mail.tku.edu.tw
and σ is the standard deviation of the hue value. They are given by
µ =
1
N
m∑
i=1
n∑
j=1
h(i, j) (2)
σ2 =
1
N − 1
m∑
i=1
n∑
j=1
[h(i, j)− µ]2 (3)
This proposal is inspired by statistics. In the sense of statistics, the area within one-σ represents
70% of probability. In this case, our algorithm will include 70% of the color distribution of the object.
If more σ’s are included, the color distribution will be too wide and background noise will also be
included too.
B. Erosion, Dilation, Edge Detection
Some noises might still be left even binarization is performed. Hence, processes of erosion and
dilation helps to clean them out. The mathematic formulae for these processes are given by
ge(i, j) = g(i, j) ∩B(i, j) (4)
gd(i, j) = ge(i, j) ∪B(i, j) (5)
where the subscript e denotes erosion while subscript d denotes dilation. B(i, j) is the matrix for these
processes.
The algorithm of Sobel edge detection is employed in this research, and given by
Gx =
 −1 0 +1−2 0 +2
−1 0 +1
 ∗ g(i, j) (6)
Gy =
 −1 −2 −10 0 0
+1 +2 +1
 ∗ g(i, j) (7)
G =
√
G2x +G
2
y (8)
C. Centroid and Momentum
Once the noises of the image are filtered and the target is left and detected, we use the centroid of
this target to represent its position in the image. Assume g(i, j) is the binary intensity after noises are
filtered. Then the centroid r = (ri, rj) of an image of size m× n is given by
ri =
∑m
i=1
∑n
j=1 g(i, j) · i
M
(9)
rj =
∑m
i=1
∑n
j=1 g(i, j) · j
M
(10)
where
M =
m∑
i=1
n∑
j=1
g(i, j)
Moreover, we employ the the image momentum to represent the shape of a body [14]. The momentum
is defined by
I =
m∑
i=1
n∑
j=1
g(i, j)[(i− ri)2 + (j − rj)2] (11)
III. RESULTS AND DISCUSSION
Our algorithm is tested in two parts: static tests and dynamic tests. The static tests demonstrate the
target detection capability, while the dynamic tests demonstrate the capability of real-time process.
A. Static Tests
1) Simple Object in Noisy Environment: In the first part, static tests are perform to demonstrate the
target detection capability. In order to show the validity of applying our algorithm in real world, we
don’t adopt clean background as usually done. At the first stage of the experiment, a circular wooden
color paper is selected as the target to identify, as shown in Fig. 6. Then papers of the same shape, but
different colors are added into the background to increase potential noises, as shown in Figs. 7 and 8.
We can see that the computer still recognize the correct object even under “shape” disturbances.
Fig. 6. Circular wooden color test
Fig. 7. A red, circular paper is added as the background
Fig. 8. A colorful, circular paper is added as the background
Fig. 12. Experiment results. The small colorful paper is successfully detected in a noisy environment where there is a disturbance of
the same color but different shape.
3) Validity of Image Momentum: This experiment tests the validity of image momentum. In practical
issues we don’t think an object different even though it rotates. However, a computer usually does.
Therefore, to prevent this situation, we introduce the image momentum to define a shape. As we know,
the moment of inertia about rotating axis should be invariant, and different shapes share different
inertia. Consequently, we use three objects, each having the same color but different shape, to confuse
the computer. Figures 13 to III-A.3 give examples of this experiment. In Fig. 13 the rectangular object
is selected as the target. In Figs. 14 to 16 noises are added in, including object rotation, blur vision,
and misalignment of image plane, etc. Our algorithm still detects the correct object.
Fig. 13. The rectangular object is selected as the target.
Fig. 14. The target rotates 90 degrees.
In Figs. 17 and III-A.3, more severe environment are introduced in the experiment. A noisy environ-
ment is created in this experiment and the image plane doesn’t align with the target either. In Fig. 17
the blue sheet is successfully detected and in Fig. III-A.3 the pre-assigned colorful sheet is recognized.
This demonstrates the robustness of our algorithm in automatic detection of target.
Fig. 19. Continuous images of dynamic tests. The figure sequences list from left to right, top to down.
paper is moving arbitrarily by the operator. We record the frames where the computer successfully detect
the target, and the processing time in this experiment. The result is shown in Fig. 20, and summarized
in Table II. Here we define the success rate as
Success Rate =
Ns
N
× 100% (12)
where Ns denotes the number of frames where target successfully detected, and N is the total number
of processed frames.
We can see that the averaged processing time is less than 0.1 seconds and the success rate is more
than 80%. It means that we can perform this algorithm in 10 Hz. Actually, if certain computation such
as filtering is taken away for a clean background, the processing time can be much shorter.
Fig. 20. Processing time of each frame
IV. CONCLUSION
In this research we study the application of MATLAB in real-time target recognition and detection.
The researches of machine vision are more and more popular in these years, and have wider and wider
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                       100  年  2  月  25  日 
報告人姓名 蕭富元 
Fu-Yuen Hsiao 
 
服務機構 
及職稱 
淡江大學航太系 
助理教授 
 
   時間 
會議地點 
100/2/14-100/2/17 
New Orleans, LA, USA 
本會核定 
補助文號 
國科會補助編號: 
NSC-99-2221-E-032-013- 
會議 
名稱 
 (中文) 2011 年度 AAS/AIAA 太空飛行力學會議 
 (英文) 2011 AAS/AIAA Space Flight Mechanics Meeting 
發表 
論文 
題目 
(中文) AAS 11-269 使用雷射光推進系統之太空船軌跡分析 
(英文) AAS 11-269 Trajectory Analysis of Spacecraft Propelled by Photonic 
Laser Propulsion System 
報告內容應包括下列各項： 
一、參加會議經過 
2/13 抵達及註冊 2/16 與其它學者交流及討論 
2/14 與其它學者交流及討論 2/17 
上午發表論文 AAS 11-269 
下午離開 New Orleans, LA 
2/15 與其它學者交流及討論   
 
二、與會心得 
AAS/AIAA Space Flight Mechanics Meeting 為美國太空學門之重要學術發表會之一。此次
與會不僅有機會將本身之研究公之於世，亦是一個與全世界其它學者互相切磋之難得機會。此
次在會議中所發表的論文「使用雷射光推進系統之太空船軌跡分析」為世界上最新之議題，
因為雷射光推進系統於 2008 年才被正式提出與受到重視，目前為止尚未有學者對其軌跡進行分
析，故在四天的會議之中，各界的學者不但對我的研究提出許多精闢的見解和意見，我也攜回
了許多有用的資料，以做為日後研究時的參考。此外，許多學者亦向我表示合作的興趣，為將
來國際合作打開一扇窗。 
 
三、考察參觀活動(無是項活動者省略) 
參觀位於密西西比州之 NASA Stennis Space Center 
四、建議 
無 
五、攜回資料名稱及內容 
Proceeding of 2011 AAS/AIAA Space Flight Mechanics Meeting 
六、其他 
無 
 
附
件
三 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：蕭富元 計畫編號：99-2221-E-032-013- 
計畫名稱：以 Matlab 為平台進行可見光域即時目標辨視及追蹤 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 0 60%  
研討會論文 4 0 30% 
篇 三篇為本計畫經
費資助發表, 一
篇為本計畫直接
產出成果. 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 8 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 0 10% 
篇 
為本計畫經費資
助發表 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 8 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
