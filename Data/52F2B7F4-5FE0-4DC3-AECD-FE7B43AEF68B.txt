I 
 
中文摘要 
本計劃的主要目標是發展一個基於亮度適應與對比強化的彩色影像自動調整機制。 
本方法具有三項特性：（1）適當的調整影像的明暗度；（2）適度的強化影像細節及(3)呈現近似正確
的顏色。首先，輸入影像無論品質好壞，經過全域性明暗調整找到一較佳的亮度準位，再由區域性明
暗調整機制突顯影像內的過暗區與過亮區，此機制奠基於遞迴式區域亮度適應架構，可為每一像素找
到其最佳輸出入轉換曲線。隨後針對明暗調整完之影像進行對比強化以突顯影像細節。與其他方法經
由實驗結果比較發現本方法的有效性。 
 
關鍵字：影像明暗調整、影像強化、Retinex、HDR 色調映射、色彩恆常性、明度恆常性 
 
Abstract 
The purpose of this project is to develop an automatic image adjustment algorithm based on luminance 
adaptation and contrast enhancement mechanisms. The proposed algorithm has three important properties: (1) 
appropriately adjusting image luminance, (2) properly enhancing image details, and (3) correctly presenting 
image colors. Firstly the global lightness adjustment produces an appropriate brightness level for a given 
image. Subsequent local luminance adaptation scheme enhances the under-/over-exposed regions of the 
image. This scheme is based on recurrent local intensity adaptation. An optimal mapping curve for each 
pixel is determined by the local adaptation level through a nonlinear recurrent framework. And then, the 
color details of the luminance adjusted image are enhanced by the contrast adjustment mechanism. We show 
that our algorithm efficiently improves the luminance and color appearance of images and we compare our 
results with the current state-of-the-art methods. The proposed image adjustment algorithm can be 
implemented as a front-end module in a computer vision system or an image processing system. 
 
Keyword：Luminance adjustment, Image enhancement, Retinex, HDR tone mapping, Color constancy, 
Lightness constancy 
 
 
2 
 
濾波在灰階差異小的區域使得原本的黑區或白
區皆轉變為灰區的一種現象。雖然可藉著多尺度
或可變尺度空間濾波減少此兩種瑕疵，但也意味
著計算複雜度的增加。 
針對上述瑕疵問題，我們提出區域灰階適應
方法強化影像中的低度曝光與過度曝光區域。區
域運算子對每一像素依據其鄰近區域內之灰階
分布計算該像素的明暗適應值，而此適應值決定
此像素的灰階轉換曲線。我們使用固定尺度的空
間濾波並配合非線性的遞迴架構獲得每一像素
的最佳明暗適應值，亦即產生最佳的轉換曲線。
相對於過去使用多尺度空間濾波的方法，本方法
更能減低或消除光暈與灰化瑕疵並減少計算量。 
 
2.1 灰階影像的明暗調整 
由於彩色影像的紅、綠、藍三成份皆使用相
同的方式處理，因此我們先針對單一成份之灰階
影像介紹如何導出區域明暗適應值。假設輸入為
已 gamma 預處理後之影像。 
計算區域明暗適應值的目的是決定每一像
素的最佳轉換曲線，而每一像素的明暗適應值則
是代表該區域的平均明暗資訊，因此相同灰階的
兩個像素，一個座落於較亮的區域，而另一個像
素則座落於較暗的區域，由於兩者的明暗適應值
不同，此兩像素的轉換值當然也不相同，以下將
闡明依據明暗適應值導出的轉換曲線。 
 
(1) 增強轉換曲線 
令 ),( yxI 代表影像的灰階值，其中 ),( yx 為影像
空間座標， [ ]1,0),( ∈yxI 。增強轉換曲線的功能是將
輸入灰階值轉換成較高的灰階值，其數學定義如
下 
),(),(
),()],([),(
1
1 yxIyxI
yxIyxIIyxI
av
avmaxb ++=  (1)
其轉換曲線如圖 1(a)所式，橫坐標代表輸入值而
縱座標為輸出(或轉換)值，上式中的 1=maxI 代表
最大的輸入灰階值， ),(1 yxIav 是像素在 ),( yx 位置
的增強型區域明暗適應值，其式為 
.),(),( 01 cyxIyxI
p
lpav +=  (2)
其中常數 0c 為所設定的最小適應值，而
),( yxIlp 則為輸入影像經過高斯遮罩平滑的
低通濾波影像，參數 p 將於後面討論其設定
方式。從圖 1(a)可知，當增強型適應值
),(1 yxIav 越小，其對應的輸出值 bI 越大。 
 
(a) 增強轉換曲線 
 
(b) 抑制轉換曲線 
圖 1. 增強型與抑制型轉換曲線 
 
(2) 抑制轉換曲線 
所謂的抑制轉換曲線是將輸入灰階值轉換為
較低的輸出值，其數學定義如下 
),(),(
),(),(
),(
2
2
yxIyxII
yxIyxI
yxI
avmax
av
s −+
⋅=  (3)
圖 1(b)描述該轉換曲線，上式中的 ),(2 yxI av 代表
像素在 ),( yx 位置的抑制型區域明暗適應值，其式
為 
4 
 
圖 4(a)為一張測試用灰階影像，由於該張影
像是由車內往外拍攝，使得車內過暗而車外則是
過度曝光。經由本方法的明暗調整，其結果如圖
4(b)所式，車內的大部分細節皆能清楚的呈現。
圖 4(c)顯式輸出與輸入兩張影像的差異，圖中的
白色區域代表原始影像中的過暗區，其亮度在輸
出影像中獲得提升，相對的，圖中的黑色區域為
原始影像中的過亮區，其亮度在輸出影像中受到
壓抑，而圖中的灰色區域則是正確的曝光區，輸
入灰階值保持不變。圖 4(d)中的每一個紫色點代
表輸入像素值映射到輸出像素值，從圖中紫色點
的分佈說明一條全域的轉換曲線是無法產生相
比擬的輸出結果。由於高頻影像可表示影像對
比，我們分別產生原始影像與輸出影像的高頻影
像，顯示於圖 4(e)與(f)，並計算他們的平均絕對
對比值，明暗調整後的平均絕對對比值相較於原
始影像提升 53%。 
 
(a) (b) 
  
(c) (d) 
 
(e) (f) 
圖 4. 灰階影像測試範例 
 
2.2 彩色影像的明暗調整 
前述的灰階值影像明暗調整方法可輕易的擴
展到彩色影像，其步驟如下：(1) 取出彩色影像
的亮度成份進行灰階拉伸，(2)明暗遞迴調整，(3)
色彩恢復。我們假設輸入影像色彩正確並已完成
gamma 預處理。 
(1) 線性拉伸亮度成份 
令輸入的彩色為 ),,(),,( BGRiyxfi ∈ 。經由彩色
座標轉換分離出亮度與色彩成份，轉換公式如下 
⋅
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎢
⎣
⎡
−
−
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
),(
),(
),(
 
3
1
3
1
3
1
3
2
6
1
6
1
0
2
1
2
1
),(
),(
),(
yxf
yxf
yxf
yxI
yxYB
yxRG
B
G
R
 (9)
其中 RG 與 YB 代表色彩成份，亮度成份 ),( yxI 之
灰階值經線性拉伸到全範圍，此步驟僅能改善低
對比影像品質。由於亮度成份並不包含彩色影像
全部之資訊，我們將拉伸的亮度成份與原始的色
彩成份轉換至 RGB 座標系統，令此彩色影像為
),,(),,(ˆ BGRiyxfi ∈ 。 
 
(2) 遞迴明暗調整彩色三成份影像 
首先針對彩色影像 ),,(),,(ˆ BGRiyxfi ∈ 之三成份
找到各自的最大值，並以此最大值對各自成份影
像進行正規化，接著使用(6)式分別遞迴調整每一
成份的明暗度，其中(6)式中的影像平均值取三成
份的最大平均值，低頻影像定義為三成份的平均
低頻影像，最後明暗調整完的影像需再乘回原始
三成份的最大值。 
 
(3) 恢復顏色 
我們必須對明暗調整影像恢復原始影像的色
彩資訊。色彩恢復程序是在線性灰階域(未 gamma
預處理 )進行。令明暗調整完之輸出影像為
( )BGRiyxhi ,,),,(ˆ ∈ 。每一像素的輸出亮度與輸入亮
度之比值定義為 
，ε+= ),(
),(),(
yxf
yxhyxratio  (10)
其中 ε 為非零的最小數值，  
.3/)],(ˆ),(ˆ),(ˆ[),(
3/)],(ˆ),(ˆ),(ˆ[),(
,,,
,,,
yxfyxfyxfyxf
yxhyxhyxhyxh
linearBlinearGlinearR
linearBlinearGlinearR
++=
++=
 
為壓抑極大偏差值，將原定義的亮度比值壓縮轉
換為 
6 
 
比弱化,因此需要對比強化機制突顯低對比區域
的影像細節。我們取彩色影像的亮度成份 ),( yxI
進行對比強化，每一像素的強化亮度對比定義如
下: 
∑∑
∈
−−Δ⋅=
masknm
nymxgymyxyxC
,
),()],;,(tanh[),( α  
其中 ),(),(),;,( mymxIyxIymyx −−−=Δ 代表像素位
置 ),( yx 與像素位置 ),( mymx −− 之間的亮度差異，
而 )(⋅g 則是高斯遮罩， 8.1=σ ,為了達到強化弱對
比的同時，又能抑制強對比，我們選擇使用 tanh
函數調整亮度差異,參數α 控制強化程度。 
由於強化的亮度對比 ),( yxC 為高頻影像,必需
將其重建回亮度成份，我們發展出利用高斯微分
小波濾波器組將此對比影像進行多解析分解再
組合，此一步驟可視為將強化的對比影像投影到
高斯微分小波基底上，使其符合重建條件，最後
透過共軛梯度法重建強化的亮度成份影像。 
 
5. 實驗結果與比較 
我們先針對標準動態範圍影像進行區域式明
暗調整測試，並與其它方法比較實驗結果，再對
HDR 影像測試整個演算方法的效益。 
 
5.1 標準動態範圍影像測試 
此節主要目的是測試區域式遞迴明暗調整
方法的效能,演算法的參數皆為自動設定，輸出結
果將與 MSRCR, ACE 及 Center-Surround 方法之
結果相互比較。 
    首先採用 Yale Face Database B[12]之灰階人
臉影像說明本方法的亮度適應機制。資料庫中的
每一個實驗者的人臉在 65 種光源下拍攝產生 65
張同一人臉照片，圖 7 中的左欄 4 張影像代表其
中一個實驗者在 4 種光源下的拍攝結果，經明暗
調整後的影像顯示於圖 7 中的右欄,可以發現暗
區的細節清楚呈現，不過亮區的對比則受到壓
抑，整體觀察，明暗調整後的影像呈現近似的明
度恆常性，我們的方法勿需估測照明成份亦能降
低其影響性。我們也分別對 65 對原始人臉影像
與其明暗調整影像計算它們的灰階平均值，標準
離差及梯度平均值。圖 8(a)的橫座標為灰階平均
值,縱座標為梯度平均值，圖中的紅點代表 65 張
原始影像的灰階平均值與梯度平均值的分佈，而
綠色點則是代表明暗調整後的分佈結果，藍色箭
號指明暗調整前後的對應影像，可以發現綠色點
之分佈較為集中，這說明調整後之影像其平均值
皆趨於一個小範圍,使得明度恆常性獲得保持。在
圖 8(b)中所顯示的灰階平均值與標準離差的分
佈，也同樣顯示綠色點具有集中性。比較圖 8(a)
與(b)可知明暗調整後的影像其梯度平均值上
升，但是其標準離差反而下降,這反映出調整完的
影像無法同時兼顧整體對比與區域對比。 
不同型態的彩色影像用於測試本方法及其
他方法，由於缺乏客觀的量化評比指標，只能依
據主觀的觀察比較，測試結果顯示於圖 9。 
圖 9 中的前四列實驗結果所使用的測試影像皆包
含過暗區與過亮區，雖然 MSRCR 之輸出具有不
錯的對比，但該方法會產生不可忽視的光暈瑕
疵、雜訊及不自然的顏色。ACE 方法則不適合處
理這類測試影像。Center-Surround 方法輸出相當
好的結果，不過仍然會產生光暈與灰化瑕疵，同
時在細微紋理如頭髮與灌木叢區產生輕微的模
糊現象，另外在老人頭部區亦產生方塊狀瑕疵。
我們的方法皆能校正不正確的曝光區域，同時給
予自然的色彩表象。第五列的測試影像為低對
比，因此呈現霧狀，我們的方法產生最好的影像
細節及真實的顏色，ACE 的輸出與我們的結果相
當接近，MSRCR 方法雖能增強區域對比但無法
提升整體對比，而 Center-Surround 方法確實增強
影像細節不過流失了顏色資訊。最後一張測試影
像為正確曝光影像，因此無需改善，此張影像的
測試目的是觀察演算方法是否能保持原本就無
須改善品質的影像，發現只有 ACE 方法會破壞
原始影像的顏色資訊。 
 
 
 
8 
 
7. 參考文獻 
[1] M.-J. S. a. V. K. A. Li Tao, “Nonlinear 
Image Enhancement to Improve Face Detection 
i n  C o mp l e x  L i g h t i n g  E n v i r o n me n t , ” 
International Journal of Computational 
Intelligence Research(IJCIR), vol. 2, no. 4, 
2006, pp. 327-336. 
 
[2] E. H. Land, “The Retinex,” American 
Scientist, vol. 52, no. 2, 1964, pp. 247-264. 
 
[3] F. Ciurea and B. Funt, “Tuning Retinex 
Parameters,” Journal of Electronic Imaging, vol. 
13, no. 1, 2004, pp. 58-64. 
 
[4] B. Funt, F. Ciurea, and J. McCann, “Retinex 
in MATLAB™,” Journal of Electronic Imaging, 
vol. 13, no. 1, 2004, pp. 48-57. 
 
[5] D. J. Jobson, Z. Rahman, and G. A. Woodell, 
“Retinex Processing for Automatic Image 
Enhancement,” Journal of Electronic Imaging, 
vol. 13, no. 1, 2004, pp. 100-110. 
 
[6] A. Rizzi, C. Gatta, and D. Marini, “From 
Retinex to Automatic Color Equalization: Issues 
in Developing a New Algorithm for 
Unsupervised Color Equalization,” Journal of 
Electronic Imaging, vol. 13, 2004, no. 1, pp. 
75-84. 
 
[7] E. Provenzi, C. Gatta, M. Fierro, and A. 
Rizzi, “A Spatially Variant White-Patch and 
Gray-World Method for Color Image 
Enhancement Driven by Local Contrast,” IEEE 
Trans. Pattern Anal. Mach. Intelligence., vol. 30, 
no. 10, 2008, pp. 1757-1770. 
 
[8] V. Vonikakis, I. Andreadis, and A. Gasteratos, 
“Fast Centre–Surround Contrast Modification,” 
IET Image Process, vol. 2, no. 1, 2008, pp. 
19-34. 
 
[9] E. Reinhard, M. Stark, P. Shirley, and J. 
Ferwerda, “Photographic Tone Reproduction for 
Digital Images,” ACM Transactions of Graphics, 
(in Proceedings of the ACM SIGGRAPH'02 
Conference), vol. 21, no. 3, July 2002, pp. 
267-276. 
 
[10] R. Fattal, D. Lischinski, and M. Werman, 
“Gradient Domain High Dynamic Range 
Compression,” ACM Transactions of Graphics, 
(in Proceedings of the ACM SIGGRAPH'02 
Conference), vol. 21, no. 3, July 2002, pp. 
249-256. 
 
[11] F. Durand and J. Dorsey, “Fast Bilateral 
Filtering for the Display of High Dynamic 
Range Images,” ACM Transactions of Graphics, 
(in Proceedings of the ACM SIGGRAPH'02 
Conference), vol. 21, no. 3, 2002, pp. 257-266. 
 
[12] A. S. Georghiades, P. N. Belhumeur, and D. 
J. Kriegman, "From Few to Many: Illumination 
Cone Models for Face Recognition under 
Variable Lighting and Pose," IEEE Trans. 
Pattern Anal. Mach. Intelligence, vol. 23, no. 6, 
2001, pp. 643-660. 
 
[13] R. Mantiuk, K. Myszkowski, and H.-P. 
Seidel, “A Perceptual Framework for Contrast 
Processing of High Dynamic Range Images,” In 
ACM Transactions on Applied Perception vol. 3, 
no. 3, 2006, pp. 286-308. 
10 
 
Original images Proposed method Reinhard Mantiuk Fattal 
     
     
圖 10. HDR 影像測試結果 
 
關領域的科學研究活動外，最重要的是促進不同領域的科技成果能相互傳播與互動。
因此與會者可以自由參加MULTICONF-10舉辦之研討會。茲將今年MULTICONF-10
包括的 10個國際學術會議，列舉如下 
International Conference on Artificial Intelligence and Pattern Recognition (AIPR-10)  
International Conference on Automation, Robotics and Control Systems (ARCS-10)  
International Conference on Bioinformatics, Computational Biology, Genomics and 
Chemoinformatics (BCBGC-10) 
International Conference on Computer Communications and Networks (CCN-10) 
International Conference on Enterprise Information Systems and Web Technologies 
(EISWT-10)  
International Conference on High Performance Computing Systems (HPCS-10)  
International Conference on Information Security and Privacy (ISP-10)  
International Conference on Image and Video Processing and Computer Vision 
(IVPCV-10) 
International Conference on Software Engineering Theory and Practice (SETP-10)  
International Conference on Theoretical and Mathematical Foundations of Computer 
Science 
 
大會安排國際知名電腦科學學者 Naphtali David Rishe教授，佛羅里達國際大學
的 the inaugural outstanding university professor , 進行 keynote speech , 講題為” 
TerraFly : GIS Integration Solution “ , 演講內容精彩豐富，獲益良多。TerraFly是一個
結合 40 兆位元組空照影像資料庫與以網路為基礎的地理資訊系統(GIS)的動態瀏覽
器。該研發計畫獲得 NSF、NASA、USGS及 IBM等單位的贊助，計畫成果廣泛被應
用到各產業領域，如政府單位、旅遊、教育、地產及保險等。主要技術包括多重型態
資料搜尋、影像拼接、GIS系統介面之最佳化，瀏覽加速演算法等。 
 
本人在 IVPCV-10 所發表的論文內容主要是發展一個全自動的影像明暗度調整方
機，亦可應用於視訊廣播產業，可是此次 IVPCV-10著墨於此課題的論文非常少，
實屬可惜。 
本人亦參加MULTICONF-10其他學術會議所發表的論文場次，比較有趣的論
文如下 : 以角色為基礎的 Particle Swarm Optimization 演算法應用於網頁文件的聚
類，具有智慧的醫學影像瑕疵偵測方法，適應與有效的資料流(data streams)分類器，
利用訊息理論的紋理特徵計算法，語音信號的時變強健濾波法，使用模糊邏輯法的
多感測器資料融合，新的向量支持機(SVM)學習演算法，基於資訊學習法的盲等化
方法(blind equalization)，時頻分佈建模方法，使用展頻技術的隱藏資訊於音訊之方
法，人眼位置的智慧檢測方法等。從所聆聽的論文發覺多重型態資料的分析、整合、
學習及應用仍是目前電腦科學領域的熱門研究課題，此次的研討會也給予本人目前
正研究的主題很多重要的啟發及未來研發方向的設定，收穫豐富。 
三、攜回資料名稱及內容 
此次會議結束後，本人帶回 IVPCV-10論文集光碟一片與個人筆記。本人非常
感謝國科會與逢甲大學分別補助本人參加此次研討會。在會議中認識了來自各國的
學者，經由討論與意見交換，使我受益良多，同時也埋下日後進一步合作的種籽 
 
2.2. Suppressive mapping curves images. A local operator would compute a local 
adaptation level for each pixel based on a neighborhood 
of pixels surrounding the pixel of interest. This local 
adaptation level then drives the mapping curve for this 
pixel. A nonlinear recurrent framework instead of multi-
scale scheme is adopted to attain an optimal adaptation 
level for each pixel. The framework better prevents halo 
and greying-out artifacts and reduces computational 
complexity. 
 
A suppressive mapping curve maps the original input 
intensity levels to the lower ones. It is defined by 
 
2. Recurrent local intensity adaptation for 
grey-level images 
 
The proposed algorithm processes each component of a 
color image by the same procedure. Hence, we derive the 
method of recurrent local intensity adaptation for grey-
level (one-component) images first. Gamma corrected 
input images are assumed. 
 
Derive an optimal mapping curve for each pixel is the 
goal of local intensity adaptation. A local adaptation level 
at a given pixel represents the local luminance of its 
neighborhood. This local adaptation level will determine 
how the considered pixel is mapped. A bright pixel in a 
dark neighborhood will be treated differently than a 
bright pixel in a bright neighborhood. A similar argument 
can be made for dark pixels with bright and dark 
neighborhoods. We shall develop these mapping curves 
based on the local adaptation levels step by step. 
 
2.1. Boosting mapping curves 
 
The intensity of a given image is denoted by , 
where x and y represent spatial position, and 
),( yxI
[ ]1,0),( ∈yxI . 
A boosting mapping curve maps the original input 
intensity levels to the higher ones. It is defined by 
),(),(
),()],([),(
1
1 yxIyxI
yxIyxIIyxI
av
avmaxb ++=  (1)
and is depicted in Figure 1(a), where indicates the 
maximum of the input intensity, and  represents 
the local adaptation level of boost at and it is given 
by 
1=maxI
,(1 yxIav
),( yx
)
.),(),( 01 cyxIyxI
p
lpav +=  (2)
The constant sets the minimum local adaptation level. 
The term denotes the low-pass filtered intensity 
image with a Gaussian mask. The parameter p will be 
discussed later. The smaller the local adaptation level of 
boost, , is given, the higher the mapped intensity, , 
is produced. 
0c
,( yx )I lp
1avI bI
),(),(
),(),(),(
2
2
yxIyxII
yxIyxIyxI
avmax
av
s −+
⋅=  (3)
and is depicted in Figure 1(b), where represents 
the local adaptation level of suppression at  and it is 
given by 
),(2 yxIav
),( yx
.)],([),( 02 cyxIIyxI
p
lpmaxav +−=  (4)
 
(a) Boosting mapping curves 
 
(b) Suppressive mapping curves 
 
Figure 1. The graphical depiction of Eqs. (1) and (3). 
 
2.3. Boosting and suppressive mapping curves. 
 
By integrating both boosting and suppressive mapping 
curves, we obtain a complete mapping mechanism that 
adjusts the input intensity at each pixel to its local 
neighborhood. The adapted output intensity, ),(~ yxI , is 
given by 
,
),()],()[,(
)],([),(~ ),(
),(
yxbyxIyxa
yxIyxI yxm
yxm
+=  (5)
where 
],5.0),([|5.0|5.11),( −⋅−+= yxIIyxm lp   
 
 
(a) (b) 
 
(c) (d) 
 
(e) (f) 
Figure 4. An example of a grey-scale test image. 
 
3. Extending the algorithm to color images 
 
The proposed algorithm for color images is composed 
of three major steps: (1) image intensity component 
stretching; (2) recurrent local intensity adaptation; (3) 
color restoration. We use gamma corrected color images 
as input. We assume that colors of the original images are 
correct. 
 
3.1. Linearly stretching the intensity component 
 
Denote a color image by . We use the 
RGB-to-RG/YB/I color transformation to decorrelate 
chromatic and achromatic information. The color 
transformation is defined by 
),,(),,( BGRiyxfi ∈
⋅
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎢
⎣
⎡
−
−
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
),(
),(
),(
 
3
1
3
1
3
1
3
2
6
1
6
1
0
2
1
2
1
),(
),(
),(
yxf
yxf
yxf
yxI
yxYB
yxRG
B
G
R  
(9)
The intensity component is stretched linearly to its 
full range. This preprocessing step only improves the 
appearances of the low contrast images. Since the 
intensity component does not contain complete image 
luminance information, we convert the stretched intensity, 
with the original RG and YB components, to RGB color 
space. The resulted color image, indicated by 
, still keeps the initial chrominance. 
The automatic luminance adjustment algorithm is applied 
to this color image instead of its intensity component. 
),( yxI
),,(),,(ˆ BGRiyxfi ∈
 
3.2. Recurrent local intensity adaptation for each 
color component. 
 
Each color component is normalized to the maximum 
of its respective component first. Then, we apply Eq. (6) 
to adjust every color component. Note that the global 
mean expressed in Eq. (6) is defined as the maximum 
mean of the three color components. The local mean 
indicated in Eq. (6) is determined by the average of the 
three low-pass filtered color components. Finally, the 
adjusted image is de-normalized by the maxima of their 
respective original color components. 
 
3.3. Color restoration 
 
The final enhanced color image is obtained by 
restoring the chromatic information of the original input 
image. The color restoration procedure is conducted in 
the linear intensity domain (without gamma correction). 
Denote the output image produced by the algorithm of 
recurrent local intensity adaptation as ( )BGRiyxi ,,),,(ˆ ∈h . 
The output-to-input intensity ratio is computed at each 
pixel by 
，ε+= ),(
),(),(
yxf
yxhyxratio  (10)
ε is the smallest non-zero numeric value， where 
.3/)],(ˆ),(ˆ),(ˆ[),(
and3/)],(ˆ),(ˆ),(ˆ[),(
,,,
,,,
yxfyxfyxfyxf
yxhyxhyxhyxh
linearBlinearGlinearR
linearBlinearGlinearR
++=
++=
,)],(tanh[),( yxratioyx ⋅
 
To suppress the outliers, the output-to-input intensity 
ratio is compressed by 
λ =α β  (11)
and)],([10 yxratiomeanα = ⋅where )(tanh 11 −−= αβ . 
The parameter β keeps the unity ratio unchanged. Finally, 
the enhanced output color image is generated by 
~
.),,(),,(ˆ),(),( (12),, BGRiyxfyxyxf linearilineari ∈⋅= λ
( )yx,
The color information of hue and saturation in the 
original image is preserved in the output color image.  
 
Figure 5(a) shows a color test image which is the 
color version of Figure 4(a). The final enhanced color 
image is shown in Figure 5(b). Figure 5(c) shows the 
nonlinearly transformed ratio pattern λ , where the 
brighter regions indicate the higher ratios.  
6. References 
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45
0.18
0.2
0.22
0.24
0.26
0.28
0.3
gray-level mean
gr
ay
-
le
ve
l s
ta
nd
ar
d 
de
vi
at
io
n 
 
(b) Grey-level means versus standard deviations 
Figure 7. Statistical data of 65 image-pairs.
 
[1] E. H. Land, “The Retinex,” American Scientist, vol. 52, no. 
2, 1964, pp. 247-264. 
 
[2] F. Ciurea and B. Funt, “Tuning Retinex Parameters,” 
Journal of Electronic Imaging, vol. 13, no. 1, 2004, pp. 58-64. 
 
[3] B. Funt, F. Ciurea, and J. McCann, “Retinex in 
MATLAB™,” Journal of Electronic Imaging, vol. 13, no. 1, 
2004, pp. 48-57. 
  [4] D. J. Jobson, Z. Rahman, and G. A. Woodell, “Retinex 
Processing for Automatic Image Enhancement,” Journal of 
Electronic Imaging, vol. 13, no. 1, 2004, pp. 100-110. 
Different types of color images were used to evaluate 
the results of our algorithm and other methods. Since 
there is lack of an appropriate no-reference image quality 
metric, the characteristics of each method are manifested 
by mutual comparison. The results are shown in Figure 8. 
The original images shown in the first four rows have 
various under-/over-exposed regions. MSRCR exhibits 
generally good contrasts. Nevertheless, this method 
generates halo artifacts, noise, and unnatural colors. ACE 
dose not perform well on these images. Center-Surround 
produces fairly good results. However, it still generates 
halo and greying-out artifacts. Fine textures such as hair 
and bush areas are mildly blurred. Blocky artifacts 
appeared on the old man image. Our method adequately 
enhances the incorrectly exposed regions. It gives natural 
color appearances on test images. The test image in the 
fifth row has a low global contrast because of a foggy 
condition. Our method exhibits the best result in terms of 
detail visibility and the original color fidelity. The result 
of ACE is comparable to ours. MSRCR does improve the 
local contrast but without improving the global contrast 
of the image. Center-Surround loses the original colors 
although it enhances image details. The test image in the 
last row is well exposed and needs no improvement. It is 
used to evaluate the ability of a method to preserve an 
image that does not need any improvement. Our method, 
MSRCR, and Center-Surround all produce images nearly 
the same as the original one. Only ACE gives an image 
with distorted colors. 
 
[5] A. Rizzi, C. Gatta, and D. Marini, “From Retinex to 
Automatic Color Equalization: Issues in Developing a New 
Algorithm for Unsupervised Color Equalization,” Journal of 
Electronic Imaging, vol. 13, 2004, no. 1, pp. 75-84. 
 
[6] E. Provenzi, C. Gatta, M. Fierro, and A. Rizzi, “A Spatially 
Variant White-Patch and Gray-World Method for Color Image 
Enhancement Driven by Local Contrast,” IEEE Trans. Pattern 
Anal. Mach. Intelligence., vol. 30, no. 10, 2008, pp. 1757-1770. 
 
[7] V. Vonikakis, I. Andreadis, and A. Gasteratos, “Fast Centre–
Surround Contrast Modification,” IET Image Process, vol. 2, no. 
1, 2008, pp. 19-34. 
 
[8] E. Reinhard, M. Stark, P. Shirley, and J. Ferwerda, 
“Photographic Tone Reproduction for Digital Images,” ACM 
Transactions of Graphics, (in Proceedings of the ACM 
SIGGRAPH'02 Conference), vol. 21, no. 3, July 2002, pp. 267-
276. 
 
[9] R. Fattal, D. Lischinski, and M. Werman, “Gradient Domain 
High Dynamic Range Compression,” ACM Transactions of 
Graphics, (in Proceedings of the ACM SIGGRAPH'02 
Conference), vol. 21, no. 3, July 2002, pp. 249-256. 
 
[10] F. Durand and J. Dorsey, “Fast Bilateral Filtering for the 
Display of High Dynamic Range Images,” ACM Transactions of 
Graphics, (in Proceedings of the ACM SIGGRAPH'02 
Conference), vol. 21, no. 3, 2002, pp. 257-266. 
  
5. Conclusion [11] A.S. Georghiades, P.N. Belhumeur, and D.J. Kriegman, 
"From Few to Many: Illumination Cone Models for Face 
Recognition under Variable Lighting and Pose," IEEE Trans. 
Pattern Anal. Mach. Intelligence, vol. 23, no. 6, 2001, pp. 643-
660. 
 
We have presented an effective method of improving 
image luminance appearance based on recurrent local 
intensity adaptation. An optimal mapping curve is 
attained for each pixel by updating the local intensity 
adaptation level through a recurrent framework. We 
tested our method on various images, compared it with 
other algorithms and showed that it efficiently increases 
the visibility and visual quality while preventing halo and 
greying-out artifacts. 
 
 
 
 
 
 
 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
