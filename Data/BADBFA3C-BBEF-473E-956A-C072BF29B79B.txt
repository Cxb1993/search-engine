 2
editing, and multimedia synchronization. We will 
present the results with correlations between photos 
and music characteristics, instead of sequentially 
showing photos one-by-one.  
 
二 計畫緣由與目的 
生活數位化的時代已隨著各種數位內容產品
的普及與數位電視的全面推廣而快速來臨。在面對
大量數位資訊與各種媒體來源時，許多問題因為實
際的應用與使用者的需求而逐漸衍生出來。為了讓
大量的多媒體資料能有效率地被運用，進而提昇數
位內容的應用價值，有效的多媒體檢索與數位內容
分析是急需被發展的技術。以商業附加價值大的運
動影片為例，若能應用數位內容分析技術將比賽中
的事件偵測出來，並自動剪輯對應的片段或進行影
片摘要，將可提供使用者更多元的觀賞模式。 
目前數位內容分析的研究主要面臨的課題在
於如何跨越語意鴻溝(semantic gap)。以往對於數位
資 料 的 分 析 只 著 重 於 特 徵 值 萃 取 (feature 
extraction)，然而，低階特徵值的特性往往跟人的
感覺不同。常用的特徵值包括圖片中顏色統計
(color histogram)、顏色分佈(color layout)、邊緣統
計(edge histogram)等；影片中的移動(motion)、鏡
頭 種 類 (camera type) 等 ； 聲 音 中 的 過 零 率
(zero-crossing rate)、能量(energy)、音高(pitch)、節
奏(tempo)等。由於這些特徵值不直接具有人為解
釋的意義，因此由這些特徵值描述而得的結果常常
不如預期。此種低階特徵值與高階語意(semantics)
之間的落差稱為語意鴻溝(semantic gap)。 
再以運動影片為例，目前的研究成果主要在
於利用顏色與邊緣資訊進行畫面分類 (shot 
classification)(如棒球或網球影片)，或者是利用球
的軌跡(ball trajectory)與移動(motion)進行比賽持
續或暫停(play-break)的分析(如足球影片)。然而，
這些初步的成果與使用者真正需要的相去甚遠。以
球迷的觀點來說，他們關心的是場上球員的表現：
是否有安打？是否有全壘打？投手今天有幾次三
振？此場比賽的射門與得分畫面等等。目前的研究
成果只能大致找出比賽中“可能比較精采的片
段”，而不是“比賽中確切發生了什麼事情”。許多
受歡迎且有意義的應用雖然已經開始出現(如美國
大聯盟網站上的線上影片)，它們仍需依靠人為的
剪輯，需要大量的時間與人力。因此，在數位媒體
大量被創造的同時，發展一套能有效偵測影片裡事
件的技術已經是刻不容緩。 
此外，從數位電子產品的普及來看，一般的
使用者越來越有能力錄製或創造自己的數位內
容。這些數位資料雖然可以很輕易地被創造與儲
存，但由於一般使用者常疏於管理或因為拍攝品質
不佳，降低了這些數位資料的價值與實用性。在這
項課題當中，以往的研究主要提供使用者一個大致
的分類結果，例如，以場景的相似性將類似的照片
歸為同一類，或以相機或攝影機附帶的時間資訊做
時間上的分類。這樣的做法在近年來也開始往內容
加值的方向進行。例如，與其觀賞一段長達一兩個
小時的家庭影片，不如將其重要的片段配上音樂，
剪輯成一段五六分鐘的影音摘要。同理，數位相機
拍得的大量照片也可在偵測畫面中物件的重要性
與場景分類之後，配上適當的音樂製作成動態的幻
燈片展示(slide show)。此種摘要式的後製資料更能
被人們接受，其相對的觀賞價值也跟著提高。 
為提昇數位家庭應用，本計劃將目標集中在
兩大方向：影片事件偵測(event detection)與複合式
影音展示(composite audiovisual presentation)。 
 
三 研究方法與成果 
本計畫共以三年時間完成，第一年著重低階
特徵值萃取與以規則為基礎的事件偵測。第二年進
一步發展以模型為基礎的事件判斷模組與圖片、音
樂分析模組。第三年整合多項模組完成影片摘要與
幻燈秀的實作。以下簡介本計畫所完成之目標與整
合成果。 
A【影片事件偵測】 
A.1 棒球視訊特徵值萃取 
根據我們的觀察，棒球比賽中的事件一定發
生在兩個投手畫面之間。如圖一所示的例子而言, 
投手投出一球但打者沒打、畫面轉往其他地方，這
段期間就沒有事情發生。下一個畫面再切回投球畫
 4
壘包區域的亮度變化來判斷(亮度高代表壘包上有
人)。 
 
圖四、字幕資訊 
 
A.2 以規則為基礎的棒球事件偵測模組 
由於棒球比賽的結構明確，且比賽的進行嚴
格遵守棒球規則，因此我們可利用規則與比賽狀態
變化來推測出事件的種類。我們可將棒球比賽規則
轉換成為 decision tree，如圖五所示。在計算出兩
投手畫面之間的資訊變化後，我們可順著此
decision tree 判斷出大部份的棒球事件。舉例來
說，如果兩投手畫面間沒有出局變化，沒有分數變
化，但在第二個投手畫面中顯示二壘有人，則此段
時間我們可推測有個二壘安打產生。 
oi,i+1 < 2
oi,i+1 = 0
Yes
ni,i+1+si,i+1=1
bi+1=1
1B or BB bi+1 = 2
2B bi+1 = 4
3B HR
ni,i+1+si,i+1=0
Nothing SB
ni,i+1+si,i+1=0
si,i+1 = 0
bi,i+1 = 0
SO or AO SAC
SF
CS
DP
No
Yes No
legal features
 
圖五、事件偵測的 decision tree 
 
A.3 比 賽 規 則 與 慣 例 於 以 模 型 為 基 礎
(model-based)的事件判斷模組 
利用比賽規則與慣例的方法雖然可偵測球賽
中的大部份事件。但有些事件光靠字幕資訊與規則
仍然無法明確區隔，例如一壘安打與四壞球保送；
三振與內外野出局等。因此，我們現階段再進一步
地加入畫面切換與語音的資訊來區分這些混淆的
狀況。 
如圖六所示，我們首先分別從視覺跟語音資
訊做偵測，之後再結合這兩方面的資訊以得到一個
整合偵測的結果[1]。如圖七所示，在時間 t1 到 t2
之間，經由字幕變化與規則判斷，我們僅能大略知
道這段期間出現一壘安打或四壞球。在這種情況
下，此區段的資料將分別進行以視訊為基礎的偵測
(Visual-based detection)與以語音為基礎的偵測
(Speech-based detection)。以視訊為基礎的偵測模組
以“是否有投手畫面緊接內外野畫面”、“在打擊出
去前投手總共投了幾球”、以及“攝影機移動程度
(motion magnitude)”等為特徵值，利用 K-nearest 
modeling 來描述一壘安打或四壞球的特性。以語音
為基礎的偵測模組利用“關鍵字詞偵測(key-phrase 
spotting)”[2]來評估某個概念發生的機率。 
 
 
圖六、視覺跟語音資訊的偵測整合 
 
 
 
圖七、結合語音關鍵字句的結果來進行混淆概念的
區分 
由於特定概念的發生將伴隨著特定的主播語
音說明，如表一所示，因此我們可根據資料庫中的
比賽來評估各個關鍵字詞出現時某特定概念出現
的機率。據本研究所統計的結果，關鍵字詞與相關
概念的機率關係如同圖八所示。另外，三振與內外
野出局的區分狀況亦同。 
 
 6
等。在自動產生摘要時，我們將概念的重要性分成
五類： 
z Rank 1：使比賽勝負狀態改變的概念。包括讓
A 隊領先 B 隊、A 隊追平 B 隊、或 A 隊被 B
隊趕過的情況。 
z Rank 2：帶有打點的安打或盜壘。雖未造成比
賽勝負狀態改變，但得分依舊是比賽中重要
的概念。 
z Rank 3：未帶有打點的安打、盜壘、雙殺或三
殺。雖未造成得分，但這些概念的發生仍間
接影響比賽結果。 
z Rank 4：帶有殘壘的三振、內外野出局或犧牲
觸擊。壘上有人時，觀眾通常會對接下來的
打者帶有期待。若他未能打出安打，則相對
來講對於比賽結果與觀眾感受的影響較大。 
z Rank 5：未帶有殘壘的三振與內外野出局。棒
球比賽中最普通的情況。 
 
根據這樣的分類，利用本研究發展出的演算法選擇
適合選為摘要的片段。此演算法如圖九所示： 
 
 
圖九、自動摘要演算法 
 
2005.04.08 興農 vs. 統一
比賽時間：3小時14分
16分鐘 3分25秒 6分鐘
Man-made summary Automatic summary Automatic highlight Automatic highlight
31 plays are selected. 25 plays 
are in the man-made sum.
Precision=0.806
Recall=0.833  
圖十、自動摘要與自動精采畫面產生之結果與電視
台製作之結果比較 
我們將自動摘要的結果與電視台專業記者剪
輯出來的摘要作比較，發現本研究的作法不管是
precision 或 recall 都可達到八成以上的準確度，如
圖十所示。 
與自動摘要類似的還有另外一種應用：自動選
取精彩片段。在這個部分我們除了考慮各個片段代
表的概念之外，還考慮到它發生的時間與相對應時
間內聲音變化的情況。因為通常比賽越到後半段張
力越高，而且當有精彩事件發生時，觀眾與主播的
聲音將明顯變化。我們將每段視訊的重要性以底下
的式子表示： 
( ) ( ) ( ) ( )i r i t i a iS E S E S E S E= ⋅ ⋅  
它代表概念的意義、時間、與聲音變化造成的重要
性的加乘。在此之後，再根據圖十一所表示的精彩
片段選取演算法(highlight selection algorithm)產生
出最後的結果。這種選取方式可根據使用者的需求
產生出不同長度的 highlight，如圖十所示。 
 
{ }
{ }
HIGHLIGHT_SELECTION( , )
1  
2  sort  into nonincreasing order by significance degrees
3  for each 
4      do if length of ( )
5               then 
6                      SMOOTH( )
7  ret
i
i
i
T E
A
E
e E
A e T
A A e
A
←∅
∈
∪ <
← ∪
urn A
Input: the user-defined highlight length T and the set of events E in the game. 
Output: the set of highlighted events A. 
 
圖十一、精彩片段選取演算法 
 
本研究計劃的實驗結果顯示出此種方法能有
效且精確地幫助我們檢視棒球影片內容，也成為跨
越語意鴻溝(semantic gap)研究中一個很典型的例
子。整個棒球語意分析的過程可用圖十二來表示。
它包括場景分類(shot classification)，語意概念偵測
(semantic concept detection) 、 以 及 延 伸 應 用
(extended applications)。有了這樣架構之後，我們
可得到精確且全面的概念偵測結果，也因此可發展
許多有趣的應用。除了之前所提到的自動摘要與精
彩片段選取之外，我們亦可提供線上的隨選視訊服
務，如圖十三所示。類似的服務已經被廣大的棒球
 8
有時一個時間叢集(time-based cluster)會過於
龐大(包含太多張照片)，因此我們可基於前一小節
所提到的主要色彩與色彩配置等特徵值對他們再
細分，如圖十五所示。在此我們採用 k-nearest 
neighbor 的作法將一個 time-based cluster 中的照片
分成多個 content-based cluster。 
 
B.3 音樂特徵值萃取 
為了往後在配合音樂與視覺畫面能更協調，
我們希望能偵測音樂的節奏，以便未來依據音樂的
拍子進行畫面切換與安排。如圖十六所示，我們主
要依據 Scheirer 所提的方法[6]，將訊號分成不同的
頻帶(frequency bands)來分析。在偵測各個頻帶的
能量變化之後，整合各頻帶的變化整合成整首音樂
的拍子資訊。 
 
Band1
Band2
Band n
+
Multi-band 
analysis  
圖十六、音樂拍子偵測 
 
B.4 使用者注意模型建置 
我們將提出一個以使用者注意模型  (user 
attention model) 為基礎的自動視訊興趣區決定架
構(如圖十七所示)。在這個研究中，視訊的注意特
徵值 (attentive features) [5] 及應用媒體美學的知
識都被同時考慮且利用。使用者興建區可用於往後
建造複合式影音展現的重要依據。 
在自動決定視訊興趣區的過程中，首先我們
將欲分析之原始視訊以一使用空間顏色敘述子 
(spatial color descriptor) 為核心之場景變化 (shot 
detection) 演算法將其分為數個場景。接著在每段
場景之中，我們以固定長度數量的訊框組成互不重
疊之訊框切片 (frame-segment)，以每一訊框切片
取代單一之訊框做為視訊興趣區分析的基本單
位。接著在每一訊框切片中，我們對每一張訊框分
別以使用者注意模型取出三類不同的視覺注意特
徵值，包含亮度 (intensity)、顏色 (color)及運動 
(motion)，並分別得到其對應之特徵值映圖 (feature 
map)。對於不同種類的特徵值映圖，我們分別以時
間平均過濾器 (temporal mean filter) 將其過濾為
唯一之已過濾特徵值映圖 (filtered feature map)。不
同的已過濾特徵值映圖即用以表示在該訊框切片
中其對應之某類注意特徵值的空間分布情形。另一
方面，我們也對每一訊框切片找出其所屬之運鏡種
纇，將不同之已過濾特徵值映圖合併為單一之顯著
映圖 (saliency map) 時，此運鏡種纇資訊將用以決
定每個特徵值映圖之合併參數。在得到該訊框切片
之顯著映圖後，即可決定出該訊框切片之興趣區數
量，同時決定出每個興趣區在訊框中之大小及位
置。整部原始視訊即可以此種方式分段決定出所有
的使用者興趣區。 
 
 
圖十七、視訊興趣區決定之所提架構 
 
B.5 實作自動圖片分類模組 
在人手一台相機的時代，照片和我們的生活
緊緊相連，但大量的照片不僅整理不易且無從瀏
覽，因此，自動圖片分析技術也日漸重要。我們根
據第一年所作的圖片叢集(photo clustering) 的分
析，實作完成圖片自動分類的模組，我們利用第一
年所提的方法萃取出圖片的特徵值，除了利用時間
資訊來作使用者的圖片叢集以及利用內容資訊的
圖片叢集外，我們另外發展一種分類模組可供使用
者選擇，此模組為採用將網路上收集到的大量照片
 10
中，相同週期的能量輸出加總後，有最大能量加總
輸出值的週期，即為音樂訊號的節奏資訊。因此將
輸入的音樂信號作節奏的偵測與分析之後，我們便
可以利用音樂的節奏資訊來輔助取得整首音樂的
節拍位置。 
利用音樂的節拍資訊便可進一步作為拼貼畫
面切換的依據。由於音樂長度有限，為了能讓音樂
和照片能更緊密的結合，我們將以音樂為主並將音
樂分成幾個段落，而後根據音樂的分段數來選擇合
適的照片來作展示播放的搭配。同時，我們也將考
慮音樂節拍的強弱，選擇強拍發生的時機來做畫面
的切換，藉由此方式加強複合式影音的瀏覽效果，
照片和音樂節拍搭配的流程如圖二十一所示。  
 
 
圖二十一、音樂節奏分析與應用 
 
B.8 拼貼幻燈秀整合與實作 
複合式影音展示之目標在於以幻燈秀之型式
將屬於同一叢集的照片展示於同一個影格(frame)
之中，並以照片內容為基礎，精巧地將照片配置於
每一塊拼貼區域(tile)。在拼貼的過程中會遇到幾個
難題: 
z 在時間長度有所限制的配樂片段中，我們無
法以適當的照片播放速度播放完所有照片，
必須從中挑選部份播放。例如，當每個影格
停留 4~6 秒鐘時，一首長度 4 分鐘的音樂最
多只能播放 60 張照片。 
z 對於屬於同一叢集的照片，必須合理地將照
片配置於畫面中。例如，較重要或較引人注
意的照片應顯示於較大的拼貼區域中，而較
相似的照片應被配置於較相鄰的拼貼區域
中。根據上述原則，我們必須設計一演算法，
從所有定義好的拼貼版面(layout)中選取最適
合的版面以及位置來放置照片。 
z 一旦決定好哪些照片該配置在哪些拼貼區域
後，仍需適當地裁切照片，並調整照片尺寸
後才可放入拼貼區域。因此須設計一最佳化 
(optimization)演算法決定照片的縮放比例與
裁切的區域。 
針對上述難題，我們整合第一年與第二年的研究成
果，開發如圖二十二所示之幻燈秀，圖二十三為生
成幻燈秀之流程圖，我們將針對每一模組詳加介
紹。 
 
圖二十二、複合式影音展示之幻燈秀系統 
 
 
圖二十三、實作拼貼幻燈秀之流程圖 
 
B.8.1 選擇照片叢集(Cluster Selection) 
本計劃第二年所研發之音樂節奏分析成果可
依據節拍資訊將使用者所選擇之背景音樂切割成
數個較短的時間區段(約4~6 秒)。屬於同一個照片
叢集(Photo Cluster)的照片將在同一個時間區段中
播放，然而使用者輸入的照片數目龐大，而一首包
 12
給予其較高的權重。一個照片叢集中的所有照片重
要性(PIi)由大至小排列後，可組成此照片叢集之重
要性向量(PV : importance vector)。 
 
B.8.3 決定版面樣本(Template Determination) 
對於一個含有h張照片之照片叢集，我們比較
此照片叢集之重要性向量(PV)與所有含h-巢的版
面樣本之重要性向量(TVh;i)，並選擇向量相似度最
高的版面樣本: 
, 
而每張照片在此版面樣本中的位置可由每張照片
的重要性決定，擁有較高重要性的照片會被放置在
較大的巢中。 
 
B.8.4 合成幻燈秀(Composition) 
將照片放至對應的巢中，就像是將磁磚貼至
牆上所屬的位置，因此我們稱此系統為拼貼幻燈
秀。然而每個巢的長寬比，通常與所要放置的照片
長寬比不同，且照片的解析度往往超過1600x1200
個像素，遠大於每個巢的像素。為了不讓照片內容
嚴重失真，對於照片叢集中的每張照片都須藉由切
割(cropping)與調整尺寸(resizing)等技術來選擇一
適當的照片顯示區域做為拼貼的素材。我們將此問
題導為一個有條件限制的最佳化問題。 
z 選擇照片顯示區域之最佳化 
給定一張照片，從中找尋一塊內容值(content 
value)最大的區域 R，且 R 的長寬比和所要放置的
巢(Rc)之長寬比相同: 
, 
其中 g(．)為該區域之長寬比，C(．)為該區域所含
之內容值。根據第二年所研發之使用者注意模型，
我們可算出每一塊區域的內容值(content calue)，並
由上式找尋一塊使資訊損失量最少但又符合適當
長寬比的區域。最後截取此區塊，將其解析度調整
為巢的解析度，即可拼貼入巢中。 
 
四 結論與討論 
本計畫的成果主要分兩部份。第一部分是以
棒球影片的事件分析為目的，棒球比賽中的事件是
球迷了解比賽過程與球員表現的重要依據，不同事
件所造成的效果對於球員與觀眾有不同的意義。因
此，有別於以往只大約偵測精采畫面或場景分類的
研究，本系統已能確切地偵測棒球比賽中發生的各
種事件。 
第二部份是實作複合式影音展現之拼貼幻燈
秀，不同於以往一張幻燈片僅播放一張照片的呈現
方式，拼貼幻燈秀結合了音樂與照片內容分析之成
果，讓使用者一次瀏覽多張照片，卻又能使視覺畫
面與聽覺刺激有明顯的調和，不失欣賞與回味的樂
趣。 
z 計劃成果自評 
【影片事件偵測】的第一年成果以畫面分
類、字幕資訊辨識以及基於棒球規則的事件偵測模
組為主；第二年進一步實作出以模型為基礎的事件
判斷模組，完成準確的事件偵測；第三年整合事件
分析系統並發展如自動摘要、精彩影片選取、線上
隨選視訊服務等延伸應用。此影片事件偵測技術的
貢獻可簡短摘要如下： 
 多層架構(multilevel framework)：引進中介資
訊，根據不同數位內容決定與發展對應函式
(mapping function)。 
 棒球影片中的語意分析：以字幕資訊為中介資
訊，詳盡利用棒球規則於語意分析。另外結合
畫面與語音資訊準確完成所有棒球概念的偵
測。此技術模組完成了內容的分析與檢索
(indexing)。 
 延伸應用：基於分析結果發展實際且有用之應
用。自動產生摘要與精彩片段完成內容重新組
織的目標。 
【複合式影音展示】方面，第一年與第二年
利用圖片特徵值萃取技術將照片自動分類，並研發
使用者注意模型與音樂節奏分析模組。有了自動圖
片分類的模組之後，我們才能將相近的照片同時展
現，藉以提昇整個視覺的強度與資訊的廣度。有了
音樂節奏分析模組，我們才能配合音樂的節拍作圖
 14
Circuits and Systems for Video Technology, vol. 
11, no. 6, pp. 688-695, 2001. 
[5] L. Itti, C. Koch, and E. Niebur, “A model of 
saliency-based visual attention for rapid scene 
analysis,” IEEE Trans. PAMI, vol. 20, no. 11, 
pp. 1254-1259, Nov. 1998. 
[6] E.D. Scheirer, “Tempo and beat analysis of 
acoustic musical signals,” Journal of Acoustical 
Society of America, vol. 103, no. 1, pp. 
588-601, 1998.   
[7] 其他參考文獻請參考計畫書 
 
一、 IEEE  ICME 大會簡介： 
  ICME 國際會議之全名為 International Conference on Multimedia 
and Expo。ICME 為多媒體領域中僅次於 ACM  Multimedia 的重要國
際學術會議 ，以今年而言總共有來自 43 個不同國家 811 篇的論文投
稿，經過 2324 人次的 review 選出 407 篇 oral 論文及 21 篇的 poster 論
文，整體的論文接受率大約是 48%。ICME 2008 的議程安排是由 6 月
23 日的 7 場 Tutorials： 
‧ Distributed Video Coding for Low Cost Multimedia Communication and 
Systems — Prof. Fernando, University of Surrey. 
‧ Analysis and Retrieval Techniques for Motion and Music Data — Dr. 
Meinard Muller, Max–Planck–Institute for Informatics.    
‧ Learning Human Perception and Semantics Understanding in Multimedia 
Applications–Dr. Cha Zhang Microsoft Research prof. Tsuhan Chan, 
CMU. 
‧ Locality aware  P2P–CDN：The Way to Scale Internet Video to the 
World — Dr. Jin Li, Microsoft Research.  
‧ Compression for 3DTV and FTV— Dr. Aljoscha Smolic, Fraunhofer 
HHI.  
‧ Reconfigurable Video Coding and Processing. 
‧ Personalized Media Processing for Attention Service Applications. 
整體而言，功於 ICME 是由 IEEE Signal Processing, Circuits and 
Systems, Communications 及 Computer 等 4 個 Societies 所共同支持,
故大會論文的範疇包括上述 4 個學術領域，與一般單一主題的學
術會議略有不同，就個人而言，ICME 實為跨領域學術交流的一個
重要盛會。 
二、 參與會議過程與心得： 
本人是 6 月 22 日搭華航直飛法蘭克機場的班機前往德國，再由 
法蘭克福搭乘德國國鐵 ICE 火車前往會議地點漢諾瓦市。為了生活機
能的考量，本人選擇較接近漢諾瓦火車總站的 Ander Hotel Plaza,離會
議地點 Hannover Congress Centrum 搭公車大約有 10 分鐘的車程。 
    在 ICME 2008 中，本人參與的研究共有三篇論文入選，分別是 
‧ Using Semantic Graphs for Image Search. 
‧ Traceable Multimedia Fingerprinting Based on The Multilevel. 
‧ Event Protection in Tennis Matches Based on Video Data Mining. 
其中第一篇係本人與 IBM T.J. Watson Research Center 的林清永博士合
作的成果，我們利用隱藏於 Wikipedia 中的 Social Network 發展出
Semantic Graphs 再利用 Semantic Graphics 所找出的 Keywords 進行
