Implementation of An Automatic Fingerprint
Identification System
Pattern Recognition and Image Processing Laboratory ∗
Department of Computer Science
National Tsing Hua University
Hsinchu 30013, Taiwan
Email: cchen@cs.nthu.edu.tw
Abstract−Fingerprints used for identification and
verification has attracted many biometric researchers.
Although no identical fingerprint from distinct identi-
ties was found, a perfect automatic fingerprint identi-
fication system (AFIS) may not exist. This paper im-
plements an AFIS with the use of fingerprint classifica-
tion and a minutiae pattern matching. Our system is
tested on a database composed of 112 300×300 right in-
dex fingerprint images contributed by 28 persons, each
has 4 duplicates via Veridicom FPS110 reader. Each
match takes 0.2 seconds on a PC with Athelon XP 2500
CPU and 512 MB SDRAM running Windows XP. We
achieve 110 correct matches out of 112 tests. The ony
two mismatched images are due to unavoidable noise.
The result of testing our system on 4×101 left index
fingerprints of more noisy images from 101 persons
achieves 88% recognition rate.
Index Terms−bifurcation, core, delta, ending, minutiae
pattern.
I. Introduction
Fingerprint used for access control, criminal veriﬁca-
tion, credit card and passport authentication, and dig-
ital right management is getting more and more pop-
ular. Whereas, a perfect automatic ﬁngerprint iden-
tiﬁcation system (AFIS) has not been discovered yet
[6] due to an unexpected variety of changes when a
ﬁngerprint is sensed [6][10]. This paper implements
an AFIS which receives a ﬁngerprint image as input
to match previously registered ones in the database
and responds either ”accept” or ”reject” according to
a designer-speciﬁed policy [3][5][7]. Our paradigm of
minutiae-based AFIS is shown in Figure 1. The remain-
ing of this paper depicts the details of this paradigm and
shows intermediate image results of our procedures.
∗This work is supported by Taiwan NSC 95-2221-E-007-198.
Image
Enhancement
Image
Binarization
Thinning
Orientation
Computing
Core & Delta
Detection
Minutiae
Detection
Type
Classiﬁcation
Pattern
Matching
Input
Image
 


 


 
Figure 1. A System of Fingerprint Identification.
II. Image Enhancement
Our AFIS takes a ﬁngerprint image of size 300×300
with 256 possible gray levels of resolution 500 dpi as
input. Figure 2(a) shows an example. Although a live
scan technique was investigated to improve the quality
of acquired ﬁngerprint images, the moisture and scars
of a ﬁnger as well as the pressure due to a ﬁngerprint
sensing could distort the quality of the acquired ﬁnger-
print image. We adopt an ad hoc strategy according to
previous studies to enhance the quality of a ﬁngerprint
image.
Suppose that A(i, j) is the image gray level at pixel
(i, j), we adopt the following transformation to stretch
the distribution of gray levels [3][7].
B(i, j) ← α + γ ∗ ([A(i, j) − u]/s), (1)
where u and s2 are the mean and variance of gray
levels of the input image, respectively, and α = 150,
γ = 95 were used [3]. Note that the selection of γ must
satisfy γ > s. Figure 2(b) shows the enhanced image
by contrast stretching.
2
After removing the spurious minutia pixels, a minu-
tiae pattern, consisting of approximately 20∼40 ridge
endings and bifurcations associated with corresponding
ridge orientations, is obtained for matching pre-stored
minutiae patterns in a database.
(a) (b)
(c) (d)
Figure 3. False Minutiae: (a) Beyond
margins, (b) Broken ridges, (c) Hair ef-
fect, (d) Too close bifurcations.
VI. Type Classification of Fingerprints
Since a minutiae-based pattern matching procedure in
a large database may consume a huge amount of time,
we classify each ﬁngerprint into one of the four types:
left loop, right loop, whorl, and arch, and search in the
database only for those ﬁngerprints whose type coin-
cides with that of a requested one. The type classiﬁ-
cation is based on the number and distribution of sin-
gular points: core and deltas [4][2][8][11][12] which are
described in the following subsections.
A. Ridge Orientation Map
A pixel orientation map is computed according to
the reports of [1][3][5]. For pixel (i, j), we apply Sobel
operators to get
Gx = B(i + 1, j − 1) + 2B(i + 1, j) + B(i + 1, j + 1)
−B(i− 1, j − 1)− 2B(i− 1, j)−B(i− 1, j + 1)
(2)
Gy = B(i− 1, j + 1) + 2B(i, j + 1) + B(i + 1, j + 1)
−B(i− 1, j − 1)− 2B(i, j − 1)−B(i + 1, j − 1)
(3)
ρ =
√
G2x + G2y, φ = tan
−1(Gy/Gx), (4)
where φ could be regarded as pixel orientation for
(i, j). To further compute the ridge orientation, let
αx = G2x −G2y , αy = 2GxGy, (5)
βx =
∑
R
G2x −G2y, βy =
∑
R
2GxGy (6)
The block direction for region R (11× 11 block) cen-
tered at pixel (i, j) can be computed by Φ = 12θ, where
θ =
⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
tan−1(βy/βx) if βx ≥ 0
tan−1(βy/βx) + π if βx < 0 and βy ≥ 0
tan−1(βy/βx)− π if βx < 0 and βy < 0
(7)
Apply a 3× 3 median ﬁlter followed by quantization
(into 8 directions) on {Φ′s}, we have a map of ridge
orientation as shown in Figure 4.
(a) (b)
Figure 4. (a) Map of Ridge Orientation,
(b) Core and Delta.
A Poincare´ index as deﬁned in [5] was adopted for
ﬁnding the cores and deltas. A left loop might contain
a delta located on the right and/or down of the core
which is convex. A right loop might contain a delta
located on the left and/or down of the core which is
convex. A whorl contains cores without deltas in the
surroundings. An arch has a delta almost right be-
low the core. This coarse classiﬁcation can signiﬁcantly
prune mismatched comparisons and speed up the minu-
tiae patern matching.
VII. Minutiae Pattern Matching
Minutiae pattern matching is an important but diﬃ-
cult task. The performance is quite diﬀerent from one
database to another database. We adopt the strategy
4
SVD-Based Projection for Face Recognition
Chou-Hao Hsu and Chaur-Chin Chen ∗
Department of Computer Science
Institute of Information Systems & Applications
National Tsing Hua University
Hsinchu 30013, Taiwan
E-mail: cchen@cs.nthu.edu.tw
Phone: +886 3 573 1078
Fax: +886 3 572 3694
Abstract−Projection-based face recognition has
been widely studied during the past two decades. One
of the problems is to require a huge storage space to
save the face features obtained from training faces.
This paper proposes an SVD-based face retrieval
system which requires less memory than the PCA,
2DPCA, Fisher, and 2DFisher approaches. The al-
gorithm tested on the famous ORL (AT&T) face
database, consisted of 400 112 × 92 gray level face
images equally contributed by 40 subjects, achieves
97.5% recognition rate of retrievals.
Index Terms−Eigenface, Fisherface, Singular
Value Decomposition (SVD).
1 Introduction
Projection-based face recognition has been
widely studied since the late 1980s. Turk and
Pentland [7] investigates the method of Eigenfaces
based on (PCA) Principal Component Analysis.
Belhumeur et al. [1] investigates the method of
Fisherfaces based on Fisher’s discriminant analysis.
Phillips et al. summarizes a comparison of various
algorithms by testing part of FERET face database
consisted of 14126 face images contributed by 1199
individuals [6]. Yang et al. [8] investigates the
method of 2DPCA by acquiring face features from
the right projection of a face image. Li and Yuan [5]
investigates 2D-LDA method based on Fisher’r ra-
tio of projections to compute face features. Yang et
al. [9] proposes another unsupervised discriminant
projection analysis for face feature extraction which
takes the local and non-local scatter information into
∗This work is supported by Taiwanese National Science
Council Grant No. NSC 95-2221-E-007-198.
account simultaneously. Dagher and Nachar [3] pro-
poses an algorithm by combining PCA and indepen-
dent component analysis (ICA) running sequentially.
Cho et al. [2] presents an eﬃcient face recognition
algorithm based on two directions and 2 dimensional
linear discriminant analysis ((2D)2DLDA) to get
the projected face features. Hsu [4] studies vari-
ous projection methods [10] and proposes a singular
value decomposition (SVD) based method for face
recognition. The recognition rates reported by the
aforementioned research works varied even on test-
ing the commonly used ORL database constructed
by AT&T Laboratories at Cambridge [11] between
April 1992 and April 1994 in the lab. We realize
that using diﬀerent subsets of training images and
diﬀerent deﬁnitions of recognition rates may obtain
various results.
This paper propses a simple algorithm based on
singular value decomposition and deﬁnes the recog-
nition rate of face image retrievals explicitly. We
shall test our algorithm running on ORL database.
The remaining of this paper is described as follows.
Section 2 introduces an SVD-based algorithm to
compute left and right projection vectors, and de-
scribes feature extraction by projection and deﬁnes
the retrieval rate. Section 3 illustrates the ORL face
image database, shows the result of performance.
Section 4 draws the discussion and conclusion.
2 SVD-Based Face Represen-
tation and Recognition
Hsu [4] proposed SVD-based face recognition
method which applies singular value decomposition
for face image reconstruction and recognition. It
6
rate of recognition but also report the rank of re-
trievals for better understanding the performance.
For each test subject image T , we ﬁrst compute the
distance R(i) between this test image and the ith
image of the 200 training images according the fea-
ture matrices computed from steps (3) and (4) from
the SVD-based algorithm as introduced in Section
2. We report the ranks of the best matched sub-
jects according to the distance R(i) from 1 up to 8.
The rate of recognition is shown in Figure 2. The
rate indicates the correct recognition occurs when
the top h (1 ≤ h ≤ 8) matches contains at least one
successful match. Since there are 5 training images
for each subject, if we deﬁne a correct recognition
for each test image when the best matched rank is
within 5, inclusively. For the aforementioned testing
procedures operations, we achieve 97.5% recognition
rate.
The three test images, subject 17-10, subject 19-
9, subject 32-7 with none of their corresponding
matched subjects is within rank 8 are also interest-
ing. We report these three face images and their
corresponding best but wrongly matched face images
subject 36-2, subject 11-4, subject 15-1 in Figure 3
for reference.
4 Discussion and Conclusion
Face recognition is one of the most popular ap-
plications when Biometric Recognition was involved
[10]. We propose an SVD-Based face representa-
tion and recognition system with very good perfor-
mance (97.5%) on the commonly used ORL (AT&T)
face database. The environments of face image ac-
quisition with experiments to promote the proposed
SVD-based face recognition merit further studies.
5 Acknowledgments
The authors appreciate the support from Insti-
tute of Information Systems and Applications.
References
[1] P.N. Belhumeur, J.P. Hespanha, and D.J.
Kriegman, ”Eigenfaces vs. Fisherfaces: Recog-
nition Using Class Speciﬁc Linear Projection”,
IEEE Trans. on Pattern Analysis and Machine
Intelligence, vol. 19, no. 7, pp.711-720, 1997.
[2] D.U. Cho, U.D. Chang, K.D. Kim, B.H. Kim,
and S.H. Lee, ”(2D)2 DLDA for Eﬃcient Face
Recognition”, First Pacific Rim Symposium,
PSIVT 2006, LNCS 4319, pp.314-321, 2006.
[3] I. Dagher and R. Nachar, ”Face Recognition
Using IPCA-ICA Algorithm”, IEEE Trans. on
Pattern Analysis and Machine Intelligence, vol.
28, no. 6, pp.996-1000, 2006.
[4] C.H. Hsu, New Projection-Based Features for
Face Recognition, M.S. Thesis, National Tsing
Hua University, Taiwan, March 2006.
[5] M. Li and B. Yuan, ”2D-LDA: A statistical
linear discriminant analysis for image matrix”,
Pattern Recognition Letters, vol. 26, pp.527-
532, 2005.
[6] P.J. Phillips, H. Moon, S.A. Rizvi, and P.J.
Rauss, ”The FERET Evaluation Methodology
for Face Recognition Face-Recognition Algo-
rithms”, IEEE Trans. on Pattern Analysis and
Machine Intelligence, vol. 22, no. 10, pp.1090-
1104, 2000.
[7] M.A. Turk and A. Pentland, ”Eigenfaces for
Recognition”, Journal of Cognitive Neuro-
science, vol. 3, pp.71-86, 1991.
[8] J. Yang and D. Zhang, A.F. Frangi, and J.Y.
Yang, ”Two-dimensional PCA: a new approach
to appearance-based face representation and
recognition”, IEEE Trans. on Pattern Analysis
and Machine Intelligence, vol. 26, no. 1, pp.131-
137, 2004.
[9] J. Yang and D. Zhang, Z. Jin, and J.Y. Yang,
”Unsupervised Discriminant Projection Analy-
sis for Feature Extraction”, Proceedings of In-
ternational Conference on Pattern Recognition,
vol. 1, August 14-16, Hong Kong, China, 2006.
[10] www.face-rec.org
[11]
www.cl.cam.ac.uk/Research/DTG/attarchive/facedatabase.html
