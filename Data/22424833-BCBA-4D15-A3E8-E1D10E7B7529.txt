高速乙太網路媒介處理控制器之設計最佳化
“Optimization on Media Access Controller(MAC) in High Speed Ethernet”
計畫編號：NSC 96-2218-E-194-003
執行期間：96 年 1 月 1 日 至 96 年 7 月 31 日
主持人：楊國男 國立中正大學電機工程學系助理教授
一、中文摘要
乙太網路的頻寬, 從過去 10 Mb/sec[1], 歷
經 100 Mb/sec[1], 進而增加至 1 Gb /sec[2]甚
至 10 Gb/sec[3]. 等效而言, 網路頻寬約每年
增加 200 %, 而系統端 CPU 效能僅增加 80 %,
記憶體效能也只增加 60 %[5]. 一旦網路頻寬
凌駕於系統效能的情況之下, CPU 與系統記
憶體將忙於處理大量的網路封包, 無暇顧及
作業系統或應用程式的任務, 導致系統資源
嚴重不足. 因此, MAC 如何卸載 CPU 及系統
記憶體的負載, 並提昇網路效能, 為本計畫的
主要課題.
本計畫的研究主軸可分為二 : 1) 高效能
DMA 架構與驅動程式的整合, 以期降低系統
記憶體的負載. 2) 實現具 IP與TCP Checksum
與Segmentation等協定的卸載引擎, 以期卸載
CPU封包處理的負載. 本計畫規劃的MAC硬
體架構, 主要包括 (1) 高效能DMA 引擎. (2)
乙太網路協定邏輯單元. (3) PCI I/O 控制電
路. 而驅動程式的開發, 涵蓋以下三大部分
[6]: (1) 系統記憶體內封包資料處理. (2) 與
作業系統的溝通與互動. (3) 中斷常駐程式執
行.
本計畫的目標, 在於高網路效能與低系統
負載 MAC 的研究與開發. 計畫的成果將作為
未來網路研究的基礎.
英文摘要
Ethernet bandwidth changes from 10
Mb/sec[1], into 1 Gb /sec[2], even 10 Gb/sec[3].
Effectively, Ethernet bandwidth increases 200%
per year. On the other hand, CPU performance
merely increases 80% and memory bandwidth
does 60%[5] per year. Once network bandwidth
overrides system performance, CPU and
memory will be busy on handling the mass
Ethernet packets, and have no extra resource to
handle tasks from OS or application programs.
This situation will results in very low system
resource. Therefore, how MAC offloads the
loading from CPU and system memory, and
how MAC increases the network performance
are both the important topics in this project.
The research interests in this projects are, 1)
integration of high performance DMA engine
and driver, to decrease the loading of system
memory. 2) implementation of TCP/IP
checksum and segmentation offloaded engine, to
offload the loading from CPU. In this project,
MAC’s hardware architecture includes[6]: (1)
high performance DMA engine. (2) Ethernet
protocol parsing logic. (3) PCI I/O control logic.
三、研究方法及成果
在開放式系統介面的七層建構(OSI-7
Layers)中, 第二層(Layer-2, MAC Layer)的
硬體架構與相配合的驅動程式, 往往主宰著
封包吞吐量及系統效能的呈現. 本計畫著重
在乙太網路的第二層硬體開發, IEEE 802.3
為網路協定的規範. 其主要部分包括載子感
應, 多重擷取, 以及碰撞的偵測(CSMA-CD,
Carrier Sense Multiple Access- Collission
Detection).
另一方面, PCI 匯流排為 MAC 與系統端連結
的介面為. 透過這個介面, MAC 得以將收送的
封包,與系統記憶體建立橋樑, 並完成封包資
料的搬移. 另外, 驅動程式亦透過此介面, 與
MAC 溝通並下達指令.
圖(二)為 Ethernet MAC 架構, 重要的介面
與邏輯區塊定義如下,
1) PCI Bus –可支援 32 及 64 Bits, 且時脈
頻率為 33 及 66 MHz 的匯流排.
2) GMII–Layer-1(Phy)與-2(MAC)的介面, 可
支援 10, 100 及 1000 Mega–Bits/sec 的全
雙工介面, 而時脈頻率各自為 2.5, 25,
125 Mega-Hz.
3) PCI Controller–在 Master Mode 情況下,
MAC 透過 PCI Memory Read & Write Command,
讀寫系統記憶體內的資料. 另一方面, 在
Slave Mode 時 , Bios 與 Driver 透過
Configuration / IO / Memory Read & Write
Command, 讀寫 MAC 內部暫存器.
4) TX DMA Engine –負責傳送封包資料的搬
移, 並支援 VLAN Tagging, Layer-3 及-4
TX Checksum Offload 以 及 TCP
Segmentation Offload.
5) Ethernet TX Logic –處理乙太網路傳送
協定. 支援碰撞回復及重傳的機制.
6) TX Buffer –TX DMA Engine 與 Ethernet
TX Logic 非同步介面緩衝區.
7) RX DMA Engine –負責接收封包資料搬移.
8) Ethernet TX Logic –處理乙太網路接
收協定. 特別是半雙工模式的載子感應
及多重線上存取, 以及碰撞的偵測.
9) RX Buffer –RX DMA Engine 與 Ethernet
RX Logic 非同步介面緩衝區.
圖(二):Architecture of MAC[4,10].
介紹了 MAC 硬體架構之後, MAC 所支援的主要
功能, 如下所列:
(1) CSMA-CD in IEEE 802.3/ab
(2) IEEE 802.1Q,VLAN(Virtual Local
Area Network) Offload
(3) PCI Local Bus / Version.3.0
(4) Interaction between MAC and Driver
(5) TX DMA Engine
(6) RX DMA Engine
(7) Layer-3 Checksum Offload in Packet
Transmission.
遞給實體層.
(第五步驟) MAC 發出 PCI Memory Write
Command,告知驅動程式, 這個
TX 描述子, MAC 已使用過了. 屆
時,中斷事件發生時, 驅動程式
可回收這個 TX 描述子.
圖(五)為 MAC 內部 RX DMA Engine 的操作
流程.
圖(五): Procedure of RX DMA Engine[10].
(第一步驟) MAC 發出 PCI Read Command.
(第二步驟)系統記憶體完成RX描述子內容的
回應.
(第三步驟) MAC 發出 PCI Write Command.
(第四步驟) MAC 發出 PCI Memory Write
Command,告知驅動程式, 這個 RX
描述子, MAC 已使用過了. 屆時,
中斷事件發生時, 驅動程式可回
收這個 RX 描述子.
網路驅動程式扮演一個橋樑, 串連著系統
端與硬體晶片. 圖(六)中, 驅動程式負起核心
系統與網路卡的溝通重責. 驅動程式如何介
入網路封包的傳送流程, 可由以下步驟完成:
1st Step) 應用程式(Application Process)準備
好一筆待傳送的封包資料.
2nd Step) 起使系統呼叫(System Call), 並完
Layer-4/Layer-3 協定的標頭處理.
3rd Step) 驅動程式加以包裝, 及處理這筆來
自上層協定的資料.
4th Step) 驅動程式根據特定的軟硬體協同互
動, 以確立硬體完成封包傳送.
圖(六): NIC, Driver and System Kernel[6].
另一方面, 驅動程式如何介入封包的接收
程序, 以下步驟亦可說明:
1st Step) 硬體收到一筆封包, 並基於特定的
軟硬體協同互動, 完成封包的搬移.
2nd Step) 硬體引發一個中斷向量, 通知相對
應的中斷常駐程式來及時處理, 並
將其包裝成與上層協定(Layer-3)介
面的標準格式.
3rd Step) 上層協定取走相關的資訊, 並根據
插座埠(Socket Port), 回傳給相對應
的應用程式.
在 Linux-Like 的作業系統當中, 驅動程式
與系統核心的互動介面, 可分為以下三大部
分, 我們將逐一討論.
圖(十): Procedures in netdev_ boot_setup_
check( )[11].
4th Step) register_netdev( ). 圖(十一)中, 驅動
程式使用 register_netdevice()函式, 來向系統
核心要求此網路元件的註冊, 並使用 netdev_
run_todo 來完成註冊的程序.
register_netdevice()會經由呼叫 dev_ new_
index ( )函式, 來賦予硬體一個獨一無二的代
號.
圖(十一): Procedure in register_netdevice( )[11].
圖(十二)是關於 net_device 資料結構的註冊
流程圖. 當驅動程式註冊或卸載一個網路元
件時, dev-> init 與 dev -> uninit 兩個函式, 可
以分別地初始化與清除 private_data資料結構.
圖(十二): State Machine in register_ netdevice( )
[11].
2nd Part) 封包的傳送與接收.
當封包已經離開傳輸層以及網際網路層之
後, 它通常以Socket資料結構的形式, 存在驅
動程式區. 圖(十三)顯示 Socket 存在一個雙向
的環圈結構. 雙向的好處, 在於可以快速的前
後移動.
圖(十三): Packet Queues in Linux Kernel[12].
Socket 資料結構包括 sk_buff_head 與 sk_
buff 兩種. 在 sk_buff_head 資料結構中, 各參
數的定義如下:
next: 第一個 sk_buff.
prev: 最後一個 sk_buff.
駐程式, net_interrupt(), 呼叫 dev_alloc _skb()
函式, 用來建構 Socket Buffer 資料結構. 另外,
eth_type_trans()函式的目的, 為解析 IP 與
MAC 轉換位址.
在完成相關資料結構的建立與網路協定的
解析之後, 驅動程式會呼叫 netif_rx() 函式,
將 Socket Buffer 整理成 softnet_data 資料結構,
以方便 CPU/RISC 處理. 而封包的內容則安置
在 softnet_data.input_pkt_queue的FIFO中.當此
FIFO 有封包尚未處理時, do_ softirq()函式會
引發一個軟體中斷(不影響 CPU 的程序執行).
當 CPU 閒置時, 驅動程式會進一步呼叫
net_ rx_action()函式, 將 FIFO 內的封包物件取
出, 並執行 netif_receive_ skb()函式, 將物件引
導至正確的協定處理函式.
圖(十七)為網路驅動程式標頭連結檔的分類
介面. 三大介面的分組為作業系統, 網路與匯
流排介面.
圖(十七): Header Files in Network Driver.[13]
與作業系統介面的互動, 主要是封包相關訊
息的註冊與擷取以及中斷常駐程式的執行.
相關的標頭檔定義如下,
module.h: 模組化系統標頭檔的宣告.
init.h: 支援驅動程式的起始與卸載.
kernel.h: 提供 Kernel Space 的程式.
delay.h: 提供延遲, 目的是與硬體同步.
與匯流排介面的互動,主要是註冊中斷序列
與 I/O 與 Memory-Base Offset 位置, 以利存取
網路硬體內部暫存器. 相關標頭檔定義如下,
asm/io.h: 定義硬體 I/O 通道.
ahb.h: 提供匯流排元件的註冊與資源的
預留.
與網路介面的互動, 為網路連線訊息的交
換, Socket 緩衝區的宣告, 與多重組群位置的
註冊. 相關的標頭檔定義如下,
mii.h: 提供連線速度與全/半雙工模式
的偵測函數.
etherdevice.h: 提供硬體層應用的函數.
netdevice.h: 提供 net_device 以及 net_device
_stats 資料結構的標頭檔.
skbuff.h: 定義 Socket Buffer 的標頭檔,
為傳送與接受封包資料所用
之格式基礎.
crc32.h: 作為多重組群位置廣播所用的
標頭檔.
3rd Part) 與上層協定的互動.
在Linux-Like的作業系統當中, 網際網路(IP)
層使用兩種不同的策略, 來處理收進來的封包.
第一種策略是接收所有封包, 而第二種是只接
收特定 IP 協定的封包, 如 ARP 協定等. 如圖
(十八)所示, 顯示兩種屬於 packet_type 的資料
結構, ptype_base與 ptype_all. 網際網路層如何
過濾 IP 協定的封包呢? 每個不同的 IP 協定,
都有各自的 packet_type 資料結構. 比對 packet
