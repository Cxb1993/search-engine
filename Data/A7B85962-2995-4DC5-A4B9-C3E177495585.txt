中   華   民   國  95 年 8 月 2 日 
像素方向圖在指紋分類上的研究 
劉立民 
I. 中文摘要 
本研究計畫提出了一個全新的指紋分類演算法。奇異點可以從強化方向圖中已改進的
SEA 演算法被提取出來，並已 2×2 像素點定義之。以奇異點的個數來分類的話，指紋可以
分類為 arch，whorl 與 solitary 等 3 類。其中 solitary 這類指紋經過適當的旋轉之後，可以更
進一步的以 direction template 來分析。而方向限制 direction constraint 則可以由 pattern 
descriptor 中導出。更進一步的可以將 solitary 這類指紋分成 3 類：right loop，left loop 與 tented 
arch。此計劃使用 NIST-4 來驗證本演算法，5 類的分類的正確率為 91.62%，拒絕率為 1.55%，
4 類的分類的正確率為 94.38%。NIST-14 的驗證結果正確率為 89.15%，拒絕率為 3.07%。 
 
關鍵字: 指紋分類;奇異點;方向圖;缺失線. 
 
II. 英文摘要 
In this search, a new fingerprint classification algorithm is proposed.  Singular points are 
first extracted from enhanced fingerprint direction images with a resolution of 2×2 pixels by the 
modified SEA algorithm.  Based on the number of singular points, fingerprints are categorized 
into types of “arch,” “whorl,” and “solitary.”  Solitary fingerprints are properly rotated and then 
further processed to generate direction patterns that lead to establishment of individual direction 
template.  Direction constraints are formed and derived from pattern descriptors by their 
structural layout.  Decision rules are then established and pattern templates are classified into 
three more types: “right loop,” “left loop,” and “tented arch.”  NIST-4 database was used for an 
experimental test, and our classification accuracy was 91.62% with 1.55% rejection on the 5-class 
system (94.38% on the 4-class system), which is the best result on the 5-class system to date.  An 
additional experiment on NIST-14 database reports 89.15% accuracy with 3.07% rejection. 
 
Key words: Fingerprint classification; Singular points; Directional image; Fault line. 
 
 
III. 內容與參考文獻 
（全文如下頁） 
 
 
IV. 計畫成果自評 
此計畫的成果已整理成可發表的論文，且已投稿，希望能早日出版。 
and “whorl.”  The “loop” type was then subdivided into “left loop” and “right loop;” while the 
“arch” was subdivided into “plain arch” and “tented arch.”  These five classes were also used in 
the NIST-4 database18 (as shown in Figure 1) and were denoted as “A” for “plain arch,” “T” for 
“tend arch,” “L” for “left loop,” “R” for “right loop,” and “W” for “whorl,” respectively.11 
Each fingerprint consists of two mutually intertwined patterns: ridges and valleys.  
Structurally speaking, valleys are the space between ridges and vise versa. More precisely, they 
are negative images to each other.  Therefore, we only need to focus on the primary pattern, i.e. 
the ridges. Each fingerprint consists of two major characteristics: a set of local features named 
minutiae and a set of global features called singular points.  Minutiae are local deformations of 
the ridges, while singular points represent regional directional makeup. 
There are two-types of singular points: core and delta.  Structurally speaking, a core is 
defined as a concentrate region where the ridge curvature is converging to a local maximum.26  
To the contrary, a delta is defined as a region where the ridge curvature is converging to a local 
minimum.  A fingerprint has only a few singular points, but can have a large number of 
randomly distributed minutiae.  For example, “A” type fingerprints contain no singular points 
while “W” type fingerprints have more than two core-delta pairs.  Due to the uncontrollable 
qualities of latent fingerprints, minutiae can not be precisely marked and some of them may even 
be missed out due to regional smudge.  As global landmarks, singular points can be used as 
references so that each presented minutia can be relatively charted. Therefore, singular points 
play a more important role in fingerprint recognition than minutiae. 
Based on the types of techniques used, fingerprint classification algorithms can be 
     
(a) (b) (c) (d) (e) 
Figure 1. Henry patterns: (a) arch, (b) tented arch, (c) right loop, (d) left loop, and (e) 
whorl. 
The experimental result is then shown in Section 5.  Finally, the conclusions are presented in 
Section 6. 
2. Fingerprint Image Preparation 
2.1. Fingerprint Image Enhancement 
The first step of the fingerprint enhancement is to distinguish the ridge flows (the desired pattern 
space) from the background.  To prepare the fingerprint image, a commonly used method based 
on block variance thresholding15 was used.  Let b(k) be the k-th block with a size of Ws×Ws 
pixels.  Its gray-level variance ν (k) can be defined as:  
( )∑ ∑−
=
−
=
−=
1
0
1
0
2
2
)(),(
1
)(
s sW
i
W
js
kjiI
W
k µν , 
where µ(k) is the mean value of all the gray-level pixels in b(k) and I(i, j) is the gray level 
intensity of the pixel at (i, j), respectively.  If ν(k) is smaller than a pre-defined threshold, then 
b(k) will be considered as a part of the background. 
The second step is to normalize the intensities of the ridge flows.  The purpose of this 
normalization is to eliminate the noise induced by the photo sensors and the gray-level shifting 
induced by unevenly pressed fingertips.10  For each pixel (i, j) that belongs to b(k), the 
normalized gray-level In(i, j) is defined as: 
( )( )
 )(
 )(, 20
0 k
kjiI
ν
µνµ −×+ ,  if I(i, j) > µ(k) 
In(i, j)   = 
( )( )
 )(
 )(, 20
0 k
kjiI
ν
µνµ −×− ,  otherwise, 
where µ0 is the desired mean and ν0 is the desired variance, respectively.  An example of this 
normalization is shown in Figure 1. It is clear that the normalized image (Fig. 2(b)) has a better 
contrast and sharpness than the original gray scale fingerprint (Fig. 2(a)). 
The third step is to enhance the ridge patterns by applying the even-symmetric Gabor 
filter proposed by Jain.9  Most importantly, a Gabor filter has both orientation-selective and 
frequency-selective properties.2, 10  Over the year, a number of researchers had applied Gabor 
filters to estimate the orientation field of flow- or ridge-like patterns.7, 9, 12, 13, 21, 22  The 
quantitatively converted into a fixed number of directions which represent their slopes.  While 
detecting singular points, most researchers used block directions defined by the medium of the 
directions among a block.4, 25, 26, 29  Then, the singular points are the locations where the 
maximum direction changes occurred.  There are two drawbacks in using block directional 
images: 1) poor contrast7 and 2) loss of details of ridges.26 
In this paper, the orientation of a pixel is determined by its 8-connected neighbors within 
a squared window.  Three direction numbers are used to represent 0, 60, and 120 degrees, 
respectively.  It means that we divide 2π into three directional zones. Orientations that are in the 
middle of a directional zone are set to be “uncertain” (shown as the pixels with yellow color in 
Fig. 3(a)).  Uncertain pixels are then smoothed by a median filtering process.3  Figure 3(b) 
shows the results of the smoothing procedure.  The edges that separate direction zones are called 
the fault lines.  The intersections of these fault lines are the places where the maximum direction 
changes occurred; i.e. the expected singular points as shown in Fig. 3 (c).  
   
(a) (b) (c) 
Figure 3. (a) pixel-wise directional image of Figure 2, (b) uncertain direction pixel 
removed image, and (c) located singular points 
To detect singular points, we used a modified two-phase shrinking and expanding 
algorithm (SEA).8  As shown in Fig. 4, the resolutions of the image are sequentially reduced by 
a factor of two from left to right by the shrinking process, and then the detecting process proceeds 
from the lowest resolution scaling up to higher resolutions from right to left. One problem for this 
shrinking process is that if the distance between core and delta is small, they might merge when 
the resolution reaches a certain low level.  It is observed that singular points around the outer 
border of the image (i.e. the area outside the red circle in Fig. 4(e)) have higher surviving 
possibilities with the lowest resolution. Any detected singular points in that outer region will be 
It is clear that “R,” “L,” and “T” types of fingerprints are geometrically similar if they are viewed 
with the tri-colored direction images.  All three types contain only one pair of singular points, 
with the delta point lying on the top of the horizontal baselines and the core point tilting to the 
right for the “R” type (as shown in Fig. 5(A) and 5(B)), to the left for the “L” type (as shown in 
Fig. 5(C) and 5(D)), and lying straight above for the “T” type (as shown in Fig. 5(E) and 5(F)). 
      
(a) (b) (c) (d) (e) (f) 
      
(A) (B) (C) (D) (E) (F) 
Figure 5. Six fingerprint images and their direction images. “R” type (a) (b); “L” type
(c) (d); “T” type (e) (f). 
Practically, when fingerprints are acquired, they are not specifically aligned with the 
imprinting papers.  Unfortunately, digitized direction images are sensitive to orientation changes.  
As shown in Fig. 6, a simple rotation can change the layout of the direction image. Fortunately, 
the expected singular points (the intersection points of the fault-lines) are not changed even 
though the rest of the fault lines may be totally distorted.  It is clear that there is no relatively 
fixed fault line geometry. We need to establish a creditable reference among the core-delta pair, 
the only fixed landmarks on the direction image, and their surrounding fault-lines.  Our singular 
points are valid references because their resolutions are accurate enough.  While other 
researchers’ singular points were detected with a resolution in the range of one in a hundred 
pixels, our accuracy is way superior with a resolution in the range of one in four pixels. 
    
(a) (b) 
in short), and to the right side of the core point, a Z5 of direction-2 is on top of a Z6 of direction-1. 
For each solitary fingerprint, the dominating directional number for all its distinguishable 
zones should be calculated.  Since each distinguishable zone is represented by its dominating 
direction number, it is noticed that more than one fingerprint may end up with an identical set of 
V. To make a direction pattern more distinctive, singular point related properties, such as the 
rotating angle α and the distance β are used. That is, the pattern template of a fingerprint is set to 
be {α, β, V}. 
4. Fingerprint Classification 
4.1. Pattern Constructions 
The proposed fingerprint template can be considered as a set of geometric constraints. 
Decision-rules can be used to describe these constraints which in term represent fuzzy 
descriptions of a direction pattern.  Let’s use typical solitary fingerprints in Fig. 7 as examples. 
For a typical “T” type fingerprint (as shown in both Fig. 7(E) and 7(F)), we can use the 
following fuzzy description to describe their dominating pattern zones: 
 ‘“T” type has a direction-0 zone in the middle of the direction pattern.’ 
This fuzzy statement can be easily translated into a set of constraints such as: 
‘Z1, Z2, Z9, Z10, Z15, and Z16 have to be 0.’ 
Then, the following decision rule can be developed from it: 
‘if the pattern template of a fingerprint has entries Z1, Z2, Z9, Z10, Z15, and Z16 
set to be 0, then this fingerprint is a “T” type.’ 
 
(a) (b) (c) (e) 
Figure 8. Eighteen direction pattern zones surrounding the rotated delta and core points 
Z1 
Z2 
Z3 
Z4 
Z5 
Z6 
Z7 
Z8 
Z9 
Z10 
Z11 
Z12
Z13
Z14
Z15
Z16
Z17
Z18
lists 9 pattern constraints that we used to classify fingerprints with small β, and Table 3 lists 
similar pattern constraints for fingerprints with larger β.  
Table 2. Some validated fingerprint pattern descriptors 
For a pattern template φi with β < 11,  
IF ( Z10=0 AND (Z15=0 AND Z16=0) ) THEN assign φi to T 
ELSE IF ( Z1!=2 AND Z2!=1 AND (Z3!=0 AND Z4!=0) ) THEN assign φi to T 
ELSE IF ( Z10=0 AND (Z3!=0 AND Z4!=0) AND α <115 AND 65< α) THEN assign φi to T 
ELSE IF ( Z1!=2 AND Z2!=2 AND (Z3=0 AND Z4!=0) AND α <65 ) THEN assign φi to R 
ELSE IF ( Z1!=1 AND Z2!=1 AND (Z3!=0 AND Z4=0) AND 115< α ) THEN assign φi to L 
IF ( Z1=1 AND Z2=1 AND Z10=1AND (Z3=0 AND Z4!=0) AND α <60 )  THEN assign φi to R 
ELSE IF ( Z1=2 AND Z2=2 AND Z10=2AND (Z3!=0 AND Z4=0) AND 
120< α ) THEN assign φi to L 
ELSE IF ( Z1!=2 AND Z2=1 AND (Z3=0 AND Z4!=0) AND α <60 ) THEN assign φi to R 
ELSE IF ( Z1=2 AND Z2!=1 AND (Z3!=0 AND Z4=0) AND 120< α ) THEN assign φi to L 
ELSE assign φi to type T   
Table 3: Some validated fingerprint patterns  
For a pattern template φi,  
IF ( Z10=0 AND (Z15=0 AND Z16=0) ) THEN assign φi to T 
IF (β < 24 AND (Z3!=0 AND Z4!=0) AND (Z7=2 AND Z8=1)  
AND (Z11=2 AND Z12=1) AND (Z15=2 AND Z16=1)) 
THEN assign φi to T 
ELSE IF ( (Z3=0 AND Z4!=0) AND Z10=1 AND α <91 ) THEN assign φi to R 
ELSE IF ( Z2=1AND (Z3=0 AND Z4!=0) AND α <95 ) THEN assign φi to R 
ELSE IF ( (Z3!=0 AND Z4=0) AND Z10=2 AND 89< α ) THEN assign φi to L 
ELSE IF ( Z1=2 AND (Z3!=0 AND Z4=0) AND 85< α ) THEN assign φi to L 
 :   
4.2. Fingerprint Classification Rules 
As aforementioned, our preliminary classification method is to distinguish fingerprint types “plain 
arch,” “whorl,” and “solitary” by examining their number of singular points. Then, solitary 
fingerprints are classified by pattern descriptors. Combine these two algorithms, the following 
classification rules are established. 
Fingerprint Classification (fingerprint φi, rule set R) 
1. If φi has no singular point, type “Plain Arch” is assigned to φi. 
2. If φi has only one singular delta point, reject φi. 
85.4% accuracy on the 5-class system and 91.4% accuracy on the 4-class system.  The later had 
91.3% accuracy on the 4-class system. 
Table 5. Classification results on NIST-4 
Approaches Class No Error rate Reject rate Dataset Comments 
5 14.6 Karu and Jain ‘9611 
4 8.6 
Decision based on 
topological info. 
Jain and Minut ‘0230 4 8.7 
zero 
4000 images,  
no training 
 Hierarchical kernel fitting 
5 14.6 
4 8.5 
KNN 
5 13.6 
4 7.9 
NN 
5 10.0 
Jain et al ’99 10 
4 5.2 
1.8 
KNN + NN 
Marcialis et al. ‘0114 5 12.12 zero NN 
Senior ‘0123 4 Avg. 8.5 zero NN 
5 10.0 
Yao et al. ‘0329 
4 5.3 
1.8 SVM + RNN 
5 8.4 
Tan et al. ‘0327 
4 6.7 
zero 
Training: First 
2000 images 
Testing: 
Second 2000 
images 
GP based learned features 
+ Bayesian classifier 
5 8.38 
This paper 
4 5.61 
1.55 
4000 images 
no training 
Directional Patterns 
 
Algorithms utilizing neural network, SVM, or genetic algorithm10, 23, 27, 29, require a 
significant amount of training data to retain a reasonably high accuracy rate.  In most of the 
cases, the size of training data was half of the test-bed.  Tan27 used Genetic Programming (GP) 
on orientation field tested on the NIST-4 database. The result was 0% rejection and 91.6% 
accuracy on the 5-class system, and 93.3% accuracy on the 4-class system.  The classification 
accuracy in29 was 90.0% with 1.8% rejection on the 5-class system, or 1.8% rejection and 94.7% 
accuracy on the 4-class system.  The results of these classification algorithms depend highly on 
their training data. When the test data changed, their methods can not guarantee a similar 
performance. Compared with other classification algorithms, our method outperforms all 5-class 
algorithms, training or no-training required. 
Our method analyzes the structure of fingerprints without requiring training.  More 
importantly, the classification accuracy rates provided by our algorithm are evenly high for 
fingerprints of all five classes.  This is attributed to our singular point detection algorithm.  We 
have also applied our algorithm on the PCASYS (NIST-14) database31 which contains 2,700 
fingerprints, and the results are listed in Table 6.  The overall accuracy rate is 89.15% with 
3.07% rejection.  
7. L. Hong, Y. Wan, and A. K. Jain, “Fingerprint Image Enhancement: Algorithm and 
Performance Evaluation”, IEEE Trans. on Patt. Analysis and Machine Intelligence 20 (1998) 
777-789. 
8. D. C. Hung and C. Y. Huang, “A Model for Detecting Singular Points of a Fingerprint”, 
Proc. Florida Artificial Intelligence Research Symposium (9th), Key West, Florida, 1996, pp. 
444-448. 
9. A.K. Jain, L. Hong, and R. Bolle, “On-line Fingerprint Verification”, IEEE Tran. on Pattern 
Analysis and Machine Intelligence 19 (4) 302-314, 1997. 
10. A.K. Jain, S. Prabhakar, and L. Hong, “A Multichannel Approach to Fingerprint 
Classification”, IEEE Tran. on PAMI, vol.21, no.4, pp.348-358, 1999. 
11. K. Karu and A.K. Jain, “Fingerprint Classification”, Patt. Recogn. 29 (1996) 389-404. 
12. D. Maio and D. Maltoni, “Direct Gray-Scale Minutiae Detection in Fingerprints, “ IEEE 
Transactions on Pattern Analysis and machine Intelligence, vol. 19, no. 1, 1997. 
13. D. Maltoni, D. Maio, A.K. Jain and S. Prabhakar, Handbook of Fingerprint Recognition, 
Springer, 2003. 
14. G. Marcialis, F Roli, and P. Frasconi. Fingerprint classification by combination of flat and 
structural approaches. Proc. of AVBPA 2001, June, 3-5, 2001, Halmstad (Sweden), J. Bigun 
and F. Smeraldi Eds, Springer LNCS 2091, pp. 241-246.  
15. B.M. Mehtre, "Fingerprint Image Analysis for Automatic Identification," Machine Vision and 
Applications, vol. 6, pp. 124-139, 1993. 
16. B. M. Merthe, N.N. Murthy, S. Kapoor and B. Chatterjee, “Segmentation of Fingerprint 
Images Using the Directional Image,” Patt. Recogn. 20 (1987) 429-435.  
17. Moscinska K. and Tyma G., "Neural Network based Fingerprint Classification", in 
proceedings 3rd Int. Conf. on Neural Network, pp. 229--232, 1993. 
18. NIST Scientific and Technical databases - Fingerprints. 
http://www.nist.gov/srd/fing_img.htm (Dec. 18, 2003). 
19. H.V. Neto and D.L. Borges. Fingerprint classification with neural networks. In Proceedings 
4th Brazilian Symposium on Neural Networks, pages 66--72. IEEE Press, 1997. 
20. G. Ongun and U. Halici, "Fingerprint Classification Through Self-organizing Feature Maps 
Modified to Treat Uncertainties," Proc. of the IEEE, vol. 84, no. 10, pp. 14971512, Oct. 
1996. 
21. V. Onnia and M. Tico, "Adaptive Binarization Method for Fingerprint Images", IEEE Int. 
Conf. on Acoustics, Speech and Signal Processing, Orlando, Florida, 2002, pp. 3692-3695. 
22. A.R. Rao, A Taxonomy for Texture Description and Identification. New York: 
Springer-Verlag, 1990.  
23. A. Senior, “A combination fingerprint classifier”, IEEE Trans. PAMI. 23 (10) (2001) 
1165–1174. 
24. S. Shah and P. S. Sastry, “Fingerprint classification using a feedback based line detector”, 
IEEE Trans Systems, Man and Cybernetics, Vol. 34, pp.85–94, 2004. 
25. B. G. Sherlock and D. M. Monro, “A Model for Interpreting Fingerprint Topology”, Patt. 
Recogn. 26 (1993) 1047-1055. 
26. V. S. Srinivasan and N. N. Murthy, “Detection of singular points in fingerprint images”, Patt. 
Recogn. 25 (1992) 139–153. 
