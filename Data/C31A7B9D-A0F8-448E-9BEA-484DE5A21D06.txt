knowledge to describe the course content objective. Section 3
gives the formal framework and the related adaptation
operation for a detailed understanding of the multimedia
content model. In Section 4, some significant concepts
presented our approaches and discussed the adaptation
operation evaluations, this paragraph discuss our approach
that try to work steadily and make solid progress. Section 5
summarizes our work and gives an outlook of ongoing and
future work.
II. ONTOLOGY-BASED INFORMATION REPRESENTATION
An easy way to comply with the conference paper
formatting requirements is to use this document as a template
and simply type your text into it.
An ontology is a specification of a conceptualization [10].
Ontology is a collection of key concepts and their
interrelationships collectively providing an abstract view of an
application domain. Ontologies play a key role in the semantic
description. With the support of ontology, both user and
system can communicate with each other by the shared and
common understanding of a domain [11]. Protégé 3.3.1 is an
ontology construction tool that is open-use, free of charge, and
has well-defined features and was developed by SMI
(Stanford Medical Informatics). Protégé is not only was one of
the most important platforms to construct ontology but is also
the most frequently adapted one [12][13]. The most special
feature is that its framework is constructed by ontology
concepts. It uses multi components to edit and make ontology
and lead knowledge workers to construct a knowledge
management system based on ontology; furthermore, users
can transfer to different formats of ontology such as RDF(S),
OWL, XML or directly inherit into databases like MySQL and
MS SQL Server, which have better supported functions than
other tools [14]. The superiorities were described by [12], [13].
Ontology is a method of conceptualization on a specific
domain [15]. Protégé-3.1.1[16] was developed by SMI
(Stanford Medical informatics) for construction ontology.
This software has some advantages for developers: (1) Open-
source software. (2) Multiple knowledge ontology support. (3)
Multiple storage formats support. (4) Multiple data types
support. (5) Integrated Application GUI. (6) Plug-in service
support.
Based on the above features, we know that the Protégé-
3.1.1 not only has a friendly GUI for developers but also
supports multiple storage formats for databases. We could use
the database to construct the entities or the XML description
to represent the semantic facilities. In this paper, we used
Protégé-3.1.1 to develop our multimedia course object
ontology. There are two main methods to construct the
ontology in Protégé: Open Knowledge Base Connectivity
protocol (OKBC) and Web Ontology Language (OWL). Open
Knowledge Base Connectivity protocol (OKBC) defines the
knowledge ontology: class describes the domain concept; slot
describes the abstraction of properties and relationships; facet
is the restriction of the properties. Inheritance relationship
existed between two classes. Subclass inherited super-class’s 
slot and their relationship. Web Ontology Language
(OWL)[17] is designed for the application to process the
messages that the documentation contains. This feature is the
only form presenting the content for people. OWL can
represent the terminologies of the specified vocabulary and
the relationship between two terminologies more clearly and
definitely. In domain semantic representation, OWL provides
more categories than XML, RDF or RDF-S. OWL adds many
lexicons to describe the properties and classes: among them,
relations between classes, cardinality, equality, richer typing
of properties, characteristics of properties, and enumerated
classes. On the other hand, OWL designed three extensible
sub-languages for special purposes communities of
implementer and users [17]:
Ontology is one theory in philosophy and is used primarily
to explore knowledge characteristics of life and real objects;
in artificial intelligence fields it is used to define the content
of domain knowledge, express knowledge, solve
communication, and commonly share problems; in
information technology field it offers much assistance for
research and development of E-commerce and Knowledge
Management [18]. Ontology provides complete semantic
models, which mean in specified domain all related entities,
attributes and base knowledge among entities have sharing
and reuse characteristics which could be used for solving the
problems of common sharing and communication. To describe
the structure of the knowledge content through ontology can
accomplish the knowledge core in a specified domain and
automatically learn related information, communication,
accessing and even induce new knowledge, therefore,
ontology is a powerful tool to construct and maintain an
information system.
The Adaptive Learning System is the system that performs
the regulation/adaptation for learners, and to conform the
student preferences for learning. Adaptive Learning System is
derived from Intelligent Tutoring Systems (ITSs) and contains:
learning material, characteristic of learner, and teaching
strategy to support the adaptive learning approach [19]. There
are many research issues in ALS, for example: course
planning, intelligent Q &A analysis, interactive problem
solving support, collaborative learning support, adaptive
presentation, and adaptive navigation support [20].
TABLE 1: LEARNING FEATURES ANALYSIS ABOUT ADAPTIVE/DYNAMIC/ TIME
LIMITATION FOR RELATED RESEARCH AND OUR APPROACH
Adaptive Dynamic Time
Limitation
[22]
Yes Yes No
[23]
Yes No No
[24]
Yes No No
Our
approach
Yes Yes Yes
Figure 4：Reference Ontology
As shown in Figure 4, Reference Ontology describes the
related references of presentation object. Reference owns
three attributes: Source (such as authors), Date (Release Date)
and Rating (Impact Factor). There are two relationships
between Reference entities: References and IsBasedOn.
 References(x,y) represents that x refers the content of y.
 IsBasedOn(x,y) represents that x is based on the
content of y.
Reference contains three subclasses: Paper (refer to the
other paper)、Book (refer to the other book) and Technical
Report (refer to the other technical report).
For the most part, a multimedia presentation must be
produced with a great quantity of data capacity. In most
existing presentation systems, the user didn’t have tobe
endowed with retrieving, abstracting, additional adapting (e.g.
select channels, time specified), weaving or customizing
facilities during the presentation. These above-mentioned
presentation system facilities are user-concerned in the
available system resources. In the section, we assume that
multimedia content model must offer the possibility to
represent alternatives and categorically to conform to the
dynamic user-context.
TABLE 2: AN EXAMPLE OF LABELED CONCEPT AND KEYWORDS FOR SLIDE
ITEM.
.Slide Item S1 S3 S4 S5 S6 S7 S8 S9 S10
Concept first Outline Ch1 1-1 1-2 1-2 Ch2 2-1 2-1 2-2
K1 ◎ ◎
K2 ◎ ◎
K3 ◎ ◎
K4 ◎ ◎ ◎
Table 2 is an example of labeled concept and keywords for
a slide item. As row of Concept shows, S1 and S2 are the first
and outline slide respectively, and from S3 to S10 represent
the subchapters’ slides. As row of K1 shows, Keyword K1 
appears in S5 and S10, Keyword K2 appears in S8 and S9,
Keyword K3 appears in S8 and S10, and Keyword K4 appears
in S3, S4 and S6. As given the above information in table 2
that represents the respective hierarchical relationship among
learning objects as well as figure 5 shows. Concept Ontology
represents Hierarchical Relationship among Concepts Objects.
Hierarchical Relationship among Concepts Objects consists of
concept objects (labeled as table of content) and arcs
(relationships:1.ConsistsOf, 2.References, 3.IsBasedOn and
4.Requires).
Figure 5：Hierarchical Relationship among Concepts Objects
According to the hierarchical relationship among learning
objects, we can derive a Multimedia Presentation Map, as
shown in Figure 6. Multimedia Presentation Map consists of
multimedia objects (slides:s1~s10), concept objects(labeled as
table of contents) and arcs (relationships:1.ConsistsOf,
2.References, 3.IsBasedOn, 4.Requires and 5.Follows).
Figure 6：Multimedia Presentation Map
According to Multimedia Presentation Map and the
keywords assigned by the user, each presentation object will
be equipped with a reasonable weight value. First, all
presentation objects’ weight values are initialized on the basis 
of Multimedia Presentation Map, as shown in Algorithm 1 and
Figure 7. The concept objects, which have no parent node, are
taken as root nodes. The weight values of root nodes are
initialized as initialValue (The weight value that represents
highest priority). Function setWeightValueOfChild is used to
initialize the weight values of root nodes' descendant nodes
recursively. The rule of initialization is as follow:
Weight_value_of_child = weight_value_of_parent + 1.(The
bigger weight value represents the higher priority.)
[16] N.F. Noy and D.L. McGuinness, "Ontology Development 101:A Guide
to Creating Your First Ontology," Available at
http://www.ksl.stanford.edu/people/dlm/papers/ontology-tutorial-noy-
mcguinness.pdf, 2000.
[17] OWL web Ontology Language Overview,
http://www.w3.org/TR/2004/ REC-owl-features-20040210/
[18] S.Y. Yang, C.W. Wu, and C.S. Ho, “Using Rule Mining and Behavior 
Prediction Techniques in Web Information Query Processing,” Proc. of 
the 6th Conference on Artificial Intelligence and Applications,
Kaohsiung, Taiwan, 2001, pp. 574-579.
[19] Burns, H. L. and Capps, C. G. (1988) Foundations of intelligent
tutoring systems: An introduction. In: M. C. Polson and J. J.
Richardson (eds.): Foundations of intelligent tutoring systems.
Hillsdale: Lawrence Erlbaum Associates, pp. 1-19.
[20] Brusilovsky, P. (1996) Methods and techniques of adaptive
hypermedia. In P. Brusilovsky and J. Vassileva (eds.), Spec. Iss. on
Adaptive Hypertext and Hypermedia, User Modeling and User-
Adapted Interaction 6 (2-3), 87-129.
[21] Zhiwen Yu, Yuichi Nakamura, Daqing Zhang, Shoji Kajita and Kenji
Mase, "Content Provisioning for Ubiquitous Learning", journal of
PERVASIVE computing, October–December 2008 pp. 62-70.
[22] Karampiperis, P. and Sampson, D., “Adaptive Instructional Planning 
using Ontologies,” In: Proceedings of The 4th IEEE International 
Conference on Advanced Learning Technologies, Joensuu, Finland,
2004, pp. 126 -130.
[23] Peng Chen, Anbo Meng, Chunhua Zhao, "Constructing Adaptive
Individual Learning Environment Based on Multi-agent System,"
Computational Intelligence and Security Workshops, International
Conference on 15-19 Dec. 2007 pp. 374-377, 2007 International
Conference on Computational Intelligence and Security Workshops
(CISW 2007), 2007.
[24] Kun Hua Tsai, Ti Kai Chiu, Ming Che Lee, Tzone I Wang,
“Automated Course Composition and Recommendation based on a 
Learner Intention”, The 7th IEEE International Conference on 
Advanced Learning Technologies (ICALT2007), Niigata, Japan.
[25] J. Ayers et al., “Synchronized Multimedia Integration Language (SMIL)
2.0, World Wide Web consortium Recommendation, Aug. 2001,
http://www.w3.org/tr/2001/rec-smile20-20010807/.
[26] Dick C. A. Bulterman, “Standards SMIL 2.0”, Journal of IEEE 
Multimedia, pp. 82-88, 2001.
[27] Ch. F. Goldfarb, “The SGML Handbook”, Claredadon 
Press,Oxford,1991.
[28] ISO/IEC JTC1/SC29/WG12, Information Technology-Coding of
Multimedia and Hypermedia Information -Part 5: Support for Base-
Level Interactive Applications, ISO/IEC IS 13522-5, ISO/IEC, 1995.
[29] ISO/IEC JTC1/SC29/WG12, Information Technology -Coding of
Multimedia and Hypermedia Information-Part 6: Support for Enhanced
Interactive Applications, ISO/IEC IS 13522-6, ISO/IEC, 1996.
[30] ISO/IEC JTC1/SC29, Information Technology-Coding of Multimedia
and Hypermedia Information-Part 1: MHEG Object Representation
ISO/IEC 13522-1, ISO/IEC IS, 1997.
[31] S.R. Newcomb, N.A. Kipp, and V.T. Newcomb, ªHyTime-The
Hypermedia/Time-Based Document Structuring Language, Comm.
ACM, vol. 34, no. 11, Nov. 1991.
[32] ISO/IEC, Information Technology-Hypermedia/Time-Based
Structuring Language (HyTime), ISO/IEC IS 10744, 1992.
[33] Dynamic HTML in Netscape Communicator, Netscape Corp.,
http://developer.netscape.com/docs/manuals/communicator/dynhtml,
1997.
[34] D. Raggett, A. Le Hors, and I. Jacobs, HTML 4.0 Specification W3C
Recommendation, revised on 24-April-1998, W3C, URL:
http://www.w3.org/TR/1998/REC-html40-19980424, Apr. 1998.
[35] B.Bos et al., Cascading Style Sheets, Level2, W3C Recommendation,
W3C, May 1998, URL: http://www.w3.org/TR/REC-CSS2
[36] Microsoft® Dynamic HTML Editing Component (DHTML Editing
Component) SDK, Microsoft® Inc., URL: http://www.microsoft.com/
[37] S. Bol, W. Klas, and U. Westermann, “ZYX - A Multimedia
Document Model for Reuse and Adaptation of Multimedia Content”, 
IEEE Transactions on Knowledge and Data Engineering, Vol.13, NO.3,
MAY/JUNE, pp. 361-382, 2001.
[38] Herman, N. Correia, D.A. Duce, D.J. Duke, G.J. Reynolds, and J. Van
Loo, "A Standard Model for Multimedia Synchronization: PREMO
Synchronization Objects", in: Multimedia Systems, 6, 1998.
-1-
EOG-based Signal Detection and Verification for HCI
Lawrence Y. Deng1, Yung-Hui Chen2, Chun-Liang Hsu3, Tzu-Ching Lin1, and Jui-Sen Tuan1
1Department of Computer Science and Information Engineering, St. John’s University
2 Department of Computer Information and Network Engineering, Lunghwa University of Science and Technology
3Department of Electrical Engineering, St. John’s University
Email: Lawrence@mail.sju.edu.tw
Abstract
In this paper, we proposed an
eye-movement tracking system. Based on
Electro-Oculography (E.O.G) technology we
detected the signal with different directions in
eye-movements and then analyzed to
understand what they represented about (e.g.
horizontal direction or vertical direction). We
converted the analog signal to digital signal and
then used as the control signals for Human
Computer Interface (HCI). In order to make
the system “robust”, several applications with 
EOG-based HCI had been designed. Our
preliminary results revealed more than 90%
accuracy rate for examining the eye-movement
that may become a new useful human-machine
user interface in the near future.
Keywords:
Electro-Oculography (E.O.G), Motor
Neuron Disease, Eye-Movement, Amyotrophic
Lateral Sclerosis, Human-Machine/Computer
Interface (HMI/HCI)
1. Introduction
Jean-Dominique Bauby was a famous
journalist and editor of the fashion magazine
ELLE. In 1995, Bauby suffered a massive stroke.
His condition is called Locked-in Syndrome; he
could only blink his left eyelid. In spite of his hard
condition, Bauby blink his eye when the correct
letter was reached by his interlocutor reciting the
alphabet and finaly accomplished the book ”The 
Diving Bel and the Buterfly” in 1997 [9]. In
Taiwan, Mr. Chen suffered Motor Neuron Disease,
(M.N.D) or Lou Gehrig's disease. Impressively,
Mr. Chen accomplished 5 books that contain
190,185 words from 1999 to 2005 (the most
words written by blinking in the Guinness World
Records) [6]. For thousands of people,
Amyotrophic Lateral Sclerosis (ALS) deprives
them from using their limbs or even speech. They
leave the brain and eyes activity unimpaired. The
only way for communication is to detect the
Eye-movement correctness. EOG-based signal
processes provided the detection of the
Eye-movement resulting from looking-up, down, left
and right. [13] have developed a new method for
automatic estimation of vigilance level by using
electroencephalogram (EEG), electromyogram (EMG)
and eye movement (EOG). [3] [4] diagnosis of
subnormal eye through the analysis of EOG signals
and then to assist the physician to make the final
decision without hesitation. So the eye-movement
HCI can be taken as an input device for
communication [8][11][16][18].
Figure 1: Eye-movement HCI platform
architecture.
In this paper, we constructed an eye-movement
HCI platform for several applications. Figure 1
illustrated the Eye-movement HCI platform
architecture. The eye-movement coils are the
electromagnetic fields that received signal between 50
to 3500uV with a frequency range of about dc-100 Hz.
Eye-movement signals needs to be
adjusted/normalized by signal amplifier, adders and
filters. The filters eliminate the effects due to other
Universal Asynchronous
Receiver/Transmitter, UART
Eye–movement coils
Signal Amplifier, adder and Filters
Analog-to-Digital Converter,
Computer COM port (RS232),
Applications Control Component
AP 1 AP 2 AP n
- 4 -
Figure 2: Flow chart of the EOG signal recording.
A.1 Bio-potential Recording
The EOG was attached on to the
surrounding area of eyes with the help of others,
and then turned on to detect the corneal-retinal
potential difference. We chose pragmatic reliable
low-cost electrodes for long-term use in EOG
signal recordings.
A.2 Bio-potential Amplifier
The amplifier IC (INA128, Texas
Instruments, TI) as shown in figure 3, which was
composed of 3 Difference amplifiers was used.
We have to modify the RG resistance to change its
gain [17]. Here we adapted ＲＧas１Ｋ to get a
voltage gain of about 50 times.
Vo= ))(
22
1(
3
4  VV
RG
R
R
R
Figure 3: INA128 [17]
A.3 Balance
Signals differentially amplified by INA128
may not be balanced, so we adapted an adder to
balance the signal.
A.4 Filtering
According to literature, the signal
band-width of eye-movement was located in the
range of 0.1Hz~20Hz, so signals more than
20Hz would be regarded as noise which should
be deleted using noise filters. Here we designed
a band-pass filter [14] ranging from 00.5 to 23
Hz to isolate the disturbance from grid
electricity of 60Hz. However, we realized that
just a one-class low-pass filter couldn’t
effectively avoid the noise, so we added another
low-pass filter of 19Hz, and the output was
better with much better stability.
fH=
2 2121
1
CCRR 
=
)101103(2
1
66 
=
328.6
1

=
84.18
1 =0.053 Hz
Figure 4: High pass filter.
The high pass filter is shown in figure 4, in
which the signal frequency below than 0.05 Hz would
be isolated. In figure 5, the first-class low-pass filter is
used to isolate signals of frequency higher than
23.417Hz. In Fig 6, the second-class low-pass filter
would deal with the signals passing through the
first-class filter to get a higher Q value of signals.
fH=
2 43109
1
CCRR 
=
)101.01068(2
1
63 
=
3108.628.6
1

=
310704.42
1

=23.417Hz
Figure 5: First-class low-pass filter
fH=
2 651413
1
CCRR 
=
)101.01082(2
1
63 
=
3102.828.6
1

=
310496.51
1

=19.418Hz
Figure 6: Second-class low-pass filter.
A.5 Horizontal Movement
Since the voltage range of AD converter in our
microprocessor was from 0 to 3.3V, we needed to
design an adjusting circuit to let the detected voltage
available.
A.6 Input into microprocessor
The reason why we selected SPCE061A as our
core microprocessor was due to its advantages like
re-programming capability, real-time debugging,
low cost, and simple interface. After AD converting,
the signals are sent to the microprocessor through an
RS-232 interface [10].
B. Preliminary Experimental Results
The following paragraph will illustrate the EOG
analog signal for bio-potential changes when the eye
moves up, down, left, and right.
B.1 EOG Analog Signal
Figure 7 show the fuzzy set values for the EOG
analog signal waves recorded by the Oscillograph.
The related fuzzy distinction rules are shown in Table
1. More testing results are shown in Appendix I.
Table 1: Fuzzy Distinction Rule
If A is high and B is high, then Up.
If A is mid and B is mid, then Right.
Voltage output to SPCE061A
Instrument amplifier
Adder
High-pass filter of 0.05Hz
Voltage adjusting and filting
Low-pass filter of 23Hz
Low-pass filter of 19Hz
Sinnals input of EOG
- 6 -
Figure 10: EOG signal adjustment sub-system
view.
C. EOG based remote-control System for TV
Turn on the TV with Electro-Oculography
interface as shown in Fig 12. Its function is to
shift the channels and to adjust the volume.
timer1.Enabled = true;
pInfo.UseShellExecute = true;
if (rs232.isStart==true){
if (P.r.d==direction){
textBox1.Text = “direction”; 
if (UpDnLfRtsignal==direction){
rs232.count = 0;
SendKeys.Flush();
}
}
}
Figure 12. EOG based Remote-control System for
TV view.
D. Eye-sight Level Checking System
a. Upon starting the system, it would
give out the test items, and users could
answer the test items with
Electro-Oculography interface and test
out the eyesight level as shown in
Fig.13.
b. After comparing with the level tested
by the hospital, a precision of up to
95% could be obtained.
c. It worked without any help from
others.
if (rs232.isStart == true){
label2.Text
if (Up Dn Lf Rt signal ==direction){
if (UpDnLfRtsignal ==direction)
r++;
else
w++;
nextPic();
count = 0;
}
}
if (end == true && final == true && r
== 2){
end = false;
}
Figure 13: EOG-based eye-sight level checking
system view
E. EOG-based Game with Eye-control
The practical game interface is shown in Figure
14.
new PictureBox[15];
for(int i=0;i<3;i++)
for(int j=0;j<5;j++){
picrecord[i * 5 + j] = index;
}
Up{
if (picrecord[5 * i + mypicloc] ==
mypicindex){
pic[5*i+mypicloc].Image=null;
picrecord[5*i+mypicloc]=99;
if (count == 15){
Show("Win!!!")
break;}
}
}
Down{
mypicindex=(++mypicindex)%3;
}
Left or right{
mypicloc--;(mypicloc++;)
}
Figure 14: EOG-based Game with eye-control view.
5. Experimental Discussion
A. Distortion of EOG Signals
In the experimental processes, we found that
there would be 30 to 90 minutes of best signal
stability for every user with different physical
conditions and environment, and over the time period,
the signals would shift. We tried to explain this
situation as resulting from long time attachment of
EOG and sweating of skin. If we wash the EOG with
alcohol, the situation would be improved.
A.2 Movement of Eyes
