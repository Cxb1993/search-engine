II
一步設計出一個情緒分析的系統架構，其中主要項目包括：從網路服務取得知識
庫，以機率方法建立情緒字典，以機器學習為本的模式、運用文句特徵建立情緒
分類知識、以情緒分類知識為核心建立各項應用。應用項目包括了對部落格文本
的搜尋過濾、跨語言的文本情緒辨識、整合作者與讀者多重觀點的情緒辨識、整
合文本與音樂多重媒體的情緒辨識，另外也實作了情緒的民意與趨勢分析，以及
協助作者判斷讀者情緒的寫作系統。
本研究從網路日誌中帶有情緒符號標記的文句出發，探討人們的溝通行為擴展
至網路空間後，如何將情緒表達的需求，反映在文字與情緒符號的使用上。並進
一步以情緒符號的意涵作為文句表達情緒的分類依據，藉由各項情緒分類器的實
驗數據，研究以情緒詞彙解釋人們在網路日誌中使用情緒符號的偏好與特徵，進
而達成對網路空間人們情緒的解讀與分析。
有關網路日誌其文本與使用者情緒的研究，需要各項自然語言處理技術的創
新發明與協助。儘管網路日誌服務提供了使用者許多有關發表內容的新技術、新
創意，使用者主要仍是以語言的方式參與網路日誌創作，並藉由語言跟其他使用
者互動、溝通。與其他使用者溝通時由於不是面對面的接觸，因此得用適當的語
言模式來表達自己的情緒，這個模式可能會是沿用自傳統的溝通習慣，或是因網
路興起而產生的規則(如網路俚語)。為了分析這些語言模式，在大量網路日誌語料
的支援下，本研究在結合機率統計模型、機器學習、語言學的方法架構下提出分
析方法及提出檢驗；期許在網路日誌蓬勃發展的同時，也能掌握下一波影響網際
網路發展的關鍵技術。
IV
multi-perceptive integration (blog and music). Knowledge on blog metadata inclusive
of textual units, time stamps, and named entities also help construct a census and trend
survey module. Other applications include implementation on emotion filtering for
blog texts, a cross-lingual adaption of emotion analysis, and an authoring tool for the
writes to predict the readers’emotions.
Written text is one of the media by which people convey their emotions. But do
bloggers always share the traceable emotions? If not, are the appearances of emotion
icons totally random, or are there recurring patterns? These are the original questions
which direct our research. By knowing how emotions conveyed by texts, it is possible
to build a system to provide users with language usage recommendations to assist uses
in expressing appropriate emotions. The analyzing system on emotions can be
integrated in other research fileds in the future.
VI
CHAPTER 6 EMOTION CLASSIFICATION ..................................................... 45
6.1 FROM TEXT CLASSIFICATION TO EMOTION CLASSIFICATION ................................. 45
6.2 BINARY CLASSIFIER PERFORMANCE ...................................................................... 46
6.3 A SYSTEM OF CLASSIFYING EMOTIONS.................................................................. 49
6.4 EVALUATIONS ON THE CLASSIFICATION SYSTEM.................................................... 51
6.4.1 Bipolarity Classification................................................................................ 52
6.4.2 Arousal-Valence Space Classification ........................................................... 52
6.5 APPLICATIONS AND DISCUSSIONS .......................................................................... 54
6.5.1 Blog IR and Emotion Filtering ...................................................................... 54
6.5.2 Cross-lingual Emotion Analysis .................................................................... 56
6.5.3 Summaries ..................................................................................................... 59
CHAPTER 7 APPLICATIONS OF EMOTION MODELS................................. 61
7.1 A MULTI-PERSPECTIVE INTEGRATION .................................................................... 64
7.1.1 Integration of Writer and Reader Emotions .................................................. 64
7.1.2 Emotional Pattern by Blog Category ............................................................ 66
7.1.3 Emotion Valence Analysis.............................................................................. 67
7.1.4 Summary ........................................................................................................ 69
7.2 A MULTI-PERCEPTIVE INTEGRATION ...................................................................... 69
7.3 EMOTION CENSUS AND TREND TOOL ..................................................................... 72
7.3.1 Name Entity Rule Mining .............................................................................. 72
7.3.2 Report Demonstrations.................................................................................. 74
7.4 AUTHORING TOOL.................................................................................................. 75
7.4.1 READER-EMOTION LEXICONS FOR WRITERS ....................................... 76
7.4.2 An Authoring Tool for Writers ....................................................................... 77
7.4.3 Ranking Recommended Words....................................................................... 78
CHAPTER 8 CONCLUSIONS............................................................................... 81
BIBLIOGRAPHY......................................................................................................... 83
APPENDIX ................................................................................................................... 93
A1. STOP WORD LIST .................................................................................................. 93
A2. EMOTION LEXICON CATEGORIZED BY EMOTIONS ................................................. 93
A3. EMOTION LEXICON CATEGORIZED BY WORDS ...................................................... 98
VIII
Figure Index
Figure 2.1 Temporal Correlations for Emotions and Texts. ............................................. 5
Figure 2.2 Application Range for Emotion Classification Tasks. .................................... 9
Figure 3.1 Graphic Models - Naive Bayes, Logistic Regression, and CRFs. ................ 18
Figure 3.2 Arousal-Valence Space and Sentiment Projection. ....................................... 22
Figure 4.1 Blog Post Structure. ...................................................................................... 27
Figure 4.2 Sample Blog Posts. ....................................................................................... 28
Figure 4.3 Blog Post Number in Hourly Distribution. ................................................... 32
Figure 5.1 Evaluation Framework for Lexicon Building Methods. ............................... 39
Figure 5.2 Some Example Words in Emotion Lexicon. ................................................. 40
Figure 6.1 System Framework. ...................................................................................... 50
Figure 6.2 Arousal-Valence Projection. .......................................................................... 50
Figure 6.3 System Flow for Emotion Filtering. ............................................................. 55
Figure 6.4 Demonstration Interface for Emotion Filtering............................................. 55
Figure 6.5 A Cross-lingual Framework. ......................................................................... 58
Figure 7.1 Application Framework................................................................................. 62
Figure 7.2 System Flow for a Multi-Perspective Integration. ........................................ 64
Figure 7.3 Valence-Arousal Graphs................................................................................ 65
Figure 7.4 Smoothed Valence-Arousal Graphs. ............................................................. 65
Figure 7.5 Stacked Area Graphs. .................................................................................... 68
Figure 7.6 System Flow for a Multi-Perceptive Integration........................................... 70
Figure 7.7 Emotion-Based Integration of Visualized Blog and Music........................... 70
Figure 7.8 Demonstration of Multi-Perceptive Integration. ........................................... 71
Figure 7.9 Demonstration of Trend Report. ................................................................... 74
Figure 7.10 An Authoring Tool for Writers .................................................................... 79
1Chapter 1
Introduction
Internet provides people with platforms for information exchange and becomes a
potential knowledge source for statistical language processing techniques. Nowadays
people communicate through internet or by means of internet media. Internet media
are mainly spread by technologies applied on the World Wide Web (abbreviated as Web).
As more techniques are invented or introduced to Web, Web evolves into a collaborative
platform which is called Web 2.0. Web 2.0 formally refers to a second generation of
the World Wide Web and arises as a collection of collaborative web sites that timestamp
messages (articles or commentaries) from a community of people.
Being a member of Web 2.0, blogosphere grows quite popularly in recent years.
Blogosphere means a collection of blog sites from an individual or a group of people
(called bloggers). The bloggers publish their articles in journal style and a blog service
typically displays the articles in a reverse chronological agenda. Blog readers can
browse the agenda, pick an interesting link, read the linked articles, and leave some
comments. A blog service also incorporates inventions, e.g. feeds and trackbacks, to
facilitate the communication.
However, blog services primarily provide bloggers with textual communication.
The internet users can hardly capture the communicator’s feeling from the textual
descriptions without sufficient context information. Therefore emotion symbols
(called smileys), originated from a sequence of ordinary printable characters, were
integrated into the textual expressions. These short strings represent facial symbols
and they also convey the communicator’s feelings.  Smileys bring the vivid
expressions and evolve into different forms. For example, after text-based smileys
3emotion states via digital ways becomes more demanding than before. With such
trend, more works on emotion analysis are proposed to help us identify more latent
meanings associated with internet communication and thus enhancing opinion analysis,
as wel as mining individuals’ sentiments toward specific subjects or events.
Written text is one of the media through which people convey their emotions.
But do bloggers always share the traceable emotions? If not, are the appearances of
emotion icons totally random, or are there recurring patterns? These are original
questions which direct our research. Previous studies have focused on emotion
analysis and we will review many of them in the Related Work section. Besides being
a psychological study, the analysis of emotions will lead to practical applications. By
knowing how emotions are conveyed by texts, it is possible to build a system to provide
users with language usage recommendations to assist the appropriate use of emotion
expressions.
1.2 Research Questions
In this research, we analyze the use of emotions in blog articles. More specifically, we
focus out attention to three questions, including:
1. What kinds of emotion-related information can be extracted from blog articles?
2. In what way can emotion-related information be analyzed in detail?
3. What application can be designed using the analyzed results?
To answer the first research question, an emotion dictionary is created as a knowledge
base for reference. Then, we incorporate the knowledge base into machine learning
methods to provide answers to the second question. As for the third question, several
applications will be proposed based on these machine-learnt models.
5Chapter 2
Emotion Analytics and Related Works
2.1 Evolution of Emotion Analytics
In The Expression of the Emotions in Man and Animals (1872), Charles Darwin
studied the consistency and inconsistency of emotions in human beings and animals.
According to Darwin, emotion expressions can link human to the past of the species and
the infancy. This argument has inspired several researches from fields such biology,
psychology, and cognitive science to conduct studies on emotion expressions.
Even though the emotion-related issues had been hotly discussed by scholars
from different fields, they have not attracted the attention from computer scientisis until
recent years. According to Oatley et al. [54]–psychologists–and Cowie et al. [21]–
computer scientists, emotional states can be observed in different categories, moods or
emotions, which are related to time. As the top part of Figure 2.1 shows, emotions are
short lived, while moods are more continuous and emotional traits are more permanent.
For instance, we can be aware of others’emotional states for a few sustained minutes
and conclude that somebody is in a good or bad mood from observations during several
Figure 2.1 Temporal Correlations for Emotions and Texts.
7On the other hand, efforts of analyzing emotions mainly come from
conversational applications [3] and other creative applications. Becker et al. [1]
directed a robot agent to react with emotions. Bernhaupt et al. [4] applied emotion
model in game animation while Shugrina and Betke [64] applied emotion model in
artworks. Liu et al. [44] used emotion models to predict sales.
2.2 Emotion-Related Works on Internet Media
In recent studies on researches on mood or emotion classification problems, blog data
that provides both training and evaluation materials has been used through various
classification methods with different levels of word segments. Mishne [51] pioneered
to use mood taggings in LiveJournal articles to train a mood classifier on
document-level using Support Vector Machines (SVM, Cortes and Vapnik [20]), while
LiveJournal provided blog authors with a special option by choosing their “current
mood”when posting articles. The published articles are regarded as corpora with
ground truths (the mood tags) and continuously motivate Mishne and de Rijke [52] to
identify the intensity of community mood during some given time intervals. Jung et al.
[30] likewise focused on the mood classification problem in LiveJournal.
As mentioned, while providing articles with emotional state taggings, LiveJournal
allow bloggers to choose a special symbol (emoticon) representing the mood. An
emoticon, emotion icon, is a graphic symbol of emotions. Computer-based emoticons
are originated from a sequence of ASCII characters and used to show how people feel
during communication. The short strings simulating facial expressions convey
people’s emotions. Face representations help people make expressions vivid and
evolve into different forms. Even in purely textual forms, these emotional symbols are
shown to be good indications of people’sinternal emotional states.
9random field (CRF; Lafferty et al. [35]) machine learning techniques. The emotion
classifiers are trained at the sentence level and applied to the document level. Their
methods also determine an emotion category by taking the context of a sentence into
account. Their experiments show that CRF classifiers outperform SVM classifiers.
When applying emotion classification to a blog at the document level, the emotion of
the last sentence in a document plays an important role in determining the overall
emotion. By take these classifiers as the analyzing kernel, Yang et al. [78] further
introduce the application of emotion analysis from both the writer’s and reader’s 
perspectives. They tackle the problem by exploiting the emotional information
contained in an online writer-emotion corpus and an online reader-emotion corpus.
The relationship between writer and reader emotions are discussed in their works.
2.2.1 Comparisons among Researches
In Section 2.1, we describe the temporal correlations for emotions and texts. We can
map the coverage of most researches on textual emotion analysis to this diagram. For
those works on emotion analysis from computational linguistics perspectives, as
referenced in Section 2.1, emotional expressions are analyzed at the word level and the
(a) (b)
(c)
Figure 2.2 Application Range for Emotion Classification Tasks.
11
Chapter 3
Emotion Analysis from Blogosphere
Blog corpora with user taggings, such as the bloggers’wordings including emotional
expressions, enabled emotion classification to go supervised: the number of supervised
taggings increases in proportional to the published number of blog posts. The
emotion-interpreting capabilities of traditional text corpora are limited, however, and
blog corpora provide the icon-attaching services that enable emotional expressions to be
created and displayed. These attached icons are referred to in this dissertation as the
emoticons. In other words, blog corpora provide huge colection on bloggers’ 
wordings with emotion icons. During composing the posts, bloggers can particularly
insert these icons to express their emotions. In such way, we can further postulate that
some words will particularly attribute human emotions in context surrounded by
emotion icons.
This dissertation aims to analyze the emotions of blog authors while composing
the posts. However, the physical and mental states of the blog authors are hard to
evaluate. Physical evaluations of biological signals are effort-consuming and usually
not well suited for sampling from internet users and mental evaluations need additional
user survey techniques. In information and language research fields, the evaluation
metric is typically based on emotion categories proposed by the psychologists. Such
evaluations are driven by enumerable emotion categories such as happy, angry, sad, joy,
etc., or measurable sentiment degrees such as positive, negative and neutral. Hence,
the emotion understanding problem can therefore be treated as a classification problem
and be dealt with classification algorithms.
There are two kinds of classification algorithms, rule-based and learning-based.
13
that we can draw evaluations (see Section 3.5) about how to best incorporate tagging
data in automatic emotion classification systems. We first define four sub tasks for the
classification problem as follows:
1. Given emotional expressions with both the text parts and the emotion
taggings, mine the associations between text vocabularies and emotion
meanings using statistical methods (defined in Section 3.3 and further
explored in Chapter 5).
2. Given emotional expressions with only text parts, predict the emotions using
machine learning models (defined in Section 3.4 and further explored in
Chapter 6).
3. Collect ground truths (defined in Section 3.2) to compare against the
prediction results.
4. Compare the results produced by the classification models with the ground
truths, using an evaluation metrics (defined in Section 3.5).
3.1.1 Problem in Symbol Definition
We summarize the problem solving process with symbols in this section. We aim to
mine the associations between text vocabularies and emotion meanings.
Basic Definition
Suppose there are m emotion senses and n vocabulary words as:
e = {e1, e2, e3,…, em}, and
w = {w1, w2, w3,…, wn} (3-1)
An emotion lexicon construction method first collects all words w from the blog corpora.
An emotion sense ei (1≦i≦m) associates with the word wj (1≦j≦n) according to its
15
That is, when s sentences are given at once, the corresponding emotions will be returned
at the same time.
3.2 Ground Truths
Bloggers use (raw) text, and if necessary, emoticons (taggings), to express their emotion.
To extract the knowledge automatically and computationally, we need first to clarify
that whether the appearance of an emoticon is an emotion indicator to a nearby word, a
sentence, or a document. Because people can insert the emotion icons into any
position of the sentence on composing a sentence, we postulate that the emoticon is an
indicator of a sentence. So wherever the emoticon appears in the sentence, we can
particularly pick its appearance as the emotion tag of the sentence. As Table 3.1 shows,
sentence S1 indicates that the author initiate the expression of the sentence with an
emoticon E1, sentence S2 indicates that the author take a tiny break of compositing the
sentence with an emoticon E2 and then finish the sentence, and sentence S3 indicates
that the author concludes the sentence in an emoticon E3. Each of all three cases can
be extracted with a vocabulary set and a corresponding emotion tag. These extracted
tags are regarded as ground truths for identifying the emotions of the emotional
expressions. For example, the ground truth of the sentence S1 is assigned as E1 and
tag (S1) denotes the assignment.
Table 3.1 Extracting Tags from Emotional Expressions.
Sentence Emotional Expressions Extractions
(S1) E1, t11, t12, …, t1p1 v(S1)= t11…t1p1, tag(S1) = E1
(S2) t21, t22,…, t2c, E2, t2d,…, t2p2 v(S2)= t21…t2p2, tag(S2) = E2
(S3) t31, t32, …, t3p3, E3 v(S3)= t31…t3p3, tag(S3) = E3
17
these terms can be collected from the corpora, statistical techniques can be used to
verify the phenomenon by showing the collocation strength between “powerful and
company”is larger then that between“strong and company”.
An implementation of collocation tests is to test whether a bigram w1w2 is a
collocation with a statistical score. In our researches, we apply the method while the
collocation strength is calculated on the relation of a vocabulary word w and an emotion
sense e. To make the application possible, by referencing the extracted tags and
vocabulary sets in Table 3.1 (Section 3.3), we further enumerate all possible collocation
pairs from the sentence extraction as Table 3.2 shows. After transforming the
extracted sentences to collocation enumerations, a newly formed dataset are used to
compute the statistics of words, emotions and word-emotion pairs, and these statistics
can be used to perform the collocation tests.
The collocation test methods can be applied to mine the relations between
candidate words and emotions. Furthermore, an emotion lexicon can be extracted by
collecting the words that are highly collocated with the emotions. While traditional
lexicon list words with possible meanings (senses), the main function of extracted
emotion lexicon is to provide words with their emotion senses. Details of collocation
test methods and the lexicon building task will be covered in Chapter 5.
Table 3.2 Enumerating Collocations from Sentence Exactions.
Sentence Sentence Extractions Collocation Pairs
(S1) v(S1)= t11…t1p1, tag(S1) = E1 cp(S1)={<t11,E1>…<t1p1,E3>}
(S2) v(S2)= t21…t2p2, tag(S2) = E2 cp(S2)={<t21,E1>…<t2p2,E3>}
(S3) v(S3)= t31…t3p3, tag(S3) = E3 cp(S3)={<t31,E1>…<t3p3,E3>}
19
3.4.1 Naïve Bayes Model
As left part of Figure 3.1, if the distribution of emotion is not bounded, then we can
only predict an emotion after composing the sentence, then the probability for assigning
emotion e given a sentence s is
)(/)|()()|(
1 k
sPefPePseP
K
k , (3-10)
where a best predicted emotion is defined as
 Kk
ee
efPePsePe
1 k
)|()(maxarg)|(maxargˆ , (3-11)
while the probability of s is omitted because the given sentence s is the same for every
candidate emotion. This forms a Naïve Bayes (NB) model for predicting the emotion
of a sentence.
3.4.2 Maximum Entropy (Logistic Regression) Model
The middle part for Figure 3.1 illustrates that the distribution model of the emotions is
considered as well. If it is guaranteed that a uniform distribution exists and has the
maximum entropy [48][53][56], then the distribution for assigning emotion e given a
sentence s is
)),(exp(
)(
1
)|(
1 kk Kk esfsZseP  (3-12)
where ),(k esf is a feature function on obtaining a relation between sentence s and
emotion e with the feature k, k is an estimated parameters and )(sZ is the
normalization factor while
 
e
K
k
esfsZ )),(exp()(
1 kk
 . (3-13)
3.4.3 Conditional Random Fields
The right part for Figure 3.1 illustrate that the distribution model of the emotions is
21
3.5 Evaluation Metric and Result Transformation
We propose evaluation metric in this section for exploring which model is good at the
text classification task on incorporating the blog tagging materials for the emotion
classification problem. Traditionally, precision, recall and F-Score are used to
evaluate a model’s prediction capabilities.
3.5.1 Basic Evaluation Metric
Suppose a total number of n testing instances are selected to evaluate a model, then the
precision is typically defined as the number of successfully classified instances divided
by the number of classified instances, recall is the number of successfully classified
instances divided by the total number of instances, and F-Score is calculated as:
recallprecesion
recallprecision
ScroeF

 2 . (3-9)
3.5.2 Result Space Transformation
In some cases, we do not assert that the ground truths is the best way to represent the
true emotions of the bloggers — indeed we can never know the real feeling of all
attendees in a social blogging network. For instance, if some emotion taggings is
aggregated to represent an abstracted emotion, we need first to transfer the ground truths
into another domain of emotions (we call it sentiment for distinction’ssake). In such
cases, we design that the global sentiment degree is derived from of local expressions’
emotions. To make this treatment possible, we first introduce Russell’s proposal [60]
on representing emotional information with a two-dimensional graph. On Russell's
graph, the horizontal axis represents the valence level, and the vertical axis represents
the arousal level. Valence level is defined as the polarity of an emotion (i.e., positive
or negative). For example, a positive emotion such as happiness would have a positive
23
2
1
)(
xhappyDegree
, (sentiment degree 1)
2
1)(
22 yx
neutralDegree

, (sentiment degree 2)
22
)1()1(
1)(
22 yx
angryDegree

, (sentiment degree 3)
22
)1()1(
1)(
22  yxsadDegree
, (sentiment degree 4)
while a real value for each sentiment category is calculated within the range between
zero (not associated at all) to one (completely associated).
3.5.3 Advanced Evaluation Metric
Suppose a total number of n testing instances are selected, then the quadrant precision
(QP) is defined as the number of successfully quadrant-classified instances divided by
the number of classified instances, quadrant recall (QR) is the number of successfully
quadrant-classified instances divided by the total number of instances, and quadrant
F-Score (QF) is calculated as:
QRQP
QRQP
QF

2 , (3-9)
while a successfully quadrant-classified instance means the prediction result for the
instance resides at the same emotion space quadrant as the ground truth resides at.
3.6 Summarization
This chapter introduces our base framework for emotion analysis on blog materials.
Blog users collaboratively contribute the emotion tags with their emotional expressions.
These tagged expressions form a valuable corpus and benefit the model learning on
25
Chapter 4
Blogosphere and the Analyzing Dataset
In this chapter, we firstly describe the concept blog and the blog posting structure.
Then we demonstrate how the emotional expressions can be extracted from the blog
posts and introduce the blog corpora for the emotion analyzing tasks. The corpora are
the fundamental materials for the lexicon building and emotion classifying tasks that are
discussed in later chapters.
With the rapid emergence of web innovations, people are continuously improving
their ways of processing information. In the early years of the 21st century, people use
web to know about the most up-to-date news, travel and life information, investment
advises, work opportunities and so on. In such cases, they are the readers. In the
recent years, web users have begun to create contents such as blogs, photo albums, and
video clips and share them with other members in the internet community. In these
cases, they are both readers and authors.
To fulfill the information-reading demands, content sites (e.g., nytimes.com and
cnn.com) and web portals (e.g., Yahoo!1 and Google2) appear. They directly compete
with each other in attracting the attention of potential consumers. To provide a
creation space, blog sites (e.g., Blogger 3 ), photo-sharing sites (e.g., Wretch 4 ),
video-sharing sites (e.g., YouTube5) emerge as powerful value-added platforms. These
sites are referred to as social media, different from the mass media such as online news
1 http://www.yahoo.com/
2 http://www.google.com/
3 http://www.blogger.com/
4 http://www.wretch.cc/
5 http://www.youtube.com/
27
4.1.1 Blog Post Structure
Blog posts are typically maintained by the web servers companied with database
systems while the mission of database systems is to keep the static (raw) posting data
robustly and the role of the web servers is to dynamically display the bloggers' writings
as creative as possible. The creativeness is revealed by the fancy layout on presenting
a article and its decoration images. A blogger need not to care about the details of the
underlying information systems and publish his work with simply some
word-processing and mouse-clicking efforts.
In perspective of data analysis, blog posts provide many valuable and structural
information. As Figure 4.1 shows, besides the main constituents of a blog post is its
title and content while the published time will be automatically attached. Before the
publishing action, a blogger can also assign a category to the post, which can help
manage the articles as files. Because a blog post is naturally a web page, any part of
the post content is allowed to be a hyperlink. Being a member of social media, blog is
capable of commentary posting, trackback referencing and friend list-rolling, with
Figure 4.1 Blog Post Structure.
29
Bloggers can post expressions on blogs in very characteristic and conversational way.
They may not follow the formal writing style to express emotional states when they
have strong feelings such as happy, angry, sad, or excited. In case when they post with
pure text editing function on Blogger, they can insert printable characters, such as “:-)”
(happy) and“:-(“(sad). In other case when they post on Yahoo! Kimo Blog, they can
use emoticons. Figure 4.2 demonstrates two samples of Yahoo! Kimo blogger’s posts
using emoticons. For instance, the transcription of the first article is as following (the
English translations are given inside parentheses):
Tom so crazy but I'm so happy
2006/10/30 22:37
今天跟你約吃飯 不知為什麼特別緊張
(I had a meal with you today. Don't know why I was so nervous.)
也許因為一陣子沒見吧
(Maybe it's because we hadn't seen each other for a long time.)
謝謝你請我吃飯 還送我禮物
(Thank you for treating me and giving me a present.)
雖然一直叫你不要送我東西
(Although I told you not to give me anything.)
但收到的時候還是很開心
(But I was very happy receiving it.)
當打開禮物的時候 整個傻眼
(When I opened the gift, I was astonished.)
居然送我 iPod 太誇張了
(You gave me an iPod. It's so unbelievable.)
Tom so crazy but I'm so happy
In this example, we find that the blogger attaches emoticons to several sentences.
From these emotion-expressed sentences, the readers can feel that the author was very
happy receiving an iPod as a gift. We treat these icons as tags introduced into text
expressions to conveybloggers’emotions. These expressions provide tagged instances
31
insert the corresponding text code (as shown in the second columns of Table 4.1) and
the blog site will automatically transform it as an emoticon10. The usage of emoticons
is completely optional. A single blog post can have as many emoticons as its writer
wishes.
We collect blog articles from July 1, 2006 to July 31, 2007. We use articles from
July, 2006 to June, 2007 as the training dataset and the posts in July, 2007 as the testing
dataset. The total number of blog posts for analysis is 18,792,918. Table 3.1 shows
the statistics of each set. The number of training articles is about eight times of the
number of testing articles. We further examine the emotion constituents. On average,
15.21% of all posts contain at least one sentence tagged with emoticons. The tagged
instances form the training and the testing datasets. We find that the average length of
tagged posts, 400 characters, is shorter than that of untagged posts, 630 characters. It
implies that people use emoticons to replace certain portions of their text contents to
make their articles more succinct.
10 This kind of transformation can be also found in modern mobile message sending systems.
Table 4.2 Statistics of the Blog Datasets.
Dataset # of articles
# of tagged
articles
% of tagged
articles
Average length of
untagged articles
Average length of
tagged articles
*07-09 ('06) 3,169,679 485,499 15.32% 614 characters 374 characters
*10-12 ('06) 4,116,066 669,224 16.26% 618 characters 383 characters
*01-03 ('07) 4,186,287 646,312 15.44% 646 characters 407 characters
*04-06 ('07) 5,312,966 779,637 14.67% 635 characters 416 characters
*Training 16,784,998 2,580,672 15.37% 630 characters 397 characters
+July ('07)
+Testing
2,007,920 277,449 13.82% 631 characters 428 characters
All 18,792,918 2,858,121 15.21% 630 characters 400 characters
33
4.2.2 Corpus Observations–by Categories
Each blog post belongs to exactly one of sixteen categories (or not assigned) defined by
Yahoo! Kimo Blog. The category of a blog post is chosen by the post writer based on
the post’s subject. Some of the categories are Moms and Babies, Hobbies, and Travel.
Yahoo! requires a blogger manually select a category before submitting a post. We
separate the blog posts into seventeen groups according to their blog categories. Table
3.2 shows the number blog posts belonging to each blog category. The largest
category group of posts is Creative Writing, which occupies 37.5%. The smallest
Table 4.3 Statistics of Blog Posts Belonging to Each Category.
Category # of articles (posts)
# of
tagged posts
% of
tagged posts
Avg. length of
untagged posts
Avg. length of
tagged posts
(unassigned) 3,782,071 (20.1%) 619,504 16.38% 430 chars 271 chars
Moms and Babies 334,525 (1.8%) 117,630 35.16% 591 chars 366 chars
Financial 381,425 (2.0%) 12,856 3.37% 1,003 chars 648 chars
Club 249,036 (1.3%) 30,862 12.39% 938 chars 494 chars
Audio-Visual 1,220,827 (6.5%) 66,990 5.49% 516 chars 557 chars
Sports 219,211 (1.2%) 22,538 10.28% 667 chars 553 chars
Travel 558,475 (3.0%) 141,900 25.41% 620 chars 585 chars
Political 195,709 (1.0%) 16,200 8.28% 1,172 chars 813 chars
Image Creation 502,406 (2.7%) 69,698 13.87% 326 chars 356 chars
Art Review 357,520 (1.9%) 30,898 8.64% 1,072 chars 661 chars
Hobbies 1,509,630 (8.0%) 200,526 13.28% 679 chars 403 chars
Life Style 1,181,203 (6.3%) 124,292 10.52% 926 chars 548 chars
Creative Writing 7,048,902 (37.5%) 1,207,427 17.13% 588 chars 386 chars
Consumer Electronics 244,733 (1.3%) 23,529 9.61% 1,033 chars 862 chars
Pets 231,536 (1.2%) 84,479 36.49% 441 chars 385 chars
Personal Growth 631,935 (3.4%) 78,789 12.47% 955 chars 538 chars
Science 143,774 (0.8%) 10,003 6.96% 1,228 chars 725 chars
Total 18,792,918 (100%) 2,858,121 15.21% 630 chars 400 chars
35
Chapter 5
Emotion Lexicon Building
Lexical resources are indispensable for an analysis of textual emotions. As a general
lexicon resource such as WordNet11 is maintained by laborious efforts but can benefit
many language processing tasks, in this chapter, we plan to propose a fundamental
emotion lexicon for emotion analyzing task. In addition, the emotion lexicon will
automatically be built when we mine the emotion-related vocabularies from emotional
expressions collaboratively annotated by internet bloggers.
Following sections will cover the studies on lexicon semantics issues, methods
for building the emotion lexicon, evaluations and observations on the building statistics,
and descriptions for a release of the emotion lexicon.
5.1 Lexical Semantics and Related Lexicons
Lexical semantics12 [57] is part of linguistic semantics and is important to many
methodologies on language processing. Every language processing task replies on
previous collected lexical knowledge to continue the understanding process for any
textual unit that is composed by the underlying vocabularies. Traditional lexical
semantics-related works make efforts on forming different kinds of lexicons
(dictionaries) and machine readable dictionaries [11] (MRD) that are particularly
referencing those collected lexicons archived in digital forms. For example, WordNet
[89] is the most famous MRD and collects conceptual definitions, senses (synonyms),
and semantic relations for its lexical entries. Several researches [38] had analyzed on
11 http://wordnet.princeton.edu/
12 http://en.wikipedia.org/wiki/Lexical_semantics
37
calculated under two different hypotheses, a null hypothesis and an alternative
hypothesis. We apply the likelihood ratio test to our problem by first giving two
alternative hypotheses when the occurrence frequency of an emotion sense e with a
vocabulary word w is collected from the observed copus:
Null hypothesis , H0: P (w | e) = p0 = P (w | ¬e), and
Alternative hypothesis, Ha: P (w | e) = p1≠ p2 = P (w | ¬e),
where the null hypothesis indicates that the occurrence of word w is independent of the
occurrence of emotion sense e and the alternative hypothesis confirms the dependence.
Three probability value p0, p1, and p2 can be extracted from the blog corpora,
,,, 000
e
eww
e
eww
CN
CC
p
C
C
p
N
C
p

 (5-1)
where Ce and Cw are respectively the occurrence count of e and w, Cew is the number of
occurrences when e meets w, and N is the total number of observed occurrences.
These probabilities and counts are parameters for calculating log of the likelihood ratio
between Hypothesis 1 and Hypothesis 2:
logλ = log L(H1) / log L(H2)
= log L(Cew, Ce, p) + log L(Cw - Cew, N - Ce, p)
- log L(Cew, Ce, p1) - log L(Cw - Cew, N - Ce, p2), (5-2)
where we take our probability cases as binomial distributions and set the likelihood
value as
L(c, n, p) = pc (1–p) n-c. (5-3)
Then an adaptive likelihood value -2logλ, referenced as a likelihood value, can be
judged with a critical value 7.88 at a 99.5% confidence level, which means if a
39
automatically in phase 2 and phase 3. In phase 2 the training dataset continue to
provide instances for training classifiers that employ mined lexicon as features. The
testing dataset is used only to evaluate the classifier in phase 3. A good evaluation
result will confirm the lexicon and hence verify a corresponding mining method is good.
The classification kernel is SVM [20]. We use a SVM tool, LIBSVM [24], to train a
polarity classifier on collection of blog post expressions using 40 or 200 lexicon entries
as features.
Table 5.2 shows the evaluation results by comparing the performance of three
collocation test methods. We find a likelihood ratio test can introduce better
classification accuracy in 40-feature case but perform worse with 200 features. A
Person’s chi-square test can apply the most in both 40-feature and 200-feature cases.
Figure 5.2 shows samples of the mined lexicon. A word entry of a lexicon may
contain several emotion senses. They are ordered by the collocation strength co. In
Figure 5.1 Evaluation Framework for Lexicon Building Methods.
Table 5.1 Evaluation on Collocation Test Methods.
40 features 200 features
Accuracy Application # Accuracy Application #
Likelihood Ratio Test 86.52% 36,444 78.61% 78,487
Person’s Chi-square Test 79.70% 61,976 85.42% 103,336
PMI 81.10% 56,096 84.23% 97,843
41
onomatopoeia, occur more often in a conversation or dialogue than in a formal sentence,
in this first observation, we find it is critical to adopt these words of sounds as features
to analyze blog corpora and it maybe because of people also use these words to express
their emotional states.
Table 5.3 examines further the top 20 bi-character words collocated with the most
popular emoticon “laughing”.  We find another sound of laughter “heh heh” is also 
collocated and the morpheme “笑” (xiao4), to laugh, appears in six cases.  The 
meaning column indicates either one of these six expressions can not be directly
Table 5.2 Top 10 Collocated Emoticons and Words.
Icon Description Word Meaning Count cew Likelihood Value
laughing 哈哈 hah hah 5,706 10,247.85
love struck 幸福 happiness 3,557 5,696.94
blushing 害羞 shy 1,189 5,585.97
angry 生氣 angry 1,691 5,364.52
angry 氣死 angry to death 1,115 5,296.55
crying 嗚嗚 wuh wuh 1,346 4,867.55
laughing 好笑 funny 1,893 4,457.10
crying 難過 sad 1,992 4,188.56
love struck 可愛 lovely 3,083 3,782.56
angry 討厭 dislike 1,564 3,324.29
Table 5.3Top 20 “laughing” Colocated Words.
Word Meaning Likelihood value Word Meaning Likelihood value
哈哈 hah hah 10,247.8 終於 finally 529.1
好笑 very funny 4,457.1 學生 student 472.1
笑死 laugh to death 1,982.3 希望 hope 445.8
開心 joyful 1,480.3 老師 teacher 430.5
爆笑 so funny 1,190.7 討厭 dislike 373.4
呵呵 heh heh 1,186.4 笑話 joke 349.7
大笑 big laugh 1,130.6 幸福 happiness 339.1
搞笑 make funny 720.7 農場 farm 320.7
狂笑 laugh wildly 663.0 難過 sad 300.8
高興 happy 576.4 不過 nevertheless 282.8
43
categories. With the observation we can associate each word with the emoticon with a
highest likelihood value.
5.5 A Release Version of Emotion Lexicon
Previous discussions in this chapter have verified the feasibilities of building the
emotion lexicon with collocation test methods. In this section, we present a practical
walkthrough to release a emotion lexicon. We sketch the walkthrough with a
algorithm in following pseudo codes.
Algorithm 1
01 Collect all sentence with emotion tags from the corpus.
02 Segment the sentences with the Stanford Chinese Word Segmenter16.
03 Enumerate the {emotion (e), word (w)} pairs for each segmented sentences.
04 Count the frequencies of each member in sets {e}, {w} and {e, w}, and a total # N.
05 For each paired member in {e,w}
06 begin
06 if w is in the stop-word-list then it skips.
07 if f(e,w) / f(e) <αthen it skips.
08 Calculate the likelihood ratio logλwith <f(w),f(e),f(e,w),N> by (5.2).
09 if -2logλ< 7.88 then it skips.
10 Insert the <w,e> pair as an sense into the Emotion Lexicon.
11 end
An Chinese Word Segmenter [12] and a stop-word-list (see Appendix A.1) are required
16 http://nlp.stanford.edu/software/segmenter.shtml
45
Chapter 6
Emotion Classification
In the previous chapter, we have described the methods used to analyze emotions
hidden in blogs. In this chapter, we will report some interesting and significant results
of our analysis. Section 6.1 will firstly discuss issues of traditional text classification.
In Section 6.2, details on the design of binary classifiers used in determing the basic
emotion will be elaborated. In Section 6.3, we will summarize the ways used in our
classifications of emotions, setting up a pratical system framework. In Section 6.4, we
propose ways to evaluate the system. Section 6.5 will then report the experimental
results and applications of the system.
6.1 From Text Classification to Emotion Classification
In terms of ways in classifying texts, the traditional way17 [61] is to assign a textual
passage (meaningful textual range) to one or more categories (classes), based on its
content or context. It is an essential part of modern information system and leads to
many applications [19][25][47][69]. There are two kinds of text classification tasks.
One is the supervised text classification where the correct classification (answer) for the
passage is available in the classification-training phase. The other one is the
unsupervised text classification where the training of the classification is done without
finding reference to the correct answer. A classification task does not necessarily
belong to either kind. For example, semi-supervised text classifications [9] apply on
training cases with both the unlabeled and partially-labeled data.
As for classifying emotions, the task is typically treated as a text castigation task
17 http://en.wikipedia.org/wiki/Document_classification
47
In this way, we obtain total number of 780402 C binary classifiers. Table 6.1
shows the performance of classifiers relevant to the top 16 frequently-used emoticons.
The upper right triangle (i.e., the combinations right to the diagonal line) reports the
testing accuracy and the lower left triangle (i.e., the combinations left to the diagonal
line) reports the accuracy of the baseline. In Table 6.1, among these 120162 C
classifiers, only one experiment on “crying vs. sad” and four experiments associated
with “blinking” emoticon perform worse than the baseline, marked by the gray grids.
All these five cases happen to be emoticons conveying the similar emotions. Because
of this, we further look at some examples associated with the “laughing” emoticon, 
which conveys a positive emotion. The results shows that “laughing vs. grinning” 
classifier, i.e., both stand for a joyful face, achieves only a net 3.3% improvement.
However, the “laughing vs. angry” classifier, i.e., the two emoticons are contrast to each
Table 6.1 Binary Emoticon Classifier Performance.
Acc.
Baseline
laughing grinning love crying happy rose surprise tongue sad angry applause praying worried blushing confuse blinking
laughing 59.8% 74.8% 77.3% 69.6% 76.6% 77.9% 66.8% 80.3% 80.2% 78.7% 81.8% 79.3% 74.5% 81.2% 78.9%
big grin 56.5% 69.1% 77.4% 60.8% 70.6% 76.6% 62.4% 77.8% 80.4% 73.1% 76.4% 77.3% 69.3% 77.9% 73.1%
love 51.9% 54.7% 83.4% 66.2% 70.9% 84.6% 75.5% 85.7% 87.2% 77.7% 80.5% 85.7% 72.9% 84.5% 77.4%
crying 54.4% 52.1% 52.6% 79.0% 79.1% 74.3% 73.8% 69.5% 75.4% 80.9% 80.1% 70.3% 79.5% 78.1% 82.2%
happy 65.8% 59.7% 64.1% 61.7% 62.9% 76.1% 65.4% 76.6% 81.2% 66.9% 72.5% 77.2% 64.8% 73.7% 65.0%
rose 71.9% 66.3% 70.4% 68.2% 57.1% 78.3% 69.3% 78.1% 81.1% 67.3% 71.8% 76.6% 66.6% 75.0% 66.0%
surprise 73.1% 67.6% 71.6% 69.4% 58.5% 51.4% 69.4% 66.6% 72.5% 73.1% 77.5% 62.7% 74.8% 64.7% 74.6%
tongue 66.3% 60.2% 64.6% 62.2% 50.5% 56.6% 58.0% 70.0% 76.9% 69.5% 75.8% 69.8% 62.9% 70.8% 66.6%
sad 73.5% 68.1% 72.0% 69.9% 59.0% 51.9% 50.5% 58.5% 73.0% 75.1% 75.8% 56.4% 75.8% 67.0% 75.8%
angry 67.8% 61.8% 66.1% 63.8% 52.2% 54.9% 56.3% 51.7% 56.9% 80.6% 82.3% 72.2% 81.1% 74.1% 81.2%
applause 77.6% 72.7% 76.3% 74.4% 64.3% 57.5% 56.1% 63.8% 55.6% 62.2% 75.4% 75.1% 67.1% 69.4% 59.7%
praying 68.3% 62.3% 66.7% 64.3% 52.8% 54.4% 55.8% 52.2% 56.3% 50.6% 61.7% 75.5% 76.4% 76.4% 74.8%
worried 73.4% 68.0% 71.9% 69.8% 58.9% 51.9% 50.4% 58.4% 50.1% 56.8% 55.7% 56.2% 75.7% 66.7% 76.3%
blush 71.1% 65.4% 69.5% 67.3% 56.1% 51.1% 52.5% 55.5% 53.0% 53.9% 58.5% 53.3% 52.9% 72.0% 62.9%
confuse 79.3% 74.6% 78.0% 76.2% 66.5% 59.9% 58.5% 66.0% 58.0% 64.5% 52.5% 64.0% 58.1% 60.9% 69.4%
blinking 79.3% 74.6% 78.0% 76.2% 66.5% 59.9% 58.5% 66.0% 58.0% 64.5% 52.5% 64.0% 58.1% 60.9% 50.0%
49
The first column in Table 6.4 shows the emoticon categories in a frequently-used
order. The red grid marks the negative emoticon categories. The boldfaced grid
number indicates where a right classification is supposed to go. The grid with a
maximum number of classification results corresponding to a positive is marked as gray.
The grid with a maximum number of classification results corresponding to a negative
emoticon is marked as red. In Table 6.4 we can see that expressions with positive
emoticons are mostlymisclassified to “love struck”.  Only expressions with “laughing 
and “praying” emoticons tend to be precisely classified. With the total number as
shown in the bottom row, we have found that the frequently used emoticons (e.g.,
“happy” and “rose”) get harder votes than those which are infrequently used (e.g.,
“angry” and “praying”.  We may conjecture the phenomenon from the reports of 
binary classifiers performance because binary classifiers associated with “angry” and 
“praying” perform over 81% (Table 6.3), beter than “happy” and “rose” that are under 
78% (Table 6.3). It motivates this research to improve the overal binary classifiers’ 
performance and hence raise enhance multiple classifiers in following sections.
6.3 A System of Classifying Emotions
In the previous sections, some significant results have been reported. In this section,
we will introduce the emotion classification system. Figure 6.1 depicts the system
where the right-center part illustrates the emotion analysis kernel. We start the
emotion analysis from the lexicon level. Then we proceed to use lexical information
to classify the emotion expressions. Blog posts are collected and segmented,
providing the training and the testing datasets for analysis. Lexicon mining method (as
discussed in Chapter 5) learns an emotion lexicon, which forms the fundamental
features for emotion classifiers. Machine learning-based classifiers, such as support
51
Expressions with emoticons in top-right are regarded as more positive and energetic and
expressions with emoticons in bottom-left side are more negative and silent. An
emotion bipolarity classifier uses the right side as positive and the left side as negative.
Each of the 36 emoticons is assigned to one of the four quadrants of the graph. Four of
the forty emoticons are not assigned to any quadrant, because the emotions they convey
are imprecise.
6.4 Evaluations on the Classification System
The major challenge in our framework is to increase the classification performance.
Table 6.5 shows the setup options used in our experiments. There are two kinds of
classifiers to be verified, where SVM are used widely from general-purpose
classification and CRF are specialized in sequence-labeling problems. We adopt the
LIBSVM19 and the MALLET20 CRF implementation toolkits. The second verified
factor is about the toughness of the problem. A coarser-classification task deals with
the emotion-bipolarity problem which partitions the instances into positive or negative
ones. A finer-classification tries to project the evaluated expressions into the
arousal-valence space, where four labels (positive-energetic, positive-silent,
negative-energetic, and negative-silent) are used. The last checked option for
modeling the classifier is about the feature size. A bigger number means more
vocabularies are used as features to model the classifiers. Despite of the experiment
setup the classifiers, we also examine the influence of corpora training size. Blog
articles spanning from one, two, and four seasons are used.
The classifiers are applied on the testing datasets. We report evaluation metrics,
19 http://www.csie.ntu.edu.tw/~cjlin/libsvm/
20 http://mallet.cs.umass.edu/
53
The problem of arousal-valence space classification is harder than bipolarity
classification because more categories are used. As shown in Table 6.7, the average
performance drops about 25%. Nevertheless, introduction of more feature words
benefits both the SVM and CRF classification performance. With finer emotion
categories, CRF still outperforms SVM classifiers in all cases. CRF can achieve better
than SVM in all measurements while still maintaining precisions over 54%.
Table 6.5 Bipolarity Classification Performance.
Training Volume 1 season 2 seasons 4 seasons
Exp. Setup P R F P R F P R F
SVM-C2-T100 76.55% 44.56% 56.33% 76.68% 44.64% 56.43% 76.54% 44.56% 56.33%
SVM-C2-T200 75.59% 63.31% 68.91% 75.93% 63.60% 69.22% 75.81% 63.50% 69.11%
SVM-C2-T300 75.45% 72.63% 74.01% 75.94% 73.11% 74.50% 75.94% 73.11% 74.50%
SVM-C2-T400 75.41% 78.47% 76.91% 75.69% 78.76% 77.20% 75.74% 78.82% 77.25%
SVM-C2-T500 75.71% 80.91% 78.22% 75.78% 80.99% 78.30% 75.73% 80.93% 78.24%
SVM-C2-T600 75.85% 82.21% 78.90% 76.19% 82.59% 79.26% 75.90% 82.27% 78.96%
CRF-C2-T100 77.37% 45.04% 56.93% 77.09% 44.88% 56.73% 77.24% 44.97% 56.84%
CRF-C2-T200 76.69% 64.23% 69.91% 76.96% 64.46% 70.15% 76.99% 64.48% 70.18%
CRF-C2-T300 76.88% 74.01% 75.42% 76.93% 74.06% 75.47% 77.05% 74.18% 75.59%
CRF-C2-T400 76.82% 79.94% 78.35% 76.92% 80.04% 78.45% 77.00% 80.13% 78.53%
CRF-C2-T500 76.99% 82.28% 79.55% 77.07% 82.36% 79.63% 77.41% 82.73% 79.98%
CRF-C2-T600 76.66% 83.10% 79.75% 77.05% 83.52% 80.16% 77.56% 84.07% 80.68%
Table 6.6 Arousal-Valence Space Classification Performance.
Training Volume 1 season 2 seasons 4 seasons
Exp. Setup P R F P R F P R F
SVM-C4-T100 42.34% 24.65% 31.16% 41.56% 24.20% 30.59% 41.33% 24.06% 30.41%
SVM-C4-T200 41.20% 34.51% 37.56% 41.42% 34.69% 37.76% 41.63% 34.87% 37.95%
SVM-C4-T300 40.37% 38.86% 39.60% 42.70% 41.10% 41.88% 42.54% 40.95% 41.73%
SVM-C4-T400 40.62% 42.27% 41.43% 42.48% 44.20% 43.32% 43.06% 44.80% 43.91%
SVM-C4-T500 40.63% 43.43% 41.98% 42.68% 45.61% 44.09% 43.20% 46.17% 44.64%
SVM-C4-T600 40.78% 44.20% 42.42% 42.92% 46.53% 44.65% 43.19% 46.82% 44.93%
CRF-C4-T100 56.82% 33.08% 41.81% 57.06% 33.22% 41.99% 57.08% 33.23% 42.00%
CRF-C4-T200 55.00% 46.07% 50.14% 55.09% 46.14% 50.22% 55.14% 46.18% 50.27%
CRF-C4-T300 54.41% 52.38% 53.38% 54.48% 52.45% 53.45% 54.62% 52.58% 53.58%
CRF-C4-T400 53.81% 56.00% 54.88% 54.26% 56.46% 55.34% 54.56% 56.77% 55.64%
CRF-C4-T500 54.16% 57.88% 55.95% 54.25% 57.98% 56.06% 54.79% 58.56% 56.61%
CRF-C4-T600 54.15% 58.70% 56.33% 54.44% 59.01% 56.63% 54.55% 59.13% 56.74%
55
Figure 6.3 shows a system flow by integrating an IR process into the emotion
analysis kernel. After relevant post posts are retrieved by the IR module, these
emotion analysis module applies on these posts and report their corresponding emotions.
Figure 6.3 System Flow for Emotion Filtering.
台灣大學 搜尋
General Info
Tab
文件摘要 #1
----------------
---------------------------
--------------
----------------
文件摘要 #2
----------------
---------------------------
--------------
----------------
文件摘要 #3
----------------
---------------------------
--------------
----------------
文件摘要 #4
----------------
---------------------------
--------------
----------------
文件摘要 #5
----------------
---------------------------
--------------
----------------
文件摘要 #6
----------------
---------------------------
--------------
----------------
文件摘要 #7
----------------
---------------------------
--------------
----------------
文件摘要 #8
----------------
---------------------------
--------------
----------------
文件摘要 #9
----------------
---------------------------
--------------
----------------
文件摘要 #10
----------------
---------------------------
--------------
----------------
(情緒過濾準則分布)
(過濾掉之文件)
(過濾掉之文件)
(使用者心情指標) 正面
情緒
Figure 6.4 Demonstration Interface for Emotion Filtering.
57
Among different media introduced by Web 2.0, the Blog constituents are the most
structured. After manipulating the blog data with emotion ground truths automatically,
the blog datasets are used as the major resource providing datasets for learning emotion
classification models. The emotion models are then used to analyze sentiments for
Web 2.0 contents.
We then apply the trained models to Web 2.0 contents and determine the
sentiments of messages extracted from the Web 2.0 materials. Because a sentiment
analyzing model is typically learnt from materials in one language but Web 2.0
materials may be written in other languages, we setup a multilingual processing step to
translate a Web 2.0 messages. In our implantation, the learning models operate on the
Chinese language and the Web 2.0 messages are in English. It follows the details of
incorporated modules.
Wikipedia Preprocessing
Wikipedia21 is a multi-lingual online encyclopedia. We can look up all meaningful
textual in this knowledge base. In our framework, the Wikipedia dataset is used in two
ways. The first way is to treat all Wikipedia entry title names as complementary
vocabularies for a segmentation module. Because the blog content are worded most
up-to-dately, the deployment of Wikipedia vocabularies can assist to overcome the
out-of-vocabulary problem in segmenting the blog articles. The second ways is to
extract the Named Entity Recognition rules from Chinese-Foreign pairs listed in the
Wikipedia.
The official Wikipedia project maintains a routine database dump procedure and
the dump data is accessible via a web interface22. In this paper, we use the 20090116
21 http://wikipedia.org/
22 http://download.wikimedia.org/
59
on the valence-arousal graph are described below. Given a global message m, let Em
be the set of tagged emoticons of local expression that composes m. Each emoticon is
associated with a two-dimensional displacement vector. Emoticons in quadrants I, II,
III, and IV have displacement vectors of (1,1), (–1,1), (–1,–1), and (1,–1), respectively.
The global coordinate of m on the valence-arousal graph is defined as
 )( )(|)(|
1
)(
mEe
elocal
mE
mglobal ,
where global(m) is the valence-arousal coordinate pair for message m, local(e) is the
displacement vector of tagged emotion e of the compositing expressing, and | E(m) | is
the cardinality of E(m). The normalizing factor |E(m)| ensures that both the valence
and arousal coordinates range from 0 to 1.
6.5.3 Summaries
We discuss the effects of different classifiers and the collaborative annotation of training
data set. First, the experiments show that CRF classifiers outperform SVM classifiers.
This means that the emotional information of nearby sentences affect each other so that
a context-aware classifier is useful. CRF has the ability to learn the transition of
emotion categories from one sentence to the next, but SVM cannot do that very well.
The category of the nearby sentence can be used as a feature in SVM, but it does not
guarantee that SVM can learn the transition relationship.
We then verify the relation between the performance and the corpus size. The
training materials are used in quarter, half and full a year. The result shows that when
more training instances are used, the learning performance raises in all CRF
experiments. The shortcoming in using SVM for this problem is that SVM seems to
suffer more from overfitting problem. As for the corpus, the annotations were made
by the authors of the blogs. An advantage of the blog corpora from our work is that it
61
Chapter 7
Applications of Emotion Models
The focus of this doctoral dissertation has been on discussing the emotion analysis from
blogosphere. More specifically, this paper focuses on the use of language and aims to
understand the emotion knowledge embedded in meaningful language units such as
words, sentences, and documents. To achieve this goal of analyzing emotions, blog
datasets, collaboratively contributed by bloggers on the web, provide a large set of
emotion-tagged text expressions useful for emotion analysis. In conducting the
emotion analysis of blogs, we have built emotion lexicon in Chapter 5 and set up a
framework of analyzing kernel in Chapter 6. In addition, how this framework can be
applied is elaborated in this chapter and the entire processes and system flows will be
summarized.
Figure 7.1 illustrates our system framework. The first objective of our system is
to automatically extract the base knowledge from two Web 2.0 representatives, the
Wikipedia and the Blog. Then we use the web knowledge to construct the emotion
analysis kernel. The top-left side of Figure 7.1 depicts this part. The dotted rectangle
symbolizes the knowledge origin of our system. The internet is known as a
frequently-updated archive of human knowledge. We can expect the update of the
internet will also facilitate this system.
We use the blog data in two ways. Firstly, we use it as the major resource
providing datasets for our emotion analysis kernel. Because the blog collects bloggers’
experiences and viewpoints during a certain period of time, we also use the dataset for
observing the emotional commentaries toward certain objectives. These commented
objectives are typically referenced as named entities. To efficiently recognize the
63
described in Section 7.1.
The emotion perception for a human on a blog article is typically about his visual
perception on the textual content, while his audio perception is idle. We implement a
Multi-Perceptive integration of emotion-related music. While a user browses a blog
post, this module suggests music to play in the same time. The detail is described in
Section 7.2.
Besides analyzing one blog post, the mentioned emotion analysis kernel can
applies on whole blogosphere articles. If all blog content is meta-attached with
analyzed emotions, we can further perform analysis on the metadata. Two ways for
using the metadata are introduced. The first one will incorporate the named entity
recognition knowledge. It will report an emotion tendency associating with a named
entity. In addition to use emotion metadata, we notice that all blog articles are
time-stamped. If the time factor is consider as well, we can observe the emotion trend
during any time span. The census and trend modules will be described in Section 7.3.
An extension of knowledge from a Multi-Perspective integration is to provide an
authoring recommendation tool. Upon selecting a lexicon for word recommendation,
the tool provides an option of ranking the lexical items by their relatedness to the words
already presenting in the text. This is done to make the recommended words fit more
naturally with the content of the text. For example, a recommendation the word
"delicious" is to instill happiness only when food is mentioned in the original text. A
system for assisting writers in prediction and generation of readers' emotions has
applications in situations where the emotional responses of readers are paramount. For
example, such a system can help advertisers to generate appropriate emotions in
consumers. The detail of the subject will be covered in Section 7.4.
65
Figure 7.3(a) shows the valence-arousal graph constructed using the entire blog
corpus. As can be seen in the figure, not all of the spaces are filled with blog post
Figure 7.3 Valence-Arousal Graphs.
(a) Moms and Babies (b) Financial (c) Clubs
(d) Political (e) Life Style (f) Creative Writing
(g) Consumer Electronics (h) Pets Legend
Figure 7.4 Smoothed Valence-Arousal Graphs.
67
in that its angry reader emotion is very prevalent. This observation reflects the
readers’strong political beliefs. The Creative Writing category generates two reader
emotions primarily, with one being positive (i.e., heartwarming) and the other being
negative (i.e., boring). This result is unsurprising, because the topics of the posts in
Creative Writing vary a lot, so we would not expect readers to lean toward a particular
emotion polarity. A similar pattern is observed for the Consumer Electronics category,
where most reader emotions are either awesome or boring. This is again reasonable,
because readers who are interested in a new product would find the product amazing. As
for those who are not interested, they will find the product boring. For the Clubs
category, most reader emotions are happy and heartwarming. This is rational, because
club activities are supposed to be fun, and readers who read about these accounts should
also feel positive. Since Life Style contains practical information, such as shopping
discounts, that is helpful to daily life, its graph naturally has an abundance of useful and
awesome reader emotions. The Pets category has plenty of awesome and
heartwarming emotions, which is logical, because pets are supposed to be fun and
lovable. So far, the reader-emotion classification results agree with the inherent
properties of the blog categories.
7.1.3 Emotion Valence Analysis
We investigate the relationship between reader emotions and the valence level further.
This is done by computing the reader-emotion distribution of the blog posts at each
valence coordinate. The results are shown in as stacked area graphs in Figure 7.5,
which have been smoothed by a 10-nearest-neighbor algorithm. More precisely, a
point’s value on the graph is the average of the point’s own value and its ten nearest
points’values. The distributions have been normalized such that the values of all
reader emotions sum to 1 at each valence coordinate.
69
negative reader emotions. That is, the total area occupied by them decreases moving
from left to right. This trend also holds for the stacked area graphs of the other eight
blog categories not shown in Figure 7.5. The observation once again shows that
positive reader emotions are more associated to the positive valence level and negative
reader emotions are more associated to the negative valence level.
7.1.4 Summary
Analyzing the valence values of the blog post points on the valence-arousal graph tells
us that reader and writer emotions agree with each other in terms of emotion polarity.
That is, positive reader emotions tend to co-occur with positive writer emotions.
Analysis on the arousal level, on the other hand, reveals less consistency in reader and
writer emotions. We also discover that the relationship between reader and writer
emotions vary according to the category of a blog post. The general trend is that the
emotion polarities of the writer and reader emotions agree with each other.
7.2 A Multi-Perceptive Integration
The Internet brings digital content to our daily life, from working needs to household
entertainment usage. Media today provide people both convenient visual and acoustic
experiencing environment with many invented multi-media equipments. Different
media equipments may be artificially combined to fill different people temporary
preferences. The key which relates to one’s preference on the selection of media
presentation in some moment is about his temporary feelings and emotions in that time.
With researches [7][13][80][90] that has invested the underlying emotions of media
format, such as music and photos, if people's emotions can be also physically detected
[28][63][83], then the media unit can promoted to some people according to their
emotion states.
71
combined to display blog content with background music. In other words, while
reading web blogs, the emotion tendency detected from an article can trigger a playing
of the music with the same emotion.
As Figure 7.6 shows, we have developed a multimedia module which help people
immerse in combination of different media, the blog posts and the music. The music's
emotion detection is according to Wu and Jeng's work [90], while the analyzed music
Figure 7.8 Demonstration of Multi-Perceptive Integration.
73
different while most of the name constituents are translated. The first part of this
module will mine the formulation rules of monolingual named entities and the
translation/transliteration rules among multilingual named entities based on
corpus-based statistically oriented methods. The mined rules specify which part of a
named entity is translated, and which part is transliterated.
A metric for dealing with the above issues is proposed in this section. The
concept is borrowed from the tfidf scheme for information retrieval to measure the
alignment of each foreign segment with possible Chinese translation segments.
Assume that N foreign segments are involved. The term frequency (tf) of a Chinese
translation segment ci corresponding to a foreign segment e represents the number of
occurrences of ci in e. The document frequency (df) of ci is the number of foreign
segments to which ci is translated. The Chinese translation segment that occurs
frequently in a specific foreign segment, but rarely in rest of the foreign segments, is
preferred. A longer Chinese segment is also preferred, so that the length of a Chinese
segment, |ci|, is also considered.
}),({ icescore )1|(|log)(}),({ 2  iii ccidfcef (7-1)
}),{(max
}),({
}),({
jj
i
i cetf
cetf
cef  (7-2)
)
)(
(log)( 2
i
i cdf
N
cidf  (7-3)
For some foreign segment e, the corresponding Chinese segment c is obtained by the
equation (7-4).
}),({maxarg i
c
cescorec
i
 (7-4)
In this way, we can produce a ranking list of pairs of <foreign segment, Chinese
segment>, which compose the multilingual keyword pairs.
75
categories Joy, Angry, Sad, and Happy are symbolized as emoticons Love-struck, Angry,
Sad, and Happy. For demonstrations, Figure 7.9 shows four sentiment trends toward
the query "馬英九" (Ying-Jeou Ma) in blog posts from June 20th to July 8th, 2007.
Generally, bloggers feel more happy and less angry about Ma. However, from June 23
to June 24, bloggers feel more sad and more angry about Ma.
Table 7.1 shows a census report on ten sampled named entities. For example,
the first two named entities are famous singing stars from a local singing tournament.
The emotion degree reports on them show that the most bloggers are feeling happy
about their excellent performance. We also find in Table 7.1 that the bloggers feel the
angriest about the Maokong Gondola. It maybe because the Maokong Gondola had
not operated smoothly and had impressed the tourists badly.
7.4 Authoring Tool
The introduction of reader emotion analysis method has encouraged us to integrate an
application on multi-perspective emotion analysis. Since written text is one of the
media by which people convey their emotions, the analysis of writer and reader
Table 7.1 Demonstration of Census Report.
Query Joy Angry Sad Happy Description
楊宗緯 12% 14% 11% 63% Singing Star
林宥嘉 14% 13% 12% 61% Singing Star
股票 7% 11% 9% 72% (Taiwan) Stock (Index)
貓空 10% 22% 19% 48% Maokong (Gondola)
纜車 11% 21% 18% 50% (Maokong) Gondola
謝長廷 7% 14% 7% 73% President Candidate
馬英九 14% 15% 10% 62% President Candidate
王建民 10% 18% 10% 62% Baseball Player
日本 14% 17% 12% 57% Japan
韓國 17% 21% 15% 48% Korea
77
method for some of the words in the blog corpus. For the ease of understanding,
words in the table have been translated from Chinese into English. In the table, we see
that a word’s reader emotion indeed changes for different combinations of valence
regions and blog categories. For example, the word “老師”(teacher) is associated
with the heartwarming reader emotion in the positive valence region of the Moms and
Babies blog category, but it is associated with the boring reader emotion in the negative
valence region of the same category. This discrepancy in the reader emotion of a word
justifies our decision to generate a separate lexicon for different combinations of
valence region and blog category.
7.4.2 An Authoring Tool for Writers
Figure 7.10 shows an example of a mother using the author tool to write an article about
her baby to share her heartwarming feeling with readers. When using the tool, the
mother first types her text into the textbox on the left portion of the user interface.
Then she clicks on the "Analyze Text" button, which tells the authoring tool to
automatically detect the emotional influence on readers; the text topic; and the writer
emotion. The results are displayed on the "Current Reader Emotion", "Text Topic" and
"Writer Emotion" fields of the interface. After that, the mother selects the desired
Table 7.2 Words in Combinations of Emotions and Blog Categories.
79
the text, which means the suggested words may appear awkward inside the current text.
To address this issue, we introduce a second ranking score which is affected by the
words already in the text.
This second ranking score is based on the mutual information of a suggested term
and all the words already presenting in the text. Mathematically, it is defined as:



Textu uwP
uPwP
TextwC
),(
)()(
log),( (7-7)
where C(w,Text) is accumulated mutual information of Text with a recommended word
w, and u is a word in Text. In this study, the probabilities P(w), P(u) and P(w,u) are
computed at the document level over the Yahoo! Kimo Blog corpus as introduced in
Section 4.2. Two words w and u co-occur if they appear within two words from each
other in a text.
The final ranking score of a lexical word w with respect to reader emotion r, text
Figure 7.10 An Authoring Tool for Writers
81
Chapter 8
Conclusions
In previous chapters, we have conducted methods for building the emotion lexicon,
training the emotion classifier, and incorporating the emotion analysis kernel into
several applications. We conclude our researches with the answers to the research
questions that was introduced in Chapter 1:
1. What kinds of emotion-related information can be extracted from blog
articles?
We have presented methods to capture the underlying knowledge between emotion tags
and the emotional expressions, since they can be collected simultaneously from the
blog posts. More specifically, we utilize emoticons that are popularly used in the
Blogosphere as the ground truths. These icons are collaboratively contributed by
bloggers and represent the knowledge on expressing the emotions. From the statistics
of blog corpora, about 15% of the blog posts contain emoticons. The
emoticon-tagged expressions further help us build emotion lexicons and the lexicons
form the knowledge base for the emotion analyzing method. In our works, the
emotion-expression sampling process is fully automatic. It is feasible to build a new
lexicon as we change the article sets in different volume or in different domains.
2. In what way can emotion-related information be analyzed in detail?
Blog corpora make supervised classification feasible. With a great quantity of tagged
blog materials, statistical techniques such as collocation test models are applied to
extract the emotion lexicon. As an emotion lexicon provides keywords as features for
modeling the emotion classifiers, machine learning techniques such as SVM and CRM
are then applied to train emotion classification models. The experimental results
83
Bibliography
[1] Christian Becker, Stefan Kopp, and Ipke Wachsmuth. Simulating the Emotion
Dynamics of a Multimodal Conversational Agent. In ADS '04: Proceedings of
Tutorial and Research Workshop on Affective Dialogue Systems, pp. 154-165,
2004.
[2] Ricardo Baeza-Yates and Berthier Ribeiro-Neto. Modern Information Retrieval,
Addison Wesley Longman, 1999.
[3] Christoph Bartneck. Integrating the OCC Model of Emotions in Embodied
Characters. In Proceedings of Workshop on Virtual Conversational Characters:
Applications, Methods, and Research Challenges, Melbourne, 2002.
[4] Regina Bernhaupt, Andreas Boldt, Thomas Mirlacher, David Wilfinger, and
Manfred Tscheligi. Using Emotion in Games: Emotional Flowers. In Proceedings
of the International Conference on Advances in Computer Entertainment
Technology, pp. 41-48, 2007.
[5] Christopher H. Brooks and Nancy Montanez. Improved Annotation of the
Blogosphere via Autotagging and Hierarchical Clustering. In WWW2006:
Proceedings of the 15th international conference on World Wide Web, pp. 625-632,
Edinburgh, Scotland, 2006.
[6] CAW2.0. Content Analysis in Web 2.0. http://caw2.barcelonamedia.org/, retrieved
on June 2009.
[7] Rui Cai, Chao Zhang, Chong Wang, Lei Zhang, and Wei-Ying Ma. MusicSense:
Contextual Music Recommendation using Emotional Allocation Modeling. In
MULTIMEDIA '07: Proceedings of the 15th International Conference on
Multimedia, pp. 553-556, 2008.
[8] Echa Chang, Chu-Ren Huang, Sue-Jin Ker, and Changhua Yang. Induction of
Classification from Lexicon Expansion :Assigning Domain Tags to WordNet
Entries. In Proceedings of COLING-2002 Workshop on SEMANET, Taipei, 2002.
[9] Olivier Chapelle, Bernhard Schölkopf, and Alexander Zien. Semi-Supervised
Learning. MIT Press, 2006.
[10] F. Chaumartin. A knowledge-based system for headline sentiment tagging. In
Proceedings of SemEval-2007, Prague, Czech Republic, June 2007.
85
[21] R. Cowie, E. Douglas-Cowie, N. Tsapatsoulis, G. Votsis, S. Kollias, W. Fellenz,
and J. G. Taylor. Emotion recognition in human-computer interaction. IEEE Signal
Process, Vol. 18-1: pp. 32-80, 2001.
[22] Xiaowen Ding, Bing Liu, and Philip S. Yu. A Holistic Lexicon-Based Approach to
Opinion Mining. In WSDM ’08: Proceedings of the International Conference on
Web Search and Data Mining, 2008.
[23] A. Esuli and F. Sebastiani. SentiWordNet: A publicly available lexical resource for
opinion mining. In Proceedings of the 5th Conference on Language Resources and
Evaluation, Genova, Italy, 2006.
[24] Rong-En Fan, Pai-Hsuen Chen, and Chih-Jen Lin. Working Set Selection Using
Second Order Information for Training Support Vector Machines. Journal of
Machine Learning Research, Vol. 6: pp. 1889-1918, 2005.
[25] Alastair J. Gill, Darren Gergle, Robert M. French, and Jon Oberlander. Emotion
Rating From Short Blog Texts. InCHI ’08: Proceeding of the 26th annual SIGCHI
conference on Human factors in computing systems, Florence, Italy, pp. 1121-1124,
2008.
[26] Vasileios Hatzivassiloglou and Kathleen R. McKeown. Predicting the Semantic
Orientation of Adjectives. In Proceedings of the 35th ACL and the 8th Conference
of the European Chapter of the ACL, Madrid, Spain, pp. 174-181, 1997.
[27] Lynette Hirschman, Jong C. Park, Junichi Tsujii, Limsoon Wong, and Cathy H.
Wu. Accomplishments and Challenges in Literature Data mining for Biology.
Bioinformatics, Vol. 18-12, pp. 1553-1561, 2002.
[28] Chang-Wei Hsieh, Chi-Te Shen, Yi-Ping Chao. and Jyh-Horng Chen. Study of
Human Affective Response on Multimedia Contents. In Proceedings of
Conference on Medical Physics and Biomedical Engineering, Seoul, Korea, 2006.
[29] ICWSM. Proceedings of 2007 International Conference on Weblogs and Social
Media, March 26-28, Boulder, Colorado, U.S.A, 2007.
[30] Yuchul Jung, Yoonjung Choi, and Sung-Hyon Myaeng. Determining Mood for a
Blog by Combining Multiple Sources of Evidence. In WI’07: Proceedings of Web
Intelligence 2007, Silicon Valley, USA, pp. 271-274, 2007.
87
[40] Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi Chen. Emotion Classification
of Online News Articles from the Reader’s Perspective, In WI’08: Proceedings of
Web Intelligence 2008, 2008.
[41] Wei-Hao Lin and Hsin-Hsi Chen. Similarity Measure in Backward Transliteration
between Different Character Sets and Its Application to CLIR. In Proceedings of
Research on Computational Linguistics Conference XIII, pp. 79-113, 2000.
[42] Wen-Cheng Lin, Changhua Yang, and Hsin-Hsi Chen. Foreign Name Backward
Transliteration in Chinese-English Cross-Language Image Retrieval. In
Proceedings of CLEF 2003 Workshop, Trondheim, pp. 611-620, Norway, 2003.
[43] Hugo Liu, Henry Lieberman, and Ted Selker. A Model of Textual Affect Sensing
using Real-World Knowledge. In Proceedings of the 2003 International
Conference on Intelligent User Interfaces, Miami, USA pp. 125-132, 2003.
[44] Yang Liu, Xiangji Huang, Aijun An and Xiaohui Yu. ARSA: A Sentiment-Aware
Model for Predicting Sales Performance Using Blogs. In SIGIR ’07: Proceedings
of the 30th Annual International ACM SIGIR Conference, Amsterdam,
Netherlands, 2007.
[45] Christopher D. Manning and Hinrich Schütze. Foundations of Statistical Natural
Language Processing, the MIT Press, London, England, 1999.
[46] Yi Mao and Guy Lebanon. Sequential Models for Sentiment Prediction. In
Proceedings of the ICML workshop on Learning in Structured Output Space,
Pittsburgh, 2006.
[47] Cameron Marlow, Mor Naaman, Danah Boyd, and Marc Davis. Tagging Paper,
Taxonomy, Flickr, Academic Article, ToRead. In HT06: Proceedings of Hypertext
2006, 2006.
[48] Andrew McCallum, Dayne Freitag, and Fernando Pereira. Maximum Entropy
Markov Models for Information Extraction and Segmentation. In ICML-2000:
Proceeding of International Conference on Machine Learning, 2000.
[49] Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. Topic
Sentiment Mixture: Modeling Facets and Opinions in Weblogs. In WWW ’08:
Proceedings of the 16th International Conference on World Wide Web, pp.
171-180, 2007.
89
[61] Fabrizio Sebastiani and Consiglio Nazionale Delle Ricerche. Machine Learning in
Automated Text Categorization, ACM Computing Surveys, 2002.
[62] Senseval. Evaluation Exercises for the Semantic Analysis of Text. Organized by
ACL-SIGLEX. http://www.senseval.org/, retrieved on June 2009.
[63] Chi-Te Shen, Yi-Ping Chao, Chang-Wei Hsieh, and Jyh-Horng Chen. Emotion
Recognition Systen for Physiologicak Signal. In Proceedings of Conference of
Biomedical Engineering Technology, Taiwan, 2005.
[64] Maria Shugrina and Margrit Betke. Empathic Painting: Interactive stylization
through observed emotional state. In NPAR ’06: Proceedings of the 4th
International Symposium on Non-photorealistic Rendering and Animation, pp.
87-96, 2006.
[65] Veselin Stoyanov, Claire Cardie , Diane Litman, and Janyce Wiebe. Evaluating an
Opinion Annotation Scheme Using a New Multi-Perspective Question and Answer
Corpus. In Proceedings of AAAI Spring Symposium on Exploring Attitude and
Affect in Text: Theories and Applications, 2004.
[66] Carlo Strapparava and A. Valitutti. WordNet-Affect: an affective extension of
WordNet. In Proceedings of 4th International Conference on Language Resources
and Evaluation, Lisbon, 2004.
[67] Carlo Strapparava, A. Valitutti, and O. Stock. The affective weight of lexicon. In
Proceedings of the Fifth International Conference on Language Resources and
Evaluation, Genoa, Italy, 2006.
[68] Carlo Strapparava and Rada Mihalcea. Learning to Identify Emotions in Text. In
Proceedings of the 2008 ACM symposium on Applied computing, Fortaleza, Ceara,
Brazil, pp. 1556-1560, 2008.
[69] Yuen-Hsien Tseng, Chi-Jen Lin, and Yu-I Lin. Text mining techniques for patent
analysis. Information Processing and Management. Vol. 43-5, pp. 1216-1247,
2007.
[70] Peter D. Turney and Michael L. Littman. Measuring Praise and Criticism:
Inference of Semantic Orientation from Association, ACM Transactions on
Information Systems Vol. 21-4: pp. 315-346, 2003.
91
[81] Masahide Yuasa, Keiichi Saito, and Naoki Mukawa. Emoticons Convey Emotions
without Cognition of Faces: An fMRI Study. In CHI ’06: Proceedings of
Conference on Human Factors in Computing Systems, Montréal, Canada, pp.
1565-1570, 2006.
[82] Stephen Wan and Cornelia Maria Verspoor. Automatic English-Chinese Name
Transliteration for Development of Multilingual Resources. In Proceedings of 17th
COLING and 36th ACL, pp. 1352-1356, 1998.
[83] Hsuan-Kai Wang, Jun-Hao Zeng, Chang-Wei Hsieh, and Jyh-Horng Chen.
Adopting Features Analysis of Bio-signals to Search Subjects’ Emotion Response 
Elicited from Music. In Proceedings of Conference of Biomedical Engineering
Technology, Taiwan, 2007.
[84] Janyce Wiebe and Rada Mihalcea. Word Sense and Subjectivity. In ACL ’06:
Proceedings of the 44th Annual Meeting of ACL, Sydney, Australia, 2006.
[85] Janyce Wiebe, Theresa Wilson and Claire Cardie. Annotating Expressions of
Opinions and Emotions in Language. Language Resources and Evaluation, Vol.
39-2: pp. 165-210, 2005.
[86] Joseph B. Walther and Kyle P. D'Addario. The Impacts of Emotions on Message
Interpretation in Computer-Mediated Communication. Social Science Review, Vol.
19-3: pp. 324-346, 2001.
[87] Ryen W. White, Mikhail Bilenko, and Silviu Cucerzan. Leveraging Popular
Destinations to Enhance Web Search Interaction. ACM Transactions on the Web
(TWEB), Vol. 2-3: pp. 1-30, 2007.
[88] Chung-Hsien Wu, Ze-Jing Chuang, and Yu-Chung Lin. Emotion Recognition from
Text Using Semantic Labels and Separable Mixture Models. ACM Transactions on
Asian Language Information Processing, Vol. 5-2: pp. 165-182, 2006.
[89] WordNet. An Electronic Lexical Database. Edited by Christiane Fellbaum. MIT
Press, 1998.
[90] Tien-Lin Wu and Shyh-Kang Jeng. Probabilistic Estimation of a Novel Music
Emotion Model. In Proceedings of MMM, 2008.
93
Appendix
A1. Stop Word List
～ + - ＊ × ／ ＝ ． ( ) ╭ @ ∴ … 〈 〉 （ ） ^ 【 】 ” 『 』 「 」
？ ！ ; 。 ˙ ， ： 、
不 你 了 好 和 与 他 的 我 口 水 點 要 能 像 大 叫 看 小 睡 被 很 啦 喔
害 來 吧 個 事 拿 老 多 著 哪 句 想 那 太 吃 就 又 只 張 更 讓 人 給 她
有 是 到 當 而 從 每 心 月 用 一 全 等 將 買 年 所 去 對 几 為 中 嗎 啊
才 也 時 為 呀 上 這 在 跟 二 後 呢 花 都 會 把 以 或 之 嘛 真 誰 錢 阿
行 它 次 帶 位 及 最 但 及 該 天 下 廷 种 寫 過 再 手 哦 做 先 嗯 知 問
家 剛 快 旺 可 打 懂 找 听 米 日 班 玩 送 如 此 臉 穿 件 滿 得 沒 坐 連
少 便 各 陪 新 比 拍 說 頭 講 使 魚 敢 怕 早 晚 已 整 話 紅 亂 三
A2. Emotion Lexicon Categorized by Emotions
α=0.0005
Happy
今天 孩子 我們 開心 分享 寶寶 快樂 朋友
高興 大家 健康 希望 一切 可以 媽咪 長大
寶貝 謝謝 出生 什么 生活 終於 心情 可是
不錯 愛 老師 很多 一起 知道 生日 他們
幸福 雖然 媽媽 一些 加油 老公 早上 起來
准備 可愛 比較 感覺 現在 之後 照片
Sad
唉 擔心 感冒 但是 難 有點 大家 可是
愛 因為 醫生 可以 哭 只好 醫院 喝
最近 媽咪 有時 希望 我們 可能 一直 心情
開始 小時 一點 感覺 晚上 所以 這様 肚子
喜歡 昨天 實在 回來 回家 早上 結果 一定
Winking
不錯 大家 可以 怎么 一直 我們 真的 各位
生活 加油 照片 出來 其實 孩子 長大 看看
一定 醫生 什么 所以 當然 一起 准備 很多
Grinning
開心 怎么 呵呵 哈哈 高興 可以 大家 笑
終於 照片 什么 哈 一直 真的 所以 喜歡
當然 這様 醫生 希望 一下 今天 結果 老公
但是 孩子 阿姨 一起 第一 知道 小孩 可愛
請 可是 不過 比較
95
Surprising
竟然 居然 怎么 哇 發現 結果 醫生 突然
大家 可以 什么 媽咪 所以 寶貝 听到 我說
想到 我們 喜歡 這么 可能 看到 原來 肚子
一定 自己 已經 他們 為什么 爸爸 然後 後來
下來 小孩 好像 兩
Angry
生气 气死 討厭 吼 脾气 婆婆 老公 居然
結果 為什么 愛 竟然 搞 人家 怎么 小孩
不過 寶寶 我說 所以 什么 一直 可以 朋友
這様 真的 不然 我們 可是 那么 東西 而且
Smug
可以 不錯 媽媽 真的 比較 怎么 希望 愛
哥哥 我們 表情 一直 終於 你們
Cool
太陽 天气 真的 小孩 搞 一直 寶貝 怎么
愛 可愛 醫生 寶寶 希望 開心 媽咪
Worried
唉 擔心 緊張 有點 可以 大家 寶貝 我們
開始 難 醫生 怎么 愛 不然 結果 實在
可是 喝 只好 可能 一直 昨天 肚子 問題
真的 小時 媽咪 早上 最近 心情 孩子 時間
哭 第一 後來 寶寶 因為
Devilish
惡魔 嘿嘿 麻麻 不然 拔拔 大家 寶貝 真的
媽 表情 今天 寶寶 我們 只要 覺得 小孩
Crying
哭 大哭 感動 難 痛 大家 可以 唉
哇 人家 結果 一直 我們 真的 听到 愛
朋友 開始 可是 因為 竟然 怎么 晚上 出來
只好 不過 媽咪 一下 這様 醫生 孩子 肚子
下來 寶貝 媽媽 為什么 比較 所以 今天 已經
回家 心情 他們 覺得 好像 自己 喝 寶寶
時候 東西 起來 第一
Laughing
哈 哈哈哈 哈哈 笑 好笑 開心 高興 呵呵
希望 表情 原來 醫生 看到 怎么 終於 不過
媽咪 愛 時間 孩子 什么 爸爸 寶寶 可愛
可是 起來 一様 但是 結果 媽媽 寶貝 只要
我說 好像 以後 開始 雖然 妹妹 一點
97
Dizzy
傻眼 大家 竟然 眼睛 醫生 結果 居然 可以
小時 有點 突然 所以 雖然 一直 媽咪 怎么
發現 我們 晚上 實在 開始 而且 孩子
Yawning
睡覺 累 好累 愛困 睡著 睡眠 起床 晚上
上班 無聊 半夜 休息 小時 時間 唉 早上
工作 有點 昨天 搞 分鐘 下午 起來 看到
希望 開始 可能 心情 大家 最近
Drooling
好吃 口水 蛋糕 流口 美味 雞腿 口味 咬
吃到 味道 好好 草莓 超好 餓 食物 喝
東西 媽媽 愛 准備 怎么 哇 期待 知道
我們 顆 這様 現在 下午 自己 已經 不錯
起來 下來 覺得
Pondering
什么 應該 到底 怎么 想想 奇怪 好像 知道
為什么 比較 可能 如何 覺得 小孩 大家 這么
媽媽 那么 愛 希望 我們 但是 看看 最近
如果 媽咪 可是 第一 問題 一下 今天 以後
不然 這様 老公 東西 有點
Giggling
呵呵 當然 一下 一直 照片 其實 老公 不過
笑 希望 可以 媽媽 媽咪 哥哥 起來 應該
今天 喜歡 什么 可愛
Applause
鼓勵 棒 拍拍手 掌聲 厲害 加油 佩服 拍手
勇敢 終於 不錯 表演 成功 自己 因為 請
老師 辛苦 知道 愛 這様 努力 時候 生日
非常 可愛 一直 第一 可是 大家 朋友 高興
結果 希望 而且 看到 喜歡 醫生 快樂 已經
一下 今天 這么 感覺 姐姐 我們 一定 所以
覺得 可以 但是 時間
Praying
希望 拜託 保佑 老天爺 平安 快快 順利 健康
期待 請 明天 一切 赶快 感謝 擔心 加油
醫生 緊張 醫院 感冒 愛 可以 長大 檢查
可愛 什么 怀孕 寶寶 看到 一點 覺得 爸爸
不然 告訴 第一 自己 一定 不過 乖乖 而且
他們 肚子 怎么 朋友
99
笑到 佩服 知道
拍手 偷情 哇哇
笑死 祈禱 平安
眼淚 媽咪 難
咦 竟然 唉
流口 痛 豬頭
好痛 心疼 噓
親親 貼心 祈求
甜蜜 長大 美味
嗚嗚嗚 好愛 傷心
永遠 感謝 祝福
勇敢 居然 愛妳
哭哭 傻眼 可惡
嗚嗚 親愛 健康
終於 討厭 小豬
好意 吼 名稱
求求 累 可怜
老天 高興 親一
大睡 祝 大家
快快 順利 難道
天使 哼 喜歡
應該 怎 期待
生日 不錯 瑪咪
父母 表演 禱告
上帝 成功 學習
母親節 陳醫師 哇
翔鉞 夢 太陽
想想 幼儿 小天
惊訝 拍謝 我們
嚇 禮物 成長
名 脾气 健健
哭聲 進步 呼呼
晚上 康康 請
拍拍 快好 為何
101
義大利 教育 能力
睡ㄌ 嘿嘿 因為
繼續 生活 周公
醫院 幚助 想睡
余媽 哄 倒頭
夸張 天下 有味
一覺 打瞌睡 啥
所以 神 第
睡眠 快流 偷笑
乖 胖丁 冰淇淋
打呼 痛苦 美麗
睡午覺 公斤 沉沉
千万 香味 恭喜
毛爸 輩子 湯
漂亮 真的 覺
但是 學生 合照
餓 老公 巧克力
其實 听到 別再
感覺 火鍋 害怕
生命 魔鬼 尷尬
怕怕 朋友 步
恐怖 進入 不過
昏睡 親子 心肝
沒睡 婚姻 開始
豬 感恩 您
可怕 失望 朵
豬小妹 烤肉 睡著ㄌ
打哈欠 了解 干嘛
原來 沒事 吃吃
入睡 婆婆 多久
噁心 有點 吃好
辰辰 食物 躺
上床 玫瑰 蚊子
一、參加會議經過
第七屆國際語言資源和評估會議(The Seventh International Conference on Language
Resources and Evaluation)，是由歐洲語言資源協會 (European Language Resources
Association)所舉辦的雙年會，今年在馬爾他首府瓦勒他國際會議中心 (Mediterranean
Conference Center)舉行，超過 1100人註冊與會，是自然語言處理研究的盛會。筆者由台北搭
乘泰國航空班機，由曼谷轉機到羅馬，再到瓦勒他參加本次會議。
二、與會心得
本次會議共收到 930 篇論文，經過審查後接受 662 篇論文，共分成 semantics and
knowledge、subjectivity、machine translation and multilingualism、infrastructural initiatives,
strategies, national and international projects、lexicons and corpora、tools and systems、
dialogue and discourse、speech and multimodal database, tools, and systems、evaluation and
validation methodologies等議題進行論文報告和討論。此外，會議主辦單位也安排 22個
workshops和 9場 tutorials。
本屆大會最大的特色是 LREC 2010 Map的收集，語言資源計有：語料庫、辭典、
詞性標記/剖析器、標記工具、語言本體、評估語料、標記綱要、語法/語言模型、評估
工具、專門用語、指涉實體辨識、標記標準等。最被廣泛使用的語料庫分別是：英文語
料、Europarl、Wikipedia、BNC等。最被廣泛使用的辭典有：WordNet、FrameNet、EDR
等。最被廣泛使用的詞性標記/剖析器為：Stanford Parser、Tree Tagger、MaltParser。最
被使用的標記工具有：ELAN、TrEd、GATE等。
經統計分析，目前語言資源應用最廣的前 5名是：資訊擷取、資訊檢索；機器翻譯、
語音對語音翻譯；知識發現和表示；語言模型；取得。而資訊擷取、資訊檢索所使用到
的語言資源有：Arabic Treebank；ACE Corpora、Open CV、Wikipedia；GATE、TREC Data。
機器翻譯、語音對語音翻譯所使用到的語言資源有：Moses、Europarl、GIZA++、JRC
Acquis、BLEU、Google Translate、SRILM 等。在知識發現和表示方面則有：WordNet
和Wikipedia。有趣的是新語言資源應用方向：除了資訊擷取、資訊檢索；機器翻譯、語
音對語音翻譯，排名不變外，情緒辨識/合成提升到第三名，知識發現和表示下降一名，
dialogue和 discourse等應用有上升的趨勢。
筆者在本次大會共發表 3 篇論文，都與意見探勘相關。有一篇談如何延伸 Penn 中
文樹狀語料庫，在上面加上意見標記；另一篇提到中文詞彙的結構關係，和詞彙意見傾
向之關聯性；第三篇則是判斷部落格貼文評論之邊界，藉以抽取各項評論之意見傾向，
這些都是目前最熱門的研究議題。以下是部份活動照片：大會會場 Mediterranean
Conference Center，是個古堡；宴會廳闢成註冊報到處、以及海報論文展示處；論文宣
讀分在不同演講廳舉行；邀請講席是在最大的會議廳進行。
大會會場 註冊報到 論文簡報 論文宣讀會場 邀請講席
會議投影片
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
99年 7月 31日
報告人姓名
陳信希
服務機構
及職稱
國立台灣大學資訊工程學系教授
時間
會議
地點
99年 7月 19日-7月 23日
瑞士日內瓦
本會核定
補助文號
會議
名稱
(中文)第三十三屆 ACM SIGIR年度會議暨議程委員會
(英文) The 33rd Annual ACM SIGIR Conference and Program Committee Meeting
發表
論文
題目
(中文)
查詢紀錄中意圖邊界偵測
(英文)
Intent Boundary Detection in Search Query Logs
附
件
三

96年度專題研究計畫研究成果彙整表 
計畫主持人：陳信希 計畫編號：96-2628-E-002-240-MY3 
計畫名稱：以部落格內容和結構探勘研究使用者之個別和群體行為 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 6 6 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
