2 
 
一、前言 
動作捕捉技術主要是記錄真實世界中生物的運動行為，原本是 1970 年代為了研究生物力
學而產生的影像分析工具，而在現今已廣泛運用在電玩遊戲、電腦動畫、生物醫學等領域。縮
短製作動畫的時間是其優點，並能夠精準記錄生物的運動過程。目前動畫與遊戲公司經常使用
動作捕捉系統來獲取擬真的特效與動作，透過真人配戴感應裝置作出想要的動作，接著將動作
捕捉系統所生成的骨架運動資料套用在其他三維模型上，如此可獲得相當逼真的三維動畫。無
論應用在電影、電玩遊戲等產業，都有相當不錯的視覺效果。正規來說，利用動作捕捉所產生
的動作捕捉資料是對物體骨架作一時間性描述。以人體骨架為例，主要是由關節與骨骼形成的
一種架構。但由於骨骼是屬剛性物質，因而關節點在空間上的旋轉量就成了描述動作捕捉資料
的主要標的。透過關節點角度的改變，進而可以充分描述整段動作的變化。在過去幾年，無論
是學術界或產業界主要專注在動作捕捉資料的取得，可喜的是—特別在最近的一段時間，已陸
續可以看到較為平價、精確度高、使用較不受拘束的捕捉系統問世。由於動作捕捉資料量相當
龐大，即便錄製完後要重新調整使用並不容易，因而有部份的文獻探討動作資料的編修與合成
的技術[7]，但如何進一步瞭解運動語意、快速檢索相似片段以達到重複使用的目的，則是後
續必須面對的問題。 
二、研究目的 
以往三維動畫的運動行為都是雇用動畫師一步一步改變三維模型在空間中的位置，使角色
的運動行為趨於自然。這樣的策略需耗費大量的人力與時間製作，況且所產生的動作往往不易
達到擬真的視覺感受，因而運動捕捉的技術因運而生。所謂「運動捕捉」意指在真實的世界中
取得真實物件的運動狀況，它可以快速取得真實的運動資料，再套用到虛擬的三維模型上，即
可省掉大量的製作時間，並且由於動作來自真實的動作捕捉因而也顯得較為自然順暢。因此，
這幾年即十分仰賴這樣的技術快速產生大量的運動捕捉資料，有許多相關的技術陸續被提出，
包括對運動捕捉資料作編修、兩段運動資料作合成、運動資料的壓縮與動作檢索等方法。 
在過去幾年，無論是學術界或產業界主要專注在動作捕捉資料的取得。特別在最近的一段
時間，已陸續可以看到較為平價、精確度高、使用較不受拘束的捕捉系統問世。由於動作捕捉
資料量相當龐大，即便錄製完後要重新調整使用並不容易，因而有部份的文獻探討動作資料的
編修與合成的技術，但其它相關技術、應用與整合仍十分缺乏，甚至連相關的文獻資料相較於
數位音訊、影像視訊、三維模型等數位媒體也明顯不足，正急待產官學界投入更多的心力在相
關的研究上。由於運動捕捉資料的類型不一，本研究主要是以人類的動作捕捉資料為例，建立
4 
 
此外，亦可將左右腳的特徵結合特徵函數 lr FFF : ，使得更容易去觀察身體各部位的交互
性關係，例如走路、跑步的動作。由於此一特徵表達僅與相對座標與方位相關，因而可滿足仿
射不變的特性。 
(4) 以運動能量為基礎的特徵萃取方法 
目前的許多文獻大多集中在距離函數衍生的特徵萃取上，在[8]中則提出一個方法能夠獨
立於影格的長度，只相依於 k 個節點旋轉數量。利用前處理計算每個節點的運動能量，好處是
能將原本的動作序列壓縮成 k 個。文獻中首先計算每個節點的速度，進而求出慣性矩，並依此
計算每個維度下的平均近似運動能量。為了抑制部份瞬間爆發性的動能節點，需要作一個對數
的處理，因此可以得到一個特徵向量。 
四、研究方法 
一般來說，運動捕捉資料錄製後除了人為敘述之外，電腦並無法自動認知，而人類的動作
經常是由許多基本動作組合而成。因此，本研究利用在資料庫當中已有的基本動作來作為訓練
的樣本，將其降維之後將整段動作捕捉資料作語意上的認知，由空間方位關連性姿勢特性定義
出基本動作，加上人為定義的行為規則以進行高階意涵的自動偵測與判斷。為了充分表達各種
可能的人體運動姿勢，有必要定義數量夠多的空間方位關連特徵，因而得到一多維度向量。另
外，各維度之間難免存有相依度不等之特性，因而如能適當降低維度，對於資料的處理上將有
莫大的幫助。 
一般來說，人類的動作經常由許多基本動作組合而成，因而本研究延續空間方位關連特徵
表示方法，以分割後小片段為單位，利用在資料庫當中既有的基本動作來作為訓練的樣本，加
上人為敘述的行為規則，以期能對未知動作捕捉資料作語意上的認知。為了降低特徵表達的複
雜度，擬使用主成份分析來將多維度的資料降維，再利用最近 k 鄰居(k-Nearest Neighborhood)
方法對原本資料中指定的基本動作作訓練，最後將輸入的動作捕捉資料中作語意上的辨認與偵
測。我們使用的策略是採雙階層的判別—藉由基本動作的比對方式進行辨識，再作一連串「複
合式動作」捕捉資料之比對，以期能自動找出高階、有意義、語意式的動作片段，其流程圖如
圖一所示。 
6 
 
步驟三、偵測基本動作 
在人類認知有關動作的高階語意中，經常由一連串基本動作所組成，因而基本動作的有效
偵測即是邁向高階的第一步。判別方法採監督學習模式(Supervised Learning Model)：在訓練階
段，由人為選定方式對於分割的動作片段賦予特定語意符號；在判別階段，對於未知動作資料
作識別藉以偵測出基本動作。本研究擬先採用 k 個最近鄰居方法，將每一基本動作分別套入目
標資料作訓練，進而偵測出所蘊含的基本語意。如圖二，假設找尋出來的一種基本動作片段以
淺綠色代表(如出左拳)，以此作法對其他各種的基本動作如法炮製。經由基本動作的偵測後，
接下來所要解決的問題就是找出特定的複合式動作。 
(a) (b) (c) (d)
 
圖二、動作偵測示意圖：(a)原始資料，(b)分段結果，(c)基本動作，(d)複合動作 
步驟四、動作描述平台 
提供使用者簡易又充份的特徵描述工具作為日後語意解析的工作，是邁向高階語意另一重
要的階段。本研究利用原本建立好的動作姿勢為基礎，制訂常規表示方法來定義動作規則。正
如同人類語言是一連串句子所構成，而語言語法則是定義該語言結構，句子又由文法所構成，
因此在語言的表達上需符合其規律，使得其他具備該語文能力的人也可輕易理解，不致有不同
語意上的誤解。常規表示式可分為兩大部分：由一般字元所組成的普通元素與具有特殊意義的
字元，如＊代表重複出現的字元、?代表出現零次或一次的字元、＋代表至少一次以上的字元、
| 代表或者、{min,max}代表重複出現的次數區間等。藉由使用兩者的組合來敘述字串，可形
成一些有規律的字串。經由第一階段之基本動作姿勢的辨識後，將得出的結果賦予代號，並給
予語法的定義而加以判讀，則可以藉由一串連動作姿勢來找出動作捕捉資料中高階的意涵。 
步驟五、動作解析方法 
依據自訂的動作規則描述，從一連串的動作類別中將特定動作擷取出來是動作解析的主要
目標，以下分兩部份來說明： 
8 
 
動作資料，並且能夠以人們所知的語意來對其作描述，藉以瞭解資料的高階意涵。整體而言，
本計畫方法對於高階語意描述與偵測皆能得到預期的成果，與人類一般感官認知也十分相符，
其成果可作為產學界之參考。 
參考文獻 
[1] Chin-Yi Chiu, Shih-Pin Chao, Ming-Yang Wu, Shi-Nine Yang and Hsin-Chih Lin, 
“Content-Base Retrieval for Human Motion Data,” Journal of Visual Communication and 
Image Representation, vol. 15, no. 3, pp. 446-466, 2004. 
[2] Chuanjun Li and B. Prabhakaran, “Indexing of Motion Capture Data for Efficient and Fast 
Similarity Search,” Journal of Computer, vol. 1, no. 3, June 2006. 
[3] CMU Graphics Lab Motion Capture Database, 2011. http://mocap.cs.cmu.edu/ 
[4] Cormen, Thomas H., Leiserson, Charles E., Rivest and Ronald L., “Introduction to Algorithms,” 
MIT Press and McGraw-Hill, 2002. 
[5] Wei-Chang Du, Ming-Ren Su and Yu-Chi Pu, “Semantic Feature Extraction and Retrieval for 
Human Motion Capture Data,” Computer Graphics Workshop, 2010. 
[6] HongLi Zhu and Jian Xiang, “A New Index Method for Large Motion Capture Data,” the first 
International Symposium on, pp. 158-160, 2007. 
[7] Jue Wang, Steven M. Drucker, Maneesh Agrawala Michael F. Cohen, “The Cartoon Animation 
Filter,” ACM Transactions on Graphics, vol. 25, no. 3, pp. 1169-1173, 2006. 
[8] Kensuke Onuma, Christos Faloutsos and Jessica K. Hodgins, “FMDistance：A Fast and 
Effective Distance Function for Motion Capture Data,” The Eurographics Association, 2008. 
[9] Meinard Müller and Tido Röder, “Motion Templates for Automatic Classification and Retrieval 
of Motion Capture Data,” ACM SIGGRAPH Symposium on Computer Animation, 2006.  
[10] Meinard Müller, Tido Röder and Michael Clausen, “Efficient Content-Based Retrieval of 
Motion Capture Data,” Proceedings of ACM SIGGRAPH, 2005. 
[11] Nancy Pollard, “Database Techniques with Motion Capture,” International Conference on 
Computer Graphics and Interactive Techniques, 2007. 
[12] Ming-Ren Su, “Compact Feature Representation and Efficient Retrieval for Human Motion 
Capture Data,” Master Thesis, I-Shou University, 2009. 
[13] S. Salvador and P. Chan, “Toward Accurate Dynamic Time Warping in Linear Time and 
Space,” Intelligent Data Analysis, 2007. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/11
國科會補助計畫
計畫名稱: 人類動作捕捉資料之內容檢索與語意偵測(2/2)
計畫主持人: 杜維昌
計畫編號: 99-2221-E-214-063- 學門領域: 計算機圖學
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
