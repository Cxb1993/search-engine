 II 
Abstract 
In order to support various Grid services to satisfy with heterogeneous needs, the Grids 
integrated with diverse types of services provided by spreading resources among the network. 
The Pisces project develops the hybrid architecture to coordinate those scattered Grid resources. 
For the purposed of developing distributed autonomic Grid systems, the centralized coordination 
architecture is utilized to manage the intra-Grid resources and the Peer-to-Peer (P2P) technology 
is applied to communicate with inter-Grid systems.  
The subproject A is a bridge between users and other subprojects and aims for developing a 
Grid System Management. In order to provide a platform for information integration and resource 
sharing, the objectives of subproject A are to provide a friendly and easy-to-use Portal and to 
develop a mechanism for certificate authority in the cross-grid environment. Based on this 
developed grid platform, we could integrate services developed from other subprojects to provide 
a graphic user interface and to satisfy various user requirements. Therefore, we accomplish the 
Grid System Management by three years. First, we mainly focus on developing user interface and 
designing the intra-Grid authentication. Through the integration of Web Portal and intra-Grid 
authentication, Users can access the sharing resources and use the basic services provided by the 
grid system after they can successfully login from the Web Portal. In the second year, we enhance 
the Web Portal to support the functionality of workflow processing. Moreover, we develop the 
inter-Grid authentication and authorization based on the intra-Grid certificate authority. By 
adopting the user account mapping mechanism, we could develop the cross-grid security among 
different grid systems and sustain the objective of the Single-Sign-On (SSO). The final year 
addresses the data manager and integrates the accomplishments of this subproject with correlative 
subprojects. By the development of our Grid System Management, Pisces can provide a uniform 
Web Portal with the cross-Grid authentication, authorization and SSO. 
 
Keywords: Pisces, Grid Computing, Grid System Management, Portal, Certificate Authority 
 
 1 
一、 前言 
格網計算[1-3]已成為相當熱門的發展趨勢，其目的是利用網路集結分散於各地的各種資源，
包含運算、儲存、通訊、程式、多媒體串流等各式各樣的資源，這些資源可能隸屬於不同的單位
組織，或者分散於世界各地，使用各種不同的硬體或作業平台。格網計算使用各種共通的語言與
開放的通訊協定，集結這些異質資源，組成虛擬的超級電腦，打破個人電腦運算與服務的界限。
格網計算的目標是將運算及資訊虛擬化，並透過分享的概念，任何人或裝置都能提供軟體服務給
其他人或裝置。另外，同樣重要的一點是，讓使用端能夠安全可靠地取得此類的各式服務。使用
者只要連上格網，通過適當的安全認證機制，便可以取得格網系統提供的各種服務。 
二、 研究目的 
子計畫 A－雙魚座之格網系統管理(Subproject A－Grid System Management)，為其他子計畫之
對外窗口，目的在於開發具親和力且簡單又方便的 Portal (入口網站)，針對使用者所提交的需求，
連結後端各子計畫以提供服務。透過一個整合性的單一入口與一致性的操作介面，作為資訊整合、
交換、以及存取共享資源之平台。藉由提供便捷的操作介面，使用者可使用 Portal 或視窗化的軟
體介面，藉此提交工作、查詢系統資訊、或者存取儲存資源的資料。使用者除了可以在 Portal 上
方便地瀏覽格網系統的各種資訊，在工作執行期間，可藉由網頁介面監控提交工作之狀態與進度，
並於工作完成時瀏覽其執行結果。因此，不論使用者在何種硬體、作業系統等平台上，只要能連
上 WWW，就可在任何地點、任何時間連上本子計畫之 Portal，使用架構在其上的任何服務。此外，
由於每個格網系統都擁有自己的認證管理機制，不同的格網系統可能有不同的使用權限。當需要
與其他格網系統協同運作時，必頇能順利通過認證與授權，經由單一簽入(Single Sign on)的安全認
證機制，存取其他格網系統提供的資源。因此，發展一套可跨越格網系統的認證管理機制以及使
用者對映(User Mapping)機制，將是一大挑戰。鑑於此，本子計畫分成三年完成格網系統管理所需
的研發項目。 
第一年的目標是先以開發使用者介面，並研發內部認證機制，整合研發的認證機制，讓使用
者可以從開發的介面成功登入格網系統，使用格網系統的基本服務。主要工作如下： 
 使用者介面之設計與開發 
 格網內部認證機制之研發 
 使用者介面與內部認證機制之整合 
 
第二年主要規劃為針對第一年之 prototype 予以延伸，包含加強 Portal 使之具備處理 workflow
能力，延伸第一年的認證機制結合使用者帳號對應機制，使其可以達到不同格網之間的認證，達
成 Single Sign On 的目的，並進行內部元件的初步整合。主要工作如下： 
 使用者介面功能之強化 
 格網系統間的認證機制之研發，以及 Single-Sign-On(SSO)的支援 
 使用者介面與不同格網系統間的認證機制之整合 
 
第三年的重點在於整合前兩年之成果並與相關子計畫進行整合與測試，完成格網系統管理介
面以提供格網系統的操作介面與跨系統之認證和 SSO。主要工作如下： 
 Client 檔案操作界面 
 格網管理系統之整合 
 3 
 使用者介面 
使用者介面能有效的縮短格網系統與使用者之間的隔閡，我們針對使用者介面開發
格網系統的 Portal。Portal 是格網系統的入口，作為資訊整合、交換、以及存取共享資源
之介面，利用網際網路無遠弗屆的連通特性，使得使用者可在任何地點、任何時間均可
透過此一入口網站使用格網系統上的任何服務，提供一個簡單而實用的使用者介面，將
可增加使用上的便利性。本子計畫中，Portal 是採用 JSP 與 Tomcat + Apache Server 技術
分別來開發網頁前、後端技術，並結合 MySQL 與 XML 來存放所需的資訊。利用 web
介面開發，其優點為只需使用瀏覽器即可使用本系統，不需安裝任何軟體及環境，並利
用動態網頁技術，配合使用者需求，即時進行網頁客製化，降低使用上的障礙。 
 
 格網內部認證機制 
為了系統內部的管理與維護，系統管理者可能有必要知道什麼人，在什麼時候，使
用哪些資源，執行了什麼程式。因此，帳號的管理與系統安全性是格網系統的重要議題。
本子計畫針對格網內部認證管理機制，提出一個解決方案，讓通過認證的使用者帳號可
在不同的元件之間。採用 Globus Alliance 所提供的 Grid Security Infrastructure (GSI)認證
機制，每個使用者的帳號是經由統一的管理模式，透過單一的使用者帳號，藉由 Proxy 
Manager 管理 Proxy 的有效驗證，並且僅頇從 Portal 登入一次即可使用格網系統提供的龐
大資源與運算能力，達到 Single-Sign-On 的目的。內部認證機制研發說明如下： 
 Proxy Manager 
本子計畫採用美國國家超級電腦應用中心 (NCSA: National Center for 
Supercomputing Applications)所發展的 MyProxy server 作為使用者 proxy 的存放空
間，Portal 在使用者登入的時候將使用著的 proxy 存入 MyProxy server，之後若是有
需要使用到 user 的 proxy(如要執行工作)便可從此 server 中取得 user proxy，接著以
使用者的身份來執行使用者的工作。 
 Local User Account Certification 
本子計畫採取三層式認證的防護措施： 
 第一層：網頁伺服器上的帳號密碼控管 
未經註冊使用的使用者無法登入網頁伺服器，萬一網頁伺服器遭到駭客入
侵而取得了資料庫中的帳號密碼，儘管可以登入網頁伺服器，不過他卻沒有辦
法拿到真正能夠存取機器的 certificate。 
 第二層：Certificate 的認證 
每個使用者會有不同的 certificate 並各自保存，只有在使用者真正 submit
工作的時候才要求使用者透過網頁將此 certificate 以及其相對應的密碼輸入到
網頁中，並且針對 password 作加密的動作，讓駭客即使得到 certificate 也無法
使用。 
 第三層：Certificate 的密碼 
必頇要有此密碼才能成功在 Portal 中產生一個 proxy 來做為執行遠端程式
的代理人。 
因此，必頇要拿到網頁的使用者帳號密碼、certificate、以及 certificate 的密碼才有辦
法使用格網系統平台。如此的設計將大大提升安全性，並且可以透過存取權限來管理哪
些使用者可以使用哪些機器，讓未來的使用資源管理以及收費機制變的更容易實現。 
 5 
 Workflow Operator 
此功能可協助使用者提交(submit)工作流程給後端作進一步的工作流程管
理，並提供一個工作狀態的監控介面。當使用者利用 Workflow Editor 功能編輯
好自己欲執行之工作流程後，透過此工作流程操作頁面，該工作流程的資訊將
提交至子計畫 B 之工作流程管理進行後續處理，並透過子計畫 B 之工作排程以
及資源篩選功能來選擇出適合的機器。此外，可以透過連結工作流程管理，讓
使用者查詢已提交之 workflow 的執行情況與進度。為了即時反應使用者的操
作，不論工作在 queue 中或是正在執行時，使用者可透過此功能查詢執行狀況，
或是透過連結工作流程資料庫，查詢歷史記錄等資訊。 
 登入導向(Portal Redirection) 
在眾多格網系統所組成的環境之中，Portal Redirection 主要功能是為了整合不同
格網系統的登入機制，提供一個共同的入口介面(Uniform Web Portal)，方便讓不同的
使用者可以從單一入口登入自己所屬的格網系統。圖三描述 Portal Redirection 的登
入流程，當使用者在 Uniform Web Portal 上，可以輸入登入時所需要的使用者資訊，
Portal 將根據所輸入的資訊，導向所屬的格網系統進行內部登入認證機制。藉由第一
年研發的內部格網認證機制，判斷當時想要登入格網系統的使用者，是否為合法的
使用者，交由自己所屬的格網系統決定每個使用者可以存取資源的權限，藉此可以
達到自治管理的目的。 
 
 格網與格網之間的認證以及 Single-Sign-On(SSO)的支援 
為了系統內部的管理與維護，帳號的管理與系統安全性是格網系統的重要議題。本
子計畫在第一年針對格網內部認證管理機制，提出一個解決方案，採用 Globus Alliance [6]
所提供的 Grid Security Infrastructure (GSI) [15]認證機制，每個使用者的帳號是經由統一
的管理模式，透過單一的使用者帳號，藉由 Proxy Manager 管理 Proxy 的有效期限，並且
僅頇從 Portal 登入一次即可使用格網系統內部提供的龐大資源與運算能力，達到內部
Single-Sign-On 的目的。然而，在分散式的點對點計算格網系統中，接收到的工作不僅是
來自於一般的使用者，也可能是來自其他格網系統所提交的工作。不論提交的工作是來
自何者，都頇經過 Certification Authorizer (CA)的認證與授權，每個格網系統可能有自己
的內部 CA 認證機制，管理可允許使用內部格網系統功能的使用者帳號。本年度延伸第
一年所研發的內部認證機制，擴大到外部認證機制，也就是進行格網系統之間的認證機
制。藉由提出的使用者帳號對映機制(Account Mapping)，讓不同的格網之間使用彼此的
內部資源。多重 CA 可讓每個格網系統將擁有自己的認證機制，並且自我管理內部的使
用者帳號資訊，不同的格網系統將可有不同的允許使用帳號。透過 SSO 的特性，達到即
使需要使用遠端格網系統的資源，也僅需讓使用者透過單次登入即可。格網對格網之間
的認證授權機制研發說明如下： 
 使用者帳號對映(Account Mapping) 
我們針對跨格網系統的使用者帳號問題，提出一個解決方案，使用者僅頇從
Portal 登入一次，即使需要使用其他格網系統的資源，也不需要透過使用者再次登
入。當工作需要尋求其他格網系統執行工作時，也可透過 CA 的 proxy 管理機制，達
到不同格網系統之間移交工作的目的。每個格網系統的 CA 認證機制採用兩種不同
的使用者帳號：區域性的使用者帳號(Local User Account)以及暫時性的使用者帳號
 7 
Portal 上所提供的功能。當使用者輸入相關資訊後，包含所屬的格網系統(Domain)、帳號
(Account)、密碼(Password)以及認證碼(Certificate Pass)，Portal 會將使用者資訊導入所屬
的格網系統，交由指定的格網系統進行身分驗證。成功登入之後，即可進入格網管理系
統使用平台上提供的服務，例如上傳或下載所需的檔案、監控資源狀態、提交工作…等。 
如圖六所示，成功登入的使用者，可以使用左邊所提供的 Data Manager 服務進行檔
案操作。使用者可以透過 Host File 選擇欲上傳的檔案資料，如欲進行分散工作的程式與
Input 資料。下方則會列出目前使用者在後端儲存系統中所擁有的檔案清單，使用者亦可
從清單中挑選欲下載回來的檔案，如執行完成的 Output。所有的檔案操作行為，都可以
在網頁上進行管理，以方便使用者無論在哪，只要能連上網路就可透過瀏覽器觀看或查
詢檔案資料。針對工作提交的部分，Portal 亦提供使用者透過 workflow 的編輯畫面，可
針對欲執行的工作編輯工作流程，如圖七所示，其中包含 Workflow、Stage、Job。此外，
使用者可以利用開發的多屬性(Multi-Attribute)資源需求介面，線上編輯執行工作時所需
的環境與資源需求，其中，本子計畫特別針對多屬性資源的需求進行研發，圖八顯示使
用者可針對工作的需求設定工作名稱、工作型態、執行參數、Input 檔案、Output 檔案名
稱、執行環境…等。編輯完成之後 Portal 會提交給後端所研發的 Workflow Management
進行工作排程並挑選適合的資源進行工作分配，使用者亦可在此網頁上查詢工作執行的
狀態與結果，如圖九所示。 
 
圖一、強化 Portal 功能示意圖。 
 
圖二、Workflow 操作功能。 
 9 
 
圖五、雙魚座 Web Portal 登入畫面。 
 
圖六、Data Manager 功能畫面。 
 
圖七、Workflow 工作編輯畫面。 
 11 
五、 結果與討論 
歸納子計畫 A 三年來的主要研發成果包含研發不同格網系統的管理以及極具創新的使用者介
面設計提供入口導向與帳號對映功能，可透過內部認證與不同格網之間的認證機制結合，達到跨
格網系統的 SSO。此外，亦提供多屬性的資源請求功能，可透過資源搜尋機制探索散佈各格網系
統中符合需求的可用資源。其中，藉由 JSP 的網頁開發技術可增加網頁功能的擴充與彈性，開發
符合底層格網系統的工作提交頁面以及整合格網監控系統的資訊，並有助於與認證管理機制的整
合。另一方面，透過研發 Proxy Manager 機制以及使用者帳號憑證控管，大幅提升格網系統的安全
性，並且可以透過存取權限的管理機制限制哪些使用者可以使用哪些機器，讓未來的使用資源管
理以及收費機制變的更容易實現。針對子計畫 B 的 workflow 管理與監控，設計 workflow 工作編
輯環境並可支援多屬性的資源請求(Multi-Attribute Range Query)，提供使用者線上編輯、提交、以
及查詢工作的功能，此外，亦針對結合子計畫 C 的檔案儲存管理系統研發檔案維護與管理的網頁
操作介面。另一方面，基於格網系統的內部認證機制，已完成延伸至不同格網之間的登入與認證
機制，藉由入口導向的機制，可讓使用者經由單一入口登入所屬的格網系統，交由所屬的格網系
統進行使用者認證以判斷登入者是否為合法的格網使用者。透過不同格網之間的認證機制以及帳
號對映機制，使用者僅需單次登入即可使用到遠端資源而毫無查覺，藉此達到不同格網之間的 SSO
目的。相關研究成果已發表至 2 篇國際會議且都即將刊載在國際期刊，如附件一，未來將可進一
步延伸多屬性資源的索引與探索機制並針對可延展性的雲端化分散式管理系統探討點對點的特性
與應用。 
六、 計畫成果自評 
子計畫 A 的研究成果已有數篇學術研究成果已發表及刊載在國際會議與國際期刊，其中所完
成的格網系統管理可透過創新的入口導向以及帳號對映功能，達到跨格網系統的 SSO 與管理機
制。此外，管理系統亦提供多屬性的資源請求功能，可透過後端資源搜尋機制探索散佈各格網系
統中符合需求的可用資源。隨著分散式運算的推廣與普及化，許多組織單位可藉由格網技術整合
內部的資源與服務。透過本子計畫的研發，不同組織單位中現有的格網系統運作可藉由整合不同
格網系統之間的資源與服務，達到彼此共享與進行協同運算。基於不同格網系統間的認證授權與
管理機制，可控管格網系統之間的使用權限以便提高系統存取的安全性。透過本計畫的研究與探
討，有助於分散式運算平台的開發以及運算系統的整合，相關的研發技術與經驗，有助於分散式
運算人才之培育，以及研發未來分散式運算之基礎。 
參考文獻 
[1] I. Foster and C. Kesselman, The Grid: Blueprint for a New Computing Infrastructure, Morgan Kaufmann 
Publishers, Inc., 1999. 
[2] Grid Computing. [Online] http://en.wikipedia.org/wiki/Grid_computing 
[3] The Grid: A New Infrastructure for 21st Century Science. [Online] 
http://www.aip.org/pt/vol-55/iss-2/p42.html 
[4] OGCE Portal Toolkit. [Online] http://www.collab-ogce.org/ogce2/ 
[5] JSRs (Java Specification Requests). [Online] http://jcp.org/en/jsr/detail?id=168 
[6] Globus Alliance. [Online] http://www.globus.org/ 
[7] Java CoG Kit. [Online] http://wiki.cogkit.org/index.php/Main_Page 
[8] SRB (Storage Resource Broker). [Online] http://www.sdsc.edu/srb/index.php/Main_Page 
[9] Condor: High Throughput Computing. [Online] http://www.cs.wisc.edu/condor/ 
[10] GPDK (Grid Portal Development Kit). [Online] http://doesciencegrid.org/projects/GPDK/ 
[11] J. Novotny, “The Grid Portal Development Kit”. [Online] 
N. Abdennadher and D. Petcu (Eds.): GPC 2009, LNCS 5529, pp. 131–141, 2009. 
© Springer-Verlag Berlin Heidelberg 2009 
G2G: A Meta-Grid Framework for the Convergence of 
P2P and Grids 
Wu-Chun Chung1, Chin-Jung Hsu1, Yi-Shiang Lin1, Kuan-Chou Lai2, 
and Yeh-Ching Chung1,* 
1 Department of Computer Science,  
National Tsing Hua University, Hsinchu, Taiwan, R.O.C. 
{wcchung,oxhead,yslin}@sslab.cs.nthu.edu.tw, 
ychung@cs.nthu.edu.tw 
2 Department of Computer and Information Science 
National Taichung University, Taichung, Taiwan, R.O.C. 
kclai@ntcu.edu.tw  
Abstract. Grid systems integrate distributed resources to form self-organization 
and self-management autonomies. Recently, for large-scale computation re-
quirement, the collaboration of different grid systems is one of the hot research 
topics. In this paper, we propose a meta-grid framework, called G2G frame-
work, to harmonize autonomic grids for realizing the federation of different 
grids. The G2G framework is a decentralized management framework on top of 
existing autonomic grid systems. It adopts a super-peer network to coordinate 
distributed grid systems. A super-peer overlay network is constructed for the 
communication among super-peers in different grid systems. The contribution 
of this study is to propose a G2G framework for the Grid-to-Grid federation and 
to implement a preliminary system. Experimental results show that the pro-
posed meta-grid framework could improve the system performance in the G2G 
system. 
Keywords: Convergence, Peer-to-Peer (P2P), Super-peer, Grid Computing, 
Grid-to-Grid (G2G). 
1   Introduction 
The grid computing system is a distributed computing system for solving complex or 
high-performance computing problems, e.g., bioinformatics, medicare/healthcare, 
natural environment, large Hadron collider, and so on. The grid middleware enables 
the grid system to integrate large-scale distributed computing resources and to provide 
an abstract interface for system development. Then, the performance of distributed 
computing and data accessing could be improved by geographical distributed  
resources. 
Many efforts adopt centralized or hierarchical architectures to develop grid systems 
based on the open grid service architecture (OGSA) [8]. In grid computing, a virtual  
                                                          
*
 The corresponding author. 
 G2G: A Meta-Grid Framework for the Convergence of P2P and Grids 133 
a standard manner while the P2P layer is used for grid services or ordinary PCs to 
participate in the grid activities. In this study, JXTA is adopted to develop JXTA 
Agents to create peers, deal with dynamics of peer groups, and communicate with 
peers on the underlying P2P network. By the implementation of the P2PGrid  
platform, resources on the edge of Internet are able to provide or consume services 
without the hassles of maintaining grid middleware packages. A separate layer from 
existing grid system is benefit since the original behaves of grid layer could be pre-
served without modifications, and the modification of the P2P manner would not 
affect the efficiency of the grid layer. The main idea of the P2PGrid is to provide a 
possible solution for integrating P2P computing with the grid environment. Peers in 
the P2P layer are created by the grid entities or common PCs without any grid system 
installed. Jobs are requested and dispatched to workers organized by created peers in 
the underlying P2P computing network.   
In this study, we present a decentralized meta-grid framework on the top of exist-
ing autonomic grid systems from another perspective. The autonomic grids are  
coordinated based on the super-peer network to form a Grid-to-Grid collaborative 
computing environment. A super-peer in the G2G system stands for a grid system. In 
this study, a super-peer is able to provide/consume the grid services to/from other 
super-peers in remote grid systems. The autonomic grids are coordinated based on a 
unstructured super-peer overlay network to form a Grid-to-Grid collaborative comput-
ing environment. By adopting a separated layer, the G2G framework could integrate 
with existing grid systems without modifying the original mechanisms and policies. 
On the other hand, we not only concern the support of computation services and data 
services, but also propose a possible solution for the verification of accessing remote 
resources because of considering the security issues in the Grid-to-Grid environment.  
3   G2G Framework and Prototype 
Currently, most of the grid systems are deployed according to centralized or hierar-
chical management approaches. However, these approaches have poor performance in 
terms of scalability, resiliency, and load-balancing for managing distributed resources 
[11]. Centralization and hierarchy are the weaknesses of deploying large multi-
institutional grid systems, let alone in the widely inter-networking G2G system. Some 
research work showed that the performance with adopting the super-peer model is 
generally more efficient and convenient than that without adopting the super-peer 
model in large-scale computing environments. 
In our G2G framework, we utilize the super-peer network to coordinate the exist-
ing grid systems and adopt the P2P technique to coordinate grid systems. In this sec-
tion, we describe the design concept for G2G system at first; and then, we introduce a 
basic conceptual overview of meta-grid framework. At the end of this section, we 
present a preliminary G2G prototype for the development of the G2G system. 
3.1   Super-Peer Based G2G System 
The super-peer network is proposed to combine the efficiency of centralized search as 
well as the features in terms of autonomy, load balance, and robustness of distributed 
 G2G: A Meta-Grid Framework for the Convergence of P2P and Grids 135 
the Local-Grid part without knowing the policies, mechanisms, or algorithms in the 
Local-Grid part. Since the Cross-Grid part and the Local-Grid part are independent, 
the Cross-Grid part doesn’t need to be modified when the mechanisms in the Local-
Grid part are modified or replaced. 
3.2   G2G Framework 
The G2G framework aims to support the seamless integration of the computing ser-
vices and the data accessing services in the autonomous grids. Therefore, the super-
peer in the Cross-Grid part consists of seven components: the Interactive interface, the 
security management, the network management, the task management, the data man-
agement, the resource management and the information service. The task management 
component takes care of the job computation, and the data management component is 
responsible for integrating the storage systems in the data grid [2]. The network man-
agement component handles the network topology and the G2G interaction between 
distinct grids. The resource management manages the distributed resources in grid 
systems according to the resource status supported by the information service compo-
nent. The interactive interface component deals with the login process for users and the 
security management component is in charge of the authorization of using grids. 
In this study, a meta-grid framework of the G2G system is proposed for federating 
multiple autonomic grid systems, as shown in Fig. 2. By cooperating these compo-
nents in the G2G framework, we can apply grid applications on this framework. The 
detail notions of developing a G2G prototype are shown in the following. 
3.3   G2G Prototype 
This study uses JAVA to develop the proposed G2G framework in which the super-
peers are connected by an unstructured overlay network. The developed components 
of the super-peer are deployed on top of each autonomic grid system to form the  
 
 
Fig. 2. Conceptual framework of components in the Cross-Grid part 
 G2G: A Meta-Grid Framework for the Convergence of P2P and Grids 137 
Passport manager takes care of the passport registration and the verification in the 
G2G system. A passport stands for the admission or verification of the request from 
remote grid systems. If one grid system wants to access resources in another grid 
system, it must get a visaed passport from the target grid system before accessing the 
resources. This study develops a distributed passport-interchange-mechanism in the 
G2G system. According to the maintenance of neighborhood relationship, each grid 
system could request a remote resource/service from its neighbors or neighbors’ 
neighbors by forwarding the resource/service request along the overlay network.  
After discovering the available resource/service in remote grids, the requester would 
receive the visaed passports from the granted grid system; and then, the requester 
could submit tasks to the granted remote grids with legal permission. 
Account manager is responsible for the account management. In this study, the 
function of the account authentication is used for a “local account” to login the grids. 
A local account indicates an originally user account in the local grid system.  Once an 
account requests for a login from the portal, the portal would ask the account manager 
to verify its identification. Another important issue of the account manager is the 
account mapping mechanism. Account mapping is used to deal with requests issued 
by foreign users from remote grid systems. Every grid system which wants to use the 
resources in other grids must register to the granted grid system before accessing 
those resources. The register process acquires a passport and gets a temporary ac-
count. Once the register process is completed, every request with the visaed passport 
from remote grid systems would be treated as a local user account through the ac-
count mapping mechanism. 
3.3.3   Data Service 
In this study, the G2G system supports specific APIs for the transparent accesses of 
existent data storage in each local grid system and for the data transmission among 
different autonomic grid systems. 
In the G2G system, the abstract APIs is responsible to contact a storage system in a 
local grid system or a general file system. Data accesses between the Cross-Grid layer 
and the Local-Grid layer adopt the general-defined data operations; otherwise, the 
data accesses from one grid to another grid adopt the G2G communication through 
super-peers. When a data transmission is necessary to communicate with remote 
grids, the super-peer takes care of the negotiation and communication with other su-
per-peers in the G2G layer. We use the account manager to manage the foreign data 
files in this case. When the data files are accessed from remote grid systems, these 
data files could be stored in the storage system and then be mapped to local owners. 
After the data mapping and the account handling, the foreign data file could be acces-
sible for local users. 
3.3.4   Information Service 
The main responsibilities of the information service include the resource indexing and 
monitoring for capturing the resource status in a grid system. Traditional Grid Infor-
mation Service (GIS) generally adopts the centralized or hierarchical organization [3], 
[4]. Such architectures for the information service are hard to directly apply to the 
G2G system because of the single point of failure problem.  To alleviate the failure 
problem, this study develops an information service for crossing the inter-grid  
 G2G: A Meta-Grid Framework for the Convergence of P2P and Grids 139 
overlay network, and supports a matchmaking policy to provide candidate resources 
satisfied the specified requirements. 
After a task is submitted to the waiting queue for execution, the G2G scheduler 
picks one of queuing jobs according to the First-Come-First-Served (FCFS) policy, 
and then checks whether local resources are sufficient or under loading at first. The 
decision of where to execute a job depends on not only checking whether local grid 
system is over loading, but also discovering whether local resources are satisfied with 
requirements through information service. If the local grid system is not busy and 
there are sufficiently available resources, the job would be migrated to the local grid 
system to be executed. Otherwise, the job manager would ask the distributed resource 
discovery module to search available resources over the overlay network. If there are 
sufficient resources in other super-peers, the job would be migrated to the remote grid 
system for execution. Otherwise, this job would be queued in the waiting queue for 
available resources. 
4   Experimental Results 
To evaluate the proposed G2G framework, two autonomic grid systems based on the 
framework of Taiwan UniGrid [15] are used. One autonomic grid system contains a 
cluster with 8 higher computational power CPUs. The other autonomic grid system 
contains a cluster with 32 lower computing power CPUs. We deploy the proposed 
super-peer network on top of each autonomic grid system to form a Grid-to-Grid 
federation environment. Each super-peer is responsible for coordinating the local 
autonomic grid system and for communicating with other super-peers over the Inter-
net. By using the information converter, each grid system in the G2G system could 
extract resource information from the Information Service module. By using the IDL, 
the Cross-Grid layer could negotiate with the Local-Grid layer; and then the message 
could be exchanged between distinct grid systems. 
We use a matrix multiplication program as the benchmark. Each job we used in 
the experiment is a parallel program written by MPI with C. The matrix size is 
2048x2048. The number of required processors for each job is set to 2. The ratio of 
communication to computation of the test program is about 1 to 100. The task we 
used for performance evaluation is composed of five independent jobs. We estimate 
the average turnaround time for finishing all the jobs in three cases. The turnaround 
time of a task is defined as the time when a task is submitted to the waiting queue for 
processing in the Cross-Grid layer to the time when all the jobs are finished in the 
Local-Grid layer. In case 1, the task is submitted to the grid system with rich re-
sources but lower computing power. In case 2, the same task is submitted to the grid 
system with fewer resources but higher computational power. For cases 1 and 2, all 
the jobs are only executed in the local grid system. In case 3, the same task is submit-
ted to the G2G system that contains both grid systems. In this case, jobs will be exe-
cuted in the local grid or the remote grid according to the decision made by the G2G 
scheduler and G2G allocator that we described in Section 3.3.6.  
Fig. 3 shows the experimental results of three cases. The experimental results show 
that the proposed meta-grid framework could improve the system performance in the 
G2G system. In general, a grid system with rich resources could finish a task with less  
 
 G2G: A Meta-Grid Framework for the Convergence of P2P and Grids 141 
References 
1. Cao, J., Liu, F.B., Xu, C.-Z.: P2PGrid: Integrating P2P Networks into the Grid Environ-
ment: Research Articles. Concurr. Comput.: Pract. Exper. 19, 1023–1046 (2007) 
2. Chervenak, A., Foster, I., Kesselman, C., Salisbury, C., Tuecke, S.: The Data Grid: To-
wards an Architecture for the Distributed Management and Analysis of Large Scientific 
Datasets. Journal of Network and Computer Applications 23, 187–200 (2000) 
3. Czajkowski, K., Fitzgerald, S., Foster, I., Kesselman, C.: Grid Information Services for 
Distributed Resource Sharing. In: 10th IEEE International Symposium on High Perform-
ance Distributed Computing, pp. 181–194. IEEE Press, New York (2001) 
4. Fitzgerald, S., Foster, I., Kesselman, C., von Laszewski, G., Smith, W., Tuecke, S.: A Di-
rectory Service for Configuring High-Performance Distributed Computations. In: Sixth 
IEEE International Symposium on High Performance Distributed Computing, pp. 365–
375. IEEE Press, Los Alamitos (1997) 
5. Foster, I., Iamnitchi, A.: On Death, Taxes, and the Convergence of Peer-to-Peer and Grid 
Computing. In: Peer-to-Peer Systems II, pp. 118–128 (2003) 
6. Foster, I., Kesselman, C., Tsudik, G., Tuecke, S.: A Security Architecture for Computa-
tional Grids. In: 5th ACM Conference on Computer and Communications Security, pp. 
83–92. ACM, San Francisco (1998) 
7. Foster, I., Kesselman, C., Tuecke, S.: The Anatomy of the Grid: Enabling Scalable Virtual 
Organizations. International Journal of High Performance Computing Applications 15, 
200–222 (2001) 
8. Foster, I., Kesselman, C., Nick, J.M., Tuecke, S.: The Physiology of the Grid: An Open 
Grid Services Architecture for Distributed Systems Integration. Technical Report. Global 
Grid Forum (2002), 
http://www.globus.org/alliance/publications/papers/ogsa.pdf 
9. Fox, G., Pallickara, S., Rao, X.: Towards Enabling Peer-to-Peer Grids. Concurr. Comput.: 
Pract. Exper. 17, 1109–1131 (2005) 
10. Mastroianni, C., Talia, D., Verta, O.: A Super-Peer Model for Resource Discovery Ser-
vices in Large-Scale Grids. Future Generation Computer Systems 21, 1235–1248 (2005) 
11. Mastroianni, C., Talia, D., Verta, O.: Evaluating Resource Discovery Protocols for Hierar-
chical and Super-Peer Grid Information Systems. In: 15th Euromicro International Confer-
ence on Parallel, Distributed and Network-Based Processing, pp. 147–154. IEEE Press, 
Los Alamitos (2007) 
12. Pallickara, S., Fox, G.: NaradaBrokering: A Distributed Middleware Framework and Ar-
chitecture for Enabling Durable Peer-to-Peer Grids. In: Endler, M., Schmidt, D.C. (eds.) 
Middleware 2003. LNCS, vol. 2672, pp. 998–999. Springer, Heidelberg (2003) 
13. Talia, D., Trunfio, P.: Toward a Synergy between P2P and Grids. Internet Computing 7, 
96–95 (2003) 
14. Yang, B., Garcia-Molina, H.: Designing a Super-Peer Network. In: 19th International Con-
ference on Data Engineering, pp. 49–60 (2003) 
15. Po-Chi, S., Hsi-Min, C., Yeh-Ching, C., Chien-Min, W., Ruay-Shiung, C., Ching-Hsien, 
H., Kuo-Chan, H., Chao-Tung, Y.: Middleware of Taiwan UniGrid. In: 2008 ACM sym-
posium on Applied computing, pp. 489–493. ACM, Fortaleza (2008) 
16. JXTA Community Projects, https://jxta.dev.java.net/ 
load balance, and the impacts of various workloads on 
SARIDS. The experimental results prove that the SARIDS is 
efficient and could improve the load balancing. 
The remainder of this paper is organized as follows. In 
Section II, we discuss related works. Then, we briefly 
describe the system overview in Section III and give the 
detailed design of the SARIDS in Section IV. The simulation 
results are presented in Section V. We give final conclusions 
in Section VI. 
II. RELATED WORK 
Many P2P-based resource sharing schemes have been 
proposed in the literature to overcome the shortcomings of 
centralized or hierarchical approaches. Recently, the 
structured P2P network model is widely adopted for resource 
discovery approaches in large scale distributed systems. 
Many structured P2P approaches [1, 10, 11, 15] use the 
locality preserving hash function to support multi-attribute 
range queries. 
In the MAAN approach [10], one DHT is constructed for 
each attribute and all of these DHTs are mapped onto the 
same overlay. However, the MAAN knows the distribution 
of the attribute values in advance for balancing the load 
among peers. In the SWORD strategy [11], each attribute is 
assigned a different sub-region of a common DHT. However, 
the load balancing mechanism in SWORD is less efficient in 
an environment with a non-uniform distribution of peer 
ranges. In the Mercury approach [1], one DHT is constructed 
for each attribute, and each of these DHTs is randomly 
mapped to a subset of peers in this system. However, the 
Mercury doesn’t support the functions of adding and 
removing attributes in the system and doesn’t consider the 
load balance among intra-overlays. In the Squid strategy [15], 
one DHT is constructed for all attributes and the Squid uses 
the dimensionality reducing indexing scheme to map the 
multi-dimensional information space to physical peers while 
preserving the lexical locality and supporting complex 
queries. However, when the dimensionality of the 
information space is greater than five, the locality preserving 
property of Spacing Filling Curve (SFC) begins to 
deteriorate and the querying response time increases. 
Compared to the aforementioned, SARIDS can 
dynamically adapt the load balancing according to the real 
situation of system load. Besides, SARIDS can balance the 
load even in the environment with a non-uniform distribution 
of peer ranges, support the functions of adding and removing 
attributes in the system, and consider the load balance among 
intra-overlays. 
In this paper, we propose two load balancing mechanisms 
for our two-tier architecture in the large scale resource 
sharing system with different sharing policies and 
heterogeneous resources. The intra-overlay load balancing 
mechanism adopts a leave-rejoin-style protocol which is 
similar to that in [8, 13]. However, this protocol only works 
well when it can contact each peer randomly. When the 
distribution of peer ranges is highly-skewed in an overlay, 
this approach is far from trivial. The previous study [8] 
proposes two solutions to solve the above problem. One is to 
enable every peer to maintain a virtual peer without storing 
any data item and without changing its position. Then, the 
proposed mechanism [8] can select a random peer by a 
random ID and route this random ID to the corresponding 
virtual peer. The other is to use the random skip list as an 
alternate routing infrastructure, such as Skip Graphs [2] or 
SkipNet [5]. However, these approaches need to maintain an 
additional overlay with extra cost. In this paper, we propose 
a leave-rejoin-style protocol based on a random-walk for the 
intra-overlay load balancing. This mechanism works well 
even in an environment with highly-skewed peer range 
distribution, and brings no extra overhead. 
III. SARIDS OVERVIEW 
This section presents an overview about the SARIDS. 
We begin with a briefly introduction of the system 
architecture before describing the detailed mechanisms. 
A. System Architecture 
The SARIDS is constructed by a two-tier architecture, as 
shown in Fig. 1. The inter-overlay is constructed by super-
peers while the intra-overlay is constructed by normal peers. 
A super-peer represents an entry for one intra-overlay. When 
a query or publishing information is issued, it starts to route 
in the inter-overlay for finding the super-peer with the 
specified attribute. Then, the request is routed to the 
dedicated intra-overlay through that super-peer and locates 
the normal peers with the matched values. 
In SARIDS, each resource is described by a set of 
attribute-value pairs. Each pair is a form of (attribute name, 
value, resource location). For example, a pair (CPU_Speed, 
2GHz, 192.168.1.11) represents the resource with 2GHz 
CPU speed. This pair describes the values of a resource 
attribute and the provider. Although we use the IP address as 
the resource location in this example, this field could be 
extended to present the other forms for the resource location.  
A query is also described by a set of attribute-value pairs, 
such as (attribute name, min value, max value). Besides, 
each query has an additional field which is the number of 
results satisfying the user’s requirement. This approach can 
also easily support the operators as follows: ≦, ≧, ＜, ＞ 
and ＝. 
 
Figure 1.  Overview of SARIDS overlay architecture. 
522
Authorized licensed use limited to: National Tsing Hua University. Downloaded on May 26,2010 at 10:45:48 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 3 shows an example for our routing mechanism. The 
query with the key 113167 routes to the super-peer which is 
correspond to the CPU speed with ID = 110000 at first. Then, 
the query would be passed to the normal peer with ID = 
113511. Then, the peer discovers its right-hand side and left-
hand side for the requested range by the bidirectional 
searching method. On the other hand, when a peer tries to 
provide resource information, it would publish the 
information to all corresponding intra-overlays according to 
its providing information. In this case, the resource 
information would be passed to the super-peers with ID = 
680000 and 110000, and is stored at the corresponding 
normal peers ID = 684156 and 119245, respectively. 
A. Intra-overlay Construction and Destruction 
Because the categories of attributes are different in 
distinct sharing policies, we propose an adaptive mechanism 
for constructing and destructing the intra-overlay. In general, 
the resource information is published to the corresponding 
intra-overlay. In the case of an attribute is only published or 
provided by very few providers, there is no corresponding 
intra-overlay. Because the load of the attribute is very light, 
this attribute is only stored temporality on a super-peer with 
a following attribute key. Therefore, this paper defines the 
temporary attribute as an attribute with a light load, and the 
primary attribute as an attribute for a dedicated intra-overlay. 
To accommodate the dynamic construction and 
destruction of the overlay, each super-peer estimates the 
global average load ρ which denotes the number of data 
items and the parameter β which denotes the threshold of 
deciding the current load status of the intra-overlay. If the 
number of resource information of a temporary attribute in a 
super-peer is greater than ሺ1 ൅ ߚሻߩ , where β < 1, this 
attribute would be a primary attribute. Then, the super-peer 
would select a new super-peer from an under-loaded intra-
overlay. This new super-peer maintains the new primary 
attribute and given a new ID by hashing this primary 
attribute name. The other loads of temporary attributes which 
IDs are less than this new primary attribute would also be 
transferred to this new super-peer. Then, the new selected 
super-peer joins the inter-overlay resulting in a new intra-
overlay. When the load of partial temporary attributes is 
greater than ሺ1 ൅ ߚሻߩ, the super-peer only chooses a new 
super-peer as its predecessor and transfers these loads of 
temporary attributes to that predecessor. 
In some cases, SARIDS would destruct the 
corresponding intra-overlay when the load of a primary 
attribute is vanished. If the total load of this peer is less than 
ሺ1 െ ߚሻߩ, the intra-overlay would be destructed. The load of 
this peer includes the load of the primary attribute and the 
load of temporary attributes. Then, this primary attribute 
would be degraded to a temporary attribute. All resource 
information in this peer would be transmitted to its successor 
in the inter-overlay. After the transferring operation uses the 
underlying Chord infrastructure, this peer rejoins the system. 
B. Load Balancing 
The SARIDS proposes an inter-overlay load balancing 
mechanism to redistribute peers among intra-overlays and 
also enhances the leave-rejoin-style mechanism to balance 
the load in the intra-overlay with a non-uniform distribution 
of peer ranges. We introduce the collection approaches for 
the load information in the SARIDS before describing the 
detailed load balancing mechanisms. 
1) Clockwise Information Collecting Method: Each 
super-peer uses a clockwise information collecting method 
to gather the load information in its intra-overlay. This load 
information includes the total number of peers and the total 
number of resource information.  
To gather the load information, a message is issued from 
a super-peer and then continuously passed to the successor in 
the intra-overlay until this message is sent back to the 
requested super-peer. This message computes the total 
number of peers and aggregates the total number of resource 
information in the intra-overlay. According to the collected 
information, super-peers can calculate the local average load 
and the global average load. Besides, this method is 
compatible with the stabilization process or the predecessor 
checking process of the Chord without extra overhead. When 
a peer joins or leaves the intra-overlay, it would notify its 
super-peer for precisely gathering the local average load. 
Then, the super-peer re-computes the local average load. 
2) Inter-overlay Load Balancing Mechanism: The load 
balancing mechanism in the inter-over has two operations 
for generating the global average load by random sampling, 
and for redistributing peers in different intra-overlays 
according to the average local/global load.  
In the first operation, each super-peer generates random 
keys and routes these keys to the corresponding super-peers. 
Then, these super-peers reply the load information of its 
intra-overlay. The experimental results show that the inter-
overlay load balancing mechanism works well by sampling 
log ܰ  peers randomly. Our mechanism adopts the similar 
method in [1] to collect most recent log ܰ  global average 
load, where N is the size of inter-overlay. The global average 
load equals the total number of resource information divided 
by the total number of peers in the most recent samples. 
In the second operation, SARIDS defines a bound β as 
the threshold to decide the load status of an intra-overlay. 
The β can help the system to bear dynamic peer joining and 
leaving, and to avoid unnecessarily redistributing a peer for 
resource information publishing and vanishing. To simply 
describe the status of an intra-overlay, let fLOAD denote as the 
following: 
 oadGlobalAvgLoadGlobalAvgLadLocalAvgLofLOAD /−= .  
When fLOAD is equal to or less than β, the load status of 
intra-overlay is balancing; when fLOAD is larger than β and the 
local average load is less than the global average load, the 
load status of the intra-overlay is light; when fLOAD is larger 
than β and the local average load is also larger than the 
global average load, the load status of the intra-overlay is 
heavy. 
Each super-peer decides the load status in its intra-
overlay. Then, the super-peer with the heavily loaded intra-
524
Authorized licensed use limited to: National Tsing Hua University. Downloaded on May 26,2010 at 10:45:48 UTC from IEEE Xplore.  Restrictions apply. 
  
Figure 6.  Intra-overlay load balancing in the non-uniform distribution of 
peer ranges. 
VI. CONCLUSION 
In this paper, we propose a self-adaptive resource index 
and discovery system, named SARIDS, for large scale 
distributed resource sharing systems with heterogeneous 
resources and different sharing policies. Our SARIDS not 
only supports the multi-attribute range queries but also 
balances the system load efficiently. In SARIDS, we propose 
a sampling-based mechanism to balance the load in the inter-
overlay, and introduce a leave-rejoin-style protocol based on 
a random-walk for the intra-overlay load balancing. By these 
mechanisms, the load of each peer is almost equal in the 
whole system even in the environment with a highly-skewed 
resource distribution. Our simulation results show that 
SARIDS supports multi-attribute range queries with well 
scalability and good load balance, and works well even in a 
non-uniform distribution of peer ranges. 
ACKNOWLEDGMENT 
This work is partially supported by National Science 
Council of the Republic of China under contract NSC 96-
2221-E-007-130-MY3 and NSC 97-3114-E-007-001. The 
authors would like to express their gratitude to the 
anonymous reviewers for their review and suggestions. 
 
 
 
 
 
 
REFERENCES 
[1] R. B. Ashwin, A. Mukesh, and S. Srinivasan, "Mercury: Supporting 
Scalable Multi-Attribute Range Queries," in ACM SIGCOMM 
Computer Communication Review. vol. 34, 2004, pp. 353-366. 
[2] J. Aspnes and G. Shah, "Skip Graphs," in Proceedings of the 
Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, 
2003, pp. 384-393. 
[3] Y. Z. Ben, D. K. John, and D. J. Anthony, "Tapestry: An 
Infrastructure for Fault-tolerant Wide-area Location and Routing," TR 
CSD-01-1141, University of California at Berkeley 2001. 
[4] Gnutella, 
"http://www9.limewire.com/developer/gnutella_protocol_0.4.pdf". 
[5] N. J. A. Harvey, M. B. Jones, S. Saroiu, M. Theimer, and A. Wolman, 
"SkipNet: A Scalable Overlay Network with Practical Locality 
Properties," in Proceedings of the Fourth USENIX Symposium on 
Internet Technologies and Systems, 2003, pp. 113-126. 
[6] A. Iamnitchi and I. Foster, "On Fully Decentralized Resource 
Discovery in Grid Environments," in Grid Computing — GRID 2001, 
2001, pp. 51-62. 
[7] S. Ion, M. Robert, K. David, M. F. Kaashoek, and B. Hari, "Chord: A 
Scalable Peer-to-Peer Lookup Service for Internet Applications," in 
Proceedings of the ACM SIGCOMM, 2001, pp. 149-160. 
[8] D. R. Karger and M. Ruhl, "Simple Efficient Load-Balancing 
Algorithms for Peer-to-Peer Systems," in Theory of Computing 
Systems, 2006, pp. 787-804. 
[9] Kazaa, "http://www.kazaa.com". 
[10] C. Min, F. Martin, C. Jinbo, and S. Pedro, "MAAN: A Multi-
Attribute Addressable Network for Grid Information Services," in 
Proceedings of the Fourth International Workshop on Grid 
Computing, 2003, pp. 184-191. 
[11] D. Oppenheimer, J. Albrecht, D. Patterson, and A. Vahdat, Scalable 
Wide-Area Resource Discovery: TR CSD-04-1334, EECS 
Department, University of California, Berkeley, 2004. 
[12] R. Ranjan, A. Harwood, and R. Buyya, "Peer-to-Peer-Based Resource 
Discovery in Global Grids: A Tutorial," IEEE Communications 
Surveys & Tutorials, vol. 10, pp. 6-33, 2008. 
[13] A. Rao, K. Lakshminarayanan, S. Surana, R. Karp, and I. Stoica, 
"Load Balancing in Structured P2P Systems," in Peer-to-Peer 
Systems II, 2003, pp. 68-79. 
[14] A. Rowstron and P. Druschel, "Pastry: Scalable, Decentralized Object 
Location, and Routing for Large-Scale Peer-to-Peer Systems," in 
Proceedings of the Middleware, 2001, pp. 329-350. 
[15] C. Schmidt and M. Parashar, "Squid: Enabling search in DHT-based 
systems," Journal of Parallel and Distributed Computing, vol. 68, pp. 
962-975, 2008. 
[16] R. Sylvia, F. Paul, H. Mark, K. Richard, and S. Scott, "A Scalable 
Content-Addressable Network," ACM SIGCOMM Computer 
Communication Review, vol. 31, pp. 161-172, 2001. 
[17] P. Trunfio, D. Talia, H. Papadakis, P. Fragopoulou, M. Mordacchini, 
M. Pennanen, K. Popov, V. Vlassov, and S. Haridi, "Peer-to-Peer 
Resource Discovery in Grids: Models and Systems," Future 
Generation Computer Systems, vol. 23, pp. 864-878, 2007. 
 
 
SARIDS Traditional Non-balanced
Std. deviation 85.04614172 246.9494724 292.4238574
526
Authorized licensed use limited to: National Tsing Hua University. Downloaded on May 26,2010 at 10:45:48 UTC from IEEE Xplore.  Restrictions apply. 
出席國際學術會議報告 
出席人員：羅世翔 
國立清華大學資訊工程學系  學生 
會議名稱：UKSim 2010 - International Conference on Computer Modelling and Simulation  
一、主要任務摘要 
參與會議並發表論文 A Scalable HLA RTI System based on Multiple-FedServ 
Architecture。 
二、經過 
UKSim 2010 - International Conference on Computer Modelling and Simulation，於 2010
年 3月 24日至 3月 26日在英國倫敦舉辦。除了發表論文A Scalable HLA RTI System based 
on Multiple-FedServ Architecture 之外，亦參加了會議的 session 及 keynote speech，以期瞭
解目前世界上各個研究單位在模擬技術以及應用領域最新的研究方向以及成果。會議
session 的主題包含了以下內容： 
- Intelligent Systems 
- Hybrid Intelligent Systems (& Hybrid Soft Computing) 
- e-Science and e-Systems 
- Methodologies, Tools and Operations Research  
- Bio-informatics and Bio-Medical Simulation 
- Discrete Event and Real Time Systems 
- Image, Speech and Signal Processing 
- Industry, Business and Management     
- Human Factors and Social Issues 
- Engineering, Manufacturing and Control  
- Energy, Power Generation and Distribution   
A Scalable HLA RTI System based on Multiple-FedServ Architecture 
Ding-Yong Hong, Fang-Ping Pai, Shih-Hsiang Lo and Yeh-Ching Chung 
Department of Computer Science 
National Tsing Hua University 
Hsinchu, Taiwan, R.O.C. 
{dyhong,fppai,albert}@sslab.cs.nthu.edu.tw, ychung@cs.nthu.edu.tw 
 
Abstract—A scalable and high performance RTI (Runtime 
Infrastructure) system implements a two-layer architecture to 
supporting large-scale simulation is proposed in this article. 
The two-layer architecture, Multiple-FedServ, exploits both 
centralized and distributed way to manage a simulation. In 
the first layer, each FedServ is in charge of a number of 
federates and in the second layer, a simulation federation is 
then formed by all the FedServs. This paper describes how the 
messages are routed and synchronization performed in this 
two-layer architecture. An RTI system based on Multiple-
FedServ architecture and follows the specification of IEEE 
1516 standard is implemented. Performance evaluations of 
this RTI using standard HLA/RTI benchmarks are presented. 
We evaluate the latency, throughput and time advancement 
benchmarks under varied size of federates and varied size of 
FedServs. Issues such as message routing, multicasting and 
synchronization are specially addressed in this article. Results 
show that Multiple-FedServ architecture can scale well. 
Keywords- High Level Architecture, Runtime Infrastructure, 
Multiple-FedServ, Scalability, Large-scale Simulation. 
I.  INTRODUCTION  
In the 1990s, Defense Modeling and Simulation Office 
(DMSO) [10] first proposed High Level Architecture (HLA) 
in order to promote reusability and interoperability of 
military simulations. HLA has been approved as IEEE 1516 
standard in September 2000. There are three necessary 
elements defined in HLA, the rules, interface specification 
and object model template (OMT) [7]. According to the 
HLA rules users can develop cooperating simulations, 
called federates. Federates can interact with each other by 
invoking sets of management service provided by Runtime 
Infrastructure (RTI). The integrated virtual environment 
composed of federates is called federation.  Recently, 
besides military applications, many simulations such as 
traffic simulations, factory workflow simulations and so 
forth use the HLA as simulation architecture.  
The RTI system provides a set of management services 
defined in the HLA interface specification. The execution 
management, time synchronization, data and event 
exchange of the federation are all handled by the 
coordination of these services. As the scale of simulation 
grows, the scalability issue of RTI is becoming more and 
more important especially for wide-ranging and large-scale 
complex simulations. This article will focus on the 
scalability problems of RTI and will address the architecture 
we adopted to implement our scalable RTI. 
The related works reported in the literature rarely take 
account of the scalability issues of an RTI system. Although 
[3], [9] and [12] propose the schemes for simulation users to 
easily construct a large-scale HLA simulation in terms of 
federate arrangement and resource management. Among 
these RTI systems, a centralized management is used to 
conduct the RTI services. That is, the RTI system uses a 
centralized manager or server to carry out the RTI services, 
such as joining and resigning of federates, data exchange for 
participating federates, etc. For a federation execution with 
a large amount of federates, the centralized manager tends 
to be overloaded because of busy processing the requests of 
the federates. In this situation, the centralized management 
will degrade the simulation performance. Also, it may cause 
a scalability bottleneck of the whole RTI system and limits 
the capacity of how many federates that can participate in a 
federation.  
Considering the loading of a RTI system, two 
requirements are necessary to build a scalable RTI system 
for a large-scale simulation. One is that the RTI system 
must have enough capability to manage the federation 
execution. The other one is that the overloaded situation 
must be avoided. In order to achieve these two requirements, 
we design a hybrid architecture called Multiple-FedServ. 
First, we adopt a centralized server called FedServ as the 
basis to provide RTI services federates belongs to this 
server. The responsibility of a FedServ is to manage the 
joining and resigning of federates, and to facilitate data 
exchange among participating federates, etc. Since it has the 
central control of the system, the performance of the 
centralized management is better than the distributed 
management. Then we make several replicas of the FedServ 
and these FedServs will form a Multiple-FedServ RTI 
system to serve all federates within the federation. The RTI 
system becomes more powerful to serve more federates 
simply by integrating the capability of each FedServ. These 
FedServs cooperate in forming a powerful RTI system to 
manage all the federates. Moreover, the loading of 
managing a federation execution can be distributed to these 
FedServs. This prevents any FedServ from being 
overloaded.  
The proposed Multiple-FedServ architecture has several 
advantages. First, our architecture can provide scalability 
and also preserve the performance. Second, based on our 
connection scheme, the system is well-organized and 
suitable for a large-scale simulation. Third, the Multiple-
FedServ design is helpful for the operations of multicast and 
synchronization with numerous federates. 
Based on the proposed architecture, we have 
implemented a RTI system following the specification of 
IEEE 1516 standard. Moreover, we have evaluated our RTI 
In our implementation, the decisions of how many 
FedServs are in a federation and how to connect the 
FedServs and federates are determined by the users. The 
users have the best knowledge about the behavior and 
execution loading of the simulation programs. Therefore, 
the users can have the best way to arrange the execution 
loading. As the numbers of federates increase in the runtime, 
the system can still execute well by increasing the numbers 
of FedServs. 
B. Two-layer ID Assignment Scheme 
When a federate joins a federation, the RTI system must 
assign the federate a unique ID in the simulation 
environment. For a single FedServ design, the centralized 
FedServ must serve the ID assignment requests from all the 
federates. For a fully distributed design, the system must 
enter a global locking state to decide the next available 
globally unique ID. When a simulation is running with 
considerable federates, neither centralized nor fully 
distributed design is suitable for the high-scalability 
simulation requirement. 
In our Multiple-FedServ architecture, the assignment 
service is provided by these FedServs cooperatively. In 
order to efficiently get a globally unique ID, we use a two-
layer ID assignment scheme. When a federate joins a 
FedServ, the FedServ will assign it a pair of numbers of the 
form (FedServ_ID, Local_Federate_ID), where the 
FedServ_ID is the ID of the FedServ and the 
Local_Federate_ID is a unique ID in the group of the 
FedServ. After the assignment process, the FedServ 
broadcasts the ID to other FedServs so every FedServ can 
know that a new federate has joined the federation. The 
following describes how to generate the FedServ_ID and 
Local_Federate_ID for FedServs and federates, respectively.  
The first FedServ created in a federation execution 
becomes the master FedServ and it will be assigned to ID 0. 
The other FedServs created after master FedServ in the 
same federation will become slave FedServs with ID 
starting from 1. In figure 2, there are one master FedServ 
and two slave FedServs which are assigned to ID 0, 1, and 2 
respectively, and three federates connect to Master FedServ, 
two federates connect to Slave FedServ 1 and two federates 
connect to Slave FedServ 2. 
 
 
Figure 2.  An example of two-layer ID assignment. 
To generate Local_Federate_ID for each federate, every 
FedServ maintains a local federate ID counter starting from 
1. Each time a federate joins a FedServ, it will concatenate 
its FedServ ID and the value of local federate ID counter as 
the ID of the newly joint federate and then increases the 
number of the counter by one. With this mechanism, we can 
make sure that any federate ID is certainly globally unique. 
For example, in figure 2, assume the three federates in the 
left-hand side join the federation with the order from the top 
to the bottom. Initially the local federate counter ID is set to 
1. When the Master FedServ receives the joining request 
from the top-left federate, it assigns its ID to (0,1) and 
increases the counter to 2. This assignment process is 
repeated when the mid-left and bottom-left federates join it 
and finally the value of counter is 4. The same assignment 
process is executed in the groups of the FedServs in the 
right-hand side. We can see that no any two federate IDs 
will be the same. 
The two-layer ID assignment scheme has the following 
advantages: First, the assignment process is finished locally 
in each group so the joining process is efficient. Second, 
every FedServ only has to handle the joining requests from 
parts of federates. This design can reduce the loading of 
each FedServ. Third, no any global locking is required 
among the FedServs. The overhead of global locking is 
avoided. Finally, the FedServs in different groups can 
handle different joining requests simultaneously. The 
performance is improved especially when a lot of federates 
are joining the federation at the same time. 
C. Message Routing and Multicast 
When a federate requests the RTI services of 
UpdateValue or SendInsteraction, the message has to be 
multicast to those federates which are interested in this 
event. The multicast operation consists of the following 
steps. 
1. The source federate sends the message to the 
FedServ in the same group. This FedServ becomes 
the source FedServ. 
2. The source FedServ determines the federates that 
will receive the message according to the 
publish/subscribe relationship. 
3. The source FedServ analyzes the two-layer IDs of 
the destination federates and finds the destination 
FedServs that consist of these destination 
federates by the FedServ_ID. 
4. The source FedServ sends the message to each 
destination FedServ. 
5. Every destination FedServ determines the local 
federates which will receive the message 
according to the publish/subscribe relationship. 
6. The destination FedServ sends the message to 
those local federates. 
From the operation in step 3, the message is transferred 
between two FedServs only once and the network traffic is 
reduced. Moreover, the operation of multicast from the 
destination FedServs to the destination federates in different 
groups can be done in parallel. Therefore, the Multiple-
FedServ architecture is efficient for the multicast operation. 
Master 
FedServ
(0)
Slave
FedServ
(1)
Federate
(0,1)
Federate
(0,2)
Federate
(0,3)
Federate
(1,2)
Federate
(1,1)
counter=4
counter=3
Slave
FedServ
(2) Federate
(2,2)
Federate
(2,1)
counter=3
From table 1, the one-hop latency of our architecture is a 
little longer than the latency of DMSO RTI. The three-hop 
latency of our architecture is about 2.5 times slower than the 
latency of DMSO RTI. From table 2, the one-hop 
throughput of our architecture is lower than DMSO RTI in 
the cases where message size is smaller than 64Kbytes. But 
when the size of an attribute value is greater than 256Kbytes, 
the throughput of our design and DMSO RTI are similar 
and both designs can achieve 40 Mbytes per second. The 
performance of three-hop throughput is about 28 Mbytes 
per second when the size of attribute value is greater than 
256 Kbytes. 
B. Time Advancement Benchmark 
The time advancement program measures RTI 
performance in terms of the rate at which time advance 
requests are granted. We set the number of federates in a 
federation execution to {4, 8,…, 256, 512} and all other 
parameters are set to the default values. The DMSO RTI-
NG1.3v6 cannot support more than 64 federates participating 
in a federation due to its design of joining a federation. 
In our RTI implementation, a conservative 
synchronization protocol [6] is used in time management. 
We test the total grants per second of our RTI system under 
1, 2 and 4 FedServs respectively and each FedServ will 
manage the same number of federates. The results are 
shown in figure 4. In figure 4, MF(k) means that there are k 
FedServs in a federation execution. For the case where 
number of federates is 4, we can see the total grants of our 
RTI system using one FedServ is larger than two or four 
FedServs. But when the number of federates is greater than 
32, using four FedServs in a simulation can achieve the 
better results than one FedServ and two FedServs because 
the loading of the RTI system is shared among the FedServs. 
The results show that we can just add more FedServs in the 
RTI system to support more federates and also preserve the 
performance. 
C. Multicast 
The performance of the multicast operation is evaluated 
by one sending federate and several receiving federates. The 
sending federate is responsible to send an interaction 
parameter to each receiving federate and each receiving 
federate sends the interaction parameter back to the sending 
federate when receiving it. The elapsed time of the 
operation is recorded. We set the size of the interaction 
parameter to 1 Kbytes and 64 Kbytes, and set the number of 
the receiving federates in a federation execution to {4, 8, …, 
128, 256}. The test is executed 100 iterations and the 
average value is calculated. The performance results are 
shown in Fig. 5 and Fig 6. 
The results in Fig. 5 and Fig. 6 show that as the number 
of federates increases, the elapsed time of multicast will be 
further reduced by increasing the number of FedServs. More 
FedServs involved in the operation of multicast will improve 
the parallelism in the message transmission from the FedServs 
to the federates and the performance is better in our Multiple-
FedServ architecture. 
 
 
 
Figure 4.  Performance of time advancement benchmark. 
 
Figure 5.  Performance of time advancement benchmark. (message size = 
1 Kbytes) 
 
Figure 6.  Performance of time advancement benchmark.(message size = 
64 Kbytes) 
D. Synchronization 
The performance of the synchronization operation is 
evaluated in terms of the elapsed time to synchronize 
specified number of federates. The elapsed time is 
calculated starting from the registration of a synchronization 
point to the point that all federates are synchronized. We set 
the number of the federates joining the operation of 
synchronization in a federation execution to {4, 8,…, 128, 
256}. The test is executed 100 iterations and the average 
value is calculated. The results are shown in Fig. 7. 
0
100
200
300
400
500
4 8 16 32 64 128 256 512
G
ra
n
ts
/S
e
c
Number of Federates
MF(1) MF(2) MF(4)
0
500
1000
1500
4 8 16 32 64 128 256
m
s
e
c
Number of Federates
MF(1) MF(2) MF(4)
0
250
500
750
1000
1250
1500
1750
2000
4 8 16 32 64 128 256
m
s
e
c
Number of Federates
MF(1) MF(2) MF(4)
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
