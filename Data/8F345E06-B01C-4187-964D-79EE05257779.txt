preprocessing, and adopts inter-model prediction to 
realize 3D motion estimation, thus getting more 
efficient compression. 
 
  
Keywords: stereoscopic video, multi-view video, 
free viewpoint video, video compression, depth 
image, DIBR, 3DMC, 3D mesh 
 
 
二、 緣由與目的 
在本期計劃的第一年 (全程計畫的第二年)，
我們的研發重點在於多視域視訊之壓縮。在影像擷
取端以攝影機陣列的方式，取得多視域視訊資料
後，利用攝影機參數與深度資訊影像來輔助壓縮編
碼，以提高編碼壓縮效率。解碼端將收到的壓縮資
料解碼後，可以利用重建後的多視域影像及深度影
像來進行 Novel- view 的合成，以提供使用者由不
同角度觀看視訊，達到互動式播放的目的。多視域
視訊的壓縮技術將來可以應用至 3DTV、free-view 
point TV (FTV)，以及互動式視訊撥放，是目前視
訊編碼發展的重點之一。 
現行的視訊拍攝方式多是以單一攝影機拍攝
的方式，使用者在觀看視訊內容時，只能跟著攝影
機拍攝時的拍攝路徑，使用者觀看的角度是由攝影
機所主導的，然而這種拍攝的方式已經漸漸無法滿
足現代人的求知慾望，尤其是對於某些形式的視
訊，例如：球賽影片、舞蹈影片，或是教學用影片
等，從單一的角度觀看限制了使用者能獲得的資
訊，多攝影拍攝的方式也因此逐漸重要。 
多架攝影機的擺設方式可以有許多種 (參考
圖 2.1)。由於多視域視訊的資料量比起一般的視訊
還要多出許多，在有限的硬體空間之下，多視域視
訊的壓縮編碼是勢在必行的，多視域視訊資料除了
有時間上的冗餘資訊 (temporal redundancy) 外，
相鄰攝影機所拍攝到的影像會有重疊的部份，因此
還 存 在 著 空 間 上 的 冗 餘 資 訊 (inter-view 
redundancy)。目前主流的單一攝影機的視訊編碼標
準，如 MPEG-2、MPEG4，以及 H.264/AVC…等，
皆 是 以 移 動 向 量 補 償 (motion estimation/ 
compensation)的方式來消除 temporal redundancy，
但要如何有效去除 inter-view redundancy，這是多
視域視訊編碼所要討論的重點之一。 
多視域視訊編碼使用 inter-view prediction 的
方式來去除 inter-view redundancy [1]，目前所普遍
採用的 inter-view prediction 方式主要可分為兩
類：(1) 視差搜尋估測 (Disparity estimation) (2) 影
像合成式估測  (View synthesis prediction) 。
Disparity estimation 的 方 式 是 以 類似 motion 
estimation 的方式，在 inter-view 的方向上搜尋最
佳的預測區塊，由於 disparity estimation 是假設目
前要進行編碼的區塊 (current block)，在 inter-view
方向上為單純的平移 (translation)，對於攝影機非
平行擺設的狀況下，兩個攝影機間的 epipolar line 
並非為水平線，這將使得 disparity estimation 的精
確度打折扣。一般是採用 pre-warping 或 image 
rectification 方式先將兩張影像轉正，使其僅具備
水平方向的 disparity。View synthesis prediction 的
方式主要可以分成兩類，一種是使用和 current 
view 相鄰的兩個 view 的影像來合成 current view
的預測影像，另一種為使用 one view 影像以及其
深度資訊影像 (depth image) 來合成 current view
的預測影像。使用 view synthesis prediction 的方式
可以模擬非平移的移動方式，因此比起 disparity 
estimation 可以更精確的預測 inter-view 的位移。 
 
(a) (b) 
(c) (d)  
圖 2.1. 多攝影機擺設方式 
(a). 平行擺設 (b). 弧狀擺設 
(c). 環狀擺設 (朝向中心) 
(d). 環狀擺設 (朝向外) 
 
由 ITU-T Video Coding Experts Group (VCEG) 
以 及  ISO/IEC Moving Picture Experts Group 
(MPEG) 所組成的 JVT 組織，已經釋出了多視域
視訊編碼平台 JMVM。JMVM 是以 H.264 編碼標
準為基礎發展的多視域視訊編碼平台，採用混合視
差 預 測 與 運 動 預 測  (Disparity Compensation 
Prediction and Motion Compensation Prediction) 的
聯合預測多視域視訊壓縮編碼系統  (Joint 
Prediction Stereoscopic Video Coding)，圖 2.2 為
JMVM 所採用的 Hierarchical B picture 的預測編碼
架構。 
 
圖 2.2  Hierarchical B pictures in JMVM 
 
本期計劃第一年(全程第二年) 所提出的多視
 2
 ( ) )(,,,
1
)( 1 cTyxtcDy
x
AcR
w
v
u
+⋅
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
⋅⋅=
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
−
   (3.1) 
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
−
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
⋅⋅=
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
− )'()()'(
'
'
'
1 cT
w
v
u
cRcA
z
y
x   (3.2) 
Camera A 
Camera B 
 
(c) Difference image between (a) and (b) 
圖 3.4  DIBR based inter view prediction 模擬 
圖 3.4 (b) 畫面中，在中間舞者的邊緣的黑色區
域，即是 occlusion 區域，圖 3.4 (c)是我們將圖 3.4 
(a)與圖 3.4 (b) 扣除 occlusion 區域之後，相減產生
的差值影像。由圖 3.4 (c) 可以看出我們做出的預
測影像與原始影像的差異頗大的。就理論上而言，
使用 DIBR 造出的預測影像應該可以和原始影像
幾乎吻合，因此我們推論，應該是攝影機校正時有
誤差，導致攝影機參數不夠精確，或是因為深度資
訊的計算方式導致深度影像不準確，才會造成預測
影像與原始影像之間的差異，這也是 DIBR based 
inter view prediction 的缺點之一：須要精確的深度
資訊與攝影機參數。因此，我們提出幾個簡單的補
償方式，以降低錯誤的深度資訊或是攝影機參數所
造成的影響。 
圖 3.3 不同攝影機間之幾何關係 
下圖 3.4 是我們以微軟所釋出的 break dancer 影像
序列的第三架和第四架攝影機模擬 DIBR based 
inter view prediction。我們將 break dancer 第四架攝
影機的影像，以 DIBR 的方式投影至第三架攝影
機，做為第三架攝影機的預測影像，如圖 3.4 所示。 
 
3.2.1 Global compensation model 
經過觀察圖 3.4(a) 與圖 3.4 (b) 後，我們覺得
製作出的預測影像和原始影像似乎存在著一個整
張畫面的平移和旋轉的差異，因此我們使用 affine 
model 來做為 global compensation model。我們在
這兩張圖中，以人工取出 8 個對應點，以 least 
square 的方式計算出 affine 參數，做為 DIBR 投影
不準確的補償，其結果如圖 3.5(a)。我們可以看出
其差異值的能量降低了許多，不過在邊緣區域還是
有些許的差異，這個可能是因為深度資訊或是攝影
機參數造成的投影誤差，並不是整體的變化，但是
使用 global compensation model 對於每一個 view
只須傳送一組 affine 參數，進行編碼時所消耗的資
料量不多，對整體的編碼效率影響較小，但是對每
一對使用 affine compensation model 的視訊，都必
須找出其對應點 (corresponding point)，才能求出
affine 參數，因此對應點的選取與配對是需要進一
步討論的課題。再者，由於視訊內容會因時間而改
變，因此對應點也會跟著時間而移動，affine 參數
也要隨著不同時間而更新。 
(a) Original image of camera 3 
(b) Predicted image of camera 3 
3.2.2 Local compensation model 
我們試著將整張畫面以 16x16 大小的 block
 4
間 t0 的重建後三維模型，右邊為時間 t1 的欲編碼
三維模型。假設 t0 已經進行完編碼，t1 的三維模
型就不進行單獨編碼，而是往前一個時刻中去做動
態搜尋 (motion search)，如圖 4.2 中藍色線所示，
試圖找到一個與自己位置最接近的頂點做為預測
源，此時我們使用的絕對誤差和 (SAD) 如(4.1)
式。 
 
zkyjxikjiSAD −+−+−=),,(     (4.1) 
其中 (i,j,k) 為現在要處理的三維模型頂點座標，
而 (x,y,z) 為前一時刻模型的頂點座標。經過與前
一時刻模型的所有頂點比對後，找到絕對誤差和
最小的，我們即認定該頂點就是目標頂點 (target 
vertex)，將其相對應的目標頂點編號 (v_index) 記
錄下來，並且立即計算自己與目標頂點座標間的
殘餘值 (x_residue , y_residue , z_ residue)，所以我
們的基本資料表示法為： 
(v_index , x_residue , y_ residue , z_ residue)  (4.2)          
其後將此資料送進適當的可變長度編碼器 (VLC, 
variable-length coding) 進行編碼壓縮。 
 
圖 4.2 三維動態估測示意圖 
 
圖 4.3  ICP 演算法示意圖 [12] 
在實際進行處理之前，使用者必須先在兩組欲
進行比較的模型裡定義一組稱為 data set，也就是
欲對準的模型。另外一組模型則稱作 model set，
這是用來當做對齊基準的資料。ICP 在經過多次
重複計算之後會找出一組最佳的幾何轉換矩陣，把 
model set (以 M 代表)對齊在 data set (以 D 代表) 
上面。可分為： 
1. 設定資料格式與停止門檻值 
2. 尋找對應點 
3. 計算幾何轉換資料 
4. 更新座標位置 
5. 計算誤差值與檢測是否停止 
等五個步驟，以下就五個步驟做細部說明。 
1. 設定資料格式與停止門檻值 
在使用 ICP 演算法之前，必須先對 data set 
與 model set 的資料型態進行設定。資料格式上 
data set 特別規定必須為點集合，在 ICP 演算法
啟動前，還需設定一個條件門檻值，停止條件門檻
值就是指每次執行完一個循環後，必須計算兩組資
料間的對正誤差值，並且計算其變化比例，如果比
條件門檻值大的話則重複執行”計算幾何轉換資
料＂(步驟 3)，反之則為停止 ICP 演算法，跳出
迴圈。 4.1.2 ICP (Iterative closest point) 法則 在程式迴圈開始執行的時候要先設定第 0 次
疊代使用的 data set Dk (k=0) =D0，D0 即為欲進行
校準的 data set，而 model set 則是設定為 M。 
在使用三維動態估測時，我們的目標是希望找
尋最佳對應之目標頂點後，藉此得到最小的殘餘
值，以便進入可變長度編碼系統時得到優良的壓縮
效果。所以我們加入了一個對齊的前處理動作。如
果可以在搜尋前，先對整體的頂點位置進行套合的
移動，讓兩模型間整體空間頂點位置差距和可以趨
小，更有利於動態估測後的壓縮編碼。 
2 尋找對應點 
設定完前置作業後，接著進行第二個步驟，尋
找對應點組合。所謂套合就是將兩組資料做整體拉
近的動作，讓兩組資料的誤差達到整體最小的目
標。首次找尋兩組間的對應點組時，如果 model set 
的資料格式也是點集合的話，那對於進行過 k 次
疊代的 data set Dk 裡的每一個點 p 來說，找到的
都是在 model set 裡距離 p 最近的點 s，是以 p 
與  s 兩點的距離  (Euclidean distance) 來決定
的，如 (4.3) 式。 
我們加入了 ICP 演算法 [11] 來進行對齊的
動作，一種使用重覆疊代運算以對齊圖形的方法，
可使用在由點、線、三角形平面、曲線或曲面等不
同的幾何結構所構成的模型上，如圖 4.3。此演算
法一開始會先拿欲進行對齊的圖形裡的所有資料
點在作為對齊基準的圖形中找出離它們距離最短
的對應點，之後再以特定的方式計算轉換矩陣，其
中包含了一個旋轉矩陣與平移矩陣。最後則是利用
該轉換矩陣處理欲進行對齊的圖形，並計算它與上
一次疊代計算結果之間的誤差值變化，若變化小於
給定的門檻值 (threshold) 則視為收斂完成。 
),(min),(
, iMs
spdMpd
∈∀ i
=         (4.3) 
總歸來說，ICP 演算法會對於 data set Dk 裡
的每一點 pi 搜尋 model set M 裡與其距離最短的
 6
在圖 4.6 中，首先進入的仍為 Fn 與重建後的 
，兩者間進行 Temporal 的動態估測，但我們
的搜尋範圍不再是全區搜尋了。其設計上是第一
個頂點的搜尋仍然使用全區搜尋，但第二個頂點
後則是在前一個頂點所找到的 v_index 上下一個
index 範圍中進行尋找。如此一來可以控制相鄰頂
點所比對到的 v_index 不會變動過大(因為我們將
使用 DPCM 的技術來編碼 v_index 的部份)。
DPCM 後 v_index 的差值較小時，則 VLC 編碼也
會較有效益。在進行完  Spatio-temporal search 
後，若所有頂點轉換誤差和大於一個設定的門檻
值，我們就必須重作全區域的 Temporal 方向動
態估測。如果小於該門檻值，則不需再進行全區
域的搜尋，直接進行下一步驟的 VLC 編碼。此
概念的實行，可以兼顧 v_index 及 residue 的編
碼 cost，以達成整體最佳的壓縮率。 
1
ˆ
n-F
4.2.2  k-means 分群 
利用 k-means 對模型頂點分群起因於我們認
為 ICP 演算法的確可以使全域的頂點經過疊代
處理後達到套合對齊的效果。然而，一旦處理的模
型是非剛體時，直接使用 ICP 演算法是不合宜
的。我們認為在這部分需先經過分群，將模型從非
剛體分類為數區塊的剛體，如圖 4.5 所示，各群頂
點再進行 ICP 演算法。 
 
 
圖 4.5  3D 網格模型分為 5群 (以色彩區分) 
4.2.3 空間-時間搜尋(Spatio-temporal search) 
Spatio-temporal search 的概念是我們除了可
以往重建後  中去尋找預測源，我們亦可在 Fn
中尋找，只是就 Fn 而言並非能全部尋找。因為在
解碼時，會有先後解碼順序的問題存在，所以在
Fn的尋找部份，我們只尋找 causal 部份的頂點 (即
排序在前，已編碼完畢的頂點)，而對於尚未處理
的頂點則不做為預測源尋找的範圍。 
1n-Fˆ
圖 4.6  包含 Local index search 的方法流程圖 
Fn 與  先進行 Temporal 方向之動態估
計 ， 假 設可 搜 尋 到一 個 頂 點  (v_index_T , 
x_residue_T , y_ residue_T, z_ residue_T)，接著，
在目前時間模型中已編碼完之頂點集合中進行搜
尋，這就是 Spatial 方向的動態估計。實際上，在
Spatial 方向上的估測並非前面全部的頂點，而僅
是往該頂點前面一段編號的頂點進行搜尋，以減
少搜尋時間 (當然這是假設頂點標號時的程序，
空間上較相鄰的頂點，其編號亦較靠近)。將這個 
Spatial 方向上搜尋到的頂點資料記為 (v_index_S, 
x_residue_S, y_residue_S, z_residue_S) 。 比 較
1
ˆ
n-F
Sz_residue_-zSy_residue_-ySx_residue_-x ++
與 Tz_residue_-zTy_residue_-yTx_residue_-x ++
之值間的大小關係，取較小者作為最後之預測
源。此即為 Spatio-temporal search 的概念與作法。 
4.2.5 改良式動態 3DMC 系統綜整 
關於改良式動態 3DMC 系統，可用圖 4.7 來
說明。第一時間的 3D 網格結構係使用 MPEG-4 
AFX-3DMC 進行壓縮，其後時間的 3D 網格結構
則往前一時刻的網格進行動態估測，對每一個頂點
進行 inter-model的預測，求得 (v_index , x_residue , 
y_ residue , z_ residue) 的資料後將其送入
MPEG-4 AFX-3DMC 的 VLC 編碼器進行壓縮編
碼，但其中的三角形資訊仍然使用 MPEG-4 AFX 
-3DMC 中所使用的 Triangle Tree 的編碼方式。
另外，MPEG-4 AFX -3DMC 是使用算術編碼算法
中基於上下文 (CX) 的 MQ 編碼器，其利用相鄰
位元之間具有較強相關性來進行預測編碼。至於網
格的相關連線資訊則仍使用  MPEG-4 AFX 
-3DMC 進行編碼。 
4.2.4 局部編號搜尋 (Local index search) 
 8
由圖 5.3 中可我們看出，全部使用 16x16，或
是 8x8 block size 的 depth 表示法，其 DIBR 的結果
比起使用 per-pixel depth 的方式還要差，這是很直
觀的結果，但是使用 variable block size 的 depth 表
示法可以逼近 per-pixel depth 的效果。由於在自然
界中，同一個物體的表面，其深度變化並不大，因
此在深度平滑的區域使用較大的 block size depth 
representation，而在深度變化大的區域使用較小的
block size，可以減少 depth 的資料量，同時也可以
降低因為 depth 的失真，造成 DIBR 的投影誤差的
現象，提升編碼效率。 
KG 誤差 
KG 誤差是在電腦繪圖領域中常見的一種量度方
式，它可以用來量度兩物體之間的誤差，並且經過
正規化後呈現的一個數值。文獻 [13] 中也提到 
KG 誤差用來量度 3D 網格模型誤差。 
nA
AA
KGE
××−
−
=
113
~
2 ]1,.....,1,1[
*100)( μ
      (5.2) 
 上式中 A 表示一個 n×3  大小的矩陣，放置原始
模型的頂點座標，n 為模型中頂點的總數，
~
A 表示
重建後的對應頂點座標，大小亦為  的矩
陣。特別在此還要計算網格頂點座標的平均值 
n×3
13×μ 。 
5.2 本期第二年計畫成果 
5.2.1 動態三維網格模型的取得 
我們所使用的3D網格模型是利用架設環場攝影機
擷取多視域視訊，再對每一時刻的多視域影像進行 
Visual hull [9] 演算法後重建出的  3D 網格模
型，如圖 5.4、5.5。使用的 3D 網格模型為“robot＂
之 Frame 0 - Frame 5。 
投影深度圖 SNR 
我們依據未壓縮前所投影的深度圖及壓縮重建後
的投影深度圖計算其 SNR 值，成為我們第三種量
度壓縮品質的方式。SNR 值公式如 (5.3) 式。 
 
圖5.4“robot＂Frame 1 圖5.5“robot＂Frame 2
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
−
⋅=
∑∑
∑∑
= =
= =
x y
x y
N
x
N
y
N
x
N
y
yxfyxf
yxf
SNRE
1
2
1
1
2
1
103
)),(ˆ),((
)),((
log10)(
  (5.3) 
(5.3)式中  為重建後的模型投影深度像素
值，  為對應於原始建構模型之投影深度圖
像素值。  影像大小為 。 
),(ˆ yxf
),( yxf
),( yxf yx NN ×
圖 5.6-5.8 分別為 MPEG-4 AFX-3DMC 與改
良式動態 3DMC 間，使用三種指標來比較之曲
線。橫軸為平均每個模型所需的 k-byte 數，而縱
軸是不同的量度指標。圖 5.6 為平均距離誤差 
(E1)，圖 5.7 為 KG 誤差 (E2)，圖 5.8 則為投影深
度圖  SNR 值  (E3 )。紅線代表  MPEG-4 AFX- 
3DMC，而藍線則代表我們所提出的改良式動態 
3DMC 方法。 
5.2.2 傳統 3DMC 技術與改良式動態 3DMC 技
術之比較 
我們除了會將重建後 3D 網格模型投影顯示
以表示主觀上的優劣外，另外將計算三種評量數
值：平均誤差距離、KG 誤差及投影深度圖 SNR 
(Signal to Noise Ratio) 等來表示壓縮前後的失真
度。 
平均誤差距離 R-D curve
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
30 40 50 60 70 80
bit rate (kbyte/model)
E1
 : a
ve
rag
e e
rro
r (
mm
)
our method
3DMC
 
因為我們的壓縮屬於有損壓縮，因此原始模型與重
建後模型兩者的頂點座標上難免造成誤差。在此我
們直接計算兩模型頂點與頂點間三維座標的誤差
值 (如 5.1 式) 
)(1
1
1 iiii
n
i
ii czbyaxn
E −+−+−= ∑
=
  (5.1) 
圖 5.6 在 E1 量度下兩種方法之 R-D 表現 (robot) (5.1) 式中假設重建後的模型頂點座標為 (x,y,z)，
對應於原始模型中的頂點座標為 (a,b,c)。n 則為模
型中頂點的總數。 
 10
R-D curve (chicken)
0.000
0.002
0.004
0.006
0.008
0.011
0.013
0.015
0.017
0 2 4 6 8 10 12
bit rate (kbyte/model)
E1
 : a
ve
rag
e e
rro
r (
un
it)
our method
3DMC
 
圖5.19在E1量度下兩種方法之R-D表現 (chicken) 
R-D curve (chicken)
0
0.5
1
1.5
2
2.5
0 2 4 6 8 10 12
bit rate (kbyte/model)
E2
 :  
KG
 er
ro
r
our method
3DMC
 
圖5.20在E2量度下兩種方法之R-D表現 (chicken) 
圖 5.19-20 顯示的是 “chicken” 的 R-D 曲
線，我們仍舊使用 5 個 Frame 取平均的數據。圖
中 MPEG-4 AFX-3DMC 三個點由左至右分別為 
BPV =8、10、12，而我們的方法中由左至右為 
QF=50、100、1000，QF=100 代表記算 (4.2) 式中
的殘餘值時，其值乘上 100 再相減，換言之就是取
到小數點第二位，因此 QF 數字越大代表取殘餘
值越精確。我們的方法在 bit rate 約等於 4 就會
出現降不下去的趨勢，這是因為我們的方法中，仍
保持一部份的三角形連線樹的資訊，這部份是使用 
MPEG-4 AFX-3DMC 做壓縮處理，也就是說我們
相對於 MPEG-4 AFX-3DMC 能降低資料量的部
份僅在於頂點座標的壓縮。因此，到此處就無法再
往下降了。 
值得一提的，我們的方法對 “chicken” 的壓縮
效果較 “robot” 來的好。在相同的品質下，QF=100 
(圖 5.21) 時平均約需要 4.6 KB/model，優於 
3DMC BPV=10 (圖 5.22) 時每個模型約需的     
8 KB/model，最高可降至 3DMC 的一半資料量，
會有此效果乃是因為 “chicken” 是由電腦繪圖製
成。先前章節已提到此類模型僅是拉動頂點來造成
模型移動的效果，因此利用我們的方法很容易找到
目標頂點，再加上此動態模型構成時，frame rate 
即為 30 frame/second，因此找到的殘餘值並不會過
大，可有良好的壓縮效果。縱使我們最主要的目的
是處理來自  3D 視訊的  3D 模型，但利用 
“chicken” 這種電腦繪圖製出的模型來進行實驗，
可以更確定我們演算法的可行性與價值。 
  
圖 5.21“chicken” 
Frame 2 改良式 
3DMC 壓縮重建後之
3D 網格  
圖5.22“chicken” Frame 
2之MPEG-4 3DMC 壓
縮重建後之 3D 網格
 
六、結論 
 
本計劃第一年度提出了DIBR-based inter-view  
prediction 的方式，移除多視域視訊的 inter-view 
redundancy，相對於 disparity estimation 的方式，
DIBR 投影能更準確的預測，由於 DIBR 的方式需
要深度資訊與攝影機參數，因此準確的攝影機較正
還有深度資訊的計算是必要的。為了補償由於攝影
機參數或是深度資訊的錯誤造成 DIBR 的錯誤投
影，我們討論了 affine compensation model、local 
motion search，以及 depth search 三種補償方式。 
在第二年度中，本計劃對 3D 視訊採用動態
三維網格的表示法，並探討其壓縮法則，本演算法
採用了三維動態估測的方式，先加入了 K-means 
與 ICP 的作法，將兩個時間的 3D 模型先行對
齊，再進行動態估測，估測時不僅往 Temporal 的
方向進行搜尋，也考慮了 Spatial 的方向，增加可
搜尋的頂點數。實驗結果顯示整體下來相較於 
MPEG-4 AFX-3DMC 可以達到減少 20%的資料
量。 
本計畫至目前的研究投稿成果如下： 
1. Jui-Chiu Chiang, Lien-Ming Liu, and Wen- 
Nung  Lie, “A Hierarchical Two-stage 
Neural-classifier for Mode Decision of 
H.264/AVC Stereo Video Encoding,” Proc. Of 2 
nd IEEE 3D TV Conference (3D-TV CONF), 
Istanbul, Turkey, May 2008.  
2. Jui-Chiu Chiang, Chun-Hung Chen, and Wen- 
Nung Lie, “Coding of Dynamic 3D Mesh Model 
for 3D Video Transmission,” submitted to IEEE 
Int’l Symposium on Circuits and Systems, 
ISCAS-2010, Paris, France. 
 
七、參考文獻 
 
[1] Yo-Sung Ho, Kwan-Jung Oh, “Overview of 
Multi-view Video Coding,” International 
Workshop on Systems, Signals and Image 
Processing, IWSSIP, pp. 5-12, 2007. 
 
 12
