 2
行政院國家科學委員會專題研究計畫期末成果報告 
蛋白質功能分析-使用新的支持向量機與核心函數 
計畫編號： NSC 96-2221 -E-151 -034 -MY2 
執行期限：96 年 8 月 1 日至 98 年 7 月 31 日 
主持人：郝沛毅  國立高雄應用科技大學資訊管理學系 
電子信箱(Email): haupy@cc.kuas.edu.tw 
 
一、摘要 
「後基因體時代-蛋白質體學」其著重的
議題是在探討蛋白質所扮演的生理功能，而蛋
白質之間的交互作用提供推論蛋白質功能重
大的線索。支持向量機(SVM)已被證明在預測
蛋白質間交互作用有優異的正確性，與其他預
測蛋白質間交互作用的計算方法一樣，SVM
必須使用正樣本與負樣本作為訓練的資料，然
而高產量的探測蛋白質交互作用實驗方法，所
找出的有交互作用的蛋白質(PPI)存在著高比
率的偽陽性。在第一年的計畫中，我們結合模
糊理論可以處理『不精確』與『含糊』等資料
的特性，解決 PPI 正樣本的不可靠性，並且使
用單類別支持向量機僅需藉由正樣本去做訓
練的特性，則可完全避免了如何選取負樣本的
問題。此外，為了解決 PPI 資料庫不斷新增資
料的問題，我們提出了一個增加式的學習演算
法。 
蛋白質三度空間結構決定了能否表現其
正常的生化功能，為了要執行特定的生物功
能，蛋白質必須擁有特定的三度空間結構。如
何從蛋白質的一級結構預測其三級結構，一直
是研究蛋白質功能最重要的一件工作。在第二
年的計畫中，我們提出一個新穎的『參數化不
敏感區間的支持向量迴歸機』，並且使用它來
預測殘基的接觸程度 residue-wise contact 
order (RWCO)。RWCO 是一種新的呈現蛋白
質結構的方法，主要是在形容各殘基之間的接
觸程度。藉由預測殘基的接觸程度(RWCO)，
可提供將來推測蛋白質三級結構的重要線索。 
 
關鍵詞：生物資訊、蛋白質交互作用、蛋白質
三級結構、支持向量機、單類別支持分類向量
機、支持向量迴歸機。 
 
二、計畫緣由與目的 
當許多生物體之基因序列被快速解析
後，生物相關學家的下一個主流研究目標將是
探究基因序列中各基因所攜帶之功能為何？
因此，以基因序列訊息資料庫為研究基礎的生
物資訊學隨之開始蓬勃發展與應用，再加上新
一代質譜技術與電腦高速運算與大量儲存能
力的蓬勃發展下，以跨領域模式而新整合發展
出『蛋白質體學(Proteomics)』。蛋白質體學
不但掀起整體生命科學研究鎖定蛋白質的新
風潮，也正式進入了「後基因體時代-蛋白質
體學開始」的階段，成為 21 世紀生物科技最
主要的研究趨勢。也就是要藉由基因體序列理
解生物體的生命系統整體是如何運作；這包含
瞭解單純的基因或其轉譯的蛋白質的功能與
結構，基因的調控，到蛋白質間的交互作用，
基因間的交互作用到更複雜的生化代謝路徑
甚至生物系統的運作。 
mRNA 所攜帶的功能訊息必須再透過其
轉譯後的產物『蛋白質』才能有執行其生理功
能的能力(如圖一)，以複雜度來比較蛋白質體
學與基因體學，基因體學像是小孩的遊戲，其
研究終點很清楚：有機體 DNA 的完整序列；
蛋白質體學則試圖補獲生命系統中的種種活
動現象。基因預估有 3~4 萬個，人類蛋白質
估計高達 20~200 萬。此外基因原則上終生不
變，蛋白質則持續變化，視其出現的組織、年
齡，甚至飲食習慣而改變。 
 4
的疾病的治療並解決可能面臨的生物危機（如
圖三）。 
功能性蛋白質體學主要分析某蛋白質其在
整體生理反應中所扮演的生化功能角色，由於
蛋白質間的功能差異很大，目前這方面研究方
向主要鎖定在蛋白質-蛋白質交互作用鑑定分
析 。 近 來 為 發 掘 蛋 白 質 功 能 ， 常 用
『guilt-by-association』方法來推論蛋白質功
能，也就是說，如果兩個有交互作用的蛋白質
其中之一知道其功能，就可以推論另一蛋白質
應該與此功能有極大的相關性。所以建立蛋白
質與蛋白質之間的交互作用及其聯絡網 
(protein-protein interactions or interaction 
networks) 將是研究功能性基因體學與蛋白質
體學的起始課題。有不同的實驗方法探測蛋白
質交互作用，不同的方法擁有不同的解析度，
第一種方法為原子層次觀察，通常是X光繞射
或核磁共振，第二是直接觀察，例如酵母菌two 
hybrid，第三是複和體探測，如免疫共沈澱法，
第四是細胞中交互作用，如受體與ligand的交
互作用的生物檢測(bioassay)。不同的實驗方法
有不同的可信賴程度[Sprinzak, 2003]。 
 
2.2 蛋白質三度空間結構 
若只將蛋質建檔以及建構出蛋白質間的
互動關係，只佔了蛋白質體學三分之二的內
容，而決定出蛋白質的立體空間結構也是同樣
重要，因為蛋白質三度空間結構決定了能否表
現其正常的生化功能。每一個蛋白質都由二十
種氨基酸(amino acid)依特定的秩序串聯而
成。蛋白質執行各種特定的生物功能則完全仰
賴其特定的三度空間結構。為了要執行特定的
生物功能，蛋白質必須擁有特定的三度空間結
構。這好比是一個工具或一部機器必須有符合
它功能的形狀和結構才具有用途。 
 
 
圖四、 (a)蛋白質的一級結構，即該蛋白質的氨基酸序
列；(b)蛋白質的二級結構，螺旋的為helix，平板折疊為 
strand；(c)蛋白質的三級結構，我們可以從其片段對應
到二級結構。 
 
如果有某種原因令生物體內一個蛋白質
的空間結構產生錯誤而使該蛋白質失去它應
有的功能，其後果小則使生物體的運作輕微失
調，大則導致生物體死亡。狂牛病的起因就是
上述的一個典型例子。蛋白質三度空間結構的
形成，背後隱藏著一個極端複雜、令人歎為觀
止的過程。瞭解蛋白質結構在人類生活上有相
當多的應用，例如：針對於有毒性的蛋白質，
瞭解使其具有活性的結構部分，藉此設計藥物
來抑制該結構，就可達到抑制該病症的療效。
如何從蛋白質的一級結構(氨基酸序列)預測
其三級結構，一直是研究蛋白質功能最重要的
一件工作。傳統的作法是由蛋白質的一級結構
先預測其較為粗略的二級結構，然後藉由二級
結構的片段，產生可能的三級結構模組
(templete)，如圖四所示。 
 
目前對於此一領域的研究方法主要可分為
兩大類，其一是利用實際實驗的方法來預測，
內容包括以 X 光繞射(X-ray diffraction)或是用
核磁共振等(NMR)物理的方式來探知一蛋白
質的結構；其二則是利用電腦的計算，依據理
論和已知的基因序列等資訊來預測，預測的方
法 則 包 括 了 同 源 模 擬 法 (Homology 
modeling)、摺疊辨識法(Folding recognition)以
及重頭起算法(Ab initio)三種。 
 6
根據統計學習理論所提出來的 Vapnik and 
Chervonenkis bound ,下列不等式成立的機率
為 η−1 ,     
Λ∈∀
−⎟⎠
⎞⎜⎝
⎛ +
+≤ λ
η
λλ
l
h
lh
RR emp
4
ln12ln
)()(   (1) 
其 中 h 是 分 類 機 器 的 VC 維 度
(VC-dimension) ，而 l 訓練資料的數目，為了
降低結構風險(structural risk) 也就是說，為了
得 到 更 加 的 推 理 能 力 (generalization 
performances)，則經驗風險以及 VC 維度對訓
練資料的數目的比率都必須越小越好。 
 
SVM 的基本原理是透過訓練資料
}1{),(,),,( 11 ±×∈ Nll Ryxyx L  
來估計出一個決策函數 }1{: ±→NRf ，首先
討論線性分類的問題，此時 SVM 的目的是找
出一個超平面(hyperplane)來區分二各類別，並
且最大化這二個類別的的資料與超平面最短
距離，也就是說 
  
liyifbxw
yifbxw
ii
ii
,..,111
11
=−=−≥−⋅
=≥−⋅
  (2) 
亦等於               
  libxwy ii ,,11)( K=≥−⋅        (3) 
而最佳的(optimal)的超平面 0=−⋅ bxw ,
也就是擁有最大化邊界 (margin)的超平面，其
中邊界(margin)所指的是平面 1=−⋅ bxw 與
1−=−⋅ bxw 之間的距離。其距離為 
　 　
2
2
w
 where ∑== ni iww 1 22     (4) 
 
 
圖六、(a)一般分類機器所找出的決策曲線(b)支持向量機
所找出的最佳決策曲線 
 
而邊界(margin)越大，代表了此分類器的 VC
維度(VC-dimension)越小，也就是說他結構風
險(structural risk)的上界也就越小。所以擁有
最大化邊界(margin)的超平面也就是 SVM 中
所要尋找的最佳化的超平面。(如圖六) 
 
而 SVM 透過求解下列的二次最佳化問題
來找出最佳的超平面 0=−⋅ bxw  
     
li
bxwyts
Cw
i
iii
l
i
ibw
,...,10
1)(..
2
1min
1
2
,,
=≥
≥++⋅
⎟⎠
⎞⎜⎝
⎛+ ∑
=
ξ
ξ
ξξ
 (5) 
其中 C > 0 是一個由使用者給定的固定的懲
罰參數，愈大的 C 值代表越不允許訓練資料
的分類錯誤發生，而參數  C 也被稱為
regularization parameter，由上式可以看到，
SVM 同時的最小化 
∑== ni iww 1 22 ，          (6) 
以找出最大邊界的超平面，同時也最小化分類
錯誤 dii}{ξ=Ξ ，而參數 C 則是負責二者最小
化比重之間的調控。 
 
要求解此二次最佳化問題，我們可以使用
拉哥郎莒(Lagrange multipliers)的技巧，假設
),.....,,( 21 lλλλ=Λ 與 ),.....,,( 21 lrrr=Γ 為非
 8
表一、常見的核心函數 
Type of classifier Kernel function 
Gaussian RBF )exp(),( 2yxyxK −−=
Muti-Layer 
Perceptron )tanh(),( θ−⋅= yxyxK
Polynomial of 
degree d 
dyxyxK )1(),( ⋅+=  
 
表一中整理出來較常使用到的核心函數，以及
她們所對應的分類器名稱。 
 
雖然支持向量機一開始是提出來解決二元分
類問題，但是也有學者提出單類別支持向量機
(one-class SVM)來解決單類別分類的問題[Tax, 
1999]，並且也有學者提出支持向量迴歸機來
解決迴歸的問題[Vapnik, 1995]。 
 
 
三、使用增加式模糊單類別支持向量機預
測蛋白質間交互作用 
支持向量機(SVM)已被證明在預測蛋白
質間交互作用有優異的正確性。支持向量機與
所有預測蛋白質間交互作用的計算方法一
樣，都必須使用正樣本與負樣本作為訓練的資
料，然而高產量的探測蛋白質交互作用實驗方
法，所找出的有交互作用的蛋白質存在著高比
率的偽陽性。不同的實驗方法有不同的可信賴
程度[Sprinzak, 2003]。本計畫中，我們結合模糊
理論可以處理『不精確』與『含糊』等資料的
特性，解決正樣本的不可靠性。 
負樣本(無交互作用的一對蛋白質)也必
需小心謹慎的選取，才能訓練出一個具有高正
確率的分類機器，然而現實環境下，並沒有『標
準與精確』的負樣本可供訓練[Jansen, 2004]。現
存的 PPI 資料庫中(如 DIP,BIND 等)，皆僅提
供正樣本而已，在網際網路上的醫學文獻資料
庫，也只會告訴你哪些蛋白質間會有交互作
用，而不會告訴你哪些蛋白質間不會有交互作
用。而早先的預測方法，在選取負樣本的作法
上都有嚴重的偏差性，例如在[Gomez, 2003]
中，他只是將沒有出現在 DIP 與 BIND 等 PPI
資料庫中的每一對蛋白質，『隨機』的選取出
其中一部分作為訓練的負樣本，這其實是滿不
合理的，因為沒有出現在現存 PPI 資料庫的某
一對蛋白質，表示尚未知道它們之間是否有交
互作用，而不代表他們是不會有交互作用。而
在[Jansen, 2003; 2004]的方法中，也是考慮沒有
出現在 DIP與 BIND 等 PPI 資料庫中的每一對
蛋白質，再用某些條件來選取負樣本，譬如一
對蛋白質要發生交互作用，必需在相同的細胞
位置 (cellular localization)，因此每一對在相同
細胞位置的蛋白質將不會選取為負樣本，因為
在相同細胞位置的蛋白質發生交互作用的機
會比較大。同樣地，這樣子選取出來的負樣本
還是有偏差的。這本計畫中，我們使用單類別
支持向量機僅需藉由正樣本去做訓練的特
性，則可完全避免了如何選取負樣本的問題。 
 
3.1 單類別支持向量機 
單類別支持向量機[Tax, 1999]使用超球
(hyper-sphere)的方式，將樣本點經由一個非線
性映射Φ映射到一個高維度的特徵空間，並
找出一個有最小半徑的超球來包含特徵空間
中所有的樣本點。 
而支持向量(support vector)定義出一個特
徵空間中的球來圍住所有的樣本點。而且一個
高維度的球在原來空間中可以是任意的形
狀。單類別支持向量機方法的概念圖可用圖八
表示。我們可以計算出所有點在特徵空間中到
球心的距離，而畫出圖八的高度圖，距球心距
離越遠則顏色越深，而由高度為球半徑的橫切
線定義出一條邊界曲線來包含所有的樣本點。 
 
 10
iiiii
iii
i
CC
CL
μαβμα
βαμξ
≤−=⇒
=−−=∂∂
  and  
0
.    (21) 
將上面式子 (19)-(21)代入原來的最佳化問
題，我們得到下列的對偶問題(dual problem) 
　 ∑∑
= =
N
i
N
j
jiji xxk
i 1 1
),(
2
1min αα
α
  
subject to                            (22) 
.,...,1,0
1
NiC ii
i
i
=≤≤
=∑
μα
α
 
3.3 增加式模糊單類別支持向量機演算法 
既然我們只使用正訓練樣本來訓練單類
別支持向量機，如何選出充足且有代表性的
PPI 訓練樣本也就變成一個很重要的問題，然
而一次就選出足夠的訓練樣本是不容易的。所
以一個增加式學習方法（incremental learning）
就變的很必要了，如何在系統發現辨識錯誤，
或著要增加新的訓練樣本時，可以只用少數的
幾個步驟就能修正錯誤與學習新增加的樣
本，而不用重新訓練整個系統，將對此 PPI
預測系統的強健性與適應性有大大的幫助。 
所以本計畫中，我們使用單類別支持向量
機的一個重要特性，來幫助我們解決這個問
題。由於單類別支持向量主要是解一個二次最
佳化函數，而且二次矩陣是半正定及限制條件
是線性的，所以他有唯一全域最佳解，而增加
一個新的訓練樣本點時，我們可以用二次函數
的最佳化條件(KKT Condition)，使用數學最佳
化的技巧，當我們發現有一新的 PPI 資料應該
增加到我們的訓練樣本時，我們便可不必要重
新再訓練整個系統。而單類別支持向量機的最
佳化條件(KKT Condition)可以簡化成下列式
子 
　
⎪⎩
⎪⎨
⎧
=≤
<<=
=≥
=
−+−=
−=
∑∑
ii
ii
i
jk
kjjk
j
jijii
iJJi
C
C
KKKR
DRg
μβ
μβ
β
βββ
;0
0;0
0;0
2
)(
,
2
22 x
 (23) 
其中 ),( jiij xxKK = 。由上式，我們可以將訓練
資料集 D 分割成三個不同的集合: 集合 S 
由邊界向量(border support vectors)所組成，這
些邊界向量皆座落在特徵空間超球的球面上 
( ii Cμβ <<0 , SiDR iJJ ∈∀=− ,0)(22 x  )，集合 E
由出界向量(outside support vectors)所組成，這
些出界向量皆座落在特徵空間超球的球外 
( ii Cμβ = , EiDR iJJ ∈∀<− ,0)(22 x  )，而剩餘的
集合 R 中的向量則皆落在特徵空間超球的球
內( 0=iβ , RiDR iJJ ∈∀>− ,0)(22 x )。 
增加式單類別 SVM 學習演算法的基本想
法就是保持所有之前已訓練過的樣本其最佳
化條件(KKT conditions)維持不變，同時『穩態
地』增加新的訓練過的樣本 c 進入系統。在集
合 D 中，在每一次 incremental step 中，所有
的邊界向量所對應的係數 iβ，會隨著新近樣本
c 所對應的係數 cβ 改變而改變，以保持一個平
衡(equilibrium)的狀態，也就是說，D 中所有
的樣本都能滿足最佳化條件(KKT conditions)。 
當新近樣本 c 所對應的係數 cβ 改變時，我們可
得到 ig 的改變如下 
}{
,222
cDi
BKKg cic
Sj
jiji
∪∈∀
Δ+Δ+Δ=Δ ∑
∈
ββ
    (24) 
與      　 ∑
∈
Δ+Δ=Δ
Sj
jcg ββ           (25) 
其中 
⎟⎟
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜⎜
⎜
⎝
⎛
Δ−⋅Δ⋅Δ−⋅⋅Δ−
⋅Δ⋅−⋅Δ⋅Δ−Δ
=Δ ∑∑
∑∑
∈∈
∈∈
ccc
Dj
cjjc
Dj
cjjc
Djk
kjjk
Djk
kjjkJ
KKK
KKR
B
2
,,
2
)(
2)(
2
1
βββββ
ββββ
所以，在“平衡狀態(equilibrium)”時 
 12
RCO 值做一個加總，用來描素各殘基與其他
鄰近殘基之間的接觸程度 [Jiangning, 2006; 
Kinjo, 2005]。在決定蛋白質三級結構時，殘基
的接觸程度提供了非常有用的資訊，例如我們
可以用接觸程度決定在動態模擬蛋白質結構
時的能量函數(energy function)。以前在預測氨
基酸的接觸程度時，可以分成使用分類
(classification)與使用迴歸 (regression)的二種
方式來解決，在使用分類的方法中，例如可以
由遞迴類神經網路(recurrent neural networks)
來預測氨基酸的接觸程度[Pollastri, 2001]，不
過使用迴歸的方式來預測更為直接，正確率也
更高。例如 Kinjo 等學者[Kinjo, 2005a]首先使
用線性迴歸的方式來預測各殘基的 RWCO
值，而[Song, 2006; Yuan, 2005]則首先使用支
持向量非線性迴歸機來預測氨基酸的接觸程
度。 
4.1 殘基接觸程度 
殘基接觸程度(residue-wise contact order, 
RWCO)是由 Kinjo 和 Nishikawa 兩位學者首次
提出來的一種判斷蛋白質摺疊率的一種方法
[Kinjo, 2005, 2006; Yuan, 2005]，有很多的觀念
都和 RWCO 有關，譬如說是 CN、CO、RCO
與 CM，都將在這個小章節做簡單的介紹。 
4.1.1 接觸數(contact number; CN)： 
殘基接觸數(contact number)可以看成是一
種對蛋白質三級結構摺疊情況的描述，它的定
義是以一個蛋白質三級結構中，從目標殘基的
中心 Cα原子和目標以外殘基的中心Cα原子接
觸的數量有多少，將這些有接觸的數量做加
總，就是所謂的接觸數(contact number, CN)。
何為接觸呢﹖研究者會先設定一個要研究的
球型半徑(例如：8Å、10Å)。如果目標殘基和
其它的殘基的距離小於研究者設定的球型半
徑，那就判斷該殘基與目標殘基有接觸， 
 
圖九 殘基接觸數概念圖 
 
透過點對點距離的計算公式來判斷目標殘基
和其它的殘基的距離[Yuan, 2005]。判斷是否
接觸的點對點計算公式： 
( ) ( )( )⎪⎩
⎪⎨
⎧= <=
≥=>−
∑ djiji
djiji
rrifr
rrifr
M
ijj
ji
i
d rN
,,
,,
1
02|:|
,
σ
σ
σ   (32) 
i
dN ：所得到的接觸數。 
dr ：研究者設定的球型半徑。例：8Å、10Å。 
jir , ：第 i 殘基和第 j 殘基之間的距離。 
M：該蛋白質序列總殘基。 
 
如圖九所示，假設藍色的殘基為所要計算的殘
基，其殘基的 Cα原子為中心，其它蛋白質序
列的殘基 Cα 原子若有在這個的半徑內就將它
視為接觸，藍色的殘基扣掉它前後兩個位置的
殘基，剩下在球型半徑範圍內殘基都視為接
觸，圖中的藍色殘基的接觸數為 2，紅色殘基
的接觸數為 3 公式(32)所得到的接觸數是整數
值，若要得到浮點數的接觸數，則還要配合公
式(33)才能得到浮點數值的接觸數。 
　 　 　 ∑Δ⋅=
N
jiSNL
CO ,
1         (33) 
 
 14
殘基與殘基之間接觸的遠近程度，RWCO 與
RCO 的差異就在於 RWCO 它不考慮目標殘基
前後的兩個殘基，並且根據兩個殘基在胺基酸
序列位置的遠近，而計算出來的值也有所不
同，例如目標殘基為第 5 個殘基，它在與第
10 個殘基接觸所計算出來的 RWCO 值與和與
第 20個殘基接觸所計算出來的RWCO值是不
同的 [Kinjo, 2005-2006; Yuan, 2005; Song, 
2006]。其計算 RWCO 的公式為： 
( )
( )
( )
⎪⎩
⎪⎨
⎧
−=
<=
≥=
>−
∑
djiji
djiji
rrifr
rrifr
ji
M
ijj
i rjiM
RWCO
,,
,,
1
0
,
2|:|
||1
σ
σ
σ
其中
  (35)  
M：所有殘基的數目。 
i：要計算的目標殘基。 
j：除了目標殘基以外的殘基。 
( )jir ,σ ：以第 i 殘基中的 βC (或叫 αC )原子
為中心，將其中心為基準畫出設定的球型半
徑圓 dr ( dr = 6Å 或 8Å)，若第j殘基在設定
的球型半徑內( dji rr <, )，則 ( )jir ,σ 為1。若j
殘基在設定的球型半徑外(
dji rr >, )，則 ( )jir ,σ
為0。 
 
為了讓蛋白質的RWCO值較平滑，Kinjo學者
提出了一個能夠讓計算出來的RWCO值變的
較平滑，其公式如下： 
( ) ( )[ ]djiji rrwr −+= ,, exp1
1σ    (36) 
w：為常數值，一般設為3。 
dr ：為研究者設定的球型半徑值，一般
設為12Å。 
 
圖十一： 支持向量迴歸機的概念圖。 
 
4.2 支持向量迴歸機(ε-SVR) 
首先我們簡介支持向量迴歸機的基本概
念，假設現在給定一組訓練資料集合
Ryy NN ×ℵ⊂)},(),...,,{( 11 xx ，其中ℵ 表示輸入
向量 (input vector)的空間，例如 nR 。則在
ε -SVM regression [Vapnik, 1995]中，其目標是
找到一條最佳的迴歸函數 f(x)使得對於所有的
訓練資料而言，它與 iy 的差異最多只有 ε 的誤
差。換句話說，在訓練這條迴歸函數時，我們
並不關心這些小於 ε 的誤差，但是不允許大於
ε 的誤差出現，若誤差大於ε 時，則我們必須
加以處罰。在 ε -SVM regression 中我們使用下
ε 不敏感懲罰函數(ε -insensitive loss function) 
　 　 　  
⎪⎩
⎪⎨⎧ −
≤=
otherwise
if
εξ
εξξ ε
0
:        (37) 
來懲罰迴歸錯誤，只有當錯誤超過 ε -不敏感
的管狀區域(ε -insensitive tube)時，我們才加
以懲罰(如圖十一)。 ε -SVM regression 所找出
的是一條線性的迴歸函數 bf +⋅= xwx)( ，要
延伸到非線性迴歸，其概念也是很簡單，我們
只需把所有的訓練資料經由一非線性轉換Φ
映射到一高維度的特徵空間(feature space)，然
後在高維度特徵空間中找出一條最佳的線性
迴歸函數 bf +Φ⋅= )()( xwx ，而在高維度特徵
空間中的最佳線性迴歸函數，在原來空間中即
是一條最佳的非線性迴歸函數。我們可以用一
個最佳化的問題來描述它 　 
 16
 
 (a)              (b)               (c) 
圖十二、(a)誤差的分佈與輸入向量 x 有關係的例子,(b)使用原
來 SVM regression 的結果,(c)真正合理的迴歸結果。 
 
 
2. 在支持向量迴歸機中，不敏感區域
(insensitive zone)被假定是一個管狀(tube)
的區域。也就是說，他假設誤差的分佈，
與輸入向量 x 無關，亦即每個輸入向量
都是一樣重要的。然而這與現實世界中
的狀況並不一樣，事實上誤差的分佈是
與輸入向量 x 有關係的，而且每個輸入
向量的重要性並不一樣，有的樣本較可
靠，可允許的迴歸誤差較少，有的樣本
較不可靠，則可允許的迴歸誤差較多。 
 
 
 
4.2 使用參數化不敏感區間的支持向量迴
歸機 (par-v-SVR) 
在本計畫中，我們研究出一個新的參數化不敏
感區間的支持向量迴歸機學習演算法，並且希
望能夠不需要事先知道誤差的機率分佈，就可
以得到此任意區間的迴歸函數。在本研究中，
我們假設不敏感區域是任意形狀的，而我們以
一個函數 g(x)來描述他，換句話說我們希望能
找出一條迴歸函數使的所有的訓練樣本點都
在 f(x)-g(x)與 f(x)+g(x)的區間之內（如圖十三
所示），我們可以用一個最佳化的問題來描述
它
 
圖十三、 使用參數化不敏感區間的支撐向量迴歸機. 
 
( )⎟⎟⎠
⎞
⎜⎜⎝
⎛ ++⎟⎠
⎞⎜⎝
⎛ +⋅+ ∑
=
N
i
ii
db N
dvC
ii 1
*22
,,,,,
1
2
1
2
1minimize
*
ξξ
ξξ
cw
cw
 
subject to                              (47) 
( ) ( ) iiii ydb ξ−≥+Φ⋅++Φ⋅ )()( xcxw  
( ) ( ) *)()( iiii ydb ξ+≤+Φ⋅−+Φ⋅ xcxw  
0, * ≥ii ξξ   for i=1,…,N. 
使用 Lagrangian 理論，上面最佳化問題的最
佳解會落在下面函數的馬鞍點上(saddle point) 
( )
( )
( )
( )
( )
∑∑
∑
∑
∑
==
=
=
=
−−
⎥⎥⎦
⎤
⎢⎢⎣
⎡
+++Φ⋅+
+Φ⋅−−
⎥⎥⎦
⎤
⎢⎢⎣
⎡
+−+Φ⋅
++Φ⋅−
⎟⎟
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜⎜
⎜
⎝
⎛
++
⎟⎠
⎞⎜⎝
⎛ +⋅
+=
N
i
ii
N
i
ii
N
i iii
i
i
N
i iii
i
i
N
i
ii
yd
b
yd
b
N
dv
CL
1
**
1
1
*
*
1
1
*
2
2
)(
)(
       
)(
)(
       
1
2
1
2
1
ξβξβ
ξα
ξα
ξξ
xc
xw
xc
xw
c
w
,  (48) 
其中 iα , *iα 與 iβ , *iβ 為非負的拉格郎舉乘
數(Lagrangian multiplier). 對 L 以 w, b, c, d, 
iξ  與 *iξ 微分，並且設定結果為 0，我們得到
下面方程式  
0)()(
1
*
1
=Φ+Φ−=∂∂ ∑∑ ==
N
i
iii
N
i
i
L xxww αα  
 18
五、蛋白質序列核心函數 
核心函數方法(kernel method)是支持向量
機中一個很重要的方法，支持向量機中有一個
很重要的特性，就是處理的樣本從不會單獨出
現，而是以內積的方式成對的出現，因此可以
藉由定義核心函數來取代資料樣本在高維度
特徵空間(feature space)的內積： 
　 　 　 )()(),( yxyx Φ⋅Φ≡k  
核心函數的定義提供了一個很有效率的方
式，讓支持向量機可以將資料樣本經由一個非
線性轉換映射到一個複雜的高維度特徵空
間。如前面所述，藉由將資料樣本映射到一個
高維度特徵空間，可以增加支持向量機的計算
能力，支持向量機其實只是在複雜的特徵空間
中作一些簡單的處理，例如找出一個線性的分
割函數（分類問題）、找出一個線性的迴歸函
數（迴歸問題）、或者找出一個體積最小的球
體（單類別分類問題），然而還原到原來空間
時，卻能得到一個很複雜的非線性函數，而此
找出的非線性函數的本質是與核心函數是有
很大的關係。藉由核心函數的定義，我們可以
避免計算資料樣本在高維度特徵空間的內
積，因為這是十分費時間的。也因此藉由核心
函數，支持向量學習演算法中要學習的參數並
不會因為我們把樣本映射到高維度空間而增
加。底下介紹在支持向量機中常用到的核心函
數： 
 
Gaussian RBF )exp(),( 2yxyxK −−=  
Muti-Layer 
Perceptron )tanh(),( θ−⋅= yxyxK  
Polynomial of 
degree d 
dyxyxK )1(),( ⋅+=  
 
 
不過除了這些核心函數外，近年來也有些學者
在研究一些新的核心函數，專門用來處理一些
輸入資料樣本是離散的資料型態—例如文件
資料或蛋白質序列。藉由這些新穎的核心函數
的發明，讓支持向量機的功能越加強大，不再
僅限制於只能處理輸入空間是尤拉空間
(Euclidean space)的問題了，而且可以應用到一
些無法在輸入空間定義線性函數的問題上。在
本研究計畫中，我們也將研究出一個適合於生
物資訊領域的核心函數。底下我們介紹目前已
提出用來處理生物序列的核心函數，以及我們
的研究方法。 
在處理蛋白質串列時，我們所面臨到的問
題是蛋白質序列是由 20 個氨基酸所組成的字
串，而且每一個字串的長度並不一樣，所以要
考慮到這些蛋白質序列該如何編碼成支持向
量機可以處理的向量格式，或者是說該如何定
義一對蛋白質序列（序列長度並不一樣）在高
維度特徵空間的『內積』是什麼？目前可以分
成高層次與低層次二種不同的作法，在高層次
的作法中，是用蛋白質序列所處的 domain 或
者是在 GO 上的註解將一條蛋白質序列編碼
(encoding)成為一個向量(vector)，但是他的缺
點在於並不是現存每一條蛋白質序列都知道
他所處的 domain、以及都有 GO 上的註解。
而低層次的作法則是直接在蛋白質的氨基酸
序列(amino acid sequence)上作處理，在支持向
量機的方法中，二個向量的內積其實是表示這
二個向量的相似程度，不同的相似程度度量方
式會造成不同的結果。所以在低層次的作法
中，主要所關心的是該如何度量二個長度不同
的氨基酸字串的相似程度。為了解決這個問
題，不同的 string kernel 被提出來。以下依序
介紹： 
Fisher kernel: 在[Kuang, 2004]中，作者所用
的方法是使用所有的訓練與測試資料集建立
一個隱藏馬可夫模組(hidden markov model, 
 20
0)( =Φ αβ ，而將一條蛋白質序列 X 映射到
高維度特徵空間的方法如下 
∑Φ=Φ
X
mkmk X
in  
),(),( )()(
α
α      (72) 
最後，k-mismatch kernel 定義為 
)(),(),( ),(),(),( YXYXK mkmkmk ΦΦ=  
k-mismatch kernel 可以使用一個 mismatch tree
的資料結構求出。 
 
Local alginment kernel：在[Saigo, 2004] 中，
作者提出了另外一種 string kernel，改進了之
前piwise similarity kernel使用Smith-Waterman 
algorithm 的一些缺點，而提出了一種新的動態
規劃演算法來計算核心函數，其演算法如下： 
Initialization: for i=0,...,|x| and j=0,…,|y|: 
M(i,0)=M(0,j)=0, 
X(i,0)=X(0,j)=0, 
Y(i,0)=Y(0,j)=0, 
X2(i,0)=X2(0,j)=0, 
Y2(i,0)=Y2(0,j)=0, 
Dynamic programming equations: for 
i=0,...,|x| and j=0,…,|y|: 
)]1,1()1,1(
)1,1(1)][,(exp[),(
−−+−−+
−−+=
jiMjiY
jiXyxjiM iisβ  
),1()exp(
),1()exp(),(
jiX
jiMjiX
e
d
−+
−=
β
β
, 
)1,()exp()]1,(
),1()[exp(),(
−+−+
−=
jiYjiX
jiMjiY
e
d
β
β
, 
),1(),1(),( 22 jiXjiMjiX −+−= , 
)1,()1,()1,(),( 222 −+−+−= jiYjiXjiMjiY
 
Termination: 
|)||,(||)||,(|
|)||,(|1),(
2
2
)(
yxMyxY
yxXyxK LA
++
+=β
 
 
上面介紹了幾種在處理蛋白質序列時所會使
用的 string kernel，在本計畫中我們也將著手
研究新的 string kernel 特別適用於生物資訊的
應用，例如在計算二個蛋白質序列的相似程度
時，應該把 gap 的數目與長度也作為一個考慮
的依據，另外不同的 string kernel 有不同考量
依據，計算一對蛋白質序列的內積（也就是相
似度）也有不同的思考觀點，而這些不同的
string kernel 也可以把他們整合在一起，成為
一個新的 string kernel，並包含這些 string 
kernel 的優點，把數個核心函數(kernel)結合在
一起的作法有下面幾種方式： 
 
從舊有的核心函數建立新核心函數的方法：令
1K 與 2K 是二個舊有的核心函數， +∈ Ra ，
f(.) 為 一 個 real-valued function ，
)()(),(3 yxyxK φφ ⋅≡ 是另一個核心函數，其
中 Ξ→x:φ 為一非線性轉換，而 B 是一個對
稱的半正定(positive semi-definite)矩陣，則底
下皆是新的核心函數： 
1. ),(),(),( 21 zxKzxKzxKnew += , 
2. ),(),( 1 zxaKzxKnew = , 
3. ),(),(),( 21 zxKzxKzxKnew =  
4. )()(),( zfxfzxKnew =  
5. ))(),((),( 3 zxKzxKnew φφ=  
6. zxzxKnew B′=),(  
 
除此之外，對於二個 string kernel 1K 與 2K ，
也可以使用迴旋(convolution)的方式，建立一
個新的 string kernel。 
),(),(),( 222
,
111
2121
zxKzxKzxK
zzzxxx
new ∑
==
=  
在本計畫中，我們將數過 string kernel 整合在
一起來，創造一個新的核心函數並包含舊有核
心函數的優點。 
 
 
 
 22
的，有不同的實驗方法探測蛋白質交互作用，
不同的方法擁有不同的解析度，每一個PPI的
可信賴程度也就不一樣。在本計畫中，我們使
用模糊理論可以處理現實世界中資訊其性質
是『不精確的』或『不確定的』的特性，來避
免出訓練出來的預測模組會受到雜訊的影
響。首先，我們必須定義出每一個PPI訓練樣
本的可靠度(或模糊度)。而我們使用下面二種
方法來決定每一個PPI訓練樣本的可靠度。 
 
A. 由樣本的實驗方法決定 
決定PPI訓練樣本的可靠度最直接的做
法，就是由他是使用何種實驗方法得到的來決
定，解析度越高的實驗得到的PPI自然越可
靠，反之高產量實驗得到的PPI就不可靠。而
不同實驗得到的PPI其中『偽陽性』與『偽陰
性』樣本的比率，也可以用來決定此實驗方法
的可信賴程度。表三是由成大醫院的專家所整
理出現存的探測PPI的實驗方法，以及它們可
信賴的程度(數值越大，表示越可靠)。另外有
些PPI的資料是由二種以上的實驗方法驗證，
它們的可靠程度自然更高。 
B. 由樣本在向量空間中的分佈 
第二種決定PPI訓練樣本的可靠度的做
法，就是由他們在樣本空間的幾何分佈情形。
如果一個PPI樣本在樣本空間中和其它的PPI
樣本都很接近的話，則他應該就是很可靠的。
反之如果一個PPI樣本在樣本空間中和其它的
PPI樣本很疏遠的話，則他就很可能是一個雜
訊(outlier)，可靠度就應是比較小，由樣本在
向量空間的分佈決定樣本可靠程度的做法，可
分成他在『原來空間(original space)』與『特
徵空間(feature space)』分佈二種情形討論: 
a) 在原來空間的分佈 
假設給定一組訓練樣本 Nxx ,...,1 ，令
meanx 表示樣本的平均分佈(mean)，以及此樣
本分佈的半徑為 
 
圖十四：資料在RBF特徵空間的分佈。 
 
meanii
r xx −= maxtarget  
則第i個樣本的可靠程度定義為[Lin, 2002] 
)(
1
target δμ +
−−=
r
meani
i
xx
 
 
如果第i個PPI距離 meanx 越近，則他的可靠程度
越大，反之如果第i個PPI距離 meanx 越遠，則他
的可靠程度越小。 
b) 在特徵空間的分布 
由於單類別SVM是將訓練樣本經由一個
非線性轉換Φ映射到一個高維度的特徵空間
(feature space)，然後找出一個最佳的超平面分
割所有的正樣本。所以第i個訓練樣本在特徵
空間的分佈也可以用來決定此樣本的可靠程
度，而使用高斯RBF核心函數對應的特徵空間
有一個特性，就是在特徵空間中所有的樣本距
離原點的距離皆是1，也就是所有的樣本都是
在一個以原點為球心的球表面上，如圖十四所
示。所以我們可以直接由樣本在特徵空間的內
積表示他們之間的距離。則第i個樣本的可靠
程度定義為 
∑
≠
=
ki
kii k ),( xxμ  
 24
表五：結合不同蛋白質序列核心函數的預測正確率 
結合 2個蛋白質
序列核心函數 
One-class 
SVM 
Fuzzy 
One-class 
SVM 
A+B 67.5 67.7 
A+C 68.0 68.4 
A+D 67.2 67.4 
A+E 67.2 67.3 
B+C 68.4 68.5 
B+D 67.8 67.9 
B+E 67.9 68.1 
C+D 68.1 68.3 
C+E 68.2 68.3 
D+E 67.4 67.5 
 
在本計畫中，我們同時比較在結合 2 個不同的
蛋白質序列核心函數後的蛋白質交互作用的
預測正確率，實驗結果如表五所示。我們發現
結合蛋白質序列核心函數的預測正確率，大多
會落在原來 2 個蛋白質序列核心函數之間，如
何提出更好的結合核心函數的方法，使得預測
的正確率能比原來 2 個蛋白質序列核心函數
更佳，將是我們未來的研究方向。 
6.2 使用參數化不敏感區間的支持向量迴歸
機應用於蛋白質殘基接觸數的預測 
近年來，有學者提出另一種從蛋白質的一
級結構預測其三級結構的方法。蛋白質的三級
結構可以藉由測量其中每一個殘基的接觸程
度(contact order)，而知道它們在空間中是如何
排列的。所謂一個折疊後的蛋白質中其殘基接
觸程度(contact order)是根據該分子所暴露的
區域環境而量度，其定義為以該殘基分子中的
αC (或 βC )原子為中心，在一特定的球形範圍
內，所有與它距離小於某特定長度 (例如
10
o
A (埃))的其它 αC (或 βC )原子的數目，然後
再判斷這些接觸的數目(CN)占總殘基數目的
比例為多少。 
Residue-wise contact order (RWCO)是一
種新的一級蛋白質結構描述遠距殘基接觸的
程度，它是一個序列中的某一個殘基和其它殘
基正在接觸的殘基之間做加總 [Hua, 2001; 
Kinjo, 2005; Kihara, 2005]。在決定蛋白質三級
結構時，殘基的接觸程度提供了非常有用的資
訊，例如我們可以用接觸程度決定在動態模擬
蛋白質結構時的能量函數(energy function)。 
因此，在本計畫中我們提出一個新穎的參
數 化 不 敏 感 區 間 的 支 持 向 量 迴 歸 機
(par-v-SVR)來改善傳統支持向量迴歸機的缺
點，並且使用他來預測氨基酸的接觸程度。由
於我們提出的par-v-SVR的不敏感區間是一個
參數化(parametric)的函數所表示，所以我們的
par-v-SVR 對於這些誤差分布與輸入樣本有關
的資料集可以得到更好的迴歸結果。 
6.2.1 人造資料集的迴歸結果 
在實驗部分我們先以簡單的實驗來說明我
們新提出的par-v-SVR與原來的SVR有什麼差
異。首先考慮下列資料集: 
 
,)05.01.0(3.02.0)2sin(2.0 22 kkkkk exxxy ++++= π  
,51,....,2,1),1(02.0 =−= kkxk     
   
此資料集也有被[Jeng, 2003]所使用。明顯的在
此資料集中，誤差的分佈與輸入樣本x有關係
的，x接近0時，誤差的變異量較小，x值越大，
變異量就越大。圖十六(a)與(b)分別顯示原始
SVR與我們提出的par-v-SVR得到的結果。明
顯的可以看到par-v-SVR得到的迴歸結果更適
合此資料集。 
 
 
 
 26
Altschul 學者以 BLAST 為基礎，再加上反覆
搜尋比對的概念所設計而成。它的特性是序列
模式的資料庫搜尋靈敏度較高、特異性較好，
因而可以發現一些距離較遠但結構上或功能
特性相似的序列片段[Altschul, 1997]。 
PSI-BLAST 會將要比對的目標蛋白質序
列從所選擇的資料庫(nr、pdbaa)做搜尋比對，
找出相似度較高的蛋白質序列，然後將這些蛋
白質序列做多重序列校準(multiple sequence 
alignment; MSA)，然後產生一個查詢序列長度
的 profile，而這個 profile 就是所謂的 PSSM。
特定位置評分矩陣 (position specific scoring 
matrix; PSSM)是根據胺基酸在每個位置上出
現頻率個別加重計分。該矩陣的橫軸是代表
20 個胺基酸在此位置出現機率的分數，而縱
軸則是胺基酸序列的長度，矩陣上的每個位置
都代表著胺基酸該此位置上出現機率的分數。 
在選擇要比對的資料庫與軟體方面，本研
究所選用的資料庫是 NCBI 網站裡面的 pdbaa
資料庫與 nr 資料庫，pdbaa 資料庫裡面所放的
蛋白質序列是蒐集 PDB 資料庫裡已經被判斷
出三級結構的蛋白質序列，nr 資料庫裡面所放
的蛋白質序列是沒有重複序列的資料庫
(non-redundant protein sequence database)，它
是從 GenPept、Swissprot、PIR、PDF、PDB
和 NCBI RefSeq 資料庫裡所收集來的蛋白質
序列並加以整理，剔除重複的蛋白質序列。
PSI-BLAST 軟體選用 NCBI 網站裡面的 blast
軟體，版本為可以在微軟環境下執行
blast-2.2.18-ia32-win32 版本。 
第二部分為 SW (sequence weight)，SW 它
是計算 Sliding windows 內的殘基分子量，維
度為 1。因為蛋白質分子量它包含了某段序列
的整體資訊(global information) 。因此，它可
改善預測 RWCO 的準確性。第三部分為
Amino acid composition(AA)，AA 是針對
Sliding windows 裡面，20 個胺基酸所佔的比
例，維度為 20。胺基酸組成份(AA)的觀念和
蛋白質分子量(SW)類似，它包含了某段序列
的整體資訊(global information)，因此，它可改
善在預測 RWCO 的準確性[Song, 2006]。由於
該部分是要計算各個胺基酸的組成份，因此總
共需要 20 個維度來表示。 
衡量 RWCO 預測績效的方法有下面幾
種，Pearson 使用 Correlation Coefficients (CC)
來衡量預測值和實際觀察值之間的相關性，其
Correlation Coefficients 公式為 
　  　
( ) ( )
,
))((
1
2
1
2
1
⎥⎥⎦
⎤
⎢⎢⎣
⎡ −⎥⎥⎦
⎤
⎢⎢⎣
⎡ −
−−
=
∑∑
∑
==
=
N
i
i
N
i
i
N
i
ii
yyxx
yyxx
CC  
 
xi和 yi分別為第 i個殘基的RWCO實際觀察值
和 RWCO 預測值，而 x 和 y 則是它們的所對應
的平均值。N 是殘基的總數。 
　 　 為了方便比較新方法與舊方法之間的
預測效能，本研究也使用RMSE來評估RWCO
實際觀察值和 RWCO 預測值之間的誤差有多
少。其 RMSE 公式為， 
( )∑
=
−=
N
i
ii xyN
RMSE
1
21  
 
6.2.3. RWCO 預測成果 
在本計畫執行期間中，我們開發了一套
RWCO 預測系統，自動由大量的蛋白質序列
中預測蛋白質序列上每一個殘基的 RWCO
值，以供未來在模擬蛋白質三級結構時使用。
我們比較了傳統的支持向量迴歸機以及本計
畫所提出的使用參數化不敏感區間的支持向
量迴歸機。 
 
 
表六：使用pddba資料庫編碼的RWCO預測結果 
 28
由本計畫贊助所發表文章有： 
1. Pei-Yi Hao*, “Interval Regression Analysis 
using Support Vector Networks,” Fuzzy Sets and 
Systems, vol. 160, no. 17, pp. 2466-2485, 
September 2009. (SCI/EI).  
2. Pei-Yi Hao*, “Fuzzy One-Class Support Vector 
Machines,” Fuzzy Sets and Systems, vol. 159, no. 
18, pp. 2317-2336, September 2008. (SCI/E).  
3. Pei-Yi Hao* and Lung-Biao Tsai, “Predicting 
Residue-Wise Contact Orders in Proteins by 
Support Vector Regression with 
Parametric-Insensitive Model,” The 22th 
International Conference on Industrial, 
Engineering & Other Applications of Applied 
Intelligent Systems (IEA/AIE 2009), Tainan, 
Taiwan, 24-27, June, 2009. 
4. Hao, Pei-Yi, “Shrinking the Tube: A New 
Support Vector Regression Algorithm with 
Parametric Insensitive Model,” The 6th 
International Conference on Machine Learning 
and Cybernetics (ICMLC2007), Hong Kong, 
China, 19-22, August 2007.  
5. 郝沛毅, 蔡龍表, 林民勗,“新的支撐向量分類
機-使用參數化邊界,＂Proceeding of the 12th 
Conference on Artificial Intelligence and 
Application (TAAI 2007), Yunlin, Taiwan, Nov. 
2007. 
6. 蔡龍表,郝沛毅,“預測蛋白質殘基接觸程度-
使用參數化不敏感區間的支撐向量迴歸機,＂
Proceeding of the 12th Conference on Artificial 
Intelligence and Application (TAAI 2007), 
Yunlin, Taiwan, Nov. 2007.  
7. Hao, Pei-Yi, Lung-Biao Tsai, and Min-Shiu Lin, 
“A New Support Vector Classification Algorithm 
with Parametric-margin Model,” The 2008 
International Joint Conference on Neural 
Networks (IJCNN2008), Hong Kong, China, 2-6, 
June, 2008 
 
參考文獻 
[1] S.F. Altschul, T.L. Madden, A.A. Schäffer, J. 
Zhang, Z. Zhang, W. Miller, and D. J. Lipman, 
“Gapped BLAST and PSI-BLAST: a new 
generation of protein database search programs”, 
Nucleic Acids Research, vol. 25, no.17, pp. 
3389-3402, 1997. 
[2] A. Bairoch, R. Apweiler, “The SWISS-PROT 
protein sequence data bank and its supplement 
TrEMBL in 2000,” Nucleic Acids Res, Vol.28(2), 
Jan 2000, pp 45-48. 
[3] Ben-Hur and W. S. Noble, “Kernel methods for 
predicting protein-protein interactions,” 
Bioinformatics, 21 suppl: i38-i46, 2005.  
[4] H. M. Berman, J. Westbrook, Z. Feng, G. 
Gilliland,T.N. Bhat, H. Weissig, I. N. Shindyalov, 
P. E. Bourne, “The Protein Data Bank,” Nucleic 
Acids Res, Vol.28(2), Jan 2000, pp 235-242. 
[5] J. R. Bock and D. A. Gough, “Predicting 
protein–protein interactions from primary 
structure,” Bioinformatics, 17 (5): 455-460, 2001. 
[6] R. Bonneau, I. Ruczinski, J. Tsai, and D. Baker, 
“Contact order and ab initio protein structure 
prediction”, Protein Sci, 1937-1944, 2002. 
[7] J. R. Bradford and D. R. Westhead, “Improved 
prediction of protein-protein binding sites using a 
support vector machines approach,”  
Bioinformatics.” Vol. 21(8):1487-1494, 2005. 
[8] M. P. S. Brown, W. N. Grundy, D. Lin, N. 
Cristianini, C. W. Sugnet, T. S. Furey, Jr.M. Ares, 
D. Haussler. “Knowledge-based analysis of 
microarray gene expression data by using support 
vector machines.” Proc. Natl. Acad. Sci. USA, 
97:262-267, 2000. 
[9] C. Cortes, and V.N Vapnik,.” Support Vector 
Network”. Machine learning, vol. 20, pp. 1-25, 
1995. 
[10] C. Deane, L. Salwinski, I. Xenarios, D. 
Eisenberg, “Two Methods for Assessment of the 
Reliability of High Throughput Observations.” 
Molecular & Cellular Proteomics, 1:349–356, 
2002. 
[11] C. H. Q. Ding and I. Dubchak, “Multi-class 
protein fold recognition using support vector 
machines and neural networks”, Bioinformatics, 
vol. 17, no. 4, 2001, Pages 349-358. 
[12] S. Dohkan, A. Koike, and T. Takagi, “Support 
vector machines for predicting protein-protein 
interactions,” Genome Informatics 14: 502-503, 
2003. 
[13] P.F.N. Faisca and R.C.Ball, “Topological 
complexity, contact order and protein folding 
rates”, J. Chem. Phys, vol. 117, pp.8587-8591, 
2002. 
[14] S. M Gomez, W. S. Noble, and A. Rzhetsky, 
“Learning to predict protein-protein interactions,” 
Bioinformatics, 19: 1875-1881, 2003. 
[15] P.-Y. Hao, “Shrinking the Tube: A New Support 
Vector Regression Algorithm with Parametric 
Insensitive Model,” The 6th International 
Conference on Machine Learning and 
Cybernetics (ICMLC2007), Hong Kong, China, 
19-22, August 2007. 
[16] S. Hua and Z. Sun. “A novel method of protein 
secondary structure prediction with high segment 
overlap measure: Support vector machine 
approach.” Journal of Molecular Biology, 
 30
reliable are experimental protein-protein 
interaction data?” Journal of Molecular Biology. 
327(5):919–923, 2003. 
[42] T. Tax and R. Duin, “Support vector domain 
description”. Pattern Recognition Letters, vol. 20, 
pp. 11-13, 1999. 
[43] V. N. Vapnik, The Nature of Statistical 
Learning Theory. Springer-Verlag, New York, 
1995. 
[44] Z. Yuan, “Better prediction of protein contact 
number using a support vector regression analysis 
of amino acid sequence”, BMC Bioinformatics, 
6:248, 2005. 
[45] H. Zhou and Y. Zhou, “Folding rate prediction 
using total contact distance”, Biophysical Journal, 
2002, Vol.82, p.458~p.463. 
 
