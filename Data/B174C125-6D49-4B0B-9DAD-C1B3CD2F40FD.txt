 1
whole face images to extract dynamic 
information of pose variation. To investigate 
the dynamic face information extracted from 
the image sequences, each person is 
represented by an appearance manifold, 
which consists of a collection of pose 
manifolds. We apply the K-means algorithm 
to cluster the image sequences of the talking 
face for each person for the sake of 
constructing the complex nonlinear 
appearance manifold for each person. In 
order to extract facial features, we develop a 
new system, which uses embedded hidden 
markov models and obtain segmentation of 
facial features. After extracting blocks of 
each feature, we represent each cluster as 
several feature planes, which are computed 
by principal component analysis (PCA). To 
take the dynamic information of the talking 
face into account, the transition probabilities 
between the pose manifolds are computed 
from the image sequences. We can compute 
distance between each frame in a text video 
and an appearance manifold by combining 
local distances of facial features and the 
temporal information of pose variations. In 
the experiments, the hit rates of our system, 
which implements facial-feature-based pose 
manifold, achieve 88.2% and 91.4% while 
the false alarm rates are about 1.7% and 
2.9%. Compared with the holistic face pose 
manifold the hit rates of our system gain 5% 
and 4% in hit rate.  
 
Keywords: Person Authentication, Biomet- 
rics, Pose Variation, Appearance Manifold, 
Pose Manifold, Embedded Hidden Markov 
Model, Facial Feature Extraction. 
 
二、緣由與目的 
隨著科技的進步，自動的身分確認已
成為一個愈來愈重要的研究領域。基於憑
證 (token-based) 或 基 於 知 識
(knowledge-based)的方法已經愈來愈不敷
安全及便利的需求。因此，利用生物特徵
的身分確認系統在近年來是一個非常熱門
的課題。在各種生物特徵中，人臉是最明
顯的外露特徵。就人類視覺而言，在相當
遠的距離時我們便可藉由人臉來分辨出對
方的身分，因此人臉辨識與確認一直是電
腦視覺領域持續關注探討的問題。 
所 謂 的 「 人 臉 身 分 確 認 」 (face 
authentication) ，與「人臉識別」 (face 
recognition)並不是完全相同的工作；前者
是要針對處理對象所宣稱的身分做出確認
的動作，後者則是要判斷處理對象的身分
是誰。這兩種工作在決策方式與評估方法
不盡相同。相關的研究大致可以根據人臉
特徵的資訊來源分成兩大類，一類使用人
臉的靜態資訊，這一類的方法會希望所處
理的人臉盡量不要有表情變化；另一類則
是利用人臉的動態資訊，這一類的方法希
望所處理的人臉最好能有一些表情或唇形
變化。在上一年度的實驗當中，我們發現
要以表情或唇形動態變化資訊做為人臉確
認或識別的依據，必須取得足夠精確仔細
的動態資料，而一般攝影機的取像頻率(每
秒取三十張影像)並不足以提供足夠的動
態變化資訊，造成我們無法得到足夠連續
性的資訊變化，使得實驗無法得到令人滿
意的結果。因此，若想以唇形和臉部表情
的動態資訊做為人臉辨識或確認依據，我
們必須使用具有相當高取樣頻率的攝影
機。在考量實際應用後，我們決定以取得
人臉在不同姿勢變化的動態資訊為目的，
並以整張人臉為取像資料。 
而人臉辨識與確認所遭遇的主要問
題，分別有姿勢、光線、表情等。在人臉
高維空間中這些變因所造成的差距，往往
大於不同身分的差距，因此如何發展不被
這些因素影響的系統是人臉辨識與確認最
主要的研究方向。 
取得的人臉影像除了可以使用整個人
臉做為辨識與確認的依據外，以人臉特徵
(facial feature)為主的辨認法也是另一種選
項，其辨認準確率往往大於前者，但如何
有效、準確並自動得取出人臉特徵則是另
一個課題。本子計劃利用外觀高維曲面解
決不同姿勢下的人臉確認問題，並提出以
嵌入隱藏式馬可夫模型取出人臉特徵，達
 3
),(),( kiHkiH CIdLId ≈ . 
  同時，為了使 )|( ICp ki 能加入時間先
後的資訊，在每一個時間點 t，都將之前
在時間點為 0 到 t-1 的人臉影像都列入考
慮，即 ),|( 1:0 −ttki IICp 。我們可以將此考
慮時間先後因素的事後機率寫成遞迴型
式: 
Δ=− *)|(*)|( 1:0, kittttki CIpIICp α  
其中 
∑
=
−−−−=Δ
m
j
tt
kj
t
kj
t
ki
t IICpCCp
1
2:0111 )|()|(  
 
當 t=0 時，我們令 1=Δ 。機率可能函數為： 
⎟⎠
⎞⎜⎝
⎛ −
Λ=
2
2
ˆ
*2
1exp1)|( ki
ki
ki dCIP σ 。 
由上述方法，依事後機率: 
⎟⎠
⎞⎜⎝
⎛ −
Λ= ),(
1exp1)|( 22 kH MIdIkp σ  
即可將待辨識的臉部影像 I 辨識為 
 
)|(maxarg* Ikpk
k
= 。 
計算一張人臉影像和外觀高維曲面的
距離，如圖一所示，令 x 為人臉影像 I 投
影到主成分平面後的點。計算 ),( kiH LId
時，計算方法如下： 
BA
ki
H ddLId *)1(*),( αα −+=  
其中 Ad 即為 I 與 x 之間的歐氏距離， Bd 為
x 與主成分平面中點的距離。目前我們設
定參數α 為 1，意即未將 Bd 列入考慮，而
Ad 的計算方法是使用歐氏距離。 
 
四、利用嵌入隱藏式馬可夫模型實作以臉
部特徵為基準的外觀高維曲面 
隱藏式馬可夫模型[5]是以一群統計
模組的集合來抓出一段訊號的統計特性。
因為隱藏式馬可夫模型可以自動得到訊號
之間的狀態轉換變化，因此在訊號處理中
是十分熱門的工具。[6]是第一個將隱藏式
馬可夫模型套用在人臉辨識問題的論文，
其理論基礎在於人臉中由上而下的額、
臉、鼻、口、下巴等特徵，其固定的排列
順序符合隱藏式馬可夫模型的狀態轉換。 
 [7][8]提出如何將人臉辨識的問題應
用在嵌入隱藏式馬可夫模型，並以此模型
得到的機率值做為人臉辨認的結果。在本
報告中，我們將嵌入隱藏式馬可夫模型視
為抓出人臉各個特徵點的工具，其方法細
節會在以下的研究方法中詳細討論，並介
紹如何將人臉特徵應用在外觀高維曲面
上。  
1. 理論介紹 
典型的隱藏式馬可夫模型如圖二所
示，是由數個狀態組成的統計模型，並有
一組狀態轉換機率來決定在時間軸上狀態
轉換的可能性。每一個狀態各有一個混合
高斯模型做為機率密度函數。若我們將人
臉做橫向切割，並將這些切割後的人臉區
塊視為一連串的訊號，放入隱藏式馬可夫
模型中，其人臉的狀態模型如圖三所示。 
 
 
《圖二》隱藏式馬可夫模型，出自[9] 
 
 
 
《圖三》人臉隱藏式馬可夫模型，出自[6] 
 
由於人臉可視為二維資料，用嵌入隱
藏式馬可夫模型更可以保留二維資料的結
構。嵌入隱藏式馬可夫模型是由一組超狀
態所組成，每一個超狀態內部都內嵌一個
隱藏式馬可夫模型。我們可以將人臉二維
資料用此模型表示如圖四，超狀態表示人
 5
這是集合中的第 i 張人臉影像，j 則是代表
對第 j 個特徵而言， jikx ,, 和 jiky ,, 則是屬於
此特徵的中心點位置， max,, jikw 和 max,, jikh 則是能
夠將此分割包圍住的最大寬度和最大高
度，如下圖所示。 
 
 
《圖七》取出特徵點中心位置和最大寬高 
 
 有了每一張人臉影像各個特徵的中心
位置和最大寬高的數值後，計算其平均寬
高 ∑∑ ==
i
jik
avg
jk
i
jik
avg
jk hl
hw
l
w max,,,
max
,,,
1,1 ，l 為 kS
中人臉個數值。最後對 kS 中的人臉影像
iI ， 第 j 個 特 徵 jkif , 則 以
),,,( ,,,,,,
ave
jk
ave
jkjikjik hwyx 決定在人臉影像中的
區塊位置和大小，最後的特徵位置如圖八
所示。 
 
 
《圖八》人臉的二十個特徵區塊位置 
 
 對於某一張測試影像 I，若我們想要
計算其人臉特徵和某一身分的某一姿勢高
維面度的距離時(由 kS 求得)，由於 kS 中的
人臉特徵分別用 p 個嵌入隱藏式馬可夫模
型取得，我們必需先決定使用哪一個來做
特徵分割，我們將測試影像 I 和訓練階段
時求得 },...,,,{ 321 kpkkk SSSS 的平均影像
},...,,,{ 321
avg
kp
avg
k
avg
k
avg
k IIII 以 歐 氏 距 離 做 比
較，若 avgkiI 之距離最小，則以 kiH 取得 I 的
特徵分割，並計算出所有特徵的中心點
},,...,,,,,,{ 332211 nn yxyxyxyx ，並以訓練時得
到 kS 的每一個特徵之平均寬高決定此測
試 影 像 的 人 臉 特 徵 大 小 區 塊 為
njhwyx avejk
ave
jkjj ,...,1),,,( ,, = 。 
 
五、實驗結果 
 我們搜集一組具有姿勢變化的人臉影
片資料庫，包括二十一個不同的人，每一
個人錄下四十秒鐘的影片(一秒約有 30 張
影像畫面)作為訓練用資料，並於兩個星期
後，再錄下二十秒鐘的影片作為測試用資
料，所有人臉資料均用人臉偵測器找到人
臉位置後，再以眼部偵測器找出兩眼的位
置，並根據兩眼位置對準。這兩段影片均
包括頭部向左、右、上、下四種不同方向
的轉動，圖九為自攝影機錄得的影像，圖
十則為偵測校準後的人臉影像。 
 
 
《圖九》自攝影機取得不同姿勢的影像 
 
 
《圖十》經過人臉偵測和眼睛對準後， 
擷取而得的人臉影像 
 
 利用 K-means 將同一身分的人臉影像
分成五群後 (m=5)，我們再將每一群以
K-means 再次分割為五群(p=5)，並將分群
後的人臉資料訓練出專屬於此群資料的嵌
入式馬可夫模型，取得所有特徴區塊後，
