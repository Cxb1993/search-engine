applications by providing high-level semantic event 
index for digital multimedia contents. Unlike the 
previous work which can only implicitly classify or 
segment the multimedia contents, this project is to 
explicitly determine the location and appearing time 
of the semantic events that users are interested in. 
Starting with home videos, the specific domain 
knowledge is utilized to establish a complete event 
ontology and analysis framework, in which 
object/concept-level algorithms are used to associate 
with the low-level features and high-level semantics 
to automatically generate the event index of home 
videos. 
The sub-project ’intelligent content management’ 
aims to facilitate user’s management tasks on 
multimedia contents by analyzing the content to 
automatically generate the content metadata. 
Meanwhile, the add-on values of individual content 
are increased by actively associating the information 
of external multimedia database. Starting with 
personal digital traveling data, an intelligent 
travel experience management system is developed. 
Technically, with the minimum user intervention, the 
system integrates the modules of photo 
classification, photo matching, multimedia database 
retrieval, geo-info extraction, text analysis, 
content metadata generation, cross-media integrated 
presentation, and so forth to make a complete content 
management loop of given travel data from initial 
organization to final presentation. 
英文關鍵詞： personalized multimedia applications, event 
detection, semantics analysis, home videos, domain 
knowledge, ontology construction, multimedia content 
management, metadata generation, cross-media 
integrated presentation 
 
  I
 
(中文摘要) 
本計劃名稱為「個人化多媒體應用中具語義性內容分析技術之研發」，以提昇個人化多
媒體應用為目標，共分成兩大方向：(1)語意事件偵測(semantic event detection)與(2)智慧型
內容管理(intelligent content management)。分別從個人數位內容中的高階語意分析與個人化
需要兩方面著手，適切地符合使用者對於新一代數位媒體應用的需求。 
【語意事件偵測】之主要目的是對多媒體數位內容建立高階語意事件索引(high-level 
semantic event index)來輔助個人化應用的開發。有別於以往的研究只能對多媒體內容做大
致的分類或分割，本計畫希望能具體找出對使用者具高階語意的事件種類與發生的時間。
本技術將從家庭影片開始，利用相應的背景知識(domain knowledge)，建立完整的事件描述
本體(event ontology)與分析架構，藉由物件/概念(object/level)層次演算法的設計，串接起低
階特徵值(low-level feature)與高階語意(high-level semantics)間的關聯性，自動產生家庭影片
內容的事件標記。 
【智慧型內容管理】之主要目的是利用內容分析的結果自動產生內容註解(metadata)，
提供使用者便利的內容管理功能，同時主動整合外部多媒體資料庫的資訊，以提昇個別數
位內容的附加價值。本技術將從針對個人數位旅遊資料開始，建立一套智慧型旅遊見聞系
統。技術上將結合照片分類、照片比對、多媒體資料庫搜尋、地理資訊萃取(geo-info 
extraction)、文字分析、內容註解合成、跨媒體整合呈現(cross-media integrated presentation)
等模組，在使用者最低程度的參與下，將所輸入的數位旅遊資料由組織到呈現，構成一個
完整的內容管理串流。 
關鍵字：個人化多媒體應用、事件偵測、語意分析、家庭影片、背景知識、描述本體建構、
多媒體內容管理、註解合成、跨媒體整合呈現 
 
  1
(一)、 報告內容 
A 前言 
近年來，多媒體技術的快速發展為人類帶來了新一波的數位革命，多元化的多媒體內
容(multimedia contents)更成為人類生活中不可或缺的一部份。在多媒體時代中，人們所扮
演的角色，已由被動的多媒體內容接受者(content consumer)轉變為主動的多媒體內容創造
者(content creator)。以網際網路為例，使用者過去僅限於在其中取得各種所需的多媒體資訊
與服務；如今，隨著多媒體裝置與設備的普及化，他們亦能積極創造個人化的多媒體內容，
如旅遊照片與生日派對錄像，並透過多媒體社群網站與公眾分享。多媒體取代傳統文字成
為紀錄人類生活與溝通的發展趨勢，更加速多媒體內容在數量上的快速成長。於此同時，
人們對於多媒體內容的個人化需求及應用也隨之增加。個人化多媒體應用的實現仰賴於對
多媒體內容的深層瞭解 (high-level understanding)，而其中所面臨的主要困難在於如何有效
跨越語意鴻溝(semantic gap)。簡單來說，人們對於多媒體內容中所包含的高階語義
(high-level semantics)可毫無困難地利用豐富的語彙加以詮釋，然而目前的內容分析技術仍
著重以低階特徵值(low-level features)進行多媒體內容的描述，此種在多媒體內容描述語意
上的落差就稱為語意鴻溝。因此，經萃取之內容特徵值所具備的語義層級(semantic level)
與相對個人化應用所能提供的服務等級直接相關。 
以家庭影片(home video)為例，其內容是拍攝者用來紀錄其日常生活中所參與的活動，
如生日派對、觀光旅遊等。一般而言，這些日常活動是由一連串的具體事件所組成，如生
日派對包含了與壽星許願與切蛋糕等事件。因此，若能提供拍攝者具自動語意事件分析的
個人化內容管理工具，將極具實用價值。然而，由於拍攝者通常是未經專業訓練的一般民
眾，故家庭影片普遍具有音訊與視訊品質差、畫面抖動、背景雜音較大等缺點，長久以來
在內容分析領域一直被認為是極具挑戰性的主題。從使用者的觀點而言，家庭影片相較於
電影或體育影片是更為重要的個人數位資產，能夠清楚且具體的標記出影片中所發生的各
種事件，以做為影片內容組織的依據供使用者利用，才能真正提昇其多媒體使用經驗。因
此，發展一套內容高階語意的有效分析技術，在個人化多媒體應用的開發上已是刻不容緩。 
此外，在個人化多媒體應用中另一個重要的課題是如何利用所分析的高階語意進一步
加強多媒體內容的附加價值，以提高使用者對於多媒體內容的重覆利用性(reuse)。以個人
旅遊為例，錄製大量的數位旅遊見聞資料，已經成為旅遊過程中不可或缺的重要活動。不
過，在旅行結束後，旅行者面對數以千計的旅遊相片、影片、或錄音片段，必須耗費大量
的時間與精力進行手動的整理，而過程中旅行者對旅遊見聞的註解及組織，也可能因為記
憶的疏漏而造成錯誤。透過數位內容高階語意分析技術，對這些大量的家庭旅遊資料進行
分析所得的高階語意，除可幫助喚起並補強使用者的個人記憶外，更大幅提高對這些數位
旅遊內容進行有意義組織與管理的可能性與便利性。此外，透過與多媒體社群網站的數位
內容進行關聯性比對，整合其它使用者或甚至跨媒體的相關資料，如地標文字介紹或特定
景點影像，以內容加值的方式呈現出新風貌的旅遊見聞，將可讓數位旅遊見聞資料在個人
情感及數位內容價值上的效用都發揮至極限。 
B 研究目的 
綜觀多媒體技術的發展，從著重低階多媒體特徵值的分析逐漸朝向高階語意的探求並
兼顧使用者個人化需要。因此，本計劃的主要目的在於研發新一代的數位內容分析技術，
  3
 
圖二、利用 Google 圖片搜尋功能，可以找出具備不同風貌的台北 101 大樓照片。 
 
 
圖三、地圖式相簿瀏覽介面示意圖。 
C 文獻探討 
近年來以數位內容分析、個人化多媒體應用及數位家庭等課題為主的研究蓬勃發展，
知名國際學術期刊與研討會紛紛開闢專刊與研討議程介紹最新的研究成果。其中較具代表
性的包括： 
 Special issue on Semantic Media Adaptation and Personalization. Multimedia 
Systems Journal, vol. 13, no. 2, 2007. 
 Special issue on Multimedia Information Systems. Multimedia Tools and 
Applications Journal, vol. 33, no. 3, 2007. 
使用者照片 Google Map  
來自數位行程表的景點介紹 
  
 
  5
挑戰性的課題。 
 國內相關研究 
就國內相關研究而言，舉凡貝蘇章教授、陳良弼教授、李素瑛教授、陳銘憲教授、與
廖弘源教授等，均在內容分析技術方面有相當卓越的研究成果產出。本計畫的提出旨在進
一步提昇多媒體語意技術開發與個人化應用的落實，因此我們深信，本計劃的產出配合上
前述學者的研究成果具有極佳相輔相乘的效果，將可使國內學術界在數位內容分析與應用
的技術水平達到國際一流的境界。 
D 研究方法與成果 
本計劃欲就【語意事件偵測】與【智慧型內容管理】兩大方向，發展相關的數位內容
分析技術，以提昇個人化多媒體應用的有效開發與數位家庭遠景的落實。第一年以建構高
階語意事件描述本體、萃取低階特徵值、必要數位詮釋資料之萃取及輸入、數位旅遊景點
照片分群與分析，為主要研究內容。第二年著重於家庭影片中階物件萃取、提昇低階特徵
值萃取之雜訊容忍性、完成自動化數位旅遊見聞註解，以及實作初步的旅遊見聞呈現。以
下分別就兩大方向的研究方法與成果作詳盡說明。 
D.1 【語意事件偵測】 
多媒體中的語意事件，是指就人類活動而言，具有約定俗成意義而使用者較感興趣的
互動事件，因此語意事件的自動偵測是達成有效個人化多媒體應用的重要步驟。傳統上，
自動語意事件的偵測是利用相對事件中所萃取的低階特徵值直接進行機器學習而得。具體
而言，在給定特定的語意事件下，由多媒體內容中萃取出多種低階特徵值，再根據特徵值
的分布特性建立相對的機率模型，經由適當的模型整合，以做為相對事件的事前機率(a prior 
probability)。特徵值的模型整合一般可分為兩大類，分別是早期整合(early fusion)與延後整
合(late fusion)。早期整合是指當多種低階特徵值由多媒體內容中萃取出後，立即合併為較
高維度的特徵值向量(high-dimensional feature vector)，做為機率模型建立的基礎；而延後整
合則是指當多種低階特徵值各自建立相對應的機率模型後，才加權合併為最終的單一模型。
然而，這兩種方法都面臨共同的難題，那就是語意鴻溝(semantic gap)。由於低階特徵值無
法用以描述人類所能詮釋的高階語意，因此無論是利用調整機器學習的訓練參數(training 
parameters)或是代換機率模型的基本架構，如貝式網路(Bayesian network)或隱性馬可夫模型
(Hidden Markov model)，都難以有效提昇語意事件的偵測正確性。 
D.1.1  事件描述本體建構(event ontology construction) 
在語意事件偵測中另一個重要的研究課題是語意事件描述本體(semantic event ontology)
的建構，其用於定義欲偵測事件的種類以及具關聯性的物件(object)或概念(concept)。有效
的個人化應用必須建立在合理且完整的描述本體架構上。可以發現的是，一個事件的發生
在不同的時空背景下有其不同的代表意義。例如，眾人齊唱生日快樂歌在生日派對中是代
表眾人對壽星的祝福，然而若在合唱比賽中發生，則僅僅做為演唱曲目的一首。相反地，
結婚典禮的影片中一般都包含新人交換信物的事件，然而此事件在其它影片中卻鮮少被觀
察到。因此，在事件描述本體的定義或偵測上，分析內容的特定背景知識(specific domain 
knowledge)也需一併納入考量，或被深入的瞭解或觀察，所偵測的事件才能符合使用者的
實際需要。我們針對不同內容的家庭影片進行觀察，並根據內容背景知識或使用者喜好，
  7
舉例來說，在牧師致詞與結婚誓言等事件中，與會者均保持肅靜以聆聽牧師或新人的說話
內容。相反地，在唱詩以及新娘進場等事件中，唱詩班是在鋼琴伴奏下進行演唱或是在事
件中播放選定的背景音樂，如莫札特的結婚進行曲。基於婚禮音訊錄音品質一般不佳的現
象，我們由文獻上常見的數十種音訊特徵值中根據實驗選出對於雜音容錯能力較佳的三種，
分別是過三分之一能量值 (one-third energy crossing)、安靜區間頻率值 (silent interval 
frequency)、以及音樂成份比率值 (music component ratio)。此外，掌聲與歡呼聲是在婚禮與
生日派對中用以表現歡愉、祝福或欣賞的重要方式。基於音訊錄音品質一般不佳的現象，
我們開發一相對應的音訊特徵值，稱為加權短時間能量值 (weighted short-time energy)，其
具體定義如下： 
  s dSFWWSEWSE
 
0
2
max
)1|)(log(|10)(1  
其中 SF(ω) 為頻率ω之短時間傅立葉轉換係數 (short-time Fourier transform coefficient)，而
W(ω)為相對應之加權函數。 
 中階視訊物件 
與會者在參加生日派對或婚禮時往往會拍照，而所拍照片的多寡大致可反應該事件的
相對重要性。因此，我們利用閃光燈在訊框 (frame) 中出現時會造成全域亮度顯著提昇的
特性，定義相對應的視訊特徵值，稱為閃光燈密度值 (flash density) 如下： 


 
1
2
11 ))( and )((
M
t
I
t
I
t
I
t
I
t ffffIFLD   
其中 M、ftI 分別為訊框數量以及訊框 ft 之平均亮度，而ε是設為 5 之臨界值。此外，生日
派對中的生日快樂歌事件通常包含著燭火物件，為了偵測燭火物件，我們以 n x n 像素大
小的窗格為基本單位(在實驗中此 n 分別設為 10,20,30,40,50)，以適度的重疊方式掃描整張
影像，每掃過一個區塊即取出該區塊所有像素之顏色資訊(RGB 值)，將其轉換為對光影與
環境雜訊容忍度較高的 Lαβ值，並取所含像素之 Lαβ平均值代表該區塊之低階色彩特
徵值，最後利用支持向量機(support vector machine, SVM)學習出可能為燭火之色彩值。 
在婚禮影片中，不同事件中所包含的主角人物不盡相同，例如新郎進場事件的主角是
新郎與其伴郎，而交換信物事件的主角則是新郎、新娘、與牧師。由此可見，主角人物的
出現模式可做為事件偵測的重要視覺線索。然而，由於拍所有主角人物的有效辨認並不容
易達成，而根據西方傳統可發現，相對於其它人物可有不同的顏色穿著，新娘恆穿著白紗
以象徵純潔。因此，我們利用影像處理的技巧，包含臨界值法 (thresholding)、形態運算 
(morphological operations)、與投射直方圖 (projective histogram) 等，由訊框中求得新娘白
比率值 (bridal white ratio) 做為視訊特徵值之一種。 
D.1.3 家庭影片事件模型化 
藉由觀察可發現像是婚禮或是生日類型的影片是一種連續性資料 (sequential data)，也
就是說單一事件的發生是與已發生事件的種類高度相關。因此，事件模型化不只需估計所
萃取之影片特徵值與各事件的相似程度，稱為事件模型化 (event modeling)，也必須考慮時
間軸上事件發生的合理性，稱為事件轉換模型化 (event transition modeling)，這樣的時空關
係 (spatio-temporal relations) 可利用隱性馬可夫模型 (hidden Markov model, HMM) 來加以
描述。 
  9
其中 E 是婚禮事件之索引集合、Ai,k 為 A 之第 i 行第 k 列之元素。圖七以婚禮影片為例，顯
示由我們的訓練資料中所得之簡化事件轉換模型，非零機率值以符號“1＂表示。將事件轉
換模型與前述之事件模型整合，即可構成隱性馬可夫模型的所需參數集合，並以此對給定
的連續性家庭影片進行事件偵測。 
 
 主
要
人
員
進
場 
新
郎
進
場 
新
娘
進
場 
唱
詩
牧
師
致
詞 
結
婚
誓
言 
交
換
信
物
掀
頭
紗
簽
定
證
書 
婚
禮
之
吻 
感
恩 
禮
成 
其
它
主要人員進
場 
1 1 1           
新郎進場 1 1 1           
新娘進場   1 1 1         
唱詩    1 1       1 1 
牧師致詞    1 1 1 1   1 1 1 1 
結婚誓言      1 1 1     1 
交換信物      1 1 1     1 
掀頭紗        1  1    
簽定證書     1    1  1 1  
婚禮之吻    1 1    1 1   1 
感恩    1     1  1 1  
禮成            1  
其它    1 1    1    1 
圖七、 簡化事件轉換模型實例。 
D.1.4 模型化之事件偵測效果 
我們利用前述所開發之隱性馬可夫模型應用於婚禮影片與以進行婚禮事件分析，而每段影
片均以秒為基本分析單位，事件偵測結果以混亂矩陣 (confusion matrix) 的形式呈現於圖八。
第一行代表該單位之真實事件 (ground truth)，而第一列則代表該單位經由我們的系統所偵
測的事件結果。實驗結果顯示，大部份的婚禮事件在precision與 recall的表現上均超過70%，
而部份更達到 85%的水準，如掀頭紗以及禮成等事件。此外，由圖八中可觀察到幾個現象：
第一、許多的偵測錯誤與唱詩以及牧師致詞事件相關，特別是後者。這個現象一般而言難
以避免，因為婚禮事件通常是由牧師所主持，如簽定證書，因此他的語音出現會影響事件
的判斷。第二、偵測錯誤具有群聚效應。也就是說，相似的婚禮事件較容易在彼此之間被
錯誤判斷，例如進場事件 (主要人員進場、新郎進場、新娘進場) 的偵測錯誤侷限在其本身。
第三、其它事件的 recall 值相對而言較低。這是由於其它事件本質上變化性較大，例如它
可以是讀詩或是新人點燃象徵永恆的蠟燭。 
  11
性照片進行比對，即可完成自動註解與組織的功能。最後，系統再依據使用者的需求與喜
好，產生極具意義與引人入勝的旅遊媒體展示效果。 
D.2.1  必要數位詮釋資料之萃取及輸入 
旅行者利用數位攝錄影音裝置所拍攝的旅遊見聞資料，其形式包括數位照片，數位影
片，聲音/語音片段以及數位的旅遊筆記。數位內容的檔案格式可以是各種常見的數位影音
或文字標準。數位內容除了本身的影音格式之外，其實還包含了部分可用的詮釋資料，例
如照片的建立日期或地理資訊(例如使用含 GPS 系統的照相機所產生的照片中即存有相關
的資訊)。除了相片本身所能提供的相關詮釋資料，使用者或旅行業者也可以透過方便的工
具來產生包含使用者行程及景點相關資訊的數位行程表。數位行程表是以 XML 格式來表
示的標準化文件，清楚指明旅遊中每一段時程所在的景點，並兼顧互通性與文件的可解析
性。在實際的應用中，數位行程表可由旅行者透過簡易的軟體自行輸入，亦可由旅行社提
供可轉換格式的電子行程表。另外，透過網路搜尋引擎或官方影像資料庫的協助，我們可
以搜尋到更多和景點有關的資訊，包過景點的說明及代表性照片等。此外，利用各大相簿
及搜尋網站所提供的服務，我們還可以輕易地取得具有完整註解的地圖資訊。圖九為一個
以 XML 格式呈現的數位行程表，其中包含了該次旅程中每一天所參觀景點的名字與相關
介紹。 
 
 
圖九、以 XML 格式之數位行程表。 
 
D.2.2  數位旅遊景點照片分群與比對分析 
大部分數位相機仍未能在拍照時提供 GPS 地理資訊，因此照片的分群與標註是極為挑
戰的一個問題。我們可以依據某次旅行的數位行程表，從網路影像搜尋引擎中獲得網際網
路上與該次旅行行程有關的景點資訊，其中最主要的資料就是各景點的參考照片。假設 kj
為第 j 個景點之名稱，以 kj 為詢問(query)關鍵詞，我們可以從網路影像資料庫中搜尋出 m
張(m=10)參考照片(ISj)。接著，我們將需要整理的旅遊照片加以分群。由於旅遊時遊客通常
會在一個景點密集拍多張照片，而從一個景點轉換到另一個景點之間會有較長的時間幾乎
  13
片，再以上述之 SIFT 比對方法對剩餘可能相似的照片做比對。 
 
圖十、在 Google/Yahoo!搜尋引擎中輸入關鍵字“艾菲爾鐵塔(Eiffel Tower)＂時所回傳的前
十張圖片。 
D.2.3 自動化的數位旅遊見聞註解與旅遊見聞呈現 
根據旅遊景點分群與比對的結果，即可將數位行程表中每個景點的相關資訊註解於相
對應的使用者拍攝照片中，如此一來即使旅行者的相機不具有 GPS 設備，依然可以利用我
們所提出的方法做正確的註解。如果旅行者所遊覽的不是相隔較遠的多個景點，而是某一
個大區域中的多個小景點，此旅遊見聞系統仍然可行，因為大多數含有多個小景點的旅遊
區，都會有官方機構提供該區域的地圖以及相關資訊，我們僅需將景點資訊來源由原本的
網路搜尋引擎改為官方提供的旅遊資訊與景點介紹圖片即可。接著，我們便可根據旅行者
所拍攝的照片，整合景點資訊(例如地圖、特色介紹、相關照片等)，呈現予使用者(如圖三
所示)。照片是最常用於紀錄旅行經歷的媒體，然而現今利用影片、音訊檔來記錄見聞的旅
行者也日益漸增，一旦照片被分群且標註完成，我們便可將其他類型的媒體檔依據錄製時
間與照片做對齊(alignment)一併呈現。數位旅遊資訊管理與呈現之完整架構圖請參見圖十
一。 
  15
(二)、 參考文獻 
[1] D. Gatica-Perez, A. Loui, and M.-T. Sun. Finding structure in home videos by 
probabilistic hierarchical clustering. IEEE TCSVT, 13(6):539–548, June 2003. 
[2] Y. Zhai and M. Shah. Automatic segmentation of home videos. Proc. IEEE ICME’05, 
pages 9–12, 2005. 
[3] R. S.V. Achanta, W.-Q. Yan, and M. S. Kankanhalli. Modeling intent for home video 
repurposing. IEEE MM, 13(1):46–55, Jan.-Mar. 2006. 
[4] Z. Rasheed and M. Shah. Detection and representation of scenes in videos. IEEE TMM, 
7(6):1097–1105, Dec. 2005. 
[5] P. Yin, X.-S. Hua, and H.-J. Zhang. Automatic time stamp extraction system for home 
videos. Proc. IEEE ISCAS’02, pages 73–76, 2002. 
[6] M. Cooper, J. Foote, A. Girgensohn, and L. Wilcox. Temporal event clustering for digital 
photo collections. Proc. ACM MM’03, pages 364–373, 2003. 
[7] C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006. 
[8] T. Mei, X.-S. Hua, H.-Q. Zhou, and S. Li. Modeling and mining of users’ capture 
intention for home videos. IEEE TMM, 9(1):66–77, Jan. 2007. 
[9] C. Dorai and S. Venkatesh. Computational media aesthetics: Finding meaning beautiful. 
IEEE MM, 8(4):10–12, Oct.-Dec. 2001. 
[10] A. Aner-Wolf and L. Wolf. Video de-abstraction or how to save money on your wedding 
video. Proc. IEEE WACV’02, pages 264–268, 2002. 
[11] Y. Takeuchi and M. Sugimoto. Video summarization using personal photo libraries. Proc. 
ACM MIR’06. 
[12] Y.-F. Ma, L. Lu, H.-J. Zhang, and M. Li. A user attention model for video summarization. 
Proc. ACM MM’02, pages 533–542, 2002. 
[13] W.-H. Cheng, C.-W. Wang, and J.-L. Wu. Video adaptation for small display based on 
content recomposition. IEEE TCSVT, 17(1):43–58, Jan. 2007. 
[14] X.-S. Hua, L. Lu, and H.-J. Zhang. Optimization-based automated home video editing 
system. IEEE TCSVT, 14(5):572–583, May 2004. 
[15] G. D. Abowd, M. Gauger, and A. Lachenmann. The family video archive: An annotation 
and browsing environment for home movies. Proc. ACM MIR’03. 
[16] M. Chen, S.-C. Chen, M.-L. Shyu, and K. Wickramaratna. Semantic event detection via 
multimodal data mining. IEEE SPM, Mar. 2006. 
[17] J.-H. Lim, Q. Tian, and P. Mulhem. Home photo content modeling for personalized 
event-based retrieval. IEEE MM, 10(4):28–37, Oct.-Dec. 2003. 
[18] Flickr, http://www.flickr.com. 
[19] Picasa, http://picasa.google.com/. 
[20] Yeh, T., Tollmar, K., and Darrell, T. Searching the web with mobile images for location 
recognition. In Proceedings of IEEE Computer Society Conference on Computer Vision 
and Pattern Recognition, vol. 2, 2004, 76-81. 
[21] Wang, C., Jing, F., Zhang, L., and Zhang, H.-J. Scalable search-based image annotation 
  17
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 無 
技轉：已技轉 □洽談中 □無 
其他：（以 100 字為限） 
 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
本計畫研發新一代的數位內容分析技術，俾使個人化多媒體應用更能符合使用者的實際需
要，進一步提昇數位內容的本體與附加價值，以滿足使用者的個人化多媒體經驗為主要研
發目標。我們為連續性的家庭影片定義不同的事件描述本體，同時抽取出具雜訊容忍性的
低階特徵及中階物件，進而利用隱性馬可夫模型偵測家庭影片中所包含的高階語意事件。
另一方面，為了讓進行自助旅行的使用者便於整理大量的旅遊照片，我們提供方便的註解
資料產生工具，讓旅行者或提供旅遊服務的業者能很容易地輸入旅遊資訊。根據數位照片
之拍攝時間與內容特徵，我們將旅者所拍攝之照片分群並自動對應至所屬的景點，藉由所
對應景點的其他媒體檔案自動完成照片註解。隨著現有網路資訊以及各景點之官方旅遊資
訊日益完整，未來可望成為一廣為使用之旅遊見聞呈現系統！ 
 
一、CIKM國際會議簡介及其重要性 
 
Conference on Information and Knowledge Management (CIKM)是 ACM學會中整
合 Knowledge Management(KM)﹐Information Retrieval(IR)及 Database(DB)三大
息息相關領域之頂尖學術會議。由於 CIKM所含括的 KM﹐IR及 DB可說是
資訊產業的核心，因此 CIKM不僅每年均吸引大量學者專家與會交流研究心
得，更安排有 Industrial Event﹐邀請實際相關資訊產業從事人員，發表業界
對各項技術之實務心得及期望。由於歷屆成效卓著，CIKM已是 ACM學會
中非常重要，更是資訊領域中極受重視的國際會議之一。 
CIKM的重要性可由以下幾項指標可獲得證實: 
1. 投稿量及論文接受率: 
以今年為例，CIKM總計收到來自歐、美、亞、非及中東地區共 918篇
的投稿論文，經過嚴格的審查，其中 134篇被接收為長篇(口頭報告)論文
(長篇論文接受率僅有 15%)，98篇為短篇論文，另有 98篇為 poster(總計
之論文接受率亦僅有 35%)。 
2. 業界的支持: 
由於 CIKM極受資訊學界重視，因此舉凡知名的資訊產業研究單位，
如:EMC2、Microsoft Research、Google、Yahoo! Research、SAP、Yandex、
IBM Research、eBay Research Labs、Cambridge University Press、Springers、
Taylor & Francis、and Gross Ref等不但都提供經費的贊助，更派員參加各
場學術研討會，及 Industrial Event等活動。 
 
二、參加會議之過程 
 
今年的CIKM會議地點選在蘇格蘭的首府Glasgow市，由於距離台灣相當遠，
為兼顧會議時間前後在台的工作及所需的飛行時數，本人選擇華航直飛倫敦
的航線，先於 10月 23日早晨由桃園機場直飛英國首都倫敦，在倫敦休息一
夜，10月 24日早晨由倫敦搭火車直達 Glasgow會場，參加 10時開始的
Before-Main-Conference Workshop: Detecting and Exploiting Cultural Diversity on 
Social Web(DETECT 2011)，24日晚上參加了在大會會場 Crowne Plaza Hotel
之 Argy11廳所舉辦的Welcome Reception，淺嚐了蘇格蘭知名的Whisky酒。 
  10月 25日上午 8時 30分參加了大會所安排的第一場 Keynote Speech: 
Creating User Interfaces that Entice People to Manage Better Information。主講人是
來自MIT的 CSAIL-Lab的 David Karger教授，Prof. Karger向來就是以其在開
發 Semantic-Web工具，提升 Information Management及 Retrieval效率方面著
稱。在此次的 Keynote Speech中，Prof. Karger以其切身的經驗及有系統的 User 
Study來證實透過有效的工具，使用者獲得的資訊量與質均可大幅提升，其
中由他所領導的 SIMILE計畫所開發完成的工具，值得從事 KM工作者仔細
with Image提出以 Image Data來豐富教科書的內容，很有啟發性也很具實用
性。 
  中午午餐時巧遇 Prof. Philip Yu(University of Illinois at Chicago)，並透過俞教
授介紹認識了大會 Database Sector Program Chair，Prof. Wenfei Fan(University of 
Edinburgh﹐UK)，大家就一起共餐，不過談話的主題都圍繞在今年台灣的總
統大選上。 
  經由俞士崙教授的推薦，26日下午我參加的 Session主要為 Information 
Retrieval Implementable Techniques﹐Keyword Search and Ranked Queries Image 
Retrieval及 Evaluation and Analysis等 Session。由於晚上有 Banquet，下午
Session的參與人數較 25日少了些。 
  今年 CIKM大會的 Banquet安排在離大會會場步行 20分鐘可到的
Kelvingrove Art Gallery and Museum(建造於 1888年)，而晚宴內容以蘇格蘭風
味為主，雖然主人非常熱情，但是口味對我而言，仍不太習慣。 
  10月 27日 8時 30分，大會安排的最後一場 Keynote Speech是由 University 
of Roma La Sapienza的 Prof. Maurizio Lenzrini主講:Ontology-Based Data 
Management。由於領域上的差別，我對這個主題比較沒有太大的興趣，不過
由現場聽眾的反應，這應該也是一個很精彩的 talk。 
  由於大會在 27日 10時起，安排了 10場由業界主講的 Industrial Events，其
內容包括了 KM﹐IR及 DB的各種挑戰及業界對學校及學界的期望，不但內
容豐富且互動良多，這是我在其他 ACM學會所舉辦的會議中很少看到的。 
  Banquet時同桌的學者專家包括中國人民大學信息學院副院長兼計算機系
主任孟小峰教授，及專攻 Data Mining的何軍副教授，Yahoo! Labs的 Dr. Yi 
Chang﹐IBM Research的 Dr. Haggai Roitman 及 Edinburgh大學的 Prof. Wenfei 
Fan.，大家對此次大會在餐飲供應(Buffet式的中餐)及交通(安排義工指引到
City Center之路線)的安排上，都深表讚許，其次對 Keynote Speeches及
Industrial Events的安排都給予很高的評價。 
  CIKM的Main Conference到 27日結束。10月 28日大會仍安排有
Post-Conference Workshop，我個人利用 28日上午的時間參加了 Cloud Data 
Management(CloudDB 2011)的Workshop，這個Workshop是由 26日一起午餐
的孟小峰主任所主持的，其主題在探討 Cloud Computing時代巨量資料管理
所面臨的各項挑戰。28日中午在Prof. Wenfei Fan.的推薦下搭車前往Edinburgh
參觀世界知名的文化遺產愛丁堡城堡(Edinburgh Castle)，到過了 Edinburgh才
知道為何 Edinburgh人會認為 Glasgow人沒有文化。下午五點左右，再轉火
車於晚間 8點半回到倫敦，夜宿於海德公園旁。 
 
 
 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/07/08
國科會補助計畫
計畫名稱: 個人化多媒體應用中具語義性內容分析技術之研發
計畫主持人: 吳家麟
計畫編號: 97-2221-E-002-181-MY3 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
