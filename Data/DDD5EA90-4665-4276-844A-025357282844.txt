 2 
Automatic text classification (TC) is 
essential for information sharing and 
management. One popular way to TC is to build 
a classifier for each category. Upon receiving a 
document, each classifier autonomously makes 
a yes-no decision for its corresponding category. 
To make such decisions, each classifier is 
associated with a threshold. A document is 
“accepted” by the classifier only if its degree of 
acceptance (DOA) with respect to the category 
(e.g., similarity with the category or probability 
of belonging to the category) is higher than or 
equal to the corresponding threshold; otherwise 
it is “rejected.” With the help of the thresholds, 
text filtering is actually achieved in the course of 
TC. Each document may be classified into zero, 
one, or several categories.  
The ideal goals of TC are to achieve 
high-quality classification: (1) accepting almost 
all documents that should be accepted and (2) 
rejecting almost all documents that should be 
rejected. More specifically, the ideal goals aim 
to achieve high recall and precision, 
respectively. Recall is measured by [total 
number of correct classifications / total number 
of correct classifications that should be made], 
while precision is measured by [total number of 
correct classifications / total number of 
classifications made]. 
Unfortunately, the ideal goals were rarely 
achieved simultaneously, since most classifiers 
could not be perfectly built and tuned, due to 
two common problems: (1) imperfect selection 
of training documents (e.g., noises, over-fitting 
and content ambiguities) and (2) imperfect 
system setting (e.g., parameter setting and 
feature selection). These problems incur 
improper DOA estimations, and hence 
high-quality TC is seldom achieved. 
 
2.1 Problem definition 
In this project, we explore a way to help 
classifiers to achieve high-quality TC by 
conducting intelligent interaction with users. 
The interaction aims to confirm the classifiers’ 
decisions. It is intelligent in the sense that the 
users are consulted only when necessary, 
reducing the cognitive load on the users. Our 
goal is to achieve high-quality TC: achieving 
high performance in both recall and precision, 
with a controlled amount of cognitive load on 
the users. 
Interactive high-quality TC differs from 
traditional classifier-improving tasks, which 
often aimed at improving the processes of 
classifier building, threshold tuning, document 
selection, and document labeling. Actually, it 
complements these classifier-improving 
processes: when the classifiers cannot be 
improved any more, system-user interaction is a 
promising (and perhaps final) approach to 
achieve high-quality TC. 
 
2.2 Motivation 
High-quality TC is essential for those 
applications in which an erroneous TC decision 
may incur high cost and/or serious problems. 
Typical applications lie on the management and 
recommendation of critical information. 
Healthcare information support is an example of 
the applications. The Internet has been a major 
information source for patients, who require 
rich information in several aspects (e.g., cause, 
symptom, curing, and prevention of each 
disease). Automatic gathering and classification 
of healthcare information are thus helpful. 
However, information from the Internet may 
not be scientifically-based, while patients 
require information verified by healthcare 
professionals, who have only a limited amount 
of time to make verification. With interactive 
high-quality TC (1) patients may enter interest 
descriptions (e.g., symptoms), which are 
classified to retrieve relevant information (e.g., 
related diseases) or send inquiries to 
corresponding healthcare professionals, and (2) 
healthcare professionals may be consulted only 
when necessary to verify information gathered 
and classified, or respond to patients’ inquiries. 
Even for traditional tasks of information 
management and recommendation, interactive 
high-quality TC is helpful as well. For each 
category, the system may rank the incoming 
information into two types: definitely related 
and potentially related (i.e. those that require 
confirmation). With the help, managers may 
enrich the category both more precisely and 
completely, and those readers interested in the 
category may read what they should read, and 
avoid missing much information, by simply 
 4 
of documents, A is the number of documents 
that are in c and contain t, B is the number of 
documents that are not in c but contain t, C is 
the number of documents that are in c but do 
not contain t, and D is the number of documents 
that are not in c and do not contain t. Therefore, 

2(t,c) indicates the strength of correlation 
between t and c. We say that c and t are 
positively correlated if AD > BC; otherwise 
they are negatively correlated. 
 
 
 
 
3.1.2 Collaboration with the classifier 
Based on COM, the next challenge is to 
design a way for ICCOM to collaborate with 
the underlying classifier. As noted above, 
ICCOM is invoked after the classifier has made 
a decision for a document (acceptance or 
rejection). It determines whether the decision 
deserves confirmation. The goal is to achieve 
extremely high CR (and hence extremely high 
TC performance in both precision and recall). 
For each category, ICCOM collaborates 
with the classifier by tuning three thresholds: 
rejection threshold (RT), positive confirmation 
threshold (PCT) and negative confirmation 
threshold (NCT). As illustrated in Figure 1, the 
three thresholds work together to help the 
system to make decisions: rejection, acceptance, 
or confirmation. RT is used to identify those 
documents whose DOA values are too low, and 
hence may be rejected without any confirmation 
(i.e. rejection). PCT is used to check whether a 
document is accepted by both the classifier (i.e. 
DOA value  the classifier’s threshold T) and 
COM (i.e. DCO value  PCT). If so, the 
document is accepted without confirmation (i.e. 
acceptance); otherwise a confirmation is 
required (i.e. confirmation). Similarly, NCT is 
used to check whether a document is rejected 
by both the classifier (i.e. DOA value < the 
classifier’s threshold T) and COM (i.e. DCO 
value  NCT). If so, the document is rejected 
without confirmation (i.e. rejection); otherwise 
a confirmation is required (i.e. confirmation). 
It is interesting to analyze the 
contributions of ICCOM. Obviously, with 
ICCOM, the classifier’s TC performance is 
improved if the user provides correct 
confirmations. Moreover, the TC performance 
is expected to reach the ideal goal of 
high-quality TC: accepting almost all documents 
that should be accepted (i.e. high recall), and 
rejecting almost all documents that should be 
rejected (i.e. high precision). This is because 
ICCOM employs a “conservative” confirmation 
strategy: the thresholds are tuned to make 
confirmation for any possible mistake. 
Obviously, the conservative strategy may 
increase the number of confirmations required. 
ICCOM reduces the number by identifying the 
cases where no confirmation is required. These 
cases fall into two types: (1) those that the 
classifier rejects confidently (by RT), and (2) 
those that both the classifier and COM accept 
(by PCT) or reject (by NCT). Empirical 
evaluation is helpful to precisely measure the 
contributions of ICCOM 
 
3.2 Empirical evaluation and case study 
.An empirical evaluation on Reuters-21578 
and a case study on Chinese cancer information 
are conducted measure the contributions of 
ICCOM.  
 
3.2.1 Experiments on Reuters-21578 
Reuter-21578 is a public data collection 
(http://www.daviddlewis.com/resources/testcoll
ections/reuters21578). To conduct objective 
and thorough investigation, ICCOM is 
evaluated under different circumstances, 
including (1) sources of experimental data, (2) 
kinds of test data, (3) settings of training data, 
(4) underlying classification methodologies, and 
(5) settings for the classification methodologies 
. There are 135 categories (topics) in the 
collection. We employ the ModLewis split, 
which skips un-used documents and separates 
 6 
CP will approach 0 and hence the classifier 
becomes nearly unusable). Therefore, 
interactive high-quality TC aims to achieve 
nearly 100% in CR, under the requirement that 
CP should be as high as possible. 
 
3.2.1.2 Underlying classifiers 
ICCOM is applied to two classification 
methodologies: (1) vector-based methodology, 
and (2) probability-based methodology. For the 
former, we implement a Rocchio classifier with 
thresholding (RO), while for the latter, we 
implement two Naive Bayes classifiers: a Naive 
Bayes classifier with thresholding (NB) and a 
Naive Bayes classifier with a fixed threshold of 
0.5 (NBFix05). All systems associate each 
category c with a classifier. Upon receiving a 
document d, the classifier estimates the 
similarity between d and c (i.e. DOA of d with 
respect to c) in order to make a binary decision 
for d: accepting d or rejecting d. 
All the classifiers require a fixed 
(predefined) feature set, which is built using the 
documents for classifier building. Each term 
that is not a stop word may be a candidate 
feature. No phrases extraction routine is 
invoked. Features are selected according to 
their weights, which are estimated by the 2 
(chi-square) weighting technique. The technique 
has been investigated and shown to be more 
promising than others. As noted above, there is 
no perfect way to determine the size of the 
feature set. Setting a proper feature set size was 
often an experimental issue in previous studies. 
Therefore, to conduct more thorough 
investigation, we try 5 feature set sizes, 
including 1000, 5000, 10000, 15000, and 20000, 
since there are about 20000 different features in 
the 2-fold training data. 
To make filtering and classification 
decisions, both RO and NB require a 
thresholding strategy to set a threshold for each 
category. As in many previous studies, RO and 
NB tune a relative threshold for each category 
by analyzing document-category similarities. 
The threshold tuning documents are used to 
tune each relative threshold. As suggested by 
many studies, the thresholds are tuned in the 
hope to optimize the system’s performance with 
respect to F1. Moreover, we also design a 
version of NB that employs a fixed threshold of 
0.5 for each category (i.e. no threshold tuning). 
This version of NB is named NBFixed05. It was 
tested in several previous studies as well. 
 
3.2.1.3 Baseline confirmation strategies 
There are two straightforward 
confirmation strategies to pursue interactive 
high-quality TC: Uniform Confirmation (UC) 
and Probabilistic Confirmation (PC). For each 
category c, both strategies are based on 
threshold tuning documents (i.e. validation 
documents), which are either positive 
(belonging to c) or negative (not belong to c).  
UC sets a confirmation range. Once a 
document’s DOA value falls in the range, a 
confirmation is conducted. Since the goal is to 
achieve high CR, UC sets a range that is large 
enough to cover the DOA values of those 
documents for which the classifier might make 
mistakes. The lower limit of the range may be 
set to the maximum DOA value below which no 
DOA values of positive documents lie. Similarly, 
the upper limit may be set to the minimum DOA 
value beyond which no DOA values of negative 
documents lie. Obviously, UC may incur lower 
CP, and hence incur heavier cognitive load. 
On the other hand, PC works for those 
classifiers that tune a threshold to optimize 
performance in some criterion, such as the 
popular F1 measure, which integrates precision 
and recall by [2precisionrecall / 
(precision+recall)]. PC is based on the 
observation that those documents whose DOA 
values are closer to the threshold tend to have a 
higher probability of leading the classifier to 
make erroneous decisions. Obviously, PC hopes 
to promote CP, but may incur lower CR, and 
hence has difficulties in guaranteeing the 
classifier’s performance. 
 
3.2.1.4 Main results 
Results show that ICCOM may help 
various kinds of classifiers to achieve 
high-quality TC with a much smaller number of 
confirmations. It may even improve 
performances of well-tuned classifiers, which 
are more difficult to improve by other means. 
 
3.2.2. A case study on Chinese cancer 
????????????  
                                                             
???? NSC 95-2221-E-320-002 
???? ???????????????????? 
????
?? 
????
??? 
??? ???????????? 
????
?? 
Kyoto University, Kyoto, Japan, 26-29 June 2007 
???? 
the 20th International Conference on Industrial, Engineer-
ing & Other Applications of Applied Intelligent Systems 
(IEA/AIE 2007) 
????
?? 
Text Classification for Healthcare Information Support 
 
 
???????? 
??????? 20 ????????????????????
??????????  (? 462 ???)??????????? 
(? 116 ????)????????????????????? 
(10 ?)??????????????????? ??????
????????????????????????????
?????? ???????? ?????????????
???????????????? ????????????
???????????????????? ????????
????????????? ???????????????
????  Springer-Verlag Berlin Heidelberg ??????  LNAI 
4570? 
 
?????? 
Text Classification for Healthcare Information Support 
Rey-Long Liu 
Department of Medical Informatics 
Tzu Chi University 
Hualien, Taiwan, R.O.C. 
rlliutcu@mail.tcu.edu.tw 
Abstract. Healthcare information support (HIS) is essential in managing, 
gathering, and disseminating information for healthcare decision support 
through the Internet. To support HIS, text classification (TC) is a key kernel. 
Upon receiving a text of healthcare need (e.g. symptom description from pa-
tients) or healthcare information (e.g. information from medical literature and 
news), a text classifier may determine its corresponding categories (e.g. dis-
eases), and hence subsequent HIS tasks (e.g. online healthcare consultancy 
and information recommendation) may be conducted. The key challenge lies 
on high-quality TC, which aims to classify most texts into suitable categories 
(i.e. recall is very high), while at the same time, avoid misclassifications of 
most texts (precision is very high). High-quality TC is particularly essential, 
since healthcare is a domain where an error may incur higher cost and/or se-
rious problems. Unfortunately, high-quality TC was seldom achieved in pre-
vious studies. In the paper, we present a case study in which a high-quality 
classifier is built to support HIS in Chinese disease-related information, in-
cluding the cause, symptom, curing, side-effect, and prevention of cancer. 
The results show that, without relying on domain knowledge and complicated 
processing, cancer information may be classified into suitable categories, 
with a controlled amount of confirmations. 
1   Introduction 
The Word-Wide Web (WWW) has been a main source of healthcare information for 
both health consumers and professionals. Healthcare information support (HIS) is 
thus essential. It aims to manage, gather, and disseminate information for healthcare 
decision support through the Internet. The challenging requirements of HIS lie on (1) 
medical information on the Internet may not be scientifically-based [10], while 
patients require validated healthcare information [5], (2) healthcare information 
should be rich in several essential aspects (e.g. cause, symptom, curing, side-effect, 
and prevention of a disease, e.g. [2]), (3) healthcare professionals only have a lim-
ited amount of time and effort to gather information and/or make validation, and (4) 
even those users that receive higher education are often unable to construct proper 
queries (i.e. keywords linked with conjunction and disjunction operators [3]). 
each document may be classified into zero, one, or several categories. Unfortunately, 
in practice, most classifiers may not be perfectly built and tuned [1] [6] [14], due to 
several common problems: (1) imperfect selection of training documents (e.g. noises, 
over-fitting and content ambiguities) and (2) imperfect system setting (e.g. parame-
ter setting and feature selection). These problems are often inevitable and may incur 
improper DOA estimations. A document that belongs to (does not belong to) a cate-
gory could not always get a higher (lower) DOA value with respect to the category. 
Improper DOA estimations may heavily deteriorate the performance of TC.  
Therefore, it is difficult to have a classifier that may achieve very high perform-
ances in both precision and recall. Low precision incurs the problem of false infor-
mation recommendation, while low recall incurs the problem of incomplete infor-
mation recommendation. Both problems are essential for HIS, especially when the 
information is critical for health promotion. 
1.2 Contributions and Organization of the Paper 
Section 2 explores the feasibility of employing interactive confirmations to ap-
proach high-quality TC. The main idea is to consult healthcare professionals to 
make confirmations to some of the TC decisions made by the classifier. Its chal-
lenge lies on the tradeoff between TC performance and cognitive load of the profes-
sionals in making confirmations: higher TC performance often incurs heavier cogni-
tive load. Accordingly, in section 3 we present a confirmation strategy to achieve 
high-quality TC. To empirically evaluate the strategy, section 4 reports a case study 
in which real-world Chinese healthcare information about several categories of 
cancer are tested. The result shows that the strategy significantly performs better 
than baseline techniques. Moreover, without relying on any domain knowledge and 
complicated text processing, those diseases corresponding to Chinese descriptions of 
symptoms may be identified, making subsequent HIS tasks more targeted.   
2   Interactive Confirmations for High-Quality TC 
When classifiers have been built and tuned to their best extent, system-user interac-
tion should be a final approach to confirm the classifier’s decision to achieve high-
quality TC. Therefore, the goal of employing interactive confirmation for high-
quality TC differs from many previous attempts, which often aimed at improving 
the classifier building process (e.g. iterative classifier refinement [11]), the threshold 
tuning process (e.g. [6]), and the document selection process (e.g. boosting [8], 
adaptive resampling [4], and query zoning [9]). 
The challenge of the confirmation lies on the tradeoff between the performance 
of TC and the cognitive load incurred to health professionals. To achieve higher-
quality TC, the system often needs to consult the professionals more often, and 
hence increase the cognitive load in reading and validation. Conversely, to reduce 
the cognitive load of the professionals, the system should make decisions on its own, 
and hence deteriorate the performance of TC. To simultaneously achieve high-
decisions. Suppose DOA values fall in the range of [Min, Max]. The probability of 
conducting a confirmation for a document with respect to a category is: 
Prob(confirmation) = (D – Max) / (T – Max),  if D  T;  
= (D – Min) / (T – Min), otherwise, 
where D is the DOA value of the document with respect to the category, and T is the 
threshold tuned for the category. Obviously, PC hopes to promote CP, but may incur 
lower CR, and hence has difficulties in guaranteeing the classifier’s performance. 
Therefore, both UC and PC are not good enough to achieve interactive high-
quality TC, which aims to achieve very high CR, under the requirement that CP 
should be as high as possible. To develop a more effective confirmation strategy, the 
main technical issue lies on, among the decisions made by the classifier, intelli-
gently identifying those decisions that deserve confirmations. 
3   Intelligent Confirmation by Content Overlap Measurement 
We present an intelligent confirmation technique for interactive high-quality TC. 
The technique is named ICCOM (Intelligent Confirmation by Content Overlap 
Measurement). The basic idea is to associate each category’s classifier with ICCOM. 
Once a document is entered, the classifier is invoked to make its decision (either 
acceptance or rejection). Based on the decision, ICCOM is invoked to determine 
whether a confirmation is required. Therefore, the integrated system makes three 
kinds of decisions: acceptance, rejection, and confirmation. The expert is consulted 
only when the decision is confirmation. 
Content overlap measurement (COM) is a key basis on which ICCOM makes de-
cisions. It aims to measure the degree of content overlap (DCO) between a docu-
ment and a category [7]. The basic idea is that if DCO between c and d is not high 
enough, d should not be classified into c, even though d mentions some content of c. 
COM is particularly helpful for previous TC techniques in which whether a feature 
may be selected mainly depends on content relatedness among the categories, with-
out paying much attention to how the contents of a category c and a document d 
overlap with each other (i.e. DCO).  
Table 1 presents the algorithm for COM. Given a category c and a document d, 
the algorithm considers two kinds of terms: those terms that are positively correlated 
with c but do not appear in d (ref. Step 2), and those terms that are negatively corre-
lated with c but appear in d (ref. Step 3). Both kinds of terms lead to the reduction 
of DCO (ref. Step 2.1 and 3.1). Therefore, a smaller DCO indicates that d talks more 
information not in c, and vice versa. In that case, it is less proper to classify d into c. 
The correlation strengths is estimated by 2 (chi-square). For a term t and a cate-
gory c, 2(t,c) = [N  (AD - BC)2] / [(A+B)  (A+C)  (B+D)  (C+D)], where N 
is the total number of documents, A is the number of documents that are in c and 
contain t, B is the number of documents that are not in c but contain t, C is the num-
ber of documents that are in c but do not contain t, and D is the number of docu-
ments that are not in c and do not contain t. Therefore, 2(t,c) indicates the strength 
of correlation between t and c. We say that c and t are positively correlated if AD 
> BC; otherwise they are negatively correlated. Note that, a term t may even ap-
whether a document is accepted by both the classifier (i.e. DOA value  the classi-
fier’s threshold T) and COM (i.e. DCO value  PCT). If so, the document is ac-
cepted without confirmation (i.e. acceptance); otherwise a confirmation is required 
(i.e. confirmation). Similarly, NCT is used to check whether a document is rejected 
by both the classifier (i.e. DOA value < the classifier’s threshold T) and COM (i.e. 
DCO value  NCT). If so, the document is rejected without confirmation (i.e. rejec-
tion); otherwise a confirmation is required (i.e. confirmation). 
4   A Case Study on Chinese HIS for Cancer 
We present a case study to illustrate the contributions of ICCOM. In the case study, 
the targeted users include patients and healthcare professionals that use Chinese as 
their native language. The disease domain is cancer. As noted in Section 1.1, with 
the support of the classifier, (1) patients may employ natural language to express 
their interests (e.g. symptoms), which are classified to retrieve relevant information 
or send consultancy inquiries, and (2) healthcare professionals are consulted only 
when necessary to validate the classifier’s decision or respond to patients’ inquiries. 
4.1 Experimental Data 
Experimental data is collected from Yahoo! at Taiwan (http://tw.yahoo.com/). We 
focus on 16 types of cancers (e.g. liver cancer, lung cancer, …, etc.), which are top-
ranked by the department of health in Taiwan. For each type of cancer, documents 
are collected by sending its Chinese name as a query to the “??+” (knowledge+) 
area. The documents are then selected and separated into 5 categories: cause, symp-
tom, curing, side-effect, and prevention of the type of cancer. Therefore, there are 
totally 80 (=165) categories. They contain 2850 documents. We randomly select 
1/10 of the documents as test documents, and the others as training documents. 
As suggested by previous studies (e.g. [12]), the set of training documents is split 
into two subsets: the classifier building subset and the threshold tuning (or valida-
tion) subset. The former was used to build the classifier, while the latter was used to 
tune a threshold for each category. Both sets have the same number of documents. A 
2-fold cross validation is conducted so that each training document is used for both 
classifier building and threshold tuning only once. 
4.2 Evaluation Criteria 
To measure the systems’ performances, we employ two groups of criteria: (1) crite-
ria to evaluate the effectiveness of confirmation, and (2) criteria to evaluate the 
quality of TC. For the former, we employ the criteria defined in Section 2: CP and 
CR. For the latter, we employ the popular criteria: precision (P), recall (R), and F1. 
P is equal to [total number of correct classifications / total number of classifications 
(31.8% improvement in the 1st fold and 60.8% improvement in the 2nd fold), indicat-
ing that ICCOM enhances RO to achieve high-quality TC with fewer confirmations.  
 
Table 2. Classification of cancer information 
 Best F1 by 
RO 
F1 by 
RO+PC 
CP of 
RO+PC 
F1 by 
RO+UC 
CP of 
RO+UC 
F1 by 
RO+ICCOM 
CP of 
RO+ICCOM 
1st 
fold 
0.3485 
(FS=1500) 
0.8413 0.0969 0.9610 0.0848 0.9607 0.1117 
2nd  
fold 
0.3270 
(FS=1500) 
0.7823 0.1037 0.9656 0.0725 0.9433 0.1166 
 
We are also interested in symptom categories for the 16 cancer types. Experi-
ments on the categories may measure the performance of the system in classifying 
patients’ natural language symptom descriptions for cancer type identification. In 
testing, we remove cancer names in the test documents, since in practice patients 
often do not know cancer types for their symptoms. Table 3 summarizes the results. 
Although all the confirmation strategies may help RO to achieve very high F1, 
ICCOM achieves the best CP again. The improvement ranges from 40.5% to 
170.5%. For the 40 test symptom documents, RO+ICCOM conducts 35 and 51 con-
firmations in the 1st and 2nd folds, respectively. Therefore, to achieve high-
performance cancer type identification, only about 1 confirmation is required for a 
symptom description. The confirmation (i.e. possible cancer types) may provide the 
patients with additional reference to reduce possible identification errors. 
 
Table 3. Classification of symptom description without cancer names 
 Best F1 by 
RO 
F1 by 
RO+PC 
CP of 
RO+PC 
F1 by 
RO+UC 
CP of 
RO+UC 
F1 by 
RO+ICCOM 
CP of 
RO+ICCOM 
1st 
fold 
0.8919 
(FS=300)  
0.9610 0.0676 0.9744 0.1017 0.9610 0.1429 
2nd  
fold 
0.8718 
(FS=300) 
0.9620 0.1000 0.9750 0.0580 0.9744 0.1569 
5   Conclusion and Future Work 
Text classification is a key kernel to provide healthcare information support through 
the Internet. It helps to manage, gather, and disseminate healthcare information for 
decision support. Since healthcare is a domain where a classification error may incur 
high cost and/or serious problems, the classifier should be “conservative” in the 
sense that, when it is possible to make an error, a confirmation request should be 
issued to healthcare professionals or patients. For healthcare professionals, the con-
firmation request suggests the professionals to make validation only when necessary. 
For patients, the confirmation request provides an additional reference for patients 
to consider. The key challenge lies on the identification of possible errors for con-
firmation. In this paper, we present an intelligent conformation strategy, and explore 
its contributions in a case study on Chinese cancer information. The results are of 
practical significance to healthcare information support through the Internet.  Future 
