 2
中文摘要 
近年來隨著寬頻網路與無線網路的發展迅速，無所不在的網路漸漸成熟，網路的存取方式也有了
重大的改變，資料不只儲存在本機端的電腦或進行編輯，資料儲存在於遠端伺服器也成為一項趨勢。
資料儲存在網路中的好處是能夠讓使用者在任何地方任何時間使用或編輯同一份文件或資料，讓網路
的使用更加有彈性與多元。雲端運算的概念是透過網路將龐大的運算處理程序自動分拆成無數個較小
的子程序，再交由多部伺服器所組成的龐大系統經搜尋、運算分析之後將處理結果回傳給用戶，即使
使用者終端運算功能不夠強大也能透過網路上龐大的運算資源，使用分工的功能完成運算並作遠端的
存取動作。 
本研究的主題為『架構於雲端運算系統上高效能讀寫與資料容錯研究』，目前雲端運算的分散式系
統將會面臨私密性資料存放於公眾虛擬網路空間中、及網路與存取資料速度等問題；我們將對現行的
雲端運算架構進行改進，提升讀取與寫入資料的效能，由於網路上各節點或各伺服器的效能不一，各
網路連線的品質也相異，在使用者要存取資料的存放節點我們提出一選取的機制，並且達到同步化的
存取，透過雲端分散運算伺服器( Cloud Distributed Computing Server, CDCS )可對資料進行有效的管理
與分配，如此一來對不同的使用者終端也能有最佳化的網路存取路由，並採用分散式多點同步讀取，
使得讀取更快速且更有效率，減少反應時間，讓使用者體驗最佳化的網路服務，即使，使用者終端的
處理能力有限，經由良好的存取機制可以提升使用網路的效率。 
經過本研究計畫的執行將達到雲端運算系統( Cloud Computing )上具高可靠資料儲存選取、高效能
資料同步儲存及自我異地備援之資料的儲存機制、多點同時讀取資料、最佳選徑及資料流分類排程達
到 QoS 之讀取效率以提高虛擬空間中資料分散式儲存之安全性的研究。 
 
關鍵詞：雲端運算、資料流分類排程、分散式儲存、資料同步儲存。 
 
 
英文摘要 
With the popularization of cloud computing, more and more people choose to store data and 
operate various programs on the Internet. In such a circumstance, instead of the functions of a system, 
what users care most now is if they can access to the Internet smoothly and quickly. Thus, based on 
the present system, we propose a topic of this research is “High Effect R/W and Fault Tolerance 
Cloud Computing System.” In order to achieve fast data access, file security and data backup, this 
plan will be executed in three phases to improve the present mechanism by modifying the data access 
method, the backup mechanism and so on. We use a distributed reading system to read data 
simultaneously according to different weight value to accomplish the synchronization. Moreover, the 
condition of the bandwidth is considered to write and read. Finally, the concept of Parity Check in 
RAID is adopted. We store the data in different hosts alternatively and use XOR debugging 
mechanism to achieve the high efficient R/W and fault tolerance of cloud computing system.  
 
Keywords：Cloud Computing, Data Classification, Distributed Synchronization, Storage. 
 4
在本研究的資料儲存演算法中共包含了三個機制，分別為『資料儲存選取機制』、『資料同步儲存
機制』與『自我異地備援機制』。其資料儲存選取機制幫助找尋網路上最佳的傳輸節點做為存放資料的
地點，然而網路上的 Host 端節點由於頻寬的不同，如果存取相同的資料量將會有資料不同步的問題發
生，透過資料同步儲存機制來改善此現象，為了考慮網路上 Host 節點失效或硬碟損壞的意外，採用了
異地備援的機制來解決這個問題。 
 
研究方法 
本研究參考 Hadoop 的儲存方式的檔案系統稱為 HDFS，該系統為一種虛擬檔案系統，我們發現儲
存的機制的功能有值得改進的需求。首先 Hadoop 將檔案分散儲存的方式是隨機選取，透過本研究的演
算法計算權重後，來考慮硬碟儲存空間、網路的頻寬、Host 端的負載、儲存區域的選擇等，依照計算
出的權重值選取適當的資料存放空間，並且達到異地備援的目的。 
我們提出的資料儲存演算法中總共包含了三個機制，分別為『資料儲存選取機制』、『資料同步儲
存機制』與『自我異地備援機制』。資料儲存選取機制幫助我們找到網路上最佳的傳輸節點做為我們存
放資料的地方，然而網路上的 Host 端節點由於頻寬的不同，如果存取相同的資料量會有資料不同步的
問題，透過資料同步儲存機制可以改善此現象，為了考慮網路上 Host 節點失效或硬碟損壞的意外，我
們加入了異地備援的機制去防範與對應。 
在資料讀取部份，主要採用多點同時讀取的方式提高讀取的速度，在儲存的機制當中透過遠端的
Host 自動找尋替代的 Host 節點協助進行本地端備份或異地端備份，因此，當在讀取資料時有更多的
Host 節點可供選擇與下載。 
 
A.資料儲存選取機制 
在資料儲存選取機制，將考慮下列幾項參數，包含「Host 的硬碟空間」、「連線的頻寬大小」、「Host
的系統負載」、「區域考量」等因素。選取架構如圖 1 所示，當使用者將資料要儲存至網路空間時，透
過雲端分散運算伺服器( CDCS )先搜尋出鄰近區域各 Host 端節點並將資料適當分割為 A、B、C 三份資
料，搜尋時首先尋找足夠空間的硬碟做為儲存的 Host，如圖 1 中的 Host1 至 Host6，透過各參數經由本
演算法分析出各 Host 的權重作為儲存選取的依據，經雲端分散運算伺服器分析出 Host1、Host3、Host5
的權重相近且較高，權重相近的優點為降低資料不同步的現象，故將資料片段分別存入所挑選出來的
Host， 雲端分散運算伺服器考慮到與各 Host 的連線狀況，讓資料產生有區域網路的高速便利性並對
於系統作一負載平衡的動作。 
我們的權重計算的參數如下列式(1)所示，考慮到存取的空間、網路連線間的頻寬、存取的速度、
儲存區域、Host 端負載、Host 系統可靠度。透過不同的參數給予不同的高低優先權比重再作加總產生
權重值(Weight)當作選取的依據，相關計算公式如下列(2)~(7)，透過我們建立的實驗架構可以模擬出不
同網路場景的最佳的經驗比重值，並實際應用於雲端網路的世界。 
Weight = { HD space, Bandwidth, Link speed, Area, Host load, Reliability }*100%            (1) 
HD space = Consult Host for the information                                          (2) 
Bandwidth = Host’s Total Data Traffic / Time (Kbps)                                    (3)         
Link speed = Average Data Traffic / Time between UE and Host (Kbps)                     (4) 
Area = Check Hop Count through Routing Table                                       (5) 
Host load = Compare the Host’s {CPU, Memory. HD}                                  (6)          
Reliability = Compare the Packet Loss Rate and Effective Link Rate (%)                    (7) 
 
 6
時也能有較多來源 Host 的選擇，增加資料傳輸的效能。其詳細流程圖如下圖 4 所示： 
 
 
圖 3、自我異地備援機制 圖 4、資料儲存演算法流程圖 
D.分散式多點同步讀取 
同時多點讀取的速度將會比單點讀取的速度快，並能提高讀取的效能，如圖 5 所示，在儲存資料
時透過選定的 Host 做自動備援機制後，將使得讀取資料時能有更多的 Host 選擇，圖 5 中的 Host 節點
皆可作為讀取點，可作同時下載資料的動作，提高網路讀取速度。 
在讀取資料的過程中，將採用分散式多點同步讀取的方式，由於在儲存時有自動備援的機制，故
存在網路上的資料至少有三份，可將資料做切割讀取。如圖 6 所示，擁有使用者終端的資料節點有一
開始選定的 Host-1 及備份的 Host-2 及 Host-3，為加快讀取速度將資料切割為三份做同時下載的動作，
即為從 Host-2 下載 P1 的部份，從 Host-1 下載 P2 的部份，從 Host-3 下載 P3 的部份，理想的讀取速度
為原本僅從單一 Host 節點下載速度的三倍。由於整體存取資料的速度大大地的提升，為考慮到使用者
終端本身的處理能力，若使用者終端無法同時處理如此大量的資料，將採用降速模式下載資料，取得
網路頻寬與下載速度的平衡點，同時也考慮到了使用者終端的工作能力。 
 
 
圖 5、使用者同時讀取多節點資料示意圖 圖 6、分散式同步讀取資料圖 
 8
在資料上傳的部份本研究比較了 HDFS 與我們提出的雲端分散運算伺服器方法應用在不同的
資料大小上傳，並計算出各資料所需的傳送時間，如圖 11 所示，在 HDFS 中，預設切割的大小
Block 為 128MBytes，並在近端與遠端尋找節點作傳輸與備份的動作。我們提出雲端分散運算伺服
器中有考慮到各節點的頻寬與處理能力，對每個節點有不同比例的上傳資料量，故整體上傳時間
較 HDFS 較好。為了加快大檔案的傳輸速度，我們加強了原本的方法，建立了門檻值(Threshold)，
加入了代理人(Agent)機制，原本在遠端備份的節點透過近端區域網路尋找新代理人加快使用者整
體上傳檔案的速度，原本遠端的備份再經由代理人幫忙處理其程序，我們模擬的門檻值預設為
1000MBytes，每增加一單位門檻值就增加一近端效能較好的節點幫忙作處理的動作，故從圖 11
可發現 Th-CDCS 在大檔案傳輸時能有更好的傳輸速度，減少使用者傳輸等待的時間，如在檔案大
小為 2304Mbytes 時使用 HDFS 需要花費 1536 秒，CDCS 花費 1152 秒，Th-CDCS 僅需 682 秒，
約為 HDFS 花費時間的 45%。 
圖 12 為上傳 Average Throughput 對資料量大小的曲線圖，由於 CDCS 會依照不同節點的效能
而適當分配資料儲存量，故在整體 Average Throughput 有較好的表現，而 Th-CDCS 因有代理人的
機制故在 Average Throughput 有更好的表現。在資料下載的部份，HDFS 中的用戶端會讀取位置最
近的複本，而 CDCS 採取多點同步下載的機制，故在相同的資料量中，下載速度有更好的表現，
然而 Th-CDCS 中加上代理人節點有更多的資料節點可讓使用者同步讀取，效能近一步的提升。 
 
 
圖 11、 整體資料上傳時間比較 
 
 
圖 12 、平均傳輸量(Throughput) 比較 
 
 1
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：100 年 4 月 21 日 
一、參加會議經過 
4月10日 
The 3rd IEEE International Workshop on Mobility 
Management in the Networks of the Future World 
(MobiWorld 2011) (in conjunction with IEEE INFOCOM 
2011), Shanghai, China 
 
會議開始 
4月11日 議程 
4月12日 議程 
 
二、與會心得 
計畫編號 NSC 99－2221－E－032－040 
計畫名稱 架構於雲端運算系統上高效能讀寫與資料容錯研究 
出國人員
姓名 吳庭育 
服務機構
及職稱 淡江大學電機工程學系/助理教授 
會議時間 
100 年 4 月 10 日
至 
100 年 4 月 12 日 
會議地點 中國、上海 
會議名稱 
(中文)第三十屆電腦通訊 IEEE 國際會議的網路行動管理討論會 
(英文) The 3rd IEEE International Workshop on Mobility Management in the Networks 
of the Future World (MobiWorld 2011) (in conjunction with IEEE INFOCOM 2011) 
 
發表論文
題目 
(中文)具適應狀態感知之行動無線網狀網路的負載平衡機制 
(英文) Adaptive Situation-Aware Load Balance Scheme for Mobile Wireless Mesh 
Networks 
 3
19. Mobile commerce technologies and applications  
20. Others and emerging new topics 
 
MobiWorld Workshop 此次一共收錄 10 篇論文，其中包含了許多來自於各國名校的作者，會議同
行的者有論文共同作者們，宜蘭大學資工所碩士生廖冠綸同學與東華大學電機系博士生陳麒元同學。
在議程的安排中，我們的發表時間被安排在 4 月 10 日下午議程中發表論文。 
此次IEEE INFOCOM研討會在大陸上海的國際會議中心舉辦。與會的各國專家都是來自世界各地
的精英，如University of Maryland, USA, The University of British Columbia Canada, University of Waterloo 
Canada, Korea University Korea, Tsinghua University P.R. China等等。在會議中聽完他們報告後，能明顯
感覺到亞洲學生對於英文口說的部份的不足，與歐美學生相比仍是有段差距。歐美學生能夠很自若的
在台上報告，並且，能常常舉例說明，甚至會說一兩則笑話緩和現場氣氛。而亞洲學生則大部分採用
背稿的形式，將事先準備的英文句子一句句地背出來。最明顯的就是回答問題的時候，歐美學生對於
議程主持人或其他學者們所提出的問題幾乎都能夠立刻回答，甚至是當場與提問者討論起來。但亞洲
學生即使知道如何回答問題，也仍難回答的如歐美學生一樣地順暢，這樣的現象是因為英文不是我國
的母語有關，但最重要的原因也跟我國在外語環境的缺乏有更大的關聯，這也是以後我國學生需要留
意及被訓練的地方。 
在研討會中，最多人討論的主題就是Mobile IPv6的技術。不論是在MIPv6的路由技術上、移動管
理技術上的討論都是相當熱烈。從這次Workshop中學到的主要技術為支援Multi-flow的移動性、基於
MIPv6來將位址加密的分散式移動解決方案以及透過集中式伺服器在大型網際網路下的移動管理技
術。經由這些移動管理的最新技術的交流對於本人在研究領域中有相當大的啟發。 
 
三、建議 
此次主辦單位對於 Workshop 的註冊與會者提供的待遇稍嫌不足，僅於當日寄送 E-mail 告知會
議介紹與論文等相關電子檔案的下載連結，於會場報到後亦只領取了名牌及註冊場次的票卷。此外
大會對於各議程的控管亦十分嚴謹，各會議室皆有工作人員驗證參與場次的票卷，因此無法臨時自
由選擇至其他有興趣的場次聆聽報告，必須選擇大會全額註冊方能自由進出所有會場。在議程中與
各國與會人員交流時發現歐美等先進大學，其研究經常是廣徵各大領域之學者來共同主持，並以實
 5
 
 
 
 7
 
 
 
 
 
 Figure 1. The architecture of Hybrid WMNs. 
Adaptive Situation-Aware Load Balance Scheme for 
Mobile Wireless Mesh Networks 
 
Guan-Lun Liao1, Chi-Yuan Chen2, Shih-Wen Hsu2, Tin-Yu Wu3, Han-Chieh Chao1,2,4 
1 Institute of Computer Science and Information Engineering, National I-Lan University, Taiwan, R.O.C. 
2 Department of Electrical Engineering, National Dong Hwa University, Taiwan, R.O.C. 
3 Department of Electrical Engineering, Tamkang University, Taipei, Taiwan, R.O.C. 
4 Department of Electronic Engineering, National I-Lan University, Taiwan, R.O.C. 
r9843005@ms.niu.edu.tw; chiyuan.chen@ieee.org; m9823048@ems.ndhu.edu.tw; tyw@mail.tku.edu.tw; hcc@ niu.edu.tw 
 
 
Abstract—Mobile Wireless Mesh Networks (MWMNs) not only 
can provide high-bandwidth services for a large number of users, 
but also offers a good solution to the last-mile problems. However, 
the abundant net flow resulted from the great number of users 
may lead to the network traffic jam. To solve this problem, we 
proposed an Adaptive Situation-Aware (ASA) routing metric. We 
also designed a load balance scheme with Max-flow min-cut 
theory to route the network flow to the optimal path to achieve 
load balance among nodes in MWMNs. 
Keywords- Wireless Mesh Networks; Mobile Wireless Mesh 
Networks; Routing Metric; Load Balance 
I.  INTRODUCTION 
With the rapid development of networks in recent years, 
people nowadays always want to access high-bandwidth 
network anytime and anywhere for enjoying ubiquitous 
network services. Owing to its high transmission rate, low 
deployment cost, and high coverage, Wireless Mesh networks 
(WMN) have replaced wired networks gradually and even 
performs well in residential areas that are incapable of line-of-
sight transmissions. 
In typical WMN, the constitution of the nodes can be 
divided into three layers. The first layer is composed of Internet 
Gateways (IGWs), which is responsible for connecting external 
wired networks and internal MR (Mesh Router) to provide 
network services. MR in the second layer takes the 
responsibility for connecting the Mesh Clients (MCs) in the 
third layer and the IGW in the first layer [1]. According to this 
constitution, WMNs can be classified into three kinds: 
Infrastructure WMNs, Client WMNs and Hybrid WMNs [2]. 
• Infrastructure WMNs: MR connects the IGW and MCs, 
and MR can form a backbone for MCs’ transmissions. 
• Client WMNs: This peer-to-peer structure is 
constructed by MCs. In such an Ad Hoc network, MCs 
manage the routing and the organization. Mesh Routers 
are not necessary. 
• Hybrid WMNs: This hybrid architecture is composed 
of Infrastructure WMNs and Client WMNs as shown 
in Fig. 1. MCs can connect to MR or connect with one 
another through MCs. 
The WMNs have a stable topology, which may changes 
due to MR failures, or new MR joints to WMNs. The 
components in WMNs usually have very low mobility, which 
is called Static WMNs. However, MCs usually are mobile 
between MRs which is called Mobile WMN (MWMN). In 
WMMNs, mesh node routes packets to destination with multi-
hop. The most concerned traffic is oriented between MCs and 
IGWs to access Internet resource for users. The transmission 
efficiency may decrease owing to the lack of the bandwidth, 
packet loss or channel interference. Therefore, to optimize the 
transmissions, the routing metric is needed for selecting best 
path for nodes and distribute the flow to achieve the load 
balance of MWMN. 
In WMNs, the nodes usually choose the shortest path or the 
path with the fewest hops for their transmissions, but this 
cannot guarantee the quality and efficiency of the path. For this 
reason, we need a routing metric for choosing the path of high 
quality and efficiency, and maintaining the optimal path 
whenever the net flow changes so that the load balance of the 
network can be guaranteed. In this paper, we propose the 
Adaptive Situation-Aware (ASA) routing metric to decide the 
optimal path for mobile MCs and increase the communication 
efficiency and decrease the interference impact. By analyzing 
This research was partly funded by the National Science Council of the 
R.O.C. under grants NSC 99-2219-E-197-001 and NSC 99-2219-E-197-002.
This paper was presented as part of the Mobility Management in the Networks of the Future World (MobiWorld) Workshop at978-1-4244-9920-5/11/$26.00 ©2011 IEEE 391
 Figure 3. Path selection example of ASA metric. 
 
Figure 2. The communication states of the node. Figure 4. Path selection example of the same metric cost. 
In order to more accurately estimate the required resources 
of nodes for transmitting a packet that includes the backoff 
time, αub in IAR metric is adopted. In IAR metric, [8] defines 
αub  as 
 .Wait Collision Backoffub
Wait Collision Backoff Success
T T T
T T T T
+ +α = + + +
  (3)  
The different states are defined as follow. 
• TSuccess: This state means that the node has successfully 
received the acknowledgement about the transmitted 
packet. 
• TCollision: This state means that the node has delivered a 
data packet but no acknowledgement about the packet 
is returned. 
• TWait: This state means that when detecting that the 
medium is busy, the node keeps waiting until its turn. 
• TBackoff: This state means that when the node needs to 
communicate with others and the medium is also 
available. According to IEEE 802.11 standard, the 
node has to wait for a random time and the medium 
must keep being available during the waiting time. 
When the node is going to transmit a packet to another one, 
or receives a packet that needs to be transferred, the node will 
experience a series of transmission states, including success, 
collision, wait and backoff, as shown in Fig. 2. 
Finally, ASA sums the cost of nodes on path p by (1), then 
we can get the ASA metric cost of path p. Fig. 3 is a path 
selection example by using the proposed ASA metric. When 
the Node A wants to transmit data to the Node D, even the 
Link AD is only one-hop distant, the Link AD is not the 
optimal path according to the calculation of the ASA metric. 
The ASA metric chooses three paths with the minimum total 
metric cost to reach the Node D. Therefore, our proposed 
metric will choose the Link AC and the Link CD to reach the 
Node A. 
B. The Concept Of Max-flow Min-cut 
However, it is not enough to choose the path with minimum 
ASA metric cost. Because the path might be chosen with 
uneven metric cost that cause the packet loss increasing. In 
order to decrease the packet loss and further achieve load 
balance, we adopt the concept of Max-flow Min-cut. In [11], 
the max-flow min-cut theorem is defined as following. 
Theorem. For any network N = (G, c, vs, vt), the maximum 
value | f | of any flow f in N is equal to the minimum capacity 
c(C) of any vs-vt-cut C in N. 
In the situation that several paths have the same ASA 
metric cost when the distribution of the links’ cost is different. 
It means that the transmission rate of the link is 
disproportionate and the load of some nodes on the path would 
be rather heavy. As shown in the Fig. 4, although the ASA 
metric costs of these two routing path from the Node A to the 
Node D are the same, the load distribution on Link ABD is 
different from the Link ACD. Because of the load of the Link 
BD is more heavily than the Link AB. It might cause lots of 393
Figure 6. The average end-to-end delay of each metric. Figure 5. The total throughput of each metric. 
TABLE II.  SIMULATION PARAMETERS 
Parameter Values 
Scenario Size 500 m*500 m 
Nodes Generated 49 nodes randomly 
Generated 1 gateway on the corner
Transmission Range 250 m 
Carrier Sense Rage 550 m 
Flows 3 CBR flows 
CBR Rate 1 Mbps 
Packer Size 1500 bytes 
δ 4 sec 
Simulation Time 600 sec 
 
Moreover, Hybrid Wireless Mesh Protocol (HWMP) [12] is 
the default routing protocol of IEEE 802.11s. We select 
HWMP for our routing protocol with Hop count, Airtime and 
ASA. WCETT has its’ own routing protocol. Then, we 
compare three results with different schemes to present the 
performance.  
• Total throughput 
• Average end-to-end delay 
• Route overhead 
First, the total throughput of each scheme is shown in the 
Fig. 5 and we can compare the average throughput of each flow 
with Table. III. At the beginning, the throughput of ASA is 
higher than WCETT. Because Hop count only considers hops, 
Airtime and WCETT only considers the packet error rate in the 
time instantly when the packet have send out. But our ASA 
considers not only the time include the packet haven’t send out, 
but also chose the path with uniform load distribution. So, ASA 
metric can keep higher throughput then other scheme from 0-
200 sec. 
At 200th, the Flow2 and Flow3 will start to transmit. 
Because Hop Count, Airtime and WCETT can’t change path 
when the network traffic load become heavy, the three flows 
will interfere with each other. So, it will reduce the throughput 
seriously. But our proposed ASA load balance scheme will 
update the load status on the path periodically. It can calculate 
the metric cost of paths and change to the path with the 
minimum load so that the total throughput can be improved. 
Our proposed ASA load balance scheme not only provides 
higher throughput at beginning. In the heavy load situation 
with three flows, ASA still can keep higher total throughput. 
Even the average throughput of flow1 in ASA is lower than 
Airtime, ASA can decrease the effect of interference by period 
update. Hence the throughput of each flow in ASA is more 
stable than Airtime. 
The average end-to-end delay of each scheme is shown in 
the Fig. 6. The average delay of ASA is the lowest than other 
schemes. Because ASA can chose a path which transmit more 
efficiently than other schemes. When the network traffic 
become congestion and the performance of the current path 
decrease, ASA can change the current path to the path with 
lighter load. So that it can get better performance and keep 
stable by periodically update. 
Finally, the route overhead of each scheme is shown in the 
Fig. 7. We can see that ASA has more overhead after 200 sec. 
Because ASA has period update mechanism which produces 
more control messages to update the metric cost on each path. 
However, the total route overhead of ASA is still in reasonable 
and better than WCETT. In the simulation results, our 
proposed ASA load balance scheme provides the highest 
throughput and lowest end-to-end delay, but produces slightly 
route overhead than Airtime and hop count. 
TABLE III.  AVERAGE THROUGHPUT OF EACH FLOW 
 0-200 sec 201-600 sec 
Flow1 
(kbps) 
Flow1 
(kbps) 
Flow2
(kbps)
Flow3
(kbps)
Hop count 281.8 83.2 82.3 101.4 
WCETT 368.0 125.1 151.5 118.7 
Airtime 384.8 160.6 147.5 155.3 
ASA 463.7 143.8 184.0 167.3 
 395
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/18
國科會補助計畫
計畫名稱: 架構於雲端運算系統上高效能讀寫與資料容錯研究
計畫主持人: 吳庭育
計畫編號: 99-2221-E-032-040- 學門領域: 計算機網路與網際網路
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
編撰「雲端運算」教材，榮獲教育部資通訊人才培育先導型計畫評選為優良教
科書，2010/12。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
