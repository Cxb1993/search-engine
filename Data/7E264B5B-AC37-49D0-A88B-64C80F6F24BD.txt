最佳化 
英 文 摘 要 ： With just binary code, very little high-level program 
information such as the program control flow graph, 
live registers, aliases, data types are available. It 
is even not always possible to detect the boundaries 
of structured nested loops that are the most time 
consuming part of most programs, and are vital to 
many important program optimizations such as 
inserting prefetching instructions to mitigate long 
latency delinquent loads. Static analysis on the 
binary code alone often yield very limited program 
information that is of significant use to the binary 
translator and optimizer. Hence, annotating binary 
code with high-level program information that is 
readily available in a static compiler could have 
many useful applications in binary translation and 
optimization. Together with the runtime information 
collected from increasingly sophisticated hardware 
performance monitoring systems, the information 
available to binary translator and optimizer could 
potentially allow them to do substantial code 
improvement that is not possible at the static 
compilation time. However, no such study has been 
conducted before as to what kind of high-level 
program information could be useful for such binary 
translation and optimizations. It is also not known 
how much performance improvement could be achieved 
with such additional information, and what kinds of 
new compilation techniques could result in using such 
additional program information. 
In this project, we plan to use an open-source 
compiler such as Open64 to annotate high-level 
program information obtained during static compiler 
analysis, and use the information for runtime 
optimization. The annotated binary code will then be 
used in the sub-project 2 for binary translation, 
followed by further binary optimization in sub-
project 3. During the binary translation, some 
additional program information could again be 
annotated in the generated code and used in the 
following binary optimization. Other important 
  I
目錄 
目錄.......................................................................................................................................... I 
中文摘要................................................................................................................................. II 
英文摘要............................................................................................................................... III 
一、前言................................................................................................................................. 1 
二、研究目的......................................................................................................................... 2 
三、文獻探討......................................................................................................................... 3 
四、研究方法......................................................................................................................... 5 
五、結果與討論..................................................................................................................... 8 
參考文獻............................................................................................................................... 11 
 
  III
英文摘要 
In an optimizing compiler, the most time consuming part of the program 
optimization lies in its program analysis. The more precise and complete information the 
program analysis could obtain, the more opportunities the program optimizations could 
exploit, and the better performance the program execution could achieve. Many program 
analyses, especially global program analyses that require inter-procedural analyses, use 
very complex iterative algorithms with a complexity proportionate to the square of the 
number of program statements, hence, will take a substantial amount of time to complete. 
For dynamic binary translation and optimization, program analysis time is considered as 
a part of the program execution time unless the program analysis could be done in 
parallel on a separate core in a multi-core environment. Even in such a situation, system 
resources are still being taken away from other useful purposes. 
With just binary code, very little high-level program information such as the 
program control flow graph, live registers, aliases, data types are available. It is even not 
always possible to detect the boundaries of structured nested loops that are the most time 
consuming part of most programs, and are vital to many important program 
optimizations such as inserting prefetching instructions to mitigate long latency 
delinquent loads. Static analysis on the binary code alone often yield very limited 
program information that is of significant use to the binary translator and optimizer. 
Hence, annotating binary code with high-level program information that is readily 
available in a static compiler could have many useful applications in binary translation 
and optimization. Together with the runtime information collected from increasingly 
sophisticated hardware performance monitoring systems, the information available to 
binary translator and optimizer could potentially allow them to do substantial code 
improvement that is not possible at the static compilation time. However, no such study 
has been conducted before as to what kind of high-level program information could be 
useful for such binary translation and optimizations. It is also not known how much 
performance improvement could be achieved with such additional information, and what 
kinds of new compilation techniques could result in using such additional program 
information. 
In this project, we plan to use an open-source compiler such as Open64 to annotate 
high-level program information obtained during static compiler analysis, and use the 
information for runtime optimization. The annotated binary code will then be used in the 
sub-project 2 for binary translation, followed by further binary optimization in 
sub-project 3. During the binary translation, some additional program information could 
again be annotated in the generated code and used in the following binary optimization. 
Other important research issues related to binary code annotation include code size 
  1
一、前言 
In the past, after the binary code is generated by a static compiler and is linked and 
loaded to the memory, it is pretty much left untouched and unchanged during its 
program execution and in the rest of its software life cycle unless the code is 
re-compiled and changed. However, on more recent systems, code manipulation has 
been extended beyond static compilation time. The most notable systems are virtual 
machines such as Java virtual machine (JVM), C# [20] and some recent scripting 
languages. Intermediate code format such as bytecode in JVM is generated first and then 
interpreted at runtime, the intermediate code could also be compiled dynamically after 
hot code traces are detected during its execution, and further optimized in its binary 
form for continuous improvement and transformation during its program execution. 
As a matter of fact, binary code manipulation is not just limited to virtual machines 
any more. Virtualization at all system levels has become increasingly important at the 
advent of multi-cores and the dawn of utility computing, also known as clouding 
computing. When there are many compute resources available on the platform, utilizing 
such resources efficiently and effectively often requires code compiled in one instruction 
set architecture (ISA) to be moved around in the internet and run on platforms with 
different ISAs. Binary translation and optimization becomes very important to support 
such system virtualization. 
There are also other important applications that require manipulation of binary code. 
The most notable application includes binary instrumentation in which additional binary 
code segments are inserted to some specific points of the original binary code. These 
added binary code segments could be used to monitor the program execution by 
collecting runtime information during program execution that could be fed back to 
profile-based static compilers to further improve their compiled code, to detect the 
potential breach of security protocols, to trace program execution for testing and 
debugging, or to reverse engineer the binary code and retrieve its algorithms or other 
vital program information. 
 
  3
三、文獻探討 
Kirner et al. in [1] presented a tool for analyzing worst-case execution time by 
annotating extra information that is produced by the compiler to the object code. Authors 
argue that compilers are in a unique position as they can see the source and object code 
to produce extra information. They present four kinds of code annotations, such as 
platform property annotations which are application-independent annotations that are 
used to describe the target platform, CFG reconstruction annotations which are 
information for the analyzer to construct the control flow graph at runtime, program 
semantics annotations which annotate the object code’s behavior for helping the runtime 
behavior calculation, and auxiliary annotations which are the annotation’s construction 
that is used to reference control-flow edges or locations in the program code. 
Krintz et al. in [2] described a compiler annotation framework for reducing the 
dynamic compile time of Java programs. Authors categorize annotations into four 
categories according to their properties. Static analysis annotation is to annotate local 
variable’s reference counts and convey this information to help the dynamic compiler to 
perform the global register assignment. Optimization memory reuse annotation is to 
provide information to the dynamic compiler that could prevent regenerating the same 
intermediate information. Selective optimization annotation uses offline profiling to 
identify which methods could be aggressively optimized in order to reduce the dynamic 
compilation overhead. Annotations for filtering optimizations use offline profiling to 
identify optimizations that are most useful on a per-method basis. The source of 
annotations comes from the static Java bytecode analysis and the profile data. The BIT 
[11] system, which is a Java bytecode rewriting tool, is modified to perform the static 
analysis and insert annotations. Furthermore, the annotation-aware JVM is implemented 
by modifying the JVM developed by Intel, called Open Runtime Platform [10]. 
Azevedo et al. in [4] and Hummel et al. in [3] implemented an annotation-aware 
Java virtual machine and present three types of annotation to reduce dynamic 
compilation overhead. The virtual register annotation provides the information about the 
virtual registers assigned at static analysis time and at runtime, the dynamic optimizer’s 
register allocator uses this information to allocate physical registers and to generate 
native code. The runtime check annotation is aimed to reduce the overhead of the 
runtime array bound check. The memory disambiguation annotation is to annotate each 
bytecode instruction’s memory reference. The dynamic compiler can then use this 
information to perform instruction rescheduling. The annotation system is built on 
guavac [12] which is a Java compiler, and kaffe [13] which is the Java virtual machine. 
The modified Java compiler translates Java source code to an intermediate 
representation (IR) format, and then converts this IR to its Java bytecode with 
  5
四、研究方法 
Figure 1 shows the framework of our annotation. It consists of two main 
components: annotation producer and annotation consumer. Annotation producer's main 
function focuses on producing useful annotations and incorporated them into the binary 
file with minimal memory requirement and easy access. The annotation producer is 
mainly an enhanced static compiler. An annotation consumer will retrieve annotations 
from the annotated binary file, and try to leverage them for more efficient and effective 
binary execution. Annotation consumers could include the binary translator and the 
binary optimizer. 
The generation of annotation data could come from two possible sources. One is 
from the static compiler, and the other is from the profiler. We use Open64 as the 
annotation producer. Open64 is an open-source optimizing compiler. It could generate 
code for the Itanium, x86-64, x86-32, NVidia and a couple of other microprocessor 
architectures. The compiler derives from the SGI compilers for the MIPS R10000 
processor, and was released under the GNU GPL in 2000. Open64 supports Fortran 
77/95 and C/C++, as well as the shared-memory programming model OpenMP. The 
major components of Open64 include a frontend for C/C++ (using gcc) and Fortran 
77/90 (using the CraySoft front-end and libraries), inter-procedural analysis (IPA), a 
loop nest optimizer (LNO), a global optimizer (WOPT), and a code generator (CG). It 
has very high-quality inter-procedural analysis, data-flow analysis, data dependence 
analysis, and array region analysis. 
 
 
Figure 1: The annotation framework. 
 
  7
section to the program header table with the PT_LOAD flag set. In order to allow the 
consumer (i.e. the binary translation and the binary optimizer) to find the location of 
the .annotate section, the section-name string table should be loaded into the memory 
too. Modifications can be made to the ELF file to enable this. The consumer can now 
read the in-memory representation of the ELF headers and load the contents of 
the .annotate section. 
  9
 
Figure 3: Modeling edge probability problems as a set of linear equations 
 
The hot regions annotation is leveraged to identify whether the execution is fallen 
into a hot region at runtime. This annotation is a part of a new phase detection called hot 
region phase detection developed by the sub-project 3. When the number of the 
instruction pointer samples reaches a threshold in our virtualization system, these 
samples will be analyzed to check whether the current execution path “touch” the hot 
regions. Further optimizations will be performed, ex. trace building, when the system 
ascertains the execution path is fallen into the hot region. Table 2 demonstrates the 
format of the hot regions annotation. 
 
Region Count Percentage (%) 
0x08049 461,017 9.97 
0x08056 351,777 8.20 
… 
Table 2: The format of the hot regions annotation 
 
Figure 4 illustrates how the hot region annotation can be used by the binary 
optimizer (sub-project 2). We collect the application’s profile by using perfmon, then 
post-process those profile to get possible hot regions. We annotate those hot regions 
information into the executable. At runtime, the binary optimizer monitors the 
application’s runtime behavior and compares the result with the hot region information 
we annotated before. If a hot region reach a pre-defined threshold, then we consider the 
application enter a stable phase. In that case, trace building will be activated to build a 
trace which can be applied much effective optimizations. 
 
  11 
參考文獻 
[1] Raimund Kirner and Peter Puschner, “Classification of Code Annotations and 
Discussion of Compiler Support for Worst-Case Execution Time Analysis”, 
Proceedings of the 5th international workshop on worst-case execution time analysis, 
July 2005. 
[2] Krintz, C. and Calder, B., “Using annotations to reduce dynamic optimization time”, 
Programming language design and implementation, 2001. 
[3] Joseph Hummel, Ana Azevedo, David Kolson, and Alexandru Nicolau. Annotating the 
Java bytecodes in support of optimization. Concurrency: Practice and Experience, 
9(11):1003-1016, November 1997. Special Issue: Java for computational science and 
engineering simulation and modeling II. 
[4] Azevedo, A., Nicolau, A., and Hummel, J., “Java annotation-aware just-in-time (AJIT) 
compilation system”, Proceedings of the ACM conference on java grande, p.142-151, 
June 12-14, 1999. 
[5] Patrice Pominville, Feng Qian, Raja Vall ée-Rai, Laurie Hendren and Clark Verbrugge, 
“A framework for optimizing Java using attributes”, Proceedings of the 2000 
conference of the Centre for Advanced Studies on Collaborative research, p.8, 2000. 
[6] Xu, Chaohao and Li, Jianhui and Bao, Tao and Wang, Yun and Huang, Bo, “Metadata 
driven memory optimizations in dynamic binary translator”, Proceedings of the 3rd 
international conference on Virtual execution environments, p.148-157, 2007 
[7] L. Baraz, T. Devor, O. Etzion, S. Goldenberg, A. Skaletsky, Y.Wang, and Y. Zemach, 
“IA-32 execution layer: A two phase dynamic translator designed to support IA-32 
applications on Itanium® -based systems,” in Proc. 36th Annu. Int. Symp. 
Microarchitecture, 2003, pp.191–204. 
[8] Intel Corporation, “Intel® IA-32® Architecture, Software Developer’s Manual”, Vol. 
1-3, http://developer.intel.com/design/Pentium4/documentation.htm 
[9] Intel Corporation, “Intel® Itanium® Architecture, Software Developer’s Manual”, Vol. 
1-3, http://www.intel.com/design/itanium/manuals/iiasdmanual.htm 
[10] Open Runtime Platform (orp) from Intel Corporation. 
http://intel.com/research/mrl/orp. 
[11] H. Lee and B. Zorn. BIT: A tool for instrumenting Java bytecodes. In Proceedings of 
the 1997 USENIX Symposium on Internet Technologies and Systems (USITS97), 
pages 73–82, Monterey, CA, December 1997. USENIX Association. 
[12] Effective Edge Technologies. guavac open source. Sources available at 
ftp://ftp.unicamp.br/pub/languages/java/guavac. 
 1
國 科 會 補 助 專 題 研 究 計 畫 項 下 出 席 國 際 學 術 會 議 心 得 報 告  
                                     日 期 ： 101 年  9 月  19 日  
 
一 、 參 加 會 議 經 過  
國 際 平 行 處 理 研 討 會 （ International Conference on Parallel Processing, ICPP） 為 資 訊 及 平 行 處
理 領 域 極 富 盛 名 的 國 際 學 術 會 議 ， 已 經 有 41 年 之 悠 久 歷 史 ， 每 年 吸 引 約 兩 百 位 來 自 世 界 各 地 的 專
家 學 者 參 與 ， 是 資 訊 及 平 行 處 理 領 域 最 重 要 的 國 際 學 術 會 議 之 一 。 本 屆 會 議 共 收 到 187 篇 論 文 投
稿 ， 經 過 嚴 格 的 論 文 審 查 程 序 後 僅 接 受 53 篇 論 文 發 表 ， 論 文 接 受 率 僅 達 28%。  
The 41st International Conference on Parallel Processing 於 民 國 一 百 零 一 年 九 月 十 日 至 十 三 日
在 美 國 匹 玆 堡 舉 行 ， 主 辦 單 位 在 第 一 天 安 排 了 六 場 workshops， 其 餘 三 天 各 安 排 一 場 的 專 題 演 講 ，
首 先 在 九 月 十 一 日 由 IBM TJ Watson Research Laboratory 的 Dr. Fabrizio Petrini 發 表 專 題 演 講
“ Scalable Graph Exploration on Distributed-Memory Supercomputers”， 九 月 十 二 日 由 日 本 Riken 的
Dr. Fumiyoshi Shoji 發 表 專 題 演 講 “ The K computer: system and applications”， 以 及 九 月 十 三 日 由 美
國 Iowa State University 的 Prof. Srinivas Aluru 發 表 專 題 演 講 “ Genomes Galore: Bigdata Challenges in 
the Biosciences”。 這 些 專 題 演 講 探 討 平 行 處 理 研 究 領 域 目 前 最 熱 門 的 議 題 ， 內 容 涵 蓋 系 統 、 技 術
和 應 用 ， 不 但 分 享 相 關 研 究 的 經 驗 ， 指 點 出 未 來 的 研 究 方 向 ， 還 有 發 掘 出 研 究 工 作 中 容 易 被 忽 視
的 問 題 ， 內 容 十 分 精 彩 ， 也 引 起 聽 眾 的 熱 烈 討 論 。  
近 年 來 雲 端 計 算 已 經 成 為 資 訊 界 最 受 重 視 的 議 題 。 雲 端 計 算 是 一 個 擁 有 遠 大 前 景 的 新 資 訊 計
算 典 範 ， 將 動 態 可 擴 展 和 虛 擬 化 的 資 源 ， 以 網 際 網 路 服 務 的 方 式 提 供 給 使 用 者 。 雲 端 計 算 擁 有 許
計 畫 編 號  NSC99 －  2221 －  E －  001 －  004 －  MY3 
計 畫 名 稱  在 多 核 虛 擬 平 台 上 的 動 態 二 元 碼 翻 釋 及 最 佳 化 之 改 進 -子 計 畫 一 ： 對 於
多 核 架 構 下 動 態 二 元 碼 編 修 之 註 釋 框 架 研 究  
出 國 人 員
姓 名  
王 建 民  
服 務 機 構
及 職 稱  
中 央 研 究 院 資 訊 所  副 研 究 員  
會 議 時 間  
101 年 9 月 10 日 至  
101 年 9 月 13 日  
會 議 地 點  美 國 匹 玆 堡  
會 議 名 稱  
(中 文 ) 
(英 文 ) The 41st International Conference on Parallel Processing (ICPP) 
發 表 論 文
題 目  
(中 文 ) 
(英 文 ) Provision of Storage QoS in Distributed File Systems for Clouds 
 3
 
五 、 攜 回 資 料 名 稱 及 內 容  
    (1) 大 會 議 程 一 份 。  
    (2) 大 會 論 文 集 光 碟 兩 份 。  
 
六 、 其 他  
 
 
 
06, 2012.  Within a few days, you will receive an author kit with complete
information on how to upload your manuscript.
The reviews and comments are attached below.  Again, try to follow their advice
when you revise your paper.
Congratulations on your fine work.  If you have any additional questions, please
feel free to get in touch.
Best Regards,
Program Chair, ICPP 2012
ICPP 2012
============================================================================
ICPP 2012 Reviews for Submission #59
============================================================================
Title: Provision of Storage QoS in Distributed File Systems for Clouds
Authors: Chien-Min Wang, Tse-Chen Yeh and Guo-Fu Tseng
============================================================================
                            REVIEWER #1
============================================================================
---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                 Originality of the Work: 4
                   Technical Correctness: 4
                 Contribution and Impact: 4
                           Overall Score: 7
         Nomination for Best Paper Award: No
---------------------------------------------------------------------------
Comments
---------------------------------------------------------------------------
Problem: storage QoS for real time systems in cloud systems.
Contributions: Proposes a distributed file system;
         Extends a known model called CNP to cloud environment
         A system architecture is proposed to implement ECNP
        A resource selection method is also proposed
        Experimental study looks exhaustive and show positive results of the
framework.
Overall a technically sound paper that would fit multiple themes: distributed
file systems/cloud computing/storage QoS.
2／ 4 2012/8/15 下 午  01:29
---------------------------------------------------------------------------
                 Originality of the Work: 4
                   Technical Correctness: 4
                 Contribution and Impact: 3
                           Overall Score: 7
         Nomination for Best Paper Award: No
---------------------------------------------------------------------------
Comments
---------------------------------------------------------------------------
The paper reports a distributed file system with storage QoS provision for
cloud computing. Selection policies in resource management were studied with a
view to improving bandwidth utilization and dynamic replication strategies
proposed for better workload balance of resource providers. All these are
investigated via experiments on real systems. As a non-expert, the paper
appears to be well put together and the results rather convincing, although the
language as well as the formatting of the manuscript may need closer attention.
----- 完 成 轉 寄 郵 件  -----
----------------------------------------------------------------
This message was sent using IMP, the Internet Messaging Program.
4／ 4 2012/8/15 下 午  01:29
be demonstrated in Section 6, and finally, Section 7 contains 
the concluding remarks. 
II. RELATED WORK 
Many distributed file systems have been proposed for 
supporting cloud computing. HDFS [23] is one of the 
implementations of the GFS [12], written in Java. HDFS uses 
one NameNode and several DataNodes to establish the 
distributed file system and facilitates massive data access. 
Before invoking any data access operation, the user client 
needs to communicate with the NameNode for acquiring the 
Metadata, which contain the distribution information of files in 
the DataNodes. Kosmix proposed another GFS implementation 
called CloudStore [11], written in C++. It provides the similar 
functionalities of file operations as the HDFS does. Lustre [4] 
is a cluster-based distributed file system widely adopted by 
supercomputer systems because of its superior performance. 
However, the file systems mentioned above target at providing 
the file access service of resource management, not the storage 
QoS for real-time requirement.  
Another category of distributed storage systems is 
constructed by disk arrays to provide massive virtual storage, 
e.g. FAB [22], Petal [14] and IceCube [31]. This type of 
storage system integrates several separate storage resources in 
order to provide a reliable, virtualized local disk storage service 
for users or applications. However, non-trivial design and 
implementation on the combination of operating system 
porting and certain hardware support are unavoidable. SCADS 
Director [25] mainly focuses on dynamic resource allocation 
for database application but not much effort is invested on 
assuring storage QoS. 
Most research associated with storage QoS focus on the 
disk scheduler, which can be achieved by scheduling the I/O 
requests for disks. In order to prevent the most aggressive best-
effort workload from starving the soft real-time one, several 
storage QoS-aware techniques have been proposed. Wu et al. 
[33] proposed managing the bandwidth by using a traffic 
shaping technique above the external disk scheduler. Bigelow 
et al. [9] proposed I/O reservation by using the Fahrrad disk 
scheduler above the Ceph file system [30]. Both of the above-
mentioned techniques do not take the global resource 
information into account, i.e. one disk scheduler will do 
nothing even if the other disk scheduler overloads.  
Some investigations have endeavored to provide support 
for storage QoS by extending the cluster file system, such as 
Lustre file system. Narasimhamurthy et al. [18] exploited both 
the bandwidth throttling and bandwidth reservation to provide 
storage QoS for high performance computing clouds; and Mu 
et al. [17] proposed that a multi-dimensional storage QoS is 
guaranteed by using resource mapping and I/O command 
scheduling. Although CA-NFS [8] can simultaneously manage 
diverse resources, including network bandwidth, server I/O, 
server CPU, and memory utilization, most effort is 
concentrated on reducing latency and improving performance 
instead of guaranteeing QoS. All of the aforementioned 
techniques do not apply the concept of data replication to 
modern cloud computing environments. 
Nikolow et al. [20] proposed the bandwidth reservation 
technique by using monitoring and performance prediction 
based on heuristic policies for virtualized heterogeneous 
storage resource in a cloud environment. Velusamy et al. [26] 
adopted data replication to offer a statistical QoS assurance 
based on a parallel NFS (pNFS) grid file system. Wei et al. [29] 
utilized QoS-aware striping with a replication model to assure 
availability and continuity based on multimedia storage. 
Wolfson et al. [32] and Ranganathan et al. [21] proposed 
diverse dynamic replication algorithms and strategies without 
considering storage QoS assurance. Although data replication 
has been adopted for the all of the above-mentioned distributed 
storage systems, the influences of data migration have been left 
unexplored. And even though Aqueduct [15] exploited data 
migration for reliability, there was little attention paid to 
sustained bandwidth guarantee. 
III. THE PROPOSED DISTRIBUTED FILE SYSTEM 
A. System Components 
The proposed distributed file system consists of the three 
components, of the Distributed File System Client (DFSC), 
Resource Manager (RM), and Metadata Manager (MM) 
(shown in Fig. 1), each of which was mapped one-by-one to 
the Requester, Storage Provider and Mapper of the ECNP 
model, respectively. These three components are not 
constrained to be deployed on the same physical machine. Due 
to the inherence of cloud computing, the RM can be deployed 
on one of the virtual machines (VM) with other VMs running 
certain applications on the same physical machine. 
From the users’ point of view, the only thing that users 
need to know is the IP address of DFSC, because DFSC will 
negotiate with RMs under the MM’s management and access 
the requested data on behalf of users. Moreover, as a single 
MM is capable of being accessed by multiple DFSCs and 
maintains the resource list of multiple RMs, we can explore the 
effect of distributed storage resource with the QoS 
management in a multi-user environment. 
The functionalities and operations of each of the system 
components of the proposed distributed file system are 
described as follows: 
 The DFSC is responsible for receiving and processing the 
external request, sending the query of a resource list to the 
MM, sending Call-For-Proposal (CFP) to the RM, 
evaluating the bid returned from the RM by feeding the 
bid as input parameters of various resource selection 
policies, and finally launching the data access with the 
selected RM. 
 The RM has the responsibility to register its own managed 
resources to the MM, to return the bid back to the DFSC 
after receiving the CFP, and to maintain the dynamic run-
time information, e.g. the current remained storage 
bandwidth, of its host during the data communication. 
 The MM needs to deal with two operations. The first is to 
collect the resource information sent from the individual 
RMs and maintain the global resource list. The other is to 
B. Interactions between System Components 
Specifically, our implementation has two principal 
differences as compared with the conceptual ECNP model: the 
first is the response mechanism of the bid message, and the 
second is the data access operation between the DFSC and the 
RM. The former is caused by the fact that only the DFSC can 
determine the selection priorities by means of various resource 
selection policies. Thus, in our design, every RM should in fact 
return the bid as the response to the CFP, instead of refusing to 
provide a bid. Furthermore, because the data communication 
between the DFSC and the selected RM is implemented by 
packet transmission over the network, the redundant bid 
rejection and bid acceptance mechanisms are eliminated. 
As shown in Fig. 2, the order of initialization of our 
proposed distributed file system is to first invoke the MM, and 
then all the RMs register their own resource information in an 
arbitrary order after being invoked, and the DFSC is the last 
one to be launched to take over the whole distributed storage 
system. When the system initialization is completed, users can 
start to send the requests and then access the virtual storage 
system constructed by the registered RMs. 
The resource management flow can be divided into three 
phases. (1) Resource exploration phase: in this phase, we 
exploit the MM to maintain the mapping between the storage 
capacity and the RM in the resource list registered by the RMs. 
Thus, the DFSC can receive the list of corresponding RMs 
from the MM for the next resource negotiation phase. (2) 
Resource negotiation phase: this phase starts from the DFSC 
sending the CFP to all eligible RMs. As mentioned in the 
previous paragraph, the DFSC’s requirement will be contained 
in the CFP message, and the eligible RMs will respond with 
their own bid determined by their bidding policies to the DFSC. 
After that, these collected bids can be evaluated in various 
resource selection policies for exploring the most appropriate 
RM. (3) Data communication phase: in this final phase, data 
can be stored into the selected storage resource or be retrieved 
from the selected one, and storage QoS will be assured during 
the data transmission. 
Note that the resource selection policies can benefit the 
storage QoS and utilization only when more than one bid is 
offered to the requester by the participating RMs. Hence, we 
need to further exploit the dynamic replication technique to 
prevent the case that no disk bandwidth is available in all the 
participating RMs. The triggering condition of dynamic 
replication may be a threshold value referred by the RMs. For 
instance, if the threshold is set too low, it may incur too many 
replications and degrade the efficiency of resource utilization. 
In contrast, if the threshold is set too high, a burst of resource 
requirements may lose their QoS assurance. 
Moreover, if the storage system only replicates data without 
deleting the redundant replicas, the resource utilization will 
continuously downgrade. Thus, the triggering condition of data 
deletion is used to determine when and how the deletion 
operation is needed. Similarly, if the threshold is set too low, it 
may slacken the data deletion and degrade the efficiency of 
resource utilization. In contrast, if the threshold is set too high, 
too many operations back and forth between data replication 
and deletion will result in significant system overhead. 
Therefore, we have to investigate the reasonable thresholds and 
mechanisms applied to our proposed distributed file system. 
IV. RESOURCE SELECTION 
As far as the resource selection algorithm is concerned, our 
goal is to achieve storage QoS by selecting the most 
appropriate resource from three different perspectives. The first 
consideration is the available bandwidth which indicates the 
current remaining bandwidth of storage managed by the 
individual RM labeled by Brem.  
The second factor is used to predict the possible trend of 
bandwidth utilization when a new request just arrives. On 
account of the arrival of the I/O request to the block device 
being unpredictable, it is hard to know in advance if requests 
will arrive in a sudden burst or remain idle for a long period. 
For this reason, we propose a historical prediction mechanism 
by combining the fixed accumulated count of request arrivals 
and the expired time instead of recording at a fixed sample rate. 
In order to preserve the historical record, we implement two 
queues in turn to accumulate the cumulative amount of 
bandwidth utilization and exchange if one queue reaches the 
specified conditions. According to the two-queue mechanism, 
when one queue is currently used for recording, the other 
queue still can be used for the historical reference to the trend 
prediction. Furthermore, both of the following two conditions 
will trigger a queue exchange: one is the sample accumulated 
to the specified count; the other is the queue that has exceeded 
the specified expired time even if the accumulated request 
count is not reached. No matter which condition has been 
triggered, the queue used to record will be changed into the 
other which is used for providing the historical reference, and 
vice versa. 
Now we formally define the time period between two 
queues exchanged as Tthreshold = Tend - Tstart . As shown in Fig. 3, 
Tstart is the timestamp when the request count starts to 
accumulate, and Tend is the timestamp when the aforementioned 
queue exchange condition is triggered.  FStotal is the total 
cumulative amount of file size in which these files are being 
accessed during the Tthreshold period; thus 
threshold
total
T
FS  is the average 
bandwidth utilization during Tthreshold, and Bused is the bandwidth 
in use when the current request arrives. Thus, 
threshold
total
used T
FSB   
divided by two leads to a bias of the predicted trend to the 
median of the current bandwidth utilization and the historical 
bandwidth utilization. Tcurrent  is the timestamp of the latest 
arriving request, so Tdistance = Tcurrent - Tend is the distance of the 
timestamp between the latest arrival request and the lattermost 
arrival request currently used as a historical reference. Tdistance is 
used to judge the degree of worthwhile reference of the 
historical records currently used. It also implies that the larger 
TimeTcurrentTendTstart
Tthreshold Tdistance
Figure 3. Timestamp parameters of historical trend prediction model. 
 
and further assure the storage QoS by balancing the bandwidth 
utilization. 
VI. EXPERIMENTAL RESULTS 
Because our goal is to build a distributed file system for 
clouds with support of storage QoS, we need a benchmark of 
disk access that is traced with storage QoS constraints. 
Nevertheless, to the best of our knowledge, most of the 
released disk traces are gathered from mail servers, web servers, 
source code servers and so forth. In addition, video traces are 
only limited by playing a single video but not the accessing of 
trace of media files on a distributed file system. For this reason, 
we conduct experiments on a real system instead of traces. We 
select 1,000 video files with different bit rates and popularity 
ratings that were extracted from YouTube, replicate each of 
them as three replicas and then distribute these three replicas 
randomly into 16 RMs. Furthermore, the input access pattern is 
generated by choosing files randomly with a probability 
derived from the file popularity. In other words, this input 
pattern can guarantee that the files with higher popularity will 
be accessed more times in a fixed time interval. The timestamp 
associated with the file access is calculated by a negative 
exponential distribution (NET) [13]. Thus, the equation of the 
request arrival time is βlnUf(x)  . In this equation, U(0,1) is 
a random distribution function with the value ranging from 0 to 
1, and β is the cumulative mean arrival time. 
A. Virtual Cloud Environment Settings 
Our virtual cloud environment consists of 25 Xen-based 
VMs, i.e. 16 RMs, 1 MM and 8 DFSC, distributed on 5 
physical machines, each of which has two Intel E5620 2.4GHz 
4-core 8-thread processors, 72GB memory, and a 1TB local 
disk, which can yield a total of 128Mbps, i.e. 16MB/s, of 
sustained disk bandwidth to be dispatched to VMs located on 
the local disk. Although we use a single MM in the 
experiments, a distributed MM can be achieved by a 
Distributed Hash Table (DHT) as shown in [28]. Each VM 
used for the RM is virtualized as a host with an Intel E5620 
2.4GHz 1-thread processor, 1GB memory and 16GB disk. 
Because real distributed storages in cloud environments might 
be heterogeneous in storage capability, we adopt an imbalance 
strategy for resource deployment by giving two extra large 
RMs with 128Mbps of bandwidth, i.e. RM1 and RM9; four 
RMs with 19Mbps, i.e. RM2, RM3, RM10 and RM11; and the 
rest of the RMs with 18Mbps. 
As mentioned in section 3.2.2, the bandwidth of an 
individual VM acquired from the physical local disk is 
controlled by the cgroup-blkio mechanism. In practice, a Xen-
based VM has its corresponding loop kernel thread, and the 
virtual storage in conjunction with the VM is mapped to the 
corresponding loopback device. Hence, the bandwidth isolation 
between individual VMs on the same physical disk can be 
achieved by separately joining the loop kernel thread process 
ID of the associated VM and the loopback device number of 
the virtual storage into the blkio.throttle.read_bps_device group. 
For the purpose of simulating multi-users access patterns, 
the request scheduler will send the request according to the 
request arrival timestamp recorded in the generated access 
pattern to the corresponding DFSC, respectively. Moreover, the 
request scheduler can designate the startup time of the 
simulation so that the multi-users access pattern can be 
guaranteed to be launched simultaneously. All of the 
experiments are conducted by using the access pattern of 256 
users unless explicitly specified otherwise. 
1) Bandwidth Allocation Scenario 
To gather sufficient statistics, the total simulation time of 
each configuration is 2 hours, and the mean value of the 
request arrival time is 300 seconds in the access pattern. 
Furthermore, due to the absence of a definitive metric for 
measuring the storage QoS, we investigate the effect of our 
resource selection policies and dynamic replication strategies in 
two different bandwidth allocation scenarios, i.e. firm real-time 
and soft real-time. Firm real-time allocation indicates that the 
requested file will fail to open when none of the RMs can 
provide sufficient bandwidth to serve the request. That is, no 
bandwidth will be allocated to the access request if the file 
open failed. Thus, the fail rate of opened files is the criterion 
when the firm real-time allocation scenario is adopted. 
On the other hand, soft real-time allocation means that 
whether or not the maximum bandwidth is exceeded, the 
bandwidth will always be allocated if requested. This scenario 
uses the over-allocate ratio 
TA
OA
OA S
SR   as the criterion for 
different configurations, where SOA is the total bytes that 
exceeds the maximum accessible bandwidth and STA is the total 
bytes assigned to this RM (shown in Fig. 4). 
B. Resource Selection 
We investigate the resource selection algorithms by 
configuring different collocations of the impact factor (α, β, γ) 
pair, as mentioned in section 4. For instance, policy (1,0,1) 
indicates this configuration only takes α and γ into account, and 
the factor β with 0 weight will be ignored in this simulation. In 
addition, policy (0,0,0) is the resource selection by choosing 
the RM randomly without any selection policy being involved. 
 
1) Soft Real-time Allocation 
To explore the influence of impact factor (α, β, γ) pair with 
soft real-time allocation scenario, we first investigate the over-
allocate ratios among the various access patterns with different 
numbers of users as shown in Table I. The rapid increase of the 
over-allocate ratio along with the increase of the number of 
users indicates that some RMs exceed their affordable 
bandwidth in soft real-time allocation scenario. Compared with 
random selection, the experimental results show that policy 
(1,0,0) performs much better than policy (0,0,0) for the over-
allocate ratio. The other selection policies also do not show a 
noticeable improvement over policy (1,0,0). Detailed 
information of the over-allocate ratios for each RM for 256 
users is shown in Table II. It can be observed that no matter 
which policy is used, some RMs may be overloaded whereas 
other RMs still have available bandwidth. 
 
1) Soft Real-time Allocation 
Here we investigate the performance of various resource 
selection policies and dynamic replication strategies. The 
results of the over-allocate ratio in soft real-time allocation are 
shown in Table IV. The policy (1,0,0) performs better than the 
policy (0,0,0) in all cases. Although some collocation of 
resource selection policies can perform better on the over-
allocate ratio, there is no noticeable improvement over the 
policy (1,0,0). On the other hand, the over-allocate ratios of 
dynamic replication strategies are all superior to that of the 
static replication strategy. Compared to the baseline strategy, 
strategy, Rep(1,8) can reduce the number of replicas 
transferred at a time and still yield a good performance. 
Moreover, strategy Rep(1,3) can save the storage capacity by 
decreasing the maximum number of replicas, with little 
degradation of performance. Therefore, strategy Rep(1,3) is of 
practical use as it takes into consideration the data traffic 
between the RMs and the storage capacity of the RMs, and still 
performs well. Fig. 6 shows the bandwidth utilization of RM1 
and RM2 over time with the selection policy (1,0,0). It can be 
observed that dynamic replication indeed balances the 
workload of RMs as time goes by. The comparisons of the 
over-allocate ratio of each RM between static replication and 
strategy Rep(1,3) with selection policy (1,0,0) are shown in Fig. 
7. 
2) Firm Real-time Allocation 
Based on the experience from the previous experiments, the 
experiments in the firm real-time allocation are conducted on 
the selection policies (0,0,0) and (1,0,0) only. The results of the 
fail rate in firm real-time allocation are shown in Table V. The 
policy (1,0,0) performs better than the policy (0,0,0) in all 
cases as in the soft real-time allocation. Similarly, the fail rates 
of dynamic replication strategies are all superior to that of the 
static replication strategy. The fail rate of strategy Rep(1,3) is 
still fairly acceptable as compared with that of baseline strategy 
and strategy Rep(1,8). In summary, the replication strategy 
Rep(1,3) with selection policy (1,0,0) can achieve 78% 
reduction on the over-allocate ratio and 86% reduction on the 
fail rate with respect to the static replication with selection 
policy (1,0,0). 
3) Destination Selection 
To further improve the bandwidth utilization, we also 
investigate the destination selection of replication strategy 
Rep(1, 3) in both soft real-time and firm real-time allocations. 
The three destination selection strategies investigated in this 
paper are given as follows: (1) Random selection strategy: the 
default strategy for all experiments; (2) Largest bandwidth first 
(LBF) strategy: only select the largest bandwidth RM, i.e. 
randomly select one of RM1 and RM9 in our configuration; 
and (3) Weighted selection strategy: RMs are selected 
randomly with probabilities according to their initial 
bandwidths. The experimental results are shown in Tables VI 
and VII. It can be observed that the weighted selection strategy 
is better in soft real-time allocation while the largest bandwidth 
first strategy is better in firm real-time allocation. 
TABLE IV.  AVERAGE OVER-ALLOCATE RATIO WITH DYNAMIC 
REPLICATION IN SOFT REAL-TIME ALLOCATION 
(α, β, γ)
 Rep(NREP, NMAXR) 
(0,0,0) (1,0,0) (1,0,1) (1,1,0) (1,1,1)
Static replication 24.60% 9.77% 9.79% 9.54% 10.01%
Baseline 16.60% 1.44% 1.30% 2.86% 2.46%
Rep(1, 8) 15.67% 1.50% 1.47% 1.63% 2.40%
Rep(1, 3) 13.37% 2.17% 2.11% 1.38% 2.86%Figure 7. Comparison of over-allocate ratio of each RM between static replication and Rep(1, 3). 
 0
 4
 8
 12
 16
 20
RM1 RM2 RM3 RM4 RM5 RM6 RM7 RM8 RM9 RM10
RM11
RM12
RM13
RM14
RM15
RM16
O
v
e
r
-
a
ll
oc
at
e 
Ra
ti
o 
(%
)
Over-allocate Ratio Between Static Replication and Rep(1, 3) Case
Static Replication
Rep(1, 3)
2
4
6
8
10
12
14
 0  1000  2000  3000  4000  5000  6000  7000
U
t
il
iz
ed
 B
an
dw
id
th
 (
MB
/s
)
Time (sec)
Sum of Bandwidth Utilization of Large Bandwidth RMs (1, 9)
(0, 0, 0)
(1, 0, 0)
5
10
15
20
25
30
 0  1000  2000  3000  4000  5000  6000  7000
U
t
il
iz
ed
 B
an
dw
id
th
 (
MB
/s
)
Time (sec)
Sum of Bandwidth Utilization of Small Bandwidth RMs (2-8, 10-16)
(0, 0, 0)
(1, 0, 0)
(a)             (b) 
Figure 5. Aggregated bandwidth utilization in firm real-time allocation. (a) is the sum of bandwidth utilization of extra large 
bandwidth RMs, i.e. RM1 and RM9; (b) is the sum of bandwidth utilization of small bandwidth RMs, i.e. RM2-8 and RM10-16. 
[23] K. Shvachko, H. Kuang, S. Radia, and R. Chansler, “The hadoop 
distributed file system,” in Proc. of IEEE 26th Symp. on Mass Storage 
Systems and Technologies, pages 1-10, May 2010. 
[24] R. G. Smith, “The contract net protocol: High-level communication and 
control in a distributed problem solver,” IEEE Trans. Comput., 29:1104-
1113, December 1980. 
[25] B. Trushkowsky et al., “The scads director: scaling a distributed storage 
system under stringent performance requirements,” in Proc. of the 9th 
USENIX conf. on File and storage technologies, FAST'11, Berkeley, CA, 
USA, 2011. USENIX Association. 
[26] V. Velusamy and A. Skjellum, “Quality of service support for grid 
storage environments,” in Proc. of Int. Conf. on Grid Computing and 
Applications, pages 134-140, June 2006. 
[27] C.-M. Wang, H.-M. Chen, C.-C. Hsu, and J. Lee, “Resource selection 
strategies for a cnp-based resource management model,” in Proc. of the 
2008 IEEE Asia-Pacific Services Computing Conference, pages 458-463, 
Washington, DC, USA, 2008. IEEE Computer Society. 
[28] C.-M. Wang, C.-C. Huang, and H.-M. Liang, “Asdf: An autonomous 
and scalable distributed file system,” in Proc. of the 2011 11th 
IEEE/ACM Int. Symp. on Cluster, Cloud and Grid Computing, CCGRID 
'11, pages 485-493, Washington, DC, USA, 2011. IEEE Computer 
Society. 
[29] Q. Wei, W. Lin, B. Veeravalli, and L. Zeng, “Qos-aware striping with 
replication model for object-based multimedia storage,” in Proc. of the 
4th Int. Workshop on Storage Network Architecture and Parallel I/Os, 
pages 114-121. IEEE Computer Society, Sept. 2007. 
[30] S. A. Weil, S. A. Brandt, E. L. Miller, D. D. E. Long, and C. Maltzahn, 
“Ceph: a scalable, high-performance distributed file system,” in Proc. of 
the 7th Symp. on Operating systems design and implementation, OSDI 
'06, pages 307-320, Berkeley, CA, USA, 2006. USENIX Association. 
[31] W. W. Wilcke, et al., “Ibm intelligent bricks project: petabytes and 
beyond,” IBM J. Res. Dev., 50:181-197, March 2006. 
[32] O. Wolfson, S. Jajodia, and Y. Huang, “An adaptive data replication 
algorithm,” ACM Trans. Database Syst., 22(2):255-314, June 1997. 
[33] J. C. Wu and S. A. Brandt, „Storage access support for soft real-time 
applications,” in Proc. of the 10th IEEE Real-Time and Embedded 
Technology and Applications Symp., pages 164-171, Washington, DC, 
USA, 2004. IEEE Computer Society. 
 
(a) RM1, static replication     (b) RM2, static replication 
(c) RM1 , Rep(3, 8)      (d) RM2 , Rep(3, 8) 
(e) RM1 , Rep(1, 8)      (f) RM2 , Rep(1, 8) 
(g) RM1 , Rep(1, 3)      (h) RM2 , Rep(1, 3) 
Figure 6. Bandwidth utilization of large bandwidth RM1 and small bandwidth RM2 with four dynamic replication strategies. 
The red solid line indicates the maximum available bandwidth assigned to the RM. 
99年度專題研究計畫研究成果彙整表 
計畫主持人：王建民 計畫編號：99-2221-E-001-004-MY3 
計畫名稱：在多核虛擬平台上的動態二元碼翻釋及最佳化之改進--子計畫一:對於多核架構下動態二元
碼編修之註釋框架研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100% 
由於此計畫為整
合型計畫，三個子
計畫共同完成已
投稿之論文將表
列於總計畫研究
成果彙整表中。 
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 3 3 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
傳統上，註釋侷限於像是 Jave byte code 此類較為高階的語言。針對低階的二元碼註釋
上的研究現今較為缺乏。本子計畫探討對二元碼加上註釋的可能性，這可以概括成底下兩
點: 
 
1.註釋可能的來源: 編譯器編譯過程中所得資訊，二元碼翻譯過程中所做的額外分析和利
用效能分析工具採集二元碼執行時的行為。 
2.對二元碼翻譯/優化有所幫助的註釋: 控制流程圖 (control flow graph)，函式出入口
(function entry/exit point) 和任何在將源碼編譯成二元碼過程中所丟失的訊息。 
 
對於註釋可能的來源，目前採用二元碼翻譯過程中所做的額外分析和利用效能分析工具採
集二元碼執行時的行為。編譯器編譯過程中所得資訊是否能為二元碼翻譯/優化所用目前
仍有困難。主要原因在於現今編譯器在設計的過程上並未考慮到二元碼將來可能會被二元
碼翻譯器做再一次的翻譯。因此許多編譯時期的資訊並未被適當的維護，這使得取得該資
訊有困難。 
 
對於二元碼翻譯/優化有所幫助的註釋，目前是擷取控制流程圖 (control flow graph) 以
及二元碼於執行時所會運行到的熱點 (hot region)。控制流程圖有助於二元碼翻譯器在
翻譯/執行二元碼的過程中，辨識出二元碼經常執行的路徑，再針對這些路徑做更進一步
