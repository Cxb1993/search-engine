functions of remotely controlled PTZ 
camera to the proper position in order to 
contain the target on the camera screen. 
(4) By using multiple PTZ cameras, 3-D 
trajectories of moving targets in the 
ground space can be obtained 
automatically without the DTM data. 
Key words: PTZ camera、digital map、
object positioning、object tracking 
二、緣由與目的 
利用衛載及空載的遙測技術日益精
進，載具上的感測器也日漸精密，但
在生活中的許多應用上，使用較價廉
的數位攝影機仍是較普遍的趨勢，特
別是在區域安全監控方面的應用上
[2][8][10]。遠端操控 PTZ 攝影機除了
能利用網路即時傳回連續影像，還有
能任意旋轉攝影機的平移(Pan)和傾斜
(Tilt)角度變換監控位置，改變放大/縮
小倍率(Zoom)取得目標特寫資料的優
點，近年來已有部份研究使用遠端操
控 PTZ 攝影機取代一般固定式攝影機
進行區域監測[4][5][6][7]。然而一般商
用 PTZ 攝影機的機械構造並不精密，
在出廠時也未加附攝影機平移、傾
斜、放大/縮小功能的參數率定，因此
使用 PTZ 攝影機進行區域監控時，往
往只能觀察到目標而無法得知目標物
的空間資訊關係。許多 PTZ 攝影機於
監控應用上，目前都只能建立從目標
至攝影機的單向關係，限定應用範圍
是先指定目標在物空間的位置，然後
從單向關係找出 PTZ 攝影機對應目標
的距離及俯仰角，並據此操控攝影機
指向目標[6][7]。若能率定 PTZ 攝影機
的平移、傾斜、放大/縮小( Pan/ Tilt/ 
Zoom)功能參數，即可建立遠端操控
PTZ 攝影機像空間及電子地圖物空間
的雙向對應關係，在有 DTM 協助提供
高程資訊的情況下，進行影像中目標
物空間位置的求定。然而現階段可取
得之 DTM 解析度往往不符合三維定
位之需求，因此若能使用兩部以上率
定過後之 PTZ 攝影機，搭配移動物體
偵測及匹配演算法，則可在不倚靠
DTM 的情況下，自動化定出目標物在
物空間的三維移動軌跡。 
本研究主要目的是在利用同時出現在
遠端操控 PTZ 攝影機畫面上及電子地
圖上的對應控制點，計算出攝影機的
空間位置及率定 PTZ 攝影機的平移、
傾斜、放大/縮小(Pan/Tilt/Zoom)功能參
數，並建立 PTZ 攝影機像空間及電子
地圖物空間的雙向轉換關係，再運用
兩部率定後之 PTZ 攝影機視訊資料進
行移動目標物的三維定位及追蹤。 
三、研究方法 
 
圖 1 研究流程圖 
本研究流程如圖 1 所示分為五個主要
步驟，第一個步驟是設計率定 PTZ 攝
影機所需要的附加參數，修改共線條
件式為適用於 PTZ 攝影機的型式;第二
個步驟是取得對應控制點後，以光束
法平差進行各攝影機方位參數求解及
功能參數率定;第三個步驟是利用求得
在本研究中使用以共線條件式為基礎
之光束法數學式如下式(5)，利用影像
中之大量光線交會建立監測區物空間
與像空間的轉換模型[3]： 
)()()(
)()()(
)()()(
)()()(
0
3
1
330
3
1
230
3
1
13
0
3
1
320
3
1
220
3
1
12
0
3
1
330
3
1
230
3
1
13
0
3
1
310
3
1
210
3
1
11
ZZmRYYmRXXmR
ZZmRYYmRXXmR
fyy
ZZmRYYmRXXmR
ZZmRYYmRXXmR
fxx
i
n
nni
n
nni
n
nn
i
n
nni
n
nni
n
nn
yyyp
i
n
nni
n
nni
n
nn
i
n
nni
n
nni
n
nn
xxxp
−+−+−
−+−+−
−=Δ++−
−+−+−
−+−+−
−=Δ++−
∑∑∑
∑∑∑
∑∑∑
∑∑∑
===
===
===
===
δ
δ
 (5) 
R11~R33 為本研究中所加入由 Pm、tm所
組成的附加參數旋轉矩陣元素，加入
此矩陣之目的在於將攝影機的左右平
移及上下俯角改變量調整為攝影機姿
態參數，並吸收其動作時產生的系統
誤差。 
2. 攝影機方位參數求解及功能參數
率定 
在此步驟中，需要使用大量同時出現
在遠端操控 PTZ 攝影機畫面上及電子
地圖上的對應控制點進行光束法平差
求解。選擇控制點的原則是以在攝影
機畫面中和電子地圖上容易辨認且位
置清楚的目標為原則，若電子地圖不
包含高程資訊，則需配合 DTM 資料以
取得控制點的高程。對於電子地圖上
同一目標必須多次轉動攝影機畫面選
取對應的像平面控制點，以確保系統
誤差與攝影機構造上所造成的誤差能
夠下降到最小。另外對於攝影機畫面
中明顯但電子地圖上不易辨識的目
標，也可利用攝影機畫面可移動性高
的特性，在多張 pan、tilt、zoom 值不
同 的 影 像 中 選 作 影 像 連 結 點 (tie 
point)，雖然連結點不具有物空間三維
坐標，但在進行光束法平差時仍能幫
助最後的求解穩定，並且能減少對控
制點數目的要求。 
3. 建立攝影機像空間與電子地圖物
空間雙向轉換模式 
攝影機之外方位參數包括攝影機位置
和姿態角(Xc、Yc、Zc、ω、φ、κ)，攝
影機功能率定參數包括平移、傾斜、
放大/縮小(Pan/Tilt/Zoom)等功能的校
正參數。利用控制點及影像連結點配
合光束法平差可得參數求解。得到攝
影機之方位參數和功能率定參數，即
表示可將攝影機之姿態角和平移、傾
斜量進行轉換，代入共線條件式中即
可建立攝影機像空間與電子地圖物空
間雙向轉換模式。因此在有 DTM 提供
高程資訊的情況下，攝影機畫面上出
現的任何目標可自動轉換成電子地圖
所代表的物坐標，並呈現在電子地圖
上。在電子地圖上隨意指定的任何目
標亦可自動轉換成攝影機上的像坐
標，並提供空間姿態參數給攝影機，
利用平移、傾斜、放大 /縮小功能
(Pan/Tilt/Zoom)移動攝影機至適當位
置，使目標出現在畫面中。 
4. 由攝影機視訊資料中萃取移動目
標資訊 
在此步驟，將由各 PTZ 攝影機的視訊
資料中萃取出移動物體資訊，例如:移
動物體在像平面上的位置、移動物體
面積、移動物體顏色等。由於本研究
最終的目的在於移動物體定位，因此
在偵測方法上，選擇了使用偵測移動
物體位置較精確且不需要複雜運算的
背景影像相減法。然而，在研究中所
使用的 PTZ 攝影機並無固定背景，亦
即無法事先建立背景影像，故一般的
背景影像相減法並不適用。在本研究
中將使用一漸進式背景影像相減法，
在逐畫格處理(frame by frame)的情況
下，以每個新加入的畫格同時進行移
動物體偵測及更新舊的背景影像，使
背景影像能符合整體環境的變化。接
著利用更新後的背景影像分離出畫格
中的移動像元，再利用形態學原理將
被過度分割的移動像元合併為移動區
塊，並將各區塊物件化(object labeling)
後可計算出各移動物體之坐標、面積
及色彩等資訊。 
5. 移動目標三維定位及軌跡建立 
  
圖 3 檢核點分佈圖 
表 2 精度與距離關係表 
Object Space (meter) 
 
RMSE_E RMSE_N 
<50 m 0.387 0.153 
<100 m 0.933 0.426 
<200 m 1.443 0.812 
<500 m 2.972 1.883 
圖 5 物空間到像平面轉換 
如圖 6 為本研究之測試視訊資料，影
像長度約為 20 秒，兩 PTZ 攝影機的
Zoom 值相同且視野範圍也幾乎相
同。移動物體包括一部單車(以紅圈標
示)、一部機車(以黃圈標示)和兩部汽
車(以藍圈及綠圈標示)，其中一汽車
(藍圈標示者)和機車為沿著同一路徑
移動。 當 PTZ 攝影機完成率定並建立物空間與像空間的對應關係後，如圖 4(a)(c)
所示在任意角度及縮放倍率的攝影機
畫面上點選目標，將自動在電子地圖
上以紅點標示出其對應之位置，如圖
4(b)(d)所示，圖中藍色標記為攝影機所
在之位置。 
 
圖 4 像平面到物空間轉換 
如圖 5(a)(c)所示在電子地圖上任意點
選一目標，亦可自動轉換成攝影機上
的像坐標，並提供空間姿態參數給攝
影機，利用平移、傾斜、放大/縮小功
能 (Pan/Tilt/Zoom)移動攝影機攝影機
轉至目標方向，圖 5(b)(d)即為顯示目
標所在的畫面。 
左攝影機影像 右攝影機影像 
  
  
  
  
  
圖 6 測試影像序列。(由上至下分別為
Vision and Applications, Vol. 16, No. 
6. Springer Berlin/Heidelberg (2005) 
1–2. 
5. Lim, S.N., Elgammal, A., Davis, L.S.: 
Image-based Pan-tilt Camera Control 
in a Multi-camera Surveillance 
Environment, ICME ’03 Proceedings, 
2003 International Conference on 
Multimedia and Expo, Vol. 1. (2003) 
645–648. 
6. Micheloni, C., Foresti, G.L., Snidaro, 
L.: A Network of Co-operative 
Cameras for Visual Surveillance, IEE 
Vision, Image and Signal Processing, 
Vol. 152, Issue 2. (2005). 205–212. 
7. Micheloni, C., Foresti, G.L.: 
Real-time Image Processing for 
Active Monitoring of Wide Areas, 
Journal of Visual Communication & 
Image Representation, Vol. 17, Issue 
3. (2006) 589–604. 
8. Pai, C., Tyan, H., Liang, Y., Liao, 
H.M., Chen, S.: Pedestrian Detection 
and Tracking at Crossroads, Pattern 
Recognition, Vol. 37, Issue 5. (2004) 
1025–1034.  
9. Press, W.H., S.A. Teukolsky, W.T. 
Vetterling, and B.P. Flannery, 
Numerical Recipes in C: The Art of 
Scientific Computing, 2nd edtion, 
Cambridge University. (1992). 
10. Qureshi, F.Z., Terzopoulos, D.: 
Surveillance Camera Scheduling: A 
Virtual Vision Approach, Multimedia 
Systems, Vol. 12, No. 3. Springer 
Berlin/Heidelberg (2006) 269–283. 
11. Wolf. P.R.: Elements of 
Photogrammetry with Air Photo 
Interpretation and Remote Sensing, 
2nd ed., McGraw-Hill, Inc. (1988). 
