 II 
Contents 
中文摘要 ....................................................... I 
Abstract ........................................................ I 
Contents ...................................................... II 
I. Introduction ......................................... 1 
II. The Mathematical Model ................... 2 
A. Per flow queueing for multicast flows .. 2 
B. Constrained simultaneous transmissions 
for links ................................................. 3 
C. Routing Vectors and admissible traffic 3 
III. Dynamic Frame Sizing Algorithm ..... 4 
A. Determining the frame size .................. 5 
B. A hierarchical smooth schedule ........... 6 
C. Frame Bound ........................................ 8 
IV. Conclusion ......................................... 10 
V. Appendix A ........................................ 10 
VI. References .......................................... 12 
 2 
an explicit upper bound for the minimum 
clearance time that can be used for the large 
deviation argument. Our idea for the upper 
bound is to compare the minimum clearance 
time with the time to drain the backlog at 
each link with the rate equal to its arrival rate 
(even though the actual arrival rate is not 
known). By so doing, we are able to establish 
the connection between the external arrival 
rates and the frame size so that the large 
deviation argument in [3], [8] can be used. 
To provide guaranteed rate services inside 
the network, we propose a hierarchical 
smooth schedule (as an extension of the 
smooth schedule in [6], [3], [8]). We then 
derive bounds on the differences between the 
guaranteed rate services provided by the 
hierarchical smooth schedule and the ideal 
rate services. These bounds are then used for 
bounding the number of packets in each 
internal queue. 
 The rest of this report is organized as 
follows. First, we describe our mathematical 
model in Section II. In Section III, we 
propose our DFS algorithm, including 
determining the frame size in Section III-A, 
proposing the hierarchical smooth schedule 
in Section III-B, and proving the finiteness of 
the expected frame size in Section III-C. In 
Section IV, we conclude this report by 
addressing some further extensions. 
II. The Mathematical Model 
In this section, we first introduce the 
mathematical model and the notations that 
will be used in the report. 
A. Per flow queueing for multicast flows 
Consider a network with L links and J 
multicast traffic flows, indexed from 1 to L 
and from 1 to J, respectively. Each flow 
enters the network at some queue, traverses 
through a set of queues arranged in a fan-out 
tree, and then leaves the network. There 
might be several flows traversing a common 
link, and we assume that per flow queueing is 
used in every link, i.e., every flow has its 
own queue in every link it traverses. We 
define )( jq as the queue for flow j traversing 
link  . Moreover, we denote )( jq as the 
ingress queue for the thj flow, and all the 
queues other than ingress ones are called 
internal queues. Notice that )( jq and 
)( jq represent the same queue if link  is the 
first link traversed by flow j in the network. 
The queues traversed right before and after 
queue q are named the upstream queue of q 
and the downstream queue(s) of q, 
respectively. For the clarity of our 
presentation, we assume at this moment that 
all the queues are of infinite sizes (including 
both ingress queues and internal queues) so 
that no packets are lost. Later, we will show 
that all internal queues are of finite sizes. 
Throughout this report, we consider the 
usual discrete-time setting by assuming that 
packets are of the same size and that time is 
slotted so that one packet can be transmitted 
within a time slot. Also, we assume that each 
queue is started from an empty system at 
time 0. We now define )()( tx j as the number 
of packets in queue )( jq at time t. Then, the 
governing equation for each queue )( jq can be 
represented as 
(1) 
where )()( ta j and )(
)( tb j are the number of 
packets arriving at )( jq at time t and the 
number of packets departing for the 
downstream queue(s) of )( jq or leaving the 
network at time t, respectively. Notice that 
if )( jq is the ingress queue for flow j (i.e., 
)()( jj qq = ), )(
)( ta j is simply the number of 
external arrival packets at time t, which is 
denoted as )()( ta j . On the other hand, for 
internal queue )( jq , the arrival packets 
of )( jq are exactly the departure packets 
of )( ),(
j
juq  , where ),( ju  is the upstream 
queue of link  for flow j. That is, 
 
for an internal queue )( jq . 
 In this report, )()( tx j , )(
)( ta j  and 
)()( tb j  are nonnegative integers for flows 
 4 
}2{4 =F . 
 Let )( jλ  be the average number of flow 
j packets that arrive at the network in a time 
slot. For the ease of our presentation, we 
simply call )( jλ  the arrival rate of flow j. 
With the routing vector for every flow in the 
network, we can then compute the average 
number of packets that need to go through a 
particular link in a time slot. Specifically, we 
have 
  (4) 
where λ , L,...,2,1= , is the average 
number of packets that need to go through 
link   in a time slot. The vector Λ  is 
called the arrival rate vector in this report. In 
the following, we define the traffic intensity 
and admissible traffic. 
Definition 1 (Intensity and admissible 
traffic) The intensity ||||Λ=ρ  of Λ  is 
defined as 
 
(5) 
The input traffic is said to be admissible if 
1<ρ . 
If the input traffic is admissible, one can 
always find a set of weights Kkk 1}{ =φ and a set 
of configuration vectors KkkP 1}{ =  such that 
1
1
=∑ =
K
k k
φ  and k
K
k k
P∑ =<Λ 1φ . In view of 
this, a simple time sharing policy that 
schedules configuration vector kP  
proportional to the weight kφ  guarantees 
that the arrival rate at each link is strictly 
smaller than the service rate of that link. If, 
furthermore, each flow is stationary and 
ergodic with a known rate, then there are 
many scheduling polices in the literature that 
can be used for stabilizing each queue in the 
network (see e.g., the rate proportional 
processor sharing (RPPS) scheme in [10] and 
the service curve earliest deadline first 
(SCED) scheme in [11]). However, if the 
arrival rates are not known, then most packet 
scheduling polices that stabilize any 
admissible traffic in the capacity region are 
related to the maximum weighted matching 
(MWM) algorithm in [13], where the most 
suitable configuration vector is identified in 
every time slot. In the next section, we will 
extend the dynamic frame sizing algorithm 
for switches and wired networks in [3], [8] to 
the mathematical model for wireless 
networks described in this report. 
III. Dynamic Frame Sizing Algorithm 
 In [3], [8], the dynamic frame sizing 
(DFS) algorithm has been used for stabilizing 
queues in switches and wired networks 
without knowing the arrival rates. In the DFS 
algorithm, time is partitioned into frames, 
where the frame size is not fixed and is 
determined at the beginning of each frame. 
The main idea of the DFS algorithm is to 
determine the minimum frame size at the 
beginning of a frame so that the backlog 
observed at the ingress queue of each flow at 
the beginning of the frame can be cleared by 
the end of the frame. To ensure the number 
of packets of each flow inside the network is 
bounded above by a finite constant, the DFS 
algorithm then provides each flow in a frame 
a guaranteed rate that is proportional to the 
backlog observed at the ingress queue at the 
beginning of that frame. As long as the 
expected size of each frame is finite, the 
expected backlog at each queue remains 
finite. 
 In view of this, there are two steps for 
the extension of the DFS algorithm to the 
mathematical model for wireless networks 
described in Section II. 
(i) Determine the frame size at the beginning 
of each frame. 
(ii) Provide guaranteed rate services in our 
mathematical model. 
We will address the first step in Section 
III-A. By proposing a hierarchical smooth 
algorithm in Section III-B, we show how to 
provide guaranteed rate services in our 
mathematical model. The proof for the 
finiteness for the expected frame size under 
the DFS algorithm will be given in Section 
III-C. 
 6 
the set of the configuration vectors 
containing link  , namely, 
 
(9) 
and ψ  be the aggregate weight for link  , 
namely, 
 
If 1
1
≤∑ =
K
k k
φ  and 0>ψ  for each link   
with 0)( >ny , then 
(10) 
Proof. If 0)( =ny  for all L,...,2,1= , 
then we know 1=nT  and the bound in (10) 
holds trivially. Now assume there exist some 
  such that 0)( >ny . For this case, nT  is 
the minimum clearance time defined in (7). 
As such, nT  is upper bounded by the time 
needed to clear all the backlogs by using the 
smooth schedule with the set of configuration 
vectors KkkP 1}{ =  and their weights 
K
kk 1}{ =φ . 
Since each token is selected not later than its 
deadline in such a smooth schedule, the total 
number of tokens that are selected for 
configuration vector kP  by time t is at least 
 tkφ  (as the deadline of the  tkφ th token 
for configuration vector kP  is 
   tt kk ≤φφ / ). This then implies that the 
total number of packets that link   can 
transmit by time t is at least  ∑ ∈ Sk ktφ . Let 
 
Then, the total number of packets sent out 
from link   in the duration [0, T] is at least 
 
(11) 
for all L≤≤ 1 . Thus, by time T, the 
backlog in every link is cleared by using the 
smooth schedule. Clearly, we have 
 
and the upper bound also holds for this case. 
 
B. A hierarchical smooth schedule 
In this section, we propose a 
hierarchical smooth schedule that is able to 
provide guaranteed rate services in our 
mathematical model for wireless networks. 
There are two levels of this schedule: (i) the 
upper level for configuration vectors and (ii) 
the lower level for flows in each link.  
(S2) The smooth schedule for configuration 
vectors: 
 Suppose the next frame size nT  is 
determined in the minimization problem in (8) 
with the set of configuration vectors KkkP 1}{ =  
and the set Kkkm 1}{ =  (the index n is omitted 
here for clarity). During the nth frame, run 
the smooth schedule with weights nk Tm / . 
As ∑ ==
K
k kn
mT
1
 in the minimization 
problem in (8), the sum of the weights is 1 in 
this smooth schedule, i.e., 1/
1
=∑ = n
K
k k
Tm . 
Specifically, the ith token of the 
configuration vector kP  is assigned with the 
eligible time  knn mTi /)1(1 −++τ  and 
deadline  knn miT /+τ , Kk ≤≤1 . Then, 
for each time slot t in the interval 
],1[ nnn T++ ττ , the smooth schedule selects 
the eligible token with the earliest deadline, 
and assigns the corresponding configuration 
vector at time t. At the beginning of the nth 
frame, the schedule for all the configuration 
vectors in ],1[ nnn T++ ττ  is computed and 
then transmitted to all the links in the 
network. 
(S3) The smooth schedule for flows in each 
link: 
Since Kkkm 1}{ =  and 
K
kkP 1}{ =  achieve the 
minimization problem in (8), we have that 
      (12) 
Similar to (9), let S  be the set of the 
configuration vectors in KkkP 1}{ = containing 
link   within the nth frame. Thus, we have 
from (12) and (6) that 
(13) 
 8 
Proof. Consider the governing equation of 
queue )( jq  in (1). Note that there is a 
departure from )( jq  at time t, i.e., 
1)()( =tb j , if a token is selected for flow j by 
link   at time t and there are packets that 
can be departed from the queue. Let )()( tc j  
be the indicator variable for the event that a 
token is selected for flow j by link   at time 
t. Thus, we can rewrite the governing 
equation of queue )( jq  in (1) as follows: 
 
(18) 
As we assume the queue is empty at time 0, 
recursively expanding the governing 
equation in (18) yields 
  (19) 
where ∑ ==
t
t
jj tatA
1 1
)()(
1
)()(   and 
∑ ==
t
t
jj tctC
1 1
)()(
1
)()(  are the accumulative 
number of packets arriving at )( jq  and the 
accumulative number of tokens selected for 
flow j by link   by time t, respectively. 
Recall that ),( ju  is the upstream link of 
link   for flow j. For link  , we define 
∑ ==
t
t
jj tbtB
1 1
)()(
1
)()(  as the cumulative 
number of packets that depart from )( jq  by 
time t. Since a packet can depart from an 
upstream queue only if there is a token 
selected for the upstream queue, it then 
follow that 
 
            (20) 
for each internal queue )( jq  . 
 From (20) and Lemma 4, it follows that 
 (21) 
 According to Lemma 4, we have that 
 
(22) 
 Thus, the result in (17) follows directly 
from (19), (21) and (22). 
 
C. Frame Bound 
In this section, we show that, for 
Bernoulli arrival traffic with arrival rates 
inside the capacity region, the expected 
frame size is finite. Thus, the DFS algorithm 
guarantees 100% throughput for such 
Bernoulli traffic.  
Here we make three specific 
assumptions on the input traffic. 
(A1) All the multicast flows are independent 
Bernoulli processes when they arrive at the 
network. Specifically, sta j )'()(  are 
independent Bernoulli random variables for 
all j and t. 
(A2) Assume that the arrival rate of flow j is 
)( jλ , 1 ≤ j ≤ J, and this rate information is 
unknown to the network. Without loss of 
generality, we also assume 0)( >jλ  for all j 
and every link is traversed by at least one 
flow, i.e., 
 
where 0 is the L-vector with all its elements 
being 0. 
(A3) The input traffic is admissible, i.e., the 
intensity defined in (5) is strictly smaller than 
1, i.e., 1|||| <Λ=ρ . 
 As we assume that the traffic is 
admissible, there is a set of weights Kkk 1}{ =φ  
and a set of configuration vectors KkkP 1}{ =  
such that 
       (23) 
and 
       (24) 
Theorem 6 Assume that the input traffic 
satisfies (A1)–(A3). Consider the set of 
weights Kkk 1}{ =φ  and the set of configuration 
vectors KkkP 1}{ =  that satisfy (23) and (24). 
Let ∑ ∈=  Sk k ρφψ / , where S  is the set of 
configuration vectors containing link   in 
K
kkP 1}{ =  as in (9). Also, let 
 ψψ L≤≤= 1min min  
 10 
 
(37) 
According to (26), we have that 
 
and (37) can be rewritten (with θ being 
replaced by *θ ) as 
(38) 
Since ][log nTeE θ  is convex in θ (see e.g., [1, 
Proposition 7.1.8]) and ρ < 1, we have that 
(39) 
Using (39) and (38) yields 
 
(40) 
Since 11 =T  (as the network is started from 
an empty system), one can verify (25) from 
induction by using (40). Finally, we use (25) 
to show the bound of the frame size in 
Theorem 6. Since xeθ  is convex in x, it 
follows from Jensen’s Inequality that 
 
(41) 
IV. Conclusion 
In this report, we extended the dynamic 
frame sizing algorithm to the setting of 
wireless networks. We modeled wireless 
networks by configuration vectors that 
specify the sets of links that can transmit at 
the same time. For such a mathematical 
model, we considered multicast flows with 
per flow queueing. We proved that the DFS 
algorithm indeed stabilizes the network for 
any admissible Bernoulli traffic. In 
comparison with the previous results for the 
DFS algorithm in [3], [8], our main 
contributions in this report are the two new 
technical results: (i) an upper bound for the 
frame size that has an explicit expression in 
terms of the workload, and (ii) a hierarchical 
smooth schedule that provides guaranteed 
rate services in such a mathematical model. 
The first result allows us to modify the large 
deviation argument in [3], [8] to prove the 
finiteness of the expected frame size, while 
the second result leads to an upper bound for 
the total number of packets in an internal 
queue. 
There are some possible extensions of 
this work. 
(i) In (S1), the frame size is chosen to be 1 
when there is no backlog in each ingress 
queue. In the worst case, this requires the 
optimization problem to be carried out in 
every time slot (which is as bad as the 
maximum weighted matching algorithm). We 
note that it is possible to set a bound on the 
minimum frame size so that the optimization 
problem needs not be carried out too often. 
This is because our proof only relies on the 
assumption that the backlog in each ingress 
queue at the beginning of a frame needs to be 
cleared by the end of that frame. 
(ii) The DFS algorithm described in this 
report does not provide traffic isolation. 
When the traffic is not admissible, the 
expected frame size cannot be bounded. As 
all the flows are coupled through the 
optimization problem that determines the 
frame size at the beginning of each frame, the 
performance could be very bad for all the 
flows. In view of this, one should enforce an 
upper limit for the frame size. But this also 
limits the throughput that can be achieved by 
the DFS algorithm. 
V. Appendix A 
In the proof of Lemma 4, we need to 
consider multiple frames. As such, we add 
the index n in )(nK , )(nmk , )(nPk , )(nS , 
and )(nF  to represent all the corresponding 
parameters used in the DFS algorithm within 
frame n. First, we consider a time slot t in the 
nth frame. Define )(tD  as the cumulative 
number of allowable time slots for link   
by time t. According to (S2) and (S3), when a 
token for the configuration vector 
)()( nSnPk ∈  is selected by the schedule at a 
time slot, then link   is allowable at that 
time slot. Prior to the nth frame, we know 
from (13) that there are totally 
∑ −=
1
1'
)'(n
n
ny tokens selected for link  . 
 Now, consider the nth frame that t 
belongs to. First, the cumulative number of 
 12 
where we use (13) in the last equality. Notice 
from (16) that maxSS ≤  for each frame n. 
Then, it follows from (46) that 
 
(47) 
Also, from (45), we have that 
 
(48) 
By following a similar procedure, one can 
verify that 
 
(49) 
Thus, (14) follows from (47) and (49). 
VI. References 
[1] C. S. Chang, Performance Guarantees in 
Communication Networks, London: Springer-Verlag, 
2000. 
[2] D. B. West, Introduction to Graph Theory, 2nd ed., 
Prentice-Hall, Inc., 2001. 
[3] C. -S. Chang, Y. -H. Hsu, J. Cheng, and D. -S. Lee, 
“A Dynamic Frame Sizing Algorithm for CICQ 
Switches with 100% Throughput, ” Proceedings of 
IEEE INFOCOM 2009. 
[4] P. Chaporkar and S. Sarkar, “Stable scheduling 
policies for maximizing throughput in generalized 
constrained queueing networks, ” Proceedings of 
IEEE INFOCOM 2006. 
[5] P. Giaccone, E. Leonardi, and D. Shah, 
“Throughput region of finite-buffered networks, ” 
IEEE Transaction on parallel and distributed systems, 
vol. 18, no. 2, Feb. 2007. 
[6] S.-M. He, S.-T. Sun, H.-T. Guan, Q. Zheng, Y.-J. 
Zhao, and W.Gao, “On guaranteed smooth switching 
for buffered crossbar switches,” IEEE/ACM 
Transactions on Networking, vol. 16, no. 3, pp. 
718-731, June 2008. 
[7] L. B. Le, E. Modiano, and N. B. Shroff, “Optimal 
Control of Wireless Networks with Finite Buffers, ” 
Proceedings of IEEE INFOCOM 2010. 
[8] C. M. Lien and C. S. Chang, “Generalized 
Dynamic Frame Sizing Algorithm for 
Finite-Internal-Buffered Networks, ” IEEE 
Communication Letters, vol. 13, no. 9, Sep. 2009. 
[9] M. A. Marsan, A. Bianco, P. Giaccone, E. 
Leonardi, and F. Neri, “Multicast traffic in 
input-queued switches: optimal scheduling and 
maximum throughput, ” IEEE/ACM Transactions on 
Networking, vol. 11, no. 3, June 2003. 
[10] A. K. Parekh and R. G. Gallager, “A generalized 
processor sharing approach to flow control in 
integrated service networks: the multiple node case,” 
IEEE/ACM Transactions on Networking, vol. 2, pp. 
137-150, 1994. 
[11] H. Sariowan, R.L. Cruz and G.C. Polyzos, 
“Scheduling for Quality of Service Guarantees via 
Service Curves,” Proceedings of the International 
Conference on Computer Communications and 
Networks, 1995. 
[12] G. Sharma, R. R. Mazumdar, and N. B. Shroff, 
“On the complexity of scheduling in wireless 
networks, ” MobiCom 2006, Sep. 2006. 
[13] L. Tassiulas and A. Ephremides, “Stability 
properties of constrained queueing systems and 
scheduling policies for maximum throughput in 
multihop radio networks,” IEEE Transactions on 
Automatic Control, vol. 31, no. 12, pp. 1936–1948, 
1992. 
hoc and sensor networks.” 
2. Prof. Shivendra Panwar, “for contributions to design and analysis of communication 
networks.” 
3. Prof. Bo Li, “for contributions to content distribution via the internet.” 
4. Prof. Guoliang Xue, “for contributions to survivability and quality of service in 
computer networks.”  
 
並頒發下列獎項： 
1. IEEE Internet Award 
 Prof. Jun Murai, “for leadership in the development and deployment of the global 
internet, especially across the Asia-Pacific region.” 
2. INFOCOM Achievement Award 
 Prof. Donald F. Towsley, “for contributions to measurement, modeling and performance 
analysis of computer networks.” 
 
 
 
本人與甫獲今年 INFOCOM Achievement Award 的 Don Towsley 教授於會場合影 
 
Best Paper Award:  
 大會依照論文的原創性、重要性的潛力以及貢獻的深度選出下列論文為大會最佳
論文: “Dynamic Right-Sizing for Power-Proportional Data Centers.” 
 
Keynote Talk / Panel: 
 大會邀請中國移動（China Mobile）研究部門總經理 Bill Huang 博士，針對通訊
網路領域的現況及未來發展走向，發表下列演說： 
 The Market and Telco’s Request in the New Mobile Internet Ecosystem. 
 
同時，大會也針對以下主題，舉辦座談會，供各方專家學者對談。 
 Internet of Things: Where We Are Now and Where We Are Going. 
 The Challenge of Cloud Computing. 
 Sustainable Computing and Networking. 
 
會議主論文:     
 本次會議主論文內容相當多樣性，並且分布非常平均，但最熱門的研究主題依然
是 Wireless Network 與 Sensor Network 方面的研究。以下我們節錄較為有趣的論文: 
座談會提及兩項重要概念。其一為反彈效應（Rebound Effect）。簡而言之，便是某
種技術所節省的能源，因消費量增加而被抵消。例如提昇燃料燃燒效率的技術雖可有
效減少每單位距離的燃油使用量，但減少的燃油及排放的廢氣量，卻會因為消費者增
加開車的頻率及距離而抵消。另外一方面，以現今全球六十億的人口數而言，地球必
須被視為資源有限，會被耗盡的生活環境。因此，在面臨任何選擇時，都不能只為了
自己的需求，甚至只因為當下的感受便做出決定。相反的，必須優先考量下一代，甚
至下下一代的生存環境，為目前尚未出生的人類預先著想。是以，對於永續發展而言，
我們需要的不只是技術上的進步，更要在教育上著手，使地球資源有限，永續發展等
概念深植人心。 
 
最後，本人非常感謝國科會計劃提供補助，使得此次會議得以成行，也使得本人
對網路的發展及研究有進一步的認知。 
 
四、攜回資料 
 
INFOCOM 2011 論文集 CD 一片，及網路科學工作坊論文集 CD 一片。 
 
 
 
Best Regards, 
 
Byrav Ramamurthy, Jie Wu and Qian Zhang 
IEEE INFOCOM 2011 TPC Co‐Chairs 
 
Jiangchuan Liu 
TPC Vice Chair for Information Systems 
  
2
2 
Best Regards, 
 
Byrav Ramamurthy, Jie Wu and Qian Zhang 
IEEE INFOCOM 2011 TPC Co‐Chairs 
 
Jiangchuan Liu 
TPC Vice Chair for Information Systems 
 
Newman's fast algorithm simply corresponds to the special 
case that the bivariate distribution is obtained from uniformly 
selecting a path with length 1. As such, its resolution is 
quite limited. To improve the resolution, it seems plausible 
to consider bivariate distributions that have nonzero probabil­
ities for selecting paths with length greater than 1. Such an 
observation is verified via extensive computer simulations for 
randomly generated graphs with 128 vertices and four known 
communities in this paper. 
In addition to the choice of the bivariate distribution for 
the problem of resolution limit, there is another choice of the 
correlation measure that might lead to performance improve­
ment. In this paper, we propose three correlation measures: (i) 
covariance, (ii) correlation and (iii) mutual information. The 
first one corresponds to the original measure used in New­
man's fast algorithm. From our simulation results, the last two 
perform better than the first one when we consider a bivariate 
distribution that has nonzero probabilities for selecting paths 
with length greater than 1. 
The rest of the paper is organized as follows. In Section 
II, we first give a brief review of Newman's fast algorithm. 
We then provide a probabilistic interpretation of Newman's 
fast algorithm in Section III. The general framework is given 
in details in Section IV. We show how one can obtain a 
bivariate distribution from the adjacency matrix of a graph 
in Section IV-A, define correlation measures in Section IV-B, 
propose the class of distribution-based clustering algorithms in 
Section IV-C, and define a community and a modularity index 
in Section IV-D. We report our simulation results in Section 
V. The paper is concluded in Section VI, where we address 
possible extensions of our work. 
II. REVIEW OF NEWMAN'S FAST ALGORITHM 
In the literature, a network is commonly modelled by a 
graph G(V, E), where V denotes the set of vertices in the 
graph and E denotes the set of edges in the graph. The problem 
of detecting community structure in a network is to find a 
function that assigns every vertex in the graph to a community 
(also known as a graph partitioning problem in [7], [25]). In 
this paper, we are particularly interested in Newman's fast 
algorithm [13] for finding such an assignment, and we will 
start from giving a brief review of Newman's fast algorithm. 
Let n = IV I be the number of vertices in the graph and 
index the n vertices from 1, 2, ... ,n. Then the graph G(V, E) 
can also be characterized by an n x n adjacency matrix A, 
where 
if vertices v and ware connected, 
otherwise . 
(1) 
Let m = lEI be the number of edges in the graph and kv be 
the degree of vertex v. From the adjacency matrix, we then 
have 
(2) 
and 
n 
kv = L Avw. 
w=l 
(3) 
Let Cv be the community of vertex v and 8(cv, i) be the 
8-function that equals to 1 if Cv = i and 0 otherwise. Then 
the fraction of ends of edges that are attached to the vertices 
in community i, denoted by ai, can be represented as follows: 
Let 
1 n 
ai = - � kv8(cv, i). 2m � v=l 
(4) 
(5) 
When i = j, eij is the fraction of edges that join the vertices 
in community i, and when i =I- j, eij is one-half of the fraction 
of edges that join the vertices in community i and the vertices 
in community j. 
In [15], Newman and Girvan proposed a modularity index 
Q as follows: 
(6) 
As explained in [13], if the fraction of within-community 
edges is the same as what we would expect for a randomized 
network, then this quantity is zero. Nonzero values represent 
deviations from randomness. The objective of a community­
detecting algorithm is then to find an assignment for each 
vertex so that the modularity index Q can be maximized. 
However, it was shown in [1] that finding such an optimal 
assignment is NP-complete in the strong sense. 
In [13], Newman proposed a heuristic approach for the 
problem based on an agglomerative hierarchical clustering 
method (see e.g., the books [7], [25] for more references on ag­
glomerative hierarchical clustering algorithms). The algorithm 
starts with a state in which each vertex is the sole member in its 
community. Then one repeatedly joins communities together 
in pairs by choosing at each step the join that results in the 
greatest increase (or smallest decrease) in the modularity index 
Q. To see how the algorithm works, suppose that there are C 
communities in a certain step with 
Q = (ell - a� ) + . . .  + (eii - a� ) + . . .  
+(ejj - a; ) + . . .  + (ecc - ab ) . 
Now suppose we group community i and community j to 
form a new community k. As ekk is the fraction of edges 
that joins the vertices in communities i and j and ak is the 
fraction of ends of edges that are attached to the vertices in 
communities i and j, it is easy to see that ekk = eii + 2eij +ejj 
and ak = ai + aj. 
Thus, the modularity index Q after grouping community i 
and community j to form a new community k is 
731 
A. From a graph to a bivariate distribution 
As mentioned before, a network is commonly modelled 
by a graph G(V, E), which in turn is characterized by an 
adjacency matrix A. The question is how one obtains a 
bivariate distribution characterization from a graph model. A 
direct approach is to follow the probabilistic interpretation in 
Section III that maps an adjacency matrix A to a bivariate 
distribution in (8). Let a(A) be the sum of all the elements in 
a matrix A, i.e., 
a(A) = LLAvw. 
v w 
Then one can rewrite (8) as follows: 
(20) 
1 
P(V = v, W = w) = 
a(A) 
Avw. (21) 
One problem of using the adjacency matrix is the resolution 
limit in community detection. As argued in [12], optimizing 
the modularity index Q in [15] may fail to detect communities 
smaller than a scale that depends on the size of the network 
and the degree of interconnectedness of the communities. This 
motivates us to consider a more general approach that maps a 
graph to a bivariate distribution. 
Recall that the bivariate distribution in (21) is the probability 
for the two ends of a randomly selected edge in a graph. 
Our idea is to generate the needed bivariate distribution by 
randomly selecting the two ends of a path. For this, we 
first consider a (matrix) function f that maps an adjacency 
matrix A to another matrix f(A). Then we define a bivariate 
distribution from f(A) by 
1 
P(V = v, W = w) = a(f(A)
/(A)vw. (22) 
This idea is further illustrated in the following example for 
randomly selecting two ends of a path with length not greater 
than 2. 
Example 1: (A random selection of a path with length 
not greater than 2) Consider a graph with an n x n adjacency 
matrix A and 
(23) 
where I is the n x n identity matrix, and AD, AI, and A2 are 
three nonnegative constants. Then the two random variables V 
and W in (22) represents the two ends of a randomly selected 
path with length not greater than 2. To see this, note that there 
are n paths with length 0 (for the n vertices), a(A) paths with 
length 1, and a(A2) paths with length 2. Since 
a(f(A)) = Aoa(I) + Ala(A) + A2a(A2), 
a path with length g is selected with probability Ada(f(A)) 
for g = 0, 1, and 2. 
We note that the computation complexity of A2 is O(mn) 
for a sparse n x n matrix with at most m nonzero elements and 
there exist other fast sparse matrix multiplication algorithms 
in the literature (see e.g., [27]). 
Another approach to generate a bivariate distribution from 
the adjacency matrix A from a graph is to consider a random 
walk on a graph (see e.g., [3]). 
Example 2: (A random walk on a graph) Consider a 
graph with an n x n adjacency matrix A. As in (2) and (3), let 
m be the total number of edges and kv be the degree of vertex 
v. A random walk on such a graph can be characterized by 
a Markov chain with the n x n transition probability matrix 
R = (Rv,w), where 
1 
Rv,w = -Avw kv 
(24) 
is the transition probability from vertex v to vertex w. The 
stationary probability that the Markov chain is in vertex v, 
denoted by 1rv, is kv/2m. Let /3£ be the probability that 
we select a path with length g, g = 1,2, . . . . Then the 
probability of selecting a random walk (path) with vertices 
v = VI, V2, ... , V£+1 = w is 
£ 
/3£1rvl II RVi,vi+l· 
i=1 
From this, we then have the bivariate distribution 
00 £ 
(25) 
p(v, w) = 1rv L /3£ L··· L II RVi,vi+l· (26) 
£=1 Vi i=1 
Since A is a symmetric matrix, it is easy to see that 
1 1 
1rvRv w = -Av w = -Aw V = 1rwRw v , 2m ' 2m ' , 
for all v and w, and the Markov chain is thus a reversible 
Markov chain [19]. This implies that 
£ £ 
1rVl II RVi,Vi+l = 1rVi II RVi+1,Vi 
i=1 i=1 
and p( v, w) = p( w, v) is thus a symmetric bivariate distribu­
tion. To randomly select a path with length not greater than 
2, we can simply let /3£ = 0 for all g > 2 and this leads to 
( ) - �A + .!!2. � 
AV,V2Av2,W (27) p v, w 
2 v,w 2 � k 
. 
m m v2=1 V2 
B. Correlation measures 
As discussed in Section III, Newman's fast algorithm uses 
covariance to measure how positively two indicator random 
variables are related. In this section, we extend this to a more 
general setting by considering "correlation measures" defined 
below. 
Definition 3: For any two indicator random variables X and 
Y, p(X, Y) is called a correlation measure in this paper if 
(CO) p(X, Y) is solely determined by the bivariate distri­
bution of X and Y, 
(Cl) p(X, Y) = 0 if and only if X and Y are independent, 
i.e., 
P(X = 1, Y = 1) = P(X = l)P(Y = 1), (28) 
733 
(P5) Repeat (P3) until either there is only one community 
left or all the remaining pairs of communities have negative 
correlation measures, i.e., p(Xi' Yj) < 0 for all i -=I- j. 
Distribution-based clustering algorithms are generalizations 
of Newmans's fast algorithm. In each iteration, the distribution 
is updated and then used for computing the new correlation 
measures. This is different from most distance-based clus­
tering algorithms [7], [25], where the new distance between 
clusters is updated directly. Note that there are at most n - 1 
iterations in the above algorithm and there are O(n) updates 
for the measures in (P4) for each iteration. The hard part is 
to find the two communities that have the largest correlation 
measure in (P3). If we simply use a linear search to find the 
two communities that have the largest correlation measure in 
each iteration, then its computational complexity is O(n2) and 
the overall computational complexity for the above algorithm 
is O(n3). To reduce the computational complexity, one can 
implement a sorted list for the measures in (P2) and then insert 
every measure update into the sorted list. As each insertion of 
a new update takes O(log(n)) steps (by using a binary search) 
and there are O(n) updates in each iteration, the computational 
complexity in each iteration can be reduced to O( n log( n)) 
and that yields O(n2Iog(n)) computational complexity for the 
above algorithm. One can further reduce the computational 
complexity by exploring the "spareness" of the bivariate 
distribution. Suppose that we stop the algorithm in (P5) once 
all the remaining pairs of communities do not have positive 
measures, i.e., p(Xi' Yj) :::; 0 for all i and j. In this case, 
we only need to maintain the list of measures with positive 
values. From (C2) in Definition 3, it suffices to maintain the 
pair of communities i and j with P(Xi = 1, Yj = 1) > o. 
Two communities i and j are said to be connected if either 
P(Xi = 1, Yj = 1) > 0 or P(Xj = 1, Yi = 1) > o. 
Suppose that there are only O(m) connected pairs of them 
at the beginning. In view of (P2), we only need to maintain 
(and update) the pair of connected communities. As such, 
instead of having O(n) updates, one only needs O(lil + Ijl) 
updates in each iteration, where Ii I (resp. Jj J) is the number 
of communities connected to community i (resp. Ijl). Thus, 
each iteration takes 0 ( (  I i I + Ij I) log n) steps. Analogous to the 
argument in [2], each connected pair contributes at most 2d 
updates till the end of the algorithm, where d the is depth of 
the dendrogram. Thus, the overall computational complexity 
for the above algorithm is O(mdlogn), In practice, we often 
have m = O(n) and d = O(logn) and the computational 
complexity of the distribution-based clustering algorithm is 
O(n(logn)2) as in [2]. 
D. A probabilistic definition of a community 
Up to this point, we have not defined what a commu­
nity means. In the literature, there are many definitions for 
communities based the adjacency matrix of the graph that 
characterizes a network (see e.g., [21], [10]). 
Here we provide a probabilistic definition of a community 
based on our framework. 
Definition 7: A set of nodes S is a community in a proba­
bilistic sense if 
P(V E S, WE S) 2:: P(V E S)P(W E S). (42) 
If P(W E S) > 0, then this is equivalent to 
P(V E SIW E S) 2:: P(V E S). (43) 
For a symmetric bivariate distribution p(v,w), P(V E S) is 
simply the probability that a randomly selected node is in 
the community. In comparison with the event that a randomly 
selected node is in the community, it is more likely to find 
the other node in the same community given that one of 
a randomly selected pair of two nodes is already in the 
community. 
Analogous to the definition of the modularity index Q in 
[15], we define a modularity index based on our probabilistic 
framework. 
Definition 8: Consider a bivariate distribution p( v, w) with 
v, w = 1,2, . . .  , n. Let Se, C = 1,2, ... , C, be a partition 
of {I, 2, . . .  ,n}, i.e., Se n Se' is an empty set for c -=I- c' and 
Uf=l Se = {I, 2, . . .  ,n}. The modularity index Q with respect 
to the partition Se, c = 1,2, ... , C, is 
c 
L (P(V E Se, W E Se) - P(V E Se)P(W E Se)) . (44) 
e=l 
In the following theorem, we show (under certain technical 
conditions) that the modularity index is non-decreasing in 
every iteration of any distribution-based clustering algorithm 
and it indeed detects communities in the probabilistic sense 
defined in Definition 7. 
Theorem 9: Suppose that p(v, w) is symmetric. 
(i) Then for any distribution-based clustering algorithm 
described in Section IV-C, the modularity index is 
non-decreasing in every iteration. 
(ii) If, furthermore, 
(45) 
for all v = 1,2, . . .  , n, then every community de­
tected by any distribution-based clustering algorithm 
described in Section IV-C is a community in the 
probabilistic sense defined in Definition 7. 
Proof. (i) Since we assume that p( v, w) is symmetric, it 
suffices to show that 
c 
L (P(V E Se, WE Se) - (P(V E Se)?) (46) 
e=l 
is non-decreasing in every iteration. Suppose that community 
i and community j are selected and grouped into a new 
community k in some iteration. Thus, we have a new partition 
of {I, 2, . . .  ,n} with Sk = Si U Sj. To prove that the 
modularity index in (46) is non-decreasing after grouping 
735 
Covariance 
OO�==�==�'�--�3----�,----�,----7,----�--� 
nurrber of intercomrunity edges per vertex ZOUI 
Fig. I. Performance of h(A). h(A) and /3(A) under the covariance 
algorithm 
the distribution-based clustering algorithms until there are 
exactly four communities left. To evaluate the performance 
of these algorithms, we compute the percentage of nodes 
that are correctly assigned. For this, we first identify the 
largest subset of vertices that are assigned to each of the 
four known communities. If two or more of these subsets 
belong to the same community, then all vertices in these 
subsets are considered incorrectly classified. Otherwise, the 
vertices in the four subsets are considered correctly classified. 
In Figure I (resp. Figure 2, Figure 3), we show the percentage 
of nodes that are correctly classified under the covariance 
(resp. correlation, mutual information) algorithm as a function 
of Zout. Each point in these figures is an average over 100 
random graphs. In these figures, we also show 95% confidence 
intervals for all data points. From these three figures, it is 
clear that the choice of using h(A) = 1+ 0.5A + O.25A2 
significantly outperforms the other two choices, especially 
when Zout is large. The intuition behind this can be explained 
by considering the illustrating example in Figure 4. In the 
figure, there are two clearly separated communities A and B. 
But it is difficult to see whether vertex C should be classified 
to community A by considering paths with length not greater 
than I (as vertex C has exactly one path with length 1 to each 
community). However, if we consider paths with length 2, then 
it is obvious that we should classify vertex C to community 
A. 
When we choose h(A) = 1+ O.5A + O.25A2, we note 
from these three figures that the performance of using the 
correlation algorithm and that of using the mutual information 
algorithm are comparable. But they both are much better than 
the covariance algorithm. This shows that the choice of the 
correlation measure might also affect the performance. 
B. Karate club 
Now, we apply our framework to a well-known set of real­
world network data, called "karate club." The set of data was 
observed by Wayne Zachary [28] over the course of two years 
in the early 1970s at an American university. During the course 
of the study, the club split into two groups because of a dispute 
��==�==�'�--�3----�,----7,----�,----�--� 
nurrber of intercomrunity edges per vertex ZOUI 
Fig. 2. Performance of h (A). h (A) and /3 (A) under the correlation 
algorithm 
Mutual Information 
��==�==�'�--�3----�,----�,----7.----T----J 
nurrber of intercomrunity edges per vertex ZOUI 
Fig. 3. Performance of h(A). h(A) and /3(A) under the mutual 
information algorithm 
within the organization, and the members of one group left to 
establish their own club. The network of friendships between 
each other in the karate club observed by Zachary is shown 
in Figure 5. 
In Figure 6, we show the dendrogram generated by using the 
covariance algorithm with h(A) = I +O.5A+O.25A2. The al­
gorithm is run until there is only one community left. As such, 
we can cut through the dendrogram at different levels to give 
divisions of the network into larger or smaller communities. As 
shown in Figure 6, the dendrogram generated by our algorithm 
matches perfectly to original structure observed by Zachary. 
A B 
Fig. 4. An illustrating example for vertices that are difficult to classify by 
considering paths with length not greater than I. 
737 
Maximizing Throughput in Wireless Networks with
Finite Internal Buffers
Ching-Min Lien, Cheng-Shang Chang, Jay Cheng and Duan-Shin Lee
Institute of Communications Engineering
National Tsing Hua University
Hsinchu 300, Taiwan, R.O.C.
E-mail: keiichi@gibbs.ee.nthu.edu.tw; cschang@ee.nthu.edu.tw;
jcheng@ee.nthu.edu.tw; lds@cs.nthu.edu.tw
ABSTRACT
In this paper, we consider the problem for maximizing the
throughput of a discrete-time wireless network, where only
certain sets of links can transmit simultaneously. It is well
known that each set of such links can be represented by a
configuration vector and the convex hull of the configuration
vectors determines the capacity region of the wireless network.
In the literature, packet scheduling polices that stabilize any
admissible traffic in the capacity region are mostly related
to the maximum weighted matching algorithm (MWM) that
identifies the most suitable configuration vector in every time
slot. Unlike the MWM algorithm, we propose a dynamic frame
sizing (DFS) algorithm that also stabilizes any admissible
traffic in the capacity region. The DFS algorithm, as an
extension of our previous work for wired networks, also does
not have a fixed frame size. To determine the frame size, an
optimization problem needs to be solved at the beginning of
each frame. Once the frame size is determined, a hierarchical
smooth schedule is devised to determine both the schedule
for configuration vectors and the schedule for multicast traffic
flows in each link. Under the assumption of Bernoulli arrival
processes with admissible rates, we show that the number
of packets of each multicast traffic flow inside the wireless
network is bounded above by a constant and thus one only
requires to implement a finite internal buffer in each link in
such a wireless network.
I. INTRODUCTION
Packet scheduling in both wired and wireless networks to
achieve maximum system throughput or provide quality of
service has been an ongoing research problem for a long
period of time. Our objective in this paper is to extend the
dynamic frame sizing (DFS) algorithm for switches [3] and
wired networks [8] to the setting of wireless networks. For
this, we consider the configuration vector model that is often
used in the literature to model the effect of link interference
in a wireless network. A configuration vector is a vector
of indicator variables that specifies a set of links which are
allowed to transmit packets at the same time in a wireless
network. The configuration vector model then characterizes
a wireless network by a set of configuration vectors. Such a
model is also known as the generalized constrained queueing
model in [4]. For the configuration vector model, it is well
known that the capacity region for a wireless network is the
convex hull of the set of configuration vectors. There are plenty
of studies in the literature (see e.g., [13], [12], [4], [7]) that
addressed the packet scheduling problem for maximizing the
throughput in such a wireless network model. In particular,
a scheduling algorithm is called throughput-optimal if it can
stabilize the network for arrival traffic with rates falling within
the capacity region. Most of throughput-optimal scheduling
schemes are related to the maximum weighted matching
(MWM) algorithm in [13], which identifies the most suitable
configuration vector according to the queue length information
available at each time slot.
Unlike the MWM algorithm, there is no need for the DFS
algorithm to solve an optimization problem in every time slot.
In the DFS algorithm, time is partitioned into frames, and
an optimization problem is solved to determine the frame
size at the beginning of each frame. For a wireless network
that implements per flow queueing for each multicast flow,
the frame size is chosen to be the minimum amount of
time, known as the minimum clearance time, to clear the
backlogs observed at the ingress queues at the beginning of
the frame. By so doing, the backlogs at the ingress queues
at the beginning of a frame is then bounded above by the
arrivals during the previous frame, and a packet that arrives
at an ingress queue in one frame will leave the ingress queue
and enter the network in the next frame. Thus, as long as the
expected size of each frame is finite, the expected backlog
at each ingress queue remains finite. For packets that have
departed from their ingress queues and entered the network,
the DFS algorithm provides each flow in a frame a guaranteed
rate that is proportional to the backlog observed at the ingress
queue at the beginning of that frame. Such a guaranteed rate
service then ensures the number of packets of each flow inside
the network is bounded above by a finite constant. As a result,
every internal buffer is finite and this mitigates the problem of
implementing unlimited internal buffers as pointed out in [5].
The extension of the DFS algorithm to the configuration
vector model is not as straightforward as one might expect.
There are two technical difficulties that need to be conquered
This paper was presented as part of the main technical program at IEEE INFOCOM 2011978-1-4244-9921-2/11/$26.00 ©2011 IEEE 2345
packets can be transmitted through link ℓ in a time slot. Here
we assume that pℓ’s are either 1 or 0, and we say that ℓ ∈ P
if pℓ = 1 and ℓ /∈ P otherwise.
Let W be the collection of all configuration vectors. In
practice, W reflects both physical and topological constraints
on the network. For example, consider the network represented
by the directed graph in Figure 1, where each directed link
represents that packets can be sent from the head of the link
to the tail of the link. Under the node exclusive interference
model [12], links 1 and 7 in Figure 1 can transmit packets
at the same time. However, since each pair of links are
separated by at most one link in Figure 1, there is at most one
input/output pair can transmit a packet at the same time under
the assumption of IEEE 802.11 based interference model [12].
As configuration vectors are mainly due to interference in
wireless networks, it is reasonable to assume in this paper
that the set W is coordinate convex, i.e., if P1 ≤ P2 and
P2 is in W , then P1 is also in W . Note that the inequality
P1 ≤ P2 holds componentwise, i.e., every component in P1 is
not greater than the corresponding component in P2.
With the collection of configuration vectorsW , the capacity
region of the network, denoted by Γ, is known to be the convex
hull of all the configuration vectors in W , namely,
Γ = {r = (r1, r2, . . . , rL)|∃ {φk}Kk=1 and
{Pk}Kk=1 ⊂W such that φk ≥ 0, ∀1 ≤ k ≤ K,
K∑
k=1
φk = 1 and r ≤
K∑
k=1
φkPk}. (2)
Clearly, if
∑K
k=1 φk ≤ 1 for a set of nonnegative numbers
{φk}Kk=1, then
∑K
k=1 φkPk is in capacity region Γ. The set
of nonnegative numbers {φk}Kk=1 are called the weights with
respect to the configuration vectors {Pk}Kk=1.
C. Routing Vectors and admissible traffic
In this paper, we only consider a fixed route for each
multicast flow. For this, we define the L-vector R(j) =
[R
(j)
1 , R
(j)
2 , . . . , R
(j)
L ] as the routing vector for flow j, where
R
(j)
ℓ = 1 if the j
th flow traverses link ℓ and R(j)ℓ = 0
otherwise. Moreover, the set Fℓ is used to denote all the flows
traversing link ℓ, namely,
Fℓ = {j|R(j)ℓ = 1, 1 ≤ j ≤ J}, (3)
for all 1 ≤ ℓ ≤ L. For example, assume that there are two
traffic flows in Figure 1. The first flow traverses through links
6, 2, 4 and 5 sequentially, and the second flow traverses
through links 8, 1, and 4 sequentially. Thus, the routing
vectors for the first and second flows in Figure 1 can be
represented as R(1) = (0, 1, 0, 1, 1, 1, 0, 0, 0) and R(2) =
(1, 0, 0, 1, 0, 0, 0, 1, 0), respectively. Also, according to (3), we
have that F1 = {2} and F4 = {1, 2}.
Let λ(j) be the average number of flow j packets that arrive
at the network in a time slot. For the ease of our presentation,
we simply call λ(j) the arrival rate of flow j. With the routing
vector for every flow in the network, we can then compute the
average number of packets that need to go through a particular
link in a time slot. Specifically, we have
Λ = (λ1, λ2, . . . , λL) =
J∑
j=1
λ(j)R(j), (4)
where λℓ, ℓ = 1, 2, . . . , L, is the average number of packets
that need to go through link ℓ in a time slot. The vector Λ is
called the arrival rate vector in this paper. In the following,
we define the traffic intensity and admissible traffic.
Definition 1 (Intensity and admissible traffic) The intensity
ρ = ||Λ|| of Λ is defined as
||Λ|| = inf
ρ′
{ρ′ =
K∑
k=1
φk|∃ weights {φk}Kk=1 and
{Pk}Kk=1 ⊂W such that Λ ≤
K∑
k=1
φkPk ∈ Γ}. (5)
The input traffic is said to be admissible if ρ < 1.
If the input traffic is admissible, one can always find a set of
weights {φk}Kk=1 and a set of configuration vectors {Pk}Kk=1
such that
∑K
k=1 φk = 1 and Λ <
∑K
k=1 φkPk. In view of
this, a simple time sharing policy that schedules configuration
vector Pk proportional to the weight φk guarantees that the
arrival rate at each link is strictly smaller than the service rate
of that link. If, furthermore, each flow is stationary and ergodic
with a known rate, then there are many scheduling polices in
the literature that can be used for stabilizing each queue in
the network (see e.g., the rate proportional processor sharing
(RPPS) scheme in [10] and the service curve earliest deadline
first (SCED) scheme in [11]). However, if the arrival rates are
not known, then most packet scheduling polices that stabilize
any admissible traffic in the capacity region are related to
the maximum weighted matching (MWM) algorithm in [13],
where the most suitable configuration vector is identified in
every time slot. In the next section, we will extend the dynamic
frame sizing algorithm for switches and wired networks in [3],
[8] to the mathematical model for wireless networks described
in this paper.
III. DYNAMIC FRAME SIZING ALGORITHM
In [3], [8], the dynamic frame sizing (DFS) algorithm has
been used for stabilizing queues in switches and wired net-
works without knowing the arrival rates. In the DFS algorithm,
time is partitioned into frames, where the frame size is not
fixed and is determined at the beginning of each frame. The
main idea of the DFS algorithm is to determine the minimum
frame size at the beginning of a frame so that the backlog
observed at the ingress queue of each flow at the beginning of
the frame can be cleared by the end of the frame. To ensure the
number of packets of each flow inside the network is bounded
above by a finite constant, the DFS algorithm then provides
each flow in a frame a guaranteed rate that is proportional to
the backlog observed at the ingress queue at the beginning2347
the total number of tokens that are selected for configuration
vector Pk by time t is at least ⌊φkt⌋ (as the deadline of the
⌊φkt⌋th token for configuration vector Pk is ⌈⌊φkt⌋/φk⌉ ≤ t).
This then implies that the total number of packets that link ℓ
can transmit by time t is at least
∑
k∈Sℓ⌊φkt⌋. Let
T = max
1≤ℓ≤L
⌈
yℓ(n) + |Sℓ|
ψℓ
⌉
.
Then, the total number of packets sent out from link ℓ in the
duration [0, T ] is at least∑
k∈Sℓ
⌊φkT ⌋ ≥
∑
k∈Sℓ
(φkT − 1)
≥
∑
k∈Sℓ
φk(
yℓ(n) + |Sℓ|
ψℓ
)− |Sℓ| = yℓ(n) (11)
for all 1 ≤ ℓ ≤ L. Thus, by time T , the backlog in every link
is cleared by using the smooth schedule. Clearly, we have
T ≤ max
1≤ℓ≤L
[yℓ(n) + |Sℓ|
ψℓ
]
+ 1,
and the upper bound also holds for this case.
B. A hierarchical smooth schedule
In this section, we propose a hierarchical smooth schedule
that is able to provide guaranteed rate services in our mathe-
matical model for wireless networks. There are two levels of
this schedule: (i) the upper level for configuration vectors and
(ii) the lower level for flows in each link.
(S2) The smooth schedule for configuration vectors:
Suppose the next frame size Tn is determined in the mini-
mization problem in (8) with the set of configuration vectors
{Pk}Kk=1 and the set {mk}Kk=1 (the index n is omitted here
for clarity). During the nth frame, run the smooth schedule
with weights mk/Tn. As Tn =
∑K
k=1mk in the minimization
problem in (8), the sum of the weights is 1 in this smooth
schedule, i.e.,
∑K
k=1mk/Tn = 1. Specifically, the i
th token
of the configuration vector Pk is assigned with the eligible
time τn + 1+ ⌊(i− 1)Tn/mk⌋ and deadline τn + ⌈iTn/mk⌉,
1 ≤ i ≤ mk, 1 ≤ k ≤ K. Then, for each time slot t in
the interval [τn + 1, τn + Tn], the smooth schedule selects
the eligible token with the earliest deadline, and assigns the
corresponding configuration vector at time t. At the beginning
of the nth frame, the schedule for all the configuration vectors
in [τn + 1, τn + Tn] is computed and then transmitted to all
the links in the network.
(S3) The smooth schedule for flows in each link:
Since {mk}Kk=1 and {Pk}Kk=1 achieve the minimization
problem in (8), we have that
K∑
k=1
mkPk = Y (n). (12)
Similar to (9), let Sℓ be the set of the configuration vectors
in {Pk}Kk=1 containing link ℓ within the nth frame. Thus, we
have from (12) and (6) that∑
k∈Sℓ
mk = yℓ(n) =
∑
j∈Fℓ
x(j)(τn), (13)
where Fℓ, 1 ≤ ℓ ≤ L, is the set of all traffic flows traversing
link ℓ as defined in (3). We now say that a link is allowed to
transmit a packet or simply allowable at time t if a configu-
ration vector containing the link is selected at that time slot.
Then, according to (13), there are totally yℓ(n) allowable time
slots for link ℓ in the nth frame. For these yℓ(n) allowable time
slots, we denote Hℓ(i) as the ith allowable time slot for link ℓ
in this frame. The lower level schedule for link ℓ now generates
x(j)(τn) tokens for each flow j in Fℓ within the nth frame.
Then, in the nth frame, the ith token of flow j is assigned
with the eligible time Hℓ
(
1 +
⌊
(i− 1)yℓ(n)/x(j)(τn)
⌋)
and
the deadline Hℓ
(⌈
i · yℓ(n)/x(j)(τn)
⌉)
. When the link ℓ is
allowed to transmit one packet, namely, the upper schedule
for configuration vectors selects some Pk that contains link ℓ,
the lower level schedule for link ℓ selects the eligible token
that has the earliest deadline among all the flows in Fℓ and
removes that token. Suppose the selected token is for flow
j, then queue q(j)ℓ is allowed to send a packet in that time
slot. In other words, the lower level schedule is also a smooth
schedule for the traffic flows traversing link ℓ with the weights
{x(j)(τn)/yℓ(n)}j∈Fℓ on all the yℓ(n) allowable time slots for
link ℓ. Note from (13) that the sum of the weights is also 1,
i.e.,
∑
j∈Fℓ x
(j)(τn)/yℓ(n) = 1.
As both the sums of the weights in (S2) and (S3) are 1, the
following lemma is a direct consequence of the well-known
result for a smooth schedule (see e.g., Lemma 3.1 in [8]).
Lemma 3 Under the hierarchical smooth schedule described
in (S2) and (S3),
(i) each token in the smooth schedule for the configuration
vectors is selected not later than its deadline, and
(ii) each token in the smooth schedule for flows in each link
is also selected not later than its deadline.
In the following lemma, we derive an upper bound and a
lower bound on the total number of tokens selected during
an interval for a particular flow by a link traversed by that
flow. These bounds will be used to bound the total number of
packets in an internal buffer for each flow in Theorem 5. The
proof of Lemma 4 is given in Appendix A.
Lemma 4 Let C(j)ℓ (t) be the cumulative number of tokens
selected for flow j by link ℓ by time t. Suppose s is a time
slot in the n1th frame and t > s is another time slot in the
n2
th frame. Then, for each link ℓ traversed by flow j, the
total number of tokens selected for flow j by link ℓ in the time
interval [s + 1, t], i.e., C(j)ℓ (t) − C(j)ℓ (s), have the following
upper and lower bounds:
E(j)(s, t)− 2(Smax + 1) ≤ C(j)ℓ (t)− C(j)ℓ (s)
≤ E(j)(s, t) + 2(Smax + 1), (14)2349
As a results, the expectation of the frame size E[Tn] is bounded
by max
(
2 logL+2δθ∗
θ∗(1−ρ)
)
.
As a direct consequence of Theorem 6, the expected number
of packets in each ingress queue is also finite. In conjunction
with the bound for an internal queue in Theorem 5, the
DFS algorithm stabilizes the network for the Bernoulli traffic
described in (A1)–(A3).
Proof.
Let φ˜k = φk/ρ. It then follows from (23) that
K∑
k=1
φ˜k = 1. (27)
Moreover, we have from (24) that
ψℓ =
∑
k∈Sℓ
φ˜k =
∑
k∈Sℓ
φk
ρ
≥ λℓ
ρ
> 0. (28)
Thus, the condition in Lemma 2 is satisfied (with the set
of weights {φ˜k}Kk=1 and the set of configuration vectors
{Pk}Kk=1) and we have from (10) that
Tn+1 ≤ max
1≤ℓ≤L
[yℓ(n+ 1) + |Sℓ|
ψℓ
]
+ 1. (29)
For θ > 0, we have that
eθTn+1 ≤ max
1≤ℓ≤L
exp
[
θ
(
yℓ(n+ 1) + |Sℓ|
ψℓ
+ 1
)]
≤
∑
1≤ℓ≤L
exp
[
θ
(
yℓ(n+ 1) + |Sℓ|
ψℓ
+ 1
)]
.
According to (6) and (13), the workload yℓ(n+ 1) for link ℓ
can be represented by
yℓ(n+ 1) =
∑
j∈Fℓ
x(j)(τn+1) =
∑
j∈Fℓ
τn+1∑
t=τn+1
a(j)(t), (30)
where a(j)(t) is the external arrival packets for flow j at
time t and Fℓ is the set that contains all the traffic flows
traversing link ℓ as described in (3). Since we assume that
the arrival processes are independent Bernoulli processes in
(A1) and {a(j)(t)}∞t=1 are i.i.d Bernoulli random variables
with parameter λ(j) in (A2), it then follows that
E[eθTn+1 |Tn] ≤
∑
1≤ℓ≤L
eθ(1+|Sℓ|/ψℓ)
{
E
[
exp
(
θ
∑
j∈Fℓ a
(j)(1)
ψℓ
)]}Tn
. (31)
Notice that
logE
[
exp
(
θ
∑
j∈Fℓ a
(j)(1)
ψℓ
)]
=
∑
j∈Fℓ
logE
[
exp
(
θa(j)(1)
ψℓ
)]
=
∑
j∈Fℓ
log
(
λ(j)eθ/ψℓ + 1− λ(j)
)
≤
∑
j∈Fℓ
λ(j)(eθ/ψℓ − 1)
= λℓ(e
θ/ψℓ − 1)
≤ ρψℓ(eθ/ψℓ − 1), (32)
where we use log(1+ x) ≤ x for x > 0 in the first inequality
and (28) in the last inequality.
Hence, we have that
E
[
eθTn+1 |Tn
] ≤ eθδ ∑
1≤ℓ≤L
exp
[
ρTnψℓ(e
θ/ψℓ − 1)
]
. (33)
For fixed θ > 0, according to Taylor’s expansion, we have that
ψℓ(e
θ/ψℓ − 1) = ψℓ
[ ∞∑
k=0
1
k!
(
θ
ψℓ
)k
− 1
]
= ψℓ
(
θ
ψℓ
+
1
2!
θ2
ψ2ℓ
+
1
3!
θ3
ψ3ℓ
· · ·
)
= θ +
∞∑
k=1
θk+1
(k + 1)!ψkℓ
, (34)
which decreases monotonically as ψℓ increases. As such,
ψℓ(e
θ/ψℓ − 1) ≤ ψmin(eθ/ψmin − 1) (35)
for all 1 ≤ ℓ ≤ L. From (33) and (35), we have that
E
[
eθTn+1 |Tn
] ≤ eθδL exp(ρTnψmin(eθ/ψmin − 1)) . (36)
Taking expectation on both sides of (36) yields
E[eθTn+1 ] ≤ eθδLE
[
exp(ρTnψmin(e
θ/ψmin − 1))
]
. (37)
According to (26), we have that
ρψmin(e
θ∗/ψmin − 1) = θ∗(ρ+ 1)/2,
and (37) can be rewritten (with θ being replaced by θ∗) as
E[eθ
∗Tn+1 ] ≤ eθ∗δLE[eθ∗Tn(1+ρ)/2]. (38)
Since logE[eθTn ] is convex in θ (see e.g., [1, Proposition
7.1.8]) and ρ < 1, we have that
logE[eθ
∗Tn(1+ρ)/2] ≤ 1 + ρ
2
logE[eθ
∗Tn ]. (39)
Using (39) and (38) yields
logE[eθ
∗Tn+1 ] ≤ logL+ δθ∗ + 1 + ρ
2
logE[eθ
∗Tn ]. (40)
Since T1 = 1 (as the network is started from an empty system),
one can verify (25) from induction by using (40). Finally, we2351
≤
x
(j)(τn)
yℓ(n)
∑
k∈Sℓ(n)
⌈
t− τn
Tn
mk(n)
⌉ (45)
for each time slot t in the nth frame, namely, τn + 1 ≤ t ≤
τn + Tn.
Now suppose s is a time slot in the n1th frame and t > s
is another time slot in the n2th frame. Using (45) yields
C
(j)
ℓ (t)− C(j)ℓ (s)
≥
n2−1∑
n′=n1
x(j)(τn′)
+
x(j)(τn2)
yℓ(n2)
∑
k∈Sℓ(n2)
⌊
t− τn2
Tn2
mk(n2)
⌋
−
x
(j)(τn1)
yℓ(n1)
∑
k∈Sℓ(n1)
⌈
s− τn1
Tn1
mk(n1)
⌉
≥
n2−1∑
n′=n1
x(j)(τn′)
+
x(j)(τn2)
yℓ(n2)
∑
k∈Sℓ(n2)
⌊
t− τn1
Tn2
mk(n2)
⌋
−x
(j)(τn1)
yℓ(n1)
∑
k∈Sℓ(n1)
⌈
s− τn1
Tn1
mk(n1)
⌉
− 2
≥
n2−1∑
n′=n1
x(j)(τn′)
+
x(j)(τn2)
yℓ(n2)
 t− τn1
Tn2
∑
k∈Sℓ(n2)
mk(n2)− |Sℓ(n2)|

−x
(j)(τn1)
yℓ(n1)
s− τn1
Tn1
∑
k∈Sℓ(n1)
mk(n1) + |Sℓ(n1)|
− 2
=
n2−1∑
n′=n1
x(j)(τn′)
+
(
x(j)(τn2)
t− τn2
Tn2
− x(j)(τn1)
s− τn1
Tn1
)
−x
(j)(τn2)
yℓ(n2)
|Sℓ(n2)| − x
(j)(τn1)
yℓ(n1)
|Sℓ(n1)| − 2, (46)
where we use (13) in the last equality. Notice from (16) that
Sℓ(n) ≤ Smax for each frame n. Then, it follows from (46)
that
C
(j)
ℓ (t)− C(j)ℓ (s) ≥
n2−1∑
n′=n1
x(j)(τn′)
+
(
x(j)(τn2)
t− τn2
Tn2
− x(j)(τn1)
s− τn1
Tn1
)
−2(Smax + 1). (47)
Also, from (45), we have that
C
(j)
ℓ (t)− C(j)ℓ (s) ≤
n2−1∑
n′=n1
x(j)(τn′)
+
x
(j)(τn2)
yℓ(n2)
∑
k∈Sℓ(n2)
⌈
t− τn1
Tn2
mk(n2)
⌉
−
x(j)(τn1)
yℓ(n1)
∑
k∈Sℓ(n1)
⌊
s− τn1
Tn1
mk(n1)
⌋ . (48)
By following a similar procedure, one can verify that
C
(j)
ℓ (t)− C(j)ℓ (s) ≤
n2−1∑
n′=n1
x(j)(τn′)
+
(
x(j)(τn2)
t− τn2
Tn2
− x(j)(τn1)
s− τn1
Tn1
)
+2(Smax + 1). (49)
Thus, (14) follows from (47) and (49).
REFERENCES
[1] C. S. Chang, Performance Guarantees in Communication Networks,
London: Springer-Verlag, 2000.
[2] D. B. West, Introduction to Graph Theory, 2nd ed., Prentice-Hall, Inc.,
2001.
[3] C. -S. Chang, Y. -H. Hsu, J. Cheng, and D. -S. Lee, “A Dynamic
Frame Sizing Algorithm for CICQ Switches with 100% Throughput,
” Proceedings of IEEE INFOCOM 2009.
[4] P. Chaporkar and S. Sarkar, “Stable scheduling policies for maximizing
throughput in generalized constrained queueing networks, ” Proceedings
of IEEE INFOCOM 2006.
[5] P. Giaccone, E. Leonardi, and D. Shah, “Throughput region of finite-
buffered networks, ” IEEE Transaction on parallel and distributed
systems, vol. 18, no. 2, Feb. 2007.
[6] S.-M. He, S.-T. Sun, H.-T. Guan, Q. Zheng, Y.-J. Zhao, and W.Gao,
“On guaranteed smooth switching for buffered crossbar switches,”
IEEE/ACM Transactions on Networking, vol. 16, no. 3, pp. 718-731,
June 2008.
[7] L. B. Le, E. Modiano, and N. B. Shroff, “Optimal Control of Wireless
Networks with Finite Buffers, ” Proceedings of IEEE INFOCOM 2010.
[8] C. M. Lien and C. S. Chang, “Generalized Dynamic Frame Sizing Al-
gorithm for Finite-Internal-Buffered Networks, ” IEEE Communication
Letters, vol. 13, no. 9, Sep. 2009.
[9] M. A. Marsan, A. Bianco, P. Giaccone, E. Leonardi, and F. Neri, “Multi-
cast traffic in input-queued switches: optimal scheduling and maximum
throughput, ” IEEE/ACM Transactions on Networking, vol. 11, no. 3,
June 2003.
[10] A. K. Parekh and R. G. Gallager, “A generalized processor sharing
approach to flow control in integrated service networks: the multiple
node case,” IEEE/ACM Transactions on Networking, vol. 2, pp. 137-
150, 1994.
[11] H. Sariowan, R.L. Cruz and G.C. Polyzos, “Scheduling for Quality of
Service Guarantees via Service Curves,” Proceedings of the Interna-
tional Conference on Computer Communications and Networks, 1995.
[12] G. Sharma, R. R. Mazumdar, and N. B. Shroff, “On the complexity of
scheduling in wireless networks, ” MobiCom 2006, Sep. 2006.
[13] L. Tassiulas and A. Ephremides, “Stability properties of constrained
queueing systems and scheduling policies for maximum throughput in
multihop radio networks,” IEEE Transactions on Automatic Control, vol.
31, no. 12, pp. 1936–1948, 19922353
97 年度專題研究計畫研究成果彙整表 
計畫主持人：張正尚 計畫編號：97-2221-E-007-104-MY3 
計畫名稱：高速封包交換機之研究--子計畫一:封包交換機架構之數學理論 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
