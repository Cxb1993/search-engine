 2
porpoise whistles and ice crackles, etc. Each 
type of signals has its own characteristics, 
and conventionally was identified by human 
experts either by listening to or by looking at 
the spectrograms of the proposed sonar 
signals. The works [1] on the models of the 
underwater signals radiated by ships has lead 
to the conclusion that the signal sources can 
be divided under three captions: machinery 
signals, propeller signals, and hydrodynamic 
signals. Machinery signals are produced by 
the diverse parts of a moving ship, such as 
pumps, pipes, and motor armature, etc. 
Propeller signals create tonal components in 
addition to the continuous spectrum of 
cavitation signals. Hydrodynamic signals 
consist of Gaussian signal generated by the 
hull of the vessel and flow signals which are 
very similar to the ambient signals in the 
ocean. Hence, the spectrum of a radiated 
signal consists of two types. One is narrow 
band has a discontinuous spectrum containing 
line components occurring at discrete 
frequencies. The other is board band which 
has a continuous spectrum. The radiated 
signals of ships consist of a mixture of these 
two types of signals. So the tonal are 
important features for ship, the extracting 
tonal features from mixed spectra effectively 
is a key task. 
Various scheme signal processing [2-10] have 
been applied to extract signatures of 
submerged targets from narrow band sonar 
data mainly for detection purposes. The 
Fourier transform is used to analysis and 
detect the sound signals in many various 
methods. Although this transform is 
extremely useful and well established, it does 
have drawbacks—principally difficulties in 
analyzing short-term transient sound behavior. 
Various short-time Fourier transforms 
(STFT), using a variety of “windows” with 
different relative advantages, have been 
developed to address this problem [2]. In 
addition, alternatives to the STFT with better 
time-frequency localization have been 
suggested; Cohen [3] devised a time 
frequency distribution composed of 
spectrums at different time intervals has been 
studied as the characterization using the 
Wigner-Ville distribution [4] and its variants. 
Such distributions describe the energy or 
intensity of a signal simultaneously in time 
and frequency, and also a powerful tool for 
the analysis of non-stationary signals. These 
various time-frequency approaches have been 
extensively reviewed [5-6]. Some of the 
potential use the wavelet transform for 
statistical problems have been discussed and 
developed in the [7-8]. They have 
demonstrated the appropriate threshold on the 
coefficients resulting from the wavelet 
decomposition, a function of unknown 
smoothness can be recovered from sampled 
data contaminated with white noise. 
Subsequently, their ideas have been used by 
various researchers to uncover useful 
structural information from complex noisy 
datasets. Such threshold techniques are 
essentially concerned with the recovery of 
“smooth” features against a background 
which is often assumed to be “white” or 
“colored” noise. The approach [9] has some 
similarities to methods that have been applied 
to data from an entirely different arena for 
different purpose. These authors used the 
wavelet transform and then applied kernel 
smoothing to the coefficient in each 
resolution level to produce useful analyses of 
dataset. In addition, Johnstone and Silverman 
[10] have developed a “level-dependent” 
threshold approach for data with correlated 
noise. 
To recognize passive tonal signals radiated by 
ships at various speeds that propagated 
through an ocean environment that a crucial 
processing stage. Traditionally, basis 
decomposition techniques such as Fourier 
decomposition or Wavelet decomposition are 
selected to analyze real word signals as 
mentioned in the former paragraph. Also, 
Fourier and Wavelet descriptors have long 
been used as powerful tools for feature 
extraction. However, the main drawback of 
those approaches is that the basis functions 
are fixed, and do not necessarily match 
varying nature of signals. The empirical mode 
decomposition (EMD) was firstly proposed 
by Huang et al. [11], with which any 
complicated data set can be decomposed into 
a finite and often small number of intrinsic 
mode function (IMF) components, which 
become the basis representing the data. Those 
 4
1) Initialization: Set 0r X=  (the residual) 
and set 1i =  (index number of IMF). 
2) Extracting the thi  IMF component: 
(a) Initialize 0 1, 1ih r j−= = . 
(b) Find all the points of local maxima, and 
all the points of local minima in 1jh − .  
(c) From the input signal 1jh − , create the 
upper envelope of local maxima, denoted by 
1max j− , and the lower envelope of local 
minima, denoted by 1min j− , by interpolation. 
(d) Calculate the mean of the upper and the 
lower envelopes by 
    1 1 1(max min ) 2i i im − − −= +           (2) 
(e) Update: 1 1j j jh h m− −= −  and 1j j= + ,  
(f) Calculate stopping criterion (standard 
deviation SDij ) 
(g) Repeat step (b) to (f) until MAXSD SDij ≤  
and then set i js h=  ( thi  IMF) 
3) Update the residual 1i i ir r s−= − , 
4) Repeat steps 2) to 4) with 1i i= +  until 
the number of extrema in ir  is less than 2. 
Note that the interpolation method usually 
used is the cubic spline interpolation [11, 13].   
3.2 Finding all the IMFs 
Once the first set of ‘sifting’ results in an IMF, 
defined by 1 1 jd h= , is obtained, this first 
component contains the finest spatial scale in 
the signal. Then the residue, 1r , of the signal 
can be generated by subtracting out 1d , 
1 1r z d= − . The residue now contains 
information about large scales. The other 
IMFs can be computed by performing the 
resifting to find additional components 
2 1 2r r d= − , …, 1n n nr r d−= − . The original 
signal can then be reconstructed, using the 
following equation 
1
( )
n
i n
i
z c r
=
= +∑ .                   (3) 
To stop the sifting process, a criterion needs 
to be determined. This can be accomplished 
by limiting the standard deviation (SD), 
computed from two consecutive sifting 
results given by 
2
( 1)2
2
1 ( 1)
( ) ( )
SD
( )
K
i j ij
ij
k i j
h k h k
h k
−
= −
⎡ ⎤−⎢ ⎥= ⎢ ⎥⎣ ⎦
∑        (4) 
the MAXSD  is usually set between 0.2 and 
0.3. Figure 4 shows a simulated example of 
an iteration of sifting process by EMD 
decomposition, where the analyzed signal 
(Fig. 4(c)) is composed of two sinusoidal 
waves with two frequencies. Low frequency 
is shown in Fig. 4(a) and high frequency is 
shown in Fig. 4(b). Figure 4(d) displays the 
lower envelope and Fig. 4(e) shows the upper 
envelope. The mean envelope is demonstrated 
in Fig. 4(f) which is computed from Equation 
(4). Finally, the first IMF is obtained and 
shown in Fig. 4(g) and the first residual is 
shown in Fig. 4(h). 
From the Figure 4, the EMD algorithm 
extracts the oscillatory mode that exhibits the 
highest local information from the data 
(“detail” in the wavelet context), leaving the 
remainder as a “residual” (“approximation” in 
wavelet analysis). According to the major 
advantage of EMD that the process of 
deriving the basis functions is empirical, the 
basis functions are derived dynamically from 
the signal itself. As shown in Fig. 4, the EMD 
approach is used to denoise the noisy acoustic 
backscattered signal and greatly improve the 
SNR. Therefore, it is reasonable to consider 
that the residual presents the basic 
characteristics of the iris and the detail 
denotes the variation of the noise represented 
by the highest local information. That is, we 
use the EMD as a low-pass filter and only the 
distinct iris characteristics (the residual of 
EMD) are utilized as discriminating features 
for accurate signal recognition.  
3.3 Feature Vector 
For the normalized acoustic signal, the 
sequences are formed to the 1-D vector V  
represented by 
1 2{ , , , , }j nV v v v v= L L              (5) 
where jv  defines the position of the vector 
V , and n  is the number of total components, 
herein, 40000n = . Features from the EMD 
 6
marked in Fig. 7(e) and 7(f). Also, those 
circles marked in Fig. 8(e) and 8(f) point out 
the differences of two samples from two 
classes. 
Furthermore, we use the data to test the 
result of recognition. Figure 9 shows the 
recognition results of the first residual as 
feature, Figure 10 displays the recognition 
results of the second residual as feature, and 
Figure 11 also demonstrates the results of 
the third residual as feature using three 
similarity measures from (7)-(9). As shown 
in Fig. 9, Fig. 10, and Fig. 11, the same class 
demonstrates the highest peak, and the 
different class shows the lowest values. 
However, in the Figure 11, the third residual 
as the feature using the MED metric is not 
easy to recognition. Hence, the MED metric 
is not suitable for the feature of the EMD. 
The other metrics demonstrate the good 
performance in the results of recognition.  
6. Conclusions 
In this paper, a novel and effective method 
for acoustic signal recognition is presented, 
which operates using the Empirical Mode 
Decomposition (EMD) technique. The 
performance of iris recognition achieved by 
the EMD approach associated with three 
different similarity measures has been 
evaluated. Experimental results have shown 
eminent performance. The cosine similarity 
measure and the correlation metric have 
achieved similar performance. Therefore, the 
proposed method has demonstrated to be 
promising for acoustic signal recognition and 
EMD is suitable for feature extraction. In the 
future, we will compare the more intra-class 
and inter-class comparison to evalute the 
proposed algorithm. We are also working at 
increasing the database in order to further 
verify the performance. 
References 
[1] Urick, R. J., “Principles of Underwater 
Sound,” McGraw-Hill,1983.  
[2] DeBilly M., “Determination of the 
resonance spectrum of elastic bodies via the use 
of short pulses and Fourier transform theory,” J. 
Acoust. Soc. Amer., vol. 79, no. 2, pp.219-221, 
Feb, 1986. 
[3] Cohen, L., “Time-frequency distribution—a 
review,” Proc. IEEE, vol. 77, no. 7, pp.941-981, 
July, 1989. 
[4] Rao, P., and Taylor, F. J., “Detection and 
localization of narrow-band transient signals 
using the Wigner distribution,” J. Acoust. Soc. 
Amer., vol. 90, pp. 1423-1434, 1991. 
[5] Boashash, B., and O’Shea, P., “A 
methodology for detection and classification of 
some underwater acoustic signals using 
time-frequency analysis techniques,” IEEE 
Transactions on Acoustics, Speech, and Signal 
Processing, vol. 38, pp. 1829-1841, 1990.  
[6] Jones, D. L., and Parks, T. W., “A resolution 
comparison of several time-frequency 
representations,” IEEE Transactions on Signal 
Processing, vol. 40, pp. 413-420, 1992. 
[7] Donoho, D. L., and Johnstone, I. M., “Ideal 
spatial adaption by wavelet shrinkage,” 
Biometrika, vol. 81, pp. 425-455, 1994.  
[8] Donoho, D. L., “Adapting to unknown 
smoothness via wavelet shrinkage,” Journal of 
the American Statistical Association, vol. 90, 
pp.1200-1224, 1995. 
[9] Nason, G. P., and Silverman, B. W., “The 
discrete wavelet transform in S,” Journal of 
Computational and Graphical Statistics, vol. 3, 
pp. 163-191, 1994. 
[10]  Johnstone, I. M., and Silverman, B. W., 
“Wavelet threshold estimator for data with 
correlated noise,” Journal of the Royal  
Statistical Society, ser. B, vol. 59, pp.319-351, 
1997. 
[11] N. Huang, Z. Shen, S. Long, M. Wu, H. 
Shih, Q. Zheng, N. Yen, C. Tung, and H. Liu, 
“The Empirical Mode Decomposition and Hilbert 
Spectrum for Nonlinear and Non-stationary Time 
Series Analysis,” Proc. of the Royal Society of 
London, Vol. 454, pp. 903–995, 1998. 
[12] C. M. Bishop, Neural Networks for Pattern 
Recognition, Oxford University Press, 1996. 
[13] P. Flandrin, G. Rilling, and P. Goncalves, 
“Empirical Mode Decomposition as a Filter 
Bank”, IEEE Signal Processing Letters, Vol. 
11, No. 2, pp.112-114, Feb., 2004. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 8
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(a) (b)
Fig. 3: the preprocessing results of the different class. (a) The 6th sample of the 3rd 
class. (b) The 3rd sample of the 4th class.  
 
(a) (b) (c)
(d) (e) (f)
(g) (h) (i)
Fig. 4: A simulated example for an iteration of the sifting process by EMD decomposition.
 10
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(a)
(b)
Fig. 6: EMD decomposition results of two samples from the different classes. (a) and
(b) are two sets of 7 times decomposition sequences with their original length.
 12
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(a) (b)
(c) (d)
(e) (f)
Fig. 8: EMD decomposition results of two samples from two classes. (a) and (b) are
two sets of feature sequences with their original length, (c) and (d) show the
first 1024 components from the original features, (e) and (f) show the first 128
components of the original features.
