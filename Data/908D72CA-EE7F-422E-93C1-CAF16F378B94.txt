 1 
(二)中文摘要及關鍵詞。 
本計畫係關於有效地擷取個人化 3D臉部資訊，並利用該資料合成擬真 3D臉部表情動畫的研
究。特別是，利用 Photometric stereo (PSM)的方式，安全並且迅速地擷取密集的 3D臉部資訊，
以重建逼真的個人化臉部模型。該個人化 3D 臉部模型將配合基本的臉部肌肉模型而進行臉
部表情的合成。 
在利用 PSM自動獲取 3D臉部表面的步驟中，本計畫將採用三組光源分別地提供臉部表面的
照明，以計算臉部表面之局部表面方向向量。這些局部表面方向向量將被積分以獲取臉部表
面的 3D座標，因而獲得密集並且逼真的 3D個人化臉部資訊。 
本計畫將採用肌肉作為控制的基本臉部模型以提供有效並且逼真的表情合成。這類的臉部模
型將定義數組肌肉控制群，以在合成表情時決定互相連結之資料點的移動位置。採用 PSM所
獲得的個人化臉部資訊與基本臉部模型結合後，即可產生個人化臉部模型以供表情的合成。
依據本計畫所採用之肌肉控制的臉部模型，基本的臉部表情可利用數組的肌肉控制函數以及
移動的參數作為代表。利用指定參與每種表情的肌肉群組和移動參數，即可合成各種基本以
及複合表情並產生順暢逼真的表情動畫。 
關鍵詞: 三維重建、臉部模型、表情合成、表情動畫 
 
Abstract: 
The project proposal is about the efficient acquisition of personalised 3D face model and the 
synthesis of realistic facial expressions.  In particular, the project uses the photometric stereo 
method for safe, fast and dense 3D reconstruction of the human face, to obtain a realistic and 
detailed personalised 3D face model.  The 3D face model is integrated with a simplified 
anatomical model of the face, which uses basic muscle movements to simulate facial expressions.  
The integrated 3D face model is used to synthesis various basic and composite facial expressions, 
and to generate sequences of expression animations. 
The project uses photometric stereo method with three light sources for 3D face reconstruction.  
Local surface orientations are estimated according to the grey level intensities of the acquired 
surface images.  The surface normals are integrated using a global integration method to obtain the 
relative 3D coordinates. 
The 3D anatomical model of the face used in this project defines several groups of facial muscles to 
determine the movement of surface vertices during expression simulation.  The face model 
obtained by the photometric stereo method is integrated with the anatomical face model by 
specifying corresponding points on both models.  The result is a personalised 3D face model 
which can generate various expressions by specifying movements of the involved muscle groups.  
Furthermore, smooth animation sequences of facial expressions can be produced by varying the 
movements in small increments in each frame. 
During the first year of the project, we have followed the proposed schedule and made good 
progress in the first stage of the proposed project to acquired 3D face models.  The 3D face models 
will be used in the second stage of the project to synthesis and generate realistic looking facial 
expressions. 
 
Keywords: 3D reconstruction, face modeling, expression synthesis, facial animation 
 3 
取資訊所需的操作步驟皆相當地簡易方便，並且不需要昂貴的硬體設備。因此，在於提供逼
真的個人化臉部資訊部份，本計畫之第一目的具有相當顯著的貢獻。 
本計畫之第二目的在於利用第一目的之 3D臉部重組系統所獲取之逼真的個人化 3D臉部模型
合成不同的臉部表情，以產生逼真的個人化臉部動畫。本計畫預計採用以肌肉為控制的 3D
臉部模型來合成不同的臉部表情。 
 
研究方法、結果與討論。 
本計畫係採用 Photometric stereo method (PSM)，一種較為穩定的 Shape from shading(SFS) 由
陰影獲得形狀之重組方法有效地擷取 3D的臉部資訊。 
PSM的優點在於其可以近乎即時的方式達成臉部表面的重組，並且所獲取的表面資訊是相當
豐富並且密集的。此外，PSM採用一般的鎢絲燈泡作為照明，對於臉部重組的應用而言，是
相當安全的。而採用鎢絲燈泡作為照明亦同時可以降低設備成本。 
在利用 PSM自動獲取 3D臉部表面的步驟中，預期採用三組光源以分別地提供臉部表面的照
明。這三組光源以如圖 1 (a)和(b)中所示之方式提供照明，相機被置於三組光源中間，將做臉
部重組的使用者位於相機正前方。背景最好以黑布遮蓋以減少反射光，以避免重組的誤差。
三組光源的方向和強度必須在進行重組步驟之前被計算或被測量。因為在以 PSM方法進行物
體表面的重組時，這三組光源的方向和強度是直接被用來計算局部表面方向向量的參數，如
Eq. 1所展示︰ 
)||||()||||( 31103133012110212201 ssssssssu EEEEEEEE −×−=
 (Eq. 1) 
Eq. 1 是計算與局部表面方向向量 n 平行的向量 u 的方程式。在 Eq. 1 中，E01、E02以及
E03 代表第一、二、三組光源的強度，s1、s2 以及 s3 則是第一、二、三組光源的方向向量， E1、
E2以及 E3 代表分別由第一、二、三組光源提供之照明所獲得之物體表面的影像之亮度。這些
局部表面方向向量將接著被積分以獲取物體之 3D 表面相對座標。以此方式，在影像中代表
物體表面之每一像素的相對 3D座標均可被計算出。因此 PSM所產生的表面資訊密度和數位
相機的解析度成正比。亦即，數位相機的解析度越高，PSM所產生的表面資訊越密集。這些
資訊足以代表臉部的細節特徵，並產生相當逼真的個人化 3D臉部模型以供後續步驟的使用。 
計畫中所架設之系統被使用於三維臉部模型的建立。圖 2展示利用該系統所獲得之資料。 
系統擷取之三張臉部影像經由所撰寫之程式利用 PSM 之方法進行演算以獲得臉部的三維資
訊並建立臉部的三維模型。臉部之三維資訊如圖 3所展示。 
從參考資料中得知，以骨架和肌肉作為控制的系統可以提供有效並且逼真的表情模擬，因此
本計劃預計採用此類的臉部模型作為表情合成的基礎。圖 3-3展示此類臉部模型之一種範例。
圖 4(a) 展示一組 3D臉部模型之資料點分佈以及可以控制的肌肉群組。這些資料點以三角形
的網格被互相連結，如圖 4(b)所展示。在表情合成時，互相連結之資料點的移動位置將取決
於鄰近的肌肉控制群組。圖 3-3 中的 3D 臉部模型範例是由 Gedalia Pasternak 所提供的 THE 
EXPRESSION TOOLKIT - An Open-Source Procedural Facial Animation System所產生[22]。 
 
 5 
 
 
 
本計畫預計在兩年內進行擷取個人化 3D臉部資訊，並利用該資料合成擬真 3D臉部表情動畫
的研究。特別是，利用 Photometric stereo 的方式，安全並且快速地擷取密集的 3D臉部資訊，
以重建逼真的個人化臉部模型。該個人化 3D 臉部模型將配合基本的臉部肌肉模型而進行臉
部表情的合成。 
本計畫之各年度預計的工作項目如下︰ 
第一年︰  
 收集相關文獻以及背景資料 
 設計資料結構 
 建立相關功能之程式庫 
 架設 PSM硬體 
 製作驅動以及操作軟體 
 整合 PSM系統 
 校正光源以及相機 
 測試 PSM系統 
 擷取個人 3D臉部資料並建立資料庫 
   
(a)       (b) 
圖 4: (a) 3D臉部模型之資料點和可控制之肌肉群組 
(b) 3D臉部模型之側視圖以及資料點的連結方式 
 
 
圖 3:利用架設系統所重建之臉部表面模型 
 7 
參考文獻: 
1. Animation Institute , "The Artificial Actors project", http://research.animationsinstitut.de/, 
2003 
2. G. Bailly, G. Gibert, and M. Odisio, "Evaluation of movement generation systems using the 
point-light technique", in IEEE Workshop on Speech Synthesis . Santa Monica, CA, 2002. 
3. V. Blanz and T. Vetter. "A morphable model for the synthesis of 3D faces", In Proc. ACM 
SIGGRAPH 99, pages 187-194, 1999. 
4. T. D. Bui, D. Heylen, and A. Nijholt. "Improvements on a simple muscle-based 3d face for 
realistic facial expressions", In Proc. CASA-2003.  
5. C.-Y. Chen, “Shape from photometric stereo and contours”, Dissertation for Ph.D. degree, 
Department of Computer Science, The University of Auckland, 2004. 
6. C.-Y. Chen, R. Klette and C.-F. Chen, "Shape from Photometric Stereo and Contours", in Proc. 
CAIP 2003, LNCS 2756, pp. 377-384. 
7. C.-Y. Chen, R. Klette and R. Kakarala, "Albedo Recovery Using a Photometric Stereo 
Approach", in Proc. ICPR, 2002, pp. 700-703. 
8. M. M. Cohen, R. L. Walker, and D. W. Massaro, "Perception of Synthetic Visual Speech'', 
Speechreading by Man and Machine: Models, Systems and Applications, NATO Advanced 
Study Institute 940584, (Aug 28-Sep 8, 1995, Chateau de Bonas, France).  
9. M. M. Cohen and D. W. Massaro. "Modeling coarticulation in synthetic visual speech", In N. 
M. Thalmann & D. Thalmann (Eds.) Models and Techniques in Computer Animation. Tokyo: 
Springer-Verlag, 139-156, 1993. 
10. P. Debevec, T. Hawkins, C. Tchou, H.-P. Duiker, W. Sarokin, and M. Sagar. "Acquiring the 
reflectance field of a human face", Computer Graphics (SIGGRAPH), 2000. 
11. S. DiPaola, A. Arya, "iFACE: Interactive Face Animation - Comprehensive Environment", 
http://ivizlab.sfu.ca/research/iface/, iVizLab, 2006. 
12. T. Ezzat and T. Poggio, "Visual speech synthesis by morphing visemes", International Journal 
of Computer Vision, vol.38, no.1, 2000, pp.45-57. 
13. T. Ezzat, T. Poggio, "MikeTalk: A Talking Facial Display Based on Morphing Visemes, IEEE 
Computer Animation '98. 
14. P. Fua, R. Plaenkers, and D. Thalmann. "From synthesis to analysis: Fitting human animation 
models to image data". In Computer Graphics International, Alberta, Canada, June 1999. 
15. B. Guenter, C. Grimm, D. Wood, H. Malvar, F. Pighin, Making faces, in: Proceedings of 
SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, ACM SIGGRAPH / 
Addison Wesley, 1998, pp. 55-66. 
16. Interactive Media Group, "Facial Personality Project (pFACE)", 
http://img.csit.carleton.ca/pface/, 2006. 
17. P. Kalra, A. Magnili, N. Magnenat-Thalmann, and D. Thalmann. "Simulation of facial muscle 
actions based on rational free form deformations", CGF(EUROGRAPHICS '92 Proceedings), 
11(3):C59 C69, 1992.  
18. Y. Lee, D. Terzopoulos, and K. Waters, "Realistic modeling for facial animation", Proc. ACM 
SIGGRAPH 95 Conf., pp. 55-62, 1995.  
