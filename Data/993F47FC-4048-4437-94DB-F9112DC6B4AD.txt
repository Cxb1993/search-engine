a query image. 
The mapping of an image to the corresponding feature 
vector is a process of dimensionality reduction. By finding 
a lower-dimensional representation of an image, an 
effective feature vector is expected to contain vital 
characteristics of the original. The pitfalls associated with 
traditional approaches are two-fold, namely, (1) 
representing features extracted are not powerful enough to 
discriminate between similar and dissimilar images, and (2) 
multiple features extracted from a single image does not 
necessarily match user’s expectation. In this paper, an 
isometric embedded feature extraction method employing 
fractal orthonormal bases is introduced. The features 
extracted from positive and negative example images are 
further combined by a multiple-instance learning paradigm 
to induce feature commonality to query image database. 
In what follows, the proposed isometric embedded 
feature extraction method employing fractal orthonormal 
basis will be introduced first. The conservation of 
Euclidean distance-based similarity measure before and 
after the mapping onto orthonormal basis will be proved. 
Image pairs with long feature distance in the feature 
domain are guaranteed to be dissimilar ones in the image 
domain, while feature points close to each other 
correspond to similar images. Next, the procedure for 
combining multiple features extracted from positive and 
negative example images to derive commonality to forge a 
unified query key will be outlined. This multiple-instance 
learning procedure identifies common positive features and 
excludes negative ones to further clarify the user’s 
searching criteria. The last section shows the effectiveness 
of this novel approach by comparing the retrieval results of 
(1) single-instance and multiple-instance learning by 
applying the same fractal-based feature extraction 
paradigm, and (2) multiple-instance retrieval by employing 
different feature extraction techniques. Due to the 
preservation of distance relationship in both the image and 
feature domains, and the derivation of commonality from 
multiple example images, consistent search results 
matching user’s expectation are obtained. 
II. ISOMETRIC EMBEDDED FRACTAL 
ORTHONORMAL BASES 
Even though similar images generally derive feature 
points close to each other. However, there is no guarantee 
that dissimilar images will map to distant feature points. 
For example, the comparison of color feature usually 
employs certain measure of histogram. Images with similar 
histogram distributions will be regarded as similar under 
this scheme. However, color histogram represents an 
image global feature. With an analogous histogram 
distribution, the color within a dissimilar image might be 
locally distributed in a totally different manner. Using 
color feature as a measure of similarity between images is 
not powerful enough to exclude false-positive cases. 
Moreover, a query image might be rotational, scaling, 
shifted, or noise-corrupted variations of database images. 
A traditional retrieval algorithm might not be sufficiently 
robust to include similar database images of these 
variations, causing the occurrence of false dismissal. 
 
Figure 1 The distance relationship between image points 
and corresponding feature points is not preserved 
through most feature extraction processes. 
Image-feature pair  and  
illustrates the false-negative and false-positive 
cases, respectively. 
}{ 2,2 fi },{ 33 fi
The corresponding feature vectors  of 
images , respectively, are shown in Figure 1. 
The derived feature points in the feature domain might not 
preserve the same spatial distance relationship as their 
counterparts in the image domain. When an image  is 
used for querying a database,  will be included in the 
search result due to the proximity of points  with 
 in the feature space. However, image  will be 
excluded since point  is considered as too distant from 
. A dissimilar image, e.g., image , mistakenly 
classified as similar is called a false-positive, while a 
similar image, e.g., image , incorrectly excluded from 
the final search result is referred to as a false-negative. 
Being unable to provide stable distance measure, most 
systems try to minimize false-negative results at the 
expense of an increased number of false positives. A 
compact, perceptually relevant representation of an image 
content that preserves the distance relationship in terms of 
similarity metric in both image and feature spaces is highly 
desirable.  
qffff ,,, 321
qiiii ,,, 321
qi
31, ii
31 , ff
qf 2i
2f
qf 3i
2i
Barnsley suggested that storing images as collections of 
transformations could lead to image compression [3]. 
Jaquin was among the first to publish a fractal image 
compression scheme by regular partitioning the image [4]. 
Jaquin’s method is based on partitioned iterated function 
systems and affine transform acting locally rather than 
globally. The accurate coding of a range block is 
dependent upon there being a self-similar domain block in 
signature for image I used in the retrieval of image 
database. Since the original image can be reconstructed by 
employing the feature set  with high S/N ratio,  
therefore is a good representation of image I with little 
information loss. The similarity measure between two 
images I, J is determined by comparing a distance metric 
 between  and . Next, we will show that the 
distance metric employing Euclidean measure is isometric 
embedded in both image and feature domains, i.e., the 
proximity of two image points I, J in the image space is 
indicative of corresponding feature points , , and 
vice versa.  
IW IW
IJd IW JW
IW JW
Proposition: The Euclidean distance between images I and 
J in the image domain, and that of the 
corresponding feature vectors  and , 
derived by projecting range blocks of I and J 
onto a set of orthonormal basis vectors, are 
equivalent. 
IW JW
Proof: The Euclidean distance  between images I and 
J can be formulated as 
JId
JId JI −= , 
or expressed in terms of range blocks 
∑
=
−=
RN
i
J
i
I
iJI rrd
1
~~ , where .~,~ J
J
iI
I
i rr RR ∈∈  
Each range block Iir~  and 
J
ir~  of image I and J can 
be further represented as a linear combination of  
orthonormal basis vectors 
rM
]~,,~,~[ 21 rMqqq L=Q , with 
coefficients 
,1,1,~~ , rRJ
J
ijI
I
ij MjNiww LL ==∈∈ WW respectiv
ely. 
∑ ∑
= =
−=
R rN
i
M
j
j
J
ij
I
ijJI qwwd
1 1
~)( . 
∑ ∑
= =
−=
R rN
i
M
j
j
J
ij
I
ij qww
1 1
2/122 )~)(( , 
 Since all basis vectors are orthonormal, i.e., 
.},1{,,0~~,1~2 jiMjiqqq rjij ≠∈∀=⋅= L  
 All cross-product terms are zeros. 
∑ ∑
= =
−=
R rN
p
M
q
J
ij
I
ijJI wwd
1 1
2/12 ))((  
∑ ∑
= =
−=
R rN
i
M
j
J
ij
I
ij ww
1 1
)(  
JIWWd= , 
The above proposition states that the Euclidean distance 
measure remains the same after the projection of points in 
image space into a set of orthonormal basis vectors in the 
feature domain. The image space and the feature space are 
“isometric” to each other. From this, we can conclude that 
the closeness of two image points in the image space, i.e., 
ε≤JId , implies the proximity of the corresponding 
feature points in the feature domain, . The 
above statement is logically equivalent to “if feature 
vectors  and  are distant from each other, then 
image I is also distant from image J.” Since similar images 
are mapped to close feature points and only points close to 
the feature point of a query image will be included in the 
retrieval results, images corresponding to distant features 
points will be excluded. This property suggests that 
false-negative cases are unlikely to occur. Therefore, 
employing the proposed paradigm will not falsely ignore 
any similar images based on the Euclidean metric in the 
feature space. Similar objects will be included in the final 
retrieval set. Another facet of the above proposition reveals 
that the proximity of feature points in feature domain 
indicates the closeness of image points in image space. 
This statement is equivalent to stating that dissimilar image 
points imply that feature points are far apart. Therefore, 
searching in near proximity of the feature point within a 
query image will not return dissimilar images. This 
property ensures that no false-positives occur. Utilizing the 
coefficients of the linear combination of an orthonormal 
basis set as feature vectors will retrieve consistent database 
retrieval result excluding both false-positive and 
false-negative cases. 
ε≤
JIWWd
IW JW
III. MULTIPLE- INSTANCE LEARNING 
Even though the above-mentioned fractal orthonormal 
bases approach can extract isometric preserving features 
contained within an image, yet an image commonly 
contains a plurality of concepts, i.e. feature clusters, 
scattered throughout the image space. For example, several 
foreground objects present in front of a non-uniform 
background are commonly observed in a natural scene. 
Given a single image to query an image database is 
ambiguous in terms of which concept the user intends to be 
included in the query. Take waterfall scene as an example, 
the image might contain concepts such as waterfall itself, 
rocks surrounding the waterfall and the plants growing 
around the waterfall, etc. Most existing Content-Based 
Image Retrieval (CBIR) systems require either global 
information is used or a user must explicitly indicate which 
part of the image is of interest. Given a reliable feature 
extractor, our next goal is to take a small set of positive 
and negative example images, each associated with 
extracted feature clusters the user desired or unwanted. The 
positive concepts are then integrated and the negative ones 
processed independently to determine the fractal 
orthonormal basis in each color plane. The fractal 
orthonormal basis matrixes  and  derived 
are 64-dimensional each. Figure 3 shows the fractal 
orthonormal basis matrixes  derived by 
following the procedures outlined in Section II. The 64 
fractal basis vectors of each color plane are composed of 
uniform, edge or texture regions. The coefficient 
corresponding to the vector 
,, GR QQ BQ
,, GR QQ BQ
1
~q , the orthonormalized 
version of the first a priori vector Tv }1,,1,1{~1 L= , is 
considered as the brightness level of a specific color 
component within an image. 
  
 (a) (b) (c) 
Figure 3 The 64  fractal orthonormal basis vectors of 
(a) R, (b) G, and (c) B color components, 
respectively, derived from an ensemble of 100 
butterfly database images. 
88×
A total of 64 coefficients for each color component are 
derived by projecting a range vector into an orthogonal 
space with 64 dimensions. A color range vector can 
therefore be losslessly reconstructed by employing 192 
linear coefficients. Since the energy is highly concentrated 
in relatively few numbers of axes, most coefficients are 
negligible in the later similarity comparison stage. Only the 
three most significant coefficients per color component are 
employed in later Euclidean distance computation, whereas 
the remaining less significant coefficients are considered as 
zero values. Since all projection coefficients of database 
images are calculated only once and stored as compression 
coefficients, the computation of similarity measure 
involves only the derivation of feature coefficients for the 
query image, subtraction of matching coefficients and 
summation of all squared differences. Therefore, the 
retrieval process with spatial constraint is very efficient.  
Figure 4 demonstrates the power of the proposed fractal 
orthonormal bases. The major features extracted are 
composed of the foreground yellow-white stripes of clown 
fish and the background anemone. If a user expects to 
retrieve relevant clown fish images from database, employ 
this specific image as a query might still retrieve 
undesirable images containing only anemone. Applying 
multiple-instance learning, another positive image with 
clown fish in different background, or negative image with 
the same background can induce the desirable feature 
clusters and retrieve expected results. 
    
 (a)  (b) 
Figure 4 (a) A database image, and (b) major feature 
clusters, composed of foreground yellow-white 
stripes of clown fish and background anemone, 
extracted by utilizing fractal orthonormal bases. 
Single-Instance v.s. Multiple-Instance 
Figure 5(a) is the positive example image used in the 
single-instance test. One more positive image Figure 5 (b) 
and one negative image Figure 5 (c) are added in the 
following multiple-instance test. Figure 5 (d) demonstrates 
the single-instance retrieval result, while Figure 5(e) shows 
the multiple-instance counterpart by employing two 
positive example images and one negative image. 
Comparing Figure 5 (d) and (e) clearly demonstrates that 
multiple-instance learning induces the common 
characteristics of while and yellow stripes existing in two 
clownfish images, while excluding the dark texture 
background in the negative image. A more satisfactory 
result is reached for the multiple-instance case. 
     
 (a) (b) (c) 
 
(d) 
 
(e) 
Figure 5 (a) Positive image 1, (b) positive image 2, (c) 
negative image, (d) single-instance retrieval result 
by using (a) as a query, and (e) multiple-instance 
retrieval result using two positive images (a), (b) 
and one negative image (c). 
In order to further demonstrate that feature commonality 
can be further consolidated by adding more example 
images, a third positive image, as shown in Figure 6 (a), is 
included in the multiple-instance query, in addition to the 
original two positive images and one negative image. The 
result in Figure 6 (b) shows even more improvement over 
that obtained in Figure 5 (e). 
