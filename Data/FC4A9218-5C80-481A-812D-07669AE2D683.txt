 2
應用於遠距教學之 IP-based 智慧型協同作業技術研究--用於提升多媒體後處理品質之
多媒體檢索特徵研究 
IP-based Intelligent Collaboration Research Applied in Tele-Education-- The research of multimedia indexing 
feature for quality improvement in the post-processing 
計畫編號：NSC 98-2221-E-155-044- 
執行期限：98 年 8 月 1 日 至 99 年 7 月 31 日 
主持人：鄭伯順    元智大學通訊工程學系 
 
中文摘要 
本計畫其宗旨在於提供一網路協同作業環
境之智慧型運算的即時處理，以解決現今網路協
同作業環境所缺乏的智慧型互動機制；特別是在
以遠距教學(Tele-Education)為應用之環境下，透
過遠端上課學生情形之影像，使用嘴唇移動偵測
(Lip Motion Detection)、條件式隨機域模型(CRF, 
Conditional Random Field)物件追蹤、及非參數式
序列變點偵測演算法 (Sequential Change Point 
Detection Algorithm)，找出高雜訊多媒體視訊與語
音，進行多媒體標記(labeling)，並在後處理階段
以原始多媒體視訊與語音取代之，藉以提昇多媒
體紀錄品質；本計畫除了可以判斷遠端學生是否
開口外，以輔助語者辨識，並可提供資料存檔備
查後處理的索引特徵，以達到遠距教學之智慧型
感知運算的能力。 
 
關鍵詞：遠距教學、協同作業技術、嘴唇移
動偵測、條件式隨機域模型、物件追蹤、變點偵
測 
 
Abstract 
The goal of this project is to enhance real-time 
intelligent computation capabilities in current 
collaboration technologies. Aimed especially at 
tele-education applications, the proposed method 
first uses lip motion detection to identify a lip region 
in the image of a student’s face in the classroom. 
Then, an object tracking method based on 
conditional random fields (CRF) is used to track the 
lip region to help to locate the lip region in the 
student face video. Finally, a non-parametric 
sequential change-point detection algorithm is 
employed to label the video sequence to indicate 
when the student’s mouth is open and when it is 
closed. The results of the project can not only help 
to identify the speaker, but also provide the indexing 
features. Accordingly, the quality of tele-education 
can be improved. 
 
Keywords: Tele-Education, collaboration 
technology, Lip Motion Detection, Conditional 
Random Field, Change Point Detection 
 
一. 前言與目的 
近年來，遠距教學已經成功地被應用在許多
地方，其中有許多的改進，但其仍存在著許多缺
點，尤以上課記錄功能的缺乏為甚。傳統上，遠
距教學大多透過攝影機與麥克風擷取視訊與音訊
後，透過網路傳送到另一端進行處理與播放，並
只能透過簡易的錄影或錄音設備，紀錄其中的內
容；此外，新型態的遠距教學系統雖加入了視訊
會議系統與協同作業的概念，卻仍缺乏事後可追
查的文件紀錄和多媒體資料存檔備查功能。因
此，當師生回顧課程已進行課後輔導或是校方進
行課程資料整理時，僅能透過固定的攝影機影像
檔或一連串的混合語音錄音檔了解上課內容，除
了容易遺漏課堂重要資訊，更無法詳細記錄師生
之間的互動情形。 
本計畫「用於提升多媒體後處理品質之多媒
1 2 1 2=( , ,...; , )    
 
N
i=1
( )= log 
。反覆的使用最大對數相似演算
法可以得到：
~
x,y
( | ) ( , ) log ( | )i ip y x p x y p y x   
        (3) 
 發言行為判別 
經由唇形物件的追蹤，系統可以觀測學生唇
形的變動，當學生嘴唇變動變劇烈時，則可能為
正要發言；因此，透過觀察唇形的變動量，系統
可以找出欲發言的學生，而偵測到的變動時間
點，則為記錄所需的時間標籤。為了偵測唇形變
動並判斷是否發言，本計畫採用觀察唇形變動的
程度，並透過變點偵測演算法 (Change Point 
Detection, CPD)找出最適當之變動檢出點，其發言
判斷準則與演算法說明如下。 
 4
 發言判斷準則 
當學生欲發言時，嘴巴必定有相當程度之變
動，因此可利用觀察其在影像序列中的變動量來
判斷其是否為準備發言。假設由唇形定位所找出
之唇形的矩形大小為M×N，此唇形在前後兩張影
像的差量定義為： 
   
 
plipdiff _
M
i
N
j
pp jigjigNM 1 1
1 ,,
1
       (4) 
其中，gp(i, j) 為第p張影像 (frame)在點(i, j)
的梯度值。此外，透過唇形區域之統計特性可判
斷唇形變動之程度： 
 
 
M
i
N
j
ppmean jigNM 1 1
,1
              (5) 
  
 
plipvar_
M
i
N
j
pp meanjigNM 1 1
2,1
      (6) 
當唇形變動大於一個門檻值，則可判定其為
發言之行為，而該門檻值的判定，則由CPD來完
成。 
 變點偵測演算法 
假設在訊號改變發生在一個未知的時間
點，給定一組在時間 t1, t2, …上的特徵參數
X = {X1, X2, …} ，假設這訊號改變時間點是t，
這時間通常是一個預先分布在k = P(=k)的隨
機變數。為了簡化，我們看待這未知的參數為一
確定的參數(deterministic parameter)而非隨機變
數。隨機Xi的模型可以通式化的，可以當成常數
或是向量值，並且可以不僅代表觀察的訊號特
徵，還可以根據觀察序列的統計。 我們考慮有一
個偵測程序能連續地處理觀察值Xi，如果確定情
況符合，在時間 提出一個警告，並且宣稱這變
動(訊號的改變)已經在時間t偵測出。這停止時間
 是一個依賴觀察的序列X1, X2, …的隨機變
數，能描述偵測的表現衡量，當這變動發生在時
間 =k，我們使用Pk與Ek代表這個變動偵測的機
率與期望值描述。在本計劃中，我們提出非參數
式 的 序 列 變 點 偵 測 演 算 法 (Non-Parametric 
Sequential Change-Point Detection Algorithm)，以
偵測唇形是否因發言而有變動。 
  
三、結論與討論 
本計畫執行重點在於提供以遠距教學之遠
端教室為場景，透過上課學生情形之臉部影像，
使用嘴唇移動偵測(Lip Motion Detection)、條件式
隨機域模型(CRF, Conditional Random Field)物件
追蹤、及非參數式序列變點偵測演算法(Sequential 
Change Point Detection Algorithm)，找出高雜訊多
媒體視訊與語音，進行多媒體標記(labeling)，並
在後處理階段以原始多媒體視訊與語音取代之，
藉以提升多媒體紀錄品質；本計畫除了可以判斷
遠端學生是否開口外，以輔助語者辨識，並可提
供資料存檔備查後處理的索引特徵，以達到遠距
教學之智慧型感知運算的能力。 
 
四、計畫成果自評 
本計畫完成各種上課學生的臉部影像視訊
相關資料的蒐集，及臉部影像序列特徵擷取與分
析。也完成自動嘴唇輪廓偵測，及以條件式隨機
域模型為基礎之影像區域追蹤技術。本研究內容
與原計畫書內容相符，預期成果及目標均已達
成，本研究成果所衍生出的相關技術，計有一篇
期刊論文，及會議論文發表，其餘成果正整理發
表中。 
 
參考文獻 
[1] S. S. Yau et al., “Smart classroom: Enhancing 
collaborative learning using pervasive computing 
technology,” ASEE Annual Conference Proceedings, 
pp. 13633-13642, 2003. 
M
ic
ro
ph
on
es
M
ic
ro
ph
on
es
 
圖一，教室環境示意圖 
 
V
oice streamV
ideo 
stream
 
圖二，系統流程 
 
 6
98 年度專題研究計畫研究成果彙整表 
計畫主持人：鄭伯順 計畫編號：98-2221-E-155-044- 
計畫名稱：應用於遠距教學之 IP-based 智慧型協同作業技術研究--用於提升多媒體後處理品質之多媒
體檢索特徵研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
