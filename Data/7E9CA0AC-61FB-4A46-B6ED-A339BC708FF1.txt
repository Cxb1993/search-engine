protocol to fully mitigate the collision problem in 
the traditional CSMA/CA protocol. Combined with a 
super mode, it enhances the spectrum utilization and 
solves the throughput asymmetry issue. The queue 
management module consists separated queues for each 
AC and traffic schedulers. By proper scheduling, we 
can mix different AC packets for a given TXOP 
duration and assign different service weight for each 
AC. Simulation results show that, the proposed system 
can enhance utilization and provide better quality of 
service. 
英文關鍵詞： WLANs, MAC, Queue management, Quality of service 
 
2 
 
行政院國家科學委員會專題研究計畫成果報告 
提供服務品質保證之 CSMA/CA無線網路的設計與分析 
Design and analysis of CSMA/CA based wireless networks with quality of 
service guarantee 
計畫編號：NSC 100-2221-E-260-028 
執行期間： 100年 8月 1日至 101年 7月 31日 
主持人： 郭耀文  國立暨南國際大學電機工程學系(所) 
計畫參與人員：楊文欽、林祐任、劉冠志、吳東岳 
                國立暨南國際大學電機工程學系(所) 
 
一、 中文摘要 
    隨著科技的發展與進步，無線網路的使用已
融入日常生活中，然而 IEEE 802.11[1]的設計無法
同時提供良好服務給大量的使用者，且無差異性
服務讓即時性資料傳輸受到很大限制。 IEEE 
802.11 EDCA雖然提供了資料的差異性服務，工
作站的每個獨立 Access Categories (簡稱 AC)佇列
可直接去進行通道存取權的競爭，但是當無線區
域網路內的工作站增加時，將導致系統有較高的
封包碰撞率；當網路為重載時，AC之間的不公平
現象，將可能導致低優先權的AC無法傳輸資料。
此外，在基礎建設模式的網域中，工作站皆須藉
由 AP進行網路傳輸，因此 AP容易成為傳輸上的
瓶頸，使得下行封包在此被丟棄，因而造成上/下
行流量的不對稱。為了解決上述的問題，本文提
出了一個新的媒體存取控制層(MAC)架構，包含
底層的多重存取演算法與上層的佇列管理模組。
多重存取演算法中，我們設計了免競爭的方式以
提供無碰撞的傳輸，搭配一個超級模式，讓 AP
直接可以去傳送下行封包，可以有效改善下行的
頻寬。在上層的佇列管理模組，我們利用適當的
排程器，可以使一段 TXOP 中混合不同 AC 封包
進行傳送，而 AP 也可以排程選擇合適的使用者
來服務，達到公平的原則。根據模擬結果顯示，
新的媒體存取控制層架構不但解決了上/下行流
量的不對稱問題，並且達到無碰撞傳輸，可以更
有效的無線通道並達到服務差異化的效果。 
關鍵詞：無線區域網路、媒體存取控制層、佇列
管理、服務品質保證。 
Abstract 
    Wireless LANs have been part of our daily life 
thanks to the ease of development and low cost. 
However, the original design of IEEE 802.11 fails to 
provide a good service in a large network. The new 
IEEE 802.11 standard defines EDCA for 
differentiated services, where each AC's queue 
operates independently to contend for the wireless 
channel. When the number of station increases, the 
collision probability increases dramatically. 
Furthermore, the lower priority ACs may starves at 
heavy load situations. In an infrastructure WLAN, 
the AP is the bottleneck for downlink packets 
because the AP needs to contend with numerous 
stations, resulting in asymmetric throughputs 
between downlink and uplink. In order to mitigate 
the above mentioned problems, in this project, we 
propose a new MAC architecture including a 
multiple access algorithm and a new queue 
management module. We design a contention-free 
CSMA protocol to fully mitigate the collision 
problem in the traditional CSMA/CA protocol. 
Combined with a super mode, it enhances the 
spectrum utilization and solves the throughput 
asymmetry issue. The queue management module 
consists separated queues for each AC and traffic 
schedulers. By proper scheduling, we can mix 
different AC packets for a given TXOP duration and 
assign different service weight for each AC. 
4 
 
802.11 DCF
Backoff
DIFS
Wmin
Wmax
transmission
Backoff
AIFS[AC0]
Wmin[AC0]
Wmax[AC0]
Backoff
AIFS[AC1]
Wmin[AC1]
Wmax[AC1]
Backoff
AIFS[AC2]
Wmin[AC2]
Wmax[AC2]
Backoff
AIFS[AC3]
Wmin[AC3]
Wmax[AC3]
Virtual collision handler
transmission
AC0 AC1 AC2 AC3
802.11e EDCA
 
圖 1、 DCF 與 EDCA 比較示意圖 
 
除了上述的問題之外，在無線區域網路當中，
亦存在著一不公平的現象，那就是上行(Uplink)
與下行(Downlink)流量之間的不對稱。在無線區域
網路中，使用者必須透過基地台(Access Point; AP)
來使用網路(Internet)傳送與接收資料封包，此種
網路傳輸模式稱之為 Infrastructure Mode，而上行
所指就是使用者傳送給 AP 的方向，代表上傳流
量，相反的，下行指的就是 AP 傳送給使用者的
方向，代表下載流量。在一個大WLAN中，使用
者的數量很多，而 AP 還是藉由相同的方式來競
爭取得通道存取權，也就是說 AP 搶到通道的機
會將會低於使用者的機會，因而使得下行成為一
個雍塞點，然而，對一般的使用來說，下行的資
料通常比較多，這將會大大影響使用的滿意度。 
總而言之，目前的標準中對於大型的WLANb
仍然有許多的問題需要克服，如碰撞問題、協定
overhead 的問題、上下行流量非對稱問題、服務
品質保證等等的問題，因此本計畫提出一套完整
的解決方案，包含上層的佇列管理與下層的多重
存取技術，來達到提升頻寬使用率並提供良好服
務品質保證的目標。 
 
四、 文獻探討 
載波偵聽多重存取／碰撞避免協定（Carrier 
Sense Multiple Access with Collision Avoid; 
CSMA/CA）： 
 CSMA/CA 是無線網路媒體存取的方式，與
乙太網路的 CSMA/CD 協定相似，差別在於乙太
網路是利用碰撞偵測的方式，但由於碰撞偵測無
線訊號有所困難，因此 CSMA/CA 改採取避免碰
撞（Collision Avoidance）的方式。避免碰撞發生
的方法是以偵測工作頻帶中的電磁波能量來發現
通道是否空閒(Idle)，若發現空閒也不立刻送出資
料訊框(Frame)，而啟動一個倒數的程序(backoff)，
倒數計數器是隨機在 contention window中選擇一
個數值，每當通道閒置的時間經過一個 slot，則計
數器減 1，等到計數器數值為 0 時，才可以真正
傳送資料，如果在倒數期間偵測到通道忙碌時，
則倒數會被凍結，直到再度確認頻道空閒時再啟
動 backoff。 
 
RTS/CTS機制： 
為了確認訊框是否成功傳送，IEEE 802.11規
範了正面回覆機制(Positive Acknowledgement)，當
發送端送出訊框後，在間隔一個 SIFS時間後，發
送端若收到由接收端所回覆的 ACK訊框，則代表
這次的傳輸是成功的；反之，發送端若沒收到接
收端回覆的 ACK，那麼發送端將判定資料傳送失
敗，則會再進入通道偵測模式，再重新傳送訊框。
以上所描述的機制，被稱作 two-way handshaking 
機制。 
 
6 
 
工作站A
工作站B
Others
RTS
CTS
Data
Ack
NAV(RTS)
NAV(CTS)
DIFS
SIFS
SIFS
SIFS
DIFS
Defer Access Backoff after Defer
CW
Next MPDU
MPDU : MAC Protocol Data Unit
 
圖 4、 網路配置向量的設定 
 
二元指數後退演算法 (Binary Exponential 
Backoff, BEB)： 
    當系統偵測通道持續 DIFS 或 EIFS 的閒置
時間後，將開始 backoff，計算方式如下: 
    Backoff time = Random()  slots 
其中 Random()為一個平均隨機分佈的亂數，其
值介於[0,CW-1]區間(Contention Window;CW)，
如果該次傳送發生碰撞(同時有兩個或以上的使
用者傳送資料)，需要再次重送時，而 BEB方法
的重點就在於，下一次 CW會變成兩倍，也就是
讓 Backoff time變大，以降低再次碰撞的機會。
令Wi為第 i次重傳時使用的contention window，
則其計算公式如下: 
'
2 ,  ',
=       
2 ,  ' .
i
i m
W i m
W
W i m
 ≤

>
 
還有兩個重要參數 m 與 m'，m 表示最多可以重
傳的次數，而 m'表示 contention window最多可
以被放大兩倍的次數。 
傳輸機會 (Transmit Opportunity, TXOP)： 
 在新的 IEEE 802.11[2]中的定義 TXOP這一
個新的功能，當一個工作站競爭到通道後，可以
傳送多個封包，來降低協定的overhead(如RTS、
CTS等等，與一些 IFS)，而最多可以使用的時間
則是 TXOP limit。在 EDCA中，每一個 AC使用
的 TXOP limit 可以設定不同，來達到差異性，
但是 EDCA有一個缺點是，TXOP並不能混用，
假設現在是 AC1 搶到通道，當這個 queue 送完
後並未超過 TXOP limit，而其他 AC還有封包待
送，然而此時這個工作站是不能傳送其他 AC的。
由於真正使用通道的時間可能不是TXOP limit，
因此工作站會使用網路配置向量 (Network 
Allocate Vector,NAV)來通知其他工作站它將使
用的時間，而其他工作站就可以暫停其backoff，
此功能稱為 virtual carrier sensing。圖 4 為搭配
RTS/CTS 機制的網路配置向量圖，以工作站
A(Sender)送出 RTS 訊框時為例，假設在工作站
A傳送範圍內的所有工作站都將收到 RTS，此時
工作站們將會藉由 RTS訊框得知工作站 A將佔
用通道的時間，並且暫停自身的倒數計時器
(Backoff Timer)。同理，當工作站 B 回覆 CTS
訊框時，在工作站 B 傳送範圍內的其他工作站
也將藉此得知工作站 B 佔用通道的時間，並且
暫停自身的倒數計時器。 
     
    以上我們對於 WLAN 做一個完整的介紹後，
接下來探討一下文獻的研究內容。 
    首先，文獻[3]對於 DCF的理論吞吐量與延
遲做分析，可以明顯看出協定 overhead的影響，
尤其對於小 pakcet更是嚴重，然而其分析的前提
是忽略碰撞，因此只能當作是 upper bound。而
實際上在 CSMA/CA 的運作中會有碰撞的情況
發生，最早 Bianchi [4] 與 Chatzimisios [5]利用
二維的 Markov chain 來分析並計算出飽和情況
下的吞吐量，Bianchi 指出了吞吐量與初始
contention window W0之間的關係，發現不同網
8 
 
  
圖 6(a)、常態模式傳輸的運作 
圖 6(b)、Super mode傳輸的運作 
1 p−
1 p−
1 p−
1
1
p
W
1m
p
W
−
m
p
W
0
1
W
圖7、DC-DCF的Markov chain model 
 
    圖 6(a)為常態傳輸模式的運作示意圖，一般
的工作站皆使用常態模式傳輸，而 AP可以在這
圖 6(a)與 6(b)兩種模式中進行切換，當 AP收到
上行的封包時啟動 Super mode傳輸封包，在上
行的 NVA結束後，經過 SIFS 馬上開始送下行的
資料，而使用的時間可以利用 CTS的 NAV來通
知所有工作站。這樣一來，每次的 RTS/CTS 交
握之後，可以傳送上行與下行的資料，將可以徹
底解決流量不對稱的問題，同時也少掉一次
RTS/CTS 交握，降低協定的 overhead。但是 AP
不可以只有 Super mode，因為如果沒有上行的資
料，那將無法送下行的資料，因此 AP必須也可
以切換到常態模式。以 DCF 為例，為了維護上
下行流量的公平性，將 AP公式(1) Backoff time
的計算方式修改如下式 
    Backoff time = {X+Random()} 
 
圖8、DC-DCF的延遲特性 
其中 X代表一常數值，使 AP的倒數時間比工作
站長，如此一來，除非所有工作站長時間都沒有
封包要上傳至 AP，那麼 AP 才會啟動常態模式
來主動競爭獲得通道存取權，而一旦切換到
Super mode，則其 backoff time會重設。 
 
延遲競爭 DCF (DC-DCF): 
    Zhai et al. [13]提出了一個流量控制的概念
來降地碰撞機率以提稱通道使用率，但是如何做
流量控制卻沒有討論。本計畫中我們針對降低碰
撞機率，提出了一個 DCF 的改善版本，稱為
Delayed Contention DCF(DC-DCF)，在標準的
DCF中，CW會隨著碰撞次數成指數的上升，雖
然可以降低再次碰撞的機率，然而卻會使已經碰
撞的封包，其等待的時間變大，也就是說封包的
delay 可以有時很小，有時會很大，這對於即時
性的訊務來說，是非常地不好。由於其原因都是
碰撞所致，因此，我們把第一次傳送時的 backoff 
time隨著網路大小做調整，來降低碰撞的機率。 
random( ),  for 1st transmission,
Backoff time  
random( ),  for retransmission.
o
i
C W
W
+
= 

 
圖 7是 DC-DCF的Markov chain model，我們可
以計算出狀態(0,0)的機率，並得到 C與碰撞機率
的關係，在 Zhai et al. [13]中提到最佳的操作點
是在碰撞機率為 0.196時，因此我們可以計算出
在不同網路大小時其對應的 C 值為多少。詳細
的過程已經發表於 2012年的 VTC[11]。 
0 0.2 0.4 0.6
0
0.002
0.004
0.006
0.008
0.01
0.012
DC-DCF (non-congested)
Data rate per other station (Mbps)
Av
e
ra
ge
 
e
n
d-
to
-
e
n
d 
de
la
y
 
 
0.6 0.8 1
0
0.1
0.2
0.3
0.4
DC-DCF (congested)
Data rate per other station (Mbps)
 
 
0 0.2 0.4 0.6
0
0.002
0.004
0.006
0.008
0.01
0.012
DCF (non-congested)
Data rate per other station (Mbps)
Av
e
ra
ge
 
e
n
d-
to
-
e
n
d 
de
la
y
 
 
0.6 0.8 1
0
0.1
0.2
0.3
0.4
DCF (congested)
Data rate per other station (Mbps)
 
 
MAC delay
Queueing delay
MAC delay
Queueing delay
MAC delay
Queueing delay
MAC delay
Queueing delay
10 
 
做資料的傳送，再等待一個 SIFS，由接收端送
出 ACK，才完成整個資料傳送的過程。在最理
想的情況下，若每個工作站都有資料需要傳送，
則最大可達到的 throughput可以寫成: 
  
ττ ++++++
×
=
ACKSIFSDATAslotDIFS
DATA
TTTTT
L
throughput 8  
其中 DATAL 為資料的長度。 DIFST 在標準中設為
sµ34 ， SIFST 為 sµ16 。 slotT 是網路最小單位時間，
在滿載的時候，每隔一個 slot，便會有工作站傳
送封包，所以這裡 slotT 為 sµ9 ，τ 是傳送訊框所
需的延遲時間，設為 sµ78.0 。 DATAT 為傳送資料
封包的時間，其公式寫成: 
  
DATA P PHY HDATA dataT T T T T= + + + , 
PT 為傳送 Preamble 耗費的時間， PHYT 為傳送
Physical標頭所耗費的時間， HDATAT 為傳送MAC
標頭所耗費的時間， dataT 為傳送 payload 耗費的
時間。 ACKT 為傳送 Acknowledgment 耗費的時間，
由於 ACK的封包長度與 CTS相同，所以傳送時
間也是一樣的，傳送 ACK(CTS)的延遲時間: 
  
)()( ctsackPHYPCTSACK TTTT ++= , 
其中 )(ctsackT 為傳送 ACK(CTS)耗費的時間。以
上的分析是在沒有使用 RTS/CTS 機制的情況，
如果有使用 RTS/CTS 機制，其 throughput 可以
寫成: 
ττ +++×+++++
×
=
ACKSIFSDATACTSRTSslotDIFS
DATA
TTTTTTT
L
throughput
3
8                                 
其中 RTST 為傳送 RTS的延遲時間，其公式寫成: 
  rtsPHYPRTS TTTT ++= , 
rtsT 為傳送 RTS 耗費的時間，Control型態封包是
用基礎速率 basicR 進行傳輸，而 Data型態封包是
用資料傳輸速率 dataR 傳輸。藉由以上的公式，我
們可以簡單地估測系統的最大吞吐量。 
 在網路中，封包延遲時間(total delay)是由傳
播 時 間 (propagation delay) 、 傳 送 時 間
(transmission delay)以及在佇列時間 (queuing 
delay)所組成。傳播時間是訊號或資料在媒介裡
傳遞所耗費的時間，傳送時間是指資料進入
MAC 層後，工作站進行配置封包，判斷傳送位
址，進行傳送的事前處理的時間。佇列時間是封
包在產生後，進入佇列(queue)等待被處理的時間。
在這裡我們把傳播時間跟傳送時間合起來，稱做
服務時間(service time)，指封包由 queue 進入
MAC層直到成功傳送封包的時間。 
   在 CF-CSMA 中，封包傳送成功的時間的計
算公式可以寫成 
  
DIFSSIFSACKDATASUC TTTTT +++= , 
這是沒有使用 RTS/CTS 機制下的傳送時間，如
果有使用 RTS/CTS機制，其計算公式可以寫成 
  
DIFSSIFSACKDATACTSRTSSUC TTTTTTT +×++++= 3 ,                         
在 CF-CSMA中，每個工作站都有自己固定的時
槽，每隔週期 N(N代表網路大小，包含 AP)定會
輪到ㄧ次傳送封包的機會。所以服務時間可以寫
成: 
    ( )S SUC slotT T T N= + × , 
代表著不論其他的工作站是否有在使用通道傳
送封包，使用者本人最多每隔 ST 時間一定能傳
送。在 CF-CSMA中，使用者本人受到其他工作
站的影響降至最小，可以不受其他使用者影響，
能給予服務品質保證，穩定度較好。 
 我們接著分析 queuing delay 的狀況，這個
部份比起 service time要複雜一點。在 CF-CSMA
中，最糟糕的狀況是每個 slot都有工作站要傳送
封包，因此，使用者必須等到固定的 ST 時間才
能傳送封包。當資料抵達程序是 Poisson時，再
重載時，CF-CSMA可以近似為一個M/D/1系統，
其 queue delay計算方式可以寫成 
     )1(21 ρ
ρ
−
×
=
S
Q
T
T ,   
其中λ是資料平均抵達的速率，而  
。 
 
佇列管理者(Queue Manager)方面： 
    為了提供差異化的服務品質保證，每一個
AC 會有一個獨立的 queue，而透過適當的排程
器來安排每個 queue的服務次序。由於 AP與工
作站的功能不同，因此，以下針對兩者設計其
queue manager。 
    圖 10 說明了工作站的架構，在排程器
scheduler A的選擇上，因為要提供優先權的差異 
1<×= STλρ
12 
 
 
表 1、模擬環境相關參數設定表 
ACKT  傳送 Ack 耗費的時間 
DIFST  DISF 時間 : 34 sµ  
SIFST  SIFS 時間 : 16 sµ  
slotT  時槽時間 : 9µs 
PT  傳送 Preamble 耗費的時間: 72µs 
PHYT  傳送 Phy標頭耗費的時間:48µs  
τ
 傳送訊框所需的延遲時間 : 2µs
 
 
H DATAL −  MAC標頭長度 : 28 bytes 
ACKL  Ack訊框的長度 : 14 bytes 
PHYL  PLCP header的長度 : 48 bits 
Data rate 傳送MAC訊框的速度 : 216 Mbps 
Basic rate 傳送 control frame的速度 : 6 Mbps 
表 2、排程驗證使用參數 
 
Cbr Rate 
(Mbps) 
Packet Size 
(bytes) 
DRR 
Quantum 
(bytes) 
VO (Voice) 30 100 200 
VI (Video) 30 1200 1500 
BE 
(BestEffort) 
30 1500 750 
BK 
(Background) 
30 600 750 
 
，其中 802.11 EDCA模組並未提供 RTS/CTS功
能，因此其協定 overhead 會比較小，而本計畫
中所提的新MAC架構則是自行在NS2開發的模
組。 
 模擬環境包含 1個AP與N個無線工作站， 
運作於 Infrastructure Mode，所以每個工作站的
上行流量接收端皆為 AP，而 AP 亦為所有工作
站的下行流量來源，系統所有的無線工作站(包
括 AP)同時有 4種(VO、VI、BE、BK)優先等級
不同類型的資料流在傳送封包。 
 
排程演算法的驗證： 
 本次研究設計了排程演算法的機制，為了驗
證設計的排程演算法是否如預期般運作，而
MAC 為 CF-CSMA，一個極重載的模擬環境來
驗證 TXOP中每個 AC的分佈比例，假設 4個 
 
 
圖 12、排程演算法之驗證 
 
AC 皆為 CBR，其中 CBR 封包大小與速率如表
2，可清楚看到排程演算法中 4 個 AC 所分配到
的額度比例為 : 1(VO) : 7.5(VI) : 3.75(BE) : 
3.75(BK)。假設工作站數量 N = 9與 AP進行雙
向傳輸，TXOP limit 設定為 0.01sec，模擬時間
為 100sec，圖 12為每個工作站中四種 AC的上
下行吞吐量分佈圖。由圖可以看出，當系統為極
重載時，因為每一段 TXOP所傳送的 AC封包分
佈隨著排程演算法所設定，所以系統整體上每個
Traffic 的上行與下行吞吐量，所呈現的比例與
AC的額度比例相當接近。 
 
四個 Traffic同時運行的情況： 
 為了使模擬的過程更接近實際的網路情況，
模擬的劇本是每個工作站有 VO、VI、BE、BG，
這四種 Traffic，如下 :  
 1. VO (Voice): CBR Traffic (UDP)。 
0
1000000
2000000
3000000
4000000
5000000
6000000
1 2 3 4 5 6 7 8 9
Uplink Throughput (bps)
Station
0
1000000
2000000
3000000
4000000
5000000
6000000
1 2 3 4 5 6 7 8 9
Downlink Throughput (bps)
station
14 
 
 
圖 15 上行傳輸，VI(Video) traffic總吞吐量變化 
 
 
 
圖 16 下行傳輸，VI(Video) traffic總吞吐量變化 
 
    
    2. VI (Video): VBR Traffic (UDP)。 
 3. BE (Best Effort): TCP Traffic (TCP)。 
 4. BK(BackGround): Poisson (UDP)。 
在系統的模擬上，是以增加工作站(1~25)的方式
來觀察網路流量從輕載轉變為重載時，每個 AC
的吞吐量變化，以及針對 CBR (Voice)與 VBR 
(Video)這兩個即時性資料流，去分析兩者的封包
延遲與封包丟棄率。同時也模擬標準的 DCF、
EDCA與我們所設計的新MAC架構，在本計畫
設計的MAC架構中分別使用 DCF機制、FCWB
機制及 CF 機制，最後比較四種 traffic 在吞吐
量、封包延遲與封包丟棄率的結果。其中 PCQ 
(Per-Class Queue)是本計劃中佇列的簡稱，之後
也將使用此簡稱代表新的MAC架構。 
 
 
0
1000000
2000000
3000000
4000000
5000000
6000000
7000000
1 3 5 7 9 11 13 15 17 19 21 23 25
T
h
ro
u
g
h
p
u
t(
b
p
s)
Number of station
UL Throughput - VI
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
EDCA
0
1000000
2000000
3000000
4000000
5000000
6000000
7000000
1 3 5 7 9 11 13 15 17 19 21 23 25
T
h
ro
u
g
h
p
u
t(
b
p
s)
Number of station
DL Throughput - VI
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
EDCA
16 
 
 
圖 19 上行傳輸，Backgorund(Poisson) traffic總吞吐量變化 
 
圖 20 下行傳輸，Backgorund(Poisson) traffic總吞吐量變化 
 
圖 17、18為 BE的上下行吞吐量變化，由
於系統中是以 TCP傳輸的方式表示 BE，所以在
系統流量輕載時，TCP可以有較大的傳輸率，也
因此具有較大的吞吐量。但是當系統流量轉為重
載時，TCP traffic的壅塞控制將啟動，如此一來，
DCF與 EDCA下 TCP的傳輸率將大幅減少，重
載時幾乎已經無法傳送資料。然而本計劃所設計
的架構中，採用了 DRR排程器的功能，將可以
保證在每一次的 TXOP傳輸中，低優先權的 AC
也可以享有固定的傳輸量，同時，AP 在 Super 
mode 與 RR 排程器的運作下，可以有效提升下
行的吞吐量。使 AP可以公平的服務每個工作站
及提升下行的總吞吐量。圖 17 可以看到
PCQ-DCF 的效能最高，這是因為上行方面加上
CW較小的原因所致，然而可以看到圖 18，在下
行方面也有同樣的問題，因此，整體而言，
PCQ-CF提供的效能是最高的。
0
200000
400000
600000
800000
1000000
1200000
1400000
1600000
1800000
1 3 5 7 9 11 13 15 17 19 21 23 25
T
h
ro
u
g
h
p
u
t(
b
p
s)
Number of station
UL Thoughput - BK
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
EDCA
0
200000
400000
600000
800000
1000000
1200000
1400000
1600000
1800000
1 3 5 7 9 11 13 15 17 19 21 23 25
T
h
ro
u
g
h
p
u
t(
b
p
s)
Number of Station
DL Throughput - BK
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
EDCA
18 
 
 
圖 23 上下行總和，4個 AC總吞吐量變化 
 
圖 24 工作站上行傳輸，VO(Voice) traffic平均延遲變化 
 
圖 25 工作站上行傳輸，VO(Voice) traffic封包丟棄率 
0
10000000
20000000
30000000
40000000
50000000
1 3 5 7 9 11 13 15 17 19 21 23 25
T
h
ro
u
g
h
p
u
t(
b
p
s)
Number of station
Total Throughput
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
EDCA
0.0001
0.001
0.01
0.1
1
1 3 5 7 9 11 13 15 17 19 21 23 25
S
e
co
n
d
s
Number of stations
UL Delay - VO
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
DECA
0
0.05
0.1
0.15
0.2
0.25
1 3 5 7 9 11 13 15 17 19 21 23 25
D
ro
p
 r
a
te
Number of stations
UL Drop Rate - VO
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
DECA
20 
 
 
圖 29 工作站下行傳輸，VO(Voice) traffic封包丟棄率 
 
 
圖 30 工作站下行傳輸，VI(Video) traffic平均延遲變化 
 
 
圖 31 工作站下行傳輸，VI(Video) traffic封包丟棄率 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 3 5 7 9 11 13 15 17 19 21 23 25
D
ro
p
 r
a
te
Number of stations
DL Drop Rate - VO
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
DECA
0.001
0.01
0.1
1
10
1 3 5 7 9 11 13 15 17 19 21 23 25
S
e
co
n
d
s
Number of stations
DL Delay - VI
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
DECA
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 3 5 7 9 11 13 15 17 19 21 23 25
D
ro
p
 r
a
te
Number of stations
DL Drop Rate - VI
DCF
PCQ-DCF
PCQ-FCWB
PCQ-CF
DECA
22 
 
requirements – “Part 11: Wireless LAN 
Medium Access Control (MAC) and Physical 
Layer (PHY) Specifications,” 2007. 
[3]. Y. Xiao and J. Rosdahl, “Throughput and 
Delay Limits of IEEE 802.11,” IEEE 
Commun. Lett., vol. 6, no. 8, Aug. 2002, pp. 
355-57. 
[4]. G. Bianchi, “Performance Analysis of the 
IEEE 802.11 Distributed Coordination 
Function,” IEEE Journal on Selected Area in 
Communications, vol.18, no.3, pp.535-547, 
2000. 
[5]. P. Chatzimisios, A.C. Boucouvalas and V. 
Vitsas, “Packet delay analysis of IEEE 802.11 
MAC protocol,” IEE Electronics Letters 39 
(18) 1358-1359, 2003. 
[6]. P. Chatzimisios, A.C. Boucouvalas and V. 
Vitsas, “IEEE 802.11 Packet Delay – A Finite 
Retry Limit Analysis,” IEEE GLOBECOM, 
vol. 2, pp.950-954, December 2003. 
[7]. H. Wu, Y. Peng, K. Long, S. Cheng, J. Ma, 
“Performance of Reliable Transport Protocol 
over IEEE 802.11 wireless LAN: Analysis 
and Enhancement,” in Proceedings of IEEE 
INFOCOM, New York City, NY, June 2003. 
[8]. Y. W. Kuo and T. L. Tsai, “On Achieving 
Maximum Channel Utilization for IEEE 
802.11n WLAN,” IEEE Asia-Pacific Services 
Computing Conference, Yilan, Taiwan, 2008, 
pp. 1168-1172. 
[9]. Y. W. Kuo and T. L. Tsai, “Fixed Contention 
Window Backoff Scheme for the 
Contention-Based IEEE 802.11 MAC,” in 
Proc. IEEE TENCON, Fukuoka, Japan, 2010. 
[10]. 郭耀文、蔡東麟,“適用於適用於載波檢測多
路存取/碰撞避免協定的固定視窗退讓機制
與參數決定之法則”, 通過中華民國專利. 
[11]. Y. W. Kuo and W. F. Lu, “Delayed contention 
DCF MAC protocol for IEEE 802.11 wireless 
LANs,” in Proc. IEEE VTC, Yokohama, Japan, 
2012. (NSC100-2221-E-260-028) 
[12]. 郭耀文、呂韋甫, “適用於載波檢測多路存取
/碰撞避免協定的延後競爭退讓方法”, 中華
民國專利申請中 
[13]. H. Zhai, X. Chen, and Y. Fang, “How Well 
Can the IEEE 802.11 Wireless LAN Support 
Quality of Service?,” IEEE Trans. Wireless 
Commun., vol. 4, no. 6, 2005. 
[14]. S. Siwamogsatham, "A novel smart-DCF 
scheme for high-speed WLANs," 
International Symposium on Communications 
and Information Technologies, October 2007. 
[15]. C. M. Yen, C. J. Chang, and Y. S. Chen, "An 
adaptive p-persistent MAC scheme for 
multimedia WLAN," IEEE Commun. Lett., 
vol. 10, no. 11, pp. 737-739, November 2006. 
[16]. F. Cali, M. Conti, and E. Gregori, "IEEE 
802.11 protocol: design and performance 
evaluation of an adaptive backoff 
mechanism," IEEE J.sel. Areas 
Commum.,vol.18, no.9,pp.1774-1786, Sep. 
2000.  
[17]. D. Skyrianoglou, N. Passas, and A. K. 
Salkintzis, “ARROW: An ef?cient traf?c 
scheduling algorithm for IEEE 802.11e 
HCCA,” IEEE Trans. Wireless Commun., vol. 
5, no. 12, pp. 3558–3567, Dec. 2006 
[18]. N. Ramos, D. Panigrahi, and S. Dey, 
 1
 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                   日期： 100 年 7 月 23 日 
計畫編號 NSC  100 －  2221 － E －  260 －  028 － 
計畫名稱 提供服務品質保證之 CSMA/CA 無線網路的設計與分析 
出國人員
姓名 
郭耀文 
服務機構
及職稱 
國立暨南大學電機系助理教授 
會議時間 
101年 5月 6日至 
101年 5月 9日 
會議地點 
Yokohama, Japan 
會議名稱 
(中文) 2012 IEEE 75屆 春季 VTC研討會 
(英文) 2012 IEEE 75th Vehicular Technology Conference - Spring 
發表題目 
(中文) IEEE 802.11無線區域網路之延遲競爭媒體存取控制協定 
(英文) Delayed contention DCF MAC protocol for IEEE 802.11 wireless 
LANs 
(中文) WiMAX系統下針對兩階訊務需求之資料排程演算法 
(英文) A Data Mapping Algorithm for Two-Level Requests in WiMAX 
Systems 
附件五 
 3
 
我們發表的論文，第一篇是WLAN相關，而第二篇是WiMAX相關，因此剛好都被
安排在 Session 5 E，如上面議程表中黑色方框所示。 
 
本次主要的行程如下:  
5月 7日: 
   凌晨: 約 4:00由埔里出發，開車前往桃園機場。由於 5月 6日的機票訂不到經濟
艙，又剛好是星期二報告，因此順延到 7日才出發。 
   下午: 中午到成田機場，轉搭火車到橫濱市，搭地鐵到飯店 check in。 
5月 8日: 
 5
軟體進行模擬，由於WiMAX漸漸式微，LTE-A是一個未來發展的趨勢，可以讓我
知道如何開始準備。而廠商展示也是相當有看頭，看到了實際的 LTE-A系統，目前
在實驗室已經可以達到約 900Mbps，不過整個系統還非常龐大，需要架設在一輛小
台車上面；戶外的部分，基地台是架設在大樓屋頂，移動端則是架設在一輛小廂型
車上，然後實際去看系統的傳輸速率，由於距離造成的衰減、多重路徑的干擾、與
車輛的移動，傳輸的速率大大降低，約只剩三、四百Mbps，如果離基地台較遠的地
方，則會降到 100Mbps以下。詢問一下可能上市的時間，對方說應該會在 2015年
之後，所以還有不少地方是可以進行研究的。 
  
A Data Mapping Algorithm for Two-Level Requests 
in WiMAX Systems 
 
 
Tsern-Huei Lee, Chi-Hsien Liu, Arleth Soleiy Garth Campbell 
Institute of Communication Engineering 
National Chiao Tung University 
Hsin-Chu, Taiwan 
{tsernhueilee, terence.am91g}@gmail.com 
Yaw-Wen Kuo 
Department of Electrical Engineering 
National Chi-Nan University Taiwan 
Puli, Nan-Tou, Taiwan 
ywkuo@ncnu.edu.tw
 
 
Abstract—The IEEE 802.16e standard known as Mobile WiMAX 
has recently been introduced. It is considered as one of the most 
promising wireless access technologies supporting high data 
throughput with low cost of deployment. Mobile WiMAX makes 
use of Orthogonal Frequency-Division Multiple Access (OFDMA) 
digital modulation scheme as the transmission method. With the 
constraint requires that all requests have to be mapped as a 
rectangle, it is shown that finding an optimum mapping solution 
is an NP-complete problem. Many burst mapping algorithms 
have been proposed, but none considered the case with 
prioritized requests. This paper presents an efficient packing 
algorithm for two-level requests with two targets: (1) map high 
(MUST part) priority data as much as possible; and (2) achieve 
high efficiency, reduces the number of unused slots, and 
minimizes the mapping information overhead. Simulation results 
show that the proposed algorithm achieves high efficiency. 
Keywords-OFDMA, WiMAX, Burst mapping, Two-level 
requests 
I.  INTRODUCTION 
IEEE 802.16e Mobile WiMAX constitutes one of the most 
promising broadband wireless access technologies, supporting 
long-distance communications, high-speed mobile Internet 
access to the widest array of devices. As the fourth generation 
of wireless technology, WiMAX delivers low-cost, open 
networks and is the first all IP mobile Internet solution 
enabling efficient and scalable networks for data, video, and 
voice [1]. 
Mobile WiMAX makes use of an Orthogonal Frequency 
Division Multiple Access (OFDMA) which in order to achieve 
a higher MIMO spectral efficiency, shorter delay, and more 
efficient use of the bandwidth available [2]. In Mobile WiMAX 
systems, a base station (BS) has full control over resource 
allocations to various mobile stations (MSs) in both the 
downlink (DL) and the uplink (UL).  
Mobile WiMAX uses a fixed frame based allocation. Each 
frame is typically of 5 ms duration and divided into the uplink 
and the downlink sub-frames. The bi-directional 
communication can be achieved by frequency division 
duplexing (FDD) or time division duplexing (TDD). In the 
FDD, UL and DL use different frequency bands, allowing the 
simultaneous transmission of both UL and DL sub-frames. The 
TDD provides a flexible partitioning of the frame into DL and 
UL sub-frames. This paper considers a TDD system, but the 
proposed algorithm can be used for both systems. 
According to the IEEE 802.16e specification, a data burst is 
mapped to a two-dimensional data block consisting of a group 
of contiguous OFDMA slots. An OFDMA slot being the 
minimum possible data unit is defined in two dimensions of 
time and frequency (symbol-subchannel). The OFDMA frame 
starts with a downlink preamble and a frame control header 
(FCH) followed by the downlink map (DL-MAP) and the 
uplink map (UL-MAP). Both maps contain the informational 
elements (IEs) that detail the burst profile for each burst. A 
DL-MAP IE consists of four primitive parameters: OFDMA 
symbol offset, OFDMA subchannel offset, number of OFDMA 
symbols, and number of OFDMA subchannels. 
In this paper, we consider the diversity sub-carrier 
permutation mode, e.g., the Partially Used Sub-Channelization 
(PUSC) mode, where the sub-carriers forming a subchannel are 
scattered uniformly over the entire frequency band. For the DL 
PUSC, it is assumed that the basic data mapping unit is a slot, 
which is a combination of one subchannel and two OFDMA 
symbols. According to WiMAX forum specified parameters, 
with 10 MHz spectrum, there are 30 subchannels each one 
consisting of 28 subcarriers. 
The IEEE 802.16e standard has defined five scheduling 
services classes with different QoS requirements, including 
bandwidth, packet loss, delay and delay jitter: Unsolicited 
Grant Service (UGS), real-time Polling Service (rtPS), 
extended real-time Polling Service (ertPS), non-real-time 
Polling Service (nrtPS), and Best Effort (BE) [3] [4]. Each 
class has different QoS parameters. The system resource is 
controlled by a scheduler at, which allocates the number of 
slots to each MS frame by frame. The allocated resources to 
MSs form a set of requests to the mapping algorithm that maps 
each request into a rectangular region. With the constraint of 
rectangular mapping, it is possible that the actual data 
belonging to a burst cannot fill the whole rectangular region 
and vacant slots are considered wasted. This mapping process, 
or called a bin packing problem, is known to be NP-complete 
[5]. 
This work was supported in part by the National Science Council, Taiwan, 
R.O.C., under grant NSC 100-2221-E-009-112 and NSC100-2221-E-260-028.
978-1-4673-0990-5/12/$31.00 ©2012 IEEE
 
Figure 2.  Example of a general burst. 
 
Figure 3.  Bursts of every variety. 
The proposed algorithm consists of two phases as described 
below.  Phase 1 maps all requests with both MUST  and  
WISH parts into the downlink subframe. Phase 2 is to return 
some allocated requests' WISH parts such that more MUST 
parts can be allocated. 
The first phase consists of four steps as follows. The 
algorithm allocates slots to a request iteratively. As the 
algorithm proceeds, the subframe will be split into some 
vertical strips. Let Ψ  be the set of all strips, and initially 
Ψ ൌ ሼܭଵ,௦ሽ. 
Step 1. Find a strip in Ψ, say ܭ௜כ,௝כ , such that it has the 
maximum available rectangle space which is denoted by 
ܴ௜כ,௝כ ൌ ሾሺݔᇱ, ݕᇱሻ; ݓᇱ, ݄Ԣሿ. 
Step 2. Select the largest request in ࡭, say ܣ௞, such that it 
can be allocated to ܴ௜כ,௝כ  found in step 1. The first phase 
terminates if no such ܣ௞ exists. 
Step 3. There are two cases for ܭ௜כ,௝כ. 
i) If หܴ௜כ,௝כห ൌ |ܭ௜כ,௝כ|, then ܭ௜כ,௝כ must be ܭ௜כ,௦.  
a) Calculate ݓ ൌ ڿܣ௞ ݄Ԣ⁄ ۀ  and ݄ ൌ ڿܣ௞ ݓ⁄ ۀ . 
Allocate the rectangle ݎ ൌ ሾሺݔᇱ, ݕᇱሻ; ݓ, ݄ሿ  for 
request ܣ௞.  
b) If ݓ ൏ ሺݏ െ ݅כ ൅ 1ሻ , then split the original 
ܭ௜כ,௝כ  into ܭ௜כ,௜כା௪ିଵ  and ܭ௜כା௪,௦ . Update 
Ψ ൌ ሺΨ െ ሼܭ௣,௦ሽሻ ׫ ሼܭ௣,௣ା௪ିଵ, ܭ௣ା௪,௦ሽ. 
ii) Otherwise there are some requests allocated in 
ܭ௜כ,௝כ . Calculate ݓ ൌ ݆כ െ ݅כ ൅ 1 and ݄ ൌ ڿܣ௞ ݓ⁄ ۀ. 
Allocate the rectangle ݎ ൌ ሾሺݔᇱ, ݕᇱሻ; ݓ, ݄ሿ  for 
request ܣ௞. 
Step 4. Update ܴ௜כ,௝כ, and remove ܣ௞ from ࡭. 
In general, one burst consists of up to three parts as shown 
in Fig. 2. The black part represents the over allocated slots. Part 
A contains all the MUST data and possibly with some of the 
WISH data or even some of the over allocated slots. Part B 
contains only part of the rest WISH data. Part C is the row 
containing the over allocated slots along with the last part of 
WISH data, if over allocated slots exist. Figure 3. shows the 
bursts of every variety. 
TABLE I.  AN EXAMPLE TO ILLUSTRATE THE PROPOSED ALGORITHM 
Resource 
(slots) 
࡭૚ ࡭૛ ࡭૜ ࡭૝ ࡭૞ ࡭૟ ࡭ૠ ࡭ૡ ࡭ૢ ࡭૚૙
38 8 86 32 41 3 115 7 17 13 
Must part 14 6 48 22 15 2 50 7 11 5 
Wish part 24 2 38 10 26 1 65 0 6 8 
The rest 
of the 
Must data 
0 0 0 0 0 0 0 0 0 0 
Over 
Allocation 0 0 1 0 0 0 1 0 0 1 
 
After completing the first phase, the unmapped requests 
might contain the MUST part. To serve as much urgent data as 
possible, the second phase selects the request according to the 
size of MUST part. 
Let Ψ ൌ ሼܭଵ,௣భ, ܭ௣భାଵ,௣మ, ڮ , ܭ௣೗ାଵ,௦ሽ , 1 ൑ ݌ଵ ൑ ݌ଶ ൑ ڮ ൑݌௟ ൏ ݏ, be the result after the first phase is done. The Second 
phase is described below. 
Step 1. Select the request in ࡭, say ܣ௞, such that its MUST 
part is the largest one. If ࡭ ൌ ׎, then Phase 2 is terminated. 
Step 2. Now, we select a proper strip in Ψ to allocate  ܯ௞. 
i) If ܯ௞ ൑ ܴ௜,௝ for some ܭ௜,௝  in Ψ, then select the strip 
with the smallest available space, say ܭ௜כ,௝כ, to fit 
ܯ௞. Go to Step 3. 
ii) Otherwise, check whether the ܯ௞  can be fit in a 
strip. Let  ܥ௜,௝ and ܤ௜,௝ be the total numbers of slots 
belonging to Part C and Part B in strip ܭ௜,௝ , 
respectively.  
a) If ܯ௞ ൑ ሺܴ௜,௝൅ܥ௜,௝ሻ  for some ܭ௜,௝  in Ψ , then 
select the strip with maximum ܥ௜,௝ , say ܭ௜כ,௝כ. 
Remove row by row the slots belonging to Part 
C in ܭ௜כ,௝כ until ܯ௞ can be fit in the strip. When 
removing a row, choose the one which has the 
most number of over allocated slots. Shift up all 
empty rows to the top, and go to Step 3. 
b) Otherwise, select the strip with maximum 
ሺܥ௜,௝ ൅ ܤ௜,௝ሻ, say ܭ௜כ,௝כ. If ܯ௞ ൑ ሺܥ௜כ,௝כ ൅ ܤ௜כ,௝כሻ, 
remove all rows the slots belonging to Part C in 
ܭ௜כ,௝כ. Remove row by row the slots belonging 
to Part B in ܭ௜כ,௝כ until ܯ௞ can be fit in the strip. 
Shift up all empty rows to the top, and go to 
Step 3. If ܯ௞ ൐ ሺܥ௜כ,௝כ ൅ ܤ௜כ,௝כሻ , then remove 
ܣ௞ from ࡭ and return to Step 1. 
Step 3. Allocate ܯ௞ in ܭ௜כ,௝כ.  If there are unused slots in 
ܭ௜כ,௝כ,  allocate the WISH part of ܣ௞. In case that only partial 
WISH part is mapped, unmapped WISH part is returned to the 
scheduler. Remove ܣ௞ from ࡭. 
Before leaving this subsection, we present an example to 
explain the operation of the proposed algorithm. Assume that 
ݏ ൌ 12 and ܿ ൌ 30 and there are 360 slots in total. There are 
ten MSs with the request set A as shown in TABLE I. and the 
sum of all requests is equal to 360, in which the sum of the 
MUST part of all requests is equal to 180. 
MUST
WISH
Part A 
Part B 
Part C 
 
Figure 5.  Average allocated slots of the MUST part vs. number of MSs 
 
Figure 6.  Average unused slots vs. number of MSs 
 
Figure 7.  Average over allocation slots vs. number of MSs 
V. CONCLUSION 
This paper presented a novel downlink burst allocation 
algorithm for two-level requests in WiMAX networks. The 
proposed algorithm introduced data mapping algorithm (the 
first phase and the second phase), it can effectively prioritizes 
the sensitive real-time traffic. Similar to eOCSA, the proposed 
algorithm meets the rectangle shape allocation constraint, 
achieves high throughput by considering mapping the larger 
resources first. The basic idea of our proposed algorithm is to 
remove less the WISH data and fit in the MUST data as much 
as possible. The performance of the proposed algorithm is 
compared with that of eOCSA. Simulation results show that the 
proposed two-level requests algorithm outperforms eOCSA. 
 
Figure 8.  Average efficiency vs. number of MS 
 
REFERENCES 
 
[1] IEEE 802.16e-2005, “IEEE Standard for Local and Metropolitan Area 
Networks – Part 16: Air interface for Fixed Broadband Wireless Access 
systems – Amendment 2: Physical and Medium Access Control layers 
for combined fixed and mobile operation in licensed bands and 
Corrigendum 1,” February 2006. 
[2] Juan I. del-Castillo, Francisco M. Delicado, Jesús Delicado and Jose M. 
Villalón “OFDMA Resource Allocation in IEEE 802.16 Networks: A 
Performance Comparative” in Wireless and Mobile Networking 
Conference (WMNC), 2010 Third Joint IFIP. 
[3]  Yanqun Le, Yi Wu, Dongmei Zhang “An Improved Scheduling 
Algorithm for rtPS Services in IEEE 802.16” 2009 IEEE. 
[4] C. So-In, R. Jain, and A. Al-Tamimi, “Scheduling in IEEE 802.16e 
Mobile WiMAX Networks: Key Issues and a Survey,” in IEEE Journal 
on Selected Areas in Comm., vol. 27, no. 2, pp. 156-171, Feb. 2009 
[5] M-R. Garey and D-S Johnson, “Computers and Intractability: A Guide 
to the Theory of NP-Completeness,” W.H. Freeman, 340 pp., Jan. 1979. 
[6] I. Gutiérrez; F. Bader; R. Aquilué; J. Pijoan, “Contiguous Frequency-
Time Resource Allocation and Scheduling for Wireless OFDMA 
Systems with QoS Support”, EURASIP Journal on Wireless 
Communications and Networking. Volume 2009, Article ID 134579, 
pages 12. 
[7] T. Ali-Yahiya; A. Beylot; G. Pujole; “Downlink Resource Allocation 
Strategies for OFDMA based Mobile WiMAX”. Telecommunication 
System;Vol 44, no.1-2, June 2010. pp. 29-37. 
[8] WiMAX Forum, “WiMAX System Evaluation Methodology V2.1,” Jul. 
2008, 230 pp. URL=http://www.wimaxforum.org/technology/documents 
[9] A. Bacioccola; C. Cicconetti; L. Lenzini; E. Mingozzi, A. Erta, “A 
Downlink Data Region Allocation Algorithm for IEEE 802.16e 
OFDMA”, 6th International Conference on Information, 
Communication and Signal Processing, pp. 1-5, December 2007. 
[10] T. Ohseki, M. Morita, and T.Inoue, “Burst Construction and Packet 
Mapping Scheme for OFDMA Downlinks in IEEE 802.16 System,” 
Proceeding of IEEE Global Communications Conference (IEEE 
GLOBECOM), 2007. 
[11] C. So-In, R. Jain, and A. Al-Tamimi, “OCSA: An algorithm for Burst 
Mapping in IEEE 802.16e Mobile WiMAX Networks,” To appear in the 
15th Asia-Pacific Conference on Comm. (APCC 2009), Oct. 2009. 
[12] Chakchai So-In, Raj Jain and Abdel-Karim Al Tamimi “eOCSA: An 
Algorithm for Burst Mapping with Strict QoS Requirements in IEEE 
802.16e Mobile WiMAX Networks” Singapore, February 26-28, 2010. 
[13] Sarigiannidis, P.G., Louta, M., Stratogiannis, D.G., Tsiropoulos, G.I., 
“Towards a QoS-Aware IEEE 802.16 Downlink Sub- Frame Mapping 
Scheme,” To appear in IEEE GLOBECOM Workshops, Dec. 2010. 
0,0
1
1= , where                                                                                                                                                           (6)
( )
(1 (2 ) )(1 ) (1
=
m
b
C f
W p p
f
+
+
− − + − 1
' 1 1 ' ' 1 ( ')
2 )(1 )                                                ,  '.
2(1 2 )(1 )
(1 (2 ) )(1 ) (1 2 )(1 ) 2 (1 2 )(1 ) ,  '.
2(1 2 )(1 )
m
m m m m m m
p p m m
p p
W p p p p W p p p m m
p p
+
+ + + −
⎧ − ≤⎪
− −⎪⎨
− − + − − + − −⎪ >⎪
− −⎩
 
source station does not receive the ACK packet, it schedules a 
retransmission and the backoff operation restarts. 
The backoff count value is chosen uniformly in [0, Wi -1] 
where Wi is the current contention window size at ith retry. At 
the first transmission attempt, W0 is equal to the minimum 
contention window size denoted by W. When the station 
detects a fail transmission, it will double Wi until Wmax is 
reached. Let m and m’ be the retry limit and the maximum 
number that Wi can be doubled, respectively. We have 
'
2 ,  ',
=                                                             (1)
2 ,  '.
i
i m
W i m
W
W i m
⎧ ≤⎨
>⎩
 
When the station fails to transmit at the mth retry, it drops the 
current packet and starts a new transmission with W0 = W.  
The basic idea behind the proposed MAC is to reduce the 
number of stations contending wireless medium during the 
backoff process of a tagged station. Our approach is to 
postpone the first transmission attempt of a new head of line 
packet for numerous slots. Because the contention cycles of 
some active stations may be delayed, our scheme is named 
delayed contention DCF. In this manner, collided packets, if 
they exist, will have a higher chance of being transmitted and 
their delay can be shortened. In addition, the traffic entering 
the network can be shaped because every packet reaching the 
head of line is postponed. As a result, the collision probability 
can be controlled and channel utilization is improved. Most 
important of all, this idea could be implemented very easily by 
modifying the calculation of the backoff counter in a station as 
follows. 
random( ),  for 1st transmission,
Backoff counter   (2)
random( ),  for retransmission,
o
i
C W
W
+⎧
= ⎨⎩
where random(Wi) is a function that uniformly generates a 
random number in [0, Wi -1], and C is a constant variable 
denoting how many extra slots a station needs to backoff for 
the first transmission of a head of line packet. Other parts of 
the MAC operation remain the same as in the DCF protocol.  
III. MATHEMATICAL ANALYSIS 
This paper adopts the Markov chain model presented in [3-5] 
to analyze the proposed protocol. Fig. 1 shows the model for a 
tagged station, where each state (s(t),b(t)) represents its current 
retry stage and backoff counter. Let bi,k be the stationary 
distribution of the of the Markov chain. Assuming that   each   
transmission   attempt   has   the   same    collision  probability 
denoted by p, we have 
0,0 0,1 0,C-1 0,C+W0-2 0,C+W0-1
1 1 1
1,0 1,1 1,2 0,W1-2 0,W1-1
1 1 1
m-1,0 m-1,1 m-1,2 m-1,Wm-1-2 m-1,Wm-1-1
1 1 1
m,0 m,1 m,2 m,Wm-2
1 1 1
0,C
m,Wm-1
1 p−
1 p−
1 p−
1
. . .
. . .
. . .
. . .. . .
. . . . . .
1
1
p
W
1m
p
W
−
m
p
W
0
1
W
 
Fig. 1.  The Markov chain model of the proposed system. 
 
,0 1,0 ,0 0,0*    for 0 .                      (3)
i
i i ib b p b p b i m−= → = < ≤  
Since the chain is regular, we have 
0
, ,0
0
0
0,0
0
0,0
,  for 0,                         (4)
,  for 0 and ,
,  for 0 and 
i k i
W kb b i
W
W k C b i k C
W
b i k C
−⎧
= >⎪⎪⎪
− +⎨
= >⎪⎪
= ≤⎪⎩
 
By using the normalization condition, we have  
01 1 1
, 0, ,
0 0 0 1 0
0,0 0,0
0
1    
( 1)
( ) ( ).                               (5)
2
i iW C W Wm m
i k k i k
i k k i k
im
i
i
b b b
p W
b C b C f
− + − −
= = = = =
=
= = +
−
= + = +
∑∑ ∑ ∑∑
∑
 
Finally, we can derive b0,0 as shown in (6). By adding the 
probabilities of the states with zero backoff counter, the 
transmission probability in a slot, which is denoted by τ, can 
be calculated by:  
1
,0 0,0
0
1 .                                                     (7)
1
mm
i
i
pb b
p
τ
+
=
−
= =
−
∑  
In the following, let us consider the worst case where N 
contending stations always have packets for transmission. The 
collision probability can be calculated by: 
0 10 20 30
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Delay (ms)
PD
F
 
 
DCF
DC-DCF
40 60 80 100
10
-6
10
-5
10
-4
10
-3
Delay (ms)
PD
F
 
 
DCF
DC-DCF
 
Fig. 3  The PDF of the MAC delay for N=30 
10 15 20 25 30 35 40 45 50
0
5
10
15
20
Av
er
a
ge
 M
AC
 
de
la
y 
(m
s)
Number of stations
 
 
St
an
da
rd
 
de
vi
at
io
n 
of
 
M
AC
 
de
la
y
0
10
20
30
40
Avg. delay (DC-DCF)
std. of delay(DC-DCF)
Avg. delay (DCF)
std. of delay (DCF)
 
Fig. 4  The delay in the MAC layer 
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
data rate per other station (Mbps)
Co
llis
io
n
 
pr
ob
ab
ilit
y 
of
 
ta
gg
e
d 
st
at
io
n
 
 
DC-DCF
DCF
congestednon-congested
 
Fig. 5  The collision probability of the tagged station 
 
This means that DC-DCF is able to provide better delay 
performance because the probability that the delay is over a 
threshold can be significantly reduced. Fig. 4 shows the 
average MAC delay and the standard deviation of the MAC 
delay. One drawback of DC-DCF is that the average MAC 
delay under the saturated networks is increased slightly 
(approximately 6.9% for the case of N=30). Nevertheless, DC-
DCF had an interesting property that the standard deviation of 
MAC delay was almost constant, while that of DCF increased 
with the network size. According to the classical queueing 
theory, the queueing delay for an M/G/1 is 
2
,                                                               (11)
2(1 )queue
xd λ
ρ
=
−
 
where λ is the packet arrival rate, x is the service time, and 
ρ=λ*   . If we model a station as an M/G/1 queue, the service 
time in the queueing model is equal to the MAC delay. 
Equation (11) shows that the queueing delay is proportional to 
the second moment of the MAC delay. Because the second 
moment is equal to the variance of x plus the square of     , the 
queueing delay of DC-DCF should be much smaller than that 
of DCF for large networks. Next, we evaluate the proposed 
protocol by NS2 to verify the performance for a more realistic 
scenario. 
B. End-to-end delay in a real network 
To investigate the performance of DC-DCF under a real 
network, we also ran simulations by NS2 for N=30. The 
implementation was very easy by slightly modifying the 
backoff timer which is used to control the instant of 
transmission. When the current contention window is equal to 
W, extra C* slots are added to the backoff counter of the packet 
in the MAC layer because it is at its first transmission attempt. 
We tagged the first station to see its performance under 
different loadings. Each station had one UDP flow which was 
generated according to the Poisson process with the fixed 
packet size equal to 1000 bytes. The data rate for the tagged 
station was fixed at 0.5Mbps, while the data rates for others 
were adjusted from 0.1Mbps to 1.0 Mbps to simulate dynamic 
network loading. The simulation time is 1000s. Fig. 5 shows 
the collision probability of the tagged station. The collision 
probability for DCF increased dramatically with the traffic 
loading as expected. On the other hand, the capability of DC-
DCF to delay the contention of the first transmission 
effectively reduced the collision probability under heavy loads. 
As the data rates of other stations increased, the network 
became congested and similar to the saturated case. We can 
divide the simulations into two parts: the congested region and 
the non-congested region. The collision probability stayed 
around 0.196 at the congested region, which also validated the 
Markov chain model presented in Section 3. 
Fig. 6 shows the end-to-end delay of the tagged station, 
which includes the MAC delay and the queueing delay. At the 
non-congested region, most packets can be sent quickly 
because the overall traffic in the network is light. In this case, 
the MAC delay dominated the end-to-end delay. Adding extra 
C* slots for the first transmission attempt in DC-DCF forced 
the packets to  wait  longer  such  that the MAC delay is larger.  
x
x
 7
四、建議 
可以直接與國外學者討論是一個很難得的經驗，本人非常感謝國科會可以提
供補助參與國際活動，也深切盼望未來國科會可以持續補助，讓國內的研究人員
可以有更開闊的視野。不過近來註冊費有越來越貴的趨勢，以本次參加 VTC來
說，IEEE會員的早鳥註冊費就要 825美金，台幣將近 2萬 5千元，或許未來經
費的補助上可以多放寬一些。 
 
五、攜回資料名稱及內容 
共攜回會議論文一份，於 USB隨身碟中。 
 
六、其他: 照片剪影 
  
 9
Poster session與廠商展示館 
 
 
 
 
 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：郭耀文 計畫編號：100-2221-E-260-028- 
計畫名稱：提供服務品質保證之 CSMA/CA 無線網路的設計與分析 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 1 1 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：■已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本計畫的目標是針對基於 CSMA 協定的無線區域網路進行研究與設計，目標是提供服務品
質保證與提高通道的利用率，這方面的研究已經進行多年，許多文獻都是基於既有的協定
去分析或是最佳化，然而還是有些問題需要克服，尤其隨著無線傳輸技術的進步，無線區
域網路已經在許多熱點被建置來服務大量的使用者，而目前的協定在用戶數量多的時候，
會有嚴重的碰撞問題，與協定的 overhead，有鑑於此，本計畫提出一個全新的架構，包含
佇列管理與媒體存取控制協定，來徹底解決這些問題，並開發 NS2 下的軟體模組，進行一
個比較接近實際情況的實驗，由實驗結果來看，本計畫提出的系統不會發生碰撞，解決了
上下行吞吐量不對稱的問題，減少了協定的 overhead，並可以提供即時性訊務一個低延遲
與低遺失的傳輸環境，整體而言，我們已經達到了計畫的預期目標。尤其我們的系統是一
個全新的設計，具有創新性，因此，頗具學術價值，目前已經發表兩篇國際會議論文，計
畫內容目前正積極整理準備，預計在媒體存取層協定與佇列管理模組這兩部分，可以寫成
兩篇論文，投稿於國際期刊。此外，由於是新的設計，在數學模型的建立與數學分析上，
是我們未來將繼續研究的主題，加上完整的數學分析後，相信可以投稿到高品質的國際期
刊上面。 
除了學術的價值之外，由於本計畫採用 NS2 模擬軟體，它是一套免費的軟體，但也因為是
免費的，因此使用上都必須自己來，它是採用物件導向的架構設計，對於電機系學生而言，
有不少障礙，不過在這一年當中，我們陸續克服程式上的障礙，從了解系統開始到最後完
成了模組的開發、測試與實驗，讓學生除了理論之外，也可以學習到實務上的程式設計技
