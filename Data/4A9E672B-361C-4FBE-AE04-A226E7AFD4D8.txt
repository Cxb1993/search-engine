 1 
摘要 
在先前的研究成果中，我們將攝影機結
合 GPS (Global Positioning System)行動裝置
來提供一個全新的視覺追蹤服務，如此監視
人員便能夠在攝影機的即時影像上針對特
定目標物體進行視覺追蹤。然而為了達成這
項服務，攝影機必須事先經過校正，透過五
組 GPS 座標與對應影像座標資料來計算出
攝影機座標轉換時所需的內部參數(intrinsic 
parameter)與外部參數(extrinsic parameter)，
這些參數可以用來將 GPS 座標轉換為影像
座標，因此可以在即時影像上標示出目標物
體的所在位置。先前攝影機校正作法主要有
兩個問題：一是未校正攝影機以手動取得五
組對應座標點的方式非常麻煩；二是已校正
攝 影 機 若 是 調 整 其 可 視 區 域 (FOV: 
Field-of-View)後則必須重新校正，造成不
便。因此本論文針對上述問題分別提出自動
化的校正方法來加以克服，首先針對未校正
攝影機的部份，所設計的自動校正方法是利
用校正人員 GPS 座標的移動向量與影像上
所有移動物體座標的移動向量進行比對來
定位出校正人員，然後就可以依序建立五組
校正所需的對應座標點。另外針對已校正攝
影機調整後的自動校正方法，則是針對攝影
機調整前、後兩張影像進行特徵點匹配以計
算出影像的調整量，接著利用調整量來修正
GPS 座標轉換後所得到的影像座標。我們也
分別針對上述兩種校正方法進行實驗分
析，未校正攝影機的實驗是比較手動與自動
取得的五組對應座標點在座標轉換結果的
準確性，實驗結果中顯示手動與自動校正的
平均誤差分別相差 2 pixels 與 11 pixels，這
表示自動校正方法可以達成與手動校正方
法類似的準確性，但是卻解決了繁瑣的手動
校正程序。另外，針對已校正攝影機的實驗
部份，分析了攝影機往上下左右四個方向調
整後，影像座標的變化以及修正過後定位誤
差的變動情形，實驗結果顯示我們提出的方
法能夠有效降低誤差的增加，克服攝影機調
整後需要重新校正的不便。 
 
Abstract 
 In the previous study, a GPS-enabled 
(global positioning system) device is 
incorporated into visual surveillance to 
provide a novel visual tracking service. A 
surveillant can track a target object carried a 
GPS-enabled device on the real-time camera 
image. However, a camera must be calibrated 
before providing such service. Five point 
correspondences, i.e., a GPS coordinate and 
its corresponding image coordinate, must be 
established to generate the intrinsic and 
extrinsic parameters needed for coordinate 
transformation. There are two main drawbacks 
in the previous approach; one is the 
troublesome on establishing five point 
correspondences manually for an uncalibrated 
camera, the other is the inconvenience to 
recalibrate a calibrated camera after adjusting 
its FOV (field-of-view). In this paper, two 
automatic calibration methods are proposed to 
overcome the above drawbacks separately. For 
an uncalibrated camera, the GPS moving 
vector of the operator is matched with the 
moving vectors of those moving objects in the 
camera image to locate the operator on the 
image. Then, five point correspondences can 
be established automatically. For the 
recalibration of a calibrated camera, the 
feature points are extracted separately from 
two images before and after adjustment. Then, 
the correlations of two sets of feature points 
are analyzed and used to obtain the offsets of 
camera adjustment in x and y directions. The 
offsets are used to adjust the image coordinate 
transformed from the GPS coordinate. Two 
experiments are also designed for two 
automatic calibration methods separately. For 
the automatic calibration method for the 
uncalibrated camera, the locating errors are 
estimated for the five point correspondences 
that are established manually or automatically. 
The differences of locating errors of manual 
and automatic calibration are only 2 and 11 
pixels, respectively. The results show that the 
locating errors of the automatic and manual 
calibration methods are similar by overcoming 
the troublesome drawback. For the experiment 
of the adjustment of calibrated camera, the 
variations in image coordinates and the 
locating errors are estimated for various 
offsets in x and y directions. The results show 
that the proposed method is useful to reduce 
the locating error without recalibrating the 
camera. 
 3 
coordinate in Tsai’s method. Therefore, the 
coordinate in DMS format is transformed to 
the format of the WGS84 (World Geodetic 
System 1984) coordinate system. Then, the 
WGS84 coordinate is transformed to a TM2 
(2-degree Transverse Mercator) coordinate 
which is popular used in digital map. That is, 
one point correspondence used in GODTA 
consists of one TM2 coordinate and the 
corresponding image coordinate. The matrices 
T and R are shown in Eq. (1). For a new TM2 
coordinate, ( )',',' zyx , the corresponding image 
coordinate,( )',' vu , can be computed by using 
Eq. (2).  












=










=
1000
0
0
0
333231
232221
131211
rrr
rrr
rrr
R  ,
t
t
t
T
z
y
x
        (1) 
z
y
z
x
tzryrxr
tzryrxrfv
tzryrxr
tzryrxrfu
+++
+++
=
+++
+++
=
'''
'''
'
'''
'''
'
333231
232221
333231
131211
           (2) 
The prototype of GODTA is shown in 
Figure 1. The location of an object can be 
displayed on a digital map and the object can 
be marked on the real-time camera image 
simultaneously. Comparing with the red dot 
on the digital map, the real-time image on the 
right-hand side is easier to realize the situation 
of the object. The inaccuracy of GPS 
coordinates causes that the transformed image 
coordinate cannot match the object location 
precisely. Some moving object detection 
techniques can be integrated into GODTA to 
mark the object precisely.   
 
Figure 1: The prototype of GODTA 
 
3. Calibration and Rectification 
Methods 
When the number of cameras is large, the 
camera calibration becomes a troublesome 
problem. It is necessary to increase the 
efficiency of the calibration procedure. There 
are two situations of camera calibration. One 
is to calibrate a new, i.e., uncalibrated, camera. 
The other is to re-calibrate a camera when its 
FOV is adjusted. Therefore, an automatic 
calibration method and a rectification method 
are designed for the above situations 
separately. They are presented in the following 
subsections. 
3.1 The calibration method of a new 
camera 
For the manual camera calibration in the 
previous study, two operators are needed to 
get the five point correspondences. The first 
operator carries the GPS receiver and walks 
into FOV of the camera. The second operator 
monitors the real-time camera image to record 
the image coordinate and the corresponding 
TM2 coordinate manually when the first 
operator is still. Obviously, the above 
procedure is time-consuming and should be 
automated.  
In order to automate the above procedure, 
the locating of the operator is the first and 
primary task. The TM2 coordinates of the 
operator are matched with those moving 
objects in the camera image. However, it is 
unable to know the location or direction of the 
operator according to his TM2 coordinates 
before the camera calibration. Therefore, the 
vector angles (VAs) of successive moving 
vectors formed by the TM2 coordinates are 
matched with those formed by the image 
coordinates of moving objects. The principle 
is described by an example shown in Figure 2. 
There are three curves of VAs in the figure. 
Two curves represent the VAs of TM2 and 
image coordinates of the operator. The third 
curve represents the VA of an unknown object. 
The maximum VA is 180 degrees. When an 
object moves straightly, the VA is approach to 
zero degree. Oppositely, a large VA is found 
when the object turns around. By observing 
these three curves, the operator turns around 
twice and causes two peaks in the curves. The 
curves of VAs formed by TM2 coordinate and 
image coordinates have the similar peaks, but 
cannot found on the curve of the unknown 
object. According to such observation, the 
operator can be located by filtering out those 
moving objects without the similar situation 
when the turn around of TM2 coordinates is 
 5 
the five point correspondences are established 
in turns and shown on the right-hand side. In 
Figure 5(b), the client tool sends the TM2 
coordinate to the server tool every second 
after clicking the “Start” button. When one 
point correspondence is generated by the 
server tool, it is transmitted to the client tool 
for the confirmation of the operator. The 
operator can restart the calibration procedure 
if the established point correspondence is not 
satisfactory. In Figure 5(c), the tool loads a set 
of testing images and the corresponding TM2 
coordinate. One of the testing images is shown 
on the left-hand side. All the image 
coordinates transformed from the TM2 
coordinates are listed on the right-hand side. A 
red circle whose center is at the image 
coordinate transformed from the 
corresponding TM2 coordinate is depicted on 
the testing image. The transformation is 
performed based on manual and automatic 
five point correspondences separately in order 
to evaluate the accuracy of the proposed 
method. 
  
(a) 
  
(b) 
 
(c) 
Figure 5: Screen shots of three tools (a) server 
tool (b) client tool (c) verification tool  
 By using the above tools, two results are 
used to evaluate the performance of the 
automatic calibration method. One is the 
elapsed time and successful rate of the server 
tool on locating the operator under various 
number of moving objects. The other is the 
locating error (LE) of the established five 
point correspondences. LE is the Euclidean 
distance between the actual coordinate and the 
center of the circle in Figure 5(c). After the 
experiments, the operator is located 
successfully for 86 times among 105 testing. 
The locating successful rate is 81.9 
percentages. The number of moving objects is 
ranged from several to 50 persons. The server 
can still be located the operator successful 
from the most about 50 persons. The elapsed 
time on locating the operator is from 5 to 21 
seconds. The average time is 11.4 seconds. It 
means the server tool can locate the operator 
within an short period 
For the second result of the LE, 30 
testing images and the corresponding TM2 
coordinates are used to compute the LE for the 
five point correspondences acquired manually 
or automatically. The average LE is 13.6 and 
16.2 pixels for manual and automatic 
calibration, respectively. The difference of LE 
is only 2.6 pixels. It means that the accuracy 
of the proposed automatic calibration method 
is close to the manual calibration method. 
 
4.2 The experiment of a calibrated camera 
In this experiment, the FOV of a 
calibrated camera is adjusted towarding up, 
down, left and right directions separately. The 
adjustments are from 40 to 200 for every 40 
pixels. Then, the average LE of six testing 
locations is computed to evaluate the 
 7 
Human”, IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. 
28, no. 9, 2006, pp. 1513-1518. 
[7] R. I. Hartley, “Self-calibration from 
multiple views with a rotating camera,” 
ECCV, 1994. 
[8] J. M. Frahm and R. Koch, “Camera 
calibration with known rotation” , in 
proceedings Ninth IEEE International 
Conference on Computer Vision, pp. 
1418-1425, vol. 2, 13-16 Oct. 2003. 
[9] Z. Zhang, “Camera calibration with 
one-dimensional objects”, IEEE 
Transactions on Pattern Analysis and 
Machine Intelligence, vol. 26, issue 7,  
July 2004, pp. 892 – 899. 
[10] R.Y. Tsai, “A versatile camera 
calibration technique for high-accuracy 
3D machine vision metrology using 
off-the-shelf TV cameras and lenses”, 
IEEE Journal of Robotics and 
Automation, vol. 3, no. 4, 1987, pp. 
323-344. 
[11] R.K. Lenz, R.Y. Tsai, “Techniques for 
calibration of the scale factor and image 
center for high accuracy 3D machine 
vision metrology”, Proceedings of the 
IEEE International Conference on 
Robotics and Automation, vol. 4, 1987, 
pp. 68-75. 
[12] L.G. Shapiro, G.C. Stockman, 
“Computer vision”, Prentice-Hall, 2001, 
pp. 444-456. 
[13] J. W. Hsieh, “Fast stitching algorithm for 
moving object detection and mosaic 
construction”, Image and Vision 
Computing, vol. 22, 2004, pp. 291-306. 
 
 9 
可供推廣之研發成果資料表 
 □ 可申請專利  █ 可技術移轉                                    日期：98 年 9 月 13 日 
國科會補助計畫 
計畫名稱：結合移動物體之 GPS 座標於視覺監視方法的相關研究 
計畫主持人：廖珗洲         
計畫編號：NSC 97-2221-E-324-043   學門領域：影像處理 
技術/創作名稱 結合 GPS 定位系統與攝影機之視覺追蹤方法 
發明人/創作人 廖珗洲 
中文：先前視覺追蹤技術不易辨識移動物體身份資料，而本技術結
合現有 GPS 定位系統與攝影機之後，可以針對任一移動物體提供
視覺追蹤的服務，對於兒童、老人或者車輛等物體，可以容易地透
過即時視覺資訊可以更明確地得知其實際狀況。 
技術說明 英文：It is difficult to identify the moving objects for the previous 
visual tracking techniques. In this technique, the incorporation of GPS 
system and Cameras enables the identification and tracking of any 
moving object. It is easily to realize the situation from the real-time 
visual information. 
可利用之產業 
及 
可開發之產品 
監視系統、車隊管理系統 
技術特點 
 提供視覺資訊來強化 GPS 追蹤系統的不足 
 提供多攝影機中相同物體比對與辨識能力 
推廣及運用的價值 
 拓展 GPS 追蹤系統相關產業規模 
 加速以 GPS 系統的普及程度 
 區隔現有產品市場，提供系統技術優勢 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位研發成
果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
  
 
附件二 
