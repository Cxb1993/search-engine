 2
車頭方向，對於狹隘的地形，若車體的迴
轉半徑過大，則機器人就會被限制而無法
達成目的。為了解決此問題，許多關於
Holonomic 系 統 或 具 有 全 向
(Omnidirectional)移動式機器人被提出來例
如：兩足機器人(Biped Robots)、全向輪移
動式機器人等。其中全向輪經過特殊的設
計，使車子可以做任一方向的平移而無須
改變車子的姿態，讓移動式機器人更提高
了機動性，在執行任務上能更有效率。 
對於移動式機器人的定位問題，至今
已有了許多不同的解決方式，而推算機器
人座標位置的量測工具也分別有許多種，
例如:馬達編碼器、GPS 導航系統、超音波
感測器、CCD 攝影機、紅外線感測器、陀
螺儀及加速規等；而這些測量儀器在實際
系統的使用上仍有些許的限制，例如:馬達
編碼器會因為車體的打滑而產生累積誤
差，陀螺儀、加速規與 GPS 導航系統會因
為精確度的不足而產生誤差，紅外線與超
音波感測器會因為感測距離而有所受限，
不能感測出大範圍的環境資訊，CCD 攝影
機雖然改善上述缺點，但傳統的攝影機由
於視野狹小，所能觀察的範圍有限，移動
之目標物容易超出視野範圍之外。而對於
寬廣的環場影像，具有類似於昆蟲複眼之
廣泛視野範圍，則可以應用在機器人之視
覺上，不管是對其安全性、導航或追尋能
力，都能有所提升。 
視覺伺服(Visual Servo)是藉由視覺所
得到的資訊作為機器人判斷策略的依據。
最早的視覺伺服系統是由 Park 和 Hill 兩人
提出[1]，整個架構分為影像處理單元和伺
服控制單元，即是使用攝影機拍攝周遭環
境之影像提供系統決定下一步之行為。近
年來計算機的速度大幅提升，以視覺為回
授的機器人因而快速興起，且辨識的對象
也逐漸由靜態影像轉變到連續的影像序
列。 
移動式機器人之控制面臨著非線性、
不確定性、系統參數變化、與未知干擾等
諸多問題，因此如何設計出一個兼顧強
韌、適應、以及控制效果的控制策略一直
是控制技術研究的重要研究課題之一。在
輪型移動式機器人中對於路徑追蹤控制的
問題，曾有許多解決辦法的提出，例如：
適應型滑動模式控制器[2]、多變數滑動模
式控制方法[3]、線性化動態模型[4]、與輸
出輸入線性化[5]等。藉由移動式機器人的
輪子與地面摩擦力[6]的關係，可建立摩擦
力的模型及相關參數，以獲得一較完整的
機器人動態模式。如果移動式機器人的位
置離開所設計的軌道位置，全向移動式機
器人需要知道目前以及相對於道路的位
置，以順利返回到原本的軌跡上。在
[7][8]，移動式機器人利用設計出來的控制
器並與透過影像處理獲得的視覺資訊使得
移動式繼器人能夠達到追隨一個指定的物
體使其完成目的。 
本 研 究 乃 藉 由 全 方 位 攝 影 機
(Omni-directional Camera)得到類似昆蟲的
寬廣視野範圍，並偵測出在空間中移動之
目標物，提出以視覺輔助機器人位置與姿
態伺服控制完整之策略及方法，以驅動裝
設全向輪之移動式機器人進行目標追循之
任務。 
 
三、全方位攝影機系統 
一般雙眼的立體視覺是使用三角測量
(Triangulation)的方法，確認出空間物體的
位置。此種方式在處理相關性計算時極為
耗時。曲面鏡全方位攝影機即是在傳統攝
影機視野中加入一個曲面鏡，鏡子的凸面
對著攝影機。利用曲面鏡的反射將周圍的
環境投影到影像平面上，如圖一所示。如
此所產生的影像即稱為全方位影像。 
 
 
圖一  全方位攝影機系統之示意圖 
 
全方位影像與傳統影像比較，其優點
為具有廣泛的視角範圍。傳統影像視角約
為30°~60°，全方位影像的視角在方位角
(Azimuth) 可 達 360° ， 仰 俯 角 (Elevation 
Angle)約為100°~135°，如圖二所示。 
 
 4
是 CpO 與通過 CO 的水平面之夾角，a、b 和
c 則是雙曲面鏡數學模型的參數。空間中點
P與影像平面之點 p之幾何投影關係可推
導如下： 
 
2 2 tanz x y α= + ⋅                     (3) 
2 2
1
2 2
( )sin 2tan
( )cos
b c bc
b c
γα γ
− + −= −               (4) 
1
2 2
tan f
x y
γ −=
+
                     (5) 
 
(2)、(3)、(4)和(5)式，敘述了空間中點P與
影像上點 p的關係。即可以從影像上一點
( ),p i j ，決定出一條唯一且通過點 P與焦點
MO 的直線，或 P點之方位角ϕ與仰俯角α。
綜合以上結果，空間中任一點 ( ), ,P x y z 點
投影到影像平面上的座標 ( ),p i j 可由下式
予以轉換[2]： 
 
2 2
2 2 2 2 2
( )
( ) 2
f b c xi
b c z bc x y z
−=
+ − + +
           (6)
 
2 2
2 2 2 2 2
( )
( ) 2
f b c yj
b c z bc x y z
−=
+ − + +
           (7) 
 
( , , )P x y z
x
y
( , )P i j
ϕ
image plane
mirror
i
j
 
圖五  沿 z 軸觀看空間點 P之方位角 
 
四、影像處理及攝影機校正 
在彩色的模型上，本研究採用 HSV 色
彩模型，HSV 為色彩的三種基本屬性：色相
(Hue)、飽和度(Saturation)、與明度(Value)。
這三種屬性可以建構出一個立體模型為
HSV 圓錐，如圖六所示。RGB 色彩模型的
缺點為必須用到所有的顏色疊加以得到真
正色彩；而 HSV 的色相是直接得到顏色的
種類。且當環境有不均勻的光照時，因光
線量不一樣而造成亮度不一致，如此的情
況在 RGB 色彩模型下將不好處理。但在
HSV 模型下，彩度並不會因為光照強度而
改變，會受到影響的是飽和度和明度。因
此HSV模型對於光照不均及陰影等現象比
RGB 模型有更強健的處理能力。 
 
 
圖六  HSV 圓錐 
 
Scaramuzza[9][10]所提供的校正工具
箱能找出曲面鏡方程式 ( )f θ 、因曲面鏡中
心線沒有與攝影機光軸重合造成的偏移影
像中心 ( ),c ci j 、仿射轉換矩陣係數C 、D、
E 等各種參數。曲面鏡的立體結構可由偏
移的影像中心為中心軸位置，利用曲面鏡
方程式繞中心軸一圈即可得到。在得到空
間至影像平面的投影關係式參數後，即可
以真正計算空間中任何一點 ( , , )x y z 投影至
全方位影像上的位置 ( ),i j 其關係如下： 
 
2 2
( )
1
c
c
ii C D xf
jj E yx y
θ ⎡ ⎤⎡ ⎤ ⎡ ⎤ ⎡ ⎤= + ⎢ ⎥⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦+ ⎣ ⎦           (8) 
 
空間中座標經過曲面方程式與仿射變
換轉換後，就得到與曲面鏡中心點的相對距
離，再加上曲面鏡中心點位置就獲得了影像
上真正的位置。除了可處理將空間投影至影
像的正轉換以外，也可以進行逆轉換。然而，
在逆轉換時會出現多重解的困難。空間中不
只一個位置投影到影像上可以是同一位置；
反之從影像上的位置投射回空間中會變成無
限多組解的問題。因此，要直接從影像上計
算出空間中實際的點是有困難的。而為了能
夠讓解唯一，可以加入額外的一個條件來限
制無限解的可能。此處所選擇的條件是將空
間中的點設定在單位球面上，式子(10)即是
將空間中的位置 ( , , )p p px y z 正規化後得到在
單位球面上的三維座標 ( , , )s s sx y z 。其轉換方
程式如下： 
 
( )1 2 2
1
p c
p c
p p p
x i iC D
y j jE
z P x x−
−⎡ ⎤ ⎡ ⎤⎡ ⎤=⎢ ⎥ ⎢ ⎥⎢ ⎥ −⎣ ⎦ ⎣ ⎦⎣ ⎦
= +
                 (9) 
 6
可以很方便地求得像機內部參數。圖十與
圖十一分別顯示相機校準所使用的影像，
以及利用所提供工具箱校準程式所偵測出
的棋盤角點並找出正交軸。 
 
 
圖八  全向視覺輔助全向移動式機器人實體 
 
PW
M
 si
gn
al
 
圖九  全向視覺輔助全向移動式機器人系統 
 
Calibration images
 
圖十  校正使用之影像 
 
Image 1
The corners have been renumbered in the right order.
Press ENTER to continue.
 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
X
Y
O
200 250 300 350 400
40
60
80
100
120
140
 
圖十一  棋盤角點偵測並找出正交軸 
經過校準的程序之後，利用全向攝影
機擷取特定顏色之目標物並進行追蹤運
動。本實驗所選定的特徵顏色為螢光綠，
目標物實際為一直徑為 15 公分之球體，且
實驗中目標物乃以不規則方式在地面上滾
動。為了表達追蹤移動物體的情況，設定
目標物體與移動平台間距離小於 0.5 m
時，定義為追循目標達成，以避免目標物
進入車體底部的盲區。此外，並給予目標
物體面積大小的門檻值，以作為一個條件
限制。使當物體過小時不予以追尋，做為
判斷物體過遠或雜訊之影響，以避免造成
誤判情況之出現。其主要的實驗程序大致
如下： 
1. 利用 HSV 找尋特定的目標物。 
2. 利用全向攝影機取得目標影像位置。 
3. 電腦得知影像座標再回傳給 DSP，計
算出平台與目標物之間的距離。 
4. 利用此距離得知平台需行進的方向與
位置，再經由控制器算出的馬達所需
的訊號，而達到目標追蹤的目的。 
 
為考量可能的任務需求，追循實驗包
含兩個類別，實驗一為單純的平移運動，
即只顧及車體之位置控制，而對於車體之
方向性不加限制；實驗二則為兼顧車體位
置與角度方向之追循控制。圖十二與十三
分別顯示實驗一與實驗二之運動目標物的
移動軌跡、方向角度，以及各個追循誤差。
圖(a)表示目標物移動軌跡，其平面座標的
原點為車體的初始位置。圖(b)呈現目標物
相對於大地座標原點的方向角度。實驗二
的目標物所在角度以人為方式設定，於時
間 5 至 12 秒間設定為 90 度，而在 20 秒之
後則為 0 度；至於其他時間則採不規則方
式運動。圖(c)則表示追循誤差，在實驗一
中追循誤差包含了平面 x 與 y 軸的距離誤
差；在實驗二則除了平面 x 與 y 軸的距離
誤差外，尚有角度誤差以呈現角度方向的
追循效果。實驗結果顯示不論是在單純平
移運動的實驗一或是兼顧車體角度方向之
實驗二，所發展出來的以全向視覺為基礎
之順滑模式控制策略均能提供滿意的運動
目標物追循結果。於是經由理論的推導以
及實際影像的校正測試，使得本研究得到
具體驗證。 
 
 8
mode control for autonomous diving and 
steering of unmanned underwater vehicles,” 
IEEE Journal of Oceanic Engineering, vol. 18, 
no. 3, pp. 327-339, 1993. 
[4]  Y. Kanayama, Y. Kimura, F. Miyaaki, and T. 
Noguchi, “A stable tracking control method for 
an autonomous mobile robot,” in Proceedings of 
the IEEE International Conference on Robot 
and Automation, pp. 384-389, 1994. 
[5]  D. H. Kim and T. H. Oh, “Tracking control of a 
two-wheeled mobile robot using input-output 
linearization,” Control Engineering Practice, pp. 
369-373, 1999. 
[6]  P. Dupont, V. Hayward, B. Armstrong, and F. 
Altpeter, “Single state elastoplastic friction 
models,” IEEE Transactions on Automatic 
Control, vol. 47, no. 5, pp. 787-792, 2002. 
[7]  L. Huang, Y.S. Lim, D. Li, and C.E.L. Teoh, 
“Design and analysis of four wheel 
omnidirectional mobile robot,” in Proc. of the 
2th International Conf. on Autonomous Robots 
and Agents, Palmerston North, New Zealand, pp. 
13-15, 2004. 
[8]  L. Freda, and G. Oriolo, “Vision-based 
interception of a moving target with a 
nonholonomic mobile robot,” Robotics and 
Autonomous Systems, vol. 55, no. 6, pp. 419-432, 
2007. 
[9]  D. Scaramuzza, A. Martinelli and R. Siegwart, 
“A flexible technique for accurate 
omnidirectional vamera calibration and structure 
from motion,” in Proceedings of IEEE 
International Conference on Computer Vision 
Systems, pp. 45, 2006. 
[10]  D. Scaramuzza, A. Martinelli and R. Siegwart, 
“A toolbox for easily calibrating omnidirectional 
cameras,” in Proceedings of IEEE International 
Conference on Intelligent Robots and Systems, 
pp. 5695-5701, 2006. 
[11]  A.M. West and H. Asada, “Design of ball wheel 
mechanisms for omnidirectional vehicles with 
full mobility and invariant kinematics,” ASME 
Journal of Mechanical Design, vol. 199, pp. 
153-161, 1997.  
[12]  Z. Zhang, “A flexible new technique for camera 
calibration,” IEEE Trans. Pattern Analysis and 
Machine Intelligence, vol. 22, no. 11, pp. 
1330-1334, 2000. 
 
出席「2011計算與電腦視覺國際研討會」報告
程 啟 正
國立中山大學機械與機電工程學系
一、 參加會議經過
2011計算與電腦視覺國際研討會(2011 International Conference on Computing
and Computer Vision, ICCCV 2011)於 2011年 7月 1日至 2日在尼泊爾首都加德滿
都(Kathmandu)之 The Dwarika’s Hotel舉行。主辦單位為國際電腦科學與資訊技術
學會(International Association of Computer Science and Information Technology,
IACSIT)，並由新加坡電子學會(Singapore Institute of Electronic, SIE)提供技術協
助。此會議提供了計算與電腦視覺跨領域的研究學者一個共同的論壇平台，以傳
述近期的研究成果。事實上，此會議為三合一綜合型國際性研討會之ㄧ，同時舉
辦的尚有 2011 軟體與電腦應用國際研討會 (2011 International Conference on
Software and Computer Applications, ICSCA 2011)，以及 2011電腦與企業管理國際
研討會 (2011 International Conference on Computer and Business Management,
ICCBM 2011)。今年會議的贊助單位還包括了巴基斯坦 University of Central
Punjab、四川大學、與貴州大學等。此次國際學術研討會經過嚴格審查過後，總
共接收了來自全世界 17個國家與地區之 37篇論文於研討會中口頭發表。
此次計算與電腦視覺國際研討會在尼泊爾加德滿都舉行。尼泊爾位於印度東
北邊，北鄰西藏，為一不靠海之內陸國家。尼泊爾面積不大，卻有著複雜多變的
地形。從海拔僅約 100 公尺的平原到超過 8,800 公尺的世界最高峰，境內海拔落
差之大，為全球之最。加德滿都為尼泊爾首都，位於加德滿都谷地，發展可遠溯
至西元第三世紀。而加德滿都谷地內包括加德滿都、帕坦(Patan)、與巴克塔布
(Bhaktapur)三處的杜兒巴廣場(Durbar Square)，以及帕蘇帕提拿(Pashupatinath)、
昌 古 納 拉 揚 寺 (Changu Narayan) 兩 座 印 度 寺 廟 ， 還有斯 瓦 揚 步 拿 寺
(Swayambhunath)、博達拿(Bouddhanath)二座佛塔早於 1979 年即登錄於聯合國世
界人類文化遺產。
西亞、伊朗、韓國、加拿大、立陶宛(Lithuania)、丹麥、智利、中國大陸、法
國、伊拉克、泰國、與台灣等大約 17 個國家地區的三十餘篇論文發表。台灣此
次共報告了 4篇論文。參與學校與研究單位包括了中山大學與台北科技大學等。
三、 與會心得與建議
此次會議筆者發表的論文題目是「移動式全向攝影機運動物體之偵測」
(Detection of Moving Objects with a Mobile Omni-directional Camera)，被安排於 7
月 2 日的下午場次。此論文內容為所指導碩士班學生周家至所撰寫碩士論文的部
分研究成果。本論文目的在針對移動式全向攝影機對於運動目標物發展偵測之方
法。全向攝影機具有寬廣的視角，可以掌握全方位的影像。以往運動目標物之偵
測，只能設定在靜態攝影機或是已知攝影機運動的狀況之下完成。本論文所探討
的課題為一全向攝影機架設在可進行平面運動之載具上。地板上傳回的影像正可
以作為估測載具車體之自我運動。利用此自我運動足以建構出地板運動的背景光
流。接著比較運動物體所造成的光流以及自我運動光流兩向量，即可偵測出週遭
的運動物體。實驗顯示即使在載具車體同時具有平移與旋轉的情況之下，仍能成
功地偵測出運動物體。會後本篇論文被此國際研討會評選為最佳論文。
儘管尼泊爾加德滿都擁有豐富的世界人類文化遺產，然落後的生活水準與週
遭相關匱乏的軟硬體設施仍使得投稿此國際學術會議的專家學者望之卻步，致使
此會議的規模臨時被大大地縮減。這也清楚顯示出成功的學術研討會議尚得有賴
於適當會議地點的選擇。然而，欣見台灣學術界仍有人注意到此會議並積極參
與，使得筆者不至於落單，同時反應出台灣該有的學術實力，總是好事一件。
四、 攜回資料
本屆會議 CD-ROM 格式論文集光碟片一張、以及紙本論文集 International
Proceedings of Computer Science and Information Technology, Vol. 9: Software and
Computer Applications一冊共計 295頁。
筆者與部份與會者合影 (後排左起第二人即為筆者本人)
筆者所報告論文被評選為最佳論文



國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/16
國科會補助計畫
計畫名稱: 全方位視覺輔助全向移動式機器人之智慧型控制
計畫主持人: 程啟正
計畫編號: 99-2221-E-110-070- 學門領域: 機器人學及應用
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
