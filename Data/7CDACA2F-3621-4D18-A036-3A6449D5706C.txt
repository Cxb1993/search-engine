行政院國家科學委員會補助專題研究計畫 ■ 成 果 報 告   □期中進度報告 
 
在不同機器學習模型下具自我調適能力的多種新型權重調整
方法 
 
 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號：NSC99-2221-E-022-009 
執行期間： 99 年 8 月 1 日至 100 年 7 月 31 日 
 
計畫主持人：黃淇竣副教授  國立高雄海洋科技大學資訊管理系 
共同主持人： 
計畫參與人員：林汶靜  國立彰化師範大學資訊管理所 
龔昱瑋  國立彰化師範大學資訊管理所 
王泰元  國立暨南國際大學資訊管理所 
鄭子敬  國立高雄第一科技大學系統資訊與控制所 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          ■涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
          
執行單位：國立高雄海洋科技大學資訊管理系 
中   華   民   國  100  年  10  月   20  日 
 2 
improved by individual learning machine 
weighting adjustment scheme. 
In this research project, novel adaptive 
weighting adjustment methods for different 
machine learning models will be proposed 
and investigated.  The weighting of each 
feature in a classification problem will be 
adjusted based on Taguchi methods.  In this 
manner, features with great importance will 
be found.  This weighting adjustment 
approach will be expected to have many 
advantages.  First, , noisy, irrelevant, or 
redundant features will be identified.  Thus, 
the performance (i.e. high classification 
accuracy) of the corresponding machine 
leaning or data mining method can be 
significantly improved.  The mining results 
can also be comprehended more precisely. 
Accordingly, novel adaptive weighting 
adjustment methods will be developed for 
homogeneous or heterogeneous ensemble 
learning.  The weighting analysis 
procedures in Grey theory will be used to 
adjust each individual homogeneous or 
heterogeneous learning machine.  As a 
result, the weighting of better individual 
homogeneous or heterogeneous learning 
machine will be increased for decision 
combination.  Meanwhile, the issues of 
diversities among different learning machines 
in heterogeneous ensemble learning will be 
addressed and investigated.  The proposed 
adaptive weighting adjustment methods will 
be expected to have many advantages.  First, 
the weighting of learning machines that offer 
superior performance will be increased for 
decision combination.  Meanwhile, the 
overall performance of the ensemble can be 
improved because the diversities among 
different learning machines are taken into 
consideration.  These proposed methods 
will be expected to yield superior 
performance, compared with other existing 
methods.    
Keywords: Machine Learning, Homogeneous 
Ensemble Learning, Heterogeneous 
Ensemble Learning, Feature Selection, 
Weighting Adjustment 
 
二、緣由與目的 
 
在機器學習領域中[1][2][3][4]，分類問
題內含一個樣本集合 ( 又稱為訓練集
(Training Set))，該集合是由多個已知類別
為何的樣本組成[83][110]，而一個樣本透
過一組特徵(Features)及一個或多個類別來
呈現。其中，有些特徵與分類問題或類別
直接相關(Revalant)，有些特徵則與分類問
題或類別不相關(Irrelavant)，此外，分類問
題亦有可能存在著雜訊 (Noisy)或重複
(Redundant)的特徵。為了移除不相關、重
複或具雜訊的資料，相關領域的專家學者
陸續提出不同的特徵選取(Feature Selection)
方法[3-12][14][18-21][24][27]，主要目的在
於從原始特徵集合(Original Feature Set)中
挑選一個特定的特徵子集合(Feature Subset) 
[5-12]。換言之，樣本的每個特徵最後的選
擇將是被挑選(Selected)納入最終的特徵子
集合 (Final Feature Subset) 或未被挑選
(Unselected)。然而，在這些現有特徵選取
方法中，一分為二的選擇過程(被挑選或未
被挑選 )可能迫使某些特徵不得不被捨
棄，而所有被挑選的特徵在此對於分類效
能則有相同的影響效果，以致於無法依實
際情況反映這些特徵的影響性與重要性程
度及大小順序於分類效能中。此外，搜尋
最佳的特徵子集合所需要的時間將會隨著
特 徵 個 數 呈 指 數 成 長 (Exponential 
Growth)，許多與特徵選取相關的問題都被
列為是 NP-hard[28]的問題。 
事實上，樣本的所有特徵對於分類效
能(或分類正確率)的影響效果並不相同。前
述現有的特徵選取方法顯然無法依實際情
況反映這些特徵的影響性與重要性程度及
大小順序於分類效能中。因此，本研究認
為在分類問題中快速、有效地決定各特徵
與分類效能相關的權重實有其必要性。然
而，較少有研究針對分類問題中各特徵與
分類效能相關的權重及其對於分類效能
(或分類正確率)的影響機制進行探討。 
為了決定分類問題中各個特徵與分類
效能相關的權重，可透過各種明確的評估
基準(Evaluation Criterion)，評估並比較樣
本的所有特徵，以汰弱留強決定各特徵的
權重。值得注意的是，使用不同的評估基
準，很有可能會產生不同的權重決定結果。 
然而，在現有的特徵權重決定方法
 4 
表一個特定的設計因子，而每一列則代表
一個特定的實驗，該實驗由所有設計因子
在特定的選擇情形(Levels or Options)下組
合而成。  
當產生二階直交表後，即可決定每個
實驗的目標函數或觀測值。接著，利用訊
號雜訊比(Signal-to-Noise Ratio (SNR))分析
並尋求所有設計因子的最佳化。一般而
言，有兩種不同的訊號雜訊比常被使用
[100]，(一)越小越好(the smaller-the-better)
的 SNR。(二) 越大越好(the larger-the-better)
的 SNR。 
在田口式方法(Taguchi Method)中，訊
號雜訊比(Signal-to-Noise Ratio (SNR))主要
用來決定每個設計因子所有選擇情形的穩
健性(Robustness)。換言之，針對每個設計
因子，可藉由挑選 SNR 值較高的選擇情
形，獲得高品質(High Quality)的特定標的
(如流程或產品)。 
綜合上述，針對穩健式實驗設計，田
口式方法(Taguchi Method)提供多項優點。
首先，在田口式方法中的實驗次數遠少於
進行完全因子實驗設計 (Full Factorial 
Experimental Design)所需要的實驗次數。另
外，特定標的中每個設計因子的重要性
(Significance)可明確地加以區分。 
本研究擬利用田口式方法中的二階直
交表與訊號雜訊比等概念進行分類問題中
各特徵的權重調整機制，其具體作法如下： 
在二階直交表中，每一列(即每一個實
驗) j ( )代表一個特定的特徵組合，該組合
或集合記為 SEj。在該組合 SEj 中，若特徵
Ci ( )被挑選納入特徵選取機制中，則其
Level 為 1，反之，則其 Level 為 0(即不被
挑選)。 
當 前 述 二 階 直 交 表 (Two-level 
Orthogonal Array)的實驗輸出(Experimental 
Layout)結果產生後(即決定每個實驗或特
徵組合的目標函數或觀測值)，接著利用訊
號雜訊比(Signal-to-Noise Ratio (SNR))分析
並尋求所有特徵權重組合的最佳化。在本
研究中，調整權重後的特徵組合其整體分
類效能被期望為越高越好，因此將採用前
述越大越好(the larger-the-better)的訊號雜
訊比進行後續分析。 
換言之，本研究利用田口式方法中的
訊號雜訊比決定分類問題中每個特徵的穩
健性(Robustness)，亦即是藉由挑選 SNR 值
較高的選擇情形(即 Level 1 或 Level 0)，獲
得高品質(High Quality)的特徵標的(在此即
優越的整體分類效能)，以供調整特徵權重
之用。針對一特徵 Ci 而言，在越大越好(the 
larger-the-better)的特性下，若其 Level 1 的
SNR 高於 Level 0 的 SNR，則建議調高該
特徵 Ci 的權重。反之，若其 Level 1 的 SNR
低於 Level 0 的 SNR，則建議調低該特徵
Ci 的權重。 
綜合上述，本研究融合田口式方法及
訊號雜訊比的精神，擬提出一個新穎、快
速且適用於特徵選取的新型權重調整方
法，調整權重後的特徵將供新樣本分類決
策判斷之用，而調整權重後的特徵組合預
期將比原始的特徵組合，有更優越的整體
分類效能。 
綜括而言，田口式方法(即穩健式實驗
設計方法)及訊號雜訊比針對本研究擬提
出的新型特徵權重調整方法提供多項優
點。舉例而言，假設有 r 個特徵，則可能
會有 2r 種不同的權重調整方向組合可供選
擇，這些多個權重調整方向組合也加深了
建立一具高分類效能的特徵權重調整方法
的難度；然而，透過田口式方法將可快速、
有效地解決此一調整特徵權重的困難。另
外，透過二階直交表—部分因子實驗設計
矩 陣 (Fractional Factorial Experimental 
Design Matrix)的使用，將可提供所有特徵
之間互動關係(Interactions)的完整分析之
外，同時包括每個特徵在不同選擇情形
(Levels or Options)下公正、具平衡性及系統
性的比較 (Fair, Balanced and Systematic 
Comparisons of Different Levels (or 
Options))。 
以上各項優點也是本研究之所以採用
田口式方法及訊號雜訊比作為在分類問題
中進行各特徵的權重調整的主要原因。 
 
四、結果與討論 
 
針對研究方法與架構及以田口式方法
及訊號雜訊比為基礎的特徵權重調整方
法，我們得到極佳的實驗結果。考量幾個
著 名 的 分 類 問 題 (Classification 
 6 
(2) 有關理論分析與文獻探討部份，已蒐
集有關蒐集特徵選取、權重調整
(Weighting Adjustment)方法、機器學
習理論以及各項理論之分類問題領
域實務應用等相關重要文獻。 
(3) 已完成相關實驗環境。 
(4) 已完成蒐集整理不同應用領域之分
類問題，將所提方法與其他現有方法
進行理論、分類效能及複雜度等比較
分析。 
(5) 已將研究心得歸納結論，並提出未來
研究方向及建議。 
(6) 已完成撰寫研究報告，並以「適用於
特徵選取的新型權重調整方法」為研
究主軸，將相關研究結果整理後於學
術研討會發表。 
 
六、參考文獻 
 
[1] T. M. Mitchell, Machine Learning, 
McGraw-Hill, New York, 1997. 
[2] I. Witten and E. Frank, Data mining - practical 
machine learning tools and techniques with java 
implementations, Morgan Kaufmann, San 
Francisco, CA, 2nd ed., 2005. 
[3] T. G. Dietterich, “Machine learning research: 
Four current directions,” AI Magazine, vol. 
18(4), pp.97-136, 1997. 
[4] P. Langley, “Machine learning as an 
experimental science,” Machine Learning, vol. 3, 
pp. 5-8, 1988. 
[5] R. Agrawal, T. Imielinski, and A. Swami, 
“Database Mining: A Performance Perspective,” 
IEEE Trans. Knowledge and Data Eng., vol. 5, 
no. 6, pp. 914-925, 1993. 
[6] U.M. Fayyad, G. Piatetsky-Shapiro, and P. 
Smyth, “From Data Mining to Knowledge 
Discovery: An Overview,” Advances in 
Knowledge Discovery and Data Mining, U.M. 
Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. 
Uthurusamy, eds., pp. 495-515, AAAI 
Press/The MIT Press, 1996. 
[7] U.M. Fayyad and R. Uthurusamy, “Evolving 
Data Mining into Solutions for Insights,” Comm. 
ACM, vol. 45, no. 8, pp. 28-31, 2002. 
[8] J. Han and Y. Fu, “Attribute-Oriented Induction 
in Data Mining,” Advances in Knowledge 
Discovery and Data Mining, U.M. Fayyad, G. 
Piatetsky-Shapiro, P. Smyth, and R. 
Uthurusamy, eds., pp. 399-421, AAAI 
Press/The MIT Press, 1996. 
[9] J. Han and M. Kamber, Data Mining: Concepts 
and Techniques. Morgan Kaufman, 2001. 
[10] S. Russell and P. Norvig, Artificial Intelligence. 
A modern approach, Prentice Hall, 1995. 
[11] J. R. Quinlan, C4.5: Programs for Machine 
Learning, Morgan Kaufmann Publishers, San 
Mateo, CA, 1993. 
[12] Y. Freund and L. Mason, “The alternating 
decision tree learning algorithm,” in Proc. of the 
16th International Conference on Machine 
Learning, Bled, Slovenia, pp. 124-133, 1999. 
[13] R. Kohavi, “The power of decision tables,” in 
European Conference on Machine Learning, 
1995. 
[14] W.W. Cohen, “Fast effective rule induction,” In 
Proc. of the 12th International Conference on 
Machine Learning, pp. 115-123, Morgan 
Kaufmann, 1995. 
[15] I.H. Witten and E. Frank, “Generating accurate 
rule sets without global optimization,” In Proc. 
of the 15th International Conference on 
Machine Learning, ICML98, pp. 144-151, 
1998. 
[16] G.H. John and P. Langley, “Estimating 
continuous distributions in bayesian classifiers,” 
In Proc. of the 11th Conference on Uncertainty 
in Artificial Intelligence, pp. 338-345, San 
Francisco, 1995. Morgan Kaufmann. 
[17] J. R. Quinlan, “Induction of decision trees,” 
Machine Learning, vol. 1, pp. 81-106, 1986. 
[18] P. Langley and H. A. Simon, “Applications of 
machine learning and rule induction,” 
Communications of the ACM, vol. 38, no. 11, 
pp. 55-64, 1995. 
[19] J. H. Friedman, “A recursive partitioning 
decision rule for nonparametric classification,” 
IEEE Trans. on Computers, pp. 404-408, 1977. 
[20] P. Clark and T. Niblett, “The CN2 Induction 
Algorithm,” Machine Learning, vol. 3, pp. 
261-283, 1989. 
[21] R. Agrawal, T. Imilienski, and A. Swami, 
“Mining association rules between sets of items 
in large databases,” In Proceedings of the ACM 
SIGMOD International Conference on 
Management of Database, pp. 207-216, 1993. 
[22] N. Pasquier, Y. Bastide, R. Taouil, and L. 
Lakhal, “Discovering frequent closed itemsets 
for association rules,” Lecture Notes in 
Computer Science, 1540: pp. 398-416, 1999. 
[23] V. Vapnik. Statistical Learning Theory. John 
Wiley and Sons, New York, 1998. 
[24] V. Vapnik. The Nature of Statistical Learning 
Theory. Springer-Verlag, New York, 1995. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/31
國科會補助計畫
計畫名稱: 在不同機器學習模型下具自我調適能力的多種新型權重調整方法
計畫主持人: 黃淇竣
計畫編號: 99-2221-E-022-009- 學門領域: 人工智慧
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
(1) 在學術研究方面，我們在權重調整方法、特徵選取、相關分類方法、機器
學習等相關學術領域的研究議題上，貢獻一己之力，進而引發學者專家針對這
項研究議題的研究興趣與討論，並將貢獻出本年度之研究成果及經驗與大家分
享。 
(2) 以「在不同機器學習模型下具自我調適能力的多種新型權重調整方法 」為
研究主軸，將相關研究結果於相關國際學術研討會議發表，為提升我國在機器
學習與人工智慧等研究領域的學術地位，貢獻一己之力。 
(3) 在實務應用方面，本研究所提新方法將有助於各種實際分類問題領域
(Problem Domains)的解決與應用發展，如人物識別、影像分類、中文辨識與手
寫字識別、語音辨識、醫療診斷、戶內與戶外場景分類、遙測資料分類、入侵
偵測、機器錯誤自動診斷等諸多複雜實務分類問題。 
(4) 在專業技術人才培養方面，本計畫將有助於我國培養具備人工智慧、機器
學習與軟體開發等專門領域知識的高級專業技術人才。計畫相關研究參與人員
藉由各項理論基礎、建立實驗環境與其在各分類問題領域的實驗結果及分析等
訓練，將可提升相關問題的深入分析討論與解決能力。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
