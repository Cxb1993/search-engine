2 
 
便使保留下來的解都是最具代表性的解。 
IV. PSO演算法搜尋廣度的改良 
PSO演算法的優點為具備快速的收斂性，但是在搜尋最佳解的過程中，其搜尋廣度
會受限於粒子群間過去的經驗而失去探索新的搜尋空間能力，此部份可考慮基因演
算法的交配機制的特性，在外部暫存器的個體中，以交配方式擴增PSO的搜尋廣度，
此過程對於多目標最佳化問題中跳脫局部最佳解、加速收斂及增加搜尋廣度等需求
皆有幫助。 
三、文獻探討 
1. 粒子群最佳化演算法 
自從1995年Kennedy與Eberhart提出Particle Swarm Optimization (PSO) [1]之後，PSO在
最佳化問題上的解決效率就受到高度的重視，期間有許多研究者應用許多不同方法改善
PSO的效能，因此目前已經被發展出來的PSO變種以及相關的研究可謂是五花八門，各有各
自著重的地方以及適用的問題類型。PSO的基礎架構與概念源於模擬鳥群或魚群的覓食行
為，藉由觀察不同生物的群體行為模式，進而發展出一種基於生物群體智能(swarm 
intelligence)的最佳化演算法。該文將其應用於連續的非線性函數最佳化(nonlinear function 
optimization)與類神經網路訓練(neural network training)，並探討PSO 與人工生命(artificial 
life)之間的關係。同年，Eberhart 與Kennedy[2]提出另一種粒子行為模式：局部版本(local 
version)，將粒子的群居資訊由原本的族群總體最佳粒子改以鄰近粒子本身的最佳粒子替
代，粒子於解空間搜尋時藉由鄰近粒子的歷史行為，取得群居資訊以修正粒子本身的搜尋
方向。作者將其應用於類神經網路的訓練，其結果指出局部版本族群的搜尋過程可避免過
早收斂於局部最佳值，但是需花費較高的計算成本才能搜尋到全域最佳值。換言之，與全
域版本(global version)相比，局部版本可有效改善當群族的總體最佳值落於解空間局部最佳
區域時，可能使族群提早收歛於局部最佳值區域的缺點。但是，卻需花費較長的搜尋過程
方可達到全域最佳值區域。1997年Kennedy [3]以生物群居科學為背景，發展粒子在群居適
應認知的模式，並就某些粒子行為深入的探討。由於在PSO各粒子間的互動行為模式對族
群的搜尋能力有著很大的影響，文中藉由模擬群居生物不同的行為模式分析比較，定義出
粒子於群居時的行為模式可分為群居(social)參數與認知(cognitive)參數兩部份；群體中各粒
子於最佳適應值搜尋時，除保有本身認知的最佳資訊，亦會與群體的同伴進行群居的資訊
交換，亦即粒子可藉由上述模式改變本身的行為以適應群居。1998 年Shi與Eberhart [4]提出
慣性權重式粒子群演算法(particles swarm optimization with inertia weighted, PSO-IW)，應用
於多變數之無限制條件解析測試函數(unconstrained analytical benchmark function)最佳化問
題。此法於原始PSO演算法的速度更新公式，導入速度慣性權重(inertia weighted)參數w，提
高原始PSO的收斂速度與函數最佳值搜尋的成功率；並且經由分析PSO於不同慣性權重參數
設定值的性能表現，定義出慣性權重參數的設定範圍，依此改善原始PSO的搜尋成功率與
收斂速度。但是，PSO演算法在慣性權重參數設置上仍存著相當模糊的範圍。隨後Shi 與
Eberhart [5]詳細分析慣性權重的參數設定與粒子的最大速限(maximum of velocity, Vmax)，
指出此兩項參數為PSO演算法性能優劣的關鍵，並提供此兩項參數設定的建議值。同年，
4 
 
易落入局部最佳值的趨勢。文中以模擬觀察太空船於太空中飛行的方式，對PSO-CF最大速
限Vmax的設定值進行改善，將Vmax限制為與搜尋空間任一維度的最大範圍等值，有效的改
善PSO-CF演算法面對不同測試函數最佳化問題時的可靠度。 
儘管PSO演進愈趨穩健，但相關參數的設定卻相當模糊不清。於是便有一部分的學者
投入所有PSO演算法參數設定之研究。2001年由Carlisle與Dozier[13]提出的“An off-the-shelf 
PSO”應用Shi與Eberhart [11]的測試函數，對PSO相關參數的設定做系列組合模擬，並由模
擬結果得到演算法最佳的參數設定值。而後於2004年，在Zhang、Yu與Hu[14]的研究，使用
更多的測試函數，就PSO-CF針對族群數(population size)、壓縮因子K 及最大速限Vmax各種
參數組合對演算法之性能影響，進行系列的統計並分析參數範圍對演算法的影響，依其模
擬結果得出各參數的最佳設定值。至此PSO-CF的參數設定，大致上有了較為廣泛且適合的
範圍。2001年Shi與Eberhart[15]就PSO-CF參數及其特性，修正PSO-IW的慣性權重函數，並
將其應用在動態系統的最佳化問題。動態性系統的全域最佳值在每個狀態下並不一定相
同，該研究將慣性權重函數修改為接近於PSO-CF參數的方式，並增加一個隨機變數，目的
在於確保原有PSO-IW動態調整粒子行為模式的精神。修改後的PSO-IW能有效的執行動態
系統的最佳化問題，藉由系統狀態的改變重新隨機化族群，在不同的精確度或較高的維度
要求下，演算法仍保有其一定的能力，並進一步導入非線性動態系統的研究。 
在Shi與Eberhart提出的PSO-IW及Kennedy與Clerc提出的PSO-CF中，同樣都是藉由修正
粒子的行為模式，以改善原始PSO的不足。有部分的學者便以此兩種PSO提出不同的改良方
式，以期能更進一步的改善PSO。2002年Fourie與Groenwold[16]提出動態慣性與最大速限縮
減式粒子群演算法(particle swarm optimization with dynamic inertia and maximum velocity 
reduction, PSO-DIVR)。此法是於PSO-IW加入動態慣性與最大速限縮減判斷準則，在滿足執
行準則時，同步隨機的降低粒子最大速限與速度慣性權重值。該研究應用於結構形狀與尺
寸最佳化問題，並與其他不同類型的演算法(包括傳統最佳化方法或常用的GA)進行比較，
結果顯示PSO-DIVR具有最高的合適性。亦即，在考量各演算法的效能上，此法均可獲得較
佳及可靠的最佳化結果。2003年Zheng[17]的研究，將慣性權重函數改以線性遞增的方式運
用於PSO-IW，並由分析粒子軌跡提出與先前不同的群居與認知參數設定值，且藉由模擬淬
火法(simulated annealing，SA)的概念提出慣性權重函數的不同觀點。在Shi與Eberhart的研
究中，認為粒子有較大的慣性權重值，即意味著具有較高的全域搜尋能力；反之，粒子具
有局部搜尋的能力。但是，Zheng的研究則認為較小慣性權重值，粒子不論在全域或局部最
佳值區域搜尋都具有探索新區域的能力，且具有“跳脫＂(jump out)的功能，可避免粒子收斂
至局部最佳值；反之，較高的慣性權重值使粒子有更高的機會呈現穩定性。Zheng的研究也
是以Angeline使用的測試函數，評估PSO-IW在使用線性遞減與線性遞增兩種不同的慣性權
重函數的性能比較，其結果指出PSO-IW使用線性遞增慣性權重函數時，演算法能在較少的
迭代數收斂至全域最佳值區域，且以Rosenbrock、Rastrigrin 函數為例，也比於PSO-IW中
使用線性遞減慣性權重函數的結果為佳。2005年，Yang與Simon [18]提出不同的粒子速度更
新準則，使用與原始PSO相反的參考資訊，將原本個體最佳與族群最佳，分別替換成個體
最差與族群最差，其餘的流程與設定仍沿用原始PSO的迭代過程。這樣的替換，導致粒子
搜尋過程有遠離本身或族群其他粒子先前曾搜尋的最差區域的行為模式，同樣也使用
Angeline的測試函數，以不同維度且使用不同的族群數，評估PSO 使用此兩種不同的粒子
行為模式的收斂速度，結果指出此法優於原始PSO。但並未進一步與PSO-IW或PSO-CF比
6 
 
最佳化問題，NPGA會出現計算效率的問題。 
此後，更有些架構在這些演算法的研究，加入其他有效的機制，例如菁英策略 (Elitism)  
及外部儲存 (External Memory or Archive)  的方法，如Zitzler和Thiele所提出來的強化式
Pareto遺傳演算法(Strength Pareto Evolutionary Algorithm, SPEA) [26]。SPEA利用明確的保留
菁英策略，額外儲存一組族群，此族群內所儲存的解即為不受支配解的群組。在每一個世
代中，新找到的不受支配解將和外部儲存的不受支配解比較，並將較好的保留下來。在SPEA
之後更進而提出強化式Pareto遺傳演算法2(Strength Pareto Evolutionary Algorithm 2, SPEA2) 
[27]。SPEA2為進階的SPEA演算法，增加了改進SPEA的給定適應值的架構，包含將被支配
及支配的解都納入計算，並加入計算附近解的密度，使得在尋找解的過程中可以有更多的
精確引導。SPEA2承繼SPEA的優點，當找到一個新的落在Pareto-optimal front上的解就儲存
在外部的族群中，在過程中的聚集方法可以使外部儲存的解有更好的延展性。但是，如同
MOGA所擁有的問題一般，擁有相同排序的不受支配解，並不會擁有同等的地位。學者
Joshua D. Knowles等人提出Pareto空間演化策略(Pareto Archive Evolution Strategy, PAES) 
[28]，PAES採用(1+1) 演化策略  (Evolution Strategy, ES)，並擁有一組固定大小的外部儲存
空間存取目前為止找到的不受支配解。在演化的過程中，將搜尋空間切割為許多區塊，藉
由同一區塊中鄰近解的數量，決定子代是否在下世代取代原先的母代，以保持解的差異性。
因此，如何決定外部儲存空間的大小及區塊切割的大小是PAES面臨的困難點；當目標函數
增加時切割空間將呈現指數的成長，更加難以保持解的較佳延展性。學者Deb提出NSGA演
算法的改良，不受支配解排序的基因演算法2(Nondominated Sorting Genetic Algorithm II, 
NSGA-II) [29], [30]。NSGA-II為一個同時擁有菁英保留及明確的保持差異性機制的演算
法，在產生大小為N的子代後，與原本大小為N的母代合併為2N，並做不受支配解的排序，
將較好的N個個體留下來，以確保母代及子代之間最佳的不受支配解能夠被保留下來，另
外也加入Crowded Tournament Selection來確保解之間的差異性。但是，也因此若第一次搜尋
時，不受支配解的數量與整體族群比較起來呈現較少的情況時，除了接近Pareto front的解
被保留至下一代外，另有一些非真正接近Pareto front的解也被保留，如此將會影響了演算
法的收斂性。 
除了前述的GA外，因為PSO被提出的目的在於解決單目標最佳化的問題 [31]，並在各
種應用獲得很好的結果，而且PSO擁有較快的收斂速度，能夠更快速的找到全域解 (global 
solution)。因此，近幾年更有研究擴展PSO的架構至多目標最佳化的問題上，研究如何從一
組未受支配的解選擇出適合的全域最佳解引導下一次的演化。例如Hu與Eberhart提出的以動
態鄰近搜尋之粒子群聚最佳化演算法(Dynamic Neighborhood Particle Swarm Optimization) 
[32]，假設在二個目標最佳化的問題中，利用先找出在目標函數1中最接近的兩個解，再從
兩個解中選出目標函數中最好的一個解做為下一代搜尋的引導。Parsopoulos與Vrahatis提出
的以向量估測的粒子群聚最佳化演算法(Vector Evaluated Particle Swarm Optimiser, VEPSO) 
[33]的方法，則是將多個目標函數給予適當的權重，把多目標的問題簡化至單目標問題，再
使用PSO搜尋出最佳化的解。Coello與Lechunga提出以方格為基礎做選擇的多重目標粒子群
聚最佳化演算法(Grid-based MOPSO) [34]的方法，在更新儲存空間裡的最佳解是利用每一
個目標函數的幾何位置，在目標空間(objective space)切割成許多小方格，依據方格的區隔
再加上輪盤法選擇(roulette-wheel selection)挑出最佳解，而這些儲存空間的最佳解，將在下
一次被選擇做為引導的參考方向。但是，此法的缺點是選出來的最佳解不一定最適合這個
8 
 
[11]. R. C. Eberhart and Y. Shi, “Comparing inertia weights and constriction factors in particle 
swarm optimization,” in Proc. Congress of Evolutionary Computation, vol. 1, pp. 84-88, 
2000. 
[12]. Davis L. (Ed.), Handbook of genetic algorithms, New York: Van Nostrand Reinhold, 1991. 
[13]. A. Carlisle, and G. Dozier, “An Off-the-shelf PSO,” Proc. of the Workshop on Particle 
Swarm Optimization, pp. 1-6, 2001 
[14]. Z. Li-Ping, Y. Huan-Jun, and H. Shang-Xu, “Optimal choice of parameters for particle 
swarm optimization,” Journal of Zhejiang University: Science, vol. 6, A, pp. 528-534, 
2005. 
[15]. R. C. Eberhart and Y. Shi, “Tracking and optimizing dynamic systems with particle 
swarms,” in Proc.Congress on Evolutionary Computation, vol. 1, pp. 94-100, 2001. 
[16]. P. C. Fourie, and A. A. Groenwold, “The particle swarm optimization algorithm in size and 
shape optimization,” Structural and Multidisciplinary Optimization, vol. 23, pp. 259-267, 
2002. 
[17]. Yong-Ling Z., Long-Hua M., Li-Yan Z. and Ji-Xin Q., “On the convergence analysis and 
parameter selection in particle swarm optimization,” in Proc.2nd International Conference 
on Machine Learning and Cybernetics, vol. 3, pp. 1802-1807, 2003. 
[18]. Y. Chunming and D. Simon, “A new particle swarm optimization technique,” in Proc.18th 
International Conference on Systems Engineering, pp. 164-169, 2005. 
[19]. R. Eberhart and J. Kennedy, “A discrete binary version of the 100 particle swarm 
algorithm,” in Proc. IEEE International Conference on Systems, vol. 5, pp. 4104-4108, 
1997. 
[20]. J. D. Schaffer, Multiple Objective Optimization with Vector Evaluated Genetic Algorithms, 
Ph.D. thesis, Vanderbilt University 1984. 
[21]. J. D. Schaffer, “Multiple objective optimization with vector evaluated genetic algorithms,” 
Proceedings of the First International Conference on Genetic Algorithms, pp. 93-100, 1985. 
[22]. P. Haiela and C.-Y. Lin, “Genetic search strategies in multi-criterion optimal design,” 
Structural and Multidisciplinary Optimization, vol. 4, no. 2, pp.99-107, 1992. 
[23]. C. M. Fonseca and P. J. Flemin, “Genetic algorithms for multiobjective Optimization: 
Formulation, discussion and generalization,”  In Stephanie Forrest, editor,  Proceedings 
of the Fifth International Conference on Genetic Algorithms, pp. 416-423, 1993. 
[24]. N. Srinivas and K. Deb, “Multiobjective optimization using nondominated sorting in 
genetic algorithms,” Evolutionary Computation, vol. 2, no. 3, pp. 221-248, Fall 1994. 
[25]. J. Horn, N. Nafpliotis and D. E. Goldberg, “A  niched pareto genetic algorithm for 
multiobjective optimization,” In Proceedings of the First IEEE Conference on Evolutionary 
Computation, vol. 1, pp. 82-87, 1994. 
[26]. E. Zitzler and L. Thiele, “Multiobjective evolutionary  algorithms: A comparative case 
study and the strength pareto approach,” IEEE Transactions on Evolutionary Computation, 
vol. 3, no. 4, pp. 257-271, 1999. 
[27]. E. Zitzler, M. Laumanns, and L. Thiele, “SPEA2: Improving the strength pareto 
evolutionary algorithm,” In K. Giannakoglou et al., editor,  EUROGEN 2001. 
10 
 
[41]. S.-T. Hsieh, T.-Y. Sun, J.-M. Chen and C.-W. Lin, “Efficient Task Scheduling for 
Heterogeneous Multiprocessors Using Particle Swarm Optimization,” Swarm Intelligence 
Symposium, Indianapolis, IN, U.S.A., May 12-14, 2006. 
[42]. S.-T. Hsieh, T.-Y. Sun, C.-W. Lin, and C.-L. Lin “Placement constraints and macrocell 
overlap removal using particle swarm optimization” Lecture Notes on Computer Science 
4150: 235-246 2006. 
[43]. S.-T. Hsieh, T.-Y. Sun, S.-Y. Chiu, C.-C. Liu and C.-W. Lin, “Cluster Based Solution 
Exploration Strategy for Multi-Objective Particle Swarm Optimization,” in Proc. IASTED 
International Conference on Artificial Intelligence and Applications, Austria, Feb. 12-14, 
2007. 
[44]. Shih-Yuan Chiu, Tsung-Ying Sun*, Sheng-Ta Hsieh and Cheng-Wei Lin, “Cross-Searching 
Strategy for Multi-objective Particle Swarm Optimization,” IEEE CEC 2007 -- 2007 IEEE 
Congress on Evolutionary Computation, Singapore, Sept. 25-28, 2007. 
四、 研究方法 
本計畫將研究的重點放在多目標PSO演算法缺點的改善，以期解決多目標最佳化問
題，並以公定的多目標最佳化問題測試及驗證所發展的演算法，我們的方法及成果分述如
下； 
1. 針對目前PSO及GA演算法解多目標函數之問題 
以下簡介GA及PSO演算法。 
a. GA演算法 
基因演算法是模仿生物進化遺傳的過程，其演算法流程如圖1。 
 
圖1 基因演算法流程圖 
主要兩個機制為交配(crossover)與突變(mutation)，交配為GA最重要的演化機制，利用
擷取母代的資訊產生新的子代，操作方法為隨機從母代中挑選出兩個染色體，藉由交換染
色體中的基因資訊產生新的子代，在交配的結果有機會產生適應值較優的個體；突變機制
目的為產生新品種，使得演化過程中有機會跳脫區域最佳解的能力，操作方法為在染色體
12 
 
psitPbestfGbest iPbesti
≤≤+= 1)),1((minarg                 (4) 
 
本計畫針對PSO及GA兩種演算法作特性上的分析，可以了解的是此兩種演算法的演算
特性造成在對於不同問題上會產生演算法效率的差異。在問題空間較簡單的情況之下，PSO
能快速的搜尋到最佳解，但在問題複雜化，區域最佳解較多且雜的情況下，PSO往往會落
入區域最佳解導致演化的停滯不進，GA雖然演化較為緩慢，但較無此缺點。 
在過去的研究中，主要皆針對個別的基礎演算法的改良，例如精英政策、聚類機制與
最佳解的定義，卻沒有面對演算法在基本上的特性問題，或許在解的收斂與解的分布性上
能夠做有效的改善，但演算法的基本特性問題卻仍未解決。 
2. 本計畫所發展的多目標最佳化演算法 
本 計 畫 提 出 結 合 跳 躍 更 新 的 多 目 標 粒 子 群 最 佳 化 演 算 法 (Jump Improved 
Multi-Objective Particle Swarm Optimization, JI-MOPSO)，改善粒子搜尋Optimal Pareto Front
的能力及效能。JI-MOPSO使用擾動機制、外部暫存器更新機制、聚類機制以及依粒子密度
對整域最佳解(Gbest)重新照比例分配定義的機制，演算法流程如圖3所示。 
 
圖3 JI-MOPSO演算法流程圖 
首先初始化化JI-MOPSO演算法的各參數，包括演化個體數量(Population size)、Pbest、
Gbest、外部暫存器(external repository)。接著藉由式(1)更新速度並移動，在移動完成後執行
擾動機制，目的為給予PSO跳脫區域最佳解的機率，本計畫擾動機制設計為在邊界內做隨
機擾動，不會有粒子跳脫空間邊界問題。在移動與擾動結束之後，粒子的位置已經更新，
新的粒子位置合併外部暫存器並利用dominate關係更新外部暫存器。接著使用跳躍更新機
制更新外部暫存器，更新完成後利用聚類機制減少外部暫存器數量。最後更新粒子的Pbest
與Gbest，由於PSO的快速收歛特性，粒子有機會能在每次的移動中找到最佳解，使得粒子
的歷來最佳解通常為本世代的位置，因此如果將Pbest定義為歷來的最佳解，則Pbest為本世
14 
 
差的成員，組成適應值較佳的下一代成員。本質上，這種演化過程具有跳躍性質，在跳躍
過程中如果有某個成員的基因跳到較佳的區域，則接下來的子代成員就會有機會跳躍到此
區域並找到更好的解。 
PSO的演化過程是藉由操作粒子的移動進行，粒子移動的方向由其過去的最佳解與所
有粒子的最佳解決定，藉此獲得粒子的新位置。本質上，PSO的演化過程具有移動性質，
若在粒子聚集之前仍未移動到或移動過整域最佳的區域，則粒子很容易會陷入在Local 
Minimum而無法跳脫出來。 
本計畫仿效GA的演化特性，提出一種跳躍更新機制用於改善PSO在演化過程的缺點。
在本計畫的演算法中，Pbest與Gbest的資訊來自於外部暫存器，而粒子的移動資訊亦來自
Pbest與Gbest；換言之，外部暫存器所存的資訊決定了粒子的移動方向，如果在外部暫存器
中的資訊不夠完整，則粒子的演化方向將會越來越朝local Minimum移動。因此，本論文提
出跳躍更新機制解決這樣的問題，藉由更新外部暫存器的資訊，讓PSO在方向的選擇更多
元，不再侷限於過去的經驗，可彌補PSO在本質上的缺失，藉由跳躍方式的更新粒子的位
置，可使粒子更有機會朝全域最佳解的區域移動。 
跳躍更新機制僅更新外部暫存器的精英粒子資訊，並不直接參與PSO的演化過程，在
提供粒子較佳的方向之下，還能夠保持PSO快速收歛的特性，在跳躍方式的選擇上，有向
內跳躍以及向外跳躍兩種，向內跳躍的效能為增強演算法在已知空間中的深度搜尋能力，
反之向外跳躍則為增強演算法在未知空間的探索能力，由於PSO演算法具有深度搜尋能力
但對於未知空間探索的效能較差，因此本論文演算法跳躍方式為藉由挑選兩精英粒子資
訊，向外跳躍探索未知的粒子空間，增加PSO演算法在外部暫存器中對於未知空間的資訊。
跳躍更新機制的操作如圖6所示，假設在外部暫存器中隨機挑選兩精英粒子，分別以向量vec1
和vec2表示其方向資訊。利用式(5)與(6)，以跳躍的方式取得新的方向資訊Oc1和Oc2，α1與α2
為介於[0, 1]之間的隨機值；亦即，利用跳躍的方式取得vec1與vec2之外的新的方向，藉此給
予PSO跳脫區域最佳解的資訊，跳躍更新機制的虛擬碼如圖7所示。 
 
圖6 跳躍更新機制 
if jump particle number is not enough 
Random pick vec1 from external repository 
Random pick vec2 from external repository 
Generate new Oc1 and Oc2 use equations (5) and (6) 
Endif 
圖7 跳躍更新機制的虛擬碼 
                      )( 21111 vecvecvecOc −+= α                     (5) 
16 
 
精英粒子在解空間的Pareto front上能夠平均散佈。 
 
圖9 聚類機制示意圖 
Assign each particle of the external repository a unique serial number 
  Calculate the cluster radius r 
  For each particle in the external repository according to the serial number 
   Put into the particle space and be a cluster 
   If the particle locates in other particle’s range of radius 
    Removes the particle 
   EndIf 
EndFor 
圖10 聚類機制的虛擬碼 
z 比例分配機制 
單目標粒子群最佳化與多目標粒子群最佳化的最大差別在於整域最佳解必須重新定
義，在單目標粒子群最佳化中，最佳解只有一個，但在多目標粒子群最佳化中，目標會互
相拉扯，最佳解通常為兩個以上，亦即整域最佳解不只一個。在單目標中整域最佳解的定
義為所有走過的資訊中最佳的唯一解，此定義在多目標問題中無法成立。因此，在多目標
的問題中，整域最佳解必須重新定義，而如何在這些互不支配解中挑選整域最佳解，會嚴
重的影響整個演算法的收斂性與分散性。 
比例分配機制的功能在於能讓在互不支配的粒子群間依照其在解空間分布的比例而分
配Gbest給搜尋的粒子，如此可使粒子在移動過程中能朝解空間中分佈較稀疏的方向前進，
找到更多的互不支配解。在多目標的問題中，不同目標的問題演算困難度不相同，若不妥
善的處理這個問題，將會造成粒子群聚集在被容易最佳化的目標搜尋，而忽略其他較難被
最佳化的目標上。 
本論文比例分配機制示意如圖11，每個圓代表一個粒子，虛線灰底為外部暫存器中的
精英粒子，實線白底為演化中的粒子，數字為粒子在解空間中的分布排序，d為粒子間的距
離。定義Gbest的方式為以下四個步驟： 
i. 將外部暫存器中的精英粒子與演化中的粒子以橫軸的排列順序給予編號，如圖11
中的粒子編號。 
ii. 計算每個精英粒子i在解空間中的疏密度參數Ｄi，疏密度參數的計算方式如式(8)，
n為外部暫存器數量，為計算本身與前後的精英粒子的平均距離，最邊界的粒子計
算方式則為與最近精英粒子的距離，以圖11為例則D1=3、D2=2、D3=1.5、D4=2。 
18 
 
Calculate the density parameter of particles in external repository 
Configure the corresponding of particles and members in external repository 
Calculate Ngb and Np 
While Ngb ≠ Np 
      If Ngb > Np 
       The maximum GbestNｉ decrease one 
      EndIf 
      If Ngb < Np 
       The minimum GbestNｉ increase one 
      EndIf 
EndWhile 
Assign Gbest 
圖12 比例分配機制的虛擬碼 
五、 結果與討論 
本計畫主持人對於以PSO為主的演化式計算研究已有二年以上的經驗，2005至2006年
間已發表五篇重要的國際會議及期刊論文，我們主要成果包含了發展一個改善版本的PSO
演算法，可以使用不同的學習率(learning rate)對類神經網路權值矩陣的各維度獨立調整各別
的參數，並應用於以可變架構的前向類神經網路為基礎的未知訊源數量的混合訊源分離演
算法，此演算法發展了一個評估函數，藉由此評估函數值的變化情況決定前向網路結構改
變的時機，以便獲得適當的分離矩陣，藉此將原始訊源的混合矩陣還原出來。並以發展的
改善版本 PSO 演算法為基礎，繼續發展出改良型多目標粒子群最佳化演算法
(MOPSO)-JI-MOPSO演算法。關於JI-MOPSO演算法已分別於2007年及2008年發表於重要的
國際會議，並將此結果投稿至Expert Systems With Applications期刊，期刊審稿及編輯對此
非常感興趣，預計於2009年12月被接受並刊登此篇論文。 
20 
 
y Tsung-Ying Sun*, Cheng-Sen Huang, Shang-Jeng Tsai, and Mey-Yin Lu, “Particle 
Swarm Optimizer based Controller Design for Vehicle Navigation System,” in Proc. 
2008 International Conference on Systems, Man and Cybernetics, Singapore, 
pp.909-914, Oct. 12-15, 2008.  
y Tsung-Ying Sun*, Chan-Cheng Liu, Sheng-Ta Hsieh, Tsung-Ying Tsai, and Jyun-Hong 
Jheng, “Optimal Determination of Wavelet Threshold and Decomposition Level via 
Heuristic Learning for Noise Reduction,” in Proc. 2008 IEEE Conference on Soft 
Computing in Industrial Applications (SMCia/08), pp. 405-410, Muroran Hokkaido, 
Japan, June 25-28, 2008. 
y Tsung-Ying Sun*, Chan-Cheng Liu, Tsung-Ying Tsai, and Sheng-Ta Hsieh, “Adequate 
Determination of a Band of Wavelet Threshold for Noise Cancellation Using Particle 
Swarm Optimization,” 2008 IEEE Congress on Evolutionary Computation (IEEE CEC 
2008) within 2008 IEEE World Congress on Computational Intelligence (WCCI 2008), 
Hong Kong, June 1-6, 2008.  
y Tsung-Ying Sun*, Chih-Li Hu, Shang-Jeng Tsai, and Chan-Cheng Liu, “Optimal UAV 
Flight Path Planning Using Skeletonization and Particle Swarm Optimizer,” 2008 IEEE 
Congress on Evolutionary Computation (IEEE CEC 2008) within 2008 IEEE World 
Congress on Computational Intelligence (WCCI 2008), Hong Kong, June 1-6, 2008. 
y Sheng-Ta Hsieh*, Tsung-Ying Sun, Shih-Yuan Chiu, and Shang-Jeng Tsai, “Solving 
Large Scale Global Optimization Using Improved Particle Swarm Optimizer,” 2008 
IEEE Congress on Evolutionary Computation (IEEE CEC 2008) within 2008 IEEE 
World Congress on Computational Intelligence (WCCI 2008), Hong Kong, June 1-6, 
2008. 
 
