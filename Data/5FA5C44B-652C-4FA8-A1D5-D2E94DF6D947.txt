 中文摘要 
 
 本計畫的主要目標為透過Multi-view Video Coding Standard，配合軟硬體編解碼最佳化技
術、立體視訊串流傳輸技術、多核心平台立體視訊平行化技術、任意視角合成技術等，實現一
即時立體視訊串流平台：“3-D-MoD：網路立體視訊播放系統。”本作品嘗試建構不同於現行
2-D視訊之MoD技術，發展下一世代 3-D MoD立體視訊系統雛型所需之關鍵技術，讓本計畫
所提之 3-D立體視訊應用概念能夠逐步落實其技術可能性，因此衍生各種創新之 3-D立體視訊
系統應用，以創造未來生活之藍圖。 
 
Abstract: 
 
  The main purpose of this project is to realize a real-time 3-D video streaming framework via 
software and hardware optimization for Multi-view Video Coding standard, 3-D streaming technique, 
3-D video parallelization technique and real-time view synthesis technique. Being distinct to the 
traditional 2-D video MoD system, this project tries to build the prototype of 3-D MoD system for 
next generation. Therefore, this project is mainly focuses on developing the key techniques 
mentioned above to build the system and create a blueprint for human future live.  
 
Keywords: Multi-view Video Coding, View-Synthesis, MVC Parallelization. 
  
5.2.1 3D-MoD Server  
 As shown in Fig. 1, the streaming server is basically formed by three components: Parallel MVC 
Encoder, Bit-stream Adaptation Unit, and Network Control Unit. The parallel MVC encoder is 
developed using the GOP-level bit-stream structure together with default fast search encoder of JMVC 
as shown in Fig. 2. The encoder unit can process 2-view QVGA in real-time over 30fps. Instead of 
using bit-stream extractor in Media-to-Go server, the second component, bit-stream adaptation unit, is 
developed by using the Bit-stream Assembler which provided by JMVC reference software. After 
encoder unit encodes multiple views input, the bit-streams are originally separated and needed to be 
merged by using bit-stream assembler as shown in Fig. 3. With this concept, we can decide which 
assigned views we want to assemble according to the transmission bandwidth. As shown in Fig. 4, in 
addition to Bit-streams, current bandwidth also becomes one of the inputs of Bit-stream Assembler. 
According to the current bandwidth, Bit-stream Assembler can compare it to the bit-rate of each view 
to finally decide which views to assemble and send to client.  
 
Figure 2: The parallel MVC encoder structure 
5.2.2 3D-MoD Client  
 
 The client of 3D-MoD system is mainly formed by three components, 1) Parallel MVC Decoder Unit, 
2) Depth Map Generator, and 3) View Synthesizer. In the beginning, the client will first receive encoded 
and assembled MVC bit-stream from 3D-MoD server. After that, the MVC Decoder Unit decodes the 
received bit-stream to be multiple views of YUV format file.  
 As Shown in Fig. 5, since there is no data dependence between neighboring GOPs for the proposed 
bit-stream structure, the decoding of each GOP can be parallel processed. Furthermore, since the first 
NAL unit of every GOP must be a SEI unit, the GOP bit-streams can be readily split without performing 
entropy decoding. Due to these well attributes of the proposed GOP level bit-stream structure, we 
implement a real-time parallel MVC decoder unit for the 3D-MoD system.  
 
Figure 5: Proposed hierarchical bit-stream structure. 
 
 As shown in Fig. 6, the parallel MVC decoder unit is formed by three functional units: 
READER/SPLITTER, DECODER and MERGER. Being similar to parallel encoder unit introduced in 
Section. 3, these functional units are simply split to be three pipeline stages by using the same FIFO 
structure as mentioned previously. The first stage, Reader/Splitter, is responsible for reading bit-stream 
from network and then splitting them GOP by GOP. After splitting bit-stream in GOP level, GOP 
decoders depending on core numbers are created to decode GOP bit-streams simultaneously. Finally, the 
last stage take charge of collecting decoding frames in display order and sends it to display unit. Each 
stage does not have to wait for each other stage until the input FIFO is empty or the output FIFO is full. 
 After decoding, in fact, there are already multiple views of video be generated, if for 3D-TV, the 
videos can directly be sent to display unit to display with 3D effects by existing 3D Monitor or 3D TV.  
 As illustrated in Fig. 1, the Depth Map Generator and the View Synthesizer are to generate arbitrary 
views as user requested to achieve FreeTV function. With these two components, free view image can be 
provided for users. The system can also achieve its target to provide not only 3D TV function, but also 
Free TV. 
 
Conclusion 
 
 In the 3D-MoD system, the proposed optimized MVC framework is used as the main component. 
Due to the proposed View Synthesizer, the server only needs to encode and send limited views to the 
clients. The clients will generate the virtual views which are requested in run time. The 3D-MoD can 
achieve QVGA real-time transmission and virtual view generation. It is mainly limited by the speed of 
the MVC Encoder Unit, if the lower level fast algorithm can be integrated to the proposed MVC 
framework, the system can achieve finer resolution in real-time. By using the 3D-MoD system, client 
users can display remote content in 3D and also can freely choose the interested view point, the View 
Synthesizer will generate it in real-time for display. In other words, the 3D TV and Free TV are 
supported in the proposed system. 
  
Reference 
 
[1] Schwarz, H. Marpe, D. Wiegand, T., "Overview of the Scalable Video Coding Extension of the 
H.264/AVC Standard," IEEE Trans. on CSVT , vol.17, no.9, pp.1103-1120, Sept. 2007. 
[2] P. Amon, T. Rathgen and D. Singer, “File Format for Scalable Video Coding,” IEEE Trans. on CSVT, vol. 
17, no. 9, pp. 1174-1185, 2007. 
[3] Yo-Sung Ho, Kwan-Jung Oh, "Overview of Multi-view Video Coding," IEEE Intl Workshop on Signal, 
System and Image Processin, pp.5-12, June 2007 
[4] Wiegand, T, Sullivan, G.J, Bjontegaard, G, Luthra, A, "Overview of the H.264/AVC Video Coding 
Standard," IEEE Trans. on CSVT , vol.13, no.7, pp.560-576, July 2003. 
[5] Chang-Hung Tsai, Kheng-Joo Tan, Ching-Lung Su, Jiun-In Guo, "A Group of Macroblock Based Motion 
Estimation Algorithm Supporting Adaptive Search Range for H.264 Video Coding," Proc of IEEE 
ISCAS, pp.1891-1894, June 2 2010. 
[6] Chih-Chuan Yang, Kheng-Joo Tan, Yao-Chang Yang, and Jiun-In Guo, "Low Complexity Fractional 
Motion Estimation with Adaptive Mode Selection for H.264/AVC, "Proc. of ICME, pp.673-678, 19-23 
July 2010. 
[7] Yu-Jen Wang, Chao-Chung Cheng, Tian-Sheuan Chang, "A Fast Algorithm and Its VLSI Architecture for 
Fractional Motion Estimation for H.264/MPEG-4 AVC Video Coding," IEEE Trans on CSVT, vol.17, 
no.5, pp.578-583, May 2007. 
[8] Tzu-Yun Kuo, Yu-Kun Lin, Tian-Sheuan Chang, "SIFME: A Single Iteration Fractional-Pel Motion 
Estimation Algorithm and Architecture for HDTV Sized H.264 Video Coding," Proc of ICASSP, vol.1, 
no., pp.1185-1188, April 2007. 
[9] Pei-Kuei Tsung, Wei-Yin Chen, Li-Fu Ding, Chuan-Yung Tsai, Tzu-Der Chuang, Liang-Gee Chen, 
"Single-Iteration Full-Search Fractional Motion Estimation for Quad Full HD H.264/AVC Encoding, 
"Proc of ICME, pp.9-12, July 2009. 
[10] Chao-Yang Kao, Huang-Chih Kuo, Youn-Long Lin, "High Performance Fractional Motion Estimation 
and Mode Decision for H.264/AVC," Proc. of ICME, pp.1241-1244, July 2006. 
[11] Yu-Kun Lin, Chia-Chun Lin, Tzu-Yun Kuo, Tian-Sheuan Chang, "A Hardware-Efficient H.264/AVC 
Motion-Estimation Design for High-Definition Video," IEEE Trans. on CSVT, vol.55, no.6, 
pp.1526-1535, July 2008. 
[12] Libo Yang, Yu, K., Jiang Li, Shipeng Li, "An Effective Variable Block-Size Early Termination Algorithm 
for H.264 Video Coding," IEEE Transactions on CSVT, vol.15, no.6, pp. 784- 788, June 2005. 
[13] Von Dem Knesebeck, M., Nasiopoulos, P., "An Efficient Early-Termination Mode Decision Algorithm 
for H.264,"IEEE Transactions on Consumer Electronics, vol.55, no.3, pp.1501-1510, August 2009. 
[14] Lien-Fei Chen, Shin-Ping Yang, Yeong-Kang Lai, "Model-Based Early Termination Scheme for 
H.264/AVC Inter Prediction," Proc of ICASSP, pp.597-600, April 2009. 
[15] Jie Yang, Yin Chen, "A Novel Fast Inter-mode Decision Algorithm for H.264/AVC Based on Motion 
Estimation Residual," Proc of ICIE, vol.1, pp.153-156, July 2009. 
[16] Yao Cheng, Si Yujuan, "Fast Inter Mode Decision Algorithm for H.264/AVC," Proc of CISP, pp.1-3, Oct. 
2009. 
[17] Li Liu, Xinhua Zhuang, "Fast Motion Estimation and Mode Decision for H.264 Video Coding in Packet 
Loss Environment," Proc of IEEE ICME, pp.781-784, April 2008. 
[18] Chao-Yang Kao, Youn-Long Lin, "A Memory-Efficient and Highly Parallel Architecture for Variable 
Block Size Integer Motion Estimation in H.264/AVC," IEEE Transactions on VLSI Systems, vol.18, no.6, 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/17
國科會補助計畫
計畫名稱: 總計畫(I)
計畫主持人: 郭峻因
計畫編號: 99-2221-E-194-045- 學門領域: 積體電路及系統設計 
研發成果名稱
(中文) 全景視訊接合與編碼系統
(英文) Panoramic video stitching and encoding system
成果歸屬機構
國立中正大學 發明人
(創作人)
郭峻因,簡呈安,張家豪
技術說明
(中文) 本作品為一種可應用於車用電子系統之創新H.264全景視訊接合與編碼系統，包
含即時全景影片接合技術與H.264 視訊編碼技術，可以針對接合後之即時全景影
片進行即時顯示與壓縮記錄。本作品主要應用於車用電子之行車駕駛輔助相關產
品(如：行車記錄器、全景倒車攝影等)，駕駛人可藉由觀看全景影片，避免行車
死角所可能造成的交通事故，並結合即時視訊編碼壓縮，降低行車記錄影片資料
量。本作品所提之全景影片接合技術效能較現有技術大幅降低93%之計算量，有
助於在嵌入式系統或以低成本硬體方式來實現，未來更可望能夠實地應用於車用
電子系統中，提供汽車駕駛人更安全的行車輔助與更全面的行車路況記錄。
(英文) This work is H.264 panoramic video stitching and encoding system, including real-time 
panoramic video stitching technology and low bandwidth H.264 video encoder. It can 
deal with video stitching on video soruces with different angles and focal lengths. BTW, 
it equips with an H.264 video encoder architecture with ultra low memory bandwidth 
requirement to achieve both the low-power and high performance design goals. This work 
could be applied to a variety of autotronics applications. According to TSMC 90nm 
CMOS technology, the proposed design could achieve HD720@30fps real-time 
processing when operated at 126MHz under 32-bit AHB 2.0 bus interface and achieve 
HD720@30fps/HD1080@30fps when operated at 66MHz/150MHz under 64-bit AXI 3.0 
bus interface, respectively.
產業別 電機及電子機械器材業
技術/產品應用範圍 多媒體SOC設計、行車紀錄系統、全景監控系統、行車輔助系統
技術移轉可行性及
預期效益
本作品為H.264全景視訊接合與編碼系統，包含即時全景影片接合技術與低頻寬H.264 視
訊編碼器。其特色如下: (1)針對不同角度或焦距拍攝之影片皆可接合處理；(2)提出超
低頻寬H.264視訊編碼器架構，可達到低功率、高效能設計目標。本作品可適用於視訊監
控產業與車用電子產業，技術移轉可行性高。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
博士生 0 0 100%  
博士後研究員 0 0 100%  
（外國籍） 
專任助理 0 0 100%  
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
Design contest awards:  
(1) ASP-DAC2011 University LSI Design Contest: Best Design Award (A 
H.264/MPEG-2 Dual Mode Video Decoder Chip Supporting Temporal/Spatial 
Scalable Video)； 
(2) 2011 旺宏金矽獎應用組評審團金獎 (車用電子應用之 H.264 全景視訊接合
與編碼系統)； 
(3) 嵌入式競賽 2011 軟硬體整合組優等 (角度任你選之低頻寬多視角視訊解
碼器)； 
(4) 嵌入式競賽 2011 創意應用組佳作(2D/3D Free Viewpoint TV Display 
System on Embedded Platforms)； 
(5) 嵌入式競賽2011創意應用組優等 (有拍有BoBee之全景H.264視訊接合系
統)； 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
