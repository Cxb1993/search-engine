2 
 
 
中文摘要 
 
隨著網際網路日漸普及帶動了電子商務的蓬勃發展，企業對於內部作業流程控管的需
求愈來愈高，工作流程管理系統在最近幾年成為相當重要的支援性技術。面對日益激烈的
商業競爭，企業如何利用網際網路來整合跨組織和跨企業的工作流程管理系統，以利彼此
之間溝通協調商業活動的繁雜事務，提升彼此的合作效率，是工作流程管理系統的首要目
標。 
 
本篇計畫旨在研究工作流程管理系統（Workflow Management System, WfMS）上進行
系統之測試及驗證所需的技術及理論。我們的目標是要提出一個全自動化的測試驗證平台
及環境，系統發展者只要具體指定其應用系統之規格、資源及限制，就可以自動進行測試
及驗證，如果平台發現問題或錯誤也能將其發生的情形記錄下來回報給系統發展者，作為
除錯的依據。 
 
我們定義一個通用的測試腳本語言(Test Script Language)，使用此語言來描述工作流程
管理系統與使用者間複雜的互動過程以及測試條件，並且詳述工作流程管理系統上之測試
策略(Testing Strategy)。 
 
關鍵字： 
工作流程、工作流程系統、工作流程管理系統、自動測試、軟體測試、測試腳本語言 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4 
 
 
1 Introduction 
Software testing is an activity which is part of the software development process aimed at 
evaluating a software item against the given set of its requirements. Sometimes, software testing 
implies running the software item in predetermined conditions, recording and analyzing the 
obtained results, and identifying errors (i.e. bugs), which means failure to satisfy a set of 
requirements to the software. Dynamic testing in software engineering refers to examining the 
physical response of a system to variables that change with time, and is used to test the dynamic 
behavior of code [1]. Unlike in static analysis, in dynamic testing the software must actually be 
compiled and run. This involves working with the software, giving input values, and checking if 
the output is as expected. Dynamic testing methodologies include unit testing, integration testing, 
system testing, acceptance testing. Source-code-level dynamic testing has been considered an 
important step in the software life cycle (software development process) [2].  
Workflow management systems (WfMSs) are software systems for supporting coordination 
and cooperation among members of an organization whilst they are performing complex business 
tasks [3,4,5,6,7]. The business tasks are modeled as workflow processes, which are automated by 
the WfMS. The workflow model (also referred to as the workflow process definition) is the 
computerized representation of the business process. It defines the starting and stopping 
conditions of the process, the activities in the process, and control and data flows among these 
activities. An activity is a logic step within a workflow, which includes the information about the 
starting and stopping conditions, the users who can participate, the tools, data, and resources 
needed to complete this activity, and the constraints on how the activity should be completed. 
Activities are usually organized into a directed graph that defines the order of execution among 
the activities in the process. Nodes and edges in the graph represent activities and control flow, 
respectively. A workflow process instance is the execution of a workflow process definition by 
the WfMS. The execution of a workflow process instance is controlled by the workflow engine. 
Figure 1 shows an example of a workflow process definition which represents the process of 
asking for leave in an organization. It is consists of nine activities. The flows are different for 
different number of days.  
 
6 
 
User interface
Activity participants
Workflow engine
Output message
Input message
Input message
•
•
•
 
Figure 2: The communication model between WfMS and participants 
 
Second, a WfMS application is always developed to assist people to handle complex tasks 
which usually involve a variety of different resources in addition to the computer hardware and 
software systems. For example, cars in a car rental software system and staffs in an 
administrative unit can be considered as the resources in a WfMS. Although these resources do 
not exist in the WfMS engine, the monitoring, managing, and operation of them can cause 
failures or exceptions in the execution of a WfMS [9,10]. The state transitions, creation, and 
removing of resources can be either triggered by the execution of activities or occur 
spontaneously. In the former case, for example, the execution of an activity may allocate a staff 
to perform a specific task. In the later case, a rented car may be out of order when it is used by 
the customer. 
Workflow process P2
B1 B2 B3
B4
B5
Workflow process P1
A1
A2
A3
A4 A5
-Activity
- Connection edge
- End of workflow
Resource A Resource B
- Resource access
- Resource
a1 a2
a3
a4
 
Figure 3: The data racing in the workflow management system 
  
Third, the operation or execution of a WfMS application may contain non-deterministic 
8 
 
We propose an operational mode to the testing of WfMS. Except that the mentioned three 
problems should be solved, our scheme can support automatic testing dynamically. Put on 
another way, it is a systematic scheme to perform traditional coding testing on WfMS. The testing 
platform is not designed for any specific workflow definition. Thus, it is platform independent. It 
makes it be capable of applying to WfMSs with different definitions and platforms. We design a 
language for the workflow designer to specify testing script which contains workflow related 
information such as activity participants, input and output messages of activities, resource 
information, validation rules, etc. Also, we give the classification of faults in WfMS and propose 
the corresponding testing strategy.   
This report is organized as follows. Section 2 surveys previous work on testing and validation 
of WfMS. Section 3 gives the classification of faults and proposes a testing strategy for WfMS. 
Section 4 discusses the proposed testing framework and the syntax of testing script. Section 5 
presents how to apply the dynamic effective testing to our framework. Section 6 presents the 
results of experiments, and Section 7 concludes this report.    
 
2 Related work 
First, we give a brief introduction to the related work of applying the model checking to the 
validation of WfMS. Cao et al. proposed to verify BPEL modeled by UML activity diagram [16]. 
It proposed to map from UML activity diagram to PROMELA code of the model checker SPIN to 
verify BPEL models. Since it is based on SPIN, it provides the verification of default properties 
such as safety and liveness. Mongiello and Castelluccia proposed a framework that performs 
automatic verification of formal models of business processes through NuSMV model checker 
[17]. Each single web services partner is modeled as a fine state machine. The BPEL documents 
are translated into SMV codes and then processed by the NuSMV model checker. Nakajima 
presented a scheme to verify the Web services flows [18]. It used WSFL as the Web service flow 
language and SPIN as the model checker. Ouyang et al. presented a scheme by translating BPEL 
processes to Petri nets and applying existing Petri net analysis techniques to perform static 
analysis on BPEL processes [19]. Foster et al. describe an approach to modeling and verifying the 
compositions of Web services workflows using the finite state processes (FSP) notation [20]. A 
model checking tool and message sequence charts are employed to verify the workflow behavior. 
Qian et al. presented an algorithm of the mapping from BPEL to timed automata and integrate it 
10 
 
Workflow process P1
Workflow process P3
Public level
WfMS
Properties A
Common 
Properties B
Protected level
Workflow process P2
Private  level
Common 
Properties C
Properties A
Relation
 
Figure 4: Three levels of faults in WfMS 
 
Since an application or system may contain a lot of workflow processes with different 
definitions, it is always a very complex work to testing an application in a whole. We think the 
testing such applications should advance gradually as show in Figure 5. The testing strategy is 
divided into three stages. 
z Single-instance-single-definition (SISD) testing: It is to test if the application contains 
private level faults. Each workflow definition is used to instantiate a single workflow 
process. We examine if the execution of the implemented workflow definition violates 
the definition of the workflow.  
z Multiple-instance-single-definition (MISD) testing: When the SISD is finished, we 
should then take the MISD testing. Each workflow definition is used to instantiate 
multiple workflow processes. One of the goals of it is to detect if those processes have 
non-deterministic behavior so as to cause faults which relates to data sharing or event 
synchronization.  
z Multiple-instance-Multiple-definition (MIMD) testing: After SISD and MISD testing, 
we can only make sure that the instantiation of a single workflow definition is without 
faults. The MIMD is to instantiate some workflow processes for all the workflow 
definitions in the application. Non-deterministic behavior, event orders, and 
synchronization related faults between workflow processes with different definition are 
expected to be found out during this stage. 
 
12 
 
 
User interface
Agent
Agent
Validation 
tool
Execution log 
collector
Workflow management system
Resource Manager
Testing script
Resource pool
Trigger of 
state transition
of resources
Collection of events
Collection 
of events
Access the 
script testing
 
Figure 6: The operation model of our testing framework 
The agent communicates with the user interface of the target WfMS. According to the 
information in the testing script, it verifies if the input messages and the participants are correct 
and then send out the output messages to the WfMS via the user interface of the target system. 
Thus, there is no need for the tester to play the role of each participant to enumerate all the 
possible combinations of the input and output messages. The agent may generate faults report 
when the participants and the input messages are wrong dynamically. Also, since the agent 
simulates the execution of activities, it may trigger the state transitions of the resources during its 
execution.  
  The resource manager is a simulator of resource entities. The state change of the resource 
entity can be triggered either by the execution of activities or spontaneously by itself. An example 
of the former is that the participant should occupy a fax machine during an execution of an 
activity. Put on another way, there is a possibility for resources like a car to be out of order. The 
operation of the resources includes their creation, deletion, and state transitions are considered as 
events in the WfMS and thus are sent to the execution log collector. 
The execution log collector is responsible for collecting the events during the execution of 
workflow processes. The events include the operations of resources, the start and end of activities, 
share resource accesses, etc. The validation tool receives the collected log from the execution log 
collector and the agent. It checks if the execution of the workflow process violates the specified 
properties and constraints in testing script. These constraints are checked either statically after the 
14 
 
indicates the starting of the definition of a testing script. The tag <Applications> means that a 
single document can contain testing descriptions for multiple applications. Then, the tag 
<Application> under it has three sections which define a complete details for the testing of a 
single application. The resources definition section describes how to simulate the operation of 
physical resources. The participant behavior section contains information about how the 
participant interacts with the workflow activity and triggers the state changes of the resources. 
The workflow constraint definition section is for the workflow designer or tester to define the 
properties and constraints of the workflow application. The testing platform will signal an error 
report when the execution of the system violates the given properties and constraints.   
 
4.1 The resources definition section 
The goal of this section is to instruct the testing platform to simulate the operation of the physical 
resources which cannot be instantiated in the system. Figure 8 shows the syntax of it.  
 
Resources_Definition Æ <resourses>Resource</resourses> 
Resource Æ 
<Resource> 
    <Type>String</type> 
    <Name>String</name> 
    <Number>INT</number> 
        <Owners>  
       [Owners] 
        </Owner> 
    <States> 
       State_INFO  
    </states> 
        <InitialState>StateName</initialState> 
        <SpontaneousActions> 
       [SpontaneousActions] 
        </SpontaneousActions> 
</Resource>{ Resource }  
Owners  Æ <Owner num=“INT”>FlowName</Owner>{Owners} 
State_INFO Æ <state Workable=“Decision">StateName</state>{State_INFO} 
SpontaneousAction Æ <SpontaneousAction > 
 Script  
</SpontaneousAction> {SpontaneousAction} 
16 
 
  < State Workable="yes">ONTIME</ State > 
  < State Workable="no">Late</ State > 
  < State Workable="yes">No Oil</ State > 
 </States>  
     <InitialState>GOAWAY</InitialState> 
     <SpontaneousActions> 
      <SpontaneousAction> 
     <![CDATA[ FROM NO-OIL TO IDLE WHERE WAITING 1 ]]> 
      </SpontaneousAction> 
     <SpontaneousActions> 
</Resourse> 
Figure 9: An example of the resource definition 
 
4.2 The participant behavior section 
To activate an automatic testing process without the human being, we should specify all the 
possible input and output messages of each participant in each activity. We consider the execution 
of an activity consisted of a sequence of pages. In each page, the WfMS shows some information 
to the participant in the <Presentation> which consists of string, image, checkbox, buttons, etc. 
The participant then generates some input information in the  <ParticipantInput> element to 
send to the system via the user interface and the behavior of the participant is defined in the 
<ParticipantAction> element which may trigger the state transitions of some resources.  
 
Participant behavior definition Æ <ParticipantBehavior>Process</ ParticipantBehavior > 
Process Æ <Process Name=“String">   
         Activity { Activity } 
           </ Process > { Process }  
Activity Æ <Activity Name=“String"> 
 Page 
</Activity> 
Page Æ <Page seq=“INT"> 
        [Presentation_Info] 
        [ParticipantInput] 
        [ParticipantAction] 
        </Page> { Page } 
Presentation_Info Æ <Presentation> 
                Object { Object } 
               </Presentation> 
18 
 
  </ProcessName> 
</ParticipantBehvior> 
Figure 11: An example of the participant behavior definition 
 
4.3 The workflow constraint definition section 
In the section, the workflow developer defines the constraints of the system. It is specified in the 
temporal logic. The execution log collector will produce event sequence during the testing of the 
system. Its idea is similar to the SYN-sequence which is collected during the dynamic testing of 
non-deterministic concurrent programs. Since the sequence is consisted of events which are 
occurred during the execution of the WfMS, we call it WfMS-event sequence. We classified 
events into the following categories: 
z Process_Instantiation(Name_of_process,Process_id,Time): It is the event of the 
creation of a process instance. 
z Process_Termination(Name_of_process,Process_id,Time): It is the event of 
termination of a process. 
z Activity_Start(Process_id, event_id,Time): It is the starting of an activity. 
z Activity_End(Process_id, event_id,Time): It is the end of an activity. 
z Resource_Operation(Type,Time): It is an operation to a resource. 
z Shared_Data_Operation(Type,Version): It is the operation to a shared data. 
 
The validation tool uses the temporal logics specified in this section to validate the collected 
WfMS-event sequence. It requires the technology to validate a partial order of events generated 
during the dynamic testing [Cite]. In the follows, we give some examples of the temporal logic.  
 
z The number of a process instances does not exceed five:  
G ( cnt ൑ 5 ) 
z The execution of activity A1 is before the activity A2. (A1 ֜ A2) 
G ൓ ( A2.Activity_Start → F A1. Activity_End ) 
z The execution of activities A1 and A2 must be in parallel. (A1 // A2) 
G ( A1 ש A2 → ൓ ሺA1 ֜ A2 ר A2 ֜ A1ሻ ) 
z If there exists an execution loop of activities A1, A2, A3, then this loop cannot iterate 
more than three times. 
20 
 
from S. 
(3) For each new race variant R derived in step (1), perform a prefix-based replay of P with 
input X and R to execute and collect an additional SYN-sequence for P with input X. The 
prefix-based replay of P with a race variant R comprises two phases: 
(i) Replay phase: control the execution of the program by following the execution order 
specified in R. 
(ii) Monitor phase: execute the program without any control and record subsequent 
synchronization events after replaying R. 
(3) Repeat steps (1) and (2) for each new SYN-sequence collected in step (2). 
 
Note that R is not a complete SYN-sequence of an execution of P. Thus, after replaying R, we 
have to record the subsequent synchronization events to obtain a SYN-sequence of an execution 
of P. This test produces a SYN-sequence. An entry protocol and an exit protocol must be inserted 
before and after each synchronization event in the original program, respectively.  
  To apply dynamic effective testing to our framework, the execution log collector needs to 
record the events sequence of the execution of the workflow processes for race analysis. Also, it 
must be able to perform prefixed-based replay for the race variant.    
 
Execution of P with input X
Race analyzer
(To derive race-variants)
Queue to store race-variants
… …
Prefix-based replay of R
(with dynamic termination decision)
Derived race-variants
Remove a race-variant R
from queue
A SYN-sequence S
Obtain a SYN-sequence
Check if it is a new
SYN-sequence
Yes
No
Discard the
SYN-sequence
SYN-sequence
Transformation Function
Some SYN-sequences
 
Figure 13: The dynamic effective testing 
 
 
22 
 
2  Roger S. Pressman, Software Engineering (A practitioner's approach), 5th edition, 2000, Mc Graw-Hill Education, 
ISBN 978-0071181822.  
3 D. Georgakopoulos, M. Hornick, and A. Shet. Overview of Workflow Management: From Process Modeling to 
Workflow Automation Infrastructure. Distributed and Parallel Databases, Vol. 3, No. 2, 1995, Pages 119–153. 
4   Shi Meilin, Yang Guangxin, Xiang Yong, and Wu Shangguang. Workflow Management Systems: A Survery. 
International Conference on Communication Technology, 1998.  
5 A. Elmagarmid, and W. Du. Workflow Management: State of the Art vs. State of the Market. Proceedings of 
NATO Advanced Study Institute on Workflow Management Systems, 1997.  
6  Workflow Management Coalition. Workflow Reference Model. Workflow Management Coalition Standard, 
WfMC-TC-1003, 1995.  
7  Workflow Management Coalition. Workflow: An Introduction. Workflow Handbook, 2002. 
8  Ellis, C.A., S.J. Gibbs, and G.L. Rein, Groupware: Some Issues and Experiences, Communications of the ACM, 
1991, 34(1):39-58. 
9  A Flexible Failure-recovery Model for Workflow Management Systems, by Gwan-Hwan Hwang, Yung-Chuan 
Lee, and Bor-Yih Wu. International Journal of Cooperative Information Systems, Vol. 14, No. 1 (2005) 1-24. 
10  Claus Hagen and Gustavo Alonso. Exception Handling in Workflow Management Systems. IEEE Transactions 
on Software Engineering, Vol. 26, No. 10, October 2000, Pages 943–958. 
11   Charles E Mcdowell and David P. Helmold, “Debugging Concurrent Programs,” ACM Computing Surveys, 
Volume 21, Number 4, December 1989.  
12   K.C. Tai and Richard H. Carver, “Testing of Distributed Programs,” Chapter 33 in Parallel and Distributed 
Computing Handbook, editor A. Y. Zomaya, McGraw-Hill, 1996.  
13  G. H. Hwang, K. C. Tai, and T.L. Huang, “Reachability Testing: An Approach To Testing Concurrent Software,” 
International Journal of Software Engineering and Knowledge Eng., 5, 4, (Dec. 1995), 493-510.  
14  Gwan-Hwan Hwang, Sheng-Jen Chang, and Huey-Der Chu, “Technology for Testing Nondeterministic 
Client/Server Database Applications,” IEEE Transaction on Software Engineering, Volume 30, Number 1, pp. 
59-77, Jan., 2004.  
15  Abraham Silberschatz, Peter Baer Galvin, and Greg Gagne, “Operating System Concepts,” John Wiley & Sons, 
ISBN: 0471417432, 6th edition (June 26, 2001).  
16  Honghua Cao, Shi Ying, and Dehui Du, “Towards Model-based Verification of BPEL with Model Checking,” 
The sixth IEEE international conference on computer and information technology (CIT’06).  
17  Marina Mongiello and Daniela Castelluccia, “Modelling and verification of BPEL business process,” 
Proceedings of the fourth workshop on model-based development of computer-based systems and third 
international workshop on model-based methodologies for pervasive and embedded software 
(MBD/MOMPES’06).  
18  Shin NAKAJIMA, “Verification of Web Service Flows with Model-Checking Techniques,” Proceedings of the 
first international symposium on cyber worlds (CW’2).  
19  Chun Ouyang, Eric Verbeek, Wil M.P. van der Aalst, Stephan Breuted, Marlon Dumas, and Arthur H.M. ter 
