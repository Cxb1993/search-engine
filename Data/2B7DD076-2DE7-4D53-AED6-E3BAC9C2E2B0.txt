 2
detection of speech attributes and events, (2) 
the integration of speech events and relevant 
knowledge, (3) the verification of events and 
evidence, (4) the design of knowledgebases, 
speech corpora, speech and language models, 
and software tools, and (5) the shared 
platform for joint design and assessment. 
Under this collaborative mode, the 
knowledgebases, corpora, models, and 
software tools generated will be opened to 
public so as to bring in more researchers to 
the ASR area. This gives a decisive chance to 
promote the research and development of 
speech technology in Taiwan. 
As an indispensable part of the whole 
collaborative project, this subproject focuses 
on: (1) establishment of speech corpora for 
benchmark test, (2) analysis of tags in the 
speech corpora, (3) study on cues for 
speech/non-speech detection, (4) study on 
segmental features for ASR, (5) study on 
prosodic features for ASR, (6) study on cues 
for language identification, and (7) 
development and evaluation of tools and 
models for ASR. 
 
Keywords: speech recognition, 
knowledgebase, speech corpora, benchmark, 
shared platform, speech attributes, speech 
events 
 
 
二、計畫緣由與目的 
 
自動語音辨識技術發展了四十年，早期的
語音辨識是依據語言學專家所知道的聲音
分類知識，許多人投入研究聲學與語言學
的規則，以建立語音辨識的機制，可以說
是以知識驅動(knowledge-driven)的解決方
法。這個方法需要語言學知識，用以建立
一個以規則為基礎的(rule-based)語音辨識
系統，但是這種系統難以應付複雜的變
化，可以說沒有強健性 (robustness)的考
慮，在隱藏式馬可夫模型(hidden Markov 
model, HMM)被提出之後，以知識驅動的
語音辨識方法就被放棄了，幾乎完全由以
語料庫為基礎的(corpus-based)語音辨識系
統所取代。到了1990 年代，許多由資料驅
動(data-driven)的演算方法被提出來，自動
語音辨識技術有了快速的進步，大詞彙連
續語音辨識 (large vocabulary continuous 
speech recognition, LVCSR)技術被開發出
來，所依賴的就是大量的語音資料與語言
資料。進入21 世紀之後，現有的技術還是
遠遠無法與人類辨識語音的能力相比，而
現有技術的進步空間有限，於是技術的進
展慢了下來。下一步該怎麼走？2003 年10 
月美國NSF在喬治亞理工學院舉辦"NSF 
Symposium on Next Generation ASR"，邀集
全美語音辨識研究領域頂尖的學者專家，
在兩天的會期中，對於語音辨識過去四十
年的發展進行檢討，並規劃未來語音辨識
研究的方向。與會者一致同意目前資料驅
動的模式，必須與語言及音韻知識密切結
合，才有機會突破目前語音辨識技術面臨
的瓶頸。 
本整合型計畫的目的是建立一個以知
識為基礎，整合資料驅動的語音辨識模
式，利用開放的測試平台，建立各界能夠
共享的一個合作的設計與評量機制，將自
動語音辨識推向下一個新世代。研究的重
點項目包括：(1)語音屬性與事件之偵測、
(2)語音事件與相關知識的整合、(3)事件與
證據的確認、(4)知識庫、語料庫、模型、
以及工具之設計、(5)建立合作設計與評量
的共享平台。 
本子計畫的目的是與總計畫及其他子
計畫共同合作建立相關的知識庫、語料
庫、模型、以及工具。相關研究成果及建
立的共享平台將提供國內學術界與研究機
構使用，希望讓更多人參與語音辨識的研
究，提升我國的語音研究水準，開發語音
辨識的相關產品。 
 
三、結果與討論 
 
本計畫執行期限為94年8月1日至97年7月
31日，第二年的主要工作項目包括：(1)開
發 自 動 音 素 分 段 (automatic phoneme 
segmentation)技術，以加速語料庫標記的進
度；(2)進行國語語料庫的音素自動標記及
人工修訂；(3)利用支向機(support vector 
machine, SVM)分類器，探討各種語音特徵
線索。 
 
A.HMM自動音素分段 
 
 4
).|(maxarg
))|(1(minarg
)|(minarg
)|(),(minarg
,
SOP
OSP
OSP
OSPSSLS
S
S
j
SSSS
jj
SS
MER
jj
j
=
−=
=
=
∑
∑
≠∈
∈
Φ
Φ
 
然而，使用 0-1 損失函數意謂著不考
慮任兩類(邊界序列)實際上的減損，即不
論多大的減損均視為相等，這與我們最終
的目標(降低整體邊界的誤差)有所牴觸。
故我們改進此項缺失，重新定義減損函
數，使分類過程更為合理。我們將減損函
數定義為實際邊界誤差，則可得到： 
).|(),(minarg
)|(),(minarg
1
OSPqqer
OSPSSERS
j
j
nn
N
nSS
jj
SS
MBE
j
j
∑∑
∑
=∈
∈
=
=
Φ
Φ
 
其中 N 表示O所包含的音素個數， nq 為 S
中第 n 個音素， jnq 為 jS 中第 n 個音素，
),( jnn qqer 為此二音素的實際邊界誤差。同
樣，為了增加實作的可行性，我們使用 LatΦ
來近似Φ，可得到 
).,()|(minarg
),()|(minarg
1
1
j
nnj
S
N
nS
j
nnj
N
nSS
MBE
qqerOSP
qqerOSPS
j
j
∑∑
∑∑
∈=
=∈
=
=
Lat
Lat
Φ
Φ
我們定義切集(cut) nC 為音素網格圖上所有
第 n 個音素段落 (phoneme arc)所成的集
合，則上式可再化簡成： 
{ }
).,()|(minarg ,
|1 ,,
mnnj
SqSq
N
nS
MBE qqerOSPS
jmnjnmn
∑∑∑
∈∈∈=
=
LatΦC
其中 mnq , 為 nC 中第 m 個音素段落。由於
{ } )|(,| OSP jSqS jmnj∑ ∈∈ LatΦ 可使用前向-後向演算
法求得，計作
mnq ,
ρ 。擁有最小邊界誤差的
邊界序列可進一步由動態規劃 (dynamic 
programming)演算法來搜尋，即 
).,(minarg ,
1
,
,
mnnq
q
N
nS
MBE qqerS
mn
nmn
ρ∑∑
∈=
=
C
 
然而，最小邊界誤差校準雖然可以找
到更佳的邊界序列，但整個過程的複雜度
提高不少，主要原因在於最小邊界誤差校
準為一種後處理的搜尋方法。第一階段需
先產生音素網格圖，包含大量的候選邊界
序列，於第二階段時供最小邊界誤差校準
搜尋，故執行時間複雜度較高。 
由於 HMM 對時間持續所產生的機率
分佈並不合乎實際統計所得的分佈，在過
去，有許多時間持續模型(duration model)
被 提 出 來 解 決 此 問 題 ， 如 hidden 
semi-Markov model (HSMM) 、 expanded 
state HMM (ESHMM)及後處理時間持續模
型(post-processor duration model)等。後處
理時間持續模型需於第一階段產生大量的
候選序列，供第二階段結合時間持續模型
機率來找尋。故本計畫嘗試結合後處理時
間持續模型及最小邊界誤差校準來克服
HMM 的不足。時間持續模型機率是以音素
段落為單位，故音素段落的相似度將修正
為： 
)()()(~ τβ qdqpqp ⋅= . 
其中 q 為音素段落， )(qp 為原來的相似
度， )(~ qp 為修正之後的相似度， )(τqd 則表
示q持續時間為τ 時的機率。β 則是用來平
衡兩項的動態範圍。本計畫使用非參數式
(nonparametric)的時間持續機率分佈，此分
佈由訓練語料統計而來。 
本計畫以 TIMIT 英文語料作為實驗平
台，用來測試所提出方法的成效。實驗語
料中分別包含了約 4,500 句訓練及 1,600 句
測試語料。聲學模型則採用 50 個由左至右
(left-to-right) 前 後 文 無 關 
(context-independent) 的 HMM 模型，每個
模型用來描述一個音素。在特徵向量方
面，則是採用 39 維經過變異數正規化 
6.50
7.50
8.50
9.50
10.50
11.50
12.50
13.50
0
(ML)
1 2 3 4 5 6 7 8 9 10 iter
Frame Err
(%)
TrainSet TestSet TrainSet cri
圖一、最小誤差訓練之音框錯誤率。橫軸為模型
訓練的次數，縱軸為音框錯誤率 (Frame error 
rate)，紅線代表訓練語料的期望錯誤率，綠線及
藍線分代表在測試及訓練語料中的實際錯誤率。
 6
中取得平衡，我們利用群聚法將信號特性
相近的音素邊界集合在一起，並集合群聚
中的轉換共同訓練一個音素轉換相關的
(phone-transition-dependent) 支 向 機 分 類
器。我們實作了兩種群聚方法：K-均數
(K-Means)群聚法和決策樹(decision tree)群
聚法。 
K-均數音素轉換群聚法描述如下：對
每一種音素轉換，取出所有屬於該種音素
轉換之人工標記邊界對應的特徵向量，並
計算其平均值。我們將音素轉換分為四大
類：響音(sonorant)接非響音、響音接響音、
非響音接非響音和非響音接響音，並分別
對屬於這四大類的平均值向量做 K-均數分
群。資料不夠的音素轉換不納入分群，而
是待分群結束後，歸入距離其平均值向量
最近的群聚中心(cluster center)所屬的群
聚。 
K-均數音素轉換群聚法的缺點是待測
資料的音素轉換若未曾在訓練資料中出
現，則不知道該歸屬於哪一類，而決策樹
群聚法則可避免這個問題。我們建立了以
下形式的問題集「轉換邊界左邊的音素是
否屬於集合 X，而右邊的音素是否屬於集
合 Y？」我們根據語音學的知識定義了大
小不等的 397 個集合，大者如響音、母音
集合，小者則只包含單一種音素。 
實驗結果如表二所示，HMM*為表一
中 HMM 自動音素分段的最佳結果。支向
機在 HMM 自動音素分段的初始邊界左右
各 5 毫秒範圍內尋找最佳的邊界。SVMKM
是採 K-均數分群的結果，而 SVMDT則是決
策樹分群的結果。我們發現兩者皆可降低
音素分段的誤差，SVMKM 略勝於 SVMDT。 
 
不同容忍誤差下邊界的準確率
(%) 訓練方式 
平均邊
界誤差 
(毫秒) ≦5ms ≦10ms ≦20ms ≦30ms
HMM* 7.14 59.58 81.57 93.73 97.17
HMM*+SVMKM 6.83 62.07 83.70 94.12 97.28
HMM*+SVMDT 6.75 62.47 84.00 94.33 97.35
表二、TIMIT 語料下平均邊界誤差(ms)及在不同容
忍誤差下邊界的準確率(%)。 
 
C. 國語語料音素自動標記及人工修訂 
 
MATBN (Mandarin Across Taiwan 
Broadcast News) 電視新聞語料為本實驗
室耗時三年與公共電視合作錄製完成，共
收錄 198 天、每天一個小時的公視晚間新
聞。所有的 MATBN 語料都含有正確轉譯
文句以及音樂、背景雜訊、停頓、語助詞、
呼吸、強調語氣、反覆、不適當的發音等
標記，這些轉譯文句與 SGML 標記均使用
DGA&LDC 的轉寫器 (Transcriber) 來完
成。由於 MATBN 語料含豐富標記資訊，
使得本語料的應用價值大為提高。為配合
本整合型計畫的需求，本子計畫從中選出
約五小時的語料，進一步進行人工音素邊
界的標記，建立之標準語料庫將作為總計
畫及各子計畫之測試基準。 
為了節省人工標記的成本，本計畫利
用HMM自動音素分段與SVM音素邊界調
整來提供初始音素標記，作為後續人工校
正與驗證的基礎。本計畫將五小時的語料
分成數個五分鐘的子語料集，對第一個子
語料集，我們使用非監督式訓練來估測模
型參數，產生初始音素邊界供人工校正，
並於完成後作為監督式訓練的語料，用來
產生下一子語料集的初始音素邊界。為了
避 免 語 料 過 少 引 起 的 過 度 訓 練
(over-training)問題，我們也將未標記的語
料加入訓練語料中，用來提供更可靠的模
型參數估測。當一子語料集經過人工修正
之後，將納入下一子語料集的監督式訓練
語料，以提高下一子語集的音素邊界標記
正確率，如此反覆的進行，直到所有的子
語料集都被修正完成。如此，每一階段具
人工標記的訓練語料會愈來愈多，模型參
數的估測會愈來愈可靠，自動標記的邊界
也會愈來愈正確，可以降低整體人力成
本。目前第一子語料集已由人工修正完
成，第二子語料集也已完成過半，因此可
以進行簡單的實驗來驗證所提出的自動切
音方法，實驗結果請見表三。 
 
D. 語音事件偵測 
 
去年度我們利用支向機，實作了英文的響
音(sonorant)事件偵測器。今年則進一步發
展了一套涵蓋靜音(silence)、母音(vowel)、
半母音(semi-vowel of approximant)、磨擦音
(fricative)、鼻音(nasal)和塞音(stop)共六大
