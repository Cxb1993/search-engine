1九十九年度行政院國家科學委員會專題研究計畫成果報告
計畫名稱：基於形態學之手掌雙模態身份辨識之研究
Study of Bimodal Hand Recognition Based on Morphology
計畫編號： NSC 99-2221-E-260 -001 -
執行期限：99 年 8 月 1 日至 100 年 7 月 31 日
計畫執行機關：國立暨南國際大學 電機工程學系
計畫主持人：陳文雄（Wen-Shiung Chen）教授
計畫研究助理：鄭仁和、王蔚強、陳振淵、林于捷、鍾易陞
中文摘要：本年度基於形態學之手掌雙模
態身份識研究所提出系統可分為四個模
組：影像擷取、前處理、特徵萃取與辨識
模組。前處理模組依照個人中指的長度定
義手掌區域。特徵萃取模組則利用影像形
態學與 Voronoi diagram 的概念，將手掌
正面的影像依照掌形，切割成若干不規則
形狀的小區塊，接著以小區塊中灰階之統
計特性做為特徵值。本計劃提出一套兩階
段辨識模組，分別以掌形與掌紋為特徵。
第一階段利用手掌之帶狀區域的數目進
行粗糙辨識，第二階段利用區塊中的灰階
之平均或變異量當作為特徵碼以進行細
部辨識。實驗資料庫以本實驗室自建的手
掌影像資料庫做實驗，獲得令人滿意的結
果。錯誤接受率（false acceptance rate;
FAR）為 0.0035%；錯誤拒絕率（false
rejection rate; FRR）為 5.7692%。最後以
F-ratio 檢視手掌中那些區域的統計特徵較
具鑑別度。
關鍵詞：生物辨識、掌紋、掌形、影像形
態學、支持向量機。
Abstract－The proposed system consists
mainly of four modules: image acquisition,
pre-processing, feature extraction, and
recognition modules. The pre-processing
module utilizes the length of middle finger
to define the region of palm. The feature
extraction module employs the image
morphology and concept of Voronoi
diagram to divide the palm image into a
number of irregular blocks in accordance
with the hand geometry. Furthermore, some
statistical measurements of the gray level
for each block are extracted as feature
values. Then, we present a two-stage
recognition based on the features from
hand-shape and palmprint of a hand. First
stage utilizes the number of stripe regions of
a palm as the feature value. Second stage
encodes the means or variances of the pixel
gray levels of the blocks as feature codes.
The experimental results show that the
proposed system has an encouraging
performance on our own hand database. The
false acceptance rate (FAR) and false
rejection rate (FRR) down to 0.0035% and
5.7692%, respectively. Finally we look over
with F-ratio in which areas with statistical
characteristics in front of the whole palm
have discriminative characteristics.
Keywords: Biometrics, Palmprint, Hand
Geometry, Morphology, Voronoi
Diagram, Support Vector Machines.
3圖 2 碎鏡法所切割成之影像示意圖
圖 3 碎鏡法流程圖
1. 帶狀切割
帶狀切割的步驟首先將手掌的二元
影像，重複的使用形態學中的浸蝕法，切
割成數個帶狀區域，如圖 4 所示。第 n 層
帶狀區域的定義：將經過 n-1 次浸蝕的手
掌二元影像，減去經過 n 次浸蝕的手掌二
元影像，所得之帶狀區域稱之為第 n 層帶
狀區域，如圖 4 所示，其中 n 為自然數。
圖 4 帶狀區域示意圖
帶狀切割會形成一些特殊的情況，在
此稱之為畸零區。畸零區（odd zone）的
定義：圖 5 所示紅色圓圈內的區域稱之為
畸零區，就是沒有與主要帶狀區域（面積
最大的連通成份）相連接的部份。
圖 5 畸零區
2. 塊狀切割
塊狀切割可以將帶狀區域切割成若
干塊狀區域，然後用小區塊中灰階之統計
特性做為特徵值。塊狀切割可分為五個步
驟，各步驟敘述如下：
Step 1. 影像閉合：
將帶狀區域的外圍邊緣，也就是第 n
層帶狀區域，其經過 n-1 次浸蝕的手掌影
像的邊緣，在去除畸零區後執行影像閉
合，使得整個邊緣成為一連通成份。
Step 2. 細線化：
對 Step 1 的結果執行形態學中的「細
線化」演算法，目的在於取得簡潔的邊
緣，如圖 6(a)所示。
Step 3. 剪除：
對前一步驟的結果執行形態學中的
「剪除」演算法，目的在於去除多餘的突
刺，如圖 6 (b)所示。
(a) (b)
圖 6 形態學處理(a) 細線化 (b)剪除
Step 4. 編號：
以第四谷點 V4 為起點，向小指尖的方
向，依序將其點座標存入一維陣列中。編
5到複製後的總點數等於 mn，然後依前述塊
狀切割的方法處理。當邊緣點總點數小於
mn，複製邊緣點的 pseudo code 如下。
虛擬碼 1.複製邊緣點。
定義：邊緣點 b1,b2,…bq
j = 0;
While q < mn
j = j + 1;
q = q + 1;
bq = bj;
end
狀況二：同一隻手掌的影像，因為拾
入誤差的關係，可能發生一張影像的最後
一層的帶狀區域如圖 8 (b)，而另一張影像
的倒數第二層的帶狀區域如圖 8(c)所示，
多出了幾個像素。為了解決這個問題，設
定當最後一層的點數小於容忍誤差δ則
不再切割；亦即視此帶狀區域為一塊狀區
域，故其特徵向量亦多出一維。為了彌補
這種誤差，其他沒有這種狀況的影像，如
圖 8(b)，所取得之特徵向量也將補上一維
特徵，其值設為前一維特徵的值，即重複
前一維特徵的值。
至於容忍誤差的設定，則以二元影像
中手掌影像的總像素個數除以容忍誤差
常數 h。通常誤差為個位數個像素，最多
十數個像素，而資料庫中二元影像中手掌
影像的總像素個數為 67,724~85,951 個，
因此 h 的值最大不可超過 10,000，但若小
於 1,000 則δ過大，以至於發生錯誤的機
率過高。本實驗為了測試系統故設
h=1,000 則δ=T/h，其中 T：二元影像中手
掌影像的總像素個數，h=1,000。
C. 虛構的特徵值之設定
狀況一、二中都會重複前幾維的特徵
值，為了使同一隻手掌的特徵向量維度一
樣，在此稱之為虛構的特徵值。本小節將
說明為何重複前幾維的特徵值，而不設定
為最大值或最小值。舉例說明如表 1。
表 1 設定虛構特徵值範例
類別 有無虛構特徵
前一維
特徵值
虛構特
徵值
A 手掌
A1
無虛構特徵
8 7
A2 影像
需虛構特徵
8 0
8 8
B 手掌
B1 影像
無虛構特徵
6 4
B2 影像
需虛構特徵
6 0
6 6
當設虛構特徵值為零時，將拉近與不
同手掌的距離（特徵空間中的距離），則
會提高 FAR。當設虛構特徵值為重複前一
維特徵值時，將拉近與同一隻手掌的距
離，則會降低 FRR。由於特殊狀況的發生
機率不高，且實驗結果中 FRR 偏高，故選
擇設虛構特徵值為重複前一維特徵值。而
重複特徵值時，其值為最大值或最小值的
機率極低。
3. 特徵向量的構成
A. 掌形特徵值
我們利用帶狀區域的數目 n 做為掌形
的特徵值，利用 n 做粗糙的辨識。也就是
說手掌影像所得之 n 若不相等，則確定影
像不屬於同一隻手掌。
B. 掌紋特徵碼計算
在經直方圖等化法處理後的灰階圖
中，以每個區塊中的灰階之平均或變異量
當作特徵碼，再依區塊的順序排列成特徵
向量，區塊數目就等於特徵向量的維度。
在決定塊狀區域的數目時，為避免造
成只有數個像素的塊狀區，使得在取其平
均或變異量時失去其區塊的代表意義，所
以 mn 必須隨著 n 的增加而遞減。又因為
外圈的外圍邊緣之邊緣點數，通常是內圈
7內圈最大區塊數目的一半減1。如此內圈
至少可以指定3圈的區塊數目，而當定比
因子為4.65時，內圈圈數通常不大於3。且
以小區塊中的灰階之平均為特徵值。實驗
結果列於表3，其中可以看出FAR，不會
因為區塊數目的增加而有大的改善，反而
FRR在外圈區塊數為40時有較好的效果。
表3 區塊數目實驗結果
定比
因子
外圈區
塊數
內圈區
塊數
FAR(%) FRR(%)
4.65 20 10-9(n-2) 0.0035 25.26
40 20-9(n-2) 0.0035 5.76
60 30-9(n-2) 0.0005 6.41
80 40-9(n-2) 0.0015 6.15
100 80-9(n-2) 0.0010 7.17
120 60-9(n-2) 0.0015 7.17
140 70-9(n-2) 0.0010 6.53
160 80-9(n-2) 0.0010 7.43
C. 統計特徵之影響
以前兩個實驗的結果，以FRR為主要考
量，取z =4.65、外圈區塊數為40。在切割
方式固定之後，取小區塊中的灰階的變異
量為特徵值。實驗結果列於表4，由中可
以看出，以變異量為特徵值的效果，不會
比以平均值為特徵值的效果好。
表4 區塊數目實驗結果
Mean
定比
因子
外圈區
塊數
內圈區
塊數
FAR(%) FRR(%)
4.65 20 20-9(n-2) 0.0035 5.76
Variance
定比
因子
外圈區
塊數
內圈區
塊數
FAR(%) FRR(%)
4.65 40 20-9(n-2) 0.0015 7.94
D. 以 F-ratio檢視特徵的鑑別度
實驗方法是由72個特徵開始，每次刪
去5個F-ratio最小的特徵值，直到特徵向量
剩下7個。由實驗結果可以看出，以少於
47個特徵做實驗，所得的FAR開始下降，
且 皆 低 於 0.006% ； 而 FRR 卻 高 於
14.359%。圖9顯示當特徵數減少，FRR快
速的上升，但FAR已無多大的改善空間
了。所以建議選用47個以上F-ratio值較大
的特徵。
(a)
(b)
圖 9 選擇特徵向量的實驗
E. 本系統與運用 Eigenpalm 的辨識法比
較
依照Eigenpalm的作法，採用weighted
Euclidean distance (WED)做為分類器，此
實驗將每一張測試影像，都與各類3張訓
練影像之平均做WED的比對。對以碎鏡法
所得之特徵向量做分類，碎鏡法的參數設
定為z =4.65、外圈區塊數為40，且未對訓
練資料做正規化。
9手指的姿勢改變而改變。所以找到更
穩定的尺度，將可以改善正確率。
iii. 使用碎鏡法的前提是：手掌影像必須
在正向視角的情形下拍攝。若使用者
在非正向視角的情況下拍攝，則必需
將手掌影像經仿射轉換（ affine
transform)，轉至正向視角所能拍得的
影像。因此測定影像中的手掌的傾斜
角度與方向，是個重要的課題。但是
因為手掌正面及側面的影像沒有明
顯的界限，使得測定手掌正面的傾斜
角度與方向，成為一個難題。
iv. 手掌影像在相同距離，但不同角度的
情況下拍攝時，其特徵值的變動就變
大。
除了上述這些研究方向之外，相信還
有其它問題有待開發和解決。希望本計畫
可以提供一些基本的參考方向，給未來在
此領域發展的研究人員。
References
[1] A. Kong, D. Zhang and M. Kamel,
“Palmprint identification using 
feature-level fusion,” Pattern
Recognition, vol. 39, no. 3, pp.
478-487, 2006.
[2] A. Kumar and D. Zhang, “Combing
fingerprint, palmprint and hand-shape
for user authentication,” 18th Int’l
Conf. on Pattern Recognition, vol. 4,
pp. 549-552, 2006a.
[3] A. Kumar and H. C. Shen,
“Recognition of palmprints using
wavelet-based features,”Proc. of Int’l
Conf. on Systems and Cybernetics,
2002.
[4] A. K. Jain and N. Duta, “Deformable
matching of hand shapes for user
verification,”Proc. of Int’lconf. on
Image Processing, vol. 2, pp. 857-861,
1999a.
[5] A. K. Jain, A. Ross and S. Pankanti,
“A Prototype hand geometry-based
verification system,” Proc. of 2ndInt’l
conf. on Audio- and Video-based
Biometric Person Authentication, pp.
166-171, 1999.
[6] A. Wong and P. Shi, “Peg-free hand
geometry recognition using
hierarchical geometry and shape
matching,”Proc. of IAPR Workshop
on Machine Vision Applications, pp.
281-284, 2002.
[7] A. W. K. Kong, D. Zhang and G. Lu,
“A study of identical twins’ 
palmprints for personal verification,”
Pattern Recognition, vol. 39, pp.
2149-2156, 2006.
[8] B. Schölkopf, J. C. Platt, R. C.
Williamson, A. J. Smola, and J.
Shawe-Taylor, “Estimating the
support of a high dimensional
distribution,”Neural Computation, pp.
1443-1471, 2001.
[9] C. C. Chang, & C. J. Lin (2001)
LIBSVM: a library for support vector
machines. Available at:
http://www.csie.ntu.edu.tw/~cjlin/libs
vm
[10] D. Zhang and W. Shu, “Two novel 
characteristics in palmprint
verification: datum point invariance
and line feature matching,” Pattern
Recognition, vol. 32, no. 4, pp.
691-702, 1999.
[11] E. Yörük, E. Konuko g˘lu, B. Sankur,
and J. Darbon, “Shape-based hand
recognition,”IEEE Trans. on Image
Processing, vol. 15, no. 7, pp.
1803-1815 2006.
[12] F. Li and M. K. H. Leung,
“Hierarchical identification of
palmprint using line-based Hough
transform,” 18thInt’lConf. on Pattern
Recognition, vol. 4, pp. 149-152,
2006.
[13] G. Borgefors, “Distance
transformations in digital images,”
Computer Vision, Graphics, and
Image Processing, vol. 34, no.3, pp.
344-371, 1986.
[14] G. Zheng, T. E. Boult and C.-J. Wang,
“Projective invariant hand geometry:
An Overciew,”Biometrics Symposium,
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
報 告 人
姓 名
陳 文 雄 服務機構
及 職 稱
國立暨南國際大學
電機工程學系
教授
時間
會議
地點
自 99年 09月 20日至 99年 09月 25日
西班牙 瓦倫西亞（Valencia, Spain）
本會核定
補助文號 NSC 99-2221-E-260-001
會 議 名 稱
(中文) 2010年第五屆國際全球資訊技術計算聯席會議
(英文) 2010 The Fifth International Multi- Conference on Computing in the
Global Information Technology（ICCGI2010）
發表論文題目
(中文) 以植基於嵌入零樹小波編碼之辨識虹膜技術作個人身份認證
(英文) Personal Authentication using Human Iris Recognition based on
Embedded Zerotree Wavelet Coding
前言：IARIA（International Academy, Research and Industry Association）為國際學術研究
與工業發展協會，其與 IEEE（The Institute of Electrical and Electronics Engineers）所聯合
舉辦的 2010年第五屆國際全球資訊技術計算聯席會議（Fifth International Multi- Conference
on Computing in the Global Information Technology ; ICCGI2010）為國際間有關資訊工業、
訊號處理與型樣識別學界相當重要且知名的國際會議。此會議集合了全世界各國與資訊工業
訊號處理與型樣識別領域理論與應用相關之研究學者發表最近一年的研究成果，所發表的論
文均經嚴格之審查，今年為第五屆，論文接受率約 30%左右。今年的 ICCGI2010會議於 2010
年9月20日至 9月25日六天在舉世聞名古老的文化之都西班牙 瓦倫西亞（Valencia, Spain）
舉行，此次會議與另外四個會議，包括 InfoWare 2010 / INTERNET 2010 / ACCESS 2010 /
ICWMC 2010，聯合舉辦，本人很榮幸受邀擔任此會議的 Technical Committee委員。ICCGI
整個會議包含四場 keynote address、三場 Panel Discussions以及四場 Tutorial Courses。論
文議程共分為十二個 technical sessions，全部以 oral形式發表論文。我們的論文被分在第三
天下午的 Session 5 - Bio-technologies, Cognitive Science, Complexity第一篇論文發表。
二、參加會議經過：本人於 9月 17日（週五）深夜搭乘長榮班機由桃園出發，於巴黎當地時
間 9月 18日凌晨 7:35抵達，並隨即轉機前往西班牙 瓦倫西亞，於下午 2:10抵達，隨
即 check in 於下榻的旅館。先暢遊瓦倫西亞兩天。會議是於 20 日~25 日共六天舉行。
20日中午赴研討會所在的地點瓦倫西亞技術大學(Polytechnic University of Valencia)報
到註冊，隔天並參加開幕典禮與Opening address。論文發表會是從 9月 21日上午 10:15
開始至 9月 24日下午 6:00結束。每天的 technical session，就根據自己的專長及興趣，
到各個不同的場次聽論文發表，或與相識的國內外教授學者相互交談、交換意見。第一
天除了參加幾個 session 聽一些論文報告之外，亦聆聽 Keynote address 演講，講題
為：”On the Trends and Challenges in Wireless Networking”，演講者為 Prof.
Mohammad S. Obaidat（Monmouth University, USA, IEEE Fellow）。我們的論文安排在
第三天下午 1:45-3:30 Session 5：Bio-technologies, Cognitive Science, Complexity的
Personal Authentication using Human Iris Recognition based on Embedded
Zerotree Wavelet Coding
Lili Hsieh
Information Management Dept.
Hsiuping Institute of
Technology Taichung, Taiwan
e-mail: lily@mail.hit.edu.tw
Wen-Shiung Chen
Dept. of Electrical Engineering,
National Chi Nan University,
Nantou, Taiwan
e-mail: wschen@ncnu.edu.tw
Tzung-Hao Li
Dept. of Electrical Engineering,
National Chi Nan University,
Nantou, Taiwan
e-mail: s96325528@ncnu.edu.tw
enhancing the iris image for the following feature extraction.
Hence, the image pre-processing module is composed of
three units: iris localization, iris segmentation with
coordinate transform, and enhancement units, as shown in
Fig. 1.
1) Iris Localization Unit
In this unit, we must determine the useful part (i.e., iris) from
an input image at first. The iris is an annular region between
the pupil and the sclera. The inner and outer boundaries of an
iris can be treated as non-concentric circles approximately.
In order to make the iris localization efficient, the system
performs an operation of enhancing principal edges and
blurring useless edges on the copied and downsample image
instead of the original one. Following that, the system
estimates the center coordinates of the iris first.
Figure 1. Pre-processing module.
Since the iris typically is darker than the Sclera and its
gray level distribution has a small variance, the system uses
Extended-Minima (EM) morphology operator [9]. EM
transform is the regional minima of the H-minima transform.
H-Minima transform suppresses all minima in the intensity
image which depth is less than a scalar. Regional minima are
connected component of pixels with the same intensity value
which external boundary pixels all have a greater value than
a scalar. We used 8-connected neighborhoods in this process.
By choosing an appropriate scalar in EM transform, a perfect
edge of outer boundary is obtained. The value of threshold is
decided, according to the histogram.
2) Iris Segmentation and Coordinate Transform Unit
The localized iris zone demarcated from the human eye is
transformed from rectangular into polar coordinate system so
as to facilitate the following feature extraction module.
When acquiring the human eye image, the iris zone images
may be of different sizes (outer and inner boundaries of iris)
due to the variations of camera-to-eye distance and/or
environment’s illumination. The variations will change the
patterns of iris texture to some extent. To solve this problem,
it is necessary to compensate for the iris deformation.
Daugman’s system uses radial scaling to compensate for
overall size as well as a simple model of pupil variation
based on linear stretching [2]. This scaling serves to map
Cartesian image coordinates to dimensionless polar image
coordinates. In addition, eyelids and eyelashes generally
obscure the upper limbus of an iris, so the procedure needs to
cut out the obscured area. The system generates a rectangular
iris image of a fixed size by linear interpolation. The image
size of iris is 512128.
3) Enhancement Unit
The normalized iris is easily affected by the non-uniform
illumination and may have low contrast. The final step of the
IIP module is to perform image enhancement in order to
obtain a good-quality image, which presents clearer texture.
The enhancement algorithm uses histogram equalization for
the normalized iris image to compensate for the non-uniform
illumination.
III. THE PROPOSED IRIS RECOGNITION METHOD
A. Embedded Zerotree Wavelet (EZW)
Embedded zerotree wavelet proposed by Shapiro in 1993 [6],
is based on the low frequency, is important than the high
frequency. First, an image passes through the discrete
wavelet transform (DWT), and embedded zerotree method is
used to set the threshold for coding the feature codes. The
feature extraction module adopts the set partitioning in
hierarchical trees (SPIHT) [7] based on EZW coding. The
SPIHT coding is shown in Fig. 2.
Figure 2. SPIHT coding procedure.
B. Feature Extraction with Embedded Zerotree Wavelet
The iris image always contains many tiny textures, which are
viewed as the noise, and different image in the same class,
and something, produce shift that pass through
downsampling to solve. In this system we use two different
methods to downsample the iris images. The downsampling
uses an mn mean mask that one is non-overlapped, as
shown in Fig. 3(a), and the other overlaps the region by half,
as shown in Fig. 3(b).
(a) (b)
Figure 3. (a) Non-overlap. (b) Overlap by half.
Figure 6. ROC curve.
TABLE 1. RECOGNITION ACCURACY
Optimi
zation Overlap
Size of
Features
(bytes)
AR
(%)
AA
(%)
FA
(%)
FR
(%)
N N 292 0.25 99.75 0.25 99.75
N N 73 0.13 99.87 0.13 99.87
N Y 292 0.01 99.99 0.01 99.99
N Y 73 0.05 99.95 0.05 99.95
Y N 292 0.25 99.75 0.25 99.75
Y N 73 0.08 99.92 0.08 99.92
Y Y 292 0 100.0 0 100.0
Y Y 73 0.02 99.98 0.02 99.98
V. CONCLUSION
In this paper, a personal authentication technique with
human iris recognition based on EZW and SPIHT coding has
been proposed. This work shows that SPHIT based on EZW
is suitable for encoding the iris features. The system may
achieve a good recognition rate of up to EER=0%. From the
experimental results, it is shown that the proposed iris
recognition technique with EZW is very suitable for the
environment with high security level.
REFERENCES
[1] A. K. Jain, R. Bolle and S. Pankanti, Biometrics:
Personal Identification in Network Society, Kluwer
Academic Publishers, 1999.
[2] J. G. Daugman,“High confidence visual recognition of
persons by a test of statistical independence,”IEEE
Trans. on Pattern Analysis and Machine Intelligence,
vol. 15, no. 11, pp. 1148-1161, 1993.
[3] R. P. Wildes et al., “A machine-vision system for iris
recognition,”Machine Vision and Applications, vol. 9,
no. 1, pp. 1-8, 1996.
[4] M. Nabti and A. Bouridane, “An effective and fast iris
recognition system based on a combined multiscale
feature extraction technique,”Pattern Recognition, vol.
41, no. 3, pp. 868-879, 2008.
[5] K. Miyazawa, K. Ito, T. Aoki, K. Kobayashi, and H.
Nakajima, “An effective approach for iris recognition
using phase-based image matching,”IEEE Trans. on
Pattern Analysis and Machine Intelligence, vol. 30, no.
10, pp. 1741-1756, 2008.
[6] C.-T. Chou, S.-W. Shih, W.-S. Chen, V. W. Cheng, and
D.-Y. Chen, “Non-orthogonal view iris recognition
system,”IEEE Trans. Circuits Systems for Video Tech.,
vol. 20, no. 3, pp. 417-430, 2010.
[7] J. M. Shapiro, “Embedded image coding using 
zerotrees of wavelet coeficients,” IEEE Trans. on 
Signal Processing, vol. 41, no. 12, pp. 3445-3462, Dec.
1993.
[8] A. Said and W. A. Pearlman,“A new, fast, and efficient
image codec based on set partitioning in hierarchical
trees,”IEEE Trans. Circuits Systems for Video Tech.,
vol. 6, no. 3, pp. 243-250, 1996.
[9] H. Proenc and L. A. Alexandre, Ubiris Iris Image
Database, http://iris.di.ubi.pt.
[10] A. Poursaberi and B. N. Araabi, “A novel iris
recognition system using morphological edge detector
and wavelet phase features,” ICGST International
Journal on Graphics, Vision and Image Processing, vol.
5, no. 6, pp. 9-15, 2005.
(a)
(b)
Figure 5. (a) The optimization variation of FRR and FAR. (b)
14 combinations of weights may obtain EER=0%.
99 年度專題研究計畫研究成果彙整表 
計畫主持人：陳文雄 計畫編號：99-2221-E-260-001- 
計畫名稱：基於形態學之手掌雙模態身份辨識之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
