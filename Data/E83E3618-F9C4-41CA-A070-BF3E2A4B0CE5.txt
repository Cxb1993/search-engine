 2
separability, neighborhood structure preservation, and NFS measurement, are all considered to find 
the most effective and discriminating transformation in eigenspaces. In the third part, the weighted 
sum of two classifiers is hybrid for classification. 
Keywords: face recognition, nearest feature line, discriminant analysis 
 
二、緣由與目的 
人臉辨識是目前監控系統以及生物認證中的熱門課題，在門禁系統與資訊安全等應用上
更是有相當大的需求，又由於目前攝影機的成本相當低，更促成了相關應用的發展，概觀目
人臉辨識方法，皆是將其人臉影像拍攝下來再經過系統直接作辨識，可是整張人臉影像卻容
易受到光線或是外在環境的影響而使辨識結果不穩定。目前人臉辨識流程可以分為三個步
驟：人臉表示法、具鑑別力特徵的抽取以及分類器設計。目前已有許多研究論文分別針對這
三個流程提出了多種不同的演算法以降低光線以及表情對人臉辨識的影響。在第一個步驟
中，研究主題在於抽取有用的特徵以表示不同的表情、光線變化以及角度，在第二個步驟中，
研究主題主要在於如何粹取最低維度且最具鑑別力的特徵空間出來，而在最後一個步驟中，
研究主題則在於如何設計或整合分類器。我們的研究成果主要可以分為三部分： 
1. 三階段人臉辨識架構。 
2. 最近特徵空間轉換法。 
3. 分類器設計。 
本研究計量提出一人臉辨識系統架構如圖一所示，其目的是希望降低光線及表情等變化
所帶來的影響以提高人臉辨識正確率。在模組一中，我們利用 Discrete wavelet transform(DWT)
轉換將高維影像降維，根據[8]中的結果，低頻影像 LL 能夠保留原影像中最不變的特徵。而
為了降低光線變化的影響，我們可以抽取具有一致性光線的區域特徵，而此目的可以藉由將
LL 影像取其灰階值與梯度值並將之等分為四個區塊來達成，分別是左半臉(L)、右半臉(R)、
上半臉(T)以及下半臉(B)，此八部分個別表示區域特徵以及獨立的特徵空間。此外，我們再對
原 LL 影像所取得的灰階值與梯度值作為全臉資訊(F)，目的是保留全域資訊。我們取得此十
個基於能量轉換所得到的部分臉以及全臉影像用以加強資料的鑑別力。有了具鑑別力的影像
特徵後，我們進一步需要好的特徵空間轉換，以進一步強化影像特徵的鑑別力，因此在模組
二中，我們提出一個新的特徵空間轉換法稱之為最近特徵空間轉換法，此特徵空間轉換法由
於不僅能將原空間中的拓樸資訊保留下來，更能將點到線所具有的一般性特點嵌入到特徵空
間中，使特徵空間更具有一般性，因此能提高人臉辨識的正確率。而在模組三中我們提出一
個多分類器整合的方法，以多分類整合方法提升辨識能力。透過了本計畫所提出的人臉辨識
流程，表情、光線變化以及角度等外在變化對人臉辨識的影響將可有效地降低，是本計畫的
貢獻。 
 
 4
1. 特徵強化與擷取：特徵強化通常是以影像處理的方法擷取重要的特徵，近期的論文
大多強調以人臉影像中的區塊(local region)特徵進行辨識會比以整張人臉進行辨識來
得有效，其原因在於區塊特徵通常包含了最細微的區別能力，然而，其缺點通常是
需要大而清楚的影像才行。此類型最著名的方法為 Local Binary Pattern (LBP)與Gabor 
feature，LBP 則受光線變化的影響較 Gabor Feature 為大，Gabor Feature 則是表現較
好的一種特徵強化方法，因為它最不受光線的影響。雖然以區塊特徵進行辨識比整
張臉的轉換來得好，但是光靠影像處理來降低光線、表情、姿勢的影響仍是不足的。
此外，梯度臉(gradientface)也是一種設計可用來降低光線影響的方式，透過簡單的水
平與垂直相減所得到的梯度特徵，光線的敏感度將可以有效的降低。 
2. 特徵空間轉換法：在特徵空間轉換法中，最重要的即為主成份分析(PCA)，主成份分
析之主要目的在「轉換」原始變項使之成為一些互相獨立的線性組合變數，而且經
由線性組合之後，得到的主成分仍保有原變數最多的資訊，故可直接比對主成份分
析後，求得特徵值(Eigenvalue)及特徵向量(Eigenvector)的相似程度作為分類的依據；
又或者進一步使用線性鑑別式分析(LDA)，則能夠將原始資料投射到最具鑑別性的向
量空間中，找出最大化及最小化分散(Class scatter)之間的轉換矩陣，由於加入類別資
訊，因此比主成份分析來得更為穩定。由於以 PCA 為基礎的演算法多著重於全域觀
點而忽略了區域局部的資訊，因此，近來有另一個與 PCA 觀點不同方法受到研究者
的重視，即使用 Laplacianface 進行人臉辨識(face recognition using laplacianfaces)。該
方法提出以特徵空間方法建立拉普拉斯矩陣(laplacian Matrix)為基礎的人臉辨識系
統，來保留訓練樣本之局部結構，其作法是在臉特徵空間中流型結構的區域性透過
區 域 保 存 投 影 方 法 (locality preserving projection, LPP) 在 最 近 相 鄰 關 係 圖
(nearest-neighbor graph)而保留下來。此外，研究者更進一步將拉普拉司臉方法加入費
雪條件(Fisher criterion)來最佳化組內緊密度和組間分離性，基於區域保存投影方法來
計算修改後的組內與組間變異，以保留局部結構，並且，使用正交基鄰近保留判別
分析 (orthogonal neighborhood preserving discriminant analysis, ONPDA)或邊境費雪分
析法(marginal Fisher analysis, MFA)等方法描述樣本之間鄰近關係的相似矩陣，此類
方法皆能大幅提升人臉辨識時對人臉表情、姿勢以及光線變化的容忍力。另一方面，
類神經網路在分類辨識問題上已行之有年，由於其非線性轉換的特性將輸入資料投
影到另一個新的空間，因此可以歸類為特徵空間的轉換，一般而言，類神經網路相
較於線性方法的優點有：(a)具有容錯的能力，(b)具有適應學習的能力，(c) 具有非線
性特徵空間轉換的能力。因此在人臉辨識中，仍有許多重要的方法，例如 Convolutional 
Neural Network、Radial based function neural network、probability neural network 等等
皆在人臉辨識領域中有不錯的表現。 
3. 分類器強化：近來，多分類器整合方法是一種相當熱門而且有效的人臉辨識技術，它認
為將多個分類器整合在一起後通常會發揮較佳的辨識能力。它將樣本的不同特徵由不同
的分類器進行訓練，並且評估不同分類器之間的分類能力，並適時給予不同的權重值，
最後進行加總，如此可以有如進行投票表決的方式進行人臉辨識，因此運用這個方法取
代傳統僅使用單一分類器所可能造成的誤差，可以簡單而有效的提升辨識結果，因此不
論是何種特徵，只需在比對階段採用不同分類器並予以整合，大多可以提升辨識率。 
 6
iy
nymy )(
)2(
, inmf y
nms , mns ,
 
圖一:最近特徵空間轉換法示意圖 
 
最後再以 Fisher's Criterion 將類別資訊加入，如下式： 
    
  




  c
i
j
P
K
P
iN
i
Ti
j
TPi
j
Ti
j
TPi
j
T
xFf
N
j
P
W ff
1
)()(
)(1
)( )xw(xw)xw(xw
)(
1
)(
S
 
(3) 
    
  




  c
i
j
P
K
P
iN
i
Ti
j
TPi
j
Ti
j
TPi
j
T
xBf
N
j
P
B ff
1
)()(
)(1
)( )xw(xw)xw(xw
)(
2
)(
S
 
(4) 
其意義為將同一類別的點到線的距離予以最小化，而不同類別之間的點到線的距離予以
最大化，如此即可以求得一特徵空間，而此一特徵空間為以點到線的距離為基礎的區別分析
所得到的特徵空間，不僅可以保留區域資訊，亦將類別之間的區別能力最大化。 
我們進行本模組的實驗，我們以 CMU 資料庫來驗證我們人臉辨識模組的強健性，第一
個實驗我們用以驗證本人臉辨識模組的空間轉換能力，我們取資料庫中的任三個人的所有影
像資料來表示，其中圖二為著名的 LPP 演算法，而圖三則為本模組所提出的演算法，我們可
以發現，我們的人臉辨識模在降到二維空間後，不僅能將三個類別的資料予以切割，亦能在
資料分佈上保留區域變化，例如人臉的光線、表情以及姿勢等，此外還能將這些變化的線性
關係保留下來。而圖四則將本模組(PCA+NFL)的方法與其它相關的人臉辨識方法作比較，此
一比較是在每一類別的 170 張影像中取不同張數作為訓練樣本，而其它影像作為測試樣本的
比較結果，可以發現在本計畫中所提出的人臉辨識模組表現較其它方法在辨識率上有較優異
的表現。 
表一是模組二所提出的最近特徵空間轉換法與其它著名人臉辨識演算法以 CMU 資料庫
進行人臉辨識率的比較，從表一可以發現，我們所提出的演算法在各種演算法中具有最高的
人臉辨識正確率，由此可知，本計畫所提出的特徵空間轉換法的確可以降低姿勢、光線與表
情變化所帶來的影響並提高人臉辨識率。 
 
 
 
 8
(a) (b) 
(c) (d) 
圖四：NFLE 與其它演算法人臉辨識比較 
 
表一：最近特徵空間轉換法人臉辨識率比較(CMU資料庫)(百分比) 
Method 6 Trains 9 Trains 12 Trains 15 Trains  
PCA+LPPFace 67.72 (56) 77.28 (52) 85.95 (61) 91.61 (66) 
PCA+OLPPFace 73.55 (64) 76.15 (66) 84.87 (59) 90.77 (70) 
PCA+ONPDA 63.71 (70) 71.90 (70) 77.81 (70) 88.28 (67) 
PCA+MFA 64.12 (70) 73.94 (70) 81.65 (70) 88.32 (70) 
PCA+NFL 
Embedding 2F  
77.48 (66) 82.58 (62) 91.15 (70) 95.14 (70) 
 
 10
 
表二: 本計畫所提出三階段人臉辨識於不同特徵空間轉換法中比較(CMU資料庫)(百分比) 
Method 6 Trains 9 Trains 12 Trains 15 Trains  
Single LPP-based classifier 67.72 (56) 77.28 (52) 85.95 (61) 91.61 (66) 
Single OLPP-based classifier 73.55 (64) 76.15 (66) 84.87 (59) 90.77 (70) 
Single ONPDA-based classifier 63.71 (70) 71.90 (70) 77.81 (70) 88.28 (67) 
Single MFA-based classifier 64.12 (70) 73.94 (70) 81.65 (70) 88.32 (70) 
Single NFL-based classifier 77.48 (66) 82.58 (62) 91.15 (70) 95.14 (70) 
Multiple NFL-based classifier 90.53(60) 93.82(50) 94.78(50) 96.53(45) 
 
 
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-2-I
M-1-I
M-1-I+G
M-2-I+G
M-1-G
M-2-G
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-2-I
M-1-I
M-1-I+G
M-2-I+G
M-1-G
M-2-G
(a) 6/164 samples (b) 9/161 samples 
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-2-I
M-1-I
M-1-I+G
M-2-I+G
M-1-G
M-2-G
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-2-I
M-1-I
M-1-I+G
M-2-I+G
M-1-G
M-2-G
(c) 12/158 samples (d) 15/155 samples 
圖五: 辨率率 versus 維度變化於不同訓練樣本數(CMU PIE database) 
 
 
 12
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-1-I
M-2-I
M-1-I+G
M-2-I+G
M-1-G
M-2-G
 
(c) 6/8 samples  
圖七: 辨率率 versus 維度變化於不同訓練樣本數(AR database) 
 
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-1-G
M-2-G
M-1-I
M-2-I
M-1-I+G
M-2-I+G
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-1-G
M-2-G
M-1-I
M-2-I
M-1-I+G
M-2-I+G
(a) 4/8 samples (b) 5/7 samples 
0.4
0.5
0.6
0.7
0.8
0.9
1
0 5 10 15 20 25 30 35 40 45 50 55 60
S-1-I
S-2-I
M-1-G
M-2-G
M-1-I
M-2-I
M-1-I+G
M-2-I+G
 
(c) 6/6 samples  
圖八: 辨率率 versus 維度變化於不同訓練樣本數(XM2VTS database) 
 
 
 14
[13] R. Lotlikar and R. Kothari, “Fractional-step dimensionality reduction,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, vol. 22, pp. 623–627, 2000. 
[14] H. Yu and J. Yang, “A direct LDA algorithm for high-dimensional data with application to 
face recognition,” Pattern Recognition, vol. 34, no. 10, pp. 2067-2070, 2001. 
[15] J. Lu, K.N. Plataniotis, and A.N. Venetsanopoulos, “Face recognition using kernel direct 
discriminant analysis algorithms,” IEEE Transactions Neural Networks, vol. 14, no. 1, pp. 
117-126, 2003. 
[16] H. Cevikalp, M. Wilkes, and A. Barkana, “Discriminative common vectors for face 
recognition,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, pp. 
4–13, 2005. 
[17] E. Kokiopoulou, and Y. Saad, “Orthogonal neighborhood preserving projections: A 
projection-based dimensionality reduction technique,” IEEE Transactions on Pattern Analysis 
and Machine Intelligence, vol. 29, no. 12, pp. 2143–2156, 2007. 
[18] X. He, S. Yan, Y. Hu, P. Niyogi, and H. J. Zhang, “Face recognition using Laplacianfaces,” 
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, pp. 328–340, 2005.  
[19] D. Cai, X. He, J. Han, and H. Zhang, “Orthogonal Laplacianfaces for face recognition,” IEEE 
Transactions on Image Processing, vol. 15, no. 11, pp. 3608-3614, 2006. 
[20] S. Yan, D. Xu, B. Zhang, H. Zhang, Q. Yang, and S. Lin, “Graph embedding and extensions: A 
general framework for dimensionality reduction,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 29, pp. 40–51, 2007. 
[21] H. Hu, “Orthogonal neighborhood preserving discriminant analysis for face recognition,” 
Pattern Recognition, vol. 41, pp. 2045–2054, 2008. 
[22] S. Z. Li, “Face recognition based on nearest linear combinations,” in Proceedings of 1998 
Computer Vision and Pattern Recognition, pp. 839-844, Jun 1998. 
[23] S. Z. Li, and J. Lu, “Face recognition using the nearest feature line method,” IEEE 
Transactions on Neural Networks, vol. 10, no. 2, pp. 439-433, 1999. 
[24] S. Z. Li, K. L. Chan, and C. L. Wang, “Performance evaluation of the nearest feature line 
method in image classification and retrieval,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 22, no. 11, pp. 1335-1339, 2000. 
[25] Z. M. Liu, and C. J. Liu, “Fusion of the complementary discrete cosine features in the YIQ 
color space for face recognition,” Computer Vision and Image Understanding, vol. 111, pp. 
249-262, 2008. 
[26] T. K. Kim, H. Kim, W. Hwang, and J. Kittler, “Independent component analysis in a local 
facial residue space for face recognition,” Pattern Recognition, vol. 37, pp. 1542 -- 1545, 2004. 
1 
 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                              日期： 100 年 10 月 26 日 
一、參加會議經過 
智慧型資訊隱藏與多媒體訊號處理研討會（ International Conference on Intelligent 
Information Hiding and Multimedia Signal Processing，簡稱 IHMSP），隨著多媒體技術進步與
智慧型層級需求遽增，此會議一直以來致力於資訊隱藏與多媒體訊號處理的技術提昇，提供
與會者交換彼此想法，傳播新的和現有技術的一個交流園地，今年舉辦第六屆能維持傳統，
吸引多篇論文投稿，多位學者參與盛會。此次參加 2010 年「第六屆國際智慧型資訊隱藏與多
媒體訊號處理研討會」，並發表論文，題目為：A Framework for Face Recognition Using Laplacian 
Eigenmaps and Nearest Feature Mixtures，為期將近八天的行程，其間行程緊湊，但獲得成果豐
碩，其行程概述如下： 
(一) 10 月 14~15 日：晚上搭乘飛機啟程，經過十多餘多於小時飛行，抵達德國法蘭克福國際
機場，隨即轉搭巴士前往會場，辦理報到手續。 
(二) 10 月 15 至 17 日：參加研討會議，發表論文：A Framework for Face Recognition Using 
Laplacian Eigenmaps and Nearest Feature Mixtures，並予與會會議學者交換心得。同時參
計畫編號 NSC 99-2221-E-239 -030 
計畫名稱 人臉辨識研究：架構、轉換與訓練樣本選擇 
出國人員
姓名 
韓欽銓 服務機構
及職稱 
國立聯合大學資訊工程學系 
教授 
會議時間 
99 年 10 月 15 日
至 
99 年 10 月 17 日 
會議地點 Darmstadt, Germany(德國) 
會議名稱 
(中文) 2010 年第六屆國際智慧型資訊隱藏與多媒體訊號處理研討會
(英文)2010 Sixth International Conference on Intelligent Information 
Hiding and Multimedia Signal Processing 
發表論文
題目 
(中文) 利用拉普拉斯 Eigenmaps 與最近特徵混合方法，做人臉辨識。
(英文) A Framework for Face Recognition Using Laplacian Eigenmaps 
and Nearest Feature Mixtures 
附件四 
3 
 
Multimedia Signal Processing 會議論文，包括此次所有發表論文內容。 
 
六、其他 
活動照片 
  
5 
 
二、與會心得 
此一研討會議包含主題甚廣，一共包括了 11 個主軸，分別為(1) Selected Areas in 
Broadband and Wireless Networks, (2) Wireless Networks, (3) Ad-Hoc, Sensor, Mesh Networks, (4) 
Ubiquitous and Pervasive Computing, (5) Multimedia and Web Applications, (6) Network Security, 
Trust and Privacy, (7) Mobile, Vehicular and Cellular Networks, (8) Distributed Algorithms and 
Systems, (9) Network Protocols, (10) Intelligent Networking and Embedded Systems, (11) Network 
Performance Analysis，本次一共投稿 181 篇論文，經過嚴格篩選，發表 53 篇高水準的論文。 
本次會議除了上述 11 個主軸發表的論文之外，大會更規劃了 10 個 workshops，這些都是
熱門的研究主題，提供對特定主題直接學習的機會。包括： 
 
1. Third International Workshop on Next Generation of Wireless and Mobile Networks 
(NGWMN-2010) 
2. Second International Workshop on Network Traffic Control, Analysis and Applications 
(NTCAA-2010) 
3. First International Workshop on Advances in Sensor Technologies, Systems and 
Applications (ASTSA-2010) 
4. First International Workshop on Intelligent Sensors and Smart Environments (ISSE-2010) 
5. First International Workshop on Methods, Analysis and Protocols for Wireless 
Communication (MAPWC-2010) 
6. First International Workshop on Diagnosis of Complex Systems (DCS-2010) 
7. First International Workshop on Cloud, Wireless and e-Commerce Security 
(CWECS-2010) 
8. First International Workshop on Symbiotic Computing and Multiagent Systems 
(SCMAS-2010) 
9. First International Workshop on Robot Interaction, Control, Communication and 
Cooperation (RI3C-2010) 
10. First International Workshop on Wireless Sensor Networks, Wireless Multimedia Sensor 
Networks &RFID (WSNR-2010) 
三、考察參觀活動(無是項活動者略) 
無參觀考察活動 
四、建議 
無 
五、攜回資料名稱及內容 
Proceeding of 2010 International Conference on Broadband, Wireless Computing, Communication 
and Applications 會議論文，包括此次所有發表論文內容。 
approach was first proposed by Li and Lu [11] and it was 
performed in the classification phase. In their approaches, an 
infinite number of pseudo prototypes for each class are 
generated by linear interpolation to reduce the PIE impacts. 
Basically, four steps are performed in the eigenspace-
based pattern classification: (1) Pre-feature transformation, 
(2) scatter computation, (3) criterion optimization, and (4) 
matching rule. In this study, we focus on the second part: the 
computation of the within-class and between-class scatters. 
Simple gray values were used for features in the first part. 
The Fisher criterion is maximized and the NN matching rule 
is applied. The better representation of scatter, the better 
performance is achieved. The feature vectors with more 
discriminative powers are selected to form those two scatters. 
The rest of this paper is organized as follows: The scatter 
computation in eigenspace-based approaches is reviewed in 
section II. In section III, we proposed an NFM embedding 
approach in the discriminant analysis for face recognition. 
The experiments were conducted to show the effectiveness 
of the proposed method in section IV. Four benchmark 
datasets of face images were tested for performance 
evaluation. Furthermore, comparisons with several state-of-
the-art eigenspace-based methods are also done. Finally, 
conclusions and future works are given. 
II. SCATTER COMPUTATION OF NEAREST FEATURE 
POINTS(NFP) 
In this section, we would like to review the 
representation of intraclass and interclass scatters. Basically, 
they are classified into three categories: (1) the global mean-
based scatters, (2) the local mean-based scatters, and (3) the 
pairwise point-based scatters. The first two kinds of scatters 
generate the pseudo means to represent the sample 
distribution. The third one is to construct the relationship 
among samples for preserving the local topology.  
Consider N  d-dimensional samples Nxxx  ..., , , 21  which 
constitute cN  classes. Let 
i
jx  denote a sample in space 
dR  
representing the thj  sample in the thi  class of size iN . The 
total sample mean of a population m  and the sample mean 
of the thi  class im  are calculated from the training set. The 
within-class scatter wS and the between-class scatter bS  are 
both calculated from the training samples. A criterion, e.g. 
Fisher criterion: ( ))()(trmax 1 wSwwSw bTwT − , is optimized 
for finding the linear projection matrix w , and a new sample 
in low-dimensional space can be obtained by the linear 
projection xwy T= . The computation of various scatters is 
briefly described in the followings. 
A. The global mean-based scatters GwS  and 
G
bS  
This global mean-based scatter is a conventional 
representation in LDA. The within-class and between-class 
scatters are respectively formulized as follows: 
∑ ∑
= ∈
−−= c
i
i
j
N
i C
Tii
j
ii
j
G
w
1
))((
x
mxmxS , and  (1)
( )( )TiN
i
iG
b
c
S mmmm −−= ∑
=1
. (2)
The Fisher criterion is maximized such that the best 
discriminant vectors w  can be derived. The discriminant 
vectors are formed by the eigenvectors of BW SS
1−  associated 
with the largest eigenvalues in maximizing the criterion. 
Another variant of the between-class scatter is formulated as 
the pairwise differences between the class means.  
( )( )TjiN
i
ji
N
ij
G
b
c c
S mmmm −−= ∑ ∑−
= +=
1
1 1
. (3)
B. The local mean-based scatters LwS  and 
L
bS  
These scatters denote the relationship between the sample 
and the local mean of its neighbors. The neighbors of a 
specified sample are collected and summed. The distances 
between samples and the local means are minimized. The 
scatters based on the locality are defined as  
∑ ∑
= ∈
++ −−= c
i
i
j
N
i C
Ti
jK
i
j
i
jK
i
j
L
w mm
1
))())(((
11
x
xxxxS ,  (4)
∑ ∑
= ∉
−− −−= c
ik
N
i C
Ti
jK
i
j
i
jK
i
j
L
b mm
1
))())(((
22
x
xxxxS . (5)
In which, symbols )(
1
x+Km  and )(2 x
−
Km  represents the 
means of the 1K  nearest neighbors of a specified point x  
with the same class and the 2K  nearest neighbors belonging 
to different classes. From another viewpoint, the local mean 
summed by the neighbors denotes the reconstruction of a 
sample in the popular LLE [12] approach. That is the 
reconstructed error between point y  and its neighboring 
points is minimized as shown below. 
∑ ∑−=
i j
j
T
jii
T
2
,min xwMxwε . (6)
C. The pairwise point-based scatter PwS  and 
P
bS  
The pairwise point-based scatter is computed in LPP 
approach [3]. Basically, the minimization of a function 
∑ ≠ −ji jijTiT ,2)(min Sxwxw  ensures that two ‘close’ 
samples ix  and jx  in high dimensional space are still 
‘close’ in low-dimensional space after transformation. The 
within-class and between-class scatters among points are 
defined as follows. 
( )( )∑ ∑∑
= ∈=
−−= i
i
i
k
c N
j Cx
w
ji
Ti
k
i
j
i
k
i
j
N
i
P
w
1
,
1
SxxxxS , and (7)
( )( )∑ ∑∑
= ∉=
−−= i
i
l
k
c N
j C
b
ji
Tl
k
i
j
l
k
i
j
N
i
P
b
1
,
1 x
SxxxxS . (8)
Only the relationships between points are considered in 
the minimization. The weight values are intuitively assigned 
as one (i.e., two points are connected) or by considering it as 
a Gaussian distance function, e.g., )/exp(
2
tji xx −− . They 
V. CONCLUSIONS 
In this study, the NFP and NFL distance measurement 
has been embedded into the discriminant analysis. The 
scatters of points to NFPs and NFLs have been represented 
in a form of Laplacian matrix for local structure preservation. 
Though the representation is the same with those of LLE and 
LPP, the weight setting of scatters using NFM embedding is 
more systematically than the others. The found transform 
matrix provides more discriminating power. From the 
experimental results, not only the structure locality has been 
preserved, but also the class separability has been achieved. 
In the future, the variation using kernel functions will be 
addressed for the nonlinear manifold learning. More 
discriminating vectors will be found and analyzed to obtain 
the effective results. 
ACKNOWLEDGMENT 
The work was supported by National Science Council of 
Taiwan under grant no. NSC 96-2221-E-239 -024 -MY2. 
REFERENCES 
[1] M. Turk and A.P. Pentland, “Face recognition using eigenfaces,” 
IEEE Conf. Computer Vision and Pattern Recognition, 1991. 
[2] P.N. Belhumeur, J.P. Hespanha, and D.J. Kriegman, “Eigenfaces vs. 
Fisherfaces: Recognition using class specific linear projection,” IEEE 
Transactions on Pattern Analysis and Machine Intelligence, vol. 19, 
no. 7, pp. 711-720, July 1997. 
[3] X. He, S. Yan, Y. Ho, P. Niyogi and H. J. Zhang, “ Face recognition 
using Laplacianfaces,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 27, no. 3, pp. 328-340, 2005. 
[4] M. Loog, R. P. W. Duin, and R. Haeb-Umbach, “Multiclass linear 
dimension reduction by weighted pairwise Fisher criteria,” IEEE 
Transactions on Pattern Analysis and Machine Intelligence, vol. 23, 
no. 7, pp. 762-766, 2001. 
[5] Z. Li, D. Lin, and X. Tang, “Nonparametric discriminant analysis for 
face recognition,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 31, no. 4, pp. 755- 761, 2009. 
[6] S. Yan, D. Xu, B. Zhang, H. J. Zhang, Q. Yang, and S. Lin, “Graph 
embedding and extensions: General framework for dimensionality 
reduction,” IEEE Transactions on Pattern Analysis and Machine 
Intelligence, vol. 29, no. 1, pp. 40-51, 2007. 
[7] F. Wang, X. Wang, D. Zhang, C. Zhang, and T. Li, “MarginFace: A 
novel face recognition method by average neighborhood margin 
maximization, Pattern Recognition, vol. 42, pp. 2863-2875, 2009. 
[8] J, H. Na, M. S. Park, and J. Y. Choi, “Linear boundary discriminant 
analysis,” Pattern Recognition, vol. 43, no. 3, pp. 929-936, 2010. 
[9] D. Cai, X. He, J. Han, and H. Zhang, “Orthogonal Laplacianfaces for 
face recognition,” IEEE Transactions on Image Processing, vol. 15, 
no. 11, pp. 3608-3614, 2006. 
[10] H. F. Hu, “Orthogonal neighborhood preserving discriminant analysis 
for face recognition,” Pattern Recognition, vol. 41, pp. 2045-2054, 
2008. 
[11] S. Z. Li, K. L. Chan, and C. L. Wang, “Performance evaluation of the 
nearest feature line method in image classification and retrieval,” 
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 
22, no. 11, pp. 1335-1339, 2000. 
[12] S. T. Roweis and L. K. Saul, “Nonlinear dimensionality reduction by 
locally linear embedding,” Science, vol. 290, no. 22, pp. 2323- 2326, 
Dec. 2000. Dec. 2000. 
 
  
(a) ORL (b) Yale 
  
(c) CMU (d) IIS 
Figure 1.  Recognition rates versus dimensionality reduction with various face image databases. 
 
Using the transmitted key, a transposition square, a 
matching table, and a host mask are generated at the 
receiver by an open algorithm. The secure data could 
be sufficiently disarranged to increase the safety. The 
error hamming distances between the host image and 
the stego image are near to 50%. That is the same with 
the guessing approach. This paper is organized as 
follows. The transposition based on magic squares is 
introduced in Section 2. The encryption and decryption 
processes are presented in Section 3. Some 
experimental results were conducted to show the 
performance of the proposed scheme in Section 4. 
Finally, some conclusions are given in Section 5. 
 
)( nmG
XOR 
operation )7(H
)( nmHM
Transposition via         
)( ppTM
pfl ,,
Mapping table 
Generation)( nmMT
Transposition
Plain texts(t)
)(tDM
SD
Substitution
fll MMM ,...,, 1
Fig. 1: The data hiding scheme. 
2. TRANSPOSITION AND SUBSTITUTION 
Transposition and substitution operations play the 
key roles in the proposed hiding scheme.  In order to 
obtain a stego image, a host gray image G is chosen, 
and the LSBs of image G are changed to hide the 
secure data. In this study, the transposition is performed 
by using the sequential magic squares. The main goal 
of transposition is to sufficiently disarrange the secure 
data. Next, the substitution operation is executed by 
matching the plain data with the constructed mapping 
table. 
2.1 Generation of Host Mask (HM) 
Consider a gray scale image G of size nm  and a 
7-bit key H, a binary host mask HM is generated by the 
XOR operation for increasing the security. The first 
seven MSBs of each pixel in image G are operated with 
key H to generate a 7-bit image G’ by using operation 
XOR  . The XOR operation is again operated on the 
pair-wise bits of each pixel in image G’.  The binary 
host mask HM of size nm  is obtained as follows: 
iii yxyx HGG'  ),(),( ;
 ),(),( yxyx iG'HM  , 
7,...,2,1,1,1  imynx . 
(1)
Since the transposition operation is based on magic 
squares, the binary HM is extended to a size of 2kp , in 
which k is the smallest integer that mnkp 2 . 
2.2 Transposition via Magic Squares 
The transposition operation in hiding process is to 
rearrange the ordering of hidden data. A popular 
approach is to randomize the data and send the 
mapping to the receiver. In this section, the ordering of 
TM  is exchanged by the sequential magic squares. 
Suppose plain texts are exchanged by a square TM of 
size pp  at the sender. The maximal and minimal 
sizes of magic squares are l  and f , respectively. 
Two values, lK  and fK , of length 20 bits are sent 
to the receiver by the RSA method. The transposition 
square TM  is first initialized as a magic square of 
size pp . The contents in TM  are iteratively 
rearranged by a sequential index squares 
fll MMM ,...,, 1  of sizes ffllll  ),...,1()1(, . 
Here, they are all magic squares and value p is not less 
than the maximal size of index squares, i.e., lp  . Let 
us consider one transposition pass as shown in Fig. 2. 
An input square P of size pp  is reordered to 
generate a new square Q by an index square jM  of 
size jj , and pj  . Square P is first partitioned 
into  22 / jp  groups in a column major ordering, and 
each group is represented as a column vector iV  of 
size 2j ,  22 /,...,2,1 jpi  . The values in the 
rearranged vector iRV  are generated from vector iV  
as defined below: 
    222 ,...,2,1,/,...,2,1),()( jkjpikk iji  VMRV  
(2)
These RVs are then catenated to generate the new 
square Q  in a column major ordering. Thus, square 
TM is obtained by repeating the transposition process 
via squares fll MMM ,...,, 1 . A square TM of size 7x7 
reordered by three index squares ,, 45 MM  and 3M  
is given in Fig. 3. 
P …
… Q
partition catenationtransposition
jj 
pp pp
Vs
1 2 3 … 1 2 3 …
RVs
 22 / jp 22 / jp
jM
Fig. 2: The transposition process via magic square Mj 
Step 3: Repeat the matching process until pair i  
matches with the code )(IMT  at index 
I  in table MT. 
Step 3.1: If pair i  is not matched with the 
code )(IMT , set the flag for code )(IMT . 
Step 3.2: Set )mod()1( 2kpII  . The 
matching process is continued in a ring 
sequence. 
Step 4: Count the number of the set flags 0n . Output a 
binary vector   of 0n  zeros and a one.  
Step 5: Encode vector   to generate a two-bit vector 
is  using a mapping: 1 to 00, 01 to 01, 001 to 10, 
and 0001 to 11. 
Step 6: Set is SDSD , and )( mod)1( 2kpII  . 
Step 7: Repeat Steps 2 to 6 until all i  were matched 
and encoded. 
Algorithm: The decoding and extraction algorithm 
Input: A binary secure data stream SD, and the 
mapping table MT. 
Output: The secure data mask DM 
Step 1: Initialize DM , a pointer I  starting at 
index 0, and stream SD is separated into several 
parts pair by pair ,..., 21 ss ..  
Step 2: Decode the two bits is  to generate a binary 
vector   using a mapping: 00 to 1, 01 to 01, 
10 to 001, and 11 to 0001. 
Step 3: Count the number of zeros 0n  for vector  . 
Reset four flags for binary codes 00, 01, 10, and 
11.  
Step 4: Repeat the setting process until 0n  flags are 
set. 
Step 4.1: Set flag )(IMT , and count the 
number of flags.  
Step 4.2: Set )( mod)1( 2kpII  . 
Step 5: Output code )(Ii MT , set i DMDM , 
and set )( mod)1( 2kpII  . 
Step 6: Repeat Steps 2 to 5 until all is  are decoded. 
 
Fig. 5: The transposition operation of DM by using 
square TM. 
 
3.3 An Illustrated Example 
An example is given to illustrate the encryption and 
decryption processes. A binary stream DM=110110101 
1001100 is separated into eight pairs of two-bit codes. 
The first two-bit 11 is first matched with code 01 
starting from index 0 in table MT. Find the smallest 
index whose code matches with bits 11. Output the 
matched result 1 when bits 11 are matched. Otherwise, 
output 0. If the un-matched code   in table MT had 
been searched, this index was skipped. Since indices 1, 
2, and 5 possess the first three un-matched codes for 
bits 11, output three 0s. The other outputs at indices 3, 
4, and 6 are skipped. Bits 11 are matched at index 7, 
and output a result 1. A binary stream 0001 is thus 
outputted. Next, the two-bit 01 is continually matched 
with the codes starting from index 8. They are 
sequentially matched with the codes in table MT, and 
the indices are retrieved. The secure data are generated 
as 0001(7)01(9)1(10)001(16)001(20)01(22)001(25)01 
(27). The indices in the parentheses denote the smallest 
matched indices. Four possible outputs 1, 01, 001, and 
0001 represent that the input two bits exactly matched 
with the codes in MT at the first, second, third, and 
fourth matching. In order to increase the transmission 
capacity, four possible outputs 1, 01, 001, and 0001 are 
encoded as 00, 01, 10, and 11, respectively. These 
secure data are thereafter encoded as 11011010110011 
and embedded into the LSBs of host images to generate 
the stego images. Next, the secure data will be 
decrypted at the receiver.  
4. EXPERIMENTAL RESULTS 
In this section, several experimental results were 
conducted to show the effectiveness of the proposed 
scheme. In addition, the performance of safety is 
discussed. The quality of stego image is evaluated by 
the PSNR (peak signal to noise ratio) measure as 
follows: 
)db(255log10
2
10 MSE
PSNR   (4)
Here,      my nx yxyxmn GGMSE 1 1 2' ,,1 , values m  
and n  represent the size of the host image G or the 
setgo image G’. A gray host image of size 22 by 39 and 
a binary plain image of size 78 by 11 are given as 
shown in Fig. 6(a) and (b), respectively. Suppose three 
parameters, H, 28lK , and 27fK  are manually 
assigned at the sender. A transposition square is 
initialized as a magic square of size 22 30p . The 
transposition square TM  is next generated whose 
values are exchanged by using magic matrices 28M  
  
(a) A host gray image. 
 
(b) A binary plain image. 
 
(c) The mask DM for parameters Kl=28 and Kf=27. 
(d) The embedded data SD for Fig. (c). 
 
(e) The mask DM for parameters Kl=31 and Kf=30. 
 
(f) The embedded data SD for Fig. (e). 
 
(g) The stego image for 
Fig. (c). 
(h) The stego image for 
Fig. (e). 
Fig. 6: A hiding example using two parameter sets. 
 
Table 1: Several possible parameter sets and their 
extracted results. and 2. 
(a) Parameter set Kl= 28 and Kf= 27. 
Kl Kf H The extracted results 
28 27 Y  
28 26 N  
29 27 N 
28 27 N 
(b) Parameter set Kl= 31 and Kf= 30. 
Kl Kf H The extracted results 
31 30 Y 
31 27 N 
33 30 N  
31 30 N 
 
 
1 Host images Hidden images SD 
1
   
2
 
Fig. 7: Two testing examples for error hamming 
distance evaluation. 
 
Example 1 Example 2 
Kl Kf 
Error 
HD(%) Kl Kf 
Error 
HD(%)
25 15 50.30 79 79 50.28
30 15 50.32 83 79 49.77
35 15 49.90 95 79 49.72
40 15 49.09 96 79 50.38
45 15 50.35 99 79 49.49
50 15 49.79 105 79 50.49
55 15 51.53 113 79 50.35
60 15 50.35 118 79 49.62
65 15 49.54 119 79 51.02
70 15 0 120 79 0 
70 6 49.17 120 19 49.38
70 7 49.25 120 29 49.11
70 8 49.00 120 39 49.95
70 9 49.59 120 49 50.32
70 10 50.44 120 59 49.41
70 11 50.69 120 69 50.18
70 12 49.37 120 80 50.71
70 13 50.55 120 83 49.22
70 14 47.79 120 91 49.79
 
ISSE-2010 notification for paper 19 
國立聯合大學資
訊中心郵件服務 
郵件
韓欽銓 <cchan@gm.nuu.edu.tw> 
ISSE-2010 <isse2010@easychair.org> 2010年6月23日上午10:30
收件者: Chin-Chuan Han <cchan@nuu.edu.tw> 
Dear Prof. Chin-Chuan Han 
 
We are pleased to inform you that your paper: 
An Information Hiding Scheme Using Magic Squares 
has been accepted for presentation at ISSE-2010. 
 
We would like to kindly remind you the following important issues: 
 
. Please follow EXACTLY the online Submission Guidelines 
(http://isse2010.yuntech.edu.tw/), provided by the Conference Publishing Services of the 
IEEE Computer Society and us, in the preparation of your camera-ready copies. Please 
upload your camera-ready copies via the online submission system 
(http://www.easychair.org/conferences/?conf=isse2010) by July 23, 2010. In the 
submission system, you can use the item [Submit a new version] to upload your 
camera-ready copies. 
 
. As a prerequisite of having your papers included in the proceedings, conference 
registration is due by July 30, 2010. 
 
 
Congratulations on this fine achievement! We are looking forward to seeing you in 
Fukuoka in November 2010. 
 
 
Sincerely, 
Chien-Cheng Lee, PC chair 
ISSE-2010 
 
 
Page 1 of 1國立聯合大學資訊中心郵件服務 郵件 - ISSE-2010 notification for pa...
2010/10/25https://mail.google.com/a/gm.nuu.edu.tw/?ui=2&ik=e3848e66e1&view...
99 年度專題研究計畫研究成果彙整表 
計畫主持人：韓欽銓 計畫編號：99-2221-E-239-030- 
計畫名稱：人臉辨識研究：架構、轉換與訓練樣本選擇 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
