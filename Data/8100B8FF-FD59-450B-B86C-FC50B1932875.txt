meaning and part-of-speeches of compounds by means of 
semantic composition rules. Although some morpheme 
types and composition rules are ambiguous, we have to 
provide reasons and constraint-based resolution 
methods for resolving ambiguities. The major research 
topics include: 
1. Study morpho-syntactic behavior of Chinese 
morphemes. 
2. Derive morphological rules for Chinese compounds. 
3. Represent about 4,000 senses of affixes of Chinese 
compounds in E-HowNet expressions. 
4. Study semantic relations between prefix and suffix 
of compounds and develop identification algorithm. 
5. Design ambiguity resolution methods for ambiguous 
morphemes. 
 
英文關鍵詞： Chinese compounds, unknown word identification, 
lexical knowledge representation, semantic 
composition, semantic role labeling 
 
compounds by representing about 4,000 
E-HowNet senses of morphemes 
(characters) in our affix database and to 
predict meaning and part-of-speeches of 
compounds by means of semantic 
composition rules. Although some 
morpheme types and composition rules are 
ambiguous, we have to provide reasons and 
constraint-based resolution methods for 
resolving ambiguities. The major research 
topics include: 
1. Study morpho-syntactic behavior of 
Chinese morphemes. 
2. Derive morphological rules for Chinese 
compounds. 
3. Represent about 4,000 senses of affixes 
of Chinese compounds in E-HowNet 
expressions. 
4. Study semantic relations between prefix 
and suffix of compounds and develop 
identification algorithm. 
5. Design ambiguity resolution methods 
for ambiguous morphemes. 
Keywords: Chinese compounds, unknown 
word identification, lexical knowledge 
representation, semantic composition, 
semantic role labeling 
2. 計畫緣由與目的  
自然語言處理中重要的步驟是中文斷
詞及剖析，在斷詞的過程中會遇到的一個
問題為未知詞的存在。現行的斷詞標記系
統以辭典為基礎輔以構詞的規則訊息進行
斷詞標記，但因為語言的特性之一『無窮
盡的創造力』，無法窮舉出所有的詞彙，而
一本好的辭典也不應該無止盡的擴大所收
錄的詞彙，因此如何辨識處理不存在辭典
中的詞彙就成了一個重要的課題。根據中
研院平衡語料庫的統計，語料中約有 3.5%
的詞不存在辭典中。中研院平衡語料庫第
三版五百萬詞內，未知詞經由人工標記為
動詞者有 9170個，佔 18.2%，名詞類有
40455個，佔 80.3%，非謂形容詞有 761個，
佔 1.5%。前人對於未知詞的探討重點集中
在名稱名詞細目(Named entity recognition)
的辨認上，如組織名、人名、地名辨識等，
而中文未知詞中最難處理的一類是複合詞
(Compounds)，由於複合詞是由字所組成，
單字詞義較不易掌握且多義，組合後的複
合詞詞義及詞類不容易判斷。我們將研究
分析複合詞構詞規律，過去僅有 Chen、Bai
與 Chen[6, 7]利用詞頭、詞尾的訊息處理全
部的未知詞，判斷未知詞詞類正確率
(Accuracy)約為 76%，而白、陳與陳[7]使用
Chen與 Chen [6]所提出的方法，再利用前
後文的訊息來補強 Chen與 Chen [6]方法不
足之處，將正確率提高至 83.83%。在動詞
辨識方面Tseng[28]利用相似動詞比較方法，
尋找相似結構的已知動詞以作為未知動詞
語義語法判別的依據。過去的這些方法多
偏重在統計式的訓練需要大量已標記結構
及語義的語料，但資料欠缺，正確結果不
高的情況下，本計畫將處理重心放在未知
詞的內部結構分析及其語義合成關係的研
究上，並且希望從根本著手將複合詞詞構
視為語義合成的現象，以這種方法整體性
的處理未知複合動詞名詞與形容詞並同時
推斷其語法特性及語義。 
未知詞從電腦處理語言的角度來看,必須
由構詞律產生(或辨識),不同形式的未知
詞經仔細分析可以分成兩種不同的類型。
第一種是封閉型,這類型的未知詞雖然數
量上可能有無窮多個,但是可以用規則語
法(regular expression)形式的構詞律產生,
例如和數字有關的複合詞,不管是自然數,
 一般研究對於中文詞素的構詞行為多
以詞類為分析依據，我們試著從語義的角
度來分析詞構，並以已知詞的構詞語義分
析推論至未知詞的語義自動合成。以下就
通用構詞規律與幾種特殊詞組語義規則加
以說明。 
 
3.1 通用語義構詞規律 
針對不同類別詞素組合，我們找出常
用的構詞規律共二十二條，期能自動合成
開放性複合詞正確的語意及詞類。 
 
構詞規律共包括以下成分： 
 適用限制 
 衍生性 
 複合詞的詞性 
 複合詞的語意 
 
這二十二條常用構詞規律如下；讀法是{x:
條件1:條件2:條件3}+{y:條件1:條件2} 
{E-HowNet定義式}; /* where (適用限制
或定義方式的補充)： 
 
例如，下面是第一條規則，產生的複合詞
為中心語在詞尾的偏正結構： 
 
1) {x:value}+{y:object}  {y: 
attribute={x}}; /* where  
attribute∈attr_of(x)  
Productivity: high 
Resulting POS: noun 
Examples: 紅花, 新衣, 快鍋 
 
意思是，當屬於 value的義元 x加上 
屬於 object的義元 y，形成的複合詞用
E-HowNet的方式定義會是{y: 
attribute={x}}。這個定義的意思是，複合
詞的中心語是 y，而 y的某個 attribute的
value是 x。 
 
冒號後的適用條件不一定是 object, event, 
attribute, value等 type，也有可能是廣義知
網知識本體上的義元、特定詞性、甚至是
特定單詞。 
 
而以上這條 rule的適用限制是，這裡的
attribute必須是 x這個 value所歸屬的
attribute，而 value歸屬哪個 attribute可由
廣義知網知識本體看出。例如，根據「廣
義知網知識本體」上的訊息，{beautiful|
美}這個 value不歸屬於「大小」這個
attribute，而歸屬{BeautyValue|美醜值}這
個 attribute，由此可自動得到合成後的複
合詞的 E-HowNet定義。 
 
這條構詞律的衍生性高，形成的複合詞的
詞性是名詞，適用這條規則的詞包括紅花、
新衣、快鍋等。 
 
其他二十一條規則如下： 
 
I. Modifier-head construction (head-final) 
2) {x:DegreeValue|程度值}+{y:value}→
{y:degree={x}} 
Productivity: high 
 Resulting POS: adjective 
Examples: 大好, 深紅, 艷麗 
 
3) {x:value}+{y:act}→{y:attribute={x}};  
/* where attribute∈attr_of(x) 
   Productivity: low 
   Resulting POS: the POS of Act1 
Examples: 靜思, 快煮 
 
4) {x:value}+{y:or({跑}, {舞}, {交}, 
{存}, {考}, {行}, {吻}, {改}, {防})}
→{fact|事
情:CoEvent={y},qualification={x}}; /* 
Resulting POS: noun 
Examples: 肉丸, 鐵環 
 
III. Verb-argument construction 
12) {x:act} +{y:object:not({food|食品})} 
 {x: Arg1={y}}, /*where Arg1 
denotes the second (object) argument 
role of x. 
Productivity: high 
Resulting POS: verb or nominalized 
verb 
Examples: 買書, 跳舞 
 
13) {x:act} +{y:food|食物} or({x: 
patient={y}},{y: agentive={x}})  
Productivity: medium 
Resulting POS: noun or verb 
Examples: 炒蛋, 煎魚 
 
14) {x:or(升 , 降 , 整 , 調 , 加 , 減 )} + 
{y:attribute}  {x: patient={y}};  
/*where 升={rise|上升}; 降
={MakeLower|降低}; 調={adjust|調
整}; 加={add|增加}; 減={subtract|削
減} 
Productivity: low 
Resulting POS: verb 
Examples: 升溫, 減重 
 
15) {x:animate|生物}+{y:act|行動}→
{y:agent={x}}; /*where x is the agent 
of y. 
Productivity: low 
Resulting POS: verb 
Examples: 鳥叫, 蟲鳴 
 
16) {x:object}+{y:act|行動}→
{y:instrument={x}}; /*where x is the 
instrument of y.  
Productivity: low 
Resulting POS: verb 
Examples: 槍殺, 火烤 
 
IV. Verb-complement construction 
17) {x:act:not({or({VH},{VA})})}+{y: 
value}→{x:goal={z},result={y: 
Arg0={z}}}; /*where Arg0 denotes the 
first argument role of the event y  
Productivity: high 
Resulting POS: verb 
Examples: 攪勻, 打破, 塗黑 
 
18) {x:act:or({VA},{VH})}+{y:value}→
{x:agent={z}, result={y: Arg0={z}}}; 
/*where Arg0 denotes the first 
argument role of the event y 
Productivity: high 
Resulting POS: verb 
Examples: 跑累, 醉倒, 哭瞎 
 
V. Coordinate construction 
19) {x:Object} + {y:Object} {or(x,y)};  
/*where Semantic-type (x) = 
Semantic-type (y) 
Productivity: medium 
Resulting POS: noun 
Examples: 手腳, 櫥櫃 
 
20) {x:Act} + {y:Act} {or(x,y)}; /*where 
Semantic-type (x) = Semantic-type(y) 
Productivity: medium 
Resulting POS: verb 
Examples: 笑鬧, 跑跳 
 
21) {x:Value} + {y:Value} {or(x,y)}; 
/*where Semantic-type (x) = 
Semantic-type (y) 
型時只須知道V1和V2本身是否是及物動
詞以及V1和V2和主語及賓語搭配的可能
性，因此也較其他須先辨識V2是修飾有生
命還是無生命物體、V1和V2的域外和域內
論元 (external and internal argument) 為
何的分析方法更符合自動處理的需要。 
遇到動補結構的詞彙時，我們往往會
想知道它是否及物，以及其結果補語的修
飾影響對象到底是主語還是賓語。而又以
利於自動分析的前提下，我們藉由動補兩
個動詞，也就是V1和V2各別的及物性與可
能的修飾對象，分析出幾種預測規則和類
型。 
3.2.1 動補結構的及物性 
動詞的及物性分為及物和不及物，以下
就動補兩個動詞的及物性來討論： 
1) V1為及物動詞 
a. 大部分VR為及物，包含VtVt的，如「打
勝」、「揉碎」；或是VtVi，如「教懂」、
「磨破」、「逛累」。 
b. 但若subject(V2)，也就是V2的主語，只
能是subject(V1)，則VR不及物，如「吃
飽」、「吃窮」。 
2) V1為不及物動詞 
a. 若組合為ViVt，VR及物，如「跑贏」、
「跳輸」。 
b. 若組合為ViVi，subject(V1) ≠subject(V2)，
則VR及物。如「哭濕」、「跪破」。 
c. 若組合為ViVi，subject(V1)=subject(V2)，
則VR不及物，如「走偏」、「飛累」。 
由上面所描述的內容，我們得到有1)a, 2)a, 
2)b三種動補結構為及物的可能情況，其他
情況為不及物。當然，如果VR為不及物，
則僅會修飾主語，VR為及物動詞才有修飾
主語或賓語的問題。 
3.2.2 動補結構的影響方向 
VR為及物動詞時，修飾的對象是依據
結合後的「影響方向」(affecting direction)
來決定，若影響方向指向賓語，則會修飾
賓語；若影響方向指向主語，則是修飾主
語。其控制表現分析如下： 
影響方向指向賓語--OC (object control)， 
要同時符合 
OC(1)：object(V1)可以是subject(V2)；以及 
OC(2)：subject(V1)不為subject(V2)。 
如在1)a的情況中有「打破」、「吃光」、
「讀破」，至於2)a和2)b情況皆為OC。 
或符合 
OC(3)：V1跟V2組合後的影響方向是指向賓
語。 
例如「餵飽」、「打死」、「教會」。 
影響方向指向主語-- SC (subject control)， 
要同時符合 
SC(1)：V2為狀態及物動詞；與 
SC(2)：subject(V1)能為subject(V2) 
因此在1)a的情況中有「搶贏」、「打輸」、
「讀懂」。 
影響方向可指向主語或賓語—兼類， 
這種類型較為少數，限制也比較嚴格，包
含subject(V1)能為subject(V2)，object(V1)
能為subject(V2)，object(VR)能為object(V1)，
以及V2表達生理或心理狀態。例如，張三
騎累了馬、張三唸煩了李四。 
3.2.3 語料分析測試 
主體連起來，而須要透過二次「形狀」這
個屬性，才能連結。其所要表達的是「船
的形狀，像龍的形狀一樣」，以廣義知網
的方式定義如下： 
def:{ship|船:shape({船})={shape({龍})}} 
又如「蜂蜜」一詞，N1和N2的關係為製成
的主事者，兩者須要透過「製造」這一個
事件來連結，訂義式為： 
蜂蜜 def:{蜜:agentive={produce|製
造:agent={蜂},PatientProduct={~}}} 
而「帽架」兩個詞素的關係，則須透過「放
置」這一事件， 
帽架def:{架子:telic={put|放置:patient={帽
子},location={~}}} 
我們參考Levi (1978) 的分類方式，將複雜
關係的NN複合詞以九種類型的事件來分
類，包含，CAUSE (如「瘧蚊」)、HAVE (如
「圖畫書」)、MAKE(如「蜂蜜」)、USE (如
「瘧蚊」)、BE (如「天價」)、IN (如「田
鼠」)、FOR(如「鼻腔噴霧器」)、FROM(如
「橄欖油」)、ABOUT(如「刑事政策」)。 
3.3.3 事件關係連結到框架網 
我們將這些簡單和複雜的兩種關係對
到框架網 (FrameNet) 細微的事件框架中，
並與框架成分(frame elements)連結，以便
能夠深入討論N1和N2的細微關係。  
例如在「家長費」一詞，「費用」對
應的是FrameNet的「MONEY」這一個框
架，其中「家長」和「費」兩個N1-N2對
到Buyer-Money這兩個框架成分；而「書
款」一詞的框架成分則是Goods-Money的對
應。另列舉其他例子如下， 
BUILDING (屋、房、室) 
N1-N2=Material-Building ex.玻璃屋、磚房 
N1-N2=Resident-Building ex.民房、狗屋 
ROADWAY (道、路) 
N1-N2=Material-Roadway ex.鐵道、柏油路 
N1-N2=Path-Roadway ex.海路、林道 
N1-N2=Use-Roadway ex.聲道、尿路、獸徑 
PEOPLE (友、人、工、手、師) 
N1-N2=Origin-Person ex.台灣人、港人 
N1-N2=Ethnicity-Person ex.苗人、華人 
N1-N2=Material-Person ex.泥人、雪人 
N1-N2=Affiliation-Person ex.慈濟人 
N1-N2=Vocation-Person ex.電影人、科技人 
N1-N2=Hobby-Person ex.球友、山友 
N1-N2= Place_of_Employment-Person ex.
廚工、碼頭工 
N1-N2=Type-Person ex. 弓箭手、營養師 
 
這些關係都能透過在FrameNet上的連結而
得到與細緻框架成分對應的關係。 
 
本計畫論文成果：  
Chung, You-shan, and Keh-Jiann Chen. 
2010. Analysis of Chinese Morphemes and 
Its Application to Sense and Part-Of-Speech 
Prediction for Chinese Compounds. 
ICCPOL 2010. California, USA. 
鍾友珊、陳克健。2011。動補結構的及物
性及修飾對象。ROCLING 2011，台灣台
北。 
Chung, You-shan and Keh-Jiann Chen. 2013. 
A Semantic-Based Approach to Noun-Noun 
Compound Interpretation. ROCLING 2013, 
Kaoshiung, Taiwan. 
Huang, Shu-Ling, Yu-Ming Hsieh1, Su-Chu 
Lin, Keh-Jiann Chen. 2013. Lexical 
15. Hsieh, Yu-Ming, Duen-Chi Yang, 
Keh-Jiann Chen. Improve Parsing 
Performance by Self-Learning, 
IJCLCLP 2007. 
16. Huang, Shu-Ling, Keh-Jiann Chen, 
2009, Knowledge Representation for 
Time Intervals in E-HowNet, CLSW 
2009,  July 27-31, Yantai, China. 
17. Huang, Shu-Ling, You-Shan Chung, 
Yueh-Yin Shih, Keh-Jiann Chen, 2007, 
Knowledge Representation for 
Interrogatives in E-HowNet, Rocling 
2007, Taipei, Taiwan. 
18. Huang, Shu-Ling, You-Shan Chung, 
Keh-Jiann Chen. , 2008, E-HowNet: the 
Expansion of HowNet, The First 
National HowNet Workshop, Beijing, 
China. 
19. Huang, Shu-Ling, Shih Yueh-Yin, 
Keh-Jiann Chen, 2006, The Knowledge 
Representation for Comparison Words 
in Extended-HowNet, CLSW7, NCTU, 
Taiwan  
20. Ide, Nancy & Jean Veronis, 1998, 
“ Special Issue on Word Sense 
Disambiguation”, Computational 
Linguistics, Vol. 24, # 1. 
21. Korn´el Mark´o, Stefan Schulz and 
Udo Hahn, 2005, “Unsupervised 
Multilingual Word Sense 
Disambiguation via an Interlingua”, 
20th National Conference on Artificial 
Intelligence, pp. 1075-1080. 
22. Keh-Jiann Chen, Yu-Ming Hsieh, 2004, 
Chinese Treebanks and Grammar 
Extraction, IJCNLP-2004. 
23. Li, C. 2007. Mandarin Resultative Verb 
Compounds: Where Syntax, Semantics, 
and Pragmatics Meet. Ph. D 
[Dissertation]. Yale University, New 
Haven, USA. [Online]: Available: 
ProQuest 
24. Levi, J. N. The Syntax and Semantics of 
Complex Nominals. New York: 
Academic Press, 1978. 
25. Levin, Beth. 1993. English Verb 
Classes and Alternations: A 
Preliminary Investigation. Chicago: 
University of Chicago Press. 
26.  Liu, C. H. Xiandai Hanyu Shuxing 
Fanchou Yianjiu (現代漢語屬性範疇研究) 
(Bashu Books, Chengdu, 2008).  
27. Shih Yueh-Yin, Shu-Ling Huang, 
Yi-Jun Chen , Keh-Jiann Chen, 2005, 
Semantic representation and 
composition for spatial concepts in 
extended-HowNet, IEEE International 
Conference on Natural Language 
Processing and Knowledge 
Engineering, Wuhan, China 
28. Shih, Yueh-Yin, Shu-Ling Huang, and 
Keh-Jiann Chen, 2006, Semantic 
Representation and Composition for 
Unknown Compounds in E-HowNet, 
Paclic 20, Wuhan China. 
29. Tai, Chia-Hung, Shu-Ling, Huang and 
Keh-Jiann Chen, 2009, A semantic 
composition method for 
Determinative-Measure Compounds in 
E-HowNet, International Journal of 
Computational Linguistics & Chinese 
Language Processing. 
30.  Tseng, H. , C. L. Liu, Z. M. Gao, A hybrid 
approach for automatic classification of 
Chinese unknown verbs (以構詞律與相似
法為本的中文動詞自動分類研究), in 
Computational Linguistics and Chinese 
Language Processing (2002) 1-28. 
31. Tseng, H., “Semantic classification of 
Chinese unknown words”, Proc. of the 41st 
參與第二屆 CIPS-SIGHAN中文處理國際會議 (CLP-2012)會後報告 
 
謝佑明 
 
  本屆中文處理國際會議（CLP-2012）由中國中文資訊學會（CIPS）和國際計
算語言學協會中文處理專業興趣組（SIGHAN）聯合組辦，會議目的在為中文處
理領域中全球的研究人員提供一個展示研究成果、交流學術思想、探索研究新方
向、推動研究發展的平臺。SIGHAN從 2003年日本札幌開始舉辦一系列的中文競
賽，包含了中文斷詞、詞類標記、中文命名實體識別、詞彙語意識別、中文句法
分析。本次國際評測競賽，包括四項評測任務：微博文本的漢語詞語切分、中文
人名識別與解歧、簡體中文句法分析、繁體中文句法分析。在繁體組的中文剖析
競賽中，由於我們的評測成績最佳，於是大會邀請我們發表論文。 
 
  大會邀請朱小燕老師與周國楝老師做專題演講，朱老師的演講主題在討論 
“資訊等不等於知識”，以及 “知識要如何累積” 等問題。這幾年來朱老師實驗室
大量的從各種來源獲取一些資訊，嘗試與研究如何將這些資訊轉換成有用的資訊
（知識），也試著將這些知識應用在解決 NLP的問題上，並建制有用的系統，如
QA系統。進一步的，朱老師提到這些知識應該要能持續的累積，甚至可以自我
累積或學習。這樣的想法與我目前的研究相近，大量資料的取得不難，但它存在
的很多有用無用的資訊，如何從中過濾出對自己有用的資訊，進一步轉換成有用
的資訊或知識，確實需要一個有用的方法來處理它。周國棟老師的演講在詳述自
然語言處理的語言學基礎，如形式語言學、功能語言學、結構主義語言學、歷史
語言學、認知語言學等。並說明 Chomsky 文法表達系統，瞭解它的轉換生成語
法與說明 “語言” 、 “言語” 的意義。另外，周老師提到 DP依存語法無法真實
反應事實，沒有成份關係，所有的關係要從語法功能來看（即句法結構），CFG
即已經隱含 DP在裡面了。因此，在中文句的分析上，要用依存分析(Dependency 
Parser)還是句法分析(Syntactic Parser)，端看應用再自行選擇。不過，我認為要瞭
解句子的深層意思，或許就是要從完整的句法分析來做比較適合。 
 
  本屆的競賽報告方面，在中文句法分析分為二組：簡體中文(Bakeoff3)與繁
體中文(Bakeoff4)。我們是參加 Bakeoff4(繁體中文句法分析)的評測，我們提出的
方式是改良 PCFG剖析的結構機率評估模式，將原本的句法規則機率與透過機率
學習估算出來的機率加以整合，以估算出更為精確的結構機率，找到更好的剖析
結構樹。從實驗的結果來看，我們的結果在 Bakeoff4中是有最佳的成績，也比
Berkeley Parser來的好。 
 
  在這二組的會議報告中，我發現大家都有一個所謂的 baseline system，也就
是都是採用 Berkeley’s Parser作為指標對象。因此，本次會議看到了各研究者提
參與亞洲語言處理國際國會(IALP-2013)會後報告 
 
謝佑明 
 
  本屆亞洲語言處理國際會議(International Conference on Asian Language 
Processing (IALP)) 是一個專注於亞洲語言處理的系列會議，會議旨在促進世界各
地亞洲語言處理各個面向的科學與技術研究人員之間的交流，倡導各語言資源建
設及資訊處理的一致標準、平台、資源共享的機制，以提高語言文字資訊處理水
準。會議論文集與往來一樣會提交 IEEE Xplore 由 INSPEC、EI、ISTP 檢索。多年來，
IALP 已經發展成為亞洲自然語言處理領域重要的年度活動之一，IALP 2008 年在
泰國清邁舉行、IALP 2009 年在新加坡舉行、IALP 2010 年在哈爾濱舉行、IALP 2011
年在馬來西亞檳城舉行、IALP 2012 年在越南河內舉行，本屆在新疆烏魯木齊舉
行。 
 
  本次大會邀請學界的 Chengging Zong 宗成慶教授與 Wushouer Silamu 教授及
業界代表 Shuanhu Bai 白栓虎教授進行專題演講。宗老師的題目是 Machine 
Translation Based on Discourse Analysis，主要探討言談分析句子的翻譯問題。言談
語料通常是２個短語以上的組合而成為完整語意的句子。短語間彼此是有關係的，
用的詞彙也會有所關連，在翻譯時如果知道關係，用的詞彙就會比較精準。這讓
我瞭解到要深層理解一個中文句子，短語之間的關係還是要去處理，我或許可以
再進一步從目前的研究（中文短語的句法分析）再擴展到言談句子的句法分析。
另一位 Wushouer 老師，則是全方面的討論多語言處理的新方向與機會，未來的
機會在大數據庫、雲計算、移動計算、多語言處理等方面，以新疆地區為例，將
會有中國最重要的運算基地－天山運算基地，在處理數量龐大的數據。在新疆，
漢人是少數，約 5%的人口，其它的 95%是回族、維吾爾族、哈薩克族…等等，
不同族群中都有自己不同的語言，其語料資源的建置與語言統一的平台，在新疆
是很重要的一件事。最後業界代表新浪的白栓虎老師，他帶領４個人的團隊來參
加本次會議，與大會研究人員進行了深入的討論，他的演講題目是 Text Mining in 
Weibo。他們從微博大量的語料中，運用 NLP 技術進行了各種可能的文字分析，
盡可能的找到有意思的資料，研究主題包含關鍵詞抽取、NER 識別、情緒分析、
中文斷詞、淺層的句法分析等。以上三位主講人的精闢演說，不管是從業界還是
學界，都是收益良多。NLP 技術的日漸成熟、網路更普及與快速、硬體設備更快
更精更大，不管是學界或業界，紛紛大量的採用與投入這個領域相關技術的研究，
NLP 的未來指日可待。 
 
  除了主題報告外，大會還分了８個 session 進行各別口頭報告，包含
Computational Linguistics, Linguistics & Language Study, Sentiment Analysis, 
Machine Translation, Spoken Language Processing, Language Information Processing
無研發成果推廣資料 
Analysis and 
Contextual Harmony 
of Durations, 
Journal of Chinese 
Linguistics Vol.41, 
No.1, pp. 118-144.
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 1) Yu-Ming Hsieh, 
Ming-Hong Bai, Jason 
S. Chang and 
Keh-Jiann Chen, 
2012, ＇＇Improving 
PCFG Chinese Parsing 
with 
Context-Dependent 
Probability 
Re-estimation, 
Proceedings of the 
Second CIPS-SIGHAN 
Joint Conference on 
Chinese Language 
Processing, pages 
216-221. 2012. 
2) Yu-Ming Hsieh, 
Ming-Hong Bai, and 
Keh-Jiann Chen. 
2013. Introduction 
to CKIP Chinese 
Spelling Check 
System for SIGHAN 
Bakeoff 2013 
E l ti I
