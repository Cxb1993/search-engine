己的身份，所以每個人身上的都要攜帶各種不同場合的證件，以表示一個人的身
份。然而這個卻造成兩個問題：便利性與偽造。太多的證件會造成攜帶的不方便，
如果忘了攜帶證件就會造成相當大的困擾。現今各種證件竊取及偽造事件相當頻
繁，證件的安全性及可靠性也就愈來愈受到質疑。所以如果採用人臉辨識的方
法，利用每個人身上容易取得的生物特徵，讓我們能輕易的辨識出身份，不僅方
便取得、也不容易被複製或仿冒。 
在這幾年來隨著科技日新月異的發展，人臉辨識的已逐漸變成生物認證中
的熱門課題，在門禁系統上更是有相當大的需求。概觀目前的人臉辨識研究，都
是以整張人臉影像進行辨識，但是卻容易受到光線或是外在環境的影響而改變辨
識結果。為了解決這個問題，所以我們提出一個想法是說因為臉上膚色區域佔整
張人臉的比例是還滿高的，而這些膚色區域卻對表示人的特徵上沒有很大的幫
助，所以為了想減少這些膚色的區域，在辨識時就不以整張人臉當輸入影像而將
人臉上重要的特徵畫分數個區域出來當做輸入影像去做辨識，再將數個辨識的結
果做一個結合，進而找出最後的辨識結果。而如何自動切割並偵測這數個重要特
徵的區域，和在最後如何結合數個辨識結果也就是本報告要探討和解決的問題。 
以下為本論文架構。第二節將探討既有之人臉辨識方法，並提出本報告之
系統架構。第三節將說明偵測人臉特徵區域的方法。人臉辨識演算法將在第四節
來說明。第 5 節將進行實驗分析，最後在第 6 節結論。 
 
2. 人臉辨識方法文獻探討 
 近年來有相當多的人臉辨識研究和方法被不斷的提出。而在技術不斷的突破
和經驗的累積下，在人臉辨識方面的相關研究也漸漸成熟。人臉辨識的演算法有
相當多，像是不含類別資訊的 Principal Component Analysis(PCA)[1]或是
Improved Principal Component Analysis(IPCA)[2]。PCA 是將所有的資料合在
一起，沒有加入不同類別所屬資訊，將所有的資料一起算共變異矩陣也就是
Covariance matrix: ∑
∈
−−=Σ
Xx
T xxxx
N
)()(1 然 後 去 求 此 共 變 異 矩 陣 的
Eigenvalue 和所對應的 Eigenvector，然後取這些 Eigenvalue 中最大 K 個
Eigenvalue 所對應的 Eigenvector，當作投影的空間；再將資料點投影到此空間
上，當作此資料的特徵向量，將此特徵向量來進行辨識比對。 
       IPCA 將 PCA 改良，它跟 PCA 的流程幾乎都一樣，不一樣的地方是在計算
共變異矩陣的部分。原本的 Covariance matrix 是 ∑
∈
−−=Σ
Xx
T xxxx
N
)()(1 ，
是拿資料向量去減去資料向量的平均值，但 IPCA 的 Covariance matrix 是 
∑ −−=Σ )()(1 μμμμ TN  = x
x
x
x
x
x
N Xx
T =⇒−−=Σ ∑
∈
μ)1()1(1  ，即將資料除以
練與辨識的流程圖如圖 1與圖 2。 
 
Input 
Image
Find Face Select Recognition Areas 
Normalization 
Wavelet Transform 
Projection Projection 
 
圖 1 訓練的架
 
 
圖 2 辨識的架構 
構 
Input Find Face 
Select Recognition 
Area 
Normalization
Wavelet Transform 
Projection 
on LDA Projection on PCA
Obtain Feature 
Use Voting and Compare Weight Output 
Compare Feature in 
Database
Obtain Feature 
Use K-means to get 
Feature Weight
Save into 
Database 
轉灰階 侵蝕 膨脹 原圖 
 
圖 4 偵測眼睛每一步驟之示意圖 
 
找到眼睛的位置 眼睛的位 之間的距離 了嘴巴
以外的其他四個區域，如下圖所示: 
 
後，再根據 置和兩眼 去預測除
 
圖 5 特徵區域偵測結果的示意圖 
 
侵蝕 膨脹 影像相減 結果 
微分量，找出灰階值投影後變化的情形，再根據這些位置去找出物件的中心。首
先先介紹 IPF 和 VPF 的定義如下 
 
                     (  
(5) 
 
再來將
(8) 
 
(9) 
再將 GPF 做微分，即得到中心點，如圖 7所示。 
 
 
                                4)∑=
=)(
y
Ix −
2
1
),(1
12
y
y
i
i
yx
yy
IPF
   
 
∑ ),(
1
i yxIx =−
= 2
1
1)(
2
x
xx i
x
yIPF
∑ −= 2 2)](),([1)( y i xIPFyxIxVPF  
              
=− 112 yy iyy (6) 
(7) 
 
∑
=
−−=
2
1
2
12
)](),([1)(
x
x
i
i
yIPFyxI
xx
yVPF
x
IPF 和 VPF 合併得到 GP 函數 F 
 
)()() xVPFx)1(( IPFxGPF ⋅−= α + α ⋅
)()()1()( yVPFyIPFyGPF ⋅−= α + α ⋅
 
最後
      
圖 7 偵測嘴巴中心點橫軸之結果 
 
接下來找嘴巴縱軸中心線有兩個方法。第一個方法是利用兩個眼睛的中心位置當
做中心線，其缺點是若嘴巴有歪斜時中心線會偏掉；第二個方法是找兩個嘴角位
置，然後以嘴角中心位置當做中心線，其缺點是當嘴角有一邊找不到或是有雜訊
而影響找到的位置，都會使中心線的位置有所誤差。因此本報告中將結合兩個方
法，當所找到中心線的位置偏離太多時， 。嘴角
2.16>黃色範圍所示，從此範圍中再利用 IPF 和 VPF 的合併去
偵測嘴巴橫軸的中心線。嘴巴的兩個嘴角和其中心線偵測結果如圖 8。找到兩條
便採用兩眼所找到的中心線位置
位置之偵測利用剛剛所找到的嘴巴縱橫軸的中心線，然後以這條線為基礎各往上
往下一部分如<圖
4. 人臉辨識演算法 
A)，Linear discriminant analysis(LDA)等。 
分類方法是用鑑別共同向量法
(Discr
4.1 共同向量(Common Vector) 
在特徵擷取上可以劃分為包含類別資訊和不包含類別資訊兩大類。包含類
別資訊代表我們已經知道資料分別歸於哪一類，而不包含類別資訊代表我們不知
道資料分別該歸於哪一類，而且我們連類別數也不知道。通常我們在處理不包含
類別資
我們
必須知
在做人臉辨識時特徵的擷取是很重要的 ，如何去在高維的資料群中做分
類並擷取特徵是一個重要的課題，在此方面有很多方法像:主成分分析(Pricipal 
component analysis, PC
LDA 和 PCA 都是要去將一群高維的資料找到一個主軸，將這群高維資料
project on 這個主軸能將此群資料分類開來，另外這個這個主軸會是這群高維
資料空間的 subspace 也就是說當這群高維資料 project on this subspace 時
所得到的 vector 維度會減少，會達到降維的目的，而這些 vector 就是 feature 
vector 也就是我們要的特徵向量。本報告的
iminant Common Vector)來擷取特徵向量。該方法分為兩個步驟：共同向量
(Common Vector)與主成分分析(PCA)等兩個步驟來完成。 
 
訊的資料時，我們會使用 Principal Component Analysis 也就是 PCA 來
找出投影主軸，並擷取出特徵向量，至於在處理包含類別資訊的資料，我們通常
使用 Linear Discriminant Analysis 也就是 LDA，也因為如此要使用 LDA
道資料的類別資訊，而要使用 PCA 則並不一定要去了解，這是 LDA 和 PCA
的不同之處。 
假設我們現在知道類別數為 C ，每個類別有 N 個訓練樣本， imX 代表
第 i類 第 m個樣本(每個資料是 d維之行向量)。我們分別定義 WS ， BS ， TS   3
個參數如下 
WS  : within-class scatter matrix 也就是類別內散佈矩陣，代表類別內資料
之間的散佈情形，而此矩陣的計算方法是: 
     ( )( )C
i
N
m
i
i
mi
i
mW XX∑∑
= =
−−=
1 1
μμ    i
T
S μ :第 i 類的 mean            (10) 
BS  : between-class scatter matrix 也就是類別間散佈矩陣，代表類別和類
別之間的散佈情形，而此矩陣的計算方法是: 
( )( )TiC
i
iB NS μμμμ −−=∑
=1
 iμ :第 i 類的 mean，μ :總 mean     (11) 
TS  : Total scatter matrix 也是全部資料的散佈矩陣，代表全部資料的散佈情
形，而全部資料的散佈情形是『類別內資料的散佈情形』和『類別間的散
就是 common vectors)能把它們分開。所以在做 PCA 時是把共同向量當作輸入去
計算共變矩陣。然後對此共變矩陣計算 Eigenvalue 和 Eigenvector，只不過是
取那些不為 0的 Eigenvalue 的 Eigenvector。 
假設資料類別為 C， 矩陣等於 0的 Eigenvalue 有 k 個: WS
)(
)(
22
2
2
1
11
2
1
)( 21
C
k
CC fff ""
#
#
1
  (12) 
 
計算共變矩陣 Eigenvalue 時，至多只有 C-1 個不為 0的 Eigenvalue[17] ，
原因有 2：第 1點原因以數學的觀點來看一筆資料是 k維，我當做一個方程式有
k 個變數而現在有 C 筆資料，也就是有 C 個方程式，然後 C < k ，k 個變數 C
個方程式，只能解出 C個變數出來。第 2點 C-假設空間中有 n 個點 ，這 n 個點
的向量排成列向量所形成的矩陣 rank 是 n，也就是說這 n 個點是互相獨立的。
所以在同時減去 mean 後，會有一個性值就是獨立個數就會少 1 個，變成 n-1 個
1 個來表
。再根據第 1點原本 C筆資料有 C個方程式，可是其中有一個方程式可以用其
而一筆資料 k維，那
麼 k 個變數 C-1 個方程式就只能解出 C-1 個變數出來。所以這也就是為什麼有
C-1 個 Eigenvalue 不為 0的原因。 
     了解原因後，我們要的是那些 Eigenvalue 不為 0的 Eigenvector 當作 PCA
的主軸，再拿之前 LDA 所算出來的特徵去投影在此主軸上，再得到一組特徵，這
k
k
fff
fff
""
""
MatrixianceCo var aaa
aaa
⎟⎟⎜⎜ ""
""
⎯⎯⎯⎯⎯⎯⎯ →⎯
⎜⎜
⎜
⎝
⎛
KxKkkkk
k
k
aaa ⎟
⎟
⎟
⎠
⎞
""
#%##
#%##
21
22221
11211
⎟⎜
獨立。  
所以從上面的兩點去看 PCA 的部分，根據第 2 點在算共變矩陣，原本有 C
筆資料這 C筆資料是互相獨立，再減去平均向量後就就變成是 C-1 個獨立，也就
是說其中有一筆資料為其它 C-1 筆資料的線性組合，也就可以用這 C-
示
它 C-1 個來表示，也就是說真正有意義只剩下 C-1 個函數，
組特徵就是最後我們所要的。原本 LDA 所算出的特徵它的維度是 k維，而再一次
PCA 後所得到的特徵它的維度便變成了 C-1 維。計算過程如下： 
 ⋅)( 321 dXXXX ""
⎟⎟
⎟⎟
⎟⎟
⎞
⎜⎜
⎜⎜
⎜
⎛
⎥⎥
⎥⎥
⎥⎥
⎤
⎢⎢
⎢⎢
⎢⎢
⎡
⎥⎥
⎥⎥
⎥⎥
⎤
⎢⎢
⎢⎢
⎢⎢
⎡
⎥⎥
⎥⎥
⎥⎥
⎤
⎢⎢
⎢⎢
⎢⎢
⎡
k21
)( 321 kffff ""
⎟⎟⎠⎜
⎜ ⎥⎢⎢⎣⎥
⎥
⎦⎢
⎢
⎣
⎟⎟⎥⎥
⎦
⎢⎥
⎢⎢
⎢
⎣⎥
⎥⎥
⎦
⎢
VVV ,,, ………
⎜⎜
⎜
⎝
=        (13) 
資料點到到此基準點的距離，然後每個資料點根據到此基準點的距離來給權重。 
K-means 分群時有一點要注意，就是初始點的設定，因為初始點的設定會
影響到分群後的結果，所以在找初始點時本報告是找互相相距最遠的資料點，例
如假設現在要分 3群，所以初始點便找資料點中 3個是互相距最遠的資料點，找
的方式是第 1個點先任選其中一個點，然後第 2個點找距離第 1個點最遠的那一
個資料點，而第 3個點是先算每一個點距離前面兩個點的距離，這兩個距離取較
小的那
，方法是每一個點的權重
一個，再拿每一個點的較小那一個距離去取最大的那一個，第 3個點就是
那一個資料點。 
分群後便開始計算距離給權重(分數)
= ∑ 離每一個點到基準點的距
和投票法要合在一起，要如何將這兩個結果合在一起呢？一開始先得到 5個特徵
區塊的辨識結果，在將這 5個辨識結果先用投票法去決定是最後結果，如果再分
不出來的時候此時便比
× 每一個點到基準點的距100 離 。算完權重(分數)後，接下來便是要將權重
較權重，詳細如下面的例子: 
 
假設現在有 5個人做 Training: 1 號、2號、3號、4號、5號 
第一個區塊的辨識結果: 1 號 
第二個區塊的辨識結果: 5 號 
第三個區塊的辨識結果: 4 號 
第四個區塊的辨識結果: 4 號 
第五個區塊的辨識結果: 1 號 
結果用投票法 1號和 4號各兩票無法決定最後是誰，此時便要用權重 
 
 
區塊一 1 號 6 0 0 0 0 
區塊二 5 號 0 0 0 0 7 
區塊三 4 號 0 0 0 7 0 
區塊四 4 號 0 0 0 6 0 
區塊五 1 號 9 0 0 0 0 
總和 15 0 0 13 7 
辨識結果 1~5 號所得的分數 
1 號    2 號    3 號    4 號    5 號 
15 分大於 13
分所以最後辨
識的結果是 1
號 
上的變化，只是環境比訓練的環境更加明亮，另一個場景是跟訓練一樣有 5盞燈
但是這 5 盞燈上沒有貼上一張紙，所以燈光會變的比訓練更亮，所
以打在臉上的變化也更加劇烈。如圖 11 所示: 
光做變化，
 
   
(a) (b) 
圖 11 辨識的場景 
 
5 種方法去做人臉辨識: 
(1)輸入影像:整張人臉 
(2)輸入影像: 5 個人臉特徵區塊 
(3)輸入影像: 5 個人臉特徵區塊 
(4)輸
   辨識
第二種方法測試的辨識率: 93% 
第三種方法測試的辨識率: 92% 
第四種方法測試的辨識率: 94% 
第五種方法測試的辨識率: 94% 
 
在測試場景二，用 278 張影像做測試，正確率如下： 
第一種方法測試的辨識率: 40% 
第二種方法測試的辨識率: 83% 
測試的方法有
   辨識方法: PCA + LDA + 小波轉換 
   辨識方法: PCA + LDA + 投票法 + 權重(分數) 
   辨識方法: PCA + LDA + 小波轉換 + 投票法 
入影像: 5 個人臉特徵區塊 
   辨識方法: PCA + LDA + 小波轉換+ 權重(分數) 
(5)輸入影像: 5 個人臉特徵區塊 
方法: PCA + LDA + 小波轉換 + 投票法 + 權重(分數) 
 
在測試場景一，用 100 張影像做測試，正確率如下： 
第一種方法測試的辨識率: 78% 
不加前處理之辨識時間(278 張)： 
 輸入影像 : 5 個人臉特徵區塊+小波   時    間 : 24 秒 
 輸入影像 : 5 個人臉特徵區塊        時    間 : 66 秒 
 輸入影像 : 整張人臉                時   間  : 21 秒 
 
包含前處理之辨識時間(278 張)： 
 整張人臉 :     0.5 秒 
 框取 5個區域 : 0.6 秒 
 
5.2 實驗結果討論 
由實驗結果顯示，本報告所提出的將整張人臉分割成不同的特徵區塊之方
法，的確能比用整張人臉之方法，在辨識率上要來的好，因為它能降低燈光或環
境對人臉辨識所造成的影響。在辨識時間上因為加入了 PCA 所以辨識的速度變的
跟訓練的人數有關，不在跟影像的大小有關係，這樣辨識時間會比沒加入 PCA
要快上許多，然後在加入 的辨識率會比沒加小波
轉換來的高一些，而且小波轉換也會使影像縮小成原來 1/4，這樣也會使速度再
更快一些。另外本報告中也提出了利用投票加上比較權重(分數)的方法來代替之
前只用投票法的方式，去結合這 5 結果在實驗結果中可以發現，本
報告所提出的方法在辨識率比只用投票法或是只用比較權重(分數)要來的高，這
是因為只用投票法會有無法解決的時候，只用權重(分數)的話會容易受到辨識錯
誤的影響，因為如果其中有一個區塊辨識錯誤，而且又剛好辨識錯誤的那一個權
重質很高，那麼這樣會影響到其中辨識正確的結果，也就是這幾個辨識正確的權
重質加起來還沒有錯誤的高。另外在權重質的地方不同的分群數也會影響辨識
率，從實驗結果中我們可以發現分群數在低於訓練人數的一半，辨識率會比較高。 
 
6. 結論和未來工作 
本報告用人臉分割特徵區塊的方法來作人臉辨識，其中我們將人臉重要的
特徵區域分割出來像是眼睛、眉毛、嘴巴這些區域，劃分這些區域可以減少人臉
上的膚色區域，也就減少這些膚色區域因為燈光或是環境的變化而影響辨識的結
果。在偵測嘴巴和眼睛的 和兩個 projection 
function 的方法來偵測嘴巴，此方法會正確的偵測到嘴巴位置而不受光線的影
響。在偵測眼睛方面利用了影像上的兩次膨脹、兩次侵蝕和 connected component
的方 而不受到光線的影響。在演算法的部份
利用 間不再跟
影 許多，另
小波轉換可以去掉一些雜訊，使
個辨識結果，
部份，本報告也提出了利用 SQI
法，也可以正確的偵測出眼睛的位置
LDA(common vector) + PCA 的方法，多加上 PCA 可以使辨識的時
像大小有太大的關係，而是跟人數比較有關，這會使的辨識時間快上
Reco
 - 47 , 1998. 
[10] S. D. Wei , S. H. Lai , “Robust Face Recognition under Lighting Variations” , 
Proc
, P. N. Belhumeu , S. K. Nayar , “Using eye reflections for face 
recog
生教育出版股份有限公司出版 , 普林斯頓國際有限公司發行 . 
4] H. Wang , S. Z. Li , Y. Wang , “Face recognition under varying lighting 
conditions using self quotient image” , IEEE International Conference on 
Automatic Face and Gesture Recognition, pp. 819 - 824 , 2004 . 
5] H. Wang , S. Z. Li , Y. Wang  , J. Zhang , “Self quotient image for face 
recognition” , International Conference on Image Processing, Vol 2 , pp. 1397 - 
1400 , 2004 . 
6] Z. H. Zhou , X. Geng , “Projection functions for eye detection” , Pattern 
ative common 
[18 g discriminative common 
[1 lez , Pattern Recognition Principles , Addison-Wesley 
   
gnition Letters 25 , 711 - 724 , 2004 . 
[8] Byung-Joo Oh , “Face recognition by using neural network classifiers based on 
PCA and LDA” , IEEE International Conference on Systems, Man and 
Cybernetics, Vol. 2 , pp. 1699 - 1703 , 2005.  
[9] M. Doi , K. Sato , K. Chihara , “A Robust Face Identification against Lighting 
Fluctuation for Lock ” , IEEE International Conference on  Automatic Face and 
Gesture Recognition, pp. 42
. International Conference on Pattern Recognition, Vol. 1, pp. 354 - 357 , 
2004 . 
[11] X. Xie , K. M. Lam , “An Efficient Method for Face Recognition under Varying 
Illumination” , IEEE International Symposium on Circuits and Systems, Vol. 4 , 
pp. 3841 - 3844 , 2005 . 
[12] K. Nishino 
nition under varying illumination” , IEEE International Conference on 
Computer Vision, Vol. 1 , pp. 519 - 526 , 2005 . 
[13] R. C. Gonzalez , R. E .Woods , 繆紹綱編譯 ,  “Digital Image Processing 2/e” , 
台灣培
[1
[1
[1
Recognition 37 , 1049 - 1056 , 2004.    
[17] H. Cevikalp , M. Neamtu , M. Wilkes , A. Barkana , “Discrimin
vectors for face recognition” , IEEE Transactions on Pattern Analysis and 
Machine Intelligence, Vol 27, pp. 4 - 13 , 2005 . 
] H.Cevikalp , M. Wilkes , “Face recognition by usin
vectors” , , Proc. International Conference on Pattern Recognition Vol. 1, pp. 
326 - 329 , 2004 . 
9] J. T. Tou , R. C. Gonza
Publishing Company , 1974 . 
