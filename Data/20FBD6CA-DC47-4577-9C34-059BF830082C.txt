use JSP (Java Server Page) and servlet to construct 
management interface in the smart home environment, 
but also to facilitate communication between the 
management interface and the OSGi framework, which in 
turn effectively manages the bundles in the OSGi 
framework, thus making possible the construct of a 
smart home website-controlled platform supported by 
relevant data banks. In addition, users of limited 
mobility can easily and readily access smart home 
facilities simply by gestures, not having to turn to 
a wheel chair or hand touch for help. Unlike those 
studies that focus mainly on the accuracy enhancement 
of hand gesture recognition, this study explores how 
images are processed in a complex dynamic background 
as well as how to retrieve a complete prospect for 
hand gestures and their interpretations. In the light 
of these rules and mechanisms, a rule-based context-
aware perceptive environment is constructed which 
allows the users of limited mobility to obtain 
desired services without having to resort to a 
complex set of pre-setting operations. 
英文關鍵詞： Smart home, OSGi, UPnP, Context aware, Web console, 
Servlet, JSP, dynamic service, dynamic rule. 
 
II 
 
中文摘要 
本篇論文將提出一個能夠跨平台、容易建置、且融合了類似雲端運算的概念的智慧家庭系統，讓
行動不便者能夠隨時隨地使用行動裝置去遠端操控家庭中的設備及各項服務。當設備或服務的狀態改
變時，同時將相關訊息回應到整個家庭環境中，即時地給予行動不便者回饋。另外藉由記錄行動不便
者的生活習慣，並動態產生新的服務。為了實現以上的論點，本論文建構一個基於 UPnP 及 OSGi 上的
系統，提供了可靠、具動態擴充性、且易於存取及管理的智慧家庭環境。此外藉由 OSGi framework 嵌
入進 web server 及 servlet contianer 中，讓我們不但能夠使用 JSP(Java Server Page)及 servlet 技術開發智
慧家庭管理介面，並且能夠讓管理介面能夠和 OSGi framework 做溝通，進而管理 OSGi framework 上
的 bundle，配合資料庫，建構一個能遠端管理的智慧家庭網頁控制平台。此外，為了讓行動不便者可
以簡單操控家庭中的設備，行動不便者可以不需要藉由手來推動輪椅或是觸碰任何家中的設備。一般
的手勢辨識相關文獻只探討如何提高手勢辨識的精準度，在本篇論文，將會討論如何在動態背景下去
處理我們的影像，以及在複雜的背景下擷取出完整的手勢前景。根據這些規則，我們可以打造一個以
規則為基礎的情境感知環境，讓行動不便者不用做複雜的設定，即可取得想要的服務。 
關鍵詞: 智慧家庭、OSGi、UPnP、JSP。 
 
英文摘要 
This study attempts to build an easy-to-install cross-platform smart home environment incorporating a 
concept similar to cloud computing, which allows users, especially those who are less mobile, to readily 
remote control home facilities and service modes available, using mobile devices close at hand. Whenever 
there is a change in any facility or service mode, relevant message will be reflected in the smart home 
environment, which in turn is transmitted in a real time manner to the less mobile users, thus dynamically 
providing them with appropriate up-dated services. To embody the said concept, this paper establishes a 
simulated environment based on UPnP and OSGi, thus making possible a smart home environment that is 
reliable, dynamically expandable and easy to access/retrieval, and effectively manageable. Besides, 
embedding the OSGi framework into the web server and servlet container enables us not only to use JSP (Java 
Server Page) and servlet to construct management interface in the smart home environment, but also to 
facilitate communication between the management interface and the OSGi framework, which in turn 
effectively manages the bundles in the OSGi framework, thus making possible the construct of a smart home 
website-controlled platform supported by relevant data banks. In addition, users of limited mobility can easily 
and readily access smart home facilities simply by gestures, not having to turn to a wheel chair or hand touch 
for help. Unlike those studies that focus mainly on the accuracy enhancement of hand gesture recognition, this 
study explores how images are processed in a complex dynamic background as well as how to retrieve a 
complete prospect for hand gestures and their interpretations. In the light of these rules and mechanisms, a 
rule-based context-aware perceptive environment is constructed which allows the users of limited mobility to 
obtain desired services without having to resort to a complex set of pre-setting operations. 
Keywords: Smart home, OSGi, UPnP, Context aware, Web console, Servlet, JSP, dynamic service, dynamic 
rule. 
2 
will describe the architecture and design of our smart home environment. 
 
 
Fig. 1 Structure of the hand gesture recognition system 
 
This study implements UPnP devices and control points based on the Felix UPnP project which can 
provide an implementation of the OSGi UPnP specification as described in the OSGi Service Compendium 
(Release 4), and this project is an open source project. The original working flow of the UPnP standard is 
shown as Fig. 2. An UPnP control point and UPnP devices get an IP address in the addressing step. When this 
step is finished, the UPnP control point will search requests to find interesting devices in the UPnP network. 
Similarly, the UPnP will create a message when a device is newly added to the network. These work 
processes are called the "Discovery" step. The next step is the description step. In this step, the control point 
will get description files of devices according to the IP address which is gotten in the discovery step. If the 
control point gets a description file of a device, it can control the device. The control point can send control 
message to change the device's status, and the device will reply a result to the control point. This step is called 
"Action". The control point also can subscribe a service of a device. As soon as a state variable of the service 
is changed, the device will notify the control point. This step is called "Eventing". The "Presentation" means 
the UPnP device may provide an URL for managing it on a web page interface. This step is optional. When 
the UPnP control point and UPnP devices is started, the smart home system will initialize the database and 
check whether the database is initialized successfully. We also make some changes in the discovery step and 
the new working flow is shown in Fig. 2. The discovery step works by transmitting a SSDP (Simple Service 
Discovery Protocol) packet which contains device IP, device type, device UUID, address of description file, 
etc. The system has to resolve the SSDP packet and then get the information it needs. 
When the UPnP control point and UPnP devices have been started, the smart home system will initialize 
the database and check whether the database is initialized successfully. We also make some changes in the 
discovery step and the new work flow is shown in Fig. 3. The discovery step work by transmitting a SSDP 
(Simple Service Discovery Protocol) packet which contains device IP, device type, device UUID, address of 
description file, etc. The system has to first resolve the SSDP packet and then get the information it need. 
 
4 
 
Fig. 4 Structure of web console 
 
 Bundle Management Tool: The bundle management tool is used to manage bundles in a smart home 
environment under the web console. It can make people manage the bundles in the OSGi framework more 
easily by the web console instead of by command lines. This tool shows the bundle's name, bundle's ID, 
bundle's version, bundle's status, and some buttons to control a bundle's status.  
 Device Management Tool: This tool is to provide the web console to manage UPnP devices in a smart 
home. Through the working process of the UPnP standard layer, there are already a lot of UPnP device 
information in the database. By this tool, the system can manipulate any UPnP devices anytime and 
anywhere, and by any mobile devices which can browse web pages. A device management tool shows 
device's UUID, friendly name, location, and status (online or offline). When clicking the hyperlink of 
device, there is interface for controlling this device. 
 Member Management Tool: The function of the member management tool is to monitor the member in a 
smart home environment and edit the data of a member. This function is like the member field in a website. 
 Rule Management Tool: The rule management tool provides an interface to make user can monitor or edit 
rules in a smart home environment dynamically. This tool shows rule ID, who conform this rule, when this 
rule conformed, where this rule conformed, what event occur make this rule conformed and what action 
should be done if all conditions are conformed. 
 Event Cache: The event cache records events which occur in a short time. The default time interval is set 
one day. In this interface, users can not only monitor events but also can select some events to be a new 
rule just by checking an event. 
The database is the most important part in the smart home environment because all of information of the 
smart home environment is stored here. A well-designed database structure can make the smart home work 
powerfully and efficiently. In this section, we will introduce database structure in a smart home environment. 
The ER model and structure of whole database is shown in Fig. 5. 
 Device Table: This table is used to store the UPnP devices' information which is gotten by control point 
in the smart home. 
 Service Table: A service is included by a device. The service table store services of an UPnP device 
which contain in description file. Those services include a set of actions, state variables, and arguments. 
 Action Table: The action table records the actions of an UPnP device. When people use web console to 
manage UPnP devices, the actions in this device are listed. 
 Rule Table: The rule table is used to store the dynamic rule information which contains some condition 
6 
III. Hand Gesture Recognition System 
This study proposes to use fingertips to guide the wheelchair on task. In other words, we consider how to 
extract the hand from complicated background that is the concern of this study. Fig. 6 is the flowchart of the 
whole system. The system consists of five steps. The first step is to build the background from the video 
stream and extract the foreground of a hand by background subtraction. The second is to set up a ROI whether 
the pixels of foreground reaches the threshold so that the system can start to detect. In third, in order to get the 
complete hand, the loss functions of robust learning algorithms and the concept of outlier is adopted to filter 
off the skin-color-like noises in the background. Finally, the fourth step is to segment the hand to detect the 
palm and find the fingertip to implement in our system.  
 
Fig. 6 Flowchart of whole system 
 
3.1 Detection of the Appearance of Hands 
In order to reduce the influence of the environment, the background is build before the user’s hand 
appears in front of camera view. The system takes K frames from the static gray background images without 
the appearance of a hand, and then it computes the mean of them to be the reference background. The 
formulas are described as follow. 
         
1
1( , ) ( , )
k
i
i
B x y b x y
K 
                                   (1) 
where ( , )ib x y  presents the i
th frame that is extracted from background image and ( , )B x y  presents the 
reference background.  As mentioned, background subtraction is adopted in this system to extract the 
foreground of hand. Every frame captured from the camera is transformed into gray images and then 
8 
3.2 Segmentation of Hand Regions and Robust Skin Color Detection 
The ROI area that is set in the middle of camera as shown in Fig. 8. Because from the arm to the palm 
that is long shape, we set a rectangle that range is the location of x direction from 220 to 420, the location of y 
direction is from 150 to 400. Both of the top and the bottom, presenting the red line, the two sides are 
presented the green line in this ROI area. 
 
 
Fig. 8 ROI area 
 
 As mentioned above, once the foreground of hand appears in the ROI area, it is observed to find the palm 
which will be located in the ROI. Therefore, we don’t obtain whole hand to be detecting foreground, setting a 
threshold to stop detection when the pixels of foreground achieves one-third of ROI area (total pixel is 50000), 
the red line presents that the pixel is more than 17000 in 117th frame. In addition, we adopt from loss function 
of robust learning algorithms to filter the sin-color-like noises of neighboring hand. Thus, the result will be 
more robust than simple skin detection.  
In this section, we discuss the relationship of CbC r and to compute the majority group of skin color. After 
that, we will use a approach called Robust Learning loss function to ensure our middle point is located on 
hand of skin color(majority), and then obtain the concept of outlier to discriminate the majority skin color 
from other minority skin color. 
There are some noises color is similar to the hand region, so this study adopts in the concept of outlier 
from statistics to remove noises connecting to the hand region. In statistics, the term “outlier” is used to 
represent an observation that is numerically “distant” from the rest of the data [8].  
3.3 Segmentation of Full Palm 
 In this study, we propose to guide the wheelchair to move such as go forward, stop and turn. The 
behavior is like that hand raises from the bottom to the middle of frame and waves it. Therefore, this study 
only concern about the lower half of frame. Firstly, we compute the centroid of foreground as follows. 
0
k
i
i
c
x
x
k


 , 0
k
i
i
c
y
y
k


                               (5)     
Where xi and yi are x and y coordinates of ith pixel in the hand region, and k denotes the number of pixels in 
the region. According to reference [3], we consider the boundary of frame to assist to segment the palm. In the 
algorithm, the edges of an image are separated into 4 line segments, namely a, b, c, and d as shown in Fig. 9. 
No matter what direction of rising hand when the hand appears in front of camera, it should exist on the 
edge of boundary. If hand appears from the bottom of frame, then white pixels should in the line a. If hand 
10 
  
(a) Bottom left side            (b) bottom            (c) bottom right side 
Fig. 11 Example of calculating the angle of the reaching hand 
 
       
(a)                           (b) 
Fig. 12 Example after rotating 
(a) Considering image Rotated by θ, (b) Vertical projection of (a) 
 
As mentioned above, we have succeeded to rotate hand region to the horizontal direction. In this study, 
the segmentation of palm [5] is employed again to separate the palm and the arm. First, we compute the sum 
pixels of vertical projection from left to right. Therefore, the length of hand is found from Fig. 12(b). However, 
the amount of column skin-color white pixels of arm region is sometimes more than that of the palm region, 
so if only use the middle line of hand region as wrist line, the palm part may be cut more. In approach [5] 
proposed a method to compromise, regarding the maximum sum pixels of vertical projection as the start line 
lmax, and the middle of hand region as end line lmid. According to the range, we set the wrist line which is the 
minimum sum pixels within the range as shown in Fig. 13. Therefore, after finding out the location of the 
wrist line, the length of the palm region lp is calculated. Instead of removing the area to the right of the wrist 
line, the area in the right-hand side of the wrist line plus lp/3 are removed. Fig. 13 of applying this idea is 
shown in Fig. 14. 
 
 
Fig. 13 Range of wrist line locates 
12 
where maxR presents the maximum distance and minR  presents the minimum. If the arm is included in the 
chosen gesture, the peak transformed from arm is may higher than threshold. Therefore, we set the width 
of peak to decide whether it is finger or arm. 
10 35peakW                                      (8) 
By all of above approaches, it is could completely extracted the palm and count the number of raised 
fingers. In our system, we want to use the finger to guide the wheelchair. Therefore, the fingertips of raised 
fingers used to control the wheelchair. According to above threshold approach, we can obtained easily the 
numbers of fingers. Following that, every angle corresponds different distance from the centroid of palm in 
polar image. Actually, after we obtain the contour of palm, every point location of contour is also computed at 
the same time. Therefore, we start to find every peak of finger which is between every trough in the polar 
image as shown in Fig. 16(a). 
 
      
(a)                                (b) 
Fig. 16 Finding fingertips by polar image 
 
Because user guides the direction of wheelchair by his/her fingertips, we shall choose the middle of all of 
fingers to be the reference point in this system. In addition, we connect the fingertip points to the centroid of 
palm, that is going to be the direction in our system as shown in Fig. 17. Even if the number of fingers is even, 
we can compute the median of the amount of finger such two, four fingers. The result is shown in Fig. 18. 
 
 
Fig. 17 Direction of fingertip 
 
14 
Finally, we develop the hand gesture recognition system to confirm smart home system that can complete 
the OSGi-based web console for smart home with dynamic service registration. Example 1 is tested in the 
indoor environment. The background is considered as a simple in our system except that skin-color-like box is 
in the right side of image and the light source is a little bit asymmetrical. However, the whole recognition rate 
is up to 96.55%.  
 
Example 1: 
(a) (b) 
(c) 
 
(d) 
 
V. Conclusions 
In this study, we propose a smart home environment which integrate the UPnP standard, the OSGi 
framework, web console, and the context awareness concept. We build the smart home environment by a 
simple way. The user can easily get a service from the smart home environment. Moreover, the user can ask 
the smart home system to complete the services they need. In addition, our system has the gesture recognition 
system under a complicated and dynamic environment which can achieve a robust recognition. In traditional 
approaches, in order to build the large data base, they always care about hand gesture appearing in a simple 
background. Once the background is more complicated, the recognition rate will become very bad. In contrast, 
our system does not need to build a large data base to process in a complicated environment. From our 
experiments, it is evident that our system can have a high recognition rate.  
 
 16
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■ 達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
   在此一研究中，我們開發一個能夠跨平台、容易建置、且融合類似雲端運算的概念的智慧
家庭系統，讓行動不便者能夠隨時隨地使用行動裝置去遠端操控家庭中的設備及各項服務。
另外藉由記錄行動不便者的生活習慣，並動態產生新的服務。為了實現以上的論點，本研究
建構一個基於UPnP及OSGi上的系統，提供了可靠、具動態擴充性、且易於存取及管理的智慧
家庭環境。可以讓行動不便者不用做複雜的設定，即可以與機器互動。所建構之互動智慧型
系統，可以用於未來的系統整合及功能測試，使互動智慧型系統能確實在一般環境下被使用。
 17
國科會補助專題研究計畫出席國際學術會議心得報告 
                                   日期：100 年 10 月 24 日 
一、參加會議經過 
    此次出席國際性研討會，能與來自全球各地的學者專家共同砥礪系統、人類及模控技術與其應用
領域的有關技術，研討現在及未來的技術發展趨勢，對筆者研究有直接的助益。以下簡述相關心得。
一如往昔，大會在研討會開始前10/9日安排一兩個技術研習會 (Workshops)以及7個教學研習會
(Tutorials)，提供有興趣於鑽研諸專題的學者專家相當程度入門基礎及應用背景知識。研討會在10月9
日下午6:00 有歡迎宴會。 
    研討會在10月10日上午8:00開始大會節目正式登場。2011的大會主題為Cyber-Physical Systems)，
著重於認知辨識，認知科學，腦波研究的先端技術與實際系統的結合應用。依循大會主題，本次大會
的議程共有與大會主題相關的3個Plenary Talks 以及1個Keynote Speech，1個論壇，105發表技術會議
（Technical Sessions）。10/10上午8:00開始大會演講，由Professor T. C. Henderson 主講「Innate Theories 
on Cognitive Agents: the Symmetry Engine」(認知代理人的天生理論:對稱引擎)。大會於9:00-10:00 安排
Professor Sukhan Lee 主講「Cognitive Recognition and the Home Mate Robot 」；在此演講中，Professor 
Lee 談及成功的商業機器人必須滿足VPC (Value>Price>Cost)準則，也必須具備Higher Dependability, 
Better Sociability, Greater Affordability 等三技術條件。另外，Professor Lee所發展的家庭伴侶機器人有
三大功能: Errand Service, Medical Delivery, and Video Chatting。  
    在10/11與10/12兩天，主辦單位於每天上午9:000至10:00間安排另兩個大會演講一，並每天於
10:30-12:10,13:40-15:30，16:00-18:00 等三兩時段內每時段最多有12場同時進行的小組技術會議。10/11
與10/12等兩場大會演講的題目與演講者分別是Prof. Jose Del R. Millan 主講第二場題目「Brain-Robot 
Interaction」(以腦波辨識與學習為主，進而控制輪椅與機器人)，Prof. Robert O. Ambrose主講第三場大
會題目「Humans & Humanoids」(行動雙手臂機器人與太空的應用)。並於在10/11 10:30至12:00間， 安
排由Keith Hipel, Jim Tan, Mo Jamshidi等三位SMC會士，舉辦論壇，介紹SMC方法，吸引多人參加研討。  
    除了吸引近數百人聆聽的大會演講的精彩演講外，更引人入勝的是各種研究領域的小組技術研討
會議。每一小型技術會議裡有6 篇與主題相關的論文發表，每篇論文的發表者必須在20分內結束報告
並有完成問題回答時間。如果您對某些論點特別感興趣，除了當場請教外，也可私底下互相交流溝通。
計畫編號 NSC 100－2221－E－011－050－ 
計畫名稱 在一般環境下之與機器互動智慧系統研發 
出國人員
姓名 蘇順豐  
服務機構
及職稱 國立臺灣科技大學 電機工程系 
會議時間 100 年 10 月 9 日至100 年 10 月 12 日 會議地點 美國阿拉斯加州 
會議名稱 (中文)2011 IEEE, SMC 國際研討會 
(英文)2011 IEEE International Conference on Systems, Man, and Cybernetics 
發表題目 (中文)滑動解耦控制系統的適應性傅立葉補償設計 
(英文)Adaptive Fourier Compensator Design for a Sliding Decoupling Control System 
 19
生參與研討會也相當熱烈。但國內業界參予研討會的人數不多，若能邀請對系統應用實務的業界研究
員，講述其系統實務設計實務經驗，以增加與會專家學者的另類觀點。 
三、發表論文全文或摘要 
    In the paper, an adaptive Fourier compensator is proposed to compensate the sliding decoupling control 
law for a class of uncertain coupling systems. Generally, on the hierarchical sliding mode, the sliding 
decoupling control law, which consists of an equivalent control law and a hitting control law, can be derived 
to stabilize the coupling system. When the system functions are subject to uncertainties, the control gain of the 
hitting control law can be adjusted to be a larger value to ensure the system stability. However, the control 
performance can not be guaranteed by the simple manner. So, in order to improve the control performance in 
this situation, an adaptive Fourier compensator is proposed to further compensate the sliding decoupling 
control law; the obtained control performance can be similar to that of the ideal sliding decoupling control law. 
The simulation results clearly demonstrate the effectiveness of the proposed adaptive Fourier compensator. 
四、建議 
    建議國內各個學術單位能積極爭取主辦大型國際研討會，增進與國際學者學術交流，此外政府相
關單位亦能充分支持國內的學術研究與交流機會，如此不但可以增進國際能見度，亦能給予國內學者
一個學習及討論的環境。 
五、攜回資料名稱及內容 
    參加此次研討會帶回CD-ROM Proceeding of the SMC2011 國際研討會，內容包括所有的會議論文。 
六、其他 
 
SMC 2011 大會論壇活動 
 21
 
SMC 2011 華人學者聚會 
 
SMC 2011 大會第三場專題演講: Dr. Ambrose 主講第三場題目「Humans and Humanoids」 
 
 23
授及台灣大學連豊力教授三位將會是special sessions 的session chairs。而且三位的論文也被選為
conference paper award candidate papers。因此經由他們的參與能更有機會拿下paper award。中山大學黃
國勝教授也協助蘇順豐教授評審paper award。經由五位評審的討論蔡清池教授及鍾翊方教授的論文為
入選(finalists)，而連豊力教授的論文則為大會最佳論文。蘇順豐教授為2013 ICSSE 的General co-chair. 
所以也在大會晚宴上幫ICSSE 2013的主辦者Imre Rudas校長做ICSSE 2013 的相關簡報。 
大會會場前 最佳論文之報告與提問 
最佳論文頒贈說明 
 
最佳論文finalist 頒贈 
最佳論文頒贈 ICSSE 2013 的簡報 
 
 17
國科會補助專題研究計畫出席國際學術會議心得報告 
                                   日期：100 年 10 月 24 日 
一、參加會議經過 
    此次出席國際性研討會，能與來自全球各地的學者專家共同砥礪系統、人類及模控技術與其應用
領域的有關技術，研討現在及未來的技術發展趨勢，對筆者研究有直接的助益。以下簡述相關心得。
一如往昔，大會在研討會開始前10/9日安排一兩個技術研習會 (Workshops)以及7個教學研習會
(Tutorials)，提供有興趣於鑽研諸專題的學者專家相當程度入門基礎及應用背景知識。研討會在10月9
日下午6:00 有歡迎宴會。 
    研討會在10月10日上午8:00開始大會節目正式登場。2011的大會主題為Cyber-Physical Systems)，
著重於認知辨識，認知科學，腦波研究的先端技術與實際系統的結合應用。依循大會主題，本次大會
的議程共有與大會主題相關的3個Plenary Talks 以及1個Keynote Speech，1個論壇，105發表技術會議
（Technical Sessions）。10/10上午8:00開始大會演講，由Professor T. C. Henderson 主講「Innate Theories 
on Cognitive Agents: the Symmetry Engine」(認知代理人的天生理論:對稱引擎)。大會於9:00-10:00 安排
Professor Sukhan Lee 主講「Cognitive Recognition and the Home Mate Robot 」；在此演講中，Professor 
Lee 談及成功的商業機器人必須滿足VPC (Value>Price>Cost)準則，也必須具備Higher Dependability, 
Better Sociability, Greater Affordability 等三技術條件。另外，Professor Lee所發展的家庭伴侶機器人有
三大功能: Errand Service, Medical Delivery, and Video Chatting。  
    在10/11與10/12兩天，主辦單位於每天上午9:000至10:00間安排另兩個大會演講一，並每天於
10:30-12:10,13:40-15:30，16:00-18:00 等三兩時段內每時段最多有12場同時進行的小組技術會議。10/11
與10/12等兩場大會演講的題目與演講者分別是Prof. Jose Del R. Millan 主講第二場題目「Brain-Robot 
Interaction」(以腦波辨識與學習為主，進而控制輪椅與機器人)，Prof. Robert O. Ambrose主講第三場大
會題目「Humans & Humanoids」(行動雙手臂機器人與太空的應用)。並於在10/11 10:30至12:00間， 安
排由Keith Hipel, Jim Tan, Mo Jamshidi等三位SMC會士，舉辦論壇，介紹SMC方法，吸引多人參加研討。  
    除了吸引近數百人聆聽的大會演講的精彩演講外，更引人入勝的是各種研究領域的小組技術研討
會議。每一小型技術會議裡有6 篇與主題相關的論文發表，每篇論文的發表者必須在20分內結束報告
並有完成問題回答時間。如果您對某些論點特別感興趣，除了當場請教外，也可私底下互相交流溝通。
計畫編號 NSC 100－2221－E－011－050－ 
計畫名稱 在一般環境下之與機器互動智慧系統研發 
出國人員
姓名 蘇順豐  
服務機構
及職稱 國立臺灣科技大學 電機工程系 
會議時間 100 年 10 月 9 日至100 年 10 月 12 日 會議地點 美國阿拉斯加州 
會議名稱 (中文)2011 IEEE, SMC 國際研討會 
(英文)2011 IEEE International Conference on Systems, Man, and Cybernetics 
發表題目 (中文)滑動解耦控制系統的適應性傅立葉補償設計 
(英文)Adaptive Fourier Compensator Design for a Sliding Decoupling Control System 
 19
生參與研討會也相當熱烈。但國內業界參予研討會的人數不多，若能邀請對系統應用實務的業界研究
員，講述其系統實務設計實務經驗，以增加與會專家學者的另類觀點。 
三、發表論文全文或摘要 
    In the paper, an adaptive Fourier compensator is proposed to compensate the sliding decoupling control 
law for a class of uncertain coupling systems. Generally, on the hierarchical sliding mode, the sliding 
decoupling control law, which consists of an equivalent control law and a hitting control law, can be derived 
to stabilize the coupling system. When the system functions are subject to uncertainties, the control gain of the 
hitting control law can be adjusted to be a larger value to ensure the system stability. However, the control 
performance can not be guaranteed by the simple manner. So, in order to improve the control performance in 
this situation, an adaptive Fourier compensator is proposed to further compensate the sliding decoupling 
control law; the obtained control performance can be similar to that of the ideal sliding decoupling control law. 
The simulation results clearly demonstrate the effectiveness of the proposed adaptive Fourier compensator. 
四、建議 
    建議國內各個學術單位能積極爭取主辦大型國際研討會，增進與國際學者學術交流，此外政府相
關單位亦能充分支持國內的學術研究與交流機會，如此不但可以增進國際能見度，亦能給予國內學者
一個學習及討論的環境。 
五、攜回資料名稱及內容 
    參加此次研討會帶回CD-ROM Proceeding of the SMC2011 國際研討會，內容包括所有的會議論文。 
六、其他 
 
SMC 2011 大會論壇活動 
 21
 
SMC 2011 華人學者聚會 
 
SMC 2011 大會第三場專題演講: Dr. Ambrose 主講第三場題目「Humans and Humanoids」 
 
 23
授及台灣大學連豊力教授三位將會是special sessions 的session chairs。而且三位的論文也被選為
conference paper award candidate papers。因此經由他們的參與能更有機會拿下paper award。中山大學黃
國勝教授也協助蘇順豐教授評審paper award。經由五位評審的討論蔡清池教授及鍾翊方教授的論文為
入選(finalists)，而連豊力教授的論文則為大會最佳論文。蘇順豐教授為2013 ICSSE 的General co-chair. 
所以也在大會晚宴上幫ICSSE 2013的主辦者Imre Rudas校長做ICSSE 2013 的相關簡報。 
大會會場前 最佳論文之報告與提問 
最佳論文頒贈說明 
 
最佳論文finalist 頒贈 
最佳論文頒贈 ICSSE 2013 的簡報 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/23
國科會補助計畫
計畫名稱: 在一般環境下之與機器互動智慧系統研發
計畫主持人: 蘇順豐
計畫編號: 100-2221-E-011-050- 學門領域: 智慧型機器人
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
