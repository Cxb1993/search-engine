中文摘要..........................................................................IV 
英文摘要..........................................................................IV 
研究目的...........................................................................5 
Design trends ........................................................................................................................................5 
Increasing complexity of the design.............................................................................................5 
Heterogeneous architectures ........................................................................................................5 
Deep sub-micron effects................................................................................................................5 
Decreasing time to market ............................................................................................................6 
文獻探討...........................................................................6 
The DSE problems...............................................................................................................................6 
Methods for evaluating a single design point ....................................................................................7 
Established benchmarks ...............................................................................................................7 
Simulation-based evaluation ........................................................................................................7 
System-level simulation .........................................................................................................7 
Cycle-accurate simulation .....................................................................................................8 
Combination of simulation-based and analytical methods .........................................................8 
Trace-based performance analysis ........................................................................................8 
Purely analytical approaches .......................................................................................................9 
Static profiling........................................................................................................................9 
Event stream-based analytical models ..................................................................................9 
High-level synthesis ...............................................................................................................9 
Methods for exploring the design space...........................................................................................10 
Optimization strategy ..................................................................................................................10 
Objective/ cost functions and metrics.........................................................................................10 
Primary objectives ...............................................................................................................10 
Secondary objectives ...........................................................................................................10 
Combined metrics ................................................................................................................11 
Strategies for covering the design space ....................................................................................11 
Exhaustively evaluating every possible design point...........................................................11 
Randomly sampling the design space ..................................................................................11 
Incorporating knowledge of the design space .....................................................................12 
Pruning the design space............................................................................................................12 
Hierarchical exploration .....................................................................................................12 
Subsampling of the design space .........................................................................................12 
Subdividing the design space into independent parts for optimization ...............................12 
Sensitivity analysis of design parameters ............................................................................12 
Constraining the design space.............................................................................................12 
Supporting functionality for automated DSE............................................................................13 
Hierarchical simulator integration......................................................................................13 
Automatic refinement of the task graph...............................................................................13 
Trace compression ...............................................................................................................13 
Coupling of incompatible building blocks...........................................................................13 
Operating system customization ..........................................................................................13 
User-assisted DSE ...............................................................................................................13 
Representing the design space ..........................................................................................................13 
Architecture models ....................................................................................................................13 
Instruction-accurate performance models...........................................................................14 
Task-accurate performance models .....................................................................................14 
Non-linear, accumulative service descriptions ....................................................................14 
Micro-architecture templates...............................................................................................14 
                I 
Simulation Environment ......................................................................................................35 
Results..................................................................................................................................36 
Optimization using ILP formulation..........................................................................................38 
Current Approach Comparison ...........................................................................................38 
Our Methodology.................................................................................................................39 
Mathematic Formulation .....................................................................................................39 
Optimization using Partitioning and Scheduling ......................................................................41 
Simulation/Verification .....................................................................................................................43 
The extensible and retargetable simulator tool-kits...................................................................43 
Liberty Simulation Environment ..........................................................................................43 
SimpleScalar toolset ............................................................................................................43 
ISIS toolset ...........................................................................................................................44 
Comparision ........................................................................................................................44 
Verification ..................................................................................................................................45 
Processor core software-based self-test...............................................................................45 
SoC bus interface verificatiion ............................................................................................45 
A Customized Processor Architecture at FCU................................................................................47 
Customized Function Unit Exploration.....................................................................................47 
Co-Processor Exploration ..........................................................................................................47 
Synthesizable HDL Generation [79] ..........................................................................................48 
Instruction Generator ..........................................................................................................48 
Control Unit block diagram.................................................................................................48 
Configuration Wizard GUI ..................................................................................................49 
Simulation ...................................................................................................................................49 
Target system simulation......................................................................................................49 
The Instruction Set Architecture (ISA) simulation...............................................................49 
結果與討論........................................................................50 
參考文獻..........................................................................50 
計畫成果自評......................................................................64 
                III 
研究目的 
The advent of SOC technology has resulted in a paradigm shift for the design process of embedded 
systems employing programmable processors with custom hardware. Modern system-level designs 
consist of Intellectual Property (IP) blocks such as processor cores, ranging from traditional Digital Signal 
Processors (DSPs) and superscalar Reduced Instruction Set Computer (RISC), to (Very Long Instruction 
Word) VLIW and hybrid ASIPs. Furthermore, SOC technologies permit the incorporation of novel 
on-chip memory organizations, including the on-chip DRAM, frame buffers, streaming buffers, and 
partitioned register files, allowing a wide range of memory organizations and hierarchies to be explored 
and customized for the specific embedded applications. System architects critically need tools, techniques, 
and methodologies to perform rapid architectural exploration for a given set of applications to meet the 
diverse requirements, such as better performance, low power, smaller silicon area, higher clock frequency 
etc.  
Design trends 
Having a look at today's common practice to design an integrated circuit or a whole system we 
recognize the impact of the designer's experience gained in prior design projects on the final system 
architecture. Indeed, taking the application domain of network processing as a prominent example, we see 
quite a diversity of available architectures in order to implement the same kind of application. This 
variety of designs can rather be explained by the knowledge gained in recently completed, prior designs 
in each of the design teams than by application-driven architecture decisions. That means, given a 
specification of the application and system requirements, the design team shrinks the range of feasible 
designs to a small number of possible designs by falling back on earlier, beneficial design decisions 
which might be sub-optimal for the current design problem and biased towards the designers' favored 
design style. The relative quality of the final design as a result of this ad-hoc system design approach 
compared to an optimal design will become even worse in the future due to the following trends: 
Increasing complexity of the design 
The complexity of integrated circuits continues to follow Moore's law, thus doubling every 18 months. 
This in particular motivates to reuse prior design knowledge at higher levels of abstraction in order to 
cope with the sheer size of the design. 
Heterogeneous architectures 
We see more and more heterogeneous architectures combining application-specific with general-purpose 
computing, different kinds of peripherals, and memory hierarchies. In addition, designers increasingly 
tend to use existing designs in parallel in order to fill the available area rather than to develop new and 
larger designs. Recognizing and exploiting the concurrency of applications therefore becomes a 
significant part of the design process. Besides this architectural diversity, more and more different 
technologies are being integrated onto a single chip, such as on-chip memory, analog interfaces, and 
high-frequency parts. It is therefore increasingly unlikely that a design team will be able to come up with 
an optimal solution by hand. Although a single designer could find an optimal subdesign of the overall 
system for his/her area of expertise (such as memories), naively putting optimal parts together does not 
necessarily lead to an optimal heterogeneous system. 
Deep sub-micron effects 
A couple of effects which have been neglected during the design process in the past make the design 
quality worse, such as increasing interconnect delays and decreasing signal integrity. Again, this point 
underpins the growing dependency among different aspects of the design. 
                5 
designs. These systems are heterogeneous in nature using multiple computation, communication, memory, 
and peripheral resources. 
 
Methods for evaluating a single design point 
Methods for evaluating a single design range from purely analytical methods, which can be 
processed symbolically, to cycle-accurate and RTL-level simulations which need complex executable 
models of the design under evaluation. Before a design can be evaluated, compilation and synthesis steps 
may be required, e.g. the hardware part of the design may be synthesized on an FPGA-based prototype. 
The complexity of validation phases can be reduced by correct-by-construction synthesis steps that 
guarantee correct implementations of the specification, thus avoiding validation by, for instance, 
simulation of test stimuli. In this case, the system evaluation using stimuli can focus on extracting design 
characteristics only, such as resource utilizations. 
 
Established benchmarks 
Available benchmarks can be classified according to their application domain. 
z Network processing: Related work on defining benchmarks for network processors include 
CommBench [123], NetBench [77], and activities of the Network Processor Forum (NPF, 
http://www.npforum.org). Related work on disciplined approaches for evaluating network processors 
can be found in [117, 20]. The Internet Engineering Task Force (IETF) has a work group on 
benchmarking methodologies (BMWG) of internetworking technologies. 
z General purpose computing: Benchmarks for general-purpose and scientific computing are published 
by the Standard Performance Evaluation Corp. (SPEC, http://www.spec.org). The Business 
Applications Performance Corporation (BAPCo, http://www.bapco.com) focuses on benchmarks for 
personal computers and notebooks.  Embedded systems: Benchmarks for embedded systems 
including automotive, telecommunication, consumer, and control systems can be found in MiBench 
[44] and are also defined by the Embedded Microprocessor Benchmark Consortium (EEMBC, 
http://www.eembc.org).  
z Multimedia-centric computing: Benchmarks focusing on multi-media processing can be found in 
MediaBench [67] and in the DSP-centric BDTI benchmarks from Berkeley Design Technology, Inc. 
z Database and transaction processing: Business-oriented transactional server benchmarks are defined 
by the Transaction Processing Performance Council (TPC, http://www.tpc.org). 
SPECjAppServer2002 is a client/server benchmark from SPEC for measuring the performance of 
Java enterprise application servers in end-to-end web applications. 
z Parallel Computing: Examples of benchmarks for parallel computing and multi-processing are 
PARallel Kernels and BENCHmarks (Parkbench, http://www.netlib.org/parkbench), Stanford 
Parallel Applications for Shared Memory (SPLASH2 [124]), and SPEC OMP (OpenMP Benchmark 
Suite). 
 
Simulation-based evaluation 
System-level simulation  
The Ptolemy framework [68] (http://ptolemy.eecs.berkeley.edu) can be used to model and simulate 
the interaction of concurrent system components by using different models of computation (MoC).  
Lieverse et al. [74] present an architecture exploration method based on a single MoC, namely Kahn 
process networks. The functional behavior of an application is kept separately from models describing the 
timing behavior of the architecture (e.g. CPU cores and buses).  The Artemis work described in [96, 95] 
refines the work described in [74] in order to resolve deadlocks in Kahn process networks by introducing 
the concept of virtual processors and bounded buffers. One drawback of restricting the designer to using 
Kahn process networks is the inability to model time-dependent behavior. Moreover, since all scheduling 
decisions are implicitly taken following the organization of FIFO buffers, all resources are assumed to use 
                7 
the design of on-chip communication structures.  Zivkovic et al. [128] augment traditional traces, that 
usually contain information on data transfers and task executions only, with control information in order 
to evaluate the cost of control as well. 
Analytical models with initial, calibrating simulation 
The analytical approach described by Franklin and Wolf [32] requires an initial characterization of 
benchmarks using exhaustive simulation runs for a range of cache organizations. Extracted information 
from these runs like miss rates and load and store instruction shares are fed into analytical models which 
allow reasoning about resource utilization, area requirements, and performance. The approach has been 
extended in [33] to include power requirements. 
 
Purely analytical approaches 
Analytical methods come into play if deterministic or worst-case behavior is a reasonable 
assumption for the system under evaluation. In addition, building an executable model of the system as 
well as simulations might be too costly or even impossible at the time of the evaluation. Analytical 
models thus in particular ease early design decisions by identifying corner cases of potential designs.  
Static profiling  
Well established methods for static program analysis, such as the complexity analysis of algorithms, 
the dependency analysis of a static schedule of a task or function call graph to extract worst-case behavior, 
or simply counting of operations appearing in pseudo code, can be used for performance estimations of an 
application mapped onto an architecture, as for instance performed in [40]. The reader is referred to 
standard literature in Computer Science, such as books by Knuth [58] and Sedgewick [105], to learn more 
about complexity analysis and common data structures for established sorting and searching algorithms. 
The formulation as an integer linear program often constitutes the core of the analysis as, for instance, 
described in the papers by Li et al. [71] and Theiling et al. [112]. 
Event stream-based analytical models 
For certain application domains dedicated calculi, task, and workload models exist which allow 
symbolic evaluation of a design. Richter et al. [99] (and the references therein) give an overview of 
mature analytical techniques for evaluating the task execution on shared resources for event streams.  
They extend these techniques by coupling the analytical models using event model interfaces, thus 
enabling system-level evaluations of platform-based designs. One example is the network calculus [66] 
which has been applied to network processor design [113, 115, 42] and used for evaluating real designs 
[41, 19]. Its applicability has also been shown for real-time embedded systems in general [18].  
High-level synthesis 
The classical high-level synthesis problems of allocating resources, binding computations to 
resources, and scheduling operations under timing and/or resource constraints are either solved by exact 
methods, such as integer/mixed linear program formulations [12, 103], or by heuristics, such as ASAP 
and ALAP [13, 98], list- [10, 21, 1], force-directed scheduling [26, 25], or evolutionary algorithms [10, 
25] (mainly used for allocation and binding problems). In conclusion, the trade-offs involved by choosing 
an appropriate evaluation method, where refinements of the evaluation method narrow the reachable 
design space (vertical direction), whereas covering algorithms explore the size of the design space 
(horizontal direction). Analytical models allow a fast evaluation of a relatively large fraction of the design 
space, thus enabling the identification of corner cases of the design. Over several possible steps of 
refinement with increasing effort for evaluation and implementation the design space can be bound to one 
particular design point. This funnel representation resembles the upper part of the platform-based design 
double pyramid [29], i.e., the final design point could also represent a whole platform. Methods for 
systematically exploring the design space on one of the layers of abstraction are discussed in the 
following section. 
 
                9 
z Afinity metrics 
z HW-SW partitioning specific metrics 
z I/O- and communication-specific metrics 
z Memory-specific metrics 
z Reliability 
z Deterministic behavior 
z Physical size 
z Compatibility 
z Usability 
z Testability 
Combined metrics 
In particular single-objective optimizers combine several objectives in order to consider confiicting 
criteria. Multi-objective algorithms could essentially also use combined objectives in order to reduce the 
number of dimensions to the problem, i.e., it could make sense to only consider the speed-cost and the 
flexibility-cost ratios for a certain design and not speed, cost, and flexibility as separate optimization 
goals. The most prevalent combined objectives are: 
z Energy-delay product 
z Computations-power ratio 
z Speed-cost ratio 
z Flexibility-related 
 
Strategies for covering the design space 
Exhaustively evaluating every possible design point 
This straightforward approach evaluates every possible combination of design parameters and 
therefore is prohibitive for large design spaces. The design space can be reduced by limiting the range of 
parameters and/or by parameter quantization. Multiple objectives can easily be maintained. The search 
process is completely unguided and unbiased towards preferences of the designer. Examples of design 
systems and case studies based on exhaustive search include system-level simulation [39, 6, 125], 
high-level synthesis [11, 13, 22, 4, 26, 111, 103], ADL-driven approaches [80, 91], cycle-accurate 
simulations [57, 48], instruction set simulators [36], code parallelization and partitioning onto 
multi-processors [54], trace-based analysis [64], and last but not least static analysis [40]. 
Randomly sampling the design space 
Evaluating only random samples is the obvious choice for coping with large design spaces. It also 
has the advantage of revealing an unbiased view of the characteristics of the design space. In [14], a 
Monte Carlo-based system is described where random samples of the solution space are generated by 
randomly creating constraints for logic synthesis. Another approach is to apply simulated annealing 
techniques. Starting from an initial design, changes to the design become more and more unlikely with 
advancing search time. In [110], Srinivasan et al. compare explorations driven by simulated annealing 
with results using an evolutionary approach. Gajski et al. [34] combine an exhaustive search over all 
possible architecture allocations with a simulated annealing-based exploration of mappings for each 
allocation. One could also think of combining the mentioned random walks with principles from Tabu 
search [38] in order to avoid evaluating the same design twice. Moya et al. [84] compare Tabu search 
with simulated annealing for an artificial, two dimensional optimization scenario. Tabu search is also the 
more promising search strategy compared with simulated annealing in the architecture allocation problem 
investigated in [5]. 
                11 
such as the network calculus [66, 113] for the network processing domain and event-stream based 
methods for the real-time embedded domain [99]. 
 
Supporting functionality for automated DSE 
Hierarchical simulator integration 
In [76], a framework is presented that integrates different simulators.   
Validation: For instance, in [51] a procedure is described to check two designs for equivalence of output 
traces. Searching the state space of both designs is avoided. Another partial verification technique is 
symbolic simulation (see [122] and the references therein) where the state space is subsampled by 
verifying system properties for defined symbolic inputs only.  
Automatic refinement of the task graph 
In [94], automatic task graph refinements to cope, e.g., with synchronization and serialization of 
accesses are described. The same kind of problem is addressed in the work by Lieverse et al. [73] for 
trace-based simulation. In [64, 63], automatic refinements of communication traces are described to 
consider DMA block lengths and bus protocols.   
Trace compression 
Lahiri et al. [64, 63] show how communication traces could be abstracted from burst transfers to 
only reveal abstract communication events.  Synthetic trace generation: The synthetic generation of 
traces according to profiling information is described in [27] in order to use (legacy) trace-based tools.   
Coupling of incompatible building blocks 
So-called wrappers/ adapters [126, 106] are needed for simulation and synthesis to fit components 
together, which can affect hardware and software parts of the system. Knowledge from interface synthesis 
[75, 108, 89, 86] can be reused for the hardware part of a wrapper, whereas following the approach of 
Networks-on-Chip [106] based on standard network interfaces affects protocol stacks on programmable 
cores. A theory of adapters for event-stream models can also be used for analysing heterogeneous systems 
[100].  
Operating system customization 
Apart from porting an existing third party real-time operating system to the system under 
development and leveraging knowledge from systematic device driver generation [85, 120], the 
generation/synthesis of a lean operating system, e.g. starting from a primary kernel of an open-source OS, 
could also be an option [35, 8].  
User-assisted DSE 
This is why Hu et al. [52] deal with the projection and visualization of a multi-objective design 
space to a three dimensional representation to ease interactive design decisions by the designer. 
 
Representing the design space 
Architecture models 
The listed architecture models mostly focus on performance perspectives of the modeled hardware. 
The same kind of representations could also be used to model or enable the analysis of properties like 
power, memory, and area consumption. Models can also be classified as abstract or executable 
descriptions. Abstract models only represent performance symbolically by, for instance, associating the 
required latency in clock cycles with each operation without actually executing any hardware description. 
                13 
traffic managers and dynamic deadline-based schedulers. Finally, the Compaan framework [46] enables 
the automatic transformation from nested loop programs written in Matlab to Kahn-like process networks 
that are especially suitable for FPGA implementations.  
Directed acyclic graphs (DAGs): 
The work by Blythe et al. [13] uses DAGs on the granularity of logic operations, whereas in [110, 
21, 103] tasks are used as nodes in the DAG. In the work by Blickle et al. [10] the nodes of a DAG 
represent computation and communication tasks. The EXPO framework [114] uses DAGs to represent 
packet processing applications for network traffic flows at the granularity of tasks. This application 
description is used by Dick et al. [25].  
Control data flow graphs (CDFG) 
The data flow part of the graph shows the underlying concurrency of the application, whereas the 
control flow part determines synchronization points of the data flow and dynamic decision points at 
run-time. CDFG representations are used in the comparison in [128].  
Non-linear, accumulative workload/ event stream descriptions:  
Arrival curves (see [66] and the references therein) describe a non-linear worst-case envelope for 
event streams, such as network traffic for all possible time intervals. Arrival curves together with DAGs 
are used in the EXPO tool [114].  
High-level programming language descriptions:   
Frameworks using high-level programming language descriptions as application description are, for 
instance, Milan [83], PICO [55], and ASIP-Meister [59].  
Transaction Level Modeling (TLM):  
TLM is a discrete-event model of computation used by SystemC, where modules interchange events 
with time stamps. TLM is used to model the interaction between software and hardware modules and 
communication through shared buses. 
Communication analysis graphs (CAG):  
In the work by Lahiri et al. [64] a CAG is used as an intermediate representation which is input to 
performance analysis. 
Co-Design Finite State Machines (CFSM) [7]:  
The communication between CFSM components is asynchronous, whereas within a finite state 
machine (FSM) the execution is synchronous, based on events.   
Click model of computation [60]:  
The StepNP framework [90] uses Click as application description and in Mescal [78] Click is one 
possible domain where applications can be specified.  
Hierarchical and heterogeneous models of computation:  
The Ptolemy framework [68] allows to combine various models of computation hierarchically in 
order to model and evaluate concurrent components. Metropolis' [9] metamodel language also allows to 
express different kinds of models of computation, such as transaction-level modeling and process 
networks.  
 
                15 
Other frameworks 
In the last category we give examples of other frameworks that integrate further ideas into the 
exploration process. EXPO is an example for an analytical exploration framework, PICO uses 
architecture templates to enable the efficient generation of tools, such as the compiler, and lastly 
Atomium shows a memory-centric exploration method incorporating domain-specific knowledge.  
EXPO [114]. Swiss Federal Institute of Technology (ETH) Zurich. EXPO is a system-level, 
analytical design space exploration tool targeted at applications and SoC architectures in the domain of 
packet processing. The SoC architecture can be composed of different computation cores, memories, and 
buses. Case studies using EXPO can be found in [42, 19, 113, 115]. The exploration process can be 
automated using a combination of binary search for the optimization of a single design and 
multi-objective evolutionary search for the covering of the design space.  
PICO [55]. Hewlett-Packard Laboratories. Architectures supported by PICO are composed of one 
VLIW processing core, a cache hierarchy, and one or several coprocessors. A coprocessor contains a 
number of functional units organized as a systolic array to accelerate compute-intense loop nests of the 
original application description. Heuristics used in order to explore the design space of the VLIW part of 
the design are compared in [109] that resemble hill climbing, regular subsampling, and probing with 
refinement.  
Atomium. IMEC, Belgium. Atomium is an exploration tool set for memory subsystems. Given a 
specification in C, the power consumption of the memory system, the memory size, and the memory 
speed can be traded-off against each other by code transformations and data layout changes. The 
techniques used are described in [79] and the references therein.  
 
The following categories are distinguished: 
z Source/origin of the framework: A(cademic) or C(ommercial) framework. 
z Application description: Representation of the application used by the tool, such as Kahn process 
networks (KPN), models of computation (MoC), programming languages like C, C++, synchronous 
or dynamic data flow (SDF and DDF), and finite state machines (FSM). 
z Architecture description: Architecture representation used, such as performance models, 
micro-architecture descriptions using architecture description languages (ADL), or hardware 
description language (HDL) descriptions. The notation 'abstract to HDL' means that the designer has 
several options and, depending on the chosen architecture representation, the abstraction level could 
vary from abstract performance models to fine-grained HDL descriptions. ISS stands for instruction 
set simulation. 
z Exploration modes: Options for exploring the design space, e.g. automatic vs. manual search in order 
to evaluate more than one design. 'Script'-based exploration in this context means that the 
corresponding tools are able to automatically explore designs exhaustively by evaluating all possible 
permutations of design parameters. Design parameters are exported by, for instance, SystemC 
modules and represent design decisions, such as clock speed, cache size, and operation bit width. 
The interconnects, i.e. the topology of the design, cannot be changed automatically by these scripts. 
z Coupling of tools: The possibility of coupling tools, in particular simulators, from different 
frameworks and third party vendors in order to evaluate a heterogeneous system is shown here. 
SystemC's transaction-level modeling abstraction is often used for this purpose. 
z Design focus: The main focus of the design tool is displayed in this column. Focused on 
system-level design ('system') implies that heterogeneous multi-processor systems can be described. 
The emphasis is put in particular on supporting different abstraction levels and refinement paths. It 
also often means that SystemC is supported and tools, such as simulators, from different sources can 
be combined for system-level evaluation. Micro-architecture centric tools ('micro') usually focus on 
single processor systems, where the automatic generation of optimized compilers and simulators 
becomes important. 
z Path to hardware: Here we state whether (synthesizable) models in a hardware description language 
(HDL) can be introduced into the evaluation. A system-level tool can often combine HDL and other 
models in a system description so that the whole design can be co-simulated. The HDL models are 
designed off-line in another tool and imported into the system-level tool. An architecture description 
                17 
organizations and hierarchies, including on-chip DRAM, frame buffers, partitioned memory address 
spaces, etc. MDes captures constraints between operations with explicit Reservation Tables [4], using a 
hierarchical description for compactness. Because this hierarchical specification allows instruction set and 
structure information to be specified at any level of the hierarchy, (e.g. usage, latency, operation), local 
changes to the architecture (for exploration) could propagate through the hierarchy, and require global 
changes to the specification making it cumbersome and error-prone. 
In EXPRESSION, we will follow a mixed-level approach (behavioral and structural) to facilitate DSE. 
Hopefully, we will provide support for specification of novel memory subsystems. We avoid explicit 
representation of the reservation tables by extracting them from the structural description using the 
algorithm developed in the near future. Our approach also eliminates redundancy by using the same 
net-list information to drive both the compiler and the simulator. 
 
Processor Simulator 
LISA seems to have been designed primarily for retargeting simulators. Also, it does not support 
specification of detailed constraint information needed for compiler instruction scheduling. RADL [16] is 
an extension of the LISA approach that focuses on explicit support of detailed pipeline behavior to enable 
generation of production quality cycle- and phase-accurate simulators. FLEXWARE [5] and MDes [18] 
have a mixed-level structural/behavioral representation. FLEXWARE contains the CODESYN 
code-generator and the Insulin simulator for ASIPs.  The simulator uses a VHDL model of a generic 
parameterizable machine. The application is translated from the user-defined target instruction set to the 
instruction set of this generic machine.  
Automatic Generation of Synthesizable RTL Models 
Two major approaches to synthesizable HDL generation have been proposed. The first one is a 
generic parameterized processor core based approach. These cores are bound to a single processor 
template whose tools and architecture can be modified to a certain degree. Another approach is based on 
processor specification languages. The language based approaches permit specification of the processor at 
the expense of restrictions on the quality and/or availability of the tools. 
Examples for processor template based approaches are Xtensa [24], Jazz [8], and PEAS [12]. 
Xtensa [24] is a scalable RISC processor core. Configuration options include the width of the register set, 
caches, memories etc. New functional units and instructions can be added using the Tensilica Instruction 
Language (TIE). A synthesizable hardware model along with software toolkit can be generated for this 
class of architectures. Improv’s Jazz [8] processor is a VLIW processor that permits the modeling and 
simulation of a system consisting of multiple processors, memories, and peripherals. It allows 
modifications of data width, number of registers, and the depth of hardware task queue. It is also possible 
to add functional units and add custom functionality in Verilog. The PICO-NPA [22] system 
automatically synthesizes nonprogrammable accelerators to be used as co-processors for functions 
expressed as loop nests in C. PEAS [12] is a GUI based hardware/software codesign framework. It 
generates HDL code along with software toolkit. It has support for several architecture types and a library 
of configurable resources. Instruction set and micro-operations are separately described. 
Processor description language based HDL generation frameworks can be divided into 
environments based on the type of information the language can capture. nML [10] and ISDL [4] 
languages capture the instruction set (IS) of the processor. In nML, the processor IS is described as an 
attributed grammar with the derivations reflecting the set of legal instructions. The architectural scope is 
limited to DSPs and ASIPs for nML based specification. In ISDL, constraints on parallelism are explicitly 
specified through illegal operation groupings. As the generation of functional units is the result of an 
analysis and optimization process of the HDL generator HGEN, the designer has only indirect influence 
to the generated HDL model. Itoh et al. [11] have proposed a micro-operation description based 
synthesizable HDL generation. The structure of the processor is derived via analyzing the 
micro-operation descriptions. It can handle a very simple processor model with no hardware interlock 
mechanism or multi-cycle operations. It relies on compiler to insert necessary NOP instructions. As a 
result, it does not support instructions related to interrupt, cache control, co-processor etc. 
                19 
The advantages of Trimaran described as following: 
z Trimaran is characterized by a parameterized processor architecture supporting novel features 
such as predication, control and data speculation and compiler controlled management of the 
memory hierarchy. 
z Optimizations and analysis modules can be easily modified. 
z Trimaran provides a detailed simulation environment and a flexible performance monitoring 
environment. 
 
The disadvantages of Trimaran described as following: 
z Mainly focused on EPIC (VLIW) architectures. 
z Complicate Machine DEScription (MDES) and Internal Representation (IR) 
z Poor compiler front-end 
EXPRESSION 
The EXPRESSION toolkit allows the SOC designer to analyze architectural trade offs by simulating 
the design on the automatically generated simulator. EXPRESSION employs a simple LISP-like syntax to 
ease specification and enhance readability [9]. An EXPRESSION description is composed of two main 
sections: behavior and structure, which are further sub-divided into three subsections each: operations, 
instruction, operation mappings, and components, pipeline/data–transfer paths, memory subsystem 
respectively. The advantages of EXPRESSION described as following: 
z Ease of specification and modification of architecture from the GUI.  
z Mixed behavioral/structural representation supporting a natural, concise specification of the 
architecture. 
z Explicit specification of the memory subsystem allowing novel memory organizations and 
hierarchies. 
z Efficient specification of architectural resource constraints allowing extraction of detailed 
Reservation Tables (RTs) for compiler scheduling. 
The disadvantages of EXPRESSION described as following: 
z EXPRESSION can not support applications having function calls 
z The presence of the memory hierarchy can not be recognized by the compiler 
z The module of back-end may not be replaced or modified. 
z Application analysis may not be integrated into the architecture optimization flow. 
MESCAL 
MESCAL is aimed at the design of heterogeneous, application-specific, programmable (multi-) 
processors. The advantages of MESCAL described as following: 
z Provide a programmer's model and software development environment that allows for efficient 
implementation of an interesting set of applications onto a family of fully-programmable 
architectures/micro-architectures  
z Develop an architecture development system to specify, evaluate and explore such 
fully-programmable (micro-) architectures using a correct-by-construction method. 
The disadvantages of MESCAL described as following: 
z Mescal is only for GSRC member without source codes, nor any support. 
 
PTOLEMY 
z The Ptolemy framework [43] allows to combine various models of computation hierarchically in 
order to model and evaluate concurrent components. The advantages of PTOLEMY is that the free 
source code and environment are available.  
                21 
Our Methodologies 
 
Compilation 
Optimization 
Simulation/ 
Verification 
Application in C
CDFG 
Machine Code 
Architecture 
Description 
High Level Language Translation (Compilation) 
System-level design frameworks allow the modeling of the behavior of the software even at very 
abstract levels and retargetable compilers ease the evaluation of the actual software on the intended 
hardware at low levels of abstraction.  
Software Compilation 
Building a processor core, instruction set architecture (ISA) plays the coordinate role to define these 
instructions built with hardware and used with software (compiler or assembler). Besides, ISA is also 
defined the hardware/ software procedure of some special situation, such as exception, interrupt, delay 
slot, and so on. In our MIPS project, our cross-platform software is utilized GNU cross-compiler to let 
our hardware architecture fit GNU cross-compiler and GNU tool chain. There are segments in a program, 
the memory locations of programs should be considered to locate a starting address of each segment in 
the program. GNU supports linker script to set the locations of segments. Using linker script can easily 
change these memory locations and reduce the effort to maintain a developed program.  
Retargetable compiler to exploit the features of the co-processor 
It is possible to design an architecture outside the scope of a compiler view. To solve this problem, 
either the architecture view is restricted or the compiler view is enhanced. It is exactly this appropriate 
defining, partitioning, and restricting of views that is the cornerstone to a successful framework. The 
computational functions that can be performed by the architecture can be extracted so that a high-speed 
cycle-accurate simulator can be generated from the architecture. The functional abstraction based 
primitives will be used to generate a retargetable simulator.  The notion of functional abstraction comes 
from a simple observation: different architectures may use the same functional unit (e.g., fetch) with 
different parameters, the same functionality (e.g., operand read) in different functional unit, or new 
architectural features.  
The retargetable compiler design for embedded systems is much more involved, not only because of 
numerous micro-architectural features, but also due to strict power, performance and cost needs of 
embedded systems. An ideal compiler should not only be able to exploit the micro-architectural features 
to generate optimized code for given metric of power, performance, cost, code size etc. It should also be 
able to utilize the co-processor (if present), and hide latencies of memory and other slow units.  
                23 
 
Figure: SUIF sub-module viewer for IDCT procedure and object dependent analysis. 
The Gcc Compiler Infrastructure 
 
                25 
 
Figure 5. Design flow of the automatic application-specific instruction generation. 
Automatic Application-Specific Instruction Generation 
To explore appropriately the design space, we developed algorithms that automatically generate the 
customized instructions from high-level application code.  A set of algorithms, including instruction 
template generation, candidate instruction selection, and application mapping, are developed to efficiently 
utilize the instruction set extensibility of the ASIP.  Traditionally, applications are specified by programs 
in high-level languages, like C/C++. Compilation optimization algorithms are usually performed on the 
control data flow graph (CDFG) derived from the program. A control flow graph consists of a set of basic 
block nodes and control edges. Each basic block node is a data flow graph in which operation nodes are 
connected by edges that represent data dependencies. The CDFG is already decomposed by SUIF2 
described in the previous section according to a given basic instruction set, so that every node 
corresponds to a basic instruction. Figure 5 shows the whole design flow of the automatic 
application-specific instruction generation.  
Given the CDFG and ASIP constraints (input/output ports and number of nodes), template 
generation and candidate building are performed to produce a template library. According to the 
limitation of maximum number of application-specific instructions, the template selection algorithm will 
be performed to obtain the final application-specific instruction. The refined C program using 
application-specific instructions is then generated by the application replacing. The algorithm for 
generating the instruction templates are depictd in the Figure 6. 
  
Figure 6. The instruction template generation algorithm.     Figure 7 The template selection algorithm. 
                27 
05
10
15
20
25
30
idct_cycle adpcm_decode_cycle adpcm_encode_cycle mpeg2decode_cycle rsa_cycle
origional
(2,1,5,5)
(3,1,5,5)
(4,1,5,5)
(2,2,5,5)
(3,2,5,5)
(3,1,2,5)
(3,1,3,5)
(3,1,4,5)
(3,1,5,1)
(3,1,5,2)
(3,1,5,3)
(3,1,5,4)
(3,1,5,6)
(3,1,5,7)
 
Figure 9. Experiment results of the speedup vs. application programs with various constraints. 
Optimization with Hardware Constrains 
Application-Specific Instruction-set Processors (ASIPs) have popularly been used to balance the 
trade-off between cost and performance for a specific target application without creating a new processor. 
The generation and selection of ASIs can dramatically affect the quality of an ASIP design with constrains 
such as number of I/Os, hardware cost, ASI hardware latency, and total number of ASIs. In this paper, the 
disjoint operations can be combined as an ASI to enrich the selection varieties. The operation cover-ratio 
and the more accurate ASI latency model are used to select good ASIs so that the performance can be 
improved. A design flow is developed to automatically generate the ASIs and the experimental results 
show that 1.64x speed up can be obtained on sha benchmark under 5 inputs, 3 outputs, and hardware cost 
less than 8000 LEs in Altera FPGA. 
Problem Formulation 
1)  Input:  Specific application program source codes in C. 
2)  Constrains: Hardware cost, number of register file I/O ports, number of selected ASI, ASI latency. 
3)  Objective:  Performance improvement. 
4)  Outputs:  SUIFvm program with ASI extensions. 
5)  Assumptions:   
• Using SUIFvm instruction set as a based processor. 
• Multi-cycle Functional Unit. 
• No memory operation in ASI. 
• No memory access and pipelining stall time. 
Design Flow Overview 
 
Figure  Design flow for optimization under hardware constraints 
The design flow consists of three phases.  In Phase 1 “DFG Generation”, the C code will be translated 
into DFGs with SUIF2 [4] and MachineSUIF [3]. We also design some passes of optimization and 
                29 
TABLE I 
HARDWARE LIBRARY EXAMPLE 
Opco
de 
Software 
executing 
cycle 
Hardwar
e latency
Hardware 
Cost 
ADD 1 0.4 1 
MUL 10 9.5 7 
STR 2 - - 
…    
When nodes are selected as a sub-graph, constrains will be  checked to implement ASI. No 
memory-access and branch instructions are allowed in ASI. The sub-graph has to be convex to keep 
data-dependence. The I/O register numbers and other constrains which are set by designer have  to be 
satisfied. Figure 3 is an example of data-flow graph. In Figure 3, if the input/output constrains are 10/10, 
the solid line circle T1 which contains node 1, 3 could be a template. The dotted line circle N1 which 
contains node 2, 4, 5 is a non-convex-graph because there is a path from node 2 to node 5 through node 3 
which is not contained in the sub-graph. So the sub-graph N1 is not a template. The sub-graph T2 which 
contains node 1-6 is the biggest template in Figure 3. We can use Table 1 to calculate the attribute of T2. 
For example, the node 2, 4, 6 are on the critical path of T2. So the critical path latency of T2 is 28.5 
(9.5+9.5+9.5). Node 7 will not be selected in a template because it is a memory store operation. 
 
Figure:  Data-Flow Graph Example 
After all templates of each DFG are generated, we just check template isomorphism to generate 
candidates.  
Candidate Selection and Application Replacement 
After the candidates are generated, we need to select candidate under hardware constrains. We needed a 
merit function to rank all the candidates for selection. Normally the reduce time of the candidates would 
be adopted. But actually the reduce time of candidate can not be easily calculated before selection 
because the overlapping between templates maybe exist in a candidate or multiple candidates. Before we 
use the equation 1 to calculate the reduce time of candidates in [9]. Tsw was the software executing cycle 
of a template. Thw was the hardware critical path latency. NT was the number of templates of the 
candidate in the DFG (Basic Block, BB). repeatingTimes was the execution frequency of the BB. If there 
is no overlapping between all templates in the same candidates, the equation 1 is correct for selecting one 
T2 
N1 T1  
 
                31 
 
Figure  Speed up when the hardware cost limit is increased under the input limit 6 and the output limit 3. 
The speed up of sha is no increasing after hardware cost limit 3000 because no template could be find 
to select after previous ASI selected. Another problem is the speed up of sha at hardware cost limit 200. 
The speed up is lower then hardware cost 100. We thought that the candidate selection method cause the 
result. When the hardware cost limitation increases from 100 to 200, the larger template is generated and 
be selected because normally the larger template brings more reduce time. But after the larger template is 
selected, the small template could not be selected due to overlapping between large template and small 
template. In this case, the sum of reduce time of multiple small templates are bigger than a large template. 
In figure 5, we evaluated the speed up when the input/output limit was increased under the hardware 
cost limit 8000. The result shows that too many input and output may not be necessary. In general, loose 
input/output limit brings large templates. Even the large template is generated, the large template may not 
be selected because the reduce time of the candidate which contained the large template was maybe not 
large the same. The small templates have greater possibility to be isomorphic than the large templates. In 
four benchmarks, only sha could get the benefit from loose limit of input/output. 
 
Figure:  Speed up when the input/output limit was increased under the hardware cost limit 8000. 
Optimization with Memory Access Reduction 
System designers may add some new instructions, called Application-Specific Instructions (ASIs), 
by automatic design flow to optimize system performance for a specific target application. In past days, 
most Application-Specific Instruction-Set Processor (ASIP) researches focus on instructions latency but 
regardless the impact of memory access to improve performance. In this paper, a design flow is proposed 
to automatically generate ASIs to improve performance with memory access consideration. The flow 
consists of translating a C program to CDFGs, selecting ASIs based on not only instruction latency but 
also memory access, and finally simulating the whole program behavior on MIPS R3000-based 
microarchitecture. Our experiment results show that the proposed approach can achieve up to 14% 
performance improvement and 10% memory access reduction comparing to without memory access 
consideration. 
Design Flow 
The overall design flow of proposed methodology is illustrated in Figure 1. At the beginning, 
application program written in C language will be compiled to assembly without register allocation. We 
                33 
Merit Functions 
W compared five merit functions which are expressed as following for ASI selection:  
 
(Tsw - Thw)* Occurrence 1) 
(Tsw - Thw + IR)* Occurrence 2) 
(Tsw - Thw + AMATd * Cex)* Occurrence 3) 
(Tsw - Thw + AMATi * (Ninst -1))* 
Occurrence 4) 
(Tsw-Thw+AMATi*(Ninst-1)+AMATd*Cex)
* Occurrence 5) 
 
where Tsw is the software execution time of one template of current candidate. Thw is hardware 
latency of this template. In this paper, the hardware is the critical path delay of this template which is 
obtained by bottom level computation [11]. IR is the number of register transfer which is hiding by this 
template. Occurrence is the execution times of this candidate which is sum of execution times of all 
isomorphic equivalent templates obtained from profiling. AMATi is average memory access time [9] for 
instruction fetch of original application. Similarly, AMATd is average memory access time for data access. 
Ninst is the number of nodes of template. Cex is maximum number of living register at each instruction of 
template which is estimated by coloring minus number of register of processor.  
 In merit function (1), the difference between software execution time and hardware delay of this 
instruction combination is considered only. Any parameter about memory is not included in this merit 
function. 
If registers are not enough to keep all the living data in processor, compiler must use store instruction 
to temporarily keep data in memory. Because memory accesses are related with register utilization, if we 
can diminish the register demand of program, the memory access will be reduced. We believe that if there 
are more register transfers that can be hided in a template, there might be more opportunity to reduce 
register requirement. Therefore, we propose the merit function (2) and take the internal register into 
consideration. 
In merit function (2), memory access does not take into account immediately. Hiding register 
transfers is not meaning register demand will be reduced consequentially because of register sharing. 
Registers which liveness is not overlapping can use the same register to reserve the data. By this reason, 
we use merit function (3) to take register sharing into account. If Cex is lager than zero, at least two 
load/store instructions will be produced to reserve data in memory when register allocation. In order to 
reduce memory access, templates which Cex is larger then zero will have a higher priority to be 
implemented as an ASI. 
Merit function (4) is considering with instruction fetch. If a template can reduce more instruction fetch, it 
has higher priority to be implemented as an ASI. However, if AMATi is very low, instruction fetch is not 
the dominant factor of system performance. Therefore, we take AMATi as a weight argument. Merit 
function (5) combine merit function (3) and merit function (4) to completely consider instruction fetch 
and data access. 
 
Simulation Environment 
In this paper, we use the instruction set of MIPS R3000 processor as our base instruction. The 
instruction bit-width of MIPS R3000 is 32 bits. There are 32 registers which using 5 bits to encode. The 
operator is using 6 bits to encode. As a result of above reasons, one instruction can only use maximum 5 
registers for data input and output. Therefore, we encode our ASIs as follows: 
 
                35 
adpcm encoder 1.1068 6.9981 1.1068 6.9981 8.2479 -0.0008 8.2479 -0.0008 4 
adpcm decoder 1.1485 8.9515 1.1485 8.9515 10.5881 -0.0009 10.5881 -0.0009 5 
 
sha
1.15
1.25
1.35
1.45
1.55
1.65
1 2 3 4 5 6 7 8
# of ASI
sp
ee
du
p 
(X
) M5
M4
M3
M2
M1
 
Figure: Speedup trend for different number of ASIs 
 
 For DCT, number of memory access is similar for Merit1 and Merit2. It is because this program 
only needs 3 temporary registers estimated by register coloring. Therefore, there is no data load/store 
which is due to insufficient register can be reduced. Therefore, the benefit of Merit2 could not be 
exhibited in this benchmark. The same appearance happens on adpcm encoder and decoder. For all merit 
function, such kinds of programs generate the same ASIs. 
Figure2 shows the effect of different number of ASIs using same system configuration with table 1. 
We find that merit function (2) obtains the best performance improvement. The speedup of merit function 
(3) is the same with Merit function (1) and this two merit function get the worst performance 
improvement. Merit function (4) and (5) obtains the same speedup). Although the speedup is the same 
with merit function (2) when we generate 8 ASIs, these two merit functions can not guarantee the speedup 
is the best for all configuration of ASI number. In the case of 6 ASIs, merit function (2) obtains about 
0.7% performance improvement comparing to merit function (4) and (5). 
Figure3 and Figure4 show the performance trend for different I-cache size and D-cache size for sha 
program.  System configurations of these two figures are the same with table 1 except for cache size and 
number of ASI. We find that merit function (3), (4), and (5) do not gain any benefit for changing memory 
hierarchy architecture even if they considering memory arguments in detail. 
sha with 6 ASIs
1.35
1.4
1.45
1.5
1.55
1.6
1.65
1 2 4 8 16
I-cache size (KBytes)
sp
ee
du
p 
(X
) M5
M4
M3
M2
M1
 
Figure: Performance trend for different instruction cache size (D-cache 4K). 
 
                37 
Our Methodology 
 
 
CDFG 
ILP Transformation 
ILP Formulation 
ILP Solver 
Selected ASIs 
Architecture Description 
 
Mathematic Formulation 
Assumptions: 
- Application: Single program 
- Architecture: RISC-based processor 
 
y A program can be represented as a CFG (control flow graph ), G*= ( i=1 to Nbb Gi )  CE 
y CE (control edge) is a set of control edges between Gi  
y Nbb: number of Basic Block 
y Gi (V,E) the directed acyclic graphs (DAGs) representing the data flow of each basic block in the 
CFG 
y The nodes V represent primitive operations and  
y The edges E represent data dependencies 
y Primitive operation table 
 
y Each graph Gi is associated to a graph Gi+ (V  V+, E  E+), which contains additional nodes V+ 
and edges E+ 
y The additional nodes V + represent input and output variables of the basic block 
y The additional edges E + connect nodes V + to V , and nodes V to V + 
 
y G*+ = ( i=1 to Nbb Gi+ )  CE , considered data dependence between Gi 
 
y A cut Si,j is an induced subgraph of Gi: Si,j ⊆ Gi 
y There are 2|V | possible cuts, where |V | = NNi is the number of nodes in Gi 
y Number of the generated Si,j is defined as NSi 
y Number of nodes in Si,j is defined as NNSj 
y An arbitrary function M(Si,j) measures the merit of a cut Si,j 
y It is the objective function of the optimization problem and typically represents an 
estimation of the speedup achievable by implementing Si,j as a special instruction 
y SW(Si,j) = Tswi,j= SW execution time of Si,j 
                39 
y  
yGain(ASIh) =   
y , Si,j∈NSAh,I Nonoverlapping 
 
 
Optimization using Partitioning and Scheduling 
A hardware/software co-design methodology is proposed in this year project for balancing 
efficiency and flexibility in embedded systems comprised by ASIP and multicluster processor 
architectures. The main challenge associated with multicluster architectures is to effectively partition 
program operations across the available instructions on each ASIP to maximize ILP. 
We adapt a powerful multilevel graph partitioning commonly used in VLSI design to perform 
operation partitioning at a global scope with the view of all operations.  Multilevel graph partitioning 
divides the dataflow graph into multiple parts in a hierarchical manner. Crucial for performance is the 
efficient scheduling of the dataflow operations. We propose a mixed scheduling that combine static and 
dynamic scheduling by implementing dynamic scheduling using a completely distributed synchronization 
scheme.  The whole design methodology is depicted in Figure 10. A set of tools in SUIF, cpp2suif, 
do_lower, do_s2m, do_il2cfg, is used to trnasform the application program from C to the opcodes of the 
SUIFvm library as well as to generate the CFG. Eventually the the CFG can be displayed using dotty by 
Graphviz show in Figure 11. Before the CFG is transformed to DFG, two new passes, Inlining and Loop 
Unrolling, are developed to obtain the finest grain of the DFG so that every node in DFG corresponds to a 
basic opcode of the SUIFvm.   
C code
CFG 
Construction
Generate
DFG
ScheduleLoop Unroll
DFG Partition
TempCFG 
Coarse 
grain 
DFG
Fine 
grain 
DFG
Result
Partition 
information
Refine?
Performance 
estimation
Inline
End
        
Figure: A design methodology with operation partitioning and mixed scheduling to maximize ILP for 
multicluster/multiprocessor architectures.  Figure: A CFG obtained from C code via SUIF tools. 
 
The DFG is transformed to the hypergraph representation as the input of the hMETIS [37], the 
multilevel hypergraph partitioning software, developed in Karipis Lab.  Figure 12 shows the DFG and 
its corresponding hypergraph with the hMETIS input format.   
                41 
   
(a)                                       (b) 
Modified List Schedule 
 while (until all node are add-in node_list) do  
 update Ready Queue 
 choice_node = find the maximum priority in the Ready Queue 
 node_list= ADD (choice_node); 
 endwhile 
 while (node_list is not empty) do 
 for k=1 to numbers_of_nodes 
  if(the parents are in the same processor) 
   add external cost to this schedule 
  endif 
 endfor 
 for k=1 to numbers_of_processors 
  Meta_Fastest = find the earlest Starting time of this node 
  if(Meta_Fastest < Fastest) then 
   Fastest = Meta_Fastest 
  endif 
 endfor 
 Schedule this node the Fastest Processor 
 Remove this node from node_list 
 endwhile 
Figure 14. (a) The modified scheduling algorithm to perform operation cluster assignment. (b) An 
example of scheduling results. 
Simulation/Verification 
The extensible and retargetable simulator tool-kits  
Liberty Simulation Environment 
The Liberty Simulation Environment (LSE) from Princeton University is a concurrent and structural 
component-based modeling tool designed to reduce time spent building simulation models, to improve 
fidelity of models, to foster more collaboration, and to facilitate technology transfer [40].  Since LSE is 
an infrastructure for building models rather than being a simulator, it does not have a limited scope. 
Models can range from processor cores to multiprocessor systems and their interconnection networks. In 
fact, nothing in LSE's core design makes it specific to processor or micro-architecture modeling. However, 
the LSE is too difficult to configure the target simulation for performance evaluation. 
The retargetable instruction set simulator will be developed to simulate real programs on a range of 
modern processors and systems, using fast execution-driven simulation as well as to provide wide range 
micro-architecture exploration from a fast functional simulator to a detailed, out-of-order issue processor 
that supports non-blocking caches, speculative execution, and state-of-the-art branch prediction. 
SimpleScalar toolset 
The SimpleScalar [42, 43] toolset provides an infrastructure for simulation and architectural 
modeling. The toolset can model a variety of platforms ranging from simple unpipelined processors to 
detailed dynamically scheduled microarchitectures with multiple-level memory hierarchies.  The toolset 
was released as an open source distribution freely available to academic noncommercial users. 
Applications run on the SimpleScalar hardware model using a technique called execution-driven 
simulation, which requires the inclusion of an instruction-set emulator and an I/O emulation module. The 
I/O emulation module provides simulated programs with access to external input and output facilities. 
SimpleScalar supports several I/O emulation modules, ranging from system-call emulation to full-system 
simulation.  The specialized simulators from SimpleScalar fall into four main categories, Functional 
simulation, Cache simulation, Profiling, and Out-of-order processor timing simulation. The tool set is 
partly derived from the GNU software development tools. It provides researchers with an easily 
                43 
Verification
A software-based self-test methodology [77] was developed for a simple processor core as well as a 
verification platform for SoC bus interface [76] was also established at FCU. The verification problems 
will gain even further importance in the future as systems grow in complexity and time to market shortens. 
Further, in order to perform rapid DSE, the designer needs tools that automatically perform or at least a 
limited form of formal verification of the specification. This problem is a very hard problem and is a hot 
bed of research activity in the ADL community. Some limited forms of formal verification that show 
promise in catching errors that may creep up in the specification. They are property checking, 
connectivity checking, consistency checking, and completeness checking. 
Processor core software-based self-test 
 
 
 
SoC bus interface verificatiion 
The advance of the system-on-chip（SoC）design paradigms makes the verification of bus interface 
protocol compliance increasingly important to the  success of a SoC project. In this thesis, a verification 
platform is established by using visual Tcl/Tk in the Linux environment to integrate a cycle-accurate 
                45 
 
Figure: VIS results. 
A Customized Processor Architecture at FCU 
In this project we built our framework on a MIPS4000 like processor architecture which we call 
OpenMIPS [11] shown in Figure 1. The architecture contains five pipeline stages – fetch, decode, operand 
read, execute and writeback.  
 
Figure 1. The architecture of OpenMIPS core. 
Customized Function Unit Exploration  
With the customized embedded processor, system designers can accelerate time-critical software 
algorithms by adding custom instructions to the MIPS instruction set. System designers can use custom 
instructions to implement complex processing tasks in single-cycle (combinatorial) and multi-cycle 
(sequential) operations. Additionally, user-added custom instruction logic can access memory and/or 
logic outside of the MIPS system. The MIPS wizard [79] was developed to configure the custom 
instructions. The MIPS wizard will automate generate the ISA specific and the ISA Verilog file for MIPS 
instruction decoder. An assembly code can be compiled by the assembler which according to the ISA 
specific. 
Co-Processor Exploration 
To balance the workload on the processor, and to accommodate the changing application 
requirements, critical portions are moved out of the processor core into coprocessors. Consequently, given 
an application, it is important to identify parts of the application that can be moved to coprocessors. This 
project, we defined coprocessor models for the special operations such as DCT and IDCT [78]. Also 
define a topology to interface the coprocessors to the main processor core, depicted in Figure 2. The 
waveform diagram of the coprocessor is shown in Figure 3. Once a coprocessor is plugged on, the 
instruction scheduler treats this coprocessor as a functional unit, and the scheduler knows all the timings. 
So the application code could be optimized, even if memory accesses for (or by) the coprocessor are quite 
long. In fact, the scheduler can take this into account for the scheduling of all the other instructions which 
                47 
Configuration Wizard GUI 
The MIPS configuration wizard integrates the user define hardware blocks with the MIPS 
processor’s ALU when building the MIPS embedded processor. The MIPS configuration wizard also 
creates software macros in Assembly, providing software access to the custom hardware via the name of 
the macro. If the custom instruction is combinatorial, the number of clock cycles needed to perform the 
instruction is exactly one clock cycle. If the custom instruction is sequential, “UDHDone” signal had to 
be provided to synchronize the CPU execution. Figure 6 depicts the ALU block diagram. Figure 7 depicts 
an example for R-type instruction generator flow and the MIPS configuration wizard GUI. 
       
Figure 6. ALU block diagram.                 Figure 7. R-type instruction generator flow 
Simulation  
Results from analytical models can be too pessimistic since these models often consider the 
worst-case. Simulations may reveal more realistic results for average-case optimization. One drawback of 
simulations is the need for an executable model. In an early phase of the design providing such a model 
may impose an unsubstantiated burden for evaluating early design decisions. 
Target system simulation 
Our students have been familiar with high level procedural or object-oriented programming 
languages, such as C, C++, Java, or Matlab for multimedia signal processing. The Synopsys's CoCentric 
System Studio and Cadence's former Virtual Component Co-Design (VCC) framework have been 
established via CIC. The POLIS and PTOLEMY from UC, Berkeley, were built as a simulation engine, 
but we are not limited to PTOLEMY or POLIS. VHDL code including all the co-simulation information 
is also an output of the system, so any commercial VHDL simulator can be adapted for this purpose. 
The Instruction Set Architecture (ISA) simulation 
The Liberty Simulation Environment (LSE) from Princeton University was established in our Lab for ISA 
simulation framework. In a retargetable ISA simulation framework, the range of architectures that can be 
captured and the performance of the generated simulators depend on three issues: first, the model based 
on which the instructions are captured; second, the decoding algorithm that uses the instruction model to 
decode the input binary program; and third, the execution method of decoded instructions. These issues 
are equally important and ignoring any of them results in a simulator that is either very general but slow 
or very fast but restricted to some architecture domain. The LSE is a concurrent and structural 
component-based modeling tool designed to reduce time spent building simulation models, to improve 
fidelity of models, to foster more collaboration, and to facilitate technology transfer [70,74].   
                49 
364-367, May 2002.  
3. G. Ascia, V. Catania, and M. Palesi. A framework for design space exploration of parameterized 
VLSI systems. In ASP-DAC/VLSI Design 2002, pages 245-250, Jan. 2002.  
4. M. Auguin, L. Capella, F. Cuesta, and E. Gresset. CODEF: a system level design space 
exploration tool. In 2001 IEEE International Conference on Acoustics, Speech, and Signal 
Processing, volume 2, pages 1145-1148, 2001.  
5. Axelsson. Architecture synthesis and partitioning of real-time systems: a comparison of three 
heuristic search strategies. In 5th Int. Workshop on Hardware/Software Codesign 
(CODES/CASHE), pages 161-165, Mar. 1997.  
6. Baghdadi, N. Zergainoh, W. Cesario, T. Roudier, and A. Jerraya. Design space exploration for 
hardware/software codesign of multiprocessor systems. In 11th International Workshop on Rapid 
System Prototyping (RSP), pages 8-13, 2000. 45  
7. F. Balarin, M. Chiodo, P. Giusto, H. Hsieh, A. Jurecska, L. Lavagno, C. Passerone, A. 
Sangiovanni- Vincentelli, E. Sentovich, K. Suzuki, and B. Tabbara. Hardware-Software 
Co-Design of Embedded Systems: The Polis Approach. Number 404 in International Series in 
Engineering and Computer Science. Kluwer Academic Publishers, 1997.  
8. F. Balarin, M. Chiodo, A. Jurecska, L. Lavagno, B. Tabbara, and A. Sangiovanni-Vincentelli. 
Automatic generation of a real-time operating system for embedded systems. In 5th International 
Workshop on Hardware/Software Co-Design (Codes/CASHE), Mar. 1997.  
9. F. Balarin, Y. Watanabe, H. Hsieh, L. Lavagno, C. Paserone, and A. Sangiovanni-Vincentelli. 
Metropolis: an integrated electronic system design environment. IEEE Computer, 36(4):45-52, 
Apr. 2003.  
10. T. Blickle, J. Teich, and L. Thiele. System-level synthesis using evolutionary algorithms. Design 
Automation for Embedded Systems, Kluwer Academic Publishers, 3(1):23-58, Jan. 1998.  
11. S. Blythe and R. Walker. Toward a practical methodology for completely characterizing the 
optimal design space. In 9th International Symposium on System Synthesis, pages 8-13, Nov. 
1996.  
12. S. Blythe and R. Walker. Effciently searching the optimal design space. In Ninth Great Lakes 
Symposium on VLSI, pages 192-195. IEEE Comput. Soc, Mar. 1999.  
13. S. Blythe and R. Walker. Effcient optimal design space characterization methodologies. ACM 
Transactions on Design Automation of Electronic Systems, 5(3):322-336, July 2000.  
14. D. Bruni and A. B. L. Benini. Statistical design space exploration for application-specific unit 
synthesis. In 38th Design Automation Conference (DAC), pages 641-646, 2001.  
15. D. Burger and T. M. Austin. The Simple Scalar tool set, version 2.0. Technical Report 1342, 
Computer Sciences Department, University of Wisconsin-Madison, June 1997.  
16. Cai, D. Gajski, and M. Olivarez. Introduction of system level architecture exploration using the 
SpecC methodology. In IEEE International Symposium on Circuits and Systems, volume 5, 
pages 9-12, May 2001.  
17. Cai, S. Verma, and D. D. Gajski. Comparison of SpecC and SystemC languages for system 
design. Technical Report CECS 03-11, University of California, Irvine, May 2003.  
18. Trimaran Release: http://www.trimaran.org. The MDES User Manual, 1998. Ahmad, M. Dhodhi, 
and C. Chen. Integrated scheduling, allocation and module selection for design-space exploration 
in high-level synthesis. IEE Proceedings - Computers and Digital Techniques, 142(1):65-71, Jan. 
1995.  
19. S. Chakraborty, S. K unzli, L. Thiele, A. Herkersdorf, and P. Sagmeister. Performance evaluation 
of network processor architectures: Combining simulation with analytical estimation. Computer 
Networks, Elsevier Science, 41(5):641-665, Apr. 2003.  
20. P. Chandra, F. Hady, R. Yavatkar, T. Bock, M. Cabot, and P. Mathew. Benchmarking network 
processors. In P. Crowley, M. Franklin, H. Hadimioglu, and P. Onufryk, editors, Network 
Processor Design: Issues and Practices, volume 1, pages 11-25. Morgan Kaufmann Publishers, 
Oct. 2002.  
21. K. Chatha and R. Vemuri. An iterative algorithm for hardware-software partitioning, hardware 
design space exploration and scheduling. Design Automation for Embedded Systems, Kluwer 
                51 
42. M. Gries, C. Kulkarni, C. Sauer, and K. Keutzer. Exploring trade-offs in performance and 
programmability of processing element topologies for network processors. In Second Workshop 
on Net- work Processors at the 9th International Symposium on High Performance Computer 
Architecture (HPCA9), Mar. 2003.  
43. T. Gr otker, S. Liao, G. Martin, and S. Swan. System Design with SystemC. Kluwer Academic 
Publishers, May 2002.  
44. M. Guthaus, J. Ringenberg, D. Ernst, T. Austin, T. Mudge, and R. Brown. MiBench: A free, 
commercially representative embedded benchmark suite. In IEEE 4th Annual Workshop on 
Workload Characterization, pages 3-14, Dec. 2001. 
45. Halambi, P. Grun, V. Ganesh, A. Khare, N. Dutt, and A. Nicolau. EXPRESSION: A language for 
architecture exploration through compiler/simulator retargetability. In Design, Automation and 
Test in Europe (DATE), pages 485-490, 1999.  
46. T. Harriss, R. Walke, B. Kienhuis, and E. Deprettere. Compilation from Matlab to process 
networks realized in FPGA. Design Automation for Embedded Systems, Kluwer, 7(4):385-403, 
Nov. 2002.  
47. Haubelt, J. Teich, K. Richter, and R. Ernst. System design for  
exibility. In Design, Automation and Test in Europe (DATE), pages 854-861, Mar. 2002.  
48. G. Hekstra, G. L. Hei, P. Bingley, and F. Sijstermans. TriMedia CPU64 design space exploration. 
In 1999 IEEE International Conference on Computer Design: VLSI in Computers and Processors, 
pages 599-606, 1999. 
49. Hoffmann, O. Schliebusch, A. Nohl, G. Braun, and H. Meyr. A methodology for the design of 
application specific instruction set processors (ASIP) using the machine description language 
LISA. In International Conference on Computer Aided Design (ICCAD), San Jose, CA, Nov. 
2001.  
50. J. Horn. Multicriterion decision making. In T. B ack, D. Forgel, and Z. Michalewicz, editors, 
Handbook of Evolutionary Computation. Institute of Physics Publishing, Bristol, UK, 1997.  
51. H. Hsieh, F. Balarim, L. Lavagno, and A. Sangiovanni-Vincentelli. Efficient methods for 
embedded system design space exploration. In 37th Design Automation Conference (DAC), 
pages 607-612, 2000.  
52. X. Hu, G. Greenwood, S. Ravichandran, and G. Quan. A framework for user assisted design 
space exploration. In 36th Design Automation Conference (DAC), pages 414-419, 1999.  
53. G. Kahn. The semantics of a simple language for parallel programming. In Proceedings of the 
IFIP Congress, pages 471-475. North-Holland Publishing Co., 1974.  
54. Karkowski and H. Corporaal. Design space exploration algorithm for heterogeneous 
multi-processor embedded system design. In 35th Design and Automation Conference (DAC), 
pages 82-87, 1998.  
55. V. Kathail, S. Aditya, R. Schreiber, B. R. Rau, D. Cronquist, and M. Sivaraman. PICO: 
automatically designing custom computers. IEEE Computer, 35(9):39-47, Sept. 2002. 48  
56. Kienhuis, E. Deprettere, K. Vissers, and P. van der Wolf. An approach for quantitative analysis of 
application-specific data 
ow architectures. In Application-Specific Systems, Architectures, and Processors (ASAP), July 
1997.  
57. Kin, C. Lee, W. Mangione-Smith, and M. Potkonjak. Power efficient mediaprocessors: design 
space exploration. In 36th Design Automation Conference (DAC), pages 321-326, 1999.  
58. E. Knuth. The Art of Computer Programming. Addison-Wesley, 3rd edition, 1997.  
59. S. Kobayashi, K. Mita, Y. Takeuchi, and M. Imai. A compiler generation method for HW/SW 
codesign based on configurable processors. IEICE Transactions on Fundamentals of Electronics, 
Communications and Computer Sciences, E85-A(12):2586-2595, Dec. 2002.  
60. Kohler, R. Morris, B. Chen, J. Jannotti, and M. F. Kaashoek. The Click modular router. ACM 
Transactions on Computer Systems, 18(3):263-297, Aug. 2000.  
61. C. Kulkarni, D. Moolenaar, L. Nachtergaele, F. Catthoor, and H. De Man. System level 
energy-delay exploration for multimedia applications on embedded cores with hardware caches. 
Kluwer Journal of VLSI Signal Processing, 22(1):45-57, Aug. 1999.  
                53 
heterogeneous programmable architectures. In International Symposium on System Synthesis, 
pages 256-261, Oct. 2001.  
81. P. Mishra, F. Rousseau, N. Dutt, and A. Nicolau. Architecture description language driven design 
space exploration in the presence of co-processors. In Tenth Workshop on Synthesis And System 
Integration of MIxed Technologies (SASIMI), Oct. 2001.  
82. P. Mishra, F. Rousseau, N. Dutt, and A. Nicolau. Coprocessor codesign for programmable 
architectures, ICS technical report 01-13. Technical report, University of California, Irvine, Apr. 
2001.  
83. Mohanty, V. K. Prasanna, S. Neema, and J. Davis. Rapid design space exploration of 
heterogeneous embedded systems using symbolic search and multi-granular simulation. In 
Workshop on Languages, Compilers, and Tools for Embedded Systems (LCTES), June 2002.  
84. F. Moya, J. Moya, and J. Lopez. Evaluation of design space exploration strategies. In 25th EU- 
ROMICRO Conference, volume 1, pages 472-476, Sept. 1999.  
85. O'Nils and A. Jantsch. Operating system sensitive device driver synthesis from implementation 
independent protocol specification. In Design, Automation and Test in Europe (DATE), pages 
562- 567, Mar. 1999.  
86. B. Ortega and G. Borriello. Communication synthesis for distributed embedded systems. In 
IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pages 437-444, Nov. 
1998. 50  
87. M. Palesi and T. Givargis. Multi-objective design space exploration using genetic algorithms. In 
Tenth International Symposium on Hardware/Software Codesign (CODES), pages 67-72, May 
2002.  
88. V. Pareto. Cours d'Economie Politique. F.Rouge, Lausanne, 1896.  
89. R. Passerone, J. A. Rowson, and A. Sangiovanni-Vincentelli. Automatic synthesis of interfaces 
between incompatible protocols. In Design Automation Conference (DAC), pages 8-13, June 
1998.  
90. Paulin, C. Pilkington, and E. Bensoudane. StepNP: a system-level exploration platform for 
network processors. IEEE Design & Test of Computers, 19(6):17-26, Nov. 2002.  
91. Pees, A. Hoffmann, and H. Meyr. Retargeting of compiled simulators for digital signal 
processors using a machine description language. In Design, Automation and Test in Europe 
Conference (DATE), pages 669-673, 2000.  
92. S. Pees, A. Hoffmann, V. Zivojnovic, and H. Meyr. LISA-machine description language for 
cycleaccurate models of programmable DSP architectures. In 36th Design Automation 
Conference (DAC), pages 933-938, June 1999.  
93. Peixoto and M. Jacome. Algorithm and architecture-level design space exploration using 
hierarchical data  
ows. In IEEE International Conference on Applications-Specific Systems, Architectures and 
Processors, pages 272-282, 1997.  
94. Peng and S. A. D. Gajski. Automatic model refinement for fast architecture exploration. In 
ASP-DAC/VLSI Design 2002, pages 332-337, Jan. 2002. 
95. Pimentel, L. Hertzberger, P. Lieverse, P. van der Wolf, and E. Deprettere. Exploring 
embeddedsystems architectures with Artemis. IEEE Computer, 34(11):57-63, Nov. 2001.  
96. Pimentel, S. Polstra, F. Terpstra, A. van Halderen, J. Co and, and L. Hertzberger. Towards 
efficient design space exploration of heterogeneous embedded media systems. In Embedded 
processor design challenges. Systems, architectures, modeling, and simulation - SAMOS, 
volume 2268 of LNCS, pages 57-73. Springer-Verlag, 2002.  
97. W. Qin and S. Malik. Architecture description languages for retargetable compilation. In Y. N. 
Srikant and P. Shankar, editors, The Compiler Design Handbook: Optimizations & Machine 
Code Generation. CRC Press, 2002.  
98. D. S. Rao and F. Kurdahi. Hierarchical design space exploration for a class of digital systems. 
IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 1(3):282-295, Sept. 1993.  
99. Richter, D. Ziegenbein, M. Jersak, and R. Ernst. Bottom-up performance analysis of HW/SW 
platforms. In Design and Analysis of Distributed Embedded Systems, IFIP 17th World Computer 
                55 
Microarchitectural exploration with Liberty. In 35th International Symposium on 
Microarchitecture (MICRO), pages 271-282, Nov. 2002. 52  
120. S. Wang, S. Malik, and R. Bergamaschi. Modeling and integration of peripheral devices in 
embedded systems. In Design, Automation and Test in Europe (DATE), pages 136-141, Mar. 
2003.  
121. S. J. Weber, M. W. Moskewicz, M. L ow, and K. Keutzer. Multi-view operation-level design - 
supporting the design of irregular ASIPs. Technical Report UCB/ERL M03/12, Electronics 
Research Laboratory, University of California at Berkeley, Apr. 2003.  
122. Wilson, D. L. Dill, and R. E. Bryant. Symbolic simulation with approximate values. In Third 
International Conference on Formal Methods in Computer-Aided Design, Nov. 2000.  
123. T. Wolf and M. Franklin. CommBench - A telecommunications benchmark for network 
processors. In IEEE International Symposium on Performance Analysis of Systems and Software 
(ISPASS), pages 154-162, Apr. 2000.  
124. S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. The SPLASH-2 programs: 
Characterization and methodological considerations. In 22nd International Symposium on 
Computer Architecture (ISCA), pages 24-36, June 1995.  
125. Ykman-Couvreur, J. Lambrecht, D. Verkest, F. Catthoor, A. Nikologiannis, and G. 
Konstantoulakis. System-level performance optimization of the data queueing memory 
management in highspeed network processors. In 39th Design Automation Conference (DAC), 
June 2002.  
126. S. Yoo, G. Nicolescu, D. Lyonnard, A. Baghdadi, and A. Jerraya. A generic wrapper architecture 
for multi-processor SoC cosimulation and design. In 9th International Symposium on 
Hardware/Software Codesign (CODES), pages 195-200, Apr. 2001.  
127. Zitzler, L. Thiele, M. Laumanns, C. M. Fonseca, and V. G. da Fonseca. Performance assessment 
of multiobjective optimizers: an analysis and review. IEEE Transactions on Evolutionary 
Computation, 7(2):117-132, Apr. 2003.  
128. Zivkovic, E. Deprettere, P. van der Wolf, and E. de Kock. Design space exploration of 
streaming multiprocessor architectures. In IEEE Workshop on Signal Processing Systems (SIPS), 
pages 228- 234, 2002.  
129. D. Zivkovic and P. Lieverse. An overview of methodologies and tools in the field of 
systemlevel design. In E. F. Deprettere, J. Teich, and S. Vassiliadis, editors, Embedded Processor 
Design Challenges: 2nd International Samos Workshop on Systems, Architectures, Modeling, 
and Simulation (SAMOS), number 2268 in LNCS, pages 74-88. Springer Verlag, 2002.  
130. http://www-cad.eecs.berkeley.edu/~polis/ 
131. http://ptolemy.eecs.berkeley.edu/ 
132. http://www-cad.eecs.berkeley.edu/Respep/Research/vis/index.html 
133. http://www.ics.uci.edu/~express/ 
134. http://www.ics.uci.edu/~aces/ 
135. M. Vachharajani, N. Vachharajani, D. Penry, J. Blome, and D. August, "Microarchitectural 
Exploration with Liberty," Proceedings of the 35th International Symposium on 
Microarchitecture, November, 2002. 
136. F. Balarin, Y. Watanabe, H. Hsieh, L. Lavagno, C. Passerone, A. Sangiovanni-Vincentelli, 
"Metropolis: An Integrated Electronic System Design Environment", Computer Magazine, April 
2003, p. 45-52 
137. P. Biswas, S. Pasricha, P. Mishra, A. Shrivastava, N. Dutt, A. Nicolau, “EXPRESSION User 
Manual version 1.0”, Feb 2003 
138. Ashok Halambi, Nikil Dutt and Alex Nicolau "Customizing Software Toolkits for Embedded 
Systems-On-Chip", DIPES 2000 
139. V. Zivojnovic et al. “LISA - machine description language and generic machine model for 
HW/SW co-design. In VLSI Signal Processing”, 1996. 
140. M. Freericks. “The nML machine description formalism.” TR SM-IMP/DIST/08, TU Berlin, 
1993. 
141. George Hadjiyiannis , Silvina Hanono , Srinivas Devadas, “ISDL: an instruction set description 
                57 
142(1):65-71, Jan. 1995.  
166. G. Ascia, V. Catania, and M. Palesi. Design space exploration methodologies for IP-based 
system-on-a-chip. In IEEE International Symposium on Circuits and Systems, volume 2, pages 
364-367, May 2002.  
167. G. Ascia, V. Catania, and M. Palesi. A framework for design space exploration of parameterized 
VLSI systems. In ASP-DAC/VLSI Design 2002, pages 245-250, Jan. 2002.  
168. M. Auguin, L. Capella, F. Cuesta, and E. Gresset. CODEF: a system level design space 
exploration tool. In 2001 IEEE International Conference on Acoustics, Speech, and Signal 
Processing, volume 2, pages 1145-1148, 2001.  
169. Axelsson. Architecture synthesis and partitioning of real-time systems: a comparison of three 
heuristic search strategies. In 5th Int. Workshop on Hardware/Software Codesign 
(CODES/CASHE), pages 161-165, Mar. 1997.  
170. Baghdadi, N. Zergainoh, W. Cesario, T. Roudier, and A. Jerraya. Design space exploration for 
hardware/software codesign of multiprocessor systems. In 11th International Workshop on Rapid 
System Prototyping (RSP), pages 8-13, 2000. 45  
171. F. Balarin, M. Chiodo, P. Giusto, H. Hsieh, A. Jurecska, L. Lavagno, C. Passerone, A. 
Sangiovanni- Vincentelli, E. Sentovich, K. Suzuki, and B. Tabbara. Hardware-Software 
Co-Design of Embedded Systems: The Polis Approach. Number 404 in International Series in 
Engineering and Computer Science. Kluwer Academic Publishers, 1997.  
172. F. Balarin, Y. Watanabe, H. Hsieh, L. Lavagno, C. Paserone, and A. Sangiovanni-Vincentelli. 
Metropolis: an integrated electronic system design environment. IEEE Computer, 36(4):45-52, 
Apr. 2003.  
173. T. Blickle, J. Teich, and L. Thiele. System-level synthesis using evolutionary algorithms. 
Design Automation for Embedded Systems, Kluwer Academic Publishers, 3(1):23-58, Jan. 1998.  
174. S. Blythe and R. Walker. Toward a practical methodology for completely characterizing the 
optimal design space. In 9th International Symposium on System Synthesis, pages 8-13, Nov. 
1996.  
175. S. Blythe and R. Walker. Effcient optimal design space characterization methodologies. ACM 
Transactions on Design Automation of Electronic Systems, 5(3):322-336, July 2000.  
176. D. Burger and T. M. Austin. The Simple Scalar tool set, version 2.0. Technical Report 1342, 
Computer Sciences Department, University of Wisconsin-Madison, June 1997.  
177. Cai, D. Gajski, and M. Olivarez. Introduction of system level architecture exploration using the 
SpecC methodology. In IEEE International Symposium on Circuits and Systems, volume 5, 
pages 9-12, May 2001.  
178. Cai, S. Verma, and D. D. Gajski. Comparison of SpecC and SystemC languages for system 
design. Technical Report CECS 03-11, University of California, Irvine, May 2003.  
179. K. Chatha and R. Vemuri. An iterative algorithm for hardware-software partitioning, hardware 
design space exploration and scheduling. Design Automation for Embedded Systems, Kluwer 
Academic Publishers, 5(3-4):281-293, Aug. 2000.  
180. S. Chaudhuri, S. Blythe, and R. Walker. A solution methodology for exact design space 
exploration in a three-dimensional design space. In IEEE Transactions on Very Large Scale 
Integration (VLSI) Systems, volume 5, pages 69-81, Mar. 1997. 46  
181. B. De Smedt and G. Gielen. WATSON: a multi-objective design space exploration tool for 
analog and RF IC design. In IEEE 2002 Custom Integrated Circuits Conference, pages 31-34, 
2002.  
182. R. P. Dick and N. K. Jha. MOCSYN: Multiobjective core-based single-chip system synthesis. 
In Design, Automation and Test in Europe Conference (DATE), pages 263-270, 1999.  
183. A. Fauth, J. Van Praet, and M. Freericks. Describing instruction set processors using nML. In 
European Design and Test Conference (ED&TC), pages 503-507, Mar. 1995.  
184. W. Fornaciari, D. Sciuto, C. Silvano, and V. Zaccaria. A design framework to efficiently explore 
energy-delay tradeoffs. In Ninth International Symposium on Hardware/Software Codesign 
(CODES), pages 260-265, 2001.  
185. W. Fornaciari, D. Sciuto, C. Silvano, and V. Zaccaria. A sensitivity-based design space 
                59 
205. D. Lanneer, J. Van Praet, A. Kii, K. Schoofs, W. Geurts, F. Thoen, and G. Goossens. CHESS: 
Retargetable code generation for embedded DSP processors. In P. Marwedel and G. Goossens, 
editors, Code Generation for Embedded Processors, volume 317 of SECS, pages 85-102. Kluwer 
Academic Publishers, 1995.  
206. C. Lee, M. Potkonjak, and W. Mangione-Smith. MediaBench: a tool for evaluating and 
synthesizing multimedia and communications systems. In Thirtieth Annual IEEE/ACM 
International Symposium on Microarchitecture, pages 330-335, Dec. 1997.  
207. A. Lee. Overview of the Ptolemy project. Technical Report UCB/ERL M03/25, University of 
California, Berkeley, July 2003.  
208. R. Leupers and P. Marwedel. Retargetable code generation based on structural processor 
descriptions. Design Automation for Embedded Systems, Kluwer Academic Publishers, 
3(1):1-36, Jan. 1998.  
209. R. Leupers and P. Marwedel. Retargetable Compiler Technology for Embedded Systems - Tools 
and Applications. Kluwer Academic Publishers, Oct. 2001.  
210. C. Liem and P. Paulin. Compilation techniques and tools for embedded processor architectures. 
In J. Staunstrup and W. Wolf, editors, Hardware/Software Co-Design: Principles and Practise. 
Kluwer Academic Publishers, 1997.  
211. Lieverse, P. van der Wolf, and E. Deprettere. A trace transformation technique for 
communication refinement. In Ninth International Symposium on Hardware/Software Codesign 
(CODES), pages 134-139, 2001.  
212. Lieverse, P. van der Wolf, K. Vissers, and E. Deprettere. A methodology for architecture 
exploration of heterogeneous signal processing systems. Kluwer Journal of VLSI Signal 
Processing, 29(3):197-207, Nov. 2001.  
213. A. Mihal, C. Kulkarni, K. Vissers, M. Moskewicz, M. Tsai, N. Shah, S. Weber, Y. Jin, K. 
Keutzer, C. Sauer, and S. Malik. Developing architectural platforms: A disciplined approach. 
IEEE Design & Test of Computers, 19(6):6-16, 2002.  
214. Mishra, N. Dutt, and A. Nicolau. Functional abstraction driven design space exploration of 
heterogeneous programmable architectures. In International Symposium on System Synthesis, 
pages 256-261, Oct. 2001.  
215. P. Mishra, F. Rousseau, N. Dutt, and A. Nicolau. Architecture description language driven 
design space exploration in the presence of co-processors. In Tenth Workshop on Synthesis And 
System Integration of MIxed Technologies (SASIMI), Oct. 2001.  
216. P. Mishra, F. Rousseau, N. Dutt, and A. Nicolau. Coprocessor codesign for programmable 
architectures, ICS technical report 01-13. Technical report, University of California, Irvine, Apr. 
2001.  
217. Mohanty, V. K. Prasanna, S. Neema, and J. Davis. Rapid design space exploration of 
heterogeneous embedded systems using symbolic search and multi-granular simulation. In 
Workshop on Languages, Compilers, and Tools for Embedded Systems (LCTES), June 2002.  
218. M. Palesi and T. Givargis. Multi-objective design space exploration using genetic algorithms. In 
Tenth International Symposium on Hardware/Software Codesign (CODES), pages 67-72, May 
2002.  
219. V. Pareto. Cours d'Economie Politique. F.Rouge, Lausanne, 1896.  
220. Paulin, C. Pilkington, and E. Bensoudane. StepNP: a system-level exploration platform for 
network processors. IEEE Design & Test of Computers, 19(6):17-26, Nov. 2002.  
221. Pees, A. Hoffmann, and H. Meyr. Retargeting of compiled simulators for digital signal 
processors using a machine description language. In Design, Automation and Test in Europe 
Conference (DATE), pages 669-673, 2000.  
222. S. Pees, A. Hoffmann, V. Zivojnovic, and H. Meyr. LISA-machine description language for 
cycleaccurate models of programmable DSP architectures. In 36th Design Automation 
Conference (DAC), pages 933-938, June 1999.  
223. W. Qin and S. Malik. Architecture description languages for retargetable compilation. In Y. N. 
Srikant and P. Shankar, editors, The Compiler Design Handbook: Optimizations & Machine 
Code Generation. CRC Press, 2002.  
                61 
Systems,Vol. 12,No. 1, Article 8, Publication date: January 2007 
244. 洪秋韻, " A Verification Platform for SoC Bus Interface" 逢甲大學資訊工程學系碩士論文, 
2005 
245. 蔡幸娟, " VLSI Implementations of a 2-D DCT/IDCT Architecture" 逢甲大學資訊工程學系
碩士班碩士論文, 2005 
246. 蔡紫蕾, " Software-Based Self-Test for a Processor Core" 逢甲大學資訊工程學系碩士論文, 
2005 
247. 石博元, "Implementations of a Customizable Embedded CPU and Its Development Tools " 逢
甲大學資訊工程學系碩士班碩士論文, 2004. 
248. Jiying Wu et al. A Design Methodology for Application-Specific Instruction-set Processors with 
Memory Access Considerations. In 18th VLSI Design/CAD Symposium, August, 2007 in 
Hualien, Taiwan 
249. 林祺傑, "在硬體限制考慮下使用特殊應用指令改進效能"逢甲大學資訊工程學系碩士班碩
士論文, 2007 
250. 吳季穎, "使用特定應用指令集處理器減少記憶體存取"逢甲大學資訊工程學系碩士班碩士
論文, 2007 
251. Shengjyi Yang, Chijie Lin, Chiu Yun Hung, Jiying Wu, Yiwen Wang. Application-Specific 
Instruction Generation for SOC Processors. ISCAS, 2007 
252. Shengjyi Yang et al. Automatic Application-Specific Instruction Generation. In 17th VLSI 
Design/CAD Symposium, August, 2006 in Hualien, Taiwan 
253. 楊勝吉, " 特殊應用指令自動化產生" 逢甲大學資訊工程學系碩士論文, 2006  
254. 張家維, " 應用程式到多處理器架構設計流程" 逢甲大學資訊工程學系碩士論文, 2006 
                63 
                 65 
對 SOC Design 技術、應用的現況、未來研究做討論，以及探討目前面臨的挑戰。整體而言這次的學術研討會圓
滿成功。 
 
三、 攜回資料名稱及內容  
z 有關 IEEE Circuits and Systems Society Newsletter,  Wireless Pervasive Computing 與 ISCAS 
2008 的宣傳資料 
z Proceedings of 2007 IEEE International Symposium on Circuits and Systems 
basic instruction count. An ASI candidate is defined as a set 
of templates which are isomorphic equivalent to each other. 
∑
∈
≤
CEc
cc NHWSHWMAX *))(((   for each c ε CE, is our 
additional constraint. We call MAX(HWc(S)) the maximal 
hardware cost which is the additional computing elements in 
S. C is an index of total computing elements. HWc is the 
computing element cycle counts, assuming as 1. The user-
defined value N indicates the maximal counts of application-
specific instructions. Therefore, our problem becomes to 
choose ASI from ASI candidates such that the performance 
can be improved and various constraints be satisfied.  
B. Overview 
Figure 1 illustrates the overall flow of ASI generation. 
We divide the flow into two phases. At the first phase, we 
use SUIF [8] to transfer an application program which 
written in C language into CDFG. Then, the CDFG are 
profiled in order to get the execution frequency of each basic 
instruction. At the second phase, we will generate and select 
ASI and then evaluate the performance of the application 
program with ASI. 
 
Figure 1.  The design flow of generation application- specific instruction 
The C code will be translated into SUIF Virtual Machine 
(SUIFvm) IR. The opcodes of the SUIFvm library are 
architecture independent. Next, the Machine-SUIF 
transforms the SUIFvm IR to CFG format. We have used the 
HALT library of the Machine-SUIF for profiling the CDFG. 
In addition, some operators - multiplier, divider, floating 
point multiplier and floating point divider – are set with 
different processor cycles counts in order to show their 
computing overhead. 
In Template Generation, ASI templates are generated 
from DFGs. A template could be implemented as 
application-specific instructions. Then, the Candidate 
Instruction Building generates ASI candidates from ASI 
templates. In an application program, there may be some 
alike ASI templates spread everywhere. These identical ASI 
templates are combined to a candidate. These generated 
candidates will be selected by a heuristic algorithm. Finally, 
the generated application-specific instructions will replace 
the original instructions. 
C. Template Instruction Generation 
At this step, templates are generated to satisfy the given 
constraints. The user specifies the number of input/output 
ports in the experimental processor. We assume each 
generated application-specific instructions is executed in one 
processor clock, ex. MUL or DIV.  
Figure 2 shows the flow of template instruction 
generation. We first check if this instruction is a 
load/store/branch instruction or not. Because application-
specific instructions contain those types of instruction still 
cost the memory access time, including them may not reduce 
execution time. Therefore, we will not cluster these types of 
basic instruction into ASI. We examine each node in the 
DFG and use it as a seed for template generation. This seed 
is grown backward along dataflow edges to produce a new 
template. 
 
Figure 2.  The flow of template instruction generation 
 
Figure 3.  Data flow graph 
Some templates that are violating the output port 
constraint may be generated. The generated templates will be 
the input of others template generation. If the template 
violates the output port constraint at this time, it may be valid 
by combined with a new seed node. As figure 3, if we 
