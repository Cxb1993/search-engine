 2
whole system. 
 
For the issues of the component 
optimization in the grid computing 
environment, we had discussed two 
appiled of the environment. First, we 
consider the load-balancing schedling 
problem of the grid computing 
environment. For example, the stateful 
invocation requires the same server to 
keep the execution state and serve it. In 
the stateless invocation, server need not 
keep any states of previous calls. However, 
we proposed a scheduling algorithm for 
different invocations. We also plan to 
implement it onto a high performance IXP 
network processor platform. the 
scheduling policy can be examed in the 
platform. 
 
Second, we also discussed the popular 
issue of network streaming transmission in  
remote object environment. We designed 
three automatic processing mechanisms 
for data streaming, because of the lacking 
of streaming abilty in remote object 
environment. We proposed the pushing, 
aggregation and forwarding mechanisms 
to improve the performance of streaming 
and requirment of automatic processing. 
the pushing is used to attach the streaming 
ability to the traditional remote object, and 
the bandwidth requirement of client will 
be met by several streaming servers by the 
aggregation mechanism. Last, the 
forwarding mechanism is used to improve 
the whole streaming system bandwidth by 
transfering the streaming resource of 
clients. 
 
In this project, we will develop the 
scheduling policy and data streaming 
mechanisms in the remote object 
enviroment. All the research results will 
make a improvement in the component 
management system and run-time 
optimization.   
 
 
Keywords: Grid computing,Java 
RMI, .NET Remoting Load balancing, 
Network processor, Streaming 
 
 
二、緣由與目的 
 
  
由於網路頻寬品質大幅進步，遠超
越電腦效能提升的進展，使得分散式計
算環境成為熱門的研究發展主流。人們
對於運算資源的需求日增，同時間還有
許多閒置的電腦存在於網際網路上，等
著 被 開 發 利 用 ， 而 格 網 運 算 (Grid 
computing)則是將這些被閒置的運算能
力集結起來，提供大量的運算能力。格
網運算的概念即是以計算力比擬為電
力，超級電腦比擬為發電廠，網路即為
傳輸計算力的線路，而 Grid 一詞即借用
傳輸電力使用的電力線 (Power Grid)，
我們期望它使用起來就像使用電器一
樣，只要將插頭插上插座，即有源源不
絕的電力送來，如同使用電力一般方便
取來運算能力。 
 
    本項計畫的主要目的就是利用遠端
元件呼叫來建構格網運算環境並規劃制
定出一套軟體元件間可共同遵守的規
範，使得程式能夠依循本身的需求，不
僅僅是在編譯時期能善用高品質的元
件，同時在執行時期，也能夠動態地在
廣大的網際網路間，尋找出特定時間的
最適元件來使用，以期增進程式執行效
能，我們已有一些初步規範，但要讓程
式間能夠快速而簡單地動態重覆使用分
散式元件，還需要更完整且詳細的規則
來輔助，此點正是我們急欲開發的目標。 
 
在本計畫中先初步針對格網運算中
熱門的應用提出相關的機制探討。對於
伺服器的建構我們提出負載平衡的解決
方法，可利用網路處理器來解決高流量
的處理問題，並且可以針對不同的遠端
元件呼叫狀態來提出解決的方法。此外
除了傳統的伺服器環境，隨著網路串流
資訊的應用越來越廣，我們也整合了網
路串流資訊在遠端元件呼叫的處理方
式，利用我們所提出的機制以求達到整
體頻寬的最大使用效率，上述兩項技術
可配合我們所研發的動態執行時期元件
 4
個不同的機制：Pushing，Aggregation 和
Forwarding 等，並且規劃一個軟體架構來
支援串流資訊的傳輸(圖五、六) 
 
 
圖五 
 
 
圖六 
而各元件負責不同的功能如下： 
 
z Stub：Stub 由 Java 自動的產生，為了
對 Stub 作修改，利用反組譯由 rmic 所
產生的類別檔(class file)來取得相關的
資訊，並在裡面加上許多功能，使其
能和多個伺服器端同時做串流的連
線，並且和 Streaming Controller 溝通。 
z Streaming Controller：和 Stub 作溝
通，接收來自 Stub 傳過來資料，經過
分析來決定把這次的呼叫由一對ㄧ變
成一對多來提高效能，或則直接從本
地端的 buffer 擷取已經存在的資料。
Streaming Controller 也負責協調每個
伺服器要如何傳遞資料到客戶端，並
且匯集 Continuous Buffer 裡的資料，
經過適當的處理和把完整的資料存到
Streaming Buffer。 
z Streaming Buffer：在我們的架構裡
面，Streaming Buffer 只存在客戶端，
Streaming Buffer 負責儲存客戶端所
需的資料。一個 RMI 串流客戶端可能
會 從 多 個 伺 服 器 端 接 收 資 料 ，
Streaming Controller 知道如何接收這
些資料並且經過處理把完整的資料存
到 Streaming Buffer。 
z Continuous Buffer：Continuous Buffer
是成對在客戶端和伺服器端出現，
Continuous Buffer 在伺服器端不斷的
送出資料到相對應的 Continuous 
Buffer，在客戶端的 Continuous Buffer
是不斷的接收所傳過的資料。 
z Loader：在標準 Java RMI 架構裡，伺
服器是被動的回應客戶端的要求，為
了提高效能，串流的 RMI 伺服器端必
需主動把資料送往客戶端，為了達成
這個目標，我們添加 Loader 元件，它
會 週 期 性 地 把 串 流 資 料 載 入 到
Continuous Buffer 裡 ， 然 後 利 用
Continuous Buffer 把資料送到客戶端。 
 
我們也針對不同的串流傳輸需求設計
一演算法，利用下列的公式來計算各伺服
器的權重(weight)，可以使用三個不同的參
數（α、β和γ係數）來調整出最適合目
前網路環境的傳輸公式。 
 
 
 
我們一提出相關的模擬實驗來驗證其
演算法的效能（圖七、八、九），目前此一
部分之成果已發表於國際學術研討[2]。 
 
