 2
早期工程圖並未電子化，在各政府機關或公司庫存著非常多的工程圖，其數
位化是件相當大的工程，而在數位化過程中如果以最有效率的方式來儲存在應用
上所需的特徵是一個相當重要的關鍵。 
工程圖影像的線特徵萃取，一直是影像自動檢測系統、圖像識別系統，以及
影像資料向量化系統的重要步驟。但是，隨著精確度與處理速度的要求日益提
高，如何從工程圖影像中萃取出線特徵，構建點與線的幾何資料，再以高效率的
結構來儲存，是一項極為重要的課題。本研究計畫希望根據工程圖之特性在影像
二值化、細化及線特徵萃取能有一連慣之研究，以利後續圖像辨識及向量化的高
效率運用。因此本研究的主要的目的，從影像掃瞄到將灰階影像轉換為二值化影
像、影像清繪與整理、細化處理、線萃取及線形態補正的整個流程上有更深入且
完整的研究及系統實作，並整合成一個部份半自動的系統。 
 
文獻探討 
影像二值化相關技術研究 
 
影像二值化是影像分割的重要課題，近年來有為數眾多的研究，提出各種方
法[1]，包含 
(1) 臨界值法：藉由統計影像的灰階範圍來做分析比較，選擇適當的臨界
值，將物體和背景分隔出來的方法，大都應用在灰階影像。 
(2) 邊界法：將影像進行梯度向量法、拉普拉斯等運算處理，強化邊緣後找
出描述物體的封閉曲線，進行影像分割。 
(3) 區域成長法：利用區域具有的灰階值、紋理等同質性，先在影像的某一
點作為起點，再向其周圍尋找相似點並將其歸納為同一群集。 
(4) 混合法：結合使用上述方法以改進影像分割成果，例如整合區域成長法
與邊界法時，首先利用細分及合併演算分割影像為多數區域，再利用區
域輪廓的邊緣資訊加以調整。 
(5) 圖形結構：將影像中的像點(Pixel)視為節點，像點間的相鄰特性為連
接節點的邊，影像分割也就是在權值最小的原則下切割圖形為多個子圖
形。 
Lawrence [2]提出先量測直方圖中縱向及橫向灰階強度，再利用小範圍的滑
動框計算變異數，取得區域的平坦程度等局部資訊，最後再決定出整體臨界值的
數量，這種利用局部的連接資訊改善整體臨界值法，是臨界值法的一種整合應
用。當影像品質不佳、背景具有紋理或是內容兼具圖形與文字之複雜狀況時，更
需要使用混合臨界值模式，將影像的像點區分為物體及背景。 
J. Sauvola 等 人 [3] 將 各 種 臨 界 值 方 法 分 類 為 ： 多 重 臨 界 值
(Multi-threshold)、單一臨界值(Single threshold)、局部臨界值(Local 
threshold)、整體臨界值(Global threshold)，四種分類的第一個字母組合成
MSLG 方法，在不同影像來源的實際應用中，M,S,L,G 可以被組成(ML),(SL),(MG)
及(SG)等混合模式，進行影像二值化作業。傳統的局部臨界值法，通常將影像切
割細分為多個小影像，再逐一進行處理。Yibing Yang 等人[4]及 Mansuo Zhao
等人[5]則是在每一個像點都適應性計算出一個臨界值，適應性的計算方法，是
依據該像點的鄰接灰階值的強度與位置，再與像點為中心的某一範圍內的平均值
比較。由於方法[4]主要在處理以印刷文字為主的影像，方法[5]則是偏重在處理
 4
景像點，並迭代進行直到沒有異動為止。這個方法可以應用在經常有封閉輪廓的
字元辨識。 
Ahmed＆Ward[23] 將旋轉不變(Rotation invariant)的特性，進行影像細化
處理時，利用物件特徵予以分類，在各分類下再檢查多個不同的 3×3 細化規則，
進行字元及中文的細化。Rockett[24]是利用圖結構的折點連接定義，以及折點
的鄰接陣列等方式，提出了改良 Ahmed＆Ward[16]的方法。Patil 等人[25]也在
2005 年針對 Ahmed＆Ward[23]的方法，提出適用在指紋辨識及符號的演算法，利
用 21 個 3×3 的細化規則，以及 4 個斜線規則，使得只有一個像點寬的指紋紋路
位於線中央，而且沒有因細化而斷裂；另外的 24 個偵測紋路分叉點(Ridge 
bifurcation)的規則，更可去除錯誤的分叉點，強化指紋辨識的應用領域。而近
年來細化技術的研究也非常多，如 2008 Meghoufel 等人[26]利用一維及二維
Shock filter 來做超音波影像的細化。2008 Yang 等人[27]提出利用計算七個
templates 的權重，再進一步使用二個 templates 針對二個像素點的線來做細
化。而在線圖影像有 2008 Zhao 等人[28]提出利用型態學來做細化的研究。 
線特徵萃取之相關研究 
Bachnak＆Celenk[29]將細化後的二值化影像進行彎角偵測，逐一比對所有
物件像點為中心的 3×3 模型(Templates)，若 8 相鄰中至少有 3 個物件像點時為
候選彎角，須再進一步判斷確認後，記錄彎角的幾何資訊。接下來，再建立彎角
間的物件像點，取得直線的位相性質，以完整的表示 2-D 影像。 
Venkateswar＆Chellappa[30]將精簡邊緣偵測 (Canny edge detector)處理
後的邊緣影像(Edge image)，由左而右上而下(LRTB)依序掃瞄，將位於同一多邊
形線上的邊緣像點，標註相同的線編號，利用空間索引串連出多邊形。 
Chiang[31]利用迭代程序找尋線段的最大內切圓，再用端點最大內切圓(MIC)
的直徑計算線段的寬度，線邊沿點與直徑垂直方向則可計算出線段的斜率，進而
取得線段的中心像點，完成線影像向量化作業。 
Haron 等人[32]從已經完成影像二值化、細化及數位化處理，而且已被編碼
為八鄰接的多邊形鏈碼影像中，取得每段編碼的斜率，分析出彎角的像點坐標位
置。 
 
參考文獻 
[1] Ety Navon, Ofer Miller, Amir Averbuch, “Color image segmentation based on 
adaptive local thresholds”,Image and Vision Computing 23 (2005) 69-85. 
[2] Lawrence O’Gorman, “Binarization and Multithresholding of Document Images 
Using Connectivity”, CVGIP: Graphical Models and Image Processing Vol.56, 
No.6, November, pp.494-506, 1994. 
[3] J. Sauvola, M. Pietikainen, “Adaptive document image binarization”,Pattern 
Recognition 33(2000) , pp. 225-236. 
[4] Yibing Yang, Hong Yan, “An adaptive logical method for binarization of 
degraded document images”, Pattern Recognition 33 (2000), pp. 787-807. 
[5] Mansuo Zhao, Yibing Yang, Hong Yan, “An adaptive thresholding method for 
binarization of blueprint images”, Pattern Recognition Letters 21 (2000), pp. 
927-943. 
[6] Weian Deng, S. Sitharama Iyengar, Nathan E. Brener, “A Fast Parallel Thinning 
Algorithm For The Binary Image Skeletonization”,The International Journal of 
 6
Journal of High Performance Computing Applications. vol.14, no.1, pp. 65-81, 
2000.   
[22] Lei Huang, Genxun Wan and Changping Liu, “ An Improved Parallel Thinning 
Algorithm”, Proceedings of the Seventh International Conference on Document 
Analysis and Recognition (ICDAR’03). 
[23] Maher Ahmed and Rabab Ward, “A Rotation Invariant Rule-Based Thinning 
Algorithm for Character Recognition”, IEEE Transactions on Pattern Analysis 
and Machine Intelligence, vol. 24, no.12, pp. 1672-1678, 2002. 
[24] Peter I. Rockett, “An Improved Rotation-Invariant Thinning Algorithm”, IEEE 
Transactions on Pattern Analysis and Machine Intelligence, vol. 27, no. 10, 
pp.1671-1674, 2005. 
[25] Pradeep M. Patil, Shwkar R. Suralkar and Faiyaz B. Sheikh, “Rotation Invariant 
Thinning Algorithm to Detect Ridge Bifurcation”, Proceedings of the 17th IEEE 
International Conference on Tools with Artificial.(ICTAI’05). 
[26] Meghoufel, A. Cloutier, G. Crevier-Denoix, N. De Guise, J.A. “A Thinning 
Algorithm for Equine Tendon Structure Ientification from 2D Ultrasound 
Images, ”  Proc. of  the 5th IEEE International Symposium on Biomedical 
Imaging: From Nano to Macro, pp.1565 – 1568, 14-17 May 2008. 
[27] Yang, Xingwei; Bai, Xiang; Yang, Xiaojun and Liu, Wenyu “An Efficient 
Quick Thinning Algorithm,”  Proc. of 2008 Congress on Image and Signal 
Processing, Volume 3, pp.475 – 478, 27-30 May 2008. 
[28] Zhao, Jingxiu; Li, Xinghua and Chong, Feng “Abstract Line Drawings from 2D 
Images Based on Thinning,” Proc. of 2008 Congress on Image and Signal 
Processing, pp.466 – 470, 27-30 May 2008. 
[29] Rafic Bachnak and Mehmet Celenk, “A Corner Detection-Based Object 
Representation Technique for 2-d Images”. Proceedings of the IEEE International 
Symposium on Intelligent Control, pp.186-190, 1988. 
[30] V. Venkateswar and Rama Chellappa, “Extraction of Straight Lines in Aerial 
Images”, IEEEE Transactions on Pattern Analysis and Machine Intelligence, 
vol.14, no.11, pp. 1111-1114, 1992. 
[31] John Y. Chiang, “A New Approach for Binary Line Image Vectorization”, IEEE 
International Conference on Systems, Man and Cybernetics, vol. 2, pp.1489-1494, 
1995. 
[32] Habibollah Haron, Siti Mariyam Shamsuddin and Dzulkifli Mohamed, “A New 
Corner Detection Algorithm for Chain Code Representation”, International 
Journal of Computer Mathematics, vol. 82, no. 8, pp. 941–950, 2005. 
 
研究方法 
本研究計畫目的希望整合 SLG 混合模式，先利用一個整體臨界值快速過濾背
景像點，再採用適應性局部臨界值法，加入多種線形樣式進行細線特徵偵測，並
以多階層動態計算方式，補強每一像點的臨界值計算規則，高效率與高正確性的
進行工程圖灰階影像的二值化。希望能研究對各種不同類別的工程圖灰階影像，
都可以獲得良好的品質，特別是在容易遺失資訊之細線，獲得良好的結果。 
接著對二值化影像的線細化，本研究將考慮比較各種方法例如使用骨架化
(Skeletonization) 等方法，將二值化影像的線細化。希望將影像中的物件，細
化成為一個像點寬度的線條，而且必須保留二值化影像的所有圖形結構性資訊，
例如線條的位置、方向和長度。 
 8
色）；圖三右圖正中央的處理像點（R2,C2）灰階值為 202，也應為物體（黑色），
使用方法[4]及方法[5]，也是一樣會錯誤歸類為背景（白色）。這種錯誤的結果，
雖然僅僅只是一個像點的錯誤分類，但是會導致線斷裂以及線交叉的關連破壞，
使得後續使用二值化影像的細線化及特徵辨識作業遭遇困難。 
    
圖三  1個像點寬度交叉線。 
 
解決方法[5]在細線及線交叉點，物體辨識會發生錯誤的問題，必須利用線
的鄰接特性，正確判斷處理中的像點應分類為物體或背景。 
一開始作業時，自動分析直方圖的灰階最小值、灰階最大值、平均值、變異
數，再將上述各項參數比對已經建立的經驗數值，以分類工程圖影像（原稿是否
彩色、是否藍晒、是否有紋理、手繪或印刷），以取得該分類的整體臨界值的參
數、動態局部臨界值參數α、可以調整臨界值的範圍△Ｔ。 
整體臨界值 T1 是為了提昇處理效率所加入的方法，經過分析各類工程圖可
以發現，物體與背景所佔像點的比例極為懸殊，也就是說物體點的灰階值都集中
在灰階值較低的一端，只要依據影像圖的類別，就可以設定出一個整體性的臨界
值 T1（介於灰階平均值與灰階最大值之間）。只要灰階值大於 T1 的像點，可以
直接判定為背景；灰階值小於等於 T1 時，再利用局部臨界值來處理。這樣可以
避免將所有像點都去比對 C形臨接以及直線樣式，大幅提高作業速度。細化流程
圖如圖四所示。 
 
 
 10
樣就可以將大部分斷開的線連接起來，消除小缺口及小洞。不過，在進
行這項閉合處理時，膨脹時的像點寬度不能設得太大，否則有可能將距
離很近的平行細線給修補成粗線。 
 
細化研究 
本研究的線細化處理構想是首先利用 Wu＆Tsai[20]的方法，由上而下由左
而右，逐一掃瞄物件像點，找到物件像點時將其相鄰像點進行圖七的 14 個模型
的比對，若是符合任一模型時，即將物件像點標註刪除。掃瞄完所有的像點後，
將被標註為刪除的物件像點清除為背景，並進行下一次的迭代作業，直到沒有像
點被標註刪除為止。 
圖五是一張 9×9 的二值化影像，塗色的格點表示物件，空白的格點表示背景
像點。最左側的圖(a)是細化前，圖(b)則是 Wu＆Tsai[20]細化後的結果。如同
Deng 等人[21]所提出的問題，Wu＆Tsai[20]的方法，在凹型像點時會有多餘的
物件像點被保存，例如圖五(c)深色塗色標示出的(col4,row3)、(col3,row4)、
(col5,row4)等三個像點，在圖五(b)的相同位置上仍有網線，表示 Wu＆Tsai[20]
無法清除這類的凹型像點。圖五(d)表示本研究所期望達成的最後結果，除了上
述凹型像點之外，還有圖五(c)標示出-及*記號的像點須處理。 
      
(a)          (b)         (c)         (d)  
圖五  9×9影像細化實例(a) 細化前  (b) 細化後  (c) 處理前   (d) 期望結果 
Deng 等人[21]的方法在每次的迭代中，掃瞄的像點只要符合(a)-(n) 模型
之一時，將像點清除為背景時，就須判斷模型類別是否屬於(a)-(f)及(h),(i)
等八種模型，接著再依各類別的條件式檢查鄰接像點，將符合條件的候選凹型像
點加入標示陣列之中，完成每次的迭代後再比對＂候選凹型像點標示陣列＂，清
除其中的凹型像點。本研究初步構想提出的解決方法，是在完成 Wu＆Tsai[20]
方法的細化之後，再另外執行一次迭代，由上而下由左而右掃瞄細化後的物件像
點，將該像點的 8 鄰接特徵，比對圖六(a)的凹型像點模型，若是符合任一個可
旋轉方向的凹型像點模型，則判定該處理中的物件像點必須立即予以清除。本研
究的想法，由於只要在完成 Wu ＆ Tsai[20] 方法的細化之後進行唯一的一次掃
瞄，又不須額外的陣列空間，條件判斷式的運算量又低，因此，處理速度較快。 
 12
表一  節點陣列(Pnodes)  
 
表二 線串陣列(Larcs)  
 
本研究計畫提出的的線特徵萃取方法，可分為兩個步驟，第一個步驟是建立
弧點資料模式；第二個步驟是修正弧點資料內容。弧點資料模式是將上一個階段
的線細化成果，利用鄰接關係將物件像點，串接出向量式資料模式的節點和線
串。節點包含了端點及交叉點，如＂表一＂所示；線串的兩端為節點中間為折點
串列，線串之間不可以相跨越，如＂表二＂所示。採用弧點資料模式，不僅可以
快速地組成線特徵，儲存點及線的位相紀錄，更可提供彈性的資料維護能力，提
供強固穏定的向量化加值應用。希望演算法能有效地將圖七(a)所有必須修正的
像點作修正，如標示於圖七(b)的三個黑色位置。 
 
線形態補正之相關技術研究 
在萃取線形態補正程序本研究計畫初步想法是利用線條約化模式，先自訂一
個容忍值（tolerance），以計算不同詳細度之線約化成果。最簡單可行的線條約
化演算法是計算線串內各折點到起點與終點連線的垂距，當垂距小於容忍值時，
則刪除該折點。重複該步驟，直至所有線串的節點都全部完成為止。除了上述的
線形態補正，也可以考慮曲線的擬合，讓原本為彎曲形態的線能經過計算，擬合
成為單曲線或是複曲線，讓折點能較平滑。 
另外，從弧點資料結構之中，就能夠據以判斷出線串的起始與終止節點的形
態，當形態是端點而不是交點時，表示該節點是虛懸節點（Dangle node），也就
是該節點只有一條線通過。先整理出所有的虛懸節點的線串，再利用霍夫轉換
（Hough Transform）在參數空間中以門檻值偵測尖峰以檢核 
直線等方式進行後續處理，就可以偵測出斷裂的直線段。將這些斷裂的線串
予以接續，並且重新整理弧點資料結構的節點以及線串陣列之後，向量化的成果
品質，當然可以獲得更實質有效的改善。 
系統整合 
最後將研究結果包括影像二值化、影像清繪與整理、細化處理、線萃取及線
形態補正的整個流程上做系統實作，並整合成一個部份半自動的系統。(影像清
繪與整理仍需人工介入處理) 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                            99 年 7 月 12 日 
報告人姓名  陳文儉 
 
服務機構
及職稱 
 
大葉大學資訊工程學系副教授 
 
     時間 
會議 
     地點 
2010/07/4~2010/07/6 
泰國芭達雅 
本會核定
補助文號
NSC 98-2221-E-212-029 
會議 
名稱 
 (英文) The 25th International Technical Conference on Circuits/Systems, 
Computers and Communications (ITC-CSCC 2010) 
發表 
論文 
題目 
  (英文) AN EDGE-ENHANCED JOINT DEMOSAICKING AND 
ZOOMING ALGORITHM FORSINGLE-SENSOR DIGITAL CAMERA 
報告內容應包括下列各項： 
一、參加會議經過 
 
二、與會心得 
 
三、考察參觀活動(無是項活動者省略) 
 
四、建議 
 
五、攜回資料名稱及內容 
 
六、其他 
 
 
 
一、參加會議經過 
 
於 7月 3日早上搭長榮班機飛泰國曼谷機場；下午轉機場巴士抵達芭達雅，4日下午大會報
到及歡迎晚會，5日上午大會開幕及四場專題演講。下午開始到 6日為各 Sessions 的論文發
表，總共超過 400 篇論文分 40 場 oral 報告及 2場 Poster 報告；本次發表論文被安排在 5日
下午 14:45~16:00 的 Poster 報告。如下照片： 
 
附件三
 
表 Y04 
(Communications)三大領域相關應用研究的學者，進行研究技術討論與心得之場合，並且藉以
提昇相關研究的發展。 
本屆共有超過 400 篇論文發表，作者來自 10 多個國家，總共接近 400 人註冊參加，規模相當
大，在大會用心的安排，是一次成功的學術研討會，從中除學術討論外也學到辦理國際研討
會的經驗，是一次非常有收穫的行程。另此次為增加博士班學生的國際交流及參加國際會議
的機會，也請博士班學生黃文聰一同前往增廣國際視野及學習的機會。 
三、考察參觀活動(無是項活動者省略) 
(無，省略) 
 
四、建議 
ITC-CSCC 2010 已經是第 25 屆了，其規模很大也涵蓋電機相關領域，國內相關學會也許
可以考慮也加入主辦行列，可能增加國際交流機會。 
 
五、攜回資料名稱及內容 
1. 大會論文摘要集, Volume 紙本一本。(收錄發表論文之論文摘要) 
2. 大會所有論文集之光碟一片。 
六、 其他 
     此次到泰國參加會議，深感韓國及日本研究生的各方面表現有十足進步，特別在用英文
報告研究成果方面值得國內研究生學習，而泰國學生雖英文音調較為特殊，但其上台報告非
常大方亦值得國內研究生學習。 
表 Y04 
                
 
        
除論文發表外，並參加其他 oral 及 poster 報告的場次，如下照片： 
        
二、與會心得 
International Technical Conference on Circuits/Systems, Computers and Communications 
(ITC-CSCC 2010) 已經是第 25 屆了，一開始只在日本由 IEICE 學會及韓國的 IEEK 學會輪流
舉辦，最近幾年泰國 ECTI 學會也加入主辦，今年第三次由泰國舉辦。 
自 1986 開始舉辦至今已經有 25 年的歷史，已經成為一個重要之國際會議。ITC-CSCC 國際
會議主要是提供從事電路系統設計(Circuits/Systems), 電腦(Computers) 及通訊
(Communications)三大領域相關應用研究的學者，進行研究技術討論與心得之場合，並且藉以
AN EDGE-ENHANCED JOINT DEMOSAICKING AND ZOOMING ALGORITHM FOR 
SINGLE-SENSOR DIGITAL CAMERA
 
Wen-Tsung Huang 
 
Institute of Computer and 
Communication Engineering 
Department of Electrical 
Engineering, 
National Cheng Kung University 
Tainan, Taiwan, R.O.C. 
e-mail: wencong6925@gmail.com 
 
 
Wen-Jan Chen 
 
Department of Computer Science 
and Information Engineering 
Da-Yeh University 
Changhua, Taiwan, R.O.C. 
e-mail: cwj@mail.dyu.edu.tw                                              
 
 
 
 
 Shen-Chuan Tai 
 
Institute of Computer and 
Communication Engineering 
Department of Electrical 
Engineering, 
National Cheng Kung University 
Tainan, Taiwan, R.O.C. 
e-mail: sctai@mail.ncku.edu.tw       
ABSTRACT 
 
This paper introduces an efficient joint demosaicking and 
zooming algorithm for single-sensor digital cameras. In 
general, it exhibits the consistency characteristics at 
different resolutions of an image. This concept is employed 
to preserve edge details and high frequency information of 
an image through our entire algorithm. Experimental results 
indicate that the new approach can produce a zoomed full 
color image with sharpness and less visual artifacts as 
compared with other approaches. 
 
Index Terms—demosaicking, color filter array, single-
sensor, zooming, digital camera. 
 
1. INTRODUCTION 
 
Single-sensor imaging technique has been widely used in 
many image-enable consumer electric products, such as 
mobile phones, digital cameras, and vision-based portable 
devices. This technique captures a visual scene using a 
single-sensor with a color filter array (CFA) to produce a 
digital raw image initially. In each pixel location of the 
captured CFA image, only one of three primary colors (Red, 
Green, and Blue) is sampled by its corresponding spectrally 
selective filter. Among various specific arrangements of 
color filters in the CFA, the Bayer pattern is the most 
commonly used nowadays. To obtain a full-color image, a 
reconstruction step of missing color components must to be 
performed. Such a processing operation is called 
demosaicking or CFA interpolation and is a critical step in 
the imaging pipeline. The cost of the imaging device as well 
as the quality of the output is significantly influenced by the 
demosaicking algorithm employed [1]. 
In a digital camera, zooming operation is frequently 
carried out in order to get a better view of a captured scene. 
Due to the limited computational resources, manufacturers 
typically employ a digital zooming solution inside a portable 
device instead of an optical zooming solution. Recently, 
various approaches concerned with demosiakcing have been 
presented to produce an enlarged full-color image from the 
CFA image. For example, approach [2] proposed a CFA 
zooming scheme for the mosaic image and then completed 
the task by employing the existing demosaicking methods. 
Alternative approaches [3-4] simultaneously combine 
demosaicking and zooming operations not only to reduce 
computational cost, but also to give a good performance. 
However, these presented solutions still lack of sharpness in 
regions of edges and fine textures because a great deal of 
high frequency components in the captured image have been 
lost through performed demosaicking and zooming 
operations.  
This paper introduces a new joint demosaicking and 
zooming framewrok which is suitable for single-sensor 
digital cameras. The edge information extracted during the 
demosaicking step is utilized to assist the enlargement task. 
This ensures the extracted edge information to be used 
consistently in both steps and leads to less objectionable 
visual artifacts. Moreover, the initially enlarged output 
image is also added to the corresponding high-frequency 
components. With this arrangement, the sharpness of edges 
will be enhanced to compensate for the image blurring after 
the numerous low-pass interpolation processing operations.  
Note that the introduced approach allows for the efficient 
computation of the entire camera image processing design 
because no separate information exaction operations are 
required in the different steps.  
The rest of the paper is organized as follows. Section 2 
presents the complete components of the proposed approach 
in brief. Section 3 gives the experimental results and 
Sections 4 concludes the paper. 
 
2. EDGE-PRESERVING JOINT DEMOSAICKING 
AND ZOOMING ALGORITHM  
 
The proposed algorithm is depicted in Fig. 1. Because the 
green plane contains more spatial details of the Bayer CFA 
image than that of the red or the blue plane, we first 
1194 ITC-CSCC 2010
,( , )
,
,
,
if
otherwise. 
if  
otherwise. 
p q
p q
i j
p q
p q
H nED
ED
V
ED H
nED

   


 
 
 


                    (6) 
 
where   belongs to a sufficiently large neighborhood of (i, 
j). An additional improvement can be achieved by giving 
more weight to the results of numerical edge indicators nED 
in the same row and column of (i, j). Fig. 3 shows an 
example of direction map produced by above introduced 
processing procedures.  
 
  
(a) (b) 
Fig. 3 (a) an interpolated green plane and (b) its direction map 
 
Having a full resolution of ED reference, we than enlarge 
both the direction map and the demosaicked green plane 
with size λMλN.  The zooming factor λ=2 will be used 
in the following discussions. The pattern of zoomed green 
plane is illustrated in Fig. 2(b) and the direction map is 
expanded as the same configuration. We first handle the 
pixels which connecting with four diagonal green neighbors. 
Let 
', '
ˆ z
i jG
represents a concerned green pixel to be 
interpolated in this phase and '  = {(i´-1, j´-1), (i´-1,  j´+1), 
(i´+1, j´-1), (i´+1, j´+1)}  be its support. To explore the 
contribution of the adjunct green components, four proper 
weights determined as dissimilar degree of ED within a 
square region SR, illustrated in Fig 2.(b), are assigned to the 
corresponding four green neighbors, such that: 
 
                  
 
, ,
( , ) '
', '
,
( , ) '
, , ,
( , )
ˆ
  1
z
p q p q
p qz
i j
p q
p q
p q p q r s
r s SR
w G
G
w
w nED nED






  



                      (7) 
 
In addition, we define the ED at position ( ', ')i j   for further 
reference in next interpolation phase. The idea is similar to 
the concept of eq. (6). Fig.2 (c) shows the output pattern of 
this interpolation phase.  
 For the remaining unprocessed green location in Fig.2(c), 
we choose to perform an edge-directed interpolation using 
the determined ED results in the green locations. Let the 
location of green neighbors of 
'', ''
ˆ z
i jG be ''   {(i´´-1, j´´), 
(i´´+1,  j´´), (i´´, j´´-1), (i´´, j´´+1)} , and 
'', ''
ˆ z
i jG is estimated as 
                  
 
 
 
'', ''
, ,
( , ) ''
'', ''
,
( , ) ''
, , ,
( , )
 ( '', 1),( '', '' 1)      if    
 ( '' 1, ),( '' 1, '') ,    otherwise
ˆ
''
  1
i j
z
p q p q
p qz
i j
p q
p q
p q p q r s
r s DR
i j i j ED H
i j i j
w G
G
w
w nED nED






  
 


  



                      (8)
 
 
whre 
'', ''i jED
 has been previously  determined according to 
its neighbors '' , and DR is a demand-shaped region of 
support as shown in  Fig. 2(c).  
 
2.3. Demosaicking and zooming  of the red and plane 
planes 
 
As for the reconstruction the red and blue planes, the 
bilinear interpolation of color-difference [5] is carried out 
with the green reference in the demosaicking and zooming 
steps. In our empirical study, more advanced red and blue 
interpolation methods does not bring a significant 
improvement. It should be noted that our method expands 
the color difference planes of the demosaicked full color 
image for the enlargement step instead of expanding the red 
and blue planes directly.   
 
2.4. Extraction of high frequency components 
 
To compensate for the image blurring caused by the 
properties of various low-pass interpolation filters, the 
enlarged full color image is added with the corresponding 
high frequency which is initially extracted from the 
demosaicked green plane as mentioned. Each green 
component is directionally convolved with [-1/4, 1/2, -1/4] 
according to the interpolation direction map to provide the 
high frequency components of the demosaicked green plane. 
By doing so, we have a high frequency image whose 
resolution is the same as the demosaiked green plane. 
Similarly, the high frequency image is firstly expanded as 
the form of Fig. 2 (b) and then its missing components are 
estimated as the procedures used in the reconstructing the 
zoomed green plane. It can save an amount of computation 
effort because the corresponding weights used in the 
interpolation have been already computed. At this time, 
better accuracy of the high frequency information is also 
expected to obtain. Fig.4 shows a cropped region of an 
enlarged high frequency image which is obtained by bicubic 
method and our extraction method, respectively. One can 
see that our result looks more clearly.  
 
  
(a) (b) 
1196 ITC-CSCC 2010
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本研究之結果可供資訊業者在處理政府機關的工程圖及其應用時的參考，對於
資訊業者開發工程圖相關商用軟體應有幫助。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
