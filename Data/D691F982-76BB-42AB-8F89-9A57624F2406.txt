2可供推廣之研發成果資料表
■ 可申請專利 ■ 可技術移轉 日期： 年 月 日
國科會補助計畫
計畫名稱：時序性高維資料分群動態預測模型建立之研究
計畫主持人：蔣以仁
計畫編號：NSC 96－2221－E－038－004 學門領域：資訊二
技術/創作名稱 即時動態文件資訊分群
發明人/創作人 蔣以仁
中文：我們的研究成果中，關鍵特徵的擷取與動態現象的模型建立，是建立同
質性分群（homogeneous clustering）以探討ㄧ動態性隨時而變的 Ontology 的
重要一歨，利用機器學習建立以特殊領域數位內容蒐集為目標之關鍵資訊萃取
方法，除首先去除虛詞，並藉助專業詞庫（ Dictionary 或 Lexicon），仍將持續
以 Zipf 為基礎，經由 TFIDF 計算，引入 Probabilistic Model，如 HMM 及專家知
識（Expert Knowledge），成為 Knowledge-Based Probabilistic Topic Terms Tracking
模式，建立專業性的關鍵詞彙擷取作業，以形成各特殊領域從專業文件中萃取
重要之詞彙；為求能確實掌握其中文義涵意，此部分以中研詞彙為基礎式的學
習方法，經過多次實驗，確能於有限且極短時間完成，以確實的成 real-time
clustering。
技術說明
英文：This research has taken scientific dataset and related articles as subject,
implementing“automatic clustering”and“scoring”model to automatically construct
the taxonomical and decision supporting ontology. Afterwards, invited experts will
evaluate the efficiency of the system with personal diagnosis and feedback the results
to the system. With the computer learning technology, the process of constructing the
ontology, especially for decision making, will be modified.
可利用之產業
及
可開發之產品
1. 圖書及檔案資訊：進行知識地圖建構，以協助檔案管理局、及
圖資系統公司。
2. 醫學文獻：已建立於國衛院實證醫學網站
(ebpg.nhri.gov.tw)，可協助臨床醫師正確找到所需的資料。
技術特點
1. 遞增式機器學習法進行詞彙選取，可使適應於各專業領域，並
隨資料累積，而使系統之準確性更加提升。
2. 即時性分群。
3. 達到語義上之詞彙歸納與分群分類。
4. 遞進式詞彙累積。
推廣及運用的價值
改善一般資料檢索方式，使能更準確掌握語意上的意義與實質內容
特性。可運用於資料檢索、群聚分析等服務。可與圖書資訊作一有
效整合。
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
※ 3.本表若不敷使用，請自行影印使用。
4be clustering is getting large–when there are
millions of in stances, many thousands of
features, and many thousands of clusters.
Since all data items have to be converted into
a vector-based data points and to be clustered
into groups based on some measures of
similarity or distance among them, these
schemes fail to produce meaningful clusters,
if the number of attributes is large. For
text/web mining, it is hard to say that two
features are relevant if both of them occur
frequently in the collection of documents but
are far away each other located in a
document, because multiple concepts can be
simultaneously defined in a single web page.
Information retrieval is normally
making use of cluster analysis to organize
documents into a collection of topic-coherent
groups [1]. In addition to aim users better
understand the retrieval documents to focus
their search, clustering has been used as
alternate organization of documents [2].
The purpose that we seek is to investigate the
implicit structure discovered by using a
clustering method. Such a structure would
help user to resolve their information needs
more efficiently and more effectively.
In the first year of the project, this study
introduces a novel algorithm for clustering to
discover the semantic structure based on
Combinatorial Topology that is efficient
when an application domain is large. In a
real world application given a
high-dimensional data set, it often mixes up
multiple heterogeneous concepts [3-6].
These concepts are considered to organize a
high-dimensional semantic space we called
Latent Semantic Space (LSS) in which could
contain several separated concepts. Along
with those separate concepts, a data set can
be clustered into meaningful groups. Each
primitive concept can be considered to be the
co-occurrences or associations (high frequent
itemsets) of features in the data set, which are
obviously as simplices in combinatorial
topology. Therefore, the semantic space is
represented as simplicial complex composed
of a collection of connected simplices.
It is naturally to cluster the data set
groups semantically in accordance with the
simplical complex. For example, the
association that consists of ‘’wal’ and
‘’street’’ denotes some financial notions that
have meaning beyond the two nodes, ‘’wal’’ 
and ‘’street’. This is similar tothe notion of
open segment (v0, v1), in which two end
points represent one dimensional geometric
object that have meaning beyond the two
0-dimensional end points. In general, an
r-association represents some semantic
generated by a set of r keywords, may have
more semantics or even have nothing to do
with the individual features.
三、Methods and Results
An undirected graph is constructed
from features that have been extracted from a
high-dimensional data. Perhaps thousands
or millions of features have been reserved.
Instead of concerting data to be a matrix in
which each instance is a vector, all its distinct
attribute-value pairs are transferred to be
individual nodes (0-simplex). If two
features are co-occurred in some instances,
an edge (1-simplex) connected these two
features are generated. Each edge is
associated with a support value to denote
how significant the association of the two
nodes connected by the edge is. That is, a
undirected graph G=(V, E, W), where V is the
set of nodes, E is the set of edges, and W
denotes the set of significant supports of G,
that is, supports can de defined on nodes or
edges. The support defined on a node
(0-simplex) is said to the elementary support
that it means the significant value of the
corresponding feature of the node [7,8].
Consider Fig. 1 is 2-complex composed
of the term set V={tA, tB, tC} in a collection
of documents. It is a close 2-simplex; we
recall here that a closed simplex is a complex
that consists of one simplex (in highest
dimension) and all its faces.
In the skeleton 21S , all 0-simplexes are
ignored, i.e., the terms depicted in dash lines.
The simplex set S={ 21Simplex ,
1
2Simplex ,
1
3Simplex ,
1
4Simplex } is the closed 2-simplex
that consists of one 2-simplex and three
1-faces, 12Simplex ,
1
3Simplex , and
1
4Simplex (0-faces are ignored). These
r-simplexes (0≦r≦2) represents frequent
63. Let K C∪H.
4. If X be the set of simplices that each simplex
in X has an common face in C∪H; X∩(C∪
H) ≠ ρ then call
CONCEPT_DISCOVERY(K, X).
5. Let U = S–X and call
CONCEPT_DISCOVERY(C, X).
6. The skeleton nmS 
n
mS ∪K where m=|H
∪C| and n≧m.
Fig.3 The algorithm is to find connected
components in a simplical complex recursively.
Comparing with other methods, the empirical
result is shown in Table.1. The
experimental evaluation of document
clustering approaches usually measures their
effectiveness rather than their efficiency, in
the other word, the ability of an approach to
make a right categorization.
Table.1 The first dataset is compared with
four algorithms, LSS, PDDP, k-means and
AutoClass. (CI: 95%)
Method LSS PDDP k-means AutoClass HCA
Procession 81.4% 65.6% 56.7% 34.2% 35%
Recall 76.2% 68.4% 34.9% 23.6% 22.5%
F-measure 0.787 0.67 0.432 0.279 0.274
四、Discussion and Conclusion
A topology-based method is presented
in this study that can naturally transfer the
data into a hierarchical semantic space.
Several latent semantic patterns reveal
connected components within the semantic
space. According to highly association
terms of each layered skeleton, the data can
be hierarchically partitioned into several
meaningful clusters.
Polysemy, phrases and term dependency
are the limitations of search technology. A
single term is not able to identify a latent
concept in a document, for instance, the term
``Network'' associated with the term
``Computer'', ``Traffic'', or ``Neural'' denotes
different concepts. To discriminate term
associations no doubt is concrete way to
distinguish one category from the others. A
group of solid term associations can clearly
identify a concept. The term-associations
(frequently co-occurring terms) of a given
collection of Web pages, form a simplicial
complex. The complex can be decomposed
into connected components at various levels
(in various levels of skeletons). We believe
each such a connected component properly
identify a concept in a collection of Web
pages.
Some terms with similar meaning, for
example, ``anticipate,'' ``believe,''
``estimate,'' ``expect,'' ``intend,'' ``project'',
could be separated into several independent
topics even with the other same sub-concepts.
In our experiments, some data of a single
concept have been specified into redundant
clusters. That makes the number of
clustering big. Thesauri and some other
adaptive methods are going to provide a
solution for it. It will be further considered
to solve in the future.
We can effectively discover such a
simplical complex and use them to cluster the
collection of Web pages. Based on our web
site and our experiments, we find that LSS is
a very good way to organize the high
dimensional data into several semantic topics.
It illustrates that geometric complexes are
effective models for automatic web pages
clustering.
五、參考文獻
1. Rijsbergen, C. J., Information Retrieval.
Butterworths, 1979.
2. Hearst,M. A., Pedersen, J. O., Reexamining the
cluster hypothesis: Scatter/gather on retrieval
results. In: Proc. of the 19th Annual International
ACM/SIGIR Conference on Research and
Development in Information Retrieval. Zurich,
Switzland, pp. 76–84, 1996.
3. Chiang, I. J, Lin, T. Y., Tsai, H. C., Wong, J. M.
and Hu, X., Latent Semantic Space for Web
Clustering, Studies in Computational Intelligence,
118, pp.61-77, 2008.
4. Chiang, I. J, Lin, T. Y., and Hsu, J. Y. J.,
Hypergraph Components Decomposition Based
on Term Associations for Document
Categorization, to be appeared in World Wide
Web.
5. Yeh, R. L., Liu, C., Shia B. C., Chiang, I. J., Yang,
W. W., and Hsiang-Chun Tsai, Semantic Based
Real-Time Clustering for PubMed Literatures, DS
2007, LNAI 4755, pp. 291–295, 2007.
6. Chiang, I. J., Discover the Semantic Topology in
High-Dimensional Data, Expert Systems with
Applications, 33 (1), 256-262, September, 2007.
7. Spanier, E., Algebric Topology. McGraw-Hill
Book Company, New York, N.Y., 1966.
表 Y04
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
97 年 7 月 31 日
報告人姓名 蔣以仁 服務機構
及職稱
臺北醫學大學 醫學資訊研究所
副教授
時間
會議
地點
96 年 9 月 31 日至 10 月 4 日
日本仙台市
本會核定
補助文號
NSC 96－2221－E－038－004
會議
名稱
(英文) The Tenth International Conference on Discovery Science (DS-2007)
發表
論文
題目
(英文) Semantic Based Real-Time Clustering for PubMed Literatures
報告內容應包括下列各項：
一、 參加會議經過
I had the honor of being accepted a paper and being arranged to oral report and
poster presentation. Thus, I made good use of this opportunity to participate in the
tutorials about“On the Philosophical, Statistical, and Computational Foundations
of Inductive Inference and Intelligent Agents”and“Introduction to Probabilistic
Image Processing and Bayesian Networks”and to focus on Professor Avrim
Blum’s invited talk about“A Theory of Similarity Functions for Learning and 
Clustering”. He have developed a theory that applies to more general similarity
functions (not just legal kernels), and furthermore he described the usefulness of a
given similarity function in terms of more intuitive, direct properties, without
need to refer to any implicit spaces. It is a useful theory.
二、 與會心得
The Tenth International Conference on Discovery Science (DS-2007) was hosted
in Sendai, Japan. It offered a series of the application of data analysis and other
support techniques for scientific discovery. My presentation was well received
and I was congratulated by many in the audience. Since it had a strict appraisal
process, only 17 long papers and 10 regular papers were accepted for inclusion in
the final technical program. Hence, the conference attracted many professionals
