driven）的時間序列濾波器；其主要方法是先統計原
始語音的特徵參數在時間上其統計特性，例如每一類
別的平均值（mean）或變異數（variance），然後配
合某一些最佳化準則，例如早期使用的線性鑑別分析
法（linear discriminant analysis，LDA），求取濾波器
之係數，俾使得濾波器之輸出有最大的分類鑑別值，
在過去文獻中證實此類資料導向濾波器效能確實超越
傳統與資料無關之濾波器，帶來更高的語音辨識精確
度。在以上這些方法中，雖然我們最常討論的是所求
得 之 濾 波 器 在 調 變 頻 域 （ modulation frequency 
domain）上的頻率響應（frequency response）特別是
強度響應（magnitude response），來分析每個頻帶對
於辨識精確度之利弊，然而，在設計濾波器過程中，
我們卻是利用特徵參數在時域（temporal domain）上
其統計特性，而很少直接利用調變頻域之性質，這樣
可能導致發生有下列兩項缺點：（一）在時域上最佳
化其濾波器，未必亦能在調變頻域上也是最佳化，可
能只是間接地利用語音特徵在時域上其特性，來推敲
在調變頻域上其特性。（二）所求得的濾波器雖然在
強度響應（magnitude response）上顯示了以語音為主
的頻帶被過濾出來，但是在相位響應（ phase 
response）上的特性通常被忽略不提，而這些所求得
之濾波器係數，通常不具有對稱（symmetric）或反對
稱（anti-symmetric）之特性，也因此鮮少具備了線性
相位（ linear phase）之良好性質，因此可想而知的
是，在濾波器通帶（pass-band）之不同的頻率成分因
為非線性相位所影響而造成不一致的群延遲（group 
delay）之失真，可能進而限制了濾波器其最佳效能。 
   根據上述第二個潛在缺點，我們在求取濾波器之強
度響應後，再利用濾波器設計之技術，設計出新的濾
波器係數，使新的濾波器係數能夠具備有線性相位，
同時又能夠逼近原濾波器其強度響應。而為了改善其
第一個缺點，我們採用語音特徵參數時間序列之調變
頻譜（而非時域）來求取其統計性質，再進一步求取
時間序列之濾波器的最佳強度響應；因此我們由調變
頻譜所求得之時間序列濾波器兼具有良好的強度響應
以及線性相位之良好的特質。以下，我們就針對如何
利用調變頻譜來設計時間序列濾波器的方法加以介
紹。 
    令某一維語音特徵之時間序列為 { }( )x n ，而我們所
要設計之濾波器響應為 { }( ), 0,1, ..., - 1h n n L= ，則濾波
器之輸出為兩者之間的摺積（convolution），其表示
如(1)式所示： 
1
0
( ) ( ) ( - )
L
u
y n h u x n u
−
=
= ∑                                                 （1） 
在這裡我們將處理的領域由時域（temporal domain）
轉換至調變頻域（modulation frequency domain），此
時其輸出調變頻譜 ( )jY e ω 以及輸入調變頻譜 ( )jX e ω 與
濾波器之頻率響應 ( )jH e ω ，之關係如(2)式所示： 
( ) ( ) ( )j j jY e H e X eω ω ω=                                                （2） 
由於調變頻譜通常是一複數（complex number），亦
即包含實部與虛部或是振幅與相位，亦即我們必須同
時處理兩個變數之問題，為了簡化計算其複雜度，我
們將原本最佳化輸出調變頻譜簡化成最佳化輸出調變
頻譜功率的問題，其定義如(3)式所示： 
2 2
2 22
0 0
( ) ( ) ( )
K K
T
Y
k k
P Y k H k X k
⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦
= =
=∑ ∑ H X                 （3） 
其中 
22 2
(0) (1) ( ) ,  2
T
KH H H⎡ ⎤⎢ ⎥= ⎢ ⎥⎢ ⎥⎣ ⎦⎣ ⎦H "  
22 2
(0) (1) ( )2
T
KX X X⎡ ⎤⎢ ⎥= ⎢ ⎥⎢ ⎥⎣ ⎦⎣ ⎦X " 。 
H相當於濾波器平方強度響應，因此，我們可以利用
一最佳化準則，藉由最佳化某一輸出功率 YP 的目標函
數(objective function) 來求取最佳的H。根據(3)式，在
求取最佳的H之過程中，會利用到輸入信號調變頻譜
X的統計特性。在本論文中，所利用的最佳化準則包
括 了 受 限 之 線 性 鑑 別 分 析 (constrained linear 
discriminant analysis, C-LDA)、受限之主軸成分分析
(constrained principal component analysis, C-PCA) 及受
限之最大分類距離(constrained maximum class distance, 
C-MCD)，這三種最佳化準則將於後面的章節中詳加
介紹。此外，為了得到輸入信號調變頻譜X的統計特
性，我們可以蒐集訓練語料庫中每一個時間序列的特
徵參數，計算其平方強度頻譜後，這些平方強度頻譜
即可視為 X的樣本(samples)，藉由這些樣本我們便能
估測X的統計特性。 
附帶一提，在這裡我們選擇輸出功率 YP 作為最佳化濾
波器過程中的參數，具備了許多優點，首先，評估一
個單一變數 YP 的表現好壞比評估一連串變數，如輸出
頻譜 ( ){ }Y k 或其平方強度 ( ){ }2Y k  相對而言簡單的
多；其次， YP 本身代表了濾波器輸出的功率，因此相
對於輸出頻譜之強度和 ( )
1
1
K
k
Y k
−
=
∑ 更具有物理意義；第
三，由(3)式可知， YP 直接關連於濾波器平方強度響
應 ( ){ }2H k  而非濾波器的頻率響應 ( ){ }H k ，如前所
提， ( ){ }2H k 是非負實數，但是 ( ){ }H k 卻通常是複
數，因此處理 ( ){ }2H k 相對而言比 ( ){ }H k 來的簡易。 
當我們藉由最佳化一個 YP 的目標函數，得到最佳之濾
波器平方強度響應 ( ){ }2H k ，後，皆下來我們可以利
用數位濾波器設計之技術，將最佳的濾波器平方強度
響應，轉換為線性相位之濾波器，首先對於一長度 L
的 FIR濾波器之脈衝響應如(4)式所示： 
{ }( ), 0 1h n n L≤ ≤ − ，                                            （4） 
( ) ( )
( )
1 LDAJ
θ
θ θ ε+ =
∂= + ∂ H HH H H                                       (15） 
其中 ε為步階量（step-size），而且 
LDA LDAJ J∂ ∂∂=∂ ∂ ∂
H
H H H
                                                 （16） 
其中矩陣 ∂∂
H
H
的第 ,i j項為 
( )
( )
1
1
2
0
exp1
exp
P
jj
K
iij
m
m
HH
H P
H
−
⎢ ⎥⎢ ⎥⎣ ⎦
=
⎛ ⎞⎟⎜ ⎟⎜ ⎟⎜ ⎟⎜∂ ⎟⎛ ⎞∂ ⎜ ⎟⎟⎜ ⎟= = ⎜⎟⎜ ⎟⎟⎜ ⎜⎝ ⎠ ⎟∂ ∂ ⎜ ⎟⎜ ⎟⎜ ⎟⎟⎜ ⎟⎜⎝ ⎠∑
H
H
 
( ) ( ) ( )
( )
2
0
2
2
0
exp exp exp
exp
K
j m i jij
m
K
m
m
H H H H
H
δ
⎢ ⎥⎢ ⎥⎣ ⎦
=
⎢ ⎥⎢ ⎥⎣ ⎦
=
⎛ ⎞⎟⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟− +⎜ ⎟⎟⎜ ⎟⎜× ⎟⎜ ⎟⎜ ⎟⎛ ⎞⎜ ⎟⎟⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟ ⎟⎜⎜ ⎟ ⎟⎜ ⎟⎜ ⎟⎟⎜ ⎟⎜ ⎝ ⎠⎝ ⎠
∑
∑
 （17） 
而且 
( ) ( )
( )
2 - 2T TW B B WLDA
T
W
J∂ =∂
H S H S H H S H S H
H H S H
          （18） 
當H收斂時由(8)式所求得之H亦即是我們所要求的受
限之線性鑑別最佳的濾波器平方強度響應。 
 
III.2 受限之主軸成分分析法 
主軸成分分析法是在數位訊號處理、影像處理以及圖
形辨識中很常見之技術，其主要目的在於求取最具代
表性（representative）的特徵值，因它可將彼此相關
的一群特徵向量採用較少維度的向量來代表，並且可
以將特徵向量維度與維度之間相關性去除。在此我們
利用主軸成分分析法作為最佳化準則，來幫助我們求
取時間序列濾波器的強度響應。 
首先必須先對於訓練語料之特徵參數做區段的切割，
對於某一維特徵參數時間序列而言，我們將其分成固
定長度的區段，將這些區段取其平方強度頻譜
( ) ( ) ( ) 22 2( ) ,1 , 2 , 2 Tn X n X n X n K⎡ ⎤⎢ ⎥⎢ ⎥= ⎢ ⎥⎣ ⎦⎢ ⎥⎣ ⎦X " ， 其 中
( ),X n k 代表了第 n 時間區段的頻譜，而 k 為頻率索
引。不同於前一節的 C-LDA 的作法，在此我們無須
對於這些區段做分類。接著，將這些區段之平方強度
頻譜取其各類之平均值 μ以及共變異數Σ，如(19)式
以及(20)式所示， 
( )
1
1 N
n
n
N =
= ∑Xμ                                                         （19） 
( )( ) ( )( )
1
1 N T
n
n n
N =
= − −∑ X XΣ μ μ                            （20） 
其中N 為區段的總數。 
    在此我們以 2σ 來表示為濾波器輸出功率之總體變異
數（global variance），則受限之主軸成分分析法所得
到最佳濾波器平方強度響應如(21)式所示： 
* 2arg max ( ), ( ) TPCA PCAH
J J σ= = =H H H H HΣ            (21) 
類似前一節，受到H必須為非負之限制，我們引進一
個沒有受限的中介向量H，並令H與H之關係如前之
(8)式所示，接下來，我們便可使用梯度降低法
（gradient-descent algorithm）來反覆求取近似最佳之
H與H，如(22)式所示： 
( ) ( )
( )
1 PCAJ
θ
θ θ ε+ =
∂= + ∂ H HH H H                                     （22） 
其中 ε為步階量（step-size），而且 
PCA PCAJ J∂ ∂∂=∂ ∂ ∂
H
H H H
                                                 （23） 
其中矩陣 ∂∂
H
H
的第 ,i j項可由(17)式表示， 
而 
2PCA
J∂ =∂ HH Σ                                                          （24） 
當H收斂時由(8)式所求得之H為受限之主軸成分分析
法準則下最佳之濾波器平方強度響應。 
 
III.3 受限之最大類別距離法 
最大類別距離法是最小分類錯誤法（Minimum 
Classification Error，MCE）之變形，其目的在於最大
化不同類別間之距離來提升分類正確率並且可以簡化
傳統之最小分類錯誤法之複雜運算以及多變數之問
題，以下我們將介紹受限之最大類別距離法： 
    首先如同受限之線性鑑別分析法，先將訓練語料每
一維特徵向量做區段的切割，並加以分類，求取每一
區段的平方強度頻譜後，將這些分類後的區段之平方
強度頻譜取其各類之平均值 ( )jμ 以及共變異數 ( )jΣ ，如
(10)式以及(11)式所示。首先我們假設每一類別之平方
強度頻譜為一隨機向量 ( )jX ，且為高斯分佈
（multivariate Gaussian distributed），其平均值為 ( )jμ
以及共變異矩陣為 ( )jΣ ，因此濾波器輸出之功率可視
為一高斯隨機變數，其平均值為 ( )T jH μ ，變異數為
( )T jH HΣ ，則其機率密度函數（ probability density 
function） ( )( )jg x 可由(25)式所示： 
( )( ) ( ) ( )( ) ; ,j T j T jg x x= H H Hμ ΣN  
( )
( )2( )
( )( )
1
exp
22
T j
T jT j
x
π
⎛ ⎞− ⎟⎜ ⎟⎜ ⎟= −⎜ ⎟⎜ ⎟⎜ ⎟⎟⎜⎝ ⎠
H
H HH H
μ
ΣΣ
                     （25） 
然後計算其輸出功率之第 i 類與及第 j 類之距離，採
用 Kullback-Leibler distance，其定義如(26)式所示： 
( )
( ) log
( )
i
ij i
j
g x
d g x dx
g x
∞
−∞∫                                         （26） 
則利用(25)式，(26)式又可表示成(27)式 
( )( )( ) ( ) ( ) ( )( )
( ) ( )
- -
log
TT i j i jT j T
ij T i T T j T
d = + H HH H
H H H H
μ μ μ μΣ
Σ Σ  
 
表 2.受限之線性鑑別分析法辨識率（％）（ Set B） 
 
 
表 3. 受限之線性鑑別分析法辨識率（％）（Set C） 
 
圖 1. 受限之線性鑑別分析法其 13維平方強度響應圖 
 
透過受限之主軸成分分析法在調變頻域設計之時
間序列濾波器之實驗結果，如表 4、表 5 與表 6 所
示，為了比較，我們將在時域中利用主軸成分分析法
設計之時間濾波器[9]的結果附於每一表的最後一列，
以 Temporal PCA 表示。同時，這些濾波器所對應之
平方強度響應如圖 2所示。 
由表 4、表 5與表 6所示，受限之主軸成分分析法
相較未處理之特徵參數 MFCC，在測試組別 A、B 與
測試組別 C 幾乎都有進步，其整體平均辨識率達
62.76％，同時，實驗數據也顯示了他們的效果優於傳
統在時域上利用主軸成分分析法所得的濾波器，但是
它們的表現卻明顯不如前一節的受限之線性鑑別分析
所得濾波器，可能原因在於，這些濾波器大多為低通
（lowpass）濾波器，如圖 2 所示，因此它們無法有效
將直流部分移除。 
 
表 4 .受限之主軸成分分析法辨識率（％）（Set A） 
 
 
表 5. 受限之主軸成分分析法辨識率（％）（Set B） 
 
 
圖 3. 受限之最大類別距離法其 13維平方強度響應圖 
 
V.結論 
由前章之實驗結果顯示，我們採用由調變頻譜來
設計時間序列濾波器確實能夠達到語音強健性，這些
方法包含受限之線性鑑別分析法（C-LDA）、受限之
最大類別距離法（C-MCD）、受限之主軸成份分析法
（C-PCA），其中前兩者其所設計出來之濾波器為帶
通濾波器，對於辨識率而言較有顯著之效果表現，而
後者由於所設計出來之濾波器為低通濾波器，因此造
成其進步率未有較顯著之效果；然而他們都明顯優於
直接在時域上所設計之濾波器，這可能意味了除了他
們有較理想的強度響應外，線性相位的良好性質也是
原因之一，因此我們所提出之由調變頻譜來設計之時
間序列濾波器兼具有最佳平方強度響應與線性相位之
優點，可提高其語音辨識效果。 
 
參考文獻 
[1] Jeih-weih Hung and Wei-Yi Tsai, "Optimization of 
Temporal Filters in the Modulation Frequency Domain for 
Constructing Robust Features in Speech Recognition", 
accepted by IEEE Transactions on Audio, Speech and 
Language Processing, 2007 
[2] Jeih-weih Hung, " Optimization of Temporal Filters in 
the Modulation Frequency Domain via Constrained Linear 
Discriminant Analysis (C-LDA) for Constructing Robust 
Features in Speech Recognition", 2007 International 
Conference on Acoustics, Speech and Signal Processing 
(ICASSP 2007) 
[3] Jeih-weih Hung, "Optimization of Temporal Filters in 
the Modulation Frequency Domain for Constructing 
Robust Features in Speech Recognition", 2007 
International Conference on Spoken Language Processing 
(Interspeech 2007 — ICSLP) 
[4] N. Kanedera, T. Aria, H. Hermansky and M. Pavel. 
"On The Importance of Various Modulation Frequencies 
for Speech Recognition", Proceedings of Eurospeech, 
1997 
[5] H. Hermansky and N. Morgan, "RASTA processing of 
speech", IEEE Transactions on Speech and Audio 
Processing, 2, 578-589, 1994 
[6] J. W. Hung and L. S. Lee, "Comparative Analysis for 
Data-Driven Temporal Filters Obtained Via Principal 
Component Analysis(PCA) and Linear Discriminant 
Analysis(LDA) In Speech Recognition", Proceedings of 
Eurospeech 2001 
[7] S. V. Vuuren and H. Hermansky, "Data-Driven Design 
of RASTA-Like Filters", Proceedings of ICSLP 1996 
[8] L. Markus and H. U. Reinhold, "LDA Derived 
Cepstral Trajectory Filters in Adverse Environmental 
Conditions", Proceedings of ICASSP 2000 
[9] J. W. Hung and L. S. Lee, "Optimization of Temporal 
Filters for Constructing Robust Features in Speech 
Recognition", IEEE Transactions on Speech and Audio 
Processing 2006 
[10] S. Tiberewala and H. Hermansky, "Multiband and 
adaptation approaches to robust speech recognition", 
Proceedings of  Eurospeech 1997 
[11] Sanjit K. Mitra, "Digital Signal Processing, a 
computer-Based Approach", second version, McGraw-
Hill 
Silence Energy Normalization for Robust Speech Rec
Chung-fu Tai and Jeih-w
Dept of Electrical Engineering, Natio
Taiwan, Republic of
e-mail : s3323542@ncnu.edu.tw, jw
Abstract 
The energy parameter has been widely used as an 
extension to the basic features of mel-frequency cepstral 
coefficients (MFCCs) to improve the recognition 
accuracy in speech recognition. In this paper, a simple 
and effective approach for energy normalization for 
silence (non-speech) portions in an utterance is proposed. 
This approach, named as silence energy normalization 
(SEN), uses the high-pass filtered log-energy as the 
feature for speech/non-speech classification, and then the 
log-energy of non-speech frames is set to be a small 
constant while that of speech frames is kept unchanged. 
In the experiments conducted on AURORA2 database, 
we showed that SEN provides an averaged word error 
rate reduction of 34.9% and 44.6% for Test Sets A and B, 
respectively, when compared with the baseline 
processing. It was also shown that SEN outperforms 
similar approaches like energy subtraction (ES) and 
feature vector selection (FVS). Finally, we showed that 
SEN can be integrated with cepstral mean and variance 
normalization (CMVN), to achieve further improved 
recognition performance.  
Index Terms: silence energy normalization, frame 
vector selection, energy subtraction 
1. Introduction 
The performance of a speech recognition system is often 
severely degraded in the presence of noise. A variety of 
approaches have been proposed to mitigate this 
degradation, and they can be roughly divided into three 
classes: utilization of a noise robust representation of 
speech signals, enhancement of the speech features 
before they are fed to the recognizer, and adaptation of 
the speech models in the recognizer to make them better 
match the noise conditions. The main difference between 
the first two classes of approaches is that, for the first 
class, the noise robust speech features are used for both 
model training and testing, and for the second, 
enhancement procedures are often performed only on the 
noise corrupted speech features for testing, while the 
speech features for training are kept unchanged. In this 
paper, our proposed approach belongs to the first class. A 
new feature normalization scheme called silence energy 
normalization (SEN) is introduced.  
As we know, the energy of speech signal contains 
important information regarding the phonetic content of 
speech, and therefore we have used it directly or the 
variation of it (for example, log-energy, delta energy, etc.) 
to be one of the speech features for recognition. However, 
these energy features are often vulnerable to noise and 
thus their discriminating capability is limited. Recently, 
some approaches have been proposed to enhance these 
energy features [1-5]. For example, in [1] the speech 
energy contour is extracted from the high-pass filtered 
signal so as to reduce the distortion in the delta energy, 
and 
both
targe
whe
fram
ones
fram
rate 
the f
norm
fram
valu
class
Part
pape
norm
utter
(sile
high
for 
norm
the s
the 
be p
nois
labe
that 
nois
corr
the 
utter
is a 
easil
for 
(CM
The 
secti
The 
secti
othe
addi
the 
brief
    
2.1 B
Whe
utter
Figu
non-
high
by n
On 
INTERSPEECH 2006 - ICSLP
2558ognition in Additive Noise Environments 
eih Hung 
nal Chi Nan University 
 China 
hung@ncnu.edu.tw
in [2] the dynamic range of log-energy sequences for 
 training and testing utterances is normalized to a 
t one in order to reduce the environmental mismatch, 
re the normalization function indicates lower-energy 
es are more affected by noise than higher-energy 
. On the other hand, [6] introduces the method of 
e vector selection (FVS) based on variable frame 
processing or voice activity detection (VAD), where 
rame-to-frame variation (for example, the Euclidean 
 of the delta feature) or the log-energy of each 
e is used as an indicator for frame selection. If its 
e is below a predefined threshold, this frame is 
ified as silence or noise-only and is then discarded.  
ly motivated by the concepts in [2] and [6], in this 
r we propose the approach of silence energy 
alization (SEN). In SEN, every frame vector of an 
ance is first classified as speech or non-speech 
nce). The classifier is based on the output of a 
-pass filter with the log-energy being the input. Then 
each of the silence frames the log-energy is 
alized to a small constant, while the log-energy of 
peech frames remains unchanged. Note that in SEN, 
classification and normalization procedures need to 
erformed on the utterances in both clean training and 
y testing databases, and unlike FVS, the frames 
lled as non-speech are not discarded. We will show 
by SEN the normalized log-energy sequence of a 
e corrupted utterance is quite close to that of the 
esponding clean version. Also, the threshold used in 
classifier for SEN is determined by the input 
ance and needs not to be tuned heuristically, which 
particular benefit of SEN. Furthermore, SEN can be 
y integrated with cepstral compensation techniques, 
example, cepstral mean and variance normalization 
VN) [7], to obtain further improved performance. 
remainder of the paper is organized as follows.  In 
on 2, the proposed approach of SEN is described. 
experimental environment setup is described in 
on 3, and the recognition results of SEN and some 
r approaches are given and discussed in section 4. In 
tion, section 4 also contains the recognition results of 
combination of SEN and CMVN. Finally, section 5 
ly contains some concluding remarks.  
 2. Silence Energy Normalization 
asic idea 
n observing the log-energy contours of a clean 
ance and its noise-corrupted counterparts as in 
re 1(a), some differences between the speech and 
speech portions may be found. For example, the 
-energy speech portions are relatively less influenced 
oise and sometimes keep the ripple characteristics. 
the other hand, the low-energy non-speech portions 
September 17-21, Pittsburgh, Pennsylvania
cepstral coefficients (MFCCs) plus log-energy. Then the 
log-energy sequence for each utterance was processed by 
the proposed SEN algorithm described in section 2 or 
some other approaches that will be described in section 4. 
The original 12-dimensional MFCCs (c1~c12) and the 
updated log-energy, plus their delta and delta-delta were 
the components in the finally used 39-dimensional 
feature vectors. Since the proposed algorithm only 
involves the front-end feature extraction, all the 
following procedures for training and recognition are 
identical to the reference experiments stated in the 
AURORA2 documentation [8]. 
4 Experimental Results 
4.1 The results of the energy-processed approaches 
In this subsection, we compare the recognition 
performance of several energy-processing approaches 
including the proposed SEN, Energy Subtraction (ES) [3] 
and two versions of Feature Vector Section (FVS). In 
FVS here, the frames classified as silence are directly 
removed from the utterance without any normalization. 
The first version of FVS uses the speech/silence 
classifier in SEN, and is thus denoted as SEN-FVS, 
while the second makes use of the output of ES method, 
and is thus denoted as ES-FVS. The ES and ES-FVS are 
briefly introduced here. 
The approach of energy subtraction (ES) is quite similar 
to the typical spectral subtraction (SS), and the algorithm 
is stated as follows, 
< > \ if  if  ESESn E n N E n TE n E n TE BC   ¯   ¯¡ ° ¡ °¢ ± ¢ ±  ¯   ¯¡ ° ¡ °¢ ± ¢ ± p ,   (4) 
where E n  ¯¡ °¢ ±  and < >nE  are the original and updated 
energy values of the n-th frame, respectively, TES is a 
threshold , N  is the noise energy estimate, D is the 
over-subtracting factor and C is the flooring factor. In the 
following experiments, both N and TES are set to be the 
average of energy values for the first five frames of each 
utterance, and D and C are set to be 0.95 and 0.05, 
respectively. 
For the approach of ES-FVS, a simple rule based on the 
updated energy values < >\ ^E n  from ES is used for 
frame vector selection. If the two consecutive energy 
values, < >E n  and < >1E n  , are both smaller than a 
threshold TES-FVS, then the n-th frame is classified as 
silence and then discarded. The threshold is determined 
by the following equation, 
	 
 < >
1
1
1
N
ES FVS ES
n
T wT w E n
N 
     ,           (5) 
where N is the number of total frames in an utterance, 
TES is the threshold used in Eq. (4), and 0 1w  . In 
our experiments, w  is set to be 0.4. 
Table 1 shows the averaged recognition accuracy for the 
baseline processing and several approaches stated 
previously for Test Set A (four types of stationary noise), 
and Test Set B (four types of non-stationary noise) of 
AUR
phen
1. Th
th
no
ca
SE
ac
re
fo
be
al
fo
an
2. Th
sim
ab
w
as
ou
ac
no
he
no
an
sim
to
3. W
af
SE
de
Su
po
er
th
(a
re
ve
sil
m
4. Fi
fra
fo
ca
cl
SE
en
fil
so
is 
be
th
w
un
de
th
From
prop
cond
case
INTERSPEECH 2006 - ICSLP
2560ORA2 database. From this table, several 
omena can be observed: 
e proposed approach SEN significantly improves 
e recognition accuracy for both stationary and 
n-stationary noise conditions in almost every SNR 
se. For example, compared with the baseline results, 
N gives 13.57% and 19.28% of absolute word 
curacy improvements for Test Sets A and B, 
spectively. Furthermore, it performs particularly well 
r non-stationary noise conditions since it gives the 
st recognition performance among all approaches in 
most all SNR cases in Test Set B. On the other hand, 
r Test Set A, SEN is especially well for the median 
d low SNR (10dB~0dB) cases.  
e approach ES also performs quite well and very 
ilarly to SEN for Test Set A, and it gives 11.98% of 
solute word accuracy improvement when compared 
ith the baseline result. However, it does not perform 
 well as SEN for Test Set B, although it still 
tperforms the baseline processing by 14.32% of 
curacy rate. One of the possible reasons is that under 
n-stationary noise cases, the noise estimate in ES 
re (simply the average of the first several frames) is 
t very accurate. In addition, the two parameters, D
d C in eq. (4), are set to be constants here for 
plicity, which in fact should be updated according 
 different noise conditions.  
hen implementing frame-vector-selection (FVS) 
ter the classification procedure of SEN (denoted as 
N-FVS in the table), the recognition performance is 
teriorated when compared with that of SEN alone. 
ch results probably tell us that the “detected” silence 
rtions do not always provide us with redundant or 
roneous information for recognition. Modifying 
ese portions (as in SEN) instead of discarding them 
s in FVS) may be a better choice. Another possible 
ason is that the classifier used here does not perform 
ry well, and thus some portions like the 
ence-to-speech or speech-to-silence transitions are 
isclassified as silence and are then discarded.  
nally, observing the results of ES-FVS, where the 
me selection is based on the results of ES, it is 
und that ES-FVS is better than SEN-FVS for all 
ses, which possibly shows that the speech/silence 
assifier in ES-FVS is more reliable than that in 
N-FVS since it depends on the noise-reduced 
ergy sequence < >\ ^E n  in eq. (4) rather than the 
tered log-energy sequence < >\ ^y n . These results 
mewhat coincide those obtained in [6], where FVS 
performed on the noise-reduced features to obtain a 
tter recognition accuracy. Furthermore, we also find 
at ES-FVS outperforms ES only when the SNR is 
orse (0dB and 5dB). One possible reason is that 
der worse SNR conditions, ES is less capable of 
aling with the silence frames, and thus dropping 
em directly as in FVS may be more beneficial. 
 the above, we can roughly conclude that the 
osed SEN performs excellently for almost all 
itions. For example, under high and median SNR 
s, it preserves the energy contour of speech portions 
