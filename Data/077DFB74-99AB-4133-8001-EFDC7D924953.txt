 I 
 
目錄 
一、摘要 .............................................................................................................................................. 1 
二、前言 .............................................................................................................................................. 2 
三、研究目的 ...................................................................................................................................... 3 
四、文獻探討 ...................................................................................................................................... 3 
五、研究方法 ...................................................................................................................................... 6 
5.1 第一年度 ............................................................................................................................... 6 
5.2 第二年度 ............................................................................................................................... 7 
5.3 第三年度 ............................................................................................................................. 11 
六、結果與討論 ................................................................................................................................ 12 
七、參考文獻 .................................................................................................................................... 12 
八、計畫成果自評 ............................................................................................................................ 14 
附圖 .................................................................................................................................................... 16 
附錄：發表於IEEE Transactions on Computers 之論文：Optimal Storage Placement for 
Tree-Structured Networks with Heterogeneous Channel Costs ....................................................... 23 
 
 2 
 
by which efficiently reduces the traffic overhead 
and improves the effectiveness of our data push 
scheme.  
In the last year of the project, we have 
extended the case of locating optimal storage 
node in the first year to a more general situation 
in which there are multiple source nodes. In this 
case, the algorithm developed for the 
single-source scenarios previously is no longer 
adequate. In the project, we have proposed a 
novel algorithm that is based on the notion of 
fully covered nodes for location the optimal set 
of storage nodes. Nevertheless, if there exists no 
fully covered nodes in the network, we have 
also provided an effective mechanism to prune 
the nodes so as to locate the single optimal 
storage node. With rigorous proof and extensive 
simulation, we are confident to say that our 
proposed method is correct and has the best 
performance for the tackled problem. 
Major result of the research has been 
published in IEEE Transactions on Computers. 
Keywords: Data push, heterogeneous channel 
costs, optimal storage problem, tree-structured, 
multicast tree, wireless network. 
 
二、前言 
近年來，通訊快速發展與科技技術的進
步，網際網路的發展也一日千里，除了傳統
的有線網路，其傳輸速度的與日俱進，無線
網路的迅速崛起與普及更令人印象深刻，而
其上的應用也日趨多元與重要。藉由無線網
路的連結，通訊得以不再受限於實體傳輸媒
介，人們可以隨時透過手上的行動裝置，如
行動電話、筆記型電腦、平板電腦等，隨時
隨地取得即時所需的各項資訊。 
隨著這些科技的發展，不同型態的無線網
路也被一一實現，如無線隨意網路(mobile ad 
hoc network)、無線感測網路(wireless sensor 
networks)、身體區域網路(body area network)
等等。其中，尤以無線網狀網路(wireless mesh 
network) 廣為被研究。無線網狀網路希望能
以經濟、有效的方式延伸無線上網的範圍，
讓使用者即使不在基地台的涵蓋範圍內，仍
可連接上網路。此類網路主要是運用預先建
置的無線路由器(mesh router)，藉由這些路由
器與閘道器(gateway)間互相連結，將使用者
的裝置連上網際網路，並形成無線網狀網路
的骨幹(backbone)。而使用者之間則利用多步
轉傳的方式，連接至網路。 
而隨著無線行動計算的蓬勃發展，使用者
最關心的莫過於如何在無線行動環境中快速
獲取想要的資料；事實上，網路通訊的最終
目的往往就是為了幫助使用者獲得所需的資
料，不論是股價、庫存查詢，收發e-mail，或
是社交網路上與朋友分享的訊息等等，這些
都是使用者想即時獲取的資訊。因此，資料
取得的效率成為無線環境的重要關鍵。簡言
之，資料獲取(data retrieval)議題可以看成資料
供給者與資料需求者之間的配對，也就是在
適當的地點與時間，讓資料供給者可以用最
小的通訊成本，將資料交付給需求者。而其
機制可依主動之節點身份將其分為兩類，若
由資料需求者主動尋找資料存放之處取得所
需的資料，此類動作屬於資料拉引(data pull)
的動作。相對的，若由資料供給者主動將其
資料推送至各個資料需求者，此相關動作稱
為資料推播(data push)。兩種機制分別可適用
於不同的網路與資料型態，資料推播可讓資
料來源端主動將熱門資料推播給需求者，而
資料拉引則適合於需求者要求稀少且分散的
情況。本次計畫即是考量在無線網路中最佳
的資料推播機制、資料散佈之研究。 
對傳統實體有線網路而言，由於節點多為
靜態使用者，沒有太多的資源限制，基本上
不需考慮傳輸成本，故資料擷取議題有兩項
基本的作法：(1)可以利用資料供給者主動將
資料散佈到所有的需求節點上即可；(2)亦可
讓資料需求者在想要資料時，主動至資料供
給節點處取得。但在多數無線網路環境下，
通常都伴隨著資源上的限制，如通訊頻寬有
限、行動裝置的電力、計算能力、記憶體容
量有限等等，太過度的使用這些資源將造成
硬體與頻寬的損耗。故在設計無線資料獲取
的機制時，勢必需將這些限制加以考量，才
符合無線網路之用。 
如在一無線感測網路中，存在有一資料匯
集點x儲存有整體平均溫度與濕度資訊，若x
每次都主動將資訊推播到所有節點，會使得x
及鄰近節點的電力消耗快速，網路的存活時
間縮短，同時亦會有廣播風暴 (broadcast 
storm)[40]的問題產生。而若每個節點採詢問
方式向x取得資料，亦會造成過高的通訊成
本，長時間的通訊延遲等等問題。此外，無
線網路還有一可能的限制為通訊成本的異質
性，意即網路的雙向溝通成本不對稱。傳統
網路多為對稱性網路，沒有不平等的通訊問
題。 
再者，由於無線網路的溝通媒介是開放
的，傳播方式也多以廣播為主，故會造成多
 4 
 
可以藉由中繼播放伺服器轉播串流資料，以
達到分流的效果，以平衡伺服器的負載量，
減低服務的延遲時間，也可增加服務的回復
力（resiliency）。 
針對上述的置放問題，先前大部分所提出
的方法多將之轉為圖論的p-重心（p-median）
以及p-中心(p-center)問題，並以approximation
方式解決之[8][33]。所謂p-median問題，簡單
來說，即是在具有n個節點的網路上，放置p
個伺服器，且要求所有節點的服務距離總和
必須越小越好，以達成伺服器最有效率的配
置。而p-center問題，則希望讓所有使用者節
點至最靠近本身之伺服器的服務距離裡，最
遠的那一段距離能夠越短越好。此外，也有
研究者提出貪婪演算法(greedy algorithm)解
決此類問題[17]。 
在[18]的研究中，作者針對樹狀結構網路
環境，在節點儲存空間有限的考量下，思考
如何置放資料副本，使得整體網路的讀和寫
資料花費成本以及資料儲存成本總和達到最
小。其中，讀取資料時，都到離自己最接近
的節點上去取得資料，而資料在做更新寫入
時，必須要能更新網路中所有儲存節點的資
料。就此，作者提出了一O( 23 pn )的演算法，
尋找p個最佳化的儲存節點群來存放資料，以
提供網路上所有n個節點讀取資料之用。論文
中，更進一步假設每個節點的資料儲存上限
為，並針對此限制，提出了一個時間複雜度
為O( 2max23 pn )的演算法，來置放資料副本。
作者將 [20]中所提出用於解決樹狀結構上
p-median問題的方法加以延伸，採用動態規劃
法(dynamic programming)的方式，來尋找最佳
的儲存節點。 
在 [6] 的研究中，作者針對網內查詢
(in-network query)系統中，如何將中繼節點配
置到最佳的位置，以幫忙執行資料篩選、關
連性處理和資料彙集，減少網路中的交通量
的問題加以探討。作者利用交換啟動operator
和暫時operator的成本訊息和資料，再藉由區
域性搜尋(localized search)方式，以適應性又
分散式的方法解決此問題。啟動operator會持
續地去估算其相關暫時operator的成本，如果
最小成本的暫時operator小於啟動operator的
成本，則最小成本的暫時operator就變為啟動
operator。由於其決定權在於各層的operator，
因此，可以用分散式的做法；不過，此方法
有可能找不到最佳解的風險。 
在先前的研究裡已經包含了不同成本環
境的模組。在[13]之中，Fisher與Hochbaum考
慮一個簡單寫入策略，將資料來源所產生的
資料送至每一個中繼儲存點，因此造成資料
從資料來源至寫入中繼儲存點的成本總和過
於龐大。而在[45]之中，寫入策略類似群撥
(multicast)一般，使得資料從來源點傳送至中
繼儲存點時，若經過相同的路徑不必重複傳
送資料達到減少成本的作用。除了大部分研
究文獻都只考慮資料傳輸成本，Li也在[27]之
中將資料儲存於中繼儲存點的成本算入考
量。在現有的研究當中，幾乎都是假設同質
頻道(homogeneous channel)成本，但這個假設
並不適用於許多的無線網路之中。而在此研
究之中，我們將考量異質頻道(heterogeneous 
channel)成本，即每一段點與點之間連結與資
料傳輸方向的通訊成本皆不同的情況。 
類似的問題也存在於網頁環境之中，在
[35][42][43]之中考量了網頁代理伺服器(Web 
proxy)合作分享網頁於記憶體之中的環境。由
於各伺服器的記憶體存放空間有限，通常這
些伺服器會各自儲存一些網頁資料，並針對
使用者的服務請求做出回應；在此，一項重
要的問題是如何將資料網頁配置到適當的代
理伺服器身上，幫助附近的節點取得其所需
的資料，以減少交通量；同時也考慮某一區
域內，需求節點都可以找得到擁有所需資料
的伺服器，以避免繞到比較遠的伺服器中取
得其所需的資料。在[43]之中介紹了Internet 
cache protocol (ICP)，在代理暫存器與需求回
應模組之間的訊息管理。而資料複製技術
(Data replication)與資料暫存(Data Caching)也
是被廣泛研究的方法[15][26][46]，目的是在
無線網路環境之中有效的提升資料傳播，我
們將在稍後資料擷取、散佈部分做更深入的
說明。 
在[29]之中，也研究了在大規模點對點
(peer-to-peer)網路環境之中資料於附近節點
的分享與儲存。一般來說點對點網路分成結
構式 (structured)與非結構式 (unstructured)兩
類。在結構式點對點網路之中，[39][49]以合
作方式將分散式雜湊表充分的利用於滿足特
定的位置與直接的需求。在非結構式點對點
網路之上，將資料隨機方式儲存於某地點，
而需求者通常以氾濫傳輸(flooding)的方式需
求資料，如Gnutella在[50]中所提出。在這樣
的網路之中，我們的研究方向與此處所談資
料傳播、資料回復等都息息相關，而資料能
於此環境中被放置任何一地點，相對於我們
所關注的資料儲存中繼點也有著密切著關
係。 
除了最佳的儲存置放位置外，網路中資料
如何擷取、散佈亦是其中關鍵的課題。有關
 6 
 
[48] ； 這 些 方 法 大 多 利 用 近 似 比 值
(approximation ratio)來衡量演算法的優劣，例
如在[24][32]中所提出的啟發式演算法，同樣
得到2-approximation的成果，而在[34]和[48]
的研究中，他們進一步獲得較佳的結果，分
別為11/6-approximation和3/2-approximation。
此處所謂的近似比值即為啟發式演算法可獲
得的成本與最佳化的成本所形成的比值
)(
)(
Xopt
XA  (此式中，X代表問題的一個案例，A
是一個啟發式演算法，而A(X)為演算法A對於
X所得到的解的成本，opt(X)則為最佳化的解
的成本)。 
雖然最小斯坦納樹問題被廣為研究，但是
由於沒有將無線網路廣播的特性考慮進去，
所以當應用於無線網路時，沒有辦法令其頻
寬的利用充分發揮。舉例而言，在圖二(a)中，
若以最短路徑的方法尋找群播樹以推播資料
至一群節點，需要傳送4次的封包；若以建立
斯坦納樹的方法，如圖二(b)所示，則一樣需
要傳送4次的封包；不過，若是以最小化傳遞
節點數量為概念建立群播樹的話，如圖二(c)
所示，則只需3次的封包傳送，可達到最小的
封包傳遞數量。 
由上述例子可得知，在無線網路環境中要
將資料推播到一群資料需求節點，頻道廣播
特性的考量是非常重要的。在加入此特性的
考量下，針對推播成本的計算應重新定義為
最 小 化 傳 遞 節 點 的 數 量 (minimizing the 
number of relay nodes)，而非像以往只考慮最
小化傳遞鏈結數(minimizing the edge cost)。在
[36]的研究中，作者針對無線網狀接取網路的
環境建立出一棵具有最小頻寬消耗的群播
樹，其中亦證明了最小化群播樹的轉傳節點
為一個NP-hard的問題，接著，提出了兩個啟
發式演算法，其一是針對集中式無線網狀網
路(centralized wireless mesh network)，另一是
針對分散式無線網狀網路(distributed wireless 
mesh network)。首先，第一個演算法分成兩
個不同的步驟，第一步為建立多棵成本最佳
化子樹(cost-efficient subtree)，再來則建立一
棵斯坦納樹，將子樹的根節點互相連結起
來。在第一個步驟中，資料需求節點需要選
擇某個節點，使其成為轉傳節點，而此轉傳
節點需要能覆蓋兩個或兩個以上的資料需求
節點或是轉傳節點，才會有資格被選中。在
建立最佳化子樹的過程中，會重複執行到所
有的資料需求節點和轉傳節點都被其他的節
點覆蓋，或是無法再找到其他兩個以上的資
料需求節點或轉傳節點時，才會停止。由於
網路中所有的節點都會執行此演算法，因
此，會建立出許多不同的子樹(subtree)，最
後，這些子樹的根節點(root)再藉由建立斯坦
納樹的方式互相連結。 
針對第二種分散式網路環境建立最小成
本子樹的概念與先前集中式的演算法大同小
異。最大的差別在於完成子樹的建立後，後
者的子樹根節點能夠得知整體網路的metric 
closure，利用這些資訊可建立出一棵最小生成
樹(minimum spanning tree)，且所有的邊都是
子樹根節點連接的最短路徑。但由於在分散
式網路中metric closure的建立是很困難的，於
是作者利用資料擁有者所屬之子樹的根節點
發送一個RREQ訊息至網路中並會隨著傳遞
增加其步數，當網路中的子樹根節點收到
RREQ時，即會將最小步數利用RREP回傳至
發送端，且沿路的節點都會變成轉傳節點。
除此之外，子樹的根節點將會把步數的欄位
重設為零，繼續發送RREQ，藉此方式達成近
似最小生成樹的建立方法，讓所有的子樹彼
此皆能互相連接。然而，於分散式網路中，
所有子樹何時建立完成這項資訊很難被獲取
到，而子樹根節點間連線的建立需依賴網路
穩定後才能完整建立出一棵樹，此機制在分
散式的網路中可能不容易達成最佳化。 
 
五、研究方法 
在本計畫中，第一年著重在樹狀網路結構
上，針對僅有單一資料來源節點時，尋找最
佳的資料儲存置放節點。第二年則善用無線
廣播的特性，提出有效率的資料推播機制以
減輕系統整體的交通量。第三年則進一步將
網路中最佳的資料儲存置放節點問題延伸至
具有多個資料來源的情況。詳細內容以下分
年概述。 
 
5.1 第一年度 
 在第一年度的研究中，我們專注在樹狀
網路結構上，如何尋找最佳資料儲存置放節
點，即尋找網路中最佳的資料儲存中繼節點
群，來達到最低的網路負擔。在第一年度中，
我們主要是以單一資料來源節點做為研究重
點，並加以考量網路的異質性。 
5.1.1 網路模型 
在我們的系統模型中，網路為一個樹狀結
構，稱之為 T。在 T 中，存在有一個資料來源
節點(source node) s，而節點 s 以 Gs(次/單位時
間)的速率產生資料，在此，Gs 簡稱為資料頻
 8 
 
及系統整體的交通量；如此可以用最節省的
方式將資料推播至最佳置放點。 
 我們首先會從單一閘道器開始，考慮如
何以最低推播成本建立群播樹，再延伸至多
個閘道器的情況。群播樹的建立是由節點們
發起，分散式的蒐集各自的廣播涵蓋範圍與
資料供給來源，以啟發式的過程完成群播樹
的建立。 
5.2.1 單一閘道器資料推播 
資料推播機制由三個步驟所組成：（1）資
料轉傳節點的選擇；（2）子樹與子樹之根節
點間的連結；（3）多餘轉傳節點的移除。以
下將依各步驟的執行循序解釋之： 
（1） 資料轉傳節點的選擇： 
我們知道無線網路具有廣播的特性，亦即
節點只需廣播一次資料，則其一步鄰居均可
接收到，故我們的作法是讓資料需求節點選
擇可以涵蓋較多資料群組節點的點當成轉傳
節點，以達到降低傳輸成本的目的。另一方
面，我們假設網路中每個節點皆具有與網路
閘道器距離的資訊，因此，當其鄰居所涵蓋
資料需求節點數一樣時，由於資料最終還是
由網路閘道器推送出來，所以，我們希望選
擇距離網路閘道器越近越好的節點，以減少
中途轉傳節點的產生，節省傳輸成本的消
耗。而這些轉傳節點亦會透過遞迴的方法找
尋新的轉傳節點，最終，網路裡將會建立出
多棵不相連的子樹。 
圖五為選擇資料轉傳節點的演算法。首
先，資料需求節點為了尋找一個適當的涵蓋
者，將會發出 JOIN 的訊息給其一步鄰居，這
些鄰居亦會回覆 JOIN_ACK 的訊息給資料需
求節點，裡面包含其收到之 JOIN 封包數量統
計值及與網路閘道器距離的步數。接下來，
資料需求節點會根據此訊息挑選出涵蓋大於
二以上且涵蓋量最大者的資料需求節點作為
轉傳節點，但是，若遇到涵蓋資料需求節點
數量相同的情況下，資料需求節點將會加以
判斷與網路閘道器的距離，進而挑出與網路
閘道器相近者為轉傳節點。確定挑選何者為
其轉傳節點時，資料需求節點將會發送
JOIN_ACT 至其一步鄰居，告知其鄰居它已選
擇了涵蓋量最大的節點為其轉傳節點，並將
此轉傳節點設為自己的父節點。而這些轉傳
節點間亦將透過遞迴的方法，依據上述步
驟，找尋新的轉傳節點。需特別注意的是，
已經選擇父節點的資料需求節點將不可回覆
他人的 JOIN 訊息，以避免產生迴圈。在此步
驟中，網路上將形成多棵不相連之子樹。如
圖六(a)所示，G 為網路閘道器(亦即資料供給
節點)，且網路中存在著 R1、R2、R3、R4 和 R5
這五個資料群組節點。R2、R3、R4 和 R5 選擇
涵蓋資料需求節點較多的 V2 作為其父節點，
形成一個以 V2 為根節點的子樹;而 R1 則選擇
V1 為其父節點形成另外一棵子樹，而形成此
兩棵不相連的子樹，如圖六(b)所示。 
（2） 子樹與子樹之根節點間的連結： 
由於上述轉傳節點的選擇會使得網路上
形成多棵不相連的子樹，為了使其成為一棵
完整的群播樹，我們必須要將這些不相連的
子樹之間互相連接。 
圖七為子樹和子樹之根節點間連結的演
算法，首先，我們將由網路閘道器所存在的
那棵子樹的根節點將 RREQ 封包 flooding 至
網路中，且裡面包含步數的資訊，步數之初
始值設為零。假設網路中，節點 V 收到由節
點 V＇發送出的非重複 RREQ 封包且其擁有
較小的步數，則節點 V 將會把節點 V＇記錄
為本身的上一步，亦即 V＇成為節點 V 的父
節點。假如，節點 V 非子樹中的根節點，節
點 V 會將先前所收到非重複的 RREQ 封包中
最小的步數再加 1，繼續發送出去；但，若節
點 V 為子樹中的根節點，節點 V 將會把自己
的步數歸為零之後，除了繼續發送 RREQ，尚
會回覆 RREP 至其鄰居，若其鄰居節點 V＇為
節點 V 的上一步，則節點 V＇的身份將變成
轉傳節點，RREP 會一直回傳達至網路閘道器
存在之子樹的根節點為止，且 RREP 回傳沿
線的節點皆會成為轉傳節點。 
如圖八所示，G 發送帶有步數資訊為零的
RREQ 封包至網路中，由於 V1 和 V2 皆為子樹
的根節點，因此，當收到 RREQ 封包時會立
即回覆 RREP 至其鄰居，當他們的父節點收
到 RREP 封包時，亦會重複同樣的動作，如
此遞迴的執行下去，形成 V1 和 V2 都是藉由
R2 和 V4 到達網路閘道器，最後建出一棵完整
的群播樹。 
（3） 多餘轉傳節點的移除： 
雖然以涵蓋資料需求節點數較多的節點
為轉傳節點，在大部分的情形下，可以達到
 10 
 
者的多寡，我們所要優先考量的重點依舊在
於節點涵蓋資料需求節點數量的多寡，若節
點涵蓋越多資料需求節點者，其所能發揮的
效益則越大。所以，在初步建立子樹時，我
們仍以節點涵蓋資料需求節點的數量作為選
擇轉傳節點的主要依據，如圖十一所示，R1、
R2、R3 和 R4 皆選擇涵蓋資料需求節點較大的
V2 當他們的轉傳節點；R5 和 R6 亦根據相同準
則選擇 V5 當轉傳節點。而當資料需求節點都
已找尋到轉傳節點而形成多棵的子樹後，該
如何讓子樹根節點和子樹根節點間互相連
結，又是另外一個考量的重點。 
子樹的根節點為再也找不到可以涵蓋兩
個以上的資料需求節點或轉傳節點的節點去
涵蓋其本身而形成，因此，這些根節點與網
路閘道器之間需要有一條適當的路徑相連，
更明確的來說，是希望挑選一條產生轉傳節
點數量較少的路徑。若我們延續單一網路閘
道器的做法，從兩個網路閘道器分別執行圖
七的演算法各自建立出群播樹，從圖十二(a)
來看，V1 距離 G1 為三步比距離 G2 較為近，
因此 V1 會先收到 G1 所發送的 RREQ，並會立
即回覆 RREP 建立出通往閘道器的路徑；V3
也依據同樣做法與 G2 相連。而 V2由於會先收
到 G2 所送的 RREQ 封包，因此，V2 會回覆
RREP 尋找到一條路經到達 G2。但若讓 V2與
相鄰近的轉傳節點 V1 相連的話，網路中所耗
費的資料推播成本將由圖十二(a)的 10個轉傳
節點，變成圖十二(b)的 9 個轉傳節點。 
圖十二(b)比圖十二(a)所花費的成本較少
的主要是因為，V2 只收到其中一個閘道器所
發送的封包時就立即回覆 RREP 建立出路
徑，雖然，時間再久一點它就可知道附近其
實存在一個比網路閘道器更近的轉傳節點，
但卻也無法去除原本的路徑而與較近的轉傳
節點連接，因此，我們將單一閘道器中的子
樹間根節點連接演算法稍做修改。在多個網
路閘道器的環境裡，由於，子樹沒有蒐集完
整的資訊即做判斷才會導致挑選到一條成本
較高的路徑，因此，我們只要讓子樹根節點
稍等待一段時間，收到各個閘道器的封包之
後再做挑選路徑的判斷，以期挑選出一條產
生轉傳節點數量較少的路徑，降低推播成本
的耗費。 
在初步完成群播樹的建立後，不論是處於
單一閘道器的環境或多個閘道器的環境，多
餘轉傳節點的產生都是無可避免的，但由於
這些多餘轉傳節點不管是在哪一種環境底下
都具有相同的特性，亦即其一步鄰居的資料
需求節點或轉傳節點可以由其他的轉傳節點
收到重複的資料。因此，我們可延續單一閘
道器所研擬出的移除多餘轉傳節點方法，去
除這些多餘的轉傳節點即可。 
5.2.3 演算法效能評估 
我們將所提出的資料推播方法和 shortest 
path tree (SPT)與 MNT2[36]兩種方法予以比
較，以評估其效益。而觀察的重點在資料推
播時所需的轉傳節點數量，這些轉傳節點數
量決定了資料在網路中需被廣播的總數。而
轉傳節點越少，表示資料推播時節點通訊量
跟著降低，不但能減少資料推播的成本，亦
能有效的利用網路頻寬，更甚者，網路中節
點的生存時間也相對的提高。 
圖十三顯示在單一閘道器的情況下，三種
方法轉傳節點數量的比較結果。從圖中可
見，由於 SPT 的方法是直接找最短路徑到達
資料供給節點，並非是以建立一棵低成本的
群播樹為目的，因此，其所需要的轉傳節點
遠多於其他兩個機制。而在需求節點數量小
的情況下，由於環境中的資料使用者稀少，
且隨機分佈，使得幾乎所有轉傳節點都不能
少，故我們的方法比起 MNT2 沒有太顯著的
改善。然而，隨著需求節點增加，節點被選
擇為轉傳節點的機會增高，從圖中可見，我
們的機制可以有效地將多餘的轉傳節點移
除，以最少的轉傳節點，有效率地將資料推
播出去。 
接著在多個閘道器的環境下，若節點單以
到網路閘道器的距離(步數)作為分組建立群
播樹的依據的話，則可能會因為位於兩閘道
器中間部分的節點，雖可被同一轉傳點覆
蓋，卻因所屬閘道器不同，而被迫找尋另外
一個屬於相同閘道器的轉傳點來涵蓋其本
身，造成多餘轉傳點的產生。圖十四顯示我
們的機制與以距離分組的機制在轉傳節點數
量上之比較。我們的方法可以有效避免上述
多餘轉傳點的產生，且在根節點相連的階
段，亦能找到最近的轉傳點與之相連。故我
們的方法可達到最有效率的資料推播。 
 
 12 
 
5.3.3 演算法效能評估 
我們將所提出的最佳中繼置放節點群演
算法，與其他的兩種方法做比較：其一是
QP_First，其作法為將有最大 source rate 與
query rate 的總和之節點，視為初始的儲存
點；接下來以此節點為起始，若其鄰居也成
為置放點亦能減少通訊成本的話，也將其鄰
居加入為一中繼置放點。依此反覆執行，直
到沒有節點的加入，可以再減少通訊成本為
止。第二種方法稱做 Pull，此法則是以拉引為
基礎的演算法。其作法為，網路中的節點在
需要資料時會發出查詢，主動從來源節點將
資料拉引回使用者端。在 Pull 演算法部分，
我們配合資料聚集的機制，讓資料可以稍作
整合，再送回給查詢節點。 
圖十九為模擬的結果之一，橫座標為每個
節點成為來源端的機率(source probability)，縱
座標為總通訊成本。Pull 的機制，因為其以拉
引為主，所以沒有資料推播(push)的成本。我
們的方法與 QP_First 則同時有資料查詢與推
播的成本。顯而易見地，當 source probability
越大時，所有方法的通訊成本都跟著提高，
Pull 的結果最糟，因為當節點要資料時，總是
需要到來源端去索取。QP_First 與我們的方
法，隨著 source probability 增加，差異也越發
明顯。此外，我們的方法所需的置放點數，
也比 QP_First 來得較少。 
 
六、結果與討論 
本計畫為三年期的計畫，計畫執行結果，
第一年進行基本的無線網路研究與較為簡單
的網路最佳中繼置放節點群之尋找。其考量
網路的通訊成本異質性，配合單一資料來源
與需求頻率，找出網路中最佳的資料置放位
置，以達到降低總體傳輸成本。 
第二年則以有了已知的置放節點群為發
想，考量如何以最有效率的方式，將資料推
播至該中繼節點群。其中的關鍵在於轉傳點
的選擇，具有最小轉傳，最佳覆蓋率的節點
們可形成一低成本群播樹，達到最佳的群播
效果。 
第三年度的研究內容主要是第一年度研
究之延伸，令其可套用至一般更普遍的無線
網路情況。而植基於前兩年度的研究基礎之
上，本年度將單一資料來源的限制，放寬至
有多個來源的情況。由於多個資料來源將使
網路環境更趨複雜，已無法簡單套用之前為
單一資料來源所設計的演算法。 
在我們的深入探討之下，發現能以一節點
是否覆蓋其鄰居節點這個觀念作為演算法設
計的關鍵處。若網路中存在有被完全覆蓋的
節點，則此類節點必然是最佳的中繼置放節
點群中的一員；若網路中不存在有被完全覆
蓋的節點，則我們首先證明至少有一最佳節
點群只包含一個單一節點，而我們亦發展了
一個有效的演算法，以削減的方式，找出最
佳的中繼置放點。 
本研究亦佐以大量的證明與多樣的模
擬，來驗證其正確性、可行性與效能，整體
而言，具有其相當之貢獻。 
總體而言，我們的研究工作有不錯的產
出，也達成原先預定的目標。除了學術論文
的發表之外，我們也將主要技術提出申請我
國專利。 
 
七、參考文獻： 
[1] C. Aggarwal, J. Wolf, and P. Yu, “Caching 
on the World Wide Web,” IEEE Trans. on 
Knowledge and Data Eng., vol. 11, no. 1, 
Jan./Feb., 1999. 
[2] Y. Ahmad and U. Cetintemel, 
“Network-aware Query Processing for 
Stream-based Applications,” in Proc. of 
VLDB, 2004. 
[3] I. F. Akyildiz, Xudong Wang, and Weilin 
Wang, “Wireless Mesh Networks: A 
Survey,” Computer Networks, vol. 47, 
Issue 4, pp. 445-487, Mar. 2005. 
[4] J. E. Beasley, “Lagrangean Heuristics for 
Location Problems,” European Journal of 
Operational Research, vol. 65, no. 3, 1993. 
[5] J. Berst, “What’s all wrong with today’s 
push technology,” ZDNet Anchor Desk, 
http://www5.zdnet.com/anchordesk/story/, 
1997. 
[6] B. Bonfils and P. Bonnet, “Adaptive and 
Decentralized Operator Placement for 
In-network Query Processing,” in Proc. of 
Information Processing in Sensor 
Networks, April 20, 2003. 
[7] G.-M. Chiu and C.-R. Young, “Exploiting 
In-Zone Broadcasts for Cache Sharing in 
Mobile Ad Hoc Networks,” IEEE Trans. 
Mobile Computing, vol. 8, no. 3, pp. 
384-397, 2009. 
[8] S. Choi and Y. Shavitt, "Proxy Location 
Problems and Their Generalizations,” in 
Proc. of Int’l Workshop on New Advances 
 14 
 
1981. 
[33] L. Qiu, V. N. Padmanabhan, and G. M. 
Voelker, “On The Placement of Web Server 
Replicas,” in Proc. of IEEE INFOCOM, 
Apr. 2001. 
[34] S. Rajagopalan and V. V. Vazirani, “On The 
Bidirected Cut Relaxation for The Metric 
Steiner Tree Problem,” in Proc. of the 10th 
Annual ACM-SIAM Symposium on 
Discrete Algorithms, pp. 742–751, 1999. 
[35] K. Ross, “Hash Routing for Collections of 
Shared Web Caches,” IEEE Networks, 
1997. 
[36] P. M. Ruiz and A. F. Gomez-Skarmeta, 
“Heuristic Algorithms for Minimum 
Bandwidth Consumption Multicast Trees 
in Wireless Mesh Networks,” Ad-Hoc, 
Mobile, and Wireless Networks, vol. 3738, 
pp. 258–270, Oct. 2005. 
[37] K. M. U. Srivastava and J. Widom, 
“Operator Placement for In-network 
Stream Query Processing,” in Proc. of 
PODS, 2005. 
[38] W. R. Stevens, TCP/IP Illustrated, Volume 
1: The Protocol. Addision-Wesley, 1994. 
[39] I. Stoica, R. Morris, D. Karger, M. F. 
Kaashoek, and H. Balakrishnan, “Chord: A 
Scalable Peer-to-peer Lookup Protocol for 
Internet Applications,” IEEE/ACM Trans. 
on Networking, vol. 11, no. 1, 2003. 
[40] Y.C. Tseng, S.Y. Ni, Y.S. Chen and J.P. 
Sheu, “The Broadcast Storm Problem in A 
Mobile Ad Hoc Network”,  ACM Wireless 
Networks, vol. 8, no. 2, pp. 153-167, Mar. 
2002. 
[41] D. Waitzman, C. Partridge, and S. E. 
Deering, “Distance Vector Multicast 
Routing Protocol,” RFC 1075, Nov. 1988. 
[42] J. Wang, “A Survey of Web Caching 
Schemes for The Internet,” SIGCOMM 
Computer Communication Review, vol. 29, 
no. 5, pp. 36–46, 1999. 
[43] D. Wessels and K. Claffy, “ICP and The 
Squid Web Cache,” IEEE Journal on 
Selected Areas in Communication, vol. 16, 
no. 3, pp.345-357, April 1998. 
[44] J.E. Wieselthier, G.D. Nguyen, and A. 
Ephremides, “Energy-efficient Broadcast 
and Multicast Trees in Wireless 
Networks,” Mobile Networks and 
Applications, pp. 481-492, 2002. 
[45] O. Wolfson and A. Milo, “The Multicast 
Policy and Its Relationship to Replicated 
Data Placement,” ACM Trans. on Database 
Systems, vol. 16, no. 1, pp. 181-205, Mar. 
1991. 
[46] L. Yin and G. Cao, “Supporting 
Cooperative Caching in Ad Hoc 
Networks,” IEEE Trans. on Mobile 
Computing, vol. 5, no. 1, Jan. 2006. 
[47] C.-R. Young and G.-M. Chiu, “Efficient 
Dissemination of Transaction-Consistent 
Data in Broadcast Environments,” IEEE 
Trans. on Knowledge and Data 
Engineering, vol. 19, no. 3, pp. 384-397, 
March 2007. 
[48] A. Zelikovsky, “An 11/6-approximation 
Algorithm for The Network Steiner 
Problem,” Algorithmica, no. 9, pp.463–470, 
1993. 
[49] B. Y. Zhao, L. Huang, J. Stribling, S. C. 
Rhea, A. D. Joseph, and J. D. Kubiatowicz, 
“Tapestry: A Resilient Global-scale 
Overlay for Service Deployment,” IEEE 
Journal on Selected Areas in 
Communication, vol. 22, no. 1, Jan. 2004. 
[50] Gnutella Protocol Development, “Gnutella 
0.6 RFC,” June, 2002. [Online]. Available: 
http://rfc-gnutella.sourceforge.net/src/rfc-0.
6-draft.html. 
 
八、計畫成果自評： 
本計畫為三年期的計畫，計畫之目標為針
對無線網路的資料獲取議題，尤其是最佳化
的資料推播問題，做一整體且深入的了解，
進而研發新穎且有效率的無線網路資料推播
機制，並做詳細的效能與成本評估。 
計畫成果在學術研究方面，主要是探討於
樹狀無線網路下，如何找出整體無線通訊成
本最少的資料儲存節點(storage nodes)，使網
路傳輸成本最少化。研究的目標對於電力供
應、通訊頻寬等資源有限的無線網路來說，
都具有相當的重要性，例如無線感測網路
(WSN)、ZigBee-based networks或body area 
networks等。此一最佳儲存置放問題與經典的
倉儲問題 (warehouse problem)有密切的關
係，我們主要的貢獻是把此問題完全一般化 
(generalized)，提出一項節點間的覆蓋觀念，
基於此覆蓋觀念，從一新的思維方向，發展
出一套時間複雜度為O(N)的最佳化演算法。
其中，N為網路中的節點個數。此一方法打破
了先前研究所面臨的瓶頸，特別是在通訊成
 16 
 
附圖： 
 
圖一 媒體廣播示意圖 
 
   
(a) Shortest Path Tree 
4 Tx/packet 
(b) Steiner Tree 
4 Tx/packet 
(c) Min. Data Overhead 
3 Tx/packet 
圖二 資料推播議題例子 
 
 
圖三 最佳中繼置放群 Single Source 演算法 
 
Algorithm Single_Source(T) {   /* s is the source node */ 
1 WQ ← ; 
2 for (each node i (≠s)) { 
Ri ← ri; 
aggreg_count[i] ← degree(i) – 1; 
if (aggreg_count[i] = 0)  /* edge node */ 
add (node i) to WQ; 
} 
3 while (WQ ≠  ) { 
remove (node x) from WQ; 
y ← sn(x); 
Ry ← Ry + Rx; 
aggreg_count[y] ← aggreg_count[y] – 1; 
if (y≠s   aggreg_count[y] = 0)  
add (node y) to WQ; 
} 
4 storage_set ← {s} ∪ {i | Ri > Gs}; 
} 
 18 
 
 
 
圖七 子樹和子樹之根節點間連結的演算法
 
R2
R3
R4
R5
V1
V2
V6
V7
V8
V9 V10
V11
V12
V13
V3
R1
V15
V4
G
V14
V5
  
 
圖八 資料群播樹建立之示意圖 
 
 
  
(a) (b)  
   
圖九 多餘轉傳節點移除之示意圖 
 20 
 
0
10
20
30
40
50
60
70
10 20 30 40 50 60 70 80 90 100
number of receivers
nu
m
be
r o
f t
ra
ns
im
is
si
on
s
MNT2
OUR
SPT
 
圖十三 單一閘道器下轉傳節點數量之比較圖 
 
20
30
40
50
60
70
80
10 20 40 60 80 100 120 140
number of receivers
nu
m
be
r o
f r
el
ay
 n
od
es
Group
OUR
 
圖十四 多個閘道器下轉傳節點數量之比較圖 
 
 
圖十五 Multiple Source 演算法，此為具有被完全覆蓋節點的演算法。 
Algorithm Multiple_Source(T) {   
1. F  the set of all nodes in T; 
  ; 
for (each ch(i, j)  T) { 
if (S(j, i) < R(i, j)) 
   ∪ {j}; 
else 
F  F – {i};  /* i is not fully-covered */ 
} 
2. if (F  ) 
  F; 
else        /* no fully-covered node */ 
  NoFullCov(); 
} 
 22 
 
 
 
圖十八 沒有被完全覆蓋節點的例子，s1 和 s2 是來源節點， 
g1 和 g2 分別是 s1 與 s2 的資料頻率。 
 
 
 
0
5000
10000
15000
20000
25000
30000
35000
Ou
rs
QP
_F
irs
t
un
it_
ag
gr
β
=0
.2
β
=0
.6
β
=1
.0
α
=0
.4
α
=0
.8
Ou
rs
QP
_F
irs
t
un
it_
ag
gr
β
=0
.2
β
=0
.6
β
=1
.0
α
=0
.4
α
=0
.8
Ou
rs
QP
_F
irs
t
un
it_
ag
gr
β
=0
.2
β
=0
.6
β
=1
.0
α
=0
.4
α
=0
.8
Ou
rs
QP
_F
irs
t
un
it_
ag
gr
β
=0
.2
β
=0
.6
β
=1
.0
α
=0
.4
α
=0
.8
Ou
rs
QP
_F
irs
t
un
it_
ag
gr
β
=0
.2
β
=0
.6
β
=1
.0
α
=0
.4
α
=0
.8
10%                                           30%                                          50%                                          70%                                           90%
Souce probability
co
m
m
un
ica
tio
n c
os
t
Pull
data query cost
data push cost
 
 
圖十九 多個資料來源之下，通訊成本與 source 機率之比較圖。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
power when they communicate with each other, thus
leading to different degrees of interference to the network.
These differences should be reflected by distinction of
the associated communication costs. However, it remains
unknown how to find an optimal storage set for networks
with heterogeneous channel costs.
In this paper, we generalize the optimal storage problem
for a tree-structured network by considering heterogeneous
channel costs. We have identified necessary and sufficient
conditions for an optimal storage set for the network. In
particular, we introduce the notion of fully covered node for
this purpose in the case of multiple sources. The proposed
algorithm only incurs a linear time cost. Extensive simula-
tions have been conducted to validate the algorithm and
evaluate its performance.
Rest of this paper is organized as follows: Section 2
surveys related work and Section 3 presents network model
and problem definition. In Section 4, we discuss how to deal
with the problem with only one source node. Then in
Section 5, we tackle the problem for the case of multiple
sources. Correctness of the proposed algorithm is rigor-
ously proved. Performance of the proposed algorithm is
evaluated by extensive simulations in Section 6. Section 7
discusses related issues that are not specifically addressed
in previous sections. The last section concludes this paper
and discusses future research directions.
2 RELATED WORK
The storage placement problem can be found in various
contexts of research areas such as the warehouse location
problem in operations research [1], [2], [29], the file
assignment problem for database systems [4], [5], web
caching and peer-to-peer (P2P) applications in computer
networks [7], [26], and data query in sensor networks [10],
[11]. These studies resolve the storage location problem on
different facilities or network platforms with a variety of
purposes and restrictions.
The warehouse location problem has been studied
extensively in the literature. The aim of the problem is to
select a number of cites on a map as warehouse locations
such that cost of transporting goods from factories to
customers is minimized [1], [2], [14]. The problem has been
proven NP-complete for general graphs and solvable in
polynomial time for trees [14]. Our problem differs from the
warehouse location problem in that, in our problem, each
storage node must store data originated from all source
nodes and one request node simply retrieves data from the
storage node that is closest to itself. In contrast, in the
warehouse location problem, goods produced by a particular
factory may be transported and stored in different ware-
houses. A customer can get goods from different warehouses
as long as total amount of the goods satisfies its demands.
The file assignment problem has also been investigated
for distributed database systems [5], [12], [13], [30]. In this
problem, data generated by a set of source nodes in a
network are replicated to a number of storage nodes. A
query node can retrieve replicas from the nearest storage
node to increase retrieval speed. A number of cost
evaluation models have been studied for this problem.
For instance, Fisher and Hochbaum considered a simple
write policy, where a separate copy of the data generated by
a specific source node is sent to each storage node [5]. The
total write cost is, therefore, sum of the distances from each
source node to each of the storage nodes. In [13], the write
policy is modeled similar to multicast in the sense that each
piece of data is sent to multiple storage nodes via multicast
communication. While most of the studies consider only
data transmission cost, data storage cost is specifically
included in the cost model in [12]. These studies are closely
related to ours in that they also address the problem of
storage placement in a network and have similar objective
to ours. However, all of them assume that the communica-
tion cost is homogeneous in either direction between two
neighbor nodes, while heterogeneous communication costs
are considered in our network model to reflect realistic
network environments.
Along with pervasive use of the Internet, web, and P2P
applications are gaining popularity among today’s Internet
users who are desperate for increasing download speed.
Web proxies are used to cooperatively cache and share web
contents [15], [17], [31], [32], [33]. For P2P overlay networks,
Distributed Hash Table (DHT) has been exploited to place
contents at specific locations and queries are directed to the
associative locations [24], [25]. If contents are placed at
random locations, queries are typically flooded to the peers
in order to locate needed data [26], [34]. These studies,
unlike ours, focus on searching locations for content
placement in order to facilitate content dissemination.
Data replication and caching have also been widely
studied for improving data accessibility in wireless envir-
onments [18], [20], [35]. Recently, considerable efforts have
been made for reducing the cost of data dissemination and
retrieval in wireless sensor networks [3], [10], [16], [21]. A
typical usage of sensor networks is to collect data by tens of
thousands of sensors which have limited computation and
communication capability. The inherited limitations make
the problem of efficient data retrieval a major challenge in
sensor networks. In [10], a data-centric storage scheme
based on DHT is proposed to locate certain type of data by
the properties of the data. Queries for the same type of data
can be served by one or a few nodes without resorting to
flooding mechanism. GEM, which is another approach for
data-centric storage, maps data to sensor nodes by embed-
ding a logical graph of storage nodes to a physical network
[21]. Hierarchical data storage and retrieval methods, which
introduce an intermediate tier between sources and data-
retrieval nodes, are also proposed for wireless or mobile
sensor networks [22], [23]. These studies focus on the design
of data dissemination and retrieval schemes.
Tree-structured networks are usually exploited in wire-
less sensor networks [11], [19], [36]. An energy-conserving
data placement scheme proposed for sensor networks is
introduced in [3], [9]. The authors propose a greedy
heuristic that places multiple copies of data in the network
and transfers the data from sensors to observers using
multicast. Essentially, storage locations are the medians
concerning communication costs among the sender and
observers. In [11], a data storage placement scheme is
proposed for a tree-structured sensor network where data
are eventually gathered at the sink. Storage nodes are
1432 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011
x to s the source-bound neighbor of x, denoted by snðx). We
define Rx as the sum of query rates of all the nodes in
T ðx; snðxÞÞ, that is, Rx ¼ Rðx; snðxÞÞ. Rx possesses the
property of rate aggregation, as stated by the following lemma:
Lemma 1. Let n0, n1; . . . ; nl ¼ s; l  2, be the path in T from
node n0 to the source node s. For all i, where 0  i  l 2, we
have Ri  Riþ1.
Proof. We have snðniÞ ¼ niþ1 for all 0  i  l 2. Hence,
the lemma can be directly derived from the fact that, for
all 0  i  l 2, T ðni; snðniÞÞ  T ðniþ1; snðniþ1ÞÞ and all
query rates are nonnegative. tu
As stated earlier, a node is a storage node if source data
are pushed to the node. A storage node may further
forward the source data onto other storage nodes. In light of
this, we have the following property:
Property 1. If j is a storage node, then all nodes on the path from
j to s are also storage nodes.
Lemma 2. Let H be a nonempty set of storage nodes and i 2 H. If
node j ðj 62 HÞ is a neighbor of i and Rj > gs, then the set
H [ fjg offers a communication cost that is less than H.
Proof. Since i and j are neighbors, either i ¼ snðjÞor j ¼ snðiÞ
is true. Property 1 implies that j cannot be snði), so i must
be snðj). Property 1 also implies that there is no storage
node in T (j, i), since otherwise j will be a storage node.
Since j 62 H, H [ fjg is the result of adding j to H. It adds
an extra data push cost of ci;j  gs, but cuts data query cost
by an amount of ci;j  Rj. Since Rj > gs, overall commu-
nication cost is reduced as of adding node j to H. tu
Lemma 3. Node j ð6¼sÞ must be included in any optimal set of
storage nodes if Rj > gs.
Proof. Let j ¼ n0, n1; . . . ; nl ¼ s; l  1, be the path from j to
s. Since Rj > gs, we have Ri > gs, for all 0  i  l 1, by
Lemma 1. Suppose, by contradiction, that P is an optimal
set of storage nodes and j 62 P . Obviously we have s 2 P .
By Property 1, there is a uniquely defined i, 0  i  l 1,
such that n0; n1; . . . ; ni are not in P while niþ1; . . . ; nl are
all in P . Applying Lemma 2 to ni; ni1; . . . ; n0 in
sequence, we can easily see that P cannot be an optimal
solution, a contradiction. tu
Lemma 3 gives a necessary condition for an optimal
solution. We now show that the same criterion also serves
as a sufficient condition in the following lemma:
Lemma 4. There always exists an optimal set of storage nodes
that does not contain any node jð6¼sÞ with Rj  gs.
Proof. Let P be any optimal set of storage nodes that
contains some node j ð6¼s) with Rj  gs. Let Pj ¼ fiji 2 P
and i 2 T ðj; snðjÞÞ}. Apparently, we have j 2 Pj. Two
cases are considered here.
Case 1: jPjj ¼ 1
In this case, j is the only node in Pj. Consider
P  ¼ P  fjg. P  adds an extra data query cost of
csnðjÞ;j Rj but cuts data push cost by an amount of
csnðjÞ;j  gs. Since Rj  gs, the overall communication cost
of P  is no greater than P .
Case 2: jPjj  1
Let i 2 Pj be a node such that there is no other node
x 2 Pj for which snðxÞ ¼ i. The path from i to s has to
pass through j. Lemma 1 leads to the fact of Ri  gs.
From the argument of case 1, we can remove i from P to
obtain another solution whose communication cost is no
greater than P . Repeatedly applying such pruning
process to all nodes in Pj, we eventually obtain a set
P  ¼ P  Pj with overall communication cost no greater
than P . Therefore, we can always remove j from P to
obtain another optimal solution. tu
Based on Lemmas 3 and 4, we can proceed to find an
optimal set of storage nodes for T . The only issue is how to
compute Rx efficiently for all node x 6¼ s. Let dT ðxÞ
represent the degree of node x in T . Since
Rx ¼
rx; if dT ðxÞ ¼ 1;
rx þ
X
y2NðxÞfsnðxÞg
Ry; otherwise;
8<
:
computation of all Rx values must follow some particular
order. For any two nodes x and y, we define y  x if
y 2 NðxÞ  fsnðxÞg. Clearly, the transitive closure of relation
 is a precedence ordering that captures computation
dependency among nodes. If we represent  as a directed
acyclic graphG ¼ ðV ;EÞ, where V is the set of nodes in T and
ðy; xÞ 2 E if y  x, computation of allRx values should follow
a topological ordering on G. It turns out that a topological
sorting algorithm with slight modification can be utilized for
the computation, which has a linear computation time.
5 MULTIPLE SOURCES OF DATA GENERATION
We now focus on the case in which two or more source
nodes in T can independently generate source data. Our
single-source solution benefits from the property of
unidirectional data flow: data originate from a single
source and are pumped to all storage nodes. The lack of
such property with multiple sources invalidates applic-
ability of our single-source solution for multiple-source
cases. In particular, unlike the single-source case in which
1434 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011
TABLE 1
Partial List of Symbols
k covers i. Since i is not fully covered, it must be true that
j does not cover i. tu
Theorem 1. If there is at least one fully covered node in the
network, then the set of all fully covered nodes is an optimal set
of storage nodes.
Proof. Let F represent the set of all fully covered nodes. For
any optimal solution F , we must have F 
 F  by
Corollary 3. Let Q ¼ F   F . If Q ¼ , then F is an
optimal solution. Otherwise, one can readily see that Q
consists of one or more disconnected tree fragments,
each of which is a subtree. Consider any one such
subtree, denoted as T1. According to Lemma 6, there
must be a node, say y, in T1 such that y is a neighbor of
some node x 2 F . Two cases are considered here.
Case 1: T1 contains only one node
This case happens when y is the only node in T1.
Consider the set F ¼ F   fyg, i.e., deleting y from F .
In comparison with F , F cuts a data push cost of
amount cx;y  Sðx; yÞ and increases the data query cost by
an amount of cx;y Rðy; xÞ. Since x 2 F , y must cover x.
The fact of y 62 F implies that y is not fully covered.
According to Lemma 8, we have that x does not cover y,
which means that Sðx; yÞ  Rðy; xÞ. We conclude that F
offers a communication cost that is no greater than F .
Case 2: T1 contains more than one node
In other words, T1 includes at least one more node
than y. Let z be a node in T1 such that z 6¼ y, z 2 F , and z
has only one neighbor in T1, that is, z is an edge node in
T1. Apparently, z 62 F . Consider the set F ¼ F   fzg.
F is still a connected subtree. Let z ¼ n0; n1; . . . ;
nl1 ¼ y, nl ¼ x, l  2, represent the path from z to x. In
comparison with F , deletion of z from F  will cut a data
push cost of amount cn1;z  Sðn1; zÞ. On the other hand, it
will increase data query cost by an amount of
cn1;z  Rðz; n1Þ. By Corollary 1, we have Sðn1; zÞ  Sðx; yÞ
and Rðy; xÞ  Rðz; n1Þ. From case 1, we have Sðx; yÞ 
Rðy; xÞ, which then leads to Sðn1; zÞ  Rðz; n1Þ. In other
words, F offers a communication cost that is no greater
than F . By repeatedly applying the same pruning
operation to nodes in T1, one-by-one starting from edge
nodes (nodes that has only one neighbor), and by the
argument of case 1, we conclude that the set F   fjjj is a
node in T1} gives a communication cost that is no greater
than F .
Applying the above argument to all of the subtrees of
Q, we eventually obtain the set F , which offers a
communication cost no greater than F . Therefore, F is
also an optimal storage set. tu
Theorem 1 founds the basis for locating an optimal set of
storage nodes in a network. To turn this theorem into a
practical algorithm, we need to compute Sði; jÞ and Rði; jÞ
for every channel chði; jÞ. A channel chði; jÞ is said to be
saturated if and only if the values of Sði; jÞ and Rði; jÞ are
both known. In general, chði; jÞ is saturated only if all
chðk; iÞ for which k 2 NðiÞ  fjg are saturated. For such a
channel, we have
Sði; jÞ ¼ gi þ
X
k2NðiÞfjg
Sðk; iÞ; ð1Þ
and
Rði; jÞ ¼ ri þ
X
k2NðiÞfjg
Rðk; iÞ: ð2Þ
For any channel ch(i, j) where dT ðiÞ ¼ 1, (1) reduces to
Sði; jÞ ¼ gi and (2) reduces to Rði; jÞ ¼ ri. We define
chðk; iÞ  chði; jÞ if k 2 NðiÞ  fjg. Given T , we can con-
struct a directed graph GT ¼ ðV ;EÞ, where V is the set of all
channels in T and 8x; y 2 V : ðx; yÞ 2 E if x  y. Fig. 3
shows such a graph for the tree shown in Fig. 2. Clearly,
computations of Rði; jÞ and Sði; jÞ should follow a topolo-
gical ordering on GT .
A straightforward approach to the computation is
therefore constructing GT from T first and then performing
a topology sorting on GT . This approach, however, can be
further optimized. The proposed algorithm, Rate_Comp,
shown in Fig. 4, computes Rði; jÞ’s and Sði; jÞ’s from T
directly. The key point is to count the number of incoming
channels that are saturated for each node, and to accumu-
late the amount of source and query rates that have been
pumped to each node during the computation. Array
in_count serves for the former purpose while S_sum
and R_sum together serve the latter. The algorithm also
involves maintaining a working queue WQ, where each
entry contains the identification of a saturated channel.
When in_count[y] reaches dT ðyÞ  1, we know that all but
one channels pointing to y are saturated. Let chðz; yÞ be the
only channel coming to y that is not yet saturated. At this
moment we have Rðy; zÞ and Sðy; zÞ computed and stored in
R_sum[y] and S_sum[y], respectively. In that case, chðy; zÞ
becomes saturated and is added to WQ for later computa-
tion. When in_count[y] equals dT ðyÞ, meaning that all
channels coming into y are saturated, we are ready to
compute Rðy; wÞ and Sðy; wÞ for all channel chðy; wÞ leaving
y. The algorithm simply repeats the removal-and-addition
process until WQ becomes empty.
After Sði; jÞ and Rði; jÞ for all chði; jÞ have been
computed, we are able to determine whether u is fully
covered by Definition 1 for any node u 2 T . This is
achieved by algorithm Multiple_Source (Fig. 5). It uses
 to indicate the set of nodes that cover some neighbor.
The optimal set of storage nodes  is given by the set of
fully covered nodes (recorded in F ) if there exists at least
one such node. However, if F is empty, the algorithm will
1436 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011
Fig. 3. Graph GT for the tree in Fig. 2.
Proof. By Lemma 9, we know that none of n0; n1; . . . ; nl2 is
included in TU if l > 1, since y is not in TU . Note that y
covers some of its neighbors as y 2 . Assume that w is a
neighbor covered by y and w 6¼ x. We have Sðy; wÞ <
Rðw; yÞ. By Lemma 5, we have that Sðx; yÞ  Sðy; wÞ and
Rðw; yÞ  Rðy; xÞ. Thus, Sðx; yÞ < Rðy; xÞ follows. There-
fore, x covers y, a contradiction with x 62 . Hence, we
show that y has to cover x. This result also implies that
Sðy; xÞ < Rðx; yÞ. Consider node nl2. Again, by Lemma 5,
we have Sðnl2; yÞ  Sðy; xÞ and Rðx; yÞ  Rðy; nl2Þ,
thus Sðnl2; yÞ < Rðy; nl2Þ follows, which implies that
nl2 covers y. By the same token, we can prove that ni
covers niþ1 for all 0  i  l 3. tu
Corollary 4 follows from Lemmas 10 and 8.
Corollary 4. Let x be a node in TU and y is a neighbor of x that is
not in TU . Consider the path n0; n1; . . . ; nl1 ¼ y,
nl ¼ x; l  1, from node n0 to x. Then, niþ1 does not cover
ni for all 0  i  l 1.
We now proceed to show that there exists an optimal
solution that contains only one node in TU .
Lemma 11. In the case of no fully covered node, there exists an
optimal solution that contains only nodes in the residual treeTU .
Proof. We prove the lemma by contradiction. Assume that
all of the optimal sets of storage nodes must contain at
least one node that is not in TU . Consider any optimal
solution P . Let Q ¼ P  fiji is a node in TU }. Obviously,
Q 6¼ . In fact, one can readily see that Q consists of one
or more disconnected tree fragments, each of which is a
subtree. Consider any one such subtree, denoted by T1.
Let b 2 TU and c 2 T1 be the closest nodes among all. Two
cases are considered here.
Case 1: T1 contains only one node
This case happens when c is the only node in T1. Let
c ¼ n0; n1; . . . ; nl ¼ b; l  1, be the path from node c to
node b. Two subcases are further considered below.
Case 1.1: Nodes b and c are not neighbors in the
network
This case occurs when l > 1. Note that node n1
belongs to neither P nor TU . Consider the set P
þ ¼
P [ fn1g, i.e., adding n1 to P . In comparison with P , Pþ
increases a data push cost of amount cc;n1  Sðc; n1Þ and
cuts data query cost by an amount of cc;n1 Rðn1; cÞ. From
Lemma 10, we know that c covers n1. That is,
Sðc; n1Þ < Rðn1; cÞ. Thus, Pþ offers a communication
cost that is less than P , which is a contradiction.
Case 1.2: b and c are neighbors in the network
This case occurs when l ¼ 1. If b 62 P , by the same
argument given in case 1.1, we can show that the set
P [ fbg offers a communication cost that is smaller than
P , a contradiction. Now consider the case of b 2 P . In this
case, consider the set P  ¼ P  fcg. In comparison with
P , P  increases a data query cost of amount cb;c Rðc; bÞ
and cuts data push cost by an amount of cb;c  Sðb; cÞ.
From Corollary 4, we know that b does not cover c. That
is, Sðb; cÞ  Rðc; bÞ. Therefore, P  gives a communication
cost that is no greater than P .
Case 2: T1 contains more than one node
In other words, T1 includes at least one more node
than c. Let z be a node in T1 such that z 2 P and z has
only one neighbor in T1, that is, z is an edge node in T1.
Consider the set P ¼ P  fzg. P is still a connected
subtree. Node z must traverse through node c to reach b.
Let z ¼ n0; n1; . . . ; ni ¼ c; . . . ; nl ¼ b, l  2, represent the
path from z to b. In comparison with P , P cuts a data
push cost of amount cn1;z  Sðn1; zÞ and increases data
query cost by an amount of cn1;z Rðz; n1Þ. From
Corollary 4, we see that n1 does not cover z, thus
Sðn1; zÞ  Rðz; n1Þ. Hence, P gives a communication
cost that is no greater than P .
By repeatedly applying the same pruning operation to
nodes in T1, one-by-one starting from edge nodes, and by
the argument of case 1, we conclude that either P is not
an optimal solution or the set P  T1 gives a commu-
nication cost that is no greater than P . Applying the
above arguments to all of the subtrees of Q, we
eventually obtain that either P is not an optimal solution
or the set P Q offers a communication cost less than or
equal to P . Since P Q contains only nodes in TU , thus a
contradiction arises. tu
The following theorem states that there exists an optimal
solution that contains only one node in the residual tree for
the case of no fully covered node.
Theorem 2. In the case of no fully covered node, there exists an
optimal solution that contains only one node in TU .
Proof. From Lemma 11, we see that there exists an optimal
solution that contains only nodes in TU . Let P be an
optimal solution that contains only nodes in TU and
jP j  1. Let x be any edge node in P and y be the sole
neighbor of x in P . Consider the set P ¼ P  fxg, i.e.,
deleting x from P . In comparison with P , P cuts a data
push cost of amount cy;x  Sðy; xÞ and increases data
query cost by an amount of cy;x Rðx; yÞ. Since y does not
cover x, we have that Sðy; xÞ  Rðx; yÞ. Hence, P offers
a communication cost that is no greater than P . Repeat
the above pruning process to nodes in P , one-by-one
starting from edge nodes, we will obtain an optimal
solution with only one node left. tu
Theorem 2 simply says that there exists an optimal
solution in the residual tree and the solution contains only
one node. A naı¨ve method to find the optimal storage node is
to take each node in the residual tree as a storage node and
calculate overall communication cost for the network.
However, this method can incur very high computation
cost. The function NoFullCov listed in Fig. 7 provides a
more efficient solution for finding the optimal storage node.
The basic idea of NoFullCov is using the set of nodes in the
residual tree TU as a reference storage set. We then compute
the amount of reduction in cost for each node x in TU , with
respect to the reference storage set, when x is the only storage
node in the network. Redundant operations can be avoided
using a technique similar to the Rate_Comp algorithm.
Assume that i is an edge node of TU and TU has more than
one node. In comparison with TU , deletion of i from TU cuts
a data push cost of amount cj;i  Sðj; iÞ and increases data
query cost by an amount of cj;i Rði; jÞ, where j is i’s single
neighbor node in TU . Let bði; jÞ ¼ cj;i  ðSðj; iÞ Rði; jÞÞ.
1438 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011
cost red qm½i; j
¼ reduced cost½i; j; if reduced cost½i; j > 0;
0; otherwise:

Note that reduced_cost[i; j] is the accumulated max-
imum amount of cost saving that can be achieved if some
storage nodes are placed in T ði; jÞ, provided that node j is
already a storage node. If this amount is no greater than
zero, it makes no sense to install storage node in T ði; jÞ.
Hence, cost_red_qm[i; j] is set to zero in this case. Note
that cost_red_qm[i; j] cannot be negative. The computa-
tion of cost_red_qm[i; j] can be performed alongside
Sði; jÞ and Rði; jÞ.
Consider the case in which some fully covered node is
found as a result of executing Multiple_Source. The
storage set will contain all the fully covered nodes in this case.
For each node j in the storage set, we should add any nonfully
covered neighbor, say i, to the storage set if and only if
cost_red_qm[i; j] is greater than zero. The same process
must be recursively applied to all the nodes in the resulting
storage set until no more new node can be added. We assert
that, as a result of this operation, the final storage set will be
the optimal one. The same process can be applied to the
single storage node identified by the NoFullCov function in
case no fully covered node exists in the network. However,
the result gives only near-optimal solution in this case.
6 PERFORMANCE EVALUATION
We have conducted extensive simulations to validate the
proposed algorithm and evaluate its performance. The
performance is compared with two other schemes.
6.1 Simulation Setup
In the simulation setting, the number of network nodes in a
tree network varies from 100 to 300. A tree network
containing a collection of nodes is randomly constructed
with a maximum degree of six. Each source node is
assigned a source rate that is randomly selected from some
given range (per unit time), with the default range being
[2.0, 4.0]. Nonsource nodes have a source rate of zero. In the
simulation, we vary the probability that a network node is a
source node, so as to capture different network configura-
tions. This probability is called source probability in the
following treatment. Each network node (including a source
node) is assigned a query rate that is randomly selected
from the range of [2.0, 4.0] per unit time. In addition, each
channel in the tree network is assigned a communication
cost (i.e., cost for transmitting one unit of data over the
channel) that is randomly selected from the range of [1.0,
3.0]. As described previously, we assume that sizes of
source data and data returned as a result of a query are both
equal to one data unit.
In the experiment, two other algorithms are also
simulated for comparison with our algorithm. Recall that
total communication cost composes of two components:
data query cost and data push cost. In addition, any storage
node set must always form a connected subtree of the
network. The first algorithm, denoted as QP_First, first
designates a node that has the largest sum of source rate
and query rate as the first storage node. It then adds a
neighbor of the storage node to the storage node set if the
addition results in reduction of communication cost. The
same process is repeated for any new storage node until no
further cost reduction is possible. This algorithm is a greedy
one and, basically, attempts to gain benefit by cutting total
communication cost at the outset.
Note that the push-mode operation described earlier
represents nothing but a special case in which all nodes in
the tree are storage nodes, while the pull mode of operation
does not resort to any storage node. Hence, we also choose
to compare our scheme with the pull mode, called Pull in
the following discussion. With Pull, a requesting node
retrieves data from all source nodes to satisfy each of its
queries, hence no data push cost is induced. Let TF
represent the subtree used to forward source data for a
query issued by a node x with Pull. In the simulation, we
assume that each source node s has to send to x newly
collected source data that is still unknown to x. The
expected size of source data sent from s to x is then gs=rx.
When measuring data query cost with Pull, we take
account of data aggregation, which refers to the effect that
data sent by various source nodes in response to the query
may be aggregated to reduce the size of transmitted data. In
the simulation, we have adopted three different aggregation
models for Pull. Let node i 6¼ x be a node on TF . Node i
may be a source node or an intermediary nonsource node.
Denote A the set of neighbors of i in TF from which i
receives (possibly aggregated) source data. Further, let j 2
TF be the neighbor of i to which i forwards source data, and
Zði; jÞ denote the average size of source data sent from i to
j, in response to the query. It is apparent that j 62 A. For
exposition purpose, we let Zði; iÞ represent the average size
of source data generated by i that is sent to x, if i is a source
node, and hence Zði; iÞ ¼ gi=rx. Zði; iÞ is zero if i is not a
source node. The first aggregation model, called max-aggr,
assumes that Zði; jÞ is given by
Zði; jÞ ¼ max  
X
k2A[fig
Zðk; iÞ; max
k2A[fig
Zðk; iÞ
0
@
1
A;
where  2 ½0; 1 is the aggregation factor. That is, max-aggr
assumes the size of source data forwarded from i to j is
given by the maximum of different (aggregated) sources
and the current aggregation result. The second aggregation
model, denoted as mnx-aggr, is more aggressive in which
Zði; jÞ is given by
Zði; jÞ ¼  max
k2A0
Zðk; iÞ þ ð1 Þmin
k2A0
Zðk; iÞ;
where  2 ½0; 1 is the aggregation factor and A0 ¼ A [ fig if
i is a source node, A0 ¼ A otherwise. Note that max-aggr
with  ¼ 0 is identical to mnx-aggr with  ¼ 1. The third
model, called unit-aggr, assumes unit data size for all
links on TF (i.e., Zði; jÞ ¼ 1). This model represents one of
the most aggressive data aggregation scenarios.
The main performance metric adopted in the simulation
is average communication cost. We also examine the
numbers of storage nodes produced by QP_First and our
algorithm. For a given number of network nodes, commu-
nication cost is averaged over 1,000 randomly constructed
network topologies, with 100 sets of source nodes which are
1440 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011
similar to the one given above for high source probability, it
becomes evident that our algorithm gains relatively more
advantage in this situation.
6.2.3 Number of Storage Nodes
For a given network topology, the number of storage nodes
produced by QP_First and our algorithm depends on
values of source rate, query rate, and source probability. To
gain more insight in this regard, we plot the number of
storage nodes versus source probability for various settings
of source rate for the algorithms in Fig. 11. In the simulation
plotted, network size is 200 nodes. Three settings of source
rate ranges are used: [0.0, 2.0], [2.0, 4.0], and [4.0, 6.0]. The
number of storage nodes produced by both algorithms
decreases when source rate or source probability increases.
This is because the volume of source data grows at a higher
source probability or source rate, which makes the data
push operation more costly. As a result, the algorithms
refrain from data push operations and hence yield less
storage nodes.
In particular, our algorithm results in less number of
storage nodes than QP_First. This is because, QP_First
will grow to include at least all fully covered nodes, when
such nodes exist in the network. Furthermore, in the case of
no fully covered node, QP_First may likely add more
storage nodes in order to cut down communication cost.
Although more storage nodes lead to lower data query cost,
they eventually result in higher data push cost as a whole.
Difference in the number of produced storage nodes between
our algorithm and QP_First is more obvious when source
probability increases. From the discussion above, we see that
the proposed optimal algorithm not only yields minimum
amount of communication cost but also achieves it with a
smallest number of storage nodes. This feature helps reduce
storage space requirement for a network.
The optimal solution produced by our algorithm con-
tains only one storage node when no fully covered node
exists in the network. Table 2 lists percentage of such
network scenarios versus source probability for a network
with 200 nodes. In the table, we show three sets of
simulation results (employing our algorithm), with source
rate falling in ranges of [2.0, 4.0], [3.0, 5.0], and [4.0, 6.0]. As
source probability grows, the percentage of no fully covered
scenarios rises. Similar trend is also observed when source
rate is increased. For example, nearly 40 percent of network
scenarios yield no fully covered node at source probability
of 70 percent, when source rate falls in range [4.0, 6.0].
6.2.4 Including Communication Cost of Transmitting
Query Messages
As described in Section 5.3, if cost for transmitting query
messages is considered in the cost model, one may need to
add more storage nodes after algorithm Multiple_
Source is completed, in order to further reduce total cost.
In what follows, we show effects of implementing such a
scheme. Fig. 12 illustrates communication cost with respect
to various q, ratio of the size of a query message to a data
unit, for a 200-node network. In the figure, we compare
communication cost with and without the above-mentioned
scheme implemented. In the simulation, both query rates
and source rates are randomly chosen from [2.0, 4.0] and
source probability is fixed at 50 percent.
From Fig. 12, we see that the proposed scheme constantly
offers benefit, in terms of communication cost, for the
network, and the cost reduction is more evident when q is
increased. This is because traffic due to transmitting query
messages becomes a more critical factor for communication
cost when q grows larger, which renders data queries more
costly. In this case, adding extra storage nodes are likely to
cut down data query cost as a whole. For example, in the
figure, overall communication cost can be reduced by as
much as 15.5 and 22.8 percent with q equal to 0.6 and 1.0,
respectively.
7 RELATED ISSUES
In this section, we discuss some issues that have not been
specifically addressed in previous sections.
1442 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011
Fig. 11. Number of storage nodes versus source probability.
TABLE 2
Percentage of Scenarios with No Fully
Covered Nodes in a 200-Node Network
Fig. 12. Communication cost versus q, ratio of the size of a query
message to a data unit, with and without node-adding scheme
implemented.
[4] L. Dowdy and D. Foster, “Comparative Models of the File
Assignment Problem,” ACM Computing Surveys, vol. 14, no. 2,
pp. 287-313, 1982.
[5] M. Fisher and D. Hochbaum, “Database Location in Computer
Networks,” J. ACM, vol. 27, no. 4, pp. 718-735, 1980.
[6] J. Douceur and R. Wattenhofer, “Optimizing File Availability in a
Secure Serverless Distributed File System,” Proc. 20th IEEE Symp.
Reliable Distributed Systems, 2001.
[7] C. Aggarwal, J. Wolf, and P. Yu, “Caching on the World Wide
Web,” IEEE Trans. Knowledge and Data Eng., vol. 11, no. 1, pp. 94-
107, Jan./Feb. 1999.
[8] M. Bhide, P. Deolasee, A. Katkar, A. Panchbudhe, K. Ramamri-
tham, and P. Shenoy, “Adaptive Push-Pull: Disseminating
Dynamic Web Data,” IEEE Trans. Computers, vol. 51, no. 6,
pp. 652-668, June 2002.
[9] K.S. Prabh and T.F. Abdelzaher, “Energy-Conserving Data Cache
Placement in Sensor Networks,” ACM Trans. Sensor Networks,
vol. 1, no. 2, pp. 178-203, 2005.
[10] S. Ratnasamy, B. Karp, S. Shenker, D. Estrin, R. Govindan, L. Yin,
and F. Yu, “Data-Center Storage in Sensornets with GHT, a
Geographic Hash Table,” Mobile Networks and Applications, vol. 8,
no. 4, pp. 427-442, 2003.
[11] B. Sheng, Q. Li, and W. Mao, “Data Storage Placement in Sensor
Networks,” Proc. ACM MobiHoc, 2006.
[12] K. Kalpakis, K. Dasgupta, and O. Wolfson, “Optimal Placement of
Replicas in Trees with Read, Write, and Storage Costs,” IEEE
Trans. Parallel and Distributed Systems, vol. 12, no. 6, pp. 628-637,
June 2001.
[13] O. Wolfson and A. Milo, “The Multicast Policy and Its Relation-
ship to Replicated Data Placement,” ACM Trans. Database Systems,
vol. 16, no. 1, pp. 181-205, Mar. 1991.
[14] G. Cornuejols, G. Nemhauser, and L. Wolsey, “The Uncapacitated
Facility Location Problem,” Discrete Location Theory, pp. 119-171,
Wiley, 1990.
[15] D. Wessels and K. Claffy, “ICP and the Squid Web Cache,” IEEE J.
Selected Areas in Comm., vol. 16, no. 3, pp. 345-357, Apr. 1998.
[16] B. Sheng, C. Tan, Q. Li, and W. Mao, “An Approximation
Algorithm for Data Storage Placement in Sensor Networks,” Proc.
Int’l Conf. Wireless Algorithms, Systems and Applications, 2007.
[17] K. Ross, “Hash Routing for Collections of Shared Web Caches,”
IEEE Networks, vol. 11, no. 6, pp. 37-44, Nov./Dec. 1997.
[18] T. Hara, “Effective Replica Allocation in Ad Hoc Networks for
Improving Data Accessibility,” Proc. IEEE INFOCOM, vol. 3,
pp. 1568-1576, 2001.
[19] S. Madden, R. Szewczyk, M.J. Franklin, and D. Culler, “Support-
ing Aggregate Queries over Ad-hoc Wireless Sensor Networks,”
Proc. IEEE Workshop Mobile Computing and Systems, pp. 49-58, 2002.
[20] L. Yin and G. Cao, “Supporting Cooperative Caching in Ad Hoc
Networks,” IEEE Trans. Mobile Computing, vol. 5, no. 1, pp. 77-89,
Jan. 2006.
[21] J. Newsome and D. Song, “GEM: Graph Embedding for Routing
and Data-Centric Storage in Sensor Networks Without Geo-
graphic Information,” Proc. First ACM Int’l Conf. Embedded
Networked Sensor Systems, pp. 76-88, 2003.
[22] R. Shah, S. Roy, S. Jain, and W. Brunette, “Data MULEs: Modeling
a Three-Tier Architecture for Sparse Sensor Networks,” Proc. First
IEEE Int’l Workshop Sensor Network Protocols and Applications,
pp. 30-41, May 2003.
[23] W. Heinzelman, A. Chandrakasan, and H. Balakrishnan, “Energy-
Efficient Communication Protocols for Wireless Microsensor
Networks,” Proc. Int’l Conf. System Sciences, 2000.
[24] I. Stoica, R. Morris, D. Karger, M.F. Kaashoek, and H.
Balakrishnan, “Chord: A Scalable Peer-to-Peer Lookup Protocol
for Internet Applications,” IEEE/ACM Trans. Networking,
vol. 11, no. 1, pp. 17-32, Feb. 2003.
[25] B.Y. Zhao, L. Huang, J. Stribling, S.C. Rhea, A.D. Joseph, and
J.D. Kubiatowicz, “Tapestry: A Resilient Global-Scale Overlay
for Service Deployment,” IEEE J. Selected Areas in Comm., vol. 22,
no. 1, pp. 41-53, Jan. 2004.
[26] Gnutella Protocol Development, “Gnutella 0.6 RFC,” http://
rfc-gnutella.sourceforge.net/src/rfc-0.6-draft.html, June 2002.
[27] B. Zelinka, “Medians and Peripherians of Trees,” Archivum Math.,
vol. 4, no. 2, pp. 87-95, 1968.
[28] H. Garcia-Molina, “Elections in a Distributed Computing Sys-
tem,” IEEE Trans. Computers, vol. 31, no. 1, pp. 48-59, Jan. 1982.
[29] M.L. Brandeau and S.S. Chiu, “An Overview of Representative
Problems in Location Research,” Management Science, vol. 35, no. 6,
pp. 645-674, 1989.
[30] L.W. Dowdy and D.V. Foster, “Comparative Models of the File
Assignment Problem,” ACM Computing Surveys, vol. 14, no. 2,
pp. 287-313, 1982.
[31] B. Li, M.J. Golin, G.F. Italiano, X. Deng, and K. Sohraby, “On the
Optimal Placement of Web Proxies in the Internet,” Proc. IEEE
INFOCOM, vol. 3, pp. 1282-1290, 1999.
[32] L. Qiu, V.N. Padmanabhan, and G.M. Voelker, “On the Placement
of Web Replicas,” Proc. IEEE INFOCOM, vol. 3, pp. 1587-1596,
2001.
[33] S. Sivasubramanian, M. Szymaniak, and G. Pierre, “Replication for
Web Hosting Systems,” ACM Computing Surveys, vol. 36, no. 3,
pp. 291-334, 2004.
[34] Y. Chawathe, S. Ratnasamy, L. Breslau, N. Lanham, and S.
Shenker, “Making Gnutella-Like P2P Systems Scalable,” Proc.
Applications, Technologies, Architectures, and Protocols for Computer
Comm., pp. 407-418, 2003.
[35] J. Luo, J.P. Hubaux, and P.T. Eugster, “PAN: Providing Reliable
Storage in Mobile Ad Hoc Networks with Probabilistic Quorum
Systems,” Proc. ACM MobiHoc, pp. 1-12, 2003.
[36] D. Estrin, R. Govindan, J. Heidemann, and S. Kumar, “Next
Century Challenges: Scalable Coordination in Sensor Networks,”
Proc. ACM MobiCom, pp. 263-270, 1999.
Ge-Ming Chiu received the BS degree in
electrical engineering from the National Cheng-
Kung University, Taiwan, in 1976, the MS
degree in electrical engineering from Texas
Tech University in 1981, and the PhD degree
in electrical engineering from the University of
Southern California in 1991. He is currently a
professor in the Department of Computer
Science and Information Engineering at the
National Taiwan University of Science and
Technology, Taipei. His research interests include distributed comput-
ing, mobile computing, fault-tolerant computing, and parallel processing.
He is a member of the IEEE.
Li-Hsing Yen received the BS, MS, and PhD
degrees in computer science from the National
Chiao Tung University, Taiwan, in 1989, 1991,
and 1997, respectively. He was an assistant
professor (1998-2003) and then an associate
processor (2003-2006) with the Department of
Computer Science and Information Engineering
at Chung Hua University, Taiwan. He was an
associate professor (2006 to 2010) and has
been a full professor since 2010 with the
Department of Computer Science and Information Engineering, National
University of Kaohsiung, Taiwan. His current research interests include
mobile computing, wireless networking, and distributed algorithms. He is
a member of the IEEE.
Tai-Lin Chin received the BS degree in
computer science and information engineering
from the National Chiao-Tung University, Tai-
wan, in 1995, and the MS and PhD degrees in
electrical and computer engineering from the
University of Wisconsin-Madison in 2004 and
2006, respectively. He is currently with the
Department of Computer Science and Informa-
tion Engineering, National Taiwan University of
Science and Technology, Taipei, as an assis-
tant professor. His primary research interests include wireless ad hoc,
vehicular, and sensor networks, mobile and pervasive computing, and
distributed algorithms. He is a member of the IEEE.
1444 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011
 2 
新的研究成果，尤其是在 ubiquitous computing 與 embedded systems，如能量控制方面的機制。 
    我們的論文則是在最後一天 8 月 25 日上午 10:30-12:00am 的 Session 8 中發表，此次是由謝仁偉教
授代表做 presentation。會議完後，在 8 月 25 日當晚即搭機返回台北。 
二、與會心得 
之前個人在相關領域雖有一些涉獵，但不是很深入，藉由此次參加會議的機會，增加了不少的知
識，事實上也是抱著多學習的態度來參加；尤其是，我的背景較接近平行計算與網路工程的範疇，而
此次的普遍計算領域，也是無線網路相關的研究方向之一；透過這一機會，除了讓個人在普遍計算方
面，能進一步認識之外，由於普遍計算環境少不了輕薄短小又易於移動的元件，而此種類型的元件多
以嵌入式系統的方式製造，因此，此類元件的特質就成為設計普遍計算機制時，必須要特別考量的因
素；其中，有關能量使用的情形，更是重要的考慮焦點；這主要是因為這類元件大多靠電池來供電，
而無線傳輸動作又是元件最耗損能量的部分，因此，如何把此一能量的係數考慮於機制的設計中，幾
乎是相關研究最重要的一部分。此次的會議即有相關的 session，探討節能的系統設計議題，這對個人
來說是很有幫助。不過，總體而言，本次會議還是以即時系統的排程(real-time scheduling)為主軸，較
屬演算法的設計。 
    我們的論文是探討以 Multi-Level Cell (MLC)為基礎的 flash memory 儲存系統問題，文中提出一項
設計 MLC Flash Translation Layer (MFTL)的方法，在所提出的機制中，我們主要是將 MLC 技術的限
制以及系統使用儲存系統的行為模式一起考量，讓所設計的方法更為有效率；而以 trace-driven 模擬
為本的實驗結果也顯示了我們機制的優點。 
    此次的會議雖然規模不大，但是卻能較集中在少數的議題上，比之於許多大型的學術會議，這樣
的會議模式也有其不錯的優點，值得推展。整體而言，本次大會的議程豐富，在各項安排上均顯得相
當有活力和積極，提供了相關研究學者一個很好的聚會討論的機會。不但論文之水準相當不錯，而且
對新的研究領域與方向的了解，尤其有幫助。另外一項值得我們注意的是，各國在國際學術會議投入
了不少的資源(即使如非以高科技著名的澳門)，我國的學者一般在國際會議方面的活躍性，相對是稍
微不足，這也是我們需要努力急起直追的地方。 
    此次會議舉辦的地點是澳門，澳門地方小小的，個人此次是第一次造訪這個城市，八月多是有點
熱，天氣與台灣差不多，有著濃濃的香港味道，城市的規劃很流線，道路比起台北市雖然小很多，但
是卻相當流暢。基本上，該城市是以娛樂及賭場的經營為主要經濟來源，這也屬於服務業的一環，因
此，在交通等基礎服務方面，自然表現得很不錯，尤其是其效率可說是相當卓著，對於正大力發展觀
光業的台灣來說，其對交通與相關設施的規劃，相當值得借鏡。 
    而除了交通之外，我也見識到澳門的國際化也很不錯，這也應和服務業的發展有關，一般而言，
在接待外國旅客的經驗及規劃方面，都蠻進步的。還有餐廳飲食也是澳門有名的特徵。由於澳門早期
為葡萄牙的殖民地，因此，也遺留了不少葡萄牙的遺跡，算是有趣的地方。不過，在澳門似乎就是娛
From: Jason Xue <jasonxue@cityu.edu.hk> 
To: jenwei@mail.ntust.edu.tw 
Date: Wed, 26 May 2010 21:18:42 +0800 
Subject: Your RTCSA 2010 Submission 
 
                                              
Dear Prof. Hsieh: 
 
On behalf of the RTCSA 2010 Program Committee, I am delighted  
to inform you that the following submission has been accepted  
to appear at the conference as a short paper: 
      
Design and Implementation for Multi-Level Cell Flash Memory Storage 
Systems 
 
The Program Committee worked very hard to thoroughly review 
all the submitted papers.  Please repay their efforts, by  
following their suggestions when you revise your paper. In the next 
few days, you will receive information about how to submit the final 
camera ready copy. 
The reviews and comments are attached below.  
Congratulations on your fine work.  If you have any additional  
questions, please feel free to get in touch. 
 
Best Regards, 
Jason Xue, PC Co-Chair  
RTCSA 2010  
 
===================== 
 
Review 1   
Relevance to the Track (1-5): 5 Presentation (1-5): 3  
Originality of the Work (1-5): 3 Technical Soundness (1-5): 4  
Overall Recommendation (1-5): 3 Nominate for Best Paper Award (yes, no): 
No  
  
Comments  
 
Overall Recommendation (1-5): 4 Nominate for Best Paper Award (yes, no): 
No  
  
Comments  
 
Often previous flash storage system design approaches do not take many 
new features/constraints of MLC flash into consideration, even though MLC 
flash memory has a large market share. This paper intends to improve the 
performance of flash memory storage system by considering such 
features/constraints. It proposes an MLC Flash Translation layer which 
can adapt the mapping granularity (i.e., page-level, block-level) 
according to access patterns (i.e., access pattern under the FAT file 
system). The paper claims that the new scheme results in less available 
SRAM but better performance.  
 
The paper's outcome has the potential to improve the performance of flash 
storage systems using MLC flash, which may then result in performance 
increases of systems that rely on such flash systems. The proposed 
framework is clearly designed. The introduction succeeds in presenting 
the challenges and the main idea of the proposed solution. The preliminary 
part provides a good introduction into the area and helps the reader to 
appreciate the problem. The paper provides sufficient details to make the 
reader understand the design principles and the evaluations in the paper 
support the claims made earlier. The bibliography also seems to be 
uptodate and complete.  
 
The “related work” part in the abstract should be described more clearly, 
particularly since only two previous methods are compared. Either in the 
abstract or the introduction, the metrics used to judge the experimental 
results should be mentioned (i.e., other than just the word 
“performance”, which is quite vague). While the third section of the 
paper provides many details on the applied principles, a paragraph 
describing the mapping scheme could help readers to understand the paper 
much better. The authors should also describe their choice of threshold 
and how varying the threshold affects the performance of their scheme.  
  
 
 
 8.In experiment part, what is the threshold for mapping mode switch 
between the page-mapping mode and the block-level mapping mode?  
  
 
 
 
Review 4   
Relevance to the Track (1-5): 5 Presentation (1-5): 4  
Originality of the Work (1-5): 4 Technical Soundness (1-5): 4  
Overall Recommendation (1-5): 3 Nominate for Best Paper Award (yes, no): 
No  
  
Comments  
 
This paper presents a Flash Translation Layer (FTL) using hybrid mapping 
scheme for the management of the modern MLC flash memory. Although MLC 
architecture has advantages of lower cost and higher density than SLC, 
it introduces new stringent constraints. Based on these conditions, 
author designed FTL, transparent mechanism to manipulate flash memory, 
to meet those requirements. It adopts a hybrid mapping scheme combining 
block-level and page-level mapping mechanism together. In order to do this, 
this article demonstrates how to do write and read in real implementation.  
 
The major concern that I have with the paper, however, is that the scheme 
focuses on file access behaviors under FAT file systems. We all know that 
largest file size of FAT32 is 4G and MLC’s most advantage is to provide 
large capacity. Constraint FTL to FAT file system will limit its usage 
and lower its confidence in FLASH storage device such as SSD. I think 
author should consider various file systems, such as ext2, ext3, and NTFS, 
etc.  
 
In addition, when it comes to the simulation, the author uses SLC as test 
flash memory chip. As IO speed of SLC is faster than MLC, comparison result 
with other file system here may be questionable. After all, FTL is a hybrid 
file system designed for MLC.  
 
Some typos and grammar mistake:  
Design and Implementation for Multi-Level Cell
Flash Memory Storage Systems
Jen-Wei Hsieh
National Taiwan University of
Science and Technology
Email: jenwei@mail.ntust.edu.tw
Chung-Hsien Wu
InCOMM Technologies Co., LTD.
Email: samwu@incomm.com.tw
Ge-Ming Chiu
National Taiwan University of
Science and Technology
Email: chiu@mail.ntust.edu.tw
Abstract—NAND ﬂash memory has gained its popularity in
a variety of applications as a storage medium due to its low
power consumption, non-volatility, high performance, physical
stability, and portability. In particular, Multi-Level Cell (MLC)
ﬂash memory, which provides a lower cost and higher density
solution, has occupied the largest part of NAND ﬂash-memory
market share. However, MLC ﬂash memory also introduces new
challenges: (1) Pages in a block must be written sequentially.
(2) Information to indicate a page being obsoleted cannot be
recorded in its spare area. This paper designs an MLC Flash
Translation Layer (MFTL) for ﬂash-memory storage systems
which takes new constraints of MLC ﬂash memory and access
behaviors of ﬁle system into consideration. A series of trace-
driven simulations is conducted to evaluate the performance
of the proposed scheme. Our experiment results show that the
proposed MFTL outperforms other related works in terms of the
number of extra page writes, the number of total block erasures,
and the memory requirement for the management.
I. INTRODUCTION
Flash-memory storage systems are normally organized in
layers, as shown in Fig. 1. The Memory Technology Device
(MTD) layer provides lower-level functionalities of ﬂash mem-
ory, such as read, write, and erase. Based on these services,
higher-level management algorithms, such as wear-leveling,
garbage collection, and logical/physical address translation,
are implemented in the Flash Translation Layer (FTL). The
objective of the FTL is to provide transparent services for ﬁle
systems such that ﬂash memory can be accessed as a block-
oriented device. As an alternative approach, a ﬁle system can
be made ﬂash-memory-aware by having the characteristics of
ﬂash memory been taken into consideration. JFFS [10] and
YAFFS [2] take this approach. Although a ﬂash-memory-
aware ﬁle system is more efﬁcient, FTL scheme has the
advantage of enabling ﬂash memory available to existing ﬁle
systems directly. Since most of the applications, especially for
portable devices, access their ﬁles under FAT ﬁle systems, this
paper focuses on FTL.
Depending on the granularity with which the mapping
information is managed, FTL can be classiﬁed into page-level
[1], block-level [7], and hybrid mapping schemes [4], [6]. For
a page-level mapping scheme, each entry in the mapping table
includes a physical page number(PPN), which is indexed by
This paper is supported in part by a research grant from National Science
Council, Taiwan, R.O.C. under Grants NSC98-2221-E-011-070.
JFFS2 YAFFS2
Ext2 FAT
Flash Translation Layer (FTL)
Memory Technology Device (MTD) Layer
Virtual File System
Operating System
Application 1 Application 2 Application n
Flash Memory
ΞΞ
ΞΞ
Ξ
Fig. 1. Architecture of Flash-Memory Storage Systems.
the logical page number (LPN). When a request arrives, the
mapping scheme translates the associated logical address into
an LPN and uses this LPN to locate the corresponding PPN
from the mapping table. With the mapping table, a logical
address can be directly mapped to a page in any location of a
ﬂash memory. It makes storage management more ﬂexible and
results in better performance for random accesses. Since the
mapping table is large in size and usually resides in SRAM,
a page-level mapping scheme is considered impractical due to
cost consideration.
To reduce SRAM requirement, block-level mapping scheme
was proposed. In a block-level mapping scheme, a logical
address has two components: a logical block address (LBA)
and a logical page offset. LBA can be translated into a physical
block address (PBA), and the logical page offset is used to
locate the target page in the physical block. The size of the
mapping table is now signiﬁcantly reduced and proportional to
the total number of blocks in ﬂash memory. However, update
requests usually incur a block-level copy overhead.
A hybrid mapping scheme is a block-level mapping scheme
with a limited number of records adopting page-level mapping.
In a hybrid scheme, a logical address is consisted of an LBA
and a logical page offset as a block-level scheme. However,
unlike the block-level scheme, it allows data update to the
next available page in another physical block, i.e., a log
block. A page mapping table is required for recording the
actual locations of the updated data. Hybrid mapping schemes
The Sixteenth IEEE International Conference on Embedded and Real-Time Computing Systems and Applications
1533-2306/10 $26.00 © 2010 IEEE
DOI 10.1109/RTCSA.2010.31
247
to merge the corresponding primary block into the replacement
block and then treat the resulting replacement block as the
primary block. We can eliminate such overhead by directly
switching to page mapping mode without merging operation
when LWP is less than half of total pages in a block. The
most signiﬁcant bit (MSB) is used to indicate whether the
mapped page is located in the primary block (set to 0) or in
the replacement block (set to 1). Each PageMapStatus contains
two elements:
• VBA records the corresponding virtual block address.
• MapArray[N] is an integer array keeping the page-
mapping information of the block, where N is the number
of pages per block. A value smaller than 0x80 in the
MapArray[i] means the i-th logical page is located at
the MapArray[i]-th page of the primary block. Otherwise,
the i-th logical page is located at the (MapArray[i] AND
0x7F)-th page of the replacement block.
C. Write Flow
When the FAT ﬁle system creates a new ﬁle, it ﬁrst issues
a write to root directory to update the ﬁle information. It then
updates FAT tables to allocate required storage space for the
ﬁle. Finally, the ﬁle body is written to the allocated area.
Conceptually, the storage space could be treated as containing
two parts: system area and data area. System area consists
of a boot record, FAT tables and a root directory, while data
area is the area used to store ﬁle body. Any write/update to
a ﬁle (data area) is accompanied by several small updates to
the system area to ensure correct ﬁle information. Observing
the very different behavior over system area and data area, we
adopt various mechanisms to deal with write operations in an
adaptive manner. Since writing data is trivial in ﬂash-memory
management, we will focus on the operation of data updating.
Upon arrival of an update request, MFTL ﬁrst determines
whether the corresponding UpdateRec exists by checking the
VBA ﬁeld of each UpdateRec. If no such an UpdateRec exists,
MFTL allocates a new one. In case that all the UpdateRec’s
have been assigned and the new update request does not
match any one of them, MFTL will select the UpdateRec
with the lowest priority as a victim for replacement (ties are
broken arbitrarily). Live pages in the primary block and the
replacement block of the victim UpdateRec will be merged
to a newly allocated block, and the victim UpdateRec could
then be released and reassigned to the new request. After the
UpdateRec is located, MFTL determines the mapping mode
of the UpdateRec. Different mapping mode would affect the
manner how MFTL writes data to ﬂash memory.
If the mapping mode is in block mapping mode, some
further checks are required. According to the index of starting
target page for the update request (i.e., STP) relative to the
index of the last written page in the replacement block (i.e.,
LWP), the update request is treated differently. For the case
in which STP is larger than LWP, the request is treated as a
forward update. Otherwise, some previously updated data is to
be updated again by the request, and the request is treated as a
backward update. Since backward updates incur higher page-
copying overheads, page-mapping mode is thus introduced to
deal with small, random, and frequently updated data.
The Count ﬁeld in UpdateRec is used to maintain the
number of backward updates that had occurred in this record.
When it exceeds a threshold, the mapping is switched to
page mapping mode. If a backward update occurs but does
not result in a switch to page mapping mode, MFTL will
examine whether page-copying after updating data is required.
The primary reason behind page-copying after updating data
is the assurance of data integrity, since the primary block or
the replacement block would be reassigned in this case.
1) Forward Update: Forward update occurs when STP is
larger than LWP in the replacement block. When the target
page for the update request is the page following the last
updated page in the replacement block, data can be directly
written to the target page in the replacement block, and LWP
of the UpdateRec is updated accordingly.
The other kind of forward update occurs when the request
skips one or more pages from the last updated page and
leaves them unchanged. To take the sequential programming
requirement of modern MLC ﬂash memory into consideration
and to simplify the management overhead, MFTL ﬁrst copies
those skipped pages between LWP and STP from the primary
block to the replacement block and then updates the target
page. After the last page in the replacement block is written,
all of the pages in the primary block would be invalid. The
replacement block becomes the new primary block, and the
original primary block could be recycled. Then, the corre-
sponding UpdateRec is cleared for upcoming requests.
2) Backward Updates in Block Mapping Mode: Backward
update occurs when some previously updated page(s) will be
updated again by the update request. In other words, backward
update occurs when STP ≤ LWP. Since the default mapping
mode is block mapping mode and a written page cannot be
updated again unless the whole block is erased, a new replace-
ment block is thus allocated. To facilitate the description, the
operation of backward update is divided into three stages: pre-
write, writing, and post-write. Conceptually, “pre-write” deals
with the required page-copying before updating data; “writing”
updates the data according to the request; “post-write” does
another page-copying for assurance of data integrity.
For the case where the update request updates all the
remaining and previously updated pages in the replacement
block, no page-copying is required in the post-write stage.
The new replacement block replaces the original one, and
the original replacement block can be recycled. The Replace
ﬁeld in the corresponding UpdateRec is updated accordingly.
Note that if the request continues to update data until the
last page, all pages in the primary block and the original
replacement block would be invalid. In this case, the new
replacement block becomes the primary block, and both the
original primary block and the original replacement block are
recycled. The corresponding UpdateRec is then cleared for
upcoming requests.
Consider the case in which only a portion of pages in
249
each block contains 64 pages, and each page is of 2KB. All
of the traces were captured by the SD/MMC card protocol
analyzer VTE2100 [9]. Note that the FAT ﬁle system would
update the root directory and FAT tables frequently to maintain
the correct ﬁle information. The cluster size was deﬁned as
16KB, where the cluster size was the minimum allocation unit
for a ﬁle. TABLE I summarizes characteristics of the seven
evaluation patterns.
Pattern Description
4KB-R Randomly create 120,000 4KB ﬁles and
process up to 4,000,000 ﬁle write/update
operations to emulate a tremendous amount
of random small-ﬁle accessing with internal
fragmentation.
64KB-S Sequentially copy 5,000 64KB ﬁles into a
directory to emulate a large amount of small
ﬁle creations without internal fragmentation.
SUB Copy ﬁles/directories with different sizes
into a subdirectory to emulate a synthetic
situation.
MP3 Copy mp3 ﬁles and photos to NAND ﬂash
storage.
TABLE I
CHARACTERISTICS OF EVALUATION PATTERNS.
B. Experiment Results
Fig. 2 compares the number of extra page writes and the
number of total block erasures of BAST, FAST, and the
proposed MFTL under different number of extra blocks over
a 2GB ﬂash memory. In addition to the extreme case (i.e.,
the pattern 4KB-R), FAST had a good performance when
the number of extra blocks was very limited; three extra
blocks would be enough to make its performance stable. This
was because FAST shares its extra blocks for all logical
blocks. However, the proposed MFTL outperformed both
BAST and FAST for all patterns when four extra blocks could
be provided. Based on our experimentation, the performance
improvement was signiﬁcant when the number of extra blocks
was between four and ﬁve. Such results were caused by two
reasons: (1) Since the FAT ﬁle system would update two
FAT tables, root directory, and data area while writing a ﬁle
to storage, four extra blocks could signiﬁcantly improve the
performance. (2) Windows XP writes ﬁles with size over
64KB by two threads, ﬁve extra blocks might be required for
updating a large ﬁle. As a result, over six extra blocks would
not have an obvious improvement for extra page writes and
block erasures.
For the pattern 4KB-R, as illustrated in Fig. 2(a) and
Fig. 2(b), the number of extra blocks seemed to have no effect
on the performance improvement. It was because a tremendous
amount of random 4KB ﬁle updates would rapidly use up log
blocks. For BAST, each subsequent update would trigger a
merge operation, and each merge operation would incur 64
extra page writes and 2 block erasures. For FAST, since a
log block was shared by all data blocks, merge operations
would not be triggered as frequent as BAST did. Recall that
each ﬂash-memory block contains 64 2KB pages and the
cluster size was 16KB, each merge operation would incur 8
× 64 = 512 extra page writes and 9 block erasures (compared
with 8 merge operations in BAST with 512 extra page writes
and 16 block erasures). For MFTL, random 4KB ﬁle updates
would not switch UpdateRec’s into page mapping mode, and
each 4KB ﬁle update would be treated as a forward update
in block mapping mode (please refer to Section II-C1). In
addition, updates to root directory and FAT tables could always
reside in page mapping mode thanks to Count and Priority in
UpdateRec. As a result, FAST and MFTL could have a better
performance in extra page writes and outperform BAST in
block erasures.
For the pattern 64KB-S, as illustrated in Fig. 2(c) and
Fig. 2(d), there was no internal fragmentation issue and
readers might expect similar performances for the three hybrid
mapping schemes. However, the experiment result showed a
different story. For BAST and FAST, while there was no log
block assigned to the corresponding data block and page offset
of the write request did not align to the block boundary (i.e.,
page offset 0), a log block would be assigned and updated data
would be written to the page 0 of the block. Even the following
write requests were sequential writes, BAST and FAST would
still incur extra page writes and block erasures during merge
operations. On the other hand, as mentioned in Section II-C,
MFTL uses Count in UpdateRec to prevent from switching
to page mapping mode immediately. This mechanism helped
UpdateRec to keep in block mapping mode for sequential write
requests. Thus merge overheads could be reduced, and a better
performance was achieved.
For patterns SUB and MP3, since large ﬁles led to much
more sequential write operations, the number of merge opera-
tions was largely reduced. As shown in Fig. 2(f) and Fig. 2(h),
the improvement over the reduction of block erasures was not
as signiﬁcant as patterns 4KB-R and 64KB-S; MFTL could
achieved a better performance on block erasures and extra
page writes compared with the other two schemes for large-
ﬁle patterns while at least four extra blocks were provided.
Note that in the pattern MP3 with at least four extra blocks,
MFTL outperformed BAST and FAST in terms of extra page
writes. It was because MFTL uses Count in UpdateRec to
prevent from switching to page mapping mode immediately.
With a small overhead of page copying, this mechanism helped
UpdateRec to keep in block mapping mode. As a result, merge
overhead could be reduced when an update request dose not
begins from page 0 of some block.
For the memory requirements of the three hybrid mapping
schemes, since block mapping tables were the same for each
scheme, we focused on the memory requirement for managing
extra blocks. TABLE II lists the memory requirements for
each extra block and each MapArray under the three different
schemes. BAST reserved one more byte to store information
for the selection of a victim log block when a merge operation
is triggered. MFTL reserved three extra bytes for ﬁelds of
LWP, Count, Mode, and Priority. For page mapping, BAST
required an array for each log block to keep track of the page
251
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/22
國科會補助計畫
計畫名稱: 無線網路中最佳化資料推播機制之研究
計畫主持人: 邱舉明
計畫編號: 97-2221-E-011-070-MY3 學門領域: WEB 技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
