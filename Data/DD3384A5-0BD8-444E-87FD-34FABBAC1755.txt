  I
中文摘要 
 
資料探勘是一種專業的資訊科技，可於大量的資料中挖掘出有用資訊，以助於企業決策運作。
但經資料探勘挖掘出來的知識，也關係到企業未來的生存發展，故更應該要加以重視與保護。目前
在資料探勘安全防護的研究領域，主要是在探討如何防止隱私資料，因資料探勘的行為而被公開揭
露。而本研究提出一個新的觀念，即針對資料探勘之「知識」的安全問題，提出反探勘(Anti-data 
mining)的觀念，作為一種用來保護「知識安全」的新型技術。反探勘主要是用來反制資料探勘的
運用。在本研究中，我們利用資料探勘在分析資料時，應該會受到干擾資料的影響。故以加入干擾
資料來做為反探勘的技術主軸，並且以不會破壞原始資料的資料偽裝概念為前提，來設計反探勘的
技術與方法，使資料集能獲得反探勘的偽裝，防止資料集裡的知識不當外洩。而且受反探勘偽裝的
資料集，亦可透過反探勘的還原機制移除干擾資料，以能正常的進行資料探勘。本研究運用反探勘
的觀念，以分群及分類演算法為技術主軸，設計了不同反分群及反分類演算法。並且採用了 UCI 
Machine Learning Repository 網站公開的多種資料集，來做為研究的實驗對象，以詳細探討各種反
分群及反分類演算法的效果。研究結果顯示，本研究所提出的反分群及反分類演算法，可以讓使用
者以自訂參數的方式偽裝資料與改變資料集的分群或分類知識，進而達到保護知識的目的。如此，
經由反探勘偽裝過的資料集，可在不慎遺失或遭竊取外流後，仍能有效的保護其知識內容的安全
性。同時藉由反探勘的偽裝機制，使用錯誤的知識內容來達到欺敵的效果，解決企業有關資料集裡
的知識安全問題。 
 
關鍵字：資料探勘、知識探索、反探勘、資料偽裝 
  III
目  錄 
 
中文摘要 ....................................................................................................................................................... I 
Abstract......................................................................................................................................................... II 
目  錄 .......................................................................................................................................................III 
1. 前言 ...........................................................................................................................................................1 
2. 文獻探討 ...................................................................................................................................................1 
3. 研究方法 ...................................................................................................................................................2 
3.1. 資料偽裝與還原方法之設計 ...........................................................................................................2 
3.1.1 加入干擾欄位法 .........................................................................................................................2 
3.1.2 加入干擾資料法 .........................................................................................................................2 
3.1.3 資料偽裝還原之設計 .................................................................................................................2 
3.2. 偽裝方法之效果評量 .......................................................................................................................3 
3.3.1 資料包含性評量法 .....................................................................................................................3 
3.3.2 重心偏移評量法 .........................................................................................................................3 
3.3.3  k-fold modified cross validation (k-fold MCV) ........................................................................4 
3.3. 建構分群及分類防護之資料偽裝方法 ...........................................................................................4 
3.4.1 階層式反分群演算法(Hierarchical anti-clustering algorithm) ..................................................4 
3.4.2 反競爭式學習演算法(Anti-competitive learning algorithm).....................................................4 
3.4.3 震盪隨機抽樣干擾法(Shaking Random Sampling Interference Algorithm).............................4 
4. 實驗結果 ...................................................................................................................................................5 
4.1. 實驗設計 ...........................................................................................................................................5 
4.2. 實驗過程與結果分析 .......................................................................................................................5 
4.2.1 階層式反分群演算法之實驗過程與結果分析 .........................................................................5 
4.2.2 反競爭式學習演算法之實驗過程與結果分析 .........................................................................7 
4.2.3 震盪隨機抽樣干擾法之實驗過程與結果分析 .........................................................................9 
4.3. 資料偽裝之安全性分析 ..................................................................................................................10 
5. 結論 .........................................................................................................................................................11 
 
  2
於個體隱私；用資料探勘的工具於整個資料集中挖掘出有用的資訊，即屬於全體隱私。 
總而言之，隱私防護之資料探勘並不是在限制資料的蒐集或是資料探勘工具的使用，
而是期能在有效探勘資料的同時，亦要能保護隱私性的資訊。目前有關隱私防護之資料探
勘方法的考量有二大方向：第一、公開使用資料集前，應於資料集中移除或修改有關個人
的隱私性資料。第二、對於資料集裡可能被挖掘出的敏感性資訊，應於資料探勘前予以移
除，以確保資訊的隱私。 
本研究基於資料探勘的知識隱私及安全性，研究如何在不破壞原始資料的情況下，對
原始資料集進行干擾，以擾亂資料集的知識內容，達到保護隱私識的目的。 
 
3. 研究方法 
反探勘的技術理念是用資料偽裝的概念來設計其偽裝知識的方法[17]。所謂資料偽裝即
是有如軍事的迷彩塗裝，藉由對人員、物體塗抹或裝置與週遭事物相似的迷彩塗料及工事，
來達到隱蔽與掩蔽的目的。本研究的資料偽裝方法，即是要產生與原始資料相近似的干擾
資料，並加入到原始資料中以進行資料偽裝，如此即可用以改變原始資料的知識，進而達
到反探勘的目的。本研究針對分群及分類演算法提出各種資料偽裝及資料還原的方法，並
且訂定偽裝效果的評量方式，以供反探勘演算法的設計規劃與運用，所提出的資料偽裝、
資料還原與效果評量方法說明如下。 
 
3.1. 資料偽裝與還原方法之設計 
3.1.1 加入干擾欄位法 
是於被保護的資料集中，新增一個或多個干擾資料欄位，來改變資料彼此之間的相似
度，藉以擾亂其分群或分類的結果。加入的欄位，必需考量其它欄位的屬性與數值，以設
計出相近似於原本資料欄位的干擾資料。本方法的好處是產生的干擾資料較少，較不會影
響資料運作的效能，同時於還原時亦較為方便，只須刪除加入的欄位即可。 
3.1.2 加入干擾資料法 
是於保護的資料集中，加入與原本資料相近似的干擾資料，加入的干擾資料一樣要考
量原本資料的屬性與特徵。本方法可較有彈性的調整偽裝知識的偏差值，也就是可讓使用
者自訂偽裝知識的效果，讓資料集的分群或分類知識，偏移至使用者設定的預期目標。加
入干擾資料法除了可以達到偽裝知識的目的，亦可用錯誤的知識來誤導非法的使用者。 
3.1.3 資料偽裝還原之設計 
以上所設計之干擾資料的產生，不論是針對欄位還是整筆資料，其所產生的干擾資料
必須與原始資料相近似，才不會輕易的被辨識過濾，本研究設計以 Random 函式來產生各
種干擾資料。在設計時，先藉由 Random 函式所產生的[0,1)之亂數值，作為干擾資料隨機
產生的基礎；另一方面，則擷取原始資料的特性來設定合理的干擾範圍區間，並使二者相
乘即可產生具有隨機性，同時又與原始資料相近似的干擾資料。 
另外，為了使受偽裝後的資料集可以被還原，也就是清除干擾資料的功能，本研究於
  4
距離總合 )(df 。 
∑
=
=
k
i
′− ii C
1
.              (3) 
3.3.3 k-fold modified cross validation (k-fold MCV) 
準確率的方法與一般的 k-fold CV 有部
分不
Cdf )(
 
為了驗證反分類演算法的效能，本研究計算分類
同。一般的 k-fold CV 方法主要是針對單一資料集進行分類準確率的運算，它會將資料
集分成 k 個等份，再交替進行 k 次的交叉運算與驗證，並以 k 次的平均值作為最後的準確
率。而本研究為了公平的測試防護前與防護後二種資料集的預測準確率，其作法是先將最
原始的資料集等分割為 k 份，並將其中一份資料當成預測的測試資料 W，再將剩餘的 k-1
份資料當訓練資料集 D，用以建構出原始資料集的分類模型，並利用保留的測試資料 W 進
行分類預測，得到原始資料集的預測準確率 OA。接下來，將訓練資料集 D 利用反分類演
算法加入干擾資料形成防護資料集D′，並且透過分類演算法建構分類模型後，一樣利用原
先保留的那一份測試資料 W 進行預 ，即可得到防護後的預測準確率 PA。如此進行 k 次的
交叉運算後取平均數，以作為本研究評量反分類演算法的知識防護效果。 
 
測
3.3. 建構分群及分類防護之資料偽裝方法 
3.4.1 階層式反分群演算法(Hierarchical anti-clustering algorithm) 
的方法來影響資料彼此
之間
3.4.2 (Anti-competitive learning algorithm) 
料法插入與原本資料相近
似的
保護後的神經元權重值，以確認保護後的資料
集無
3.4.3 (Shaking Random Sampling Interference Algorithm) 
擾亂的反探
勘資
階層式反分群演算法[13][14]的基本觀念，是採用加入干擾欄位
的相似度，使得階層式分群演算法對資料的分群分析結果獲得改變。同時採用資料包
含性評量法來評量本方法的對分群知識的保護效果，並且使用Random(Seed)函式來產生干
擾欄位，使得本方法可以有效移除干擾欄位，進而反向還原資料集，讓合法的使用者可以
正常的進行資料探勘。 
 
反競爭式學習演算法
反競爭式學習演算法[15]是於原始資料集中，運用加入干擾資
干擾資料，用以擾亂神經元權重值的調整，產生錯誤的神經元權重值，使得競爭式學
習的分群效果喪失，達到反探勘的目的。 
本方法使用重心偏移法來評量保護前與
法正確的產生神經元的權重值。而在干擾資料的設計方面，則是使用原始資料集的神
經元權重值來當作基準，再加上使用者設定的偏移比例與 Random(Seed)函式來產生干擾資
料，一方面可有效的擾亂神經元權重值的產生；另一方面一樣保留可以還原資料集的效果。 
 
震盪隨機抽樣干擾法
震盪隨機抽樣干擾法[16]是一種以加入干擾資料法，對分類演算法進行知識
料偽裝技術，藉由加入與原始資料相似的錯誤類別偽裝資料，以降低分類演算法的分
類預測準確率，進而達到保護原始資料的分類知識。本方法採用k-fold MCV來對保護前與
  6
 
接下來取 Iris 資料集裡的最大值與最小值作為干擾資料範圍 ，並設定干擾資料增加率
、預期干擾比例 與執行次數限制
q
1.1=r %50=Tr 100=tT
D
。然後開始進行 HAC 的資料偽裝
，形成偽裝後的資料集流程，以產生干擾欄位資料的方式將其加入原始資料集 D′。接下
來，
果 jC
再將偽裝後之資料集D′進行階層式分群分析，取得 Iris 資料集偽裝後的階層式分群結
,...,3,2,1,{ i gid }k′= ],1[ k ， kg=′ ， j∈∀ ′為偽裝後各分群的資料個數。再將 jC ′與偽裝前的
分群結果 jC 進行資料包含性 jiji CdandCd ′∈∈ 的計算，以得到 HAC 對 Iris 資料集進行資
料偽 為 jC 與 jC裝的效果。表 4.2 所列的資料，即 將 ′進行資料包含性計算後， 得到的各分
1
所
群資料個數於偽裝前與偽裝後的資料量變化。以偽裝後的分群C ′為例
48 筆，其中有 8 筆資料是屬於偽裝前的分群 、32 筆資料是屬於偽裝前的分群 、8 筆
3
 
表4.2 Iris資料集─HAC之資料偽裝效果
，其分群資料筆數為
HAC
效果。
 
1C 2C
對於資料偽裝的資料是屬於偽裝前的分群C ，這些資料所屬分群的改變，即代表了
  2  3C  1C ′ C ′ ′
kg ′  48 62 40 
1C  8 5 0 
2C  32 37 18 
3C  8 20 22 
 
完成表 4.2 的計算後，接著要計算整體的資料偽裝效果，也就是再以公式(2)來計算整
體的資料偽裝比例值， 將結果列於 4.3。表 4.3 中的 s 代表的是 I
群，在經過 HAC 的資料偽裝後，仍屬於第 群的資料個數， 為 群用公式(2)
所得的資料偽裝效果比例值。以 為例，其原本的資料個數為 筆，經 HAC 進行資料偽
裝 後 ， 未 改 變 的 資 料 筆 數 為 8 筆 公 式
即為
所設定的 50%，也代表者 HAC 可以有效的對資料集進行資料偽裝，以保護其所蘊含的知識。 
表4.3 Iris資料集─HAC之整體實驗結果 
並 表 ris 原始資料集的第 jC
計算jC
， 以
38.47%
jRC
13
第 jC
來 進 行 改 變 比 例 的 計 算 ， 即
分群的資料偽裝效果。最後再將三個
1C
，所得的
(2)
%47.38%100))131( =×÷−
分群
8( 1C
的資料偽裝效果加總取平均，所得到的整體比例值 RC=50.65%，大於預期干擾比例 rT
 1C  2C  3C  
k  g 13 87 50 
s 22 8 37 
jRC 38.47% 57.48% 56%  
RC 50.65% 
  8
.表4 6 Iris資料集─ACL之資料偽裝效果(r=-0.1) 
神經元 權重值 與原始權重值之差值 
1w′  (4.48, 3.04, 1.36, 0.21) (-0.52, -0.37, -0.10, -0.03) 
2w′  (4.94, 2.03, 3.64, 1.12) (-0.96, -0.71, -1.29, -0.31) 
3w′  (6.15, 2.88, 5.04, 1.73) (-0.68, -0.19, -0.70, -0.34) 
 
由上述的實驗可知 重值調整比例 行設定偽
裝神經元權重值的結果與調整的方向，如此可有效的符合實際需求，亦可方便使用者自訂
合理的偏移範圍，達到誤導非法使用者的目的。 
ACL 於偽裝神經元權重值時，干擾資料的數量為主要關鍵，調整比例愈高，所需的干
擾資料數量亦要愈多，才可達到指定的調整比例。所以在實驗時，運用調整係數
，ACL 可以藉由設定權 的方式，讓使用者自
α 來加速
ACL 的干擾速度，如此可以減少所需要的干擾資料數量。但是，如果α 值設定的太大，容
易使整個干擾資料偏離原始資料集，形成一群離群值，所以建議α 值應介於 2~4 之間，並
且必需考量不同資料集的資料屬性，來給與適當的調整係數，如此才能達到最佳的效果。 
另外，在干擾資料與原始資料的相似度方面，由於是以原始資料的神經元權重值，亦
即原始資料的代表值， 生與原始資料相近似
且不易分辨的干擾資料，是於 Iris 資料集與干擾資料裡各取三筆資料列於表 4.7 4.7 中
的 是 則是依各分群的神經元權重值所產生的干擾
資料，以第一組資料 數值都相 掉 ACL
所產生的干擾資料並不容
 
表4.7 Iris原始資料與ACL產生的干擾資料範例列表 
加上於指定範圍內產生的亂數數值，所以能產
。表
id Iris 資料集裡三個不同分群的資料， z
和 y 為例，不同欄位的
y
1d 1
易。 
當接近，所以要過濾篩選
資料 欄位數值 
1d  (5.10, 3.50, 1.40, 0.20) 
1y  (5.29, 3.83, 1.77, 0.30) 
2d  (7.00, 3.20, 4.70, 1.40) 
2y  (6.96, 3.51, 4.84, 1.69) 
3d  (6.30, 3.30, 6.00, 2.50) 
3y  (7.25, 3.94, 6.11, 2.51) 
 
最後，為了能更廣泛的驗證 ACL 的實用性，本實驗將其它九種不同類型資料集的 ACL
實驗結果，與 Iris 資料集一併彙整列於表 4.8。表 4.8 中的資料，分別是這十種實驗資料集，
將權重值的調比例 r 設為 0.1 與-0.1 所需要增加的干擾資料數量。於實驗結果可知，十種不
同的資料集都於加入一定數量的干擾資料後，即可改變原來的神經元權重值，並達到使用
 
者設定的調整比例。經由不同資料集的實驗，可驗證 ACL 的方法是可多元化的應用。 
 
  10
VM 與 CLC 增加 10%的干擾資料只到達顯著水準 0.05 的差異之
外，其他產生各種比例的資料都達到了 0.01 的顯著差異。所以用本方法對 MySVM 與 CLC
進行防範時，建議增加 20%以上的干擾資料，而對 LibSVM 進行防範時，建議增加 30%以
上的干擾資料。雖然由圖 4.1 的整體平均數看來，MySVM 與 LibSVM 的整體平均差異並不
大，卻檢定出有顯著差異，是因為這些實驗的資料庫中，各個準確度降低的幅度大小不一，
降低幅度較小的資料庫拉低了整體的平均數，所以造成整體平均數顯示差異不大。但是藉
由成對樣本 t 檢定對其資料的變異程度進行檢定，依舊可以證實，本研究所提出的方法，
確實可以有效的干擾各種分類器，達到混亂分類器，使其降低預測準確度的效果。 
表 4.9 防護前後的 t 檢定結果 
 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
料庫防護前與防護後是否有顯著差異。建立的虛無假設與對立假設如下： 
H0 各個資料庫在進行防護前的準確度與防護後的準確度無顯著差異。 
H1 各個資料庫在進行防護前的準確度與防護後的準確度有顯著差異。 
其檢定結果列於表 4.9。由表 4.9 中可以看出，除了 LibSVM 增加 10%與 20%的干擾資
料還未達到顯著差異，MyS
MySVM 0.192 0.011* 0.127* 0.021* 0.029* 0.016* 0.009** 0.006** 0.004** 0.002**
LibSVM 0.023* 0.018* 0.004** 0.002** 0** 0** 0** 0** 0** 0** 
CLC 0** 0** 0** 0** 0** 0** 0** 0** 0** 0** 
KNN 0** 0** 0** 0** 0** 0** 0** 0** 0** 0** 
*Significant at the 0.05 level. 
**Significant at the 0.01 level. 
 
4.3.
算法
被破解的困難度增高，增加其安全性。 
(2) 干擾資料的數量：由於反分群演算法是以「加入整筆干擾資料或是干擾資料欄位」的
式進 料 裝 料 效 反 算 料 以
演 要
式 加 且於 進 ，若 群
到 目 該 的 資料 即 不變 即 著 次 。
方 效 依各 資 況， 的 干擾 ， ，
 
 資料偽裝之安全性分析 
本研究的偽裝知識的方法，主要是藉由加入與原始資料相近似的干擾資料或欄位，來
改變分群或分類分析的結果，使資料裡的分群或分類知識獲得保護，故這些保護方法亦要
能經得起「破解」的考驗，以下將針對有可能受到的攻擊方法進行探討，以充份瞭解本研
究所提出的知識保護方法，其安全性是否符合反探勘的要求。 
(1) key 值的安全性：反分群演算法於進行資料偽裝與還原時所使用的 key 值，即為虛擬
亂數函式中的 Seed 值。Seed 值的設定，除了可以使用一般程式內建的函數外，亦可採
用模組程式進行安全性的強化，例如：RSA、PKI 等等安全性機制，使非法者不易隨
意猜測。除此之外，還原時所需的參數亦缺一不可，這些參數亦可以讓反分群演
方 行資 的偽 ，為了兼顧資 處理 率與 分群演 法資 偽裝的效果，
KAC 算法為例，本研究將每一群 加入的干擾資料數量，設計成以各原始分群的資
料數為基礎，再依偏移比例與演算次數漸進 的增 。並 演算 行中 有分
已達 調整 標，則 分群 干擾 數量 固定 ，意 不再隨 演算 數遞增
如此 可有 率的 分群 料狀 適度 增加 資料 避免干擾資料數量過多
暴露資料集的保護情況。
  12
dings of the Eighth International Conference 
nd Y.H. Kao, “A Novel Anti-competitive Learning Neural 
ngress on Intelligent 
院資訊科技與應用
9(3), January, 2010, 500-505. [EI] 
[14] T.S. Chen, J. Chen, Y.H. Kao and T.C. Hsieh, “A Novel Anti-data Mining Technique Based 
on Hierarchical Anti-clustering (HAC),” Procee
on Intelligent Systems Design and Applications, 3, 2008, 426-430. 
[15] T.S. Chen, J. Chen, B.J. Tu a
Network Technique against Mining Knowledge from Databases,” Proceedings of the 2009 
WRI World Congress on Software Engineering, IV, 2009, 383-386. 
[16] T.S. Chen, J. Chen, Y.C. Lin and Y.C. Tsai, “Research to Protect Database by Shaking 
Random Sampling Interference,” Proceedings of the 2009 Global Co
Systems, III, 2009, 569-572. 
[17] 高元宏，”基礎分群演算法之資料偽裝技術研究”，國立臺中技術學
研究所碩士論文，2009。 
 2
 
二、與會心得 
此次能參與 ICETC 2010 國際學術會議交流，並在國科會的經費補助下，幸得順利前往
主辦地中國上海 - 瀚海明玉酒店 (GOLDEN JADE SUNSHINE HOTEL)。此次任務除了發表
論文外，並能與各國學者互相交流和討論。更擴展在不同的研究領域上，獲取難能可貴的經
驗及新知。 
此次會議時段，同時舉行三個國際性學術會議，包含 The 2010 International Conference on 
Education Technology and Computer (ICETC 2010)、The 2010 International Conference on 
Information and Network Technology (ICINT 2010) 以及 The 2010 International Conference on 
Information and Electronics Engineering (ICIEE 2010)。其會議主題、參與學者及會議的規模，
也相對提高了三倍。雖然藉此提供更多的主題互相交流和分享，然而，因會議時間有限，與
學者討論主題如蜻蜓點水式的交流，無法做更深入的探討和剖析，不免有遺珠之憾。 
總體而言，能有機會與各領域學者互相交流，將此經驗運用於往後的教學或研究上，將
受益無窮。 
 
三、考察參觀活動(無是項活動者略) 
此行程除了發表論文和各國學者互相交流之外，主辦單位提供一張上海世博會的門票，
於會議活動之餘，本人選擇中國館進行參觀。由於時間緊湊、人潮擁擠，參觀世博時走馬看
花，僅稍微體會其文化內容，未能有充足時間深入瞭解此次展覽之精神。 
 
四、建議 
在補助經費有限情況之下，此次無法提供讓參與計畫的學生，有此國際學術交流的機
會。期盼並建議類似的國際學術交流，能提供足夠的經費，讓參與計畫的學生也能夠有此擴
增國際視野，進而提升學生的競爭力。相信對學生往後的學習或畢業後的人生規畫，將有莫
大的啟示和鼓舞。 
 
五、攜回資料名稱及內容 
 Conference Program 
 學術論文集及光碟 
 
 
2010 IACSIT SHANG HAI CONFERENCES 
 
 
- 1 - 
 
2010 IACSIT SHANGHAI CONFERENCES 
SCHEDULE 
 
 
The 2010 International Conference on Education Technology and Computer (ICETC 2010) 
The 2010 International Conference on Information and Network Technology (ICINT 2010) 
The 2010 International Conference on Information and Electronics Engineering (ICIEE 2010) 
 
 
 
 
 
 
 
 
 
Shanghai, China 
GOLDEN JADE SUNSHINE HOTEL 
22-24 June, 2010 
 
 
Sponsored and Published by 
          
www.ieee.org 
www.iacsit.org 
 
2010 IACSIT SHANG HAI CONFERENCES 
 
 
- 18 - 
R753 Improving an Interactive Simulator for Computer Systems with Learning Objects 
S.T.Fung, Vincent Tam, Edmund Y.Lam 
R758 Dynamic Pairwise Key Establishment Algorithm for Wireless Sensor Networks 
Jiashan Huang ,Lei Wang 
 
12：30 - 13：30 Lunch Break 
 
 
Afternoon, June 24, 2010 (Thursday) 
SESSION – 13 (ICETC- Education Technology and Computer) 
Venue: conference room 1 
Session Chair: 
Time: 13:30 – 15:30 
 
R766 Complexity Reduction of the Best Multiple Spanning Tree Algorithm 
F.Akhavan Sigari, Ghasem Mirjalily, Reza Saadat 
R767 Estimating Function points : Using Machine Learning and Regression Models 
Geeta Sikka, Dr.Arvinder Kaur, Dr.Moin Uddin 
R768 Mapping Annotated Sequence Diagram to a Petri Net Notation for Reliability Evaluation 
Sima Emadi 
R773 A Rational Discussion on Deviated Problems between Enterprise Management Teaching and 
Business Community in Universities 
Xiuzhi Zheng, Guochen Du, Qian Wang, Diantong Liu 
R775 Innovation and Practice of National Quality Course of ―Automatic Control System‖ 
YANG Hai-zhu,YU Fashan,LIU Jie  
R776 The research of improving innovate ability from smart car game about Automation specialty 
students 
Liu Jie, Yang Haizhu 
R778 Application of Computers in Environmental Education in China 
Wenxiang Xia, Jincheng Li, Xiong Wang, Jiuzhou Zhao 
R780 A Model for Information Technology Education for Undergraduates of Engineering 
Minjie LI 
R784 The Operation of Supply-chain Logistics in Iron and Steel Enterprises 
WU Xiaozhen, SHAO Zhengyu, ZHANG Xumei, GAO Jun, JIN Guilin  
R794 Development of Visual Circuit Calculation Software Based on MATLAB GUI 
Jingxiu Lee,Weijuan Zhang 
R797 Data Hiding by Exploiting Modification Direction Technique Using Optimal Pixel Grouping 
Kai Yung Lin, Wien Hong, Jeanne Chen, Tung-Shou Chen, Wen Chin Chiang 
R819 Lossless Embedding Using Difference between Sub-sampled images 
Che Lun Pan,Jeanne Chen,Tung-Shou Chen,Wien Hong,Rong-Chang Chen,Wan Yi Ji 
R804 An Improved Interactive Whiteboard System: A New Design and an Ergonomic Stylus 
Koray Yucel, Nevzat Orhan, Gizem Misirli, Gozde Bal, Yasar Guneri Sahin 
R805 Teachers’ Expectations from Computer Technology and Interactive Whiteboard: A survey 
2010 IACSIT SHANG HAI CONFERENCES 
 
 
- 28 - 
Conference Secretariat Contact: 
ICETC：icetc@vip.163.com  
ICINT : icint@vip.163.com  
ICIEE : iciee@vip.163.com  
IACSIT Section: 4006-999-648 (中文咨询电话), +86-28-8652-8228 (International) 
Lossless Embedding Using Difference Between Sub-Sampled Images 
 
Che Lun Pan1, Jeanne Chen2, Tung Shou Chen2, Rong-Chang Chen3, Wan Yi Ji4 
1Dept. of Multimedia & 
Game Science 
Yu Da University 
Miaoli, Taiwan 
panpeter@ydu.edu.tw 
 
2Dep. of Computer Science 
and Information Eng.  
National Taichung Institute 
of Technology 
Taichung, Taiwan 
{jeanne,tschen}@ntit.edu.tw
3Department of Logistics 
Eng. and Management 
National Taichung Institute 
of Technology 
Taichung, Taiwan 
rcchens@ntit.edu.tw 
4Dept. of Info. Management
Yu Da University 
Miaoli, Taiwan 
wanyi.ji@gmail.com 
 
 
Abstract—Kim et al. improved the histogram-shifting 
embedding technique by exploring the spatial correlation 
between pixels. The original image had to be partitioned into 
sub-images. The differences between the sub-images were then 
calculated for use in hiding data. However after embedding, 
larger image damage would be impacted by the resulting 
difference histogram for which an empty bin exists at -1. In 
this paper, we propose a new shifting method to resolve the 
problem which results in higher PSNR. Experimental results 
showed that the proposed method can effectively increase 
image quality, avoid unnecessary damage and the hidden 
secret is not easily detected from the stego media.  
Keywords- histogram shifting; embed; reversible; data 
hiding 
I.  INTRODUCTION 
The advancement of internet has brought on much 
activity on the net. On the internet, transmitted information is 
easily accessible which puts on stake personal privacy, 
intellectual property rights or trade secrets [1]. Security of 
transmitted information has, thereby, become an important 
issue. Much research has been done to protect the transmitted 
information from illegal access, piracy or tamper.  
Data hiding is a technique that hides the secret 
information in a cover media. The media could be voice, text, 
image and files [2]. Currently, the most common media 
transmitted over the internet is the digital image. Much 
research had been done on data hiding techniques [3,4,5] to 
hide secret information on the cover image to provide 
protection to the images during transmission. Reversible data 
hiding is one technique that involves the reversibility of the 
image after the hidden secret was retrieved.  
Ni et al. [6] proposed the histogram shifting technique for 
reversible data hiding. The peak and zero locations need to 
be located before histogram shifting was performed to embed 
the secret data. Since only shifting one grayscale value was 
needed, the stego-image remained perceptibly high quality. 
The payload of this method is restricted by the peak; that is 
the higher the peak the larger the payload and vice versa 
[4][7]. Tsai et al. [8] proposed an improved histogram 
shifting method by using the difference modification of 
pixels to achieve reversibility. The original image is 
partitioned into a number of n×n blocks. The center point of 
each block is the basic pixel which must not be modified 
during embedding and retrieval. The basic pixel value was 
used to subtract the corresponding block pixel values 
resulting in the 1n n× − difference values for each block. The 
histogram was created from all these difference values which 
were used in shifting for embedding data.  
Kim et al. [9] proposed a similar method which also 
made use of the difference pixels but with additional 
embedding levels for embedding data. The embedding level 
allows more room for modification with increased payload. 
Although Kim et al.’s method showed increased payload, an 
unnecessary empty bin located at -1 not only lowers image 
quality but also easy to be detected by illegal users. In this 
paper, the proposed method is to reduce the amount of 
shifting of difference values. The method may improve the 
quality of the image during histogram shifting. 
II. RELATED WORK 
In 2009, Kim et al. proposed a reversible data hiding 
method that improves the traditional histogram-shifting 
technique. They exploited the difference between pixels to 
solve the low embedding capacity problem existed in 
histogram-shifting technique. The payload can be adjusted 
by setting different embedding level. The larger embedding 
level provides larger payload; however, the stego image 
quality will be down graded. The detailed embedding 
procedure is listed as follows:  
Step 1: Partition the original image I sized M M×  into N 
sub-images ( ) 1{ }
k N
kIS =  of size m m× . 
Step 2: Select a sub-image RIS that maximize the spatial 
correlation between ( ) 1{ }
k N
kIS =  as the reference 
image and subtract other sub-images from RIS  to 
obtain 1N −  difference images ( ) 11{ }
k N
kD
−
=
.  
Step 3: For 0 , 1i j m≤ ≤ − , scan the difference images 
( ) 1
1{ }
k N
kD
−
=
 and shift the differences ( ) 1, 1{ }
k N
i j kD
−
=
 in each 
difference image according to the following rule:  
( ) ( )
, ,( )
, ( ) ( )
, ,
1, if 1,
1, if 1.
k k
i j i jk
i j k k
i j i j
D L D L
D
D L D L
+ + ≥ +⎧⎪
′ = ⎨
− − ≤ − −⎪⎩
 
V3-124
2010 2nd International Conference on Education Technology and Computer (ICETC)
C
Step 5: Set 1L L= −  and repeat Step 4 until all the secret 
data are embedded. 
Step 6: After all the secret data are embedded, the stego 
image SI  can be obtained by adding up 
( ) 1
1{ }
k N
kD
−
=
′   
and the reference image RIS . 
The extraction and the original image recovery 
procedures are as follows. 
Step 1: Partition the stego image SI  and obtain the 
reference image RIS  and the difference images 
( ) 1
1{ }
k N
kD
−
=
′ . This step is equivalent to Steps 1-2 in the 
extraction procedure of Kim et al.’s method. 
Step 2: Set 0L = . 
Step 3: Data bits embedded in level L can be extracted by 
performing the following extraction rule: 
If 0L = ,
( )
,
( )
,
1, if 2 1,
0, if 2 ,
k
i j
k
i j
D L
s
D L
′ = +⎧⎪
= ⎨
′ =⎪⎩
 
If 1L = , 
( )
,
( )
,
( )
,
( )
,
1, if 2 1,
0, if 2 ,
1, if 2 ,
0, if 2 1.
k
i j
k
i j
k
i j
k
i j
D L
D L
s
D L
D L
′ = +⎧⎪
′ =⎪
= ⎨
′ = −⎪⎪ ′ = − −⎩
 
If 1L > , 
( )
,
( )
,
1, if 2 1  or  2 1,
0, if 2   or  2 .
k
i j
k
i j
D L L
s
D L L
′ = + − −⎧⎪
= ⎨
′ = −⎪⎩
 
The shifted differences are recovered to their original 
states by using the following rule: 
If 0L = , 
( ) ( )
, ,( )
, ( )
,
1, if 1,
, otherwise.
k k
i j i jk
i j k
i j
D D
D
D
′ ′
− =⎧⎪
′ = ⎨
′⎪⎩
 
If 1L = , 
( )
,
( )
,( )
, ( )
,
( )
,
, if 2 1,
, if 2 ,
, if 2 ,
, if 2 1.
k
i j
k
i jk
i j k
i j
k
i j
L D L
L D L
D
L D L
L D L
′ = +⎧⎪
′ =⎪
′ = ⎨
′
− = −⎪⎪ ′
− = − +⎩
 
If 1L > , 
( )
,
( )
,( )
, ( )
,
( )
,
, if 2 1,
, if 2 ,
, if 2 1,
, if 2 .
k
i j
k
i jk
i j k
i j
k
i j
L D L
L D L
D
L D L
L D L
′ = +⎧⎪
′ =⎪
′ = ⎨
′
− = − −⎪⎪ ′
− = −⎩
 
Step 4: Set 1L L= +  and repeat Step 3 until eL L= . 
Step 5: Shift the difference values in each difference image 
back to their original: 
( ) ( )
, ,( )
, ( ) ( )
, ,
1, if ,
, if .
k k
i j i j ek
i j k k
i j i j e
D L D L
D
D L D L
′ ′
− − >⎧⎪
= ⎨
′ ′+ < −⎪⎩
 
Step 6: The original image I can be obtained by adding up 
the difference images ( ) 11{ }
k N
kD
−
=
 with the reference 
image RIS . 
These modifications enhance the embedding efficiency in 
that the difference ( ),
k
i jD  at 1−  can now be used to embed 
data. In case we need to detect whether the stego image is 
tampered, we can use a hash function, e.g., MD5, to obtain 
the signature of the stego image. The signature can be 
transmitted via a secret channel to the receiver for the 
authentication purpose. 
IV. EXPERIMENTAL RESULTS 
In the experimental testing, comparisons will be made 
with Kim et al.’s [9] method. The selected images are Lena, 
Boat, Airplane and Tiffany with sizes 512×512 (see Fig.1). 
The secret is generated randomly. The peak signal-to-noise 
ratio (PSNR) is used to analyze the quality of the images and 
is defined as follows 
2
10
255PSNR 10log
MSE
= . 
where MSE is used to estimate the difference between the 
original image and the stego image 
1 1
2
, ,
0 0
1MSE ( )
M M
i j i j
i j
x x
M M
− −
= =
′= −
×
∑∑ . 
where ,i jx  and ,i jx′  represent the pixel values of the original 
and stego-image, respectively. A higher PSNR represents the 
closer similarity to the original image. 
 
Table I shows the comparison results between Kim et 
al.’s method and our proposed method. The test is performed 
for each image partitioned to 16 blocks of size 32×32. 
Embedding is done for different embedding levels. The two 
methods are then compared based on PSNR for different 
embedding levels. The results in Table I showed that the 
proposed method has higher PSNR values compared to Kim 
et al.’s method in all embedding levels. However, both 
methods have lower PSNR at higher embedding levels; with 
the proposed method still having higher PSNR. 
 
Figure 1.  Original images having size 512×512. 
(a) Lena (b) Boat 
(c) Airplane (d) Tiffany
V3-126
2010 2nd International Conference on Education Technology and Computer (ICETC)


其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
除了可量化的成果外，本計畫執行期間，我們亦跨領域與資料隱藏研究相結合，
提出一些不同的研究想法，並於資料隱藏的研究中獲得不錯的成果。接下來將
會運用這兩種研究領域的成果，相互激盪出新的研究方向與成果，目前已有嘗
試將初步的成果進行發表。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
