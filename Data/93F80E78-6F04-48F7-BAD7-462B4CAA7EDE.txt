application problems. Resulting factors of asthma are 
complex and there is a lot of information with the 
noises or outlier. Therefore, an intelligent 
algorithm based on BFO is applied to analyze asthma 
data in this project. It includes BFO and robust 
fuzzy algorithm (RFA) in the proposed algorithm. RFA 
is used to establish the fuzzy model to analyze 
asthma data. RFA with the property of robust can 
reduce the influence of noises or outlier, and can 
effectively analyze asthma data. BFO can quickly 
converge to the global best solutions, which 
consequently enhance the efficiency of determining 
asthma. Combined with the advantages of above 
methods, an intelligent algorithm based on BFO is 
applied to analyze asthma data. 
 
英文關鍵詞： Intelligent Algorithm, Bacterial Foraging 
Optimization, Asthma, Robust Fuzzy Algorithm 
 
  
2 
 
1. Introduction 
Asthma has become the highest incidence of chronic disease in children. 
It  is  a  chronic  health  condition  that  causes  inflammation  and  swelling  of  the  airways.   Characteristic  
symptoms  of  asthma  include:  wheezing,  coughing,  difficulty  breathing,  and  tightening  of  the  chest 
[3,6,9]. Generally, data mining techniques are used to analyze asthma data [7,8,18,23]. These algorithms include 
learning rules, decision trees (DT), artificial neural network (ANN), genetic algorithms (GA), support vector 
machine (SVM), etc [2,12,14,24]. In this paper, asthma data classified as four classes have been collected from 
Mackay Memorial Hospital in Taiwan. The asthma data are not evenly distributed and then noises or outlier 
might exist in asthma data. In the literature, some approaches have been proposed to deal with this type of 
data [4,22]. These approaches include resizing training datasets, cost-sensitive classifier and snowball method 
[4,11,17,27]. These approaches might increase the misclassification of classes and loss information in general 
rules, might end up with over specific rules, and might tend to overfit the data and result in poor performance 
[4,16,25,28-31,33]. To overcome above drawbacks, an intelligent algorithm based on BFO and RFA is 
proposed to analyze asthma data in this paper. In the proposed algorithm, RFA has the property of robust and 
then can be used to reduce the influence of noises or outlier. BFO has the mechanism of natural selection. It can 
converge to the global best solutions, which consequently enhance the performance of determining asthma. 
The rest of this paper is organized as follows. Because BFO plays an important role in the proposed 
algorithm, section 2 provides a brief literature overview of BFO. Section 3 describes the proposed algorithm. 
Section 4 outlines the simulation results. It also provides detailed comparisons between the proposed 
algorithm and other existing approaches. Finally, conclusions are drawn in the last section. 
2. The Brief Introduction BFO 
Foraging strategy is to maximize the function of E/T where E is the obtained energy and T is the time for 
spending on foraging. Animals with successful foraging strategies tend to survive, but animals with poor 
foraging strategies could be eliminated. Optimal foraging strategy formulates the foraging problem for 
solving optimal problems. The bacteria foraging optimization was introduced by Passino for solving 
distributed optimization and control problems [19-21]. The foraging strategy of E. coli bacteria can be 
  
4 
 
The reproduced bacteria replace with the other eliminated bacteria. Then, the population of the bacteria 
remains constant. After Nre reproduction steps, the process of elimination and dispersal is taken. Let Ned be 
the number of elimination and dispersal steps. In the elimination and dispersal process, bacteria could be 
eliminated and/or dispersed to a new location according the probability Ped. Elimination and dispersal 
process could reduce the chances of convergence at local optima location. The flowchart of bacteria foraging 
optimization is shown as follows [5,10,15,26]. 
Generate ( , , )i j k l  randomly. 
Compute ( , , , )J i j k l . 
For elimination-dispersal process (l) loop: l=l+1 and l<Ned 
For reproduction process (k) loop: k=k+1and k<Nre 
For chemotaxis process (j) loop: j=j+1 and j<Nc 
For bacterium (i) loop: i=i+1 and i<S 
Generate a random vector ( )i  as a unit length random direction for tumbling behavior.  
Let ( 1, , ) ( , , ) ( ) ( )i ij k l j k l C i i     . 
Let ( , 1, , )lastJ J i j k l  . 
Let ( , 1, , ) ( , 1, , ) ( ( 1, , ), ( 1, , ))
i
sw ccJ i j k l J i j k l J j k l P j k l      . 
Let Nsb = 0 for swimming behavior. 
While sb sN N  
   Nsb = Nsb +1. 
   If ( , 1, , )swJ i j k l  < lastJ  
      Let lastJ = ( , 1, , )swJ i j k l . 
                   Let ( 1, , ) ( 1, , ) ( ) ( )i ij k l j k l C i i      .              
Compute ( , 1, , ) J i j k l and ( , 1, , ) swJ i j k l .                 
End 
  
6 
 
subject to  
1
1


C
i
iju , for Nj 1 ,                                  (6) 
where iju  is the firing strength of the i-th rule for the j-th training pattern,  i  is a robust loss function 
associated with cluster i , and ijw  is the weight function and obtained as  2 2ij ij ijw e e   . To minimize 
J  in Eq. (5) subject to Eq. (6), the Lagrange multiplier method is applied. The Lagrange function is defined 
as  
 
2
2 2
1 1 1 1 1 1
1
C N C N N C
ij i ij ij ij j ij
i j i j j i
L u e w u u 
     
   
      
  
                    (7) 
The necessary conditions for minimizing J  are  
 
2
2
1
0
N
ij
ij iji i
j
eL
u w
a a

 
 
 ,                                    (8) 
The component of 
2
ij
i
e
a


 in Eq. (8) can be obtained by using Eq. (4) as 
 
2
2 2 ( );
iij ij ij
ij j ii i i
e e e
e y f x j a
a a a
     
    
.                     (9) 
Substituting Eq. (9) into Eq. (8), 
     2 2
1 1
( ); 0
N N
iij ij
ij ij j ij ij ii i
j j
e e
u w y u w f x j a
a a 
 
 
 
  ,              (10) 
( )
ij
i
e
x j
a

 

.                                            (11) 
Then, the Eq. (10) can be rewritten as a matrix form 
 
iT T
i iX D X a X DY  , Ci ,...,2,1 .                         (12) 
Hence, the parameter vector 
i
a  for the consequent part of the i-th rule is obtained as 
1i T T
i ia X D X X DY

    , Ci ,...,2,1 ,                        (13) 
     Where ( 1)N mX R    is matrix with ( )x k  as its (k+1)-th row and the elements in the first row are all 1, 
  
8 
 
foraging optimization, J is defined as the error rate (ER) and it is defined as Eq. (18): 
Classification accuracy =
1
( )
100%,  ;
A
i
j
i
asses a
a A
A

 

                 (18) 
                   ER=100%-classification accuracy                                (19) 
Let ( )asses a =a.c then classify(a)=1 otherwise classify(a)=0. Where A is set of asthma data to be classified, 
ia A , a.c is the classification of item a, and classify(a) represents the classification of a. In each iteration of 
bacteria foraging optimization, the process of chemotaxis, swarm and reproduction are performed 
respectively. For chemotaxis process, Eq. (1) is performed to obtain the updated location 
i . Eq. (3) is 
applied to calculate the cost of swJ  for swarm process. For reproduction process, / 2rS S bacteria with the 
least cost of J die and other bacteria with the highest cost of J split into two bacteria at the same location. 
In the elimination-dispersal process, the new i is generated by RFA according to the probability ped. The 
proposed algorithm is repeated until stop criteria have been processed. Finally, the classification accuracy is 
reported. 
4.  Simulation Results 
In the asthma data, there were 338 patients with 44 attributes. These 44 attributes are listed in Table 1. 
To test the accuracy of classification, 250 e-mails are randomly selected as training data and others are test 
data. In simulation, we need to identify a set of parameters. These parameters are set as S=50, Nc=100, Ns=4, 
Nre=4, Ned=2, ped=0.25, attractd =2, repelenth =2, attractw =0.2, repelentw =10 and C(i)=0.1, 1,2, ,i S for BFO. It 
is noted that the same values of parameters are set for all compared approaches for fair comparisons. 
Therefore, the iteration is set as 100 4 2 800c re edN N N      [14]. 
To verify the performance of the proposed algorithm, various approaches include k-nearest neighbor 
(KNN) algorithm [13,34], artificial neural network (ANN), genetic algorithms (GA), and support vector machine 
(SVM). The back-propagation network (BPN) is one of the most used ANNs. In this paper, BPN is used to 
test the performance of asthma data. The simulation results are shown in Table 2. The From Table 2, the 
classification accuracy of the proposed algorithm for asthma data is 91.17%. Because the p-values are not 
  
10 
 
14 Eosin continuous 
15 Ige continuous 
16 PEFR％ continuous 
17 FEVI continuous 
18 FEF25-75％ continuous 
19 Fas continuous 
20 Far continuous 
21 Fad nominal 
22 Furticaria nominal 
23 Fsmoke nominal 
24 spring nominal 
25 summer nominal 
26 fall nominal 
27 winter nominal 
28 EASISCORE continuous 
29 ARSCORE continuous 
30 WBC continuous 
31 Band continuous 
32 Neut continuous 
33 Eosin2 continuous 
34 Baso continuous 
35 Mono continuous 
36 Lym continuous 
37 DP continuous 
38 DF continuous 
39 Cat continuous 
40 Dog continuous 
41 cock continuous 
42 egg continuous 
43 fish continuous 
44 milk continuous 
 
 
 
 
 
 
 
 
  
12 
 
Table 4: The classification accuracy for zoo data 
Approaches Classification accuracy (%) 
DT 94% 
SVM 96.3% 
BPN 90.5% 
GA 91.6% 
KNN 94.48% 
The propose algorithm 99.5% 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
14 
 
Reference  
[1] Blake C, Keogh E, Merz CJ (1998) UCI repository of machine learning databases 
[http://www.ics.uci.edu/»mlearn/MLRepository.html], Department of Information and Computer 
Science, University of California, Irvine, CA. 
[2] Chawla NV, Japkowicz N, Kotcz A (2003) Proceedings of the ICML'2003 Workshop on Learning from 
Imbalanced Data Sets. 
[3] DCAsthma, http://www.dcasthma.org/index.htm 
[4] Fu X, Wang L, Chua KS, Chu F (2002) Training RBF neural networks on unbalanced data, HProceedings 
of the 9th International Conference onH Neural Information Processing 2: 1016-1020. 
[5] Ghoshal SP, Chatterjee A, Mukherjee V (2009) HBio-inspired fuzzy logic based tuning of power system 
stabilizerH, Expert Systems with Applications 36: 9281-9292. 
[6] GINA. http://www.ginasthma.com/ 
[7] Hanifi, G., Abdulkadir, S. (2006) Comparison of clustering algorithms for analog modulation 
classification, Expert Systems with Applications, 30, 642-649. 
[8] Hannu TT,   Päivi O,  Kari V,  Vesa O,  Petteri S,  Heikki M,   Mathias H, Juha K (2000) Data 
mining applied to linkage disequilibrium mapping, The American Journal of Human Genetics 67(1): 
133-145. 
[9] Hardy SG (1992) Nursing implications of increasing asthma prevalence, British Journal of Nursing, 
1(13): 653-659. 
[10] Hazra J, Sinha AK (2008) Environmental constrained economic dispatch using bacteria foraging 
optimization, HJoint International Conference onH Power System Technology and IEEE Power India 
Conference, pp 1-6. 
[11] Hogg RV, Ledolter J (1987) Engineer statistics. England: MacMillan Publishing Company. 
[12] Japkowicz N (2000) Proceedings of the AAAI'2000 Workshop on Learning from Imbalanced Data Sets. 
[13] Jiang Y, Zhou ZH (2004)H Training data for kNN classifiers with neural network ensembleH. ISNN 1: 1-6.  
[14] Lee CY and Lee ZJ (2012) A novel algorithm applied to classify unbalanced data, Applied Soft 
  
16 
 
[28] Wang J, Miyazaki M, Kameda H, Li J (2000) Improving performance of parallel transaction processing 
systems by balancing data load on line, HSeventh International Conference onH Parallel and Distributed 
Systems 5: 331-338.. 
[29] Weiss S, Indurkhya N (1995) Rule-based machine learning methods for functional prediction, Journal of 
Artificial Intelligence Research 3: 383-403. 
[30] Yang X, Song Q, Cao A (2004) Clustering nonlinearly separable and unbalanced data set, H2004 2nd 
International IEEE ConferenceH on Intelligent Systems 2: 491-496. 
[31] Ye D, Chen Z (2008) A rough set based minority class oriented learning algorithm for highly unbalanced 
data sets,H IEEE International Conference onH Granular Computing, 736-739. 
[32] Zhang Y, Wu L (2009) HStock market prediction of S&P 500 via combination of improved BCO approach 
and BP neural networkH, Expert Systems with Applications 36: 8849-8854. 
[33] Zhang J, Bloedorn E, Rosen L, Venese D (2004) Learning rules from highly unbalanced data sets, 
Fourth IEEE International Conference on HData Mining, ICDM '04. H1-4:571-574. 
[34] Zhang J, Mani I (2003) KNN approach to unbalanced data distributions: A case study involving 
information extraction, Proceedings of the ICML'2003 Workshop on Learning from Imbalanced Datasets. 
 
  
100 年度專題研究計畫研究成果彙整表 
計畫主持人：李仁鐘 計畫編號：100-2221-E-211-004- 
計畫名稱：植基於細菌覓食優化之智慧型演算法應用於分析氣喘資料 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
