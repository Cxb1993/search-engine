propose a polynomial time algorithm to re-rank the 
execution order of CARs by rules‘ priority to reduce 
the influence of the rule dependency problem. 
Consequently, the performance (the classification 
accuracy and recall rate) of the associative 
classification algorithm can be improved. 
英文關鍵詞： Association Classification  Text Classification  Rule 
Dependency 
 
 2 
 
究主要探討關聯式分類器中 Rule Dependency Problem 的問題，並提
出不同的多項式時間(polynomial time)排序演算法來設定分類器中
規則的執行順序，以降低規則相依問題對分類結果的影響，進而提
昇關聯式分類器的分類準確度。 
在實驗的部分為了證明我們提出來的演算法，能夠有效改善分
類的準確度，因此我們採用「Reuters-21578」[52]及 UCI 網站[53]
提供的兩組不同的測試資料。其中，Reuters-21578 由路透社(Reuters 
Newswire)從 1987 年 2 月到 10 月間的新聞文件蒐集而成。而 UCI
是美國加州大學爾灣分校（University of California at Irvine）的資訊
電腦學院（Donald Bren School of Information and Computer Science），
UCI 網站收集了各式各樣領域的資料，各國的專家學者可以透過機
器學習或文件分類等學術研究，來對網站所搜集的資料進行分類。
在實驗數據的取樣部份，我們以隨機的方式抽取五次完成，並且在
實驗過程當中的訓練資料佔 80%及測試資料佔 20%。同時，由於
L
3分類演算法與其他 AC 分類演算法比較起來，於準確率方面，平
均高於其他 AC 分類演算法，所以本研究最後分類的結果將與 L3
分類演算法做比較。 
  
 4 
 
相同的第 k 種物品項目組合產生的高頻項目集則稱為 k 高頻項目集。
如此，在傳統的關聯式演算法必須透過去除不滿足最小支持度的
(k-1)高頻項目集再來產生 k 候選項目集，進而找出 k 高頻項目集。
這也就是說，對於 ABC 三項物品項目而言，AB、AC 與 BC 的支
持度必須都高於最小支持度，ABC 候選項目集才能夠生成。這麼才
符合向上包含性質(如果子集合不滿足最小支持度，超集合也必定
不滿足最小支持度)。 
 
Apriori 演算法(Apriori Algorithm)是購物籃分析中最具代表性
的演算法。Apriori 演算法是一種典型的由下而上(Bottom-Up)的演
算法，換言之，Apriori 演算法乃是自長度短的項目集開始，並逐漸
朝長度較長的項目集進行分析。Apriori 演算法在處理每一層不同長
度的項目集時均可分為二大階段；第一階段：產生候選項目集。第
二階段：計算項目集之支持度。其詳細步驟如下： 
首先訂定最小支持度和最小信賴度，然後搜尋整個資料庫一次，
並對每個項目出現的次數進行計數，即候選 1-項目集(Candidate 
1-itemsets)。若是某個項目出現的次數大於或等於所訂定的最小支
持度，則會成為大 1-項目集(Large 1-itemsets)。 
在此步驟中，可分成兩個階段來說明。第一，在第 k-1 層找出
大項目集 Lk-1(Large k-1-itemsets)，並使用 apriori-gen function 產生
 6 
 
根據以上所述，我們以一簡單的例子再加以詳細說明。若資料
庫中含有交易資料，此外假定使用者定義之最小支持度門檻值為
50%，則 Apriori 演算法之過程，如圖 2-3 所示。由於資料庫中含
有{A}、{B}、{C}、{D}和{E}等五個候選“1-項目集”經過第一次
掃描資料庫後，可以獲得此五個項目各自的支持度，和支持度門檻
值比較後可獲得{A}、{B}、{C}、{E}等四個高頻“1-項目集”。接
著利用結合和削減來產生候選“2-項目集”，也就是 C2，再經過掃
描資料庫便獲得 C2 中所有項目集的支持度，再和支持度門檻值比
較，便產生{A，C}、{B，C}、{B，E}、{C，E}等四個高頻“2-項
目集”，反覆進行上述步驟便可產生所有的高頻項目集。 
 8 
 
型(Association Classification)，並為了預測目的建立分類器模型。其
中關聯式法則是找出文件中各詞彙之間的關聯性，而關聯式分類，
主要的目的是做分類的預測，表 2-1 為顯示關聯式法則與關聯式分
類器之差異。 
表 2-1 關聯式規則搜索與關聯式分類差異表 
 
近年來有關 AC 分類器的演算法主要有四種[5][6][7][8]，這些
演算法的執行步驟皆非常相似，而最大的差異點通常在於 CARs[7]
的排序(Ranking)及修剪(Pruning)方法不同；而不同的排序及修剪方
法將直接影響到 AC 分類器的的分類效能。 
規則排序（Ranking），在使用關聯式法則（Association Rule, AR）
建立分類器時，規則的排序會影響分類效能，一般 AC 分類規則排
序，主要先依照信賴值由高至低排序，同樣信賴值再依支援值由高
至低排序，同樣信賴值及支援值，再依規則由短至長排序，為了使
得更多文件可以分類，因此通用性較高的短規則優先於較特別的長
規則。 
 10 
 
容易分類錯誤的影響，[6]於研究中提出 Lazy 的 L3演算法，首先在
刪除規則（Pruning）時除了保留至少分對一篇文件的規則外，另外
在訓練過程中完全分不到類的規則也予以保留，比 CBA[7]及
CMAR[5]等方法留下更多的規則，在規則排序上亦可以準確性為主
要考量準則，先依長規則分類，認為長規則的準確度較高不會有分
類錯誤的問題，若真的無法分類，再來考慮短規則較不會對分類產
生不良的影響。接下來我們針對各別演算法作簡單的介紹。 
2.2.1 Lazy 
Lazy 分類器[6]是由 E.Baralis 所提出之關聯式分類法，研究中
提出 L3演算法( Live And Let Live )包含規則排序方式及修剪規則方
式，L3演算法規則排序的方式，當規則的屬性與屬性之間相同的情
形下，L3演算法會取規則較長的優先執行，將較長較特殊的規則先
行分類，因為 Lazy 分類器認為短規則通用性高容易分類錯誤，因
此給予長規則更高的優先順序，當長規則無法分類時，再以短規則
來分類，其排序方式如下所述 : 
兩個已篩選的規則 Ri, Rj，在下面的條件下，規則 Ri的執行順
序會優先於規則 Rj： 
1. 如果規則 Ri的信賴度高於規則 Rj的信賴度。 
 12 
 
認為雖然這些規則分不到訓練資料但不代表它們是錯誤的規則，因
為在測試資料中或許仍然可以分到資料，所以先將這些規則予以保
留。最後如果還有資料無法被 Usedrules 和 Sparerules 分類，則這
些無法被分類的資料將被直接歸類到預設的類別  (Default 
Class) 。 
 14 
 
(CBA-Classifier Builder)。而CBA-RG規則產生的部分是利用Apriori 
演算法(Agrawal and Srikant 1994) [9] 產生關聯規則。而這個演算法
利用多層次篩選方式，可從資料集每一筆資料的相關屬性找到所有
可 能 有 用 的 規 則 組 合 。 而 CBA-RG 演 算 法 如 圖  2-6 ：
 
圖 2-6 CBA-RG 演算法 
CAB-CB 分類器產生的部分，為了得到最好的分類效果，最佳
分類的準確度，CAB-CB 將從訓練資料集所產生的所有規則集中，
評估所有可能的子集合，選擇具有最高準確率或最低錯誤率的規則
序列，所以 CBA-CB 演算法主要的想法是從整個規則集找出規則準
確率最高的優先順序，且對於整個訓練資料集覆蓋率達 100%的規
則子集產生出分類器。 
 16 
 
3. 如果 Ri和 Rj的信賴度和支持度都相同，則將 Ri的字母排序
在 Rj的字母排序之前。 
 接下來從已排序過的規則集 R 中選取規則放進已選定的規則集 C
中，而放進規則集 C 必須完成下列動作： 
 至少能從未分類資料中分類一筆正確的資料。 
 從已選定規則集 C 中選擇預設分類以及計算錯誤。 
 最後將未能改善分類器準確率的規則從已取定規則集 C 中移除 
 即將規則本身分類之準確率低於已選定規則集C的準確率之
規則進行移除其中 CBA-CB M1 演算法滿足兩個優點： 
1. 每一筆訓練資料集中的資料至少會被已選定規則集C裡一個
規則所分類。 
2. 當規則被篩選放進已選定規則集 C 中，意謂著任一規則至少
能從未分類的訓練資料，正確分類到一筆資料，達到訓練資
料 100%的覆蓋率。 
CBA 分類器在訓練過程中會先找出所有規則並且修剪及排序，
 18 
 
 
圖 2-8 Selecting rules based on database coverage 
如前所述 CBA 法欲對未知的測試資料分類，乃從產生的規則
集裡找到第一條符合的規則予以分類，此規則乃是該測試所有符合
的規則裡排行最高的規則，CMAR 法對此提出不同的看法，認為若
僅依據一條符合的規則加以分類風險極高，尤其對文件數不平均的
文件集更容易造成分類錯誤，因此 CMAR 法將一組符合的規則，
以加權卡方積(weighted X2)的公式算出最高積分的規則予以分類。 
2.2.4 CPAR 與 PRM 
CPAR（classification based on Predictive Association Rules ）演
算法[8]，在規則的產生上繼承了 FOIL (First Order Inductive Learner)
 20 
 
 
圖 2-9 PRM 演算法 
 
 
因 CPAR 是採用貪婪演算法（greedy algorithm），也就是僅考
慮當下應如何能夠得到最高的增益值，優點是快速且容易明瞭，但
缺點是容易忽略了某一條可能極為重要的規則，因而照成文件進行
分類時發生錯誤，分類準確率降低。且由於實驗證實，lazy 演算法
相比於一般的 association classification，如 CBA、CMAR 或是 CPAR
演算法，可以降低 10%的 error rate，而若是跟 decision tree 
 22 
 
Training Document
Test Document
Feature Extraction 
Pre-Process 
Document Representation 
Feature Selection
Class Keywords
 Database
l  r
 t
Classifier
Class A Class B Class C
 
圖 2-10 文件分類流程圖 
如圖 2-10 所示，訓練文件為一批經由人工已預先給定類別的
文件，經過機器預處理，各詞彙分別計算權重並加以篩選足以代表
該類別之特徵詞，運用分類器將測試文件分類並評估分類效能。自
動分類系統會先將文件分解成一個個語意較小的單位，英文文件可
依空格將文件分解成數個詞（Word），再進行學習、分類。預處理
視文件語系而有所不同，英文文件中的詞彙有各種詞性，需做詞幹
處理(Stemming)，目前最著名乃是 Martin Porter 於 1987 年所提出的
Porter Stemmer[13]。 
 24 
 
與摘要以及平均 13 個取自 Mesh（Medical Subject Headline）分類
表的類別，全部用到 14,321 個類別。20ng 為 20 Newsgroups 的縮
寫，最初是由 Ken Lang 在 1995 年整理而成，包含近 20,000 篇文
章，均勻分佈在 20 個Usenet的討論群，大部分文件只有一個類別，
只有 4.5%的文件有兩個或兩個以上的類別。 
 
 
圖 2-12 關聯式分類器分類流程示意圖 
關聯式分類的流程如圖 2-12所示。若將Association Rule應用在文
件分類，則著重在找出同時出現在一篇文件中詞彙的關係，Yoon 
etal.[17]曾利用Association Rule的方法，如圖 2-12，以20 Newsgroups
為文件集，在訓練文件中找出這樣的規則，經過適當的篩選建立規則
 26 
 
經常再定義 F1=2PR/(P+R)，來比較不同系統的成效。 
如果同時有好幾個類別要一起考量，則有 Micro-Average 與
Macro-Average 兩種平均方法，定義如下： 
 
其中註標 I 是指第 I 個類別，而 M 是類別的總數。同理，F1
值也可依原公式，帶入相關的P與R，分別得到Micro-F1或Macro-F1。
Micro-Average 由於是全部文件一起累加統計，不分類別，因此容
易受到大類別（佔大多數文件）表現好壞的影響。相對的，
Macro-Average 考慮每個類別的成效後再做平均，因此容易受到大
量的小類別影響。在展示成效時，經常這兩種平均數據都報告出來，
以便分析比較。從數值上來看，通常 Micro-Average 都遠高於
Macro-Average。 
在 F1=2PR/(P＋R）的公式中，為得到最佳的數據，必須把分
類器的表現調整到 P=R 的情況（準確率等於回收率），以求得最高
的 F1 值。本研究主要將利用準確率、回收率、F1 值來評估我們所
提演算法之效能。 
 28 
 
至相對應的類別，因此文件庫中已無這四篇文件。接下來再執行
R2→C1 規則，此時由於 T11、T12已經先被 R1→C1 分類至 C1 類別，
因此 R2→C1 規則只會將 T14、T22、T23三份文件分類至 C1 類別。
接著執行 R3→C1，將 T15分類至 C1 類別，最後執行 R4→C2，將
T24分類至 C2 類別。依此執行順序，最後分類結果正確 6 篇，錯誤
3 篇，準確度為 66%。 
表 3-1 範例規則 1 
執行順序 規則 分對 分錯 信賴度 
1 R1→C1 T11、T12、T13 T21 75% 
2 R2→C1 T11、T12、T14 T22、T23 60% 
3 R3→C1 T14、T15 T22、T21 50% 
4 R4→C2 T21、T24 T11、T12 50% 
 
但若此時考慮規則相依性，當一篇訓練文件 T 同時被數個規則
參考到時，當其中一條規則先執行後，由於文件 T 已被分類，因此
原先根據文件 T 所產生的規則將受到影響。換言之，由於文件 T 已
被分類，所以對尚未被分類資料而言，有可能會造成其他規則信賴
值改變，且除了信賴度改變外，規則的分類結果也可能會改變。在
此表格中，當執行第一條規則 R1→C1 後，由於 T11、T12、T13、T21
文件已分類，由於 R2、R4 在計算信賴度時有使用到這四份文件，
所以 R2 和 R4 的信賴度會被改變，必須重新計算信賴度，重新計
算信賴度與新的執行順序，如表 3-2 所示。 
 30 
 
C2 信賴度為 100%，R2→C2 信賴度為 66.6%，因此我們將原來的
規則執行順序調整成先執行 R3→C2 ，再執行 R2→C2。所以原本
使用 L3演算法會被分錯的 T24文件，在規則相依的考慮下會分類到
正確的類別。依此執行順序，最後分類結果正確 8 篇，錯誤 1 篇，
準確度為 88%。 
由於規則相依問題會造成規則信賴度的改變，所以對尚未被分
類資料而言，目前關聯式分類法都實際上並未完全信賴度的由高低
來進行分類，進而影響最後分類的結果。根據以上的說明，順序改
變實際上會影響分類的結果。我們在利用 AC 作分類時，必須考慮
規則相依性的問題。但對有 N 條規則的 AC 而言，規則有 N! 種
執行順序，所以要解決規則相依問題 (找尋最佳規則執行順序) 將
是一個非常耗時的工作。所以本論文將針對 規則相依問題 做探討；
提出不同的演算法對規則做重新排序來降低規則相依問題對分類
結果產生的影響，進而改善最後分類的結果。 
 32 
 
Beginningi i
Training 
documents
Store rules ranked 
by the L3 method in 
the rule table
t  l   
 t   t  i  
t  l  t l
Select the highest 
confidence level and 
delete these rules 
from rule table
l   i  
fi  l l  
l   l  
f  l  l
End
Is there a rule? t   l
100% or not?  t
Re-rank the execution 
order of rules in the 
highest confidence 
level
 t  ti  
  l  i  t  
i t i  
l l
Recalculate the confidence 
for rules that are affected by 
the deleted documents and 
change the classification 
categories
l l t  t  i  
 l  t t  t   
t  l t  t   
 t  l i i ti  
t i
Yes
No
No
Yes
Delete redundant 
rules
l t  t 
l
Rule Tablel  l
Delete those 
documents which can 
be classified by the re-
rank rules from 
training documents
l t  t  
t  i   
 l i i   t  
 l   
t i i  t
 
圖 4-1 MLRP 演算法流程圖 
 
在圖 4-1 的流程中，我們首先要刪除多餘的規則，再使用 L3
的排序方法作初始排序，將規則儲存於規則表中。刪除多餘的規則
定義如下: 
 
Definition 1. Let R1 and R2 be two association rules, where R1 = A1, A2, … 
and An -> Ci and R2 = A1, A2, … and Am -> Cj. Then, R2 is a redundant rule 
with respect to R1 iff n  m, i = j, and the confidence of R1  the 
confidence of R2. 
 
在使用 L3演算法排序後，我們依規則信賴度的範圍定義每個階
層。除了 100%信賴度外，在同一信賴度範圍中的規則屬於同一階
 34 
 
 
如圖 4-2 所示，我們提出 MLRP 演算法來找到規則的優先執行
順序。 
 
Algorithm: Multi-Levels Rule Priority 
Input: S be Classification Associative Rules (CARs), a set of documents T 
Output: The execution order (priority) of rule set, Rule Table (RT)  
Procedure Priorityrule(){  
(1) For each highest confidence level in S  
(2)   Let rule set CL be the rules in current highest confidence level 
(3)     If highest confidence level is 100% 
(4)      RT <- RT  CL  
(5)      Remove documents covered by CL from T 
(6)     Else 
(7)      Compute Effective Weight Matrix, EWM, for all rules in CL;  
(8)      CL’ <- Rerank_Priority (CL); 
(9)      Remove documents covered by CL’ from T 
(10)      RT <- RT  CL’ 
(11)     End If 
(12)   Remove rules in CL from S 
(13) End For 
(14) Output RT 
} 
圖 4-2 MLRP 演算法 
 
在圖 4-2 的演算法中，若最高階層的信賴度為 100%，則將這
些規則直接放入 Rule Table(RT：規則表)中(line 4)。接下來，針對每
一個階層最高信賴度且信賴度值小於 100%的規則放入變數
S(Classification Associative Rules：關聯規則)中，並以階層為單位，
將該階層的所有規則取出後計算該階層的 Effective Weight 
Matrix(EWM)。在演算法中，我們利用 EWM來記錄兩規則之間的互
 36 
 
 
Algorithm: Rerank_Priority 
Input:  CL be the rules in current highest confidence level S 
Output: CL’ be the rules with their execution order 
Procedure Rerank_Priority(CL){  
(1) If CL contains only one rule Then Output CL’ <- CL’  CL 
(2) Else { Compute Improve_value[i] with respect to the rules in CL; 
(3)  Let LIV be the rule set with largest Improve_value[i] in CL; 
(4)  A = max_rule(LIV) ; /* Choose the rule A from LIV */ 
(5)  Let S1 and S3 be the sequences of rules in CL; 
(6)  Let S1 = {R11, …, R1n} be the sequence of rules which effective value to A are equal to or 
          greater then 0; That is, EWT[1i, A]  0 and i= 1 to A; 
(7)  Let S3= {R31, …, R3m} be the sequence of rules which positive effect to A are equal to or 
          greater then 0; That is, EWT [A, 3j]  0 and j = A+1 to m;  
(8)  Output (Rerank_Priority (S1) followed by A followed by Rerank_Priority (S3)) 
(9)  } 
(10) } 
圖 4-3 Rerank_Priority 對最高階層的規則重新排序規則演算法 
 
由圖 4-3 的演算法中，我們在排序時需要先瞭解每條規則先執
行時，會對其他規則改善分類準確的程度。因此我們先對每條規則
i 計算出其改善分類準確的程度，計算公式定義如下： 
 
Improve_value[i] = ΣEWT[i, j], where EWT[i, j] > 0. 
 
例如，Improve_value[i] =10 代表所有的規則中，在規則 i 先執
行的狀況之下，會改善 10 篇文件的分類準確度。 
我們使用 EWM 與 Improve_value[i]來決定規則執行的優先順序，
我們首先計算 Improve_value，取出 Improve value 最大值的規則(line 
4，max_rule 演算法，如圖 4-4 所示)。在 Rerank_Priority 演算法的
 38 
 
在執行時會花費較多的時間。因此，本節提出一個名為 Multi-Levels 
Class Priority (MLCP)演算法，與 MLRP 演算法主要的差異在於我們
是計算類別與類別之間的影響來決定每一階層內規則執行的優先
順序，以降低規則相依對分類準確度的影響。例如：在階層 1 中共
有下列 4 條規則 R1→C1、R2→C2、R3→C1、R4→C2，由於此 4
條規則分別屬於兩個不同的類別(C1 與 C2)。所以在執行 MLCP 演
算法後，會決定類別之間的執行優先順序。假設執行 MLCP 演算法
後 C1 類別是優於 C2 類別之前執行，此時所有指向 C1 類別的規則
會比指向 C2 類別的規則優先執行。因此，本範例的規則執行順序
R1→C1、R3→C1 會比 R2→C2、R4→C2 優先執行。 
由於每一階層分類的類別數量並不多，因此我們在執行計算的
效率上會優於 MLRP 演算法。本節我們將詳細介紹 MLCP 演算法。
首先，我們將介紹 MLCP 演算法的流程圖，如圖 4-5 所示。 
 
 40 
 
然後再利用類別間互相影響的狀況來決定階層中類別規則的執行
順序。再接下來，我們會利用前述排好的規則對訓練資料進行分類，
把符合這些規則的文件從訓練資料中刪除並重算其他尚在規則表
中規則的信賴度，然後再依前述步驟決定在規則表中具有最高信賴
度規則的執行順序，以此類推直到全部規則皆排序完成為止。 
如圖 4-6 所示，我們提出 MLCP 演算法來找到規則的優先執行
順序。 
Algorithm: Multi-Levels Class Priority 
Input: S be Classification Associative Rules (CARs), a set of 
documents T 
Output: The execution order (priority) of rule set, Rule Table (RT)  
Procedure Priorityrule(){  
(1) For each highest confidence level in S  
(2)   Let rule set CL be the rules in current highest confidence level 
(3)     If highest confidence level is 100% 
(4)      RT <- RT  CL  
(5)      Remove documents covered by CL from T 
(6)     Else 
(7)     Compute Effective Weight Table of classes, EWT, for all rules in CL;  
(8)      CL’ <- Rerank_Priority (CL); 
(9)      Remove documents covered by CL’ from T 
(10)      RT <- RT  CL’ 
(11)     End If 
(12)   Remove rules in CL from S 
(13) End For 
(14) Output RT 
} 
圖 4-6 MLCP 演算法 
在圖 4-6 的演算法中，若最高階層的信賴度為 100%，則將這
些規則直接放入 Rule Table(RT：規則表)中(line 4)。接下來，針對每
 42 
 
 
Algorithm: Rerank_Priority 
Input:  CL be the classes in current highest confidence level S 
Output: CL’ be the classes with their execution order 
Procedure Rerank_Priority(CL){  
(1) If CL contains only one class Then Output CL’ <- CL’  CL 
(2) Else { Compute Improve_value[i] with respect to the classes in CL; 
(3)  Let LIV be the class set with largest Improve_value[i] in CL; 
(4)  A = max_class(LIV) ; /* Choose the class A from LIV */ 
(5)  Let S1 and S3 be the sequences of classes in CL; 
(6)  Let S1 = {C11, …, C1n} be the sequence of rules which effective value to A are equal to or 
          greater then 0; That is, EWT[1i, A]  0 and i= 1 to A; 
(7)  Let S3= {C31, …, C3m} be the sequence of rules which positive effect to A are equal to or 
          greater then 0; That is, EWT [A, 3j]  0 and j = A+1 to m;  
(8)  Output (Rerank_Priority (S1) followed by A followed by Rerank_Priority (S3)) 
(9) } 
(11) } 
圖 4-7 Rerank_Priority 對最高階層的規則重新排序規則演算法 
 
由圖 4-7 的演算法中，我們在排序時需要先瞭解每個類別先執
行時，會對其他類別改善分類準確的程度。因此我們先對每個類別
i 計算出其改善分類準確的程度，計算公式定義如下： 
 
Improve_value[i] = ΣEWT[i, j], where EWT[i, j] > 0. 
 
例如，Improve_value[i] =10 代表所有的規則中，在類別 i 先執
行的狀況之下，會改善 10 篇文件的分類準確度。 
我們使用EWT與 Improve_value[i]來決定規則執行的優先順序，
我們首先計算 Improve_value，取出 Improve value 最大值的規則(line 
4，max_class 演算法，如圖 4-4 所示)。在 Rerank_Priority 演算法
 44 
 
第5章 實驗結果 
為了證明我們提出來的演算法，能夠有效改善分類的準確度，
所以，本論文採用「Reuters-21578」及 UCI 資料庫中的 Balance 及
Vehicle 資料庫所提供的資料庫做為實驗資料集，探討我們提出演算
法對分類結果的影響。 
5.1 實驗結果(1)-使用 Reuters-21578 
5.1.1 資料來源 
Reuters-21578 由路透社(Reuters Newswire)從 1987 年 2 月到 10
月間的新聞文件蒐集而成，其中裡面有 22 個 SGML 檔案格式所組
成，前面 21 個檔案皆包含了 1000 篇文件，僅最後一個檔案為 578
篇文件，所以共有 21,578 篇文件。文件範例如圖 5-2 所示，此篇
文件為編號 23。圖 5-1 顯示文件中會已<Reuters>開頭，並且已
</Reuters>結尾，而 REUTERS 的文件標籤。 
<REUTERS TOPICS=?? LEWISSPLIT=?? CGISPLIT=?? OLDID=?? NEWID=??> 
圖 5-1 Reuters 文件標籤 
屬性TOPICS是記錄該文件屬於哪類的主題，裡面的值為YES、
 46 
 
 
圖 5-2 Reuters 文件範例 
表 5-1 顯示內文的文件標籤包涵 DATE、PLACES、PEOPLE、
TOPICS、BODY 等，而有些標籤被當作分類的類別，每個類別的
篇數皆不同。 
 
 48 
 
表 5-2 訓練及測試文件數 
Category 
No. of 
Documents 
No. of Training 
Documents 
No. of Test 
Documents 
Earn 2970 2376 594 
Acq 1644 1315 329 
Interest 197 157 40 
money-fx 245 196 49 
Trade 238 190 48 
Total 5294 4234 1060 
 
將資料來源建立完成後，針對文件裡的內容做分析。本研究主
要是針對英文文件進行分類。我們使用下列的步驟來進行文件的預
處理： 
STEP1： 首先必須去除裡面不必要的符號，再進行英文斷句、
斷詞。本實驗在斷句、斷詞的部分採用了微軟公司所開發
的 SQL Server 2008 SSIS[19]中的「詞彙擷取」以及「辭彙
查閱」，將文句斷成為名詞或名詞片語。 
STEP2： 接下來我們使用去除停用字(stop word removal)的演
算法，將 the、to、and、the 等字詞給予移除。因為這些字
詞在文章出現的頻率很高，也不具有鑑別度，在分析的過
程當中，我們必須將這些雜訊移除。表 5-3 為 stop word list
的部分範例。 
  
 50 
 
件中同時出現「shr」、「period」、「Note」單字，則將該文
件分類至「earn」類別，其 confidence 為 100%，預估準確
確為 100%。 
 
表 5-4 DB2 Intelligent Miner 關聯式規則範例 
規則編號 memo1 memo2 memo3 類別 最大 conf 
1 shr period Note earn 100 
2 shr period Mln earn 100 
3 cts gain tax earn 98.96 
4 mln current cts earn 98.96 
5 cts tax gain earn 98.96 
6 march pay record earn 98.96 
7 shares stake common acq 98.96 
8 cts period loss earn 98.96 
… … … … … … 
STEP6： 在使用關聯式法則（Association Rule, AR）建立分類
器時，規則的排序會影響分類效能，一般 AR 分類規則設
定排序，主要先依照信賴值由高至低排序，同樣信賴值再
依支援值由高至低排序，同樣信賴值及支援值，再依規則
由短至長排序，為了使得更多文件可以分類，因此通用性
較高的短規則優先於較特別的長規則。 
STEP7： 在分類器中多餘的規則是不需要的而且實際上會是
一個嚴重的問題，特別是在如果發現規則的數目非常大的
時候。為避免無用的規則過多，有效刪除規則（Pruning）
 52 
 
Predict classified by default class 表示預設類別預測文件數，L3 
proportion 表示使用演算法預測比例，Default Class proportion 表示
預設類別預測文件比例，L3 accuracy rate 表示演算法分類正確率，
Default class accuracy rate 表示預設類別分類正確率。 
在表 5-5 及表 5-6 中，每個類別的正確率（Precision rate）、回
收率（Recall rate）、F1 值是不同的，但因為全部資料都能夠分到類
別的緣故，所以總正確率（Precision rate）、總回收率（Recall rate）、
總 F1 值結果是相同的就如同表 5-5 所示，僅使用 L3 演算法的分類
結果而言，獲得三個數據皆為 84.04%，因此我們以下僅顯示正確
率的數據。 
表 5-5 Classification results from using L3 without Rule Priority(Reuters-21578) 
(a) 
Class 
Total 
doc. 
Total 
correct 
classified 
Correct classified 
by L
3
 
Recall 
Rate(%) 
Accuracy 
Rate(%) 
F1(%) 
Earn 594 564.6 562.6 95.05% 85.41% 89.98% 
Acq 329 276.2 276.2 83.95% 84.52% 84.22% 
Trade 40 19.8 19.8 49.50% 79.93% 61.02% 
Money-fx 49 18.6 18.6 37.96% 74.89% 50.22% 
Interest 48 11.6 11.6 24.17% 51.52% 32.87% 
Total 1060 890.8 888.8 84.04% 84.04% 84.04% 
 
 
 
 
 
 
 
 
 
 54 
 
而少部分的類別卻佔有大量的文件數。觀察表 5-5 及表 5-6 可以看
出，部分類別如 trade、money-fx、interest 三個類別的回收率較低，
主要是因為這三個類別的文件數較少，所以訓練過程中找到的規則
數少，故測試過程中能夠提供分類的規則數相對來說亦不多，此情
形除了會降低這些類別的回收率外，在使用 L3演算法時分不到類的
文件會設定預設類別，因此正確率也會跟著降低。例如：在本實驗
中”earn”類別為預設類別。表 5-5(a)中顯示”earn”類別使用 L3 演算
法的正確率為 85.89%，但因為受到預設類別分類的影響，最後的
正確率只有 85.41%。所以，如圖 5-3 可知，在五次的實驗中，每
次的正確率，所示僅使用L3正確率最低為82.26%，最高為85.19%，
平均正確率為 84.04%。L3 with MLRP 正確率最低為 89.91%，最高
為 91.79%，平均正確率為 90.98%。 
我們由表 5-5、表 5-6 及圖 5-3 顯示，在「使用 L3+MLRP 演
算法」的表現上，其準確率、回收率及 F1 每次實驗皆高於僅使用
L3 演算法。因此，本實驗的結果顯示使用「L3+MLRP 演算法」可
以提高正確分類的結果。 
 56 
 
(b) 
Class 
Correct 
classified 
by default 
class 
Predict 
classifi
ed 
by L
3
 
Predict 
classified 
by default 
class 
L
3 
proportion 
(%) 
Default 
Class 
proportion(
%) 
L
3 
accuracy 
rate(%) 
Default 
class 
accuracy 
rate(%) 
Earn 2 660.8 6 99.09% 0.91% 87.33% 33.33% 
Acq 0 324.8 0 100.00% 0.00% 96.30% 0.00% 
Trade 0 18.6 0 100.00% 0.00% 68.90% 0.00% 
Money-fx 0 19.8 0 100.00% 0.00% 54.56% 0.00% 
Interest 0 30 0 100.00% 0.00% 45.71% 0.00% 
Total 2 1054 6 99.43% 0.57% 87.90% 33.33% 
本實驗結果我們設定信賴度範圍 1%為同一階層，由於總正確
率（Precision rate）、總回收率（Recall rate）、總 F1 值結果是相同
的，就如表 5-5 所示，僅使用 L3 演算法的分類結果而言，獲得三
個數據皆為 84.04%。如圖 5-4 顯示五次的實驗中，每次的正確率。
僅使用 L3 正確率最低為 82.26%，最高為 85.19%，平均正確率為
84.04%。而 L3 with MLCP 正確率最低為 86.98%，最高為 88.21%，
平均正確率為 87.58%。 
由表 5-5、表 5-7 及錯誤! 找不到參照來源。顯示，在「使用
L
3
+MLCP 演算法」的表現上，其準確率 P、回收率 R 及 F1 皆高於
僅使用 L3 演算法。因此，本實驗的結果顯示使用「L3+MLCP 演算
法」可以提高正確分類的結果。 
 58 
 
表 5-8 Balance 資料庫範例 
類別 左權重 左側距離 右權重 右側距離 
B 1 1 1 1 
R 1 1 1 2 
R 1 1 1 3 
R 1 1 1 4 
R 1 1 1 5 
R 1 1 2 1 
R 1 1 2 2 
Vehicle 資料庫是記錄車輛二維輪廓的形狀特徵的資料集。1986
年由 Drs.Pete Mowforth 提供給 UCI 做為數據資料庫。表 5-9 顯示
示 Vehicle 的資料範例，此資料集中有 18 個屬性及 4 個類別，共有
946 筆資料。 
表 5-9 Vehicle 資料庫範例 
類別 半徑比 距離面積 長寬比 
最大長度的
矩形面績 
短軸長度 長軸長度 … 
Van 95 48 83 178 72 10 … 
Van 91 41 84 141 57 9 … 
Saab 104 50 106 209 66 10 … 
Van 93 41 82 159 63 9 … 
Bus 85 44 70 205 103 52 … 
Bus 107 57 106 172 50 6 … 
Bus 97 43 73 173 65 6 … 
 
 
 
 
 
 60 
 
演算法的分類結果而言，獲得三個數據皆為 77.66%。 
 Balance 資料庫 
 
表 5-12 Classification results from using L3 without Rule Priority(Balance) 
(a) 
Class 
Total 
rec. 
Total 
correct 
classified 
Correct classified 
by L
3
 
Recall 
Rate(%) 
Accuracy 
Rate(%) 
F1(%) 
L 58 44 42 75.86% 70.94% 73.30% 
R 58 46.8 46.8 80.69% 83.66% 82.13% 
B 10 7.2 7.2 72.00% 90.28% 79.98% 
Total 126 98 96 77.78% 77.78% 77.78% 
 
(b) 
Class 
Correct 
classified 
by 
default 
class 
Predict 
classified 
by L
3
 
Predict 
classified 
by 
default 
class 
L
3
 
proportion(%) 
Default Class 
proportion(%) 
L
3
 
accuracy 
rate(%) 
Default 
class 
accuracy 
rate(%) 
L 2 57 5 91.22% 8.78% 73.66% 40.00% 
R 0 56 0 100.00% 0.00% 83.66% 0.00% 
B 0 8 0 100.00% 0.00% 90.28% 0.00% 
Total 2 121 5 95.87% 4.13% 79.34% 40.00% 
 
 
表 5-13 Classification results from using L3 with MLRP Algorithm(Balance) 
(a) 
Class 
Total 
rec. 
Total 
correct 
classified 
Correct classified 
by L
3
 
Recall 
Rate(%) 
Accuracy 
Rate(%) 
F1(%) 
L 58 47.8 45.8 82.41% 78.13% 80.21% 
R 58 50.6 50.6 87.24% 90.06% 88.62% 
B 10 7.6 7.6 76.00% 88.61% 81.75% 
Total 126 106 104 84.13% 84.13% 84.13% 
 
  
 62 
 
 
表 5-15 Classification results from using L3 with MLRP Algorithm(Vehicle) 
(a) 
Class 
Total 
rec. 
Total 
correct 
classified 
Correct classified 
by L
3
 
Recall 
Rate(%) 
Accuracy 
Rate(%) 
F1(%) 
bus 44 28.8 27.8 65.45% 84.20% 73.57% 
opel 43 42 42 97.67% 83.71% 90.15% 
saab 44 40.8 40.8 92.73% 92.29% 92.50% 
van 40 37.6 37.6 94.00% 88.65% 91.22% 
Total 171 149.2 148.2 87.25% 87.25% 87.25% 
 
(b) 
Class 
Correct 
classified 
by 
default 
class 
Predict 
classified 
by L
3
 
Predict 
classified 
by 
default 
class 
L
3
 
proportion(%) 
Default Class 
proportion(%) 
L
3
 
accuracy 
rate(%) 
Default 
class 
accuracy 
rate(%) 
bus 1 31.2 3 90.33% 9.67% 89.11% 33.33% 
opel 0 50.2 0 100.00% 0.00% 83.71% 0.00% 
saab 0 44.2 0 100.00% 0.00% 92.29% 0.00% 
van 0 42.4 0 100.00% 0.00% 88.65% 0.00% 
Total 1 168 3 98.21% 1.79% 88.22% 33.33% 
 
圖 5-5 顯示 UCI_Balance 資料庫五次實驗的正確率。L3 with 
MLRP 正確率最低為 82.54%，最高為 85.71%，平均正確率為 84.13%。
在相同的測試資料中，使用僅使用 L3 演算法正確率最低為 74.60%，
最高為 80.16%。所以，如圖 5-6 可知 UCI_Vehicle 資料庫五次實驗
的正確率。L3 with MLRP 正確率最低為 86.55%，最高為 88.3%，
平均正確率為 87.14%。在相同的測試資料中，使用僅使用 L3 演算
法正確率最低為 75.44%，最高為 82.46%。 
 64 
 
5.2.3 The Multi Levels Class Priority Algorithm 實
驗結果 
本研究將「使用 L3+MLCP 演算法」針對 Balance 資料庫及
Vehicle 資料庫分別進行五次實驗，結果顯示在表 5-17(Balance 資
料庫詳細執行結果請參考附錄 E、Vehicle 資料庫詳細執行結果請參
考附錄 F)。 
 Balance 資料庫 
表 5-16 Classification results from using L3 with MLCP Algorithm(Balance) 
(a) 
Class 
Total 
doc. 
Total 
correct 
classified 
Correct classified 
by L
3
 
Recall 
Rate(%) 
Accuracy 
Rate(%) 
F1(%) 
L 58 46.8 44.8 80.69% 76.74% 78.66% 
R 58 48.4 48.4 83.45% 85.53% 84.47% 
B 10 7 7 70.00% 83.61% 76.14% 
Total 126 102.2 100.2 81.11% 81.11% 81.11% 
 
(b) 
Class 
Correct 
classified 
by 
default 
class 
Predict 
classified 
by L
3
 
Predict 
classified 
by 
default 
class 
L
3
 
proportion(%) 
Default Class 
proportion(%) 
L
3
 
accuracy 
rate(%) 
Default 
class 
accuracy 
rate(%) 
L 2 56 5 91.07% 8.93% 80.02% 40.00% 
R 0 56.6 0 100.00% 0.00% 85.53% 0.00% 
B 0 8.4 0 100.00% 0.00% 83.61% 0.00% 
Total 2 121 5 95.87% 4.13% 82.81% 40.00% 
 
 
 
 
 
 66 
 
70%
72%
74%
76%
78%
80%
82%
84%
第1次 第2次 第3次 第4次 第5次
A
cu
ra
cy
 R
ag
e
(%
)
次數
Accuracy Rate(%)
L3
class_priority
 
圖 5-7 UCI_Balance 資料庫五次 MLCP 實驗正確率 
 
在「使用 L3+MLCP 演算法」的表現上，我們由圖 5-7、圖 5-8、
表 5-17 顯示，其準確率皆高於僅使用 L3 演算法。因此，本實驗的
結果顯示使用「L3+MLCP 演算法」可以提高正確分類的結果。 
70%
72%
74%
76%
78%
80%
82%
84%
86%
88%
第1次 第2次 第3次 第4次 第5次
A
cc
u
ra
cy
 R
at
e
(%
)
次數
Accuracy Rate(%)
L3
class_priority
 
圖 5-8 UCI_Vehicle 資料庫五次 MLCP 實驗正確率 
 68 
 
Bibliography 
[1] F. THABTAH, “A review of associative classification mining,” Knowl. Eng. Rev., vol. 
22, 2007, pp. 37-65. 
[2] J.-Y. Jiang, R.-J. Liou, and S.-J. Lee, "A Fuzzy Self-Constructing Feature 
Clustering Algorithm for Text Classification,"accepted by IEEE Transactions on 
Knowledge and Data Engineering, Nov. 2009. 
[3] B. Settles. Active learning literature survey. Computer Sciences Technical Report 
1648, University of Wisconsin–Madison, 2009. 
[4] P. Soucy and G. Mineau, “A simple KNN algorithm for text categorization,” Data 
Mining, 2001. ICDM 2001, Proceedings IEEE International Conference on, 2001, 
pp. 647-648. 
[5] W. Li, J. Han, and J. Pei, “CMAR: accurate and efficient classification based on 
multiple class-association rules,” Data Mining, 2001. ICDM 2001, Proceedings 
IEEE International Conference on, 2001, pp. 376, 369. 
[6] P.G. Elena Baralis, “A Lazy Approach to Pruning Classification Rules,” Dec. 2002. 
[7] B. Liu, W. Hsu, and Y. Ma, “Integrating Classification and Association Rule Mining,” 
Knowledge Discovery and Data Mining, 1998, pp. 86, 80. 
[8] Yin, X. & Han, J. 2003 CPAR: Classification based on predictive association rule. 
In Proceedings of the SIAM International Conference on Data Mining. San 
Francisco, CA: SIAM Press, pp. 369–376. 
[9] R. Agrawal, T. Imielinski, A. Swami, “Mining Association Rules between Sets of 
Items in Large Databases,” Proceedings of the 1993 ACM SIGMOD 
Conferencen on Management of Data, Washington D.C., pp. 207-216, May 
1993. 
[10] K. Wang, S. Zhou, and Y. He, “Growing decision trees on support-less association 
rules,” Proceedings of the sixth ACM SIGKDD international conference on 
Knowledge discovery and data mining, Boston, Massachusetts, United States: 
ACM, 2000, pp. 265-269. 
[11] K. Wang, Y. He, and D.W. Cheung, “Mining confident rules without support 
requirement,” Proceedings of the tenth international conference on Information 
and knowledge management, Atlanta, Georgia, USA: ACM, 2001, pp. 89-96. 
[12] K. Aas and L. Eikvil. “Text categorisation: A survey,” Technical report, Norwegian 
Computing Center, 1999. 
 70 
 
LEARNING, vol. 667, 1993, pp. 3--20. 
[27] E. Baralis, S. Chiusano, and P. Garza, “On support thresholds in associative 
classification,” Proceedings of the 2004 ACM symposium on Applied computing, 
Nicosia, Cyprus: ACM, 2004, pp. 553-558. 
[28] R. Agrawal and R. Srikant, “Fast Algorithms for Mining Association Rules,” Proc. 
20th Int. Conf. Very Large Data Bases, VLDB, J.B. Bocca, M. Jarke, and C. 
Zaniolo, eds., Morgan Kaufmann, 1994, pp. 487–499. 
[29] Y. Yang and X. Liu, “A re-examination of text categorization methods,” 
Proceedings of the 22nd annual international ACM SIGIR conference on 
Research and development in information retrieval, Berkeley, California, United 
States: ACM, 1999, pp. 42-49. 
[30] T. Joachims, “A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text 
Categorization,” Proceedings of the Fourteenth International Conference on 
Machine Learning, Morgan Kaufmann Publishers Inc., 1997, pp. 143-151. 
[31] P. Bickel and E. Levina, “Some theory for Fisher's linear discriminant function, 
`naive Bayes', and some alternatives when there are many more variables than 
observations,” Bernoulli, vol. 10, 2004, pp. 1010, 989. 
[32] Tseng, Yuen-Hsien, “Effectiveness Issues in Automatic Text Categorization,” 
Bulletin of the Library Association of China, vol. 68, Jun. 2002, pp. 62-83. 
[33] Cho-Ming Lee, “Classifying Chinese Text Documents by Association Rule,” 
Master thesis of Tamkang University, Jun. 2006, pp. 1-66. 
[34] Lee, L., Isa, D., Choo, W., & Chue, W. (2010). Tournament structure ranking 
techniques for Bayesian text classification with highly similar categories. Journal 
of Applied Sciences, 10, 1243-1254. 
[35] Sriram, B., Fuhry, D., Demir, E., Ferhatosmanoglu, H., & Demirbas, M. (2010). 
Short text classification in twitter to improve information filtering. 
[36] Botsis, T., Nguyen, M. D., Woo, E. J., Markatou, M., & Ball, R. (2011). Text mining 
for the Vaccine Adverse Event Reporting System: medical text classification 
using informative feature selection. Journal of the American Medical Informatics 
Association, 18(5), 631-638. 
[37] Crossley, S. A., & McNamara, D. S. (2011). Shared features of L2 writing: 
Intergroup homogeneity and text classification. Journal of Second Language 
Writing. 
[38] Ganiz, M., George, C., & Pottenger, W. (2011). Higher Order Na&# x00EF; ve 
Bayes: A Novel Non-IID Approach to Text Classification. Knowledge and Data 
Engineering, IEEE Transactions on(99), 1-1. 
 72 
 
[52] http://www.daviddlewis.com/resources/testcollections/reuters21578 
[53] http://archive.ics.uci.edu/ml/index.html 
[54] Francesco Ricci, Lior Rokach, Bracha Shapira, Paul B. Kantor (Eds.): 
Recommender Systems Handbook. Springer 2011, ISBN 978-0-387-85819-7 
[55] J. Hipp, U. Güntzer, and G. Nakhaeizadeh, “Algorithms for Association Rule 
Mining – A General Survey and Comparison,” SIGKDD Explorations, Vol. 2, 
Issue 1, pp. 58-64, 2000. 
[56] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo, “Fast 
Discovery of Association Rules,” Advances in Knowledge Discovery and Data 
Mining, U. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, eds., 
AAAI/MIT Press, pp. 307-328, 1996. 
[57] J. Han and Y. Fu, “Mining Multiple-level Association Rules in Large Databases,” 
IEEE Trans. on Knowledge and Data Eng., Vol. 11. No. 5, pp. 798-805, 1999. 
[58] A. Savasere, E. Omiecinski, S. Navathe, “An Efficient Algorithm for Mining 
Association Rules in Large Database,” Proc. 21th VLDB, Zurich, Switzerland, pp. 
432-444, 1995. 
[59] H. Toivonen, “Sampling large databases for association rules,” In Proc. 22nd 
VLDB Conference, Bombay, India, pp. 134-145,Sept. 1996. 
[60] J.S. Park, M.S. Chen, and P.S. Yu, “Using a Hash-Based Method with 
Transaction Trimming for Mining Association Rules,” IEEE Trans. on Knowledge 
and Data Eng., vol. 9, no. 5, pp. 813-825, Sept./Oct. 1997. 
[61] Hung-Ju Huang; Chun-Nan Hsu;, “Bayesian classification for data from the 
same unknown class: Systems, Man and Cybernetics ” , Part B, IEEE 
Transactions on , Volume: 32 , Issue: 2 , April 2002，pp137-145 
[62] H D Navone, D Cook ,T Downs and D Chen, “Boosting Naive-Bayes classifiers 
to predict outcomes for hip prostheses, Neural Networks”, 1999. IJCNN '99. 
International Joint Conference on , Volume: 5 , 10-16 July 1999，pp3622 – 
3626 
[63] Weiguo Fan, Michael D. Gordon, and Praveen Pathak,2004,” Discovery of 
Context-Specific Ranking Functions for Effective Information Retrieval Using 
Genetic Programming”, IEEE TRANSACTIONS ON KNOWLEDGE AND DATA 
ENGINEERING, VOL. 16, NO. 4, pp. 523-527 
 
100 年度專題研究計畫研究成果彙整表 
計畫主持人：蔣璿東 計畫編號：100-2221-E-032-062- 
計畫名稱：文件分類運用多層次之規則優先關聯分類器 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
