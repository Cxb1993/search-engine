Abstract 
This report aims at developing novel methodologies and core technologies for 
system design, capabilities, functionalities, and implementation of an intelligent 
human-symbiotic service robot with ability of high-speed maneuvers. A modular and 
mechatronic method is presented to design and synthesize such an advanced robot 
with desired capabilities and functions of learning, adaptation, networking, 
intelligence, mobility, safety, reliability, cost, appearance and human-robot interaction. 
All novel components and subsystems developed in this project include (i) novel 
mechanism design of a two-wheeled self-balancing mobility mechanism and two 
multiple degrees-of-freedom manipulators; (ii) improved design of smell, tactile and 
FM-modulated ultrasonic sensors,  and  control of the mobility mechanism and the 
dual arm-hand configuration; (iii) advanced localization and navigation system design 
and its applications; (iv) intelligent computer vision and audition using computational 
intelligence; (v) cooperation, force compliance and learning of the two arms and 
high-speed visual servoing;; (vi) intelligent man-machine interfacing and man-robot 
interaction using intelligent multi-agent approach and service-oriented architecture.  
All the developed key components and subsystems together with other well-known 
technologies will be implemented into an experimental robotic system, which will be 
considered as a test platform to evaluate how the robot interacts with people.  In 
addition to a variety of theoretical innovation and improvement, all the proposed core 
technologies and designed functions are realistically constructed and verified via 
experimentations on the laboratory-built robots.  Through computer simulations and 
experimental results, all the proposed technologies are proven useful and effective not 
only in establishing and improving the real operation functions, mobility and 
intelligence of the current human symbiotic robots, but also in extending the 
 ii
中文摘要 
本報告的目的是研發具有高速運動功能的智慧型與人共生機器人，以及探討該
系統設備之關鍵核心技術及其相關系統晶片與軟硬體實現技術。一兼顧感知學
習、行動、操控性、智慧決策、安全、可靠度、價格、造型與友善介面等功能
的機電模組化設計策略被提出來用以設計一前瞻與創新之智慧型與人共生機器
人系統。此系統之關鍵核心技術研發項目，由各子計畫分別執行，其重點涵蓋
高速運動功能的兩輪自平衡運動平台與具力量順應的雙手臂機構設計，驅動控
制技術及其系統晶片研製，先進定位導航技術，智慧型視覺與聽覺，智慧型人
機互動系統設計以及順服雙手臂學習合作與視覺伺服等六項。整合計畫的重點
是需整合以上核心技術，完成可進行實驗展示的與人共生服務機器人系統，並
且進行必要的使用者評估。除創新理論與技術的發展外，所有的單項關鍵技術
與整合系統功能均需被實際地製作成系統晶片並分別在原型設備上進行實驗測
試以檢證其可行性與有效性。本整合計畫所開發的關鍵技術可提昇智慧型與人
共生機器人系統的運動功能、操控性、感知、學習與智慧；所研發的系統軟硬
體建置與相關實務技術，不但有助於現今目前與人共生機器人系統的研製，同
時可推廣應用於休閒娛樂、居家服務以及老年照護機器人之研發。 
 
關鍵詞 ： 與人共生，服務機器人，兩輪，自平衡，運動平台，定位，導航，觸
覺，力量順應，超音波，語音對話，語音控制，影像辨識、姿態辨識，人機介面，
雙手臂，高速視覺伺服。 
 iv
3.8  本章結論 ........................................................................................................46 
第四章   第二年研究成果 .....................................................................................20 
4.1  前言 .................................................................................................................47 
4.2  總計畫「智慧半人型與人共生服務機器人之設計與研製」 .....................47 
4.3  子計畫二「嵌入式智慧型感測器與運動控制器之設計與研製 .................48 
4.4  子計畫三「先進定位導航技術」 .................................................................51 
4.5  子計畫四「智慧型機器人之視覺與聽覺系統設計」 ......................54 
4.6  子計畫五「具視覺伺服之雙手臂順服控制與合作學習」 .............56 
4.7  子計畫六「智慧型人機互動系統設計」 .............................................59 
4.8  本章結論 ........................................................................................................69 
第五章  第三年研究成果 .......................................................................................20 
5.1  前言 .................................................................................................................62 
5.2  總計畫「智慧半人型與人共生服務機器人之設計與研製」 .....................62 
5.3  子計畫二「嵌入式智慧型感測器與運動控制器之設計與研製 .................63 
5.4  子計畫三「先進定位導航技術」 .................................................................68 
5.5  子計畫四「智慧型機器人之視覺與聽覺系統設計」 ......................71 
5.6  子計畫五「具視覺伺服之雙手臂順服控制與合作學習」 .............80 
5.7  子計畫六「智慧型人機互動系統設計」 .............................................85 
5.8  本章結論 ........................................................................................................91 
第六章  總結與未來研究 .......................................................................................20 
6.1  總結 .................................................................................................................92 
6.2  未來研究 .........................................................................................................94 
參考文獻 .....................................................................................................................20 
附錄一 計畫成果自評 ...............................................................................................20 
 
 vi
圖 3.6 與人共生機器人之避障之實驗結果..............................................................37  
圖 3.7 移動式機器人測試平台(點餐服務機器人)...................................................38  
圖 3.8 閃避障礙物終點正確面向 90°實際測試. (1)  機器人行走軌跡 (2)終點距   
離、馬達轉速、目標角度、機器人角度及障礙物距離值................................39 
圖 3.9 閃避障礙物終點正確面向 180°實際測試. (1)  機器人行走軌跡 (2)終點距
離、馬達轉速、目標角度、機器人角度及障礙物距離值................................40  
圖 3.10 第一組實驗之結果........................................................................................42  
圖 3.11 第二組實驗之結果........................................................................................42  
圖 3.12 第三組實驗之結果........................................................................................42  
圖 3.13 基於橢圓體之距離估計...............................................................................43  
圖 3.14 (a)兩只機器手臂移動時碰撞；(b)速度控制下的兩只機器手臂移動且無碰
撞..............................................................................................................................44 
圖 4.1 實際雙手臂機器人平台..................................................................................47  
圖 4.2 雙手臂機器人之嵌入式系統架構圖..............................................................48  
圖 4.3 雙圈運動..........................................................................................................49  
圖 4.4 雙手臂寫字......................................................................................................50  
圖 4.5 雙手臂合作抓取色球......................................................................................50  
圖 4.6 泡咖啡任務......................................................................................................51  
圖 4.7 點餐服務機器人第二代之硬體實體圖.........................................................52  
圖 4.8 點餐服務機器人第二代之系統架構圖.........................................................52  
圖 4.9 機器人軌跡(無障物).....................................................................................53 
圖 4.10 機器人軌跡(有障物)...................................................................................53  
圖 4.11 KGPS 誤差量 .................................................................................................54  
圖 4.12 多路徑導航實際與預期比較.......................................................................54  
圖 4.13 餐盤辨視.......................................................................................................54  
圖 4.14 資料庫影像範例...........................................................................................56  
 viii
圖 5.18 機器人模擬環境圖.......................................................................................77  
圖 5.19 基因演算法適應值變化圖..........................................................................78  
圖 5.20 5 與75× 7× 之基因演算法模擬結果 ..........................................................78  
圖 5.21  global 與 local 參考路徑示意圖................................................................79  
圖 5.22 5 與75× 7× 之基因演算法模擬驗證 ..........................................................80  
圖 5.23 整合開發系統平台運用架構......................................................................81  
圖 5.24 整合開發系統架構......................................................................................81  
圖 5.25 dsPIC 控制模組...........................................................................................82  
圖 5.26 SPI 與 CAN 互轉電路實體圖 ....................................................................83  
圖 5.27 DE2-70 開發板 ............................................................................................84  
圖 5.28 控制機器手臂之實現架構..........................................................................84  
圖 5.29 控制機器手臂之實現實體圖......................................................................85  
圖 5.30.情境感知系統架構.........................................................................................87  
圖 5.31 驗證方法循序圖............................................................................................90  
圖 5.32 Document Translator 內部循序圖..................................................................90  
 
 x
  
第一章 
緒論 
 
1.1 研究背景 
   現階段國家科學委員會配合行政院 SBR 會議大力投入智慧型機器人科技發展，期望開發
符合國內外研究趨勢與市場需求的關鍵、核心技術與商品，用以提供人類生活更好的協助，
並進而建立相關的新興產業，落實該重點研究成果於國家整體經建發展。有鑑於近年來服務
機器人系統技術的研究，在美、日、德、韓等國已蓬勃發展，各國不斷地推出創新功能的服
務機器人；國內也有許多學術工作者積極從事於此方面的研究。我國政府的智慧型機器人發
展策略，也由機器人為「人的助理」的概念，逐步朝向發展「人的夥伴(伴侶)」以及「隨時
幫助(無所不在)者」等高智能機器人。 綜覽國內外目前服務機器人之發展雖迅速，但其功能
都僅能執行某些簡單或特定的任務，動作行為，反應速度、認知與智慧操作功能也不足，離
真正能服務人類活動或成為「人類夥伴」的願景，尚須許多的研究努力與創意。因此本報告
即在此大前提及動機之下，擬從事此一結合雙臂與兩輪自平衡與四輪複合機構設計與驅動控
制、臉部表情、新型感測(超音波探測)、雙手臂協調控制，力量順應、定位、自主導航、智
慧型視覺與聽覺、高速影像伺服、智慧型軟體、人機互動以及嵌入式系統晶片等跨領域科技
之研究構想－智慧半人型與人共生服務機器人之設計與研製。    
與人共生的夥伴機器人一直被認為有可能實現服務人類活動或成為「人類夥伴」的機器人
種類，這種機器人的研究目的是期望發展在人類真實生活空間內，與人類安全共處，達成服
務人類活動的機器人科技，但實用可行的與人共生人型機器人系統需要高度工藝與跨領域科
技的系統整合。除了基本運動平台之驅動、控制與導航技術外，本整合報告將周延明確地掌
握某些應用領域(如商用服務、休閒娛樂、居家服務以及老年照護等領域)的實際需求與可能
處境，進而轉換成系統設計規格與性能，然後在應用已有或研發創新相對應的工程技術，並
進行一連串的設計與修正，用以落實或達成所定義的需求、機能與性能。同時為適合不同技
 1
 
 型的比例縮小，身高越矮重量越輕，耗能與越少(攜帶的能量也跟著降低)，致動器的輸出轉
矩越小，感測與控制器的尺寸將隨之縮小，所需的材料機械強度也較弱，對使用者的心理威
脅也較弱。因此，以目前本計劃團隊所具有之小型和輕量化的機構技術、具環保功能的鎳氫
或離電池、IC 化馬達致動器，輕薄短小且功能強大的感測技術，智慧型軟體與訊號處理，與
高性能的控制技術，嵌入式系統晶片技術等技術能力，應可符合研製一高度約於如圖 1.1 所
示，130 公分的智慧型與人共生服務夥伴機器人，其規格如下： 
體積：寬 600 mm×高 1300mm×縱深 600mm 
重量：60 公斤 
移動平台：兩輪自平衡移動與四輪複合跨障機構(共四輪，平坦地形採用兩輪自平衡運動
機構（移動速度靈敏、快速，最大移動速度 1.67m/sec (即 6 km/hr)），跨越不平
坦地形與執行特殊工作則採用四輪機構)。  
雙手臂：六個自由度的雙手臂，一至多個個自由度的手指，手臂定位精度 1cm，可協調合
作。 
計算模組：採用單一 PC 作為視覺，聽覺，導航與語音人機互動系統的計算模組，其他的
裝置皆使用嵌入式系統晶片。 
頭頸與臉部表情系統：三個自由度的頸部系統，多自由度的臉部表情系統，具喜怒哀樂等
情緒。 
驅動：兩輪自平衡移動與四輪複合跨障機構採用 DC 無刷伺服馬達與專用驅動晶片，雙手
臂與頸部採用 Maxon DC 有刷伺服馬達與 Nios Stratix II 系統控制晶片，臉部表情
系統採用 RC 馬達與 Nios II 嵌入式晶片。 
電源：使用 300Wh、24V 鎳氫或鋰電池，有電源管理，自動充電與保護，連續工作 2 小
時 
感測：手臂觸覺，嗅覺，視覺，聽覺，超音波感測，里程計，紅外線雷射定位與掃描器， 
   DGPS，KGPS。 
導航：具室內外的定位功能，有即時路徑規畫的自主導航，無即時路徑規畫的自主導航， 
      沿牆運動與遠端遙控。 
 3
 
 識與語音合成系統，陀螺儀與加速度感測器，以及各關節的電位計。現在的 Asimo 走路更像
人，也可以和人跳舞、爬樓梯，穿著太空衣、臉上露出笑容，會說一些日本話，以後只需換
晶片，還可說任何國家的語言。雖然因 Asimo 的造價太高還無法量產，但 Honda 希望，看來
像個 12 歲小孩子的 Asimo，再經過 5～10 年的改善後，能夠做撿報紙、倒垃圾之類的事，做
家庭的好幫手。 
除 Asimo 外，其他顯著特出的日本人型機器人也不少，早期有早稻田大學在 1980 年
代所發展的雙足行走者 WL-12、彈鋼琴的 WABOT-2 與具視覺能力，能前進後退的 WEBIAN， 
近期有 DB, Pino,Hoap，Qrio 與 HRP-2 [4]。圖 1.2 說明 Asimo，Hoap，Qrio，HRP-2 與 WABIAN-2
等人型機器人的外貌。DB(Dynamic Brain)是日本 ERATO 計畫的早期大型人型機器人成果，
高 185 公分，重 80 公斤，油壓致動，用於研究類神經肌肉行為。Pino 是日本 ERATO 計畫的
2000 年中型小型機器人產品，高 70 公分，重 4.5 公斤，馬達致動，有視覺能力，可兩足行走
但不佳，適用於教學研究的共用平台。Hoap 是富士公司的系列小型人型機器人產品，高 48
公分，重 6 公斤，馬達致動，使用 RT-linux 作業系統，可與個人電腦透過 USB 介面溝通，
具歌唱與跳舞的功能。Qrio 是 SONY 在 2003 年發表的人型娛樂機器人，伺服馬達致動，高
60 公分，重 5 公斤，具有在三維空間之圖像識別、聲音定位、辨識與合成的功能，不僅能踢
球、投球、起立、座於地板與站起，彎腰、90 度轉彎，指揮交響樂，而且能尋音定向與人打
招呼[5-11]。 
        
   (a)               (b)      (c)     (d)          (e) 
圖 1.2 雙足型機器人，(a) Honda – ASHIMO，(b)Kawada – HRP-2P，(c)Fujitsu – HOAP-1，(d) 
Sony – Qrio，(e) 早稻田大學之 WABIAN-2。 
 5
 
 59 公斤重，不過星際王子身手靈活，還可以跟隨音樂跳舞，與旁人握手和說出一口流利的英
語。Johnnie 兩足機器人被用以研究如何穩定行走。 
 
   
   圖 1.3  Hubo 實驗室的中型人型機器人 
 
韓國是另一積極發展中型人型機器人的國家。圖 1.3 為韓國 KAIST Hubo 實驗室的中型
人型機器人(KHR-3)。 Hubo KHR-3 是基於倒單擺的平衡控制觀念，來讓 Hubo 在站立時可以
維持平衡不致摔倒。至於行走的部份則需配合預先計算的 ZMP（Zero Moment Position）來提
供人型機器人在運動中的動態平衡，藉這樣多層次控制的配合，Hubo KHR-3 可以做前進、
後退、左右轉等動作。近年來非常熱門的阻抗控制（impedance control）則是 Hubo 與人類介
面的控制基礎，例如當我們與機器人握手的時候，提供機器人與人介面的控制就以此為基礎。
機器人的背後背著一個大箱子，這是機器人的控制電腦和供應機器人運動軸能量的電池。 
    以上美、日、德、英、韓等國所發展的人型機器人大都用於娛樂與研究發展，少有商業
用途。近幾年來，商業用途的人型機器人種類如雨後春筍般的增加。比較著名的商品有 KHR-1
與 e-nuvo. KHR-1 是相當暢銷的商用 DIY 式的人型機器人，使用容易操作的伺服機作致動器，
具有仿人動作能力，如跑步、雀躍、伏地挺身、側翻、前滾翻、後滾翻、倒立、上下樓梯等
動作行為，但無內裝感測模組器。KHR 系列人型機器人已被國內成功大學、中興大學與淡江
大學改造，加入 SOPC 控制晶片、PDA 系統與視覺系統，發展成 Kidsize 的人型足球機器人。 
e-nuvo 是使用伺服馬達模組的商用兩足機器人，每隻腳使用六個含減速機的 DC 馬達且擁有
6 DOF，有電位計、陀螺儀、加速度感測與足部壓力感測等模組，並附有一本教科書。 
 
 7
 
  
圖 1.5. 具有繪畫的功能的雙臂機器人. 
 
1.2.3 國外雙手臂與臉部表情系統之研究概況:架構、感測與致動 
    至於雙手臂的研究，在日本著名大學(如東京大學，早稻田大學，東北大學)都投入相當
的人力與物力。目前已知的雙手臂可分成兩類:剛性雙手臂與撓性雙手臂。大部份的人型機器
人採用剛性雙手臂。 圖 1.5 為東京大學 Ikeuchi 教授實驗室的具有繪畫的功能的雙臂機器人，
此機器人之週遭配備有多部攝影機，同時其頭部有九部 CCD 攝影機，能經由影像處理的技
術，勾勒出空間中一物體的外型，再經由控制機器人手中所拿的畫筆，畫出此物體的外型。
圖 1.6 是日本早稻田大學 Sugano Lab 的發展出的與人共生機器人(Human Symbiotic Robot) 
WENDY (Waseda ENgineering Designed sYmbiont)。WENDY (有點像電影中的霹靂五號)主要
發展目標是開發能在人類真實生活空間內與人類安全共處的機器人。 她高度約 150cm、重量
為 170 公斤，具有雙眼視覺，和 52 個自由度的關節，可以跟人類進行各種形式的物理上或情
緒上的互動。 
        
圖 1.6 WENDY                     圖 1.7 MR Helper          圖 1.8 臉部表情研究機器
人 WE-4RII 
 9
 
 大學）、三節機器人與兩足機器人 (中央大學)，全方位輪式行動單手臂機器人（中興大學），
雙手臂照護機器人(中興大學)，足球人型機器人(成功大學與淡江大學)，居家照護機器人系統
（交通大學），手術後照護機器人(台灣大學)等系統之主要核心與系統整合技術之研發與軟硬
體裝備建置。。由以上的成果可知國內的人型機器人研究正處於萌芽發展期，其功能未達日
本的水準，且大部分已研發的人型機器人都採用反應速度較慢的伺服機，尚未採用較快速的
伺服馬達。在感測器方面，除 CCD 攝影機與聽覺的使用外，其他的觸覺與嗅覺感測器待進一
步研究。 
   國內的雙臂與臉部表情的研究，尚在起步的階段，遠落後於日本。成大電機李教授開始
著手雙臂的研製，中興大學蔡教授一開始如何設計照護與導覽機器人的臉部表情系統。另外，
國內的兩輪自平衡運動機構的研究首推暨南大學王文俊教授與成大機械系蔡明棋教授，中興
大學蔡教授亦研發一款可載人的兩輪自平衡運動機構。 
 
1.3  研究動機與目的 
    綜合以上國內外的研究現況而言，本報告所提議之與人共生機器人系統之機構設計
與驅動控制，感測，自主導航，智慧型視覺與聽覺，人工智慧，資訊與嵌入式系統晶片等次
系統技術與系統整合，確實符合國內外目前的研究需求與方向。就技術發展而言，要達到實
用多功能與人共生機器人系統，的確仍有許多的發展與創意空間，更待進一步的研究探討。 
 
1.3.1 短、中、長期的研究規劃與策略 
設計具有跨越不平坦地形與敏捷運動功能的智慧型與人共生服務機器人，並使之成為安
全及可依賴的人類夥伴的遠景，需要許多創新的理念與技術以及長期的研究人力與經費挹
入，方能落實。為有效地達成此一遠景目標，本報告提出如1.9圖的短、中、長期的研究規劃
與策略。在短期(3年)方面，本報告著重於發展具兩輪自平衡人型機器人系統之運動平台，導
航，人機互動，任務執行與計算模組等關鍵零主件與次系統技術，以及應用系統整合技術，
其中包括可跨越不平坦地形與敏捷運動功能之兩輪自平衡機構，反應更快的感測器(嗅覺，觸
 11
 
  
在中期(4-5)研究方面，本報告將 (1) 發展高等順從式裝置；(2)更新機器人之關鍵零主件
與次系統技術，以及系統整合技術； (3)發展任務導向的高階控制架構；(4) 發展智慧化的動
作規劃與與控制軟體；(5) 進行在商用服務、休閒娛樂、居家服務，老年照護以及其他等領
域之應用研究；(6) 與有興趣之廠商進行產業合作計畫，將技術轉移至工業界，將研究成果
產品化。本報告的長期(6-8 年)研究遠景是建造以無所不在之服務型式為宗旨的服務機器人，
讓其能成為人類的安全及可依賴夥伴。 
 
 
與人共生服務機器人系統之設計與研製 
智慧型視覺，聽覺，雙臂與視覺協調控制 
智慧型人機互動系統 
子計畫二 子計畫三
子計畫五
子計畫六
子計畫四 
子計畫一
 
圖 1.10 各子計畫間與系統整合的關係圖 
 
1.3.2 整體分工合作架構 
為有效地達成此一願景目標，本整合型計畫共有有六個子計畫，總計畫須協調統合各子
 13
 
 計畫四著重以模糊類神經與計算知能技術，研究機器人的智慧型視覺與聽覺技術，使其具有
物件，姿態，手勢，對象與語音內容之辨識與控制應用。子計畫五以應用已開發的雙臂，結
合視覺伺服技術，探討機器人之合作協調控制，順服控制與合作學習，使機器人完成合作任
務。子計畫六應用智慧代理人技術與服務導向架構，完成人機互動系統設計，使機器人有意 
 
半 人 型 與 人 共 生 機 器 人 系 統 之 設 計 與 研 製
智 慧 型 視 覺 ， 聽 覺 ， 雙 臂 與 視 覺 協 調 控 制  
智 慧 型 人 機 互 動 系 統  
子 計 畫 二 子 計 畫 三
子 計 畫 五
子 計 畫 六
子 計 畫 四  
子 計 畫 一  設
計
更
新
 
圖 1.11 各子計畫間之技術關聯與系統整合 
 
圖辨識與中文對話的能力。由以上描述，可以了解到本計畫中各個子計畫皆有其負責開發之
核心技術，同時各子計畫間具有十分密切之整合性。 
本整合計畫在規劃階段除參考國內外目前發展趨勢外，各子計畫也分別以圖 1.11 之各項
核心功能為主要研究興趣與範圍，因此具有縱向整合之功能，同時參予此項計畫之定期成果
研討會，對橫向的技術支援與交流亦容易達成。在計畫進行期間除定期集會外亦可參與國內
外學術研討會，人才培訓與各類競賽，進而推廣研究成果與促成學術交流。另外，本計畫所
創新改良與人共生機器人系統的專利、設計製作技術與方法學，亦可提昇國內智慧型人型服
 15
 
  
 
17
第一年:
居家服
務夥伴 
子計畫二:嗅覺感測器與運動平台與頭部系統研製 
子計畫四: 室內智慧視覺與聽覺 
子計畫五:雙臂順服控制與學習合作
子計畫六: 智慧型人機互動界面 
子計畫三:室內定位導航技術 
子計畫一: 運動平台與雙手臂機構設計 
子計畫二:觸覺感測與雙手臂運動控制器研製 
子計畫三:室內外導航 
子計畫一:進階運動平台與雙手臂機構設計與改善 
子計畫四: 室內外智慧視覺與聽覺 
子計畫五: 雙臂順服控制與學習合
子計畫六: 智慧型人機互動界面 
第二年:
餐點服務
夥伴 
子計畫一: 運動平台與雙手臂機構 
子計畫三:室內外導航 
子計畫二:整合運動控制研製 
子計畫四:智慧視覺與聽覺 
子計畫五: 雙臂順服控制與學習合
子計畫六: 智慧型人機互動界面 
第三年:
老年照
護夥伴 
 時所開發的實體可作為商用服務、休閒娛樂、居家服務以及老年照護機器人之共通實驗平台，
可縮短其研發時間，加快其產品上市。  
 
1.5  章節組織 
本報告的章節組織如下。 第二章致力於說明各子計畫的研究方法與其三年度之研究項
目。第三、四、五章說明第一、二、三年整合計畫之成果。第六章為本報告的總結與未來研
究工作。 
 19
 
 所示為移動載具平台與順應式裝置的設計分析流程，在設計分析流程中，首先根據設計需求
產生移動載具平台與順應式裝置的概念設計，再針對移動載具平台與順應式裝置結構分析其 
 
圖 2.1 機構設計分析流程圖 
 
靜態與動態特性，並根據理論分析與設計需求訂定尺寸最佳化設計的限制條件與目標函數，
最後將所得結果帶入理論分析中與 ANSYS 有限元素分析的結果二者比較，藉此以驗證整個
理論分析流程的正確性。最後將 ANSYS 分析所得的結果與理論分析所得的結果逕行比較，
並評估移動載具平台與順應式裝置設計的可靠性與安全性，若不符合最初的功能需求與限制
條件，就再一次針對移動載具平台或順應式裝置架構的部分重新設計；若成功符合需求則進
入實體化階段，完成後並以實際實驗量測及證明之。 
 
2.2.3 子計畫二：嵌入式智慧型感測器與運動控制器之設計與研製 
    子計畫二的研究方法詳述如下：(1)在兩輪自平衡與四輪複合機構的伺服馬達驅動模組研
製的研究方法上，子計畫二擬採用兩輪自平衡機器人的常用 100W 直流伺服馬達, 其驅動器
則使用自製的H-型PWM驅動 IC與CPLD驅動器，其控制器則使用Altera 的Strait II SOPC 晶
片。使用 Stratix II SOPC 晶片的優點是可以集成所有的馬達控制法則與 PWM 訊號產生器於
 21
 
 完成點餐服務的功能，顧客可利用手動觸控螢幕或語音聲控兩種方式，進行點餐。利用智慧
型感測融合技術，有效地去除量測訊號之雜訊，發展行動服務機器人室內戶外的先進定位與
導航技術。探討其他追蹤控制演算法在行動服務機器人路徑規劃與追蹤控制上的可行性。另
外，本計畫擬利用定位技術及自主驅動控制法則驅動機器人至自動充電裝置，達成自動充電
的目的。 
 
2.2.5 子計畫四：智慧型視覺與聽覺功能研究 
    子計畫四是以計算智慧技術為基礎，完成智慧型視覺與聽覺的功能，主要方法有三：(1) 
其一為物體/人體偵測方法。本研究將以色彩資訊配合小波（wavelet）轉換及多重解析度
（multi-resolution）方法來求取物體的特徵參數[77-78]。由於物體從各個角度所觀看的影像均
不相同，對此將發展一個基於支持向量機（support vector machine）的模糊系統來當偵測器，
以學習不同角度的物體影像。所偵測結果，再配合 stereo camera 所獲得的 disparity 影像及幾
何運算，完成物體 3D 位置計算。在人體的偵測方面，將利用 stereo camera 所獲得的 disparity
影像[81]，將適當高度內的資料投影至 X 軸與 disparity 方向所形成的平面上，接著使用聚類
（clustering）演算法和不同範圍的濾波器來取出人體的可能的區域，最後再使用數個主要姿
態的人形樣版（template）來比對並確認人體的位置。 (2) 其二為人臉的偵測與手勢辨識方法
[82]。人臉的偵測可以用來確認人體偵測的正確性，並有利於人臉辨識與手勢擷取的進行。
當機器人移動至適當位置時，我們可以偵測到較大範圍的穩定膚色區域，再配合利用 disparity
影像以及聚類演算法來求出可能的人臉區域，然後使用一個以不同角度的臉部影像所訓練的
模糊類神經網路來定位出臉部位置。在人臉的區域內，尋找特徵點的 3D 資訊，例如眼睛、
眼角、嘴角、鼻孔等位置，就可以估計出臉的準確位置與方向。在手勢辨識方面，利用膚色
切割與影像差異配合 Kalman 濾波器完成動態手勢擷取。辨識器方面，我們將發展一基於支
持向量機的遞迴模糊系統，以完成動態訊號辨識。(3)  其三為人臉辨識與語音控制方法。在
人臉辨識方面，將採用兩種方法，第一種是臉部特徵點的位置資訊比對，藉由人臉偵測所得
到的特徵點的位置資訊，使用 3D 彈性樣版演算法（elastic template matching）來比對資料庫
中各類別的資料；第二種方法則是利用人臉偵測所得到的臉部方向，從資料庫中選取最接近
 23
 
 除了傳統上以壓力感知的方式進行順從控制的設計之外，並以類神經肌肉系統
(neuron-muscular system)來加強在力量的順服性與位置的準確性，同時，高速的視覺伺服亦將
用於實現更為自然的人機互動方式。例如在握手的動作上，一般的順從控制提供了被動但安
全的行為模式，但運用高速影像分析的資訊，我們更得以開發機器手臂主動式的握手方式，
而相同的技術亦可運用於機器人在其他方面主動的情感表達途徑。另外，我們亦將探討順從
控制於雙手臂互動時的特性以及所須的特定功能。 
    在探討高速的視覺伺服方面，子計畫五所強調的高速視覺伺服，主要的方法包括利用兩
架高速攝影機，進行高速的機器手臂三維定位、以及高速的移動物體追蹤等兩項功能。就第
一個部分，首先將以 SIMD (Single Instruction, Multiple Data) 的平行處理架構來實現低階的影
像分析，例如影像中特徵點的搜尋等工作。其次再以 Kalman filter 或是 KLT tracker 的方式，
追蹤並預估影像特徵點的可能位置，以達到計算區域化與減量的目的。最後，將搭配預先建
立的機器手臂三維電腦模型，以其移動上自由度的限制，減低立體視覺影像匹配時的搜尋範
圍。第二部分對於高速移動物體的追蹤，主要將運用於快速的雙手臂與環境或物體的互動
[86-87]，例如快速抓球的動作[88-89]。除了上述的高速影像處理方式之外，亦將探討在影像
擷取頻率有限的情況下(目前市售中價位攝影機之即時影像傳輸速率約為 100 fps)，移動物體
所產生的動態模糊現象所能提供的機器手臂運動資訊。 
Service 
Broker 
Service 
Requester 
Service 
Provider
bind 
find publish 
圖 2.2 服務導向架構 
Mediator 
Agent 
User 
Agent 
Service 
Agent 
bind 
find pu
圖 2.3 服務導向代理人架構 
blish 
 
 
2.2.7 子計畫六：智慧型人機互動系統設計 
  子計劃六之研究主軸有二方面，一方面為人機介面的問題[91]，另一方面為機器人間的
介面問題。人機介面研究的目的，主要為如何滿足使用者的需要[90]。機器人間的介面主題，
 25
 
 是一個重要的研究[92]。以上所描述的情境，將以多重代理人來處理，所研究的人工智慧技
術如下：(1) 環境知識瞭解及ontology建構；(2)使用者模型建構；(3)使用者意圖處理；(4)單
純句子的自然語言處理；(5)服務組合與服務滿足。 
 
2.3 總計畫與各子計畫之年度研究項目 
本整合計畫執行之全部時程為三年，總計畫及各個子計畫的分年工作項目詳述如下： 
2.3.1 總計劃: 智慧半人型與人共生服務機器人之設計與研製 
總計畫每年均有三項重點工作項目: 
第一項是協助各子計畫完成必要的硬體系統設計、重要元件選擇與安裝，輔助各子計畫
完成各項技術開發與整合，推動數位化研究教學資源中心與數位學習，安排定期成果研討會，
達成橫向的技術支援與交流。 
第二項著重於整合六項單項關鍵性技術的研發，進行系統整合與實驗測試，第一年完成
研製家庭服務夥伴，第二年點餐服務夥伴，第三年老年照護夥伴，並且進行必要的使用者評
估。每年積極參與機器人相關學術活動，辦理機器人設計技術研習與應用創意競賽。 
第三年項是，與台中自然科學博物館展示組合作，推動與人共生人型機器人研究成果展
示與示範，推動大眾科普教育；舉辦產學研討會，促進產學研界之互動與合作，並進行研究
成果商品化的研究。 
 
2.3.2 子計畫一：運動平台與雙手臂機構設計(未通過，由總計畫代為執行) 
在複合式運動載具平台方面，第一年的研究項目為 (1)複合式運動載具平台相關資料之
收集與整理；(2)利用ADAMS軟體對複合式運動載具平台進行運動模擬; (3)進行複合式運動載
具平台之結構分析；(4)針對雙輪自平衡運動載具平台進行機構設計與試製; (5)針對跨越障礙
機構進行設計與試製;(6)撰寫研究報告。第二年的研究項目為 (1)繼續複合式運動載具平台相
關資料之收集與整理；(2)複合式運動載具平台之改良與製作；(3)將分別與子計畫二、三進行
資訊整合動作、共同改良、進行感測器安裝與實際控制操作；(4)實驗與討論;(5)撰寫研究報告。
 27
 
 制與實驗測試，(4) 整體系統之行為控制與實驗測試，  
 
2.3.4 子計畫三： 先進定位導航技術 
    第一年研究計畫利用雷射掃瞄器與雷射定位儀執行機器人室內即時定位幾項比較重要的
工作項目說明如下：(1)建立一以多感測器(結合光學編碼器、環狀超音波感測器、SICK 雷射
掃描測距器與 CCD 攝影機影像處理技術)融合為基礎，同時完成室內定位與環境認知方式，
以及以行為融合導航策略。(2)利用訊息理論、可拓類神經網路系統辨識能力，結合各感測元
件所收集資訊，進行系統模式驗證與物理參數估測，以因應各種不同應用環境。(3)融合雷射
定位儀、雷射掃描儀、超音波感測器、CCD 影像與所發展非線性控制策略技術，實現以上所
說明之功能編寫程式與作各項功能實驗，並完成系統整合與導航控制功能測試。(4)文件撰寫
與成果報告及發表論文。第一年的導航研究項目包括：(1)建立一共同的實務測試平台，即點
餐服務機器人機構的設計與研製。(2)推導並模擬驗證機器人的動態方程式及運動學方程式。
(3)電子羅盤、光學編碼器、超音波感測器、雷射掃描器及雷射定位儀等感測器之安裝、測試
及其介面電路之設計。(4)完成避障與防撞、環境認知之功能，建立地圖、執行室內路徑規劃。 
第二年研究計畫利用 KGPS 定位技術執行機器人戶外即時定位幾項比較重要的工作項目
說明如下：(1)發展即時動態 GPS 快速演算法之過程中，對於電離層和對流層模基的建立及衛
星曆的誤差估算，衛星時鐘差之修正或去除，應儘可能接近實際的情況，否則會造成演算速
度雖快，但其精確度不佳的狀況，吾人要求的定位精度為公分級，故必須考量。對於演算法
則之推導與實現，先以 MATLAB 程式語言模擬演算無誤後，再利用 C 程式語言設計，可節
省轉譯時間，達到即時動態的效果。(2) 基站與移動站之 RTK GPS 接收器需選擇有載波相位
輸出信號性能較佳，更新資料速度較快的來建立參考基站的 KGPS 接收器定位精度高就可有
效地將虛擬距離/載波相位修正量，正確地傳送到移動站使用者做即時修正之參考。(3) 建構
一操作機構為平台的智慧型機器人，內有編碼器、環狀超音波感測器、SICK 雷射掃描測距器，
CCD 攝影機，PC 控制與影像處理器，以及其它電源管理、無線網路與通信設備。(4)文件撰
寫與成果報告及發表論文。第二年的導航研究的項目包括：(i)改良點餐服務機器人的機構設
計。(ii)KGPS 演算法推導及 KGPS 接收器、無線電收發機之安裝與測試。(iii)電子羅盤、光學
 29
 
 後續研究。 
第二年預計完成下列工作項目：(1)提出新的 SVM 之核心函式（kernel），即 TS-kernel。
(2)提出以 SVM 訓練之 TS 型模糊辨識器 （SVM-TSFC）。(3)提出以 SVM 訓練之遞迴型 TS
型模糊辨識器 （SVM-RTSFC）。(4)以新的膚色分割法求取手掌軌跡。(5)以遞迴型 TS 型模糊
辨識器為基礎的動態手勢辨識法。(6)利用膚色分析與人體偵測的結果，找尋適當的 ROI。(7)
在 ROI 範圍內利用 NEFCARI 分類器進行人臉偵測。(8)在偵測結果中的 T 形區域擷取人臉的
2D 和 3D 資訊，當作人臉辨識的特徵。(9)利用人臉偵測的結果來進一步驗證人體偵測的結果。 
第三年預計完成下列工作項目：(1) 配合臉部辨識，辨識使用者身份後，執行特定與者
語音辨識。(2)以第二年所提出之 SVR-RTSFC 執行特定語者約 60 個國語單音的辨識。(3)提出
利用動態時間校正（DTW）執行特定語者約 30 個國語詞組命令組的辨識。(4)三維人臉特徵
點之萃取與定位。(5)利用三維影像資訊，估測人臉旋轉角度。(6)二維人臉影像之校正與 T 字
部位特徵抽取。(7)多模型人臉辨識系統之相似度融合與輸出。 
 
2.3.6 子計畫五：具視覺伺服之雙手臂順服控制與合作學習 
  第一年預計完成 PRM 方法適用於動態的運動規劃問題功能，也就是利用高速視覺所回傳的
靜、動態障礙物快速架構出 PRM 以及双手臂自由軌跡。在視覺系統方面則預計完成攝影系統
的建構、校正、與機器手臂上特徵點的追蹤與視覺定位。我們亦將完成双手臂三維電腦骨架
模型的建立，並提供運動軌跡的規劃。 
第二年預計同時完成各別手臂輔助器的跟隨功能與攙扶功能。也就是不僅隨著對手(另一
手臂)以不同的姿態(pose)前進，同時提供一固定的支撐力道，以平衡或讓握持物保持在一特
定姿態。例如當一手臂必須搬動桌子等大型物品時，另一手臂則在無運動控制狀態下僅用輔
助器即可協助該手臂搬移大型物品。由於在一輔助器上，同時要做到跟隨與攙扶兩個目標，
所以我們便以兩個代理人，以合作的方式來完成這個目標。然而，此時會面臨到的問題是由
外界(高速視覺系統或附加感測器)傳回來的獎勵值只有一個，要如何判定不穩態的原因是由
於那一個部份所引起，便是一個難題。我們提出解決的辦法是將代理人所有的狀態以及所採
取的行為產生的獎勵值分別記錄下來，以便觀察此不穩態的獎勵值是由那個代理人所引發
 31
 
 第三章 第一年研究成果 
 
3.1  前言 
   本章致力於說明總計畫與五個子計畫第一年的主要成果。由於原先子計畫一未通過，子計
畫一的部分內容由總計畫與子計畫二代為執行。 
3.2  總計畫「智慧半人型與人共生服務機器人之設計與研製」 
     圖3.1 為總計畫與子計畫二所設計的自平衡之兩輪服務機器人的架構圖，機器人由一個
自平衡的兩輪平台和一個類人之機器頭顱所組成。自平衡之兩輪平台是由2個24伏特無刷電動
馬達所驅動，其能量來源為2個12伏特直流鉛酸電池，控制器使用數位訊號處理器(DSP) 
TMS320F28335來實現相關之控制法則， 感測器有陀螺儀，傾斜儀，雷射掃描器和兩個編碼
器。圖3.1 (c)為總計畫所研製的居家照護機器人之外型設計。 為圖3.2為機器人頭部支架構
圖，頭部是由七個伺服馬達與2個網路攝影機以及鋁製的骨架所組成，因此擁有7 自由度
(DOFs). 機器人頭模件的主要目的是進行人機互動，以及取得察覺確定有人存在的資訊時，
然後進行導航路徑之規畫與執行。圖3.2 (c)為總計畫所研製的居家照護機器人之人機互動系統
之外型設計。 
 
  
(1)                 (2)     (3) 
圖3.1 與人共生機器人之系統架構圖: (1) 前視圖；(2) 後視圖；(3) 居家照護機器人。 
 
 33
 
 (PCA)和支持向量機(SVM)等方法組成。而在運動導航部分，本機器人的移動必須是依據該運
動平台的非線性動態模型，設計滑動模式速度，偏轉速度等兩控制器以及運動軌跡產生器，
最後再考慮服務對象的人類的心理層面需要，規劃避免碰撞物體以及符合人們心理與安全需
要的運動軌跡，進而完成導航控制。 
 
3.3.1 研究方法 
     本小節介紹子計畫二之自平衡兩輪與人共生機器人的二個主要控制模組:運動控制器與
人機互動控制器，首先為運動導航控制器，此控制器是由滑動模式之速度控制器、滑動模式
之偏轉速率控制器與運動軌跡產生器所組成，滑動模式速度控制器的控制目標為速度追隨與
兩輪平台的平衡，滑動模式偏轉速率控制器則為控制兩輪平台的轉向，最後運動軌跡生成器
則依據服務對象的行動軌跡以及障礙物規畫出適當的機器人運動軌跡之相對應的速度令以及
偏轉速率令給前述之兩控制器所使用。另一為互動式人臉與情感識別模組，人臉識別與情感
識別的演算法是採用Haar小波轉換、主成分分析(PCA)和支持向量機(SVM)等方法組成，人臉
與情感識別模組能夠辨認出使用者的表情，例如自然，愉快，憤怒，悲慘和快樂， 並且依據
使用者的情緒做出相對應的機器臉部表情讓使用者覺得人性化 
 
3.3.2 結果與討論 
圖3.3至圖3.6分別為人臉識別、情感識別、人跡追隨與躲避障礙物之實驗結果，圖3.3顯示
出12位使用者的身分均能成功的透過互動式人臉與情感識別模組辨別出，同時圖3.4也表現出
使用者的喜、怒、哀、樂的情緒也能成功的被辨別出來。圖3.5為與人共生機器人之人跡追隨
的實驗結果，圖中顯示與人共生機器人能夠追隨使用者做移動，最後一個實驗為自主服務機
器人之躲避障礙物的測驗，圖3.6顯示與人共生機器人成功的躲避走道上的障礙物。實驗結果
驗證機器人的運動控制，避開障礙物、辨別人臉與臉部表情以及考慮有人存在的導航。 
 35
 
  
(1)          (2)         (3) 
 
(4)          (5)          (6) 
圖 3.5 與人共生機器人之人跡追隨之實驗結果。 
 
 
(1)                (2)                 (3)  
 
(4)                   (5)               (6) 
圖3.6 與人共生機器人之避障之實驗結果。 
 
3.4  子計畫三「先進定位導航技術」 
   子計畫三之目的是提出一個正確終點面向的路徑規劃法，並設計兩個模糊邏輯控制器，第
一個為用來規劃出正確終點面向；第二個用來閃避障物，以切換輸出的方式來規劃出最佳路
 37
 
  
3.4.3 結果與討論 
為了驗證所設計的演算法之有效性，在實驗中，測試環境大小為5m*5m，黑色部份為障礙
物，紅色線條為機器人實際所移動的路徑，藍色點為終點，座標單位為0.5公尺/格，超音波感
測器的偵測範圍調整至250cm，機器人的左右輪轉速設定在0~600rpm，30:1的減速箱及直徑為
20cm的主動輪，經由計算後可得知機器人實際所行走的速度為0~20.9 cm/s。實驗裡將障礙物
加入做實際的測試，且將終點面向角度設定為90°及180°，以單一障礙物做測試，實驗結果如
圖3.8及圖3.9所示，經由實驗結果可知除了能閃避障礙物，其定位誤差於0~10cm及面向角度
誤差為0°~10°之間。經模擬及實際驗證後，可得知方法可正確面向所指定的角度，且能閃避
障礙物防止碰撞的發生，透過實驗的模擬，將其參數最佳化後套用至實際測試上可加快程式
開發，且定位誤差及角度誤差小。 
 
(1)                    (2) 
圖3.8 閃避障礙物終點正確面向90°實際測試. (1)  機器人行走軌跡 (2)終點距離、馬達轉速、
目標角度、機器人角度及障礙物距離值。 
 39
 
 繁雜，應用時很許多不便之處；相對的，Zhang 所提出的方法不僅容易求解，且可以求出多
組攝影機不同姿態的外部參數以及未知的視覺平台的機械參數，當然還包括透鏡本身的扭曲
參數。另外，Zhang 的方法所用的校正板只需以一般的印表機來列印即可，可以有效的降低
實驗成本且取得十分容易。像差影像可由經過校正的雙眼攝影機，透過其介面軟體直接取得。
為了使資料的分佈較為平均，在直方圖統計的部份加入了模糊歸屬函數的概念。由於人類物
件在影像中會有不同的大小，在沒有任何大小資訊的情況下，是很難從其中將物件偵測出來
的。空間及大小區域濾波方法被用來偵測特徵、邊緣以及角落。加入人體寬度作為判斷的依
據，我們以 50%的平均人體寬度做為誤差值，亦即當其寬度大於 1.5 倍的平均人體寬度時，
判斷其中不只存在一個人體物件，此時便用分水嶺法對直方圖做分群，直到符合條件。如此
便能順利將不同物件區隔開來。 
 
3.5.3 結果與討論 
第一組實驗為兩人並排行走，環境為本校電機大樓之大廳，兩人並排向攝影機靠近，一
開始距離攝影機約 3 公尺，行走至約離 1.5 公尺，結果如圖 3.10 所示。第二組實驗為一對一
行走，環境為本校電機大樓之大廳，一人類物件站立不動，另一人類物件在其周圍行走，一
開始距離攝影機約 2 公尺。其中某些影像由於其一人類物件大部份皆位於另一人類物件的後
方，導致水平像差分佈上的遮蔽，因此無法準確判斷是否為人類物件。在此我們的設定誤差
為 50%，即未達 0.5 倍平均人體寬度皆判定不為單一人類物件。結果如圖 3.11 所示。第三組
實驗為三人於不同距離，環境為本校電機大樓之大廳，三個人類物件各在不同距離開始向攝
影機靠近，由於人類物件較靠近的關係，導致其像差在直方圖的分佈上出現重疊的情形，除
了原本設定好之分水嶺法，再加入人體於不同深度的平均寬度資訊條件，以便將各個人類物
件做一區分。一開始距離攝影機約 3.5 公尺，行走至約離 1.5 公尺。結果如圖 3.12 所示。計
畫中，以校正完之雙攝影機擷取立體序列影像並獲得立體像差資訊，使用模糊歸屬函數來建
構 X-D 二維平面直方圖，再利用大小適應性濾波器來對直方圖做空間與大小區域的加強。如
同實驗結果所示，視訊影像中人類物件存在的部份確實有人型的分割區域產生。經過邊界的
搜尋動作，將其結果還原至原始影像，其人體部份皆被圈選出來，如此已達成我們所需要的
 41
 
  
3.6 子計畫五「具視覺伺服之雙手臂順服控制與合作學習」 
子計畫五為在共同的工作區內工作的兩台機器人可以分別地規劃運動軌跡，為了避免彼
此之間的衝突。一個基於快速和高準確衝突偵測的即時速度協調策略在這份報告中提出，決
定 slave(低優先權)機器人下一步移動的無碰撞軌跡規劃對於兩台機器人。圖型式模擬
PUMA560 機器人手臂在共同工作區有單一目標進行避免碰撞的能力證明。結果顯示我們的方
法有較少速度改變的數量對於潛在衝突有回應。 
 
3.6.1 研究方法 
先前所提出的演算法。為了於快速的距離估測和衝突偵測，多面體被使用於幾何物件模型
裡。三者的關係的描述在圖 3.13。採用非全域規劃的方法， 建造完整的構造空間並設計共同
區域裡一條軌跡或者製造空間無衝突的軌道，研究方法為直接在空間區域實施碰撞偵測，和
以前使用不同的方法，在每一個補償時間只考慮距離的計算，並且反映出在動態環境內的實
際情況給機器人應用。 
real distance
ordinary estimate
x*
y*
q1
P1
q2
P2
3
11
3
1 oi A εε ⊂⊂
3
22
3
2 oi A εε ⊂⊂
 
圖3.13 基於橢圓體之距離估計 
 
3.6.2 結果與討論 
為了證明距離的估計和速度改變下的無碰撞軌跡規劃的性能，使用兩只 RUMA560 機器人
手臂建立。不過，如果兩只機器人手臂向前走，兩只手臂的碰撞將發生如圖 3.14(a)所顯示。
接著使用速度改變策略來協調機械手臂的速度以避免碰撞。使用的速度改變策略並使用橢圓
體來估計距離的控制策略下的手臂移動則不會發生碰撞在圖 3.14(b)且此結果與傳統方法的結
 43
 
  
3.7.1 研究方法 
人與服務機器人的互動所需的人機介面，包含容易使用的輸入機制、友善的輸出介面、
善於瞭解使用者的判斷能力等功能。藉由主動式的互動模式及使用動機的瞭解，服務機器人
可以更貼切的滿足使用者的需求，並且讓使用者快速適應服務機器人。因此，讓機器人融入
使用者的生活，並協助其生活上的需求，是一項有價值且富有挑戰性的研究主題。過去相似
的研究，如居家照護系統或智慧型居家環境等研究中，在這方面已有初步性的研究並在文獻
中發表。 
以智慧型居家照護環境為例，其包括許多不同任務、不同平台的系統，如看護機器人、
智慧型輔助系統、居家無線通訊系統、保全系統、智慧型家電、智慧型人機介面等。其研究
在於如何設計出高擴充性與高容錯性的架構，而且可控制各個不同的系統。傳統的控制架構
如循序式或主從式的架構不適用於此需求，而需要一個彈性高又能包含多種平台的架構，因
此多重代理人架構可視為扮演此類系統角色的選擇。此外，如果居家中有多於一位使用者或
不同環境的系統擴充需要，這類架構應容許適應不同的需求。這類智慧型環境的研究中，我
們可看到幾項研究的重點，如處理多使用者的需求、多樣性的任務需求、多台服務機器人管
理等。同時，如何提供友善的使用者介面也是挑戰之一。 
 
3.7.2 結果與討論 
在第一年，子計畫六以環境知識的定義為出發點，利用居家中的家電為服務提供者並配合
排程技術，定義出一個可以使用服務導向架構的環境，並開發出一個雛形系統。目前正在將
服務機器人可提供的功能規劃為高階的服務，將排程的結果視為機器人的細節指令，在第一
年的結束前可將此結果結合在此系統。至於意圖的擷取，目前以高階指令為基礎，使系統找
出所對應的服務，並結合學習，讓不同的使用者可擁有不同的服務選擇，這功能應可在第二
年上半年加入此雛形系統。. 
 
 
 45
 
 第四章 第二年研究成果 
 
4.1  前言 
   本章致力於說明總計畫與五個子計畫第二年的主要成果。由於原先子計畫一未通過，子計
畫一的部分內容由總計畫與子計畫二代為執行。另外總計畫的重點是需整合以上核心技術，
本年度的重點工作項目是研製餐飲服務夥伴，主要的功能設定為接待，引導，說明與餐點服
務。開發該型機器人之關鍵項目與第一年相似。  
4.2  總計畫「智慧半人型與人共生服務機器人之設計與研製」 
圖 4.1 為總計畫與子計畫二所設計的雙手臂機器人搭載立體視覺模組、準系統電腦、
StraixII 整合發展實驗板和二隻七個自由度的機械手臂。圖 4.2 為整個雙手臂機器人的嵌入式
控制系統架構。立體視覺模組被用來找尋頭部系統與物件之間的矩離和物件的影像資料。準
系統電腦用來執行分析式逆向運動學和手臂移動路徑平滑化。StraxiII 整合發展實驗板用來執
行手臂七個馬達的 PIV 運動控制。 
 
圖 4.1 實際雙手臂機器人平台 
 47
 
 4.3.1 研究方法 
   首先推導手臂之順向運動學和分析式逆向運動學六大步驟，接著軌跡規劃產生器使手臂運
動軌跡平滑化與PIV法則控制馬達，最後基於任務型的運動規劃以及兩臂的概念式合作任務來
完成單手寫字、雙手合作抓取色球和泡咖啡任務。在實作方面利用SOPC技術和模組化理念來
完成實現控制器模組。 
 
4.3.2 結果與討論 
圖4.3至圖4.6分別為雙手繞圓運動、雙手寫字、雙手合作抓取色球與泡咖啡之實驗結果，
圖4.3顯示分析式逆向運動學和點對點控制的實驗結果，同時圖4.4也表現出軌跡規劃與單手臂
控制的實驗結果，圖4.5為智慧立體視覺模組對物件與機器人的矩離判斷、物件辨視與雙手合
作的實驗結果，圖4.6中顯示任務型的運動規劃和雙手臂合作的實驗結果。 
 
圖 4.3 雙圈運動 
 49
 
  
圖 4.6 泡咖啡任務 
 
4.4 子計畫三先進定位導航技術 
子計畫三之目標是所開發點餐服務機器人第二代為主要平台，除了針對既有的定位導航
技術進行回顧研究外，還結合了以雙影像為主的餐盤辨識系統(Stereo Vision System)與視覺定
位系統及五軸機器人手臂機構與功能設計，第三年能達成準確地端取餐點的任務。在導航避
障部份，利用場效直方圖演算法(Vector Filed Histogram, VFH)結合模糊控制(Fuzzy Controller)
演算法，使移動式機器人不但能夠順利到達預先設定的目標點，還可針對環境中，突如其來
的障礙物進行分析，執行障礙物閃避的工作。而餐盤辨識部分，則利用 WebCam 作為主要影
像辨識感測器來對餐盤進行辨識及定位的工作。於實驗結果中，導航共分為模擬測試以及實
際測試兩部分，餐盤辨識以實際測試為主，使用 Borland C++ Builder 6 來達成模擬與實作目
標。 
 51
 
 馬達，推算逆運動方程式的幾何分析及移動軌跡，藉由模擬的方式來判定誤差及方向，透過
基因演算法及模楜演算法來作為輔助系統，考慮手臂尺寸長度及移動的速度。 
 
4.4.3 結果與討論 
實驗結果，如圖4.9所示，此為無障礙物時的模擬結果，而圖4.10為有障礙物時的實驗結
果，圖中綠色的軌跡為載具行走軌跡，較密的部分為規避障礙物時載具修正航向的軌跡，整
體精確度約在±10cm以內。圖4.11為KGPS於下午四點至五點之間的連續試誤差量，約
0.6m~0.8m的精確度。圖4.12為多路徑導航實驗與預期路徑比較。圖4.13為餐盤辨視之實驗結
果。 
 
圖4.9 機器人軌跡(無障物) 
 
圖4.10 機器人軌跡(有障物) 
 53
 
 們採用梯度臉演算法，完成一不受光源變化影響的人臉辨識系統。實驗結果顯示，本系統可
以達到 100%之正確辨識率。 
 
4.5.1 系統架構 
    立體影像的形成是利用人類的視覺原理，人類的雙眼就像兩台攝影機，各自拍攝形成影
像，成像落於視網膜中。因此，使用 Bumblebee BB2 stereo vision camera 來模擬人類雙眼視覺，
藉由 Bumblebee BB2 stereo vision camera 拍攝得到所需的人臉影像以及相關資訊來達成人臉
辨識的目的。 
 
4.5.2 研究方法 
採用結合特徵臉(Eigenface)演算法與類神經網路的人臉偵測系統來找出各張輸入影像中
的人臉座標與大小。接著，利用 disparity 影像資訊與轉角偵測法(corner detection)找出人臉特
定之特徵點三維座標。並且，利用彩色空間中人體膚色的分佈情形，分割出屬於膚色的人臉
部分。最後，依照 disparity 的資訊，將分割出來的人臉部分作距離的正規化，使每張偵測出
來的人臉都與攝影機有相同的距離。在切割出人臉區域，並且完成距離正規化之後，可以利
用偵測出的人臉特徵點以及其三維座標，估測出影像中人臉在三度空間的旋轉角度(yaw, pitch 
and roll)。最後，利用簡單的特徵萃取方法，抽取出代表人臉影像的特徵。 
在比對模組方面，在系統資訊庫中，每位不同人員擁有五張人臉影像之特徵向量。此五
張人臉影像分別以不同對攝影機之偏離角(yaw)作取樣。一張測試影像經過前述前處理與特徵
萃取之後，將與資料庫中，每位人員的 yaw 角度最接近之人臉特徵進行比對。 
 
4.5.3 結果與討論 
本計劃中，使用 Bumblebee BB2 stereo vision camera 來擷取人臉立體影像。每位受測者分
別在不同時期進行兩次的拍攝取樣工作。在第一個時期，受測者分別將頭旋轉五個角度(yaw
角)，取得五張影像(如圖 4.14)。第二個時期，以連續拍攝的方法，請受測者緩慢將臉從左側
轉向右側，最後再轉回左側。因此，第二時期的取樣，每位受測者因轉速的不同，會取得不
 55
 
 以藉此達到硬即時的要求。。也因為 RT-Linux 的特性，使其開發程式的方式不僅僅是與一般
Linux 環境中開發程式的過程相同，更提供額外有關即時性功能的程式介面，給予程式開發者
使用來建構出具即時性的程式。因此，此開放架構選用 RT-Linux 作業系統來作為開放架構中
的作業系統。 
 
4.6.2 系統架構 
本機器手臂控制軟體的架構如圖 4.15 所示，圖中每個矩形方塊代表一個特定的功能，其
功能名稱被附加標示在該矩形中。例如，手臂行為操控負責產生未來被控制機器手臂的姿態，
並對於每個姿態附貼上時間標籤，以標示其先後次序。而圖 4.15 的有方向性的線條，則代表
資料的流向。附貼在線條上的文字則代表被傳送資料的內含意義。 
機 器 手 臂
關 節 驅 動 器 模 型
手 臂 行 為 操 控
手 臂 姿 態 轉 換 控 制
手 臂 尖 端 期 望 位 置
順 向 運 動 學 各 軸 位 置 控 制
計 數 器
數 位 類 比 轉 換 介 面
放 大
器
光 編 碼 器
直 流 馬 達
各 軸 期 望 位 置手 臂 尖 端 位 置
各
軸
控
制
量
各
軸
相
對
計
數 值
各
軸
控
制
量
參
考
類
比
值
驅 動 電 流
AB
向
脈
波
 
圖4.15  軟體架構圖 
 57
 
 4.6.3 結果與討論 
系統內的每一個階層間，均透過函式呼叫的方式溝通。而被置放於核心部份的軟體則是
需透過 RTLinux 作業系統的核心來達成資料交換的目的，以滿足即時處理的要求。除此之外，
此程式架構中亦包含有兩個核心的擴充模組：控制器演算法模組與控制迴圈與應用程式介面
模組。第一個模組負責控制演算法的實現，著重於單一控制迴圈的控制量求取；第二個模組
則在於建立控制迴路與提供應用程式介面以便能夠提供單一個應用程式對機器手臂下達命令
與多個應用程式對機器手臂的狀態監控。而控制演算法的部分，提供標準程式寫作介面，讓
使用者可以建構自己的控制演算法來控制機器手臂的運作。應用程式介面則提供了使用者發
展高階行為控制演算法的機制。 
 
4.7 子計畫六智慧型人機互動系統設計  
子計畫六的第二年主要導入情境感測系統的研究於整合型計畫中。本子計畫的主要研究
課題是要提升人機互動、結合多台服務機器人、並提供多樣且依個別任務來服務多位使用者。
使用規則式推理系統於情境感知系統有許多的優點，包括規則式推理系統符合人類思維，較
易設計、對於完整的資訊仍然推理出可能的答案、規則彼此之間可獨立撰寫，避免複雜的程
式設計、程式可讀性較高、以及程式的修改性高。本研究中規則式推理使用在服務的推論，
由於規則式推理的特性可以使情境感知系統處理複雜多變的人類喜好具有優勢，而本體論則
被使用於建構使用者行為推論的部份，這是因為本體論用來表達知識具有優勢。 
 
4.7.1 研究方法 
本子計畫將推論引擎分成前端推論以及服務推論，前端推論引擎牽涉到如何將感應器接
收到的資料透過推論轉換成高階的資訊，例如:判斷使用者目前的行為，或者環境目前的狀
態。服務推論引擎則收集使用者資訊，諸如:喜好、習慣、經驗、價值觀…等，並轉換成知識
以供服務推論使用。針對推論工具而言，許多的情境感知系統都採用規則式推理系統，採用
規則式推理建構情境感知系統服務推論的部份，此外本子計畫所建立的規則另外包含了規則
 59
 
 完成必要的單項技術設計與實現。總計畫的第二年重點工作項目是與子計畫三共同研製餐飲
服務夥伴，主要的功能設定為接待，引導，說明與餐點服務，目前大致完成基本架構。戶外
定位與導航功能，並以語音方式建立與機器人溝通的管道，及利用語音點餐等技術，業已完
程，待進一步開發雙影像為主的餐盤辨識系統(Stereo Vision System)與視覺定位系統及五軸機
器人手臂機構與功能設計，即可達成能達成準確地端取餐點的任務。目前本整合型計畫已進
行四次小型成果交流、分享與交換相關技術，解決共有問題，並協助各子計畫積極進行預定
的工作項目與實驗,且獲得上述子計畫成果。 
 61
 
  
(a) 
pτ
yτ
αω&ν&ω&∫
αω∫
α&
x&
y&
θ&
α
x
y
θ
rx
ry
rθ
+
+ +
+
rτ
lτν
1 2,  φ φ
3φ
ω
 
(b) 
圖 5.2 與人共生機器人之嵌入式系統架構圖：(a) 二隻七個自由度的機器手臂;(b) 自平衡兩輪
移動平台。 
5.3  子計畫二智慧型嵌入式感測器與運動控制器之研製 
   子計畫二之目的是發展與人共生機器人之運動規劃與察覺人存在的導航系統。該運動規畫
假設在無人類存在的行動空間中，進行最佳路徑的全域路徑規畫，並完成即時的動靜態物體
避障。該導航系統可知覺人類存在，然後因人類的心理層面需要，規劃所需避免碰撞物體以
及符合人們心理與安全需要的運動軌跡，進而完成導航控制。 
 
 63
 
  
圖 5.4 使用修正型粒子群最佳化(MPSO)演算法與彈性帶技術之路徑規畫流程圖. 
   該導航系統可知覺人類存在，該系統依據與人共生的三原則: (i) 不傷害人的安全導航 (ii) 
考慮與人共生機器人運動特性與工作任務需求，進而產生可靠安全運動。 (iii) 納入考量人類
的運動模式，或人的特定習慣與需求的社會行為的移動方式等人類的心理層面需要，規劃所
需避免碰撞物體，以及符合人們心理與安全需要的運動軌跡，進而完成導航控制。圖5.5為考
慮與人共生的三原則的導航系統的可能操作情境示範，以及主要的三大功能模組。 
    
(a)                              (b) 
圖5.5考慮與人共生的三原則的導航系統(a)依可能的操作情境；(b)導航系統的主要功能模組 
 65
 
  
  (a)                                         (b)  
圖 5.8 (a) 使用所提方法的路徑規畫結果; (b) 使用與人共生機器人的路徑追隨實驗結果。 
 
    為檢驗所提的遵守與人共生三原則的導航系統的可行性與實用性，本報告已進行多項有
人存在時的實驗。圖5.9 為若有兩人正在對話時，遵守與人共生的三原則之導航系統的實驗
行駛與影片，而圖5.10.說明該導航系統的實驗結果。由圖5.9顯示該導航系統可達成預期的
運航行為. 
. 
 
圖5.9. 遵守與人共生的三原則的導航系統的實驗過程與影片. 
 67
 
 Builder 6來達成上述技術的模擬與實作目標。 
 
5.4.1 系統架構 
   以嵌入式電腦作為主要控制器，使用SICK NAV200，作為定位用的設備，並利用SICK 
LMS291 雷射測距儀，作為環境認知的主要感測器，主要通訊協定為RS-232。機器人硬體架
構圖如圖5.11所示，系統架構圖如圖5.12 所示。 
 
圖5.11 點餐服務機器人硬體實體圖 
 
圖5.12 點餐服務機器人系統架構圖 
 
5.4.2 研究方法與結果 
   在機器人定位導航方面，主要採用模糊控制來達到智慧型機器人由起始位置到達所設定之
 69
 
     在雙機器手臂部分，完成逆向運動學之推導，求得末端效應器座標與角度的關係式，使
用順序控制方式控制雙機械手臂運動軌跡，配合雙眼視覺系統所得到的目標物座標結果，進
行完成抓取目標物的行為控制。 
 
5.5 子計畫四智慧型機器人之視覺與聽覺系統設計  
   子計畫四之主要目的為發展以計算智慧（computational intelligence）為基礎的機器人
視覺與聽覺系統。其中機器人視覺包含機器與人的互動與環境的認知。而人體與目標物的偵
測是一重要的前處理步驟，人臉的偵測與辨識則是對於提供服務以及環境監控等應用所必須
具備的基本功能。人臉偵測與辨識的目地在於偵測出人臉的位置以及方向，以提高人臉辨識
的準確率。其結果可以用來驗證人體偵測的正確性以及做為環境監控的依據。 
人臉偵測目的在於從包含複雜背景之影像中，找出其人臉可能出現在位置，進而可以用
來確認人體偵測的正確性，並有利於人臉辨識與手勢擷取的進行。本計劃採用結合特徵臉
(Eigenface)演算法與類神經網路的人臉偵測系統來找出各張輸入影像中的人臉座標與大小。
接著，我們利用 disparity 影像資訊與轉角偵測法(corner detection)找出人臉特定之特徵點三維
座標。並且，利用彩色空間中人體膚色的分佈情形，分割出屬於膚色的人臉部分。最後，依
照 disparity 的資訊，將分割出來的人臉部分作距離的正規化，使每張偵測出來的人臉都與攝
影機有相同的距離。在切割出人臉區域，並且完成距離正規化之後，我們可以利用偵測出的
人臉特徵點以及其三維座標，估測出影像中人臉在三度空間的旋轉角度(yaw, pitch and roll)。
最後，我們利用簡單的特徵萃取方法，抽取出代表人臉影像的特徵。在比對模組方面，我們
在系統資訊庫中，每位不同人員擁有五張人臉影像之特徵向量。此五張人臉影像分別以不同
對攝影機之偏離角(yaw)作取樣。一張測試影像經過前述前處理與特徵萃取之後，將與資料庫
中，每位人員的 yaw 角度最接近之人臉特徵進行比對。 
 在機器人方面，移動式機器人（mobile robot）的路徑規畫（path planning）是一個很重要
的議題。利用路徑規劃的方式能讓移動式機器人能藉由事前規劃的路徑，能達成在不同領域
的相關應用。在路徑控制系統方面，我們藉由模糊控制器的設計並且搭配基因演算法能自我
 71
 
  
圖 5.14  實驗用的Pioneer3-DX移動平台 
 
5.5.2 研究方法 
   子計畫四以計算智慧為基礎，設計機器人之視覺系統。人臉偵測與辨識是對於機器人提供
服務與環境監控所需要的基本功能。雖然目前的人臉辨識技術已經具有不錯的辨識率，然而
人臉辨識常常因為辨識環境背景的限制以及光源強度的問題而降低了辨識的正確率。子計畫
四提出一個藉由立體攝影機產生三維空間資訊的人臉辨識系統。利用三維空間資訊判斷人臉
角度，並且正規化人臉影像。此外，子計畫四亦採用梯度臉演算法，完成一不受光源變化影
響的人臉辨識系統。該方法可分成(i)人臉影像擷取與前處理;(ii)人臉與眼睛偵測;(iii)人臉特徵
點定位;(iv)膚色分割與人臉正規化;(v)臉特徵萃取;(iv)人臉特徵比對等六步驟來完成。 
另外，子計畫四也設計一個有效的沿牆行走之行為模式的模糊控制系統。透過模糊控制
系統使機器人在一個未知的環境中，於設定的安全距離內，能夠貼合著牆面沿牆行走。透過
雷射測距儀與影像處理之形態學結合的方式，系統能即時的規劃出一較為準確的參考路徑。
由於機器人對於某些轉角路徑不夠貼合，子計畫四另外加入了基因演算法來改善模糊控制器
的效能。利用基因演算法能夠自我演化的特性，能獲得一組貼近於環境的模糊控制參數，增
加機器人行走行為的準確性。透過軟體模擬來驗證本計畫設計的方法具有低複雜度及更加穩
定的效果。 
5.5.3 結果與討論 
子計畫四使用 Bumblebee BB2 stereo vision camera 來擷取人臉立體影像。每位受測者分別
 73
 
  
 
圖 5.16 測試影像與對應梯度臉範例 
 
(三) 機器人實驗軟體與環境 
本小節使用 ArRobot 所提供的 MobileSim 模擬軟體來進行實驗模擬，透過 MobileSim 模
擬軟體提供的機器人模組，能夠得到與現實相近的模擬結果，並且能夠免除掉許多在實際實
驗時會發生的各種不穩定因子，也能消除硬體結構的干擾、環境的不確定性，如：感測器的
雜訊、機器人的輪胎打滑等。 
另外，我們在同一個模擬環境中設計了五種典型的轉角，如圖 5.17 所示。希望能藉由我
們所設計的轉角，讓機器人能演化出一組能符合各種複雜環境的參數。如此一來機器人就能
應付各種未知的環境，機器人模擬環境如圖 5.18 所示。 
 
 
（a）轉角 1。 
 75
 
  
（d）轉角 5。 
圖 5.17 五種典型轉角訓練路徑圖。 
 
 
圖 5.18 機器人模擬環境圖 
(四) 機器人模擬結果 
在模擬實驗中，使用 MobileSim 模擬軟體並且搭配 Pioneer3-DX 機器人，Pioneer3-DX 機
器人。機器人上搭載 SICK-2000 雷射測距儀，其有效距離與範圍分別為 32 公尺與 180 度。模
擬地圖大小為1700cm ；另外，設定機器人為定速行駛，速度為 150 (mm/sec)。 1700cm×
在未知的環境中，使用模糊控制器來控制機器人的行進角度以利避障以及沿牆行走。機
器人必須要能針對直角、鈍角與鋭角等三種角度的轉彎來進行轉彎，並且能行走於曲線與直
線的路徑。對於這些不同情況的路徑與環境，我們希望基因演算法能夠選出一組好的模糊控
 77
 
 在模擬誤差實驗中，利用下面的式子來計算出機器人與參考路徑的平均誤差量，計算公
式如下： 
( ) 1
n
t
t
D
e n
n
==
∑
 
，其中 為機器人與參考路徑的誤差。另外，在實驗中我們同時考量了global/local的參考路
徑與機器人的誤差。如圖 5.21
tD
圖所示，藍線部份是local的參考路徑為機器人在每個時間t即時
計算出來的參考路徑；紅線部份是global的參考路徑，是對整張地圖所計算出的參考路徑。 
為了驗證所提方法的穩定性，我們設計了凹形與八角形兩種不同的環境來進行模擬實
驗。由圖 5.22 可以發現，5 與7 的實驗組在執行基因演算法數代的演化後，機器人的行
進路徑都能逐漸貼合參考路徑行走，與參考路徑的誤差也都大幅縮小。如表 5.1 所示，在
5× 7×
5 5×
實驗組中，local 的部份從 153(mm/sec)減少到 73(mm/sec)；global 的部份從 324(mm/sec)減少
到 120(mm/sec)。在 實驗組中，local 的部份從 87(mm/sec)減少到 64(mm/sec)；global 的部
份從 148(mm/sec)減少到 116(mm/sec)，透過設計的多種實驗環境模擬結果可證明，我們所提
出的方法可以適應各種未知的環境，達成機器人在未知的環境沿牆行走之行為控制的目的。 
7 7×
 
 
圖 5.21  global與local參考路徑示意圖 
 
g 5×5 rule table 7×7 rule table 
 79
 
 統龐大的演算法則並下達整體系統運作方針，但也可依照工作性質與環境的不同而有所調
整。圖 5.24 所示的低階控制系統主要是用於處理機器人系統的周邊硬體驅動與監控。如此分
類方式也使機器人整體系統可被有效率的規畫，硬體控制與龐大運算量各有各自的核心專門
處理，不會因為同時要處理硬體即時控制與龐大計算量而使核心需使用成本更高、速度更快
並更繁瑣的排程來滿足整體系統運作。由於龐大的機器人系統需要資源管理降低系統繁雜
度，並且針對外在環境狀況做即時的反應能力，因此需要在各個核心中移植適當的即時作業
系統，藉由軟體框架以及即時性設計完整的機器人系統。 
 
 
圖 5.23 整合開發系統平台運用架構 
 
 
圖 5.24 整合開發系統架構 
5.6.2 研究方法 
 81
 
 定以 CANBus 為整體系統的通訊傳輸介面。控制器區域網路（Controller Area Network），簡
稱 CANBus，它目前被廣泛應用於車輛中電子設備間的一種串列傳輸技術。接線數只需兩條，
串接節點數高，抗雜訊以及傳輸穩定可靠度皆高，外加其具有廣播特性和訊息優先權功能，
讓整體系統有更完善的即時性和工作效能。 
由於 CANBus 技術目前大多運用於車用電子上，儘管本專案低階控制系統所選用的核心
架構中有 ECAN 模組符合 CANBus 規範，但高階決策系統的核心架構不一定有相關的硬體模
組可使用，所以屆時將會需要轉換橋接器的設計與使用。解決方式可藉由自行設計的 dsPIC
控制模組作為橋接器使用，將高階決策系統所傳出的訊號透過自行設計的程式轉為 CANBus
訊號，如此也可將其視為分散式架構中的一環，在此子系統中作額外功能開發。另外在市面
上也可購買的到相對應轉換 IC，如圖 5.26 所示就是透過 MCP2515 此 IC 作為 SPI 訊號與
CANBus 訊號之間的轉換橋接器。 
 
 
圖 5.26 SPI 與 CAN 互轉電路實體圖 
5.6.2.2 高階控制系統設計 
以機器手臂控制方面來說，首先解決問題為計算順向及逆向運動學計算式，如此才可定
義及規劃手臂姿態，往後才可以決策或學習的演算法來發展。運動學是計算物件在空間的位
置，以矩陣型態解聯立方程式，因此在運算量上是相當龐大的，尤其當機器手臂的轉軸數越
多，所以此處核心主旨需符合高速運算需求。本處系統核心控制將選用 Altera 公司的 DE2-70
開發板，因其能夠從事非常廣泛的硬體設計與邏輯電路的實現，再者其 CPU 的執行速度可以
達到 100MHz，且由於它符合計算機架構，所以可以在處理器內使用 C 語言來進行程式的撰
 83
 
  
圖 5.29 控制機器手臂之實現實體圖 
子計畫五已實現分散式系統的機器手臂的控制系統，該系統藉由 CANBus 的通訊介面使
得，使各層控制可更為完善。使用者可將各子系統以模組化的方式進行溝通，無論是控制、
通訊、擴充性、時間控制等問題，皆可在本系統中透過分工的方式得到解決。 
 
5.7 子計畫六智慧型人機互動系統設計  
子計畫六主要的研究課題是要提升人機互動、結合多台行動機器人、並提供多樣性且依
個別需求的任務來服務多位使用者。服務機器人最大的任務，就是滿足使用者的需求。使用
者所期待的服務機器人，莫非能提供使用者即時又貼切的服務及協助。在生活中，機器人的
出現與存在，是否帶給使用者方便（或者是麻煩），必須要考慮到機器人與使用者的互動問題。
本子計畫所探討的問題就是如何改善使用者與機器人的溝通，使用者的需求可藉由語音的介
面傳達於機器人，而機器人的回應也藉由語音傳遞給使用者。機器人與使用者的溝通，不限
於單向的溝通，機器人可處於被動式的接受使用者的指示，也可以是主動式與使用者對話。
因此，如何瞭解使用者的意圖將成為機器人所需的機能。同時，機器人不只是與使用者需要
溝通，也需要與其他機器人或智慧型環境等服務機制溝通，本子計畫將探討服務導向架構以
及多重代理人架構，提升具多模式介面機器人系統的擴充性。本子計畫於第一年探討人機互
動所需之知識表示方法，於第二年研究情境資訊，將環境知識與人機互動所需的知識作整理。
 85
 
  
圖5.30.情境感知系統架構 
以下簡述圖 5.30 系統內各個元件的功能: 
z Behavior Reason Component:此元件用來推理人類行為，系統會先向行為本體論要求一個
人類行為的背景知識，之後透過感應器觸發該元件裡的本體論實體，並透過演算法加以
計算，並得到與該元件內容行為的相似程度，藉此系統了解人類目前的情況，此元件會
將目前的情況傳送給「Environment Ontology」。 
z Behavior Ontology:行為本體論，此元件是紀錄人類行為的本體論，內容包含與人類行為
相關的時間、地點、物品與子行為，透過這些相關的線索可以進行人類行為的推理與判
斷。 
z Environment Monitor:此元件用來監控目前環境的狀態，包含人類的行為、物品的使用、
時間…等等相關的資訊，但此元件會記錄「Behavior Ontology」所推理的結果，因為人類
正在發生的行為屬於一種環境狀態。此元件所包含的資訊會傳送給規則式推理的事實
庫，以及元件「Confidence Modify Component」。 
z Environment Ontology:環境的本體論，內容記錄著環境物件彼此之間的關係、以及物件本
 87
 
 工作在於環境知識的定義以及排程系統的建立。本子計畫第二年主要導入情境感測系統的研
究於整合型計畫中。第三年所研究的內容包括服務組合的驗證及系統的整合。所使用的技術
包括規則式及案例式推理並派翠網路驗證法。本研究中規則式推理使用在服務的推論，由於
規則式推理的特性可以使情境感知系統處理複雜多變的人類喜好具有優勢，而本體論則被使
用於建構使用者行為推論的部份，這是因為本體論用來表達知識具有優勢。在情境推論中採
用案例式推理，此推論是參考使用者過去之歷史資訊做為推論依據，隨著案例的增加系統的
推論能力越強也越貼近使用者。了解使用者之行為後，本研究也建構了個人化本體論來表達
使用者對於服務的習慣與偏好，並利個人化本體論來選擇出適合的服務。在驗證階段，對於
轉換產生的派翠網路模型可以透過遮蔽樹、關連矩陣與狀態方程式以及遞移矩陣等驗證方
法，驗證安全性、可到達性與活性等與結構正確性相關的性質。 
 
5.7.2 結果與討論 
子計畫六所提的方法一次只能檢驗一個描述網路服務組合的 OWL-S 檔案，每個 OWL-S
檔 案 只 能 含 有 一 層 組 合 服 務 架 構 ， 即 檔 案 中 只 有 一 個 組 合 服 務 存 在 ( 一 個
process:CompositeProcess 標籤)，而組合服務所含有的成員服務也必須為基本服務。雖然這個
限制導致本系統無法直接驗證某些 OWL-S 檔案，但我們知道最原始的組合服務是由多個基
本服務組成，也就是說任何組合服務都可拆解成完全以基本服務組成的服務，因此對於含有
多個組合結構的 OWL-S 檔案，可以在系統外部拆解重組成單一組合服務架構的 OWL-S 檔案
後，再呼叫本系統執行。 
圖 5.31 以循序圖描述驗證方法主要工作之間的關係，圖中虛線方塊代表外部系統提供的
物件，實線方塊則代表系統內部的物件，其中 Correctness Verificator 是由 Safeness Verificator、
Reachability Verificator 與 Liveness Verificator 組成，Document Translator 則是由 OWL-S to 
PNML Translator、OWL-S Parser、XSLT Engine 與 PNML Parser 組成。 
 
 89
 
 進行拆解與修改，接著 OWL-S to PNML Translator 將 OWL-S Parser 產生的 OWL-S 格式結構
樣版交由 XSLT Engine，搭配對應的 XSLT 範本文件轉換為 PNML 格式的結構樣版，最後
OWL-S to PNML Translator 將這些樣版交由 PNML Parser 進行合併與修改，產生儲存 place、
transition 與 arc 的陣列並回傳給 Correctness Verificator，完成了塑模的程序。在塑模結束後，
這些陣列被當成輸入參數傳給 Structure Verificator，依序執行安全性驗證、可到達性驗證與活
性驗證，驗證產生的結果文件會被 Correctness Verificator 交由 Verification Result Integrator 進
行整合，以產生一份正確性驗證結果文件，並將文件回傳給 Plan Generator 完成了驗證的程序。 
 
5.8 本章結論  
   第三年期末報告已敘述如何完成協調統合各子計畫完成第三年預定工作項目，並協助各子
計畫完成必要的單項技術設計與實現。總計畫大致初步完成與應用各子計畫所完成的重點技
術，研製老年照護伴侶所需的關鍵技術，以及應用項目如照護、保健，事件提醒，扶持，餐
食與物件提供開發等功能。目前本整合型計畫業已進行四次小型成果交流、分享與交換相關
技術，解決共有問題，並協助各子計畫積極進行預定的工作項目與實驗,且獲得上述子計畫成
果。 
 91
 
 技術的脈動，承先啟後開發新技術與發明創意，並完成上開的六項關鍵技術的研究。另外本
整合計畫也引進日韓等國外大學的關鍵零主件、系統技術與設計創意與構想，彌補國內之不
足，促進製作技術的提昇。在實作方面，本整合計畫採用嵌入式系統晶片技術，使整體控制
系統彈性化、小型化、省電化與智能化；如此可以依據應用的需要，輕而易舉地更改設計，
用以達成不同用途的應用功能。同時藉此一能結合智慧型與人共生服務夥伴機器人機構設
計、系統設計、感測、驅動，導航，視覺，聽覺，雙臂協調控制，智慧人機互動與嵌入式系
統晶片等應用科技的研發主題，提昇學生學習興趣與成效，落實工程創新教育，培育理論與
實務兼備的工程人才。 
    整體而言，本整合計畫所開發的關鍵技術已顯著提昇智慧型與人共生系統的感知、學習、
行動、操控性、智慧決策、安全、可靠度、價格、造型與友善介面；所研發的系統軟硬體建
置與相關實務技術，不但有助於現今智慧型與人共生機器人系統的實際研製技術，同時所開
發的實體可作為商用服務、休閒娛樂、居家服務以及老年照護機器人之共通實驗平台，可縮
短其研發時間，加快其產品上市。 
就學術研究、國家發展及其他應用方面而言，本整合計畫已有以下效益與貢獻： 
(1)  本整合計畫已提昇每一關鍵技術之設計、機能與智慧功能，並提出一創新，有效實用的
工程設計方法，發展軟硬體的實作技術，並建置完成可進行實驗展示與實驗測試的與人
共生機器夥伴系統。因此，所發展的技術對我國機器人產業，可提供基礎的研發能量，
開發新穎實用之關鍵技術與系統技術。 
(2)  每年完成六份有關六項創新技術之研究報告，並完成相關技術之關鍵軟硬體製作與測
試，每年已發表至少 12 篇研討會論文，6 篇 SCI 級期刊論文，投稿於國內外著名的研討
會與期刊。 
(4) 整個計畫已完成訓練碩士班究生 26 名及博士生 6 名，使其分別獲得機電整合、定位導航、
感測器、系統控制、晶片設計、電腦視覺、智慧資訊處理、人工智慧、資訊技術與系統
晶片等技術之分析設計與實作經驗。這些人才已進入國內業界，研究單位與教育單位服
務，這些人才已對提昇國家競爭力將有助益。 
(5) 整個計畫已產生5個專利或發明，將來期望可技術轉移至產業界，可提昇國內控制與智慧
 93
 
 References 
[1]  …,“Robots Stand on own Two Feet,”Spectrum, IEEE, Aug., 2002. 
[2]  Y. Sakagami, R. Watanabe, C. Aoyama, S. Matsunaga, N. Higaki and K. Fujimura,“The 
intelligent ASIMO: System overview and integration,”Proc. of IEEE Int. Conf. Intelligent 
Robotics and System, pp. 2478-2483, Oct., 2002. 
[3]  S. Yamamoto, K. Nakadai, H. Tusuino and H. G. Okuno,“Assessment of General Applicability 
of Robot Audition System by Recognizing Three Simultaneous Speeches,” Proc. of IEEE Int. 
Conf. Intelligent Robotics and System, pp. 2111-2116, Oct., 2004. 
[4] G. A. Bekey, Autonomous robots, MIT Press,Cambridge, Massachusstts, 2005. 
[5]  R. C. Arkin, M. Fujita, T. Takai and R. Hasegawa,“An ethological and emotional basis for 
human–robot interaction,”Robotics and Autonomous, vol. 42, pp. 191-201, 2003. 
[6]  L. Geppert,“Qrio, the robot that could,”Spectrum, IEEE, May., 2004. 
[7]  …,“Yoshihiro Kuroki dancing with robots,”Spectrum, IEEE, Feb., 2004. 
[8]  J.-S. Gutmann, M. Fukuchi and M. Fujita,“Stair Climbing for Humanoid Robots Using Stero 
Vision,”Proc. of IEEE Int. Conf. Intelligent Robotics and System, pp. 1407-1413, Oct., 2004. 
[9]  K. Nagasaka, Y. Kuroki, S. Siziki, Y. Itoh and J. Yamagouhi,“Integrated Motion Control for 
Walking, Jumping and Running on a Small Bipedal Entertainment Robot,” Proc. of IEEE Int. 
Conf. Intelligent Robotics and System, pp. 3189-3194, Apr., 2004. 
[10] F. Tanaka, B. Fortenberry, K. Aisaka, J. R. Movellan,“Plans for Developing Real-time 
Interaction between QRIO and Toddlers in a Classroom Enviroment,”Proc. of IEEE Int. Conf. 
Development and Learing, pp. 142-147, 2005. 
[11] K. Sabe,“Development of Entertainment Robot and Its Future,”Symposium on VLSI Circuits 
Digest of Technical, 2005. 
[12] Y. nakamura, H. Hirukawa, K. Yamane, S. Kajita, K. Fujiwara, F. Kanehiro, F. Nagashima, Y. 
Murase and M. Inaba,“Humanoid robot simulator for the METI HRP Project,”Robotics and 
 95
 
 [23] International Football Association Board. Laws of the game. [Online]. Available : 
http://www.fifa.com./refs/laws_E.html 
[24] B. Jeosen, G. Froidevaux, X. Greppin, A. Lorotte, L. Mayer, M. Meisser, G. Ramel, R. 
Sliegwart, “The interactive Autonomous Mobile System Robox, ” proceeding of the 2002 
IEEE/RSJ International conference on intelligent robots and systems, Lausanne, Switzerland, 
pp. 1221-1227, 2002. 
[25] W. Burgard, A. B. Cremers, D. Fox, D. Hahnel, G. Lakemeyer, D. Schulz, W. Steiner, S. Thurn,  
“The Interactive Museum Tour-Guide Robor,” proceeding of the fifteenth National Conference 
on artificial intelligence (AAAI-98), Madison, Wisconsin, 1998.  
[26] S. Thurn, M. Bennewin, W. Burgard, A. B. Cremers, F. Dellaert, D. Fox, D. Hahnel,,C. 
Rosenberg, J. Schulte, D. Schulz, “MINERVA: A secong-generation museum tour-guide 
robot,” Proceeding of the 1999 international conference on robotics and automation, Detroit, 
Michigan, USA, pp.1999-2005, May 1999. 
[27] B. Graf, M. Hans, R. D. Schraft, “Mobile robot assistants,” IEEE Robotics and Automation 
Magazine, pp.67-77, June 2004.  
[28] G. Kim, W. Chung, K-R Kim, S. Han, R-H. Shinn, “The autonomous tour-guide robot Jinny,”  
proceeding of the 2004 IEEE/RSJ International conference on intelligent robots and systems, 
Sendai, Japan, pp. 3450-3455, September 28-October 2, 2004. 
[29] 日本愛知博覽會，http://www-1.expo2005.or.jp。 
[30] R. D. Schraft and G. Schmierer, Service Robots, A K Peters, Ltd., 2000. 
[31] K.Kawamura,; Iskarous, M. “Trends in service robots for the disabled and the elderly “'',. 
Proceedings of the IEEE/RSJ/GI International Conference on Intelligent Robots and Systems 
'94, IROS '94, vol.3, pp.  1647-1654, 1994. 
[32] Schraft, R.D.; Schaeffer, C.; May, T., “Care-O-bot TM: the concept of a system for assisting 
elderly or disabled persons in home environments,” Proceedings of the 24th Annual Conference 
of the IEEE Industrial Electronics Society, IECON '98, pp.2476 -2481, 1998. 
 97
 
 mobile manipulators”, IEEE Transactions on Robotics and Automation, 
Vol.18,  No.6, pp.957 – 965, Dec. 2002. 
[43] Y.Umeda, T.Yakoh, “Configuration and collision control for a mobile robot with external 
sensors,” IEEE Transactions on Industrial Electronics, Vol.49, No.1, pp.241-247, 2002. 
[44] S. Kamio and H. Iba, “Adaptation Technique for Integrating Genetic Programming and 
Reinforcement Learning for Real Robots,” IEEE trans. On Evolutionary Computation, vol.. 9, 
no.. 3, pp. 318-333, June 2005. 
[45]  http://www.segway.com/ 
[46]  H. Yunsu and S. Yuta ‘‘Trajectory Tracking Control for Navigation of self-Contained Mobile 
Inverse Pendulum,’’ IEEE/RSI/GI International Conference Advanaced Robostic Systems and 
the Real World, vol 3,pp. 12-16, September 1994. 
[47]  F. Grasser, A.D’Arrigo, and S. Colombi, “JOE: A Mobile, Inverted Pendulum,” IEEE 
Transactions on Industrial Electronics, vol. 49, no. 1, pp.107-114, February 2002. 
[48] T. Blackwell, “Building a Balancing Scooter”, http://www.tlb.org/scooter.htm. 
[49] M. L. Swinson, D. J. Bruemmer, 2000, “Expanding Frontiers of Humanoid Robotic,” IEEE 
Intelligent Systems Special Issue on Humanoid Robotics, July/August.  
[50]  O. Brock, O. Khatib, 2000, “Integrated Planning and Execution: Elastic Strips,” Proceeding 
of the World Automation Congress, 8th International Symposium on Robotics with 
Applications, Maui, Hawaii, June 11-16.  
[51] O. Brock, O. Khatib, 2002, “Elastic Strips: A Framework for Motion Generation in Human 
Environments,” The International Journal of Robotics Research, Vol. 21, No. 12, pp. 1-22. 
[52] O. Khatib, O. Brock_, K.C. Chang, D. Ruspini, L. Sentis, S. Viji, 2003, “Robots for the Human 
and Interactive Simulations,” Proceedings of the 11th World Congress in Mechanism and 
Machine Science, Aug. 18-21, Tianjin, China.  
[53] M. Zinn, O. Khatib, B. Roth, and J.K. Salisbury, “A New Actuation Approach for Human 
Friendly Robot Design,” in Proceeding of the International Symposium on Experimental 
 99
 
 [63] P. Jensefelt, and S. Christensen, “Active Global Localization for a Mobile Robot Using 
Multiple Hypothesis Tracking,” IEEE Transactions on Robotics and Automation, Vol. 17, No.5, 
pp.748-759, October 2001. 
[64] C. Schlegel, and T. Kampke, “Filter Design for Simultaneous Localization and Map Building 
(SLAM),” Proceedings of 2002 IEEE International Conference on Robotics and Automation, 
Washington D.C., USA, pp. 2737-2742, May 2002. 
[65] Ti-Chung Lee, Kai-Tai Song, Ching-Hung Lee, and Ching-Cheng Teng, “Tracking Control of 
Unicycle-Modeled Mobile Robots Using a Saturation Feedback Controller,” IEEE Transactions 
on Control Systems Technology, Vol. 9, No. 2, pp.305-318, March 2001. 
[66] Ti-Chung Lee, Chi-Yi Tsai, and Kai-Tai Song, “Fast Parking Control of Mobile Robots: A 
Motion Planning Approach with Experimental Validation,” IEEE Transactions on Control 
Systems Technology, Vol. 12, No. 5, pp.661-676, September 2004. 
[67] Cheng Chen, Han Wang, Ng Teck Chew et. al., “Target-Tracking and Path Planning for Vehicle 
Following in Jungle Environment,” 2004 8th International Conference on Control, Automation, 
Robotics and Vision, pp.455-460, Kunming, China, December 6-9, 2004. 
[68] Norihisa Miyake,Toshihiro Aono, Kenjiro Fujii, Yuji Matsuda, Shintaro Hatsumoto, “Position 
Estimation and Path Control of an Autonomous Land Vehicle,” pp.690-696, Proc. IEEE/IROS 
97 0-7803-4119-8/97. 
[69] David W. Hodo, John Y. Hung, David M. Bevly, and Scott Millhouse, “Effect of Sensor 
Placement and Errors on Path Following Control of a Mobile Robot-Trailer System,” 2007 
American Control Conference, September 22, 2006. 
[70] Chia-Ju Wu, and Ching-Chih Tsai, “Localization of an Autonomous Mobile Robot Based on 
Ultrasonic Sensory Information,” Journal of Intelligent and Robotic Systems 30: pp.267-277, 
2001 Kluwer Academic Publishers. Printed in the Netherlands. 
[71] Tsong-Li Lee, and Chia-Ju Wu, “Fuzzy Motion Planning of Mobile Robots in Unknown 
Environments,” Journal of Intelligent and Robotic Systems 37: pp.177-191, 2003 Kluwer 
 101
 
 Cybernetics and Intelligent Systems, Singapore, pp. 135-140, 1-3 December, 2004. 
[82] A. Mian, M. Bennamoun, and R. Owens, “An Efficient Multimodal 2D-3D Hybrid Approach 
to Automatic Face Recognition,” IEEE Transactions On Pattern Analysis and Machine 
Intelligence : Accepted for future publication, 2007, Digital Object Identifier 
10.1109/TPAMI.2007.1105 
[83] K. S. Hwang and M. Y. Ju, ``Speed Alteration Strategy for Multi-Joint Robots in Co-Working 
Environment,'' IEEE Transactions on Industrial Electronics, Vol. 50, pp. 385- 393, 2003.  
[84] K. S. Hwang, S. W. Tan, and C. C. Chen, ``Cooperative Strategy Based on Adaptive 
Q-learning for Robot Soccer Systems,''  IEEE transaction on Fuzzy Systems, pp. 569-574, Vol. 
12, 2004.  
[85] C. H. Wu, K. S. Hwang, and S. L. Chang, ``Analysis and Implementation of A 
Neuromuscular-Like Control for Robotic Compliance,'' IEEE Transactions on Control Systems 
Technology, vol. 6, no. 2, pp.586-592, Nov. 1997. 
[86] A. Namiki, K. Hashimoto, and M. Ishikawa, ``A Hierarchical Control Architecture for 
High-Speed Visual Servoing,'' International Journal of Robotic Research, Vol. 22, No. 10-11, pp. 
873-888, Oct.-Nov. 2003. 
[87] Y. Nakabo, I. Ishii, and M. Ishikawa, ``3D Tracking using Two high-Speed Vision Systems,'' 
IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 360-365, 2002. 
[88] M. Riley and C. G. Atkeson, `` Robot Catching: Towards Engaging Human-Humanoid 
Interaction,'' Autonomous Robots, pp. 119-128, Nov. 2004. [7] U. Frese, B. Bauml, S. 
Haidacher, G. Schreiber, I. Schaefer, M. Hahnle, and G. Hirzinger, `` Off-the-Shelf Vision for a 
Robotic Ball Catcher,''IEEE/RSJ International Conference on Intelligent Robots and Systems, 
pp. 1623-1629, 2001. 
[89] I. Marsic, A. Medl, and J. Flanagan, “Natural communication with information systems,” 
Proceedings of the IEEE, vol. 88 , no. 8 , Aug. 2000, pp. 1354-1366. 
[90] H.M. Meng and K.C. Siu, “Semiautomatic acquisition of semantic structures for understanding 
 103
 
 2006.  
[100] Z. Li, A. Ming, N. Xi, M. Shimojo, and M. Kajitani, “Mobile manipulator collision control 
with hybrid joints in human-robot symbiotic environments,” Proc. of IEEE/RSJ international 
conference on intelligent robots and systems, Sendai, Japan, pp. 154-161, September 
28-October 2, 2004. 
[101] T. Morita K. Shibuya, S. Sugano, “Design and control of mobile manipulation system for 
human symbiotic humanoid: Hadaly-2, ” Proceeding of the 1998 international conference on 
robotics and automation, Leuven, Belgium, pp.1315-1320, May 1998.  
[102] T. Morita H. Jwata,  S. Sugano, “Development of human symbiotic robot, ”Proceeding of 
the 1999 international conference on Robotics and Automation, Detroit, Michigan, USA, 
pp.3183-3188, May 1999. 
[103] T. Morita H. Jwata,  S. Sugano, “Human symbiotic robot design based on division and 
unification of functional requirements, ”Proceeding of the 2000 international conference on 
Robotics and Automation, San Francisco, CA, USA, pp.2229-2234, April 2000.  
[104] H. Jwata, S. Sugano, “Human robot interference adapting control coordinating human 
following and task execution,” Proc. of IEEE/RSJ international conference on intelligent 
robots and systems, Sendai, Japan, pp. 2879-2885, September 28-October 2, 2004. 
[105] S. Sugano, “Design of humanoid robot for human-robot interaction-Waseda Robots:Wendy 
and Wamoeba” Proc. of 2005 IEEE international conference on Robotics and Biomimetics, 
pp.16-19, 2005. 
[106] R. Fukui. H. Morishita and T. Sato, “ Expression Method of Human Locomotion records for    
path planning and control of human-symbiotic robot system based on special existence 
probability model of humans, ”Proceeding of the 2003 international conference on Robotics 
and Automation, Taipei, Taiwan,  pp.4178-4184, September 14-19, 2003. 
 105
 
  
 
107
     整體而言，本整合計畫所開發的關鍵技術已顯著提昇智慧型與人共生系統的感知、學
習、行動、操控性、智慧決策、安全、可靠度、價格、造型與友善介面；所研發的系統軟硬
體建置與相關實務技術，不但有助於現今智慧型與人共生機器人系統的實際研製技術，同時
所開發的實體可作為商用服務、休閒娛樂、居家服務以及老年照護機器人之共通實驗平台，
可縮短其研發時間，加快其產品上市。 
   除六項創新技術之成功開發外，就提昇國內研發能量與人才培育而言，本整合計畫已完成
執行結合中台灣四個國立大學學術與技術兼備的優秀研究者，共同合作，群策群力，掌握智
慧型與人共生機器人的核心關鍵技術的脈動，承先啟後開發新技術與發明創意，並完成上開
的六項關鍵技術的研究。另外本整合計畫也引進日本等國外大學的關鍵零主件、系統技術與
設計創意與構想，彌補國內之不足，促進製作技術的提昇。在實作方面，本整合計畫採用嵌
入式系統晶片技術，使整體控制系統彈性化、小型化、省電化與智能化；如此可以依據應用
的需要，輕而易舉地更改設計，用以達成不同用途的應用功能。同時藉此一能結合智慧型與
人共生服務夥伴機器人機構設計、系統設計、感測、驅動，導航，視覺，聽覺，雙臂協調控
制，智慧人機互動與嵌入式系統晶片等應用科技的研發主題，提昇學生學習興趣與成效，落
實工程創新教育，培育理論與實務兼備的工程人才。 
 
(3) 主要發現及其他相關價值： 
就學術研究、國家發展及其他應用方面而言，本整合計畫已有以下主要貢獻與相
關價值： 
(1)  本整合計畫已提昇六項關鍵技術之設計、機能與智慧功能，並提出一創新，
有效實用的工程設計方法，發展軟硬體的實作技術，並建置完成可進行實
驗展示與實驗測試的與人共生機器夥伴系統。因此，所發展的技術對我國
機器人產業，可提供基礎的研發能量，開發新穎實用之關鍵技術與系統技
術。 
(2)  每年完成六份有關六項創新技術之研究報告，並完成相關技術之關鍵軟硬
體製作與測試，三年共發表 120 篇研討會論文，36 篇 SCI 級機器人領域相
  
 
109
如此可以依據應用的需要，輕而易舉地更改設計，用以達成不同用途的應用功能。同
時藉此一能結合智慧型與人共生服務夥伴機器人機構設計、系統設計、感測、驅動，
導航，視覺，聽覺，雙臂協調控制，智慧人機互動與嵌入式系統晶片等應用科技的研
發主題，提昇學生學習興趣與成效，落實工程創新教育，培育理論與實務兼備的工程
人才。 
97 年度專題研究計畫研究成果彙整表 
計畫主持人：蔡清池 計畫編號：97-2221-E-005-070-MY3 
計畫名稱：智慧半人型與人共生服務機器人之研製--總計畫：智慧半人型與人共生服務機器人之研製
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 0%  
研究報告/技術報告 1 1 100%  
研討會論文 4 2 200% 
篇 
 
論文著作 
專書 0 0 0%   
申請中件數 3 1 300%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 2 2 100%  
博士生 1 1 100%  
博士後研究員 0 0 0%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 1 100% 
人次 
 
期刊論文 9 3 300%  
研究報告/技術報告 0 0 100%  
研討會論文 32 4 800% 
篇 
 
論文著作 
專書 1 1 100% 章/本  
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
目 計畫成果推廣之參與（閱聽）人數 0  
 
