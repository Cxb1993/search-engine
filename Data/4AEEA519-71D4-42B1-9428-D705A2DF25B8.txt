摘要
 前列腺全量病理切片的方式保留了腫瘤細胞區域及其所佔總量比例的資訊。這些資訊
對臨床的診斷治療預後是很重要的。然而這麼大範圍的影像檢視對於病理醫師是一個很大的
負擔，而且以人工的方式進行腫瘤細胞數量和腫瘤與其他組織的距離估計是相當主觀而且因
人而異的。而自動化的檢視可以減少病理醫師的一些重複性工作的負擔，而且由電腦計算所
得到的客觀估量，對於臨床診斷治療的準確性會更有幫助。因此這個研究的主題是以一些資
訊技術來進行前列腺全量病理切片自動化檢測，其中包括三個主要問題:一、如何利用相關
影像技術快速的自一張前列腺全量切片中辨識並切割出腫瘤細胞；二、如何自動進行葛力森
分級，並進行區域分割、 標示與估量；三、如何利用台中榮總病理部特有的全量連續切
片，產生有用的三維影像並進行三維的估量來幫助臨床醫師進行更精準的診斷和治療。
 本計畫將以第一和第二個問題為主要的標的，一開始利用切片中切割出來細胞的分布
來協助辨識腺體的管腔，去除掉切片上常有的空洞和間質組織，留下腺體、血管、神經結和
尿道，接下來以腺體管腔為主要的辨識依據來計算腺體間質比，決定該區域是否為正常腺體
或是低分級前列腺癌。剩下的區域再辨識血管、神經結和尿道的組織，接下來可能為高分級
的前列腺癌和發炎，由這些分割出來的區域我們建立出二維全量切片的模型。提供醫師二維
的檢視和估量由醫師和評估轉移的可能性，決定其預後和治療的方式。 
關鍵詞:前列腺癌，切片影像，切割，二維空間模型
 
II
I. 前言
 
 前列腺是人體的一個外分泌腺。它是男性生殖器官中最大的一個附屬性腺，對男性生
殖功能具有特殊的作用。前列腺位於膀胱的下方，圍繞著前列腺部尿道，上接膀胱頸，下接
膜狀尿道。 其中有2條射精管穿過前列腺後方，並集中在前列腺尿道中央進入尿道。正常前
列腺外形微扁，形似栗子，呈圓錐體狀，底朝上，尖朝下，大小約為4×3×3公分，重量約
20公克。前列腺的被膜有三層構成，即外層、中層和內層。外層為前列腺筋膜，來自直腸膀
胱之間的盆筋膜，它緊貼在前列腺的前面和側面，含有豐富的靜脈和疏松結締組織；中層為
纖維鞘，亦即前列腺固有包膜，是由纖維組織和平滑肌構成的一層緻密而堅韌的包膜，部分
包膜伸入腺體實質，使腺體分葉，因此，包膜與腺體之間緊密粘合；內層是肌層，與前列腺
組織內的大量肌纖維相連。精囊腺左右各一，長約4～5厘米，前后扁平，呈分葉狀，近似倒
八字形緊貼于膀胱后壁與直腸之間。精囊腺內含大量複管泡狀腺，腺腔較大，其排泄管與輸
精管末端匯合，穿過前列腺進入尿道前列腺部，開口於尿道上。
 而前列腺癌(prostate cancer)，又稱攝護腺癌，依據1993~2001年的統計，全球男性最常
罹患的癌症分別是肺癌、前列腺癌和胃癌。根據行政院衛生署統計，民國82年台灣地區前列
腺癌之年發生率為每十萬人5.52人，為男性第八位癌症，而在今年衛生署所公佈的94年度臺
灣地區主要癌症死亡原因中的男性癌症死因，前列腺癌則已經上升到第6位。因此前列腺癌
的診斷和治療對我們的重要性是與日俱增。[1]
 前列腺癌治療的種類，大致可分為五大類：第一類是暫不治療，門診持續追蹤；第二
類是手術治療；第三類是放射治療；第四類是荷爾蒙治療；第五類是化學治療。每一類的治
療又可細分為幾個小類，例如前列腺根除手術(Radical prostatectomy)，經會陰前列腺根除手
術，腹腔鏡前列腺根除術，達文西機器人腹腔鏡前列腺根除術等。而在手術切除後若有前列
腺包膜、貯精囊、周邊組織如膀胱直腸有癌細胞侵犯、距離手術切口非常近、有骨盆腔淋巴
結轉移等情況，需建議病人接受手術後放射治療。這時，前列腺的病理切片所提供的資訊就
變得很重要了。臨床醫師可以根據腫瘤細胞的分級，分布位置，總量以及侵犯的範圍來決定
其治療方針和預後評估。另外許多因前列腺肥大而手術的病人，從其組織病理切片中發現前
列腺癌者大約佔手術者的1/10，這些病人大多是早期的前列腺癌，早期的發現並接受正確的
治療，可以大大的提高存活率。所以前列腺病理切片中對腫瘤細胞的偵測、分級、分布位置
和總量的估計是很重要的。
 傳統前列腺切片是從前列腺的兩側，各做三個切片總共做六個切片的方法。但是在21
世紀以後這方法已經被漸漸改良，現在已經將切片增加到前列腺兩側各切5片、共切10片的
方法，甚至可以切到12片、14片，或是15片。傳統6針的前列腺切片可以偵測到70-80%的腫
瘤。儘管如此，仍然會有不夠精確的問題存在，並不能對全貌進行評估。
 臺中榮總病理部目前嘗試著改採全量(WM, whole mount)的切法，WM標本可以看出腫
瘤的全貌和腫瘤在前列腺確實的分布情形，並且可以進行總量的估算對病情能有更精準的診
斷。例如【圖1】，以奇異筆所標示的部分是前列腺癌的腫瘤部分，在全量病理切片中可以
看出其癌細胞的範圍、癌細胞並未擴散到包膜及其他敏感組織。
析都不適用，因此本計畫將針對全量影像開發一連串的演算法和特徵抽取來辨識和切割出所
有可能的組織和分級後的腺體區域，產生二維的模型，提供病理醫師適當的診斷輔助。
IV.研究方法  
 本計畫所使用之的全量切片影像均請台中榮總醫檢師林淑娟小姐幫忙拍攝，在個別影
像分析後再進行全量影像組合。而個別影像分析方面，主要的目標是要將影像切割成一個個
的同質區塊，然後進行辨識和前列腺癌分級。可是切片的組織變化相當的大，並不太容易以
單一技術完成切割，在觀察後發現影像中的空洞是最大的關鍵。因為若空洞是前列腺癌的腔
體，則使用各種統計的特徵來分辨是合理的。然而在全自動化的前提下，空洞有各種的可能
性，空洞就變成不是一個可靠的特徵。因此必須以這空洞為主體先進行一次分類及切割，讓
個別的區域內所包含的空洞特徵一致，再以紋理特徵進行分類。這空洞按其大小大致分成三
類如下：
1. 空洞面積很大，約佔影像的1/9，可能的組織為：
·正常腺體
·血管
·尿道
·切片在製作過程中，因為人為因素所產生的白色空洞。
·前列腺被膜
2. 空洞面積較小，約佔影像的1/ 16，可能的組織為：
·分級3或4
·血管
·脂肪
·間質組織
·切片在製作過程中，因為風乾等過程所產生的白色空洞。
3. 幾乎沒有空洞或非常的小。，可能的組織為：
·間質組織
·分級4和5
·發炎細胞
·神經結
針對以上，我們將整個分析分成幾個主要的步驟：
步驟一：針對切片中的大空洞區域辨識出正常的前列腺腺體
 由於切片中可能會出現各種可能的組織或現象，直接以紋理技術分析是無法奏效的，
尤其切片中常出現的白色空洞，大小形狀差異很大，很容易干擾最後的分析結果，所以我們
必須先處理這一部份，而空洞面積的大小會影響判斷的策略，因此第一步驟主要針對較大面
積的空洞，主要必須先辨識出正常腺體，因為正常腺體的腔體面積很大，在使用紋理辨識技
術時是一個很大障礙，然而切片在製作過程中，因為風乾等過程致使切片影像會出現類似正
常前列腺腔體的白色空洞。此外，有些血管也會和腺體形態相似。所以第一個步驟是將所有
疑似腔體的空洞找出來，進行區分。如圖二a左方是正常的腺體，而右方則是血管。從圖中
3仍可以看出一個個的腺體，他們仍是分開的，而分級4則無明顯的腺體存在，在低倍率的鏡
頭下呈現篩板狀，所以他們周圍細胞的分布對兩者的區分是很重要的。而圖四c和d的空洞則
必須將他忽略掉，圖四d的空洞是脂肪，明顯的，周圍並無細胞的存在，其空洞是可以忽略
掉的。而圖四c則比較複雜，不太容易由周圍的細胞來和分級4區分，而因為他是風乾萎縮造
成，通常成平滑的圓形或橢圓形。 但是他的其餘區域就有可能是間質組織或分級4或5，所
以圖四b和c是不太容易直接區分的，必須先辨識出風乾萎縮造成的空洞，再以細胞的紋理來
辨識分級3和4。
  (a) Grade 3                  (b) Grade 4   
  (c) Hole                         (d) Fat 
 圖四 一些較小空洞的切片影像
步驟三： 這個階段的影像完全無空洞或空洞非常的小，主要會是間質、分級4和5以及神經
結等等，如圖五。所以，這個步驟可以完全以紋理特徵來分析。
 
 最後如圖六a為例，影像中包含三個區域，正常前列腺體、分級三的前列腺癌和間質，
使用前述三個步驟分析而得，如圖六b、 c和d所示。如果直接以紋理方法分析整張影像，則
結果會非常的不穩定，而且三個區域的辨識特徵各自不同，很容易產生不正確的結果。
V. 結果與討論（含結論與建議）
 
 本計畫共取得台中榮總95~97年的病理全量切片兩百多例，因染色退化等原因篩選後
共173例，經過前述的分析轉成二維模型，在前列腫瘤方面可以百分之百被偵測出來，然而
分級會有5%的錯誤率，主要錯誤發生在於兩個方面，第一，分級三的腺體若遭到癌細胞影
響，無法形成單一腺體的形態，會診斷為分級四，然而這個界限仍是非常的模糊，我們所採
用的黃金標準是醫師所提供，但醫師仍認可我們分級結果仍是有可能的也就是介於分級三和
四之間。第二，發炎細胞的干擾，如圖六，有些應該是分級四，然而因為發炎的關係，使得
形態和分級五非常的相似，造成診斷上的困難。醫師分辨的依據是在400倍的鏡頭下觀察其
細胞核和細胞質，可是在無自動取像機器的支援下，400倍的取像作業困難度非常的高，工
作量過於巨大，且在400倍的影像有些分級會因為視野過窄而產生困擾，例如正常的腺體可
能只看到很小的一部分，因此在有自動取像設備的支援下，建議以多解析度的分析來執行這
些作業會得到更正確的結果，同時也符合醫師診斷時的作為，也就是會低倍和高倍的鏡頭交
互切換的來進行分析診斷。
 在二維模型完成後，可以使用如圖六的使用者界面來距離計算、前列腺癌估量和其他
危險因素評估，由這個界面我們可以計算
1. Gleason Grading Score.
2. 分別計算各個分級腫瘤腺體的總量。
3. 所有指定敏感組織和腫瘤腺體的最近距離。
4. 所有指定敏感組織在特定的距離範圍內腫瘤腺體的量及其分級情形。
 
附件二
可供推廣之研發成果資料表
□ 可申請專利　　□ 可技術移轉                                      日期：　年　月　日
國科會補
助計畫
計畫名稱：
計畫主持人：　　　　　　　　
計畫編號：　　　　　　　　　　　　　學門領域：
技術/創作
名稱
發明人/創
作人
技術說明 中文：
（100~500字）
英文：
可利用之
產業
及
可開發之
產品
技術特點
推廣及運
用的價值
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送　貴
單位研發成果推廣單位（如技術移轉中心）。
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
※ 3.本表若不敷使用，請自行影印使用。
The Histological Grading of HCC 
Using Fusion Images
Shao-Kuo Dai and Yen-Chih Wu
Dept. of Information Management
Chaoyang University of Technology
Taichung, Taiwan
{sgdai, s9714601}@cyut.edu.tw
Yee-Jee Jan and Shu-Chuan Lin
Department of Pathology
Taichung Veterans General Hospital
Taichung, Taiwan
{yejan, sara}@vghtc.gov.tw
Abstract—The histological grading of  Hepatocellular 
Carcinoma is essential to prognosis and treatment planning. 
Providing a quantitative analysis by machine vision is 
desired for a determination of  the grading result. However, 
the cells on the biopsy are not all in the some depth of  focus 
under the microscope. Some cells in the images captured by 
machine may become a blur with a small variance of  focus. 
These cells may not be segmented from images or segmented 
into  a undesized shape and thus affect the grading results. 
Consequently, an “all-in-focus image” is very useful to the 
grading of Hepatocellular Carcinoma performed by the 
machine. In this paper, we proposed an image fusion 
approach based on the wavelet-based focus measure to fuse 
two images with different depth of focus into one image, 
which contains much more in-depth focus cells. In our 
experiments, we demonstrated that the fused images not only 
provide clear appearance of cells but also higher accuracy of 
grading than original images.
Keywords: HCC biopsy image; image fusion; HCC 
grading;  focus measure.
I.  INTRODUCTION 
Hepatocellular Carcinoma (or HCC) is one of major 
health problems in the world [1]. The prognosis and 
medical treatments are various for different grading of 
HCC so that accurate pathological discrimination among 
different grades of HCC becomes very important. 
However, pathological analysis of tissue is time-consuming 
and requires correct visual interpretation for microscopic 
images. Therefore, computer-based analysis for 
microscopic images is highly desired to provide 
quantitative,  more objective and consistent results for 
assisting pathologists to improve prognosis and treatment 
planning.
Many methods for analyzing pathological images have 
been proposed during the last few years. Beil et al. [2] 
proposed a dual approach to structural texture analysis for 
microscopic cell images. Thiran and Macq [3] presented an 
automatic recognition method based on shape and size 
analysis for the observed cells in cancerous tissues. A 
Biopsy Analysis Support System (BASS) was introduced 
by Schnorrenberg et al. [4] to detect the nuclei of breast 
cancer based on staining intensity and the number of 
stained nuclei.  Esgiar et al. [5] developed an algorithm to 
identify cancerous colon mucosa using six texture features. 
Weyn et al. [6] developed a computer assisted differential 
diagnosis system. A computerized method for grading 
prostate biopsy images was also reported in [7][8], which 
employed multi-wavelet transform and co-occurrence 
matrices for feature extraction to analyze the entire image 
instead of individual cells. 
However, slight variance of focus can blur the shape of 
cells under the high resolution of microscope. No way to 
promise that cells in the slide are all in the some proper 
focus depth. Therefore, images captured with one depth of 
focus may loss some information which is important for 
diagnosis. Besides, defocused cells with blurred shape 
could affect the efficiency of segmentation algorithm. In 
this paper, we proposed a fusion method based on wavelet 
decomposition to fuse two different focus images into one 
clear image. The comparison of the grading results 
between fused and original HCC images are performed.
II. IMAGE FUSION
In this study, every image was obtained by the same 
processing and acquisition method. Tissue was embedded 
in paraffin cubes after chemical processing and then cut 
into thin sections. These sections were placed on glass 
slides and stained with colored dyes such as Hematoxylin 
and Eosin. The images were acquired by a set of 
equipments including a digital camera of model DP71 
produced Olympus Inc., and an image acquisition 
computer system. Each scope was captured twice with 
different focus under microscope with magnifying factor of 
400. These images were analyzed by an experienced 
pathologist and classified into five grades (0 to 4) in 
advance for later comparison. 
  
Figure 1. (a) and (b) are two different focus images. (c) The fused 
image.
Fig. 1(a) and 1(b) is the HCC biopsy image with same 
scope but different focus.  In both images, there are some 
defocused cells which with blurred shape. These could 
reduce the performance of segmentation and classification. 
But it can be improved by fusing these two images 
according to their degree of focus, as showed in Fig. 1(c). 
There are two kinds of focus measure, spatial domain focus 
measure and frequency domain focus measure. Sum-
modified-Laplacian (SML) [9] can provide better 
performance than other spatial domain focus measures 
[10]. Fused image is composed by the pixels which are the 
maximum SML value of two original images. However, 
methods in the spatial domain are always suffered from the 
mosaiclike problem which should be avoided in this 
表 Y04
Criteria 4: Nuclear Size.
Nuclear size is represented by the area of nuclear.
Criteria 5: Anisonucleosis.
The Standard deviation of nuclear size and Difference of 
extreme nuclear size are extracted to identifying HCC for 
higher grades.
Criteria 6: Nuclear Texture.
Gray Level Co-occurrence matrices (GLCM) have been 
shown to be useful in texture analysis [19]. We select 
uniformity energy, contrast and homogeneity for nuclear 
texture analysis. 
IV. EXPERIMENT RESULT
Fig. 4 is the examples processed by our method. Each 
row contains a set of same scope of HCC biopsy image. 
First two images of them are captured with different 
focuses; third and fourth are fused by the first two images, 
which with the DWT and SML method respectively. These 
original images, more or less, have same cell faded away. 
But the SML and DWT fused images can reveal these cells 
and increase the accuracy of HCC grading. Besides, fused 
images not only increase the amount of cell for 
classification but also provide clear shape cell which can 
avoid the improper segmented cell and affect the grading 
result. In these two original images, Fig. 4(b) and 4(i), all 
have one blurred cell which cause the segmented cell area 
much larger than others that the value of DENS feature 
will increased and image is misclassified as grade 4. 
Whereas, fused images omit the blurred cells and replace 
with the clear one. Fig. 4(e) and (f) both have cells with 
undesired contour which could confuse the classifier and 
generate an incorrect grading. 
Although SML and DWT method can provide the same 
grading results,  but as showed in Fig. 5, images fused by 
SML method sometimes contain mosaiclike appearance. 
The complicate background is not fit for window-based 
spatial method. The distortion can be sensed easily by 
human vision so it is inappropriate to applied in this 
application domain. We collected 1200 HCC biopsy 
images which are graded by senior pathologist in advance 
for the experiment. Table I is the accuracy of grading by 
SVM where training set is from 50 to 200. The accuracy of 
original image A and B are between 0.81 and 0.87 while 
the accuracy of fused image is above 0.90. Thus we can 
conclude that image fusion produce a better segment and 
higher accuracy of grading. Also the SML-based fusion 
method will have some mosaiclike appearance but they can 
produce almost the same performance of grading.
TABLE I. ACCURACY OF HCC GRADING.
Training 
Set 
Original Image
Image A Image B Image C Image D
50 0.83 0.81 0.90 0.91
100 0.85 0.86 0.91 0.92
150 0.86 0.86 0.93 0.93
200 0.86 0.87 0.94 0.94
V. CONCLUSION
Accurate grading for hepatocellular carcinoma (HCC) in 
biopsy images is important to prognosis and treatment 
planning. Visual grading by human beings is time-
consuming, subjective, and inconsistent while 
computerized HCC analysis for biopsy images is a very 
complex task requiring a lot of appropriate image 
processing steps and experts’  domain knowledge for 
correct justification. In this paper, we adopted image fusion 
technique to improve image quality. Then dual 
morphological reconstruction method is applied to segment 
nuclei from image and fourteen features are extracted. 
Finally, SVM classifier generated the HCC grading 
automatically. The experiment results show that fusion of 
two different focus images can improve the image quality 
and facilitate HCC grading by machine vision.
REFERENCES
[1] American Cancer Society, Cancer Facts & Figures, Atlanta, GA: 
American Cancer Society, 2007.
[2] Michael Beil, Theano Irinopoulou, Jany Vassy, and Gunter Wolf, 
“A Dual Approach to Structural Texture Analysis in Microscopic 
Cell Images,” Computer Methods and Programs in Biomedicine, 
vol. 48, no. 3, pp. 211–219, May 1995.
[3] Jean-Philippe Thiran and Benoit Macq, “Morphological Feature 
Extraction for the Classification of Digital Images of Cancerous 
Tissues,” IEEE Transactions on Biomedical Engineering, vol. 43, 
no. 10, pp. 1011–1020, December 1996.
[4] Frank Schnorrenberg, Constantinos S. Pattichis, Kyriacos C. 
Kyriacou, and Christos N. Schizas, “Computer-Aided Detection of 
Breast Cancer Nuclei,” IEEE Transactions on Information 
Technology in Biomedicine, vol. 1, no. 2, pp. 128–140, June 1997.
[5] Nasser Esgiar, A., Naguib, R.N.G., Sharif, B.S., Bennett, M.K., 
Murray, A., “Microscopic Image Analysis for Quantitative 
Measurement and Feature Identification of Normal and Cancerous 
Colonic Mucosa,” IEEE Transactions on Information Technology 
in Biomedicine, vol. 2, no. 3, pp. 197–203, December 1998.
[6] Barbara Weyn et al., “Computer-Assisted Differential Diagnosis of 
Malignant Mesothelioma Based on Syntactic Structure Analysis,” 
Cytometry, vol. 35, no. 1, pp. 23–29, January 1999.
[7] Kourosh Jafari-Khouzani and Hamid Soltanian-Zadeh, 
“Multiwavelet Grading of Pathological Images of Prostate,” IEEE 
Transactions on Biomedical Engineering, vol. 50, no. 6, pp. 697–
704, June 2003.
[8] Y. Zhu, S. Williams, and R. Zwiggelaar, “Computer technology in 
detection and staging of prostate carcinoma: A review,” Medical 
Image Analysis, vol. 10, pp. 178–199, April 2006.
[9] Nayar, S.K., Nakagawa, Y., “Shape from focus,” IEEE Transactions 
on Pattern Analysis and Machine Intelligence, vol. 16, no. 8, pp. 
824–831,  August 1994.
[10] Wei Huang and Zhongliang Jing, “Evaluation of focus measures in 
multi-focus image fusion,” Pattern Recognition Letters, vol. 28, pp. 
493–500, March 2007.
[11] Jaroslav Kautsky, Jan Flusser, Barbara Zitova, and Stanislava 
SSimberov, “A new wavelet-based measure of image focus,” 
Pattern Recognition Letters, vol. 23, pp. 1785–1794, December 
2002.
[12] Kamal G. Ishak, Zachary D. Goodman, and J. Thomas Stocker, 
“Tumors of the Liver and Intrahepatic Bile Ducts,” Washington 
DC: Armed Forces Institute of Pathology, 2001. 
[13] Chih-Chung Chang and Chih-Jen Lin, “LIBSVM: A Library for 
Support Vector Machines,” Software available at http://
www.csie.ntu.edu.tw/~cjlin/libsvm, 2001.
[14] Vincent Luc, “Morphological Grayscale Reconstruction in Image 
Analysis: Applications and Efficient Algorithms,” IEEE 
Transactions on Image Processing, vol. 2, no. 2, pp. 176–201, April 
1993.
[15] Jos B.T.M. Roerdink and Arnold Meijster, “The Watershed 
Transform: Definitions, Algorithms and Parallelization Strategies,” 
Fundamenta Informaticae, vol. 41, no. 1, pp. 187–228, January 
2000.
[16] Murk J. Bottema, “Circularity of Objects in Images,” The 2000 
IEEE International Conference on Acoustics, Speech, and Signal 
Processing, vol. 6, pp. 2247–2250, June 2000.
[17] Hannu Kauppinen, Tapio Seppanen, and Matti Pietikainen, “An 
Experimental Comparison of Autoregressive and Fourier-Based 
Descriptors in 2D Shape Classification,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, vol. 17, no. 2, pp. 201–
207, February 1995.
表 Y04
