  1 
 
行政院國家科學委員會專題研究計畫成果報告 
探討多執行緒之 MPI 叢集電腦於液膜潤滑分析之計算性能 
Performance evaluation of multi-threaded MPI cluster computer on  
fluid-film lubrication analysis  
計畫編號：NSC 93-2212-E-182-003 
執行期限：95 年 8 月 1 日至 96 年 7 月 31 日 
主持人：王能治   長庚大學 機械工程學系 
 
摘要     
本研究探討一個新的平行計算平台，即 Cluster OpenMP (CLOMP)，以進行分散式平行
計算，並以氣體軸承的多目標最佳化為應用範例。原始設計的 OpenMP 語法為跨平台的共享
記憶體架構之平行計算語法，採取多執行緒之方式進行，目前適用於 C/C++和 Fortran 程
式語言。新發展的 CLOMP 保留 OpenMP 的特色，如以指令為基礎的語法、有利於除錯的漸近
式應用及容易程式的序列化執行機制。本研究採用 4台單處理器/雙核心之電腦來組成計算
叢集，並與一台雙處理/雙核心之電腦器進行平行計算性能比較，即比較在液膜潤滑計算中
之共享與分散式記憶體架構訊息溝通的瓶頸大小。在研究中以多種不同工作量大小的計算
進行氣體軸承最佳化的測試。本研究發現 CLOMP 能取代 MPI 處理多執行緒之平行計算，而
訊息溝通的瓶頸只受限於硬體，與計算平台及語法關係不大。而同一個液膜潤滑的程式可
以在 CLOMP 與 OpenMP 之平台上執行，對於中等或大的工作量均能獲得高的平行效率，本研
究證實 CLOMP 適合以多執行緒之叢集電腦進行液膜潤滑的高性能計算。 
關鍵字 
    平行計算、基因演算法、最佳化、液膜潤滑 
 
Abstract 
This study presents a performance evaluation of a new portable parallel programming 
paradigm, the Cluster OpenMP (CLOMP) for distributed computing, in solving an illustrated 
example of multi-objective optimization of air bearings. The OpenMP application program 
interface is designed to support multi-platform shared-memory parallel programming in C/C++ 
and Fortran executed in multi-threaded format. The CLOMP retains the characteristics of the 
directive-based OpenMP, such as incremental programming for effortless-debugging, and 
serial-coding compatibility for easy-implementation. In this study the performance of a CLOMP 
cluster of four dual-core computers is examined. A reference computer equipped with two 
dual-core processors was used to compare the overhead of the computing in this shared-memory 
processing (SMP) machine with the cluster. Several multithreaded applications of various task 
sizes for air-bearing optimization were tested. It was found that the multi-threaded application of 
CLOMP can replace MPI in many engineering applications with similar performance bounded by 
communication hardware. Except the differences in computing environment, the source program 
for air bearing performance computing was compiled and executed without modification in the 
SMP system and the CLOMP cluster. It is shown that both the medium- to large-grain tasks can 
be effectively dealt with by using the CLOMP. The verified high speedup and low overhead of 
the multi-thread CLOMP cluster demonstrate the potential application of the CLOMP for 
tribological computation.  
 
KEY WORDS 
 parallel computing, genetic algorithm, optimization, fluid-film lubrication 
  3 
 
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂
=∂
∂+∂
∂
otherwise
regionmaterialporousin
z
pk
h
y
p
x
p
p
0
ˆ
ˆ12 2
3
2
22
2
22
   (1) 
0
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
2
22
2
22
2
22
=∂
∂+∂
∂+∂
∂
z
p
y
p
x
p
     (2) 
 
where p  and pˆ  are the air pressure in the film and porous material, respectively; yx,  and 
zyx ˆ,ˆ,ˆ  are the coordinates for the film and porous material, respectively; h  is the film 
thickness; and pk  is the permeability coefficient of the porous material. In the porous pad and 
air film interface ),( yxp  equals )0,ˆ,ˆ(ˆ yxp . 
Each side of the square bearing pad has a length of 100 mm. The ranges selected for the 
variables are 200 to 600 kPa for supply air pressure, 5 to 15 mm for porous material width, 5 to 
25 mm for porous material to pad edge distance, and 2 to 10
21510 m−× for the permeability of 
porous material. In the analysis, the film thickness of the porous air bearing is 10 mμ  and the 
thickness of the porous material is 5 mm. 
 
3. Multi-objective Optimization 
Since the pressure distribution of the air film is a function of aforementioned four design 
variables, the goal of this study is to find an optimum setting of these variables with high 
confidence to satisfy multiple objectives simultaneously. In this study the two nonlinear 
objectives were to maximize the bearing stiffness ( )k  while minimizing the air mass flow ( )m&  
to the bearing. The optimization analysis is conducted by use of a genetic algorithm (GA). 
Single-point crossover is used with crossover probability being one. Each of the four design 
variables is decoded in 12 binary bits and the bit mutation probability is 1.0%. The Pareto 
criterion [Deb, 2001; Wang and Chang, 2004] is used in this multi-objective optimization study. 
In this study the GA was allowed to evolve to 60th generation with the population size of 64.  
In the multi-objective problem of this study, the rank of a member is based on the Pareto 
optimality [Wang, 2005]. In the ranking process, the first rank is determined from the first set of 
Pareto points. The points of second rank are then determined using the same criterion after the 
points of the first rank are removed. The process is continued until all the points are ranked in a 
generation. The chance of a point being selected in the mating group to produce offspring is 
inversely proportional to its rank number. The same concept and approach can be applied with 
little modification to the optimization problems with more than two objectives. 
For multi-objective problems, the process may not be trivial. First of all, an ideal set of 
weighting factors for the objectives is not easy to determine. In addition, a preset combined 
objective may restrict the understanding of the whole objective function space (criterion space) of 
a problem. In the context of Pareto optimality (to be introduced in the later of this section), the 
dominated designs are the points in the criterion space that are inferior to at least one other point 
for the prescribed objectives. For those designs are not dominated by any other designs in the 
criterion space are the optimal designs in a multi-objective optimization. The visualization of a 
two-dimensional criterion space (objective function space) can be useful for the understanding of 
the Pareto optimality.  
 
5. The Cluster OpenMP 
OpenMP is a well-known parallel programming paradigm for shared-memory 
multiprocessors. In the past, OpenMP has been confined to Symmetric Multi-Processing (SMP) 
machines and teamed with Message Passing Interface (MPI) technology to make use of multiple 
SMP systems. A new system, Cluster OpenMP, is an implementation of OpenMP that can make 
  5 
 
in Table 1. The cluster consists of four dual-core computers. Therefore the maximum number of 
available computing cores can be executed at once is eight. Configuring a cluster for the purpose 
of using CLOMP involving making a few decisions about how the cluster will be administrated 
and how it fits in with the computing environment. One node of the cluster is distinguished as the 
head node. The other nodes of the cluster are referred to as the compute nodes. 
The nodes in the cluster have identical configuration and one of them was used to act as the head 
node to execute the multithreaded programs. The computer program was coded as an OpenMP 
program and then tested as a multithread application in the head node. Then the program was 
compiled as a CLOMP execution code which can use up to the eight computing cores 
simultaneously in the current setup. The performance of the cluster is determined by the speedup, 
the CPU time required in single thread computation divided by the CPU time required in 
multithread computation. 
A reference computer (Table 2) with two dual-core processors was used in this study to 
compare the overhead of OpenMP computing in SMP with CLOMP. Except the differences in the 
computing environment, the source program was compiled and executed without modification in 
the SMP system and the CLOMP cluster.. The expected performance is better due to lower 
communication overhead. To compile a ported OpenMP program for use with CLOMP, only a 
compiler option is required. This option produces an executable code of a CLOMP program. The 
user’s guide of CLOMP [www.intel.com] gives detail description of configuring a cluster and 
porting a code works correctly with OpenMP to a CLOMP program if the aforementioned 
compiler option fails to identify the variables that must made sharable.  
 
6. Results 
Figure 2 shows the CPU times of the air bearing optimization using CLOMP with four and 
eight computing-thread, respectively. The calculation of objective functions is divided equally 
among the available computing-core specified by the CLOMP. Since the convergent rate for each 
objective function calculation is different the CPU time of each thread in one generation varies. 
For example in the case of eight-thread computing the average CPU time for a core to execute 
eight tasks is about 34 s. Therefore, a task requires roughly 4.25 (= 34/8) s to be completed. 
However, when the size of the numerical-grid is small (e.g., 50) the average CPU time for a 
thread execution is only about 0.47 s. In this study load balancing is not considered by which in 
some cases may improve the cluster performance.  
To examine the performance of the CLOMP in the current setup three sizes of computing 
task were tested. The task size was varied by changing the numerical-grid in the numerical model 
(Figure 3). For different numerical-grid the relaxation factors for solving Reynolds equations and 
Darcy’s law are optimized for execution time. Note that in each optimization case a total of 3,840 
computing threads are to be executed. Figure 4 shows the percentage of overhead in the 
computation using various computing threads (GA of 60-generation with 64-member). For the 
same computing-thread case various execution times were obtained by different numerical grids. 
Figures 5 and 6 show the overhead times and speedups of the multithread computation of 
various numerical-grid sizes, respectively. The overhead is obtained by subtracting the CPU time 
from the elapsed time in one computation. The overhead is mainly due to network 
communication and the time for threading fork-join processes. The resulted high speedups and 
low overheads demonstrate the excellent performance of the cluster using CLOMP as a 
distributed computing tool.  
The criterion space of the GA’s 1st generation of 64 members is shown in Figure 7. The 
ranking of the Pareto curves for offspring selection is marked in the graph. Figure 8 shows the 
Pareto curves of the 60th generation of the two-objective GA optimization. The min-max 
criterion [10] can be used to determine the ideal Pareto point from the last design. 
 
7. Discussion 
The GAs are naturally suitable for parallel computing as well as for multi-objective 
optimization. The bottleneck of the GA in search of optimum is the calculation of the fitness 
functions. In this study the two objective functions can be easily obtained when the numerical 
  7 
 
 
Table 1 The setup of the 4-node CLOMP cluster. 
OS Redhat Enterprise Linux WS3  (for EM64T or AMD64) 
Language Fortran 95 
Compiler Intel Fortran Compiler for Linux v9.1 Software
Clustering Software 
Intel Cluster OpenMP for Linux 
(require 64-bit supporting 
environment) 
Computing-node HP dc7600 
Processor Pentium-D 820 2.8 GHz (dual core) 
RAM 2 GB Hardware 
Networking 1 Gbps Ethernet 
 
 
Table 2 The setup of the reference SMP machine. 
OS Microsoft Windows XP 64-bit   
Language Fortran 95 Software
Compiler Intel Fortran Compiler for Windows v9.1 
Computing-node Asus PC 
Processor AMD dual -processor (dual core) Hardware 
RAM 2 GB 
 
 
 
 
 
 
 
 
 
 
Figure 1. The schematic diagram of the 4-porous-pad air thrust bearing. The air bearing is square 
shape and each porous-pad is located symmetrically about the geometric center. 
 
 
 
100 mm 
Porous Material 
LBLB
LL
  9 
 
 
50 100 150
0
20
40
60
80
O
ve
rh
ea
d 
Ti
m
e 
(s
)
Numerical-Grid Size
Number of Simultaneous 
Computing-Thread
 1-thread (for reference)
 4-thread
 8-thread
 
Figure 5. The overhead times of the multithread tasks of various numerical-grid sizes (GA of 
60-generation with 64-member). 
50 100 150
3.5
4.0
4.5
7.0
7.5
8.0
 
S
pe
ed
up
Computing-Grid Size
 8-thread computing
 4-thread computing
 
Figure 6. The speedups of the multithread tasks of various numerical-grid sizes (GA of 
60-generation with 64-member). 
0.0 0.2 0.4 0.6 0.8 1.0
0.00
0.20
0.40
0.60
0.80
1.00
 
 
N
or
m
al
iz
ed
 A
ir 
M
as
s 
Fl
ow
Normalized Air Bearing Stiffness
Pareto Curves
 1st Rank
 2nd Rank
 3rd Rank
 4th Rank
 5th Rank
 6th Rank
 7th Rank
 8th Rank
 
Figure 7. The criterion space and Pareto curves of the first generation of the optimization. 
 1
美國磨潤工程師學會2007年會 
2007 STLE 62nd Annual Meeting & Exhibition 
Philadelphia, PA, USA 
2007/5/6 - 2007/5/10 
 
長庚大學 機械系 王能治 
 
參加會議經過 
    2007年美國磨潤工程師學會（Society of Tribologists and Lubrication 
Engineers, STLE）之年度會議於5月6日至10日在美國費城的Marriott Hotel
舉行。此會議為美國磨潤工程師學會的年度會議，今年會議參與的人數、
論文發表數及系列的工程課程為例年僅見的規模。5月份的STLE年會和每年
10月份舉辦的國際磨潤學研討會（International Joint Tribology Conference，
由STLE及American Society of Mechanical Engineers -Tribology division共同
主辦）比較，此年度會議，不僅參與的人數眾多，而且有多家的磨潤相關
的廠商參與攤位的展出，會場活動較多且熱鬧。此次會議期間論文均以口
頭發表的方式進行，另外亦有多場的討論會（Panel Discussion）及收費之教
育課程，在會期中論文發表同時在多個會議廳舉行，共有400篇的論文以口
頭發表，每篇論文發表及討論的時間為30分鐘，大會統計約有1,200與會者
參加論文發表會議、短期教育課程、大會展覽等活動。 
由於此次大會在賓卅費城舉行，在費城的STLE分會的大力協助下，大
會得以順利的舉城。今年的大會演講（Keynote session）由Said Jahanmir博
士（Mohawk Innovative Technology & MiHiHeart Corp.）在5月7日星期一上
午主講，講題為仿生時代（Bionic Age），主要內容為磨潤學於未來的生物
科技、仿生工程上之應用及其重要性。星期一晚上為接待晚宴，亦由費城
分會主辦。本次會議的另一焦點為5月8日中午舉行的STLE會長午餐大會，
