1  
一、前言 
 
近年來，由於資訊硬體技術的快速進步特別是網路頻寬的提升與通訊技術的發
展，促使一種連續性的資料收集的方式稱之為資料串流(Data Streams)，普遍地應用在
各種領域，例如感測網路、網路流量監控及入侵偵測、交通流量監控、股市型情分析、
環境品質監控、天然災害偵測、預警網站日誌分析等[BBD02, GO03, GZK05]。沿襲傳統
資料探勘的研究領域，目前的資料串流探勘研究大致上也可分歸納為幾個主要方向
[Agg07, GZK05]：資料分群(Clustering)、資料分類(Classification)、預測(Forecasting)、
樣式探勘(Pattern Mining)等，其中樣式探勘的研究一如其在傳統資料探勘領域的狀況，
是最多學者研究探討的問題。 
然而近年來許多研究發現[SON98, TKS00, TK01, THC02]，那些出現頻率較低的樣
式(即非頻繁樣式)若具有某些特質(如負相關)，同樣具有極高的參考價值，因其能反映
資料來源中某些隱藏但值得重視的現象。不過要從一堆資料中找出具負關聯的非頻繁樣
式卻是極具挑戰性的工作，其最大的困難在於非頻繁樣式的數目遠超過頻繁項目集的數
目，其意味著探勘方法將需要更多的記憶體空間與花費的更多的計算時間，另外一個問
題則是如何避免產生過多無價值的樣式。過去幾年雖然有不少學者提出可探勘負關聯樣
式及規則的方法[AZ04, CPX+06, SON98, TW04, WZZ04]，不過仍然無法避免上述問題。 
Tan 等[TKS00]於 2000 年提出來的一種新的非頻繁樣式關係，稱之為間接關聯，對
於非頻繁樣式的探勘提供另一個思考的模式，可有效減少非頻繁樣式過多且大多是無意
義的樣式的問題。其概念是藉由一組稱之為“中介子(Mediator)”的頻繁樣式的聯繫，將一
組出現頻率較低的項目關聯起來。利用此概念，可自資料庫中探索出有價值的“非頻繁
項目對＂(infrequent itempairs)。此種非頻繁樣式已證實可廣泛應用在許多不同的應用
上，如電子商務網站的經營，商品的定價策略，文件的探勘，以及生物資訊等 [TKS00, 
TK01, KK05, KM05, 曾劉辛 07]。可惜的是截至目前為止，這些研究成果都是考慮傳統
的資料集合，對於近來應用廣泛的資料串流環境，仍未見有研究進行探討。其原因可能
一方面資料串流探勘的是較新的研究議題，其所要求的探勘方法特性遠多於傳統的探勘
方法，另一方面也是因間接關聯問題的難度遠高於頻繁樣式的探勘，除了頻繁項目集外
(中介子的部分)，還須考慮非頻繁項目集(項目對部分)。 
另外一方面，目前關於資料串流探勘方法，特別是樣式探勘的研究皆是針對特定的
串流式窗模式，如所謂的標界視窗模式、遞減視窗模式、滑動視窗模式等，發展有效的
探勘方法。此種作法雖然可以針對各個模式量身訂做特別有效的演算方法，但是若面臨
的問題無法套入既定的視窗模式，則須再特別設計新的演算法。再者，當我們要發展可
適用各種視窗模式的串流探勘系統時，更須要能提供彈性、可依據使用者需求設定符合
的視窗模式，並能快速產生符合的型樣，在此種狀況下，很難對各種可能的視窗模式都
發展特定的演算方法。 
 
二、研究目的 
 
本計畫的主要目的是研究如何在資料串流中探勘具間接關聯的非頻繁樣式。除了探
究在目前幾種主要的資料串流視窗模式下，包括標界視窗模式、遞減視窗模式、及滑動
視窗模式，如何設計有效率的間接關聯的探勘方法外，我們更希望能發展一個通用的探
勘系統架構，能夠將目前的幾種視窗模式整合在一個通用的視窗模式，並且具資源感知
能力，有可以根據 CPU 的工作負荷與資料到達的速度，調整資料的處理量。此外，在
此架構下，我們希望能發展一個通用的探勘方法，能配合通用的視窗模式，有效率的找
出間接關聯，並保證其品質。 
 
 
遞減視窗模式是加入權重的概念，對於離目前時間愈近的資料給予愈高的權重，且
各資料的權重隨著時間的增加而逐漸降低，藉此模擬現實世界的常態資料的價值隨歲
月消逝而逐漸式微。此種模式又有些不同的做法。一種較簡單的做法是設定一個權重遞
減率(decay rate)[CL03a]，每當有新資料到達時便用此遞減率更新舊資料的權重，如圖 2
所示。另一種做法是設定幾個不同時間尺度的視窗[GHP+03]，例如將最近一個月的資料
分為30天+23小時+4刻的尺度組合，此種方法又稱為傾斜時間視窗(Tilted-time window)。 
 
3  
 
圖 2：遞減視窗模式示意圖 
 
3.2.3 滑動視窗模式 
 
滑動視窗模式是指以現在的時間點為基準設定一個固定長度的視窗，對此視窗內的
資料進行探勘，隨著新資料的到來而自視窗中移除舊的資料，以保持視窗的長度。其運
作模式如圖 3 所示。 
 
 
tj
timet0 t1 t2 ti

W1
tj+1 tj+2
W2
W3 
 
圖 3：滑動視窗模式示意圖 
 
此種視窗模式尚可分為兩種類型：交易感知滑動視窗(transaction-sensitive sliding 
window)與時間感知滑動視窗(time-sensitive sliding window)[LCW+05]。前者是固定視窗
範圍內的資料量，例如固定十筆資料為視窗長度，後者則是固定視窗所涵蓋的時間範
圍，例如以每小時的交易量當做視窗長度。 
 
3.3 資料串流中頻繁樣式探勘方法 
此問題是一個廣為矚目的研究問題，短短幾年間國內外已有不少的文獻發表。爲能
清楚地比較這些研究的差別，在此我們從三個不同的面向來說明這些研究：(1)資料串流
的視窗模式，分為標界視窗模式(LW)、遞減視窗模式(DW)、以及滑動視窗模式(SW)；
(2)採掘的樣式類型，分為頻繁項目集(Frequent itemset, 簡稱 FI)、最大頻繁項目集
(Maximal Frequent Itemset, 簡稱 MFI)、以及封閉頻繁項目集(Closed Frequent Itemset, 簡
稱 CFI)；以及(3)探勘結果的精確性，可分為精確解以及近似解。這些方法的分析比較
整理在表 1。 
從採用的視窗模式來區分，Manku 及 Motwani [MM02]所提出的 Lossy counting 演
算法是最早考慮在標界視窗模式下的頻繁樣式探勘方法；之後則有 Li 等 [LLS04a]、Jin
及 Agrawal [JA05]、Yu 等 [YCL04+, YCL+06]提出新的方法。在遞減視窗模式方面，則
有Chang及Lee [CL03a]提出採用權重遞減率的 estDec演算法，以及Giannella等[GHP+03]
提出採用傾斜時間視窗模式的 FP-stream 演算法。Lee 及 Lee [LL05]則以 estDec 方法為
tj timet0 t1 
Wk
tj+1ti tj
Wk+1
d 

ti+1
d 
tj1 
dji　 Weight:
d2dji+1 Weight:
5  
基本上是一較直覺的兩階段方法。大致可描述如下： 
 
步驟 1：首先第一階段利用任何一種的頻繁項目集方法如Apriori 或FP-growth產生所有
支持度大於tf的頻繁項目集； 
步驟 2：執行下列步驟產生所有的間接關聯 
2.1：運用類似 Apriori 方法的模式，反覆由第一階段產生的長度為 k 的頻繁項目集合 Fk
經由合併產生長度 k + 1 的候選間接關聯集合。例如若{a∪M}與{b∪M}同時屬於
Fk，則可合併為一可能的間接關聯a, b | M 。 
2.2：檢查並去除不符合項目對支持度條件、中界子支持度條件、中界子相依度條件的候
選間接關聯。  
 
INDIRECT 方法的主要缺點是必須先產生所有的頻繁項目集，而後再執行合併動作
產生候選間接關聯再進行篩選。此一過程通常需要相當多的計算時間。有鑑於此，Wan
及 An [WA03, WA06a]提出一改進的方法稱為 HI-mine。其基本概念是先找出所有的間接
項目對 IIS (Indirect Itempair Set)  
IIS = {a, b|{a}, {b}F1  sup({a})  tf  sup({a})  tf  sup({a, b}) < ts} 
對每一個在 IIS 中的間接項目對a, b，分別找出其各自的支持的中介子集合(Mediator 
Support Set) MSS(a)及 MSS(b) 
MSS(x) = {M|MF  sup({a}∪M})  tf  dep({a}, M)  td } 
則所有可使a, b成為間接關聯的中介子即存在於 MSS(a)∩MSS(b)的集合中。 
基於上述原理，HI-mine 方法利用一個改良自 H-mine 結構[PHL+01]的資料投影結
構，稱為 HI-struct，以各個擊破的方式，遞迴地在 HI-struct 結構上找出所有的間接關聯。 
雖然實驗證明 HI-mine 在各方面都遠優於 INDIRECT 方法，但 HI-mine 仍有二個主
要缺點：需要掃描資料庫兩次，另外所建構的 HI-struct 較佔記憶體空間，較容易產生記
憶體不足的現象。故 Wan 及 An [WA06b]隨後又提出改良的版本，稱為 HI-mine*，其與
HI-mine 最大的差別是先將原始資料庫轉成一個作者所提出的超級壓縮資料庫(Super 
Compact Transaction Database, SCTD)格式，在利用此壓縮資料庫進行 HI-struct 的建構與
隨後的探勘工作。實驗顯示 HI-mine*所需的記憶體空間遠較 HI-mine 要少，且速度也快
上許多。不過 HI-mine*必須將原始資料庫先轉換成壓縮資料庫，且必須加以儲存在硬碟
上。 
另外 Chen 等[CBL06]也提出一個探勘間接關聯的演算法，稱為 MG-Growth。此方
法所依據的原理與 HI-mine 類似，先建構間接項目對集合 IIS，後找出各項目的支持中
介子集合 MSS，再找出所有的間接關聯，不過 MG-Growth 是結合有向圖(Directed Graph)
與位元映照(Bitmap) ，稱為頻率圖(Frequency Graph)來建構 IIS，再產生對應 MSS 的中
介子圖(Mediator Graph)來找出符合的間接關聯。此方法只須掃描資料庫一次，實驗顯示
其速度明顯優於 HI-mine。然 MG-Growth 與 HI-mine*孰優孰劣，則有待進一步的分析比
較。上述有關間接關聯探勘方法的比較整理於表 2。 
 
表 2：間接關聯樣式探勘方法之比較分析 
探勘方法 資料庫掃描次數 主要資料結構 
INDIRECT  視採用的頻繁樣式探勘法而定 視採用的頻繁樣式探勘方而定 
HI-mine  2 HI-struct 
HI-mine*  1 SCTD+HI-struct 
MG-Growth  1 Frequency graph＋Mediator Graph 
 
圖 5：AOG 資源感知探勘架構[GZK05b] 
 
1. 只需掃描資料一次 
2. 具有資源感知的能力 
3. 能盡量減少記憶體的使用 
4. 能確保產生的結果的誤差在一定的範圍內 
 
4.1 標界視窗模式之間接關聯探勘演算法  
 
在這個部分，我們發展了兩個演算方法，稱為 MIA-LM (Mining Indirect Association 
over a Landmark Model)以及 EMIA-LM。 
 
4.1.1 MIA-LM 方法 
   
在標界視窗模式下的頻繁樣式探勘最早是 Manku 等人所提出的 Lossy counting 演算
法 [MM02]，是以每次累計遞增的方式來保留過去以往的頻繁項目集。該演算法根據使
用者給定的一個支持度誤差 ε，以一個 bucket 作為單位，想像將資料串流分成N*個
buckets，N 為資料串流中的交易總筆數，即每一個 bucket 含有  ε/1 筆交易，每次將 n
個 buckets 讀取進記憶體中並累計其項目集的次數，之後將每一個項目集的次數減 n，
若某項目集其次數小於或等於 n，表示此項目集在過去極少出現，未來再出現的機率相
對來說比較低，考量到記憶體有限的情況下，故將此項目集刪除，保留其它的項目集。
使用者要查詢頻繁項目集時，假設最小支持度為 s，則輸出支持度大於 s  ε的項目集。
此演算法雖然最後輸出的項目集可能會非常多，但是保證不會遺漏任何頻繁項目集，不
過考慮到有限記憶體的環境下，此演算法可能效果有限。 
在 2004 年，Li 等人進而提出 DSM-FI 演算法[LLS04]，一樣是將資料串流中的交易
切分成若干區段(block)，一次讀取一個區段進記憶體，為了避免窮舉出交易的所有子
集，作者將每筆交易根據每個項目分解成項目字尾交易(item-suffix transaction)，並各自
建立對應的項目字尾樹(item suffix tree)來儲存項目集，並在累計完區段中的項目集後，
把目前小於支持度誤差 ε的項目集刪除，使用者要查詢頻繁項目集時，則輸出目前支持
度大於或等於最小支持度 s 的項目集，此演算法輸出的頻繁項目集雖然無法將所有的頻
繁項目集找出，但保證不會輸出非頻繁項目集。實驗證明其執行時間和記憶體使用量都
比 Lossy counting 好。 
本方法採用改良自 Li 等人所提出的 DSM-FI 演算法來做為整個演算法的主體，並參
7  
.....
Block3
Time
TID1 A,B,D
TID2 B,C,D
TID3 C,D
TID4 B,D,E
TID5 B,D
Block1 Block2
TID6 A,C
TID7   A,D,E
TID8   B,C
TID9   C,D,E
TID10 A,D,E
 
 
圖 6：資料串流範例。 
 
A:4:1
D:4:1
B:5:1 D:8:1 C:5:1
A:4:1 B:4:1 D:8:1 C:5:1
D:3:1
E:4:1
E:4:1
C:1:2 D:2:2
E:2:2
E:3:2C:1:2
E:1:2
21C
22D
Block‐idCountItem
E 2 2
14D
21C
Block‐idCountItem
<{A,C}:1>
candidate IIS
<{itempair}:count>
<{A, B}:1>
<{A,E}:2>
<{B, C}:2>
<{B, E}:1>
<{D, E}:1>
23E
Block‐idCountItem
13D
21E
Block‐idCountItem Block‐idCountItem
FI
-li
st
 
IS
-tr
ee
 
圖 7：經過處理完 Block1 及 Block2 之後的 Candidate IIS 和 ISFI-forest。 
 
考慮由 MIA-LM 產生的項目集 X。令 Tsup(X)代表 X 的真正支持度，Esup(X)代表由
MIA-LM 所得到的支持度。我們證明 Tsup(X)和 Esup(X)的差距必不大於，即 
 )()(0 XEsupXTsup  
 
4.1.2 EMIA-LM 方法 
 
MIA-LM 方法最大的缺點是其資料結構 IS-tree 儲存每個交易產生的項目字尾交
易，需占據較大的記憶體空間。為改善此缺點，我們另外提出 EMIA-LM 演算法，此方
法運用一個類似 HI-mine*[WA06b] 所用的資料結構，可以有效地壓縮資料。以下說明
EMIA-LM 所用的資料結構，其具體格式如圖 8 所示。 
1. CTT (Compact Transactions Table)：交易壓縮表，用以儲存壓縮後的交易資料，
內含四個欄位，Index、Count、Left、Right。我們所用的壓縮方法為，當任兩筆
長度相同的交易資料其內容最多只有最後一個項目不同，則將此兩筆資料壓縮
成一筆，即任兩筆交易資料 a1, a2, … an 及 b1, b2, … , bn，而 a1 = b1, a2 = b2,…, an-1 
= bn-1。Index 為標識欄位，用以區分壓縮後的交易；Count 為紀錄此壓縮交易對
應多少筆原始交易資料；Left 用以儲存相同的部分，即 a1, a2,…, an-1；Right 則
儲存不同的部分，儲存成 an: count，bn: count，count 表項目的出現次數。 
2. HT (Hash Table)：雜湊表，用以儲存 CTT 中每筆壓縮資料的 Left 欄位的雜湊值
做為索引，指到此壓縮資料的位址。 
3. Item-list：項目串列，用以儲存所有的項目(Item)、其出現頻率(Count)及在 CTT
9  
   
HT 
Key Link 
A, B 
B 
 
 
 
1 
2 
 
 
CCT 
Index Count Left Right 
1 
2 
 
 
 
3 
2 
 
A, B 
B 
C:2, E:1 
C:1, D:1 
 
Item-list 
BlockId Item Count Links 
1 
1 
1 
1 
1 
A 
B 
C 
D 
E 
3 
5 
3 
1 
1 
1 
2 
1,2 
2 
1  
圖 10：處理完 Block1 之後的 CCT，HT 及 Item-list 的內容。 
 
   
HT 
Key Link 
A,B 
B 
C 
A 
B,C 
 
1 
2 
3 
4 
5 
 
CCT 
Index Count Left Right 
1 
2 
3 
4 
5 
 
3 
3 
1 
1 
1 
A,B 
B 
C 
A 
B,C 
C:2,E:1 
C:2,D:1 
E:1 
F:1 
F:1 
 
Item-list 
BlockId Item Count Links 
1 
1 
1 
1 
1 
2 
A 
B 
C 
D 
E 
F 
5 
7 
6 
1 
2 
2 
1,4 
2,5 
1,2,3,5
2 
1,3 
4,5  
圖 11：處理完 Block2 之後的 CCT，HT 及 Item-list 的內容。 
 
接下來假設使用者於此時提出查詢需求，故執行步驟 5。首先自 Item-list 及 CTT 中
刪除非頻繁項目，此例為 E 及 F，因其次數小於 3，結果如圖 11 中加上雙刪除線的部分；
然後產生 MSS-list 及 IIS-list。我們作法的概念為對在 Item-list 中的每個項目依序產生其
對應的投影表(Projection table)，即在 CCT 表中以此項目開頭的壓縮資料。以項目 A 為
例，其對應的 CCT 投影表如圖 12 所示。然後由 A 對應的 CCT 投影表，產生所有可能
的 MSS 及 IIS，將之加入 MSS-list 及 IIS-list。此例，AB 的支持度為 3/10 = 0.3  tf，且 IS(A, 
B) = 3/(57)1/2 = 0.51 > td，故 B 可當作 A 的中介子，故將 B 加入 MSS(A)；另外，AC 的
支持度為 2/10 < ts，可形成一可能的 IIS，故將 AC 加入 IIS-list 中。 
 
CCT 
Index Count Left Right 
1 
4 
3 
1 
A,B 
A 
C:2 
圖 12：項目 A 對應的 CCT 投影表 
 
如同 MIA-LM，我們同樣證明對任何由 EMIA-LM 產生的項目集 X，其 Tsup(X)和
Esup(X)的差距必不大於，即 
 )()(0 XEsupXTsup  
 
4.2 通用型間接關聯探勘系統架構及演算法 
 
在這一節中，我們將說明我們所發展的通用的間接關聯探勘系統架構，包括通用的
視窗模式與通用的探勘架構及探勘方法。 
 
4.2.1 通用串流視窗模式 
 
過去關於串流樣式探勘方法的研究皆是針對特定的串流式窗模式發展有效的探勘
方法，如表 1 所示。此種作法雖然可以針對各個模式量身訂做特別有效的演算方法，但
是若面臨的問題無法套入既定的視窗模式，則須再特別設計新的演算法。在本計畫中，
11  
 標界視窗模式：可記為(l, , 1, 1)。因為視窗大小 ω設為 ，表示其大小無限制，
所以若在時間點 j 的視窗為(tl, tl+1, …, tj)則在時間點 j 1　 的視窗為(tl, tl+1, …, tj, tj+1)。 
 遞減視窗模式：可記為(l, , 1, d)。這個模式與標界模式的設定的不同之處在於多
了一個小於 1 的遞減比率。  
 滑動視窗模式：可記為(l, ω, 1, 1)。因此模式的視窗大小固定為 ω，若在時間點 j
的視窗為 (tjω1, tjω2, …, tj)，則在時間點 j1 的視窗為(tjω2, …, tj, tj+1)。 
 
4.2.2 通用探勘架構 
 
根據 Tan 和 Kumar 所提出來的概念，間接關聯探勘的工作可以分為兩個主要子工
作：首先由串流資料中找出所有支持度大於 tf的 頻繁項目集；接著再由這些頻繁項目
集產生所有的間接關聯規則。根據這個想法，我們提出的探勘系統架構如圖 15 所示。
其中，CPU Monitor & Load Shedding 這個模組為資源感知的控制機制，其工作為監督
CPU 目前的計算能力與資料串流的速率，以估算接下來的工作量是否會超出 CPU 的負
荷，若是則進行負載減量(Load shedding)，利用取樣的方式減少進來的資料量。PF 為儲
存可能的頻繁項目集，詳細的說明將在演算法的設計時一併敘述。 
 
13  
 
Process 1: 
Discover & 
maintain FP 
PF
model setting & 
adjusting 
Process 2: 
Generate IA 
result 
data stream 
Access & 
update 
query
圖 15：通用型間接關連探勘系統架構. 
 
4.2.3 資料感知機制 
 
這個機制的運作方式包括幾個主要的部分：(1)監督 CPU 的負荷能力；(2)監視資料
串流的速度，以估算工作量；(3)若工作量超出 CPU 的負荷能力則進行負載減量。以下
分別說明每個部份的設計方式。 
首先在 CPU 的負荷能力，我們是觀察以固定的時間內，程序 1 所處理的項目集的
數目為計算單位。假設在第 i 次的 CPU 的實際負荷能力為(i)，估算出的負荷能力為 (i)，
則預測接下來的 CPU 的負荷能力可表示 
(i+1) = (i) + (1) (i)                    (4.1) 
接下來在工作量的估算方式，因每筆交易的長度不一，我們參考[DNO+07]這篇論
文的作法，先計算平均一筆交易資料內含多少項目集 Li，在乘上單位時間內到達的資料
筆數 r，如下所示： 
 
CPU 
Monitor & 
Load 
shedding 
Access  
對任何由 GIAMS 產生的項目集 X，其 Tsup(X)和 Esup(X)的差距必不大於，即 
 )()(0 XEsupXTsup  
另外我們還證明：當中界子相依度門檻 td 設為 td  tf，則任何滿足定義 1 中的項
目對支持度條件及中介子支持度條件的間接關聯必同時滿足中介子相依度條件。換句話
說，當我們將中界子相依度門檻設為小於 tf，則我們的演算法保證所有由 PF 中的頻
繁項目集產生的間接關聯皆符合要求。 
 
4.2.5 GIAMS 的實作 
 
GIAMS 只是一個通用的演算法架構，其細部的設計仍然需要考慮。基本上有關程
序 1 的實作可參考前述的 MIA-LM 的做法所用的資料結構，至於 EMIA-LM 因為所儲存
的是視窗範圍內的壓縮資料，並不是直接儲存頻繁項目集的資訊，故不並適用於此架構， 
但是 MIA-LM 所採用的資料結構 IS-forest 所需的記憶體較多，故我們另外發展了一個資
料結構，稱為 Card-Stree，其概念如圖 16 所示，在根節點之下的子樹 S1, S2, …, Sk分別
儲存長度為 1, 2, …, k 的項目集，而每個節點則存儲項目集的內容及其區塊向量與次數
向量。 
 
15  
 
圖 16：Card-Stree 的結構範例。 
 
至於程序 2 的實作，最簡單的做法即是仿照 MIA-LM 的方法，直接採用 INDIRECT
的做法，我們將此一實作方法稱為 GIAMS-IND。然而我們發現在傳統的間接關聯探勘
演算法中的中介子有ㄧ特性，即如某項目集為中介子則其支持度必定會大於某一門檻值
2tf ts，以下為推導過程。 
假設有一中介子 M，與兩項目或項目集 A 與 B，如果存在a, b | M ，根據定義 1 可
以將它們的關係以集合的概念表示成下列公式： 
M  (A  M)  (B  M)                        (4.6) 
根據公式(4.6)與定義 1，我們可將上式改寫為下列公式(3.7)： 
|M|  |(A  M)  (B  M)|                       (4.7) 
root
 .....
length=1 length=2 length=n 
X.id=A 
X.bidv=[1,3] 
X.countv=[2.17,3.5] 
length=3 
X.id=CDE 
X.bidv=[14,15] 
X.countv=[15,2] 
 
 
  
(a) 
 
 
(b) 
圖 17：演算法 MIA-LM、EMIA-LM 及 Hi-mine*的比較：(a)執行時間的狀況；(b)記憶體
使用量的狀況。 
 
5.2 GIAMS-IND 及 GIAMS-MED 的比較 
 
在這個部分的實驗所用的測試資料為T5.I5.N0.1K.D1000K。表 3為各參數的預設值。 
圖18顯示的是在此視窗模式下我們的通用探勘法GIAMS的執行時間與記憶體使用
量的表現。基本上可以很明顯地看出程序 1 的執行時間是隨資料量的增加呈線性成長，
而隨中介子支持度的增加而減少；記憶體使用量亦是類似的情況。在程序 2 的部分，很
清楚可以看到 GIAMS-MED 的實作方法遠比 GIAMS-IND 有效率。至於其正確性在所有
的組合下 ASE 皆為 0，而 Recall 為 100%。 
圖 19 則為遞減視窗模式的狀況。由於程序 2 的執行效率與視窗模式較無關，故在
這個實驗我們僅觀察程序 1 的表現，但增加觀察遞減率的變化對執行效率的影響。由實
驗結果可以看出遞減率愈高，執行時間愈短，這是因為遞減率愈低，項目集過時的機會
增加，因此，項目集進出 Card-Stree 的頻率增加。相反地，遞減率愈高，項目集停留在
17  
19  
超過使用者給定的範圍。近年來的研究顯示，許多其他的探勘問題，包括分類、分群、
循序樣式，皆可先找出頻繁項目集，再從中產生需要的樣式或規則。故我們相信，本研
究所提出的架構可更進一步發展成一個通用的串流探勘系統，適合各種探勘的工作。運
用此架構，系統發展者不需像目前的做法，為每種探勘工作、在不同的視窗模式下都發
展適合的演算法，將可節省大量的開發時間，同時又提供使用者自訂視窗模式的彈性，
且保證探勘的品質。 
 0
50
100
150
200
250
300
80
K
16
0K
24
0K
32
0K
40
0K
48
0K
56
0K
64
0K
72
0K
80
0K
88
0K
96
0K
Transaction size
Ti
m
e(
se
c)
20
30
40
50
60
70
80
90
100
M
em
or
y(
M
B
)
Mem. d=0.9
Mem. d=0.8
Mem. d=0.7
Time d=0.9
Time d=0.8
Time d=0.7
 
(a) 
 
10
100
1000
10000
80
K
16
0K
24
0K
32
0K
40
0K
48
0K
56
0K
64
0K
72
0K
80
0K
88
0K
96
0K
Transaction size
Ti
m
e(
se
c)
30
40
50
60
70
80
90
100
Mem. 0.01
Mem. 0.012
Mem. 0.014
Mem. 0.016
Mem. 0.018
Time 0.01
Time 0.012
Time 0.014
Time 0.016
Time 0.018
 
(b) 
圖 19：於遞減視窗模式，程序 1：(a)不同的遞減率對執行時間與記憶體使用量的影響； 
(b)不同的 tf的設定對執行時間與記憶體使用量的影響。 
21  
23  
 
參考文獻 
 
[曾劉辛07]曾新穆、劉又誠與辛致煒，”以間接關聯規則探勘基因表現微陣列資料”，2007
年全國計算機會議。 
[Agg07] C. Aggarwal, Data Streams: Models and Algorithms, Springer, 2007. 
[AZ04] M.L. Antonie and O.R. Zaane, “Mining positive and negative association rules: An 
approach for confined rules,” in Proceedings of the 8th European Conference on 
Principles and Practice of Knowledge Discovery in Databases, pp. 27-38, 2004.  
[BBD+02] B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom, “Models and issues in 
data stream systems,” in Proceedings of 21st ACM Symposium on Principles of 
Database Systems, pp. 1-16, 2002.  
[CHM+00] I. Cadez, D. Heckerman, C. Meek, P. Smyth, and S. White, “Visualization of 
navigation patterns on a web site using model-based clustering,” in Proceedings of 6th 
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 
280-284, 2000. 
[CBL06] L. Chen, S.S. Bhowmick, and J. Li, “Mining temporal indirect associations,” in 
Proceedings of 10th Pacific-Asia Conference on Knowledge Discovery and Data 
Mining, pp. 425-434, 2006.  
[CL03a] J.H. Chang and W.S. Lee, “Finding recent frequent itemsets adaptively over online 
data streams,” in Proceedings of 9th ACM SIGKDD International Conference on 
Knowledge Discovery and Data Mining, pp. 487-492, 2003.  
[CL03b] J.H. Chang and W.S. Lee, “estWin: Adaptively monitoring the recent change of 
frequent itemsets over online data streams,” in Proceedings of 12th ACM International 
Conference on Information and Knowledge Management, pp. 536-539, 2003. 
[CL04] J.H. Chang and W.S. Lee, “A sliding window method for finding recently frequent 
itemsets over online data streams,” Journal of Information Science and Engineering, 
Vol. 20, No. 4, pp. 753-762, 2004. 
[CL05] J.H. Chang and W.S. Lee, “estWin: Online data stream mining of recent frequent 
itemsets by sliding window method,” Journal of Information Science, Vol. 31, No. 2, 
76-90, 2005.  
[CKN06] J. Cheng, Y. Ke, and W. Ng, “Maintaining frequent itemsets over high-speed data 
streams,” in Proceedings of 10th Pacific-Asia Conference on Knowledge Discovery and 
Data Mining, pp. 462-467, 2006.  
[CKN07] J. Cheng, Y. Ke, and W. Ng, “A survey on algorithms for mining frequent itemsets 
over data streams,” Knowledge and Information Systems, accepted manuscript, 2007. 
[CPX+06] C. Cornelis P. Yan X. Zhang and G. Chen, "Mining positive and negative 
association rules from large databases," in Proceedings of IEEE International 
Conference on Cybernetics and Intelligent Systems, pp. 1-6, 2006.  
[CWY+04] Y. Chi, H. Wang, P.S. Yu, and R.R. Muntz, “Moment: maintaining closed 
frequent itemsets over a stream sliding window,” in Proceedings of 4th International 
Conference on Data Mining, pp. 59-66, 2004.  
[CWY+06] Y. Chi, H. Wang, P.S. Yu, and R.R. Muntz, “Catch the moment: maintaining 
closed frequent itemsets over a data stream sliding window,” Knowledge and 
Information Systems, Vo. 10, No. 3, pp. 265-294, 2006.  
[DNO06] X.H. Dang, W.K. Ng, and K.L. Ong, “Adaptive load shedding for mining frequent 
patterns from data streams,” in Proceedings of 8th International Conference on Data 
Warehousing and Knowledge Discovery, pp. 342-351, 2006. 
[DNO+07] X.H. Dang, W.K. Ng, K.L. Ong, and V.C.S. Lee, “Discovering frequent sets from 
data streams with CPU constraint,” in Proceedings of 6th Australasian Data Mining 
Conference, 2007. 
25  
streams with a time-sensitive sliding window,” in Proceedings of 5th SIAM 
International Data Mining Conference, 2005. 
[LHK+06] H.F. Li, C.C. Ho, F.F. Kuo, and S.Y. Lee, “A new algorithm for maintaining 
closed frequent itemsets in data streams by incremental updates,” in Proceedings of 6th 
IEEE International Conference on Data Mining - Workshops, pp. 672-676, 2006.  
[LL05] D. Lee and W. Lee, “Finding maximal frequent itemsets over online data streams 
adaptively,” in Proceedings of 5th IEEE International Conference on Data Mining, pp. 
266-273, 2005. 
[LLS04a] H.F. Li, S.Y. Lee, and M.K. Shan, “An efficient algorithm for mining frequent 
itemsets over the entire history of data streams,” in Proceedings of 1st International 
Workshop on Knowledge Discovery in Data Streams, 2004.  
[LLS04b] H.F. Li, S.Y. Lee, and M.K. Shan, “Mining maximal frequent itemsets in data 
streams,” in Proceedings of International Computer Symposium, 2004. 
[LLS05] H.F. Li, S.Y. Lee, and M.K. Shan, "DSM-TKP: Mining top-k path traversal patterns 
over web click-streams," in Proceedings of the 2005 IEEE/WIC/ACM International 
Conference on Web Intelligence, 2005. 
[LK06] C.K.S. Leung and Q.I. Khan, “DSTree: A tree structure for the mining of frequent 
sets from data streams,” in Proceedings of 6th IEEE International Conference on Data 
Mining, pp. 928-932, 2006.  
[MAA05] A. Metwally, D. Agrawal, and A.E. Abbadi, “Efficient computation of frequent and 
top-k elements in data streams,” in Proceedings of 10th International Conference on 
Database Theory, pp. 398-412, 2005. 
[MM02] G.S. Manku and R. Motwani, “Approximate frequency counts over data streams,” in 
Proceedings of 28th International Conference on Very Large Data Bases, 2002. 
[Mut03] S. Muthukrishnan, “Data streams: Algorithms and applications,” in Proceedings of 
14th annual ACM-SIAM symposium on discrete algorithms, 2003.  
[PHL+01] J. Pei, J. Han, H. Lu, S. Nishio, S. Tang, and D. Yang, “H-mine: Hyper-structure 
mining of frequent patterns in large database,” in Proceedings of 2nd IEEE 
International Conference on Data Mining, pp. 441-448, 2001. 
[SOL06] X. Sun, M.E. Orlowska, and X. Li, “Finding frequent itemsets in high-speed data 
streams,” in Proceedings of 2006 SIAM Conference on Data Mining – Workshop, Vol. 1, 
pp. 1-6, 2006. 
[SON98] A. Savasere, E. Omiecinski, and S.B. Navathe, “Mining for strong negative 
associations in a large database of customer transactions,” in Proceedings of 4th 
International Conference on Data Engineering, pp. 494-502, 1998.  
[TCY04] W.G. Teng, M.S. Chen, and P.S. Yu, “Resource-aware mining with variable 
granularities in data streams,” in Proceedings of 4th SIAM International Conference on 
Data Mining, 2004. 
[THC02] W.G. Teng, M.J. Hsieh and M.S. Chen, “On the mining of substitution rules for 
statistically dependent items,” in Proceedings of IEEE 2nd International Conference on 
Data Mining, pp. 442-449, 2002.  
[TKS00] P.N. Tan, V. Kumar and J. Srivastava, “Indirect association: Mining higher order 
dependencies in data,” in Proceedings of 4th European Conference Principles of Data 
Mining and Knowledge Discovery, pp. 632-637, 2000.  
[TK01] P.N. Tan and V. Kumar, “Mining indirect associations in web data,” in Proceedings 
of 3rd International Workshop on Mining Web Log Data Across All Customers Touch 
Points (WEBKDD’01), pp.145-166, 2001.  
[TSK06] P.N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining, Addison 
Wesley, 2006. 
[TW04] D.R. Thiruvady, and G.I. Webb, “Mining negative rules using GRD,” in Proceedings 
of 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 161-165, 
2004.  
978-1-4244-6474-6/10/$26.00 ©2010 IEEE ICSSE 2010 in Taiwan
Mining Indirect Associations over Data Streams
Chun-Hao Chen
Dept. of Computer Science and Information Engineering
Tamkang University
Taipei 251, Taiwan, R.O.C.
chchen6814@gmail.com
Wen-Yang Lin, Yi-Ching Chen, and He-Yi Li
Dept. of Computer Science and Information Engineering
National University of Kaohsiung
Kaohsiung 811, Taiwan, R.O.C.
wylin@nuk.edu.tw
Abstract—Indirect association is a new type of infrequent
pattern, which provides a new way for interpreting the value of
infrequent patterns and can effectively reduce the number of
uninteresting infrequent patterns. The concept of indirect
association is to “indirectly”connect two rarely co-occurred items
via a frequent itemset called mediator, and if appropriately
utilized it can help to identify real interesting “infrequent 
itempairs” from databases. All of the literature on indirect
association mining, to our best knowledge, is confined to the
traditional, relatively static database environment; no research
work has been conducted on mining indirect associations over
data streams. In this paper, we propose an approach, namely
MIA-LM (Mining Indirect Association over a Landmark Model)
algorithm, for mining indirect associations over data streams.
The proposed method can not only discover indirect associations
over data streams efficiently, but also guarantee the error of
derived itemsets not to exceed a user-specified parameter.
Experiments on real web-click stream are also made to show the
effectiveness and efficiency of the proposed approach.
Keywords—data stream mining, indirect association, indirect
itempair, landmark window model.
I. INTRODUCTION
In recent years, due to the rapidly improvement of
informatics techniques, a new continuous data collection
approach, namely data stream, is applied widely to different
applications, such as sensor networking, intrusion detection,
traffic controlling, financial analysis and earthquake prediction
[1, 2, 6]. As usual, pattern mining in data stream for researcher
is the most interesting field as in the traditional data mining
fields. Most data stream mining approaches are focus on
discovering frequent patterns [7, 10, 12].
However, infrequent patterns have also been shown their
high valuable merits if they have certain characteristics such as
negative correlation [13, 14]. It is a tough challenge for
discovering infrequent patterns that have negative correlations
since the number of infrequent patterns is significantly larger
than that of frequent patterns. Another problem is how to avoid
generating useless patterns. Although lots of approaches have
been proposed for discovering infrequent patterns [5, 13, 19],
they still can not deal the problems well.
Indirect association, proposed by Tan and Kumar [15], is a
new type of infrequent pattern, which provides a new way for
interpreting the value of infrequent patterns and can effectively
reduce the number of uninteresting infrequent patterns. The
concept of indirect association is to indirectly connect two
rarely co-occurred items via a frequent itemset called
“mediator”, and if appropriately utilized it can help toidentify
real interesting “infrequent itempairs”from databases. Many
approaches have been proposed and applied on different fields,
including e-commerce, text mining, bioinformatics, etc. [3, 8, 9,
16, 17, 18]. To our best knowledge, all of the literatures on
indirect association mining are confined to the traditional,
relatively static database environment.
In this paper, we propose an algorithm, namely MIA-LM
(Mining Indirect Association over a Landmark Model), for
mining indirect associations over data streams. We show that:
(1) the support error of an itemset is smaller than the support
error threshold ; that is, no false negative itemsets will be
generated by using the proposed approach; (2) if the mediator
dependence threshold td is set smaller than (tf ), all possible
indirect association patterns can be derived by the proposed
approach. Experiments on real web-click stream are also made
to show the effectiveness and efficiency of the proposed
approach.
II. PROBLEM DEFINITION
Definition 1 An indirect association{x, y} | Mmeans that
an itempair {x, y} is indirectly associated via a mediator M if it
satisfies the following three conditions:
1. Itempair support condition: sup({x, y}) < ts;
2. Mediator support condition: sup({x} M) tf and sup({y}
M)tf;
3. Mediator dependence condition: dep({x}, M) td and
dep({y}, M)td,
where ts, tf and td are itempair support threshold, mediator
support threshold and mediator dependence threshold,
respectively. dep(R, S) is a measure of the dependence between
itemsets R and S. The well-known dependence function IS
measure IS(R, S) (= P(R, S) / sqrt(P(R)P(S))) is used in this
paper.
Definition 2 A transaction data stream TDS is any ordered
pair (T, ), where a transaction T = tid, Itis a set of items It
with identifier tid and ItI, where I = {i1, i2,…, im} is a set of
items, andΔ is a sequence of positive real time intervals.
In this paper, given a transaction data stream TDS and
parameters, including an itempair support ts  (0, 1), a
mediator support tf (ts, 1), a mediator dependence td (0, 1)
and a support error threshold  (0, ts), we attempt to design
ICSSE 2010 in Taiwan
4. candidateIIS-list: If the support of a 2-itemset (itempair)
is less than itempair support ts, no matter its subsets are
frequent or not, it is stored in candidateIIS-list. Two
attributes, item-id and item-count, of each itempair are
recorded in candidateIIS-list.
A. Algorithm Description
The MIA-LM algorithm is described in Fig. 1. Four user-
specified parameters must be given, including ts, tf, td, and .
The MIA-LM algorithm first divides TDS into blocks that are
denoted as {B1, B2, ..., Bn}. Each block Bi consists of a set of
transactions represented as Bi{T1, T2, ..., Tk}, where k is set to
1/as suggested by [12]. Moreover, the total number of
transactions N seen so far in the transaction data stream TDS is
defined as N|B1||B2|...|Bl|, ln. The other four phases
of the proposed algorithm (Lines 4~8) are Transaction
projection, Candidate IIS updating, Pruning ISFI-forest and
Indirect Association Mining.
Algorithm Name: MIA-LM(TDS, ts, tf, td,)
Input: Transaction data stream TDS, an itempair support threshold
ts, a mediator support threshold tf, a mediator dependence
threshold td and a support error threshold.
Output: Indirect Association Patterns P.
Step:
1: Determine the size of block by using1/;
2: Divide TDS into blocks; each block contains 1/
transactions;
3: for each Bi do
4: TrasactionProjection(Bi, i);
5: UpdateIIS(ISFI-forest, candidateIIS-list, ts, N);
6: PruneISFI-forest(ISFI-forest, i);
7: if user query request = ture
8: IndirectAssociationMining(ISFI-forest, candidateIIS-list,
tf, td, ts, N);
9: endfor
Figure 1. The MIA-LM algorithm.
In the transaction projection phase, each transaction is
loaded from the current block and projected to a set of item-
suffix transactions. That is, a transaction T = {x1, x2, ..., xm} is
projected to m items-suffix transactions that are t1 = {x1, x2, …, 
xm}, t2 = {x2, x3, …, xm}, …, tm-1 = {xm-1, xm} and tm = {xm}.
These item-suffix transactions are then inserted into the
corresponding IS-tree and FI-list according to the first item of
each item-suffix transaction.
The main task of candidate IIS updating phase is to
maintain the candidate Indirect Itempair Set (candidate IIS),
which is used for deriving indirect associations in the last phase.
Each 2-itemset in ISFI-forest whose count is less than ts*N is
first put into candidateIIS-list. If a 2-itemset already exists in
candidateIIS-list, then update its count. Due to deleting existing
2-itemsets in candidateIIS-list in this phase may lead to false
positive indirect itempairs, MIA-LM postpones the deletion till
the fourth phase.
Memory usage is very important in a data stream mining
environment. The purpose of pruning ISFI-forest phase is to
prune itemsets whose counts are less than a specific threshold
k(currentblockid X.block_id + 1). The currentblockid and
X.block_id denote the current block and the block where
itemset X is inserted. Since we choose the block size k to be the
inverse of support error threshold , the threshold equals to
(currentblockid X.block_id + 1). If the count of an itemset is
less than this threshold, that itemset will have low probability
to appear in subsequent blocks, and should be considered as
infrequent itemset. In this case, the itemset is pruned to save the
memory space.
In the indirect association mining phase, the proposed
approach generates the indirect association patterns and
response patterns to user by using ISFI-forest and candidateIIS
as HI-mine did. For each itempair {x, y} in candidateIIS, it first
uses ISFI-forest to generate its corresponding frequent itemsets.
If the mediator dependences of frequent itemsets are larger than
the mediator dependence threshold td, they are put into
mediator support set, denoted as MSS(x) and MSS(y). If an
itemset Z appears both in MSS(x) and MSS(y), then an indirect
association{x, y} | Zis generated.
B. An Example
Assume that we have a transaction data stream and the
support error threshold is set at = 20%. The transaction data
stream is divided into blocks, each of which contains five (=
1/0.2) transactions. The first two blocks are shown in Fig. 2.
.....
Block3
Time
TID1 A,B,D
TID2 B,C,D
TID3 C,D
TID4 B,D,E
TID5 B,D
Block1 Block2
TID6 A,C
TID7 A,D,E
TID8 B,C
TID9 C,D,E
TID10 A,D,E
Figure 2. The first two blocks of transaction data stream.
The first transaction TID1 = {A, B, D} in Block1 is
projected to three item-suffix transactions, including {A, B, D},
{B, D} and {D}. These item-suffix transactions are inserted
into the corresponding IS-tree and FI-list according to the first
item of each item-suffix transaction. The updated ISFI-forest is
shown in Fig. 3.
B:1:1
D:1:1
Block-idCountItem
B 1 1
D 1 1
A:1:1
D:1:1
B:1:1 D:1:1
A:1:1 B:1:1 D:1:1
11D
Block-idCountItem Block-idCountItem
F
I-
lis
t
IS
-t
re
e
Figure 3. The updated ISFI-forest after inserting TID1.
In candidate IIS updating phase, after processing
transactions in current block, the proposed algorithm is then
derived candidate indirect itempair set (candidate IIS) from the
ISFI-forest. Take IS-tree of item A as an example, two 2-
itemsets with their counts can be generated as <{A,B}:1> and
ICSSE 2010 in Taiwan
conclude that if the mediator dependence threshold td is set
smaller than (tf ), then all possible indirect association
patterns will be generated by using the proposed approach.
VI. EXPERIMENTAL RESULTS
In this section, experiments on a real web-click dataset were
made to show the effectiveness and efficiency of the proposed
MIA-LM algorithm. The dataset contains 294 attributes (items)
and 32711 instances (transactions). More details of the dataset
can be obtained from
“http://kdd.ics.uci.edu/databases/msweb/msweb.html”.
We enlarged the dataset to 327,110 transactions by
duplicating the original dataset. All experiments were
implemented in Java and made on a HP ProLiant DL380 G6
with Intel Xeon E5530 2.40GHz and 6GB RAM. The
comparison of the proposed approach (MIA-LM) and the
traditional approach (INDIRECT) [15] with respect to
execution time and memory usage were first made to show the
performance of the proposed algorithm. The results are shown
in Fig. 5 and 6.
12 11 8 8 7 8 8 8 7
261
114
77
57
45
31 25 22 19
0
50
100
150
200
250
300
0 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009
tf = ts
E
xe
cu
tio
n
Ti
m
e
(s
ec
)
MIA-LM INDIRECT
Figure 5. Performance comparison of MIA-LM (= 0.00006, td = 0.1) and
INDIRECT.
8
7 7 7 7 7
6 6 6
11
10 10
9 9 9 9 9
8
0
2
4
6
8
10
12
0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009
tf
M
em
or
y
U
sa
ge
(M
B
)
MIA-LM INDIRECT
Figure 6. Memory usage comparison of MIA-LM (= 0.00006, td = 0.1) and
INDIRECT.
From Fig. 5, we can observe that although the execution
times of both approaches are decreasing along with the
increasing of mediator support (tf), MIA-LM is superior to
INDIRECT, especially when the mediator support is small (e.g.
tf = 0.001). From Fig. 6, we can also observe that the memory
usage of MIA-LM is less than INDIRECT. These experimental
results show that MIA-LM is suitable for mining indirect
association patterns over data streams.
The experiments were then conducted to evaluate the
quality of the indirect associations by comparing the results
obtained by MIA-LM and INDIRECT, which is shown in Fig. 7,
where“Shared”means the percentage of patterns discovered by
both approaches, “Missed” represents the percentage of
patterns missed by MIA-LM, and “Invalid” depicts the
percentage of invalid patterns generated by MIA-LM.
Indirec t As s oc iation P atterns
7 4 2 2 1 0 0 0 0
1363 1353 1107 931 825 689 545 406 271
0 0 0 0 0 0 0 0 0
0%
20%
40%
60%
80%
100%
0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009
tf = ts
Pa
tte
rn
Pe
rc
en
ta
ge
missed shared invalid
Figure 7. Comparison results of derived indirect association patterns by
using MIA-LM (= 0.00006, td = 0.1) and INDIRECT.
We can observe that no invalid indirect association patterns
are generated by MIA-LM when comparing with INDIRECT.
Since the frequent itemsets are maintained by using the data
structure ISFI-forest, a little bit counting errors are raised.
Some missing indirect associations are thus expected. Most of
patterns generated by MIA-LM are the same as INDIRECT.
These experimental results show the effectiveness of the
proposed approach.
VII. CONCLUSIONS
In this paper, we have proposed an algorithm, namely MIA-
LM, for mining indirect associations over data streams. To the
best of our knowledge, the proposed MIA-LM algorithm is the
first work for mining indirect associations over data streams.
We also have shown that two important characteristics of MIA-
LM: (1) the support error of an itemset is smaller than the
support error threshold ; and (2) if the mediator dependence
threshold is set smaller than a specific value (= tf - ), then all
possible indirect association patterns can be generated by MIA-
LM. Experiments were also conducted on a real web-click
stream to show that efficiency and effectiveness of the
proposed approach. In the future, we will continue our work on
indirect associations mining over data streams, including
improving the proposed algorithm and extending it to different
window models.
ACKNOWLEDGMENT
This work is partially supported by National Science
Council of Taiwan under grant No. NSC97-2221-E-390-016-
MY2.
REFERENCES
[1] C. Aggarwal, Data Streams: Models and Algorithms, Springer, 2007.
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                    日期： 98 年 9 月 2 日 
計畫編號 NSC 97－2221－E－390－016－MY2 
計畫名稱 從資料串流中探勘間接關聯型樣技術之研究 
出國人員
姓名 林文揚 
服務機構
及職稱 國立高雄大學資訊工程學系教授 
會議時間 98 年 8 月 17 日至 99 年 8 月 19 日 會議地點 中國江西南昌 
會議名稱 
(中文) 2009 年國際微粒計算研討會 
(英文) 2009 IEEE International Conference on Granular Computing 
(IEEE GrC 2009) 
發表論文
題目 
(中文) 利用用戶喜好本體於多維度關聯規則探勘之支持度門檻設定
建議 
(英文) Favorable Support Threshold Recommendation for 
Multidimensional Association Mining Using User Preference Ontology 
一、參加會議經過 
IEEE 國際微粒計算研討會(International Conference on Granular Computing，簡稱
IEEE GrC)是由華裔資深學者 T.Y. Lin 教授創立的微粒計算學會所發起舉辦的研討
會，其主旨在推廣微粒計算的理論與應用。所謂的微粒計算係指任何能有效運用微
粒概念，如類別、群聚、子集、群組、間距，以建構有效的計算模式於需要處理大
量資料、資訊或知識的應用。第ㄧ屆國際微粒計算研討會於 2005 年在大陸北京舉行，
今年是第五屆。此次會議於 2009 年 8 月 17 日至 19 日在大陸江西的南昌舉行。此會
議所涵蓋的主題相當廣，任何能運用到微粒觀念的領域都涵蓋在內，不過主要還是
偏重在傳統的智慧型計算、資料探勘與機器學習、生物與醫療資訊等。 
此會議共分三天進行，內容的安排上大致為每天早上安排三場專題演講，所請
到的皆為相關領域的極為活躍或知名的人物，演講的主題涵蓋模糊理論、計算生物、
普及智慧等。緊接專題演講之後為論文發表場次，今年大會的時間雖然只有三天，
不過參與的學者仍然相當踴躍，總計三天下來共有十七個場次。 
此次筆者與系上同事洪宗貝教授共同組織一個特別場次，主題為 Intelligent Data 
Analysis and Applications，共有五篇論文發表。我們的場次被安排在第一日下午 4:20
至 6:30。筆者發表的論文題目為 Favorable Support Threshold Recommendation for 
 1
 3
詢在台灣舉辦此研討會的意願，但了解上述限制後決定待將來相關規定放寬後再行
考慮。現在兩岸的交流已越趨開放頻繁，對於對岸學者來台參加研討會的簽證申辦
若能重新調整，相信必能有助於吸引大陸學者來台的意願。 
 
五、攜回資料名稱及內容 
IEEE GrC 論文集。 
 5
分開始，在本研討會一共有六場的演講，其中(1)第一場為 Olivier Teytaud 博士進行
大約 5 分鐘的簡短地介紹電腦圍棋程式過去、現在及未來; (2)第二場為義大利薩萊諾
大學(University of Salerno)的 Vincenzo Loia 教授進行以模糊標語言(Fuzzy Markup 
Language, FML)進行知識表達主題的演講; (3)第三場為圍棋程式 Many Faces of Go 程
式研發團隊成員 David Fotland 說明該團隊設計的圍棋程式理論; (4)第四場為圍棋程
式 Fuego 程式研發團隊成員 Martin Müller 教授說明該團隊設計的圍棋程式理論; (5)
第五場為英國艾克塞大學(University of Essex)Hani Hagras 教授，其演講主題為基於第
二型模糊進合(Type-2 Fuzzy Set, T2FS)進行知識表達; (6)第六場為清華大學資訊工程
學系鍾葉青教授介紹台灣格網。在整個研討會中，演講者與與會者討論熱絡，進行
得相當順利，團隊成員於會後也與邀請之演講者合照。也邀請大家參加 7 月 20 日
於舉辦的「人腦對抗電腦圍棋賽」及參加明年在台灣舉辦的 FUZZ-IEEE 2011 國際學
術會議。 
「人腦對抗電腦圍棋賽」於 7 月 20 日上午 8 時在巴塞隆納國際會議中心登場，
IEEE CIS 總裁 Gary Yen 教授、IEEE CIS 副總裁 Gary Fogel 博士、IEEE CIS 財務副
主席 Piero P. Bonissone博士、IEEE Transactions on Computational Intelligence and AI in 
Game (IEEE TCIAIG)國際期刊總編輯 Simon Lucas 教授、IEEE CEC 2010 競賽主席
Philip Hingston 教授及 IEEE CIS 學術副總裁 Hisao Ishibuchi 教授等多位 IEEE CIS 重
要成員及國內多位教授，包括郭耀煌教授、林進燈教授及蘇順豐教授等蒞臨致詞及
指導，另外也吸引許多對圍棋有興趣的國外學者前來觀戰。David Fotland 及 Martin 
Mueller 教授也於現場即時進行盤面解說，以讓與會貴賓及對圍棋有興趣的學者專家
更進一步了解比賽的過程。整個比賽從上午 8 時 15 分到下午 6 時 30 分，共進行 22
場比賽，4 位職業及業餘棋士合計取得 13 勝，周俊勳及周平強二位職業棋士就包辦
9 勝，電腦圍棋程式取得 9 勝，日本的 Zen 圍棋程式就包辦 4 勝。整個比賽非常圓滿
成功。 
筆者個人發表的論文被安排在 21 日下午 4:50 至 6:30 的場次，此場次的主題為
Fuzzy Ontologies and Fuzzy Markup Language Applications，共有五篇論文發表。個人
的 論 文 題 目 為 Updating Generalized Association Rules with Evolving Fuzzy 
Taxonomies，主要探討在模糊分類關係改變時，如何有效地維護並更新先前探勘得
到的一般化關聯規則。晚上隨後舉行大會晚宴，此次晚宴於當地的美術館旁據說是
停車場的空間舉行，由於出席的人數超過千人，故整個晚宴的陣仗極為龐大，讓人
印象深刻。席間我們與日本大阪府立大學 Hiroshi Tsuji 教授、義大利薩萊諾大學
Vincenzo Loia、義大利比薩大學 Francesco Marcelloni 教授及日本明治大學 Tomohiro 
Takagi 教授一同用餐，並邀請他們共同參與明年於臺灣舉辦 FUZZ-IEEE 2011。 
7 月 22 日與 7 月 23 日團隊成員整理「人腦對抗電腦圍棋賽」相關活動資料，並
委由國立臺南大學秘書室發佈活動成果新聞稿，並於國內平面媒體、國內外電子媒
體與網站報導相關活動成果。7 月 24 日上午我們一行人於巴塞隆納機場經由巴黎及
香港返程回台灣，結束這次的活動旅程。 
Favorable Support Threshold Recommendation for Multidimensional
Association Mining Using User Preference Ontology
1 Chin-Ang Wu Wen-Yang Lin Chang-Long Jiang Chuan-Chun Wu
Dept. of Information
Management, I-Shou
University, Taiwan
cwu@csu.edu.tw
Dept. of Comp. Sci.
and Info. Eng.,
National University of
Kaohsiung, Taiwan
wylin@nuk.edu.tw
Dept. of Elec. Eng.,
National University of
Kaohsiung, Taiwan
m0955107@mail.nuk.
edu.tw
Dept. of Information
Management, I-Shou
University, Taiwan
miswucc@isu.edu.tw
1 Chin-Ang Wu is also a lecturer in Cheng Shiu University, Niaosong Township, Kaohsiung County 833.hsiung County
Abstract
The classical algorithms for mining association rule
require the user to specify a support threshold to
determine if an itemset is frequent or not.
Unfortunately, the setting of support threshold is
subjective without clear standard and has great
influence on the mining results. In this paper we
propose an intelligent minimum support suggestion
framework with the help of the user preference
ontology. The user preference ontology maintains the
frequently used mining queries extracted from the
mining log. The system finds the most similar queries
to the user’s mining intension, aggregates them and
obtains the favorable support range for the user to
refer. In this paper we describe briefly the construction
of the user preference ontology and focus on the
methodology for query similarity comparison.
1. Introduction
The Apriori algorithm for mining frequent itemset
of association rules is first introduced by Agrawal and
Srikant [2]. It is an influential algorithm that is based
on the property that non-empty subsets of the frequent
itemsets are also frequent. Whether an itemset is
frequent depends on the user-specified minimum
support. In general, an association mining finds the
frequent itemsets that satisfy the minimum support first,
then the association rules are derived based on the
frequent itemsets that satisfy the minimum confidence.
Suppose that A and B are sets of items and AB =.
An association rule has the form A  B with support
and confidence. The support is the possibility of the
transactions that contain the itemset AB, which is
P(AB). The confidence is the possibility of the
transactions that contain A also contain B, which is
P(B|A).
The challenge is that the settings of minimum
support and minimum confidence have no clear-cut
standard. Different minimum support settings will
discover different numbers of frequent itemsets, hence
influence the rules mined. If the minimum support is
set too low, numerous frequent itemsets will be
discovered, thus also numerous rules are generated and
leave the users challenges in order to recognize the real
useful knowledge. If minimum support is set too high,
very few frequent itemsets can be found, thus some
useful knowledge might be left out. Thus reasonable
settings of minimum support and minimum confidence
are important in order to find useful knowledge. Users
try the settings of minimum support and minimum
confidence to and fro to converge on a favorable set
when they are satisfied. Fayyad et al. [3] described data
mining as a repetitive sequence of searching processes,
which implies that the efficiency of mining process
depends much on the proper setting of a mining query
which includes the settings of the minimum support and
confidence.
When the association rule mining is first introduced,
it implied typically on the retailer’s basket data, that is,
it focuses on the purchase analysis which discovers the
associations among solely the product dimension. Later
in [5][6][11], multidimensional association mining
from data cube or multi-dimensional data warehouse
has been proposed. Multiple dimensions are allowed
and the users can specify more precisely the target data
for mining via setting the data granularity with optional
filtering condition. Thus the query for a
1. Find the query patterns of the meta rule format “tG
 tM”, which indicates that the tG and tM tend to be
used together under certain threshold.
2. Cluster the close related query patterns in step 1 and
derive a surrogate query patterns;
3. Find the “where”attribute patterns of the meta rule
format“tG, tM wca”, from the mining log with the
surrogate query patterns in step 2. This indicates
that the surrogate query patterns and the attributes
of the“where”condition (wca) are likely to be used
together, under certain threshold.
4. Cluster the “where”conditions in the mining log
that have the“where”attribute patterns in step 3 and
derive a surrogate“where”conditions;
5. Generate the surrogate queries by combining the
surrogate query patterns and the surrogate “where”
condition (wc);
6. Calculate the minimum support and minimum
confidence for the surrogate queries by averaging
the original queries that are related to the surrogate
queries.
Figure 1. The distillation process
The rules discovered by a surrogate query will
include the rules that are discovered by the queries
covered by the surrogate query. The surrogate queries
are structured and stored in the user preference
ontology as shown in Figure 2. The attribute index
provides fast access to tG and tM by connecting the
attribute to the corresponding tG and tM. A surrogate
query is presented as a path in the user preference
ontology. The user preference ontology is structured
with hierarchies in tG tM wc. It collects surrogate
queries that are relatively used often before. The user
preference ontology will be re-built automatically while
the mining log is growing over a certain threshold.
4. The intelligent recommendation of
minimum support
This section presents the intelligent suggestion
mechanism for minimum support. First we will
introduce the mining system framework and second,
the details of the mechanism for the minimum support
suggestion will be provided.
Figure 2. The user preference ontology
4.1. The intelligent suggestion framework
The intelligent suggestion framework with the user
preference ontology is shown in Figure 3. A
multidimensional association mining of data warehouse
starts from the query formulation by a user. The mining
engine runs the query the user has defined and the
resulting rules are sent back to the users. The
successful queries are maintained in the mining log.
The user preference ontology is generated from the
mining log by performing the distillation process as
described in the previous section. The minimum
support suggestion module is responsible for providing
a favorable minimum support range to the user
interactively while a user is formulating a query. It
computes the similarities between the user specified
query and the surrogate queries in the user preference
ontology and recommends a reasonable support range
to the users.
Figure 3. The intelligent suggestion framework
for minimum support
Minimum Support
Suggestion
Query
Formulation
Data Cube
Data
Mart
Data
Mart
Data
Warehouse

User
…
Mining Engine
…
…
User Preference
Ontology
...
Mining Log
Distillation
… …
CustID
Date,
Gender,
Education
ProdName,
Salesman
…
60%,90%
CustID Date ProdName Gender
attribute index
Educationr
…
CustID
Category,
City=”Taipei”
60%,85% 45%,80%
ProdName,
Education
…… (tG)
(tM)
(wc)
(ms,mc)
User Preference
Ontology
...
Mining Log
…
Surrogate query Support & confidence
calculation
Query pattern “where” atribute 
pattern
Surrogate query
pattern
Surrogate “where” 
condition
“where” condition
…
(2) Value matching. Let Wa be the wc formulated by
the user and Wb be the wc from the user preference
ontology. Suppose Wa = {wca1, wca2,…, wcai} and Wb =
{wcb1, wcb2,…, wcbj}, where wcax = waax Opax vax and
wcbz = wabz Opbz vbz, 1 x i, 1 z j. waax is the
attribute, Opax is the relational operator while vax and
vbz denote the “value”of the conditional expression.
To compute V, the matching degree of the “values”in
conditional expressions, we consider the following
cases:
case 1: wcax = wcbz, V = 1;
case 2: waaxwabz, V = 0;
case 3: waax = wabz and (OpaxOpbz or vaxvbz), V
= CV;
The computation of CV, the complex conditional
“value”, is defined as follows:
CV(wcax, wcbz) =









0
)( axwadist
dist(waax) denotes the counts of distinct values within
waax. The numerator is the overlapping degree of the
“values”in the conditional expressions between wcax
and wcbz.
),max( bzbzaxax vOpvOp
),min( bzbzaxax vOpvOp
The values of μand ℓdepend on the relational
operators. The sequence of relational operators are not
important, thus their cardinalities are as shown in
Table 2. Table 2 shows all cases of μand ℓwhile
waax = wabz..
Table 2. All cases ofμandℓ
Op1 Op2 μ ℓ
  min(vle , v<le) 0
  dist(waax) max(vge ,v ge)
= = 0 0
  dist(waax) - 2 0
=  0 0
 = 1 if veq > v ge0 if veq < v ge 0
  vge -1 if vne > vgevge if vne < vge v ge
 = 1 if veq < vle0 if veq > vle
0
  vle if vne > vlevle -1 if vne< vle 0
  vle - v ge if vle>vge0 otherwise 0
subscript notation of v:le,ge, = eq,ne
v with an notation in the subscript denotes the
“value” of a conditional expression that has the
corresponding operator.
The matching degree of the conditional “values”is
defined as follows:
matchW (Wa, Wb) =
),(
),(
1 1
bzaxWA
i
x
j
z
bzax
wawamatch
wcwcV
 
For example, let
Wa= Age < 60-70,
Wb= Age > 20-30, Salary > 50000,
Suppose Age has 10 distinct range values. Then,
matchW (Wa, Wb) =
5.0
04.0 
4.2.4. Aggregating query similarity and suggesting
the minimum support range. Let Qa, Qb be the user
defined query and the queries in the user preference
ontolog respectively. Suppose the tG, tM and wc of Qa
and Qb are as follows:
Qa = <tG: Ga, tM : Ma , wc: Wa>
Qb = <tG: Gb, tM : Mb , wc: Wb>
The overall query similarity between Qa, Qb is defined
as follows:
QSimilarity(Qa, Qb) = matchG(Ga, Gb)matchM(Ma,
Mb)matchW(Wa, Wb)
Through the similarity comparison of these queries,
the top N similar queries from the user preference
ontology are obtained. The final range of minimum
support to be offered to the user is computed by the
following steps:
1. Sort supports of the top N queries;
2. Average the smaller half of the N queries as the
lower bound;
3. Average the bigger half of the N queries as the
upper bound;
4. Validate the lower bound with the smallest possible
value which is 1/n, where n is the count of the
transactions after grouping. If the lower bound is
beyond the smallest possible value, the smallest
possible value becomes the lower bound;
5. Validate the upper bound with the largest possible
value which is the maximum frequency among all
the one-itemsets. If the upper bound is beyond the
[11] H. Zhu, On-line Analytical Mining of Association
Rules, Master Thesis, SIMON FRASER University,
1998.
generalization [1, 11].
Compared with the substantial amount of research on
mining generalized association rules there is a lack of effort
devoted to the problem of mining generalized associations
with taxonomy evolution. In [16, 17], we have considered this
problem and some of its extensions, and have proposed
efficient Apriori-like algorithms.
III. PROBLEM STATEMENT
A. Mining generalized association rules with fuzzy
taxonomies
Let I{i1, i2,…, im} be a set of items and DB = {t1, t2,…, tn}
be a set of transactions, where each transaction tiTID, A
has a unique identifier TID and a set of items A (AI). We
assume that the fuzzy taxonomy of items, T, is available and is
denoted as a directed acyclic graph on I J, where J = {j1,
j2,…, jp} represents the set of generalized items derived from
I. An edge in T denotes an is-a relationship, that is, if there is
an edge from j to i, we call j a parent (generalization) of i and
i a child of j. For example, in Fig. 1 I = {Laser, HP Officejet,
ScanMaker, Desktop, Notebook} and J = {Scanner,
Printer, PC, Peripheral}.
In a crisp taxonomy, we assume that the child item
belonging to its ancestor has a membership degree with 1. But
in a fuzzy taxonomy, the membership degree of an item may
relate to all nodes of the taxonomy. For any two nodes x and y
in the taxonomy, the membership degree xy of an item y
belonging to its ancestor node x can be calculated as follows
[19]:
xy =
yxl 

:
(
le on
 le ) (1)
where l: xy is one of the paths of accessing x from y, e on l is
one of the edges on path l, andle is the membership degree on
the edge e on l. Operatorsanddepend on the problem of
concern. For illustrative purposes, max stands for and min
for. Furthermore,xx is set to 1, indicating that any item is
fully belonging to itself.
Next, consider calculating the support of items under a
fuzzy taxonomy. If a is an item in a certain transaction tDB,
and x is an item in certain itemset X, then the membership
degree xa with which a belongs to x can be obtained
according to (1). Finally, the support sup(X) = count(X)/|DB|,
where count(X) denotes the accumulated degree that every
transaction supports X in DB, calculated as follows:
 )max(min)( xa
DBt taXxDBt
tXXcount  
 
 (2)
Example 1 Consider Fig. 1. The membership degree
PeripheralLasermin {(Printer, Laser),(Peripheral, Printer)}min {1,
1}1. Similarly,PeripheralOfficejetmax {min {(Printer, officejet),
(Peripheral, Printer)}, min {(Scanner, officejet), (Peripheral, Scanner)} 
max {min {0.7, 1}, min {0.3, 1}} = 0.7. Now consider the
transaction database in Table 1. Let X = {Peripheral, PC}.
The degree that the first transaction supports X is min {max
{PeripheralLaser, PeripheralHP Officejet}, max {PCLaser,
PCHP Officejet} = min {max {1, 0.7}, max {0, 0}} = 0.
TABLE 1. A TRANSACTION DATABASE (DB).
TID Items Purchased
11 Laser, HP Officejet
12 HP Officejet, Desktop
13 ScanMaker, Desktop
14 HP Officejet, Notebook
15 Notebook
16 ScanMaker, Notebook
Given a user-specified minimum support ms and a
minimum confidence mc, the problem of mining generalized
association rules is to discover all generalized association
rules whose support and confidence levels are larger than the
specified thresholds. This problem is usually reduced to the
problem of finding all frequent itemsets for a given minimum
support.
After an initial discovery of all the generalized association
rules in DB, let L be the set of all generalized frequent itemsets
with respect to ms. As time passes, some update activities may
occur to the taxonomies due to various reasons [5]. Let T’
denote the updated taxonomies. The problem of updating
discovered generalized association rules in DB is to find the
set of frequent itemsets L’with respect to the refined
taxonomies T’.
B. Types of taxonomy updates
Our previous work [16] has identified four basic types of
item updates that will cause taxonomy evolution, item
insertion, item deletion, item rename, and item
reclassification. The essence of frequent itemsets update for
each type of taxonomy evolutions is further clarified in what
follows. New type of taxonomy update specific to the fuzzy
taxonomic structure is introduced as well. Note that hereafter
the term“item”refers to a primitive or a generalized item.
Type 1: Item insertion. The strategies to handle this type of
update operation are different, depending on whether the
inserted item is primitive or generalized.
When the new inserted item is primitive, we cannot process
this item until there is an incremental database update,
because the new item does not appear in the original set of
frequent itemsets. On the other hand, if the new item
represents a generalization, then the insertion itself also has no
effect on the discovered associations until the new
generalization incurs some item reclassification.
Fig. 2 shows an example of this type of taxonomy evolution,
where a new item “J”is inserted as a primitive item or a
generalized item. Note that in Fig. 2b item“E”is reclassified
to the generalization represented by“J”.
regarded as an affected item since its count shall change from
zero to nonzero.
Case 3. xTT’. This case also depends on whether x is
a primitive or generalized item. Obviously, if x is a primitive
item, there is no change on its support and so x is an unaffected
item. On the other hand, if x is a generalized item, its count
may change or not, depending on whether any of its
descendants is involved in any evolution operation of item
reclassification or membership adjustment. Recall that in (2)
the support counting of an itemset is primarily determined by
calculating the membership degree in (1). Thus we can derive
a simple rule for determining a generalized item as affected or
not, as clarified in the following lemma.
Let Q(x) and Q’(x) denote in T and T, respectively, the set
of primitive descendants of x, each along with their
membership degrees with respect to x. More specifically, Q(x)
{(y1,xy1), (y2,xy2),…, (yn,xyn)} and Q’(x){(y’1,xy’1),
(y’2, xy’2), …, (y’m, xy’m)}, where {y1, y2,…, yn} and {y’1,
y’2,…, y’m} are the descendants of x in T and T’, respectively.
Lemma 1 Consider a generalized item xTT’. If Q(x)
Q’(x), then countED(x) countED’(x), where Q(x) Q’(x)
means m n; y1 y’1, …, yn y’n; and xy1xy’1, …, xyn
xy’n.
Proof: Consider a transaction t in DB. If t supports x with
respect to ED, there exists at least one item being primitive
descendant of x in T, say d1, d2,…, di and {d1, d2,…, di}{y1,
y2,…, yn}. Likewise, if t supports x with respect to ED’, then
there must exist at least one item being primitive descendant
of x in T’, say {d’1, d’2,…, d’j} and {d’1, d’2,…, d’j}{y’1,
y’2,…, y’m}. Since m n and y1 y’1, …, yn y’n, it follows
that ij and d1d’1,…, did’i. Further,xd1xd’1,…,xdi
xd’i. According to (2), the degree that t supports x in ED is
equal to that in ED’. The lemma then follows.
Example 2 Suppose that the taxonomy in Fig. 1 is refined to
that in Fig. 5, with the inclusion of a new subcategory of
peripheral, Fax, as well as the adjusting of membership
degrees of HP Officejet. Clearly, Fax is an affected item
(Case 2). Now consider the generalized items satisfy Case 3,
i.e., Printer, Scanner, Peripheral, and PC. PC is unaffected
since it possesses the same set of primitive descendants, each
of which retains the same membership degree. However,
Printer, Scanner, and Peripheral are affected items.
Although each of them has the same set of primitive
descendants, at least one of its primitive descendants changes
the membership degree.
Fig. 5. A refined fuzzy taxonomy of T in Fig. 1.
Definition 2 For a candidate itemset A, we say A is an
affected itemset if it contains at least one affected item.
Definition 3 A transaction is called an affected transaction
if it contains at least one of the affected items with respect to a
taxonomy evolution.
B. Inference of Frequent and Infrequent Itemsets
Now that we have clarified how to differentiate the
unaffected and affected itemsets, we will show how to utilize
this information to determine in advance whether or not an
itemset is frequent before scanning the updated extended
database ED’. We observe that there are four different cases.
1) If A is an unaffected itemset and is frequent in ED, then it
is also frequent in ED’.
2) If A is an unaffected itemset and is infrequent in ED, then
it is also infrequent in ED’.
3) If A is an affected itemset and is frequent in ED, then it
may be frequent or infrequent in ED’.
4) If A is an affected itemset and is infrequent in ED, then it
may be frequent or infrequent in ED’.
Note that only cases 3 and 4 need further database scan to
determine the support count of A. Table 2 summarizes the
above discussion.
TABLE 2. FOUR CASES FOR INFERRING WHETHER A CANDIDATE ITEMSET IS
FREQUENT OR NOT.
T T’ L ED’ Action Case
 frequent no 1unaffected  infrequent no 2
 ? scan ED’ 3affected  ? scan ED’ 4
C. Algorithm FDiff_ET
Based on the aforementioned concepts, the proposed
FDiff_ET algorithm is described in Fig. 6.
First, let candidate 1-itemsets C1 be the set of items in the
new item taxonomies T’. Next derive the membership degree
among all items in C1 represented as a matrix and identify
affected items for dividing candidate itemsets. Then load the
original frequent 1-itemsets L1 and divide C1 into two subsets:

1C and

1C .

1C consists of unaffected 1-itemsets in L1, and

1C contains affected 1-itemsets, where

1C is for Cases 1 and
2, and 
1C is for Cases 3 and 4. According to Case 2, all
itemsets in 1C that is not in L is infrequent and so are pruned.
Then compute the support counts of each 1-itemset in 
1C
over only transactions that contain affected items in ED’.
After this, we create new frequent 1-itemsets 1Lby
combining 
1C and those itemsets being frequent in

1C . The
next cycle is that we generate candidates 2-itemsets C2 from
1Land repeat the same procedure until no frequent
k-itemsets kLare created.Laser HP Officejet ScanMaker
Printer Scanner
Peripheral PC
Desktop Notebook
111 1
11 0.6
Fax
1
0.2 0.2
[7] T.P. Hong, K.Y. Ling, S.L. Wang, “Fuzzy data mining for interesting
generalized association rules,” Fuzzy Sets and Systems, vol. 138, pp.
255–269, 2003.
[8] Y.F. Huang and C.M. Wu,“Mining generalized association rules using
pruning techniques,”Proc. IEEE Int. Conf. on Data Mining, pp.
227–234, 2002.
[9] M. Kaya and R. Alhajj, “Effective mining of fuzzy multi-cross-level
weighted association rules,”Proc. 16th Int. Symp. on Foundations of
Intelligent Systems, Lecture Notes in Computer Science, vol. 4203, pp.
399–408, 2006.
[10] Y.C. Lee, T.P. Hong, and T.C. Wang, “Multi-level fuzzy mining with
multiple minimum supports," Expert Systems with Applications, vol.
34, pp. 459–468, 2008
[11] F.E. Petry and L. Zhao, “Data mining by attribute generalization with
fuzzy hierarchies in fuzzy databases,”Fuzzy Sets and Systems, vol. 165,
no. 15, pp. 2206–2223, 2009.
[12] B. Shen, M. Yao, and Y. Bo, “Mining weighted generalized fuzzy
association rules with fuzzy taxonomies,” Proc. Int. Conf.
Computational Intelligence and Security, Lecture Notes in Computer
Science, Vol. 3801, pp. 704–712, 2005.
[13] R. Srikant and R. Agrawal, “Mining generalized association rules”, 
Proc. 21st Int. Conf. Very Large Data Bases, pp. 407–419, 1995.
[14] K. Sriphaew and T. Theeramunkong, “Fast algorithms for mining
generalized frequent patterns of generalized association rules,”IEICE
Transaction on Information and Systems, vol. 87, no. 3, pp. 761–770
2004.
[15] M.C. Tseng and W.Y. Lin, “Efficient mining of generalized association
rules with non-uniform minimum support,”Data and Knowledge
Engineering, vol. 62, no. 1, pp. 41–64, 2007.
[16] M.C. Tseng, W.Y. Lin, and R. Jeng,“Updating generalized association
rules with evolving taxonomies,”Applied Intelligence, vol. 29, no. 3,
pp. 306–320, 2008.
[17] M.C. Tseng, W.Y. Lin, and R. Jeng, “Incremental maintenance of
generalized association rules under taxonomy evolution,”Journal of
Information Science, vol. 34, no. 2, pp. 174–195, 2008.
[18] S. Wang, K.F.L. Chung, and H. Shen, “Fuzzy taxonomy, quantitative
database and mining generalized association rules,” Intelligent Data
Analysis, vol. 9, no. 2, pp. 207–217, 2005.
[19] Q. Wei and G. Chen,“Mining generalized association rules with fuzzy
taxonomic structures,”Proc. 18th Int. Conf. North American Fuzzy
Information Processing Society, pp. 477–481, 1999.
97年度專題研究計畫研究成果彙整表 
計畫主持人：林文揚 計畫編號：97-2221-E-390-016-MY2 
計畫名稱：從資料串流中探勘間接關聯型樣技術之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 3 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 3 30%  
研究報告/技術報告 0 0 100%  
研討會論文 3 4 50% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
