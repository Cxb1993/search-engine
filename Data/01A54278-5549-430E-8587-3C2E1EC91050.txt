中文摘要 
本研究乃延續先前研究成果，主要在與由成功大學的臨床團隊合作，以確定沈浸式虛
擬實境環境應用於自發性高血壓大鼠的過動症大鼠及比較組(WKY)之可行性。我們將由成大
協助植入式腦部單一神經元訊號電極，以配合動物活動模式的記錄及分析。首先，我們將
設計常見之五項系列選擇任務反應時間 (5CSRTT)作為本虛擬實境系統的初步印証實驗。其
次，將利用腦皮質單細胞記錄電極，找出實驗動物在相同場景中出現較高的觸發頻率的場
位細胞後。即可進行更高階認知活動的視覺流研究，並比較過動症動物之實驗組及控制組
之海馬回的場位細胞對虛擬實境對所產生的各式視覺流的敏感度，此一模型的建立將有助
空間記憶及空間認知學的研究。 
 
 本研究經由擷取腦部神經活動與虛擬活動的動物行為資訊，將幫助臨床神經科學家獲
得有效介入過動症的治療方式。將虛擬實境技術應用整合於動物實驗之中，我們可以將新
式資訊技術引進到生物科技及工程的研究領域之中，作為技職體系實用研發的一重要性突
破及深具商業價值。 
 
關鍵字：注意力缺失過動症、虛擬實境、動物行為、神經科學 
 
Abstract 
This aims of this year project is to verify the feasibility of using the immersive VR for 
ADHD animal mode of spontaneously hypertensive rat (SHR). The results obtained from SHR 
will be compared to those of Wistar Kyoto rats (WKY), performed at our collaborative lab in 
National Cheng Kung University. The neural activities by implanted wired electrodes as well as 
the animal mobility from the 5-choice serial reaction time task test and awarding approach will be 
served as initial validation for our VR system. Later, the implanted wire electrodes can be used 
for detecting the place filed cell in hippocampus. The response sensitivity of place filed cells to 
varied optical flow, generated by our VR system, can be compared between SHR and WKY 
groups for studying spatial learning scheme and cognitive map.  
Gathering the ADHD animal behavior information from neural activities could help clinical 
neuroscientists to observe their effective intervention. With the integration of VR into the 
animal studies, we can introduce the novel information technologies into the neuroscience 
research fields which is quite suitable for our technical-oriented R&D program with great 
commercialized potentials.  
 
Key word: Attention Deficit Hyperactivity Disorder, virtual reality, animal behavior, 
neuroscience 
 1
方式放置在最佳位置，並且在最佳位置後方設置攝影機進行觀看與紀錄。安置最佳位置的
老鼠上方連接著移動偵測器，移動偵測器可以測量出老鼠的移動角度與高低變化，而下方
則連動著助跑模擬器，助跑模擬器則可以測量出老鼠的移動速度，透過兩項偵測裝置即可
精確的了解實驗動物的活動狀況，並將老鼠與虛擬實境互動的情況傳送給負責處理訊號擷
取的電腦，再將訊號與虛擬實境做整合以達到同步的互動效果，並即時的將畫面投影在半
球形屏幕上，如此一來沈浸式虛擬實境系統的雛型便浮現在眼前(如圖二)。 
從以上的描述來看實驗可以建構出一個具有沈浸式虛擬實境的環境，在此系統下可以測
量出老鼠的活動情況與神經訊號的變化，並且確實的記錄老鼠與虛擬實境互動的情況。在
此，若增加溫度控制與氣味導入等其他控制條件，則可觀察在特定條件下老鼠碰到突發事
件的反應表現，如設計寒冷的天氣、惡臭的環境、引入貓兒氣味等，而在此多樣控制的系
統下觀測動物行為之研究，即成為最適合的研究環境(如圖三)。 
 
 
、文獻探討 
therland 教授首先提出「ultimate display」[5]，介紹以電腦顯示三度
空間
ry)於 1992 年時，
建立
半球形投影
30cm 
對流抽氣孔
溫溼度調節孔
氣味導入孔 
40cm
50cm 
攝影機
圖三．實驗箱結構圖 圖二．系統構想示意圖 
二
1965 年，ivan e. su
圖像的觀念。但虛擬影像在螢幕上顯示缺乏真實感，似乎還需要模擬設備來配合，因
此在 1968 年，ivan e. sutherland 建立第一個頭盔顯示器[6]，將虛擬影像與硬體設備做結合，
成功的踏出沈浸式虛擬實境的第一步，也從此打開了擬真世界的大門。 
美國的伊利諾州立大學 EVL 實驗室(Electronic Visualization Laborato
了一個沈浸式虛擬實境系統─CAVE™ (如圖四)［7］，內含三個背投影的平面屏幕以及
一個前投影螢幕的地面，以達到具有沈浸效果的投影環境，而置身在此系統中佩戴立體眼
鏡則會使虛擬場景變為更真實的立體視覺效果，環繞在四周的影像呈現出擬真的場景，讓
使用者彷彿走進了一個真實的環境裡。但本研究的實驗對象是與人類基因相似的老鼠，在
此系統環境下的老鼠，並非像人類般可以配戴立體眼鏡，而 CAVE™系統若無透過立體眼
鏡觀看，則所觀看的是個扭曲失真的場景，尤其是在屏幕接合部分失真地問題更為嚴重，
因此為了解決老鼠此問題，並且也能保留沈浸的效果，則勢必得在系統上做正確的改良與
修正。 
 3
  
 
觀察分析系統 
在此利用 NI LabVIEW
料與分析介面，由硬體設備所偵測到的動作行為及腦部活動訊號透過 NI 公司的 DAQ 擷
擷取的基本媒介，但這樣未經處理的訊號並不能直接被電腦接收使用，因
此必
研究成功建立出動物行為實驗箱，有效阻隔外界干擾，並藉由半球形屏幕的投影下，
真般效果使實驗動物於局限環境下沈浸在虛擬環境之中，動物在虛擬場景中移動被確實
過上方的感測器與下方的助跑模擬器測量實驗動物在箱內的移動訊號，
從而
觀察，系統間相互傳遞的過程也成功的達到如預
期般
圖七．模擬魚眼鏡頭處理後的虛擬場景魚眼
圖六．互動動作偵測裝置 
所提供量測與自動化之圖形化開發程式語言來建立視覺化資訊
資
取卡，來做訊號
須透過 LabVIEW 來開發設計轉換擷取程式，開發出的程式可提供訊號擷取與資料轉換
的功能(如圖八)，將擷取到的類比訊號轉換成數
位訊號，以呈現視覺化的同步訊號資料，而動
作行為訊號，透過 TCP/IP 傳輸方式，傳送資料
封包至另一台 Virtools 平台的虛擬實境視覺產
生系統電腦做同步互動處理。本研究亦以
Virtools 所提供的 SDK 自行開發其 TCP/IP 傳輸
的通訊元件，藉由自行設計出的 SDK 驅動程
式，達到資料能夠正確且快速傳遞的功能，如
此一來才能使電腦與電腦間相互連線，讓電腦
能夠將接收到互動訊號與虛擬場景做即時互
動。 
 
五、結果與結論 
本
圖八．LabVIEW 視覺化資訊資料與分析介面 
擬
的記錄下來，且透
了解實驗動物在虛擬實境觀測環境下的行為模式與腦部活動表現，進而透視其思維與
神經元活動之關聯性，一窺腦部奧秘。 
實驗動物與互動動作偵測裝置的操縱(如圖九)，使感測器得以擷取到移動訊號，將測量
到的類比訊號轉換成數位訊號後透過 TCP/IP 網路協定於電腦間傳遞，此訊號可做為互動整
合的依據，研究員並可經網路於遠端操控
的效果，並展現出系統互動整合的能力。 
 5
7. eira, D. Sandin, T. DeFanti, R. Kenyon and J. Hart, “The CAVE - audio visual 
xp. 
9. Kahana, J.B. Caplan, T.A. Fields, E.A. Isham, E.L. Newman, and I. Fried, 
 
rs”, Neuroscience, vol.109, pp. 767-772, 2002. 
12.  and M. E. Hasselmo, “Modeling 
14. 術諮詢總會通訊，第十
15. 白朮對老化促進小白鼠學習記憶能力影響研究＂，
 
C. Cruz-N
experience automatic virtual environment”, Communications of the ACM, Vol. 35, No. 6, 
1992, pp. 65-72. 
8. N. Burgess, “The hippocampus, space, and viewpoints in episodic memory”, Q. J. E
Psychol., vol. 55A, pp.1057-1080, 2002. 
D. Ekstrom, M.J. 
“Cellar networks underlying human spatial navigation”, Nature, vol. 425, pp. 184-187, 
2003. 
10. C. Harmon, T. O. Moore, K. L. Huhman, and H. E. Albers, “Social experience and social 
context alter the behavioral response to centrally administered oxytocin in female syrian 
hamste
11. M. E. Hasselmo, J. Hay, M. Ilyn, and A. Gorchetchnikov, “Neuromodulation, theata rhythm 
and rat spatial navigation”, Neural. Netw.,vol.15, pp. 689-707,2002. 
R. A. Koene, A. Gorchetchnikov, R. C. Cannon,
goal-directed spatial navigation in the rat based on physiological data from the 
hippocampal formation”, Neural. Netw.vol.16, pp. 577-584, 2003. 
13. E.R. Wood, and P. A. Dudchenko, “Aging, spatial behavior and the cognitive map”, Nat. 
Neurosci., vol. 6, pp. 546-548, 2003. 
孔祥智，“以突變鼠為工具來研究人類疾病＂，中央研究院學
二卷，第二期，中華民國九十三年二月一日 
王銘富，杜易潔，賴貞秀，黃克峰，“
中醫藥雜誌，第十四卷，第四期，民國九十二年十二月 
 7
式以壁報發表 (Poster Sessions) 為主，約近 100 篇論文發表。 
 
此次壁報發表之論文為“Development of Virtual Reality Environment for 
Behavioral Study of Rats” H. Y. Lee, M. D. Kuo, Y. S. Ou-Yang, J. J. J. Chen 
 
 
本會期的主題範圍幾乎含蓋所有腦神經科學及認知醫學研究領域，主題有 
(1) Nervous system plasticity; 
(2) motor control;  
(3) Neurological disorders and disease;  
(4) motor control and motor dysfunction;  
(5) Auditory and vestibular systems;  
(6) Modeling and computer-based approaches;  
(7) reward and addition;  
(8) brain and behavior。 
 
下列五大主題與現有研究關係密切 
(1) 帕金森症大白鼠模型之建立:帕金森症大白鼠成為常用的動物模型。為了不同
的研究目的，目前有暫時性或稱急性（transient or acute）及慢性(chronic)的動物
模型。選擇性多巴胺 D2 拮抗藥（selective dopamine D2 antagonist），如 raclopride，
及治療精神病的藥物（antipsychotic drug），如 haloperidol、chlorpromazine 等，
可以經由皮下或腹膜注射造成大白鼠暫時性的肌肉僵直(muscle rigidity)。其症狀
出現的時間經由腹膜注射約需十五分鐘，經由皮下注射則需約一個小時；持續的
時間則與注射的量有關可維持二到五個小時（2.5 mg/Kg～10 mg/Kg）。這樣誘導
的方式並非實際傷害釋放多巴胺的神經細胞，不會危害到動物的性命及健康。
6-OHDA 是類神經傳導物質，除了消耗神經末稍的正腎上腺素存量，也會造成釋
放多巴胺之神經元死亡造成腦中多巴胺濃度的下降，常用於建立慢性（chronic）
帕金森氏症的動物模型。由於 6-OHDA 無法穿透血腦屛障（blood-brain barrier，
BBB），所以通常都直接注入腦組織，如 substantia nigra、medial forebrain bundle
或是 striatum。其中經由破壞 striatum 可造成漸進逆行性的中樞釋放多巴胺神經
的死亡，引發帕金森氏症的症狀，如姿態及步態的異常、動作不能等等。單側注
射 6-OHDA 破壞單側多巴胺系統造成 hemiparkinsonism 動物模式克服了雙側注
射術後大白鼠照護的困難是目前研究常採用的方式。 
 
 9
現的圖像和立體圖像進行反應及辨認上是有幫助的。近幾年來，無論國內外
的認知治療或教育機構以電腦這項科技性的工具提供一個虛擬的治療性環境
將這些治療的方式加以應用，利用虛擬實境系統提供各式場景，給予受測者
各種不同模擬情境的認知活動；患童可以利用虛擬實境系統之週邊感知虛擬
實境系統之建立不但可整合 VEP 訊號與 MRI 影像，，所建構的模型結構與顯
示法也可應用於腦部的手術模擬，兼具臨床與實用的價值。視覺誘發電位
(VEP)為臨床常用之誘發電位檢查之一。主要用途在於偵測視覺路徑上可能之
病灶。通常臨床上只注意記錄到的訊號延遲(delay)是否正常以及波形是否正
常，對於訊號出現的位置則無法精確的定位，因此只能粗略的知道視覺路徑
有病灶。假如能夠精確的定位，則對於疾病的症狀能有更準確的掌握。Single
Trial 的 VEP 訊號即時擷取在近年來已是相當熱門的研究課題，而結合生醫
訊號與醫學影像的構想目前才方興未艾。尤其是包含時空訊息的 VEP 訊號更
是迫切需要視覺化的顯示。利用虛擬實境顯示系統的建立多種類物體彩色透
明化的顯示，本會議提出了許多新的構想，對應法以完成不同色彩與透明度
的快速顯示，以虛擬實境方式建構 Optical flow 及各式視覺的刺激的方式，
以便實驗者調整所喜好的刺激方式，以達到最佳及更真實的視覺效果。 
 
(5) 肌肉張力的評估: 肌肉張力表現與肌肉所處的長度或被被動牽張速度相
關，由於肌肉的長度在活體時並無法測得，取而代之其相關關節所處的位置
反應了肌肉當下所處的長度。因此在肌肉張力的量測系統中，除了反應的阻
力（reactive resistance）外，關節瞬時角度也是重要的擷取參數，由關節角度
除了反應肌肉長度，另外也可以提供動作時的速度。除了在生物力學的表現
之外，肌肉張力尚與調變其的反射相關。由於這個因素，肌電訊號也是評估
的參數之一。在大白鼠後肢上進行肌肉張力的量測，其面臨的困難在於其肢
體較小，相對所使用的夾具必須更加輕巧，另外所選用的力量或力矩量測感
測器無論是範圍或是體型需微小化。可採用充足氣體的氣球作為量測反應阻
力的感測器，其輕巧且敏感的特性符合了在大白鼠模型後肢進行張力量測的
需求。在大白鼠後肢的背側及腹側皆有氣球進行雙向運動（plantarlfexion 及
dorsiflexion）的反應阻力擷取，一改先前只能量測單方向反應阻力（extensor
或 flexor）的不足。此外利用光學感測器量取角度的變化值，與反應阻力的輸
出值做相位比較，以得到關節動態被動牽張時肌肉張力的變化。 
 
 在大白鼠後肢量測肌電圖的活動探討神經反射的影響，表面多點電極以其獨
特具有的小擷取面積（約 0.2 平方公釐）及多點（6 點）所提供的空間解析度，
被選為所使用的電極。他克服了一般盤狀電極（disc electrode）量測時只能擷
取到多群動作神經元興奮加總起來的電訊號及 cross-talk 的缺點，另外也避免
 11
  13
I. Introduction 
Most virtual reality environments are primarily visual experiences, displayed either on a 
computer screen or through special stereoscopic displays, but some simulations include additional 
sensory information, such as sound through speakers or headphones. Some advanced and 
experimental systems have included limited tactile information, know as haptic force feedback. In 
immersive VR, the user becomes fully immersed in an artificial, three-dimensional (3D) world 
that is completely generated by a computer. An immersive virtual environment may be displayed 
on head-mounted display (HMD), Cave Automatic Virtual Environment (CAVE), or VisionDome. 
The HMD is a device to provide its wearer with an immersive experience. A typical HMD 
houses two miniature display screens and an optical system that channels the images from the 
screens to the eyes, therefore, presenting a stereo view of a virtual world. A motion tracker 
continuously measures the position and orientation of the user's head and allows the image 
generating computer to adjust the scene representation to the current view. As a result, the viewer 
can look around and walk through the surrounding virtual environment. However, in order to 
overcome the often uncomfortable intrusiveness of HMD, alternative concepts (e.g., CAVE and 
VisionDome) for immersive viewing of virtual environments were developed. The CAVE 
provides the illusion of immersion by back-projecting onto the three walls of a room-sized cube, 
and projecting from above onto the floor. A head tracking system continuously adjusts the stereo 
projection to the current position of the leading viewer. The VisionDome is the world's first fully 
immersive multi-user, single projection VR environment for interactive space development. Upon 
entering the VisionDome, users are completely drawn into a fully immersive 180 degree 
hemispheric screen. The tilted screen is positioned so as to fill the users’ field-of-view as well as 
creating an incredible sense of immersion. Users experience vivid images which take on depth 
via the unique optical system. The VisionDome is further enhanced by an environmental sound 
system. 
 
 15
virtual environment for studying spatial learning [19]. For insects, the virtual environments pass 
through LCD projector, which were projected onto a rear-projection dome screen (66 cm 
diameter) and occupied 250 degree of the moth’s field of view. The position of the abdomen was 
monitored by an optical sensor that fed into PC for controlling the virtual scenes. The wind 
source produced pheromone, was placed in front of the head of the moth. An infrared video 
camera was placed above and slightly behind the moth to record abdominal ruddering and wing 
kinematics during tethered flight. The results indicated that the insect was able to navigate 
through the simulated environment and produce flight tracks in response to presentation of 
pheromone that resemble those observed in free flight [20]. 
Moreover, it has been demonstrated that rodents could navigate in VR environments for 
covering a large area of the visual field but did not need high resolution and luminance. A VR 
set-up developed by Hölscher et al. [21] that covers a large part of the rat’s visual field (360° of 
azimuth, –20° to +60° of elevation). The animal ran on top of an air-cushioned polystyrene 
sphere. Any translational movement of the animal leaded to a rotation of the sphere, which was 
monitored and fed to the PC that controlled the generation of the VE. The VE was rendered and 
presented to the animal in a closed action-perception loop. The rats could indeed be accustomed 
to this VR system and successfully navigated in various environments for sugar water rewards. 
Furthermore, the rat navigated in virtual environments which were a simulated radial arm maze 
by using Hölscher et al.’s device [21]. The tetrodes of electrodes each were implanted in area 
CA1 of the hippocampus of rat in order to study the contributions of visual, vestibular and motor 
information to place cell development in detail. The visual stimulus was adapted to the large 
visual field of rats, can be easily manipulated and well controlled and be allowed to study the 
orientation of rats in large environment [21].  
With recent new wave of bio-technology and bioengineering development, the demands for 
animal studies, pharmaceutical drug test, behavior neuroscience, and cognitive science have 
increased progressively. In various aspects of clinical studies, more and more animal experiments 
 17
II. Materials and Methods 
(A) Overall architecture of integrated VR system 
In this study, we adopted the immersive VR by using only a single LCD projector to project 
the 3D scene into hemisphere screen. The testing animal was partially constrained on the 
treadmill at optimal view point in the immersive environments. This eliminates the needs of extra 
position tracking device or 3D eyeglasses. The intentions of animal were detected by body 
position detection pass though analog circuit and DAQ card which fed to PC for storage and 
display. For VR display, the body positions were sent to VR system that controls the generation 
of the virtual environments by using TCP/IP transmission in real time. The animal experiment 
could be worked in an animal cage that possessed the capability of sound proof environment. The 
video camera was able to monitor the movements of animal which were stored in PC for further 
off-line analysis. 
 
Figure 1. The overall structure of integrated VR system 
(B) Immersive VR system for animal study 
The immersive VR system consists of LCD projector, dome screen and PC, as shown in 
Figure 2. The main feature of LCD projector (EMP-TW20, EPSON) is able to project onto the 
 19
3D scenes were projected onto the rear-projection dome screen to interact with the sensing 
positions of rat.  
    
(a)                                   (b) 
Figure 3. VR scenes for (a) optical flow and (b) checkerboard stimulation patterns 
(C) Treadmill system with body position sensing 
Table 2.1 Specifications of the animal treadmill system for rat 
 Our Treadmill Design 
Running area/ way 350mm * 120mm 
Speed 7 kph (kilometers per hours) 
Deck 9 mm thickness plywood with pre-waxed surface 
Belt Poly Urethane High Density Conductivity 
Rollers 38.1 mm rollers with 6001ZZ ball bearing 
Max. Loading 1 Kg 
Inclination +8.5 degrees 
 
Table 2.1 lists the specifications of animal treadmill system for rat. The size of the treadmill 
is 407 × 350 × 205 mm, which is designed for rat behavior study. The treadmill is constructed out 
of two zinc coated steel plates, two steel rollers, a medium density fiberboard and two DC motors. 
The smaller motor controls the inclination angle of the treadmill at positive and negative slope. 
The larger motor controls the speeds (movement) of the nylon belt. The running area is 350 by 
 21
Meanwhile, the behavior of the animal during an experiment was monitored by a Marlin F-033C 
video camera (Allied Vision Technologies Inc., Marlin, Germany) operating at 30 frames per 
second (a shutter speed of 33ms). The camera was mounted behind and slightly above the animal 
which allowed experimenter to observe the locomotion of rat without any interference to rat’s 
visual field. 
 
(D) Transmission between immersive VR and body position sensing 
The body position sensing data was displayed on a GUI programmed in LabVIEW software. 
The rotary and elevation angles were translated into the strings which sent to the immersive VR 
system via TCP/IP transmission. The TCP/IP communication was operated in a protocol of stack 
processing at the termination nodes in a client and server modes. The server system was 
programmed using LabVIEW software to sense the body position and send the signals to client 
for processing immersive VR display. When the body position system sends data to the 
immersive VR system by a TCP/IP connection, the immersive VR system would establish a 
connection with destination host. Moreover, the Virtools SDK (Software Development Kit) is a 
set of development tools for accessing to all the functionalities used in Virtools applications 
which enables us to write software components from direct use of these functionalities. Therefore, 
we programmed the SDK using C programming embedded in the Virtools as a client system to 
receive the signals from body position sensing. This configuration produced interactive 
environments at a rendering 30 frames of per second. 
(E) Establishment of animal VR cage for behavior study 
Figure 4 shows the design of the animal cage for behavioral study. The whole device is 
assembled by three components, including body position sensing, outer cage and treadmill 
modules. The front hemisphere screen connects to the outer cage in one-degree-of-freedom 
(1-DOF) for pitch rotating which ensures the animal is constrained at optimal view point during 
the experiment. The treadmill module was fixed at the bottom of the cage. A sliding pole 
 23
synchronization of the video of the simulated environment, behavioral video and physiological 
data. 
    In our system, the lag time occurred between the start of body movement to initiation of a 
change in VR scenes. This experiment aimed to quantify the delay time in order to verify the 
feasibility of the integrated VR system for animal study. In this experiment, we swing the rigid 
links which connect with the rotary position sensor to alter the yaw angles. The yaw angles were 
changed within -20 to 20 degree or -40 to 40 degree cases The swing frequency for rat was 
appropriately between 0.5 and 1 Hz. Thus, the simulation swing frequency were set at 0.5 and 1 
Hz by using computer metronome during this experiment. The VR scenes was the optic flow 
pattern after adding a feature of “A” in the center for accurately localizing the center position of 
scene. The video and data sensing from VR scenes and the shift of the yaw angle were recorded 
in PC for Matlab off-line analysis. 
 
III. Results 
(A) The integrated VR system for animal behavioral study 
    The hardware modules of our integrated VR system includes three major parts: (1) VR 
generating system with PC, LCD projector, and dome; (2) body position sensing device with 
positioning sensors inside the animal cage, signal acquisition unit connecting to a PC, and (3) 
video acquisition and camera monitoring system placed at the back of animal cage. 
The hemisphere screen with diameter 457 mm was made up by acrylic materials. The Screen 
Goo is a specially formatted, highly reflective acrylic paint, designed specifically for the video 
projection industry. In addition, Screen Goo acrylic paint allows one to transform any smooth 
paintable surface into a high performance projection screen. The internal surface of dome was 
coated with Screen Goo acrylic paint in order to transform dome to be a high fidelity of 
projection screen. The hemisphere screen connects the front of outer cage, which allows 1-DOF 
pitch rotating. 
 25
is used to grab the video for monitoring the locomotion of rat. The video camera operated at 30 
frames per second with a shutter speed of 33ms. The pixel depth was set to be 8-bit gray level at 
640 × 480 pixels of image size. 
 
(B) Example of animal position sensing data 
The testing animal was constrained on the treadmill at optimal view point in the immersive 
environments during treadmill activity. The VR environments were simulated the optic flow 
stimulation. In this condition, turning direction was presented as rotation of the yaw angle either 
clockwise (left turn) or counterclockwise (right turn). Upward and downward turns of rat and 
rotations were represented as negative or positive DC offset, which were digitized and recorded 
on a continuously sampled channel along with the time stamps of synchronization pulses. The 
movements of the rat’s body drove changes in the heading and rotation of simulated environment. 
Figure 5 are sample data showing that the movement of the rat produced turns in the optic flow 
environment. Data from this example were from an experiment designed to test the effects of 
reversing the polarity of the body position feedback. Thus, movements of the rat’s trunk to the 
right produced a left turn in VR environment. In addition, the sensing data were translated into 
frequency domain to observe the rhythmic movement of rat, as shown in Figure 6, which 
indicated the swing frequency for rat was appropriately 1 Hz. Nevertheless, these data clearly 
demonstrate the ability of the rat to walk in VR system. 
 27
 
Figure 6. The frequency distribution of (a) rotation and (b) weight sensing data when rat walked 
on a treadmill. 
 
Figure 7. Matlab GUI for observing the sensing data and video of synchronization, the video 
image corresponds to the middle of sensing data, and the display of data is within 10 seconds. 
Integration of video and position sensing data are in Matlab GUI for off-line analysis, as 
shown in Figure 7. The parameters include data sampling rate and view points which were setting 
 29
 IV Discussion and Conclusion 
In this study, a rear projected VR with positioning detection as feedback for alternating 
display has been established. During the initial animal behavior trial, the rats exhibited 
characteristic turning pattern in response to imposed rotations of the visual environment (Fig. 3.8). 
The locomotion of the rats produced specific pattern during treadmill walking. Our results 
indicated that the locomotion pattern changes in yaw angles between -20 to 20 degree at a 
frequency between 0.5 to 1 Hz. Therefore, this kinematic range was adopted in our validation 
tests for evaluating the lag time between the positioning data and those acquired from video 
display which might be caused by LabVIEW acquisition software and TCP/IP transmission. The 
lag time was around 180-270 ms which should be taken into consideration during future design of 
using VR as a visual stimulation for rats. 
During VR displaying, our system did not address the exact relationship between body 
ruddering and turning in the real world acquired from position sensing device and the visual 
scenes from VR display. Our approach was based on constraints determined by the maximum 
excursion of the body during tethered ruddering as well as the maximum rotational visual flow 
(clockwise or counterclockwise) produced by the software. Although it is possible for our system 
to match the visual adaptability to variable coupling constants by adjusting the sensitivity in the 
Virtools softwarem the exact relation might be difficult to evaluate from varied position of rats. 
Our current design presents the rat with video images rendered at 30 frames/s, which, given the 
flicker fusion frequency of the rat’s eye at the light levels we used 30-84 lux is sufficient to 
produce a smooth visual flow for this particular preparation [26, 27]. 
In comparison with our system to roaming global approach designed by Hölscher et al.’s 
device [21], our current configuration does not allow the rat to change its x axis. Our approach 
utilized the treadmill which required less space and achieved an immersive environment by using 
only a single LCD projector to project onto dome screen. However, the treadmill produces 
 31
Neurosci. 111, 937-954, 1997. 
[7] D. Gaffan, “Idiothetic input into object-place configuration as the contribution to memory of 
the monkey and human hippocampus: a review,” Exp. Brain Res. 123, 201-209, 1998. 
[8] C. Hölscher, “Time, space, and hippocampal functions,” Rev. Neurosci. 14, 253-284, 2003. 
[9] R. A. Robb, B.M. Cameron, and S. Aharon, “Efficient shape-based algorithms for modeling 
patient specific anatomy from 3D medical images: applications in virtual endoscopy and 
surgery, Shape Modeling and Applications,” Proceedings of Shape Modeling and 
Applications, pp. 97-108, Aizu-Wakamatsu, Japan, March 3-6, 1997. 
[10] B. Barnes, A. S. Menon, R. Mills, C. D. Bruyns, A. Twombly, J. Smith, K. Montgomery, and 
R. Boyle, “Virtual reality extensions into surgical training and teleportation Information 
Technology Applications in Biomedicine,” 2003. 4th International IEEE EMBS Special 
Topic Conference on 24-26 April 2003 Page(s):142 – 145. 
[11] N. G. Kim, C. K. Yoo, and J. J. Im, “A New Rehabilitation Training System for Postural 
Balance Control Using Virtual Reality Technology,” IEEE Transactions on Rehabilitation 
Engineering, 7, No. 4, 482-485, 1999. 
[12] C. G. Song, J. Y. Kim, and N. G. Kim, “A New Postural Balance Control System for 
Rehabilitation Training Based on Virtual Cycling, IEEE Transactions on Information 
Technology in Biomedicine, 8, No. 2, 200-207, 2004. 
[13] N. Burgess, E. A. Maguire, and J. O'Keefe, “The human hippocampus and spatial and 
episodic memory,” Neuron. 35, 625-41, 2002. 
[14] J. P. Wann, S. K. Rushton, M. Smyth, and D. Jones, “Virtual environments for the 
rehabilitation of disorders of attention and movement. In G. Riva, (Ed.), Virtual Reality in 
Neuropsycho-physiology: Cognitive, Clinical, and Methodological Issues in Assessment and 
Rehabilitation Amsterdam: IOS Press, 157-164, 1997. 
[15] R. S. Astur, L. M. Ortiz, and R. J. Sutherland, “A characterization of performance by men 
 33
