2行政院國家科學委員會專題研究計畫成果報告
智慧型動態與複雜背景之物體與人臉偵測的安全監視系統
(II)
Intelligent Surveillance System of Motion and Face Detections
in Complex and Dynamic Backgrounds (II)
計 畫 編 號：NSC97-2221-E-211-007
執 行 期 限：97 年 08 月 01 日至 98 年 07 月 31 日
主 持 人：陳佑冠 華梵大學電子系
計畫參與人員：舒御威 華梵大學電子系
一、摘要
人類膚色應用在影像中的人類識別偵測
上，是為非常有效的特徵，而正確的人類膚色
分區，有助於後續之人臉偵測、手勢偵測分析
與標的影像過濾等之辨識系統的準確率。在正
常的光線下，影像中的膚色灰階值會介於一定
的區段範圍內，但是當要被辯識的影像有過暗
或曝光不足的情況時，一般的膚色判定方法大
都無法適用。本篇論文利用影像增強的技巧，
將這些過暗或曝光不足的影像增強，使其膚色
轉換至可被偵測出的範圍，進而正確的將含有
膚色區域找出來。實驗結果證明所提出之演算
法，確實可正確的將這些過暗或曝光不足的影
像之人類膚色的區域找出來。因此可以廣泛應
用在光源不佳或夜間的影像自動監視系統
中，以增加其警報之正確率。
關鍵詞：覺膚色分區，人臉偵測，手勢偵測，
增強影像，對比度展延，影像自動監視
系統
Abstract
In normal light, the range of humanity's
skin color is usually lying within an interval.
When an input image is too dark or insufficient
exposure, the range of its skin color is outside
the interval of humanity's skin color and it will
result in the error detections for the previous
algorithms. By using the image enhancement to
the image with dark or insufficient exposure, the
range of its human’s skin color is converted to
the detectable range of humanity's skin color.
Then, the correct regions of the skin color are
found. Experiments are carried out for some
samples to demonstrate the computational
advantage of the proposed method. Therefore,
the proposed algorithm can be easy used in the
intelligent image surveillance systems.
Keywords: skin segmentation, face detection,
hand gesture analysis, image enhancement,
contrast extended, image surveillance
system
二、報告內容
1. Introduction
The humanity's skin color in an image is
not only affected by the light sources and the
related environment factors, but also affected by
the different race like Caucasian, the person of
Asian descent, the melanoderm and so on. In the
processes of the human recognition and human
detection, the first important step is the
humanity's skin segmentation. Human’s skin 
segmentation stands for finding the regions with
the humanity's skin color in an image. With the
correct skin segmentation, the procedures of the
face detection [1][2], hand gesture analysis [3],
and objectionable image filtering [4] are then
reaching the higher accuracy.
4Figure 1. The original image of IMG-1.
Figure 2. The humanity's skin color regions found by
WY-RGB [7] for image IMG-1.
HSV color representation uses hue,
saturation, and value to represent color. It can be
derived from the RGB color representation with
an angle , maximum, and minimum functions.
The variable angle  is









 
))(()(
))()((5.0
2
1
BGBRGR
BRGR
COS .
Then the hue H is expressed as





GBif
GBif
H
,360
,


.
The saturation S is
   
 BGRMax
BGRMinBGRMax
S
,,
,,,, 
and the value V is
 
255
,, BGRMax
V  .
Based on the H, and S in HSV color
representation, Sobottka and Pitas [13] proposed
a humanity’s skin segmentation in 1998. Their
definitions of skin color are in the ranges of
500 H and 68.032.0 S . We use SP
[13] to represent this method. By adding the
value V to the SP [13]’s method, Wang and
Yuan [7] proposed a humanity’s skin
segmentation in 2001. We use WY-HSV [7] to
represent this method. WY-HSV [7]’s method
defines thehumanity’s skin color lied within the
intervals 500 H , 68.020.0 S , and
0.135.0 V . With applying the methods of
SP [13] and Wang-RGB [7] for image IMG-1,
Figures 3(a) and 3(b) show the results of skin
segmentation by using the methods of SP [13]
and WY-RGB [7], respectively. By comparing
the results of Figure 2 and Figure 3, it is obvious
to see that the methods in HSV are better than
that of the method in RGB. Since the
relationship between hue, saturation, and value
is small, mutual disturbance of hue, saturation,
and value is lower than that of RGB and that
results in good effect of skin segmentation.
From the transformation equations of HSV, they
are more complexity than that of RGB.
Therefore, the methods of HSV will take more
time than that of RGB. From Figures 3(a) and
3(b), it is found that the result of skin
segmentation in Figure 3(b) is better than that of
Figure 3(a). However, there are lots of error skin
segmentation in the backgrounds of both
methods.
(a)
6original image and the normalized enhancement
image, respectively. The normalized gray values
of r(x, y) and s(x, y) are within interval 0 and 1.
We have
255
),(
),(
yxf
yxr  and
255
),(
),(
yxg
yxs  .
On the other hand, g(x,y) is derived from the
integer of s(x, y) multiplied 255, that is,
 255),(),(  yxsyxg .
Assume Tm is the mean value of the
normalized original image r(x, y). The
power-law equation [21] used in the proposed
algorithm for enhancement the original image is
 






E
T
yxr
m
yxs
),(
1
1
),( , (1)
where E is a positive constant andδ is a smallest
positive constant. In order to avoid r(x, y) equal
to zero, it is necessary to add a small constant δ
to r(x, y).
Let  yxfR , ,  yxfG , , and  yxfB , be the
gray levels of R, G, and B in  yxf , ,
respectively. Then the normalized gray levels
 yxrR , ,  yxrG , , and  yxrB , are
255
),(
),(
yxf
yxr RR  ,
255
),(
),(
yxf
yxr GG  ,
and
255
),(
),(
yxf
yxr BB  ,
respectively. The mean values Rm , Gm , and
Bm of the normalized gray levels  yxrR , ,
 yxrG , , and  yxrB , are
MN
yxr
m
M
x
N
y
R
R





1
0
1
0
),(
,
MN
yxr
m
M
x
N
y
G
G





1
0
1
0
),(
,
MN
yxr
m
M
x
N
y
B
B





1
0
1
0
),(
.
The total mean Tm is
)(
3
1
BGRT mmmm  .
Let  yxsR , ,  yxsG , , and  yxsB , be the
normalized gray levels of R, G, and B in s(x, y),
respectively. Based on the power-law equation
(1),  yxsR , ,  yxsG , , and  yxsB , are
expressed as
 






E
R
T
R
yxr
m
yxs
),(
1
1
),( ,
 






E
G
T
G
yxr
m
yxs
),(
1
1
),( ,
 






E
B
T
B
yxr
m
yxs
),(
1
1
),( .
With multiplication s(x, y) by 255, the
enhancement output image g(x, y) is then
derived. Finally by using HD [16] to find out the
skin color regions, the proposed algorithm is
then derived. Let b(x, y) be the binarization
image of skin color segmentation. If f (x, y) is
classified as a skin color pixel, then b(x, y) is set
to 1. Otherwise, b(x, y) is set to 0. Then the
proposed skin segmentation is expressed as
followers.
Algorithm of Adaptive Power-Law Skin
Segmentation
Input: f (x, y)
Output: b(x, y)
1. Derive normalized image r(x, y) from f (x,
y).
2. Calculate the total mean Tm of r(x, y).
8original input image is classified as an image
which is too dark or insufficient exposure.
Through Figures 7(a) to 7(l) are some original
input images named IMG-3, IMG-4, IMG-5,
IMG-6, IMG-7, IMG-8, IMG-9, IMG-10,
IMG-11, IMG-12, IMG-13, and IMG-14,
respectively. All of these images are too dark
and have their value of Tm lessen than 0.2. The
values of total mean Tm for images IMG-3,
IMG-4, IMG-5, IMG-6, IMG-7, IMG-8, IMG-9,
IMG-10, IMG-11, IMG-12, IMG-13, and
IMG-14 are 0.1531, 0.0899, 0.1010, 0.1796,
0.0964, 0.0721, 0.1018, 0.1008, 0.1168, 0.1601,
0.1061, and 0.0522, respectively. It is found that
the darker image has the smaller the value of
Tm . Therefore, the threshold 0.2 of Tm is used
in the proposed algorithm to determine the input
original image is dark or normal.
(a) (b) (c)
(d) (e) (f)
(g) (h) (i)
(j) (k) (l)
Figure 7. Original dark images named (a) IMG-3, (b)
IMG-4, (c) IMG-5, (d) IMG-6, (e) IMG-7, (f) IMG-8,
(g) IMG-9, (h) IMG-10, (i) IMG-11, (j) IMG-12, (k)
IMG-13, and (l) IMG-14.
If the total mean Tm of an input image is
greater than 0.2, the original input image is
classified as an image with normal exposure and
the image enhancement with power-law
equation is not necessary for this input image.
Figures 8(a) to 8(l) show some original input
images with normal exposure and they are
named as NOR1, NOR2, NOR3, NOR4, NOR5,
NOR6, NOR7, NOR8, NOR9, NOR10, NOR11,
and NOR12, respectively. The values of total
mean Tm for images NOR1, NOR2, NOR3,
NOR4, NOR5, NOR6, NOR7, NOR8, NOR9,
NOR10, NOR11, and NOR12 are 0.2252,
0.2410, 0.3028, 0.3331, 0.3792, 0.4088, 0.4142,
0.4382, 0.4615, 0.4727, 0.5478, and 0.5727,
respectively. All of the total means Tm of these
image are greater than 0.2.
(a) (b) (c)
(d) (e) (f)
(g) (h) (i)
(j) (k) (l)
Figure 8. Original normal images of (a) NOR1, (b)
NOR2, (c) NOR3, (d) NOR4, (e) NOR5, (f) NOR6,
(g) NOR7, (h) NOR8, (i) NOR9, (j) NOR10, (k)
NOR11, and (l) NOR12.
There is another threshold E required to be
determined in the power-law equation of the
proposed algorithm. By using the power-law
equation with different values of E to convert
the image IMG-2, Figures 9(a) to 9(i) show the
enhancement images with E=0.1, E=0.5, E=1,
E=2, E=3, E=4, E=5, E=6, and E=10,
respectively. The enhancement images become
fuzzy when the values of E are smaller, such as
Figures 9(a), 9(b), and 9(c). On the other hand,
the enhancement images become black and
orange if we use the larger values of E, such as
Figures 9(g), 9(h), 9(i). Since the skin color in
Figure 9(d) is closest to the humanity's skin
color, we have the best value of E equal to 2.
Figures 10(a) to 10(i) show the skin color
images with implementations of the proposed
10
Table 1. Skin color images of methods compared.
name ProposedAlgorithm HD [16] CN [14] SP [13] WY-RGB [7]
IMG-3
IMG-4
IMG-5
IMG-6
IMG-7
IMG-8
IMG-9
IMG-1
0
IMG-1
1
IMG-1
2
IMG-1
3
IMG-1
4
12
Electronics (IEEE ISIE 2009), pp. 775-778, July
5-8, Seoul, Korea 2009. (EI)
[R2] Yu-Kumg Chen, Tung-Yi Cheng, and Shuo-Tsung
Chiu, “Motion Detection with Using Theory of
Entropy,” in the proceedings of the IEEE
International Symposium of Industrial Electronics
(IEEE ISIE 2009), pp. 1889-1892, July 5-8, Seoul,
Korea 2009. (EI)
[R3] Fan-Chei Cheng, Yu-Kumg Chen, and Kuan-Ting
Liu, “An Efficient Gray-level Clustering
Algorithm for Image Segmentation,”in the IEEE
proceedings of the International Asia Conference
on Informatics in Control, Automation and
Robotics (CAR2009), pp. 259-262, February 1-2,
Bangkok, Thailand, 2009. (EI)
[R4] Yu-Kumg Chen, Tung-Yi Cheng, and Shuo-Tsung
Chiu, “Motion Detectionwith Entropy in Dynamic
Background,” in the IEEE proceedings of the
International Asia Conference on Informatics in
Control, Automation and Robotics (CAR2009), pp.
263-266, February 1-2, Bangkok, Thailand, 2009.
(EI)
[R5] Fan-Chei Cheng and Yu-Kumg Chen, "Effective
Σ–Δ Background Estimation for Video
Background Generation," in the IEEE proceedings
of the First International Workshop on Multimedia,
Information Privacy and Intelligent Computing
Systems (MPIS2008), pp. 1315-1321, December
9-10, Jiaosi, Yilan, Taiwan, 2008. (EI)
[R6] 邱毅鴻, 陳佑冠,“基於影像增強的新膚色偵測
演算法之研究,” 華梵大學機電工程學系碩士
學位論文, 2009.
四、計畫成果自評
計畫成果之內容主要發現乘冪率轉換的
方程式，可將過暗影像裡的膚色區域灰階值轉
換至可被一般不需透過訓練膚色分區方法能
偵測出膚色的值，如此便可將過暗影像裡的膚
色區域找出來。計畫成果之內容與原計畫相符
合，甚至還超出原計畫之內容，並且達成預期
目標。研究成果極具學術與應用之價值，是適
合在 SCI 所收錄之學術期刊發表，如果將之應
用在日常生活的監控環境下，或許可以申請專
利。
