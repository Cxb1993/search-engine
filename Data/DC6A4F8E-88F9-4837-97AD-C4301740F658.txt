developed predictor, a stochastic gradient algorithm, together
with the parameter convergence properties, for identifying the
parameters of the optimal one-step ahead predictor are given
in Section 3.4. Adaptive minimum variance control design is
discussed in Section 3.5. Stability and tracking performance of
the adaptive minimum variance fuzzy control system are proved
in Section 3.6. Simulation study is discussed in Section 3.7.
Conclusions and discussions are given in Section ??.
Notations and Deﬁnitions
Let ‖x‖ be the Euclidean norm of a vector x. Let A(q−1) be
a polynomial with A(q−1) =
n∑
i=0
aiq
−i. The companion matrix
ΞA associated with the polynomial A(q−1) is deﬁned as
ΞA =
[
0(n−1)×1 In−1
−an −an−1 · · · −a1
]
三、研究方法及成果
A. System modeling and problem formulation
The i-th rule of the considered stochastic fuzzy T-S ARMAX
model is given by:
Plant Rule i:
If
z1(k) is Fi1 and z2(k) is Fi2
and · · · · · · and zg0(k) is Fig0
Then
Ai(q−1)y(k + 1)
= Bi(q−1)u(k) + Ci(q−1)w(k + 1)
(1)
for i = 1, 2, ..., L, where Fij is the fuzzy set, z1(k), z2(k),
· · · , zg0 (k) are the premise variables, and L is the number of
if-then rules. Polynomials Ai(q−1), Bi(q−1), and Ci(q−1) are
deﬁned, respectively, as follows
Ai(q−1) = ai0 + ai1q−1 + ......+ ainq−n, ai0 = 1
Bi(q−1) = bi0 + bi1q−1 + ......+ bimq−m,
Ci(q−1) = ci0 + ci1q−1 + ci2q−2 + ......+ cilq−l, ci0 = 1
(2)
for i = 1, 2, ..., L, where q−1 denotes the delay operator, i.e.,
q−1y(k) = y(k − 1). Without loss of generality, Ci(q−1) can
be taken to have roots inside the unit circle [9][10]. y(k) is
the output measurement, u(k) the control input, and the noise
process w(k) will be taken to satisfy the following assumptions
[9][10]:
E[w(k + 1)| zk] = 0, a. s. (3)
E[w2(k + 1)| zk] = σ2w, a. s. (4)
lim sup
N→∞
1
N
N∑
k=1
w2(k) ≤ Kw <∞, a. s. (5)
where E denotes the expectation, zk denotes the sub-σ alge-
bra generated from the data set {y(s)}s≤k. Note that zk is
increasing, i.e., zk ⊂ zk+1. We shall demand that u(k) is
zk−measurable. For the premise variables zi(k), 1 ≤ i ≤ g0,
we assume that they are zk−measurable, i.e., zi(k) depends
on the data set {y(s), u(s)}s≤k. Using the smoothing property
of the conditional mean [18], conditions (3) and (4) imply that
w(k) is also a white process with zero mean and variance σ2w.
Note that condition (5) implies
1
N
N∑
k=1
w2(k) ≤ Kw, a.s., for N ≥ Nw (6)
where Nw is a sufﬁciently large integer.
Given the input/output sequences {u(k)} and {y(k)}, the
stochastic fuzzy system (1) is equivalent to
y(k + 1) =
L∑
i=1
hi(z(k)){(1−Ai(q−1))y(k + 1)
+Bi(q−1)u(k) + Ci(q−1)w(k + 1)} (7)
where z(k) = [z1(k) z2(k) ... zg0(k)] and, for 1 ≤ i ≤ L,
µi(z(k)) =
g0∏
j=1
Fij(zj(k)) (8)
hi(z(k)) =
µi(z(k))∑L
i=1 µi(z(k))
(9)
where the function Fij(zj(k)) is the grade of membership of
zj(k) in Fij . For (8) and (9), we assume that
hi(z(k)) ≥ 0 ,
L∑
i=1
hi(z(k)) = 1 (10)
The physical meaning of (7) is that the L local linear stochas-
tic subsystems are interpolated by the fuzzy basis functions
hi(z(k)), for i = 1, 2, . . . , L.
In the sequel, we shall ﬁrst attack the identiﬁcation problem
for estimating the parameters of the optimal predictor related to
the fuzzy ARMAX model (1). After obtaining the estimates of
the parameters, the design objective is to determine the adaptive
control input u(k), as a function of {y(s), u(s− 1)}s≤k, to
minimize the mean square error [10]
J1(k + 1) = E{[y(k + 1)− y∗(k + 1)]2|zk} (11)
between the the output y(k + 1) and the bounded reference
signal y∗(k + 1).
B. Stability of Stochastic T-S Fuzzy Systems
In order to deal with the adaptive control problem of the
stochastic T-S fuzzy ARMAX model, the stability issue of the
stochastic fuzzy system must be addressed ﬁrst. Since the fuzzy
ARMAX model, such as in (7), can be transformed into a state-
space stochastic fuzzy model and stability is easier to discuss
from the state-space perspective, we consider a forced T-S fuzzy
system in the state-space form as follows
x(k + 1) = [A(k)x(k) +B(k)us(k)]
ys(k) = [C(k)x(k) +D(k)us(k)]
(12)
where the sequences
{
‖A(k)‖2
}
,
{
‖B(k)‖2
}
,
{
‖C(k)‖2
}
,
and
{
‖D(k)‖2
}
are uniformly bounded. It is also assumed that
A(k), B(k), C(k), and D(k) are all zk−measurable.
Theorem 1: If there exists a sequence of symmetric positive
deﬁnite matrices {P (k)} with 0 < λminP I ≤ P (k) ≤ λmaxP I <
where the regression vector φ(k) and the function r (k) are
deﬁned as
φ(k) =
[
h1(z(k))χT (k) h2(z(k))χT (k)
· · · · · · hL(z(k))χT (k)
]T
(26)
χ(k) = [−y(k) · · · − y(k − l + 1) y(k) · · · y(k − n+ 1)
u(k) · · ·u(k −m)]T (27)
y(k) = φT (k − 1)θ̂(k) (28)
r(k − 1) = r(k − 2) + φT (k − 1)φ(k − 1) (29)
For the initial conditions, θ̂(0) can be arbitrarily chosen and
r(−1) must be a positive scalar. By its deﬁnition, the variable
y(k) can be regarded as a posterior estimate of y(k).
Before proceeding to analyze the stochastic gradient algo-
rithm, some useful deﬁnitions are made as follows
ŷ(k) = φT (k − 1)θ̂(k − 1) (30)
e(k) = y(k)− ŷ(k) (31)
η(k) = y(k)− y(k) (32)
ς(k) = η(k)− w(k) (33)
θ˜(k) = θ̂(k)− θ0 (34)
β(k) = −φT (k − 1)θ˜(k) (35)
Some general properties of the stochastic gradient algorithm
can be extracted from Lemma 8.5.1 in [10] as follows.
lim
N→∞
N∑
k=1
φT (k − 1)φ(k − 1)
r(k − 1)r(k − 2) <∞ (36)
η(k) =
r(k − 2)
r(k − 1)e(k) (37)
E {β(k)w(k)| zk−1} =
− φ
T (k − 1)φ(k − 1)
r(k − 1) σ
2
w, a. s. (38)
Lemma 1: For the stochastic gradient algorithm in (25)-(27),
we have
L∑
i=1
hi(z(k − 1))Ci(q−1)ς(k) = β(k) (39)
Proof: The proof is given in Appendix C.
In addition to the results in Lemma 1, we shall need the
following assumptions in order to obtain some properties of
the parameter estimate θ̂(k).
Assumption 2 : For each i, 1 ≤ i ≤ L, system Ci(q−1) is
input strictly passive (ISP) [10].
In (39), the signals ς(k) and β(k) are related by the fuzzy
polynomial
∑L
i=1 hi(z(k − 1))Ci(q−1). As shall be shown in
the next lemma, Assumption 2 implies a passivity condition
for that fuzzy polynomial.
Lemma 2: Consider the fuzzy system in (39). With Assump-
tion 2 that Ci(q−1) is input strictly passive (ISP), we have
k∑
j=1
β(j)ς(j)− ²ς2(j) ≥ 0, for k ≥ 1 (40)
for some ² > 0.
Proof: The proof is given in Appendix D.
Theorem 3: Under Assumption 2, for the stochastic gradi-
ent algorithm in (25)-(29), we have the parameter difference
convergence
lim
N→∞
N∑
k=1
∥∥∥θ̂(k)− θ̂(k − 1)∥∥∥2 <∞, a. s. (41)
and the normalized prediction error convergence
lim
N→∞
N∑
k=1
[e(k)− w(k)]2
r(k − 1) <∞, a. s. (42)
Proof: With the help of previous lemmas, the results can
be conducted along the same line made in Theorem 8.5.1 in
[10]. Therefore the proof is omitted.
E. Adaptive Minimum Variance Control
To propose a direct adaptive fuzzy minimum variance con-
troller, we shall ﬁrst discuss the structure of the non-adaptive
minimum variance controller by assuming that the system
parameters are given. For the fuzzy stochastic system (7)
having the optimal one-step ahead prediction form in (21),
the minimum variance tracking control minimizing the cost
function J1(k + 1) in (11) is given by [19]
u(k) =
1
b0(k)
{
−
L∑
i=1
hi(z(k))
[
Bi(q−1)− bi0
]
u(k)
+
L∑
i=1
hi(z(k))
[
Ci(q−1)y∗(k + 1)− αi(q−1)y(k)
]}
(43)
where b0(k) =
∑L
i=1 hi(z(k))bi0. The effect of the control law
in (43) is to give
y0(k + 1|k) = y∗(k + 1) = φT (k)θ0, (44)
i.e., the predicted output is forced to be equal to the desired out-
put. Now suppose that the estimated parameters, α̂ij(k), bˆij(k),
and cˆij(k) are obtained by using the stochastic gradient algo-
rithm at time k. Accordingly, denote α̂i(k, q−1), Bˆi(k, q−1),
and Cˆi(k, q−1) be the estimates of the polynomials αi(q−1),
Bi(q−1), and Ci(q−1) at time index k, respectively. Also let
b̂0(k) =
∑L
i=1 hi(z(k))bˆi0(k). Based on the above estimated
polynomials, the adaptive minimum variance control law is
given by
u(k) =
1
b̂0(k)
L∑
i=1
hi(z(k))
{
−
[
B̂i(k, q−1)− b̂i0 (k)
]
u(k)
+
[
Ĉi(k, q−1)y∗(k + 1)− α̂i(k, q−1)y(k)
]}
(45)
in which the control law is derived from the following equation
y∗(k + 1) = φT (k)θ̂(k) (46)
where
A1(q−1) = 1− 0.27q−1 + 0.011q−2
A2(q−1) = 1− 0.33q−1 + 0.023q−2
A3(q−1) = 1− 0.36q−1 + 0.0288q−2
A4(q−1) = 1− 0.39q−1 + 0.035q−2
A5(q−1) = 1− 0.44q−1 + 0.0468q−2
B1(q−1) = 1− 0.2q−1, C1(q−1) = 1− 0.135q−1
B2(q−1) = 1− 0.3q−1, C2(q−1) = 1− 0.165q−1
B3(q−1) = 1− 0.4q−1, C3(q−1) = 1− 0.18q−1
B4(q−1) = 1− 0.5q−1, C4(q−1) = 1− 0.195q−1
B5(q−1) = 1− 0.6q−1, C5(q−1) = 1− 0.22q−1
and w(k) is a zero-mean Gaussian white noise with σ2w = 0.01.
The membership function for the fuzzy logic set Fi is given in
Fig 1 and the premise variable z(k) is chosen as z(k) = y(k).
We choose y∗ (k + 1) = sin( 2pik100 ) + 3 sin
(
6pik
100
)
as the refer-
ence signal. In Fig. 2, the adaptive minimum variance control
u(k) is shown in the upper trace, while the output y(k) and
the reference signal y∗(k) are compared in the lower trace.
Obviously, a usual transient phase of the adaptive control can
be observed. Fig. 2 veriﬁes that the internal stability and the
tracking performance of the closed-loop system. The standard
deviation of the tracking error during the steady state is 0.1058,
which is very close to the standard deviation σw = 0.1 of w(k)
as guaranteed in Theorem 4.
四、結論與討論
Adaptive minimum variance control for stochastic T-S fuzzy
ARMAX model is addressed in this study. From the fuzzy
ARMAX model, a fuzzy one-step ahead prediction model
is ﬁrst developed. A stochastic gradient algorithm is then
proposed to identify the parameters of the related one-step-
ahead predictor. Under the direct adaptive control scheme, the
minimum variance control is applied to make the output track
a desired reference signal. Stability and tracking performance
of the adaptive stochastic fuzzy control system are rigorously
derived and veriﬁed by simulation study.
參考文獻
[1] M. Sugeno and K. Tanaka, “Successive identiﬁcation of Fuzzy model,”
Fuzzy Set and Systems, Vol. 28, pp. 156-33, 1988.
[2] T. Takagi and M. Sugeno, “Fuzzy identiﬁcation of systems and its
applications to modeling and control,” IEEE Trans. Syst. , Man, Cybern.,
Vol. 15, pp. 116-132, Jan/Feb, 1985.
[3] M. Sugeno and T. Yasukawa, “A fuzzy logic-based approach to qualitative
modeling,” IEEE Trans. Fuzzy Systems, Vol. 1, No. 1, pp.7-31, Feb. 1993.
[4] L. X. Wang, Adaptive Fuzzy Systems and Control: Design and Stability
Analysis, Englewood Cliffs, NJ, Prentice-Hall, 1994.
[5] L. X. Wang, “Stable adaptive fuzzy control of nonlinear systems,” IEEE
Trans. Fuzzy System, Vol. 1, No 2, pp. 146-155, May. 1993.
[6] L. X. Wang, “Modeling and Control of hierachical systems with fuzzy
systems,” Automatica, Vol.33, No 6, pp. 1041-1053, June. 1997.
[7] T. K. Yin and C. S. George Lee, “Fuzzy model-reference adaptive control,”
IEEE Trans. System, Man, Cybern., Vol.25, No. 12, pp.1606-1615, Dec.
1995.
[8] B. S. Chen, C. H. Lee, and Y. C. Chang, “H∞ tracking design of uncertain
nonlinear SISO systems: adaptive fuzzy approach,” IEEE Trans. Fuzzy
Systems, Vol.4, No. 1, pp. 32-43, Feb. 1996.
[9] D. Williamson, Digital Control and Implementation, Prentice Hall, En-
glewood Cliffs, N.J. 1991
−10 −8 −6 −4 −2 0 2 4 6 8 10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
F1 F2 F3 F4 F5
z(k)
Membership grades
圖 1. Membership functions used in Example 1.
0 50 100 150 200 250 300
−100
−50
0
50
100
time(k)
u(k)
0 50 100 150 200 250 300
−100
−50
0
50
100
y*(k) and y(k)
time(k)
 
 
y*(k)
y(k)
圖 2. Iutput y(t) and its reference signal y∗(t) in Example 1.
[10] G. C. Goodwin and K.S. Sin, Adaptive ﬁltering prediction and control,
Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1984.
[11] K. Watanabe, “Stochastic fuzzy control. I. Theoretical derivation,” Pro-
ceedings of 1995 IEEE International Conference on Fuzzy Systems, vol.2,
pp. 547-554, March. 1995.
[12] K. Watanabe, K. Izumi and Fuha Han, “Stochastic fuzzy servo control
using multiple linear dynamic models,” Proceedings of the Second Inter-
national Conference on Knowledge-Based Intelligent Electronic Systems,
Vol.3, pp. 474-482, April. 1998.
[13] E. G. Laukonen, K. M. Passino, V. Krihnaswami, G.-C. Luh, and G.
Rizzoni, “Fault detection and isolation for an experimental internal
combustion engine via fuzzy identiﬁcation,” IEEE Trans. Control System
Technology, Vol. 3, No. 3, pp. 347-355, Sep. 1995.
[14] J. Hu, K. Kumamaru, and K. Inoue, “A hybrid quasi-ARMAX modeling
scheme for identiﬁcation and control of nonlinear systems,” Proceedings
of the 35th IEEE Conference on Decision and Control, Vol. 2, pp. 1413
-1418, Dec. 1996.
[15] J. B. Waller, J. Hu, and K. Kirasawa, “Nonlinear model predictive control
utilizing a neuro-fuzzy predictor,” 2000 IEEE International Conference on
Systems, Man, and Cybernetics, Vol. 5, pp. 3459-3464, Oct. 2000.
[16] H.-T. Yang and C.-M. Huang, “A new short-term load forecasting ap-
proach using self-organizing fuzzy ARMAX models,” IEEE Transactions
on Power Systems, Vol. 13, No. 1, pp. 217-225, Feb. 1998.
[17] T. T. Ho, “Stochastic fuzzy direct adaptive control,” Proceedings of the
Third IEEE Conference on Fuzzy Systems, Vol.2, pp. 750-755, June 1994.
[18] A. N. Shiryayev, Probability, in Graduate Texts in Mathematics Series,
Vol. 95, Springer-Verlag, New York, 1984.
[19] Bor-Sen Chen, Bore-Kuen Lee, and Ling-Bin Guo, “Optimal tracking
design for stochastic fuzzy systems,” IEEE Transactions Fuzzy Systems,
, Vol. 11, No. 6, pp. 796-813, Dec. 2003.
where c3 is deﬁned as c3 = 3C2Lc
2
2 ‖x(0)‖2 . Considering the
change of index i = k− j, the ﬁrst summation term in the last
inequality can be rearranged as
k−1∑
j=0
‖Φ(k, j + 1)‖ =
k∑
i=1
‖Φ(k, k − i+ 1)‖
=
K1∑
i=1
‖Φ(k, k − i+ 1)‖
+
k∑
i=K1+1
‖Φ(k, k − i+ 1)‖
(B.2)
With the transition matrix deﬁned in (16), it follows that
‖Φ(k, k − i+ 1)‖ ≤ Ai−1L for i ≤ K1. On the other hand,
for i > K1, inequality (17) ensures that ‖Φ(k, k − i+ 1)‖ ≤
c2
√
λ
i−1
, a.s. and thus
lim
k→∞
k−1∑
j=0
‖Φ(k, j + 1)‖ ≤
K1∑
i=1
Ai−1L + c2
∞∑
i=K1+1
√
λ
i−1
= c4 <∞, a. s. (B.3)
where
c4 =
1−AK1L
1−AL + c2
√
λ
K1
1−√λ
Taking the summation operation 1N
∑N
k=1 on both sides of (B.1)
and using (B.3), one can get
1
N
N∑
k=1
‖ys(k)‖2 ≤ 1
N
c3
1− λ +
3D2L
N
N∑
k=1
‖us(k)‖2
+
3C2LB
2
Lc4
N
×
N∑
k=1
k−1∑
j=0
‖Φ(k, j + 1)‖ ‖us(j)‖2 , a. s.
(B.4)
in which the double summation term can be rearranged as
follows
N∑
k=1
k−1∑
j=0
‖Φ(k, j + 1)‖ ‖us(j)‖2
=
N−1∑
j=0
N∑
k=j+1
‖Φ(k, j + 1)‖ ‖us(j)‖2
With the same argument made from (B.2) to (B.3), it is easy
to see that
N∑
k=j+1
‖Φ(k, j + 1)‖ ≤
∞∑
k=j+1
‖Φ(k, j + 1)‖ ≤ c4 <∞, a. s.
(B.5)
Therefore, following from (B.4) and (B.5), inequality (18) can
be attained with
K3 = c31−λ + 3C
2
LB
2
Lc
2
4 ‖us(0)‖2
= 3C2L
(
c22
1−λ ‖x(0)‖2 +B2Lc24 ‖us(0)‖2
)
K2 = max
(
3D2L, 3C
2
LB
2
Lc
2
4
)
C. Proof of Lemma 1
Proof: Rewrite (7) to get
L∑
i=1
hi(z(k − 1))Ai(q−1)y(k)
=
L∑
i=1
hi(z(k − 1))
[
Bi(q−1)u(k − 1) + Ci(q−1)w(k)
]
(C.1)
Substituting (20) into (C.1), we have
L∑
i=1
hi(z(k − 1))[Ci(q−1)− q−1αi(q−1)]y(k)
=
L∑
i=1
hi(z(k − 1))
[
Bi(q−1)u(k − 1)
+Ci(q−1)w(k)
]
which leads to
L∑
i=1
hi(z(k − 1))Ci(q−1)[y(k)− w(k)]
=
L∑
i=1
hi(z(k − 1))
[
q−1αi(q−1)y(k)
+Bi(q−1)u(k − 1)
]
From (32) and (33), we subtract
∑L
i=1 hi(z(k −
1))Ci(q−1)y(k) from both sides of the above equation
to get
L∑
i=1
hi(z(k − 1))Ci(q−1)[y(k)− y(k)− w(k)]
=
L∑
i=1
hi(z(k − 1))
[
q−1αi(q−1)y(k)
−Ci(q−1)y(k) +Bi(q−1)u(k − 1)
]
and thus
L∑
i=1
hi(z(k − 1))Ci(q−1)ς(k)
=
L∑
i=1
hi(z(k − 1))
[−(Ci(q−1)− 1)y(k)
+q−1αi(q−1)y(k) +Bi(q−1)u(k − 1)− y(k)
]
Using (27), we can get the following equation
L∑
i=1
hi(z(k − 1))Ci(q−1)ς(k)
=
L∑
i=1
hi(z(k − 1))χT (k − 1)θi0 − y(k)
= φT (k − 1)θ0 − φT (k − 1)θ̂(k) = −φT (k − 1)θ˜(k)
= β(k)
This completes the proof.
which implies that for the system in (E.5), it follows from
Theorem 2 that
1
N
N∑
k=1
‖xu(k)‖2
≤ K2
N
N∑
k=1
‖Vu(k + 1)‖2 + K3
N
, a. s., for N ≥ K1
(E.7)
For the left hand side of (E.7), by the deﬁnition of the vector
xu(k), it follows
1
N
N−1∑
k=1
‖u(k)‖2 ≤ 1
N
N∑
k=1
‖xu(k)‖2 (E.8)
For the left hand side of (E.7), by the deﬁnition of Vu(k + 1),
we have
‖Vu(k + 1)‖2
=
{
b˜0(k)
b0,min
L∑
i=1
hi(z(k))
(
θTAiφy(k + 1)− θTCiφw(k + 1)
)}2
where
θAi =
[
1 ai1 · · · ain]
]T
θCi =
[
1 ci1 · · · cil]
]T
φy(k + 1) =
[
y(k + 1) y(k) · · · y(k + 1− n) ]T
φw(k + 1) =
[
w(k + 1) w(k) · · · w(k + 1− l) ]T
Let CAC = max
{
max
1≤i≤L
‖θAi‖ , max
1≤i≤L
‖θCi‖
}
. As 0 <
b0,min ≤
∣∣∣˜b0(k)∣∣∣ ≤ 1, it follows
‖Vu(k + 1)‖2 ≤ 2C
2
AC
b20,min
(‖φy(k + 1)‖2+‖φw(k + 1)‖2) (E.9)
Meanwhile, similar to (E.8), one can obtain
1
N
N∑
k=1
‖φy(k + 1)‖2 ≤ (n+ 1) 1
N
N+1∑
k=1
y2(k) (E.10)
1
N
N∑
k=1
‖φw(k + 1)‖2 ≤ (l + 1) 1
N
N+1∑
k=1
w2(k) (E.11)
Therefore, by (E.7)-(E.11) and (5), we have, for N ≥ N,
1
N
N−1∑
k=1
‖u(k)‖2 ≤ K6 × 1
N
N+1∑
k=1
‖y(k)‖2 +K7
where N = max{Nw,K1}
K6 =
2C2ACK2(n+ 1)
b20,min
, K7 =
2C2ACK2Kw(l + 1)
b20,min
This completes the proof.
F. Proof of Lemma 4
Proof: (i) The proof can be referred to part (iii) of Lemma
11.3.1 in [10].
(ii) The proof can be referred to part (iv) of Lemma 11.3.1
in [10].
(iii) In (29) with k = N , we have
r(N − 1)
= r(0) +
N−1∑
k=1
φT (N − 1)φ(N − 1) (F.1)
= r(0) +
N−1∑
k=1
L∑
i=1
h2i (z(k))χ
T (k)χ(k) (F.2)
≤ r(0) +
N−1∑
k=1
L∑
i=1
hi(z(k))χT (k)χ(k) (F.3)
= r(0) +
N−1∑
k=1
χT (k)χ(k) (F.4)
By the deﬁnition of χ(k) in (27), it follows from (49),(50),
and (51) that, for N ≥ N,
1
N
r(N − 1) ≤ Ka2
N
N−1∑
k=1
[e(k)− w(k)]2 +Ka1
for some positive numbers Ka2 and Ka1. This completes the
proof.
表 Y04 
一、 參加會議經過: 
    此次2008年機器學習與人工頭腦學國際研討會(2008 International Conference on 
Machine Learning and Cybernetics ，ICMLC 2008)，由河北大學、IEEE SMC (System, 
Man, and Cybernetics) 協會、香港機器學習與控制研究所（MLCRI）等單位聯合主辦，
於 97 年 7 月 12 日到 97 年 7 月 15 日，在中國昆明市 Grand Park Hotel 舉行。台灣科技
大學校長陳希舜教授為 Honorary Conference Chairs 之ㄧ，台灣的學者參與此研討會
非常踴躍。 
此次研討會所有論文都列入 IEEE Explorer 之資料庫，都屬於 EI Index。研討會之網
路首頁為 http://www.icmlc.com/，整個研討會包含四個 Tutorials： 
[1] Application of Neural Network and Cerebellar Model Articulation Controller in Control 
Problem, Speaker: Prof. Chih-Min Lin (元智大學電機系教授) 
[2] Principles of Stochastic Discrimination and Ensemble Learning, Speaker: Prof. Tin Kam 
Ho   
[3] Linguistic models: from data to granular architectures, Speaker: Prof. Witold Pedrycz  
[4] Intelligence Pattern Recognition and Applications to Biometrics in an Interactive 
Environment, Speaker: Prof. Patrick Wang 
另外有兩個 Plenary Talk： 
[1] Multimedia Information Security: An Overview of Research and Challenges, Speaker:
Prof. Philip Chen 
[2] - Alan Turing, spam e-mail, pattern recognition: an intriguing triangle, Speaker: Prof. 
Fabio Roli 
此次研討會之主題包含： 
1. Adaptive systems  
2. Neural net and support vector machine 
3. Business intelligence  
4. Hybrid and nonlinear system 
5. Biometrics  
6. Fuzzy set theory, fuzzy control and system 
7. Bioinformatics  
8. Knowledge management 
9. Data and web mining  
10. Information retrieval 
11. Intelligent agent,  
12. Intelligent and knowledge based system 
13. Financial engineering  
14. Rough and fuzzy rough set 
15. Inductive learning  
16. Networking and information security 
17. Geoinformatics  
18. Evolutionary computation。 
 
