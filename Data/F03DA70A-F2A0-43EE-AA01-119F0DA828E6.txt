行政院國家科學委員會補助專題研究計畫 □ 成 果 報 告   ■期中進度報告 
 
熱能與功率導向之研究方法－應用於處理器之設計 
子計畫四：熱能導向之編譯器方法及相對溫度感應器設置之
研究(3/3) 
計畫類別：□ 個別型計畫  ■ 整合型計畫 
計畫編號：NSC 99-2220-E-007-004 
執行期間：99 年 08 月 01 日至 100 年 07 月 31 日 
 
計畫主持人：黃婷婷 
 
 
成果報告類型(依經費核定清單規定繳交)： 
□精簡報告  ■期中完整報告 
 
本成果報告包括以下應繳交之附件： 
■赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
          
 
執行單位：清華大學資訊工程系 
 
中   華   民   國 九十九 年 五 月 三十一 日 
 
年有許多針對中央處理器(CPU)散熱的研
究，而這些研究大致上可以分成兩大類：
靜態熱能管理(static thermal management)
與 動 態 熱 能 管 理 (dynamic thermal 
management)。 
(一)、靜態熱能管理之暫存器繫結及指令排
程以平衡及減少暫存器存取。 
(二)、動態熱能管理之相對溫度感應器之設
計及其設置。 
 
以下分別說明兩個問題之背景及目的。 一般而言，靜態熱能管理方法，它的的主
要概念可分為兩個步驟，首先是先執行大
量的程式來得到CPU在程式運行時的溫度
分佈資料，而後利用分析這些溫度分佈資
料的結果來研發各種熱能管理的技術。這
方面相關的研究例如 [1] 提出了在晶片佈
局(floorplan)時降低最高溫度點(hotspot)
的演算法；主要是在晶片佈局時，將常會
楚在高溫狀態的模組分散排列，並且將這
些高溫的模組放在平時較為低溫模組的旁
邊，利用決定模組之間的相對位置關係來
避免將常楚於高溫的模組排列在旁邊，進
而達到降低最高溫度點的目的。然而，使
用這個方法會失去一些彈性調整的空間，
畢竟各種應用程式對於每個模組的溫度影
響又不盡相同，然而，當晶片佈局完成之
後，每個模組的位置就無法改變。而另一
個相關的研究 [2] 是在程式編譯時完成熱
能管理；所提出的方法是借由編譯程式的
時候，盡量將運算指令分配給不同的運算
元件，使每個運算元件的工作量都不會相
差太大，如此一來可避免特定運算元件因
工作量太大而導致最高溫度點的產生。 
(一)、靜態熱能管理之暫存器繫結及指令排
程以平衡及減少暫存器存取。 
我們提出的方法主要是在程式編譯時做處
理，並且將著重於暫存器的熱能管理。只
針對暫存器做降溫處理的原因在於中央處
理器的最高溫度點通常都發生在暫存器，
這是因為暫存器被存取的次數相對於其他
元件而言是最多的，而且暫存器的面積都
偏小，因此無法有效的散熱。為了證明這
點，我們做了一個實驗來模擬中央處理器
各元件的溫度分布，使用的範例程式是採
用 PowerStone benchmark set 裡面的
summin 評效程式，模擬的結果如圖 (一) 
所示，其中縱軸代表溫度而橫軸代表每個
不同的元件，由於 summin 是屬於整數
(integer)評效程式，所以在圖 (一) 中我們
可以發現最高溫度點是發生在整數暫存器
(integer register)；而其他的評效程式的模
擬也有相似的結果。 
至於動態熱能管理方法是在程式實行時
(run-time)偵測中央處理器各元件的溫度變
化，並且控制過熱元件的運行，直到該元
件的溫度下降至可接受的程度。這方面的
研究如  [3] 是利用動態調整電源電壓
(voltage scaling)以降低中央處理器的功率
消 耗 ， 進 而 以 此 降 低 最 高 溫 度 點
(hotspot)。而 [4] 則是利用控制指令擷取
(instruction fetch)的速率來調整溫度，在溫
度較高的時候降低指令擷取的速率而在溫
度較低時增快指令擷取的速率。動態熱能
管理方法的優點在於可以精確的監控中央
處理器的溫度變化，加上利用降溫的方式
掌握熱能控管，如此一來可以確保最高溫
度點(hotspot)必定會低於預設的安全溫度
值。 
圖 (一) 
 
由於持續的功率消耗將導致高溫的產生，
因此，為了降低暫存器的溫度，我們考慮
經由降低每次存取暫存器的功率耗損來達
到這個目的。 
在這個問題上，我們將分別解決兩個子問
題： 
　 暫 存 器 繫 結 以 平 衡 暫 存 器 存 取 
(Thermal-aware post-compilation for 
因此在本計劃探討兩個問題： 
在圖 (三) 中，橫軸代表在 SPICE 模擬中
定義的溫度，縱軸代表測量出的溫度和定
義溫度的誤差。實驗中證明了，在考慮
process variations 的情況下，雖然在
typical corner 的狀況下，最大的溫度誤差
只有 3℃的，但是在加入 slow 和 fast 
corner 的情況下，最大的溫度誤差可以達
到 13℃。以 25℃為參考點，在 typical 
corner 的情況下，溫度誤差只有 0.6℃，但
是在 fast corner 的狀況下，溫度誤差可以
達到 8.3℃，而在 slow corner 的狀況下，
溫度誤差可以達到－7.8℃。由實驗三可以
發現，由於 process variations 所造成的影
響，在應用絕對溫度測量器來進行溫度的
測量時，很難確保溫度的正確性。 
因此本計劃設計一相對溫度感應器，同時
探討它的設置(placement)問題。 
 
三、 研究方法及進行步驟 
(一 )、暫存器繫結以平衡暫存器存取
(Thermal-aware post-compilation for 
register re-binding) 
首先，我們採用參考文獻[7] 所提出的暫存
器架構，將原本的暫存器分成數個子暫存
器 (sub-bank register file)如圖  (四 ) 所
示，而圖中的 enable signal 訊號線是用來
控制每個子暫存器的開啟或關閉，如此一
來，只有被存取的子暫存器會開啟，其他
沒有用到的子暫存器則會關閉，而關閉的
暫存器不會消耗任何功率，除此之外，也
因為每次存取的暫存器的大小已經縮小，
所以可降低每次存取暫存器所消耗的功
率。 
 
圖 (三) 
在此，我們提出了一個暫存器繫結
(register binding)的演算法，在編譯程式
的同時處理熱能管理的問題，主要的概念
是在進行暫存器配置時，盡量將工作量平
均分散給每個子暫存器，以避免同一個子
暫存器因存取次數過多而成為最高溫度
點(hotspot)。然而，要降低中央處理器的
最高溫度點(hotspot)，只有考慮減少存取
暫存器的功率是不夠的，還必須要考慮兩
個問題，第一個是環繞在暫存器周圍元件
的溫度，因為熱能是輻射能量，所以周圍
元件的溫度會影響暫存器的溫度變化，我
們將由事先模擬程式執行來得到暫存器
周圍元件的溫度資料，並且在演算法執行
的同時，將周圍元件對暫存器溫度的影響
列入考慮；而第二個需要列入考慮的問題
則是子暫存器之間的溫度變化，在進行暫
存器繫結 (register binding)演算法的同
時，每個子暫存器的存取次數也隨著改
變，而這個改變會反應在溫度變化上，加
上每個子暫存器之間相互的位置會使輻
射熱能相互影響，因此，在演算法進行子
暫存器分配的同時，也必須考慮已分配的
不會
pilation for 
子暫存器所造成的溫度影響。 
在本年度的研究中，我們提出了一個演算
法來解決上述的這些問題。我們所提出的
演算法建構在優先性考量之圖形著色演
算法(priority-based graph coloring)上。首
先，透過分析控制流程圖 (control flow 
graph)的方式，可以找出個變數的生命週
期(live range)，並進一步建立出變數之間
的牴觸關係圖(interference graph)。接下
來，變數的優先性會依照其生命週期(live 
range)被決定。依照各變數的優先性，可
使用的暫存器(available register)會依序
透過圖形著色的方式(graph coloring)的
方式，被分配到不同變數的生命週期(live 
range)。由於演算法的特性，在牴觸關係
圖中(interference graph)，相鄰的點必定
會有不同的顏色，代表同一個暫存器
被分配給生命週期相衝突的變數。 
( 二 ) 、指令排程以減少暫存器存取
(Thermal-aware post-com
instruction re-scheduling) 
指令排程的(instruction scheduling)的演
算法也是在編譯程式的同時處理熱能管
理的問題，當然，降低暫存器的最高溫度
HBJT 所擺放的位置，需要越接近可能的
熱點越好，才能有效的測量溫度。RBJT
因為是作為溫度的參照點，需要放在溫度
比較低且穩定的位置。同理，由於 process 
variations 會造成原本穩定電流(Ibias)的
變異，CORE 也需要放在溫度較低且穩定
(
BJT、RBJT 和
IORTS 之間的溫度關係: 
導出絕對溫度達到
量溫度目的。這次 
我們最後實驗中使用 1um 和 10um) 。 
 
的地方。 
在應用新的架構下，CORE、HBJT 和
RBJT 擺放的位置都隨著不同的限制而變
化，因此在 CORE 和 RBJ/HBJT 之間，
需藉由導線的連線，來傳遞穩定的電流
(Ibias)和測量出的電壓(VEB)，而導線的長
短和寬度，會造成電流和電壓的誤差。如
何在減少額外 BJT 所造成的面積負擔
上，適當的對 HBJT，RBJT 和 CORE 進
行分組的動作，並針對不同的群組，在晶
片上進行擺設的動作，來降低導線和
process variations 所造成的影響，除此
之外，由於此架構只能得到相對溫度，為
了能將相對溫度感應測量得到的值轉換
成絕對溫度，我們進一步提出 IO-type 
relative temperature sensor (IORTS)來
幫助溫度測量，IORTS 包含了原先提出的
CORE 和一個 BJT。由於我們要利用溫度
感應器測得基準溫度，我們將 IORTS 放
置於 IO area 中並且遠離 hotspot 來取得
較穩定的基準溫度，並且由外部電源輸送
10um 給予其穩定電流 Ibias)，再利用下
列方程式關係可以找出 H
)()(21 IORTSTHBJTTT 
所以利用△
)()(
)()(
2
1
IORTSTRBJTT
RBJTTHBJTT


 
T即可以推
測
 
四、 結論 
在本年度主的研究中，我們將相對溫度感
應器的架構及其特性中再提出，做更多的
修改透過一系列的實驗，去做深入的分析
及討論。基於實驗的結果，我們利用數學
公式化的方式，將相對溫度感應器配置時
所要考慮的各項因素，以及相對溫度感應
器的配置問題，轉換為一系列數學優化的
題目。在得到數學公式化的題目定義後，
我們將整個相對溫度感應器配置的問題，
依照 HBJT、RBJT、CORE 的順序，分成
三階段，個別提出演算法去處理。在圖(六)
的實驗中，為考慮在擺置溫度感應器後，
其金屬繞線寬度對於溫度測量誤差的實驗
結果，因此我們可選定適當的導線寬度來
做我們的溫度感應器的繞線寬度選定 (在
此
 
           圖(六) 
HBJT
個數和誤差關係如圖(七)所示。 
 
 
除了金屬導線寬度有溫度誤差之外，我們
另外測量在同一群聚(cluster)下使用
的
 
           圖(七) 
接著比較單一 cluster 下其 HBJT 的溫度誤
差我們將其表示於圖(八)，我們可以觀察到
我們所提出的架構相較於傳統的架構誤差
都相對小很多。最後，基於提出溫度感應
器架構下，各面積的比較表示於圖(九)中。 
 
 
圖(八) 
Retention”,IEEE/ACM International 
Conference on Computer Aided 
del in HotSpot 4.0 with 
structing, and Debunking,June. 
its Vol. 35, No. 11 
 Computer Design, 2005, 
Manufacturing 
is and optimizations,” 
, 
//www.specbench.org/osg/cpu20
Design, Nov. 2002. 
[16] W. Huangy, K. Sankaranarayanany, R. 
J. Ribandoz, M. R. Stan and K. 
Skadron,”An Improved Block-Based 
Thermal Mo
Granularity 
Considerations”,Proceedings of the 
Workshop on Duplicating, 
Decon
2007 
[17] S. Rusu, G. Singer, ”The First IA-64 
Microprocessor”, IEEE Journal of 
Solid-state Circu
November 2000 
[18] Kyeong-Jae Lee, Kevin Skadron and 
Wei Huang, ”Analytical model for 
sensor placement on 
microprocessors,” International 
Conference
pp. 24-27. 
[19] W. Huang, S. Ghosh, K. 
Sankaranarayanan, K. Skadron and M. 
R. Stan, ”HotSpot: Thermal modeling 
for CMOS VLSI systems,” IEEE 
Transactions on Component 
Packaging and 
Technology, 2005. 
[20] David Brooks, Vivek Tiwari and 
Margaret Martonosi, ”Wattch: A 
framework for architectural-level 
power analys
ISCA, 2000. 
[21] ”SPEC-CPU2000, Standard 
Performance Evaluation Council, 
Performance Evaluation in the New 
Millennium, Version 1.1,” 2000
http:
00. 
[22] Michiel A. P. Pertijs, Kofi A. A. 
Makinwa, Johan H. Huijsing, ”A 
CMOS smart temperature sensor with 
a 3_ inaccuracy of ±0.1_C from 
-55_C to 125_C,” IEEE Journal of 
Solid-State Circuits, Vol. 40, NO. 12, 
 51, NO. 9, Sep. 
FETs,” IEDM, 2003, pp. 
Res., 
ecture News, 1997. 
25(3), pp. 13-25 
Dec. 2005, pp. 2805-1815. 
[23] Souvik Mahapatra, P. Bharath Kumar, 
M. A. Alam, ”Investigation and 
modeling of interface and bulk trap 
generation during negative bias 
temperature instability of 
p-MOSFETs,” IEEE Transactions on 
Electron Devices, Vol.
2004, pp. 1371-1379. 
[24] M. A. Alam, ”A critical examination 
of the mechanics of dynamic NBTI 
for PMOS
345-348. 
[25] Heyer LJ, Kruglyak S, Yooseph 
S, ”Exploring expression data: 
identification and analysis of 
coexpressed genes,” Genome 
1999 Nov;9(11) pp. 1106-1115. 
[26] D. C. Burger and T. M. Austin, ”The 
SimpleScalar tool set, Version 2.0,” 
Computer Archit
Placement of Temperature Sensors Under Process Variations
Hsien-Te Chen, Wei-Hein Lo, Chieh-Chun Chang and TingTing Hwang
Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan 300
Abstract—Variations occur inevitably in temperature sensor from
process variations. To tackle the former variations, a relative temperature
sensor is proposed and explored in this paper. It eliminates the process
variations in temperature measurement and improves area efﬁciency.
The new temperature sensor is able to provide accurate temperature
information. Compared with the absolute temperature sensor where
maximum temperature error could be as high as 15◦C, our relative
temperature sensor shows 4.4◦C maximum temperature error with 75%
area reduction (m = 8) using 1um wide metal connection, and 3.8◦C
maximum temperature error with 3% area overhead (m = 8) using
10um wide metal connection, in the best case.
I. INTRODUCTION
As feature size of MOS technology continues to shrink, power
density becomes a critical issue for transistor scaling. With power
density reaching hundreds of watt per centimeter square, tempera-
ture has signiﬁcant impacts on threshold voltage, carrier mobility,
resistivity, reliability and even package.
In recent years, a number of Dynamic Thermal Management
(DTM) techniques have been proposed for thermal safety at run time
[1]. One key step to the success of DTM techniques is to accurately
detect the temperature in the selected hot spots, so as to determine
the executions of dynamic voltage scaling, frequency scaling, or
energy aware process scheduling, etc. In the previous work, absolute
temperature sensor was used. Subsequently, researches on allocation
and placement of temperature sensor were proposed based on the
model of absolute temperature sensor [1], [2].
In deep submicron technologies, process variations present difﬁ-
culty in manufacturing, design and even inaccurate absolute tem-
perature sensing. For example, in [1], the un-calibrated accuracy
of temperature sensors is about ± 12◦C over the manufacturing
process corners for absolute temperature measurements. To solve
this inaccuracy problem, research work using external calibration
was proposed in [3]. However, it is time and cost consuming for
external calibration.
In this paper, we propose a relative temperature sensor which as
corollary minimizes the temperature errors caused by process vari-
ations and temperature ﬂuctuation behavior. Furthermore, a sensor
placement algorithm taking into consideration the characteristics of
our relative temperature sensors is proposed.
The rest of the paper is organized as follows. Section II discusses
the motivation of this work. Section III proposes the architecture of
our relative temperature sensor. Section IV formulates the problem
of placing relative temperature sensors and proposes an algorithm to
solve it. Section V shows the experimental results. Conclusions are
put forth in Section VI.
II. MOTIVATION
Fig. 1 illustrates the operational principle of an absolute temper-
ature sensor. Diode-connected bipolar transistor at the left of Fig. 1,
denoted as BJT, is applied to produce voltage VEB with constant
current. The block at the right of Fig. 1, denoted as CORE, consists
of a constant current generator and an analog-to-digital converter to
output digital values according to the temperature at the location of
BJT.
To understand the effect of process variations on the measured
absolute temperatures as described in Fig. 1, we conduct a SPICE
simulation. In this experiment, 45nm technology is used and 10uA
constant current is pumped into BJT for different process corners
at various speciﬁed actual temperatures. The estimated temperature
is reported by CORE according to the measured voltage VEB . The
ﬁrst experiment is conducted assuming process variations occur in
BJT and do not in CORE. The measured absolute temperatures
are calculated according to VEB with 10uA at typical, fast, slow
Fig. 1. Block diagram of the temperature sensor
ˀ˄˃
ˀˋ
ˀˉ
ˀˇ
ˀ˅
˃
˅
ˇ
ˉ
ˋ
˄˃
˄˅
˄ˇ
ˀˇ˃ ˃ ˅ˈ ˋˈ ˄˅ˈ
˧˸̀̃˸̅˴̇̈̅˸ʳʻкʼ
˧˸
̀
̃˸
̅˴
̇̈
̅˸
ʳ˘
̅̅̂
̅ʳʻ
к
ʼ
˙˙ʳ˴́˷ʳ˜˸˵ːˋ̈˔ ˧˧ʳ˴́˷ʳ˜˸˵ː˄˃̈˔ ˦˦ʳ˴́˷ʳ˜˸˵ː˄˅̈˔
˙˙ʳ˴́˷
˜˸˵ːˋ̈˔
˴̇ʳ˅ˈк
Fig. 2. Temperature errors due to process variation in BJT and CORE
corners and actual assigned temperatures in SPICE simulation. In this
simulation, the measured temperature is within one digit error (8◦C)
as compared with the actual temperature when process variations
occur only in BJT.
Similarly, we conduct our second experiment where process vari-
ations occur in CORE and do not in BJT. The temperature difference
between the speciﬁed and the measured at typical corner in CORE
which pumps 8uA, 10uA, 12uA into BJT and typical corner in
BJT. In this simulation, single-digit inaccuracy (7◦C) is observed
when process variations occur only in CORE.
To sum up the variations of both BJT and CORE, the third
experiment is conducted. In this simulation, Fig 2 represents the
combined effects. In this ﬁgure, horizontal axis is the actual temper-
atures in simulation and vertical axis is the temperature difference
of the measured temperatures in absolute temperature sensor to the
actual temperatures. The experiment shows that for all the reported
temperatures, in typical corner, the maximum temperature error is
within 3◦C. However, in fast and slow corners, the variations in BJT
and CORE result in double-digit inaccuracy (13◦C). Let us take data
point labeled at 25◦C as an example. It shows that there is only 0.6◦C
temperature error while BJT is in typical corner and current source
of CORE pumps 10uA into BJT (”TT and Ieb=10uA”). However,
absolute temperature sensor reports 8.3◦C higher (33.3◦C in absolute
temperature) than actual 25◦C while BJT is in fast corner and current
source of CORE pumps 8uA into BJT (”FF and Ieb=8uA”). Judging
from the results illustrated by the above ﬁgure, it is difﬁcult to assure
the accuracy of absolute temperature under the process variations in
both BJT and CORE.
As to MOS devices, the key temperature-dependent parameters
are the mobility μ and the threshold voltage VT . However, those
two parameters have different temperature impacts on drain current.
In other words, temperature causes mobility sensitive circuitry and
threshold voltage sensitive circuitry to have different circuit behav-
iors. Therefore, in order to avoid the complex temperature dependent
behavior of circuitry and erroneous measurement, CORE should be
placed at locations which have minimum temperature ﬂuctuation.
To solve problems of the above-mentioned process variations and
temperature ﬂuctuation, we propose a relative temperature sensor.
Our speciﬁc contributions in this paper are
• to propose a novel architecture of relative temperature sensor
to alleviate the temperature errors from process variations and
temperature ﬂuctuation in a chip;
• to propose an efﬁcient algorithm to allocate and place relative
978-1-4244-5271-2/10/$26.00 ©2010 IEEE 271
Fig. 5. Design ﬂow of relative temperature sensor placement
stable grids so that Eq. (1) is satisﬁed. Finally, the goal to place
COREs is to identify grids so that the grids have small temperature
ﬂuctuation (Eq. (2), Eq. (3)), the distance from RBJT to CORE and
the distance from HBJTs to CORE is balanced (Eq. (5)) and the total
wire length is minimized (Eq. (6)).
Before we describe the details of the ﬁrst step, we give the
following assumptions. Assume a given ﬂoorplan consists of b blocks
and p sets of benchmarks. First, SimpleScalar [4] generates p sets of
test vectors by simulating benchmarks. Second, Wattch [5] estimates
the power consumption of each block by simulating test vectors.
Next, the power consumption information is fed to HotSpot [6], a
thermal model tool, to identify hot spots and compute temperature
information. We assume that our placement of relative temperature
sensor will take all benchmarks into consideration in one time.
Hence, we will have b ∗ p hot spots (each benchmark reports b hot
spots and we have p benchmarks). We also assume each block is
guarded by one HBJT.
Therefore, the ﬁrst step of placing HBJTs is to select b locations
so that b ∗ p hot spots can be detected by b HBJTs. In this step, K-
mean clustering algorithm [2] is utilized where b clusters are formed.
One HBJT is placed at the center of a cluster to assure minimum
temperature difference between HBJTs and hot spots.
The second step is to place RBJTs. The location of RBJT is
strongly related to locations of the other m HBJTs in the same cluster
because they share the same CORE. Since we have b HBJTs, there
will be  b
m
 RBJTs, where m is 1 · · · 10 in our design and  
is ceiling function. One RBJT and m HBJTs will form a cluster
(together with a CORE forms a relative temperature sensor).
Placing of RBJT is conducted in 2 steps. First, based only on
the distance among HBJTs, Quality-Threshold (QT) clustering [7] is
used to form groups, where each group contains m HBJTs. Then,
the center of m HBJTs is computed. Based on this center and
the clustering result produced by QT algorithm, K-mean clustering
algorithm [2] is called to reﬁne the initial result. In this reﬁnement
process, the same distance cost as QT clustering is used. After the K-
mean clustering algorithm is completed, we have groups of HBJTs.
For each group j, we ﬁnd the position of its RBJT (denoted as Rj).
For Rj at grid location k, the following cost function is computed.
Cost(j,k)=α×RF1+β×RF2 (8)
where RF1 is deﬁned to be the temperature gradient of Rj at grid
k. RF2 is the total distance from Rj to the other m HBJTs. α, β
are weighting factors to control the relative importance of RF1 and
RF2. In this case, α is set to be much larger than β. RF1 is the
same as F1 deﬁned in Eq. (1). RF2 is deﬁned as
RF2=
∑m
i=1
||Rjk;Hi||2 (9)
where Rjk denotes that Rj at grid k position, Hi is the grid position
of HBJT found in the ﬁrst step and ||Rjk;Hi||2 is the manhattan
distance from Rjk to Hi. This term is used to prevent RBJT from
being moved too far away HBJTs.
The cost function is computed for all grid positions. The one with
the least cost is chosen for the RBJT in group j. For n groups (n
relative temperature sensors), n iterations will be called.
The ﬁnal step is to place COREs. Now the locations of one RBJT
and m HBJTs in a cluster are known. For each cluster, the location
of CORE is searched by computing the cost function deﬁned in Eq.
(7) for all grids given the locations of RBJT and HBJTs in the same
cluster.
SPEC2000
SimpleScalar
Test
Vectors
Wattch
Power Data
HotSpot
Relative
Temperature Sensor 
Placement
Metal Connection 
Route
Floorplan
Fig. 6. Simulation ﬂow of placement to relative temperature sensors
V. EXPERIMENTS
A. Experiment Setup
15 benchmark examples are selected from SPEC2000 suites [8].
The benchmark examples are ﬁrst simulated with SimpleScalar [4]
which simulates a super-scalar processor with out-of-order issue
and execution. Alpha 21364 is chosen as the base processor for
temperature analysis. Next, Wattch version 1.02 [5] is used as an
analysis tool for architectural level power modeling and HotSpot [6]
version 3.0 as a thermal analysis tool for temperature computation.
Fig. 6 illustrates our experimental ﬂow. Initial die temperature is
assumed to be 40◦C. 200 by 200 grid size is chosen for HotSpot
temperature analysis and the subsequent sensor placement. Area of
Alpha 21364 processor is 2.56cm2 and area ratio of BJT to CORE
is 1:80.
In those experiments, the weighting factors α and β in Eq. (8)
are 0.8 and 0.2, respectively and the weighting factors in Eq. (7) are
W1=0.26 W2=0.03, W3=0.06, W4=0.51, W5=0.13 and W6=0.01.
The numbers of HBJT’s in a cluster ranging from m = 1 to 10 are
tested.
In order to take into consideration the temperature effect on metal
resistance in this experiment, we perform routing step after the
placement of our relative temperature sensors. Hence, the metal
connections between BJT’s (including both HBJT’s and RBJT) and
CORE are routed. In this routing step, the resistance difference
among paths from BJT’s to CORE is to be minimized. That is, the
goal is to minimize Eq. (10).
M1(Rj ,Cj ,Hij)=mink1,k2,k3∈grids
∑m
i=1
(||Rjk1 ;Cjk2||R−||Hijk3 ;Cjk2 ||R)
(10)
j = 1, · · · , n, where ||x; y||R is metal resistance of x to y taking into
consideration temperature effect on resistance along path of x to y, n
is the number of clusters and m is the number of HBJTs in a cluster.
Our routing step completes metal connections between HBJT’s and
CORE, as well as RBJT and CORE in the same cluster. Only L-
shape routes between two nodes are considered. For each cluster, the
routing path of metal connection is chosen by cost function deﬁned
in Eq. (10).
We apply ±20% variation in constant current source. In other
words, the current to BJT’s varies from 8uA to 12uA (10uA in
average). Moreover, 3 process corners, SS (both PMOS and NMOS
are in slow corner), TT (both in typical corner) and FF (both
in fast corner) are applied for temperature measurements. In our
simulations, both current variations in CORE and process corner
variations in BJT occur.
B. Experiment Results
The ﬁrst experiment is to ﬁgure out how metal width impacts
on maximum temperature errors. In this experiment, benchmark
”WUPRISE” is used to run simulation at 25◦C while BJT’s are in
fast corner and current source of CORE pumps 8uA into BJT. In
Fig. 7, the vertical axis is the maximum temperature error while the
horizontal axis is the width of metal connections between HBJT’s,
RBJT and CORE. Simulation shows that metal width between 1um
and 10um is good candidate for metal interconnections because
temperature error is less than 4◦C and area ratio of BJT’s to metal
273
出席國際學術會議心得報告 
         
計畫編號 NSC 99-2220-E-007-004 
計畫名稱 熱能與功率導向之研究方法 －應用於處理器之設計-子計畫四：熱能導向之編譯器方法及相對溫度感應器設置之研究(3/3) 
出國人員姓名 
服務機關及職稱 
黃婷婷  
清華大學資訊工程學系   教授 
會議時間地點 
100125~1000128 
日本 Yokohama 
會議名稱 16th Asia and South Pacific Design Automation Conference (ASP-DAC 2011) 
發表論文題目 
1.Enhanced Heterogeneous Code Cache management scheme for Dynamic 
Binary Translation 
2.A physical-location-aware fault redistribution for maximum IR-drop reduction
 
一、參加會議經過 
本次會議的目的為報告研究的成果。這次報告有兩篇其主要解決議題分別為: 
a、 記憶體的容量在嵌入式系統上通常都會受限導致整體效能下降，我們提出
Heterogeneous Code Cache (HCC)同時考慮 program behavior 來達到效能提高的目的。 
b、 在測試晶片技術上，我們提出考慮錯誤位置來重新調整 test pattern 的內容，達到改善
壓降的目的。 
 
會議的開幕儀式(1/26)舉行，主持人簡單的報告了本屆論文的投稿、審查，以及領域分布
情形，並頒發本屆最佳論文獎。值得一提的是，在本屆會議中，台灣投稿且被接受的論
文數量，位居世界各國第二，僅次於美國，可見台灣在電子設計自動化領域之研究實力
與成果。 
 
1/26~1/28 三天，每天早上各有一場 keynote 演說，由會議邀請的本領域資深學者及專
家，透過演講的方式，去說明電子設計自動化領域未來的趨勢與方向。keynote 演說後，
緊接著就是 regular session 的時段，可以聽各國同領域的學者發表其最近研究成果，可以
了解學術及業界的研究趨勢吸收經驗。 發表論文被安排於 1/26 下午以及 1/28 下午發表
於”High-Level Embedded Systems Design Techniques”和”Test for Reliability and Yield”兩個
session，發表過程中也和學者們一起熱烈討論發表的成果。 
 
二、與會心得 
由於手持的普及和電子系統的廣泛應用，導致 normally-off computing 的情形愈來愈常見，這
將導致對 non-volatile memory 的需求愈來愈高。在第一場 keynote 演說中，演說者詳細的介紹
Enhanced Heterogeneous Code Cache Management Scheme
for Dynamic Binary Translation
Ang-Chih Hsieh, Chun-Cheng Liu and TingTing Hwang
Department of Computer Science, National Tsing Hua University
HsinChu, Taiwan 300
Abstract— Recently, Dynamic Binary Translation
(DBT) technology has gained much attentions on em-
bedded systems due to its various capabilities. How-
ever, the memory resource in embedded systems is of-
ten limited. This leads to the overhead of code re-
translation and causes signiﬁcant performance degra-
dation. To reduce this overhead, Heterogeneous Code
Cache (HCC), is proposed to split the code cache among
SPM and main memory to avoid code re-translation.
Although HCC is eﬀective in handling applications with
large working sets, it ignores the execution frequen-
cies of program segments. Frequently executed pro-
gram segments can be stored in main memory and suﬀer
from large access latency. This causes signiﬁcant per-
formance loss. To address this problem, an enhanced
Heterogeneous Code Cache management scheme which
considers program behaviors is proposed in this paper.
Experimental results show that the proposed manage-
ment scheme can eﬀectively improve the access ratio of
SPM from 49.48% to 95.06%. This leads to 42.68% im-
provement of performance as compared with the man-
agement scheme proposed in the previous work.
I. Introduction
The widespread popularity of mobile and handheld de-
vices leads to the development of more and more demand-
ing applications on embedded systems. The requirements
of these applications pose new challenges for embedded sys-
tem designers. For example, in addition to taking and
displaying pictures, advanced image recognition and post-
processing functions are desired on digital cameras and mo-
bile phones. Moreover, to increase the security level of mo-
bile communications, advanced online encryption and de-
cryption algorithms are required. Many of these challenges
can be solved by Dynamic Binary Translation (DBT) tech-
nology. In a DBT system, instructions of a running pro-
gram are modiﬁed or translated dynamically by a binary
translator before being executed. This technology pro-
vides various capabilities including instruction set trans-
lation [1][2], security [3][4], virtualization [5], runtime opti-
mization [6], code compression [7], power management [8]
and memory management [9][10] to solve the above men-
tioned challenges.
DBT is beneﬁcial in embedded systems. However, the
performance of DBT is largely dependant on the design of
memory structure. In a system that uses DBT technol-
ogy, the instructions that are processed by binary transla-
tor are stored in a software-controlled memory buﬀer which
is referred as code cache. To ensure good performance
and power eﬃciency on embedded systems, a small on-chip
scratchpad memory (SPM) [11] is allocated as code cache.
Since the capacity of SPM is small, repetitive translations
of identical code fragments are inevitable when SPM is not
large enough to hold the working set of an application. The
This work was supported in part by National Science Council of
Taiwan, Republic of China, under grant NSC 97-2220-E-007-004.
translation of code fragments is very time consuming in
embedded systems. Re-translation of code fragments may
severely decrease the performance of a system. To overcome
the size limitation of SPM-based code cache, heterogenous
code cache (HCC) is proposed to split the code cache among
SPM and main memory [12]. Unlike a multi-level memory
hierarchy, the code cache in main memory is used as an ex-
tension of SPM. Thus, a translated code fragment can be
stored in either SPM or main memory (but not both). The
architecture of heterogenous code cache allows more trans-
lated code fragments to be stored and eﬀectively avoids the
re-translation of code fragments.
The goal of heterogenous code cache is to achieve fast
access using small SPM while keeping the low miss rate
using main memory. In heterogenous code cache, the system
stores the most recently translated code fragments in SPM
while storing the code fragments that are evicted from SPM
in main memory. Once a translated code fragment is stored
in main memory, it cannot be moved back into SPM unless
it is evicted from main memory and re-translated again.
This code cache management scheme is eﬀective in handling
applications with large working sets. However, it is unaware
of the execution frequencies of translated code fragments.
Once a frequently executed code fragment is moved to main
memory, all executions of that code fragment suﬀer large
access latency because the access latency of main memory
is much larger than that of SPM. This leads to signiﬁcant
performance loss.
In this paper, an enhanced heterogenous code cache man-
agement scheme is proposed to address this problem. The
proposed management scheme traces the execution behav-
iors of code fragments in both SPM and main memory.
Depending on the execution behaviors, promotion and de-
motion policies are used to determine which code fragments
should be stored in SPM and which code fragments should
be removed from SPM. Our proposed management scheme
can eﬀectively increase the utilization of SPM and therefore
lead to better performance.
The rest of this paper is organized as follows. In Sec-
tion II, the framework of DBT and the structure of het-
erogenous code cache are ﬁrst introduced. Then, a simple
example is presented to explain the motivation of this work.
The overview of the proposed heterogenous code cache man-
agement scheme is described in Section III. The hard-
ware structures and the operations required in our proposed
management scheme are explained in Section IV. Next, ex-
perimental results are presented in Section V. Section VI
concludes this work.
II. Heterogenous Code Cache & Motivation
The overview of the DBT framework proposed by Scott
et al. [13] is depicted in Figure 1. In a system using DBT
technology, Operating System must ensure that all instruc-
tions of applications are examined and processed by binary
translator and loaded into code cache prior to their exe-
cution. The processor fetches and executes the translated
instructions from code cache until a special trampoline is
978-1-4244-7516-2/11/$26.00 ©2011 IEEE
3A-2
231
L1-HCC
L2-HCC
newly 
translate 
fragments
second-time
executed
fragments
Seg. 4Seg. 3Seg. 2Seg. 1
periodically 
executed
fragments
out-of-date 
fragments
evicted 
fragments
1
34
5
Adjustable boundary line
2
L1-HCChigh
L1-HCClow
Fig. 4. The Overview of Enhanced HCC Management Scheme
terms of performance and hardware resources. The over-
head of these techniques is prohibitive in most embedded
systems. In our proposed management scheme, the exe-
cution behaviors of fragments are monitored and classiﬁed
through software-based techniques that are conducted by
Operation System and implemented as parts of interrupt
routines. This leads to small performance loss and hard-
ware overhead. The other requirement of the management
scheme is to keep the storage structures of L1-HCC and
L2-HCC simple and regular to avoid fragmentation prob-
lems. FIFO-based eviction policies proposed by Baiocchi et
al. [12] are still adopted. However, the number of storage
regions needs to be increased so that fragments with diﬀer-
ent execution behaviors can be stored in diﬀerent regions
and managed separately. The discussion above leads to our
proposed enhanced heterogenous code cache management
scheme depicted in Figure 4.
In our proposed management scheme, L1-HCC is parti-
tioned into two regions which are referred as L1-HCChigh
and L1-HCClow, respectively. The reason to partition L1-
HCC into two regions is explained as follows. When a frag-
ment is executed repeatedly over a period, it is beneﬁcial
to move that fragment into L1-HCC. However, if the ca-
pacity of L1-HCC is not large enough to contain the entire
working set of an application, the contention among frag-
ments will cause thrashing problems. To avoid thrashing
problems, fragments in L1-HCC are partitioned into two
groups according to execution behaviors. For fragments
that are periodically executed, the eviction policy is more
rigorous to prevent them from eviction. On the contrary,
the eviction policy for fragments that are only required for
short periods are less rigorous to allow other fragments to
be moved into L1-HCC. By storing fragments that are pe-
riodically executed in L1-HCChigh and fragments that are
temporally required in L1-HCClow, the performance of our
DBT is signiﬁcantly improved. Moreover, in our system,
the boundary line between L1-HCChigh and L1-HCClow is
adjustable. Thus the capacities of L1-HCChigh and L1-
HCClow can be adjusted according to program behavior
dynamically.
The arrows that are labeled with numbers in Figure 4
are the fragment operations required in our management
scheme. These operations are summarized as follows.
1. Operation for newly translated fragments: In-
stead of storing a newly translated fragment in L1-
HCC, in our proposed management scheme, a newly
translated fragment is stored in L2-HCC. This can pre-
vent frequently executed fragments in L1-HCC from
eviction due to this newly translated fragment of which
the execution frequency is still unclear.
2. Operation for second-time executed fragments:
When a fragment in L2-HCC is executed the second
time, it is beneﬁcial to store this fragment in L1-HCC
since this fragment is likely to be executed again. To
keep the storage structure in L2-HCC simple and reg-
ular, the executed fragment is duplicated and is not
removed from L2-HCC. Unlike the original manage-
f1
f2
f3
fn
Global Hash Table
addr1f1
addr2f2
addr3f3
addrnfn
L1-HCChigh Hash Table
L1-HCClow Hash Table
L2-HCC Hash Table
įįį
įįį
įįį
įįį
Fig. 5. Hash Tables in the Proposed Management Scheme
ment scheme, a fragment in our proposed management
scheme may appear in L1-HCC and L2-HCC at the
same time.
3. Operation for periodically executed fragments:
When a fragment is moved into L1-HCC due to its
second-time execution, it is ﬁrst stored in L1-HCClow.
For fragments in L1-HCClow, those are executed pe-
riodically are further promoted to L1-HCChigh. The
mechanism to detect and move these fragments will be
explained in Section IV.
4. Operation for out-of-date fragments: When a
fragment in either L1-HCChigh or L1-HCClow has not
been executed over a period, it is evicted from L1-
HCC. Operating System checks whether an identical
fragment is stored in L2-HCC. If the answer is posi-
tive, the evicted fragment is simply deleted from L1-
HCC. If the answer is negative, the evicted fragment
is moved to L2-HCC to prevent re-translation of that
fragment.
5. Operation for evicted fragments: The eviction
policy of L2-HCC is based on segmented-FIFO which
is identical to the original HCC management scheme.
Whenever the capacity of L2-HCC is exhausted, the
entire segment that contains the least recently moved-
in fragment is evicted.
The primary objective of our proposed management
scheme is to let frequently executed fragments appear in
L1-HCC to exploit the small access latency of SPM. In our
management scheme, L2-HCC is mainly used to prevent
the re-translations of fragments. The detailed introduc-
tions to the operations described above and the mechanism
to adjust the boundary line in L1-HCC are described in
Section IV.
IV. Structures and Management Policies
In this section, the management of the hash tables in our
management scheme is ﬁrst introduced in Subsection A.
Then, the structures of L1-HCC and L2-HCC are intro-
duced in Subsection B and Subsection C, respectively. Re-
lated fragment operations are also explained. The adjust-
ment of the boundary line in L1-HCC is presented in Sub-
section D.
A. Management of Hash Tables
In our proposed management scheme, two-level hash ta-
bles instead of a one-level hash table are designed for L1-
HCChigh, L1-HCClow, and L2-HCC. Local hash tables for
L1-HCChigh, L1-HCClow, and L2-HCC are constructed and
are used to build a global hash table as depicted in Fig-
ure 5. In global hash table, each entry maintains a pointer
to an entry in local hash tables and backward pointers for
fragments unlinking or re-linking, while in local hash ta-
bles, each entry records the exact address of a fragment.
Fragment re-linking is required in our management scheme
when a fragment is moved from one code cache region to
another. In this case, an old entry is deleted and then a
new entry is created in their corresponding local hash ta-
bles. Finally, the pointer to that fragment in the global hash
table is updated. After that, all branches to that fragments
3A-2
233
0%
20%
40%
60%
80%
100%
0%
20%
40%
60%
80%
100%
MainMemory
SPM
2
ULJ
LQ
DO
+
&
&
(
+
&
&
Fig. 7. Access Ratio of SPM and Main Memory
TABLE I
System Parameters
Parameter Conﬁguration
SPM Latency 1 cycle
DRAM Latency 10 cycles ﬁrst chunk, 4 cycles rest
DRAM Width 8-bit
L1-HCC (SPM) Size 2 Kbytes
L2-HCC (DRAM) Size 10 Kbytes
record whether any fragments in L1-HCChigh are executed
recently. Whenever a fragment in L1-HCChigh is executed,
the used bit is set. The used bit is disabled right after a
fragment is promoted from L2-HCC to L1-HCClow. Thus,
the used bit signiﬁes whether any fragment in L1-HCChigh
is executed since the last time a fragment is moved to L1-
HCClow. The counter is designed to be increased by 1 when
an instruction in code cache is executed if the value of used
bit is 0. It is reset to 0 when the used bit is set from 1 to 0.
If the counter is greater than a predeﬁned threshold value,
it means that the fragments in L1-HCChigh have not been
executed for a long period since the last time the used bit
is disabled.
Now, we describe how to adjust the boundary line using
these two hardware components. Initially, all space in SPM
is assigned to L1-HCClow. When a fragment is ﬁrstly pro-
moted from L1-HCClow to L1-HCChigh, the boundary line
is always moved down. In the subsequent executions, when
a fragment is to be moved to L1-HCChigh from L1-HCClow
and the capacity of L1-HCChigh is exhausted, Operating
System ﬁrst checks whether the used bit is set or not. If
the used bit is set, the boundary line is moved down by
one unit page. Otherwise, one or more fragments in L1-
HCChigh are evicted to release free space for the fragment
to be moved-in.
When a fragment is moved from L2-HCC to L1-HCClow
and the capacity of L1-HCClow is exhausted, the used bit
and the counter are checked. If the used bit is set or the
counter does not reach the threshold described above, evic-
tion of fragments is performed to release free space. Oth-
erwise, the boundary line is moved up by one unit page.
After adjusting the boundary line, the counter is reset to
0.
V. Experimental Results
Experiments are conducted to demonstrate the perfor-
mance improvement of our proposed heterogenous code
cache management scheme. The code cache management
scheme proposed by Baiocchi et al. [12] is implemented
for comparison. For simplicity, the code cache manage-
ment schemes proposed by Baiocchi et al. and us are re-
ferred as Original-HCC and E-HCC, respectively. Sim-
pleScalar/PISA [18] is used as our system simulator and
programs from MiBench benchmark suite [19] are tested.
System parameters for simulation are listed in Table I.
Since the objective of this work is to increase the uti-
lization of L1-HCC and minimize the performance loss due
to accessing frequently executed fragments from L2-LCC,
the implementation of the binary translator is simpliﬁed.
A lookup-table based binary translator is developed to an-
alyze and reproduce PISA instructions. The cycle counts
for accessing instructions from code caches, code transla-
tion, and additional management overhead of E-HCC are
recorded and used to evaluate the performance of Original-
HCC and E-HCC.
Figure 7 shows the comparison for access ratios of SPM
and main memory. The access ratio is computed as the
number of accesses to a memory region divided by the total
number of accesses. As we can see from the upper part of
Figure 7 (experimental results of Original-HCC ), in many
test cases, the access ratios of SPM are less than 40%.
In test cases jpeg d, tiffdither, and dijkstra large,
the access ratios of SPM are even smaller than 3%. This
means, most of the fragments in these test cases are ac-
cess from main memory instead of SPM. In average, the
access ratio of SPM is 49.48% in Original-HCC. Obviously,
Original-HCC cannot eﬀectively bring out the beneﬁt of
the small access latency of SPM. The experimental results
of E-HCC are shown in the lower part of Figure 7. In most
cases, the access ratios of SPM are increased to more than
90%. Only two exceptions, test cases rijndael enc and
rijndael dec, the access ratios of SPM are 30.93% and
30.83%, respectively. This is because the program behav-
iors of these two cases are similar to extremely large loops
where all fragments are executed with similar frequencies.
Therefore, the proposed E-HCC management scheme can
only slightly increase the access ratios of SPM in these two
cases. In average, the access ratio of SPM is increased from
49.78% to 95.06% in E-HCC.
Next, the normalized cycle counts of Original-HCC and
E-HCC are summarized in Figure 8. Since E-HCC can
eﬀectively keep frequently executed fragments in SPM and
increase the access ratio of SPM, the cycle counts in E-HCC
are signiﬁcantly reduced. In average, the performance of
E-HCC is improved by 42.68% as compared with Original-
HCC. In 9 test cases (susan smo, sha, patricia large,
patricia small, adpcm rawcaudio, adpcm rawdaudio,
crc large, crc small, and gsm untoast), the cycle counts
of Original-HCC and E-HCC are similar. For 6 of
these 9 test cases (susan smo, sha, adpcm rawdaudio,
adpcm rawdaudio, crc large, and crc small), the reason
why E-HCC cannot provide further improvements on per-
formance can be explained by the access ratios of SPM in
Figure 7. From Figure 7, we can see that, the access ratios
of SPM in test cases susan smo, sha, adpcm rawdaudio,
adpcm rawdaudio, crc large, and crc small are already
close to 100% when the management scheme of Original-
HCC is used. Therefore, E-HCC cannot provide further
improvements.
As for the reason why the performance of test cases
3A-2
235
A Physical-Location-Aware Fault Redistribution for
Maximum IR-Drop Reduction
Fu-Wei Chen, Shih-Liang Chen, Yung-Sheng Lin and TingTing Hwang
Department of Computer Science
National Tsing Hua University, Hsinchu, Taiwan 30013, R.O.C.
{fwchen, chensl}@cs.nthu.edu.tw,g9662586@oz.nthu.edu.tw, tingting@cs.nthu.edu.tw
Abstract
To guarantee that an application speciﬁc integrated circuits
(ASIC) meets its timing requirement, at-speed scan testing
becomes an indispensable procedure for verifying the per-
formance of ASIC. However, at-speed scan test suffers the
test-induced yield loss. Because the switching activity in
test mode is much higher than that in normal mode, the
switching-induced large current drawn causes severe IR drop
and increases gate delay. X-ﬁlling is the most commonly
used technique to reduce IR-drop effect during at-speed test.
However, the effectiveness of X-ﬁlling depends on the number
and the characteristic of X-bit distribution. In this paper, we
propose a physical-location-aware X-identiﬁcation 1 which re-
distributes faults so that the maximum switching activity is
guaranteed to be reduced after X-ﬁlling. The experimental
results on ITC’99 show that our method has an average of
8.54% more reduction of maximum IR-drop as compared to
a previous work which re-distributes X-bits evenly in all test
vectors.
I. INTRODUCTION
In at-speed testing, scan test is the most commonly used
technique [1]. Nevertheless, it suffers IR-drop issue. First, test
vectors are designed to generate a lot of switchings within a
clock period. Moreover, test vector compression compresses
vectors to reduce test sequence. Thus, the switching activity
in test mode is often higher than that in normal mode. The
application of test vector may result in large current drawn
which causes severe IR drop and increases gate delay. The
analysis from Ahmed et al. [4] also states that IR-drop effect
increases up to 16 percent during at-speed test as compared
to normal mode.
This IR-drop problem in test mode exacerbates delay de-
fects and results in false failures. Xiong et. al. [3] has shown
that the test induced-yield loss of an industrial ASIC with
over a million gates in 90 nm may be as high as 9% when
the path delay is increased by 6 ps. Previous work [5], [6]
has addressed IR-drop issue and emphasized the importance
of avoiding false delay test failures caused by IR-drop.
To solve this problem in test mode, post-ATPG X-ﬁlling [2],
[9] is one effective approach to reduce switching activity by
ﬁlling unspeciﬁed bits in test vectors. In general, there are
over 50% X-bits in most of test vectors. X-ﬁlling approach is
to keep circuit from transition except target faults by ﬁlling
X-bits in test vectors. However the effectiveness of post-ATPG
1This work is supported in part by the National Science Council of Taiwan
under Grant NSC-99-2221-E-007-116-MY2.
X-ﬁlling is determined by the number and the characteristic of
X-bits. The more X-bits in a test vector, the more effective the
X-ﬁlling is. In addition, if the propagation of X-bits reaches hot
region of IR-drop, the IR-drop in hot region can be effectively
reduced by ﬁlling appropriate values to these X-bits.
Yet, one more important issue that decides the effectiveness
of X-ﬁlling needs to be discussed - fault distribution. To reduce
test time, test vectors are compressed as much as possible. The
consequences are twofold. First, many test vectors compressed
in a single test vector reduce the X-bits rate. Second, the
proximity of target faults and the propagation paths of target
faults are usually not considered during test compression. For
example, if faults are located closely or their sensitization
paths propagate through the same hot region, then the high
transition count in the hot region can not be reduced. Both
result in ineffectiveness of X-ﬁlling method.
Previous test vector compressors greedily compress as many
faults as possible to achieve high vector compression rate. That
is, most faults are covered by vectors located at the beginning
of the whole test sequence. K. Miyase et.al. found that this
fault distribution causes low X-ratio in the initial vectors.
Distribution-Controlling X-Identiﬁcation (DCXID) [10] was
proposed to distribute X-bits evenly in all test vectors so that a
fully-speciﬁed test vectors after X-ﬁlling method is applied can
reduce IR-drop. DCXID effectively balances the distribution
of X-bits in every test vector. However, the physical location
of transition gates is not considered. In other words, many
faults propagating through the same region may still lead to
IR-drop no matter how evenly X-bit is distributed in the test
vector.
In this paper, based on transition delay fault model, we
propose an algorithm to identify faults that cause IR-drop in
hot regions. We redistribute these faults to other test vectors.
Instead of blindly balancing the ratio of X-bit in each test
vector, we carefully characterize the care bits of faults and
re-distribute faults based on the locations of faults and the
propagation paths of the faults. Our algorithm is applied after
physical design is performed so that more accurate layout
information can be used.
The rest of this paper is organized as follows. In Section II,
we introduce our test model and state our motivation by an
example. Section III presents our proposed physical-location-
aware algorithm to re-distribute fault so that the maximum IR-
drop is reduced. Section IV shows our experimental results.
Finally, we conclude this paper in Section V.
978-1-4244-7516-2/11/$26.00 ©2011 IEEE
8B-1
701
draw power/ground from the nearby power stripe. By using
stripes and rails, the standard cells are routed to power source.
Rings
Pads
Stripes
Trunks
Rails
Fig. 4. The power/ground distribution network
B. Overview of Our Proposed Method
In order to take physical location into account, our algorithm
is performed after physical synthesis. A test vector (with X-
bits) and a X-ﬁlled test vector (full speciﬁed) are input to
our algorithm. Only those test vectors whose high transition
regions are not improved after X-ﬁlling method is applied are
selected for X-identiﬁcation. The objective of our algorithm is
to identify more X-bits in these test vectors so that X-ﬁlling in
the later stage can be utilized to reduce IR-drop in hot region.
Figure 5 is the overview of our algorithm. After placement
and routing, physical information of the circuit is collected
to be utilized in the following steps. First, region partition
is performed. Since the power grid structure is applied in
our work, we divide the chip into several regions based on
physical layout. All components in the chip are assigned to
appropriate regions according to their coordinates. Each region
is surrounded by limited number of stripes and rails. If a large
number of cells switch simultaneously within the same region,
IR-drop may increase in this region. Our objective is to reduce
switching activity in these hot regions.
The next step is target vector selection. With a set of given
critical paths and X-ﬁlled test vector, switching activity of all
regions for all test vectors are ﬁrst calculated. The test vectors
which have regions with high switching activity are selected
as target vectors for processing. For each test vector, regions
with high switching activity (target region) are processed
one by one. For each target region, candidate faults which
either are in the target region or propagate through it are
selected because these faults lead the components in the target
region to switch. With these candidate faults, we perform a
two-step fault removal to reduce excessive switching activity
in the target region. Finally, we collect the dropped faults
and perform recover dropped fault to retain the fault cover-
age The details of target vector selection, fault removal and
recover dropped fault steps are described in the following
subsections.
C. Target Vector Selection
This step is to recognize test vector that results in high
switching activity regions (target region). In order to dis-
criminate target regions from other regions, a cost function
- weighted switching activity (WSA) [2] with modiﬁcation
is adopted. The cost function, WSA(region) is deﬁned to
represent the IR-drop impact of each region. For a region i,
TetraMax
Initial Vectors 
(with X-bits)
Target Vector Selection
X-filled Patterns
(Full Specified 
Vectors)
Circuit
Placement & Routing
Critical Paths
Region Partition
Recover Dropped Fault
Fault Removal
X-filling
More Test Vector to Be 
Processed
YES
NO
Finish
More Region to 
Be Processed
YES
ŏŐ
Dropped Fault 
Fig. 5. Physical-location-aware X-identiﬁcation ﬂow
its WSA(regioni) is deﬁned as follows.
WSA(regioni) =
∑
∀gatejregioni
gatej
((1 + α · Crij)×
switching weight(typej ) ×
∑
kfanout of gatej
capacitancek )
(1)
Crij represents whether gatej is on critical path and deﬁned
as
Crij =
{
1, if gatej is on critical paths.
0, otherwise.
where α is a weight used to emphasize the importance of
gatej if gatej is on the critical path. Typej in equation (1)
represents type of toggle for gatej . Switching weight of toggle
type representing the preference and ﬂexibility to assign a
speciﬁc transition. The higher the value, the less the preference
(ﬂexibility) is. Then, for all test vectors and for all regions,
we compute their WSA. Among all regions, the regions with
the top 15% highest WSA(region) are viewed as hot regions,
i.e., target regions. These WSA values will be used as our
threshold to select target regions to be processed. Next, a test
vector that has at least one hot region, i.e.,target regions, is
selected for fault removal. (i.e., the step of identifying more
X bits)
D. Fault Removal
For a target vector and a target region, fault removal is
performed. For a target vector, a number of faults are covered
by simulating this vector in circuit. Certain bits, care bits, must
be set in order to cover these faults. Therefore, after selecting
a target vector for X-identiﬁcation, the ﬁrst step, care bit
identiﬁcation, in fault removal is to identify care bits for faults
covered by the test vector. Care bits which either control the
value or propagate value of faults to be observed are identiﬁed.
Without implementing fault simulation, we use TetraMAX
to run fault simulation. We set each care bit to X one by
one for each test vector. For each setting, fault simulation is
performed. After this step, care bits corresponding to each
individual fault are known. With the information, a fault table
8B-1
703
P 1
X
0
1
0
1
1
X
1
0
0
1
0
1
1
1
1
G1
G2
G3
G4 G1
G2
G3
Last Shift  Cycle
(test vector ready)
Launch Cycle
( first timing-frame of capture mode)
FF1
FF3
FF4
FF3
FF2
FF1
1
0
G6
G7G5
FF4
FF2
FF3
FF2
FF1
1
1
G6
G7G5
FF4
0G4
0 1
FF5 FF5
Fig. 9. Reclaim care bits
may result in new non-essential fault. Hence, after setting one
care bit, the ﬂow goes back to the removal of non-essential
fault.
3) Reclaim Un-used Care Bit: After identifying one care
bit and set it to X, we should reclaim other un-used care bits.
We explain why reclaiming un-used care bit is necessary by
an example in Figure 9. In this ﬁgure, FF2, FF3 and FF4
are set to sensitize faults - G1, G4, G5 and G7. When FF2 is
re-set to X (faults, G1, G4, G5 and G7, are removed from the
coverage of the current test vector), it is not necessary to set
the value of FF3 and FF4 any more and FF3 and FF4 can
be reclaimed to X value.
Reclaiming un-used care bit proceeds as follows. First,
recall that, in the step of care bit identiﬁcation, a fault table
that records coverage of fault by care bit is constructed. This
fault table is utilized to reclaim un-used care bit. Suppose that
a care bit, bitj , in column j is set to X to remove the coverage
of faulti. Then, all faultk will not be covered if fekj = 1 for
1 ≤ k ≤ row size. For a fault, faultk, that is not covered,
if its care bit is not required by any other faults, the care bit
can be reclaimed.
Take the fault table in Figure 6 as an example. Suppose that
fault1 is to be removed. Bit1 is selected to be set to X. After
setting bit1 to X, fault2 will not be covered any more. In this
case, care bits, bit2 and bit3, are not required for fault2 any
more. However, bit3 is still required for fault3. Hence, only
bit2 can be reclaimed.
4) Recover Dropped Fault: Removal of pseudo non-
essential and essential fault reduces the fault coverage. To re-
cover the dropped faults, the last step, recover dropped fault,
is performed. The procedure is to check if any test vector in
the original test set can cover a dropped fault without violating
the IR-drop constraint. For one dropped fault, Fi, we select
one vector, tvj , from the original test set. If the care bits of
Fi and tvj are consistent and no region violates the WSA
constraint after setting care bits for Fi, we select tvj to cover
fault, Fi. This checking is performed for all dropped faults.
Note that if a fault can be re-covered in this step, no extra test
vector is generated.
IV. EXPERIMENTAL RESULTS
We implemented the proposed method using C++ program-
ming language and performed experiments on all ITC’99
benchmark [11] except b1-b13 and b16. b1-b13 and b16 are all
small circuits whose gate counts are smaller than 1000 after
synthesis. The circuits are described in VHDL and synthesized
by Synopsys Design Compiler [14] with TSMC 90nm cell
library. Six kinds of gates including BUFFER, INVERTER,
NAND, NOR, AND and OR are used for synthesis. The gate-
level netlist and the test protocol in STIL format are generated.
TABLE I
DESCRIPTIONS OF CIRCUITS AND TEST VECTORS
Circuit #PI #FF #Gate #Stripe #Row #Vec Fault Cov.(%) X-bit(%)
b14 36 215 20328 3 99 574 90.02 63.5
b15 40 417 10289 3 115 653 71.38 86.7
b17 42 1317 30537 5 150 672 70.47 85.4
b18 91 3308 94269 8 747 826 65.76 85.5
b19 92 6618 162799 12 1339 1153 63.98 87.4
b20 36 430 25089 5 293 575 85.48 61.4
b21 36 430 25619 5 293 578 83.22 63.3
b22 36 613 38701 5 293 576 86.02 62.7
TABLE II
THE RESULTS OF X-FILLING
Circuit random-ﬁlled PB-based [2]MAX. Avg. MAX. (%) Avg. (%)
b14† 5.66 0.7980 5.66 0.00‡ 0.6805 14.72
b15 3.17 0.1200 2.87 9.30 0.1078 10.14
b17 4.32 0.1158 3.88 10.24 0.1039 10.24
b18 4.10 0.1151 3.67 11.82 0.1023 12.50
b19 3.81 0.1208 3.52 10.08 0.1048 15.27
b20† 5.13 0.5132 4.98 3.01‡ 0.4581 10.75
b21† 7.81 0.4389 7.71 1.29‡ 0.3907 10.99
b22† 5.49 0.6990 5.45 0.72‡ 0.6157 11.92
† Difﬁcult circuit
‡ Maximum WSA improvement is not signiﬁcant
The input to SoC Encounter (SoCE) [15] is the netlist and
the output is a layout design with detailed physical location
and the timing information after ﬂoorplaning, placement, and
routing. Then the netlist and the test protocol are fed into
TetraMax to generate test vectors with unspeciﬁed bits. In
this generation process, transition delay fault model is taken.
Meanwhile, the timing information is used as input ﬁle for
PrimeTime [17] to produce critical paths information. Our
algorithm takes the netlist of layout design (*.def), the test
vector with unspeciﬁed bits, the test vector after X-ﬁlling
and the critical paths information as input ﬁles, identiﬁes
some care bits, and relaxes them as X-bits for X-ﬁlling.
Table I shows the descriptions of benchmark circuits and test
vectors generated from TetraMAX. The columns labeled #PI,
#FF, #Gate, #Vec, Fault Cov.(%), and X-bit(%) represent the
number of primary input, the number of scan-chain ﬂip-ﬂop,
the total number of gate count, the total number of test vectors,
fault coverage, and average X-bit ratio(%) of all test vectors,
respectively. The number of vertical stripes and the number of
rows used to divide a layout into regions are listed in columns
5 and 6.
Table II shows the maximum and average WSA for random-
ﬁlled (labeled random-ﬁlled) and physical-location-aware X-
ﬁlling method (labeled PB-based) [2]. The column labeled
MAX. and Avg. represent the maximum and average WSA,
respectively. The column (%) is the reduction ratio of PB-
based method as compared with random-ﬁlled. Although the
average of WSA for all circuits can be efﬁciently reduced
by an effective X-ﬁlling algorithm, the improvements of the
maximum WSA for some circuits, b14, b20, b21 and b22
are not signiﬁcant. We view the four circuits as difﬁcult
circuits for X-ﬁlling algorithm. Fault redistribution algorithms,
DCXID and ours, are applied to difﬁcult circuits. Table III
shows the comparison of the maximum WSA after performing
fault redistribution step and then the same X-ﬁlling step. In
Table III, columns labeled Max. WSA, Improvement(%) and
#DF represent the maximum WSA of a region among all
8B-1
705
出席國際學術會議心得報告 
         
計畫編號 NSC 99-2220-E-007-004 
計畫名稱 熱能與功率導向之研究方法 －應用於處理器之設計-子計畫四：熱能導向之編譯器方法及相對溫度感應器設置之研究(3/3) 
出國人員姓名 
服務機關及職稱 
黃婷婷  
清華大學資訊工程學系   教授 
會議時間地點 
1000314~1000318 
德國 Grenoble 
會議名稱 Design, Automation & Test in Europe (DATE 2011)  
發表論文題目 A new architecture for power network in 3D IC 
 
一、參加會議經過 
DATE 會議為歐洲 EDA 領域最大的研討會。本次會議的目的為報告研究的成果。這次報
告論文主題為在 3D IC 下，我們提出 stacked TSV 的 power distributed network 來改善壓降
問題並降低溫度。除了發表論文之外亦和各國學者熱烈討論。 
 
 
  
二、與會心得 
  DATE 會議較其他會議有較多 ESL 方面的學術研究發表，可以看到相同領域的其他方
面研究。除此之外，今年舉辦於德國半導體重鎮 Grenoble 可見此會議與業界關係越來越
密切。在與會期間，可以和許多歐美方面的學者互相討論，除了深入解國內方面研究更
可以吸收歐美學者的研究方向。 
 
Intermetallic compound  
face
tier-2
TSV
via array
tier-1
(bottom)
metal layer
bumping layer
device layer
tier-3
TSV
via array
RDL in Package
back
face
back
face
back
…
top tier
metal layer
face
device layer
Fig. 1. Proﬁle of Stacked TSV
designs not only with single power domain but also with
multiple-power domain. It serves three objectives: (1) power
distributed network for IR-drop minimization; (2) thermal
distributed network for thermal dissipation; (3) decoupling
capacitance distributed network for power noise reduction.
• A voltage volume in 3D IC extended from 2D voltage island
for multiple power domain is proposed.
• Based on the new proposed STDN architecture, an algorithm
to demonstrate the effectiveness of STDN for signal integrity
and thermal dissipation in both single power domain (SPD)
and multiple-power domain (MPD) is put forth.
The rest of the paper is organized as follows. Section 2 proposes
an integrated architecture of stacked-TSV and thermal and power
distributed network (STDN). Section 3 formulates the minimization
problem for voltage drop, temperature and other factors in the
new proposed architecture and proposes an algorithm to solve
them during ﬂoorplanning. Section 4 shows experimental results.
Conclusions are put forth in Section 5.
2 NEW ARCHITECTURE OF STACKED-TSV AND DISTRIBUTED
NETWORK
In this section, we will discuss basic characteristics of STDN and
compare it with other work.
Fig. 1 illustrates the proﬁle of stacked-TSV. The basic character-
istics of the stacked-TSV are described as follows.
• TSV goes through silicon and stops on metal-1 (M1). M1 uses
stacked via-array to connect top metal.
• Connection of tier-1 to package by RDL directly uses ﬂip-
chip method. Tier-1 to tier-2 are connected back-to-back by
bumping layer which also links TSV of tier-1 to TSV of tier-
2.
• Tier-2 to tier-3 are connected face-to-back by intermetallic
compound which links top metal of tier-2 to TSV of tier-3.
The same interconnection is constructed between tier-3 to tier-
4, tier-4 to tier-5, and so on except tier-(n-1) to top tier.
• Tier-(n-1) to top tier is connected face-to-face by intermetallic
compound which links top metal of tier-(n-1) to top metal of
top tier. This structure allows that the top tier does not need
TSV process.
• All of power/ground (PG) sources are connected through RDL
to PG nodes of tier-1, while the PG nodes in upper tiers are
connected to PG sources by TSVs of tier-1.
Fig. 2. Architecture of STDN in 3 Tiers
• Taking 3 tiers as an example. To serve as power TSVs and
thermal TSVs, stacked-TSVs could be connected in two ways:
(1) tier-1 → tier-2; (2) tier-1 → tier-2 → tier-3. To serve as
DECAP (decoupling capacitor) TSVs, stacked-TSVs could be
connected in three ways: (1) tier-1 → tier-2; (2) tier-1 → tier-2
→ tier-3; (3) tier-2 → tier-3;
Next, the basic characteristics of the STDN are described as
follows.
• The pitch ratios among all tiers are integers. For example,
in the experiments conducted in this paper, pitch ratio of tier-
1:tier-2:tier-3:tier-4 is 1:2:4:4. This is a key property of our
power network. With this property, stacked-TSVs connecting
power networks in different tiers can be inserted easily. The
actual pitch size is determined by module activities, IR drop,
thermal dissipation and ﬂoorplan during ﬂoorplanning.
• Stacked-TSVs are placed on cross section optionally.
• For multiple power domain applications, voltage volume is
designed. The concept of voltage volume in 3D is similar to
voltage island in 2D. As is implied by its name, the modules
using the same voltage are placed at the same planar (2D)
location among all tiers such that STDN are partitioned to cut
power mesh and the corresponding stacked-TSVs are able to
connect to the same voltage.
An example of STDN in 3 tiers is illustrated in Fig. 2. The pitch
ratio of tier-1:tier-2:tier-3 is 1:2:4. The planar lines in red are power
mesh and the planar lines in blue are ground mesh. The vertical bars
in red are TSVs connected to power mesh while the vertical bars
in blue are TSVs connected to ground mesh. The thick solid bar in
yellow shows a stacked TSV connects power networks in tier 1, 2
and 3.
Fig. 3 demonstrates an example of 3D ﬂoorplan with voltage
volume in multiple power domain of STDN. The modules in the
same color are assigned to the same voltage. The lines of the same
color are PDN in the same voltage. In this example, two voltages
are assigned for tiers and two voltage volumes are constructed.
In order to avoid large leakage in standard cell, a level shifter is
required when signal propagates from low voltage to high voltage.
One advantage of voltage volume is that level shifters are easily
placed at any tier. Because each tier are partitioned into voltage
volume according to the number of voltages used, each tier has all
its required voltage levels. The two power supply voltages of level
shifter are able to be connected at the same tier wherever level
shifter is placed. Without the concept of voltage volume, it is very
difﬁcult to place level shifter. For example, suppose a level shifter
100+ Randomized Floorplans
STDN for Floorplans
Initial Floorplan with Lowest Cost
Simulated Annealing Done? Floorplan PerturbationNo
Generation of IR-drop Netlist
Generation of Thermal Netlist
SPICE Simulations
No. of Tiers,
Module Information,
STDN Constraints,
Floorplan Constraints,
Timing Constraints,
No. of Voltages
Yes
Next Move Selection
Transient Power Noise Analysis
DECAP Stacked-TSV Insertion
Best Solution 
&
Lowest Cost
Construction of Voltage Volume
STDN Reconstruction
Fig. 4. Proposed Algorithm in 3D Floorplan
IR drop simulation, HSPICE simulator is applied to simulate and
to output temperature measurement data.
3.4 PROPOSED ALGORITHM
In order to trade off many design factors in 3D ﬂoorplan at the
same time, nondeterministic algorithm, simulated annealing (SA),
is used in our algorithm as shown in Fig. 4. In addition, 3D B*-tree
structure is applied in our algorithm as a ﬂoorplan representation
[5].
First, the number of tiers in 3D ﬂoorplan, module information
(power consumption, netlist, width, length, pins, etc.), the size of
stacked-TSV, the width of PDN in STDN, range of PDN pitch,
IR drop and EM limitations are fed into ﬂow. Furthermore, if 3D
ﬂoorplan is constructed in multiple power domain (MPD) the timing
constraints and the number of voltages applied in MPD are also
fed into ﬂow. Second, hundreds of 3D ﬂoorplan of the selected
benchmark are randomly generated and the corresponding STDN
structures are constructed accordingly. Based on our cost function,
the best ﬂoorplan with the corresponding lowest cost is found
among those hundreds of random ﬂoorplans as an initial solution. In
single power domain (SPD), the cost factors in cost function include
maximum IR drop, maximum temperature, maximum temperature
gradient, maximum area variation, footprint area, the number of
stacked-TSVS in STDN, the number of TSVs for signals, total
wire length of signals, total wire length of STDN and white space.
White space is deﬁned as area not used by module in core area (it
might be used by power strips in STDN and stacked-TSVs outside
of modules). In multiple power domain (MPD), besides the cost
factors deﬁned in single power domain, the cost factors in cost
function include the number of level shifters, area of level shifters
and product of power and delay.
Third, simulated annealing (SA), a non-deterministic algorithm,
is applied as a main body of our algorithm to ﬁnd lowest cost
solution. Fourth, the perturbation of the current ﬂoorplan and STDN
is created. The perturbation consists of inter-tier movement, inter-
tier swapping, intra-tier movement, intra-tier swapping, intra-tier
rotation and pitch reﬁnement. Fifth, if 3D ﬂoorplan is MPD, voltage
volume (i.e., voltage domain partition) is constructed. Then Integer
Linear Programming (ILP) is applied for voltage assignment [8].
Sixth, the SPICE run decks and net-lists (both DC and transient)
are constructed according to 3D ﬂoorplan and STDN structure for
IR-drop and thermal simulations. Seventh, SA selection method is
used with HSPICE simulation results.
TABLE I
KEY PARAMETERS USED IN EXPERIMENTS
Parameter Value
Max. number of tiers 4
Thickness of wafer 50um
Metal width for signals 1um, 10um
Max. Metal Width 10um
Diameter of TSV 6um, 8um
Metal width for STDN 8um, 10um
Min. pitch of STDN 50um
ρR of TSV (Ω · um) 0.0198
ρC of TSV (fF/um2) 4.316
ambient temperature 25◦C
Finally, when the simulated annealing process terminates, tran-
sient power noise (transient IR drop analysis taking both resistance
and capacitance into account) is analyzed for the generated ﬂoorplan
and STDN. If transient power noise of node is larger than a
predeﬁned threshold (10% VDD in our algorithm), the stacked-
TSVs, serving as decoupling capacitors, are added in STDN around
nodes which violates power noise threshold.
4 EXPERIMENTS
4.1 EXPERIMENT SETUP
Four benchmark examples (AMI33, XEROX, APTE and AMI49)
selected from MCNC benchmarks are used in our new architecture
for 3D ﬂoorplan experiments. The number of tiers varies from 1 to 4
for each benchmark. The CMOS BULK process with copper TSV
and metal layers in 90nm technology is applied in experiments.
As to 3D ﬂoorplan in single power domain, 1V typical voltage
is applied. As regards 3D ﬂoorplan in multiple power domain,
three voltages (0.8V, 1.0V, 1.2V) are applied. When the number
of tier is one, the ﬂip chip with 2 times STDN pitch is applied to
connect power pads. In other words, ﬂip chip pitch is 100um while
STDN pitch is 50um. If maximum IR drop and ground bouncing
is larger than 15% of VDD, then the metal width of power pin of
the module to STDN is redeﬁned to 10um (the width is 1um by
default for power pins of the modules). The key parameters used
in experiments are summarized in Table I, where ρR is resistivity
and ρC is capacitance per unit area.
Furthermore, we take effect of TSV area into consideration in
Table II and comparison of single and multiple power domains in
subsection 4.2.2 where module area is expanded to accommodate
the area of TSVs. The amount of expansion is determined by the
number of stacked-TSV, size of TSV used and structure of STDN.
However, the comparison in Tables III and IV assumes zero size
TSV because our data is compared to that presented in [5] where
zero size TSV (i.e., a module is not expanded to accommodate
TSVs) is assumed.
4.2 EXPERIMENTAL RESULTS
4.2.1 3D FLOORPLAN IN SINGLE POWER DOMAIN
The ﬁrst experiment is to understand the effectiveness of STDN
in single power domain. The experiment results are shown in Table
II. All data are the average of four selected MCNC benchmarks. In
this table, the module area is scaled up according to the number of
stacked-TSVs and structure of STDN. ”Size” in the ﬁrst column is
the size of stacked-TSV, where 6 (8) is a 6 (8)um TSV. ”Ratio” in
the ﬁrst column means data in ”Ratio” rows are performance ratio
of 6um data (numerator) to 8um data (denominator) ”#Tiers” is
TABLE IV
COMPARISON OF NETWORK STRUCTURE [5]
Size #Tier
AMI33 XEROX APTE AMI49
Max IR #TSV Max IR #TSV Max IR #TSV Max IR #TSV
Ours [5] Ours [5] Ours [5] Ours [5] Ours [5] Ours [5] Ours [5] Ours [5]
6 1 0.012 0.140 0 0 0.018 0.148 0 0 0.068 0.597 0 0 0.139 0.479 0 0
6 2 0.143 0.145 8 12 0.070 0.143 36 72 0.211 0.326 96 168 0.153 0.153 72 256
6 3 0.130 0.139 10 16 0.067 0.135 32 168 0.288 0.366 94 196 0.180 0.282 94 168
6 4 0.131 0.127 12 28 0.053 0.131 34 252 0.334 0.577 72 264 0.154 0.161 246 450
8 1 0.013 0.144 0 0 0.018 0.110 0 0 0.080 0.201 0 0 0.144 0.469 0 0
8 2 0.071 0.137 8 8 0.091 0.138 40 72 0.263 0.341 70 8 0.183 0.221 40 70
8 3 0.086 0.145 10 16 0.090 0.132 40 24 0.258 0.404 72 160 0.163 0.185 120 216
8 4 0.081 0.104 20 24 0.089 0.123 40 252 0.234 1.185 86 324 0.158 0.198 162 216
As to the maximum temperature and the maximum temperature
gradient, both structures show similar performance. As to footprint
area, total wire length and white space, our approach shows better
results. As to the maximum IR drop, out approach reduces 64%
more voltage drop than that in [5].
As to the number of TSVs, our approach shows ﬂexibility to
provide 5 times more number of TSVs than [5]. Even though 5 times
more number of TSVs are used, the total area of TSVs occupies
less than 2% (0.51%, 0.51%, 0.23%) of footprint area in AMI33
(XEROR, APTE, AMI49).
Next, we want to understand if our power network is a better
structure even without large number of TSVs, we conduct an
experiment to remove the requirement of IR drop reduction in our
approach. Table IV is the comparison of [5] and ours. It shows that
we use less or equal number of TSVs for 31 cases out of 32 and
achieve smaller maximum IR drop for all cases.
4.2.2 3D FLOORPLAN IN MULTIPLE POWER DOMAIN
The third experiment is to understand the effectiveness of STDN
in multiple power domain. In multiple power domain, two kind of
application domains are experimented- high performance (HP) and
low power (LP). Three voltages (0.8V, 1.0V, 1.2V) are available
in experiment of multiple power domain. Because of no timing
information provided in MCNC benchmarks, we create delay infor-
mation of module based on module area. The larger module area
results in larger delay. As to HP experiments, the timing constraint
of MPD is set to 0.9X of SPD delay in 1.0V (i.e., speed of MPD is
10% faster than that of SPD in 1.0V). As regards LP experiments,
the timing constraint of MPD is set to 1.3X of SPD delay in 1.0V
(i.e., speed of MPD is 30% slower than that of SPD in 1.0V). All
data are the average of four selected MCNC benchmarks.
In summary, both in high performance (HP) and low power (LP)
experiments, MPD shows similar performance as compared with
SPD in footprint area, the number of TSVs for signal interconnec-
tions, and the total wire length of signal interconnections.
As to speed in HP experiments, compared with SPD, MPD
achieves 14% faster with overhead of 2.0X more maximum IR drop,
8% higher maximum temperature, 1.4X more number of stacked-
TSVs, 41% longer total wire length of STDN, 10% more white
space, 26 level shifters added and 29% more power .
As regards power-related performance in LP experiments, com-
pared with SPD, MPD achieves 42% less power, 31% less maxi-
mum IR drop, 11% lower maximum temperature with overhead of
24% more number of stacked-TSVs, 18% longer total wire length
of STDN, 28% more white space, 21 level shifters added and 29%
slower.
From voltage volume point of view, the total wire length of
signal interconnections and footprint area are not much affected.
Moreover, the number of level shifters is very limited. However,
multiple power domain partition (cut) does have impact on STDN
architecture (the number of stacked-TSV and total wire length of
STDN) and white space.
5 CONCLUSION
A new integrated architecture, STDN (Stacked TSV Distributed
Network), is developed to create 3D ﬂoorplan and its distributed
network for power delivery and thermal dissipation at the same time.
It presents its effectiveness in solving IR drop, temperature, power
noise and ﬂoorplan quality. Furthermore, voltage volume is proved
as an effective approach in multiple power domain partitioning for
3D ﬂoorplan.
REFERENCES
[1] W. Chen, W. R. Bottoms, K. Pressel, and J. Wolf, “The next step in
assembly and packaging: System level integration in the package (SiP),”
Tech. Rep., 2008.
[2] M. Umemoto, K. Tanida, Y. Nemoto, M. Hoshino, K. Kojima, Y. Shirai,
and K. Takahashi, “High-performance vertical interconnection for high-
density 3D chip stacking package,” in Proc. Electronic Components and
technology Conference ECTC, 2004, pp. 616–623.
[3] S. Sapatnekar, “Addressing thermal and power delivery bottlenecks in
3D circuits,” in Design Automation Conference, 2009. ASP-DAC 2009.
Asia and South Paciﬁc, Jan. 2009, pp. 423–428.
[4] Y.-J. Lee, Y. J. Kim, G. Huang, M. Bakir, Y. Joshi, A. Fedorov, and S. K.
Lim, “Co-design of signal, power, and thermal distribution networks for
3D ICs,” in Design, Automation Test in Europe Conference Exhibition,
2009. DATE ’09., Apr. 2009, pp. 610–615.
[5] P. Falkenstern, Y. Xie, Y.-W. Chang, and Y. Wang, “Three-dimensional
integrated circuits (3D IC) ﬂoorplan and power/ground network co-
synthesis,” in Design Automation Conference (ASP-DAC), 2010 15th
Asia and South Paciﬁc, Jan. 2010, pp. 169–174.
[6] G. Huang, M. Bakir, A. Naeemi, H. Chen, and J. Meindl, “Power
delivery for 3d chip stacks: Physical modeling and design implication,”
in Electrical Performance of Electronic Packaging, 2007 IEEE, Oct.
2007, pp. 205 –208.
[7] HSPICE Simulation and Analysis User Guide, V-2004.03. Synopsys,
2004.
[8] W.-P. Lee, H.-Y. Liu, and Y.-W. Chang, “An ILP algorithm for
post-ﬂoorplanning voltage-island generation considering power-network
planning,” in Computer-Aided Design, 2007. ICCAD 2007. IEEE/ACM
International Conference on, Nov. 2007, pp. 650–655.
[9] H. Su, S. Sapatnekar, and S. Nassif, “Optimal decoupling capacitor
sizing and placement for standard-cell layout designs,” Computer-Aided
Design of Integrated Circuits and Systems, IEEE Transactions on,
vol. 22, no. 4, pp. 428 – 436, Apr 2003.
國際合作計畫赴國外研究心得報告 
         
計畫編號 NSC 99-2220-E-007-004 
計畫名稱 熱能與功率導向之研究方法 －應用於處理器之設計-子計畫四：熱能導向之編譯器方法及相對溫度感應器設置之研究(3/3) 
出國人員姓名 
服務機關及職稱 
黃婷婷  
清華大學資訊工程學系   教授 
會議時間地點 
1000312~1000319 
法國 Grenoble 
會議名稱 2011 DATE 
發表論文題目 A New Architecture for Power Network in 3D IC 
 
一、參加會議經過 
本次會議的目的為報告研究的成果。我們的論文主要是在探討 3D IC Power Network的設
計，我們提出了一個新的 Power Network的 structure，可以減少 IR Drop、散熱等的問題。
除了論文報告外，亦見到許多相關領域教授，討論甚佳。 
 
 
二、與會心得 
DATE會議包含較多 system及 software方面的研究領域，DATE會議有較多歐洲學者參
加。其 submission paper 的數目及參加人數，都成長很快。Grenoble是法國的科技產業
的重鎮，可以說是法國的矽谷，工業界參加很多人。Grenoblen雖是工業城，但是也是一
個古都，城市發展的很美麗，是一個學習的榜樣。 
 
Intermetallic compound  
face
tier-2
TSV
via array
tier-1
(bottom)
metal layer
bumping layer
device layer
tier-3
TSV
via array
RDL in Package
back
face
back
face
back
…
top tier
metal layer
face
device layer
Fig. 1. Proﬁle of Stacked TSV
designs not only with single power domain but also with
multiple-power domain. It serves three objectives: (1) power
distributed network for IR-drop minimization; (2) thermal
distributed network for thermal dissipation; (3) decoupling
capacitance distributed network for power noise reduction.
• A voltage volume in 3D IC extended from 2D voltage island
for multiple power domain is proposed.
• Based on the new proposed STDN architecture, an algorithm
to demonstrate the effectiveness of STDN for signal integrity
and thermal dissipation in both single power domain (SPD)
and multiple-power domain (MPD) is put forth.
The rest of the paper is organized as follows. Section 2 proposes
an integrated architecture of stacked-TSV and thermal and power
distributed network (STDN). Section 3 formulates the minimization
problem for voltage drop, temperature and other factors in the
new proposed architecture and proposes an algorithm to solve
them during ﬂoorplanning. Section 4 shows experimental results.
Conclusions are put forth in Section 5.
2 NEW ARCHITECTURE OF STACKED-TSV AND DISTRIBUTED
NETWORK
In this section, we will discuss basic characteristics of STDN and
compare it with other work.
Fig. 1 illustrates the proﬁle of stacked-TSV. The basic character-
istics of the stacked-TSV are described as follows.
• TSV goes through silicon and stops on metal-1 (M1). M1 uses
stacked via-array to connect top metal.
• Connection of tier-1 to package by RDL directly uses ﬂip-
chip method. Tier-1 to tier-2 are connected back-to-back by
bumping layer which also links TSV of tier-1 to TSV of tier-
2.
• Tier-2 to tier-3 are connected face-to-back by intermetallic
compound which links top metal of tier-2 to TSV of tier-3.
The same interconnection is constructed between tier-3 to tier-
4, tier-4 to tier-5, and so on except tier-(n-1) to top tier.
• Tier-(n-1) to top tier is connected face-to-face by intermetallic
compound which links top metal of tier-(n-1) to top metal of
top tier. This structure allows that the top tier does not need
TSV process.
• All of power/ground (PG) sources are connected through RDL
to PG nodes of tier-1, while the PG nodes in upper tiers are
connected to PG sources by TSVs of tier-1.
Fig. 2. Architecture of STDN in 3 Tiers
• Taking 3 tiers as an example. To serve as power TSVs and
thermal TSVs, stacked-TSVs could be connected in two ways:
(1) tier-1 → tier-2; (2) tier-1 → tier-2 → tier-3. To serve as
DECAP (decoupling capacitor) TSVs, stacked-TSVs could be
connected in three ways: (1) tier-1 → tier-2; (2) tier-1 → tier-2
→ tier-3; (3) tier-2 → tier-3;
Next, the basic characteristics of the STDN are described as
follows.
• The pitch ratios among all tiers are integers. For example,
in the experiments conducted in this paper, pitch ratio of tier-
1:tier-2:tier-3:tier-4 is 1:2:4:4. This is a key property of our
power network. With this property, stacked-TSVs connecting
power networks in different tiers can be inserted easily. The
actual pitch size is determined by module activities, IR drop,
thermal dissipation and ﬂoorplan during ﬂoorplanning.
• Stacked-TSVs are placed on cross section optionally.
• For multiple power domain applications, voltage volume is
designed. The concept of voltage volume in 3D is similar to
voltage island in 2D. As is implied by its name, the modules
using the same voltage are placed at the same planar (2D)
location among all tiers such that STDN are partitioned to cut
power mesh and the corresponding stacked-TSVs are able to
connect to the same voltage.
An example of STDN in 3 tiers is illustrated in Fig. 2. The pitch
ratio of tier-1:tier-2:tier-3 is 1:2:4. The planar lines in red are power
mesh and the planar lines in blue are ground mesh. The vertical bars
in red are TSVs connected to power mesh while the vertical bars
in blue are TSVs connected to ground mesh. The thick solid bar in
yellow shows a stacked TSV connects power networks in tier 1, 2
and 3.
Fig. 3 demonstrates an example of 3D ﬂoorplan with voltage
volume in multiple power domain of STDN. The modules in the
same color are assigned to the same voltage. The lines of the same
color are PDN in the same voltage. In this example, two voltages
are assigned for tiers and two voltage volumes are constructed.
In order to avoid large leakage in standard cell, a level shifter is
required when signal propagates from low voltage to high voltage.
One advantage of voltage volume is that level shifters are easily
placed at any tier. Because each tier are partitioned into voltage
volume according to the number of voltages used, each tier has all
its required voltage levels. The two power supply voltages of level
shifter are able to be connected at the same tier wherever level
shifter is placed. Without the concept of voltage volume, it is very
difﬁcult to place level shifter. For example, suppose a level shifter
100+ Randomized Floorplans
STDN for Floorplans
Initial Floorplan with Lowest Cost
Simulated Annealing Done? Floorplan PerturbationNo
Generation of IR-drop Netlist
Generation of Thermal Netlist
SPICE Simulations
No. of Tiers,
Module Information,
STDN Constraints,
Floorplan Constraints,
Timing Constraints,
No. of Voltages
Yes
Next Move Selection
Transient Power Noise Analysis
DECAP Stacked-TSV Insertion
Best Solution 
&
Lowest Cost
Construction of Voltage Volume
STDN Reconstruction
Fig. 4. Proposed Algorithm in 3D Floorplan
IR drop simulation, HSPICE simulator is applied to simulate and
to output temperature measurement data.
3.4 PROPOSED ALGORITHM
In order to trade off many design factors in 3D ﬂoorplan at the
same time, nondeterministic algorithm, simulated annealing (SA),
is used in our algorithm as shown in Fig. 4. In addition, 3D B*-tree
structure is applied in our algorithm as a ﬂoorplan representation
[5].
First, the number of tiers in 3D ﬂoorplan, module information
(power consumption, netlist, width, length, pins, etc.), the size of
stacked-TSV, the width of PDN in STDN, range of PDN pitch,
IR drop and EM limitations are fed into ﬂow. Furthermore, if 3D
ﬂoorplan is constructed in multiple power domain (MPD) the timing
constraints and the number of voltages applied in MPD are also
fed into ﬂow. Second, hundreds of 3D ﬂoorplan of the selected
benchmark are randomly generated and the corresponding STDN
structures are constructed accordingly. Based on our cost function,
the best ﬂoorplan with the corresponding lowest cost is found
among those hundreds of random ﬂoorplans as an initial solution. In
single power domain (SPD), the cost factors in cost function include
maximum IR drop, maximum temperature, maximum temperature
gradient, maximum area variation, footprint area, the number of
stacked-TSVS in STDN, the number of TSVs for signals, total
wire length of signals, total wire length of STDN and white space.
White space is deﬁned as area not used by module in core area (it
might be used by power strips in STDN and stacked-TSVs outside
of modules). In multiple power domain (MPD), besides the cost
factors deﬁned in single power domain, the cost factors in cost
function include the number of level shifters, area of level shifters
and product of power and delay.
Third, simulated annealing (SA), a non-deterministic algorithm,
is applied as a main body of our algorithm to ﬁnd lowest cost
solution. Fourth, the perturbation of the current ﬂoorplan and STDN
is created. The perturbation consists of inter-tier movement, inter-
tier swapping, intra-tier movement, intra-tier swapping, intra-tier
rotation and pitch reﬁnement. Fifth, if 3D ﬂoorplan is MPD, voltage
volume (i.e., voltage domain partition) is constructed. Then Integer
Linear Programming (ILP) is applied for voltage assignment [8].
Sixth, the SPICE run decks and net-lists (both DC and transient)
are constructed according to 3D ﬂoorplan and STDN structure for
IR-drop and thermal simulations. Seventh, SA selection method is
used with HSPICE simulation results.
TABLE I
KEY PARAMETERS USED IN EXPERIMENTS
Parameter Value
Max. number of tiers 4
Thickness of wafer 50um
Metal width for signals 1um, 10um
Max. Metal Width 10um
Diameter of TSV 6um, 8um
Metal width for STDN 8um, 10um
Min. pitch of STDN 50um
ρR of TSV (Ω · um) 0.0198
ρC of TSV (fF/um2) 4.316
ambient temperature 25◦C
Finally, when the simulated annealing process terminates, tran-
sient power noise (transient IR drop analysis taking both resistance
and capacitance into account) is analyzed for the generated ﬂoorplan
and STDN. If transient power noise of node is larger than a
predeﬁned threshold (10% VDD in our algorithm), the stacked-
TSVs, serving as decoupling capacitors, are added in STDN around
nodes which violates power noise threshold.
4 EXPERIMENTS
4.1 EXPERIMENT SETUP
Four benchmark examples (AMI33, XEROX, APTE and AMI49)
selected from MCNC benchmarks are used in our new architecture
for 3D ﬂoorplan experiments. The number of tiers varies from 1 to 4
for each benchmark. The CMOS BULK process with copper TSV
and metal layers in 90nm technology is applied in experiments.
As to 3D ﬂoorplan in single power domain, 1V typical voltage
is applied. As regards 3D ﬂoorplan in multiple power domain,
three voltages (0.8V, 1.0V, 1.2V) are applied. When the number
of tier is one, the ﬂip chip with 2 times STDN pitch is applied to
connect power pads. In other words, ﬂip chip pitch is 100um while
STDN pitch is 50um. If maximum IR drop and ground bouncing
is larger than 15% of VDD, then the metal width of power pin of
the module to STDN is redeﬁned to 10um (the width is 1um by
default for power pins of the modules). The key parameters used
in experiments are summarized in Table I, where ρR is resistivity
and ρC is capacitance per unit area.
Furthermore, we take effect of TSV area into consideration in
Table II and comparison of single and multiple power domains in
subsection 4.2.2 where module area is expanded to accommodate
the area of TSVs. The amount of expansion is determined by the
number of stacked-TSV, size of TSV used and structure of STDN.
However, the comparison in Tables III and IV assumes zero size
TSV because our data is compared to that presented in [5] where
zero size TSV (i.e., a module is not expanded to accommodate
TSVs) is assumed.
4.2 EXPERIMENTAL RESULTS
4.2.1 3D FLOORPLAN IN SINGLE POWER DOMAIN
The ﬁrst experiment is to understand the effectiveness of STDN
in single power domain. The experiment results are shown in Table
II. All data are the average of four selected MCNC benchmarks. In
this table, the module area is scaled up according to the number of
stacked-TSVs and structure of STDN. ”Size” in the ﬁrst column is
the size of stacked-TSV, where 6 (8) is a 6 (8)um TSV. ”Ratio” in
the ﬁrst column means data in ”Ratio” rows are performance ratio
of 6um data (numerator) to 8um data (denominator) ”#Tiers” is
TABLE IV
COMPARISON OF NETWORK STRUCTURE [5]
Size #Tier
AMI33 XEROX APTE AMI49
Max IR #TSV Max IR #TSV Max IR #TSV Max IR #TSV
Ours [5] Ours [5] Ours [5] Ours [5] Ours [5] Ours [5] Ours [5] Ours [5]
6 1 0.012 0.140 0 0 0.018 0.148 0 0 0.068 0.597 0 0 0.139 0.479 0 0
6 2 0.143 0.145 8 12 0.070 0.143 36 72 0.211 0.326 96 168 0.153 0.153 72 256
6 3 0.130 0.139 10 16 0.067 0.135 32 168 0.288 0.366 94 196 0.180 0.282 94 168
6 4 0.131 0.127 12 28 0.053 0.131 34 252 0.334 0.577 72 264 0.154 0.161 246 450
8 1 0.013 0.144 0 0 0.018 0.110 0 0 0.080 0.201 0 0 0.144 0.469 0 0
8 2 0.071 0.137 8 8 0.091 0.138 40 72 0.263 0.341 70 8 0.183 0.221 40 70
8 3 0.086 0.145 10 16 0.090 0.132 40 24 0.258 0.404 72 160 0.163 0.185 120 216
8 4 0.081 0.104 20 24 0.089 0.123 40 252 0.234 1.185 86 324 0.158 0.198 162 216
As to the maximum temperature and the maximum temperature
gradient, both structures show similar performance. As to footprint
area, total wire length and white space, our approach shows better
results. As to the maximum IR drop, out approach reduces 64%
more voltage drop than that in [5].
As to the number of TSVs, our approach shows ﬂexibility to
provide 5 times more number of TSVs than [5]. Even though 5 times
more number of TSVs are used, the total area of TSVs occupies
less than 2% (0.51%, 0.51%, 0.23%) of footprint area in AMI33
(XEROR, APTE, AMI49).
Next, we want to understand if our power network is a better
structure even without large number of TSVs, we conduct an
experiment to remove the requirement of IR drop reduction in our
approach. Table IV is the comparison of [5] and ours. It shows that
we use less or equal number of TSVs for 31 cases out of 32 and
achieve smaller maximum IR drop for all cases.
4.2.2 3D FLOORPLAN IN MULTIPLE POWER DOMAIN
The third experiment is to understand the effectiveness of STDN
in multiple power domain. In multiple power domain, two kind of
application domains are experimented- high performance (HP) and
low power (LP). Three voltages (0.8V, 1.0V, 1.2V) are available
in experiment of multiple power domain. Because of no timing
information provided in MCNC benchmarks, we create delay infor-
mation of module based on module area. The larger module area
results in larger delay. As to HP experiments, the timing constraint
of MPD is set to 0.9X of SPD delay in 1.0V (i.e., speed of MPD is
10% faster than that of SPD in 1.0V). As regards LP experiments,
the timing constraint of MPD is set to 1.3X of SPD delay in 1.0V
(i.e., speed of MPD is 30% slower than that of SPD in 1.0V). All
data are the average of four selected MCNC benchmarks.
In summary, both in high performance (HP) and low power (LP)
experiments, MPD shows similar performance as compared with
SPD in footprint area, the number of TSVs for signal interconnec-
tions, and the total wire length of signal interconnections.
As to speed in HP experiments, compared with SPD, MPD
achieves 14% faster with overhead of 2.0X more maximum IR drop,
8% higher maximum temperature, 1.4X more number of stacked-
TSVs, 41% longer total wire length of STDN, 10% more white
space, 26 level shifters added and 29% more power .
As regards power-related performance in LP experiments, com-
pared with SPD, MPD achieves 42% less power, 31% less maxi-
mum IR drop, 11% lower maximum temperature with overhead of
24% more number of stacked-TSVs, 18% longer total wire length
of STDN, 28% more white space, 21 level shifters added and 29%
slower.
From voltage volume point of view, the total wire length of
signal interconnections and footprint area are not much affected.
Moreover, the number of level shifters is very limited. However,
multiple power domain partition (cut) does have impact on STDN
architecture (the number of stacked-TSV and total wire length of
STDN) and white space.
5 CONCLUSION
A new integrated architecture, STDN (Stacked TSV Distributed
Network), is developed to create 3D ﬂoorplan and its distributed
network for power delivery and thermal dissipation at the same time.
It presents its effectiveness in solving IR drop, temperature, power
noise and ﬂoorplan quality. Furthermore, voltage volume is proved
as an effective approach in multiple power domain partitioning for
3D ﬂoorplan.
REFERENCES
[1] W. Chen, W. R. Bottoms, K. Pressel, and J. Wolf, “The next step in
assembly and packaging: System level integration in the package (SiP),”
Tech. Rep., 2008.
[2] M. Umemoto, K. Tanida, Y. Nemoto, M. Hoshino, K. Kojima, Y. Shirai,
and K. Takahashi, “High-performance vertical interconnection for high-
density 3D chip stacking package,” in Proc. Electronic Components and
technology Conference ECTC, 2004, pp. 616–623.
[3] S. Sapatnekar, “Addressing thermal and power delivery bottlenecks in
3D circuits,” in Design Automation Conference, 2009. ASP-DAC 2009.
Asia and South Paciﬁc, Jan. 2009, pp. 423–428.
[4] Y.-J. Lee, Y. J. Kim, G. Huang, M. Bakir, Y. Joshi, A. Fedorov, and S. K.
Lim, “Co-design of signal, power, and thermal distribution networks for
3D ICs,” in Design, Automation Test in Europe Conference Exhibition,
2009. DATE ’09., Apr. 2009, pp. 610–615.
[5] P. Falkenstern, Y. Xie, Y.-W. Chang, and Y. Wang, “Three-dimensional
integrated circuits (3D IC) ﬂoorplan and power/ground network co-
synthesis,” in Design Automation Conference (ASP-DAC), 2010 15th
Asia and South Paciﬁc, Jan. 2010, pp. 169–174.
[6] G. Huang, M. Bakir, A. Naeemi, H. Chen, and J. Meindl, “Power
delivery for 3d chip stacks: Physical modeling and design implication,”
in Electrical Performance of Electronic Packaging, 2007 IEEE, Oct.
2007, pp. 205 –208.
[7] HSPICE Simulation and Analysis User Guide, V-2004.03. Synopsys,
2004.
[8] W.-P. Lee, H.-Y. Liu, and Y.-W. Chang, “An ILP algorithm for
post-ﬂoorplanning voltage-island generation considering power-network
planning,” in Computer-Aided Design, 2007. ICCAD 2007. IEEE/ACM
International Conference on, Nov. 2007, pp. 650–655.
[9] H. Su, S. Sapatnekar, and S. Nassif, “Optimal decoupling capacitor
sizing and placement for standard-cell layout designs,” Computer-Aided
Design of Integrated Circuits and Systems, IEEE Transactions on,
vol. 22, no. 4, pp. 428 – 436, Apr 2003.
99 年度專題研究計畫研究成果彙整表 
計畫主持人：黃婷婷 計畫編號：99-2220-E-007-004- 
計畫名稱：熱能與功率導向之研究方法－應用於處理器之設計--子計畫四：熱能導向之編譯器方法及
相對溫度感應器設置之研究(3/3) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 3 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 3 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 7 7 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
