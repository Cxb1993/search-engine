 I 
摘要 
本計畫的目標，要將一個完整的華語 CAPT（電腦輔助發音訓練，Computer Assisted 
Pronunciation Training）系統實做在微電腦平台上（以 ARM11 平台為主），以便符合各項
載具的使用（例如智慧型手機、機器人、玩具等），此系統除了能夠使用語音辨識的技術和
使用者進行華語對話外，還必須對使用者的華語發音進行評分（包含每個詞彙及每一個音，
評分標準包含音色、韻律、音調、音量、連音等），並給予發音改進的建議，讓使用者能夠
反覆練習，加強自己口說華語的正確發音。「電腦輔助發音訓練與評分」則是語音辨識的一
個新興研究與應用領域，相關的文獻與報告相當豐富，但是用於嵌入式系統的整合應用，
則尚未有相關文獻或報導。我們希望經由此計畫，實際產出一個可以和使用者進行「華語
對話」和「發音練習」的系統，最後並將相關的開發經驗推廣到英語和日語等不同語系，
以語音科技來促進數位學習產業升級。 
 
關鍵詞：電腦輔助發音訓練、電腦輔助語言學習、語音辨識、語音評分 
 
Abstract 
In this project, we shall concentrate on the research and development of a computer-assisted 
pronunciation training (CAPT) system for Mandarin Chinese, and more importantly, we shall 
implement the CAPT system on an ARM11-based embedded platform. The system should be able 
to take an utterance from the user and compare it to that of a target native speaker. The similarity 
assessment is based on timbre, pitch (tone/intonation), time duration (rhythm), and volume. The 
scoring details should be able to used phone-level acoustic information for objective and 
consistent evaluation. Moreover, the system should be able to identify common error patterns 
(syllables or phones) of non-native speakers. 
 
Successful implementation of a CAPT system over an embedded platform is a quite a challenge 
since we need to convert all the floating operations into their counterparts in integers. However, it 
is also rewarding since the end product ranges from smart phones to intelligent robots/toys that 
can provide ubiquitous edutainment for digital learning. 
 
Keywords: Computer-assisted Pronunciation Training (CAPT), Computer-assisted Language 
Learning (CALL), Embedded Speech Recognition, Pronunciation Assessment 
 
 1 
 前言 
最近幾年開始，世界各地開始有一股學習中文的熱潮。各種中文學習的書籍或是課程不斷
地問市，使得中文學習的市場非常的熱絡。相較於有關英文學習的電腦軟體隨處可見，有
關中文學習的電腦軟體在市面上卻不多見，可隨身攜帶學習的中文口語學習機更是非常少
見。 
由於個人電腦的普及和運算速度的提高，「電腦輔助語言學習」（CALL, Computer Assisted 
Language Learning）的研發已經到達可以商業化的階段，其中又以「電腦輔助發音訓練」
（Computer Assisted Pronunciation Training）最受到矚目，因為其實用性很高，可以大量彌
補世界上華語師資的不足，如果能夠開發可隨身攜帶學習的中文口語學習機，個人可以進
行無所不在的學習，以加強口說語言之能力，這是市場經濟效益相當巨大，但是其技術上
的難度很高，除了需要語音辨識的技術外，還需要評分參數的微調，以及瞭解語音學習可
能碰到的困難，才能整合各個領域的資源，開發一套確實有用的系統。然而，要開發適用
於嵌入式系統的電腦輔助口說華語發音練習系統，還要考量嵌入式平台硬體效能的限制，
例如核心處理器速度較慢，只有定點數(Fixed-point)運算單位等問題。 
本計畫和軟體工具開發業者「鈦思科技股份有限公司」合作開發「適用於嵌入式系統的電
腦輔助口說英文發音練習系統」（Computer-assisted English Pronunciation Training for 
Embedded Systems），使用語音辨識及 CAPT相關技術，在工研院的 PAC Duo平台上開發
語音辨識系統，預計使用現有的軟硬體來推廣相關的技術到各個業界。 
 
 3 
 文獻探討 
由於多語系語音辨識與 CAPT的相關研究，都需要以語音處理及辨識為主要技術核心，因
此在國內從事 CAPT相關研究的研究單位或大學，都是以語音辨識起家，相關的學者有台
灣大學的李琳山教授，成功大學的吳宗憲教授、王駿發教授，交通大學的陳信宏教授，清
華大學的王小川教授，銘傳大學的周福強教授，長庚大學的呂仁園教授，師範大學的陳柏
琳教授等等。在國外方面，有關 CAPT的研究更加普遍，例如，以 2005年在葡萄牙里斯本
所舉行的EuroSpeech的計畫集來看，就有五個以上的Sessions是和電腦輔助語音學習相關。
國外相關的研討會還有 ICASSP (International Conference on Acoustics, Speech, and Signal 
Processing)和 International AES (Audio Engineering Society) Conference等。 
近幾年來，與 CAPT相關的公司陸續成立，相關研究單位也相繼投入相關研究，有此可以
看出 CAPT的實用性與市場價值不可小覷。尤其在目前許多標準的語言測驗都需要口說英
語的實測，若能夠以電腦來取代人工評分，經濟效益非常宏大。 
但就我們所知，就已發表的商業產品而言，並無任何使用於嵌入式系統的口說英語發音練
習系統。本實驗室在語音辨識與語音評測相關研究已經有多年的基礎和經驗，希望藉由此
計畫，將這些技術移植到嵌入式系統，並實現於鈦思公司的軟硬體平台，以便落實到產品
面，加速技術商品化。 
關於嵌入式語音評分與辨識相關研究，從[1]中，我們可了解整個 ASR 系統是如何運作，
諸如 Viterbi Beam Search 的最佳化、如何運用 不同的語料來訓練所需的聲學模型，以及Tree 
Net 的建立與最佳化等，再依據[2]我們可得知，如何在MFCC 的整個過程中，將有浮點數
的資料型態放大成相對應的整數型態數值，並且建立相對應於浮點數的整數 Hamming 
Window Table、Cos Table、Sin Table、Square Root Table 及 Log Table等等方法來加速運
算能力較弱的機器，而[3]更進一步的將之實現在 Pocket PC上，並於實驗過程中求得所對
應的 TCC300 部分語料的變動參數，雖然辨識的準確度與所耗費的時間，均為可被接受的
範圍，但仍有一定的空間可以進一步來改善之。[2]與[3]各提及到不同的方法來改進整個
MFCC 中耗費最多時間的 FFT (佔總體MFCC 時間約莫 57% ，參考[2]) ，並使之能適用
於整數的 FFT。 
本計畫將著重的部份在於特徵擷取MFCC，透過運算改寫運算過程、查表、與找出最佳放
大係數與升降流程，希望能讓定點數版MFCC 的數值與浮點數版MFCC 更為相近，以達
到精準度與辨識率的提昇。預計讓嵌入式整數版語音辨識系統，其精準度與辨識率可以更
加逼近浮點數版語音辨識系統。 
 
 5 
不過由於整體數值會變得很大，運算時容易造成溢位的產生，目前電腦系統處理溢位有兩
種方式： 
1.循環：當數值超過範圍時，數值會從最大值變為最小值、最小值變為最大值。以整
數型態為例：2,147,483,647+1=−2,147,483,648。如此一來進行語音辨識等工作就會造成錯誤
的產生。較多嵌入式系統使用此方法。 
2.飽和：當數值超過範圍時，數值過大會維持在最大值、數值過小會維持在最小值。
以整數型態為例：2,147,483,647+1=2,147,483,647。較少嵌入式系統使用此方法，雖可以透
過軟體達到，但會增加不少運算負擔。 
我們的目標在於如何在精準度與溢位的天平上尋找一個最佳的平衡點，下面將以MFCC 為
範例說明。 
實際於MFCC 系統時，除了前述議題之外，還有還原(Scale down)時機的問題：整體系統
流程每個步驟都有自己的放大係數，我們必須考慮不同步驟放大係數之間配合的效果，累
積維持精準度或是避免溢位發生的機率，例如：預強調乘以放大係數之後不還原，繼續下
一步漢明窗，如此一來精準度較佳、溢位可能性高；反之，預強調乘以放大係數之後還原，
繼續下一步漢明窗，如此一來精準度較差、但溢位可能性低。 
 
 
 7 
改進方法二趨勢與方法一雷同，但是在溢位抑制這方面明顯有較好的效果，直到 218 才開
始有溢位產生，相較之下方法一在 213 就開始溢位，這邊就可以展現出運算過程改寫，維
持小數值運算的效果。另外在最佳精準度的表現方面，第一名 21
 嵌入式平台實作 
，誤差為 0.341920，提昇
效益為 0.1539，較原始方法只改放大係數比較提昇效益約為 0.1539/0.0025≒62 倍，效果最
為顯著。 
我們依據上述的改進方法，開發出一套整數版本的語音辨識演算法，在 PAC Duo平台的實
作可分為兩個部分，分別為唐詩語句的辨識跟 Google map語音命令，使用的辨識方法為隱
藏式馬可夫模型（Hidden Markov Model），此模型會比對輸入語音跟資料庫語音模型的機
率，使用 Viterbi Search找出機率最高的語句當作辨識結果。整體辨識率可達 94.13%，在
50句辨識語句下，計算速度約需 5秒。其中唐詩語句辨識，使用者可以說出白居易琵琶行
任一詩句，系統將會在畫面上顯示使用者說出的語句。 
Google Map語音命令系統的語料庫為日常生活食衣住行相關地點的語詞共 50組，我們將
這 50組字詞顯示在觸控式螢幕上，使用者可以選擇想要搜尋的地點，辨識結果可以連結到
Google Map，顯示出附近相關的地點，例如測試語句為小吃店，系統將連結 Google Map，
顯示出使用者所在位置附近的小吃店。 
語音互動功能已成為今日行動多媒體嵌入式平台的主流功能之一，如手機的聲控撥號、語
音命令、簡訊語音播報、語音情緒辨識、語者身份確認、語言學習、、、等，這些語音相
關應用將逐漸成為智慧型手機基本功能。有鑑於語音發展的重要性快速提升，未來我們將
持續投入語音應用軟體的開發工作，以現有研發成果為基礎，建立及時語音互動的多媒體
平台。 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/12/26
國科會補助計畫
計畫名稱: 適用於嵌入式系統的電腦輔助口說華語發音練習系統
計畫主持人: 張智星
計畫編號: 98-2622-E-007-023-CC3 學門領域: 自然語言處理與語音處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
