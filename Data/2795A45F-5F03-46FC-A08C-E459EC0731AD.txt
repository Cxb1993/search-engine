we hope to achieve a usable application of ESNs or 
comparable approaches in the following project that 
is currently conducted. 
英文關鍵詞： service robot , humanoid robot , robot soccer ,  
robocup@home ,  reservoir computer , echo state 
networks 
 
Contents
1 Overview 4
1.1 Purpose of the proposal . . . . . . . . . . . . . . . . . . . . . 4
1.2 Build up of the laboratory . . . . . . . . . . . . . . . . . . . . 4
1.3 Theoretical work, experiments with simulations, theoretical
models with relevance to development in human and develop-
mental impairments . . . . . . . . . . . . . . . . . . . . . . . . 4
2 Summary of project achievements to the initial goals 5
2.1 Initial Goals as outlined in the proposal . . . . . . . . . . . . . 5
2.1.1 Item 1 Preparation of the robot platform: . . . . . . . 5
2.1.2 Item 2 Optimization of the reservoir: . . . . . . . . . . 7
2.1.3 Item 3: Reservoirs in service robots . . . . . . . . . . . 7
2.1.4 Item 4: Are ESNs useful in service robots? . . . . . . . 7
2.1.5 Item 5: Publications from dissemination . . . . . . . . 7
3 Overview comparison between results and targets in the ini-
tial proposal 8
4 Conclusions from the project 8
5 Qi Programming Design 9
5.1 Action Server . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
5.1.1 Scheduler . . . . . . . . . . . . . . . . . . . . . . . . . 9
5.1.2 Memory Pool . . . . . . . . . . . . . . . . . . . . . . . 10
5.1.3 Packets . . . . . . . . . . . . . . . . . . . . . . . . . . 10
5.2 User interface . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
5.3 Design Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
5.3.1 Structure based approach . . . . . . . . . . . . . . . . 12
5.3.2 Action Flow Based . . . . . . . . . . . . . . . . . . . . 12
6 A Simple Strategy of Qi on DARwIn-OP 12
6.1 Humanoid Robot - DARwIn-OP . . . . . . . . . . . . . . . . . 13
6.2 Experiment of DARwIn-OP . . . . . . . . . . . . . . . . . . . 14
7 Navigation 17
7.1 Algorithm description . . . . . . . . . . . . . . . . . . . . . . . 18
8 Introduction to the Robot arm: 21
8.1 Servo motor: . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
8.2 Theoretical work: . . . . . . . . . . . . . . . . . . . . . . . . . 21
2
1 Overview
1.1 Purpose of the proposal
The purposes of the project were to go towards the usage of machine learning
algorithms (and initially mainly echo state networks, ESNs) on a service
robot to perform anticipative behavior, i.e. to find a new way to provide an
adaptive predictive model of the environment and to set up the necessary
preconditions.
In addition, in the present work it was intended to attack two problems of
service robots: First, one task of service robots is that they have to be in-
tegrated in a wider framework of an intelligent house. Moreover, a team of
several robots may be used that needs to have an integrated software envi-
ronment. Second, we would like to have a kind of meta-control framework,
which can help to detect ’unusual’ states of the control system and then can
help to put the main control modules back on track.
1.2 Build up of the laboratory
Since the start of the project coincided with the start of the Advanced Em-
bedded Systems and Robotics (AES&R) laboratory, much of budget has been
used for the build up for a general laboratory environment, and also for robot
platforms.
• several computers for the robots also for the students
• various sensors (see below) for the service robot (including a robot arm)
• several robot platforms
– Aldebaran NAO humanoid robot
– Darwin OP humanoid robot
– additional small size differential drive robot (under construction)
1.3 Theoretical work, experiments with simulations,
theoretical models with relevance to development
in human and developmental impairments
As part of the project and as part of international collaborations several
studies on reservoir optimization have been conducted. Results were dis-
seminated in several journal publications and conference proceedings. In
4
dynamically as modules into the framework during runtime, and are
automatically depicted in a graphical user interface, that also allows
to control that data flow between the modules. 2. Network capability:
The data flow can easily cross from one embedded system to another
via the network, the developer does not need to care if a flow goes from
one embedded system to another. In this way a kind of ’cloud com-
puting’ between embedded system shall be realized. Behavior modules
can be easily shifted from one embedded system to another.
Initially in the proposal the Player/Stage software had been suggested.
During the project step by step Player/Staged proved insufficient be-
cause some of the software could not be integrated (this was especially
true for the speech processing). Thus, an own integrated development
environment had been developed. The environment has been called Qi,
it bases on concepts of the earlier environment Qflow, initially devel-
oped for the , which fulfills the following requirements:
– Graphical user interface
– Flexible modules that can be loaded during runtime
– Graphically visualized slots and piping
– Networking capability. That means information between slots can
be transported from module, even if the modules are located on
different platforms, and the GUI can be on a different platform
than the server.
• Self-localization and navigation in an inhabited environment. For this
purpose a SLAM algorithm and several navigation algorithms have
been developed.
• Speech processing which has been realized by using Sphinx software
(open source, as outlined in the proposal).
• Speech synthesis, realized by using Festival (open source, as outlined
in the proposal).
• Face recognition, realized by comparing standard feature lists, face de-
tection as provided in the OpenCV library.
• Arm for gripping objects, coordinated by using the Kinect sensor, that
has been purchased during the project.
6
student. So I would like to meet him 1-2 time to exchange and update
with his newest results.
• From the implementation of the ESN into our service robot or the
SimSpark simulator expect to publish one journal paper or one confer-
ence proceedings. Subject of the publication is going to the performance
of an ESN with an adaptive reservoir on a real or a simulated robot.
• Possibly I can publish one paper about the biological relevance of findings
in echo state networks. If results can be achieved here that can be
disseminated in journals is specultativ. However, usually, if there are
results then these results can be published in journals that have a higher
impact factor.
3 Overview comparison between results and
targets in the initial proposal
Initial goals in the proposal Achievement Ref. in the report or publ.
Prepare the platform Done. See Secs. 5, 7, 11,
Sect. 2.1.1 10 (and report of 2010)
Optimization of the reservoir processed in an international See publications [1, 2]&
Sect. 2.1.2 collaboration [12, 13]
Integration of ESNs on agents realized in simulations See master thesis in the App. A , [14]
Sects. 2.1.3 and 2.1.4
Dissemination in publications 3 journals + See publication list 14
Sect. 2.1.5 11 proceedings
Journal. pubs ≥ 2
4 Conclusions from the project
The core question of the project was if ESNs can be used to for anticipation
and prediction in service robots and also other types of mobile robots. One
conclusion is that standard ESNs can only be used in a very limited set of
applications. Thus, we are going to use reservoir optimization and also are
going to consider alternative approaches in the subsequent projects, as for
example the current project.
8
Figure 1: A principle of action server and module communication.
like motor controlling, Qi provides a high priority for processing. Dependent
on the hardware platform, the scheduler also supports OpenMP and PThread
multi-thread and parallel programming libraries. The scheduler also supports
the thread-safe function in module design.
5.1.2 Memory Pool
Qi possesses an own memory allocator. This avoids leakage of memory for
bad allocations and also reduces the resources that are necessary when pro-
gram reconstructs data structures.
5.1.3 Packets
Qi contains a converter that makes it easy to convert string data and transmit
the data via the network. The user also can implement standard I/O to make
a package that contains the respective custom data type.
If module receives a packet or some event occurred, Qi will trigger the func-
tion to handle incoming data. The respective processes are called ”actions”.
10
5.3.1 Structure based approach
The structure based approach builds each function, part and sensor into one
module each. Qi transmits data between each module, the advantage is we
can monitor all the data exchange between modules. The problem is that it
is hard to modify the behavior during runtime.
This is the major design flaw the we focused on in the present approach.
The idea origins from the general design of embedded systems In modern
embedding system design we build controller modules, sensor modules and
moving platform modules. Each part commutates with commands, sensor
value and control code via ”wires”.
5.3.2 Action Flow Based
In the action flow based support the user builds each processing sequence
into the module. The disadvantage is here that it is difficult to expand the
system and to include new hardware. For example, we can design an action
sequence to define the motion and design a policy in some critical section.
6 A Simple Strategy of Qi on DARwIn-OP
Robots are comprised of several systems working together as a whole. The
troublesome part with which the behavior designer is confronted is how to
integrate these systems. This process can be particularly tedious if the details
of the other components are not known very well. Thus, it may be diffiult to
include these systems into a standard protocol.
In order to overcome these problems we can use the novel approach Qi.
Qi provides the framework of the robot system to integrate all system on
robot and construct intelligent behavior of robot by icons. Qi has been used
connect to DARwIn-OP via ethernet or wireless through UDP protocol. The
intention is to implement communication between Qi servers on different
robots as distributed embedded system. One additional idea is to achieve
the cooperation between different robots which is very suitable for humanoid
soccer robots. This feature is a basic requirement for skills as passing, co-
localization and mapping and sharing of other useful information as it may
be necessary in the Humanoid Soccer Robot League in RoboCup[7]. In the
following, we will introduce our basic behavior structure of humanoid robot
as an example for the usage of Qi. and explain our modules in detail. In
the behavior structure, we will implement a simple strategy of humanoid
soccer robot including image processing, tracking ball, following ball, and
shooting. We can understand our strategy easily and clearly and debug our
12
from gyrometer to make DARwIn-OP balance while walking. Another algo-
rithm for image processing can track a red ball. Thr algorithm converts the
RGB color space into HSV color space. It then sets the threshold of each
element of HSV color space to extract the pixel we expected and filter out
pixels that are not expect. According to these two algorithms, we implement
modules for each and combine two modules to build our strategy handy and
to modify our strategy easily. In the next section, we will explain the function
of each model that bases on the above mentioned algorithms and explain the
structure of the strategy in detail.
6.2 Experiment of DARwIn-OP
As a simple strategy of humanoid soccer robot, we implement three dif-
ferent modules including DARwIn camera, DARwIn FindBall and DAR-
wIn FollowBall to construct our strategy as depicted in Fig.5. Each module
will follow a standard protocol designed by user to communicate with each
other. These three different modules response for different tasks in the strat-
egy as depicted in Fig.6, Fig.7, and Fig.8 separately. The DARwIn Camera
module is setting up the environment of DARwIn-OP humanoid robot for ex-
tracting the image from the camera and displaying the image on http server.
In this case, we will find out what the robot sees from http webserver and
comfirm our algorithm is successful or not effectively. The DARwIn Camera
module also transmits the information of image to the next module, DAR-
wIn FindBall, for image processing.
Figure 5: A simple strategy for a humanoid soccer robot composed of the
DARwIn Camera, DARwIn FindBall, DARwIn FollowBall modules
14
Figure 8: The funtion of the DARwIn BallFollow module.
HSV_Image
Filtering red ball
Erosion 
&
Dilation
Average
the point of selected pixel
Send 
the point of red ball
Next Module
Figure 9: The flow chart of DARwIn FindBall module.
calculate the angle of availably horizontal view and availably vertical view of
the camera. Thus, we can calculate the angle of the tilt or pan for each pixel.
The pattern of walking depends on the IK algorithm. The parameters of the
IK algorithm including the distance of x-axis and y-axis and the rotation
of z-axis is calculated by the distance between the position of the red ball
and the center of the image. If DARwIn-OP is more closely to the red ball
position, the angle of the tilt of the head is more lower. As the angle of the
tilt is lower than the threshold we set, DARwIn-OP will prepare for shooting.
The flow chart of DARwIn FollowBall module is depicted in Fig.10.
Combining these three modules, we can construct our simple strategy handy
by using Qi. If the strategy is more complex than the simple strategy that
we designed, for example 10 or 20 modules in the strategy as depicted in
Fig.29, the Qi framework allows to debug and modify the strategy easily and
16
algorithm, such as The Bug Algorithm, The Bug2 Algorithm, The Po-
tential Field Algorithm, The Vector Field Histogram (VFH) Algorithm,
The Bubble Band Technique.
We refer to an approach called µNav and use a part of the approach, which
is: Sensors return some information back, such as the information to the goal
and the information to the closest obstacle, such as distance, orientation, po-
sition, and we use these information to generate a function or a vector, and
the vector can lead robot to the goal or let the robot avoid the obstacle.
7.1 Algorithm description
When the robot was moving, no matter what is the environment simple or
complex, there has some information we need know and use these data to
compute a navigation function on the basis of an artificial potential field
(APF).
Definition:
The following time-varying quantities are defined with respect to FR
(a moving frame centered on the robot).
(1) g(t): a unit vector (gx , gy) directed to the goal.
(2) r(t): the distance vector to the closest obstacle, where ∠r corresponds
to the direction of the range measurement and ρ = |r| corresponds to the
sensed range.
(3)U(t): the current value of the potential field, i.e.,
U =
{
(1
ρ
− 1
ρmax
)2, ρ ≤ ρmax
0, ρ > ρmax
where ρmax identifies the maximum sensing range.
(4) f(t): a unit vector (fx , fy) directed along the inverse gradient of the
potential field; since −∇U is directed along ∠r but with an opposite sign, f
can be computed as
f =
{ − ∇U|∇U | , ∇U 6= 0
0, ∇U = 0
∇U = d
dρ
U · ( r|r|)
d
dρ
U =
{
2
ρ2ρmax
− 2
ρ3
, ρ ≤ ρmax
0, ρ > ρmax
(5) t1(t) and t2(t) are unit vectors referred to as the “left” and “right” tan-
gents, respectively. Both of them are tangents to the APF equipotential line,
i.e.,
18
Figure 13: Plot of Wg,Wt and Wf versus the sensed range ρ
where λ1 and λ2 determine the exact shape of the sigmoid, it did not have
exact value, UL is a constraint according to the robot’s position on the po-
tential field(see in Fig.12).
The vector v can be calculated from the components of g, t, f, Wg,Wt,Wf ,
the three weights Wg,Wt,Wf , which can calculated depending on U. In con-
trast to standard APF, the robot motion law, v(t) is given by
v(t) = [Wg(U)g +Wt(U)t +Wf (U)f ]Vref
where Vref is a reference value of speed defined by the robot.
The weight Wf is not as critical as Wg and Wt, this condition can be observed
in Fig.13, when the robot is closer to obstacles, Wf will become important
in function v. After we got the vector v, which can use to do some decision
according to the information returned by sensors, like distance to the obsta-
cle, then we can make the robot go to the destination or starting obstacle
avoidance function depending on the information vary by time.
When the program was finished and the module was created, we used the
module on Qi. In one example application were four modules combined
together(see fig.14, module’s left side is input and right side is output.),
the laser-scanner module send information(distance). The path module do
the path-planning and send out the result. The UbotModule integrates the
command, when it receives the packet from the NAV3 module, which will
send command to control robot’s action, like move, turn right/left. The
NAV3 module combines with the other three modules together. It uses the
information which can be used to calculate the vector v. The result makes
the robot know how to move.
20
Figure 15: Dynamixel servo motor control method
Jointi θi degree di cm ai cm αi degree
1 θ1 0 22 0
2 θ2 0 8 -90
3 θ3 0 24 0
The Robotic arm’s Denavit−Hartenberg
A1 =

cos θ1 − sin θ1 0 a1 cos θ1
sin θ1 cos θ1 0 a1 sin θ1
0 0 1 0
0 0 0 1
A2 =

cos θ2 0 − sin θ2 a2 cos θ2
sin θ2 0 cos θ2 a2 sin θ2
0 −1 0 0
0 0 0 1

A3 =

cos θ3 − sin θ3 0 a3 cos θ3
sin θ3 cos θ3 0 a3 sin θ3
0 0 1 0
0 0 0 1
TransformationMatrices
A.Direct Kinematics: The direct kinematics is a computation of the po-
sition and orientation of robot’s end effector as a function of its joint
22
Figure 16: Usage of the Qi program to run the kinect module and arm control
module
In retrieving shots part, we use OpenNI and Opencv 2.3 (In this version, it
has kinect support) library to do it.
In detecting object part, we use SMOR. SMOR is a short of Scalable Mul-
timodal Object Recognizers. By rapidly adding various different unimodal
recognition techniques in the form of Simple Unimodal General Abstract Rec-
ognizers (SUGAR’s), it is possible to create realtime object recognition that
is tailored to the task at hand without spending hours of programming time.
In brief, it based on histogram analysis, when we use it, giving a rectangular
region (we can give many region s in many shots) to the object we want to
detect, and then, analyze these regions with different types of SUGAR, there
are Sobel/Laplace Mean, Color Histogram, Orientation Histogram etc. At
last, we use this analyzed index (the result generated by SUGAR) to justify
whether the shot has the object or not.
Calculating distance start running when detecting object part returns the
object we want. This part calculates object’s center and returns its infrared
value. But How do we check the center of object? The idea is that after
24
Figure 18: Flow chart of how vision module working
Figure 19: The program to decide the region we want by hand
26
Figure 21: The graphical representation of our Slam structure in Qi. There
are four modules in total, Joystick, LaserScanner, MobileRobot and Mapping
module.
Figure 22: The sample slam result of our laboratory.
28
Figure 24: Face detection use Haar-like features.
11.2 Face Recognition
SURF Speeded Up Robust Feature [10] (see figure 25) is a robust image de-
tector and descriptor, first presented by Herbert Bay et al. in 2006, that can
be used in computer vision tasks like object recognition or 3D reconstruc-
tion. It is partly inspired by the SIFT [11] descriptor. The standard version
of SURF is several times faster than SIFT and claimed by its authors to
be more robust against different image transformations than SIFT. SURF
is based on sums of approximated 2D Haar wavelet responses and makes an
efficient use of integral images.
It uses an integer approximation to the determinant of Hessian blob detector,
which can be computed extremely quickly with an integral image (3 integer
operations). For features, it uses the sum of the Haar wavelet response
around the point of interest. Again, these can be computed with the aid of
the integral image.
We combine face detect and SURF to build our system.(see figure 27,26
software interface) After training our system can identify eight people at
the same time. This system can be use in any real time face recognition
applications like home service robot system , access management system
....etc. Future work is to combine this system with GPU and cloud computing
technology. With Qi 23 we can setup out system in any kind of device via
internet .
30
Figure 26: Detect two people face.
the visible layer. To generate data from RBM, the alternating Gibbs sampling
process is performed.
12.3 Future Works
We have successfully implemented the deep believe network on the hand-
written digits task using MNIST database[12] as presented in [3] under Qi’s
framework. The layered module structure works flawlessly so far, we would
like to try more applications like training a random number generator and
generate a identical distribution.
13 Summary of the purpose of Qi
As we mentioned above, for mobile service robots it is necessary to com-
prise several systems working together as a whole. While developing a robot
system we need a simple way to integrate these systems. There are other
frameworks of the robot system, like ROS (Robot Operating System)[8], for
overcoming these problems we mentioned above. However we found that
even if ROS can integrate all systems as a whole, it is not as friendly for de-
bugging by inspecting the code as our system is. Due to these problems, we
propose our approach, Qi that provides the framework of the robot system to
integrate all system on robot and construct intelligent behavior for the robot
32
Figure 29: The blueprint for strategy of humanoid soccer robot.
14 Own publications from results within the
project
.
[1] J. Boedecker, O. Obst, J. T. Lizier, N. M. Mayer, M. Asada. Information
Processing in Echo State Networks at the Edge of Chaos. Theory Biosci.
2010, ( accepted, SCI: 1.278, ca. 5000 words).
[2] J. Boedecker, O. Obst, N. M. Mayer, M. Asada. Initialization and Self-
organized Optimization of Recurrent Neural Network Connectivity. Hu-
man Frontier Science Program (HFSP) Journal 2009, 3, 340–349, (SCI:
1.786, ca. 5000 words).
[3] N. M. Mayer, J. Boedecker, M. Asada. Robot motion description and
real-time management with the Harmonic Motion Description Protocol.
Robotics and Autonomous Systems 2009, 57, 870–876, (SCI: 0.6, invited
contribution, ca. 5000 words).
[4] L.-W. Lu, N. M. Mayer, Analogies between the autistic brain and the
state of the art artificial autonomous agent in 第33回人工知能 AI 研究-
2011世界大向-第33回人工知能 AI 研究概要, 大阪, Japan.
[5] N. M. Mayer, H. Wu, I. Fasel, M. Asada, Analogies between the autistic
brain and the state of the art artificial autonomous agent in 第33回人
工知能 AI 研究- 2011世界大向-第33回人工知能 AI 研究概要, 大阪,
Japan.
34
[2] A. Sgorbissa F. Mastrogiovanni and R. Zaccaria. Robust navigation
in an unknown environment with minimal sensing and representation.
IEEE Transactions on Systems, Man and Cybernetics, 39, 2009.
[3] Osindero S. Hinton, G. E. and Y. Teh. A fast learning algorithm for
deep belief nets. neural computation. 18, 2009.
[4] RoMeLa Laboratory. Retrieved from the World Wide Web
: http://www.romela.org/main/DARwIn_OP:_Open_Platform_
Humanoid_Robot_for_Research_and_Education, 2011.
[5] OpenCV. http://sourceforge.net/projects/opencvlibrary/,
2011.
[6] OpenCV. http://opencv.willowgarage.com/wiki/FaceDetection,
2011.
[7] RoboCup. Retrieved from the World Wide Web : http://www.
robocup.org/.
[8] ROS. Retrieved from the World Wide Web : http://www.ros.org/
wiki/.
[9] Bruno Steux and Oussama El Hamzaoui. tinyslam. http://openslam.
org/tinyslam.html.
[10] wikipedia. http://en.wikipedia.org/wiki/SURF, 2011.
[11] wikipedia. http://en.wikipedia.org/wiki/Scale-invariant_
feature_transform, 2011.
[12] Corinna Cortes Yann LeCun. http://yann.lecun.com/exdb/mnist/,
2011.
A Yu Cheng Chan Master Thesis
[see after this]
36
  i
ACKNOWLEDGEMENTS 
First of all, I would like to appreciate my advisor, Prof. Norbert Michael Mayer, 
for his instruction, guidance and assistance in this research work. He kept supporting 
me on the completion of the thesis with his knowledge and experience during my 
study in graduate institute; his constant encouragement and great patience has always 
inspired me in my investigation. In addition, I would specially like to thank the thesis 
committees, Prof. Kao-Shing Hwang, Prof. Tzuu-Hseng S. Li, and Prof. Ching-Chi 
Tsai, for their valuable discussions and comments on this work.  
I would also like to thank the members of AES&R laboratory: Horng Wu, 
Yu-min Hung, Li-wei Lu, Kuo-hao Chung, Chang-hsun Lee, Wei-lun Lin, Hung-ching 
Chan, Yu-cheng Cheng, He-chih Liu, and those project students that I didn’t mention 
but will always cherish in my heart. Having them around, I can always regain my 
nerve and put more effort on the work.  
Finally, I want to thank my friends and my girlfriend for their moral support. 
Last but not least, I am grateful to my family for they are always my source of 
inspiration.  
 
  iii
ABSTRACT 
Echo State Network is a computing model proposed recently. It contains a big 
sized internal hidden layer that provides rich dynamics, together with the special 
training mechanism that differs from other neural networks. These features make it 
suitable for modeling nonlinear signals. In this thesis I proposed a training method 
based on the concept of sliding window, and made experiments together with two 
other known training methods. I get the sensory value sequence from simulated 
humanoid robots of a robot soccer simulator SimSpark by a parser, record them, and 
then test them in MATLAB, in order to predict the sensory input signals on next 
iteration from the past input signals of simulated humanoid robots. 
 
  v
4.1 SIMSPARK ROBOT SOCCER SIMULATOR ......................................25 
4.1.1 System Overview: Server ......................................................................25 
4.1.2 System Overview: Agents ......................................................................26 
4.2 MOTION DESIGN TOOL: QMOTION2 ...............................................28 
4.2.1 GUI Overview.........................................................................................28 
4.2.2 Motion Design and Porting ...................................................................29 
4.3 SUMMARY ................................................................................................32 
V. RESULTS............................................................................................................35 
5.1 THE PREDICT TARGET.........................................................................35 
5.2 BATCH TRAINING ..................................................................................36 
5.3 STANDARD ONLINE TRAINING .........................................................37 
5.4 RECURSIVE LEAST SQUARE LEARNING........................................38 
5.5 DISCUSSION TO HIDDEN NEURONS.................................................39 
VI. CONCLUSION AND FUTURE WORKS ...................................................48 
6.1 CONCLUSION ..........................................................................................48 
6.2 FUTURE WORKS.....................................................................................49 
REFERENCES...........................................................................................................50 
VITA............................................................................................................................52 
 
  vii
LIST OF TABLES 
Table Page 
 4.1 An example preceptor message ...................................................................... 33
 4.2 Perceptor List .................................................................................................. 34
 5.1 Batch Learning MSE & standard deviation to hidden neurons ...................... 37
 5.2 Standard online training MSE & standard deviation to hidden neurons......... 38
 5.3 Recursive Least Square Learning MSE .......................................................... 39
 5.4 Recursive Least Square Learning Standard Deviation ................................... 39
  9
between internal nodes. In order to avoid the problem, three approaches have been 
proposed: The Backpropagation-Decorrelation (BPDC) learning rule, the Liquid State 
Machine (LSM), and the one I adopt here: Echo State Networks. The three approaches 
above are main representatives of reservoir computing. [3] 
The common idea of RC is that the input signals are fed into a fixed dynamical 
system, which is called a reservoir. The reservoir is formed by the randomly generated 
recurrent connection, the connections remain unchanged generally. With the 
dynamical response produced by the input, the reservoir is able to reconstruct the 
desired output through the basis from the response. The construction is done by a 
linear combination task.  
 Fixed reservoir, and the training that only performs on readout stage makes RC 
simple to use. Usually to derive a linear classifier that performs optimally on data sets 
by reservoir, one trains a network with training data and obtains classifier using a 
computationally efficient way, the pseudo-inverse method. As a matter of fact, there 
are more methods able to apply to the reservoir computing. [4] 
 
1.2 Motivations and Objectives 
We would like our robots to be able to learn from past “experience” and make 
decisions. The characteristic of recurrent neural networks is they can have some 
memory effect, which would make the prediction based on the history of what was fed 
into the network before. Meanwhile, to model such “experience” in the view of neural 
network, it should be converted into some numerical data which is able to input to the 
networks. Thus our first step of this goal is to use Echo State Network, with some 
sensory data as the network's input and different learning algorithms applied; the 
robot is expected to predict the next sensory input. I try some kinds of offline and 
online learning methods, observe how they perform. I expect the conclusion of this 
  11
II. ECHO STATE NETWORKS 
Echo State Networks are artificial computation models proposed in Jaeger (2001). 
As being one type of reservoir computing, one feature that differs from other neural 
networks is that it uses a large sized hidden layer as its reservoir (on the order of 50 to 
1000 neurons; whereas other techniques use 5 to 30 neurons typically) to model 
nonlinear systems. Previous approaches may tune all the synaptic connections, which 
may result in a problem of slow convergence, and ESNs were designed to solve such 
problem. Being another feature of Echo State Networks that differs from previous 
approaches, the adaption is only performed in the readout stage, making it possible to 
use many available constructive linear regression algorithms for the training (Jaeger, 
2001), which indeed improves the performance of learning. With this simple learning 
mechanism ESNs can have the modeling power of recurrent neural networks, but cost 
less time complexity to achieve our goal. Fig. 2.1 depicts the structure of a standard 
Echo State Network. The solid lines are fixed weights; the dotted lines are the weights 
to be trained; the dashed lines are weights that possible but not required.  
The third difference between ESNs and other ordinary neural networks is the 
setup of connection weights. Basically the connections in read-in stage and in 
recurrent hidden layer are randomly generated. It is suggested in [2] that the 
connections to be sparse. In other words, the connectivity should be low. This is to 
make each subnetworks in hidden layer present dynamics more independently. In 
addition, Jaeger [1] also stated that the hidden connection weight should contain a 
characteristic about the behavior of internal dynamics. The description of the 
characteristic will be given later. 
  13
−
update equation in a general form: 
  (2.1) ( ) ( ( 1) ( 1) ( 1))in backt f t t t= − + − +x W u Wx W d
Where the 1( ,..., )Nf f f=  stands for the internal units' output nonlinear function,  
Typically sigmoid function (e.g. ) is adopted. The network output equation is:  tanh
  (2.2) ( 1) ( ( ( ), ( ), ( )))out outt f t t t+ =y W u x y
Where 1( ,..., )
out out out
Lf f f=  corresponds to the output unit's output functions, 
respectively.  is a vector concatenated from the input, internal and 
previous output activation vectors, 
( ( ), ( ), ( ))t t tu x y
( 1)back t −W d  is a noise vector not strongly 
required.  
Now, start from two arbitrary initial states  and , with the same input 
sequence , driving the network by equation 2.1. After sufficient long time, if the 
following condition holds, then the network is said to have echo states: 
x
t
'x
( )tu
 ( ) '( )t ≈x x   
To express in an equivalent way of Echo State Property is that the network will 
have echo states if there exists a so-called “echo function” E  that maps all the past 
input to the current state [2], so that the activation of hidden states is a function of the 
input history fed into network. 
  (2.3) ( ) ( ( ), ( 1), ( 2),...)t E t t t= − −x u u u
We treat these input history ( ), ( 1),...u t u t −  “echoes” in the hidden layer as 
current state  [4]. In other words, the network tends to wash out initial 
information over time. With running time long enough the state will be determined 
only by the teaching sequences  and , regardless of what the state was in 
the beginning. 
( )tx
( )tu ( )td
 
2.1.2 Condition of Echo States 
  15
radius α . 
4.  is (always found to be, according to [2]) an Echo State 
Network, regardless of how we choose  and . 
( , ,in backW W W )
inW backW
 
2.2 Summary 
In this chapter, I gave an overview of the structure of ESN. We have seen the 
characteristic of Echo States: Their one algebraic definition, how they work, and the 
how we get an Echo State Network in practice. Next part I will focus on the training 
part, introducing what algorithms I adopt. 
 
  17
z For the internal connections: A N N×  weight matrix ( )ijw=W  
z For the output connections: A ( )L K N L× + +  weight matrix  ( )out outijw=W
z For the output to the internal connections: A N L×  weight matrix 
 ( )back backijw=W
: 
3.1.3 The Activation Functions  
The activations of neurons in the hidden layer and the output layer are updated 
according to (2.1) and (2.2). Originally in Jaeger [1], these equations were in their 
general forms when they first introduced. I modified them at some place in my 
simulation. The adapted equations are:  
  (3.1) ( ) ( ( ) ( 1))int f t t= + −x W u Wx
x  (3.2) ( ) ( ( ))out outt f t=y W
where no feedback term is used, no concatenation vectors of inputs at time , 
previous states at time , output at time  are used; nonlinear functions applied 
to the output of hidden units is ; and I use linear function on the output layer, i.e.  
t
1t − t
tanh
   ( )outf =v v
 
3.1.4 Weight Matrices Setup  
Since I am not using the concatenation vector, the size of the output weight 
matrix is changed:  
z For the output connections: A L N×  weight matrix  ( )out outijw=W
Jaeger suggested that connectivity should be low, one way used in [1] is that they 
set each values with only three probabilities: 0.95, 0.025 and 0.025, corresponding to 
values of 0, +0.4 and -0.4, which creates a weight with connectivity of 5%, whereas I 
  19
In offline training based on pseudo inverse, training steps are listed below:  
1. Build a recurrent neural network  with K, N, and L 
neurons in input layer, hidden layer, and output layer, respectively. Use the 
procedure listed in section 2.1.2 to ensure the Echo State Property.  
( , , )in backW W W
2. Sampling the input signal, dismiss initial transient:  
A. Feed the input into network at every time step, use equation 2.1 to 
update the activation of hidden units. 
B. Repeat the action for  times, so that initial transient is washed out. 
 can be in a range from 50 to 1000, depending on the size of 
network 
minn
minn
3. Collect state sequences for any time larger or equal than initial washout time 
, into a matrix . Also collect teaching sequences into a matrix . 
Note that collecting length in both matrices should match, and take the 
teaching signal before training as zero value, i.e. 
minn M T
(0) 0=d . 
4. Compute output weight by calculating 
 1( )out T −= ⋅W M T  (3.3) 
 where 1−M  is the pseudo inverse of state collecting matrix . M
5. Transport  into . The network is then ready to use. ( )out TW outW
I would like to predict the input signal at the next time step, i.e. the output weight 
 should map the state into sensory signal one step in the future. Therefore, I care 
about the ordering of collected internal states and teacher signal sequences, and their 
time corresponding in each vector. Each state collected in  should always be one 
iteration late of its corresponding teacher signal in . 
outW
M
T
 
3.2.2 Online Training: Recursive Least Square Algorithm  
  21
 1 ,
1
τ λ≈ −   
it determines the exponent of the MSE convergence /ne τ− . [3] 
The implementation of RLS algorithm begins with an initialization of a 
symmetric matrix 1λ
−Ψ  that computes the gain vector . The rank of matrix ( )tu λΨ  
is less than its dimension  for values of  smaller than the filter length, . This 
means for , there is no inverse matrix of 
N n N
n N< λΨ  which will be used in tap-weight 
vector correction. [7] states that to solve this problem, commonly one can simply start 
the RLS algorithm with an initial setting of 
 (0)λ δ=Ψ I   
where  is the identity matrix and I δ  is a small positive constant. To minimize the 
effect of  on the steady-state performance of RLS algorithm, Farhang 
Boroujeny et al. stated that it works well by choosing a very small value for 
(0)λΨ
δ , the 
effect of  on the convergence behavior can also be minimized due to this 
initial setting. [7] 
(0)λΨ
Based on above,  can be obtain by taking the inverse of . Then 
follows the algorithm I use, which was from table 12.1 of [7] with a newly-added step 
to suit ESN situation: 
1(0)λ
−Ψ (0)λΨ
1. Initialize the  matrix with 1(0)λ
−Ψ
1
δ I  
2. For every iteration (t starts from 1), do 
A. Activation of hidden units updates by using equation 3.1. 
B. Compute gain vector: 
   1( ) ( 1) ( )t tλ−= −u Ψ x t
 1( ) ( )
( ) ( )T
t
t tλ= +k x u tu   
C. Compute the network output: 
  23
backW
t
procedure stated in 2.1.2 to obtain Echo States. (  is not used) 
2. Set output weight  to zero vector, which results in a zero output at 
first iteration. 
(0)outW
3. For every iteration, do  
A. Collect state into a collecting matrix . M
B. Hidden state update by equation 3.1. 
C. Collect teacher signal into a collecting matrix . T
D. Compute output using current state and current output weight. (Equation 
3.2) 
E. Use collected information in  and T , calculate new output weight 
using equation 3.3. 
M
The size of collecting matrices $T$ and $M$ cannot grow unlimitedly. Therefore 
a limit $n_{limit}$ to their length is necessary in such algorithm. I state the dealing to 
the collected data in the window here: 
 
When time  limitt n<
In some developing environments (e.g. OpenCV) the size of matrices cannot be 
extended, which may result in the rest limitn −  entries remain zero vectors when 
collecting states and teacher signals. In such condition, using existing collected state 
and teacher signal to compute output weight is needed. 
 
When time  limitt n>
Maximum sizes of my collecting matrices  and  are: T M limitL n×  and 
, respectively. The storage spaces are full when  equals to  after step 
C in 3.2.3, there is indeed no space for saving new information after one iteration. 
Thus in every time step after , I discard one oldest data out from matrices  
limitN n× t limitn
limitt n> T
  25
IV. SIMULATION ENVIRONMENT 
I use a robot soccer simulator called SimSpark, together with a motion design 
tool to design simulated Nao robot's motions, both of the programs are open-sourced, 
meaning any changes to the source code are allowed and free. The following sections 
will give a brief overview to the software.  
 
4.1 SimSpark Robot Soccer Simulator 
SimSpark is used as the official Robocup 3D simulation server. As we know one 
purpose of Robocup is to encourage AI & intelligent robotics research, thus it chose to 
use soccer game as a primary domain. A new approach to a three-dimensional 
physically realistic soccer simulation was proposed on RoboCup 2003 Symposium, 
one year later SimSpark was adopted as the official competition in RoboCup 
Simulation League 3D, 2004. Although the players were modeled as spheres in 
simulation in the very first version, now humanoid robots are also supported since the 
SimSpark development grew considerably. SimSpark is a generic physical multi-agent 
simulator system for agents in three-dimensional environments. It builds on the 
“Spark” application framework, which provides generic and flexible physical 
simulating environments for different kinds of simulations. One can create new 
simulations by using a scene description language, compared to specialized simulators. 
SimSpark is a powerful tool to state different multi-agent research questions. [12] [13] 
 
4.1.1 System Overview: Server 
SimSpark consists of a server and clients. I briefly introduce how they work: 
Server holds a simulation. Properties of objects like position, speed, acceleration, etc. 
may change due to several influences, including interactions between objects and  
  27
perform actions within the simulation; whereas perceptors, who receive messages 
from the server, are the senses of an agent, containing information from the 
environment and the agent itself. SimSpark supports two kinds of agents, one is the 
Soccerbot, the other is the Nao robot. The latter is what I choose for my task. I would 
like to use the perceptor messages from Nao in my task, parse them and extract 
signals I’m interested of. In the following section we will see into the message detail 
of a perceptor. 
 
Message Format 
The basic data structure of perceptor and effector message is symbolic 
expressions (S-expressions). Messages are encoded of default ASCII character set, i.e. 
one byte for each character. Using this format, one can easily read and parse due to 
the compact syntax of the message. There are two types of preceptor messages, I list 
them below: 
 
z One-valued Message: Perceptors like hinge joint perceptors, receive 
information about the angle of the corresponding single axis hinge joint. It 
contains the identifier HJ, the name of the perceptor, and the position angle of the 
axis. Zero degrees corresponds to straightly aligned bodies. Format of 
one-valued perceptor message and an example of it is below: 
♦ Format: (HJ (n <name>) (ax <ax>) ) 
♦ Example: (HJ (n laj3) (ax -1.02)) 
z Three-valued Message: Perceptors like GyroRate perceptor and 
Accelerometer perceptor deliver information about the orientation of a body. 
Currently only the upper torso contains a gyro perceptor. The message contains 
the GYR identifier, the name of the body to which the gyro perceptor belongs 
  29
 
Fig. 4.2 Perceptor and the corresponding body parts of simulated Nao robot. 
(Image is extracted from [12]) 
joints in Qmotion2 differ a little from the perceptor message in SimSpark. 
 
4.2.2 Motion Design and Porting 
After adjusting green dots of desired joints on each time tag, adding some 
frequency points, choose “interpolate” in pop-up menu so that Qmotion2 will use 
these frequencies to approximate required value sequence by linear combination.  
  31
 
Fig. 4.4 Simulated Nao robot 
… 
These messages will appear on the terminal window where Qmotion2 executable  
 
is running. Copy these messages and paste them into the C code, so that one can use 
the designed motion pattern in his own control program. One can also preview the 
motion by choosing “Start Time” in pop-up menu. It is recommended in the manual of 
Qmotion2 that to divide complicated motion into basic movements, generate the code 
of these movements by Qmotion2, and compose the movements into one motion in C 
program by switching them on and off. [19] 
 
 
  33
 
Table 4.1: An example preceptor message 
(time (now 93.60)) 
(GS (t 0.00) (pm BeforeKickOff)) 
(hear 0.00 self 1000-501) 
(GYR (n torso) (rt -0.35 -0.36 -0.01)) 
(ACC (n torso) (a 0.20 -0.20 9.79)) 
(HJ (n hj1) (ax 0.33)) 
(HJ (n hj2) (ax -3.31)) 
(See (G2R (pol 17.55 -3.33 4.31)) 
(G1R (pol 17.52 3.27 4.07)) 
(F1R (pol 18.52 18.94 1.54)) 
(F2R (pol 18.52 -18.91 1.52)) 
(B (pol 8.51 -0.21 -0.17)) 
(P (team teamRed) (id 1) 
(head (pol 16.98 -0.21 3.19)) 
(rlowerarm (pol 16.83 -0.06 2.80)) 
(llowerarm (pol 16.86 -0.36 3.10)) 
(rfoot (pol 17.00 0.29 1.68)) 
(lfoot (pol 16.95 -0.51 1.32))) 
(P (team teamBlue) (id 1) 
(rlowerarm (pol 0.18 -33.55 -20.16)) 
(llowerarm (pol 0.18 34.29 -19.80)))) 
(HJ (n raj1) (ax 31.72)) 
(HJ (n raj2) (ax -20.12)) 
(HJ (n raj3) (ax -0.01)) 
(HJ (n raj4) (ax 40.04)) 
(HJ (n laj1) (ax 64.37)) 
(HJ (n laj2) (ax 19.96)) 
(HJ (n laj3) (ax 0.09)) 
(HJ (n laj4) (ax -40.11)) 
(HJ (n rlj1) (ax -0.06)) 
(HJ (n rlj2) (ax 20.31)) 
(HJ (n rlj3) (ax -39.24)) 
(HJ (n rlj4) (ax 20.02)) 
(HJ (n rlj5) (ax 0.04)) 
(FRP (n rf) (c 0.01 -0.01 -0.02) (f -0.21 0.21 19.77)) 
(HJ (n rlj6) (ax 0.21)) 
  35
V. RESULTS 
This chapter I show my simulated result of prediction of implemented programs 
of SimSpark simulator. I use my message-parsing program to parse the value from the 
perceptor of Nao robot every cycle in SimSpark, record them as a text file, then use 
MATLAB and GNU Octave to test my network. The sensor I use in the test is the 
gyroscope inside the Nao robot, the x-value of the gyroscope at every iteration is the 
teacher signal of my network, the input of network is the same x-value from previous 
one step.  
The figure 5.1 is the flowchart of my agent programs generally. Basically the 
action of “TRAINING PROCEDURE” block depends on which training I choose, for 
consistency I simplify and express them in one block. The plot in this chapter shows 
some prediction results compared to the teacher signal, which is the x part of the 
gyroscope of simulated Nao robot. The black solid line is the teacher signal; the red 
solid line is the predicted result. 
 
5.1 The Predict Target 
The Nao robot possess a gyroscope and accelerometer located at center of the 
body, to keep track of radial as well as axial movement of itself in the three 
dimensional space. The gyro rate perceptor delivers information about the change in 
orientation of a body. These rotation angles describe the change rates in orientation of 
the body during the last cycle. I designed a motion from Qmotion2 that lets the hip 
joints of Nao robot moe back and forth slowly, and take the x-value of the inner 
gyroscope of Nao as my input signal and also teacher signal. What I feed into the 
network is always the x-value of the gyroscope from previous one step; what I predict 
is the x-value of current step, which should be the teacher signal of the network. As  
  37
the training period is set to 700 time steps. After training, the other signal sequence is 
used for testing, 300 steps of signal was predicted. The spectral radius of this 
experiment is set to 0.8. 
Plots of the results using 10, 20, 30 and 40 hidden neurons are in Fig. 5.2a. The 
blue line is the teacher signal (the x-value of the gyroscope), while the red line in the 
same plot is the predicted signal. I also recorded and plotted the difference between 
current and previous signal, the plots of 10, 20, 30 and 40 hidden neurons are in Fig. 
5.2b. I calculate the mean-squared error from iteration 100 to 300 to get rid of the 
unreasonable value in the beginning. Standard deviation of each case (hidden neurons) 
is given in table 5.1. 
 
Table 5.1: Batch Learning MSE & standard deviation to hidden neurons (iteration 100 to 300) 
Hidden Neurons 10 neurons 20 neurons 30 neurons 40 neurons 
MSE 0.9334995 0.958387 1.003324 1.119631 
Standard Deviation 2.161255 2.175631 2.167928 2.640369 
 
5.3 Standard Online Training 
This section shows the result of using standard online training. X-value of 
gyroscope sensor from previous iteration is the input of the network; the network tries 
to predict the teacher signal, which is the current x-value of gyroscope of Nao. The 
training period (the size of the sliding window) is set to 200 iterations. Spectral radius 
of hidden weight matrix I used in this experiment is 0.5α = . 
In this experiment only one gyroscope sequence is used, for testing and weight 
computing. Plots of the results are in Fig. 5.4a. I also recorded and plotted the 
difference between current and previous signal, the plots of 10, 20, 30 and 40 hidden 
neurons are in Fig. 5.4b. A plot of MSE to neurons is in Fig. 5.5. I calculated the 
  39
hidden neuron and the forgetting factor λ , which is shown in Fig. 5.8. 
 
Table 5.3: Recursive Least Square Learning MSE 
 λ= 0.3 λ= 0.5 λ= 0.7 λ= 0.9
5 hidden neurons 29.35414 22.47065 12.78118 9.655906
10 hidden neurons 131.6991 37.64766 18.24146 8.114248
15 hidden neurons 1266.095 190.9388 25.66467 8.636237
20 hidden neurons 2479.441 964.3967 47.18191 8.696978
 
Table 5.4: Recursive Least Square Learning Standard Deviation 
 λ= 0.3 λ= 0.5 λ= 0.7 λ= 0.9
5 hidden neurons 109.9287 117.8982 90.06941 82.53108
10 hidden neurons 757.7202 136.3755 100.1106 81.81923
15 hidden neurons 6917.097 986.7847 109.6837 81.83764
20 hidden neurons 20551.32 6686.217 229.4815 81.71403
 
5.5 Discussion to Hidden Neurons 
In the results of the above three experiments, we see a problem could be found 
from the plots: Worse performance with more neurons inside the hidden layer. 
To find out this phenomenon, I made another experiment: I used MATLAB and 
tried singular value decomposition (SVD) to the state collecting matrix and observed 
how many singular values that are very close to zero for different numbers of neurons 
in hidden layer. I have computed the average number of singular values of state 
collecting matrix in condition of different hidden neurons; the result is plotted in Fig. 
5.9. We can see from the plot that more neurons in hidden layer will cause more 
singular values that are very close to zero. This probably due to the computing 
  41
 
  
(a) Plots of teacher signal  (blue) and predicted value  
(red). From top to bottom: 10, 20, 30 and 40 hidden neurons 
( )td ( )ty (b) Plots of difference between current and previous signal 
Fig. 5.2 Batch learning prediction of x-value of gyroscope using different hidden neurons 
  43
 
  
(a) Plots of teacher signal  (blue) and predicted value  
(red). From top to bottom: 10, 20, 30 and 40 hidden neurons 
( )td ( )ty (b) Plots of difference between current and previous signal 
Fig. 5.4 Standard online training prediction of x-value of gyroscope using different hidden 
neurons 
  45
 
  
(a) 5 hidden neurons (b) 10 hidden neurons (c) 15 hidden neurons (d) 20 hidden neurons 
Fig. 5.6 Recursive Least Square prediction of x-value of gyroscope using different hidden neurons and 
forgetting factor λ . From top to bottom: 0.3,0.5,0.7,0.9λ = . The teacher signal is the blue line; the red 
line is the predicted value 
 
  47
 
 
Fig. 5.8 Mesh plot of MSE in different combination of hidden neurons and 
forgetting factor in RLS Learning. Mean-squared difference of current and previous 
teacher signal ( ) is 30.9 ( ) ( 1)t t− −d d
 
 
 
Fig. 5.9 Plot of average number of close-to-zero singular values to different hidden 
neurons 
  49
6.2 Future Works  
According to our result, still there are many problems left in the experiment. This 
section provides several points for follow-up developers the directions on putting 
improve and enhance to my works. The following items are possible ways of what to 
do: 
z Find out and solve the problem of more hidden neurons causing worse 
performance. 
z Apply Backpropagation Decorrelation (BPDC) algorithm to Echo State 
Network, one application of using BPDC ESN is in paper [10] and thesis [4] 
z One may use values from moving hinge joints as another inputs feeding into 
networks. 
z Make predicted values more visible, draw an extra robot arm if the predict 
target is the value of a robot arm joint, for example. 
z Make ESN as a generic black-boxed Qi-module, which is developing in our 
lab, aiming to integrate all transferring of signals together. 
z The final goal we would like to achieve: Let the robot to do some decision, 
which is based on the past “experience”. 
 
  51
[10]  Jochen J. Steil, Backpropagation-Decorrelation: online recurrent learning with 
O(N) complexity, In Proc. IJCNN, volume 1, pages 843–848, 2004. 
[11]  Joschka Boedecker et al., SimSpark User's Manual v1.2, 
http://simspark.sourceforge.net/wiki/images/a/ad/User-manual.pdf, 1998. 
[12] http://simspark.sourceforge.net/wiki/index.php/About_SimSpark
[13]  Norbert M. Mayer, Joschka Boedecker and Minoru Asada, Robot motion 
description and real-time management with the Harmonic Motion Description 
Protocol, Robotics and Autonomous Systems Journal, 2009. 
[14] http://en.wikipedia.org/wiki/Neural_network
[15] http://www.csie.nctu.edu.tw/~kensl/AIrpt.htm
[16] Kazuhiro Masui, Using Echo State Networks to Classify and to Predict Sensory 
Input, Master Thesis, Dept. of Adaptive Machine Systems, Osaka University, 
Japan, 2008. 
[17] N. Michael Mayer and Oliver Obst, Time Series Causality Inference Using Echo 
State Networks, Department of Electrical Engineering, National Chung Cheng 
University, Taiwan, 2010. 
[18] R.J.Frank, N.Davey, S.P.Hunt, Time Series Prediction and Neural Networks, 
Department of Computer Science, University of Hertfordshire, Hatfield, UK., 
2000. 
[19] Juris Klonovs and Lin Xiang Zhang, Qmotion2 User's Manual, 2009. 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                   
                                 
一、參加會議經過 
The main purpose of the visit was to attend the Japan Open and present recent 
developments in the attached symposium. Initially it was also planned to participate 
with our NAO team and our RoboCup@home team but because of the events after the 
Tsunami in March my students were reluctant to go to Japan, although the 
competition site is considerably far away from  site of the nuclear reator in 
Fukushima. 
二、與會心得 
I presented our results at the SIG meeting. At the Japan Open I learned about 
recent devopments in robot soccer and service robotics at the competition site. In 
addition, I met with Prof. Dr. Hiroshi Ishiguro to discuss how to promote his new 
project“Elfoid”(human shaped mobile phone) in Taiwan. 
三、考察參觀活動(無是項活動者略) 
I visited Dr. Daron Standley and Dr. Nicolas Smith at Osaka University to discuss 
possibilities for further collaborations. 
計畫編號 NSC  98－2218－E－194-003－MY2 
計畫名稱 服務機器人 
出國人員
姓名 
 
許宏銘 
服務機構
及職稱 
 
國立中正大學 
電機工程學系副教授 
 
出國時間 
100 年 5 月 3 日至 
100 年 5 月 8 日 
出國地點  
Osaka, Japan 
會議名稱 
(英文) 
Meeting of the RoboCup Japan Open Special Interest Group (SIG) and the Japan Open 
 
發表論文
題目 
(英文)  
1. An Efficient Data Sharing Solution of Multi-Functional Robotics Design: Qflow 
2. Analogies between the autistic brain and the state of the art artificial autonomous 
agent 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
 
                                                                   
一、參加會議經過 
The visit had 3 targets. The first target was to visit the RoboCup competition 5-10 of 
July, the second target was to organize the the RoboCup symposium, the third was to 
meet collaborators and potential collaborators in Germany. 
二、與會心得 
The RoboCup included several highlights including the win of the Darwin OP robot in 
the Humanoid League. Although that is not directly related to our team it is interesting 
because the Robot is distributed by Dynamixel who are one of our industrial partners. 
The symposium included several organizational issues, that could finally solved with 
the help of the local organizers. Most important issues of the Symposium were the 
invited speakers Dieter Fox from the University of Washington and Luc Steels from 
the University of Brussels. 
三、考察參觀活動(無是項活動者略)  
-- 
四、建議 
Future meetings with international collaborators should be held more frequently. 
計畫編號 NSC  98－2218－E－194-003－MY2 
計畫名稱 服務機器人 
出國人員
姓名 
許宏銘 
服務機構
及職稱 
 
國立中正大學 
電機工程學系副教
授 
會議時間 
100 年 7 月 2 日至 
100 年 7 月 25 日 
會議地點 
 
Istanbul, Turkey  
會議名稱 
(Chinese)机器人世界杯徑賽会議 
(English) RoboCup World Championship and Symposium 2011 
發表論文
題目 
 
(Chinese) 
(English) Proceedings of the RoboCup Symposium (Springer) 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                   
                                 
一、參加會議經過 
The main purpose of the visit was to attend the Japan Open and present recent 
developments in the attached symposium. Initially it was also planned to participate 
with our NAO team and our RoboCup@home team but because of the events after the 
Tsunami in March my students were reluctant to go to Japan, although the 
competition site is considerably far away from  site of the nuclear reator in 
Fukushima. 
二、與會心得 
I presented our results at the SIG meeting. At the Japan Open I learned about 
recent devopments in robot soccer and service robotics at the competition site. In 
addition, I met with Prof. Dr. Hiroshi Ishiguro to discuss how to promote his new 
project“Elfoid”(human shaped mobile phone) in Taiwan. 
三、考察參觀活動(無是項活動者略) 
I visited Dr. Daron Standley and Dr. Nicolas Smith at Osaka University to discuss 
possibilities for further collaborations. 
計畫編號 NSC  98－2218－E－194-003－MY2 
計畫名稱 服務機器人 
出國人員
姓名 
 
許宏銘 
服務機構
及職稱 
 
國立中正大學 
電機工程學系副教授 
 
出國時間 
100 年 5 月 3 日至 
100 年 5 月 8 日 
出國地點  
Osaka, Japan 
會議名稱 
(英文) 
Meeting of the RoboCup Japan Open Special Interest Group (SIG) and the Japan Open 
 
發表論文
題目 
(英文)  
1. An Efficient Data Sharing Solution of Multi-Functional Robotics Design: Qflow 
2. Analogies between the autistic brain and the state of the art artificial autonomous 
agent 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
 
                                                                   
一、參加會議經過 
The visit had 3 targets. The first target was to visit the RoboCup competition 5-10 of 
July, the second target was to organize the the RoboCup symposium, the third was to 
meet collaborators and potential collaborators in Germany. 
二、與會心得 
The RoboCup included several highlights including the win of the Darwin OP robot in 
the Humanoid League. Although that is not directly related to our team it is interesting 
because the Robot is distributed by Dynamixel who are one of our industrial partners. 
The symposium included several organizational issues, that could finally solved with 
the help of the local organizers. Most important issues of the Symposium were the 
invited speakers Dieter Fox from the University of Washington and Luc Steels from 
the University of Brussels. 
三、考察參觀活動(無是項活動者略)  
-- 
四、建議 
Future meetings with international collaborators should be held more frequently. 
計畫編號 NSC  98－2218－E－194-003－MY2 
計畫名稱 服務機器人 
出國人員
姓名 
許宏銘 
服務機構
及職稱 
 
國立中正大學 
電機工程學系副教
授 
會議時間 
100 年 7 月 2 日至 
100 年 7 月 25 日 
會議地點 
 
Istanbul, Turkey  
會議名稱 
(Chinese)机器人世界杯徑賽会議 
(English) RoboCup World Championship and Symposium 2011 
發表論文
題目 
 
(Chinese) 
(English) Proceedings of the RoboCup Symposium (Springer) 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/11/11
國科會補助計畫
計畫名稱: 服務機器人
計畫主持人: 許宏銘
計畫編號: 98-2218-E-194-003-MY2 學門領域: 智慧型機器人 
研發成果名稱
(中文) Qi 分散式嵌入式系統整合工具
(英文)
成果歸屬機構
國立中正大學 發明人
(創作人)
許宏銘
技術說明
(中文) Qi是一種可以組合許多module的平台或者是Server，就算module是在各種不同的
電腦上開發出來，但我們只要將這些分散於不同電腦中的module集中於一部擁有
Qi的電腦上就可以將其結合，舉著例子，一個電子產品，不妨將module想成是一
件元件，它有著一種屬於它的功能，如電阻、電容‧‧‧等元件。 
Qi有著像Word文件裡的檔案選項，如開新檔案、開啟舊檔、儲存檔案等功能，開
新檔案可以讓你開啟新的頁面使用module重新連結成一個元件，這個元件可能是
一個完成品也可能是一個更進一步的元件，例如OP放大器；它也有儲存這個功能
可以將你剛剛完成的一個元件儲存下來，讓你之後想要再用到時可以直接開啟之
前儲存的元件；Server選項裡有可以輸入server位址的功能跟開啟Server的功能。
 
P.S. 在Qi中，module是一個.so檔，這個.so檔可以使用Makefile將你寫得.cpp
檔和.h檔拿來編譯而產生的。 
(英文) Qi: A tool for rapid prototyping of integrated behavior systems on a team of distributed 
embedded systems 
 
In the present work , we would like to have a kind of meta-control framework, that can 
help to detect 'unusual' states of the control system and then can help to put the main 
control modules back on track. For these purposes we are developing a tool that meets the 
following specifications: 1. All functions of the control systems can be loaded 
dynamically as modules into the framework during runtime, and are automatically 
depicted in a graphical user interface, that also allows to control that data flow between 
the modules. 2. Network capability: The data flow can easily cross from one embedded 
system to another via the network, the developer does not need to care if a flow goes from 
one embedded system to another. In this way a kind of 'cloud computing' between 
embedded system shall be realized. Behavior modules can be easily shifted from one 
embedded system to another.
產業別 資訊服務業
技術/產品應用範圍 適用於高階機器人整體功能控制
技術移轉可行性及
預期效益
以QT多平台開放式開發，可以移轉於裝載QT的linux系統和window系統上
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
FIRA(國際足球機器人比賽)榮獲 HuroCup-Penalty Kick Category 比賽亞軍 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
