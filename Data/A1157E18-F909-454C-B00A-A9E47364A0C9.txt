 1 
中文摘要 
本計畫係以單一攝影機作傾斜式之攝影(tilt photograph-
ing)，利用CCD攝影機拍攝距離不同時，在目標物體所在
之傾斜平面上兩任意指定點於影像中之像素值會產生差異，
藉以求得CCD攝影機與待測目標物的實際距離、傾斜面角
度、以及傾斜面上任意兩點之距離，再利用所提出之方法
求得傾斜面上目標物體距離影像中心軸在傾斜面投影點之
距離，完成目標物體之2D平面定位 (localization)，並以人
形機器人競賽場地之目標物定位為例，驗證所提出方法之
可行性。 
 
Abstract—This project proposes an image-based system 
for measuring target objects on an oblique plane based on 
pixel number variation of charge-coupled device images for 
digital cameras by referencing to two arbitrarily desig-
nated points in the image frame. Based on an established 
relationship between the displacement of the camera 
movement along the photographing direction and the var-
iation in pixel counts between the reference points in the 
images, photographic distance and incline angle for objects 
lying on an oblique plane can be calculated via the pro-
posed method. As a real-case application of the proposed 
approach, two-dimensional localization of target objects in 
robot soccer competitions is also demonstrated to show the 
effectiveness of the proposed approach.  
 
Keywords —distance measurement, photogrammetry, ob-
lique plane, incline angle, digital cameras, CCD images, 
image-based measuring systems, localization. 
I. INTRODUCTION 
As far as non-contact distance measurement is concerned, 
ultrasonic-based [1]-[5] and laser-based [6]-[7] tech-
niques are among the most commonly-used methods. 
Unfortunately, measurement accuracy via the laser- and 
ultrasonic-based methods heavily depended on surface 
reflectivity of the object under measurement. If the ref-
lection surface is undesired, the measuring system gen-
erally performed poorly. The calibration of laser-based 
instrument is not a trivial issue either, since systematic 
trends could produce the lost of accuracy. Furthermore, 
these methods have difficulties in recording images of 
the objects while taking measurement. Alternatively, 
photogrammetric methods [8]-[11] have been proposed 
for measuring distance as well as determining geometric 
properties of objects from photographic images. Thanks 
to the advantages in providing a rich source of envi-
ronment information, photogrammetric methods have 
been widely adopted in various applications, for example, 
localization of mobile robots [12], traffic accidents in-
vestigation, forensic engineer as well as dimensional 
analysis of pathologies over facades [13]. In recent years, 
a more sophisticated technique referred to as stereo vi-
sion [14], [15], [16] is getting increasingly more popular 
in estimating the three-dimensional coordinates of points 
on an object. However, traditional stereo vision-based 
systems generally required two cameras displaced hori-
zontally from one another to capture two different pic-
tures for further analysis. As a result, pattern recognition 
[17]-[21] or image analysis [22]-[24] of a whole image 
frame are required to extract and match features from the 
images for obtaining the distance measurement. Thus, 
huge amount of storage capacity and high-speed digital 
signal processors (DSP) are required for system so es-
tablished, inevitably resulting in disadvantages in terms 
of system complexity, processing speed, and establish-
ment cost. As a result, performance of real-time mea-
surement via the pattern recognition or image analysis 
methods was generally not satisfactory, particularly for 
embedded applications, because of the speed constraint. 
Recent developments in camera technology like Pho-
tonic Mixer Device (PMD) systems [25] have provided a 
possibility of measuring distances for 2D scene in real 
time. One major disadvantage of PMD, however, is the 
relatively low resolution or corresponding limited field 
of view (FOV) [26]. As an attempt to solve this problem, 
an image-based distance measuring system (IBDMS) 
[21], [27] was proposed to measure distance and area 
using two laser projectors and a CCD camera based on a 
triangular relationship. Unfortunately, the IBDMS is 
valid only for measuring objects or surfaces that are 
perfectly perpendicular to the optical axis. Any tilt in the 
plane formed by the target surface that intersects the two 
laser beams will have an adverse effect on the determi-
nation of pixel counts, and consequently distance mea-
surement. Based on a binocular stereo vision model, a 
ranging method for remote objects was proposed by us-
ing a single camera [28]. As a stereo vision-based ap-
proach, this method required that the camera be mounted 
on a rotating platform driven by a step motor to obtain a 
rotating angle for calculating the ranging distance. Extra 
constraints on obtaining the parallax images are inevita-
ble because of the use of external step motor or angle 
encoder. With the use a single camera, an angle invariant 
approach [12] was proposed to obtain target positions 
relative to the camera using only data extracted from a 
single image. Though this approach works to some ex-
tent, it is nevertheless a dedicated application for mid-
dle-size soccer robots. As a result, extra pre-experiments 
are required to obtain the measuring parameters. A pixel 
position indicating the height of the CCD camera is also 
required as a reference point to obtain the distance 
measurement. For ranging or localization of remote ob-
jects, this approach will be too restricted to be useful. 
Other image-based approaches include those based on 
the use of omni-directional cameras with panoramic 
views to localize objects [29]. These approaches, how-
ever, are beyond the scope of discussion in this project, 
where measurement based on a single planar camera is 
only investigated. There was also a distance measure-
ment method based on pixel number variation of images 
[30]. Unfortunately, this approach failed to solve the 
problem in measuring objects on an oblique plane, sim-
ilar to the IDBMS method. By extending the previous 
work by the authors [31], this project proposes an im-
age-based approach based on pixel number variation of 
images, overcoming the above-mentioned difficulties to 
measure photographic distance and incline angle for 
objects on an oblique plane. As an application of the 
proposed approach, two-dimensional localization of 
target objects on an oblique plane is also demonstrated to 
show the effectiveness of the proposed approach. To 
allow the use of widely available digital zoom cameras 
for ranging and localization by the proposed method, a 
 3 
pendicular to the optical axis. If the surface under mea-
surement is not perpendicular to the optical axis, it would 
have different relationships. Thus, the design objective 
of this project is to establish a new relationship based on 
the displacement of the camera movement and the vari-
ation in pixel counts to measure the photographic dis-
tance and incline angle for objects lying on an oblique 
plane.  
Figure 2 shows the configuration of the proposed 
image-based system for measuring objects on an oblique 
surface based on variation of pixel counts, where an in-
cline angle 
m  exists between the oblique and perpen-
dicular planes. Referring to Fig. 2, because point A on the 
target plane is farther from and point B is closer to the 
CCD camera, formulas (4) to (7) do not apply in this case. 
To solve this problem, the concept of virtual planes can 
be introduced to address the problem to measure the 
photographic distance and incline angle 
m . Virtual 
planes, for example planes VP_A and VP_B in Fig. 2, are 
intangible planes that are perpendicular to the optical 
axis. Thus, the distances between the camera and the 
virtual planes at different positions can be obtained as: 
 
  Shh
ANAN
AN
Ah 


)()(
)(
12
2
1
                  (8) 
  Shh
ANAN
AN
Ah 


)()(
)(
12
1
2
                 (9) 
  Shh
BNBN
BN
Bh 


)()(
)(
12
2
1
                 (10) 
  Shh
BNBN
BN
Bh 


)()(
)(
12
1
2
                 (11) 
where )(1 Ah  and )(1 Bh  are distances from the camera 
at position 1 (OP1) to virtual planes VP_A and VP_B, 
respectively, )(2 Ah  and )(2 Bh are distances from the 
camera at position 2 (OP2) to virtual planes VP_A and 
VP_B, respectively, and )(XNn  stands for the pixel 
counts in the image plane for point X when the image is 
taken at position n . 
From (8), (9), (10), and (11), we have: 
          mBA ddkBhAhBhAh tan2211  (12) 








 
BA
m
dd
k1tan             (13) 
where k  is the distance between the virtual planes 
VP_A and VP_B, and 
m  is the incline angle between 
the oblique and virtual planes. 
Ad  and Bd  represent the 
distances from points A and B to the intersections of the 
optical axis and virtual planes VP_A and VP_B, respec-
tively, which can be expressed as follows: 
 
   
  HH
A h
NANAN
ANAN
d tan
)()(
2
max_12
21 


    (14) 
   
  HH
B h
NBNBN
BNBN
d tan
)()(
2
max_12
21 


    (15) 
To this end, the photographic distances from the camera 
at positions 1 (OP1) and 2 (OP2) to point O can be re-
spectively expressed as: 
 
      mBmA dBhdAhOh  tantan 111    (16) 
      mBmA dBhdAhOh  tantan 222    (17) 
In order to determine the position of target objects in 
the real-world environment, we represent the distance 
between two arbitrary points A and B appearing on the 
same scan line in the image as )(ABD , which can be 
derived as: 
    mBA ddABD sec   (18) 
if point O lies between points A and B, or 
  mBA ddABD sec        (19) 
if point O does not lie between points A and B.  
h
1 (A
)
h
2 (O
)
Δ
h
A
hs
hs
CCD 
camera
Image plane
Image plane
NH_max
NH_max
B
O
h
1 (B
)
h
2 (B
)h
2 (A
)
N2(B) N2(A)
h
1 (O
)
VP_A
VP_B
N1(B) N1(A)
dA
dB
H
m k
1op
2op
oblique plane
  
Fig. 2  Configuration of the proposed image-based system for mea-
suring objects on an oblique surface based on variation of pixel counts. 
 
IV. TWO-DIMENSIONAL LOCALIZATION OF OBJECTS 
ON AN OBLIQUE PLANE 
Figure 3 shows a perspective diagram of the localization 
scheme using the proposed method, where images are 
taken by a camera above the oblique plane painted in 
light blue color. The oblique plane formed by points P‘, 
Q‘, R‘, S‘ is an illustration when the camera takes images 
at position 1 (OP1). Similarly, the oblique plane formed 
by points P‘‘, Q‘‘, R‘‘, S‘‘ illustrates the case in which 
camera takes images at position 2 (OP2). Unless specif-
ically described, we will use images taken at position 1 
(OP1) for illustration to avoid confusions.  
Note that there is an incline angle 
m  lies between 
the oblique plane formed by points P‘, Q‘, R‘, S‘, and a 
virtual plane formed by points P, Q, R, S by rotating the 
oblique plane around x-axis. Based on the derivations in 
the previous section, 2-dimensional localization of an 
object C‘ on the oblique plane can be obtained through 
the following simple rules: 
 5 
''
1tan
BC
m
dd
k


      (24) 
where 
 
V
V
C h
CONCON
CON
N
CON
d tan
)'()'(
)'(2'
2122
22
max_
21
' 

    (25) 
 
V
V
B h
BONBON
BON
N
BON
d tan
)'()'(
)'(2'
2122
22
max_
21
' 

   (26) 
where 
V  is the maximal vertical view angle of the 
camera, and 
max_VN  is the maximal pixels in a vertical 
scan line of an image frame. From (22) and (24), we have: 
  mCdCOD sec' '2     (27) 
To this end, we can express the coordinates of a target 
object, C‘, on the oblique plane as: 
 
 )'(),'(),'(),,(' 121 ChCODCODzyxC  ,  (28) 
where )'( 1COD , )'( 2COD , and )'(1 Ch  stand for the dis-
tance to the y-axis, the distance to the x-axis, and pho-
tographic distance, respectively, achieving the objective 
of localization for objects on the oblique plane. 
V. EXPERIMENT RESULTS 
To demonstrate the effectiveness of the proposed ap-
proach in measuring photographic distance and incline 
angle for objects on an oblique surface as well as 2-D 
localization of objects, extensive experiments have been 
conducted. Figure 6 shows the schematic diagram of the 
setup of the proposed image-based system for measuring 
target objects on an oblique surface based on pixel 
number variation of CCD images. The CCD camera 
adopted to conduct the experiments in this project is 
Canon 400D with 3888max_ HN pixels and 
2592max_ VN  pixels. Measuring parameters of the 
camera include: 55.1cot H , 33.2cot V , 11.4Sh  
cm, and 50h  cm, which are obtained in advance 
before the experiments begin.  
 
 
 
Fig. 6  Schematic diagram showing the proposed image-based system 
for measuring objects on an oblique surface based on pixel number 
variation of CCD images. 
 
Measurement of 2-D localization of objects on an oblique plane 
Fig. 7 shows an image of the experiment setup to conduct 
2-dimensional localization of objects on an oblique surface via the 
proposed method, where red boxes A, B, C, D are the objects to be 
localized. Table 1 shows the coordinates measurements of the objects 
deployed in Fig. 7 by measuring the bottom-left corner of these boxes, 
where three measurements are recorded for each object in the table, 
including horizontal distance to y-axis, vertical distance to x-axis, and 
photographic distance. From the experiment results, it can be seen that 
smaller errors can be obtained for objects lying closer to the image 
center, while larger errors for objects farther from the image center. 
These results are expected due to the effect of radial distortion of the 
lens. 
D
BA
C
X-axis
Y-axis
  
Fig. 7  Image showing 2-dimensional localization of objects on an 
oblique surface via the. 
 
 
Table 1 Two-dimensional localization of objects on an oblique surface 
in Fig. 7 
Object coordinates in 
image (pixels) 
A 
(213,253) 
B 
(476,262) 
C 
(461,219) 
D 
(150,212) 
Horizontal 
distance to 
y-axis  
Actual 
(cm) 
50 70 90 110 
Measured 
(cm) 
49.21 68.24 92.55 114.20 
Error (%) -1.58% -2.51% 2.83% 3.82% 
Vertical dis-
tance to 
x-axis  
Actual 
(cm) 
50 70 90 110 
Measured 
(cm) 
49.42 68.34 92.85 115.02 
Error (%) -1.16% -2.37% 3.17% 4.56% 
Photographic 
distance  
Actual 
(cm) 
399 370 525 539 
Measured 
(cm) 
406.12 379.75 539.75 559.61 
Error (%) 1.78% 2.64% 2.81% 3.82% 
 
Real-case applications 
 
Two real-case applications in robot soccer competi-
tions adopted from The Federation of International Ro-
bot-soccer Association (FIRA) [36], including penalty 
kick and obstacle run in HuroCup, are demonstrated in 
this section using the proposed method. These two events 
are robotics benchmark problems for humanoid robots. 
In penalty kick challenge, the robot must approach and 
kick a ball positioned somewhere in the ball area. A robot  
 
 
Table 2 Coordinates of the objects in an obstacle run challenge in 2010 FIRA HuroCup game field for Fig. 9(a) (robot on the start side) 
Objects A B C D E 
 2 
To allow practical use of the proposed approach, an 
equivalent parameter for digital zoom cameras is also 
derived, so that the proposed measuring approach can be 
readily applicable without the need to physically move 
the camera to obtain a measurement. As demonstrated in 
the report, the proposed measuring system has overcome 
problems and difficulties encountered by conventional 
image-based measuring methods and demonstrated itself 
as a simple yet practical way in measuring distance and 
incline angle for objects on an oblique surface while 
simultaneously recording images. In order to obtain 
better measurement result, users are advised to locate the 
object under measurement as close to the image center as 
possible during the measurement to minimize radial lens 
distortion. Larger displacement h  is preferable 
whenever possible, as long as the reference points can be 
correctly identified in the first place. To improve the 
automatism to automatically extract reference points in 
the images, object recognition techniques, for example, 
Speeded Up Robust Features (SURF) technique [35], can 
be incorporated to perform efficient feature matching to 
recognize objects in the image frame for determining the 
pixel number variation due to different photographic 
distances. 
VII. REFERENCES 
[1] F. Gueuning, M. Varlan, C. Eugene, and P. Du-
puis, ―Accurate distance measurement by an au-
tonomous ultrasonic system combining 
time-of-flight and phase-shift methods,‖ IEEE 
Transactions on Instrumentation and Measure-
ment, vol. 46, no. 6, pp. 1236-1240, Dec. 1997. 
[2] A. Caarullo and M. Parvis, ―An ultrasonic sensor 
for distance measurement in automotive applica-
tions,‖ IEEE Sensors Journal, vol. 1, no. 2, pp. 
143-147, Aug. 2001. 
[3] K. Nakahira, T. Kodama, S. Morita, and S. 
Okuma, ―Distance measurement by an ultrasonic 
system based on a digital polarity correlator,‖ 
IEEE Transactions on Instrumentation and 
Measurement, vol. 50, no. 6, pp. 1478-1752, Dec. 
2001. 
[4] A. Carullo, F. Ferraris, and S. Graziani, ―Ultra-
sonic distance sensor improvement using a 
two-level neural network,‖ IEEE Transactions on 
Instrumentation and Measurement, vol. 45, no.2, 
pp. 667-682, Apr. 1996. 
[5] K.T. Song and W.H. Tang, ―Environment per-
ception for a mobile robot using double ultrasonic 
sensor and a CCD camera,‖ IEEE Transactions 
on Industrial Electronics, vol. 43. no.3, June 
1996. 
[6] H. Kazuya, M. Seiichi, Y. Hideo, A. Tsuyoshi, F. 
Tadahide, S. Tamotsu, H. Shigeru, and I. To-
monori, ―Range finder system,‖ US Patent of 
Invention, no. 4123650, 1978. 
[7] K. Osugi, K. Miyauchi, N. Furui, and H. Miya-
koshi, ―Development of the scanning laser radar 
for ACC system,‖ JSAE Review, vol. 20, no. 4, pp. 
549-554, Oct. 1999. 
[8] T. Schenk, Introduction to Photogrammetry, 
Department of Civil and Environmental Engi-
neering and Geodetic Science, The Ohio State 
University, 2005.  
[9] Clive S. Fraser and Simon Cronk, ―A hybrid 
measurement approach for close-range photo-
grammetry,‖ ISPRS Journal of Photogrammetry 
and Remote Sensing, vol. 64, pp. 328-333, 2009. 
[10] Frank A. van den Heuvel, ―3D reconstruction 
from a single image using geometric constraints,‖ 
ISPRS Journal of Photogrammetry and Remote 
Sensing, vol. 53, pp. 354-368, 1998. 
[11] De-hai Zhang, Jin Liang, and Cheng Guo, ―Pho-
togrammetric 3D measurement method applying 
to automobile panel,‖ 2010 The 2nd International 
Conference on Computer and Automation Engi-
neering (ICCAE), 2010, pp. 70-74. 
[12] J.C. Fernandes and J.A.B. Neves, ―Angle Inva-
riance for Distance Measurements Using a Single 
Camera,‖ 2006 IEEE International Symposium 
on Industrial Electronics, Montreal, Canada, 
9-13 July 2006, pp. 676 - 680. 
[13] Mario Gardiol and Ana Maria Pighini, ―Saint 
Anthony‘s Chapel Facade Pathology Documen-
tation,‖ XXI International CIPA Symposium, 
Athens, Greece, 01-06 October, 2007.  
[14] Yuichi Ohta and Takeo Kanade, ‗Stereo by Intra- 
and Inter-Scanline Search Using Dynamic Pro-
gramming,‖ IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. PAMI-7, 
no. 2, pp. 139-154, 1985. 
[15] Zhi-Wei Gao, Wen-Kuo Lin, Yu-Shian Shen, 
Chia-Yen Lin, and Wen-Chung Kao, ―Design of 
signal processing pipeline for stereoscopic cam-
eras,‖ IEEE Transactions on Consumer Elec-
tronics, vol. 56, no. 2, pp. 324 – 331, 2010. 
[16] D. Paulus and G. Schmidt, ―Approaches to Depth 
Estimation from Active Camera Control,‖ Pro-
ceedings of the German / Slovenian Workshop, 
1996, pp. 1-10. 
[17] C.C. Peng, ―A compact digital image sensing 
distance and angle measuring device,‖ M.S. the-
sis, Optical Science Center, Nation Central Univ., 
Taoyuan County, Taiwan, 2001. 
[18] T. Egami, S. Oe, K. Terada, and T. Kashiwagi, 
―Three dimensional measurement using color 
image and movable CCD system,‖ The 27th 
Annual Conference of the IEEE Industrial Elec-
tronic Society, Denver , USA, 29 Nov. - 02 Dec. 
2001, pp.1932-1936. 
[19] M.C. Lu, ―Image-based height measuring system 
for Liquid or particles in tanks,‖ ROC patent of 
invention, no. 201536, 2004. 
[20] D. Katsoulas and A. Werber, ―Edge detection in 
range images of piled box-like objects,‖ Pro-
ceedings of the 7th International Conference on 
Pattern Recognition, Cambridge UK, August 
23-26, 2004, vol. 2, pp. 80-84. 
[21] M.C. Lu, W.Y. Wang, and C.Y. Chu, ―Im-
age-based distance and area measuring system,‖ 
IEEE Sensors Journal, vol. 6, no. 2, pp. 495-503, 
Apr. 2006. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/08
國科會補助計畫
計畫名稱: 以SOPC為基礎利用單一攝影機傾斜攝影之移動式機器人物體追蹤與定位系統
計畫主持人: 許陳鑑
計畫編號: 99-2221-E-003-009- 學門領域: 智慧型控制
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1. 指導學生張家瑋、劉韋辰、朱書漢，參加 2011 亞洲創新設計大賽 (100 年 9
月 6 日)，入選決賽，題目：指揮機器人。 
2. 指導學生楊誠愷、侯如瑜、張華恩，參加 2011 亞洲創新設計大賽 (100 年 9
月 6 日)，入選決賽，題目：不球於人。 
3. 指導學生郭家瑞、賴古梵、蔡宗翰，參加 2011 亞洲創新設計大賽 (100 年 9
月 6 日)，入選決賽，題目：獵殺賓拉登。 
4.      擔任 Program Co-chair, 2011 International Conference on Service 
and Interactive Robotics, Taichung, Taiwan, Nov. 25-27, 2011. 
2. 擔 任 Program Co-chair, 16th FIRA RoboWorld Cup and Congress, 
Kaohsiung, Taiwan, August 26-30, 2011. 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
