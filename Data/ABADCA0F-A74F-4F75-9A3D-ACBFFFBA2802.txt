 2
ˆX( , ) ( , ) _m i x m i Noise eng= −  
.
5
),(ˆ
),(ˆ            
4
0
∑
=−= m
imx
imx         (6) 
由(6)式，我們可以計算出熵的機率 
20
1
( , )
( , ) ,  1 20,
( , )
k
X m i
P m i i
X m k
=
= ≤ ≤
∑
     (7) 
其中 m為音框，i為頻帶。根據(7)的機率公
式，我們可推導出熵(Entropy)參數如下: 
20
1
1MS-entropy(m) ( , ) log
( , )i
P m i
P m i=
=∑    (8) 
此 MS-entropy 可以估測語音訊號在頻譜上
振幅的不明確性，其數值大小與頻譜上振幅
的關係可以藉由圖二來說明。此外，我們也
採用 MiFre, SV-MiFre 與 LV-MiFre 參數來
估測噪音環境能量。其計算方式為將前面式
(6)處理如下。 
 
[ ]( )20,..2,1),(minˆ == iimXSMOOTHINGX  (9) 
 
( ) ( )( )mXConstraSlopemMiFre ˆint =     (10) 
 
.10)MiFre(mMiFre(m)MiFre(m)SV −−=-  (11) 
 
.25)MiFre(mMiFre(m)MiFre(m)LV −−=-  (12) 
 
如果 Xˆ (m)變動很大的話，Slope Constraint 
可以限制其變動弧度，關於 MS-entropy，
MiFre，SV-MiFre 與 LV-MiFre 的計算流程請
見圖三。 
 
三、類神經模糊網路(NFN) 
本計畫為了基於熵之背景雜訊預估技
術發展及其應用於語音訊號補償，將利用類
神經模糊網路自我學習能力。該網路架構如
圖四所示之五層架構，此架構具有自我建構
學習能力並能夠處理許多時序上的問題。其
各層功能介紹如下: 
 
z 第一層(Layer 1)： 
此層節點直接把輸入值傳送到下一層 
(1)
if u=  and  a = f            (13) 
從這個等式可以知道連結的權重值 (1)iw 等於
1 
z 第二層(Layer 2)： 
這層的每個節點相當於在第一層某一
個當輸入變數的語音標籤。因為使用高斯分
佈函數，所以這層執行 
(2) 2
2
( )i ij
ij
u m
f σ
−= −  and fa e=       (14) 
ijm 和 ijσ 分別為輸入變數 ix 的高斯分佈函
數中的均值與寬度，因此聯結權重 ( 2 )ijw 可被
當成 ijm 。 
 
z 第三層(Layer 3)： 
這層的聯結通常是預先配合模糊邏
輯，因此我們使用 AND 運算 
 (3)
1
p
i
i
f u
=
=∏  and a = f              (15) 
第三層節點的輸出表示對應模糊邏輯的激
發強度，而聯結權值 (3)iw 為 1。 
 
z 第四層(Layer 4)： 
此層連結執行模糊 OR 運算來求相同後
項的合： 
 (4)i
i
f u=∑  and min(1, )a f= .      (16) 
因此聯結的權重等於 1。 
 
z 第五層(Layer 5)： 
這層的每個節點相當於一個輸出變數
與去模糊器。如果 ijm 是第 i個輸出語音變數
中的第 j個部份的分布函數中心，那麼下面
的式子通常能模擬去模糊區域的中心。 
(5) (5)
ij ij
j
f m u=∑  and (5)
ij
j
fa
u
= ∑         (17) 
因此在第五層聯結的權重( (5)ijw )是 ijm 。 
 
四、基於熵值分析之適應性語音訊號補償 
我們採用 MS-entropy，MiFre，SV-MiFre
與 LV-MiFre 參數來當作類神經模糊網路的
輸入參數以估測噪音環境能量。因此，第一
層輸入層總共有四個節點。整體架構流程如
圖五所示。在輸入類神經模糊之前，須將四
 4
  [ ]∑
∑
=
=
−= K
n
K
n
nsns
ns
SNROutput
1
2
1
2
)(ˆ)(
)(
log10_   (27) 
其中 K 為音框長度，s(n)為乾淨的語音信
號，d(n)為我們加入的雜訊， sˆ (n)為補償過
後的語音信號。Input_SNR 為有參雜雜訊的
語音信號的 SNR 值。Ｏutput_SNR 為經過語
音信號補償過後的 SNR 值，其值越大，表示
補償效果越好。在我們的實驗中，語音信號
輸入之 Input_SNR 範圍位由 0db 至 15db，利
用式(27)來計算Ｏutput_SNR，實驗結果為
表一所示。跟 C. T. Lin[6]所提出的技術比
較，我們所提出的技術因為語音訊號區段中
之噪音估測值 modˆ ( )jwifiedD e 會利用熵分析多
頻帶上並隨著噪音變動而對應更新，所以語
音補償效果較佳。由此實驗結果可知在一個
會變動的背景環境噪音下，基於 MS-entropy
對語音訊號區段做噪音估測較沒有利用
MS-entropy 做噪音估測的 SNR 高。所以本計
劃所提出的基於熵之背景雜訊預估技術發
展及其應用於語音訊號補償具有很好的成
效。 
 
六、結論： 
本計劃執行中，我們已經完成(1)多頻
帶語音訊號分析及適應性選取頻帶。(2)藉
由熵(entropy)分析多頻帶上的能量。(3)提
出語音區段內雜訊能量估測之方法及參
數。(4)建立自我學習之類神經模糊網路架
構與程式撰寫。(5)以自我學習的類神經模
糊網路來決定不確定的法則與參數。(6)基
於多頻帶分析之基於熵之語音訊號補償程
序發展與建立。(7)測試並驗證所提語音訊
號補償技術之效果。  
我們提出了一基於熵之背景雜訊預估
技術發展及其應用於語音訊號補償，可以在
快速變動背景噪音等級情況下消除背景雜
訊之干擾。未來此語音訊號補償技術將可以
推廣應用於語音辨識系統或數位語音通訊
上。當此發展的語音訊號補償技術當作語音
訊號處理之前端處理時，將可以提高語音辨
識的正確率或數位語音通訊的音質。 
 
 
參考文獻 
[1] B. Widrow and S. D. Stearns, “Adaptive 
inference cancellation,” in Adaptive Signal 
Processing, pp. 302-367, Englewood Cliffs, 
NJ: Prentice-Hall, 1985. 
[2] W. G. Knecht, M. E. Schenkel and G. S. 
Moschytz, “Neural network filters for 
speech enhancement,” IEEE Trans. Speech 
and Audio Processing, vol. 3, pp. 433-438, 
Nov. 1995. 
[3] C. T. Lin and C. F. Juang, “An adaptive 
neural fuzzy filter and its applications,” 
IEEE Trans. System, Man and Cybernetics, 
vol. 27, pp. 635-656, Aug. 1997. 
[4] S. F. Boll, “Suppression of acoustic noise 
in speech using spectral subtraction,” IEEE 
Trans. Acoust., Speech, Signal Processing, 
vol. ASSP-27, pp. 113-120, Feb. 1979. 
[5] Sim, B. L., Tong, Y. C., Chang, J. S., and 
Tan, C. T., “A parametric formulation of 
the generalized spectral subtraction 
method,” J. IEEE Transactions on Speech 
and Audio Processing, Vol. 6, No. 4, pp. 
328-337,1998. 
[6] C. T. Lin, “Single-Channel Speech 
Enhancement in Variable Noise-Level 
Environments”, IEEE Trans. System, Man 
and Cybernetics, vol. 33, no. 1, pp. 
137-144, Jan. 2003. 
 
 
 
 6
 
0 1000 2000 3000 4000 5000 6000 7000 8000 9000
-1.5
-1
-0.5
0
0.5
1
1.5
x 104
Sample index
M
ag
ni
tu
de
 
(a) 
0 10 20 30 40 50 60 70
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Frame index
M
S
-e
nt
ro
py
-b
as
ed
 N
FN
 e
st
im
at
io
n
 
(b) 
圖六、(a)受背景雜訊干擾的語音波形圖。(b) 基於
熵值分析之類神經模糊網路背景噪音能量估測結果。 
 
y(n)
s(n)
Windowing
+ 
FFT
Magnitude
Averaging
Feature
Extraction
RTF-based RSONFIN Algorithm
Beginning Boundary:bb
Ending Boundary:eb
Magnitude
Phase
Half-Wave
Rectification
Reduce Noise
Residual
Additional Signal Attenuation
During Non-Speech
IFFT
Overlap
Add
^
Spectral
Subtraction
LV-MiFre
SV-MiFre
bb
eb
Neural Fuzzy Network
3-point Median Filter
MiFre
MS-entropy
MS-Entropy-Based NFN Estimation
圖七、基於熵值分析之適應性語音訊號補償流程圖。 
 
 
 
 
 
表一、實驗結果 
        
      Method
Noisy 
Environments 
Proposed 
MS-entropy-based 
NFN speech 
enhancement 
MiFre-based 
speech 
enhancement [6]
Type Input SNR Output SNR Output SNR 
車內變
動噪音
15 1.485 1.471 
10 1.334 1.312 
5 1.177 1.166 
0 1.171 1.154 
Average 1.292 1.276 
 
