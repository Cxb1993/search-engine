計算、網路內嵌系統等就可以利用FPGA的特
性達到更大的系統效能。 
然而，要管理這樣複雜的設計，就必須有
一套作業系統能不只管理軟體工作和資源，也
要同時管理硬體工作和相關的FPGA資源。這
個計劃為一個遠程目標，用以設計並且實作出
一個支援可重組系統的作業系統。我們在計畫
中已探討的研究議題包含以下所列。第一，一
個OS4RS 核心提供的基本服務以及其實作。
第二，一個OS4RS 架構的必備元件以及其實
作 。 第 三 ， 一 個 OS4RS 的 基 本 抽 象 化
(abstractions)以及其設計。第四，OS4RS 的效
能評估及改進的平台。 
為因應以上的議題，我們所提出的OS4RS 
提供基本的硬體管理服務，例如硬體工作的載
入、環境儲存、分割、排程及擺置。OS4RS 的
架構包含一個載入器、分割器、排程器及擺置
器。作業系統支援的抽象化將包含共用硬體工
作介面、軟硬體溝通介面及硬體工作的重置
性 。 OS4RS 的效能評估包含空間分片
(fragmented)面積、排成產量、工作反應時間及
工作可攜性。 
 
三、 研究方法及成果 
在一個嵌入式系統中通常同時存在軟體
功能元件和硬體功能元件。用軟體來實現功能
通常有較佳的彈性，但是執行效能則較差。而
用硬體來實現功能在執行效能會比軟體來的
好，可是成本也相對的提高許多且系統會比較
缺乏彈性。為了要在系統效能與彈性之間取得
一個平衡，動態部分重組式系統變成了一個可
行的方法，可以同時有軟體程序執行在微處理
器上及硬體模組執行在 FPGA 裝置上，並且工
作可以從軟體切換到硬體或硬體切換到軟
體。在這樣的系統中要管理所有的資源是相當
複雜的，所以我們就需要一個針對動態部分重
組式系統的作業系統來管理這些軟硬體工作
與資源，包括執行工作切割、排程、工作溝通、
及空間配置。我們提出了一套針對即時可重置
工作的排程與空間配置演算法 [1]，使得這些
工作可以盡量滿足各自的時間限制以及讓裝
置上的碎裂變得更少；另一方面我們還提出了
一套偷取工作閒置時間的演算法 Slack Time 
Stealing (STS) [1]，使用這套演算法可以讓系
統中的硬體資源使用率增加大約 15％。此外，
考慮到低功率的議題，我們也提出一個在動態
部分重組系統的低功率軟硬體排程演算法，該
成果也已經發表於國際會議 [2, 3]。 
針對FPGA的空間配置的問題，就目前相
關研究，許多的演算法只有針對一種目標做配
置空間的管理，例如最小化繞線資源
(minimization of routing resources, MR)、最小
化碎裂空間(minimization of fragmentation, MF)
等。這些目標大多會相互衝突，如硬體工作之
間的溝通會被在執行的硬體工作所影響，最小
化繞線資源的配置並沒有考慮到空間碎裂的
問題，最小化碎裂空間不會考慮到繞線資源的
使用等。因此，我們提出一個多重目標的配置
方 法 Multi-Objective Hardware Placement 
(MOHP) [4]，針對不同的配置方法之間的衝突
提出一些經驗規則。當工作被拒絕率 (task 
rejection rate)相同時，MOHP的總繞線資源花
費會接近MR，甚至因為工作的進入的順序，
有時會小於MR。對總碎裂而言，會比MR要
好，較接近MF。利用真實例子，再加上我們
所 定 義 的 最 低 可 以 被 浪 費 的 時 間 ，
   )1B
D(2 3 c
f
ii B××+×= ωδν ( iδ 是工作的燒
錄時間， 是最小的資料儲存的大小， 是
bus bandwidth，而 是bus frequency)，發現
MF是較少被應用的函式，因真實例子的規畫
時間很大，以至於工作的Slack Time幾乎都小
於
cD ωB
fB
iν 。 
在系統架構部分，我們提出一個新的可重
組式模組序列器設計－Reconfigurable Module 
Sequencer (RMS) [5, 6]。如圖 1 所示，其中動
態部分為動態部分重組系統，一般最常採用的
包含兩種溝通架構：  Processor-controlled 
network architecture (PNA) 及
而為了軟硬體系統資源的有效使用以達
到系統效率的提升，我們也提出一個工作切換
以及重新配置的機制 [9]，用以解決切換點、
溝通的維護以及資料的傳送等三項議題。當一
個工作在接獲切換或重新配置的要求，在到達
可切換點時，會去整理並且傳送所需的資料並
告知系統其已準備好被切換。而未完成的資料
以及工作狀態，在工作切換的機制下必需傳送
給中介者儲存到記憶體，在工作重新配置的機
制下必需傳送給取代原有工作的新工作。考慮
到有限的 FPGA 資源，並非所有的工作都可以
用硬體實作，就實作的結果來看，由軟體切換
到硬體會有 45%改善，而由硬體切到軟體會有
37%改善，顯示出具備重新置換的系統效能明
顯會比單純由軟體完成來得比較好，更清楚說
明工作切換和重新置換的機制能有效地增進
系統效能。 
 
四、 結論與討論 
本研究計畫長期目標是要建構一套針對
動態部分重組架構的作業系統[10-12]，我們已
提出了軟硬體排程與重組空間配置方法，一個
新的溝通介面的設計，並且提供軟硬體可動態
切換機制，都能有效地提升系統的效能。 
本研究群的相關研究結果，由 94 年開始，
已發表過會議論文 11 篇，期刊 2 篇。目前有
一篇會議論文和一篇期刊論文也已投稿。 
 
五、參考文獻 
1. C.-C. Chiang. “Hardware/Software Real-Time 
Relocatable Task Scheduling and Placement in 
Dynamically Partial Reconfigurable Systems.” 
Master’s thesis, Department of Computer Science and 
Information Engineering, National Chung Cheng 
University, Taiwan, ROC., June 2007. 
2. P.-A. Hsiung and C.-W. Liu, "Exploiting Hardware 
and Software Low Power Techniques for Energy 
Efficient Co-scheduling in Dynamically 
Reconfigurable Systems," Proceedings of the 17th 
International Conference on Field Programmable 
Logic and Applications (FPL'2007, Amsterdam, 
Netherlands), pp. 165-170, IEEE Press, August 2007. 
3. P.-A. Hsiung and C.-W. Liu, "Energy Efficient 
Hardware-Software Co-scheduling in Dynamically 
Reconfigurable Systems," Proceedings of the 
International Conference on Hardware/Software 
Codesign and System Synthesis (CODES+ISSS'2007, 
Austria), pp. 87-92, ACM Press, September 2007. 
4. H.-W. Liao. “Multi-Objective Placement of 
Reconfigurable Hardware Tasks in Real-Time 
Systems.” Master’s thesis, Department of Computer 
Science and Information Engineering, National Chung 
Cheng University, Taiwan, ROC., June 2007. 
5. C.-C. Hung and P.-A. Hsiung, "Reconfigurable 
Hardware Module Sequencer for Dynamically 
Partially Reconfigurable Systems," Proceedings of the 
VLSI Design / CAD Symposium, August 2007. 
6. C.-C. Hung. “Reconfigurable Hardware Module 
Sequencer for Dynamically Partially Reconfigurable 
Systems.” Master’s thesis, Department of Computer 
Science and Information Engineering, National Chung 
Cheng University, Taiwan, ROC., June 2007. 
7. C.-H. Huang, K.-J. Shih, C.-S. Lin, S.-S. Chang, and 
P.-A. Hsiung, "Dynamically Swappable Hardware 
Design in Partially Reconfigurable Systems," 
Proceedings of the IEEE International Symposium on 
Circuits and Systems (ISCAS), New Orleans, USA, 
May 2007.  
8. C.-H. Huang, S.-S. Chang, and P.-A. Hsiung, 
"Generic Wrapper Design for Dynamic Swappable 
Hardware IP in Partially Reconfigurable Systems," 
International Journal of Electrical Engineering, Vol. 
14, No. 3, pp. 229-238, June 2007. 
9. H.-Y. Sun. “Dynamic Hardware-Software Task 
Switching and Relocation for Reconfigurable 
Systems ” Master’s thesis, Department of Computer 
Science and Information Engineering, National Chung 
Cheng University, Taiwan, ROC., June 2007. 
10. P.-A. Hsiung, C.-H. Huang, and C.-F. Liao, "Perfecto: 
A SystemC-based Performance Evaluation 
Framework for Dynamically Partially Reconfigurable 
Systems," Proceedings of the 16th IEEE International 
Conference on Field Programmable Logic and 
Applications, (FPL'2006, Madrid, Spain), pp. 190-198, 
IEEE CS Press, August 2006. 
11. P.-A. Hsiung, C.-H. Huang, and Y.-H. Chen, 
"Hardware Task Scheduling and Placement in 
Operating Systems for Dynamically Reconfigurable 
SoC," Journal of Embedded Computing, to appear, 
IOS Press, The Netherlands, 2007. 
12. C.-H. Tseng and P.-A. Hsiung, "UML-Based Design 
Flow and Partitioning Methodology for Dynamically 
Reconfigurable Computing Systems," Proceedings of 
the 2005 IFIP International Conference on Embedded 
and Ubiquitous Computing (EUC'2005, Nagasaki, 
Japan), LNCS, Vol. 3824, pp. 479-488, Springer 
Verlag, December 2005. 
EXPLOITING HARDWARE AND SOFTWARE LOW POWER TECHNIQUES FOR ENERGY
EFFICIENT CO-SCHEDULING IN DYNAMICALLY RECONFIGURABLE SYSTEMS
Pao-Ann Hsiung† and Chih-Wen Liu
Department of Computer Science and Information Engineering,
National Chung Cheng University, Chiayi, Taiwan 621, ROC.
†Email: hpa@computer.org
ABSTRACT
Currently, the hardware and the software tasks in reconﬁg-
urable systems are either scheduled separately at run time
or co-scheduled statically, which results in high power con-
sumption and low performance. This work proposes run-
time co-scheduling of hardware and software tasks by us-
ing the slack time, which is introduced due to reusing hard-
ware task conﬁgurations, for dynamically scaling the pro-
cessor voltage such that preceding software tasks consume
lesser power. At the same time, the reuse of hardware task
conﬁgurations also result in lower power consumption and
higher performance due to fewer number of reconﬁgura-
tions. The combined effects of hardware conﬁguration reuse
and software dynamic voltage scaling result in schedules
with a lower power consumption and higher performance
than that obtained through individual techniques applied to
hardware and software separately. The proposed method
was implemented in the SystemC-based Perfecto simula-
tion environment for dynamically reconﬁgurable hardware
software systems and TGFF was used for generating ran-
dom task sets as input for Perfecto. We performed extensive
experiments whose results show that irrespective of differ-
ent slack ratios or hardware partitions, the schedules gener-
ated by our proposed method are more energy efﬁcient than
methods that either do not apply any runtime techniques or
only apply hardware conﬁguration prefetch and reuse.
1. INTRODUCTION
Low power design has permeated each and every level of
a system design, including the hardware circuits, software
applications, operating systems, compilers, and architecture
designs. However, often we observe that the low power in-
frastructure is not used optimally in a system design because
there is little integration between the different low power
schemes embedded in each system component or level. For
example in reconﬁgurable systems, a single reconﬁguration
requires as much as 450mW , thus conﬁguration reuse has
been proposed as a low power design technique [1]; at the
same time, dynamic voltage scaling (DVS) in a processor al-
lows the software to execute with a lower power. Under cer-
tain circumstances, when these hardware speciﬁc and soft-
ware speciﬁc low power design techniques are both made
available in a system, the result could counter intuitively re-
quire more power, instead of lesser power. The reason is
because the low power techniques might affect each other
resulting in either an increase in the number of reconﬁgu-
rations or a decrease in the possibility of dynamically low-
ering the processor voltage. We propose to integrate these
two techniques such that they work together collaboratively,
instead of contradictorily.
As a motivating example, consider two tasks with task
graphs as shown in Fig. 1, where task A consists of four se-
quential functions f0, f1, f2, f3 and task B consists of func-
tions f1, f4, f2, f5. Each function represents a basic unit
of execution in a task and is also an indivisible unit for parti-
tioning into hardware or software implementations. A func-
tion has several attributes as shown in Fig. 1. Without the
proposed schedulingmethod, the resulting schedule takes 51
ms as shown in Fig. 2, while using our method, the schedule
takes only 45 ms as shown in Fig. 3. Not only is the total
time reduced, but the total energy consumption is also re-
duced from 50.2 mJ to 46.3 mJ, where the reconﬁguration
power is 450 mW, the execution power of reconﬁgurable
logic is 1000mW, and the processor power is 5.3W. Further,
the number of reconﬁguration also dropped from 7 to 5. In
this example, we can see that, using our method, the con-
ﬁgurations of the two hardware functions f1 and f2, which
are common to both tasks, can be reused or shared between
the tasks. Thus, we eliminate two reconﬁgurations, which
also reduced the total time and energy. Further in this ex-
ample, we use the slack time generated between the func-
tions f0 and f1, due to conﬁguration reuse of f1, for dynam-
ically scaling down the processor voltage, so that the soft-
ware function f0 executes under a lower power consumption
and takes up the slack time.
The rest of this article is organized as follows. Section
2 gives some related previous work. Section 3 describes the
systemmodel and related terminologies. Section 4 describes
1-4244-1060-6/07/$25.00 ©2007 IEEE. 165
3. SYSTEM MODEL AND NOTATIONS
A hardware-software dynamically reconﬁgurable system is
modeled by a set of concurrent communicating tasks. A task
is speciﬁed by a 4-tuple Ti = (Ai, Di, Pi, Gi), where Ai is
the arrival time, Di is the deadline, Pi is the period, and Gi
is a function graph. A function graph is a directed acyclic
graph (V,E), where each node in V represents a partitioned
function and an edge in E represents a precedence relation
between two functions. A function is characterized by 4 at-
tributes (SEi, HEi, HCi, HSi), where SEi and HEi are
the worst case execution times of a function implemented in
software and hardware, respectively, HCi and HSi are the
conﬁguration time and space required by its hardware imple-
mentation, respectively. A partitioned function is one with
its implementation in hardware or software given a priori.
The computing resources for running the above system
is a DVS capable microprocessor and a reconﬁgurable logic
called FPGA. The microprocessor has several ﬁxed volt-
age levels and the worst case execution time of a function is
given in terms of its highest voltage level. For the FPGA,
a 1-dimensional model is assumed, hence the conﬁguration
space for a function is measured in terms of the number of
columns, where a column is a basic unit of reconﬁguration.
A typical example is Xilinx Virtex Pro II. The FPGA has a
ﬁxed number of columns.
Our target problem is formulated as follows. Given a set
of tasks and the computing resources as described above,
the problem is to decide an execution order for the func-
tions assigned to the processor and the FPGA such that the
schedule satisﬁes all task requirements, computing resource
constraints, and consumes the least amount of total energy.
Deadline violations are allowed within some threshold.
4. ENERGY EFFICIENT CO-SCHEDULING
A two-phase scheduling method is proposed for solving the
target problem. At the design time phase, some calculations
are made so as to alleviate the need for complex computa-
tions at runtime.
4.1. Design Time Phase
For each hardware function H that is common to two or
more tasks, we ﬁrst search for all the instances so that they
can be grouped together to reduce the number of reconﬁgu-
rations at runtime. For each H , a preceding software func-
tion S, if any, is selected as the leading software function
such that there is no other software function along the path
from S to H and S has the longest execution time among all
candidates. The leading software function is the target for
applying DVS. Each path from a leading software function
to a common hardware function is called a key path. Key
paths are used to construct a delay-time table that records the
time intervals in which two instances of a common hardware
function in two different tasks might overlap in execution if
their leading software functions terminate execution at the
same time. It is formally deﬁned as follows. Given two key
paths Pi and Pj , the delay-time table is constructed as an
n × n matrix Δ as follows, where n is the total number of
key paths, H is the common hardware function, and Si(H)
and Ci(H) are the start and completion times of H in Pi,
respectively, assuming both leading software functions ter-
minate at time 0.
Δ(i, j) =
⎧⎨
⎩
[a, b], a = min{0,Si(H)−Cj(H)}
b = Ci(H)− Sj(H) ≥ 0
undeﬁned, if Ci(H)− Sj(H) < 0
(1)
The time slack in a task Ti is computed as ζ(Ti) =
Di −
∑
k Ek, where Ek is in the worst case execution time
of a partitioned function Fk in a critical path of Ti. A crit-
ical path is one with the longest total execution time. The
time slack ζ(Ti) is evenly shared by the leading software
functions in the task, where each function S is allocated
ζS(Ti) = ζ(Ti)/|{S}| slack time, which is also the static
priority of a task.
To illustrate the proposed scheduling phases, we use an
example system consisting of 3 tasks, whose task graphs are
shown in Fig. 4. The function associated with a node TXi
is given inside the node as Fj . Functions F1, F7 and F10
are software, while the rest are all hardware. The software
functions are usually the control programs or drivers, while
the hardware functions could be any IP such as (I)DCT, ma-
trix multiplier, FFT, motion estimator, that is, circuit designs
that could be used across different applications. The arrival
times for tasksA,B,C are, respectively, 0, 2600, 5000, their
priorities are 2, 3, 1, where a higher value represents higher
priority, and their deadlines are 6500, 6600, 5500. The func-
tion attributes are as shown in Table 1.
In this example, F6 and F9 are two common hardware
functions, and F1, F7, and F10 are leading software func-
tions. As shown in Table 2, there are 5 key paths from the 3
Task B
TB1
F6F6
F8
F9F9
F7
TB2
TB3
TB4
Task C
TC1F10
F9F9
F6F6
TC3TC2
Task A
F3
F1
F4F2
F5
F6F6
TA3
TA2
TA1
TA4
TA5
TA6
Fig. 4. An Example System with 3 Tasks
167
TA1(F1) TB1(F7)
TA3(F3)
TA5(F5)
TA6(F6)TB2(F6)
TA6(F6)TB2(F6)
TC1(F10)
TC2(F6)
TC2(F6)
TB3(F8)
For key paths P3 and P5:
Original finish time of TC1 is at time 
8600.
8600 – 6200 = 2400  [1800,3000],
where 6200=C3(TB1)
Therefore, the execution of TB1 is
extended from 2400 to 
2400+(3000-2400) = 3000.
TA2(F2)
TB4(F9)
TC3(F9)
For key paths P2 and P4:
Original finish time of TC1 of is 
at time 8600. 
8600 – 6200 = 2400 >1200, 
where 6200=C2(TB1)
Therefore, this does not affect 
the  execution time of TC1.
Processor
Column1
Column2
Column3
Column4
0           2000          4000          6000         8000       10000        (time)
One column of 
reconfiguration is saved.
For key paths P1 and P4:
Original finish time of TC1 of is at 
time 8600. 
8600 – 2600 = 3000 >1200, where 
2600=C1(TA1)
Therefore, this does not affect 
execution time of TC1.
TA4(F4)
TA2(F2)
Fig. 5. Scheduling Results for Example
Table 3. Scheduling Results Comparison
M1 M2 Ours I1 (%) I2 (%)
TT 12100 9700 10400 16.0 −7.2
TE 96.76 96.49 73.27 24.3 24.1
CE 3.51 3.24 2.16 38.5 33.3
RN 2/3 1 1 33.3 0.0
Ii: Improvement over Mi, TT : total execution time (μs),
TE: energy consumption (mJ), CE: conﬁguration energy (mJ),
RN : % of tasks with deadlines satisﬁed
apply any acceleration technique, while method M2 applies
conﬁguration prefetch and reuse, but without DVS. The
comparisons are shown in Table 3, where we can see that
the proposed method outperforms the other two methods.
Compared to the bare method M1, the proposed method not
only consumes lesser amounts of total energy and total con-
ﬁguration energy by 24.23% and 38.5%, respectively, and
allows 33.3% more task deadlines to be satisﬁed, but also
the total execution time is reduced by 16%. Compared to
method M2, the proposed method similarly satisﬁes all task
deadlines, but it requires more execution time of about 7.2%
to save 24.1% total energy and 33.3% conﬁguration energy.
5. EXPERIMENTS
The proposed scheduling method was implemented in Per-
fecto [12], a SystemC-based performance evaluation frame-
work for dynamically reconﬁgurable systems. We had to
make several changes to Perfecto, including the hardware
and software power modeling for reconﬁgurable systems,
the random partitioning of functions into hardware and soft-
ware, the newly proposed scheduler algorithm, and the new
task model. Several experiments were conducted on a Linux
machine with a 2.4 GHz Pentium 4 CPU and 1 GB RAM.
Table 4. Varying Slack Ratio
SR M1 M2 Ours I1 I2
(%) (%)
0.67 TT 557496 500123 518974 5.4 -3.7
TE 6207 6100 5278 15.0 13.5
CE 317 209 142 58.0 32.2
RN 86 93 90 4.3 -4.4
0.75 TT 564571 455308 498562 19.4 -4.9
TE 6286 6186 5127 18.4 17.1
CE 351 250 162 54.7 35.1
RN 88 95 93 5.3 -1.9
0.80 TT 554283 439614 486213 12.3 -10.6
TE 6148 6026 5075 17.8 15.8
CE 324 203 122 62.5 40.0
RN 89 96 94 4.9 -1.8
SR: slack ratio, Ii: Improvement over Mi
The target platform is Xilinx ML310 with a Virtex II Pro
XC2VP30 chip, two PowerPC 405 cores, and 256 MB DDR
RAM. We compared our work with two conventional meth-
ods, one without any acceleration technique and the other
with only conﬁguration prefetch and reuse, but without DVS.
Four metrics were used including total execution time, to-
tal energy consumption, conﬁguration energy consumption,
and the percentage of tasks with deadlines satisﬁed. TGFF
[13] was used to generate random task sets from user-given
templates. Each task set contained 25 to 30 function graphs
with an average of 20 functions per graph. Partitioning re-
sults and task arrival times were randomly generated. The
varied parameters included the ratio of task slack time to
task deadline (0.67, 0.75, 0.8) and the number of common
hardware functions (8, 16, 20). We experimented with 50
task sets for each parameter and took the overall averages.
The experimental results are given in Tables 4 and 5, re-
spectively, for each of the varied parameters including slack
ratio and common hardware functions. We can make the fol-
lowing observations from the experiments. When compared
to the bare scheduling approach (method M1), our method
shows improvements in all the 4 metrics, namely total exe-
cution time (TT) in μs, total execution energy (TE) in mJ, to-
tal conﬁguration energy (CE) in mJ, and percentage of tasks
with deadlines satisﬁed (RN). When compared to method
M2, which integrates conﬁguration prefetch and reuse, but
not DVS, our method also shows as much as 17% decrease
in TE and 40% decrease in CE, at the expense of at most
10.6% increase in TT and 4.4% increase in RN. With an
increase either in slack ratio or in the number of common
hardware functions, our method generates schedules with
signiﬁcant decrease in both total execution and conﬁgura-
tion energies, which shows the scalability of our method. At
the same time, the reduction in the percentage of tasks with
deadlines satisﬁed is maintained within a limit of 1.8%.
169
