 2 
網格計算環境下有效的資源管理(I) 
 
計畫主持人：王淑卿 
共同主持人：嚴國慶 
計畫參與人員：楊士慶、鄒永峰、陳秀芳、董育萍 
 
摘 要 
由於科技進步與網路普及，使得網格計算逐漸成為分散式應用之主流。網格計算是藉由結合
網路上閒置的電腦形成強大的計算能力，以進行分散式應用，如此不僅可提供大量的運算資源，
協助無法在單一機器上解決的複雜計算問題，更可達到有效資源之整合與共享。但由於網格計算
之資源是由閒置節點所組成，節點提供資源的有效性會隨著時間而改變，即某節點目前也許是閒
置的，極有可能在下一秒鐘因進入忙碌狀態，而無法繼續提供資源，因此在選擇節點分配工作時，
如何選擇一有效且能長期提供充足資源之節點協助工作執行，是一值得深入研究之議題。為解決
此問題，本研究提出整合靜態及動態負載平衡技術之混合式負載平衡策略，先利用靜態負載平衡
策略選擇出有效且適合之節點集，以降低將工作分配給無效節點而發生負載失衡之機率。而在節
點可能無法繼續提供資源時則啟用動態負載平衡策略，可在短時間內判斷節點是否失效，當確認
節點失效時，將在短時間內找尋新的遞補節點，以維持系統之執行效能。 
關鍵字：網格計算、工作排程、負載平衡、分散式計算 
 
Abstract 
In recent years, network bandwidth and quality has been drastically improved, even much faster 
than the enhancement of computer performance. The various communication and computing tasks in the 
fields such as telecommunication, multimedia, information technology, and construction simulation, can 
be integrated and applied in a distributed computing environment in nowadays. However, as the 
demands of many researches for computing resources gradually grow, Grid Computing integrated with a 
distributed computing environment and the Internet (network) has gained more attention. The so-called 
Grid Computing is to utilize the idle computing resources (nodes) on the network to facilitate the 
execution of complicated tasks that require large-scale computing. In other words, the composition of 
Grid resources is dynamic and varies with time. Thus, when selecting nodes for executing a task, the 
dynamic of the nodes in the Grid must be considered, and to exploit the effectiveness of the resources, 
they have to be properly selected according to the properties of the task. This study proposed a hybrid 
load balancing policy which integrated static and dynamic load balancing technologies to assist in the 
selection for effective nodes. In addition, if any selected node can no longer provide resources, it can be 
promptly identified and replaced with a substitutive node to maintain the execution performance and the 
load balancing of the system.  
Keyword: Grid computing, Distributed computing, Load balancing 
 
1.  Research Motivation and Background 
With the advancement and development of various technologies, the computing problems we need 
to solve have become more complicated and larger in size. However, due to the high cost of super 
computers, they cannot be extensively utilized. Thus, people have to resort to distributed systems to 
resolve the problem of large-scale computing. There are several options for establishing distributed 
systems, and Cluster System and Grid System [5] are the most common ones for distributed applications. 
Cluster System combines several personal computers or workstations to conduct distributed applications 
through a local network in a fixed area. Its flaw is that the use of Cluster System has to be limited to a 
 4 
related to average operation, operation cycle, and etc, and according to these data, tasks are distributed 
through mathematic formulas or other adjustment methods, so that every node in the distributed system 
can process the assigned tasks until completed. The merit of this method is that system information is 
not required to be collected at all time, and through a simple process, the system can run with simple 
analyses. However, some of the nodes have low utilization rates. Due to the fact that it does not 
dynamically adjust with the system information, there is a certain degree of burden on system 
performance [4,8]. The common static load balancing policies are Speed-Weighted Random Splitting 
Policy and Load-Dependents Static Policy [2,4]. 
 
2.2 Dynamic Load Balancing Policies 
Dynamic load balancing policies refer to the current state of the system or the most recent state at 
the system time, to decide how to assign tasks to each node in a distributed system.  If any node in the 
system is over-loaded, the over-loading task will be transferred to other nodes and processed, in order to 
achieve the goal of a dynamic balance [4]. However, the migration of tasks will incur extra overhead to 
the system [4]. It is because the system has to reserve some resources for collecting and maintaining the 
information of system states.  If this overhead can be controlled and limited to a certain acceptable 
range, in most conditions, dynamic load balancing polices outperform than static load balancing policies 
[8]. The general dynamic load balancing policies include Shortest Queue Policy, Never Queue Policy, 
Maximum Throughput Policy, and Adaptive Separable Policy [8]. 
Each of the static and dynamic load balancing polices has its merits and flaws. Static load balancing 
policies do not require constant collection of system status and only analyze with available related 
information. Thus, no extra overhead will be caused. Relatively speaking, without continuous gathering 
of related information and prompt adjustment to the change of system environments, they are unable to 
properly adjust the loading of each node. In addition, as dynamic load balancing policies monitor system 
states in real time, they can dynamically adjust task assignment according to the loading of each node. 
However, continuous monitoring will cause extra overhead to the system [2,4,8]. Related researches 
have shown [10] that before the execution of tasks, if the required process time can be calculated in 
advance, static load balancing policies may have better effects, because the algorithms adopted by static 
load balancing policies are simpler and will not cause extra burden to the system. If there are frequent 
variations in load conditions of the system, dynamic load balancing policies are more suitable than static 
load balancing policies. In addition, the nodes in a Grid environment are composed of idle nodes, so the 
resource that each node can provide is very dynamic and not resolvable with simply static load balancing 
policies or dynamic load balancing policies. Therefore, this study proposed a hybrid load balancing 
policy that adopts dynamic load balancing policies to avoid the reduction of system performance due to 
the variation of nodes. Further details will be introduced in the next section. 
 
3.  The Design of System Environments 
This section will explain the structure of the proposed system and how to utilize load management 
mechanisms to achieve optimal performance of the system. The structure of the proposed system mainly 
consists of a dispatcher that manages system related tasks and nodes that join the Grid and provide 
resources  
A dispatcher’s role in the system is the management of tasks, including maintenance of the load 
balancing, monitor on the status of each node in the Grid, selection for nodes for task execution, and 
assignment and adjustment of tasks for each node. To make a dispatcher accomplish its mission in the 
most efficient way, a dispatcher has the mechanisms of an agent, node selection, and calculation of 
effective node. 
In this system environment, an agent mainly collects related information of each node participating 
in this Grid, such as CPU utilization, remaining CPU capability, remaining memory, the execution 
 6 
of executing a task is made, the task will be assigned to an appropriate node to achieve the goal of load 
balancing. In addition, in the stage dynamic load balancing, the system will be adjusted dynamically 
according to the load balancing until a balance is reached. 
 
4.1 The Static Load balancing Stage 
Due to the fact that Grid resources are provided by idle nodes, when a request for executing a task 
is proposed, the task has to be divided into several subtasks by logic size.  Based on the proposed task, 
a table of effective nodes for the task will be built, so that the needed nodes can be selected from the 
table of effective nodes. Suppose in executing a certain task and totally k nodes are required to provide 
assistance, the top k nodes with the highest value will be selected from the table of effective nodes to 
assist the execution of the task. If the total amount of nodes in the table is smaller than the required 
amount k, a portion of subtasks will be first assigned to effective nodes and the remaining subtasks will 
be processed when new nodes are incorporated in the table of effective nodes. 
 
4.2 The Dynamic Load balancing Stage 
In a Grid environment, the effectiveness of nodes may vary with time. Thus, the assignment of tasks 
has to be dynamically adjusted in accordance with the variation of node status. The variation of the node 
status can be identified in two conditions; firstly, when the dispatcher receives the message that a certain 
node can no longer provide resources, and secondly, when the execution of a certain node exceeds the 
expected time. When any of the above situations occurs and is detected by the dispatcher, the dispatcher 
will launch the agent mechanism to collect the related data of all the nodes in the table of effective nodes 
and compare the collected data with historic ones, in order to confirm if the node is still effective.  If 
the node remains effective, the distribution of the task will not be re-adjusted, but the time required for 
the node’s execution of the task will be estimated again. If the node is confirmed ineffective, a node with 
the highest value will be selected from the waiting aggregate, and the existing task will be transferred 
from the ineffective node to the new effective one. 
 
5.  Simulation Experiment 
In this section, simulation experiments were conducted according to the method proposed in the last 
section. Based on the demands for computing resource for the execution of the task and transmission rate, 
simulation tests were conducted on the four different conditions and compared to other node-selection 
mechanisms in terms of performance, in order to verify if the mechanism proposed by this study had a 
better performance. 
 
5.1 Experiment Design 
In this subsection, experiment verification was conducted on the nodes selected to execute tasks by 
the value function of this study. The value of each node is estimated with the value function and serves 
as the basis for task assignment. This method first divides the task into several independent subtasks and 
takes minimum resource demand of each node as the threshold value. After the value of each node is 
estimated with the value function, the nodes for the execution of the task are selected by the order of 
their values. In the value function, decision variables can be given a different setting according to the 
factor focused in the actual application. In the experiment, the available CPU capacity, size of available 
memory, transmission rate, and the past completion rate were the four factors regarded as the threshold 
for the value function to select nodes and the decision variables for estimating node values. 
The Grid environment is composed of heterogeneous systems, so the structures of each system may 
greatly differ. In other words, the computing capability provided by the CPU and the available size of 
memory are different. In addition, Grid Computing utilizes idle resources of each node, so the available 
resource of each node may vary in a busy condition. From the perspective of task completion time, the 
 8 
were tested. To simulate the heterogeneity of nodes in the Grid environments, the CPU capability, 
memory size, CPU usage and memory usage, past task completion rate of each node were generated at 
random, and the effective time of each node was generated at random and then multiplied by the past 
task completion rate, so as to reflect the relation between the past task completion rate and effective time 
of the node.  
Because the composition of Grid resources is dynamic and varies with time, the state of node is 
difficult to forecast. However, in our experiment, the effective time of each node is generated randomly. 
According to the computing resource and amount of data transmission required to execute the task, the 
experiment was conducted in the following four conditions. 
Condition 1: Demand for computing resource is large (25,000GHz), and amount of data 
transmission is small (100MB) 
Condition 2: Demand for computing resource is small (1,000GHz), and amount of data transmission 
is large (300,000MB) 
Condition 3: Demand for computing resource is large (25,000GHz), and amount of data 
transmission is large (300,000MB) 
Condition 4: Demand for computing resource is small (1,000GHz), and amount of data transmission 
is small (100MB) 
In the experiment, the four different task scheduling algorithms, including First Come First Served 
(FCFS), Later In First Out (LIFO), available CPU usage (CPU-based), and value function (VF) was 
employed to select 10 nodes for task assignment.  The task was divided into 10 subtasks and distributed 
to 10 nodes. If any of the nodes could not complete the assigned task, new nodes would be selected and 
substituted for according to various task scheduling algorithms, and the task would be re-distributed and 
executed. 
 
5.2 Experiment Results and Analyses 
Based on the above-mentioned four conditions, this section details the simulation experiment as 
well as the analyses and comparison of the task completion time and times of task re-distribution. To 
verify that the nodes selected by value function performed better than those by other task scheduling 
methods did, value functions of different sets of weight were evaluated, and each set was simulated 100 
times, so as to obtain the objective data.  Under the value functions of different weights, the one with 
the shortest completion time was listed as the best case, the longest as the worst. The best case and the 
worst one were compared to the other different scheduling algorithms in terms of completion time and 
times of re-distribution. In addition, the task completion time included the duration that the task was 
transmitted to the node and the duration that the task was executed. 
 
1. Condition 1 (Demand for computing resource is large, and amount of data transmission is small) 
When demand for computing resource is large and amount of data transmission is small, the 
available CPU capacity memory usage provided by the node will obviously affect the completion of the 
task, and the impact transmission rate of the node on the task completion time is not significant. The 
experiment results are shown from Figures 1 to 4. As FCFS(     ) and LIFO(     ) selected the nodes 
by the order of node’s arrival, and the related factors of the nodes are not considered, the task 
re-distribution and re-execution constantly occur because the selected nodes often cannot complete the 
task in effective time, thus prolonging the task completion time (as shown in Figure 2). In addition, 
CPU-based (     ) selects nodes by the available CPU capacity, and because the selected nodes can 
provide richer CPU resources, the completion time of each selected node is relatively shorter. In other 
words, the task could be completed in the effective time, so the times of task re-distribution are fewer 
than those in the cases of FCFS and LIFO, and so is the task completion time. In the aspect of value 
functions (VF,     ), due to the considerations for the various factors of the nodes (such as the 
 10 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2 Demand for computing resource is large and amount of data transmission is small 
the task completion time in the best case. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3 Demand for computing resource is large and amount of data transmission is small 
the time of task re-distribution in the worst case 
0 
5000 
10000 
15000 
20000 
25000 
30000 
100 200 300 400 500 600 700 800 900 1000 
Number of nodes 
Co
m
pl
et
io
n
 
tim
e 
(m
in
i s
ec
o
n
d) 
VF FCFS LIFO CPU-based 
0 
5000 
10000 
15000 
20000 
25000 
30000 
100 200 300 400 500 600 700 800 900 1000 
Number of nodes 
Ti
m
es
 
o
f t
as
k 
re
-
di
st
rib
u
tio
n
 
(ti
m
es
) 
VF FCFS LIFO CPU-based 
 12 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5 Demand for computing resource is small and amount of data transmission is large 
the time of task re-distribution in the best case 
 
 
 
 
 
 
 
圖 6 工作執行量小且傳輸量大最佳情況之完成時間 
 
 
 
 
 
 
 
Figure 6 Demand for computing resource is small and amount of data transmission is large 
the task completion time in the best case. 
0
5
10
15
20
25
100 200 300 400 500 600 700 800 900 1000
Number of nodes
Ti
m
es
 
o
f t
as
k 
re
-
di
st
rib
u
tio
n
(ti
m
es
)
VF FCFS LIFO CPU-based
0
5000
10000
15000
20000
25000
30000
35000
40000
100 200 300 400 500 600 700 800 900 1000
Number of nodes
Co
m
pl
et
io
n
 
tim
e(m
in
i s
ec
o
n
d)
VF FCFS LIFO CPU-based
 14 
 
 
 
 
 
 
 
 
 
 
圖 9 工作量大且資料傳輸量大最佳情況之重新分配工作的次數 
 
 
 
 
Figure 9 Demand for computing resource is large and amount of data transmission is large 
the time of task re-distribution in the best case 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 10 Demand for computing resource is large and amount of data transmission is large 
the task completion time in the best case. 
 
0
5
10
15
20
25
30
100 200 300 400 500 600 700 800 900 1000
Number of nodes
Ti
m
es
 
o
f t
as
k 
re
-
di
st
rib
u
tio
n
(ti
m
es
)
VF FCFS LIFO CPU-based
0
5000
10000
15000
20000
25000
30000
35000
40000
45000
100 200 300 400 500 600 700 800 900 1000
Number of nodes
Co
m
pl
et
io
n
 
tim
e(m
in
i s
ec
o
n
d)
VF FCFS LIFO CPU-based
 16 
 
 
 
 
 
 
 
 
 
Figure 13 Demand for computing resource is small and amount of data transmission is small 
 the time of task re-distribution in the best case 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 14 Demand for computing resource is small and amount of data transmission is small  
the task completion time in the best case. 
 
 
0
1
2
3
4
5
6
100 200 300 400 500 600 700 800 900 1000
Number of nodes
Ti
m
es
 
o
f t
as
k 
re
-
di
st
rib
u
tio
n
(ti
m
es
)
VF FCFS LIFO CPU-based
 18 
6.  Conclusion 
The resources in a Grid environment are composed of idle resources on the network, and nodes that provide 
these resources will dynamically change with time; that is to say, a node may be idle in one second, but be busy 
in the next, and cannot continue to provide resources. Therefore, a new node has to be located to take over the 
already assigned task, and task re-execution and re-distribution will occur. Therefore, node selection cannot 
simply depend on the resources that a node can provide (such as the available CPU capacity), other factors of the 
node has to be considered too, so as to find suitable and effective nodes for assisting the execution of tasks. To 
maintain the load balancing of the system in a Grid environment, this study proposed a hybrid load balancing 
policy, which integrates static and dynamic load balancing techniques, to locate effective nodes, identify system 
imbalance in the shortest time when any node becomes ineffective, and fill in with a new node. The experiment 
on the above-mentioned four conditions has proven that the proposed method, whether in the best or worst case, 
is far more effective than the other methods in selecting nodes with better effectiveness and performance for task 
execution, reducing task completion time, and avoiding the occurrence of task re-distribution and re-execution. 
Thus, it can effectively maintain the load balancing and enhance the performance of the system. The proposed 
method has the main advantage of locating proper resources according to the task properties. It can reduce the 
drop of system performance resulted from miss-selection of ineffective nodes, and maintain the load balancing of 
the system. 
In this report, a hybrid load balancing policy is proposed for the dynamic Grid environment. Since the Grid 
environment is more complicated than other distributed system, if the policy can achieve the load balancing in 
the Grid environment, the policy will also be able to solve the load balancing in other distributed systems.  
 
References 
[1] D. P. Anderson, J. Cobb, E. Korpela, M. Lebofsky, D. Werthimer, “SETI@home: An Experiment in Public-resource 
Computing,” Communications of the ACM, Vol. 45, No. 11, pp. 56-61, 2002. 
[2] A. S. Banawan, N. M. Zeidat, “A Comparative Study of Load Sharing in Heterogeneous Multicomputer Systems,” 
Proceedings of the 25th Annual Symposium, pp. 22-31, April 1992.  
[3] C.H. Chen, C.T. Yang, C.L. Lai, “Towards an Efficient Replica Selection for Data Grid,” Proceedings of the First 
Workshop on Grid Technologies and Applications (WoGTA '04), December 2004. 
[4] S. P. Dandamudi, “Sensitivity Evaluation of Dynamic Load Sharing in Distributed Systems,” IEEE Concurrency, 
July-Sept, Vol. 6, No. 3, pp. 62-72, 1998. 
[5] I. Foster, C. Kesselman, “The Grid: Blueprint for a New Computing Infrastructure,” First edition, San Francisco, 
Morgan Kauffmann, 1999. 
[6] I. Foster, C. Kesselman, S. Tuecke, “The Anatomy of the Grid: Enabling Scalable Virtual Organizations,” The 
International Journal of High Performance Computing Applications, Vol. 15, No. 3, pp.200-222, 2001. 
[7] N. Fujimoto, K. Hagihara, “A Comparison among Grid Scheduling Algorithms for Independent Coarse-Grained Tasks,” 
Proceedings of SAINT 2004 Workshop on High Performance Grid Computing and Networking, pp. 674-680, Tokyo, 
Japan, January 2004. 
[8] K. Koyama, K. Shimizu, H. Ashihara, Y. Zhang, H. Kameda, “Performance Evaluation of Adaptive Load Balancing 
Policies in Distributed Systems,” Proceedings of the Singapore International Conference on Networks/ International 
Conference on Information Engineering '93, pp.606-611, 1993. 
[9] H.Y. Sit, K.S. Ho, R.W.P. Luk, L. K. Ho, “An Adaptive Clustering Approach to Dynamic Load Balancing,” 
Proceedings of the 7th International Symposium on Parallel Architectures, Algorithms and Networks(ISPAN’04), 
pp.415-420, 2004. 
[10] X. Zhang, Y. Qu, L. Xiao, “Improving Distributed Workload Performance by Sharing Both CPU and Memory 
Resources,” Proceedings of the 20th Int'l Conf. Distributed Computing Systems, (ICDCS '2000), pp. 233-241, Apr. 
2000. 
[11] S. Zhou, “A Trace-Driven Simulation Study of Dynamic Load Balancing,” IEEE Transactions on Software Engineering, 
Vol. 14, No. 9, pp. 1327-1341, September 1988. 
[12] Folding@home, http://folding.stanford.edu/, 2006. 
[13] Globus, http://www.globus.org/, 2006. 
[14] LCG, http://lcg.web.cern.ch/LCG/, 2006. 
[15] SETI@home, http://setiathome.berkeley.edu/, 2006. 
[16] The Network Simulator Version 2 (NS-2), http://www-isi.edu/nsnam/ns/ ns-documentation, 2005. 
 
C. Policy Based Management Systems (PBMS)  
o Real-time management of wireless/mobile networks based on high-level policies 
(server side and mobile client side).  
o Failure recovery and load balancing managed by PBMS.  
o High-level policy definitions.  
o Inter-domain policy negotiations and management.  
o Policy conflict and resolution.  
o Policy representation and the XML family.  
 
D. Network Management and Security Policies  
o Traffic engineering and shaping (network side and mobile client side).  
o Security policies and implementation.  
o Attack detection and prevention in wireless/mobile inter-working.  
o Intrusion detection and Denial of Service in multi-domain wireless networks.  
o QoS management in mobile architectures.  
 
E. Mobility for Handheld Devices  
o Light-weight security protocols suitable for handheld devices.  
o Real-time configuration.  
o Multi-domain authentication (processing requirements, time-delay).  
o Support for VoIP, multimedia and video-on-demand in wireless devices.  
o Bursty data traffic management.  
o QoS specification and implementation across multiple wireless platforms.  
 
此次會議是在 Phuket, Thailand 舉行，研討會中，所邀請的 Keynote speaker 為來自
University Technology Malaysia, Malaysia的 Shaharuddin Salleh進行專題演講，講題為 Numerical 
Modelling and Simulations for High-Performance Computing: Trends and Direction，主要說明現今
存在的 numerical models 與 simulation 的手法，及未來可能的發展方向。 
除了專題演講外，研討會中亦安排了 Tutorial Session，由來自美國 Old Dominion University
的 Stephan Olariu 以 Advances in Wireless Sensor Networks 為主題進行講解。在這個 Tutorial 中
主要在闡述 Wireless Sensor Network (WSN)與 and Mobile Ad-hoc Network (MANET)的不同
處。除此之外,更以 WSN 的相關技術、系統、軟體議題、與相關應用等進行說明。 
  
會場照片
 
 
會議論文集光碟：
 
 
 
 
 
出席證及Conference Program 
 
 
發表之論文： 
unrestricted mobility. 
Furthermore, each processor has highly mobility in 
MANET, it will causes network topology changes of the 
wireless mobile network. In addition, the limitation of 
power leads processors disconnects mobile unit frequently 
in order to save power consumption. On the other hand, 
processors may immigrate into the network or move away 
from the network at any time. In MANET, virtual subnet 
is composed of several groups by overlay network 
approach [1,5]. Fig. 1 is a topology of virtual subnet 
under the MANET. There are two situations that the 
processors communicate underlying virtual subnet: 
Situation 1. Processors in the same group communicate 
to each other directly by virtual backbone. 
Situation 2. Processors in different groups are 
exchanging messages with each other via 
virtual subnet or physical communication 
media (such as the agent-based). 
A mobile processor is said to be healthy if it follows the 
protocol specifications during the execution of a protocol; 
otherwise, the mobile processor said to be faulty. The 
symptoms of mobile processor failure can be classified 
into two categories: dormant fault and malicious fault 
(also called as Byzantine fault) [7]. The dormant faults of 
a fallible mobile processor are crashes and omission. A 
crash fault happens when a processor is broken. An 
omission fault takes place when a processor fails to 
transmit or receive a message on time or at all. However, 
the behavior of a mobile processor with malicious fault is 
unpredictable. A mobile processor with malicious fault 
may work in coordination with other faulty mobile 
processor to prevent other healthy mobile processors to 
reach an agreement value. In this study, we will solve the 
BA problem with mobile processor with malicious and 
dormant fault. 
 
 
3.  The proposed protocol 
 
This paper proposes a new protocol, Dual Agreement 
Protocol, called DAP, to solve the BA problem due to 
faulty processor(s), which may send wrong messages to 
influence the system to reach agreement in a virtual 
subnet.  The notations and parameters of our protocols 
DAP for the virtual subnet network is shown in follow: 
 Let x, y be the group identifier where 
1≤x,y≤g and g≥4. 
 Let fm be the total number of malicious faulty 
processors. 
 Let fd be the total number of dormant faulty 
processors. 
 Let FGm be the maximum number of 
malicious faulty groups allowed. 
 Let FGd be the maximum number of dormant 
faulty groups allowed. 
 Let TFP is the total number of allowable faulty 
processors, TFP = fm+fd. 
 Let TFG is the total number of allowable 
faulty groups, TFG =FGm+FGd. 
 Let ηx is the number of processors in Gx, 
0≤x≤g. 
 Let c be the connectivity of the virtual subnet 
network, where c is g – 1. 
The proposed protocol DAP is organized as two phases 
with the procedure TRANSMISSION. In the first round 
of the message exchange phase, the source processor 
sends its initial value to all processors by using 
TRANSMISSION, and then receiver processor stores the 
received value in the root of its mg-tree. The mg-tree is a 
tree structure that is used to store the received message 
[8]. If the source processor is dormant fault, then the 
value “λ0” has replaced the initial value from source 
processor. After the first round of message exchange 
phase (θ >1), each processor without source processor 
uses TRANSMISSION to transmit the value at level θ−1 
in its mg-tree to all processors. If the value at level θ−1 is 
λi (the value λi is used to report absent value), then the 
value λi will be replaced by λi+1, where 0≤i≤TFG–1. At the 
end of each round, the receiver processor uses the 
function RMAJ on it received VMAJ values, which are 
from the same group by TRANSMISSION, to get a single 
value. Moreover, each receiver processor stores the 
received messages (VMAJ values) and function RMAJ 
value in its mg-tree. 
 
Subsequently, in the decision making phase, each 
processor without the source processor reorganizes its 
mg-tree into a corresponding ic-tree. The ic-tree is a tree 
structure that has used to store a received message 
without repeated group names [8]. Therefore, the common 
value VOTE(s) has obtained by using function VOTE on 
the root s of each processor’s ic-tree. The function VOTE 
counts the non-value λ0 (expert the last level of the 
ic-tree) for all vertexes at the θ-th level of an ic-tree, 
where 1≤θ ≤TFG+1. The conditions in the function VOTE 
are similar to conventional majority vote [7]. The detail 
steps of the proposed protocol DAP has presented in Fig. 
2. The procedure TRANSMISSION used to transmit 
messages in DAP. Based on the distinctions of virtual 
subnet network [1,5], TRANSMISSION can provide a 
virtual channel to help each processor to transmit 
messages to each other without influence from faulty 
inter-communication medium. The description of 
TRANSMISSION is shown in Fig. 3. 
 
An example is given to execute our protocol DAP, the 
virtual subnet network is shown in Fig. 1. There are 24 
processors falling into seven groups. Gp1 includes source 
processor Ps, P1 and P2. Gp2 includes P3, P4, P5 and P6. 
Gp3 includes P7, P8, P9 and P10. Gp4 includes P11 and P12. 
Gp5 includes P13 and P14. Gp6 includes P15 and P16. P17, 
P18, P19, P20 and P21 belong to Gp7, P22 and P23 belong to 
Gp8. In BA problem, the worst situation [3] is that the 
Proof: There are TFG+1 vertices along each root-to-leaf 
path of an ic-tree in which the root is labeled by the 
source name, and the others are labeled by a sequence of 
group names. Since at most TFG groups can fail, there is at 
least one vertex that is correct along each root-to-leaf path 
of the ic-tree. Using Lemma 3, the correct vertex is 
common, and the common frontier exists in each healthy 
processor’s ic-tree.  
Lemma 5. Let α be a vertex; α is common if there is a 
common frontier in the subtree rooted at α. 
Proof: If the height of α is 0, and the common frontier (α 
itself) exists, then α is common. If the height of α is θ, the 
children of α are all consistent using the induction 
hypothesis with the height of the children at θ-1, the 
vertex α is then common.  
Corollary 1. The root is common if a common frontier 
exists in the ic-tree. 
Theorem 3. The root of a healthy processor’s ic-tree is 
common. 
Proof: By Lemma 3, Lemma 4, Lemma 5 and Corollary 1, 
the theorem is proved.  
Theorem 4. Protocol DAP solves the BA problem in a 
virtual subnet of MANET. 
Proof: To prove the theorem, it has to show that DAP 
meets the agreements (Agreement’) and (Validity’)  
(Agreement’): Root s is common. By Theorem 3, 
(Agreement’) is satisfied.  
(Validity’): VOTE(s) = v for all healthy processors, if the 
initial value of the source is vs say v=vs. 
Since most of the processors are healthy, they use 
TRANSMISSION to transmit the message to all others. 
The value of correct vertices for all healthy processors’ 
mg-tree is v. When the mg-tree is reorganized to an ic-tree, 
the correct vertices still exist. As a result, each correct 
vertices of the ic-tree is common (Lemma 3), and its true 
value is v. Using Theorem 3, this root is common. The 
computed value VOTE(s)=v is stored in the root for all 
healthy processors. (Validity’) is satisfied.  
 
The complexity of DAP is evaluated in terms of 
1) the minimal number of rounds; and 2) the 
maximum number of allowable faulty 
components. Theorems 5 and 6 below will show 
that the optimal solution is reached. 
 
Theorem 5. DAP requires TFG+1 rounds to 
solve the generalized (dual faults) BA in a 
virtual subnet of MANET if 
g>(g-1)/3+2FGm+FGd, where TFG≤(g-1)/3, 
and TFG+1 is the minimum number of rounds of 
message exchange. 
Proof: Because message passing is required only in the 
message exchange phase, the message exchange phase is 
a time consuming phase. Fischer pointed out that t+1 
(t≤(n-1)/3) rounds are the minimum number of rounds 
to get enough messages to achieve BA [4]. The unit of 
Fischer is processor, but the unit of the group-oriented 
network is group. So that, the number of required rounds 
of message exchange in the group-oriented network is 
TFG+1 (TFG≤(g-1)/3). Thus, DAP requires TFG+1 rounds 
and this number is the minimum.  
Theorem 6. The maximum number of allowable 
faulty components by DAP is FGm malicious faulty 
groups and FGd dormant faulty groups where 
g>(g-1)/3+2FGm+FGd. 
Proof: In Siu et al. [6] indicates the constraint of BA 
problem for processor faults only is n>(n-1)/3+2fm+fd and 
the unit of [6] is processor. However, the unit of virtual 
subnet is group, so we can suppose a processor in [6] as a 
group in a virtual subnet. Therefore, n>(n-1)/3+2fm+fd in [6] 
imply g>(g-1)/3+2FGm+FGd in virtual subnet. Further, 
the fault status of our assumption is processor faults. So, 
the constraint is rewritten as g>(g-1)/3+2FGm+FGd. And. 
the total number of allowable faulty components by DAP 
is FGm malicious faulty groups and FGd dormant faulty 
groups, which is maximum if g>(g-1)/3+2FGm+FGd.  
 
As a result, DAP takes a minimum number of rounds and 
tolerates a maximum number of faulty components to 
make healthy processors reach a common agreement. The 
optimality of the protocol is proven. 
 
 
5. Conclusion 
 
In the previous work, the complex networks had studied 
in a branch of mathematics known as graph theory. The 
network topology developed in recent years [1,5] shows a 
mobile feature. The previous protocols such as [2,3,6-8] 
cannot adapt to solve BA problem in MANET, and none 
of the BA protocol is designed for the virtual subnet of 
MANET. Therefore, the BA problem in virtual subnet 
network with dual failure mode on fallible processor is 
revisited. The proposed protocol can tolerate the most 
damaging failure type of fallible processors. The proposed 
DAP can take the minimum number of required rounds to 
achieve an agreement, and tolerate the maximum number 
of faulty components. 
 
Furthermore, in a generalized case, there are not only 
processors may be crash, omission or malicious, but also 
communication medium. On other hand, our protocol will 
be extend to solve when dormant or malicious 
communication media or processors are existed 
simultaneously underlying virtual subnet network of 
MANET in future work. 
 
 
Reference 
 
[1] M. Fischer, The consensus problem in unreliable 
distributed systems (A brief survey), Technical 
Report, Department of Computer Science, Yale 
  
The symbol notations: 
 
: Healthy processor 
 
: Malicious faulty processor 
 
: Dormant faulty processor 
 
: Physical communication media (agent-based) 
Fig. 1. The topology of virtual subnet 
 
 
 
DAP (source processor with initial value vs) 
Pre-Execute. Computes the number of rounds required. 
Message Exchange Phase: 
Case θ = 1, run 
A) The source processor transmits its initial value vs to each 
group’s processors by using TRANSMISSION. 
B) Each receiver processor obtains the value and stores it in the 
root of its mg-tree. 
C) If the source processor is dormant fault, and then the value “λ0” 
has replaced the initial value from source processor. 
Case θ>1, run 
A) Each processor without the source processor uses 
TRANSMISSION to transmit the values at level θ−1 in its 
mg-tree to each group’s processors. If the value at level θ−1 is 
“λi”, and the value λi will be replaced by λi+1, where 
0≤i≤TFG–1. 
B) Each receiver processor applies RMAJ on its received messages 
and stores RMAJ value in the corresponding vertices at level θ 
of its mg-tree. 
Decision Making Phase: 
Step 1: Reorganizing the mg-tree into a corresponding ic-tree. (The 
vertices with repeated group names are deleted). 
Step 2: Using function VOTE on the root s of each processor’s 
ic-tree, then the common value VOTE(s) has obtained. 
Function RMAJ(V) 
1. The majority value in the vector Vi, if it exists. 
2. Otherwise, choosing a default value (φ). 
Function VOTE(µ) 
1. If the µ is a leaf or the number of value λ0 is 
3*(TFG–θ+1)+(g–1)%3, then output µ. 
2. Else if the majority value is not existed, then output φ. 
3. Else if the majority value is λi, where 1≤i≤TFG, then output λi-1. 
Otherwise, output m, where m∈{0, 1}. 
Fig. 2. DAP protocol 
 
 
 
 
 
 
Procedure TRANSMISSION 
Definition: 
1. For the virtual subnet, each processor has the common 
knowledge of entire graphic information Ĝ = (E, Gp), where 
Gp is the set of groups in the network and E is a set of group 
pairs (Gpx, Gpy) indicating a physical communication medium 
(the sensing is covered) between group Gpx and group Gpy. 
2. Each processor communicates with all other processors via 
virtual subnet, virtual backbone or physical communication 
media [1,5]. 
3. The processor plays sender, receiver or agent, depends on the 
behavior of which kinds of transmission [1]. 
4. The agent-based processor cannot garble the message between 
the sender processor and receiver processor; this assumption 
has achieved by the technology of encryption (such as RSA 
[4]). 
Step 1: The sender processor i (1≤i≤n) transmits the value vi to 
the receiver group. 
Step 2: If the group-disjoint path from sender processor to 
destination group passes through any dormant faulty 
processor or if the sender processor has dormant faults, 
then stores λ0 itself. 
Step 3: The processors in the receiver group take the local 
majority value from the same group paths and then 
construct the vector Vi = [vpath 1,vpath 2, …, vpath c-1, vpath c]. 
Step 4: The processors in the destination group apply VMAJ on 
vector Vi. 
Function VMAJ (for each vector Vi) 
1. Count the received value: Take the majority 
2. If the majority value is λ0 and the number of value λ0 is 
greater than or equal to c–(g−1)/3, then output the value λ0. 
3. Else set majority value m, where m∈{0, 1} 
If the majority value does not exist, then output the majority 
value λ0. 
Otherwise, output the majority m, where m∈{0, 1}. 
Fig. 3. TRANSMISSION  
 
 root s 
Gp1’s healthy processors 0 
Gp2’s healthy processors 1 
Gp3’s healthy processors 0 
Gp4’s healthy processors 1 
Gp5’s healthy processors 1 
Gp6’s healthy processors 1 
Gp7’s healthy processors 1 
Gp8’s healthy processors 1 
VMAJ values 
 
Fig. 4(a). The mg-tree of each processor at the 1st round 
 
root s Level 2 Function RMAJ 
Val(S)=1 s1 0 (0,0) 
 s2 1 (1,1,0,1) 
 s3 0 (0,0,0,0) 
 s4 1 (1,1) 
 s5 1 (1,1) 
 s6 1 (1,1) 
 s7 0 (0,0,1,0,1) 
 s8 λ0 (λ0, λ0) 
VMAJ values 
 
Fig. 4(b). The mg-tree of healthy processor P1 at the 2nd round 
 
