 2 
有無血管侵犯與淋巴節轉移。 
藉由 CT 影像判讀肝腫瘤常需要參佐各種與器官與病變相關的型態資訊，
例如肝臟的輪廓、肝臟及腫瘤體積的評估、腫瘤發生的部位、肝臟血管的走向以
及這些組織在空間中的相對關係等等。然而，由於部分體積效應（Partial volume 
effect）的影響，正常的肝臟組織與腫瘤銜接的區域有時界線是十分模稜兩可的，
腫瘤在灰階強度、紋理或型態等外觀特徵的多變，因而增加判讀工作的難度。再
加上肝臟本身包含複雜的血管網絡，在肝臟影像中所呈現出的複雜紋理有時會對
影像切割造成干擾。若是以人為判斷，容易受主觀因素影響或受限於經驗而產生
不一致的判讀結果產生。另一個挑戰是，動態掃瞄的影像資料雖然可以幫助醫師
得到更多結構與組織的細節，但是相對換來的是資料量的暴增，因此利用電腦輔
助診斷系統（Computer Aided Diagnosis，CAD）來輔助醫師處理 CT 影像資料，
將有效減輕放射科醫師在影像判讀上的負擔。透過電腦系統的高速運算，可先行
自動切割出肝臟與定位肝腫瘤區域，並進一步根據異常部位產生相關特徵資訊，
將有利於醫師進行後續的分析，對提升臨床診斷的效率與準確度將有所助益，可
使評估手術計畫達到最佳效果[5,6]。 
研究目的 
腹部電腦斷層影像在一般的例行檢查數量不少，而本研究既然旨在發展自動
化肝腫瘤分析的 CAD 系統，因此前期的工作重點在於定位肝臟 CT 影像當中的
目標器官與相關組織的空間關係，以利後續的特徵擷取。本研究中的切割技術將
以 J.-S. Hong 等人所提出的方法做為框架，主要採取型態學的方法來圈選出肝臟
輪廓。而原始方法僅採用了 10 位肝血管瘤與肝癌病患的影像資料，如考慮其他
不同的肝腫瘤類型，其實仍很大的改善空間。每一組病例會掃瞄出四組在不同時
段掃瞄的連續影像，其中第一組為未施打顯影劑之影像組合，及三組施打顯影劑
之影像組合。在顯影劑的擴散下，肝臟以及異常組織影像的灰階強度也會隨之改
變，此動態資訊將成為我們在影像切割問題上的有利參考。 
 
 
CT
1（未注射顯影劑） 
影像套合
（registration） 
CT
2（動脈相） 
CT
3（門脈相） 
CT
4（延遲相） 
CT
1
' 
CT
2
' 
CT
3
' 
CT
4
' 
肝臟影像切割 
 
圖一 流程圖 
文獻探討 
 4 
GE Healthcare），參數設定如下：120 kV，300 mA。每位病患以每秒 3 mL的速
度總共注射了 100 mL 的顯影劑（Iohexol; Omnipaque 350, Amersham Health, Co. 
Cork or Ireland, GE Healthcare）。取得的影像每張厚度為 5 mm，影像的大小
皆為 512 x 512像素，肝臟的位置座落在影像的左上方。在這些資料中，選取
50組病患做為肝臟影像切割實驗之用，共 1500 張影像，平均每組有 30張。肝
臟當中組織異常的位置由專業的放射科醫師圈選出來，以作為評估標準。 
 
 
CT
1
k 
CT
2
k+2 
CT
2
k+1 
CT
2
k 
CT
2
k-2 
CT
2
k-3 
Fixed Image 
Moving Image 
 
圖二：時間軸校正之概念。 
 
2. 影像套合 
本次計畫應用 mutual information（MI）方法[9,10]對四組影像進行套合。
MI的方法則適用於影像複雜度較高的圖像。其採用 entropy的計算方法；假設
令代表當 A與 BT完全不相關時： 
      TT BHAHBAH ,  (1) 
相對地，只要 A與 BT有任何相似性時： 
      
TT BHAHBAH ,  (2) 
最後，整個 MI公式可以表示為： 
        
TTT BAHBHAHBAI ,,   (3) 
其中 H(A)代表 A的 entropy；H(A,BT)代表 A 與 BT的 joint entropy。令 CT1代表
未施打顯影劑的影像集合，而其他三相影像集合則分別標示為 CT2、CT3，與 CT4。
首先先固定 CT1內的所有影像，其他影像序列(即 CT2、CT3、CT4)的影像，與 CT1
中的所有影像逐一比對與校正。由於拍攝的時間不同，故病人的平躺位置與掃瞄
時的呼吸及心跳，皆成為套合過程中的變因。在此，我們參考 Chang 等學者的研
 6 
的型態閉合與七次的斷開，以得到肝臟的正常組織部分。 
 
3) 填補區塊凹洞 
每個腫瘤在器官中的外觀皆有不同。如果和正常的組織做比較，異常部位的
灰階答多較低，因此在目標器官的區塊中會造成凹洞。所以，我們必須要將這些
凹洞進行影像的填補，才能真正回復肝臟的完整輪廓。這個部分我們可以由型態
特徵來了解輪廓是否出現凹洞。我們根據式子(4)到(7)的計算出數值，這四個參
數分別代表四種型態上的特徵。如果此數值符合表一中每一列所對應的條件，便
將此區域標示，並涵括到肝臟區域之中。 
qofAreaRS  . (4) 
},min{
w
h
h
w
RHW 
. (5) 
RofArea
qofArea
RA 
. (6) 
massliver togneighborin NOT pixels ofNumber 
massliver  to ngneighnbori pixels ofNumber  
RL
 (7)
  
 
 
Thresholding 
(gray value) 
RS 
(pixel) 
RHW RA RL 
Category 1 0-0.8σ >100 >0.4 >0.35 >1.6 
Category 2 0-30 >100 >0.6 >0.6 >0.5 
Category 3 10- (ū-1.2σ) >100 >0.7 >0.5 >0.9 
Category 4 25- (ū-1.2σ) >100 >0.5 >0.4 >1.3 
  
表一 形態特徵篩選的條件 
 
 
5. 腫瘤偵測 
在已萃取出來的肝臟腫瘤中我們將進一步針對每個像素與其鄰域進行型態分
析，以判定該點是否來自於異常組織。在 CT 研究當中，Haralick 紋理[7,12]是
最常用的紋理分析。Haralick 紋理的計算來自於共生矩陣(co-occurrence 
matrix)，共有包括 13 種計算的公式，我們連同平均值、標準差，以及 entropy
也納入計算。然而，並非每一個紋理特徵皆適用於肝腫瘤組織的偵測，因此我們
利用 t 檢定來驗證每一種紋理特徵，如果驗證所得到 p-value 小於 0.01，即代
表此特徵具有統計上分類的意義。因此在經過篩選之後，我們最後僅保留其中六
個特徵進行腫瘤像素的挑選，包括區域平均值、區域標準差、區域亂度
(entropy)、Haralick 亂度、Haralick energy，以及 Haralick平方和。我們針
 8 
本研究中實驗當中的 TP(深灰色)、FP(淺灰色)以及 FN(灰色)的分布情形。圖四
為實驗結果的圖示；圖四(a)到(c)為其中三個偵測成功的範例，其 TP 分別為
88.6%，以及 99.2%；而 FP 則分別為 1.6%、0%，以及 0.7%。然而，因為個體的
變異性以及目前方法的限制，仍會有些偵測錯誤的情況發生。圖四(d)到(f)即列
出其中的三種情況；圖五(d)到(f)的 TP 分別為 67.3%、89.7%以及 0%；而 FP 則
分別為 77.9%、41.9%，以及 100%。 
 
  
(a) (b) 
  
(c) (d) 
  
(e) (f) 
  
圖四  (a)到(c)為偵測成功的範例，而(d)到(f)為切割失敗的範例；其中紅色
輪廓代表 TP，綠色為 FP，而藍色代表 FN。 
 10 
TP、FP以及 FN分別為 71.8%、37.8%，與 28.1%。不過，目前的技術能有一些需
要克服的問題。首先，當腫瘤的結構比較複雜且接近肝臟邊緣的情況下，異常組
織的偵測將會變成更為困難。因為這種情況常造成在肝臟輪廓擷取的過程中產生
錯誤的肝臟區塊，導致腫瘤在第一時間即被排除在外，使得偵測結果錯誤。另外，
當腫瘤的位置靠近在肝臟血管的時候，也有可能在切割肝臟的時候被誤判為正常
的血管組織而遭到排除，結果導致偵測的 TP 率下降。最後，過小的腫瘤也會影
響本系統的辨識結果。這些問題尚有賴進一步改善肝臟影像切割的技術才能得以
解決。 
 因此未來研究的方向將以加強肝臟影像切割效能為目標，例如透過比對參考
常模影像來定位腹腔器官的位置，並且在後續異常組織的辨識上再引入更多的彣
理特徵。最後，我們也期望可以使用動態輪廓模型來改善切割的結果，以得到較
為清楚的腫瘤輪廓。 
  
 2 
全小波封包樹」（complete packet tree）來進行多重形狀的過濾，其中高頻與低頻資訊能在此樹
狀結構中再一次被分解開來。本研究採用兩種醫學影像資料庫做為實驗素材，並用傳統的 ASM方
法做為比較，以點對線（Point-to-Curve）偏移錯誤做為量化比較的依據。數據顯示新的方法大
部分切割結果所得到的誤差較小；其中，如果當訓練的資料個數較少的時候，新方法所提出的技
術所得到誤差可大幅降低；整體的表現比起傳統 ASM 影像比對法較為穩定，不易受到訓練資訊而
產生大幅的影響。 
  
 
圖一 
 
（二） Detection of the Optic Disc in Retinal Images by Means of Ant Colony Optimization 
Algorithm 
本研究室蟻群優化演算法（Ant Colony Optimization Algorithm，ACO Algorithm）的應用。蟻
群演算法為一種模仿現實生活螞蟻生態的邊緣偵測法，一開始在影像中灰階變化大的地方放入「螞
蟻」，建立「費洛蒙」矩陣，每當「螞蟻」走過的路徑即會在對應的空間位置中留下「費洛蒙」；
接著經過幾次回合之後，所有的「螞蟻」即會依循「費洛蒙」殘留的路徑來行走。本研究將此演
算法應用於視網膜影像上，藉此擷取出視神經盤（Optic Disc，OD），切割結果未來將有助於診斷
糖尿病視網膜病變（Diabetic Retinopathy，DR）等疾病。本論文首先使用 Anisotropic Diffusion
將血管的內部區域模糊化，接著再使用 ACO演算法要找出 OD的位置。其切割結果相當準確，不過
由於 ACO演算法需要在多次回合中不斷計算與更新費洛蒙矩陣，因此所耗費的時間較多，執行效
率是未來應用上亟需改善的問題之一。 
 
（三） Automatic Facial Expression Recognition Using Neural Network 
本論文主要研究辨識人類表情的電腦技術，研究中所使用的技術是類神經網路，用來辨識並分類
人類臉部的影像特徵。本研究僅限定於正面且五官清晰之女性人像，未考慮頭部旋轉以及配戴眼
鏡等問題，共計 115張影像。臉部特徵的擷取主要由影像水平軸與垂直軸的投影來計算得來。從
投影的曲線定義出臉部特徵點的位置，共計 30個；藉此根據臉部特徵點位置的分佈變化來做為表
情分類的依據。類神經網路採用兩層架構，分別包含 10個節點與 4個節點。提供四種生氣、快樂、
驚訝與無表情等類別。除了驚訝表情僅 86.6%的準確率之外，其他表情的分類準確率皆可達九成
 4 
 
圖三 
 
 
圖四 
 
二、與會心得 
應用醫學影像之輔助診斷系統大抵皆包含 ROI定位，以及疾病分類等兩大步驟。ROI的定位即仰賴
影像切割，將目標器官連同病灶圈選出來後，再配合紋理分析與分類器進一步定位病灶的位置。因
此相對地，影像切割如果有出現差錯，便會直接影響自動診斷的結果。這次研討會的主題廣納了許
多與影像技術相關的主題，尤其在影像切割與型態分析的問題上見識了許多最新的技術發展。這些
技術提供我們許多研究的想法，未來可以與本計畫中的方法結合，以提升目標輔助診斷的準確度。
同時，更可以導入教學中，以豐富日後的課程教材，對於學習影像處理的學生而言，將是非常有用
的學習資訊。 
 
IPCV 2011 Conference - decision on your paper 
From: hra@cs.uga.edu
Sent: Thursday, April 28, 2011 7:37:44 PM
To: sfhuang@mail.tcu.edu.tw; spiculate@hotmail.com
Cc: spider0645@mail.tcu.edu.tw
 
Dear Dr. Sheng-Fang Huang: 
 
I am pleased to inform you that the following paper which you 
submitted to The 2011 International Conference on Image 
Processing, Computer Vision, and Pattern Recognition (IPCV'11: 
July 18-21, 2011, USA) has been accepted as a Regular Research 
Paper (RRP) - ie, accepted for both, publication in the 
proceedings and oral formal presentation. Please see below for 
the categories of accepted papers. 
 
Paper ID #: IPC2885 
Title: An Automatic Detection Method for Liver Lesions Using Abdominal 
Computed Tomography 
Sheng-Fang Huang and Kuo-Hsien Chiang 
Tzu Chi University, Hualien, Taiwan; 
Buddhist Tzu Chi General Hospital, Hualien, Taiwan 
 
Note: The "paper ID #" shown above is composed of three letters 
(conference prefix) followed by four numeral/digits. You will 
need to have this "Paper ID #" at the time of registration and 
final paper submission (for publication). 
 
(The evaluation of this paper is arranged by Track Chair # 122) 
 
General comments to authors of accepted papers: 
1. Each paper was peer-reviewed by two experts in the field for 
originality, significance, clarity, impact, and soundness. 
In cases of contradictory recommendations, a member of the 
conference program committee was charged to make the final 
decision (accept/reject) - often, this involved seeking help 
from additional referees by using a double-blinded review process. 
In addition, all papers whose authors included a member of the 
conference program committee were evaluated using the 
double-blinded review process. Chairs of approved sessions were 
responsible in evaluating the papers that were submitted to them. 
2. Authors of accepted papers are strongly encouraged to enhance 
the organization and the quality of the English writeup of 
their papers before uploading them to the publication web site 
for the preparation of the printed books/proceedings. 
3. Only those authors whose papers have been accepted SUBJECT to 
MANDATORY changes will receive the compiled referees' report. 
Your paper has been accepted without any mandatory changes. 
 
For information regarding author instructions including: 
 
- Presentation Formats / Accepted Paper Categories 
- Typing Instructions 
- Deadline (registration and camera-ready papers due: May 12, 2011); 
We strongly encourage authors to register as soon as possible. 
- Conference Registration 
- Hotel Reservation 
- Conference Program/Schedule 
Please visit: 
http://www.worldacademyofscience.org/worldcomp11/ws/authors 
 
For Submission of Final Camera-Ready Papers for Publication in the 
Conference Proceedings/book, please visit: 
http://www.ucmss.com/cr/main/papersNew/worldcomp11_first_html 
 
To Request Invitation Letters for US Visa Purposes, please visit: 
http://www.ucmss.com/cr/main/invitations/worldcomp_index_html 
 
General information can be found at: 
http://www.world-academy-of-science.org/ 
 
 Council on Medical and Care Compunetics; Eastern Virginia Medical School 
and the American College of Surgeons, USA. The compiled list of Academic 
sponsors of 2011 will be at similar caliber as above and will be 
announced in May. 
 
PUBLICATION: 
 
All accepted papers will be published in the IPCV 2011 conference 
proceedings in a printed book form. Later, the proceedings will also 
be made available online. The proceedings will be indexed in Inspec / 
IET / The Institute for Engineering & Technology, DBLP / Computer 
Science Bibliography, and others.) In the past, all tracks of WORLDCOMP 
have also been included in EI Compendex/Elsevier. Like prior years, 
extended versions of selected papers will appear in journals and 
edited research books (a large number of book projects and journal 
special issues are in the pipeline: Springer, Elsevier, BMC journals, ...) 
Authors of selected papers will be given the opportunity to submit 
the extended versions of their papers for consideration; this process 
will start soon after October 2011. For a few examples of recent books 
and journal issues based on WORLDCOMP papers, see the links below: 
http://www.springer.com/life+sciences/bioinformatics/book/978-1-4419-7045-9 
http://www.springer.com/life+sciences/bioinformatics/book/978-1-4419-5912-6 
+ a number of journal special issues published by BMC Genomics: 
http://www.biomedcentral.com 
 
NEWS: 
 
According to "Microsoft Academic Search" (a Microsoft initiative) all 
tracks of WORLDCOMP are listed as worldwide "Top-ranked Conferences" 
(based on various metrics but mainly based on the number of citations). 
You can access "Microsoft Academic Search" to extract citation data for 
each individual track of worldcomp using the following link: 
http://academic.research.microsoft.com/ 
As of March 4, 2011, the papers published in the proceeedings have 
received 14,385 citations which is a higher citation than many 
reputable journals in computer science. 
  
 
Figure 1.  Flowchart of liver segmentation. 
 
our method. Finally, we make discussion and 
conclusions in Section V. 
II. DATA AQUISITION 
 
The dataset included abdominal CT images 
acquired from 50 patients, with each patient 
averagely having 30 images. Totally, 1500 
DICOM images were used in our study. Each 
CT image was was scanned at an interval of 5 
mm. The technique of 300 mAs was used with 
120 KVP, field of Vision we can achieve image 
enhancement to highlight he- 
(fov) 280. The dimension of image matrix 
was 512 x 512. For each patient, 100cc of 
omnipaque 350 was injected intravenously at the 
rate of 3cc per second. Scanning delay was 30 
seconds, where 20 second spiral scanning was 
used with a pitch of 0.984. We assumed that the 
liver located on the left of the abdomen for all 
the input images. 
 
III. METHOD 
A. Image Enhancement 
Pixels in a CT image are displayed in terms of 
relative radio-density. The pixel itself can be 
quantified according to the mean attenuation of 
the tissues.  The Hounsfield unit (HU) scale, 
which ranges from -1024 to +3071, is measured 
by a linear transformation of original linear 
attenuation coefficients in a material. Using liver 
window level, patic lesion brightness. Liver 
windows have a window level equal to the 
attenuation levels of hepatic parenchyma (50 HU 
without contrast material; 100 HU after the 
intravenous administration of contrast material) 
and a narrower window width (150 HU) than 
conventional soft-tissue window levels. However, 
medical images differ in every body and every 
taking. A fixed liver window may not result in a 
good enhancement for liver and liver lesions. In 
our study, we computed an adaptive threshold 
value as window center to solve the problem. 
Since liver is located on the left side of the 
abdomen according our scanning protocol, we 
computed the mean of pixels which have HU 
values ranging from 0 HU to 300 HU in the left-
half of the input image as the new window center. 
The window width was determined by 
experiments. A small window width can enhance 
details of liver compositions, but could also 
increase the amount of other irregular patterns, 
such as noise. In our study, the window width 
was chosen 150.  
 
B. Liver segmentation 
Our liver segmentation method consists of 
several steps as shown in Figure 1, which we 
will describe the details in the following sections.  
 
1) Rib-cage Extraction 
The infiltration of fat content lowers the HU 
values in human liver. A fatty liver could 
become less distinguishable when it neighbors 
upon the extra-abdominal fat closely, which may 
induce an erroneous segmentation result. 
Because the extra-abdominal fat locates outside 
the rib cage, we can find the location of ribs and 
draw a contour to exclude the fat.  
First, the initial CT scan image was 
thresholded using values ranging from 0 to 300 
HU to obtain the body periphery. A center R was 
then determined by the spatial center of the body 
region. The boundary for body can therefore be 
represented by its signature, denoted by )(s , 
which is a 1-D function that describes the distant 
from R for a specific angle  . Next, it is 
necessary to compute the signature )(r  for rib 
cage so that we can evaluate the size  
 
of structuring element for the erosion by 
subtracting )(r  from )(s  for any  .  
 
features, four co-occurrence matrices are 
necessary to describe different orientations, 
including P0, P90, P45, and P135, which 
respectively represent a co-occurrence matrix 
that describes pixels adjacent to one another in 
four directions. We computed Haralick texture 
features for every point where it has four co-
occurrence matrices. Therefore, we summed 
them up to one matrix to calculate its statistical 
features. There were total 16 texture features 
computed for each liver pixel, including 13 
Haralick textures and four local statistical 
features. The three local statistical features were 
normalized mean, local variance, local, and 
entropy The normalized mean was a ratio of 
local mean to global mean for liver region, 
because the gray level values for liver and liver 
lesions in a CT scan image vary in different 
patients. A normalized ratio would be better to 
capture the difference between normal liver and 
the abnormalities. However, not all the texture 
features were used for classification. After 
computing features for all pixels, we first 
evaluated their feasibility by using the unpaired 
Student’s t-test (two -tailed) to evaluate and keep 
the feature that its t-test value under 0.01. The 
proposed features were statistically significant 
over the entire database and were used to 
classify pixels.  In our study, only six features 
among the 16 texture features were chosen, 
including normalized mean, local variance, local 
entropy, Haralick entropy, Haralick energy, and 
Haralick sum of  squares, which we used for 
tumor detection. 
 
4) Neural Network 
To identify whether a region is a normal liver 
tissue or liver lesions, we adopted a general 
multi-layered perceptron (MLP) neural network 
and chose the back-propagation algorithm as the 
learning rule. The value produced by the output 
node of the neural network lies between 0 and 1. 
The output value was used as a probability 
evaluation for the prediction of tumor regions. In 
the study, we used four layer back-propagation 
algorithms. The first layer was an input and 
included five neurons (nodes) that denote the 
foregoing six features. The framework of this 
neural network consisted of two hidden layers, 
with the number of neurons being given seven 
and three respectively, and the last layer was the 
output layer with two neurons which classifies 
the input pixels whether it is of tumor or of liver.  
 
Figure 3.  Areas for evaluating TP, FP, and FN rates. 
 
In order to stabilize this neural network, we 
trained the data with 500 iterations. The learning 
parameter was set 0.01 and the momentum was 
chosen as 0.01 for converging quickly. 
 
IV. EXPERIMENT RESULTS 
The k-fold cross-validation method was used 
to estimate the accuracy of feature classification. 
With the k-fold cross-validation method, the 50 
case were randomly divided into k groups. The 
first group was chosen as test set, and the 
remaining (k-1) groups were used as train set for 
training the neural network. The trained model 
produced by the network was then used to test 
the former group that we left aside. The process 
repeated until every group has been tested. Each 
time when a group was to be tested, the other (k-
1) groups were used to train the network first. In 
our study, k was 5. A trial is predicted right if the 
tumor region can be successfully selected.  
To evaluate the accuracy of our segmentation, 
we quantitatively compared the automated 
results with the liver lesions. In order to measure 
the performance of the proposed segmentation 
method, we used three different error measures. 
They were true-positive (TP), false-positive (FP) 
and negative-positive volume fractions, which 
were defined as follows [6]. 
m
na
A
AA
TP


 
m
mma
A
AAA
FP


 
m
ama
A
AAA
FN


 
where the term Am refers to the area of the tumor 
determined by manual segmentation and Aa is 
the area of the lesion determined by the proposed  
TP 
FP 
FN 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/07/29
國科會補助計畫
計畫名稱: 應用三相式電腦斷層掃描影像之肝腫瘤電腦輔助診斷系統
計畫主持人: 黃聖方
計畫編號: 99-2221-E-320-001- 學門領域: 醫學資訊
無研發成果推廣資料
已獲得件數 0 0 100%  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
