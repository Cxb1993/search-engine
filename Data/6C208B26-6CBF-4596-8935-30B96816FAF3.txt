ii 
二、 目錄 
 
一、 中文摘要 ..................................................................................................................... i 
二、 目錄 ............................................................................................................................ ii 
三、 前言 ............................................................................................................................ 1 
四、 研究目的 .................................................................................................................... 1 
五、 文獻探討 .................................................................................................................... 1 
5.1. 智慧型代理人 ........................................................................................................ 1 
5.2. 開放式軟體架構 .................................................................................................... 2 
5.3. 行動手臂操縱器自動控制 .................................................................................... 2 
5.4. 多機器人互動控制 ................................................................................................ 2 
六、 研究方法及成果 ........................................................................................................ 3 
6.1. 互動控制系統設計 ................................................................................................ 3 
6.1.1. 系統架構 ................................................................................................................ 3 
6.1.2. 開發環境 ................................................................................................................ 4 
6.2. 移動式機械臂之抓物行為控制設計 .................................................................... 4 
6.2.1. 嵌入式即時影像系統 ............................................................................................ 4 
6.2.2. 視覺抓取控制 ........................................................................................................ 4 
6.2.3. 避障與抓取行為融合 ............................................................................................ 6 
6.3. 即時物體分割、偵測與焦點移轉系統 ................................................................ 6 
6.4. 多模使用者注意力轉移及追蹤系統 .................................................................... 7 
6.5. 多機器人之定位與協調控制 ................................................................................ 8 
七、 結果與討論 ................................................................................................................ 9 
八、 結論 .......................................................................................................................... 10 
九、 參考文獻 .................................................................................................................. 10 
 
 
 2
5.2. 開放式軟體架構 
與系統結構跟控制法則同樣重要的是用來實現的軟體架構(Framework)。因為在機器
人上所需要的軟體元件不管在複雜度或者數量上都不停的增加，所以在發展的過程中
必須注重彈性和可重覆使用性，才能避免程式碼不必要的重寫、也才方便維護。像是
Windows 開發常用的 MFC 就是很好了例子，智慧型代理人的開發也有 JINI [6] 或 
April [7]之類的開發套件可用。 因此對機器人的開發，也應該有一套專門的軟體架構，
以便減少開發的難度，增加開發的效率。而且因為機器人的硬體平常常更換，此軟體
架構也應該能夠適應各種環境的開發。例如 BERRA [8] 使用 ACE適應式通訊環境來
實現元件間的溝通，具備跨平台的特性。CLARAty [9]使用抽象化的方法來建立架構，
因此可以利用不同的實現方法來適應各種不同特性的機器人平台。OROCOS project 
(Open Robot Control Software), [10],是一套以元件為基礎，分散式而且可調整的機器人
系統軟體架構。它具備即時的系統核心、通用的控制結構、以及客製化的工具，並且
提供絕佳的彈性：包括網路分散控制、跨作業系統、對特殊用途硬體的高效能設定等、
可擴充性等等。在此我們也會利用類似的方法，分離介面與實作，提供必需之工具，
用以實作機器人之系統控制結構。 
5.3. 行動手臂操縱器自動控制 
行動機器人操作學中大致上可以分為兩個領域：(1)導航避障與(2)載具平台與操作器
的協調合作。 第一個領域，導航與避障，對普通載具(沒有操作器)之研究在過去幾
十年中已經被廣泛的討論，[11-12] 。 但在裝置操作器之載具這方面，則還有許多新
的問題產生，並且持續的被研究 [13-14] 。 此議題多數的問題起因於使用輪式載具所
產生之非完全性約束條件(non-holonomic constraints)，以及載具與操作器結合所產生之
運動冗餘(kinematics redundancy)。  
第第第第第，載載載載載載載載載載載載載，也也也也也也也載也也。首首，和和
面相同的是冗餘問題。在執行空間(workspace)中一特定點可以藉由移動操作器、移動
平台、或兩者並行來達成，找尋最佳解因此十分困難；第二，操作器的反應動態響應
通常比移動平台快，協調上更加不容易；第三，操作器原本是不受限的，但一個典型
的輪式移動平台卻會受限於非完全性約束條件；第四，操作器與移動平台會不斷的與
對方互動。前述的問題在許多文獻中都有所記載[15-16] 與實現 [17-18] ，應用於不同
的研究之中。  
在最近幾年的文獻中[ 15 , 19-21]中，在手臂的研究領域提出許多不同的架構。N.P. 
Papanikolopoulus[19] 提出了 Active Vision 的架構。 C.E. Smith[21] 等人在 N.P. 
Papanikolopoulus 的架構上增加視覺導引之操作器(Visually-Guided Manipulation)的功
能。這種視覺導引之操作器利用電腦視覺來調整機器人行進間的路徑。因為同時間追
蹤也是使用電腦視覺因此結合這兩大系統具有提供更穩定系統之能力。當然也增加了
系統的複雜度，而必須注意龐大的計算量是否能夠符合即時控制的需求。 
5.4. 多機器人互動控制 
分散式多機器人系統之研究應用範圍包括有 (1)多機器人保安系統 (2)環境狀態探
測(含太空探測) (3)交通環境監測 (4)團隊清潔機器人系統 (5)多機器人搜索及救援任
務，以上這些應用都必須透過任務分配 (Task Allocation) 的方式由多個機器人合力完
成，故如何「協調」這些機器人們將是一個很大的問題，而其中最基本的問題是如何
讓每一個機器人都能夠從起始位置移動到它執行任務的目標地，而在過程裡可以閃避
障礙物(靜態或動態)以及其它的機器人們，一直到執行任務完為止[22]。 
有關分散式多機器人系統的「隊形維持與變換」[23,24]是這幾年來一直有人在研究
的一個主題。 Stefano Carpin 和 Lynne E. Parker [25]提出了一套合作式的追隨領導者 
(Leader Following) 的方法，可以讓機器人團隊在移動行走的過程裡，即使受到障礙物
 4
人。 
 短期記憶(Short-term Memory) 記錄代理人執行的過程以及其中所用之資料。 
 知識庫(Knowledge Base) 儲存已知的、判斷用的知識，例如物體與人臉的影像與屬
性、行程、地圖等等…。 
 計時器(Clock) 用來產生時間訊號，提供系統的高解析度即時執行機制以及按照行
程安排執行之能力。 
 資源管理員(Resource Manager) 管理可用的記憶體以及 CPU資源，調整各代理人的
執行狀態以及速度，以便調整系統效能，保證系統的執行效果。 
 全域抉擇者(Global Decision Maker) 根據目前的系統狀態、工作目標、等，決定代
理人的執行時間，並且交由資源管理員來調整。 
6.1.2. 開發環境 
整個控制系統的軟體架構可以分為三層。首先最底層是提供系統運作的基礎
API，包含訊息處理機制、即時處理機制等。第二部份是以 API 建構成之系統元件，第
三層就是設計實用功能的部分。透過幾種特別的結構樣式，讓開發人員能夠簡單的開發
或移植功能到此系統上。  
6.2. 移動式機械臂之抓物行為控制設計 
6.2.1. 嵌入式即時影像系統 
在機器人的基本行為控制設計上，本計畫結合嵌入式即時影像系統完成一套基於
眼-手(Eye-in-hand)配置之機器人即時影像平台[29]。圖二顯示所研發之影像平台以及其
在機器人上的配置。本計畫採用 CMOS 影像感測器擷取外部的影像，然後將所得到的
影像資料送進 DSP 6416 DSK 學習板做處理，在 DSK6416和 CMOS感測器之間則使用
FPGA和 Frame Buffer 作為兩者之間溝通的介面。運用 DSK6416內部硬體之 EDMA 的
介面，影像擷取之理速度可達到每秒 30 張的影像。本系統可用來即時計算機器人混合
式光流法之視覺避障、眼-手影像伺服、以及物體特徵點等。 
6.2.2. 視覺抓取控制 
本計畫利用 Image Jacobian 的概念結合機器人與攝影機間的 Jacobian關係，發展
出一個基於影像的視覺伺服控制器[30]。此控制器藉由修正在影像平面上特徵點位置，
能夠同時產生機器人移動平台與機械臂的速度控制命令，協調機器人上的機械臂到達與
目標相對的特定位置。因為攝影機使用 Eye-in-hand 的架設方式，遠端特徵點在攝影機
太靠近目標時無法使用，而近端特徵點因為影像系統解析度的限制，在離攝影機距離太
遠時無法被辨識出來。為了協調近端與遠端兩個控制器，我們利用 Behavior-based 架構
中的 Subsumption 架構來設計機器人的抓取行為：由於機器人距離目標遠近會決定視覺
伺服系統所用的影像特徵點，若抓取目標為移動式的物體，我們無法預測機器人會在何
種距離下偵測到目標物體。利用 Subsumption 架構，可以讓機器人在不同的目標距離下
快速切換適當的控制器行為，提高成功抓取的機會。 
 
DSK6416
FPGA
Daughter board
(Frame Buffer)
Daughter board 
(COM Port I/F) 
 
Gripper ICM205 CMOS sensor chip
CMOS sensor board
Industrial PC (IPC)
Power supply 
(DC-DC converter)
Battery
Foot & Head 
Motion Control
Battery
Arm motion control
CMOS sensor board
4 COM ports I/F
(COM1, 2, 3 & 4)
Embedded Imaging board
 
圖二. 影像平台及其在機器人上的配置 
 6
下，機器人只需稍微前進即可抓取到目標。 
6.2.3. 避障與抓取行為融合 
避障與抓取原先是互斥的行為，舉例來說，當人類站在前方想遞給機器人抓取物
體時，系統亦會將前方視為有障礙物。本計畫透過多代理人控制系統整合此二行為，便
可使機器人具備同時閃避與追蹤辨識目標物之功能。系統架構如圖六所示，即時影像系
統中混合式光流法所計算的 Time to contact(TTC)，條碼物體辨識得到目標物的位置與距
離視為環境與目標感測器代理人。機器人在 PC端設計追蹤及避障兩個行為代理人，並
由行為決策代理人控制此二行為代理人。 
在避障行為代理人的部分，根據 TTC 可以控制機器人前進的方向。由於 TTC 計
算必須在速度固定的前提下準確度最高，因此避障代理人亦會根據馬達軸編碼器
(Encoders)的回傳值決定目前收到的 TTC是否可信。追蹤行為代理人的則根據目標物的
中心和距離作影像伺服追蹤控制機器人，一方面調整角速度使目標物座標停留在影像平
面中央，另一方面根據距離調整線速度。當目標物進入夾爪時，嵌入式平台會自動控制
夾爪抓取物體。機器人執行時，此二行為同時計算出所達到目標需要的馬達控制命令。
透過代理人架構，行為決策代理人亦可以同時取得目標物的距離與 TTC，並以此來計算
兩者的融合比重。當目標物尚遠時以避障行為為主，而當目標物靠近時則以追蹤行為為
主。 
實驗結果如圖七所示，機器人行進中讓行人故意移動到其前方，分別如圖七(a)和
圖七(c)所示，機器人都能順利閃避行人，如圖七(b)和圖七(d)~(e)所示。而在圖七(e)避障
後發現目標物，則機器人一面持續避障，另一方面則朝向目標移動，並抓取目標，如圖
七(f) 最終機器人順利完成抓取。 
6.3. 即時物體分割、偵測與焦點移轉系統 
機器人如果要能與環境互動，就必須具備辨識環境中的所要互動之物體的能力。其
中一般性的物體影像辨識系統一直是這方面相當關鍵的技術。然而影像辨識的計算量龐
大、辨識率不高一直是其為人所詬病之處，對機器人的互動反應時間也相當不利。本計
畫基於人類實際上只會對畫面中的特定感興趣區域作詳細的辨別的概念，設計一物體偵
測與焦點移轉系統，可以根據互動行為的需要，即時選取可能為目標的區域，先追蹤目
標，再進行臉部辨識，一方面可以達成即時的影像追蹤，另一方面由於縮小了搜尋範圍，
可以提高辨識的速度以及辨識率。 
Obstacle 
Avoidance
Target 
Tracking
Foot motor 
Control
Decision 
Maker
Bar code 
Recognition
Optical flow 
estimation
Safety histogram target position on 
image plane
motor command
Image 
Acquisition
image image
Grasper 
Control
motor 
command
CMOS Image 
Sensor
6416 DSP-based
image 
processing 
board
Embedded IPC 
for Robot Control
 
圖六. 機器人避障與抓取行為融合系統 
 8
可以藉由多模追蹤器的資訊估測機器人與人的距離。最後，如果所有的感測器都無法偵
測到目標，則追蹤器會重新回到搜尋模式。 整合控制由本計畫研發出之多代理人系統
完成，透過工作管理員根據感測器代理人的資訊統整並指派任務，同時間頭部以及移動
平台的代理人依然能根據當前的工作目標持續對機器人的移動作即時的反應與控制。 
6.5. 多機器人之定位與協調控制 
延續單一機器人的互動控制系統，本計畫設計出一基於行為融合之多機器人協調控
制架構，如圖九所示。透過機器人間的溝通協調，建立符合任務需求的機器人行為變換
機制，使機器人團隊能更加適應各種不同的環境場合及狀態。結合多機器人間的影像系
統與無線通訊來實現此行為選擇架構，讓多機器人藉由靈活的行為變換來更容易地完成
複雜的團隊任務。  
為了使機器人間能夠更容易的觀測到彼此，本計畫使用全向式攝影機
(Omni-directional camera)做為機器人系統的影像 Sensor：傳統的攝影機一直有著 FOV 
(field of view)的先天限制，而全向式攝影機的出現解決了這個問題，不僅裝置簡單，且
有 360度的可視角度，避免觀測上的死角，使得隊形控制更加容易進行。 
圖十為多機器人協調控制之模擬結果，因為是基於行為模式之控制架構，機器人隊
伍會優先執行障礙物閃避的行為，直到障礙消失時才會回到隊形控制的行為模式。圖十
一則展示以全向式攝影機為視覺回授之多機器人隊形控制實驗結果，其中一台機器人
(Master)帶領前進，其餘兩台(Slave)則依影像回授資訊控制機器人本體的移動，維持三
角形的隊形移動[32]。 
在實際的導航任務中，除了閃避障礙物的功能外，定位的精確性，影響隊形控制及
導航的結果甚大。本計畫亦設計機器人在室內走廊的環境下完成自我定位的功能，圖十
二為基於全向式攝影機之機器人定位方法架構，主要使用 SIFT 演算法來擷取比對環境
中的特徵點，並以 EKF-based SLAM 完成機器人的定位與環境地圖的建立；比對兩張影
像中的特徵點，並基於特徵點的位置來估測出機器人的位置。SIFT 演算法具有：對抗
影像尺度大小改變的影響、特徵點描述具有對抗旋轉的特性、對於視角的改變有一定容
忍性…等特色。可配合用於機器人導航的目的，將位置相鄰的兩張全向式影像作比對，
以估測環境特徵點的位置，圖十三即是使用 SIFT 演算法之實驗結果，左右兩張影像相
差 45度，共比對出 47 個特徵點，證實此方法具有抗影像旋轉的功效。使用全向式攝影
機結合 EFK-SLAM 演算法，可建立出環境地圖及定位出機器人的位置。 
 
圖九. 基於行為之多機器人協調控制架構 
-5 -4 -3 -2 -1 0 1 2 3 4 5
-5 
-4 
-3 
-2 
-1 
0 
1 
2 
3 
4 
5 
X(m)
Y(m) 
R1 
R2 
R3 
 
圖十.多機器人協調控制模擬結果 
 10
縱系統，增加了機器人互動能力與實用性，設計出物體追蹤、避障、導航抓取等行為。
在行為融合設計上本計畫採用模糊類神經往路可根據環境參數如障礙物和目標的距離
等，計算各行為之比重以及資源分配，使機器人得以一面閃躲靜態與動態之障礙物，一
面朝向被辨識的目標前進。 
 
八、 結論 
 
本計畫之研究內容已達到預期目標，所發展之多代理人控制系統以及相關之互動控
制行為研究成果具有學術價值與實用性，已發表 6篇國際研討會及中華民國自動控制研
討會論文，較完整的論文近期內將投稿於學術期刊。 
 
九、 參考文獻 
[1] K. Konolige, K. L. Myers, E. H. Ruspini, and A. Saffiotti,”The Saphira Architecture: A 
Design for Autonomy”, J. of Experimental and Theoretical Artificial Intelligence, 1997, 
pp. 215-235 
[2] M. C. Neves and E. Oliveira , "ARCoS- An Autonomous Mobile Robot Control System", 
in Proc. of International Symposium on Engineering of Intelligent Systems, Tenerife, 
Spain, Feb 1998 
[3] M. C. Neves and E. Oliveira ,"A Multi-Agent Approach for a Mobile Robot Control 
System," in Proc. of Workshop on "Multi-Agent Systems: Theory and Applications" 
(MASTA'97 - EPPIA'97), Coimbra - Portugal, Oct 1997 
[4] M. C. Neves and E. Oliveira , "A Control Architecture for an Autonomous Mobile 
Robot," in Proc. of First International Conference on "Autonomous Agents" (AA'97) in 
Marina d'el Rey, California - USA, Feb 1997 
[5] M. C. Neves and E. Oliveira, "Fuzzy and Connectionist Paradigms in a Multi-Agent 
Control Architecture for a Mobile Robot," in The 3rd World Multi-Conference on Systems, 
Cybernetics and Informatics and The 5Th International Conference on Information 
Systems Analysis and Synthesis (SCI/ISAS'99) ,Orlando - Florida - USA, July 31-Aug 
4,1999 
[6] " About Jini.org, " [online] Nov. 2003, [cited Nov. 16, 2003], available from World Wide 
Web: < http://www.jini.org/about/jiniorg.html > 
[7] F. G McCabe, and K. L. Clark, “April—Agent Process Interaction Language,” in 
Intelligent Agents, Lecture Notes in Artificial Intelligence, 890, Wooldridge, M. J. and 
Jennings, N. R., Eds, Springer-Verlag, 1995, pp.324-340, 
[8] M. Lindstrom, A. Oreback, and H. I. Christensen, “BERRA : A Research Architecture for 
Service Robots,” in Proceeding of the IEEE Conference on Robotics and Automation, 
San Francisco, CA, USA, 2000, pp. 3278-3283 
[9] R. Volpe, I. Nesnas, T. Estlin, D. Mutz, R. Petras, and H. Das. “The CLARAty 
architecture for robotic autonomy,” in Proc. of the 2001 IEEE Aerospace Conference, Big 
Sky, Montana, March 2001. 
[10] H. Bruyninck, P. Soetens, and B. Koninck, “The Real-Time Motion Control Core of the 
Orocos Project,” in Proc. of the 2003 IEEE International Conference on Robotics & 
Automation, Taipei, Taiwan, September 14-19, 2003 
[11] J. Barraquand and J.C. Latombe, “Robot motion planning: a distributed representation 
approach,” The International J. of Robotics Research, vol.10-6, Dec. 1991, pp.628-649 
[12] B.Steer,”Trajectory planning for a mobile robot,” The International J. of Robotics 
Research, vol.8-5, Oct. 1989, pp. 3-14 
[13] C. Perrier, P. Dauchez, and F. Pierrot, “A Global Approach for Motion Generation of 
Non-Holonomic Mobile Manipulators,” in Proc. of the 1998 IEEE International 
Conference on Robotics & Automation, Leuven, Belgium, May 1998 
 12
Orlando, Florida, 2006, pp3624-3629 
[32] P. C. Sun, “Behavior-Based Multi-Robot Coordination Control,” M.S. Thesis, National 
Chiao Tung University, Hsinchu, Taiwan, Republic of China, 2005 
 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          96 年 9 月 29 日 
報告人姓名  宋開泰 服務機構及職稱 
 
國立交通大學電控系 
教授 
     時間 
會議 
     地點 
96/6/20~23 
美國佛羅里達州 
Jacksonnville 
本會核定
補助文號
NSC－95－2221－E－009－178 
會議 
名稱 
 (中文) 2007 年第七屆 IEEE 機器人與自動化之計算智慧國際學術研討會 
 (英文) 7th IEEE  International Symposium on Computational Intelligence in 
Robotics and Automation , CIRA2007 
發表 
論文 
題目 
(中文)1.運用自調式卡門濾波器之強健式機器人視覺追蹤控制系統 
      2.機器人情緒辨識系統之快速學習法則 
(英文) 1.Robust Mobile Robots Visual Tracking Control Using Self-Tuning 
Kalman Filter 
2. Fast Learning Algorithm for Robotic Emotion Recognition 
報告內容應包括下列各項：(請見下頁 ) 
一、參加會議經過 
 
 
二、與會心得 
 
 
三、考察參觀活動(無是項活動者省略) 
 
 
 
四、建議 
 
 
 
 
五、攜回資料名稱及內容 
 
 
六、其他 
 
 
 
 
 
附件三
 
