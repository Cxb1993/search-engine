一、前言 
數位內容乃政府近年來兩兆雙星的重點發展領域，數位內容的核心技術則以
多媒體系統為主。本計畫嘗試想研究的則是多媒體之風格化的相關議題，其
實有關此議題的研究其來有自，從早期的語音合成，到較近期的將相片轉化
成印象派的畫作[35,36]，都可視為與此議題相關的研究。前者可視為個人化
的範例，而後者則可視為風格化的範例。本研究的重點除了持續加強過往的
研究方向外，與之前的研究不同的是對各媒體個人化，風格化，及客製化的
整合探討。例如，個人化的語音合成研究已行之多年，但有關語音的風格化
卻較少著墨。典型的例子是如何將年輕人的聲音變得蒼老，老人的聲音變年
輕；如何將男人的聲音變得娘娘腔或將女人的聲音變得雄糾糾；如何讓聲音
變得輕快或沉重等，說穿了是要進行聲音的風格化。另一個具體的例子是如
何模仿某人畫圖或寫字的樣子，說穿了是要進行繪圖或寫字的個人化。換言
之，所謂整合性探討的意義即探索目前已有的風格化研究領域中較少或尚未
被觸及的方向。另一方面，由於多媒體所涉內容過多，我們的重點計劃方向
將有以下兩方面：一、影像風格化，二、動作表情風格化，以下分項細述之。 
 
一、 影像風格化：相較於聲訊合成，在影像風格化方面近年來則研究成
果豐碩。其中最有關莫過於非擬真著色。有關非擬真著色的研究可分兩
大部分，其一是將既有影像做風格轉換，使之成為風格別具之影像，例
如轉成一張具印象派風格的繪畫[35,36];其二是設計一繪畫介面，模擬真
實系統之特定畫筆，顏料及紙張在符合物理定律之相互作用下
(physics-based rendering)作畫之風格，例如可以模擬使用毛筆在宣紙下之
水墨畫的效果[38,39]。由於影像風格化發展相對較成熟，除了持續探討
一些尚未被研究的風格外，研究重點將放在於影像個人化的部分。具體
來說，我們希望將某特定人士之繪畫風格(包括用色，筆觸等)粋取出來，
以此風格應用至任意影像上，達成個人化之目的。也可以嘗試以個人化
的風格為主，搭配某特定的風格做變化，或者其他可能的混合等。另一
個有趣的方向是觀察年紀，性別，甚至情緒等對風格的細微影響，以作
為影像風格化的參考。除此之外，還有可能研究方向包括與所謂的數位
鑑識(digital forensics)中的影像鑑識結合，以其中的專家系統(expert 
systems)或知識庫(knowledge databases)作為影像特徵擷取的參考。 
二、 動作表情風格化：與以上研究領域截然不同，但也可以做風格化的
多媒體主要是在動畫或視訊方面，例如人物角色的動作及(說話)表情。
近年來在電腦圖學上有關人物動作的合成上已有長足的進展，這主要是
藉由「動作擷取」(motion capture)的一些硬體裝置上我們累積了大量人
體動作資訊[33,34]，再將這些資訊經處理後「移轉」(re-targeting)或套用
在一般化的 3D 人體模型上，於是就產生了動作[42]，有關人物的表情，
甚至說話時口鼻部分的牽動亦可採用類似的技術。有關動作的風格化也
曾是研究的對象[45]，例如走路可以採大跨步或是躡手躡腳等方式，笑
的時候可以是微笑或是開懷大笑等。本計劃的研究重點將在動作表情的
個人化，或是如同前述媒體般以個人化為基礎，再混合其他特定風格。
再者也如同前述媒體般，探討年紀，性別等因素對風格化可能的影響。 
愈來愈多的人懷念以前收到手寫信的感覺。對此，我們可以設計一個電子郵
件系統，在學習了個人的筆跡後，將所有電腦打字的內容替換為手寫筆跡後
再以影像檔的方式寄出，即可以達到模擬的效果。3.個人化表情系統：現今
利用 VOIP 的技術進行網路交談已愈趨流行，並有許多軟體已有支援視訊的
功能。然而在網路上傳輸視訊畢竟仍需較高的頻寬，在某些環境下可能無法
配合。一個可能的替代方案是在一端以 web cam 偵測交談者的表情，並將偵
測結果傳至另一端進而自動合成該交談者的相關表情。如此所需要的僅是該
交談者的表情資訊，或是以本計畫的術語而言，表情的風格化資訊，則可以
達到相當於是十分高效率之「資料壓縮」的功能。4.書寫美化及學習：一個
能學習各類書寫風格的系統，也可以在結合手寫辨認的功能下提供其他有趣
的服務：使用者的手寫筆跡輸入若過於潦草拙劣，可以予以美化(例如可對齊
前後的字，將歪曲的筆劃做修正，將大小奇異過大的字做調整等)，或者由風
格資料庫中找出具最相近風格的書寫風格予以混合。另外，具風格資料庫的
系統亦可用來作書法訓練用，例如想學王羲之的字體，一旦開始寫任意的一
個字，系統即可辨識使用者的輸入與王羲之風格之筆跡的差距，進而給出建
議。如此的「嘗試—建議—修正」的訓練過程應對學習十分有幫助。除以上
應用外，有於個人化與風格化的密切關係，我們相信風格化的研究對「數位
鑑識」中的「身分鑑識」而言也將產生重大助益。另一個由風格化研究所可
能導引出是「個人風格之智慧財產權」的問題。一旦個人之風格可被學習，
就可能遭剽竊與盜用，故如何保護個人風格之智慧財產權將會是一個重要的
課題。 
三、文獻探討 
此處我們將針對前述與本計劃之主要關鍵技術其相關研究部分進行探討，也
將對於之前許多尚未解釋清楚的部分作進一步的闡釋。需要強調的是，由於
所涉文獻範圍過多，此處將僅針對與本計劃較相關之部分作探討，若對未提
及之相關研究之細節部分有興趣者可參閱之後參考文獻的部分。 
一、 多媒體資訊分群及分類：在進行風格化的過程中，將所蒐集資訊進
行分群或分類實屬必要。由於近年來機器學習(machine learning)領域的
長足進步，使得這方面技術的發展更臻成熟。在分群方面，較常用的方
式有 K-mean 分群法，混和高斯(Gaussian mixtures)，以及採用階層式分
群概念的 UPGMA (unweighted pair-group method with arithmetic mean)演
算法等。至於在分類方面，常用的有決策樹(decision tree)，支撐向量機
(SVM，support vector machine)，簡易貝式(Bayesian)模型等，也可以將
各方法綜合起來，採取多重策略法(multiple strategy approach)。 
二、 多媒體資訊裁減：主要採用降低維度的方式，但又因降低維度的方
法有許多，故此處將僅探討一些較可能採取的方法，包括主成份分析
(PCA), 獨立成份分析(ICA)，局部線性嵌入(LLE)及奇異值分解(SVD)等。 
三、 多媒體資訊合成：因各媒體之處理不同，以下分別就各媒體探討之。 
甲、 影像合成：此處相關研究最多者應為在各式風格下的影響轉
換，例如有關非擬真呈像(non-photorealistic，或 NPR)的研究[35,36]，
更具體的例子是將一張相片轉換為印象派(impressionism)或水墨或
素描般的的畫作[36]，以下簡介三篇重要的相關論文： 
如曲線類比。見圖三(引用自同篇論文)：基本上還是透過 A：A’ 
= B：B'由 A，A’及 B 來決定 B’的線條應該如何變化。 
 
圖三(引用自[54]) 
 
乙、 動作表情合成：不論是動作或表情，近年來的基本做法，是採
用動作捕捉器(motion capture)，見圖六，同時也藉助分析肌肉與動
作或表情之關係，所以可能涉及解剖學(anatomy)等相關知識，來將
動作表情與身體的特徵部位作連結，見圖七。此處我們就表情與動
作分別作探討。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖六 
 
 
 
 
 
 
 
 
 
 
圖七 
• 表情合成： 
 
圖十(引用自[45]) 
 
四、研究方法 
 
研究方法與原因： 
本計畫的目的在研究多媒體的個人化，風格化及客製化。因內容所涉過多而時間
有限，我們將以聲訊，影像，書寫筆跡及動作表情為主，以下分別就各類媒體其研
究方法詳述之。在這當中，有一個十分重要的中心議題有待探討：何種分類分群及
維度降低方法較適用於何種媒體。注意到若要進行個人化，可能需就同一使用者蒐
集較多且稍具跂異性的資訊，並在分群或分類時採用較細緻的處理。若進行風格化，
一個可能的做法是可就部分使用者的資訊先做分群，也就是先找出具有明顯不同風
格的群落，皆接著再搭配分類的方法，將其餘使用者作分類。至於資訊裁減，可以
搭配分類及分群的方式反覆執行。例如可以先執行 PCA 或 SVD 來減少資訊量，進
而提升分群或分類的效率及精確性。 
一、影像風格化：如之前研究背景所言，目前對於一般影像風格化的研究已十分
盛行，尤其在前述相關研究部分所提之影像類比[37]的技巧，已可解決許多具
各式風格的影像合成問題的情況下，因此本計劃除了延續風格化的研究，但
將焦點置於前人較少研究的方向外，另一重點將放在影像的個人化上，更具
體地說，我們希望捕捉的是個人的用色及筆觸等習慣，以便能更精確地掌握
與複製個人化的風格，則將來一方面可將個人的風格更突顯，另一方也可透
過風格的混合或處理替未來做更精緻的影像客製化鋪路。 
 
  
圖十八 
 
甲、影像資訊蒐集：有關影像風格化通常其整張影像即為蒐集的資料，但這
其中有一些議題要注意。首先，並非所有的影像原本即為數位的形式，
故可能涉及數位化的過程，這當中掃描(scan)是常見的方式，但要注意的
是色彩可能因此產生偏差，故需仔細地進行色彩校正(color correction)。
同時，所用的紙張材質，大小，顏色，所用的畫筆種類等都需詳細紀錄，
好。至於有關筆觸的部份則可能需要先做邊緣偵測(edge detection)，才容
易將線條或筆劃取出，見圖十八，其中左圖為一輸入之花朵圖，其右則為
放大的做過 Canny[56]邊緣偵測法後的結果。此處我們必須指出，由於影
像類比係採用材質合成(texture synthesis)[51,52]的做法，故對於較小鄰域
(neighborhood)的掌握較好，但對於較全域性的結構則常無法捕捉。故若
在用色或筆觸有牽涉較大範圍者，可能還是得先經過處理後較容易將相關
特徵先取出。至於對特殊畫派的處理，其方式也可能大不相同，必須視情
況而定，例如梵谷圖中的筆觸線條及畢卡索圖中的立體形狀等，可能都需
先透過人為的仔細觀察，再設法模擬之。此外，還有顏色的轉換也十分重
要，例如將原本 RGB 的顏色轉換至 HSV 的顏色系統，使得更顏色的彩度
(hue)，飽和度(saturation)及明亮度(value 或 brightness)變得更容易。 
  
  
  
 
輸入影像
 色彩空間轉換
 
 測邊 色彩擾動 區域分割
 
 輪廓
 
 折邊 背景層
 
中間層
 
 輪廓強化
 
 摺邊強化
 
補色 
 輸出影像
 
圖二十一 
 
乙、影像資訊合成：若合成的方式並非採用影像類比，則在經過資訊處理，
資訊分類，分群及資訊剪裁後，即可進行合成。此處以我們曾嘗試過的
秀拉點畫派的模擬做為例子，說明影像合成時可能需經過的步驟，當然
我們也必須強調，每一種影像風格可能有其獨特性，需要特殊處理。以
秀拉的畫而言，其最大的特色有四：第一，點(point)為其主要繪畫元件
(primitive)，改變點的大小，形狀，位置，顏色等屬性讓此成為可能。第
二，秀拉所用來著色的顏色數十分地少，有所謂的十一原色的說法，圖
十九所示即是秀拉所用的調色盤，而顏色的多元化主要是透過並置
(juxtaposition)或所謂的分光主義(divisionism)來達成，也就是類似電腦圖
學中的 dithering 的技巧。第三，秀拉的人、物邊緣輪廓(silhouette)經常烘
 
圖二十九 
ii. 特徵點的擷取(feature selection)：透過全自動的方式，如五官自動定
位，或半自動的方式，如先由使用者概略圈出五官，再利用如主動
式輪廓 (active contour)法[43]等，將五官以控制點標出，見圖二十
九，以進行後續的處理。 
iii. 三角化(triangulation)：當我們從前面的步驟中取得眼睛、眉毛、嘴
巴的控制點後,我們希望能進一步將眼睛、眉毛、嘴巴的區域做三角
化，如圖三十。作三角化可以方便我們在之後控制局部變形的幅度;
另外,為了考慮變形後的眼睛、眉毛、嘴巴這些區域與周圍臉部皮膚
之間由於差異性不一而產生不自然的現象，因此,我們在眼睛、眉毛
之間做三角化也在眼睛、眉毛及嘴巴周圍作三角化，也就是當眼睛、
眉毛、嘴巴區域做變形的同時,周圍區塊的控制點只要有被改變的可
能則也要做變形的修正。 
 
 
圖三十 
至於動作資訊處理部分，也是十分類似，只是將特徵部分更換為身體的
關節或端點部位。另外要注意的是，我們此處係以 2D 的處理做例子，若
是處理 3D 的動作表情，則需對 3D 的特徵做處理。 
 
[6] Freund, Y. and Schapire, R. E. (1997). “A decision-theoretic generalization of on-line 
learning and an application to boosting”, Journal of Computer and System Science, 55: 
119–139. 
[7] Freund, Y., and Schapire, R. E. (1999). “A short introduction to boosting”, Journal of 
Japanese Society for Artificial Intelligence, 14(5): 771–780. In Japanese and translated by 
Naoki Abe; English version at http://www.research.att.com/~schapire/cgi-bin/ 
uncompress-papers/FreundSc99.ps 
[8] Frey, B.J. (1998). Graphical Models for Machine Learning and Digital Communication, 
Cambridge: MIT Press. 
[9] Hyvärinen, A. and Oja, E. (1999). “Survey on independent component analysis”, Neural 
Computing Surveys, 2: 94—128. 
[10] Hyvärinen, A., Jarhunen, J. and Oja, E. (2001). Independent Component Analysis, John 
Wiley & Sons. 
[11] Jensen, F. V. (2001). Bayesian Networks and Decision graphs, Springer-Verlag, New York. 
[12] MacQueen, J.B. (1967). “Some Methods for classification and Analysis of Multivariate 
Observations”, Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and 
Probability, Berkeley, University of California Press, 1: 281–297. 
[13] Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, E. (1953). 
“Equation of state calculations by fast computing machines”, Journal of Chemical Physics, 21: 
1087—1092. 
[14] Mitchell T. (1997). Machine Learning, McGraw Hills. 
[15] Pao, H.-K., Chang, S.-C. and Lee, Y.-J. (2004). “Model trees for classification of hybrid 
data types”, 6th International Conference on Intelligent Data Engineering and Automated 
Learning. 
[16] Quinlan, J. R. (1993). C4.5: Programs for machine learning. San Mateo, CA: Morgan 
Kaufmann Publishers. 
[17] Roweis, S. T. and Saul, L. K. (2000). “Nonlinear dimensionality reduction by locally 
linear embedding”, Science, 290(22): 2323—2326. 
[18] Scholköpf, B., Smola, A. and Müller, K. (1998). “Nonlinear component analysis as a 
kernel eigenvalue problem”, Neural Computation, 10: 1299—1319. 
[19] Schoelköpf, B., Burges, C. and Smola, A. (1999). “Kernel principal component analysis”, 
Advances in Kernel Methods - Support Vector Learning, 327—352. MIT Press, Cambridge. 
[20] Tenenbaum, J. B., de Silva, V. and Langford, J. C. (2000). “A Global Geometric 
Framework for Nonlinear Dimensionality Reduction”, Science, 290(22): 2319—2323. 
[21] University of California, Berkeley, Meta-search engines. 
(2000). http://www.lib.berkeley.edu/TeachingLib/Guides/Internet/MetaSearch.html. 
[22] Vapnik, V. (1995). The Nature of Statistical Learning Theory, Springer Verlag, New York, 
1995. 
[23] Vapnik, V. (1998). Statistical Learning Theory, John Wiley and Sons, New York, 1998. 
[24] Wainwright, M. J. and Jordan, M. I. (2003). “Graphical models, exponential families, and 
variational inference”, Technical Report 649, Department of Statistics, University of California, 
Berkeley. 
[25] Thomas G. Dietterich. Ensemble learning. In The Handbook of Brain Theory and Neural 
Mixtures". Conference in Uncertainty in Artificial Intelligence (UAI). 
[48] Sneath, P.H.A. and Sokal, R.R. (1973) in Numerical Taxonomy (pp; 230-234), W.H. 
Freeman and Company, San Francisco, California, USA. 
[49] Fukunaga, Keinosuke. " ((1990). Introduction to Statistical Pattern Recognition. Elsevier.". 
[50] Abdi, H. "((2007). Singular Value Decomposition (SVD) and Generalized Singular Value 
Decomposition (GSVD). In N.J. Salkind (Ed.): Encyclopedia of Measurement and Statistics. 
Thousand Oaks (CA): Sage.". 
[51] Michael Ashikhmin. Synthesizing Natural Textures. 2001 ACM Symposium on 
Interactive 3D Graphics, pages 217–226, March 2001. 
[52] Li-Yi Wei and Marc Levoy. Fast Texture Synthesis Using Tree-Structured Vector 
Quantization. Proceedings of SIGGRAPH 2000, pages 479–488, July 2000. 
[53] I Drori, D Cohen-Or, H Yeshurun – “Example-based style synthesis”, Computer Vision 
and Pattern Recognition, 2003. 
[54] A Hertzmann, N Oliver, B Curless, SM Seitz - Proceedings of the 13th Eurographics 
workshop on Rendering, 2002. 
[55] 林欣儀，簡筮哲，林志穎，顏士華，“卡拉OK數位人聲導唱系統”, Technical Report, 
2005. 
[56] J. Canny A Computational Approach to Edge Detection, IEEE Transactions on Pattern 
Analysis and Machine Intelligence, Vol. 8, No. 6, Nov. 1986. 
[57] R. Gonzalez and R. Woods Digital Image Processing, Addison-Wesley Publishing 
Company, 1992, pp 518 - 548. 
[58] Chuan-kai Yang and Li-kai Peng, “Automatic Mood-Transferring between Color Images”, 
IEEE Computer Graphics and Applications 28(2):52-61, 2008. 
[59] Chuan-kai Yang and Wei-ting Chiang, “An Interactive Facial Expression Generation 
System”, Multimedia Tools and Applications 40(1):41-60, 2008. 
[60] Chuan-kai Yang and Hui-lin Yang, “Realization of Seurat’s Pointillism via 
Non-Photorealistic Rendering”, The Visual Computer 24(5):303-322, 2008. 
 
 
