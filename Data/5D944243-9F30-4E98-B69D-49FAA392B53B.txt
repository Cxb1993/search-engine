行政院國家科學委員會補助專題研究計畫
■ 成 果 報 告
□期中進度報告
音樂搜尋的加速與辨識率提升，及其在嵌入式系統的
實作與應用
計畫類別：■ 個別型計畫 □ 整合型計畫
計畫編號：NSC95-2221-E-007-220
執行期間：2004 年 8月 1日至 2007 年 7月 31 日
計畫主持人：張智星
共同主持人：
計畫參與人員：博士班研究生-兼任助理：林政源、陳江村、許肇凌、陳
致生
成果報告類型(依經費核定清單規定繳交)：□精簡報告 ■完整報告
本成果報告包括以下應繳交之附件：
□赴國外出差或研習心得報告一份
□赴大陸地區出差或研習心得報告一份
■出席國際學術會議心得報告及發表之論文各一份
□國際合作研究計畫國外研究報告書一份
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢
□涉及專利或其他智慧財產權，□一年■二年後可公開查詢
執行單位：
附件一
研發成果推廣單位（如技術移轉中心）。
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
※ 3.本表若不敷使用，請自行影印使用。
entries for digital library applications. This is due to either excessive complexity in computation (which
leads to a long response time) or performance degradation (which leads to erroneous retrieval results).
Striking a balance between computation and performance is the ultimate goal for such retrieval systems, as
there are some speedup mechanisms proposed for melody recognition [4][5][15]. However, most of the
previously proposed methods still fall short of detailed analysis on the tradeoffs between efficiency and
effectiveness. Therefore, this paper proposes the framework of progressive filtering (PF) with an efficient
design method that can achieve statistically the maximum recognition rate within a given response time
constraint.
The proposed approach is applied to a QBSH system with a database of 13,320 songs, which is suitable
for commercial karaoke applications that usually hold a song database of 5000~20,000 entries. The
experimental results demonstrate that the proposed method can be used to construct an effective
multi-stage music retrieval system based on singing/humming input. Moreover, it should be noted that the
proposed framework of PF is actually a general methodology that can be applied to any multimedia
information retrieval system using the same strategy of design and analysis.
The rest of this paper is organized as follows. Section 2 introduces the concept and formulation of PF,
and proposes the corresponding design method using dynamic programming. Section 3 introduces the
recognition methods used at each stage for our multi-stage QBSH system. Section 4 describes the
experiments and the corresponding results. Finally, Section 5 gives the conclusions and addresses
important future directions for this work.
the use of multi-stage PF for QBSH but with little design analysis. Moreover, Jang and Lee [14] have
proposed a simplified version of PF with a constant computation time with respect to survival rates for
each recognition method recently. In this paper, we shall propose a general framework of PF, together
with the mathematical formulation of its design and analysis that take the full characteristics of each
underlying recognition/comparison method into consideration.
B. Mathematical Formulation of PF
The multi-stage representation of PF is shown in Figure 1, where there are m stages, corresponding to
m different recognition/comparison methods with varying complexity. For stage i , the input is the query
and 1in surviving songs from the previous stage; the only tunable parameter is the survival rate is ,
which is between 0 and 1. The output of stage i is a reduced set of candidate songs of size iii snn 1
for the succeeding stage 1i . In other words, each stage performs a filtering process that reduces the
number of the candidate songs by a factor of the survival rate is . The delay time id of stage i can be
expressed as iiii stnd 1 , where ii st is the normalized computation time (or one-to-one
computation time) that represents the average time required to compute the distance between a query and a
song in the candidate pool of stage i . As a result, we have the following expressions:
,
,
1
2101
iiii
iiii
stnd
sssnsnn



 
(1)
where nn 0 is the original database size, and mn is the number of songs in the final output list.
  00 ir and  11 ir , .i
 A method with better discriminating power should have an RS curve with a steep slope initially
followed by a gentle slope close to zero finally.
 A method of random selection has an RS curve with a slope equal to 1.
The RS curve of a given stage is statistically determined by a large amount of query data
(singing/humming input) with labeled outputs (the ground truth). In other words, here we are using a
data-driven approach to construct a numerical approximation to the RS curve. Ideally, if we have infinite
amount of data, the approximation can approach the real RS curve seamlessly:
  srnsr iin  ,ˆlim ,
where sri is the true RS curve for stage i while  nsri ,ˆ is the estimated RS curve using n queries.
However, the value of n is always finite in the real word and we shall use  nsri ,ˆ to approximate
sri in this paper. For simplicity, we shall use sri instead of  nsri ,ˆ in the following discussion.
On the other hand, the efficiency of a given stage can be represented by a TS (time vs. survival rate)
function st i which is the normalized computation time for stage i when the survival rate is equal to
s . If we are using a simple linear comparison, then the plot of st i should be a constant since the
normalized time is independent of the survival rate s . However, this is not the case when we employ
some speedup techniques. Commonly used speedup schemes are listed next.
1) Premature termination: During the comparison between a query and a song, if the accumulated
distance is already larger than a top-n threshold (where n is the number of output candidates for a
stage), then terminate the comparison immediately and move on to the next song.
2) Indexing for distance metrics that satisfy the triangle inequality: There are numerous indexing
follows.
Generally speaking, there are two constraints for the overall system from the viewpoint of a practical
real-world application.
 The first constraint states that the maximum allowable overall response time should be less than or
equal to a constant maxT . This is equal to the user’s waiting time after the query is issued, which
should not be too long (say, less than 5 seconds) in order to make the system practical for end users.
 The second constraint states that the number of the final output songs should be equal to a small
integer such that the user can browse the returned song list easily. We shall set it to 10 throughout
the discussion in this paper.
These two constraints can be expressed by the following equations:
    




 
10321
max121332122111
m
mmm
sssns
Tstssnsstsnsstnssnt

 (2)
The objective function is the overall recognition rate:
  mmm srsrsrsssR  221121 )(  (3)
It is hard to solve such an optimization problem directly. Fortunately, this is a multi-stage sequential
optimization problem and we can develop an efficient solution based on dynamic programming. In
particular, we define the optimum-value function  tsRi , as the optimum overall recognition rate from
stages 1 to stage i , with a cumulated survival rate s and a cumulated computation time less than or
which each of the optimum set of survival rates is identified by dynamic programming, such that the best
configuration of m-stage PF with q possible recognition methods can be identified.
III. RECOGNITION METHODS FOR QBSH
This section describes several common recognition methods that can be used for each stage in PF for a
QBSH system. It should be noted that each method is legitimate for melody recognition, with varying
degrees of efficiency (in terms of computation time) and effectiveness (in terms of recognition rates).
However, we do not attempt to elaborate on optimization of these methods since our primary goal is to
demonstrate the use of these methods within the framework of PF.
A. Range Comparison
Range comparison is an efficient but less effective method that can eliminate unlikely songs quickly.
That is, a song is eliminated if the range of the query input (in terms of semitones) is different from that of
the song by a given threshold. In symbol, a song c is eliminated if the following condition is satisfied:
 )()( crangeqrange (6)
where )(qrange is the pitch range of the query input q , defined as the difference between the maximum
and minimum of q . Similarly, )(crange is the pitch range of the first several notes (whose total duration
is equal or close to that of q ) in a candidate song c . All rests are removed before computing the range.
It should be noted that all statistical ensemble parameters, such as range, variance, high-order
momentum, and so on, can be used for such fast elimination of unlikely candidates. Moreover, it is
The distance measure used in linear scaling is the Euclidean distance with length normalization. To
achieve key transposition, we can simply shift both pitch vectors to zero mean before invoking distance
computation. The RS and TS curves of this stage are shown in Figures 4 and 5, respectively, which
indicate that linear scaling is both efficient and effective.
C. Edit Distance
In order to perform edit distance [3], we need to segment the query pitch vector into music notes. This is
done by using a two-step approach:
1) A new music note is established whenever the difference between the current and the previous pitch
element is greater than 0.7 semitones. The pitch of a music note is the median of its pitch elements.
2) If a music note has a duration less than 0.1 second, it is merged to its neighboring note that is closer
(in terms of pitch difference) to the current one.
A typical example of music note segmentation is shown in Figure 3.
Fig. 3. A typical example of music note segmentation.
Frames







)2,1(
)1,1(
)1,2(
min|)()(|),(
jiD
jiD
jiD
jritjiD . (8)
The recurrent relation shows that the optimal path exists only when the test input is within half to twice
the size of the reference vector. This constraint is reasonable since it is rather difficult to sing/hum a song
faster than twice or slower than half the speed of the intended song.
For this study, we assume the user always sings/hums from the beginning of a song. The corresponding
boundary conditions of this "anchored beginning, unanchored end" case are:






.|)1()1(|)1,1(
,,...,2,),1(
,,,2,)1,(
rtD
njjD
miiD 
(9)
Before invoking DTW we need to consider key transposition. This is taken care of by a heuristic
approach that involves 5-time pitch translation around the mean [4].
Another popular formula for DTW is based on the following recurrent formula:







)1,(
)1,1(
),1(
min|)()(|),(
jiD
jiD
jiD
jritjiD (10)
However, our experiment shows that DTW of this type does not perform as well as the formula in
Equation (8) for query by singing/humming. The top-1 recognition of this DTW is about 2% lower than
the one in Equation (8). Therefore we shall use the formula in Equation (8) for DTW in this stage. The RS
8000/256 = 31.25. In other words, an 8-second singing clip is converted to a pitch vector of 31.25*8 = 250
elements in semitones, where the frequency to semitone conversion is based on the formula:
69
440
log*12 2 


 freqsemitone (11)
Rests or silences in a pitch vector are either removed or replaced by the previous nonzero elements,
depending on the recognition method used for a specific stage.
500 clips of the singing corpus are used as the training data for obtaining the RS and TS curves for each
recognition method. The remaining clips in the corpus are used as the test data for verifying the proposed
approach. Since the focus of this paper is on PF, all the computation time referred to in this paper does not
contain the time for pitch tracking.
Each singing clip in the corpus starts from the beginning of the target song. Therefore, our music
retrieval task in this paper corresponds to the case of “anchored beginning, unanchored end” or simply
“anchored beginning”. This is ideal for certain applications, such as the retrieval of ringback songs where
the input singing clip should match the references from the beginning since there might be several pieces
of ringback tones selected from a song. On the other hand, for the retrieval of karaoke songs, we need to
be able to extend the proposed method to the case of “unanchored beginning, unanchored end” or simply
“anchored anywhere”. This can be simply achieved by taking the beginning of each note in a song as a
potential beginning position for the comparison of“anchoredbeginning”. In other words, if each reference
melody has 20 notes, then the comparison of “anchored anywhere”for a melodic database of size 100 is
equivalent to the comparison of “anchored beginning”for a database of size 2000. It seems that the
(a) RS curves with the survival rate from 0 to 100%
(b) RS curves with the survival rate from 0 to 1%
Fig. 4. (a) RS curves of the five recognition methods (range comparison, edit distance, DTW/2, linear
scaling, and DTW) introduced in Section III. An effective method is usually characterized by its initial
sharp slope, such as the RS curve of DTW. (b) A close-up view of (a) with the survival rate in the range [0,
1%], such that we can examine the details of each RS curve when the survival rate is small.
to the survival rate, then it would require about 19.27137.5
100
100
37.5
100
2
37.5
100
1  
hours to obtain a TS curve of 100 points. As a result, we need to reduce the reference song database to one
tenth of its original size in order to obtain the TS curves in a timely manner. For performance evaluation
on the test data set, the full-sized song database was used.
Moreover, it should be noted that the problem of over-training does not really happen since we are only
using the training data to obtain each method’s characteristics(RS and TS curves), instead of manipulating
the data in a highly optimized manner as to find optimum parameters for each method to boost the
system’s overall recognition rate.
C. The Assignment of a Recognition Method to Each Stage
Once we have the RS and TS curves of each recognition method, we need to put them into multi-stage
PF for QBSH. Intuitively, the beginning stage should eliminate unlikely candidates in an efficient manner,
and the ending stage should identify the most likely candidates in an effective manner, but possibly
requiring more computation time. Fortunately, the DP-based design method for PF is very efficient, so we
can try all kinds of method-to-stage assignment exhaustively. In other words, we can have all possible 120
( = 12345  ) permutations of the five recognition methods for 5-stage PF where the best survival
rates are identified by DP. Table 1 lists the results of the best assignment of the recognition methods under
various values of maxT . Except for 2max T where stages 4 and 5 are not used (due to insufficient
allowable time), all the other larger values of maxT correspond to the best assignment of range
comparison as stage 1, linear scaling as stage 2, edit distance as stage 3, DTW with down-sampled input
as stage 4, and DTW as stage 5. This is exactly as expected: quick but ineffective methods are used first;
TABLE 1.
BEST ASSIGNMENT OF RECOGNITION METHODS UNDER VARIOUS VALUES OF maxT
Best method for each stage and the corresponding survival rates
maxT
1 2 3 4 5
Predicted
RR
Test
RR
2 Range
comparison
(89.53%)
Edit
distance
(95.61%)
Down
sampled
(33.73%)
Linear
scaling
(0.26%)
(Not used) 34.61% 35.33%
5 Range
comparison
(93.45%)
Edit
distance
(90.41%)
Down
sampled
(29.62%)
Linear
scaling
(0.30%)
(Not used) 58.80% 62.11%
10 Range
comparison
(100%)
Edit
distance
(86.81%)
Down
sampled
(20.15%)
Linear
scaling
(10.01%)
DTW
(4.29%)
74.24% 71.64%
15 Range
comparison
(100%)
Edit
distance
(84.03%)
Down
sampled
(18.01%)
Linear
scaling
(10.35%)
DTW
(4.79%)
81.74% 78.92%
D. Recognition Rates vs. Computation Time
One of the major advantages of PF is its scalability. That is, given an overall time constraint, the overall
recognition rate can always achieve its highest possible value (statistically) via the adjustment of the
survival rate at each stage. Therefore it will be interesting to see how the recognition rates degrade with
decreasing allowable computation time. In this experiment, we assume the assignment of recognition
methods are: range comparison (stage 1), linear scaling (stage 2), edit distance (stage 3), DTW with
down-sampled input (stage 4), and DTW (stage 5). Figure 6 demonstrates the curves (including predicted
and actual) of the recognition rates vs. computation time. The predicted recognition rates are obtained
from the training data set, while the test recognition rates are obtained from the test data set. Deviations
between these two curves mostly come from the statistical differences between the training and test data
sets. In other words, the deviations mostly come from the differences of RS/TS curves between the
Fig. 7. Survival rates vs. required computation time. The upper plot shows the individual survival rates of
each stage w.r.t. computation time. The lower plot shows the accumulated survival rates of each stage w.r.t.
computation time.
In Figure 7, if a stage is missing for a given required computation time, then the stage is not used at all,
or the stages have a 100% survival rate. For instance, when the overall computation time is 1 second, both
stages 4 and 5 are missing since these two stages (for down-sampled DTW and full DTW) are simple too
time consuming to be included in the comparison process. In general, if the required computation time is
shorter than or equal to 5 seconds, some stage will have a survival rate of 100%, indicating that the stage
is not used at all.
 We only applied premature termination for speeding up each recognition method. In Fact, we
can apply some other more efficient indexing techniques for linear scaling [10] or DTW
[8][11]. This will make the corresponding TS curves more efficient.
 If we have a lot more recognition methods, then the assignment based on exhaustive
permutation would not be feasible. An efficient algorithm for method-to-stage assignment is
one of our immediate future directions of research.
 The computation of RS and TS curves is time consuming when the number of test queries or
song database is large. How to select representative subsets from the test queries and the song
database, respectively, for fast derivation of RS and TS curves is also an important task for
our future work.
 In this paper, we assume the independence among various recognition methods to facilitate
the derivation of DP. In reality, correlation among methods can affect the assignment of
methods to stages. Such “second-order effects”is considered essential future work for more
detailed analysis of PF.
REFERENCES
[1] A. J. Ghias, D. C. Logan and B. C. Smith, “Query by humming-musical information retrieval in an
audio database”, ACM Multimedia ’95, San Francisco, 1995.
[2] J. R. J. G., Proakis and J. H. L., Hansen "Discrete-time processing of speech signals," New York,
Macmillan Pub. Co., 1993.
[11] C. A. Ratanamahatana and E. Keogh, “Three Myths about Dynamic Time Warping”, In
proceedings of SIAM International Conference on Data Mining (SDM '05), Newport Beach, CA,
April 21-23, pp. 506-510, 2005.
[12] J.-S. R. Jang, "QBSH: A Corpus for Designing QBSH (Query by Singing/Humming) Systems",
available at the "QBSH corpus for query by singing/humming" link of the “Corpus page”at the
organizer's homepage at http://www.cs.nthu.edu.tw/~jang.
[13] J.-S. R. Jang, H.-R. Lee, M.-Y. Kao, "Content-based Music Retrieval Using Linear Scaling and
Branch-and-bound Tree Search", IEEE International Conference on Multimedia and Expo, Waseda
University, Tokyo, Japan, August 2001.
[14] J.-S. R. Jang, and H.-R. Lee, "An Initial Study on Progressive Filtering Based on Dynamic
Programming for Query by Singing/Humming", The Seventh IEEE Pacific-Rim Conference on
Multimedia, Zhejiang, China, Nov 2006.
[15] X. Wu, M. Li,“A Top-down Approach to Melody Match in Pitch Contour for Query by Humming”,
The 5th International Symposium on Chinese Spoken Language Processing, Singapore, Dec. 2006.
[16] D. Mazzoni and R. B. Dannenberg, “Melody Matching Directly From Audio”, International
Symposium on Music Information Retrieval 2001, Bloomington, Indina, USA, Oct 2001.
[17] Y. Zhu and D. Shasha, “Warping Indexes with Envelope Transforms for Query by Humming,” ACM 
SIGMOD 2003, International Conference on Management of Data, June 9-12, 2003, San Diego,
California.
出國報告書：ISMIR 2006
張智星
相關資訊
 計畫編號：NSC 95-2221-E-007-220
 計畫名稱：音樂搜尋的加速與辨識率提升，及其在嵌入式系統的實作與應用
 出國人員姓名、服務機關及職稱：張智星，清華資訊工程系，副教授
 會議名稱：ISMIR (International Symposium on Music Information Retrieval)
 舉辦時間與地點：2006/10/08~2006/10/12, Fairmont Empress Hotel in Victoria,
Canada
 發表論文題目：Simple But Effective Methods for QBSH at MIREX 2006
 大會網址：http://ismir2006.ismir.net
 歷年網址：http://www.ismir.net
參加會議經過
ISMIR 是一個在 Music Information Retrieval 方面的世界性重要會議，第一次
ISMIR 研討會從 2000 才開始，今年是第七屆，但是每年與會的人數都是越來越
多，可見音樂檢索的重要性是與日俱增。
我是在十月七日搭乘華航的班機，直飛加拿大溫哥華機
場。而我們開會的地點，是在維多利亞，離溫哥華還有四
個小時的車程。（雖然有維多利亞機場，但是並沒有從台
灣直飛此機場的班機。）下飛機後，我才問別人如何到維
多利亞，我原先以為有公車可搭，結果並沒有，所以我就
先搭計程車到渡輪口，然後坐了大約一個半小時的渡輪到
維多利亞港口，然後再換公車到市中心會議所在地。仔細
算算，從機場到旅館大概花了四個小時，又加上有時差，
有點辛苦。
研討會的地點是在 Fairmont
Empress Hotel，非常氣派，是一棟歷史悠久的旅館，已經
成為當地的地標。我原先也想訂這個旅館，但是房價實在
太貴，訂不下手，還好有 Google Map，讓我在來此地之
前，就找了一家最近的旅館 Queen Victoria Hotel，房價
大概只有一半，但離會議地點只有兩個街口。（後來和其
他與會人士閒聊，他們也都認為我的選擇是對的，
Fairmont Empress Hotel 實在太貴了！）
上次的 ISMIR 2006，台灣方面有我
和長庚大學的呂仁園教授、中研院的王新明博士及蔡偉和
教授等人參加，但這次會議，台灣方面只有我來參加，蠻
意外的。事實上我發覺這個會議很像聯合國，各個國家的
代表都有，甚至有人提到在晚宴時，一桌10個人都是來自
不同的國家，很特別。由於只有我一個人從台灣來開會，
第一天所拍的
Fairmont Express
Hotel，天氣有點
陰暗。
豔陽下的
Fairmont Express
Hotel，景色非常
漂亮！
第 1 頁，共 4 頁出國報告書：ISMIR 2006
2007/2/24
的衝擊。
最後在 MIREX 的討論會中，我有針
對 QBSH 比賽，提出幾個建議：
1. QBSH 的比賽是 MIREX 所有比賽
中，比較容易評比的比賽，因為
標準答案非常確定，不需要人為
的評分，因此可以進行大規模的
評比，歡迎大家參加。
2. 下一屆的 QBSH 比賽，希望每一
位參賽者都能夠貢獻一部分哼唱
的語料，讓主辦者能夠進行 outside test，這樣所得到的辨識率才會比較
客觀。
回程時，我選擇了搭乘水上飛機，直飛溫哥華機場。我直
接由旅館將行李拖到水上飛機的起飛地點，上飛機時，才
發覺只有兩位乘客，加上機長，只有三個人。飛機起飛
後，噪音很大，但是我因為太興奮，忙著拍影片和照片，
所以也沒有帶飛機上提供的耳塞。由於霧太大，我們轉降
另一個降落地點，最後還是靠免費的計程車才將我送到溫
哥華機場。
與會心得
 這一次我主持 QBSH 的比賽，雖然花了很多時間，但是也認識了幾位相關的教授，同時
也讓我們實驗室所蒐集的資料能夠用於比賽，提高台灣在這個研究領域的知名度，相當
值得。
 我們這次參加 QBSH (Query By Singing/Humming) 的比賽，拿了第一名及第三名，證
Prof. Angelos
Pikrakis 幫我拍
的照片。（出國前
我還特別去理髮
呢。）
Victoria 的國會
殿堂在夜間的景
色。
我就是搭乘這種水
上飛機，從
Victoria 飛回溫
哥華機場。
Victoria 市區的
街道點綴著十月的
楓紅。
水上飛機起飛地
點，和我的背包和
旅行箱。
水上飛機內部，只
有我和另一位乘
客，以及機長。
水上飛機飛過雲
海，後來由於霧太
大，改停另一個機
場，還有免費的計
程車送我們到溫哥
華機場。
溫哥華機場的藝術
品，是我趕飛機的
寫照。
第 3 頁，共 4 頁出國報告書：ISMIR 2006
2007/2/24
Simple But Effective Methods for QBSH at MIREX 2006 
J.-S. Roger Jang, Nien-Jung Lee, and Chao-Ling Hsu 
Department of Computer Science 
National Tsing Hua University, Taiwan 
{jang, qmonster, leon}@wayne.cs.nthu.edu.tw
 
Abstract 
This extended abstract describes a submission to the 
QBSH (Query by Singing/Humming) task of MIREX 
(Music Information Retrieval Evaluation eXchange) 2006. 
The methods used for both subtasks 1 and 2 are introduced 
together with the evaluation results Comments and 
suggestions for further QBSH task are also addressed in 
the paper. 
Keywords: MIREX, Query by Singing/Humming (QBSH), 
LS (Linear Scaling), DTW (Dynamic Time Warping). 
1. Overview of QBSH Task 
The goal of QBSH (Query by Singing/Humming) task 
at MIREX 2006 is to evaluate MIR systems that take sung 
or hummed query input from real-world users. QBSH task 
consists of two subtasks: 
 
z Subtask 1: Known-Item Retrieval 
¾ Input: 2797 sung/hummed queries of 8 
seconds. 
¾ Test database: 48 ground-truth MIDIs + 2000 
Essen Collection MIDI noise files. 
¾ Evaluation: Mean reciprocal rank (MRR) of 
the ground truth computed over the top-20 
returns. 
z Subtask 2: Queries as Variations 
¾ Input: 2797 sung/hummed queries + 48 
ground-truth files of 8 seconds 
¾ Test database: 48 ground-truth MIDIs + 2000 
Essen MIDI noise files + 2797 sung/hummed 
queries. 
¾ Evaluation: The precision based on the 
number of songs within the same ground-truth 
class of the query calculated from the top-20 
returns for each of the 2845 queries. 
2. QBSH Corpus 
The QBSH corpus provided by Roger Jang [1] consists 
of recordings of children’s songs from students taking the 
course “Audio Signal Processing and Recognition” over 
the past 4 years at CS Dept of Tsing Hua Univ., Taiwan. 
The corpus consists of two parts: 
 
1. MIDI files: 48 monophonic MIDI files of ground 
truth. 
2. WAV files: 2797 singing/humming clips from 118 
subjects, with sampling rate of 8 KHz and bit 
resolution of 8 bits. 
 
For each of the WAV file, the corpus provides another 
two files distinguished by their file extensions, including 
PV (files of pitch vectors, derived with a frame size of 256 
and zero overlap), and MID (midi files). PV files are pitch 
vectors labelled manually by the student who recorded the 
clip. MIDI files were generated from the PV files through 
a simple note segmentation algorithm. The participants 
may choose any one of the formats as the input to their 
systems. 
The recording count of each MIDI file is shown in 
Figure 1. 
 
Figure 1. Recording count of each MIDI file. 
 
3. Our Approaches 
Since all the query data are available, we have to choose 
a simple but effective distance measure, which do not run 
into the potential problem of over fitting/training. Under 
this guideline, our primary candidates are 
 
z DTW: Dynamic Time Warping [2, 3] 
z LS: Linear Scaling [4] 
z LS+DTW: LS plus DTW [5] 
