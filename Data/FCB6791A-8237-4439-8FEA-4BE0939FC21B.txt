特徵所設計，進而得到良好的效能，我們希望能探討
TSN 法單純作用於未經任何處理的梅爾倒頻譜特徵
時，其效果是否也一樣明顯。 
根據以上對 TSN 法的分析與觀察，在本計畫中，我們
提出了三種語音特徵時間序列之調變頻譜正規化
(modulation spectrum normalization)的新方法，分別為
等漣波時間序列濾波器法(equi-ripple temporal filtering, 
ERTF)、最小平方頻譜擬合法 (least-squares spectrum 
fitting, LSSF)與強度頻譜內插法 (magnitude spectrum 
interpolation, MSI)，這三種方法之目的與 TSN 類似，
皆為了正規化語音特徵時間序列的功率頻譜密度，但
我們會在後面章節的實驗結果發現，這三種方法之效
能皆比 TSN 法來得好，且並不需要與 MVN 或 MVA
法結合，即可以十分有效地處理梅爾倒頻譜特徵因雜
訊干擾所造成的失真。然而，當它們與 MVN 或 MVA
相結合時，也可以得到更佳的辨識精確率，此代表它
們與 MVN 或 MVA 有良好的加成性。相關結果已經發
表於文獻[8]與[9]中。 
以下，在 II.2 節中，我們將討論原始時間序列結構正
規化法，包括其執行程序及初步效果，接下來，II.3
節將主要針對時間序列結構正規化法作改進，而提出
三種新的調變頻譜正規化法，並對其初步效果加以介
紹。在 II.4 節，我們將執行一系列的語音辨識實驗，
來驗證所提之新方法足以有效提昇語音特徵在雜訊環
境下的強健性。 
 
II.2 時 間 序 列 結 構 正 規 化 法 (temporal structure 
normalization, TSN) 
z TSN 處理簡介 
  本節主要介紹時間序列結構正規化法 (temporal 
structure normalization, TSN)[7]，在下一節中，我們將
以 TSN 法之觀念為基礎，提出一系列的調變頻譜正規
化的演算法。 TSN 是屬於一種時間序列濾波器
(temporal filter)設計之強健性語音技術，原始的 MFCC
語音特徵參數序列經過 CMVN 法[2]或 MVA 法[4]處理
後，先求取其功率頻譜密度(power spectral density)，
接著藉由此功率密度與事先定好的參考功率密度來決
定一濾波器的強度響應(magnitude response)，此強度
響應經反離散傅立葉轉換 (inverse discrete Fourier 
transform, IDFT)、漢寧窗化(Hanning window)處理與直
流增益正規化處理後，產生一組濾波器係數，此即為
TSN 法所求得的時間序列濾波器，將語音特徵序列通
過此濾波器後，則預期可達到調變頻譜正規化的效
果，而增加語音特徵之其強健性。圖一為 TSN 法的處
理程序示意圖： 
 
 
圖一、TSN 法處理程序示意圖 
    在 TSN 法中，每一句訓練語料之某一維特徵序列
{ }s n⎡ ⎤⎢ ⎥⎣ ⎦ 與測試語料同一維特徵序列 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ ，先求取其功
率頻譜密度，分別以 ( ){ }SS kP ω 與 ( ){ }XX kP ω 表示。接著將
訓練語料所有句子同一維的功率頻譜密度作平均，所
得即為參考功率頻譜密度，如下所示： 
( ) ( ){ },SS k SS kP E Pω ω=                                                 (式 II.1) 
在 TSN 法中所使用的濾波器，其初始的強度頻譜設定
如下式所示： 
 ( ) ( ) ( ),k SS k XX kH P Pω ω ω=                                      (式 II.2) 
其上式明顯看出，當任一測試語料 x n⎡ ⎤⎢ ⎥⎣ ⎦ 通過上式之濾
波器時，其原始功率頻譜密度 ( )XX kP ω 會被正規化為
( )SS kP ω 。 
    為 了 進 一 步 求 取 濾 波 器 的 脈 衝 響 應 (impulse 
response)，上式(II.2)中的 ( )kH jω 先經過反離散傅立葉
轉換(inverse discrete Fourier transform, IDFT)，之後再
乘上一個漢寧窗(Hanning window)，並將濾波器係數
總和正規化為 1，以達到直流增益正規化的目的。其
數學表示式如以下數式所示： 
1、反離散傅立葉轉換： 
( )1
0
1
,     0 1k
M
j m
k
k
h m H j e m M
M
ωω
− −
=
⎡ ⎤ = ≤ ≤ −⎢ ⎥⎣ ⎦ ∑ .           (式 II.3) 
2、漢寧窗化處理： 
hˆ m h m w m⎡ ⎤ ⎡ ⎤ ⎡ ⎤= ⋅⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ,                                                    (式 II.4) 
其中 
     0.5 1 cos 2 ,       0 1
1
m
w m m M
M
π
⎛ ⎞⎛ ⎞⎟⎜ ⎟⎜⎡ ⎤ ⎟⎟⎜= − ≤ ≤ −⎜ ⎟⎟⎢ ⎥ ⎜ ⎜ ⎟⎣ ⎦ ⎟⎜ ⎟⎜ −⎝ ⎠⎝ ⎠
. 
3、直流增益正規化： 
1
0
ˆ
M
m
h m
h m
h m
−
′=
⎡ ⎤⎢ ⎥⎣ ⎦⎡ ⎤ =⎢ ⎥⎣ ⎦ ⎡ ⎤′⎢ ⎥⎣ ⎦∑
 .                                                       (式 II.5) 
其中M 為濾波器長度。式(II.5)之 h m⎡ ⎤⎢ ⎥⎣ ⎦ 即為 TSN 所求
得之時間序列濾波器的脈衝響應。 
 
z TSN 法效果相關討論 
    在 TSN 之文獻[7]中，所用的原始特徵參數皆為經過
CMVN 法或 MVA 法所處理後之梅爾倒頻譜特徵參數
(MFCC)。這裡我們特別將 TSN 法運用在未經處理之
梅爾倒頻譜特徵參數上，觀察其改進效果。其中我們
( ) ( ) ( ) ( ) ( )( )arg min maxkk k k kHH W H Dωωω ω ω ω= −  ,              (式 II.6) 
其中 ( )kW ω 為權重值， ( )kH ω 為最佳化濾波器之頻率響
應， ( )kD ω 為參考的頻率響應， ( )kD ω 可表示如下式： 
                  ( ) ( )( )
SS k
k
XX k
P
D
P
ωω ω=                                   (式 II.7) 
由此法得到的濾波器係數 { }h n⎡ ⎤⎢ ⎥⎣ ⎦ ，會自動符合前後對稱
(symmetric)的性質，因此其相位響應是線性的(linear 
phase)[11]，並不會使原始特徵序列的調變頻譜產生相
位失真的情形，同時，因為濾波器本身是根據最佳化
準則設計，所以我們預期它會比 TSN 法所得之濾波器
效果來的好。 
z 最小平方頻譜擬合法(least-squares spectrum fitting, 
LSSF) 
    在這方法裡，我們針對每一個待正規化的N 點特徵
時間序列 { }0 1x n n N⎡ ⎤ ≤ ≤ −⎢ ⎥⎣ ⎦ 先定義一 2P 點的參考調變
頻譜，作為此特徵序列的調變頻譜正規化的目標： 
( ) ( ) ( )( )exp ,    0 2 1,k k X kY Y j k Pω ω θ ω= ≤ ≤ −              (式 II.8) 
其中的強度成份 ( )kY ω 以下式表示： 
( ) ( ) ( ) ( )k k SS k XX kY X P Pω ω ω ω=                                (式 II.9) 
    其中， ( )SS kP ω 與如式(II.1)中所定義，即 ( )SS kP ω 為所
有訓練語料特徵與 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ 同一維序列的功率頻譜密度平
均而得， ( )XX kP ω 為原始特徵序列 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ 的功率頻譜密
度。而強度成份 ( )kX ω 和相角成份 ( )X kθ ω 為 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ 經過
2P 點之離散傅立葉轉換(discrete Fourier transform, DFT)
所得到。值得注意的是，特徵長度N 會隨著不同的語
句而不同，但是這裡的 DFT 取樣點數 2P 則設為一固
定值，也就是參考調變頻譜的長度對於每一個語句都
是相同的。 
    由式(II.8)與式(II.9)可知，我們希望每一個更新後的
特徵序列，其調變頻譜的強度成份能趨於一致，而相
位成份則由原始的特徵序列 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ 而來。接下來，我們
利用最小平方化(least-squares)[11]的最佳化準則求取一
新的特徵參數序列，使新的特徵序列 { }y n⎡ ⎤⎢ ⎥⎣ ⎦ 的調變頻譜
逼近如式(3.3)的參考調變頻譜，如下式所示： 
{ } ( ) ( )
2
22 1 1
2
0 1 0 0
min ,  2
nkP N j
P
k
y n n N k n
y n y n e Y P N
π
ω
− − −
⎡ ⎤ ≤ ≤ −⎢ ⎥⎣ ⎦ = =
⎡ ⎤ ⎡ ⎤= − ≥⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦∑ ∑  (式 II.9) 
其中 2P 為 DFT 取樣點數，N 為此特徵序列的點數。 
藉由矩陣與向量表示法，我們可將式(II.9)改寫為下
式： 
                  2minW= −
y
y y Y
                                  (式 II.10) 
其中W 是 2P N× 的矩陣，其第 ( , )m n 項如下所示： 
2
exp ,
2mn
mn
W j
P
π⎛ ⎞⎟⎜ ⎟= −⎜ ⎟⎜ ⎟⎜⎝ ⎠  
而 y、 y與 Y 則定義為： 
0 1 1 ,
T
y y y n⎡ ⎤⎡ ⎤ ⎡ ⎤ ⎡ ⎤= −⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦⎣ ⎦y "  
0 1 1 ,
T
y y y N⎡ ⎤⎡ ⎤ ⎡ ⎤ ⎡ ⎤= −⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦⎣ ⎦y
   "  
( ) ( ) ( )0 1 2 1 ,TPY Y Yω ω ω −⎡ ⎤= ⎢ ⎥⎣ ⎦Y   "  
由於 y為實數向量，故式(II.10)可改寫為： 
        
( ) ( ) 2
2 2
min
min
R R I I
R R I I
W j W
W W
= − + −
⎛ ⎞⎟⎜= − + − ⎟⎜ ⎟⎜⎝ ⎠
y
y
y y Y y Y
y Y y Y


  
                      (式 II.11) 
其中矩陣
R
W 與
I
W 分別為矩陣W 的實部與虛部，而向
量
R
Y
 與
I
Y
 則分別為向量 Y 的實部與虛部。 
   由式 (II.11)明顯看出，此為一典型的最小平方化
(least-squares)的求解問題，故其精確的封閉解(closed-
form solution)可由下式表示： 
( ) ( )1T T T TR R I I R R I IW W W W W W−= + +y Y Y                         (式 II.12) 
所以，式(II.12)中的 y即為 LSSF 法所求得之新特徵參
數序列 { }y n⎡ ⎤⎢ ⎥⎣ ⎦ ，其 2P 點之 DFT 和式(II.8)的參考調變頻
譜之間具有最小平方誤差的良好性質。 
z 強度頻譜內插法(magnitude spectrum interpolation, 
MSI) 
    在此方法中，我們為每一個待正規化的 N 點特徵序
列 { }0 1x n n N⎡ ⎤ ≤ ≤ −⎢ ⎥⎣ ⎦ ，定義了一個 N 點的參考調變頻
譜，作為此特徵序列之調變頻譜正規化的目標，如下
式所示： 
( ) ( ) ( )( )exp ,     0 1k k X kY Y j k Nω ω θ ω′ ′ ′ ′= ≤ ≤ −            (式 II.13) 
其中相位成份 ( )X kθ ω ′ 為 x n⎡ ⎤⎢ ⎥⎣ ⎦ 取N 點的 DFT 所得。MSI
法跟前節之 LSSF 法的最大不同之處，在於此時我們
是使用一個跟原始特徵序列長度相同的參考調變頻
譜，而由於不同語句的特徵序列，其點數N 也隨之不
同，我們不能如前面的 LSSF 法中，直接拿 2P 點的參
考功率頻譜密度 ( ){ }0 2 1SS kP k Pω ≤ ≤ − (如式(II.1)所示)
來求取式(II.13)中的 N 點頻譜強度 ( )kY ω ′ 。然而，由
於原始 2P 點的參考頻譜其涵蓋頻率範圍與欲求的
( )kY ω ′ 頻率範圍相同，在這裡，我們使用線性內插
(linear interpolation)[10]的方法，藉由式(II.9)中所示的
之 2P 點的 ( ){ }0 2 1kY k Pω ≤ ≤ − 來求取式(II.13)中 N 點
的 ( ){ }0 1kY k Nω ′ ′≤ ≤ − 之近似值。但是式 (II.13) 的
( ){ }kY ω ′ 為一實數序列之離散傅立葉轉換，其強度成份
( ){ }kY ω ′ 必 須 符 合 左 右 對 稱 的 性 質 ， 即
( ) ( )k N kY Yω ω′ ′−=  ，因此我們先利用 ( ){ }kY ω 的左半部
所發行之語料庫：AURORA 2.0[10]，內容是以美國成
年男女所錄製的一系列連續的英文數字字串，語音本
身並加上各種加成性雜訊與通道效應的干擾。加成性
雜訊共有八種，分別為地下鐵、人聲、汽車，展覽會
館、餐廳、街道、飛機場和火車站雜訊等，通道效應
則有兩種，分別為 G712 與 MIRS[12]。雜訊含量的大
小包含了乾淨無雜訊的狀態，以及六種不同訊雜比
(signal-to-noise ratio, SNR) 狀 態 ， 分 別 是 20dB 、
15dB、10dB、5dB、0dB 與-5dB，因此我們可以觀察
不同的雜訊環境對於語音辨識的影響。因雜訊特性的
不同，測試環境可分為 Set A、Set B 與 Set C 三組
[10]。 
    聲學模型是執行隱藏式馬可夫模型工具 (hidden 
Markov model tool kit, HTK)[13]訓練所得，包含 11 個
數字模型 (zero, one, two, …, nine 及 oh)以及靜音
(silence)模型，每個數字模型包含 16 個狀態，各狀態
包含 20 個高斯密度混合。 
 
z 各種調變頻譜正規化法作用於梅爾倒頻譜特徵參
數之實驗結果 
   本章節所有實驗所使用的語音特徵為梅爾倒頻譜係
數(mel-frequency cepstral coefficients, MFCC)，我們採
用的 MFCC 特徵參數為13維(c0~c12)，加上其一階差
量(delta)和二階差量(delta-delta)，總共為39維特徵參
數。基本實驗(baseline experiment)是以原始 MFCC 特
徵參數作為訓練與測試，TSN-1法為 II.1節中所介紹之
原始 TSN 法，而 TSN-2法則是將原始 TSN 法中直流
增益正規化步驟省略所得的修正法，TSN-1與 TSN-2
所得之時間序列濾波器長度皆設為21，此值是直接參
考 TSN 法的文獻[7]而來。ERTF 法所得的時間序列濾
波器長度為21，而 LSSF 與 MSI 法所用的 DFT 點數
2P (如式(3.3)所示)則固定為1024。下表一中，我們綜
合了 TSN-1、TSN-2、ERTF、LSSF、MSI，及著名的
特徵正規化技術 CMVN[2]和 MVA[4]，其各別作用於
原始 MFCC 特徵參數所得的平均辨識率（20dB、
15dB、10dB、5dB 與0dB 五種訊雜比下的辨識率平
均），其中 AR 與 RR 分別為相較於基本實驗結果之
絕對錯誤降低率(absolute error rate reduction)和相對錯
誤降低率(relative error rate reduction)。 
     
 
表一、各種特徵序列處理技術之辨識率(%) 
 
 
由表一的數據，我們可看出以下幾點現象： 
1 . 原始 TSN 法(TSN-1)對 MFCC 特徵在雜訊環境下的
辨識率的改進並不是很明顯，只進步0.55%，然而
TSN-2法帶來十分明顯的辨識率提升(Set C 除外)，在
Set A 和 Set B 環境下，平均辨識率相對於 TSN-1而言
分別改進了8%與14%左右。如此看出，藉由省略直流
增益正規化的步驟，TSN-2比 TSN-1具有更佳的特徵
調變頻譜正規化的效果，這也呼應了圖二的結果，即
原始 TSN 法無法有效降低各雜訊環境下，原始語音
MFCC 特徵時間序列之功率頻譜密度曲線的不匹配現
象。 
2 . ERTF、LSSF 與 MSI 法三種新方法在各種不同的雜
訊環境下皆能明顯提升辨識率，對 Set A 環境而言，
它 們 分 別 使 辨 識 率 提 升 了 12.99% 、 11.91% 與
11.15%，對 Set B 環境而言，辨識率分別提升了
18.61%、17.90%與 17.05%，在 Set C 環境下，辨識率
分別提升了 6.52%、5.90%與 5.46%。這三種方法中，
又以 ERTF 法的表現最好，明顯優於 LSSF 法與 MSI
法，但它們所能達到的相對錯誤降低率都高達 40%以
上，明顯優於 TSN-1 法與 TSN-2 法。另外，值得一提
的是，TSN-2 法在 Set C 中的效果比 TSN-1 與基礎實
驗差，但 ERTF、LSSF 與 MSI 法卻未有這樣的不良結
果。 
3  兩種目前廣為人用的特徵正規化技術：CMVN 法與
MVA 法，對辨識率的提升都十分明顯，CMVN 的效
能與我們所提的三種新方法大致相同，但結合了
CMVN 與 ARMA 濾波處理的 MVA 法其效能又比
CMVN 法來的好，基於這樣的觀察，在下兩小節中，
我們將試著把各種調變頻譜正規化法與 CMVN 法或
MVA 法加以整合，探討是否能帶來辨識率上更顯著的
進步。 
    當我們使用 LSSF 法與 MSI 法時，我們會將原始為
N 點的特徵序列轉換成 2P 點之功率頻譜密度或離散頻
譜，然而由於通常 2P N> ，我們會以補零的方式先將
原始的 N 點的特徵序列變長為 2P 點，意即多補了
2P N− 個零點，這樣的作法容易產生非零值的點與零
值的點之間訊號值不連續的情形，而引進了不必要的
高頻成份，這效應類似於直接於一訊號加上矩形窗所
造成頻譜遺漏(leakage)[]的缺點，因此，我們這裡在
LSSF 與 MSI 法之補零的程序前，先將原始的N 點的
特徵序列乘上一漢寧窗(Hanning window)[11]，來降低
上述可能的不良效應，觀察這樣的操作是否可進一步
提升 LSSF 法與 MSI 法的效果，我們稱這樣修改結果
分別為修正式 LSSF 法(modified LSSF)與修正式 MSI
法(modified MSI)。 
圖八為原始與修正式 LSSF 與 MSI 作用於原始
MFCC 特徵之平均辨識率長條圖。由此圖中可以看出
修正式 LSSF 法相較於原始 LSSF 法而言，平均辨識率
有 0.67%的提升，而修正式 MSI 相較於原始 MSI 而
 
圖九、原始和修正式 LSSF 與 MSI 作用於 CMVN 法處
理後 MFCC 特徵之平均辨識率 
 
z 調變頻譜正規化法結合倒頻譜平均與變異數正規
化結合自動回歸動態平均濾波器法之實驗結果 
    前面提到，倒頻譜平均與變異數正規化結合自動回
歸動態平均濾波器法(MVA)[4]能夠對雜訊環境下的語
音特徵有明顯的強健化效果，而帶來十分顯著的辨識
率提升，且其效能優於 CMVN，因此在這裡，我們將
各種調變頻譜正規化法與 MVA 法作結合，也就是把
這些正規化法作用於經 MVA 法處理後之 MFCC 特徵
上，以檢視這些正規化法與 MVA 法是否有加成性。
實驗中我們設定 MVA 法中的 ARMA 濾波器階數為
2(參照[4])。在下表三中，我們列出了 MVA 法分別結
合 TSN-1、TSN-2、ERTF、LSSF 與 MSI 各方法所得
的平均辨識率，其中 AR 與 RR 分別為相較於單一
MVA 法之結果的絕對錯誤降低率(absolute error rate 
reduction) 和 相 對 錯 誤 降 低 率 (relative error rate 
reduction)。 
 
表三、各調變頻譜處理法作用於 MVA 處理後之
MFCC 特徵所得之辨識率(%) 
 
 
    由表三可看出，TSN-1 在結合 MVA 後，其效能有
明顯的提昇，而 TSN-1 和 TSN-2 之間的差異雖然不明
顯，但是省略直流增益正規化步驟的 TSN-2 法仍然表
現比較好，相對於單一 MVA 法的結果而言，結合了
MVA 法之 TSN-1 在總平均辨識率上提升 1.36%，而
TSN-2 提升了 1.52%。此外，結合 MVA 法之後，我們
提出的 ERTF、LSSF 與 MSI 三個方法仍優於 TSN-1 與
TSN-2，而其中以 MSI 法最好，在辨識率上提升
1.71%，其次為 LSSF 法，提升了 1.67%， ERTF 法則
提升了 1.59%。儘管如此，我們可明顯看出，這些方
法在結合 MVA 法後，所帶來的辨識率提升程度相對
而言都已十分接近。 
    如同前節所描述之原始 LSSF 法與 MSI 法的可能缺
點，在這裡，我們同樣地測試修正式 LSSF 法與 MSI
法結合 MVA 法的效果，即在原始 LSSF 法或 MSI 法
之補零的程序前先將原始 N 點之 MVA 法處理後之
MFCC 特徵序列乘上一漢寧窗(Hanning window)，觀察
這樣的操作能否帶來進步。 
圖十為原始與修正式 LSSF 與 MSI 作用於 MVA 法處
理後 MFCC 特徵之平均辨識率長條圖。由此圖可以看
出，在結合 MVA 法的前提下，修正式 LSSF 法相較於
原始 LSSF 法而言，有 0.65%平均辨識率的提升，而
修正式 MSI 法相對於原始 MSI 法而言，有 0.48%平均
辨識率的提升，因此，我們驗證了兩種修正式方法都
能使原始方法進一步提升效能。 
 
圖十、原始和修正式 LSSF 與 MSI 法作用於 MVA 法
處理後 MFCC 特徵之平均辨識率 
 
 
III.靜音能量特徵正規化法 
III.1 背景介紹 
在特徵參數抽取步驟時，我們經常計算語音的能
量值作為特徵之一；根據過去的文獻指出[14][15]，語
音訊號的能量特徵(energy feature)所包含的辨識資訊大
過於其它特徵，且能量特徵的計算複雜度很低。所以
根據上述能量特徵的優勢，在本論文中，我們特別對
其強健性技術加以分析、討論與發展。 
近 年 來 ， 有 許 多 成 功 的 強 健 性 對 數 能 量 特 徵
(logarithmic energy, logE)的技術相繼被提出，例如，
對數能量動態範圍正規化法(log-energy dynamic range 
normalization, LEDRN)[16]其目標是使訓練與測試的語
音資料其對數能量值之動態範圍一致化；對數能量尺
度重刻法(log-energy rescaling normalization, LERN)[17]
則是將對數能量特徵乘上一個介於 0 與 1 間的權重
值，試圖重建出乾淨語音的對數能量特徵；而本實驗
室先前所提出的靜音音框對數能量正規化法(silence 
energy normalization, SLEN)[18]，是將判別為非語音音
框(non-speech frame)的對數能量特徵設定為一極小值
響。首先，我們將式(III-2)以泰勒級數(Taylor series)展
開，其展開的中心點設定為 ( ) ( )( ) ( ), 0, 0s dE n E n⎡ ⎤ ⎡ ⎤ =⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ，展開
階層為 2 階，如式(III-4)所示： 
( ) ( )( ) ( )( )( )log exp expx s dE n E n E n⎡ ⎤ ⎡ ⎤ ⎡ ⎤≈ +⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦  
( ) ( )( ) ( )( ) ( )( ) ( ) ( )2 21 1log2 2 8s d s d s dE n E n E n E n E n E n⎛ ⎞⎟⎜⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤⎟≈ + + + + −⎜ ⎟⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎜⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦⎟⎜⎝ ⎠ .                                                                               
式(III-4) 
因此，若將上式(III-4)取傅立葉轉換，則此雜訊
語音的對數能量序列 ( ){ }xE n⎡ ⎤⎢ ⎥⎣ ⎦ 的調變頻譜可用下式表
示： 
( ) ( ) ( ) ( ) ( )( )12 log 2
2
X j S j D jω π δ ω ω ω≈ + +  
( ) ( ) ( ) ( ) ( ) ( )( )1
16
S j S j D j D j S j D jω ω ω ω ω ωπ+ ∗ + ∗ − ∗ ，
      式(III-5) 
式中 ( )X jω 、 ( )S jω 以及 ( )D jω 分別為雜訊語音之logE序
列 ( ){ }xE n⎡ ⎤⎢ ⎥⎣ ⎦ 、乾淨語音之logE序列 ( ){ }sE n⎡ ⎤⎢ ⎥⎣ ⎦ 與雜訊之logE
序列 ( ){ }dE n⎡ ⎤⎢ ⎥⎣ ⎦ 的調變頻譜。假設 ( ){ }sE n⎡ ⎤⎢ ⎥⎣ ⎦ 與 ( ){ }dE n⎡ ⎤⎢ ⎥⎣ ⎦ 兩序
列皆為低通(low-pass)訊號，且
s
B 與
d
B 為其相對應之頻
寬 (bandwidth) ， 則 式 (III-5) 中 ( ) ( )D j D jω ω∗ 與
( ) ( )S j D jω ω∗ 兩項的頻寬分別為 2 dB 與 s dB B+ ；這意味
著雜訊語音之logE序列 ( ){ }xE n⎡ ⎤⎢ ⎥⎣ ⎦ 相較於雜訊的logE序列
( ){ }dE n⎡ ⎤⎢ ⎥⎣ ⎦ 將擁有更大的頻寬。換言之，對 logE序列而
言，雜訊語音比雜訊擁有較多高頻的調變頻譜成份；
這便可以解釋為何在一雜訊語音訊號中含有語音的區
段，比起純雜訊的區段看起來振盪情形(fluctuating)更
為明顯。 
接著我們探討加成性雜訊對於 c0 特徵的影響。
假設雜訊語音中第 n個音框的 c0 特徵值以 ( )
0
x
c n⎡ ⎤⎢ ⎥⎣ ⎦做表
示，而 ( )
0
s
c n⎡ ⎤⎢ ⎥⎣ ⎦ 與
( )
0
d
c n⎡ ⎤⎢ ⎥⎣ ⎦ 分別表示此音框之所含乾淨語音
訊號及純雜訊的 c0 特徵值，則它們可被推導如下三
式： 
( ) ( )( ) ( ) ( )( )0 log , log [ , ] [ , ]x x s dk kc n M k n M k n M k n⎡ ⎤ ⎡ ⎤= ≈ +⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦∑ ∑ 式 (III-6) 
( ) ( )( )0 [ ] log [ , ]s skc n M k n= ∑ ，                                        式(III-7) 
( ) ( )( )0 [ ] log [ , ]d dkc n M k n= ∑ ，                     式(III-8) 
其中， ( )[ , ]xM k n 、 ( )[ , ]sM k n 與 ( )[ , ]dM k n 分別為式(III-1)中雜
訊語音訊號
n
x m⎡ ⎤⎢ ⎥⎣ ⎦ 、乾淨語音訊號 ns m⎡ ⎤⎢ ⎥⎣ ⎦ 以及雜訊 nd m⎡ ⎤⎢ ⎥⎣ ⎦
於轉換成梅爾倒頻譜特徵時，第 k 個梅爾濾波器的輸
出值。因此我們可推導出，由於加成性雜訊干擾所導
致雜訊語音與乾淨語音訊號兩者之 c0 特徵值的差異
0
c n⎡ ⎤Δ ⎢ ⎥⎣ ⎦ 如下式所示： 
( ) ( ) ( )
( )0 0 0
[ , ]
log 1
[ , ]
d
x s
k s
M k n
c n c n c n
M k n
⎛ ⎞⎟⎜ ⎟⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎜ ⎟Δ = − ≈ +⎜ ⎟⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ⎜ ⎟⎟⎜⎝ ⎠∑  
1
        log 1
[ , ]k SNR k n
⎛ ⎞⎟⎜ ⎟= +⎜ ⎟⎜ ⎟⎜⎝ ⎠∑ ，                      式(III-9) 
式中 [ , ]SNR k n 定義為第 n個音框中第 k 維梅爾頻帶的訊
雜比，即 
( )
( )
[ , ]
[ , ]
[ , ]
s
d
M k n
SNR k n
M k n
= .                                               式(III-10) 
由式(III-9)可看出，若多數梅爾頻帶的訊雜比 [ , ]SNR k n
都比較大時，差異值
0
[ ]c nΔ 也相對變小，因此這可約略
解釋含語音之音框(SNR 較大)相對於純雜訊音框(SNR
較小)而言，c0 特徵值較不易受到影響的現象。 
以下我們將探討加成性雜訊對於 c0 特徵序列之調變頻
譜 (modulation spectrum)上的影響。首先為了推導起
見，我們將式(III-6)、式(III-7)與式(III-8)改寫成下列三
式： 
( ) ( ) ( )( ) ( )( )( )0 [ ] [ , ] log exp [ , ] exp [ , ]x x s dk kc n M k n M k n M k n= ≈ +∑ ∑   , 
  式(III-11) 
( ) ( )
0
[ ] [ , ]
s s
k
c n M k n= ∑  ,                                              式(III-12) 
( ) ( )
0
[ ] [ , ]
d d
k
c n M k n= ∑  ,                                              式(III-13) 
其 中 ( ) ( )( )[ , ] log [ , ]x xM k n M k n= 、 ( ) ( )( )[ , ] log [ , ]s sM k n M k n= 、
( ) ( )( )[ , ] log [ , ]d dM k n M k n= 。類似將式(III-11)與式(III-2)作比
較，可看出雜訊語音、乾淨語音與純雜訊三者的關係
在 logE 與 c0 兩特徵中十分類似，因此藉由前面之式
(III-4)與式(III-5)對於 logE 特徵序列之調變頻譜的推
導，我們可以發現對每個梅爾濾波器輸出的對數值序
列 ( ){ },xM k n⎡ ⎤⎢ ⎥⎣ ⎦ 而言，其頻寬仍是大於 ( ){ },dM k n⎡ ⎤⎢ ⎥⎣ ⎦ ，也就是
說 ( ){ }0xc n⎡ ⎤⎢ ⎥⎣ ⎦ 比起 ( ){ }0dc n⎡ ⎤⎢ ⎥⎣ ⎦ 將擁有更大的頻寬，因此，類似
logE 特徵的結果，我們同樣歸納出雜訊語音之 c0 特徵
序列比純雜訊之 c0 特徵序列擁有較多高頻的調變頻譜
成份，亦即前者比後者有更明顯的上下振盪現象。 
圖十二(a)與圖三(b)分別為一句語音訊號之 logE 特徵
及 c0 特徵的功率頻譜密度(power spectral density, PSD)
曲線圖，其中的語音訊號及雜訊為 Aurora-2.0 資料庫
中的"FAC_5Z31ZZ4A"檔與人聲雜訊(babble noise)，訊
雜比為 15dB。由這兩圖我們可以很明顯地看出，雜訊
語音相對於純雜訊而言，其 logE 特徵序列與 c0 特徵
序列都有較大的頻寬，此亦驗證了我們之前的推導。 
 
 
 
 
 
 
 
 
關特徵值可以較趨近於原始乾淨語音訊號之特徵值，
達到降低失真的目的。 
 
圖十三、靜音特徵正規化法I處理前((a)與(b))與處理後
((c)與(d))能量相關特徵序列曲線圖，其中(a)與(c)為
logE 特徵序列曲線，(b)與(d)為 c0 特徵序列曲線 
 
z 靜音特徵正規化法II (silence feature normalization II, 
SFN-II) 
SFN-II 法與前一節之 SFN-I法最大的差異在於，SFN-
II是將原能量相關特徵 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ 乘上一權重值(weight)，而
得到新特徵值 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ 。SFN-II的演算法如下式所示： 
SFN-II:    x n w n x n⎡ ⎤ ⎡ ⎤ ⎡ ⎤=⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ,                   式(III-18) 
其中， 
( )( )( )
( )( )( )
1
2
1 / 1 exp if 
if 1 / 1 exp
y n y n
w n
y ny n
θ βσ θ
θθ βσ
⎧⎪ ⎡ ⎤ ⎡ ⎤+ − −⎪ >⎢ ⎥⎪ ⎣ ⎦ ⎢ ⎥⎪ ⎣ ⎦⎡ ⎤ = ⎨⎢ ⎥⎣ ⎦ ⎡ ⎤⎪ ≤⎡ ⎤+ − −⎪ ⎢ ⎥⎣ ⎦⎢ ⎥⎪ ⎣ ⎦⎪⎩
 式(III-19) 
其中 y n⎡ ⎤⎢ ⎥⎣ ⎦ 如前一節之式(III-15)所示，為 { }x n⎡ ⎤⎢ ⎥⎣ ⎦ 通過一高
通濾波器之輸出值， θ 為門檻值、
1
σ 與
2
σ 分別為
{ }y n y n θ⎡ ⎤ ⎡ ⎤ >⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ( 大 於 門 檻 值 θ 之 所 有 的 y n⎡ ⎤⎢ ⎥⎣ ⎦ ) 以 及
{ }y n y n θ⎡ ⎤ ⎡ ⎤ ≤⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦  (小於或等於門檻值 θ 之所有的 y n⎡ ⎤⎢ ⎥⎣ ⎦ )所對
應之標準差、 β 為一常數。SFN-II之門檻值 θ 跟 SFN-I
相同，計算式如下所示： 
( )
1
1
N
n
N y nθ
=
⎡ ⎤= ⎢ ⎥⎣ ⎦∑ ,                  式(III-20) 
式中N 為此段語音中音框總數。 
式 (III-19)的權重值 w n⎡ ⎤⎢ ⎥⎣ ⎦ 如圖十四所示，其中假設
0θ = 、
1
1σ = 、
2
3σ = 以及 0.1β = 。由圖十四可以發
現，權重值函數w n⎡ ⎤⎢ ⎥⎣ ⎦ 為一個左右不對稱之遞增的 S 形
曲線(sigmoid curve)，其值介於 0 和 1 之間。此權重值
所代表的意義與 SFN-I法相似，我們希望新得到的能
量相關特徵 x n⎡ ⎤⎢ ⎥⎣ ⎦ 能在原始特徵值很大時，儘量維持不
變；而原始值較小時，則使其變得更小。SFN-II 法和
SFN-I法不同之處在於，SFN-II 法具有"軟式"的語音端
點偵測決策(soft-decision VAD)，而 SFN-I法則為"硬式
"的語音端點偵測決策(hard-decision VAD)；因此 SFN-
II 法相較於 SFN-I法而言，其 VAD 判定錯誤的影響可
能相對來得比較小，效能也會比較好，這推想將會在
之後的實驗結果驗證。 
 
圖十四、權重值函數 [ ]w n 曲線示意圖 
 
圖十五為 SFN-II 法處理前與處理後能量相關特徵之曲
線圖。與之前的圖三類似，(a)與(b)分別為原始的 logE
特徵序列以及 c0 特徵序列曲線；(c)與(d)分別為經過
靜音特徵正規化法II 處理後所得到之 logE 序列以及 c0
序列曲線，其中紅色實線是對應至乾淨語音(Aurora-
2.0 資料庫中的"FAK_3Z82A"檔)[10]、綠色虛線與藍
色點線則分別為對應至訊雜比 15dB 與 5dB 的雜訊語
音。很明顯地，經由 SFN-II 處理過後之雜訊語音的能
量相關特徵，皆類似 SFN-I法的效果，可以更趨近於
原始乾淨語音之特徵，有效降低雜訊造成的失真。 
 
圖十五、靜音特徵正規化法II處理前((a)與(b))與處理
後((c)與(d))能量相關特徵序列曲線圖，其中(a)與(c)為
logE 特徵序列曲線，(b)與(d)為 c0 特徵序列曲線 
 
III.3 能量相關特徵處理技術之實驗結果與討論 
z 語音資料庫與辨識系統簡介 
這裡所用的語音辨識實驗所使用的語音資料庫與
II.3 節相同，為 Aurora-2.0 語料庫[10]，根據此語料庫
標準設定，語音特徵參數主要是使用梅爾倒頻譜係數
(mel-frequency cepstral coefficients, mfcc)及能量相關特
徵，附加上其一階差量與二階差量。為了分析能量相
關特徵的影響，於本論文中採用兩組不同的特徵參
數；第一組是 12 維梅爾倒頻譜特徵值(c1～c12)加上 1
維的對數能量(logE)，另一組則是使用 12 維梅爾倒頻
譜特徵值(c1～c12)加上第零維倒頻譜特徵係數(c0)；
1 .類似之前的表四之結果，各種方法作用於 c0 特徵
時，都能帶來提昇辨識率的效果，其中，LEDRN-I 與
LEDRN-II 的表現比其他方法稍差，尤其是 LEDRN-
II，只有 3.57% 之絕對錯誤降低率(AR)，其可能原因
在於，LEDRN 原本是針對 logE 特徵所設計，若我們
直接將其套用於 c0 特徵處理上，其所使用的參數並非
是最佳化而得，導致效果不彰。 
2 .三種原本作用於所有種類特徵之方法：MVN、
MVA 與 HEQ 法，單純作用於 c0 特徵時，仍然以
HEQ 表現最好，MVA 法次之，MVN 法較差，但彼此
表現的差距並未如之前在表二來得明顯。此外，
LERN-I、LERN-II 與 SLEN 都有十分顯著的改進效
果，唯與表二的數據不同之處，在於三種方法的效能
十分接近，而 LERN-I 略優於 SLEN。  
3 .本計畫所提出的兩種靜音特徵正規化法，SFN-I 與
SFN-II，相對於基礎實驗結果而言，平均辨識率分別
提升了 13.79%與 14.13%，相對錯誤降低率約為
46%，類似表二的結果，SFN-II 仍然優於 SFN-I，且
這兩種方法之表現仍優於其他所有的方法。此結果驗
證了我們所提的兩個新方法，能有效地提昇 c0 特徵在
加成性雜訊環境下的強健性。 
 
表五、針對 c0 特徵之強健式語音技術之辨識率的綜合
比較表(%) 
 
 
雖然 SFN 法有效地降低雜訊對 c0 造成的失真，
進而提昇辨識率，但當我們比較表四與表五時，發現
無論是 SFN-I 或 SFN-II，作用於 logE 特徵可得到的辨
識率會高於作用在 c0 特徵所得之辨識率；由此，我們
推斷由 logE 特徵所得之 SFN-I 法與 SFN-II 法其中的
語音端點偵測(VAD)結果，可能會比由 c0 所得結果來
的好。根據此推想，我們將原來針對 c0 特徵的兩種
SFN 法稍作修改。於 SFN-I 中，我們先利用 logE 對音
框做語音/非語音的分類，再將此判別結果套用於 c0
上，對非語音音框的 c0 做如式(III-16)之正規化處理；
而 SFN-II 也是利用相同的方式，先利用 logE 對音框
做語音/非語音的分類，再將其結果轉換至 c0 上，並
對語音與非語音音框的 c0 特徵序列求取其式(III-19)所
用的標準差
1
σ 與
2
σ ，然後作式(III-18)之正規化處理。
我們將以上的修正作法分別稱作針對 c0 特徵之修正式
SFN-I 法(modified SFN-I)與修正式 SFN-II 法(modified 
SFN-II)。 
針對 c0 特徵之修正式 SFN-I 法與修正式 SFN-II
法，其所得之平均辨識率如表六所示，如我們所預期
的，修正式 SFN 法相對於原始 SFN 法，能有更進一
步的改進效果，對 SFN-I 而言，前者相較於後者額外
提昇了 1.29%的平均辨識率，而對 SFN-II 而言，前者
相較於後者額外提昇了的 1.33%平均辨識率。此結果
部分驗證了我們的推想，即利用 logE 特徵來執行語音
端點偵測(VAD)，其效果會比 c0 特徵來的好。 
 
表六、針對 c0 特徵之原始 SFN 法與修正式 SFN 法之
辨識率比較表(%) 
 
 
z 靜音特徵正規化法與其它特徵強健法結合之實驗
結果與討論     
之前一系列的實驗，主要是探討各種能量相關特
徵處理技術效能，進而突顯出我們所新提出之靜音特
徵正規化 (SFN)法的優異表現，這些實驗中，只有
logE 與 c0 兩種能量相關特徵被處理，剩餘的梅爾倒頻
譜特徵係數(c1~c12)則維持不變。在這裡，我們嘗試
將作用於 logE 與 c0 特徵的 SFN 法與作用於 c1~c12 之
梅爾倒頻譜特徵係數的強健性技術加以結合，藉以觀
察兩者之間是否有加成性，能進一步改進語音辨識
率。 
我們選擇之前所提之 MVN[2]、MVA[4]以及
HEQ[22]三種強健性技術，分別作用於 c1~c12 之梅爾
倒頻譜特徵係數上，而將我們所提之 SFN-I 或 SFN-II
法作用於能量相關特徵(logE 或 c0)上，我們將其上述
所有的實驗結果分別彙整成表七與表八。 
針對第一組特徵(logE, c1~c12)處理之表七的數據
中，列 (2)~(4)是利用單一強健技術 (MVN, MVA 或
HEQ)處理全部特徵參數之結果，而列(5)~(10)則分別
為靜音特徵正規化法(SFN)結合其它方法之結果。當我
們將列(2)、列(5)與列(8)的結果相比較、列(3)、列(6)
與列(9)的結果相比較，及列(4)、列(7)與列(10)的結果
相比較，都可以看出將 SFN-I 或 SFN-II 使用於 logE
特徵，並用其他方法使用在 c1～c12 特徵上，所得到
的辨識率比單獨使用一種方法處理全部特徵的辨識結
果高出許多，例如列 (9)之『SFN-II (logE) + MVA 
(c1~c12)』法，其平均辨識率高達 89.97%，超越了列
(4)之『HEQ (logE, c1~c12)』法所得之 87.44%的平均
辨識率。同時，我們也看出 SFN-II 的效能普遍優於
SFN-I，此結果跟前一章的結論是一致的。而當我們將
表五與表二的數據相比較時，也可以看出，使用 SFN
但當它們作用於 CMVN 法或 MVA 法處理過後的
MFCC 特徵時，其效能的差異性已經很小，這意味著
運算複雜度較小的 MSI 法相對於 ERTF 法與 LSSF 法
而言，可能有更佳的應用性。 
在第二類『靜音能量特徵正規化法』(Silence feature 
normalization, SFN)技術上，是針對能量相關特徵(logE
與 c0)因加成性雜訊造成的失真現象作適當的補償。
SFN 法利用了一個高通濾波器去處理原始能量相關特
徵序列，並將通過此高通濾波器所的之輸出特徵序列
拿來作語音/非語音的分類，並應用簡單且有效的方法
來處理非語音部份的特徵，將雜訊對語音特徵的干擾
降低，以期提升訓練與測試環境匹配度，進而提升雜
訊環境下的語音辨識率。由實驗數據中可發現，就處
理能量相關特徵而言，SFN 法比基本實驗以及許多強
健式語音技術得到更好的辨識率；由此可知針對能量
相關特徵做適當的補償，在穩定以及非穩定雜訊環境
下皆得到十分顯著的辨識率提升，顯示了能量相關特
徵所含的語音鑑別資訊是影響辨識率的一個重要指
標。此外，當我們將 SFN 法與其它強健式語音技術做
結合，發現其辨識率比單獨使用一種強健式語音技術
所得到的辨識率更高，其中又以 SFN-II 法結合 MVA
法得到的辨識率最高，可達到將近 90%的平均辨識
率。 
綜合以上所言，我們在本計畫中所發展的語音強健性
技術，經廣泛的實驗，驗證了其對於語音特徵具有有
效改善其環境強健性的效果，而且這些技術運算複雜
度低，且與其他類強健性技術多具有良好的加成性，
深具應用之價值。 
 
參考文獻  
[1] S. Furui, "Cepstral Analysis Technique for 
Automatic Speaker Verification", IEEE Trans. on 
Acoustics, Speech and Signal Processing, 1981 
[2] S. Tiberewala and H. Hermansky, "Multiband and 
Adaptation Approaches to Robust Speech 
Recognition", 1997 European Conference on Speech 
Communication and Technology (Eurospeech 1997) 
[3] H. Hermansky and N. Morgan, "RASTA Processing 
of Speech", IEEE Trans. on Speech and Audio 
Processing, 1994 
[4] C-P. Chen and J-A. Bilmes, "MVA Processing of 
Speech Features", IEEE Trans. on Audio, Speech, 
and Language Processing, 2006 
[5] S. Yoshizawa, N. Hayasaka, N. Wada and Y. 
Miyanaga, "Cepstral Gain Normalization for Noise 
Robust Speech Recognition", 2004 International 
Conference on Acoustics, Speech and Signal 
Processing (ICASSP 2004) 
[6] J-W. Hung and L-S. Lee, "Optimization of Temporal 
Filters for Constructing Robust Features in Speech 
Recognition", IEEE Trans. on Audio, Speech and 
Language Processing, 2006 
[7] X. Xiao, E-S. Chng, and Haizhou Li, "Temporal 
Structure Normalization of Speech Feature for 
Robust Speech Recognition", IEEE Signal 
Processing Letters, vol. 14, 2007 
[8] Chi-an Pan, Chieh-cheng Wang and Jeih-weih Hung, 
"Improved Modulation Spectrum Normalization 
Techniques for Robust Speech Recognition", 2008 
International Conference on Acoustics, Speech and 
Signal Processing (ICASSP 2008), April 2008 
[9] Chieh-cheng Wang, Wen-Hsiang Tu and Jeih-weih 
Hung, "Study of Modulation Spectrum 
Normalization Techniques for Robust Speech 
Recognition", 2008 Conference on Computational 
Linguistics and Speech Processing (ROCLING 
2008), September 2008 
[10] H. G. Hirsch and D. Pearce, "The AURORA 
Experimental Framework for the Performance 
Evaluations of Speech Recognition Systems under 
Noisy Conditions", Proceedings of ISCA IIWR 
ASR2000, Paris, France, 2000  
[11] S. K. Mitra, "Digital Signal Processing", The 
McGraw-Hill International, 3rd edition, 2006 
[12] ITU recommendation G.712, "Transmission 
Performance Characteristics of Pulse Code 
Modulation Channels," Nov. 1996 
[13] http://htk.eng.cam.ac.uk/  
[14] Bocchieri , E. L., and Wilpon, J. G., "Discriminative 
Analysis for Feature Reduction in Automatic Speech 
Recognition", 1992 International Conference on 
Acoustics, Speech, and Signal Processing (ICASSP 
1992). 
[15] Julien Epps and Eric H.C. Choi, "An Energy Search 
Approach to Variable Frame Rate Front-End 
Processing for Robust ASR", 2005 European 
Conference on Speech Communication and 
Technology (Interspeech 2005—Eurospeech). 
[16] Weizhong Zhu and Douglas O’Shaughnessy, "Log-
Energy Dynamic Range Normalization for Robust 
Speech Recognition", 2005 International Conference 
on Acoustics, Speech, and Signal Processing 
(ICASSP 2005). 
[17] Hung-Bin Chen, "On the Study of Energy-Based 
Speech Feature Normalization and Application to 
Voice Activity Detection", M.S. thesis, National 
Taiwan Normal University, Taiwan, 2007. 
[18] C-F. Tai and J-W. Hung, "Silence Energy 
Normalization for Robust Speech Recognition in 
Additive Noise Environments", 2006 International 
Conference on Spoken Language Processing 
(Interspeech 2006—ICSLP). 
[19] Wen-Hsiang Tu and Jeih-weih Hung, "Exploiting 
Cumulative Quantized Spectrum in Silence Energy 
Normalization for Robust Speech Recognition in 
Additive Noise Environments", to be published in 
International Journal of Electrical Engineering, vol. 
出席國際學術會議心得報告 
                                                             
計畫編號  NSC 97‐2221‐E‐260‐031‐ 
計畫名稱  雜訊環境下於調變頻譜域之語音辨識特徵參數正規化之研究 
出國人員姓名 
服務機關及職
稱 
洪志偉, 國立暨南國際大學電機工程學系助理教授 
會議時間地點 2009/06/28~2009/07/03, 美國紐約Waldorf=Astoria Hotel, New York City 
會議名稱  2008  International  Conference  on  Multimedia  and  Expo  (ICME 2009) 
發表論文題目 Sub‐band  Feature  Statistics  Compensation  Techniques  Based  on Discrete Wavelet Transform for Robust Speech Recognition 
 
一、 參加會議經過 
 
本次會議原本預定在墨西哥坎昆(Cancun)舉辦，然而因為當時新流感(H1N1)在墨
西哥蔓延甚廣，會議主辦單位為了與會者健康安全起見，於五月底將會議地點
改至美國紐約市舉行。本人與共同作者(研究所學生)范顥騰於 6 月 28 日早上在
桃園機場搭乘飛機，飛往會議地點美國紐約市，歷經約 15個小時的飛行時間，
於 29日下午抵達紐約紐華克機場，隨即赴 Waldorf=Astoria  Hotel下榻。本次會
議也是在此旅館之會議中心所舉辦，因此在稍作休息後，即前往旅館三樓的會
議中心領取會議相關資料，並熟悉會場的環境與標記重要議程。會議前兩天(6/28
與 6/29)是 Tutorial  speech，而論文發表會期則是從 6月 30日上午開始，至 7月
3日下午結束，其間我每天即根據自己的專長及興趣，與研究生分別前往各個不
同的場次聆聽 keynote speech、lecture與 poster sessions的論文發表，有時並向
演講者發問或互相討論。在此次會議裡，遇見了國內外多媒體研究的傑出學者，
並有幸與他們相互交談及交換意見。本人的論文安排在 7 月 1 日下午以
"Multimedia Content Analysis and Synthesis" 為主題的 post session發表，論文題
目為『Sub‐band  Feature  Statistics  Compensation  Techniques  Based  on  Discrete 
Wavelet Transform for Robust Speech Recognition』，此篇論文提出一種分頻式的特
徵統計正規化法，藉此提升受雜訊干擾之語音辨認的精確度，根據之前的論文
搜尋發現，本篇論文為歷年以來首次以離散小波轉換(discrete wavelet transform)
來執行語音特徵之時間序列分頻帶處理與統計正規化程序，且達到十分優異的
語音強健性效果。發表的過程中，經由與在場許多學者相互討論交流，得到許
多寶貴的建議，使我與研究生都收穫頗多。在參加完 4 日的議程後，即於 5 日
早上前往機場搭機返回台灣。 
 
二、 與會心得 
Sub-band Feature Statistics Compensation Techniques Based on Discrete Wavelet Transform for Robust 
Speech Recognition 
 
Hao-Teng Fan and Jeih-weih Hung 
Dept of Electrical Engineering, National Chi Nan University 
Taiwan, Republic of China 
e-mail: s96323516@ncnu.edu.tw , jwhung@ncnu.edu.tw 
 
Abstract 
This paper proposes a novel scheme in performing feature 
statistics normalization techniques for robust speech recognition. 
In the proposed approach, the processed temporal-domain feature 
sequence is first decomposed into non-uniform sub-bands using 
discrete wavelet transform (DWT), and then each sub-band stream 
is individually processed by the well-known normalization 
methods, like mean and variance normalization (MVN) and 
histogram equalization (HEQ). Finally, we reconstruct the feature 
stream with all the modified sub-band streams using inverse DWT. 
With this process, the components that correspond to more 
important modulation spectral bands in the feature sequence can 
be processed separately. For the Aurora-2 clean-condition training 
task, the new proposed sub-band MVN and HEQ provide relative 
error rate reductions of 20.18% and 19.65% over the conventional 
MVN and HEQ. 
Index Terms—discrete wavelet transform, speech 
recognition, robust speech feature 
 
1. Introduction 
The environmental mismatch caused by additive noise and/or 
channel distortion often degrades the performance of a speech 
recognition system seriously. Various robustness techniques have 
been proposed to reduce this mismatch, and one category of them 
aims to normalize the statistics of speech features in both training 
and testing conditions. These feature statistics normalization 
techniques include cepstral mean subtraction (CMS) [1], mean and 
variance normalization (MVN)[2], cepstral gain normalization 
(CGN) [3], histogram equalization (HEQ) [4], higher-order 
cepstral moment normalization (HOCMN) [5] and cepstral shape 
normalization (CSN) [6], etc. Regardless of the simplicity in 
implementation, these methods usually enhance the noise 
robustness of speech features significantly and thus bring about 
better recognition accuracy.  
In the above feature statistics normalization methods, the features 
in an utterance are often viewed as the samples of a random 
variable, and thus the required statistical information (such as the 
mean, variance and probability distribution) of this random 
variable is estimated directly via these samples. Although it is 
simple in implementation, such a process somewhat ignores the 
time-varying characteristics (i.e., the modulation spectral 
information) of features within an utterance. From another point 
of view, it processes the components over the entire modulation 
frequency band in a joint manner. However, different modulation 
frequency components have unequal importance for speech 
recognition. More precisely, in [7] it has been shown that most of 
the useful linguistic information is in the modulation frequency 
components between 1 Hz and 16 Hz, with the dominant 
component at around 4 Hz. Some well-known temporal filters [8,9] 
are thus designed in order to highlight these important modulation 
frequency components and thus improve the recognition accuracy. 
Partially motivated by the above observations, in this paper we 
propose to decompose the feature stream into sub-band streams, 
and then the normalization process is performed on some or all 
sub-streams separately. The finally new feature stream is 
reconstructed by integrating all sub-streams properly. In particular, 
the above decomposition and reconstruction procedures are based 
on the well-known discrete wavelet transform (DWT)[10]. As we 
know, in DWT a non-uniform quadrature-mirror filter (QMF) 
bank is employed, which spreads over the entire frequency band 
and does not introduce aliasing distortion. Therefore, the filter-
bank processing within our proposed approach will not further 
contaminate the original feature stream or cause any information 
loss. Experiments conducted on the Aurora-2 digit database show 
that our proposed sub-band MVN and HEQ can further alleviate 
the distortions caused by noise and improve recognition accuracy 
more significantly when compared with the conventional ones 
which operate in a full-band manner.  
The remainder of the paper is organized as follows: Section 2 
introduces the proposed sub-band feature statistics compensation 
methods. The experimental setup is described in Section 3, and the 
experiment results are given and discussed in Section 4. Finally, 
Section 5 contains brief concluding remarks and future works. 
 
2.  The Sub-band Feature Statistics Compensation Methods 
Consider using the Mel-scaled filter-bank cepstral coefficients 
(MFCC) for speech recognition. Let 	 
 < >mx n  be the mth cepstral 
coefficient of the nth frame of an utterance. As a result, we have 
M feature streams,  
	 
 < >\ ^;1mx n n Nb b , 0 1m Mb b  ,                                         (1) 
where M  is the number of cepstral coefficients within a frame 
and N  is the number of frames of the utterance. Here, each 
feature stream 	 
 < >\ ^mx n  is processed with the objective that the 
resulting new feature stream, denoted as 	 
 < >\ ^mx n , can be more 
noise-robust and thus the recognition accuracy can be enhanced. 
For the sake of compact notation, we omit the superscript 	 
" "m  in 
	 
 < >\ ^mx n  and 	 
 < >\ ^mx n  in the later discussions. 
The procedures of our proposed method here are illustrated in 
Figure 1. First, the original feature stream < >\ ^x n  in an utterance 
is split into L  sub-band streams < >\ ^x nA , 1 Lb bA , by means of 
an octave-band analysis bank with down-sampling. The above 
process of generating the set of output sub-band streams is 
equivalent to performing an (L-1)-level discrete wavelet transform 
(DWT) on < >\ ^x n . Besides, given that the frame rate of < >\ ^x n  is 
sF  in Hz and thus < >\ ^x n  is within the modulation spectral band 
0, 2sF
  ¯¡ °¢ ± , the band range of the 
thA  sub-band stream can be 
approximately represented as 
	 

	 
 	 

1
2 1
1 1
1
0, 2                 if 1
2
2 2
2 , 2     if 2, 3, ,
2 2
sL
s sL L
F
F F L

 
 
£  ¯¦¦ ¡ °¦¦¡ °¢ ±¦¤  ¯¦¦¡ ° ¦¦¡ °¦¢ ±¦¥
A A
A
A "
.                                  (2) 
586978-1-4244-4291-1/09/$25.00 ©2009 IEEE ICME 2009
of all the utterances in the training set are used to estimate the 
required statistics (i.e. the mean ,aNA , variance 2,aTA  in eq. (3) and 
the probability distribution function 	 
, .X aF A in eq. (4)). The 
parameter L is preliminarily set to 4 here, which indicates that a 
3-level DWT is performed, and the frequency ranges for the 4 
octave sub-band streams are approximately [0, 6.25Hz] and 
[6.25Hz, 12.5Hz], [12.5Hz, 25Hz] and [25Hz, 50Hz], respectively. 
The Daubechies 2 (db2) wavelet is used in the DWT and IDWT 
processes.  
Finally, for each utterance in both the training and testing sets, 
each sub-band stream is used to estimate the required statistics (i.e. 
the mean ,sNA , variance 2,sTA  in eq. (3) and the probability 
distribution function 	 
, .X sF A  in eq. (4)). With all the statistical 
information, the sub-band statistics normalization methods, SB-
MVN and SB-HEQ, are realized on some or all sub-band streams 
for an utterance. The updated sub-band streams together with the 
other unchanged ones are used to reconstruct the feature sequence 
for that utterance. The resulting 13 new features, plus their first 
and second order derivatives, are then the components of the 
finally used 39-dimensional feature vector. With these new feature 
vectors in the clean training set, the HMMs for each digit and 
silence are trained following the Microsoft complex back-end 
training scripts [12]. Each digit HMM has 16 states and 20 
Gaussian mixtures per state. 
 
4. Experimental Results and Discussions 
Tables 1 and 2 list the recognition results of the MFCC baseline 
and various methods for Test Sets A, B and C, where Table 1 
presents individual set recognition accuracy rates averaged over 
five SNR conditions (0~20dB, with 5dB intervals), and Table 2 
contains the recognition accuracy rates for different SNR 
conditions averaged over all the noise types in the three Test Sets. 
In the two tables, the two full-band processing methods, FB-MVN 
and FB-HEQ represent the original MVN and HEQ, respectively. 
Besides, we conduct the new proposed SB-MVN and SB-HEQ in 
four modes.  Different modes correspond to different number of 
lower sub-bands to be processed by MVN or HEQ. For example, 
"SB-MVN(1,2)" indicates that the lowest two sub-bands (i.e. [0, 
6.25Hz] and [6.25Hz, 12.5Hz]) are MVN-processed, and  "SB-
MVN(1,2,3,4)" indicates that all the four sub-bands are MVN-
processed. In other words, for the modulation frequency range to 
be dealt with, the lower cutoff frequency is always fixed at 0Hz 
while the higher cutoff frequency is varied, with the main reason 
that the lower frequency components are usually regarded as more 
important than the higher ones. 
From Tables 1 and 2, some phenomena can be observed as follows: 
1. Compared to baseline processing, all versions of MVN and 
HEQ provide very significant improvement (more than 45% in 
relative error reduction) in averaged recognition accuracy. 
Besides, HEQ outperforms MVN in almost all cases, which 
reveals the fact that compared with MVN, the extra 
compensation for higher order moments of features in HEQ 
help improving the recognition accuracy. 
2. All the four modes of SB-MVN outperform the original FB-
MVN, and the situation holds for SB-HEQ and FB-HEQ. In 
particular, the best possible SB-MVN and SB-HEQ give rise to 
20.18% and 16.65% in relative error reduction compared with 
FB-MVN and FB-HEQ, respectively. These results show that 
the new proposed sub-band processing approaches behave 
better than the conventional ones, and they support our 
statements in the previous sections that performing the 
normalization process on each sub-band separately rather than 
on the entire band helps a lot.  
3. For the matched clean condition, all methods give very similar 
high recognition accuracy, which implies that these methods do 
not reduce the discriminating capability of the original MFCC 
features. However, under the various mismatched noisy 
conditions, all these methods enhance the robustness of MFCC 
with significantly improved recognition accuracy. At high 
SNRs of 20dB and 15dB, the performance difference among 
full-band and sub-band approaches is insignificant. When the 
SNR gets worse, SB-MVN and SB-HEQ outperform FB-MVN 
and FB-HEQ, respectively, in most cases.  
4. For the different modes in SB-MVN and SB-HEQ, we find that 
even only the lowest sub-band ([0, 6.25Hz]) features are 
processed while the higher frequency components are kept 
unchanged (in the methods of SB-MVN(1) and SB-HEQ(1)), we 
still can achieve significant accuracy improvement with respect 
to baseline processing. As we increase the number of sub-bands 
for normalization, the accuracy rate is also raised accordingly in 
most cases. In particular, processing the lowest two sub-bands 
([0, 6.25Hz] and [6.25Hz, 12.5Hz])  as in the methods "SB-
MVN(1,2)" and "SB-HEQ(1,2)" already achieves the nearly 
optimal performance. Further processing the higher sub-bands 
often just results in a relatively slight improvement. These 
results are somewhat consistent with the observation in the past 
research that the modulation frequency components between 
1Hz and 16Hz are particularly important for speech recognition. 
 
 
Method Set A Set B Set C Avg. RR1 RR2
Baseline 72.46 68.31 78.82 72.07 ʳ Ё Ё 
FB-MVN 85.07 85.57 85.63 85.38 ʳ 47.66 Ё 
SB-MVN(1) 86.11 87.54 86.45 86.75 ʳ 52.56 9.36 
SB-MVN(1,2) 87.87 88.96 87.77 88.29 ʳ 58.06 19.87 
SB-MVN(1,2,3) 88.06 88.86 87.82 88.33 ʳ 58.22 20.18 
SB-MVN(1,2,3,4) 87.87 88.71 87.61 88.15 ʳ 57.58 18.96 
FB-HEQ 86.95 88.39 87.40 87.62 ʳ 55.66 Ё 
SB-HEQ (1) 87.70 89.31 87.81 88.37 ʳ 58.34 6.06 
SB-HEQ (1,2) 89.22 90.55 90.23 89.95 ʳ 64.03 18.88 
SB-HEQ(1,2,3) 89.51 90.75 89.54 90.01 ʳ 64.24 19.35 
SB-HEQ (1,2,3,4) 89.51 90.83 89.57 90.05 ʳ 64.37 19.65 
Table 1. Recognition accuracy (%) achieved by various methods 
for the Aurora-2 clean condition training task averaged across the 
SNRs between 0 and 20dB. RR1 (%) and RR2 (%) are the relative 
error rate reductions over the baseline and the full-band methods, 
respectively 
 
 
Method clean 20dB 15dB 10dB 5dB 0dB 
baseline 99.79 95.51 88.11 74.76 57.55 44.46
FB-MVN 99.80 98.73 96.87 91.92 79.60 59.78
SB-MVN(1) 99.81 98.60 96.74 91.60 81.30 65.50
SB-MVN(1,2) 99.77 98.66 97.22 93.22 84.12 68.21
SB-MVN(1,2,3) 99.76 98.73 97.24 93.26 84.28 68.14
SB-MVN(1,2,3,4) 99.75 98.71 97.12 93.02 84.02 67.89
FB-HEQ 99.76 98.89 97.39 93.53 83.34 64.96
SB-HEQ (1) 99.72 98.72 97.31 93.34 83.98 68.49
SB-HEQ (1,2) 99.64 98.84 97.64 94.50 87.52 71.28
SB-HEQ(1,2,3) 99.66 98.84 97.70 94.68 87.09 71.74
SB-HEQ (1,2,3,4) 99.64 98.85 97.69 94.74 87.15 71.83
Table 2. Recognition accuracy (%) achieved by various methods 
for different SNR values averaged over all noise types in Test Sets 
A, B and C of Aurora-2 clean condition training task 
588
