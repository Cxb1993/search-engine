    上述相關於安全偵測的研究重點在於準確性與穩定性。視
覺安全偵測很容易受到天候及環境因素的影響；所以技術研發
的關鍵在於方法是否不受天候狀況 (晴、陰、雨、霧、暗) 的
影響；是否在各式道路環境 (高速、快速、平面道路、巷弄、
鄉間小道) 都可維持良好的偵測效果。考慮各種天候及環境因
素對於視覺偵測的影響是我們技術發展上的特色之一。 
英文摘要： In these few decades, the vehicle number is rapidly 
increasing because people’s incomes are increasing. 
In addition to the vehicle number, more factors of 
road situation, driving environment, and human 
attention result in a large amount of traffic 
accidents and casualties. If there is a mechanism to 
help the driver to detect the road situation and 
driving environment, and then to provide some useful 
information to the driver in these situations, the 
danger is therefore avoided. In this research project, 
we are just combining the techniques of computer 
vision, image processing, and pattern recognition, and 
matching the domestic environment to develop state-of-
the-art techniques of vision detection to reduce the 
load of drivers, to reduce the traffic accidents, and 
then improve the driving safety.  
    From 2001, we have studied the vision detection 
techniques for the advanced safety vehicle. Based on 
the versatile computer vision techniques, we proposed 
methods to detect the situations of driving 
environment and personal conditions and provide 
warning to improve the safety of driving. Based on our 
previous basis and the results, this research project 
aims various driving conditions to develop new-
function and more practical techniques to aid driving. 
    There are four studying topics of computer vision 
in this research project: (1) forward and rear 
collision detection and warning, (2) detection in side 
and blind spots, (3) parking assistance, and (4) 
driver drowsiness detection and warning. 
    These four topics will be executed 
simultaneously； the studying items in each research 
topic will be sequentially completed in the following 
three years. 
The studying topics of the first-year project include: 
(1) binocular stereo vision detection technique, (2) 
 - 1 -
 
行政院國家科學委員會補助專題研究計畫 ■成果報告   □期中進度報告 
 
 
輔助道路安全駕駛的多樣性視覺偵測技術 
 
計畫類別：■個別型計畫   □整合型計畫 
計畫編號：NSC 97-2221-E-008 -073 -MY3 
執行期間：97 年 8 月 1 日至 100 年 7 月 31 日 
 
執行機構及系所：國立中央大學資訊工程系 
 
計畫主持人：曾定章 
計畫參與人員：林君威、王嘉鈺、李侑青、黃竫淳、鄭育昕、楊小璿、 
吳怡君、陳致民、李國煒、張均為、陳威伸 
 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
■出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
 
中   華   民   國 100 年 7 月 31 日 
 
 - 3 -
 
中文摘要 
關鍵詞： 智慧車輛、先進安全車輛、輔助安全駕駛、單眼電腦視覺、車輛防撞偵測、側邊盲
點偵測、停車輔助、駕駛昏睡狀態偵測 
隨著經濟快速成長，人民所得提高，生活品質提昇，人口增加，機動車輛數量亦隨之快
速成長。車輛增多，再加上開車時的各種環境、道路、及人為等因素，而使得交通事故之件
數及其所造成之死傷人數也相對增加。因此若能有一些協助駕駛人偵測道路狀況、行車狀況、
及駕駛狀況等機制，提供各種道路相關資訊給駕駛人，並提醒駕駛人，對社會大眾而言，勢
必多了一層安全保障。本研究的目的即是結合電腦視覺、影像處理、與圖形識別等技術，考
慮各國環境之需求，發展與世界同步之視覺偵測技術，給予駕駛者提醒、警示、及預防等機
制，降低駕駛者工作負荷，減低人為失誤，進而預防交通事故發生，提升行車安全性。 
從 2001 年起，我們就一直在從事先進安全車輛之視覺偵測技術的研究。藉由多樣性的
電腦視覺偵測技術，偵測駕駛環境及個人狀況，提供警示功能，以提高行車安全。本研究即
建立在過去的基礎及成果上，繼續針對各種可能的交通安全性及駕駛方便性，發展更新的或
更穩定的電腦視覺輔助道路安全駕駛技術；讓技術得以實現出來，創造利潤，造福人群。 
本計畫之電腦視覺系統涵蓋了四個研究主題：(1) 前後車防撞偵測、(2) 側邊盲點偵測、
(3) 停車輔助、及 (4) 駕駛昏睡狀態偵測。 
(1) 前後車防撞偵測的研究項目有：双眼立體視覺偵測技術發展、FCW 的車輛偵測/追蹤、
LDW/FCW 的嵌入式系統化。 
(2) 側邊盲點偵測的研究項目有：盲點位置的物體偵測及距離估計、整合動態與靜態資訊的盲
點偵測、多重解析度的光流估計。 
(3) 停車輔助的研究項目有：環場鳥瞰監視系統、倒車軌跡分析、環場鳥瞰偵測的停車輔助。 
(4) 駕駛昏睡狀態偵測的研究項目有：不均勻照度的臉部/眼睛偵測與分析、昏睡與注意力分
析、3D 臉部方位偵測的駕駛注意力分析。 
四個研究主題將同時執行；每個研究主題中的工作項目都將依序在三年中完成。 
第一年的研究項目有：(1) 双眼立體視覺偵測技術發展、(2) 盲點位置的物體偵測及距離估
計、(3) 環場鳥瞰監視系統、(4) 不均勻照度的臉部/眼睛偵測與分析。 
第二年的研究項目有：(1) 車輛偵測/追蹤、(2) 整合動態與靜態資訊的盲點偵測，(3) 倒車軌
跡分析，(4) 昏睡與注意力分析。 
第三年的研究項目有：(1) LDW/FCW 的嵌入式系統化、(2) 多重解析度的光流估計、(3) 環
場鳥瞰偵測系統、 (4) 3D臉部方位偵測的駕駛昏睡與注意力分析。 
上述相關於安全偵測的研究重點在於準確性與穩定性。視覺安全偵測很容易受到天候及
環境因素的影響；所以技術研發的關鍵在於方法是否不受天候狀況 (晴、陰、雨、霧、暗) 的
影響；是否在各式道路環境 (高速、快速、平面道路、巷弄、鄉間小道) 都可維持良好的偵
測效果。考慮各種天候及環境因素對於視覺偵測的影響是我們技術發展上的特色之一。 
 
 - 5 -
detection system, and (4) 3D face orientation estimation for drowsiness analysis and 
discrimination. 
The key problems of the safety detection techniques are accuracy and stability. The methods 
concerning the safety vehicles are easily influenced by climate conditions and environment factors; 
thus the key points of useful methods are whether the proposed methods are not influenced by 
various climate conditions (sunny, cloudy, rainy, foggy, and night days) ? whether the proposed 
methods may keep well performance in variant road conditions (freeway, highway, general road, 
and country roads). Considering the influence factors of climate conditions and environment 
situations to the vision detection techniques is one characteristic of our development of the 
computer vision techniques for advanced safety vehicles. 
 
 - 7 -
駕駛狀況偵測：酒醉駕車、疲勞駕駛、蛇行、緊急煞車、頃幅、震幅， 
突發事件偵測：人、車、物、或其他移動物體的橫向突發狀況等。 
本研究計畫是一個三年期的研究計畫，在本計畫的研究中，我們共規劃了四個電腦視覺
研究主題，用於輔助道路安全駕駛：(1) 前後車防撞偵測、(2) 側邊盲點偵測、(3) 停車輔助、
及 (4) 駕駛昏睡狀態偵測。 
(1) 前後車防撞偵測的研究項目有：双眼立體視覺偵測技術發展、FCW 的車輛偵測/追蹤、
LDW/FCW 的嵌入式系統化。 
(2) 側邊盲點偵測的研究項目有：盲點位置的物體偵測及距離估計、整合動態與靜態資訊的盲
點偵測、多重解析度的光流估計。 
(3) 停車輔助的研究項目有：環場鳥瞰監視系統、倒車軌跡分析、環場鳥瞰偵測的停車輔助。 
(4) 駕駛昏睡狀態偵測的研究項目有：不均勻照度的臉部/眼睛偵測與分析、昏睡與注意力分
析、3D 臉部方位偵測的駕駛注意力分析。 
四個研究主題將同時在三年中執行。每個研究主題中的工作項目都將依序在三年中完成；每
個研究主題中的工作項目都有前後順序的關係，如圖 1 所示。 
 
第一年 双眼立體視覺偵測技術發展 
 盲點位置的物體
偵測及距離估計
環場鳥瞰監視系
統 
 不均勻照度的臉
部/眼睛偵測 
       
第二年 車輛偵測/追蹤  整合動態與靜態資訊的盲點偵測 倒車軌跡分析
 昏睡與注意力分
析 
       
第三年 LDW/FCW 的嵌入式系統化 
 多重解析度的光
流估計 
環場鳥瞰偵測系
統 
 3D 臉部方位偵
測的注意力分析
圖 1 . 四個研究主題分在三年中執行。 
 
第一年的研究項目有：(1) 双眼立體視覺偵測技術發展、(2) 盲點位置的物體偵測及距離估
計、(3) 環場鳥瞰監視系統、(4) 不均勻照度的臉部/眼睛偵測與分析。 
第二年的研究項目有：(1) 車輛偵測/追蹤、(2) 整合動態與靜態資訊的盲點偵測，(3) 倒車軌
跡分析，(4) 昏睡與注意力分析。 
第三年的研究項目有：(1) LDW/FCW 的嵌入式系統化、(2) 多重解析度的光流估計、(3) 環
場鳥瞰偵測系統、 (4) 3D臉部方位偵測的駕駛昏睡與注意力分析。 
 
三、文獻探討 
以下就我們所找到與本研究相關的研究技術：(1) 前後車防撞偵測、(2) 側邊盲點偵測、
(3) 停車輔助、及 (4) 駕駛昏睡狀態偵測，個別闡述於下。 
 
3.1 前後車防撞偵測 
前車偵測在車輛的視覺安全偵測中是最重要也是最難的一項 (難在於準確與穩定)。基本
上，每一個車輛偵測系統都會有兩個基本步驟：(i) 偵測出所有可能車輛 (hypothesis generation, 
HG) 及 (ii) 確認每一個可能車輛 (hypothesis verification, HV) [34 , 35]。在過去十年中，有許
多車輛偵測技術被提出，這些方法可分成三類：特徵偵測法、立體視覺法、及動態分析法。
這些方法的優缺點比較陳列在表 1 中。一般前車或障礙物偵測都會執行兩個步驟：偵測 
 - 9 -
     
圖 3. 車輛偵測的流程。 
 
Sun et al. [34] 使用一組 Gabor 濾波器來偵測確認前車。他們提出 Gabor 濾波器的最佳
演進法 (evolutionary Gabor filter optimization, EGFO) 來區別什麼特徵是車輛，什麼特徵不是
車輛的，如圖 4 所示。 
 
 
圖 4. 兩階段的車輛偵測策略。 
 
3.2 側邊盲點偵測 
側邊監測可以幫助駕駛者偵測到在 “盲點” (blind spot) 車的兩側和後方車輛，使得駕駛
者可以安全的在高速公路上轉換車道，如圖 5 所示；其中標示 “1” 是盲點範圍，”2” 是側邊
的偵測範圍。轉換車道輔助系統 (Lane Change Assistance, LCA) 是一個以短程感測模式為主
加上長距離的感應器來偵測相鄰車道中高速接近和可能在駕駛者轉換車道時發生危險的車輛 
[6]。 
 
 
 
 
 
 
 
 
 
 
 
 
圖 5. 側邊盲點監測。 
 
2
1
1
2
 - 11 -
裝上側邊監測系統的公車發生了100起碰撞事件，而沒有裝的公車發生了 300 起。這個系統
很快的就被商品化，減少了感測器監測的範圍並應用在一般車輛上來防止碰撞的發生。 
 
3.2.4 適應不同天氣狀況的車道轉換輔助系統 [11] 
一個車道轉換決策輔助系統 (Lane Change Decision Aid System, LCDAS) 可以只使用一
部相機來偵測在相鄰車道內的車輛並會在駕駛準備轉換車道且可能發生危險時對駕駛發出警
告。LCDAS 系統 [11] 裝在左右兩側後照鏡上，主要是偵測出在兩側後方及正後方的車輛，
當駕駛想要轉換車道時，系統會評估狀況，如果換車道可能發生危險，系統便會警告駕駛，
但系統並不會對可能發生的碰撞採取自動控制車輛的行動，安全控制車輛仍然是駕駛的責任。 
LCDAS 的一個重點技術就是無論天氣都能準確的偵測出接近的車輛，一個使用相機感測
器的系統對於亮度的變化是很敏感的，所以車輛的偵測是會被現實世界的種種因素影響的。
為了能夠解決亮度和天氣變化的問題，我們將系統分成三種模式:白天、夜晚、雨天。模式是
根據車頭燈和雨刷是否啟動的訊號而做切換，再以輪胎上的訊號確認駕駛是否要轉換車道和
了解轉換的方向，系統同時接收後照鏡上的影像和各種訊號分析，如果分析出來的結果是有
危險的，系統會用燈光或聲音發出警告。白天模式是根據影像中特定區域中的車底陰影來判
斷來車。夜晚模式則是改用來車頭燈作為判斷的依據。雨天模式分成兩個部份：短程模式、
長程模式。短程模式和白天模式一樣使用車底陰影來辨識車輛，長程模式和夜晚模式一樣使
用車頭燈的燈光來辨識車輛；在近距離，車頭燈的燈光對偵測車底陰影的影像較小，但當距
離越長影響也就越強。所以在這個模式中，影像會先轉換成反白影像，並使用車底陰影辨識
車輛；如果找不到車，則轉換成和夜晚模式一樣以車頭燈燈光作為辨識的特徵。另外也有以
光流資訊、模板比對法、或卡爾曼濾波器 (Kalman filter) 執行車道轉換輔助 [1]。 
 
3.3 停車輔助 
行車的安全愈來愈受到重視，道路交通事故的主要原因，大致是沒有看到或看不清楚而
無法立即發現危險做必要措施所引起。駕駛者在行駛車輛時，因為車輛的車速、結構、後視
鏡，以及人體視覺的視野不同，導致駕駛人的視野死角。一般人的雙眼水平視野約 200°，而
能清楚辨識的範圍約只有 75°，駕駛者坐在汽車駕駛座，部分視野或視線會被車體結構遮蔽，
所以視野又更小了。 
不論我們的後視鏡有多寬或駕駛的頭轉動幅度有多大，在駕駛過程中難免會產生死角，
使得駕駛無法了解全面的路況。透過先進的電腦視覺技術可以避免因駕駛死角而無法知覺周
圍狀況所產生的交通意外發生。 
我們將停車輔助系統分成下列三個階段：(i) 車體環場鳥瞰監視系統，(ii) 車輛前進後退
之軌跡分析，及 (iii) 結合環場監視與軌跡分析停車輔助。 
 
3.3.1 車體環場鳥瞰監視系統 
三洋電機於2007年10月17日宣佈，開發出了“車載用全方位顯示器系統”。該系統可通過 4 
個攝影頭拍攝影像，在螢幕上合成顯示出如同從上方俯瞰車輛的影像，如圖 6 所示。目的是
為卡車及越野車等大型車輛停車以及在十字路口轉向時提供支援。攝影頭配備在車輛前後左
右 4 個位置。其影像處理過程為：先將各影像執行補償失真，將視點轉換為上方的轉換處理
後再合成到一起。在合成影像時，使用了新開發的拼接、對位演算法，實現了高品質的影像。
另外，日產汽車及松下電器產業也開發類似系統，通過 4 個攝影機拍攝影像合成出如同從上
方俯瞰車輛的結果。 
 - 13 -
以下我們就與本計畫相關的研究議題：昏睡偵測方法、眼睛偵測、眼睛閉合分析、臉部
偵測、臉部方向估計等，闡述於下: 
 
表 2. 疲勞偵測技術 
偵測技術 描  述 準確度 實用性 擴充性
生理 
現象 
生理信號 腦波變化、心跳、脈搏、皮膚電位變化、等 ◎ X △ 
身體反應 眨眼、眼睛閉合頻率、頭部傾斜變化、頭部下垂姿勢、手部握力 ◎  ◎ 
駕駛操作 駕駛操作行為的改變；例如，方向盤、加速、煞車、換擋、等  ◎ X 
車輛行為 車輛行為的改變；例如，速度、偏離車道、快速過彎、蛇行、頃幅、震幅、等  ◎ X 
駕駛反應 開車時的週期性刺激測試反應 △ X ◎ 
行車狀況 已開車時間、天色 (白天/夜晚)、身體狀況 (感冒、胃痛)、開車速度、等 X  ◎ 
◎：很好   ：好   △：普通   X：不好 
 
3.4.1 駕駛人昏睡狀態偵測 
圖 8 是一個典型的視覺式昏睡偵測系統，主要可以分為兩個子系統：影像處理子系統及
昏睡分析子系統。影像處理子系統主要是在執行臉部定位、眼睛定位、與眼部狀態偵測等工
作。疲勞分析子系統主要是依據駕駛人眨眼頻率與眨眼間隔，來判別駕駛人是否是在疲勞的
狀態，並適時的對駕駛人提出警告。 
 
 
 
 
 
 
 
 
 
 
圖 8. 昏睡偵測系統。 
 
影像處理的方法分兩類，一類是以膚色為基準來偵測臉部與嘴角位置，另一類是用紅外
線攝影來捉取臉部影像。通常比較需要昏睡狀況偵測的時刻是夜晚，因此使用紅外線攝影機
是比使用彩色相機適合，不過要注意該紅外線攝影機的感光波長範圍，否則易受雜訊干擾。 
Ueno et al. [37] 以駕駛人的眨眼情形來估計駕駛人警覺性 (alertness level)，並且確認了
眨眼、臉部表情、與腦波 (α2 波) 三者之間的關係，圖 9 所示。當一個人的警覺性降低，大
量的 α2 波會出現且振幅 (amplitude) 變大。我們量測腦波的高低電位變化來評估眨眼及眼睛
閉合的時間及頻率。在正常的警戒心情下，眨眼會呈現尖銳的波形。當人的警覺性下降，尖
銳的波形會更頻繁，但波型會變得混亂些。當眼睛閉合久一點，腦波會變成凌亂的梯型，如
圖 9 所示。 
 
影像處理系統 
昏睡分析系統 
昏睡警示系統
紅外線相機 
 - 15 -
  
(a) 暗瞳效應。       (b) 亮瞳效應。 
圖 11. 瞳孔反應。 
 
為了進一步去除背景光源的影響，在抓取奇數影像時只點亮外圈的紅外光 LED，則可得
到暗瞳的影像，在抓取偶數影像時只點亮內圈的紅外光 LED，則可得到亮瞳的影像，兩張影
相減則可去除背景光源的影響，並可得到更明顯的瞳孔影像。 
將強化後的影像依 minimizing kullback information distance 取得之閥值做二值化，得到一
群圖形，再依形狀、大小、相對位置確定是否為瞳孔位置，並使用卡曼濾波器 (Klman filter) 追
蹤連續影像之間的瞳孔位置。頭部的轉動則是依照兩眼之間的距離，兩瞳孔的大小來決定轉
動的方向。駕駛人視覺凝視的方向則由亮瞳的中心與暗瞳上的反光點相對的位置來決定凝視
方向。 
Ji et al. [22] 後來改進了即時駕駛人疲勞監視系統。此系統使用一個固定裝置的 CCD 相
機搭配主動式的紅外線發光源來取得駕駛人的影像。藉由各種不同的視覺線索被即時地選取
出來並且有系統地結合這些線索推測駕駛人疲勞的狀態為何，判斷警示的程度為何。這些視
覺線索利用眼瞼的移動、視線的移動、頭部的移動行為和臉部表情的表現來當作特徵。發展
一個模組來判斷人類疲勞的行為表現，並且根據觀察到的視覺線索和一些可利用判斷的資訊
來預測疲勞的發生可能。同時利用多項視覺線索和有系統地結合多種研究領域來判斷疲勞特
徵，比起僅使用單一視覺線索而言，已經越來越穩定和正確了。這套系統已證實可用在真實
生活的人類疲勞情況下，無論是不同的人種、性別、年紀、有無配戴眼鏡及不同的亮度情況
都適用。此系統在疲勞特徵的判斷相當可靠、穩定。 
 
3.4.3 駕駛人眼睛偵測與分析 
駕駛人特徵偵測最困難的地方在於如何經由影像處理與電腦視覺的技術去穩定的偵測頭
部、臉部、與眼睛的動作 [43]。 
即時的臉部偵測與眼睛追蹤是頭部姿勢辨識及臉部表情辨識的第一步驟。Kawato and 
Tetsutani [23] 提供一個新的圓形頻率濾波器 (circle-frequency filter) 來偵測及追蹤臉上的特
徵點 (位於兩眼之間的特徵點，稱為 between-eye)，如圖 12 所示。這個濾波器與旋轉無關，
且能夠容忍臉部大角度的旋轉變異。這個濾波器的計算很簡單，因此可以結合膚色區域擷取
技術來即時的從視訊中偵測及追蹤臉部的特徵點，如圖 13 所示。 
 
  
圖 12. 使用圓形頻率濾波器找出 “between-eyes“ 特徵範例。 
 
 - 17 -
析包括 Hough transforms 來找到圓還有使用輪廓相互關係的 reciprocal operations。 
Shih et al. [29] 提出了一個使用 3D 視覺系統來測量和追蹤人的 3D 視線。這個方法使用
多個相機還有許多光源點來測量視線而不使用使用者相關的參數，因此避免了麻煩的校正處
理。這個方法使用一個簡單的眼睛模型，首先使用紅外線光源的 Purkinje images 來確認眼睛
位置。當光打到中間時有些部份會反射有些部份則會折射。一開始的 Purkinje image 是表面的
角膜反射光線所產生。然後他們靠著測量出的角膜中心然後使用線性關係來決定視線。 
Hamada et al. [17] 提出一個影像擷取及處理系統來測量駕駛在駕駛時的狀態。首先他們
設計了一個對照周圍亮度變化的擷取方法。然後針對不同的個人臉部對那些圍繞著眼睛的圖
形做影像處理。他們個別的處理眨眼的波長，最後在推論出駕駛清醒時眨眼的週期。 
 
3.4.4 駕駛人臉部偵測與分析 
Smith et al. [30, 31] 以膚色為基準來偵測臉部與嘴角位置，再利用嘴角位置來幫助偵測眼
睛位置，並且使用階層式的追蹤策略來減少運算量，如圖 15 所示。另外他們還分析駕駛人的
視線方向。使用膚色為基準偵測臉部容易受到天氣及周遭光源的變化而影響到結果。 
 
   
圖 15. 以膚色為基準偵測臉部。 
 
Yan et al. [40] 提出了一個參考亮度區塊的主動外形模式 (texture-constrained active shape 
model, TC-ASM) 演算法從影像中找出臉部。此模式同時包含了外形及亮度區塊特徵。因此，
在偵測上很穩定，不會受到光源變化的影響。 
Cristinacce and Cootes [12] 使用 AdaBoost 及一系列的 Haar 小波函數做特徵偵測臉
部。再以整體外形限制 (global shape constraint) 來改善特徵偵測的效能。實驗結果顯示，對
於各種不同解析度影像，這都是一個能夠正確且可靠偵測臉部特徵的方法，如圖 16 所示。 
 
 
圖 16. 使用 AdaBoost 及整體外形限制的偵測結果。 為偵測到的點，+ 為預測的
點，方格是整體搜尋區域。 
 - 19 -
在車輛前方的行人偵測中，我們先將左右影像經由雙相機校正方法，依序透過相機參數
校正、扭曲校正、以及影像矯正，得到左右極線彼此平行且對齊的影像。其中，經過影像矯
正後的影像與光軸的交點已經改變，所以在此我們將影像矯正後的影像再做一次相機參數校
正，得到目前影像與相機的新關係。接著進入視覺技術偵測，首先透過關聯式動態規劃法計
算出像差圖；將像差圖經由形態學平滑化消除雜訊；利用 v-像差將地面資訊濾除，接著產生
連結區塊，將區塊根據在影像上的長度及距離分為長度太小與夠大兩類；長度太小的區塊則
根據單眼影像的色彩資訊判斷相鄰且距離差距不大的區塊是否為同一物體，接著與長度夠大
的區塊一起經由地面消失線濾除高於地面太多的物體，並判斷區塊的距離及長度是否符合我
們定義的長度範圍；最後根據行人的長寬比例框出結果並根據像差值求得該物體與攝影機之
距離。雙眼立體視覺偵測流程如圖 17 所示。 
 
4.1.2 車輛偵測/追蹤 
過去六年多來，我們ㄧ直都在進行單眼電腦視覺輔助道路安全駕駛的研究。在前車偵測、
距離估計、偏離車道偵測、與偏離車道警示方面 (FCW & LDW) 應用於高速及快速道路上已
有相當的成果。在本計畫中，我們將繼續相關的前後車防撞及偏離車道警示研究，應用於更
難的天候環境及平面道路上，如圖 18 所示。 
前車偵測中最常使用的方法就是利用車輛在地面上的陰影偵測前車，但是在雨天或天候
不良的狀況下，無法有效的偵測到陰影。為了在不同的天氣下都能穩定的偵測前車，我們提
出以水平邊及垂直邊的互動組合偵測前車。首先，我們動態的二值化水平邊及垂直邊；並且
利用水平邊的真實寬度濾除過短的水平邊。接著，估算水平邊上方的垂直邊的顯著程度，如
果水平邊上方的垂直邊夠顯著，我們判斷這條水平邊為車輛的最底部的水平邊，並在水平邊
的左右兩側找到垂直的邊緣，產生候選車輛。而水平邊上方的垂直邊不夠顯著時，我們則是
在水平邊的左右找一組對稱的垂直邊配對作為垂直邊緣。這時我們無法以水平邊找到車輛的
底部，我們改以垂直邊配對的底部作為候選車輛的底部，產生候選車輛。最後，我們利用支
持向量機 (SVM) 對候選車輛做驗證判斷候選車輛是否為車輛或障礙物。 
 
   
(a) 雨天。               (b) 大雨天。                (c) 傍晚。 
   
(d) 長車底陰影。           (e) 地面標誌。              (f) 長陰影。 
圖 18. 不良於前車偵測的範例。 
 
 - 21 -
體左右垂直邊界尋找可能的車體區塊，再利用車寬與車道寬的比例、區塊對稱性及區塊灰階
的變異數來驗證找到的區塊是否屬於車輛。 
為了增加處理速度和正確率，系統會參考連續影像的資訊，對已經偵測到的車體區塊進
行追蹤。利用前幾張影像中車體區塊的中心位置，預測車輛在下一張影像的位置，並且用固
定比例來擴大出一個追蹤範圍。系統在追蹤範圍中搜尋新的車體區塊，並比對新的追蹤區塊
與偵測區塊的灰階變異數差異，以判斷是否屬於同一台車。如果符合條件的話，則利用新偵
測到的區塊更新所要追蹤的車輛區塊，並繼續追蹤和記錄車體中心位置在連續影像中的移動
向量。如果車輛逐漸逼近己車，則系統會在駕駛人打方向燈時提出警示。 
假設相機座標系統相對於空間座標系統只有左右 (yaw) 及上下 (pitch) 的旋轉關係，沒
有 roll 旋轉。在三度空間中，右車道線與相機光軸在地面上的投影向量之夾角為 。右車道
線投影到相機之 yz-plane 上，與相機光軸 (z-axis) 的夾角為 。若已知相機與路面的垂直距
離為 h，而相機光軸所指的路面點 (也就是影像中心點所表示的路面點) 到相機所在位置垂直
的路面距離為 Z，則根據直角三角形的關係， 
 tan
Z
h   cot   hZ  .                                                    (1) 
現在我們要從已知的車道寬 W 求在影像中水平方向的車道寬 w。在相機沒有 roll 旋轉
的情形下，影像中的任一條水平線一定與該水平線反向投影到地面的直線平行；因此影像中
央水平方向的車道寬 wl 與該水平線反向投影到地面的三維車道寬 (W/cos) 之關係為 
o
W
q
w cos ，                                                            (2) 
其中 q 是像距，o 是從鏡頭到相機光軸所指的路面點 (xo, yo) 的距離， 
o
hsin 。                                                              (3) 
結合公式 (2) 及 (3)，我們可以得到影像中央水平方向的車道寬 w。 


cos 
sin  
h
Wqw  。                                                         (4) 
假設某一條水平線在影像平面中心點的下方 a1 距離處。而其路面位置到相機的路面距離
為 Z1，其視線為光軸下轉 1 角；也就是該視線與光軸的夾角 1，則該視線與車道線的夾角
為  1 
 1 =  + 1 .                                                           (5) 
根據相機座標系統中的直角三角形關係，我們可以求出 1， 
)(
q
a
q
a 11-
11
1 tan    tan   .                                              (6) 
也就是 )  (tan 111 q
a 。因此在影像中央下方 a1 處的水平方向之車道寬為 


cos 
sin  1
1 h
Wq
w  。                                                         (7) 
另外，我們也知道 
 11 cot hZ  .                                                            (8) 
 - 23 -
疊部份，可以作適當的色彩混合及亮度一致化，使所產生出來的拼接影像整體平順自然。而
就拼接影像的可監控範圍而言，現有的環周監控停車輔助系統的可監控區域為介於車外的 1.5
到 3 米之間的地面，而攝影機實際拍攝到的原始影像中，除了車身旁邊的地面區域外，還有
拍到高出地面的景觀，例如是更遠處的來車、行人、障礙物等。這些景物會因鳥瞰轉換後，
影像中高出地面的景物會被轉換函數沿影像中心向外嚴重拉扯成失真影像，因此無法被現有
的鳥瞰監控系統所利用。 
我們就以上問題，建立了一組影像徑向的非等比縮放函數，把失真的影像處理成可利用
的有效影像，為駕駛提供更廣範圍的全周監控，並建構 3D 模型，把現有 2D 的視覺輔助提
升到能任意改變監控視角的 3D 環場視覺監控。經過一連串的影像轉換及合成處理，得到三
個不同的監控模式給駕駛者使用。 
 
4.3.2 倒車軌跡分析 
我們所提出的影像式倒車導引技術。在倒車影像中尋找一些地面特徵點，藉由追蹤這些
特徵點在前後影像中的移動量，反推出車輛的行進軌跡。這項技術可代替現有倒車輔助系統
中方向盤下方轉向感測器的工能，用影像中地面特徵點的運動關係代替轉向感測器偵測方向
盤轉向角換算出行車軌跡的工作，以軟體取代硬體。只需要安裝四台廣角攝影機，就可以同
時達到廣域全周府瞰監視及倒車軌跡估算的工能。不但節省設備成本，還可以讓駕駛在車輛
出廠後能選購倒車導引系統，而不需要再把車輛開回原廠作安裝轉向感測器的作業流程，使
倒車導引技術應用大眾化，能適應在不同車種上使用。 
 
4.3.3 環場鳥瞰偵測的停車輔助 
在俯瞰碰撞偵測方面，我們先篩選適合的光流向量，再利用光流向量的方向、位置、及
大小做分群，對分群得到的移動區塊分析其移動的軌跡及與己車碰撞的可能碰撞時間判斷是
否要給予駕駛者警告。 
 
4.4 駕駛昏睡狀態偵測 
駕駛分心是造成交通事故最重要的因素，因此駕駛昏睡偵測與注意力偵測即為輔助安全
駕駛中重要的一環。我們以電腦視覺偵測技術偵測駕駛昏睡程度與頭部方向判斷駕駛的專心
程度。根據人臉特徵點在影像與三維空間座標的對應關係，我們提出一個頭部姿勢估測方法
來推測出頭部轉動方向。為了估計出準確的頭部姿勢，我們提出強化的特徵偵測方法來提高
特徵點位置的準確度。特徵偵測包括眼睛與嘴巴，考慮到行駛中車輛的環境變化，我們的特
徵偵測方法可以適應於不同的光影變化的環境與變換的頭部姿勢。 
 
4.4.1 不均勻照度的臉部/眼睛偵測與分析 
針對亮度不均勻的影像，我們根據影像的邊強度將影像劃分為多個區域，再對影像各區
域各別二值化，經由幾何限制條件擷取可能的眼睛區塊，再利用支援向量機 (Support Vector 
Machine, SVM) 辨識是否為眼睛，最後再進行雙眼的驗證。根據雙眼的位置估計臉部範圍。
當連續三張影像偵測成功，進入追蹤模式。在追蹤模式，我們在預測的區域內做三階段的眼
睛偵測。 
 
4.4.2 昏睡與注意力分析 
在眼睛閉合偵測部份，我們測試了兩種方法並比較其準確性。在視線方向偵測，我們根
 - 25 -
 
n
dd
n
i
ii 
 1
2
均方根誤差 ，                                                (12) 
其中 d 為演算法計算出之像差，d 為實際之像差，n 為包含像差資訊之點數。 
我們另外對我們拍攝的影像分別使用兩種動態規劃法產生像差圖，如圖20 所示。關聯式
動態規劃法產生的像差圖誤差明顯下降，所花費的時間只有些微的上升，條紋狀的現象也減
輕了，如表3 所示。 
 
   
(a)                        (b)                        (c) 
   
(d)                       (e)                        (f) 
圖20. 原始與關聯式動態規劃法之比較。(a) 原始左影像。(b) 實際像差圖。(c) 遮敝與不連續
處。圖中黑色為遮敝處，白色為不連續處。(d) 遮敝與無紋理處。圖中黑色為遮敝處，
白色為無紋理處。(e) 原始動態規劃之像差圖。(f) 關聯式動態規劃之像差圖。 
 
表3. 原始與關聯式動態規劃法比較表 
 原始之動態規劃 關聯式動態規劃 
整體均方根誤差 2.803837 1.613112 
非遮敝處之均方根誤差 2.505320 1.343965 
遮敝處之均方根誤差 5.731970 3.892451 
有紋理處之均方根誤差 2.513962 1.346727 
無紋理處之均方根誤差 1.137938 0.976034 
不連續處之均方根誤差 5.922698 4.833157 
演算法執行時間 (秒) 0.406000 0.421000 
 
第二年將雙眼立體視覺技術實做在行人偵測上。本實驗都是在 Intel Pentium Core2 
Duo 2.93GHz、2 GB RAM 與 Microsoft Windows 7 作業系統下進行。本實驗用來取像的攝
影機為 SLW-C93，1/3" CCD，鏡頭焦距為 4.5mm，水平視角約 58 度。兩台攝影機架設在
一定制的水平平台上，並將此平台架設在 NISSAN MARCH。 
我們將展示相機擺放盡量完美與相機擺放不完美分別根據第一次與第二次的相機參數做
距離估測其準確度的比較，如圖 21 及表 4, 5 所示。 
 - 27 -
在本研究中，我們發現經過影像矯正後的影像與光軸的交點已經改變，因此提出將影像
矯正後的影像再做一次相機參數校正，利用這次得到的參數值代入相機擺放完美的距離公式
估測距離；接著根據估測的距離資訊結合單眼資訊來偵測行人。 
我們根據雙相機校正法將左右影像經由相機參數校正、扭曲校正以及影像矯正來得到左
右極線彼此平行且對齊的影像。並將經過影像矯正後的影像再做一次相機參數校正，得到目
前左右影像與其相機的關係。接著利用關聯式動態規劃法計算出像差圖。將像差圖先經過形
態學平滑化去除雜訊；再經由 v-像差濾除地面資訊；接著根據距離門檻值將影像分割成不同
深度的區塊；之後將區塊依照區塊的長度及距離分為長度夠大及太小兩類；長度太小的區塊
則結合單眼影像的色彩資訊，透過與區塊相對應位置的色彩資訊利用簡單群聚搜尋法將其做
分群，以此判斷相鄰且距離差距不大的區塊是否為同一物體，接著與區塊長度夠大的一起透
過地面消失線濾除高於地面太多的區塊；再根據不同距離之三維物件高度範圍呈現到影像平
面的長度範圍濾除不符合一般人身高的區塊；最後利用行人的長寬比例框選出最後偵測結果
並估測距離。 
在我們的研究中，我們利用動態規劃產生像差圖所需時間較長，所以偵測速率只達每秒
2 張。將來若可以從而改進演算法，或者使用 GPU 加速運算，則本實驗即可達成即時運算。
此外，我們是利用經過影像矯正後的左右影像分別重新估算左右相機的內部參數，將此參數
值代入相機擺放完美的距離公式來估測距離。但原本左右相機擺放就不完美，所以理論上應
該將原始左右影像得到的參數值直接代入相機擺放不完美的公式來求得距離。因此將來可以
再實驗比較此兩種方法估測距離的準確度。另外，我們框選行人的條件還不夠完整，將來可
以再加入影像處理的技術，如光流、HOG 等，以及行人的特性，如雙腿的周期性運動、身體
結構有一定的順序等，來降低錯誤的警告，以達到更好的效果。 
 
5.1.2 FCW 的車輛偵測/追蹤 
在實驗中，我們利用不同的天氣像是晴天、陰天、雨天、向陽、與傍晚的影片來測試我
們的演算法。我們在晴天、陰天、和向陽的天候狀況下，有超過 90% 的偵測率。此外，在
雨天及傍晚的天候狀況下，也有超過 80% 的偵測率。在 Intel® Core™2 Duo E7400 2.80GHz 
CPU and 2.0GB DDR2 RAM 的電腦上執行，我們的演算法，具有每秒三十個畫面左右的處理
效能。部份結果如圖 22 所示。 
我們的演算法在計算距離時需要正確的偵測到車輛與路面的交會點，所以，當車輛與路
面的交會點偵測不準確，我們計算的距離會不準確。在大雨天或車輛距離己車很近時，車輛
與路面的交會點偵測不準確，造成距離估算錯誤。我們希望能改善這樣的情況，使得前車距
離更準確，提供駕駛更穩定的幫助。 
 
   
(a) 雨天。                (b) 大雨天。                (c) 長陰影。 
圖 22. 不同天候的前車偵測結果。 
 
 - 29 -
 
5.2 側邊盲點偵測 
 
5.2.1 盲點位置的物體偵測及距離估計 
我們利用多種不同天候狀況和道路環境視訊來測試我們的偵測系統，天候狀況包括：晴
天、陰天、及雨天，道路環境則包含了高速公路、快速道路、和一般市區道路，如圖25 所示。
從實驗的結果顯示，在良好的天候狀況下，我們都能準確地偵測到道路線以及側邊車輛，車
輛偵測率平均可達 92%。然而，在不良天候狀況下，道路線能夠準確被偵測到，但車輛偵測
的結果卻不理想。因此，不良天候下的側邊車輛偵測將是我們未來的發展方向。在Intel 
Pentium D 3.0 GHz CPU 和 1 GB DDR RAM的電腦上執行，我們的側方盲點偵測系統，具有
每秒三十個畫面以上的處理效能。 
 
  
(a) 晴天在高速公路上。                (b) 陰天在市區道路上。 
  
(c) 陰天在快速道路上。                 (d) 雨天在高速公路上。 
圖 25. 側方盲點偵測結果。 
 
5.2.2 整合動態與靜態資訊的盲點偵測 
 
 - 31 -
  
  
圖 27. 近處盲點區域車輛偵測結果。 
 
5.3 停車輔助 
 
5.3.1 環場鳥瞰監視系統 
本實驗所用的相機為彩色廣角相機，是 1/4" CMOS，水平視角 136°，垂直視角 115°。我
們將四台相機分別架設在 TOYOTA COROLLA 與輕型電動車 LEV 上如圖 28 所示。 
 
  
  
(a) COROLLA。 
 - 33 -
 
  
  
圖30. 合成的鳥瞰影像。 
 
5.3.2 倒車軌跡分析 
我們提出的影像式倒車導引技術，與現有停車輔助系統獲得車輪轉向的方式有所不同，
不再利用方向盤下方轉向感測器獲得轉向資訊，而是利用後方攝影機拍攝到的影像變化來推
斷出車輛的轉向軌跡。以軟體取代硬體，降低技術造價，增加成本效益，部份結果如圖 31 所
示。 
 
 - 35 -
5.4 駕駛昏睡狀態偵測 
 
5.4.1 不均勻照度的臉部/眼睛偵測與分析 
我們利用各種不同照度的車上影像來測試我們的偵測系統。這些影像包含正常照度、豔
陽有戴眼鏡、豔陽無戴眼鏡、夜間有戴眼鏡、夜間無戴眼鏡、及不均勻照度的影像。經過實
驗，在大部份的狀況下，我們都能夠正確地偵測與追蹤駕駛人的眼睛，進而獲得駕駛人的眼
睛開/閉與視線方向的資訊，並分析駕駛人是否可能陷入昏睡，發出警示燈號與聲音來警告駕
駛人。實驗數據提示，眼睛偵測的偵測率為88.6%，誤判率為1.16%；眼睛閉合偵測的正確率
為93.5%，誤判率為6.39%；平均偵測時間為0.057045秒，每秒可處理18張影像，如圖33 及 表
6, 7 所示。 
 
    
(a)                  (b)                 (c)                  (d) 
    
(e)                  (f)                 (g)                  (h) 
    
(i)                  (j)                 (k)                  (l) 
圖 33. 三種不同環境的眼睛偵測與追蹤。 
 
 
表 6. 眼睛偵測的正確率。 
Video #Frame #Detected #False Detection rate False rate
Normal light 890 845 5 94.9% 0.56% 
Sunlight without glasses 913 769 9 84.2% 0.98% 
Sunlight with glasses 908 842 10 92.7% 1.10% 
Nighttime without glasses 361 337 0 93.3% 0.00% 
Nighttime with glasses 340 279 16 82.0% 4.70% 
Nighttime with strong light 944 928 4 98.3% 0.42% 
Uneven illumination 1 948 780 5 82.3% 0.53% 
Uneven illumination 2 394 320 4 81.2% 1.01% 
 
 
 - 37 -
表 8. 眼睛偵測率 
Scenario (with SVM ) True positive Detection rate False positive False negative
Normal light 99 93.21% 28 7 
Uneven illumination1 104 83.33% 31 21 
Uneven illumination2 78 71.56% 56 31 
 
Scenario True positive Detection rate False positive False negative
Normal light 105 99.05% 64 1 
Uneven illumination1 122 97.60% 90 3 
Uneven illumination2 103 94.44% 98 6 
 
表 9. 嘴巴偵測率 
Scenario #Frame #Detected Detection rate 
Normal light 261 257 98.47% 
Uneven illumination1 72 69 95.83% 
Uneven illumination2 51 46 90.19% 
 
5.4.3 3D 臉部方位偵測的駕駛注意力分析 
我們使用 C++程式語言、微軟基礎類別 (Microsoft Foundational Classes, MFC) 資料庫及
Intel®開源電腦視覺庫 (OpenCV)。拍攝的影片是使用型為 Logitech Pro9000 的攝相機，並將
鏡頭擺設在車內的方向盤上，擺設如圖 36 所示。為了建立頭部姿勢資料庫，在牆上標記了很
多不同位置的記號，該記號是為了讓頭部轉向有個依據。所有的實驗都是利用處理器 Intel® 
CoreTM2 Duo CPU 2.80GHz, 2.00GB RAM, 和 Microsoft® Windows 7 企業版作業系統。輸入的
影像是 320×240 大小的灰階影像。 
 
 
圖 36. 在車內擺設相機的位置。 
 
針對框出臉部的影像，做眼睛及嘴巴區塊的偵測，再各別對偵測到的區塊做角點的偵測，
而偵測的結果如圖 37 所示。 
 
 - 39 -
   
(a)                        (b)                        (c) 
   
(d)                        (e)                        (f) 
   
(g)                        (h)                   (i) 
 
(j) 
圖 38. 實驗影像。(a)為 X 軸旋轉 0 度，Y 軸旋轉 0 度。(b)為 X 軸旋轉 0 度，Y 軸旋轉 15 度。
(c)為 X 軸旋轉 0 度，Y 軸旋轉 30 度。(d)為 X 軸旋轉 0 度，Y 軸旋轉 45 度。(e)為 X 軸
旋轉 15 度，Y 軸旋轉 0 度。(f)為 X 軸旋轉 30 度，Y 軸旋轉 0 度。(g)為 X 軸旋轉 15，
Y 軸旋轉 15 度。(h)為 X 軸旋轉 15 度，Y 軸旋轉 30 度。(i)為軸旋轉-15 度，Y 軸旋轉
15 度。(j)為 X 軸旋轉-15 度，Y 軸旋轉 30 度。 
 
 - 41 -
周達華 廣域全周俯瞰監視與影像式倒車導引 
馬紹宗 整合動態與靜態視覺技術的盲點區域車輛偵測 
簡偉丞 適應性的車道偏離警示與夜間的前車碰撞警示系統 
李國煒 全周俯瞰監視與側邊偵測系統 
謝依潔 三維臉部方位估計與追蹤 
另外，還有9篇研討會論文已發表及一篇期刊論文已投稿、一篇期刊論文準備投稿中。 
[11] Din-Chang Tseng, Chun-Wei Lin, and En-Fong Chou, “Weather-invariant vehicle detection 
for forward collision warning system,” IET Computer Vision, 2011. (preparing) 
[10] Din-Chang Tseng* and Chun-Wei Lin, “Robust lane departure warning system for advanced 
safety vehicles,” IEICE Trans. on Information and Systems, 2011. (submitted) 
[9] En-Fong Chou and Din-Chang Tseng, “Weather-adapted vehicle detection for forward 
collision warning system,” in Proc. of The World Congress on Engineering, London, UK, 
Jul.6-8, 2011, pp.1294-1299. 
[8] Tat-Wa Chao, Chun-Wei Lin, and Din-Chang Tseng, “Image-based parking guiding system,” 
in Proc. 3rd Int. Conf. on Machine Vision, Hong Kong, Dec.28-30, 2010, CD. 
[7] Shao-Zong Ma, Chang-Tao Hsu, and Din-Chang Tseng, “Blind-spot vehicle detection with 
dynamic and static vision methods,” in Proc. of the 23th IPPR Conf. on Computer Vision, 
Graphics and Image Processing, Kaohsiung, Taiwan, Aug.15-17, 2010, CD. 
[6] Chun-Wei Lin, Han-Ying Wang, and Din-Chang Tseng, “A robust lane detection and 
verification method for intelligent vehicles,” in Proc. of The 3rd Int. Conf. on Intelligent 
Information Technology Application, Nanchang, China, Nov.21-22, 2009, CD. (EI) 
[5] Yen-Hsiang Lin, Li-Kung Huang, Chi-Wei Lin, and Din-Chang Tseng, “Visual blind-spot 
detection for lane change assistance, ,” in Proc. of the 22th IPPR Conf. on Computer Vision, 
Graphics and Image Processing, Shitou, Taiwan, Aug.23-25, 2009, CD. 
[4] Chi-Lei Ho, Hsin-Liang Shen, Han-Ying Wang, and Din-Chang Tseng, “A surrounding 
bird-view monitoring system with image refinement for parking assistance,” in Proc. of the 
22th IPPR Conf. on Computer Vision, Graphics and Image Processing, Shitou, Taiwan, 
Aug.23-25, 2009, CD. 
[3] Li-Jen Tsao, Din-Chang Tseng, Ching-Chun Huang, Li-Kung Huang, and Long-Tai Chen, 
“Driver drowsiness detection and warning under various illumination conditions,” in Proc. of 
the 21th IPPR Conf. on Computer Vision, Graphics and Image Processing, Yilan, Taiwan, 
Aug.24-26, 2008, CD. 
[2] Yi-Fu Chen, Din-Chang Tseng, Chi-Lei Ho, Li-Kung Huang, and Long-Tai Chen, “A 
bird-view surrounding monitor system for parking assistance,” in Proc. of the 21th IPPR Conf. 
on Computer Vision, Graphics and Image Processing, Yilan, Taiwan, Aug.24-26, 2008, CD. 
[1] Chi-Jui Lin, Din-Chang Tseng, Chun-Wei Lin, Tony Hu, and Robert Luo, “Forward and 
sideward collision warning for advanced safety vehicles,” in Proc. of the 21th IPPR Conf. on 
Computer Vision, Graphics and Image Processing, Yilan, Taiwan, Aug.24-26, 2008, CD. 
 
 
六、參考文獻 
[1] Alonso, J. D., Multimodal Bio-inspired Vision System, Ph.D Dissertation, University of 
Granada, Spain, 2006, Chapter.8: Lane Change Decision Aid System based on Motion-driven 
Car Tracking. 
 - 43 -
[20] Ito, T., S. Mita, K. Kozuka, T. Nakano, and S. Yamamoto, "Driver blink measurement by the 
motion picture processing and its application to drowsiness detection," in Proc. IEEE Int. Conf. 
Intelligent Transportation System, 2002, pp.168-173. 
[21] Ji, Q. and X. Yang, "Real-time eye, gaze, and face pose tracking for monitoring driver 
vigilance," Real-Time Imaging archive, vol.8, Issue.5, Oct. 2002, pp.357-377. 
[22] Ji, Q., J., Z. Zhu, and P. Lan, "Real-time nonintrusive monitoring and prediction of driver 
fatigue," IEEE Trans. Vehiclar Technology, vol.53, no.4, pp.1052-1068, July 2004. 
[23] Kawato, S. and N. Tetsutani, "Circle frequency filter and its application," in Proc. Int. 
Workshop on Advanced Image Technology, Taejon, Korea, Feb.8-9, 2001, pp.217-222. 
[24] Keogh, E. and C. A. Ratanamahatana, "Exact indexing of dynamic time warping," Knowledge 
and Information Systems, vol.7, no.3, pp.358-386, May 2005. 
[25] Lowe, D. G., "Distinctive image features from scale-invariant keypoints," International 
Journal of Computer Vision, vol.60, issue.2, pp.91-110, Nov. 2004. 
[26] Lucas, B. D. and T. Kanade, "An iterative image registration technique with an application to 
stereo vision," in Proc.of the 1981 DARPA Image Understanding Workshop, pp.121-130, Apr. 
1981. 
[27] Luis, M. B., J. Nuevo, and M. A. Sotelo, "Real-time system for monitoring driver vigilance," 
in Proc. IEEE Conf. Intelligent Vehicles Sym., June 14-17, 2004, pp.78-83. 
[28] Ruprecht, D. and H. Muller, "Image warping with scattered data interpolation," IEEE 
Computer Graphics and Applications, vol.15, no.2, pp.37-43, Mar. 1995. 
[29] Shih, S. W., Y. T. Wu, and J. Liu, "A calibration-free gaze tracking technique," in Proc. 15th Int. 
Conf. Pattern Recognition, Barcelona, Spain, Sep.3-7, 2000, vol.4, pp.201-204. 
[30] Smith, P., M. Shah, and N. da Vitoria Lobo, "Monitoring head/eye motion for driver alertness 
with one camera," in Proc. of 15th Int. Conf. Pattern Recognition, vol.4, Sep.3-7, 2000, 
pp.636-642. 
[31] Smith, P., M. Shah, and N. da Vitoria Lobo, "Determining driver visual attention with one 
camera," IEEE Transactions on Intelligent Transportation Systems, vol.4, Issue: 4, Dec. 2003, 
pp.205-218. 
[32] Stefano, L. D. and A. Bulgarelli, "A simple and efficient connected components labeling 
algorithm," in Proc. Int. Conf. Image Analysis and Processing, 1999, pp.322-327. 
[33] Steinfeld, A., D. Duggins, J. Gowdy, J. Kozar, R. MacLachlan, C. Mertz, A. Suppe, C. Thorpe, 
C.-C. Wang, “Development of the side component of the transit integrated collision warning 
system,” in Proc. IEEE Intell. Transportation Systems Conf., Washington, DC, Oct.3-6, 2004, 
pp.343-348. 
[34] Sun, Z., G. Bebis, and R. Miller, “On-road vehicle detection using evolutionary Gabor filter 
optimization,” IEEE Trans. Intelligent Transportation Systems, vol.6, no.2, pp.125-137, June 
2005. 
[35] Sun, Z., G. Bebis, and R Miller, “On-road vehicle detection: A review,” IEEE Trans. Pattern 
analysis and Machine Intelligence, vol.28, no.5, pp.694-711, May 2006. 
[36] Tseng, D.-C., Hsiao-Ting Tseng, and Chun-Liang Chien, “Automatic cloud removal from 
multi-temporal SPOT images,” Applied Mathematics and Computation, vol.205, is.2, 
pp.584-600, Nov. 2008. 
[37] Ueno, H., M. Kaneda, and M. Tsukino, "Development of drowsiness detection system," in 
 - 45 -
附件一 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用
價值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否
適合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 ■洽談中 □無 
其他：（以 100 字為限） 
 
除發表會議論文外，三年共產出十二篇與本計畫相關的碩士論文 
林育正 以關聯式動態規劃法做雙眼立體視覺偵測 
林彥翔 輔助變換車道的盲點範圍視覺偵測 
何祈磊 具有影像優化處理的環場鳥瞰監視停車輔助系統 
楊小璿 強化特徵偵測與三維臉部特徵點匹配的頭部姿勢估計法 
周恩鋒 可適應天候變化的前車偵測技術 
吳怡君 整合雙眼與單眼視覺技術的行人偵測 
藍易康 以動態視覺為基礎的前車停止啟動及俯瞰碰撞偵測 
周達華 廣域全周俯瞰監視與影像式倒車導引 
馬紹宗 整合動態與靜態視覺技術的盲點區域車輛偵測 
簡偉丞 適應性的車道偏離警示與夜間的前車碰撞警示系統 
李國煒 全周俯瞰監視與側邊偵測系統 
謝依潔 三維臉部方位估計與追蹤 
另外，還有9篇研討會論文已發表及一篇期刊論文已投稿、一篇期刊論文準備投稿中。 
[11] Din-Chang Tseng, Chun-Wei Lin, and En-Fong Chou, “Weather-invariant vehicle detection 
for forward collision warning system,” IET Computer Vision, 2011. (preparing) 
 
 
 - 47 -
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用
價值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
本研究計畫是一個三年期的研究計畫，在本計畫的研究中，我們共規劃了四個電腦視覺
研究主題，用於輔助道路安全駕駛：(1) 前後車防撞偵測、(2) 側邊盲點偵測、(3) 停車輔助、
及 (4) 駕駛昏睡狀態偵測。 
(1) 前後車防撞偵測的研究項目有：双眼立體視覺偵測技術發展、FCW 的車輛偵測/追蹤、
LDW/FCW 的嵌入式系統化。 
(2) 側邊盲點偵測的研究項目有：盲點位置的物體偵測及距離估計、整合動態與靜態資訊的
盲點偵測、多重解析度的光流估計。 
(3) 停車輔助的研究項目有：環場鳥瞰監視系統、倒車軌跡分析、環場鳥瞰偵測的停車輔助。
(4) 駕駛昏睡狀態偵測的研究項目有：不均勻照度的臉部/眼睛偵測與分析、昏睡與注意力分
析、3D 臉部方位偵測的駕駛注意力分析。 
在本研究中，我們已完成上述所有內容，與原計畫有 90 % 以上的相符程度。而且其中
部份技術具有學術及實用價值。研究成果即將整理撰寫投稿國內外學術會議及期刊；另外部
份成果亦將整理申請國內或國外專利。 
在本研究中，我們提出有效率的電腦視覺偵測技術輔助道路安全駕駛。我們的技術具有
下列多項特色： 
1. 在車輛偵測中，我們的方法：(i) 可適應各種天候狀況、(ii) 不受陰影影響、及 (iii) 不受
雨刷與車輛局部遮蔽車道線的影響。 
2. 在前車停止啟動及俯瞰碰撞偵測部份，偵測高達 98 %。 
3. 在側邊盲點的視覺偵測方面，我們整合了動態與靜態視覺技術，以提高偵測率。 
4. 在双眼立體視覺偵測方面，我們直接偵測行人距離，並以灰階資訊強化偵測結果。 
5. 在影像式倒車導引技術，與現有停車輔助系統獲得車輪轉向的方式有所不同，不再利用方
向盤下方轉向感測器獲得轉向資訊，而是利用後方攝影機拍攝到的影像變化來推斷出車輛
的轉向軌跡。以軟體取代硬體，降低技術造價，增加成本效益 
6. 在駕駛注意力偵測方面，我們特別針對亮度不均勻的影像，我們根據影像的邊強度將影像
劃分為多個區域，再對影像各區域各別二值化，經由幾何限制條件擷取可能的眼睛區塊，
再利用支援向量機 (Support Vector Machine, SVM) 辨識是否為眼睛，最後再進行雙眼的驗
證。根據雙眼的位置估計臉部範圍。並且以 3D 頭部模型協助推測頭部轉動方向。 
我們非常專注且長時間的投注在本研究上，期望能吸引相關企業合作；而且也確實吸引
中科院第二所、工研院機械所、車輛研究測試中心及私人公司主動找我們合作。希望更遠的
未來，能將此技術改進的更精良，並與未來發展的技術整合成更完整的系統。 
 
 
 
 
 
 
 - 49 -
 
技術說明 
四個研究主題將同時執行；每個研究主題中的工作項目都將依序
在三年中完成。 
第一年的研究項目有：(1) 双眼立體視覺偵測技術發展、(2) 盲點
位置的物體偵測及距離估計、(3) 環場鳥瞰監視系統、(4) 不
均勻照度的臉部/眼睛偵測與分析。 
第二年的研究項目有：(1) 車輛偵測/追蹤、(2) 整合動態與靜態資
訊的盲點偵測，(3) 倒車軌跡分析，(4) 昏睡與注意力分析。
第三年的研究項目有：(1) LDW/FCW 的嵌入式系統化、(2) 多重
解析度的光流估計、(3) 環場鳥瞰偵測系統、 (4) 3D臉部方
位偵測的駕駛昏睡與注意力分析。 
先進安全車輛的視覺偵測應用不是創新，國內外都有一些相
關的研究，而且國外已有一些產品問世了；但我們專攻視覺偵
測，不像某些單位只把視覺偵測視為附屬的工具，或者只是用來
爭取研究計畫而已；因此在視覺偵測的技術發展上，我們做得廣
泛，而且使用的理論、觀念、與技術也最精專；例如，許多研究
採用 Canny operator 或 Sobel operator 做邊界偵測，但卻不知道在
什麼情形下才需要用這些運算，更不管這些運算有多耗時；Canny 
operator 及 Sobel operator 是我們目前做邊界偵測的 20 多倍及 7
倍的運算量。 
上述相關於安全偵測的研究重點在於準確性與穩定性。視覺
安全偵測很容易受到天候及環境因素的影響；所以技術研發的關
鍵在於方法是否不受天候狀況 (晴、陰、雨、霧、暗) 的影響；
是否在各式道路環境 (高速、快速、平面道路、巷弄、鄉間小道) 
都可維持良好的偵測效果。考慮各種天候及環境因素對於視覺偵
測的影響是我們技術發展上的特色之一。 
 
(英文) 
In these few decades, the vehicle number is rapidly increasing 
because people’s incomes are increasing. In addition to the vehicle 
number, more factors of road situation, driving environment, and 
human attention result in a large amount of traffic accidents and 
casualties. If there is a mechanism to help the driver to detect the road 
situation and driving environment, and then to provide some useful 
information to the driver in these situations, the danger is therefore 
avoided. In this research project, we are just combining the techniques 
of computer vision, image processing, and pattern recognition, and 
matching the domestic environment to develop state-of-the-art 
techniques of vision detection to reduce the load of drivers, to reduce 
the traffic accidents, and then improve the driving safety.  
 
 
 
 - 51 -
 
技術說明 
The key problems of the safety detection techniques are 
accuracy and stability. The methods concerning the safety vehicles 
are easily influenced by climate conditions and environment factors; 
thus the key points of useful methods are whether the proposed 
methods are not influenced by various climate conditions (sunny, 
cloudy, rainy, foggy, and night days) ? whether the proposed 
methods may keep well performance in variant road conditions 
(freeway, highway, general road, and country roads). Considering the 
influence factors of climate conditions and environment situations to 
the vision detection techniques is one characteristic of our 
development of the computer vision techniques for advanced safety 
vehicles. 
 
 
產業別 
可利用之產業 
1.汽車電子業、 
2.車用資通系統 (Telematics) 
技術/產品應用範圍 
可開發之產品 
1. 車道偏離警示 LDW (lane departure warning) 
2. 前車碰撞警示 FCW (forward collision warning) 
3. 盲點偵測 BSD (blind spot detection)  
4. 立體視覺行人偵測 PD (pedestrian detection) 
5. 全周俯瞰監視系統 STM (surrounding top-view monitoring) 
6. 全周俯瞰偵測系統 WSTD 
7. 影像式停車導引 IPG (image-based parking guiding) 
8. 停車啟動偵測 ISG (image-based Stop-&-Go) 
9.昏睡偵測與注意力監視 (drowsiness detection & attention 
monitoring) 
 
技術移轉可行性及預期
效益 
在本研究中，我們提出有效率的電腦視覺偵測技術輔助道路
安全駕駛。我們的技術具有下列多項特色： 
1. 在車輛偵測中，我們的方法：(i) 可適應各種天候狀況、(ii) 不
受陰影影響、及 (iii) 不受雨刷與車輛局部遮蔽車道線的影響。
2. 在前車停止啟動及俯瞰碰撞偵測部份，偵測高達 98 %。 
3. 在側邊盲點的視覺偵測方面，我們整合了動態與靜態視覺技
術，以提高偵測率。 
4. 在双眼立體視覺偵測方面，我們直接偵測行人距離，並以灰階
資訊強化偵測結果。 
5. 在影像式倒車導引技術，與現有停車輔助系統獲得車輪轉向的
方式有所不同，不再利用方向盤下方轉向感測器獲得轉向資
附件三 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                  日期：100 年 1 月 10 日 
一、參加會議經過 
2010 IACSIT 會議舉辦於香港新界天水圍的嘉湖海逸酒店，此會議隸屬於 IEEE 協
會並由 IACSIT 協會主辦，此會議包含三場會議子會議，分別為：(1)第二屆 Information 
and Multimedia Technology 會議，(2)第三屆 Machine Vision 會議，以及(3)首屆 Physics 
Science and Technology 會議。 
我所參加的會議為第三屆 Machine Vision 會議(以下簡稱 ICMV10)，其中領域涵蓋
(1)Machine Vision, Image Processing, and Pattern Analysis，(2) Computer Vision and Image 
Analysis，和(3) Pattern Recognition and Basic Technologies 三大領域。我所投稿的領域
為第一主領域中的 Applications of Machine Vision。 
會議議程共有三天，第一天為報到日，於嘉湖海逸酒店報到。之後兩天為正式會
議，同樣於嘉湖海逸酒店舉行。當天早上的議程為四場 Keynote Note speech，下午開
始則是各個子會議的報告時間。在我所報告的會議場次 Session I1 中由於沒有細部分
類，論文類別略為雜亂，但也因此聽到了許多有趣的應用，例如應用影像處理技術判
斷出植物病蟲害的區域並分析是何種病灶。在我發表完論文後的問答時間中，與會者
反應熱烈，提出了四個問題與建議，有助於之後論文的改進。 
 
二、與會心得 
此次會議與會者來自世界各地，以英文作為交談與報告的語言，本次報告較上次
流利許多，但因為各地口音的關係，對於印度腔濃厚的英文理解力有限，應該要再加
強自己的英文聽說技巧。 
在議程的規劃上，第一天議程只有報到，應該可以將後兩天的會議發表時間分散
到第一天，減輕與會者的精神壓力。而我所報告的場次雖然列名有 19 篇論文發表，但
實際上只有 9 篇有來報告，有些有興趣的論文沒有聽到發表也失去了與作者討論的機
會，感覺有些可惜。另外，此會議在報到時就已經給予與會證明暨口頭報告證明書，
個人覺得有些不妥。由於該會議收錄的論文領域均以 Machine Vision 相關，可以在會
場中聽到很多與自己研究同領域但不同的應用，也能從其他的應用中學習核心技巧。 
 
三、考察參觀活動(無是項活動者略) 
   無 
計畫編號 NSC 97-2221-E-008-073-MY3 
計畫名稱 輔助道路安全駕駛的多樣性視覺偵測技術 
出國人員姓
名 林君威 
服務機構及
職稱 
中央大學資訊工程所博士班
七年級 
會議時間 99 年 12 月 28 日至 99 年 12 月 30 日 會議地點 香港 
會議名稱 The 3rd Int. Conf. on Machine Vision (ICMV 2010) 
發表論文題
目 
(中文)以影像為基礎的停車導引系統 
(英文) Image-based Parking Guiding System 
 - 3 -
 
國科會補助計畫
計畫名稱: 輔助道路安全駕駛的多樣性視覺偵測技術
計畫主持人: 曾定章
計畫編號: 97-2221-E-008-073-MY3 學門領域: 影像處理 
8. 停車啟動偵測 ISG (image-based Stop-&-Go) 
9. 昏睡偵測與注意力監視 (drowsiness detection & attention monitoring)
技術移轉可行性及
預期效益
在本研究中，我們提出有效率的電腦視覺偵測技術輔助道路安全駕駛。我們的技術具有
下列多項特色： 
1. 在車輛偵測中，我們的方法：(i) 可適應各種天候狀況、(ii) 不受陰影影響、及 
(iii) 不受雨刷與車輛局部遮蔽車道線的影響。 
2. 在前車停止啟動及俯瞰碰撞偵測部份，偵測高達 98 %。 
3. 在側邊盲點的視覺偵測方面，我們整合了動態與靜態視覺技術，以提高偵測率。 
4. 在双眼立體視覺偵測方面，我們直接偵測行人距離，並以灰階資訊強化偵測結果。 
5. 在影像式倒車導引技術，與現有停車輔助系統獲得車輪轉向的方式有所不同，不再利
用方向盤下方轉向感測器獲得轉向資訊，而是利用後方攝影機拍攝到的影像變化來推斷
出車輛的轉向軌跡。以軟體取代硬體，降低技術造價，增加成本效益 
6. 在駕駛注意力偵測方面，我們特別針對亮度不均勻的影像，我們根據影像的邊強度將
影像劃分為多個區域，再對影像各區域各別二值化，經由幾何限制條件擷取可能的眼睛
區塊，再利用支援向量機 (Support Vector Machine, SVM) 辨識是否為眼睛，最後再進
行雙眼的驗證。根據雙眼的位置估計臉部範圍。並且以3D頭部模型協助推測頭部轉動方
向。 
 輔助道路安全駕駛的多樣性視覺偵測技術研究，在國內外都有人在做；我們專攻視覺偵
測，因此在視覺偵測的技術發展上，我們做得廣泛，而且使用的理論、觀念、與技術也
最精專。我們也特別重視系統的準確性與穩定性。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
