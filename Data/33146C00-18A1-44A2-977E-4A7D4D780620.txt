 2 
on short-time Fourier transform (STFT) and hence 
is used to capture the uniform-resolution features in 
the speaker signal.  On the other hand, the Mel-
filter like WPT [2] is simultaneously used to capture 
the multi-resolution features in the speaker data, the 
mean and covariance properties of log-energy in 
each sub-band obtained by the WPT are calculated 
for each speaker and the Bhattacharyya distance 
(BD) measure is also applied to select the most 
resembling candidates.  A decision fusion system 
is designed at this point to greatly reduce the 
computational cost for the Mel frequency cepstral 
coefficient (MFCC) based GMM classifier in the 
second-stage.  When the closest or number one 
speakers from the above two candidate selectors 
based on the KLT and the WPT are in concord or 
agreement, the fusion system will conclude that the 
final speaker will be the one both agree.  Otherwise, 
the fusion system will choose equal number of 
candidates from the two selectors to further identify 
the correct speaker by the GMM. 
 
Karhunen-Loeve transformed features [3]:  
 
Let X be an N-dimensional spectral random 
vector, computed from each frame of speech data 
by a fast Fourier transform. The spectral mean 
vector and the covariance matrix are: 
 
][XEX =m                 (1) 
 
]))([( TXXX XXE mm --=S         (2) 
 
respectively, where E is the expectation operator 
over the whole speech training database and T 
represents the matrix transpose. 
 
The covariance matrix estimated from the 
above equation is then used to solve the Karhunen-
Loeve equation to find the global eigenvalue matrix 
L  and the corresponding eigenvector matrix F . 
 
L*F=F*SX             (3) 
 
Then, a linear transform is applied to the 
original spectral data X to optimally represent the 
database in the transformed domain Y, as shown in 
Eq.(4) 
 
XY T *F=              (4) 
 
 Since the importance of any transformed 
coordinate is measured by the magnitude of its 
eigenvalue, only the first few eigenvectors 
corresponding to the largest eigenvalues are used to 
transform the spectral dataset to optimally represent 
the original data. Considering the minimum mean 
square truncation error and the maximal energy 
packing properties [1], only the first K components 
(K<<N) associated with the largest eigenvalues are 
required to preserve most of the recognition 
information in the speaker dataset. 
 
Wavelet packet transformed features [2]: 
 
A sixteen subband wavelet packet tree which 
approximates the Mel-scale frequency division is 
constructed.  Figure 2 shows the derived WP tree 
structure and Table 1 shows the associated filter 
bands for the 16-band MFCC and 16-band WPT.  
The signal bandwidth is 5512.5 Hz since the speech 
data is sampled at 11.025 KHz.  After performing 
the WP decomposition using ‘Daubechies 8’ 
wavelets to the 256-sample frames of speaker data, 
the log energy in each one of the 16 frequency 
bands, 
 
   
÷÷
ø
ö
çç
è
æ
= å
=
iN
j
jigif
1
2 ),(log)(  , 161 ££ i   (5) 
 
is calculated, where ),(2 jig is the j ’th energy 
component in the i ’th frequency band, and   
iN is the total number of components in the i ’th 
frequency band.  These 16 coefficients are then 
taken as the WPT features. 
 
Bhattacharyya distance [4]:  
 
Bhattacharyya distance is closely tied to the 
probability of error as an upper bound on the Bayes 
error for normally distributed classes.  For normal 
pdf’s, the Bhattacharyya distance between class i 
and j is 
 
)()
2
()(
8
1
2
ln
2
1
1
2
2
1
2
1
ji
jiT
ji
ji
ji
BD
mmmm -
S+S
-+
SS
S+S
=
-
  (6) 
 4 
On the other hand, the optimal number of 
candidates for the KLT-WPT/GMM approach is 
only 10, i.e. 5 candidate speakers (NC=5, 1% of 
total number of speakers) from the KLT-BD 
classifier and the WPT-BD classifier respectively, 
and the identification rate is 97.6% for this model.  
Therefore, as the candidate size gets bigger, the 
performances for these two models do not always 
monotonically increase. Therefore, merely using a 
large candidate size does not benefit in terms of 
performance and imposes a cost in terms of 
memory and search complexity. 
 
Fig. 3 also shows that the features derived 
from the KLT and the WPT can compensate each 
other.  Using these two features at the same time, 
the number of candidates needs to be further 
classified by the GMM will be greatly reduced.  
And therefore this will increase the correct rate from 
92% to 97.6%, and decrease the classification time 
from 0.36s to 0.028s on a Pentium-4 mobile 1.7GHz 
machine.  Since the GMM requires 3.54s of CPU 
time to find the correct speaker, a computation cost 
saving of 125 (3.54/0.028) times compared to that 
of the conventional GMM can then be achieved. 
 
In our experiments, it is observed that 
approximately 85% of the closest or number one 
speakers from the KLT-BD classifier and the WPT-
BD classifier are in concord or agreement. This can 
be checked by the 500-candidate cases where the 
time spent for the KLT/GMM is 3.54s while the time 
spent for the KLT-WPT/GMM is 0.56s (0.56/3.54= 
15.8%).  This implies that the amount of time spent 
in the KLT-BD and WPT-BD of the first stage is 
much less than that spent in the GMM of the second 
stage.  The classification time is approximately 
linear with the number of candidate speakers. 
 
Table 2 indicates that the KLT/GMM [1], the 
WPT/GMM and the KLT-WPT/GMM models have 
an accuracy improvement of 4%, 6.4% and 9.6% 
over the conventional GMM approach respectively.  
The numbers in the parentheses are the numbers of 
candidates used. 
 
Conclusions:  
 
A text-independent speaker identification 
system based on the KLT, the WPT and the GMM 
has been designed in Project.  It indicates that the 
features derived from the KLT and the WPT can 
compensate each other.  And this property can be 
used to diminish the use of the more speaker-
ambiguous and time-consuming GMM classifier as 
much as possible.  For a database with 500 
Mandarin speakers, it is demonstrated that the 
accuracy improvement up to 9.6% and the 
computational cost saving of 125 times compared 
to those of the conventional GMM model can be 
achieved.  
 
References 
 
[1] C.C.Thomas Chen, C.T. Chen and C.K. Hou: 
‘Speaker identification using hybrid Karhunen-
Loeve transform and Gaussian mixture model 
approach,’ Pattern Recognition, 2004, 37, pp. 
1073-1075 
 
[2] O. Farooq, and S. Datta: ‘Mel filter-like 
admissible wavelet packet structure for speech 
recognition’, IEEE Signal Processing Letters, 
2001, 8, (7), pp. 196–198 
 
[3] C.C. Thomas Chen, C.T. Chen and C.M. Tsai: 
‘Hard-limited Karhunen-Loeve transform for 
text-independent speaker recognition,’ 
Electronics Letters, 1997, 33, (24), pp. 2014-
2016 
 
[4] J.P. Campbell,: ‘Speaker recognition: A 
Tutorial’,  IEEE proceedings,  1997, 85,  pp. 
1437-1462 
 
[5] D.A. Reynolds, and R.C. Rose, ‘Robust text-
independent speaker identification using 
Gaussian mixture speaker models’, IEEE 
Transaction on Speech and Audio Processing, 
1995, 3, (1), pp. 72-83 
 
 
 
 
 6 
 
 
 
 
 
 
 
Fig. 2 Sixteen band Mel-like wavelet packet tree structure 
(The numbers indicate the pass band of each filter, in Hz) 
 
 
 
 8 
 
 
 
Fig. 3  Optimal number of candidates for the 500-speaker database 
 
 
Table 2:  500-speaker database identification rates 
Method GMM KLT/GMM WPT/GMM KLT-WPT/GMM 
Pc, correct rate 0.88 (500) 0.92 (50) 0.942 (20) 0.976 (10) 
