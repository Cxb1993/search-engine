Resisting the Random Distortion Attack
in Digital Image Watermarking
Po-Chyi Su
Dept. of Computer Science and Information Engineering,
National Central University, Jhongli, Taiwan
E-mail:pochyisu@csie.ncu.edu.tw
ABSTRACT
This research presents a feature-based still image
watermarking approach. Scale-Invariant Feature
Transform (SIFT) is first applied to locate the in-
terest points, from which we form the invariant
regions for the watermark embedding. In order
to resist geometrical transformations, the extended
synchronization template or grid, which helps to
ensure that reasonably large invariant regions be
available for carrying the watermark payload and
for increasing the confidence of watermark detec-
tion will also be embedded. In the detection phase,
after SIFT, the synchronization template is first
determined locally by adjusting the related affine
parameters of the grid to match with the possible
hidden template so that the watermark can be re-
trieved afterwards. Experimental results show the
feasibility of the proposed method.
Keywords: Digital watermark, geometrical trans-
formation, SIFT, StirMark.
1. INTRODUCTION
Digital watermarking has been considered as a po-
tential solution to providing further protection of
digital content. The close integration of the hidden
signal, i.e. digital watermark, with the host media
can be used for declaring/verifying the ownership
of the content, controlling the software/hardware
operations or for the trailer tracking purposes. In
most of the related applications, the digital water-
mark signal has to be robust against the so-called
watermarking attacks, including lossy compression,
signal processing procedures and even intentional
watermark-removal operations. For still images,
the watermark surviving geometrical transforma-
tions is always required since such manipulations
as cropping, rotation and scaling are so common.
Nevertheless, these editing procedures cause the
challenging synchronization problems for the wa-
termark detection and the special care must be
taken to ensure that the watermark resist such at-
tacks to meet the requirements of applications.
This research aims at enabling the digital image
watermark to survive geometrical transformations.
Many methods have been proposed, including the
exhaustive search, embedding the watermark in the
invariant domains, embedding the template as the
side information, and employing the features for
locating the watermark. A good review of this
topic can be found in the book of Cox et al. [1]
Among the potential solutions, the feature-based
approaches gain more and more attention. Kut-
ter et al. [2] first proposed that the feature-based
approaches are the second-generation watermark-
ing schemes. They illustrated this by employing
the Mexican-hat wavelet to extract the features and
the Voronoi diagram to define the local character-
istic regions for watermark embedding and detec-
tion. Bas et al. [3] used the Harris detector to
extract the salient points for producing the con-
tent descriptor and Delaunay tessellation to define
the invariant regions. Seo et al. [4] extended the
affine invariant point detection to extract the fea-
ture points, from which the affine covariant regions
(ACR) of different shapes are generated. The wa-
termark is geometrically transformed into the re-
lated shape for the embedding and detection. Gao
et al. [5] proposed an image watermarking scheme
by incorporating the advantages of the affine in-
variant point detector, ACR normalization, orien-
characteristic scales. It should be noted that the
extracted invariant area will be embedded with the
signal with a fixed size so the scaling of either our
hidden signal pattern or the image content cannot
be avoided. If the size of invariant area is too
different from the size of our hidden signal pat-
tern, the scale itself may affect the embedded pat-
tern severely. Then, we check the robustness of
interest points and delete weaker ones according
to the strength of SIFT. To simulate the effects of
lossy compression, we apply mediate JPEG com-
pression followed by Gaussian filtering and exam-
ine the matched SIFT interest points between the
original image and modified image.
For the remaining interest points, we expect
that the interest points should be separated from
each other by a reasonable distance. We adopt
the maximum distance algorithm to disperse the
feature points. To be more specific, the loca-
tion of interest points can be seen as a set of 2-
dimensional vectors, V = {vi}. We calculate the
centroid of the |V | vectors and choose the one
closest to the centroid as our first feature point,
fp1. From the |V | − 1 vectors, choose the one
that has the largest distance from the first fea-
ture point as the second feature point, fp2. To
find the third feature point from the remaining
|V | − 2 vectors, we calculate the distance Disi of
each vector, vi, and the two feature points, (i.e.,
Disi = Min(dist(fp1, vi), dist(fp2, vi))). Again,
we will find the one with the largest distance as
fp3. Repeat the process to increase the number of
feature points until the additional feature point will
yield the distance from the selected points smaller
than a distance threshold, Tdist. These feature
points will then be used to form the grid for the
signal embedding. Fig. 2(c) illustrates the chosen
invariant regions. It should be noted that some ex-
isting schemes may only employ these regions for
the watermark embedding/detection. However, if
the regions are small, the payload or the detection
confidence will be affected. On the other hand, if
a larger size is used, the embedded watermark may
be affected by the local distortion easily, such as
the random geometrical attacks of StirMark [9]. In
our scheme, the invariant areas or grids will be ex-
tended to cover a larger area for signal embedding.
Before expanding the embedding regions, Voronoi
diagram is used to set up the boundaries for sepa-
rating the image into subregions as shown in Fig.
2(d). Each subregion of the image will belong to
one interest point and will be embedded with a wa-
termark. The expansion of invariant area can then
be applied according to Fig. 2(e). For an invari-
ant grid, four extended grids are generated. The
grids associated with the same feature points can
thus have the same size and orientation. The same
process will be applied on each extended grids too
and the expansion of one initial grid will be limited
in the Voronoi sub-region. A few grids can still
be added on the boundaries of Voronoi sub-regions
as long as the added ones will not overlap others.
The embedding blocks can then be generated al-
most all over the host image as illustrated in Fig.
2(f), where the grey areas represent the grids and
the black dots represent the grid centers.
(a) (b)
(c) (d)
(e) (f)
Figure 2: (a) The extracted interest points by SIFT
on Lena and (b) the associated invariant areas. (c)
The chosen invariant regions, (d) the subregions
separated by Voronoi diagram for signal embed-
ding, (e) the extension of the grid and (f) the ex-
tended grids.
the template embedding, the masked pixel is rep-
resented by It(i, j).
Even though we embed both the watermark and
the template signal almost all over the host image,
the effect on the image is limited as the perceptual
model is used. It should be noted that the wa-
termark is embedded in the middle frequencies of
DCT so the negative effect on the template signal
is limited and acceptable. Our scheme ensures that
the template signal be detected first so we embed
the watermark signal first and then embed the tem-
plate signal without considering its effect on DCT
coefficients so that the template can be more reli-
ably determined.
2.3. Signal Detection
For the signal detection, an investigated image will
be applied with SIFT to extract the interest points
to locate the areas for the hidden signal detection.
The correlation coefficient between the retrieved
signal and the host template/watermark will be
computed to verify whether the hidden signal ex-
ists. If the template is found, the watermark will
be extracted and the expanding procedure will be
performed to find other embedding areas. To de-
tect the watermark, each obtained grid will then
be transformed into the known fixed-size block for
calculating the 8× 8 DCT. It is worth noting that
most of the interest point elimination procedures
will be performed in the watermark embedder, not
in the detector, since any elimination procedure
in the detector may cause the wrong selection of
the interest points, especially after the image has
been distorted. We do remove extremely large and
small areas to simplify the detection process. It
is worth noting that the characteristic scale, po-
sition and orientation of the interest point may be
slightly different after certain signal processing pro-
cedures. Therefore, the size, orientation and posi-
tion of a grid associated with an interest point has
to be tuned. In other words, during the watermark
detection, by adjusting the parameters of obtained
scale, position and orientation, we can generate a
variety of compensative grids in order to obtain the
best match of the template. Then, this grid will be
used for the subsequent watermark detection. For
each interest point, a set of various compensative
grids, gui where u = 1, 2, . . . , P , is generated by
altering parameters, where i is the interest point
number and P is the total number of trial param-
eter sets. Basically, we determine the center of a
grid and use the tested affine matrix to interpolate
the test grid. We then process the grid by a filter,
F , to generate the estimated pattern δgui for the
template detection. The preprocessing filter, F , is
defined as
F =

0 1 −2 1 0
1 2 −6 2 1
−2 −6 16 −6 −2
1 2 −6 2 1
0 1 −2 1 0
 , (6)
which can be applied efficiently and we found that
this method is effective in assisting template detec-
tion. The correlation coefficient between the ath
test template, W at , and an estimated pattern δgui is
calculated by
ρa,u =
W at · δgui√
W at ·W at
√
δgui · δgui
. (7)
The testing pattern W at is determined to exist in
this region if ρa,u > Tnc, the detection threshold.
As mentioned before, we expect to obtain a more
accurate grid for increasing the response of water-
mark detection. The most possible size of a grid,
which is approximately synchronized with the em-
bedded template, can be determined by the max-
imum of ρa,u. Meanwhile, the maximum of ρa,u
is also required to be larger than Tnc for ensuring
that the template pattern exist. Once the first syn-
chronized grid associated with the interest point is
marked as the template pattern, other patterns em-
bedded in the extended grids may also be found by
the similar method. The expanding procedure is
utilized to obtain more grids for the template de-
tection again. We use the altered orientation and
characteristic scale from the synchronized grid as
the initial orientation and characteristic scale of the
adjacent extending points to form a larger area of
the synchronized grids. It should be noted that, if
the estimated grids that are generated by the cur-
rent point do not have responses higher than the de-
tected threshold, the expanding procedure will not
be continued to the next ones. After deriving the
areas according to the template detection, each grid
in the area of the investigated image will be affine
transformed to the fixed-size square and then 8× 8
block DCT will be applied. The same coefficients as
Table 1: The signal detection of Lena
Table 2: The performance of our scheme against
random bending attacks on Lena
grids further, such as modifying the positions of its
four corners, may provide more different forms of
grid for detection, with the cost of more compu-
tational load. Future work will be increasing the
stability and security of feature points’ identifica-
tion and speeding up the detection process.
REFERENCES
[1] I. Cox, M. Miller, J. Bloom, J. Fridrich, and T.
Kalker, “Digital watermarking and steganog-
raphy,” 2007.
[2] M. Kutter, S. Bhattacharjee, and T. Ebrahimi,
“Towards second generation watermarking
schemes,” in IEEE International Confernece
on Image Process, vol. 1, 1999, pp. 320–323.
[3] P. Bas, J. Chassery, and B. Macq, “Geomet-
rically invariant watermarking using feature
points,” IEEE Transactions on Image Process-
ing, vol. 11, no. 9, pp. 1014–1028, 2002.
[4] J. Seo and C. Yoo, “Image watermarking based
on invariant regions of scale-space representa-
tion,” IEEE transactions on Signal Processing,
vol. 54, no. 4, pp. 1537–1549, 2006.
[5] X. Gao, C. Deng, X. Li, and D. Tao, “Geomet-
ric Distortion Insensitive Image Watermarking
in Affine Covariant Regions,” IEEE transac-
tions on systems, man and cybernetics. Part
C, Applications and reviews, vol. 40, no. 3, pp.
278–286, 2010.
[6] X. Wang, J. Wu, and P. Niu, “A new dig-
ital image watermarking algorithm resilient
to desynchronization attacks,” IEEE Transac-
tions on Information Forensics and Security,
vol. 2, no. 4, pp. 655–663, 2007.
[7] D. Zheng, S. Wang, and J. Zhao, “RST in-
variant image watermarking algorithm with
mathematical modeling and analysis of the wa-
termarking processes,” IEEE Transactions on
Image Processing, vol. 18, no. 5, pp. 1055–
1068, 2009.
[8] D. Lowe, “Distinctive image features from
scale-invariant keypoints,” International jour-
nal of computer vision, vol. 60, no. 2, pp. 91–
110, 2004.
 1 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：100年 11月 23 日 
                                 
一、參加會議經過 
On July 30th. 2011, I arrived in Maui, Hawaii to attend International Conference on Computer 
Communications and Networks (ICCCN). This year is the 20th anniversary year of ICCCN, which is a 
well-know large conference in the field of networking. There are totally 452 submissions this year and 
134 papers are accepted. The accept rate is less than 30% so ICCCN 2011 is thought to be a conference of 
pretty good quality. 
 
There are several tutorials on the first day of ICCCN. These tutorials cover more general ideas of certain 
subjects and are presented by experienced scholars and researchers. I tried to focus on the tutorials more 
related to general networking or multimedia and I certainly learned a lot. First, I listened to the tutorial 
“Packet Core Network Evolution in Regard to Future Internet Research Trends” by Prof. Magedanz. In 
this tutorial, the networking evolution was overviewed and several network standards, including LTE and 
WIMAX, were covered. Then the emerging future Internet and the related issues were discussed. In the 
afternoon, I listened to the tutorial “User-Centric Cross-Layer Design for Multimedia Communications” 
by Prof. Song Ci, I learned that the cross-layer designs should take users’ perceived quality into 
consideration, instead of emphasizing merely on throughput/delay, so that quality-aware service-oriented 
multimedia networks can be developed. The issues of behavior characterization of multimedia 
計畫編號 NSC 99 － 2221 － E － 008 － 089 － 
計畫名稱 針對數位影像浮水印隨機變形攻擊之防禦 
出國人員
姓名 
蘇柏齊 
服務機構
及職稱 
國立中央大學資訊工程學系 
會議時間 
100年 7月 31日至 
100年 8月 4日 會議地點 
Maui, Hawaii, USA 
會議名稱 
(中文)第二十屆計算機通訊與網路國際會議 
(英文)20th International Conference on Computer Communications and Networks 
發表論文
題目 
(中文) 適用於 H.264/AVC畫面內預測編碼之內容適應性畫質變異與量化模型 
(英文) A Content-Adaptive Distortion-Quantization Model for Intra Coding in H.264/AVC 
附件四 
 3 
In the evening of Aug. 2nd, I attended the banquet and enjoy the meal. I left Maui and took an airplane 
back to Taiwan via Japan on Aug. 3rd. Since the conference was held in the summer time, the ticket was 
extremely expensive and the seats were all booked except on that day. 
 
二、與會心得 
Although ICCCN is more related to networking than to my field, from this conference, I surely learned a 
lot about the issues of networks, which are extremely important these days. I also met many famous 
scholars with slightly different backgrounds from mine and it is a very good experience to me. Although I 
cannot fully understand some talks in some sessions, attending such good conferences certainly motivates 
me to do more advanced research. One thing that I noticed is that many famous scholars and Ph.D. 
students are from China. They are young and prosperous. I only met my advisor Prof. C.-C. Jay Kuo, Prof. 
Homer Chen of NTUEE and Prof. Da-Chung Chang, my colleague in the Dept. of Communication 
Engineering, from Taiwan. It is a kind of warning to me since the scholars from China have been playing 
more and more important roles in the academia. They are more aggressive and hold important positions in 
schools of USA and the conferences. I think we should work harder to keep our competiveness and hope 
that our students can also sense this and take the challenges. 
 
This is my first time to visit Maui. This place is 
quite different from Honolulu since it is quiet 
and peaceful. I enjoyed a lot by the blue sky and 
sun. The beach is so beautiful. The only down 
aide may be the high expense on the 
accommodation. I also walked around with Prof. 
Da-Chung Chang in the area of the conference 
hotel. 
 
 
 
 
 
 
 
 
 
三、考察參觀活動(無是項活動者略)     
四、建議 
五、攜回資料名稱及內容： Conference CD (ICCCN 2011) 
A Content-Adaptive Distortion-Quantization Model
for Intra Coding in H.264/AVC
Ching-Yu Wu
Dept. of Computer Science and Information Engineering
National Central University, Taiwan, ROC
Email: 985402014@cc.ncu.edu.tw
Po-Chyi Su
Dept. of Computer Science and Information Engineering
National Central University, Taiwan, ROC
Email: pochyisu@csie.ncu.edu.tw
Abstract—A content-adaptive Distortion-Quantization (D-Q)
model for intra coding of H.264/AVC is proposed in this research.
A single-parameter Distortion-Quantization (D-Q) relationship is
derived for predicting the coding performance associated with
the Quantization Parameter (QP). The content complexity of
a macroblock (MB), which is evaluated by using the Sum of
Absolute Transformed Difference (SATD), will be employed to
determine the model parameter so that a suitable QP can be
assigned. In order to acquire a video with more consistent quality,
we propose two schemes, i.e. the two-pass method and the single-
pass scheme with self adaption. In the two-pass scheme, the
resulting frame quality after the first encoding pass using the
initial QP is evaluated and a refining factor will be computed to
determine a more appropriate QP. In the single-pass adaptive
scheme, the adjustment is applied by referencing the model
accuracy in the previous frame. The experimental results show
that the assigned QP can effectively help to achieve the targeted
frame quality in the H.264/AVC intra coding.
Index Terms—H.264/AVC, Content-Adaptive Distortion-
Quantization model, Constant Quality
I. INTRODUCTION
Visual quality control and rate control are both important
issues in video coding. Many coding schemes aim at reducing
the video quality variation with a more efficient bit-rate as-
signment. Several Rate-Quantization (R-Q) and/or Distortion-
Quantization (D-Q) models are then developed to achieve
this objective. In traditional hybrid video coding systems,
the intra-frame coding plays a significant role since it may
consume most of the bits in a group of pictures (GOP) and
its quality/bit-rate assignment will affect the subsequent inter-
coding frames considerably. In general, the rate control or
the video quality control problem can be viewed as the issue
of assigning suitable Quantization Parameter (QP) values of
frames. Some related works have been proposed to efficiently
allocate QP to intra coding frames. Wang et al. [1] discussed
the intra-frame QP initialization problem, in which both the
entropy information and the intra16 DC mode were employed
as the features to help predict a good initial QP for the
first intra-frame. Lee et al. [2] proposed a gradient-based
complexity measurement to efficiently allocate the bit budget
and to determine a proper QP of an intra-coded macroblock
(MB). Li et al. [3] proposed an efficient intra-frame rate
control scheme, where the QP is determined by the statistics
of the deviation measurement. Tian et al. [4] utilized the
gradient information to help solve the buffer control problem
in intra-frames. Sun et al. [5] introduced a rate-complexity-
quantization (R-C-Q) model for intra frames, in which the
histogram of pixel intensity and gradient information of a
frame are used to improve the bit assignment.
In this research, we develop an accurate D-Q model for the
intra-frame coding. To be more specific, given a target frame
quality, the scheme is able to select the correct QP for the intra-
frame coding. Some related works on D-Q curve estimation
have been proposed. Ma et al. [6] found that there exists a
linear relationship between PSNR (Peak Signal to Noise Ratio)
and QP value. A Rate-Distortion model is then developed to
efficiently allocate the bit budget of each frame. Kamaci et
al. [7] utilized Cauchy-density function to approximate the
distribution of the AC coefficients of DCT. A Distortion-Qstep
model is then proposed to derive the Rate-Distortion model
for solving the frame-level bit allocation problem. Guo et
al. [8] proposed a Distortion-Quantization model, which first
chooses a probing QP to encode the video and then analyzes
the distribution of DCT coefficients to construct the D-Q curve
of a specific frame. It should be noted that the assignment of
QP for achieving the target frame quality is also related to
the constant-quality video coding [9], [10]. Nevertheless, the
strategies of the existing schemes usually have to encode a
video several times to adjust the QP values frame by frame
so the entire coding process is time-consuming. Our ultimate
goal is to develop a more efficient constant-quality video
coding scheme. Since the intra-frame coding plays a very
important role in this aspect, we focus on determining an
accurate relationship between the intra-coding frame quality
and QP. With the quality distortion measured in PSNR or
the Sum of Squared Error (SSE), we will propose a more
accurate single-parameter D-Q model. To achieve the constant-
quality video coding, we will allow our intra-frame encoding
to be executed at most two passes. To be more specific, two
schemes, i.e. the two-pass method and the single-pass scheme
with self adaptation, will be presented in this research.
The rest of this paper is organized as follows. In Section II,
the proposed single-parameter D-Q model will be presented
and compared with the Distortion-QStep model proposed in
[7]. The QP assignment with the refinement will be presented
in Section III. Experimental results are shown in Section IV
to demonstrate the performance of our proposed D-Q model.
The conclusion and future work are described in Section V.
978-1-4577-0636-3 /11/$26.00 ©2011 IEEE
(a)
−3 −2 −1 0 1 2 3
−6
−4
−2
0
2
4
6
8
10
12
14
β
ln
( α
 
)
D = α × QPβ × Qstep
 
 
R2 = 0.9879
(b)
Fig. 2: The proposed D-Q model: (a) the relationship between
the actual SSE and the predicted SSE by Eq. (3) and (b) the
relationship between α and β in Eq. (3).
to imitate the intra16 DC mode as the macroblock prediction
by simply calculating the mean value of the current MB. Fig.
3 illustrates the non-linear relationship between the predicted
SATD value and β in Eq. 4 and can be roughly depicted by
β ≈ s× ln(SATDpred) + c, (7)
where s and c are the trained constants and are set as 1.361
and −9.819, respectively. The R2 value of the fitting curve in
Fig. 3 is over 0.85, which shows that the predicted SATD value
can be utilized to efficiently estimate the only parameter of the
proposed D-Q model. Besides, we can observe from Fig. 2 (b)
that, when β is large, α will be smaller so these two content-
dependent parameters tend to restrain each other. Therefore,
there should be a tolerant range for the parameter setting and
the prediction made by Eq. (7) should be reasonably good.
By using Eqs. (4) to (7), we can efficiently obtain an
approximate D-Q curve without performing any encoding
processes as follows. After the encoder reads a raw frame,
for each MB, the predicted SATD value will be calculated
for determining the parameter β by Eq. (7). Then, Eq. (4) is
employed to obtain an approximated D-Q curve at the MB-
Fig. 3: The relationship between the predicted SATD and β.
level. Finally, we can sum up the D-Q curve of every MB in a
frame to acquire a D-Q curve at the frame-level. The QP value
with the minimum absolute difference of the corresponding
SSE and target SSE will be chosen as the estimated QP.
III. FINAL QP ASSIGNMENT
The performance of the proposed D-Q model is first eval-
uated as follows. We collect 120 high-quality images from
Corel image database and concatenate them into an image
sequence. We set three target PSNR values, i.e. 35, 40, and
45 dB, to compress this sequence and employ our model to
determine the QP for each frame. The results are shown in
Table I. We can see that the model performs reasonably well
for the target PSNR set as 35 dB and 40 dB, since the average
PSNR values are close to the target ones. The model seems
to assign a slightly smaller QP than it should be when the
target PSNR is set as 45 dB. However, the performance may
not be that satisfactory when we check the individual frames.
Fig. 4 shows the PSNR values of frames and some larger
deviations appear. We can also observe that the variations of
these three cases tend to be similar so we may keep over- or
under-estimating the D-Q relationship of a frame.
TABLE I: The mean and variance of PSNR values of coding
the image sequence by using the proposed D-Q model.
Target Target Target
PSNR=35dB PSNR=40dB PSNR=45dB
Average PSNR (dB) 35.2049 40.2784 45.5237
PSNR Variance 0.9726 0.5576 0.2655
To reduce the prediction errors of the D-Q model, a two-pass
QP assignment method can be adopted. That is, the probing
QP determined by the proposed D-Q model is first used to
encode the frame and a refining factor θ will then be used to
correct the deviation. The factor θ can be obtained by
θ =
SSEactual
SSEpredicted
. (8)
The prediction from Eq. (4) will then be adjusted by θ via
SSE = θ × e(l×β+r) ×QP β ×Qstep. (9)
0 10 20 30 40 50 60 70 80
0
10
20
30
40
50
60
70
80
Actual MSE
Ta
rg
et
 M
SE
 
 
one−pass method
two−pass method
(a)
0 10 20 30 40 50 60 70
0
10
20
30
40
50
60
70
Actual MSE
Ta
rg
et
 M
SE
 
 
one−pass method
two−pass method
(b)
Fig. 6: The comparison of one-pass and two-pass prediction accuracy for frames in (a) Coastguard and (b) News.
TABLE III: The mean (Avg.) and variance (Var.) of PSNR in the four test videos.
Single-pass method
Target PSNR=30 Target PSNR=35 Target PSNR=40 Target PSNR=45
Avg. Var. Avg. Var. Avg. Var. Avg. Var.
Foreman 31.1637 0.9858 35.5911 0.7541 40.0693 0.2373 45.2696 0.0815
Stefan 31.2365 0.0555 36.2803 0.0562 40.8594 0.0614 45.6856 0.0119
Coastguard 29.9743 0.0815 34.4708 0.0731 39.4194 0.0213 44.8940 0.0048
News 32.0658 0.0060 36.8840 0.1763 41.6328 0.0027 46.0357 0.0028
Two-pass method
Target PSNR=30 Target PSNR=35 Target PSNR=40 Target PSNR=45
Avg. Var. Avg. Var. Avg. Var. Avg. Var.
Foreman 30.1111 0.0751 35.1458 0.0294 40.1605 0.0633 45.1495 0.0171
Stefan 30.1209 0.0603 35.0747 0.0594 40.0903 0.0368 45.0362 0.0167
Coastguard 30.0244 0.0378 35.1008 0.0704 40.2403 0.0357 44.8939 0.0048
News 29.9903 0.0071 35.0722 0.0051 40.0353 0.0022 45.4239 0.0156
Single-pass method with self-adaption
Target PSNR=30 Target PSNR=35 Target PSNR=40 Target PSNR=45
Avg. Var. Avg. Var. Avg. Var. Avg. Var.
Foreman 29.9767 0.0711 35.0837 0.0348 39.9419 0.0908 45.1497 0.0186
Stefan 30.0678 0.0720 35.1177 0.0592 40.0516 0.0373 45.1755 0.0609
Coastguard 29.9729 0.0176 35.1847 0.0624 40.2167 0.0496 44.8940 0.0048
News 30.0044 0.0322 35.0886 0.0316 40.0433 0.0156 45.1811 0.1077
be viewed as the first step for performing the constant-quality
video coding. Based on this single-parameter D-Q model, the
constant-quality coding for inter-frames may also be achieved,
as long as suitable spatial/temporal features are available.
REFERENCES
[1] H. Wang and S. Kwong, “Rate-distortion optimization of rate control for
H.264 with adaptive initial quantization parameter determination,” IEEE
Trans. on Circuits and Systems for Video Tech., vol. 18, pp. 140–144,
Jan. 2008.
[2] Y. G. Lee and B. C. Song, “An intra-frame rate control algorithm for
ultralow delay H.264/AVC,” IEEE Transactions on Circuits and Systems
for Video Technology, vol. 19, no. 5, pp. 747–752, May 2009.
[3] J. Li and E. Abdel-Raheem, “Efficient rate control for H.264/AVC intra
frame,” IEEE Transactions on Consumer Electronics, vol. 56, no. 2, pp.
1043–1048, May 2010.
[4] L. Tian, Y. Sun, I. Ahmad, and S. Sun, “Effective intra-only rate
control for H.264/AVC,” in IEEE International Conference on Image
Processing, Egypt, Nov. 2009, pp. 3445–3448.
[5] Y. Sun, Y. Zhou, Z. Feng, and Z. He, “A novel incremental rate control
scheme for H.264 video coding,” in IEEE International Conference on
Image Processing, San Diego, CA, USA, Oct. 2008, pp. 1612–1615.
[6] S. Ma, W. Gao, and Y. Lu, “Rate-distortion analysis for H.264/AVC
video coding and its application to rate control,” IEEE Trans. on Circuits
and Systems for Video Tech., vol. 15, no. 12, pp. 1533–1544, Dec. 2005.
[7] N. Kamaci, Y. Altunbasak, and R. M. Mersereau, “Frame bit allocation
for the H.264/AVC video coder via cauchy-density-based rate and
distortion models,” IEEE Transactions on Circuits and Systems for Video
Technology, vol. 15, no. 8, pp. 994–1006, August 2005.
[8] L. Guo, O. C. Au, M. Ma, Z. Liang, and P. H. W. Wong, “A novel
analytic quantization-distortion model for hybrid video coding,” IEEE
Transactions on Circuits and Systems for Video Technology, vol. 19,
no. 5, pp. 627–641, May 2009.
[9] N. Cherniavsky, G. Shavit, M. F. Ringenburg, R. E. Ladner, and
E. A. Riskin, “Multistage: A minmax bit allocation algorithm for
video coders,” IEEE Transactions on Circuits and Systems for Video
Technology, vol. 17, no. 1, pp. 59–67, Jan. 2007.
[10] K.-L. Huang and H.-M. Hang, “Consistent picture quality control
strategy for dependent video coding,” IEEE Transactions on Image
Processing, vol. 18, no. 5, pp. 1004–1014, May 2009.
[11] D.-K. Kwon, M.-Y. Shen, and C.-C. J. Kuo, “Rate control for H.264
video with enhanced rate and distortion models,” IEEE Trans. on
Circuits and Systems for Video Tech., vol. 17, pp. 517–529, May 2007.
國科會補助計畫衍生研發成果推廣資料表
日期:2011/11/23
國科會補助計畫
計畫名稱: 針對數位影像浮水印隨機變形攻擊之防禦
計畫主持人: 蘇柏齊
計畫編號: 99-2221-E-008-089- 學門領域: 圖形辨識
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
