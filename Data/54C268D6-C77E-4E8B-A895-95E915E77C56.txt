  
 
 
2 
智慧型移動式機器人控制設計與實現(II) 
 
計畫編號：NSC 97－2221－E－019－025－ 
執行期間：97 年 8 月 1 日至 98 年 7 月 31 日 
計畫主持人：莊季高  國立臺灣海洋大學 通訊與導航工程學系 
 
摘要 
 本報告提出以感測資料為基礎之自走車路徑追
隨控制。利用模糊系統來模擬人類的推論模式，經由
使用者的經驗和感測器的整合，建立一個兼具控制及
判斷的方法，不需要非常複雜的數學方程式，就可以
設計出一個效果不錯的控制器。本文主要利用室內定
位系統來提供自走車的位置以及頭向夾角，結合模糊
邏輯建立停車的行為模式與使用超音波感測器作為停
車安全的考量，再搭配基因演算法所搜尋之參考路
徑，達到自走車追跡效能最佳化。另外亦使用攝影機
與影像處理技術來擷取路面特定顏色的線條，並且計
算其長度藉以判斷停車地點，再透過超音波感測器完
成路邊停車動作。 
關鍵詞: 自走車、模糊系統、基因演算法、室內定位
系統、影像處理技術。 
 
Abstract 
 
 This report presents a car-like mobile robot using 
sensor data to path following. An intelligent control 
scheme is proposed, which includes the fuzzy system, 
genetic algorithm, localization system, and image 
process. Through the system integration, the control 
system can effectively control the robot without using 
any complicated mathematical equations. Ultrasonic 
sensors are used to detect and examine the safety 
distance during parking process. A CCD camera is 
utilized to determine the location of a parking lot. The 
localization system provides the position and heading 
direction of the robot. Fuzzy logic is used to form 
parking behavior pattern. Reference paths are searched 
by a genetic algorithm. 
Keywords: Mobile robot, fuzzy system, genetic 
algorithm, indoor localization system, image process. 
1. Introduction 
 Robotic systems have been successfully applied to 
industrial automation, medical care, home services, space 
exploration, military, entertainment, traffic, etc. In this 
paper, we integrate an autonomous wheeled mobile robot 
(WMR) [1]-[4] to perform automatic garage parking and 
parallel parking by path following [5]-[7]. The WMR can 
figure out optimal path quickly and accurately by using 
sensors on the WMR with intelligent algorithm to path 
following. Since Lotfi Zadeh introduced fuzzy logic in 
1965 [8], fuzzy control becomes one of the most used 
techniques in intelligent control. Fuzzy logic is easy to 
implement when a mathematical model of the process 
does not exist, or the model is too complex to be 
evaluated for real time operation. In past decades, fuzzy 
logic based approaches have been successfully applied to 
control ill-defined and nonlinear systems. In early 
researches, classic control methods such as optimal 
control, PID control, and adaptive control have been 
used for wheeled mobile robot control [9], [10]. When 
artificial intelligence methods were introduced, 
applications of these methods were extended to wheeled 
mobile robot control. Nowadays, neural networks, fuzzy 
logic and genetic algorithm methods are used very often 
to control the WMR [11]-[13]. Among these methods, a 
simple fuzzy logic system and a real-valued genetic 
algorithm are used in this study.  
In the case of visual guided robot, image process of 
the RGB color space is difficult to calculate. Usually the 
color is transformed to different representation that is 
easy to use. Especially when the WMR operates in the 
outdoor environment the sunshine is a serious 
disturbance for RGB color space. The HSV (Hue, 
Saturation, Value) color space [14] is a good module that 
is often used under sunshine. Through the histogram 
method, we can set up a range of the color that we need, 
then use a filter to purify the useless information. Follow 
the color space transform, histogram values search, and 
the filter process, then the specified color line which is 
on the floor can be obtained. Using the distance 
calculation method of the camera helps us to detect the 
specified color line on the floor and calculate the 
distance of the line. For parallel-parking, the camera 
finds the special color line on the floor via image process 
[15,16]. A filter is utilized to purify the useless message 
and to preserve the useful information. By calculating the 
length of the specified color line, the WMR can 
determine whether the space is suitable for parking or not 
and use the ultrasonic sensors via path following to 
complete the parking task.  
Fuzzy system has the ability of emulating human 
reasoning pattern. Having proper fuzzy rules and 
localization information, the WMR can complete path 
following automatically. In addition, changing 
membership function of the fuzzy rules and adjusting the 
control sequence which is searched by a genetic 
algorithm can provide optimal paths and minimum 
energy control [17]. To obtain this objective, a suitable 
path is needed to be planned first. Then apply the sensor 
feedback signals as input signals and use the proposed 
  
 
 
4 
It is seldom affected by surroundings such as an infrared 
ray, a fluorescent light, and sunshine. The localization 
system can provide positioning message to control 
process in real time. The StarGazer is installed on top of 
the WMR in the center position. Control signal is 
calculated and is used to adjust robot’s moving path.  
 
2.2 Camera distance estimation 
 In Cheng’s earlier study [16], geometry method 
can compute the real world distance. We use this 
geometry method to calculate the pixels between the first 
pixel and the final pixel. Lx is the largest length of width 
that camera can see. Ly is the largest distance between 
the camera and the farthest place away from camera that 
camera can see. At the first we use our experiment data 
to calculate the distance Ly+b as shown in (7). The data Y 
which is computed by [16] is inaccurate. (7) is the 
distance Y that we obtained by experiment data via curve 
fitting. P is the row number of the detected pixel. Then 
we use this data to substitute the L and calculate the X 
which becomes the Lx. Fig. 2 and Fig. 3 show the top 
view and side view of the CCD camera. 
1 2tan (tan ( 1))
2
x
u
img
u
w
θθ −= −        (5) 
tan uX L θ=
 
            (6) 
6 5 4 3 2
1 2 3 4 5 6 7Y a P a P a P a P a P a P a= + + + + + +      (7) 
where 
1
2
3
4
5
6
7
0.000000000000302
0.000000000532604
0.00000037712465
0.000138893602871
0.029154763387189
3.727565261742653
321.628218317646
a
a
a
a
a
a
a
=
= −
=
= −
=
= −
=
             
When the WMR operates in the outdoor situation 
the localization system cannot be applied to detect the 
position. Instead, a CCD camera is used to search the 
target. Through image process methods useful data can 
be obtained. Consider the color property that under the 
sunshine, the HSV (Hue, Saturation, Value) color space 
[14] is a good model that reduce the noise of sunshine. 
The RGB to HSV transform is shown as follows: 
 
1
2
( ) ( )
cos ,
( ) ( )( )
R G R BH B G
R B R B G B
−
− + −
= ≤
− + − −
       (8) 
1
2
( ) ( )2 cos ,
( ) ( )( )
R G R BH B G
R B R B G B
pi −
− + −
= − >
− + − −
    (9) 
max( , , ) min( , , )
max( )
R G B R G BS
R B G
−
=
+ +
               (10) 
max( , , )
255
R G BV =                           (11) 
 
Fig. 2. Top view of camera [14] 
 
Fig. 3. Side view of camera [16] 
3. Path Following 
 There are three cases in this research. The first case 
is path following with known garage position. The 
StarGazer detects location of the WMR, and the WMR 
keeps moving on preset safety line. If the right side of 
the WMR is far away from the wall the left wheel will 
accelerate, otherwise the right wheel will accelerate if it 
comes close to the wall. The second case is path 
following with unknown garage position. Follow the first 
case, the WMR keeps moving on the safety line, and 
then the WMR uses the right side ultrasound sensor to 
find the location of the garage and determines the size of 
the garage. After entering the garage, the WMR uses the 
sensors on the body to adjust and move the robot to the 
best position. In Fig. 4, d1 to d4 are the distances 
measured by the corresponding reflective sensor (SR1 to 
SR4) between the WMR and the wall. The (x, y, θ) are 
the measurement values of the WMR from the StarGazer. 
The third case utilizes the camera and through the 
  
 
 
6 
 
(c) finishing parking 
Fig. 6. Backward garage parking 
 
 Histogram method is a popular algorithm in image 
process. One can define a special value then purify the 
other values that are useless. At the first we can set a 
special color that is below the line on the floor, and then 
save the image only with the specified line color. The 
through color space transform, RGB model to HSV 
model, we can use the H, V and the specified value of 
histogram to do the filtering that support us to search the 
special color line on the floor. The simulations are shown 
in Fig. 7 to Fig. 13.  
 
 
Fig. 7. The initial image 
 
 
Fig. 8. The initial H-space image 
 
Fig. 9. The initial S-space image 
 
 
 
Fig. 10. The H-space image after using the histogram 
process 
 
 
 
Fig. 11. The S-space image after using the histogram 
process 
  
 
 
8 
 
(f) 
 
 
 
(g) 
 
 
 
(h) 
 
 
 
(i) 
 
Fig. 14. Real-time image process from LabView 
8.5 operating interface 
 
     In this part, we use the LabView 8.5 operating 
interface to control the motion of the WMR. The 
ultrasonic sensors detect the distance between the WMR 
and objects. The WMR can move on the safety line. 
Through the camera information, the WMR searches the 
special color line on the floor, and calculates the length 
of the line. If the length of the line is long enough, the 
ultrasonic sensor will check whether the space is a vacant 
parking lot or not. If the space is large enough to park 
then the WMR will take the motion of the backward 
parallel-parking. In the backward parallel-parking 
motion, we apply the ultrasonic wall-following, and the 
safety line is defined from the ultrasonic sensor 
information. Fig. 15 shows the real-time control 
experiment. The (a) is the initial position and the (g) is 
the last position. 
 
  
(a)    
         
 
(b) 
 
(c)                                  
Fig. 15. Backward parallel-parking (continued) 
  
 
 
10 
Chitrakaran, “Visual servo tracking control of a 
wheeled mobile robot with a monocular fixed 
camera,” Proceedings of the 2004 IEEE 
International Conference on Control Applications,  
Vol. 2, pp. 1061-1066, 2004. 
[8] E.X. Shi, W.M. Huang, Y.Z. Ling, “Fuzzy 
Predictive Control of Wheeled Mobile Robot Based 
on Multi-Sensors,” Proceedings of the Third 
International Conference on Machine Learning and 
Cybernetics, pp. 439-443, 2004. 
[9] W. K. Liu, J. H. Fan and J. G. Juang, “Application 
of Genetic Algorithm base on System Performance 
Index on PID Controller,” Proc. of the Ninth 
Conference on Artificial Intelligence and 
Application, 2004. 
[10] T. Y. Wang, C. C. Tsai, “Adaptive trajectory tracking 
control of a wheeled mobile robot via Lyapunov 
techniques,” IECON 2004. 30th Annual Conference 
of IEEE Industrial Electronics Society, Vol. 1, pp. 
389-394, 2004. 
[11] W. S. Lin and P. C. Yang, “DHP Adaptive Critic 
Motion Control of Autonomous Wheeled Mobile 
Robot,” Proceedings of the IEEE International 
Symposium on Approximate Dynamic Programming 
and Reinforcement Learning, ADPRL, pp. 311-317, 
2007. 
[12] E. X. Shi, Y. M. Huang, and Y. Z. Ling, “Fuzzy 
predictive control of wheeled mobile robot based on 
multi-sensors,” Proceedings of 2004 International 
Conference on Machine Learning and Cybernetics, 
Vol. 1, pp. 439-443, 2004. 
[13] D. R. Ramirez, D. Limon, J. Gomez-Ortega, and E. 
F. Camacho, “Nonlinear MBPC for mobile robot 
navigation using genetic algorithms,” Proceedings of 
the 1999 IEEE International Conference on Robotics 
and Automation, Vol. 3, pp. 2452-2457, 1999. 
[14] T. W. Chen, Y. L. Chen, and S. Y. Chien, “Fast 
Image Segmentation Based on K-Means Clustering 
with Histograms in HSV Color Space” Proceedings 
of the IEEE 10th Workshop on Multimedia Signal 
Processing,  pp. 322-325, 2008. 
[15] Shiau Yi Lin, Navigation and Obstacle Avoidance of 
Wheeled Mobile Manipulators with an Eye-in Hand 
Vision System, Master Thesis, National Cheng Kung 
University, Taiwan, 2005. 
[16] G. Cheng and A. Zelinsky, ”Real-time visual 
behaviours for navigating a mobile robot,” 
Proceedings of the 1996 IEEE/RSJ International 
Conference on Intelligent Robots and Systems '96, 
vol.2, pp. 973-980, Nov 1996. 
[17] H.S. Chen and J.G. Juang, “Path Planning and 
Parking Control of a Wheeled Mobile Robot,” Proc. 
of National Symposium on System Science and 
Engineering, P0473, 2008. 
[18] WiRobot X80 USER MANUA, WiFi802.11 Wireless 
Mobile System, DrRobot, 2005.  
[19] User’s Guide, Localization system StarGazer™ for 
Intelligent Robots. HAGISONIC Co., LTD, 2004. 
[20] B. dAndrea, G. Bastin, and G. Campion, “Dynamic 
Feedback Linearization of Nonholonomic Wheeled 
Mobile Robots,” Proceedings of the 1992 IEEE 
International Conference on Robotics & Automation, 
pp. 820-825, 1992. 
 
 
 
 
 
 
 
 
 
 
成果自評: 
 
本計畫已完成理論分析、軟體模擬及硬體模擬。目前 WMR 能進行追跡控制及倒車入庫與路
邊停車，均有不錯的結果。在理論分析及軟體模擬部分，已發表於 2007 智慧型機器人跨領域
科技研討會。在硬體模擬部分，已發表於 2008 系統科學與工程研討會、2009 IEEE International 
Conference on Advanced Intelligent Mechatronics 及 2009 ICROS-SICE International Joint 
Conference。未來除了將陸續整理發表論文外，將應用更簡易的演算法於 FPGA 中，以實現
即時避障與自動控制。 
 
出席國際學術會議心得報告 
計畫編號 97-2221-E-019-025- 
計畫名稱 智慧型移動式機器人控制設計與實現(II) 
出國人員姓名 
服務機關及職稱 
莊季高
 
國立台灣海洋大學通訊與導航工程學系  教授 
會議時間地點 97年9月15至18日中國上海市 
會議名稱 International Conference on Intelligent Computing-ICIC 2008 
發表論文題目 
1. CMAC於智慧型著陸控制之應用 
2. 螞蟻殖民地系統於實驗用螺旋槳系統之應用 
 
 (一) 參加會議經過 
此次國際性學術會議由IEEE及IEEE計算智慧協會及國際神經網路委員會技術支援，由中國
科學院主辦、上海大學承辦的IEEE系列第四屆國際智慧計算會議（International Conference on 
Intelligent Computing-ICIC2008），於9月15至18日在上海市舉行。會議分為大會報告、大會小
組討論、分會場口頭報告等主要議程，來自世界30多個國家的近三百位專家、學者齊聚一堂，
共同參與了這一促進智慧計算科學與技術領域的學術盛會。會議特別邀請美國德州大學阿靈頓
分校（University of Texas at Arlington）的 Frank L. Lewis 教授、美國國科會（National Science 
Foundation）的 Paul J. Werbos 博士、美國波士頓大學（Boston University）的 Daniel Bullock 教
授、日本東京大學 (University of Tokyo) 的 Kazuyuki Aihara 教授、德國波昂大學（University of 
Bonn）的 Rolf Eckmiller 教授、澳大利亞克丁科技大學 (Curtin University of Technology) 的 
Svetha Venkatesh 教授等專家做了精彩的大會專題報告。 
 
在四天的會議中，與會專家學者藉由論文報告、會議研討、口頭交流等形式在人工智慧、
機器學習、神經計算、生物資訊、計算生物、計算智慧、群體智慧等學科領域的最新發展和成
果進行深入的學術交流和討論。ICIC2008會議共收到來自31個國家和地區的2336篇論文投稿，
經程式委員會嚴格評審，有281篇論文被本次大會錄用，錄取率約為12%，其中252篇分別由德
國Springer出版社以《電腦科學講義》（Lecture  Notes in Computer Science-LNCS）、《人工智
慧講義》（Lecture Notes in Artificial Intelligence-LNAI）和《電腦和資訊科學通訊》（Commu-
nications in Computer and Information Science –CCIS）三個圖書系列正式出版，其餘29篇文章則
分別被推薦到《電路、系統與計算機》（Journal of Circuits, Systems, and Computers）、《環球
計算機科學》（Journal of Universal Computer Science）等兩個國際期刊以專集（Special Issue）
的形式出版。本人論文“Applications of Cerebellar Model Articulation Controllers to Intelligent 
Landing System” 經評選獲收錄於 Journal of Circuits, Systems, and Computers 期刊 (EI)。 
 
    
筆者於9月18日主持智慧型控制分組討論並發表「CMAC於智慧型著陸控制之應用」及「螞
蟻殖民地系統於實驗用螺旋槳系統之應用」兩篇論文，此兩篇文章引起與會人士的熱烈討論，
論文發表後並與許多學者專家相互交換智慧型理論於不同系統之應用與研究心得。本分組報告
的重點為智慧型系統於控制與自動化之應用，包含智慧型監視器於齒輪變速箱之應用、RBF類
神經模糊系統於節能控制系統之應用、量化條件影響之學習行動模式於軟體規格之設計、應用
類神經網路與逆向控制於發電系統之應用、新機構演算法於
 Fredholm 積分程式之應用等。其中
Applications of Cerebellar Model Articulation 
Controllers to Intelligent Landing System 
Jih-Gau Juang1 and Chia-Lin Lee 
 
Department of Communications and Guidance Engineering 
National Taiwan Ocean University, Keelung, Taiwan 
jgjuang@mail.ntou.edu.tw1 
Abstract. The atmospheric disturbances affect not only flying qualities of an 
airplane but also flight safety. According to flight records, most aircraft 
accidents occurred during final approach or landing. If the flight conditions are 
beyond the preset envelope, the automatic landing system (ALS) is disabled 
and the pilot takes over. An inexperienced pilot may not be able to guide the 
aircraft to a safe landing at the airport when wind disturbance is encountered. 
This study proposes different cerebellar model articulation controllers (CMAC) 
to improve the performance of conventional ALS. A CMAC with general basis 
function (CMAC-GBF) and a type-2 fuzzy CMAC (FCMAC) are applied to 
construct intelligent landing system which can guide the aircraft to a safe 
landing in severe wind turbulence environment. 
Keywords: Intelligent landing system, CMAC, wind disturbance. 
1   Introduction 
On March 1, 2008, at Hamburg airport, a Lufthansa Airbus A320 tried to land in 
crosswind conditions which exceeded the limit for the aircraft and made the left wing 
touch ground. The pilots then performed a go around and successfully saved the 
aircraft from crashing. According to a survey of the National Transportation Safety 
Board (NTSB) [1], 22.6 percent of aircraft accidents in the years of 1989 to 1999 
were weather related. Most aircraft accidents occurred in final approach or landing. 
Another NTSB report, between 1994 and 2003, there were 19562 aircraft accidents. 
Weather was a contributing factor in 4159 of these accidents and involved 4167 
aircraft. Of the 4159 weather-related accidents, 2726 were due to wind conditions. In 
addition, a single accident may involve multiple weather conditions. According to the 
statistics of Flight International 10-16, January 2006 issue [2], there were 23 
accidents/incidents affected by weather, causing total 324 (34 crew and 290 
passengers) fatalities. The average accident fatality caused by weather is 14 people. It 
was apparent that most of cases were in the landing phase. Therefore, pilots should 
never be absent minded and remain their best condition, especially in landing phase. 
The first Automatic Landing System (ALS) was made in England during 1965. 
Since then, most aircraft have had this system installed. The ALS relies on the 
TTEEqgwgu ZZgqXwwXuuXu δδθγ
pi
++∆−∆+−+−= )cos()
180
()()( 0ɺ           (1) 
Tqgwgu gqUZwwZuuZw θγ
pipi )sin()
180
()
180
()()( 00 −∆−+−+−=ɺ         (2) 
TEEqgwgu MMqMwwMuuMq ++∆+−+−= δ)()(ɺ                         (3) 
q=θɺ                                 (4) 
θpi 0180
Uwh +−=ɺ                                           (5) 
where u  is the aircraft longitudinal velocity  (ft/sec), w  is the aircraft vertical 
velocity (ft/sec), q  is the pitch rate (rate/sec), θ  is the pitch angle (deg), h  is the 
aircraft altitude (ft), Eδ  is the incremental elevator angle (deg), Tδ  is the throttle 
setting (ft/sec), oγ  is the flight path angle (-3deg), and g  is the gravity (32.2 ft/sec2). 
The parameters ii ZX , and iM  are the stability and control derivatives. 
 
 
~ 
~ 
0 ft 
50 ft 
touchdown 
1200 ft 
glide path 
flare path 
Runway 
position 
Altitude 
  
Fig. 1. Glide path and flare path 
 
To make the ALS more intelligent, reliable wind profiles are necessary. Two 
spectral turbulence forms models by von Karman and Dryden are mostly used for 
aircraft response studies. In this study the Dryden form [8] was used for its 
demonstration ease. The model is given by : 








+∆
+=
u
uu
gcg
as
a
t
Nuu
21)1,0( σ                   (6) 








+
+
∆
= 2)(
)(31)1,0(
u
www
g
as
bsa
t
Nw
σ
            (7) 
where ])51ln(
)510/ln(1[510
h
uu windgc +−= ,
u
o
u L
U
a = , hLw = ,  
u
o
u L
U
a = ,  
w
o
w L
U
a = ,  
3w
o
w L
Ub =  , 
3/1100hLu = for 230>h , 600=uL  for 230≤h , 
( )hu gcw ×+= 00098.05.02.0σ  for 5000 ≤≤ h , gcw u2.0=σ  for 500>h .  
sw h+1
pitchupθpitchupθ
cθh
ch
hɺ
chɺ
+
−
+
+
+
+
−
hk
hk ɺ
applied only during flare
typical value : °= 4pitchupθ
1.0=hw
25.0=hk
3.0=hk ɺ
 
Fig. 3. PID-controller 
 
Aircraft
Response
cθ +
−
θk
qk
typical value-Glide Slope : 
q
eθ Eδ
Rate loop
Position loop
8.2=θk
8.2=qk
5.11=θk
0.6=qk
Flare : 
θ
−
+
 
Fig. 4. Pitch autopilot 
 
The overall control scheme is described in Fig. 5, in which the control signal U 
is the sum of the PID controller output and the CMAC-GBF or type-2 fuzzy CMAC 
output. The inputs for the CMAC and PID controller are: altitude, altitude command, 
altitude rate, and altitude rate command. The PID controller provides tolerable 
solutions. In each time step k, the CMAC involves a recall process and a learning 
process. In the recall process, it uses the desired system output of the next time step 
and the actual system output as the address to generate the control signal CMACU . In 
the learning process, the control signal of the pitch autopilot, U, is treated as a desired 
output. It is used to modify the weights of CMAC stored at location which is 
addressed by the actual system output and the system output of the next time step. 
The output of the CMAC is the compensation for pitch command. When the wind 
turbulence is too strong, the ALS can not control the aircraft to land safely. In here 
we use a CMAC-GBF or a type-2 fuzzy CMAC control scheme to improve the ability 
of turbulence resistance of the ALS. 
 
for xl and e, f, g, and h in the second row for x2 are possible shifted regions. Ee, 
Ef,...Hh are new hypercubes from the shifted regions. With this kind of 
decomposition, if there are Ne elements in a complete block, we will have Ne layers 
of hypercubes. In the given example, there are four layers as shown in Fig. 7. The 
state is covered by Ne different hypercubes, one from each layer.  
 
1S
2S
 
Fig. 7. Block division of CMAC-GBF for a two-variable case 
 
In the original CMAC, a constant value is assigned to each hypercube. By 
inputting vectors into these hypercubes, no matter what the positions are, the obtained 
values are the same. The output of CMAC is the sum of several values of hypercube 
and the input vector is treated as memory addresses. Therefore, the output is 
irrelevant to input and the differential of output to input is also not obtainable. Thus, 
in the CMAC-GBF, a general basis function (GBF) is used to replace constants in 
every hypercube. In this way, the positions of input vectors are related to output 
value, and the learning precision is also increased.  
In the CMAC-GBF, the content of hypercube can be expressed as 
)()( siisi xbvxw = , where )( si xb  is a general basis function and iv is a weight to be 
obtained through learning. The output of the CMAC-GBF can be written as below. 
∑==
eN
i
siiiss
T
ss xbvaxwaxy )](..[)()( ,          (8)                         where 
]......... [
,2,1, eNsss
T
s aaaa = is the hypercube selection vector and 
))(2)(())(ˆ(
)(
)(
3
2
,
,
ij
ijis
siiiss
T
ss
e
m
ij
ij
ij
si
sie
ije
ij
mx
xbvaxway
N
xw
xw
E
N
E
N
σ
α
σ
φ
φ
α
σ
α
σ
σ
σ
−
−−=
∂
∂
∂
∂
∂
∂
−=
∂
∂
−=∆
   (15) 
where mα  and σα  are the learning rates for the variances. 
 
3.2 Type-2 Fuzzy CMAC 
 
The type-2 fuzzy theorem is utilized into CMAC structure in order to promote more 
accurate resolution than conventional CMAC. The mapping procedure of type-2 
FCMAC is similar as conventional FCMAC. The diagram structure of type-2 
FCMAC is shown in Fig.8. Each phase of mapping is described as follows. The X is 
an n-dimensional input space, as shown in Fig 9. For the given ].....[ 2,1 nxxxX = , 
].....[ 2,1 nsssS =  represents the quantization vector of x. It is specified the 
corresponding state of each input variable before the fuzzifization. Type-2 FCMAC 
uses the interval type-2 fuzzification method of the fuzzy theorem as its addressing 
scheme. After the input vector to the interval type-2 fuzzy set is being fuzzified, the 
input state values are transformed to upper firing strength and lower firing strength, 
which is based on corresponding interval type-2 membership functions. We choose 
the product inference method as the t-norm operator. The jth rule’s upper firing 
strength jc and lower firing strength firing strength jc  in type-2 FCMAC could be 
computed as: 
 
1S
2
S
••
••
•
•
••
•
•
•
•
 
Fig. 8. Diagram of type-2 FCMAC in 3-D 
w  and w  are the corresponding weights of c  and c , respectively. L and R can be 
obtained from [19]: 
Step 1. Assume that the pre-computed jw  are arranged in ascending order, i.e.,  
Nwww ≤≤≤ ...........21  
Step 2. Compute ry by initially setting  2/)( jjj ccc +=  f or Nj .......1= and let 
rr yy =′  
Step 3. Find )11( −≤≤ NRR such that 1+≤′≤ RrR wyw  
Step 4. Compute ry with 
jj cc = for Rj ≤  and jj cc =  for Rj >  
and let rr yy =′′  
Step 5. If rr yy ≠′′  then go to step 6. If rr yy ′=′′ then stop and set rr yy ′≡′′  
Step 6. Set rr yy ′′=′  and return to Step 3. 
The procedure for computing ly  is very similar to the one just given for ry . In Step 3 
find )11( −≤≤ NLL  such that 1+≤′≤ LlL wyw . Additionally, in Step 2 compute 
ly initially setting 2/)( jjj ccc +=  for Nj .......1= and in Step 4 compute ly  with 
jj cc =  for Lj ≤  and jj cc =  for Lj > . 
The defuzzified output is simply the average 
lr yyy +=                        (21) 
The work on learning of type-2 FCMAC is to update the memory weight according to 
the error between the desired output and the actual output. The learning rule for 
Type-2 FCMAC is as following: 
∑
=
−
−+=
N
j
jjd
i
j
i
j xcxcyy
m
ww
1
)1()( )(/)()(α            (22) 
∑
=
−
−+=
N
j
jjd
i
j
i
j xcxcyy
m
ww
1
)1()( )(/)()(α                              (23) 
where α is the learning rate, m is the size of floor (called generalization ). 
4   Simulations 
The aircraft starts the initial states of the ALS as follows: the flight height is 500 ft, 
the horizontal position before touching the ground is 9240 ft, the flight angle is -3 
degrees, the speed of the aircraft is 234.7 ft/sec. Successful touchdown landing 
conditions are defined as follows: 
1). 1)(3 −≤≤− ThTDɺ     (ft/sec)  2). 300 ( ) 1000TDx T− ≤ ≤   (ft) 
3). 200 ( ) 270TDV T≤ ≤    (ft/sec)  4). 10 ( ) 5TD Tθ− ≤ ≤        (degrees) 
 0 5 10 15 20 25 30 35 40 45
-20
-18
-16
-14
-12
-10
-8
-6
-4
-2
0
Time (sec.)
ft.
/s
ec
.
Vertical Velocity (Solid) & Vertical Velocity Command (Dashed)
 
Fig. 11. Aircraft vertical velocity and command 
 
5 10 15 20 25 30 35 40 45
0
50
100
150
200
250
300
350
400
450
500
Time (sec.)
ft.
Altitude (Solid) & Altitude Command (Dashed)
 
Fig. 12. Aircraft altitude and command 
 
Table 2. The results from using CMAC-GBF control scheme 
Wind  
speed 
Landing 
point (ft) 
Aircraft vertical 
speed (ft/sec) 
Pitch angle 
(degree) 
10 796 -2.61 -0.95 
20 808 -2.42 -0.54 
30 949 -2.16 -0.33 
40 796 -2.09 0.07 
50 796 -2.13 0.17 
60 808 -1.55 0.92 
71 820 -1.71 0.89 
 
Table 3. Results from using CMAC controller 
Wind  
speed 
Landing 
point (ft) 
Aircraft vertical 
speed （ft/sec） 
Pitch angle
（degree） 
5 10 15 20 25 30 35 40 45
0
50
100
150
200
250
300
350
400
450
500
Time (sec.)
ft.
Altitude (Solid) & Altitude Command (Dashed)
 
Fig. 15. Aircraft altitude and command 
 
The type-2 FCMAC control scheme can successfully guide the aircraft flying through 
wind speeds of 0 ft/sec to 100 ft/sec while the type-1 FCMAC can only reach 90 
ft/sec [20], as shown in Table 4 and Table 5. The situations at wind turbulence 100 
ft/sec are that the pitch angle is 0.6968 degrees, vertical speed is -1.7101 ft/sec, 
horizontal velocity is 234.6779 ft/sec, and horizontal position at touchdown is 
937.8017 ft, as shown in Fig.16 to Fig. 18. 
Table 4. Results from using type-1 FCMAC control 
Wind  
speed 
Landing 
point (ft) 
Aircraft vertical 
speed （ft/sec） 
Pitch angle
（degree） 
10 797 -2.83 -1.41 
30 938 -1.54 -0.58 
50 891 -2.13 0.47 
70 691 -2.21 1.41 
90 926 -1.99 1.34 
 
Table 5. The Results from using type-2 FCMAC control 
Wind 
speed 
Landing point 
（ft） 
Aircraft vertical 
speed （ft/sec） 
Pitch angle 
（degree） 
20 855 -2.51 -0.52 
40 726 -2.44 0.03 
60 996 -2.00 0.50 
80 890 -1.71 1.39 
100 937 -1.71 0.69 
 
5   Conclusions 
The purpose of this paper is to investigate the use of a CMAC with general basis 
function and a type-2 fuzzy CMAC in aircraft automatic landing system and to make 
the automatic landing system more intelligent. Current flight control law is adopted in 
the intelligent controller design. Tracking performance and adaptive capability are 
demonstrated through software simulations. For the safe landing of an aircraft using a 
conventional controller, CMAC or a conventional fuzzy CMAC, the wind speed of 
turbulence limits are 30, 58, and 90 ft/sec [20], respectively. In this study, a well-
trained CMAC-GBF control scheme can reach 71 ft/sec and the type-2 fuzzy CMAC 
can reach 100 ft/sec. The proposed controllers have better performance than previous 
works. The CMAC controller can be used to successfully replace the conventional 
controller. The proposed intelligent controller can act as an experienced pilot and 
guide the aircraft to a safe landing in severe wind turbulence environment. 
 
Acknowledgement. This work was supported by the National Science Council, 
Taiwan, ROC, under Grant NSC 92-2213-E-019 -005. 
References 
1. NASDAC Review of NTSB Weather-Related Accidents, http://www.nasdac.faa.gov/ 
aviation_studies/weather_study/studyindex.html 
2. Flight Safety Foundation-Taiwan, http://www.flightsafety.org.tw/news1.php?Code=1 
&main_id=3&pages=5 
3.  Federal Aviation Administration, “Automatic Landing Systems,” AC20-57A (1997). 
4. C.E. Cohen, et al., “Automatic Landing of a 737 Using GNSS Integrity Beacons,” Proc. 
ISPA, 1995. 
5. DDC-I, “Advanced Auto Landing System from Swiss Federal Aircraft Factory,” Real-Time 
Journal, Sprint, 1995. 
6. S. Asai, et al., “Development of Flight Control System for Automatic Landing Flight 
Experiment,” Mitsubishi Heavy Industries Technical Review, vol. 34, no. 3, 1997. 
7. D.N. Kaufmann and B.D. McNally, “Flight Test Evaluation of the Stanford University and 
United Airlines Differential GPS Category III Auotmatic Landing System,” NASA 
Technical Memorandum 110355, June 1995. 
8. C.C. Jorgensen and C. Schley, “A Neural Network Baseline Problem for Control of 
Aircraft Flare and Touchdown,” Neural Networks for Control, pp. 403-425, 1991. 
9. J.G. Juang and K.C. Chin, “Intelligent Landing Control Based on Neural-Fuzzy-GA Hybrid 
System,” Proc. IEEE International Joint Conference on Neural Networks, vol. 3, pp. 1781-
1786, 2004. 
10. D.K. Chaturvedi, R. Chauhan, and P.K. Kalra, “Application of Generalized Neural 
Network for Aircraft Landing Control System,” Soft Computing, vol. 6, pp. 441-118, 2002. 
11. H. Izadi, M. Pakmehr, and N. Sadati, “Optimal Neuro-Controller in Longitudinal 
Autolanding of a Commercial Jet Transport,” Proc. IEEE International Conference on 
Control Applications, CD-000202, pp. 1-6, Istanbul, Turkey, 2003.. 
12. Y. Iiguni, H. Akiyoshi, and N. Adachi, “An Intelligent Landing System Based on Human 
Skill Model,” IEEE Transactions on Aerospace and Electronic Systems, vol. 34, no. 3, pp. 
877-882, 1998. 
