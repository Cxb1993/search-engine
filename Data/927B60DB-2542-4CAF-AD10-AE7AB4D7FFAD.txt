 1
行政院國家科學委員會專題研究計畫成果報告 
演化式計算與群體智慧應用於排程問題 
Evolutionary Computation and Swarm Intelligence  
for Scheduling Problems 
計畫編號：NSC-94-2213-E-011-034 
NSC-95-2811-E-011-006 
執行期限：94 年 8 月 1 日至 96 年 7 月 31 日 
主持人：廖慶榮 教授   台灣科技大學工業管理系 
計畫參與人員：曾兆堂  台灣科技大學工業管理系博士後研究 
              阮曉健  台灣科技大學工業管理系碩士班 
              程哲廞  台灣科技大學工業管理系碩士班 
              趙謙文  台灣科技大學工業管理系碩士班 
              徐千淇  台灣科技大學工業管理系碩士班 
 
 
中文摘要 
 
粒子群最佳化演算法（Particle Swarm Optimization；PSO）是一個集合演化式計算
與群體智慧的共通啟發式演算法，它啟發自鳥群或魚群的行為。目前粒子群最佳化演算
法應用在排程問題上的研究是相當罕見。因此，本研究設計三種不同的粒子群最佳化演
算法，來求解典型之流程型工廠、批量流之流程型工廠以及多工處理之多階混合流程型
工廠等三類排程問題。本研究主要區分為以下三個部份： 
 
第一部份：PSO 求解流程型工廠排程問題 
針對此問題，我們發展出一個間斷型粒子群最佳化演算法（Discrete Particle Swarm 
Optimization；DPSO），該演算法延伸自間斷版本的粒子群最佳化演算法。在演算法中，
我們重新定義粒子及速度且發展一個有效的方法使粒子移動至新的順序。實驗結果證明
我們提出的間斷型粒子群最佳化演算法非常具有競爭力。 
 
第二部份：PSO 求解批量流之流程型工廠排程問題 
針對此問題，首先我們提出一個淨移動利益演算法(Net Benefit of Movement; 
NBM)，求得一個已知順序下的最佳子批量配置。其次，我們改善第一部份提出的 DPSO
演算法以搜尋最佳的順序。此新的 DPSO 演算法引入基因演算法中的繼承機制，改善粒
子的建構方式。實驗結果顯示，改善後 DPSO 演算法，在此排程問題上呈現最好的績效。 
 
第三部份：PSO 求解多工處理之多階混合流程型工廠排程問題 
針對此問題，我們再提出一個新 PSO 的演算法。該演算法主要延伸自連續版本的
PSO 演算法，並引入一個新的粒子編碼方式並找出最好的粒子速度方程式及鄰域拓撲機
制。實驗結果證明，我們所提出的 PSO 演算法有很好的求解效果。 
 
關鍵詞：粒子群最佳化演算法、演化式計算、群體智慧、排程、流程型工廠 
 
 3
Part I. Particle swarm optimization for flowshop scheduling problem 
 
1.  Introduction 
 
Particle Swarm Optimization (PSO), originally designed by Kennedy and Eberhart 
(1995), is an emerging population-based optimization method. Since 2002, PSO has been 
growing rapidly with over 100 published papers every year. All the related research has 
totaled over 300 papers until 2004 (Hu et al., 2004). PSO has been applied successfully to 
continuous nonlinear functions (Kennedy and Eberhart, 1995), neural networks (Van den 
Bergh and Engelbrecht, 2000), nonlinear constrained optimization problems (El-Galland et al., 
2001), etc. Most of the applications have been concentrated on solving continuous 
optimization problems, but the studies of PSO on discrete optimization problems are 
relatively few. In this research, we will develop a PSO algorithm for the flowshop scheduling 
problem, a class of important discrete optimization problems. 
In the PSO literature, the research on scheduling is extremely few. Tasgetiren et al. 
(2004a) first developed a PSO algorithm for the single machine total weighted tardiness 
problem. They used the smallest position value (SPV) rule, a non-decreasing order 
mechanism, to convert a position vector to a job permutation. Also, a well-known local search 
method, called variable neighborhood search (VNS), was applied to improve the solution. 
With the same approach, Tasgetiren et al. (2004b) solved two permutation flowshop problems 
with the criteria of makespan minimization and maximum lateness minimization, respectively. 
Both their algorithms with and without VNS were experimented on the benchmark problems 
given by Demirkol et al. (1998) and both showed their advantages over the respective genetic 
algorithms (GA) proposed by themselves. 
It is noted that the above scheduling research on PSO is an extension from the continuous 
version of PSO (i.e., the original PSO). To solve discrete optimization problems, Kennedy 
and Eberhart (1997) also developed a discrete version of PSO, which however has seldom 
been utilized. Adopting a different approach from Tasgetiren et al. (2004a,b), this research 
attempts to develop an algorithm for the flowshop scheduling problem based on discrete PSO. 
The proposed PSO algorithm has several features including the construction of a particle 
sequence and a new neighborhood structure of particles, among others. 
To evaluate the performance of the discrete PSO algorithm for flowshop scheduling, we 
will conduct a series of experiments in this research. First, we will compare our discrete PSO 
algorithm with the continuous PSO algorithm of Tasgetiren et al. (2004b). The two algorithms 
will be used to solve the makespan minimization problem in a flowshop, studied by 
Tasgetiren et al. (2004b). Second, we will make a comparison between PSO and GA, another 
population-based metaheuristic. A recent GA algorithm of Etiler et al. (2004) is chosen and 
the comparative study is made based on the well-known benchmark problems given by 
Taillard (1993). Third, as Pinedo (2002) indicates, population-based algorithms are well 
suited for multi-objective scheduling problems because they are already designed to carry a 
population of solutions from one generation to next generation. Hence, we will select a GA 
algorithm, developed by Sridhar and Rajendran (1996), for a triple-objective flowshop 
scheduling problem for comparison. Finally, to improve our PSO algorithm we will attempt to 
incorporate a local search scheme into the algorithm. The best upper bounds on total flow 
time reported by Rajendran and Ziegler (2004) are utilized for the relative performance 
evaluation. 
The structure of this research is organized as follows. In the next section, we introduce 
the background of PSO. The structure of the proposed PSO algorithm is presented in Section 
 5
1
1 1 2 2( ) ( )
t t t t t t
id id id id gd idv v c r p x c r p x
−= + − + −                        (1) 
where 1c  is the cognition learning factor, 2c  is the social learning factor, and 1r  and 2r  
are random numbers uniformly distributed in [0,1] . Eq. (1) specifies that the velocity of a 
particle at iteration t is determined by the previous velocity of the particle, the cognition part, 
and the social part. The values k kc r  ( 1, 2)k =  determine the weights of the two parts, where 
their sum is usually limited to 4 (Kennedy et al., 2001).  
By Eq. (1), each particle moves according to its new velocity. Recall that particles are 
represented by binary variables. For the velocity value of each bit in a particle, Kennedy and 
Eberhart (1997) claim that higher value is more likely to choose 1, while lower value favors 
the 0 choice. Furthermore, they constrain the velocity value to the interval [0, 1] by using the 
following sigmoid function: 
1( )
1 exp( )
t
id t
id
s v
v
= + −                               (2) 
where ( )tids v  denotes the probability of bit 
t
idx  taking 1. To avoid ( )
t
ids v  approaching 0 or 
1, a constant maxV  is used to limit the range of 
t
idv . In practice, maxV  is often set at 4, i.e., 
max max[ , ]
t
idv V V∈ − +  (Kennedy et al., 2001).  
Kennedy et al. (2001) give the pseudo code of discrete PSO as follows (for maximization 
problem): 
Loop 
For 1i =  to pN  
If ( ) ( )t ti iG X G P>  then            // ( )G  evaluates objective function 
     For 1d =  to D  bits 
      t tid idp x=                     // tidp  is best so far 
     Next d  
End if 
g i=                             //arbitrary 
For j = indexes of neighbors (or population) 
     If ( ) ( )t tj gG P G P>  then g j=      // g  is index of best performer in  
 neighborhood (or population) 
Next j  
For 1d =  to D   
     1 1 1 2 2( ) ( )
t t t t t t
id id id id gd idv v c r p x c r p x
−= + − + −  
     max max[ , ]
t
idv V V∈ − +            
     If random number ( )tids v<  then 1 1tidx + = ; else 1 0tidx + =  
Next d  
Next i  
Until criterion 
 
3. The proposed PSO algorithm 
 
The flowshop scheduling problem can be described as follows: given n jobs and m 
machines. The job sequence is the same for each machine and the machine sequence is the 
same for each job, i.e., the permutation schedule. Each machine can process only one job at a 
time. The ready times of all jobs are zero. No job splitting is allowed; that is, once a job is 
 7
Step 2.  (Fitness) Evaluate the fitness of each particle in the swarm. 
Step 3.  (Update) Calculate the velocity trail of each particle by Eq. (3). 
Step 4.  (Construction) Each particle applies Eq. (4) to select the next position repeatedly 
until a complete sequence is constructed. 
Step 5.  (Termination) Stop the algorithm if the stopping criterion is satisfied; return to Step 
2 otherwise. 
 
We attempt to incorporate a local search scheme into the proposed PSO algorithm (called 
PSO-LS) to improve its performance. The local search scheme is a combination of IT 
(interchange) and IS (insertion). First, IT is implemented, with the first-improvement strategy, 
until no better sequence is found. After that, IS is applied to complete the local search. The 
movement for both forward and backward interchanges and insertions is restricted to a 
maximum of 12 nearest positions. The local search is combined into the PSO procedure as 
follows. To start with, a local search is first employed to each particle. In the loop of the 
DPSO algorithm, the local search is carried out once for every fixed number (the number of 
jobs) of iterations. 
 
4. Computation results 
 
Three sets of computational experiments were conducted to test the performance of the 
proposed PSO algorithm. The first set compares our algorithm with the continuous PSO 
algorithm of Tasgetiren et al. (2004b). The second sets draw a comparison with GA, another 
population-based metaheuristic, for flowshop scheduling with single objective. The third set 
examines the performance of the algorithm with the incorporation of local search technique. 
All the algorithms were coded in Visual C++ and run on a Pentium IV 3.2 GHz PC. 
 
4.1.  Comparison with continuous PSO 
Tasgetiren et al. (2004b) developed a continuous PSO algorithm for the makespan 
minimization problem in a flowshop. We will compare our PSO algorithm with their 
algorithm. The comparative experiments were conducted on the benchmark instances for 
flowshop scheduling with makespan given by Demirkol et al. (1998) in accordance with 
Tasgetiren et al. (2004b). 
We solve the 40 benchmark instances by using each of the two PSO algorithms, where 
each instance is tested for 10 trials. We use the percentage relative increase (PRI) in 
makespan as the performance measure, i.e.,  
( )PRI 100A U
U
−= ×  
where U  represents the best upper bound, A  represents the makespan value generated by 
the respective algorithm. For each instance, the average PRI( ),μ  standard deviation PRI( ),σ  
and minimum PRI(min )  of PRI are computed. The results are given in Table 1, which gives 
the mean PRIμ  (avg), mean PRIσ  (std), and mean PRImin  (min), along with the number of 
iterations (iter.) and average computation time ( t ). It can be observed that the proposed PSO 
algorithm outperforms the algorithm of Tasgetiren et al. for all the combinations. For the 
mean PRIμ  (avg), there is an average difference of 1.46. With the increase in the number of 
jobs, the difference is slightly raised. The proposed PSO algorithm is also superior in terms of 
std and min. 
However, it is observed in Table 1 that our algorithm requires more computation time.  
 9
collaborateurs/etd/. The results are summarized in Table 3, which gives the mean PRIμ  (avg) 
yielded by PSO, GA, and NEH (1983). We note that NEH is a constructive heuristic and it 
can generate the solution in a very short time. It is observed from the table that the proposed 
PSO algorithm performs best for most problems, while GA is the best for two large-sized 
problems (100 10×  and 100 20× ). 
 
4.3.  Performance of PSO with local search 
We now attempt to incorporate a local search scheme into the proposed PSO algorithm 
(called PSO-LS) and observe its performance for flowshop scheduling with total flow time 
criterion. We will compare its solutions with the best upper bounds on total flow time 
reported by Rajendran and Ziegler (2004), which developed two ant-colony algorithms, called 
M-MMAS and PACO. The comparative experiments will be carried out on the benchmark 
problems of Taillard (1993).  
The computational results are summarized in Table 4, which gives the mean value of RPI 
in total flow time yielded by BEST(LR) (2001), M-MMAS, PACO, LS, PSO-LS, respectively. 
It is observed that both M-MMAS and PACO outperform other algorithms for most problems. 
Although our PSO-LS performs well for some problems, the results are obtained by taking 
more iterations and more computation times. We note that both M-MMAS and PACO are the 
latest versions of ant-colony algorithms, which have been applied to the scheduling problems 
for about ten years. Nevertheless, PSO has just been employed in solving scheduling 
problems for one or two years, and thus it still has potential to be developed as a good 
solution approach for the scheduling problem. In addition, LS in Table 4 denotes the 
implementation of our local search without using any other solution methods. To have a fair 
comparison between LS and PSO-LS, LS was run to attain the same computation time as 
PSO-LS. It is observed that PSO-LS is superior to LS in all the problems, which indicates that 
the particles are truly led to good intermediate solutions by PSO. 
 
Table 3  Comparison with GA of Etiler et al. for single- 
objective flowshop 
 
n m×   NEH GA PSO t  
20×5  3.30 1.52 1.25 0.99 
20×10  4.60 2.81 2.17 1.17 
20×20  3.81 2.55 2.09 1.24 
50×5  0.73 0.63 0.47 13.71 
50×10  5.07 3.62 3.60 14.42 
50×20  6.64 5.36 4.84 16.66 
100×5  0.53 0.45 0.35 95.65 
100×10  2.22 1.56 1.78 122.42 
100×20  5.34 4.90 5.13 139.28 
 
 11
applications to discrete optimization problems are few. In this research, we have 
demonstrated that the discrete version of PSO can be applied to the flowshop scheduling 
problem, a class of discrete optimization problems, and the extended algorithm is very 
competitive. Future research may be conducted to further investigate the applications of 
discrete PSO to other scheduling problems. It is also worthwhile to design other versions of 
PSO to continue pursuing the best performance of PSO in solving flowshop scheduling 
problems. 
 
References 
 
Demirkol, E., Mehta, S. and Uzsoy, R., Benchmarks for shop scheduling problems. European 
Journal of Operational Research, 1998, 109, 137-141. 
Eberhart, R.C. and Kennedy, J., A new optimizer using particle swarm theory, in Pceedings of 
the Sixth International Symposium on Micromachine and Human Science, 1995, pp. 
39-43. 
El-Galland, AI., El-Hawary, M.E. and Sallam, A.A., Swarming of intelligent particles for 
solving the nonlinear constrained optimization problem. Engineering Intelligent Systems 
for Electrical Engineering and Communications, 2001, 9, 155-163. 
Etiler, O., Toklu, B., Atak, M. and Wilson, J., A genetic algorithm for flow shop scheduling 
problems. Journal of the Operational Research Society, 2004, 55, 830-835. 
Garey, M.R., Johnson, D.S. and Sethi, R., The complexity of flowshop and jobshop 
scheduling. Mathematics of Operations Research, 1976, 1, 117-129. 
Hu, X., Shi, Y. and Eberhart, R.C., Recent advances in particle swarm, in Proceedings of the 
IEEE Congress on Evolutionary Computation, 2004, pp. 90-97. 
Kennedy, J. and Eberhart, R.C., Particle swarm optimization, in Proceedings of IEEE 
International Conference on Neural Networks, Piscataway, 1995, pp. 1942-1948. 
Kennedy, J. and Eberhart, R.C., A discrete binary version of the particle swarm algorithm, in 
Proceedings of the World Multiconference on Systemics, Cybernetics and Informatics, 
1997, pp. 4104-4109. 
Kennedy, J., Eberhart, R.C. and Shi, Y., Swarm Intelligence, 2001 (Morgan Kaufmann: CA). 
Liu, J. and Reeves, C.R., Constructive and composite heuristic solutions to the || iF C∑  
scheduling problem. European Journal of Operational Research, 2001, 132, 439-452. 
Nawaz, M., Enscore, E.E. and Ham, I., A heuristic algorithm for the m-machine, n-job 
flowshop sequencing problem. OMEGA, 1983, 11, 91-95. 
Onwubolu, G.C., Emerging Optimization Techniques in Production Planning and Control, 
2002 (Imperial College Press: London). 
Pinedo, M., Scheduling: Theory, Algorithm, and System, 2nd ed., 2002 (Prentice-Hall:NJ). 
Rajendran, C. and Ziegler, H., Ant-colony algorithms for permutation flowshop scheduling to 
minimize makespan/total flowtime of jobs. European Journal of Operational Research, 
2004, 155, 426-438. 
Shi, Y. and Eberhart, R.C., A modified particle swarm optimizer, in Proceedings of the IEEE 
congress on Evolutionary Computation, Piscataway, 1998, pp. 69-73. 
Sridhar, J. and Rajendran, C., Scheduling in flowshop and cellular manufacturing systems 
with multiple objectives--a genetic algorithmic approach. Production Planning and 
Control, 1996, 7, 374-382. 
Taillard, E., Benchmarks for basic scheduling problems. European Journal of Operational 
Research 1993, 64, 278-85. 
Tasgetiren, M.F., Sevkli, M., Liang, Y.C. and Gencyilmaz, G., Particle swarm optimization 
 13
Part II. Particle swarm optimization for lot-streaming flowshop scheduling 
problem 
 
1. Introduction 
 
In a traditional flowshop, each job must be processed on every machine and all jobs must 
follow the same machine sequence (route). One of the common restrictions made in most 
research studies is that a job cannot be transferred to the next machine before its processing is 
finished. This need not be the case in many practical situations because a job may be split into 
a number of smaller sublots. When a job sublot is completed, it can be immediately moved to 
the next machine. By splitting jobs, the idle time on successive machines can be reduced. The 
job splitting into sublots process is usually called “lot streaming”, which was first introduced 
by Reiter (1966). Some studies showed that lot streaming can significantly improve the 
schedule performance with respect to the makespan (Potts and Baker, 1989; Baker and Pyke, 
1990). In recent years, lot streaming has received extensive attention and been applied to the 
flowshop scheduling problem. A complete survey can be found in Chang and Chiu (2005). 
For the lot-streaming problem of a single job in a flowshop, the objective is to simply 
determine the optimal sublot sizes. Potts and Baker (1989) considered a flowshop with 
makespan criterion and indicated when it is sufficient in a single-job model to use the same 
sublot sizes for all machines. Trietsch and Baker (1993) reviewed the different forms of 
single-job lot streaming existing in the literature and generalized some important structural 
insights. To minimize the total flow time, Kropp and Smunt (1990) presented optimal sublot 
size policies and two heuristic methods for a single job in a flowshop. Bukchin et al. (2002) 
identified the optimal solution properties and developed a solution procedure to minimize the 
total flow time in a two-machine flowshop with detached setups and batch availability. 
For the lot-streaming problem with n  jobs ( 1,..., )j n=  in a flowshop with makespan 
criterion, we need to simultaneously obtain the best job sequence and the optimal sublot 
allocation (sublot starting and completion times). Potts and Baker (1989) showed that it is not 
possible to solve the n-job problem simply by applying lot streaming individually to the 
single-job problem. Vickson and Alfredsson (1992) modified Johnson’s rule to obtain the 
optimal solutions for the two-machine and special three-machine problems with unit-size 
sublots. Kalir and Sarin (2001) investigated equal-size sublots and developed a bottleneck 
minimal idleness heuristic to generate solutions that were very close to the optimum. To the 
best of our knowledge, the n-job model in a flowshop with total flow time criterion was not 
considered in the literature. 
With the advent of just-in-time (JIT), the criterion involving both earliness and tardiness 
penalties has received significant attention. Yoon and Ventura (2002a) examined 
lot-streaming flowshop scheduling with respect to earliness and tardiness penalties. For a 
given job sequence, they presented linear programming (LP) models to obtain the optimal 
sublot allocation for cases where the buffers between successive machines have limited or 
infinite capacities and the sublots have equal sizes or are consistent. For the case with 
equal-size sublot and infinite capacity buffer, sixteen pairwise interchange methods obtained 
by combining four rules to generate initial sequences with four neighborhood search 
mechanisms are considered. The experimental results showed that the best performance was 
obtained using a non-pairwise interchange mechanism and the smallest overall slack time rule 
to generate the initial sequence. Later, Yoon and Ventura (2002b) provided a genetic 
algorithm (GA) that incorporated the LP and pairwise interchange method for the 
lot-streaming flowshop scheduling with equal-size sublot and infinite capacity buffer. Their 
 15
jd    due date of job j  
jC    completion time of job j  
jT    tardiness of job j , max(0, )j j jT C d= −  
jE  earliness of job j , max(0, )j j jE d C= −  
jα  earliness penalty of job j  
jβ  tardiness penalty of job j  
( )kl  last sublot of ( )kJ  on the last machine  
( )ke  starting time of ( )kl   
( )kUNB  net benefit by moving ( )kl  one time unit 
 
The problem considered in this research can be stated as follows. There is a flowshop 
with n  jobs and m  machines. Each job must be processed on each one of the m  
machines in series. Job j  can be split into js  equal sublots where js  is the same for all 
machines. This type of sublots is called equal-size sublots in the lot streaming realm. Both the 
setup time and the sublot transportation time are ignored. The objective is to minimize the 
total weighted earliness and tardiness, i.e.,  
1
min  ( ) ( )
n
j j j j
j
f E Tπ α β
=
= +∑  (1) 
The problem can be divided into two subproblems. The first subproblem is to find the optimal 
starting and completion times for each sublot on each machine for a given sequence. The 
second one is to search for the best sequence with minimum total weighted earliness and 
tardiness. The two subproblems are clearly dependent, and hence it is rather difficult to 
determine the optimal schedule for the problem.  
 
3. Optimal sublot allocation for a given sequence 
 
As a subproblem for the considered problem, we need to determine the optimal starting 
and completion times of each sublot on each machine for a given sequence. Yoon and 
Ventura (2002b) presented an LP model for this purpose. Due to a large computational effort 
for the LP model, which is used in their GA, only small-size problems with at most 15 jobs 
are solved. In this section, we develop an efficient algorithm which can serve the same 
purpose but requires much less computation time. The developed algorithm can be easily 
incorporated into any metaheuristic and thus large-size problems can be solved. 
The proposed algorithm uses the concept of net benefit of movement (NBM) to 
determine whether a considered sublot should be moved. At the beginning of the algorithm, 
each sublot is started as soon as possible in the flowshop for a given sequence. Thus, a 
backward movement is not allowed, and we need only to consider a forward movement to 
minimize the objective function.  
The job completion time is determined using the last sublot for the job on the last 
machine. When the optimal starting and completion times for all of the last sublots on the last 
machine are obtained, the optimal schedule can be generated by delaying processing other 
sublots on each machine as much as possible without affecting the starting times for these last 
sublots. Based on the above discussion, we can focus our attention on scheduling the last 
sublots for jobs on the last machine ( ( ) ,kl 1,2,...,k n= ).  
The basic idea of the NBM algorithm can be briefly explained as follows. The algorithm  
 17
Proof. If ( )kl  is moved ( 1) ( 1)k r k rA I I+ + + +′= +  time units, then both ( 1)k rI + +  and ( 1)k rI + +′  are 
reduced to zero (see Fig. 1), meaning that we need to fine a new r . From Eq. (3), a new r  
will result in a change in ( )kUNB . On the other hand, ,..., ( )min { }j k k r jB E= +=  is the smallest 
earliness for those jobs placed between the k th and ( )k r+ th positions. When ( )kl  is moved 
B  time units, the job with the smallest earliness, say ( )jJ , is changed from earliness to “on 
time”, deriving a new ( )jUB . From Eqs. (2) and (3), a new ( )jUB  will result in a change in 
( )kUNB . Therefore, within the amount of min{ , },M A B=  the movement of ( )kl  does not 
cause a change in the current ( )kUNB . Beyond this amount, ( )kUNB  will be different.     
 
From Theorem 1, it is worth moving ( )kl  forward M  time units at a time if 
( ) 0kUNB > . After that, ( )kUNB  must be recalculated to determine whether ( )kl  is still worth 
moving. The proposed NBM algorithm is a simple backward procedure which consists of 
repeatedly checking ( )kUNB  and applying Theorem 1 for each ( )kl . We now state the NBM 
algorithm, which is used to obtain the optimal starting and completion times for all sublots on 
each machine for a given sequence, as follows: 
Step 1.  For a given sequence π , let each sublot be started on the machines as soon as 
possible. Compute ( ) ( ) ( ) ( ), , ,k k k kE T I I ′  for 1,2,...,k n= . 
Step 2.  Consider ( )nJ . If ( ) 0nE > , then move ( )nl  forward ( )nE  time units and update 
( ) ( ) ( )n n nI I E= +  and ( ) 0nE = . Set 1k n= − . 
Step 3.  Find the smallest r  ( 0r ≥ ) such that ( 1) 0k rI + + >  or ( 1) 0k rI + +′ > . If it cannot be 
found until 1k r n+ + = , then r n k= − . 
Step 4.  Compute ( )kUNB . If ( ) 0kUNB > , proceed to Step 5; otherwise go to Step 6. 
Step 5.  Move ( )kl  forward M  time units. Update ( )kI , ( 1)k rI + +′ , and ( 1)k rI + + . Compute 
( )jE  and ( )jT  for ,...,j k k r= + . Return to Step 3. 
Step 6.  Let 1k k= − . If 1k ≥ , return to Step 3. 
Step 7.  Generate the final schedule: (1) Compute the optimal starting times of the last 
sublots of jobs on the last machine, ( ) ,ke as follows: If ( ) 0,kE >  then 
( ) ( ) ( ) ( ) ,k k m k ke d lt E= − −  else ( ) ( ) ( ) ( ) ;k k m k ke d lt T= − + (2) Delay the processing of 
other sublots on each machine as much as possible without affecting ( )ke  for all k . 
 
We briefly explain the above steps. Step 1 is self-explained. Step 2 considers the last job 
( )nJ . Using Theorem 1, ( )nl  can be moved ( )nE  time units if ( ) 0nE > . Steps 3-5 consider 
the remaining jobs 1, ,1.k n= − K  In Step 3, we determine which jobs should be included in 
( )kUNB , which is computed in Step 4. If ( ) 0kUNB > , then Step 5 moves ( )kl  forward M  
time units and updates the related data. Using Theorem 1, ( )kUNB  must be recalculated to 
determine whether ( )kl  is still worth moving. Steps 3-5 are repeated for ( )kl  until 
( ) 0kUNB ≤ . In Step 6, the procedure is continued until all jobs are considered. In Step 7, the 
final schedule is generated by first determining the optimal starting times for the last sublots 
of all jobs on machine m  ( ( )ke ), and then delaying the processing of other sublots on each 
machine as much as possible without affecting all ( )ke . 
 
 19
construction operator of DPSO algorithm. 
The performances of the five inheritance schemes for the considered problem are 
compared in the next section and the best one is selected as the construction operator in our 
DPSO algorithm. The steps of the proposed DPSO algorithm can be stated as follows: 
Step 1.  Determine parameters: 1 2 max, , , , , .pN c c w V f  Set 
0 0,iV = 1,2,..., ,pi N=  0.t =  
Step 2.  Randomly generate initial particles 0 ,iX 1,2,..., pi N= . Set 0 0.i iP X=  
Step 3.  Evaluate the objective function ( ),tif X 1,2,..., pi N= . 
Step 4.  Assign pbest and gbest as follows:  
a. Find pbest: If ( ) ( )t ti if X f P≤ , then ,t ti iP X= 1,2,..., pi N= .  
b. Find gbest: Compare the evaluated values of tiX  and find 
t t
g lP X=  such that 
( ) ( ),t tl if X f X≤  for 1, 2,..., pi N= . 
Step 5.  Update the velocity trail tiV  for 1, 2,..., pi N=  according to the velocity equation 
of DPSO algorithm. 
Step 6.  Construct new particles 1tiX
+  for 1, 2,..., pi N=  as follows: 
a. Let iO  be a null sequence. Either pbest or gbest is selected as the parent. The 
selected jobs from the parent are copied over to iO  at the same positions. 
b. Job j  chosen from the set of unscheduled jobs is placed in an unoccupied 
position k  according to the construction operator of DPSO algorithm until a 
complete sequence iO  is constructed. Set 
1t
i iX O
+ = . 
Step 7.  Stop the algorithm if the specified stopping criterion is satisfied; return to Step 3 
otherwise. 
 
5. Computational results 
 
In this section, we examine the five different inheritance schemes first and choose the 
best one for use in the algorithm. The proposed DPSO algorithm is then compared with HGA 
by Yoon and Ventura (2002b). All algorithms, including HGA, were coded in Visual C++ and 
run on a Pentium IV 3.4 GHz PC with 512MB memory. 
 
5.1.  Parameter settings 
To determine the best values of parameters, a series of pilot experiments was conducted. We 
first chose the one-point inheritance of DPSO to test in 100 problem instances with 30 jobs 
and 5 machines. The initial parent selection was pbest and the related data were generated the 
same as that in Yoon and Ventura (2002b), from discrete uniform distributions as follows: 
~ (1,31),ijlt U ~ (1,6),js U ~ (1,6),j Uα  ~ (1,6)j Uβ , ~ (15 ,15 ( ))jd U n n m× × + . The ranges 
of parameter values, following the recommendation from the PSO literature (Kennedy and 
Eberhart, 1995; Kennedy and Eberhart, 1997; Liao et al., 2007), were: (5,60),pN =  
(1, 4),kc =  (0.8,1.2),=w  max (3, 20),V = (0.2 ,0.8 ).f n n= × ×  The maximum number of 
iterations MaxIter (40 )m n= + ×  is used as the stopping criterion. The results showed that 
the algorithm performed best under the following settings: 40,pN = 1 2 1.5,c c= =  
max1, 4,w V= = 0.4 .f n= ×  Experimentally, we found that other inheritance schemes of 
DPSO algorithms, even for different problem sizes, gave almost the same results. Besides, a 
selection of pbest as the parent was better than that of gbest. Therefore, these parameter  
 21
Table 2  
Comparison of different algorithms  
for small-size problems 
 
  GA HGA DPSO2  
n m×  MRPI N MRPI N MRPI N CT 
7 3×  5.35 8 0.04 29 0.00 30 0.08 
7 5×  5.38 8 0.10 28 0.00 30 0.10 
10 3×  16.32 0 0.67 21 0.00 29 0.17 
10 5×  15.35 0 0.62 21 0.00 27 0.21 
 
only difference between the two methods is the additional use of interchange (a local search 
method) in HGA. Yoon and Ventura (2002b) showed through extensive experiments that both 
GA and HGA performed best using a population size of 100, a crossover rate of 1.0, and a 
mutation rate of 0.01. These parameter settings were used in all of these experiments. To be 
fair, we increased the number of iterations for GA and HGA to achieve the same computation 
time as DPSO2. Table 2 shows that DPSO2 is the best, even though HGA employs an 
additional local search. It is worth mentioning that it took, according to Yoon and Ventura 
(2002b), 6646.36 seconds to solve the problem with n = 10 and m = 5 using HGA together 
with LP model. However, because of the efficiency of NBM algorithm, it took only 0.21 
seconds using HGA together with NBM to solve the same problem. The computation time 
savings achieved by replacing the LP model with NBM was tremendous. 
For large-size problems, we first evaluate the performances of all algorithms without 
local search. The results are summarized in Table 3, which gives the mean RPI (MRPI), 
number of times that the associated algorithm produces the best solution (NB), and average 
computation time (CT) for GA, DPSO2, and DPSO. The number of iterations in GA was 
increased to achieve relatively the same computation time as DPSO2. It is observed from the 
table that DPSO2 performs much better than GA. Comparing DPSO2 with DPSO shows that 
the inheritance scheme introduced in DPSO2 produces excellent results. Moreover, the 
improvement is raised as the number of jobs increases. To study the convergence behavior of 
the algorithms, we plot the solution values with respect to time (in seconds) for two arbitrary 
instances from 30 5×  and 40 5×  problems in Fig. 2. It can be seen that the convergence 
rate of DPSO2 is higher than those of GA and DPSO, and DPSO2 can find a good solution in 
a short time.  
Finally, we compare the three algorithms with local search. The first algorithm is the 
HGA of Yoon and Ventura (2002b) which employs the interchange (IT) as local search. At 
each iteration the least fit individual in the mating pool is replaced by the best individual in 
the IT neighborhood. Applying the same local search method, DPSO2 with IT (called 
DPSO2-1) carries it out once, on the replacement of each particle, for every fixed number of 
iterations. The third algorithm is DPSO2 with combination of interchange (IT) and insertion 
(IS) (called DPSO2-2). The IT and IS local search is carried out in the same manner as 
DPSO-LS of Liao et al. (2007) and the steps are given in Appendix A. 
A preliminary experiment showed that the same parameter settings as above were 
inappropriate here because of local search incorporation. We used the same manner as in 
Section 5.1 to determine the best parameter settings for DPSO2-1 and DPSO2-2 and obtain 
the following values: 10,=pN 1 2 2, 1,= = =c c w max 4,V =  0.25f n= × , and the local search 
 23
 
Fig. 2. Convergence behavior of two problem instances. 
 
6. Conclusions 
 
This research examined the n-job, m-machine lot-streaming problem in a flowshop with 
equal-size sublots. The objective was to minimize the total weighted earliness and tardiness. 
We proposed the NBM algorithm, which is much more efficient than the LP model of Yoon 
and Ventura (2002b), to obtain the optimal sublot allocation for a given sequence. According 
to the computational experiments conducted by Yoon and Ventura (2002b), 6646.36 seconds 
were required to solve problems with n = 10 and m = 5 using HGA together with LP model. 
However, it took only 0.21 seconds using HGA together with NBM to solve the same 
problems. The computation time savings achieved by replacing the LP model with NBM were 
tremendous. 
We also developed a DPSO algorithm, which incorporates the NBM algorithm, to search 
for a near-optimal sequence. To improve the DPSO algorithm of Liao et al. (2007), the 
inheritance scheme has been introduced into the construction approach. The experimental 
results show that the two-point inheritance scheme provides faster construction of new 
particles with better solution quality. The main reason for such good performance with the 
two-point inheritance scheme is due to balance in the construction operator between 
exploration of new solutions and taking advantage of previous solutions. 
To further verify the proposed DPSO algorithm with and without the use of local search, 
it has been compared with GA and HGA for small-size and large-size problems. The 
computational results have demonstrated the superiority of the proposed DPSO over both GA 
and HGA with the same computation time.  
In this research, we demonstrated that the DPSO algorithm can be applied to the 
lot-streaming flowshop problem and the improved DPSO algorithm is very competitive. 
Further research may be conducted to investigate the applications of other metaheuristics to 
the lot-streaming flowshop problem. It is also worthwhile to design other versions of PSO to 
continue pursuing the best performance of DPSO. 
30 5×  40 5×
0
10000
20000
30000
40000
50000
60000
0 0.5 1 1.5 2 2.5
time (in seconds)
fit
ne
ss 
va
lue
GA
DPSO2
DPSO
0
20000
40000
60000
80000
100000
0 1 2 3 4
time (in seconds)
fit
ne
ss 
va
lue
GA
DPSO2
DPSO
 25
sequencing problem. European Journal of Operational Research, 2007, 177, 1930-1947. 
Trietsch, D. and Baker, K.R., Basic techniques for lot streaming. Operations Research, 1993, 
41, 1065-1076. 
Van den Bergh, F. and Engelbrecht, A.P., Cooperative learning in neural network using 
particle swarm optimizers. South African Computer Journal, 2000, 26, 84-90. 
Vickson, R.G. and Alfredsson, B.E., Two- and three-machine flow shop scheduling problems 
with equal sized transfer batches. International Journal of Production Research, 1992, 
30, 1551-1574. 
Yoon, S.H. and Ventura, J.A., Minimizing the mean weighted absolute deviation from due 
dates in lot-streaming flow shop scheduling. Computers and Operations Research, 
2002a, 29, 1301-1315. 
Yoon, S.H. and Ventura, J.A., An application of genetic algorithms to lot-streaming flow 
shop scheduling. IIE Transactions, 2002b, 34, 779-787. 
 
 
 
 27
problem, Tasgetiren et al. (2004a, 2004b) propose PSO algorithms extending from continuous 
PSO to solve single machine and flow-shop problems. On the other hand, Liao et al. (2007) 
develop a PSO algorithm based on discrete PSO for the flow-shop scheduling problem. 
In this research, we propose a PSO algorithm based on continuous PSO for the 
scheduling of multiprocessor tasks in a multistage hybrid flow-shop with makespan 
minimization. The proposed PSO algorithm has several features, such as a new encoding 
scheme, an implementation of the best velocity equation and neighborhood topology among 
several different variants, and an effective incorporation of local search. The proposed PSO 
algorithm will be compared with the existing GA and ACS algorithms. 
The remainder of this research is organized as follows. In the next section, we formally 
define the problem. The structure of the proposed PSO algorithm is presented in Section 3. A 
series of comparative experiments are conducted in Section 4 to evaluate the performance of 
the algorithm. Finally, conclusions are given in Section 5. 
 
2. Problem Statement 
 
In this section we formally define the stated problem. The following notation is used 
throughout the part III of research: 
 
n  number of jobs 
k  number of stages 
jJ    job  ( 1,2,..., )j j n=  
im    number of parallel machines at stage i ( 1, 2,..., )i k=  
ijt    processing time of job j at stage i 
sizeij  number of machines required to process job j at stage i 
maxC  makespan 
π   a processing sequence of jobs 
 
The scheduling problem considered in this research can be stated as follows. There are k 
stages in a system and each stage i consists of im  identical machines. All jobs have to be 
processed first at stage 1, second at stage 2,…, and last at stage k. Job (task) j has to be 
processed simultaneously on sizeij  identical parallel machines (processors) at stage i for ijt  
time units. At any time each machine can process only one job and the processing of the job 
can not be interrupted. The objective is to find a processing sequence π  that minimizes the 
makespan maxC , or the maximum completion time. Using the well-known three-field notation, 
the problem can be denoted by 1 max( ,..., ) | size |k ijFk Pm Pm C  (Błażewicz et al. 2001, Oğuz 
and Ercan 2005). 
 
3. Proposed PSO algorithm 
 
In this section, we propose a PSO algorithm for the 1 max( ,..., ) | size |k ijFk Pm Pm C  
problem. Before presenting the algorithm, we introduce the PSO metaheuristic.  
 
3.1  Background of PSO 
PSO, inspired by the motion of a flock of birds searching for food, is developed by 
 29
the fitness value of a particle. For a given particle (sequence), the LS algorithm constructs the 
schedule by starting each job as soon as possible at each stage. As in Example 1 (see Section 
2), jobs are assigned to the first stage according to sequence π = (1234567). At the second 
stage, jobs are processed as soon as possible based on the job completion times from the first 
stage. Clearly, the algorithm creates a semi-active schedule for a given sequence. Details of 
the LS algorithm can be found in Oğuz and Ercan (2005). 
 
3.2.3  Update of velocity 
For the scheduling problem, we define the velocity of particle i at iteration t as 
1 2( , ,..., ), ,
t t t t t
i i i in ijV v v v v R= ∈  where tijv  is the movement for job j of particle i from the current 
position value to the next one at iteration t. The velocity updating step is to adjust the 
searching direction of particle. To guide the search out of local minima, different velocity 
equations and neighborhood topologies have been proposed in the literature. In this research, 
we examine several promising velocity equations and neighborhood topologies for the 
scheduling problem. Three of such velocity equations are described as follows. 
(1) Standard formula (SF) 
Equation (1) in Section 3.1 is a standard formula used in PSO. For the 
1 max( ,..., ) | size |k ijFk Pm Pm C  problem, we can rewrite equation (1) as follows. 
1
1 1 2 2( ) ( )
t t t t t t
ij ij ij ij gj ijv wv c r p x c r p x
−= + − + −  (3) 
where 1 2( , ,..., ),
t t t t t
i i i in ijP p p p p I= ∈  denotes the best solution that particle i has obtained until 
iteration t, 1 2( , ,..., ),
t t t t t
g g g gn gjP p p p p I= ∈  denotes the best solution obtained from tiP  in the 
local neighborhood at iteration t, and other parameters are the same as in equation (1). 
(2) Passive congregation (PC) 
He et al. (2004) additionally introduce a social behavior of passive congregation to the 
velocity equation. The particle’s new velocity is updated by 
1
1 1 2 2 3 3( ) ( ) ( )
t t t t t t t t
ij ij ij ij gj ij cj ijv wv c r p x c r p x c r p x
−= + − + − + −  (4) 
Here, 1 2( , ,..., ),
t t t t t
c c c cn cjP p p p p I= ∈  denotes a particle selected randomly from the swarm, 3c  
is the passive congregation coefficient, and 3r  is a random number uniformly distributed in 
U(0,1) . He et al. (2004) indicate that each particle in an aggregation has a multitude of 
potential information from other particles that may minimize the chance of missed detection 
and incorrect interpretations. Such information should be added in the velocity calculation.  
(3) Interrelated weights (IW) 
Ho et al. (2005) point out that SF has difficulties in striking a balance between 
exploration and exploitation. They propose the following formula: 
1
3 2 2 1 1 2 2 1(1 ) ( ) (1 ) (1 )( )
t t t t t t
ij ij ij ij gj ijv s r v r c r p x r c r p x
−= + − − + − − −  (5) 
where 3s  equals 1 if a random number is greater than 0.05 and 1−  otherwise. In SF, each 
particle adjusts its velocity according to equation (1), and the weighting factors ( 1 1c r  and 
2 2c r ) between cognition part and social part are independently and randomly generated. Ho et 
al. (2005) claim that weighting factors are not completely independent; as in human 
decision-making, if one prefers the personal experience (cognition part), the social experience 
(social part) will be ignored. Accordingly, Ho et al. (2005) use only one random number 1r  
to control the two parts. Similarly, another random parameter 2r  is introduced to balance the 
 31
version of variable neighborhood search (VNS) that differs from most local search heuristics 
in that it uses two or more neighborhoods, instead of one, in its structure. It is based on the 
principle of systematic change of neighborhood during the search. Here, we select the 
insertion (IS) and interchange (IT) as the neighborhoods used in RVNS. IS contains all the 
schedules obtained by removing a job at the i th position and inserting it in the j th position 
( )i j≠ . IT contains all the schedules obtained by swapping two jobs in the i th and j th 
positions ( )i j≠ . In the proposed PSO algorithm, RVNS is applied to the best one after each 
particle has completed a feasible solution and is carried out once for every fixed number of 
iterations. The basic idea of the incorporation is using the mechanism of PSO to lead the 
solution to a good region, and then improving it by RVNS. 
 
4.  Computational results 
 
In this section, we first examine nine combinations of PSO with three velocity equations 
and three neighborhood topologies and choose the best combination to be used in the 
algorithm. Then, the developed PSO algorithm is compared with the existing algorithms for 
the same problem. Except for the large-size problems, the PSO without local search is 
selected for testing. All the PSO and GA algorithms were coded in Visual C++ and run on a 
Pentium IV 3.4 GHz PC. 
The computational experiments were conducted on the benchmark problems given by 
Şerifoğlu and Ulusoy (2004). There are five different numbers of jobs ( n = 5, 10, 20, 50, 100) 
with four different numbers of stages ( k =2, 5, 8, 10), where the processing time ijt  and the 
number of machines required sizeij  were drawn from uniform distributions U(1,100)  and 
U(1, )im , respectively. For each combination, 10 instances were generated for each of two 
problem types, Type-A and Type-B. In Type-A problems the number of machines im  at 
stage i was drawn from a discrete uniform distribution U(1,5) , whereas in Type-B problems 
im  was fixed at 5. There are 400 instances in all, which can be downloaded from 
http://web.ntust.edu.tw/~ie/ index.html. 
 
4.1 Evaluation of different PSO variants 
To evaluate the three velocity equations and three neighborhood topologies, 
computational experiments were conducted on Type-A problems with 20 jobs. We solved all 
the 40 instances, each of which was tested for 10 trials. To determine suitable parameter 
settings, the following ranges of parameter values were tested (Shi and Eberhart 1998, 
Kennedy et al. 2001, He et al. 2004): (20,200),pN = 1 (0.5,4.0),c = 2 (0.5,4.0),c =  
3 (0.5,4.0),c = (0.8,1.2),=w max (3,20),V = ns (2, / 2).pN=  The initial populations were 
created randomly, the initial velocities are set to be zero, and the maximum number of 
iterations MaxIter 5 n= × . Based on the experimental results, the best settings of parameters 
are as follows: 200,pN = 1 2 3 2,c c c= = = max1, 4,w V= = ns 20.=  
The percentage deviation (PD) in makespan is used as the performance measure, i.e., 
max( )PD 100
AC LB
LB
−= ×  
where max
AC  represents the makespan value generated by the respective algorithm A  and 
LB  represents the lower bound provided by Şerifoğlu and Ulusoy (2004). For each instance, 
the average PD (APD) of 10 trials is computed. A trial is stopped before the specified 
 33
Table 3.  Comparison of different PSO variants  
for large-size problems. 
 
  IW 
  lbest time-delay 
n k×   Avg N CT Avg N CT
50×2  4.08 10 1.96 4.22 3 1.88
50×5  2.39 8 4.13 2.65 5 3.74
100×2  4.69 9 8.71 4.93 4 8.67
100×5  4.97 8 19.38 5.12 2 18.56
Mean  4.03 8.75 8.55 4.23 3.5 8.21
 
maximum number of iterations if the best objective function value equals LB. The results are 
given in Table 2, which gives the mean APD (Avg), number of times that the associated 
algorithm produces the best APD (N), and mean computation time (CT) in seconds.  
It is observed from Table 2 that the PSO models with IW and lbest/time-delay yield 
solutions of superior quality, as against other solutions of PSO variants. The model with IW 
and lbest performs slightly better than the one with IW and time-delay. As a further 
comparison, additional tests were conducted on large-size problems. From Table 3, it is 
observed that the model with IW and lbest performs better, and thereby it is selected as the 
proposed algorithm. 
 
4.2 Comparison with existing algorithms 
To evaluate the PSO algorithm, experiments were conducted to make a comparison with 
two existing GA algorithms and an ACS algorithm based on the benchmark problem provided 
by Şerifoğlu and Ulusoy (2004). The three metaheuristic algorithms are the best-performing 
ones for the 1 max( ,..., ) | size |k ijFk Pm Pm C  problem in the literature. 
For small- and medium-size problems ( n = 5, 10, 20), there are 240 problem instances, 
each of which is tested for five trials. A trial is stopped before the specified maximum number 
of iterations if the best objective function value equals LB (same as in Şerifoğlu and Ulusoy 
2004). A preliminary experiment shows that the same values of PSO parameters as in Section 
4.1 are also suitable here. For each instance, the best PD PD(Best )  is obtained from the five 
trials. The results for both Types A and B problems are presented in Table 4, which give the 
mean PDBest  (Best) and mean computation time (CT) in seconds for all the algorithms. The 
compared algorithms include GAŞU (Şerifoğlu and Ulusoy 2004), GAOE (Oğuz and Ercan 
2005), ACS (Yin and Lin 2006), and PSO (proposed PSO without local search). Because 
GAOE was originally tested on different benchmark problems, we recoded GAOE in Visual 
C++ and provided its results on the same benchmark problem.  
According to Table 4, we can observe that GAŞU is more efficient and effective than 
GAOE for small- and medium-size problems, taking into account of different computer 
environments. It is also observed that PSO outperforms all the other algorithms, even that 
ACS employs additional local search. It is worth mentioning that some ACS solution values 
are better than PSO for 5,10n = . In fact, these values must be incorrect because the solutions 
of PSO for these small-size problem instances have been verified to be optimal by total 
enumeration. 
 35
Table 5.  Performance of different algorithms without local search 
for large-size problems. 
 
 GAŞU GAOE PSO  
n k×  Best Avg Best Avg Best Avg CT 
Type-A Problems   
50×2 2.70 3.22 2.88 2.65 3.25 4.13 1.98 
50×5 2.29 2.75 2.14 2.75 1.89 2.36 3.96 
50×8 4.69 5.18 4.71 5.55 3.60 4.42 8.91 
50×10 3.65 4.38 3.65 4.66 2.91 3.59 10.52 
100×2 2.18 2.51 2.49 3.00 3.86 4.81 8.61 
100×5 3.96 4.21 4.32 4.96 4.53 5.02 19.53 
100×8 2.31 2.66 2.57 3.33 2.25 2.74 32.89 
100×10 1.61 1.89 1.75 2.63 1.50 1.89 50.92 
Type-B Problems   
50×2 6.56 7.38 6.84 7.78 7.65 8.94 3.15 
50×5 15.83 17.68 15.78 17.91 13.76 15.71 6.98 
50×8 22.38 24.87 23.76 25.69 20.40 22.28 10.79 
50×10 26.72 28.48 27.37 29.47 24.42 26.05 13.21 
100×2 7.50 8.01 7.99 9.17 12.16 13.60 14.01 
100×5 14.60 15.69 16.06 17.55 17.01 18.49 30.73 
100×8 19.60 20.98 21.67 23.16 20.89 22.76 48.45 
100×10 27.24 28.98 29.45 31.30 27.29 28.75 59.57 
 
recoded GAŞU and GAOE in C++ and allowed their numbers of iterations to increase so as to 
achieve the same computation time as PSO. It is observed that GAŞU is still better than GAOE. 
Also, we observe that PSO performs best for 50×5, 50×8, and 50×10 problems while GAŞU 
is the best for most 100-job problems. 
Finally, we compare all the algorithms with their own designed local search schemes, i.e., 
ACS, GAŞU-2opt and PSO. Some PSO parameters are fine tuned for the incorporation of local 
search as follows: 100,pN = 1 2 2,c c= = max1, 4,w V= =  ns 50,=  MaxIter 10 .n= ×  Also, 
the local search RVNS in PSO is applied to the best particle once for every 20 iterations, and 
it is implemented 7 n×  times within a search. The comparative results for both Types A and 
B problems are given in Table 6, which demonstrates that the PSO yields solutions of 
superior quality, as against the GAŞU-2opt and ACS solutions. In addition, the PSO requires 
much less computation time than the ACS. 
 
5.  Conclusions 
 
The main contribution of this research is to provide a powerful metaheuristic, a PSO 
algorithm, for the scheduling of multiprocessor tasks in a multistage hybrid flow-shop with 
makespan minimization. The results have demonstrated that the PSO algorithm outperforms 
all the other metaheuristic algorithms such as GA and ACS for the problem. Specifically, we  
 37
Bean, J.C., Genetics and random keys for sequencing and optimization. ORSA Journal on 
Computing, 1994, 6, 154-160. 
Błażewicz, J., Ecker, K.H., Pesch, E., Schmidt, G. and Weglarz, J., Scheduling Computer and 
Manufacturing Processes, 2nd Ed., 2001 (Springer-Verlag: Berlin). 
Chen, J. and Lee, C.Y., General multiprocessor task scheduling. Naval Research Logistics, 
1999, 46, 57-74. 
Drozdowski, M., Scheduling multiprocessor tasks- an overview. European Journal of 
Operational Research, 1996, 94, 215-230. 
Eberhart, R.C. and Kennedy, J., A new optimizer using particle swarm theory. in Proceedings 
of the Sixth International Symposium on Micromachine and Human Science, 1995, pp. 
39-43. 
Eberhart, R.C. and Shi, Y., Comparing inertia weights and constriction factors in particle 
swarm optimization. in Proceedings of Congress on Evolutionary Computing, 2000, pp. 
84-88. 
Guan, Y., Xiao, W.Q., Cheung, R.K. and Li, C.L., A multiprocessor task scheduling model 
for berth allocation: heuristic and worst-case analysis. Operations Research Letters, 
2002, 30, 343-350. 
Guinet, A., Solomon, M.M., Kedia, P.K. and Dussauchoy, A., A computational study of 
heuristics for two-stage flexible flowshop. International Journal of Production Research, 
1996, 34, 1399-1415. 
Gupta, J.N.D., Two stage, hybrid flowshop scheduling problem. Journal of the Operational 
Research Society, 1988, 39, 359-364. 
Gupta, J.N.D. and Tunc, E.A., Schedules for a two-stage hybrid flowshop with parallel 
machines at the second stage. International Journal of Production Research, 1991, 29, 
1489-1502. 
Hansen, P. and Mladenović, N., Variable neighborhood search for the p-Median. Location 
Science, 1997, 5, 207-226. 
Hansen, P. and Mladenović, N., Variable neighborhood search: principles and applications. 
European Journal of Operational Research, 2001, 130, 449-467. 
Haouari, H. and M’Hallah, R., Heuristic algorithms for the two-stage hybrid flowshop 
problem. Operations Research Letters, 1997, 21, 43-53. 
He, S., Wu, Q.H., Wen, J.Y., Saunders, J.R. and Paton, R.C., A particle swarm optimizer with 
passive congregation. BioSystems, 2004, 78, 135-147. 
Ho, S.L., Yang, S., Ni, G., Lo, E.W.C. and Wong, H.C., A particle swarm optimization-based 
method for multiobjective design optimizations. IEEE Transactions on Magnetics, 2005, 
41, 1756-1759. 
Kennedy, J. and Eberhart, R.C., Particle swarm optimization. in Proceedings of IEEE 
International Conference on Neural Networks, 1995, pp. 1942-1948. 
Kennedy, J. and Eberhart, R.C., A discrete binary version of the particle swarm algorithm. in 
Proceedings of the World Multiconference on Systemics, Cybernetics and Informatics, 
1997, pp. 4104-4109. 
Kennedy, J., Eberhart, R.C. and Shi, Y., Swarm Intelligence, 2001 (Morgan Kaufmann: CA). 
Krawczyk, H. and Kubale, M., An approximation algorithm for diagnostic test scheduling in 
multicomputer systems. IEEE Transaction on Computers, 1985, 34, 869-872. 
Lee, C.Y., Lei, L. and Pinedo, M., Current trends in deterministic scheduling. Annals of 
Operations Research, 1997, 70, 1-41. 
Liao, C.J., Tseng, C.T. and Luarn, P., A discrete version of particle swarm optimization for 
flowshop scheduling problems. Computers and Operations Research, 2007, 34, 
