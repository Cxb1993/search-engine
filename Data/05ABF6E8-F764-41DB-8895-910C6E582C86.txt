1 
INTRODUCTION AND LITERATURE REVIEW 
Digital images become more prevalent in biological research each year. As the ease of 
capturing digital images increases while the cost of storage decreases, the need of 
retrieving specific images from larger databases also increases. Accordingly, it is 
necessary to develop a generic system for semantic analysis and retrieval of relevant 
information for study and/or diagnosis. The system should be capable of interacting 
with the user in natural language and then translating into a number of precise 
instructions for the following computational tasks, such as semantic analysis and 
retrieval of biological or medical imagery. To support such system with the needed 
functionality, a semantic image database system should be able to extract out 
biological objects and distinguish abnormal objects. 
Although such system is designed to be as generic as possible, we apply the system to 
fundus images for its increasing importance. Instead, the typical approach is to use a 
battery of image measures Mi, where i = 1, 2, ... , n, and summarize a given image I by 
the vector of values M(I) = (M1(I), M2(I), ... , Mn(I)). These measures are likely to be 
variously sensitive to textural and/or chromatic image content. Searches through the 
image database can then be based on decision rules that get applied to the vectors 
M(I). This approach has the virtue that it is relatively easy to implement. One can 
adopt a number of image measures, and conduct fairly effective searches for images 
containing various sorts of textured and/or colored material. It should be emphasized, 
however, that such retrieval schemes do not require interpretation of image contents. 
Searches of this sort are thus essentially not semantic. They impose no requirement 
that the retrieval system recognize image components. 
Our aim is semantic analysis and retrieval of biological and/or medical images. 
Although semantic retrieval of arbitrary images is, in general, a very difficult problem 
(imagine, for example, asking a retrieval engine to pull up from a database all pictures 
containing any man-made item), specific domains of biological images may be 
sufficiently constrained in content that one might well hope to achieve semantic 
retrieval. However, even given the restricted semantic content of a domain of 
biological images, the task of semantically parsing an image from that domain 
remains challenging (though some domains are decidedly easier to attack than others). 
Therefore, it is of importance to parse or extract these biological objects from these 
biological and/or medical images with a mechanism for object annotation. To this 
point, each object associated with its attributes relevant to semantic analysis can be 
stored in an image database [24, 26, 10, 9]. 
Images must be annotated to support semantic content-based retrieval; however, the 
annotation task is a burdensome work for human. Therefore, it is of necessity to 
automatically annotate images with learning methods [12, 25, 2, 11] or using a 
coherent language model [13]. Usually, annotation of the concept-sensitive salient 
objects or annotating objects with various keywords at different semantic levels [6] is 
used for semantic image retrieval. Upon the completion of image annotation, the 
correction task can be done with automatic annotation weight estimation [18] or 
annotation conflict detection [14] to avoid ineligible annotations. 
Searching image data is one of the essential functions for image database systems. 
Pioneering work has been done by IBM's QBIC (Query By Image Content) system 
[15], which supports queries using color, shape, sketch, and texture features [17] on 
images, such as post stamps, art pictures, and trademark drawings [7]. The Chabot 
3 
METHODOLOGY 
As illustrated in Fig. 1, the framework of this proposed method consists of two 
important tasks, i.e. image analysis for microaneurysm extraction and annotation 
analysis for keyword grouping. Major steps in both tasks will be described in detail in 
the following section. In this research work, fundus photos and the associated 
annotations including ophthalmic diseases and syndromes are collected as the data set 
from an atlas of ophthalmology. Annotations are manually parsed into a number of 
meaningful terms that can be verbs, nouns, or adjectives. 
Manual Annotation 
Parsing
Occurrence Matrix 
Construction
Two-way Association 
Rule Mining
Group Association 
Relevance
Photos & Terms
Database
Photos & Terms 
Extraction
Appropriateness 
Calculation
Send 
Request
Retrieve 
Data
Retrieval by Ranking
Green Channel extraction & 
Gray-value Reversing
Contrast Enhancement & 
Image Smoothing
Vertical & horizontal Line 
Scanning for Peak Selection
Checking Diagonal Lines for 
Removing Unwanted Peaks
Local Polynomial Surface 
Fitting for Candidate Peaks
Feature Extraction
Peak Classification
Image
Analysis
Fundus Photos & 
Annotations
 
Fig. 1 System framework 
Image Analysis for Microaneurysm Extraction 
Contrast Enhancement 
Instead of using fluorescein angiographies, color fundus images are utilized due to the 
non-intrusive characteristic. As shown in Fig. 2, moreover, microaneurysms appear in 
the green channel [28] much clearer than the red and blue channels. 
 
(a) Red channel 
 
(b) Green channel 
 
(c) Blue channel 
Fig. 2 An example of microaneurysm 
Accordingly, the green channel is selected and reversed for contrast enhancement by 
employing Walter-Klein method [29, 30] defined as follows: 
5 
interested in utilizing the geometric characteristic of microaneurysms without 
suffering from the limitations of noise effect varied sizes of microaneurysms. Further 
observation reveals that grayscale distribution of a fundus image can be thought of as 
a landscape and a microaneurysm looks like a small hill after performing image 
complement. Under an assumption that white noise is uniformly distributed, the 
landscape more or less exhibits some shapes (or reliefs) representing major objects 
shown in the image. This important observation leads us to consider local polynomial 
surface fitting demonstrated in Fig. 4c as a way to locate objects in different shapes 
and sizes without worrying about the effect caused by white noise. 
 
  
(a) Complement image of a 
potential microaneurysm 
(b) Mesh of (a) (c) Mesh of (a) after surface 
fitting 
Fig. 4 A potential microaneurysm adjacent to blood vessel, where the complement 
image is for illustrative purpose only 
All candidate peaks that have been selected in previous step are then modeled by 
performing local polynomial surface fitting. Let ui, j be the gray value of pixels in a 
window, where i, j = 1 … w are the image coordinates and w is the window size. The 
estimated gray value vi, j(d) derived from polynomial surface fitting can be expressed 
in a general form as 
 ∑
=+
⋅⋅=
d
qp
qp
qpji jiadv
0
,, )(  (2) 
where d indicates the highest power or degree of the bivariate polynomial and ap, q are 
the coefficients to be solved. Suppose a quadratic form is selected, the estimated gray 
value becomes 
 0,01,00,1
2
2,01,1
2
0,2, )2( ajaiajajiaiav ji ++++⋅+=  
For a d-degree bivariate polynomial, there are nd = (d + 2) (d + 1) / 2 terms after 
expansion of (2). Let each pixel value be one observation and the window size be w, 
then w2 observations can form w2 equations to solve nd coefficients and w2 > nd. 
Redundant observations provide the chance to solve optimal solution by using least 
squares fitting. Thus, the energy function is defined as 
 [ ] ∑∑ ∑∑∑
= = =+= =
⋅⋅−=−=
w
i
w
j
d
qp
qp
qpji
w
i
w
j
jiji jiaudvu
1 1
2
0
,,
1 1
2
,, )()(ξ  (3) 
By taking partial derivatives of the energy function with respect to all unknown 
coefficients ap, q and letting them be equal to zero, fortunately, the mathematical 
derivation of linear least squares yields a general form expressed as (5). 
 0)()(2
1 1 0
,,
,
=⋅⋅⋅⋅−−=
∂
∂ ∑∑ ∑
= = =+
w
i
w
j
qp
d
nm
nm
nmji
qp
jijiau
a
ξ  (4) 
0
2
4
6
8
1
2
3
4
5
6
7
140
150
160
170
180
190
200
210
1
2
3
4
5
6
7
1
2
3
4
5
6
7
140
150
160
170
180
190
200
7 
of support and conference are still kept. Accordingly, each photo pu and its associated 
terms tv are thought of as a transaction and the items, respectively. Moreover, each 
term tv annotates some photos pu can be regarded in the same manner. By setting 
predefined support and confidence values, two sets of groups Gp and Gt defined as 
 
}1|{
}1|{
,
,
njgG
migG
jtt
ipp


==
==
 (9) 
are generated. It denotes that the ith group gp,i has some photos and is one member of 
the group set Gp consisting of m groups; and the jth group gt,j containing some terms 
belongs to the group set Gt having n groups. Note that a photo can appear in different 
groups gp,i; likewise, a term may exist in different groups gt,j as well. 
Group Association Relevance 
At the second stage of semantic retrieval, both group sets Gp and Gt are further 
utilized to form an m×n relevance matrix R, where element ri,j in matrix R shall 
indicate the relevance between a group of photos pu and a group of terms tv. That is to 
say, it is desired to retrieve some associated terms t, which are highly relevant to a 
group of photos p. To make it simple, suppose gp,i has np photos and gt,j has nt terms. 
The relevance ri,j is defined as 
 ∑
∈
∈×
=
jtv
ipu
gt
gp
vu
tp
ji onn
r
,
,
,,
1  (10) 
where ou,v are elements in the occurrence matrix O that has been defined in equation 
(8) previously. It is obvious that the relevance ri,j ∈ [0, 1]. In fact, the relevance 
matrix R can be rearranged in advance by sorting the ri,j values and indexing the order 
of all groups gp,i for each group gt,j to facilitate the subsequent retrieval. 
Retrieval by Ranking 
Traditional SQL query in database systems has been a powerful manner in data 
management for many decades. It is, however, not able to perform semantic retrieval 
of relevant information. In this work, semantic retrieval is carried out by seeking out 
the most appropriate group gt,α from Gt based on a set of user-provided word(s) 
defined as gu. An indicator called appropriateness αj is defined 
 
ujt
ujt
j gg
gg
∪
∩
=
,
,α  (4) 
where αj ∈ [0, 1]. The most appropriate group gt,α with αmax is selected, and its 
relevance values ri,α to all photo groups gp,i are calculated using Eq. 3. The most 
relevant photos and terms are retrieved finally by ranking the ri,α values. 
RESULTS AND DISCUSSION 
A framework for semantic retrieval of fundus photos as well as the associated relevant 
terms is presented. A two-way association rule mining is employed to generate two 
sets of item groups for fundus photos and terms, respectively. To build up the 
relationship of group association relevance among the sets of photos and terms, an 
indicator called relevance is introduced. Appropriateness is a simple yet effective 
indicator to help identify the most appropriate group of terms. 
The current work emphasizes on the process of using image annotations to 
semantically retrieve relevant photos and terms. Automatic parsing of annotations can 
9 
15. Niblack CW, Barber R, Equitz W, Flickner MD, Glasman EH, Petkovic D, 
Yanker P, Faloutsos C, and Taubin G, QBIC project: querying images by 
content, using color, texture, and shape, SPIE Storage and Retrieval for Image 
and Video Databases, 1908, 1993, pp. 173-187. 
16. Ogle VE and Stonebraker M, Chabot: Retrieval from a relational database of 
images, IEEE Computer, 28(9), 1995, pp. 40-48. 
17. Pala P and Santini S, Image retrieval by shape and texture, Pattern Recognition, 
32(3), 1999, pp.517-527. 
18. Qi X and Han Y, Incorporating multiple SVMs for automatic image annotation, 
Pattern Recognition, 40(2), 2007, pp.728-741. 
19. Sun JY, Sun Z, Zhou RH, and Wang HF, A semantic-based image retrieval 
system: VisEngine, International Conference on Machine Learning and 
Cybernetics, 2002, pp.349-353. 
20. Tam AM and Leung CHC, Structured natural-language descriptions for semantic 
content retrieval of visual materials, Journal of the American Society for 
Information Science and Technology, 52(11), 2001, pp.930-937. 
21. Tang HL, Hanka R, and Ip HHS, Histological image retrieval based on semantic 
content analysis, IEEE Transactions on Information Technology in Biomedicine, 
7(1), 2003, pp.26-36. 
22. Tsai CF, McGarry K, and Tait J, Using neuro-fuzzy techniques based on a two-
stage mapping model for concept-based image database indexing, The 5th IEEE 
International Symposium on Multimedia Software Engineering, 2003, pp. 6-12. 
23. Wang JZ, Li J, and Wiederhold G, SIMPLIcity: Semantics-sensitive integrated 
matching for picture libraries, IEEE Transactions on Pattern Analysis and 
Machine Intelligence, 23(9), 2001, pp. 947-963. 
24. Wang L, Khan L, Liu L, and Wu W, Automatic image annotation and retrieval 
using weighted feature selection, The 6th IEEE International Symposium on 
Multimedia Software Engineering, 2004, pp. 435-442. 
25. Yao J, Antani S, Long R, Thoma G, and Zhang Z, Automatic medical image 
annotation and retrieval using SECC, The 19th IEEE Symposium on Computer-
Based Medical Systems, 2006, pp. 820-825. 
26. Yu F and Ip HHS, Spatial-HMM: A new approach for semantic annotation of 
histological images, The 18th International Conference on Pattern Recognition, 
2006, pp. 663-666. 
27. Zhang R, Zhang Z, and Qin Z, Semantic repository modeling in image database, 
IEEE International Conference on Multimedia and Expo, 3, 2004, pp. 2079- 
2082. 
28. Walter T, Massin P, Erginay A, Ordonez R, Jeulin C, and Klein JC, Automatic 
detection of microaneurysms in color fundus images, Medical Image Analysis, 
11(6), 2007, pp. 555-566. 
29. Walter T and Klein JC, Automatic detection of microaneyrysms in color fundus 
images of the human retina by means of the bounding box closing, Lecture Notes 
in Computer Science, 2526, 2002, pp. 210-220. 
30. Antal B and Hajdu A, Improving microaneurysm detection using an optimally 
selected subset of candidate extractors and preprocessing methods, Pattern 
Recognition, 45(1), 2012, pp. 264-270. 
31. Zhang B, Wu X, You J, Li Q, and Karray F, Detection of microaneurysms using 
multi-scale correlation coefficients, Pattern Recognition, 43(6), 2010, pp. 2237-
國科會補助計畫衍生研發成果推廣資料表
日期:2012/01/31
國科會補助計畫
計畫名稱: 研發語意生醫影像分析服務技術
計畫主持人: 蕭震緯
計畫編號: 99-2221-E-468-021- 學門領域: 生物資訊
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本研究計畫之部分工作與美國加州大學爾灣分校之電機系教授合作，成果已發
表於 IEEE 國際研討會。 
Wei‐iang Tai, Rouh‐ei Hu, Han C.W. Hsiao, Rong‐ing Chen, and Jeffrey J. 
P. Tsai, Blood Cell Image Classification Based on Hierarchical SVM, 2011 
IEEE International Symposium on Multimedia, Dana Point, California, USA, 
December 5-7, 2011, CD-ROM. 
Han C.W. Hsiao, Rouh-Mei Hu, Wei-Liang Tai*, Rong-Ming Chen, Jeffrey J.P. 
Tsai, Object Relational Programming of Biomedical Images, The 11th IEEE 
International Conference on Bioinformatics and Bioengineering, 
Taichung, Taiwan, October 24-26, 2011, pp. 52-57. 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
