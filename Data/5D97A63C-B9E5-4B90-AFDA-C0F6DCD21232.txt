 2
1. 摘要 
本計畫第一年報告提出一個創新的
Content-based 影像驗證架構，該架構利用小波
轉換嵌入半易碎之影像特徵至 Host Image。架
構中，由 target image 的低頻率域取出下列兩
個特徵來產生兩浮水印：(1) Zernike 
moments ： 用來對影像內容的蓄意修改做分
類。(2) Sobel edge：用來標示出被修改的區
域。值得一提的是我們設計出一個系統式的方
法來自動排序選擇 Zernike moments，另外為了
分辨出影像的處理是否為惡意，我們也提出於
重建的過程中採用 weighted Euclidean 
Distance。 
 我們設計架構的優點是可容忍一定程度的
壓縮跟雜訊，同時排除一些常見的影像修改如
旋轉。實驗結果顯現該架構可指出惡意竄改區
域，其偵測區域約 8x8 區塊。同時對於內容保
護的處理也展示高度強韌性，如 JPEG 壓縮
(Q>=30)及高斯雜訊(variance<=20)。 
 
ABSTRACT 
 
This first year report of the project  present a 
novel content-based image authentication 
framework which embeds the semi-fragile image 
feature into the host image based on wavelet 
transform. In this framework, two features of a 
target image from the low frequency domain to 
generate two watermarks: Zernike moments for 
classifying of the intentional content modification 
and sobel edge for indicating the modified location. 
In particular, we design a systematic method for 
automatic order selection of Zernike moments and 
in order to tell if the procession on the image is 
malicious or not, we also propose a weighted 
Euclidean distance by its reconstruction process. 
An important advantage of our approach is that it 
can tolerate compression and noise to a certain 
extent while rejecting common tampering to the 
image like rotation. Experimental results show that 
the framework can locate the malicious tamper 
locally, the unit of detection region is 8x8 block, 
while highly robust to content preserved 
processing, such as JPEG compression Q>=30 and 
Gaussian noise variance<=20.  
 
Key words:  
Authentication; Semi-fragile watermarking; Image 
features; Wavelet transform; content based 
watermark 
 
2. INTRODUCTION 
 
With the rapid progress of multimedia 
technologies, any people can perfectly modify 
digital image using widely available editing 
software. The authentication of digital image 
content is necessary in real world. However, the 
authentication of images and multimedia content 
in general differs from the traditional problems of 
authentication in cryptography. The traditional 
encryption method has some disadvantages in the 
protection of multimedia, because it has high 
redundancy and huge data.  
Digital watermarking is one approach by 
adding signal to digital content to ensure the 
authenticity, and it has become a very active 
research field and been widely accepted as a 
promising technique for multimedia security.  
According to embedding purposes, 
watermarks can have two types: robust and fragile 
watermarks. Robust watermarks are designed to 
withstand arbitrarily malicious attacks, such as 
image scaling bending, cropping, and lossy 
compression. They are usually used for copyright 
protection to declare the rightful ownership. On 
the contrary, for the purpose of image 
authentication, fragile watermarks are adopted and 
designed to detect any unauthorized modification. 
It is very sensitive and is designed to detect every 
possible change in a marked image. But in most 
multimedia applications, minor data modifications 
are acceptable as long as the content is authentic, 
so the semi-fragile watermark is developed and 
used in content authentication. Semi-fragile 
watermarking has the character of both robust and 
fragile watermarking, it can tolerate some normal 
signal processing such as JPEG compression, filter 
etc, at the same time it can inspect whether 
original image is tampered and where the image is 
tampered. Because of above, semi-fragile 
watermarking emerges as a widely accepted 
approach in information cryptic technology. In this 
paper, we focus on semi-fragile watermarks and 
develop a digital image authentication procedure 
that allows for the detection of malicious 
tampering while staying robust to incidental 
distortion introduced by compression, noise, etc. 
A typical approach of semi-fragile 
watermarking based authentication is shown in 
Fig.1. 
Step 1: The image feature is extracted from 
original image. 
Step 2: Quantized the image feature. 
Step 3: The quantized feature is embedded as 
message into the image.  
During authenticity verification, the message 
is detected using the watermarking detector, and 
the image feature is extracted from the 
 4
have the property of orthogonality and the features 
have some degree of redundancy. 
For a two-dimensional density 
function ( , )p x y , the ( )thp q+ order geometrical 
moments pqm are defined as: 
( , )p qpqM x y p x y dxdy
∞ ∞
−∞ −∞
= ∫ ∫     
If an image is considered as a discrete function 
( , )p x y  with 0,1,...x M= and 0,1,...y N= , then 
0 0
( , )
M N
p q
pq
x y
M x y f x y
= =
= ∑ ∑     
However, it should be noted that it can 
assume very large values, especially for high order 
moments. This often leads to numerical 
instabilities as well as high sensitivity to noise. 
Furthermore, image reconstruction is not 
straightforward, due to the fact that geometric 
moments are not of orthogonal basis (Cartesian 
monomial function). 
 
b. Complex Moments (CM) 
Complex moments are defined similarly to 
geometric. If an image is considered as a discrete 
function ( , )p x y  with 0,1,...x M=  
and 0,1,...y N= , then 
0 0
( ) ( ) ( , )
M N
p q
pq
x y
m x yi x yi f x y
= =
= + −∑∑  
These moments provide rotation invariance, but 
still are not of orthogonal basis, and present the 
same drawbacks with geometric moments. 
 
c. Legendre Moments (LM) 
The Legendre moments of order ( )m n+  are 
defined as 
(2 1)(2 1) ( ) ( ) ( , )
4mn m n
m n P x P x p x y dxdyλ ∞ ∞
−∞ −∞
+ +
= ⋅ ∫ ∫
,  
Where , 0,1,2,...,m n = ∞ .  
The Legendre polynomials { }( )mP x [7] are a 
complete orthogonal basis set on the interval [-1, 
1]. 
The nth-order Legendre polynomial is 
2
0
1( ) ( 1)
2 !
nn
j n
n nj n n
j
dP x a x x
n dx
=
= = −∑  
By the orthogonal principle, the image function 
( , )p x y  can be written as an infinite series 
expansion in terms of the Legendre polynomials 
over the square [ 1 , 1]x y− ≤ ≤  
0 0
( , ) ( ) ( )mn m n
m n
p x y P x P yλ
∞ ∞
= =
= ∑∑  
where the Legendre moments { }mnλ  are 
computed over the same square. If only Legendre 
moments of order N≤  are given, then the 
function ( , )p x y  can be approximated by a 
continuous function which is a truncated series: 
,
0 0
( , ) ( ) ( )
N M
m n n m n n
m n
p x y P x P yλ
− −
= =
≈ ∑ ∑  
The Legendre moments and geometric moments 
are related by 
0 0
(2 1)(2 1)
4
m n
m n m j nk jk
j k
m n
a a Mλ
= =
+ +
= ∑ ∑  
Thus, a given Legendre moment depends only on 
geometric moments of the same order and lower, 
and conversely. 
is the angle between the vector ρ  and x axis in 
counterclockwise direction; ( )nmR ρ  is Radial 
polynomial defined as: 
( | |) / 2
2
0
( )!( ) ( 1) | | | |!( )!( )!
2 2
n m
s n s
nm
s
n sR
n m n m
s s s
ρ ρ
−
−
=
−
= −
+ −
− −
∑
 
The Zernike moment of order n with 
repetition m for function ( , )p x y  is defined as: 
2 2
*
1
1 ( , ) ( , )nm nm
x y
nA p x y V x y dxdy
pi + ≤
+
= ∫∫ ,  
where 
,
( , ) ( , )nm n mV x y V x y∗ −=  
To compute the Zernike moment of a digital 
image, we just need to change the integrals with 
summations: 
2 21 ( , ) ( , ), 1nm nm
x y
nA p x y V x y x y
pi
∗+
= + ≤∑∑  
Suppose we know all Zernike moments 
nmA of 
( , )p x y  up to order N  , we can reconstruct the 
image by: 
0
( , ) ( , )
N
nm nm
n m
p x y A V x y
=
′ = ∑ ∑  
As discussed above, Geometric moments 
present a low computational cost, but are highly 
sensitive to noise. Furthermore reconstruction is 
extremely difficult. Complex moments provide 
with additional invariant descriptors, but present 
the same problems regarding noise and 
reconstruction. Moments of orthogonal 
polynomial basis were proposed such as Legendre 
and Zernike. They have proven less sensitive to 
noise, are natively invariant to linear 
transformations and can be effectively used for 
 6
As aforementioned, we show that Zernike 
moments can be taken as image features, a main 
question to be answered is; how big order should 
be? In other words, up to what order moments are 
needed for a good robustness of some common 
image processing. In fact, a major drawback of 
many previously developed feature sets for image 
representation is the lack of a systematic method 
for automatic selection of this number.  
A good set of features is one that can 
characterize and represent the image well. The 
difference between an image and its reconstructed 
version from a finite set of its  
moments is a good measure of the image 
representation ability of the considered set of 
moments. The ease of image reconstruction from 
Zernike moments makes it practical to base the 
feature selection process on such a measure. The 
idea is that n, the maximum needed order, is one 
which can generate a reconstructed image which is 
similar to the original in the sense of a defined 
threshold. 
Let jI denote the image reconstructed by 
using Zernike moments of order 0 through j 
extracted from the original image I , and the 
Euclidean distance between the two 
images ( , )jE I I is employed to quantify this 
difference, that is a simple measure of image 
representation ability between jI and the original 
image I .If ( , )jE I I  is small enough, then it can 
be concluded that enough information is extracted 
and no additional order of moments needs to be 
computed, i.e., order=j. Here we can use a 
threshold α to facilitate our judgment. Obviously, 
the smaller the α is, the higher the needed order is. 
Based on different application, by presetting the α, 
the proposed scheme can embed ZMMs of various 
orders. When a high level of robustness is 
specified, we should need a smaller α that it will 
embed more watermark bits, meanwhile, it also 
may affect the quality of watermarked image 
degrade. In other words, with a larger α, fewer 
watermark bits will be embedded, so a higher 
fidelity of the watermarked image will be achieved. 
But this will decrease the performance of 
semi-fragile feature, because of less image 
information embedded. 
The above procedure not only decides the 
highest order needed, but also provides a way to 
treat features each order differently. Furthermore, 
we hope to understand how important the ZMMs 
of different orders are on our semi-fragile 
watermark scheme. We can get the important 
degree of ZMMs by calculating its contribution 
and use it to weight the corresponding features. 
The contribution of jth order moments to the 
reconstruction process can be measured by 
computing how much closer jI  is to 
original I compared to 1jI − .The contribution of 
the jth order moments denoted by ( )D j , is 
computed as 
1( ) ( , ) ( , )j jD j E I I E I I−= − . 
 
A large positive value of ( )D j indicates that 
the jth order moments do capture a lot of 
important information about the shape. On the 
other hand, a small positive or a negative ( )D j is 
an indication that the corresponding moments 
focus on unimportant aspects of the image under 
study. Consequently, it distinctly can weight the 
important degree of ZMMs of various orders. 
Thus, we can introduce a weighting mechanism 
based on their corresponding ( )D j s′ , Euclidean 
distance is again employed to carry out this task, 
that is, after the related order ZMMs have been 
extracted, we will multiply different weights to 
these order ZMMs to compute weight Euclidean 
distance during authentication stage. Finally, we 
obtain the distance as a judge factor to determine 
whether the image was suffered by malicious 
attack. 
The weight of order j is defined as: 
( ) (min)
(max) (min)j
D j D
w
D D
−
=
−
, 1, 2,...,j order=  
(max)D : The maximal D(j) 
(min)D : The minimal D(j) 
 
The formula will change the Wj into range of 
[0, 1] first, and utilize the value as order weight to 
compute the weighted Euclidean distance. Note 
that if ( )D j is negative, jw is not set to zero, and 
the weight of the zeroth order and first order 
moments are set to 0.5 since there is no previous 
image for comparison. These above processes will 
enhance the precision of the formula because it 
doesn’t omit any available information. And we 
get the weighted Euclidean distance shown below:  
2
, ,
0
( , ) ( )
order
w order m m n m n
m
E I I w Z M M Z M M
=
= −∑
    
Table 3 shows some statistics including 
corresponding ( , )jE I I
)
, ( )D j , and jw for 
reconstructed images in Fig.2 when threshold 
 8
The quantization-based watermarking 
approach divides a real number axis in the wavelet 
domain into intervals with equal size at each scale 
and assigns watermark symbols to each interval 
periodically. As shown in Fig.3, assuming that x is 
a wavelet coefficient, and Q is the size of a 
quantization interval, the watermark symbol, 
which is either 0 or 1, is determined by a 
quantization function Quan(x, Q), where 
( , )
0     Q ( 1)Q    0 , 2 , 4  , ...
1     Q  ( 1)Q    1 , 3  , 5  , ...{x Q if t x t fo r tif t x t fo r tQ u an ≤ < + = ± ±≤ < + = ± ± ±=
 
 
Let w denote the target watermark value that 
is to be encoded for a wavelet coefficient x. The 
watermark bit w is embedded by modifying the 
wavelet coefficient x so that Quan(x, Q) is equal to 
w. So, the coefficient is modified to the nearest 0 
bin (the double arrowhead) or 1 bin (the single 
arrowhead) according to w, and the bins of 1 and 0 
locate in the middle of the quantization step Q. 
Specifically, the wavelet coefficient x is updated 
to x* by 
 











≠+−⋅












+
=++⋅












+
=
w
Q
xQuanifQQQ
Q
x
w
Q
xQuanifQQQ
Q
x
x
)
2
(
2
)
2
(
)
2
(   
2
)
2
(
*
　　　
　　
 
where ⋅    is the floor operator and x
* is the 
expected updated wavelet coefficient. 
When all watermark bits of ZMMs and WE 
are separately embedded into HL2, LH2 subbands 
by quantization-based method, IDWT using 
updated wavelet coefficients is employed to 
produce the watermarked image, and Fig.4 shows 
an overview of our watermarking process. 
 
3.5 Watermark retrieval  
The framework of the watermark retrieval 
process is almost the same as that of the 
watermark embedding process, except that the 
order and weight of ZMMs decision is discarded. 
The selected order and corresponding weight of 
Zernike moments, threshold, and the quantization 
step Q are conveyed to the watermark detector as 
side information. First, take a three-level wavelet 
decomposition on M N×  watermarked 
image I ′ .Next, the coefficients in the two 
subbands HL, LH of the 2th level are ready to be 
extracted as ZMMs watermark and sobel edge 
watermark. The quantization process of all the 
wavelet coefficients in HL2 and LH2 is 
recalculated and the watermark bit is extracted by 
*( , )w Quan x Q′ = .  
 
3.6 Authenticity verification & Localization 
capability 
To authenticate the received image, the 
extracted watermarks MW ′ and EW ′  are compared 
with the generated image features MW  and EW , 
respectively. If all the extracted image features 
match the original ones, the image is claimed 
authentic, otherwise it may be tampered. An 
authentication decision is made after the weighted 
Euclidean distance comparison by moment feature 
with a received threshold, and the purpose of the 
edge feature comparison is help us localize the 
tampered areas.  
In order to achieve the capability of 
localizing tampered regions, many existing 
watermarking schemes embed the watermark in a 
block-based way. The image is divided into blocks 
and the watermark information is embedded into 
every block. The block content authentication is 
done by verifying whether the watermark can be 
successfully extracted from the block. In our 
block-based methods, the content of the image is 
monitored by the edge feature embedded in the 
wavelet domain. Following, thanks to the 
spatial-frequency localization of the wavelet 
transform, every position is verified by the edge 
watermark bit embedded in the corresponding 
wavelet coefficient. So, we will achieve the 
capability of localizing tampered regions. 
The authentication matrix DE is defined to 
estimate the difference between EW ′ and EW  
by
E E ED W W′= ⊕ . However, the image edge 
feature is not robust that we considered, it 
probably makes the isolated verified coefficients 
are still randomly distributed over the 
authentication matrix like random noises. Based 
on the fact that the tampering commonly occurs in 
a continuous area of the image in the practical 
applications, only the region with the high density 
of the unverified coefficients should be the actual 
manipulation. In consequence, we define those 
isolated unverified coefficients as noise dots. 
Other continuous unverified coefficients, which 
are mapped back to adjacent positions, are 
identified as the actually tampered ones. A visual 
illustration of the authentication process is given 
in Figure 5. 
 
5. EXPERIMENTAL RESULTS 
 
 10 
[9] A. Khotanzad, “Invariant Image Recognition 
by Zernike Moments,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, Vol. 12, 
No.5, May. 1990. 
[10] C. W. Chong, P. Raveendran and R. 
Mukundan, “Translation Invariants Of Zernike 
Moments,” Pattern Recognition, Vol. 36, 
pp.1765-1773, 2003. 
[11] H. Liu, J. Lin and J. Huang, “Image 
Authentication Using Content Based Watermark,” 
IEEE International Symposium on Circuits and 
Systems, Vol. 4, pp.4014-4017, May. 2005. 
[12] Y. P. HU and D. Z. HAN, “Using two 
semi-fragile watermark for image authentication,” 
Proc. of Machine Learning and Cybernetics 
International Conference, 2005 
 
Fig.1. Typical content based image authentication 
 
 
 
 
 
 
 
 
 
 
Fig.2.The reconstructed image of letter D. From 
top left to right, reconstructed image with up to 
third order moment through to twelfth order 
moment 
 
 
 
Fig.3. Quantization process. 
 
 
 
Fig.4. Overview of the watermark embedding 
process. 
 
Fig.5. Overview of the authentication process. 
 
Fig.6. Image quality with different quantization 
step. 
 
 12 
 
 
Table3. Euclidean distance and its corresponding 
weight for reconstructed images shown in 
Fig.2. 
 
 
Table4. List of zernike moments and their 
corresponding number of features from 
order zero to order eleven. 
 
 
Table5. The semi-fragile characteristics of ZMMs 
of LL3 subband. 
 
Table 6. Order information and its corresponding 
weights for Lena256x256. 
 
8. 計畫成果自評部份: 研究內容與原
計畫相符，達成預期目標應該適合在學
術期刊或會議發表。 
 
 14 
 
 
摘要 
本計畫第二年報告提出基於資料隱藏及適性區塊的高效
能數位影像錯誤修復法。由於網際網路的興起，資料隱
藏在多媒體變得十 分重要。數位影像之認證及錯誤隱藏
在軍事、遠距醫療、數位監控獲得廣泛注意。本報告提
出兩個方法用來影像之認證及錯誤位置偵測。第一個方
法為一個高效率之資料隱藏技術，可用於錯誤位置偵測
及回復被竄改之影像。第二個方法為利用平均移動分割
方法用為影像之認證及錯誤位置偵測。實驗結果亦顯示
所提出方法可行性。 
Abstract 
The second year report of the project proposes high efficient 
adaptive block based error concealment for digital images 
with data hiding. In this report, we proposed two methods 
for image authentication and tampered area location. The 
first method proposes a high efficient adaptive block based 
error concealment with data hiding. The second method 
proposes an image authentication system uses mean shift 
segmentation analysis and pixels’ mean value as 
authentication feature. The experimental results show the 
feasibility of the applications in image authentication and 
error recovery. 
 
1. INTRODUCTION 
                                                                                                                             
With the progress of network technology, people can 
transmit files through internet by using wireless or wired 
network. However, the convenience brings some security 
issue. How can we make sure that the transmitted file is not 
malicious tempered during the transmission? For example, 
as the transmission is used in military or medical usage, we 
have to make sure the correctness of image. In addition, if 
the bandwidth of network is very low, we also have to 
compress the image for transmission. Then image 
authentication becomes more and more important. It is also 
very important to make sure the authentication scheme will 
not be affected by image compression. 
Image authentication is a very popular research field since 
the security issue became more important than before. There 
are two kinds of method used to indicate the tempered pixels 
in a malicious tempered image. One is block based and the 
other is pixel based. Generally speaking, pixel based 
algorithms provide better accuracy to indicate tempered 
region, but it distorts the image too much and looses image 
quality. Recently, most the proposed methods are 
concentrated on block based scheme like [1] and [2].   
There are features could be used to do image analysis and 
authentication. Like transform feature, the low frequency 
part of an image in the frequency domain is representative. 
People transformed imaged from spatial domain to 
frequency domain and extract the low frequency coefficients 
as authentication features. Like [3], the coefficients in 
frequency domain after wavelet transform is extracted as 
authentication feature. The other authentication feature uses 
variance of each block as digital signature in [4]. 
To do image authentication, we have to embed the 
authentication features into the image as watermarks. The 
watermark could be embedded in two domains. These two 
domains are spatial domain and frequency domain. 
Embedding watermark in spatial domain usually changes 
the pixel value [8] and maintains good visual quality but has 
low robustness. Embedding watermark in frequency domain 
modifies the coefficients after discrete cosine transform 
(DCT) or discrete wavelet transform (DWT). It might affect 
the image quality but it could withstand image compression. 
In our proposed method we chose the second one to make 
our watermark can withstand image compression.  
In this report, we proposed two methods for image 
authentication and tampered area location. The first method  
proposes a high efficient adaptive block based error 
concealment with data hiding. The information of recovery 
for each block is embedded to other blocks adaptively by its 
content.  Each block is classified to be an interblock or an 
intrablock according to the sum of absolute values of the AC 
DCT coefficients of the block. If it is an interblock it takes 
advantage the redundant information for its adjacent blocks 
and its bit rate for recovery is determined to be small. If it is 
an intrablock it is further classified to be in one of three 
groups. A block recovery bit rate assignment algorithm is 
used to assign the block of each group the bit rate it needs 
for recovery according to the complexity of the block. The 
simulation shows the effectiveness of the proposed error 
concealment method to recovery the image in good quality 
when certain blocks are not available. The second method 
proposes an image authentication system uses mean shift 
segmentation analysis and pixels’ mean value as 
authentication feature. To embed these features as 
watermark, we modified AC coefficients and used pairs of 
coefficients to embed watermark bit. For localization we 
split image into blocks to indicate the tempered image 
blocks. 
2. REVIEWS OF THE PREVIOUS WORK 
 
Many previous works have been done and make 
contribution in many different ways. In [9], Lin, Sow and 
Chang show a great combination between fine fidelity 
concealment ability and strong robustness against JPEG 
compression with pre-quantizer. Wang[10] proposed a 
technique for Image authentication with localization and 
recovery using adjacent block. He uses a H.264/AVC-like 
framework to eliminate redundancy information between 
adjacent blocks and minimize the watermark length 
impressively.  
Figure 1 is the simplified flow-chart of Wang’s 
algorithm. Right neighbor block or down neighbor block 
would be chosen for the construction of reference block, and 
the column of pixel in the chosen neighbor block which is 
 16 
non-overlapping blocks Bij, (0 < i ≤ M/8, 0 < j ≤ N/8). Each 
block Bij has a reference block Rij, which is constructed 
using the right and down neighbor blocks RNij and DNij as 
shown in Figure 3. It is a mechanism of the two-way 
reference block to  solve error propagation  problem.  
By expanding the adjacent pixels the block Bij into two 8×8 
blocks RNE and DNE the reference block Rij is the average 
of RNE and DNE. The Residual block Sij is the difference 
between Bij and Rij. We transform Sij into the frequency 
domain using DCT. ( )ijij SDCTS ='
 
and compute  Cij, where  
( )
64
,
8
1
8
1
' 





= ∑∑
= =u v
ijij vuSC
 
If Cij is less than a threshold τ, S’ij will be coded for 
inter-block-recovery; otherwise B’ij = DCT(Bij) is coded for 
intra-block-recovery. 
Also, indexing all AC coefficients in B’ij with 1 to 63 in 
zigzag order, then we classify the block Bij into four groups 
according the following: 
 
τ<∈ ijij CifGB ,1
 
( ) ( ) 7.0,,2 63
1
'
21
1
' >≥∈ ∑∑
== i
ij
i
ijijij iBiBCifGB τ
 
( ) ( ) 8.0,,3 63
1
'
42
1
' >≥∈ ∑∑
== i
ij
i
ijijij iBiBCifGB τ
 
otherwiseGBij ,4∈
 
 
According to the above classification, G4 is the set of 
blocks that is most complex and G2 is the simplest. Suppose 
that C is the total bit rate that will be embedded in the image 
to recover the image. The average bit allocated for a single 
block would be Cs = C/Nb, Nb = (M×N)/16. Since G1 can 
be recovered by using the information of adjacent blocks it 
required small bit rate for recovery. For simplicity, we set 
the bite rate required to recover the block in G1 is 0.5Cs. 
That is, we can construct an initial capacity distribution map 
as 
 
( )
( ) otherwiseCsjiCDMap
GBCsjiCDMap ij
,0.1,
1,5.0,
=
∈∀=
 
 
The remaining capacity 0.5Cs for each block in G1 can 
be used for the recovery for other blocks not in G1. The 
total remaining capacity from G1 is computed as  
 
1,5.0 11 GblocksofnumbertheisnCsnIEC ∈×=
 
 
Then, IEC will be distributed to blocks in G1, G3 and 
G4. According to our simulation, the following pseudo code 
shows an optimal adaptive block recovery bit rate 
assignment 
The capacity distribution is according to the priority 
order list of G4, G4, G3, G4, G1, and G1 as shown in Figure 
4. The maximum capacity for G4, G3 and G1 is 2.50Cs, 
1.5Cs and 1.0Cs, respectively. Also, the capacity for the 
block in G2 is 1.0 Cs. 
 
2-2. Data generation and mapping block locating 
Watermark coding stage is composed of two separate coding 
phases, authentication bits coding phase and recovery bits 
coding phase. 
As the essential design issue of watermark-based error 
concealment framework, recovery bits of block Bij might be 
hided in one or several other blocks. On the other hand, 
authentication bits of the block Bij would be embedded in 
the block itself to guarantee that chain authentication 
problem is not going to happen. 
For every block Bij, six most significant bits of DC 
coefficients in B’ij is going to form DCij in order to represent 
the average color tone of the block. First six AC coefficients 
are divided into three pairs; each pair holds a relationship 
about their absolute value that can be coded in one bit 
according to the equation below. By combining three 
relations, 3 bits of ACij are formed to indicate the low 
frequency texture of the block. 
 
If |AC1| ≥ |AC2|,  ACij (1) = 0, else ACij (1) = 1 
If |AC3| ≥ |AC4|,  ACij (2) = 0, else ACij (2) = 1 
If |AC5| ≥ |AC6|,  ACij (3) = 0, else ACij (3) = 1 
 
Authentication bits Aij for the block Bij, would be the 
concatenation of DCij and ACij with the length 6 + 3 = 9 bits. 
Bit rate embedding map (CDMap) indicates the bit rate 
required of a block for recovery. For this reason, a prefix 
code has to be made to specify the bit rate assigned to 
blocks. Moreover, one block can hold only 1.0Cs and some 
sophisticated blocks like G3 or G4 blocks need more than 
1.0Cs, implying that single pre-assigned mapping block is 
not enough to embed the bit rate required for the recovery of 
a block and therefore, extra blocks are necessary for 
embedding. 
 
 Mapping block and extra block locating 
The mapping block MBij of Bij shown in Figure 4is located 
by the equation below: 
( )
( ) 8/1,8/mod
8/mod16/
'
'
NKNKij
MMii
≤≤+=
+=
 
Equation of i’ ensure that there is enough distance between 
Bij and its mapping block MBij to avoid losing both of these 
blocks at the same time. K is a secret key that protect the 
mapping function from attackers. 
Figure 4 illustrates an example of extra block EBij 
allocation of a block Bij of G3 or G4. All mapping blocks of 
 18 
11 12 13 16 23 20 15 15 
16 15 16 23 20 15 15 15 
23 20 23 20 15 15 15 15 
25 23 20 15 15 15 15 15 
25 23 15 15 15 15 15 15 
23 15 15 15 15 15 15 15 
Qc 
20 16 25 39 50 46 62 68 
16 18 23 38 38 53 65 68 
25 23 31 38 53 65 68 68 
39 38 38 53 65 68 68 68 
50 38 53 65 68 68 68 68 
46 53 65 68 68 68 68 68 
62 65 68 68 68 68 68 68 
68 68 68 68 68 68 68 68 
Qs 
Table.1 Customized quantization table Qc and JPEG 
standard quantization table Qs 
 
Quantized coefficients Qij are going to be grouped 
according to the outcome of mapping block and extra block 
locating phase and each address has a corresponding amount 
of capacity. A block Bij that requested 2.5Cs coefficients in 
adaptive block recovery bit rate assignment phase could 
have structure in Table.2: 
 
Bij MBij EBij1 EBij2 EBij3 EBij4 
Capacity 1.0Cs 0.5Cs 0.25Cs 0.25Cs 0.5Cs 
 
Table.2 Example of coefficients grouping of a block that 
requires 2.5Cs coefficients 
 
Hence, first 2.5Cs coefficients of Qij start from low 
frequency part will be divided into five groups based on the 
structure and capacity list in Table.3. Send every group of 
coefficients to Huffman encoder and bind output of every 
coefficient within a group with each other to form a 
watermark fragment Wijk for group k of block Bij. k will be 1 
for all G1 and G2 blocks. 
 
 Data integration 
After preprocessing, all data fragments are set. Fig.5~7 
illustrates three possible data structure. The confirmation of 
structure type at decoder end will be determined by the 
value of extracted Pij. IWij is used for symbolizing the 
completely integrated embedding data of Bij.  
Figure 4 shows that for every block Bij, a complete data 
embedded in MBij when Bij is a G1 block. 9 bits AMBij stands 
for the authentication information for MBij, 3 bits Pij 
demonstrates seven different bit rate using status in MBij, 
Wijk is the partial recovery information of Bij, and Wuvk is the 
recovery information fragment k of a G3 or G4 block Buv 
because Buv allocated MBij as one of its extra block. Finally, 
EBuvk+1 stands for the extra block address which leads Buv to 
its next extra block. 
Figure 5 shows the structure of the complete data 
embedded in MBij for a Bij block of G2. Figure 6 shows the 
structure of the complete data embedded in MBij and extra 
blocks EBijk for a G3 or G4 block Bij 
 
 
Fig.5 structure of data embedded in the block MBij for a 
block Bij of G1 
 
 
Fig.6 structure of data embedded in mapping block MBij for 
G2 block Bij 
 
 
Fig.7 structure of data embedded in mapping block MBij for 
G3 or G4 block Bij 
 
2-3. Data embedding 
AMBij Pij Wij1 EBij1 
Authentication bits of Bij 
Prefix bits of Bij 
Partial recovery bits of Bij  
First extra 
address code of 
Bij 
MBij 
AEBij1 Puv Wuv1 Wij2 EBij2 EBij1 
AEBij2 Pxy Wxy1 Wij3 EBij3 EBij2 
Pab Wab1 Wij4 EBij3 
used by Bij used by other blocks 
Partial recovery bits of 
Bij  
Partial recovery bits of Bij  
Partial recovery bits of 
Bij  
AEBij3 
AMBij Pij Wij1 
Authentication bits of Bij 
Prefix bits of Bij 
Recovery bits of Bij  
used by Bij 
MBij 
AMBij Pij Wij1 Wuv
k 
EBuvk+1 
Authentication bits of MBij 
Prefix bits of Bij 
Recovery bits of Bij  
Recovery bits of Buv 
(MBij is the extra block 
k of Buv) 
Extra address code if k is 
not the last extra block of 
Buv used by Bij used by Buv 
MBij 
 20 
 
Fig. 9  flowchart of authentication and recovery 
 
3. SIMULATION RESULTS AND DISCUSSIONS 
 
According to the test results of coefficient’s code length, 
average amount of coefficients Cs for single block will be 
24 in the rest of the simulations. Six sample images were 
used and the outcome would contain five images for each 
sample.  
i. Original image. 
ii. Data hided image with its PSNR against original 
image. 
iii. Tampering or cropping of data hided image. 
iv. Authentication map to locate the tamper or error. 
Unauthenticated block would be highlight in the 
map. 
v. Recovered image with its PSNR against original 
image 
These simulation results demonstrate remarkable tamper 
detecting ability of proposed method and the recovering 
ability is also proved. Furthermore, the visual quality is still 
impressive in massive cropping test. That depicts the 
successfully reduction of error propagation by joint-source 
recovery. 
Figure 10 shows the simulation of cropping attack.  
Figure 10(a) is  the original image. Figure 10(b) is  the 
image that is  embed information for recovery. The 
cropping area was chosen from the most content-sensitive 
part in the three sample images shown in Figure 10(c). 
Figure 10(d) shows the areas which are not authenticated. 
Figure 10(e) show that the recovered area is fabulous under 
human vision. 
Figure 11 is the simulation of performance gain from 
the proposed error concealment method with adaptive bit 
rate embedding distribution. The PSNR gain of our 
algorithm is about 3 to 5 dB in the recovered image. 
However, the visual quality gain in complex block is in 
good quality. Figure 10(a) is recovered without bit rate 
distribution, and Figure 10(b) is  recovered with the 
supporting of bit rate distribution. The recovered quality of 
complex area, like the hat’s edge and pupil in Lena and the 
number on the clock are much better with bit rate 
distribution. 
Compares to [3] which has excellent recovering quality 
but lack of speed due to inpainting and [2] that is fairly fast 
but has only average quality, the  proposed method 
accomplishes fantastic visual quality and still maintain low 
computation complexity at the same time. Both encoding 
and decoding could be done in few seconds. PSNR after 
embedding is also corresponsive high because of the 
optimized codeword length. 
    
(a)  Original image         (b) Embedded image 
PSNR=53.6886 
 
IDCT 
DCT 
ADD 
Divide into 
block Bij 
Image I 
Locating mapping 
block MB and extra 
blocks EB 
Huffman 
Decoder 
Get recovery bits 
Construct 
reference 
block R 
Joint source 
classifier 
Output I’ 
Compare 
Data 
extraction 
Authenticate
d 
Calculate 
authentication bits 
Un-Authenticated 
IDCT DeQuantization 
DCT 
 22 
Fig. 14 : High Region and Low Region 
 
Bit Type 1 Type 2 
0 (Low Region , Low Region) (High Region , High Region) 
1 (Low Region , High Region) (High Region , Low Region) 
Table 3: Representation of bit 
 
 Pair Coefficients Used 
To Embed Watermark 
Modified into Low 
Region or High Region 
Watermark 
Embedding Bit 
Bit = 1? 
YES NO 
Same 
Region? 
Same 
Region? 
Do Next Bit 
YES NO 
Modify the coefficient 
nearer to the other 
region to the other 
region. 
YES NO 
 
Fig. 15: watermark embedding flow chart 
 
Generating Watermarked Image Flow Chart 
 
Original Image 
Embedding 
Watermark 
into blocks 
Feature 
Extraction 
Split Image into 
8 by 8 blocks 
Watermarked 
Image 
 
Fig. 16: watermark embedding system flow chart 
 
 
Figure 17 shows the watermark extraction flow chart. 
Step 1: 
The coefficients in the High Region or Low Region will 
remain higher or lower than half of the largest tolerable 
quantization step size separately after the image is 
compressed by the quantization step size smaller than the 
largest tolerable quantization step size. To extract the 
watermarks, we did quantization in frequency domain by 
using the largest tolerable quantization table. 
Step 2: 
After the quantization by using largest tolerable quantization 
table, the Low Region coefficients will become zero and the 
high region coefficients will be higher than the quantization 
step size. In this step we extracted watermark bits by 
compute the zero numbers of the pairs of coefficients. If the 
pair of coefficients have even number of zeros, the 
embedded bit will be ‘0’. On the other hand, if there is only 
one zero in the pair of coefficients, then the embedded bit 
will be ‘1’. 
 Coefficients Quantized By 
Largest Step Size 
Count Pair Coefficients’ 
Zero Number 
YES NO 
Even? 
Bit 1 Bit 0 
 
Fig. 18: watermark extraction flow chart 
 
3.2. Authentication 
As received one image, we did mean shift segmentation to 
extract blocks’ mean shift segmentation feature and also 
calculate the mean value of blocks. Besides, we did 
watermark extraction to get the watermarks which are 
embedded in clusters. After did the feature extraction and 
watermark extraction. We compared the features to the 
watermark. From this chapter’s introduction we can know 
that the cluster number remains unchanged or decreases. If 
the extracted cluster number is more than the number 
embedded in the watermark, we then have the confidence to 
tell the block was malicious attacked. Besides, if the 
extracted cluster number is less or equal to the embedded 
number and the mean value of the block is equal to the 
embedded value, then we have the confidence to tell the 
block was not malicious modified. Figure 19 shows image 
authentication system flow chart. 
 
 
Watermark 
Extraction 
Feature 
Extraction 
Split Image 
into 8 by 8 
Received  
Image 
Compare 
Feature with 
Watermark 
Cluster Increased 
or Mean Value 
not equal? 
Yes 
Labeled as 
Error Block 
 
Fig. 19: image authentication system flow chart 
 
 24 
行政院國家科學委員會補助專題研究計畫■成果報告    □期中進度報告 
 
（計畫名稱） 
 
基於半碎型及碎型浮水印技術的影像竄改偵測、回復與認證之研究(3/3) 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號：97-2221-E-007-113-MY3  
執行期間：2008 年 8 月 1 日至 2011 年 7 月 31 日 
 
計畫主持人：張隆紋教授 
共同主持人： 
計畫參與人員：蕭佩琪 陳鼎介 王辰瀚 江振揚 
              何青龍 吳尚威 許家瑋 黃柏臻 
 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告■完整報告 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列管計
畫及下列情形者外，得立即公開查詢 
 
■涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
執行單位：國立清華大學  資工系 
 
中   華   民   國 100 年 9 月 6 日 
                                                                
 26 
bright subimage. Therefore, the value of α  is adaptively 
determined by  
128
128
,
,
32
128
25531
32
128
96
>
≤












⋅
−
−






⋅+
=
m
m
if
if
m
m
α
,  (2)                                         
where m  is the mean of ),( yxR s corresponding to 
1),( =yxW
. As a result, the value of α  for a bright 
subimage is small such that the visible watermark is dark; 
whereas the value of α  for a dark subimage is big such 
that the visible watermark is bright. By (1) and (2), we form 
a visible watermark which meets the requirements of 
transparency and visibility. However, the mathematical 
floor  ⋅  in (1) causes the rounding error such that, given 
),( yxRV
, it is impossible to find an inverse mapping 
function to restore ),( yxR  from ),( yxRV . However, we 
can approximate it by   
0),(
1),(
,
,
)),((2
),(),(~
=
=



−
=
yxW
yxW
if
if
yxR
yxR
yxR
V
V
α
, where 1,0 −≤≤ Nyx .                        
(3) 
The subimage R
~
 subtracted from R  is the difference 
image RD . The pixel values in RD  must be either “0” or 
“1”. This is because that from (1) and (3), ),( yxDR  
corresponding to 1),( =yxW  is equal to “0”, and 
),( yxDR
 corresponding to 0),( =yxW  is the original 
LSB of ),( yxR . Therefore, RD  must be a bi-level image. 
We compress RD  by a binary image lossless compression 
algorithm called JBIG to be a compressed bitstream 
denoted as )( RDC . The compressed bitstream )( RDC  is 
the residual data that has to be embedded in the image.  
With the disclosure of the pixel value mapping (1), 
unauthorized users can easily nearly recover the original 
subimage from the visibly watermarked subimage VR . 
That is, the nearly-recovered subimage differs from the 
original one only in the LSBs. Therefore, we further protect 
the pixel values corresponding to 0),( =yxW  in VR  by 
adding the random integer numbers pixel-by-pixel. The 
sequence is generated by the secret key 1K . Here, we 
assume the generated sequence to be },...,,{ 21 nsssS = , 
where Z∈is , ni ≤≤1 , and n  is the number of the 
pixels corresponding to 0),( =yxW  in VR . We index the 
pixel corresponding to 0),( =yxW  in VR  as ip  in the 
raster-scan order, where ni ≤≤1 . These pixel values are 
modified by  
256mod)(' iii spp += , where ni ≤≤1 .   (4)                                      
By (4), we generate the secure visibly watermarked 
subimage 'VR . 'VR  and R  form the secure visibly 
watermarked image 'VI , where R  is the area except R  
in I . In the last step, we use the SHA-256 hash function 
[17] to compute the 256-bit hash value of the original image 
denoted as )(IHash . The value of )(IHash  is further 
encrypted by the key 2K  to be ))((E 2 IHashK . As a result, 
the concatenation of the encrypted hash value and the 
residual data denoted as DB = ))((E 2 IHashK || )( RDC , 
where || denotes the concatenation of bitstreams, will be 
embedded in 'VI  . We use the reversible data hiding 
algorithm [7] to embed DB  in 'VI  to become the 
reversible visibly watermarked image ''VI . In summary, 
with the two keys 1K  and 2K , the embedder selects a 
subimage R  in the original image I  and generates S  
by 1K . R  is embedded the visible watermark W  by (1) 
to become VR . VR  and R  form the visibly 
watermarked image VI . Then, VR  is further modified by 
(4) to become 'VR . 'VR  and R  form the secure visibly 
watermarked image 'VI . Finally, the data bitstream DB  
containing ))((E 2 IHashK  and )( RDC  is embedded in 
'VI
 by the reversible data embedding algorithm [12] to 
obtain the reversible visibly watermarked image ''VI , as 
shown in Fig. 2.  
 
Fig. 2. The diagram of the proposed secure reversible 
visible watermarking with authentication scheme.  
 28 
EURASIP Journal on Applied Signal Processing, vol. 2002, 
no. 2, pp. 185–196, 2002. 
[4] J. Tian, “Reversible data embedding using a difference 
expansion,” IEEE Transactions on Circuits and Systems for 
Video Technology, vol. 13, no. 8, pp. 890–896, 2003  
[5] Zhicheng Ni, Yun-Qing Shi, N. Ansari, andWei Su, 
“Reversible data hiding,” IEEE Transactions on Circuits 
and Systems for Video Technology, vol. 16, no. 3, pp. 
354–362, 2006. 
[6] M. U. Celik, G. Sharma, A. M. Tekalp, and E. Saber, 
“Lossless generalized-lsb data embedding,” IEEE 
Transactions on Image Processing,, vol. 14, no. 2, pp. 
253–266, 2005. 
[7] Han-Min Tsai and Long-Wen Chang, “Adaptive 
multilayer reversible data hiding using the mean-to-pixel 
difference modification,” in Proc. IEEE International 
Conference on Multimedia and Expo, pp. 2102–2105, 2007 
[8] T. Kalker and F. M. J. Willems, “Capacity bounds and 
constructions for reversible data-hiding,” in Proc. 14th 
International Conference on Digital Signal Processing, vol. 
1, pp. 71–76, 2002 
[9] Sunil Lee, C. D. Yoo, and T. Kalker, “Reversible image 
watermarking based on integer-to-integer wavelet 
transform,” Information Forensics and Security, IEEE 
Transactions on, vol. 2, no. 3, pp. 321–330, 2007.  
[10] C. C. Lin, W. L. Tai, and C. C. Chang, “Multilevel 
reversible data hiding based on histogram modification of 
di erence images,” Pattern Recognition, 2008.ﬀ  
[11] G. Xuan, Y. Q. Shi, P. Chai, X. Cui, Z. Ni and X. Tong, 
“Optimum histogram pair based image lossless data 
embedding,” International Workshop on Digital 
Watermarking (IWDW07), Guangzhou, China, December 
2007. 
[12] W. Stallings, “Cryptography and Network Security: 
Principles and Practices”, 3rd edition, international edition, 
2003.  
 
6. 計畫成果自評部份: 研究內容與原計畫相
符，達成預期目標應該適合在學術期刊或會議
發表。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(一)參加會議經過:  
本人搭乘長榮航空班機抵達日本東京成田機場，再經火車抵達東京。東京是日本
最繁華之城市。本人在本會議發表兩篇口頭報告論文，論文是有關多媒體及符水
印應用之論文。大會安排亦安排本人擔當session chairman，主持 Image Processing  
5 (oral session) 。本次國際會議，是由Meiji University主辦，亞太訊號處理及通
訊學會（Asia-Pacific Signal and Information Processing Association）、IEEE Tokyo 
Section 等協辦。近年來日本常常舉辦國際的研討會及展示活動，提升國際形象
及爭取觀光資源。本次大會主辦單位可說非常盡地主之誼，除大會場地非常良好
之外，亦提供非常豐盛之晚餐Banquet，亦有高水準之音樂節目。 
本次國際會議主題如下: 
(1) Signal Processing 
(2) Communication Systems 
(3)  Computer and Information 
(4) Circuits and Systems 
(5) VLSI  
(6)  Information Technologies 
大會安排的 4 場 Keynote speeches: 
(1) Keynote Speech 1 (Academy Hall)Invite Speaker: Prof. Magdy A. Bayoumi 
(University of Louisiana at Lafayette, U.S.A), Chair: Yoshikazu Miyanaga (Hokkaido 
University, Japan) 
(2) Keynote Speech 2 (Academy Hall) Invited Speaker: Prof. Tomonori Aoyama 
(Keio University, Japan), Chair: Kaoru Arakawa (Meiji University, Japan) 
(3) Keynote Speech 3 (Academy Hall) Invited Speaker: Prof. King Ngi Ngan (The 
Chinese University of Hong Kong, Hong Kong), Chair: Supavadee Aramvith 
(Chulalongkorn University, Thailand) 
(4) Keynote Speech 4 (Academy Hall) Invited Speaker: Prof. Y. Jay Guo (CSIRO, 
ICT Centre, Australia), Chair: Tetsushi Ikegami (Meiji University, Japan) 
(英文) (1)High Efficient Adaptive Block Based Error Concealment 
for Digital Images with Data Hiding 
(2) Semi-Fragile Watermarking for Image Authentication, Localization, 
Using Tchebichef Moments 
and Recovery Using Tchebichef Moments 
 
High Efficient Adaptive Block Based 
Error Concealment for Digital Images with 
Data Hiding  
Po-Shuin Huang and Long-Wen Chang 
Department of Computer Science,  
National Tsing Hua University 
Hsinchu  Taiwan, 
E-mail: lchang@cs.nthu.edu.tw 
Abstract—Data hiding has become important 
since the rising of internet and multimedia 
services. Issues about authentication and 
error concealment of digital images get 
considerable attention in applications of 
military, tele-medical, and surveillance 
systems without local storage device. Due to 
the crucial time and space restriction under 
these circumstances, images of a specific time 
are usually non-reproducible. Furthermore, 
images using in each of these applications are 
highly content-sensitive. Consequently, error 
concealment with data hiding has been 
designed for specific applications. However, 
the common defect of these algorithms is the 
time consuming at either encoding or 
decoding end. This paper proposes a high 
efficient adaptive block based error 
concealment with data hiding. The 
information of recovery for each block is 
embedded to other blocks adaptively by its 
content.  Each block is classified to be an 
interblock or an intrablock according to the 
sum of absolute values of the AC DCT 
coefficients of the block. If it is an interblock it 
takes advantage the redundant information 
for its adjacent blocks and its bit rate for 
recovery is determined to be small. If it is an 
intrablock it is further classified to be in one of 
three groups. A block recovery bit rate 
assignment algorithm is used to assign the 
block of each group the bit rate it needs for 
recovery according to the complexity of the 
block. The simulation shows the effectiveness 
of the proposed error concealment method to 
recovery the image in good quality when 
certain blocks are not available. 
I. INTRODUCTION 
Data hiding based error concealment 
algorithms[1-8] designed for media have two 
different kinds of purposes. The first type of 
method is designed for videos. Main 
characteristic of these methods is high speed. 
The extraction and error concealment procedure 
need to be as fast as possible for real-time. The 
quality of recovered video is not the major 
concern of this kind of method. Acceptable and 
smooth visual quality would suit the requirement. 
The other type is  designed for 
content-sensitive media. Concealment quality 
becomes the main feature requested by the user. 
Many algorithms have been proposed to push up 
the visual quality of images after error 
reference block Rij is the average of RNE and 
DNE. The Residual block Sij is the difference 
between Bij and Rij. We transform Sij into the 
frequency domain using DCT. 
( )ijij SDCTS ='
 
and compute  Cij, where  
( )
64
,
8
1
8
1
' 





= ∑∑
= =u v
ijij vuSC
 
If Cij is less than a threshold τ, S’ij will be 
coded for inter-block-recovery; otherwise B’ij = 
DCT(Bij) is coded for intra-block-recovery. Also, 
indexing all AC coefficients in B’ij with 1 to 63 
in zigzag order, then we classify the block Bij 
into four groups according the following: 
τ<∈ ijij CifGB ,1
 
( ) ( ) 7.0,,2 63
1
'
21
1
' >≥∈ ∑∑
== i
ij
i
ijijij iBiBCifGB τ
 
( ) ( ) 8.0,,3 63
1
'
42
1
' >≥∈ ∑∑
== i
ij
i
ijijij iBiBCifGB τ
 
otherwiseGBij ,4∈
 
 
 
Fig.3  Construction of reference block Rij 
According to the above classification, G4 is 
the set of blocks that is most complex and G2 is 
the simplest. Suppose that C is the total bit rate 
that will be embedded in the image to recover 
the image. The average bit allocated for a single 
block would be Cs = C/Nb, Nb = (M×N)/16. 
Since G1 can be recovered by using the 
information of adjacent blocks it required small 
bit rate for recovery. For simplicity, we set the 
bite rate required to recover the block in G1 is 
0.5Cs. That is, we can construct an initial 
capacity distribution map as 
( )
( ) otherwiseCsjiCDMap
GBCsjiCDMap ij
,0.1,
1,5.0,
=
∈∀=
 
The remaining capacity 0.5Cs for each 
block in G1 can be used for the recovery for 
other blocks not in G1. The total remaining 
capacity from G1 is computed as  
1,5.0 11 GblocksofnumbertheisnCsnIEC ∈×=
 
Data generation and mapping block locating 
Watermark coding stage is composed of two 
separate coding phases, authentication bits 
coding phase and recovery bits coding phase. As 
the essential design issue of watermark-based 
error concealment framework, recovery bits of 
block Bij might be hided in one or several other 
blocks. On the other hand, authentication bits of 
the block Bij would be embedded in the block 
itself to guarantee that chain authentication 
problem is not going to happen. 
For every block Bij, six most significant bits 
of DC coefficients in B’ij is going to form DCij in 
order to represent the average color tone of the 
block. First six AC coefficients are divided into 
three pairs; each pair holds a relationship about 
their absolute value that can be coded in one bit 
according to the equation below. By combining 
three relations, 3 bits of ACij are formed to 
indicate the low frequency texture of the block. 
If |AC1| ≥ |AC2|,  ACij (1) = 0, else ACij (1) = 1 
If |AC3| ≥ |AC4|,  ACij (2) = 0, else ACij (2) = 1 
If |AC5| ≥ |AC6|,  ACij (3) = 0, else ACij (3) = 1 
 
Authentication bits Aij for the block Bij, would be 
the concatenation of DCij and ACij with the 
 Prefix bits Pij 
Watermark embedded in MBij for Bij would 
consist of authentication data of MBij, recovery 
information of Bij, and possibly the recovery 
information for a G3 or G4 block Buv if Bij ∈ 
G1. 
There are six distinct cases of watermark 
embedding capacity using status in MBij; Buv is 
the block which regards MBij as extra block for 
recovery. 
i. If ∃ Buv require 0.5Cs embedding 
bit rate in MBij then we set Pij = 000. 
ii. If ∃ Buv require 0.5Cs embedding 
bit rate and an extra block address in 
MBij then we set Pij = 010. 
iii. If ∃ Buv require 0.25Cs embedding 
bit rate in MBij then we set Pij = 111. 
iv. If ∃ Buv require 0.25Cs embedding 
bit rate and an extra block address in 
MBij then we set Pij = 101. 
v. If Bij ∈ G2 then we set Pij = 001. 
vi. If Bij ∈ G3 or G4 then we set Pij = 
110. 
vii. If Bij require 1.0Cs embedding bit 
rate in Bij and Bij ∈ G1 then we set 
Pij = 011 
 Coefficient bits 
Before coding, either B’ij or S’ij (chosen by joint 
source selector) is quantized by a special 
customized quantizer Qc.  
 
Fig.4 Example of mapping block MBij of G1~G4 
blocks Bij and Extra block EBij1~k of G3 or G4 
blocks Bij 
 Data integration 
After preprocessing, all data fragments are set. 
Fig.5~7 illustrates three possible data structure. 
The confirmation of structure type at decoder 
end will be determined by the value of extracted 
Pij. IWij is used for symbolizing the completely 
integrated embedding data of Bij.  
Figure 5 shows that for every block Bij, a 
complete data embedded in MBij when Bij is a 
G1 block. 9 bits AMBij stands for the 
authentication information for MBij, 3 bits Pij 
demonstrates seven different bit rate using status 
in MBij, Wijk is the partial recovery information 
of Bij, and Wuvk is the recovery information 
fragment k of a G3 or G4 block Buv because Buv 
allocated MBij as one of its extra block. Finally, 
EBuvk+1 stands for the extra block address which 
leads Buv to its next extra block. 
Figure 6 shows the structure of the 
complete data embedded in MBij for a Bij block 
of G2. Figure 7 shows the structure of the 
complete data embedded in MBij and extra 
blocks EBijk for a G3 or G4 block Bij 
j 
i 
Bij 
i’ 
j’ 
MBij 
Image I 
1 2 3 4 
EBij1~4, allocated in 
raster scan order 
Extra blocks already been allocated for other G3 or G4 blocks 
Available blocks for G3 and G4 blocks 
judging block type by joint source classifier, the 
reference block will be built if using 
inter-block-recovery, and the un-authenticated 
block will be recovered and sent to the output. 
(1)  Block Authentication   
Authentication bits are constructed following the 
manner at encoding end. Calculated 
authentication bits CAij are a coupling of six 
most significant bits DC magnitude information 
and three bits of AC relations for first six AC 
coefficients of every DCT block B’ij of block Bij. 
Extraction starts from least significant 
bit-plane’s low frequency area of B’ij following 
zigzag order after rounding to integer. First nine 
bits being extracted are extracted authentication 
bits EAij, and subsequent three bits are extracted 
prefix bits EPij. Comparing calculated 
authentication information CAij with embedded 
authentication information EAij. If there is 
different between these two authentication 
bit-streams, then block Bij is not authenticated. It 
might suffer from attack or packet loss. 
(2) Recover un-authenticated blocks 
For every un-authenticated block Bij, its mapping 
block MBij can be easily located by the same 
equation at encoder end. If the prefix bits EPMBij 
extracted from MBij equals to 010, 101, and 110, 
it means that there is an extra block address 
which leads to the next extra block connecting to 
the end of data extracted from MBij. Then the 
system will once again checks on the end of 
extra block’s watermark for another extra block. 
The sequential searching will continue until 
there is no any address code exists. According to 
the block addresses, recovery bits EWij1 can be 
retrieved from MBij and recovery bits EWij2~k can 
be reclaimed from extra blocks been found. 
Applying Huffman decoder and dequantizer to 
EWij1~k, right after that, 0.5Cs to 2.5Cs top 
coefficients are set for the recovery process of 
Bij. 
Un-authenticated blocks Bij with prefix 
code EPMBij of MBij equals to 000, 010, 011, 101, 
or 111 are blocks using inter-block-recovery. 
Reference blocks of these blocks would be built 
because the recovery bits encoded for these 
blocks are residual block S’ij. On the other hand, 
rests of the blocks use intra-block-recovery 
which is independent to other blocks. Hence, 
un-authenticated block Bij with prefix code of 
MBij equals to 001 or 110 are going to omit the 
construction of reference block and get right into 
recovery completion phase. 
The construction of reference block at the 
decoder end is identical to the process at the 
encoder. Right neighbor block and down 
neighbor blocks of block Bij are used for 
building the reference block Rij. IDCT decoded 
coefficients in order to build the reconstructed 
block RBij. RBij would be the straight output of 
recovery if using intra-block-recovery; 
Otherwise, RBij need to be added with reference 
block Rij to form recovered output block. 
( ) otherwiseRRBblockered
EPifRBblockered
ijij
MBijij
,_covRe
110,001,_covRe
+=
==
 
 
III SIMULATION RESULTS AND 
DISCUSSIONS 
 
According to the test results of coefficient’s code 
length, average amount of coefficients Cs for 
single block will be 24 in the rest of the 
simulations. Six sample images were used and 
the outcome would contain five images for each 
sample.  
i. Original image. 
V. REFERENCE 
[1] C.Y. Lin, D. Sow, and S.F. Chang, “Using 
Self-Authentication-and-Recovery Images for 
Error Concealment in Wireless Environments,” 
Proceedings of SPIE, Volume 4518, pp. 267-274, 
November 2001. 
[2] Chung-Yen Wang, “Image authentication 
with localization and recovery using adjacent 
block,” NTHU, VIP Lab, 2007 
[3] S.S. Wang and S.L. Tsai, “Automatic image 
authentication and recovery using fractal code 
embedding and image inpainting,” Pattern 
Recognition, Volume 41, Issue 2, pp. 701-712, 
February 2008 
[4] D.W. Cook II and P.K Rajan, “TIAMAT: A 
New Fragile Watermarking Technique for Image 
Authentication,” System Theory, 2006 
Proceeding of the Thirty-Eighth Southeastern 
Symposium, pp. 221- 225, March 2006 
[5] Q. Sun, J. Apostolopoulos, C.W. Chen, and 
S.F. Chang, “Quality-Optimized and Secure 
End-to-End Authentication for Media Delivery,” 
Proceedings of the IEEE, Volume 96, No. 1, 
January 2008 
[6] F. Ahmed and I.S. Moskowitz, 
“Correlation-based watermarking method for 
image authentication applications,” Optical 
Engineering, Volume 43, Issue 8, pp. 1833-1838, 
August 2004 
[7] C. Fei, D. Kundur, and R.H. Kwong, 
“Analysis and Design of secure 
Watermark-Based Authentication Systems,” 
IEEE transactions on information forensics and 
security, Volume 1, No.1, March 2006 
[8] C.B. Adsumilli, M.C.Q. Farias, S.K. Mitra, 
and M. Carli, “A Robust Error Concealment 
Technique Using Data Hiding for Image and 
Video Transmission Over Lossy Channels,” 
IEEE transactions on circuits and systems for 
video technology, Volume 15, No.11, November  
 
Fig.9  flowchart of authentication and recovery 
    
(a)  Original image                        
(b) Embedded image PSNR=53.6886 
 
(c) Cropped im  (d) Authentication map 
 
(e) Recovered image PSNR=47.2921 
Fig.10 Cropping test of 256 by 256 Lena 
Semi-Fragile Watermarking for Image 
Authentication, Localization, and 
Recovery Using Tchebichef Moments 
Wen-Hsin Chang  and Long-Wen Chang 
Department of Computer Science,  
National Tsing Hua University 
Hsinchu  Taiwan, 
Emai: lchang@cs.nthu.edu 
fumishin@gmail.com 
Abstract— A semi-fragile watermarking for 
image authentication, localization, and 
recovery scheme by using Tchebichef 
moments is proposed. We use robust invariant 
Tchebichef moments to generate the 
authentication feature, and use scaled 
Tchebichef moments to construct recovery 
information from low-frequency domain. In 
order to improve the quality of watermarked 
image and keep the robustness of watermark, 
we applied HVS to adjust the embedding and 
extraction quantization step size. The 
proposed method provides a complete 
authentication process from RST attack 
estimation to image recovery. The proposed 
method has high accuracy of authentication, 
can localize and recover the tampered region 
successfully and is robust to JPEG 
compression and AWGN operations. 
INTRODUCTION 
Recently, with the rapid growth of 
multimedia and network technologies, people 
transmit lots of digital files by wireless or 
wire internet and can modify, attack the 
digital files during transmission easily. 
Therefore, the issue of security in multimedia 
becomes more and more important. Digital 
watermarking is a method which embeds 
imperceptible information in digital 
multimedia to ensure the reliability of digital 
contents. There are two types of digital 
watermarking scheme, fragile watermarking 
and robust watermarking. Fragile 
watermarking scheme is fragile to any attack. 
We can use fragile watermark to detect the 
digital content is attacked or not, but the 
watermark is too fragile to be robust against 
the normal compression and noise. Robust 
watermarking scheme is designed for resist 
various attacks. We can extract the watermark 
logo even the digital content has malicious 
attacked. Although we can extract the correct 
watermark logo, we cannot ensure the digital 
content is tampered or not. 
Both fragile and robust watermarking scheme 
have their advantages and disadvantages. A 
tradeoff between fragile and robust watermarking 
is semi-fragile watermarking. Semi-fragile 
watermarking has properties of both fragile 











 +






−
−−
−= ∑
=
−
k
x
n
kn
kN
kN
nt
n
k
kn
n
1)1(!
0
. 
 The discrete Tchebichef polynomials nt  is 
scaled by nNNn =),(β as 
),()(
~
Nn
t
xt nn β= . 
The scaled Tchebichef moments is written as 
),()(~)(~),(~),(~
1 1
0
1
0
yxfytxt
NnNm
T n
N
y
m
N
x
mn ∑∑
−
=
−
=
= ρρ
. 
The image 1,0),.( −≤≤ Nyxyxf  can be 
obtained by the inverse moments function 
)(~)(~),(
1
0
1
0
ytxtTyxf nm
N
m
N
n
mn∑∑
−
=
−
=
= . 
Fig. 1 shows the Tchebichef polynomials for N=8. 
Fig.2 shows the reconstruction images of 64 x 64 
by different moment orders from 5 to 60. It shows 
that the image contains no information in Figure 
2(a) and then gradually to become an image that 
is very close to the original. Therefore, 
Tchebichef moments are used for recovery 
information and authentication. RST attacks 
mean rotation, scaling, translation attacks. The 
geometric attack estimation method just needs at 
most three Tchebichef moments of the original 
image[2].  
II PROPOSED METHOD 
The proposed semi-fragile watermarking scheme 
has three parts. The first part is introduction of 
human visual system (HVS) [3]which we will use 
in our scheme. The second part is concerned 
about watermark embedding procedure, which 
includes authentication feature extraction, 
localization watermark, and recovery information 
extraction. The third part is concerned about 
watermark extraction and authentication 
procedure, which includes the complete 
authentication procedure with RST estimation, 
image authentication, tampered localization, and 
image recovery. 
 
Fig.1: Scaled Tchebichef polynomials for N=8 
 
 
Fig.2: The image reconstruction by scaled Tchebichef 
moments with different orders from 5 to 60. (a) 5 orders (b) 10 
orders (c) 15 orders (d) 20 orders (e) 25 orders (f) 30 orders 
(g) 35 orders (h) 40 orders (i) 45 orders (j) 50 orders (k) 55 
orders (l) 60 orders 
DISCRETE WAVELET DECOMPOSITION AND 
EMBEDDING PROCEDURE 
First, we will apply 2-level 2D discrete 
wavelet transformation to a gray level image. 
After 2-level decomposition, the host image will 
be decomposed into seven parts of high, middle, 
and low frequencies, which are LH1, HL1, HH1, 
LH2, HL2, HH2, and LL2 sub-bands. The LH1, 
HL1, HH1, LH2, HL2, HH2 sub-bands represent 
the detail of  the mage, and LL2 sub-band 






−
+=
−
−=
2
)()1,2()1,2(
2
)()2,1()2,1(
22
,
2
,
22
,
2
,
diffDD
diffDD
HL
vu
HL
vu
HL
vu
HL
vu
τ
τ
 
where τ is user defined. In our experiments, we 
set  



=
<=
.,20
2.16
otherwise
JNDif
τ
τ
 
 
Fig.4: The authentication embedding flowchart 
 
Fig.5: Relationship between DWT coefficients 
LOCALIZATION WATERMARK  
We use the binary logo to be localization 
watermark and embed the watermark into HH1 
sub-band. The localization embedding procedure 
is as Fig.6: 
 
Fig.6: Localization embedding procedure 
The detailed steps of localization watermark 
embedding procedure are as follows: 
Step 1: Use a secret key  and a chaotic map 
to transform the watermark into a chaotic 
watermark ionlocoalizatW  from  the  original 
watermark onlocalizatiW .   
The chaotic map is used to change a pixel of 
the watermark W from (x,y)  to (x’,y’)  can be 
represented as follows: 
N
y
x
lly
x
mod
1
11
'
'






+
=





 
Where 11)
1
11
det( −=





+
or
ll
  
denotes an integer;  denotes the width of a 
square image, we set 2=l   in our experiments. 
Fig. 7 shows the original watermark and the 
chaotic map watermark. 
Step 2: Use odd-even quantization to embed 
L ionlocoalizatW  into HH1 sub-band. The 
quantization step size  is user predefined, we 
set  123 =q  in our experiments. 
          
(a)                     
  (b) 
Fig.7  The watermark before and after chaotic map 
RECOVERY INFORMATION EMBEDDING 
We use scaled Tchebichef moments to get 
recovery information for each block, because 
scaled Tchebichef moments has high accuracy of 
reconstruction. The recovery information 
embedding procedure is as Fig. 8: 
 
Step 1: Construct just three Tchebichef 
moments from the received watermarked image 
to estimate RST parameters. If the received 
watermarked image is not attacked by RST 
attacks, the image passes, and goes to step 2. 
Otherwise, the received image is attacked by 
RST attacks, the image fail, and goes to step 6. 
Step 2: Apply 2-level 2D discrete wavelet 
transform (DWT) 
Step 3: As shown in Fig.10, we determine the 
image is authenticated or not by following 
sub-steps 
i. Construct invariant Tchebichef moments 
from the LL2 sub-band 
ii. Get feature watermark receivFM   from 
invariant Tchebichef moments.  
iii. Get embedded feature watermark  
embeddedFM for authentication from 
HL2 sub-band by relationship of DWT 
coefficients. We divided HL2 into 4*4 
blocks, for each block we can extract 
one watermark bit by the relationship of 
)2,1(2
,
HL
vuD and )1,2(2,HLvuD  by 




≤
>
)1,2()2,1(0
)1,2()2,1(1
2
,
2
,
2
,
2
,
),( HL
vu
HL
vu
HL
vu
HL
vu
vuembedded DDif
DDif
FW
 
iv. Calculate the difference image atDI   
between  receivFM and  embeddedFM  
v. Calculate the bits error rate from atDI  , if 
the bits error rate is under 0.04, the 
received image is authenticated and goes 
to step 7. Otherwise, the received image 
is not authenticated and goes to step 4. 
Step 4: Use odd-even quantization to get 
localization watermark ' onlocalizatiW   from HH1 
sub-band, and calculate the difference 
image localDI   between 
'
onlocalizatiW and 
onlocalizatiL , which a logo and can be available to 
the decoder. Then, we denoise the difference 
image localDI  to get localization result. As 
shown in Fig.11 , for an error detection pixel in 
localDI , we determine the pixel is maliciously 
attacked if its eight neighbor pixels are at least 
two pixels are error detection pixel. 
Step 5: As shown in Fig. 12, for each 
tampered block, we recover it by the following 
sub-steps 
i. Use the chaotic map to find the mapping 
block index (u’,v’) from original block 
(u,v). If mapping block is not tampered 
block, go to sub-step ii. Otherwise, go to 
sub-step vi. 
ii. Use odd-even quantization to extract the 
lsign _  from LH2, bitflag8  from 
HH2, and recovery information from 
LH1 and HL1 
iii. Convert the binary code to decimal and 
multiply 4 
iv. Use the reconstructed scaled Tchebichef 
moment to recover the block by inverse 
Tchebichef moments function. 
v. Determine are all tampered blocks 
reconstructed or not. If all tampered 
blocks are reconstructed, go to sub-step 
vii. Otherwise, go to sub-step i. 
vi. Skip the block, do next block and go to 
sub-step i. 
vii. Finish the recovery procedure, and go to 
step 7. 
Step 6: Use the parameters which are 
estimated by RST estimation to transform the 
We applied HVS to adjust the quantization 
step size 1q  and 2q  and authentication 
threshold τ to improve the quality of 
watermarked image and at the same time remain 
the robustness of watermark. If 
thresholdJND < , we use smaller 
quantization step size, and vice versa. 
The proposed method is very flexible, 
because user can predefine the parameters which 
are like quantization step size  1q  and 2q  and 
authentication threshold τ  with their preference 
between image quality or watermark robustness. 
V. REFERENCES 
[1] R.Mukundan, D.H. Ong, P.A. Lee, “Image 
Analysis by Tchebichef Moments,” IEEE 
Transactions on Image Processing, vol. 10, No. 
9, pp.1357~1364, September 2001 
[2] L. Zhang, G.B Qian, W.W Xiao, “Geometric 
Distortions Invariant Blind Second Generation 
Watermarking Technique Based on Tchebichef 
Moments of Original Image,” Journal of 
Software, vol. 18, No. 9, pp.2283~2294, 
September 2007 
[3] H.F. Yang, X.M. Sun, “Semi-Fragile 
Watermarking for Image Authentication and 
Tamper Detection Using HVS Model,” 
International Conference on Multimedia and 
Ubiquitous Engineering 2007 
[4] M.J. Tsai, C.C Chien, “A Wavelet-Based 
Semi-Fragile Watermarking with Recovery 
Mechanism,” IEEE International Symposium on 
Circuits and Systems, pp.3033-3036, May 2008 
[5] L. Zhang, G.B Qiam, W.W Xiao, J. Zhen, 
“Geometric Invariant Blind Image 
Watermarking by Invariant Tchebichef 
Moments,” Optics Express, vol. 15, No. 5, 
pp.2251~2261, March 2007 
[6] G.H. Liu, Z. Zhu, X. Jie, “Orientation and 
Damage Inspection of Insulators Based on 
Tchebichef Moment Invariants,” IEEE 
International Conference Neural Networks & 
Signal Processing, pp.48~52, June 2008 
[7] Y.L. Tang, C.T. Chen, “Image 
Authentication Using Relation Measures of 
Wavelet Coefficients,” IEEE International 
Conference on e-Technology, e-Commerce and 
e-Service, 2004 
[8] K.W. See, K.S. Loke, P.A. Lee, K.F. Loe, 
“Image Reconstruction Using Various Discrete 
Orthogonal Polynomials in Comparison with 
DCT,” Applied Mathematics and Computation, 
pp.346~359, 2007 
[9] S.M. Elshoura, D.B. Megherbi, “Analysis of 
Noise Sensitivity and Reconstruction Accuracy 
of Tchebichef Moments,” IEEE Southestcon, 
pp.521~526, April 2008 
[10] C.W. Kao, “Zernike Moment and Edge 
Features Based Semi-Fragile Watermark for 
Image Authentication with Tampering 
Localization,” NTHU VIP Lab, 2007 
[11] H.F. Yang, Z.H. Yang, M.F. Jiang, 
“Content Based Image Public Waternarking,” In 
proceedings of Eurographics Workshop on 
multimedia, pp.163~172, 2004 
[12] K. Ding, C. He, L.G. Jiang, H.X. Wang, 
“Wavelet-Based Semi-Fragile Watermarking 
with Ttamper Detection,” IEICE Transaction 
Fundamentals E88-A(3), pp.787~790, 2005 
論文被接受發表之大會證明文件 
  Paper ID: 00131 
   Title   : High Efficient Adaptive Block Based Error Concealment for 
             Digital Images with Data Hiding 
   Authors : Long-Wen Chang 
 
Dear Prof. Long-Wen Chang 
 
CONGRATULATIONS! 
 
Your above-referenced manuscript has been accepted for presentation  at ISCIT 2010. 
 
For preparing your final camera-ready manuscript and Copyright Transfer Form, please 
read the following instructions. 
 
1. Instruction for Upload of Camera Ready Paper and Update of Paper Information 
 
Please upload the final camera ready paper, Maximum of 6 pages on A4 paper, at 
UserSite https://splab.cs.kitami-it.ac.jp/sms/iscit2010/user 
from August 11 to September 1. You should upload no later than  1st September, 2010. 
Click the button "Paper" and upload your accepted paper by clicking "upload PDF 
file". 
 
 
* Please Verify The IEEE Xplore Compatibility of Your Camera Ready Paper 
IEEE PDF eXpress has been enabled for use by your conference 
authors and personnel. Please go to the IEEE PDF eXpress site at 
www.pdf-express.org. Click on the link "New Users - Click Here" and 
fill in your information. You will need the Conference ID which is: iscit10x 
 
 
Then, please update the paper information at the UserSite  
https://splab.cs.kitami-it.ac.jp/sms/iscit2010/user.   
Abstract book will be published based on this information.   
Use "update paper" button in the page of "Paper". 
 
 
September 2010.  
 
 
 
----------------------------------------------------------- 
Review Comments: 
 
--- Comments from Reviewer --- 
 
There is mismatch error (as Figure 16). 
 
 
----------------------------------------------------------- 
 
 
Best Regards, 
 
ISCIT 2010 TPC co-Chairs 
Tetsushi Ikegami  Meiji University, Japan 
Xiaojing Huang  CSIRO, Australia 
Zhifeng Zhao  Zhejiang University, China 
Supavadee Aramvith  Chulalongkorn University, Thailand 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
* For Student Awards, please check yes/no in the box "student" at the 
button "update paper". This is only for the speaker. 
 
 
 
2. Instruction for Copyright Transfer Form Submission 
 
You have to submit the signed copyright transfer form to include your  
accepted paper in the ISCIT2010 proceedings and in the IEEE Xplorer.  
Individual PDF file of IEEE Copyright Form filled with the paper title  
and authors' names can be downloaded from "Paper" page at UserSite.  
Click "create Unsigned Copyright form" to download the form.  
You can also use Original IEEE Copyright Form at the page Download.  
 
* We provide two ways to submit the signed copyright form:  
  <BY WEB> 
Scan the signed copyright form and upload it by clicking  
"upload Signed Copyright form" on "Paper" at UserSite.  
  <BY FAX>  
Fax the signed form to fax number +81-44-934-7445.  
 
* You should submit your IEEE Copyright Form no later than  
1st September, 2010.  
 
 
Note: 
1.  For paper authors, to include your paper in the program,  
the abstract book and the USB(Proceedings), at least one author  
of your paper MUST PAY the Regular Registration fee by 1st  
September 2010. 
2.  One Regular Registration can cover only one paper presentation.  
In the case of multi-authored papers, at least one author must register  
at the Regular Registration fee for the paper to be considered for  
presentation at the conference. If an author has more than one accepted  
paper, he/she must pay the paper charges for each paper. At least one  
author of each accepted paper MUST PAY the Regular Registration fee by  
1st September 2010 to be included in the program. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/12
國科會補助計畫
計畫名稱: 基於半碎型及碎型浮水印技術的影像竄改偵測、回復與認證之研究
計畫主持人: 張隆紋
計畫編號: 97-2221-E-007-113-MY3 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
擔任 Technical Program Vice Co-Chair of The Fifth International Workshop 
on Image Media Quality and its Applications 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
