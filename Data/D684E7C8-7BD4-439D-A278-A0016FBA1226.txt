面停止播送類比電視信號，開始進入全數位
電視廣播的時代，歐洲國家也從 2010 年起
陸續停播類比電視信號，日本預定於 2011
年全面停播類比電視。 
 2
除了透過傳統地面廣播、衛星廣播、與
有線廣播等接收技術之外，近年來數位電視
也開始強調移動接收與手持裝置技術。在手
持式行動裝置（如手機或 PDA）上收看電
視節目，可以讓廣大的行動通信用戶隨時隨
地獲取他們需要的資訊和喜愛的節目，也可
以讓通訊業者提供更多樣化的多媒體加值
服務。 
在國際間目前已（試）營運的手持式電
視系統中，DVB-H 標準是目前聲勢最浩大
且市佔率較高者，而且對於數位電視地面廣
播系統採用 DVB-T 標準者（如我國），採用 
DVB-H 將可相容於現有地面廣播傳輸模式
與終端接收設備；也因此，本計畫將以實作 
DVB-H 標準的視訊與音訊解碼為目標。 
DVB-H 的視訊編碼建議選用 H.264 及
VC-1 規格，音訊編碼則建議採用 MPEG-4 
HE AAC v2 及 3GPP 的 AMR-WB+。由於
H.264 與 MPEG-4 AAC 格式是高效率影音
壓縮的主流，目前提供 DVB-H 服務的電
台，絕大部份都是使用 H.264 與 MPEG-4 
AAC 規格，所以本計畫將僅實作 H.264 與
MPEG-4 HE AAC v2 解碼器，至於 VC-1 與
AMR-WB+則暫不考慮。 
二、H.264 視訊編碼 
H.264 （ 亦 稱 為  MPEG-4 AVC, 
Advanced Video Coding）是 ITU 與 ISO/IEC 
等國際標準組織所共同制定的最新視訊編
碼標準，它能提供高效率的視訊壓縮，及壓
縮視訊在各種不同網路環境的有效表示。
H.264 用不到一半的位元率，就可以達到與
MPEG-1/2 相同的視訊品質。壓縮效率的改
進，代表傳輸或儲存成本的降低與使用便利
性的提升，因此 H.264 已成為數位電視、影
音串流、行動視訊、高密度光碟等各項多媒
體服務的關鍵技術。 
 
圖二：H.264 的分層架構與可能傳輸環境 
H.264 標準在架構上包含 VCL (Video 
Coding Layer)與 NAL (Network Adaptation 
Layer)兩層，如圖二所示。VCL 為視訊壓縮
的部份，其技術核心包括動作估計、轉換編
碼、預測編碼、去區塊效應濾波、及熵編碼
等技術。NAL 提供 VCL 編碼資料與實際網
路之間的介接，進行編碼資料的格式化，添
加必須的檔頭資訊，再封裝成適當的傳輸單
元。除了實際的視訊封包之外，NALU 也可
以傳送獨立之參數集(Parameter Set)，做為
解碼的輔助資訊。 
H.264 標準雖不求向後相容，但它和之
前的 H.26x/MPEG 標準仍有許多雷同之
處，基本上還是以區塊動作估計與轉換編碼
為主體。H.264 的編碼端架構如圖三所示，
相較於過去的視訊壓縮技術，H.264 主要的
改 進 包 括 ： (1) 動 作 估 計 的 比 對 區 塊
(macroblock)大小可做動態調整，(2)提供 1/4
像素點的動作估計，(3)可參考超過 2 張畫
面，(4)使用畫面內空間域預測，(5)使用 4×4
的整數 DCT 轉換，(6)在編碼迴路內使用去
除 區 塊 效 應 濾 波 器 ， (7) 以 CAVLC 
(context-adaptive variable length coding)或
CABAC (context-adaptive binary arithmetic 
coding)消除編碼冗餘。 
將低頻的頻譜複製到高頻，故高頻部份只記
錄概略之能量數值，以節省編碼之位元數。
SBR 之 analysis QMF (Quadrture Mirror 
Filter) bank 為 32-band complex QMF，而
synthesis QMF 則 為 64-band complex 
QMF。至於 MPEG-4 HE AAC v2 則是在
MPEG-4 HE AAC 中加上了參數立體聲 
(Parametric Stereo, PS)之工具，其編碼示意
圖如圖六所示。由此圖可知，較低頻之訊號
經 PS 編碼器取出參數後，再送入 AAC 編
碼器編碼低頻部份（開關向上），至於高頻
部份，則只由 SBR 計算頻譜之包絡，而不
編碼頻譜值。 
圖六：MPEG-4 HE AAC v2 之編碼示意圖 
 4
四、Android Media Player 
Android是由Google及開放手機聯盟所
發展的一個基於Linux作業系統的開放手持
式裝置軟體架構，Android 提出了一個應用
軟體開發框架，讓應用程式可以用類似元件
的方式來組成。此外，Android 將軟體架構
分成數個層次，讓軟體的開發可以依功能區
隔開來，並且可以很容易地移植到不同的硬
體平台之上。 
Android MediaPlayer 為 Android 的基礎
多媒體框架，內部主要分為七大部分：PV 
Player、PV Author、Codec、Packet Video 
Multimedia Framework (PVMF)、Operating 
System Compatibility Library (OSCL) 、
Common、Open MAX。PV Player 和 PV 
Author 提供音訊和視訊的錄製及播放的功
能，並透過 Linux 的硬體驅動程式和硬體溝
通。由於 PV Player 和 PV Author 使用的都
是原始資料的形式，所以必須先透過編解碼
器來進行編碼或解碼。PVMF 是 Android 判
斷檔案格式及編碼內容的框架，自動決定要
用哪一個 Parser 來解開或包裝檔案，並選擇
適當編解碼器進行編碼或解碼，Common 則
存放各種整體框架的共通功能。OSCL 提供
包括資料型態、記憶體管理、執行等基本函
式。Open MAX 分為 DL、IL、AL 三種層級，
讓編解碼器的開發更簡易，其中。DL 掌管
直接和硬體連接的部分，包含對 CPU、顯示
晶片、數位訊號處理器等的最佳化和驅動程
式的接口；IL 提供編解碼器函式庫，硬體編
解碼加速器亦可經由 Open MAX IL 和上層
連結；AL 控制錄影、放影、各種感測器及
顯示器等使用者介面。 
 
III. 研究與實作方法 
DVB-H 傳送系統的影音資料封裝方式
如圖七所示。視訊資料經過 H.264 VCL 層
壓縮，再由 H.264 NAL 層封裝成為 NAL 單
元(NAL unit, NALU)，一個 NALU 包含 1
個位元組的標頭，與一段影像語法元素
(syntax elements)。NALU 標頭的後 5 個位元
說明其編碼型態(type)，其他位元說明此
NALU 的重要性。TS 102 005 技術規範規
定，對於手持式裝置 IP Datacast 的應用，
H.264 的影像資料應該用單一的 NALU 或
非交錯模式的 RFC 3984 直接封裝成一個 
RTP 封包。至於音訊資料則在使用 RTP 通
訊協定之前，先用 RFC 3640 來包裝。RTP
封包有 12 位元組的標頭，包含承載資料型
態、序列號碼、時間戳記、同步資料源識別
碼及其他欄位之資料。RTP 封包再用 UDP 
(User Datagram Protocol) 和 IP (Internet 
Protocol) 通 訊 協 定 進 一 步 封 裝 成 IP 
datagram。 
 
圖七：DVB-H 傳送/接收系統的資料封裝 
音訊 RTP 封包的處理流程如圖十所
示。音訊以 Audio Unit (AU)為封包的基本單
位，也就是說，音訊 RTP 封包的 payload 即
是一個或一個以上的 AU。AU (RFC 3640)
的結構如圖十一所示，共包含三個區段
(section)：AU Header Section（不一定有）、
Auxiliary Section（不一定有）、以及一定得
出現的 AU Data Section。AU Header Section
的前兩個位元組(AU-headers-length)標示其
後所有 AU 標頭區段的總長度(in bits)，後面
跟著若干個 AU 的標頭，AU-headers-length
的值若為 0x0010 時，表示只有一個 AU。每
一個 AU header 的前 13 位元代表這個 AU
的大小，再來的 3 位元代表 AU 的索引值。
根據這些資訊即可將 HE AAC 的音訊資料
依序存入 Audio Buffer 中。 
圖十一：RTP Payload Format 結構 (RFC 3640) 
  
 
 
在處理完RTP得到H.264和HE AACv2
後，必須將資料封裝成 3GP 媒體檔案格式，
Android MediaPlayer 才有辦法順利播放。
3GP 是 MPEG-4 Part 14 （MP4 檔案格式）
的一種簡化版本，它減少了儲存空間和頻寬
需求，以方便在手機上有限的資源下使用。
3GP 的檔案格式如圖十二所示，大致上分為
File Type Box (ftyp)、Media Data Box (mdat)
和 Movie Box (moov)三個部分。ftyp 相當於
檔案的檔頭，主要描述的是 3GP 支援版本
和影音編碼格式等資訊。mdat 用來放置影
像以及聲音的資料串流，moov 則用來描述
mdat 中的資料串流。moov 裡頭再分為 mvhd
和 trak 兩部分，大致上一個 moov 會有兩個
trak，一個用來描述 mdat 中的影像，而另一
個描述聲音。 
 
 
 
圖十：音訊 RTP 處理流程圖 
 
圖十二：3GP 資料結構圖 
 6
Main VIDEO VideoRTP AudioRTP ThreeGPPackage IPDC
setDecoderInfor(Video_SDP_Structure *)
getRTPPackets(ip , audioPort , videoPort , vecor<A_RTP*> , vecor<A_RTCP*> , vecor<V_RTP*> , vecor<V_RTCP*>)
read():string
rtp packets
processVRTP(vector<V_RTP*> , vector<H264Structure*> , vector<ParameterSet*> , SDP)
to_H264(vector<V_RTP*> , vector<H264_Structure*>)
processARTP(vector<A_RTP*> , vector<AACStructure*> , SDP)
to_AAC(vector<A_RTP*> , vector<AACStructure*> , SDP)
setVideoFile(vector<H264Structure*> , vector<ParameterSet*>)
setAudioFile(vector<AACStructure*>)
write3GPFile():string
回傳檔案位置
回傳檔案位置
圖十五：Sequence Diagram
本計畫之系統架構圖如圖十六，其軟體
開發流程分為系統需求、系統設計、系統測
試三大部份。 
 
一、系統需求 
分為計畫執行規劃書與系統需求規格
書兩部份。計畫執行規劃書內容包括時間規
劃、工作和人員分配、資料控管等；系統需
求規格書內容包括系統架構、系統內外部介
面需求、功能需求、Use Case 等。其中較
重要之功能需求列在表二。 
圖十六：系統架構圖 
 
 8
 10
VI. 參考文獻 
[1] EBU, Digital Video Broadcasting (DVB); 
Transmission system for handheld terminals 
(DVB-H), ETSI EN 302 304, v1.1.1, 2004.  
[2] EBU, Digital Video Broadcasting (DVB); 
Specification for the use of video and audio 
coding in DVB services delivered directly 
over IP protocols, ETSI TS 102 005, v1.3.1, 
2007.  
[3] G. Faria, J. A. Henriksson, E. Stare, and P. 
Talmola, “DVB-H: digital broadcast services 
to handheld devices,” Proceedings of the 
IEEE, vol. 94, no. 1, pp. 194 - 209, Jan. 2006.  
[4] M. Kornfeld and G. May, “DVB-H and IP 
datacast－broadcast to handheld devices,” 
IEEE Trans. Broadcasting, vol. 53, no. 1, 
pp.161- 170, March 2007.  
[5] Advanced Video Coding for Generic 
Audiovisual Services, ISO/IEC 14496-10, 
Version 8, Apr. 2007. 
[6] SMPTE, Proposed SMPTE standard for 
television: VC-1 compressed video bitstream 
format and decoding process, SMPTE 421M. 
[7] G. J. Sullivan and T. Wiegand, “Video 
compression from concepts to the H.264/AVC 
standard,” Proceedings of the IEEE, vol. 93, 
no. 1, pp. 18-31, Jan. 2005. 
[8] D. Marpe, T. Wiegard, and G. J. Sullivan, 
“The  H.264/MPEG4 advanced video coding 
standard and its applications,” IEEE 
Communications Magazine, vol. 44, no.8, pp. 
134-143, Aug. 2006.  
[9] M. Horowitz, A. Kossentini, and A. 
Hallapuro, “H.264/AVC baseline profile 
decoder complexity analysis,” IEEE Trans. 
Circuits Syst. Video Technol., vol. 13, no. 7, 
pp. 704-716, July 2003. 
[10] 楊士萱、陳柏源，H.264/AVC 技術與
應用簡介，影像與識別，vol. 13, no. 2, June 
2007。 
[11] ISO/IEC: Information Technology - 
Coding of audio-visual objects - Part 3: Audio, 
ISO/IEC 14496-3, 2009. 
[12] 3GPP, Audio codec processing functions; 
Extended Adaptive-Multi-rate – Wideband 
(AMR-WB+) codec; transcoding functions, 
3GPP TS 26.090 (ETSI TS 126 290). 
[13] S. Meltzer and G. Moser, “MPEG-4 HE 
AAC v2 — audio coding for today’s digital 
media world,” EBU Technical Review, pp. 
1–12, Jan. 2006.  
[14] IETF, RTP payload for transport of H. 
264, RFC 3984, 2005. 
[15] IETF, RTP payload for transport for 
generic MPEG-4 elementary streams, RFC 
3640, 2003. 
[16] IETF, RTP, A transport protocol for real 
time applications, RFC 3550, 2003.  
