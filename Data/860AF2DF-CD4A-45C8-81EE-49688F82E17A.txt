  
I
行政院國家科學委員會專題研究計畫進度報告 
 
前瞻性機器學習法應用於語音，語言及圖形辨識 
Advanced Machine Learning Methods for Speech, Language and Pattern Recognition 
 
計畫編號：NSC 97-2221-E-006-230-MY3 
執行期限：97 年 8 月 1 日至 100 年 7 月 31 日 
主持人：簡仁宗  執行機構：國立成功大學資訊工程學系 
 
中文摘要 
機器學習廣泛的包含各領域的重要應用如：語音辨識、資訊擷取、電腦視覺、生物特徵辨識、
手寫辨識等。本計劃提出三種新穎性的機器學習演算法：因素分析之多串流隱藏式馬可夫模型
(Factor Analyzed Streamed Hidden Markov Model, FASHMM)、最小錯誤排序學習法(Minimum 
Ranking Error, MRE)與遞迴式貝氏支持向量機(Recursive Bayesian Support Vector Machine, RB-
SVM)，並透過各演算法符合機器學習理論的特性來呈現與機器學習應用領域之間的關聯。在
三個分年計畫中，我們著重在以統計式模型的觀念來貫穿機器學習相關問題的解決。其中我們
從圖型辨識、統計方法及群聚理論來探討隱藏式馬可夫模型與支持向量機。我們將貝氏決策,
貝氏擷取跟鑑別式學習的觀念來與資訊檢索中檢索排序錯誤的風險相結合，並且基於貝氏檢索
理論提出一個具鑑別性的文件模型以期提高資訊檢索的效能。另外貝氏線上學習與傳統的支持
向量機理論相結合來增加其學習能力並提升對圖形辨識的強健性。對於各分項的進一步內容我
們簡短摘要如下：     
    我們提出一種新穎的多串流(Streamed)隱藏式馬可夫模型(HMM)來做為語音辨識別的架構。
我們採用因素分析(Factor Analysis, FA)來從聲學特徵中擷取出共同因子與獨特因子，而在建立
HMMs 過程中，共同因子(Common Factor)會聚集成為一分流，而此分流的規律性取決於倒頻
譜(Cepstrum)特徵之間相互關係。那些對應到相同共同因子的特徵其 HMM 的狀態轉移特性視
為相同，因此，馬可夫鏈裡倒頻譜向量中不同維度的錯綜複雜的變化都可以據此來進行補償。
在本研究中所發展的因素分析之多串流隱藏式馬可夫模型(FASHMM)方法，可解除在標準
HMM 架構中每一個音框裡的全部特徵皆用相同狀態轉移特性之假設，相比較於分解式隱藏式
馬可夫模型(Factorial HMM, FHMM)，我們提出的 FASHMM 更為精細且複雜，並且在每一串
流的輸入資料上可以自動的決定，不像 FHMM 需要人工去定義每一串流的輸入資料內容。此
外為了降低 Factor Loading 矩陣的參數量，我們更進一步求出矩陣之間的相似度，並以此達到
FA 模型的參數分享。總體而言，FASHMM 對於多變量的資料，能夠以共同因子與獨特因子
(Specific Factor)將資料當中各種不同的狀態轉移特性做更精確的表現，因此能更符合串流式馬
可夫模型欲達成之目的。基於 FASHMM 的語音辨識架構中，我們提出新穎的語音解碼
(Decoding)演算法。 
    其次統計語言模型化眾所周知的已經被成功開發在很多智慧型系統裡例如語音辨識，機器翻
譯和資訊擷取。本計畫提出一個新穎的最小排序錯誤(Minimum Rank Error, MRE)鑑別式訓練演
  
III
Abstract 
Machine learning techniques have been extensively developed and widely applied in many 
pattern recognition systems. In this project, we present three novel learning algorithms based on 
machine learning theories: Factor Analyzed Streamed Hidden Markov Model (FASHMM), Minimum 
Ranking Error (MRE) and Recursive Bayesian Support Vector Machine (RB-SVM). We use the 
concepts of machine learning to characterize the relationships between machine learning theories and 
machine learning applications. In this project, we adopt the statistical approaches to solve the 
problems of machine learning. We discuss the issues of hidden Markov model (HMM), support 
vector machine (SVM), pattern recognition, statistical approach and clustering theory. In the 
application of HMM in speech recognition, we adopt the decision tree learning and the Bayesian 
network of graphical model to establish the novel structure of FASHMM. In order to attain higher 
information retrieval performance by discriminative training method, we integrate Bayes decision 
theory, Bayesian retrieval and discriminative learning to minimize the rank error in information 
retrieval task. In addition, Bayesian learning is combined with the conventional SVM algorithm in 
this project to enhance the capability of on-line learning. Such enhancement can improve the 
robustness of pattern recognition in adverse environments. In what follows, we briefly address the 
machine learning algorithms in this project.  
Firstly, a novel streamed hidden Markov model (HMM) framework for speech recognition is 
presented. The factor analysis (FA) principle is adopted to explore the common factors from acoustic 
features. The streaming regularities in building HMMs are governed by the correlation between 
cepstral features, which is inherent in common factors. Those features corresponding to the same 
factor are generated by identical HMM state. Accordingly, the multiple Markov chains are performed 
to compensate the complicated variation trends in different dimensions of cepstral vectors. A FA 
streamed HMM (FASHMM) method is developed here to relax the assumption of standard HMM 
topology, namely all features at a speech frame conduct the same state emission. The proposed 
FASHMM is more sophisticated than the factorial HMM where the streaming was empirically 
determined. To reduce the parameter size of factor loading matrices, the similarity between matrices 
is further evaluated for an optimal solution to FA model sharing. Generally, FASHMM fulfills the 
streamed Markov chains for a sequence of multivariate Gaussian mixture observations through state 
transitions of the partitioned vectors. A new decoding algorithm is presented for FASHMM based 
speech recognition. 
It is well-known that the statistical language model has been successfully developed in many 
information systems, e.g. speech recognition, machine translation and information retrieval. This 
project presents a new minimum rank error (MRE) algorithm for n-gram language model training. The 
language models are estimated for information retrieval according to the metric of average precision. 
However, the maximization of average precision is comparable to minimizing the rank error or 
optimizing the order of the ranked documents. We accordingly calculate the rank error loss function 
from the misordering pairs of relevant and irrelevant documents in rank list. The Bayes risk due to the 
expected rank loss is minimized to develop the Bayesian retrieval rule for ad-hoc information retrieval. 
Correspondingly, the discriminative training of language model is performed by integrating the 
discrimination information from the relevant documents relative to the irrelevant documents. 
Finally, we propose a novel Bayesian adaptation algorithm for support vector machines (SVM). In 
state-of-art researches, support vector machine has attracted many researchers with considerable 
interests in related fields due to its power of model generalization. Continuous advances in SVM have 
led to many successful applications, such as information retrieval, speech recognition, and face 
  
V
目錄 
中文摘要................................................................................................................................................... I 
Abstract .................................................................................................................................................. III 
目錄......................................................................................................................................................... V 
First Year Project: Factor Analysis Streamed Hidden Markov Model .................................................... 1 
1. INTRODUCTION ....................................................................................................................... 1 
2. CEPSTRAL FACTOR ANALYSIS ............................................................................................ 1 
3. FA STREAMED HMM ............................................................................................................... 4 
4. EXPERIMENTS .......................................................................................................................... 7 
5. CONCLUSIONS.......................................................................................................................... 9 
6. REFERENCES .......................................................................................................................... 10 
Second Year Project: Minimum Rank Error Language Model ............................................................. 11 
1. INTRODUCTION ..................................................................................................................... 11 
2. RELATED WORKS .................................................................................................................. 11 
3. MINIMUM RANK ERROR TRAINING ................................................................................. 13 
4. EXPERIMENTS ........................................................................................................................ 16 
5. CONCLUSIONS........................................................................................................................ 17 
6. REFERENCES .......................................................................................................................... 17 
Third Year Project: Recursive Bayesian Regression Model .................................................................. 19 
1. INTRODUCTION ..................................................................................................................... 19 
2. RELATED WORKS .................................................................................................................. 19 
3. RECURSIVE BAYESIAN REGRESSION .............................................................................. 21 
4. EXPERIMENTS ........................................................................................................................ 23 
5. CONCLUSIONS........................................................................................................................ 24 
6. REFERENCES .......................................................................................................................... 25 
  
2
find that the cepstral coefficients make considerable changes at different time moments. The 1st 
MFCC and 13th MFCC have similar transition time, but the movement of 4th MFCC is different from 
that of 1st and 13th MFCC. The transitions in Markov chains or the boundaries of HMM states should 
be represented by the streamed HMM where the features in the same stream are similarly behaved and 
modeled by the shared Markov chain. In this study, we are presenting a factor analysis approach to 
capture the correlations among features and the regularities for state transitions. 
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45
-15
-10
-5
0
5
10
15
Time (sec)
M
FC
C
 
 
13th MFCC
1st MFCC
4th MFCC
 
Figure 1: Dynamics of different cepstral features of TIDIGIT “4”. 
 
2.1. Factor Analysis 
Statistical factor analysis (FA) is a machine learning approach to discovering the correlations inherent 
in observation data. FA was applied for front-end preprocessing of noisy speech signal [2]. It was also 
used to construct the HMM covariance matrix for speech recognition [9][10]. Different from the 
processing in signal domain [2] and model domain [9][10], we are applying FA approach both in 
feature domain and in model domain. We are detecting the correlations among features via FA method 
and merging these correlations in HMM modeling. 
FA conducts data analysis of the multivariate observations using the common factors and the 
specific factors. For a D  dimensional feature vector TDyy ],[ 1 y , the general form of FA model is 
given by 
εfWy  f ,                                                               (1) 
where f  and ε  denotes 1M  common factor and 1D  specific factor and are independently 
Gaussian distributed by densities ),0( IN  and ),0( ψN , respectively. The MD   matrix fW  is called 
the factor loading matrix with each entry recording the correlation between feature dy  and common 
factor mf . We should estimate FA parameters }  { f εfW ,, . Using the maximum likelihood estimation 
[11], we can find a DD  transformation matrix W  by FA procedure. By dividing W  into two 
complementary sub-matrices ] [ rf WWW  , we rewrite (1) by rf yyy   rWfW rf   and 
accordingly estimate f  and ε  by ff yWf T  and rWyε rr  , respectively. Here, we are motivated 
to interpret different dynamics in acoustic features by common factors and specific factors. The 
features with high correlation should contribute the specific factor loading weights. We use separate 
Markov chains to model the dynamics caused by the common factor and the residual factor. We 
  
4
Mf
ts 1
1
1
f
ts 
r
1ts
1ty ty 1ty
r
ts r 1ts
Mf
ts M
f
ts 1
1f
ts 11
f
ts 
      
 
Figure 2: Topology of FASHMM. 
 
3. FA STREAMED HMM 
Using FA, the processes of observed features and hidden states are represented by common factors 
and residual factors. We intend to use separate Markov chain to model the movements of acoustic 
features corresponding to different factors. Figure 2 shows new topology based on the proposed FA 
streamed HMM (FASHMM). Markov chains are driven by common factors },,{ 1 Mff   and residual 
factor r . At each frame t , we use several states to generate the feature vector ty . This is similar to 
the topology of FHMM [5]. FHMM was seen as a Bayesian belief network which was composed of 
more than one stream. Markov chain at each stream was used to characterize the dynamics of feature 
vector. Nevertheless, the streams in FHMM had the inputs of observed features instead of those of 
common factors and residual factors used in FASHMM. 
 
3.1. Survey of Different HMMs 
In standard HMM, the joint probability of observation sequence },,,{ 21 TY yyy   and state 
sequence },,,{ 21 TsssS    was represented by 



T
t
tttt spsspspspYSp
2
1111 )|()|()|()(),( yy ,                                       (5) 
where ty  was a 1D  feature vector. Using FHMM, the state at time t  was extended to M  states, i.e. 
)()()1( ,,,, Mt
m
ttt ssss  . FHMM was also related to the multi-stream HMM [4]. In multi-stream 
HMM, the likelihoods at different streams were combined at subword level. This was different from 
FHMM where the combination was done at frame level. Using FHMM, the state transition of one 
stream was constrained to be independent to that of other streams. The state transition probability was 
given by 


 
M
m
m
t
m
ttt sspssp
1
)(
1
)(
1 )|()|( .                                                   (6) 
Also, the calculation of likelihood function )|( tt sp y  involved M  states. The likelihood function was 
defined by a Gaussian density with a common covariance matrix and a mean vector which was a 
linear combination of means for a HMM state [5] 
  
6
. )|()|()|()(),(
1 1
r
1 1
r
1
r









 








 

    
  
T
t
M
m
f
tmt
T
t
M
m
f
ijij
M
m
f
ii
mmm sfpspaaSYpSpYSp r    (11) 
Parameters },,,,,,,,,{
2rrrrr m
kk
m
kk
m
kk
f
ijij
f
ii ccaa mm  Σμ  are constructed. In model training 
procedure, we perform the maximum likelihood (ML) estimation of FASHMM parameters   through 
the expectation-maximization algorithm. The expectation function of new estimate   given current 
estimate   is determined by 
 
.
)|(log)|(log        
loglogloglog
),|()'|,(log),|()|'(
1 1
r
1 1
r
1
r





















 







 

 

 
 

 
 
T
t
M
m
f
tmt
T
t
M
m
f
ijij
M
m
f
ii
SS
m
mm
sfpsp
aa
YSpYSpYSpQ
r


(12) 
 
By maximizing )|( Q  with respect to  , we can find the closed-form solutions given below 
Mm
kiγ
fkiγ
T
t
f
t
T
t
tm
f
t
f
ik
m
m
m ,,1   ,
),(
),(
1
1
,




 ,     



 T
t
t
T
t
tt
ik
kiγ
kiγ
1
r
1
r
r
),(
),( r
μ                            (13) 
Mm
ki
fki
T
t
f
t
T
t
f
iktm
f
t
f
ik
m
mm
m ,,1   ,
),(
))(,(
)(
1
1
2
,
2 








 ,      





 T
t
t
T
t
T
iktiktt
ik
ki
ki
1
r
1
rrr
r
),(
))()(,(

 μrμr
Σ    (14) 
where ),( kimft  and ),( kitr  are the occupation probabilities for state ist   and mixture k  at different 
stream m  and time t . 
At each time moment, we accumulate log-likelihood score for each stream. A simple approach is 
to set equivalent stream weight. But, in FA model, one common factor shall represent more than one 
feature component. The stream weight should be adaptive. In this project, we calculate the stream 
weights from the columns of the rotated factor loading matrix }{ ijhH . The weight function j  in 
stream j  is empirically determined by taking absolute values of entries }{ ijh  and computing the ratio 
of those values in column j  over all columns. For simplification, we integrate the stream weights of 
the first M  common factors into one shared weight. 
 
3.3. Implementation Procedure 
Typically, using the proposed FASHMM, we are able to incorporate multiple Markov chains to model 
a multivariate input sequence of features for speech recognition. We are not only extracting the salient 
common factors but also modeling the dynamics of common factors containing highly correlated 
features. In training procedure, similar to standard HMM, we first collect acoustic feature vectors 
corresponding to different words through Viterbi decoding algorithm and then estimate the word 
  
8
and their first and second derivatives. In standard HMM, we fixed 16 states for each digit and one 
shared state for all silence segments. Number of mixture components in a HMM state was four at most. 
In the evaluation, we changed the number of states for different streams. In FA procedure, we used 
maximum likelihood approach to estimate factor loading matrix and then find common factors and 
residual factors [11]. 
2 4 6 8 10 12 14 16 18 20
-2550
-2500
-2450
-2400
-2350
-2300
Iteration
Lo
g 
Li
ke
lih
oo
d
 
 
FASHMM-(16,16)
FASHMM-(10,16)
FASHMM-(6,16)
SFHMM
HMM
 
Figure 4: Evaluation of log likelihood function 
 
4.2. Evaluation of Likelihood Function 
In what follows, we calculate the accumulated log-likelihood to evaluate the goodness-of-fit 
performance of training data using different methods. We compare the standard HMM, the streamed 
FHMM (SFHMM) [6] and the proposed FASHMM. Without loss of generality, only two streams are 
considered. In SFHMM, we used three features of log-energy and its first and second derivatives in 
the first stream. The remaining 36 features of 12 MFCCs and their first and second derivatives were 
collected in the second stream. In implementation of FASHMM, we also used 3 and 36 acoustic 
features in the first and the second streams, respectively. The assignment of acoustic features to two 
streams was determined automatically by FA principle. Number of states was varied at two streams. In 
Figure 4, we fixed 16 states in the second stream and used 6, 10 and 16 states in the first stream. We 
can see that SFHMM-(16, 16) and FASHMM attain higher likelihood score that standard HMM. In 
case of using 10 and 16 states in the first stream, FASHMM has better likelihood score compared to 
SFHMM. 
 
4.3. Recognition Results 
In evaluation of speech recognition, we compare the word error rate (WER) of using standard HMM, 
SFHMM, and different realizations of FASHMM in Table 2. Error rate reduction is reported in the last 
column. In realizations of FASHMM, we change the number of features and the number of states at 
each stream. The streamed HMMs using SFHMM and FASHMM outperform the conventional HMM 
without streaming process. Also, different realizations of FASHMM do decrease the word error in 
comparison with SFHMM. The best performance is obtained by setting 5 and 34 features and 6 and 16 
states for the first stream and the second stream, respectively. Error rate reduction is 35.8% at most. 
Attractively, this realization does not only attain the lowest word error but also involve the smallest 
model complexity among the streamed HMM methods. 
  
10
[7] A. Nadas, D. Nahamoo and M. A. Picheny, “Speech recognition using noise-adaptive prototypes”, 
IEEE Transactions on Acoustic, Speech, and Signal Processing, vol. 37, no. 10, pp. 1495-1503, 
1989. 
[8] L. R. Rabiner and B.-H. Juang, Fundamentals of Speech Recognition. Englewood Cliffs, NJ: 
Prentice-Hall, 1993. 
[9] A.-V. I. Rosti, M. J. F. Gales, “Factor analyzed hidden Markov models for speech recognition”, 
Computer Speech and Language, 2004. 
[10] L. K. Saul and M. G. Rahim, “Maximum likelihood and minimum classification error factor 
analysis for automatic speech recognition”, IEEE Transaction on Speech and Audio Processing, 
vol. 8, no. 2, pp. 115-125, 2000. 
[11] M. S. Srivastava, Methods of Multivariate Statistics, John Wiley & Sons, 2002. 
[12] T. Virtanen, “Speech recognition using factorial hidden Markov models for separation in the 
feature space”, Proc. of International Conference on Spoken Language Processing 
(INTERSPEECH), pp.89-92, 2006. 
 
 
 
 
  
12



K
kQw
dkdK MwPMwwwPDQP
1,
21 )|()|,,,()|(  .                                (1) 
This unigram model can be easily extended to the n-gram model. Nevertheless, there is no reference 
of class variable C  that denotes the relevance or the irrelevance. Given a query and a set of 
documents, the retrieval system ranks the documents based on the maximum a posteriori decision 
rule and finds the optimal document D for a given query 
)()|(maxarg)|(maxargˆ DPDQPQDPD
DD
 ,                              (2) 
where )|( DQP  is the likelihood of a query given a document model, )(DP  is the prior probability 
that document D is relevant. 
 
2.2 MCE Discriminative Training 
In MCE training of acoustic models for speech recognition, a loss function [8][9] was calculated to 
approximate the classification error of speech recognizer. A misclassification measure was defined by 


1
,
))|(exp(log  
1
1log)|(log)( 



  iri CCC irr CxPCCxPxd ,                        (3) 
where   was a positive number, C was the number of classes, )|( rCxP  and  )|( iCxP  were the 
likelihood functions of target (relevant) and competing (irrelevant) classes. The sigmoid function was 
used to define the class loss function [8][9] as  
))(exp(1
1))((   xdxdl rr ,                                            (4) 
where   and   were control parameters for the slope and the offset of the function, respectively. 
However, such a classification framework should be modified and followed by the metric used for 
information retrieval. Also, this misclassification error could not reflect the metric of average 
precision as a measure for information retrieval. Minimizing the classification error does not 
guarantee the high ranking of test documents. To deal with this issue, we develop a new learning 
algorithm of language model by optimizing the retrieval performance with the highest average 
precision. 
 
2.3 Average Precision versus Classification Accuracy 
Average precision is the average of precision computed after truncating the list after each of the 
relevant documents in turn. Let us consider two systems that produce probability estimates for a set of 
10 documents. We assume that both systems retrieve five as relevant documents and the other five as 
irrelevant documents. We rank the test documents according to the probability of + (relevant), as 
shown in Table 1. If we calculate average precision, we obtain 1 ((1/1+2/2+3/3+4/4)/4) and 0.6792 
((1/2+2/3+3/4+4/5)/4) for retrieval system 1 and system 2, respectively. However, we see that two 
systems for binary classification have the same classification accuracy 80% and thus they are 
equivalent in terms of classification accuracy. Clearly, we know that system 1 is better than system 2 
since system 1 shows a better overall ranking performance. 
 
  
14
3.2 Maximum Average Precision & Minimum Rank Error 
In a document retrieval system, X is the set of documents which answer the given queries Q. For each 
query, the training documents are comprised of a relevant set rX  and an irrelevant set iX . The 
matching score of a document d with respect to a given query q can be defined by a discriminant 
function )(xf . Let ir xx   denote that rx  is ranked higher than ix . The objective function is defined 
by considering the classification rule  
IiRririr SxSxxfxfxx  ,),()( .                                        (5) 
The loss functions should be related to the number of rank errors that decision function f makes on the 
training set. The rank error rate [3][14] is the number of a lower scoring irrelevant document that is 
incorrectly ranked above the relevant document. This objective is determined by the probability of 
misordering a document pair ),( ir xx , i.e. occurring )()( ri xfxf  . The rank errors are accumulated by 
 
 
 

 




Qq rixx
itrt
Qq rixx
itrt
rixx
ri
t ri
t riri
xqPxqPI
xqfxqfIxfxfPXError
,,
,,,,
)];|();|([  
)];,();,([  )]()([)(
,              (6) 

 
otherwise ,0
0for   ,1
][
y
yI ,                                                             (7) 
where ][yI  is an indicator function and   is language model. In (6), the discriminant function is 
written by );|();,()(   xqPxqfxf tt . We can define the total distance measure by 
);|(log max);|(log)P;(   idrr XQPXQPXd i ,                               (8) 
which is the difference between the log likelihood scores of the target document and the most 
competing document. If this distance is negative, no rank error is induced. It is easy to see that 
minimizing (6) is equivalent to maximizing the average rank of the relevant documents. Let xyn denote 
the number of class-x input tokens which are classified as class-y. Here, x, y have the labels r  and i  
corresponding to the relevant state and the irrelevant state, respectively. Figure 2 illustrates the metric 
of average precision. 
Relevant  documents
Retrieved
Non-retrieved
Irrelevant documents Rank List
rrn 
irn 
rin 
iin 
Rank 1
Rank 2

 
Figure 2: Illustration of the metric of average precision 
  
16
4. EXPERIMENTS 
In the experiments, we evaluate the performance of proposed MRE training of language model using 
two TREC collections. One is the Associated Press Newswire (1988) (AP88) dataset consists of 
79,919 documents and the other dataset is the Wall Street Journal (1987) (WSJ87) consists of 46,448 
documents. 
4.1 Evaluation of Model Perplexity 
When evaluating model perplexity, we used Wall Street Journal dataset as training data for language 
model estimation. The Associated Press Newswire dataset is used as the test data. For comparison, we 
carried out the baseline language model using maximum likelihood (ML) estimation. Discriminative 
language model via MRE training was realized. During MRE training procedure, we adopted the 
parameters 1 , 1  , 0   and 5.0  . Table 2 reports the perplexity for unigram and bigram 
language models based on ML and MRE training. The baseline unigram and bigram obtain the 
perplexity of 1781.03 and 443.55, respectively. The perplexity is reduced to 1775.65 of unigram and 
440.38 of bigram, which are trained using MRE algorithm. The perplexities of two methods are 
comparable because MRE discriminative training does not aim to improve the ability of language 
model to predict unseen texts. MRE aims to maximize average precision rather than improve the 
performance of data fitting. 
 
Table 2: Comparison of perplexity using ML and MRE language models 
 ML MRE 
Unigram 1781.03 1775.65
Bigram 443.55 440.38 
4.2 Experimental Results on Information Retrieval 
In the next set of experiments, we evaluate the performance of discriminative training on the TREC 
ad-hoc information retrieval task. There were two query sets and the corresponding relevant 
documents in this collection. We used TREC topics 51-100 as training queries and the TREC topics 
101-150 as test queries. Queries were sampled from the ‘title’ and ‘description’ fields of the topics. 
The average length of these queries contained about 8-12 words. In both training and test sets, we 
used ML language model as the baseline system. In each query test, we retrieved 1000 documents and 
calculated the average precision over all topics. To test the significance of improvement between two 
methods, Wilcoxon test [7] was employed in the evaluation. Table 3 compares the average precision 
on two datasets using ML and MRE training. For both datasets, MRE outperforms ML. Average 
precision is improved by 10.9% and 13.1% on two data. Table 4 highlights the evaluation of precision 
in document level using AP88 dataset. MCE training is also compared. R-precision is a measure of 
precision after R documents are retrieved where R is the number of relevant documents in the 
collection for a query. We find that a significant increase in averaged precision is obtained when 
comparing MRE over ML. The Wilcoxon test specifies the significance of improvement in precision 
is at the 5% threshold level. In some cases, MRE is not significantly better than MCE. 
 
Table 3: Comparison of average precision using two TREC datasets 
Collection  ML MRE Improvement Wilcoxon 
WSJ87 0.1012 0.1122 10.9% 0.0163* 
AP88 0.1692 0.1913 13.1% 0* 
  
18
[6] J. Huang and C. X. Ling, “Using AUC and Accuracy in Evaluating Learning Algorithms”, IEEE 
Trans. Knowledge and Data Engineering, vol. 17, no. 3, pp.299-310, 2005. 
[7] D. Hull, “Using statistical testing in the evaluation of retrieval experiments”, in Proc ACM 
SIGIR, pp. 329-338, 1993. 
[8] B. H. Juang, W. Chou, and C.-H. Lee, “Minimum classification error rate methods for speech 
recognition”, IEEE Trans. Speech and Audio Processing, pp. 257-265, 1997. 
[9] B.-H. Juang and S. Katagiri, “Discriminative learning for minimum error classification”, IEEE 
Trans. Signal Processing, vol. 40, no. 12, pp. 3043-3054, 1992. 
[10] H.-K. J. Kuo, E. Fosler-Lussier, H. Jiang, and C.-H. Lee, “Discriminative training of language 
models for speech recognition”, in Proc. ICASSP, pp. 325-328, 2002. 
[11] R. Nallapati, “Discriminative models for information retrieval”, in Proc. ACM SIGIR, pp. 64-71, 
2004. 
[12] J. M. Ponte and W. B. Croft, “A language modeling approach to information retrieval”, in Proc. 
ACM SIGIR, pp.275-281, 1998. 
[13] G. Salton, and M. J. McGill, Introduction to Modern Information Retrieval. McGraw-Hill, New 
York, 1983. 
[14] J.-N. Vittaut and P. Gallinari, “Machine learning ranking for structured information retrieval”, in 
Proc. 28th European Conference on IR Research, pp.338-349, 2006. 
  
20
Using SVM, we are seeking the optimal hyperplane bf T  zwzw ),( , which has the maximum 
margin between support vectors of two classes. Vapnik [13] also extended SVM to kernel-based 
support vector regression (SVR). In SVR, training samples of a class are represented by 
ii
T
i by   zw .                                                          (1) 
This  insensitive loss function [13] was presented to obtain the sparseness property of SVM. Hence, 
we have  ),(, * wx iiii fy   as a modeling error with value of   being margin width.   is 
empirically defined. Using this loss function, the estimation accuracy of outliers will not hurt too 
much. The optimal parameters of w  and b  are obtained according to the least square error criterion 



n
i
iiC
1
2 )(
2
1 w .                                                          (2) 
How to automatically determine regularization parameter C  for various datasets becomes a crucial 
issue. Kwok [5] illustrated the relationship between SVM and MacKay’s Bayesian framework. The 
hyperparameters of SVM were estimated by maximizing the evidence. 
In SVR model [6], the parameter w  was assumed to be random and C . Meaningfully, the 
hyperparameter   controls the model complexity. The hyperparameter   controls the training error. 
The prior distribution of w  is Gaussian distributed  
)
2
exp()( 2ww  p .                                                      (3) 
Assuming training samples are i.i.d., the output distribution of training samples D  is [5]  
 )(),,(),,(),(
11 i
n
i ii
n
i ii
pypypDp zwzwzw     ,                      (4) 
where an exponential distribution is specified as 
)1(2
)exp(
),,( 
 
 iiiyp wz .                                                (5) 
The posterior probability of w  can be formulated by 
 www
ww
w
dpDp
pDp
Dp
)(),(
)(),(
),,( 
 .                                           (6) 
The optimal parameter of w  is calculated by maximizing this posterior probability. Optimal MAP 
estimate MAPw  is used to approximate the evidence in (6). Optimal values of   and   are then 
obtained by iterating the process of finding MAPw  and maximizing the evidence. Parameter b  is 
determined correspondingly. The integral in evidence is done in accordance with MacKay’s evidence 
framework [8]. In [1], SVR was regarded as a classification problem in the dual space. No model 
learning was concerned in these works. 
 
2.2. Relevance Vector Machine 
Accordingly, Tipping [12] presented Bayesian learning via a relevance vector machine (RVM). 
Different from Bayesian SVR [6], RVM assumed that parameters α  and   are random. The training 
samples are represented as  
j
n
i
ijij bKwy 
1
),( xx .                                                       (7) 
  
22
where   can be regarded as the margin between two classes. The model parameters turn out to be 
Tb ],,[~ ww   and the input pattern can be extended to TiTii c ],1,[~ zz  . We can find the least-square 
solution to regression parameters w~  by minimizing 
)~~()~~(
1
2 wZywZyξξ 

TT
n
i
i ,                                              (14) 
where Tn ]~,,~[
~
1 zzZ  . Reducing this expected error is able to achieve maximum margin and 
minimum classification error. The least-squares estimator is built by yΦZw 1~~ˆ  T  where 
T
n ]
~,,~[~ 1 ΦΦΦ   is a nn  matrix given Tniii ]~~,,~~[~ 1 zzzzΦ   . We can rearrange (14) to be [9] 
)]ˆ~(~[)]ˆ~(~[)ˆ~()ˆ~()~~()~~( wwZwwZwZywZywZywZy  TTT                    (15) 
After careful derivation and consideration of (10)(15) and the assumption in RVM, we write the 
likelihood function in a form of 










   

 exp)ˆ~( )ˆ~(
2
exp
)2(
1),,~( 1)2(
1
)2(2/ ww1R1wwwy dnnd
T
np      (16) 
where 1~ ΦR , 2/)2(  n , )ˆ~()ˆ~( -1 wZywZy  T  and  1 ij1  for all ji, . In (16), the first 
term is viewed as a Gaussian density for w~  given  , and the second term is viewed as a gamma 
density for  . This distribution is known as normal-gamma distribution. 
 
3.2. Recursive Bayesian for Incremental Learning 
To activate incremental learning, we select the prior density of regression parameters w~  and   as 
a conjugate prior [3], which is a normal-gamma distribution 
),,,ˆ(GammaNormal),~(  Rww p .                                           (17) 
Advantage of considering this conjugate prior is twofold. First, the prior density and the pooled 
posterior density belong to the same distribution family so that the incremental learning mechanism 
can be activated. Second, the computation of model parameters is efficient because the mode of 
posterior density turns out to be MAP estimate. In incremental learning, we collect a sequence of 
block data },,{ )()1( TT DDD   for model adaptation in individual epoch. At learning epoch t , we 
have current block data tni
t
i
t
i
t yD 1
)()()( )},{(  z  and sufficient statistics accumulated from previous data 
sequence },,{ )1()1(1   tt DDD  . We are calculating the posterior distribution, which combines the 
likelihood function of current block data )(tD  and the prior density calculated from historical data 
1tD  
  
24
pixels. As shown in Figure 1, ba, bj and bk indicate the frontal images. bj and bk has different facial 
expression and lighting condition, respectively. bb through bi is a series of images under different 
pose angles. 
To test system robustness, for each person, we adopted three images, ba, be, and bf, to train the 
initial prior model in (16)(17). Number of adaptation data for initial prior model was equivalent to 0. 
We performed five-fold cross validation through random selection from the other images. For each 
person, four images were selected for examination of batch learning as well as incremental learning. 
The remaining four images served as test images. Here, we used RBF kernel function   22RBFexp),( jijiK xxxx   .                                             (20) 
with the given parameter 1002RBF  . The regularization parameter C  was obtained by Bayesian 
SVM method [5]. 
0 1 2 3 4
84
85
86
87
88
89
90
R
ec
og
ni
tio
n 
A
cc
ur
ac
y 
(%
)
Number of Adaptation Data
 RBR
 RVM
 Batch SVM
 Incremental SVM
 
Figure 2: Comparison of recognition accuracies (%) using SVM, RVM and RBR. 
 
4.2.Experimental Results 
In Figure 2, we compare the results of the proposed recursive Bayesian regression (RBR) algorithm, 
SVM and RVM. These methods are based on binary classification, one-against-one strategy. Class 
number is 200. Batch SVM [13], incremental SVM [4] and RVM [12] were carried out. The proposed 
RBR method achieves over 85% recognition accuracy. The accuracies of RBR method are better than 
batch SVM, incremental SVM and RVM. We do see the consistent improvement by increasing 
number of adaptation data. These results show a significant performance by adapting the facial kernel 
regression when testing on the data in different environments. 
 
5. CONCLUSIONS 
We have presented a novel recursive Bayesian regression approach for online pattern recognition. 
Importantly, the relations to SVM, SVR and RVM were illustrated. The updating mechanism of 
sufficient statistics was developed. The advantages of proposed RVR method were its fast and robust 
capabilities. We have shown the improvement of face recognition compared to SVM and RVM. The 
incremental learning improvement from adaptation data was confirmed. The spirit of SVM with 
maximum margin and minimum error will be illustrated in the future. 
 
 
出席國際學術會議心得報告 
                                                             
計畫編號 前瞻性機器學習法應用於語音、語言及圖形辨識(3/3) 
計畫名稱 NSC 97-2221-E-006-230-MY3 
出國人員姓名 
服務機關及職稱 
簡仁宗 國立成功大學資訊工程學系 教授 
會議時間地點 九月二十六日至九月三十日 參加於日本幕張舉行之 INTERSPEECH  
會議名稱 
(中文) 2010年國際語音通訊學會學術研討會 
(英文) 2010 Annual Conference of the International Speech Communication 
Association (INTERSPEECH 2010) 
發表論文題目 
(中文) 線上高斯程序應用於非穩定語音分離 
(英文) Online Gaussian Process for Nonstationary Speech Separation 
 
一、參加會議經過 
 
出國開會行程報告： 
九月二十六日 早上從台南出發搭乘接駁巴士至高雄小港國際機場，搭乘日亞航飛機於中
午到達日本東京成田國際機場，然後再搭火車及計程車至下塌飯店，短暫
休息後隨即乘座飯店接駁巴士至 INTERSPEECH 會場 International 
Conference Hall - Makuhari Messe International Convention Complex領取大
會註冊資料及論文集並了解演講和海報會場，與外國友人短暫寒暄。 
九月二十七日 參加 INTERSPEECH Open Ceremony及聆聽會議議程，並於下午發表口頭
演講式論文「線上高斯程序應用於非穩定語音分離」，晚上七點參加
Welcome Reception，地點在 Hotel New Otani Makuhari，現場提供飲料及豐
富餐點。 
九月二十八日 參加 INTERSPEECH研討會及聆聽會議議程。 
九月二十九日 參加 INTERSPEECH研討會及聆聽會議議程，晚上參加晚宴，地點在 Apa 
Hotel & Resort Tokyo Bay Makuhari，大會提供日本傳統音樂「津輕三味線」
等表演，極富日本風味，精采有趣。 
九月三十日 參加 INTERSPEECH研討會及聆聽會議議程，下午離開會場並搭乘火車至
成田國際機場搭飛機回高雄再搭接駁巴士至台南，到達台南為九月三十日
晚上十一點半。 
 
者、期刊負責人接觸、討論並交換意見，是我這次開會最大的收穫。希望國內大學教授或研
究生應該多多參加國際會議，以拓展個人的研究視野，這對台灣學者往後的生涯有很大的助
益，國科會或教育部也應該繼續秉持此一信念，多鼓勵國內專家學者出國參加國際會議，我
們國家的形象及實力也會因此而提高。另外，我也建議往後我國應該要積極爭取舉辦大型的
國際會議，如此，對國家形象的提昇有很大的助益。這次會議攜回資料名稱及內容有一、會
議論文摘要集，二、會議論文集光碟片(儲存所有會議論文)，三、未來相關國際會議資料(可
供國內學者參考)，四、語音處理相關的期刊數本。 
background music signal .3s  As the time evolves from t to 
,1t  the mixing matrix }{ nmaA   should be changed as 
)1()(  tt AA  to reflect the nonstationary speaking 
environment. For example, the first speaker 1s  may move and 
his distance to the second sensor is changed from 1d  to .1d   
The resulting change occurs in mixing coefficient )1(21
)(
21
 tt aa  
which depends on a time-varying function of the distance 
between sensor and source. The second speaker 2s  and the 
music 3s  have no change, then 
)1(
22
)(
22
 tt aa  and .)1(23)(23  tt aa  
At the next time frame ,2t  the first speaker may stop talking 
and simultaneously a new speaker comes in the party to replace 
the second speaker. For this scenario, the mixed signals are 
obtained due to the changes of coefficients  0)2(21 ta  and 
.)2(22
)1(
22
  tt aa  In this study, we deal with a nonstationary 
cocktail-party problem. The temporal structure of time-varying 
mixing matrix )(tA  is characterized by a Gaussian process (GP). 
 
 
)(
21
ta
)1(
23
)(
23
 tt aa
)1(
21
ta
)1(
22
)(
22
 tt aa
)2(
22
ta
1S
2S 0)2(21 ta
)2(
23
)1(
23
  tt aa21  tt
3S
1d
'
1d 3
d
'
2d
2d
3d
1S
2S
3S
 
Figure 1: Scenarios in a nonstationary cocktail-party problem. 
 
 
 
2.2. Speech separation using Gaussian process 
 
Speech signals are temporally correlated. It is important to 
incorporate temporal information in a speech separation system. 
Gaussian process is known as a mechanism of characterizing 
the temporal structure of observation data. The probability 
distributions of GP are latent and can be expressed as the space 
of functions Sf :  where any subset of the variables has a 
joint Gaussian distribution. Different from the parametric model 
using autoregressive model, GP is a nonparametric latent model 
which is specified by a mean function )( )(tmm s  and a covariance 
function ),,( )()(  mtm ss  i.e. 
 
)),(),((GP~)( )()()( )(  mtmtmtm mf ssss                    (1) 
where 
)]([)( )()( tm
t
m fEm ss                                  (2) 
))](-)())((-)([(),( )()()()()()(  mmtmtmmtm mfmfE ssssss  .      (3) 
 
Here, )(tms  and 
)(
ms  denote the speech samples at the mth source 
in time frames t  and .  For simplicity, the mean function is 
usually assumed to be zero. Some covariance functions or 
kernels are available in [14]. In [9], Gaussian process priors 
were combined into the factor analysis model for representation 
of spatio-temporal data. In [12], GP model was used to 
characterize the temporal structure of source signal via the 
distribution of latent functions )(f  which related the current 
source sample to its past samples. A Gaussian process prior was 
merged and the pseudo-likelihood estimation was performed. 
Compared with the autoregressive process, GP is more flexible 
and allows the nonlinear time series as source signals. However, 
these methods were designed to explore the temporal structure 
of source signals rather than that of the nonstationary mixing 
system which is more realistic in nonstationary BSS. We are 
motivated to conduct an online Gaussian process for mixing 
coefficients and perform the dynamic source separation. 
 
3.  Online Gaussian Process 
 
3.1. Online Bayesian learning 
 
Typically, the environmental conditions of the mixed signals 
are changed naturally as time moves on. A flexible ICA 
procedure should be established by relaxing the assumptions in 
standard ICA where the number and the distribution of sources 
are varied with time. It is preferable to perform online speech 
separation by Bayesian framework. This paper presents a new 
online Gaussian process ICA (OLGP-ICA) algorithm to 
incrementally characterize the temporal structure of the time-
varying mixing matrix and to estimate the GP parameters to 
identify dynamic sources. The sufficient statistics from previous 
frames is merged with the likelihood of current frame and is 
propagated for adaptive speech separation. The mixing matrix 
and the distributions of source signals are incrementally 
estimated instead of performing Markov chain for each source 
signal in switching ICA [2][5]. The computational load can be 
reduced accordingly. Our idea is to incrementally detect the 
source signals and estimate the corresponding distributions 
from online observation data }.,,,{ )()2()1( tt XXX   Since 
different scenarios of the nonstationary conditions are 
considered, the mixing coefficients have prominent temporal 
structure in essence. The GP is applied to express the nonlinear 
time series appearing in the mixing matrix. The time-dependent 
parameters are incrementally estimated instead of running time-
consuming Markov process for each source signal [5]. At each 
time frame t, we estimate ICA parameter )(t  by maximizing 
the posterior distribution using t . The posterior distribution 
)|( )( ttp   is calculated through the stages of prediction and 
correction. Given the historical data ,1t  the prediction of the 
parameters )(t  is obtained according to the probability 
)|( 1)( ttp   calculated by 
  )1(1)1()1()( )|()|( ttttt dpp  .               (4) 
When a new frame )(tX  is observed, the prediction is corrected 
by 
 


)(1)()()(
1)()()(
)(
)|()|(
)|()|()|(
ttttt
tttt
tt
dpXp
pXpp

 .       (5) 
Different from the batch training [2][5], we present an efficient 
approach to detect the status of each source signal and to 
estimate the distributions of reconstructed source signals at each 
frame. This online learning works for dynamic source 
separation under different scenarios [7]. 
 
 
3.2. OLGP model construction 
In model construction using OLGP, the noisy ICA model 
)()()()( tttt ESAX   with a noise term LiittE 1),()( }{  ε  is 
adopted for data generation. Let Li
ittX 1
) ,()( }{  x  denote a set 
of L mixed samples acquired from N microphones. These mixed 
samples are modeled by a linear mixture of M  unknown 
independent source signals .}{ 1
) ,()( L
i
ittS  s  The graphical 
representation of OLGP model is depicted in Figure 2. 
Assuming that each entry of the MN   time-varying mixing 
entries of mixing matrix represent the relative position and 
distance between sources and sensors. The first and the second 
sources relative to the sensors had a changing rate of 
20/11 f Hz and 10/12 f Hz, respectively. Figure 3 displays 
four nonstationary mixing coefficients .},,,{  )(22
)(
21
)(
12
)(
11
tttt aaaa  
Figure 4 shows the waveforms of two channels which contained 
two speakers and one background music which were sampled 
from http://www.kecl.ntt.co.jp/icl/signal/. In the first channel, a 
male speaker was inactive at 2 sec and the music signal was 
active at 3 sec, and so the distribution of the source signal was 
changed. The scenario of switching and moving sources was 
considered. In the second channel, the female speaker was 
inactive at 3 sec and active at 4 sec. The scenario of presence 
and absence of the same speaker was examined. In the 
implementation, the online signal separation was performed 
with a time window of 0.25 sec. For comparison, the variational 
Bayesian ICA (VB-ICA) [8], the switching ICA [5], the 
Bayesian ICA with hidden Markov sources (BICA-HMM) [2] 
and the online VB-ICA [6] was implemented. The demixed 
signals of OLGP-ICA were displayed in Figure 4. We provided 
the waveforms of original signals, mixed signals and demixed 
signals at http://chien.csie.ncku.edu.tw/~olgp. The signal-to-
interference ratios (SIRs) of two demixed signals were reported 
in Table 1. The proposed OLGP-ICA achieved the highest SIR 
among different methods. In our investigation, OLGP-ICA 
significantly saves 73% of running time compared to the 
switching ICA [5] when implementing on a personal computer 
with a core 2 quad 2.4GHz CPU and a memory of 8 GB. 
 
 
 
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-1
-0.5
0
0.5
1
sec
 
a11
a12
a21
a22
  
Figure 3: Four nonstationary mixing coefficients. 
 
 
 
 
 
0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-0.1
0
0.1
Original signal 1
sec
0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-0.1
0
0.1
Original signal 2
sec
0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-0.1
0
0.1
Mixed signal 1
sec
0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-0.1
0
0.1
Mixed signal 2
sec   
0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-0.1
0
0.1
Demixed signal 1
sec
0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-0.1
0
0.1
Demixed signal 2
sec      
 
Figure 4:  Waveforms of source signals, mixed signals and 
demixed signals using OLGP-ICA. 
Table 1: Comparison of SIRs (in dB) for different methods 
 
 
 
 
5.  Conclusions 
This paper presented a novel nonstationary ICA algorithm to 
cope with the problem of dynamic source separation. The 
online learning adaptively captured the statistics of the source 
signals and mixing coefficients. This learning scheme is based 
on the VB learning where the robust modeling was achievable. 
In the nonstationary mixing process, the mixing coefficients 
were time-variant and nonlinear. The comparative experimental 
results demonstrated the efficiency and effectiveness of 
modeling the temporal information of mixing coefficients by 
using OLGP-ICA model. Instead of incorporating Markov 
model for individual source signals using batch estimation, the 
proposed OLGP employed an ARD model and efficiently 
determined the number of the latent sources by incremental 
learning method. This method was practical for real-world 
speech enhancement and separation. In the future, we will 
investigate sparse learning for GP model so as to reduce the 
computation cost and enhance the model generalization for 
speech separation. 
 
 
 
 
6.  References 
 
[1] K. Chan, T. W. Lee and T. J. Sejnowski, “Variational learning of 
clusters of undercomplete nonsymmetric independent 
components”, Journal of Machine Learning Research, vol. 3, pp.  
99-114, 2002. 
[2] R. A. Choudrey and S. J. Roberts, “Bayesian ICA with hidden 
Markov sources”, Proc. of ICA, pp. 809-814, 2003. 
[3] L. Csato and M. Opper, “Sparse on-line Gaussian processes”, 
Neural Computation, vol. 14, pp. 641-668, 2002. 
[4] R. Everson and S. J. Roberts, “Non-stationary independent 
component analysis”, Proc. of ICANN, pp. 503- 508, 1999. 
[5] J. Hirayama, S. Maeda and S. Ishii, “Markov and semi-Markov 
switching of source appearances for nonstationary independent 
component analysis”, IEEE Transactions on Neural Networks, vol. 
18, no. 5, pp. 1326-1342, 2007. 
[6] A. Honkela and H. Valpola, “On-line variational Bayesian 
learning”, Proc. of ICA, pp. 803-808, 2003. 
[7] H.-L. Hsieh and J.-T. Chien, “Online Bayesian learning for 
dynamic source separation”, Proc. of ICASSP, pp. 1950-1953, 
2010. 
[8] N. D. Lawrence and C. M. Bishop, “Variational Bayesian 
independent component analysis”, Technical Report, University of 
Cambridge, 2000. 
[9] J. Luttinen and A. Ilin, “Variational Gaussian-process factor 
analysis for modeling spatio-temporal data”, Advances in Neural 
Information Processing Systems, pp. 1177-1185, 2009. 
[10] D. J. C. MacKay, “Probable networks and plausible predictions - a 
review of practical Bayesian methods for supervised neural 
networks”, Network: Computation in Neural Systems, vol. 6, pp. 
469-505, 1995. 
[11] S. M. Naqvi, Y. Zhang and J. A. Chambers, “Multimodal blind 
source separation for moving sources”, Proc. of ICASSP, pp. 125-
128, 2009.  
[12] S. Park and S. Choi, “Gaussian processes for source separation”, 
Proc. of ICASSP, pp. 1909-1912, 2008. 
[13] J. Quinonero-Candela and O. Winther, “Incremental Gaussian 
processes”, Advances in Neural Information Processing Systems, 
pp. 1001-1008, 2003. 
[14] C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for 
Machine Learning, The MIT Press, 2006. 
 VB-ICA Switching ICA
BICA-
HMM 
Online 
VB-ICA
OLGP-
ICA
Demixed 
signal 1 7.97 12.06 9.04 11.26 17.24
Demixed 
signal 2 -3.23 -4.82 -1.5 4.47 9.96 
多位研究人員提出重要問題並有熱烈討論，會後與 Lim Boon Pang、Ville 
Hautamaki、Rafael E. Banchs 等博士個別討論，中午與 Li Haichou 及 Ma Bin
博士一起用餐。 
一月二十六日 參與 Li Haichou 研究群討論並收集計畫相關資料，與實驗室張博士進行學
術交流。 
一月二十七日 新加坡樟宜國際機場出發經香港轉機後飛抵高雄國際機場。 
 
 
二、與會心得 
 
國立新加坡大學學術風氣鼎盛是國際知名的頂尖學術單位， Institute of Infocomm 
Research 則是扮演類似台灣工研院負責學術界與工業界交流的單位，此次參訪不僅實質上促
進了台灣成功大學與新加坡學術單位的研究交流，共享機器學習與語音辨識的最新尖端技
術，對我個人的研究生涯也相當有助益，不僅增廣了個人的視野，在最新的研究課題上也收
穫不少。在此次參訪中有多次機會與國際知名學者、期刊負責人接觸、討論並交換意見，是
我這次參訪最大的收穫。希望國內大學教授應該多多參訪國際知名學術單位，以拓展個人的
研究視野，這對台灣學者往後的生涯有很大的助益，感謝國科會持續秉持此一信念，鼓勵國
內專家學者出國參觀訪問促進國內外學術交流，我們國家的形象及實力也會因此而提昇。 
議議程。 
五月二十五日 參加 ICASSP 研討會、聆聽 Plenary Talk 並於下午 16:15 至 18:15 之議程
「Statistical Methods for ASR」發表論文「貝氏感知隱藏式馬可夫模型應用
於語音辨識」以及議程「Machine Learning Methods and Applications II」發
表論文「使用高斯過程進行非穩態且時域相關聯之來源分離」，也聆聽其他
會議議程。晚上參加「Czech Evening」晚宴，地點在一座宮殿建築 Zofin 
Palace，大會提供一場交響樂團演奏的音樂饗宴，並有獨唱、豎情及直笛等
Soloist 演出，極富捷克風味，精采絕倫。 
五月二十六日 參加 ICASSP 研討會並聆聽 Plenary Talk 及其他會議議程。 
五月二十七日 參加 ICASSP 研討會、聆聽 Plenary Talk 並於上午 9:30 至 11:30 之議程
「Discriminative Techniques for ASR」發表論文「貝氏感知隱藏式馬可夫模
型之鑑別性訓練」，也聆聽其他會議議程。 
五月二十八日 下午搭乘電車及巴士至布拉格國際機場再搭飛機於阿姆斯特丹及香港轉機
回高雄再搭接駁巴士至台南，到達台南為五月二十九日晚上八點。 
 
這次出國參加在捷克布拉格舉行的 2011 年聲學語音暨訊號處理國際研討會 International 
Conference on Acoustics, Speech, and Signal Processing (ICASSP 2011)共五天，這一系列研
討會是由國際電機電子工程師學會(The Institute of Electrical and Electronics Engineers, 
IEEE)主辦，每年三、四、五月定期於世界各大城市輪流舉行，ICASSP 已是訊號處理及
語音處理相關領域中規模最大、影響力最深遠以及論文接受率最低的國際會議，每年吸
引來自世界各地專家學者出席此盛會，出席的專家學者中以來自美國及歐洲居多，由於
舉辦城市都選在風光明媚的城市，常吸引相當多的亞洲國家學者參加，包括日本、中國
大陸、台灣、韓國、新加坡和香港的學者，今年 General Chair 為捷克布拉格 Institute of 
Information Theory and Automation 大學教授 Prof. Petr Tichavsky，開會地點就在市中心地
鐵站 Vysehrad 的 Prague Congress Centre (PCC)，參加人數相當多(兩千多位)，討論非常
熱烈，來自台灣的論文包括台大、交大、清大、成大及中研院等，議程共分成兩類，第
一類是演講式，第二類是海報式，海報式議程的論文是由張貼海報的方式來發表論文，
由作者站在海報牆旁邊接受別人的詢問，這個方式的好處是能夠直接與論文作者面對面
的討論，然而，由於時間有限且詢問的人過多，無法對每篇論文做詳細的討論。演講式
議程的論文則是在演講廳的台上發表論文，它的好處是可以對每一篇論文詳細的聆聽，
但能夠發問的時間很短。本次研討會共發表一千多篇論文，我們共四篇論文被安排在五
月二十四日上午的海報式議程- Large Vocabulary Continuous Speech Recognition, 五月二
十五日下午的海報式議程- Statistical Methods for ASR 及海報式議程- Machine Learning 
Methods and Applications II, 五月二十七日上午的海報式議程- Discriminative Techniques 
for ASR，其他參加的議程包括 
 
五月二十四日：Plenary Talk、Acoustic Source Separation I、Compressive Sampling and Sparse 
MULTI-VIEW AND MULTI-OBJECTIVE SEMI-SUPERVISED LEARNING FOR LARGE
VOCABULARY CONTINUOUS SPEECH RECOGNITION
Xiaodong Cui1, Jing Huang1 and Jen-Tzung Chien2
IBM T. J. Watson Research Center, Yorktown Heights, NY, 10598, USA1
National Cheng Kung University, Tainan, Taiwan 70101, ROC2
Emails: cuix@us.ibm.com, jghg@us.ibm.com, jtchien@mail.ncku.edu.tw
ABSTRACT
Current hidden Markov acoustic modeling for large vocabulary
continuous speech recognition (LVCSR) relies on the availability
of abundant labeled transcriptions. Given that speech labeling is
both expensive and time-consuming while there is a huge amount of
unlabeled data easily available nowadays, semi-supervised learning
(SSL) from both labeled and unlabeled data which aims to reduce
the development cost for LVCSR becomes more important than
ever. In this paper, we propose SSL for LVCSR by using the mul-
tiple views learned from different acoustic features and randomized
decision trees. In addition, we develop the multi-objective learning
of HMM-based acoustic models by optimizing a hybrid criterion
which is established by the combination of the discriminative mu-
tual information from labeled data and the entropy from unlabeled
data. Experiments conducted on Broadcast News show the benefits
of proposed methods.
Index Terms— semi-supervised learning, multi-view, multi-
objective learning, discriminative training, LVCSR
1. INTRODUCTION
Current hidden Markov model (HMM) based acoustic modeling
for large vocabulary continuous speech recognition (LVCSR) relies
on speech signals with transcriptions which are both expensive and
time-consuming to obtain. On the other hand, there is a huge amount
of unlabeled speech data readily available from many sources (e.g.
internet, digital media, call center, etc.). Therefore, it is important
to investigate semi-supervised learning (SSL) approaches that can
leverage the current LVCSR systems trained from transcribed speech
by learning additional acoustic structure from unlabeled speech data.
Researches on SSL have been very active in machine learn-
ing. In [1], automatic classification of web pages from labeled
and unlabeled documents was performed by using the expectation-
maximization (EM) algorithm where the unknown class labels
in unlabeled documents were treated as missing variables. This
approach later on was extended to HMM [2] for classification of se-
quence data such as speech signals and gesture data. SSL on HMMs
was further studied by taking into account the balance between ob-
jective functions by using labeled data and unlabeled data, which
was controlled by an allocation parameter via a homotopy method
[3]. It is also popular to conduct SSL based on the co-training
[4] where the representation of an input pattern was partitioned
into two different views. Both views were used together to select
the unlabeled data with the highest classification confidence to in-
crease the set of labeled examples. Co-training was then extended
to tri-training [5] where an unlabeled example was labeled for a
classifier if the other two classifiers agreed upon the labeling. In
addition, the multi-objective learning was proposed for SSL based
on a product of multiple conditional likelihoods [6]. The hybrid gen-
erative/discriminative methods were accordingly established. This
method was applied for phonetic classification [7] where the gen-
erative model was trained from unlabeled speech and was merged
with the discriminative model estimated from labeled speech. An
unsupervised learning of acoustic models was studied in [8] with the
transcriptions of the unlabeled data being estimated for combination
with a confidence measure.
In this paper, we learn the acoustic structure from the labeled and
unlabeled data using multiple complimentary views where multi-
objective learning is performed for the HMM classifier for each in-
dividual view. Created by multiple acoustic features and randomized
acoustic decision trees, the multiple complimentary views are inte-
grated by a decision committee which votes for the labels of the unla-
beled data via recognizer output voting error reduction (ROVER)[9].
The cross-view learning has been partially presented in our previous
paper [10]. In this paper, we further perform a multi-objective learn-
ing of the acoustic HMMs according to the hybrid criterion of the
maximum mutual information (MMI) between speech signals and
their references for the labeled data, and the maximum entropy (ME)
of the unlabeled speech signals. The combination is carried out in a
boosted MMI (BMMI) framework with I-smoothing.
The remainder of the paper is organized as follows. Section 2
gives the details of the construction of the decision committee under
multi-view which includes selection of acoustic features, random-
ized decision tree, multi-objective learning of HMM classifiers, de-
cision aggregation and iterative learning with ROVER. Experimental
results on Broadcast News dataset are presented in Section 3 fol-
lowed by a summary in Section 4.
2. CONSTRUCTION OF MULTIVIEW COMMITTEE
Suppose from the training data Or , r = 1, · · · , R, one creates
M views hi, i = 1, · · · ,M . These M views form a committee
H = {h1, h2, · · · , hM}. Given an unlabeled speech signal Ou,
each view contributes its decision hi(Ou) based on which the com-
mittee makes an overall decision by applying an aggregation func-
tion T
H(Ou) = T (h1(O
u), · · · , hM (O
u)) (1)
Apparently, it is crucial for individual views to provide complimen-
tary information to help the committee to make a better overall de-
cision. In addition, it is also necessary for each view to have decent
performance as a single classifier. Fig.1 illustrates the construction
of the multiview committee in this paper using various acoustic fea-
tures and randomized decision trees. There are four types of acoustic
features used to describe the speech data. For each type of feature,
two decision trees are generated by randomizing the acoustic ques-
tions when splitting the nodes. An HMM classifier is built for each
4668978-1-4577-0539-7/11/$26.00 ©2011 IEEE ICASSP 2011
where λ and λ¯ are new and current estimates of the HMM parame-
ters, and Gnuml (λ, λ¯), Gdenl (λ, λ¯) and Gdenu (λ, λ¯) are the Q-functions
for the numerator HMM of the labeled data, the denominator HMM
of the labeled data and the equivalent denominator HMM of the un-
labeled data, respectively. GsmI (λ, λ¯) is the I-smoothing term which
always backs off to the previous iteration [15]. It is computed from
the numerator HMM of the labeled data. GsmD (λ, λ¯) is the smoothing
term for convexinization of the optimization landscape which leads
to the D constants. Maximizing Eq.7, one has the update equations
for the mean and variance for state j Gaussian component m as
μjm =
{θnum
′
l,jm(O)− θ
den
l,jm(O)− αθ
den
u,jm(O)}+ Djmμ¯jm
{γnum
′
l,jm − γ
den
l,jm − αγ
den
u,jm}+ Djm
(8)
σ
2
jm =
{θnum
′
l,jm(O
2)− θdenl,jm(O
2)− αθdenu,jm(O
2)}+ Djm(μ¯
2
jm + σ¯
2
jm)
{γnum
′
l,jm − γ
den
l,jm − αγ
den
u,jm}+ Djm
− μ2jm (9)
where the statistics are
γ
(·)
l,jm =
T lX
t=1
γ
(·)
l,jm(t), γ
den
u,jm =
TuX
t=1
γ
den
u,jm(t)
θ
(·)
l,jm(O) =
T lX
t=1
γ
(·)
l,jm(t)O
l(t), θdenu,jm(O) =
TuX
t=1
γ
den
u,jm(t)O
u(t)
θ
(·)
l,jm(O
2) =
T lX
t=1
γ
(·)
l,jm(t)O
l2(t), θdenu,jm(O
2) =
TuX
t=1
γ
den
u,jm(t)O
u2(t)
with (·) standing for (num) and (den) for the labeled HMM and
γ
(·)
(·),jm(t) the posterior probability of being state j and Gaussian
component m given the numerator or denominator lattices for la-
beled or unlabeled data. T l and T u are the total numbers of frames
from labeled and unlabeled data, respectively. Under I-smoothing
with counts τ I
γ
num
′
l,jm = γ
num
l,jm + τ
I
θ
num
′
l,jm(O) = θ
num
l,jm(O)
γnuml,jm + τ
I
γnuml,jm
, θ
num
′
l,jm(O
2) = θnuml,jm(O
2)
γnuml,jm + τ
I
γnuml,jm
In Eq.8 and Eq.9, Gaussian-specific Djm is chosen as the larger of
(1) twice the smallest value needed to ensure positive variances, (2)
E · (γdenl,jm +αγ
den
u,jm) where E is set to 2 [15]. The mixture weights
cjm is optimized using the following weak-sense auxiliary function
G(cjm, c¯jm) =
MX
m=1
γ
num
jm log cjm −
γdenl,jm + αγ
den
u,jm
c¯jm
cjm (10)
Solving Eq.10 leads to an iterative update formula
c
(p+1)
jm =
γnumjm + kjmc
(p)
jmP
m
(γdenl,jm + αγ
den
u,jm) + kjmc
(p)
jm
(11)
and
kjm =
„
max
m
γdenl,jm + αγ
den
u,jm
c¯jm
«
−
γdenl,jm + αγ
den
u,jm
c¯jm
2.3. Decision Aggregation and Iterative Learning
Once the HMM classifier is trained for each view with a particular
acoustic feature and randomized decision tree, unlabeled data is de-
coded by each view hi in the committee H . The final decision is
made through the aggregation function T in Eq.1 which can be re-
alized at various levels. For instance, the aggregation can be carried
out at the likelihood level as tree array by averaging over decoding
likelihood scores from each individual view at each state. The aggre-
gation can also be carried out at the text level as ROVER or N-best
ROVER by output voting. In this work, we use ROVER for decision
aggregation on text outputs of the multiple views.
The learning process is iterative. It starts from the labeled data
from which multiple views {h(0)i } are created. The views are used
to decode the unlabeled data. For an unlabeled utterance Our and
a particular view at iteration k, h(k)i , its updated label for the next
iteration W (k+1)r is an aggregated outputs from other views in the
committee
W
(k+1)
r = T (h
(k)
1 (O
u
r ), · · · , h
(k)
i−1(O
u
r ), h
(k)
i+1(O
u
r ), · · · , h
(k)
M (O
u
r ))
The updated labels are then fed back to perform SSL to refine all the
views in the committee for next iteration. In test session, the recog-
nition output of test data is the aggregation of the results from all
of the views in the committee. This cross-view labeling is helpful to
diversify the views for better overall performance under aggregation.
3. EXPERIMENTAL RESULTS
Experiments are carried out on Broadcast News (BN) dataset from
which in total of 100 hours of data are randomly selected based on
speakers. These 100 hours of data are split into 50 hours of la-
beled data (50hL) and 50 hours of unlabeled data (50hU). There is
no speaker overlap between the two subsets. The PLP, MFCC and
LPCC features are 13, 13 and 19 in dimension in the original feature
space, respectively. Every 9 frames of the features are spliced to-
gether before projected down to a 40 dimensional space by linear dis-
criminant analysis. For the NN feature, the first layer of the network
maps an input of 9 frames of 13 mean- and variance-normalized PLP
features to a hidden representation of N dimensions (N is set to 800
for 50-hour data, and 1500 for 100-hour data). A second layer of
weights projects this high dimensional hidden representation to a 40-
dimensional feature vector. The weights from the 3-layer network
are trained using the cross-entropy criterion to discriminate between
400 context-dependent HMM states. The language model used for
decoding is a 4-gram model with 3.3M n-grams. The recognition
dictionary consists of 84K words and 90K pronunciations. In the
experiments, 1K quinphone states and 30K Gaussians are used in all
the models trained with 50 hours of data; 3K quinphone states and
80K Gaussians are used in all the models trained with 100 hours of
data (whether they are all labeled or a mix of labeled and unlabeled).
The EARS Dev-04f set (dev04f), composed of 3 hours of audio, is
used for evaluation since it is a relatively tough set for testing. EARS
RT-03 set (rt03), composed of about 2.3 hours of audio, is used as a
development set for choosing the combination factor α in the multi-
objective learning.
Table 1 shows the word error rates (WERs) of the PLP (with-
out randomized decision tree) after BMMI discriminative training
on 50hL and also on the whole 100 hours assuming all labels are
known (100hL). In terms of performance, it is a reasonable baseline
to start with as a single system. In the table, 22.8% under 100hL can
be considered a “ground truth” for the SSL investigated in this work.
The selection of the combination factor α in Eq.2 for multi-
objective learning with 50hL and 50hU is performed on rt03 as
shown in Table 2. In the same table, WERs of the test set dev04f
are also presented. The labels for 50hU are purely generated by the
BMMI model trained from 50hL. The decision tree and ML model
are built upon the true label for 50hL and generated label for 50hU.
The table reveals a similar trend of performance on both dev and test
sets. Particularly, when α = 0, only statistics from 50hL are used
4670
BAYESIAN SENSING HIDDENMARKOVMODELS FOR SPEECH RECOGNITION
George Saon† and Jen-Tzung Chien‡∗
†IBM T. J. Watson Research Center, Yorktown Heights, NY, 10598, USA
‡National Cheng Kung University, Tainan, Taiwan 70101, ROC
ABSTRACT
We introduce Bayesian sensing hidden Markov models (BS-HMMs)
to represent speech data based on a set of state-dependent basis vec-
tors. By incorporating the prior density of sensing weights, the rele-
vance of a feature vector to different bases is determined by the cor-
responding precision parameters. The BS-HMM parameters, con-
sisting of the basis vectors, the precision matrices of sensing weights
and the precision matrices of reconstruction errors, are jointly esti-
mated by maximizing the likelihood function, which is marginal-
ized over the weight priors. We derive recursive solutions for the
three parameters, which are expressed via maximum a posteriori es-
timates of the sensing weights. Experimental results on an LVCSR
task show consistent gains over conventional HMMs with Gaussian
mixture models for both ML and discriminative training scenarios.
Index Terms— Speech recognition, Bayesian learning, basis rep-
resentation, acoustic model
1. INTRODUCTION
There have been many technologies successfully developed to rep-
resent or encode a general signal based on a set of over-determined
basis vectors. It is beneﬁcial to use a relatively small set of rele-
vant basis vectors to represent the underlying signal. The overﬁtting
problem in such a transform coding is alleviated. Model regulariza-
tion can be thus achieved in pattern recognition systems, e.g. face
recognition and speech recognition, where the overtraining issue al-
ways exists in presence of heterogeneous environments using sparse
data, noisy data, unlabeled data, etc. The regularized model is cru-
cial to achieve good recognition performance on unknown test data.
Recently, sparse coding techniques have been developed for feature
extraction of speech signals based on an over-determined dictionary
using the exemplar-based method [1],[2]. This paper proposes a
new Bayesian representation of speech data and introduces Bayesian
sensing HMMs (BS-HMMs) for large vocabulary continuous speech
recognition (LVCSR).
In standard HMMs, the sequential data in a Markov state are as-
sumed to be conditionally independent and are represented by state-
dependent Gaussian mixture models (GMMs). The corresponding
state sequence is determined according to the accumulated likeli-
hood function and the state transition probability. However, the max-
imum likelihood (ML) estimates of HMM parameters are prone to
be overtrained. We question whether GMMs are suitable for the rep-
resentation of training data as well as for the generalization to un-
known test data. Predictive HMMs [3] were accordingly proposed
to compensate the overﬁtting problem by incorporating the uncer-
tainties of HMM parameters, expressed by prior distributions, in a
Bayesian model comparison [4]. Another approach was given by
∗This work was performed while the author was visiting IBM Research.
buried Markov models [5] which relaxed the conditional indepen-
dence assumption for the representation of speech features. A set of
state-dependent basis vectors was trained to express the condition-
ally dependent feature vectors. In yet another approach, subspace
Gaussian mixture models [6] were constructed to represent speech
features by using the state-dependent weights and a common large-
scale GMM structure. The feature representation was seen as sens-
ing based on different subspaces of a global GMM.
In this study, we address the basis representation of speech fea-
tures for hidden Markov modeling and present the Bayesian sens-
ing framework to ensure model regularization for speech recogni-
tion. The resulting BS-HMMs are constructed by a set of basis
vectors, the precision matrix of sensing weights, and the precision
matrix of reconstruction errors. The precision matrix of weights
naturally reﬂects how relevant the input feature is encoded by the
basis vectors similar to the perspective of relevance vector machine
(RVM) [7]. Importantly, we maximize the marginal likelihood of
the training data over random weights and jointly estimate the three
sets of parameters. Multivariate solutions are derived by maximum
likelihood (ML) type II estimation and expressed through recursive
formulas. These formulas are interpreted in terms of the mean vector
and covariance matrix of the a posteriori distribution of the sensing
weights. The maximum a posteriori (MAP) estimate of the sensing
weights plays a central role in BS-HMMs. Experimental results on
an LVCSR task show consistent improvements over standard HMMs
with Gaussian mixture models.
2. BAYESIAN SENSING HIDDEN MARKOVMODELS
2.1. Model Construction
The concept of Bayesian sensing is incorporated within the HMM
framework by viewing the D-dimensional feature vector xt ∈ IRD
as a measurement based on a set of state-dependent basis vec-
tors Φi = [φi1, . . . ,φiN ] for state i, which may suffer from an
overﬁtting problem. We assume that the reconstruction error be-
tween measurement xt and its representation Φiwt, where wt =
[wt1, . . . , wtN ]
T , is Gaussian distributed with zero mean and a state-
dependent precision matrix Ri. Furthermore, the sensing weight
vector wt is assumed to be Gaussian distributed with zero mean
and a state-dependent precision matrix Ai. Accordingly, the state
likelihood function is expressed as
p(xt|wt, λi) ∝ |Ri|
1/2 exp
»
−
1
2
(xt − Φiwt)
T
Ri(xt − Φiwt)
–
(1)
Each frame xt is generated by the BS-HMM parameters λ =
{πi, aik, Ai,Φi, Ri} consisting of initial state probabilities {πi},
5056978-1-4577-0539-7/11/$26.00 ©2011 IEEE ICASSP 2011
Similar to the solution for Ai, the new estimate of Φi can be
written in an implicit form, i.e.
Φˆi =
"X
t
γt(i)xtm
T
ti
# "X
t
γt(i)(Σi + mtim
T
ti)
#
−1
=
P
t γt(i)xtm
T
tiP
t γt(i)
· Aˆi
Δ
= Ξ(Φi)
(11)
Again, we reuse the notationsmti and Aˆi to express the solution to
Φi.
To ﬁnd the new estimate of the precision matrix of reconstruc-
tion errorsRi, we similarly maximize the auxiliary function (5) with
respect to Ri and obtain
X
t
γt(i)
»
R
−1
i − ΦiΣiΦ
T
i − xtx
T
t +
∂
∂Ri
(xTt RiΦiΣiΦ
T
i Rixt)
–
= 0
(12)
where the gradient in the last term of the LHS is derived by
∂
∂Ri
(xTt RiΦiΣiΦ
T
i Rixt) =
∂
∂Ri
Tr{ΣiΦ
T
i Rixtx
T
t RiΦi}
= −ΦiΣiΦ
T
i Rixtx
T
t RiΦiΣiΦ
T
i + ΦiΣiΦ
T
i Rixtx
T
t
+xtx
T
t RiΦiΣiΦ
T
i
(13)
Equivalently, (12),(13) are arranged as
Rˆ−1i = ΦiΣiΦ
T
i +
P
t γt(i)(xt − Φimti)(xt −Φimti)
TP
t γt(i)
Δ
= Ψ(Ri)
(14)
which is also a recursive solution to Ri since the RHS of (14) de-
pends on Ri. Importantly, we express the new estimate Rˆi by using
the notationsmti andΣi which have been deﬁned and calculated for
the solutions to Ai and Φi. Note that the RHS of (14) is symmetric
positive definite which is required for the estimation of Ri.
Such consistent solutions to Ai, Φi and Ri, expressed as im-
plicit equations, do not require a gradient descent implementation.
The convergence of parameter estimation is empirically observed.
Moreover, the computational cost of estimating the three parameters
is signiﬁcantly reduced due to the shared calculation ofmti and Σi.
To our knowledge, the multivariate solutions for BS-HMMs are
novel and differ signiﬁcantly from those of RVM [7]. Addition-
ally, they are speciﬁcally designed for HMM-based sequential pat-
tern recognition.
2.4. Extensions for Acoustic Modeling
The following two extensions were found beneﬁcial for improving
the performance of BS-HMMs for acoustic modeling. First, we con-
sider a mixture model of basis vectors within each state. Feature
vectors are assumed to be generated from several state-dependent
subspaces constructed by different sets of basis vectors. Mixture
component j for state i has precision matrix of sensing weights Aij ,
basis Φij and precision matrix of reconstruction errors Rij .
Second, we allow the reconstruction error for mixture compo-
nent (i, j) to have a non-zero mean μij that can be estimated from
data. Accordingly, (7),(11),(14) are modiﬁed by replacing xt with
xt − μij . The ML estimate for μij is the same as for GMM-based
HMMs. The primary reason for introducing mixture component
means is to be able to use MLLR for speaker adaptation1 .
3. EXPERIMENTS AND RESULTS
3.1. Experimental Setup
We experimented with the mixture model of BS-HMMs on an En-
glish broadcast news transcription task. The training data consists of
50 hours of transcribed audio and we report results on the DEV04f
test set which has 2 hours of speech and 22.6K words.
The input speech is encoded by VTL-warped PLP cepstral
frames which are mean and variance normalized on a per speaker
basis. Every 9 consecutive frames are spliced together and projected
to 40 dimensions by an LDA transform followed by a decorrelat-
ing semi-tied covariance (STC) transform [9]. Words in the recog-
nition lexicon are represented as sequences of phones, and phones
are modeled with 3-state left-to-right HMMs without state skipping.
All acoustic models have pentaphone cross-word acoustic context
and are speaker adaptively trained with feature-space MLLR (FM-
LLR) [9]. At test time, speaker adaptation is performed with VTLN,
FMLLR and multiple regression tree-based MLLR transforms. The
recognition vocabulary has 90K words and the decoding is done with
a 4-gram language model containing 4M ngrams which was trained
with modiﬁed Kneser-Ney smoothing.
The baseline GMM-HMMs and the proposed BS-HMMs have
comparable context decision trees containing 2200 leaves. We care-
fully optimized the baseline models by varying the number of Gaus-
sians per state and we report results for two conﬁgurations: 64 Gaus-
sians per state and 128 Gaussians per state. For the BS-HMMs, the
number of mixture components per state is empirically set to the
number of Gaussians per state divided by 4 resulting in two conﬁg-
urations: 16 and 32 components per state, respectively.
We found that the performance of the BS-HMMs is quite sen-
sitive to parameter initialization. The best results were obtained by
partitioning the Gaussian means of the baseline GMM for a given
state using k-means into clusters. The clusters become the bases
{Φij} for the BS-HMM mixture components. Note that the BS-
HMMs have 25% fewer parameters than the corresponding GMM-
HMMs because of fewer mixture component variances. The means
μij are initialized to zero. The precisionsAij andRij are initialized
to the identity matrix and are assumed to be diagonal. The training
regime for the BS-HMMs consists of 5 iterations with ﬁxed HMM
state alignments followed by two Viterbi iterations where the data
are re-aligned with the BS-HMMs.
3.2. Experimental Results
In Figure 1, we plot the average and standard deviation of the esti-
mated precisions of the sensing weights as a function of the training
iteration for the 16 components per state model. We ﬁnd that the
precisions tend to increase for the ﬁrst few iterations until they sta-
bilize. This implies that more basis vectors become less relevant to
the observation data as the training proceeds.
In Table 1, we compare the performance of the baseline GMM-
HMMs and the proposed BS-HMMs for maximum likelihood and
1We assume that the precision matrixRi −RiΦiΣiΦTi Ri in (3) is diag-
onal for MLLR transform estimation.
5058
NONSTATIONARY AND TEMPORALLY CORRELATED SOURCE SEPARATION 
USING GAUSSIAN PROCESS 
 
Hsin-Lung Hsieh and Jen-Tzung Chien 
 
National Cheng Kung University, Tainan, Taiwan 70101, ROC 
{hlhsieh,chien}@chien.csie.ncku.edu.tw
 
ABSTRACT 
Blind source separation (BSS) is a process to reconstruct source 
signals from the mixed signals. The standard BSS methods assume 
a fixed set of stationary source signals with the fixed distribution 
functions. However, in practical mixing systems, the source signals 
are nonstationary and temporally correlated; e.g. source signal 
may be abruptly active or inactive or even replaced by a new one. 
The mixing system is also time-varying. In this paper, we present a 
novel Gaussian process (GP) to characterize the time-varying 
mixing coefficients and the temporally correlated source signals. 
An online variational Bayesian algorithm is established to learn the 
noisy mixing process where GP priors are adopted to express the 
correlated sources as well as the mixing matrix. Experimental 
results demonstrate the effectiveness of proposed method in speech 
separation under different scenarios. 
Index Terms— Blind source separation, Gaussian process, 
Bayesian method, online learning 
1. INTRODUCTION 
Typically, blind source separation (BSS) aims to recover 
independent source signals under the conditions that we only 
observe the mixed signals and the actual mixing process is 
unknown. The ICA algorithms using higher-order statistics were 
developed to find the demixing matrix by minimizing the mutual 
information or maximizing the likelihood of reconstructed signals. 
However, the maximum likelihood model is prone to be 
overtrained. The variational Bayesian ICA model was built to 
assure model regularization [12]. In addition, ICA methods using 
the second-order statistics were established to characterize the time 
structure of source signals. In [10], a second-order-based blind 
identification algorithm was proposed to tackle the 
underdetermined system with rank-deficient mixing matrix. In [14], 
the Gaussian process (GP) model was developed to characterize 
the temporal structure of source signals via a GP prior distribution 
for a latent function. This function was used to predict a source 
sample given its past samples. Furthermore, the GP priors were 
incorporated into a factor analysis model, called GP-FA, for 
representation of spatio-temporal data [11]. Most of the above 
methods were proposed by considering the stationary signals. In 
practice, the source signals in BSS system involve various 
nonstationary scenarios such as a time-varying mixing system or a 
sudden presence or absence of source signals. The ICA methods 
designed for static mixing process and stationary source 
distributions are not fitted to overcome the real-world 
circumstances. A nonstationary ICA algorithm should be 
developed.
There have been several methods proposed to cope with the 
situations of dynamic sources or to compensate the variations of 
mixing system in nonstationary environments. Considering the 
first scenario that the sources or sensors may be moving, we 
should explore the time-varying mixing process and the adaptive 
ICA algorithms. In [4], a state transition matrix was adopted to 
capture the variations of mixing coefficients when the speaker or 
microphone was moving. In the second scenario that the source 
may suddenly appear or disappear or is replaced by a new source, 
we need to modify source distribution or trace the status of 
individual sources at different time moments. In [2], a hidden 
Markov model (HMM) was incorporated to represent the 
distributions of source signals at different locations of an image 
signal. The source distributions were dependent on HMM state. In 
[5], an indicator variable was used to indicate if the sources were 
active or inactive in a switching ICA procedure. The computation 
cost was high due to the incorporation of Markov chain in ICA. In 
[6], an online variational Bayesian (VB) learning was performed in 
ICA procedure by considering time-dependent source signal and 
time-independent mixing matrix. The source distributions were 
updated incrementally while the number of sources was fixed. 
Such an approach was unable to tackle the case of suddenly 
appearing or disappearing sources. In [7], a time-varying 
autoregressive (AR) process was proposed to simulate the time 
structure of nonstationary source signals, but the mixing matrix 
was regarded as time-independent. All of these methods did not 
simultaneously consider two nonstationary scenarios. 
Recently, an online Bayesian learning for dynamic source 
separation was proposed by considering two scenarios 
simultaneously [8]. The mixing matrix and the distribution of 
source signals were jointly estimated at each frame via an 
incremental VB procedure. The GP model was also incorporated to 
characterize the temporal structure of nonstationary mixing 
coefficients [9]. In this study, we further extend the nonstationary 
ICA algorithm to deal with the time-varying mixing process and 
the temporally correlated source signals. We present an online 
learning algorithm for Gaussian process so that the temporal 
structure of source signals and the time-varying mixing matrix are 
jointly estimated and incrementally updated according to a 
nonstationary ICA procedure. A nonstationary Gaussian process 
ICA (NGP-ICA) is developed for dynamic source separation. The 
online learning of NGP parameters is exploited according to a 
recursive Bayesian method, which is different from online GP 
based on sparse representation [3]. The proposed NGP-ICA is 
evaluated by the comparative experiments on different scenarios 
where the dynamic sources with multiple speakers are present. 
2. TEMPORALLY CORRELATED SOURCE SEPARATION 
In realistic mixing environments, the observed signals, e.g. speech 
and music signals are sequential and temporally correlated. The 
correlation information is important for reconstructing source 
signals. The time-varying AR model [7] was incorporated into 
reconstruction of temporal structure of source signals. Let the mth
source signal tms ,  at sample t be generated by its past p samples 
T
ptmtmtm ss ][ ,1,1,   &s  through an AR model 
tm
p
n
ntmntmtm shs ,
1
,,, H ¦
 
                           (1) 
2120978-1-4577-0539-7/11/$26.00 ©2011 IEEE ICASSP 2011
)),(,0(~)( )( 1,
)(
1,
)(
1,
l
m
l
tm
l
tm Nf  WN sss &&&                   (11) 
where ),( )( 1,
)(
1,
l
m
l
tm  WN ss &&  is the variance which has been defined in 
(8) but using the associated hyperparameters }.,{ )1()1(  ls
l
s mm
UO  The 
GP prior of the mth source Lt
l
tm
l
m s 1
)(
,
)( }{   s  in frame l is given by 
).,0|(),|( )1()1()1()()1()1()(     lslslslmlslslm mmmmm Np KRȝsRȝs    (12) 
The ),( Wt  element of the covariance matrix is given by 
WWW GN tlml tmtlsm   ),(][ )( 1,)( 1,)1( ssK
&&
.                  (13) 
In addition, the noise vector )(ttİ  is assumed to be an isotropic 
Gaussian with zero mean and a diagonal precision matrix 
}.{diag )()( ln
l E ȕ  Different from the GP-FA model [11], we 
consider the uncertainty of the noise vector by choosing a Gamma 
prior for )(lnE  with hyperparameters }.,u{ )1()1(  ll nn wEE  We have 
},,,,,,,,},{{ )()()()()()()()()()()()( llls
l
s
l
s
l
s
l
A
l
A
l
A
l
a
l
A
l
nm EE wuȡȜRMȡȜRȝMĭ   
as the hyperparameters of NGP-ICA. This study highlights the 
time-varying mixing process for nonstationary source separation. 
The temporal structure of mixing coefficients is represented by a 
time series. In [11], the spatio features of GP-FA were represented 
by individual column vector of a fixed factor loading matrix which 
was time invariant. Here, NGP-ICA deals with the time-varying 
mixing process or the case that the sources or sensors are moving. 
The dependence between mixing coefficients is reflected by a time 
series. Importantly, we characterize the temporal structure of time-
varying mixing coefficients by a Gaussian process with the scaling 
hyperparameter .)1( lanmȜ  If 
)1( l
anm
O  is very small, it implies that the 
associated )( 1,
l
tnm a
&
 have little effect on the prediction of .)( ,
l
tnma
Estimating the hyperparameter )1( lanmȜ  is equivalent to performing 
the automatic relevance determination (ARD) [13], which reflects 
the activities of source signals. For instance, when the source 
signal is abruptly inactive, the corresponding mixing coefficients 
shall become zero. The previous mixing coefficients have little 
impact on prediction of the current mixing coefficients. By 
tracking and updating the scaling parameter ,)1( lanmȜ  we determine 
the status of source signals at different frames. 
3.3 Model inference 
Since the exact posterior distribution )|( )(lp FĬ  is intractable, we 
employ the VB inference to approximate the posterior distribution 
by a variational distribution ).(Ĭq  The true posterior is 
approximated by a factorized distribution 
)()()()()|( )()()()()()( llllll qqqqp ȕSAĬĬ  |F .          (14) 
The VB learning has the advantage of avoiding the overfitted 
model. In VB framework, we maximize the lower bound of the 
logarithm of marginal distribution )( )(lp F  or )|( )1()( llp ĭX
which is equivalent to minimize the Kullback-Leibler distance 
between true posterior )|( )()( llp FĬ  and approximate posterior 
).( )(lq Ĭ  The lower bound is obtained by 
(15))(log))((
)(log))(()(log))((
),,|(log)|(log
)(
)()(
)(
)()(
)(
)()(
)()()(
)()()()()1()(
E
E
q
ll
Sq
ll
Aq
ll
qSqAq
llllll
pqS
pqSpqS
pp
!
!!
!t
ȕȕ
SSAA
ȕSAXĭX
where )(qS  is the entropy of q and !  denotes the expectation 
over an approximate distribution q. By taking the differential of 
lower bound with respect to )( )(lq Ĭ  and setting it to zero, we find 
the variational parameters of ),( )(lq A  )( )(lq S  and ).( )(lq ȕ  The 
optimal )( )(ljq Ĭ  satisfies 
.)|,(log)(log )(
)1()()()(
jq
llll
j pq 4z4
 !v ĭĬXĬ       (16) 
The log variational posterior )(log )(lnmq a  over the L mixing 
coefficients in )(lnma  is given by 
).(log),,|(log )()()(
)()()()( l
nmqSq
lll
nm
l pp aȕSaX ! E        (17) 
The pseudo likelihood in the first term of (17) can be rearranged as 
a Gaussian function [11] 
))(,|~)((
}),,|(logexp{
1)()()(1)(
)()()()(
v
!
l
a
l
nm
l
a
l
a
lll
nm
l
nmnmnm
N
p
ȌaxȌ
ȕSaX
                  (18) 
where )(~ lanmx  is a 1uL  vector with the tth element 
)(~ )( ,
)(
,
)(
,
)(
,
)(
,
)(
, ¦z !!!! 
M
mk
l
tk
l
tnk
l
tn
l
tm
l
tn
l
ta saxsx nm E         (19) 
and )(lanmȌ  is the LLu  diagonal matrix with tth diagonal elements 
.][
2)(
,
)(
,
)( !!  l tmltnttla snm EȌ  Substituting (9) and (18) into (17) 
yields the variational posterior ),,|()( )()()()( la
l
a
l
nm
l
nm nmnm
Nq Rȝaa  
which is a new Gaussian with the updated mean vector and 
covariance matrix 
)(1)(1)1()( ~)()( la
l
a
l
a
l
a nmnmnmnm
xȌRȝ                          (20) 
.])([ 11)1()()(  lalala nmnmnm RȌR                         (21) 
The estimation of )( )(lmq s  is similar to that of )(
)(l
nmq a  and can be 
computed by substituting )(lnma  by .
)(l
ms  Also, the log variational 
posterior )(log )(lnq E over the noise precision is proportional to 
)(log,,|(log )()()(
)()()()( l
nAqSq
llll pp E! ȕSAX           (22) 
The optimal variational posterior )( )(lnq E  is derived as a new 
Gamma distribution with the updated hyperparameters 
»»¼
º
««¬
ª
! ¦
 
L
t
l
tn
l
tnl
l xx
n
n 1
2)(
,
)(
,)1(
)( )ˆ(
2
1
u
1u
E
E                   (23) 
)2()1()( Lww ll
nn
 EE .                              (24) 
The expectation function in (23) is given by 
¦
 
!!!  M
m
l
tm
l
tnm
l
tn sax
1
)(
,
)(
,
)(
,ˆ                         (25) 
!!!  )( ,)( ,)( ,)( , ˆˆˆˆ l tnl tmltnl tm xxxx                          (26) 
].)()([
ˆˆˆ
2)(
,
2)(
,
2)(
,
1
2)(
,
2)(
,
)(
,
)(
,
!!!!
!! 
¦
 
l
tm
l
tnm
l
tm
M
m
l
tnm
l
tn
l
tn
l
tn
sasa
xxx
      (27) 
The updating rules for hyperparameters },,,{ )()()()( lS
l
S
l
A
l
A ȡȜȡȜ  are 
similarly obtained by maximizing the same objective function [11]. 
As a result, at each frame l, we can realize the NGP-ICA 
parameters )(lĬ  and update the hyperparameters of )(lĭ in VB 
procedure. These hyperparameters )(lĭ  are propagated to the next 
frame 1l and acted as the new statistics of conjugate priors for 
VB learning. The computational complexity of NGP-ICA is 
2122
DISCRIMINATIVE TRAINING FOR BAYESIAN SENSING HIDDENMARKOVMODELS
George Saon† and Jen-Tzung Chien‡∗
†IBM T. J. Watson Research Center, Yorktown Heights, NY, 10598, USA
‡National Cheng Kung University, Tainan, Taiwan 70101, ROC
ABSTRACT
We describe feature space and model space discriminative training
for a new class of acoustic models called Bayesian sensing hidden
Markov models (BS-HMMs). In BS-HMMs, speech data is repre-
sented by a set of state-dependent basis vectors. The relevance of a
feature vector to different bases is determined by the precision matri-
ces of the sensing weights. The basis vectors and the precision ma-
trices of the reconstruction errors are jointly estimated by optimizing
a maximum mutual information (MMI) criterion. Additionally, we
discuss the training of an fMPE-style discriminative feature transfor-
mation under the same criterion given these models. Experimental
results on an LVCSR task show that the proposed models outperform
discriminatively trained conventional HMMs with Gaussian mixture
models (GMMs). Cross-adapting the baseline GMM-HMMs to the
BS-HMM output yields a 6% relative gain which indicates that the
two systems make different errors.
Index Terms— Bayesian learning, basis representation, discrimi-
native training
1. INTRODUCTION
Modern ASR systems employ discriminative training (DT) for pa-
rameter estimation in order to achieve optimal performance on a
given task. Feature space techniques like fMPE [1] consist in
transforming the acoustic feature vectors according to an objective
function which is closely related to recognition performance such
as maximum mutual information (MMI) [2] (and recent variants
thereof [3],[4]) or minimum phone error rate (MPE) [5]. Model
space discriminative training adjusts the parameters of the acoustic
model under the same discriminative criteria.
It is our experience that, oftentimes, novel acoustic modeling
techniques which show promising performance with maximum like-
lihood (ML) estimation barely make a difference, at best, after dis-
criminative training. Undeterred by this state of affairs, we experi-
ment with discriminative training for a new class of acoustic models
called Bayesian sensing HMMs [6] which combine ideas from rel-
evance vector machines [7] and bayesian dictionary learning. The
main idea behind BS-HMMs is to represent acoustic features with
state-dependent basis vectors and to integrate out the sensing weights
assuming state-dependent zero-mean Gaussian priors. We compare
these models against state-of-the-art discriminatively trained GMM-
HMMs on an English broadcast news transcription task.
2. BAYESIAN SENSING HIDDEN MARKOVMODELS
The concept of Bayesian sensing is incorporated within the HMM
framework by viewing the D-dimensional feature vector xt ∈ IRD
∗This work was performed while the author was visiting IBM Research.
as a measurement based on a set of state-dependent basis vec-
tors Φi = [φi1, . . . ,φiN ] for state i, which may suffer from an
overﬁtting problem. We assume that the reconstruction error be-
tween measurement xt and its representation Φiwt, where wt =
[wt1, . . . , wtN ]
T , is Gaussian distributed with zero mean and a state-
dependent precision matrix Ri. Furthermore, the sensing weight
vector wt is assumed to be Gaussian distributed with zero mean
and a state-dependent precision matrix Ai. Accordingly, the state
likelihood conditioned on the weight vectorwt is expressed as
p(xt|wt, λi) ∝ |Ri|
1/2 exp
»
−
1
2
(xt − Φiwt)
T
Ri(xt − Φiwt)
–
(1)
Each frame xt is generated by the BS-HMM parameters λ =
{πi, aik, Ai,Φi, Ri} consisting of initial state probabilities {πi},
state transition probabilities {aik}, precision matrices of sensing
weights {Ai}, basis vectors {Φi} and precision matrices of residu-
als {Ri}. The marginal likelihood or Bayesian predictive likelihood
p(xt|λi) is obtained by marginalizing over the weight vectorwt and
is proportional to
Z
IRN
|Ri|
1/2 exp
»
−
1
2
(xt − Φiwt)
T
Ri(xt − Φiwt)
–
·|Ai|
1/2 exp
»
−
1
2
w
T
t Aiwt
–
dwt
∝ |Ri|
1/2|Ai|
1/2|Σi|
1/2 exp
»
−
1
2
x
T
t (Ri −RiΦiΣiΦ
T
i Ri)xt
–
= |Ri|
1/2|Ai|
1/2|Σi|
1/2 exp
»
−
1
2
(xTt Rixt −m
T
tiΣ
−1
i mti)
–
(2)
where Σi Δ= (ΦTi RiΦi + Ai)−1, mti
Δ
= ΣiΦ
T
i Rixt are the
covariance matrix and the mean vector of the posterior distribu-
tion p(wt|xt, λi), respectively. Here, the mean vector mti corre-
sponds to the maximum a posteriori estimate of sensing weights,
i.e. wMAP = mti. In [6], we discuss the estimation of BS-HMM
parameters according to the ML type II criterion by maximizing the
marginal likelihood of the training dataX = {xt}.
3. MODEL-SPACE DISCRIMINATIVE TRAINING
Instead of the goodness-of-ﬁt criterion using a marginal likelihood
function forML type II estimation, the objective function of discrim-
inative training is established according to the mutual information
between observation data X and the sequence of reference words
W r [2]
5316978-1-4577-0539-7/11/$26.00 ©2011 IEEE ICASSP 2011
4. FEATURE-SPACE DISCRIMINATIVE TRAINING
Next, we develop the discriminative training in feature-space for
building BS-HMMs according to the MMI objective function. This
is similar to the discriminatively trained features for conventional
HMMs [1]. Here, the original feature vector xt is transformed to
yt = {ytd} by yt = xt + Mht where M = {mdj} is a transfor-
mation matrix and ht = {htj} is a high dimensional feature vector
calculated at frame t. The transformation matrix is updated by gra-
dient ascent
mdj ←− mdj + vdj
∂Q
∂mdj
= mdj + vdj
X
t
∂Q
∂ytd
htj (13)
using the parameter-speciﬁc learning rate vdj which is empirically
determined. Since the MMI objective function Q(λ|λ(k)) depends
on BS-HMM parameters and on the transformed features them-
selves, the partial derivative in (13) accordingly consists of a direct
derivative and an indirect derivative as follows
∂
∂yt
Q({yt}, λ({yt})|λ
(k)) =
∂Q
∂yt|{z}
direct
+
∂Q
∂λ
∂λ
∂yt| {z }
indirect
(14)
The direct derivative is calculated as
∂Q
∂yt
=
X
i
∂Q
∂ log p(yt|λi)
·
∂
∂yt
log p(yt|λi) (15)
where the ﬁrst term in RHS equals to γnumt (i) − γdent (i) given the
transformed features {yt} and the second term is obtained by
∂
∂yt
log p(yt|λi) = −(Ri −RiΦiΣiΦ
T
i Ri)yt (16)
which is derived from (2). In calculating the indirect derivatives, we
consider the dependencies of the MMI objective function on Φi and
Ri and ﬁnd
∂Q
∂λ
∂λ
∂yt
=
X
i
∂Q
∂ log p(yt|λi)
·
"X
d
X
n
∂
∂φidn
log p(yt|Φi = {φidn}) ·
∂φidn
∂yt
+
X
d
X
d′
∂
∂ridd′
log p(yt|Ri = {ridd′}) ·
∂ridd′
∂yt
# (17)
For each frame yt, we calculate the partial derivative of log p(yt|λi)
with respect to the individual elements of Φi = {φidn} and Ri =
{ridd′}, which are given by the elements of the matrix derivatives
∂
∂Φi
log p(yt|Φi) = Ri(−ΦiΣi − Φimtim
T
ti + ytm
T
ti) (18)
∂
∂Ri
log p(yt|Ri) =
1
2
»
R−1i − ΦiΣiΦ
T
i
−(yt −Φimti)(yt − Φimti)
T
–
(19)
By combining the derivatives of φidn and ridd′ with respect to
the transformed features yt using the ML type II versions of (9)
and (11), the terms in the bracket of the RHS of (17) are derived as
∂
∂yt
log p(yt|Φi) = γ
num
t (i)Ri(−ΦiΣi − Φimtim
T
ti + ytm
T
ti)
×
"X
t
γ
num
t (i)(Σi + mtim
T
ti)
#
−1
mti
(20)
∂
∂yt
log p(yt|Ri) = −
γnumt (i)X
t
γ
num
t (i)
×Ri
»
R−1i − ΦiΣiΦ
T
i
−(yt − Φimti)(yt −Φimti)
T
–
Ri(yt − Φimti)
(21)
Here, mti are assumed to be constant with respect to yt. By sub-
stituting (20),(21) into (17) and by combining direct derivatives (15)
and indirect derivatives (17), we ﬁnd the gradient of the MMI objec-
tive with respect to the transformed features yt and accordingly per-
form gradient ascent to estimate the discriminative feature transfor-
mation matrixM . Each gradient ascent iteration entails three passes
over the training data which serve to
1. accumulate statistics for the indirect derivatives,
2. accumulate transform gradient and update transform and
3. accumulate statistics for BS-HMM parameter estimation in
the transformed space and update parameters.
5. EXPERIMENTS AND RESULTS
5.1. Useful Extensions for Acoustic Modeling
First, we consider a mixture model of basis vectors within each state
where each component has its own basis and precision matrices (for
sensing weights and reconstruction errors). Second, we allow the
reconstruction error to have a non-zero mean μij for component j
of state i. These means were introduced primarily in order to apply
MLLR for speaker adaptation. TheMMI estimate forμij is the same
as for GMM-HMMs. In all derivations, xt is replaced with xt−μij
and, for feature space training, the indirect derivative with respect to
μij is also considered [1].
5.2. Experimental Setup
The experiments were carried out on an English broadcast news tran-
scription task using the mixture model of BS-HMMs trained on 50
hours of transcribed audio. Results are presented on the DEV04f test
set which contains 2 hours of speech and 22.6K words.
The front-end processing consists in extracting VTL-warped
PLP cepstral frames every 10ms which are mean and variance nor-
malized on a per speaker basis. Consecutive frames in a time win-
dow of 9 frames are concatenated and projected to 40 dimensions
by an LDA transform followed by a decorrelating semi-tied co-
variance (STC) transform [9]. Words in the recognition lexicon
have a phonetic representation, and phones are modeled with 3-
state left-to-right HMMs without state skipping. All acoustic models
have pentaphone cross-word acoustic context and are speaker adap-
tively trained with feature-space MLLR (FMLLR) [9]. At test time,
speaker adaptation is performed with VTLN, FMLLR and multiple
regression tree-based MLLR transforms. The recognition vocabu-
lary has 90K words and the decoding is done with a 4-gram lan-
guage model containing 4M ngrams which was trained with modi-
ﬁed Kneser-Ney smoothing.
5318
國科會補助計畫衍生研發成果推廣資料表
日期:2011/06/15
國科會補助計畫
計畫名稱: 前瞻性機器學習法應用於語音,語言及圖形辨識
計畫主持人: 簡仁宗
計畫編號: 97-2221-E-006-230-MY3 學門領域: 自然語言處理與語音處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
簡教授榮獲 99 學年度國科會傑出研究獎，並發表多篇論文於頂尖國際會議如
ICASSP 及 NIPS Workshop，其中有數篇論文為簡教授前往 IBM T J Watson 
Research Center 進行訪問研究過程中與 IBM 同僚 Drs. George Saon, Xiaodong 
Cui 以及 Jing Huang 共同研發完成的。計畫執行期間受邀至國立新加坡大學、
Institute of Infocomm Research、日本東京工業大學、香港中文大學等頂尖
研究機構進行專題演講。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
