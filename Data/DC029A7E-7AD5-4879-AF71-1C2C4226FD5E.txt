  
2 
 
X1: 花萼長 
X2: 花萼寬 
X3: 花瓣長 
X4: 花瓣寬 
 
費雪嘗試找出這四個特徵的一個最佳線性組合來
區 分 出 不 同 品種 ， 他稱 這 個 線 性 組合 為
Discriminant: 
 
Discriminant = w1X1+w2X2+w3X3+w4X4 
 
不同品種間算得的 Discriminant分數(score)應該差
異越大越好，而相同品種的 Discriminant分數應該
越雷同越好。因此，我們希望尋得一組線性組合係
數 (w1, w2, w3, w4) 使得 
 
  不同品種之 Discriminant分數差異   
  相同品種之 Discriminant分數差異 
 
可以最大化；亦即，最小化在分母的「相同品種間
差異」，並同時最大化在分子的「不同品種間差
異」。由於這是一個線性問題，數學上很容易證明
這組最佳係數其實就是對應於矩陣 BW SS
1−
 最大
特徵值 (the largest eigenvalue) 的第一組特徵向量 
(eigenvector)，其中 Sw 是象徵相同品種間差異的
「組內」變異數矩陣而 SB則是象徵不同品種間差
異的「組間」變異數矩陣。而對應於第二大特徵值
的特徵向量亦可用來當作第二個 Discriminant 2 
的線性組合係數，兩個 Discriminants 之間可被證
明不具有統計上的關聯性。將 150個樣本分別算得
Discriminant 1 分數與 Discriminant 2 分數，令
Discriminant 1為 x軸而 Discriminant 2為 y軸，我
們便可於 x-y 平面上描繪出每個樣本的位置 (圖
一)。 
 
圖一：不同品種的 Iris樣本在費雪的 Discriminant
空間上的分布 
 
圖一中不同的符號代表不同的品種。很明顯的，
Discriminant 1可以很容易區分出其中一種品種，
但若要區分右邊集結一起的兩個品種，便需要用到
垂直方向的 Discriminant 2。費雪的 Discriminant
不但可利用簡單的數學解得，我們更可利用線性組
合的係數來詮釋每個 Discriminant的意義，我們將
兩個 Discriminant 的兩組係數值分別用直條圖 
(Bar Chart) 繪出於圖二(a)與圖二(b)。 
 
 
(a)                  (b) 
圖二： 花朵特徵於兩個 Discriminants中的重要性 
 
從圖二 (a)可看出，花瓣長與寬的係數權重在
Discriminant 1的線性組合中的貢獻度遠比花萼的
長與寬來得大，亦即，Discriminant 1是利用花瓣
大小來區分出其中的一個品種；從圖二 (b)的
Discriminant 2係數權重，我們也可發現若要進一
步區分出 Discriminant 1不能區分的兩個品種，花
萼與花瓣的寬是相對重要的特徵並應被同時審視。 
費雪的區分方法  (FLD) 是個典型的線性分類
法，我們可以用圖三的示意圖來說明其原理。 
 
X1
X2
X1
X2
3•X1+1•X2
 
(a)                  (b) 
X1
X2
1•X1+1•X2
 
(c) 
圖三：FLD的原理示意 
 
圖三(a)中，我們想利用兩個屬性 (X1與 X2) 來區
分藍色十字與紅色原點兩種類別，圖三(b)中的線
性組合 3X1+X2 似乎無法很理想地區分出兩個類
別，但圖三(c)的線性組合 X1+X2不但將不同類別
的樣本區分開來，也將同一類別內樣本間的距離拉
近了，費雪的方法便是嘗試找出這樣的線性組合當
作 Discriminant。 
  
4 
X1
X2
X12+X22
 
圖九：平方項線性組合的 Determinant 
 
我們現在的問題是要取怎樣的非線性項？圖九中
我們用了平方項，可是有先非線性問題可能需要三
次方或更高，甚至是指數 (exponential) 的非線性
項。要解決這個問題，Kernel 函數[2]扮演著最關
鍵的角色。最早利用 Kernel 函數解決非線性分類
問題的是一種機器學習技術叫 Support Vector 
Machine (SVM) [3]。Mika et al. [4]等人則利用
Kernel 函數與變異數矩陣的良好數學性質發展了
Kernel費雪區分 (Kernel Fisher Discriminant, KFD) 
方法。KFD 方法可以將有限維度的屬性空間
(attribute space)轉換到無窮多個非線性項組成的特
性空間(feature space)，並在這個特性空間尋找最佳
的 Determinant來作分類。令人驚歎的是，KFD的
解法居然和 FLD 一樣只是去解一個有限維度矩陣
的 eigenvalues 與 eigenvectors，而所解得的
Discriminants 稱為 Kernel Discriminants。圖十(a)
為一同心圓的非線性問題，圖六(b)則為利用 KFD
解得每一個樣本的 Kernel Discriminant 1 分數與
Kernel Discriminant 2分數後繪點於 x-y平面上的
示意圖。 
 
 
(a)                   (b) 
圖十：同心圓非線性問題及 KFD的區分結果 
 
從圖十(b)可看出，Kernel Discriminant 1便可將兩
個同心圓區分出來。比其他的非線性機器學習方
法，KFD 的數學性質可以被更清楚描述與了解。
但是，KFD 和多數機器學習方法一樣，無法描述
屬性在分類過程中的意義與扮演的角色。我們的研
究便是希望 KFD可以像 FLD一樣，在分類完後可
以去了解並解釋分類背後的意義；亦即，去解析各
個屬性在分類中的貢獻度。 
 
四、非線性分類之屬性解釋方法 
屬性解釋(Attribute Interpretation)對於分類方法是
非常重要的，但一般非線性的分類方法，都無法提
供屬性解釋的功能。針對非線性分類中屬性意義不
明的難題，我們提出 Kernel Segmentation 的方
法，對觀察樣本先進行分割，我們的目的是讓分割
後的各組樣本可以很容易被屬性解釋其分類法
則。由於線性分類具備屬性解釋能力(如 Iris 例子
所示)，因此我們可以利用 Kernel Discriminant 分
數將原本的樣本切割成幾個具有線性結構的小
組，並在每個小組中使用線性的費雪區別法，如此
便可得到每個小組中的屬性解釋。以同心圓為例，
如果我們可以將樣本切割成如圖十一(a)的八個區
塊(segments)，如此，每一區塊(如圖十一(b)的第一
區塊)的兩個類別便很容易利用 FLD來分類，也可
以利用 FLD的屬性解釋來了解分類的意義 
 
 
 
  
 
 
  
 
 
 
(a)                    (b) 
圖十一：非線性問題的切割 
 
圖十二(a)是另外一個非線性例子，一個類別分布
上下兩個群集，另一個類別分布成左右兩個群集。
看似簡單的一個例子，FLD 卻一樣束手無策，需
依賴圖十二(b)的 KFD來區分兩個類別。 
 
 
(a)                     (b) 
圖十二：兩類別四群集的非線性分類問題與 KFD
分類結果 
 
如果我們將四個群集作如圖十三的簡單切割，上述
的非線性問題馬上變成了兩個很簡單的線性問題。 
 
圖十三：四群集非線性問題的切割 
  
6 
 
(a)                  (b) 
圖十六：肝失調分類的屬性貢獻度 
 
表一整理了 FLD、SVM、及 Kernel Segmentation
經過 5-fold cross-validation 後的分類正確率。
Kernel Segmentation 的正確率不但可以媲美
SVM，更可以提供 SVM所沒有的屬性的分類解釋
能力。 
 
表一：各種方法的肝失調分類正確率 
5-Fold FLD SVM Kernel-partition FLD 
1 61.31 68.97 70.33 
2 63.16 70.01 69.09 
3 63.27 69.41 67.95 
4 65.02 72.11 71.46 
5 63.29 71.39 70.00 
average 63.21 70.38 69.77 
 
五、參考資料 
[1] Fisher, R.A. (1936), "The use of multiple 
measurements in taxonomic problems", Annals 
of Eugenics 7, 179-188.  
[2] Harry Hochstadt. Integral equations. Wiley 
Classics Library. John Wiley & Sons Inc., New 
York, 1989. ISBN 0-471-50404-1. Reprint of 
the 1973 original, A Wiley-Interscience 
Publication. 
[3] B. Schölkopf, C. J. C. Burges, & A. J. Smola, 
editors. Advances in Kernel Methods – Support 
Vector Machine. MIT Press, Cambridge, MA, 
1999. 
[4] Mika, S., Rätsch, G., Weston, J., Schölkopf, B., 
& Müller, K-R. (1999). Fisher Discriminant 
Analysis With Kernels. IEEE International 
Workshop on Neural Networks for Signal 
Processing, Vol. IX, Madison, USA, August 
1999, 41-48. 
 
一、  參加會議經過及與會心得 
第 39 屆的計算機與工業工程國際會議 (CIE39) 是在法國香檳區的 Troyes
舉行。Troyes 雖位於香檳區離法國首府巴黎僅有兩小時車程，因此本屆 CIE39
算相當盛大，吸引了約 50 個國家地區超過 700 篇論文的投稿，只有 347 篇論文
獲得接受並納入最後的會議議程，技術報告天數長達三天。本次參加會議之主
要目的有；了解目前全世界工業工程領域之最新研究發展趨勢、報告會議論文、
並順道拜訪與本校(國立台灣大學)簽有交換協議的 Universite De Technologie De 
Troyes(UTT) 的工業系統系系主任。 
1. 工業工程系系主任之拜訪 
本人於出發前便與該系系主任連絡，並於 CIE39 會議舉行獲得回覆，於會
議第二天前往拜會會議舉辦學校 (UTT) 的工業系統系系主任 Prof. Christophe 
Berenguer，Prof. Berenguer 本身的領域在於系統建模與系統可靠度分析。UTT
是法國少數學校有以工業系統為名的系所學校，主要是因為 UTT 是一個相對新
的學校，是法國政府近年推展以科技為核心的高等教育所新成立的學校之一，
算是重點發展學校之一，因此才有機會將在美國及台灣行之有年的工業工程領
域引入成為重點發展領域之一。該系的目標是教育未來的工程師工業系統設
計、控制、與改善的方法與技術。又分有工業系統與設置控制 (Industrial systems 
and installations control)、作業安全與環境 (Operational safety and the 
environment)、生產系統管理 (Production systems management)、供應鏈管理 
(Supply Chain Management)等四大專業領域。從其專業領域可看出該系是很典型
在理論方面有：Prof. Hans Kellerer談對稱二次背袋、排程、與 convex 二次規劃
等問題；Prof. Eugene Levner談圖學中的循環路線演算法 (Cyclic Routing 
Algorithms on Graphics) 及其於機器人排程 (Robot Scheduling) 上的應用；Prof. 
A. Ridha Mahjoub談網路可存活性與多面體分析 (Network Survivability and 
Polyhedral Analysis) 。 
本次大會是在 UTT 校園最主要的 landmark橢圓型建築物舉行，事實上交通
並不是很方便，大會所安排的住宿旅館離校園皆有一段距離，若沒有車子，必
須搭公車至某站後步行 15-20 分鐘方可到達會議現場，所提供的交通車亦不是十
分方便，因此雖然報名與會的學者專家很多，但實際在會議現場的與會者並沒
有那麼多，本人曾參加一個討論 Formal Models 的 session，卻因為其中三篇論文
中的兩篇論文作者也是 session chair 無法趕到而差點流會，最後由大會指定人員
來主持該 session 方使該 session 的唯一報告者得以報告。大會的 reception 及 gala 
banquet 皆是在Troyes的downtown舉行。Reception是在非常具歷史的Maison De 
L’outil 舉行，而 gala banquet則是在 Espace Argence 舉行，晚宴非常盛重，除了
有傳統的法國餐飲外也有模仿 Beatles 的樂團演出，就像典型的法國晚宴一樣，
一直到本人於 11:30pm 離開時，晚宴尚未結束，對於許多遠道而來交通上不方
便的與會者而言，將造成一些困擾。 
 
3. 論文發表(B3) 
本人本次參加會議主要是發表本人在國科會補助計畫「利用線性及非線性多
變量統計方法分析癌症基因微陣列資料之研究」下的研究，發表的場次為大會
