                         
Efficient Strategies for Many-task Frequent Pattern 
Mining in Cloud Computing Environments 
Kawuu W. Lin 
Department of Computer Science and Information 
Engineering 
National Kaohsiung University of Applied Sciences 
Kaohsiung, Taiwan 
linwc@cc.kuas.edu.tw 
Yu-Chin Luo 
Department of Computer Science and Information 
Engineering 
National Kaohsiung University of Applied Sciences 
Kaohsiung, Taiwan 
kim-x@yahoo.com.tw
 
 
Abstract—The goal of data mining is to discover the hidden 
useful information from large databases. Mining frequent 
patterns from transaction databases is an important problem in 
data mining field. As the size of database increases, the 
computation time and the required memory increase severely. 
Parallel and distributed computing techniques have attracted 
extensive attentions on the ability to manage and compute the 
significant amount of data in the past decades. The difficulty of 
mining large database launched the research of designing parallel 
and distributed algorithms to solve the problem.  However, most 
of the past studies did not focus on the many-task issue that is 
very important, especially in cloud computing environments. In 
cloud computing environments, application is provided as service 
like Google search engine, meaning that it will be used by many 
users at the same time. In this paper, we propose a set of 
strategies for many-task frequent pattern mining. Through 
empirical evaluations on various simulation conditions, the 
proposed strategies deliver excellent performance in terms of 
execution time. 
Keywords—Data mining, cloud computing, association rule 
mining, frequent pattern mining 
I.  INTRODUCTION 
The basic conception of frequent pattern mining problem is 
to discover the pattern whose frequency of appearance in the 
database is greater than a specific threshold. An association 
rule is defined as X=>Y, where X and Y are sets of items. The 
concept of association rule mining is to discover the sets of 
items tending to associate with the others in the database. The 
studies on association rule mining can be classified into two 
types, 1) the generate-and-test [w] (Apriori-like) approach and 
2) the frequent pattern growth approach [5] (FP-growth-like). 
The Apriori-like methods iteratively generate candidate 
itemset of size (k+1) from frequent itemset of size k and scan 
the database repetitively to test the frequency of each 
candidate itemset. Definitely, the Apriori-like methods suffer 
from the large number of candidate itemsets, especially when 
the support threshold is small.  In view of this reason, Han et 
al. [5] proposed a novel data structure, named frequent pattern 
tree (FP-tree), in which the transactions are compressed and 
stored. A mining algorithm, namely FP-growth was also 
proposed for discovering the frequent patterns from the FP-
tree. FP-growth needs only two scans on physical databases 
and therefore has a great improvement on the execution time. 
As the size of database increases, the computation time and 
the required memory increase severely. Many studies on 
association rules mining were proposed mainly to improve the 
efficiency in terms of execution time. In the past decades, 
parallel and distributed computing (PDC) techniques have 
attracted extensive attentions on the ability to manage and 
compute the significant amount of data. The difficulty of 
mining large database launched the research of designing 
parallel and distributed algorithms to solve the problem [3], 
[4], [6], [7], [8], [9], [10], [11], [12], [13]. The main approach 
of the existing studies is to divide the database and then to 
distribute each part of the database to nodes or processors for 
mining with the goal to distribute the computation loading. 
During the mining process, the nodes will exchange required 
transactions from each other. The workload of data 
exchanging among nodes becomes heavy when the average 
length of transaction is long or the size of database is large. 
Although many algorithms have been proposed, the execution 
efficiency of frequent pattern mining is still a challenge to the 
researchers due to the data explosion.    
   In [9], the authors proposed a data mining method named 
CARM, which is able to efficiently utilize the cloud nodes to 
discover frequent patterns in cloud computing environments, 
but did not discuss the many-task issue that is very important 
in this kind of environments. The authors [9] focused on only 
the aspect of speeding up the mining process for a single task. 
In cloud computing environments, application is provided as 
service like Google search engine, meaning that it will be used 
by many users at the same time. In this paper, we propose a set 
of strategies for many-task frequent pattern mining. Through 
empirical evaluations on various simulation conditions, the 
proposed strategies deliver excellent performance in terms of 
execution time.  
In the following sections, we briefly review related work in 
Section 2. In Section 3, the strategies for many-task frequent 
pattern mining are presented. The empirical evaluation for 
performance study is made in Section 4. The conclusions are 
given in Section 5. 
  
In Step B, the header table is uniformly partitioned into 
N parts in which each part has the same number of header 
items. Suppose there are M items of the header table. The 
strategy will randomly select M/N items for each 
computing node. Because the required mining time for 
each conditional pattern base is different and cannot be 
known in advance, we use random selection in this step.  
2. Balancing Strategy by Request On Demand (ROD) 
The EWS strategy is expected to incur a lot of idle time 
because the two challenge characteristics make it difficult to 
distribute the workload equally. To reduce the idle time and the 
complete time, this strategy use the method named request on 
demand. The strategy works as the following steps: 
A. Construct the initial FP-tree and the header table 
named HT. 
B. Wait for computing node’s requesting.  
C. If the computing node does not have the FP-tree, 
distribute the FP-tree with an unprocessed header item 
to the computing node for mining. Otherwise, 
distribute only an unprocessed header item to the 
computing node. 
D. Repeat Step C until all header items in HT are 
processed. 
The advantage of this strategy is that the idle time will be the 
minimal and the workload can be balanced. Although ROD has 
the advantages, the complete time is expected to be extended 
for it requires large a lot of times of data transmission over 
network. 
3. Balancing Strategy by Small Size Working Set (SSWS) 
The advantages of EWS and ROD are the minimal times of 
data transmission and the most workload balanced respectively. 
The third strategy in designed to find the trade-off between 
EWS and ROD. To avoid large amount of data transmission 
times as ROD, the proposed SSWS strategy partitions the 
header items into several working set in which the size of each 
working set is equal. Unlike ROD distributes to computing 
node one header item per time, SSWS distributes a set of 
header items per time to reduce the cost of data transmission. 
The detailed steps are as described below. 
A. Construct the initial FP-tree and the header table 
named HT. 
B. Partition the HT into disjoint subsets, where each 
subset is with the L header items. 
C. Wait for computing node’s requesting.  
D. If the computing node does not have the FP-tree, 
distribute the FP-tree with a subset of header items to 
the computing node for mining. Otherwise, distribute 
only the subset of header items to the computing node. 
E. Repeat Step C until all header items in HT are 
processed. 
In Step B, if L is large the strategy will be identical to EWS. 
If L is set to one, the strategy will be identical to ROD. 
Therefore, determining the value of L is critical to the mining 
process. 
4. Balancing Strategy by Progressive Size Working Set 
(PSWS) 
SSWS attempts to find the trade-off between EWS and ROD. 
Only through detailed experiments can determine a suitable 
value of L. In this paper, we propose a strategy that is able to 
balance the workload by adjusting the size of working set 
dynamically. Unlike SSWS using a fixed size of working set, 
this strategy decreases the size of working set progressively in 
the mining process. The strategy works as follows: 
A. Construct the initial FP-tree and the header table 
named HT. 
B. Let N be the number of available computing nodes 
and HTR be the remaining header items not processed. 
Partition the HTR into N+1 disjoint subsets, named ht1, 
ht2, ..., and htN+1. Copy htN+1 to HTR. 
C. Distribute the FP-tree with hti to i-th computing node 
for mining. 
D. Repeat Step B until all header items in HT are 
processed. 
IV. EXPERIMENTAL RESULTS 
To evaluate the performance of the proposed algorithm, 
CARM, we use IBM’s Quest Synthetic Data Generator [1] to 
generate the workload data for mining. The experiments were 
conducted on a cloud system with three clouds. The first cloud 
contains four nodes, including the kernel node, in which each 
node is equipped with an E8400 2.4GHZ CPU, 1GB of 
available RAM and 320GB of disk storage. The second cloud 
and third cloud contain four and three nodes respectively, in 
which each node is equipped with a P8600 2.4GHZ CPU, 1GB 
of available RAM and 160GB of disk storage. The network 
bandwidth among these three clouds is 100 Mbit/sec. The 
network latency from cloud 1 to cloud 2 is 20 ms on average. 
The network latency from cloud 1 to cloud 3 is 18 ms on 
average. Note that the kernel node is responsible for receiving 
the requests and is not used for mining. Therefore totally ten 
nodes can be used for mining in the system. To verify the 
performance, since there are very few parallel and privacy-
preserved algorithms of frequent pattern mining, we select the 
BTP-tree for comparison, which is one of the most efficient 
algorithms that can parallelize the mining task on grid systems. 
Both of CARM and BTP-tree were implemented in Java, and 
the message passing among nodes and remote function call 
were implemented in Java RMI technology. Since the most of 
the existing parallel algorithms are database dividing approach, 
we select the most efficient one, BTP-tree, for performance 
comparison. 
Effects of varying the number of tasks 
In the experiment, we investigate the effects of varying the 
number of tasks for the proposed strategies and BTP-Tree in 
terms of execution time by varying the number of tasks from 
10 to 50. We generate 50 dataset for performance evaluation. 
The transaction length is modeled as uniform distribution 
bounded from 10 to 30 and the mean is set to 20. The number 
 出國報告（出國類別：參加國際會議） 
 
 
 
 
 
ICSSE 2011 in Macao 
 
 
 
 
 
服務機關：國立高雄應用科技大學 
姓名職稱：資訊工程學系   助理教授 林威成 
          資訊工程學系 碩士班學生 林俊宏 
派赴國家：澳門 
出國期間：100 年 6 月 7~11 日 
 
 
 1 
 
本  文 
ICSSE (International Conference on System Science and Engineering，系統科學
與工程國際會議)是中華民國系統學會創始的國際研討會，而今年 ICSSE 2011 於
澳門之澳門大學舉行。 
出國目的 
本次出國目的為參與在澳門大學舉辦之 ICSSE 2011 國際會議，其中： 
林威成教授於 ICSSE 2011 擔任智慧型數據分析與應用之特別會議 (Special 
Session : Intelligent Data Analysis and Applications)的聯席主席。 
學生(林俊宏)出席報告被接受之論文並接受詢問； 
被接受之論文：基於 CAST 之超大型資料庫快速分群演算法研究與實作 
(COD-CAST: A Fast CAST-based Clustering Algorithm for Very Large 
Database)。 
過程 
ICSSE 2011 於 6 月 8~10 日在澳門大學圖書館舉行；其中分有 12 類主題會
議、4 個特別會議及 4 個全體會議講座。(詳細列表見附錄之會議議程，p.5) 
我們的論文於 6 月 9 日上午 11 點~12 點 30 分舉行的「智慧型數據分析與應
用之特別會議(Special Session : Intelligent Data Analysis and Applications)」中，報
告並接受詢問。該會議共 6 篇論文，我們報告順序回最後一位。 
最後，於 9 日之晚間 7 點於澳門新濠天地之君悅酒店，出席 ICSSE 2011 之
晚宴。此外，10 日由主辦單位安排澳門著名景點之巡禮。 
  
 3 
 
附  錄 
與會照片 
  
 
圖 1 特別會議聯席主席(林威成) 
 
圖 2 論文報告(學生：林俊宏) 
 5 
 
會議議程 
資料來自 ICSSE 2011：http://www.fst.umac.mo/icsse2011/program.html 
 
8-June 9-June 10-June 
8:00 am‐08:30am 
 Parallel Oral Sessions 
Free 
Macao 
City 
Tour 
8:30 am‐09:30am Open Ceremony 
09:30am-09:45am Break Break 
09:45 am‐10:45am Parallel Oral Sessions Plenary Talks 
10:45 am‐11:00 am Break Break 
11:00 am-12:00 pm Plenary Talks 
Parallel Oral Sessions 
12:00 am-12:30 pm 
 
12:30 pm-1:30 pm Lunch Lunch 
Have 
Good 
Trip! 
1:30 pm-3:00 pm Parallel Oral Sessions Parallel Oral Sessions 
3:00 pm-3:15 pm Break Break 
3:15 pm-4:15 pm Plenary Talks Plenary Talks 
4:15 pm-4:30 pm Break Break 
4:30 pm-6:00 pm Parallel Oral Sessions Parallel Oral Sessions 
Poster 
Session 
6:30 pm- Welcome reception 
 
 7:00 pm- 
 
Banquet 
共 12 項主題： 
Communication Systems, Decision and Control Systems, Emerging 
Technologies in Medical Mechatronics, Information and System Engineering, 
Intelligent Mobile Robotic Systems, Intelligent Systems, Novel Applications of 
Systems Engineering, Optimization, Systems Applications in Business and Industry, 
Systems Modeling, Tools and Simulation, Systems Science, and Traffic Science and 
Engineering 
4 個特別會議(Special Session)： 
Intelligent Data Analysis and Applications, Intelligent Systems and Application, 
Intelligent System and Its Applications, and System Modeling and Simulation 
4 個全體會議講座(Plenary Talks) 
Strategic Opportunities in Systems Engineering, Prof. Keith Hipel 
Intelligent Transportation Systems in Taiwan, Prof. Tsu-Tian Lee 
From Large-Scale Systems to System of Systems – Challenges for the 21st 
Century Sustainable Energy, Prof. Mo Jamshidi 
Manufacturing and Services: A Comparative Systems Analysis, Prof. James Tien 
 7 
 
file or check your PDF file for IEEE Xplore compliance. (Use Conference 
ID: ICSSE11xx ) 
 
3. Upload your camera-ready paper by visiting 
http://conference.iis.sinica.edu.tw/Conference-Submission/servlet/Mem
ber/PersonManipulation?FunctionName=SubmissionStatus&PageAction=submi
tPaper&actionConference=71. After login, click "Upload/Update Final 
Paper" and follow the instructions. When the message of "Upload Final 
Paper Success" appears, the upload procedure is complete. In addition, 
all accepted papers must be accompanied with an IEEE Copyright Form. When 
you complete your upload procedure, you must also click a button of "Click 
Here" to proceed to the online process to complete the IEEE Electronic 
Copyright Form. In case this fails, you can find another form at: 
http://www.ieee.org/documents/ieeecopyrightform.pdf. Download the form 
and print it out. Be sure to indicate the Paper ID and Session (Regular 
or Special) on the form. Lastly, send the completed form to ICSSE2011 
(email: icsse2011@orion.ee.ntust.edu.tw). Only do this if you were unable 
to submit the IEEE Electronic Copyright Form. 
IMPORTANT: No paper without a completed IEEE Copyright Transfer Form will 
be published. 
 
4. For a paper to be published in the ICSSE2011 proceedings, at least one 
of the authors must register. When submitting registration, please key 
in your paper ID to register your paper. For additional papers of an author, 
NT$ 4700 per additional paper will be charged. For a paper that exceeds 
six pages, there will be an extra NT$ 3300 charge for each additional page. 
No papers exceeding eight pages will be accepted in the proceedings.  
IMPORTANT: In order for the paper to be published in the proceedings, at 
least one of authors for each paper must register by May 10, 2011. Without 
Registering, your paper will not appear in the proceedings. 
 
5. Make your hotel reservation for the ICSSE 2011 by checking the page 
"Hotel Information" at the main page 
(http://www.fst.umac.mo/icsse2011/hotel.html ). 
 
Thank you very much for your contributions to ICSSE 2011. We are looking 
forward to seeing you in Macau. 
 
 9 
 
 
論文摘要 
 
The advances in nanometer technology and integrated circuit technology enable the 
graphics card to attach individual memory and one or more processing units, named 
GPU, in which most of the graphing instructions can be processed parallelly. 
Obviously, the computation resource can be used to improve the execution efficiency 
of not only graphing applications but other time consuming applications like data 
mining. CAST (Clustering Affinity Search Technique) is a famous clustering 
algorithm, which is widely used in clustering the biological data. In this paper, we will 
propose two algorithms, namely Calculation-On-Demand CAST, abbreviated as 
COD-CAST and Calculation-On-Demand CAST with GPU, abbreviated as 
COD-CAST-GPU, respectively. The first proposed COD-CAST algorithm is a refined 
CAST algorithm that can process large amount of objects more efficiently in terms of 
execution time. The proposed COD-CAST-GPU algorithm can utilize the GPU and 
the individual memory of graphics card to accelerate the COD-CAST. The 
experimental results show that our proposed algorithms deliver excellent performance 
in terms of execution time and required memory. 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：林威成 計畫編號：99-2221-E-151-046- 
計畫名稱：在雲端計算環境中資料探勘演算法暨平台之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
