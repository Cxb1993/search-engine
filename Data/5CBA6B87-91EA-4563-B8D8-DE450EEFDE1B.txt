  
multi-human and multi-robot interaction at home are 
demonstrated in detail to illustrate the proposed framework. 
 
Index Terms—social interaction, home service robot, human 
robot interaction 
 
I. INTRODUCTION 
The development of robots has been tended to serve human 
in industry and factory environment. Therefore, it is an 
important issue on how to design robots to perform home 
service and provide all kinds of entertainment activities to 
human. When a robot becomes a part of human daily life, the 
interaction relation between human and robot is important. 
The subject has been a key research topics in robotics and 
other research fields, including psychology, artificial 
intelligence, and human-robot engineering. 
In recent years, the role of robots has been changed from an 
instrument to a partner or a friend of human in the workplace 
or family. Meanwhile, researchers attend to study the way to 
change the emotion of a robot, and to establish the complex 
social relationship and cooperation of human with robots. 
The research topics are used to understand the two-way social 
interaction between human and robots. The fundamental of 
these researches is mainly based on psychology and biology. 
Strictly speaking, the interaction relationship between 
human and robot is not identical with artificial intelligence. 
The artificial intelligence is to minic the expression of human 
directly. However, the human-robot interaction is to analyze 
and comprehend the social interaction in intelligence and to 
build a suitable respond pattern. Moreover, the human-robot 
interaction not only studies the human intelligence, but also 
discusses interactively learning model. 
Traditionally, the design of robot only considers the 
interaction between robot and environment in one 
pre-planned task. Hence, the robot by a traditional design can 
not point out clearly the interaction content and timeing 
between human and robot. Therefore, it is required to 
establish a common ground between human and robot by 
analyzing their interaction pattern. The basic design principle 
is to integrate all sensory data then to combine the cognitive 
process and emotional expression. Besides, it also employs 
the self societal to find the interaction framework between 
human and robot [1: Huttenrauch et al. 2004]. 
The human usually uses the body language to support the 
voice and only needs the classification of quality in cognitive 
capability. However, the cognitive capability of robot needs 
more specificity quantification standard. For example, the 
representation of the red color is distinct in difference human. 
The representation is a rough description. But, in a robot 
system, the values of RGB are used to be a quantified data to 
represent the red color. In consequence, the human-robot 
interaction model should have the capability of management 
two different cognitive types.  
The study on the emotion of robot is based on the 
psychology. The robot is proposed by Breazeal et al. can 
determine the direction of eyes, the facial expression and the 
voice recognition. It also can show several kinds of emotion 
state such as happiness, sadness, smile. Furthermore, this 
robot is easy to make a communication with human [2: 
Breazeal 2003].  
Several applications related to the development of 
interaction between human and robot are summarized below. 
Ahn et al. make a photo-robot which can interact with human 
as well as a cameraman. The main function of photo-robot is 
to determine the action of wave and approach human to take a 
photo and upload the photo into the personal computer 
through wireless network [3: Ahn et al. 2006]. Austermann et 
al. develop a robot named MEXI which can control facial 
components to respond by determining the emotion of human 
[4: Austermann et al. 2005]. Song et al. research a robot 
system can track and orientate the position of eyes in a noise 
environment by determining the direction of sound [5: Song 
et al. 2006].  Kato et al. present a cute robot named Ifbot 
which has various facial expressions to communicate with 
human [6: Kato et al. 2004]. 
The rest of the report is organized as follows. Section II 
discusses the related work of interaction between human and 
robot. Section III presents the human-robot interaction 
framework which includes multimodal nodule, cognitive 
module and emotional module. Section IV illustrates the 
experimental design in family. Section V summarizes this 
report. 
The development of robot has been tend to offer service, 
assistance, and entertainment. The environment is from 
simple to complex and requirements of robots are from 
accuracy to safety. The role of robots is from machine to 
partner. The appearance of robots is from wheeled robot to 
humanoid robot as Honda ASIMO, Sony QRIO, and Kismet. 
In order to make robot capable of interacting smoothly with 
human, many researchers devoted to developing mechanisms 
and algorithms. Furthermore, it is a trend to combine 
psychology, sociology, cognition, and behaviorism with 
robotics and engineering. The humanoid robots are able to 
express face expression to indicate six basic emotions. For 
instance, the Kismet is built by Breazeal and it is able to move 
its eyeball, eyebrows, mouth and neck to present any kinds of 
human expression. Humanoid Robots are able to walk, run, 
and greet with people as ASIMO. 
The goal of robots is to make human life better and to help 
people to solve problems that are often happened in daily life. 
The acceptance of robot is increased by improving the 
appearance and abilities. Robots will exist everywhere to 
offer any information, help and entertainment in the future. 
At that time, robot interacts with not only single people but 
also multi people and robots simultaneously. The robot is 
usually placed in the factory, school, office, laboratory, and 
museum [2: Kanda et al. 2007] [3: Doulgeri and Matiakis 
2006]. The locations are very organization and inflexible. 
However, the society has higher varying and uncertain. The 
characteristics of society must be analyzed when robots are 
  
within last two years in the website of IEEE Xplore. 
According to different conferences and years, the amounts of 
papers are summarized in Table 1. Most of the papers related 
to the interaction between human and robot were appeared in 
the IEEE/RSJ International Conference on Intelligence 
Robots and Systems (IROS) and IEEE International 
Workshop on Robot and Human Communication (ROMAN).  
The intelligence robot system includes four types: (1) 
service robots (2) assistance robots (3) social robots, and (4) 
health care robots. In this report, social robots are mainly 
focused in detail. The study of social interactions can be 
explained in terms of the relation between human and robots, 
the using duration of robots by human, and the purpose of 
using robots. The relationship between people and robots can 
be divided into active and passive. The using duration of 
robots by human can be categorized into long-term and 
short-term. For short-term, the purpose of using robots is to 
provide services, information and entertainment. For 
long-term, the purpose is to exhibit itself personality and 
character. Robot owns the capability of facial expression, 
speech recognition, movement, emotional, and social contact 
[7: Gockley et al. 2005]. As mentioned above, these are 
summarized in Table 2. 
 
Table 1. The number of paper about social interaction in different 
conference.  
Conference (year) Numbers 
IROS(2007,2006) 48 
RoMan(2006,2005) 32 
ICRA(2007,2006) 23 
IECON(2007,2006) 9 
SICE(2007,2006) 5 
 
Table 2. The type of social robot  
People Robot Type Purpose Equipment 
Short-term 
Nonverbal 
Interaction 
Not 
 provide  
information 
Facial 
Expression 
Movement Do not  
Actively 
 interact  
with 
 robot 
Short-term 
Serve, 
Provide 
Information 
And 
entertain 
Speech 
Facial 
Expression 
Emotional 
Actively  
interact 
with 
 robot 
Long- term 
Service 
Exhibit 
Personality 
And 
character 
Social 
competence
 
The position of human is divided into bystander and 
participant in a communication. When a robot becomes as 
medium between human and human, the type of medium can 
be categorized into passive, interactive, and passive-social as 
shown in Figure 1. The passive medium means that the robot 
merely provides information to people. The interactive 
medium means that the robot not only receives requests from 
people but also presents information to people.  The 
passive-social medium means that the robot does not accept 
requests from people, but presents more information to 
people through its social ability which is the expression of 
conversation. The application case of passive-social is shown 
in Figure 2. Two robots perform the Manzai show which is 
Japanese comedy conversation by signal exchange. 
 
 
Figure 1. Three types of medium of robots. [8: Hayashi et al. 2005] 
 
 
Figure 2. Two robots perform a Manzai show in Japan. [8: Hayashi 
et al. 2005] 
   
          (a)                                    (b)   
Figure 3. (a) A receptionist robot of facial expression, speech, and  
background storytelling. [7: Gockley et al. 2005] 
               (b) A robot interacting with onlooker. [9: Hollinger et al. 
2006] 
  
Doulgeri and Matiakis 2006]. Nazim transforms an ordinary 
industrial robot into autonomous contour tracking robot by 
using intelligent behavior in obstacle avoidance to do time 
consuming work [11: Nazim 2007].  
Over the past years, robots are developed to take care of 
and entertain human in the hospital or home. Many 
researchers devoted to improve the interaction behavior 
which is lacked in industrial robot between human and robot. 
Breazeal integrates the cognition and emotion theory into 
their robot, Kismet, and demonstrates the robot interacting 
with human as a partner [4: Breazeal 2004] [7: Breazeal 
2003]. Kismet is able to express its emotion expression by 
driving its eyeballs, eyebrows, mouth and neck components 
[4: Breazeal 2004] [7: Breazeal 2003]. Arkin et al. describe 
the role of the ethology and emotion models as the basis in the 
framework of entertainment robot, AIBO [6: Arkin et al. 
2003]. AIBO is a dog-like pet robot and respond to external 
stimuli from unknown environment through action sequence 
generator [9: Fujita 2001]. 
From the previous works, the human-like or animal-like 
robots enable people to understand their body language and 
promote people to interact with robot unconsciously. Hence, 
the appearances of the robot play a specific role in the human 
robot interaction. Kanda et al. analyze the participant 
impressions and behaviors toward two humanoid robots, 
Robovie and ASIMO, in simple human robot interaction [1: 
Kanda et al. 2008]. The results reveal that the different 
appearances affect participant nonverbal behaviors. In terms 
of the interaction behavior between human and robot, Kanda 
et al. design robot behavior according three principles. First is 
calling human by name.  Second is to adapt its behaviors for 
each human. Third is to confide its personal secret to the 
human who have interacted with robot for a specific time [2: 
Kanda et al. 2007]. 
The purpose of development of the robots is to promote the 
human life to become more comfortable and more convenient. 
Hence, it is not only to concern about the functions of robots 
but also the psychology state of the people and what 
information is really needed to offer to human. Shibata 
discusses the design issue of the robot in terms of psychology 
and describes the differences of the industrial and service 
robot in terms of their psychological enhancement [5: Shibata 
2004].  
Studies regarding robot interactive behavior often 
concentrate on the appearances, functions, reaction 
programming and motor system. Although robots integrate 
the emotion and cognition theory, robots only have the 
likeness of human. It efficient reduces the distance between 
human and robot and raises the will of human to interact with 
robot. However, humans always lose their inclination of 
interacting when they find the nature of robot [2: Kanda et al. 
2007] [8: Fong et al. 2003]. Nagai et al. analyze the features 
in parent-infant interaction, then discover parent knowing to 
significantly alter their infant directed actions versus 
adult-directed ones e.g. make more pauses between 
movements. They utilize the features to design a robot 
learning system to allow robot equipping with the infant 
ability [10: Nagai et al. 2007]. Therefore, it is important to 
make human to interact continually with robot. If robot is able 
to predict the next step or psychological state of human, then 
robot is capable of adopting the adaptive behavior to human.  
The current trend is towards to investigate the interaction 
between single robot and single human [2: Kanda et al. 2007] 
[4: Breazeal 2004] [7: Breazeal 2003] [8: Fong et al. 2003]. 
However, humans are social and group-living creatures. The 
relationship between human and robot is towards that in 
multi-robot and multi-human. Therefore, the robots need to 
communicate with each other to complement their 
insufficiency of abilities. Consequently, the contents of 
communication are an important subject and the role of robot 
is required to redefine. 
The purpose of this paper is to extract the characteristics 
existing in the dynamical interaction behavior between 
human and human. The characteristics guide us to design the 
perception framework of robot. The cooperation of robots is 
also integrated into it. More details of perception framework 
are described in the next section.  
 
對於機器人如何判斷人的意圖，Valibeik et al. 在2009
年提出利用Contextual Information和Bayesian network來
判斷人的意向。Valibeik et al. 利用頭部偵測和追蹤來定
位與辨別不同人。Valibeik et al.會以頭部為主要偵測部
位，是因為在人與人的互動中，頭部(臉部)的方向通常也
代表著人所注意的人事物所處的方位，因此，利用頭(臉)
部的方向性、Bayesian network的統計分析，和更多的資
訊，例如:眨眼或是相對的3D位置，Valibeik et al. 成功的
將一群人們分成好幾組的互動群組 [8: Valibeik et al. 
2009] 。 
對於機器人之間的溝通模式，Nishiyama et al.在1998年
提出Multiagent Robot Language (MRL)來讓多個代理人能
夠溝通的協定，主要是透過廣播的方式做溝通，而不是
一對一。MRL主要強調是語意層級上的溝通，而不是傳
統的訊號傳輸。代理人主要有三個層級: Super (Root) 
agent、 Sibling agent和Sub-agent。Super agent是唯一的，
負責管理Sub-agents，Super agent相對於Sibling agent而
言 ， 就像 是 路 由器 一樣； Sibling agent 有相同的
Super-agent，彼此之間不溝通；Sub-agents彼此之間透過
廣播的方式來傳遞訊息，並且會確認要傳遞的訊息是否
是重要的[7: Nishiyama et al. 1998]。 
對於機器人生活在人類的環境中，是否應該要去避免
掉某些會讓人討厭的行為。Koay et al.在2006暑假做了一
個為期五個星期的人與機器人共同生活的實驗，實驗場
景位於University of Hertfordshire的Robot House中的擬家
庭環境中。總共有五個互動的場景包含兩種試驗，一種
為測試人們喜歡的互動類型，另一種為機器人參與人們
習慣性活動時，人們的反應為何。五個互動的場景為: 
“Hot and Cold” game、Robot in the family、Confidential 
  
 
Figure 6. The interaction relation exists among robot, parent, and 
child. 
 
The robot carries various scenarios such as playing with 
child, studying with child, watching safe of child and taking 
care of child and so on. The robot has multimodal interaction 
model, cognitive model and emotional model in every 
scenario. Figure 7 shows more details interaction process. 
Step 1: parent decide one scenario through touchscreen on 
robot. Step 2: robot adopts a suitable action and interaction to 
child and enhances the right behavior through detecting the 
respond or emotion of child. Step 3: based on the cognition 
and emotion level of child to analyze the responds and 
categorize those then robot responds to child. Step 4: when 
child finishes action or shows bad emotion, the robot informs 
parent of the time that they should appear. 
 
 
Figure 7. The interaction framework of robot, parent, and child. 
 
 
                                           (a) 
 
                                           (b) 
 
                                       (c)  
Figure 8. Learning scenario.  
(a) Robot observes the interaction of father with child.  
(b) Robot becomes as medium between father and child.  
(c) Robot informs the father appearance. 
Figure 8 shows a learning scenario. First, father is teaching 
child how to draw a triangle and robot only observes the 
interaction between father and child. When child starts to ask 
repeated actions or questions and father has to do other thing 
as job, the robot becomes a bridge or medium between father 
and child. The robot has the capability of teaching child to 
draw a triangle. The communication channel of robot and 
father uses network. When emergency situation happens, 
robot sends a message to inform father. It is important that the 
robot is not to replace the position of father. The design of 
robot is to create a better entertainment in family. 
 
V. DESIGN CONCEPT 
 
A. Motivation 
The exchange procedure of information of human is a very 
complex in a communication process. Human 
communication can be categorized into verbal and nonverbal. 
Nonverbal includes body language, picture, scripts and 
symbols. In face-to-face communication, exceed 65% is 
using nonverbal.  The bi-communication processes of human 
are described in Figure 1. The procedures of the encoding 
component are affected by four rules that are skills (reading, 
listening, speaking, and reasoning), attitude, knowledge, and 
background social system. The gateway means medium, for 
instance, cell-phone, msn, skype etc. The procedures of the 
decoding are also affected by the same rules of encoding.  
Virginia Satir is a famous American psychotherapist, 
especially for family therapy. Satir purposes five types of 
human communication as follows, acquiescent, blameful, 
rational, interruptive, and identity.  The identity 
communication is an optimum way to exactly express oneself 
emotion, thought, feeling, and experience to other people. 
 
Figure 1.  Bi-communication of human. 
 
  
 
 
 
 
input image( ) sound( ) distance( ) ,  , , 1, 0,1
image face(book) detection, body motion, edge
sound word, loud, direction
distance far, average, near
1,   face(book) detection
0,  body motion
1,  edge
     

    







1,  word 1,  far
0,  loud 0,  average
1,  direction 1,  near
, , are decided by the characteristics of interaction scenario
,   , 
   

 


 
 
        

(b) 
Figure 2.  (a) Perception framework of single robot. (b) The illustration of 
defining  . 
 
(2) The communication way between robots  
The interaction pattern between human and robot will 
change into multi-human-multi-robot in the future, since 
human is group-living creatures. As we know, the family is as 
small-scale society. Besides, abilities of robots are different 
because of their purpose. For example, industrial robots are 
designed to be powerful, accuracy and efficiency but 
entertainment robots are designed to be more delights, and 
loveable. Therefore, the communication of robots is a vital 
issue when robots need to cooperate to achieve a goal in a 
home. The transmission model of robots is categorized into 
two levels, information and data, based on the information 
flow model of human in sociology [14: Turner 1998].  
The information level means that the message exchanged is 
already a sentence that is decided at perception stage of robot. 
It is presented in Figure 3(a). The elements of a sentence 
consist of five parts, identity, time, location, emotion, and 
behavior in Figure 3(c). The attributes of each parts is shown 
in Table 2. H_ and R_ indicate human and robot, respectively. 
F, M, GF, GM, B, S denote father, mother, grandfather, 
grandmother, brother and sister, respectively. R_A, R_E, 
R_C show that robot is for the adult, elder, and child, 
respectively. The data level means that the message 
exchanged is a raw data.  In Figure 3(b), sensor data of a robot 
might come from another robot. 
 
(a) 
(b) 
 
(c) 
Figure 3. (a) Information level.  (b) Data level. (c) Protocol for information 
level 
 
Table 2. The format of the protocol 
Identity H_F, H_M, H_GF, H_GM, H_B, H_S, R_A, R_C, R_E 
Time Morning, Noon, Afternoon, Evening, Hour, Minute 
Emotion H_Common, H_Angry, H_Happy, H_Sad 
Location LivingRoom, Bedroom, Kitchen, Bathroom 
Behavior
H_Moving, H_Cooking, H_Reading, H_Singing, 
H_ListeningNews, R_PlayingMusic, R_PlayingNews, 
R_Moving, R_Reading, R_ShakingHand, R_OpeningLight, 
R_AvoidingObstacle, R_Exploring 
 
VI. EXPERIMENT 
 
The experiment scenarios are designed to present that 
robots are integrated into the daily life of human in a family. 
The purposes of robot are to entertain human, satisfy human 
needs, and reinforce the happiness in a family. More details of 
scenario are described as follows. 
 
A. Scenario 
Three interaction scenarios present different targets and 
robots play distinct role. First scenario shows the target that is 
to assist human to achieve something. Second scenario shows 
the goal that is to entertain humans. Third scenario shows the 
objective that is to satisfy human needs. The diagram of three 
scenarios is presented in Figure 4(a), Figure 4(b), and Figure 
4(c), respectively.  
First scenario is that mother cooks in the kitchen, and robot 
on the side to offer information about food and warn of the 
emergency situation. Robot also records the customs of 
mother. In this scenario, image detection ability is important. 
Robot uses camera to obtain the state of food and shows the 
information about food in the screen. The feature of image is 
face/food detection ( 1  ). Robot is also able to record the 
process of cooking for human. When cooking is finished, 
robot responds to close the light, gas and switch of oven or 
other electric products. In Figure 4(a), the green line between 
human and robot represents the information flow. Robot 
  
Start
request
Check its 
ability
priority
stop
ask for help
yes
no
can do
can’t do
interrupt the 
current task 
to execute 
new task
schedule
high
low
Check 
others’ 
ability
yes
Not 
support
no
 
Figure 2. 機器人彼此溝通機制和合作機制的流程圖 
VIII. SIMULATION 
在 這 一 節 裡 ， 利 用 Matlab/Simulink 裡 的 一 個
Toolbox –Stateflow來模擬和呈現一個真實家庭中會出
現的互動場景，可以清楚的看見狀態之間的轉移，這裡
的狀態是指互動事件，例如: 爸爸回家、爺爺吃藥和小
孩在念書等。同時，也可以看見當互動事件發生時，合
作機制的狀態轉移。 
A. Script 
場景 機器人的行為 
Scenario 1: 
下午的家中只有老人獨自在
睡著午覺。機器人Julia定時來回
的在客廳以及廚房巡邏守護著家
裡的安全。傍晚，Julia偵測到小
孩放學回家後，送出小孩已回家
的訊息，PiPi機器狗收到此訊息
時，則開心的在客廳走來走去搖
著尾巴歡迎他的小主人回家。小
孩之後就抱著PiPi到房間開始念
書。 
 Julia: 
 定點巡邏、保全、避障 
和家中成員偵測。 
 PiPi: 
 在客廳亂走。 
 合作機制: 
 藉由Julia送出小孩回家 
的訊息，協商機制發出
訊息給PiPi，告知小孩已
回家了。 
Scenario 2: 
Julia發現爸爸回家了之後，主
動的朝爸爸身邊移動，並且慰問
他一天的辛勞。爸爸回到家的第
一件事，就是關心每個家中成員
是不是都在家裡。爸爸問了Julia
爺爺和小孩的情況之後，Julia則
根據PALII和PiPi所回傳的使用
者狀態，告訴爸爸他們現在的情
況。 
 Julia: 
 語音互動、朝爸爸移
動。 
 合作機制: 
 收到Julia送出要知道爺 
爺跟小孩的狀態，合作機
制立刻將所儲存的最新
狀態回傳給Julia。              
Scenario 3: 
爺爺在房間中利用PALII玩著
益智問答並且快樂的唱著歌。爺
爺每天定時量心跳、血壓的時間
到時，PALII即提醒爺爺該做測量
了，並送出測量需求，使護士機
器人可以準備開始幫爺爺測量
了。護士機器人幫爺爺量完血壓
之後，送出測量完畢的訊息。此
時PALII再度提醒爺爺吃藥的時
間到了，爺爺吃完藥之後，就開
始玩護士機器人身上的wii 遊
戲。護士機器人送出開始玩遊戲
 PALII: 
 益智問答、卡拉ok互 
動、吃藥、量心跳、量
血壓定時設定。 
 護士機器人:  
 心跳、血壓測量、與爺
爺遊戲互動。 
 合作機制: 
 收到PALII送出要爺爺 
良心跳和血壓，合作機立
刻傳給護士機器人要其
準備好。 
 收到 護士機器人要求小
的訊息，並且要求小孩和PiPi一
起過來同樂，但是因為PiPi偵測
到小孩目前還在讀書，沒有辦法
過來玩遊戲，遂將此訊息回傳。
孩與PiPi一起同樂的訊
息，經過狀態比對，發
現小孩與PiPi正在讀書
互動，因此，合作機制
發送小孩沒有辦法過來
個訊息給護士機器人，
讓護士機器人將此訊息
回到給爺爺。             
Scenario 4: 
小孩念完書之後，PiPi送出小
孩想要出去玩的訊息。Julia收到
此訊息之後，就問在客廳的爸
爸，小孩書念完了，可以出去玩
了嗎？爸爸看看時間也差不多
了，就說可以，並透過Julia回傳
此訊息給PiPi。PiPi收到訊息後就
告訴小孩說，爸爸肯讓他出去玩
了。PiPi可傳小孩要出去玩的訊
息，並通知PALII，讓PALII通知
爺爺可以帶著小孩出去散步。 
 Julia: 
 語音互動。 
 PiPi: 
 語音互動。 
 合作機制: 
 收到PiPi送出小孩想出 
   去玩的訊息，合作機制  
   知道Julia與爸爸正在互 
   動，因此將小孩想出去 
   玩的訊息給Julia，讓Julia
   將此訊息傳遞給爸爸。
 收到Julia回傳爸爸願意 
讓小孩出去玩，合作機
制立刻回傳此訊息給
PiPi和PALII，讓爺爺帶
著小孩出去散步。 
B. State Flow 
Matlab/Simulink ToolBox – Stateflow是根據有線狀態機
理論所發展成為事件驅動系統的一個交互式設計和模仿
的工具.Stateflow提供圖像化元素的的語言，以自然，可
讀和可理解的形式，用來描述複雜的邏輯。Stateflow與 
MATLAB/Simulink提供一個包含控制，監督和邏輯的高
效率嵌入式系統的設計環境。 
Stateflow理的狀態有兩種設計方法，一種為Hierarchy，
另一種為Parallel。而狀態間的轉移是以事件驅動的的方
式並用箭頭表示狀態的轉移方向，箭頭上面描述著狀態
轉移的條件與狀態轉移時要做的動作。何謂Hierarchy呢?
簡單的說，即只要一個state之內還有substate, 便形成
Hierarchy。只有substate的上層superstate啟動後,下層的
substate才會啟動；任何階層的state,都可以建立parallel 
states，一個state中，只能全部是parallel或全部是exclusive 
states。狀態之間的轉移語法如圖三所示 [10: 童元鍼 
2008]。 
 
狀態A 狀態B
事件[事件要發生的條件]{條件成立時所做的事}/狀態轉移成功時所做的事
Figure 3. Stateflow裡狀態之間的轉移語法 
在這篇論文中，所撰寫的Stateflow 模型，其狀態均為
Parallel，因為在家庭中的成員互動，並不是序列性的，
而是同時在發生的。首先，在Simulink裡建立事件輸入和
合作機制、Julia、PALII、PiPi和護士機器人的有限狀態
機模組。如圖四所示。接著，利用Stateflow我們建立兩
個 parallel 狀態，分別為:Coordination 和 FinalEvent 。
  
models have been proposed and one of those is used to 
establish our interaction model in family. In order to adapt to 
the various environment and responds from people, the 
multimodal interaction module is necessary. Further, 
cognition and emotion process are important component of 
interaction behavior between human and human. Hence, 
robot also has cognitive and emotional module. Section VI 
presents a experiment scenario about the interaction among 
robot, child and parent. 
The future work is to analyze the appearance time and stay 
time of father in interaction process. To characterize the 
quantity and quality of symbol transmitted by network and to 
correspond the meaning of symbol to words used in human 
interaction. 
The perception framework and communication way of 
robots are proposed in the paper. By focusing the features of 
human behavior and emotion, for instance, attention, face 
expression and unconscious actions.  Robot adopts adaptive 
behavior to human based on the decision module after 
perception component. The prediction module of decision 
component predicts effectively the human behavior after 
robot responds. Robot maintains the long-term friendly 
relationship with human by doing right action and decision in 
the right time. The experiment design of multi-human and 
multi-robot is also described in the Section IV. Three 
scenarios are presented as follows, one human with two 
robots, two humans and two robots, and three humans and 
three robots. Robots play a different role and function in 
difference scenarios. The transmitted message is classified 
into two scales as information and data level. The information 
protocol consists of five elements as human, time, emotion, 
location, and behavior. The data level emphasizes the 
supporter connection between robots. That is, the deficiency 
of sensors abilities is supported from robots. 
Future work is to analyze the experiment results and to 
reinforce the completeness of perception framework. 
Moreover, the development of mathematics model of 
interaction process between human and robot is also the goal. 
最後提出了多機器人之間的溝通模式與平台的建立。
利用有限狀態機的理論和Matlab/Simulink – Stateflow，得
以建立一個在真實家庭中會出現的互動場景。基於
Nishiyama et al. 在 2000年的提出的Multiagent Robot 
Language，設計出適用於機器人與機器人的溝通合作機
制，機器人可以根據事件的優先權加以排程，當收到其
他的機器人的要求時，合作機制會依據現階段的個子機
器人的狀態、能力、所處的位置和服務的對象，來協調
各個子機器人彼此之間的互助合作。每個子機器人的能
力都是根據其服務對象的年齡層所設計的，當機器人進
入家庭後，家庭成員互動的多樣性，使得機器人必須合
作以提供更好的互動品質。 
X. 計畫成果自評 
 
在本計畫的研究中，我們提出了機器人的感知架構和溝通的
方式。機器人可以藉由注意到存在於人類行為中的特徵和情
緒，例如：注意力、臉部表情和無意識行為，來採取適當行為，
這些行為是經由感知元件感知人類行為後，再由決策模組所決
定。預測模組可以在機器人採取行為後，能有效的預估人類行
為的變化，因此，機器人可以在正確的時機做出正確的行為，
因而能夠跟人類維持長期且友好的關係。在第四節中呈現三種
多人多機器人的實驗場景設計：一人對一個機器人、兩人對兩
個機器人、三人對三個機器人。在這三種不同場景中，機器人
分別扮演著不同的角色和功用。在機器人與機器人溝通的模式
上，分為兩個層級來探討，分別為：資訊的層級和資料的層級。
在資訊的層級上，由五種協定組成：身份、時間、情緒、 地點
和行為。在資料的層級上，主要是著重於機器人之間的互相支
援，也就是說，感測器功能上的不足可以從別台機器人上獲得
支援。未來將著重於分析實驗的結果和數據 並且加強感知架構
的完整性，同時，發展存在於人與機器人中的互動方程式，也
是未來的目標之一。 
除此之外，建構了一個整合環境情境感知的控制系統和機器
人與機器人之間的通訊合作平台。藉由環境感測器的建構，機
器人可以獲得更多空間中移動物和靜態物的相關位置，以及家
中成員和其他子機器人所處的位置。合作平台的建立，讓機器
人彼此之間透過合作來提供家中成員更豐富的休閒娛樂，機器
人只需要關注在目前跟服務對象的互動，如果有需要支援，只
需要將訊息傳送到合作平台，合作平台會透過比對機器人狀
態、能力、事件優先權的高低和所處的位置，來找出最適合的
機器人前去支援。一個整合環境感知、人機互動和機器人與機
器人互動的智慧型系統的建構將帶給人們更舒適歡樂的家庭環
境。 
 
計畫查核點及審查要項： 
 
查核點 查核項目 具體評量指標 
完成居家環境之中，不同年齡層的成員在於休閒娛樂的需
求型態與影響規劃  
休閒
娛樂
的需
求與
影響
分析在家庭中，兒童、青少年、中年人、老年人，對休閒
娛樂的需求型態以及所具備的影響性。 
完成對家庭中的成員於互動上所需要之基本行為模式與相
關訊息交換機制之設計與規劃  
第
一
年
度
上
半
年
人類
互動
行為
模式
與訊
息交
換機
制  
  
在社會學中，存在著討論人類社會互動結構的模型，我們
利用這個模型設計出在家庭中，父母、機器人、小孩的基
本的互動行為模式。關於訊息交換的機制主要是建立在，
手勢、語言、音調、情緒和個人認知背景，這五個重要的
因素上。進一步定義出在每次的互動中，訊息所代表的量
與質，接著歸納出數個層級，並且實際應用所設計的情境
例子中。 
 
查核點 查核項目 具體評量指標 
完成一套家庭成員與各類機器人之間的互動溝通平台之設
計  
第
一
年
度
下
半
年 人機
互動
溝通
平台 對於家庭中人機互動溝通平台，藉由人與人互動的模式架
構，推展至人機互動溝通的平台。對於平台所採用的網路協
定，討論在傳送符號訊息的過程中，符號的量與質與實際人
類互動所採用的訊息的相對應。當機器人變成人與人溝通之
間的媒介時，傳遞訊息的頻率就顯得很重要，藉由
Shannon＇s information theory，來分析傳遞訊息所需頻
  
Kai-Tai Song, Jwu-Sheng Hu, Chi-Yi Tsai, Chung-Min Chou, 
Chieh-Cheng Cheng, Wei-Han Liu, and Chia-Hsing Yang,  “Speaker 
Attention System for Mobile Robots Using Microphone Array and Face 
Tracking,＂Proceeding of the 2006 IEEE International Conference on 
Robotics & Automation, pp. 3624-3629, Orlando, Florida, May 2006.  
[6: Kato et al. 2004]  
Shohei Kato, Shingo Ohshiro, Hidenori Itoh, Kenji Kimurai, 
“Development of a Communication Robot Ifbot,＂Proceedings of the     
2004 IEEE International Conference on Robotics & Automation,  
pp. 697-702, New Orleans, LA, April 2004. 
[7: Gockley et al. 2005] 
R. Gockley, A. Bruce, J. Forlizzi, M. Michalowski, A. Mundell, S. 
Rosenthal, B. Sellner, R. Simmons, K. Snipes, A. C. Schultz, and J. 
Wang, '' Designing Robots for Long-Term Social Interaction,'' IEEE/RSJ 
International Conference on Intelligent Robots and Systems (IROS 2005). 
pp. 1338-1343, 2-6 Aug. 2005. 
[8: Hayashi et al. 2005] 
K. Hayashi, T. Kanda,  T. Miyashita, and H. Ishiguro, N. Hagita, "Robot 
Manzai–Robots’Conversation as a Passive Social Medium," 
Proceedings of 5th IEEE-RAS International Conference on Humanoid 
Robots, pp. 456-462, 5-7 Dec. 2005. 
[9: Hollinger et al. 2006]  
G. A. Hollinger, Y. Georgiev, A. Manfredi, B. A. Maxwell, Z. A. 
Pezzementi, and B. Mitchell, “Design of a Social Mobile Robot Using 
Emotion-Based Decision Mechanisms,” Proceedings of the IEEE/RSJ 
International Conference on Intelligent Robots and Systems, Beijing, 
China, pp.3093-3098, 9-15 Oct. 2006. 
[10: Lee et al. 2005] 
K. W. Lee, H.-R. Kim, W. C. Yoon, Y.-S. Yoon, D.-S. Kwon, “Design A  
Human-Robot Interaction Framework For Home Service Robot,” IEEE  
Interactional Workshop on Robot and Interactive Communication,  
pp.286-292, 2005.  
[11: Murcie 2002]  
John Murcie, 家庭社會學, 韋伯文化國際, 2002. 
[12: Turner 1998]  
Jonathan H. Turner, A theory of social interaction, Stanford University 
Press, 1988. 
[13: Bales 2002]  
Robert Freed Bales, Social interaction systems : theory and 
measurement, New Brunswick, N.J. : Transaction Publishers, 2002. 
[14: Hare et al. 2005]  
A. Paul Hare et al., Analysis of social interaction systems: SYMLOG  
research and applications, University Press of America, 2005. 
[15: 台灣省國民學校教師研習會 1996] 
    台灣省國民學校教師研習會, 兒童美術教育理論與實務探討, 台灣省
國 
民學校教師研習會, 台北縣板橋市, 1996. 
 
[1: Kanda et. al 2008]  
T. Kanda, T. Miyashita, T. Osada, Y. Haikawa and H. Ishiguro, 
“Analysis of Humanoid Appearances in Human-Robot Interaction,” 
IEEE Transactions on Robotics, vol. 24, no. 3, pp. 725-734, June, 2008. 
[2: Kanda et al. 2007]  
T. Kanda, R. Sato, N. Saiwaki and H. Ishiguro, “A Two-Month Field 
Trial in an Elementary School for Long-Term Human-Robot 
Interaction,” IEEE Transactions on Robotics, vol. 23, no. 5, pp. 
962-971, October, 2007. 
[3: Doulgeri and Matiakis 2006]  
Z. Doulgeri and T. Matiakis, “A Wed Telerobotics System to Teach 
Industrial Robot Path Planning and Control,” IEEE Transactions on 
Education, vol. 49, no. 2, pp. 263-270, May, 2006. 
[4: Breazeal 2004] 
C. Breazeal, “Function Meets Style: Insights from emotion Theory 
Applied to HRI,” IEEE Transactions on System, Man, and Cybernetics- 
part C: Application and Reviews, vol. 34, no. 2, pp. 187-194, May, 
2004. 
[5: Shibata 2004]  
Shibata, “An Overview of Human Interactive Robots for Psychological 
Enrichment,” Proceeding of the IEEE, vol. 92, no. 11, pp. 1749-1758, 
November, 2004. 
[6: Arkin et al. 2003] 
R. Arkin, M. Fujita, T. Takagi and R. Hasegawa, “An Ethological and 
Emotional Basis for Human-Robot Interaction,” Robotics and 
Autonomous Systems, vol. 42, pp. 191-201, 2003. 
[7: Breazeal 2003] 
C. Breazeal, “Toward Sociable Robots,” Robotics and Autonomous 
Systems, vol. 42, issues 3-4, pp. 167-175, March, 2003. 
[8: Fong et al. 2003]   
T. Fong, I. Nourbakhsh and K. Dautenhahn, “A Survey of Socially 
Interactive Robots,” Robotics and Autonomous Systems, vol. 42, pp. 
143–166, 2003. 
[9: Fujita 2001]   
M. Fujita, “AIBO: Towards the Era of Digital Creatures,” International 
Journal of Robotics Research, vol. 20, no. 10, pp. 781–794, October, 
2001.  
[10: Nagai et al. 2007]   
Y. Nagai, C. Muhl, and K. J. Rohlfing, “Toward Designing a Robot that 
Learns Actions from Parental Demonstrations,” IEEE International 
Conference on Robotics and Automation, Pasadena, CA, USA,, pp. 
3545–3550, May 19-23, 2008. 
[11: Nazim 2007]   
M.-N. Nazim, “AIBO: Towards the Era of Digital Creatures,” 
Proceeding of the IEEE International Conference on Mechatronics and 
Automation, Harbin, China, pp. 3931–3936, August 5-8, 2007. 
[12: Partan & Marler 1999]   
S. Partan and P. Marler, “Communication Goes Multimodal,” Science, 
vol. 283, pp. 1272-1273, February, 1999.  
[13: Meredith 2002]   
M. A. Meredith, “On the Neuronal Basis for Multisensory Convergence: 
A Brief Overview,” Cognitive Brain Research, vol. 14, pp. 31-40, 2002. 
[14: Turner 1998]  
Jonathan H. Turner, A theory of social interaction, Stanford University 
Press, 1988. 
 
[1: ASIMO]  
http://world.honda.com/ASIMO/ 
[2: AIBO]  
 http://support.sony-europe.com/aibo/ 
[3: Shimon Y. Nof 1999]  
Shimon Y. Nof, Handbook of Industrial Robotics, 2nd edition, John 
Wiley & Sons,  1999.   
[4: ServiceRobots] 
     http://www.ifr.org/service-robots/  
[5: Lee & Yannakakis 1996]  
D. Lee, M. Yannakakis, “Principles and methods of testing finite state  
machines-a survey,” Proceeding of the IEEE, vol. 84, no. 8, pp.  
1090-1123, August 1996. 
[6: Nishiyama et al. 2000] 
H. Nishiyama, W. Yamazaki, and F. Mizoguchi, “ Negotiation Protocol 
Proof of Realization of Cooperative Task in Multi-Agent Robot  
System,” IEEE International Conference on Systems, Man, and 
Cybernetics, vol. 3, pp.1685 - 1690, 8-11 October 2000. 
[7: Nishiyama et al. 1998] 
H. Nishiyama, W. Yamazaki, and F. Mizoguchi, “A Multiagent Robot 
Language for Communication and Concurrency Control,” Proceedings 
of International Conference on Multi Agent Systems, pp. 206-213, 
Paris, France, 3-7 Jul 1998. 
[8: Valibeik et al. 2009]   
S. Valibeik, J. Ballantyne, B. Lo, A. Darzi and G.-Z. Yang, 
“Establishing Affective Human Robot Interaction through Contextual 
Information,” 18th IEEE International Symposium on Robot and 
Human Interactive  Communication, Toyama, Japan, Sept. 27-Oct. 2, 
2009. 
[9: Koay et al. 2009]   
K. L. Koay, D. S. Syrdal, M. L. Walters, and K. Dautenhahn, “Five 
Weeks in the Robot House – Exploratory Human-Robot Interaction 
Trials in a Domestic Setting,” Second International Conferences on 
Advances in Computer-Human Interactions, Mexico, pp. 219-226, 1-7 
Feb. 2009.  
[10: 童元鍼 2008]   
童元鍼, “動態邏輯系統建模－Stateflow 7.0入門,” 鈦思科技股份有
限公司, 2008.  
 
 
2
報告內容 
 
一、 參加會議經過 
 
今年的CDC國際會議是第四十八屆了，本屆會議的主辦城市是中國的上海，這是第三次在
西太平洋岸舉行，另外，也是第一次同時由CDC與中國的第二十八屆的CCC同時舉行，會議期間
為十二月十五至十八號在上海的國際會議中心舉行。 
本次會議之議期共計四天，會議第一天(12/15)為大會的Workshop與歡迎會，Workshop的主
題為：“20 years of passivity-based control: theory and applications＂, “Five decades 
of ho-ntrol and ho-ptimization＂ , “Network science: New directions in control systems＂ , 
“Biomolecular circuit analysis and design ＂ , “Model predictive control: Design and 
implementation using Matlab＂。 
其後的三天(12/16-18)即為主要的議程，主要包含一個Bode Lecture，三個主題演講，四個
重點演講，以及九個論文報告與互動式討論時段。今年的Bode Lecture是由加拿大McGill 
University的Prof. Peter E. Caines所發表的“Mean field stochastic control＂，三個主題
演講分別為：來自美國 Harvard University 的 Prof. Roger W. Brockett，講題為：“Poisson 
processes and the design of finite state controllers＂、 來自美國 University of Illinois 
的 Prof. P.R. Kumar，講題為：“Towards a system theoretic foundation for control over 
networks＂、以及來自美國Washington University 的 Prof. Tzyh Jong Tarn，講題為：“New 
opportunities for control: Quantum internal model principle and decoherence control＂。 
本屆大會總共有3105篇論文投稿，最後共計有1473篇左右的論文被接受發表，這個投稿論文
數，再次創了CDC的紀錄。所有論文發表分散在九個論文發表與互動是討論時段時段，每個時段同
時約有二十個場次的專題報告，以及一個場次的互動式海報討論專區。專題演講每天早上各兩場
場，主題論文則分佈於三天的早上的一個與下午的兩個時段，報告議程緊湊而豐富，為聆聽此等
論文的報告，個個與會者均在會場穿梭奔波，不亦忙乎。 
 
 
 
4
 
專題演講 by Prof.Jadbabaie 論文報告 
 
參與廠商 參展書商 
 
大會晚宴 大會晚宴表演：頂上芭蕾 
 
 
二、與會心得 
 
IEEE CDC乃是國際間控制領域中最重要的國際會議之一，藉由參與此盛會，可以與國際間控
制界重量級的人物交換最新的研究心得，本屆會議中，本人參與了大會的開幕式，IEEE CSS年度
獎項的頒獎典禮，瞭解目前最資深與最先進的學者他們的研究領域，以及Bode Lecture與主要的
專題演講與專題報告，同時也在互動式的論文報告中與與會的學者交換相關的意見。同時，也藉
 
 
6
 
 
魯迅故居  
 
 
四、建議 
 
無 
 
 
五、攜回資料名稱及內容 
 
Proceedings of 2009 IEEE 48th International Conference on Decision and Control 
Proceedings of 2009 IEEE International Conference on Robotics and Biomimetics 
Journal of Systems Biology 
IET Journal of Control Theory and Applicaions 
Call for Papers: CDC 2010, Asian Journal of Control 
Control and Robotics 相關產品書面與光碟資料 
  相關研究計畫成果報告書面簡報 
 
 
六、其他 
感謝教育部與國科會贊助此次參與國際會議之旅費與此項研究計畫之研究經費。 
所發表之學術論文資料如附件。 
 
 
 
 
2
報告內容 
 
一、 參加會議經過 
 
今年的MSC 2010國際會議主要整合三個系統與控制相關的國際會議：第十九屆控制應用，第
十屆電腦輔助控制系統設計與第二十五屆智慧控制等三大會議。此次舉辦地點為：日本著名的東
京灣港口城市：橫濱市舉行，會議期間為九月七至十號在日本橫濱港口邊的國際會議中心舉行。 
本次會議的主題為：Systems and Control，主要是想要強調：系統理論與控制技術對於日
常生活與工程應用的實際展現，希望隨著地球環境上改變的問題，能夠提供進一步的科技發展與
人類生活上的平衡。 
本次會議之議期共計四天，會議第一天(9/7)為大會的Workshop與歡迎會，Workshop的主題
為：“Modeling, Analysis, and Design of Repetitive Processes and Iterative Learning 
Control Systems＂,“Systems with uncertainty＂, “Integrated modeling and parameter 
estimation: an LFR-modelica approach＂。這幾個主題都是與系統理論與控制技術有關。 
其後的三天(9/8-10)即為主要的議程，主要包含三個主題演講，一個專題演講，以及七十五
個專題報告與討論時段（51 sessions for CCA, 12 sessions for CACSD, 12 session for ISICS）。
四個主題演講分別為：來自美國 University of Texas at Dallas 的 Prof. Mathukumalli 
Vidyasagar，講題為：“Modeling and Coping with Extremely Rare or Adverse Events＂、 來
自美國 University of California, San Diego 的 Prof. Miroslav Krstic，講題為：“Extremum 
Seeking for Nash Games in Financial and Energy Markets＂、來自日本 Kyoto University 的 
Prof. Yutaka Yamamoto，講題為：“From Sampled-Data Control to Signal Processing: Beyond 
the Shannon Paradigm＂。另外一個專題演講，乃是2009年 IEEE CSS Transition to Practice Award
的得主：來自美國 University of California, Berkeley 的 Prof. Kameshwar Poolla，講題為：
“Computation: the emerging bottleneck in integrated circuit design and 
manufacturing＂。此次論文投稿總數為539篇，最後接受了423篇左右的論文發表，主要的論文發
表分散在75個專題報告場次。此次大會的安排行程每天一個主題演講，三個論文報告場次，在第
一天晚上，安排歡迎會，第三天傍晚安排一個專題演講，以及晚上的大會晚宴，第四天晚上為歡
送會。報告議程緊湊而豐富，為聆聽此等論文的報告，個個與會者均在會場穿梭奔波，不亦忙乎。
在這幾天的會議之中，本人參與了大會的開幕式，以及三個專題演講與一個主題演講，同時也在
 
 
4
  
專題演講 論文報告 
  
論文報告討論 論文報告 
  
報告中場休息討論時間 大會晚宴會場 
  
大會晚宴表演 此次大會所在的橫濱港 
 
 
 
 
6
五、攜回資料名稱及內容 
 
Proceedings of 2010 IEEE Multi-Conference on Systems and Control (CD-ROM) 
IEEE Control Systems Magazine, Feb. 2010 
Call for Papers: MSC 2011, SICE 2011 
Systems and Control 相關產品書面與光碟資料 
東京工業大學相關簡介資料與相關研究計畫成果報告書面簡報 
 
 
六、其他 
感謝教育部與國科會贊助此次參與國際會議之旅費與此項研究計畫之研究經費。 
所發表之學術論文資料如附件。 
 
 
 
 
8
國科會補助出席國際會議報銷申請須知 
一、 經費報銷及申請歸墊方式如下： 
(一) 受補助人應於返國後一個月內，將所支費用單據整理，並填報國外出差旅費報告表及支出憑證粘存單並
附外幣兌換水單或報銷當天匯率證明，經任職機構首長及主辦會計人員審核蓋章後再送國科會核銷歸墊。 
(二) 報銷機票時應檢附機票票根正及旅行同業公會統一印製之「旅行業代收轉付收據」，如前項之證明及票根
金額低於國科會核定之金額時，依實際支付金額補助。 
二、 受補助人應於返國後一個月內向國科會提送出國開會心得報告，該會得擇優刊登於「科學發展月刊」。亦得邀
請受補助人在該學門之學會中報告出席會議之經過與心得，或請其主持討論會，或請其撰寫專文發表，俾便傳
播心得與新知。出席會議所攜回之資料，亦應儘可能提供國內學界與科技參考。 
三、 出國經費已報銷歸墊之受補助人在未繳交報告前，國科會暫不受理其出席會議申請案。 
四、 注意事項： 
(一) 所有報銷書表填寫之會議名稱，概以國科會核定補助公函內之名稱為準；除非有誤，請勿改動。 
(二) 報銷費用項目，以國科會核定補助公函內所列補助項目為準；非核定補助項目，國科會概不核銷。 
(三) ［旅費］報銷： 
1. 機票款務請填報，如票上金額不明，請洽詢購票旅行社或國科會國際合作處。 
2. 其他搭乘車船等交通費用之報銷，以在國科會核定補助旅程範圍以內並有正式單據者為限。 
(四) ［生活費］報銷：可列總數，亦可按天列報。（不必檢附單據） 
(五) ［註冊費］報銷：以正式單據為憑。 
(六) 填寫［國外出差旅費報告表］時請注意： 
1. 自動身，迄返國，所有旅程及活動情形，請詳填。 
2. 報銷之各項費用，以何種貨幣支付，即以何種貨幣報銷，不必折換台幣或美金。 
3. 表右下方［具領人］［出差人］［單位主管］［院長］在報銷案送交本校秘書室以前，請分別先行蓋
章。 
(七) 所有單據請貼於［支出憑證粘存單］第三欄橫線下（勿將蓋章空格遮住）。---旅費單據機票票根，不必
貼附整本，用正張即可。--貼妥以後，請在右方［經手］處蓋本人章，［監驗或證明］欄，請服務單位
主管蓋章，他處勿蓋。 
(八) 如有餘款繳還國科會，請於送報銷案至本校秘書室時，先將款繳交總務處出納組。 
(九) 報銷案送交本校秘書室以前，請先行檢查辦理報銷申請書［附件］欄所列各項附件是否齊全，如有缺漏，
請補齊以後再送。 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：連豊力 計畫編號：98-2218-E-002-008- 
計畫名稱：家庭全方位之多樣性群組型娛樂/休閒機器人--子計畫四：家庭成員與娛樂休閒機器人之行
為互動智慧型控制(3/3) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 3 3 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 11 11 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
