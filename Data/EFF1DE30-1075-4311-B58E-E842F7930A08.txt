 2
行政院國家科學委員會專題研究計畫成果報告 
 
計畫編號：NSC 95-2221-E-011-120 
執行期限：95 年 8 月 1 日至 96 年 7 月 31 日 
主持人：楊英魁   國立台灣科技大學 電機工程研究所 
 
 
一、中文摘要 
 
建構一個無教導式的模糊圖樣分類系
統，首先必須從圖樣的數值資料中萃取出
標準圖樣，並根據標準圖樣建立精確的系
統模式以及定義出適當的裁決程序，才能
正確且有效率地進行圖樣識別或分類。近
來有很多經由數值資料產生模糊規則並自
動建立模糊圖樣分類系統的研究被提出
來，這些相關研究遇到了若干的瓶頸，諸
如未考慮資料的結構而直接對圖樣空間進
行均分式地分割、模型複雜難予理解而且
演算法需要甚高的計算成本、無法處理多
維度的分類問題、訓練時間過長等等。模
糊群聚分析常應用於模糊系統模式的建立，但
是在自組織模糊群聚的相關研究之中，通
常可以得到整體最佳解的群聚演算法，其
時間複雜度相當的高；而時間複雜度較低
的群聚演算法，所得到的結果往往都是局
部的最佳解。本研究針對這些缺失作改
善，提出了一個基於模糊群聚以及資料分
佈結構的模糊分類方法。這個分類方法既
簡單又有效，具有模糊規則式系統易於理
解的優點，能根據輸入-輸出的資料對，自
動地發展出一個模糊分類系統，而且亦改
進了模糊圖樣分類的效能。 
 
 
關鍵詞：模糊群聚、圖樣分類、資料分佈、
特徵權重 
 
Abstract 
 
To construct an unsupervised fuzzy 
pattern classification system, generating 
standard patterns from a given set of sample 
data for classification is an important first 
step. Then, an accurate system model and 
discrimination function for efficient pattern 
classification can therefore be defined based 
on the generated standard patterns. Recent 
researches have proposed methods of 
automatic construction of such systems, 
drawbacks, however, have been encountered 
through conducting these researches such as 
not considering the characteristic of data 
distribution, the constructed model is too 
complex to understand and its associated 
computation cost is too high to become 
practical. This research intends to improve 
the drawbacks and propose a fuzzy pattern 
classification approach based on fuzzy 
clustering, the structure of data distribution 
and the features of data to improve the 
performance of fuzzy pattern classification. 
 
Keywords: fuzzy clustering, pattern 
classification, data distribution, 
feature weight 
 
 4
表性的標準圖樣，並根據標準圖樣建立精
確的系統模式以及定義出適當的裁決程
序，才能正確且有效率地進行圖樣的識別
或分類。由於模糊群聚分析廣泛地被用來
組織及分析資料，應用在模糊系統模式的
建立有不錯的成效。因此本研究就是基於
資料分佈的結構，並結合了模糊群聚、模
糊推理以及利用統計觀念，發展了一個模
糊分類方法，這個分類方法具有模糊規則
式系統易於理解的優點，並改進了模糊分
類的效能。 
本研究基於資料分佈及特徵權重的模
糊圖樣分類方法以下列方式進行：(1)一方
面將模糊推理系統融入了自組織模糊群聚
分析之中，提出了一個自組織模糊群聚推
理 網 路 (self-organizing fuzzy clustering 
inference network, SOFCIN)，以自組織的方
式對給定的圖樣資料集合進行群聚的工
作，得到能適切地代表圖樣資料相關特性
的群集中心集合，也就是標準的圖樣。另
一方面則同時以統計觀念計算出訓練資料
集合中每一個特徵之權重，藉以判斷特徵
的重要性，使圖樣類別更易於分辨。(2)針
對自組織模糊群聚所得到的結果進行規則
萃取，將一個群集映射為一條模糊分類規
則；把群集中心轉換為規則的前件，而群
集中心的所屬類別則轉換為規則之後件，
進而建立了模糊規則庫。(3)根據所得到的
模糊分類規則以及特徵權重定義裁決函數
以進行分類處理，藉以確定圖樣資料的分
類，並提高分類正確率。 
 
四、重要參考文獻 
 
 
[1] George J. Klir and Bo Yuan, Fuzzy Sets 
and Fuzzy Logic ： Theory and 
Applications, Prentice Hall Inc.,New 
Jersey, 1995. 
[2] V. Boskovitz, H. Guterman, “An adaptive 
neuro-fuzzy system for automatic image 
segmentation and edge detection, ” 
IEEE Trans. On Fuzzy Systems, vol. 10, 
pp. 247 -262 , Apr. 2002. 
[3] N. Li, Y.F. Li, “Feature encoding for 
unsupervised segmentation of color 
images ” IEEE Trans. On Systems, Man, 
and Cybernetics, Part B, vol. 33, no.  3, 
pp. 438 –447, Jun. 2003.  
[4] S. Eschrich, Ke Jingwei, L.O. Hall, and 
D.B. Goldgof, “Fast accurate fuzzy 
clustering through data reduction” IEEE 
Trans. On Fuzzy Systems, vol. 11, no. 2 , 
pp. 262 –270, Apr. 2003.  
[5] C. Stutz, T.A. Runkler, “Classification 
and prediction of road traffic using 
application-specific fuzzy clustering” 
IEEE Trans. On Fuzzy Systems, vol. 10, 
no. 3 , pp. 297 –308, Jun. 2002.  
[6] N.R.Pal, J.C.Bezdek, “On cluster validity 
for the fuzzy c-means model,” IEEE 
Trans. On Fuzzy Systems vol. 3, no. 3, pp. 
370-379, Aug. 1995. 
[7] A.M. Bensaid, L.O. Hall, J.C. Bezdek, L. 
P. Clarke, et al. “ Validity-guided 
(re)clustering with applications to image 
segmentation, ” IEEE Trans. On Fuzzy 
Systems, vol. 4, no. 2, pp. 112-123, May 
1996. 
[8] C.C.Lee, “Fuzzy logic in Control 
Systems : Fuzzy logic controller, part 
 6
Systems, vol. 7, no. 4, pp. 479-480, 
Aug. 1999. 
[25] M.Y.Chen, and D.A.Linkens,“A fast 
fuzzy modelling approach using 
clustering neural networks,” IEEE 98 on 
Fuzzy Systems Proceeding, 
pp.1088-1093,1998. 
[26] H.M. Lee, C.M. Chen, J.M. Chen, and 
Y.L. Jou “An efficient fuzzy classifier 
with feature selection based on fuzzy 
entropy ” IEEE Trans. on Systems, Man, 
and Cybernetics, Part B, vol. 31, no. 3, 
pp. 426-432, Jun. 2001. 
[27] W. Pedrycz, “Fuzzy sets in pattern 
recognition: Methodology and 
methods,” Pattern Recognition, vol. 23, 
no. 1/2, pp. 121-146, 1990. 
[28] L. I. Kuncheva, Fuzzy Classifier Design, 
Physica-Verlag,New York, 2000. 
[29] E.H. Ruspini ,“A new approach to 
fuzzy clustering ,” Information and 
Control. vol. 15, pp.22-32,1969 . 
[30] J. C. Dunn, “A fuzzy relative of the 
ISODATA process and its use in 
detecting compact well separated 
clusters,” J. 
Cybern.,vol.3,no.3,pp.32-57,1974. 
[31] J. C. Bezdek, Pattern Recognition with 
Fuzzy Objective Function Algorithms, 
Plenum Press, New York,1981. 
[32] M.P. Windham, “Cluster validity for the 
fuzzy c-means clustering algorithm,” 
IEEE Trans. on Pattern Analysis and 
Machine Intelligence, PAMI-4 ,no.4, 
pp.357-363, July 1982. 
[33] J.-S.R.Jiang , C.-T.Sun, and E.Mizutani, 
Neuro-Fuzzy and Soft Computing 
Prentice-Hall Inc. , pp.18-19,1997. 
[34] Seymour Lipschutze, Theory and 
Problems of Probability, McGraw-Hill, 
Inc., New York, 1968. 
[35] R. A. Fisher, “The use of multiple 
measurements in taxonomic problem,” 
Annals of Eugenics, vol. 7, no. 2, pp. 
179-188, 1936. 
[36] G. Castellano and A.M. Fanelli, “A 
staged approach for generation and 
compression of fuzzy classification 
rules,” The Ninth IEEE International 
Conference on Fuzzy Systems, vol. 1, 
pp.42-47, May 2000. 
[37] K. Nozaki, H. Ishibuchi, and H. Tanaka, 
“Adaptive fuzzy rule-based classification 
systems,” IEEE Trans. on Fuzzy Systems, 
4(3):238–250, Aug. 1996. 
[38] D. Nauck and R. Kruse, “Nefclass - a 
neuro-fuzzy approach for the 
classification of data,” in Proceedings of 
the 1995 ACM Symposium on Applied 
Computing, pp. 461-465, Nashville, Feb 
1995. 
參加 ICAI2007研討會心得報告 
報告人： 楊英魁  2007.08.28 
時間： 2007年 6月 25日 ~ 2007年 6月 28日 
地點： Las Vegas, USA 
報告內容： 
這次在 Las Vegas, USA 為期四天所舉行的研討會  The 2007 International Conference on Artificial 
Intelligence (ICAI2007)，是學術界在人工智慧與控制領域上重要的一次會議。ICAI2007 是 WORLDCOMP07 
(The 2007 World Congress in Computer Science, Computer Engineering, and Applied Computing)中 25個研討
會之一。由於它的重要性，所以有另外九個與人工智慧領域有關的研討會一起舉行。總共有來自全球不同領域的
近兩千個專家學者參與，氣氛熱絡，連當地旅館都不容易定到，每位 Keynote Speaker都是在人工智慧領域裡大
師級的人物。 
參加這次 ICAI2007 主要是去發表一篇由國科會所支持研究的成果論文 A Novel Approch of Constructing 
Fuzzy Model for a Data Domain with Noise and Outliers。此論文提出一個 Robust FCM方法，以便能消除掉樣
本資料裡雜訊及外來物的影響，進而建構此樣本資料所代表之系統的正確系統模型。此方法簡單，algorithm 的
時間複雜度小，由各種實驗証明其效果很好，與會者對這方法都極為肯定。 
這幾天期間，與各地學者專家深入討論各個不同的領域，受益良多，也能正確的掌握目前人工智慧的領
域，尤其是每天第一場的 keynote speech 更是精采。主講者不但學術豐富，有幽默感，而且明確指出今後在此
領域上可以進行的幾個方向，足以當作最好的參考。 
參加此研討會，不但有機會與來自世界各地的學者專家廣泛討論，相互切磋，也因此更確定目前所進行的
研究方向是正確的。而且同時可以參加六個相關研討會，真是不虛此行。 
been used successfully to extract circular, elliptical, and 
rectangular curves or lines in noise data [3]-[10]. In these 
algorithms, each curve is represented by parameters. 
However, these shell-based clustering algorithms can be 
used to deal with only a small number of curve shapes that 
can be represented by parameters. But in real world, most 
curves can rarely be described accurately by a mathematical 
formula or by a reasonably small number of parameters, 
which means these curves cannot be extracted correctly by 
the shell-based clustering methods. 
In this section, a modified FCM algorithm is proposed 
to solve this problem. The  idea of the proposal is to 
represent curves by a set of cluster centers instead of 
formula and parameters. These cluster centers can then be 
formed into a model representing original system curves.  
Set X={x1,x2,…xn}
dℜ⊂  be a data set with noise and 
outliers in a d-dimensional feature space, and 
v={ v1 ,v2 ,…,vc } be a cluster center set, where vk 
dℜ∈ . 
Suppose vi-1 ,vi ,vi+1 in Figure 1 are three neighboring local 
cluster centers. Obviously, center vi is the one influenced by 
noise or outlier and therefore is the one causing the 
generated cluster centers not being located in a smooth line. 
If a new point *iv  is positioned in a location inside the 
triangle formed by vi-1 ,vi ,vi+1 as shown in Figure 1 , then 
the system model formed by vi-1 , 
*
iv , vi+1 would be 
smoother. By the rule of triangle, the sum of distances 
between vi-1 ,vi and vi, vi+1, is greater than the sum of 
distances between vi-1 ,
*
iv and 
*
iv , vi+1. This relation can be 
represented by Equation (3). 
2
1 |||| −− ii vv  + 21 |||| ii vv −+  > 21* |||| −− ii vv  + 
2*
1 |||| ii vv −+                    (3) 
On the other hand, for a cluster i with center vi, the 
sum of distances between vi and the data points, say xki(k = 
1,2…mi), in the cluster is minimized according to the 
definition of a cluster center. Consequently, when vi is 
replaced by *iv , the sum of distances between data points 
xki(k = 1,2…mi) and 
*
iv will be greater than the sum of 
distances between these data points and vi. This relation is 
represented as follows. 
∑∑
==
−≥− ii
m
k
iki
m
k
iki vxvx
11
* ||||||||        (4) 
From above analysis, when vi is moved to 
*
iv , 
Equation (3) shows the total distances among its two 
neighboring centers become smaller while Equation (4) 
shows the total distances between the center and its 
associated data points in the cluster become greater. These 
two terms can therefore be combined using Lagrange 
multiplier as Equation (5) to find the optimal solution of the 
two terms. In Equation (5), *iv  is being replaced by vk for 
simpler expression. 
JBFCM(μ ,v) 
= +−+−∑ ∑
= =
2
21
2
1 1
||(||||||)( vvvx
n
i
c
k
ki
m
ik αμ
)||v-|| )||||||(|| 21-c
2
1
1
2
2
1 ckk
c
k
kk vvvvv +−+− +
−
=
−∑  
+−+−+−= ∑ ∑
= =
2
12
2
21
2
1 1
||||||(||||||)( vvvvvx
n
i
c
k
ki
m
ik αμ
)||v-|| |||||||||||| 21-c
2
1
2
23
2
23 ccc vvvvvvv +−+−+− −L  
=
21
1
1
2
1 1
||||||||)( ∑∑ ∑ −
=
+
= =
−+−
c
k
kk
n
i
c
k
ki
m
ik vvvx λμ    
where λ=2α               (5) 
The λ  is Lagrange multiplier. In the right hand side 
of Equation (5), the first term is the original FCM algorithm 
for getting good cluster centers while the second term is the 
constraint for getting smooth lines. To find the optimal 
solution of Equation (5), the derivative of JBFCM(μ ,v) with 
respect to vk is set to zero while fixing μ . Equation (6) 
expresses this relationship. 
)()(0),( 1
1
kk
n
i
ki
m
ik
k
RFCM vvvx
v
vJ −+−==∂
∂
+
=
∑ λμμ       (6) 
The value of vk can be obtained as Equation (7). 
∑
∑
=
=
+
+
+
= n
i
m
ik
n
i
i
m
ikk
k
u
xv
v
1
1
1
λ
μλ
               (7) 
 
Algorithm 1: Robust FCM algorithm 
 
Step 1) Set value of m satisfying 1<m<∞ . 
Step 2) Calculate the membership matrix of μ . 
Step 3) Update fuzzy cluster centers using Equation (7). 
Step 4) Calculate objective function value by Equation (5). 
Stop if either the value is below a certain tolerance 
or its improvement over previous iteration is below 
a certain threshold. 
Step 5) Compute a new μ . Go to Step 3. 
 
 Figure 1: An example of non-smooth curve 
          
  ymax 
 
 
 
 
  Tv(xih) 
 
         ymin                                   
 xih                                  xi  
ps=(xis,ymin) 
u 
     Figure 4: Projected valley pattern 
Assume the m data points in slip window in Figure 2 
are {(x1j,x2j…xij,..xkj,yj)|1≤j≤m}. Let ymin = min(y1,y2…ym) 
and ymax = max(y1,y2…ym) respectively represent the 
maximum and minimum of the output variable y for m data 
points. For an input value xih of a data point in the slip 
window, as shown in Figures 3 and 4, its  peak and valley 
patterns can be defined as Equations (8) and (9) 
respectively. 
Peak pattern: 
Tp(xih)= 
⎪⎪⎩
⎪⎪⎨
⎧
>−×−
−+
<−×−
−+
isihihi
isi
isihiih
is
xxifxx
xx
yyy
xxifxx
xx
yy
y
,)(
)(
)(
,)(
)(
)(
max
max
minmax
min
min
min
minmax
min
 (8)  
Valley pattern: 
Tv(xih)= 
⎪⎪⎩
⎪⎪⎨
⎧
>−×−
−+
<−×−
−+
isihisih
is
isihihis
iis
xxifxx
xx
yyy
xxifxx
xx
yyy
i
,)(
)(
)(
,)(
)(
)(
max
minmax
min
min
minmax
min
(9)   
 For a data point ph, h=1,2…n, the slip window selects 
the m-1 points closest to ph making totally m data points in 
the slip window. Naturally, the pattern formed by the m 
data points often does not conform to the definition of 
either peak pattern in Equation (8) or valley pattern in 
Equation (9). For example, for a point p3, the slip window 
selects the closest points of p1, p2, p4 and p5 for TPSN to 
examine the matching degree against peak pattern at point 
p3, as denoted in Figure 5(a). 
 
 
 
(a): 7 data points 
 
(b): Projected data points and peak pattern 
Figure 5: Comparison between m data points and peak 
pattern 
These 5 points are projected onto (x1, y) plane as 
shown in Figure 5(b) where circles denote the projected 
points of p1 ~ p5 in the slip window and solid lines denote 
the projected peak pattern in Figure 3. It is obvious that the 
shape formed by p1 ~ p5 does not match against the peak 
pattern totally, but to some degree. Fuzzy theory is 
therefore applied here to define the fuzzy matching degree 
between the shape and the pattern in Figure 5(b).  
 As mentioned previously, the value yj of j’th data 
point, where 1≤j≤m, is often different from cpijy of a peak 
pattern. The matching degree between value yj and value 
cp
ijy  for a peak pattern can be measured by a fuzzy 
membership function defined in Equation (10). 
)
)(
2
1(exp)(y 1
2
j1
range
k
i
cp
ijj
j y
yy
μ
∑
=
−
−= (10) 
 
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
RFCM
X
Y
0 10 20 30 40 50 60
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
X
Y
 
  (c) FDS result        (d) final result   
 Figure 6(a): function 3
2
xy =  with Gaussian noise    
    N(0,0.03)                 
  (b): RFCM result.               
  (c): FDS result                
  (d): Final result. The constructed TS model   
    denoted by Dotted lines and SVM denoted  
    by dashed lines 
Example 2: 
In this example, the sinc function is considered and 
defined as [11] 
x
xy sin=   with x ∈[−10,10]           (14) 
Within Figure 7(a), there are 51 sample data points 
generated from Equation (14) with Gaussian noise 
N(0,0.03). The noise data points are denoted by circle and 
the Equation (14) is represented by solid line. The RFCM 
is applied against the data set to mitigate the influence of 
noise and outliers. The result is shown in Figure 7(b) in 
which stars denote the resultant cluster centers. As can be 
seen here, the influence of data noise has been greatly 
minimized. There are 7 good turning-points are then 
searched out by running FDS and the data domain is 
therefore partitioned into 8 clusters creating 8 TS fuzzy 
rules, as shown in Fig 7(c). Figure 7(d) shows the finial 
result of TS fuzzy system model for the data domain. 
Another 201 testing data points are generated by Equation 
(14) to be used for evaluating the performance of the 
proposed method. The finial RMSE value is 0.0505. In [11], 
ARRBFN was applied to the same function with no noise. 
The result was 12 rules (hidden nodes) with RMSE value 
0.0560. Again, the proposed approach in this paper 
generates less fuzzy rules with smaller error. The rules that 
obtained by this paper are: 
If  x is A1 then y = 0.1233 x +  1.133       
    If  x is A2 then y = -0.1271x  -  0.7697      
    If  x is A3 then y = 0.1411x  +  0.5309      
     If  x is A4 then y = 0.3845x + 1.156       
    If  x is A5 then y =-0.3476x +  1.08       
   If  x is A6 then y = -0.3205x  +  1.303       
   If  x is A7 then y = 0.1232x  - 0.6582      
   If  x is A8 then y = -0.1736x + 1.327       
      where the A1~A8 are defined in Table 2. 
Table 2: Obtained definitions of A1~A8 
 σ1 ϕ1 σ2 ϕ2 
A1 1.291 -11 0.3663 -8.042 
A2 0.01773 -7.464 0.39 -4.484 
A3 0.2777 -3.892 -0.5798 -2.853 
A4 0.9669 -2.259 1.103 -0.3031 
A5
0.9251 0.6821 0.6761 1.815 
A6
0.8426 2.623 1.674 3.763 
A7 1.811 4.364 1.724 7.287 
A8 1.058 7.96 1.26 10.47 
-10 -8 -6 -4 -2 0 2 4 6 8 10
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
X
Y
-10 -8 -6 -4 -2 0 2 4 6 8 10
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
X
Y
  
(a) Sample data points            (b) RFCM result 
-10 -8 -6 -4 -2 0 2 4 6 8 10
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
X
Y
-10 -8 -6 -4 -2 0 2 4 6 8 10
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
X
Y
    
(c) finial result        (d) RMSE convergence curve 
Figure 7: Equation 
x
xy sin=  added noise N(0, 0.03) 
5. Conclusions 
 This paper proposes an approach to set up a good TS 
fuzzy model for a given set of sample data that are bound 
with data noise and outliers. The experiments show that, 
despite a given set of input data includes noise and outliers, 
