 
現場邏輯陣列閘硬體平台於臉部表情辨識與 
情緒分析系統之研究與設計 
 
林灶生 
國立勤益科技大學  資訊工程系 
 
二、 中文摘要 
本研究提出了以小波轉換和類小腦硬體模
型架構來進行臉部表情辨識，並使用著名的
JAFFE 資料庫進行表情的訓練與測試。本系統
共使用了六種表情，分別是高興、生氣、難過、
驚訝、恐懼和無表情等。進行臉部表情辨識前，
我們必須先針對 JAFFE 資料庫的影像進行前處
理的動作，包含了影像雜訊移除，影像增強，邊
緣偵測，臉部位置擷取等等。透過前處理的方式
將重要的資訊保留，非必要之資訊移除。 
首先我們先以 MATLAB 軟體進行演算法之
測試與驗證，當辨識率達到我們的需求後，透過
硬體描述語言將演算法移植到 FPGA 硬體上進
行測試。最後透過 Visual Basic 與 FPGA 來進行
人臉表情之訓練與測試。本實驗所提出之方法在
辨識率最高可達到 88.3%。 
 
關鍵詞：小波轉換、類小腦模型，表情辨識，
FPAG 雛型設計 
 
Abstract 
In this research, we proposed a hardware 
system with Field Programmable Gate Array 
(FPGA) for facial expression recognition, in which 
the Haar Discrete Wavelet Transform (DWT) and 
Cerebellar Model Articulation Controller (CMAC) 
were used. The proposed method has been tested 
and trained in the process of hardware emulation 
with the famous JAFFE (Japanese Female Facial 
Expression) database in the proposed hardware. 
The testing facial images must be preprocessed to 
remove noises, enhance the contrast, and cut the 
image to normalize the facial images for the 
training and recognition phases.  
   Firstly, the facial expression features are 
automatically extracted and preprocessed from 
given still images in the JAFFE database in which 
the frontal view of faces are contained. A 2D DWT 
is then used to focus the key information of 
expression characteristics in order to decrease the 
size of images. Thirdly, a block size of the lower 
frequency of DWT coefficients is rearranged as 
input vectors with binary manner to send into the 
proposed CMAC IP that can rapidly obtain output 
using non-linear mapping with look-up table in 
training or recognizing phase. Finally, the 
experimental results in hardware emulation 
demonstrated the promising recognition rates with 
various block size of coefficients for six 
expressions, including happiness, sadness, surprise, 
anger, disgust and natural in lower frequency. 
 
三、 緣由與目的 
人類的情感表達方法有各式各樣方式，而大
部分都是從本身意識中發出，在醫學上已經有許
多生理訊號的反應，如當人生氣的時候身體的腎
上腺素會增加，心跳加速，以及呼吸加速，判斷
力下降，而當人高興的時候，會加速血液循環，
血壓容易升高。這些生理反應能透過視覺或聽覺
的方式感受到對方情緒上的變化，如能從聲音，
臉部表情或是怪異的行為舉止上發現。 
隨著科技的進步，消費性產品也越來越多
元化，許多產品也漸漸的開始朝人性化發展。在
人機互動的方面，想要讓產品與人互動的更為豐
富，必須藉由加裝感測器的方式來了解人的多樣
性反應。透過感測器抓取資料並進行資料的判
斷，再經過人工智慧(AI) 的介面來判斷產品要
如何與使用者之間做最佳互動。在這方面應用的
領域最廣泛的則是在機器人上，許多市面上的商
品大部分都只會根據系統的設定來進行動作，根
據使用者下達之命令來決定該產品要做哪些
事。而這方面由於本身缺乏感測器，因此無法與
使用者進行良好的互動。 
表情辨識除了應用在機器人之外，還可應用
在醫療照護方面，由於社會已漸漸邁入高齡化的
時代，老年人的照護變得非常重要，更因為少子
化的關係，造成社會福利與公共設施的財源匱
乏。在老年人照護方面，由於勞動人數供給不
足，相對的也會造成醫療照護人員人力不足之問
題。因此在照護老年人方面，必須要依賴其他非
人力資源的方式，才能夠減緩人力不足問題。老
年人通常最需要注意的是意外的發生，社會上許
多老年人經常都是自己一個人在家，如果身體突
然異常，往往會錯過最佳急救時間。因此，如果
 
圖 3. Virtex-4 ML40x 平台 
 
∑ ∑
= =
×Ψ+−×Ψ=Ψ
2/
1 1
),2(),12(),('
m
x
n
y
yxyxyx  
   (1) 
∑ ∑
= =
−×Ψ−−×Ψ=+Ψ
2/
1 1
),12(),12(),2/('
m
x
n
y
yxyxymx
   (2) 
∑ ∑
= =
×Ψ+−×Ψ=
m
x
n
y
yxyxyxX
1
2/
1
)2,(')12,('),(  
   (3) 
∑ ∑
= =
×Ψ−−×Ψ=+
m
x
n
y
yxyxnyxX
1
2/
1
)2,(')12,(')2/,(
 (4) 
由於 CMAC 架構必須使用到大量的記憶
體，礙於 Block Ram 的空間有限，因此我們使用
Sram 的記憶體來存放我們 CMAC 的權重的位
置。而在進行 CMAC 訓練或測試前，必須以圖
2 電路先將 DWT 運算完之後的結果進行 CMAC
輸入資料轉換。 
圖 3 是由兩個子電路 Conv Control 與 Conv 
Operation 以及 Block Ram 所構成。在經過 DWT
轉換後，我們取出低頻的資料，以每一塊 2x2
的區塊加起來然後分成三等分，每一等分當作
CMAC 的輸入資料。而 Conv Control 則是負責
Row和Column的控制，並且根據Row和Column
當作 Block Ram 的記憶體位置來進行讀取動
作。而 Conv Operation 則是負責將 Block Ram 讀
取出來的資料進行加總，並且將加總完後的結果
分成三等分，分別的寫入所對應到的 Block Ram
記憶體位置上。 
 
 
圖 3. DWT 低頻資料轉換 CMAC 輸入資料方
塊圖 
 
3.3 CMAC IP 
CMAC 類神經網路[12-14]主要是仿效人類
小腦皮質分層儲存訊息的架構(皮質分層共分成
分子層、細胞層、粒狀層)，它是由 J. S. Albus 根
據 Marr 所發表之小腦架構於 1975 年提出
[12]。此架構是利用多層超立方塊(hypercube)
與記憶細胞(memory cell)的概念，並利用映射
(mapping)的技巧，將不同狀態的資訊儲存於多
層超立方塊所對應的記憶細胞中。因此必須要規
劃模擬小腦儲存訊息的記憶體，並根據學習過程
中，依據輸出的期望值來與實際記憶體的權重來
改變權重大小在進行辨識之前，首先 CMAC 的
第一步就是進行記憶體訓練的步驟，透過輸入的
參考資料進行記憶體權重之調整。而圖 4 中，主
要是包含兩個子電路，分別為 Yout Calc 電路和
Weighting Adjust 電路。Yout Calc 電路主要是計
算目前該表情所對應到全部記憶體之總和。透過
簡單的記憶體讀取動作與累加器的電路，將記憶
體之總和計算出來。而 Weighting Adjust 電路主
要是根據公式(5)進行記憶體權重之調整，利用
計算出來之 Yout 與輸入之參考資料所對應到的
記憶體位置之值進行調整與記憶體更新。 
G
yyWWWW diii )(11 −+=Δ+= −− β       
  (5) 
i  ：第 i 次的學習 
G ：每個取樣狀態點所對映之記憶體單元的
個數 
yd：理想的期望值 
y  ：記憶體個數之總和 
β  ：學習率(learning rate) 
 
表 2. CMAC 分群 4 位元之辨識結果 
 高興 難過 
驚
訝 
生
氣 
噁
心 
無
表
情
辨識
率 
高興 10 0 0 0 0 0 100%
難過 0 9 1 0 0 0 90% 
驚訝 0 1 8 0 0 0 80% 
生氣 0 1 0 7 2 0 70% 
噁心 0 0 0 7 9 0 90% 
無表
情 0 0 0 0 0 10 100%
平均 88.3%
 
表 3. 分群 6 位元之辨識結果 
 
高
興 
難
過 
驚
訝 
生
氣 
噁
心 
無 
表情 辨識率
高興 0 1 0 0 0 1 80% 
難過 0 8 0 0 0 2 80% 
驚訝 0 0 7 0 0 3 70% 
生氣 0 2 1 6 0 1 60% 
噁心 １ 2 0 0 7 0 70% 
無表情 0 0 0 0 0 10 100% 
平均 76.6% 
 
本論文所提出之人臉表情辨識，在著名的
JAFFE 人臉資料庫上，辨識率上最高可達到
88.3%，而在演算法的硬體移植上也移植的非常
成功，在自行開發之小波轉換 IP 與類小腦模型
IP，應用在表情辨識上幾乎與模擬之結果一模一
樣。 
在未來研究方面，我們將著手進行動態影像資料
庫上進行人臉辨識，由於在靜態影像辨識上，無
需考慮到光源的強弱所造成辨識的結果，如當光
線不足時，在人臉影像資訊會過少，且雜訊過
多，使得在辨識上容易造成誤判知問題。因此如
何進行光源補償是未來研究之課題。另外再記憶
體儲存部分，由於目前是採用 SRAM 與 Block 
RAM 當作記憶體儲存裝置，在處理影像上，只
可處理在 256 x 256 影像之大小，且對於較複雜
之影像處理，會造成記憶體不足之問題，未來我
們將研發 DDR SDRAM 來當作我們儲存裝置，
以便進行其他相關演算法之開發。 
 
五、參考文獻 
[1] M. Lyons, S. Akamasku, M. Kamachi, 
and J. Gyoba, “Coding facial expressions 
with Gabor wavelets,” In Proceedings of 
International Conference on Face and 
Gesture Recognition, 1998. 
[2] Y. Tian, T. Kanade, and J. Cohn. 
“ Eye-state action unit detection by 
Gabor wavelets” . In Proceedings of 
International Conference on Multi-modal 
Interfaces (ICMI 2000), pp. 143-150, 
Sept, 2000. 
[3] Z. Zhang, M. Lyons, M. Schuster, and S. 
Akamatsu, “Comparison between 
geometry- based and 
gabor-wavelets-based facial expression 
recognition using multi-layer perceptron,” 
In International Workshop on Automatic 
Face and Gesture Recognition, pp. 
454-459, 1998. 
[4] Xiao-xu Qi, JIANG Wei. “Application of 
Wavelet Energy Feature in Facial 
Expression Recognition,“ In 
Auti-counterfeiting, Security, 
Identification, 2007 IEEE International 
Workshop, pp. 169-174, 2007. 
[5] Ying-li Tian Takeo Kanade and Jeffery F. 
Cohn,” Evaluation of 
Gabor-Wavelet-Based Facial Action Unit 
Recognition in Image Sequences of 
Increasing Complexity,” Proceedings of 
the Fifth IEEE International Conference 
on Automatic Face and Gesture 
Recognition, 2002. 
[6] P. Ekman and W.V. Friesen, “The facial 
action coding system: a technique for the 
measurement of facial movement,“ San 
Francisco: Consulting Psychologists 
Press, 1978. 
[7] H.A. Rowley, S. Baluja, T. Kanade, 
“Neural network-based face 
detection,“ IEEE Trans. Pattern Analysis 
and Machine Intelligence, vol.20, no.1, 
pp. 23-38, Jan, 1998. 
[8] H.A Rowley. S. Baluja, T, Kanade, 
“Rotation Invariant neural network-based 
face detection,“ Proc. IEEE Conf, 
Computer Vision and Pattern 
Recognition, pp. 38-44, 1998. 
[9] Xilinx Virtex-4 相 關 資 料 , 
http://www.xilinx.com/ 
support/documentation/virtex-4.htm. 
[10] A. Grossmann, J. Morlet, 
“Decomposition of hardy functions into 
square integrable wavelets of constant 
shape,” SIAM Math Anal. Vol.15, pp. 
723-736, 1984. 
[11] A. Grossmann, J. Morlet, 
“Decomposition of functions into 
wavelets of constant shape and related 
transforms in mathematics and physics,” 
附錄A 出席國際學術會議心得報告 
 
計畫編號 ：NSC96-2221-E-167019-MY2 
計畫名稱：現場邏輯陣列閘硬體平台於臉部表情辨識與 
情緒分析系統之研究與設計 
 
出國人員姓名 林灶生 
服務機關及職稱 國立勤益科技大學 資訊工程系教授 
會議時間地點 2009 8/18 – 8/20    中國大陸  西安 
會議名稱 2009 Fifth  International Conference on 
Information Assurance and Security 
發表論文題目 Facial Expression Recognition Based on Field 
Programming Gate Array 
 
一、參加會議經過 
2009 Fifth  International Conference on Information Assurance and 
Security於2009年08/18-08/20在大陸西安舉辦，本人為該研討會B02:Multimedia 
Processing and Multimedia Interaction 議程主席。本人帶領博士班學生廖又儀同學
參與，於 08/18 抵達西安。08/19 參與議程委員會議後，參與各研討會場之報告。
08/19 除主持 Multimedia Processing and Multimedia Interaction 議程外，廖又儀同
學報告其論文並參與各研討會場之報告。08/19 參與各研討會場之報告。 
 
二、與會心得 
本次會議中所安排的主要研究與討論的主題如下： 
1. Facial Expression Recognition Based on Field Programming Gate Array 
2. Analysis and Evaluation of Contrast Enhancement Methods in Digital Images 
3. Contrast Enhancement Method Based on Average Luminance with Weighted 
Histogram Equalization 
4. Application of Averaged Learning Subspace Method in MRI Classification 
5. Low Bit Rate ROI-Based SAR Image Compression 
6. Optimal Information Rates of Novel Graph Based Access Structures 
7. A Rapid Algorithm and its implementation for Modular Inversion 
 
三、攜回資料名稱及內容 
本次會議攜回2009 Fifth  International Conference on Information Assurance and 
Security的論文集一本，內容為各主題會議中所發表的論文。 
 
 
 
 
 
Facial Expression Recognition Based on Field Programmable Gate Array 
Jzau-Sheng Lin*, Shao-Han Liou*, Wu-Chih Hsieh*, Yu-Yi Liao*, HongChao Wang**, and QingHua Lan** 
*Department of Computer Science and Information Engineering 
National Chin-Yi University of Technology,
No. 35, Lane 215, Sec. 1, Chung-Shan Rd., Taiping, Taichung, Taiwan. 
TEL: 886-4-23924505 ext 7311 FAX: 886-4-23917331
E-mail: jslin@ncut.edu.tw, liou@ncut.edu.tw   
**Embedded Laboratory, Huaxia Vocation College, Xiamen, China 
Abstract 
In this paper, we proposed a hardware system with 
Field Programmable Gate Array (FPGA) for facial 
expression recognition which used Haar Discrete 
Wavelet Transform (DWT) and Cerebellar Model 
Articulation Controller (CMAC).  
 Firstly, the facial expression features are 
automatically extracted and preprocessed to obtain the 
frontal view of faces. A 2D DWT IP is then used to 
decrease the size of images. Thirdly, a block size of the 
lower frequency of DWT coefficients is rearranged as 
input vectors with binary manner to send into the 
proposed CMAC IP that can rapidly obtain output 
using non-linear mapping with look-up table in 
training or recognizing phase. Finally, the 
experimental results demonstrated recognition rates 
with a block size of coefficient in lower frequency to 
recognize six expressions, including happiness, 
sadness, surprise, anger, disgust and natural to show 
promising recognition results. 
Key words: CMAC, FPGA, Facial expression 
recognition, Feature extraction 
1. Introduction 
Human being is a social animal and their facial 
expressions play a significant role in communication. 
Facial expressions are facial movements in response to 
the internal affective state, psychological state, and 
cognitive activity of a man. In recent years facial 
expression recognition has become an active research 
topic and a number of methods have been proposed in 
the literature [1-4].  
Ekman and Friesen [5] proposed the six basic 
emotions that possess each a distinctive content 
together with a unique facial expression for the 
standard of classification of recognition in 1971 and 
developed the well-known Facial Action Coding 
System (FACS) for facial expression description. The 
FACS provides 46 Action Units (or AUs) to describe 
any facial expression of human being and indicates 
eyebrows, eyes and mouth that are the key features for 
facial expression recognition. 
The two dimensional DWT is often used in signal 
and image compression, because it can concentrate the 
most of signal information into low frequency 
components. It also had been utilized in 2D facial 
expression recognition in recent years. In reference 3, 
they used the entire facial image to obtain 2D DWT 
coefficients to facial expression recognition. 
The CMAC was proposed by Albus [6]. It is a 
supervised neural network of associative memory 
based on table look-up method. The advantages of 
CMAC are fast learning, simple computation, local 
generalization, non-linear mapping, and can be easily 
implemented by the hardware. In this paper, hardware 
implementation of a recognition technique with FPGA 
is proposed, which used the 2D DWT over the entire 
face image as a facial expression feature extractor and 
the CMAC with clustering memory as a classifier. 
2. The 2D DWT and the proposed CMAC 
network (DWT-CMAC) 
The facial expression recognition system based on 
2D DWT and the CMAC network is proposed in order 
to recognize facial expression, in which a difference 
image by subtracting a neutral image from a given 
expression image was obtained  
Wavelet transformations are a method of 
representing signals into conversion of time-frequency 
2009 Fifth International Conference on Information Assurance and Security
978-0-7695-3744-3/09 $25.00 © 2009 IEEE
DOI 10.1109/IAS.2009.266
547
4.1. DWT IP 
The block diagram of the proposed DWT module is 
shown as Figure 3. The DWT module can be divided 
into two modules such as controller module and 
operation module respectively. The input image was 
normalized with a size of 128128 u . The DWT 
module did wavelet transformation when signal 
DWT_Done was changed to high state. The 
transformation process was divided into horizontal and 
vertical phases in accordance with Haar transformation. 
In the block RAM, 16k bytes are used to store an 
image while the other 16k bytes are used as the 
processing buffer.  
Figure 3 Block diagram of the DWT module
In the DWT Controller module, the column and 
row locations of the transformed image and memory 
address are generated. As obtained Row and Column, 
we can get the memory with ColumnRow u128  in 
accordance with the base address. The base addresses 
are 0 and 16384 (for a 128128 u  image) for 
horizontal and vertical transformation individually.   
Figure 4 CMAC Training circuit
4.2. CMAC IP 
The input data of the CMAC IP was extracted from 
the low-frequency band of Haar DWT transformation. 
Owing to huge memory to be used for the CMAC and 
limited space of block RAM, an external SRAM was 
selected to store weighting parameters of the CMAC.  
In the proposed system, the LL-band data of the DWT 
occupies 3232 u  bytes. Therefore, we have 
819283232  uu  bits for the CMAC input layer. In 
order to simplifier the input coding circuit of the 
CMAC, we divided a nun-overlap 22 u  block as a 
training sample for the 3232 u  LL-band data and 
selected an SRAM to store the coding addresses with a 
size of 3072121616  uu bits. Figure 4 shows the 
block diagram of CMAC training circuit. 
In the recognition phase, the unknown input data 
are mapped into memory by using the Weight 
Summation Module shown as in Figure 5 to find the 
weights and sum them as total weights to express the 
intensities for different facial expressions. Then, we 
used the Max module in Figure 5 to find the maximum 
facial-expression intensity. A block size of 22u  was 
summed and divided as three branches as partial data 
in CMAC input ports. Therefore, a tested image 
occupied 12288 memory words for 768 input data 
( 76834
1024  u ) and 16 locations for each data.  
5. Experimental results 
The facial express patterns were obtained from 
JAFFE database and transmitted through the image 
interface in an FPGA SoC platform with Virtex IV-
ML40X. The six facial expressions include neutral (N), 
happiness (H), sadness (S), anger (A), disgust (D), and 
surprise (P) of 10 Japanese female models in JAFFE 
database were used in our experiments. Each person 
was recoded three images for each expression. In our 
simulation experiments, two images of each expression 
were used for network training and the remainder 
images were used for testing, namely 120 subjects for 
training and 60 subjects for testing. For the CMAC 
network, learning rate was set 0.005 and the sizes of 
cluster were set 2, 4, and 6 bits, respectively. If the 
cluster size is small, the CMAC will have more 
clusters. Tables 5.1 and 5.2 show the recognition rates 
with 4-bit and 6-bit clusters. From the experimental 
results, we find that a CMAC hard IP with 4-bit cluster 
can obtain better recognition rate than other cluster 
sizes. 
549
