 1 
行政院國家科學委員會補助專題研究計畫
成果報告   
□期中進度報告 
 
Non-uniform Sampling and Wavelet Kernel Canonical Correlation 
Analysis for Speaker Recognition 
 
 
計畫類別：個別型計畫   □整合型計畫 
計畫編號：NSC 100－2221－E－130－026 
執行期間： 100  年 08 月 01 日至 101 年 07月 31 日 
 
執行機構及系所：銘傳大學 電通系 
 
計畫主持人：龍生雲 
共同主持人： 
計畫參與人員：楊子昀、賴昆煒 
 
 
 
成果報告類型(依經費核定清單規定繳交)：精簡報告  □完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
 
中   華   民   國 101   年 08   月  20  日 
 3 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：101年 08月 20日 
                                 
一、參加會議經過 
二、與會心得 
三、考察參觀活動(無是項活動者略) 
四、建議 
五、攜回資料名稱及內容 
六、其他 
 
 
計畫編號 NSC 100－2221－E－130－026     
計畫名稱 
Non-uniform Sampling and Wavelet Kernel Canonical Correlation Analysis 
for Speaker Recognition 
 
出國人員
姓名 
龍生雲 
服務機構
及職稱 
銘傳大學 電通系 
會議時間 
101年 04月 02日
至          
101年 04月 04日 
會議地點 
Thailand, Phuket 
會議名稱 
(中文) 
(英文)The 31st IASTED Conference on Modelling, Identification, 
and Control 
發表論文
題目 
(中文) 
(英文) Wavelet Feature Slection Using Genetic Algorithm for TISR 
 5 
2. We propose an improved algorithm for KCCA to tackle the singularity problem of the wavelet matrix. 
 
Given an acoustic speech signal, it is very difficult, if not impossible, to recover the exact excitation 
signal.  Most of the proposed speaker identification systems use Mel frequency cepstral coefficient (MFCC) 
[7, 8] and linear predictive cepstral coefficients (LPCC) [9] as features.  Although MFCC and LPCC have 
proved to be two very good features in speech recognition, they are not necessarily good in the speaker 
identification.  The drawback of the MFCC is that it uses short time Fourier transform, which has poor 
time-frequency resolution and an assumption that the signal is stationary.  Thus it is relatively difficult to 
recognize plosive phonemes by these features.   
 
Currently, some researches [10]-[16] are focusing on the wavelet transform for feature extraction.   
Existing wavelet feature can be catalogued into the following three types. 
 (Basic) Wavelet transform: Both continuous and discrete wavelet transforms have been introduced to 
implement feature extraction.  In theory, the scale parameter of a wavelet in the continuous wavelet 
transform can be any positive real value and the shift can be an arbitrary real number.  This is referred 
to as the continuous wavelet transform [10].  In practice, however, the discrete wavelet transform limits 
the values of the shift and scale parameters to some discrete lattices to improve computation efficiency.  
This is then referred to as the discrete wavelet transform [11]. 
 Wavelet decomposition: In relevant research [12], wavelet bases are based on decomposition through 
interpolating scaling function.  The cost of calculating the coefficients may be significantly reduced 
with a wavelet basis of interpolating scaling functions.  In Ref. [13, 14], the idea of combining wavelets 
 7 
regularization to the wavelet matrix such that the wavelet matrix becomes invertible.  In this paper, we 
propose an improved KCCA algorithm based on eigenvalue decomposition approach rather than the 
regularization method to overcome this problem. 
 
  Gaussian mixture model (GMM) [28, 29, 31] recently have become the dominant approach in the text 
independent speaker recognition.  One of the powerful attributes of GMMs is the capability to form smooth 
approximations to arbitrarily shaped densities [31].  Although for text dependent applications, hidden 
Markov models (HMMs) can have some advantages when incorporating temporal knowledge, GMMs still 
show the best performance to date for the text independence speaker recognition with high accuracy.  In this 
paper, we briefly review the GMM based speaker identification scheme (in Section IV) that will be used in 
our simulations. 
 
The remainder of this paper is organized as follows: we derive the KCCA formulations in Section II, and 
the improved wavelet algorithm based on KCCA in Section III.  The speaker recognition of Gaussian 
mixture model (GMM) is described in Section IV.  Experimental results are shown in Section V., and 
conclusions are given in Section VI.   
 
 
2. Kernel Canonical Correlation Analysis (KCCA) 
Given two centered random multivariables x
n
Rx and y
n
Ry , the goal of canonical correlation 
analysis (CCA) is to find a pair of directions xw  and yw  such that the correlation ),( yx  between the 
 9 
were defined using approximately equivalent approaches.  According to [23], there exists direction 
)(x such that  
)()( )( xx Xw                                        (5) 
Assume that ),( ji xxk  is a kernel function that can be expressed as the dot product form on the Hilbert space 
F  
)())(()(),(),()( j
T
ijijiij xxxxxxkk            (6) 
Where  )(),( ji xx  stands for the dot product of )( ix and )( jx . 
 
 
3. Improved Wavelet Algorithm Based on KCCA  
The centering and whitening preprocessing [19] steps can be performed in the kernel feature space.  The 
goal of whitening is to transform the centered samples via an orthogonal transformation into vectors where the 
correlation matrix is the unit matrix.  The wavelet matrix is a correlation matrix [12, 31].  This matrix is 
denoted by K .  From (4) and (6), we obtain that the NN   matrix ijkK )(  can be written as   
)())(( XXK T                                (7) 
From (5), (3), and (7), we obtain   
y
TT
xy
TT
x wKYwYXw )()( )(                          (8) 
y
TT
y wYYw = )()( ))()(( x
TT
x wXXw   = )()( x
T
x KK    =1       (9) 
Thus, solving the KCCA problem is equivalent to finding )(x  and yw  that maximize y
TT
x wKY)(  under 
the constraints 
y
TT
y wYYw = )()( x
T
x KK   =1 
 11 
regularization to the wavelet matrix.  In fact, the largest eigenvalue of (13) gives the maximum of the 
following Rayleigh quotient [25] 
)()(
)(
1
)(2
)(
x
T
x
x
TTT
x
KK
YKYYKY







                        (16) 
Let YYYYW TT 1)(  , then (16) can be rewritten as 
)()(
)()(2
x
T
x
x
T
x
KK
KWK





                                (17) 
Thus, solving KCCA is equivalent to finding )(x  that maximizes the Rayleigh quotient in (17), which is 
equivalent to solving the same optimal problem as that of generalized discriminant analysis (GDA) [25].   
Therefore, we can adopt the same eigenvalue decomposition approach as that used in GDA for the wavelet 
matrix to system (17).  Moreover, note that there exists the degenerate eigenvalue problem in solve system 
(17), we propose to use the method used in the modified generalized discriminant analysis (MGDA) [26] 
algorithm to tackle this problem.  The main contribution of this paper is to highlight the improved algorithm 
for KCCA to overcome the singularity problem of the wavelet matrix and the degenerate eigenvalue problem 
of solving the eigenequation of KCCA.  
 
 
4. Gaussian Mixture Models (GMM) 
GMM based speaker recognition systems have become the most popular method to date.  This is because 
GMMs can capture the acoustic phenomena or acoustic classes that are presented in speech [27].  In fact, 
some of the GMM clusters have been found to be highly correlated with particular phonemes [28].  As a 
result, good recognition performance can be achieved with GMM based systems. 
 13 
The parameter set   is obtained by maximizing the likelihood function (20).  The parameter   could 
not be solved directly.  However, it can be obtained iteratively using EM algorithm [29].  Each iteration 
consists of expectation step (E-step) and maximization step (M-step) [30]. 
 
  E-step: compute the expected value of the complete log-likelihood, conditioned on the data and the current 
parameter estimate, 


  
  


K
j
M
i
T
t
jtiijt j
K
j
M
i
T
t
jtjt
j j
j
j j
j
yppyijp
yijpyijpQ
1 1 1
 ,
1 1 1
  
)}(log){log,|,(              
)|,,(),|,();(


 
where   is an initial model and   is a new model to estimate. 
 
  M-step: the new model parameters is estimated by maximizing the expectation of log-likelihood as  
);(maxarg  Q  
 
  In EM algorithm, the new model becomes the initial model for the next iteration and the process is repeated 
until some convergence threshold is reached. 
 
Initialization of EM is a critical issue because EM converges to a local maximum of the likelihood function: 
the final estimate depends on the initialization.  We used the random selection method and K-mean 
clustering for initialization of GMM in each cluster.  In random selection method, the initial mean of mixture 
consisted of randomly choosing M  vectors from training vector in each cluster.  In two methods, 
covariance matrix is starting from an identity matrix. 
 
 
 15 
 
Fig. 2 System framework (training phase) 
 
In the identification phase, a vector sequence can be obtained from a given test sentences by using 
short-time analysis technique.  The classification for the vector sequence is determined using a decision 
rule [28, 29]. 
 
C. Results and Discussions 
  Several speaker recognition experiments were performed to evaluate the various WT.  For speaker 
recognition experiments, the results for four methods and two databases are reported in Table 2 and 3.  The 
best recognition rate of improved wavelet algorithm obtained was 96% and 98% in TALUNG and KING 
databases.  
 
Table 2.  Speaker recognition rates (TALUNG) 
 
Table 3.  Speaker recognition rates (KING) 
 
Table 2 and 3 demonstrates the identification accuracy of the system when using KCCA in addition to the 
wavelet features.  The table also shows several wavelet types of the best performing features.  The accuracy 
rate represents the percentage of test samples that were correctly identified by the system, as shown below.   
 17 
6. Conclusion 
The speaker recognition problem based on improved WT has been addressed in this paper.  Learning the 
correlation between the wavelet transform (WT) and the expression vector is performed by kernel canonical 
correlation analysis (KCCA).  The experimental results have proved that using a small or medium phonemes 
database provides an excellent recognition rate, that we can improve taking care of the following: 
- KCCA is a very effective method for correlating the nonlinear relationship.  
- We also provide an improved algorithm for KCCA to overcome the singularity problem of the WT matrix 
and the degenerate eigenvalue problem of solving the eigenequation of KCCA.   
- The improved algorithm for KCCA can increase the robustness of the speaker recognition system. 
Finally, the proposed method proved its’ efficiency by given a high recognition rate when compare with other 
methods (WT, Multi-wavelet Decomposition, Fuzzy WT). 
 
Although the best classification performance in the experiment using TALUNG and KING databases is 
obtained when the improved KCCA is used, a major drawback of doing this is that the computation time has 
slightly increasing.   
  
 
Acknowledgment: The author would like to thank the anonymous reviewers for their valuable comments, 
which help improve the clarity and quality of the paper. 
  
 
References  
[1] J.M. Lilly, S.C. Olhede, Higher-order properties of analytic wavelets, IEEE Transactions on Signal 
Processing. 57 (2009) 146-160. 
[2] H.F. Ates, M.T. Orchard, Spherical coding algorithm for wavelet image compression, IEEE Transactions on 
Image Processing. 18 (2009) 1015-1024. 
[3] S.Y. Lung, Feature extracted from wavelet decomposition using biorthogonal riesz basis for text 
independent speaker recognition, Pattern Recognition. 41 (2008) 3068-3070. 
[4] H. Perez Meana, Advances in Audio and Speech Signal Processing: Technologies and Applications, Ideal 
Group Publishing. 2007, 371–407. 
[5] V. Kumbasar, O. Kucur, Better wavelet packet tree structures for PAPR reduction in WOFDM systems, 
Digital Signal Processing. 18 (2008) 885-891. 
 19 
16 (2004) 1283-1297. 
[27] J. Ming, T.J. Hazen, J.R. Glass, D.A. Reynolds, Robust speaker recognition in noisy conditions, IEEE 
Transactions on Audio, Speech, and Language Processing.  15 (2007) 1711–1723. 
[28] B.L. Pellom, J.L. Hansen, An efficient scoring algorithm for Gaussian mixture model based speaker 
identification, IEEE Transactions on Signal Processing Letter.  5 (1998) 281–284. 
[29] D.A. Reynolds T. F. Quatieri and R. B. Dunn, Speaker verification using adapted  Gaussian mixture 
models, Digital Signal Processing. 10 (2000) 19–41. 
[30] J. Zhang, W.L. Woo, S.S. Dlay, Expectation-maximisation approach to blind source separation of 
nonlinear convolutive mixture, IEEE Transactions on Signal Processing. 1 (2007) 51–65. 
[31] S.Y. Lung, Feature extracted from wavelet eigenfunction estimation for text independent speaker 
recognition, Pattern Recognition. 37 (2004) 1543-1544. 
 
 
 
 
 
 
 
 
 
 
new ideas, facilitate cultural exchange and encourage international unity
wavelet matrix such that the wavelet matrix becomes 
invertible.   
 
A genetic algorithm (GA) was first investigated by 
Holland [] and has been in recent years attracted a great 
deal of attention in many different areas as a way to 
effectively search through complex and multi-dimensional 
spaces. Actually the goal of the genetic algorithm is to 
come up with a best value, but not necessarily optimal 
solution to the problem.  GA beings with a set of initial 
populations that is randomly generated.  And then, the 
each population calculates fitness function that reflects the 
quality of the solution.  In order to generate improved 
offspring, thereafter, a good parent is selected from the 
pool of chromosomes according to each individual’s 
fitness using selection operator, which reproduces the 
individuals selected to form a new population.  Thereafter, 
crossover and mutation on the population are performed 
and such operations are repeated until some condition is 
satisfied.    
 
In this paper, we propose a speaker recognition approach 
based on KCCA and GAs.  We first use KCCA to extract 
features in wavelet domain.  After feature extraction by 
the use of the KCCA, we employ GAs to select the 
optimal feature subset for recognition, or more precisely 
the optimal nonlinear components.  When we got the 
optimal feature vectors, we use Gaussian mixture model 
(GMM) for recognition tasks.   
 
  Gaussian mixture model (GMM) [28, 29, 31] recently 
have become the dominant approach in the text 
independent speaker recognition.  One of the powerful 
attributes of GMMs is the capability to form smooth 
approximations to arbitrarily shaped densities [31].  
Although for text dependent applications, hidden Markov 
models (HMMs) can have some advantages when 
incorporating temporal knowledge, GMMs still show the 
best performance to date for the text independence 
speaker recognition with high accuracy.  In this paper, we 
briefly review the GMM based speaker identification 
scheme (in Section IV) that will be used in our 
simulations. 
 
 
2. Kernel Canonical Correlation Analysis 
(KCCA) 
 
The centering and whitening preprocessing [19] steps can 
be performed in the kernel feature space.  The goal of 
whitening is to transform the centered samples via an 
orthogonal transformation into vectors where the 
correlation matrix is the unit matrix.  Given two centered 
random multivariables 
xnRx and 
ynRy
, the goal 
of canonical correlation analysis (CCA) is to find a pair of 
directions x
w
 and y
w
 such that the correlation 
),( yx
 
between the two projections 
xwTx  and 
ywTy  is 
maximized [19], where 
}{}{
}{
),,,(
y
TT
yx
TT
x
y
TT
x
yx
wyywEwxxwE
wxywE
wwyx 
                                                                                          (1) 
Suppose that { i
x
} and { i
y
} are N observations of x  
and 
y
respectively.  Then the goal of CCA is equivalent 
to finding x
w
 and y
w
 that maximize 
y
TT
yx
TT
x
y
TT
x
yx
wYYwwXXw
wXYw
wwyx ),,,(
                
(2) 
where 
]...,,[ ,21 NxxxX  , 
]...,,[ ,21 NyyyY  . 
 
Let x be mapped into a Hilbert space F  through a 
nonlinear mapping   
FR x
n  : , ).(xx   
Also, we suppose that 
)(x
 is centered in F .  For a 
method to center 
)(x
, see [21].  From (2), we obtain 
that the correlation function in F  can be formulated as 
y
TT
yx
TT
x
y
TT
x
yx
wYYwwXXw
wYXw
wwyx
)()(
)(
)(
))()((
)(
),,),((







 
Therefore, the goal of KCCA is equivalent to finding 
)(xw  and y
w
 that maximize y
TT
x wYXw )()(   under 
the constraints  
)()( ))()(( x
TT
x wXXw   = y
TT
y wYYw  =1                   
(3) 
where 
         
)](),...,(),([)( 21 NxxxX                     (4) 
It is well-known that principal component analysis (PCA) 
[22] looks for those directions of 
xnR in which the 
variance of the data is large.  For optimal selection of the 
independent directions, several objective functions were 
defined using approximately equivalent approaches.  
According to [23], there exists direction )(x

such that  
)()( )( xx Xw                                        (5) 
Assume that 
),( ji xxk  is a kernel function that can be 
expressed as the dot product form on the Hilbert space F  
  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1.  Speaker recognition rates (TALUNG)  
 
 
 
 
 
 
                                       
Figure 2.  Speaker recognition rates (KING) 
 6. Conclusion
 
The speaker feature selection problem based on GA has 
been addressed in this paper.  We use genetic algorithms 
to select the optimal feature set for speaker identification.   
Although the best classification performance in the 
experiment using TALUNG and KING databases is 
obtained when the GA is used, a major drawback of doing 
this is that the computation time has slightly increasing.   
 
References
 
[1] J.M. Lilly, S.C. Olhede, Higher-order properties of 
analytic wavelets, IEEE Transactions on Signal 
Processing. 57 (2009) 146-160. 
[2] H.F. Ates,M.T. Orchard, S pherical coding algorithm for 
wavelet image compression, IEEE Transactions on 
Image Processing. 18 (2009) 1015-1024. 
[3] S.Y. Lung, Feature extracted from wavelet 
decomposition using biorthogonal riesz basis for text  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
independent speaker recognition, Pattern Recognition. 
41 (2008) 3068
-
3070.
 
[4] H. Perez Meana, Advances in Audio and Speech 
Signal Processing: Technologies and Applications, 
Ideal Group Publishing. 2007, 371–407. 
[5] V. Kumbasar, O. Kucur, Better wavelet packet tree 
structures for PAPR reduction in WOFDM systems, 
Digital Signal Processing. 18 (2008) 885-891. 
[6] R.M. Rao, A.S. Bopardikar, Wavelet Transforms-
introduction to Theory and Applications, Addison-
Wesley. 1998. 
[7] K.M. Indrebo, R.J. Povinelli, Johnson, M.T., 
Minimum mean-squared error estimation of mel-
frequency cepstral coefficients using a novel 
distortion model, IEEE Transactions on Audio, 
Speech, and Language Processing. 16 (2008) 1654-
1661. 
[8] D. Hosseinzadeh, S. Krishnan, Combining vocal 
source and MFCC features for enhanced speaker 
recognition performance using GMMs, Proc. Int. 
Conf. on Signal Processing. (2007) 365-368. 
[9] M. Afify,  O. Siohan, Comments on vocal tract length 
normalization equals linear transformation in 
method                                                      Feature 16 24 32 
WT [9] 86% 88% 90% 
Multi-wavelet decomposition [18] 88% 90% 92% 
Improved WT [18]   90% 93% 96% 
Wavelet kernel feature + GA 93% 96%  
method                                                              Feature 16 24 32 
WT [9] 87% 91% 94% 
Multi-wavelet decomposition [18] 90% 92% 94% 
Improved WT  [18] 90% 95% 98% 
Wavelet Kernel Feature + GA 93% 97%  
WAVELET FEATURE SELECTION 
USING GENETIC ALGORITHM 
FOR TEXT-INDEPENDENT 
SPEAKER RECOGNITION   
S H U N G -Y U N G   LU N G  
 
M I N G  C H UA N  U N I V E R S I T Y    
TA I WA N  
0 2 / 0 4 / 2 01 2  
1 
BACKGROUND (1) 
3 
S
p
e
e
c
h
  p
ro
c
e
s
s
in
g
 
Analysis 
 Recognition 
Coding 
Speech Recognition 
Speaker Recognition 
Speech Identification 
SYSTEM OVERVIEW(1) 
Basic System 
5 
Pre -
processing 
Feature 
Extraction 
Classification 
In
p
u
t D
a
ta
 
In
fo
rm
a
tio
n
 
  F
e
a
tu
re
 s
e
t 
  Re
c
o
g
n
itio
n
 
WAVELET FEATURE 
  
 The scale j of the wavelet transforms  can be decomposition 
uniquely as  
                            
 
 
where         i s the diagonal matrix of eigenvalues of the covariance 
matrix      .  
7 
},,,,{ 121 Lj
L
jjjj WWWWW
 
12/1  jjjj VUW
j
jK
 GENETIC ALGORITHM 2 
Step3. Compute new centroids as follows: 
 
 
 
Step4. (Mutation Operator)Compute a new gain field by solving the    
following space-varying difference equation for      : 
 
     
 
9 



2
j
q
jk
jj
q
jk
k
gu
ygu
v
j
j
C
k
C
k
kk
q
jkjkj
q
jk
gH
gHvvugvyu
)*(                            
)*(
22
11
1 1



 
 
IDENTIFICATION 
A Gaussian mixture model (GMM) [6] was used to represent each 
reference speaker.  
 
The GMM were trained using the expection-maximization 
algorithm (EM).  
11 
DISCUSSION 
 The algorithm is automated. 
 
 Small memory space and little computation required. 
 
 Robustness on noisy sources. 
13 
100 年度專題研究計畫研究成果彙整表 
計畫主持人：龍生雲 計畫編號：100-2221-E-130-026- 
計畫名稱：非均勻取樣與小波核心二次相關分析於語者辨識之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
