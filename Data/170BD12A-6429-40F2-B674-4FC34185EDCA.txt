 1
to improve performance or reduce power 
consumption of the transformed applications 
targeted on Processor-in-Memory platforms. 
Based on the results we have done, we plan 
using five students and three years to expand 
our original prototype. In this project, we 
will design a novel automatic parallelizing 
system, Octans, to fit the capability 
difference between the host and memory 
processors. 
To make our draft Octans become a 
complete system, we will focus on two 
major topics. The first is to develop the 
basic analyzing modules of statement 
splitting, weight evaluation and schedule 
generation. The second is to design the 
scheduling mechanisms, CMS 
(Couple-Matching Scheduling), for the 
purpose of high performance computation.  
Finally, we will evaluate our new 
Octans system using the standard 
benchmarks such as NAS, SPEC2000 and 
Perfect Benchmark to obtain the real 
performance results for the 
Processor-in-Memory platform. The 
execution of this project not only can 
enhance the practicability and 
popularization of the Processor-in-Memory 
but also can offer a reference for other 
researchers who intend to develop new 
parallelizing and optimization strategies for 
MPSoC (Multi-Processor System-on-a-Chip) 
architectures. 
 
Keywords: Processor-in-Memory, Octans, 
Couple-Matching Scheduling, 
System-on-a-Chip(SoC). 
 
二、緣由與目的 
本 實 驗 室 先 前 曾 針 對
Processor-in-Memory 架構提出了一個新的
程式平行化系統雛形，稱為 SAGE II，並
且發展了一些演算法與分析轉換機制。在
過去的基礎之上，我們將利用三年的時
間，發展一新的分析轉換最佳化系統，稱
為 Octans。有別於以往使用迴圈輪次(Loop 
Iteration)為基本分析單位，Octans 使用陳
述(Statement)為基本分析單位，它可分析
原始程式碼(Source Codes)，透過陳述分割
(Statement Splitting)將程式切分為許多區
塊，並依其相依關係，產生對應之權重分
割相依圖(Weighted Partition Dependence 
Graph，WPG)，再決定每一區塊的權重
值。在完成上述的程式基本單位分析與分
割之後，在 Octans 系統裡，我們計劃用三
年的時間，開發所需之程式效能最佳化排
程與耗能最佳化排程，並完成 Octans 系統
中的各個基本分析轉換模組。此外，我們
亦嘗試開發數種最佳化技術，整合至
Octans 系統，使之具有更強大的功能，更
有效的分析轉換 Source Program。 
在效能最佳化排程機制中，我們計劃
發 展 一 排 程 技 術 ， 稱 為 CMS 
(Couple-Matching Scheduling)，此技術可提
高先前所發展之平行排程機制，依不同的
處理器能力與程式行為，選擇最好的工
作，以增加其平行化分析之能力，並針對
Processor-in-Memory 架構不同於傳統計算
機結構之特點，予以特殊的最佳化轉換。 
本實驗室先前在 Processor-in-Memory
架構下，提出 SAGE II 的研究計畫，藉由
國科會的補助，我們得以發展此一計算機
結構所需的平行化機制雛形，在本計畫
裡，我們實際撰寫出自動化之平行編譯器
系統，結合先前的各項技術與機制，並以
先前的研發成果為基礎，開發 Octans 系統
與 CMS (Couple-Matching Scheduling)機
制，並將初步成果發表於國際會議[1][2]。
其主要發展步驟如下：  
 
1. 發展 Octans 系統之基本分析模組：承
續先前所提出之 Statement-Based 之
分析觀點，取代過去平行化系統所採
用的 Iteration-Based 的分析方式，著
手設計 Octans 之各個模組，包括陳述
間 資 料 相 依 分 析 (Statement 
Dependence Analysis) 、 陳 述 分 割
(Statement Splitting)、WPG 產生器
(Weighted Partition Dependence Graph 
Generation) 、區塊權重評估 (Block 
Weight Evaluation)、區塊執行次序分
 3
驗證 Octans 系統與 CMS 技術在不同情況
下之正確性。真實測試程式之實驗數據請
見表一與圖二。在 Octans 系統與 CMS 機
制的排程下，我們可以獲得將近 4.38 倍的
效能增進，足見本系統與排程方法的功效。 
 
四、計劃結果自評 
 
在今年的計劃裡，我們發展 Octans 系
統 與 CMS 排 程 演 算 法 。 在
Processor-in-Memory 模擬器上，驗證 CMS
演算法的功能。在實際撰寫程式實作
CMS、測試模組間的資料傳遞、與實驗模
擬系統安裝時，我們學到許多原本我們所
忽略到的知識；相關參與這項研究計劃的
學生們也能夠藉此學習研究的方法與作學
問的態度。本計劃的初期研究成果，已發
表在國際會議[1] [2]。 
 
五、參考文獻：  
[1][2][3]為本國科會計畫補助之研究
成果。 
 
[1] Slo-Li Chu; Toward to Utilize the 
Heterogeneous Multiple Processors of the 
Chip Multiprocessor Architecture; in 
Lecture Notes in Computer Science. (EUC 
2007), Vol.  4808, Springer-Verlag, Pages: 
234 - 246, (December 2007). (EI) (NSC 
96-2221-E-033 -019). 
[2] Slo-Li Chu; Critical Block Scheduling: a 
Thread-Level Parallelizing Mechanism for 
a Heterogeneous Chip Multiprocessor 
Architecture; in Lecture Notes in Computer 
Science. (LCPC 2007), Vol. 5234, 
Springer-Verlag, Pages: 261–275, 2008.  
(EI) (NSC 96-2221-E-033 -019) 
[3] Slo-Li Chu; Design a Parallelizing System 
to Fully Utilize Processing Units in the 
Chip Multi-Processor System; in 
Proceedings of The 14th Workshop on 
Compiler Techniques for 
High-Performance Computing; (National 
Taiwan University, Taipei, Taiwan; May 
26-27, 2008). Page(s): II-27-35. (NSC  
96-2221-E-033 -019) 
[4] Agrawal, K., He, Y., Hsu, W-J., Leiserson, 
C.: Shared Memory Parallelism: Adaptive 
Scheduling with Parallelism Feedback. In 
Proceedings of the Eleventh ACM 
SIGPLAN Symposium on Principles and 
Practice of Parallel Programming, Mar. 
(2006). 
[5] Armstrong, R., Hensgen, D., and Kidd, T.: 
The Relative Performance of Various, 
Mapping Algorithms is Independent of 
Sizable Variances in Run-Time Predictions.  
In Proceedings of 7th IEEE Heterogeneous 
Computing Workshop, Mar. (1998), 79-87. 
[6] Arora, N., Blumofe, R., Plaxton, C.: Thread 
Scheduling for Multiprogrammed 
Multiprocessors. In Proceedings of the 
Tenth Annual ACM Symposium on Parallel 
Algorithms and Architectures, Jun. (1998).     
[7] Blume,W., Eigenmann, R., Faigin, K., 
Grout, J., Hoeflinger, J., Padua, D., Petersen, 
P., Pottenger, B., Rauchwerger, L., Tu, P., 
Weatherford, S.: Effective Automatic 
Parallelization with Polaris. International 
Journal of Parallel Programming, May, 
(1995). 
[8] Chu, S. L.: PSS: a Novel Statement 
Scheduling Mechanism for a 
High-performance SoC Architecture. In 
Proceedings of Tenth International 
Conference on Parallel and Distributed 
Systems, Jul. (2004). pp. 690-697. 
[9] Cintra, M., Torrellas, J: Eliminating 
Squashes Through Learning Cross-Thread 
Violations in Speculative Parallelization for 
Multiprocessors. In Proceedings of 2002 
Eighth International Symposium on 
High-Performance Computer Architecture, 
Feb. (2002), 43-54. 
[10] Crisp, R.: Direct Rambus Technology: the 
New Main Memory Standard. In 
Proceedings of IEEE Micro, Nov., (1997), 
pp. 18-28. 
[11] Hall, M., Anderson, J., Amarasinghe, S., 
Murphy, B., Liao, S., Bugnion, E., Lam, M.: 
Maximizing Multiprocessor Performance 
with the SUIF Compiler. IEEE Computer 
Dec., (1996). 
[12] Hall, M., Kogge, P., Koller, J., Diniz, P., 
Chame, J., Draper, J., LaCoss, J., Granacki, 
J., Brockman, J., Srivastava, A., Athas, W., 
Freeh, V., Shin, J., Park, J.: Mapping 
Irregular Applications to DIVA, a 
PIM-Based Data-Intensive Architecture. In 
 5
演算法一：Couple-Matching Scheduling (CMS) Algorithm 
[Input] 
WPG=(P,E): original weighted partition dependence graph after weight and order of blocks 
are determined. 
[Output] 
An execution order schedule EO={EO1, EO2….} where EOi={PM(ba.… bb), PM(bc.… bd)} 
in which PH(ba.… bb) means that blocks ba.… bb will be assigned to P.Host in oreder i, 
PM(bc.… bd) means that blocks bc.… bd will be assigned to P.Mem in order i. 
[Intermediate] 
W: a working set of nodes ready to be visited.  
R: a working set of blocks ready to be scheduled 
min_pred_O(bi): the minimum execution order for all bi’s predecessor blocks. 
PHW(bi): the weight of bi for P.Host. 
PMW(bi): the weight of bi for P.Mem. 
ph_tmp(h),pm_tmp(m): working arrays to insert blocks for scheduling. 
Weight_Temp(i,j):store weight difference between PH and PM 
[Algorithm] 
/*Initialization and weight determination for each blocks */  
for each bi∈ Pdo  
iO = 0 
end for 
 
/* Execution order assignment */ 
W=P 
 
W=P-{ bs },where bs is the start block of WPG 
O(bs)=1 
h=m=0 
R=φ  
while W≠φ AND A≠P do  
call Ready Set Determination (W,R) 
If W≠φ  then 
call Sort Block ( R, h, m, ph_temp, pm_temp ) 
 
p=q=1 
if  h≠0 AND m≠0 then 
call Load Balanced Blocks Selection ( ph_temp, pm_temp, h, m ) 
end if 
if  h=0 then 
for i=1 to m do 
bi _temp=pm_temp[i] 
h=h+1 
insert bi _temp into pm_temp(h) in decreasing order by the PHW(bi) 
end for 
call Load Balanced Blocks Selection ( ph_temp, pm_temp, h, m ) 
end if 
if  m=0 then 
 7
end if 
  end for 
} 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Subroutine
for P. Mem
Block Execution Order Analysis
Block Weight Evaluation
Code Generator
Weight 
Table
Subroutine
for P. Host 
Source 
Program 
Dependence
Analysis
Statement
Splitting
WPG Graph
Generation
Statement Splitting
Couple-Matching 
Scheduling
User
Constraints
 
圖一、Octans 系統的分析階段組織圖 
表一：測試程式在Octans排程後之實驗數據 
Speedup 
Bench 
mark 
Standard 1H-1M 1H-nM 1H-1M 1H-nM n  (Occupied 
P.Mem) 
swim 228289321 116669760 52168027 1.96 4.38 6 
cg 91111840 51230772 32124287 1.78 2.84 4 
TISI 133644087 173503404 91098174 0.77 1.47 2 
fft 117998621 101841407 110399171 1.16 1.07 2 
strsm 201133647 139990872 53711479 1.44 3.74 5 
 1
專題研究計畫成果報告 
出席國際會議研究心得報告 
 
一、 會議名稱︰ 
The 20th International Workshop on Languages and Compilers for Parallel 
Computing 
        
二、 會議期間及地點︰ 
October 11-13, 2007, University of Illinois at Urbana-Champaign, Siebel 
Center for Computer Science, Urbana, Illinois, USA 
 
三、 發表論文︰ 
Critical Block Scheduling: a Thread-Level Parallelizing Mechanism for a 
Heterogeneous Chip Multiprocessor Architecture 
 
四、 受補助項目︰ 
機票費 
 
五、出席國際會議報告書︰ 
 
(一)參加會議經過 
 
本篇 paper 報告之時間，排定是 10 月 12 號上午 16:30-17:30，為第二個
報告者。其排定之時間如下列所示： 
 
16:30-17:30 Parallel Compiler Technology II 
 
Exploiting SIMD Parallelism with the CGiS Compiler Framework 
Nicolas Fritz, Philipp Lucas and Reinhard Wilhelm  
Critical Block Scheduling: a Thread-Level Parallelizing Mechanism for a 
Heterogeneous Chip Multiprocessor Architecture 
Slo-Li Chu  
 
 
 
 
