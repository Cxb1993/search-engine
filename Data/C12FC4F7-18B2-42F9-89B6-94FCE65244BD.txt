of operating parameters.  
Furthermore, an inverse predicting model of the SOFC 
stack is developed by the calculating algorithms of 
the BPNN. This model is proved to effectively predict 
the operating parameters to achieve a desired 
performance output of the SOFC stack. 
英文關鍵詞： a SOFC stack, BPNN, inverse predicting model of 
operating parameters, optimization of electrical 
performance 
 
 I 
 
 
Contents 
中文摘要 1 
Abstract 1 
1. INTRODUCTION 2 
2. Description of the theory 3 
3. Modeling by Back-Propagation Neural Network 5 
4. Optimization Using Improved BPNN 7 
5. Inverse prediction of operating parameters by using Improved BPNN 8 
6. Results and discussions 9 
6.1 The important priority of factors decided by Taguchi’s method 9 
6.2 Modeling and prediction of current density for a SOFC stack 11 
6.3 Optimization of performance for a SOFC stack 13 
6.4 Inverse prediction of operating parameters for a SOFC stack 14 
7. Conclusions 15 
References 15 
國科會補助專題研究計畫成果報告自評表 17 
 
 2 
 
1. INTRODUCTION 
Including two electrodes of anode and cathode, as well as one solid electrolyte between the anode and 
cathode, a solid oxide fuel cell (SOFC) delivers oxygen ions from cathode to anode.  Methane and ethanol 
serve as the fuel, whose operating temperature is very high about 600-1000°C.  Many studies had been 
investigated in the performance simulation under different conditions recently; such the effects of fuel rate, 
inlet temperature, operation pressure, cell size, etc. on the temperature and current density distribution. 
Yakabe et al. [1] modeled an anode-supported planar SOFC unit with double channels of counter-flow pattern.  
Their results indicated that the water shift reaction could effectively reduce the concentration polarization.  
Later, Yakabe et al. [2] simulated a three-dimensional model for a unit of planar SOFC, in the considerations 
of internal or external steam reforming, water shift reaction, and diffusion of gases with co-flow or 
counter-flow pattern.  Recknagle et al. [3] also simulated a three-dimensional unit of SOFC with three kinds 
of flow patterns, i.e. co-flow, counter-flow, and cross-flow.  Their results showed that the pattern of the 
co-flow had the most uniform temperature distribution and the smallest thermal gradients.  Beale, et al. [4] 
investigated three different approaches in numerical methods for solving a unit and ten-stack SOFC in 
cross-flow, which results indicated that the direct numerical method is the most accurate method for a single 
cell, and the simpler approaches have the potential to supplant or complement the direct numerical method in 
the analysis of fuel cell stacks.   The study of Iwata et al. [5] investigated the effects of gas re-circulation 
ratio, operating pressure and physical properties on current and temperature distributions by establishing a 
numerical program to estimate the temperature and current density profiles of a planar-type SOFC unit with 
co-flow, counter-flow, and cross-flow. 
Also, coupling electrochemical kinetics with fluid dynamics, Huang et al. [6] developed a multi-physics 
model to evaluate the transport phenomena in a mono-block-layer SOFC.  Because the spatial variation of 
the catholic and anodic surface over-potential is considered locally, their model improves the prediction of the 
local current density distribution. Janardhanan et al. [7] offered a performance analysis of a planar solid oxide 
fuel cell under direct internal reforming conditions to study the influences of various operating parameters on 
cell performance. Their results suggested that the efficiency of the fuel cell is higher for pre-formed fuel 
compared with non-reformed fuel. Araki et al. [8] presented a power generation system consisting of two 
SOFCs at different operating temperatures and in the serial connection. Their results showed that the power 
generation efficiency of the two-stage SOFC is somewhat higher than that of SOFC using only a 
high-temperature. 
However, few reports have investigated the effects of non-uniform inlet flow on fuel cell temperature and 
current density. Hirata and Hori [9] presented a numerical method to discuss the relationships between planar 
and stacking direction gas flow uniformities, and cell performance in a co-flow type fuel cell.  Liu et al. [10] 
as well as Yuan and Liu [11] developed a reliable numerical method to examine the effect of inlet flow 
maldistribution in the transverse direction on the thermal and electrical performance of a MCFC and SOFC 
unit with cross-flow configuration. Their results showed that the non-uniform inlet flow has only slightly 
effects on the average temperature and average current density, but induces significantly the non-uniformities 
of temperature and current density for most maldistribution patterns. The non-uniform gas flow rate in each 
stack is very severe because of the gas manifold. Some research [12], [13] and [14] identified an obvious 
maldistribution of the gas flow rate in the stacking direction of a SOFC stack.  
Also, Yuan [15] investigated the non-uniform effect of gas flow rate on the thermal and electrical 
performance of a SOFC stack, considering a uniform profile and a progressively increasing profile in the 
stacking direction with two boundary conditions, adiabatic and constant temperature, on the top and bottom 
faces of a SOFC stack. Although the non-uniform effect on the electrical performance of each stack is 
apparently realized, the optimal conditions in consideration of all non-uniform inlet flow rates and parameters 
as well as their importance are still difficult to obtain by the numerical method. 
Instead of the numerical method, neural network architecture has currently become more and more 
important as an effective learning technique in the field of pattern recognition since neural networks have 
strong abilities to learn, to self-organize information, and need only few specific requirements and prior 
 4 
 
 
Fig. 1. Schematic diagram of a unit solid oxide fuel cell stack with cross-flow configuration [15]. 
 
 
 
 
 
 
 
dstack =1.5  dstack =1.25  dstack =1  dstack =0.75  dstack =0.5 
 Fig. 2. the whole SOFC stack with two inlet flow distributions 
 6 
 
n
jx  
 
1n
kj
W  
 
1n
1
x
 
n
j1W  
 n
ji
1n
i Wx
  
n
jnet  f 
n
jt  
 
(n-1)th layer 
 
nth layer 
 (n+1)th layer 
ith neuron 
 jth neuron 
 
kth neuron 
 
Fig. 3  Schematic diagram of a neuron 
model 
 
 
  
 
 
improved BPNN will be applied here to establish a rapid calculating scheme for predicting the average current 
densities in each layer of a SOFC stack. 
An artificial BPNN usually has multi-layers.  The input layer accepts the environmental information; the 
output layer carries information to the environment. The layers lying between the input and output layers are 
called the hidden layers.  The basic unit  the neuron  acts as a “processing element”.  For an example 
shown in Fig. 3, the jth neuron in the nth layer has many inputs 1n
1
x  which come from the neurons in the 
(n-1)th layer, but only a single output n
jx  that carries its signal to the neurons in the (n+1)th layer.  An 
adjustable weight, n
jiW , representing the connecting strength, lies between the jth input branch in the nth layer 
and the ith neuron in the (n-1)th layer.  The basic function (net sum) of a neuron is to sum up its inputs and 
by means of the transfer function to produce an output.  An internal threshold t is usually introduced and 
subtracted from the sum.  Mathematically, the net sum n
jnet  of the jth neuron in the nth layer can be 
expressed as 
  
i
n
j
1n
i
n
ji
n
j txWnet
 (7) 
Then the output value n
jx  can be calculated as 
n
j
n
j1
)(
n
jn
j
n
j netβ
e
θ
netfx



 (8) 
, where f ( ) is the transfer function. The sigmoid function is a type of the transfer function used most 
commonly.  Rangwala [24] presented a new form of the sigmoid function adopted here as eq.(8) in order to 
make the network respond to arbitrary input/output mapping, where sigmoid slope  regulates the size of the 
input zone beyond which the neuron output saturates as well as the steepness of the sigmoid curve.  The 
maximum output  controls the maximum output of one neuron. 
 
 
 
 
 
In the back propagation learning scheme, the calculated outputs in the output layer, 
q
jx , are compared with 
the desired outputs, dj, to find the error, before the error signals are propagated backward through the network.  
The error function E can be defined as 



p
1j
2q
jj )( xdE
2
1
 (9) 
, where q is the total number of layers in the network and p the total number of the output neurons.  The 
learning process is to adjust the learning parameters, W, t,  and, so that the error E can be minimized and 
the mapping between inputs and outputs can be realized.  In order to accomplish this, gradient descent 
technique is applied to calculate the gradient of the error with respect to each learning parameter.  Then the 
learning parameters are changed and adjusted in the direction of the steepest descent of the error. The training 
formulae to adjust W, t,  and  can be written as   
)()( nji
1n
i
n
j
n
ji TWxTW 
 1
 (10) 
)(1)(Δ nj
n
j
n
j TΔtγδηTt   (11) 
)(])([)( nj
n
j
n
j
n
j
n
j
n
j
n
j TnetxxT   11  (12) 
)()()( nj
n
j
n
j
n
j
n
j TxT   1  (13) 
 8 
 
  njnjnjnjnjnjnjn
j
n
j
n
j
n
j
n
j )( 



 xxnetf
net
x
x
F
net
F




 1
 (23) 
For hidden layers, the quantities 
n
j  and
n
j  can be derived as 
n
j
1n
k
k
1n
k
n
j x
net
net
F
x
F








 (24) 
 
k
1n
jk
1n
k
n
j w
 (25) 
  njnjnjnjnjnjnjnj )( βθxxnetf  1  (26) 
For input layer, the quantities 
1
j  can be derived as 

k
2
jk
2
j
1
j w
 (27) 
The quantities n
j  and
n
j  are propagated backward, a calculating process similar to the above model 
developed by the improved BPNN.  For the output layer, the quantity n
j  is first decided by the cj, the 
weighting for the output average current density q
jx  of the jth layer in a SOFC stack, and then the quantity 
n
j  can be obtained by the quantity
n
j .  The process of calculation is characterized by the adoption of the 
calculating algorithm of the BPNN from the output layer back propagated to the input layers. Thus, the 
adjustment of the operating parameter can be rewrote as 
)()( 1j
1
j
1
j TxTx 
 1
 (28) 
The scale of the performance, i.e. operating performance window, of a SOFC stack is desired in practical 
application, whose value is between the maximum F and minimum F.  The Maximum F can be obtained as 
mentioned above. On the other hand, the minimum F can be achieved just by changing the opposite direction 
of the steepest descent of the objective function as the operating parameters are adjusted. Thus, the adjustment 
of the operating parameters for the minimum F can be expressed as 
)()( 1j
1
j
1
j TxTx 
 1
 (29) 
5. INVERSE PREDICTION OF OPERATING PARAMETERS BY USING IMPROVED BPNN 
Sometimes the performance of a SOFC stack is requested to be maintained at or changed to a certain value 
in practical operation.  An operator would prefer to efficiently realize the proper operating parameters to 
obtain the desired performance of a SOFC stack. Thus, the inverse prediction of operating parameters is 
developed here to achieve a desired performance of a SOFC stack.  Once a desired performance output Q, 
limited in the operating performance window of a SOFC stack, is decided, the object function can be derived 
as the sum of square of the difference between a temporary performance and the desired Q value.   
2








 

QxcF
p
1j
q
jj
 (30) 
The desired performance is on the target when the object function has the minimum value, i.e. 0. Therefore, 
the optimized process is to adjust the operating parameters 1jx  so that the objective function can be minimized. 
Similarly, gradient descent technique is applied to calculate the gradient of the objective function with respect 
to each operating parameter.  Then the operating parameters are changed and adjusted in the reverse 
direction of the steepest descent of the objective function. The adjustment of the operating parameters can be 
expressed as 
)(1)( 1j1
j
1
j Tx
x
F
Tx 


  
 (31) 
, where * is the converging rate, 0  *< 1, T is the iteration, and * is the momentum factor, 0  *< 1.  
Also, all the operating parameters
1
jx  are constrained between their top and down levels. 
Similarly, the quantities 
n
j  and
n
j  are defined as the above section, which calculating process are 
propagated backward by the application of BPNN. Differently, the quantity 
n
j  for the output layer is 
 10 
 
TABLE 1.   
THE FACTORS AND LEVELS APPLIED IN L50(2
1
×5
11
)  
factor description symbol Level 1 Level 2 Level 3 Level 4 Level 5 
A Air flow deviation in the stacking direction dstack 0.5 0.75 1 1.25 1.5 
B Mole flow rate in anode inlet Nf 0.03 0.06 0.09 0.12 0.15 
C Molar fraction H2 in anode inlet 2HX
  0.16 0.24 0.32 0.40 0.48 
D Molar fraction CO2 in anode inlet 2COX
  0.02 0.03 0.04 0.05 0.06 
E Molar fraction H2O in anode inlet OH2X
 0.02 0.04 0.06 0.08 0.10 
F Molar fraction CO in anode inlet COX  0.12 0.18 0.24 0.30 0.36 
G Mole flow rate in cathode inlet  Na 0.06 0.12 0.18 0.24 0.30 
 
TABLE 2.   
THE DESIGN OF TRAINING DATA FOR ALL FACTORS AND LEVELS BY L50(2
1
×5
11
) 
Exp. A B C D E F G Ia1 Ia2 Ia3 Ia4 Ia5 Ia6 Ia7 Ia8 Ia9 Ia10 Sum 
1 1 1 1 1 1 1 1 4221.91  4249.58  4264.65  4272.11  4275.04  4274.84  4271.40  4263.11  4246.59  4216.56  46538.19 
2 1 2 2 2 2 2 2 4428.72  4478.11  4497.83  4505.16  4507.46  4507.31  4504.51  4495.96  4473.14  4416.53  46804.67 
3 1 3 3 3 3 3 3 4464.97  4522.16  4541.14  4546.98  4548.57  4548.47  4546.52  4539.54  4516.90  4449.20  46989.4 
4 1 4 4 4 4 4 4 4471.90  4532.55  4550.10  4554.75  4555.88  4555.83  4554.43  4548.78  4527.51  4454.22  47125.58 
5 1 5 5 5 5 5 5 4471.19  4533.38  4549.56  4553.52  4554.40  4554.36  4553.26  4548.46  4528.58  4452.53  47229.71 
6 2 1 2 3 4 5 1 3848.69  3883.09  3901.34  3910.19  3913.62  3913.38  3909.33  3899.44  3879.32  3841.81  43878.78 
7 2 2 3 4 5 1 2 4050.64  4104.57  4125.60  4133.21  4135.57  4135.42  4132.55  4123.61  4099.16  4037.03  44395.93 
8 2 3 4 5 1 2 3 5362.35  5413.77  5430.75  5435.95  5437.33  5437.25  5435.54  5429.29  5408.99  5347.90  44921.56 
9 2 4 5 1 2 3 4 5136.68  5193.09  5209.71  5214.26  5215.35  5215.28  5213.93  5208.41  5188.21  5119.85  51909.28 
10 2 5 1 2 3 4 5 3926.07  3989.71  4006.27  4010.20  4011.06  4011.02  4009.96  4005.15  3984.84  3906.61  51297.11 
11 3 1 3 5 2 4 4 4544.88  4593.96  4612.04  4618.48  4620.46  4620.31  4617.82  4610.10  4588.47  4529.98  41720.88 
12 3 2 4 1 3 5 5 4621.52  4676.49  4694.57  4700.27  4701.84  4701.72  4699.72  4692.75  4670.71  4603.96  49352.01 
13 3 3 5 2 4 1 1 4581.44  4630.97  4651.60  4659.32  4661.75  4661.62  4658.77  4649.91  4626.41  4570.38  48954.31 
14 3 4 1 3 5 2 2 3527.27  3590.76  3611.10  3617.03  3618.54  3618.46  3616.67  3609.67  3585.68  3511.06  48809.25 
15 3 5 2 4 1 3 3 5001.86  5059.72  5075.94  5080.09  5081.04  5081.01  5079.86  5074.90  5055.41  4985.83  48716.83 
16 4 1 4 2 5 3 5 4178.18  4232.02  4251.05  4257.57  4259.54  4259.39  4256.90  4248.98  4225.92  4160.91  45742.6 
17 4 2 5 3 1 4 1 5402.19  5435.20  5451.42  5458.58  5461.14  5460.97  5457.93  5449.81  5431.58  5394.97  46155.38 
18 4 3 1 4 2 5 2 4143.60  4200.18  4220.36  4226.97  4228.83  4228.72  4226.47  4218.67  4194.95  4128.82  46432.08 
19 4 4 2 5 3 1 3 4246.80  4307.98  4326.21  4331.17  4332.37  4332.31  4330.84  4324.89  4303.00  4229.49  46507.04 
20 4 5 3 1 4 2 4 4295.61  4358.16  4375.01  4379.18  4380.12  4380.08  4378.92  4373.89  4353.37  4276.96  53575.71 
21 5 1 5 4 3 2 4 4662.56  4711.46  4729.73  4736.28  4738.32  4738.17  4735.62  4727.75  4705.91  4647.68  43029.31 
22 5 2 1 5 4 3 5 3642.44  3702.28  3721.77  3727.79  3729.44  3729.33  3727.25  3719.86  3696.08  3623.25  43816.93 
23 5 3 2 1 5 4 1 3827.59  3881.76  3904.15  3912.55  3915.17  3915.04  3911.95  3902.31  3876.71  3815.12  51311.76 
24 5 4 3 2 1 5 2 5210.17  5262.84  5280.61  5286.06  5287.50  5287.43  5285.70  5279.28  5258.31  5196.18  50762.3 
25 5 5 4 3 2 1 3 4995.37  5053.85  5070.44  5074.73  5075.72  5075.67  5074.49  5069.36  5049.44  4978.88  50239.23 
26 1 1 1 4 5 4 3 3386.99  3440.26  3461.23  3469.13  3471.68  3471.48  3468.35  3459.04  3434.43  3372.25  42328.88 
27 1 2 2 5 1 5 4 4832.25  4883.48  4901.08  4906.80  4908.43  4908.32  4906.27  4899.36  4878.22  4817.08  43201.99 
28 1 3 3 1 2 1 5 4753.28  4809.99  4827.31  4832.31  4833.56  4833.47  4831.90  4825.78  4804.66  4735.70  50019.97 
29 1 4 4 2 3 2 1 4661.93  4715.35  4735.46  4742.26  4744.20  4744.12  4741.85  4734.07  4711.10  4650.31  49695.32 
30 1 5 5 3 4 3 2 4631.45  4691.35  4709.66  4714.67  4715.91  4715.86  4714.38  4708.51  4687.09  4616.94  49461.87 
31 2 1 2 1 3 3 2 4047.06  4091.97  4111.54  4119.60  4122.38  4122.18  4118.82  4109.50  4087.05  4035.98  47062.85 
32 2 2 3 2 4 4 3 4219.19  4274.28  4294.14  4300.93  4302.91  4302.78  4300.32  4292.22  4268.64  4203.71  47229.74 
33 2 3 4 3 5 5 4 4284.02  4343.66  4362.30  4367.75  4369.14  4369.05  4367.32  4360.67  4338.11  4266.08  47346.74 
34 2 4 5 4 1 1 5 5581.26  5635.41  5650.60  5654.54  5655.45  5655.40  5654.27  5649.43  5630.77  5564.34  47273.29 
35 2 5 1 5 2 2 1 4189.40  4249.13  4268.96  4274.88  4276.41  4276.36  4274.61  4267.85  4245.10  4176.55  47367.12 
36 3 1 3 3 1 2 5 4871.51  4919.01  4935.81  4941.64  4943.40  4943.26  4941.06  4934.02  4913.69  4856.35  44015.17 
37 3 2 4 4 2 3 1 4854.59  4893.48  4911.97  4919.89  4922.68  4922.50  4919.20  4910.20  4889.42  4846.19  44680.5 
38 3 3 5 5 3 4 2 4808.91  4862.61  4881.80  4888.11  4889.88  4889.78  4887.64  4880.20  4857.66  4795.08  45155.76 
39 3 4 1 1 4 5 3 3695.50  3758.60  3777.76  3783.09  3784.41  3784.34  3782.73  3776.30  3753.29  3677.67  52253.68 
40 3 5 2 2 5 1 4 3884.77  3949.22  3966.26  3970.46  3971.37  3971.33  3970.21  3965.15  3944.39  3865.88  51426.65 
41 4 1 4 5 4 1 2 4307.46  4352.10  4371.51  4379.42  4382.15  4381.94  4378.62  4369.44  4347.12  4296.20  41755.43 
42 4 2 5 1 5 2 3 4403.20  4457.57  4477.24  4483.94  4485.92  4485.78  4483.32  4475.29  4451.90  4387.63  49494.01 
43 4 3 1 2 1 3 4 4571.71  4627.74  4645.38  4650.58  4651.93  4651.85  4650.18  4643.84  4622.40  4554.53  49221.23 
44 4 4 2 3 2 4 5 4538.69  4598.54  4615.21  4619.57  4620.57  4620.52  4619.27  4613.94  4593.38  4519.73  49038.34 
45 4 5 3 4 3 5 1 4489.93  4548.03  4567.77  4573.77  4575.36  4575.36  4573.46  4566.59  4543.91  4476.93  48905.09 
46 5 1 5 2 2 5 3 4889.71  4933.53  4951.14  4957.90  4960.11  4959.94  4957.21  4949.23  4928.54  4877.28  45931.52 
47 5 2 1 3 3 1 4 3834.03  3891.87  3911.57  3917.93  3919.72  3919.60  3917.35  3909.64  3885.86  3816.28  46176.38 
48 5 3 2 4 4 2 5 4021.18  4082.27  4100.60  4105.73  4107.01  4106.94  4105.33  4099.02  4076.55  4001.63  46468.26 
49 5 4 3 5 5 3 1 4090.67  4148.82  4169.98  4176.94  4178.90  4178.82  4176.55  4168.57  4144.21  4077.28  46682.68 
50 5 5 4 1 1 4 2 5438.81  5492.58  5509.47  5514.28  5515.47  5515.42  5514.00  5508.34  5488.40  5424.77  53819.68 
 
 
 
 12 
 
TABLE 5.   
THE DESIGN OF TRAINING DATA FOR ALL FACTORS AND LEVELS BY L50(2
1
×5
11
) AND THEIR LEARNING RESULTS AT 
THE 77710 NETWORK STRUCTURE 
Exp. A B C D E F G *D 1 *D 2 *D 3 *D 4 *D 5 *D 6 *D 7 *D 8 *D 9 *D 10 Error% 
1 1 1 1 1 1 1 1 4199.62  4254.92  4270.77  4273.47  4273.47  4283.99  4273.59  4270.23  4254.73  4185.97  0.222 
2 1 2 2 2 2 2 2 4421.39  4479.78  4497.33  4501.47  4501.22  4503.67  4501.94  4496.11  4475.57  4405.62  0.088 
3 1 3 3 3 3 3 3 4464.64  4523.57  4541.38  4546.39  4547.05  4546.65  4546.54  4540.20  4518.48  4448.17  0.02 
4 1 4 4 4 4 4 4 4467.56  4526.43  4544.06  4549.73  4551.19  4549.55  4549.46  4543.10  4521.16  4450.81  0.117 
5 1 5 5 5 5 5 5 4471.85  4530.67  4548.10  4554.30  4556.26  4553.81  4553.71  4547.37  4525.29  4454.95  0.034 
6 2 1 2 3 4 5 1 3823.99  3883.08  3901.79  3906.00  3908.71  3912.70  3905.94  3900.17  3880.93  3808.15  0.193 
7 2 2 3 4 5 1 2 4046.84  4105.83  4125.13  4128.82  4131.09  4132.98  4129.28  4122.83  4102.50  4030.52  0.075 
8 2 3 4 5 1 2 3 5365.17  5425.92  5442.33  5446.09  5445.13  5446.57  5446.37  5441.84  5421.48  5348.81  0.167 
9 2 4 5 1 2 3 4 5127.81  5188.83  5205.17  5210.60  5209.35  5208.73  5211.20  5205.38  5183.25  5111.48  0.102 
10 2 5 1 2 3 4 5 3926.22  3989.81  4010.40  4016.83  4015.80  4012.51  4017.63  4009.39  3981.69  3909.28  0.087 
11 3 1 3 5 2 4 4 4546.39  4603.16  4619.99  4623.65  4624.65  4628.18  4623.74  4618.78  4600.30  4530.88  0.137 
12 3 2 4 1 3 5 5 4612.31  4671.62  4688.98  4694.12  4694.24  4693.96  4694.66  4688.24  4666.53  4596.03  0.135 
13 3 3 5 2 4 1 1 4581.36  4639.98  4657.07  4662.94  4665.07  4663.20  4662.57  4656.31  4635.19  4564.55  0.103 
14 3 4 1 3 5 2 2 3522.19  3587.64  3607.19  3615.78  3617.06  3613.52  3614.86  3606.45  3580.76  3503.95  0.103 
15 3 5 2 4 1 3 3 5001.03  5060.76  5077.13  5081.93  5080.99  5080.56  5081.40  5075.79  5055.06  4983.79  0.02 
16 4 1 4 2 5 3 5 4169.52  4227.93  4247.08  4250.33  4252.38  4254.57  4251.06  4244.75  4224.72  4153.42  0.129 
17 4 2 5 3 1 4 1 5381.72  5441.71  5458.31  5461.51  5461.44  5463.20  5461.63  5457.50  5437.85  5365.40  0.16 
18 4 3 1 4 2 5 2 4144.62  4205.35  4221.91  4229.84  4230.75  4228.43  4227.99  4221.15  4199.24  4126.64  0.055 
19 4 4 2 5 3 1 3 4245.27  4305.53  4322.47  4329.87  4331.40  4328.72  4328.57  4321.64  4299.73  4227.53  0.056 
20 4 5 3 1 4 2 4 4295.91  4355.06  4373.66  4378.54  4379.76  4379.11  4378.72  4372.15  4349.97  4279.34  0.033 
21 5 1 5 4 3 2 4 4635.19  4693.53  4710.38  4715.81  4717.49  4716.84  4715.64  4709.69  4689.15  4618.74  0.448 
22 5 2 1 5 4 3 5 3635.86  3696.81  3716.49  3720.79  3723.22  3726.82  3721.01  3714.56  3694.21  3619.66  0.135 
23 5 3 2 1 5 4 1 3820.13  3881.04  3901.51  3905.26  3907.16  3908.67  3906.05  3898.89  3877.13  3803.50  0.139 
24 5 4 3 2 1 5 2 5202.86  5261.96  5279.21  5281.83  5281.76  5283.64  5282.31  5277.58  5258.01  5186.58  0.073 
25 5 5 4 3 2 1 3 4994.27  5053.02  5070.02  5074.21  5075.01  5074.86  5074.33  5068.93  5048.52  4977.78  0.014 
26 1 1 1 4 5 4 3 3375.93  3437.67  3457.74  3462.01  3464.78  3470.54  3462.41  3456.49  3436.19  3360.61  0.157 
27 1 2 2 5 1 5 4 4827.08  4885.23  4902.18  4905.20  4903.84  4907.44  4905.96  4900.81  4881.22  4811.48  0.052 
28 1 3 3 1 2 1 5 4753.25  4814.08  4831.09  4836.49  4834.01  4834.24  4837.76  4831.06  4807.97  4737.34  0.061 
29 1 4 4 2 3 2 1 4661.82  4720.63  4737.67  4743.31  4744.46  4742.90  4743.05  4736.92  4715.43  4645.09  0.05 
30 1 5 5 3 4 3 2 4631.39  4690.10  4707.03  4713.20  4715.04  4712.62  4712.60  4706.45  4684.85  4614.48  0.038 
31 2 1 2 1 3 3 2 4043.00  4100.87  4119.30  4122.49  4124.06  4129.23  4123.03  4117.61  4098.78  4027.77  0.158 
32 2 2 3 2 4 4 3 4215.32  4274.08  4293.05  4296.89  4298.39  4299.60  4297.47  4291.05  4270.06  4199.09  0.063 
33 2 3 4 3 5 5 4 4289.41  4348.18  4366.82  4371.40  4373.29  4372.98  4371.61  4365.12  4343.68  4272.86  0.109 
34 2 4 5 4 1 1 5 5568.17  5631.32  5646.67  5651.80  5649.17  5650.34  5651.57  5647.49  5625.98  5551.52  0.102 
35 2 5 1 5 2 2 1 4190.96  4253.81  4268.50  4280.54  4280.82  4273.09  4276.65  4269.01  4244.68  4171.11  0.069 
36 3 1 3 3 1 2 5 4860.22  4918.96  4935.00  4938.99  4937.17  4941.25  4940.06  4934.84  4915.23  4845.14  0.077 
37 3 2 4 4 2 3 1 4837.35  4895.38  4912.35  4916.63  4917.86  4918.12  4916.64  4911.19  4891.24  4821.00  0.128 
38 3 3 5 5 3 4 2 4802.09  4860.38  4877.33  4882.42  4884.32  4882.98  4882.13  4876.38  4855.81  4785.38  0.108 
39 3 4 1 1 4 5 3 3692.03  3756.08  3777.26  3783.25  3783.80  3781.68  3784.00  3775.74  3749.39  3674.97  0.049 
40 3 5 2 2 5 1 4 3866.76  3928.52  3949.15  3953.95  3955.08  3954.39  3954.70  3947.16  3922.99  3850.02  0.447 
41 4 1 4 5 4 1 2 4302.24  4359.72  4377.27  4381.81  4384.47  4385.97  4381.52  4375.86  4356.64  4286.05  0.13 
42 4 2 5 1 5 2 3 4407.07  4465.55  4483.52  4488.39  4490.54  4490.04  4488.45  4482.08  4461.30  4390.48  0.125 
43 4 3 1 2 1 3 4 4567.21  4625.79  4643.80  4646.72  4644.93  4648.22  4647.80  4641.96  4621.13  4551.53  0.067 
44 4 4 2 3 2 4 5 4544.34  4603.16  4621.24  4625.27  4624.82  4625.48  4625.77  4619.61  4597.91  4528.06  0.122 
45 4 5 3 4 3 5 1 4497.33  4557.07  4572.93  4581.11  4582.66  4578.42  4579.03  4572.47  4550.64  4479.16  0.131 
46 5 1 5 2 2 5 3 4888.43  4947.29  4964.00  4968.87  4969.47  4969.32  4969.10  4963.41  4942.74  4872.14  0.208 
47 5 2 1 3 3 1 4 3834.27  3893.54  3912.71  3916.13  3918.14  3922.94  3916.65  3910.71  3891.41  3818.62  0.05 
48 5 3 2 4 4 2 5 4024.03  4083.60  4103.32  4106.90  4108.66  4110.31  4107.61  4100.87  4079.83  4007.63  0.065 
49 5 4 3 5 5 3 1 4089.48  4150.40  4167.59  4175.45  4177.73  4174.67  4174.02  4166.78  4144.80  4071.50  0.055 
50 5 5 4 1 1 4 2 5438.37  5498.74  5515.45  5518.34  5517.86  5519.97  5518.44  5514.48  5494.81  5421.96  0.079 
*: BPN network output results                                                                               Ave:0.11%  
By the processes of try and errors, it is found that 7 neurons in first hidden layer and 7 neurons in second 
hidden layer are more efficient for both better learning results and testing results. Therefore, 77710 
network structure is utilized here to perform the learning scheme.  The learning results, including the array of 
factors and value of all levels, are listed in Table 5.  Also, the testing results are listed in Table 6. 
Compared with the direct solutions, the mean percent errors for the training results and the testing results 
are 0.11% and 0.52%, respectively. The small mean percent errors verify that the superior mapping relations 
between inputs and outputs can be realized by the improved BPNN with great satisfaction. Hence, the 
development of the model of the current density has been accomplished by the implemented neural network 
algorithm. 
 Thus, the accuracy and effectiveness of the developed BPN algorithm are certified. The results also show 
 14 
 
 
Fig.5 The converging process of optimization 
6.4 Inverse prediction of operating parameters for a SOFC stack 
The operating performance window of a SOFC stack studied here is 33939.36 ≤ F ≤ 57795.62, as section 
mentioned above. Taking 5 desired performances as examples, the objective function converges steadily to the 
desired performance output Q in the optimized processes when the iteration T increases, as illustrated in Fig.6. 
Compared with the direct solution by FORTRAN program, all errors for the prediction of the desired 
performance of all cases listed in Table 8 are satisfactorily small. Hence, the inverse prediction of operating 
parameters developed by the calculating algorithms of the improved BPNN shows great effectiveness in 
achieving a desired performance of a SOFC stack. 
Instead of the direct solving procedure, the inverse calculating algorithm developed by the improved BPNN 
can provide a quick prediction of operating parameters to achieve a desired performance of a SOFC stack so 
as to complete dynamic control of the operating parameters,, such as the mole fraction of species and molar 
flow rate in inlet which are considered to be changeable. 
It is noted that a desired performance usually has multi sets of solutions as the calculating algorithms of 
inverse prediction of operating parameters proceed. It is better to fix the levels for those operating parameters 
are insignificant factors, and then unite solution can be achieved by the adjustment of one significant 
operating parameter with fixed levels of the other significant factors. They are our future works. 
 
Fig.6 The converging process of inverse prediction of operating parameters for desired performances of a 
SOFC stack 
 16 
 
[13] R.J. Boersma and N.M. Sammes, J. Power Sources 66 (1997), pp. 41–45. 
[14] T. Okada, S. Matsumoto, M. Matsumura, M. Miyazaki and M. Umeda, J. Power Sources 162 (2006), pp. 
1029–1035. 
[15] Ping Yuan, J. Power Sources 185 (2008), pp. 381-391. 
[16] Arriagada, J., Olausson, P., Selimovic, A., “Artificial neural network simulator for SOFC performance 
prediction”, J. Power Sources, vol. 112, 2002, pp. 54-60. 
[17] J.H. Koh, H.K. Seo, Y.S. Yoo and H.C. Lim, Chem. Eng. J. 87 (2002), pp. 367–379. 
[18] L.J.M.J. Blomen and M.N. Mugerwa, Fuel Cell Systems, Plenum Press, New York (1993) pp. 73–75. 
[19] S.H. Chan, K.A. Khor and Z.T. Xia, J. Power Sources 93 (2001), pp. 130–140. 
[20] J. Larminie and A. Dicks, Fuel Cell Systems Explained (1st ed.), Wiley, West Sussex (2000) p. 53. 
[21] R. Maric, S. Ohara, T. Fukui, H. Yoshida, M. Nishimura, T. Inagaki and K. Miura, J. Electrochem. Soc. 
146 (1999), pp. 2006–2010. 
[22] A.L. Hines and R.N. Maddox, Mass Transfer Fundamentals and Applications, Prentice-Hall, New Jersey 
(1985) pp. 17–59. 
[23] Wang, S.B., Wu, C.F., “Selections of working conditions for creep feed grinding. Part (III): avoidance of 
the work piece burning by using improved BP neural network”, Int. J. Adv. Manuf. Technol., vol. 28, 2006, 
pp. 31-37. 
[24] Rangwala, S., Dornfeld, D., “Learning and optimization of machining operations using computing 
abilities of neural networks”, IEEE Trans. on Systems, man and Cybernetics’, vol.19, No. 2, 1989, pp. 
299-314. 
[25] Peace, G., Taguchi Method: A Hands-on Approach, Addison-Wesley, Reading, MA,1993. 
[26] Syu-Fang Liu, Mu-Sheng Chiang, Shih-Bin Wang, Ping Yuan, Electrical and thermal performance of a 
solid oxide fuel cell unit with non-uniform inlet flow and high fuel utilization, Journal of Fuel Cell 
Science and Technology, June 2011, Vol. 8, pp. 031002.1-031002.7 
 
 
 1 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                     日期：101年 7月 30日 
                               
一、參加會議經過 
2012 International Conference on Applied Human Factors and Ergonomics 應用人因與人體工學
國際研討會(簡稱 2012 AHFE)每兩年舉辦一次，今年特別是在美國舊金山希爾頓飯店舉行。今年
擴大舉行，總計有五天行程，前兩天 7/21 7/22 參加半天四個特別主題之研習營，由有名教授授課，
我對與應用人因之實務特別有收穫。 
7/22 晚有歡迎參會 能有機會與看到來自不同的國家學者聚在一起交談。 
7/23~7/25 為期三天論文發表，總計有將近 150 個主題近上千篇的論文中發表。我的論文排
在 7/24 下午， plaza room 是大研討室，可容納 250 人主題是: Occupational Upper Extremity Injuries: 
From Observations to Solutions，我發表[The Analysis on Force of Door Operation of Applying 
Universal Design and the Mechanism Design of Measurement Device] 此會議主持人來自台灣 到美
國已有多年，目前也是 J. Applied Ergonomics 的編輯之一，他鼓勵我，研討會之後可將論文整理
投此期刊。  
二、與會心得 
透過參加國際研討會，可增進國際視野，通過與會者之間的交流與溝通，發現台灣仍是大
有可為。國際場合代表國家立場，為了能將台灣推展出去，多結交一些外國朋友，未來在英文表
達方面需要更努力。 
 
三、發表論文全文或摘要 
計畫編號 NSC 100-2221-E-234 -003 - 
計畫名稱 固態氧化物燃料電池堆性能最佳化與操作參數之選擇 
出國人員
姓名 
王士賓 
服務機構
及職稱 
黎明技術學院創意產品設計系 
副教授 
會議時間 
101年 7月 21日至 
 101年 7月 25日 
會議地點 U.S.A, CA, San Francisco 
會議名稱 
(中文)第四屆應用人因與人體工學國際研討會 
(英文) AHFE 2012 (4th International Conference on Applied Human Factors 
and Ergonomics) 
發表題目 
(中文)應用通用設計於門操作力分析之機構與量測設備 
(英文) The Analysis on Force of Door Operation of Applying Universal 
Design and the Mechanism Design of Measurement Device 
 3 
六、其他：參加照片 
 
 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：王士賓 計畫編號：100-2221-E-234-003- 
計畫名稱：固態氧化物燃料電池堆性能最佳化與操作參數之選擇 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100% 計畫執行之研究結案報告 
研討會論文 0 1 100% 
篇 
預計參加於12月7
及 8日於與 101年
度與中國機械工
程學會101年年會
/第 29屆全國學術
研討會同時舉辦
能源學門成果發
表會 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100% 
預計投稿國外燃
料電池與能源相
關期刊 
研究報告/技術報告 0 0 100%  
研討會論文 0 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
