F-Measure of MRCC is 74.50% which outperforms the RCC 
(63.54%) and segmentation-based approach (41.41%) 
significantly. 
英文關鍵詞： saliency map, background region detection, 
computational aesthetics, composing text-overlaid 
images 
 
 2 
中文摘要 
之前 Lai 等人(2010)的研究，建立了一個在圖文合成影像(text-overlaid images)中視覺平衡和
計算美學之間的正相關關係。在圖文合成影像上必須要有精確的背景區域範圍來藉以計算
出視覺平衡，也避免蓋到重要的圖上物件。而 Lai 在背景區域的選擇上是採用影像區塊化
分割技術 (Comaniciu & Meer 1997)，將原圖區塊化處理之後選擇最大區塊面積視為背景。
由於影像的背景也可能是有複雜的物件、紋裡、漸層的複雜情況出現，區塊化分割技術無
法適用於所有複雜的背景圖片而造成誤判率太高。本計畫研究的重點則在探討使用顯著圖
(saliency map)技術，來進行複雜背景圖片的背景區域選擇。我們以 Region based contrast 
saliency map cut (RCC , Cheng et al. 2011)為基礎，發展出適用於圖文合成影像研究上取出背
景方法Multiple region based contrast map saliency cut (MRCC)，能在多物件複雜背景的圖片
中，選取出正確的背景區域來，也避免了中空及邊界侵蝕的問題。從實驗結果顯示，在單
一物件複雜背景圖片測試中 MRCC 可維持 F-Measure = 85.55%，而在多物件複雜背景圖片
測試中，MRCC F-Measure = 74.50%，超越 RCC(63.54%)及 SEG(41.41%)各有 10.96%及
33.09%之多。 
 
關鍵詞: 計算美學，視覺平衡，顯著圖，背景區域，自動化圖文合成系統 
 
Abstract 
Our previous research in Lai et al. (2010) proposes a computational model for estimating the 
visual balance of colored text-overlaid images based on background region segmentation 
techniques. The human subjective experiments establish a positive correlation between the model 
of average visual balance and human perception on the aesthetic appeal of text-overlaid images. 
However, for images with complex and cluttered background regions, the error rate of the 
segmentation techniques for detecting the background region of an image is high. Based on the 
saliency map model of the “Region based contrast saliency map cut” (RCC , Cheng et al. 2011), 
this project develops a “Multiple region based contrast map saliency cut” (MRCC) for detecting 
the background regions of cluttered images with multiple salience objects. The experiments 
showed that F-measure is 85.55% of MRCC for images with a single salient object. For images 
with multiple salient objects, the F-Measure of MRCC is 74.50% which outperforms the RCC 
(63.54%) and segmentation-based approach (41.41%) significantly. 
 
Keywords: saliency map, background region detection, computational aesthetics, composing 
text-overlaid images  
 
 
 4 
顯著圖最後被正規化到 0 和 1 之間的一個範圍，有較高顯著值的像素代表吸引更多的視覺
注意，文字應適當地被定位並放置在非顯著區域與最小的顯著度值的位置，以避免可能蓋
到一個圖像的主要物件。但是其方法所產生的顯著圖，往往在物件上產生中空及邊界失真
現象，如圖 2，本計畫則採用了最近被證明效能良好的 Cheng 等人(2011)所發展的計算
Saliency Map 的方法來改善這些缺失。 
 
圖 2. Itti’s Saliency Map: 物件上產生中空的現象及物件邊界擴大而模糊 
原圖 顯著圖 
  
 
區域性對比顯著圖切割- REGION BASED CONTRAST SALIENCY MAP CUT (RCC) 
人類往往會更加關注在那些與周圍環境對比強烈圖像區域(Eihhauser & Konig 2003)，但是除
了對比，圖像中空間關係在引起人類的注意力方面也扮演一個重要角色。證據顯示通常一
個區域的顯著性是相較於離較遠的區域，在其周邊區域影響是更強的，雖然兩者的對比度
相同。Cheng等人(2011) 提出了直方圖對比方法(histogram-based contrast method) (HC)去量
測顯著性，HC 圖基於像素顯著值的方式，簡單地從所有其他圖像上的像素，做像素顏色分
離，產生與原圖相同大小的顯著圖。接著加上空間關係去改良 HC 圖，首先區塊化圖像，
然後指定每一個區塊的顯著值，這個區塊顯著值是從整體對比分數計算出來的，計算區塊
與圖像上其他區塊的對比值和空間距離，產生區域對比 (region-based contrast) (RC) 圖。 
 
Cheng (2011) 首先分割圖像成區塊圖，藉由圖像中的色彩統計，他提出 histogram-based 
contrast (HC)去定義圖像上像素的顯著值，然後對於每個區塊建立顏色直方圖成為 HC 圖，
在整張圖像中，對於區塊 kr ，量測與所有其他區塊顏色對比值來計算出它的顯著值。  



ik rr
ikrik rrDrwrS ),()()(                                  (1) 
在此， )( irw 為區塊 ir 的權重值， )(,rD 為在兩個區塊間的顏色距離陣列。使用 ir 區塊中像數
總數當作 )( irw 值，用來強調兩個較大區塊間的顏色對比。在兩個區塊 1r 和 2r 的顏色距離值
是定義成： 
 6 
圖4. 接近圖像邊緣會產生侵蝕 
  
 
 
圖5. 只針測到單一明顯物件 
  
 
 
圖6. (a) 擴大子圖的邊界。(b) 產生RCC二值圖。 
 
(a) 
 
(b) 
 
整個 MRCC 處理流程如下，首先，我們由原始圖片產生 RC 圖(圖 7(b))，根據 RC 圖灰階
的分佈特性，採用動態閥值的 Otsu 方法，粗略地產生可能會有明顯物件的區塊(圖 7(c))，
此時的 Otsu 圖產生的物件外觀形狀並不能很準確顯示出來，而且其可能出現物件的位置會
有些誤判，如圖 7(c)的左邊零星白點部分。為了進一步提高明顯物件可能真正出現區域，
我們加入了區塊化圖(圖 7(d))作為輔助判斷並加入下列規則： 
1. 同一顏色區塊面積總和最大者，此一區域應為圖片背景區域，不會出現物件，如圖 7(d)
中墨綠色區域即是。 
2. 同一顏色區塊如佔據圖片邊緣長度(上下左右)50%以上者，此一區塊此一區域應為圖片
背景區域，如圖 7(d)中土黃色區域即是。 
 8 
圖8. 含有多個物件的MRCC圖處理流程 
 
 
 
 
圖9.是MRCC與RCC比較的幾個例圖，由此可見，MRCC在有關多物件及位於圖片邊緣的物
件外形都遠比RCC來的正確。 
 
 
 10 
三：實驗結果與討論 
為了比較我們的MRCC 與 RCC 及 Lai 等人(2010)的圖像區塊化技術(SEG)的效能，我們設
計了兩個實驗，分別來比較這些方法的效能。 
 
實驗一：1000張單一物件複雜背景圖 
圖像來源 : Achanta (2009)引用了由 Liu 等人的公開可用的圖像資料庫，創建一個準確的物
件輪廓的 ground truth 的 1000 圖像資料庫。此 1000 張的圖像也大多數只含有單一的物件。 
 
評估 
我們的MRCC 為改良 RCC 只能偵測圖片中單一物件及強化物件邊緣形狀的能力，在此實
驗中，由於此 1000張的圖片偏向於只有單一物件居多，所以，在此實驗中目的為比較 MRCC
在單一物件的測試圖時與 RCC 會增加多少誤判比例。另外，再和之前，Lai 所使用的區塊
化技術 (SEG)比較能否改善許多？我們引用 Cheng (2011) 的評估方式，分別在實驗中進行
平均精確率、召回率及來做比較。而 F-Measure 定義如下： 
callecision
callecision
F
RePr
RePr)1(
2
2





                           (4) 
使用和 Achanta 有相同 β2 = 0.3去加重精確率的權重。 
實驗結果，RCC 方法 (平均精確率= 90.05%, 平均召回率= 90.63%及平均 F-Measure= 
88.84%)，MRCC 方法 (平均精確率= 84.64%, 平均召回率= 94.89%及平均 F-Measure= 
85.55%)，SEG 方法  (平均精確率= 52.78%, 平均召回率= 91.33%及平均 F-Measure= 
56.95%)，如圖 10所示。 
 
圖10. 1000 張圖像資料庫的平均精確率、平均召回率及平均F-measure. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Precision 0.900490685 0.846439077 0.527807768
Recall 0.906257627 0.948857209 0.913336671
F-measure 0.888362242 0.855517897 0.569499098
RCC MRCC SEG
 
 12 
標註的一致性 
我們找了七位人員，1000 張圖像平均分給他們，根據每人自己的觀點做人工的不得放字的
非背景區域“ground truth”標註，標註過程是各自進行的，不在同一時間。之後，對每張圖
不得放字的非背景區域“ground truth” 標註範圍進行投票，如果認為不得放字的非背景區域
“ground truth”標註是正確的就投他一票， 如果，這七位人員對任何一張圖不得放字的非背
景區域“ground truth” 標註範圍認定有問題，我們就放棄此圖，不再納入我們的圖庫當中。
最後，我們選取 500 張圖作為實驗二所使用的圖片，並且也將對每張圖不得放字的非背景
區域“ground truth” 標註範圍產生二值圖，如圖 11所示。 
 
評估 
實驗結果，RCC 方法 (平均精確率= 80.34%,平均召回率= 49.18% 及平均 F-Measure= 
63.54%)，MRCC 方法 (平均精確率= 79.51%,平均召回率= 73.61%及平均 F-Measure= 
74.50%)，SEG 方法  (平均精確率= 38.10%,平均召回率= 81.17% 及平均 F-Measure= 
41.41%)，如圖 12所示。 
 
圖12. 500 張圖像資料庫的平均精確率、平均召回率及平均F-measure 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Precision 0.803413781 0.795111218 0.380958976
Recall 0.491829319 0.736078097 0.811733687
F-measure 0.635380788 0.745016781 0.414119553
RCC MRCC SEG
 
 
四：結論 
我們所提出的 MRCC 方法，在實驗一的單一複雜背景物件圖庫中，平均 F-Measure = 
85.55% ，略低於 RCC方法平均 F-Measure = 88.84% ，MRCC 的平均精確率 = 84.64% 略
低於 RCC 方法平均精確率= 90.05%，MRCC 的平均召回率= 94.89% 反高於 RCC 方法平均
召回率= 90.63%，這是因為 MRCC 是設計於偵測多個物件的情形，在只含有單一複雜背景
 14 
6. Itti, L., Koch, C., Niebur, E., 1998. A model of saliency-based visual attention for rapid 
scene analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence 20(11), 
1254–1259. 
7. Lai, C.Y., Chen, P.H., Shih, S.W., Liu, Y., Hong, J.S., 2010. Computational models and 
experimental investigations of effects of balance and symmetry on the aesthetics of 
text-overlaid images. International Journal of Human-Computer Studies 68(1-2), 41–56. 
8. Lai, C.Y., Chen, Y.R., Liu, J.C., Hong, J.S., 2009. Using image saliency map for computing 
visual balance of text-overlaid images. In: Proceedings of the 17th World Congress on 
Ergonomics (IEA), Beijing, China, 9–14 August 2009. 
9. Cheng, Ming-ming., Zhang, Guo-Xin., Niloy, J.Mitra, “Global Contrast based Salient 
Region Detection,”   IEEE CVPR, p. 409-416, ColoradoSprings, USA, June 21-23, 2011. 
10. Tie Liu, Jian Sun, Nan-Ning Zheng, Xiaoou Tang and Heung-Yeung Shum. Learning to 
Detect a Salient Object. In Proc. IEEE Cont. on Computer Vision and pattern Recognition 
(CVPR), Minneapolis, Minnesota, 2007. 
11. Horprasert T., D. Harwood, and L.S. Davies, “A robust background subtraction and shadow 
detection,” in Asian Conference on Computer Vision (ACCV’2000), Taipei, Taiwan, January 
8-11 2000 
12. Y.-L. Hou, S. Member, G. K. H. Pang, and S. Member, “People counting and human 
detection in a challenging situation,” IEEE Transactions on Systems Man and Cybernetics 
Part A: Systems and Humans, vol. 41, no. 1, pp. 24–33, 2011. 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/16
國科會補助計畫
計畫名稱: 以影像顯著圖計算圖文合成的圖像美感
計畫主持人: 洪政欣
計畫編號: 100-2221-E-260-035- 學門領域: WEB 技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
