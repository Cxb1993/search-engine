with stringent memory and limited response time 
becomes a very difficult problem. The time-sensitive 
sliding window model handles the data stream during a 
user-defined time interval and is more practical. Most 
time-sensitive sliding window algorithms assume that 
the memory is always available and enough for holding 
the entire transaction data in a window. Nevertheless, 
these algorithms would fail if bulk data comes in a 
short burst for the latest sliding window. 
  In this project, we have devised an algorithm, 
called Tisbom, to solve the problem of mining frequent 
patterns in time-sensitive stream data using a bounded 
memory. The Tisbom algorithm uses a condensed 
representation for each block for efficient window 
sliding. A block allocation mechanism is invoked to 
re-adjust the block sizes in the window when the 
memory is insufficient for the new incoming block. The 
experiment results using both synthetic and real 
datasets show that Tisbom is efficient and has good 
precisions and recalls for mining time-sensitive 
stream using a bounded memory. 
 
 
II
一、 中文摘要
資料串流，不論是線上或離線的資料串流，其特性是快速、大量、隨時間改變、無法
預測且持續不斷產生。依據資料的處理模式，可以分成標界模式、時間衰減模式、與滑動
窗模式。資料串流的探勘因為其資料並不固定，因此比傳統探勘難，必須設計單次掃瞄無
限制資料串流的有效率探勘方法。探勘如何改善現有方法的效率與呈現更精確的近似結果
是近年來熱門的研究議題。
由於資料串流並無法保留全部的歷史資料，資料多數也僅能掃瞄一次。因此，如何在
有限的記憶體、單次的掃瞄、甚至有限的運算時間限制下得到所求相當困難。交易感知的
滑動視窗探勘的對象是最近的固定交易時間內的頻繁項目集，因此比較實用。大部份對時
間感知的滑動視窗演算法都假設記憶體可以儲存滑動視窗內所有交易。然而在真實情況
中，資料串流是有可能突然來很多筆的交易超過記憶體所能存放的數量，那麼這些演算法
將會發生錯誤。
本計畫的研究，提出一個演算法 Tisbom，使用固定的記憶體空間，在資料串流中對
時間感知的滑動視窗挖掘出頻繁項目集。Tisbom 對每個資料區塊都使用一個資料結構來
儲存交易，因此可以有效率的滑動視窗。除此之外，當記憶體不足以存放所有資料區塊時，
Tisbom 根據所提出的記憶體分配公式來分配資料區塊的記憶體空間。使用合成資料及實
際資料實驗的結果證實，在使用固定的記憶體條件下，Tisbom 是一個保有良好的查全率
和準確率、有效率的滑動窗模式資料串流頻繁樣式勘測演算法。
關鍵詞: 資料串流、串流探勘、頻繁樣式、時間感知滑動窗、互動式探勘
IV
目錄
一、 中文摘要……………………………………………………………………II
二、 英文摘要…………………………………………………………………..III
三、 報告內容…………………………………………………………………..1
I. 前言……………………………………………………………………….1
II. 研究目的 ……………………………………………………………….2
III. 文獻探討…………………………………………………………………2
IV. 研究方法………………………………………………………………….3
V. 結果與討論………………………………………………………………6
四、 參考文獻……………………………………………………………………10
五、 計畫成果自評………………………………………………………………13
2in the window. These patterns are maintained and then updated against subsequent blocks of transactions.
Nevertheless, the minimum support setting should be variable, especially for data stream applications.
Different distributions of data may make previous support threshold no longer suitable for the mining of
current window of transactions. Moreover, the user may specify various support thresholds to evaluate
patterns in current window. Thus, algorithms for mining frequent itemsets in a time-sensitive siding window
stream should be able to accept new support thresholds.
II. 研究目的
To our knowledge, no algorithms have been proposed to solve the above issues in the time-sensitive
sliding window stream. Therefore, we propose an algorithm, called Tisbom (TIme sensitive Sliding window
mining using BOunded Memory), to solve both the transaction surge and the variable support issues under
bounded memory constraints. The Tisbom algorithm compactly represents the transactions in a block by using
a grouped synopsis vector. When the pre-determined and bounded memory space for holding all the blocks in
a window is insufficient, the Tisbom algorithm performs transaction approximations and size adjustments to
reduce the total size of the in-memory blocks. The transaction approximation in each block is flexibly
controlled by an approximate-difference threshold in each grouped synopsis vector. The size adjustments
ensure that the available memory is allocated in proportion to the size of a block so that information loss can
be minimized. The mining module in the Tisbom algorithm adapts the FP-growth* algorithm [16] and
performs the mining, with respect to any minimum support, from the grouped synopsis vectors in the window.
Comprehensive experiments using synthetic and real datasets show that the Tisbom algorithm is both effective
in transaction approximation and efficient in the mining. Moreover, the Tisbom algorithm has high precisions
and high recalls when the window slides, after conducting transaction approximations and size adjustments.
III. 文獻探討
C. Giannella et al. propose a method FP-stream. This method is mining frequent itemset over data stream.
An FP-stream structure is composed by two parts, frequent pattern tree and tilted-time window table. Frequent
pattern tree is used to maintain the frequent itemset by using the tree structure to reduce the memory cost.
Tilted-time window table is to record the support of frequent itemset with multiple time granularities.
C.-H. Lin et al. proposed a method for stream itemset mining using the time-sensitive sliding window.
They use the PFP structure to store the potential frequent itemsets. The algorithm supplies two outputs: no
false dismissal and no false alarm. The Discounting Table (DT) is maintained to contain the information of
potential frequent itemsets in the time sensitive siding window in order to deal with the oldest block deletion.
Two method, naïve adjustment and selective adjustment, are presented to merge the information in DT table.
H.-F. Li et al. propose MFI-TransSW and MFI-TimeSW two methods for mining frequent itemset over
data stream using the sliding window. The first algorithm is running on the transaction-sensitive sliding
window and the second is the time-sensitive sliding widow. They use the bit-sequence to represent the state of
items in the sliding window. When the frequent itemsets are required, the algorithm will use the bitwise
operator “and” to get the support of itemset with the Apriori property.
C.-Y. Wang proposes the GruFI algorithm to mining frequent itemset over data stream using the
landmark model. They use the group synopsis vector (GSYV) structure to maintain all the transactions in data
stream and a PFI-tree structure to store the potential frequent itemsets. The transaction entry in the GSYV is
4Although |Bi| is reduced from 8 to 6, it might be desirable to further reduce its size. For this purpose,
Tisbom uses delegates to approximate the itemsets in GSYVi. The resulting GSYVi could be smaller due to
transaction approximation. A delegate dg is said to approximate to an itemset e if the number of different
items (named approximate-difference) between dg and e is no more than certain difference threshold
(abbreviated as dh), i.e. diff(dg, e) dh. The approximate-difference is |dg \ e|+|e \ dg| where ‘\’denotes the
‘set-difference’operator. The approximation is performed by considering itemsets from group tables of longer
length down to that of smaller length. For example in Fig. 1, the starting entry for next approximation (3, 0)
and delegate (4, 0) indicates that the next approximation should start with the beginning entry (0) of G(3) and
the delegate is entry(0) of G(4). When the size after an approximation against all the itemsets in current
GSYVi is still too large, we increase the difference threshold dh by one and repeat the approximation. The
process is repeated until the desirable size is reached. The initial dh for an original (not approximated) GSYVi
is zero.
IV.2 Block Allocations in the Initial Sliding Window
The mining of the very first window cannot start until w blocks of transactions are received. Upon
receiving a block Bi, the Tisbom algorithm processes the transactions in Bi and constructs the GSYVi with dh
= 0. Thus, after receiving p blocks, the initial window will have p group synopsis vectors (GSYV) and the
in-memory sizes are |B1r|, |B2r|, …, and |Bpr|, respectively. The in-memory size of the initial window W1 up to
block Bp would be |W1m| = (|B1r|+|B2r|+…+|Bpr|). If |W1m| Mc after collecting w blocks, the mining of the
first window can be performed. If unfortunately |W1m| > Mc before w blocks are collected, we need to reduce
|W1m| until it is smaller than or equal to Mc to begin the mining. Suppose that B1, B2, …, Bp-1 are collected and
the addition of the incoming block Bp leads to the insufficiency of memory, i.e. |W1m|Mc and that p w.
The initial idea of the Tisbom algorithm is to fairly allocate new sizes for all these blocks. The new size |Bjm|
for block Bj is calculated with the formula: |Bjm| = Mc * |Bj| / (|B1|+|B2|+…+|Bp|), 1jp.
However, the new size |Bjm| for some block Bj can be too large for the in-memory grouped vectors. For
example, the |Bjr| for block Bj can be smaller than the calculated |Bjm| when Bj contains many identical
transactions and the |Bjr| entries are sufficient to represent all the transactions in Bj. Consequently, some
blocks will be over-allocated. To best utilize the bounded memory, we reclaim the un-used space from the
over-allocated block and re-calculate the new sizes for the rest of the blocks. Our implementation calculates
the new size and re-assigns the unused space by considering block Bp down to block B1. Therefore, we first
determine the objective size for Bp (denoted by |Bpo|), which is the minimum between |Bpr| and |Bpm| = Mc *
|Bp|/(|B1|+|B2|+…+|Bp|). Next, the objective size for Bp-1 (denoted by |Bp-1o|) is determined as the minimum
between |Bp-1r| and |Bp-1m| = (Mc-|Bpo|) * |Bp-1|/ (|B1|+|B2|+…+|Bp-1|). Then, the objective size for Bp-2 (denoted
by |Bp-2o|) is determined as the minimum between |Bp-2r| and |Bp-2m| = (Mc-|Bpo|-|Bp-1o|) * |Bp-2|/
(|B1|+|B2|+…+|Bp-2|). The objective sizes for blocks Bp-2 down to B1 are determined in the same way as well.
Note that when, at last, the objective size of B1 is bigger than |B1r|, the over-allocated size is re-assigned to the
latest block Bp in order to maximize the memory utilization.
After the objective size of each block is determined, the Tisbom algorithm then performs the transaction
approximation, as described in Section IV.1, with respect to each block until the number of entries used by the
block is no more than its objective size. Therefore, individual blocks might stop at different approximation
points, i.e. the starting entries for next approximation and delegate for each block can be different. As long as
W1 contains fewer than w blocks, the construction of GSYVi, and the allocations of objective sizes and
6i l+w-1. The mining module in Tisbom adapts the FP-growth* algorithm [16] by adding the ability to
accept cardinalities of transactions. In fact, any existing algorithms for mining frequent itemsets in traditional
databases, such as the Apriori algorithm, can be adapted for the same purpose. After reading all the (itemset,
cardinality) pairs in all the GSYVs, all the frequent itemsets can be efficiently found. In addition, the user may
optionally specify any block combinations in the window to be used for the mining. Thus, the Tisbom
algorithm can be flexibly used to discover the changes of patterns in the latest window.
V. 結果與討論
We have conducted experiments to assess the performance of the proposed Tisbom algorithm. All the
experiments were performed on an Intel Q8400 2.66GHz PC with 2 GB memory running Windows 7. The
datasets were generated by the IBM synthetic dataset generation program [1]. Dataset TIDmeans that the
dataset was generated with |T|=, |I|=, |D|=. That is, the average size of transactions was, the average size
of the maximal potentially frequent itemsets was, and the total number of transactions was. Default values
were used for the other parameters [1]. Comprehensive datasets simulating various distributions of data
streams were used in the experiments.
A dataset was partitioned into blocks and blocks were sent to the Tisbom algorithm one-by-one to
simulate the blocks in a time-sensitive sliding window stream. In a time-sensitive sliding window stream, the
performance of mining algorithms is not related to the total number of blocks in the data stream but related to
the total number of transactions in a window. Thus, all the experiments were presented with the results of
15-block streams. Various arrival rates of the data in a data stream were simulated by varying the sizes of
blocks.
The performance of the Tisbom algorithm is assessed by precision, recall, and the total execution time of
each window. Assume the results comprise a set T of frequent patterns mined from exact stream data without
any approximations, and a set O of frequent patterns discovered by the Tisbom algorithm. Precision is defined
as |T∩O|/|O|, the number of truly frequent patterns divided by the number of frequent patterns discovered by
the Tisbom algorithm. Recall is defined as |T∩O|/|T|, the number of truly frequent patterns divided by the total
number of frequent patterns. The total execution time is broken down into the transaction approximation time
and the mining time to further investigate the effects of transaction approximations.
Fig. 3. shows the results of varying Mc, the bounded memory size, with respect to dataset T10I4D150k
of constant data-rate |B| = 10000, w = 4, , and ms = 0.1%. The Tisbom algorithm approximated the 40000
transactions (in each window) with three sizes of Mc, 20000, 28000, and 36000, respectively. Fewer
transactions would require approximations for a bigger size of memory so that the precision of Mc = 36000 is
the highest while that of Mc = 20000 is the lowest, as shown in Fig. 3(a). All the recalls are more than 60%, as
shown in Fig. 3(b). Fig. 3(b), which also shows that a bigger Mc has a higher recall.
Fig. 3(c) indicates that the total execution time of a smaller memory is longer than that of the larger one.
More approximations have to be performed with respect to a smaller Mc to accommodate all the transactions
so that the total execution time is longer. Fig. 3(d)(e) is the breakdown of the execution time. As shown in Fig.
3(d), the first approximation occurred at block 4 for Mc = 36000 since the memory is sufficient for blocks 1, 2
and 3. The first approximation for Mc = 20000 and Mc = 28000 occurred at block 3. The memory supplied
with Mc = 20000 is smaller than that with Mc = 28000 so that the approximation time of the former is larger
than that of the latter at block 3. At block 4, the approximation time of Mc = 20000 is smaller than that of Mc
8still has good performance even when we supplied a 42000 Mc for mining the block of 10000*10=100000, as
shown in Fig. 5(a). Fig. 5(b) shows that the recall smoothly decreases as the sliding window size increases.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Av
g.
pr
ec
isi
on
Minimum support ms (%)
T10.I4.D150k, w=4, |B|=10000, Mc=28000
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Av
g.
Re
ca
ll
Minimum support ms (%)
T10.I4.D150k, w=4, |B|=10000, Mc=28000
(a) average precision (b) average recall
18.8
19
19.2
19.4
19.6
19.8
20
20.2
20.4
20.6
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Av
g.
to
ta
le
xe
cu
tio
n
tim
e
(s
ec
.)
Minimum support ms (%)
T10.I4.D150k, w=4, |B|=10000, Mc=28000
17
17.2
17.4
17.6
17.8
18
18.2
18.4
18.6
18.8
19
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Av
g.
ap
pr
ox
im
at
io
n
tim
e
(s
ec
.)
Minimum support ms (%)
T10.I4.D150k, w=4, |B|=10000, Mc=28000
(c) average total execution time (d) average approximation time
Fig. 4. The effect of varying the minimum support.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
3 4 5 6 7 8 9 10
Av
g.
pr
ec
isi
on
Sliding window size
T10.I4.D150k, |B|=10000, Mc=42000, ms=0.1%
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
3 4 5 6 7 8 9 10
Av
g.
re
ca
ll
Sliding widow size
T10.I4.D150k, |B|=10000, Mc=42000, ms=0.1%
(a) average precision (b) average recall
0
5
10
15
20
25
30
35
3 4 5 6 7 8 9 10
Av
g.
to
ta
le
xe
cu
tio
n
tim
e
(s
ec
.)
Sliding window size
T10.I4.D150k, |B|=10000, Mc=42000, ms=0.1%
0
5
10
15
20
25
30
3 4 5 6 7 8 9 10
Av
g.
ap
pr
ox
im
at
io
n
tim
e
(s
ec
.)
Sliding window size
T10.I4.D150k, |B|=10000, Mc=42000, ms=0.1%
(c) average total execution time (d) average approximation time
Fig. 5. The effect of varying the sliding window size.
10
the total execution time and the processing time, no more than 3.5 seconds, is fast. We break down the
execution time and show the approximation time in Fig. 7(d). Again, the maximum approximation time
occurred at the coming of B7.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6 7 8 9 10 11 12
Pr
ec
is
io
n
Block number
BMS-WebView-1, w=4, Mc=9000
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6 7 8 9 10 11 12
Re
ca
ll
Block number
BMS-WebView-1, w=4, Mc=9000
(a) precision (b) recall
0
0.5
1
1.5
2
2.5
3
3.5
1 2 3 4 5 6 7 8 9 10 11 12
To
ta
le
xe
cu
tio
n
tim
e
(s
ec
.)
Block number
BMS-WebView-1, w=4, Mc=9000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
1 2 3 4 5 6 7 8 9 10 11 12
Ap
pr
ox
im
at
io
n
tim
e
(s
ec
.)
Block number
BMS-WebView-1, w=4, Mc=9000
(c) total execution time (d) approximation time
Fig. 7. The effect of mining on BMS-WebView-1.
四、參考文獻
(I) 計畫相關之著作
1. Sue-Chen Hsueh, Jing-Yan Lin, Ming-Yen Lin, "Secure Cloud Storage for Convenient Data
Archive of Smart Phones," Proceedings of the 15th IEEE International Symposium on
Consumer Electronics, 2011-06, Singapore. (EI)
2. Ming-Yen Lin, Sue-Chen Hsueh, and Hung-Chih Yao, "Efficient Mining of Sequential Patterns in
Time-Sensitive Data Streams," Proceedings of the 2011 European Conference on Data Mining,
pp. 127-134, 2011-07, Rome, Italy. (Acceptance rate: 16%)
3. Ming-Yen Lin, Sue-Chen Hsueh, and Hung-Chih Yao, "Equivalent Range Queries in Reverse
Skyline Computations," Proceedings of the 2011 European Conference on Data Mining, pp.
111-118, 2011-07, Rome, Italy. (Acceptance rate: 16%)
4. 董燕文、林明言、許芳榮，"人類基因中外顯子跳躍事件的頻繁內隱子片段與循序樣式探勘
", National Computer Symposium (accepted)，2011-12，嘉義、台灣.
5. Ming-Yen Lin, Tzer-Fu Tu, and Sue-Chen Hsueh, "High Utility Pattern Mining using the
Maximal Itemset Property and Lexicographic Tree Structures," Submitted to Information
Sciences (Paper no.: INS-D-11-649). [under 1st revision] (SCI)
6. Ming-Yen Lin, Sue-Chen Hsueh, and Chih-Chen Chan, " Discovery and Maintenance of
12
Frequent-Patern Discovery in Dynamic Data Streams,” In Proceedings of the 2010 International
Conference on Machine Learning and Cybernetics, pp. 2466-2471, July 2010.
[10] N. Jiang, L. Gruenwald, “Research Issues in Data Stream Association Rule Mining,” ACM
SIGMOD Record, Vol. 35, No. 1, pp. 14-19, March 2006.
[11] H.-F. Li, S.-Y. Lee, “Mining Frequent Itemsets over Data StreamsUsing Efficient Window
Sliding Techniques,” Expert Systems with Applications, Vol. 36, No. 1, pp. 1466-1477, January
2009.
[12] H.F. Li, S.Y. Lee, M.K. Shan, “An Eficient Algorithm for Mining Frequent Itemsets over the 
Entire History of Data Streams,”In Proceedings of Workshop on Knowledge Discovery in Data
Streams, pp. 20-24, 2004.
[13] C.-H. Lin, D.-Y. Chiu, Y.-H. Wu, A.L.P. Chen, “Mining Frequent Itemsets from Data Streams 
with a Time-Sensitive Sliding Window,” In Proceedings of the SIAM Intentional Conference on
Data Mining, pp. 68-79, 2005.
[14] M.Y. Lin, S.C. Hsueh, S.K. Hwang, “Variable Support Mining of Frequent Itemsets over Data 
Streams Using Synopsis Vectors,” In Proceedings of the 10th Pacific-Asia Conference on
Advances in Knowledge Discovery and Data Mining, pp. 724-728, April 2006.
[15] G.S. Manku, R. Motwani, “Approximate Frequency Counts over Data Streams,” In Proceedings
of the 28th International Conference on Very Large Databases, pp. 346-357, August 2002.
[16] E. Ozkural, C. Aykanat, “ASpace Optimization for FP-Growth,” In Proceedings of the IEEE
ICDM Workshop on Frequent Itemset Mining Implementations, November 2004.
[17] S. K. Tanbeer, C.F. Ahmed, B.-S. Jeong, Y.-K. Lee, “Sliding Window-Based Frequent Pattern
Mining over Data Streams,” Information Sciences, Vol. 179, No. 22, pp. 3843-3865, November
2009.
[18] P.S.M. Tsai, “Mining Frequent Itemsets in Data Streams Using the Weighted Sliding Window 
Model,” Expert Systems with Applications, Vol. 36, No. 9, pp. 11617-11625, November 2009.
[19] C.-Y. Wang, Enhanced Variable Support Mining for Frequent Itemsets over Data Streams,
Master Thesis, Department of Information Engineering and Computer Science, Feng Chia
University, 2007.
[20] Z. Zheng, R. Kohavi, L. Mason, “Real World Performance of Association Rule Algorithms,” In
Proceedings of the 7th ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, pp. 401-406, August 2001.
 
 
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　第 1758 次　討論　 2058　 99/06/30　 (第 1758 次通過)
 
 
            99年度 【 可變更探勘條件之滑動窗模式資料串流頻繁樣式勘測 】經費核定清單
 
　　　　　　執行機構：逢甲大學　　　　　　　　　　　　主　持　人：林明言　　　副教授(資訊工程學系（所）)
　　　　　　　　　　　朝陽科技大學　　　　　　　　　　共同主持人：薛夙珍　　　助理教授(資訊管理系（所）)
　　　　　　┌──────┬──────┬──────┬──────────────────────────────┐
　　　　　　│　補助項目　│　申請金額　│　核定金額　│　　　　　　　　　 說　　　　　　　　　明　　　　　　　　　 │
　　　　　　├──────┼──────┼──────┼──────────────────────────────┤
　　　　　　│業務費　　　│　　 494,000│　　 436,000│一、研究人力費：336,000元　　　　　　　　　　　　　　　　　 │
　　　　　　│　　　　　　│　　　　　　│　　　　　　│　1. 碩士班研究生研究助學金1名72,000元　　　　　　　　　　　│
　　　　　　│　　　　　　│　　　　　　│　　　　　　│　2. 碩士班研究生研究助學金2名144,000元　　　　　　　　　　 │
　　　　　　│　　　　　　│　　　　　　│　　　　　　│　3. 本會依規定主動增核研究主持費1名，月支10,000元(12.000月 │
　　　　　　│　　　　　　│　　　　　　│　　　　　　│　　 計)　　　　　　　　　　　　　　　　　　　　　　　　　　│
　　　　　　│　　　　　　│　　　　　　│　　　　　　│二、耗材、物品及雜項費用：100,000元　　　　　　　　　　　　 │
　　　　　　├──────┼──────┼──────┼──────────────────────────────┤
　　　　　　│研究設備費　│　　 175,000│　　　70,000│電腦及週邊設備等　　　　　　　　　　　　　　　　　　　　　　│
　　　　　　├──────┼──────┼──────┼──────────────────────────────┤
　　　　　　│國外差旅費　│　　 100,000│　　　70,000│一、出席國際會議差旅費：70,000元　　　　　　　　　　　　　　│
　　　　　　│　　　　　　│　　　　　　│　　　　　　│二、本項目不核列管理費　　　　　　　　　　　　　　　　　　　│
　　　　　　├──────┼──────┼──────┼──────────────────────────────┤
　　　　　　│管理費　　　│　　 100,350│　　　57,000│研究主持費不核列管理費　　　　　　　　　　　　　　　　　　　│
　　　　　　├──────┼──────┼──────┼──────────────────────────────┤
　　　　　　│合　　　　計│　　 869,350│　　 633,000│執行期限： 99/08/01 ～ 100/07/31　　　　　　　　　　　　　　│
　　　　　　│　　　　　　│　　　　　　│　　　　　　│計畫編號： NSC 99-2221-E-035 -075 -　　　　　　　　　　　　 │
　　　　　　└──────┴──────┴──────┴──────────────────────────────┘
　　　　　　研究類型：一般型研究計畫(個別型)　　　　　　　　　　　 學門名稱：資料庫系統及資料　流水號： 98WFD0600280
　　　　　　研究性質：應用研究　　　　　　　　　　　　　　　　　　　　　　　 工程　　　　　　　　承辦人： 李玓
　　　　　　應繳報告：精簡報告
　　　　　　研究成果歸屬：逢甲大學
　　　　　　各項費用之支用請依「行政院國家科學委員會補助專題研究計畫經費處理原則」規定辦理。
表 Y04 
三、攜回資料名稱及內容： 
(1) IADIS ECDM 2011 會議議程資料 
(2) IADIS ECDM 2011 Proceedings CD (會議論文收錄於 IEEE Xplore) 
(3) IADIS ECDM 2012 會議 call for papers 資料 
四、其他 
感謝國科會核准經費贊助，以及逢甲大學資訊電機學院的贊助，使本人能夠順利
前往義大利參與國際會議討論，並發表研究論文。 
 
 
Piet Kommers, University of Twente, The Netherlands
Pedro Isaías, Universidade Aberta (Portuguese Open University), Portugal
MCCSIS 2011 General Conference Co-Chairs
NOTE: This e-mail is being sent to all co-authors of this submission.
***********************
Please consider the following data for your final submission (using the link above):
Your Login is: linmy@fcu.edu.tw
Your password is: 9251
 
***********************
Paper Title: EFFICIENT MINING OF SEQUENTIAL PATTERNS IN TIME-SENSITIVE DATA
STREAMS  
Submission code: 87
Evaluation Results:
 Originality: 6 - Good
 Significance: 6 - Good
 Technical: 6 - Good
 Relevance: 6 - Good
 Classification: 6 - Good
 
 
 Comments: The paper presents a new algorithm for mining sequential patterns from data
streams. The idea sounds good and it tested with extensive experiments.
 
 Positive Points: The paper is well organised and the proposed technique is tested with various
parementer settings.
 
 Negative Points: Only synthetic data is used in testing. The authors are expected to test their
method with real-world data as well. There is no comparison with existing techniques
 Originality: 7 - Excellent
 Significance: 6 - Good
 Technical: 6 - Good
 Relevance: 6 - Good
 Classification: 6 - Good
2011/5/30 逢甲大學 GoMail 郵件 - ECDM 2011: p…
mail.google.com/a/mail.fcu.edu.tw/#inbox… 2/4
 Originality: 5 - Average
 Significance: 5 - Average
Technical: 5 - Average
 Relevance: 6 - Good
 Classification: 5 - Average
 Comments: The paper propose a new method for sequential pattern mining over sliding
window of data streams, which use bit vectors. Experiments are conducted, which show the
effectiveness of the method. Though the proposed method seems to be interesting, its space
and time complexity is not theoretically analyzed
 
 Positive Points: 1. A potentially interesting algorithm is proposed. 2. The paper is written clearly
 
Negative Points: 1. The proposed method is not analyzed theoretically.
-- 
IADIS Secretariat
------------------------------------
URL: http://www.iadis.org/ 
Visit our page and join us on Facebook:
http://www.facebook.com/IADIS
and on Twitter http://twitter.com/IADIS
2011/5/30 逢甲大學 GoMail 郵件 - ECDM 2011: p…
mail.google.com/a/mail.fcu.edu.tw/#inbox… 4/4
EFFICIENT MINING OF SEQUENTIAL PATTERNS 
IN TIME-SENSITIVE DATA STREAMS 
Ming-Yen Lin1, Sue-Chen Hsueh2 and Hung-Jr Yao1 
1Dept. of Information Engineering and Computer Science, Feng Chia University - 100, Wenhua Rd., Taichung 407, 
Taiwan (R.O.C.) 
2Dept. of Information Management, Chaoyang University of Technology - 168, Gifeng E. Rd., Taichung 413, Taiwan 
(R.O.C.) 
ABSTRACT 
Sequential pattern mining in data streams can present interesting and timely results. Data streams of time-sensitive sliding 
window models consider the most recent transactions so that analysis results are more practical. The analysis is very 
complicated because elements with the same customer identification have to be merged with respect to their temporal 
relationships. The number of transactions in each block is unpredictable; as a result, the main memory might not be able 
to hold all of the transactions in the window, considering the number of incoming transactions in the latest block. In this 
paper, we propose an algorithm, called BBSwin, for mining sequential patterns in a time-sensitive sliding window stream 
using bounded memory. The BBSwin algorithm effectively uses block bit-vectors for window sliding and mining and 
solves the surges in transactions with bit-vector compressions. Experiments show that the proposed BBSwin algorithm is 
efficient for mining sequential patterns in a data stream of the time-sensitive sliding window model.  
KEYWORDS 
Data stream, sequential patterns, time-sensitive sliding window, bounded memory. 
1. INTRODUCTION 
Sequential pattern mining, which discovers frequent subsequences in a database, has been an important 
research topic among data mining communities [1][2][3][10]. Studies of algorithms for mining sequential 
patterns in data streams [5][6][8][9][11] is even more challenging since the data are continuously generated 
in a high rate in these applications. Most mining models used on data streams have been of the following 
three types: the landmark model, the time-fading model, and the sliding window model [4][7]. The sliding 
window model considers only the last “window” of stream transactions for the mining. The “window” in the 
model may refer to a fixed number of transactions (called transaction-sensitive sliding window) or a fixed 
period of time (called time-sensitive sliding window).  
Recent researches usually focus on the mining in the sliding window model [8][11] since people have 
more interests in up-to-date patterns. Specifically, time-sensitive sliding window model is more practical 
since it is more natural to specifying a fixed time period than a fixed number of transactions. In a time-
sensitive sliding window model, the transactions in a basic time unit are collected as a block. A user specifies 
an interested time period as a window so that a window typically consists of several blocks. The window 
“slides” one block as one basic unit time passes. All the transactions of a customer are sorted, in increasing 
time order, into a customer-sequence so that a window contains many customer-sequences. The objective is 
to mine the sequential patterns from the customer-sequences in the latest window. 
Some algorithms have been proposed to solve the mining of sequential patterns in streams. The IncSPAM 
algorithm [8] extends the SPAM algorithm [1] to merge newly appended item candidates and previously 
sequential patterns into new candidates. This algorithm adopts a transaction-sensitive sliding window to 
sample the stream data. If the sequential patterns are not updated for a long time, the algorithm decays the 
support weights. The SSM algorithm [6] is for mining sequential patterns in click data streams. This 
algorithm scans a batch and uses the counts of the items in the batch to update a D-List structure, which is a 
hash indexed array all items’ cumulative support counts. Then, it constructs a PLWAP-tree of frequent 
IADIS European Conference Data Mining 2011
127
list. In addition, the total number of customer-sequences is not necessarily equal to the total number of 
transactions (|Bi|) in block Bi. 
A window W contains w blocks of customer transactions, and the window “slides” one block as one time 
unit passes. Thus, window W1 contains blocks B1 through Bw, window W2 contains blocks B2 through Bw +1, 
and so on. The w is referred to as the length of the window. All the transactions of the customer cid in 
window Wi are sorted by increasing order of timestamps into the customer’s sequence in the window, 
denoted by Wi.cid. In other words, a customer-sequence in a window (Wi.cid) is composed of the customer’s 
sequences from individual blocks (Bi through Bi+w-1) in the window, in timestamp order. Thus, the customer-
sequence (of a customer cid) in window Wi, denoted by Wi.cid, is <Bi.cid Bi+1.cid … Bi.cid>. When there is 
no ambiguity, the Wi.cid is written as <BiBi+1…Bi+w-1>, and Wi.cid may further be written as <BiBi+1…Bk-
1Bk+1…Bi+w-1> if certain Bk.cid is empty in Wi.cid. If the customer cid has no transactions in window Wi, the 
empty Wi.cid is removed from the window. The number of customer-sequences in window Wi is referred to 
as its size, denoted by |Wi|. The size of individual windows might be different because variable number of 
customers might have transactions in individual windows. Such a model of data stream is referred to as the 
time-sensitive sliding window model of customer-sequences. 
For example, given B1.1 = [(a,c)(b)], B1.2 = [(a,b,c)], B1.3 = [(b)], and B1.4 = [(a,c)] in Figure 1. |B1| = 5 
since there are 5 transactions in B1. B2.1 = [(d)] and B2.4 = [(a)(b,d)], so |B2| = 3. When w = 2, W1 contains 
blocks B1 and B2. W1.1 = <B1.1B2.1> = <[(a,c)(b)][(d)]>, W1.2 = <[(a,b,c)][]>, W1.3 = <[(b)][]>, and W1.4 = 
<[(a,c)][(a)(b,d)]>. The four customer-sequences can be simply written as W1.1 = <(a,c)(b)(d)>, W1.2 = 
<(a,b,c)>, W1.3 = <(b)>, and W1.4 = <(a,c)(a)(b,d)> without loss of generality.   
In the time-sensitive sliding window, the support count of a sequence s in Wi, denoted by count(s), is the 
number of customer-sequences containing s in Wi. The support of a sequence s in Wi, denoted by sup(s), is 
count(s)/|Wi|. Given a user specified minimum support threshold σ ∈ (0, 1], sequence s is a frequent sequence, 
or sequential pattern, if sup(s) ≥ σ. Particularly, the memory used to hold all the transactions in the latest 
window is bounded to a pre-determined fixed size Mb. Given Mb, the objective is to mine the sequential 
patterns for the latest window, with respect to any specified minimum support σ.  
To our knowledge, no algorithm has been proposed to solve the sequence mining problem in the 
addressed time-sensitive sliding window model. First, previous algorithms for sequential pattern mining in 
streams overlook the sequence-merging issue. Most of them [5][6][8][9][11] assume that the customer-
sequences are independent. That is, the customer-sequences in one mining are not related to any customer-
sequences in another mining, even when the cids of the customer-sequences are the same. Such an 
assumption is not realistic but it simplifies the sequence mining problem because the transactions of a 
customer need not to be merged into one customer-sequence. Second, some algorithms [5][6][9][11] mine 
sequential patterns with respect to a fixed threshold and maintain some structures for updating patterns 
against new blocks so that some customer-sequences can be discarded after mining. However, if the 
minimum support threshold needs to be changed due to certain new data-arrival rate, there is no way to 
discover the true patterns from the discarded customer-sequences. 
In this paper, we assume that the maximum number of customer-sequences in any window is |D| and we 
use the same amount of memory space, Mc, for storing each customer-sequence. Given a memory bound Mb, 
Mc = Mb/|D|. The Mc needs to be designed with the ability to “slides” the oldest Bj.cid out and “slides” the 
newest Bj.cid in. Thus, the Mc is further described as w*bs, i.e. w blocks and each block uses a equal space of 
size bs. Consequently, the addressed problem can be solved by the following two processes, window sliding 
and window mining. 
 
 Block B1 B2 B3 B4
Customer 1 3 4 2 1 4 5 2 5 3
Sequence (a, c)(b) (b) (a, c) (a, b, c) (d) (a)(b, d) (a, b)(c, d) (b, c, d)(c, d) (a)(a)(a)(c)(c, d) (a)
W1
W2
W3
 
Figure 1. Customer-sequences in a time-sensitive sliding window stream. 
IADIS European Conference Data Mining 2011
129
transaction surges by the technique in Section 3.3. With respect to item k of a customer-sequence in a 
window, the window sliding in the BBSwin algorithm simply “shifts” out bvk1 and “appends” bvkg. The shift-
and-append operation is applied to all the block bit-vectors of all the customers. The window sliding 
procedure then is efficiently finished. In addition, the used memory is still bounded to the same size after 
window sliding since the sizes of bvk1 and bvkg are equal. 
For example, given B1.4= [(a, c)], B2.4= [(a)(b, d)], and B3.4= [], the corresponding bit vectors of item a 
for cid = 4 in block 1 (bva1) is 1000, that in block 2 (bva2) is 1000, and bva3 is 0000. The process of window 
sliding with respect to item a for cid = 4 is as follows. Block bit-vector bva1 is shifted out and bva3 is 
appended as the window slides. Thus, the block bit-vectors of item a for cid = 4 is 10000000 in the window. 
The block bit-vectors of items b, c, and d for cid = 4 can be obtained in the same way. The block bit-vectors 
of all the customer-sequences in the window then are obtained by applying the above operations to all the bit-
vectors of items for all the customers. 
3.3 Handling Transaction Surge by Bit-vector Compression 
The user determines the bounded memory Mb as |D|*w*(N*z) bits before mining. The value of z is pre-
determined and set to the common number of transactions for a customer in a time unit. For example, if a 
customer generally has a maximum of 4 transactions in a time unit, z is set to 4. However, there might be a 
sudden increase in the number of transactions sometimes. With respect to the surge of transactions, more bits 
are required to represent these transactions. Let the number of transactions conducted by a customer in the 
latest time unit (the newest block) be y and y > z ≥ 2. We refer to the y bits as b[1], b[2], …, b[y] and the z 
bits as c[1], c[2], …, c[z]. The bit-vector compression mechanism is described as follows. 
The y bits need to be compressed into the z bits. We illustrate the compression of 3 bits into 2 bits first, 
and then extend the principle to general cases. There are 8 combinations from b[1..3]. The BBSwin algorithm 
assigns b[3] to c[2] so as to keep the latest bit (i.e. c[2]) up-to-date, and assigns c[1] to the agreed value from 
b[1] and b[2]. Consequently, the algorithm sets c[1] to ‘0’ when b[1..2]= ‘00’, and sets c[1] to ‘1’ when 
b[1..2]= ‘11’. When b[1] differs from b[2], the algorithm simply chooses b[1] as c[1]. Thus, c[1] = b[1] when 
b[1] disagrees with b[2]. We refer to such a compression as 3-2-rule.  
The compression of more than 3 bits into 2 bits follows the same principle of 3-2-rule. Thus, compressing 
m bits (m>3) can be realized as repeating the 3-2-rule continuously on the leading bits until the objective size 
of 2 bits is reached. We analyze such operations and have the following findings: c[1] = b[1] and c[2] = b[m]. 
Thus, compressing m bits into 2 bits takes a constant time, independent of the m value. 
When y > z ≥ 3, the BBSwin algorithm uses the 3-2-rule to compress the first m=(y-z+2) bits in b[*] into 
c[1..2], and assigns correspondingly the last z-2 bits in b[*] to the last (z-2) bits in c[*].The BBSwin algorithm 
uses this mechanism to keep as many latest bits as possible, emphasizing the preservation of up-to-date 
transactions.  
For example, given a bit-vector 1100011010 (10-bit long) to be compressed into a 4-bit vector, y = 10, 
and z = 4. Thus, m = 8 so c[4] = b[10] = ‘0’, c[3] = b[9] = ‘1’, and c[1..2] = ‘10’ from b[1..8]= ‘11000110’ so 
that c[*]=‘1010’. An example of bit-vector compressions is presented in Table 1.  
Table 1. An example of bit-vector compressions 
Original y z m Compressed
1100011010 10 4 8 1010
100110110 9 5 6 10110
11100010 8 3 7 110
11100010 8 2 8 10
 
0
4000
8000
12000
16000
20000
24000
1 2 3 4 5 6 7 8 9 10
Nu
m
be
r o
f t
ra
ns
ac
tio
ns
Block number
 
Figure 3. A stream of variable sized blocks. 
IADIS European Conference Data Mining 2011
131
00.04
0.08
0.12
0.16
0.2
1 2 3 4 5 6 7 8 9 10
C
o
m
p
re
ss
io
n
ti
m
e
 (
se
c.
)
Block number
D3C60T2.5S4I1.25, w: 2, z: 5, σ: 1%
0
5
10
15
20
25
1 2 3 4 5 6 7 8 9 10
M
in
in
ig
   
ti
m
e
 (
se
c.
)
Block number
D3C60T2.5S4I1.25, w: 2, z: 5, σ: 1%
0
5
10
15
20
25
1 2 3 4 5 6 7 8 9 10
To
ta
l e
xe
cu
ti
o
n
  
 t
im
e
(s
e
c.
)
Block number
D3C60T2.5S4I1.25, w: 2, z: 5, σ: 1%
0
0.2
0.4
0.6
0.8
1
1 2 3 4 5 6 7 8 9 10
R
e
ca
ll
Block number
D3C60T2.5S4I1.25, w: 2, z: 5,  σ: 1%
 
(a)                                        (b)                                      (c)                                      (d) 
Figure 4. Result of mining variable sized blocks: (a) compression time (b) mining time (c) total execution time (d) recall 
Next, the effects of varying the minimum supports were evaluated. The minimum supports were 
increased from 1% up to 2%. The other parameters were fixed. Figure 5(a) shows that the average 
compression time is nearly constant because the time is independent of minimum supports, given a fixed 
window size. Figure 5(b) shows that the average mining time is shorter for a larger support. As a result, 
Figure 5(c) depicts a decreasing trend for the increased supports. The average recall is increased, as presented 
in Figure 5(d), since the number of true patterns is decreased. 
0
0.2
0.4
0.6
0.8
1
1 11 12 13 14 15 16 17 18 19 2A
v
g
.  
co
m
p
re
ss
io
n
  t
im
e
 (
se
c.
)
Minimum support (%)
D3C60T2.5S4I1.25, w: 2, z: 5
2
4
6
8
10
12
1 11 12 13 14 15 16 17 18 19 2
A
v
g
.  
m
in
in
g
  t
im
e
 (
se
c.
)
Minimum support (%)
D3C60T2.5S4I1.25, w: 2, z: 5
2
4
6
8
10
12
1 11 12 13 14 15 16 17 18 19 2A
vg
.  
to
ta
l 
e
xe
c
u
ti
o
n
  
ti
m
e
(s
e
c
.)
Minimum support (%)
D3C60T2.5S4I1.25, w: 2, z: 5
0.68
0.72
0.76
0.8
0.84
0.88
1 11 12 13 14 15 16 17 18 19 2
A
v
g
.  
re
ca
ll
Minimum support (%)
D3C60T2.5S4I1.25, w: 2, z: 5
 
(a)                                        (b)                                      (c)                                      (d) 
Figure 5. The effect of varying the minimum support: (a) average compression time (b) average mining time (c) average 
total execution time (d) average recall. 
The performance with respect to the number of bits for a block (denoted by z) was then assessed. The z 
value was increased from 5 to 14 and the other settings were the same. As shown in Figure 6(a), the 
compression time decreases when z increases because most transactions can be represented directly without 
compressions. Hence, the average recall, as shown in Figure 6(d), is increased. Figure 6(b) illustrates that 
when the number of bits is larger, the mining time is longer since the size of the patterns is longer. Figure 
6(c) shows average total execution time. 
0
0.02
0.04
0.06
0.08
0.1
5 6 7 8 9 10 11 12 13 14
A
v
g
.  
co
m
p
re
ss
io
n
  t
im
e
 (
se
c.
)
Number of bits
D3C60T2.5S4I1.25, w: 2, σ: 1%
3
6
9
12
15
18
5 6 7 8 9 10 11 12 13 14
A
v
g
.  
m
in
in
g
  t
im
e
 (
se
c.
)
Number of bits
D3C60T2.5S4I1.25, w: 2, σ: 1%
7
9
11
13
15
17
5 6 7 8 9 10 11 12 13 14A
v
g
.  
to
ta
l 
e
xe
cu
ti
o
n
  
ti
m
e
(s
e
c
.)
Number of bits
D3C60T2.5S4I1.25, w: 2, σ: 1%
0
0.2
0.4
0.6
0.8
1
5 6 7 8 9 10 11 12 13 14
A
v
g
.  
re
ca
ll
Number of bits
D3C60T2.5S4I1.25, w: 2, σ: 1%
 
(a)                                        (b)                                      (c)                                      (d) 
Figure 6. The effect of varying the bit constraint: (a) average compression time (b) average mining time (c) average total 
execution time (d) average recall. 
Figure 7 demonstrates the effects of varying the size of the window with a fixed number of bits (z = 4) 
and σ = 1%. The sequence becomes longer so that the average mining time in Figure 7(b) becomes longer. 
The average compression time in Figure 7(a) is also increased. The average total execution time, shown in 
Figure 7(c), consequently, has a shape similar to Figure 7(b). The average recall is getting worse as the 
increase of the window size, as indicated in Figure 7(d). 
To summarize, the BBSwin algorithm efficiently compresses the bits for variable number of transactions 
in a block. The precision value is always one since no false positive patterns are generated. The total 
execution time is increasing in proportion to the increasing number of bits and the increasing sizes of the 
window. The recall value is decreased as both the number of bits and the size of the window increase. 
IADIS European Conference Data Mining 2011
133
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/31
國科會補助計畫
計畫名稱: 可變更探勘條件之滑動窗模式資料串流頻繁樣式勘測
計畫主持人: 林明言
計畫編號: 99-2221-E-035-075- 學門領域: 資料庫系統及資料工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
