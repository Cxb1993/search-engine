method, few donor kidneys are available and 
transplantation can be limited by the physical 
conditions of patients. General medical staff may 
perform routine examinations for particular factors 
associated with a particular disease. 
This work uses an entropy function to identify key 
features related to HD. By identifying these key 
features, one can determine whether a patient 
requires HD. This work uses these key features as 
dimensions in cluster analysis. The key features can 
effectively determine whether a patient requires HD. 
The proposed data mining scheme finds association 
rules of each cluster. Hidden rules for causing any 
kidney disease can therefore be identified. The 
contributions and key points of this paper are shown 
below. 
1. This paper finds some key features that can be 
used to predict the patient who may has high 
probability to perform hemodialysis. 
2. We apply entropy function to choice the key 
features which have high relationship with 
hemodialysis 
3. The proposed scheme applies k-means clustering 
algorithm with the key features to category the 
patients.  
4. A data mining technique is used to find the 
association rules from each cluster.  
5. The mined rules can be used to determine whether a 
patient requires hemodialysis. 
 
英文關鍵詞： Hemodialysis, Dialysis, Data Mining, Clustering, 
Entropy Function, Association Rules 
 
2 Advances in Artificial Neural Systems
However, improving one’s physical condition and diet
are insuﬃcient. To control one’s physical condition, periodic
health examinations at a hospital have become a common
disease-prevention strategy. Doctors may oﬀer advice to
patients based on health examination results to reduce
disease risk.
Many scholars have applied data mining techniques
for disease prediction. These techniques include clustering,
association rules, and time-series analysis. Diﬀerent anal-
yses may require diﬀerent mining techniques. Selection of
an appropriate mining technique is the key to obtaining
valuable data. However, choosing a data mining technique
is very diﬃcult for general hospitals, especially when dealing
with diﬀerent forms of original data. Therefore, to help
medical professionals identify hidden factors that cause
kidney diseases, this work applies a novel hemodialysis
system (HD system). The HD systemmay identify factors not
previously known.
General medical staﬀ may perform routine examinations
for particular factors associated with a particular disease
and ignore other factors that may be associated with other
diseases, such as kidney diseases. For example, staﬀ may
only assess blood urea nitrogen (BUN) and creatinine (CRE)
levels and CRE clearance (CC). However, increasing amounts
of data indicate that some hidden rules and relationships
may exist. Therefore, this work uses an entropy function
to identify key features related to HD. By identifying these
key features, one can determine whether a patient requires
HD. This work uses these key features as dimensions in
cluster analysis. When patients requiring HD are classified
into the same group, and the other patients are classified into
the other group, the key features can eﬀectively determine
whether a patient requires HD. The proposed data mining
scheme finds association rules of each cluster. Hidden rules
for causing any kidney disease can therefore be identified.
2. Literature Review
2.1. Hemodialysis. Hemodialysis is also called dialysis. An
artificial kidney discharges uremic toxins and water to
eliminate uremic symptoms. In an HD system, a semi-
permeable membrane separates the blood and dialysate. The
human blood continues passing through on one side of an
artificial kidney and the dialysate carries away uremic toxins
on the other side. Finally, the cleaned blood will back into the
body. This continuous cycle eventually purifies blood.
A doctor may recommend that patient undergo dialysis
according to the diﬀerence between acute and chronic. If
kidney failure is acute, the doctor will recommend that the
patient undergo dialysis before the occurrence of uremic
toxins accumulate. For chronic kidney failure, medical
treatment is first utilized and HD may be initiated after
uremia occurs. Additionally, a doctor may assess according to
the causes of kidney failure, kidney size, anemic state, degra-
dation of kidney function, and recovery. Moreover, each
examination indicator will be assessed. The most commonly
used indicators are BUN concentration, CRE concentration,
CC, urine-specific gravity, and osmotic pressure [1, 2].
2.1.1. Blood Urea Nitrogen (BUN). Blood urea nitrogen is
the metabolite of proteins and amino acids excreted by the
kidneys. The BUN concentration in blood can be used to
determine whether kidney function is normal. The normal
BUN range is 10–20mg/dL. If the BUN concentration
exceeds 20mg/dL, this is called high azotemia. However,
the BUN concentration may increase temporarily because
of dehydration, eating large amounts of high-protein foods,
upper gastrointestinal bleeding, severe liver disease, infec-
tion, steroid use, and impaired kidney blood flow. When
the BUN concentration is high and the CRE concentration
is normal, kidney function is normal. Although the BUN
concentration can be used as an indicator of kidney function,
it is not as accurate as the CRE concentration and CC.
2.1.2. Creatinine (CRE). Creatinine is mainly a metabolite
of muscle activity and daily production is excreted through
the kidneys. Daily CRE production cannot be fully excreted
and the CRE concentration increases when TRY kidney
function is impaired. As the CRE concentration increases,
kidney function decreases. Because CRE is a waste generated
by muscle metabolism, the CRE concentration is associated
with the total amount of muscle or weight but is not
related to diet or water intake. The CRE concentration
may reflect kidney function more accurately than the BUN
concentration.When the CRE concentration is in the normal
range, it does mean that kidney function is normal; that
is, CC is a better tool when assessing kidney function.
The compensatory capacity of the kidney is large. For
example, although the CRE concentrationmay increase from
1.4mg/dL to 1.5mg/dL, kidney function may have declined
by more than 50%.
2.1.3. Creatinine Clearance (CC). Creatinine clearance is
widely used and is an accurate estimation of kidney function.
Creatinine Clearance is the amount of CRE cleared per
minute. The CC for a healthy person is 80–120mL/min; the
average is 100mL/min. Kidney failure is minor when the
CC is 50–70mL/min and moderate when CC is only 30–
50mL/min. If CC is <30mL/min, kidney failure is severe
and uremic symptoms will develop gradually. When CC is
<10 gradually, a patient must start dialysis. By collecting all
the urine produced within 24 hours, CC can be determined
easily. Notably, CC is derived as follows:
CC = Urine CREconcentration
(
mg%
)× 24hours urine volume (c.c.)
Blood CREconcentration
(
mg%
) × 1440 (minutes) . (1)
2.1.4. Urine-Specific Gravity and Osmotic Pressure. Urine-
specific gravity and osmotic pressure reflects the ability of
the kidney to concentrate urine. If the specific gravity of
4 Advances in Artificial Neural Systems
Input procedure
Preprocess procedure
Mining procedure
Output procedure
Input data
HIS systems data
LIS systems data
Excel report
Data warehouse
Streamline
Sampling
Select features
Entropy function
Information sort
Quantitative
Extreme value
Picking
YesNo
Outliers Excluded
Data mining
Filtering
Clustering analysis
Association rule analysis
Result
(missingNum >minMissing)
Figure 1: The System Architecture.
Table 1: Kidney function test features.
Kidney function test items Reference Units
Blood urea nitrogen BUN 5–25 mg/dL
Creatinine CRE 0.3–1.4 mg/dL
Uric acid UA 2.5–7.0 mg/dL
Albumin-globulin in ratio A/G ratio 1.0–1.8
Creatinine clearance/24 hrs urine CC
M: 71–135
mL/min
F: 78–116
Renin Penin 0.15–3.95 pg/mL/hr
Creatinine urine Creatinine urine 60–250 mg/dL
Natrium Na 135–145 meq/L
Potassium K 3.4–4.5 meq/L
Calcium Ca 8.4–10.6 mg/dL
Phosphorus IP 2.1–4.7 mg/dL
Alkaline phosphatase ALP 27–110 U/L
6 Advances in Artificial Neural Systems
Table 4: Packing method normalized data.
Sex Age WBC RBC HB BUN CRE UA GOT GPT TP ALB GLO A/G TG Dialysis
Qj 2 5 4 3 3 4 2 2 4 5 2 2 2 2 3 2
1 1 3 1 1 1 3 1 0 0 0 0 0 0 0 1 1
2 0 1 3 1 0 0 0 0 0 1 1 0 1 0 1 1
3 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1
4 0 2 0 1 0 0 0 0 2 0 0 0 0 0 2 0
5 1 3 1 1 1 2 1 0 3 4 1 1 1 0 1 0
6 1 1 1 1 2 1 1 1 0 0 0 0 0 0 1 1
7 0 4 2 0 0 1 1 0 0 0 1 0 1 0 1 0
8 1 1 1 1 2 3 1 0 2 4 0 0 0 1 2 1
9 1 2 0 1 2 2 1 1 1 2 0 0 0 1 1 0
10 0 2 3 1 0 2 0 1 2 1 0 0 1 0 2 0
11 1 0 1 2 2 1 0 0 1 1 1 1 1 0 1 0
12 0 0 1 1 0 3 0 0 0 0 0 0 0 0 1 0
13 0 2 1 2 0 0 0 0 0 1 1 0 1 0 1 1
14 1 2 2 0 1 1 1 1 1 0 0 1 0 1 1 0
15 1 2 3 1 2 3 1 1 1 1 0 1 0 1 1 0
Table 5: Calculation information gain of sex relative to dialysis.
Sex j Dialysis Count (Djν) PDjν PDjν× log(1/PDjν ) Entropy (Djν) Entropy (Dj)
0
0 4 4/7 0.46
0.99 0.459773
1 3 3/7 0.52
1
0 5 5/8 0.42
0.95 0.509031
1 3 3/8 0.53
sum 0.968804
In (3), Entropy (Djv) is the information content of
the j feature dimension, the v value, and classification
and information quantity, Djv is the j feature dimension,
including v kinds of values, and the j feature dimension has
|Dj| values.
In (4), Gain (Dj) is a classification problem, the informa-
tion gain received by the j feature dimension. Through (2)–
(4), the information gain of each feature for a classification
problem is found. This work then evaluates all threshold set-
tings and collects the features with the greatest information
gain to form a feature set for classification. Entropy is used
to identify key features and cluster HD patients to determine
the accuracy of key features.
2.3. Clustering Algorithm. Although many clustering tech-
niques have been proposed, the k-means algorithm is the
most representative and widely applied [9]. The k-means
algorithm is also called the generalized Lloyd algorithm
(GLA) [10]. The k-means algorithm transforms each data
record into a data point and random numbers are utilized
to generate the initial cluster center to determine which data
point belongs to which cluster point. The divided data points
are used to calculate the distance between a data point and
the cluster center, such that a data point will belong to one
cluster center when the data point is closer to one cluster
center than another cluster center. The newly recomputed
cluster center is the average among all data points in a cluster,
and the new cluster center is taken as a basis for the next
iteration. This process is repeated until no change occurs.
The steps of the k-means algorithm are as follows.
(1) Use random numbers to generate the initial cluster
centers Ci = {1, 2, . . . , k}.
(2) Calculate the Euclidean distance d(X ,Ci) for each
data point X = {x1, x2, . . . , xm} and each cluster
center Ci. The point with the shortest distance is
classified in to Ci, and the distance formula is as
follows:
d(X ,Ci) =
√
√
√√
√
m∑
j=1
(
xj − ci j
)2
, (5)
(3) Recompute the new cluster center Ci. If the move-
ment of all data points in a cluster stop moving, all
clustering work stops; otherwise, steps (1) and (2) are
repeated for clustering.
2.4. Association Rule. An association rule is a widely used
technique. It progressively scans a database to identify
rules for the relationships between items. For instance, the
probability that people will buy bread after buying milk
is milk → bread (support= 50% and confidence= 100%);
support means that the probability of a consumer buying
8 Advances in Artificial Neural Systems
Table 8: Clustering results.
Cluster UA AST (GOT) TG K (Blood) Density
Cluster-1 6.54 24.48 119.72 5.10 14.14
Cluster-2 6.16 30.12 138.92 3.92 11.59
Cluster-3 4.47 24.72 112.33 4.07 11.22
Cluster-4 8.40 28.03 228.72 4.20 20.91
(3) The mining procedure is also divided in two subpro-
cedures. For clustering analysis, one subprocedure,
the clustering algorithm is applied to these key
features to group patients. For the association rule,
the other subprocedure, the Apriori algorithm is
applied to find the association rule in each cluster.
(4) The output procedure may express the entire mining
result, and a medical professional will explain the
mining result, and find any factor that may cause a
disease.
3.1. Input Procedure. Examination information is frommany
sources, such as a hospital information system (HIS),
laboratory information system (LIS), or Excel report. These
diﬀerent systems may have diﬀerent data storage formats.
For example, in the A database, gender is 1 for male and 2
for female, but in the B database, M is for male and F is
for female. Thus, an error may occur while collecting data.
Therefore, one should apply the preprocess process to ensure
that information is correct, complete, and suﬃcient. The
preprocess process is divided into five steps.
(1) Unified data storage format: to simplify mining, all
information must be in the same format.
(2) Irrelevant data: if one does not specify the mining
topic, mining eﬃciency and even accuracy will be
adversely aﬀected.
(3) Incorrect data: incorrect data may be caused by a
source error or login error; thus, one should modify
or remove.
(4) Formats do not match: to smooth information
mining, information must be converted into an
appropriate format when necessary.
(5) Incomplete data: incomplete data is a common
problem; for example, some information may be lost,
lacking for a certain period.
3.2. Preprocess Procedure. Data are standardized to improve
analytical accuracy. A standard value may be applied to
an item such as triglycerides (TG). If the TG level is
≥201mg/dL, it exceeds and the standard is 100; if TG is
normal it is in the range of 20–200 and the standard is 50;
if TG is smaller than <19mg/dL, it is lower than the standard
and the standard is 0. If data are consecutive, a packing
normalization method is used; its formula is as follows:
v′j =
⌊(
vj −min j
max j −min j
)
×Qj
⌋
, (6)
where vj represents raw data, min j is the minimum value of j,
max j is the maximum value of j, v′j is the packing normalized
value, and Qj is quantified distance. Table 4 shows example
data after quantization.
Table 4 is a normalized form used to derive information
gain and in association rule analysis, and it can eﬀectively
diﬀerentiate between patients. This work simultaneously
uses extreme value normalization; its formula is
v′′j =
vj −min j
max j −min j × 100, (7)
where vj represents raw data, min j is the minimum value of
j, max j is the maximum value of j, and v′′j is the packing
normalized value. For instance, if the WBC value is 1,
max= 10.7, andmin= 3.5, then v′′ = [(1−3.5)/(10.7−3.5)]×
100 = 38.89% can be derived by applying (7).
In the entire database, the maximum and minimum
values of each item markedly aﬀect the quantification result,
and the values are called outliers. If outliers exist, anomalies
will also exist; for example, suppose that Q of CRE is 80, and
CRE values are generally 0.37–2.99; however, a polarization
datum may occur when a record is 6990. After quantization,
values in the range of 0.37–2.99 will be quantified as 1, and
the value recorded as 6990 will be assigned 80. Therefore,
this work creates a mechanism to remove outliers. To avoid
the influence of outlier values, this work sets a minNum
threshold for each record. For example, assume minNum= 3
is the threshold. The total number of hemoglobin (HB),
which is quantified as 2 (HB= 2), is 9; however, that of HB,
which is quantified as 0 (HB= 0), is 1. This means that most
data are assigned to HB= 2, and only 1 datum is assigned
to HB= 0. The total number of quantified values that are
smaller than minNum is the extreme value. This scheme
replaces the extreme value with the average value.
3.3. Information Gain Analysis. This work uses dialysis item
to identify information gain. For example, 6 patients are on
dialysis (Dialysis= 1) (Table 4), the occurrence probability
is P1 = 6/15, and information gain is P1 × log(1/P1) =
(6/15) × log(6/15) = 0.528771. When 9 patients are
nondialysis (Dialysis= 0), occurrence probability is P0 =
9/15, information gain is P0 × log(1/P0) = (9/15) ×
log(9/15) = 0.442179, and total information gain of P0 and
P1 is 0.970951.
Next, this work calculates the information gain of each
item relative to dialysis item. Take Sex (Table 5) as an
example. The Sex of 7 women is 0 (Sex= 0) and only 4
records with non-dialysis (Dialysis= 0), the probability is
PDjv = 4/7 of Sex= 0 and Dialysis= 0, and information
10 Advances in Artificial Neural Systems
gain is 0.46. Three records have Sex= 0 and Dialysis= 1;
thus, the probability PDjv = 3/7, and information gain
is 0.52. Total information gain of 0.46 and 0.52 is 0.99.
Information gain of the women is 0.99 × (7/16) = 0.459773
because the probability of Sex= 0 is 7/16. After summing the
information gain of the women (Sex= 0) and men (Sex= 1),
total information gain is 0.968804, where 0.968804 =
0.459773 + 0.509031. Next, via (3), which is Entropy (N) −
Entropy (Dj), Gain (Dj) = 0.970951− 0.968804 = 0.002147.
The information gain of each item related to dialysis can
be obtained and ranked, and the association rule can be
mined using the top few items as key features. Take Table 6
as an example. Assume that the top three items are chosen.
Thus, Age, WBC, and BUN are taken as key features.
3.4. Data Mining Procedure
3.4.1. Missing Values. Some patients may have missing
values. If their records are removed directly, some import
information may be lost. Thus, this work applies a second
filter before data mining analysis. This research sets min-
Missing as the threshold and takes missingNum as a null
value of each record. If missingNum>minMissing, then the
record is removed. Otherwise, missingNumminMissing,
the record will be retained and the missing null values will
be replaced by the mean value. For instance, Age, WBC,
and BUN are the top three key features when records are
missing records. Assume minMissing is 1. When a record for
whichmissingNum> 1, the record is removed; otherwise, the
record is retained and the missing null values are replaced by
the mean value.
3.4.2. Clustering. This work uses key features for clustering,
where x1, x2, . . . , xm as m key features, X = {x1, x2, . . . , xm}
are patient records, xj is a key feature in X, 1≤ j≤m, and k is
the cluster number. The k-means process is as follows.
(1) First, randomly generate k initial cluster centers
Ci = {c1, c2, . . . , cm}. Figure 2(a) has ten solid circles,
N = 10, which are the locations of each record, and
three triangles, k= 3, which are the locations of
cluster centers Ci.
(2) Apply (5), d(X ,Ci) =
√∑m
j=1(xj − ci j)2, to calculate
the distance between each patient’s data point X and
the cluster center Ci. When some X distance d1 is less
than di, X will be classified to C1.
(3) Let Ĉi = {Xci1,Xci2, . . . ,XciS} be a cluster center
membership, where S is the total number of
members in Ci, and Xciu is u patient’s data
point in Ci. Thus, newCi will be added to
the sum of XciS in each Ĉi, and newCi =
{(∑su=1 xu1/S), (
∑s
u=2 xu2/S), . . . , (
∑s
u=1 xuj/S)}
can then be obtained. This function can also be taken
as a new cluster center.
(4) Repeat steps (2) and (3) until each Ci remains the
same.
3.4.3. Association Rule. Next, the proposed scheme finds
each clustering characteristic rule using Apriori association
rule analysis. We assume that the total number of records
in cluster Ci is S, and each cluster membership is Ĉi =
{Xci1,Xci2, . . . ,XciS}; thus, the u patient’s data point Xc,u
is in the Ĉi, and the j key features xuj are in Xciu =
{xu1, xu2, . . . , xum}. Next, the association rule is used to
analyze each cluster Ci.
(1) First, set the values of minimum support minSup and
minimum confidence minConf.
(2) Convert the normalization table into an extreme
values table.
(3) Find the candidate set. We assume α = itemij p, where
itemij pis the p quantified value of the j key feature
in Ĉi, 1 pQ, and Sup(α) denotes the occurrence
probability of itemij p in Ĉi. If Sup(α)minSup, then
itemij p becomes a candidate itemset LZ and proceed
to the next step.
(4) Through candidate set Lz = {α1,α2, . . . ,αy}, generate
a set of two items, L̂y = {α1 ∪ α2,α1 ∪ α3, . . . ,α1 ∪
αy ,α2 ∪ α3, . . . ,αy−1 ∪ αy}; however, αA and αB
cannot be the same item. Calculate the occurrence
probability of each group, Sup(αA ∪ αB). If Sup(αA ∪
αB)>minSup, it becomes a member of frequent
itemset LZ+1.
(5) Take LZ as a candidate set and repeat step (4) until
the candidate set is null.
(6) Generate the association rule of the frequent itemset.
If the confidence of the rule exceeds minConf, the
rule is set up and the process is as follows.
(i) Let α∗ be one of the frequent itemsets L f , α∗ =
(RA ∪ RB).
(ii) Generate rules RA → RB and RB → RA.
In the case of A clustering CA, where minSup= 2
and minConf= 0.5, the key features are item1 =Age,
item2 =WBC, and item3 =BUN, and S= 7 is the total number
of records in CA. Thus, this work finds the frequent itemsets
L1 using the minSup and minConf thresholds. The proposed
scheme merges two items by L1 as a candidate set, where
j =Age, p= 3 in α1, and j =WBC and p= 1 in α3, and then
calculates Sup(α1 ∪ α3). If Sup(α1 ∪ α3)minSup, then let
α1 and α3 be the two frequent itemsets until nomore frequent
itemsests are found.
Next, the quantified values are converted back into their
original values if all rules are found; the formula is
vj =
v′j
Qj
×
(
max
j
−min
j
)
+min
j
, (8)
where v′j is a quantified value, min j is the minimum value of
j, max j is the maximum value of j, vj is the original value,
andQj is a quantified interval. Take WBC= 1→Age= 3 as an
example rule. If the max j of WBC is 10.7, the min j value is
3.5, andQj is 4; then the original value ofWBC= 1 isWBC =
12 Advances in Artificial Neural Systems
this paper under Contract no. NSC 99-2622-E-324-006-
CC3.
References
[1] DrKao, “Normal Test Values,” 2010, http://www.drkao.com/
1st site/health wap/normal main.htm.
[2] Green Cross, “How to Detect Renal Function,” 2010,
http://www.greencross.org.tw/kidney/symptom sign/kid
func.html.
[3] Shin Kong Wu Ho-Su Memorial Hospital, 2010,
http://www.skh.org.tw/mnews/178/4-2.htm.
[4] K. C. Hung, Multiple minimum support association rule mining
for hospitalization prediction of hemodialysis patients [M.S.
thesis], Computer Science and Information Engineering, 2004.
[5] S. Y. Huang,The evaluation& analysis of the risk of mortality for
patients receiving long-term hemodialysis proposal [M.S. thesis],
Graduate Institute of Biomedical Informatics, 2009.
[6] J. Y. Yeh, T. H. Wu, and C. W. Tsao, “Using data mining tech-
niques to predict hospitalization of hemodialysis patients,”
Decision Support Systems, vol. 50, no. 2, pp. 439–448, 2011.
[7] Y. J. Lin, Applying data mining in health management infor-
mation system for chronic desease [M.S. thesis], Department of
Computer Science and Information Management, 2008.
[8] J. R. Quinlan, “Induction of decision trees,” Machine Learning,
vol. 1, no. 1, pp. 81–106, 1986.
[9] T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. Piatko,
R. Silverman, and A. Y. Wu, “An eﬃcient k-means clustering
algorithms: analysis and implementation,” IEEE Transactions
on Pattern Analysis and Machine Intelligence, vol. 24, no. 7, pp.
881–892, 2002.
[10] J. Z. C. Lai, T. J. Huang, and Y. C. Liaw, “A fast k-
means clustering algorithm using cluster center displacement,”
Pattern Recognition, vol. 42, no. 11, pp. 2551–2556, 2009.
[11] R. Agrawal, R. Srikant, H. Mannila et al., “Fast discovery of
association rules,” in Advances in Knowledge Discovery and
Data Mining, pp. 307–328, 1996.
  2
成為主流，Prof. Daniel 提出很多有關服務導向管理及相關創新技術的概念，值
得我們參考。 
第二場演講主題是新產品發展的可靠度管理，顧客感覺一項產品的好壞，很大
的因素來自該產品的可靠程度，然而，產品要求可靠度越高，其成本代價就越
高，如何在可靠度及成本上取得平衡，就顯得相當重要。此場演講主要在說明
如何在產品發展時，在可靠度及成本中間進行有效的決策。這個論點可以用在
我們此次提出之計劃，因預警系統若要真實呈現，即預警可靠度及精確度高，
其所花費的成本必然很高，這裡指的成本包含探勘成本、系統建製成本、人員
培訓成本等；反立，若只要求精簡的探勘結果，則預警系統必然無法符合需求。
因此，如何在預警可靠度、精確度及各種成本上取得平衡點，讓系統各種參數
制訂時能夠給予適當的決策，也是我們需要考量及評估的。 
此外，IEEM研討會分成數個議程，包含： 
z Decision Analysis and Methods 
z Supply Chain Management 
z Intelligent Systems 
z Systems Modeling and Simulation 
z Operations Research 
z Technology and Knowledge Management 
z Information Processing and Engineering 
z … 
我們最有興趣的議題是 Decision Analysis and Methods、Intelligent Systems、
Information Processing and Engineering及 Technology and Knowledge Management
等議程。學者分享了他們使用類神經網路、模糊理論、線性規劃等方法於決策
分析、專案管理、供應鏈管理等理域時產生的效益及優缺點；還聽到許多學者
國科會補助計畫衍生研發成果推廣資料表
日期:2011/12/19
國科會補助計畫
計畫名稱: 血液透析資料關聯性規則分析及預警系統
計畫主持人: 呂慈純
計畫編號: 100-2221-E-324-033- 學門領域: 資料庫系統及資料工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本研究實驗產出一些規則，如  
高風險腎臟病規則： 
 (Cluster-1) 當 BUN 約為 60±1.5 時。 
 (Cluster-1) 當血中鈉 Na(Blood)約為 140±2.5 時。 
低風險腎臟病規則： 
 (Cluster-2) 當 UA 約為 6.5±0.25 且 TG 約為 159.75±25 時。 
 (Cluster-2) 當 AC-GLU 約為 136±25 時。 
 (Cluster-2, 3, 4) 當 K(Blood)約為 4.14±0.25 時。 
 (Cluster-3) 當 CRE 約為 0.85±0.15 且 K(Blood)約為 4.14±0.25 時。 
以上探勘結果發現，BUN 約在 60±1.5 時確實為高風險之腎臟病，是現在醫學上
洗腎病患的洗腎評估指標之一，而其它規則目前尚未證實是否與洗腎病患相
關，因此需要進一步研究才可以證實。從實驗中可以發現 AST(GOT)指標約為
24.5±10 或者 45±10 時，在高風險的第 1 群與低風險的第 3 群中都有出現，因
此判定該指標與腎臟病無關聯性。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
