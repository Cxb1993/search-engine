let Xi = 0. The Bernoulli parameter p in such a case is called the bit error
rate (BER). Constructing a good conﬁdence interval procedure for the BER
is critical to determine the quality of a communication system. This task is
particularly challenging for highly reliable communication systems with their
low BER (Song and et al., 2005). Our motivation is to construct a good and
cheap (in terms of sample sizes) conﬁdence interval of p.
The conﬁdence interval procedure for p with conﬁdence level 1 − α is a
procedure to determine L and U such that the following probability statement
is satisﬁed:
P(L ≤ p ≤ U) = 1− α, (1)
where 0 < α < 1. Both L and U are functions of X1, X2, . . . , Xn; hence, they
are random variables. Once we select a sample of size n (say X1 = x1, X2 =
x2, . . . , Xn = xn), and compute the values of L and U using the sample values,
we obtain a conﬁdence interval (l, u) for p. Both l and u are real values.
In practice, it is diﬃcult or impossible to ﬁnd a CI procedure to satisfy
Equation (1) for any given α, n and p. Our objective is to construct a CI
procedure to form (L,U) for p at a nominal conﬁdence level 1 − α such that
(i) its actual coverage probability (CP), P(L ≤ p ≤ U), is close to the nominal
level 1− α; (ii) its expected interval width, E(U −L), is narrow enough to be
informative; and (iii) its standard deviation of the interval width, std(U −L),
is small enough to be stable. It is easy enough to construct a CI procedure
that satisﬁes any one of these criterion. Our aim is to meet all three criteria
simultaneously.
Here we deﬁne and clarify more notation to make further analysis easier.
First we make a distinction between “CI procedure” and “CI”. We use CI
procedure to refer to a procedure to form (L,U) which is a random interval,
and use CI to refer to a real-value interval (l, u). Let Pˆ and pˆ, respectively,
be the general point estimator (random variable) and the corresponding point
estimate (real number) of p. To refer to a speciﬁc CI procedure, we sometimes
add subscripts to CI, Pˆ and pˆ. For example, to refer to a standard CI proce-
dure, we use the notation CIS, PˆS and pˆS. CP denotes the coverage probability,
and CP(n, p) refers to the coverage probability measured at values n and p.
The organization of this paper is as follows: In Section 2, we review and
expand upon two well-known CI procedures (the standard and Wilson) and
estimators of Bernoulli parameters. In Section 4, we introduce ideas for devel-
oping the proposed CI procedures. In Section ??, we propose new improved
procedures. In Section ??, we evaluate the performances of the new proce-
dures and compare them with the performances of the existing procedures.
We present a summary and conclusions in Section ??.
2
where pˆW =
k + (z2α/2/2)
n + z2α/2
and
σˆW =
√√√√npˆS(1− pˆS) + (z2α/2/4)
(n + z2α/2)
2
, (6)
where pˆS = k/n was deﬁned in Equation (3).
The lower and upper bounds in the Wilson interval are two roots of p for
the following equation
pˆS − p√
p(1−p)
n
= ±zα/2. (7)
The Wilson CI procedure improves the standard procedure because the
approximation — substitute the estimate pˆS for the true parameter p in the
expression (4) — for CIS is not made. Brown et al. (2001 and 2002) surveys
many existing CI procedures and conclude that the Wilson CI procedure works
better for small n (say n ≤ 40) than many other CI procedures and performs
as well as other CI procedures for larger n in terms of the coverage probability.
We will show that the Wilson CI with the rule “n min{p, 1 − p} ≥ 6”
guarantees that the actual coverage probabilities stay above 0.90 for 0.001 ≤
p ≤ 0.999. Furthermore, we will show in that the Wilson CI with the rule
“n min{p, 1− p} ≥ 11” guarantees that the actual coverage probabilities stay
above 0.92 for 0.001 ≤ p ≤ 0.999.
3.3 The Estimators of Bernoulli Parameter
A generalization of the estimator of the Bernoulli parameter p used in many
well-known CI procedures has the form
Pˆ =
K + r
n + 2r
, (8)
where n is the sample size, K is the number of success, and r is a positive real
number. Five examples are well known:
1. The standard CI procedure uses r = 0. The corresponding point esti-
mator of p is deﬁned by PˆS = K/n, already shown in Section 2.1. The
K/n is the maximum likelihood estimator of p.
2. Jeﬀrey’s CI procedure uses r = 0.5. See Brown et al. (2001). The
corresponding point estimator of p is deﬁned by PˆJ =
K + 0.5
n + 1
.
3. Laplace estimator uses r = 1. See Chew (1971). The corresponding
point estimator of p is deﬁned by
PˆL =
K + 1
n + 2
. (9)
4
4. mse(Pˆ ) ≤ mse(PˆS) if and only if
p ∈ [1/2− w/2, 1/2 + w/2] , (11)
where w =
√
n + r
n + r + nr
.
Consider one example when r = 1 and n = 100, Equation (11) shows that
mse(PˆL) ≤ mse(PˆS) if and only if p ∈ [0.145, 0.854].
4 IDEAS For DEVELOPING THE NEW CI
PROCEDURES
4.1 Determining Student-t Degrees of Freedom
The coverage probabilities of CIS are all below the nominal probability 0.95.
One way to improve the coverage probability for CIS is to replace the zα/2
in Equation (2) by tα/2(υ) because the value of tα/2(υ) is larger than zα/2 for
any value υ. The question now is the selection of the value for υ. A logical
supposition for a degrees of freedom (d.f.) is n− 1. Deﬁne
υS = n− 1. (12)
The value of υS deﬁned in Equation (12) does not depend on the value of p.
In this section, we propose a new d.f., called “the adjusted d.f.”, as a function
of both n and p. We believe that a better υS should depend on both n and p
because the amplitudes of oscillations depend on both n and p.
Let X1, X2, . . . , Xn ∼ iid Bernoulli (p). The value of the adjusted degrees
of freedom is deﬁned by
υA =
2n
1
p(1− p) − 3−
n− 3
n− 1
, (13)
and the corresponding t-value is deﬁned by
t(υA) =
{
t(υA), υA ≤ 1
β t(υA	) + (1− β) t(υA), υA > 1 , (14)
where β = υA−υA , υA is the smallest integer greater than or equal to υA,
and υA	 is the largest integer less than or equal to υA.
The reason for using υA is given in Theorem 2 below and in the following
explanation.
6
