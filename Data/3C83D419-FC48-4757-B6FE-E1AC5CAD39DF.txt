similarity search over high-dimensional data sets. 
英文關鍵詞： Similarity Search, kNN Search, high-dimensional 
datasets, subspace, query processing, indexing 
structures 
 
由於高維空間中的 similarity search特別適合使用
於 image database application上，主持人目前也正和
系上影像處理專長的教師和作，探討如何將本計畫
的技術應用在 image retrieval的應用上。目前我們初
步的成果是將這些技術使用在學生的專題上。我們
所指導的學生開發了「手寫計畫機」的應用，其利
用影像辦識的技術辦認使用者的手寫數學式、計算
此數學式，並將結果呈現給使用者。這個學生專題
的辦識技術中，便有利用本計畫的索引機制來加速
辦識的效率。目前這個專題獲得了教育部的「建國
百年開放軟體創作競賽」銅牌獎。相信這部分的成
果也展現了本計畫在實務上的潛力。 
關於本計畫之研究目的、文獻探討、研究方法、
結果與討論，由於都已經在我們所發表的論文中有
闡述，因此底下列出我們所發表的其中一篇論文供
reviewer參考。 
目前的研究多在探討如何有效率的處理“單一個 
kNN 查詢”。事實上我們發現在許多的情境中，伺
服器往往需要處理許多類似的 kNN 查詢。舉例來說，
海灘是每一個旅客在夏季時最喜歡的渡假地點。當
旅客在做度假規劃時往往會先向伺服器提出 kNN 的
查詢, 例如搜尋 k間距離海邊最近的飯店，或者搜尋
靠近海邊 k 個不可錯過的旅遊景點等。每一個旅客
都可能會提出這一類的查詢，而查詢間的差異往往
就只在 k 值的不同。例如使用者 A 可能提出的查詢
是搜尋最靠近海邊的 3 間飯店，而使用者 B 則是要
查詢 5 間距離海邊最近的飯店。然而目前的研究方
法對於這樣相似的 kNN 查詢大多採取「伺服器重新
計算」的方式。換言之, 伺服器會將每一個查詢視為
是一個獨立且不同的 kNN 查詢。然後一一的針對這
些查詢從資料集中找出符合的資料，再回應給使用
者。而這些類似的 kNN 查詢則會因為伺服器不斷的
執行而造成系統資源的浪費，同時延緩使用者回復
的時間。 
因此本篇計畫主要針對多個 kNN 查詢提出一個
更有效率的處理方法。藉由“資訊分享”來加速多
個 kNN 的查詢。我們利用一個例子來說明為何資源
共享可以達到加速查詢處理的原因。在圖中有兩個
查詢點，q1及 q2，以及 15個資料點（p1~ p15）。令
q1及 q2都是 3NN查詢（i.e., k = 3），且 server已經
處理完 q1，並得到 q1的結果{ p4, p5, p14}。圖 1中的
實線圓代表 q1的搜尋區域，在這個區域中存在 q1的
3NN 結果。現在 q2出現，且 q2很接近 q1。由圖 1
中可以看出，q2的答案為{ p2, p5, p4}，明顯地 q1和
q2的結果有很大的重疊。這說明了一個現象，那就
是「當查詢點的距離很靠近時，這些查詢的答案會
有許多重疊的部分。」我們利用了這個現在，設計
了一個資訊分享的策略，其利用了先前查詢的結果，
加速目前查詢的處理效率。以圖 1 而言，我們可以
利用 q1的結果，進而推論出 q2的搜尋範圍（即圖 1
中虛線圓），並且快速地找到 q2的結果。 
 
圖 1 資訊分享的例子。 
雖然資訊分享的概念很簡單且直覺，但要利用這
個概念來加速 kNN 查詢的處理並不是那麼簡單。考
慮前述的例子，當 server 想利用資訊分享的方式來
加速 q2 的處理時，必須克服底下幾個困難： (1) 
server 如何知道 q1存在，且可以利用 q1的結果來加
速 q2的處理？(2) 知道 q1的答案為{ p4, p5, p14}後，
如何利用這些資訊來取得 q2的結果？(3)萬一不存在
任何可以分享的資訊時（例如 q2是 server 所處理的
第一個查詢），這時 server應該如何處理？  
在本計畫中，我們設計了一個名為 Multiple kNN 
query algorithm，其可以克服上述所有的困難。在演
算法中，我們設計了一個新的索引結構，其名為 R-
Grid。R-Grid 架構於 R-tree 之上，其可以讓我們的
演算法利用資訊分享的概念來加速查詢的處理。 
最後，我們透過實驗證明我們所提出的方法能夠
有效率的處理多個 kNN 的查詢。在實驗中我們也比
較了我們的方法與傳統的 kNN (e.g., BFS[1]) 演算法
在執行多個 kNN 查詢時的效能，由實驗結果可以證
明我們的方法在執行時間及 I/O Cost 上都比傳統的 
kNN演算法來的好。k 
本論文其它各節架構如下:第 3 節簡介過去 kNN
的研究；第 4 節說明本計畫的背景知識；第 5 節為
本計畫的研究方法及步驟；第 7 節是本論文的實驗
結果；最後第 7節為本計畫的結論與未來展望。 
3. RELATED WORK 
 
kNN 查詢處理在資料庫領域中一直是個熱門的議
題，有許多相關的研究成果不斷地被發表出來[1-11]。
然而，如同我們在第 1 節中所提到的，這些研究都
集中在“單一個 kNN 查詢”的處理上。由於計畫篇
幅的限制，我們無法詳細地解釋這些計畫的內容。
在此僅就影響最廣的 kNN 演算法加以說明，此演算
法是由 Hjaltason et al.於 1999 年提出[1]，其名為
Best First Search (BFS) algorithm。由於 BFS利用 R-
tree[12]來加速查詢的處理，因此在底下的文章中，
我們先介紹 R-tree，之後再說明 BFS的細節。 
3.1 R-tree 
中的資料點個數已達 k 個，所以將 best_distance 設
為 dist(q1, p2)。現在 H 中的第一個元素 N2，且
best_distance = dist(q1, p2)。我們發現 q1 和 N2 的
mindist>best_distance。這代表著，在 MBR N2底下
的資料點中，最接近 q1的點，其和 q1的距離都大於
best_distance。這意味著 N2底下的其他資料點，都
不可能是 q1的 3NN。又因為 N2是所有未被拜訪的 
MBR中離 q1最近的，若 N2不可能包含 q1的 3NN，
那麼其他未被拜訪的 MBR也不可能包含 q1的 3NN，
於是演算法便可以終結。最後，candidate set 中的結
果便是 q1的 3NN。詳細的步驟如表格 1所示。 
表格 1 BFS執行過程。 
 
4. PRELIMINARY 
 
這一章節的說明，包含了我們的環境假設、問題
定義、資料結構。Section 4.1 說明環境假設及問題
定義。接著在 Section 4.2 說明我們所設計的索引結
構。 
4.1 Assumptions and Problem Definition 
以下說明我們設定的一些假設及環境。本計畫是
在集中式的環境下處理 kNN查詢，因此 server 知道
整個資料庫中點集合 D 中所有資料點的屬性值。D
是一個維度為 d (d ≥ 2) 的靜態資料點集合。pi則是 
D 中第 i 筆資料。Q 是一個查詢集合，而 qi (𝑖 =1 …𝑁) 是 Q中的一個查詢點。qi.k 是 kNN 查詢點 qi
所求的 k 值，每個查詢所求的 k 值不一定相等。我
們將每個資料點 pi及查詢點 qi的屬性值皆正規化到 
[0..1]之間。為了方便說明我們所提出的演算法，在
本計畫中我們以 2 維空間 (i.e., d = 2) 舉例說明。然
而本計畫所提出的方法也可以使用到多維的資料空
間中。本計畫的目標則是發展一套演算法，讓 server 
依序處理 Q 中每個查詢點，且其所耗的時間總合和 
I/O Cost 為最小。 
4.2 Index Structure 
在此章節，我們介紹本計畫所提出的索引方式及
資料結構。在本計畫中我們提出了三個索引結構，
分別是 Query Result Hash Table (QRHT)、R-Grid，
以及 MBR pointer table。QRHT是一個 hash table，
其用來索引系統所收到的查詢。R-Grid 則是 R-tree 
的擴充版，其用來索引 R-tree 中的 MBR。而 MBR 
pointer table是一個儲存 MBR pointer的 table，使得
可以透過此 table 快速存取 MBR。底下我們先介紹 
QRHT 的架構，之後再說明 R-Grid 及 MBR pointer 
的設計原理。 
3.2.1 Query Result Hash Table (QRHT) 
在 Section 2 曾提到當兩個 kNN 查詢距離很相近
時，其 kNN 的答案也會非常相近。因此，我們利用
此觀察發展出資訊分享 (Information Sharing Strategy) 
的機制來解決 Multiple kNN Queries 的問題。為了使
查詢點的資訊能夠分享，演算法必需能辦識出那些
查詢點間距離較為相近。如此，演算法在處理一個 
kNN 查詢 qi時，便能快速地辦識出離 qi較近的查詢
點，並利用這些查詢點的查詢結果來推導出 qi的結
果。請注意，這個辦識的過程要十分地快速，如此
才不會拖慢整個系統的效率。為了達到這個目的，
我們根據 Locality Sensitive Hash (LSH) [13]發展一個
資料結構稱為 Query Result Hash Table (QRHT) 。如 
圖所示，QRHT為一個 in-memory 的 hash table，存
放每個查詢點的查詢結果。當 server 處理完查詢 qi
後，除了將 qi的結果回傳給使用者外，還需將 qi的
結果存到 QRHT 中。舉例而言，q1是一個 kNN查詢，
且 q1的結果為 = {p1, p2}。令 h 是一個 LSH，且 h(q1) 
= buecket 1 (見圖 5)。於是 server 便會把{p1, p2}儲存
到 bucket 1 中，如圖 5所示。 
 
圖 5 LSH的例子。 
 
4.2.2 R-Grid 
如同現有的演算法[1, 2]，我們也使用 R-tree 對資
料點作索引。過去使用 R-tree 的演算法[1, 2]在運作
時，都會由 R-tree 的 root 開始，走訪 R-tree 直到 
leaf node，並取出最終的結果。這種走訪 R-tree 的過
程，需要做大量距離的計算，因此十分的耗費 CPU 
cost。在 multiple kNN queries 的環境中，我們可以
利用過去 kNN query 的結果，來加速走訪 R-tree 的
過程。我們希望在處理查詢 q 時，不要每次都由 R-
tree 的 root 開始走訪，而是直接取出 q附近的 MBR，
並由這些 MBR 中取得 q的結果。更進一步地說，我
們藉由省略走訪 R-tree 的過程，達到加速處理 kNN 
search 的目的。 
我們設計了一個新的索引架構 R-Grid 來幫助我們
達到這個目的。R-Grid 是一個架構在 R-tree 上的索
引架構，其索引了 R-tree 的 leaf node。我們利用一
個例子來說明 R-Grid的細節。 
在圖 3 的 R-tree中，其 leaf node 有 6個 MBRs 
(即 N1…N6)，它們在 2 維空間中的位置如圖 2 所示。
我們利用 R-Grid 將整個資料空間切割成許多子空間 
(subspace) 來索引這 6個 MBRs。首先我們將每個維
度等分成𝛿個子空間（𝛿為系統參數），由於屬性值
被正規化到[0,1]之間，所以每個子空間的寬度為1 𝛿⁄ 。
圖 6 及圖 7 分別展示了 d1維度空間，以及 d2維度
空間被𝛿等份後，子空間的分佈狀況。 
 
圖 9 MBR pointer table。 
5. MULTIPLE KNN QUERIES ALGORITHM 
我們所設計的演算法（Multiple kNN algorithm）
其背後的想法是根據「若 q1和 q2很近，則這兩個查
詢的結果也會很相似」的觀查而來的。我們讓 server 
處理每個查詢點時，先判斷是否有先前的查詢點所
分享的資訊。若有資訊可以分享，我們可以利用所
分享到的資訊來找尋 kNN 的答案。當沒有資訊可以
分享時，我們則採用傳統 kNN 的查詢演算法來找到
解答 (以本計畫而言，我們使用 BFS 演算法) 。找到
解答後，會將這些解答儲存在 QRHT 中 (見 Section 
4.2.1) ，而日後有新進的查詢時，便可以使用這些儲
在 QRHT中的資訊來加速查詢。 
為了方便說明 Multiple kNN演算法，我們需要先
定義一些符號。令 B[i]為 QRHT 中的一個 bucket，
為一群資料點的集合，且|B[i]|為 B[i]中資料點的個
數。B[h(qi)]則代表 qi 經 LSH 後，所 hash 到的 
bucket。 
我們在 Algorithm 1 中呈現 Multiple kNN 演算法。
在演算法中，當 qi 進入系統中時，演算法會利用
LSH將 qi到 QRHT 中 ( Line 4 ) 。於是我們就可以得
到 qi所分享到的資訊，也就是落於 B[h(qi)]中的資料
點。若B[ℎ(𝑞𝑖)] ≥ 𝑞𝑖 . 𝑘，代表我們可以利用 B[h(qi)]
中的資料，找到 qi的解答 ( Line 5 )，因此演算法就
進入 share phase ( Line 6 )，關於其細節，見下面文
章的說明。若B[ℎ(𝑞𝑖)] < 𝑞𝑖 . 𝑘，那代表我們無法使用
分享資訊取得 qi的解答，於是我們便使用 BFS來找
qi的解答( Line 9 )，關於 BFS的細節，見 3.2中的說
明。 
 
在 share phase中，我們利用 server之前儲存的資
料來加速 qi的處理。首先，我們將 B[h(qi)]中的資料
點根據與 qi的距離由小到大排序。接著在這些資料
中，取出前 k 筆資料，並放入 candidate(qi)中。
Candidate(qi)是一個 minheap，其儲存了 qi的 k 個候
選結果。演算法以 qi 為圓心，利用 qi 到第
candidate(qi)中第 k 筆資料的距離為半徑，畫一個圓，
這個區域稱為 search region（SR）。明顯的，SR 中
必定包含 k筆資料。接著我們只要快速地將 SR所包
含的 MBR取出，並抓出這些 MBR中所儲存的資料，
即可得到 qi的 kNN 結果。我們使用了 Section 4.2.2
中所設計的 R-Grid 來達到這個目的。 
在說明如何達到目的前，我們先說明兩個 R-Grid 
上重要的 operations ： 
 Bitwise OR operation (⋁ )： Grid(di)[j]  ⋁ 
Grid(di)[k]，代表將這兩個 bit vector 做
bitwise OR 的操作，其結果依然是一個 bit 
vector。 
 Bitwise AND operation (⋀ )：Grid(di)[j]  ⋀ 
Grid(di)[k]，代表將這兩個 bit vector 做
bitwise AND 的操作，其結果依然是 bit 
vector。 
有了上述兩個 operations 後，我們可以說明如何
快速地取得 SR 所涵蓋的 MBR。對於 di維度空間而
言，我們先找到它的一群子空間，這群子空間都和
SR 交集。以圖 8 為例。對於 d1維度而言，其子空
間 2、3、4和 SR交集。接著我們找出這些子空間對
應的 R-Grid column，並在這些 column 上做 bitwise 
OR operation。延續前例，我們取出 R-Grid(d1)[2]，
R-Grid(d1)[3]，及 R-Grid(d1)[4]，並做 bitwise OR 
operation，亦即：R-Grid(d1)[2]  ⋁R-Grid(d1)[3]  ⋁  R-
Grid(d1)[4]。其結果為一個 bit vector V(di)，若
V(di)[j]為 0，代表 MBR Nj「沒有被」SR cover，反
之，若 V(di)[j]為 1，表示 MBR Nj「可能被」SR 
cover。再延續前例，V(di) = {1,1,1,0,1,0}，這代表了
MBR N4及 N6沒有被 SR所 cover。做完上述步驟後，
我們可以得到 d個 bit vector，即 V(d1)，V(d1)，…，
V(dd)。 
之後再將這 d 個 bit vector 做 bitwise AND 
operation，得到一個 bit vector 𝒱。若𝒱[𝑗]為 1，代表
MBR Nj有和 SR 交集；反之，則代表 Nj沒有和 SR
交集。延續前例，V(d1) = {1,1,1,0,1,0}，且 V(d2) = 
{1,1,1,1,0,1}，於是得到𝒱 = V(d1) ∧ V(d2) = {1, 1, 1, 0, 
0, 0}。這代表MBR N1, N2, 及 N3有和 SR交集。於是
我們只需要檢查這 3個 MBR中所包含的資料，即可
以確定 q2的 3NN為何。我們檢查的方式很簡單，取
出所有的 MBRs，再取出這些 MBR中所包含的資料，
計算它們和 qi的距離，推入 candidate(qi)中。最後，
取出 candidate(qi)中的前 k 筆資料，它們便是 qi的
kNN。我們將 share phase的虛擬碼展示在 Algorithm 
2中。 
又不耗費太多的 memory，我們選擇𝛿 = 40 當作預
設值。 
6.3.2 The effect of the number of data points 
在這節中，我們試驗資料量的個數對於演算法效
能的影響。圖 13 及圖 14 分別展示了我們的演算法，
以及 BFS在不同資料量下的 CPU cost以及 I/O cost。 
 
圖 13 資料點個數對 CPU cost的影響。 
 
圖 14  資料點個數對 I/O cost的影響。 
在圖中可以發現，無論是 BFS或是我們的演算法，
隨著資料點個數變多，演算法所需要耗費的 CPU 
time及 I/O cost會逐漸變多。此外，我們也發現 BFS 
耗費的 CPU cost 隨著資料點個數增多而急遽上升。
然而Multiple kNN 表現的比 BFS 穩定， 其效能曲線
上升的較為緩慢。雖然 Multiple kNN的 CPU及 I/O 
cost 也隨著資料點個數上升而上升，但它仍然表現
的比 BFS 還要來的好。這是因為當查詢點可以透過
資訊分享的方式取得答案時，不需要花費多餘的 I/O 
Cost 即可取得資料點的資訊。如此，可使 I/O Cost 
及 CPU Time 的花費降低。 
5.3.3 Effect of the dimensionality 
在這個實驗中，我們展示了維度的多寡對演算法
效能的影響，其結果展示在圖 15 及圖 16 中。在這
裏，我們用 Ratio of benefit (RoB)來展示 Multiple 
kNN 和 BFS 的效能比。RoB 值越大，代表 Multiple 
kNN較 BFS越佳。RoB的計算方式如下： RoB = BFS 的效能− Multiple 𝑘NN 的效能BFS 的效能  
上述的「效能」部分，可以改為 CPU cost，或是
I/O cost。舉例而言，若要計算 Multiple kNN 對於
BFS在 CPU cost的 RoB的話，前述的公式可改為： 
RoB = BFS 的 CPU cost − Multiple 𝑘NN 的 CPU costBFS 的 CPU cost  
 
圖 15 不同維度下，Multip kNN和 BFS的 CPU cost比較。 
 
圖 16  不同維度下，Multip kNN和 BFS的 I/O cost比較。 
由圖中可以看出，這兩個演算法的效能都會隨著
維度的增加而變差。這是因為這兩個演算法都以 R-
tree為基礎，但 R-tree在維度變高時，會有效能下降
的傾向，這也是有名的「維度詛咒」現象 [13]。
Multiple kNN 在維度較低時，其效能遠遠凌駕於
BFS。雖然在較高的維度上，Multiple kNN的優勢較
不明顯，但其效能還是優於 BFS。 
7. CONCLUSION AND FUTURE WORK 
 
本計畫探討有效率的處理多個 kNN 查詢的問題。過
去傳統的 kNN 演算法都是重新計算每個查詢點。不
斷的重新計算，需要一直的重新存取資料庫，導致
系統整體效能下降。本計畫提出 R-Grid 索引方式及 
Multiple kNN algorithm 解決多查詢點的問題。利用 
R-Grid 索引，更清楚的掌握  MBR 的分佈情況。
Multiple kNN algorithm 以資訊分享的方式，有效率
的處理多查詢點的問題。 
我們以實驗來驗證 Multiple kNN 的效能，並且與現
有的傳統 kNN演算法 BFS比較。如同實驗所展示的， 
Multiple kNN 的整體效能比 BFS 的效能優越。 
在實驗中我們發現，無論是 Multiple kNN 或是 BFS 
在高維度時的效能都被 R-Tree 的效能所限制。因此
在未來的研究方向中，我們將針對 R-Grid 索引進一
步做改善。使 Multiple kNN 在高維度時的效能可以
更好。 
參考文獻 
 1 
IKE 2012參加國際會議心得報告 
鍾毓驥 於 101/07/31 
本人於七月十五日至七月十九日赴美國拉斯維加斯參與 IKE 2012國際會議。本會議附屬
於WORLDCOMP 2012這個綜合型會議，其下共有分成數十個領域，每個領域均有其所屬的
會議，並且有來自世界各國學者專家就前述各類領域的論文發表及實務經驗分享與討論。IKE 
2012的全名是 The 2012 International Conference on Information and Knowledge Engineering，屬
於資料處理相關的會議。其議程分成四天，共發表了 57篇論文。其會議的接受率為 27%，其
中有 17%的論文被選為 poster。 
我於七月十三日由台灣出發經 LA轉機，於七月十三日下午 04:00左右抵達拉斯維加斯。
由於會議舉辦的地點在Monte Carlo Resort，因此在會議舉辦的過程中，便入住在同樣的飯店
中。 
由於我的報告被安排在第二天，所以第一天時，就抱著輕鬆的心情去聽其他學者的演講。
在第一天的議程中，共有兩場議程同時舉行，一個是屬於軟體工程方法論的議程，另一個則
較偏向於 database application。由於自己對方法論的部分著墨不深，因此就去聽了
APPLICATIONS AND RELATED ISSUES這個議程。議程中有許多有趣的 idea被提出來。例
如有美法合作的學者提出智慧型交通號誌控制的想法。另外也有中國學者提出了新的 video 
content judgment系統。聽完這些有趣的報告，我深深體會創意的中要性，之前有些學者有提
過，所謂的創意，就是看到別人沒看到的機會。在這個議程中，我發現有許多的研究都是在
微小而不明顯之處，發現了令人著目的有趣點。 
第二天，也就是我的議程舉辦的時間點。由於發表時間被排在下午，因此上午便抱著緊
張的心情聽取其他學者的報告。值得一提的是，主辦單位將 IKE會議與另一個 GEM會議（The 
2012 International Conference on Genetic and Evolutionary Methods）合併舉辦（其實就是上午
為 GEM會議，下午則變成 IKE會議）。因此我上午聽的，其實便是 GEM會議的報告。GEM
會議的內容偏向人工知慧，機器學習。雖然之前只修過一些課程，但抱著學習的精神，也是
學到了不少東西。在上午10:30後，就是 IKE會議的開始。我選擇ONTOLOGIES + DATABASES, 
BIG DATA, VISUALIZATION, COMPRESSION, DATA PRIVACY, AND DATA MINING這個
session。會選擇它的理由很簡單，因為我的論文便被排在這個 session（只是在下午才會輪到
我發表）。在上午的聽講中，利用 fuzzy semantic來強化 database的 search system的論文最引
起我注意。這個想法其實不新，有許多過去的研究都對此有過著墨。本論文的作者群們提出
了一個架構，只要稍微修改 SQL 的語法，就可以讓原本的資料庫系統支援 fuzzy semantic。
由於這是作者們的初步成果，因此他們只做到了搜尋天氣的功能（例如只要用不精確地語義
描述“較冷”，或“較溼”即可搜尋類似這種天氣的城市。 
下午就是我的報告了。在本次會議中，我發表了利用 bitmap index來強化 query system效
率的論文。這篇論文的重點是建立一個索引架構，強化 range query的效率。和過去研究不一
樣之處，是這個 index系統並不 index data object，而轉而 index query object。在這場會議中我
發表了初步的成果，獲得了一些意見。這些意見會被加入延伸的成果中，並將擴充成期刋論
文來發表。 
剩下兩天由於報告已經結束，因此抱著輕鬆的心情聽取其他學者的報告。聽講的內容較
偏向 data mining的部分。雖然我的研究領域是資料處理，但對於這個領域中最紅的主題 data 
mining，一直沒有很深入的瞭解，也因此，在參加會議時，會較注意這個主題。在這些報告
中，有些主題非常地有趣，但也很實用。例如有學者提出了在 Twitter上做 text mining的想法。
其精神是分析使用者在 Twitter上發表的意見，得知使用者對於公司產品的想法（例如覺得產
品好，或產品普普通通）。透過這樣的 text mining的演算法，公司就不用再花錢去做市調了，
只需要分析社群網路上使用者的發言，就可以瞭解普羅大眾對產品本身的想法。 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/17
國科會補助計畫
計畫名稱: 在高維度環境中處理複雜之近似查詢
計畫主持人: 鍾毓驥
計畫編號: 100-2221-E-309-011- 學門領域: 資料庫系統及資料工程
無研發成果推廣資料
已獲得件數 0 0 100%  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
