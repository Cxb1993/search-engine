 
 
 
low-level features (color, shape, and texture), is used to 
retrieve images. Experimental results show that the 
performance of the proposed method is excellent when 
compared with that of QBIC CBIR system and the Zhang and 
Zhang’s proposed system. 
II. THE OVERVIEW OF SUPPORT VECTOR MACHINES 
From the viewpoint of image-semantics, each object has its 
activity scope. Finding the maximum and fair activity scope 
for every object in an image is the best way to guide hidden 
semantic concepts. Many existing linear classifiers 
(hyperplanes) can separate the space of object. However, 
only one achieves maximum separation. SVMs were a set of 
related supervised learning methods for pattern classification 
and function regression, which was developed by Vapnik [5]. 
It has also been proved to be very successful in many other 
applications such as handwritten digit recognition, face 
detection, and texture classification. A special property of 
SVM is known as maximum margin classifier which can 
simultaneously minimize the empirical classification error 
and maximize the geometric margin.  
 
A. Binary classification 
The primary technique of support vector machine (SVM) 
is using a high-dimension space to find a hyperplane to do 
binary division, where the achieved error rates are minimal. 
A SVM uses a portion of data to train the system and finds 
several support vectors that represent training data. These 
support vectors will be formed into a model and represented 
in a category using the SVM. According to this model, the 
SVM will classify a given unknown document by the 
following classification decision formula: 
}.1,1{,),,(),....,,( −+∈∈ yRxyxyx mnnii  
where (xi,yi),…,(xn,yn) are training samples, n is the number 
of samples, m is the input dimension, and y belongs to 
category of +1, -1, respectively. The constant y denotes the 
class to which the point xi belongs.  
If the training data are linearly separable, we can select 
these hyperplanes so that there are no points between them 
and then try to maximize their distance. By using geometry, 
we find the distance between the hyperplanes is 2/|w|, so we 
minimize |w|. To exclude data points, we need to ensure that i 
is either: 
1
1
−≤−⋅
≥−⋅
bXW
or
bXW i
  
However, it is not easy to find a hyperplane to classify the 
data in many problems. The SVM has several kernel 
functions in Ref[8], which applied to solve different 
problems. Selecting the appropriate kernel function can solve 
the problem of linear inseparability.  
B. Multiclass classification of SVM 
Many real-world classification problems involve more 
than two classes. Attempts to solve q-class problems with 
SVM have involved training q SVMs. Each of which 
separates a single class from all remaining classes, or training 
q(q-1)/2 machines. The first type of classifiers are usually 
called one-vs.-all and classifiers of the second type are called 
pairwise classifiers. When the one-vs.-all classifiers are used, 
a test point is classified into the class whose associated 
classifier has the highest score among all classifiers. In the 
case of pairwise classifiers, a test point is classified in the 
class which gets the most results from all the possible 
classifiers [6]. 
III. REGION-BASED IMAGE REPRESENTATION FOR HIDDEN 
SEMANTIC CONCEPT DISCOVERY 
The “hidden semantics discovery” concept requires that 
similarity measures for low-level visual features, such as 
color, texture, color layout, be defined. Ideally, what we try 
to measure is the semantic similarity which physically is very 
difficult to define, even to describe. Humans tend to use 
high-level concepts in everyday life. However, what exiting 
computer vision techniques can automatically extract from 
images are mostly low-level features. Object segmentation 
and recognition is the primary step of computer vision for 
applying to image retrieval of higher-level image analysis [3]. 
Automatic segmentation and recognition of objects via object 
models is a difficult task without a prior knowledge about the 
shape of objects. 
 Instead of segmentation and detailed object 
representation, several image-to-image similarity 
measurements that combine information from all of regions 
have been proposed [7]. Although the defined 
region-to-region similarities attempt to approximate the 
semantic similarity, the approximation is heuristic and not 
reliable. Hence, the retrieval accuracy is limited with these 
systems because not all of regions in an image that is 
semantically relevant with respect to a query image. The 
irrelevant regions hinder the accuracy of the captured hidden 
semantic concepts based on the low-level features of regions. 
To solve the problem, in [8] the authors suggest employing 
relevance feedback in retrieval to remove the irrelevant 
regions for improving the retrieval accuracy according to a 
region-based representation.  
Instead of identifying irrelevant regions using relevance 
feedback in this paper, we propose a region-based retrieval 
method to discover hidden semantic regions in an image 
using EM technique. The images in a database are first 
segmented into homogenous regions. A kind of color feature, 
called primitive, will be extracted to discover hidden 
semantics from each region using the EM technique. Then a 
novel method of semantic learning for content-based image 
retrieval using a decision boundary of support vector 
machine is proposed, which can decide the activity scope of 
an object. Last, the multiple low-level features such as color, 
shape, and texture and semantic-level features are extracted 
to represent the content of each region for the image retrieval.  
A. Image Segmentation and the Primitive Extraction 
 In this section, we will describe a kind of color feature 
called primitive which will be used for color image retrieval. 
The YIQ model is used as the color model. The image is first 
segmented into a disjoint regions, the mean color of region is 
represented its region. Assume that an image is segmented 
into n’s regions, that are, R1, R2, R3,…, Rn, and the region Ri 
has m’s neighbors. Let ),,()( iRiRiRi QIYRf =  denote the 
mean color of region Ri, and the primitive value of color is 
defined as: 
 
 
 
        
),(),(
),(),(
11
1
22
11
1
11
∑
=
∑
=
∑
=
∑
=
=
=
m
j
bj
n
j j
bnB
m
i i
a
m
i i
amA
yxyxC
yxyxC
r
r
                  (14) 
where ),( 11 yx  and ),( 22 yx denote the vectors of centroid 
position of objects A and B, respectively. For processing 
convenience, each vector in the space is subtracted by 
centroid and this result in translating the origin of the feature 
space the centroid. The centroid vectors ),( 11 yxC A
r and 
),( 22 yxCB
r  were chosen to construct the principal axis L of 
space. To find the support vectors, the vectors of objects A 
and B will be projected onto the principal axis. Let the 
projection scores vis and ujs associate with the same vectors 
ais and bjs, respectively. The projection scores of support 
vectors will be found as 
                
njuCDd
mivCDd
jAjV
iBiV
,...,1)),,((min
,,...,1)),,((min
2
1
==
==
rr
rr
            (15) 
where )(⋅D  denotes the distance metric using the Euclidean 
distance. The coordinates of support vector ia and jb on the 
principal axis can be calculated as 
),(),(
2)(2)(
)
1
2)(2)((
1
2)(2)(
)
1
2)(2)((
1
11
AC
y
BC
y
AC
x
BC
x
AC
yVd
AC
y
BC
y
AC
x
BC
x
BC
yVd
AC
y
BC
y
AC
x
BC
x
AC
xVd
A
CyBC
y
AC
x
BC
x
BC
xVd
vv yxP
rrrr
rrrrrrrr
rrrr
rrrrrrrr
rr
−+−
⋅−−+−+⋅
−+−
⋅−−+−+⋅
=  
),(),(
2)(2)(
)
2
2)(2)((
2
2)(2)(
)
2
2)(2)((
2
22
AC
y
BC
y
AC
x
BC
x
BC
yVd
AC
y
BC
y
AC
x
BC
x
AC
yVd
AC
y
BC
y
AC
x
BC
x
BC
xVdAC
y
BC
y
AC
x
BC
x
AC
xVd
VV
yxQ
rrrr
rrrrrrrr
rrrr
rrrrrrrr
rr
−+−
⋅−−+−+⋅
−+−
⋅−−+−+⋅
=
 (16) 
where
1V
d r and
2V
d r denote the projection scores of the support 
vectors ia  and jb  projected on the principal axis L 
according to eq. (16). A perpendicular bisector will be found 
by  
  .0),()cos,(cos
21212
21
2
21 =−−⋅−− ++ vvvvv
yvyvxvx yyxx rrrr
rrrr
βα  (17)  
The decision boundary of SVM is simple to obtain by 
.cos)(cos)()cos,(cos 2
)2
2
2
1
()2
2
2
1
(
2121
vyvyvxvx
vvvv xxxxd
rrrr
rrrr
−+−
−−+−= βαβα  (19) 
The support vector machine will be constructed using two 
classes of objects shown as Fig. 1.  
 
C. Multiclass Virtual SVM 
As image usually use more then two objects to represent 
the semantic of the image. The proposed scheme based on 
pairwise classifiers is used to solve the many classifier 
problems. To improve the effectiveness of the proposed 
method, the intermediate classification strategies in the style 
of ECC [12] is applied in the proposed method. The 
completing of proposed classification algorithm based on the 
multiclass SVM is given as follows.  
Algorithm 1: Proposed classification algorithm based on the 
multiclass SVM. 
Input: A set of objects which represents the semantic of an 
image. 
Output: A set of decision boundary function Fi which 
separate the semantic space of an image. 
Method: 
1. Let R denote the collection of object sequences 
( nrrr ,...,, 21 ) of an image, where each of them is 
constructed from the scanning of an image from 
left-to-right and top-to-bottom fashion. 
2. Let D and T denote a collection consisting of the object 
selected and empty initially. 
3. Select an object ri from R.  
4. While (R ≠  NULL) 
4.1. CR=ri. 
4.2. Let Rn denote the neighbor objects of CR in R. 
4.3. Find the centroid of object ri using eq. (14). 
4.3.1. While ( NULLRN ≠  ) 
4.3.2. Select the object rj from R, which is the 
neighbor object of the objects ri in R. 
4.3.3. Find the centroid of object rj using eq. (14). 
4.3.4. Construct the principal axis L using the 
centroid of objects ri and rj. 
4.3.5. Project the vectors of each object onto the 
principal axis using eq. (13). 
4.3.6. Find the projection position of support vector 
AS and BS  using the eq. (15). 
4.3.7. Find the decision boundary function Fi of SVM 
using the eq. (17). 
4.3.8. Remove the selected object rj from R, and add it 
to T. 
4.4. Remove the selected object ri from R, and add it to D. 
4.5. Remove the object in T, and add it to R. 
4.6. Select an object ri from R. 
5. Return the set of decision boundary function Fi. 
(a)    ,        : The center 
vector of each objects
(b)         : principal Axis of two objects
Object A
Object B
(c) :  Projection the vectors
on the principal axis
SA , SB: support vector of object A
and B, respectively. 
SA
SB
SA
SB
Q
1v
dr decision boundary
AC
r
BC
r
P
2v
dr
(d)                 :decision boundary 
 Fig.1. An example illustrates that the decision boundary will 
be decided using the support vector: (a) two objects are 
reserved to present the semantic of an image; (b) the 
principal axis is found using the centroid vectors connection; 
(c) projection of the vectors of each objects on the principal 
axis; (d) the decision boundary is decided by using eq.(18). 
IV. IMAGE RETRIEVAL STRATEGIES 
Three types of low-level features, i.e., color, shape, and 
texture are extracted from the objects of each database image. 
According to the QBIC method [13], the three low-level 
features are the color histogram, digital central moments and 
triple (contrast, coarseness, directionally) for color features, 
shape feature, and texture feature, respectively. In the QBIC 
 
 
 
SVM decision boundary. Moreover, special attention is paid 
to solve the problem of SVM decision boundary by principal 
axis analysis. The similarity measurement based on the 
proposed semantic distance metric has been defined to 
capture the perceptual and semantic meanings. Compared 
with Zhang and Zhang’s method, Zhang and Chen’s method, 
and QBIC method, the experimental results demonstrate that 
the proposed method outperforms other methods in terms of 
retrieval accuracy in the image database, which shortens the 
gap between the low-level feature and high-level semantic 
access methods. Some possible improvements and future 
research topics are as follows. 
Firstly, the proposed method can be extended to describe 
the semantic of images when there is a better way is provided 
to determine the threshold. Furthermore, the proposed 
method can also be useful for applications of semantic 
classification and image annotation.  
 
REFERENCES 
 
1. Y. Liu, D. Zhang, G. Lu, and W. Y. Ma, “A survey of 
Content-based image retrieval with high-level 
semantics,” Pattern Recognition, vol.40, pp262-282, 
2007.  
2. A. Mojsilovic, B. Rogowitz, “ISee: perceptual features 
for image library navigation,” Proc. Of the SPIE, Human 
Vision and Electronic Image, Vol. 4462, pp266-277, 
2002.  
3. Y. Rui and T. S. Huang, “Optimizing Learning in image 
retrieval,” in Proc. Of IEEE Int. CVPR, Jun. 2000.(3)  
4. Z. Wang, Z. Chi, D. Feng, and A. C. Tsoi,” 
Content-based image retrieval with relevance feedback 
using adaptive processing of tree-structure image 
representation, Int. J. Image Graphics, 3(1), pp. 119-144, 
2003. 
5. V. Vapnik,” The nature of statistical learning theory,” 
New York: Springer-verlag; 1995. 
6. H.-C. Kim, S. Pang, H.-M. Je, D. Kim, B. Yang, and 
Sung, “Constructing support vector machine ensemble,” 
Pattern Recognition, 36(12), pp. 2757-2767, Dec. 2003.  
7. A. W. M. Smeulders, M. Worring, A. Gupta, and R. Jain, 
“Content-based image retrieval at the end of early 
years,” IEEE Trans. Pattern. Anal. Machine Intell., 
22(12), pp 1349-1380, 2000. 
8. R. Zhang and Z. Zhang, Hidden semantic concept 
discovery in region based image retrieval,” in Proc. Of 
IEEE Int. Conf. on Computer Vision and Pattern 
Recognition (CVPR’04), 2004.  
9. M. Karger and S. Sandomirsky, “Multidimensional 
statistical technique for detection of low contrast 
geochemical anomalies,” J. of geochemical Exploration, 
72, pp.47-58, 2001.  
10. S. C. Cheng and T. L. Wu, “Subpixel edge detection of 
color images by principal axis analysis,” Pattern 
Recognition, 38, pp. 527-537, 2005.  
11. B. Kolman, Introductory linear algebra with applications, 
Prentice-Hall, Inc. 1997.  
12. Y. Yao, G. Y. Marcialis, M. Pontil, P. Frasconi, and F. 
Roli, “ Combining flat and structured representations for 
fingerprint classification with recursive neural networks 
and support vector machines,” Pattern Recognition, 
36(2), pp. 397-406, 2006.  
13. M. flickner, H. Sawhney, W. Niblack, J. Ashley, Q. 
Huang, B. Dom, M. Gorkani, J. Hafner, D. Lee, D. 
Petkovic, D. Steele, and P. Yanker,” Query by image and 
video content: the QBIC system, IEEE Computer, 28(9), 
pp23-32, 1995.  
14. C. Zhang, and T. Cheng,”An Active Learning 
Framework for Content-based Information retrieval,” 
IEEE trans. On Multumedia, 4(2), pp.260-268, June 
2002.  
Table 1. The results of the average number for the ratio of 
capturing the semantic of an image using the different 
category of database images. 
The ratio of capturing the semantic of an image (%)
The category 
of image 
7.0=ρ
 
8.0=ρ  85.0=ρ
 
9.0=ρ  
scenes 46 80 85 86 
persons 60 84 90 87 
animals 42 84 90 88 
plants 45 80 91 92 
traffics 44 79 90 88 
buildings 45 75 90 90 
sports 55 78 91 92 
pictures 45 80 93 89 
arts 45 82 92 90 
others 48 84 90 90 
10 20 30 40 50 60 70 80 90 100
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of retrievals
Pr
ec
is
io
n
 
 
Proposed method
Zhang and Zhang method
Zhang and Chen method
QBIC method
 
Fig.4. Average precision versus number of retrievals. 
10 20 30 40 50 60 70 80 90 100
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of retrievals
R
ec
al
l
 
 
Proposed method
Zhang and Zhang method
Zhang and Chen method
QBIC method
 
Fig. 5. Average recall versus number of retrievals. 
 1
Abstract 
This paper presents the recognition of shapes for object retrieval in image databases 
using skeleton-based and contour-based representation by discrete curve evaluation and two 
consecutive primitive edges. Humans tend to use high-level concepts in everyday life. 
However, the existing computer vision techniques that can automatically extract data from an 
image find mostly low-level features. Object segmentation and recognition is the primary 
step of computer vision to achieve image retrieval of high-level image analysis. 
Contour-based and skeleton-based representations are important for object recognition in 
different areas. In comparing the contour-based approaches with the skeleton-based 
approaches for object representation, the contour-based is more sensitive to noise than a 
skeleton-based approach based on a good skeleton pruning method, but a rough shape 
classification can be performed since the obtained skeletons do not represent any shape 
details. In this paper, we proposed a novel method to integrate the contour-based approaches 
with skeleton-based approaches for object representation. The contour-based and 
skeleton-based representations are based on the proposal of two consecutive primitive edges 
method and discrete curve evolution method respectively. Experimental results demonstrate 
that the performance of the proposed algorithm is superior to Torsello and Hancock’s method 
[41] in terms of retrieval accuracy and execution speed. 
Keywords: Skeleton, shape similarity measure, visual parts, discrete curve evolution 
 
 3
shape-based retrieval of similar objects [10]. In general, the shape recognition problem can be 
approached with three main frameworks [11]: The statistical approach uses global shape 
features such as moments [12], autoregressive coefficients [13], and Fourier descriptor [11] to 
recognize shapes. A hybrid approach is the method combining the statistical (or 
decision-theoretic) and syntactic (or structure) approaches to shape recognition [14]. They are 
not difficult to compute global features but the local structures of shape cannot be described 
in detail. Part-based representations of shape features allow for recognition that is robust in 
the presence of occlusion, movement, growth, and deletion of portions of an object, and play 
an important role in theories of categorization and classification. There is strong evidence for 
part-based representations in human vision [15]. Hoffman and Richards [15] provide strong 
evidence that shape features are psychologically segmented into visual parts.  
In the past, contour and skeleton were usually used to analyze and represent the shape of 
objects. Contour-based is an important aspect of human visual perception. Polygonal 
approximation has been a very popular shape representation technique. It not only 
satisfactorily represents a shape, but also significantly reduces the amount of processing data 
for further applications. Therefore, many shape recognition (matching) methods through 
polygonal approximation [14,16,17] have been proposed. However, some conventional 
methods are somewhat sensitive to non-consistent results of polygonal approximation. For 
example, the method [14] using attributed string matching cannot accurately define the edit 
distance (cost) for insertion and deletion operations. Other methods, such as the shape 
matching using polygonal approximation and dynamic alignment [17] and recognition 
schemes based on relative distance of feature points (polygonal vertices) from the centroid 
may have the same segmentation problem, which will potentically reduce the recognition rate 
or increase the processing time for better segmentation results. The system [18] analyzes each 
image to extract features that show strong evidence of presence in these objects. These 
 5
approaches for overcoming skeleton instability are based on skeleton pruning. Pruning can 
either be performed implicitly as a post processing step or integrated in the step of 
skeletonization computation. In general, the skeletonization algorithms can broadly be 
classified into four types: (1) the first type is thinning algorithms, such as those with shape 
thinning and the wave front/grassfire transform [26,27] .These algorithms iteratively remove 
border points, or move to the inner parts of an object in determining an object’s skeleton. 
These methods usually preserve the topology of the original object with many redundant 
branches, but they are quite sensitive to noise and often fail to localize the accurate skeletal 
position. In addition, it is important to determine a good stop criterion of this iterative process; 
(2) the second type is the category of discrete domain algorithms based on the Voronoi 
diagram [28,29]. These methods search the locus of centers of the maximal disks contained in 
the polygons with vertices sampled from the boundary. The exact skeleton can be extracted as 
the sampling rate increases, but the time of computation is usually prohibitive; (3) the third 
type of algorithms is to detect ridges in a distance map of boundary points [30,31]. 
Approaches based on distance maps usually ensure accurate localization but does not 
guarantee that the skeleton can connect completely. Under the completeness the skeleton 
branches representing all significant visual parts are present; (4) the fourth type of algorithms 
is based on mathematical morphology [32,33]. Usually, these methods can localize the 
accurate skeleton, but may not guarantee the connectivity of the skeleton [33].   
In comparing the contour-based approaches with the skeleton-based approaches for 
object representation, the contour-based approach is more sensitive to noise than 
skeleton-based approach based on a good skeleton pruning method, but a rough shape 
classification can be performed since the obtained skeletons do not represent any shape 
details.  In this paper, we proposed a method to integrate the contour-based approaches with 
skeleton-based approaches for object representation. The contour-based and skeleton-based 
 7
original object or equivalently how to identify the noisy points. The discrete curve evolution 
(DCE) is proven experimentally and theoretically to eliminate the noisy points [35,36]. 
However, none of the existing skeleton pruning methods yields satisfactory results without 
user interaction. In this paper, the proposed skeleton growing with DCE is based on a subset 
of vertices which are pre-selected from the contour of shape. This subset can also be viewed 
as a partitioning of original-polygon contour into contour segmentation defined by 
consecutive vertices of the simplified polygon.  
2.1. The Proposed Contour Sampling Method using Discrete Curve Evolution 
GHT [37] was initially proposed to represent a planar set D with arbitrary boundary 
using a so-called R-table [38]. As an example shown in Fig. 1, the boundary of the planar set 
D can be described by geometric relationship between the centroid XR of D and the boundary 
point X’s. According to the R-table in GHT to represent the boundary in question can be 
constructed as:  
).,(),...,,(),,(
),,(),...,,(),,(
),,(),...,,(),,(
),,(),...,,(),,(
332211
3
3
3
3
2
3
2
3
1
3
1
33
1
2
1
2
2
2
2
2
1
2
1
22
1
1
1
1
2
1
2
1
1
1
1
11
n
k
n
kkkkkk
nn
nn
nn
rrr
rrr
rrr
rrr
αααφ
αααφ
αααφ
αααφ
M
                        (1) 
where iφ  is the common slope for the tangent line passing through the boundary points 
njx ji ,...,1, = . However, the information of R-table in GHT cannot link information of 
boundary into the planar set D in an image, and it is also difficult to express which boundary 
is a significant visual part.  
    The characters of significant visual part in a contour have be proposed in literature 
[15,35]. We can summarize the observation into four rules:  
(1) These visual parts are defined to be “convex” or “nearly convex shape” from the rest of 
object at concavity extrema.  
 9
[2]. In the chain-code process, the point coded moves along the digital curve or edge pixels 
with 8-adjacency model in 8-direct code. This assumes that the chain-code with 8-adjacency 
in a 3×3 block is limited to a multiple of 450 and it is quantized to be the nearest multiple of 
450. A boundary chain starts with a random point in the edge pixels. Each edge pixel has 8 
neighboring points among which there is at least one edge point. The boundary chain-code is 
the direction description of current point aj to the next one aj+1, and the chain-code can be 
defined as 
               1+→= jjj aae                              (2) 
where ej denotes the number 0 to 7 for a description in 8-direction chain-code.  
ei ei+1
(g)
aj aj+1 aj+2 aj aj+1
aj+2ei e i+
1
aj aj+1
aj+2
ei
ei+1
(a)                                 (b)                         (c)
aj+2
aj aj+1
ei
ei+1
aj+2
aj aj+1
ei ej+1
ei
aj aj+1
aj+2
e j+
1
(d)                                   (e)                       (f)
aj aj+1
aj+2
ei ej+1
 
Fig.2 shows the possible 7 types of visual parts in a 3×3 block. 
 
The boundary in a planar set D can be described with a start point and a series of 
sequence direction codes. There are some problems of chain-code method: (1) the chain-code 
varies dramatically with different start points. Selecting the proper start point on the 
chain-code is a common process; (2) the chain-code method cannot be applied to the rotation 
and scaling of D. Based on this reason, the consecutive primitive edge is proposed to describe 
 11
descending order ( )... 7321 NNNN ≤≤≤≤  associates the same ordering to the CPEis  
                        721 ,..., CPECPECPE ≤≤≤                          (6) 
A ratio is decided to reserve how much of the visual parts can represent the object as the 
significant visual parts and the remainder will be ignored. The ratio ρ is defined by  
                         ∑
≤≤
∑
≤≤≤
71
1
j
jN
pi
iN
ρ                                 (7) 
where p (p<7) denotes preceding sequences in eq. (7). It is important to determine a good 
stop criterion of the ratio selected. However, the ratio ρ  selected usually appears in a 
variety of application-dependent cases. When the ratio is higher, it will preserve the topology 
of the original object with many redundant branches, but they are quite sensitive to noise and 
often fail to localize the accurate turning point. When the ratio is smaller, it can usually 
ensure accurate localization but neither guarantees connectivity nor completeness. According 
to the property of the CPE, the number of visual parts belongs to straight boundary and (or) 
near straight boundary is the most occurred in all of objects. It can preserve the perceptual 
appearance sufficiently for object recognition when the ratio ρ  is assigned as 0.1.  
A skeleton similarity measure is useful for object-based retrieval in image databases 
should be according to our perception. This basic property leads to the following 
requirements: 
(1) A skeleton similarity measure shall permit recognition of perceptually similar objects that 
are not mathematically identical. 
(2) It shall preserve significant visual parts of objects. 
(3) It shall not depend on scale, orientation, or position of objects. 
(4) A skeleton similarity measure is universal, in the sense that it allows us to identify or 
distinguish objects of arbitrary skeleton, i.e. no restrictions on shapes are assumed.  
 13
as Fig. 4, the curvature of ci is 
                    2/3)2)('1(
)(''
xf
xf
i +
=Ω                           (9)  
the average of curvatures is computed as 
                         
n
n
T N
Ω++Ω+Ω= ...21χ                           (10)           
the pruning point should be found as 
                             Tii χ≥Ω−Ω + || 1                           (11) 
r
f
c
i
),( yxυ
 
Fig. 4 shows the curvatureΩ of a point ci at the function f. 
 
Rule 3. If a straight boundary is between the neighbors of two turning points, then the 
pruning point is determined using the center of the straight boundary. 
Rule 4. The skeleton should be grown according to the boundary points set ℜ  of the object, 
which include turning points set Ti and pruning points set Pj, and defined 
as mjniPT ji ,...,1,,...,1)},{}{{ ==∪=ℜ .  
Rule 5. Connect skeleton points which are found using the boundary point set ℜ  and 
turning points Ti’s, the skeleton arc of the object is found. 
2.2. Skeleton Growing 
Assume that ai-1, ai, and ai+1 denote two consecutive points, and the ai is a turning point 
 15
)(tan)( 11 xxyy −=− φθ                         (16) 
The straight line L1 should intersect another line L2 in the object. Let the L2 define as  
                    gx+hy+i=0                             (17) 
Combining the equations (16) and (17), it is assumed that the homogeneous system has a 
nontrivial solution. The nontrivial solution of system should be found by performing of 
Guass-Jordan reduction procedure [39] on the augmented matrix [M|0]. The result is  
⎥⎦
⎤⎢⎣
⎡
0
0
|
|
1
0
0
1
2
1
k
k
                        (18) 
where ki,i=1,2 are the ratios of x and y. Based on the reduction results, the values of x2 and y2  
has the intersect point between straight line L1 and L2, and can be computed as 
                             ),(),(
2
2
2
11
2
2
2
2
1
1
1
22
kk
k
kk
kyx
++++
= .            (19)           
The skeleton point should be found as 
                              ),( 2
21
2
21 yyxxs ++=                          (20) 
Based on the skeleton point sets ,ks mnk +=  is found from the boundary points set ℜ  of 
the object. The skeleton arc comes into being according to the following algorithm.   
Algorithm 1: Proposed the skeleton arc of object comes into being. 
Input: Two boundary point sets {Ti} and mjniPT ji ,...,1,,...,1)},{}{{ ==∪=ℜ  
Output: A skeleton arc of the object comes into being.  
Method:  
1. Let S denote the collection of all the skeleton point sets sk, and empty initially. 
2. Let E denote the completed skeleton arc of an object and empty initially. 
3. while )( NULL≠ℜ  
 Find a skeleton point using a boundary point in ℜ  by the equation (20). 
 17
to encode the boundary of an object with visual-pattern block by block along the edge pixels. 
Hence, two given object blocks from along the boundary pixel can be encoded and can 
indicate which visual-pattern is mapped. If we have a shape of an object such as Fig. 1, the 
R-table can be modified based on the proposed TCPE as                                
)),,,(,()),...,,,,(,()),,,,(,( 1015432232101 aaaaaaaaaaaa nnn +ΓΓΓ ααα     (22) 
where α  is belonging to the type of virtual-pattern in Fig. 6, a0 and an denote the start-point 
and end-point respectively. To obtain the consistency of TCPE for any structure of objects, 
two decision rules are considered: (1) the starting boundary and ending boundary overlap; (2) 
the scanning sequence uses the anticlockwise method in the boundary of object.  
1                         2                       3             4                      
5                       6                        7           8
9                      10                      11               12
13                    14                      15                16                    
 
  Fig.6. Possible sixteen types of visual patterns in a square block. 
 
4. Similarity measurement of object representation 
Consider a database DB consisting of a large number of objects. Each of them is 
represented as a high-dimensional feature vector },,{ βΦΓ=F , where ,,ΦΓ andβ denote the 
feature vector of TCPE, skeleton arcs, and skeleton branch in an object, respectively. The 
feature vector of TCPE can further be represented as },...,1;16,...,1},,{{ njipf ji ===Γ , 
where fi and pj are ith feature and the corresponding number of TCPE in Fig. 6, respectively. 
 19
Let },...,1},,,{{ 1 nissX
a
i
a
i
a
i == + θ and ),...,1},,,{{ 1 mjssY bjbjbj == + θ be the feature vectors 
of skeleton arcs. Then the distance between X and Y is computed as 
                                   || saY
sa
X
sa WWD −=                     (28) 
: Boundary of object
:Pruning point decision
:Skeleton arcs
:Skeleton Branch
e1
e2
b1 b2
b3
b4
b5 b6
s1
s2
s3
s4
s5
s6
s7e3
e4
e5
e6
 
Fig. 7. An example of representing an object by the boundary of object, skeleton arcs, and a 
skeleton branch. 
 
The feature vector of a skeleton branch can further be represented as 
},...,1,,...,1,},,,{{ nkmjibee kjii ===φ shown as Fig. 7, where bk denotes the skeleton 
branch, and ei and ej are the boundary edges of object, which is connecting to the skeleton 
branch bk. A weight of a skeleton branch in an object can be found as 
                             ∑
=
= n
i
sb
i
sb WW
1
                         (29) 
and the sbiW is defined as  
                              
                      
⎪⎩
⎪⎨
⎧
>
>
=
ijjs
is
jiis
js
sb
kb sswhen
sswhen
W
,
,
 .                   (30) 
Let },...,1,,...,1,},,,{{ 11 nkmjibeeX xk
x
j
x
i ===  and },...,1,,...,1,},,,{{ 11 nnmmlbeeY ynymyl ===  
be the description vectors of a skeleton branch. Then the distance between X and Y is 
 21
    In order to evaluate the proposed approach, a series of experiments were conducted on 
an Intel PENTIUM-IV 3GHz PC. A skeletal measure method proposed by Torsello and 
Hancock’s method [41] is also simulated by computer software for the purpose of 
performance comparison. An image database which consisted of 1266 binary objects is 
extracted from scenery images. Each object image in database is first formatted to 256×256 
for testing the retrieval approach. Before the evaluation, human assessment was done to 
determine the relevant matches in the database to the query object image. The top 100 
retrievals from both the Torsello and Hancock’s method and the proposed approaches were 
marked to decide whether they were indeed visually similar in skeleton and contour.  
It is difficult to derive a formal method in evaluating the retrieval accuracy of an image 
database system. Traditional metrics for evaluating performance are recall and precision. 
They are functions of both correct matches and the relevance of database images to a query. 
The retrieval accuracy measured by recall and precision is computed as following. Recall 
measures the ability of the system to retrieval all the images that are relevant and defined as  
relevancesall
retrievedcorrectlylevancescall ReRe =  . 
Precision measures the ability of the system to retrieve only images that are relevant and can 
be computed by 
                    
retrievedall
retrievedcorrectlyrelevancesecision =Pr . 
Recall and precision require a ground truth to assess the relevance of images for a set of 
significant queries. 
Fig. 8 shows some objects and their corresponding skeletons using the proposed method.  
According to the simulation results, the proposed algorithm provides a dramatic method on 
the skeleton represented from its corresponding object. Fig.10 shows the statistics of every 
 23
10 20 30 40 50 60 70 80 90 100
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Number of retrievals
Pr
ec
is
io
n
 
 
Proposed method using skeleton and contour features
Proposed method using  contour features
Proposed method using  skeleton features
Torsello and Hancock's  Method
0 20 40 60 80 100
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Number of retrievals
R
ec
al
l
 
 Proposed method using skeleton and contour features
Proposed method using  contour features
Proposed method using  skeleton features
Torsello and Hancock Method
 
                (a)                                   (b) 
Fig.11. Average precision and recall versus number of retrieved image: (a) Precision; (b) 
Recall. 
 
300 400 500 600 700 800 900 1000 1100 1200 1300
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
0.6
0.65
Number of images
A
ve
ra
ge
 re
tr
ie
va
l t
im
e
 
 Proposed method using skeleton and contour features
Proposed method using  contour features
Proposed method using  skeleton features
Torsello and Hancock Method
 
 Fig. 12. Average retrieval time (in seconds) versus the size of database. 
 
Fig. 12 shows the performance comparison in terms of the average retrieval time (in seconds) 
with response to a query using the proposed method and Torsello and Hancock’s method. The 
proposed method is faster than Torsello and Hancock’s method. And hence, this proposed 
method can be used for practical applications. Fig.13 and Fig. 14 show the retrieval examples 
of the proposed method using a binary object image. 
 
 25
References 
1. A. D. Bimbo, 1999,” Visual Information Retrieval,” Margan Kaufimann Publishers, Inc., 
San Francisco, California.  
2. M. Flickner, H. Sawhney, W. Niblack, J. Ashley, Q. Huang, B. Dom, M. Gorkani, J. 
Hafner, D. Lee, D. Petkovic, D. Steele, and P. Yanker1995, ” Query by image and video 
content: The QBIC system,” Comp., 28(9), pp. 23-32.  
3. S. C. Pei and C. M. Cheng, 1999, “Extracting Color features and dynamic matching for 
image database retrieval,” IEEE Trans. On Circuit and Systems for Video Technology, 
9(3), pp. 501-512. 
4. B. Manjunath and W. Ma, 1996, ”Texture feature for browsing and retrieval of image data, 
“ IEEE Trans. Pattern Anal. Machine Intell., 18, pp. 837-842.  
5. A. K. Jain and A. Vailaya, 1996, “Image Retrieval using color and shape,” Pattern 
Recognition, 29(8), pp. 1233-1244.  
6. Y. Rui, T. S. Huang, and S.-F. Chang, 1999,”Image retrieval: current techniques, 
Promising direction and open Issues,” J. Vis. Commun. Image Representation, 10, pp. 
39-62. 
7. M. W. Smeulders, S. Santini, A. Gupta, and R. Jain, 2000,”Content-based image retrieval 
at the end of early years, “ IEEE Trans. Pattern Anal. Mach. Intel., 22, pp. 1340-1380. 
8.  J. Z. Wand, J. Li, and Widerhold, 2001, Semantic-sensitive integrated matching for 
picture libraries, IEEE Trans. Pattern Anal. Mach. Intel., 23(9), pp. 947-963. 
9.  H. Blum, 1973, “Biological shape and Visual Science (Part I),” J. Theoretical Biology, 
38, pp. 205-287. 
10. D. Forsyth, J. Malik, R. Wilensky, 1997, “Searching for digital pictures, Scientific Am., 
pp. 88-93, June. 
11. E. Person and K.S. Fu, 1997, “Shape discrimination using Fourier descriptors,” IEEE 
 27
their shock graphs,” IEEE Trans. Pattern Anal. Mach. Intell., 26(5), pp.550-571. 
23. L. J. Latecki, R. Lakamper, and U. Eckhardt, 2000, “Shape Descriptors for Non-rigid 
Shapes with a Signal closed Contour,” Proc. CVPR. 
24.  S. C. Zhu and A. Yuille, 1995, “FORMS: a Flexible Object recognition and Modeling 
System,” Internal. Conf. Computer Vision, 20-23 June, pp. 465-472. 
25.  T. Liu, D. Geiger, and R. V. Kohn, 1998, “ Representation and Self-Similarity of 
Shapes,” Internal. Conf. Computer Vision, 4-7 June, pp. 1129-1135. 
26. W. Xie, R. P. Thompson, and R. Perucchio, 2003, “A topology-preserving parallel 3D 
thinning algorithm for extracting the curve skeleton,” Pattern Recognition, 36, pp. 
1529-1544. 
27. F. Leymarie and M. Levine, 1992, “Simulating the grassfire transaction form using an 
active Contour model,” IEEE Trans. PAMI, 14(1), pp. 56-75. 
28. R. L. Ogniewicz and O. Kubler, 1995,” Hierarchie Voronoi skeletons,” Pattern 
Recognition, 28(3), pp. 343-359. 
29. J. W. Brandt and V. R. Algazi, 1992, “Continuous skeleton computation by Voronoi 
diagram, Comput. Vision, Grophics, Image Process, 55, pp. 329-338. 
30. W.-P. Choi, K.-M. Lam, and W. C. Siu, 2003,“ Extraction of the Euclidean skeleton based 
on connectivity,” Pattern Recognition, 36, pp. 721-729. 
31. Y. Ge and J. M. Fitzpatrick, 1996, “On the Generation of Skeletons from Discrete 
Euclidean Distance Maps,” IEEE Trans. PAMI. 18(11), pp. 1055-1066. 
32. K. Siddiqi, S. Bouix, A. R. Tannenbaum, and S. W. Zucker, 2002,” Hamiton-Jacobi 
Skeletons,” Internal. Journal of Computer Vision, 48(3), pp. 215-231. 
33. A. Vasilevskiy and K. Siddiqi, 2002,”Flux Maximizing Geometric Flows,” IEEE Trans. 
PAMI, 24(12), pp.1565-1578. 
34. H. Blum, 1973, “ Biological Shape and Visual Science,” J. Theoretical, 38, pp. 205-287. 
