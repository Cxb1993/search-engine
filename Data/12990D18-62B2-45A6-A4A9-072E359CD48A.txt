possess wide applications in real world in recent 
years, such as transactional records, web-flow or 
click-stream records, etc. There is possibly some 
hidden information in the streaming data which are 
valuable but not easy to find out. The natural 
features of data streams such as variable 
transmission rate and peak volume have brought out 
many constraints. As a result, data mining in data 
streams is much more difficult than that in 
databases. Besides, the characteristic or 
distribution of data in a data stream usually changes 
dynamically with time, which phenomenon is 
called ’concept drift’. Concept drifts in data 
streams are a practical problem which will badly 
affect the mining performance or mining quality of a 
mining system. However, the problem has rarely been 
considered in the research of frequent-pattern mining 
so far. 
 
In this project, we propose a method for concept 
drift handling as well as frequent pattern mining in 
dynamic data streams. Our study includes data-concept 
definition, concept modeling, concept representation, 
and the method of count-approximation based mining. 
The designed mining method records part of the 
itemsets in a data stream as the synopsis. To 
accomplish the mining task, it approximates for the 
unrecorded itemsets using the synopsis and then 
selects the frequent ones. By building the model of 
correlation between the frequencies of different 
itemsets (as a mapping function), the mining method 
is able to understand and represent the concept 
hidden in the streaming data. When a concept drift 
occurs in the data stream, the mining method knows 
the new concept by re-building the model (or 
incrementally adjusting the model). The problem of 
concept drift is solved accordingly. The study in 
this project shows some potential issues about 
concept drift in data-stream frequent-pattern mining, 
which would bring about new research topics. For 
those real-life applications having high-degree 
demand for the discovery of data-stream frequent 
  
行政院國家科學委員會專題研究計畫 成果報告 
 
於概念漂移的動態資料串流環境下 
有效挖掘頻繁樣式的估算式探勘方法 
研究成果報告(精簡版) 
 
計畫類別： 個別型 
計畫編號： NSC 100－2221 －E－005 －088 － 
執行期間： 100 年 08 月 01 日至 101 年 07 月 31 日 
 
執行機構及系所：國立中興大學資訊科學與工程系(所) 
計 畫 主 持 人：賈坤芳 
計畫參與人員：博士班兼任研究助理 李兆偉 
計畫參與人員：博士班兼任研究助理 許智為 
計畫參與人員：碩士班兼任研究助理 施宇涵 
 
 
報 告 附 件：出席國際學術會議心得報告及發表論文 
 
處 理 方 式：本計畫可公開查詢 
 
 
 
 
中   華   民   國  101  年  7  月  31  日 
Abstract 
 
Data mining is a process of finding interesting knowledge from a world of data 
stored in databases. Recently, knowledge discovery communities have focused on a 
new form of data presentation, where data arrive in the form of continuous streams. It 
is often referred to as “data streams”. Data streams possess wide applications in real 
world in recent years, such as transactional records, web-flow or click-stream records, 
etc. There is possibly some hidden information in the streaming data which are 
valuable but not easy to find out. The natural features of data streams such as variable 
transmission rate and peak volume have brought out many constraints. As a result, data 
mining in data streams is much more difficult than that in databases. Besides, the 
characteristic or distribution of data in a data stream usually changes dynamically with 
time, which phenomenon is called “concept drift”. Concept drifts in data streams are a 
practical problem which will badly affect the mining performance or mining quality of 
a mining system. However, the problem has rarely been considered in the research of 
frequent-pattern mining so far. 
 
In this project, we propose a method for concept drift handling as well as frequent 
pattern mining in dynamic data streams. Our study includes data-concept definition, 
concept modeling, concept representation, and the method of count-approximation 
based mining. The designed mining method records part of the itemsets in a data 
stream as the synopsis. To accomplish the mining task, it approximates for the 
unrecorded itemsets using the synopsis and then selects the frequent ones. By building 
the model of correlation between the frequencies of different itemsets (as a mapping 
function), the mining method is able to understand and represent the concept hidden in 
the streaming data. When a concept drift occurs in the data stream, the mining method 
knows the new concept by re-building the model (or incrementally adjusting the 
model). The problem of concept drift is solved accordingly. The study in this project 
shows some potential issues about concept drift in data-stream frequent-pattern mining, 
which would bring about new research topics. For those real-life applications having 
high-degree demand for the discovery of data-stream frequent patterns, the mining 
system with our proposed mining method will bring them essential helpfulness. 
 
Keywords: (Data Mining; Data Stream; Frequent Pattern; Count Approximation; Data 
Concept; Concept Drift) 
 
 2 
2. 研究問題及目標 
 
如果以進行資料串流探勘時所要處理的時間長度或資料涵蓋範圍進行區分，
可以歸納出三種不同的資料處理模型 [22]，分別是里程碑模型、滑動時間窗模型，
以及衰退式模型。里程碑模型(landmark window model) [19, 23, 24] 所劃定的探勘
範圍是從稱為「里程碑」的某個特定時間點開始直到目前時間點為止，在這個範
圍內包含的每一筆資料對探勘結果的產生都具有同等重要性。滑動時間窗模型
(sliding window model) [5, 6, 21] 的探勘範圍總是只包含最近期的資料元件，因此
會隨著時間推進而逐漸捨棄過去的舊資料。時間窗大小的計算可分為兩種方式：
以時間長度計算（例如距今幾個單位時間內的資料），或者以資料元件數量計算（例
如最近的幾筆交易）。衰退式模型(damped window model) [3, 4] 與滑動時間窗模
型有些類似，主要差別在於其加入「權重值」的概念，進一步將探勘範圍內的資
料元件劃分為更小的時間窗，並區分其重要程度；較新的時間窗會設定較高的權
重值，反之較舊的時間窗則設定較低的權重值。本計畫是使用滑動時間窗模型，
從固定資料元件數量的時間窗範圍中探勘出資料串流的頻繁項目集。 
 
    給定一個由交易紀錄組成的資料串流，以及兩個使用者設定的參數(最小支持
度的計數值門檻以及表示滑動時間窗大小的數值)，本計畫的目標在於設計一個資
料串流探勘方法，根據滑動時間窗模型，從可能發生概念漂移的串流資料中找出
最近期的頻繁樣式。更具體而言，當使用者要求探勘結果時，我們要從包含在目
前時間窗內的資料串流元件中，尋找出現次數達到最小支持度的頻繁項目集(並傳
回給使用者)。欲達成這個目標，有幾項議題需要處理。首先，我們要針對頻繁樣
式探勘領域的資料串流，定義所謂的「概念」以及「概念漂移」。其次，我們要
設計描述和認知資料串流概念的方式。再者，我們要提出以估算支持度來發掘頻
繁項目集的有效探勘方法，以及在概念漂移發生時的處理方式。本計畫的頻繁樣
式探勘方法有兩項主要訴求：（1）具備時間以及空間上的高效率性，亦即快速的
資料處理速度以及少量的記憶體使用量。（2）能夠提供可接受的探勘準確度，並
且在資料串流發生概念漂移現象時能夠避免準確度大幅降低，維持探勘結果的品
質。 
 4 
為 1 及長度為 2 的項目集與其出現次數。對於一個長度在 3 以上的項目集，例如
abc，CA 將其不同長度的子集合的計數值總和（亦即 |a|+|b|+|c| 與 |ab|+|bc|+|ac| 的
值）作為參數代入排容原理估算公式，經過交換計算而得到公式中交集項 |a∩b∩c| 
的數值，對應到項目集 abc 之計數值(的近似值)。在這個例子中，CA 並未實際掃
瞄資料來源，而是透過數學公式和一些子集合的計數值資訊，便可以迅速求出 abc
的(近似)計數值。這種估算式探勘方法，其優點在於高執行速度以及低記憶體用
量。CA 只需要記錄屬於基底部分的項目集及其計數值；當有探勘需要時，首先快
速進行計數值的估算，接著從中找出滿足最小支持度的頻繁項目集作為結果即
可。至於其缺點則是透過估算程序求出項目集計數值的方式容易受到資料來源的
資料分佈之影響，使得估算值的誤差產生較大變動。 
「概念漂移」是一個在資料串流環境下相當重要的議題。在資料串流這種動
態環境中，因為資料的特徵可能隨著時間流逝而有所不同，若是始終採用一個模
型去進行預測或者發掘知識，到頭來將會得出品質不佳甚至是錯誤的結果。例如，
依照歷史資料來進行客戶族群的預測，可能在歷史資料過舊的狀況下無法準確預
測新進資料的類別。 
目前在資料串流環境下嘗試解決概念漂移問題的研究多是屬於分類的領域，
其中一種有效且具有代表性的方法為「合議分類器」(Ensemble Classifier) [18, 19]。
這個方法對每一個資料區塊建立一個分類器，並根據每一個分類器的正確率和建
構時間等因素給予適當的權重值。此權重值不但會影響最終輸出結果，亦會決定
某個分類器是否該被淘汰，藉以達到一定的效率和準確度。將所有分類器搭配其
權重值結合成最終的(合議)分類器，用以對新進資料進行類別預測。根據新進資
料，會建立新的分類器和修正原有分類器的權重值。除上述方法之外，尚有一些
研究者提出不同的技術來解決分類領域中的概念漂移問題，例如 CVFDT [13] 和
WAH [10]。這些技術利用分類器在無法適用新資料時正確率會突然降低之現象，
來發現概念漂移的發生並藉以重建或修正分類器，作為演算法在資料概念不穩定
（會變動）之情況下的解決方案。 
近年來，概念漂移已逐漸成為資料串流探勘研究中的一個熱門研究議題。然
而多數的研究皆從機器學習的角度去處理關於分類(classification)的概念漂移現
象，對於探勘頻繁樣式(frequent pattern)和關聯規則(association rule)的概念漂移問
題則尚未出現代表性的研究成果。這主要的原因在於探勘頻繁樣式的處理複雜度
（必須考慮不同屬性之間的關聯性）遠大於分類的處理複雜度（僅對一組輸入屬
性給予一個輸出類別），使得頻繁樣式的資料概念(concept)難以明確定義。即使是
在分類學習領域中的可行方法，例如合議分類器，也因為問題特性和複雜度的差
異而無法套用在解決頻繁樣式探勘領域的概念漂移問題。 
 6 
 
圖 4.2. 連續長度與間隔長度的項目集在出現頻率之間的關聯性 
 
假設我們可以知道前述之隱含於資料中的「關聯性」，表示當我們已知某些項
目集的頻率時，便能夠(以預估方式)知道這些項目集增長而成的(超)項目集的頻
率。參考延續自圖 4.2 的圖 4.3，其中頻率以支持度的觀點、藉由區塊的大小和梯
度來表示。圖 4.3 表示一個項目集的支持度可以使用一個(對映)函數 f 從其子項目
集的支持度（作為引數）計算獲得。這個函數可能是線性的或者是非線性的，其
表示項目集頻率之間相互關係的法則。而在函數中用來塑模(modeling)關聯性的參
數或者係數，就相當於資料串流中的資料概念。 
 
 
圖 4.3. 以函數表示項目集支持度之間的相互關係 
 
4.2. 支持度估算式探勘方法 
 
若我們有辦法得到像 f 這樣的函數，例如透過學習，便能夠藉由瞭解項目集頻
率之間的關聯性而具體地認知並且表示資料概念。至於尋找頻繁樣式所使用的探
勘方法也需要基於這樣的資料概念模型來設計，才能夠處理概念漂移的議題。 
為了達到研究目標，即概念漂移資料串流中的頻繁樣式探勘，我們採用一種
計數值估算(count approximation)的資料串流探勘方式，根據此方式設計出一個能
解決概念漂移的頻繁樣式探勘方法。此探勘方法會記錄並維護一部分關於資料串
流的摘要資訊(synopsis information)，並在使用者發出要求時，使用此記錄的摘要
資訊來產生出探勘結果(即,頻繁樣式)。這裡的「摘要資訊」係指串流資料中包含
的項目集以及對應之支持度(即,出現頻率)。在所有可能出現的項目組合中，有記
 8 
 
4.3. 探勘演算法與概念漂移處理 
 
根據支持度估算的方式，我們提出了一個名為 CPM 的頻繁樣式探勘演算法，
其虛擬碼呈現於圖 4.5 中。這個演算法使用滑動時間窗模型，並採取批次模式處理
接受到的串流資料。資料串流的第一批資料元件(作為樣本)用來取得前述之描述
支持度關聯性的實例資料。根據這些實例，CPM 演算法使用線性迴歸技巧建立一
組估算函數（估算器），每一個函數對應到一個長度在 3 以上的項目集階層。當估
算器建立完成後，接著根據計數值估算的方式來處理接踵而來的串流資料。每次
接收到一個批次的串流資料元件時，CPM 演算法列舉出資料中長度為 1 以及長度
為 2 的項目集，連同它們的計數值一起記錄於資料結構中（作為摘要資訊）。屬於
滑動時間窗之最舊批次的摘要資訊接著會從資料結構中被移除。我們所使用的資
料結構為查閱快速且節省空間的前綴樹(prefix tree)。當使用者下達探勘要求時，
 
 
圖 4.5. 資料串流頻繁樣式探勘演算法 CPM 
 10 
5. 實驗評估結果 
 
本節報告我們探勘方法的實測效能表現。我們透過執行實驗以評估 CPM 演算
法的「時間效率」與「空間效率」，並且比較有針對概念漂移做處理與未做概念漂
移處理的方式，觀察兩者在「探勘準確度」方面的差異。時間效率部分以處理完
測試資料所花費的執行時間來衡量，空間效率部分以維護摘要資訊的記憶體使用
量來衡量，至於探勘結果的準確度以綜合了 precision（精確度）以及 recall（完整
度）的 F-measure 指標來衡量。 
實驗平台採用個人電腦，配備 Pentium 2.80 GHz 的雙核心處理器以及大約 2.95 
GB 的可用記憶體空間，並安裝 Windows XP Professional 2002 SP3 的作業系統。探
勘演算法的程式以 C++編寫並以 Dev C++編譯。實驗的測試資料為一個包含兩種
資料概念、有概念漂移現象的虛擬資料集，實際上由兩個以不同參數產生的人工
資料集結合而成，大小為 100 萬筆交易。表 5.1 列出測試資料集的相關參數。從表
中可以發現，分屬於兩個概念的資料，在內含屬性數量、最大交易長度、平均交
易長度等部分皆有相當明顯的差異。測試資料集在實驗中以循序讀取方式來模擬
交易紀錄（資料元件）陸續抵達的資料串流；在接收到大約 50 萬筆交易時，資料
串流的概念會由 A 轉變為 B，亦即發生概念漂移。 
 
表 5.1. 測試用概念漂移資料集之描述 
資料概念 交易筆數 屬性數量 
最大 
交易長度 
平均 
交易長度 
頻繁樣式 
平均長度 
Concept A 499,243 2,000 28 8.29 4 
Concept B 500,757 1,500 41 15.23 8 
 
以下敘述實驗方式以及相關設定。本實驗中的(滑動)時間窗大小定為 25 萬筆
交易，並且劃分為 5 個獨立區段，每一個區段的大小為 5 萬筆交易。每次從資料
串流接收到 5 萬個資料元件時，便作為一個批次進行處理（記錄摘要資訊）。CPM
演算法使用包含 5 萬筆交易的串流資料序列來建立其估算支持度的對映函數，預
設在開始處理資料串流之前會先建立一組估算函數。最小支持度的參數值範圍介
於 0.1%與 1.0%之間。給定一個最小支持度值，資料串流頻繁樣式的探勘結果每隔
25 萬筆交易便產生並輸出一次。圖 5.1 說明各個滑動時間窗和資料串流之資料概
 12 
5.2. 探勘準確度之實驗結果 
 
我們接著進行關於探勘準確度的實驗。準確度的高低使用 F-measure 來評估；
愈高的 F-measure 分數代表愈高的準確度（即找到愈多的正確答案以及產生愈少的
錯誤答案），也表示探勘結果的品質愈高。為了測試所提方法針對概念漂移現象的
處理能力，本實驗中測試了 CPM 與 CPM
+
這兩個方法，並且互相比較。對於概念
漂移的資料串流，CPM 方法(在最初)會建構一組對映函數，並且在整個探勘期間
固定使用該組函數來估算項目集支持度（以找出頻繁項目集）。相較之下，CPM
+
方法在概念漂移之後會(用新的樣本)重新建構一組對映函數，並在後續的探勘作
業中使用新建構的函數來估算項目集支持度。換句話說，在兩個方法中，CPM
+
有
針對概念漂移做處理（而 CPM 則沒有）。 
我們將本實驗的結果呈現於圖 5.3。本實驗測試了 0.5%（較大）以及 0.4%（較
小）兩個不同的最小支持度，其中後者相較於前者會導致更多的頻繁項目集需要
被發掘。從圖中可以發現，當尚未發生概念漂移時，亦即在第一個與第二個時間
窗，CPM 和 CPM
+
兩個方法可以達到幾近相同的高準確度。然而，在概念漂移發
生後，CPM 方法的準確度大幅降低。以最小支持度 0.4%為例，從第二個時間窗到
(概念漂移後的)第三個時間窗，CPM 的 F-measure 分數下跌了將近 30 個百分比。
主要原因在於其建立的對映函數已不適合經過改變的串流資料概念（在估算項目
集支持度時會產生可觀的誤差值）。相較之下，CPM
+
方法的 F-measure 分數並未有
大幅度的減少，維持在約 90%的可接受程度。這個實驗顯示出，在串流資料概念
發生改變時配合著更新(相當於概念描述的)對映函數，可以在準確度方面有效地
處理概念漂移所帶來的問題。綜合本項實驗以及前項實驗的結果，可以證明我們
所提出的頻繁樣式發掘方法對於探勘概念漂移資料串流擁有良好的表現。 
 
圖 5.3. 最小支持度為 0.5%(左)及 0.4%(右)之探勘準確度之實驗結果 
 
 14 
7. 參考文獻 
 
[1] R. Agrawal, T. Imielinski, and A. Swami, “Mining association rules between sets 
of items in large databases,” Proceedings of the 1993 ACM SIGMOD International 
Conference on Management of Data, 1993, pp. 207–216. 
[2] R. Agrawal and R. Srikant, “Fast algorithms for mining association rules,” 
Proceedings of the 20th International Conference on VLDB, 1994, pp. 487–499. 
[3] J. H. Chang and W. S. Lee, “Finding recent frequent itemsets adaptively over 
online data streams,” Proceedings of the 9th ACM SIGKDD International 
Conference on Knowledge Discovery and Data Mining, 2003, pp. 487–492. 
[4] J. H. Chang and W. S. Lee, “Finding recently frequent itemsets adaptively over 
online transactional data streams,” Information Systems, 31(8), 2006, pp. 849–869. 
[5] J. Cheng, Y. Ke and W. Ng, “Maintaining frequent closed itemsets over a sliding 
window,” Journal of Intelligent Information Systems, 31(3), 2008, pp. 191–215. 
[6] Y. Chi, H. Wang, P. S. Yu, and R. R. Muntz, “Moment: maintaining closed frequent 
itemsets over a stream sliding window,” Proceedings of the 4th IEEE International 
Conference on Data Mining, 2004, pp. 59–66. 
[7]  M.M. Gaber, A. Zaslavsky, and S. Krishnaswamy, “Data Stream Mining,” Data 
Mining and Knowledge Discovery Handbook, 2010, pp. 759–787. 
[8] N. Jiang and L. Gruenwald, “Research issues in data stream association rule 
mining,” ACM SIGMOD Record, 35(1), 2006, pp. 14–19. 
[9] M. N. Garofalakis, J. Gehrke, and R. Rastogi, “Querying and mining data streams: 
you only get one look,” Proceedings of the 2002 ACM SIGMOD International 
Conference on Management of Data, 2002, pp. 635. 
[10] G. Widmer and M. Kubat, “Learning in the presence of concept drift and hidden 
contexts,” Machine Learning, 23(1), 1996, pp. 69–101. 
[11] J. Han, M. Kamber, and J. Pei, “Data Mining: Concepts and Techniques (3rd 
edition),” Morgan Kaufmann, San Francisco, CA, USA, 2011. 
[12] J. Han, J. Pei, and Y. Yin, “Mining frequent patterns without candidate generation: 
a frequent-pattern tree approach,” Data Mining and Knowledge Discovery, 8(1), 
2004, pp. 53–87. 
[13] G. Hulten, L. Spencer and P. Domingos, “Mining time-changing data streams,” 
Proceedings of the 7th ACM SIGKDD International Conference on Knowledge 
 16 
 
國科會專題研究計畫 出席國際學術會議心得報告 
                                  日期： 101 年 6 月 30 日 
                                 
一、參加會議經過 
本次參加的研討會為 FSKD 2012 國際會議，於 2012 年 5 月 29 日至 5 月 31 日在中國重慶市舉
行。FSKD 研討會包含知識發現基礎（Knowledge Discovery Foundations）、模糊理論與演算法（Fuzzy 
Theory and Algorithms）、模糊應用（Fuzzy Applications）等數個主要的討論主題；我們的研究內容
與投稿論文屬於「知識發現基礎」的範疇。本人於 5 月 28 日搭乘華信航空班機，前往會議所在地
的中國重慶市，入境後於當日抵達會場並進行註冊與報到手續。我們的論文被安排在 5 月 30 日上
午進行發表，該場次的發表/討論內容包括了關於分類、分群、頻繁樣式等之資料探勘基礎理論以
及實務應用。在本人做完簡報並和與會者進行意見交流之後，會議場次順利結束。 
 
二、與會心得 
FSKD 研討會今年已經是第九次舉辦，參與者來自世界各地（以亞太地區占多數），研究主體
囊括資訊科學和資訊工程的各個範疇。會議中由各個領域的專家學者介紹自己的研究成果，討論當
今新潮、熱門的研究議題。參加此次會議，不僅獲得一次使用英文進行簡報的寶貴機會，對於研究
計畫的後續發展，甚至於個人研究領域的廣度、深度等，都有相當深刻的助益。另外，透過與其他
學者的討論，除了可以相互解答疑惑以及激發創意，更能夠認識相關領域的研究專家，建立人脈、
擴展研究領域。此行參加會議讓本人以及整個計畫團隊收穫良多。 
 
三、攜回資料內容 
FSKD 2012 論文集一本(第三冊)、FSKD 2012 論文集電子檔光碟一片、出席會議紀念品。 
計畫編號 NSC 100－2221 －E－005 －088 － 
計畫名稱 於概念漂移的動態資料串流環境下有效挖掘頻繁樣式的估算式探勘方法 
出國人員
姓名 
李兆偉 
服務機構 
及職稱 
國立中興大學資訊科學與工程系(所) 
博士班兼任研究助理 
會議期間 
101年 5月 29日至 
101年 5月 31日 
會議地點 
中國重慶市 
重慶萬友康年大酒店 
會議名稱 The 9th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2012) 
發表論文
題目 
Using Count Prediction Techniques for Mining Frequent Patterns in Transactional Data Streams 
(發表論文內容檢附於後,共 5頁) 
 18 
In the model, a window which slides with time is present. The 
window always covers a certain number of most recent 
elements and the mining task at any time point focuses on 
elements within the current window. Yet another class takes 
the damped window model [17, 18, 19]. In the model, each 
element is associated with a weight which is relative to the 
time. Newly-received elements have higher values of weight 
than earlier-received elements. 
In the area of classification, the term concept is considered 
as the whole distribution of the problem in a certain time point 
[6], which is represented by the joint distribution of the input 
(attributes) and the output (classes). Therefore, a concept drift 
represents a change in the distribution of the problem, which 
may be an unconditional change, a conditional change, or a 
dual change [7]. There are studies on handling concept drifts 
in online learning. In [9], the concept of model granularity is 
introduced, which results in a rule-based stream classifier. The 
authors showed that with a classifier of finer granularity, the 
local components in the classifier being affected by a concept 
can be pinpointed efficiently. In [8], the authors proposed a 
general framework of weighted ensemble classifiers. The 
classifiers in the ensemble are individually weighted based on 
their expected classification accuracy on the testing data. In 
[10], the authors presented an approach which builds a global 
set of classifiers and pertinently selects classifiers from the set 
to form the ensemble as well as represent the current concept 
of the stream. 
In the literature on data-stream frequent-pattern mining, 
regardless of the processing model being adopted, existing 
methods cope with the data of a data stream either element by 
element [13, 14, 20] or batch by batch [3, 4, 5]. There are 
several notable methods. Manku and Motwani proposed an 
algorithm called Lossy Counting [3]. The algorithm uses an 
error parameter ε to ensure that no false-negative answers are 
present as well as the errors in individual itemset counts are 
bounded. Leung and Khan proposed a tree structure called 
DSTree [4]. The tree captures the contents of transactions in a 
sliding window to support exact stream mining. Li and Jea 
proposed the SWCA algorithm [16] which includes the 
application of the theory of approximate inclusion-exclusion 
[15]. The algorithm discovers frequent itemsets through a 
procedure called support approximation. Yu et al. proposed an 
algorithm called FDPM [5] which is based on the Chernoff 
bound. The algorithm uses a running error parameter to prune 
itemsets (control mining quality) and uses another reliability 
parameter to control memory size. However, to our best 
knowledge, most methods in the literature do not refer to the 
significant issue on data stream mining, namely concept drift. 
III.  PROBLEM DESCRIPTION 
We define the basic terms related to the problem of this 
search as follows. Let I = {xa, xb, …, xm} be a set of attributes 
where an attribute corresponds to an item. An itemset is a 
subset of I and also called a pattern. The length of an itemset 
is the number of items included in the itemset. Itemsets with a 
length of n are in the nth order and called n-itemsets. A 
transaction is a set of items, and it supports an itemset X if X 
is a subset of it. An itemset is supported at most once by a 
transaction. The frequency count or simply the count of an 
itemset in a set of transactions is the number of occurrences 
that the itemset has within the transaction set. With respect to 
a threshold of count, an itemset is called frequent or large if its 
count is equal to or greater than the threshold; otherwise it is 
called infrequent. 
A data stream over I is a continuous sequence of elements 
where each element is a transaction. The concept of the data 
stream at a certain point of time refers to the data as well as 
the distribution of the data at that time. In terms of frequent 
pattern mining, it would be characterized by both the 
frequency counts of items and the frequency correlations 
between different items and/or itemsets. A concept drift 
therefore represents a change in either the data or the 
distribution of the data, or possibly in both. Concept drifts 
would let the set of frequent itemsets vary from time to time. 
Given a data stream of transactions in which the concept 
may change with the time, together with two user-specified 
parameters, namely a count threshold called minimum support 
(ms) and a window size to the sliding window (sw), the goal of 
this research is to discover frequent itemsets from recent data 
elements of the data stream effectively. More specifically, we 
are to find the itemsets whose counts (i.e., numbers of 
occurrences) equal or exceed ms×sw, from the data elements 
within the current sliding window, each time as there is a 
request for frequent patterns. 
IV.  PROPOSED METHOD 
To solve the problem described above, we adopt a 
prediction-based mining approach. The frequency correlations 
between different items result in different frequencies of the 
combinations of items, that is, the itemsets. As long as the 
correlations (which are abstract) can be learned or modeled, 
we would predict the frequency counts of longer itemsets even 
if we do not know them, based on the frequency counts of 
single items and/or shorter itemsets. Once the counts of 
itemsets are known through count prediction, the frequent 
itemsets can be decided according to the minimum support. As 
a result, we record itemsets of the first two orders including 
their counts and use them to predict the counts of higher-order 
iemsets (which are not recorded). To describe the issue of 
count prediction more specifically, given two frequency counts 
concerning itemsets in the first two orders, a value of count is 
predicted for an itemset being the superset of the itemsets. A 
function or model is thus necessary for the procedure of count 
prediction. 
For the purpose of predicting the frequency counts of 
itemsets, we employ the technique of regression analysis 
which is widely used for forecasting and prediction. In 
regression analysis, an observed dataset of instances is 
necessary for constructing the so-called predictive model or 
regression function. In this research, an instance consists of 
the frequency count of a higher-order itemset and the two 
counts of its first-two-order subsets. In other words, there are 
one dependent variable (i.e., the count of an itemset) and two 
independent variables (i.e., the counts of its subsets in the 1st 
and 2nd orders) in the prediction procedure. The way to 
generate the instances is described as follows. A subsequence 
of the data stream is taken, and the itemsets which are frequent 
in the data subsequence are discovered and stored in the data 
 20 
We have conducted several experiments to evaluate the 
performance of the proposed algorithm namely CPM, and the 
results are presented in this section. The experiments were 
carried out on a personal computer with a Pentium 2.80 GHz 
dual-core CPU and about 2.50 GB of available memory. The 
operating system is Windows XP Professional SP3. The 
program of the CPM algorithm is implemented in C++. 
We use artificial data to simulate the data source, namely a 
concept-drifting data stream. The testing dataset has one 
million of transactions, and it is actually composed of two 
synthetic datasets representing distinct concepts, say, A and B. 
Each dataset is generated by the synthetic data generator of 
IBM [21] and has a size of approximately 500 thousands of 
transactions. Table I shows the statistics of the testing dataset. 
The setting to the experiments is described as follows. The 
sliding window is 250 thousands of transactions in size and 
divided conceptually into 5 panes, that is, 50 thousands of 
transactions per pane. Elements of the testing data stream are 
processed batch by batch, where the size of a batch 
corresponds to that of a pane. The CPM algorithm takes a 
sequence of fifty-thousand transactions to construct the 
models for count prediction. The range of minimum support is 
between 0.1% and 1.0%. The answers of frequent itemsets are 
mined and outputted as an outcome every separate sliding 
window. Fig. 2 illustrates the relationship between the sliding 
windows and the concepts of the data stream. As one can see 
from the figure, a concept drift happens between the second 
and third sliding windows. 
We first present the experimental results of running time 
and memory consumption in Fig. 3, where the value of 
minimum support is 0.5%. According to the figure, the 
performance of the CPM algorithm, in terms of both runtime 
and memory, is stable across the sliding windows having the 
same concept of data (for example, at sliding windows #1 and 
#2). More importantly, it is not affected greatly by the concept 
drift (that is, from sliding window #2 to sliding window #3). 
The proposed method counts and records itemsets of the first 
two orders, so the synopsis it has to keep is generally small in 
scale. No matter what concept the stream is currently in and/or 
what value the minimum support is specified, it can efficiently 
process the received data elements and maintain the extracted 
synopsis. This is the reason for the stable performance. 
The next experiment tests for mining quality in terms of 
accuracy. The accuracy (of a frequent-itemset mining outcome) 
is assessed by the F-measure which is the harmonic mean of 
the precision and recall (of the outcome). The higher an 
F-measure (ranging from 0% to 100%) is, the better the 
mining accuracy/quality is. Two methods are tested and 
compared with each other in the experiment, namely CPM and 
CPM+. In regard to the concept-drifting data stream, CPM 
constructs a group of predictive models and uses it 
consistently to count-prediction based mining over the stream, 
while CPM+ constructs individual groups of predictive models 
upon the concepts and uses them to count-prediction based 
mining respectively. In other words, CPM+ is for addressing 
concept drifts while CPM is not. We show the result of the 
experiment in Fig. 4, where two values of minimum support 
were specified namely 0.5% (larger) and 0.4% (smaller). In 
the figure, CPM and CPM+ achieve much the same 
high-accuracy before the concept drift, that is, at sliding 
windows #1 and #2. However, as the concept drift happens, 
the accuracy of CPM falls severely, for example, by nearly 
30% at the minimum support of 0.4%. The reason is that the 
constructed count-prediction models (describing a concept) do 
not fit the changed concept anymore. On the other hand, 
CPM+ retains acceptable accuracy without a major decrement 
because the reconstructed count-prediction models adapt to the 
altered concept. According to this experiment, CPM+ would 
handle concept drifts effectively. Taking the results of all the 
experiments together, it is observed that the proposed 
algorithm possesses a satisfactory performance in mining 
frequent itemsets from a concept-drifting data stream. 
VI.  CONCLUSIONS 
Data streams are dynamic sources to data mining 
algorithms. The concept in a data stream may change with the 
time, which could affect the performance of a data-stream 
 
Figure 2.  Relationship between the sliding windows and the stream concepts. 
 
Figure 3.  Experimental results of running time (left) and memory consumption (right). 
國科會專題研究計畫 出席國際學術會議心得報告 
                                  日期： 101 年 6 月 30 日 
                                 
一、參加會議經過 
本次參加的研討會為 FSKD 2012 國際會議，於 2012 年 5 月 29 日至 5 月 31 日在中國重慶市
舉行。FSKD 研討會包含知識發現基礎（Knowledge Discovery Foundations）、模糊理論與演算法
（Fuzzy Theory and Algorithms）、模糊應用（Fuzzy Applications）等數個主要的討論主題；我們的
研究內容與投稿論文屬於「知識發現基礎」的範疇。本人於 5 月 28 日搭乘華信航空班機，前往會
議所在地的中國重慶市，入境後於當日抵達會場並進行註冊與報到手續。我們的論文被安排在 5
月 30 日上午進行發表，該場次的發表/討論內容包括了關於分類、分群、頻繁樣式等之資料探勘
基礎理論以及實務應用。在本人做完簡報並和與會者進行意見交流之後，會議場次順利結束。 
 
二、與會心得 
FSKD 研討會今年已經是第九次舉辦，參與者來自世界各地（以亞太地區占多數），研究主體
囊括資訊科學和資訊工程的各個範疇。會議中由各個領域的專家學者介紹自己的研究成果，討論
當今新潮、熱門的研究議題。參加此次會議，不僅獲得一次使用英文進行簡報的寶貴機會，對於
研究計畫的後續發展，甚至於個人研究領域的廣度、深度等，都有相當深刻的助益。另外，透過
與其他學者的討論，除了可以相互解答疑惑以及激發創意，更能夠認識相關領域的研究專家，建
立人脈、擴展研究領域。此行參加會議讓本人以及整個計畫團隊收穫良多。 
 
三、攜回資料內容 
FSKD 2012 論文集一本(第三冊)、FSKD 2012 論文集電子檔光碟一片、出席會議紀念品。 
 
計畫編號 NSC 100－2221 －E－005 －088 － 
計畫名稱 於概念漂移的動態資料串流環境下有效挖掘頻繁樣式的估算式探勘方法 
出國人員
姓名 
李兆偉 
服務機構 
及職稱 
國立中興大學資訊科學與工程系(所) 
博士班兼任研究助理 
會議期間 
101年 5月 29日至 
101年 5月 31日 會議地點 
中國重慶市 
重慶萬友康年大酒店 
會議名稱 The 9th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2012) 
發表論文
題目 
Using Count Prediction Techniques for Mining Frequent Patterns in Transactional Data Streams 
(發表論文內容檢附於後,共 5頁) 
                                                                                                                                          1168
In the model, a window which slides with time is present. The 
window always covers a certain number of most recent 
elements and the mining task at any time point focuses on 
elements within the current window. Yet another class takes 
the damped window model [17, 18, 19]. In the model, each 
element is associated with a weight which is relative to the 
time. Newly-received elements have higher values of weight 
than earlier-received elements. 
In the area of classification, the term concept is considered 
as the whole distribution of the problem in a certain time point 
[6], which is represented by the joint distribution of the input 
(attributes) and the output (classes). Therefore, a concept drift 
represents a change in the distribution of the problem, which 
may be an unconditional change, a conditional change, or a 
dual change [7]. There are studies on handling concept drifts 
in online learning. In [9], the concept of model granularity is 
introduced, which results in a rule-based stream classifier. The 
authors showed that with a classifier of finer granularity, the 
local components in the classifier being affected by a concept 
can be pinpointed efficiently. In [8], the authors proposed a 
general framework of weighted ensemble classifiers. The 
classifiers in the ensemble are individually weighted based on 
their expected classification accuracy on the testing data. In 
[10], the authors presented an approach which builds a global 
set of classifiers and pertinently selects classifiers from the set 
to form the ensemble as well as represent the current concept 
of the stream. 
In the literature on data-stream frequent-pattern mining, 
regardless of the processing model being adopted, existing 
methods cope with the data of a data stream either element by 
element [13, 14, 20] or batch by batch [3, 4, 5]. There are 
several notable methods. Manku and Motwani proposed an 
algorithm called Lossy Counting [3]. The algorithm uses an 
error parameter ε to ensure that no false-negative answers are 
present as well as the errors in individual itemset counts are 
bounded. Leung and Khan proposed a tree structure called 
DSTree [4]. The tree captures the contents of transactions in a 
sliding window to support exact stream mining. Li and Jea 
proposed the SWCA algorithm [16] which includes the 
application of the theory of approximate inclusion-exclusion 
[15]. The algorithm discovers frequent itemsets through a 
procedure called support approximation. Yu et al. proposed an 
algorithm called FDPM [5] which is based on the Chernoff 
bound. The algorithm uses a running error parameter to prune 
itemsets (control mining quality) and uses another reliability 
parameter to control memory size. However, to our best 
knowledge, most methods in the literature do not refer to the 
significant issue on data stream mining, namely concept drift. 
III.  PROBLEM DESCRIPTION 
We define the basic terms related to the problem of this 
search as follows. Let I = {xa, xb, …, xm} be a set of attributes 
where an attribute corresponds to an item. An itemset is a 
subset of I and also called a pattern. The length of an itemset 
is the number of items included in the itemset. Itemsets with a 
length of n are in the nth order and called n-itemsets. A 
transaction is a set of items, and it supports an itemset X if X 
is a subset of it. An itemset is supported at most once by a 
transaction. The frequency count or simply the count of an 
itemset in a set of transactions is the number of occurrences 
that the itemset has within the transaction set. With respect to 
a threshold of count, an itemset is called frequent or large if its 
count is equal to or greater than the threshold; otherwise it is 
called infrequent. 
A data stream over I is a continuous sequence of elements 
where each element is a transaction. The concept of the data 
stream at a certain point of time refers to the data as well as 
the distribution of the data at that time. In terms of frequent 
pattern mining, it would be characterized by both the 
frequency counts of items and the frequency correlations 
between different items and/or itemsets. A concept drift 
therefore represents a change in either the data or the 
distribution of the data, or possibly in both. Concept drifts 
would let the set of frequent itemsets vary from time to time. 
Given a data stream of transactions in which the concept 
may change with the time, together with two user-specified 
parameters, namely a count threshold called minimum support 
(ms) and a window size to the sliding window (sw), the goal of 
this research is to discover frequent itemsets from recent data 
elements of the data stream effectively. More specifically, we 
are to find the itemsets whose counts (i.e., numbers of 
occurrences) equal or exceed ms×sw, from the data elements 
within the current sliding window, each time as there is a 
request for frequent patterns. 
IV.  PROPOSED METHOD 
To solve the problem described above, we adopt a 
prediction-based mining approach. The frequency correlations 
between different items result in different frequencies of the 
combinations of items, that is, the itemsets. As long as the 
correlations (which are abstract) can be learned or modeled, 
we would predict the frequency counts of longer itemsets even 
if we do not know them, based on the frequency counts of 
single items and/or shorter itemsets. Once the counts of 
itemsets are known through count prediction, the frequent 
itemsets can be decided according to the minimum support. As 
a result, we record itemsets of the first two orders including 
their counts and use them to predict the counts of higher-order 
iemsets (which are not recorded). To describe the issue of 
count prediction more specifically, given two frequency counts 
concerning itemsets in the first two orders, a value of count is 
predicted for an itemset being the superset of the itemsets. A 
function or model is thus necessary for the procedure of count 
prediction. 
For the purpose of predicting the frequency counts of 
itemsets, we employ the technique of regression analysis 
which is widely used for forecasting and prediction. In 
regression analysis, an observed dataset of instances is 
necessary for constructing the so-called predictive model or 
regression function. In this research, an instance consists of 
the frequency count of a higher-order itemset and the two 
counts of its first-two-order subsets. In other words, there are 
one dependent variable (i.e., the count of an itemset) and two 
independent variables (i.e., the counts of its subsets in the 1st 
and 2nd orders) in the prediction procedure. The way to 
generate the instances is described as follows. A subsequence 
of the data stream is taken, and the itemsets which are frequent 
in the data subsequence are discovered and stored in the data 
                                                                                                                                          1170
We have conducted several experiments to evaluate the 
performance of the proposed algorithm namely CPM, and the 
results are presented in this section. The experiments were 
carried out on a personal computer with a Pentium 2.80 GHz 
dual-core CPU and about 2.50 GB of available memory. The 
operating system is Windows XP Professional SP3. The 
program of the CPM algorithm is implemented in C++. 
We use artificial data to simulate the data source, namely a 
concept-drifting data stream. The testing dataset has one 
million of transactions, and it is actually composed of two 
synthetic datasets representing distinct concepts, say, A and B. 
Each dataset is generated by the synthetic data generator of 
IBM [21] and has a size of approximately 500 thousands of 
transactions. Table I shows the statistics of the testing dataset. 
The setting to the experiments is described as follows. The 
sliding window is 250 thousands of transactions in size and 
divided conceptually into 5 panes, that is, 50 thousands of 
transactions per pane. Elements of the testing data stream are 
processed batch by batch, where the size of a batch 
corresponds to that of a pane. The CPM algorithm takes a 
sequence of fifty-thousand transactions to construct the 
models for count prediction. The range of minimum support is 
between 0.1% and 1.0%. The answers of frequent itemsets are 
mined and outputted as an outcome every separate sliding 
window. Fig. 2 illustrates the relationship between the sliding 
windows and the concepts of the data stream. As one can see 
from the figure, a concept drift happens between the second 
and third sliding windows. 
We first present the experimental results of running time 
and memory consumption in Fig. 3, where the value of 
minimum support is 0.5%. According to the figure, the 
performance of the CPM algorithm, in terms of both runtime 
and memory, is stable across the sliding windows having the 
same concept of data (for example, at sliding windows #1 and 
#2). More importantly, it is not affected greatly by the concept 
drift (that is, from sliding window #2 to sliding window #3). 
The proposed method counts and records itemsets of the first 
two orders, so the synopsis it has to keep is generally small in 
scale. No matter what concept the stream is currently in and/or 
what value the minimum support is specified, it can efficiently 
process the received data elements and maintain the extracted 
synopsis. This is the reason for the stable performance. 
The next experiment tests for mining quality in terms of 
accuracy. The accuracy (of a frequent-itemset mining outcome) 
is assessed by the F-measure which is the harmonic mean of 
the precision and recall (of the outcome). The higher an 
F-measure (ranging from 0% to 100%) is, the better the 
mining accuracy/quality is. Two methods are tested and 
compared with each other in the experiment, namely CPM and 
CPM+. In regard to the concept-drifting data stream, CPM 
constructs a group of predictive models and uses it 
consistently to count-prediction based mining over the stream, 
while CPM+ constructs individual groups of predictive models 
upon the concepts and uses them to count-prediction based 
mining respectively. In other words, CPM+ is for addressing 
concept drifts while CPM is not. We show the result of the 
experiment in Fig. 4, where two values of minimum support 
were specified namely 0.5% (larger) and 0.4% (smaller). In 
the figure, CPM and CPM+ achieve much the same 
high-accuracy before the concept drift, that is, at sliding 
windows #1 and #2. However, as the concept drift happens, 
the accuracy of CPM falls severely, for example, by nearly 
30% at the minimum support of 0.4%. The reason is that the 
constructed count-prediction models (describing a concept) do 
not fit the changed concept anymore. On the other hand, 
CPM+ retains acceptable accuracy without a major decrement 
because the reconstructed count-prediction models adapt to the 
altered concept. According to this experiment, CPM+ would 
handle concept drifts effectively. Taking the results of all the 
experiments together, it is observed that the proposed 
algorithm possesses a satisfactory performance in mining 
frequent itemsets from a concept-drifting data stream. 
VI.  CONCLUSIONS 
Data streams are dynamic sources to data mining 
algorithms. The concept in a data stream may change with the 
time, which could affect the performance of a data-stream 
 
Figure 2.  Relationship between the sliding windows and the stream concepts. 
 
Figure 3.  Experimental results of running time (left) and memory consumption (right). 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/09/20
國科會補助計畫
計畫名稱: 於概念漂移的動態資料串流環境下有效挖掘頻繁樣式的估算式探勘方法
計畫主持人: 賈坤芳
計畫編號: 100-2221-E-005-088- 學門領域: 資料庫系統及資料工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
