1 
 
 
行政院國家科學委員會補助專題研究計畫 ■ 成 果 報 告   □期中進度報告 
 
智慧型視覺監控之感知整合 
 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號：NSC 96－2221－E－009－125－MY2 
執行期間： 96 年 08 月 01 日至 98 年 11 月 30 日 
 
計畫主持人：莊仁輝 
共同主持人： 
計畫參與人員： 林泓宏、羅國華、許諾白、邱永昌、林尚一、黃聖中 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
■出席國際學術會議心得報告及發表之論文各一份 
  (已上傳國際學術會議心得報告一份) 
□國際合作研究計畫國外研究報告書一份 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，■一年□二年後可公開查詢 
          
執行單位： 
中   華   民   國  99 年    2 月    26 日 
3 
 
 
Abstract 
This project is based on the basic framework of visual surveillance wherein various types of 
cameras are deployed in an indoor environment. These cameras are capable of capturing visible 
as well as infrared lights, and they can be fixed in space, possibly having pen-tilt-zoom (PTZ) 
capability, or mounted on a mobile platform. The motivation is to achieve more critical visual 
surveillance tasks through multi-sensor fusion. To that end, the project studied the 
communication and information sharing schemes among heterogeneous cameras, and other 
system integration issues including those associated with the dynamic surveillance functions of 
the mobile platform, so as to achieve the ultimate goal of active/passive surveillance around the 
clock. The proposed research areas of sensor fusion are dealing sensors of homogeneous as well 
as heterogeneous (visible and infrared image data) nature. Moreover, analyses of surveillance 
data obtained from both fixed and mobile platforms need to be taken into account together. The 
major research results of this two-year project include the following three main topics: 
1. Dynamic/static background construction and integration of heterogeneous image data:  
This topic focuses on the construction of dynamic/static background model of visible light 
and mid-infrared cameras mounted on a mobile platform. This can be the foundation for the 
development of mobile platforms for intelligent surveillance, which is crucial to human 
detection in the next topic. In addition, we used foreground segmentation result to integrate 
image data of visible light and mid-infrared. 
2. Nighttime localization of mobile platform and human target: 
We developed a cross-ratio based technique for mobile platform localization so that the task 
of mobile surveillance can be accomplished. And then the above human detection technique 
can be adopted to find the person’s relative location to help wide area monitoring. 
3. Human posture recognition and pointing direction estimation: 
This subject directly follows the above topic and focuses on posture recognition which can 
identify the person’s head and limbs quickly present a torso-less human activity model. We 
also analyze the posture of pointing further and estimate its pointing direction by multiple 
cameras. 
The above-mentioned subjects have close relationship with one another. They can be integrated 
into a future surveillance system suitable for both day and night time environments which can 
track locations of human and identify their postures. Such a system can serve as a fundamental 
integration platform of development and testing for the establishment of new types of integrated 
surveillance service. 
 
Keywords: sensor fusion, visual surveillance 
 
 
 
 
5 
 
用於動態攝影機的前景背景分割。而另一方面，當光線亮度不足的情況下，若使用一般的
可見光攝影機，通常都無法有效地監視環境中的人物或是異常現象。因此我們也為中紅外
線攝影機建立背景模型，以偵測場景中人物。由於中紅外線攝影機所接收到的並非一般的
可見光，而是物體所輻射出的溫度，因此即使環境中無可見光源，仍可正常的運作。透過
整合可見光和中紅外線兩種攝影機性質不同的資訊，期望能達成完整的監控，並可藉此增
加人物偵測的穩健性，以提供更豐富的監控影像記錄。 
    目前的實驗結果是由改良式的高斯混合模型對可見光和中紅外線動態影像建立正確的
背景模型，並由此切割前景。之後利用座標轉換的概念，將中紅外線影像中的目標物疊合
至可見光影像中，以進行影像資訊整合，由中紅外線影像提供正確的前景物輪廓給可見光
影像找出前景物，可見光影像則提供前景物色彩、位置等特徵以供分析。異質影像之間的
資訊整合可以彌補彼此間資訊不足的部份，更能提高分析時的準確度。 
 
二、 自動車夜間視覺定位與人物定位： 
    在這個主題中，我們希望以自動車上的攝影機取得之影像為基礎，發展日夜均能運作
的自動巡邏與人物定位系統。為了達成此一目的，我們需要發展兩項關鍵的方法： 
1. 自動車定位：利用 Cross-Ratio(交比)定出自動車在空間中的位置 
2. 人物定位：計算出監控對象或物品的所在位置 
    由於夜間監控環境中光線不足，因此我們在監控環境中佈建主動發出近紅外線光源的
發光二極體當作標記物，從影像畫面擷取標記物後利用上述方法 1.找出自動車位置。接著
我們可使用中紅外線影像配合第一年研發的動態前景切割方法來進行人物偵測，並搭配方
法 2.找出人物的位置，藉由這兩項位置資訊我們可推算出人物在環境中的位置。 
    目前實驗結果在自動車靜止時定位結果較佳，而在攝影機旋轉時定位結果較不穩定。
然而一般的安全監控系統可以是讓攝影機移動到一個定點進行拍攝後，再移動到另一個定
點，因此移動時無法對人物定位的問題對安全監控系統並沒有影響。 
 
三、 人物姿態辨識與多攝影機指向偵測：  
    人物肢體識別主要目的是希望能夠藉由偵測被觀測者的頭、手、腳等位置來辨別人物
目前的姿態。我們透過考慮人體區域之質心與人體區域的輪廓各點的距離與夾角當作特
徵，識別出頭、手和腳的位置。且基於保護被觀測者之隱私權，我們使用一資料量極少的
人體模型來表示人物。 
人物肢體識別中我們已經可以由單一攝影機偵測出人物頭部與四肢，有了肢體位置
後，我們便可以容易的偵測出人物的指向姿態，而在多攝影機的環境下，我們能將此結果
進一步應用於偵測呈長直條狀的手臂之指向方向，並進一步計算出其所指向的位置。此資
訊將可用於大螢幕的簡報系統、控制家電或是與機器人進行互動。為達此目的，我們發展
了一套指向系統，概念是藉由三平面的交點作為指向位置，首先計算場景中直條狀的指向
物的兩端點與兩攝影機中心點所構成的兩平面。再求出此兩平面與事先定義的投影平面之
交點即為指向位置。 
 
藉由上述主題之整合將可為長程的視覺監控研究，提供一個基礎的整合、研發和測試
平台。以下，我們將內容為分三主題，各自包含文獻探討、研究內容、實驗結果與討論以
及成果自評，進行細部的說明與描述。 
7 
 
                     
圖 1-1 (a)前景物，(b)背景影像，(c)偵測出的前景物。 
 
然而此方法的限制是可見光攝影機必須是靜止不動的狀態，因為一旦攝影機有任何的
移動，我們將無從判斷像素之間的配對關係，造成影像中的像素和高斯模型之間的對應是
不正確的結果。因此我們希望提出一個適用於動態背景的改良式高斯模型，不為每一個像
素建立數個高斯模型，而是用高斯模型來模擬環境中的物件，並且希望這樣可以免去前後
影像的像素位置要完全一致的問題。為了對每個物件建立以顏色為基礎的高斯混合模型，
我們利用各個物件之間顏色不同的特性，設計一個改良式高斯背景模型。由於此處之影像
為彩色影像，因此在計算與某模型之相似程度是以（三維）彩色之差異來考量。 
 
(a)                     (b) 
(c)                    (d) 
圖 1-2 (a)背景影像，(b)前景物出現的影像，(c)
背景影像的高斯模型分佈，(d)前景影像的切割
結果。 
 
圖 1-2 (a)、(b)分別為前景未出現與出現後的彩色影像實例。圖 1-2 (c)、(d)則分別為前
兩者在經過背景模型分析後所獲得的背景區域。由圖 1-2 (d)中可以看出，人體（白色區域）
下半身的區域仍有切割不正確之處，原因是下半身的部份在連續畫面分析的過程中，和所
在區域的背景模型過於相似，而被誤判為背景。 
另一方面，在夜晚或缺乏光源的情況下，可見光攝影機無法取得清楚的影像，所以我
們使用中紅外線攝影機擷取影像。中紅外線攝影機所儲存的格式是原始資料，其數值範圍
為 0~4095，如果要在一般的螢幕上顯示必須要經過格式的轉換，一般大多是用灰階的方式
呈現。然而轉換成灰階影像只有 0~255 數值可以表示，所以當轉換灰階時會有失真的情況，
即細節的地方在顯示上會有些難以分辨，如下圖 1-3 所示。所以我們利用一個中紅外線影
像強化方法[2]，將不明顯的地方加以突顯，如圖 1-4 所示。 
9 
 
 
圖 1-6  較大的（大於 100 像素）連通區域。 
    
 
圖 1-7  含位置資訊的三維高斯模型。 
 
第一張中紅外線影像背景建立好之後，接下來就是連續動態影像的處理。在此我們不
能將下一張所有像素直接拿來對第一張所有模型做比較。原因是當我們對全部模型做比較
時，就是考慮了整張圖中所有的位置所對應到的高斯模型，這樣一來即沒有充分利用到位
置的資訊，而造成無法完整的區別出前景物體。所以我們採用改良的方法，即每一個像素
我們只對於一個 5×5 區域內的所對應到的模型做比較。當某像素在此區域內有匹配到某一
個模型，就會被歸為此模型，若都沒有匹配，則會再把它對前一張的原始像素數值來做比
較，如果上述都沒有匹配就是被歸為前景（白色）。由圖 1-8 我們可以看到，偵測出來的人
物沒有破碎的情形，即驗證了本方法的偵測效果十分良好。 
 
第二部份、異質影像之資訊整合 
接下來本計畫考慮了利用可見光和中紅外線影像進行影像資訊整合。整個系統的流程
(如圖 1-9 所示)中先同時從可見光和中紅外線攝影機取得影像，接著再以前背景分割找出
目標物後，進行目標物資訊的分析，找出目標物的特徵。若是有可見光目標物，則可利用
可見光與中紅外線目標物的特徵求出兩個影像平面之間的二維座標轉換矩陣，並做轉換和
調整誤差以顯示結果。最後再儲存資訊以便在下一張影像進行目標物偵測時增加判斷的精
準度。若是可見光目標物消失或偵測結果不佳時，則使用之前的轉換矩陣把中紅外線影像
的目標物轉換到可見光影像中。 
在轉換中紅外線影像的目標物到可見光影像中的方法上，若是把整個目標物(圖 1-10(a))
轉換到可見光影像中，會把可見光影像中的目標物整個覆蓋住，觀察圖 1-10(b)，可以發現
11 
 
 
(a)                                  (b) 
圖 1-10 (a)中紅外線影像，(b)中紅外線影像的目標物轉換到可見光影像結果。 
 
有時可見光影像會因光線不足或是目標物體顏色與背景過於相似而使得前背景分割的
結果發生錯誤。不過在這樣的情況下，中紅外線影像卻不會受到這種因素的干擾，因此可
以清楚地分割出前景(如圖 1-11)。為了判斷影像中是否有完整目標物，我們以切割出的前景
面積是否在一定大小以上做為判斷的依據，若前景物面積太小(像是圖 1-11(b)的前景區塊)
則我們判斷前景物不完整而不做轉換參數的運算。這時就可以用之前所儲存的轉換矩陣把
中紅外線影像中目標物的輪廓做座標轉換，又因可見光影像中看不清楚目標物，所以在畫
面左上角顯示 “Target lost” 做為警示(如圖 1-12)。 
 
      (a)                         (b) 
 
    (c)                         (d) 
圖 1-11 可見光偵測失敗而中紅外線偵測正確的例子。(a)可見光影像，(b)不正確的可見光
前景分割結果，(c) 中紅外線影像，(d)正確的中紅外線前景分割結果。 
13 
 
 
 
 (a)                                   (b) 
圖 1-14 目標物完整出現在影像中的轉換結果。(a) 中紅外線影像，(b)可見光影像。 
 
 
(a)                                   (b) 
圖 1-15 即將判斷目標物消失前的轉換結果。(a) 中紅外線影像，(b)可見光影像。 
 
 
(a)                                   (b) 
圖 1-16 判斷目標物消失瞬間的轉換結果。(a) 中紅外線影像，(b)可見光影像。 
 
15 
 
 
圖 1-20 中紅外線與可見光影像目標物重疊比率(縱軸)，橫軸為 frame 編號。 
 
成果自評 
在第一部份、動靜態背景建構的部分，動態可見光背景模型方面，除了顏色相近的前
景和背景的分割結果較差外，其他方面並沒有太大的問題，不過現階段只能適用於小幅度
動態的情況，尚無法完全達成分析較大幅度動態背景的目標。中紅外線影像特殊動態背景
模型的建構結果，雖然仍不完美，但大致上已經能提供給人工使用的系統，作為夜間的監
控警示用途。而在第二部份、異質影像之資訊整合方面，除了因為可見光影像的前景分割
有破碎導致座標轉換的結果出現較大的誤差以外，當人物完整出現於監控場景中且前景分
割正確時都能有良好的整合結果。 
17 
 
 
第一部份、自動車夜間視覺定位 
Cross-Ratio定義有下面兩種形式（圖2-1）: 
 
1D: 
 
 
 
2D:  
 
ADBC
BDACDCBACR
ADBC
BDAC == θθ
θθ
sinsin
sinsin
)',',','(0  
 
前者適用於直線上連續四點（A, B, C, D），後者適用於平面上含原點 O 之五點，其中任三
點均不共線。我們先在實驗的場景中放置了可以發出近紅外線的標記物，接著由近紅外線
影像(圖 2-2)偵測出標記物的影像座標。又因為 Cross-Ratio 關係在投影後仍會維持不變，我
們可以藉由算出圖 2-3 中向量→D  及→D ' ，然後再個別產生兩條直線方程式 L1 及 L2，最後我們
計算出 L1 及 L2 的交點，即為自動車在環境空間中的位置。 
圖 2-2  近紅外線影像。 
 
圖2-3  場景的俯視圖。 
 
第二部份、人物定位 
在得知自動車位置後，我們進一步對影像作處理，找出人物在影像中與地面的接觸點
(立足點)，並估測人物在空間中的位置。我們可利用第一主題所建立的背景模型，從中紅外
線影像中偵測出前景，再使用連通物件法找出影像中的前景，並使用等高線圖演算法切出
較完整的人物區塊。圖 2-4 (a)為輸入的中紅外線影像，而圖 2-4 (b)為等高線演算法偵測出
之人物區塊。 
/( , , , )
/
AC BC ACBDCR A B C D
BD AD BC AD
= =
── ── ── ──
── ── ── ──
19 
 
行走後，自動車的路徑看起來是有點像曲線。 
 
圖2-6 自動車定位的結果。 
 
第二部份、人物定位 
為了實驗我們的定位方法之正確性，我們在地板上放了一個固定位置的發熱物體，並
且讓攝影機靜止不動對著物體拍攝，並計算出定位之結果。定位的結果如圖2-7所示，其中
橫軸為第幾個frame，縱軸為位置，紅色與藍色個別表示定位的x與y值。我們可以看出定位
的穩定性良好，僅有小幅度的波動。 
接著我們將攝影機進行轉動，先往右轉，停一下之後再轉回原來的朝向。在這期間持
續進行物體定位。定位結果如圖2-8所示，可以看出結果比圖2-7來的不穩定，定位效果略差，
這是因為中紅外與近紅外攝影機無法完全同步所造成的影響，使得frame100與200處發生了
較大的誤差。 
 
圖 2-7 攝影機不動時人物的定位結果。 
21 
 
第三主題: 人物姿態辨識與多攝影機指向偵測 
本主題為兩大部分，第一部份為人物肢體識別，第二部分為多攝影機指向偵測。第一
部分找出人體的頭與四肢後，即可知道該人物姿態。第二部分使用多攝影機，在得知人物
位置與姿態後，便可偵測呈長直條狀的手臂之指向方向，達成指向系統的功能，便可應用
於日常生活中。例如：當人物指向一個家電時，便可將其開啟或關閉。 
 
文獻探討 
在人類行為認知之相關研究中，有以下常見的主題：行為分析、姿勢分類、姿態識別、
活動表示等。行為分析[21-23]是指利用若干方法來分辨被觀測者是屬於走路、跑步、坐下、
躺下等正常行為或是跌倒、爬牆等異常行為。姿勢分類[24-26]則是判別被觀測者是站、坐、
躺、蹲下、彎曲等姿勢中的哪一個。姿態識別[27-29]則是偵測被觀測者的頭、手、腳等位
置。活動表示[30, 31]則是將被觀測者用模型之方式呈現，其目的在於保護被觀測者之隱私
權。而不論是哪一類的方法大部分都是透過先利用前景分割或是 frame difference 找出活動
的人體，再進而針對人體的部分進行分析。 
行為分析中，有一種方法是在擷取人體特徵後，[21]利用分類器來進行分析。而[22]是
透過固定規則來進行分析。[23]則是直接將人體區域逼近為一個橢圓形，橢圓形的角度與長
短軸比例做為是否跌倒之依據。姿勢分類的主要目的是希望能夠找出人物目前的活動屬於
哪一種型態，像是走、站…等。其常見的方法如[24]在擷取人體特徵後，將人體區域以細化
（thinning）的方式擷取出人體的近似骨架，再分析各肢體部位的骨架數量及狀態來識別人
體的姿勢。另一類則是將擷取的特徵比對資料庫最近似的姿勢[25, 26]。 
    姿態識別的研究中，比較常見的是利用區域分割（region splitting）的方式來找頭、手、
腳，如[27]的作法是找到人體區域的外接矩形後，再依照人體高度之比例分為幾個區域，透
過考慮各區域大小及膚色特徵，再利用一些規則即可偵測出頭、手、腳的所在位置，並透
過追蹤肢體的方式來增加判斷的準確度。而[29]利用頭、手和腳在人體中較為顯著的特性來
做識別，考慮人體區域之質心與人體區域的輪廓各點的距離和夾角當作特徵，再利用膚色
的資訊，進一步分析出頭、手和腳的位置。 
    活動表示之研究中，[30, 31]皆是參考[32]以 0°、45°、90°和 135°掃描出近似中軸線段。
[30]的模型呈現方式是僅以一個最佳近似中軸線段代表一個肢體或軀幹，並利用若干規則找
出頭、手、腳後，以橢圓及平行四邊形代表這些部位，即完成人體模型之建立。而[31]則是
考慮到手、腳有關節存在，無法單純只由一個近似中軸線段來代表，所以允許局部重疊的
情況。也因此省略了[30]的頭、手、腳規則判斷，直接用梯形代表肢體並建立人體模型。 
在指向系統之研究中，R. Sukthankar et al. [33]、J.-F. Lapointe et al. [34]、D. Laberge et al. 
[35]提出的雷射筆簡報系統，是基於二維平面轉換的系統。在這些系統中，都是利用平面投
影轉換原理，來取得相機平面、投影平面與顯示平面間的對應關係，當雷射點出現於影像
上時，系統先找出雷射點所在位置，再轉換到顯示平面之上。而在[35]中作者提及直接偵測
雷射點的準確度很高，誤差範圍為±3 個像素。然而這些系統的共同限制是，雷射光點在影
像上的亮度必須要比背景亮，否則將不易完成指向定位。 
另一類的作法是以手作為指向物來判斷其朝向。A. A. Argyros et al. [36]所提出的系統
中，先由影像中的色彩分佈（color distribution）來判斷出包含膚色的部分，再利用貝式分
類器（Bayesian classifier）來判斷出影像中手的座標，最後求出指尖的位置。然後定義一些
23 
 
(a)該中心軸線段是否由三個以上的橫截面所構成。 
(b)中心軸線段的平均橫截面寬度是否小於等於該中心軸線段之長度。 
經過上述的條件過濾後，我們可以獲得較適合代表肢體的近似中軸線段。 
 
(2)標示頭及肢體之末端 
除了考慮肢體的形狀，我們可以進一步地利用端點的概念，協助我們之後能選出較合
適的近似中軸線段來代表肢體。由圖 3-1 中我們可清楚地看出，接近肢體末端的近似中軸
線段，其橫截面的分布必定會出現由無到有（綠色箭頭）或者由有到無（紅色箭頭）的情
形。我們利用此特性將這一類的近似中軸線段的起始（終止）橫截面的中心點標示為末端
點，如圖 3-2 中水藍色點所示。 
                      
圖 3-2 四個方向找出可能代表肢體的近似中軸線段，由左而右分別為 0°、 45°、90°、135°。 
 
(3)整合近似中軸線段 
在取得了四個方向的近似中軸線段後，由於同一肢體可能有多個候選的近似中軸線
段，我們希望選出一個最合適的來代表該肢體，以達成人體肢體之活動表示並進行後續姿
態識別。 
首先，我們考慮空間上的關係，將位置較相近的含有末端點近似中軸線段分為同一類
別，例如圖 3-2 中將會產生 5 個集合，以中心軸線代表肢體的黑色線段所成的集合。我們
將不含末端點近似中軸線依據位置關係，歸類到各集合去。判別方法是檢查一集合內是否
有末端點與不含末端點近似中軸線的起始或終止橫截面的中心點距離小於 Ttip。若是，則歸
類於該集合。 
接著，我們將對於每個集合，挑選出一個最適合代表該肢體末端部位的近似中軸線段，
挑選步驟如下： 
一、挑選近似中軸線段和橫截面垂直方向的最小夾角，因為夾角越小越能代表該近似中軸
線段越貼近肢體的走向。 
二、再從最小的夾角容許範圍內，挑選最長的近似中軸線段，若該近似中軸線段不具末端
點(水藍色的點)，則在最接近末端的起始或終止橫截面中心點上添加末端點。 
三、排除集合中與此最長的近似中軸線段重疊者。 
若集合中若僅剩此最長的近似中軸線段，則用其代表那一肢體末端部位。否則，即代表該
肢體呈現多節肢體，此時我們挑選與外側較接近者(較靠近人體輪廓)。所找出的結果如圖
3-3 所示，(a)~(d)展示各角度找出的近似中軸線段，(e)中呈現從各個集合挑選出最合適代表
25 
 
頭，跳至步驟(4)。 
(2) 判斷人體區域的長寬比是否大於 Tlie，如果是，則使用 0°掃描線最上面的橫截面中點來
當作參考點，否則使用 90°掃描線最右邊的橫截面中點來當作參考點。 
(3) 找到距離參考點最遠的 2 個肢體即是腳，剩下的 2 個肢體就是手。 
(4) 找到距離頭最遠的 2 個肢體，如果第二遠跟最遠的比值大於門檻值 Tfoot就二個都是腳，
否則只有最遠的一個是腳。而剩下的肢體就是手。 
情況三 (3 或 4 個肢體，此情況下都會再分成有頭或無頭的情況): 
(1) 找出 3 個肢體中，不含多節肢體中角度最大和最小的近似中軸線，如果最大和最小的
角度差值小於 Theadless，則跳至步驟(2)，否則最大角度的就是頭，跳至步驟(4)。 
(2) 判斷人體區域的長寬比是否大於 Tlie，如果是，則使用 0°掃描線最上面的橫截面 y 值到
最下面的橫截面 y 值的距離來當作參考距離，如果末端特徵的 y 值在最上面的橫截面 y
值的 1/10 參考距離範圍內就是頭。否則使用 90°掃描線最右邊的橫截面 x 值到最左邊
的橫截面 x 值的距離來當作參考距離，如果末端特徵的 x 值在最右邊的橫截面 x 值的
1/10 參考距離範圍內就是頭。如果有找到頭，則剩下兩個肢體就是腳。 
(3) 如果人體區域的長寬比大於 Tlie，則使用 0°掃描線最上面的橫截面中點來當作參考點，
否則使用 90°掃描線最右邊的橫截面中點來當作參考點。找到距離參考點最遠的 2 個肢
體，如果第二遠跟最遠的比值大於門檻值 Tfoot 就兩個都是腳，否則只有最遠的一個是
腳，而剩下的肢體就是手。 
(4) 判斷頭到兩個肢體的距離比值是否小於 Tfoot，如果是，則最遠的一個是腳，另一個就
是手。否則如果人體區域的長寬比大於 Tlie，使用 0°掃描線最上面的橫截面中點到最下
面的橫截面中點的距離來當作參考距離，否則使用 90°掃描線最右邊的橫截面中點到最
左邊的橫截面中點的距離來當作參考距離，最後判斷頭到肢體的最遠距離和參考距離
比值是否大於門檻值 Tfoot，如果是就判斷兩個都是腳，否則兩個就是手。 
情況四 (1 或 2 個肢體) : 
(1) 判斷人體區域的長寬比是否大於 Tlie，如果是則代表是直立的，跳至步驟(2)。表示躺著
的，跳至步驟(3)。 
(2) 使用 0°掃描線最上面的橫截面 y 值到最下面的橫截面 y 值的距離來當作參考距離，如
果末端特徵的 y 值在最上面的橫截面 y 值的 1/10 參考距離範圍內就是頭。如果在最下
面的橫截面 y 值的 3/10 參考距離範圍內就是腳，剩下就是手。 
(3) 使用 90°掃描線最右邊的橫截面 x 值到最左邊的橫截面 x 值的距離來當作參考距離，如
果末端特徵的 x 值在最右邊的橫截面 x 值的 1/10 參考距離範圍內就是頭。如果在最左
邊的橫截面 x 值的 3/10 參考距離範圍內就是腳，剩下就是手。 
第二部份、多攝影機指向系統偵測 
在前面的姿態分析中我們已經可以由單一攝影機偵測出人物頭部與四肢，而在多攝影
機的環境下，我們能將此結果更進一步應用於人機互動上。近幾十年來，人機互動是相當
熱門的研究領域，舉凡虛擬實境、人臉辨識、手勢…等，皆屬於此範疇。而這些應用之中，
常需要知道人物所指的方向，例如:指向某特定的家電後，再搭配其他手勢，則可以命令其
開啟或是關閉、在射擊遊戲中偵測玩家的指向及扣板機的時機來完成射擊的動作。由上述
27 
 
紅色代表頭，綠色代表手，藍色代表腳，黑色的點是定位點。不同於[30]、[31]的方法，本
研究可以辨別出肢體部位，並以不同的顏色進行標示，且在人體姿態模型的呈現上我們的
模型具高隱密性及較小的資料量。 
                            
        (a)                    (b)                    (c)                   (d) 
圖 3-6 人體模型表示結果：(a) 前背景圖，(b) [30]的人體模型表示，(c) [31]的人體模型表
示， (d) 本研究的人體模型表示。 
 
我們利用實作出來的姿態識別系統來進行實際影像畫面的實驗，並證明本研究的系統
具有較佳的正確性與實用性。利用兩段影片經前景切割後的二值影像作為輸入，並將辨識
後的結果顯示如下。第一段影片如圖 3-7 所示，是一個人物走一段路後坐下來。而其結果
如表 3-1 所示，我們可以看到識別的結果良好。其中五個肢體(一頭二手二腳)，準確率達
100%，4 個肢體時，正確率 89.79%，為整體識別正確率最低，但整體的準確率仍相當良好。
我們測試另一段影片如圖 3-8 所示，是一人物由右向左呈大字形走動，而識別的結果顯示
於表 3-2，可以看出結果非常良好，原因是這段影片中的人物肢體的部位較明確，使得辨識
率能大大增加。 
                    
(a)                                   (b) 
 
(c)                                    (d) 
 
(e)                                    (f) 
圖 3-7 人像走動並坐下的連續中紅外線影像及姿態識別後所產生的人體模型。 
29 
 
0 頭 1 手 0 腳    N/A 
0 頭 0 手 1 腳    0/1 
Total  
243/255 = 95.29% 
202/205 = 98.53% 
415/427 = 97.18% 
860/887 = 96.95% 
248/261 = 95.01% 
 
表 3-2 人像呈大字形走動的連續可見光影像的姿態識別正確率。 
 
肢體種類 
各個肢體標記正確率 整個影像正確率 
辨識出 frame 數/實際 frame 數 
5 個肢體 1 頭 2 手 2 腳   51/51 
(頭)  51/51 = 100% 
(手)  102/102 = 100%
(腳)  102/102 = 100%
(total)255/255 = 100%
51/51 = 100% 
4 個肢體 
1 頭 1 手 2 腳    N/A 
1 頭 2 手 1 腳    2/2 
0 頭 2 手 2 腳    3/3 
(頭)  2/2 = 100% 
(手)  10/10 = 100% 
(腳)  8/8 = 100% 
(total) 20/20 = 100% 
5/5 = 100% 
Total  
53/53 = 100% 
112/112 = 100% 
110/110 = 100% 
275/275 = 100% 
56/56 = 100% 
 
第二部份、多攝影機指向系統 
為了驗證我們的指向方法，我們建構了一個虛擬的會議室，並在房間的天花板上架
設了 2 台攝影機，如頂視圖 3-9 中 C1,C2 所示，而紅色線段為指向物體的位置，圖中綠色線
段為投影幕之位置，我們於投影幕之上設定了 9 個目標點，如圖 3-10 中藍色十字所示 ，
重建出的指向點則標示為紅色的十字。由於放置攝影機的方式是對稱的，因此我們觀察到
的指向結果也十分的對稱。此外一半以上的位置都相當正確，僅中間兩側與下排兩側的指
向點具有較大的定位誤差，而整體的平均誤差為 6.7764 cm，屬於可接受的誤差範圍，也證
明了此一方法的正確性。 
成果自評 
 
在第一部分、人物肢體識別，我們致力於精確的辨識出人體各肢體部位，且經實驗證實辨
識的結果相當良好，這也能夠支持第二部分多攝影機指向系統的需求。而對於第二部分、
指向偵測的部分，實驗的結果證實了我們方法的可行性與準確性，將可以結合指向系統，
應於家電控制或機器人操控等應用。 
31 
 
[2] D. G. Lowe, “Object Recognition from Local Scale-invariant Features,” IEEE International 
Conference on the Proceedings of the Seventh, vol. 2, pp. 1150-1157, 1999. 
[3] M. Awrangieb and G. Lu, “A Robust Corner Matching Technique,” IEEE International 
Conference on Multimedia and Expo, pp. 1483-1486, July 2007. 
[4] F. Candocia and M. Adjouadi, “A Similarity Measure for Stereo Feature Matching,” IEEE 
Transactions on Image Processing, vol. 6, issue 10, pp. 1460-1464, 1997. 
[5] S. D. Sharghi and F. A. Kamangar, “Geometric Feature-based Matching in Stereo Images,” 
Information Decision and Control, pp. 65-70, 1999. 
[6] Z. Hamrouni, “Hierarchical Feature Grouping for Stereo Matching,” Proceedings of the 
IEEE Southwest Symposium on Image Analysis and Interpretation, pp. 160-165, April 
1996. 
[7] P. Fieguth, P. Bloore, and A. Domsa, “Phase-based Methods for Fourier Shape Matching,” 
IEEE International Conference on Acoustics, Speech, and Signal Processing, vol. 3, pp. 
425-428, 2004. 
[8] O. Demuynck and J. L. Lafzaro, “An Efficient Approach Technique for Dynamical Infrared 
Visible Images Fusion,” IEEE International Symposium on Intelligent Signal Processing, 
pp. 1-6, 2007. 
[9] Y.-H. Chen, “Visual Surveillance Using Infrared Images,” Master Thesis, National Chiao 
Tung University, June 2004. 
[10] K.-C. Chen, “Vision-based Mobile Robot Localization Using Homographies,” Master 
Thesis, National Chiao Tung University, June 2007. 
[11] Y.-T. Tsai, “Error Analysis of A Real-time Vision-based Pointing System,” Master Thesis, 
National Chiao Tung University, June 2007. 
[12] E. Rivlin, I. Shimshoni, and E. Smolyar, “Image-Based Robot Navigation in Unknown 
Indoor environments,” IEEE International Conference on Intelligent Robots and Systems, 
pp. 2736-2742, 2003.  
[13] R. Basri, E. Rivlin, and I. Shimshoni, “Image-Based Robot Navigation Under the 
33 
 
and Behavior Analysis,” Third International IEEE Conference on Signal-Image 
Technologies and Internet-Based System, pp. 812-818, Dec. 2007. 
[23] C. Rougier, J. Meunier, A. St-Arnaud, and J. Rousseau, “Fall Detection from Human Shape 
and Motion History Using Video Surveillance,” 21st International Conference on 
Advanced Information Networking and Applications Workshops, Volume 2, pp. 875-880, 
May 2007. 
[24] C. Castiello, T. D’Orazio, A. M. Fanelli, P. Spagnolo, and M. A. Torsello, “A Model-free 
Approach for Posture Classification,” IEEE Conference on Advanced Video and Signal 
Based Surveillance, pp. 276-281, Sept. 2005. 
[25] J.-W. Hsieh, Y.-T. Hsu, H.-Y. M. Liao, and C.-C. Chen, “Video-based Human Movement 
Analysis and Its Application to Surveillance Systems,” IEEE Transactions on Multimedia, 
Volume 10, Issue 3, pp. 372-384, April 2008. 
[26] P. Guo and Z.-J. Miao, “Projection Histogram Based Human Posture Recognition,” The 8th 
International Conference on Signal Processing, Volume 2, pp. 16-20, 2006. 
[27] F. Jean, R. Bergevin, and A. B. Albu, “Body Tracking in Human Walk from Monocular 
Video Sequences,” The 2nd Canadian Conference on Computer and Robot Vision, pp. 
144-151, May 2005. 
[28] I. Haritaoglu, D. Harwood, and L. Davis, “W4: A Real Time System for Detecting and 
Tracking People,” IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition, pp. 962-962, June 1998. 
[29] C.-F. Juang, C.-M. Chang, J.-R. Wu, and D. Lee, “Computer Vision-based Human Body 
Segmentation and Posture Estimation,” IEEE Transactions on Systems, Man, and 
Cybernetics, Part A, Volume 39, Issue 1, pp. 119-133, Jan. 2009. 
[30] J.-H. Chuang, C.-W. Lee, and K.-H. Lo, “Human Activity Analysis Based on a Torso-less 
Representation,” 19th International Conference on Pattern Recognition, pp. 1-4, Dec. 
2008. 
[31] N.-H. Chu, “A Torso-less Representation of Human Activity with Multi-joint Trapezoids,” 
ICIP2009 心得報告 
 
    一年一度的國際影像處理會議（ICIP2009），今年是在埃及舉辦。由於這是
此一盛會多年來第一次在中東地區，尤其是金字塔古文明所在國舉辦，吸引了許
多世界各國的研究人員與學者專家前來參與。在大會開幕典禮上，主辦單位特別
將若干重要的統計數字以金字塔形狀呈現，以顯示影像處理領域對於此次會議之
重視與支持。其中包括，投稿論文共計 2442篇，審稿人員共計 1142人，共有
1101篇論文被接受，會議共計有 23場口頭報告會節以及 70場海報會節，在場
與會人士均對於上述會議成果，給予熱誠的喝采。 
    在開幕典禮之後，緊接是本次會議的第一場全體參與之專題演講。此一演講
是由大名鼎鼎的 Hawass博士所提供。演講主題為「Image and Technologies 
Revealing Secrets of the Sand」亦即「發掘黃沙中的秘密之影像與技術」，由於千
年古墓中之物品與木乃伊均十分脆弱，因此，利用各式新進技術取得的影像資
訊，如 X-光、斷層掃描，成為發現與了解古代人、事、物所不可或缺的利器。
例如，透過人體組織的三維重建，有位曾經傳說被刺殺的法老王被發現其實是因
病而死。此外，利用電腦 3D動畫技術，工作人員也得以將一顆撿到的牙齒，在
電腦繪圖的虛擬世界中，將之歸位於其主人的口腔之中，物歸原主。 
    其實，在這些科技的議題之外，吾人也曾思索開掘前人墳墓所衍生之道德問
題，亦即類似「金字塔的詛咒」的想法。幾千年以後的現代人，有何權利去使用、
侵犯前人的身體權、物品權呢？這些古文明的所有權是僅僅專屬於其所在地之國
家(埃及)嗎？因此，先前被盜賣至世界各地的文物，均應無條件歸還嗎？另一方
面，這些被發現的古文明，卻也提供了世人最深刻的省思。雖然中國文化號稱五
千年歷史，但是在五千年之初的中國文化，是十分簡單且原始的。如果與古埃及
文明來作比較，其實由建築之規模，抑或文物之細緻程度等標準而言，五、六千
年前的埃及已經就有非常高超的水準，這是可以在開羅市區的埃及博物館中就可
以直接獲得證實的，而這一切，也正是因為有這些考古學家、盜墓者先後去叨擾
先人墓室，逕自取得先人之財物，甚至遺體而造就的。如果這一切能給現今世上
我們有所領悟，那道德上又是否可以立足？最後一個問題是：在此紛擾不斷的二
十一世紀之初，我們面對曾經輝煌而又隕落古文明的反省又是什麼呢? 
    Hawass博士為國際知名的考古學家，目前擔任埃及開羅最高文物委員會秘
書長，他曾撰寫了大量學術文章和書籍，並且為高度受舉世所尊重的埃及古物學
者。在他漫長的考古生涯中，已獲得了諸多獎項和榮譽。由於 Hawass博士以其
特有魅力與努力，不遺餘力的保護埃及的珍貴遺產，最近並獲得美國電視藝術與
科學學院頒發的艾美獎。2006年時，時代雜誌亦選擇了 Hawass博士為 2005年
百大最有影響力的人。在此次演講結束時，有一段不太尋常的插曲。在主持人致
贈禮物之後，Hawass博士隨即在下台時轉交給一旁的工作人員，而後逕自大步
自觀眾席間的走道步離會場，此一舉動十分令人難以理解。 
