行政院國家科學委員會補助專題研究計畫
成果報告
□期中進度報告
開放式知識探勘平臺
計畫類別：個別型計畫 □整合型計畫
計畫編號：NSC 98-2221-E-002-142-MY3
執行期間：98 年 8 月 1 日至 101 年 7 月 31 日
執行機構及系所：國立臺灣大學 資訊工程學系暨研究所
計畫主持人：賴飛羆教授
共同主持人：賴美淑教授、譚慶鼎醫師、梁嘉德醫師
計畫參與人員：平曉鷗、曾意儒、許景崴、吳亞霖、劉子華
成果報告類型(依經費核定清單規定繳交)：□精簡報告 完整報告
本計畫除繳交成果報告外，另須繳交以下出國心得報告：
□赴國外出差或研習心得報告
□赴大陸地區出差或研習心得報告
□出席國際學術會議心得報告
□國際合作研究計畫國外研究報告
處理方式：除列管計畫及下列情形者外，得立即公開查詢
□涉及專利或其他智慧財產權，□一年□二年後可公開查詢
中 華 民 國 101 年 8 月 15 日
II
Abstract
Because of more and more adoption of electronic medical record (EMR) systems, the enormous healthcare
records will be accumulated in the clinical data repository. Clinical data repository contains accumulated
information of patients that can describe the patients’ statuses for the medical related processes.The aim of
this project was to extract the information from repositories and developed the knowledge modules based on
these retrieved data (including structuralized data and non-structuralized data). An infrastructure was proposed
to gather clinical data and discover knowledge from the gathered data for facilitating quality improvement of
healthcare. The non-structuralized data was extracted as structuralized data. The validation system was
developed for verifying information extraction (IE) system. The case-based reasoning (CBR) approach was
adopted to provide the reference information by identifying similar patients’ cases during the medial
decision-making of the current patient cases.
Keywords: Electronic medical record, clinical data repository, knowledge module, information extraction,
medial decision-making
11 Introduction
1.1 An infrastructure for clinical data extraction, medical knowledge and mining services sharing
Because of more and more adoption of electronic health record (EHR) systems, the enormous
healthcare records will be accumulated in the clinical data repository. We proposed an infrastructure
to gather clinical data, discover knowledge from the gathered data, and share the knowledge and
mining modules services for facilitating quality improvement of healthcare.
1.2 The approach for assisting structuralizing the textual clinical documents
Clinical data repositories contain enormous data accumulated by the daily operation of health
information system. After operating a long period, hospitals can accumulate great amount of
medical data. In the data, they enclose physicians' treatment experience and expertise that can be
extracted, learned, and gained knowledge. For the structuralized clinical data, the data can be
directly exported for further analyzing and mining. However, not all the clinical data are stored in
structuralized format. There are many medical data, such as radiology reports, discharge summaries
are still stored in free-text format without any formal convention. The data need to be further
processed to extract the relevant information.
In recent years, numerous works put the efforts on extracting relevant information from the textual
clinical documents. The purposes of these researches can be analyzed as three categories. The first
one is marking the concepts and keywords in the textual clinical documents. Cancer Text
Information Extraction System (caTIES) was developed for indexing clinical concepts in free text
reports using natural language processing (NLP) techniques. The caTIES can display the original
reports and highlight the matched concepts with different colors. In several researches, caTIES was
adopted for supporting the concept reorganization in the surgical pathology reports and radiology
reports [1-2]. The RadOn is the ontology which is proposed for modeling the semantics in the
radiology reports. The ontology can be used to model the concepts with related semantics. When
the users input the keyword, the system can retrieve the reports with the keyword or the related
semantics [3]. The second type researches are to extract the data items in textual documents and to
fill the outcomes into the predefined template. Besides the concept and keyword search
methodologies, the information extraction is utilized for filling predefined templates [4-5]. The
third type related researches are providing the verification interface for users to verify the extracted
information. Some researchers utilized the commercial NLP engines for medication information
extraction from clinical free-text reports. The extracted data are filled into the predefined template
with the item fields, including the names, doses, routes, and frequencies of medication. In their
medication extraction verification interface, the system presents the highlight information of
medication, and the editor presents the extracted data in the template for users to verify the data
filled in the template [6].
In the paper, we proposed an approach combines the benefits of the three categories of researches to
extract relevant information from the textual clinical documents we mentioned above. The objective
3liver cancer (i.e. hepatocelular carcinoma (HCC) in this study) patients’ textual reports [8]. These
extracted results produced by the IE system are used for supporting the development of recurrence
predictive model. After information was extracted, it is important to prove these extracted results
are reliable [9]. However, we are not sure about the correctness of these extracted results without
checking that manually. In the study, two of our team members had reviewed all extracted
information. According to their reviews, the precision of the IE system can be analyzed. The
precision of this IE system can achieve 95%. The wrong-extracted information is about 5% of total
amount of results. But, checking the correctness of all extracted results manually would be a very
time-consuming and labor-intensive task. Therefore, the aim of this study is to provide an efficient
way for facilitating the process of checking these extracted results. We designed the validation
system for predicting the correctness of each extracted result. According to the prediction of
validation system, the reviewers can efficiently check the smaller part of extracted results predicted
as wrong-extracted information by the validation system and correct them; instead of checking all
extracted information. In this way, it can highly promote the efficiency of the future reviewing
process. Figure 2 shows an overview of the procedure to predict the confidence score of each
extracted result.
Figure 2. The validation system labels high and low confidence scores to each extracted result
based on the extracted features by the IE system.
1.4 A CBR-based method for retrieving similar cases
Clinical data repository contains accumulated information of patients that can describe the patients’ 
statuses for the medical related processes. The aim of this study is to provide the reference
5execution engine through web-based services module.
The ontology-based methodologies could be involved for extracting and querying information [15].
The different mining methodologies could be appended incrementally such as support vector
machines (SVM) and decision trees. One or more of the guideline representation languages can be
chosen to present the results, including GLIF, Arden syntax, Asbru, PROforma, EON, PRODIGY,
etc [16].
Figure 3. The components, repositories, and workflow.
2.2 The approach for assisting structuralizing the textual clinical documents
2.2.1 Overall process of the data extraction
The process of data extraction from the imported textual documents can be separated into
several major sub-processes as indicated in Figure 1. The descriptions and the architecture of
the approach are illustrated in the followings:
1) Textual clinical documents retrieving: The patient list is displayed for clinicians to select a
patient on demand. The textual documents are retrieved based on the demographic data of the
selected patient. The selected patient’s documents are retrieved and displayed for clinician to 
review.
2) Keyword selection from user interface: The keyword selection interface provides the
functionality of a keyword list based on the categories of textual documents or a personal
setting for a specific research. A clinician can select the appropriate keyword in the list for
7fields can be dynamically added or removed on demand. Under various research purposes, the
data need to be collected may have variation. For example, if the data are extracted for research
regarding the treatment strategies of liver cancer, then the information included in the radiology
reports, pathology reports, and the treatment procedures need to be collected as well.
2.3 A method for identifying confidence level of the extracted results
In the study, the liver cancer patients’ textual medical records are processed by the IE system to 
produce the extracted results. There are 958 extracted results relevant to tumor information and
have been checked accompanying with their original textual reports manually.
Figure 4. The examples of extracted results that labeled with high confidence score, including the
source sentences in textual reports, extracted results by the IE, and the reasons for labeling the
results with high confidence score.
The reviewers labeled the correctness of these extracted results. If the extracted results are correct,
it would be labeled with a high confidence score. Figures 4 and 5 show the examples of the
extracted results labeled with high and low confidence scores, respectively.
After the manual reviewing process, all the extracted results are labeled with either high or low
confidence scores according to their correctness.
The support vector machine (SVM) classifier is employed in the validation system. Each extracted
result has its corresponding features collected by the IE system during the extracting process. The
features and their descriptions are listed in Table 1. These features are used as input information to
the validation system [17].
9All the 958 extracted results are half divided randomly to a training set and a testing set for training
and testing the performance of the validation system. According to the features of extracted results
in training set and in testing set, the validation system can predict the confidence score of extracted
results. In the final step, the human-labeled confidence score would be compared with SVM-labeled
confidence score to calculate the sensitivity and specificity. According to the prediction of the
validation system, these extracted results predicted with low confidence are firstly taken into the
reviewing process for checking their correctness.
2.4 A CBR-based method for retrieving similar cases
The major topic is focused on the recurrent status after the specific treatment of the patients with
liver cancer. In the study, every patient’s clinical data can be regarded as a case. Each case has 16 
clinical features (Table 2) which may affect the recurrence of liver cancer, including age, gender,
laboratory tests, tumor size, and tumor number. These features are selected from 58 clinical features
by the expert in the domain. The list of features is presented in Table 2 Based on the type of data,
every feature can be categorized as qualitative or quantitative data.
Table 2. The list of 16 features and value types
Feature type Feature name
Qualitative data
(Categorical
data)
Gender
HBV antigen
HCV antigen
Quantitative
data
(Numeric data)
Age
Albumin
Aspartate transaminase
(AST)
Alanine transaminase (ALT)
Alpha-fetoprotein (AFP)
Platelet count
Creatinine
Total bilirubin
Prothrombin time
international normalized ratio
(INR)
Barcelona clinic liver cancer
(BCLC) staging
Cirrhosis
Liver tumor number
Liver tumor size
11
(2)
After calculating local similarities of all features, the global similarity can be obtained by eq. (3)
[10]. The symbol n means the amount of features, so n value is 16 in this study and is the
weight value of feature i. In this research, the four different feature selection methods are employed
for calculating the feature weights which are assigned to the corresponding features for the process
of case similarity comparison. The four feature selection methods from R packages are employed
and compared in this study, as “atStats of Boruta” package, “correlation of FSelector” package, 
“random forest importance of FSelector” package, and “relief of FSelector” package. 
(3)
The global similarities between retrieved cases and current case are ranked. These ranked results are
processed and only the statistics values and the chart are displayed. Therefore, the complicatedly
original clinical data are hidden and the privacy of patients’ data is protected. Moreover, to evaluate 
this approach, the majority status (recurrent or non-recurrent) of the 10 most similar cases is used as
the prediction result of the current case. Because the predictions of recurrent cases have to be given
more attention than those of non-recurrent cases, when the numbers of recurrent cases are equal to
those of non-recurrent cases, the prediction result is considered as recurrent.
2.5 The methodology for handling missing data during development of predictive model
Figure 7 shows the methodology for evaluating IMs through simulation experiment, preparing data
sets (i.e. by CC, CV, and IMs), and using these data sets to develop recurrence predictive model.
Each data set is divided into two parts for training and testing the SVM-based predictive model. The
92 liver cancer patients were included (with 7.6% MVs). The analyzed features contain age, gender,
laboratory tests, tumor size, tumor number, and cancer staging, etc. In the simulation experiment,
the observed values are randomly masked as missing values and the IMs are employed for imputing
these missing entries. After the process of data imputation, the masked true values and the imputed
valued estimated by IMs can be compared. The normalized root mean squared errors (NRMSEs)
can be used for evaluating the imputation accuracy of IMs. Single IMs are “SVDImpute”, 
“LLSImpute”, “PPCA”, “BPCA”, “NLPCA”,and “Nipals PCA”. Multiple IMs are the “MICE” and 
“mi”. For each IM, the simulation experiment is repeated 20 times and the distribution of these 20 
NRMSEs is analyzed rather than calculating one mean value of these NRMSEs. The summation of
first quartile, third quartile, and the median is regarded as the IM selection criterion for comparing
the imputation performance in the stability and accuracy.
13
major description.
The major description can be further categorized into two types: 1) a single major report
description such as the pathology report; 2) multiple report description fields such as the
discharge summary.
3.2.2 Keyword-based and semantic-driven data matching modules
The keyword can be selected from the retrieved keyword list, or the keyword can be entered
directly by clinicians. When the matching process is started, the matching profile of the
keyword is retrieved, and the matching process executes based on the profile and the mapped
matching rule in the modules.
After the matching operation is finished, the matched keyword and the data with related
semantics are highlighted using different colors in the viewer. The keyword is “size” and six 
data items are matched. The matching modules not only mark the term, “size”, but also mark
therelated information relevant to the “size” such as the information of tumor size, “4.9 x 1 x 
1.8”. The discharge summary contains several major report descriptions, and the keyword is
“date”. The matching process accesses on the multiple report descriptions; eight data items are
matched in the report such as “2009/12/29” and “12/29”. The keyword is “date” and the data 
items with related semantics of date are highlighted.
The matching profile of keyword and the matching rules in the modules provide the capability
of matching the keyword and the related information of the keyword. The keyword-based and
semantic-driven data matching modules are used for guiding clinicians to extract information
on demands.
3.2.3 Case-oriented template in the extraction verification editor
With different diseases or research purposes, the corresponding template can be designed for
collecting the necessary information in different cases.
The item fields are automatically generated based on the predefined schema of the template.
The matched information can be semi-automatically extracted from the textual clinical
documents into the item fields of the template.
The item field component of the template can be further divided into two categories: 1) the
components that need reference other specific component for deciding how many copies of the
component need to be generated. For example, the component of “Tumor info” contains four 
item fields, including the tumor location, tumor length, tumor width, and tumor height. The
“Tumor info” component references the data value of the “Tumor Number”, and the 
coresponding copies of the “Tumor info” component can be generated dynamicaly. The value
in the “Tumor Number” item field is two and two copies of the “Tumor info” component are 
generated dynamically; 2) the components need not reference other specific component to
decide how many copies of the component need to be generated. This category of component
always has one copy of the component such as the “Diagnosis Date” and “Ascites” 
components.
15
3.5 The methodology for handling missing data during development of predictive model
Although the sensitivity and specificity of CC are 100% and 83%, in fact, the total included
patients’ cases and the total corect prediction cases of CC are both less than that of CV and IMs.
(Table 5) The best sensitivity and specificity of CV are 86% and 79%, respectively. In the study, we
designed the score of IM selection criterion for selecting the more appropriate IMs. The best three
IMs can achieve better predictive accuracy (i.e. the same sensitivity, 86%, and the better specificity,
88%) than CV. The best IM, “BPCA”, can use just four features (included the feature with MVs).  
IMs for data with MVs still show the compatible benefit for the recurrence predictive model.
Table 5. Analysis of CV, CC, and the best three IMs
4 Discussion
In the literature review, the researches regarding to data extraction from textual clinical documents can be
categorized as: 1) marking the concepts and keywords in the textual clinical documents; 2) extracting the
data items in textual documents and filling the extracted data into the predefined templates; 3) providing
the verification interface for users to verify the extracted information. We proposed the approach for
connecting the benefits of these three categories of researches. The information matching modules
provides the capabilities of matching in the textual reports, including matching the keywords and
matching other data items with related semantics. In the extraction verification editor, the matched
information can be further verified; the case-oriented template provides the item fields for clinicians to
fill the matched information semi-automatically.
The adoption of keyword matching profile and the case-oriented template can increase the potential of
utilizing the approach for other textual documents besides the five categories of free-text reports as
mentioned in the paper. The design of the case-oriented template provides the flexibility in the data
collection for different research aims. The matched data are semi-automatically extracted and verified by
the domain experts in the extraction verification editor. After the structuralized data are correctly
extracted and stored back into the clinical data warehouse, the data can be directly retrieved and used for
further analyzing.
In the system, the information can be matched using various highlighted colors, and the different
matching processes based on the distinct keywords can be identified using the colors.
We utilized the benefits provided by the system to assist data extractions from textual clinical documents.
17
[11] C. L. Chuang, "Case-based reasoning support for liver disease diagnosis," Artificial Intelligence in
Medicine, vol. 53, pp. 15-23, 2011.
[12] J. M. Juarez, et al., "A Reuse-Based CBR System Evaluation in Critical Medical Scenarios," in Tools
with Artificial Intelligence, 2009. ICTAI '09. 21st International Conference on, 2009, pp. 261-268.
[13] A. Burton and D. G. Altman, "Missing covariate data within cancer prognostic studies: a review of
current reporting and proposed guidelines," British Journal of Cancer, vol. 91, pp. 4-8, Jul 5 2004.
[14] K. J. Janssen, et al., "Missing covariate data in medical research: to impute is better than to ignore," J
Clin Epidemiol, vol. 63, pp. 721-727, July 2010.
[15] Mabotuwana, T. and J. Warren, "An ontology-based approach to enhance querying capabilities of
general practice medicine for better management of hypertension," Artif Intell Med, vol. 47, pp.
87-103, 2009.
[16] Peleg, M., S. Tu, et al., "Comparing computer-interpretable guideline models: a case-study
approach," J Am Med Inform Assoc, vol. 10, pp. 52-68, 2003.
[17] R. S. Bhatia, et al., "Extracting information for generating a diabetes report card from free text in
physicians notes," presented at the Proceedings of the NAACL HLT 2010 Second Louhi Workshop
on Text and Data Mining of Health Documents, Los Angeles, California, 2010.
[18] A.-L. Minard, et al., "Hybrid methods for improving information access in clinical documents:
concept, assertion, and relation identification," Journal of the American Medical Informatics
Association, May 19, 2011 2011.
19
Cancer ,”The Second AMA-IEEE Medical Technology Conference on Individualized Healthcare,
Boston, MA. USA, Oct. 16-18, 2011.
[4] Ching-Wei Hsu, Xiao-Ou Ping, Ja-Der Liang, Yi-Ju Tseng, Ya-Lin Wu, Pei-Ming Yang,
Guan-Tarn Huang, Yufang Chung, and Feipei Lai, “A CBR-based method for retrieving similar
patients from case base,” The Second AMA-IEEE Medical Technology Conference on
Individualized Healthcare, Boston, MA. USA, Oct. 16-18, 2011.
[5] Xiao-Ou Ping, Ja-Der Liang, Yi-Ju Tseng, Pei-Ming Yang, Guan-Tarn Huang, and Feipei Lai,
“The methodology for handling missing data during development of predictive model,” The 
Second AMA-IEEE Medical Technology Conference on Individualized Healthcare, Boston, MA.
USA, Oct. 16-18, 2011.
98 年度專題研究計畫研究成果彙整表 
計畫主持人：賴飛羆 計畫編號：98-2221-E-002-142-MY3 
計畫名稱：開放式知識探勘平臺 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 5 5 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
