  
中文摘要 
尋找高頻項目集在許多重要的資料探勘應用中扮演了極為關鍵的角色，例如
關聯式規則探勘、循序序列探勘、網路入侵行為分析探勘等，然而如何有效地找
出資料庫中所有高頻項目集卻是一個極富挑戰性的問題。傳統的研究利用由下而
上、廣先搜尋的方式來解決此問題，即不斷地產生候選項目集方式，每一回合中
的高頻項目集均被利用來成為下一回合的候選項目集。然而當資料庫存在候選項
目集個數過多時，利用此種方式有可能造成探勘效率不彰。因此，如何發展出一
種更有效率的高頻項目集探勘方式即為本計畫的研究目的。 
本計畫主要採用分群的方法，並在每一個分群中以支持度傳遞方式找到所有
高頻項目集。不同於傳統演算法，支持度傳遞方式的特點為掃描資料庫一次即可
以由上而下的方式去找到所有的高頻項目集，然而它卻有產生過多項目集的問
題，因此本計畫提出利用分群方法來改善支持度傳遞方式的空間問題。除此之
外，為了驗証本研究計畫的探勘效能，我們也將設計一實驗平台，針對本研究計
畫及傳統的探勘演算法進行實驗數據分析，並歸納出由上而下及由下而上兩種探
勘方式的特點及其適用性以提供更多學者來進行後續研究。 
 
 
關鍵字: 資料探勘，高頻項目集，支持度傳遞，分群方法 
 
 
  2
 1. 前言  
近幾年來，資料挖掘越來越受到資料庫領域的重視，主要原因在於，現今龐
大的資料量早已遠遠超過了人力所能分析的範圍，而利用電腦來有效率地探勘資
料庫中隱含的資訊即為資料挖掘。一般而言，資料挖掘可被分成幾個類別：關聯
規則(Association Rules)、分類(Classification)、分群(Clustering)等。關聯規則挖掘
可以找出資料庫中屬性彼此之間隱含的關聯性；分類探勘是根據已知的資料及其
類別屬性來建立資料的分類模型，並利用此分類模型來預測新進資料的類別屬
性。分群探勘分析資料彼此間的相似程度，自動將性質接近的資料分成一個一個
的群集以推論出令人感興趣的特性和現象。 
關聯規則探勘，是目前極為普遍的資料挖掘技術之一，它的目的是要從銷售
的交易資料庫中，發現商品項目間的關聯，並提供決策者作為參考的依據。關聯
規則挖掘的一個典型應用就是購物籃分析(Market Basket Analysis)。所謂購物籃
分析就是在某商店的銷售事務資料中分析該商店的顧客購物行為，例如“一定比
率的顧客會在一次購物中同時購買什麼商品？”，得知此類資訊之後，決策者就
可以對商品進行促銷或其他活動，以促進顧客的購買欲望。因此，如何從大量的
資料中找出物品間的關聯規則成為一項極為重要的議題。 
關聯規則探勘的相關定義如下:資料庫內的每一筆交易(Transaction)均由項
目(Item)所組成，項目與項目之間可結合成項目集(Itemset)，項目集在所有交易中
的出現比例稱之為項目集之支持度(Support)，若項目集 X之支持度大於等於使用
者定義的最小支持度 (Minimum Support)，則稱 X 為高頻項目集 (Frequent 
Itemset) ，而不被其他高頻項目集所包含的高頻項目集稱為最大高頻項目集
(Maximum Frequent Itemset)。由項目集 X的出現來推論出在同筆交易內亦有項目
集 Y的出現，稱之 X對 Y 的信賴度(Confidence)，若此值大於使用者定義的最小
信賴度(Minimum Confidence)且當 X和 Y均為高頻時，則稱其關聯規則存在，表
示為 XÆY。而找出資料庫內所有關聯規則的過程即稱為關聯規則探勘。 
目前在關聯規則中已經有許多方法被提出，但這些方法都可能會有效能或是
空間上的問題。過去我們曾經提出了一個技術，TDM(Top-Down Mininig )[8]，
由上而下地利用交易拆解及傳遞支持度的方式來探勘高頻項目集，而後，我們又
提出 TDC(Transaction Decomposition with Clustering)[9]來改進 TDM的儲存空間
問題，其結合分群方式及由上而下的交易拆解方式來計數項目集合的支持度，實
驗的結果顯示在大型的資料庫中 TDC有很不錯的效能，然而 TDC卻還是有可能
因為分群方式而帶來了記憶體空間使用上的問題。本研究的主要動機，就是為了
克服 TDC的分群缺點並發展一個有效率的高頻項目集探勘演算法。 
在本論文中，我們提出了一個改善 TDC 的方法，稱為 TDC+，利用高頻 3-
項目集的資訊來將分群結果加以改善，再以交易拆解為基礎來挖掘資料庫中的所
有頻繁項目集。 
 
  4
 料庫，再使用拆解方式由上而下快速的檢查資料庫，但當分群效果不好時，還是
可能嚴重會影響到探勘時的效率。為了克服 TDC的缺點，本研究也提出一個改
善 TDC的方法，命名為 TDC+，利用進一步的資訊將原始資料庫加以切割，進
而使用交易拆解來找出所有高頻項目集。 
 
3. 支持度傳遞演算法 
不同於其他傳統演算法，TDC 以交易拆解方式來效率地計算項目集之支持
度。在交易拆解的方法中，每一個父項目集會將本身的支持度傳遞給自己本身的
所有子項目集，但利用此種方式則會產生支持度多重繼承的問題。即較低層的子
孫項目集會產生較大的支持度。因此，公式(1)被採用來修正計算出正確的支持
度。以下說明公式(1)。 
假設 T = {t1, t2, …, tn}為交易的集合且每筆交易有 m的項目，令 xk是表示長
度為 k的項目集，且被 T中的交易所包含住，其 1≦k≦m-1，每個項目集依據其
本身的長度 k 被歸類在第 k 層，且其在一筆交易中會有(m-k)個父親。Pij為 xk在
第 ti筆交易中的第 j個父親，其 1≦i≦n、1≦j≦m-k。如此利用公式(1)可以即可
計算出 xk的支持度。 
 
⎪⎩
⎪⎨
⎧
>−−
=−
= ∑∑
=
−
=
n
i
km
j
ij
k kmifkmP
kmifT
x
1 1
1)(),/())sup((
1)(,||
)sup(
                       
(1) 
 
表 1-範例交易資料庫 
TID Transaction 
100 {b, c, d, g, e} 
200 {a, b, c, g} 
300 {a, c, g} 
400 {a, b, c} 
 
  
 
 
 
 
圖 1為在拆解方式中計算項目集的虛擬碼。I為項目集，Support_list為記錄
了項目集 I累計的支持度，且這些支持度是由項目集 I的分別在不同層的祖先所
  6
 = (sup(acg) + sup(abg)) / (4-2), 
其中{acg}和{abg}為{ag}的父集合 
sup(acg) =|T|= sup(abcg)= 1, 和 
sup(abg) =|T|= sup(abcg}= 1. 
如此，sup(ag)從{abcg}中所獲得的支持度傳遞為 
   sup(ag) = (1+1)/(4-2) = 1. 
接著，從{acg}中可計算 sup(ag)的支持度傳遞，令 T={acg}，因為{acg}是第
三層而{ag}是第二層，故在公式(1)中，m=3，k=2，我們可以得到的 sup(ag)如下： 
sup(ag) = support(T) = support(acg)= 1 
最後，將{abcg}和{acg}所傳遞過來正確的支持度加總起來，所以 sup{ag}
為 2。 
TDC 中，用一個有效的分群技巧來降低拆解的成本然後再對每一群去找出
候選頻繁項目集。我們修改了 Zaki的演算法來產生 maximal cliques，圖 2為修
改後的演算法內容。[i].CoveringSet 是一個集合，集合的內容是長度為 2 的頻繁
項目集扣除 i 項目的另一個項目集合。[i].CliqList 是開頭項目為 i 的一群 clique
的集合。每一個項目的排序大小在[i].CoveringSet或是在[i].CliqList裡都不會低於
i。第 4行為當在產生 maximal cliques時，考慮到 covering set裡的每一個項目；
第 5行，考慮 covering set裡以每個項目為主的 CliqList。在將新產生的 clique插
入前，必須先將其重複或是子集合給剔除(第 7-8行)。第 9-13行則是保證每一個
clique在MaxCliqList會是 maximal clique。 
 
 
 
 
 
 
 
 
 
 
 
 
  8
 繁項目集，稱為 TDC+。 
 
4. 改善支持度傳遞演算法 
當 TDC 演算法在分群效果不佳時，將會再次造成空間不足的問題，因此在
TDC+中，將會針對 TDC所分群之 maximal cliques過長時，利用更進一步的資訊，
也就是利用高頻 3-項目集的資訊來再一次進行分群，以解決 maximal cliques 過
長的問題，在 4.1節將會說明。TDC+將會結合 TDC演算法與 4.1節所提出的分
群方式，以有效率地挖掘頻繁項目集，我們在 4.2節會有詳細的介紹。 
4.1 改善Maximal Cliques過長問題 
當利用長度為 2的頻繁項目集當作資訊，做第一次分群後，有可能因為歪斜
的狀況，導致分群的效果不彰，而令某筆或甚至多筆 maximal cliques 的長度過
長，如此在交易拆解時，仍有可能造成空間上的問題。因此在本篇論文中，當
maximal clique的長度大於等於 13時，我們稱此 maximal clique為過長，原因是
當 TDC在做交易拆解時，當 maximal clique長度超過 13時，效率明顯變得相當
差。為了將歪斜的情況去除，我們利用更進一步的資訊，找出長度為 3的頻繁項
目集，F3來對過長的 maximal clique再次分群，來確保分群的效果。 
圖 3 為利用 F3為資訊做再次分群的方法。[i].CoveringSet_3-itemsets 是一個
集合，集合的內容是長度為 3 的頻繁項目集扣除 i 項目的另一個項目集合。
[i].CliqList 是開頭項目為 i 的一群 clique 的集合。每一個項目的排序大小在
[i].CoveringSet或是在[i].CliqList裡都不會低於其 i。第 1行為利用掃瞄第三次資
料庫獲得 F3的資訊；第 3行中呼叫了一個名為 join的 procedure，join procedure
為 Apriori演算法中產生候選項目集的方式，也就是利用長度為 k的頻繁項目集，
找到前 k-1個長度相等的項目集，結合成長度為 k+1的候選項目集，如(3, 4, 5)
和(3, 4, 6)會產生(3, 4, 5, 6)，我們利用這樣的概念去對 CoveringSet_3-itemsets裡
的集合內容做 join，直到無法再產生更長的項目集合，並將項目集和放在 CliqList
裡，且必須去除重複或包含狀況。第 5-10行，要將 CliqList裡所有的項目集合加
入 MaxCliqList中，並且必須判斷加入的項目集合，是否與原本存在 MaxCliqList
中的項目集互相包含或重複，若有則必須去除。 
 
 
 
 
 
 
 
 
 
  10
 4.2 TDC+演算法 
Algorithm: TDC  
Input: DB: a transactional database; min_sup: the minimum support. 
Output: F: the set of frequent itemsets  
Parameters: Lk: the set of itemsets in layer k; 
Method:  
1.  Scan DB twice and generate frequent 2-itemsets F2; 
2.  F : = F2; 
3.  if F2≠ φ  then  
4.    MaxCliqList =Max_Clique_Generation(F2); 
5.    for each MaxCliq∈MaxCliqList do begin 
6.      if  length of MaxCliq > 13 then 
7.       remove MaxCliq from MaxCliqList 
8.       Max_Clique_Generation_3-itemsets(MaxCliq) 
9.    end 
10.    for each MaxCliq∈  MaxCliqList 
11.     project DB to DB’ by items in MaxCliq and partition transactions in DB’   
into various layers according to the number of items in each transaction;  
12.     let t be the largest number of items in transactions; 
13.     k : = t; 
14.     Lk : = {c ∈  Lk | c ∉  a descendant of any frequent itemsets in F}; 
15.     for each itemset I ∈  Lk do begin  
16.        if Itemset-count(I, k, Lk+1) ≧ min_sup then  
17.          F : = F ∪  { I } ; 
18.          Lk : = Lk - { I }; 
19.        else 
20.          for each child I’ of I do begin 
21.            Lk-1 : = Lk-1 ∪  { I’}; 
22.         end 
23.     end 
24.     k : = (k-1);  
25.     if k > 2 then go to line 8;  
圖 4. The TDC+ algorithm 
圖 4為 TDC+完整的演算法。第 1行，掃瞄兩次資料庫來取得長度為 2的頻
  12
 5、實驗結果與討論 
5.1 開發工具版本與硬體規格 
為了去評估 TDC+的效率，我們實作了四個演算法，分別為 Apriori、
Pincer-Search、TDC 和 TDC+，在各種不同類型的資料庫上探勘頻繁項目集。本
論文實作的系統環境為 AMD Althlon 64 X2 Dual Core Processor 4600+ 2.41GHz 
PC with 1.5GB memory，作業系統是Microsoft Windows-XP，使用 C++做程式設
計。我們藉由 IBM Data Mining Research Group所提供的程式，來產生測試資料
庫。每個資料庫的特性是由 4或 5個參數來制訂且命名。表 3概述在我們實驗中
所使用到的參數。 
表 2.主機硬體配備 
硬體 規格/型號
主機 HP DL380 G4
中央處理器(CPU) AMD Althlon 64 X2 Dual Core 
記憶體(RAM) 1.5G
硬碟容量 500G
作業系統 Microsoft Windows XP 
程式語言 C++
 
 
表3. THE  PARAMETERS OF TEST DATABASES 
|D| Number of transactions per database 
|T| Average number of items per transaction 
|I| Average length of maximal frequent patterns 
|N| Number of items per database 
|L| Number of patterns 
5.2 實驗結果與分析 
第一個實驗，圖 6為四個演算法 Apriori、Pincer Search、TDC、TDC+在執行
時間上的比較，在 T10I6D100KN1000L50 資料庫上利用各種不同的最小支持度
來進行比較。TDC演算法的執行效率，會受制於 maximal cliques的長度與個數，
因此當最小支持度越來越小時，不僅 maximal cliques的個數會越來越多，maximal 
cliques的長度也有可能越來越長，當最小支持度在 2%時，產生了 38筆 maximal 
cliques，其中最長的 maximal clique長度為 17，因此在拆解時造成了項目集過多
的空間問題，以致於執行時間過長，而無法記載，然而 TDC+則會針對過長的
maximal cliques 做再一次的分群，產生了 59 筆 maximal cliques，其中最長的
  14
 況下，掃瞄資料庫的次數都一樣，也因此其執行的時間也幾乎都相同。當最大頻
繁型樣平均長度為 20時，TDC產生 138筆的 maximal cliques，而主要影響執行
效率的是裡面有多筆 maximal cliques 長度為 16，導致執行時間攀高，而 TDC+
則只有 108筆 maximal cliques產生且最長長度為 10。當最大頻繁型樣平均長度
為 25時，TDC產生 928筆的 maximal cliques且最長長度為 24，由於拆解項目集
個數過多，使其執行時間過長而無法記載；TDC+則產生 138筆 maximal cliques
且其最長長度為 10，故仍可探勘出資料庫中的高頻項目集。 
由實驗可知，TDC+不論是在最小支持度較小時，或是平均高頻項目集較長
時，執行的探勘時間都優於其他演算法，並可改進 TDC 且有效的探勘出高頻項
目集。 
6. 結論 
在本研究中，我們提出了改善 TDM的兩個演算法，稱為 TDC與 TDC+，以
進行頻繁項目集挖掘。TDC+利用更進一步的資訊來確保可以將原始資料庫切割
成部分較小的特性資料庫，令其每個部分可以被利用交易拆解方式獨立地被探
勘。TDC+在當最小支持度很小時或是當頻繁型樣的長度較長時，仍能有效地挖
掘所有的頻繁項目集。實驗結果也顯示 TDC+在效能上可以勝出其他的演算法，
並改進 TDC以更有效率地方式來探勘出高頻項目集。 
7 計畫成果自評 
本計劃之研究成果已達成計畫書中所提預期達到的系統架構與功能，並在真實
環境中開發出與現有演算法比較的系統平台，此研究除了在探勘高頻項目集外，
對於探勘最大高頻項目集及資料流的高頻項目集也能有很大的助益。 
本研究之成果除了有一篇國際會議論文[9]發表。以及發表一篇論文於 2009 數
位生活科技研討會[18]之外，也有一本碩士論文[20]，另外我們也有一篇論文” A 
Hybrid Method for Mining Frequent Itemsets Using Decomposition and Clustering”
投稿至 SCI期刊 Journal of Information Science and Engineering，目前正審稿中。 
     
8參考文獻 
[1] R. Agrawal, T. Imielinski, and A. Swami (1993) Mining Association Rules 
(2005) MAFIA: A 
Between Sets of Items in Large Databases, Proc. of the ACM SIGMOD Conf. on 
Management of Data, pp. 207-216.  
[2] R. Agrawal and R. Srikant (1994) Fast Algorithm for Mining Association Rules 
in Large Databases, Proc. of 20th VLDB Conf., pp. 487-499. 
[3] D. Burdick, M. Calimlim, J. Flannick, J. Gehrke, and T. Yiu 
  16
   18
[17] http://researchweb.watson.ibm.com 
[18] 陳宏賓，林克仲，廖宜恩，<一種改進支持度傳遞的有效分群演算法>，2009 
數位生活科技研討會，成功大學，May 28-29, 2009。NSC 97-2221-E-005-083. 
[19] 廖宜恩、陳志勝、林克仲，「一個改進頻繁樣式成長法的挖掘關聯規則探勘
方法」，第七屆離島資訊技術與應用研討會(ITAOI2008)，澎湖吉貝，May 
30-31, 2008, pp.183-191。 
[20] 陳宏賓，<基於項目集分群的交易拆解方式進行高頻項目集探勘>，中興大
學資訊科學與工程研究所，碩士論文，2009。 
 
In this paper, we proposed a new method, called TDC  
(Transaction Decomposition with Clustering), that combines 
the transaction decomposition method and the clustering 
technique to discover frequent itemsets. TDC divides the 
original lattice into smaller pieces such that each portion can 
be solved by pattern decomposition method independently. 
Experimental results show that this new algorithm has very 
short execution time and its performance is relatively 
independent of the minimum support threshold. 
This paper is organized as follows. Section 2 presents the 
related work, and Section 3 defines the problem to be solved. 
Section 4 describes the details of the TDC method and 
Section 5 shows our experimental results. Finally, Section 6 
concludes this paper. 
II. RELATED WORK 
Since Agrawal [1-2] introduced the frequent itemset 
mining problem, several algorithms for solving the problem 
have been proposed [1-7, 9-15]. The Apriori algorithm [1-2] 
utilizes a bottom-up strategy to discover frequent itemsets 
from a database. It uses a candidate generation method such 
that the frequent k-itemsets at one level can be used to 
construct candidate (k+1)-itemsets at the next level. However, 
it has to scan the database many times for verifying frequent 
itemsets. DHP [11] improves the performance of Apriori. It 
uses a hash table to reduce the number of candidate 2-itemsets 
and employs a database trimming technique to lower the costs 
of database scanning. Pincer-Search [9] combines both the 
top-down and bottom-up searches. However, the number of 
database scans of Pincer-Search may be the same as that of 
Apriori in the worst case. 
FP-Growth [6-7] is a different approach from the Apriori 
algorithm. Without candidate generation, the FP-Growth 
method uses a pattern growth approach to find the frequent 
itemsets. It first scans database twice and generates a FP-tree 
for storing the frequency information of the transaction 
database. By employing a divide-and-conquer method on the 
FP-tree, the support of each itemset is determined. 
Nevertheless, the recursive mining may decrease the whole 
mining performance. Thus, several approaches are proposed 
for improving the performance of  FP-Growth [5, 12]. 
Combining clustering techniques with association-rule 
methods has been widely discussed recently. CDAR [14] 
partitions a database into several clusters by transaction length 
and employs a top-down manner to mine frequent itemsets. If 
an itemset X is frequent, both X and all its subsets will be 
output and then removed from the clusters because all of its 
subsets must be also frequent. Thus, CDAR improves the 
performance by decreasing the members in clusters. 
MaxClique [15] separates itemsets into various clusters 
alphabetically, and a sub-lattice is constructed for each cluster. 
By traversing these sub-lattices individually, MaxClique is 
very efficient to discover frequent itemsets. Nevertheless, 
skewedness is a potential problem with the clustering step in 
MaxClique.  
Recently, we proposed a hierarchical mining technique 
called TDM [8] to discover frequent patterns. The major 
feature of this technique is to examine database transactions 
in a top-down manner, resulting in lowering the I/O cost in 
counting patterns from a large database. However, the 
decomposition method may incur a space problem when it 
generates too many sub-patterns during the decomposition 
process.  
To overcome the drawback of transaction decomposition 
method, this paper proposes a new algorithm, namely TDC 
(Transaction Decomposition with Clustering), which 
combines decomposition method with clustering to improve 
the throughput of frequent itemset mining. 
III. PROBLEM DESCRIPTON 
TDM can count the support of itemsets efficiently based 
on its transaction decomposition method. All of the subsets of 
a transaction T form a full lattice. The full lattice is partitioned 
into layers, and each itemset at the layer k has the length of k. 
In the decomposition method, each parent propagates its 
support to all of its children. The descendants in lower layers 
may have larger support than their real one due to multiple 
inheritances from the transactions. Thus, equation (1) is 
adopted in decomposition method to get the correct support of 
a descendant.  
Assume that T = {t1, t2, …, tn} is a set of transactions in 
which each transaction has m items. Let xk represent an k-
itemset that is contained in each transaction in T. Each itemset 
xk in the layer k will have (m-k) parents in one transaction. Let 
Pij represent the jth parent of xk in the transaction ti (1≦k≦i-
1). 
⎪⎩
⎪⎨
⎧
>−−
=−
= ∑∑
=
−
=
n
i
km
j
ij
k kmifkmPsup
kmifT
xsup
1 1
1)(),/())((
1)(,||
)(      (1)    
Figure 1 displays the procedure of counting an itemset in 
decomposition method. For an itemset I, the Support_list 
records its accumulated supports inherited from I’s ancestors 
in various layers. 
Let us consider the database in TABLE Ⅰ , which 
comprises four transactions: {(b, c, d, g, e), (a, b, c, g), (a, c, g) 
and (a, b, c)}. Suppose that the support of each transaction is 
1. 
 
Line 5 generates the maximal cliques for items in the covering 
set for each class. Before inserting a new clique, all duplicates 
or subsets are eliminated (Line 7 - Line 8). Line 9 - Line 13 
guarantees that each clique in MaxCliqList is a maximal 
clique. 
Algorithm: TDC  
Input: DB: a transactional database; min_sup: the minimum 
support. 
Output: F: the set of frequent itemsets being mined 
Parameters: Lk: the set of itemsets in layer k; 
Method:  
1.  Scan DB twice and generate frequent 2-itemsets F2; 
2.  F : = F2; 
3.  if F2≠ φ  then  
4.    MaxCliqList =Max_Clique_Generation(F2); 
5.    for each MaxCliq∈  MaxCliqList 
6.  project DB to DB’ by items in MaxCliq and 
partition transactions in DB’ into various layers 
according to the number of items in each 
transaction;  
7.       let t be the largest number of items in transactions;
8.       k : = t; 
9. Lk : = {c ∈  Lk | c ∉  a descendant of any frequent 
itemsets in F}; 
10.       for each itemset I ∈  Lk do begin  
11.           if Itemset-count(I, k, Lk+1) ≧ min_sup then  
12.              F : = F ∪  { I } ; 
13.              Lk : = Lk - { I }; 
14.           else 
15.              for each child I’ of I do begin 
16.                 Lk-1 : = Lk-1 ∪  { I’}; 
17.            end 
18.       end 
19.      k : = (k-1);  
20.      if k > 2 then go to line 8;  
Figure 3. The TDC algorithm 
 
We use an example to show that how we generate 
maximal cliques. Let F2 be {13, 14, 15, 16, 23, 25, 34, 35, 
45}. Based on F2, four covering sets {[1]:{3, 4, 5, 6}, [2]:{3, 
5}, [3]:{4, 5}, [4]:{5}} are generated. For covering set [3], 
the intersection of covering set [3] and [4].CliqList (i.e., {3, 4, 
5} {4, 5}) is {4, 5}. Next, a cliq[3, 4, 5] (i.e., {3} {4, 5}) 
is generated and inserted into [3].CliqList and MaxCliqList. 
Performing the same process on [2] and [1], cliq[2, 3, 5] and 
cliq[1, 3, 4, 5] are added into MaxCliqList. In addition, cliq[3, 
4, 5] is removed from MaxCliqList since it is a subset of 
cliq[1, 3, 4, 5]. Therefore, two maximal cliques (cliq[1, 3, 4, 5] 
and cliq[2, 3, 5]) are available in this example. 
∩ ∪
B.  The TDC Algorithm 
Figure 3 shows the whole TDC algorithm. Line 1 scans 
database twice in order to get the set of frequent 2-itemsets F2. 
Line 4 generates all maximal cliques from F2. Based on 
maximal cliques, TDC partitions the database into a set of 
projected databases, and then for each projected database, 
perform its corresponding decomposition method (Line 5 - 
Line 20). Line 9 excludes those descendants of any frequent 
itemsets in F. Line 11 calls the Itemset-count method to count 
itemset’s support. Line 16 adds the children of I to the set of 
itemsets in layer (k-1) for further mining in the next iteration. 
As an example, we use TDC to mine frequent itemsets 
from DB in Table 1 and let the min_sup be 2. By scanning 
database twice, five frequent 2-itemsets F2={ab, ac, bc, ag, cg} 
are generated. The procedure Max_Clique_Generation is used 
for generating two maximal cliques (i.e., cliq[abc] and 
cliq[acg]).  Based on the two cliques, TDC builds projected 
databases correspondingly. The two projected databases, D1 
and D2, are shown in Figure 4. TDC then employs the 
Procedure: Max_Clique_Generation 
Parameter: Nmax: the maximum item’s identifier; Nmin: the 
minimum item’s identifier;  
Input: F2: the set of frequent 2-itemsets; 
Output: MaxCliqList: a list of maximal cliques; 
Method: 
1. MaxCliqList=φ ; 
2. for (i’s identifier = Nmax; i’s identifier >= Nmin; i--) do 
3.   [i].CliqList=φ ; 
4.   for each x∈[i].CoveringSet do 
5.     for each cliq∈[x].CliqList do 
6.       M = cliq ∩  [i]; 
7.       if (M≠ φ ) and ({{i}∪M}≠ any subset of cliques 
in [i].CliqList) then 
8.          add {{i}∪M} into [i].CliqList 
9.     for each cliq’∈[i].CliqList do 
10.       for each cliq”∈MaxCliqList do 
11.         if cliq”⊆  cliq’ then 
12.           remove cliq” from MaxCliqList; 
13.           add cliq’ to MaxCliqList; 
Figure 2. Maximal clique generation procedure 
 Figure 7 shows the running time of the three algorithms 
on T10I6D100KN1000L50 with respect to various minimum 
supports. TDC outperforms Apriori and Pincer-Search in the 
data set. The length of maximal frequent itemsets in the data 
set is 9 and TDC generates 22 maximal cliques in the data set. 
As the minimum support was set to 10%, the number of 
database scans of Apriori is equal to that of Pincer Search, 
resulting in almost the same performance. 
1
10
100
1000
10000
4% 6% 8% 10% 12% 14%
Ex
ec
ut
io
n 
tim
e 
(s
)
Minimum Support (%)
Apriori Pincer Search TDC
Figure 7. Performance under various minimum support on 
T10I6D100KN1000L50 
 
For the fourth database group, the scalability with the 
number of transactions was tested. The minsup was set to 
1.5% in the databases T10I4N1000 with various numbers of 
transactions, from 10K to 1000K. We illustrate the execution 
results in Figure 8.  When the size of database increases, the 
cost of scanning database makes the performance of Apriori 
and that of Pincer-Search get worse. In contrast, even if the 
database size becomes large, TDC can mine frequent itemsets 
efficiently. 
 
From the experimental results, TDC is an efficient 
algorithm for mining frequent itemsets in the database. Even 
if the size of the database becomes large, TDC is also very 
efficient. Therefore,  TDC is suitable for different types of 
high performance applications.  
VI. CONCLUSION 
By contrast with the traditional approaches of mining 
frequent itemsets, we proposed an efficient method called 
TDC algorithm. TDC employs a clustering technique to 
alleviate the space problem in the transaction decomposition 
method. It partitions the original database into smaller 
projected databases such that each portion can be solved by 
decomposition method independently. Experimental results 
show that the proposed TDC algorithm outperforms its 
counterpart algorithms in execution time.  
REFERENCES 
[1] R. Agrawal, T. Imielinski, and A. Swami, “Mining 
Association Rules Between Sets of Items in Large 
Databases,” Proc. of the ACM SIGMOD Conf. on 
Management of Data, pp. 207-216, 1993.  
[2] R. Agrawal and R. Srikant, “Fast Algorithm for Mining 
Association Rules in Large Databases,” Proc. of 20th 
VLDB Conf., pp. 487-499, 1994. 
[3] D. Burdick, M. Calimlim, J. Flannick, J. Gehrke, and T. 
Yiu, “MAFIA: A Maximal Frequent Itemset Algorithm,” 
IEEE Transactions on Knowledge and Data Engineering, 
Vol.17, No.11, pp.1490-1504, 2005. 
[4] A. Ghoting, G. Buehrer, S. Parthasarathy, D. Kim, A. 
Nguyen, Y. Chen, and P. Dubey, “Cache-Conscious 
Frequent Pattern Mining on Modern and Emerging 
Processors,” The International Journal on Very Large 
Data Bases, Vol. 16, Issue 1, pp. 77–96, 2007. 
1
10
100
1000
10000
100000
0.25% 0.50% 0.75% 1.00% 1.50% 2.00%
Ex
ec
ut
io
n 
tim
e 
(s
)
Minimum Support (%)
Apriori Pincer Search TDC
Figure 6. Performance under various minimum support on 
T10I6D100KN1000 
Apriori Pincer Search TDC
1
10
100
1000
10000
10k 50k 100k 250k 500k 750k 1000k
Ex
ec
ut
io
n 
tim
e 
(s
)
Number of transactions
Figure 8. Performance under various numbers of transactions
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 97-2221-E-005 -083 
計畫名稱 以有效分群方法進行高頻項目集探勘 
出國人員姓名 
服務機關及職稱 
廖宜恩 
中興大學資訊科學與工程學系教授 
會議時間地點 July 13-16,2009, Las Vegas, USA 
會議名稱 The 5th International Conference on Data Mining 
發表論文題目 Mining Frequent Itemsets by Transaction Decomposition with Itemset Clustering 
 
一、參加會議經過 
 
    本次研討會於 2009 年 7 月 13-16 日，在美國 Las Vegas 舉行。這次會議總共有 62 篇來
自世界各國的論文，分 10 個 Session 發表，我的論文報告安排在第三天下午。  
 
 
二、與會心得 
 
本研討會是較大型的國際會議，主辦單位特別邀請幾位知名的學者作主題演講(Keynote 
Lecture)，包括 Ian Foster 教授主講 ”Grid Computing”、Eric Drexler 教授主講 ”Advanced 
Nanotechnology: Advanced Computing on the Critical Path”、 Viktor Prasanna 教授主講 
“Algorithm Design for Reconfigurable Computing Systems”等，以及多場的專題演講
(Tutorials)，如:” Data Mining with Sensitivity to Rare Events and Class Imbalance”, 
“Autonomous Machine Learning”, “A Tour of Advanced Data Mining Methodologies”等，這
些演講都讓我受益良多。我報告論文後，也引起蠻熱烈的討論，成果受到與會者的肯定。
本人對於能出席這次會議並發表論文，並和來自不同國家的學者交換意見，深覺獲益良
多。所發表之論文附錄如下： 
 
 
In this paper, we proposed a new method, called TDC  
(Transaction Decomposition with Clustering), that combines 
the transaction decomposition method and the clustering 
technique to discover frequent itemsets. TDC divides the 
original lattice into smaller pieces such that each portion can 
be solved by pattern decomposition method independently. 
Experimental results show that this new algorithm has very 
short execution time and its performance is relatively 
independent of the minimum support threshold. 
This paper is organized as follows. Section 2 presents the 
related work, and Section 3 defines the problem to be solved. 
Section 4 describes the details of the TDC method and 
Section 5 shows our experimental results. Finally, Section 6 
concludes this paper. 
II. RELATED WORK 
Since Agrawal [1-2] introduced the frequent itemset 
mining problem, several algorithms for solving the problem 
have been proposed [1-7, 9-15]. The Apriori algorithm [1-2] 
utilizes a bottom-up strategy to discover frequent itemsets 
from a database. It uses a candidate generation method such 
that the frequent k-itemsets at one level can be used to 
construct candidate (k+1)-itemsets at the next level. However, 
it has to scan the database many times for verifying frequent 
itemsets. DHP [11] improves the performance of Apriori. It 
uses a hash table to reduce the number of candidate 2-itemsets 
and employs a database trimming technique to lower the costs 
of database scanning. Pincer-Search [9] combines both the 
top-down and bottom-up searches. However, the number of 
database scans of Pincer-Search may be the same as that of 
Apriori in the worst case. 
FP-Growth [6-7] is a different approach from the Apriori 
algorithm. Without candidate generation, the FP-Growth 
method uses a pattern growth approach to find the frequent 
itemsets. It first scans database twice and generates a FP-tree 
for storing the frequency information of the transaction 
database. By employing a divide-and-conquer method on the 
FP-tree, the support of each itemset is determined. 
Nevertheless, the recursive mining may decrease the whole 
mining performance. Thus, several approaches are proposed 
for improving the performance of  FP-Growth [5, 12]. 
Combining clustering techniques with association-rule 
methods has been widely discussed recently. CDAR [14] 
partitions a database into several clusters by transaction length 
and employs a top-down manner to mine frequent itemsets. If 
an itemset X is frequent, both X and all its subsets will be 
output and then removed from the clusters because all of its 
subsets must be also frequent. Thus, CDAR improves the 
performance by decreasing the members in clusters. 
MaxClique [15] separates itemsets into various clusters 
alphabetically, and a sub-lattice is constructed for each cluster. 
By traversing these sub-lattices individually, MaxClique is 
very efficient to discover frequent itemsets. Nevertheless, 
skewedness is a potential problem with the clustering step in 
MaxClique.  
Recently, we proposed a hierarchical mining technique 
called TDM [8] to discover frequent patterns. The major 
feature of this technique is to examine database transactions 
in a top-down manner, resulting in lowering the I/O cost in 
counting patterns from a large database. However, the 
decomposition method may incur a space problem when it 
generates too many sub-patterns during the decomposition 
process.  
To overcome the drawback of transaction decomposition 
method, this paper proposes a new algorithm, namely TDC 
(Transaction Decomposition with Clustering), which 
combines decomposition method with clustering to improve 
the throughput of frequent itemset mining. 
III. PROBLEM DESCRIPTON 
TDM can count the support of itemsets efficiently based 
on its transaction decomposition method. All of the subsets of 
a transaction T form a full lattice. The full lattice is partitioned 
into layers, and each itemset at the layer k has the length of k. 
In the decomposition method, each parent propagates its 
support to all of its children. The descendants in lower layers 
may have larger support than their real one due to multiple 
inheritances from the transactions. Thus, equation (1) is 
adopted in decomposition method to get the correct support of 
a descendant.  
Assume that T = {t1, t2, …, tn} is a set of transactions in 
which each transaction has m items. Let xk represent an k-
itemset that is contained in each transaction in T. Each itemset 
xk in the layer k will have (m-k) parents in one transaction. Let 
Pij represent the jth parent of xk in the transaction ti (1≦k≦i-
1). 
⎪⎩
⎪⎨
⎧
>−−
=−
= ∑∑
=
−
=
n
i
km
j
ij
k kmifkmPsup
kmifT
xsup
1 1
1)(),/())((
1)(,||
)(      (1)    
Figure 1 displays the procedure of counting an itemset in 
decomposition method. For an itemset I, the Support_list 
records its accumulated supports inherited from I’s ancestors 
in various layers. 
Let us consider the database in TABLE Ⅰ , which 
comprises four transactions: {(b, c, d, g, e), (a, b, c, g), (a, c, g) 
and (a, b, c)}. Suppose that the support of each transaction is 
1. 
 
Line 5 generates the maximal cliques for items in the covering 
set for each class. Before inserting a new clique, all duplicates 
or subsets are eliminated (Line 7 - Line 8). Line 9 - Line 13 
guarantees that each clique in MaxCliqList is a maximal 
clique. 
Algorithm: TDC  
Input: DB: a transactional database; min_sup: the minimum 
support. 
Output: F: the set of frequent itemsets being mined 
Parameters: Lk: the set of itemsets in layer k; 
Method:  
1.  Scan DB twice and generate frequent 2-itemsets F2; 
2.  F : = F2; 
3.  if F2≠ φ  then  
4.    MaxCliqList =Max_Clique_Generation(F2); 
5.    for each MaxCliq∈  MaxCliqList 
6.  project DB to DB’ by items in MaxCliq and 
partition transactions in DB’ into various layers 
according to the number of items in each 
transaction;  
7.       let t be the largest number of items in transactions;
8.       k : = t; 
9. Lk : = {c ∈  Lk | c ∉  a descendant of any frequent 
itemsets in F}; 
10.       for each itemset I ∈  Lk do begin  
11.           if Itemset-count(I, k, Lk+1) ≧ min_sup then  
12.              F : = F ∪  { I } ; 
13.              Lk : = Lk - { I }; 
14.           else 
15.              for each child I’ of I do begin 
16.                 Lk-1 : = Lk-1 ∪  { I’}; 
17.            end 
18.       end 
19.      k : = (k-1);  
20.      if k > 2 then go to line 8;  
Figure 3. The TDC algorithm 
 
We use an example to show that how we generate 
maximal cliques. Let F2 be {13, 14, 15, 16, 23, 25, 34, 35, 
45}. Based on F2, four covering sets {[1]:{3, 4, 5, 6}, [2]:{3, 
5}, [3]:{4, 5}, [4]:{5}} are generated. For covering set [3], 
the intersection of covering set [3] and [4].CliqList (i.e., {3, 4, 
5} {4, 5}) is {4, 5}. Next, a cliq[3, 4, 5] (i.e., {3} {4, 5}) 
is generated and inserted into [3].CliqList and MaxCliqList. 
Performing the same process on [2] and [1], cliq[2, 3, 5] and 
cliq[1, 3, 4, 5] are added into MaxCliqList. In addition, cliq[3, 
4, 5] is removed from MaxCliqList since it is a subset of 
cliq[1, 3, 4, 5]. Therefore, two maximal cliques (cliq[1, 3, 4, 5] 
and cliq[2, 3, 5]) are available in this example. 
∩ ∪
B.  The TDC Algorithm 
Figure 3 shows the whole TDC algorithm. Line 1 scans 
database twice in order to get the set of frequent 2-itemsets F2. 
Line 4 generates all maximal cliques from F2. Based on 
maximal cliques, TDC partitions the database into a set of 
projected databases, and then for each projected database, 
perform its corresponding decomposition method (Line 5 - 
Line 20). Line 9 excludes those descendants of any frequent 
itemsets in F. Line 11 calls the Itemset-count method to count 
itemset’s support. Line 16 adds the children of I to the set of 
itemsets in layer (k-1) for further mining in the next iteration. 
As an example, we use TDC to mine frequent itemsets 
from DB in Table 1 and let the min_sup be 2. By scanning 
database twice, five frequent 2-itemsets F2={ab, ac, bc, ag, cg} 
are generated. The procedure Max_Clique_Generation is used 
for generating two maximal cliques (i.e., cliq[abc] and 
cliq[acg]).  Based on the two cliques, TDC builds projected 
databases correspondingly. The two projected databases, D1 
and D2, are shown in Figure 4. TDC then employs the 
Procedure: Max_Clique_Generation 
Parameter: Nmax: the maximum item’s identifier; Nmin: the 
minimum item’s identifier;  
Input: F2: the set of frequent 2-itemsets; 
Output: MaxCliqList: a list of maximal cliques; 
Method: 
1. MaxCliqList=φ ; 
2. for (i’s identifier = Nmax; i’s identifier >= Nmin; i--) do 
3.   [i].CliqList=φ ; 
4.   for each x∈[i].CoveringSet do 
5.     for each cliq∈[x].CliqList do 
6.       M = cliq ∩  [i]; 
7.       if (M≠ φ ) and ({{i}∪M}≠ any subset of cliques 
in [i].CliqList) then 
8.          add {{i}∪M} into [i].CliqList 
9.     for each cliq’∈[i].CliqList do 
10.       for each cliq”∈MaxCliqList do 
11.         if cliq”⊆  cliq’ then 
12.           remove cliq” from MaxCliqList; 
13.           add cliq’ to MaxCliqList; 
Figure 2. Maximal clique generation procedure 
 Figure 7 shows the running time of the three algorithms 
on T10I6D100KN1000L50 with respect to various minimum 
supports. TDC outperforms Apriori and Pincer-Search in the 
data set. The length of maximal frequent itemsets in the data 
set is 9 and TDC generates 22 maximal cliques in the data set. 
As the minimum support was set to 10%, the number of 
database scans of Apriori is equal to that of Pincer Search, 
resulting in almost the same performance. 
1
10
100
1000
10000
4% 6% 8% 10% 12% 14%
Ex
ec
ut
io
n 
tim
e 
(s
)
Minimum Support (%)
Apriori Pincer Search TDC
Figure 7. Performance under various minimum support on 
T10I6D100KN1000L50 
 
For the fourth database group, the scalability with the 
number of transactions was tested. The minsup was set to 
1.5% in the databases T10I4N1000 with various numbers of 
transactions, from 10K to 1000K. We illustrate the execution 
results in Figure 8.  When the size of database increases, the 
cost of scanning database makes the performance of Apriori 
and that of Pincer-Search get worse. In contrast, even if the 
database size becomes large, TDC can mine frequent itemsets 
efficiently. 
 
From the experimental results, TDC is an efficient 
algorithm for mining frequent itemsets in the database. Even 
if the size of the database becomes large, TDC is also very 
efficient. Therefore,  TDC is suitable for different types of 
high performance applications.  
VI. CONCLUSION 
By contrast with the traditional approaches of mining 
frequent itemsets, we proposed an efficient method called 
TDC algorithm. TDC employs a clustering technique to 
alleviate the space problem in the transaction decomposition 
method. It partitions the original database into smaller 
projected databases such that each portion can be solved by 
decomposition method independently. Experimental results 
show that the proposed TDC algorithm outperforms its 
counterpart algorithms in execution time.  
REFERENCES 
[1] R. Agrawal, T. Imielinski, and A. Swami, “Mining 
Association Rules Between Sets of Items in Large 
Databases,” Proc. of the ACM SIGMOD Conf. on 
Management of Data, pp. 207-216, 1993.  
[2] R. Agrawal and R. Srikant, “Fast Algorithm for Mining 
Association Rules in Large Databases,” Proc. of 20th 
VLDB Conf., pp. 487-499, 1994. 
[3] D. Burdick, M. Calimlim, J. Flannick, J. Gehrke, and T. 
Yiu, “MAFIA: A Maximal Frequent Itemset Algorithm,” 
IEEE Transactions on Knowledge and Data Engineering, 
Vol.17, No.11, pp.1490-1504, 2005. 
[4] A. Ghoting, G. Buehrer, S. Parthasarathy, D. Kim, A. 
Nguyen, Y. Chen, and P. Dubey, “Cache-Conscious 
Frequent Pattern Mining on Modern and Emerging 
Processors,” The International Journal on Very Large 
Data Bases, Vol. 16, Issue 1, pp. 77–96, 2007. 
1
10
100
1000
10000
100000
0.25% 0.50% 0.75% 1.00% 1.50% 2.00%
Ex
ec
ut
io
n 
tim
e 
(s
)
Minimum Support (%)
Apriori Pincer Search TDC
Figure 6. Performance under various minimum support on 
T10I6D100KN1000 
Apriori Pincer Search TDC
1
10
100
1000
10000
10k 50k 100k 250k 500k 750k 1000k
Ex
ec
ut
io
n 
tim
e 
(s
)
Number of transactions
Figure 8. Performance under various numbers of transactions
