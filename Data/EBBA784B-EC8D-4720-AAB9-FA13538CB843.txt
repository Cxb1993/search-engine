 2
(5) GPS satellite Positioning Applied to 
Navigation in Urban Canyons, 
(6) Development and Implementation of a 
Visualization-based Geoinformation 
system for Cyber City. 
This report demonstrates the first year 
achievements of the project. It reveals that 
the targets of the project have been reached. 
In addition, journal papers relating to the 
project have been accepted for publication. 
 
Keywords: Cyber City, Geoinformation, 
Acquisition, Analysis, Integration, 
Visualization, Imagery, Lidar, Video, 
Positioning technique 
二、前言與研究目的 
數碼城市若能將都市的管理者與居
民藉由網際網路快速交換資訊，並作最佳
之決策，則未來之都市管理更能顯現高的
效率與效能。數碼城市是未來社會資訊化
實際展現，在其所包含諸多資訊中與空間
相關者是不可或缺的。數碼城市所需的空
間資訊就靜態而言主要在於建置立體的
模型，就動態而言，則在於即時之定位技
術及快速影像資訊探測能力及特徵萃取
及變遷偵測。城市之立體模型以房屋及道
路為主。房屋之模型除屋頂面形狀外，側
面形狀及紋理就虛擬空間之視覺化而言
是必須的。城市中的道路模型則需考慮多
層道路系統中之立體交叉。在動態監測部
份，採用影像獲取動態資料，無疑地，是
最佳之選擇。然而在資料獲取之瞬間，探
測器之方位求取須藉由動態定位之技
術。衛星全球定位系統是相當成熟之定位
技術，但在高樓林立之都會區將造成衛星
之幾何配置不良，因此因應之定位技術亦
需加以研發。此種動態定位技術之應用當
然不限於影像獲取系統之定位，其他如導
航，LBS 亦是數碼城市中重要的資訊獲取
技術。 
基於以上之需求，本整合計畫共有六個子
計畫，包括： 
(1)整合空載多元探測技術及空間資料重
建都市之人工建物及植被覆蓋模型， 
(2)應用地面光達及近景攝影測量建置三
維實體場景 
(3)空載光達點雲數據擷取線型特徵研究 
(4)整合視訊資料及空間資料於數碼城市
中目標追蹤及定位 
(5)衛星GPS 定位於都會峽谷區導航應用
之研究 
(6)數碼城市視覺化空間資訊系統建置之
研究 
空載光達為一個結合雷射測距系
統、全球定位系統(GPS)以及慣性導航系
統(INS)等三部分的整合性技術。空載光達
點雲數據的精度與此三個組成系統息息
相關，其影響因素包括[Maas, 2002]：斜距
的量測精度，雷射系統掃描角解析力及機
械的震動影響，GPS 的精度，INS/GPS 系
統整合之精度及雷射系統、載具及
GPS/INS 間的校準誤差。 
藉由光達能快速的獲取地表物三維
點位資訊的特點，並且相較於航照資料及
二維向量資料有較佳的精度。光達資料的
引進，使得房屋模型的精確度及自動化程
度更向前邁進了一步。如以光達資料自動
化產生房屋模型[Oda et al., 2004]。也有許
多研究以資料融合的方式，目的是為了結
合各種資料的優點，產生更精確的房屋模
型。如以光達資料結合航照資料具有邊界
資訊的優點，產生房屋模型[Rottensteiner 
et al., 2004]，或以光達資料結合二維向量
地圖屋緣線明確的優點，產生房屋模型
[Vosselman & Dijkman, 2001]。其他如以光
 4
成四類[Lohmann et al.,2000]：即型態學過
濾法[ Vosselman,2000]，線性推估[Pfeifer 
et al., 2001] ， 曲 面 近 似 法 
[ Axelsson,2000]，及一般影像處理法  
[Priestnall et al., 2000]。 
由離散點所組成之點雲，其線形特徵
為隱含，若直接由此離散點雲內插、格網
化，所產生之數值高程模型忽略了地性
線，如稜線、谷線、斷線等特質，其內插
成果從而有多種缺失，不能真實描述地
形。其解決方案之一為由其他圖資，如平
面圖、地形圖，獲得相關資料。但是，由
離散點雲所組成之高程模型，其內部實際
上含有地性線之資料。故而，先行由點雲
萃取地性線，應為另一種方案。子計劃三
以空載光達所產製之數值高程模型為主
題，依序由點雲資料預處理、點雲數據格
網化、進而探討由其產生線形特徵之相關
問題。初期研究將以集水區界線及水系為
探討目標，進而討論其他細緻之線型，如
道路及房區。由於點雲所可萃取之線型，
其細緻程度受點雲分布密度影響。本研究
以目前常用之作業規格，每一平方公尺一
點之密度為探討對象。比對之數據則由航
空攝影測量所產製。 
在動態目標追蹤部份， [Zhao and 
Shibasaki, 2003]利用車載雷射掃描儀獲取
周圍建物輪廓資料，同時配合CCD 攝影
機獲取的影像來建置道路週遭的建物輪
廓模型。其方法是當車輛行駛過觀測區域
後便同時將雷射點與CCD 影像記錄下
來，處理後獲得具有視覺化材質的點、
線、面空間物件，以建構觀測區域的建物
輪廓模型。[Zhao and Shibasaki, 2004]利用
放置在地面的單線式雷射測距儀觀測行
人的腳，藉以偵測並追蹤行人的移動，試
驗的結果可以找出行人移動的軌跡、人
數，且利用此資料分析行人的動線。
[Makris and Ellis, 2002]在戶外架設攝影
機，用來觀測過往的行人，並由偵測所得
的軌跡分析觀測區域內行人頻繁移動的
路線以架構路線網，並根據路線網資料來
預測行人可能的移動路線與機率。[Yung 
and Lai, 2001] 使用攝影機偵測交通路口
的交通號誌，並且以虛擬感測線圈的概念
偵測闖紅燈的車輛。[Heikkilä and Silvén, 
2003]利用Learning Vector Quantization配
合類神經網路，將攝影機獲得的動態目標
分類為行人與自行車騎士及流量。[Pai et 
al., 2003]等利用攝影機、行人模型與行人
的步行節奏來偵測十字路口上行人移動
的狀況，並分辨複數行人一起移動與車輛
的差異。 
為了達成整合攝影機視訊資料與數
碼城市空間資訊的目的，首先必須要獲得
攝影機像坐標與數碼城市物空間坐標之
間的轉換關係。此轉換關係必須先要建構
攝影機的內、外方位參數模式，因此攝影
機的率定將是第一要務。此部份期望最終
能夠完成一整合的介面，具有攝影機參數
模式的率定功能，以及展示數位地圖與攝
影機之間坐標轉換的圖形化介面。下一步
將發展攝影機在數碼城市中的應用。攝影
機的優勢之一便是能夠獲得動態的影像
資訊，透過攝影機的動態影像便可以追蹤
畫面內的移動物體。在數碼城市中，車輛
或是行人的行為模式是一項重要的資
訊，若能獲得行人、車輛的移動資訊，便
能夠分析其在數碼城市中的移動行為模
式。在子計劃四中將發展於攝影機中追蹤
移動目標，且將其軌跡位置以物空間坐標
來表示的方法。 
在導航之應用研究方面，GPS 為目
前最實用且价廉便宜的定位系統，由24 
顆以上均布衛星向地面發送訊號，若能夠
同時接收到四顆以上衛星訊號，就可以訂
 6
些功能則必須使用視角導向的成像處理
演算法[Evers-Senne & Koch, 2003]與多層
次網處理(Level of Detail)。 
在視覺化系統中，物件如果只有坐標
等幾何資訊，則該系統的功能就僅止於物
件的展示 [Slocum et al., 2001]，對於數碼
城市整體應用的貢獻仍然有限。如果視覺
化空間資訊系統除展示外還能具備查
詢、模擬、模式化等分析功能，則不僅能
提昇視覺化空間資訊系統在數碼城市中
的加值能力，更重要的是可整合數碼城市
中離散的空間資料，再透過直覺化的分析
工具，將其轉化、構建成為具高附加價值
的知識，進一步達到推廣數碼城市整體應
用的目的。就本整合性計畫而言，視覺化
的空間分析不僅可以整合其他各子計畫
所產生的資訊，更可以提供其他子計畫一
個驗證、分析、和應用的平臺。視覺化的
空間資訊分析功能需要整合一些基礎的
視覺模擬與空間運算元件，而第一步就是
必須建立系統中各物件的屬性以及物件
和屬性間的連接。屬性的管理與連結建立
後，下一步就是建構完整的查詢、模擬、
與模式處理等分析功能，主要目標是建立
一個視覺化的決策支援平臺。在視覺化的
的空間資訊系統中，這些分析功能的建立
所要考慮到的兩個重要因素是互動性與
多樣性[MacEachren and Kraak, 2001]；而
技術面上則需要透過使用者界面與空間
運算來做支撐 [Burrough, 1998]。 
因此，子計劃六結合本整合性計畫中
其他子計畫，建置一視覺化的多維數碼程
式空間資訊系統，透過資訊視覺模擬將空
間資訊以最接近實景的三維或多維方式
呈現，並提供人類感官與認知能力中最直
覺的視覺化資訊分析功能。 
三、主要研究流程 
研究內容為三年期計畫之第一年。六
個子計畫之研究內容扼述如下： 
1.1.子計畫一：整合空載多元探測技術及
空間資料重建都市之人工建物及植生
覆蓋模型 
本研究流程包括三個部分，第一部分
為資料前處理，包括光達資料以及航照資
料。第二部分為建物區塊偵測，融合兩種
資料的特性，擷取影像上及光達資料中，
屬於建物的部分。第三部分為建物模型重
建，在航照影像上偵測建物輪廓以及階梯
線，透過光達資料共面分析求取屋脊線，
最後模塑產生三維建物模型。 
建物牆面輪廓分析是以等高線的概
念，在建物區塊內，對網格化光達資料取
不同高度以上的資料，得到許多不同層的
資料在每層資料內各區塊，找出上下層區
塊面積及位置改變量小於門檻值的區
塊，且需要連續數層皆符合在門檻之內，
表示符合牆面的特徵(圖 1)，以其邊緣線為
建物牆面輪廓線，包括建物外圍概略輪廓
及階梯線輪廓。此法在本研究內稱為切片
法[Teo et al., 2005; Zhan et al., 2002]。 
利用建物牆面輪廓分析所得到之概
略建物外圍輪廓，萃取建物範圍內的光達
點 雲 建 構 成 迪 氏 三 角 網 (Delaunay 
Triangulation)，以區塊成長法，分析出建
物頂各個不同屋頂面[郭志奕, 2005]。圖 2
所示為區塊成長之成果例。 
建物結構線包括外圍輪廓線，階梯線
及屋脊線。屋脊線利用屋頂面相交方式求
得，並利用相鄰點切割成為線段。將建物
牆面輪廓投影至影像中建立工作區域，以
Canny Edge Detector[Canny, 1986]偵測邊
界。接著在偵測得到之邊界點中，判斷圓
弧候選區。利用縮編原理，將邊界線分離
成為許多接近直線之短線段。再判斷相鄰
兩線段的夾角及長度比，若其長度接近，
 8
部份，即(1)高程偏移量內部精度之分析及
(2)建物點雲分類及邊緣萃取。在內部經部
分析之目的在於暸解空載光達原始掃描
數據與經過平差改正後的數據之內部精
度變化情形。本研究採用之數據成果平差
改正的方式為使用 TerraMatch (Terrasolid, 
2004)進行無地面控制點的航帶平差。 
內部精度分析主要在於探討平差前
後之航帶重疊區點雲高程資料的吻合程
度 (Internal Consisitency) ， 本 單 元 以
2002LiDAR、c2002LiDAR、2005LiDAR、
c2005LiDAR 各時期各航帶重疊區之資料
進行比對分析。各時期資料皆分別經由地
面點自動分類後，針對所有地面點比較高
程平均偏移量(Dz)及平均絕對誤差。使用
TerraMatch 進行比對計算時，需於各航帶
重疊區選取比對區域，進行比對樣區選取
時，應盡量以地勢平坦及分類地面點較多
的區域作為選取標準。各時期依垂直航帶
方向的前(1)、中(2)、後(3)三區分別取樣，
因此每一組重疊航帶會得到 3 個區域的內
部精度計算成果。 
在建物點雲分類及邊緣萃取部份，參
考 Ahokas 等(2004)透過 TerraScan 之 By 
height from ground 工具，以光達點雲高度
資訊進行建物點雲分類。研究中以二個實
驗區進行實作與評估，實驗區Ⅰ為國家科
學委員會共同樣區，其區域位於新竹工研
院中興院區，房屋型態多為高層建物，針
對該區進行建物點雲分類時所使用之高
度門檻值為 12m 及 18m。實驗區Ⅱ為璞玉
發展計畫區域中選擇的平房區域實驗
區，針對該區進行建物點雲分類時所使用
之高度門檻值為 4m。完成建物點雲分類
後，透過影像處理技術找尋建物邊緣及角
點，由萃取成果疊合 1/1000 線繪圖進行視
覺疊合分析及誤差距離量測統計分析。使
用的光達數據為二時期原始掃描數據成
果(2002LiDAR、2005LiDAR)，萃取比對
流程如圖 5，該程序主要分為「建物點雲
分類」、「視覺疊合分析」、「光達數據網格
化」、「建物邊緣萃取及角點偵測」、「誤差
距離量測統計」等步驟。 
1.4.子計畫四：整合視訊資料及空間資料
於數碼城市中目標追蹤及定位 
本研究流程如圖 6 所示分為三個步
驟，第一個步驟是設計率定 PTZ 攝影機所
需要的附加參數，第二個步驟是取得對應
控制點後以光束法平差進行攝影機方位
參數求解及功能參數率定，第三個步驟則
是利用求得之參數建立 PTZ 攝影機像空
間與電子地圖物空間雙向轉換模式。 
一般攝影測量中，在已知內方位參數
情況下，可利用已知物空間坐標與像平面
坐標之控制點進行外方位參數求解，由此
求得之參數解即可建立物空間對像平面
之對應模式。然而大多數遠端操控 PTZ 攝
影機的用途都非在於精確的定位，故本研
究中將加入其它附加參數進行內方位參
數之率定。 
在本研究中所使用 PTZ 攝影機具有畫
面左右平移（Pan），上下俯角改變（Tilt）
與放大倍率改變（Zoom）的功能，操控攝
影機進行動作時，能得到其 Pan、Tilt、
Zoom 值，但其物理上的運作方式與內部
成像架構通常無法得知，所得傳回值對實
際物理量的轉換也不夠精確，故需使用控
制點進行外方位參數求解。 
在攝影機方位參數求解及功能參數率
定部份，需要使用大量同時出現在遠端操
控 PTZ 攝影機畫面上及電子地圖上的對
應控制點進行光束法平差求解。另外對於
攝影機畫面中明顯但電子地圖上不易辨
識的目標，也可利用攝影機畫面可移動性
高的特性，在多張 pan、tilt、zoom 值不同
的影像中選作影像連結點(tie point)，以強
 10
（0 至 15 度）的全球定位系統觀測量通常
捨棄不用，以減少多路徑影響，同時可避
免嚴重的對流層延遲問題。如果衛星與接
收器皆為靜止的，多路徑偏移則是一固定
值。因此，如何精準校正多路徑偏移是都
會區導航定位之重要研究課題。 
1.6.子計畫六：數碼城市視覺化空間資訊
系統建置之研究 
本研究針對數碼城市三維房屋模型
紋理製作及映射轉換（敷貼）開發一以多
邊形為基礎的數位影像紋理製作及敷貼
系統。整體流程如圖 7 所示。 
在鑲嵌部份，個別數位影像先以半自
動方式選出套合點以八參數進行套合。若
原始影像為不規則（非平面）模型牆面，
則先經一二階段式的紋理校正。接著由套
合後之影像選取興趣紋理區塊 (Area of 
Interest, AOI) 之多邊形做為鑲嵌的基
準。值得注意的是，為避免產生過多離散
的小多邊形，AOI 的選取可使用“負多邊
形”之處理；亦即，紋理影像上遭遮蔽之
部份可視為大多邊形中的“洞”，如此可以
一完整的複雜多邊形表示有興趣之紋理
區塊，並同時排除受遮蔽或其他不適合之
區塊。 
先前進行的影像套合可處理鑲嵌時
對各興趣紋理區塊幾何上的對位，然而，
各區塊之光影與色調仍須進一步進行調
校，以避免光影不連續之情形。本研究將
影像鑲嵌時常用之 Alpha blending 加以
擴充，除考慮像元位置至區塊多邊形邊界
之距離做為權重外，另加入像元至區塊多
邊形質心之距離做為給定權重之另一基
準。 
最後，鑲嵌完成之完整紋理影像則可
以直接敷貼至相對應之模型表面上。對於
平面或規則牆面，此一敷貼過程只需在物
空間中以簡單的仿射線性轉換即可達
成；然而，對於非規則牆面，則必須在參
數空間中進行敷貼，以避免複雜的非線性
轉換運算。 
至於整體的物件顯示方面，本研究採
用以視覺為導向的動態物件視覺模擬方
式。其原則是依據使用者（客戶端）的視
覺條件，動態合成視覺模擬場景。以數碼
城市視覺模擬另一重要元件的大型地形/
地景模擬為例，本研究將目標區先行切割
成一定大小的區塊，再依視覺條件判定可
視範圍和物件解析度，動態合成場景。而
個別區塊的資料則可事先進行多層次細
緻程度 (LOD) 的處理，以配合所判斷出
之解析度進行視覺模擬，避免不必要地使
用高解析力的資料。本研究利用不同的門
檻值，配合四分樹 (quad-tree) 演算法製
作地形區快的多重 LOD 資料；影像部份
則是利用影像金字塔製作區塊內地景紋
理影像的多重 LOD 資料。最後，配合視
覺條件判斷，客戶端在進行大規模數碼城
市視覺模擬時只需要讀入可視區塊當場
景 LOD 等級的資料進行成像運算及處
理即可。當視覺條件改變時，則只需讀入
增加及 LOD 等級改變之少數區塊的新
資料，不必重複讀取高解析力的原始資料
以增加整體視覺化模擬的效能。 
四、主要研究成果 
首先摘述本研究各子計畫之成果。其
中子計畫一、二、三、五以精度分析為主，
子計畫四與六以系統設計為主。 
4.1.子計畫 1 
測試資料包括(1)光達點雲，密度為
2.15 點/m2 及(2)50cm 解析度之航照影像。
測區為新竹科學園區，工業技術研究院。
成果如下： 
(1) 就完整度而言區塊偵測成功率為
 12
六、參考文獻 
1. 莊智清、黃國興，2001。電子導航，全
華科技圖書股份有限公司，pp.1-305。 
2. 郭志奕，2005，「結合光達資料與大比例尺
向量圖重建三維建物模型」，碩士論文，國
立中央大學土木工程研究所。 
3. Ahokas, E. and H. Kaartinen and J. 
Hyyppä, 2004. A quality assessment of 
repeated airborne laser scanner 
observations, International Archives of 
Photogrammetry and Remote Sensing, 
Istanbul. 
4. Axelsson, P., 2000. DEM Generation 
from Laser Scanner Data Using Adaptive 
Models, International Archives of 
Photogrammetry and Remote Sensing, pp. 
110-117. 
5. Balazs, A., M. Guthe, R. Klein, 2004. Fat 
borders: gap filling for efficient 
view-depend LOD NURBS rendering, 
Computer & Graphics, vol. 28, pp. 
79-85. 
6. Baltsavias, E.P., 1999. A Comparison 
Between Photogrammetry and Laser 
Scanning, ISPRS Journal of 
Photogrammetry & Remote Sensing, 
vol.54, pp. 83-94. 
7. Burrough, P.A., 1998. Virtual reality 
modeling and geocomputation, in Longly, 
P. et al. (Eds.), Geocompution: A Primer, 
Wiley, New York, pp. 165-191. 
8. Canny, J., 1986. A Computational Approach 
to Edge Detection, IEEE Transactions on 
Pattern Analysis and Machine Intelligence, 
Vol 8, No. 6, pp. 679-698. 
9. Clode S., Kootsookos P. and 
Rottensteiner F., 2004. The automatic 
extraction of roads from LiDAR data, 
Vol. 35, Part B3, pp. 231-236. 
10. Deng F., Z., Zhang and J., Zhang, 2004. 
Construction 3D urban model from 
LIDAR and image sequence, IAPRS, Vol. 
XXXV, part B3  
11. Evers-Senne, J-F., R. Koch, 2003. 
Image based interactive rendering with 
view dependent geometry, in 
EUROGRAPHICS 2003, P. Brunet and 
D. Fellner (Editors), Vol. 22, No.3 
12. Garland, M., P.S. Heckbert, 1997, Fast 
triangular approximation of terrains and 
height fields. 
13. Hatger, C. and Brenne, C., 2003. 
Extraction of Road Geometry Parameters 
from Laser Scanning and Existing 
Databases , IAPRS, Vol. 34, Part 3/W13, 
URL:http://www.isprs.org/commission3/
wg3/workshop_laserscanning, (last date 
accessed: 15 Oct 2004) 
14. Heikkilä, J., Silvén, O., 2004. A 
Real-Time System for Monitoring of 
Cyclists and Pedestrians, Image and 
Vision Computing Vol. 22, pp.563-570 
15. Hu X., Tao C.V. and Hu Y., 2004. 
Automatic road extraction from dense 
urban area by integrated processing of 
high resolution imagery and LiDAR 
Data , Vol. 35, Part B3, pp. 320-324. 
16. Kraak, Menno-Jan, 2002. Some 
Aspects of Geovisualization, 
GeoInformatics, Vol. 5,No. 8, pp. 26-37. 
17. Lachapelle, G., Cannon, M. E., and Lu, 
G., 1992. High-presicion GPS navigation 
with emphasis on carrier-phase 
ambiguity resolution. Marine Geodesy, 
Vol. 15, No. 4, pp. 253-269. 
18. Lichti, D. D., Stewart, M. P., Tsakiri M. 
and Snow A. J., 2000. Calibration and 
Testing of A Terrestrial Laser Scanner, 
International Archives of 
Photogrammetry and Remote Sensing. 
 14
extraction of buildings in densely 
built-up areas, IAPRS, Vol. XXXV, part 
B3 
34. Slocum, T.A., C. Blok, B. Jiang et al., 
2001. Cognitive and usability issues in 
geovisualization, Cartographic and 
Geographic Information Science, vol. 28, 
pp. 61-75. 
35. Song, J., Han, S., Yu, K., Kim, Y., 
2002. Assessing the possibility of 
land-cover classification using LiDAR 
intensity data, ISPRS Commission III, 
September, pp.9-13 
36. Terrasolid, 2004, TerraScan user guide 
(18.11.2004), Terrasolid. 
37. Teo, T.A., Chen, L.C., Liu, J.K., and Hsu, 
W.C., 2005. Building reconstruction from 
LIDAR data using iterative regularization 
approach, Proceedings of Asian Conference 
on Remote Sensing, Nov. 7-11, Hanoi, 
Vietnam, CD-ROM. 
38. Teunissen, P. J. G., de Jonge, P. J., and 
Tiberius, C. C. J. M., 1997. Performance 
of the LAMBDA method for fast GPS 
ambiguity resolution, Navigation, Vol. 
44, No. 3, pp. 373-383. 
39. Vosselman, G., 2000. Slope Based 
Filtering of Laser Altimetry Data, 
International Archives of 
Photogrammetry and Remote Sensing, pp. 
935-942. 
40. Vosselman, G.and S., Dijkman, 2001. 
3D building model reconstruction from 
point clouds and ground plans, IAPRS, 
vol 34, part 3/W4, pp. 37- 44 
41. Vosselman, G., 2003. 3D 
reconstruction of roads and trees for city 
modeling, IAPRS, Vol. 34, Part 3/W13, 
URL:http://www.isprs.org/commission3/
wg3/workshop_laserscanning, (last date 
accessed: 15 Oct 2004) 
42. Watt, A., 1999, 3D Computer Graphics, 
Addison-Wesley, 3rd. Ed., 1999. 
43. Wehr, A. and Lohr, U., 1999. Airborne 
Laser Scanning - an Introduction and 
Overview, ISPRS Journal of 
Photogrammetry & Remote Sensing, 
vol.54, pp. 68-82 
44. Xu. L, Oja, E., and Kultanen, P., 1990, A 
new curve detection method: randomized 
Hough transform (RHT), Pattern Recognition 
Letters, Vol. 11, No. 5, pp. 331-338.Douglas, 
D. H., and Peucker, T. K., 1973. Algorithms 
for the reduction of the number of points 
required to represent a line or its caricature. 
The Canadian Cartographer, 10(2):112-122. 
45. Yung, H. C., Lai, H. S., 2001. An 
Effective Video Analysis Method for 
Detecting Red Light Runners, IEEE 
Transactions on Vehicular Technology, 
Vol. 50, No. 4 
46. Zhan, Q., Molenaar, M. and Tempfli, K., 
2002. Building extraction from laser data by 
reasoning on image segments in elevation 
slices, IAPRS, XXXIV(part 3 
A+B):305-310. 
47. Zhao, H. J., Shibasaki, R., 2003. A new 
Interface for Extracting Urban Spatial 
Objects Using Laser and CCD Images, 
Proc of Computers on Urban Planning 
and Urban Management. 
48. Zhao, H. J., Shibasaki, R., 2004. 
Pedestrian Tracking Using Multiple 
Laser Range Scanners, Proc. of 
Computers on Urban Planning and Urban 
Management 
 
.
 16
 
 
 
 
 
 
圖 8 建物模型重建成果
圖 9 工研院主樓細緻模型
圖 10 電子地圖上之控制點位置 圖 11 像平面上之控制點位置 
