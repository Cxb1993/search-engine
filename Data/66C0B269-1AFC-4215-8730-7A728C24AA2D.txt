i 
 
目      錄 
 
一、前言．．．．．．．．．．．．．．．．．．．．．．．1 
二、研究目的．．．．．．．．．．．．．．．．．．．．．1 
三、文獻探討．．．．．．．．．．．．．．．．．．．．．1 
四、研究方法．．．．．．．．．．．．．．．．．．．．．2 
五、結果與討論．．．．．．．．．．．．．．．．．．．．6 
六、結論與建議．．．．．．．．．．．．．．．．．．．．8 
 
參考文獻．．．．．．．．．．．．．．．．．．．．．8 
計畫成果自評．．．．．．．．．．．．．．．．．．．．．9 
 
 
2 
 
過不同領域像控制、通訊、信號處理的模擬，他們證實 SONFIN 可以應用在數種領域。
Lin [12] 等提出 SCFNN 並實現於永磁式同步馬達速度控制器，這是一個具有線上結構
學習與參數學習能力的模糊類神經網路，相較於 SONFIN 的高複雜度，SCFNN 的推
論輸出與參數學習都較為簡單容易實現。而 ANFIS (artificial neural fuzzy inference system) 
在 1993 年由 Shing [13] 所提出，是近年來頗具代表性的類神經模糊推論系統，在不同
的領域有許多成功的應用實例，例如 Altug 的馬達故障偵測系統[14]、Djukanovic 的動
態電力負載系統 [15]等。貝氏最佳解法 (Bayesian decision theory) 首先計算測試樣本與
所有訓練樣本之間的歐式距離 (Euclidean distance)，再依計算結果判別測試中的樣本對
應輸出值應是 1 或 0，亦即分析訓練樣本的群聚現象，直接計算判別測試樣本的輸出。
本計畫主要擴展 SCFNN 的功能，使之能應用在具有符間干擾 (intersymbol interference, 
ISI) 效應、非線性與雜訊的數位通道中，以還原 QAM 失真信號，之後並且以 FPGA 
(field programmable gate array) 硬體實現此通道等化器。我們將 SCFNN 硬體化加以實
現，提出了適合硬體實現的改良演算法，並且利用分時多工的方法大幅降低了硬體成本。
最後，對於硬體化的效能也做了詳細的評估與分析。 
 
 
四、研究方法 
 
    SCFNN 是一個四層結構的模糊類神經網路，其結構如圖一所示。系統運作之初僅
有輸入節點與輸出節點，隨著即時學習 (on-line learning) 的進行，訓練樣本逐一進入 
SCFNN，然後是結構學習、計算推論輸出值、參數學習三個動作直至學習完成。所謂學
習完成有兩個要點，一是建立完整的模糊規則其次是調整相關參數至最佳值。回想 
(recalling) 是 SCFNN 另外一個重要的動作，也可以說是測試學習完成的 SCFNN 工作
表現。以本文模擬的數位通道信號重建為例，我們將失真信號輸入給完成學習動作的 
SCFNN，檢視 SCFNN 輸出，並與正確輸出值比較，最後計算位元錯誤率就是 SCFNN 
的回想動作。SCFNN 的推論輸出值依下列的過程計算： 
 
Layer 1：此層是輸入節點，數位序列 r1(k) 與 r2(k) 透過此節點進入下一層，於此並沒
有計算動作。其中 r1(k) 與 r2(k) 分別代表傳送端經通道效應與白色高斯雜訊
後的同相 (in-phase) 及正交 (quadrature) 數位序列，符號也可記為 ri(k) 及 
rq(k)。 
Layer 2：此層的每一節點相當於是第一層輸入變數的語意項 (linguistic label)，亦即算
出輸入變數 i 屬於此歸屬函數的程度 Aji，本研究中採用高斯函數做為歸屬函數 
(membership function) 
  
Mji
mkr
A
ji
jii
ji 






 
 1,2,1,exp
2
2

            (1) 
其中，mji 與 ji 分別為信號 ri(k) 對第 j 個歸屬函數的中點 (mean) 及標準差 
(standard deviation)。 
Layer 3：此層的每一節點表示模糊規則的後鍵部 (consequent part)，其函數是 
MjAAu jjj  1,21                            (2) 
亦即此層各節點的輸出是輸入信號的乘積。 
Layer 4：此層僅有一個節點主要的動作是解模糊化 (defuzzification)，若以 *y  表示推
論輸出值，則 
4 
 
更新 ωj，其中 N 是樣本序號。 
Layer 3：歸屬函數的平均值 jim  (mean) 與標準差 ji  
(standard deviation) 之差距量公
式如下： 
 
  
 
2
2
ji
jii
jj
*
m
ji
mji
σ
mr
uωyyη
m
E
ηΔm




                 (7) 
  
 
3
2
2
ji
jii
jj
*
σ
ji
σji
σ
mr
uωyyη
σ
E
ηΔσ




                (8) 
 
上式中    ,m  分別是歸屬函數平均值與標準差差距量的係數，可用錯誤嘗試
法調整以得到較快較好的收斂。接著以 
 
    2,1,1,1  iMjmNmNm jijiji             (9) 
    2,1,1,1  iMjNN jijiji             (10) 
 
更新高斯歸屬函數的 jim 與 ji 。 
每一筆訓練樣本進入 SCFNN，上述三個動作都需完整執行一次，所有訓練樣
本都執行過一次叫一個學習循環 (learning cycle)，一般用均方值 (mean square 
error, MSE) 評估 SCFNN 是否完成學習，均方值的定義如下： 
 



P
j
yy
P
ESM
1
2*)(
1
..                            (11) 
 
其中 P 為總訓練樣本數，y 代表期望輸出值或正確輸出值，y* 為 SCFNN 推
論輸出值。在模擬過程中，為了達即時控制效果，我們都僅執行一個學習循環。 
 
 
    本計畫已將 SCFNN 架構完全採用硬體的方式來設計，並用 FPGA 來實現推論輸
出、結構學習與參數學習的架構。圖二為等化器的整體模型，主要架構是由兩個 SCFNN 
所組成，分別處理同相 (實部) 與正交相 (虛部) 兩組成份。在通訊系統的接收端，接
收到由振幅與相位所組成的 4-QAM 信號  krφ ，透過 Source generator 方塊的運算，
轉換成同相與正交相兩組信號    krkr qi  。Real processor 也就是本論文的主要架構 
SCFNN，在學習過程，輸入一連串  kri ,  krq  與  kyi  所組成的輸入輸出對，  kyi  
為發射端所送出的正確信號。在回想的階段，只要輸入  kri  與  krq ，經過運算便可
得到  ky *i 。其值為帶有小數的實數，只要再透過 Real decision unit 的決策，以 0 做
為決策邊界值，若  ky *i  大於 0 則  kyi  判斷為 1，小於 0 則為 1 。最後，再將 
 kyq  乘上 j 與   kyi  相加，便可得到已還原的 4-QAM 信號  ky 。Real processor 
與  Imaginary processor 方塊的內部硬體架構是相同的，也就是本論文的主要架構
SCFNN。同樣的，Real decision unit 與 Imaginary decision unit 方塊的設計也是完全相
同，其決策邊界值均設定為 0。 
6 
 
練樣本以讀取完畢，則 SCFNN 直接進入回想過程，對照前述的運算過程，即是執行公
式(1)-(3) 的算式，此時系統處於訓練完成的可使用狀態。若尚有訓練樣本還未讀取，則
系統進入訓練過程，進行結構學習與參數學習，此部份除了要執行回想過程的運算外，
還要做結構學習與參數學習，亦即需執行公式(4)-(10) 的運算。每當訓練過程的一個週
期結束，則會再進行判斷，根據公式(11) 所定義的 MSE 參數，來檢視系統是否已達穩
定的收斂狀態。若系統已收斂則進入回想過程；若否，則再讀取新的訓練樣本，使系統
再次接受訓練學習。 
    而 SCFNN 的訓練過程是用來做系統的結構與參數學習，其運作流程如圖四(b) 所
示。在訓練過程所包含的一個訓練週期裡，均是先進行結構學習後再進行參數學習。而
這兩個學習都需使用到推論輸出部份計算所得的數值，並且結構學習是在推論輸出的中
途發生，故在圖四(b) 將推論輸出分成前推論與後推論。當前推論結束，所得到的參數
即足以提供結構學習使用。根據前推論提供的參數，判斷是否須進行結構的增加，若符
合自建條件，則進行結構自建。自建結束後，再繼續完成後推論部份得到更多的參數，
以完成參數學習。若不符合自建條件，則直接進入後推論，再執行參數學習。如此週而
復始，直到符合結束訓練過程的兩個條件的其中之一才停止，轉而進入回想過程。 
 
 
讀取訓練
樣本
訓練樣本
結束？
訓練過程
是否已
收斂？
回想過程
是
否
是
否
前推論
符合自建
條件？
結構自建
後推論
參數更新
否
是
 
 (a)                         (b) 
圖四 (a) SCFNN 運作流程   (b) 訓練過程運作流程 
 
 
五、結果與討論 
 
    就本架構而言，硬體實現與軟體模擬最主要的差異在於參數學習的速度，硬體由初
始訓練到完成收斂較軟體所需的時間要來的久。圖五為硬體與軟體在不同 SNR 下的收
斂特性，可觀察出在軟體模擬的情況下，平均只要 10 個學習週期即可達到收斂。而硬
體實現部份，由於受限於有效位數長度，收斂時間顯得較不穩定，收斂的速度跟 SNR 也
沒有一定的關係。雖然硬體收斂的時間不穩定，但是經由觀察，只要確保學習時間足夠 
50 個週期，此系統必定可以收斂。 
8 
 
 
表一  系統所使用的硬體成本分配表 
 加/減法器 乘法器 除法器 
前推論輸出 592M (2-DSP+1)2M 6392M 
後推論輸出 36M+760 (2-DSP+1)M  
ω 參數更新 38M (2-DSP+1)M  
m 參數更新 412M 
(2-DSP+1)2M 
5982M 
(2-DSP+1)2M 
σ 參數更新 292M (2-DSP+1)2M  
 
 
表二 使用多工器後的硬體成本比較 
 
總硬體成本 
DPS blocks Logic elements 
使用多工器 10M 777+2459M 
未使用多工器 20M 777+3379M 
 
 
六、結論與建議 
 
    本計畫成功地將 SCFNN 應用於數位通信的通道等化器，並在硬體上加以實現。除
了用 FPGA 實現 SCFNN 架構外，並且對原始的演算法加以修改。根據原始公式推導
出減少硬體成本與降低運算複雜度的演算法。在硬體效能上，結果顯示當小數位的位元
數高於 12 位元時，其位元錯誤率並不會有太明顯的下降，故本系統的小數位只需取到 
12 位元即可。硬體實現與軟體模擬的學習速度上，軟體模擬均可在 10 個訓練週期即
達到收斂；但是就硬體而言，至少要到達 50 個訓練週期才能確保系統達到收斂。很明
顯地，這是硬體與軟體之間的一大差異，硬體的訓練時間要比軟體模擬的結果要來的久。
SCFNN 所耗費的硬體成本十分的可觀，因為其運算過程使用了大量的乘法器與除法器，
尤其除法器幾乎耗費了整個架構中一半的資源。不過，我們利用分時多工的技術，巧妙
的運用的三組的多工器與解多工器，共用了除法器與乘法器，得以節省 920M 個 logic 
elements 與 10M 個 DSP blocks (其中 M 為 SCFNN 架構中第三層的節點數目)。整體
而言，本文所述之等化器是頗符合實際上需求的設計。 
 
 
參考文獻 
 
[1] M. Ibnkahla, “Applications of neural networks to digital communications,” Signal 
Processing, vol. 80, pp. 1185-1215, 2000. 
[2] C. Luo, S. Cheng, L. Xiong, J. Nguimbis, Y. Zhang and J. Ma, “A 
nonlinear equalization method based on multilayerperceptron for OFDM power-line 
communication,” IEEE Trans. on Power Delivery, vol. 20, Issue 4, pp. 2437-2442, 2005. 
[3] S. Chen, B. Mulgrew and P. M. Grant, “A clustering technique for digital 
communications channel equalization using radial basis function networks,” IEEE Trans. 
on Neural Networks, vol. 4 , Issue 4, pp. 570-590, 1993. 
[4] G. Kechriotis, E. Zervas, and E. S. Manolakos, “Using recurrent neural networks for 
adaptive communication channel equalization,” IEEE Trans. on Neural Networks, vol. 5, 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/30
國科會補助計畫
計畫名稱: 遞迴式自建模糊類神經網路等化器之設計
計畫主持人: 翁萬德
計畫編號: 100-2221-E-224-079- 學門領域: 人工智慧
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本計畫所述之等化器是頗符合實際上需求的設計。本設計研發過程需要類神經
網路及模糊理論之數學背景，以及在實作上對硬體電路成本的精準考量，因此
研究成果兼具學術及應用價值。目前正準備將部份研究成果發表於學術期刊。
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
