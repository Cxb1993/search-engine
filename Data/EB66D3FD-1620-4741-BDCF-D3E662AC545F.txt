中英文摘要： 
中文摘要 
本計畫為研究在不同的亮度情況下具有高辨識率的影像比對方法。主要的焦點是在著
重於不同的亮度情況下比較影像中主體物件的問題，我們將這個比對法應用到困難度較高
的臉部辨識上。本計畫改良先前一種根據對應的二個臉部圖像的臉部位置累積其一致性的
正規化梯度變化；利用同一個人、同一表情、同一位置的三個不同方向的照明情況作為其
測度比較參考的依據。其中一種參考的方式為局部比較臉部輪廓和重要部分的位置上每個
點將參考三個不同的梯度變化中取其最大的正規化的絕對值量，再累積其度量；另一種方
式為全域比較臉部輪廓和重要部分的位置上將分別參考三個不同亮度情況計算其正規化的
梯度變化累積量取其最大。也將會利用一個明暗度加權的函數來修正陰影和明暗度飽和所
產生的影響。我們先比較上述單獨考慮局部或全域的參考方式，也同時會混和局部和全域
的累積度量來尋找最佳方法。我們將用耶魯大學臉部資料庫來測試此演算法，此資料庫其
中包含 15 個人與 3 種不同亮度的情況。我們深信所提出的方法將會在實驗中能達到令人
滿意的辨識結果。 
關鍵字：影像比對，亮度程度，臉部辨識 
 
英文摘要： 
 
Abstract 
In this research we study the image matching methods that have high recognition rate in 
different illumination conditions. We focus on the recognition of the main object in an image 
with different light sources. These image matching methods are applied to solve the face 
recognition problem which is a difficult work. We improve previous methods based on 
accumulating the consistency normalized gradients of two comparing face contours of the 
corresponding location. The methods use three reference face templates to get more accuracy 
recognition rates. There are two ways to accumulate the consistency normalized gradients. One 
is considering every point on the two corresponding face contours that we use the largest 
normalized gradient of these three reference templates images. Another is we use one reference 
to compare the searching face in the whole face contour. Then we select the largest of these 
three measures of the accumulating the consistency normalized gradients. We will also mix 
these two ways to find the best matching method. The Yale Face Database will be used to 
examine these methods. This database includes 15 persons and 3 different illumination 
conditions. We believe these proposed method will have excellent recognition rates.  
Keyword: image matching, conditions illumination, face recognition. 
I 
[4] A. Mojsilovic and J. Hu, “Extraction of perceptually important colors and 
similarity measurement for image matching”, Proc. Int. Conf. Image Processing, 
pp.61-64, 2000. 
[5] P. N. Belhumeur, J. P. Hespanha, and D. J. Kriegman, “Eigenfaces vs. 
Fisherfaces: recognition using class specific linear projection”, IEEE Trans. 
Pattern Analysis Mach. Intel., Vol. 19, No. 7, pp.711-720, 1997. 
[6] Y. Adini, Y. Moses, and S. Ullman, “Face recognition: the problem of 
compensating for changes in illumination direction”, IEEE Trans. Pattern 
Analysis Mach. Intel., Vol. 19, No. 7, pp. 721-732, 1997. 
[7] L. Wiskott, J.-M. Fellous, N. Kuiger, C. von der Malsburg, “Face recognition 
by elastic bunch graph matching”, IEEE Trans. PAMI, Vol. 19, No. 7, pp. 775 
-779, 1997. 
[8] K. Hotta, T. Mishima, T. Kurita, and S. Umeyama, “Face matching through 
information theoretical attention points and its applications to face detection and 
classification”, Proc. Fourth IEEE Conf. on Automatic Face and Gesture 
Recognition, pp.34-39, 2000  
[9] B. Takacs and H. Wechsler, “Face recognition using binary image metrics”, 
Proc. Third IEEE Conf. Automatic Face and Gesture Recognition, pp. 294-299, 
1998  
[10] G. J. Edwards, C. J. Taylor, and T. F. Cootes, “Interpreting face images using 
active appearance models”, Proc. Third IEEE Conf. on Automatic Face and 
Gesture Recognition, pp. 300-305, 1998  
[11] K. Sengupta and J. Ohya, “An affine coordinate based algorithm for 
reprojecting the human face for identification tasks”, Proc. International 
Conference on Image Processing, Vol. 3, pp. 340 -343, 1997  
[12] A. S. Georghiades, D. J. Kriegman, P. N. Belhumeur, “Illumination Cones for 
Recognition under Variable Lighting: Faces”, Proc. IEEE Conf. CVPR, pp. 
52-59, 1998. 
[13] A. S. Georghiades, D. J. Kriegman, P. N. Belhumeur, “From Few to Many: 
Illumination Cone Models for Face Recognition under Variable Lighting and 
Pose”, IEEE Trans. Pattern Analysis Mach. Intel., Vol. 23, No. 6, pp. 643-660, 
2001. 
[14] W.-Y. Zhao and  R. Chellappa, “Illumination-Insensitive Face Recognition 
using Symmetric Shape-from-Shading”, Proc. IEEE Conf. CVPR, pp. 286-293, 
2000. 
[15] D. Beymer and T. Poggio, “Face recognition from one example view”, MIT AI 
Meno No. 1536, 1995. 
[16] W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery, Numerical 
Recipes in C, 2nd Ediition, Cambridge University Press, 1992. 
 
2 
∑ ∑Γ∈
Γ∈
∈∈
+∇
∇•+∇
∇
=
ji
ji
WlkWlk
jiTI
jiTI
clkI
jiTI
clkI
jiI
ITIE jiTji
,
,
1
1
1
),(
1
0
),(
0
01 ))),(((
))),(((
),(max
)),((
),(max
),(
);,( ),(),( τ
τ
 (4) 
其中強度權重函數被給予為 
⎪⎪⎩
⎪⎪⎨
⎧
≤<−
−
≤≤
<≤∗
=
255)
255
*
2
cos(
1
0)
2
sin(
)(
IIwhere
I
II
IIIwhere
IIwhere
I
I
I
Ub
Ub
Ub
UbLb
Lb
Lb
π
π
τ  (5) 
 ILb 和 IUb 意味權重作用的最大下界和最小上界面。這個加權函數的說明在圖 1。 
1 
0         I Ib           Ub       L
圖 1. 加權函數 
像點接近明暗度值離零或 255 的灰階值，在相似性度量中我們分配較小的權重。在公
式(4)的分母的正規化因子，是變換的位置後的所有權重總和。使用正規化因子的用途為修
改相似性度量正規化後的度量落在[0,1] 。 
在我們的臉部比對的演算法中，我們為每個在臉部資料庫的臉部影像樣板，藉由邊緣
偵測以某一個量為過濾值來萃取臉部輪廓。另外，我們也計算正規化梯度為臉部影像樣板
資料庫。然後, 我們輸入臉部影像I1 與各個樣板臉部影像I0比較，解決以下最佳化的問題：
注意這個最佳化問題可以用Levenberg-Marquardt 算法解決[16] 可利用一些幾何轉換參
量為初始的猜測。在實踐上，我們先運用一種臉部偵測算法發現臉部的近似位置和大小在
輸入的影像，如此提供幾何轉換參量的一個最初的猜測。然後, Levenberg-Marquardt算法
被運用最佳化相似性度量作用在所有樣板臉部影像。具有最佳化相似性度量的樣板臉部是
最接近輸入臉部。所以，這是最接近的臉部辨識結果。換句話說，臉部辨識可能被公式化
作為以下最佳化問題: 
);,(maxmaxarg )(01
k
TFk
ITIE
∈  (6) 
其中是 是第 k個臉部樣板影像，F 表示在資料庫所有臉部樣板影像。 )(0kI
4 
結果與討論： 
我們在耶魯臉部資料庫中，測試我們的提議的臉部比對演算法，比照在光線的變化中，
檢查它的有效性。這個臉部資料庫包括 15 個對象，其每一個對像在不同情況下，拍攝 11
張照片。由於 我們有興趣的是在不同光線情況下的圖片比對，我們在三種不同光線情況下
測試這 15 個對向，例如，光源直射，光源右照，光源左照。圖 3顯示在耶魯大學臉部資料
庫的第一位對象，在三種不同光源情況下的圖像。 
剪下在光源直射下的臉部區域，當作臉部模型圖像(template image)，我們顯示這 15
張臉部模型圖像在圖 3. 在我們臉部比對方法中，在斜率操作之前，我們先在臉部圖像做
平滑操作。平滑操作不僅降低了干擾作用，也在輪廓位置周圍，延伸斜率函數的支援。 後
者有助於增加最佳化問的區域的聚合，在我們的實驗中，為了平滑作用，我們簡單地使用
平均操作. 
 
圖 3. 對象 01 的臉部於(a)光線直射(b)光線右照(c)光線左照 
 
圖 4. 從耶魯臉部資料庫裡光源直射的圖像中剪下的 15 個臉部圖像例子 
 
    
(a)    (b) 
圖 5.(a)臉部模型和(b)其萃取出的臉部邊緣圖 
 
在我們實驗中，為完成最佳成效，有些參數是要注意的。包括平均過濾器的視窗大小、用
來找出區域最大值的視窗大小、邊緣偵測的門檻，權重函數的下界(ILb)及上界(IUb)，以及
在相似方法中的參數c。在我們的實驗中，我們做完的sample是臉部圖像為原本的 1/4 大
小。然後，在傾斜標準化中，我們用 3x3 的 average filter，5x5 的區域視窗。在邊緣偵
6 
 可供推廣之研發成果資料表 
□ 可申請專利  V 可技術移轉                                      日期：96年10月30日 
國科會補助計畫 
計畫名稱：楊權輝 
計畫主持人：         
計畫編號：NSC 95－2221－E－364－002－ 學門領域：影像處理
技術/創作名稱 以全域或局部的梯度差異變化對不同亮度下的影像比對法 
發明人/創作人 楊權輝、賴尚宏、張隆紋 
中文： 
本計畫為研究在不同的亮度情況下具有高辨識率的影像比對方
法。主要的焦點是在著重於不同的亮度情況下比較影像中主體物件
的問題，我們將這個比對法應用到困難度較高的臉部辨識上。本計
畫改良先前一種根據對應的二個臉部圖像的臉部位置累積其一致
性的正規化梯度變化；利用同一個人、同一表情、同一位置的三個
不同方向的照明情況作為其測度比較參考的依據。其中一種參考的
方式為局部比較臉部輪廓和重要部分的位置上每個點將參考三個
不同的梯度變化中取其最大的正規化的絕對值量，再累積其度量；
另一種方式為全域比較臉部輪廓和重要部分的位置上將分別參考
三個不同亮度情況計算其正規化的梯度變化累積量取其最大。也將
會利用一個明暗度加權的函數來修正陰影和明暗度飽和所產生的
影響。我們先比較上述單獨考慮局部或全域的參考方式，也同時會
混和局部和全域的累積度量來尋找最佳方法。 
技術說明 英文： 
In this research we study the image matching methods that have high 
recognition rate in different illumination conditions. We focus on the 
recognition of the main object in an image with different light sources. 
These image matching methods are applied to solve the face 
recognition problem which is a difficult work. We improve previous 
methods based on accumulating the consistency normalized gradients 
of two comparing face contours of the corresponding location. The 
methods use three reference face templates to get more accuracy 
recognition rates. There are two ways to accumulate the consistency 
normalized gradients. One is considering every point on the two 
corresponding face contours that we use the largest normalized 
gradient of these three reference templates images. Another is we use 
one reference to compare the searching face in the whole face contour. 
Then we select the largest of these three measures of the accumulating 
the consistency normalized gradients. We will also mix these two ways 
to find the best matching method. 
附件一 
8 
 附件二 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC  95－2221－E－364－002－ 
計畫名稱 以全域或局部的梯度差異變化對不同亮度下的影像比對法 
出國人員姓名 
服務機關及職稱 楊權輝；玄奘大學資訊科學學系；助理教授 
會議時間地點 
時間：June 25-28, 2007  
地點：Monte Carlo Resort, Las Vegas Nevada, USA 
會議名稱 WORLDCOMP’07，The 2007 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV'07) 
發表論文題目 A Data Hiding Technique by Using 2D Interpolation Methods in Spatial Domain 
 
一、參加會議經過 
    啟程：June 24 傍晚 
    返國：July 3 早上 
報告時間：June 26 下午 1:30-2:30 
報告方式：POST 
 
二、與會心得 
1. 這個報告論文，以影像處理方法應用在影像資訊隱藏上。 
2. 再次增進 POST 的經驗，對應和了解問題都是要很迅速的。 
3. 和做相同領域的學者互相交流，親自體會其他人對這些相同或類似的問題的看法或
解決之道。 
4. 和台灣去的老師與同學交換不同問題的心得。 
5. 聆聽一些有興趣的議題，幫助了解更多相關的領域。 
6. 英文有些退步，要多多練習了。 
7. Las Vegas 變化很大，賭城除賭博以外慢慢轉變以觀光來吸引遊客。 
 
三、附件：發表論文 
10 
 distribution in macro-block decreases after data hiding. Lin 
et al. [9] propose a variable depth LSB substitution data 
hiding technique. The pixels of cover-image are grouped 
according to their luminance values. After counting the 
occurrence of pixel-values in each group, they are sorted in 
monotone increasing. Finally a bit plane-wise data hiding 
method is used to hide data in cover image. They also 
formulated the worst-square-error between the stego-image 
and the cover-image. In Ni et al. [11], they are interested in 
lossless data hiding. Most of the existing lossless data 
hiding algorithms are fragile that they will be defeated 
when compression or other small alteration is applied to the 
cover image. They proposed a nove1 robust lossless data 
hiding technique, which does not generate salt-pepper 
noise and successfully applied to many commonly used 
images. Ramkumar and Akansu [12] give the practical 
solutions for signaling methods for multimedia 
steganography. Data hiding seems to be a sophisticated 
signaling technique using a periodic signal constellation. 
They propose such a signaling method and give both 
theoretical and the simulation of its performance in an 
additive noise circumstances.  
Secondly, we introduce some authors’ works in 
frequency domain. Ikeda et al. [7], they work on audio data. 
They use the band-limited random sequences to establish 
further flexibility in the spread spectrum based audio data 
hiding. They set up a systematic method in order to 
generate band-limited and orthonormal random sequences 
of any length to understand the sub-band data hiding. In 
Mukherjee et al. [10], the authors present a source and 
channel coding framework for data hiding. It allows any 
tradeoff between the distortions, the data embedded, and 
the robustness. The secret data is source coded by vector 
quantization. They use orthogonal transform domain vector 
perturbations to embed data in the cover video after the VQ 
indices obtaining in the process. According to noise-
resilient channel codes derived from multidimensional 
lattices, the transform coefficients of cover image’s are 
grouped into vectors and perturbed. The maximum mean-
squared error limits the perturbations. The optimally 
channel coding can be used to increase the robustness to 
noise. LZW is one of the well-known lossless compression 
methods. The modifiable elements of LZW for data hiding 
and how to handle them are proposed in Shim et al. [13]. 
The DH-LZW method embeds data into cover image in a 
lossless manner. Wang and Ji [14] propose a novel error 
concealment scheme for images compressed in wavelet 
domain. To reconstruct missing data of region-of-interest 
(ROI) is based on data hiding techniques. They use shape-
adaptive wavelet transform to transform the ROI and 
region-of-background (ROB) of images into wavelet 
domain and coded with the rate-distortion optimized coder. 
Embedded data are truncated from the coded bit stream of 
ROI and embedded into the wavelet coefficients of ROB. 
In Xuan et al. [15], they propose a reversible data hiding 
algorithm based on integer wavelet transform. This means 
that can convert the stego-image to the original image 
without any distortion after extracting the hidden data. 
Data are hidden into one (or more) middle bitplane(s) of 
the integer wavelet transform coefficients in the middle and 
high frequency subbands. It is a tradeoff between the 
amount of data and the distortion how to satisfy the 
imperceptibility requirement. 
This paper is organized as follows. In section 2 we 
discuss our proposed method that includes how to embed 
the secret data into a cover image and extract these 
embedded data from this marked cover image. Section 3 
then gives several computer experiment results and 
comments. Finally, in the conclusion we summarize our 
major results and outline our future work. 
2 Proposed method 
 We are going to propose an effective and 
imperceptible data hiding method in spatial domain. We 
may easily embed the secret data into a gray level cover 
image, and extract those secret data without using the 
original cover image. Here we give a briefly discussion 
first. The cover image is divided into small 3 by 3 blocks 
images that have overlapping with boundaries. We use four 
known points to be the control points to generate a new 
local 3 by 3 images by 2D interpolation technique. Please 
see Fig. 1. If the difference between the interpolation value 
and original gray level at the same pixel is less than a 
threshold and larger than zero, we may embed 2 bits, 3 bits, 
or even 4 bits in this pixel. If original gray level is larger 
than interpolation value, we let the new gray level be 
interpolation value adding to embedding bits values. Fig. 2 
shows the condition. Similarly, if original gray level is 
smaller than interpolation value, we let the gray level be 
interpolation value subtracting from embedding bits values. 
Concerning the security, we transfer the secret data into a 
bit stream, shuffle them by a pseudo-random generator then 
embed data in the location that satisfying the embedding 
condition. The extracting steps just follow the embedding 
algorithm to check the possible embedded location to 
collect the embedded bits. Then we use the same pseudo-
random generator to shuffle back the bit stream order to 
find the original secret data. 
 
Fig. 1. Four known control points (black points) in a 3 by 3 
block image, the white points will be the 
interpolations. The middle white point is computed 
by 2D interpolation method and the other fours 
whites are computed by the linear interpolation 
method. 
 
2 
 4 
 
Fig. 3. The interpolation A(x, y) and four known 
points are shown. 
 
Bicubic Interpolation 
The bicubic interpolation value f(x, y) of a function f at a 
point (x, y) is calculated as a weighted average of the 
nearest sixteen known pixels in a rectangular 4 by 4 grid. 
By using two cubic interpolation polynomials, one for each 
plane direction, are computed. The bicubic interpolation is 
calculated as follows: 
3 3
0 0
i j
ij
i j
a x y
= =
∑∑                                        (2.5)  
For each of the vertices of the known pixels, the local 
coordinates at (0,0), (1,0), (0,1) and (1,1) can be input into 
above equations to induce 16 equations to solve. 
2.2 Proposed Embedding and Extracting 
algorithm 
 Here we denote the C is the cover image and M is its 
edge map. D is the secret data. After embedding secret data, 
we have a stego-image, said S. The embedding and 
extracting algorithms are as follows.  
Embedding Algorithm 
Step   1 :Transfer the secret data D into bit stream.  
Step 2 :Shuffle the bit stream by a pseudo-random 
generating function (PRNG) . 
Step 3 : Divide the cover image C into 3 by 3 blocks 
overlapping with the boundaries, then apply the 
2D interpolation to get C’ . 
Step 4 : Apply one of the edge detection algorithm with the 
interpolation of cover image C’ to get the edge 
map M. 
Step 5: If the 3 by 3 block has edge point(s), and the 
absolute of difference is larger than zero and less 
than 3(embedding 2 bits), or 7(3 bits), or 15(4 
bits), 
etc, the interpolation position is embedded the 
number of bits what we want. 
P11(x1, y1) 
P12(x1, y1) 
P22(x1, y1) 
P21(x1, y1) 
A(x, y) 
Q2(x, y2) 
Q1(x, y1) 
Step 6: Repeat Step 4, until the secret data bit stream is      
running out or the cover image has no place to 
embed. We obtain a stego-image S. 
Extraction Algorithm 
Step 1：Divide the stego-image S into 3 by 3 blocks 
overlapping with the boundaries. 
Step 2：Apply 2D interpolation with stego-image S to get 
S’ (=C’)，then apply one of the edge detection 
algorithm with S’ to obtain  the edge map M. 
Step 3：If the 3 by 3 block has edge point(s), and the 
difference if it is larger than zero and less than 
4(embedding 2 bits), or 8(3 bits), or 16(4 bits), 
etc, the interpolation position is embedded the 
number of bits that we did. Collect the embedded 
bits to form a bit stream. 
Step 4：Repeat Step 2, until the stop criterion is satisfied. 
Step 5：Shuffle back the bit stream by the same PRNG as 
the embedding algorithm used. 
Embedding
 
Fig. 4. A flow-chart diagram of embedding and extraction 
algorithms. 
 
 
Secret  image 
bit stream
Stego-Image 
No 
Cover Image 
Test 
Conditio
Embed
End of bit stream 
or 
End of  cover  mage 
Yes 
Yes 
No 
Extraction 
No 
Stego- Image 
 
Test 
Condition 
Extract
End of bit stream 
or 
End of  cover 
image
Yes
Yes 
No 
 
Find 
interpolation 
Find 
interpolation
Shuffle by 
PRNG
Shuffle back by 
PRNG
Secret image
 Jet 34.8009 
(18497) 
33.9681 
(23495) 
33.9579 
(24198) 
Pepper 35.2978 
(15493) 
34.7865 
(19302) 
34.8110 
(19281) 
 
Table 3. The PSNR table of embedding 3 bits and 4 bits as 
possible as it can in one position for three 
interpolation methods with only lenna images. 
Interpolation\Picture Lenna (3 bits) Lenna (4 bits) 
Nearest(embedded) 33.3865 
(114037) 
28.3714 
(136684) 
Bilinear(embedded) 33.3754 
(126722) 
28.8856 
(140244) 
Bcubic(embedded) 33.3414 
(127464) 
28.8753 
(140856) 
 
4 Conclusions 
We proposed an effective and imperceptible data 
hiding method in spatial domain. We may easily embed 
data into a gray level cover image, and extract those hidden 
data without using the original cover image. We use the 
interpolation techniques to reach the hiding goal. The 
computer experiments show we have good PSNR after 
embedding data. For the security consideration we use the 
PRNG to scramble the secret data before embedding. The 
future works we may shift the one or two rows, one or two 
column to be the starting pixel to divide the cover image 
into 3 by 3 overlapping blocks. It may be developed to an 
adaptive data hiding algorithm. 
  
(a) Original image (b) Nearest interpolation 
method 
  
(c) Bilinear interpolation 
method 
(d) Bicubic interpolation 
method 
Fig. 6. the stego-image lenna with embedding 3 bits in one 
position for three interpolation methods. 
  
(a) Original image (b) Nearest interpolation 
method 
  
(c) Bilinear interpolation 
method 
(d) Bicubic interpolation 
method 
Fig. 7. the stego-image lenna with embedding 4 bits in one 
position for three interpolation methods. 
 
  
(a) Nearest interpolation  
(3 bits) 
(b) Nearest interpolation  
(4 bits) 
  
(c) Bilinear interpolation  
(3 bits) 
(d) Bilinear interpolation  
(4 bits) 
  
(e) Bicubic interpolation  
(3 bits) 
(f) Bicubic interpolation  
(4 bits) 
Fig. 8. the stego-image lenna with embedding 3 bits 
(a)(c)(e) and 4 bits (b)(d)(f) as possible as it can in one 
position for three interpolation methods. 
 
6 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC  95－2221－E－364－002－ 
計畫名稱 以全域或局部的梯度差異變化對不同亮度下的影像比對法 
出國人員姓名 
服務機關及職稱 
楊權輝；玄奘大學資訊科學學系；助理教授 
會議時間地點 
時間：June 25-28, 2007  
地點：Monte Carlo Resort, Las Vegas Nevada, USA 
會議名稱 WORLDCOMP’07，The 2007 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV'07) 
發表論文題目 A Data Hiding Technique by Using 2D Interpolation Methods in Spatial Domain 
 
一、參加會議經過 
    啟程：June 24 傍晚 
    返國：July 3 早上 
報告時間：June 26 下午 1:30-2:30 
報告方式：POST 
 
二、與會心得 
1. 這個報告論文，以影像處理方法應用在影像資訊隱藏上。 
2. 再次增進 POST 的經驗，對應和了解問題都是要很迅速的。 
3. 和做相同領域的學者互相交流，親自體會其他人對這些相同或類似的問題的看法或解
決之道。 
4. 和台灣去的老師與同學交換不同問題的心得。 
5. 聆聽一些有興趣的議題，幫助了解更多相關的領域。 
6. 英文有些退步，要多多練習了。 
7. Las Vegas 變化很大，賭城除賭博以外慢慢轉變以觀光來吸引遊客。 
 
三、附件：發表論文 
 distribution in macro-block decreases after data hiding. Lin 
et al. [9] propose a variable depth LSB substitution data 
hiding technique. The pixels of cover-image are grouped 
according to their luminance values. After counting the 
occurrence of pixel-values in each group, they are sorted in 
monotone increasing. Finally a bit plane-wise data hiding 
method is used to hide data in cover image. They also 
formulated the worst-square-error between the stego-image 
and the cover-image. In Ni et al. [11], they are interested in 
lossless data hiding. Most of the existing lossless data 
hiding algorithms are fragile that they will be defeated 
when compression or other small alteration is applied to the 
cover image. They proposed a nove1 robust lossless data 
hiding technique, which does not generate salt-pepper 
noise and successfully applied to many commonly used 
images. Ramkumar and Akansu [12] give the practical 
solutions for signaling methods for multimedia 
steganography. Data hiding seems to be a sophisticated 
signaling technique using a periodic signal constellation. 
They propose such a signaling method and give both 
theoretical and the simulation of its performance in an 
additive noise circumstances.  
Secondly, we introduce some authors’ works in 
frequency domain. Ikeda et al. [7], they work on audio data. 
They use the band-limited random sequences to establish 
further flexibility in the spread spectrum based audio data 
hiding. They set up a systematic method in order to 
generate band-limited and orthonormal random sequences 
of any length to understand the sub-band data hiding. In 
Mukherjee et al. [10], the authors present a source and 
channel coding framework for data hiding. It allows any 
tradeoff between the distortions, the data embedded, and 
the robustness. The secret data is source coded by vector 
quantization. They use orthogonal transform domain vector 
perturbations to embed data in the cover video after the VQ 
indices obtaining in the process. According to noise-
resilient channel codes derived from multidimensional 
lattices, the transform coefficients of cover image’s are 
grouped into vectors and perturbed. The maximum mean-
squared error limits the perturbations. The optimally 
channel coding can be used to increase the robustness to 
noise. LZW is one of the well-known lossless compression 
methods. The modifiable elements of LZW for data hiding 
and how to handle them are proposed in Shim et al. [13]. 
The DH-LZW method embeds data into cover image in a 
lossless manner. Wang and Ji [14] propose a novel error 
concealment scheme for images compressed in wavelet 
domain. To reconstruct missing data of region-of-interest 
(ROI) is based on data hiding techniques. They use shape-
adaptive wavelet transform to transform the ROI and 
region-of-background (ROB) of images into wavelet 
domain and coded with the rate-distortion optimized coder. 
Embedded data are truncated from the coded bit stream of 
ROI and embedded into the wavelet coefficients of ROB. 
In Xuan et al. [15], they propose a reversible data hiding 
algorithm based on integer wavelet transform. This means 
that can convert the stego-image to the original image 
without any distortion after extracting the hidden data. 
Data are hidden into one (or more) middle bitplane(s) of 
the integer wavelet transform coefficients in the middle and 
high frequency subbands. It is a tradeoff between the 
amount of data and the distortion how to satisfy the 
imperceptibility requirement. 
This paper is organized as follows. In section 2 we 
discuss our proposed method that includes how to embed 
the secret data into a cover image and extract these 
embedded data from this marked cover image. Section 3 
then gives several computer experiment results and 
comments. Finally, in the conclusion we summarize our 
major results and outline our future work. 
2 Proposed method 
 We are going to propose an effective and 
imperceptible data hiding method in spatial domain. We 
may easily embed the secret data into a gray level cover 
image, and extract those secret data without using the 
original cover image. Here we give a briefly discussion 
first. The cover image is divided into small 3 by 3 blocks 
images that have overlapping with boundaries. We use four 
known points to be the control points to generate a new 
local 3 by 3 images by 2D interpolation technique. Please 
see Fig. 1. If the difference between the interpolation value 
and original gray level at the same pixel is less than a 
threshold and larger than zero, we may embed 2 bits, 3 bits, 
or even 4 bits in this pixel. If original gray level is larger 
than interpolation value, we let the new gray level be 
interpolation value adding to embedding bits values. Fig. 2 
shows the condition. Similarly, if original gray level is 
smaller than interpolation value, we let the gray level be 
interpolation value subtracting from embedding bits values. 
Concerning the security, we transfer the secret data into a 
bit stream, shuffle them by a pseudo-random generator then 
embed data in the location that satisfying the embedding 
condition. The extracting steps just follow the embedding 
algorithm to check the possible embedded location to 
collect the embedded bits. Then we use the same pseudo-
random generator to shuffle back the bit stream order to 
find the original secret data. 
 
Fig. 1. Four known control points (black points) in a 3 by 3 
block image, the white points will be the 
interpolations. The middle white point is computed 
by 2D interpolation method and the other fours 
whites are computed by the linear interpolation 
method. 
 
2 
 4 
 
Fig. 3. The interpolation A(x, y) and four known 
points are shown. 
 
Bicubic Interpolation 
The bicubic interpolation value f(x, y) of a function f at a 
point (x, y) is calculated as a weighted average of the 
nearest sixteen known pixels in a rectangular 4 by 4 grid. 
By using two cubic interpolation polynomials, one for each 
plane direction, are computed. The bicubic interpolation is 
calculated as follows: 
3 3
0 0
i j
ij
i j
a x y
= =
∑∑                                        (2.5)  
For each of the vertices of the known pixels, the local 
coordinates at (0,0), (1,0), (0,1) and (1,1) can be input into 
above equations to induce 16 equations to solve. 
2.2 Proposed Embedding and Extracting 
algorithm 
 Here we denote the C is the cover image and M is its 
edge map. D is the secret data. After embedding secret data, 
we have a stego-image, said S. The embedding and 
extracting algorithms are as follows.  
Embedding Algorithm 
Step   1 :Transfer the secret data D into bit stream.  
Step 2 :Shuffle the bit stream by a pseudo-random 
generating function (PRNG) . 
Step 3 : Divide the cover image C into 3 by 3 blocks 
overlapping with the boundaries, then apply the 
2D interpolation to get C’ . 
Step 4 : Apply one of the edge detection algorithm with the 
interpolation of cover image C’ to get the edge 
map M. 
Step 5: If the 3 by 3 block has edge point(s), and the 
absolute of difference is larger than zero and less 
than 3(embedding 2 bits), or 7(3 bits), or 15(4 
bits), 
etc, the interpolation position is embedded the 
number of bits what we want. 
P11(x1, y1) 
P12(x1, y1) 
P22(x1, y1) 
P21(x1, y1) 
A(x, y) 
Q2(x, y2) 
Q1(x, y1) 
Step 6: Repeat Step 4, until the secret data bit stream is      
running out or the cover image has no place to 
embed. We obtain a stego-image S. 
Extraction Algorithm 
Step 1：Divide the stego-image S into 3 by 3 blocks 
overlapping with the boundaries. 
Step 2：Apply 2D interpolation with stego-image S to get 
S’ (=C’)，then apply one of the edge detection 
algorithm with S’ to obtain  the edge map M. 
Step 3：If the 3 by 3 block has edge point(s), and the 
difference if it is larger than zero and less than 
4(embedding 2 bits), or 8(3 bits), or 16(4 bits), 
etc, the interpolation position is embedded the 
number of bits that we did. Collect the embedded 
bits to form a bit stream. 
Step 4：Repeat Step 2, until the stop criterion is satisfied. 
Step 5：Shuffle back the bit stream by the same PRNG as 
the embedding algorithm used. 
Embedding
 
Fig. 4. A flow-chart diagram of embedding and extraction 
algorithms. 
 
 
Secret  image 
bit stream
Stego-Image 
No 
Cover Image 
Test 
Conditio
Embed
End of bit stream 
or 
End of  cover  mage 
Yes 
Yes 
No 
Extraction 
No 
Stego- Image 
 
Test 
Condition 
Extract
End of bit stream 
or 
End of  cover 
image
Yes
Yes 
No 
 
Find 
interpolation 
Find 
interpolation
Shuffle by 
PRNG
Shuffle back by 
PRNG
Secret image
 Jet 34.8009 
(18497) 
33.9681 
(23495) 
33.9579 
(24198) 
Pepper 35.2978 
(15493) 
34.7865 
(19302) 
34.8110 
(19281) 
 
Table 3. The PSNR table of embedding 3 bits and 4 bits as 
possible as it can in one position for three 
interpolation methods with only lenna images. 
Interpolation\Picture Lenna (3 bits) Lenna (4 bits) 
Nearest(embedded) 33.3865 
(114037) 
28.3714 
(136684) 
Bilinear(embedded) 33.3754 
(126722) 
28.8856 
(140244) 
Bcubic(embedded) 33.3414 
(127464) 
28.8753 
(140856) 
 
4 Conclusions 
We proposed an effective and imperceptible data 
hiding method in spatial domain. We may easily embed 
data into a gray level cover image, and extract those hidden 
data without using the original cover image. We use the 
interpolation techniques to reach the hiding goal. The 
computer experiments show we have good PSNR after 
embedding data. For the security consideration we use the 
PRNG to scramble the secret data before embedding. The 
future works we may shift the one or two rows, one or two 
column to be the starting pixel to divide the cover image 
into 3 by 3 overlapping blocks. It may be developed to an 
adaptive data hiding algorithm. 
  
(a) Original image (b) Nearest interpolation 
method 
  
(c) Bilinear interpolation 
method 
(d) Bicubic interpolation 
method 
Fig. 6. the stego-image lenna with embedding 3 bits in one 
position for three interpolation methods. 
  
(a) Original image (b) Nearest interpolation 
method 
  
(c) Bilinear interpolation 
method 
(d) Bicubic interpolation 
method 
Fig. 7. the stego-image lenna with embedding 4 bits in one 
position for three interpolation methods. 
 
  
(a) Nearest interpolation  
(3 bits) 
(b) Nearest interpolation  
(4 bits) 
  
(c) Bilinear interpolation  
(3 bits) 
(d) Bilinear interpolation  
(4 bits) 
  
(e) Bicubic interpolation  
(3 bits) 
(f) Bicubic interpolation  
(4 bits) 
Fig. 8. the stego-image lenna with embedding 3 bits 
(a)(c)(e) and 4 bits (b)(d)(f) as possible as it can in one 
position for three interpolation methods. 
 
6 
