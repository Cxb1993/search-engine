2 
摘要 
本計劃提出一自動辨識鳥類鳴叫聲音之方法、對於一輸入之鳥類聲音，我們首先將此聲音之
每一音節切取出來，然後以整個音節之二維倒頻譜係數為此音節之特徵向量，二維倒頻譜
係數能夠表現一個音節裡聲音頻譜圖裡之靜態(static)和動態(dynamic)特性，也就是說可以
表現出一個音節整體的頻率變化和細微的頻率變化；另外，二維倒頻譜係數還能夠同時解
決音節長度不同的問題，因為在二維倒頻譜係數中真正有意義的是分佈於低頻的係數，所
以只要取固定數目分佈在低頻的係數來辨識就可得到極佳之辨識結果。由於鳥類鳴叫聲音
相當豐富多變化，即使是同一種鳥類所發出之聲音音節也有極大的差異，因此我們採用一
個自動分群的方法，把屬於同一種鳥類聲音音節細分成幾個小群，因此屬於同一小群之不
同音節其特徵向量會較相似，所以對於同一種鳥鳴聲，我們將採用多組特徵向量來表示其
不同之音節特性。最後以線性區別分析演算法來提升辨識之正確率，此一演算法可以縮小
同類特徵向量之距離而且加大不同種類特徵向量之距離，因此可以在減少特徵向量維度之
情況下提高辨識率。 
 
一. 報告內容 
1. 前言 
在動物叫聲的辨識中，鳥類鳴叫聲音(bird song/call)的辨識為最多人所研究。目前全世
界的鳥類約有 9,200 種，臺灣己列入正式記錄的鳥類約有 450 種(中華民國野鳥學會 1995)，
在分類學上分別隸屬於 18 目 68 科。由於種類繁多，不同物種間的棲息環境及生活方式也
都有所差異，因此眾多研究人員投入研究生物叫聲的差異性，希望依此發現新的物種，然
而目前所使用生物聲音的辨識方法，多採用人工至野外錄音，再回實驗室做人工的識別，
如此相當耗時且耗力，因此本計劃擬對鳥類鳴叫聲音之自動辨識做一深入之研究。 
鳥類沒有像人類般的聲帶(larynx)，其主要之發聲器官稱為鳴管(syrinx)，和人類的聲帶
位置比起來，鳴管位在鳥類胸腔的更深處。鳥類的鳴管是成對的，在鳥類胸腔的深處氣管
分成兩條支氣管，而鳴管有一部份在兩個支氣管內，且能發出聲音，這表示鳥類可以同時
發出兩種不同的聲音，甚至可以自己鳴唱二重奏。所以不同鳥類可以不同的方式來發出成
雙的鳴唱合弦。然而並不是所有的鳥類都會歌唱，也不是所有鳥類所發出的聲音都稱做歌
曲(song) [1]。通常歌唱的能力僅限於燕雀目(Passeriformers)或棲息性(perching)的鳥類，所
以世界上有將近一半的鳥種不會歌唱。幾乎會歌唱的鳥類都是雄鳥，而且雄鳥並不是整天
或整年鳴唱，鳥兒們如何選擇歌唱之時辰及地點是觀察鳥類行為之重要指標，而其歌唱之
主要目的有兩種：吸引雌鳥及宣告領土主權。就吸引雌鳥而言，雄鳥必須先確認雌鳥可以
很容易的就聽見他們的歌聲，因此不同的鳥類會調整使用不同的方式來歌唱。就宣告領土
主權而言，雄鳥之歌聲同樣需要被其他的雄鳥聽見，其目的有點像是在說：這個領土已經
被佔領而且主人正在家裡。針對鳥類歌聲而言，其聲音結構是較複雜的，通常是將鳥類歌
聲表示成一階層式之結構[2]，其中最簡單的一個鳥類聲音單元稱為音素(element)或是音調
4 
當輸入一段生物聲音訊號時，首先將一個個音節切割出來，每一個音節視為辨識系統
之基本的辨識單元。而選擇以音節當成辨識單元，是因為當所輸入聲音訊號同時有許多不
同種類的動物聲音時，要切出一個個的音節是比較簡單的，除此之外，利用音節所擷取出
來的特徵值較為穩定。在這裡我們是依據 Harma 之方法以頻率上的資訊來完成音節切割
[9]，其詳細步驟如下: 
Step 1. 利用 short-time Fourier transform(STFT)建立輸入生物訊號的頻譜，我們用一個矩
陣來表示此頻譜 )  ,( tfM ，f 和 t 分別表示頻率值和時間的索引值。 
Step 2. 設 n =0。 
Step 3. 針對所有的 )  ,( tf ，找出振幅強度之最大值，即 ),(),( tfMtfM nn     ≥ ，且將第 n
個音節的位置記錄為 )  ,( nn tf 。 
Step 4. 求得 )  ,(log20)0( 10 nnn tfMA = dB，當 β−< )()( 0A0A 0n  dB，停止切割動作，這代
表第 n 個音節的強度太小了因此就不需再切割出任何音節了， β 為一門檻值
(threshold)且其值設為 20。 
Step 5. 從 )  ,( nn tf 的 nt 位置找出 ntt < 的 )  ,( tfM 最大值，直到 dB )0()( β−<− nnn AttA ，同
時也尋找出 ntt > 的 )  ,( tfM 最大值，直到 dB )0()( β−<− nnn AttA 。這個步驟是要
找出第 n 個音節的起始時間 )( sn tt − 和結束時間 )( en tt + 。 
Step 6. 儲存第 n 個音節的時間點軌跡 ensnn tt...,,tt τA +−=       ),( 其中τ 。 
Step 7. 令 0)]...,,[,( =+−        snsn ttttfM ，目的是要將第 n 個音節的部份給清空，並令
n=n+1 且回到 Step 3 尋找下一個音節。 
 
2.2 特徵擷取 
 對於切割出來之每一鳥類聲音之音節，我們將以二維梅爾倒頻譜係數(Two-dimensional 
Mel-scale Frequency Cepstral Coefficients, TDMFCCs）及動態二維梅爾倒頻譜係數(Dynamic 
TDMFCC, DTDMFCC)為此音節之特徵向量。 
 
2.2.1 二維梅爾倒頻譜係數 
二維倒頻譜係數(Two-dimensional cepstrum, TDC)已被用於語音辨識上[13-15]，主要原
因是二維倒頻譜係數能夠表現出倒頻譜係數隨著時間的變化，對於描述相鄰音框特徵的關
聯性是一個不錯的方法，另外也能表現一個音節裡聲音頻譜圖裡之靜態(static)和動態
(dynamic)特性，也就是說可以表現出一個音節整體的頻率變化和細微的頻率變化；另外，
6 
將每一個音節切割成一個一個的音框，大小為 512，而且為了讓每個音框的差異性
不大，我們又讓每個音框重疊一半。 
步驟 3. 乘上漢明視窗(Hamming Windowing)  
為了來消除每個音框與開始與結束的不連續性，每個音框都乘上一個漢明視窗，
漢明視窗式子如下。 
   10  ),
1
2cos(46.054.0][ −≤≤−−= NnN
nnw π  
步驟 4. 快速傅立葉轉換(FFT) 
將音訊訊號從時域轉換成頻率域 
   NkenskX
N
n
n
N
kj <≤=∑−
=
−
0   , ][~][
1
0
2π
, 
其中 N 為音框大小。 
步驟 5. 梅爾三角帶通濾波器(Mel-frequency Triangular band-pass filter) 
由於人耳對聲音的頻率的解析度不是呈線性關係，而是呈現對數(logarithm)變化，
利用梅爾三角帶通濾波器將聲音訊號分成一個個頻帶，並算出每個頻帶的能量: 
   JjAkE
K
k
kjj <≤= ∑−
=
0  ,)(
1
0
φ , 
J 為三角帶通濾波器之個數, Ak為 X[k]的振幅: 
   2/0  ,|][| 2 NkkXAk <≤= , 
而φj為第 j 個濾波器: 
   
⎪⎩
⎪⎨
⎧
≤≤−−
≤≤−−
≥≤
=
j
h
j
c
j
c
j
h
j
h
j
c
j
l
j
l
j
c
j
l
j
h
j
l
j
IkIIIkI
IkIIIIk
IkIk
k
),/()(
),/()(
or  ,0
][φ  
在這裡， jlI , jcI 和 jhI 分別代表第 j 個濾波器之低頻索引值，中間頻率索引值，和
高頻索引值: 
   
)( Nf
fI
s
j
lj
l = , )( Nf
fI
s
j
cj
c = , )( Nf
fI
s
j
hj
h = , 
fs為取樣頻率， jlf , jcf , jhf 為第 j 個濾波器的低頻、中頻和高頻值，而每個濾波
器的低頻、中頻和高頻值。 
步驟 6. 二維離散餘弦轉換(Two-Dimensional Discrete Cosine Transform) 
 我們利用二維離散餘弦轉換具有可分離特性，先對一音節內之每一音框計算其梅
爾倒頻譜係數： 
8 
步驟 1: 預強調 (Pre-emphasis) 
][ˆ][][ˆ 1nsansns −−= , 
][ns  為我們輸入訊號， aˆ 的預設值為 0.95。 
步驟 2: 取音框 (Framing) 
將每一個音節切割成一個一個的音框，大小為 512，而且為了讓每個音 
框的差異性不大，我們又讓每個音框重疊一半。 
步驟 3: 傅立葉轉換(DFT)  
    NkenwnxkX
N
n
n
N
kj
qq <≤=∑−
=
−
0  ][][][
1
0
2 ，π  
其中 N 為音框大小，令 xq[n]表示第 q 個音框之第 n 個訊號值，Xq[k]為第 q 個音框之
第 k 個傅立葉係數，w[n]為漢明視窗(Hamming window)之第 n 個係數值： 
Nn
N
nnw <≤−−= 0  ),1
2cos(46.054.0][ π  
步驟 4: 三角帶通濾波器(Triangular band-pass filter)  
利用三角帶通濾波器將聲音訊號分成一個個頻帶，並算出每個頻帶的能量: 
∑−
=
=
1
0
)(
K
k
kjj AkE φ ， Jj ≤≤0 。 
步驟 5: 計算迴歸係數 
令 Ei(j)表示第 i 個音框之第 j 個三角帶通濾波器輸出值，將所有音框之三角帶通濾
波器之輸出值依時間順序排列，計算其迴歸係數 ai(j): 
∑
∑
−=
=
−+ −
=
0
0
0
2
1
))()((
)( n
nn
n
n
nini
i
n
jEjEn
ja , Jj ≤≤0 。 
步驟 6: 離散餘弦轉換(Discrete Cosine Transform) 
對這些迴歸係數乘上不同的餘弦值，求出動態梅爾倒頻譜係數 )(mCi′ : 
,))((log))5.0(cos()(
1
0
10∑−
=
+=′
J
j
ii jajJ
mmC π  10 −≤≤ Lm      
步驟 7: 對同索引值係數沿時間軸做離散餘弦轉換 
令 )(mCC q′ 為對所有 )(mCi′ 沿著時間軸做離散餘弦轉換得到的動態二維梅爾倒頻譜
係數，式子如下: 
10 
其中γ為大於 0 之常數值。 
 
2.4 代表向量生成 
由於鳥類鳴叫聲音相當豐富多變化，因此就算有兩個音節是從同一種鳥類聲音中所切
割出來的，所擷取出來的特徵向量也可能會有明顯的不同，所以對於每一種鳥類聲音，我
們將使用一個編碼簿(codebook)包含好幾個特徵向量來表示一種鳥類的鳴叫聲，因此屬於同
一種鳥類聲音之不同音節可以分成幾個小群，而屬於同一小群之不同音節其特徵向量會較
相似，所以同一種鳥類聲音必須以好幾個特徵向量來表示。 
在本計畫中，我們將採用一個向量量化法(Vector Quantization, VQ)的分群方法，稱為
progressive constructive clustering (PCC) algorithm [18]，自動把屬於同一種鳥類聲音細分成
幾個小群，令 },,,{ 21 jNjjj jS xxx L= 為所有第 j 種鳥類的特徵向量之集合， jN 為 jS 的大小，
而 PCC 演算法的敘述如下： 
步驟 1. 取 j1x 為群別 1 的中心點 )( 1c 。令 i = 2 且 nc = 1。 
步驟 2. 取特徵向量 jix 和集合 {c1, …, cnc}中每一個向量做比較以便決定其屬於        
那一群，比較方法為 : 令 kc 和 jix 的距離最短且表示為 ),( kjid c  x ，當       
dk
j
i Td ≤),( c  x 時將 jix 歸類為群別 k，如果不是，就跳到步驟 4。其中 Td 之定義
為： 
  Td = α×0.001×d, 
d 為特徵向量之長度，α為正整數。 
步驟 3. 當群別 k 有加入新的成員時，便重新計算代表群別 k 的中心點，之後跳   
        到步驟 5。 
步驟 4. 令 nc = nc + 1 並得到一個代表新群別的中心點 cnc = jix 。 
步驟 5. 如果 i = Nj便結束; 否則令 i = i+1 並回到步驟 2。 
 
2.5 線性區別分析演算法(Linear Discriminant Analysis, LDA) 
線性區別分析演算法之目的是將一個高維度的特徵向量轉換成一個低維度的向量，並
且增加辦識的準確率[19]，線性區別分析演算法主要處理不同類別間的區別程度而不是用
於不同類別之表示方式。線性區別分析演算法的主要精神是要把同類之間的距離最小化，
並且把不同類別之間的距離給最大化，所以，必需決定一個轉換矩陣(transformation matrix)
來將維度 n 的特徵向量轉換成維度 d 的向量，在這裡 nd ≤ ，透過這樣的轉換我們能夠增強
12 
) ,() ,( kr dd xxxx ≤ , 1 ≤ k ≤ N, k ≠ r. 
在這裡的距離公式是歐基里德距離(Euclidean distance)： 
∑
=
−=
d
m
k
mm
k xxd
1
2)(),( xx  
所辨認之鳥鳴聲種類代表編碼 s 即由 xr所屬之鳥類種類之特徵向量所形成之集合來決定： 
    , Ni Gxis s
ir ≤≤∈=     1  ,  if    
其中 Gi表示所有用以代表第 i 種鳥類之特徵向量所形成之集合，Ns 代表資料庫中鳥類之種
類數目。 
 
3. 實驗結果與討論 
在實驗所用鳥類聲音資料檔案，取樣頻率為 44100 Hz，音訊範圍大小為 16 bits，主要
來源是聲音光碟及網際網路中，總共分成兩個資料庫。第一個資料庫有 420 種日本之鳥類
鳴聲[20]，總共切割之音節數目為 29,754 個音節，在對資料庫中所有鳥類聲音擷取特徵進
行辨識前，我們以頻譜能量之資訊對每個鳥類聲音檔案切出音節，隨機取一半之聲音音節
做為訓練音節，而另一半之聲音音節為測試音節。第二個資料庫有 28 種在台灣錄音得到之
鳥類鳴聲[21-23]，此 28 鳥類之詳細資料請參考表一，其中訓練及測試音節分別自不同聲音
檔案中擷取出來，總計有 3,550 個訓練音節及 685 個測試音節。 
在實驗中，我們比較我們所提出的方法(STDMFCC 及 SDTDMFCC)與其他已知之方法
(ALPCC 及 AMFCC)。首先，為了評估特徵向量篩選演算法對於辨識正確率之影響，我們
對於 SFFS 演算法中所用到的參數值(γ)代入不同數值以評估其辨識正確率(如圖二)，由圖二
可以看出當以 Mahalanobis distance 來計算兩特徵向量之距離時，其辨識正確率會比用
Euclidean distance 來得高，而且當γ = 0.05 時可以得到最高之辨識正確率，然後隨著γ值變大
而遞減。另外，以 Mahalanobis distance 來計算兩特徵向量之距離時，當γ = 0.2 時可以得到
最高之辨識正確率，然後一樣隨著γ值變大而遞減。表二顯示針對不同γ值所篩選保留之特
徵向量維度，由此表可以得知利用 SFFS 特徵向量篩選演算法可以將特徵向量維度降低並
且提高辨識正確率。 
14 
50%
52%
54%
56%
58%
60%
62%
64%
66%
68%
- ∞ 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
γ
C
A
Euclidean distance Mahalanobis distance
 
圖二 在 SFFS 演算法中，參數值(γ)與辨識正確率之關係 
 
另外，為了評估 PCC 分群演算法對於辨識正確率之影響，我們對於 PCC 演算法中所
用到的參數值(α)代入不同數值以評估其辨識正確率(如表三)，由表三及圖二可以看出當以
較多組特徵向量來代表一種鳥類鳴聲時，其辨識正確率可以提高約 20%。 
為了評估 LDA 演算法對於辨識正確率之影響，我們對於 PCC 演算法後再加上 LDA 演
算法中，此一實驗結果顯示於表四中，由表四可以看出以 Mahalanobis distance 或 Euclidean 
distance 來計算兩特徵向量之距離時，其辨識正確率是相同，主要的原因是在 LDA 演算法
中我們加入了 whitening 之步驟，使得每一特徵值之變異數值是一樣的。 
最後，表五比較這幾種方法對於第一個資料庫之辨識正確率，由此一表中，我們可看
出 STDMFCC 之正確率比 ALPCC 及 AMFCC 高，而且當加上 DTDMFCC 時 (即
SDTDMFCC)，其辨識正確率最高可達 89.63%。表六則比較這幾種方法對於第二個資料庫
之辨識正確率，由此一表中，我們可看出 STDMFCC 之正確率比 ALPCC 及 AMFCC 高，
而且當加上 DTDMFCC 時(即 SDTDMFCC)，其辨識正確率最高可達 79.01%。 
 
表三 分群參數值(α)及特徵向量篩選參數值(γ)對辨識正確率之影響 
α Distance metric γ 1 2 3 4 5 
0.05 80.23 80.77 80.81 80.33 79.47 
0.10 84.42 84.62 84.02 83.61 82.33 
0.15 85.83 85.78 84.88 84.44 83.30 
0.20 86.41 86.30 85.54 84.77 83.56 
Euclidean 
distance 
0.25 86.46 86.38 85.59 84.29 83.15 
0.05 84.68 86.06 86.15 85.57 84.84 
0.10 87.63 88.43 88.45 87.87 86.93 
0.15 88.42 89.12 88.78 88.47 87.81 
0.20 88.61 89.18 88.85 88.49 87.28 
Mahalanobis 
distance 
0.25 88.50 88.86 88.54 87.71 86.73 
16 
Proc. of IEEE Conf. on Communications, Power, and Computing, Vol. 2, pp. 409-414, May 
1995. 
[6] A. L. McIlraith and H. C. Card, “A comparison of backpropagation and statistical classifiers 
for bird identification”, in Proc. of IEEE Int. Conf. on Neural Networks, Vol. 1, pp. 100-104, 
June 1997. 
[7] A. L. McIlraith and H. C. Card, “Birdsong recognition using backpropagation and 
multivariate statistics”, IEEE Trans. on Signal Processing, Vol. 45, No. 11, pp. 2740-2748, 
Nov. 1997. 
[8] A. L. McIlraith and H. C. Card, “Bird song identification using artificial neural networks 
and statistical analysis”, in Proc. of Canadian Conf. on Electrical and Computer 
Engineering, Vol. 1, pp. 63-66, May 1997. 
[9] A. Harma, “Automatic identification of bird species based on sinusoidal modeling of 
syllables”, in Proc. of IEEE Int. Conf. on Acoustics, Speech, and Signal Processing, Vol. 5, 
pp. 545-548, 2003. 
[10] A. Harma and P. Somervuo, “Classification of the harmonic structure in bird vocalization”, 
in Proc. of IEEE Int. Conf. on Acoustics, Speech, and Signal Processing, Vol. 5, pp. 
701-704, 2004. 
[11] P. Somervuo and A. Harma, “Bird song recognition based on syllable pair histograms”, in 
Proc. of IEEE Int. Conf. on Acoustics, Speech, and Signal Processing, Vol. 5, pp. 825-828, 
2004. 
[12] P. Somervuo, A. Harma, and S. Fagerlund, “Parametric representations of bird sounds for 
automatic species recognition”, IEEE Trans. on Audio, Speech, and Language Processing, 
Vol. 14, No. 6, Nov. 2006, pp. 2252-2263. 
[13] Y. Ariki, S. Mizuta, M. Magata, and T. Sakai, “Spoken-word recognition using dynamic 
features analysed by two-dimensional cepstrum”, IEE Proceedings, Pt. I, No. 2, Apr. 1998, 
pp. 133-140. 
[14] H. F. Pai and H. C. Wang, “A study of the two-dimensional cepstrum approach for speech 
recognition”, Computer Speech and Language, No. 6, 1992, pp. 361-375. 
[15] C. T. Lin, H. W. Nein, and J. Y. Hwu, “GA-based noisy speech recognition using 
two-dimensional cepstrum”, IEEE Trans. on Speech and Audio Processing, Vol. 8, No. 6, 
Nov. 2000, pp. 664-675. 
[16] S. Furui, “Speaker-independent isolated word recognition using dynamic features of speech 
spectrum”, IEEE Trans. on Acoustics, Speech, and Signal Processing, Vol. ASSP-34, No. 1, 
Feb. 1986, pp. 52-59. 
[17] P. Pudil, J. Novovicova, and J. Kittler, “Floating search methods in feature selection”, 
