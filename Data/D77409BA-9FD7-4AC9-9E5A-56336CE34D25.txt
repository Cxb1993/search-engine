摘要 
隨著物理模擬技術的成熟，目前相當多電影與遊戲都加入物理模擬技術，使物件
之間互動更為自然。但是要在三維物理模擬環境下，重現動作捕捉器動畫相當困難，
因為不容易維持模擬人體的平衡。 
    本研究提出新方法，可以在物理模擬環境下，即時(real-time)控制三維兩腳角
色重現目標動作捕捉器動畫，並動態對外界影響做出反應。本篇論文是利用倒單擺代
表整個人體，並即時去改變動作路徑，使模擬人體身體與動作捕捉動畫人體維持相同
的狀態。除了重現動作捕捉器記錄下來的動畫外，在不同的地形與外 力影響下，亦
可維持平衡。此外，用於控制人體做出目標姿勢的技術中，最常見的控制技術是比例
微分控制器(Proportional - Derivative controllers)。但是此種控制器需要微調
參數，不同動作的參數皆不同。因此本研究提出一個速度驅動控制器(velocity- 
driven)，只需要粗略設定一組參數，即可做出各種類型的動畫。 
    本研究提出的控制器，可以在即時(real-time)運算下，控制模擬的人體跟隨目
標動畫。並可以隨時改變地形、給予外力、改變姿勢，或使用者給予的動作限制，皆
可立即(real-time)反應在模擬人體上，並保持平衡。 
 
關鍵字：三維人體動作; 物理模擬; 倒單擺; 動作捕捉 
 1
 3
報告內容 
 
    由於本計畫之成果已寫成完整論文並被 IEEE TRANSACTIONS ON 
VISUALIZATION AND COMPUTER GRAPHICS (TVCG) 接受，將於 2010 年初刊登。
因此附上全文作為報告內容。 
 
the control parameters for various character sizes/styles
can be manually set or automatically optimized. Once the
parameters of a controller are specified, the animated
character can respond to environmental disturbances in
real time. However, considerable efforts may be required in
designing task-specific or character-specific controllers.
In this paper, we present a physics-based controller for
animating three-dimensional biped characters that can react
to dynamic environments in real time (Fig. 1). Our frame-
work employs a balance motion filter that adjusts the
desired motion trajectory in an online manner. Our biped
balancing strategy is based on an inverted pendulum model
(IPM) simplified from a full-body character model. The IPM
simplification allows the balance motion filter to produce
physically plausible and balanced motion trajectories for
controllers to track. The dynamics of the IPM is so simple
that the balance strategy can be determined in real time
either by solving a closed form (on a flat ground) or through
numerical root finding of a simple algebraic equation (on a
slope). We adopted a velocity-driven tracking method to
track the target trajectory generated by the balance motion
filter. The velocity-driven tracking is formulated as a linear
complimentary problem (LCP) to compute torques at joints
that generate the desired joint velocities. The functionality
of the velocity-driven tracking is similar to that of PD
servos, but it does not require tedious parameter tuning and
allows a large time step for simulation. Our results show
that the proposed method allows three-dimensional biped
characters to maintain their balance and respond to external
perturbation while being simulated in real time.
This paper provides the following novel insights and
contributions to the biped walking problem. First, although
the IPM has been seen repeatedly in biomechanics and
robotics, it has received much less attention in computer
animation. We introduced a new problem to the graphics
community that the IPM must also follow a motion capture
example and proposed a novel method to solve this
problem. To the best of our knowledge, the proposed
method is the first one that does not require additional
computational efforts in dealing with different motion styles
and character inertia parameters, while other methods often
need a certain amount of offline computational time.
Second, our method allows the character to withstand
stronger disturbances because the balance motion filter
calculates the exact foot-placing spot in real time. In contrast,
other approaches rely on offline precomputed optimization
or control parameter tuning procedures, resulting in weaker
abilities in responding to unexpected perturbations. Finally,
although great simplification in body segments is adopted to
allow fast computation of balanced motion, the proposed
method of transformation between the whole body and IPM
shows the effectiveness of our approach.
2 RELATED WORK
Designing dynamic controllers for biped characters is a
fundamental issue in computer graphics and robotics.
Animations of robust running and hopping gaits have been
developed by Raibert, Hodgins, and their colleagues [12],
[13], [14], [5]. The controls of running speed, jumping
height, and trunk orientation are the key components of
their approach. Dynamic balance during running is
achieved by properly placing the landing position of the
swing leg. Yin et al. proposed a similar balancing strategy
that produces dynamic walking of three-dimensional biped
characters [6]. Although these approaches have been
successfully applied to the control of walking and running
robots and animated characters, designing each controller
requires significant manual work for tuning control para-
meters. Several researchers explored algorithms for auto-
matically adapting existing dynamic controllers to new
characters [15] and new environments [16], [17] through
parameter optimization.
Physics-motivated objectives and constraints have been
employed in an optimization-based motion synthesis frame-
work [18], [19], [20], [1], [4]. The burden for maintaining
biped balance has often been circumvented by specifying
the root trajectory kinematically [3] or using designated
standing controllers [21], [22]. These optimization-based
approaches successfully reproduced stylistic human motion
2 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 16, NO. X, XXX/XXX 2010
Fig. 1. Real-time physics-based 3D character animation generated by our framework.
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on December 28, 2009 at 21:42 from IEEE Xplore.  Restrictions apply. 
which is a nonlinear differential equation of eðtÞ. This
equation is used to compute the trajectory of the COM and
determine the landing position of the swing leg based on
the constraints extracted from motion data.
3.3 Velocity Changes at the Double Stance Phase
Once the swing leg hits the ground, the single stance phase
ends and the biped walking enters the double stance phase.
As the IPM is only valid for the single-stance phase, we
simulate the double-stance phase by letting the simulated
character simply follow the motion capture data. The roles
of swing leg and stance leg exchange immediately after the
double-stance phase ends. Fig. 3b depicts the IPM at the
double stance phase. The velocity of the COM before and
after foot strike is related by
V2 ¼ V1 cos; ð3Þ
where V1 and V2 are the velocity of the COM before and
after the swing leg strikes the ground, respectively, and  is
the angle between two legs. Note that when the swing leg
hits the ground, the COM velocity along the axial direction
vanishes due to the ground reaction force and only the
tangential velocity component is left. Equation (3) also
explains a finding from biomechanical investigations [28]
that biped walking inevitably costs energy. The energy lost,
E, is
E ¼ m
2
V 21 
m
2
V 22 ¼
m
2
ðV1 sinÞ2; ð4Þ
which is related to  (or equivalently the step length). When
the swing leg and stance leg exchange their roles, positive
work must be done to maintain the same forward speed
(provided that angle between the two legs is not zero). In
real human motion, energy can be injected into the system
by muscular work done by extending the stance leg and
effectively pushing the ground. In the IPM motion, the lost
energy is compensated by exerting appropriate joint
torques to properly adjust the stance and swing leg so that
the desired COM speed is achieved.
The most significant property of the double stance
phase is that the ground reaction force along the swing leg
can be exploited to eliminate the impact of external forces
on the COM. Therefore, the balance motion filter can
adjust the landing position of the swing leg and the length
of the stance leg in order to produce positive work to keep
walking and maintain balance. We will explain how the
balance motion filter functions in Section 4.
4 OUR APPROACH
Fig. 4 shows an overview of our approach, which consists of
the mapping between a full-body posture to a simplified
IPM, balance motion filter, tracking control, and dynamics
simulation. The function of each component is summarized
as follows.
4 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 16, NO. X, XXX/XXX 2010
Fig. 3. (a) Single stance: The dynamics of the stance leg due to the
gravity applied between two angular positions s and e is governed by
the law of energy conservation. !s and !e corresponds to the instant
angular velocity at s and e, respectively. (b) Double stance: Velocity
changes at the double stance phase. Before the swing leg strikes the
ground, the COM velocity is V1. After the swing leg lands, the stance leg
immediately leaves the ground and the COM velocity becomes V2. V1
and V2 are perpendicular to the stance and swing leg, respectively.
Fig. 4. Approach overview. The balance motion filter and velocity-driven tracking controller are performed at each time step in real time.
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on December 28, 2009 at 21:42 from IEEE Xplore.  Restrictions apply. 
need to compute four angles, three DOF for the hip, and one
DOF for the knee, to bring the end-effecter of the foot to the
correct COP position. This is a typical inverse kinematics
(IK) problem, which can be solved analytically using an
approach similar to Lee and Shin’s method [37]. We assume
the toe part is flat while the ankle angle generally follows
the motion capture data. When the stance foot in the motion
captured data is flat on the ground and the current COM
horizontal velocity differs from the target value, we adjust
the stance ankle angle in the desired motion trajectory when
mapping an IPM posture to a full-body posture. For
example, when the COM moves faster than the desired
speed, the ankle angle is adjusted such that the stance leg
contacts the ground with the toes. Otherwise, the heel
contacts the ground.
In addition, the swing leg trajectory is generated accord-
ing to the motion capture data. Since the step length
calculated by the balance motion filter may be different
from themotion capture data, the path of the foot is rescaled.
The new path usually has similar shape as the motion
capture data with the same height but the step length
becomes identical to that calculated by the balance motion
filter. The landing time is determined by the calculated
swing leg trajectory; however, it can also be specified by
users to explicitly control the landing time of the swing leg.
The upper body can either track the motion capture data or
be specified by the animator. Motion tracking may not be
achieved perfectly since the velocity constraints may be
violated if any computed joint torque exceeds the preset
torque limit. The proposed method focuses on the lower
body rather than the upper body because the formal is
considered more crucial to balance motions.
4.2 Balance Motion Filter
A key component in our framework is the balance motion
filter, which computes balancedmotion trajectories based on
the IPM dynamics and the IPM motion converted from the
input motion data. The design of the balance motion filter is
motivated by the need for instantly predicting a proper
landing of the swing leg to maintain balanced motion using
simple equations. Two major tasks of the balance motion
filter are: 1) computing the trajectory of the COM and
2) adjusting the leg landing position to maintain the balance
of the IPM and reproduce the motion characteristics in the
input motion data. The computed COM trajectory and leg
landing position are then used to generate the desired joint
angles of hips, knees, ankles, and toes in full-body dynamics
simulation. As the computational cost of the IPM dynamics
is low, our balance motion filtering is executed at all time
instants so that unexpected disturbances in a dynamic
environment can be handled in real time.
The position and velocity of the COM in the single stance
phase, ST and VST , can be easily computed using (1). When
the swing leg hits the ground, the ground reaction force
along the swing leg is utilized to cancel out the impact of
external force applied to the animated character. At the
double stance phase, the position and velocity of the COM
is obtained from the motion capture data to be tracked.
The computation of the landing position of the swing leg
is illustrated in Fig. 6. The landing position is determined by
the unknown parameter SW1. Suppose the desired position
and velocity of COM at specified time are given, i.e., SW2
and VSW2 are known parameters extracted from the motion
capture data. The only unknown parameter SW1 can be
computed by combining (1) and (2):
1
2
I!2SW1 mgrðcos SW2  cos SW1Þ ¼
1
2
I!2SW2; ð5Þ
where the angular velocities !SW1 and !SW2 are obtained
from the linear velocities of the COM,
!SW1 ¼ 1
r
VSW1 ¼ 1
r
VST cosðSW1 þ ST Þ; ð6Þ
!SW2 ¼ 1
r
VSW2: ð7Þ
VST and VSW1 are the COM velocities immediately before
and after the swing leg strikes the ground, respectively.
Equation (5) is solved numerically using the fourth-order
Runge-Kutta method since there is no closed-form solution
for SW1. Although the numerical solution of the contact
angle SW1 may not be precise, this numerical error does not
affect the balance control of the character since corrections
are made in subsequent time steps.
The IPM length r is actually not constant because the
movements of body segments affect the COM position, and
consequently COM to COP distance. Likewise, r needs to be
changed on a slope. In either case, r is repeatedly computed
at each time step. The length of the swing leg r can be
calculated from the height of COM Ly using
r ¼ Ly sinð

2  ST  GÞ
cos ST sinð2  SW1 þ GÞ
; ð8Þ
where G is the slope angle of the ground.
Equation (5) describes the dynamics in the 2D case. In a
3D environment, the calculation is divided into a frontal
and a sagittal plane. Thus, SW2 becomes SW XY or SW ZY
6 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 16, NO. X, XXX/XXX 2010
Fig. 6. The ground reaction force at the double stance phase is exploited
to eliminate the impact of external forces exerting on the IPM in the
single stance phase. The direction of ground reaction force is
determined by the landing position of the swing leg. Hence, an
appropriate SW1 is computed to achieve a desired COM velocity VSW2
when the COM velocity VST at the single stance phase is affected by
external forces. Subscript 1 and 2 means before and after the swing leg
striking ground, respectively.
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on December 28, 2009 at 21:42 from IEEE Xplore.  Restrictions apply. 
Thus, from the tracking error between the current joint
angle and the desired joint angle, the desired angular velocity
of a joint can be acquired by the error-velocity curve in Fig. 7.
After the angular velocities are assigned, ODE solves the
linear complementarity problem to obtain the required joint
torques for achieving the desired angular velocities and
consequently the desired posture. As the muscle strength for
each joint is different, Frad2velðerrÞ is multiplied by a constant
ci to model this variation, i.e., the desired angular velocity of
the ith joint is !i ¼ ci  Frad2velðerrÞ. Larger ci value means
that the joint to be controlled can achieve the target position
faster. In addition, each joint has its own limit on the torque
that it can generate. These joint torque limits are enforced as
inequality constraints in the LCP. Since the error-velocity
relation and themaximal joint torques that the humanmodel
can produce are both predefined values, desiredmotions can
be achieved without tedious control parameter adjustments,
and the same set of control parameters can be used for
different types of motions.
Our velocity-driven control approach is actually similar
to a PD controller in which the applied forces/torques are
obtained according to the differences in the current and
target positions/velocities. We further simplify the con-
troller by using only the velocity information because of the
bell-shaped curve [40] in the biomechanics literature. The
comparison between tracking with PD and velocity-driven
controllers in our pilot experiments showed the validity of
this method. We also experimented with other error-
velocity curves, which allow the desired joint angular
velocity to increase with the tracking error, e.g., a linear
relation. Although these curves can also generate acceptable
results, the relation in Fig. 7 is adopted because it produces
better results.
5 RESULTS
We used the proposed approach to generate 3D character
animations that respond to dynamical environments in
real time. Three sets of experiments are performed:
imitating motion capture data (Section 5.1), motion styles
and transitions (Section 5.2), robustness (Section 5.3). The
skeleton model (Table 1) used in our experiments is
modified from the skeleton in CMU’s Motion Capture
Database. For better balance control, we add one more
degree of freedom (DOF) at the ankle joint (3 DOF). Thus,
the skeleton has 30 joints and 58 DOF in total. Body
segment mass and moment inertia parameters are from
[36] with the total mass of 81.4 kg. The Coulomb friction
model is adopted as the ground contact model and the
friction coefficient of the ground is 1. For all the
experiments, motions are simulated using a time step of
0.02 seconds with the resulting frame rate of 25 frames
per second. On an Intel E8400 PC, the computational time
of the balance motion filter and the tracking control with
dynamics simulation are 5.10 ms and 8.45 ms, respec-
tively. Thus, the ratio of simulation time versus real time
is 13:55 ms= 20 ms ¼ 0:68.
5.1 Balanced Walking with Motion Capture Imitation
Our balance motion filter with velocity-driven tracking
control successfully simulates biped walking without
8 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 16, NO. X, XXX/XXX 2010
Fig. 7. Error-velocity curve Frad2velðerrÞ, where err is the difference
between the desired joint angle and current joint angle.
TABLE 1
Number of DOFs, Torque Limits, and ci of All Joints of the Simulation Body
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on December 28, 2009 at 21:42 from IEEE Xplore.  Restrictions apply. 
found manually [6], [11] or precomputed with much more
efforts [41], [42], [43].
5.3 Robustness
We demonstrated the robustness of our approach by testing
it under uneven terrains, unexpected external forces and
variations of model parameters.
Uneven terrains. The most distinctive feature of our
method is its ability to react to unexpected disturbances in
real time. We demonstrate this by letting the animated
character walk on uneven terrains. We adjust the IPM leg
length, which corresponds to leg flexion or extension in the
multisegment model, when nonplanar ground surface is
detected. Our approach allows the character to successfully
walk up and down on slopes of up to 15 degrees. This result
shows that our approach is more robust than previous
methods [6], [11], in which the character can walk on slopes
of up to 5 or 6 degrees.
Unexpected external forces. In addition, we also tested
the robustness of our controllers by exposing the character
to unexpected external pushing forces (or impulses). The
goal is to maintain standing or walking balance by taking
several steps after a push or pull. Once an external force is
applied, the COM velocity is first calculated, and then the
IPM is utilized to estimate the remaining COM velocity after
each swing leg placement. We tested the balance recovery
capability of our controllers by pushing the character with
different impulse magnitudes and from different horizontal
directions (see Fig. 10 and accompanying video which can
be found on the Computer Society Digital Library at http://
doi.ieeecomputersociety.org/10.1109/TVCG.2009.76). The
maximal applied force lasting 0.4 s in eight evenly sampled
directions are (unit: Newton (N)): (0 N,486.02 N), (354.75 N,
321.30 N), (456.24 N, 0 N), (266.06 N, 365:90 N), (0 N,
457:72 N), (296:91 N, 341:59 N), (469:68 N, 0 N),
(270:78 N, 380.75 N). Comparing with the maximal
impulse (340 N in 0.4 sec) that the character can withstand
in [6], our method endures larger disturbance without
adjusting any control parameters.
Model parameter variations. Because any kind of
human body can be modeled using an IPM, our controllers
can successfully simulate the motion of bodies with
different sizes. In the accompanying video which can be
found on the Computer Society Digital Library at http://
doi.ieeecomputersociety.org/10.1109/TVCG.2009.76, we
show that characters with the original leg length, and twice
or half of it, can be controlled using the same set of control
parameters without any difficulty. In contrast, similar
robustness was tested by only a 10 percent increase in the
leg (femur) length in [6]. In addition, our method uses the
same set of control parameters, while manual tuning of
feedback gains for different characters is sometimes
necessary in [6].
5.4 Discussion
From our experimental results, one can find that the most
significant advantage of our work over prior work is that
our method requires no preprocessing and allows the
10 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 16, NO. X, XXX/XXX 2010
Fig. 9. Snapshots of a character walking while stooping under a barrier. This example is generated by bending the back and lowering the COM of the
character in a motion capture data of normal walking. Note that the squatting motion of the lower body is generated automatically by our method.
Fig. 10. Snapshots of a character’s balance-maintaining motion when a 700 N force is applied sideward for 0.2 seconds.
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on December 28, 2009 at 21:42 from IEEE Xplore.  Restrictions apply. 
onto an IPM. We would like to investigate this possibility to
produce more motion styles in our future work. Besides,
generating the interactive motion between two or among
more characters is also one of our future goals.
ACKNOWLEDGMENTS
The authors would like to thank anonymous reviewers for
their helpful comments to improve this paper. We are also
grateful toKangKangYinandMichiel vandePanne tohelpus
to perform experimental studywith theirwork [6]. Thiswork
is supported in part by the Landmark Program of the NCKU
Top University Project (Contract B0008), and the National
Science Council (Grants NSC-97-2628-E-006-125-MY3, NSC-
96-2628-E-006-200-MY3, NSC-96-2221-E-006-244-MY2, and
NSC-96-2221-E-009-152-MY3), Taiwan, Republic of China.
For correspondence, please contact ProfessorTong-YeeLeeat
tonylee@mail.ncku.edu.tw
REFERENCES
[1] A.C. Fang and N.S. Pollard, “Efficient Synthesis of Physically
Valid Human Motion,” ACM Trans. Graphics, vol. 26, no. 3,
pp. 417-426, 2003.
[2] A. Safonova, J.K. Hodgins, and N.S. Pollard, “Synthesizing
Physically Realistic Human Motion in Low-Dimensional, Beha-
vior-Specific Spaces,” ACM Trans. Graphics, vol. 23, no. 3, pp. 514-
521, 2004.
[3] C.K. Liu, A. Hertzmann, and Z. Popovic, “Learning Physics-Based
Motion Style with Nonlinear Inverse Optimization,” ACM Trans.
Graphics, vol. 24, no. 3, pp. 1071-1081, 2005.
[4] A. Sulejmanpasic and J. Popovic, “Adaptation of Performed
Ballistic Motion,” ACM Trans. Graphics, vol. 24, no. 1, pp. 165-179,
2005.
[5] J.K. Hodgins, W.L. Wooten, D.C. Brogan, and J.F. O’Brien,
“Animating Human Athletics,” Proc. ACM SIGGRAPH ’95,
pp. 71-78, 1995.
[6] K. Yin, K. Loken, and M. van de Panne, “Simbicon: Simple Biped
Locomotion Control,” Proc. ACM SIGGRAPH ’07, p. 105, 2007.
[7] K.W. Sok, M. Kim, and J. Lee, “Simulating Biped Behaviors from
Human Motion Data,” Proc. ACM SIGGRAPH ’07, p. 107, 2007.
[8] J. Lee, J. Chai, P.S.A. Reitsma, J.K. Hodgins, and N.S. Pollard,
“Interactive Control of Avatars Animated with Human Motion
Data,” ACM Trans. Graphics, vol. 21, no. 3, pp. 491-500, 2002.
[9] L. Kovar, M. Gleicher, and F. Pighin, “Motion Graphs,” ACM
Trans. Graphics, vol. 21, no. 3, pp. 473-482, 2002.
[10] Y. Li, T. Wang, and H.-Y. Shum, “Motion Texture: A Two-Level
Statistical Model for Character Motion Synthesis,” ACM Trans.
Graphics, vol. 21, no. 3, pp. 465-472, 2002.
[11] M. da Silva, Y. Abe, and J. Popovic, “Interactive Simulation of
Stylized Human Locomotion,” ACM Trans. Graphics, vol. 27, no. 3,
pp. 82:1-82:10, 2008.
[12] M.H. Raibert, Legged Robots that Balance.Mass. Inst. of Technology,
1986.
[13] M.H. Raibert and J.K. Hodgins, “Animation of Dynamic Legged
Locomotion,” Proc. ACM SIGGRAPH ’91, pp. 349-358, 1991.
[14] J.K. Hodgins, “Biped Gait Transitions,” Proc. IEEE Int’l Conf.
Robotics and Automation, 1991.
[15] J.K. Hodgins and N.S. Pollard, “Adapting Simulated Behaviors for
New Characters,” Proc. ACM SIGGRAPH ’97, pp. 153-162, Aug.
1997.
[16] S. Coros, P. Beaudoin, K. Yin, and M. van de Panne,
“Synthesis of Constrained Walking Skills,” ACM Trans.
Graphics (Proc. ACM SIGGRAPH Asia), vol. 27, no. 6, 2008.
[17] K. Yin, S. Coros, P. Beaudoin, and M. van de Panne, “Continuation
Methods for Adapting Simulated Skills,” ACM Trans. Graphics,
vol. 27, no. 3, 2008.
[18] A. Witkin and M. Kass, “Spacetime Constraints,” Proc. ACM
SIGGRAPH ’88, pp. 159-168, 1988.
[19] M.F. Cohen, “Interactive Spacetime Control for Animation,” Proc.
ACM SIGGRAPH ’92, pp. 293-302, 1992.
[20] Z. Popovic and A. Witkin, “Physically Based Motion Transforma-
tion,” Proc. ACM SIGGRAPH ’99, pp. 11-20, Aug. 1999.
[21] V.B. Zordan and J.K. Hodgins, “Motion Capture-Driven Simula-
tions that Hit and React,” Proc. Symp. Computer Animation (SCA),
pp. 89-96, 2002.
[22] Y. Abe, M. da Silva, and J. Popovic, “Multiobjective Control with
Frictional Contacts,” Proc. Symp. Computer Animation (SCA),
pp. 249-258, 2007.
[23] H. Miura and I. Shimoyama, “Dynamic Walk of a Biped,” Int’l J.
Robotics Research, vol. 3, no. 2, pp. 60-74, 1984.
[24] S. Kitamura, Y. Kurematsu, and M. Iwata, “Motion Generation of
a Biped Locomotive Robot Using an Inverted Pendulum Model
and Neural Networks,” Proc. IEEE Conf. Decision and Control,
vol. 6, pp. 3308-3312, 1990.
[25] S. Kajita, F. Kanehiro, K. Kaneko, K. Yokoi, and H. Hirukawa,
“The 3d Linear Inverted Pendulum Mode: A Simple Modeling for
a Bipedwalking Pattern Generation,” Proc. IEEE/RSJ Int’l Conf.
Intelligent Robots and Systems, vol. 1, pp. 239-246, 2001.
[26] A.D. Kuo, “Stabilization of Lateral Motion in Passive Dynamic
Walking,” Int’l J. Robotics Research, vol. 18, no. 9, pp. 917-930, 1999.
[27] M. Srinivasan and A. Ruina, “Computer Optimization of a
Minimal Biped Model Discovers Walking and Running,” Nature,
vol. 439, no. 7072, pp. 72-75, Jan. 2006.
[28] A.D. Kuo, J.M. Donelan, and A. Ruina, “Energetic Consequences
of Walking Like an Inverted Pendulum: Step-to-Step Transitions,”
Exercise and Sport Sciences Rev., vol. 33, no. 2, pp. 88-97, 2005.
[29] M. Brubaker, D.J. Fleet, and A. Hertzmann, “Physics-Based Person
Tracking Using Simplified Lower-Body Dynamics,” Proc. Compu-
ter Vision and Pattern Recognition, pp. 1-8, 2007.
[30] J.E. Pratt and R. Tedrake, “Velocity-Based Stability Margins for
Fast Bipedal Walking,” Proc. First Ruperto Carola Symp. Fast
Motions in Biomechanics and Robotics: Optimization and Feedback
Control, pp. 299-324, 2005.
[31] M. Abdallah and A. Goswami, “A Biomechanically Motivated
Two-Phase Strategy for Biped Upright Balance Control,” Proc.
IEEE Int’l Conf. Robotics and Automation, pp. 1996-2001, 2005.
[32] M. van de Panne, E. Fiume, and Z.G. Vranesic, “Physically-Based
Modeling and Control of Turning,” Computer Vision, Graphics, and
Image Processing: Graphical Models and Image Processing, vol. 55,
no. 6, pp. 507-521, 1993.
[33] P. Faloutsos, M. van de Panne, and D. Terzopoulos, “Composable
Controllers for Physics-Based Character Animation,” Proc. ACM
SIGGRAPH ’01, pp. 251-260, 2001.
[34] A. Bruderlin and T.W. Calvert, “Goal-Directed, Dynamic Anima-
tion of Human Walking,” Proc. ACM SIGGRAPH ’89, pp. 233-242,
1989.
[35] T. Komura, H. Leung, S. Kudoh, and J. Kuffner, “Animating
Reactive Motions for Biped Locomotion,” Proc. Virtual Reality
Software and Technology (VRST ’04), pp. 32-40, 2004.
[36] G. Harry, Anthropometry and Mass Distribution for Human
Analogues. Volume I: Military Male Aviator. Defense Technical
Information Center, Mar. 1988.
[37] J. Lee and S.Y. Shin, “A Hierarchical Approach to Interactive
Motion Editing for Human-Like Figures,” Proc. ACM SIGGRAPH
’99, pp. 39-48, 1999.
[38] M. Cline and D. Pai, “Post-Stabilization for Rigid Body Simulation
with Contact and Constraints,” Proc. IEEE Int’l Conf. Robotics and
Automation, vol. 3, pp. 3744-3751, 2003.
[39] D. Baraff, “Fast Contact Force Computation for Nonpenetrating
Rigid Bodies,” Proc. ACM SIGGRAPH ’94, pp. 23-34, 1994.
[40] T. Flash and N. Hogan, “The Coordination of Arm Move-
ments: An Experimentally Confirmed Mathematical Model,”
J. Neuroscience, vol. 5, no. 7, pp. 1688-1703, 1985.
[41] J. Lee and K.H. Lee, “Precomputing Avatar Behavior from Human
Motion Data,” Proc. Symp. Computer Animation (SCA), pp. 79-87,
2004.
[42] J. McCann and N. Pollard, “Responsive Characters from Motion
Fragments,” ACM Trans. Graphics, vol. 26, no. 3, pp. 6:1-6:7, 2007.
[43] A. Treuille, Y. Lee, and Z. Popovic, “Near-Optimal Character
Animation with Continuous Control,” ACM Trans. Graphics,
vol. 26, no. 3, pp. 7:1-7:7, 2007.
[44] M. da Silva, Y. Abe, and J. Popovic, “Simulation of HumanMotion
Data Using Short-Horizon Model-Predictive Control,” Computer
Graphics Forum, vol. 27, no. 2, pp. 371-380, 2008.
[45] Y. Ye and C.K. Liu, “Animating Responsive Characters with
Dynamic Constraints in Near-Unactuated Coordinates,” ACM
Trans. Graphics, vol. 27, no. 5, pp. 1-5, 2008.
12 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 16, NO. X, XXX/XXX 2010
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on December 28, 2009 at 21:42 from IEEE Xplore.  Restrictions apply. 
計畫編號 NSC 96-2221-E-006-244-MY2 
計畫名稱 應用物理與生物特性之動畫合成及動作轉移 
出國人員姓名 
服務機關及職稱 鄭匡佑成功大學副教授 
會議時間地點 2009 年 8 月 29 日至 9 月 2 日 上海 
會議名稱 The Fourth International Symposium on Aero Aqua Bio-Mechanisms(ISABMEC 2009) 
發表論文題目 僅參與會議 
 
    此次由上海交通大學、日本千葉大學以及大阪大學聯合舉辦的第四屆國際會
議“The Fourth International Symposium on Aero Aqua Bio-Mechanisms＂ (ISABMEC 
2009)於 2009 年 8 月 29 日至 9 月 2 日在中國上海召開，來自日本、美國、英國、
法蘭西、瑞士、以色列、韓國以及國內 100 多位仿生力學的學人和專家參加了會
議。這個由 Aero Aqua Bio-Mechanisms 研究團隊創辦的國際性的系列專題研討會，
為生物學家、科學家和工程師們建立領域溝通橋樑，彼此促進對各專擅領域之發
展。上海交通大學校長張傑院士和副校長陳剛教授分別參加了會議的開幕式和閉
幕式。日本千葉大學教授和上海交通大學長江學人講座教授劉浩博士擔任研討會
主席。 
    其中，會議邀請了國際著名仿生力學專家以及世界各名校教授做精彩的主題
報告，並進行了 41 個場次的會議交流報告和 28 篇研究論文的海報展覽，主題包
括：微生物中的生物力學、昆虫和鳥類飛行中的生物力學、游泳生物力學、 體育
生物力學、計算機生物力學、普通生物力學、生物系統和生物結構、生物材料生
物傳感器和定位控製、生物聲學和生物信標跟蹤記錄、生物神經肌肉系統生物機
本研究製作 21.6 公分翼展拍翼式飛行器，模仿鳥類拍翼運動及外型設計拍翼式
飛行器，並經實地測試飛行，鳥型拍翼式飛行器已可持續飛行 230 秒，驗證仿
生拍翼式飛行器設計的可行性。 
    誠如上述所言，在現今各領域均有值得讚嘆的成就前提下，如何統整各界現
有資源創造出更多的未來發展，乃為學術研究其努力不懈目的之一，而這樣的發
展與相輔相成實為各界學者所樂見與致力研究之圭臬，在此除感謝參與此次研討
會獲益良多外，也驚嘆於各界孜孜不倦而蓬勃發展的驚人成就，相信此次研討會
未來更能敦促後進，在各專長領域內大放異彩。 
以下為會議地點相片 
 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 96-2221-E-006-244-MY2 
計畫名稱 應用物理與生物特性之動畫合成及動作轉移 
出國人員姓名 
服務機關及職稱 
鄭匡佑成功大學助理教授 
會議時間地點 Aug 17-21, 2009. Limerick, Ireland  
會議名稱 International Society of Biomechanics in Sports Conference (ISBS 2009) 
發表論文題目 Computer Simulation of the Optimal Vaulting Motion during the Horse (table) Contact Phase 
 
 
 
一、 參加會議經過 
由於生物力學在人體動作與動畫模擬等領域佔有重要地位，因而本次參加的
國際研討會是運動生物力學界最重要的大會，會中報告的文章都是與運動相關
的生物力學論文。我本身專長領域為模擬，又這次發表關於體操跳馬的電腦模
擬動作，故便挑選了許多關於跳躍運動分析的論文做聽講，以及一些關於垂直
跳、立定跳遠、步態分析、跳馬運動與棒球投擲等等的研究來獲取新知。在聽
講各學者的發表時，首先我會先去看他們使用的研究方法是什麼，實驗儀器是
什麼（例如：使用的動作分析軟體是什麼？關節力矩是用什麼方法計算出來的
等等）。接著看著他們所畫出來的結果圖形，除了瞭解他們所研究的細節，也
在學習他們表達的方式。一些發表者的排版與構圖，讓我學習到了如何製作簡
報與海報可以讓人更清楚閱讀。在這次的研討會中，也看到了許多形形色色特
殊運動的生物力學分析，例如跆拳道與划船等等。 
覺得可惜的地方，也就是參訪的學術單位太少。另外建議學校提供愛爾蘭相關
地區的補助可以多一些，因為相較於其他地區，英國地區之生活費用偏高，然
而生活費用補助卻反而較低，不甚合理。 
 
圖一 開幕演奏 
 
圖二 Moher Cliff  
METHOD: 
A six-segment (6S) planar human body model comprising the lower arm, upper arm, head - 
trunk, thighs, shanks, and feet was developed to simulate the vaulting motion during horse 
(table) contact. Movement was driven by torque actuators at the ankle, knee, hip, shoulder 
and elbow. The model was customized to an elite gymnast through subject specific length 
and strength parameters. Detailed inertia parameters were determined using the data of 
Taiwanese gymnasts by an MRI method (Chen & Ho, 2006). A high-speed camera operating 
at 200Hz was used to record the vaulting motion. The trail with the greatest CM velocity at 
take-off from horse was chosen for kinematical analysis and as the input values of the model. 
Equations of motion were generated by the software AUTOLEV (www.autolev.com). Each 
joint torque T was assumed as the product of 3 factors:  
                                                    )()()(max tAhTT                                                (1) 
Tmax() depends on joint angle is the maximum isometric torque (effective torque for both 
extremities). The dependence on joint angular velocity is modeled by h().  




 1                              0,)(
 1  ,)()()(
0
000


h
h
                                       (2) 
Here  is the instantaneous joint angular velocity, 0=±20 rad/s is maximum angular velocity 
(positive in extension), and constant =2.5 is a shape factor. Joint activation level A(t) 
characterizing the coordination strategy corresponds to the effective activation of muscles 
across the joint. The activation level -1≤ A(t) ≤1 represents maximum effort for flexion and 
extension respectively. Linear interpolation was used to get the value at every time instant. 
The visco-elastic properties of the interface between the model and the vaulting horse (arm-
horse interface) were modeled by a non-linear spring force F ( King & Yeadon, 2005). 
VDKDSF  2                                          (3) 
Here S is the stiffness, D is joint displacement, K is the damping coefficient, and V is the joint 
velocity. This force F is applied in both horizontal and vertical directions. The objective was to 
maximize the vertical velocity of the center of mass (CM) at takeoff from the horse. The 
optimization algorithm adopted was the downhill simplex method. Varying initial guesses and 
re-starting the optimization from a newly found optimum are employed. The model was 
validated when the averaged angular difference between the model and actual performance 
was < 5%. Next, the elbow joint was fixed to develop a five-segment (5S) model. By varying 
the initial kinematic parameters and repeating the optimum calculation, the likelihood of 
finding the global rather than a local optimum was increased.  
RESULTS AND DISCUSSION: 
The averaged difference between actual performance and model was 4.10%, which met the 
criterion of model validity in this study. The elbow angle changed from 2.98 to 3.14 rad in the 
horse contact phase (Fig.1, 2).        
   
Figure 1: Motion in the horse contact phase of the 6S model 
