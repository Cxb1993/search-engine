Z`Ł
3Ùßar½	ÙóC(Ranking and Selection Procedures; R&S proce-
dures, see for instance [BSG95]) ﬀÂ½Tà¼ŁX^t·;®Þ	ºóCÙ
Îb§óê&ÆºàÙóC¼óÌbtTtº[TÂ (expected
performance measure) ÝÙ¬vÃt·ÙÝPºy×Íã¸àï¯
¼ÝÑ@óC^£ (probability of correct selection; PCS)Kim and Nelson ([KN01])
è×Í|øÍ¿í (sample mean) £Ý=$ðPóC (Fully Sequential
Selection Procedure; FSSP)&ÆÞ¸ÌﬁKNKN3NÍhø$ðºE)DºÝÙ
hã×ÍøÍqAáÝøÍ£G¼
 ó«ZÝÙ9øÝM»º×à
¹ìàÕt¡©yì×ÍÙåßﬁ}ß¡Z[PhD07]è×l=óC
(Controlled Sequential Selection Procedure; CSS)|²3¹*(Variance Reduction
Technique) 	Ý×ó (Control Variate) Ãs"fKN ?b[£ÝFSSP
Ä[PhD07]èÝCSSb9;Ýè ÎÆÍ@~Tè?b[£Xm
ÀøÍó?KÝ×lFSSP¨²$ÎbZ¤EyøÍ¿í|C×óÚxÝóC
×«PÝf´5Í@~ùÞEyŁèÝ±Ý[NS06]	ÝÞ$
ðP|CKNõCSSjE!Ý(®ÞÀÙóê9>&Ù Ý
TÂC²ó-û×ó®Ý8n;óTÎøÍóf´Í
8A¢ôT
×MèºóC3!µìÝóàÈ
n"ÞÙóC; ^t·;; ²3¹*; ×ó
I
1 G
In the stochastic simulation community, ranking and selection (R&S) procedures have been
proposed to select the simulated system with the largest or smallest expected performance
measure when the number of alternative designs is finite. There are many R&S procedures
providing different types of guarantees. In this paper we focus on extending one well-known
and effective procedure due to Kim and Nelson (2001, procedure KN ) which is a fully se-
quential R&S procedure. Such procedures take a single basic observation from each system
still in contention at each stage, and eliminate systems whenever they are statistically in-
ferior. This sort of elimination has been shown to greatly reduce the computational effort
required to find the best system relative to two-stage procedures.
Control variates (CV) is a variance reduction technique. Controls are random variables
in the simulation that are correlated with the output of interest, but whose expected values
are known. Nelson and Staum (2006) derived two-stage R&S procedures that employ CV
estimators, and Tsai, Nelson and Staum (2008) added screening in the first stage. These
CV procedures can be more statistically efficient than their sample-mean-based counterparts
since the CV estimator has a smaller variance than the conventional sample-mean estimator.
Our goal is to develop new fully sequential R&S procedures by employing a more effective
sum of differences, which we called a controlled sum, instead of the raw sum of differences
used in all previous work. A controlled sum of differences can be more statistically efficient
than a raw sum of differences because the Brownian motion process based on it has reduced
variance and the continuation region for the selection process has smaller area, leading to
fully sequential procedures that are correspondingly more efficient. In a controlled sum of
differences, the raw sum of differences is adjusted by a multiple β of the centered sum of
control variates that is correlated with the raw sum of differences. This reduces the variance
without changing the drift. The vector of coefficients, β is critical to the effectiveness of the
controlled sum. In practice, however, the optimal β is not known and choosing β arbitrarily
may degrade our procedure. Therefore, the key issue is estimating the optimal β.
The paper is organized as follows: In Section 2.1, we present our CV model and a
Generic Procedure from which specific procedures are derived. Subsection 2.2 provides a
statistically valid procedure when β∗ is unknown. In Subsection 2.3 we present a procedure
that combines the procedure in Subsection 2.2 and KN . An approximate procedure which
can not be proven to obtain the probability of correct selection (PCS) guarantee but may
require a smaller sample size is discussed in Subsection 2.4. A realistic illustration are
provided in Sections 3. The paper ends with conclusions in Section 4.
2 @~]°
2.1 The Generic Procedure
In this section we present the CV model on which our procedures are based, provide the
definitions and notation that will be used throughout the paper and introduce the Generic
Procedure utilizing a controlled sum.
1
2.1.2 The Procedure
Suppose that a larger mean is better, and unknown to us µk ≥ µk−1 ≥ · · · ≥ µ1. We want a
procedure that guarantees to select system k with PCS≥ 1−α whenever µk ≥ µk−1+δ, where
δ > 0 is a user-specified parameter representing the smallest difference worth detecting.
For each system i = 1, 2, . . . , k, any non-negative integers a, b, with b > a+ 1, and qi × 1
vector βi, the controlled sum from the (a+ 1)st sample to the bth sample is defined as
Xi [a, b,βi] =
b∑
j=a+1
[
Xij − (Cij − ξi)T βi
]
.
We use the following controlled sum of differences between systems i and ` to construct the
tracking process in our procedure:
Xi [a, b,βi]−X` [a, b,β`] =
b∑
j=a+1
[
Xij − (Cij − ξi)T βi −X`j + (C`j − ξ`)T β`
]
(2.2)
And,
X¯i[a, b,βi] =
1
b− aXi[a, b,βi].
For all i 6= `, define the controlled sample variance, S2i` [a, b,βi,β`], as
1
b− a− 1
b∑
j=a+1
[
Xij − (Cij − ξi)T βi −X`j + (C`j − ξ`)T β` − X¯i[a, b,βi] + X¯`[a, b,β`]
]2
.
The Generic Procedure
Setup: Select confidence level 1/k < 1 − α < 1, indifference-zone parameter δ > 0,
preliminary-stage sample size m0 > q + 2 (or m0 = 0 when there is no preliminary
stage), and first-stage sample size n0 such that n0 − m0 ≥ 2. Let λ = δ/2 and
h2 = 2η × (n0 −m0 − 1), where
η =
1
2
[(
2α
k − 1
)−2/(n0−m0−1)
− 1
]
.
Initialization: Let I = {1, 2, . . . , k} be the set of systems still in contention.
If m0 > 0, then
obtain (Xij,Cij), i = 1, 2, . . . , k, j = 1, 2, . . . ,m0 (preliminary stage),
compute the estimator β̂i(m0) of β
∗
i and set βi = β̂i(m0), i = 1, 2, . . . , k.
Else
set βi = β
∗
i or 0 or to an arbitrary value as desired, for i = 1, 2, . . . , k.
Endif
Obtain (Xij,Cij), i = 1, 2, . . . , k, j = m0 + 1,m0 + 2, . . . , n0 (first stage).
3
2.3 A Controlled Sequential Selection Procedure Combined with
KN
CSS is a statistically valid procedure that requires taking preliminary-stage samples to cal-
culate β̂i(m0) before we enter the screening process; therefore these m0 samples are wasted.
In this section we propose a controlled sequential procedure in which the preliminary-stage
samples can be exploited while still securing the required PCS. This procedure is basically
the combination of KN and CSS, so we call it CSS-C.
In CSS-C the m0 preliminary-stage samples are collected to compute β̂i(m0) and the
raw sample variance is utilized to set up the continuation region for KN . The KN proce-
dure is then performed from observation m0 to observation n0 (first stage); meanwhile, the
controlled sample variance S2ik[m0, n0, β̂i(m0), β̂k(m0)] is obtained and both KN and CSS
are implemented in parallel after the first stage (observation n0). A system is eliminated
when either KN or CSS eliminates it, and the procedure terminates when there is only one
system remaining.
The advantage of CSS-C is that it gives us an opportunity to eliminate inferior systems
in the first stage. The disadvantage is that it uses the conservative Bonferroni inequality to
combine KN and CSS to guarantee the overall PCS. This procedure is more desirable when
there are a large number of systems whose means are expected to differ widely. In that case,
we expect the savings gained through eliminating inferior systems in the first stage to more
than offset the losses incurred in applying the Bonferroni inequality.
In CSS-C we apply KN to screen out noncompetitive systems in the first stage. Then
after the first stage KN and CSS are applied to the surviving systems to select the best
system. We spend α0 of the overall allowable probability of incorrect selection α on KN ,
and the other α− α0 on CSS (typically we take α0 = α/2).
2.4 A Controlled Sequential Selection Procedure with Approxi-
mate Variance Estimator
To avoid wasting samples in the preliminary stage, we derive the Controlled Sequential
Selection Procedure with Approximate Variance Estimator (CSS-A). CSS-A is similar
to CSS except that it only requires a first stage (sample size n0 > q + 2) to estimate
the β̂i(n0) and an approximate variance estimator. For the Generic Procedure, we set
m0 = 0 in the Setup step, set βi = β̂i(n0) and replace S
2
i`[0, n0, β̂i(n0), β̂`(n0)] with
n0
(
∆̂2i (n0)τ̂
2
i (n0) + ∆̂
2
`(n0)τ̂
2
` (n0)
)
in the Initialization step.
The internal variance estimator, r
(
n0∆̂
2
i (n0)τ̂
2
i (n0)
)
, is a biased estimator of Var
[
Xi[0, r, β̂i(n0)]
]
for any observation counter r > n0, leading to the unfavorable consequence that the PCS
guarantee may not be attained. However, we expect the bias to be mild when n0 is not too
small, because
β̂(n0)
w.p.1−→ β∗ as n0 →∞ (Avramidis and Wilson 1993), and
n0∆̂
2(n0)τ̂
2(n0)
p−→ τ 2 as n0 →∞ (Nelson 1990),
5
Table 2: Results for NSGS, TNS-I, KN , CSS, CSS-C and CSS-A in 100 trials with δ = 0.1,
m0 = 20, n1 = 10 and 1− α = 0.95.
Procedure PCS ANS ŝe(ANS) PSS
NSGS 0.98 158 6.1 0.9
TNS-I 0.99 90 5.4 0.4
KN 0.99 89 2.9
CSS 0.96 37 0.4
CSS-C 0.96 36 0.4 0.7
CSS-A 0.90 42 2.1
is, for each replication we sample the initial condition in accordance with that steady-state
distribution of the number of customers in the system. An average waiting time for thirty
customers is used as the output on each replication. We use the average service time as
the control on replication j. The preliminary-stage sample size m0 for CSS and CSS-C is
set as 20, and we set the first-stage sample size n1 = 10 for all procedures. We choose the
indifference-zone parameter δ to be 0.1 and CRN is not applied.
Table 2 gives the results of the simulation study with 100 complete macroreplications
and nominal PCS = 0.95. We also provide the estimated standard error of ANS to illustrate
that there is a significant difference.
The observed PCS for all procedures is greater than 0.95 except for CSS-A. To be more
specific, X¯[0, n0, β̂(n0)] and n0∆̂
2(n0)τ̂
2(n0) will be biased when linearity fails; therefore,
the observed PCS for CSS-A deviates from the nominal PCS greatly. Notice that the
unbiasedness of the controlled sum and the controlled sample variance for CSS and CSS-
C do not depend on linearity. The efficiencies of the three CV procedures are similar and
superior to NSGS, TNS-I and KN in terms of ANS. There is not much difference between the
performance of TNS-I and KN . TNS-I can eliminate more systems than CSS-C in the first
stage (PSS=0.4 vs. PSS=0.7); however, CSS-C has smaller ANS than TNS-I because our CV
fully sequential selection procedure is much more efficient than the CV selection-of-the-best
procedure in Nelson and Staum (2006).
4 ¡
In this paper we have proposed a general methodology and several specific procedures for
applying control variates in a fully sequential indifference-zone selection procedure. We
recommend using CSS − C only when there are a very large number of widely spaced systems
so that the benefits of screening during the first stage are realized. For general use we
recommend CSS. We showed that these two procedures reduce the required sample size with
respect to KN while still delivering the PCS guarantee. An approximate procedure called
CSS −A may require fewer observations, and the experiments showed that it performed
well when all assumptions are satisfied even though we cannot prove its validity. On the
other hand, when the linearity assumption is violated, it seems risky to use CSS −A.
7
