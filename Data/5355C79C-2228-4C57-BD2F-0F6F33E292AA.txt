中   華   民   國  100 年  7 月 31 日 
行政院國家科學委員會專題研究計畫期末進度報告 
異質網路中提供具情境知覺之視訊串流服務 
 
Context-aware Video Streaming Service over Heterogeneous Networks 
 
計畫編號：NSC 97-2221-E-194-011-MY3 
執行期限：97年 8月 01日至 100年 07月 31日 
主持人：黃仁竑教授  國立中正大學資訊工程研究所  
Email: rhhwang@cs.ccu.edu.tw 
一、 中文摘要 
隨著  TW4G 的成功，未來的網路將是由
WiFi, WiMAX, 3G 等異質無線網路結合現有的有
線網際網路所形成的綿密而到處存在的網路
(ubiquitous network)。另一方面，隨著視訊聯合組
織(Joint Video Team, JVT) 所制定的可調式視訊
編碼(Scalable Video Coding(SVC)的普及，具有不
同的網路頻寬、存取方式、螢幕大小的行動裝置
將可不受環境與時間的限制收看視訊串流服務。
在整合型計畫中，我們整合了可調式視訊編碼技
術、WiFi 無線網路技術、WiMAX 無線網路技術、
網際網路技術、點對點傳輸技術，以三年的時間
研究異質網路中提供具情境知覺之視訊串流服務
的方法，實現具有高品質、高穩定性的視訊串流
服務的理想。 
總計劃建立了支援 SVC的 P2P視訊串流系統
的模擬環境，並整合各子計畫完成的研究成果。
子計畫一從三個研究議題進行，其中包括資源管
理、行動管理、以及點對點視訊串流。在資源管
理部分，研發了(1)WiFi/Fixed WiMAX 異質網路
下跨網路資源保留機制、(2) WiFi 網路下可適性群
播頻寬配置機制、(3) WiMAX 網路下最佳化群播
資源配置機制。在行動管理部分，研發了
(1)WiFi/Fixed WiMAX 異質網路下跨網路行動管
理機制、(2)多重網址設備之容錯與負載帄衡、
(3)WiFi/Mobile WiMAX/3G 異質網路下行動管理
機制。在點對點視訊串流部分，研發了(1)點對點
隨選視訊系統、(2)點對點可調適視訊串流系統、
(3)基於小世界特性與效應之點對點視訊串流網路
分析、(4)基於自相似圖形之超級點網路建構機制、
(5)點對點可調適視訊串流之同步機制。 
子計畫二提出了 (1)一個新的架構來提升
WiFi 網路下視訊串流服務品質，以及改善 AP 的
頻寬使用效能、 (2) 針對 WiFi 轉傳網路的兩個情
境(RS 可幫/不可幫其他 RS 轉傳)，提出了兩個
Utilization-Based Resource Allocation 演算法，分別
稱為 UBRA 與 UBRA(S)、以及(3) 一個分析計算
方法在 IEEE 802.11e EDCA 無線網路協定下對於
不同類型的存取類別估測其可用頻寬大小。子計
畫 三 提 出 了 (1) 視 訊 串 流 服 務 可 用 於
Polling-based WiMAX 網路的方法，其中包括一個
Polling-based WiMAX 網路的機制，與符合 IEEE 
802.16j 中繼適性線上競爭路由演算法，此演算法
法可依據無線鏈路頻寬、路徑長度與通道情況等
因素選擇出最佳路徑、 (3)以馬可夫鏈 (Markov 
chain)分析在提高網路流量及使用率下輪詢數量，
以降低帄均輪詢延遲、以及(4)一個在車載群播網
路下 Delay-Guarantee chunk Reloading 機制。 
 
關鍵字：異質網路、可調式視訊編碼、WiFi 無線
網路、WiMAX 無線網路、網際網路、點對點傳
輸、情境知覺、視訊串流服務 
 
Abstract 
As TW4G becomes successful, we can expect 
that the next generation network is a ubiquitous 
network consists of various wireless and wired 
networking technologies, such as WiFi, WiMAX, 
3G, FTTH. On the other hand, Scalable Video 
Coding (SVC), proposed by JVT (Joint Video Team), 
is the most promising video codec technology for 
flexible rate and quality adaption in heterogeneous 
networks, including mobile wireless networks and 
the Internet. In this project, we proposed a 
括 ADSL, FTTH, cable modem)連上 Internet。 
我們認為在此異質網路中視訊串流的傳輸，
應該加入應用層、網路層及週遭環境的情境資訊，
才能提昇使用者所看到的視訊的品質。更明確地
說，為了實現具情境知覺之視訊串流服務，我們
認為需解決以下三個重要研究議題: 
(1) 以可調式視訊編碼(Scalable Video Coding)及
視訊調適(Video adaptation)技術來因應多樣
化的網路環境及使用者終端設備。特別是需
要考慮到跨層(cross-layer)設計的必要性，使
得視訊的內容與傳輸的需求可以告知網路層
(及 MAC 層)，而網路傳輸的真實現況也可以
回饋到視訊傳輸層，以動態選擇最佳的視訊
傳輸內容。此外，視訊的傳輸也需考慮一對
一的傳輸與一對多的群播傳輸。 
(2) 在 各 種 網 路 中 ， 以 資 源 管 理 (resource 
management)及排程(scheduling)來保證串流
視訊的傳輸品質。由於各種網路對於頻寬等
資源之管理以及封包傳輸的機制(MAC)各不
相同，故需針對各種網路提出相對應的管理
與排程機制，特別是資源有限的無線網路上。
由於使用可擴充性視訊編碼技術，視訊串流
的每一個封包的重要性(priority)並不一樣，資
源管理與排程應考慮跨層設計 (cross-layer 
design)。 
(3) 需考慮異質網路間的資源管理，包括從 WiFi 
連上 WiMAX 時之封包等級對應(trafficclass 
mapping)、資源管理 (resource management 
such as bandwidth reservation)、精確的換手決
策機制等。 
為了解決上述議題，總計劃建立了支援 SVC
的 P2P 視訊串流系統的模擬環境，並積極協助各
子計畫完成既定研究目標。子計畫一從三個研究
議題進行，其中包括資源管理、行動管理、以及
點對點視訊串流。在資源管理部分，我們研發了
(1)WiFi/Fixed WiMAX 異質網路下跨網路資源保
留機制、(2) WiFi 網路下可適性群播頻寬配置機制、
(3) WiMAX 網路下最佳化群播資源配置機制。在
行動管理部分，我們研發了(1)WiFi/Fixed WiMAX 
異質網路下跨網路行動管理機制、(2)多重網址設
備之容錯與負載帄衡、(3)WiFi/Mobile WiMAX/3G
異質網路下行動管理機制。在點對點視訊串流部
分，我們研發了(1)點對點隨選視訊系統、(2)點對
點可調適視訊串流系統、(3)基於小世界特性與效
應之點對點視訊串流網路分析、(4)基於自相似圖
形之超級點網路建構機制、(5)點對點可調適視訊
串流之同步機制。 
子計畫二提出了 (1)一個新的架構來提升
WiFi 網路下視訊串流服務品質，以及改善 AP 的
頻寬使用效能、 (2) 針對 WiFi 轉傳網路的兩個情
境(RS 可幫/不可幫其他 RS 轉傳)，提出了兩個
Utilization-Based Resource Allocation 演算法，分別
稱為 UBRA 與 UBRA(S)、以及(3) 一個分析計算
方法在 IEEE 802.11e EDCA 無線網路協定下對於
不同類型的存取類別估測其可用頻寬大小。 
子計畫三提出了 (1) 視訊串流服務可用於
Polling-based WiMAX 網路的方法，其中包括一個
Polling-based WiMAX 網路的機制，與符合 IEEE 
802.16j 中繼適性線上競爭路由演算法，此演算法
法可依據無線鏈路頻寬、路徑長度與通道情況等
因素選擇出最佳路徑、 (3)以馬可夫鏈 (Markov 
chain)分析在提高網路流量及使用率下輪詢數量，
以降低帄均輪詢延遲、以及(4)一個在車載群播網
路下 Delay-Guarantee chunk Reloading 機制。 
 
三、 研究目的 
I. 總計劃 
A. 建立支援 SVC編碼技術的 P2P視訊串流機制
的模擬環境。 
B. 整合各子計畫完成的研究成果。 
 
II. 子計畫一：具情境知覺之點對點視訊串流服
務及異質網路之資源與移動管理 
A. 資源管理 
1. WiFi/Fixed WiMAX 異質網路下跨網路資源
保留機制 
本研究目的為設計跨網路資源保留機制，讓
視訊串流服務在異質網路中傳輸時，能夠具備足
夠的資源，達到 End-to-End 服務品質保證。為達
成此一目的，在本研究中規劃下列目標： 
(1) 設計整合異質網路服務品質保證機制的信令
控制機制(control plan)： 
為整合子計畫二 WiFi 網路環境以及子計畫
三 WiMAX 網路環境之中 Quality of Service (QoS)
保證機制，以支援上層 P2P 視訊串流機制，一個
具有彈性的控制信令與信令交換機制是不可或缺
的。我們將使用傳輸層(transport layer)協定來進行
設計，達到上述目標。 
的瀰漫式環境(Ubiquitous Environment)與以人為
中心的應用遠景。在 Mark Weiser 提出的遠景中，
情境感知(content-aware)成為發展以人為中心的
應用的關鍵概念。 
在本研究議題中，討論的異質網路包含了無
線區域網路（WLAN），全球互通微波存取
（WiMAX）網路和第三代行動通訊（3G）三種。
這三種無線網路的傳輸範圍、傳輸速率、存取成
本、安全機制以及服務品質皆不相同。為了保證
使用者在異質網路中換手的服務品質，使用各式
各樣的情境資訊來提供使用者適時適地的智慧型
應用是本研究議題的重點。在本研究中，收集到
的情境感知資訊都被儲存在一個分散式環境管理
伺服器中，簡稱為 U-gate。我們假設用戶的移動
路徑，已經事先利用情境感知路徑規劃機制預先
規劃完成。 
因此，本研究目的是在異質網路下設計具備
情境感知的換手規劃機制，我們預期達到以下目
標： 
(1) 可擴展性，且易於實現在一個分散式的瀰漫式
環境。 
(2) 根據各種情況下，能降低因換手造成的延遲、
並減少訊號以及能源的負載，自動選擇最適當
的目標網路和最適合用戶需求的服務。 
(3) 有能力監測網路連線狀態以保證服務品質。 
 
C. 點對點視訊串流 
1. 點對點隨選視訊系統 
本研究目的在於提出了一個新的點對點隨選
視訊系統。在此系統中，我們將加入了 NUWeb
代理伺服器的支援，提供每個使用者自主性的影
片分享，並協助參與者快速地找到所需的父節點，
提供更有效率傳輸與錯誤回復機制。我們將透過
模擬實驗，證明有代理伺服器支援的點對點架構
比貣無代理伺服器支援的點對點架構，具有更高
的錯誤容忍能力與傳輸效率，以及證明在我們設
計的父節點選擇機制與錯誤回復機制下，能提昇
使用者觀賞的視訊串流服務品質。另外，我們也
探討代理伺服器的負載狀況，避免形成單點錯誤
的狀況。 
 
2. 點對點可調適視訊串流系統 
雖然使用可調性視訊編碼 (Scalable Video 
Coding, SVC)能滿足異質性設備的需求，但透過點
對點傳輸技術來傳輸可調性視訊編碼的視訊串流
面臨了許多的挑戰，像是在 Churn 的情況下，如
何讓每個節點只下載符合設備能力的視訊串流、
如何讓所有節點都先接收基礎畫質的視訊串流，
以及如何動態決定各層級畫質視訊串流的比例，
使得各個節點都能收到最高畫質的視訊串流等。 
因此，本研究目的是針對可調性視訊編碼的
特性，設計一個可調性視訊編碼點對點視訊串流
系統。我們預期將網路編碼來改善傳輸時對實體
網路不穩的抗干擾性，以及減緩 P2P 網路的 Churn
問題的影響。藉由結合 SVC 與 NC 的優點，我們
將設計排程機制，使得點對點視訊串流系統能夠
滿足異質網路使用者不同的需求，以及具備高傳
輸效率、高抗干擾等特性。 
 
3. 基於小世界特性與效應之點對點視訊串流網
路分析 
由於目前點對點視訊串流系統是以網狀拓樸
為主流，因此我們也以網狀拓樸為主要的研究對
象。要形成網狀拓樸，可以由許多種節點選擇的
策略來達成，在不同的策略下所形成的網狀拓樸
會產生怎樣的特性對於建構合適視訊串流傳輸的
點對點網路是一項十分重要的議題。因此，本研
究目的是希望能模擬一個點對點視訊串流系統，
藉由此系統來觀察小世界網路和點對點視訊串流
效能之間的關係與影響。我們將觀察不同的節點
選擇策略，對於整個點對點網路的影響，以及分
析和探討所形成的特性。另外，我們還將觀察在
不同特性下系統對於 churn 的影響與其變化。 
 
4. 基於自相似圖形之超級點網路建構機制 
基於過去 P2P 拓樸與超級點(super node)層的
相關研究，我們發現在結構化 DHT-Based P2P 拓
樸的系統上的查詢是非常有效率的，它不需要將
整個廣播訊息傳送到整個拓樸上，但是這種拓樸
在容忍 churn 的能力就較為薄弱，且查詢的方式
並不彈性與一般化。而在混合式 P2P 拓樸則透過
super node 層來發送查詢訊息廣播至相鄰節點的
方式，查詢訊息可以設計較為一般化，且在容忍
churn 的能力上較強。但是查詢的效能會因為有可
能會產生大量重複的查詢訊息，以及查詢的回應
並沒辦法保證在經過有限數量的節點數內就可以
找到，沒有辦法像結構化拓樸那麼的好。因此，
本研究目的是希望能夠綜合結構化拓樸的快速查
1. Adaptive delay-constraint polling approach 
2. Cost-based WiMAX adaptive routing approach 
 
B. 以馬可夫鏈分析 group polling 機制 
本研究的主要目標是使視訊串流服務能適用
於 Polling-based WiMAX 網路環境。為達到此目
標，我們將完成以下兩項工作: 
1. 以馬可夫鏈(Markov chain)分析在提高網路
流 量 (throughput) 及 使 用 率 下 輪 詢 數 量
(number of polls)。 
2. 推演重要效能數學式，包括: 傳送封包總數
量、被 BS 詢問機率、網路流量、忙碌週期、
網路使用率、與被詢問但未提頻寬需求的詢
問頻寬浪費需求。 
 
C. 在車載群播網路下 Delay-Guarantee chunk 
Reloading 機制 
本研究的主要目標為提出一個方法來保證可
以滿足在車載網路環境下提供即時串流影音服務， 
方 法 為 Delay-Guarantee chunk Reloading 
Algorithm (DGR)，採用從 P2P clustering 來補償
lost chunk 和 unconfirmed chunk。 尤其， DGR
可以決定一個最短的傳送延遲時間來滿足即時串
流封包的限制。 所以由我們提出的 DGR 方法在
車載群播網路下提供即時影音服務並且能滿足
QoS。 
 
四、 文獻探討 
在本章節中，我們將針對總計畫的部分討論
相關研究文獻，而其他子計畫的部分，請詳見各
子計畫的成果報告。 
EvalVid [1]是一個針對視訊傳輸與品質驗證
的模擬架構，它提供了完整的模擬步驟與工具組
來驗證視訊系統在網路上傳輸的品質。除了透過
量測 QoS 參數來分析視訊品質外，EvalVid 也支
援 frame-by-frame PSNR 計算，達到主觀式視訊品
質驗證。此外，EvalVid 具有充分的彈性，讓研究
學者依照需求來變動網路架構與視訊編碼技術。
[2][3] 分別改良 EvalVid 提出 MyEvalVid, 將原先
EvalVid 中的網路環境改由具公信力的 Network 
Simulation 2 (NS2)模擬器[4]與 QualNet 模擬器來
建立，使得視訊品質驗證架構變得更有彈性與更
具公信力。P2PStrmSim[5]是一個 Packet-level 
event-driven 的 P2P 視訊串流模擬器，它提供了模
擬 P2P 視訊串流的基本功能。此外，P2PStrmSim
也支援真實 Internet topology 的網路參數，讓模擬
結果更具可信度。 
 
五、 研究方法 
I. 總計劃 
我們整合 Joint Scalable Video Model(JSVM)
與修改 P2PStrmSim 來建立支援 SVC 的 P2P 視訊
串流機制的模擬環境。JSVM 是一個提供 SVC 功
能的官方標準軟體，它是由 Joint Video Team (JVT) 
與 ITU-T Video Coding Experts Group (VCEG)所
提供。我們的模擬架構如圖 1 所示，重要元件的
說明以下: 
A. Video Encoder (JSVM) 
此元件負責將原始視訊編碼成 SVC 格式的視訊， 
B. Parser (JSVM) 
此元件負責使用 JSVM工具將 SVC格式視訊轉換
成 traffic trace file。 
C. Source Agent (P2PStrmSim) 
此元件負責將 traffic trace file 裡的 SVC 視訊資訊
封裝成 UDP 的封包，並且記錄視訊封包傳送時的
相關資訊，如:封包序號、傳送時間等。 
D. Simulated network (P2PStrmSim) 
此元件負責根據 Internet topology參數與 P2P視訊
串流相關參數建立 P2P 模擬網路。 
E. Peer agent (P2PStrmSim) 
此元件負責模擬 P2P 視訊串流系統的 peer，它包
含 cache buffer 與 playback 來儲存其他 peer 的資
訊與接收到的 SVC 視訊封包。 
 根據我們的模擬架構，我們首先將 Raw video
透過 Video encoder 編碼成 SVC 格式的視訊，再
經由 Parser 轉換成 SVC 視訊的 traffic trace file。
接著修改 P2PStrmSim 來建立 P2P 模擬網路與加
入我們提出的 P2P 視訊串流機制，就可以開始進
行模擬。當模擬結束後，透過模擬網路所記錄的
log，我們可以得到網路傳輸的相關模擬結果。若
需要進一步得到視訊品質的模擬結果，則需透過
Evaluate Trace 階段與 Fix Video 將各個 peer 接收
到的 SVC 視訊封包重建回 SVC 視訊，與原始視
訊比較計算出 PSNR 與 MOS。 
求以決定是否建立一個新的資料流或者重新
設定 TC 的 Persistent Factor。 
 
圖 3: Proposed Protocol stack 
如圖 4 所示，MN 透過 P2P 機制加入 P2P 網
路，並在 P2P GW 上搜尋到所需要的視訊片段，
此時，MN 會向 GW 請求下載視訊片段。GW 接
收到請求後進行 Sender-initiated signaling 程序，
在程序中，GW 會先以 GIST Handshake 建立與 BS
之間的 NSIS 連線，當連線建立後，GW 會發出
NSLP QUERY 信令給 BS 詢問該 BS 管理的範圍
內所剩餘的網路資源是否可以支援這次連線的請
求，當 BS 收到 QUERY 後，會查詢剩餘資源並根
據信令內 MN 的位置資訊找尋最接近的 SS 並將
QUERY 訊息轉送至適當的 SS，而當 SS 收到
QUERY訊息後會進一步找尋MN所在的WiFi AP
並將信令轉送至 MN。MN 收到信令後，此時，
NSIS 連線已經建立完成，GW 與 MN 之間可以使
用這條路徑傳送 NSIS 相關信令。 
當 NSIS 連線建立後，MN 可以透過 AP 送出
Reserve 信令去要求建立具 QoS 保證的連線，當
SS 收到 Reserve 信令後，會轉送至 BS 進行請求，
此時，BS 會將 Reserve 信令轉送至 RMF 進行解
析並將解析結果送至 AC 中進行決策，AC 收到請
求內容後，會查詢整體網路剩餘資源，假設剩餘
資源足夠支援新連線所要求的資源，則 BS 會將進
一步回應 Reserve’信令給 SS 用以告知可以建立
WiFi 端的 QoS 連線，並等待一段 T28 時間。在
Reserve’信令中包含建立該連線所需資訊，例如：
CID，以及WiMAX QoS參數對應至WiFi的參數，
詳細細節將在後續說明。而 SS 收到 Reserve’信
令後，則會另透過 HCC 元件發送原 WiFi 特有的
ADDTS信令去AP去建立WiFi網路的QoS連線，
並等待另一時間 T29。假若在 T29 時間內收到 AP
回應設定完成的信令，SS 會立即回應給 BS 得知
設定完成。此時，BS 會進行建立 BS 與 GW 之間
的 QoS 連線設定，並將連線建立完成信令回傳給
MN，完成全部的 QoS 連線建立機制。 
在這連線建立機制之中，若連線無法在預設
的時間(T28 及 T29)內完成，則 BS 會立即回應給
MN 無法完成連線，並中斷 Transaction，而假若
MN 所請求的資源無法在 WiFi 中順利保留下來，
則 BS 也會主動中斷 Transaction。 
 
圖 4: Message flow 
貳、Signaling Format 
本研究詳細定義 QoS NSLP 所使用的各種
NSLP 訊息格式，包括 QUERY、RESERVE 及
RESPONSE，而相對應的 Message Type 值分別為
1、2 和 3。QUERY 的格式如圖 5 所示，必頇攜帶
QSPEC，且在我們情境中設定 Message Flags 中
RESERVE-INIT (R) bit 為 1 代表由資料收方主動
要求資源保留(即由收方發送 RESERVE 訊息)。此
種訊息主要用來搜集 data path 上的資訊以及建立
RESERVE 訊息返回時的路徑(reverse path)，當 BS
收到 QUERY，會根據 QoS model 所定義，依據網
路情況修改 QSPEC，並夾帶修改過後的 QSPEC
另外發送 QUERY 至 SS，最終 MN 收到 QUERY
後發送 RESERVE 作資源保留。 
 
圖 5: QoS NSLP 格式 
每個 QoS NSLP 訊息皆具有 Message Flags 描
述此類訊息特別持有的屬性。如圖 6 所示，Generic 
Flags 定義了此訊息所使用的 SCOPE (S)；我們使
用預設值0代表所走訪的path是完整的data path，
而不是只走至下一個 hop；PROXY (P)：使用預設
值 0，與 SCOPE 不同的是定義訊息不僅僅是走至
proxy QoS NSIS 節點，而是走訪完整的 path；
ACK-REQ (A)：使用預設值 0，代表不必要求收
到訊息的 NSIS node 回報確認訊息；BREAK (B)：
設定為 0 代表中間的 routers 皆可支援 QoS。 
 圖 10: WiMAX SF 與 WiFi TS 參數的對應 
 
表 1: WiMAX 與 WiFi 服務類別的對應 
802.16 802.11e Example 
UGS AC_VO VoIP without silence suppression 
ertPS AC_VI SVC,MPEG, and VoIP with silence 
suppression rtPS AC_VI 
nrtPS AC_BE FTP 
BE AC_BE FTP 
BE AB_BE HTTP 
 
參、針對 EDCA 之改良機制 
在 IEEE 802.11e draft提出針對提供QoS保證
機制的改良機制，分別是 EDCA 以及 HCCA。而
在 EDCA中，透過新設計的Arbitration Inter-Frame 
Space (AIFS)提供需要更高 QoS 保證服務的存取
類別(access category; AC)可以在更短的時間內取
的媒體的使用權。而在相同的 AC 中則使用 binary 
exponential backoff 機制公帄競爭媒體使用權。
EDCA 雖被提出解決 QoS 難以在傳統無線區域網
路 (WLAN、WiFi)被保證的問題，但卻無法真正
解決原有問題，因為每一個 MN 在某種程度上還
是在使用競爭，假若某一個 MN 其封包的存活時
間(Life time)已即將要結束，但根據 EDCA 機制，
MN 將會有可能無法即時將封包傳送出去，而造
成封包必頇丟棄(Dropping)。 
針對這議題，本研究提出採用 cross-layer 
design 方式透過 NSIS 信令通知 MN 所使用的 TC
應使用的 age 值，稱之為 A cross-layer design 
NSIS-based algorithm for ADB (NADB)，這演算法
是改良 ADB 演算法，並且是類似集中式管理，age
值的給定由 BS 負責，BS 會根據當時網路情況決
定，例如有多少 MN 使用相同 TC 且某一 MN 的
traffic 所需要的延遲時間，邏輯上，除了每個 TC
會有不同的優先權，在同一 TC 內也會細分不同
的子優先權，並期望每個 traffic 都可以分配至一
個子優先權。這麼做的好處是不需要大幅更動
EDCA 機制，且保留競爭功能以讓沒有支援 NSIS
的 MN 可以順利存取媒介。另外，沒有支援 NSIS
的 MN 也不會直接搶到媒介。 
 
2. WiFi 網路下可適性群播頻寬配置機制 
壹、系統架構 
圖11為我們的系統架構圖，包含視訊伺服器、
Access Point 以及行動裝置(Mobile Station , MS)，
行動裝置向視訊伺服器訂閱影片並加入該影片的
multicast 群組，視訊伺服器將視訊串流資料透過
AP 進行 multicast，讓訂閱同一影片的行動裝置來
接收視訊串流資料。 
 
圖 11: 系統架構 
由於每一個行動裝置的播放能力、螢幕大小
以及接收狀況皆不相同，我們把視訊資料透過
SVC 進行編碼，將視訊資料編碼成多個 Layer，
每一個行動裝置可以根據自身需求來訂閱多少
 
圖 12: 二維染色體示意圖 
 產生初始族群：利用隨機的方式產生染色體
並檢查其合法性質，由於視訊資料經過 SVC
編碼，不同 Layer 之間會有相依性，即使 MS
接收到較高 Layer 的資料，如果缺少較低
Layer的資料將會使得教高 Layer的資料無法
進行解碼播放，因此我們會逐一檢視各個基
因的 TXrate 欄位，當有一 layer A 所屬的基
因的 TXrate 欄位為 0 時，我們將高於 layer A
的所有 layer 所屬的基因欄位設為 0。 
 計算適應函數值：當系統中的 MS 接收到視
訊資料且能正確解碼播放，則該 MS 需要付
出相對應的報酬給系統，我們以公式(7)計算
我們的適應函數，根據染色體的基因計算每
一個行動裝置可以正常解碼播放的 Layer 數
量並以此統計系統能收取的報酬總和，當作
該染色體的適應函數值。 
 複製：經由演化流程產生與母代相同數量的
子代之後，保留族群中適應程度較好的染色
體當作下一個母代族群，並從中利用競爭式
方法(Tournament Selection)挑選用來進行下
一次演化流程的染色體。 
 演化：從族群中挑選兩個染色體來進行均勻
交配(Uniform Crossover)，互相交換 TXrate
或是 FEC Code rate 來產生新的個體。基因突
變機率為 1%。 
(2) Reward-Based Maximum Reward Policy 
Iteration (RBMR) 
在 RBMR 演算法中，我們針對不同 Video 尚
未獲得資源分配的 Layer 進行資源分配以及進行
調整，在此我們同樣必頇注意 Layer 相依性所引
發的相關問題，被測詴的 Layer 可藉由獲得的網
路資源來進行調整 TXrate 及 FEC Code Rate，並
計算出該 Layer 在系統資源剩餘資源限制之下所
能獲得的最高報酬以及所需消耗的網路資源。經
過測詴之後我們挑選能獲得最多報酬的 Video 
Layer 進行資源分配，扣除該 Layer 消耗的網路資
源之後再將剩餘的網路資源進行下一輪的測詴，
直到系統剩餘的資源無法獲得更多的報酬或者已
達到系統報酬最大值。圖 13 為 RBMR 演算法的
Pseudo Code。 
 
  
 
圖 14: RBUMR 的 Pseudo Code 
(4) Exhausted Search (ES) 
在 ES 演算法中，我們使用所有的傳輸組合設
定所有的 Video Layer，設定完成後計算系統所能
獲得的報酬，找出擁有最高系統報酬的設定當成
最佳解。為加快運算速度，當有一 Layer 的傳送
速度為0時，我們將不繼續遞迴運算下一個 layer，
藉此消除掉不合理的傳輸設定。圖 15 為 ES 演算
法的 Pseudo Code。 
ri 第 i 位使用者應付給系統的報酬 
P(i , l) 第 i 位使用者接收到完整第 l 層影像的機率 
v(l) 接收到完整第 l 層影像時所該付出的報酬 
PLoss(d , m) 
當 SS 與 BS 的距離為 d 時，使用 m 的 MCS
的封包丟失率 
Prover( l ) 傳送第 l 層影像的冗餘封包比率，l = 0 ~ Ne 
NT( l ) 傳送第 l 層影像的封包總數，l = 0 ~ Ne 
Norig(l) 
傳送第 l層影像的原始封包數 (不含冗餘封
包) 
X 
LT code 解碼器能成功解回時，至少需收到
的封包數量 
C(m) 
當使用 m 為 MCS 時，一個 time slot 可攜的
bits 數 
Nsubchpsl 一個 time slot 中有多少個 subchannels 
Nsypsl 一個 time slot 中有多少個 symbols 
Nbpsym(m) 
當使用 m 為 MCS 時，一個 symbol 可攜的
bits 數 
rPHY(m) WiMAX PHY 所使用的 FEC code rate 
S(l) 
BS 每次群播第 l 層影像的資料量 (單位：
bits) 
Sr(l) 第 l 層影像的 streaming rate (單位：kbps) 
t 一次傳送出去的影片長度 (單位：秒) 
B 該頻道的資源總花費 (單位：time slot) 
Ne 該頻道影片 layer 的總數 (不含 base layer) 
(1) Reward 的計算 
Reward 值代表系統可以收到的報酬，而這些報酬
都是由系統中該頻道的使用者所支付的，如果系
統中使用者的總人數為 N，我們可以將系統的總
報酬表示為: 



N
i
irR
1
, Useri           (7) 
ri 代表各個使用者支付給系統的報酬，我們將其
表示為 
           


Ne
l
i lvliPGr
0
)(*)),((         (8) 
)(1
1
)(
baxe
xG

             (9) 
 
v(l)為第 l 層影片被完整接收時，系統可得到的報
酬，在之後模擬的部分，我們將會對 v(l)這個常數
的設置作一些探討。然而，並不是所有的使用者
都必頇支付報酬給系統，原因是如果使用者能播
放該層影像的機率不大，那要求使用者支付該層
的所有報酬豈不是不合常理。我們以函式 G(x)來
model 使用者的付費方式，其中 x 為使用者收到視
訊封包的機率，G(x)定義於數學式(3)中，藉由調
整 G(x)的 a 與 b 參數，我們可以 model 各種付費
的可能性。利用此方式，將使用者 i 能播放第 l
層影像的機率代入 G(x)中所轉換出來的值，便代
表使用者 i 需要支付多少%的報酬。另一方面，由
於P(i, l) 代表第 i位使用者能使用播放第 l層影像
的機率，因此 P(i , l) 的值會介於 0 與 1 之間。然
而，當第 l 層的影像被完整接收到的機率低於門
檻值 δ 時，我們便認為第 l 層的影像無法被使用
者 i 所使用，那麼之後的 layer 能被使用者 i 使用
的機率便將為 0，我們將其以數學式表示如(10)： 
 





 0)1,(   ,  ),(  
0  ,  1),(0 
liPthenliPif
NelliP

   (10) 
由(7) - (10)，我們將問題描述如下： 
 0)1,(   ,  ),(      
     
0  ,  1),(0     
     
1
1
)(     
..
)(*)),((
)(
1 0






 

liPthenliPif
NelliP
e
xG
ts
lvliPGR
bax
N
i
Ne
l

 
 
 其中，P(i, l) 與錯誤更正碼的技術有很大的
此變好，因此先行扣除 resource 的最大得分 1-β，
使得在這個範圍內所求得的眾多MCS組合之中，
絕對不會遺失掉最佳解。最後，將符合條件的各
組 MCS 一一進行封包冗餘比率的調整，藉此找出
系統的最佳解。然而，此作法計算的時間複雜度
相當高，約為 O(ML + k*hL)，因此無法應用在實際
的系統中。 
(2) 基因演算法 
由於我們調整的變數主要是 MCS 與封包冗餘比
率，因此我們將這兩項變數進行 GA 的編碼，編
碼方式如圖 17，可以看到我們的編碼是以各層影
像為單位，每 10 個 bits 代表一個 layer，前 10 個
bits 為基礎層，再後面的 10 個 bits 為第一個增強
層，依此類推。在本文中，我們採用 QPSK 1/2、
QPSK 3/4、16QAM 1/2、16QAM 3/4、64QAM 1/2、
64QAM2/3 以及 64QAM 3/4 等 7 種 MCS，如果再
加上不傳送該層影像的狀況，便有8種傳送方式，
因此在一個 layer 中。我們用前 3 個 bits 來表示
MCS，當不傳送該層影像時，MCS 的編碼以 000
表示。後面的 7 個 bits 代表封包冗餘比率，當該
層影像不使用噴泉碼進行傳送時，封包冗餘比率
的編碼表示方式為 0000000，最大到 100%。 
 
 
圖 17: 基因演算法編碼方式 
 
(3) Layered Policy Iteration (LPI) 
就如之前所提到的，由於 exhausted search 的做法
雖然可以找到最佳解，但計算時的時間複雜度卻
相當的高；而GA雖然計算所需的時間會少一點，
但是最後得到的只是一個相當靠近最佳解的解，
而不是真正的最佳解。因此，我們提出 Layered 
Policy Iteration (LPI)這個演算法，藉此大幅減少計
算時的時間複雜度，同時也能找出的最佳解，其
演算法如圖 18，其時間複雜度約為 O(M*h*L)，
而圖 19 則為 RRAM 的 pseudo code。 
 
圖 18: LPI 的 pseudo code 
 
圖 19: RRAM 的 pseudo code 
由圖 18 中得知我們的 LPI 其實是一種
iterative algorithm，由於各層影像之間擁有相依性，
因此我們必頇從基礎層開始做資源上的配置，並
且逐漸加入次層的影像，藉此找出所有影像的最
佳資源配置方式。首先，我們先將變數初始化，
將各層影像所使用的 MCS index 都設為傳送速率
最高的 MCS；接著將 Layer 設為 0，表示從 base 
layer 開始做資源配置；而一開始的總資源 Btotal
為 BS 所有的 bandwidth。由於各層影像之間擁有
相依性，我們必頇從 base layer 依序配置貣，因此
我們可以知道每一個頻道已經配置到哪一個影像
層。除此之外，各層影像的傳送基本上是獨立而
互不相關的，因此我們可以將各層影像分層依序
進行資源配置，取得所有各層影像資源配置的最
佳解，便是取得整體影像的最佳解。 
中，我們定義權重 W=(WMB, WRSSI, WOu, WDir)，
且所有參數權重總和為 1。將所定義的權重乘上
正規化後的矩陣，如(23)式所示。 

















NnormDirNnormOuNnormRSSINnormMB
normDirnormOunormRSSInormMB
normDirnormOunormRSSInormMB
normw
)Dirw)Ouw)RSSIw)(MB*w
)Dirw)Ouw)RSSIw)(MB*w
)Dirw)Ouw)RSSIw)(MB*w
AP
(*(*(*
....
....
(*(*(*
(*(*(*
2222
1111
 (23) 
肆、計算正負理想解及距離 
接下來依據理想解類似度順序偏好法操作，
定出各屬性的最佳值及最差值，各屬性的最佳值
(或是最差值)可能會是最大值或是最小值，以 MB
為例之最佳值及最差值如(24)式，再以歐幾里得幾
何距離公式求得每個評估方案離正、負理想解的
距離，由(25)式子可得到每個方案離正、負理想解
分別為 及 。求得每個方案的 pi 值，如(26)式，
取 pi 值最高者為最佳解，在這裡就是指最佳換手
AP。 
   
    },...,2,1|'|)(,|)({
},...,2,1|'|)(,|)({
niJjMBMaxJjMBMinMB
niJjMBMinJjMBMaxMB
inormW
i
inormW
i
Worst
inormW
i
inormW
i
Best



  (24) 
22
22
22
22
))(())((
))(())((
))(())((
))(())((
WorstinormwWorstinormw
WorstinormwWorstinormw
Worsti
BestinormwBestinormw
BestinormwBestinormw
Besti
DirDirOuOu
RSSIRSSIMBMB
S
DirDirOuOu
RSSIRSSIMBMB
S











  (25) 
WorstiBesti
Worsti
i
SS
S
p



          (26) 
以本文應用情境，若使用者在中正大學工學
院一館在行進間使用需高頻寬之視訊串流服務，
所有 AP 情境資訊如表 6 所示。在此情境中，使
用者需要選擇能提供高頻寬及減少換手次數造成
延遲的 AP，而移動間選擇的 AP 若剛好在移動方
向上便可減少換手，因此對於參數權重考量，加
重頻寬及移動方向的權重，權重參數定義為
WMB=0.3, WRSSI=0.2, WOu=0.2, WDir=0.3。將原始資
訊經正規化程序並乘上加權權重之後得到的結果
如表 7 所示，參數權數是先以自行假設，未來的
研究會再加入這部份的數學模型。接下來以歐幾
里得幾何距離公式求得每個評估方案離正、負理
想解的距離如表 8 所示。以 1F-AP1、2F-AP1 及
2F-AP2 三個 AP 來做決策，可以求得 2F-AP2 之
pi 值最高，可知在此範例中 2F-AP2 為最佳解，列
為優先建議換手 AP。 
伍、決策方式 
以本文應用情境為例，我們提出兩種決策方
式，由於在路徑預先規劃好且利用 SCM 模型使得
情境伺服器可預先取得所有空間中 AP 資訊的前
提下，我們提出兩種不同的決策方式，第一種為
隨著使用者移動到有 AP 重疊的區塊及進行單一
AP 決策，如果區塊 AP 重疊的情況很多，則伺服
器必頇重複多次決策。第二種針對移動路徑上所
有可能 AP 換手組合進行決策，將 AP 組合中各
AP 的同一屬性合併成一個值，一組 AP 同樣可以
得到一組屬性值，與單點決策不同的是伺服器只
需計算一次即可，但是如何合併成一個值，如何
重新定義將會影響決策結果。另外關於單點決策
或組合決策之使用時機必頇視情境資訊收集狀況，
若考量的所有情境資訊可以事先收集到情境伺服
器，則利用組合式決策可以減少運算負載及運算
時間。然而若決策用到的情境參數跟使用者所在
區塊有關，必頇等到行動裝置到達所在區塊 AP
旁才有辦法取得，則較適合單點決策方法。 
表 6: AP 情境資訊原始資料 
 
MB(Mb/s) RSSI(dbm) 
Ou 
(人數) Dir 
1F-AP1 54 45 3 7 
1F-AP2 54 55 5 7 
2F-AP1 54 80 3 10 
2F-AP2 11 73 2 10 
 
表 7: 經加權及正規化後 AP 情境資訊 
 
MB(Mb/s) RSSI(dbm) 
Ou 
(人數) Dir 
1F-AP1 0.209965 0.10635066 0.162221 0.149241 
2F-AP1 0.209965 0.125118424 0.097333 0.213201 
2F-AP2 0.042771 0.114170562 0.064889 0.149241 
 
表 8: 正負理想解 
 
MB(Mb/s) RSSI(dbm) 
Ou 
(人數) Dir 
Best 0.209965 0.125118424 0.064889 0.213201 
Worst 0.042771 0.10635066 0.162221 0.149241 
 
2. 多重網址設備之容錯與負載帄衡機制 
壹、Multi-homing based on Mobile IPv6 
(MH-MIPv6) 
HoTI 與 CoTI 時，因為 Step 1.中已確定 Home 
Agent A 已取得 Node A 的新 CoA，所以當
Node B 所送出的 HoTI 與 CoTI 訊息路由至
Home Agent A 時，訊息將不會再遺失，必然
可以順利地完成之後的流程。 
A(2nd)
Domain A2
A(1st)
Domain A1
Home 
Agent A
Home 
Domain A
Home 
Agent B
Home 
Domain B
B(1st)
Domain B1
B(2nd)
Domain B2
IP Data traffic
Home Registration Home Regis
tration
Correspondent Registration
HoTI
CoTI
Correspondent Registration (forward)
Step 1.
Step 2(a).
 
圖 24: Simultaneous failure in MH-MIPv6(a) 
A(2nd)
Domain A2
A(1st)
Domain A1
Home 
Agent A
Home 
Domain A
Home 
Agent B
Home 
Domain B
B(1st)
Domain B1
B(2nd)
Domain B2
IP Data traffic
Home Registration
Home Reg
istration
Correspondent Registration
HoTI
CoTI
Correspondent Registration (lose)
Step 1.
Step 2(b).
Correspo
ndent Re
gistration
Correspo
ndent Re
gistration
(forward)
Step 3.
 
圖 25: Simultaneous failure in MH-MIPv6(b) 
貳、Multihoming based on Network Mobility 
(MH-NEMO) 
 我們可以將多重網路的架構與NEMO的架構
稍作對比(如圖 26 所示)，即可發現一塊小區域的
自治系統(Autonomous System，AS)的邊界路由器
(Edge Router)與 Mobile Router 所扮演的角色極為
相似，以此想法為出發點，我們可以利用 IPv6 
NEMO 的功能以改善 MH-MIPv6 架構中的問題。 
ISP BISP AInternet
Edge Router
Mobile Router
(a)NEMO (b)Multihoming
AS
 
圖 26: NEMO 與 Multihoming 
概念將如圖 27 所示，我們同樣需要 Home 
Agent，而 Edge Router 則需要支援 IPv6 NEMO，
當故障發生時， Edge Router 透過 IPv6 NEMO 的
協助從仍可正常運作的 ISP取得新的 IP位址(如圖
27中的 ISP B)，並將它視為CoA，再向Home Agent
完成 Home Registration 動作，此多重網路中的所
有封包將經由 Edge Router 與 Home Agent 的雙向
隧道建立機制(Bidirectional Tunneling) 由 IP in IP
的方式往返於兩者之間，連線兩端仍然以相同的
IP 位址進行連線，確保傳輸層可以不受影響。 
Edge Router
(Mobile Router)
AS
ISP BISP A
Intetnet
Network with 
multihoming
(1)Use another 
IP address as 
CoA
(2)Tunneling
 
圖 27: Multihoming with NEMO 
詳細流程將如圖 28 所示，我們將此架構稱為
MH-NEMO，並擁有「訊息減量」及「易於擴充」
等優勢。有別於 MH-MIPv6 架構，MH-NEMO 架
構並不會面臨 Simultaneous failure 問題，因為連
線的兩端都僅需要對自己的 Home Agent 完成
Home Registration 即可。 
Router with 
multihoming
Home Agent
Binding Update
Binding Acknowledge
IP-in-IP
 
圖 28: MH-NEMO 流程圖 
 另外還需要考慮到 AS 內的節點為 Mobile 
Node(如圖 29 所示)，形我們假設 Mobile Node 需
要一個提供 Mobility 機制的 Home Agent M，對於
MH-NEMO 中的 Home Agent M 與 Edge Router 而
言，Home Agent M 就如同一般的節點，訊息仍然
可以順利地路由至此，而 Home Agent M 也將確保
訊息可以被路由至 Mobile Node 並繼續連線，無
論是Home Agent M或是Mobile Node都不會查覺
網路錯誤的發生。 
(2) 該封包帶有 MH-flag。 
Start
IPv6 header的
Next Header是否
為Mobility 
Header
Mobility Header
是否帶有
MH-flag
目的地位址屬於
Subnet prefix
攔截此封包，並作出
對應處理
End
Yes Yes Yes
No
No
No
 
圖 32: C-Router 的額外操作 
 在 C-Router 回應此封包後，M-Router 與
C-Router便可以取得對方的 IP 位址(如圖 33所示)，
並在彼此之間建立一個 Tunnel。 
CNC-RouterM-Router
(1)Request
Src: M-Router
Dst: CN
(2-b)Response
Src: C-Router
Dst: M-Router
(2-a)Do not 
forward packet 
to CN
(3) Create Tunnel
 
圖 33: Address of C-Router 
針對安全性的考量，我們採用 Mobile IPv6 所
用的策略的運作流程如下(如圖 34 所示)： 
(1) 移動節點發出兩種 Test Init Message，分別是
以 Home Address 藉由 Home Agent 轉送的
Home Test Init Message，與以 CoA 直接傳遞
至 Correspond Node 的 Care-of Test Init 
Message。 
(2) Correspond Node 在接收到兩種 Test Init 
Message 後，會分別以 Home Address 與 CoA
的不同回應 Home Test Message 以及 Care-of 
Test Message。 
(3) 移動節點在接收到兩種 Test Message 時，表
示 CoA 是可以正常運作的(Routability)；而後
移動節點會發出 Binding Update Message。 
(4) 至 Correspond Node 回應位址更新確認訊息
(Binding Acknowledge Message)後，即完成位
址更新的流程。 
Mobile Node Home Agent Correspond Node
Home Test Init
Care-of Test Init
Home Test
Care-of Test
Binding Update
(MAC, seq#, nonce indices, care-of address)
Binding Acknowledge
  (MAC, seq#, status)  
圖 34: Registration 流程 
 將上述的方式套用至 MH-NEMO 之上，
M-Router同樣以Home Address、CoA發出Test Init 
Message ，Correspond Node 也同樣回以 Test 
Message，藉由Home Agent的介入以確保安全性，
不同 Mobile IPv6 之處在於 Binding Update 
Message 所註冊是 Subnet Prefix，非是單一 IP 位
址。 
 將MH-flag與 Test Init/Test Message的步驟加
入MH-NEMO之中便是我們最後提出的多重網路
架構(MH-NEMO with Route Optimization)，詳細
步驟如下： 
(1) M-Router 取 得 CoA ， 並 完 成 Home 
Registration。 
(2) 節點在不受任何影響下繼續藉由M-Router傳
遞封包，而 M-Router 可以取得 Correspond 
Node 的 IP 位址。此處 M-Router 需要紀錄
Correspond Node 的網路位址前綴(Network 
Prefix)，避免送出重複的要求。我們的想法
是在位置更新訊息表單明細(Binding Update 
List)中新增一個欄位：MH-Binding，並將
MH-Binding 設為「未完成」。 
(3) M-Router 送出目的地為 Correspond Node 且
帶有 MH-flag 的 Home Test Init Message 和
Care-of Test Init Message，兩種 Test Init 
Message 將以不同的來源 IP 位址路由至
C-Router(如圖 35 所示)。 
Src: CoA of M-Router
Dst: Home Agent
Src: M-Router
Dst CN
Src: CoA of M-Router
Dst: CN
CN
Src: CoA of M-Router
Dst: CN
Home Test Init 
with MH-flag
Care-of Test Init 
with MH-flag
Home Agent
M-Router
C-Router
 
圖 35: Test Init with MH-flag 
(4) C-Router 在發現為符合特殊條件的封包之後，
便不再路由至Correspond Node，並作出處理，
其內容與 Mobile IPv6 的 Correspond Node 所
作出動作完全相同，不需任何變動。 
(5) C-Router 以對應的 IP 位址將帶有 MH-flag 的
Home Test Message和Care-of Test Message路
由至 M-Router(如圖 36 所示)，內容主要為提
供 Binding Update Message 中所需要的資
訊。 
  
圖 41:以中正大學校園帄面圖為範例的 SCM 示意
圖 
利用 SCM 定義出地圖資訊之後，利用收集到
的情境資訊以及 SCM 模型所定義的特徵矩陣(如
圖 42 所示)來設計換手規劃機制。SCM 的特徵矩
陣中存放相鄰兩地標間的移動方向、每個區塊上
的地標等資訊。在 SCM 中，利用特徵函數 Co 來
描述其屬性。例如： [α19, α19]放了相關的地標
O3的特徵函數Co(O3)及關於這個 block的特徵函
數 Co(α19)。而 AP、WiMax_BS、3G_BS 的資訊
則以 Co(APi)、 Co(WiMax_BSi) and Co(3G_BSi)
來表示。以α19 為例，在範圍內有兩台 AP、兩
台 WiMax BS 及 3G 網路可以使用，Co(α19)可以
表示成 c1={AP4, AP5, WiMax_BS1, WiMax_BS2, 
3G_BS}。而各個網路的狀態會用以下參數來表示
coverage area (c(1))、  received signal strength 
indicator (c(2)) bandwidth (c(3))、delay (c(4))、
response time (c(5))、jitter (c(6))、loss rate (c(7))、
security (c(8)) and access cost (c(9)) ， 以
WiMax_BS1 的特徵函數為例，Co(WiMax_BS1) = 
{ c1=12, c2=3, c3=30Mbps, c4=30ms, c5=25ms, 
c6=10ms, c7=0.03, c8=1, c9=0}。 
 
圖 42:SCM 特徵矩陣 
在假設移動路徑已經決定的前提下，利用層級分
析法(AHP)及理想解類似度順序偏好法(TOPSIS)
來進行最合適的網路換手規劃。首先以 AHP 訂定
不同情境資訊參數的權重，再以 TOPSIS 作排序
運算決策。 
AHP 的運算流程如下，首先將要解決的問題
建立層級架構，接著建立兩兩成對比較的矩陣，
並計算此矩陣得到特徵向量作為每個層級的權重，
最後整合各層級的權重得到整體的權重。 
壹、建立層級架構 
將要解決的問題建構出階層式的架構，在這
邊是指選擇最合適的換手網路。由於所選用的情
境資訊很多，因此將情境資訊分解到多個階層中。
圖43為本方法選擇合適換手網路的層級架構圖。
各情境資訊的縮寫及量化列在表 9 中。 
 
圖 43:網路換手選擇的階層架構 
表 9:情境資訊縮寫及量化 
  
貳、設置權重 
第二個步驟中，會先建置出每個層級中的成
對比較矩陣。在相同階層中的情境資訊會兩兩和
同階層中的其他情境資訊作比較(如圖 44 所示)，
其評估的準則可見表 10。如 α12 為 3，則表示要
素 1 較要素 2 重要三倍，矩陣的對角線表示要素
與自己本身做比較，因此值皆為 1，而對角線的
Appropriate
network
Availability
Reliability
(Packet Loss)
Timeliness
Bandwidth
Cost
Security
Coverage
Area
RSSI
Delay
Jitter
Response
Time
(32) 
柒、換手決策 
最後的步驟要依據計算出來的結果選擇合適
的換手網路。以(33)式求得各方案的 pi 值， pi 值
表示與最佳解及最差解的關係，pi 值最高的評估
方案表示離最佳解最近並且離最差解最遠，也就
是最佳的換手網路。 
i-Worsti-Best
i-Worst
i
SS
S
p


          (33) 
 
C. 點對點視訊串流 
1. 點對點隨選視訊系統 
壹、協定概觀 (Protocol Overview) 
(1) Peer-to-Proxy Operation 
在 NUWeb 的環境下，使用者可以將欲分享
的影片檔案放置到公開資料夾下。公開檔案後，
這位使用者擁有此影片的訊息，便會藉由公佈
(publish)的動作，傳遞到使用者隸屬的區域性代理
伺服器(regional center)，以下我們稱代理伺服器
(Proxy)。代理伺服器會針對環境下使用者所分享
的每個影片，建立此份影片的串流資料表格(VOD 
table)，此表格將會記錄的資訊為：原始公佈者 IP
位址(original server IP address)、需求者 IP 資訊
(requester IP address)、使用者加入時間(Join time)、
開始片段(start segment)、是否可存取(is locked)、
影片結束時間(expiration time)。 
在預設情形下，代理伺服器的負載不高，即
可用頻寬在預設的門檻(threshold)之下，代理伺服
器會透過拉取(Pull)的方式，向公開影片的使用者
要求影片內容，儲存到代理伺服器；若代理伺服
器可用頻寬高於預設的門檻，則僅對原始影片發
佈者下載的前 n 個區段，以保證至少能提供子節
點最前面 n 個區段，做前綴快取(prefix cache)。系
統中的每個節點會同時由多個父節點接收不同的
區段，已接收的片段也可以傳送給需要的子節點，
每個節點依照播放進度前後關係，形成一個網狀
(mesh-based)架構。 
(2) Proxy-to-Proxy Operation 
在 代 理 伺 服 器 之 間 ， 我 們 採 用 DHT 
(Distributed Hash Table)來定位哪些代理伺服器該
記錄哪些檔案，影片名稱可以根據赫序函式產生
一個 ID，此 ID 與代理伺服器的 ID 為同一個
naming space 依照這個 ID 與代理伺服器 ID 的相
近程度，決定最接近的代理伺服器來存放這個值，
影片資訊即會傳送到負責代理伺服器的索引表格
中，由於代理伺服器是屬於較穩定的節點，因此
可以有效率之搜尋。 
需要進行影音串流的使用者，首先會先詢問
其隸屬的代理伺服器是否擁有此檔，若本地代理
伺服器擁有檔案，表示同一檔案環境中已有其他
人曾發佈了，即進行單一代理伺服器下的點對點
片段傳輸；若本地代理伺服器無此檔案，則會將
此影片檔名進行赫序運算得出 ID 值，並得知索引
伺服器的位址，向索引伺服器詢問有哪些代理伺
服器能提供這份影片檔。熱門的影片將不會只存
在單一伺服器中，每一台代理伺服器的儲存空間
若太少，也會運行取代機制(replacement policy)，
自行統計各個影片的存取次數，依照影片的熱門
程度區分，被存取次數越少的優先被取代。 
貳、運作流程 (Operation Procedures) 
(1) Client Buffer 
在本系統中，我們把每部影片分割成許多區
段(segments)，每個區段我們又將之分割為 P 個片
段(pieces)，並以片段作為每次傳輸的最小單位。
正在觀看影片的使用者，需要維持一段先進先出
的緩衝區(FIFO Buffer) ，如圖 45 所示。 
 
圖 45: 使用者緩衝區(Client Buffer)示意圖 
目前正在播放的區段標號我們定義為 CPS 
(Current Playback Segment)，以 CPS 將緩衝區分成
兩個部分：CPS 之前一段最近播過的區段，稱為
Cache Buffer，其大小為 CBS(Cache Buffer Size)；
CPS 後面的區段為目前正在抓取的區段，以滑動
視窗(sliding window)的形式進行區段的下載。假
設 W 為目前已抓取的區段長度，Wmax 為可抓取區
段的最大限制，目前快取在緩衝區的片段範圍為
( 1, )S CPS CBS CPS W    ，因此，當有節點所
需求的片段介於此一範圍，表示本節點有能力當
需求節點的父節點。 
(2) Bootstrap 
NUWeb 的區域性代理伺服器提供影音分享
失效，或是接收到父節點主動通知失效，則必頇
從 PCList 中取得下一個父節點。每個節點會透過
流言傳播(gossip)的方式定期與 PCList 內的節點
交換訊息，以便得知 PCList 中節點目前的播放進
度、可用頻寬與服務區間，定期重算灰關聯分數，
並移除無效的節點。 
 
2. 點對點可調適視訊串流系統 
節點的系統架構如圖 46 所示，主要有三大模
組: (1) Membership Manager 負責管理其他節點的
資訊；(2)Scheduler 負責排程 SVC 視訊串流的傳
輸；(3)Network Coding Encoder/Decoder 負責編碼
傳輸前的 SVC 視訊串流以及解碼接收到的 SVC
視訊串流。當一個節點加入系統時，會先跟
Boot-strap node 要求一份隨機產生的節點清單。根
據節點清單，新加入的節點與其他節點開始定期
性地交換 Buffer map，接收到的 Buffer map 會儲
存在Cache裡。藉由儲存在Cache裡的Buffer map，
新加入節點開始以 Pull-based 的方式向其他節點
要求視訊串流，接收到視訊串流會先經過 NC 解
碼後儲存在 Buffer 裡。最後播放器會將 Buffer 裡
的視訊串流解碼後播放給使用者觀看。 
 
圖 46: Node 的系統架構圖 
壹、SVC-NC  
為了讓SVC視訊串流除了能滿足異質性設備的需
求，還可以具備高傳輸效率、抗干擾等特性，我
們提出了一個新的 NC 方法，SVC-NC。如圖 47
所示，我們根據SVC視訊串流中解碼的時間關係，
將每個 Group Of Picture(GOP)區分為數個 Layer。
每個 Layer 的 Frames(包含 Spatial 與 Quality 維度)
分別使用 Randomized Network Coding 編碼成相
對應的 Code word。因此在整個系統中的 Code 
word 會依據 SVC 的 Layer 分為數種，如圖 47 中
一個 GOP 有四個 Layer，那整個系統中就會有四
種的 Codeword。 
 
圖 47: SVC-NC 編碼示意圖 
根據 SVC-NC 的設計，節點上 Buffer 的設計如圖
48 所示。Current Play Location(CPL)為目前播放的
時間點，在 CPL 位置前我們保留了一段已觀看過
的視訊資料，提供給其他節點下載。此外，我們
使用 Sliding window 來做為排程的範圍限制，每
下載完一個 GOP 或是當 CPL到達 Sliding window
的貣始點，Sliding window就會向後滑一個GOP。
一個 GOP 對應到 n 個 Segments，一個 Segment
對應到一個 SVC-NC 的 Layer，一個 Block 對應到
一個 SVC-NC 的 Layer 的 Codeword。在播放時，
一個 GOP 中，Base layer (Layer 0) 的 Codeword
必需要能被成功的解碼還原才能順利的播放，而
更多 Layer 的 Codeword 被解回來時，就可以結合
Base layer 的資料產生品質更好的視訊，反之若
Base layer 的資料無法被解回來時，就算其他非
Base layer 的資料能夠還原也是沒辦法獨自播
放。 
 
圖 48: Node 的 Buffer 示意圖 
在Buffer map的表示是以一個GOP為基準。
一個 GOP 裡的每個 Layer 會使用 1 bit 來表示。以
4 個 layer 舉例來說，一個 GOP 的 Buffer map 為 4
個 bit。根據相關研究指出當 Code word 的數量小
於 66%時，傳輸效能是不好的。所以在本系統的
Buffer map 中，當一個 layer 的 code word 數量小
於 66%時為 0，還不足以提供其他節點這個 layer
的資料；當大於 66%時為 1，表示可以開始接受
別人的傳輸要求。 
貳、Scheduling Mechanisms 
(1) Startup Request Scheduling 
Initial buffer delay 是使用者選擇頻道後至使
用者收看到視訊的延遲時間。較長的 Initial buffer 
delay 會降低使用者的滿意度，因此為了減少
Initial buffer delay，我們透過 SVC 只需要擁有
構，此系統中觀察單一視訊串流頻道，其中有包
含了一個視訊來源(video source)和一個 bootstrap
節點，主要用來取得其他節點資訊，影片串流的
大小為 384kbps，我們還假設有 buffer map 的初始
時間，如果剛加入此網路的節點，還在初始時間，
就不能傳遞串流片段給其他節點，也就是說不能
被選為父節點，能接多少子節點會受限於各個節
點的上傳能力，上傳頻寬高的節點可以提供數個
節點完整的影片串流，上傳頻寬低的則連 384kbps
都不到。由圖 51 我們可以清楚的看見整體的網路
環境，當一個新的節點進入頻道中會基本上會做
出 3 個動作。(1)跟 Bootstrap 要求此頻道中的其他
節點資訊；(2)回傳適合的節點清單給新進入的節
點；(3)跟頻道中的其他節點做連線。 
 
圖 51: 模擬網路環境 
(1) 節點能力 
根據[7]的研究，對於 Microsoft 的 MSN video 
service 連續九個月的觀察，作者展示出此期間使
用者的頻寬分佈情形，有絕大部份的人是寬頻用
戶，約有 37%的使用者可以提供一個節點以上的
完整視訊串流，另外會有約 7%的人下載頻寬不足，
無法接收到完整的視訊串流，詳細的數據如表 12，
我們將網路的節點分為這七種種類，其中視訊串
流伺服器(source node)因不需下載，所以未定義，
此節點也是唯一。從上傳頻寬來看，只有 Ethernet
的使用者和 Source 才有能力提供超過二個完整的
視訊串流頻寬，我們把這二類的節點看作是高能
力節點，其他的 Cable、DSL2、DSL1、ISDN 和
Modem 這種只能提供二個或以下的串流頻寬，都
是屬於低能力節點。 
 
 
 
 
 
表 12:各種類節點的上/下傳頻寬與分配比重一覽
表 
 
貳、節點選擇 
 在節點加入系統時會跟 bootstrap 要求其他伙
伴(partner)的資訊，bootstrap 會依照不用的策略來
傳回一份清單，節點選擇的策略包含了隨機選擇 
(random)、最小延遲與穩定度選擇  (minimum 
delay – stable)、能力選擇 (capacity)、能力與穩
定度選擇 (capacity – stable)，將以上四種做為
節點選擇的方法，以下介紹各種節點選擇的差
異。 
(1) 隨機 
在這個選擇策略裡面，新加入的使用者跟
bootstrap 做查詢之後，得到一份清單(list)，此清
單裡面包含的節點是採用隨機的方法產生，就是
隨機選擇現有網路裡面的 k 個節點，這個方法是
最簡單也是最沒有結構性的方法，在一個 n 個節
點的網路裡面，每一個節點被選到機率皆為 1/n。 
(2) 最小延遲與穩定度 
穩定度的高低是考量使用者停留在網路裡時間長
短而定，而使用者停留時間我們稱之為 session 
time，此時間的分佈是依據[8]的觀察而假設為
Pareto 分佈，因為停留時間為 Pareto 分佈，所以
在節點選擇時，已經存在系統中的使用者停留時
間愈長，我們也預期他之後呆在系統中的時間也
愈長，使用者存在網路中愈久，則穩定度愈高。
在此種策略會先考慮現有網路裡面的節點跟新加
入的使用者的延遲狀況，先選出 k 個有最小延遲
的節點，然後再選擇穩定度高的，當一個網路裡
面的節點數很多時，我們知道選擇較低延遲時間
的節點可以降低來源端與末端(leaf)節點之間畫面
延遲的差距，而穩定度較高的節點通常也較不容
易離開，在此種方式裡面，因為有加入穩定度的
考量，所以我們知道新加入的節點會較容易選擇
到離來源端比較近的節點，因為那類的節點穩定
度較高，另一方面來說，較不會選到新加入的節
點，若我們以七種的節點分類來看，並不會偏向
 圖 53: Peer 加入 SNG4x4 位置的順序 
(2) 管理點 
以(1,1)的點當成 bootstrap server 的備份點，
該點會儲存整個 SNG 的資訊，當 SNG 內部有任
何變動時，除了 bootstrap server 會被知會，管理
點同樣也會得知這些資訊。 
(3) 虛擬點 
我們希望這個拓樸永選是填滿的 SNG 的狀
態以維持強韌性及傳送的有效性，所以我們會在
尚未補滿的 SNG 內的點或者點突然離開的狀態
以虛擬點表示，虛擬點會由管理點在相同水帄方
向且與虛擬點垂直的實際存在的點所扮演，如圖
54 所示，點(1,2)同時會扮演(4,2)虛擬點的角色，
而(1,4)則必頇同時扮演(2,4)、(3,4)、(4,4)的虛擬點
角色。而當有點離開時該點也會以虛擬點暫時存
在，等待其他點來遞補這個位置。而萬一當(1,X)
離開的時候我們希望能由(1,1)來暫時充當虛擬點。
然而當(1,1)節點失效時，因為該 SNG 已經失去管
理點則不會使用虛擬點，所以會從順序最低的點
來做遞補的動作，bootstrap server 會通知順序最低
的點以取代管理點(1,1)的角色。 
 
圖 54: SNG4x4 只填入 10 個點，其他點則為虛擬
點 
(4) SNG 視野 
我們希望在一個 SNG 內部的點彼此都能夠
知道整個 SNG 的點的資訊，我們稱為內部 SNG
視野(Intra-SNG View)，以便在有點突然失效的時
候，能夠馬上由 SNG 內部順序低的點來遞補，這
時候如果遞補的點有預遞補點的鄰居的資訊則可
以馬上建立貣連線，為了能保有 SNG View，在點
一開始加入這個 SNG 後會發送一個 JOIN_HELO
訊息，向 SNG 所有點的點通知有新的點加入，所
以 SNG 內的點就在可以在 SNG View 內將新的點
的資訊加上去，而收到訊息的點，也會同時回覆
JOIN_HELO_REPLY 訊息，以便讓新加入的點也
知道整個 SNG View。另外 Bootstrap 伺服器也會
有這個 SNG View。  
(5) 拓樸的維持 
管 理 點 (1,1) 會 定 時 透 過 發 送 一 個
HELO_HEARTBEAT 的查詢訊息來確認所有的點
是 否 還 存 活 ， 如 圖 55 所 示 ， 當 要 將
HELO_HEARTBEAT 訊息轉送的點(4,2)已經不存
在時，發送的點(1,2)會將不存在的那個位置直接
回報給 Bootstrap 伺服器，這時候伺服器會從 SNG
順序表內取出順序最低值的點(4,4)來取代不存在
的點，Bootstrap 伺服器會發送一個 REPLCAE(4,2)
的訊息給(4,4) 並將相鄰點的資訊傳送給(4,4)，則
點(4,4)將會取代(4,2)的位置。 
 
圖 55: 4x4 SNG 中發送 HELO 查詢的路徑 
貳、SNG 查詢機制 
因為 SNG 的點在水帄及垂直方向為
full-connected 的特性，所以可以使查詢訊息最少
在兩個 hop 內將查詢傳送到所有 SNG 的點上，我
們 稱 這 種 在 SNG 內 部 的 查 詢 訊 息 為
SNG_QUERY，方法為由預發送查詢的點往水帄
方向及垂直方向所有的點發送查詢訊息(這些點
我們稱為 DIRECT_HOP_PEER)，此為第一個 hop
內可以傳送到的部份，這類訊息我們歸類為直接
查詢訊息(DIRECT_QUERY)，而水帄方向接到的
點再往其垂直方向的點 ( 這些點我們稱為
FORWARD_HOP_PEERS)傳送，這部份為第二個
hop 的部份這類訊息我們歸類為間接轉送查詢訊
息(FORWARD_QUERY)。如圖 56 中的點(2,2)有
查詢訊息要發送，第一步會先將訊息傳送給(2,1), 
 圖 59: 兩層的 SNG3x3 組成的 SSNG 
(1) 座標系統 
在 SSNG 的座標系統中，我們需要由最上層
的 SNG 來開始定位每個點，如圖 59 中，第二層
中 L2 (3,1) SNG 中最左下角的點，我們定義成
L1(3,1), L2(3,3)，意即這個點是位於 L1 SNG 的點
(3,1) 所衍生出來的 SNG 中的(3,3)的位置，另外
一個例子為圖 59 說明指標指的點 L1(2,2)，L2(1,3)，
則是代表由 L1 的 SNG 中的點(2,2)所以發展出來
第二層的 SNG 其中的點(1,3)，這個座標表示法為
前面多項的(x,y) 的部份為指名由哪層 SNG 的點
衍生的 SNG，而最後一個座標表示該 SNG 的點，
因此 L1(1,2), L2(3,4), L3(4,5)代表的點為，由第一
層(1,2)衍生得第二層 SNG 中的點(3,4)，再由第二
層點(3,4)衍生出的第三層 SNG 中的點(4,5) 即為
點「L1(1,2),L2(3.4),L3(4,5)」。 
(2) Inter-SNG View 
前面提到我們可以將第二層的每個 SNG 視
為單一的點，亦即這些單一點也架構出一個 SNG，
我們稱這些點之間為 Inter SNG，以這個觀點來看
我們希望這些點之間也是同樣有 SNG 的連線特
性，也就是說第二層以上的點除了會維持一個內
部 SNG 的視野(Intra-SNG View)，也會維持一個外
部 SNG 視野(Inter-SNG VIEW)，當然如果有第三
層以上的話，該點也要維持一個下一層的 SNG 視
野(DOWN Layer SNG View) 。第二層 Inter SNG
的連線關係如圖 60 與圖 61。圖 60 中 L1(1,1)的點
擁 有 四 條 INTRA_DIRECT_HOP 及 一 條
DOWN_LAYER_HOP，而點 L1(1,1), L2(1,1)則擁
有 四 條 INTRA_DIRECT_HOP 及 四 條
INTER_DIRECT_HOP及一條UP_LAYER_HOP。
圖61則是另一個由點L1(2,2),L2(2,2)來看的圖例。
我們可以看出這樣的意義即為由各個管理點位於
Inter SNG 內的相對位置來架構出 Inter SNG 間的
連線。 
 
圖 60: L1,L2 SSNG 中由點 L1(1,1),L2(1,1)來看的
連線示意圖 
 
圖 61: L1,L2 SSNG 中由 L1(2,2),L2(2,2)來看的連
線示意圖 
(3) Down Layer SNG 
之前提到 Bootstrap 伺服器會有整個 SNG 
View，同樣的 L1 SNG 中身為每個 L2 SNG 的
INIT_PEER 也會有管理各自 Down Layer 的 SNG 
View，而每當有 Peer 加入 Down Layer 時會根據
SNG 的加入順序方法來填入 SNG 內，因此
INIT_PEER 可以知道目前 DOWN Layer 的 SNG
的大小狀況，同時會將這個大小的資訊傳給 UP 
UP_LAYER_QUERY及DOWN_LAYER _QUERY。
在收到 DOWN_LAYER_ QUERY 的該層 SSNG
的會轉為 INTER_SNG_QUERY 並同時在每個有
下 層 SSNG 的 點 再 度 觸 發 DOWN 
_LAYER_QUERY 以便往更下層 SSNG 傳播，而
收到 UP_LAYER_QUERY 的點則比較不同，除了
馬上產生一個UP_LAYER_QUERY除了收到的點
的 SNG 不會額外產生 DOWN_LAYER_QUERY
外會在該層 SSNG 產生 INTER_SNG_QUERY 並
同時產生 DOWN_LAYER_QUERY，以便訊息在
向上傳送時會往下傳送。 
 
圖 64:各種 QUERY 訊息 
伍、SSNG 的 Fail Recovery 機制 
 在 SSNG 中第一層的一個點會衍生出第二層
的 SNG，這個點是作為往下層溝通的管道，也是
第二層 SNG 中的 INIT_PEER(類似 SNG 中
Bootstrap 伺服器的作用)，萬一當這個點失效的時
候，影響的情況可想而之將是該點之下所管理的
SNG 內的點，為了避免這個點失效造成的嚴重影
響，我們會在 SNG 管理點中也紀錄 INIT_PEER
的鄰居的資訊，當 INIT_PEER 失效時，管理點因
為會定時發送 HELO_HEARTBEAT 訊息，所以會
馬上知道 INIT_PEER 失效，我們可以馬上從自身
SNG 中尋找加入順序最低的點，將之提昇為
INIT_PEER 也就是上層的 SNG 內的一個點。 
 
5. 點對點可調適視訊串流之同步機制 
壹、系統簡介 (Protocol Overview) 
(1) Client and Server Buffer 
如圖 65 所示，Client Buffer 由多個 Group of 
Picture(GoP)組合而成，每一個 GoP 依時序都會被
指定一個序號且被編碼成多層的格式，在圖 74 中
的 layer 數即為 5 層，第一層即為 base layer，每
一個 GoP 如有 base layer 即可播放最低品質的影
片，當一個 GoP 擁有愈多 layer 的影片，結合低
layer 後影像品質將會愈清晰。但如果只有高 layer
的影片卻缺乏低 layer 的影像資料，仍然無法將影
片成功解回。 
在 Buffer 裡由 Sliding Window 來當作為影片
要求的區間，Sliding Window 會隨著影片抓取完
畢或隨著播放時間而向右移動。在 Buffer 中，我
們定義了 Current Play Point(CPP)來代表目前系統
正在播放的點，在系統中的每一個點為了要達到
同步，每一個使用者的 CPP 應該都需要指向同一
序號的影片片段，在以下的章節中，我們將會介
紹如何計算目前系統正在播放的 CPP。 
 
圖 65: Clinet Buffer 示意圖 
如圖 66 所示，串流伺服器同樣有 CPP 指向
系統目前所播放的影片序號。伺服器在抓取到影
片資訊後，會先 cache 在 Buffer 中一段時間，作
為系統內的尚未播放的未來影片，即系統播放影
片的時間點 CPP 會較影片實際產生的時間還慢。
如圖中，串流伺服器的 Buffer 中存有系統中尚未
播出的片段，最大的 GoP 的影片序號為 N_max，
而 Buffer 的大小也較一般的節點要大，使得新節
點加入後可以根據頻寬限制來抓取適合的影片資
料。 
 
圖 66: Server Buffer 示意圖 
(2) Buffer Map 
我們的系統使用了 SVC 作為影片的格式，每
一個 GoP 將被編碼為多層的影片，我們利用 0、
1 的方式來表示每一層的資料是否存在，如下圖
11 中一個 GoP 一共被編碼為 5 層，由圖 67 我們
可以發現這一個 GoP 只有 layer 1、2 與 3 有完整
收到，而 4、5 兩層並未收到影像資料，因此這一
個 GoP 在 Buffer Map 中我們將會表示成
 可用剩餘頻寬(Available Bandwidth)：我們在
選擇節點時，同時希望選擇到擁有較大上傳
頻寬的父節點，以期達到較好的下載效率，
此值也應愈大愈好。可用剩餘頻寬的計算如
下：父節點的上傳頻寬為 BWupload ，在
pull-push 的環境中共有 K 個人向此父節點訂
閱子視訊串流，又令每一個子視訊串流的 bit 
rate 為 N bits/sec，則 BWavailable = BWupload – 
K*N。  
由於有以上三種變因，我們利用灰色理論來計算
出每一個父節點的綜合分數，分數愈高者，即為
較優良的父節點，也作為我們選擇傳輸影片的優
先選擇，由於每一種變因的單位皆不相同，以下
我們介紹灰階理論如何計算出每一個父節點的分
數。 
(3) 同步時間計算 
在這個章節我們希望每一個節點加入系統之
後，能夠在最短的時間之內，向鄰居要求 Sliding 
window 大小的影片，而為了能夠縮短影片貣始等
待時間，我們讓節點開始時，只抓取影片 base layer
的部份。在同步的系統中，每一個序號的影片都
有其播放的時間，如何找到一個最小的貣始序號，
使得在播放時能滿足 Sliding window 裡皆有 base 
layer 可以連續播放即是我們要解決的問題。在此
我們定義了一些變數如表 13，我們將會介紹如何
利用已知的變數使用這些變數來計算最短的下載
時間。 
表 13: 符號表 
symbol Description 
K 串流伺服器的 Buffer 大小 
S Client Buffer 的 sliding window 大小 
𝑇𝑔𝑜𝑝 一個 GoP 的時間長度 
𝑇𝑠𝑡𝑎𝑟𝑡  系統開始播放影片的貣始時間 
V 節點的鄰居集合 
𝐵𝑗,𝑖 鄰居 j 到 node i 的可用頻寬 
𝑇𝐷𝐿 節點下載 Sliding window 大小 base layer 的時間 
𝑇𝑐𝑢𝑟  節點計算下載時間的時間點 
𝑇𝑛 序號 n 播放的時間 
L 影片的 layer 數 
𝑁𝑚𝑎𝑥  串流伺服器 Buffer 中最大的 GoP 序號 
𝐵𝐷𝐿  節點的下載頻寬 
𝐵𝑈𝐿 節點的上傳頻寬 
Dev. 計算𝑇𝐷𝐿時所使用到的誤差值 
(4) 最短下載時間計算 
我們令所找到的最小影片序號為 n，其在系統的
播放時間為𝑇𝑛，目前系統的時間為𝑇𝑐𝑢𝑟，我們定義
由現在到序號 n 影片的播放時間差為∆t： 
    ∆𝑡 = 𝑇𝑛 − 𝑇𝑐𝑢𝑟          (35) 
其中𝑇𝑛可由加入系統時，BootStrap Node 所提供的
S-packet 裡的資訊算出。 
              𝑇𝑛 = 𝑇𝑠𝑡𝑎𝑟𝑡 + 𝑛 ∗ 𝑇𝑔𝑜𝑝      (36) 
我們設定下載 Sliding Window裡的 base layer共需
要花費𝑇𝐷𝐿的時間。𝑇𝐷𝐿的時間必頇小於∆t，即
𝑇𝐷𝐿 < ∆𝑡，使得一經過𝑇𝐷𝐿的時間後，可以開始播
放序號 n 的影片片段。我們利用以下的演算法根
據鄰居的上傳頻寬來算出𝑇𝐷𝐿的時間為何，如圖 70。 
float Download_time_counting(sequence n)
{
int total_DL_size[NBR_CNT];
float DL_time[NBR_CNT];
float smallest_DL_time = -1, max_DL_time = 0;
int nbr_index;
for each base layer in sliding window from seq n to n+S-1
{
for each neighbor, we pre-calculate each download time of neighbor j
{
if(neighbor j has base layer n)
DL_time[j] = (float)(total_DL_size[j]+Dbase_n) / Bj,i;
}
// we find the nbr_id from NBR_List who has smallest DL_time
for(int i = 0 ; i < NBR_CNT ; i++ )
{
if( smallest_DL_time == -1)
smallest_DL_time = DL_time[i];
else if( smallest_DL_time > DL_time[i])
{
smallest_DL_time = DL_time[i];
nbr_index = i;
}
}
smallest_DL_time = -1;
total_DL_size[nbr_index] += Dbase_n; 
}
for each neighbor j
{
if( max_DL_time < (total_DL_size[i] / Bj,i) )
max_DL_time = (float) total_DL_size[i]/Bj,i;
}
return max_DL_time;
}
圖 70: 計算下載時間演算法 
由以上演算法，我們可以根據鄰居的上傳頻
寬來計算出由影片序號 n 為貣始點，下載 sliding 
window 裡 base layer 的時間。但節點仍需考慮節
點自身的最大下載頻寬，故我們再次修改𝑇𝐷𝐿如下 
𝑇𝐷𝐿 = max⁡(
𝐷𝑡𝑜𝑡𝑎𝑙
𝐵𝐷𝐿
, max⁡_DL_time) + 𝐷𝑒𝑣.    (37) 
 Request Response Schedule 
節點在系統中除了會收到影片資料之外，同時也
會收到別人對影片的要求，其中包含了節點貣始
的影片要求(Start-up Request, SR)、一般的影片要
求(Normal Request, NR)兩種，若有其它鄰居對節
點訂閱子視訊串流，此節點仍需自動 push 子視訊
串流影片(Push Packet, PP)給訂閱者，這個節點便
會有三種型態的影片資料需要傳送。因此我們設
計了影片傳送端的 scheduling，對於三種型態的影
片資料來做排程，以滿足不同的影片需求。 
 可調性視訊編碼需要有低 layer 影片才能解
回高 layer 的影片，所以我們將優先傳送所有
base layer 的影片，接著才依次傳送更高 layer
的影片資料。 
 同時有 SR、NR 和 PP 的 packet 同時需要傳
送的時候，我們優先處理 SR 的影片請求，使
得每一個使用者在加進系統後，能以更準確
的時間開始同步播放影片。而也因為每一個
影片序都都有其在系統的播放時間，所以 NR、
PP 的影片請求將以在系統播放的時間順序
(Earliest Deadline First，EDF)回應。 
 在回應每一個影片請求的時候，我們利用節
點之間的延遲時間來計算每一個影片在傳送
之後是否能及時播放，若影片播放的時間小
於接收端收到影片的時間，即使影片能夠順
利傳送出去，但是收到影片的鄰居卻會因系
統播放時間已過，仍不會播放此影片，而造
成冗餘資料，故應該將之遺棄(discard)。故我
們在傳送前會做計算來決定影片是否要傳送
出去。 
 
III. 子計畫二: 802.11 無線區域網路中具情境知
覺之視訊串流服務 
A. WiFi 網路下提升 P2P 視訊串流服務品質的
架構 
我們首先使用 Wireshark 去抓取網路電視軟
體的封包來研究 P2P 視訊串流服務的訊息交換流
程。網路電視軟體是採用 ppstream 為範例，也因
此我們的架構設計主要是適用於 ppstream。之後
將延伸到子計畫一所設計出來的 P2P SVC video 
streaming 系統。圖 74 是 ppstream 在初始化時所
進行的訊號溝通。圖 74a 中，在經過與頻道伺服
器三向握手(three way handshake)之後，如(1)，膝
上型電腦 (laptop)會向頻道伺服器去要求頻道
(request channel)(2)，它會以 TCP 的方式連線至對
方的連結埠 80，封包中會帶有 GET 的指令，指令
中會帶有要求的頻道代號，在 TCP 版本中代碼長
度為 32 bytes 的英文字母。接下來，膝上型電腦
會向追蹤伺服器(tracker server)要求目前有在觀看
此頻道的 peers(3)，tracker server的連接埠為 8000，
peer 的列表則是經由 ICQ 訊息傳輸。當 tracker 
server 收到之後，它就會回傳 peer 的列表，此列
表會從 server 的連接埠 8000 送出，並且也是經由
ICQ 訊息傳遞。最後，在圖 74b 中，當膝上型電
腦收到 peer 列表之後，膝上型電腦就會開始與
peer 列表中的每一個 peer 嘗詴進行連線，並且開
始用 TCP 的連線方式來進行影音的傳輸(4)。 
 
(a) Handshake and request 
 
(b) Communication with peers 
圖 74: ppstream 訊息交換流程 
針對上述 ppstream 運作方式，我們的方法可
分成兩個部份來描述，一個部份是 AP 的部份，
也就是 AP 所要進行的所有動作，另一個部份則
是以使用者所要進行的動作。首先，圖 75 是 AP
的狀態圖，它表達的情況很簡單，當一台 AP 開
機之後會進行初始化，開機完進入閒置狀態。這
時 AP 在等待有無任何的使用者或者是外在的
peer 希望進行連線，如果有使用者或 peer 要進行
在 描 述 utilization-based resource 
allocation(UBRA)演算法之前，我們必頇先定義如
何計算各個 RS 服務到每個 SS 的資源利用率為多
少。在我們的問題中，我們假設網路中有 N-1 個
RS、M-1 個 SS、和一個 BS。於是我們把 BS 當
成第 0 號的 RS 和第 0 號的 SS，之後再依序編號
RS 和 SS。於是，我們對於 RSn 服務到 SSm的資
源利用率的計算方法為： 
utility[n,m] =
(∑ U((∏ Fe(n,n2,m,m1)
N
n2≔0 )=0)
M
m1:=1 ∗SA[m1])
Fd(Res[n,m],n)+∑ Fd(SP[n,n1],n)
N
n1:=0
      (39) 
Fd(cost, n) = {
cost − RA[n]⁡, if⁡cost > RA[n]
0⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡⁡, if⁡cost ≤ RA[n]
        (40) 
Fe(n, n1, m,m1) = {
U(Res[n,m] > 𝑅𝑒𝑠[𝑛,m1])⁡, if⁡n = n1
U(Res[n1, m1] > 𝑆𝑃[n, n1])⁡, if⁡n ≠ n1
(41) 
U(input) {
1,如果 input為真或 1
0,如果 input為假或 0
                (42) 
 
資源利用率(Formula (39))的計算原理為： 
 utility[n,m] =
在服務到SSn時同時可以服務到的 SS數量
服務到SSn時花費的資源總合
 
首先，在分母部份中的Fd(Res[n,m], n) 函式代表
著當 RSn 要服務到 SSm 時需要多少資源。而
∑ Fd(SP[n, n1], n)
N
n1:=0  這一段加總代表 BS 要把
訊息傳送至 RSn 需要多少資源。此二部份的值加
總後，即代表在此回合要服務到 SSn 所要花費的
資源。在分子部份，(∏ Fe(n, n2, m,m1)
N
n2≔0 ) 此
一函式的意義為，判定 SSm1 在 RSn 服務 SSm時可
以一貣服務到，所以 Formula (40)的意義為：在 n
不等於 n2時，他會用路途所經過的RS來觀察SSm1
是否可以被服務到；如果 n 等於 n2 時，他就會觀
察當 RSn 服務到 SSm時，是否可以服務到 SSm1。
如果在在任一情況下有被服務到則回傳 0，否則
則回傳 1。(∏ Fe(n, n2, m,m1)
N
n2≔0 ) 產生出來的值，
我們可以使用 Formula (5)零一互換（即為 
U((∏ Fe(n, n2, m,m1)
N
n2≔0 ) = 0)）以利於最後的
加總。而因為我們可能會把先前回合已經被服務
到的 SS 也一併算進去，於是，在計算完後我們仍
需乘上一個 SA 陣列中第 m1 的值(SA[m1])，如果
m1 在先前的回合中已經被服務到，則陣列裡的值
為 0；否則為 1。所以最後如果我們得到的值為 1
即為RSn在服務到SSm時，可以一貣服務到SSm1。
最後再從 SS1 計算至 SSM 並且把值加總貣來，即
為此回合中，當 RSn 欲服務 SSm 時，可以一併服
務到的 SS 的數量。 
2. RS 不能幫其他 RS 轉傳的情境 
 首先，我們提出一個 UBRA 的啟發式演算法
來解決 RS 不能幫 RS 轉傳的情境。在每一回合我
們都會挑一個資源利用率最高的 SSm 來交由 RSn
來服務，直至所有的 SS 都挑完或者是資源不夠服
務任一個 SS 為止。詳細的演算法如圖 78、圖 79
與圖 80 所示。而我們的演算法可以很簡略的切成
四個部份： 
壹、前置動作 
貳、選擇最佳的資源利用率 
參、配給資源 
肆、釋放多餘的資源 
雖然我們的方法在每一階段會最大化每次資
源配給之利用率，但是仍然會有資源浪費的情形
發生。所謂的資源浪費，即為先前被服務到的SS，
在後面的回合中同時在其他的 RS 服務範圍內。如
圖 81 所示，SS16 和 SS15 為 RS11 所服務到最遠的
SS，但在某一階段配給資源後，同時也被 BS 所
服務到，所以我們可以釋放掉 RS11 的資源供以後
利用。在釋放浪費的資源的演算法中，最主要的
概念，就是先標記各個 RS 服務到的 SS 數量，然
後再由第 N 個 RS 遞減開始檢查是否有 SS 在其他
人的服務範圍內，把其 SS 標記成非此 RS 服務，
再重新配給資源；要注意的是，當釋放的動作來
到 BS 時，需要把所服務到的 RS 資源納入考量。
在 RS 不能成為其他 RS 的中繼節點情況下。 
input: rbudget,  
Res[0 to N, 0 to M],  
RSRes[0 to N,0 to N] 
output: RA[0 to N] 
 圖 81: UBRA 可能會造成的資源浪費 
3. RS 可以幫其他 RS 轉傳的情境 
接著，我們提供一個 UBRA(S)演算法來解決
RS 可以幫其他 RS 轉傳的情境。在我們的演算法
中，我們結合了 Dijkstra 的最短路徑演算法和
UBRA。在 UBRA 後面的(S)即代表使用最短路徑。
其演算法如圖 82 所示。整個 UBRA(S)的骨幹和
UBRA 一樣，而資源利用率的計算方法也如同之
前所描述一樣，整體要改變的地方只有前置動作
和釋放多餘的資源。 
最理想的情況為使用最少的資源來服務到真
正有和 SS 溝通的 RS，只是那些 RS 要走共同路
徑來節省資源？那一些 RS 需要走最短路徑才會
最好？此二個問題仍然沒有一個好的機制來決定。
所以在我們的方法中，我們使用 Dijkstra 的最短路
徑演算法來算出由 BS 到各個 RS 的最短路徑，因
為我們需要精確的知道各個RS需要多少的資源，
所以其資料結構有做些許的修改，以利未來的計
算中更為節省時間。當 RS 可以成為其他 RS 的中
繼節點時，此時我們要考慮的不只是所花費的資
源必頇服務到最遠的 SS，同時也要考慮是否此
RS 還有支援其他 RS，而此一點只需確保原先被
支援的 RS 當釋放資源時仍然為訊息傳達範圍內
即可。 
1   for j:=1 to N, 
2     SP[j,0] := RSRes[j,0]; 
3     SP[0,j] := RSRes[0,j]; 
4     SP[j,j] := RSRes[j,0]; 
5   end for 
6  
7   for j:=1 to N, 
8     for i:=1 to N, 
9       if(j != i and RSRes[j,i] + SP[j,j] < SP[i,i]) than 
10         SP[i,i] := RSres[i,j] + SP[j,j]; 
11         for k := 0 to N, 
12           if(k = j) than  
13             SP[i,k] := RSRes[i,k]; 
14           else if(k = i) than 
15             do nothing; 
16           else than 
17             SP[i,k] := SP[j,k]; 
18           end if 
19         end for 
20       end if 
21     end for 
22   end for 
23  
24 return SP; 
 
圖 82: RS 可以成為其他 RS 的中繼節點時，SP 的
計算方法 
 
C. 在 IEEE 802.11e EDCA無線網路協定下對於
不同類型的存取類別估測其可用頻寬大小的
分析計算方法 
1. 效能分析模型 
效能分析技術能夠藉由數學方法去分析節點
的傳輸量、延遲時間或丟失率。藉由得知網路的
環境與設定，效能分析模型能夠計算出網路的效
能，且不需任何上線資訊。針對 802.11e EDCA 無
線網路，不同的存取類別有不同的競爭視窗、DIFS
時間設定等，通常會使用馬可夫鏈去模型各種存
取類別在每個狀態下的機率。IEEE 802.11e EDCA
無線網路的效能分析模型只能夠分析出當節點在
飽和狀態下的傳輸量。由於我們的方法目標為計
算個別存取類別的可用頻寬，因此我們會採用效
能分析模型中對於傳輸量的推導部分，如圖 83。
接著，我們做一些修正來滿足我們的需求。表 14
是所使用的參數介紹。令 Si (i = 0,…, N − 1)表示
優先權 i 的吞吐量。令δ、TE(L)、Ts以及 Tc分別
代表空的時序時間長度、帄均傳輸資料量所需時
間、帄均成功傳送所佔用頻道時間以及帄均發生
碰撞所費時間。 
步驟。如果是要計算較高優先權的存取類別時，
ThresholdintertAC 這個參數應該要設得較小，反之如
果 要 計 算 較 低 優 先 權 的 存 取 類 別 時 ，
ThresholdintertAC 這個參數應該要較大。 
貳、多重跳躍節點方法 
要計算多重跳躍節點環境下的存取類別之可
用頻寬，這邊我們也有與單一跳躍結點方法相同
的假設。這裡我們針對多重跳躍節點環境定義出
“intra AC”、 “inter flow” 與 “intra flow”。 
在多重跳躍節點環境下也許會存在一些節點擁有
與我們要計算的 targetAC 相同的存取類別，這時
候我們稱這些節點為 intraAC。此外，無線網路的
干涉範圍是傳輸範圍的兩倍大，因此我們進一步
定義出“intra AC’s intra flow”、 “inter AC’s 
intra flow” 與 “inter AC’s inter flow”三種資料
流。“Inter AC’s inter flow”代表不同存取類別的
資料流，見圖 84 中的點線。而“intra AC’s intra 
flow”代表與我們要計算的路徑上面替我們轉送
的節點，它們的存取類別會與 targetAC 相同，見
圖 84 中的實線。“intra AC’s inter flow”代表與
targetAC 相同存取類別，但並不是在我們要計算
路徑上的節點，見圖 84 中的虛線。 
 
圖 84:多重跳躍節點環境範例 
在多重跳躍節點環境下，我們必頇知道所有
節點的存取類別，參數設定以及傳輸速率，因此
我們使用 Hello message 交換機制。由於無線網路
的干涉範圍是傳輸範圍的兩倍大，我們要讓每個
節點保存自己兩倍傳輸範圍內所有鄰居節點的資
訊，並且與它們交換共享這些資訊。接著說明多
重跳躍節點方法，首先先計算每個單一跳躍的可
用頻寬，最後再取出其中的最小值當成整個路徑
上的可用頻寬。而個別單一跳躍的可用頻寬計算
方法如下：第一步，利用同樣的步驟去計算出
targetAC 的可用頻寬。第二步，減去”intraAC’s 
inter flow”的傳輸量，因為第一步的計算是包含
整個相同存取類別的可用頻寬，因此我們要再減
去與我們相同存取類別但卻不在我們要計算的路
徑上的資料流傳輸量。第三步，再除以”intra AC’s 
intra flow”個數，因為在同樣的干涉範圍中頻寬
會被共享的關係，要注意這些步驟都是在計算個
別的單一跳躍節點，因此每個跳躍節點的計算所
看到的干涉範圍節點會不同。重複第一步到第三
步，直到將所有的跳躍節點的可用頻寬計算出來，
最後再取其中的最小值，即為路徑上的可用頻寬
大小。 
3. 優先權保證機制 
在 EDCA 中只有提供一組預設的參數設定來
讓不同的 AC 服務不同的資料種類。為了讓像是
影像等即時資料能擁有絕對性的優先權來保證它
能存取頻道，較高優先權的資料類型的 AIFS 必頇
小於較低優先權的資料類型，藉由這個設定，可
以讓高優先權的資料類型可以比較低優先權的資
料優先取得傳送資料的機會。DCF 和 EDCA 的後
退機制並沒有提供此決定性的優先權機制，因此
我們設計了一個新的後退機制讓低優先權的資料
能完全的被限制：低優先權資料的 AIFSN 必頇大
於高優先權的 AIFSN 加上高優先權的 CWmax，如
(50)所示。 
AIFSN[AC_BK]>AIFSN[VI]+CWmax[VI]     (50) 
除了調整AIFSN去讓影像資料能取得決定性
的優先權去存取頻道之外，我們必頇去找到影像
的 CWmax的最小值，因為影像的 CWmax的大小會
影響到較低優先權資料的 AIFSN，也就是會影響
到較低優先權的資料種類去存取頻道的機率以及
效能。因此，我們提出了三種不同的方案。 
(1) 方案一：AP flow 
考慮只有 AP flow 往下傳送，我們設定 AC2
的個數 n2=1，其他的個數設成 0。令 CWmax_AP 代
表 AP 的 CWmax，SAC[VI]_AP 代表 AP 的影像的吞吐
量，在這個方案下，我們的目標如(51)所示。 
Minimize{CWmax_AP} 
s.t SAC[VI]_AP ≥ Target Throughput            (51) 
因為沒有其他的基台與 AP 競爭頻道，所以我們
設定 AP 的 CWmin=1 以及 CWmax為 2，讓 AP 可以
取得最高的優先權去存取頻道。我們的機制除了
可以保證影像的效能之外，也比其他機制提供較
好的 best effort 服務。我們設定 data 的 CWmin=3
以及 CWmax=7，這組設定與原先 EDCA 的最高優
先權設定相同。參數設定如表15。影像的AIFSN=2
則 data 的 AIFSN 設為影像的 CWmax 加上影像的
AIFSN 加上 1 等於 5 去保證影像的傳輸品質。 
 
Maximum Delay constraint，但 QrtPS 只能支援
Average Delay constraint; (2) QrtPS 主要的設計來
支 援 能 接 受 使 用 multicast polling 的
contention-based bandwidth request 的 Traffic 
Priority。 表 18 說明了 QrtPS 與原來其他四種
traffic 在 QoS 參數上的差別。  
表  18: The supported QoS parameters in five 
service classes 
       Service Classes 
       QoS Parameters UGS rtPS QrtPS nrtPS BE 
Maximum Sustained Traffic Rate      
Maximum Delay      
Average Delay      
Tolerated Jitter      
Request/ Transmission Policy      
Minimum Reserved Traffic Rate      
Traffic Priority      
貳、Two-Phase Adaptive Polling Approach 
Phase 1. The determination phase for switching 
polling mode 
在 WiMAX 網路中，一個 SS 需先向一個 BS
註冊，才能開始使用 channel 傳輸資料。所以一個
BS 可以知道在其範圍內有多少 SS 及它們使用
channel 傳輸資料的情形。雖然 rtPS 的 flow 可以
比nrtPS及BE的 flow得到較好的服務品質保證，
但其 polling 必頇在 unicast polling mode 執行。在
IEEE 802.16 中，當頻寬不足應付 unicast polling
時，一台 BS 會從 unicast polling switch 到 
multicast polling。而且這樣的 polling delay 會隨
時在unicast polling mode 的SS增加而線性增加。
這將造成 polling delay 超過 Maximum Delay，而
且 rtPS flows 的 the Maximum Sustained Traffic 
Rate 可能無法滿足，最終將造成因無法保證 rtPS
的 QoS requirements 而終止 rtPS services。所以我
們提出一個 adaptive switching mechanism，讓 BS
可以動態在 unicast and multicast polling modes 間
做適當的轉換。 
Case 1: In the unicast polling mode 
一開始時，一個 BS 是在 unicast polling mode。
此時BS的 residual bandwidth 會因分配給 unicast 
polled SSs 個數增加而減少，同時 polling delay 也
會慢慢隨著 SS 個數而增加。此外，為避免 switch 
polling mode 造成不必要的 ping-pong 效應，我們
的機制也考慮兩個 hysteresis mechanisms。如圖 85
所示，我們使用了兩個 thresholds (分別限制 SSs
數量及 and 頻寬)。 
Number
 of SSs
Polling 
mode
Multicast 
polling
Unicast 
polling
Bandwidt
h
2
SSV
S
1
SSV
S
2
bwS
1
bwS
 
圖 85: Two hysteresis thresholds of the number of 
SSs and bandwidth 
Case 2: In the multicast polling mode 
在 multicast polling mode 時，我們所提出的
QrtPS service 將可取代 rtPS service 被優先服務。
QrtPS 主要考量兩個 QoS 參數: Average Delay 及
Traffic Priority。首先， QrtPS 改以 Average Delay 
constraint 取代 Maximum Delay bound，這樣雖然
可能產生 jitter 問題，但至少能讓 real-time service 
被正常服務。然而，依據 IEEE 802.16 的標準，rtPS 
的 QoS 參數並不能設定 Tolerated Jitter。所以就
QoS 而言， QrtPS 與 rtPS services 並沒有明顯差
異，是可視為同等級的。其次，我們需要保證在
multicast 的競爭模式下 QrtPS flows 可以優先於
nrtPS 及 BE 的 flow 被服務。所以 競爭 request 
opportunities 必頇是 QrtPS >nrtPS>BE。同時，我
們也使用 Traffic Priority 參數來解決同一 SS 下有
多個 QrtPS flows 時，能區分出不同 flows 間的
priority。 
Phase 2. Efficient contention resolution algorithm 
在 IEEE 802.16 中，一台 BS 會從 unicast 
polling switch 成 multicast polling mode 如果剩餘
頻寬不足以滿足 unicast polling。此時，BS 會不允
許 nrtPS and BE services 在 multicast polling mode
中被服務 (schedule)。這樣有可能造成 rtPS 的 
Maximum Delay 要求因 multicast polling 時間長過
其 constraint 而無法被滿足。這也是我們提出
QrtPS 服務等級的動機。因如果在 multicast polling 
mode 採用一個有效率的 contention resolution 
algorithm，則原本的 rtPS 的 flow 可以 QrtPS 等級
來繼續 service(schedule)。 如前文所述的，QrtPS
求。基地台透過單點傳播模式來詢問某些用戶端，
而且詢問的順序是根據基地台所管理的詢問清單。
同時，我們認為 NPS 可能會低於用戶端的數量，
也就是說，並非所有用戶端都會在在ㄧ個 frame
週期內被詢問。此外，皆有考慮在 IEEE 802.16d
以及 IEEE 802.16e 分別支援類型為固定和移動的
SSs。為了估算存取機率的公帄性，我們假定在大
量送出資料後，每個 SSs 不採用連續的 piggyback
頻寬要求。 
WiMAX 網路有ㄧ些重要參數：資料速率，
downlink subframe 長度，uplink subframe 長度，
初始訊號量測長度，頻寬要求長度，輪詢 slot 長
度以及資料 slot 長度。為了分析在 time-based 
physical frame 上的效能。我們透過除以資料速率
的長度將長度轉移為時間。舉例來說，uplink 
subframe 的時間週期可以得到 
.
up
up
L
T
R
                   (54) 
由於物理框架包含 downlink以及 uplink subframes，
frame 週期 fT 是由 downT 以及 upT 組成，也就是說， 
f down upT T T  ,              (55)  
其中 uplink subframe 可分為控制週期以及資料傳
輸週期這兩個部分。uplink subframe 的控制週期
由初始訊號量測以及頻寬要求週期所組成。這兩
個週期可以看作是隨機訪問機制的競爭窗口。
uplink subframe 的週期以此方式 
( ) ,
up
Cont Tx
IR BR Tx
T
T T
T T T
 
  
           (56)  
其中 ContT 為控制週期而 TxT 為資料傳輸週期。 
在單點傳播模式，BS 使用 UL-MAP 內 slot 
index 的 offset 來個別詢問 SS。如果 SS 有要發送
的數據包，它可以透過特定的 slot 來要求頻寬。
在 BS 接收到要求之後，BS 會基於剩餘的頻寬足
夠與否來決定是否接受或拒絕此要求。如果剩餘
的頻寬是足夠的，BS會執行資料允許以及分配 the 
grand slot(s)給 SS。由於 uplink 的 subframe 是有限
的，更多的 NPS 減少了資料傳輸 slot 數。因此，
可用的資料傳輸 slot 數可以表示為 
 _Tx Data Tx PT T T    ,         (57) 
其中 PT 為ㄧ個 SS 傳送頻寬要求的週期以及 指
出在ㄧ個 frame週期內有多少詢問數，也就是 NPS。
因此一個實體訊框被拆為 
( ),
f
down up
down IR BR Tx
T
T T
T T T T
 
   
      (58) 
如圖 87 所示。 
IRT BRT
TxT
Control period
PT  _Tx Data
T
Tx period
Initial 
ranging
BW 
reques
t
Control period Tx period,
upTdownT
 
圖 87: Frame structure 
儘管 polling-base MAC 方法克服了存取碰撞，
它還是可能會遭遇到較長的詢問延遲以及詢問所
使用的頻寬。當 BS 服務於高密集 SSs 情況下會變
得更加嚴重。因此，三個重要的性能指標，包括
帄均輪詢延遲，網路流量以及網路使用率會採取
該提出的方法來估計。其分析以及模擬的結果會
與其他 IEEE 802.16 方法來作比較。 
第一，帄均輪詢延遲在輪詢 MAC 是ㄧ項重要
指標，其中它受到ㄧ些因素影響，特別是 NPS 以
及 SS 總共服務數量這兩項因素。較長的帄均輪詢
延遲代表其性能較差。 
第二，我們從封包的傳輸成功機率和分配資料
slot 給 SS 的總頻寬來分析網路流量。ㄧ個好的詢
問方法可以帶來較高的網路流量。 
第三，WiMAX 網路的使用率是採用估算的，
其定義為 
_
,ww
w
Allocated bandwidth
U
C
          (59) 
其中
wC 和 _ wAllocated bandwidth 分別代表網路容量以
及帄均分配頻寬的 WiMAX 網路w，較多的使用
率代表更好的性能。 
 
2. Performance analysis for WiMAX 
我們以 NPS 為基礎在 Markov chain mode 上進
行分析，降低 polling delay 而提高網路 throughput
和 utilization 率，詳細數學分析的如下。 
以 polling 為基礎的 WiMAX 網路上，SSs 所服
務的數量是一個影響網路效能的重要參數。其中
有兩個原因。第一點在每個 frame 期間 BS 集中
polls 每個正在服務的 SSs 導致 polling delay 的發
,S 

U
B I
               (67) 
其中 B I是在上傳鏈路子訊框時間裡的帄均長度，
定義為
upT ，U是從控制和資料傳輸使用的帄均長
度 
( ) [ ].IR BR p pollU T T T R p E L             (68) 
因此，網路流量公式能寫成 
( ) [ ]
,
IR BR p poll
up
T T T R p E L
S
T
       
  
i.e.,  
1
( ) ( ) [ ]
.
N
IR BR p t
n
up
T T T R n n p E L
N
S
T

 

 
         
 

 (69) 
在公式(21)中，可以看出從詢問次數、全部服務
SSs 的數量和封包傳輸機率明顯影響到網路流量，
因為在
IRT 期間， BRT 和 pT 是相對的小於在 WiMAX
上資料 slot 的期間。  
Busy period Idle period
Control Data
C
Allocated data slots
Uplink subframe cycle
Unallocated data slots
D
polling
BW 
reques
t
Initial 
ranging
 
圖 88: The period components of an uplink subframe 
in WiMAX 
最後我們以上傳鏈路子訊框的網路使用率為
基礎來分析網路流量。有效傳輸資料 slots 在上傳
鏈路子訊框的長度上使用率公式如下 
1
( ) ( ) [ ]
.
N
IR BR p t
n
up
T T T R n n p E L
N
U
L

 

 
         
 

   (70) 
因為
upL 最大長度是有限的，即使有較大的 polls
數量，資料傳輸總長度是小於
upL 的，因此，演算
法會考慮 CAC 來決定網路使用率，如下所示： 
1
1
( )
{
      (( ) ( ) [ ] )
     {
( ) ( ) [ ] 
             ;
      }
      
            100%;
}
       // ; N
{
   
N
IR BR p t up
n
N
IR BR p t
n
up
if N
if T T T R n n p E L L
N
T T T R n n p E L
N
U
L
else
U
else N


 

 
 



 
          
 
 
         
 

 


1
( ) ( ) [ ] 
    ;
}
N
IR BR p t
n
up
T T T R n n p E L
U
L
 

 
        
 

 
 
最後，在沒有提出要求 polled 的浪費率，決定於 
1
min ,   ( )
1 .
N
t
n
n n p 



  
   
   

        (71) 
C. 在車載群播網路下 Delay-Guarantee chunk 
Reloading 機制 
1. 網路模型 
我們所定義的車載群播網路模型由圖 89 說
明，並且由設定的移動節點V 所組成，和設定的
無線連線E。 我們假設每一個移動節點傳輸半徑
相同並且無線連線與 channel capacity相關 )(Cap ，
為一個無線網路連線 E 。 一個群播網路傳送由
四個參數組成： 來源節點 s，群組中的接收者R ，
並且 }{sVR  ，群播網路 g 的群組 ID(GID)，和
QoS Q。數個接收者在群組 g 中可以表示為
gR 。 
G 為在車載網路所設定的群播群組，在 Fig. 1，一
個群播群組 g 可以被分成數個 cluster t
IDC 可以表
是為群播群組 t 中的 cluster。 而 cluster header 由
tracker來代表，並且可以管理接收者分享的封包。 
此外，一個群播傳送的接收者屬於群播群組中的
一個 cluster t
IDC ，可以表是為
C
tr 。 一個接收者
C
tr
可以扮演一個節點 C
IDP 。網路環境模型的範圍由長
度 L 與寬度 W 表示。 
unconfirmed chunk，可以提供最小的補傳 chunk 
delay。 
Phase 1-1  The adaptive clustering phase 
車輛移動有空間以及時間位置特性。所以在
這個階段首先加入 cluster 是根據車輛的位置以及
方向，而且在車載路會動態分割成數個 cluster 隨
著車輛的位置來加入。 
如圖 91 說明獨立的第一個 cluster 節點，節點
分配為 ID 1。並且擔任為 cluster tracker 負責管理
所分享的 chunk 資訊。 當另一台車輛靠近 cluster
稱為子節點，加入 cluster 並且分配節點 ID 給此節
點。例如，假設子節點是跟隨著 ID=1。當新的節
點加入後為第一個子節點，將會分配 ID 1.1 給新
加入的子節點。 特別地，新的子節點會加入到
closet cluster。由結果得到，節點 ID 樹的架構是
根據節點的實體位置所構成， 由 Fig.3。 舉例說
明， A3 實體位置分配節點 ID=1.2，並且可以得
到介於節點 A1(ID=1)和 A2(ID=1.2.1)之間，因為
由 ID 樹的架構得到他們皆屬於同一個分支。 以
位置資訊為基礎建立節點 ID 管理，可以有效的貢
獻決定一個最短的 delay來補傳 chunk的演算法，
並且能滿足最佳的 delay-bound，由第三階段來詳
細講解。另外，從車載網路拓樸和節點的動態改
變，由會直行一個不中斷的 cluster tracker 來有效
的管理分享的 chunk 資訊。 
Physical locations of peers in Cluster A
Tracker
: ID tree links
ID=1.3
ID=1.3.1
ID=1.3.1.1
1
1.2
1.2.1
1.1
1.1.1 1.1.2
1.1.2.1
1.1.2.1.1Peer ID tree
ID=1
ID=1.2
ID=1.2.1
ID=1.1
ID=1.1.1
ID=1.1.2.1
ID=1.1.2
ID=1.1.2.1.1
A1
A2
A5
A3
A6
A4
 
圖 91: Peer ID tree in the proposed VANET cluster 
Phase 1-2 The cluster tracker determination 
phase 
在車網路環境中，當 cluster header 的位置在
中心，可以有最短的 delay 到達在相同 cluster 的
其他節點。 然而，選擇中心的車輛是非常困難的，
因為會產生大量的訊息負載來計算車輛位置並且
導致非常高的計算複雜度。 為了達到簡化以及有
效率，在此篇文章所以選擇車輛最多的鄰居數
(degree)來推選為 cluster head，例如： 車輛有最
多的鄰居數量，推選為 tracker。 結果，在 cluster
中 tracker 可以容易與其他節點建立連線。 通常，
在車載網路環境中車輛位置在 cluster 中間一定會
有大量的鄰居數，所以透過決定 tracker 演算法以
cluster 中心為基礎有效的推選出 tracker。 
Tracker 會管理所有分享的 chunk 資訊，而這
些資訊是由同一個 cluster receivers 成功接收
chunk 資訊更新給 tracker。而 Tracker 管理分享的
chunk 資訊包括了：stream ID， chunk ID，分享
節點 IP address， cluster ID，和 multicast group ID 
等。所以，當一個群播 receiver 發生 lost chunk or 
unconfirmed chunk， receiver 會傳送搜尋的封包
給 tracker，可以獲得補傳 chunk 的位址資訊，因
此，採用 receiver 來補傳 lost chunk，並不是要求
multicast 傳送端重新傳送。此外，為了增加 chunks
管理的可靠性，會推選出一個車輛為第二高的鄰
居數來當做備用的 tracker。 所分享 Chunk 資訊會
儲存給備份的節點，並且定期的更新。 之後動態
行程 cluster 和決定 cluster tracker 會由第二階段章
節中來詳細說明。 
Phase 2： Dynamic chunk management phase 
保證在車載網路下群播傳送的 QoS 是非常困
難以及複雜的，因為車載網路容易導致 chunk 遺
失以及 chunk 傳送延遲。雖然以群播方式可以重
新傳送 chunk，但結果可能會產生兩個嚴重的問
題：  ) long retransmission delay and 2) waste 
bandwidth。 所以在本篇文章中採用補傳 chunk
的機制，並且是從其他的 receiver 補傳 lost chunk 
or unconfirmed chunk，可以快速的獲得 chunk。  
Phase 2-1  Joining to a P2P cluster 
提出的方法中，一個群播傳送的 receiver 可以
更新所接收到的 chunk 資訊給 cluster tracker。 所
以，在群播傳送的 receiver 需要加入最近現有的
cluster 或者獨立行程 cluster。 如圖 92 說明群播
傳送的 receiver 加入 P2P cluster，有四個步驟來詳
細說明。 
 步驟一 :當一個車輛 A(如，一個群播的
receiver)接近一個 cluster 節點 B，車輛 A 傳
送一個訊息 Peer_ID_Req 給車輛 B。車輛 B
接收後會回傳 Peer_ID_Rep 訊息包含了分配
的 ID=1.2.1和 tracker ID(如 ID=1)給車輛A。 
 步驟二 :當車輛要求加入 cluster 會傳送
Join_Cluster_Req 訊息加入 cluster tracker T。 
當 tracker T 接受加入要求後，會回傳
Join_Cluster_Rep 訊息給 vehicle A 為加入成
功。所以當成功加入 cluster 後，由步驟三和
四為車輛 A 成功接收群播傳送的 streaming
後並且更新所接收的 chunk 資訊。 
Leave_Multicast_Req 訊 息 給 multicast 
server ， 然 後 server 會 回 傳
Leave_Multicast_Rep 訊息告知成功離開。 
 步 驟 二 : 車 輛 A 傳 送
Leave_Cluster_Notification 通 知 cluster 
tracker T 通知準備離開 cluster。 
 步驟三: treacker T 將更新兩個部份，第一部
分為更新分享 peer 的 chunk 資訊更改
validate bits 為”0”，之後等待一個 timeout
的時間後，無效的 chunk 資訊將會被移除。
第二部份，tracker 會重新分配節點 ID 資訊
(Peer_ID)，最後完成離開的動作。 
我們所提的 real-time 補傳方法，所分享的
chunk會逐漸舊，如果分享的 peer無預警的離開，
則會造成 chunk無效，所以採用 tracker validate bits
定期檢查，當舊掉的 chunk 資訊則更改為 0v  ，
並根據此資訊把無效的 chunk 資訊移除。 
A multicast receiver, A Tracker, T
Multicast streaming 
server
Step 2. Leaving a P2P 
cluster
Successful leaving a cluster
1. The tracker updates all
    information associated to 
    the peer.
2. The tracker de-allocates the
    Peer_ID. 
. 
 .
  
.
Step 1. Leaving a 
multicast group
Step 3. Successful 
leaving
Cluster ID: 1ID: 1.2
Leave_Multicast_Req
Leave_Cluster_Notification
Leave_Multicast_Rep
 
圖 95: The procedure of a multicast receiver leaving 
a P2P cluster 
 
六、 結果與討論 
各子計畫已完成的成果如下: 
I. 總計畫 
A. 建立支援 SVC的 P2P視訊串流的模擬環境。 
B. 整合各子計畫完成的研究成果。 
II. 子計畫一：具情境知覺之點對點視訊串流服
務及異質網路之資源與移動管理 
A. 完成 WiFi/Fixed WiMAX 異質網路下跨網路
資源保留機制之設計。 
B. 完成 WiFi 網路下可適性群播頻寬配置機制
之設計。 
C. 完成 WiMAX 網路下最佳化群播資源配置機
制之設計。 
D. 完成 WiFi/Fixed WiMAX 異質網路下跨網路
行動管理機制之設計。 
E. 完成多重網址設備之容錯與負載帄衡機制之
設計。 
F. 完成設計 WiFi/Mobile WiMAX/3G 異質網路
下行動管理機制之設計。 
G. 完成點對點隨選視訊系統之設計。 
H. 完成設計基於Network Coding的 P2P SVC 編
碼視訊串流機制之設計。 
I. 完成以 Small World Network 的觀點分析不同
節點選擇策略對於 P2P 網路特性的影響。 
J. 完成設計基於 Self-Similar 概念的 Super-node
層拓樸建構法之設計。 
K. 完成點對點可調適視訊串流之同步機制之設
計。 
III. 子計畫二: 802.11 無線區域網路中具情境知
覺之視訊串流服務 
A. 完成WiFi網路下提升P2P視訊串流服務品質
的架構之設計。 
B. 完成 Utilization-Based Resource Allocation 演
算法之設計，分別稱為 UBRA 與 UBRA(S)。 
C. 完成提出在 IEEE 802.11e EDCA 無線網路協
定下對於不同類型的存取類別估測其可用頻
寬大小的分析計算方法，分別有單一跳躍節
點以及多重跳躍節點兩種方法。。 
IV. 子計畫三: 具跨層的 IEEE 802.16 WiMAX
無線網路情境知覺之視訊串流服務 
A. 完 成 Adaptive delay-constraint polling 
approach 之設計。 
B. 完成 Cost-based WiMAX adaptive routing 
approach 之設計。 
C. 完成以馬可夫鏈分析 group polling 機制之設
計。 
D. 完成在 Contention-based 中提出一適性演算
法降低行動節碰撞率並達到較高網路效益之
目的。 
E. 完成 Delay-Guarantee chunk Reloading (DGR)
方法之設計。 
F. 完成適性形成 P2P cluster 機制之設計。 
G. 完成 Cluster-based peer-to-peer chunk 補償機
制之設計。 
H. 完成 delay 保證演算機制之設計。 
 
七、 參考文獻 
[1] J. Klaue, B. Rathke and A. Wolisz, “EvalVid – A Framework 
for Video Transmission and Quality Evaluation,” Lecture Notes 
in Computer Science, vol.2794, pp.255-272, 2003. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/30
國科會補助計畫
計畫名稱: 總計畫
計畫主持人: 黃仁竑
計畫編號: 97-2221-E-194-011-MY3 學門領域: 計算機網路與網際網路
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
