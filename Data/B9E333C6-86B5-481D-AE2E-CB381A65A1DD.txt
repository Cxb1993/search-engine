  1 
針對多類分類問題之新型特徵擷取方法 
A new feature selection method for multi-class classification 
計畫編號：NSC 98-2218-E-238 -001 
執行期限：98 年 08 月 01 日 至 99 年 07 月 31 日 
主持人：   周建興 助理教授  淡江大學電機工程系 
共同主持人：  蘇木春 教授   中央大學資訊工程系 
計畫參與人員：謝易錚    中央大學資訊工程系 
e-mail：chchou@mail.tku.edu.tw 
 
一、摘要 
在模式分類的問題中，分類演算法以及特徵
擷取方法的選擇，都是模式分類成功與否的
關鍵。而成功的特徵擷取方法，除了能抽取
出使用者所關心的特徵，在某些問題上，甚
至可進一步提升分類時的辨識率。例如在
DNA 序列的分析研究中，透過特徵擷取可以
找到序列中可能導致疾病的段落位置或是氨
基酸種類。然而傳統的特徵擷取方法，大多
沒有考量多類(multi-class)模式分類的問題
特性，往往導致成效不如預期。因此，在此
計畫中，我們針對多類的模式分類問題，應
用一種新的特徵擷取策略。我們將多類問題
分解成數個兩類問題，然後針對每一個兩類
問題，使用特徵擷取演算法擷取屬於該子問
題的子特徵集合。這個新的特徵擷取策略不
僅適用於不同的特徵擷取演算法；與傳統的
作法相比較下，此策略也呈現出較為優異之
成效。 
 
關鍵詞：特徵擷取、多類分類問題、模式分
類、模式識別 
 
Abstract 
In the problem of pattern classification, it 
is very important to select the classification 
method and the feature selection algorithm. 
Choosing a proper feature selection algorithm 
could not only extract the key feature interested 
by researchers but also improve the recognition 
accuracy in some classification problems. In 
biology, for example, researchers need to know 
whether a DNA sequence or a sequence of 
amio acids is responsible for certain types of 
disease. However, for most traditional feature 
selection algorithms, they usually do not 
perform well in multi-class classification 
problem. In this project, we propose a new 
feature selection strategy focuses on the 
multi-class classification problem. In the 
proposed strategy, the multi-class classification 
problem will be decomposed to several binary 
classification problems. The feature selection 
algorithm is then applied to each 
sub-classification problem to extract the 
corresponding feature subset. The proposed 
strategy can be applied for different feature 
selection algorithms, and it also achieves better 
performance by comparing with the original 
strategy. 
Keywords: feature selection, multi-class 
classification, pattern classification, pattern 
recognition 
 
二、計畫緣由目的與文獻探討 
 
在模式分類的問題中，分類演算法以及
特徵擷取方法的選擇都是模式分類成功與否
的關鍵。目前有許多模式分類的演算法被提
出來，包括了 k-nearest neighbors (KNN) [1-3], 
condensed nearest neighbor (CNN)[4], 
MLP(multilayer perceptron) [5]以及 support 
vector machines (SVM) [6-7]等方法。在選擇
合適的分類演算法時，除了要考量分類器的
辨識準確度外，訓練以及測試時所需花費的
時間，亦是十分重要的考量。有關分類演算
法的介紹可以參考[8]。在此計畫中，我們將
研究重心放在特徵擷取上。特徵擷取除了能
  3 
取出有效的特徵，往往得選擇十分大量的原
始特徵進行分類。如此一來，不但失去了特
徵擷取的意義，也未能達到預期中的效果。 
 
 
圖二、五個不同的中文字。淡紅色區塊部分
代表分類此文字的關鍵區域。 
 
針對上述多類的模式分類問題，我們提出
一個新的解決策略。此策略的關鍵是將多類
問題先拆解成數個兩類問題。假設總共有 C
個類別，我們先分解成 C 個獨立的子分類問
題，而針對單一的子分類問題（例如類別 A）
只包含兩個類別，分別為 A 類別(class A)與
非 A 類別兩類(class non-A)。接著我們針對
每一個子分類問題擷取出重要的子特徵集合
(feature subset)。在此計畫中，我們採用最近
鄰居法(Nearest Neighbor, NN)當分類器，以
及 backward floating search (BFS) [20]作為特
徵擷取的演算法。針對每一個獨立的子分類
問題，使用 NN 與 BFS 擷取出該子分類問題
的子特徵集合。在資料的測試階段（如圖三
所示），由於每一個子分類器所選擇的子特
徵集合與特徵數目都不相同；因此，我們將
資料樣本 x 送到每一個子分類器，計算此資
料 樣 本 x 屬 於 該 子 分類 器的 歸屬 度
membership(i)，而歸屬度的計算公式如下所
示： 
inoni
inon
dd
d
imembership
−
−
+
=)(  
where ||||min
i jClassxi
xxd
j
−=
∈
, 
||||min
i knonClassx
inon xxd
k
−=
−∈
−
 
其中 id 是 x 在 ith 子分類器中與類別屬於 i
的資料之最短距離，而 inond − 是 x 在 ith 子分
類器中與類別屬為 non-i 的資料之最短距
離。歸屬度越大則代表 x 屬於類別 i 的可能
性越高。最後我們在所有的歸屬度中，選取
歸屬度最大的 class作為此資料樣本 x的分類
結果。計算之公式如下所示： 
)(max*
,,1
imembershipArgi
Ni K=
=  
 
圖三、資料樣本 x 在測試階段，決定其之類
別方法。 
 
四、結果與討論 
 
在實驗模擬中，我們在 ETL9b 的手寫中
文字元資料庫中，分擇 5 個較為相似的中文
字元作為測試的作為實驗模擬的資料（如
table 1 所示）。每一筆字元資料使用 density 
feature 產生出 256 個維度的特徵。然後我們
將所有的字元資料均勻的分成三個資料集，
分別是 training dataset, development dataset, 
test dataset。在特徵擷取的過程中，先使用
training dataset 建立分類器(NN)，然後使用
development dataset 來評估辨識率，由 BFS
擷取出子特徵集合。完成所有訓練過程後，
整合 training dataset 與 development dataset，
以被擷取的子特徵集合建立 testing時的分類
器，以進一步計算 test dataset 的辨識率。 
 
Table 1. 實驗模擬之測試字元 
 Char Class # Total Dataset 
5 classes 大, 犬, 太, 天, 木 1000 
 
Table 2 列出實驗模擬的辨識率，我們簡
單歸納模擬的結果。(1)對傳統的特徵擷取策
略而言，測試的辨識率由 73.35 提升到
76.64，而 BFS 由原本 256 個特徵中，擷取了
161 個特徵。而此計畫所提出的特徵擷取方
法，其辨識率高達 89.22，而每個子分類問
題，所選取的特徵數目也遠少於傳統的方
法。例如，子分類問題”犬”，選取 61 個特徵，
而子分類問題”木”更僅選取 18 個特徵。圖四
為子分類問題”犬”所選取的特徵區域，大多
數被擷取出的子特徵皆位於字元的右上區。
而實際上，字元的右上區也確實是分類字元”
犬”的關鍵位置。此外，其他字元所擷取出的
子特徵集合也有類似的現象。因此，根據實
驗模擬的結果，顯示出所提出的策略，確實
能有效改善傳統特徵擷取演算法所遭遇的問
題。 
  5 
Fourteenth International Conference on 
Machine Learning, pp. 412 - 420, 1997. 
[11] N. Guyon, A. Elisseeff, “An introduction 
to variable and feature selection”, Journal 
of Machine Learning Research, vol. 3, 
2003, pp. 1157-1182. 
[12] H. Liu, L. Yu, "Toward Integrating 
Feature Selection Algorithms for 
Classification and Clustering," IEEE 
Transactions on Knowledge and Data 
Engineering, vol. 17, no. 4, pp. 491-502, 
2005. 
[13] R. Kohavi, G. John, “Wrappers for feature 
selection”, Artificial Intelligence, vol. 97, 
no. 1-2, pp. 273-324, 1997. 
[14] A. Blum, P. Langley, “Selection of 
relevant features and examples in machine 
learning,” Artificial Intelligence, vol. 97, 
no. 1-2, pp. 245–271, 1997. 
[15] G. Forman, “An Extensive Empirical 
Study of Feature Selection Metrics for Text 
Classification”, Journal of Machine 
Learning Research, vol. 3, 2003, pp. 
1289-1305. 
[16] R. Bekkerman, R. El-Yaniv, N. Tishby, Y. 
Winter, “Distributional word clusters vs. 
words for text categorization,” Journal of 
Machine Learning Research, vol. 3, pp. 
1183–1208, 2003. 
[17] I. Dhillon, S. Mallela, R. Kumar, “A 
divisive information-theoretic feature 
clustering algorithm 
for text classification,” Journal of Machine 
Learning Research, vol. 3, pp.1265–1287, 
2003. 
[18] K. Torkkola, “Feature extraction by 
non-parametric mutual information 
maximization,” Journal of Machine 
Learning Research, vol. 3, pp. 1415–1438, 
2003. 
[19] J. Reunanen, “Overfitting in making 
comparisons between variable selection 
methods,” Journal of Machine Learning 
Research, vol. 3, pp. 1371–1382, , 2003. 
[20] Pudil, P., Novovičová, J., & Kittler, J. 
(1994). Floating search methods in feature 
selection. Pattern Recognition Letters, 
15(11), 1119-1125. 
[21] F. C. H. Rhee, Y. J. Lee, “Unsupervised 
feature selection using a fuzzy-genetic 
algorithm,” IEEE International Cnference 
on Fuzzy Systems, vol. 3, pp. 1266-1269, 
1999. 
[22] S. Das, “Filters, Wrappers and a 
Boosting-Based Hybrid for Feature 
Selection,” Proc. 18th Int’l Conf. Machine 
Learning, pp. 74-81, 2001. 
[23] E. Xing, M. Jordan, and R. Karp, “Feature 
Selection for High-Dimensional Genomic 
Microarray Data,” Proc. 15th Int’l Conf. 
Machine Learning, pp. 601-608, 2001. 
[24] F. Chang, C. H. Chou, “Bi-Prototype 
Theory for Facial Attractiveness,” appear 
in Neural Computation. 
 
 
 A Machine Learning Approach to Classify Sleep Stages of Rats 
Zong-En Yu1, Chung-Chih Kuo2, Chien-Hsing Chou3†, Fu Chang4 
Department of Electrical Engineering, Taiwan University, Taiwan1 
Institute of Neuroscience, Tzu Chi University, Taiwan 2 
Department of Electronics Engineering, Vanung University, Taiwan3† 
Institute of Information Science, Academia Sinica, Taipei, Taiwan4 
Email: brendon@cobra.ee.ntu.edu.tw1, cckuo@mail.tcu.edu.tw2, chchou@mail.vnu.edu.tw3† 
 
Abstract: Identifying the vigilance states of the mammalian is an important research topic to bioscience in 
recently years, which the vigilance states is usually categorized as slow wave sleep, rapid eye movement sleep, 
and awake, etc. To discriminate difference vigilance states, a well-trained expert needs spend a long time to 
analyze a mass of physiological record data. In this paper, we proposed an automatic sleep stages classification 
system by analyzing rat’s EEG signal. The rat’s EEG signal is transferred by FFT and then extracted features. 
These extracted features are used as training patterns to further construct the proposed classification system. 
The proposed classification system contains two components, the principle component analysis (PCA) as the 
first component is used to projects the high dimensional features into lower dimensional subspace, and the 
k-nearest neighbor (k-NN) method as the second component is applied to identify the physiological state for a 
period of EEG signal. By experimenting on 810 periods of EEG signal, the proposed classification system 
achieves satisfactory classification accuracy of sleep stages. 
 
Key-Words: sleep stages, pattern classification, machine learning, PCA, k-NN, FFT 
 
1 Introduction 
Sleep is circadian activities composed with repeated 
cycles of slow wave sleep (SWS) and rapid eye 
movement sleep (REM). For the research fields 
related to sleep studies (e.g. sleep depriving, the 
effect of drugs, circadian clock, etc.), identifying the 
sleep stages with precision and effectiveness is an 
important research topic . Scoring vigilance in sleep 
studies is a time-consuming work to a 
well-experienced expert. Consequently, how to 
reduce the human intervention is an signif icant topic 
in this research field. A variety of automated sleep 
staging systems via different analyses have been 
developed over the past decades [1, 10-17]. Some of 
proposed methods still required human intervention 
[1, 17]. For example, the user has to decide the 
appropriate parameters (thresholds) or participate in  
the entire classification procedure. However, to 
select appropriate parameters to different conditions  
is a very subjective task to each researcher. To solve 
the problem of selecting parameters, we apply 
machine learning techniques to develop an automatic 
sleep stages classification system of rats. By 
collecting the labeled EEG data in advance, a 
machine-learning-based classification system is 
constructed to recognize the testing patterns of 
different vigilance states with one channel of EEG 
signal. Through the proposed method, three types of 
vigilance state could be categorized automatically to 
save the time of human intervention. In this paper, 
we roughly category sleep stages into the following 
three states: 
1. Awake (AW) 
2. Slow wave sleep (SWS) 
3. Rapid eye movement sleep (REM) 
During the awake stage, the animal represents a 
low amplitude and high frequency EEG. Some 
investigators distinguished active awake from quite 
awake by high EMG activity. The spectrum of EEG 
in this stage is with high theta and gamma power 
density. Slow wave sleep which is defined by high 
amplitude and low frequency EEG begins with sleep 
spindle and is dominant with delta waves. In REM, 
the animal showed the low amplitude and high 
frequency EEG which is similar to the awake stage 
and atonic with flat EMG activity. High activities of  
theta and gamma band were the characteristics of this 
stage [2-9]. The EEG and EMG signals of three 
states are as shown in Fig 1.  
 
 
Fig 1. The EEG and EMG signals of three vigilance 
states. 
Recent Advances in Signals and Systems
ISSN: 1790-5109 120 ISBN: 978-960-474-114-4
 
Fig. 3. The activities of delta band (green line), gamma band (blue line) and alpha band (red line) of three sleep 
stages. 
 
Fig. 4. The EEG spectrum obtained by applying FFT. 
 
signal and reduce the complexity for designing the 
classification rules. Delta band and gamma band 
denote the low and high frequency signal, and they 
are the key bands for classifying sleep stages. In Fig. 
3, we measure the power of delta band as delta 
activity (green line) and the power of gamma band as 
gamma activity (blue line), respectively. One may 
find that delta activity is observed more predominant 
than other frequency bands in SWS state, and gamma 
activity is more predominant in REM and awake 
states. To further distinguish REM and awake, most 
classification methods measure EMG amplitude as 
key information, because the muscle intensity is 
lower or not observed in REM stage. One thing 
should be noticed here; unlike REM stage, we 
observe that the power strength of gamma band in 
awake state is close to the power strength of delta 
and alpha band. This motivates us to classify sleep 
stages with EEG signal only. 
 
2.2 Feature Extraction 
For any machine learning technique, the first 
work in training procedure is extracting meaningful 
features from original data. Fast Fourier Transform 
(FFT) is performed on each period of 4 seconds EEG 
signal to generate EEG spectrum, as shown in Fig. 4. 
For example, the EEG spectrum of the sixth second 
is derived from the EEG signal consisting of the 
signal between the third second to the sixth second. 
Different to above rule -based classification methods , 
the EEG spectrum is separated into 32 uniform 
frequency bands. We then calculate the relative ratio 
EEG Signal EEG Spectrum 
0 1 2 3 4 5
Time (sec)
-100
0
100
200
AD17
Rate Histograms, bin = 0.001 s
C
ou
nt
s/
bi
n
0 10 20 30 40 50
Frequency (Hz)
0
0.5
1
1.5
2
2.5
AD17
Power Spectral Densities
P
ow
er
 S
pe
ct
ra
l D
en
si
ty
 (
%
)FFT 
SWS 
Awake SWS REM 
0
20
40
60
80
100
1201 1301 1401 1501 1601 1701 1801 1901 2001 2101 2201 2301
DELTA GAMMA ALPHA
Recent Advances in Signals and Systems
ISSN: 1790-5109 122 ISBN: 978-960-474-114-4
 SWS state denoted as the yellow cluster in Fig. 5(c), 
the higher precision rate of SWS state is expectable. 
Second, most misclassified errors are occurred in 
REM and AW states, such situation can be contrast 
with Fig. 5(c). Third, although most studies in sleep 
field emphasize that the EMG signal is key factor to 
discriminate between REM and AW. However, the 
proposed classification system with EEG signal only 
provides good performance.   
 
Table. 3. The classification results of proposed 
method. 
 Prediction 
  REM SWS AW Precision
REM 88 0 9 90.70% 
SWS 0 402 1 99.75% 
AW 17 10 283 91.29% 
Ground 
Truth 
Recall 84.80% 97.60% 96.60%  
 
 
4 Conclusion 
In this paper, an automatic sleep stage classification 
system is developed based on machine learning 
technique. By simply analyzing EEG signal, the 
feature extraction of the proposed system is achieved 
by FFT and classification is performed by PCA and 
k-NN. The proposed system can obtain a prediction 
of current sleep state for each second and achieve 
95.43% accuracy rate with a short period of 
computational time. The satisfactory performance 
makes it highly suitable for a real-time application in 
the future.  
 
 
Acknowledgement: This work was supported by the 
National Science Council, Taiwan, R.O.C., under the 
Grant NSC 98-2218-E-238-001. 
 
 
References 
[1] R. P. Louis, J. Lee, and R. Stephenson, “Design 
and validation of a computer-based sleep-scoring 
algorithm,” Journal of Neuroscience Methods., 
2004, vol. 133, no. 1-2, pp. 71-80. 
[2] P. Achermann, and A.A. Borbely, 
“Low-frequency (< 1 Hz) oscillations in the 
human sleep electroencephalogram,” 
Neuroscience, vol. 81, no. 1, 1997, pp. 213-222. 
[3] A. Destexhe, D. Contreras, and M. Steriade, 
“Spatiotemporal analysis of local field potentials 
and unit discharges in cat cerebral cortex during 
natural wake and sleep states,” Journal of 
Neuroscience, vol. 19, no. 11, 1999, pp. 
4595-4608. 
[4] C. Gottesmann, “The transition from slow-wave 
sleep to paradoxical sleep: evolving facts and 
concepts of the neurophysiological processes 
underlying the intermediate stage of sleep,” 
Neuroscience & Biobehavioral Reviews, vol. 20, 
no. 3, 1996, pp. 367-387. 
[5] P. Mandile, P., S. Vescia, P, Montagnese, F. 
Romano, and A. O. Giuditta, “Characterization 
of transition sleep episodes in baseline EEG 
recordings of adult rats,” Physiology & Behavior, 
1435. vol. 60, no. 6, 1996: pp. 1435-1439. 
[6] M. Steriade, D.A. McCormick, and T.J. 
Sejnowski, “Thalamocortical oscillations in the 
sleeping and aroused brain,” Science, vol. 262, 
no. 5134, 1993, pp. 679-685. 
[7] C.H. Vanderwolf, “Hippocampal electrical 
activity and voluntary movement in the rat,” 
Electroencephalography & Clinical 
Neurophysiology, vol. 26, no. 4, 1969 pp. 
407-418. 
[8] E. Werth, P. Achermann, D.-J. Dijk and A.A. 
Borbély, “Spindle frequency activity in the sleep 
EEG: individual differences and topographic 
distribution,” Electroencephalography & Clinical 
Neurophysiology,. vol. 103, no. 5, 1997 pp. 
535-542. 
[9] J. Winson, “Patterns of hippocampal theta rhythm 
in the freely moving rat,” 
Electroencephalography & Clinical 
Neurophysiology, vol. 36, no. 3, 1974, pp. 
291-301. 
[10] C. Robert, P. Karasinski, R. Natowicz, and A. 
Limoge. “Adult rat vigilance states 
discrimination by artificial neural networks using 
a single EEG channel.” Physiology & Behavior, 
vol. 59, no. 6, 1996, pp. 1051-1060. 
 [11] Gottesmann C, et al., Automatic analysis of the 
sleep-waking cycle in the rat recorded by 
miniature telemetry. Brain Res, 1977. 132: pp.  
562-8. 
[12] Itowi, N., et al., Development of a computer 
program classifying rat sleep stages. Journal of 
Neuroscience Methods, 1990. 31(2): pp. 137-43. 
[13] Clark, F.M. and M. Radulovacki, An 
inexpensive sleep-wake state analyzer for the rat. 
Physiology & Behavior, 1988. 43(5): pp. 681-3. 
[14] Ruigt, G.S., J.N. Van Proosdij, and L.A. Van 
Wezenbeek, A large scale, high resolution, 
automated system for rat sleep staging. II. 
Validation and application. 
Recent Advances in Signals and Systems
ISSN: 1790-5109 124 ISBN: 978-960-474-114-4
  2 
國科會補助出席國際會議報告 
 
                                           98  年   09   月   25   日 
報告人姓名 周 建 興 服務機關名稱（請註明系所）及職稱 萬能科技大學電子系助理教授 
會議期間及地點 自 2009 年 09 月 3 日至     
2009 年 09 月 5 日(匈牙利) 
國科會核定 
補助文號 
  98 年  05 月 13 日 
計畫編號：NSC 98-2218-E-238 
-001 
會議名稱 
（ 中文 ）第九屆訊號、語音與影像處理之國際研討會 
（  英 文  ） The 9th International SIGNAL, SPEECH AND IMAGE 
PROCESSING (SSIP 09) 
發表論文題目 （ 中文 ）以機器學習為基礎之鼠類睡眠狀態之分類系統 
（ 英文 ）A Machine Learning Approach to Classify Sleep Stages of Rats 
報告內容應包括下列各項： 
一、參加會議經過 
二、與會心得 
三、建議 
四、攜回資料名稱及內容 
五、其它 
 
  4 
附件二 
 
投稿至 Expert Systems and Applications 期刊審查中 
 
 
A Machine Learning Approach to Classify Vigilance 
States in Rats 
 
Zong-En Yu1, Chung-Chih Kuo2,3, Chien-Hsing Chou4*,  
Chen-Tung Yen5, Fu Chang6 
 
 
Department of Electrical Engineering, National Taiwan University, Taiwan1 
Institute of Neuroscience, Tzu Chi University, Taiwan 2 
Institute of Phsyiological and Anatomical Medicine, Tzu Chi University, Taiwan 3 
Department of Electrical Engineering, Tamkang University, Taiwan 4* 
Institute of Zoology, National Taiwan University, Taiwan5 
Institute of Information Science, Academia Sinica, Taipei, Taiwan6 
 2 
classification method for analyzing EEG signals in rats. The EEG signals were transferred by 
fast Fourier transform before extracting features. These extracted features were then used as 
training patterns to construct the proposed classification system. The proposed classification 
system contains two functional units. The first unit is principle component analysis (PCA) 
method, which is used to project the high dimensional features into the lower dimensional 
subspace. The second unit is the k-nearest neighbor (k-NN) method, which identifies the 
physiological state in each EEG signal epoch. Based on the results of analyzing 810 epochs 
of EEG signal, the proposed classification method achieves satisfactory classification 
accuracy for vigilance states. Based on machine-learning algorithms, the classifier learns to 
approach the configuration that best fits the categorization task. Therefore, additional training 
in searching best parameters and thresholds can be avoided. Moreover, the PCA algorithm 
projects data instances into a 3-D space, making it possible to visualize state-changing 
dynamics. Experimental results show that the proposed machine-learning based classifier 
performs better than conventional vigilance state classification algorithms. The results also 
suggest that it is possible to identify the vigilance states with only EEG signals using the 
proposed pattern recognition technique. 
Keywords: vigilance stages, pattern classification, EEG, machine learning, PCA, k-NN 
 
1. Introduction 
Sleep is a physiological state composed of different stages. Electroencephalogram (EEG) 
analysis shows that typical patterns of activity are correlated with different stages of sleep, 
wakefulness, and some pathophysiological processes, such as seizures. It is important for the 
researchers to be able to identify sleep stages in some cases, for example, in sleep deprivation 
and seizure studies [1-5]. Typically, sleep stages can be identified by the combination of EEG, 
electromyogram (EMG), electroosculogram (EOG) and visual behavioral monitoring. 
However, it is a time-consuming task to score these vigilance states manually even when the 
 4 
(20-50 Hz) power levels [16]. The SWS state, which is defined by a high amplitude and low 
frequency EEG, begins with a sleep spindle and is dominated by delta (0.5-4 Hz) waves. In 
the REM state, the animal also shows the low amplitude and high frequency EEG results 
characteristic of the AW state. However, the animal is atonic and shows flat EMG activity. 
High activity in the theta and gamma bands are also characteristics of REM state [6, 7, 16], as 
Fig. 1 shows. 
 
  
(a)         (b) 
 
(c) 
Fig. 1. (a) The rat in our experiment. (b) The EEG and EMG signals of three vigilance states. 
(c) The spectrum of three vigilance states. 
 
The current study also adopts machine learning techniques to develop an automatic 
classifier to classify the vigilance states of rats. The typical signals of one channel EEG 
recording in 3 different states were labeled in advance. A machine-learning based 
classification system was then constructed to recognize the patterns in the test data for 
 6 
2.1 EEG Recordings 
For continuous EEG monitoring, recording electrodes were chronically implanted on the 
skull of the rat. The rat was initially anesthetized with sodium pentobarbital (50mg/kg). 
Ketamine hydrochloride was administrated as necessary to maintain the depth of anesthesia 
so the animal did not exhibit the flexor reflex during surgery. Rats were mounted on a 
stereotaxic apparatus. For EEG recording, a parietal electrode was implanted on the same 
level of bregma and 4mm lateral to the midline. The signal was referenced to a ground 
electrode implanted over the cerebellum. The signal was connected to personal computer 
using a connector. All of the instruments were sealed and secured to the skull with dental 
cement, and the skin was sutured with wound clips. The rat was allowed to recover for one 
week. 
Before the start of recording, rats were placed in a test chamber for 4 hours per day to 
habituate them to the recording environment. On the recording day, the rats were temporarily 
anesthetized with halothane (4% in pure oxygen) when connecting the cable and headstage to 
the connector on the rat skull. After the rat stopped inhaling halothane, it was placed in the 
recording chamber for 30 minutes to get accustomed to the recording environment. The EEG 
and rat behavior were recorded simultaneously. 
 The EEG and EMG signals were recorded with a Multi-channel Neuronal Acquisition 
Processor system (MNAP, Plexon, Dallas, TX) and passed from the headstage to an amplifier 
and band-passed-filtered (EEG filter: 0.7 ~ 170 Hz, gain: 1000-5000). The rat’s EEG signals 
were recorded for 2 to 6 hours at a sampling rate of 1K Hz. The recorded files were dealt 
offline with Neuroexplorer (Nex technology). EEG signals were then transformed into 
frequency information with fast Fourier transform (FFT) [38-40]. The EEG power spectrum 
was calculated with 4-second window size and 1-second overlap. 
The electrical activity of the EEG is a measure of the extracellular current flow from the 
activity of many neurons. This electrical activity originates from neurons in the underlying 
 8 
2.2 Feature Extraction 
This study computes the EEG spectrum using the FFT method with a 4-second window 
size, a frequency range from 0 to 50 Hz, and a resolution of 32 frequency bands, as Fig. 4 
shows. The power of each frequency band is normalized by the sum of power for each 
frequency band. As a result, the EEG in each epoch can be transformed into 32 numbers and 
used as the classifier input. 
 
Fig. 4. The EEG spectrum obtained by applying FFT. 
 
Before constructing the classification system, a well-experienced expert made sure that 
the training and testing patterns were accurately labeled the corresponding vigilance state. 
The data were categorized into one of three states by examining EEG and EMG activity and 
the locomotor behavior in video files. A total of 108 and 810 EEG epochs were used as the 
training and testing patterns, respectively. Table 1 lists the number of epochs in each state. 
 
 
 
 10 
good accuracy rates, and is also easily implemented. To determine the appropriate number of 
components used in PCA and the parameter k in k-NN, we perform a cross validation 
operation that partitions all training samples employed in the experiment into five folds. We 
conducted five tasks, using four folds in each task as training data to construct k-NN 
classifiers and the remaining fold as testing data. For a specific number of PCA components, 
we selected the value of k that maximizes the average accuracy rate in the five tasks. Figure 5 
shows the average accuracy curve for different numbers of components. The highest accuracy 
occurs when using 6 components, but the proposed method also achieves comparable 
accuracy using 3 components. This figure also illustrates that the top 3 components achieve a 
96.4% average prediction accuracy rate for the training patterns. Finally, these top 3 
components are used to project the data patterns into a 3-D subspace. This approach makes it 
possible to visualize classification performance. In Fig. 6, the 3-D k-NN classifier is 
constructed by projecting 108 training patterns (epochs) into a 3-D space. The data patterns 
of SWS (yellow dots), AW (red dots) and REM (blue dots) form 3 clusters in the 3-D space.  
 
Fig. 5. Average accuracy curve of the cross-validation results. The x-axis denotes the top x 
components are used, while the y-axis denotes the average accuracy of the cross-validation. 
 12 
 
Fig. 7. Visualization of the testing patterns by projecting them into a 3-D subspace. 
 
The proposed classification system requires less than 1 second to categorize 810 testing 
patterns, achieving a 95.43% accuracy rate. Table 2 provides more classification results. 
Some observations are summarized. First, all precision rates are over 90%, especially for 
SWS state (99.75%). In contrast with the patterns of SWS state denoted as the yellow cluster 
in Fig. 7, the higher precision rate of SWS state is expected. Second, the most 
misclassification errors occurred in the REM and AW states, the situation can be also contrast 
with Fig. 7. Third, although most studies in the sleep field emphasize the EMG signal as the 
key factor in discriminating between REM and AW. However, the proposed EEG signal 
classification system also achieves good performance.   
 
SWS 
AW 
REM 
 14 
3.3 Comparison with Louis et al.’s Algorithm 
 
This study also compares the proposed methods with the automated sleep staging 
algorithm proposed by Louis et al. [7]. Louis et al.’s algorithm divides the EEG into five 
frequency bands: delta (δ; 1.5–6 Hz), theta (Θ; 6–10 Hz), alpha (α; 10.5–15 Hz), beta (β; 
22–30 Hz), and gamma (γ; 35–45 Hz). This algorithm makes predictions according to the 
following steps: 
 
Step 1: If the EMG amplitude is greater than the threshold T0, output AW. 
Step 2: If the EEG amplitude ratio (δ × α)/(β × γ) is greater than the threshold T1, output 
SWS. 
Step 3: If the EEG amplitude ratio Θ2/(δ × α) is greater than the threshold T2, then output 
“REM”. Otherwise, output AW. 
 
Because our comparisons do not consider the EMG amplitude, Step 1 is skipped here. The 
threshold T1 and T2 should be decided before prediction. The value range of the threshold T1 
is set to {T1 = 0.1, 0.5, 0.75, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 2}, and the value range of 
threshold T2 is set to {T2 = 0.1, 0.5, 0.75, 1, 1.1, 1.2, 1.3, 1.5, 1.8, 1.9, 2, 2.1}. Then, the 
optimal thresholds (T1, T2) are set as (1.1, 2) after applying 5-fold cross validation to the 
training patterns. Table 4 shows that Louis et al.’s algorithm ultimately obtains an 81.61% 
accuracy rate for the testing patterns.  
 
Table 4. Testing performance of two automatically vigilance stages classification methods. 
Method Testing Accuracy Rate (%) 
PCA+k-NN 95.43 
Louis et al.’s Algorithm 81.61 
 16 
 
(a) 
 
(b) 
Fig. 8. (a) Box plot of the first principle component. (b) Box plot of the second principle 
component. 
 
 18 
5. Conclusion 
This paper proposes a machine-learning based classifier for identifying the vigilance 
states in rats. Users may benefits from this classifier in two ways. 1) Human intervention in 
tuning the threshold and system parameters is not necessary, as this has been replaced by the 
machine learning algorithm. 2) The classification results can be visualized by projecting the 
data patterns into a 3-D space using principle component analysis, allowing users to evaluate 
the validity of their classification results. Moreover, the spectral weight of the top two 
components indicates that a part of the high frequency and low frequency band play 
important roles.  
 
Acknowledgement: This work was partly supported by the National Science Council, 
Taiwan, R.O.C, under the NSC 98-2218-E-238 -001 and the NSC 99-2221-E-238 -017. 
 
References 
[1] Balkin, T.J., O'Donnell, V.M., Kamimori, G.H., Redmond, D.P., & Belenky, G. (1989). 
Administration of triazolam prior to recovery sleep: effects on sleep architecture, 
subsequent alertness and performance. Psychopharmacology, 99(4), 526-531. 
[2] Mendelson, W.B., & Bergmann, B.M. (2001). Effects of pinealectomy on baseline sleep 
and response to sleep deprivation. Sleep, 24(4), 369-373. 
[3] Bagshaw, A.P., Jacobs, J., LeVan, P., Dubeau, F., & Gotman, J. (2008). Effect of sleep 
stage on interictal high-frequency oscillations recorded from depth macroelectrodes in 
patients with focal epilepsy. Epilepsia, 50(4), 617-628. 
[4] Marzec M.L., Malow, B.A., (2003). Approaches to staging sleep in polysomnographic 
studies with epileptic activity. Sleep Medicine, 4(5), 409-417.  
[5] Natarajan, A., Marzec, M.L., Lin, X., Minecan, D., & Malow, B.A. (2002). Interictal 
epileptiform discharges do not change before seizures during sleep. Epilepsia, 43(1), 
 20 
Jessell (Eds.). Principles of Neural Science. New York. 
[17] Müller, K.R., Krauledat, M., Dornhege, G., Curio, G., & Blankertz, B. (2004). Machine 
learning techniques for brain–computer interfaces. Biomedical Engineering, 49(1), 11–22. 
 
[18] Kaper, M., Meinicke, P., Grossekathoefer, U., Lingner, T., & Ritter, H. (2004). BCI 
competition 2003–data set IIb: support vector machines for the p300 speller paradigm. 
IEEE Trans. Biomed. Eng., 51(6), 1073–1076. 
[19] Garrett, D., Peterson, D.A., Anderson, C.W., & Thaut, M.H. (2003). Comparison of 
linear, nonlinear, and feature selection methods for EEG signal classification. IEEE Trans. 
Neural Syst. Rehabil. Eng., 11(2), 141–144. 
[20] Hiraiwa, A., Shimohara, K., & Tokunaga, Y. (1990). EEG topography recognition by 
neural networks. IEEE Engineering in Medicine and Biology Magazine, 9(3), 39–42. 
[21] Anderson, C.W., & Sijercic, Z. (1996). Classification of EEG signals from four subjects 
during five mental tasks Solving Engineering Problems with Neural Networks. Proc. Int. 
Conf. on Engineering Applications of Neural Networks, 407-414.  
[22] Acir, N., & C. Güzeli , (2004). Automatic recognition of sleep spindles in EEG by using 
artificial neural networks. Expert Systems with Applications, 27(3), 451-458.  
[23] Güler, N.F., Übeyli E.D., & Güler, I. (2005). Recurrent neural networks employing 
Lyapunov exponents for EEG signals classification. Expert Systems with Applications, 
29(3), 506-514. 
[24] Acir, N. (2005). Automated system for detection of epileptiform patterns in EEG by 
using a modified RBFN classifier. Expert Systems with Applications, 29(2), 455-462. 
[25] Yildiz, A., Akin, M., Poyraz, M. & Kirbas, G. (2009). Application of adaptive 
neuro-fuzzy inference system for vigilance level estimation by using wavelet-entropy 
feature extraction. Expert Systems with Applications, 36(4), 7390-7399. 
[26] Tavakolian, K., & Rezaei, S. (2004). Classification of mental tasks using Gaussian 
 22 
Engineering. In B. He (Ed.). Neural Engineering (pp. 85–122). Kluwer/Plenum 
Publishers.  
[37] Lotte, F., Congedo, M., Lécuyer, A., Lamarche, F., & Arnaldi, B. (2007). A review of 
classification algorithms for EEG-based brain–computer interfaces. Journal of Neural 
Engineering, 4(2), R1-R13. 
[38] Cooley, J.W., & Tukey, J.W. (1965). An algorithm for the machine calculation of 
complex Fourier series. Math. Comp., 19, 297-301. 
[38] Brigham, E.O. (1974). The Fast Fourier Transform. Prentice-Hall, Englewood Cliffs, 
NJ. 
[40] Brigham, E.O., & Yuen, C.K. (1978). The Fast Fourier Transform. IEEE Transactions on 
Systems, Man and Cybernetics, 146-146. 
[41] Hart, P. (1968). The condensed nearest neighbor rule. IEEE Trans. Information Theory, 
14, 515-516. 
[42] Chou, C.H., Kuo, B.H., & Chang, F. (2006). The Generalized Condensed Nearest 
Neighbor Rule as A Data Reduction Method. 2006 International Conference on Pattern 
Recognition, 2, 556-559. 
[43] Werbos, P.J. (1974). Beyond regression: new tools for prediction and analysis in the 
behavioral sciences. Doctoral dissertation, Harvard University. 
[44] Rumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986). Learning internal 
representations by error propagation. In D.E. Rumelhart & J.L. McClelland (Eds.). 
Parallel Distributed Processing. Cambridge, MA: MIT Press. 
[45] Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20(3), 
273-297. 
[46] Vapnik, V. (1995). The Nature of Statistical Learning Theory. New York: Springer 
Verlag. 
[47] Pearson, K. (1901). On Lines and Planes of Closest Fit to Systems of Points in Space. 
  5 
附件三 
 
Apper in “Tamkang Journal of Science and Engineering” 
 
 
A Reinforcement-Learning Approach to Color 
Quantization 
Chien-Hsing Chou1*, Mu-Chun Su2, Yu-Xiang Zhao3, Fu-Hau Hsu2 
 
Department of Electrical Engineering, Tamkang University, Taiwan1* 
Department of Computer Science & Information Engineering, National Central 
University, Taiwan2 
Department of Computer Science & Information Engineering, National Quemoy 
University, Taiwan3 
 
 2 
1. Introduction 
    True type color images can consist of more than 10 million (224) possible colors in a 24 bit full 
RGB color space. Consequently, it is very important in games and mobile devices to reduce the number 
of image colors for presentation, transmission and compression of color images. The most popular 
techniques for color reduction in digital images are the multithresholding and color quantization 
approaches. In the multithresholding approach, proper thresholds are determined from color histograms 
defining the limits of the image color classes [1]-[5]. Since the approach is based on the assumption 
that object and background pixels in an image can be well distinguished by their colors, the 
multithresholding approach does not give satisfactory results in the case of complex images such as 
natural or textured images. 
In color quantization, a true color image is irreversibly transformed into a color-mapped image 
consisting of K carefully selected representative colors. The ultimate goal of color quantization is to 
select K representative colors to ensure minimization of a specific distortion measure between the 
original and the quantized images [6]-[17]. In general, these color quantization algorithms can be 
divided into two main categories: (a) splitting algorithms [7]-[10] and (b) clustering-based algorithms 
[6], [11]-[17]. In this paper, we aim at improving the clustering-based algorithms. The performance of 
these clustering-algorithm-based techniques varies greatly depending on how the K representative 
colors are chosen. These techniques have to make a tradeoff between their computational efficiency 
and minimization of the distortion measure. For example, the K-means algorithm can efficiently 
minimize the quantization error if enough number of iterations are allowed [12]-[13]. Hsieh and Fang 
proposed an adaptive clustering (AC) algorithm for color quantization [14], in their algorithm the 3D 
RGB histogram of an input image is calculated first to generate a sorted histogram bin list. Then the K 
palette colors corresponding to the representative dominant colors are generated from the sorted 
histogram bin list. By controlling carefully for a distance threshold, the palette colors will be adaptively 
determined for the best situation. However, the authors did not provide guidance in how to choose an 
appropriate distance threshold. It is the quest for resolution of this question which motivated us to use a 
 4 
2.1. Brief Review of AC Algorithm 
The AC algorithm is briefly described as follows: 
Step 1: Accumulate all the pixels with the same color in the input image to form a 3D RGB color 
histogram. The bN  least significant bits of each color component are set to be zero while the 
histogram is calculated, where the parameter bN  is determined by the user. Here we assume 
that the number of the histogram bins is C. For example, each of two color images shown in Fig. 
1 consists of 256256 ×  pixels. We first sum up the histogram bins for the two images. Fig. 1(a) 
and 1(b) contain a total of 61,389 and 33,870 different colors, respectively. Then, the three least 
significant bits ( 3=bN ) of each color component (R, G and B) are set to be 0. The number of 
reduced histogram bins, C, of Fig. 1(a) and 1(b) become 2,860 and 992, respectively. The 
advantage of such a procedure is that the reduced RGB color space design can not only shorten 
the execution time but also easily locate the dominant colors in the image. Furthermore, Fig. 1(a) 
contains more histogram bins than Fig. 1(b) does. This means that Fig. 1(a) is more colorful 
than Fig. 1(b). In our opinion, one should also consider this information in quantizing a color 
image. More details are given in Section 3. 
  
(a)          (b) 
Fig. 1. Two color images. (a) Baboon; (b) House. 
 
Step 2: Sort the histogram bins in a descending order according to the histogram values. Table I shows 
the list of the top 5 ordered histogram bins for Fig. 1(a). 
 6 
Step 4: Re-calculate the R, G and B values of each dominant color as the weighted average of the R, G 
and B values of all the bins assigned to it. 
    By controlling the distance threshold η  carefully, the palette colors will be adaptively 
determined for the best situation. However, Hsieh and Fan did not provide guidance about how to 
choose appropriate 0η  and dη . They empirically set the initial distance threshold 0η  to be 
3 3255 K . And they set the decreasing parameter dη  to be 4 if the number of unfound dominant 
colors is larger than 64, otherwise they set dη  to be 2.  
Through our experiments with setting different 0η  and dη , we found that the performance of the 
AC algorithm greatly depends on these two parameters (especially 0η ). Better results could be 
achieved if the appropriate parameters 0η  and dη  were used in the clustering algorithm. We apply an 
AC algorithm to quantize Fig. 1(b) with Hsien and Fan’s suggestion and 7 different sets of 0η  and dη , 
for which the peak signal-to-noise ratio (PSNR) values are given in Table II. According to the 
performance results as shown in Table II, we have following observations: First, Hsien and Fan’s 
suggestion of 0η  and dη  doesn’t achieve the optimal performance. Second, the best set of 
parameters 0η  and dη  among the entire sets is not identical for quantizing different color numbers 
(color numbers of 8 and 16 in this case). Through some experiments, we also found that selecting an 
appropriate 0η  and dη  is related to the desired number of quantization level K, and the number of 
histogram bins C of the input image. This means that we need an expert or a prediction system to 
provide appropriate 0η  and dη  to deal with varied quantizing conditions. These findings motivated 
us to use a learning system to predict 0η  and dη  under different conditions of K and C. However, we 
are unable to construct the training data set to train a learning system through supervised learning since 
we lack knowledge of the input-output relationship between the input parameters K and C and the 
desired output 0η  and dη . Hence, one possible way to solve this problem is to apply reinforcement 
learning to construct a learning system. In our previous work [25], the ACSNFIS uses a special 
reinforcement learning algorithm to incrementally construct its architecture and tune the system 
 8 
Layer 1: 















 −
−
=








−−
== ∑
=
n
i ji
jii
j
j
jj
wxwx
xmO
1
2
2
2
,1
)(
2
1
exp
2
||
exp)(
σσ
     (3) 
Layer 2: jbidjjbidjjj BCSxmCSOO =⋅⋅=⋅⋅= )(,1,2         (4) 
Layer 3: 
∑
=
== J
i
i
j
jj
B
B
BO
1
,3 '               (5) 
Layer 4: '
,4 jjj BCO =                (6) 
Layer 5: ∑
∑
∑
∑
∑
=
=
=
=
=
====
J
j
J
i
iibid
jjbid
j
J
j
J
i
i
j
j
J
j
jjj
xmSC
xmSC
C
B
B
CBCxOutO
1
1
1
1
1
,5
)(
)(
')(       (7) 
where jiO ,  represents the output of the jth node in the ith layer, [ ]Tjnjj www ,...,1=  and 
[ ]Tjnjj σσσ ,...,1=  are adaptive parameters, jS  is the strength of the jth fuzzy rule, bidC  is a constant 
related to the bid coefficient ( 10 ≤< bidC ), jB  is the bid of the jth hidden node, and jC  is an 
adaptive parameter which represents the consequent part of the jth rule. The fuzzy rules in the system 
can then be represented as 
jR : IF ( x  is jHE )               (8) 
THEN the system output is jC  with strength jS   
where x  is an n-dimensional input vector. The fuzzy set, jHE , defines an n-dimensional 
hyper-ellipsoid, 1
2
1
=







 −
∑
=
n
i ji
jii wx
σ
, which has the membership function, 















 −
−= ∑
=
2
12
1
exp)(
n
i ji
jii
j
wx
xm
σ
, to measure the degree of an input vector, x , belonging to the fuzzy 
set jHE . The parameter jC  is the consequent part of the jth rule. 
 
 10 
success. The parameters of the system are adjusted based on the temporal difference of the 
reinforcement signal, )()1( trtr −+ . 
 
 
Fig. 3. The proposed ACSNFIS system in the reinforcement-learning environment. 
In order to learn behavior through trial-and-error interaction in a dynamic environment, the 
proposed system can explicitly explore its environment and exploit the new rules automatically. The 
architecture of the neuro-fuzzy system is incrementally constructed during the training procedure. First, 
the system starts with no hidden node (i.e. no fuzzy rule). During the learning procedure, we will 
exploit a new rule if none of the existing rules has good enough response to the current state (i.e. 
mjJj
txm θ≤
=
)}(({max
,...1
, where mθ  is a pre-specified threshold and J represents the current number of rules 
in the present system). At the same time, we also need to eliminate useless rules so as to keep the 
number of rules as small as possible. Those fuzzy rules whose strengths are weaker than a pre-specified 
threshold, sθ , (i.e. sj tS θ<)( ) will be eliminated during the training procedure. This elimination 
criterion is reasonable. If the strength of a rule is below a pre-specified threshold sθ , it means that this 
rule often results in bad actions during the training procedure. 
 12 
Condition 1: IF trtrtr >−+ )()1(  
           THEN  we update jw  and jσ  in the following ways: 
        ))()()((')()1( twtxtBtwtw jjjj −⋅+=+ δ  
        sjjj tBtt σδσσ )(')()1( ⋅+=+         (10) 
Condition 2: IF trtrtr −<−+ )()1(  
           THEN  we update jw  and jσ  in the following ways: 
        ))()()((')()1( twtxtBtwtw jjjj −⋅−=+ δ  
        sjjj tBtt σδσσ )(')()1( ⋅−=+         (11) 
Condition 3: IF tt rtrtrr ≤−+≤− )()1(  
           THEN  we do not update jw  and jσ         (12) 
where tr  and sσ  are two positive real-valued constants pre-specified by the user, and δ  is the 
learning rate determined by the user. If )()1( trtr −+  is larger than tr , it means that the performance 
is improved to a certain degree, and if )()1( trtr −+  is smaller than - tr , it means that the performance 
becomes worse to a certain degree. Obviously, the rule in Eq. (11) will result in the increase of the 
membership degree ))(( txm j  when the system encounters the same state )(tx  while the rule in Eq. 
(12) decreases the membership degree ))(( txm j . This makes the updated system more likely respond 
to that state, )(tx , in the future.  
 
 
3. The Proposed Modified Adaptive Clustering Algorithm 
In this section, we proposed the modified adaptive clustering (MAC) algorithm combined with 
ACSNFIS and AC algorithm. Fig. 4 shows the architecture of the MAC algorithm. In our conception, 
choosing the suitable values of 0η  and dη  should be related to the desired number of quantization 
 14 
 
 
Fig. 4. The architecture of the modified adaptive clustering (MAC) algorithm combining the ACSNFIS 
with the AC algorithm. 
 
   In the ACSNFIS, the crucial problem is how to determine a reinforcement signal. The success of 
training the ACSNFIS through reinforcement learning is always related to providing an appropriate 
reinforcement signal. Before we introduce our chosen method to determine the reinforcement signal, 
we first define how to evaluate the performance between an original image and its quantized image. 
The PSNR is usually adopted to evaluate this performance. Consequently, it can be used as the basis of 
the reinforcement signal. The PSNR is defined as follows:  




















−
⋅⋅
=
∑∑ ∑
= = =
W
i
H
j k
kjiBkjiA
HW
PSNR
1 1
3
1
2
2
10
))..(),,((
3
1
255log10
        (13) 
where ),,( kjiA  and ),,( kjiB  are the RGB values of pixel (i, j) taken from the original image and 
its corresponding quantized image, respectively. 
Here, we use twenty color images for training, and some of them are shown in Fig. 5. For all 
training images, we apply the K-means algorithm [27] to quantize the training images with nK 2= , for 
9,,2,1 K=n . For each run we continued the K-means algorithm until 50 iterations were reached. Table 
III tabulates the resulting PSNR values achieved for Fig. 5(a).  
 16 
After we obtain the PSNR values of all training images, the reinforcement signal, )(tr , of the 
ACSNFIS with different K is further determined to be: 
IF )()( KPSNRKPSNR KMMAC >  
THEN 1)( =tr ; 
ELSE IF )10)(()()( −≥≥ KPSNRKPSNRKPSNR KMMACKM  
THEN 
10
)10)(()()( −−= KPSNRKPSNRtr KMMAC ;       (14) 
ELSE 0)( =tr ; 
where )(KPSNRMAC  and )(KPSNRKM  represent the PSNR values resultant from the MAC algorithm 
and the K-means algorithm, respectively. The idea of using the reinforcement signal given in Eq. (14) 
is very straightforward. If the MAC algorithm achieves comparable performance to the K-means 
algorithm, we can obtain a larger value of r(t). Otherwise, r(t) will have a lower value when the MAC 
algorithm performs worse than the K-means algorithm. If nK 2≠ , for 9,,2,1 K=n , we can simply 
use the linear interpolation to approximate the values of )(KPSNRKM . One thing should be noticed 
here. In the training process of the MAC algorithm, the K-means algorithm is applied to compare the 
quantized image of MAC, and generate the reinforcement signal r(t) by Eq. (14). Then the 
reinforcement signal r(t) is used to update the parameter of the MAC algorithm. However, the K-means 
algorithm is not executed in the testing process, because we don’t need to generate the reinforcement 
signal and update the parameter of the MAC algorithm. 
Besides, in the training process, the final goal is to generate a well-trained MAC algorithm that 
may outperform K-means with 50 times iteration for the entire training images. In fact such situation is 
never met in the training process, however, the eq. (14) should still consider this situation if MAC 
outperform K-means. Finally the temporal difference of the reinforcement signal will be used to reward 
or punish the strength of each rule by using the Reward Mechanism [25].The training task was 
decomposed into three sub-tasks such as are shown in Table IV. At each sub-task, we trained the 
ACSNFIS for 500 trials. After 1500 trials, the ACSNFIS established 89 fuzzy rules. 
 
 18 
first comparison, the K-means algorithm achieves the highest PSNR for several cases, especially for the 
Tiffany image (Fig. 8). But it also pays the price of having the longest computational time. The 
proposed MAC algorithm achieves the highest PSNR on the other cases, especially for the Science 
image (Fig. 9). Moreover, we observe that the MAC algorithm requires the least processing time of all 
the cases. This means that the MAC algorithm achieves comparable performance (PSNR) to K-means 
algorithm but only spends about 20% of the required execution time on average. Here we would like to 
emphasize that if the KM algorithm is processed more than 30 to 50 iterations, the performance of the 
KM algorithm will outperform the MAC algorithm in all cases. However, this level of performance 
necessitates a very long computational time. We also observe that the computation time of the MAC 
algorithm is shorter than that of the AC algorithm in all cases (computational time is reduced by 10.4% 
on average). According to the experimental results, we show that our proposed MAC algorithm 
outperform the AC algorithm in execution time and PSNR value.  
 20 
   
(a)         (b) 
  
(c)         (d) 
Fig. 6. Test results for Jet image. (a) The original image. The quantized images with 32 colors by using 
(b) AC; (c) K-means; (d) MAC algorithm. 
 22 
  
(a)        (b) 
  
(c)        (d) 
Fig. 8 Test results for Tiffany image. (a) The original image. The quantized images with 32 colors by 
using (b) AC; (c) K-means; (d) MAC algorithm. 
 
 24 
Additionally, we also designed a questionnaire completed by 20 persons to compare the quantized 
images after having been processed by the three different methods (i.e. Figs. 6(b)-9(b), 6(c)-9(c) and 
6(d)-9(d) for K=32), with the original images (Figs. 6(a)-9(a)). The questionnaire contains five rating 
scale as shown in Table VI. The higher score in the scale means that the quantized image appears more 
similar to the original image. Table VII shows the average scores of the three methods as obtained from 
the qualitative survey questionnaires.  
 
Table VI. Five rating scales in the questionnaire. 
 
 
Table VII. The average scores for the three methods. 
Testing Image Image Size C AC KM MAC 
Jet 256×256 765 2.85 3.15 4 
Waterfall 172×256 592 3.05 2.8 2.85 
Tiffany 256×256 638 2.2 4.05 2.55 
Science 222×256 1134 2.95 2.3 3.15 
Average 2.76 3.08 3.14 
 
Comparing the results in Table VII with that in Table V, we make the following observations: 
(1) In terms of the average score, the MAC algorithm ranks first in Fig. 6 and Fig. 9, the AC algorithm 
ranks first in Fig. 7, and the K-means algorithm ranks first in Fig. 8. 
(2) The MAC algorithm achieves the highest average score. 
(3) The average scores of the three methods for Fig. 6, Fig. 8 and Fig.9 are positively correlated with 
the values of PSNR. However, for Fig. 7, the AC algorithm with the lowest PSNR value (31.791) 
obtains the largest average score. 
Summarizing these results in Table V and Table VII, we observe that the MAC algorithm always 
Scale Rating Words 
1 Bad 
2 Poor 
3 Fair 
4 Good 
5 Excellent 
 26 
also demonstrates that the reinforcement learning method is a proper way to provide a solution of the 
learning problem while there is a  lack of the knowledge of the input-output relationship. 
 
5. Conclusion 
In this paper, we have shown a way to apply a reinforcement learning algorithm to solve the 
problem of color quantization where there is lack of knowledge about the input-output relationship. 
Reinforcement learning is used to generate the fuzzy rules for choosing more appropriate parameters 
that are able to improve the performance of the original AC algorithm. Compared with the original AC 
algorithm in testing 30 color images, the MAC algorithm improves average PSNR values by 3.3% to 
5.8%, and with less computational time. Compared with the K-means algorithm, the MAC algorithm 
provides comparable quantized image performance but requires only 20% of the computational time.  
 
Acknowledgement: This work was partly supported by the National Science Council, Taiwan, R.O.C, 
under the NSC 98-2218-E-238 -001 and the NSC 99-2221-E-238 -017. 
 
References 
[1] J. Kittler and J. lllingworth, “Minimum error thresholding,” Pattern Recognition, vol. 19, 1986, pp. 
41–47. 
[2] N. Papamarkos and B. Gatos, “A new approach for multithreshold selection,” Comput. Vision 
Graph. Image Process.—Graph. Models Image Process., vol. 56, no. 5, 1994, pp. 357–370. 
[3] P. K. Sahoo, S. Soltani, and A. K. C. Wong, “A survey of thresholding techniques,” Comput. Vision, 
Graph. Image Process., vol. 41, 1988 , pp. 233–260. 
[4] S. S. Reddi, S. F. Rudin, and H. R. Keshavan, “An optimal multiple threshold scheme for image 
segmentation,” IEEE Trans. on System, Man, and Cybernetics, vol. SMC-14, 1984, pp. 661–665.  
[5] D. M. Tsai, “A fast thresholding selection procedure for multimodal and unimodal histograms,” 
Pattern Recognition Letters, vol. 16, no. 6, 1995, pp. 653–666. 
 28 
2009 IEEE International Symposium on Industrial Electronics, pp. 775-778, 2009. 
[18] L. P. Kaelbling, M. L. Littman, and A. W. Moore, “Reinforcement learning: a survey,” Journal of 
Artificial Intelligence Research, vol. 4, 1996, pp. 237-285. 
[19] J. H. Holland, Adaptation in natural and artificial systems, University of Michigan Press, Ann 
Arbor, MI, 1975. 
[20] J. Schmidhuber ,“A general method for multi-agent learning and incremental self-improvement in 
unrestricted environments,” In Yao, X. (Ed.), Evolutionary Computation: Theory and Applications. 
Scientific Publ. Co., Singapore, 1996. 
[21] A. G. Barto, R. S. Sutton, and C. W. Anderson, ”Neuronlike adaptive elements that can solve 
difficult learning control problems,” IEEE Trans. on System, Man, and Cybernetics, vol. 13, no. 5, 
1983, pp. 834-846. 
[22] R. S. Sutton, “Learning to predict by the methods of temporal differences,” Machine Learning, vol. 
3, 1988, pp. 9-44. 
[23] C. J. C. H. Watkins, Learning form delayed rewards. Ph.D. thesis, King’s College, Cambridge, UK, 
1989. 
[24] C. J. C. H. Watkins and P. Dayan, “Q-learning,” Machine Learning, vol. 8, no. 3, 1992, pp. 
279-292. 
[25] M. C. Su, C. H. Chou, E. Lai and J. Lee “A new approach to fuzzy classifier systems and its 
application in self-generating neuro-fuzzy systems,” Neurocomputing, vol. 69, 2006, pp. 586-614. 
[26] D. Goldberg, Genetic algorithm in search, optimization, and machine learning. Addison-Welsley, 
MA, 1989.  
[27] H. Ball and D. I. Hall, “Some fundamental concepts and synthesis procedures for pattern 
recognition preprocessors,” Proc. of Int. Conf. Microwaves, Circuit Theory, and Information Theory, 
Tokyo, Japan, Sep. 1964, pp. 281-297. 
[28] The USC-SIPI Image Database. “http://sipi.usc.edu/database/”. 
 ??? SSIP 2009 ??????? 
 
?? ?????? 
??????????????????? (The 9th International SIGNAL, 
SPEECH AND IMAGE PROCESSING)??????????????????
????????(WSEAS)???????????????(Budapest)???
??????????????????????????????????
??????????????????????????????????
?????????????????????? 
 ????????????? 198 ??????????????????
???????? 3 ?????????? 3 ???????????????
????? 
 
?????? 
 ?????????????????????????????????
???????????????????????????????????
???????????????????????????????????
???????????????????????????????????
????????????????????????????? 
 
???? 
 ????????????????????????????????
???????????????????????????????????
??????????????????????????? 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
