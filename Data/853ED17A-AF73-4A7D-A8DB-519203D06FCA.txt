I 
中文文本分析技術的開發和應用(II) (III) 
 
 
摘要 
 
 
    隨著華語文學習與使用在全球各地日受重視，中文語言處理技術的開發也愈趨重要。
目前在中文的文本分析中多著重在詞組或小句的處理上，對於句群、段落間等語義處理尚
未見廣泛的討論。因此在本計劃中，我們除了延續笫一期所進行的指代消解研究外，在第
二期計畫中，我們針對中文書面語的語篇連貫結構分析處理，提出有效的計算模組。在第
三期計畫中，我們設計一個中文文本語句主題詞之辨識法並應用所發展的文本分析技術，
進行中文作文評分與分析糸統的開發與建置。 
語篇分析是文本理解中一項不可缺乏的工作，藉以釐清文章的論題或邏輯結構。在第
二期計畫中我們提出以語料為主的語篇分析方法，針對並列、承接、遞進、選擇、轉折、
因果、條件、解證、目的等九種語篇類別，進行表層特徵收集及擴展，並制定標記規則，
以建立有效的自動標記程序。我們使用中研院平衡語料庫 3.0 版中的報導、傳記日記、散
文、信函、評論、說明手冊等文類，共 7265 篇作為探勘語料，探勘線索詞和連續詞性、特
殊標點符號等語篇特徵。我們使用 100篇平均字數為 1500字的報紙社論進行效能評估實驗，
在句內的標記部份，正確率可達到 91%。另外，在句間的標記部分，正確率可達到 86%。
我們相信此種語篇標記的研究，有助於自動問答、作文評分、閱讀測驗、摘要和簡報系統
等應用上。 
此外，我們針對時間關係進行探討。我們提出一個貝式分類器與 C4.5 決策樹的辨識中
文語篇時間關係的方法。我們使用包含位置特徵、主詞為人物、主要動詞組、時間詞組、
主要動詞前動詞、主要動詞前後副詞、時態字根、主要動詞詞性組以及小句中心一致性。
實驗數據顯示所有的特徵對於辨識都有正向的作用，在 22842 正例和 15269 負例的句內辨
識實驗中，我們使用 C4.5 決策樹可達 95.39% F-Score。 
在第三期計畫中，我們提出一個中文文本語句主題詞之辨識法。此法乃利用重心理論
並考量中文語句結構的特性，使之可應用於作文評分中的離題偵測、主題連貫性和語義概
念結構分析。我們以長句中每小句重心為基礎，分別就其頻率、位置、主題延伸性、前後
句之一致性、主題概念等特徵，進行權重設計以辨識每一完整長句的主題詞。從實驗結果
顯示此法在長句主題詞的辨識上，在 9 篇報紙社論可達 86.84%正確率，在 22 篇高中生作
文可達 80.86%正確率。另在 83 篇高中生作文的離題偵測實驗上，所提的方法也較前人所
用的詞彙方法得到較佳的偵測，辨識效果可達 63%正確率。 
    最後，我們提出一個作文分析與評量的糸統，以期對作文者和評量者有所助益。此糸
統主要的模組包括語料收集與整理、文本處理、離題偵測、主題連貫性和語義概念結構分
析、評分機制、外部知識庫和輔助查詢工具的建置。我們並整合之前所做的輔助工具包括
共現詞組萃取、相似句檢索、語篇連貫結構檢索等，以供華語學習者案例查詢。我們相信
本計劃的執行不僅對中文文本結構有深入的探討和創新的法則提出，對資訊自動化技術的
發展、和中文學習者亦有所幫助。 
 
關鍵詞: 自然語言處理、中文、文本分析、指代消解、語篇分析、作文評量 
III 
目錄 
 
 
摘要 ....................................................................... I 
Abstract ................................................................... II 
圖目錄 .................................................................... IV 
表目錄 ..................................................................... V 
第一章 前言 ........................................................ 6 
第二章 研究目的 .................................................... 7 
第三章 文獻探討 .................................................... 8 
3.1 語篇結構分析相關研究 .............................................................................................. 8 
3.2 時間關係辨識相關研究 .............................................................................................. 8 
3.3 主題詞辨識相關研究 .................................................................................................. 9 
3.4 作文分析與評分相關研究 ........................................................................................ 10 
第四章 研究方法 ................................................... 11 
4.1 語篇結構分析方法 .................................................................................................... 11 
4.1.1 語篇線索詞探勘 ............................................................................................ 11 
4.1.2 辨識及標記執行步驟 .................................................................................... 12 
4.1.3 實驗設計與分析 ............................................................................................ 13 
4.2 時間關係辨識方法 .................................................................................................... 13 
4.2.1 語料庫建立 .................................................................................................... 13 
4.2.2 辨識特徵擷取 ................................................................................................ 14 
4.2.3 實驗設計與分析 ............................................................................................ 16 
4.3 主題詞辨識方法 ........................................................................................................ 16 
4.3.1 小句重心辨識 ................................................................................................ 16 
4.3.2 長句主題詞辨識 ............................................................................................ 17 
4.4 作文分析與評分 ........................................................................................................ 19 
4.4.1 作文語料分析 ................................................................................................ 19 
4.4.2 離題偵測 ........................................................................................................ 20 
4.4.3 連貫性評量 .................................................................................................... 20 
4.4.4 文章概念結構 ................................................................................................ 21 
4.5 中文篇章處理分析系統 .................................................................................................. 22 
第五章 研究成果 ................................................... 26 
第六章 結果與討論 ................................................. 27 
參考文獻 .................................................................. 27 
附錄 
 
 
 
 
V 
表目錄 
表 1：語篇連貫關係類別 .......................................................................................................................................... 11 
表 2：語篇連貫關係辨識及標記步驟 ....................................................................................................................... 12 
表 3：語篇連貫關係標記符號表 ............................................................................................................................... 12 
表 4：語料庫資料 ...................................................................................................................................................... 14 
表 5：正負例例數 ...................................................................................................................................................... 14 
表 6：特徵出現頻率列表 .......................................................................................................................................... 15 
表 7：長句句內實驗結果 .......................................................................................................................................... 16 
表 8：特徵組合長句句內實驗 ................................................................................................................................... 16 
表 9：重心模型 .......................................................................................................................................................... 17 
表 10：長句主題詞特徵表 ........................................................................................................................................ 18 
表 11：社論語料之長句主題詞辨識實驗結果 ......................................................................................................... 19 
表 12：作文分數分佈情形 ........................................................................................................................................ 19 
表 13：「最上一層樓」離題實驗結果 ....................................................................................................................... 20 
表 14：「最上一層樓」作文 未/含重複到訪主題之比較 ........................................................................................ 21 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                                                            
第二章 研究目的 
有鑑于有效的自動語篇分析有助於釐清文章的論題或邏輯結構，而目前關於中文語篇的計算模
組及標記語料皆十分缺乏。因此在本計畫中，我們將針對語篇連貫結構提出有效的標記程序，並建
立一個可資參考評量的語篇標記語料。目前，我們針對常見的如並列、承接、遞進、轉折等語篇結
構關係，提出以語料為主的分析方法。我們利用統計方法進行表層特徵如線索詞、連續詞性、特殊
標點符號等收集及擴展並制定標記規則。 
再者時間關係是連貫關係的一類，可作為判定文章語義的線索。時間關係是指兩個語段在時間
上或是先後發生，或是同時發生，或是具有明確時間點。時間關係中任一片段可能是描述「狀態」
與「事件」，因此具時間關係的兩片段中至少其中之一是事件。我們提出一個使用特徵來辨識時間
關係的方法，從語料中挑選有用的特徵，利用機器學習方式挑選出最佳組合，以有效地辨識文章中
含時間關係的句子。 
從實際的應用上，正確的語篇結構分析不僅有助於作文評分系統中語義連貫的判別[Burstein et 
al., ‗98]和文章結構完整性的檢驗[Anthony and Lashkia, ‗03] ，亦有助於答問系統對解釋型或敘述型
答案的辨識。其它的應用還有自動摘要[Chan et al., ‗00]和自動投影片產生系統[Tomohide et al., ‗05]，
利用分析語篇的結構找出文本中各個小句之間的連貫關係，抽出關鍵的主題句作為投影片的內容。
因此我們將語篇分析工具的開發作為本計劃第二期(2007/8/1-2008/7/31)的主要研究議題，並將其應
用到本計劃另一主題「作文分析及評分系統的建置」。 
作文能力是評量語文學習的一項重要指標，也是邏輯推理、記憶與組織、創造等能力的顯示。
因此本計劃第三期(2008/8/1-2009/7/31)的主要研究議題為建置一個可適用於分析並評量台灣高中學
生程度的中文作文評分糸統。目前在英文作文方面，已有著名的 E-Rater 評量工具 [Burstein, ‗00，‘05]；
在中文方面，有大陸針對外籍人士所做的 HSK 高等漢語水平考詴與 HSK 動態作文語料庫的建立。
然而如前所述，這項考詴的華語水平目前尚在基本生活應用階段，對語文進階的寫作分析和評量無
法適用。因此我們將應用近年所做的詞彙語義標記、詞組抽取、相似句萃取和指代消解、語篇連貫
和修辭結構等段落間的語義分析處理技術，開發與建置一個可適用於台灣高中學生程度的中文作文
評分與分析糸統。藉由分析文章的合題性、連貫性、結構等項目，進行評分並評語。我們相信本計
劃的執行不僅對中文文本結構有深入的探討和創新的法則提出，對資訊自動化技術的發展、和中文
學習亦有所幫助。 
 
  
                                                                            
續、、進行）、Modality verbs（必頇、會）、Verbs related to causality（導致、致使、引起）、Conjunction 
words（並、並且、不過）、Auxiliary words（著、了、過）、Time words（過去、今年）以及Adverb
（便、並、不）；事件組則分為四種事件，分別為：State、Punctual、Developing和Progress。實驗了
三種訓練方式，以600筆人工標記的測資作為訓練語料，100筆作為測詴語料，當中表現最好者，訓
練語料的測詴正確率為88.7%，測詴語料為78%。此方法主要是處理一子句間的時間關係，一般是
一個小句，至多到兩個小句；多個小句間及長句間的時間關係並沒有處理。另外，此方法使用的特
徵都是一些詞彙上的特徵，對於其他類型的特徵並沒有探討。 
針對連貫關係關鍵詞省略問題，英文語篇關係探勘的相關研究已對此問題提出了一些解決方式。 
[Marcu and Echihabi, ‗02]針對四種連貫關係提出不使用關鍵詞進行判定的辨識方法。四種連貫關係
分別為：Contrast、Explanation-Evidence、Condition 以及 Elaboration。他們使用連貫關係的關鍵字，
自動產生訓練語料中的正例，並以亂數挑選不連續的兩片段作為訓練語料中的負例。他們使用貝氏
分類器從訓練語料中擷取出共同出現的詞組，並利用這些詞組進行辨識。他們的理論是，若關鍵詞
是可以省略的，則必在文章片段中有其他非關鍵詞的文字可作為判定的線索。他們將各連貫關係的
語料兩兩組合測詴，包含無關係者總共進行 15 組的測詴。測詴語料共 5000 例，其中正確率最高者
為 95%，最低者為 64%，平均為 75%。此方法僅使用共現的詞語進行辨識，若挑選共現詞語的門檻
森嚴，則不免回饋率變低；若挑選的門檻寬鬆，也許在封閉測詴的情況下表現不錯，但在開放測詴
的情況下結果則可能並不理想。另外，這個方法產生負例的方式令人有所質疑，畢竟在真實的文章
中，是不會出現亂數挑選的組合的。 
[Sporleder and Lascarides, ‗05]參考[Marcu and Echihabi ‗02]，用相同的方式自動產生訓練語料，
但他們在方法上做了些許的更動，第一是處理的連貫關係不同，他們的方法針對以下這五種連貫關
係關係進行處理，分別為：Contrast、Explanation、Result、Summary 以及 Continuation；第二是採
用了更多的特徵，共使用了 72 種特徵，分為七大類：Position（關係出現的位置等資訊）、Length
（關係延續的長度等資訊）、Lexical（跟詞彙相關的資訊）、Part-of-Speech（詞性標記等資訊，包含
句子的詞性標記串列）、Temporal（跟時態相關的資訊）、Syntactic（句子結構樹等資訊）以及 Cohesion
（主詞延續等資訊）。第三是使用 BoosTexter 進行辨識。他們使用了 7795 筆例子作為訓練語料，865
筆例子作為測詴語料，訓練語料與測詴語料中各類關係的數量是約等的，各關係的正確率不等，平
均正確率為 57.55%，最高為 83.35%，最低為 43.64%。此數據顯示，雖然使用了更多的特徵，其效
能卻不甚理想，可能是因為七類特徵細分為 72 項，單一項的例數都不夠多，反而造成結果不佳。 
 
3.3 主題詞辨識相關研究 
主題詞辨識是文本理解中一項不可缺乏的工作，可為訊息的中心陳述。以往主題詞辨識多應用
於文件分類問題上，從單篇或多篇文章中以統計方法抽取關鍵詞做為文件內容的主題描述。如以一
袋子詞與權重計算，抽取重要的詞彙當成主題詞 [Khoo, and Ishizuka ‗02] [Lin ‗04]。另有將人、事、
時、地、物等當成向量元素，以「事件」來呈現主題[Makkonen et al. ‗04]。其它有[Grosz et al. ‗95]
所提出的重心理論(Centering Theory)，從連續兩個英文句子間，判斷句子的重心，抽取主題。[Yeh and 
Chen ‗04]亦將重心理論利用於中文文本中的零指代消解。然而前述所提方法並不考慮文章中句間的
邏輯結構是否呈現主題敘述的連慣性和段落間主題論述首尾呼應的一致性，是以無法直接應用於作
文評分的自動化。 
 
 
                                                                            
第四章 研究方法 
4.1 語篇結構分析方法 
依據程祥徽與田小琳[程祥徽和田小琳,‗89] 所提出的複句及句群關係分類來定義語篇片段之間
的連貫關係，並參照 Wolf 和 Gibson [Wolf and Gibson, ‗05]的理論，我們在本方法中，排除沒有明顯
表層特徵的總分及連鎖關係，將語篇連貫關係分為如下九類：  
表 1：語篇連貫關係類別 
語篇類別 定義 
並列關係 指表達幾件相關的事件，但彼此並不構成因果關係，也沒有語氣
或語意上的轉折。 
承接關係 描述一連續的動作，或是以發生的時間順序來連接的一連串事
件，以及依事件發生的空間順序來進行敘述的事件。 
選擇關係 含有從幾件事物中進行選擇的語義。 
遞進關係 在連續片段中，具有後一個片段比前一個片段的語意層次更進一
層關係的語篇視為遞進關係。 
轉折關係 指前一片段的語義與後一片段相對或相反。 
因果關係 使用兩個或兩個以上的片段來說明事件的原因及其結果。 
條件關係 前一片段假設一種情況或提出一種條件，後一片段說明如果實現
的話會產生的結果。 
解證關係 前一片段提出一種看法、道理、事實、現象，後一片段加以解釋、
說明、補充、引申的語篇。 
目的關係 前一片段提出一個目的，後一片段說明為了達成這個目的需要做
的事。 
 
4.1.1 語篇線索詞探勘 
語篇線索詞的探勘是以中研院平衡語料庫 3.0 版中的敘述型語料來進行的，主要步驟為現有線
索詞收集、詞性篩選、成對線索詞組探勘、單一線索詞探勘及輔助特徵探勘。 
我們以「現代漢語」[程祥徽和田小琳,‗89]所列出的語篇線索詞來當作查詢詞，在探勘語料中進
行更多線索詞的收集。成對線索詞組的探勘是以統計方法得知線索詞的位置為語篇片段中的第 1 到
12 個詞彙，計算連結強度，探勘連結方向，篩選出句內線索詞組 406 組，句間線索詞組 82 組。 
有時成對線索詞也可單獨出現。我們以檢驗成對線索詞組的例句進行辨識篩選，收集了 309 個
單一線索詞。至於輔助特徵，我們參考[田小琳, ‗84]及 [Tomohide and Sadao, ‗05]的研究，設定四種
輔助特徵包括具有時間詞(Nd)詞性的詞彙，例如：「今天…明天」，出現在連續的語篇片段時，則視
這些語篇片段具有「承接關係」。當具有數詞定詞(Neu)詞性的詞彙，例如：「第一…第二」，出現在
                                                                            
D#, 
以‖D‖作為開頭的數字，為語篇連貫關係之編號，如
表 3-2 所示。 
[] 以―[‖、―]‖標示語篇片段的左右邊界。 
C# 
以‖C‖作為開頭的數字，為分句語篇片段在整個長句
裡的排列順序。 
S# 
以‖S‖作為開頭的數字，為長句語篇片段在整個文章裡
的排列順序。 
Theme 以 Theme 標示語篇連貫關係中的第一個語篇片段。 
Rheme 以 Rheme 標示語篇連貫關係中的其他語篇片段。 
 
 
圖 1：語篇標記結果範例 
 
4.1.3 實驗設計與分析 
我們從主要的平面媒體電子報，收集 100 篇社論來檢驗系統標記的效能，每篇的字數平均約為
1500 字，內容均為政治、經濟及民生議題。 在我們的實驗中，句內標記正確率可達到 91%，句間
標記正確率可達到 86%。由實驗結果得知，社論類的文章使用最多的語篇是遞進與轉折，其比例分
別是句內 20.27%、27.35%以及句間 13.11%、36.69%，次多者句內和句間有所不同，句內為並列與
條件，比例分別為 17.20%、14.05%，而句間則為解證與因果，比例分別為 20.53%、9.53%。相對
於句間大量使用解證，句內則較少使用，而句內較常使用的條件語篇，在句間則很少使用。 
句內或句間單一線索詞的使用率都是最高的，分別達到 77.43%及 75.63%，而句內使用率偏低
的是連續的 Neu 以及最後一個詞使用有列舉涵義的詞，而句間使用率較少的則是片段最後一個詞使
用有解證涵意的詞。我們認為是因為長句再表達解證義涵時，通常都會使用「：」來表達，其比例
有 13.25%。 
 
4.2 時間關係辨識方法 
時間關係是連貫關係的一類，可作為判定文章語義的線索。時間關係是指兩個語段在時間上或
是先後發生，或是同時發生，或是具有明確時間點。我們提出一個從語料中挑選有用的特徵，利用
機器學習方式，以有效地辨識文章中含時間關係的句子。 
4.2.1 語料庫建立 
我們使用光華雜誌社（Sinoroma）語料庫（1976~2001）1、中央研究院平衡語料庫2、The Lancaster 
                                                 
1光華雜誌語料庫 http://www.aclclp.org.tw/use_gh_c.php 
遞進[Forward]:([C1:尤其是除了金融與企業行為的管理以外，]|解證[Elaboration]:([C2:更是有許多限制與
控管是針對個人而來的，]|並列[Coordinate]:([C3:例如公司董事與經理人赴大陸投資行為、企業投資的檢
舉獎金，]|[C4:以及開放大陸人士來台灣觀光的管理等等。])))  
                                                                            
表 6 為辨識的特徵出現頻率列表。其中主詞為人的詞彙，諸如代名詞、稱謂、人名等。我們使用同
義詞詞林當中的人稱代名詞、稱謂、職業等三類輔助判斷；在人名方面，我們取出斷詞標記為 Nb
者（即專有名詞），再配合百家姓的資料輔助辨識人名，當主詞的前一或兩個字符合出現在百家姓
內的姓氏，則將此名詞當成人名。 
 
 
表 6：特徵出現頻率列表 
特徵 出現率 
主詞為人物 55.87% 
前後句主要動詞組 40.06% 
時間詞組 7.12% 
主要動詞前動詞 23.55% 
副詞 主要動詞前副詞 11.23% 
主要動詞後副詞 8.78% 
時態字根 38.21% 
主要動詞詞性組 95.84% 
小句重心一致性 66.82% 
 
在時間關係中，由於前後兩個語段或是有先後的順序，或是同時發生，因此我們用統計的方式
找出這些作為事件發生敘述的動詞組合。我們將訓練語料以查詢詞為分割點，切分為兩個片段。從
句首開始，找該句的前後句主要動詞組，計算它們的相關性並取門檻值高的動詞組，例如: (迷航，
沉默) 、(沮喪，悟出來) 、 (寵愛，轉送到) 、(考取，妒恨)。 
我們從訓練語料庫中找出整個長句中所有的主要動詞，然後找出所有出現在主要動詞前的動詞，
例如: …開始擔心…的「開始」。挑選出現在正負例資料庫中正例的比例超過 50%的動詞。另過濾掉
詞性標記為(VH)者，因為這種詞性標記的動詞常是狀態性的，容易作為副詞用。擷取出的動詞如: 導
致、通過、處理、同意、順利、變成、著手、慢慢、想到、出面、經過、決定、開始…。同樣我們
以相同的統計的計算方式得到可具連貫關係判斷性的動詞詞性組。時間詞的出現是判斷時間順序的
一個明顯依據。我們分別針對前後片段找出的一個時間詞串列，所謂的時間詞串列是指連續出現並
標記為（Td）的時間詞，例如：一九九五年六月三日下午。另外也判斷句中是否含序數型時間詞，
例如：前些時候….，最近…。 
我們希望找出會影響時間關係的副詞作為判斷時間關係的依據。例如: ―…都已成家立業…‖的
「已」。從每一長句中，我們先找出主要動詞，再挑選出現在正負例資料庫中正例的比例超過 50%
的副詞。找出的動詞前的副詞有: 一直、甚至、先、曾、陸續、立刻、逐漸、常常、將、…；動詞
後的副詞有: 經年、原本、至今、必…。另外我們收集常在中文語句中的時態字根，表示事件敘述
的時件是正在進行或是已經成為過去。 
在時間關係中，圍繞著相同的主題敘述的狀況是常見的。我們利用重心模型挑選小句的重心詞 
[潘善均, ‗07] ， 然後從這些重心詞考量多種特徵挑選主題詞。我們將訓練語料以查詢詞為分割點，
切分為兩個片段，並進行兩種比較：第一，比較前後兩個片段是否具有相同的小句主題詞；第二，
比較前後兩個片段是否具有相同的小句主題候選詞。如果有相同者，則參數為 1，沒有則為 0。 
 
                                                                            
稱代名詞作為候選詞。若遇連續的名詞組，則取最後的名詞作為候選詞。由於中文常有出現名物化
動詞的情形，故我們參考[馬偉雲, ‗06]，將部分的名物化動詞列入候選詞，如「是」前面的動詞、「的」
後面的動詞，及物動詞(VC)後面的動詞。我們也參考[Wu and Liang, ‗09]，針對中文常出現的零指代
與第三人稱代名詞進行辨識。 
我們參考[Grosz et al.‗95]的重心模型來進行小句重心選取，並依照中文的特性加以改進。重心
模型如表 9 所示，其中 Ci 代表第 i 小句重心，Ci-1 則是 Ci 前一小句的重心，Ci-2 則是 Ci-1前一小句
的重心，C 是 Ci 的候選詞。Can(Ci)表示 Ci 的重心候選詞集合，C(3rd-anaphor)代表第三人稱代名詞，
C(Zero-anaphor)代表零指代。 
 
表 9：重心模型 
Case 1 延續：Ci-1＝Ci-2 且 
1.1 C Can(Ci), C＝Ci-1，則 Ci=C＝Ci-1 
1.2 (3rd-anaphor)Can(Ci) OR C(Zero-anaphor)Can(Ci)，則 Ci=Ci-1。 
Case 2 保留： Ci-1＝Ci-2, 且 
2.1 C Can(Ci), C≠Ci-1 且 C(3rd-anaphor)Can(Ci) AND C(Zero-anaphor)Can(Ci)，
則 Ci=Can(Ci)。 
2.2 前一小句沒有重心(標示為 E)，或者此小句為長句中的第一小句，則 Ci=Can(Ci)。 
Case 3 平順遞移：Ci-1≠Ci-2, 且 
3.1  kC Can(Ci-1),  jC Can(Ci), jk CC  ，則 Ci=Ci-1 = jk CC  。 
3.2 C(3rd-anaphor)Can(Ci) OR C(Zero-anaphor)Can(Ci) 則 Ci=Ci-1=C, where 
Freq(C)=MaxFreq( Can(Ci-1) )。 
3.3  kC Can(Ci-1),  jC Can(Ci), jk CC  ，且 C(3rd-anaphor) Can(Ci) AND 
C(Zero-anaphor)Can(Ci)，則 Ci =Ci-1 =C , where Freq(C) =MaxFreq(Can(Ci), 
Can(Ci-1))。 
MaxFreq(Ti…Tk)：計算 k 個詞彙 Ti…Tk，於此文章中出現之頻率，並取其頻率最高
者。若為第一、第二人稱代名詞，其頻率視為 0。 
Case 4 粗糙遞移 Ci-1≠Ci-2, 且 Can(Ci-1)={C1}, Can(Ci)={C2}，C1≠C2，則 Ci=C2。 
 
在 Case 4 中，我們將「粗糙遞移」的狀況限制的很嚴謹，並將原本應視為「粗糙遞移」的狀況
視為是「平順遞移」（Case 3.3）。這是因為若 Ci-1 已為「保留」狀況，且此時 Ci-1 想帶出 Ci，Ci 才是
重點，兩小句既無重複的候選詞亦無代名詞與零指代。「粗糙遞移」在文章當中原本就較少出現，
即使判定為「平順遞移」影響亦不大，且此舉將更有助於之後的長句主題詞辨識。 
我們蒐集了 11 篇內容為政治和經濟議題的聯合報社論。11 篇社論共包含 15404 字數，共 276
長句數，平均每一長句有 4.65 小句。在計算重心選取正確率時，我們排除無重心候選詞的 128 小句，
僅人工檢視 1156 小句的重心選取結果，得到 83.70%正確率。 
 
4.3.2 長句主題詞辨識 
                                                                            
為長句的主題詞。模組 V 是以長句中出現頻率最高之名詞或動詞為主題詞。實驗結果證實所提的以
小句重心理論模組確實較辭彙模組得到較高的辨識。此外，所用的五種特徵都是正向影響因子，因
此我們以模組 III 做為後續應用於作文評量的工具。在第二組的 22 篇作文測詴語料上，對 188 個長
句進行主題詞辨識，得到 80.86%的正確率。 
表 11：社論語料之長句主題詞辨識實驗結果 
 模組 正確數 錯誤數 正確率 
重心理論 
模組 I 188 40 82.46% 
模組 II 194 34 85.09% 
模組 III 198 30 86.84% 
詞彙 
模組 IV 101 127 44.29% 
模組 V 89 139 39.04% 
 
4.4 作文分析與評分 
4.4.1 作文語料分析 
長句主題詞與小句重心可以用來協助教師作學生作文的離題偵測。在本計畫中，學生作文語料
為新竹市一所市立高中國文考詴的 95 篇學生作文；題目為「最上一層樓」，約 400 字作文。其引導
文如下： 
 
 
 
 
 
 
 
圖 2：作文「最上一層樓」之引導文 
 
95 篇學生作文作文分數分佈情形如表 12。表 13 是我們以實驗模組Ⅲ對作文語料萃取主題詞之實驗
結果，並將此應用到作文離題和連貫性偵測。 
 
表 12：作文分數分佈情形 
0~3 分 4~6 分 7~9 分 10~12分 13~15分 16~18分 
7 21 15 30 16 6 
 
有位富翁，一日到朋友家拜訪，那位朋友的住屋有三層樓高，雄為壯麗，氣派非常。特別
是走到第三層樓，由此俯瞰四方，感到視野廣闊，景致宜人。他在羨慕之餘，回到家就招來工
匠，在自家的地上也要興建樓房，但是他命令工匠，不准先建造第一層及第二層，他要的只是
最上面的一層樓。 
看完這則故事，請以「最上一層樓」為題，寫一篇文章，抒發你的看法和感想。 
                                                                            
與文章不夠精鍊。 
 
4.4.4 文章概念結構 
我們利用長句主題詞與其同義詞概念，進行文章敘述結構的分析。圖 3ab 分別為一篇高分與低
分文章的主題詞詞串。我們可以發現高分文章的結構較為嚴謹，會重複敘述到重要的主題詞，以達
到前後呼應的效果；而低分文章傾向以直敘法來敘述，主題詞之間沒有重複性，關連性低。 
 
 
 
圖 3a：高分作文 A 之長句主題詞串 
 
圖 3b：低分作文 E 之長句主題詞串 
我們統計作文結構含有與未含重複到訪主題，並將含重複到訪主題者依照重複到訪主題數與到
訪距離細分如表 14 所示。 
 
表 14：「最上一層樓」作文 未/含重複到訪主題之比較 
文章分數 有重複到訪主題 
有重複到訪主題 
未含重複到訪主題 到訪主題數=1 
(距離<=2 ; 距離>2) 
到訪主題數>1 
0~3 分 2 2  (1;  1) 0 5 
4~6 分 8 7  (5;  2) 1 13 
7~9 分 5 5  (4;  1) 0 10 
10~12 分 17 14 (7;  7) 3 13 
13~15 分 6 4  (2;  2) 2 10 
16~18 分 5 4  (2;  2) 1 1 
文章總數 43 36 (21; 15) 7 52 
文章平均分數 10.37 10.11 (9.52; 10.93) 11.71 8.96 
 
除了觀察有無重複到訪主題之外，我們統計相鄰主題之間的推導，發現高分作文中常見主題「樓
房」後接主題「地基」，此種主題推導與引導文題意吻合，要學生瞭解建築「樓房」最需要的是底
層厚實的「地基」。然而此一主題配對卻未見於低分作文中。 
 
意義叢林工程讀數字 
房子地基基石學習故事羅馬 
大樓(與房子同概念)工人 
                                                                            
圖 5： 詞彙配搭詞查詢—配搭詞與例句查詢 
 
圖 6 為主題詞辨識一開始的頁面。此圖片顯示了使用者目前有一個資料夾‖社論‖，點選資料夾
進入後才能上傳文章與觀看先前文章等。 
 
圖 6： 主題詞辨識—顯示所有資料夾畫面 
 
圖 7 是我們點選‖新增檔案‖後的頁面，此頁面為上傳一篇文章的介面，使用者上傳一個文字檔，
系統會分析檔案內容並且找出其小句重心與主題詞，系統分析完成後，呈現的方式有二種，分別是
全文檢視和小句檢視。 
 
圖 7： 上傳文章的介面 
 
                                                                            
字的部份是長句主題詞同時也代表著是小句重心，而藍色字的部份則是小句重心但未被選為長句主
題詞。 
 
圖 10：作文的全文檢視畫面 
 
圖 11 為作文的檢視畫面，系統會在辨識主題詞結束後，根據小句重心、長句主題詞、合題詞..等作
為依據並給予評分，此篇作文為例人工評分為四級分，系統評分為五級分。 
 
圖 11：小句檢視的作文畫面 
 
                                                                            
6. 小句重心標記模組建構和展示。 
7. 評分機制設計。 
8. 相關論文發表 
甲、潘善君，中文主題詞辨識與應用，國立交通大學資訊科學與工程研究所，碩士論文 2007。 
乙、潘善君、梁婷、陳冠熙，中文文本中長句的主題詞辨識與其應用，全國計算機會議，2009
台北。 
丙、Dian-Song Wu and Tyne Liang, 2009, Zero Anaphora Resolution by Case-based Reasoning 
and Pattern Conceptualization, Expert systems with applications Expert Systems with 
Applications 36 (4) (2009, May) 7544–7551. 
丁、C.L. Chen, Frank S.C. Tseng, and T. Liang, An Integration of Fuzzy Association Rules and 
WordNet for Document Clustering, 13
th
 Pacific-Asia Conference on Knowledge Discovery and 
Data Mining, Bangkok, Thailand (PAKDD-2009), Lecture Notes in Computer Science 5476, pp. 
147-159. (acceptance rate=39/338) 
 
第六章 結果與討論 
中文語言處理技術的開發隨著中文在全球各地日受重視也愈趨重要。在本計劃中，我們除了延
續這些年所進行的中文書面語料的實体名稱辨識、相似句計算、指代消解研究外，我們針對語篇連
貫結構分析處理，提出有效的計算模組和驗証。此外我們提出中文作文評分與分析糸統。此糸統主
要的模組包括語料收集與整理、文本處理、離題偵測、主題連貫性和語義概念結構分析、評分機制、
外部知識庫和輔助查詢工具的建置。我們相信本計劃的執行不僅對中文文本結構有深入的探討和創
新的法則提出，對資訊自動化技術的發展、和中文學習者亦有所幫助。 
本計劃的執行有賴國科會的贊助得以完成。計劃成果如前章所述。目前尚待加強的是具專家評
分標記的作文語料的擴充、成語典故和譬喻的詞彙運用檢視。前者需要與大考中心能建置此項電子
語料庫；後者修辭用字則需在後續研究中加強。 
參考文獻 
黃國文 (1988)，語篇分析概要，編著，北京商務印書館 
胡壯麟 (1994)，語篇的銜接與連貫，上海外語教育出版社 
程祥徽、田小琳 (1989)，現代漢語，台北書林書店 
田小琳 (1984)，中學教學語法系統提要，北京人民教育出版社。 
周國正 (1993)，語法句群與篇章句群，語文建設通訊，41 期 
林孝璘 (2001)，台灣華文逗句號研究，國立新竹師範學院臺灣語言與語文教育研究所，碩士論文 
楊遠 (1962)，標點符號研究，香港天健出版社，頁3，15-31 
蘇培成 (1995)，台灣出版「重訂標點符號手冊」，語文建設，2期 
范開泰、張亞軍、張斌編 (2000)，現代漢語語法分析，上海華東師範大學出版社 
曹逢甫 (1995)，主題在漢語中的功能研究（A functional study of topic in chinese:The first step toward discourse analysis）:謝天
                                                                            
Hobbs, J. R. Literature and Cognition, (1990), CSLI Press, Stanford, California. 
Hovy, E. and E. Maier.,(1995),‖Parsimonious or profligate: How many and which discourse relations?‖, Technical report, University 
of Southern California. 
Hsu, W. L., Y. S. Chen, and Y. K. Wang,( 1998),  ―A context sensitive model for concept understanding‖, Proceedings of Third Int. 
Conf. on Information-Theoretic Approaches to Logic, Language, and Computation. 
Hearst, M. A.,( 1997),‖TextTiling: Segmenting Text into Multi-paragraph Subtopic Passages‖, Computational Linguistics, 23 (1), 
33-64, March. 
Halliday, M. A. K. & Hasan, R., Coherence in English, London: Longman.,1976. 
Kamp, H., (1981), ―A theory of truth and semantic representation: Formal Methods in the Study of Language‖, MC TRACT 135, J. 
A. G. Groenendijk, T. M. V. Janssen, and M. B. J. Stokhof (Eds.), Amsterdam, p. 277. 
Lascarides, A., and Asher, N., (1991), ―Discourse Relations and Defeasible Knowledge‖, Proceeding of 
the 29th Annual Meeting on Association for Computational Linguistics, pp.55-62. 
Lin, K. H. C. and V. W. Soo,(1993), ―Toward discourse-guided theta-grid parsing for Mandarin Chinese --a preliminary report‖, 
Proceedings of ROCLING Il, pp. 259-270. 
Li, S., Zhang, J.,(2002), ―Semantic Computation in Chinese Question-Answering System‖, Journal of Computer Science  and 
Technology, 17(6): 933. 
Miltsakaki, E., and Kukichy, K., (2000), ―Automated Evaluation of Coherence in Student Essays.‖  In 
Proceedings of LREC 2000 Workshop: Language Resources and Tools in Educational Applications, 
Athens, Greece. 
Sadao K., Makoto N.,(1994), ―Automatic Detection of Discourse Structure by Checking Surface Information in  Sentences‖, 
COLING , pp.1123-1127. 
Tiun, S., Abdullah, R., and Kong, T., (2001), ―Automatic Topic Identification Using Ontology Hierarchy.‖  
Lecture Notes in Computer Science : Computational Linguistics and Intelligent Text Processing : Second 
International Conference, CICLing 2001. Mexico City, Mexico. 
Tomohide S. and Sadao K.,(2005), "Automatic Slide Generation Based on Discourse Structure Analysis", In Proceedings  of 
Second International Joint Conference on Natural Language Processing (IJCNLP-05), pp.754-766, Jeju Island, Korea. 
T'sou, Benjamin K., Lai, Tom B. Y.,  Chan, Samuel W. K., Gao, Weijun, Zhan, Euegang, (2000), 
―Enhancement of a Chinese discourse marker tagger with C4.5‖, Proceeding of the Second Chinese 
Language Processing Workshop. 
Wang, Y. K., Y. S. Chen, and W. L. Hsu, (1998), ―Empirical study of Mandarin Chinese discourse analysis: an event-based approach,‖ 
to appear in 10th IEEE Int‘l Conf. on Tools with Artificial Intelligence (ICTAI‘98). 
Wolf, F. and Gibson, E.,( 2005 ),‖Representing discourse coherence: A corpus-based analysis‖, Computational Linguistics, 31(2): 
249-287. 
Wu, D., and Liang, T., (2009), ―Improving Chinese Pronominal Anaphora Resolution Using Lexical 
Knowledge and Entropy-based Weight.‖ Journal of the American Society for Information Science and 
Technology, 59(13) (2008, November), pp. 2138-2145. 
  
                                                                            
while learning-based methods require a large well-tagged training corpora for satisfactory performance 
[11, 12, 13]. Besides, learning approach like SVM-based classification manipulates candidates by labeling 
positive or negative classes rather than estimating the likelihood that a candidate becomes an antecedent. 
In this paper, an effective approach to Chinese pronoun resolution is presented. In addition to the features 
commonly used in previous approaches, two innovative features are introduced by considering Chinese 
discourse structures. One is feature of coherence relations which are helpful to guide pronominal anaphora 
resolution [8]. The other is the feature of forward-looking centers associated with discourse utterances [5, 
14]. Such discourse features will be extracted by implementing the presented heuristic rules with the help 
of outer resources. Moreover, our antecedent identification is implemented by a maximum-entropy based 
model which is motivated to yield global optimization of feature weighting [1]. The experimental results 
show that our method yields 83.5% success rate on 651 anaphor-antecedent pairs, enhancing 8% and 3% 
success rates respectively while compared to the general rule-based method presented in [15] and a 
SVM-based method. Besides, the experimental results show that the impact of the innovative discourse 
features is positive in enhancing the presented pronoun resolution. 
2   The Pronoun Resolution 
The presented resolution is implemented in the training phase and the testing phase. The training phase is 
mainly to train the presented maximum-entropy confidence estimation on the selected feature set. The 
testing phase involves the tasks to process texts, extract informative features from both contexts and outer 
resources, and finally determine antecedents. Table 1 lists the target pronominal anaphors to be resolved in 
this paper. Unlike English pronouns, Chinese pronouns remain the same in expressing nominative and 
accusative cases. 
Table 1. The target pronominal anaphors. 
 Singular Plural Possessive (Singular) Possessive (Plural) 
Male 他(he, him) 他們(they, them) 他的(his) 他們的(their, theirs) 
Female 她(she, her) 她們(they, them) 她的(her, hers) 她們的(their, theirs) 
Neutral 它(it) 它們(they, them) 它的(its) 它們的(their, theirs) 
2.1 Text Processing 
Text preprocessing involves sentence segmentation, Part-of-speech tagging, noun phrase chunking and 
grammatical tagging. The sentence segmentation and POS tagging are processed by CKIP Chinese word 
segmentation system
5
. Noun phrase chunking is implemented by our finite-state machine chunker. All 
                                                 
5
 CKIP Chinese word segmentation system is available at http://ckipsvr.iis.sinica.edu.tw/ 
                                                                            
i. NP= person name+女士; 
ii. the first character of NP is ―女‖; 
iii. the last character of NP is ―母‖; 
iv. NP+的+male_title word;  
v. NP +她; 
vi. first-name contains any female character; 
Step 5: For other cases, the gender feature is marked unknown. 
2.2 Extensive Feature Representation 
In this paper, each antecedent candidate is represented with a rich set of extracted features. As listed in 
Table 2, the features can be grouped into six categories. Among them, lexical, positional, grammatical and 
heuristic features are employed in our resolution as well as most of previous resolutions. However, our 
approach acquires more semantic features instead of syntactic features like parsing results used in [4, 17].  
The extracted semantic features include the named entities identified by the named entity identifier 
presented in [7]. Moreover, two other semantic features are also included in our rich feature set while we 
considering Chinese discourse structures. One is coherence relation feature and the other is 
forward-looking center feature. As pointed in [8], the establishment of coherence relation guides 
pronominal anaphora resolution, and vice versa. In this paper, we assume that a coherence relation exists 
between an antecedent candidate and a pronoun if they are in the same discourse unit which may cross 
sentences. The discourse unit is identified by checking whether there are explicit discourse markers 
collocating in the discourse unit containing an antecedent candidate and a pronoun. The collocating 
markers are those words of the discourse lexicon database presented in [3]. For example, ―一方面‖ (―on 
the one hand‖) and ―另一方面‖ (―on the other hand‖) are collocating markers linking the coherence 
relations among a discourse unit. 
As indicated [5, 14], a discourse utterance is associated with forward-looking or backward-looking centers. 
Backward-looking centers are often omitted or realized as pronouns while ranking of forward-looking 
centers corresponds to the likelihood that a center becomes the primary focus of subsequent discourses. 
Considering Chinese language is called a topic-prominence language, we hence extract forward-looking 
centers as one kind of discourse features by implementing the following simple center-identification rules.  
 
1. The first noun phrase in a sentence is treated as topic by default. 
2. For each pronoun, all the noun phrases appearing in the preceding clause are treated as 
forward-looking center candidates. 
3 If one of the candidates is the identified topic, the topic becomes the forward looking center; 
otherwise, the candidates are selected to be the center by following the priority rule, that is, 
subject-labeled candidate is firstly selected; an object-labeled candidate is the second one; the other 
                                                                            
 
(1) 
where 
x: x{positive, negative} and x labels c as positive or negative 
c: an antecedent candidate for its corresponding pronoun 
i : the weight for feature if  




otherwise 0,
sconstraint feature satisfied )if(1,
)(
x,c
x,cfi
 
3  Comparative Results and Analysis 
The presented resolution is trained by a training corpus which contains 157 news documents extracted 
from a balanced corpus ASBC
8
. Another different set of 150 news documents is used as testing data for 
performance comparison. The resolution is evaluated in terms of success rate (Equation (2)).  
 
(2) 
 
The proposed resolution is verified and compared to rule-based and SVM-based approaches. The 
rule-based method is implemented in the way as presented in [15] in which only four features, namely, 
number, gender, grammatical, and position are extracted and weighted manually. On the other hand, the 
SVM-method is implemented by using the toolkit LIBSVM
9
 with the presented 21 features. Table 3 
shows that our method yields better success rate to the rule-based method by considering more features at 
antecedent identification. On the other hand, a SVM-based approach essentially ignores the remaining 
antecedent candidates whenever one candidate is tagged to be positive, hence less success rate is obtained 
by the SVM-based resolution while compared to the presented method.  
The impact of features is verified by implementing leave-group-out evaluation. Table 4 shows that 
grammatical features as well as semantic features are the first two important features. It also shows that 
the innovative discourse features are useful to enhance the pronoun resolution though they improve 
success rate slightly. The reason is that few inter-sentential discourse units were identified by the discourse 
marker based matching method. Improvement of discourse identification is expected in the future work. 
                                                 
8
 Academia Sinica Balanced Corpus is available at http://www.sinica.edu.tw/SinicaCorpus/ 
9
 LIBSVM is available at http://www.csie.ntu.edu.tw/~cjlin/ 
))(())((
))((
)|(





i
ii
i
ii
i
ii
negative,cfexppostive,cfexp)c(Z
)c(Z
postive,cfexp
cpositivexPrconfidence
 pairs antecedent-anaphor ofnumber  total
pairs antecedent-anaphor resolvedcorrectly  ofnumber 
rate success 
                                                                            
2. Bergsma, S. & Lin, D. (2006). Bootstrapping Path-Based Pronoun Resolution. Proceedings of the 21st International Conference on 
Computational Linguistics and 44th Annual Meeting of the ACL (pp. 33-40). 
3. Chen, Shou-Yi (2006) Corpus-based Coherence Relation Tagging in Chinese Discourses, Master Thesis, National Chiao Tung University, 
Taiwan. 
4. Converse, S. P. (2005). Resolving Pronominal References in Chinese with the Hobbs Algorithm. Proceedings of the 4th SIGHAN 
Workshop on Chinese Language Processing (pp. 116-122). 
5. Grosz, B. J., Joshi, A. K. & Weinstein, S. (1995). Centering: A Framework for Modeling the Local Coherence of Discourse. 
Computational Linguistics. 21(2), 203-225. 
6. Lappin, S. & Leass, H. (1994). An Algorithm for Pronominal Anaphora Resolution. Computational Linguistics, 20(4), 535-561. 
7. Liang, T., Yeh. C. H. & Wu D. S. (2003), A Corpus-based Categorization for Chinese Proper Nouns. Proceedings of the National 
Computer Symposium (pp. 434-443) 
8. Kehler, A. (2002). Coherence, reference, and the theory of grammar. Stanford, CA: CSLI Publications. 
9. McCallum, A. K. (2002). MALLET: A Machine Learning for Language Toolkit." http://www.cs.umass.edu/~mccallum/mallet. 
10. Mitkov, R. (1999). Multilingual Anaphora Resolution. Machine Translation, 14(3-4), 281-299. 
11. Ng, V. (2005). Machine learning for coreference resolution: From local classification to global ranking. Proceedings of the 43rd Annual 
Meeting of the Association for Computational Linguistics (pp. 157-164). 
12. Ng, V. & Cardie, C. (2002). Improving machine learning approaches to coreference resolution. Proceedings of the 40th Annual Meeting of 
the Association for Computational Linguistics (pp. 104-111). 
13. Strube, M. & Muller, C. (2003). A machine learning approach to pronoun resolution in spoken dialogue. Proceedings of the 41st Annual 
Meeting of the Association for Computational Linguistics (pp. 168-175). 
14. Strube, M. & Hahn, U. (1996).Functional centering. Proceedings of the 34th annual meeting on Association for Computational Linguistics 
(pp. 270-277) 
15. Wang, H. F. & Mei, Z. (2005). Robust Pronominal Resolution within Chinese Text. Journal of Software, 16, 700-707. 
16. Wang, N., Yuan, C. F., Wang, K. F., & Li, W. J. (2002). Anaphora Resolution in Chinese Financial News for Information Extraction. 
Proceedings of the 4th World Congress on Intelligent Control and Automation (pp. 2422-2426). 
17. Yang, X. F., Su, J., & Tan, C. L. (2006). Kernel-Based Pronoun Resolution with Structured Syntactic Knowledge. Proceedings of the 21st 
International Conference on Computational Linguistics and 44th Annual Meeting of the ACL (pp.41-48). 
 
  
                                                                            
基於在處理中文文章結構上，我們視每一長句
具有一完整的主題論述。中文長句定義為以
「。！？」為長句結束符號。一個中文長句句
法結構上可包含數個小句，因此在進行辨識長
句主題詞的辨識時，我們考量小句重心在文章
中的頻率、位置、延伸性、一致性、概念等特
徵。此種長句主題詞辨識法，不僅可偵測文章
段落上的主題，也可應用於主題概念的推演結
構分析。 
 
2.二階段式的長句主題詞辨識法 
  我們採用二階段方式挑選長句的主題詞，
第一階段依據重心理論來選取長句中各小句
的重心，第二階段則由這些小句重心來決定一
個長句的主題詞，這種由小句重心選取主題的
方法可以避免較長的句子有太多的主題候選
詞。 
2.1 小句重心辨識 
2.1.1重心候選詞萃取 
小句重心辨識是基於重心候選詞的萃取。
文章經 CKIP 10標記系統，並依標點符號
「，。！？；」切分成小句。而後將標記為普
通名詞(Na)、專有名詞(Nb)、地方詞(Nc) 的詞
彙，以及第一、第二人稱代名詞作為候選詞。
若遇連續的名詞組，則取最後的名詞作為候選
詞。由於中文常有出現名物化動詞的情形，故
我們參考[2]，將部分的名物化動詞列入候選詞，
如「是」前面的動詞、「的」後面的動詞，及
物動詞(VC)後面的動詞。我們也參考[15]，針
對中文常出現的零指代與第三人稱代名詞進
行辨識。 
2.1.2重心候選詞選取 
我們參考[7]的重心模型來進行小句重心選
                                                 
10
 CKIP: http://ckipsvr.iis.sinica.edu.tw/ 
取，並依照中文的特性加以改進。重心模型如
表 1 所示，其中 Ci 代表第 i 小句重心，Ci-1則
是 Ci 前一小句的重心，Ci-2 則是 Ci-1 前一小句
的重心，C 是 Ci 的候選詞。Can(Ci)表示 Ci 的
重心候選詞集合，C(3rd-anaphor)代表第三人稱
代名詞，C(Zero-anaphor)代表零指代。 
 
 
 
 
表 1：重心模型 
Case 1 延續：Ci-1＝Ci-2 且 
1.1 C Can(Ci), C＝Ci-1，則 Ci=C＝Ci-1 
1.2 (3rd-anaphor)Can(Ci) OR 
C(Zero-anaphor)Can(Ci)，則
Ci=Ci-1。 
Case 2 保留： Ci-1＝Ci-2, 且 
2.1 C Can(Ci), C≠Ci-1 且
C(3rd-anaphor)Can(Ci) AND 
C(Zero-anaphor)Can(Ci)，則
Ci=Can(Ci)。 
2.2 前一小句沒有重心(標示為 E)，或者
此小句為長句中的第一小句，則
Ci=Can(Ci)。 
Case 3 平順遞移：Ci-1≠Ci-2, 且 
3.1  kC Can(Ci-1),  jC Can(Ci), 
jk CC  ，則 Ci=Ci-1 = jk CC  。 
3.2 C(3rd-anaphor)Can(Ci) OR 
C(Zero-anaphor)Can(Ci) 則
Ci=Ci-1=C, where 
Freq(C)=MaxFreq( Can(Ci-1) )。 
3.3  kC Can(Ci-1),  jC Can(Ci), 
jk CC  ，且 C(3rd-anaphor) 
Can(Ci) AND C(Zero-anaphor)
Can(Ci)，則 Ci =Ci-1 =C , where 
Freq(C) =MaxFreq(Can(Ci), 
                                                                            
主題詞，系統以辨識正確率進行評估，其計算
公式如下： 
正確率 = 系統正確辨識主題詞的長句數/ 
總長句數 
為比較主題詞辨識成效，我們設計五種實驗模
組，分別以重心理論和一般詞彙方法來做比較，
如表 3。其中模組 I 為基本模組僅考慮頻率、
位置特徵，模組增加句間的一致性和延伸特徵，
模組 III則是再增加考慮主題詞的概念化特徵。
模組 IV 是以長句中出現頻率最高之小句重心
候選詞，做為長句的主題詞。模組 V 是以長句
中出現頻率最高之名詞或動詞為主題詞。實驗
結果證實所提的以小句重心理論模組確實較
辭彙模組得到較高的辨識。此外，所用的五種
特徵都是正向影響因子，因此我們以模組 III
做為後續應用於作文評量的工具。在第二組的
22 篇作文測詴語料上，對 188 個長句進行主題
詞辨識，得到 80.86%的正確率。 
3.主題辨識應用 
3.1 作文語料分析 
長句主題詞與小句重心可以用來協助教
師作學生作文的離題偵測。在本論文中，學生
作文語料為新竹市一所市立高中國文考詴的
95 篇學生作文；題目為「最上一層樓」，約 400
字作文。其引導文如下： 
95 篇學生作文作文分數分佈情形如表 4。
表 5 是我們以實驗模組Ⅲ對作文語料萃取主題
詞之實驗結果，並將此應用到作文離題和連貫
性偵測。 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖 2：作文「最上一層樓」之引導文 
 
 
表 3：社論語料之長句主題詞辨識實驗結果 
 模組 正確數 錯誤數 正確率 
重心理論 
模組 I 188 40 82.46% 
模組 II 194 34 85.09% 
模組 III 198 30 86.84% 
詞彙 
模組 IV 101 127 44.29% 
模組 V 89 139 39.04% 
 
表 4：作文分數分佈情形 
0~3 分 4~6 分 7~9 分 10~12分 13~15分 16~18分 
7  21  15  30  16  6  
 
有位富翁，一日到朋友家拜訪，那位
朋友的住屋有三層樓高，雄為壯麗，氣派
非常。特別是走到第三層樓，由此俯瞰四
方，感到視野廣闊，景致宜人。他在羨慕
之餘，回到家就招來工匠，在自家的地上
也要興建樓房，但是他命令工匠，不准先
建造第一層及第二層，他要的只是最上面
的一層樓。 
 
看完這則故事，請以「最上一層樓」
為題，寫一篇文章，抒發你的看法和感想。 
                                                                            
題者佔 7 篇，而這些離題文是中途岔開離題，
故的確有連貫性問題。剩下的 3 篇中，1 篇是
結尾草率、用詞不佳，1 篇為錯字太多，1 篇
是文中未能詳述道理與文章不夠精鍊。 
3.4 文章概念結構 
我們利用長句主題詞與其同義詞概念，進
行文章敘述結構的分析。圖 3a 與圖 3b 分別為
一篇高分與低分文章的主題詞詞串。我們可以
發現高分文章的結構較為嚴謹，會重複敘述到
重要的主題詞，以達到前後呼應的效果；而低
分文章傾向以直敘法來敘述，主題詞之間沒有
重複性，關連性低。 
 
 
 
圖 3a： 高分作文 A 之長句主題詞串 
 
圖 3b： 低分作文 E 之長句主題詞串 
我們統計作文結構含有與未含重複到訪主
題，並將含重複到訪主題者依照重複到訪主題
數與到訪距離細分如表 6 所示。重複到訪主題
數大於 1 者，表示其論述前後呼應，故其平均
分數最高(11.71 分)。到訪主題數等於 1 且其主
題詞距離若大於 2，表示間隔 2 長句以上才回
到原本主要主題，這中間的間隔有引名言、例
證，以多方取材而造成重複到訪主題的距離增
加，故其平均分數(10.93 分)明顯比距離小於 2
的平均分數(9.52 分)要高。 
表 5：「最上一層樓」離題實驗結果 
離題偵測方法 偵測結果 
篇數 
正確篇數 未含離題評語 
篇數 
正確率 文章平均 
得分 
五個概念化名詞 14 8 6 57.14% 8.07 
全部詞彙 22 10 12 45.45% 8.50 
長句主題詞 27 17 10 62.96% 8.56 
 
表 6：「最上一層樓」作文 未/含重複到訪主題之比較 
文章分數 有重複到訪主題 
有重複到訪主題 
未含重複到訪主題 到訪主題數=1 
(距離<=2 ; 距離>2) 
到訪主題數>1 
0~3 分 2 2  (1;  1) 0 5 
4~6 分 8 7  (5;  2) 1 13 
7~9 分 5 5  (4;  1) 0 10 
10~12 分 17 14 (7;  7) 3 13 
13~15 分 6 4  (2;  2) 2 10 
16~18 分 5 4  (2;  2) 1 1 
文章總數 43 36 (21; 15) 7 52 
文章平均分數 10.37 10.11 (9.52; 10.93) 11.71 8.96 
房子地基基石學習故事羅馬 
大樓(與房子同概念)工人 
意義叢林工程讀數字 
                                                                             
[14]  S. Tiun, R. Abdullah and T. Kong, ―Automatic Topic Identification Using Ontology 
Hierarchy.‖  Lecture Notes in Computer Science : Computational Linguistics and Intelligent 
Text Processing : Second International Conference, CICLing 2001. Mexico City, Mexico, 
2001. 
[15]  D. Wu and T. Liang, ―Improving Chinese Pronominal Anaphora Resolution Using Lexical 
Knowledge and Entropy-based Weight.‖ Journal of the American Society for Information 
Science and Technology, 59(13) (2008, November), pp. 2138-2145, 2009. 
[16]  C. Yeh and Y. Chen, ―Creation of Topic Map by Identifying Topic Chain.‖ Proceedings of the 
2004 ACM symposium on Document engineering, Milwaukee, Wisconsin, 2004. 
 
