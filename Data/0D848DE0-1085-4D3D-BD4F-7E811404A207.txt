X˙µ =
∑r
ρ=1 µ˙ρXρ, the time derivative of V (x(t)) along the
state trajectories is
V˙ (x) = x˙TX−1µ x+ x
TX−1µ x˙+ x
T
dX−1µ
dt
x
= xT (ATµX
−1
µ +X
−1
µ Aµ +
dX−1µ
dt
)x.
Base on Lyapunov theory, a sufficient condition is
ATµX
−1
µ +X
−1
µ Aµ +
dX−1µ
dt
< 0.
Pre- and post-multiplying the inequality above by Xµ yields
XµA
T
µ +AµXµ +Xµ
dX−1µ
dt
Xµ < 0.
Since
dX−1µ
dt
= −X−1µ X˙µX−1µ
we have
XµA
T
µ +AµXµ − X˙µ < 0
yielding
XµA
T
µ +AµXµ −
r∑
ρ=1
µ˙ρXρ < 0 (6)
By the virtue of the bounded µ˙ρ assumption, an upper bound
expression is given below:
LHS(6) ≤
r∑
ρ=1
φρXρ +
r∑
i=1
r∑
j=1
µiµjMij
=
r∑
ρ=1
φρXρ + µTMµ
= f(µ) < 0 (7)
where
|µ˙ρ| ≤ φρ, φρ ≥ 0
µ = [µ1 · · ·µr]′
M =
 M11 · · · M1r..
.
.
.
.
.
.
.
Mr1 · · · Mrr

Mij = (XjATi +AiXj)
and Mij are real symmetric, matrix-valued and linear functions
of decision variables (multiple Lyapunov matrices) Xi. Note
that the problem arisen with (7) involves infinitely many LMIs
associated with each value of the parameter µ and is known to
be intractable [17]. By enforcing some constraints of geometric
structure on the functional dependence in µ, it is possible to
reduce the problem to solving a finite number of LMIs. To
this end, we note that the parameter vector µ = [µ1 · · ·µr]′,
known as the firing strengths, evolves in the simplex defined
below
Γ := {µ :
r∑
i=1
µi = 1, µi ≥ 0}.
Recalling (1), we have the polytope Γ shown in Figure 1:
To ease the proof, we assume r = 3 so that a geometrical
Fig. 1. Firing strength in the three dimension space
structure becomes tangible and the vertices of Γ can be found
to be v1 = [1, 0, 0]′, v2 = [0, 1, 0]′, v3 = [0, 0, 1]′ (see Figure
1) and the sufficient condition (7) for r = 3 becomes
f(µ) =
3∑
ρ=1
φρXρ +
[
µ1 µ2 µ3
]
 M11 M12 M13M21 M22 M23
M31 M32 M33
 µ1µ2
µ3
 < 0 (8)
Equation (8) being a quadratic function of µ, Corollary 1 says
that f(µ) is negative whenever it is multiconvex along lines
paralleling the edges of Γ and furthermore f(µ) is negative
over vert Γ. The remaining of the proof follows in the two
phase : (A) showing the second derivative condition (2) is
satisfied so that the negativeness of V˙ is assured by (B)
checking the vertexes of Γ.
(A) To check the multiconvexity along the edges of Γ.
The directions dl, l = 1, · · · , q is determined by vectors with
all but two zero coordinates, the nonzero coordinates having
opposite signs.
Along the direction d1 := [1,−1, 0]′ of Figure 1, we get
f(µ+ λd1) =
r∑
ρ=1
φρXρ +
[
µ1 + λ µ2 − λ µ3
]
 M11 M12 M13M21 M22 M23
M31 M32 M33
 µ1 + λµ2 − λ
µ3

which yields
∂2f
∂λ2
=M11 +M22 −M12 −M21.
Along the direction d2 := [0, 1,−1]′, we get
f(µ+ λd2) =
r∑
ρ=1
φρXρ +
[
µ1 µ2 + λ µ3 − λ
]
 M11 M12 M13M21 M22 M23
M31 M32 M33
 µ1µ2 + λ
µ3 − λ

2
Proof: Consider a quadratic function V (x(k)) =
x′(k)X−1µ x(k) where Xµ =
∑r
j=1 µjXj . The time difference
of V (x(k)) is displayed below:
∆V = V (x(k + 1))− V (x(k))
= x′(k + 1)X−1µ x(k + 1)− x′(k)X−1µ x(k)
= x′(k)A′µX
−1
µ Aµx(k)− x′(k)X−1µ x(k)
= x′(A′µX
−1
µ Aµ −X−1µ )x < 0.
A sufficient condition is
A′µX
−1
µ Aµ −X−1µ < 0
yielding
XµA
′
µX
−1
µ AµXµ −Xµ < 0.
Schur complement gives[ −Xµ XµA′µ
AµXµ −Xµ
]
< 0
Rewriting the matrix inequality yields
0 >
[ −∑rj=1 µjXj ∗∑r
i=1
∑r
j=1 µiµjAiXj −
∑r
j=1 µjXj
]
= −
r∑
j=1
µj
[
Xj 0
0 Xj
]
+
r∑
i=1
r∑
j=1
µiµj
[
0 XjA′i
AiXj 0
]
= −µ′Mˆ + µ′M˜µ < 0
= f(µ) (14)
where µ = [µ1 · · · µr]′ and
Mˆ =
 M1..
.
Mr
 , Mj = [ Xj 00 Xj
]
M˜ =
 M11 · · · M1r..
.
.
.
.
.
.
.
Mr1 · · · Mrr
 Mij = [ 0 XjA′iAiXj 0
]
Notice that the matrices Mj and Mij are real symmetric,
matrix-valued and linear functions of decision variables (mul-
tiple Lyapunov matrices) Xi.
For r = 3, we have (14) displayed below.
f(µ) = −
 µ1µ2
µ3
′  M1M2
M3
+
 µ1µ2
µ3
′
 M11 M12 M13M21 M22 M23
M31 M32 M33
 µ1µ2
µ3
 .
Arguing in the same fashion as in the proof of continuous
case, we
(A) check multiconvexity condition: Along the direction
d1 := [1,−1, 0]′ (Figure 1), we get
f(µ+ λd1) = −
 µ1 + λµ2 − λ
µ3
′  M1M2
M3
+
 µ1 + λµ2 − λ
µ3
′  M11 M12 M13M21 M22 M23
M31 M32 M33
 µ1 + λµ2 − λ
µ3

Then
∂2f
∂λ2
=M11 +M22 −M12 −M21.
Similar to the first direction just shown, along the direction
d2 := [0, 1,−1]′ we get
∂2f
∂λ2
=M22 +M33 −M23 −M32.
and along the direction d3 := [−1, 0, 1]′, we get
∂2f
∂λ2
=M11 +M33 −M13 −M31.
For r = 3, the multiconvexity condition is satisfied if
M11 +M22 −M12 −M21 ≥ 0
M22 +M33 −M23 −M32 ≥ 0
M11 +M33 −M13 −M31 ≥ 0.
Arguing in the same fashion as r = 3 case, we have the
following results for the general case (1 ≤ i < j ≤ r)
Mii +Mjj −Mij −Mji
=
[
0 ∗
AiXi +AjXj − (AiXj +AjXi) 0
]
≥ 0
This proves inequality (13).
(B) Check vertexes condition:
At the vertex [1, 0, 0]′
f(v1) = −
[
1 0 0
]  M1M2
M3

+
[
1 0 0
]  M11 M12 M13M21 M22 M23
M31 M32 M33
 10
0

= −M1 +M11.
Similar to vertex [1, 0, 0]′, we arrive at the following ex-
pression for the vertex [0, 1, 0]′
f(v2) = −M2 +M22.
and for the vertex [0, 0, 1]′
f(v3) = −M3 +M33.
For r = 3, to ensure negativeness, we need
−M1 +M11 < 0
−M2 +M22 < 0
−M3 +M33 < 0.
4
