 2
1.3 Speech recognition 
The objective of speech recognition is to provide a 
friendly human-robot interface. Speech recognition is a 
fundamental problem for any speech processing system, and 
automatic speech recognition (ASR) is one of the leading 
technologies in man-machine interface for real-world 
applications. For ASR, Hidden Markov Models (HMMs) [29] 
have drawn great attention since 1980s, and have become the 
dominant approach, especially for large vocabulary, 
continuous speech recognition. In addition to HMM, many 
recognition algorithms based on artificial neural networks 
(ANNs) [30] have also been proposed due to their nonlinear 
mapping functionality, learning ability, and flexible 
architecture, which can easily accommodate contextual inputs 
and feedback. Many ANN structures, like the Time Delay 
Neural Network (TDNN)[31], and Linked Predictive Neural 
Network (LPNN)[32], have been proposed for speech 
recognition. The performance of ANNs is comparable or even 
better to HMMs for small vocabulary, isolated word 
recognition [31].  
In this project, recognizer design based on recurrent fuzzy 
neural is proposed. In addition, to increase the robustness of 
recurrent fuzzy networks for noisy speech recognition 
problems, a new network structure, the Singleton-type 
recurrent neural fuzzy network (SRNFN), is proposed. The 
SRNFN modifies the TSK-type consequence of TRFN [28] to 
be fuzzy singletons, such that the consequent values are less 
sensitive to noises contained in input variables.  
 
2. Skin Color Segmentation 
2.1. Color model  
Skin color segmentation is a very important step in face 
detection as faces are detected from segmented skin areas. A 
better segmentation result obtains a better detection 
performance. This project uses the Hue, Saturation and Value 
(HSV) color space. RGB color spaces may be transformed to 
HSV color spaces by the following three equations: 
  
[ ]-1
2
0.5 (R G) (R B)
H1 cos
(R G) (R B)(G B)
H H1                                  if   B G
H 360 H 1                        if  B G
− + −
=
− + − −
= ≤
= − >
      (1) 
Max{R,G,B}-Min{R,G,B}S  
Max{R,G,B}
=         (2) 
Max{R,G,B}V  
255
=                    (3) 
To eliminate the effect of lighting on the segmentation 
performance, only HS color space is used for skin color 
segmentation. The HS values are fed as inputs to SOTFN-SV 
[21] for skin color segmentation. The original ranges of H and 
S are [0, 360] and [0, 1], respectively. Before feeding HS 
values to a classifier, the range of H is scaled to [0, 1], so that 
its range is the same as S value. The scaled HS color values are 
denoted as hs. The SOTFN-SV segments skin color according 
to its output and a output threshold. This project uses a fuzzy 
system to adaptively determine the threshold according to the 
V color space. Therefore, influence of lightness on the 
segmentation result is minimized.  
2.2 Structure of SOTFN-SV 
This subsection briefly describes structure and learning of 
SOTFN-SV proposed in [21]. Figure 1 shows SOTFN-SV 
structure. Each rule in SOTFN-SV is with TS-type and is of 
the following form  
Rule i  :  IF 1x  is 1iA  And …  And nx  is inA    
Then 
1
n
ij j
j
y p x
=
′ =∑                               (4) 
where ijA  is a fuzzy set and ijp  is a real number. The 
model of this five-layered network is described as follows.  
Layer 1: Each node in this layer corresponds to one input 
variable, and only transmits input values to the next layer 
directly. The training data is represented by a set S  with  
1 1 2 2{( , ), ( , ) ( , )}N NS x y x y x y=
K K K"       (5) 
Layer 2: Each node in this layer corresponds to a fuzzy set 
A  and computes the degree to which an input value belongs 
to it. Fuzzy set kjA  is employed with the following Gaussian 
membership function: 
2
2
( )
( ) exp
2
j kj
kj j
k
x m
M x
σ
⎧ ⎫−⎪ ⎪
= −⎨ ⎬⎪ ⎪⎩ ⎭
       (6) 
where kjm  and kσ  denote the center and width of the 
fuzzy set, respectively. Here, for all the fuzzy sets connected to 
node k , the width is the same and is denoted as kσ . 
Layer 3: A node in this layer represents one fuzzy logic 
rule and performs antecedent matching of a rule. The following 
AND operation is used for each node: 
2
2
11
2
2
( )
( ) ( ) exp{ [ ]}
2
|| ||         exp{ }
2
n n
j kj
k kj j
jj k
k
k
x m
x M x
x m
µ
σ
σ
==
−
= = −
−
= −
∑∏K
K K        (7) 
where 1[ , , ]nx x x=
K … . Here the same width kσ  is 
assigned to all Gaussian fuzzy sets in the same rule. 
Layer 4: This layer is called the consequent layer. For 
each node k , a linear combination of the inputs, i.e. km x⋅
K K
, 
is performed, where km
K
 is the center of the Gaussian fuzzy 
set in the antecedent part of the k th rule. The combination 
result of each node is then multiplied by its corresponding 
firing strength kµ from layer 3. Thus, the output value, kO , 
of each node k  in this layer is as follows: 
2
2
|| ||( ) ( ) exp{ } ( )
2
k
k k k k
k
x mO x m x m xµ
σ
−
= ⋅ ⋅ = − ⋅ ⋅
K KK K K K K      (8) 
where the output kO  is the product of the Gaussian and 
linear functions. This function is a kernel function and is 
named TS-kernel in [21]. The node number in layer 4 is equal 
to the cluster number.  
Layer 5: Each node in this layer corresponds to one output 
variable. The node calculates the simple weighted sum for 
defuzzification. The node integrates all the actions 
recommended by Layer 4 plus a bias. Thus, the output can be  
 
 
 4
Color features that also fed as SOTFN-SV classifier 
inputs are introduced as follows. The colors of eyes and mouth 
are effective facial characteristics. For a frontal face, eyes and 
mouth are located in fixed positions. Therefore, approximate 
locating regions of eyes and mouth are predefined for a frontal 
face candidate in this thesis. Figure 2 shows the defined 
regions of eyes and mouth, where each region is represented by 
an ellipse to resemble the actual shape of an eye or mouth. In 
this figure, a and b  are major and minor axes of the BFE, 
respectively. As in skin color segmentation, scaled H and S (hS) 
values are used to represent a color pixel. Average hS values in 
each eye region and mouth region are computed. Average hS 
values for pixels inside the BFE except the eyes and mouth 
region are computed and used to represent facial skin color. 
Average hS color values of the eyes, mouth, and face regions 
are used as color features. That is, the color feature dimension 
is eight. These eight color features together with the two shape 
features constitute a ten-dimensional detection features and are 
fed as inputs to a SONTFN-SV classifier to make a final face 
or non-face decision.  
In SOTFN-SV training, the inputs are the ten-dimensional 
detection features, and the output shows category, face or 
non-face, to which the input feature belongs. That is, when the 
inputs are features from a face, then the desired output is “+1”; 
otherwise, the desired output is “-1”. Training patterns are 
collected from face candidates generated from skin color 
segmentation. Since the generated face candidates contain face 
and non-face patterns, no additional effort on manual selection 
of training patterns are required. In addition, the non-face 
pattern number is small because many non-face patterns have 
been filtered in stages one. This eases the whole classifier 
training process and reduces classifier size.  
During test, SOTFN-SV receives a ten-dimensional feature 
vector and sends an output y . If y θ≥ , where θ  is a 
predefined detection threshold, the corresponding face 
candidate is classified as “face”; otherwise, it is classified as 
“non-face”. 
4. Face Tracking 
Face detection is performed for each captured image. For 
face tracking, we use a Kalman filter algorithm to predict the 
next search region. Face detection is performed within a 
predicted window to reduce the computation cost and 
smoothes the tracking trajectory. Denote the position and 
velocity of the face center by ( , )c cx y  and ( , )x yv v , 
respectively. The system model for tracking is  
( 1) ( ) ( )
( 1) ( 1) ( 1)
x t Ax t w t
z t Hx t v t
+ = +
+ = + + +
K K K
K KK       (13) 
where [ ]T( ) c c x yx t x y v v=K , ( 1)z t +K  is observed 
position, ( )w tK and ( )v tK are measured noise and are assumed 
to be Gaussian noise with zero mean. The matrix A  is state 
transition matrix and is  
1 0 0
0 1 0 0
0 0 1
0 0 0 1
T
A
T
⎡ ⎤⎢ ⎥⎢ ⎥= ⎢ ⎥⎢ ⎥⎣ ⎦
. 
The structure of the measurement matrix H is 
1 0 0 0
0 0 1 0
H ⎡ ⎤= ⎢ ⎥⎣ ⎦
. 
The whole filtering procedure consists of two steps, the 
prediction and correction steps which are carried out 
alternatively.  
    The state in the next time step is predicted from the 
current state using 
ˆ ˆ( 1 | ) ( | )
ˆˆ( 1 | ) ( 1 | )
x t t Ax t t
z t t Hx t t
+ =
+ = +
K K
KK             (14) 
Face detection is performed on the window centered at 
ˆ( 1 | )z t t+K , and the window size is 200 × 200. Detection 
performed within the window instead of the whole image help 
reduce the detection time. This is important for real-time 
operation.  
The Kalman corrector is  
ˆ ˆ ˆ( 1| 1) ( 1| ) ( 1)( ( 1) ( 1| ))x t t x t t K t z t z t t+ + = + + + + − +K K K K (15) 
where ( 1)K t + is the Kalman gain and is computed as  
1( 1) ( 1) [ ( 1| ) ( 1)]T TK t P t H HP t t H R t −+ = + + + + (16) 
The covariance matrix P is updated as  
( 1 | ) ( ) ( | ) ( ) ( )
( 1 | 1) [ ( 1) ( 1)] ( 1 | )
TP t t F t P t t F t Q t
P t t I K t H t P t t
+ = +
+ + = − + + +
(17) 
where ( ) [ ( ) ( )],TQ t E w t w t= K K  ( ) [ ( ) ( )]TR t E v t v t= K K  and 
(0 | 0) [ (0) (0)]TP E x x= K K  
The Kalman corrector helps smoothen the trajectory of face 
tracking. 
 
5. Speech Detection 
5.1 Robust Detection Parameters 
Wavelet Transform (WT) is a technique for analyzing the 
time-frequency domain that is most suited for a non-stationary 
signal. For short-time analysis and discrete speech signal, 
discrete-time WT (DTWT) is used. Let the amplitude of the 
k th point in the i th frame of a noisy speech signal be 
denoted by ( , )s i k  and the frame length in sample number 
be represented by N . The DTWT of the i -th speech frame 
is as follows, 
0 0
10
1DTWT( , ) ( , ) ( )
N
m
m
k
m n s i k a k n
a
ψ τ−
=
= −∑ ,     (18) 
where ( )ψ ⋅  represents a wavelet basis function, 0ma  is the 
scale and 0τ  is a translation parameter which is set to 0
ma−  
in this project. The commonly used value 0a =2 is used in this 
project, resulting in a binary dilation. Thus, Eq. (18) can be 
written as  
1
1DTWT( , ) ( , ) [2 ( )]
2
N
m
m
k
m n s i k k nψ −
=
= −∑      (19) 
 
 (a) 
 6
the TSK-type consequence of TRFN to be fuzzy singletons, 
such that the consequent values are less sensitive to noises 
contained in input variables. In this section, the structure and 
learning of SRNFN are introduced below.  
The structure of SRNFN is shown in Fig. 5. In contrast to a 
six-layered TRFN, there are only five layers in SRNFN. To 
give a clear understanding of the mathematical function of 
each node, functions of SRNFN are described layer by layer 
below.   
Nodes in layer 1 are input nodes. The node only transmits 
external input values jx and internal input values ih  to layer 
2. Each node in layer 2 acts as a membership function. Two 
types of membership functions are used in this layer. For 
external input jx , Gaussian membership functions which 
locally map the input spatial space to the output space are used, 
and the mathematical functions is  
2
2
( )
exp{ }j iji
ij
x mµ
σ
−
= − ,          (22) 
where ijm and ijσ  are, respectively, the center and the width 
of the Gaussian membership function. For internal variable ih , 
sigmoid membership function 1/(1 exp{ })ih+ −  is used. 
Each internal variable has a single corresponding fuzzy set. 
Each node in layer 3 is called a rule node. The output of each 
node in this layer is determined by fuzzy AND operation.  
Here, the product operation is utilized to determine the firing 
strength of each rule.  The function of each rule is 
2
2
1 1
( )1 1 exp{ }
1 exp{ } 1 exp{ }
n n
j ij
i j
j ji i ij
x m
h h
µ
σ
= =
−
Φ = ⋅ = ⋅ −
+ − + −
∏ ∑ (23) 
Each node in layer 4 is called a context node and performs 
defuzzification operation for internal variable ih . The number 
of internal variables in this layer is equal to the number of rule 
nodes. The link weights represent the fuzzy singleton values in 
the consequent part of the internal rules. The simple weighted 
sum is calculated in each node,  
                    
1
r
i ij j
j
h w µ
=
=∑               (24) 
where r  is the number of rules. As in Fig. 5, the delayed 
value of ih  is fed back to layer 1 and acts as an input variable 
to the precondition part of a rule. Each rule has a 
corresponding internal variable ih  and is used to decide the 
influence degree of temporal history to the current rule. Nodes 
in layer 5 are called defuzzification nodes. Each node performs 
weighted average operation for output y . The node in this 
layer computes the output signal y of the SRNFN. The output 
node together with links connected to it act as a defuzzifier. 
The mathematical function is 
1
1
r
j jj
r
jj
b
y =
=
Φ
=
Φ
∑
∑                          (25) 
1b
1y
2 ( 1)h t +
1 ( 1)h t +
1 ( )h t 2 ( )h t
22w
21w
12w11
w
1x 2x
R1 R2
Z-1Z-1
Layer 4
Layer 1
Layer 2
Layer 3
Layer 5
2b
 
Fig. 5. Structure of the Singleton-type Recurrent Neural Fuzzy network 
(SRNFN). 
The task of constructing the SRNFN is divided into two 
subtasks: structure learning and parameter learning.  The first 
task in structure learning is to decide when to generate a new 
rule. The criterion of generating a new rule is the same as that 
used in TRFN, where the spatial firing strength 
1
( ) ( )ni jjF x xµ== ∏K K  is used as the criterion to decide if a new 
fuzzy rule should be generated. For each incoming data ( )x tK , 
find  
1 ( )
arg max ( ( ))ii r tI F x t≤ ≤=
K
        (26) 
where )(tr  is the number of existing rules at time t . If the 
rule with the maximum firing strength is smaller than a 
pre-defined threshold, i.e., ( )I inF F t< , then a new rule is 
generated, where ( ) (0,  1)inF t ∈ is a pre-specified threshold 
that decays during the learning process.  Once a new rule is 
generated, the initial centers and widths of the corresponding 
membership functions are computed by  
                ∑
=
+
+
−
⋅=
=
n
j Ij
Ijj
itr
iitr
mx
txm
1
2
2
)1)((
)1)((
)(
)(
σ
βσ   (27) 
for ni "1= , where 0β > decides the overlap degree 
between two clusters. In this project, β  is set at 0.8. The 
number of fuzzy sets in each external input dimension is equal 
to the number of fuzzy rules. Generation of a context node in 
layer 4 accompanies the generation of a rule. As to the 
parameters, they are tuned by real-time recurrent learning 
algorithm [7]. 
     When SRNFN is used as a detector, its input is a 
two-dimensional vector composed of WE and ZCR. The output 
of SRNFN indicates whether the corresponding frame is 
speech signal or noise. For this purpose, there are two outputs 
in SRNFN. When the input frame is speech signal, the desired 
output is (1, 0). On the contrary, when the input is noise, the 
desired output is (0, 1). During test, if the SRNFN outputs are 
1 2( ,  )y y  then the corresponding input frame is detected as 
speech signal if 1 2y y θ> + , where θ  is a threshold. Figure 
6 shows the speech with white noise added  
 
 8
 
Fig. 8. Test images and their face detection results; (a) Correct detections, (b) 
False detections.  
 
 
Fig. 9. Segmentation results using SOTFN-SV with a neighborhood averaging 
operation for the test images in Fig. 8. 
 
number of positive samples is much smaller than the number of 
negative samples, i.e., the training patterns are imbalanced, 
then the performance of classifier using general SVM training 
may be poor. For this problem, modified SVM can be used 
[30].  
Table 1. Test Performance of Different Skin Color Segmentation Methods in 
Experiment 1. 
 
 
For SOTFN-SV training, structure learning parameter thµ  
was set at 0.9 and consequence learning parameter C  was set 
at 68 10× . After learning, 31 rules were generated. To verify 
the generalization ability of the proposed segmentation method, 
400 images were used for testing. The ground truth is 
constructed by manually labeling the skin color regions. 
Fifteen of the 400 test images are shown in Fig. 8. The average 
hS values of a 10 × 10 non-overlapping pixel block were used 
as features in the skin color segmentation experiment. Figure 9 
illustrates the SOTFN-SV segmentation results with a 
neighborhood averaging operation. To measure segmentation 
performance, the Detection Rate (DR) was computed when the 
False Positive Rate (FPR) is equal to 10%. The DR gives the 
fraction of skin pixels being classified correctly and FPR gives 
the fraction of non-skin pixels being mistakenly classified as 
skin. Table 1 shows SOTFN-SV segmentation performance 
with and without a neighborhood averaging operation. The 
results indicate that SOTFN-SV with a neighborhood 
averaging operation achieved a higher DR than without it.  
  Gaussian kernel SVM, Fuzzy Neural Network (FNN) 
[11], Mixture of Gaussian Classifier (MGC) [15], and 
Histogram-based skin classifier (HSC) [9] were applied to the 
same segmentation problem for performance comparison. For 
FNN, the TSK-type self-constructing neural fuzzy inference 
network [11] was used, where the parameters were tuned by 
gradient descent algorithm. The models in MGC were trained 
using the standard Expectation-Maximization (EM) algorithm. 
Both FNN and MGC were trained using the same data as 
SOTFN-SV. HSC method comparison involved skin and 
non-skin histogram models using 50000 skin pixels and 50000 
non-skin pixels, respectively, from the 100000 training pixels. 
The HS space contained 32 bins per channel, equally 
partitioning the HS into 32 × 32 bins. Table 1 shows the 
structure, total number of parameters, and DR in each 
segmentation model. The results in Table 1 show that DR of 
SOTFN-SV is comparable to Gaussian kernel SVM and is 
higher than the other models. However, the number of 
parameters in SOTFN-SV is only about one fourth of Gaussian 
kernel SVM. That is, SOTFN-SV has the advantage of using 
far fewer parameters than SVM.  
 
7.2 Face detection  
After skin color segmentation, face detection performance 
was evaluated using 400 test images containing a total of 456 
human faces. The detection rate (DR) and number of false 
alarms (FA) were used to evaluate face detection performance. 
The DR is defined as the ratio between the number of faces 
correctly detected and the actual number of faces. A FA 
inaccurately claims a face detection. As stated in Section  
 10
 
(b) 
 
Fig. 12. (a) The clean speech. (b)The speech with white noise added and 
detection results of WE-based SRNFN and RTF-based RSONFIN.  
 
performed. Two sequences of training data are utilized because 
the succeeding test results show that a bad detection 
performance is achieved if only one training sequence is used 
for RTF-based RSONFIN. After training, there are seven rules 
in RTF-based RSONFIN.  
To get a quick view on the test performance of WE-based 
SRNFN and RTF-based RSONFIN with continuously varying 
SNR levels, one illustrative example is experimented. The 
result is shown in Fig. 12. In Fig. 12(b), white noise with 
changing noise levels is added to the clean speech in Fig. 12(a). 
For RTF-based RSONFIN test, the parameter “noise_time” 
that estimates noise energy is computed on-line. The results in 
Fig. 12 show that when the noise level changes successively or 
when the time between two words is too short, inaccurate 
estimation of “noise_time” occurs leading to a poor estimation 
result of RTF-based RSONFIN. For WE-based SRNFN, 
estimation of noise energy is unnecessary and much better 
detection results are achieved.  
For testing, the speech database is made up of sequences 
of words, where each sequence consists of ten isolated 
Mandarin words “0”, “1”," , “9”. Each sequence is uttered 
fifty times. Thus, there are fifty test sequences consisting of 
500 words in all. The total number of test samples in these test 
sequences is about 77.5 10× . The noise added to the speech 
sequence is of variable levels. The detection rates when 
FPR=0.1 for the WE-based SRNFN, WE-based TRFN, and 
RTF-based RSOFIN methods when variable-level white noise 
is added to each sequence with average SNR 5 ~ 20 in the test 
database are shown in Table 2, where the Detection Rate (DR) 
is defined as  
n u m b e r of c orrec tly d e tec te d  sp e ec h  fram esD R =
n u m b e r of sp e ec h  fram es
       (28) 
 
 
 
 
 
Table 2. Detection rates for different methods with white noise. 
 
 
 
 
 
 
 
 
 
 
Table 3. Performance Levels Of Different Types Of Recognizers For 
Recognizing Ten Words In A Clean Environment.  
 
 
 
and the False Positive Rate (FPR) is defined as  
number of noise frames detected as speech framesFPR
number of noise frames
=
    (29) 
The comparison results show that the WE-based SRNFN 
shows better performance than WE-based TRFN and 
RTF-based RSONFIN at different SNRs. For TRFN, the 
consequence is a linear combination of input variables, which 
makes the output being sensitive to noises in input variables, 
especially at lower SNRs. 
 
7.5 Speech Recognition 
Experiment 1: In this simple experiment, ten numbers in 
Mandarin “0”-“9”are recognized. For recognizer training, 100 
patterns collected from ten noise-free repetitions of each digit 
are used as training data. To avoid overtraining, 100 patterns 
collected from another ten noise-free repetitions of each digit 
are used for cross-validation. For recognizer test, another 100 
patterns collected in the same way are used. Speech 
recognition using SRNFN is experimented, and ten SRNFNs 
are created. After training, the number of fuzzy rules generated 
for each SRNFN ranges from 7 to 17.  Recognition results of 
SRNFN are shown in Table 3.  
For evaluation, the performance of TRFN is compared 
with SRNFN. The aforementioned recognition configuration is 
used except that SRNFN is replaced by TRFN. For each word 
recognizer, the number of fuzzy rules in TRFN is the same as 
that in SRNFN.  The recognition results are shown in Table 3, 
which shows that the performance of SRNFN is about the 
same as TRFN. 
Next, recognition by multilayer perceptron (MLP), time 
delay neural network (TDNN) and Hidden Markov Model 
(HMM) are tested. For MLP, one MLP discriminator with ten 
output nodes denoting the ten classes is used. Three frame 
features as fed as network input, i.e. network input node 
number is 36, and the inputs are shifted one frame-by-frame 
for succeeding inputs. The number of hidden nodes is 30. The 
parameter learning rate is 0.03.  For TDNN, the numbers of 
SNR WE-base
d 
SRNFN 
WE-based 
TRFN 
RTF-based 
RSONFIN 
20 92.66 91.21 80.71 
15 89.68 80.23 74.51 
10 86.65 68.91 57.37 
5 82.74 50.23 36.22 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 95-2218-E-005-003 
計畫名稱 智慧型看護與居家照顧機器人系統之設計與研製--子計畫三 : 機器人之智慧型聲控與視覺功能研究(3/3) 
出國人員姓名 
服務機關及職稱 
莊家峰 (Juang, Chia-Feng), 國立中興大學電機工程系 教授 
會議時間地點 2007 年 7 月 23 日至 26 日， 英國 倫敦 
會議名稱 
(中文) 2007 國際電機電子學會模糊系統研討會 
(英文) 2007 IEEE International Conference On Fuzzy Systems 
發表論文題目 Fuzzy controller design by ant colony optimization 
 
一、參加會議經過 
23 日︰本日為付費之 Tutorial 課程，個人並未付費參加。 
24 日 : 本日辦理註冊。在註冊現場有廠商展示。但主要為出版社展示較多。在此可得知
有那些最近模糊書籍出版。白天為一般 session 進行。共有 7 個 session 平行舉辦。每個
session 共 75 分鐘。其中並有一 plenary lecture 與 invited lecture。晚上 6:30pm~8:30pm 則
為 poster session。個人的論文亦在此發表。在此並遇到許多台灣的教授。可見台灣研究
模糊理論之學者亦不少。 
25 日︰本日白天亦為一般 session 進行。共有 7 個 session 平行舉辦。今日的重點為晚宴。
大會精心的安排在郵輪上舉辦，夜遊泰晤士河。其間除了晚宴之外，並有頒獎活動，頒
發對模糊理論有貢獻學者，即 IEEE Trans. Fuzzy Systems 年度最佳論文獎。在晚宴賞，
大家可以交談認識，個人在此亦認識了一些同領域的朋友。 
26 日: 本日白天亦為一般 session 進行。共有 7 個 session 平行舉辦。許多同行的台灣學
者，均在此日作論文發表。 
 
 
二、與會心得 
個人已出國參加會議多次，每次均自覺收穫頗豐。與第一次出國參與會議相較，因有
了多次的經驗，因此較懂得如何安排時間，以穫得最大的收益。本次計會議地點位在倫
敦，除了可來此希望相關領域的新資訊之外，亦參觀了劍橋大學的各個學院。此行遇到
相當多的台灣來的同儕。就個人而言，參加這次會議，無論在學術或生活視野的擴展上，
均覺得相當有收穫。 
事實上從事模糊理論研究的學者亦可感覺到，模糊理論相關的研究論文一直在急速的
增加中，其含概的範圍更包括各個領域，如控制、辨識、資料庫、決策系統及金融等。
這可由會場外展示的許許多多各類模糊理論的書籍及期刊可看出。此次開會，亦發現有
些領域的研究參與者有越來越多的趨勢，如模糊理論中的type-2理論，及support vector 
 
 
 
  
Abstract—An Ant Colony Optimization (ACO) application to 
a fuzzy controller design, called ACO-FC, is proposed in this 
paper for improving design efficiency. A fuzzy controller’s 
antecedent part, i.e., the “if” part of its composing fuzzy if-then 
rules, is partitioned in grid-type, and all candidate rule 
consequent values are then listed. An ant tour is regarded as a 
combination of consequent values selected from every rule. A 
pheromone matrix among all candidate consequent values is 
constructed. Searching for the best one among all combinations 
of rule consequent values is based mainly on the pheromone 
matrix. The proposed ACO-FC performance is shown to be 
better than other evolutionary design methods on one 
simulation example. 
I. INTRODUCTION 
Many evolutionary learning algorithms have been used 
to automate fuzzy system designs. The best-known existing 
evolutionary fuzzy system is the genetic fuzzy system [1]-[3], 
and many studies on this topic are currently being pursued. In 
contrast to evolutionary algorithms, a new swarm intelligence 
optimization technique, the Ant Colony Optimization (ACO) 
[4]-[6], inspired by real ant colony observations, has recently 
been proposed. The ACO is a multi-agent approach for 
solving difficult combinatorial optimization problems like the 
traveling salesman problem (TSP) [4]. In the ACO 
meta-heuristic, artificial ant colonies cooperate in finding 
good solutions for difficult discrete optimization problems. 
ACO algorithms have been successfully applied to a number 
of different combinatorial optimization problems, like data 
mining and network routing [7, 8]. In previous research [9], 
ACO has been used for fuzzy system design, where learning 
data is collected off-line in advance. In the on-line fuzzy 
controller design problem considered in this paper, no 
training data is available in advance. The data is generated 
on-line during the control process. Thus the significant rule 
determination and heuristic value assignment approach 
proposed in [9] cannot be applied to on-line control problems. 
Applying ACO to an on-line fuzzy controller design 
(ACO-FC) is proposed in this paper. In contrast to [9], a 
different type of pheromone matrix definition and heuristic 
value assignment approach is proposed in ACO-FC.  
Let a fuzzy rule be expressed in the form of “if … 
then ….”. In ACO-FC, the antecedent part is produced a 
priori and possible control actions are listed. Then, a possible 
control action needs to be assigned for each fuzzy rule for 
controller best performance. The best consequent action 
 
Chia-Feng Juang and Chun-Ming Lu are with the Department of Electrical 
Engineering, National Chung-Hsing University, Taichung, 402 Taiwan, 
R.O.C. (e-mail: cfjuang@ dragon.nchu.edu.tw). 
Hao-Jung Huang is with the Department of Electrical Engineering, 
Chung-Cho Institute of Technology, Yuan-Lin, Chang-Hua, Taiwan, R.O.C. 
selection of all fuzzy rules can be regarded as a combinational 
problem, and ACO is used to solve this problem. In ACO-FC, 
one selected control action combination of all fuzzy rules 
corresponds to one ant tour. Best combination selection is 
based on the pheromone trails between the candidate control 
actions. ACO-FC performance will be verified from Section 
IV demonstration simulation results. Comparisons with 
designs by evolutionary  
This paper is organized as follows. Section II describes 
the basic ACO algorithms concept. The proposed ACO-FC is 
introduced in Section III. Simulation results of ACO-FC is 
demonstrated in Section IV. Finally, conclusions are 
presented in the last section.  
II. BASIC CONCEPT OF ANT COLONY OPTIMIZATION (ACO) 
The ACO meta-heuristic was inspired by real ant 
behavior, particularly how they forage for food [4]-[6]. In 
ACO algorithms, a colony of artificial ants with finite size is 
created, and each ant develops a solution. The performance 
measure is based on a quality function ( )F ⋅ . ACO 
algorithms can be applied to problems described by a graph 
consisting of nodes and edges connecting the nodes. 
Optimization problem solutions can be expressed in terms of 
feasible paths on the graph. Among the feasible paths, ACO 
can be used to find the one with minimum cost. The problem 
of selecting fuzzy rule consequences can be described by a 
graph as shown in Section III, and solved by ACO algorithms. 
The information collected by ants during the search process is 
stored in pheromone trailsτ  associated to edge connections. 
The ants cooperate in finding the solution by exchanging 
information via the pheromone trails. Edges can also have an 
associated heuristic value η  representing a priori 
information about the problem instance definition or run-time 
information provided by a source different from the ants. 
The first algorithm to fall within the ACO algorithms 
framework was the ant system (AS) [4]. The overall AS 
algorithm is described, using the TSP as an example. Given a 
number of cities, the TSP objective is to find a minimal travel 
length, visiting each city once. A set of N  cities, represented 
by nodes, and a set E  of edges fully connecting the 
N nodes are given. Let ijd  be the length of the 
edge ( , )i j E∈ , that is the distance between cities i  and j , 
with ,i j N∈ . At each time t, an ant in city i has to choose 
the next city j it goes to, from those cities not already visited. 
Let ( )ij tτ  be the pheromone level on edge ( , )i j  at time t , 
and ijη  be the corresponding heuristic value. In AS, the 
Fuzzy Controller Design by Ant Colony Optimization 
Chia-Feng Juang, Member, IEEE  Hao-Jung Huang and Chun-Ming Lu 
1-4244-1210-2/07/$25.00 ©2007 IEEE.
29
 
 
 
the consequent action selected by mR  is iu , then for 1mR +  
the selection of one consequent action out of the 
N candidates is based on ijτ , 1 ~j N= . This means that 
consequent part selection of each fuzzy rule is dependent on 
the consequent part of its neighboring fuzzy rule. The special 
value 0 jτ  determines the control action selection of 1R  
when an ant moves out from its nest.  
Determination of the heuristic value η  usually requires 
a priori information about the problem instance. The 
controlled plant model is assumed unknown in this paper, and 
no input-output training is collected in advance except the 
change of output direction with control input. For example, in 
a temperature control system, it is known that control voltage 
increase causes a higher temperature. For the candidate 
control actions in each fuzzy rule, two heuristic values Lη  
and Sη ( Lη > Sη ) are assigned to two sets of control actions, 
the non-negative and non-positive, respectively. According 
to one of the control input variables, like control error ( )e k  
or its change ( )e k∆ , the set of control actions that will cause 
a smaller error is assigned with Lη , and the other set is 
assigned with Sη . Take the temperature regularization 
control system as an example. Suppose the difference, ( )e k , 
between real output ( )y k and desired output 
temperature ( )dy k , i.e. ( ) ( ) ( )de k y k y k= − , is used as 
one of the controller inputs. For the fuzzy rules whose 
antecedent variable ( )e k  is non-positive, i.e. 
( ) ( )dy k y k≤ , then the set of non-negative control actions 
are assigned with Lη  and the other set is assigned with Sη . 
The same idea is applied to the other fuzzy rules whose 
antecedent variable, ( )e k , is non-negative. 
In the initial of the ACO-FC system, a colony of aN  ants 
is generated and placed in the nest, (0)ijτ s’ are set as 
positive constants, and a terminal condition is defined. The 
terminal condition in this paper is the total number of 
searching iterations performed by the ant colony. Next, the 
ant travels through a tour that corresponds to the choice of all 
fuzzy rule consequent actions, according to the pheromone 
level. When the current fuzzy rule consequent action is iu , 
then the transition probability from iu  to the following fuzzy 
rule candidate actions is given by  
1
( ) ( )
( )
( ) ( )
i j j
i j n
i j jj
t
p t
t
β
β
τ η
τ η=
= ∑              (6) 
where t  denotes the iteration number and 1, ,j N= … . In a 
fuzzy controller, since it is natural for different fuzzy rules to 
use the same control action, the set kiN  in Eq. (1) is released 
to the whole set U  for all i  in Eq. (6). When an ant 
completes a tour, the overall fuzzy controller and its control 
performance is evaluated by a quality function F . A higher 
value calculated by F  means better control performance. 
For each iteration, after all the ants in the colony have 
completed their tours, i.e. the construction of aN  whole 
fuzzy controllers, we find the globally highest F  from the 
start of the algorithm and denote it as *kF . The new 
pheromone ( )ij tτ  is updated by  
( ) ( ) ( )ij ij ijt t tτ ρτ τ= + ∆                     (7) 
where 0 1ρ< <  is the pheromone trail evaporation rate and  
*
*
,      if  ( , ) global-best-tour and 
( )                 a new  is found in the iteration
0,                       otherwise
k
ij k
c F i j
t Fτ
⋅ ∈∆ = 
     (8) 
where c is the parameter for controlling the update amount. 
Finally, the ants will find the best consequent action 
combination according to pheromone level and heuristic 
values.  
IV. SIMULATIONS 
To verify the performance of ACO-FC, simulation on a 
tracking control problem is conducted. In the example, the 
antecedent part is partitioned in advance by a grid-type 
partition, and the consequent part is designed by ACO. In 
ACO, the ant number is aN =10, and parameters ρ  and c  
are set to 0.9 and 0.1, respectively. The heuristic values are 
set at Lη =8 and Sη =2. The initial pheromone τ (0)s’ are 
all set to 1. Simulation results by other design methods are 
also performed and compared in this example.  
Example.  (Tracking control) 
The plant to be controlled is described by 
3
2
( )( 1) ( )
1 ( )
y ky k u k
y k
+ = ++                       (9) 
where ( )u k is the controller output. The objective is to 
control the output ( )y k to track the following desired 
trajectory 
     ( ) 0.1 sin( ),       1, ,600
100d
ky k kπ= ⋅ = …            (10) 
The controller input variables are control error ( )e k and its 
variation with time ( )e k∆ , defined as 
( ) ( ) ( )de k y k y k= −  and ( ) ( ) ( 1)e k e k e k∆ = − − , 
respectively. For each input variable, Gaussian fuzzy sets are 
used, and there are seven Gaussian fuzzy sets in the two 
inputs. The Gaussian membership function is defined by  
(a)                                       (b) 
31
