  
行政院國家科學委員會補助專題研究計畫 █成果報告   □期中進度報告 
 
3-D MOD：網路立體視訊播放系統— 
子計畫四：任意視角立體視訊合成器設計 
 
計畫類別：□個別型計畫   █整合型計畫 
計畫編號：NSC 99－2221－E－035－094－ 
執行期間：2010 年 08 月  01 日至 2011  年 08 月 31 日 
 
執行機構及系所：逢甲大學電子工程學系 
 
計畫主持人：陳冠宏 
共同主持人：郭峻因 
計畫參與人員：章志豪、陳正豪、陳慶儒、王立慶 
 
 
 
成果報告類型(依經費核定清單規定繳交)：█精簡報告  □完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
█出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            █涉及專利或其他智慧財產權，□一年█二年後可公開查詢 
 
中   華   民   國   100 年  8  月  31  日
  1 
 
第一章、 前言 
由於立體電影的推出，將已經行之有年的立體顯示技術首次展現在大戲院中，廣受
大眾的好評，因而掀起了一股立體風潮，從此之後，消費者對於影像上有了更進一步的
要求，除了高解析度的畫質之外，更要求畫面的立體化，甚至是多視角的播放方式，希
望能有更為貼近真實場景的體驗。  
而現有市面上多數的立體播放系統都是需要戴上特殊眼鏡 (例如 :紅藍眼鏡、快閃式
眼鏡、偏光式眼鏡 )，才能使得畫面有立體的效果，這無非是一項令人覺得麻煩的事情，
且對於部分原本就因為視力問題配戴眼鏡的人而言，更是一大困擾，再加上長期觀看下
來，會使人有眼花、暈眩、嘔吐感的不適症狀出現，導致有部分人對於立體視訊的推廣
失去信心，所以希望藉由裸眼式立體的顯示技術的研發來解決這些不便，使得立體視訊
的格式成為新一代的視訊主流，並且運用於各方面上。  
國內外學者在立體顯示方面投入大量的人力和物力來研究此領域，但卻發現，大眾
們對於此立體播放系統卻仍保持觀望態度，重點原因就是在於，即便有了相當完善的立
體顯示系統，但能夠支援立體顯示的播放內容過少，且在立體視訊的格式上也尚未統
一，使用上大為不便；再者，過去相當大量的平面影像都無法在目前的立體顯示系統中
以立體的方式呈現出來，所以除了立體顯示器端需要加強顯示的效果之外，在立體播放
內容的產生上，也需要龐大的技術基礎。  
所以現今許多學者開發了相當多樣的立體視訊相關演算法來使得製造立體視訊更
為簡單且快速；另外也使得過去的平面影像可以透過演算法來計算出立體播放時需要的
深度資訊，使得播放內容的產生不再侷限於高成本的立體拍攝系統上，降低了播放內容
產生的困難度，漸漸的提高立體播放器以及立體視訊的市場普及度和接受度，國內外許
多業界的先進們也願意投入大量資源來開發這新一代的視訊型態。  
 
第二章、 研究目的 
為了讓大眾感受到身歷其境的立體感，立體顯示器除了要能讓觀看者感受到類似真
實空間之深度感外，還必須能隨著視角不同而提供多重視角之影像。若要達到此功能，
最直接的作法就是在拍攝某場景或目標時，於每個視角上皆架設一攝影機，利用緊密的
攝影機陣列將所有視角畫面拍攝起來，再透過網路或其他傳送介面傳送給使用者。  
然而，這樣的方法在實務上並不可行，龐大的攝影機陣列會導致拍攝時的不便，且
設備的成本上也相當可觀；再者，隨著提供的視角畫面增加，在影像傳送的頻寬和儲存
上，負擔必然會隨之劇增。為了降低如此龐大的硬體成本，希望透過少許拍攝畫面的資
訊，將其中間畫面以合成的方式產生出來，如此一來，可以同時有效的降低拍攝硬體數
量、傳送和儲存時的資料量，使得多視角視訊的未來性大增。  
現有的視角合成技術，主要是透過拍攝影像所對應的深度資訊來合成出虛擬的視角
畫面，所以深度資訊的準確程度會最直接的反應在合成的虛擬視角畫面上，但由於深度
要達到完全正確是相當困難的，所以在視角合成演算法上，通常都會加入一些針對特定
的深度誤差的處理程序，降低錯誤深度對於虛擬視圖的影響。  
  3 
 
Synthesis With Boundary-Splatting)”之專利提出邊界潑濺 (boundary-splitting)之扭曲方法
[5]，若扭曲的像素位於邊界處時，利用潑濺技術將像素值再貼至該像素位置的左邊及右
邊上最接近之目標像素，目的是減少邊界周圍之空洞或減輕非邊界位置中的高頻細節損
失。  
第四章、 提出之視角合成演算法 
本計畫之主要目的在於提供一解決深度圖中物件大小與實際物件大小不相符之深度
錯誤、修正合成後物件中裂縫被背景物件填補之錯誤以及減少冗餘運算之視角合成演算
法。實際錯誤情況範例如圖 1 所示，圖中之綠色角錐在扭曲運算後，出現了兩種誤差，
第一種是明顯的物件邊界殘留，第二種是同一物件內部出現具有背景物件像素值的裂
痕。  
  
圖 1 殘留的物件邊界與物件中的裂痕示意圖  
 
圖 2 本計畫所提出之非對稱式視角合成圖  
所提之方法適用於對稱與非對稱式的視角合成，可修正深度不匹配之錯誤以及同
一物件中之裂縫情況，且根據 [4]為基礎提出一改良的非對稱式視角合成，如圖 2，與
前述非對稱式視角合成最大的不同在於扭曲運算部分，為了修正深度上的特定錯誤，
加入了兩個改善的技術，去除深度不匹配區域 (Residual-Edge Removing)與物件內裂縫
  5 
 
某像素的整數位移量。ScaleFactor 是量化因子，用以轉換深度值和位移量 (或稱視差值 )，
此值通常和視差估計運算時的搜尋範圍有關，大致上來說，左右相機鏡頭的差距越大，
深度估計時的搜尋範圍會變得越大，而量化因子則是變得越小。舉例來說，當鏡頭距離
為 5 到 20 公分左右時，量化因子大約是介於 4 到 1 之間。 (2)表示左圖計算位移量 (dl)
之公式，而 (3)表示右圖計算位移量 (dr)之公式，而 “weight”表示使用者或觀看者選取視
角的參數，此參數介於 1 到 0 之間，越靠近 1 表示越接近右視角畫面，越接近 0 表示越
接近左視角畫面。   
                     (2) 
                     (3) 
如圖 3 所示，計算出像素位移量後，先判斷目前像素座標 (水平方向座標 )加上此量
後是否會超出圖片或影像的最大邊界，若超出最大邊界則進行下一像素的運算。若未超
出邊界，判斷此像素之深度值是否大於水平座標加上位移量後之像素 (稱之為目標像素 )
的深度值，若當前像素深度值並未大於目標像素深度值，表示此像素在扭曲後，是被遮
蔽的像素，所以就進行下一像素的計算。若當前像素的深度值大於目標像素的深度值，
表示此像素在扭曲後是屬於前景的物件，所以此一像素會被顯示出來。  
因為要將可能出現深度錯誤之處先設定為空洞，以便後續的空洞填補可以修補此區
域，所以在此加入深度邊界判斷。  
以深度圖物件小於實際物件為例，深度圖發生錯誤的地方會出現在前景物件和背景
物件交界之處，且錯誤的地方會成為背景的深度值，一旦出現這種情況，在後處理很難
以空洞填補的方式填補起來。所以我們提出一方法可以在扭曲運算時就先將這些地方以
正確的資訊填補起來。  
深度出現錯誤的地方，通常都位於物件的邊緣處，所以先判斷此像素是否位於深度
邊界，若是位於深度邊界，表示這裡是可能出現錯的地方，接下來再加入深度不匹配條
件的判斷，如此才不會將所有邊緣皆視為不匹配錯誤區，藉此一步驟提高判斷的準確度。 
以深度圖上物件小於實際物件的情況為例，當目前像素在邊界處時需再判斷目前像
素深度值是否小於目標像素的右邊一個座標單位的像素深度值，或是目前像素深度值小
於目標像素左邊一個座標單位的像素深度值 (此 ”一個 ”可以依照深度圖的錯誤特性來做
修改 )，若上述條件成立，則表示此像素是位於錯誤區的，所以將此像素位移後座標上的
像素值指定為空洞；若上述條件都未成立，則表示此像素並非在可能錯誤區，同時因為
該像素是位於邊緣區，所以只將目前像素填入，而不進行補償像素判斷。  
若目前像素不在邊界處時，表示目前像素扭曲後，是位於物件中間，而為了防止物
件內部出現裂縫，所以在此我們會進行補償像素的判斷，如圖 4 所示， “D”表示四捨五
入前之位移量 (非整數位移量 )，而 “Dt”表示四捨五入後之位移量 (整數位移量 )，進行補償
式扭曲運算前，先將當前像素的像素值及深度值填入目標像素，接下來計算非整數點位
移量 (dlf)，如方程式 (4)，非整數點位移量是用來與整數點位移量進行比較大小，判斷出
當前像素位於目標像素的左邊或右邊。  
                       (4) 
若是 D < Dt 之情況，整數點位移量大於非整數點位移量，表示當前像素在扭曲後，
對於目標像素及其左方像素皆有影響，所以再另外判斷目標像素的左方像素深度值是否
  7 
 
況下，就使用相同的位移量，此一作法可以大量的降低運算時間，因為判斷是否相同只
需進行一次減法，而計算位移量則最少需要一個乘法和一個除法，且通常一張深度圖
上，深度連續的區塊會占整張圖大部分的區域。  
圖 7 為一區塊式扭曲之範例，彩色部分代表原圖上之色彩，黑白部分表示相對應的
深度值，藍色圓圈代表運算位移量的運算單元。  
 
                     (a)                  (b) 
圖 7 區塊式扭曲運算示意圖 (a)原始作法(需要 10 次扭曲運算) (b)加入區塊式扭曲(需要 3 次扭曲運算) 
第五章、 結果與討論 
5.1 實驗結果  
表 1 中，Before 為尚未加入去除深度不匹配區域與物件內裂縫補償之 PSNR，After
為加入後之 PSNR，平均提升了約 1.7dB 左右。  
表 1 改善前後之 PSNR 比較  
Sequence Before(dB) After(dB) upgrade(dB) 
Cones 24.35 28.73 4.38 
Teddy 29.08 30.82 1.74 
Venus 33.16 33.75 0.59 
Sawtooth 32.96 33.05 0.09 
 
 
圖 8 提升速度前的時間分析  
  9 
 
5.3 結論  
本計畫提出一具有修正深度不匹配與補償深度誤差功能之低複雜度視角合成演算
法，在改善虛擬視角畫面品質上，提出了兩大技術，去除深度不匹配區域與物件內裂縫
補償，降低了深度圖誤差對於虛擬視角合成圖的影響，相較於未加入此技術前的作法平
均提升了 PSNR 約 1.7dB，而在提升運算速度方面，也提出一區塊式扭曲運算之技術以
及合併部分重覆運算，提升 30 倍之效能，在小畫面的即時運算，適合應用在攜帶型多
媒體平台上。  
誌謝 
此計畫是由行政院國家科學委員會補助之下完成，計畫編號為 NSC 99－ 2221－E－
035－ 094 與總計畫編號為 NSC 99－ 2221－E－ 194－ 045，特別在此感謝。  
參考文獻  
[1] Ying Chen, Weixing Wan, Miska M. Hannuksela, Jun Zhang, Houqiang Li, and Moncef Gabbouj, 
“Depth-level-adaptive view synthesis for 3D video,” in Proc. ICME'2010, pp. 1724 - 1729, 2010. 
[2] Hsin-Chia Shih, and Hsu-Feng Hsiao,“A depth refinement algorithm for multi-view video synthesis,”in 
Proc. ICASSP'2010, pp. 742 - 745, 2010. 
[3]  Lu Yang1, Tomohiro Yendo1, Mehrdad Panahpour Tehrani1, Toshiaki Fujii, and Masayuki 
Tanimoto,“Error supression in view synthesis using reliability reasoning for FTV,”in Proc. 3DTV-CON, 
pp. 1 - 4, 2010. 
[4] Y.-M. Feng, D.-X. Li, K. Luo and M. Zhang, "Asymmetric Bidirectional View Synthesis for Free 
Viewpoint and Three-dimensional Video," IEEE Trans. on Consumer Electronics , vol. 55, no. 4, 
pp.2349-2355, 2009. 
[5] 中華民國專利-具有範圍潑濺之景色合成 VIEW SYNTHESIS WITH BOUNDARY-SPLATTING，公開
號 201023618。 
[6] Pei-Kuei Tsung, Hsin-Jung Yang, Pin-Chih Lin, Kuan-Yu Chen, and Liang-Gee Chen,“Hybrid color 
compensation for virtual view synthesis in multiview video applications,”in Proc. ISCAS'2010, pp. 12F1 - 
124, 2010. 
[7] J. Lu, S. Rogmans, G. Lafruit, and F. Catthoor, “Stream-Centric Stereo Matching and View Synthesis: A 
High-Speed Approach on GPUs,” IEEE Trans. on CSVT., vol. 19, no. 11, pp. 1598-1611, Nov. 2009. 
[8] Shinya Shimizu, and Hideaki Kimata,“Improved view synthesis prediction using decoder-side motion 
derivation for multiview video coding,”in Proc. 3DTV-CON, pp. 1 - 4, 2010. 
[9] Xin Tong, Ping Yang, Xiaozhen Zheng, Jianhua Zheng, and Yun He,“A pixel gradient-based adaptive 
interpolation filter for multiple view synthesis,”in Proc. ICME'2010, pp. 938 - 943, 2010. 
[10] P. Ndjiki-Nya, M. Koppel, D. Doshkov, H. Lakshman, P. Merkle, K. Muller, and T. Wiegand,“Depth 
image based rendering with advanced texture synthesis,”in Proc. ICME'2010, pp. 424 - 429, 2010. 
[11] Hariprasad Kannan, Kiran N Iyer, Kausik Maiti, Devendra Purbiya, Ajit Bopardikar, and Anshul 
Sharma,“Alpha model based mixed pixel processing for view synthesis,”in Proc. 3DTV-CON, pp. 1 - 4, 
2010. 
[12] Ting-Ching Lin, Hsien-Chao Huang, and Yueh-Min Huang,“Preserving depth resolution of synthesized 
images using parallax-map-based dibr for 3D-TV,”IEEE Trans. on Consumer Electronics, vol. 56, no. 2, 
pp. 720 - 727, 2010. 
 1 
可供推廣之研發成果資料表 
█可申請專利  □ 可技術移轉                                      日期：100 年 8 月 10 日 
國科會補助計畫 
計畫名稱：3-D MOD：網路立體視訊播放系統—子計畫四：任意視
角立體視訊合成器設計 
計畫主持人：陳冠宏 
計畫編號： NSC 99－2221－E－035－094 
領域：微電子學門(積體電路及系統設計) 
技術/創作名稱 具有檢查深度不匹配與補償深度誤差功能之低複雜度視角合成演算法 
發明人/創作人 陳冠宏 
技術說明 
中文： 
本發明是應用於多視角視訊應用之具有低複雜度和錯誤深度
區域判斷功能之視角合成。根據深度邊界判斷和視差量四捨五入前
後的比較，分別進行補償式扭曲運算和殘留物件邊緣的修正，提高
虛擬視圖之真實性。此外，我們利用判斷深度連續情形來降低運算
的複雜度，以提升視角合成技術的實用程度。最後以 Middlebury
大學網站上所提供之測試序列來進行評測，皆可達到 PSNR 平均
30 以上，且達到即時運算之需求。 
英文： 
The invention is applied to multi-view applications. The low 
complexity algorithm could determine the error region of depth map. 
According to edge-judgment and the comparison of the rounding 
disparity, we could solve the problems that are residual edges and the 
crack in one object. We utilize the continuity of depth to group the 
same depth values to reduce the computational complexity. 
可利用之產業 
及 
可開發之產品 
可利用之產業：消費電子產業 
可開發之產品：具多視角影像產生之多媒體平台 
技術特點 
低複雜度、且對於深度錯誤有修正功能之視角合成演算法 
推廣及運用的價值 
提供立體影像更為真實的觀感，促進新一代視訊型態的發展 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
頁  2 
 
(b) Regular sessions: 本次大會主題包含： 
1. Computer technology 
2. Electrical engineering 
3. Automation control 
4. E-Commerce 
5. Management science 
 
二、與會心得 
個人所發表之論文：適用於非穿戴式量測之足部反作用力感測裝置於八月十日
上午以口頭演說方式發表，與會國際學者相當多，因我們所提設計深具學術與實用
價值，發表後有許多學者發問討論，反應良好。除發表論文之外，個人也充份利用
時間參與其他論文之研討，收穫良多。以下為個人主要參與研討之論文： 
        Computer technology: 
(1) Secure Cloud Computing Architecture on Mobile Internet 
(2) Algorithmic Research of Speeding License Plate Location Based on Mathematics 
Morphology 
(3) The application of real-time operating system QNX in the computer modeling and 
simulation 
(4) Application and Analysis of UWB in Emergency Materials Storage 
(5) Research of monitoring method modeling of moving objects in video 
(6) Stereo Vision-based Fast Obstacles Avoidance without Obstacles Discrimination 
for Indoor UAVs 
        Electrical engineering: 
(1) Sensorial Structure for Unobtrusive Measurement of Feet Reaction Force 
(2) A fast and accurate approach image identification based on general randon 
transform 
(3) An improved accuracy rate for face authentication with pose adjustment based on 
2D-3D transform 
(4) Reverberant Speech Enhancement by Spectral Processing with Reward-punishment 
Weights 
(5) Image-Based Measurement of Particle Movement in Rotating Cylinders 
(6) The Natural Ventilation System Study On Electric Vehicle 
          Automation control: 
(1) A Novel Low-stress Driven Technique for On-panel TFT Gate Driver 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/11/08
國科會補助計畫
計畫名稱: 子計畫四：任意視角立體視訊合成器設計(I)
計畫主持人: 陳冠宏
計畫編號: 99-2221-E-035-094- 學門領域: 積體電路及系統設計
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
競賽得獎 
1.2011 年全國嵌入式系統設計競賽創意應用組 佳作 
2.2011 年全國 MatLab 論文競賽優選 
3.2011 年逢甲大學 MatLab 校園論文競賽第四名 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
