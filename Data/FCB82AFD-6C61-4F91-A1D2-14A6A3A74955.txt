1行政院國家科學委員會專題研究計畫成果報告
支援無線感測網路應用之致能技術及協定設計之研究
Research on Enabling Techniques and Communication Protocols for Wireless Sensor
Network Applications
計畫編號：NSC 95-2221-E-011-085
執行期限：93 年 8 月 1 日至 96 年 7 月 31 日
主持人：陳金蓮 教授 國立台灣科技大學 電子工程研究所
計畫參與人員： 許俊彥 國立台灣科技大學 資訊工程研究所
陳建忠 國立台灣科技大學 電子工程研究所
詹益昇 國立台灣科技大學 電子工程研究所
吳志偉 國立台灣科技大學 電子工程研究所
侯玉祥 國立台灣科技大學 電子工程研究所
林依潔 國立台灣科技大學 電子工程研究所
摘 要
無線感測節點具有通訊能力，可自
組成為一無線感測網路用以監測並蒐集
各種環境資訊，並可實際應用在醫療、
土木或軍事等等用途之上。由於無線感
測網路的感測節點數量多且密度大，其
路由協定常常受到擴充性(scalability)與
節點密度(node density)的限制，因此路由
協定必須另外特別設計。
本計畫在感測網路節點緊急訊息通
報的路由協定設計方面，以 Appointed
BrOadcast (ABO)方法為基礎，設計了一
套協定能夠減低網路層找尋路徑時傳送
與接收封包花費的頻寬，並以模擬結果
說明其性能，藉 由 使用封包側聽
(overhearing)的方式可明顯降低路徑發
現所需的代價。
此外，針對感測網路服務資訊散播
及資訊搜尋設計出資源散播及搜尋協
定，稱為 Simple Resource Advertisement
and Discovery (SRAD)，適合用於網路型
態大且稠密之無線感測網路，此協定可
使節點自我組織成一個完全分散式架構
的能力，模擬結果顯示在大量且密集的
無線感測網路中傳送訊息時，SRAD 協
定仍能達到不錯的效能。
為考量感測網路節點電源的管理，
以降低電能之消耗，本研究提出 throw
and drowned (T&D) flooding protocol、叢
集式 cluster-based 演算法等協定，模擬結
果顯示此協定及演算法可達到省電及延
長網路的生命時間的目的。另外，針對
軟體無線電技術之應用，我們亦提出一
種讓無線感測網路中所有節點即時下
載、更新軟體的方法。
最後，我們另提出 cross-layer link
adaptation (CLLA)及CSMA protocol with
collision avoidance, packing and
accompanying (CSMA/CAPA)方法。模擬
結果顯示即使在資料錯誤率很高的情況
下，CSMA/CAPA 方法也能明顯提高網
路的 capacity，而 CLLA 方法在移動環境
中可以達到更高的流通量。
關鍵詞： Appointed BrOadcast (ABO),
SRAD, throw and drowned (T&D),
cluster-based, SDR, CSMA/CAPA, CLLA
Abstract
3multi-hop implicit routing method, called
throw and drowned (T&D) flooding protocol,
which has threefold mechanisms for
power-saving. First, T&D is capable of
turning sensor node into sleeping mode to
save power. Second, T&D is designed as a
flooding-based and implicit routing protocol.
Last, T&D uses “link-layer-relaying” instead 
of “network-layer-forwarding.” Most ofthe
sensing tasks require knowledge of location
information and part of WSNs routing
protocol requires the assistance of location
information. The T&D does not use the
sensornode’s location information. However, 
it can be applied to the applications whether
they have the location information or not.
The software-defined radio (SDR)
technology provides software control of a
variety of modulation techniques, wide and
narrow band operations, communication
security functions, and waveform
requirements of current and evolving
standards over a broad frequency range. An
SDR reconfigurable device is able to
combine a software programmable processor
and reconfigurable hardware components
that can be reused for different applications.
Software downloading is the delivery of
reconfiguration data or new executable
codes to an SDR device to modify its
behavior or performance. In a multi-hop
SDR reconfigurable network, nodes may be
reconfigured while they are working. An
intuitive method for software delivery is to
broadcast software to each node via flooding.
However, in this way, a serious problem will
occur during the flooding process. If a node
receives new software and turns itself into
new mode that works in another
communication protocol right after it
forwards the software, the network will then
be partitioned, and the flooding procedure is
no longer effective. To avoid this problem,
we propose a download scheme for real-time
software download, application software
upgrades, or radio protocol changing of
wireless nodes.
In the IEEE 802.11 standard, an access
point (AP) acts as the gateway or a sink node.
The carrier sense multiple access with
collision avoidance (CSMA/CA) protocol
suffers from contentions that the system
performance degrades rapidly with
increasing number of active sessions. Note
that in DCF, all nodes have the same
transmission priority. Since the packet
arrival rate of downstream traffics at the AP
is generally higher than that of upstream
traffics at a node. As the number of active
sessions increases, both the loss rate and
delay of downstream traffics rise rapidly,
which limits the number of active sessions
the network can support. We propose the
Carrier Sense Multiple Access protocol with
Collision Avoidance, Packing and
Accompanying (CSMA/CAPA) protocol.
The packing scheme is employed to upgrade
network capacity, and the accompanying
scheme can mitigate packet loss rate and
delay difference between upstream and
downstream traffics. Packing packets can
significantly reduce the access delay and loss
rate. The accompanying scheme allows
nodes to transmit a DATA frame after
having received a DATA frame, so that
upstream and downstream traffics can have
balanced transmission opportunities.
We study the off-duty role to turn off
some redundant sensor nodes in order to let a
large sensor network maintain long network
lifetime while having low sensing coverage
loss. We propose a cluster-based scheme to
find sensor nodes with larger number of
neighboring sensor nodes and remaining
lifetime in their sensing coverage, which
may possibly be elected as a cluster head
node. A cluster head node has to perform
sensing tasks, and other nodes are served as
redundant nodes if they can be covered by
several cluster head nodes.
In order to improve the throughput of a
wireless network, dynamic link adaptation
schemes can be applied so that the signal and
protocol parameters can be adjusted as the
radio link conditions change, according to
the quality of a wireless channel. Receiver's
signal-to-noise ratio (SNR) and received
signal level (RSL) are two critical
performance parameters that vary with time
due to path loss, shadowing effect,
5always moving and the network topology is
highly dynamic, while pause time of 900
seconds implies that all nodes are stationary
during simulation. For fair comparisons, the
mobility and traffic patterns are the same
among the compared protocols. The
presented simulation results come from a
mean of 50 runs.
2. Performance comparisons
Table 1 summarizes performance
metrics that are used for comparisons. Since
the sink node is assumed to have no energy
concerns, the cost spent by the sink node to
send or receive packets and frames is not
included in the simulation results. In this
way, we emphasize on the costs incurred in
mobile nodes. Power consumption in
memory access is not considered since it is
insignificant compared with that of CPU
operations and wireless transmissions. CPU
time required for four packet lengths are 100,
192, 500 and 1000 bytes, respectively. We
supplement the CPU time required for other
packet lengths by linear regression as
depicted in Figure 2. The model developed
by Feeney, where the corresponding
parameters are given in Table 2, is used to
measure the energy consumption at the
MAC layer.
At the transmitter,
btranctl + brecvctl + mtran×size + btran + brecvctl.
At the destination node of the data frame,
brecvctl + btranctl + mrecv×size + brecv + btranctl.
At non-destination node that discards the
frame,






DnTn
DnTn
bbsizem
bb
discardctldiscarddiscard
discardctldiscardctl
)(
At non-destination node that operating in
promiscuous mode,






DnTn
DnTn
bbsizem
bb
discardctlrecv_promrecv_prom
discardctldiscardctl
)(
where T and D denote respectively the set of
neighboring node of the transmitting and
destination nodes.
0
100
200
300
400
500
600
700
0 100 192 500 1000
packet length (Bytes)
pr
oc
es
si
ng
tim
e
(μ
s)
receiving
sending
Figure 2. Processing time required with respect to
packet length
Figure 1 shows the normalized network
layer control cost using different H values.
H=0 implies that nodes do not defer before
replying RREP message back to the source
node. An underestimated H value cannot
prevent the network from the reply storm
problem. On the contrary, an overestimated
H value may result in the source node route
discovery times out, and then route
discovery is initiated again, which introduces
more number of control messages. In the
following, only the result of AODV is
presented.
Figure 3 compares the number of control
and data packets sent and received using the
three MAC protocols. Note that even when
all nodes are stationary (pause time=900s), a
small amount of RERR messages are issued.
This is because, sometimes, the MAC layer
transmits a frame but receives no ACK
because of collisions. The MAC layer will
retry until an ACK is received or the retry
limit is reached. If the latter occurs, the
MAC layer will signal the network layer that
the wireless link is not available. The
network layer then recognizes this as a route
failure and initiates an RERR message to the
corresponding source nodes.
Table 1 Performance metrics used in simulations
Performance
metrics Description
Normalized
network layer
control cost
The number of control packets (i.e., the
RREQ, RREP and RERR packets, but
not data packets) sent or received at the
network layer per data packet delivered
to the AP.
Network layer cost
The total number of packets (including
data and network layer control packets)
sent and received at the network layer.
MAC layer cost The number of frames (including data
70
5
10
15
20
25
30
35
0 300 600 900
pause time(sec)
R
ec
ei
ve
d
co
nt
ro
lp
ac
ke
ts
|
RERR
RREP
RREQ
(b) Number of received control packets
10
12
14
16
0 300 600 900
pause time(sec)
Se
nt
da
ta
pa
ck
et
s
|
Prom
ABO
802.11
(c) Number of sent data packets
0
50
100
150
200
250
0 300 600 900
pause time(sec)
R
ec
ei
ve
d
da
ta
pa
ck
et
s
|
Prom
ABO
802.11
(d) Number of received data packets
Figure 3. Network layer costs (CBR sources=25)
0
2000
4000
6000
8000
10000
12000
14000
0 300 600 900
Pause time (sec)
C
PU
tim
e
(μ
s)
Recv data
Recv ctrl
Send data
Send ctrl
Prom
ABO
802.11
Figure 4. Normalized CPU time
0
10
20
30
40
50
60
70
80
0 300 600 900
pause time(sec)
Se
nt
fr
am
es
Control
ABO
Unicast
Broadcast
Prom
802.11
ABO
(a) Number of transmitted frames
0
200
400
600
800
1000
1200
1400
0 300 600 900
pause time(sec)
R
ec
ei
ve
d
fr
am
es
Control
ABO
Unicast
Broadcast
Prom
ABO
802.11
(b) Number of received frames
Figure 5. MAC layer costs (CBR sources=25)
II. The SRAD Protocol
If a resource discovery protocol heavily
relies on network-wide broadcast, nodes will
experience considerable power consumption.
Besides, resource discovery mechanism
must be designed properly so that users can
discover the resource efficiently while the
cost is minimized. We assume that nodes
have the capability of location awareness.
1. Resource description and management
In the application layer, the location
information of a restaurant, for example, can
be described using a resource descriptor in
this form: < information-orient. location.
restaurant >. Then, the resource descriptor is
encoded as a 128-bit resource key using the
MD5 algorithm. In this way, a resource
descriptor can be encoded as a unique
number called resource key.
The SRAD protocol is devised to let
server nodes advertise their resource
9encoding process. Thus, the client can obtain
the same resource key as what server obtains.
Using that resource key, the client node can
calculate the main slope of a line trajectory
to disseminate a resource request (RREQ)
packet for resource discovery.
The client firstly generates a RREQ packet
and initiates the resource discovery process.
Note that for resource discovery, the RREQ
packet is disseminated along a line trajectory
perpendicular to the line trajectory used in
the resource advertisement process. The
nodes that lie in both the resource area and
discovery area can send a resource reply
(RREP) packet to the client node using
unicast to complete the resource discovery
process. Moreover, if a node coming from
the resource area just moves to the discovery
area, it will also send a RREP packet to the
client node. The RREP packet consists of the
following fields:
< Packet type, Sequence Number, Server’s
ID, Server’s Coordinate, Resource Key, Hop
Count, Coordinate of the Reply Node, Main
Slope, Lifetime >
When a node receives a RREQ packet, it
first checks whether the RREQ packet is a
duplicated one. If true, the RREQ packet is
discarded. Otherwise, if it has cached the
resource information, it then sends back a
RREP packet directly to complete the
resource discovery process, or else it then
determines whether or not itself lies in the
discovery area using geometry calculations.
If the node lies in the discovery area and
does not have the desired resource
information, then, the node decrements the
value of the Hop Count field in the RREQ
packet by one, and broadcasts it again if the
value of Hop Count is larger than zero;
otherwise, the RREQ packet is discarded. A
resource discovery process fails if the client
node does not receive the RREP packet
within TRTT , the maximum tolerable round
trip time. TRTT is set according to the average
number of hops the RREQ packet is
expected to travel. If resource discovery
processes fail frequently, TRTT and the value
of the Hop Count field in the RREQ packets
can be set larger.
2.2 Enhanced line-based (ELB) SRAD
It is possible that a server is located at the
geographical border of the network and no
neighboring node lies on the discovery
trajectory or resource area. Besides, because
the geometric coverage area near the server
is small, some nodes may be close to the
server but could not recognize the resources
of the server. Hence, the enhanced line-based
(ELB) SRAD protocol is proposed. The ELB
protocol uses two main slopes that form two
line trajectories perpendicular to each other
to disseminate the ADV and RREQ packets.
In the ELB protocol, the resource
discovery process is the same as that of the
LB protocol based on one selected main
slope. But if the first resource discovery
process fails, the client node will try to send
another RREQ packet using the other main
slope.
2.3 Cross-line-based (CLB) SRAD
To increase hit rate and consider that
nodes may not be uniformly distributed in
the network, the cross-line-based (CLB)
SRAD protocol is proposed. In the CLB
protocol, the resource advertisement process
is the same as that of the ELB protocol based
on two main slopes. But the former
discovers resource based on two main slopes
at the same time. The performance penalty
of the CLB protocol is that the transmitted
message overhead is more than that of the
ELB protocol since it discovers resource
along two line trajectories.
3. Simulation study
For comparisons, an on-demand (OD)
resource discovery protocol modified from
the AODV routing protocol to support
resource discovery is implemented in
simulations. The performance metrics to be
observed include:
 Number of transmitted messages: the total
number of broadcast messages in the
network.
11
Figure 7 depicts the medium allocation
method of T&D. The time is equally divided
by packet propagation period (PPP). A
number of PPPs comprise a super frame.
T&D is designed to carry one packet per
PPP. However, due to the contention-based
MAC protocol, T&D has the probability to
transmit either none or more than one packet
from individual sensor node to sink in a PPP.
The first PPP in a super frame is a control
PPP reserved for
monitoring/management/query packets. Sink
or remote user uses the control PPP to send
monitoring/management/query packets to
sensor nodes. The other PPPs are data PPPs
which sensor nodes use to transmit their
periodically reports or response the query to
the sink. The number of PPPs comprising a
super frame is a managerial parameter
depending on the load of network signaling
and queries. The length of a PPP is also a
system parameter whose duration is a value
between [PPP_min, PPP_max]. PPP_min
must be long enough to propagate a packet
from any sensor node to sinks, which is
dependent on the scale of WSN. When data
load gets higher, the PPP can be shortened
down to the PPP_min to adopt these loads.
On the other hands, when data load gets
lower, the PPP can be prolonged for power
saving.
3.2 T&D-MAC
The terminology “frame” is used to be
the data unit in MAC layer. Here we assume
that a data packet in the WSN can be
completely encapsulated in a frame.
Therefore,the terms “frame” and “packet” is 
interchangeable in this study.
A sensor node acts in three states:
contention state, relaying state, and sleeping
state, during a PPP. Figure 8 illustrates the
state transition diagram of a sensor node.
And the tasks performed by a sensor node
during a PPP are shown in Figure 9. For
each state, the activation of each subsystem
of a sensor node is tabulated in Table 4. The
start state of all sensor nodes is the sleeping
state. When a data PPP starts, a sensor node
turns to contention state if it has a packet
want to send to sink. Otherwise, it turns to
relaying state directly. Sensor nodes which
are in contention state select a backoff time
(BT) in units of slot times and decreases the
backoff time by one until to zero. When the
backoff time is decreased to zero, a sensor
node transmits the packet and turns to the
sleeping state until next PPP starts. If sensor
nodes fail in contending the channel, i.e.,the
nodes receive a packet during the backoff
procedure, they freeze the backoff time and
turn their state to relaying state.
Sensor nodes which are in relaying state
monitor the channel until the PPP_min
expired. If they receive a frame by PPP_min,
they perform the relaying procedure. The
relaying procedure is identical to the backoff
procedure using in the contention stage;
however, the contention window (CW) size
may different and the backoff counter will
be reset every relaying stage. Moreover, the
sensor node should wait a inter frame space
(IFS) before random backoff. After relaying
a packet, sensor nodes turn into the sleeping
state. If a sensor node is in relaying stage
and receives more than one packet,
regardless of duplicating packets or different
packets, before successfully relaying any
packet. We say that the node is drowned by
packets, and then the node stops relaying any
packet and turns to the sleeping state.
Because the T&D is designed to use
“link-layer-relaying” instead of 
“network-layer- forwarding,” the sensor 
node will not cache any packet and, except
the MAC address resolution and check sum,
the sensor node will not perform any header
check. In addition, sensor nodes use only
one cache for cooperating packet routing.
Because that sensor nodes use
contention-based channel access scheme,
collision may occur in contention stage and
relaying stage. If a sensor node detects
collision occurred, it simply turns to sleeping
state until next PPP starts. However,
collision will not significantly affect the
packet propagation. For example, in Figure
10, if node A and node B transmit packets
simultaneously, node C will detect collision
and turns its state to sleeping state. However,
13
pure flooding and Gossiping scheme has the
almost same lifetime is because they listen
the channel all the lifetime. The length of a
PPP is a managerial parameter, which is
selected according to the tradeoff among the
traffic load, packet delay, and WSN’s 
lifetime.
15
in the network that have the same capability
such as computing power and memory
capacity. Every node in the reconfigurable
network, e.g., a wireless sensor network, can
forward software to its neighbors after it
receives new software. The node which
broadcasts new software is called the
resource manager (RM). The RM manages
software version and determines whether to
broadcast new software. The control center
of the network or the data sink of a sensor
network can play the role of RM. The
location of RM can be anywhere in the
network. Before we describe the CFSD
scheme, we will first define and explain the
following terms: virtual-time-to-live (VTTL),
inner nodes, outer nodes, and confirmation
message (CM).
A VTTL field of the software packet is
designed to let the software, as far as
possible, be distributed from the
geographical center of the network (relative
to the location of the RM), and to distinguish
nodes as inner nodes and outer nodes, as
shown in Figure 17. If we use a very large
VTTL value, the node near the border of the
network will first be reconfigured.
Equivalently, if we set VTTL value to be 0
and place the RM at the border of the
network, the node near the border of the
network will first be reconfigured. The node
that receives a packet with VTTL value
being larger than or equal to zero is called an
inner node –otherwise the node is called an
outer node.
CM is used to notify the predecessor node
that the delivery of software is successfully
completed. CM is sent only when the node
receives the software correctly. Note that a
node will not turn itself into new mode right
after it forwards the received software. If an
inner node receives any CM from its
successors, it can decide whether to turn its
working mode into new mode. In this way,
the inner nodes can defer their
reconfigurations to avoid an immediate
partition problem and ensure that their
successors have received the software.
An outer node acknowledges the CM right
after the software is received correctly, and
then forwards the software to its successors.
This can avoid that the network starts
reconfiguration from nodes near the border
of the network. Because while the outer
nodes are forwarding the software to their
successors, the inner nodes can start to
reconfigure themselves, which will not result
in long network reconfiguration time.
The CFSD scheme is IP (Internet
Protocol) compatible, which can be easily
integrated with conventional IP networks. In
the header of the standard IP packet format,
the Protocol field is used to specify the
packet type.
(a)
(b)
Figure 15. Centralized software download architecture
Figure 16. Decentralized software download architecture.
17
cases some nodes are crashed or neighbors
have moved out of the node’s
communication range. Besides, if a node is
located at the border of the network, it may
not receive any CM because it may have no
successors. In this case, the deadlock
prevention method, i.e., five times
retransmissions, still holds.
4. Simulation Study
In order to see the performance of the
CFSD scheme, we have performed some
simulation experiments using OPNET 11.0
PL1. For comparisons, the following simple
flooding and the modified flooding schemes
are implemented in simulations.
Flooding is the process which one node
sends packets to all the other nodes in the
network. In the simple flooding scheme,
each node must forward the software packet
to its neighbors whenever it receives the
software packet for the first time. However,
the simple flooding scheme must use a
certain mechanism to synchronize all nodes
in the network after all nodes have received
the software. In this article, we assume that,
for the simple flooding scheme, a
synchronization mechanism exists to let all
nodes turn their working mode into new
working mode right after all nodes have
received new software. However, in the
modified flooding scheme, each node has to
forward the software just one time when it
receives the software packet. Then, it turns
its working mode into new working mode.
The modified flooding scheme does not need
a mechanism to synchronize all nodes in the
network, but it cannot guarantee that each
node receives the software correctly, which
may result in the partition problem. Because
it only forwards the software one time and
immediately turns itself into new mode, the
looping packet effect of flooding is no
longer available.
We define the reachability as the ratio
of the number of nodes that have received
new software to the total number of nodes in
the reconfigurable network. The overhead is
defined as the total number of generated
packets in the network to deliver software to
all nodes. These packets include CM packets,
software packets and retransmitted software
packets.
Simulation results show that, in the
general cases of 95 to 290 nodes uniformly
distributed in an IEEE 802.11b network, the
reachability of the CFSD and simple
flooding schemes is about 10% higher than
that of the modified flooding scheme. And
the overhead in the CFSD and the modified
flooding schemes is about 99% lower than
that of the simple flooding scheme.
5. The Rescue of Switched off Nodes
Currently, the CFSD scheme only deals
with the software downloading for nodes
that are switched on. A switched off node is
isolated from the network when it is
switched on during the software
downloading process, or after the new
software has been downloaded to all the
working nodes in the network. This could be
a research issue that is worth further study.
A preliminary solution to this issue is
described as follows.
It is feasible for a node to keep a mini
boot in its flash memory. The boot code is
small and nonvolatile, which can let a node
operate in an emergency mode and wait for a
rescue. When a node cannot find any
neighbor, it has a choice to reboot system
into the emergency mode. In this mode, a
node sends periodically a special signal (or
tone) at the frequency band specified by the
boot code to identify itself as an isolated
node, and then it just waits to receive any
response signal.
A node working in new mode can listen
to the special signal at a low duty cycle
when it is idle. The node can send responses
and new software to any isolated node once
it finds any node waiting for a rescue, using
one-hop transmission. Note that if an
unexpected cyclic redundancy check (CRC)
error occurs while a node is booting, the
19
downstream traffics. The accompanying
scheme is shown in Figure 21, when a node
(namely, node A) completes the backoff
procedure, it will transmit a DATA frame to
another node (namely, node B). Having
received the DATA frame, node B will reply
node A with an ACK frame. Then, if node B
has DATA frame for node A, it will transmit
the DATA frame after the transmission of
the ACK frame. The DATA frame that node
B transmits to node A in this case is called
the accompanying frame. Using the
accompanying scheme, a node can transmit
its DATA frame on either of the following
two conditions: 1) having completed the
backoff procedure, or 2) having received a
unicast DATA frame from the node that is
the next-hop node of its head-of-line MSDU
in queue. In this way, the accompanying
scheme can mitigate the packet loss rate and
delay difference between upstream and
downstream traffics.
3. Performance Evaluation
We evaluate the performance of the
proposed CSMA/CAPA protocol in terms of
loss rate, delay and voice jitter using the
NS-2 simulator. CSMA/CA with packing
(CSMA/CAP) and CSMA/CA with
accompanying (CSMA/CAA) schemes are
evaluated to see the individual effectiveness
of the packing and accompanying schemes.
The IEEE 802.11 and IEEE 802.11e are also
considered for comparisons.
3.1 Parameter Settings
The IEEE 802.11e supports four access
categories (ACs). In our simulations, voice
traffics are categorized as AC 3, which is the
highest priority category, and data traffics
AC 0, which is the lowest priority category.
In IEEE 802.11e, services are differentiated
using different AIFS, CWmin and CWmax
values according to their access categories.
In the simulations, we useAIFS[AC3]=25μs, 
AIFS[AC0]=34μs, CWmin[AC3]=7,
CWmin[AC0]=31, CWmax[AC3]=15 and
CWmax[AC0]=1023.
Direct sequence spread spectrum (DSSS)
technology is used with the channel bit rate
of 11 Mbps. Transmission range is 30 m and
carrier sensing range is 120 m. The
maximum frame body length is 2304 bytes.
In an area of 8080 m2, 30 mobile nodes are
randomly deployed. The AP is placed at the
center of the simulation area. Mobile nodes’ 
movement follows the random waypoint
model with a mean pause time of 300
seconds and a moving speed that is
uniformly distributed between 0 and 10 m/s.
The bit error rate is 10-5, which is specified
in the IEEE 802.11 standard. Priority queue
is assumed that voice packets have higher
priority and the queue size is set to be 50
packets. 10 CBR data sources, 5 for
upstream and 5 for downstream, are used.
Each CBR data source is with packet
inter-arrival time of 0.2 sec and packet
length of 1500 bytes. The AODV routing
protocol is used as it has been shown to be
suitable in networks. Simulation results are
the average of 20 runs, each with simulation
time of 120 seconds. G.729 with 20 ms
packet length is chosen as the voice codec. A
300 ms one-way delay budget is assumed in
order to maintain a low percentage of
difficulty while leaving as much delay budge
for the network as possible. The backbone
delay budget is 125 ms, and 100 ms delay
budget for packet processing at the sending
and receiving points is used. All these
factors leave 75 ms for the access delay in
the network. In the simulation, voice packets
with delay exceeding 75 ms are considered
lost. The basic BlockACK mode shown in
Figure 22 has been proved to be efficient. In
the basic BlockACK mode, the originator
and the recipient reserve the channel by
respectively declaring network allocation
vector (NAV) in the first MPDU and the
subsequent ACK frame. The back-to-back
transmission of the MSDUs is limited by a
channel occupancy time (i.e., the
transmission opportunity limit, TXOP limit).
In this study, a TXOP limit of 10 ms is used.
In a network, since nodes may be resource
limited, the procedures in setting up and
tearing down sessions are required each time
a node attempts to transmit MPDUs using
21
likely to be dropped because of buffer
overflow. The high data loss rate limits the
number of simultaneous calls in the network
can support. The data loss rate can be
improved by assigning voice and data
packets with the same priority in queue. In
other words, all packets are stored in order
according to the time they arrive at the queue.
In this way, voice and data packets will have
similar loss probability. As shown in Figure
26, when the arrival time (AT) is used as the
queueing strategy, the network using
CSMA/CAPA can support 14 simultaneous
calls while the data loss rate remains low. In
contrast, 8 simultaneous calls can be
supported if voice packets are assigned
higher priority than data packets.
23
25
VI. Cluster-based Algorithm
In dense sensor networks, there are a
large number of low-power, short-lived, low
cost and unreliable sensors. A major
challenge in constructing dense sensor
networks is to prolong network lifetime as
well as to keep low sensing coverage loss
ratio. To prolong network lifetime, it is
necessary to turn off redundant nodes to
save energy. Moreover, to obtain low
sensing coverage loss ratio is an important
issue in dense sensor networks.
We introduce a cluster-based algorithm
for redundant nodes discovery in dense
sensor networks. From cluster perspective,
the higher the node density and the higher
the energy a sensor node has, the higher the
probability that it should be on duty to serve
neighboring nodes. We exploit this feature to
increase the probability of the intersection
between clusterhead nodes to cover
redundant nodes. We regard redundant nodes
as nodes that are covered by the minimum
number of clusterhead nodes which can
almost completely cover the sensing
coverage of a redundant node. We derive the
minimum number of clusterhead nodes in
the next section.
1. Off-duty Eligibility Rules
We now discuss the sensing coverage of
sensor nodes that may be covered by a
number of clusterhead nodes and identify
nodes that satisfy off-duty eligibility rules as
redundant nodes which are put to sleep using
the computational geometry concept.
We consider several scenarios to find out
the number of neighboring nodes in a
27
Received Signal Strength Indicator or power
control capacity can obtain sufficient
knowledge to judge other nodes whether
they located at its sensing coverage.
The principle of our cluster-based
algorithm is described as follows:
1. Clusterhead nodes: nodes dynamically
elect a clusterhead node as working nodes
based on the residual energy level of
nodes and the degree of neighboring
nodes at the time.
2. Redundant nodes: If a node has k (i.e. a
design parameter can be set 2, 3 or 4)
neighboring clusterhead nodes in its
sensing range, then it can be a redundant
node to put to sleep as an off-duty node.
3. The working time of clusterhead nodes
is dynamically determined by the residual
energy of clusterhead nodes to avoid
overloading on some specific sensor
nodes so that results in network partition.
4. The sleep time of redundant nodes is
determined by selecting the max.
working time of neighboring clusterhead
nodes. Thus, the number of the
clusterhead node election is invoked by
sensor nodes themselves as rarely as
possible to save energy overhead.
3. The Procedure of Cluster-based
Algorithm
To discuss the proposed cluster-based
algorithm, we explain how to elect
clusterheads and identify redundant nodes as
follows.
Clusterhead election procedure:
In Figure 30, this election is mainly used
to elect a sensor node as a clusterhead node
for working and a redundant node for
sleeping. We will describe a sensor node
how to execute this election as follows.
Step 1: A sensor node executes the
“discovering procedure” to discover 
neighbors and records neighboring
information such as the number of
clusterhead nodes, the number of neighbors,
source ID and working time of clusterhead
nodes in its sensing coverage. Jump to the
next step.
Step 2: A sensor node judges counter C as
recording a number of neighboring
clusterhead nodes whether there is at least k
clusterhead nodes. If not, jump to step 6
behind; otherwise, jump to the next step.
Step 3: A sensor node selects the maximum
working time of neighboring clusterhead
nodes as sleep time and starts sleep-timer.
Jump to the next step.
Step 4: A sensor node switches active mode
to inactive mode. Jump to the next step.
Step 5: Wait until sleep-timer is up, and
jump to step 1.
Step 6: A sensor node executes the
“comparing procedure” to obtain 
neighboring information such as weighted
values, source ID and the working time of
neighbors in its sensing coverage. Jump to
the next step.
Step 7: First, calculate the weights (W v) of a
sensor node
W v = w1 N v+ w2E v, (3)
w1+ w2=1, N v ≤10 and E v≤10                      
where w1, w2 are weighting parameters.
N v and E v represent respectively the degree
of neighbors and the residual energy level of
node v. A sensor node broadcasts a compare
message with the weighted value obtained
by eq.(3).
To compare the weighted values with
neighbors, a node determines whether it is
large as a clusterhead node to afford sensing
tasks in the working interval. When the
working interval is up, clusterhead nodes
return to step 1. If equal, then a sensor node
should jump to the next step. If small, then it
becomes a member node. In meanwhile, it
checks whether there are at least k
neighboring clusterhead nodes. If true, it
jumps to step 3; otherwise, it return to step
1.
Step 8: To compare the ID no., if it has the
largest ID no. as a clusterhead node to afford
sensing tasks in working interval. When the
working interval is up, clusterhead nodes
return to step 1. If small, then it becomes a
member node. In meanwhile, it checks
whether there are at least k neighboring
clusterhead nodes. If true, it jumps to step 3;
otherwise, it return to step 1.
29
Therefore, by carefully choosing a suitable k
and w1, one can obtain the desired data
success ratio.
Figures 37 to 39 illustrate the data
delivery lifetime which cluster-based
algorithm compares with probe-based
algorithm at the termination of algorithms
until data success ratio drops below 75% or
all sensor nodes die off. We see that the data
delivery lifetime of the cluster-based
algorithm that could be approximately
double that of the probe-based algorithm is
best when k is set to be 2 for different
number of nodes. When w1 is set to be 0.8 or
node density is higher, the data delivery
lifetime is best. However, the data delivery
lifetime at k=4 could be worst because there
is much energy overhead while clustering.
Hence, to avoid energy consumption the
designated number of cluster- head nodes
may be set at k=2 or 3 and keep higher data
success ratio.
Our algorithm provides the flexibility of
adjusting the weighting factors and k
parameter according to the system needs.
Data delivery lifetime (k=2)
0
3000
6000
9000
12000
15000
18000
21000
54 63 72 81
no. of nodes
tim
e(
se
c.
)
w1=0.2 w1=0.5 w1=0.8
Figure 31. Data delivery lifetime (k=2).
Data delivery lifetime (k=3)
0
3000
6000
9000
12000
15000
18000
21000
54 63 72 81
no. of nodes
tim
e(
se
c.
)
w1=0.2 w1=0.5 w1=0.8
Figure 32. Data delivery lifetime (k=3).
Data delivery lifetime:(k=4)
0
3000
6000
9000
12000
15000
18000
21000
54 63 72 81
no. of nodes
tim
e(
se
c.
)
w1=0.2 w1=0.5 w1=0.8
Figure 33. Data delivery lifetime (k=4).
Data success ratio (k=2)
0
0.2
0.4
0.6
0.8
1
54 63 72 81
no. of nodes
da
ta
su
cc
es
s
ra
tio
w1=0.2 w1=0.5 w1=0.8
Figure 34. Data success ratio (k=2).
Data success ratio (k=3)
0
0.2
0.4
0.6
0.8
1
54 63 72 81
no. of nodes
da
ta
su
cc
es
s
ra
tio
w1=0.2 w1=0.5 w1=0.8
Figure 35. Data success ratio (k=3).
Data success ratio (k=4)
0
0.2
0.4
0.6
0.8
1
54 63 72 81
no. of nodes
da
ta
su
cc
es
s
ra
tio
w1=0.2 w1=0.5 w1=0.8
Figure 36. Data success ratio (k=4).
Data delivery lifetime (w1=0.2)
0
3000
6000
9000
12000
15000
18000
54 63 72 81
no. of nodes
tim
e(
se
c.
)
probe-based cluster-based (k=2)
cluster-based (k=3) cluster-based (k=4)
Figure 37. Comparison of data delivery lifetime
(w1=0.2).
Data delivery lifetime (w1=0.5)
0
3000
6000
9000
12000
15000
18000
54 63 72 81
no. of nodes
tim
e(
se
c.
)
p robe-based cluster-based (k=2)
cluster-based (k=3) cluster-based (k=4)
Figure 38. Comparison of data delivery lifetime
(w1=0.5).
Data delivery lifetime (w1=0.8)
0
3000
6000
9000
12000
15000
18000
54 63 72 81
no. of nodes
tim
e(
se
c.
)
p robe-based cluster-based (k=2)
cluster-based (k=3) cluster-based (k=4)
Figure 39. Comparison of data delivery lifetime
(w1=0.8).
31
by one, otherwise the counter will remain
unchanged.
3. Pseudo Coherence Time Adaptation
The pseudo coherence time is not only
used to determine whether to trigger the
RTS/CTS mechanism, but it also used to
decide the frame size. The value of the
pseudo coherence time can be any of 100 ms,
20 ms, 10 ms, 5 ms, 2.5 ms and 1 ms. The
default pseudo coherence time is 100 ms.
Each mobile station records and uses the
number of successful transmission and the
number of failed transmission to adjust the
pseudo coherence time. In CLLA scheme,
the pseudo coherence time will be adjusted
if the packet error rate or the number of
transmitted packets is larger or less than a
threshold.
4. Fragmentation Mechanism
It is always more appropriate to lower
the transmission rate rather than to fragment
a packet, because every fragment is sent and
acknowledged individually, thus the MAC
overhead increases linearly with the number
of fragments. Throughput improvement due
to fragmentation is only observable in a
narrow SNR range.
In CLLA scheme, the fragmentation
mechanism is usually not used in the first
transmission of a frame. It uses the basic
mechanism when the wireless channel is in
good condition. The transmission time of the
frame may be larger than channel coherence
time, which will increase the probability of
transmission failure. If the transmission
error occurred and the error count reaches a
threshold, the mobile station then uses the
fragmentation mechanism. In order to reduce
the probability of transmission error, the
mobile station fragments the packet
according to the data rate and frame length
to fit the pseudo coherence time using a
table lookup. This can increase the
probability of successful transmission and
improve the throughput. Table 8 shows the
table for IEEE 802.11b.
TABLE 8
PSEUDO COHERENCE TIME VS. FRAGMENT SIZE IN BYTE AT
DIFFERENT DATA RATES OF IEEE 802.11b
Pseudo
Co_Time
1 Mbps 2 Mbps 5.5 Mbps 11 Mbps
100 ms 2312 2312 2312 2312
20 ms 2312 2312 2312 2312
10 ms 1000 1500 2312 2312
5.0 ms 500 1000 2312 2312
2.5 ms 100 100 1000 2312
1.5 ms 100 100 100 500
1.0 ms 100 100 100 100
5. Simulation Study
We evaluate the performance of the
CLLA, RBAR, ARF and other fixed-rate
(FR) schemes using the GloMoSim
simulator. In the simulation, the following
scenario is used to evaluate the throughput
when the IEEE 802.11b and 802.11g
environments are deployed. We assume a
200×200 m2 region. An AP is fixed in the
center. In a WLAN with a Rayleigh faded
channel, the AP transmits Beacon frames
periodically. The number of mobile stations
varies from 5 to 30. Every mobile station
follows the random waypoint mobility
model. The speed of a station varies from 1
m/sec to 20 m/sec. Mobile stations transmit
frames of 1500 bytes and 100,000 frames to
the AP. An ON/OFF traffic model is used in
each mobile station. In this traffic model, the
OFF time duration is drawn from Pareto
distribution with parameters =0.7, and
ON time duration is drawn from Weibull
distribution with parameters k=0.9 and b=90.
During the ON period, the inter-arrival time
is governed by another Weibull distribution
with parameters k=0.5 and b=4.5.
Simulation results are shown in Figures 40
and 41 for the IEEE 802.11b and IEEE
802.11g, respectively. Note that the CLLA
has the best performance compared with the
others whatever in IEEE 802.11b or IEEE
802.11g environments. The RBAR
outperforms the ARF, because RBAR can
get channel information more quickly than
ARF scheme. It is interesting that the
throughputs of FR-11 and FR-05 in Figure
1(a), as well as FR-54, FR-24 and FR-12 in
Figure 2(a), outperform the ARF scheme. As
33
protocols while generating fewer transmitted
messages in large and dense WSNs.
Thirdly, we propose a location-
information-free and flooding-like routing
protocol for WSNs, called throw and
drowned (T&D) flooding protocol. This
protocol is a multi-hop implicit routing
protocol and an energy saving protocol. It
is also capable of turning the sensor node
into the sleeping mode for the purpose of
power saving. Instead of pure flooding,
T&D is designed for applications with
dynamic topology change and scalable
WSNs.
Fourthly, we propose a download scheme
for real-time software download, application
software upgrades, or radio protocol
changing of wireless nodes in multi-hop
reconfigurable networks.
Fifthly, we propose the CSMA protocol
with collision avoidance, packing and
accompanying (CSMA/CAPA) protocol.
The packing scheme allows more packets to
be transmitted in a frame while the
accompanying scheme allows nodes with
more opportunities to transmit their frames.
Simulation results show that CSMA/CAPA
can significantly upgrade the capacity of a
wireless network even when the channel
error rate is high.
Sixthly, we propose a cluster-based
algorithm, which is energy-efficient, flexible
and adjustable to identify redundant nodes
under different requirements of network
lifetime and sensing coverage loss ratio.
This algorithm does not need location
information and directional antennas to help
identify redundant nodes. Simulation results
show that the cluster-based algorithm can
save energy consumption to prolong
network lifetime, while achieving a low
sensing coverage loss ratio.
Finally, we propose a cross-layer link
adaptation (CLLA) scheme that uses the
number of successful transmissions, the
number of transmission failures, and the
channel information from the physical layer
to determine proper transmission parameters
for subsequent medium accesses. The CLLA
scheme lets frames be transmitted at the
highest available data rate using proper
medium access methods to achieve high
throughput. Simulation results show that the
CLLA scheme performs well in throughput
in practical mobile environments.
During these three years, we have
published 5 international conference papers
and 3 journal papers. These results can help
engineers develop the architecture and
protocols used in wireless sensor networks
for the need of various wireless sensing
tasks in the near future.
四、參考文獻
[1] H. -H. Liu, J. -L. C. Wu and C. -J. Wang, "A
multi-hop implicit routing protocol for sensor
networks," In Proc. of IEEE 60th Vehicular
Technology Conference (VTC2004-Fall), Sept.
26-29, 2004, Vol. 4, pp. 2946-2950.
[2] Shun-Te Wang, Jean-Lien C. Wu, Chung-Ching
Deng and Chun-Yen Hsu, "An Adaptation
Scheme for Quick Response to Fluctuations in
IEEE 802.11 Link Quality," In Proceedings of
2007 IEEE Region 10 Conference (TENCON
2007), October 30-November 2, 2007, Taipei,
Taiwan.
[3] Chun-Yen Hsu, Jean-Lien C. Wu and Shun-Te
Wang, "Capacity Upgrading in Mobile Ad Hoc
Access Networks (MAHAN) Using
CSMA/CAPA," In Proceedings ofthe Fourth
ACM International Workshop on Mobility
Management and Wireless Access (MobiWac
2006), October 2, 2006, Torremolinos, Malaga,
Spain, pp. 28-34.
[4] Shun-Te Wang, Jean-Lien C. Wu, Chun-Yen
Hsu and Wen-Chun Ni, "Software Downloading
in Reconfigurable Networks of Open Wireless
Architecture Using SDR Technology," IEEE
Communications Magazine, Vol. 44, No. 10,
October 2006, pp. 128-134.
[5] Shun-Te Wang, Jean-Lien C. Wu and Chun-Yen
Hsu, "Design of a Resource Advertisement and
Discovery Protocol for Large and Dense
MANETs," Journal of the Chinese Institute of
Engineers, Vol. 29, No. 7, November 2006, pp.
1161-1171.
[6] Jean-Lien C. Wu, Shun-Te Wang and Chun-Yen
Hsu, "A Simple Resource Advertisement and
Discovery Protocol for Large and Dense
MANETs," In Proceedings of the3rd
International Conference on Information
Technology: Research and Education (ITRE
2005), June 27-30, 2005, Hsinchu, Taiwan, pp.
18-22.
[7] Chun-Yen Hsu, Jean-Lien C. Wu and Shun-Te
表 Y04
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
96年 9月 19日
報告人姓名
許俊彥
服務機構
及職稱
國立台灣科技大學資訊工程系
博士生
時間
會議地點
95年 9月 13、14、15共三日
新加坡
本會核定
補助文號
NSC-94-2213-E-011-018
會議
名稱
(中文)
(英文) IEEE Intl. Conf. on Networks 2006 (ICON’06)
發表
論文
題目
1. A Time-Efficient Algorithm for Optimal Design of Backbone Wireless
Mesh Networks
一、參加會議經過
IEEE ICON 2006 於 2006/9/13 ~ 2006/9/15 在新加坡舉行，由 IEEE 與 Singapore
Polytechnic主辦。此會議屬於網路領域中數個優良國際會議之一，其與會者來自於世界
各地專精於『通訊網路』領域的專家，包括了產業界、學術界以及相關之研究機構。在
與會的過程中，本人除了聆聽 Tutorial和各個 Technical Session的論文發表外，也參與了
Application/Panel議程， 與各個不同國家的專家們進行特定議題的面對面討論。更特別
的是，藉由 IEEE ICON 2006的舉行，本人能夠見到許多無線通訊系統與產品之研究進
展，進而瞭解無線通訊產業目前研究之概況。
本人參與今年度之 IEEE ICON 2005，發表“A Time-Efficient Algorithm for Optimal
Design of Backbone Wireless Mesh Networks”一文，此篇論文之發表於會中受到廣泛的
討論，本人並和與會的其他國家同領域之學者專家，討論演說內容之相關議題。
二、與會心得
今年的 ICON 的主題相當廣泛，其中包含了 19 個 Technical Sessions，有 Network
Architectures、Next Generation Networks、Wired Networks and Grids、Flow and Congestion
Control、Multicasting、Wireless Ad Hoc and Sensor Networks、Routing, Switching and
Addressing、Privacy, Security, DoS and Defences及 Quality of Service (QoS)等 Session。本
人此次參與會議以 Quality of Service為重點，從這些演說中得到下列重點，QoS的重要
性日益增大，而其發展出懸而待解之問題也日益增多，其中包括了(1)如何在緊急事件發
生時仍維持系統之 QoS，(2) QoS品質之認定與評估標準，以及(3)分散式系統如何協調
系統之 QoS需求。因此，本人不斷地就這幾個議題，向不同國家的產業界及學術界專家
提出自己的看法，並聆聽他們的意見，在此意見交換的過程中，對本人未來在 QoS方面
的研究有相當程度的影響。
表 Y04
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
96年 9月 30日
報告人姓名
許俊彥
服務機構
及職稱
國立台灣科技大學資訊工程系
博士生
時間
會議地點
95年10月 2日至六日共五日
西班牙馬拉加市
本會核定
補助文號
NSC-94-2213-E-011-018
會議
名稱
(中文)
(英文)ACM MobiCom 2006
發表
論文
題目
Capacity Upgrading in Mobile Ad Hoc Access Networks (MAHANs) Using
CSMA/CAPA
一、參加會議經過
本年度 MobiWac 2006會議在西班牙的馬拉加市舉行，從十月二日至十月六日為
期五天，本人被安排在第一天的上午發表論文。
由於台灣與西班牙之間並無直飛班機，本人九月廿七日搭乘瑞士航空經香港抵達
蘇黎士，再由蘇黎士搭乘火車沿途遊覽南歐風光，於十月一日下午三點抵達馬拉加
市，隨後前往此次研討會場旅館 Hotel Melia Costa Del Sol報到，該旅館位於馬拉加市
有名的陽光海岸度假勝地，放眼望去盡是藍白相間的地中海風光，然而本人今日無心
欣賞，早早回飯店準備翌日早上的報告。
十月二日早上研討會開始舉行，本人參加Wireless Mesh and Access Networks議
程，聆聽相關領域學者報告其最新研究，並發表 Capacity Upgrading in Mobile Ad Hoc
Access Networks (MAHANs) Using CSMA/CAPA 論文乙篇。下午參加 Location,
Tracking and Proximity Detection議程。。
十月三日上午本人參加Modeling and Performance Evaluation議程，下午參加
Modeling and Performance Evaluation議程的第二部份，聆聽相關領域學者報告其最新
研究。。
十月四日上午本人參加 Group Communication and Services以及MANETs議程，
下午本人抽空前往馬拉加市著名的畢卡索博物館與回教阿卡乍堡等地參觀，增加對當
地歷史人文的了解。
由於機位的限制，此次無法留在馬拉加市全程參與研討會，本人於十月五日下午
一點由馬拉加機場搭機經由蘇黎士與香港兩地轉機返國，於台灣時間十月六日中午抵
達桃園中正機場。
二、與會心得
MobiWac 2006研討會是與MSWiM研討會合併舉行，MobiWac 2006以無線接取
技術為主軸。由於有線網路發展已臻成熟，無線通道的頻寬將成為無線網路系統的發
展瓶頸，也因此無線接取是未來無線網路系統中最關鍵的技術，在MobiWac 2006研
討會中，與會學者針對未來無線接取網路預期應提供的各種服務，及其所面臨的各種
挑戰，提出各種看法供大家討論，在討論過程中，未來的無線接取網路服務架構即逐
漸成型。
表 Y04
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
96年 9月 20日
報告人姓名
陳建忠
服務機構
及職稱
國立台灣科技大學電子工程系
博士生
時間
會議地點
96年 4月 2、3、4共三日
泰國普吉島
本會核定
補助文號
NSC-94-2213-E-011-018
會議
名稱
(中文)
(英文) IASTED Asian Conference on Communication Systems and Networks
發表
論文
題目
2. Optimal Contention Window Assignment for Best Effort Services in IEEE
802.16 Systems
一、參加會議經過
第四屆 IASTED AsiaCSN 2007於 2007/4/2 ~ 2007/4/4於泰國普吉島舉行。本次會議
為 2007 年國際科學與技術發展協會(The International Association of Science and
Technology for Development) 所舉辦的國際研討會，該會議於同時間同地點共分為三個
主題：
一、 高等計算機科學及技術 (Advances in Computer Science and Technology,
ACST 2007)
二、 電力與能源系統(Power and Energy Systems, AsiaPES 2007)
三、 通訊系統及網路(Communication Systems and Networks, AsiaCSN 2007)。
本人參加之會議為通訊系統及網路(AsiaCSN 2007)。此會議與會者來自於世界各地
專精於『通訊系統與網路』領域的專家，包括了產業界、學術界以及相關之研究機構。
在與會的過程中，本人除了出席 Tutorial和各個 Technical Session的論文發表外，也與
各個不同國家的學者專家進行面對面討論。藉由此會議本人有機會了解通訊系統與網
路之研究進展，及當前研究之概況。
本人參與此次之 IASTED AsiaCSN 2007，發表“Optimal Contention Window
Assignment for Best Effort Services in IEEE 802.16 Systems”一文，本人並和與會的其他
