 2
experiment the non-periodic short-term forecasts on 
international stock price indices and typhoon moving 
paths. Here, we focus on the structured adiabatic 
quantum search by nesting a partial search over a 
reduced set of variables into a global search for solving 
an optimization problem on SVR, yielding an average 
complexity of order αN , with 1<α , compared with a 
quadratic speedup of order N  over a naive Grover’s 
search. Their related publications of this research 
results have been listed in [23-34]. 
 
Keywords: Nested local adiabatic evolution algorithm, 
Support vector regression; Hopfield-
neural-net; Structured adiabatic quantum 
search, BPNN-weighted Grey-C3LSP 
model, nonlinear autoregressive 
conditional heteroscedasticity. 
 
二、 緣由與目的 
 
1. Introduction 
 
A quantum-neuron-based (QN-based) optimization 
[1] is devised to improve the classical quantum-
computing algorithm to break NP-complete problem. 
This is to incorporate quantum dynamics into a neural 
network, in such a way that one could utilize global 
information and overcome the disadvantage of neural 
network being trapped to some local minimum and 
outputs error due to gradient descent. It follows that 
QN-base optimization considers a qubit as a Hopfield-
Neural-Net’s neuron [2] and designed a new 
Hamiltonian by converting the synaptic weights of 
Hopfield-Neural-Net’s neurons to the interactions of 
qubits. By utilizing adiabatic Hamiltonian evolution 
[3], it may be possible to introduce dissipation-like 
effect to a qubit network with a complexity of 
polynomial-time rather than a complexity of 
exponential-time. It actually turns NP-problem into P-
problem, and this is a manifest benefit for QN-based 
computation. 
However, QN-based computation with traditionally 
adiabatic Hamiltonian evolution solved an 
unstructured search problem in a time of order N  
where N  is the dimension of search space. The cost of 
QN-based optimization in fact is still considerable 
while searching a big unsorted database. In order to 
speedup the QN-based search, we study how the 
structure of the search problem may be exploited to 
further improve the efficiency of these quantum 
adiabatic algorithms [4]. First, Cerf, Grover, and 
Williams showed that partitioning the unknown 
variables into two (or more) sets and nesting a 
quantum search over one set into another search over 
two (or more) sets, can yield an average complexity of 
order αN  with 1<α  [5]. Second, a local adiabatic 
search over a subset of the variables can be used to 
build a better initial Hamiltonian for the global 
adiabatic search [6], according to the report by Roland 
and Cerf. In this research, we bring the ideas of nested 
quantum search and local adiabatic evolution together, 
called nested local adiabatic evolution, so that it is with 
a complexity that, although still exponential, grows 
with a reduced order in the problem size. 
More precisely, nested local adiabatic evolution 
QN-based computation is designed to implement the 
optimization algorithm, the global adiabatic evolution 
(stage C) has to be discretized, which makes it possible 
to nest the preliminary adiabatic search locally (stages 
A and B) into the global one. Each step of the 
discretized algorithm requires alternating partial 
adiabatic searches backward and forward with global 
search iteration steps. Moreover, it is noted that this 
scaling could be further improved by using several 
levels of nesting, i.e., by replacing the preliminary 
search over the primary variables by another nested 
structured search. Eventually, several levels of nesting 
has the average complexity of order of, αβN  with 
1<α  and 1<β , which it can reduce the computation 
time further. 
 
2. Adaptive support vector regression 
 
We consider approximating functions )(⋅f  solved 
by support vector regression (SVR) [7] with the form 
of 
bxwf
l
i
ii +=∑
=1
)(),( φwx , (1) 
where )(⋅φ , iw , and b denote a nonlinear mapping, a 
weighted value, and a bias, respectively. Furthermore, 
Vapnik introduced a general type of loss function, 
namely the linear loss function with ε -insensitivity 
zone [7], as 
⎪⎩
⎪⎨
⎧
−−
≤−=−
.),(
,),(0
),(
otherwisefy
fyif
fy ε
ε
ε wx
wx
wx  (2) 
According to the learning theory of SVMs [8], this 
can be expressed by maximizing dual variables 
Lagrangian ),( *ααdL  where l , ix , iy , and ),( ⋅⋅K  denote 
the number of vectors, an input vector, an output 
vector, and the kernel function, respectively. 
 4
composing a new Hamiltonian FH  considering the 
synaptic weights ijklw . The Hamiltonian FH  for the 
target problem is obtained as shown in the following 
equation. The eigenvalue iε  of a basis state i  should 
be obtained from the cost function in Eq. (10). 
Therefore, FH  has iε  as the diagonal elements as 
∑−
=
−
=
⎟⎟
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜⎜
⎜
⎝
⎛
=
12
0
12
1
0
0
0 n
n
n
iF iiH ε
ε
ε
ε
O
, (16) 
By choosing a proper FH , it is possible to solve the 
problems. However, the calculation cost of n2 , where 
n  is the number of qubits, is necessary in order to 
obtain the above-mentioned Hamiltonian FH  , and 
there is no difference when compared with a heuristic 
search. Therefore, the key of application is how we 
choose a more effective FH  with less calculation cost. 
The Hopfield net [13] is a recurrent neural network 
as shown in Figure 1 in which all connections are 
symmetric. Invented by John Hopfield (1982), this 
network has the property that its dynamics are 
guaranteed to converge. If the connections are trained 
using Hebbian learning then the Hopfield network can 
perform robust content-addressable memory, robust to 
connection alteration. Various functions of an artificial 
neural network (ANN) are realized by choosing 
suitable synaptic weights. A full connection neural 
network has 2n  synapses, where n  is the number of 
neurons. In order to reduce the calculation cost of the 
Hamiltonian, we consider interactions between qubits 
and study a new method with a new FH  comprising 
nondiagonal elements considering its analogy to ANN. 
For convenience, we assume we have closely coupled 
2-spin-1/2 qubits. The Hamiltonian of this quantum 
system is 
⎟⎟
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜⎜
⎜
⎝
⎛
−
−==
1000
0120
0210
0001
),( 1221 JJH σσ , (17) 
where 12J  is the magnitude of the interactions, and iσ  
is the Pauli spin matrix. The eigenvalues and 
eigenvectors of this Hamiltonian when 112 =J  are 
shown as -3 for 1001 −  and 1 for 1001,11,00 + , 
respectively. The possible states to be measured are 
10  or 01  if the system is in the ground state 
1001 − . It can be said that the interaction of two 
neurons is inhibitory if we consider the analogy with 
an ANN model. Excitatory interaction is also possible 
with another Hamiltonian. From the above 
consideration, we can design a new Hamiltonian by 
converting the synaptic weights in Eq. (10) to the 
interactions of qubits.  
The neuromorphic quantum -based optimization [1], 
as shown in Figure 1, can apply kjw  in Eq. (10) to 
calculate final Hamiltonian FH  like an example as 
shown in Eq. (17) providing for adiabatic evolution 
algorithm in Eq. (12)-(13) to train the constrained 
optimization for an cost function expressed in Eq. (3)-
(4). 
 
Figure 1. A Hopfield network is exploited for 
neuronmorphic quantum-based optimization. 
 
4. Nested adiabatic evolution for quantum-
neuro-based computation 
 
In this article, we consider a class of problems 
where one has to find an assignment for a set of 
variables. For each additional variable considered, new 
constraints appear and reduce the set of satisfying 
assignments. This corresponds to most problems 
encountered in practice (k-SAT, graph coloring, 
planning, combinatorial optimization, etc.). Now 
suppose we consider a larger set of variables nAB 
=nA+nB that have to satisfy a set of constraints CAB⊃CA. 
To discriminate between assignments satisfying CAB or 
not, we will use an oracle OAB or a corresponding 
Hamiltonian HAB. 
The basic idea of our structured search will be to 
find the solutions of CAB by first building the 
assignments of the nA primary variables satisfying CA, 
then by completing them with all possible assignments 
of the nB secondary variables, and finally by searching 
among these could-be solutions the global satisfying 
assignments. This problem is of the same type as the 
one considered in [5], for which the technique of 
nesting was introduced in the context of the traditional 
implementation of Grover’s algorithm on a 
conventional quantum circuit. Here, we apply this 
technique to the adiabatic quantum search algorithm. 
Suppose we divide the variables of our problem into 
 6
where all MA’s had to be supposed equal to 1, as here it 
is sufficient that they are of the same order of 
magnitude to ensure an error probability of the same 
order for each term. At the end of this second stage, we 
have thus constructed a state close to 
,||
|1
|1
||1|
//
0
>+>=
>⊗
>+
>⊗>=>
∑
∑
∑
Μ∈
Μ∈
Ν∈
Μ∈
S
A
S
ANS
A
NS
A
m
B
mB
m
A
i
A
j
m
BA
BA
AB
M
M
M
M
m
M
me
M
jm
NM
AmBBA
S
AA
Am
B
NS
AA
ψψ
ψ
φ  (34) 
where the 
Amφ ’s are phases appearing during the 
evolution, 
∑
Ν∈
Μ∈
>⊗>>=
B
NS
AA
j
m
BA
B
NS
A
NS jm
NM
||1|ψ , (35) 
∑∑
Μ∈Μ∈
>⊗>>=
AmBBA
S
AA
Am
m
B
mBm
A
i
S
A
NS m
M
me
M /
|1|1|
/
φψ , (36) 
and NSAM  ( SAM ) is the number of elements in set NSAΜ  
( SAΜ ). 
 
4.3. Global adiabatic search 
 
The stages A and B define a unitary evolution U that 
applies the initial state >⊗> BA ss ||  onto >ABψ| : 
>>≈⊗> ABBA ssU ψ|||  (37) 
>+>= S
A
S
ANS
A
NS
A
M
M
M
M ψψ || . (38) 
In this state, we now need to decrease the amplitude of 
the first term, corresponding to partial solutions only, 
and increase the amplitude of the second term, 
corresponding to global solutions. This could be 
realized efficiently by performing an adiabatic search 
using an initial Hamiltonian: 
|| ABABAi IH ψψ ><−=  (39) 
+><⊗><−≈ UssssIUH BBAAABi |)|||(  (40) 
+≈ UUHH i 0  (41) 
where ||||0 BBAAAB ssssIH ><⊗><−= , and a final 
Hamiltonian 
∑
Μ∈
><⊗><−=
=
ABBA mm
BBAAAB
ABf
mmmmI
HH
),(
||||
 (42) 
during a time 
⎟⎟⎠
⎞
⎜⎜⎝
⎛= S
A
A
C
M
NOT . (43) 
Unfortunately, we do not have access to Hi , so that 
the interpolating Hamiltonian H(s)=(1-s)Hi+sHf cannot 
be applied directly. However, we will see that thebasic 
steps of the quantum-circuit implementation of this 
adiabatic algorithm require only the application of Hi 
during a particular time t, that is, 
+−−− =≈ + UUeee tiHtUiUHtiHi 00 . (44) 
Hence, each application of Hi during a time t will 
be equivalent to sequentially applying U+, tiHe 0− e-iH0t, 
and U, which means performing the adiabatic 
evolution U (stages A and B) backward, then applying 
H0 for a time t, and finally rerun U forward (stages A 
and B). We will see that, when discretizing the 
evolution, we must take a number of steps rC of order 
TC. We may now evaluate the complexity of this 
algorithm. As it consists of rC steps, each involving 
two applications of U or U+, that last a time of order 
TA+TB , the algorithm finally takes a time of order 
.)( CBA rTTT +=  (45) 
.
min
min
/
/
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+=
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+=
A
A
A
A
mB
m
S
A
BA
S
A
A
S
A
A
mB
m
B
A
A
MM
NM
M
NO
M
M
M
N
M
NO
 (46) 
Let us notice that, with the same hypothesis as in 
[15], namely, 
AmB mM A ∀= ,1/ , (47) 
AB
S
A MM = , and the computation time is 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ +=
AB
BAA
M
NMN
OT , (48) 
so that the complexity is the same as that of the 
equivalent circuit-based algorithm described in [5]. A 
more detailed analysis of this complexity will be 
performed below. 
 
4.4. General method 
 
The implementation of a global adiabatic evolution 
algorithm on a discrete quantum circuit was initially 
shown in [3], further studied in [14], and extended to 
the case of a local adiabatic evolution algorithm in [16]. 
Let us recall that we use the term ‘‘global’’ when the 
adiabatic condition is imposed globally and the 
evolution interpolates linearly between the initial and 
the final Hamiltonians, whereas ‘‘local’’ means that 
the evolution is optimized at each time, using a local 
version of the adiabatic condition, which is the case 
here. We now quickly review the discretization of this 
last method, which uses two successive 
approximations. The first approximation consists in 
cutting the evolution time T into r intervals ΔT=T/r and 
replacing the continuously varying Hamiltonian H(t) 
by a Hamiltonian H'(t) that is constant during each 
interval ΔT and varies at times tj=jΔT only: 
jjj tttiftHtH ≤≤=′ −1)()( , (49) 
 8
五、 參考文獻 
 
8. References 
 
[1] S. Sato, M. Kinjo, O. Takahashi, Y. Nakamiya, 
and K. Nakajima, “A Study on Neuromorphic 
Quantum Computation,” Proc. of IJCNN 2004, pp. 
3253-3256, 2004. 
[2] D. W. Tank and J. J. Hopfield, “Simple ’neural’ 
optimization networks: An A/D converter, signal 
decision circuit, and a linear programming 
circuit,” IEEE Trans. Circuits Syst., Vol. 36, pp. 
533- 541, 1986. 
[3] E. Farhi, J. Goldstone, S. Gutmann, J. Lapan, A. 
Lundgren, and D. Preda, “A Quantum Adiabatic 
Evolution Algorithm Applied to Random 
Instances of an NP-Complete Problem,” Science, 
Vol. 292, pp. 472-475, 2001. 
[4] J. Roland and N. J. Cerf, “Adiabatic quantum 
search algorithm for structured problems,” Phys. 
Rev., A 68, 062312, 2003. 
[5] N. J. Cerf, L. K. Grover, and C. P. Williams,” 
Quantum search by local adiabatic evolution,” 
Phys. Rev., A61, 032303, 2000. 
[6] J. Roland and N. J. Cerf, “Nested quantum search 
and structured problems,” Phys. Rev., A 65, 
042308, 2002. 
[7] V. Vapnik, The Nature of Statistical Learning 
Theory, Springer-Verlag, New York, 1995. 
[8] N. Cristianini, J. Shawe-Taylor, An Introduction 
to Support Vector Machines (and other kernel-
based learning methods), Cambridge University 
Press, London, 2000. 
[9] B. R. Chang, “Compensation and Regularization 
for Improving the Forecasting Accuracy by 
Adaptive Support Vector Regression,” 
International Journal of Fuzzy System, Vol. 7, No. 
3, pp. 109-118, 2005. 
[10] E. Kreyszig, Advanced Engineering Mathematics, 
8th Edition, Wiley, New York, 1999. 
[11] G. H. Golub and C. F. van Loan, Matrix 
Computations, 3rd Ed., Johns Hopkins University 
Press, Baltimore, 1996. 
[12] A. Messiah, Quantum Mechanics, Dover, New 
York, 1999. 
[13] J. J. Hopfield, “Neural networks and physical 
systems with emergent collective computational 
abilities,” Proc. of the National Academy of 
Sciences of the USA, Vol. 79, No. 8, pp. 2554-
2558, 1982. 
[14] W. van Dam, M. Mosca, and U. Vazirani, “How 
Powerful is Adiabatic Quantum Computation?,” 
Proc. of the 42nd Annual Symposium on the 
Foundations of Computer Science, pp.279–287, 
IEEE Computer Society Press, New York, 2001. 
[15] D. Aharonov and A. Ta-Shma, “Adiabatic 
Quantum State Generation and Statistical Zero 
Knowledge,” Proc. of the 35th Annual ACM 
Symposium on Theory of Computing, pp. 20–29, 
ACM Press, New York, 2003. 
[16] J. Roland and N. J. Cerf, “Quantum-circuit model 
of Hamiltonian search algorithms,” Phys. Rev., A 
68, 062311, 2003. 
[17] U. Schoning, “A Probabilistic Algorithm for k-
SAT and Constraint Satisfaction Problems,” Proc. 
of the 40th Annual Symposium on the 
Foundations of Computer Science, pp. 410–414, 
IEEE Computer Society Press, New York, 1999. 
[18] T. Hofmeister, U. Schoning, R. Schuler, and O. 
Watanabe, “A Probabilistic Algorithm for k-SAT 
and Constraint Satisfaction Problems,” Proc. of 
the 19th Annual Symposium on Theoretical 
Aspects of Computer Science, pp. 192–202, edited 
by H. Alt and A. Ferreira, Lecture Notes in 
Computer Science Vol. 2285, Springer, Berlin, 
2002. 
[19] B. R. Chang, “Hybrid BPNN-Weighted Grey-
CLMS Forecasting,” Journal of Information 
Science and Engineering, Vol. 21, No. 1, pp. 209-
221, January 2005. 
[20] B. R. Chang, “Applying Nonlinear Generalized 
Autoregressive Conditional Heteroscedasticity to 
Compensate ANFIS Outputs Tuned by Adaptive 
Support Vector Regression,” Fuzzy Sets and 
Systems, Vol. 157, No. 13, pp.1832-1850, July 
2006. 
[21] International Stock Price Index, FIBV FOCUS 
MONTHLY STATISTICS, 2001. 
[22] Typhoon Moving Trace Inquire, Central Weather 
Bureau, Taipei, Taiwan, 2005. 
[23] Bao Rong Chang, Hsiu Fen Tsai, Shi-Huang 
Chen, and Yu Chang Chen, “Diversity of 
Quantum Optimizations for Training Adaptive 
Support Vector Regression,” Proc. of 11th 
Conference on Artificial Intelligence and 
Applications (TAAI2006), pp. 830-836, National 
Kaohsiung University of Applied Science, Dec. 
15-16, 2006. 
[24] Bao Rong Chang, Chung-Ping Young, Hsiu Fen 
Tsai, Shi-Huang Chen, Yu-Chang Chen, and Yu-
Kuo Tseng, “Nested Local Adiabatic Evolution 
for Quantum-Neuron-Based Adaptive Support 
Vector Regression and Its Application,” Proc. of 
IEEE The Second International Conference on 
Innovative Computing, Information and Control 
(ICICIC-07), Kumamoto City International 
Center, Japan, Aug. 30-Sept. 1, 2007. 
 10
Table 2. The performance evaluation follows the 
criteria: (a) mean square error (MSE)* and (b) mean 
absolute percent error (MAPE) on Nari typhoon 
moving path during September 6-19, 2001 and 
Mindulle typhoon moving path during June 28 – July 3, 
2004. 
 
(a) 
Methods Nari Typhoon  Moving Path 
Mindulle Typhoon 
Moving Path Average
GM 0.0082 0.0060 0.0071
C3LSP 0.0469 0.0381 0.0425
4LR 0.0477 0.0387 0.0432
HW 0.0184 0.0130 0.0157
BJ 0.0275 0.0137 0.0206
BPNN 0.0195 0.0526 0.0361
ARMANG 0.0660 0.2397 0.1529
BWGC 0.0077 0.0054 0.0066
NQNASVR-
BWGCNG 0.0075 0.0048 0.0062
 
(b) 
Methods Nari Typhoon  Moving Path 
Mindulle Typhoon 
Moving Path Average
GM 0.0047 0.0043 0.0045
C3LSP 0.0086 0.0140 0.0113
4LR 0.0092 0.0147 0.0120
HW 0.0072 0.0068 0.0070
BJ 0.0075 0.0056 0.0066
BPNN 0.0089 0.0127 0.0108
ARMANG 0.0695 0.6052 0.3374
BWGC 0.0044 0.0041 0.0043
NQNASVR-
BWGCNG 0.0039 0.0034     0.0037
 
0 5 10 15 20 25 30 35 40 45
7000
8000
9000
10000
11000
12000
sample number
fu
nc
tio
n 
va
lu
e
djindex
desired sequence
predicted sequence by grey
predicted sequence by c3lsp
predicted sequence by nqnasvr
 
Figure 3. Forecasts of N. Y. -D. J. Industrials. monthly 
index for 48 months from Jan. 2002 to Dec. 2005. 
0 5 10 15 20 25 30 35 40 45
3500
4000
4500
5000
5500
6000
6500
7000
7500
8000
8500
sample number
fu
nc
tio
n 
va
lu
e
taiexindex
desired sequence
predicted sequence by grey
predicted sequence by c3lsp
predicted sequence by nqnasvr
 
Figure 4. Forecasts of Taiwan TAIEX monthly index 
for 48 months from Jan. 2002 to Dec. 2005. 
 
0 5 10 15 20 25 30 35 40 45
0.8
0.9
1
1.1
1.2
1.3
1.4
1.5
1.6
x 10
4
sample number
fu
nc
tio
n 
va
lu
e
nikindex
desired sequence
predicted sequence by grey
predicted sequence by c3lsp
predicted sequence by nqnasvr
 
Figure 5. Forecasts of Japan Nikkei monthly index for 
48 months from Jan. 2002 to Dec. 2005. 
 
0 5 10 15 20 25 30 35 40 45
3500
4000
4500
5000
5500
6000
sample number
fu
nc
tio
n 
va
lu
e
ftindex
desired sequence
predicted sequence by grey
predicted sequence by c3lsp
predicted sequence by nqnasvr
 
Figure 6. Forecasts of London FTSE-100 monthly 
index for 48 months from Jan. 2002 to Dec. 2005. 
 1
參加 ICICIC 2007 國際研討會出國報告書 
報告人：張保榮 
國科會補助編號：NSC 95-2221-E-143-004 
 
1.參加會議經過   
二 00 七年國際創新計算、資訊、控制研討會（2007 Second International Conference 
on Innovative Computing, Information and Control）所舉行之計算、資訊和控制
(Computing, Information, and Control Technology)三領域之綜合性國際研討會，於
九月五日至九月七日共三天由日本 ICIC國際中心(ICIC International Center, Japan)
主辦，在日本九州熊本市國際交流會議中心(Kumamoto City International Center, 
Kumamoto, Japan)舉行。該會議是每年一度重要的國際研討會，結合學者及業者
從學術界到工業來呈現訊號處理、影像處理、語音處理、移動計算、多媒體處理、
資訊安全、嵌入性系統、生物醫學、資料探勘、知識管理、機械學習、人工智慧、
神經網路控制、模楜控制、最佳化及決策、建模與模擬、風險管理、系統辨識的
最新進展，含蓋計算、資訊、系統和控制這四方面的理論及應用。主辦單位計有
IEEE 學會電腦社團(IEEE Computer Society)、日本 ICIC 國際中心 (ICIC 
International Center, Japan)、日本九州東海大學(Kyushu Tokai University, Japan)、 
台灣國立高雄應用科大 (National Kaohsiung University of Applied Sciences, 
Taiwan)、台灣人工智慧學會 (Taiwanese Association for Artificial Intelligent)及熊
本國際展場暨旅遊局(Kumamoto International Convention and Tourism Bureau)。近
年因創新計算與資訊及智慧型系統與控制的熱烈發展，所以本研討會劃分有兩大
類，細分包含有 25 個專業領域；共收到超過 1000 篇投稿論文，其中只接收 624
篇，論文審查接受率為 63％，然而受到日本 ICIC 國際中心熱心的邀請之影響，
因而增加許多人參加會議，因此實際參與此次的論文發表人數近乎起超過 300
人 左 右 。 筆 者 在 會 中 發 表 乙 篇 論 文 為 ”NESTED LOCAL ADIABATIC 
EVOLUTION FOR QUANTUM-NEURON-BASED ADAPTIVE SUPPORT 
VECTOR REGRESSION AND ITS APPLICATION”。 
 
2.與會心得 
本次國際研討會共邀請二位學者專家來做全席大會演講，其目的是為了彰顯此次
大會所揭櫫的主題：創新計算、資訊、控制。第一位受邀演講者是 Professor Harold 
Szu, PhD, Fellow of IEEE, and AIMBE, Office of Naval Research, and George 
Washington University, USA 所演講的主題是 ” Innovative Computing for 
Homecares”。第二位演講者是 Professor Pieter Nagel, PhD, Victoria University, 
Australia 所演講的主題是 “Logistics Cities: Infrastructural Nodes Towards Supply 
Chain Efficiencies”。實際這兩場演講內容都是涵蓋在電腦和資訊科技的領域中，
這二篇都著重於概念的獲得和實務的介紹。這種大型的演講安排了理論與應用並
