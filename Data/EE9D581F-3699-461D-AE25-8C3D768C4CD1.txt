 1
行政院國家科學委員會專題研究計畫成果報告 
 
遍布即時多媒體系統與技術（總計畫）(III) 
Pervasive Multimedia System and Technology (III) 
計畫編號：95-2221-E-009 -070 -MY3 
執行期限：97 年 8 月 1 日至 98 年 10 月 31 日 
主持人：杭學鳴   國立交通大學電子工程學系教授 
共同主持人：蔡淳仁，彭文孝，李素瑛，蕭旭峰 國立交通大學 
計畫參與人員：林鴻志、洪朝雄、蔡家揚、呂忠穎、韓建智、吳明儒 國立交
通大學研究生 
 
 
 
 
中文摘要 
鑑於未來網路結構與應用趨於異質結合，本計畫將針對『無所不在』的多媒體系統
與技術進行研究。在異質網路中，每個終端設備接入的網路頻寬及特性並不一致，且終
端設備本身的運算能力也不相同，造成傳統的單一層次多媒體編碼在應用上有相當困
難。在此種環境中，需利用多層次編碼法與分散式運算，以求得整體最佳效能。而建構
這類應用則需要串流系統的支援才能實現。有了這些技術，多媒體內容可以廣為散佈至
各種接收環境。然而，必須輔以內容為檢索基礎的搜尋技術以及智慧財產權保護機制，
讓媒體提供者樂於提供，讓媒體接收者方便搜尋，如此才能達到『無所不在』的多媒體
系統概念。 
上述多媒體系統相關技術分在五個子計畫中進行: (1)在 P2P 環境下運用分散式視訊
編碼技術的視訊通訊系統設計；(2)可調視訊編碼之適應性動態精細改進和編碼；(3)多
型態多媒體為基礎之內容分析、索引與查詢；(4)多媒體傳輸安全機制與可調音訊編碼；
以及(5)有線/無線環境上建構於對等連網及內容傳播網之可適性串流技術。本計畫之研
究涵蓋異質網路多媒體應用的基礎關鍵技術，預期研究成果將可促進相關系統的研發，
並可貢獻於學術界與產業界。交通大學團隊持續參與 MPEG 標準會議，並提出貢獻案。
整體計畫時程為三年，本報告將簡述三年來之各項成果，特別著重於第三年。 
 
關鍵詞：分散式編碼、可調層次式編碼、多媒體搜尋、多媒體安全、串流視訊 
 3
目錄 Table of Contents 
 
1.  背景與目的 ........................................................................................................................ 4 
2.  在 P2P 環境下運用分散式視訊編碼技術的視訊通訊系統設計 -- 蔡淳仁教授 ......... 5 
2.1.  緣由與目的 ............................................................................................................ 5 
2.2.  結果與討論 ............................................................................................................ 6 
3.  可調視訊編碼之適應性動態精細改進和編碼 –彭文孝教授 (蔣迪豪教授) ............. 10 
3.1.  第一部分 .............................................................................................................. 10 
3.2.  第二部分 .............................................................................................................. 10 
3.3.  第三部分 .............................................................................................................. 11 
3.4.  參考文獻 .............................................................................................................. 14 
4.  多型態多媒體為基礎之內容分析、索引與查詢 -- 李素瑛教授 ............................... 14 
4.1.  運動影片分析 ...................................................................................................... 15 
4.2.  人類行為辨視 ...................................................................................................... 16 
4.3.  音樂節奏分析 ...................................................................................................... 17 
4.4.  總結與未來發展 .................................................................................................. 18 
5.  多媒體傳輸安全機制與可調音訊編碼 -- 杭學鳴教授 ............................................... 18 
5.1.  第一部份 (前兩年計劃研究成果) ..................................................................... 19 
5.2.  第二部份 (本年度計劃研究成果) ..................................................................... 20 
6.  有線/無線環境上建構於對等連網及內容傳播網之可適性串流技術 -- 蕭旭峰教授
 25 
6.1.  整體系統架構說明 .............................................................................................. 25 
6.2.  系統特性之說明 .................................................................................................. 27 
6.3.  系統各伺服器之展示 .......................................................................................... 28 
6.4.  總結與未來發展 .................................................................................................. 29 
7.  本年度參與之 MPEG 會議活動 ..................................................................................... 30 
8.  計畫整體成果與自評 ...................................................................................................... 31 
9.  本研究群發表之相關論文與碩博士論文 ...................................................................... 32 
 5
此「遍布即時多媒體系統與技術」整合計畫依照每位教授的專長，分工負責其中的
關鍵技術，其分配情形如下： 
(一) 在 P2P 環境下運用分散式視訊編碼技術的視訊通訊系統設計 
      －－子計畫一：蔡淳仁(資訊工程學系)教授 
(二) 可調視訊編碼之適應性動態精細改進和編碼 
     －－子計畫二：蔣迪豪(電子工程系) 彭文孝(資訊工程學系)教授 
(三) 多型態多媒體為基礎之內容分析、索引與查詢 
     －－子計畫三：李素瑛(資訊工程學系)教授 
(四) 多媒體傳輸安全機制與可調音訊編碼 
      －－子計畫四：杭學鳴(電子工程系)教授 
(五) 有線/無線環境上建構於對等連網及內容傳播網之可適性串流技術 
      －－子計畫五：蕭旭峰(資訊工程學系)教授 
以下節錄各計畫之成果，不盡完備之處請參閱各計畫報告。 
 
 
2. 在 P2P 環境下運用分散式視訊編碼技術的視訊通訊系統設計 -- 蔡淳仁
教授 
在過去三年的計畫中，子計畫一主要的工作項目是開發新的分散式視訊編碼的技
術。由於點對點 (Peer-to-Peer, P2P) 即時通訊系統的通訊應用有越來越廣泛的趨勢，而
且進行對等視訊傳輸的兩個終端設備(Peers)的種類也變得多樣化。因為傳統視訊編碼演
算法在編碼端的計算量遠大於解碼端，如果在 P2P 的即時視訊傳輸應用中，傳送端設備
（如手機）比接收端設備（如桌上電腦）的計算能力小很多時，傳統的即時視訊編碼的
演算法就不符應用。比較適合 P2P 應用的視訊編碼演算法則是分散式視訊編碼演算法
(Distributed Video Coding, DVC)，因為 DVC 可以在維持一定的編碼效率的前提下，根據
兩個終端設備的計算能力來調整編碼及解碼所需的運算量。而本計畫在過去三年最主要
的成果，就是開發了一套新的 DVC 編碼演算法。跟目前國外所提出的效能最佳的 DVC
演算法(DISCOVER codec)相較，在一些實用的測試條件下，我們的編碼效率提升可以多
達 1dB ，而且跟 AVC/H.264 zero motion 的 inter-coding 效能相近。 
2.1. 緣由與目的 
本計畫以分散式編碼原則設計一套新的編解碼系統，目標是在編碼端運算複雜度
相當的情形下，達到跟 AVC/H.264 一樣的壓縮率。我們針對解碼端影像模型和編碼端
預估誤差模型進行討論和設計。在解碼端影像模型部份，我們分別設計投影式 Side 
 7
Key frame
(frame t) Key frame
(frame t+2)SI of W-Z frame(frame t+1)
MVt
MVf
MVb
 
圖 1 投影式 SI 產生法 
圖 2 是 foreman 和 carphone 兩個 sequences 中 WZ frame 的 SI。在 foreman 中，可
以發現在臉部有非常明顯的視覺瑕疵，這樣的瑕疵來源是因為這部分運動並不符合區塊
運動模型因此難以精確估計。而在背景部分，牆壁的地方在視覺效果上並無明顯的瑕
疵，但是實際的錯誤量卻很大，這主要成因是因為利用線性內插來估測真實移動量所產
生的錯誤。在 carphone 也有類似的現象。 
        
圖 2 Side Information and Error Image 
從以上分析可以很明顯的看出，假設 SI 生成的誤差是成 i.i.d.分佈，因而設計固定
的 WZ code 編碼來校正錯誤會是相當沒有效率的作法。而且不同種類的 error 對視覺效
果所造成的影響也不盡相同，善用這樣的特性，在相同頻寬編碼條件下可以達到更好的
視覺上的畫質。 
Adaptive WZ-Coding for DVC 
根據前述分析，我們提出一個新的分散式視訊編碼架構。如圖 3 所示：影片首先
被分為 KEY frames 和 WZ frames，KEY 經過傳統 intra-coding 壓縮，WZ 則是經過 WZ 
encoder編碼。在解碼端，SI生成模組根據KEY的資訊產生SI，接下來利用SI和WZ bit
進行解碼。在架構中，我們提出一個新的壓縮工具：動態群組 (adaptive grouping)。在
WZ code 之前，我們將資料根據特性進行分組，盡量使得每一組有相同的錯誤特性，
接下來針對不同的組設計對應的WZ code。這樣的架構下，基本的WZ code單位從 frame
變為 group，新的編碼工具有如下好處： 
甲、每個 group 裡的資料有相同的 error 特性，因此同一個 code block 裡的資料更符
合 i.i.d.的特性，可以提升 channel code 的效能 
 9
構下，我們可以優先 deocode 會造成視覺瑕疵的部分，而忽略在視覺上並不易發現的錯
誤，因此本計畫提出了一個對應的 rate control 演算法。我們假設一個線性 bit allocation
模型：每個 group 所需要花的 bits 數和 MPSAD 成正比。 
Bi =   Ei , 
其中，Bi 是第 i 個 group 所分配到的 bits 數， 為可調的常數，而 Ei則是第 i 個 group
在進行 SI 生成時的 MPSAD。在解碼過程中，利用上述關係找出目前 group 所需要的
rate，並且更新。利用這樣的方式我們可以有效的將資源分配給 WZ frame，在有限頻
寬下達到較好的視覺效果。 
Experimental Result 
 我們根據上述架構設計實驗，圖 4 是 foreman 和 hall 的 RD 表現。如圖所示，藍色
的線是 DISCOVER 的表現，黑色的線是完全不將 bit 放在 WZ 上的表現，紅色的線是基
於我們提出的架構去更正視覺誤差的表現。由圖可以發現，我們所提出的架構比
DISCOVER 有更好的 RD 表現，也較 AVC Intra/Zero Motion 好。並且因為我們優先更正
為對視覺產生影響的 group，因此可以達到較佳的視覺效果。 
50 100 150 200 250 300 350 400 450 500
28
30
32
34
36
38
40
Rate (kb/s)
P
S
N
R
 (
db
)
RD curve:foremanqcif
 
 
DISCOVER
Without WZ decoding
TimeAdaptiveRateControl
AVC Intra
AVC Zero Motion
50 100 150 200 250 300 350 400 450 500
28
30
32
34
36
38
40
Rate (kb/s)
P
S
N
R
 (
db
)
RD curve:hallqcif
 
 
DISCOVER
Without WZ decoding
TimeAdaptiveRateControl
AVC Intra
AVC Zero Motion
 
圖 4 R-D Curve 
總結以上的結果，本子計畫提出新的分散式編碼工具，利用這個工具可以增進 WZ
的編碼效率並且在視覺上可以達到更好的效果。目前的成果已經大符超越現今國際上有
發表的效果最佳的分散式編碼法－DISCOVER codec，而且大約與傳統編碼法中的
AVC/H.264 的 zero-motion 的 inter-frame coding 的效能相當，不過，要在實用上能取代
傳統的編碼法，我們必需把編碼效率提高到明顯超越 H.264 的 zero-motion inter-frame 
coding。也是未來努力的方向。 
 
 11
3.3. 第三部分 
緣由與目的 
這是第三年度所提出的研究，基於可調視訊編碼(SVC)之架構，在使用多層編碼控制
(Multi-layer Encoder Control)下，進行編碼速度優化的問題。傳統由下往上的編碼控制
(Bottom-up Encoder Control)相對於單層編碼(Single-layer Coding)上會有不對稱的編碼效
率損失。因此為了能夠在基層(Base Layer)和增進層(Enhancement Layer)之間的編碼效率
上做權衡，多層編碼控制技術已在先前被提出來。然而在現今的方法上，有兩個主要的
問題存在:(1)基層使用權重式的Lagrangian成本決策方法(Mode Decision)，(2)增進層則是
使用單層編碼決策方法。前者在解決限制式最佳化問題上，其目標函數和限制條件兩者
都將會隨著權重因子(w)的選擇而有所變化。此外又因為基層和增進層方法不一致的影
響，導致在增進層的編碼效能上可能出現無法預期的結果。為了解決這些問題我們修改
多層編碼控制的Lagrangian成本計算方式。此外多層編碼控制存在著編碼速度過於緩慢
的缺陷，本研究利用主導性配對(Dominant Mode Pair)的觀念以及對增進層決策的重新審
視，提出了一個兩階段式的快速決策演算法。實驗結果顯示，本文提出的快速決策演算
法跟徹底式搜尋(Exhaustive Search)所需的56組配對相比，我們平均僅需要測試13組即可
在這樣的決策組數降低下，編碼平均速度不僅超越徹底式搜尋逾84%，更在編碼品質上
沒有太多的失真。此外，產生出來的實驗結果也顯示，新的快速決策演算法相較於過去
的決策演算法上，本方法在給予不同的權重因子中更具有可預測性以及連貫性。 
 
實驗結果與結論 
本次研究中，我們提出了一個不同於Schwarz多層編碼控制的方程式[1]， 如下： 
------------------(1) 
方程式(1)可以依照使用者的需要，給予不同的權重來調整基層和增進層的畫質。而我們
所提出的決策方法與Schwarz的決策方法之差異，在於Schwarz的多層編碼控制在基層使
用權重式的Lagrangian成本，但在增進層則是使用單層編碼決策方法;而我們的方法則是
使用修改過的權重式Lagrangian成本同時決定基層和增進層的一組分割模式配對。以方
程式(1)為基礎，徹底式搜尋(Exhaustive Search)的分割模式配對有56組，為了減少分割模
式選擇(Mode Decision)所需要的時間，我們提出了一個快速決策的演算法，如圖 5，其
流程如下: 
1) 先假設增進層的分割模式，然後計算權重式Lagrangian成本。以方程式(1)計算
 13
 
圖 5 本次研究提出的快速決策演算法 
在圖 6的測試Sequence為圖片大小為QCIF的Crew和大小為CIF的Soccer。經過快速決策
演算法運算後的R-D曲線，效能和徹底式搜尋有很接近的結果;基於本次研究所提出的方
程式和演算法之實驗結果，基層和增進層在不同權重時有不同的畫質及減少的時間量，
且可減少84%以上的計算量。 
Soccer CIF 15Hz
Bite rate[kbits/s]
0 200 400 600 800 1000
Y-
P
S
N
R
[d
B
]
10
15
20
25
30
35
40
Muli-layer(W=0) 
Muli-layer(W=0.1) 
Muli-layer(W=0.25) 
Muli-layer(W=0.5) 
Muli-layer(W=0.75) 
Muli-layer(W=0.9) 
Muli-layer(W=0.95) 
Muli-layer(W=0.99) 
Muli-layer(W=1) 
Single Layer 
Fast (W = 0~1)
Crew QCIF 15Hz
Bite rate[kbits/s]
0 50 100 150 200 250
Y-
P
S
N
R
[d
B
]
20
25
30
35
40
Muli-layer(W=0) 
Muli-layer(W=0.01) 
Muli-layer(W=0.25) 
Muli-layer(W=0.5) 
Muli-layer(W=0.75) 
Muli-layer(W=0.9) 
Muli-layer(W=0.95) 
Muli-layer(W=0.99) 
Muli-layer(W=1) 
Single Layer 
Fast (W = 0~1)
 
圖 6 以本次研究所提出的快速決策演算法運算後，基層和增進層在不同權重時有不同
的PSNR和Bitrate;左圖為Soccer CIF,右圖為Crew QCIF。 
 15
4.1. 運動影片分析 
我們利用球賽的特性和視覺的特色為基礎，規劃一個可在球賽轉播畫面擷取球之行
進軌道的架構。系統架構流程如圖 7 所示。首先，將投球畫面（Pitch Scene）裡的移動
物體都被分割出來。然後每個畫面就會產生出球在畫面上可能分佈的位置與圖像，其中
包含真正的球和很像球的物體，且這些物體都必須符合球的尺寸、形狀和完整性。連續
畫面中所偵測到的這些球形物體的垂直方向分佈和水平方向分佈即可用來分析行進軌
跡。最後經過鑑定的軌跡即可被擷取出來。 
 
圖 7 系統架構流程圖 
在此研究分析中，有兩個較為新穎的關鍵點。第一點是球的行進軌跡之追蹤方法雖
然會偵測到所有球形物體的軌跡，但我們可利用球賽轉播畫面裡，球會因地心引力的影
響而呈現拋物線方向運動之特性，來鑑定球真正的軌跡，即使畫面中球形物體再多，透
過此鑑定方式仍可找出我們想要的軌跡。第二點是透過對投手投出的球做軌跡分析，可
藉著所偵測到的軌跡曲線來估算出變化球的變化程度，並藉著所偵測到的球點數目來測
量出球速，以達到影像加強的效果。 
a.球之追蹤與軌跡擷取（Ball Tracking and Trajectory Extraction）: 
此演算法包含以下幾個處理過程：移動中物體之分割擷取、球形物體之偵測、球形
物體之分佈分析和軌跡之尋找與鑑定。至於投球片段的擷取（Pitch Scene Extraction），
則是利用場景分析與索引（Shot classification and indexing）的技術，透過主色比對
（dominant color matching）、區域劃分（region segmentation）和主色分布分析（dominant 
color layout analysis）來取得。 
b.影像加強（Visual Enrichment）： 
以追蹤球的位置和擷取軌跡為基礎，有一些視覺化的呈現方式可用來達到影像加強
的目的。第一，我們可以從所擷取到的軌跡之起始到結束的時間間隔去估算出球速有多
快。第二，從球路拋物線的曲率可以用來估算出變化球的幅度。此外，包含擷取出之軌
跡的第一個球的畫面可以顯示投手的投球姿勢，而包含擷取出之軌跡的最後一球的畫面
 17
 
圖 9 特徵擷取流程圖 
為了進一步辨識人上半身更複雜的動作，我們對人體建立更精細的模型。我們將
人的身體拆解成四種身體區塊，包含頭、軀幹、上手臂、下手臂。如圖 10 所示，藉由
區塊和區塊之間的關節點必須符合人體動力學(Human Kinematics)的關係，我們可以將
這四個區塊對應到每個畫面中人體相對應的位置(Pose Estimation)，而建立起人體的模
型。 
 
圖 10 採用的人體模型以及模型建立的示意圖 
我們觀察手臂上關節點的位置，將關節點之間空間上的關係分類，作為辨識動作的局
部特徵(Local Feature)。另外，我們採用手掌之間的距離作為動作辨識的全域特徵(Global 
Feature)，透過此階層式的分析，局部和全域的隱藏馬可夫模型先透過局部和全域特徵
對人體動作做初步的辨識，接著互動式 隱藏式馬可夫模型合併整合初步的辨識結果，
判斷出更為準確的辨識結果。 
 
4.3. 音樂節奏分析 
我們利用音樂訊號能量的強弱，來做拍子追蹤（beat tracking），定位每個拍子適當
的時間點。接著可以做節拍預估（tempo estimation），分析整個音樂訊號的節拍成份
 19
基礎的輪廓轉換的影像編碼等；而第二部份則包含(1) H.264/AVC 可調式視訊編碼之時
域預測模式快速演算法、(2) H.264/AVC 可調式視訊編碼之平行化演算法與於 NVIDIA 
CUDA 之實現、(3) 適用於可調式視訊之小波轉換參數訊源模型研究。此兩部分的研究
方法與成果簡述如下： 
5.1. 第一部份 (前兩年計劃研究成果) 
可調式多媒體階層式保護 
可調式多媒體階層式保護的架構中，數位內容被分成一個基本層以及數個加強層，
每多一層被解碼，數位內容的品質就會有一定程度的上升，因此我們可以藉由加密加強
層以達到階層式保護的效果，只有經過授權的使用者可以得到相對應品質的數位內容。
這個架構實現的原理是將解密所需的資訊以浮水印鑲嵌於前一層，不過傳統浮水印多半
受限於鑲嵌強度，所能夾帶的資訊量並不足以夾帶解密金鑰以及擷取浮水印本身所需的
資訊。為了克服這個問題，我們提出了視覺上可移除的浮水印之架構，被鑲嵌的浮水印
可以在浮水印被擷取之後盡可能的移除以達到視覺上不被發現的效果，如此一來我們可
以成功藉由浮水印挾帶大量的額外資訊以達到傳輸資料的功效。 
可替換式數位版權管理系統及其嵌入式裝置實作 
由消費者的觀點來看，各種不同的 DRM 系統有時候在使用上會造成困擾，因此，
可替換式的 DRM 系統有其需求。為了證明我們的設計能做到可替換式的 DRM 系統，
我們選用凌陽所開發的嵌入式系統平台(SPG290)，這個平台式原來的設計是用來發展電
視遊戲或是其他應用程式，在我們的研究上，我們使用它當作是一個擁有 SD 卡的行動
裝置，而且事前把 bootstrap 程式寫好，放在 NOR-flash 上，當此行動裝置一開機，bootstrap
程式就從 NOR-flash 載入到 SDRAM 上，並且開始執行。這個程式提供了簡單的圖形使
用者介面，讓使用者選擇想要使用哪一種 DRM 程式，再經過驗證以及載入的動作，程
式的控制主導權轉移到 DRM 的程式上，如此即可證明我們的設計能做到可替換式的
DRM 系統。 
Universal Audio and Speech Coding 
LPC 在語音壓縮已經成功了許多年。在之前的報告中有提到，我們將以原本 AAC
之為基準加上 LPC 之壓縮以改善 AAC 對語音之壓縮。由於直接使用 LPC 反倒是無法改
善對語音壓縮的效果，因此我們進一步的探討其理由為何，並發現了三個影響的因素 –  
正確的 LPC spectrum，Post-echo amplify 與 Wrong bit-allocation。 
為了比較 codec 之效能，我們使用 ITU-R BS. 1387 作為客觀評量。實驗結果顯示
TD-LPC 對語音編碼已經有所改善。此外，編碼參數的微調亦會影響其壓縮之品質，如
block 之大小、LPC order、不同取樣頻率需如何對應等皆對語音品質有相當程度的影響。 
 21
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 16x16
Temporal layer
P
er
ce
nt
ag
e 
(%
)
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 16x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 8x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 4x4
Temporal layer
 
 
FW (Qp = 40)
BW (Qp = 40)
BI (Qp = 40)
FW (Qp = 30)
BW (Qp = 30)
BI (Qp = 30)
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 16x16
Temporal layer
P
er
ce
nt
ag
e 
(%
)
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 16x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 8x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 4x4
Temporal layer  
圖 11 Distribution of Temporal Prediction (FW, BW, and BI) 
此外，加上觀察(a)大切割模式之雙向預測相關性、(b)雙向預測之碼率-失真貢獻與
(c)小切割模式之前向預測、後向預測相關性。我們提出了一套在層級時域預測架構的需
求設定下，針對雙向預測之低複雜度決定機制快速演算法，主要含三大步驟，如下： 
Step 1 (Exhaustive Prediction Type Search for Inter16x16)：16x16 切割模式中的
三種時域預測模式(Temporal Prediction Type)採用全域搜尋之方式，並保留有效
之編碼資訊，以供 Step 2 使用。 
Step 2 (Conditional BI Elimination for Large Partitions)：根據 Step 1 所得到的編
碼資訊，JSVM 編碼器可以得知何時不需要測試雙向預測(BI)，以達到減低運算
複雜度，並保留 8x8 切割模式有效之編碼資訊，以供 Step 3 使用。 
Step 3 (Adaptive Prediction Type Selection for Small Partitions)：根據 Step 2 所得
到的編碼資訊，比較前向預測(FW)與後向預測(BW)的編碼效能優劣，讓小切割
模式作為參考依據，以節省運算複雜度。 
 實驗結果顯示出我們所提出之演算法有效地大量減少在層級時域預測架構下所需
之編碼時間，其減少幅度可以達到 60%，亦比前人所設計的演算法(只有 36%之運算節
省量)更佳。 
H.264/AVC 可調式視訊編碼之平行化演算法與於 NVIDIA CUDA 之實現 
使用 GPU 來做通用運算(GPGPU)已發展多年，而一直無法普及，原因在於沒有專
用硬體和相對應的程式語言，造成開發困難。但在最近幾年，全球市佔最高的幾家大廠
如 INTEL、AMD、NVIDIA 都開始在繪圖處理器上增加通用運算的硬體，以及相關的開
發程式及工具，繪圖處理器具有極高的平行運算能力，且非常的普及，因此 GPGPU 又
再度受到大家的重視。 
 23
GOP SIZE 為 16 及 8，分別測試單一 spatial layer 及有兩層 spatial layer 的時間。實驗結
果顯示，在單一 spatial layer 有接近 10 倍加速，在兩層 spatial layer 中也有 7 倍加速。 
適用於可調式視訊之小波轉換參數訊源模型研究 
訊源編碼廣泛使用的拉格朗日(Lagrangian)最佳化方法可針對單一位元率進行有效
的位元率分配。由於可調式小波視訊編碼的量化步驟獨立於編碼之外，並且單一壓縮位
元流須同時滿足不同位元率需求，因此拉格朗日方法不適用於可調式小波視訊編碼。如
研究計畫提案之規畫，本研究目的為提出適用於小波視訊編碼之最佳化方法。此最佳化
之方法可在不同位元率條件下，得到適用之動態資訊(motion information)。 
為了進行可調式小波視訊編碼之動態資訊位元率分配之研究，我們進行下列兩個研
究步骤: (1) 提出動態資訊預測效率測量方法。(2) 提出適用於可調式小波視訊編碼之模
式決定方法。 
 動態資訊預測效率測量方法：由於動態預測主要的目的是希望可有效降低殘存
訊號的能量，進而降低因量化所造成的失真；因此，若比較在某個切取位元率
條件下的所得到的失真量，有進行動態預測的失真應該較無進行動態預測的失
真(即以 0 值作為動態向量)要來的低。所以，對一個有效率的動態預測來說， 
R-D 曲線間應呈現以下的關係 
 
 適用於可調式小波視訊編碼之模式決定方法：MPG 值越高，表示可以用較小
的動態資訊換得較大的殘存訊號變化量，我們認為這是較有效率之動態預測方
法; 反之，則被認為是較差之方法。因此，直覺上來說可以直接將 MPG 值作
為目標函式(objective function)以判斷動態向量的好壞。然而在實際情況下當動
態資訊之位元率為 0 時，MPG 值會發生奇異點問題(singularity)，此問題會造
成在判斷時過於傾向 0 值動態向量，因而導致判斷失準。因此我們利用 MPG
概念，不直接使用 MPG 值作為目標函式，而是利用其等效函式。提出基於
MPG 概念之新型態代價函式如下 
 
 根據上述兩項分析，其所設計之演算法流程如圖 13。 我們利用所提出之模式決
定方法進行模式決定步驟，並且在兩種可調性測試中測試 PSNR 表現。第一個測試是進
行 SNR 可調性測試，我們預先給定 7 個由低至高的位元率，然後測量解碼視訊之平均
PSNR 值，所使用的測試視訊為 Akiyo、Tempete、Waterfall 以及 Coastguard; 此四個測
試視訊皆為 CIF 大小，畫面率為 30fps。第二個測試則是綜合時間(temporal)與 SNR 兩種
可調性，我們預先設定 6 個位元率由低至高並具不同畫面率的測試點，然後測量解碼視
 25
 
6. 有線/無線環境上建構於對等連網及內容傳播網之可適性串流技術 -- 蕭
旭峰教授 
隨著網路影音質與量的與日俱增，傳統的 Client-Server 架構已無法適用於龐大的使
用者，而群播及同儕多播的架構提供較為可行的解決方向。但是 Peer-to-Peer 的許多天
生缺陷會造成整個串流系統的不穩定性，因此我們從多個角度切入以期可以達到穩定串
流媒體系統、提供高品質串流媒體內容以及快速零時差的多媒體串流服務。我們必須從
影音串流的編碼、網路串流導流的拓譜建立、Peer-to-Peer 節點的維護三方面同時著手
來達到我們的目標。 
以下為我們到目前為止所進行的相關研究，第二部份為整體系統架構說明，第三部
份為系統特性之說明，第四部份為結論與未來發展。  
6.1. 整體系統架構說明 
 
圖 14 整體系統架構 
串流資料提供者(Video Source)擁有初始的資料(Raw media stream)，將初始資料
 27
b. 維護模型 Maintenance Module： 
節點每個 section 結束後，需要去根據每個父節點所給他的貢獻去做出評分。
評分的來源在我們的方法裡定義了如下標準:包含資料有效的程度，有效頻寬，與串
流資料提供者之間的延遲，及與父節點網路連結之間的震盪程度。經由所提演算法
再加以衡量出最終成績。 
 
c. 資料處理模型 Data Module： 
串流資料提供者:將原本 yuv 的檔案，經由 Video Coding 的編碼，再經由 Channel 
coding 再一次的編碼，最後將壓縮好的串流資料在傳送給節點。 
節點: 接收到一定數量來自父節點的資料後，需要先利用通道編碼解碼出經過
視訊編碼過的資料，接著再做一次通道編碼，才把資料送給下游。由於我們使用的
資料是經過通道編碼，所以是以一段 section 為單位；串流資料提供者會以 section
為單位來壓縮影片，為了讓使用者能夠順暢地播放影片，我們會有一段播放影片的
緩衝區；先以提供者來說，它會先保留兩段 section 的資料後，再進行傳送的動作；
再以傳送端來說，他會根據接受端要求的 section index 來進行傳送資料的動作；最
後是接收端，在預計收完一段 section 資料之若干時間之前，隨即告訴傳送端可以傳
送下一段 section 的資料以增進頻寬使用效率。 
6.2. 系統特性之說明 
一般使用多媒體串流之使用者常常會發生下列情況： 
a. 下載影片的速度跟不上影片播放的速度 
b. 播放影片的品質很差 
我們的系統針對這兩種情況有下列之特性可以減少發生的機會： 
A. 播放/下載之協調機制： 
由於通道編碼是以 section 為單位的特性，我們可以借此來做播放點與下
載點的協調，而在系統中唯一要做協調的是接收端，他會有兩個索引值，播放
點與下載點，播放點是用來控制播放哪一段 section 的資料索引，下載點是用
來控制下載哪一段 section 的資料索引。接收端也是會先保留住兩段 section 的
資料再進行播放的動作，所以當播放點大於下載點時，就是發生影片播放不順
暢的時候，此時接收端本身就需要去更新自己的節點列表，重新連結連線品質
較好的節點。 
 29
   
圖 17 實機展示效果數據 
圖 17 呈現了使用者播放影片順暢之分析數據。這張圖的橫軸是: 時間，縱軸是播
放哪段影片的索引。他的數據是由 10 個 peer 的數據平均而來的。藍色線代表的是 peer
理想的播放速度。紅色線代表的是 peer 正在接收與解碼的 section 索引；而淺綠色線代
表的就是 peer 正在播放的 section 索引，我們可以看到跟理想值相差不遠。因為實驗室
可使用之機器有限，我們讓一台電腦運作３個 peer 個數，全部的 peer 個數大概只有一
兩個 peer 的播放速度會有些許慢，因此我們認為只要在機器上執行有限的 peer，便可確
保每個 peer 順暢地撥放。更多之分析請見子計畫報告書。 
圖 18 是隨機兩個 peer 的程式畫面截圖與程式介面解說。 
 
圖 18 展示用之網路拓樸圖 
6.4. 總結與未來發展 
目前我們已經完成了整個多媒體串流展示系統。在每個獨立的節點中，利用我們所
提出來的架構及演算法，能夠擁有穩定而且順暢的影音播放功能，最後希望藉由這次經
驗能夠在多媒體網路研究上有所貢獻。 
 31
 
MPEG 標準涵蓋的範圍包括系統、視訊、音訊等，而受矚目的世界標準包含 MPEG-2, 
MPEG-4, MPEG-21 等。對於視訊壓縮，Core Experiments on Scalable Video Coding 
Technology 正是目前最熱門的主題之一。在未年兩年的 MPEG 會議將會有更多的公司組
織帶著他們的技術參與 MPEG-4 Part 10 Amd. 4 MVC 視訊標準之制定，以角逐成為
MPEG-4 Part 10 Amd. 4 視訊壓縮技術的標準之工具。另外，VCTR 亦值得視訊硬體設計
廠投入更多的努力。而交通大學團隊亦持續於標準會議中提出貢獻案，這顯示了我國參
與 MPEG 國際標準會議之先進技術的積極態度與研究能力。目前我們規劃將參與 2010
年 MPEG High Performance Video 標準草案競賽。 
 
 
8. 計畫整體成果與自評 
鑑於未來網路結構與應用趨於異質結合，本計畫完成的目標為 --- 設計與實作隨處
可得多媒體系統之相關技術。為期三年計畫中，本年度為第三年。 
本計畫在下述四類領域開發新技術: (1)可調層次式視訊及音訊壓縮技術，(2)多媒體
內容搜尋技術，(3)多媒體智慧財產權保護技術，與(4)媒體串流系統之設計與實作。接
續前幾年的研究，因此本年度內有多篇國內外期刊與學術研討會論文發表，如前一節所
列。 
特別值得一提的是我們持續參與 MPEG 標準會議。這個年度中，本校團隊的兩位老
師蔡淳仁及彭文孝及其博士生，在國科會計畫補助旅費情況下參與 MPEG 標準會議。提
出數件 MPEG 貢獻文件(Contributions)。將我人發展之技術提案至 MPEG 標準組織，有
助我國技術進入國際舞台。目前我們規劃將參與 2010 年 MPEG High Performance Video 
標準草案競賽。 
本計畫更直接並且對工商業更有價值的貢獻將是人才訓練。同學們在學校階段已熟
悉較前瞻的世界標準，畢業後進入產業，直接有助於產業界開發新產品，提昇我國工業
技術能力。 
綜合評估：本計畫產出相當多具有學術與應用價值的成果，並積極參與國際 MPEG
標準會議，將我人研發成果推廣到國際舞台。此外亦達到人才培育之效，整體成效良好。 
 
 33
Processing (CVGIP’09), Nantou, Taiwan, Aug. 2009. 
[19] H.-C. Lin, H.-M. Hang, and W.-H. Peng, “Fast Temporal Prediction Selection for H.264/AVC 
Scalable Video Coding,” IEEE Int’l Conf. on Image Processing (Accepted) 
 
1. Shang-Yu Yeh 葉尚諭, “Coding Efficiency and Quality Improvement for MPEG Surround En-
coding,” MS Thesis, NCTU, June 2008. 
2. Wei-Nien Chen 陳威年, “H.264/AVC Encoder Parallelized Realization on NVIDIA CUDA,” MS 
Thesis, NCTU, June 2008. 
3. Hao-Ting Chu, 朱浩廷, “Design and Implementation of MHP Video and Graphics Accelerators 
on Xilinx ML403 Platform,” MS Thesis, NCTU, August 2007. 
4. Ernie Chu, 朱育成, “Layered Protection of Scalable Media using Perceptual Removable Wa-
termarking,” MS Thesis, NCTU, June 2007. 
5. Chiao-Lin Wu, 吳巧琳, “A Switchable DRM Scheme with Embedded Device Implementation,” 
MS Thesis, NCTU, June 2007. 
6. Chih-Kang Han, 韓志岡, “MPEG Surround Codec Acceleration and Implementation on TI DSP 
Platform,” MS Thesis, NCTU, June 2007. 
7. Chia-Hsien Lu 呂家賢, An Implementation of MPEG-21 IPMP and REL with MPEG-4 IPMPX 
Framework on MPEG-21 Testbed, MS Thesis, NCTU, June 2006. 
8. Min-Hong Chen 陳旻弘, Design and Implementation of a Simple Video and Graphics Subsystem 
of MHP on Xilinx ML310 Platform, MS Thesis, NCTU, June 2006. 
9. Feng-Cheng Chang 張峰誠, Digital Image Retrieval and Scalable Media Protection, Ph.D. Dis-
sertation, NCTU, May 2006 
 
蔡淳仁 
[1] Y.-C. Sun, S.-Y. Lian, and C.-J. Tsai, “Prioritized Side Information Correction for Distributed 
Video Coding,” Proc. of 27th Picture Coding Symposium, Chicago, U.S.A., May 2009. 
[2] Y.-C. Sun and C.-J. Tsai, “Low Complexity Motion Model Analysis for Distributed Video Cod-
ing,” Proc. of Int. Symp. on Multimedia over Wireelss, Crete Island, Creece, Aug. 2008. 
[3] J.-M. Hsiao and C.-J. Tsai, “Analysis of an SoC Architecture for MPEG Reconfigurable Video 
Coding Framework,” Proc. IEEE Intern. Symposium on Circuit and System, New Orleans, May 
2007. 
[4] C.-P. Ho and C.-J. Tsai, “Content-Adaptive Packetization and Streaming of Wavelet Video over IP 
Networks,” EURASIP Journal on Image and Video Processing, Volume 2007, Article ID 45201, 
2007. 
[5] Y.-H. Yu, C.-P. Ho, and C.-J. Tsai, “Multiple Adaptations and Content-Adaptive FEC Using Pa-
rameterized RD Model for Embedded Wavelet Video,” EURASIP Journal on Advances in Signal 
Processing, Accepted, 2007. 
[6] C.-P. Ho and C.-J. Tsai, “Content-Adaptive Packetization and Streaming of Wavelet Video over IP 
Networks,” Proc. of Workshop on Consumer Electronics and Signal Processing (WCEsp) 2006, 
Hsinchu, Taiwan, 2006. 
 
1. 蕭哲民，支援 MPEG 可重組視訊編碼運作模式之系統單晶片架構設計，國立交通大學碩士
論文，2007。 
2. 蔡雅婷，利用方向小波轉換分析進行視訊編碼之位元分配，國立交通大學碩士論文，2007。 
3. 廖珮晴，在異質雙核心平台上設計與分析動態分工的串流播放器，國立交通大學碩士論文，
2008。 
4. 連曉玉，解碼端影像誤差估測用於分散式視訊編碼法校正優先權的設計，國立交通大學碩
士論文，2009。 
 
 
 35
6. H. T. Huang, "A Rate-Distortion Optimization Model for SVC Inter-layer Encoding and Bit-
stream Extraction," Institute of Multimedia Engineering, 2008. 
7. Y. C. Lin, "A Preliminary Study on Adaptive Frame Skipping for Quality- and Rate-Constrained 
Streaming Systems," Institute of Computer Science and Engineering, 2008. 
8. M. C. Chen, "A De-interlacing Algorithm Using Smoothness Constraint for Adaptive Spatiotem-
poral Interpolations," Institute of Computer Science and Engineering, 2008 
 
李素瑛 
[1] Hua-Tsung Chen, Wen-Jiin Tsai and Suh-Yin Lee, "Sports Information Retrieval for Video An-
notation", to appear in International Journal of Digital Library System (JDLS),  1 (1) 04, 2009.  
[2] Hua-Tsung Chen, Wen-Jiin Tsai and Suh-Yin Lee, "Contour-based Strike Zone Shaping and Vi-
sualization in Broadcast Baseball Video: Providing Reference for Pitch Location Positioning 
and Strike/Ball Judgment", Multimedia Tools and Applications (MTAP) July 2009. DOI: 
10.1007/s11042-009-0321-9  
[3] Hua-Tsung Chen, Ming-Chun Tien, Yi-Wen Chen, Wen-Jiin Tsai and Suh-Yin Lee,  "Phys-
ics-based Ball Tracking and 3D Trajectory Reconstruction with Applications to Shooting Loca-
tion Estimation in Basketball Video", Journal of Visual Communication and Image Representa-
tion (JVCI) Volume 20, pp. 204-216, 2009.  
[4] Hua-Tsung Chen, Hsuan-Sheng Chen, Ming-Ho Hsiao, Wen-Jiin Tsai and Suh-Yin Lee (2007), 
"A Trajectory-Based Ball Tracking Framework with Visual Enrichment for Broadcast Baseball 
Videos", Journal of Information Science and Engineering (JISE), Vol. 24, No.1, pp.143-157, Jan 
2008. 
[5] Yi-Wen Chen, Ming-Ho Hsiao, Hua-Tsung Chen, Chi-Yu Liu and Suh-Yin Lee (2008), "Con-
tent-Aware Fast Motion Estimation Algorithm", Journal of Visual Communication and Image 
Representation (JVCI), Volume 19, Issue 4, pp. 256-269, May 2008.  
[6] Ming-Ho Hsiao, Yi-Wen Chen, Hua-Tsung Chen, Kuan-Hung Chou and Suh-Yin Lee (2007), 
"Content-Aware Video Adaptation under Low-Bitrate Constraint", EURASIP Journal on Ad-
vances in Signal Processing (JASP), Volume 2007, Article ID 17179, May 2007.  
[7] Hua-Tsung Chen, Wen-Jiin Tsai and Suh-Yin Lee, "Stance-Based Strike Zone Shaping and Vi-
sualization in Broadcast Baseball Video: Providing Reference for Pitch Location Positioning," 
in Proc. of IEEE International Conference on Multimedia and Expo 2009 (ICME 2009), 
pp.302-305. 
[8] Hui-Zhen Gu, Yung-Wei Kao, Suh-Yin Lee, and Shyan-Ming Yuan, “HVPN: The combination 
of horizontal and vertical pose normalization for face recognition,” International Conference on 
Multimedia Modeling, pp. 367-378, 2009. 
[9] Hua-Tsung Chen, Ming-Ho Hsiao, Hsuan-Shen Chen, Wen-Jiin Tsai and Suh-Yin Lee, "A 
Baseball Exploration System using Spatial Pattern Recognition," in Proc. of IEEE International 
Symposium on Circuits and Systems 2008 (ISCAS 2008), pp. 3522-3525.  
[10] Hui-Zhen Gu , Yung-Wei Kao , Suh-Yin Lee and Shyan-Ming Yuan, “Automatic Morphing for 
Face Recognition,” in proc. The Tenth World Conference on Integrated Design & Process 
Technology, vol. 5371/2008 pp. 367-378.  
[11] Hua-Tsung Chen, Ming-Ho Hsiao, Wen-Jiin Tsai, Suh-Yin Lee and Jen-Yu Yu, "A Tempo Anal-
ysis System for Automatic Music Accompaniment," in Proc. of IEEE International Conference 
on Multimedia and Expo 2007 (ICME 2007), pp.64-67. 
[12] Hsuan-Sheng Chen, Hua-Tsung Chen, Wen-Jiin Tsai, Suh-Yin Lee and Jen-Yu Yu, 
"Pitch-By-Pitch Extraction from Single View Baseball Video Sequences," in Proc. of IEEE In-
ternational Conference on Multimedia and Expo 2007 (ICME 2007), pp. 1423-1426. 
[13] Hua-Tsung Chen, Hsuan-Shen Chen and Suh-Yin Lee, "Physics-based Ball Tracking in Volley-
ball Videos with Its Applications to Set Type Recognition and Action Detection," in Proc. of 
IEEE International Conference on Acoustics, Speech, and Signal Processing 2007 (ICASSP 
2007), pp. I-1097-I-1100. 
[14] Min-Chun Tien, Hua-Tsung Chen, Yi-Wen Chen, Ming-Ho Hsiao and Suh-Yin Lee, "Shot Clas-
sification of Basketball Videos and Its Applications in Shooting Position Extraction," in Proc. of 
IEEE International Conference on Acoustics, Speech, and Signal Processing 2007 (ICASSP 
1 
 
出席 2008 年 10 月 MPEG 國際標準會議報告 
杭學鳴 
國立交通大學電子工程系 
蔡淳仁、彭文孝 
國立交通大學資訊工程系 
 
一、前言 
 
    西元 2008 年 ISO/IEC JTC 1/SC 29/WG 11 MPEG (Moving Picture Experts 
Group)主辦的第八十六屆國際標準會議（86th ISO/IEC JTC 1/SC 29 WG1 & WG 11 
meetings）在 2008 年 10 月 13 日至 10 月 17 日於韓國釜山(Busan, Korea)舉辦而
第二十九屆的 Joint Video Team meeting 則同樣在 2008 年 10 月 12 日至 10 月 17
日於韓國釜山(Busan, Korea)舉行。本次MPEG會議共有 218 貢獻案(Contributions)
而 JVT 會議則有 14 件貢獻案。這次交通大學團隊共有一位碩士生(陳俊吉)，加
上晨星半導體一位研究員(童怡新)和成功大學一位教授(李國君)與兩位碩士生
(陳柏翰、鄭淵隆)。這次主要之目的是(1) 參加 Free-view Point Television (FTV)
的討論，(2)參與 FTV EE1~4 文件之修訂，(3)以及發表 Reconfigurable Video 
Coding(RVC)之相關技術。 
 
二、出席會議經過 
    
FTV 分組會議在 10 月 12 日開始，為期 7 天。在分組會議中主要的議題包括 
(1)審查前次會期 EEs 的結果 
(2)審查本次會期的貢獻案 
(3)討論貢獻案的成果表現 
(4)討論 VSRS1.1、DERS1.1 的文件和軟體 
(5)討論 FTV Applications and Requirements 
(6)建立下次會期的 EEs 
 
本次 MPEG-FTV 分組會議，總共有約 22 個提案。其中有 6 件提案為技術文
件，僅有 16 件回應前次會期所丟出的 EEs 文件。由於 FTV 屬新興議題，大部分
的提案專注在回應 EEs 文件制定的內容，並持續改進現有的參考軟體。因此關於
提案的程式演算法部分的討論狀況並不熱烈。 
 
首先討論的是上次會期 FTV EEs 的結果。其中包含 
(1) EE1: Subpel & temporal consistency 
(2) EE2: View Synthesis Based on Disparity (ViSBD) 
3 
 
出席 2009 年 4 月 MPEG 國際標準會議報告 
杭學鳴 
國立交通大學電子工程系 
蔡淳仁、彭文孝 
國立交通大學資訊工程系 
 
一、前言 
 
西元 2009 年 ISO/IEC JTC 1/SC 29/WG 11 MPEG (Moving Picture Experts 
Group) 主辦的第八十八屆國際標準會議（88th ISO/IEC JTC 1/SC 29 WG1 & WG 
11 meetings）在今年 4 月 20 日至 24 日於美國的 Maui 舉行。在一般會議前一天
（4 月 19 日）有一系列的分組會議（AHG group meeting）。本次會議共有 258
貢獻案(Contributions)。這次交通大學團隊共有兩位教授(蔡淳仁、彭文孝)，加上
台灣大學一位兼任教授(童怡新)和成功大學一位教授(李國君)出席。這次主要之
目的是參加 MPEG 最新的  Video 標準工作項目：High Performance Video 
Codec(HVC)的討論。目前 HVC 尚在 Call-for-Evidence(CfE)的前置工作階段，必
須要等下次會議的 CfE 結果出來之後，才能確定是不是要發出公開的
Call-for-Proposal (CfP)，以進行新標準的制訂。 
  
二、本次會議討論項目 
    
以下就針對幾個 MPEG 正在進行中、可能對業界有實質影響的工作項目進
行說明。 
首先，在 HVC 方面，這次的討論主要是集中在跟 ITU-T 的合作關係。因為
過去 ISO 和 ITU-T 在制訂 AVC/H.264 的過程中，合作的並不順利，因此在前一
次的會議中，MPEG 就考慮要中止兩邊合作的團隊 JVT。但是目前 ITU-T 的子
單位 VCEG 也打算制訂一個新的高畫質視訊編碼標準：Next Generation Video 
Coding (NGVC)，如果 ISO 和 ITU-T 各行其事，產生兩套效能雷同但並不相容
的標準，對業界將是一大困擾。因此在這次的會議中，關於 HVC 的討論有很多
是在於要如何跟 ITU-T 商談合作方式，才能避免過去在訂定 AVC 時所犯的錯。 
至於在 HVC 技術方面的貢獻案，多是延續之前會議的結果，並無創新的提
案出現。主要是在分析加大 macroblock 的大小(最大到 64x64) 對編碼效能的提
升。另一個技術相關的討論，是關於 PSNR 的替代方案。PSNR 是用來測量畫質
的客觀估算質。但是當 PSNR 用在高畫質的視訊資料時，往往不能真實反應出人
眼視覺的印象。因此在會議過程中，有相當長的討論想要找一個比較好的客觀畫
質測量度量。不過最後的結論還是目前沒有明顯比 PSNR 好的方法。最後，Y. A. 
Rezink 有一個相當不錯的貢獻文件，分析過去的視訊編碼法在 transform coding
5 
 
iv. S. Sekiquchi, et al., “Additional coding performance evaluation of 
extended MB size,” MPEG input document M16473, Maui Meeting, 
Apr. 2009. 
 
乙、MMT 
i. C. Timmerer, et al., ”On MPEG Modern Transport over Networks,” 
MPEG input document M16307, Maui Meeting, Apr. 2009. 
ii. David Singer, “On Modern Media Transport (MMT),” MPEG input 
document M16362, Maui Meeting, Apr. 2009. 
丙、AIT 
i. M. Choi, et al., “Use Cases for Advanced IPTV Terminals,” MPEG 
input document M16288, Maui Meeting, Apr. 2009. 
ii. C. Timmerer, et al., “Input on the Advanced IPTV Terminal (AIT) 
Architecture,” MPEG input document M16313, Maui Meeting, Apr. 
2009. 
 
丁、MPEG-V 
i. M. Waltl, et al., “An API for Sensory Effect Metadata compliant to the 
MPEG Extensible Middleware (MXM),” MPEG input document 
M16301, Maui Meeting, Apr. 2009. 
ii. J. Gelissen, “MPEG-V WD Contributions,” MPEG input document 
M16336, Maui Meeting, Apr. 2009. 
iii. Y. Tokumo, et al., “Study on MPEG-V Sensory Information,” MPEG 
input document M16358, Maui Meeting, Apr. 2009. 
 
  
 
7 
 
 Expansion of Block Transform Sizes 
 Adaptive Loop Filter 
 Increment of internal bit-depth 
 High Precision Interpolation Filter 
 Adaptive Interpolation Filter 
 
此次主觀測試強調不公開比較各提案的優劣，只公布具有最佳效果的提案的
結果，但此結果關乎是否發出 CfP 的需求，所以引起所有人的熱烈討論。測試結
果，大家一致認為以現存的技術是具有足夠的可能性去發展新一代的標準，因此
在會議後期，初步制定出 CfP 的測試條件，但由於時間過於緊湊，正式的 CfP
文件將會在下次會期確定並於會議結束後發出。 
在討論到 HVC 是否循著開發 H.264/AVC 時的模式和 VCEG 合作的問題時，
引起許多人對彼此合作模式的看法，蔡淳仁教授也發表了一個在 JVT 合作階段
所引發的問題以供警惕。在經過熱烈的爭辯之後，MPEG 最後還是和決定和
VCEG合作一起開發 HVC，同時也將會在下次會議後正式發出 HVC 的 CfP 文件。 
 
三、攜回資料 
無。所有會議相關之資料與檔案皆可以在 MPEG 和 JVT 的網頁中取得。 
http://mpeg.nist.gov 
http://ftp3.itu.int/av-arch/jvt-site 
 
四、參考文獻 
 
 
 
 
