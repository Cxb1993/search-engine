海洋放牧已成為目前普遍被採用的方式之
一。 
由於海上箱網養殖所放養的魚類大多
具有高經濟價值，例如海鱺、龍膽石斑(或
他種石斑)、嘉臘、黑鯛…等高經濟魚類；
且箱網養殖平台均是放置在大海中，漁民則
是需要搭工作船前往養殖平台進行相關的
養殖作業，所以平時並不會有人會在養殖平
台上看守。由於海上箱網養殖具有上述先天
的屬性，所以常常發生箱網養殖中的魚類被
偷竊而造成漁民重大的經濟損失。因此，箱
網養殖的安全性已成為發展海上箱網養殖
及其普及化的一個重要的問題。 
目前使用在箱網養殖的監控系統為數
位 式 監 視 系 統 (Digital Video Recorder, 
DVR)，它雖可改善掉類比式監視系統
(Video Cassette Recorder, VCR)的缺點且具
有遠端監控的優點，且無法避免掉監視人員
24 小時長時間的工作。所以，本計畫提出
了智慧型 DVR 箱網養殖監控系統來達到漁
船的主動偵測、追蹤及入侵物的偵測與發佈
警報的目的。如此便可大大降低監視人員的
工作負荷及提升箱網監控的安全性。 
 
三、研究方法 
在漁船的偵測及追蹤方面，本研究先利
用前 N 張 frames 及中位數法來快速建立初
始的背景影像 )，其中 、
和 為背景影像中像素點 的 RGB 
components ，且 、 和 分別為 
、 及
的中位數值。 
,,( mememe BGRB meR meG
meB ),( yx
meR meG meB
},,,{ 21 NRRR K },,,{ 21 NGGG K },,,{ 21 NBBB K
由於海浪的變動會影像移動物的偵測
結果，所以我們提出了一植基於掃瞄視窗內
最 小 差 值 的 背 景 相 減 法 (background 
subtraction based on the minimum difference 
within the scanning window)，其公式定義如
下，其中 為 掃瞄視窗的區間。 WS kk ×
)','(),(minarg),(
)','(
yxByxIyxD ttSyxt W
−= ∈  (1) 
在背景更新上，我們則是使用了一植基
於改良式學習函數的歷史圖法來更新背
景，其公式如式子(2)所示，該方法改善了
Fahn and Sung 等人所提出的植基於學習函
數的歷史圖法[9]，大大降低因海浪變動所造
成的高頻繁的背景更新問題。 
⎩⎨
⎧
<−
≥+=
TyxDyxh
TyxDyxh
yxh
tt
tt
t ),( if ,W),(
),( if ,A),(
),(  (2) 
一旦移動物被成功偵測出來後，接著採
用 optimal multi-level thresholding [10]來獲
得二值化影像。接著，我們提出了一快速四
連通法(fast 4-connected-component labeling)
來大大降低傳統四連通法的運算時間；以一
張 240320× 大小的影像為例，傳統四連統需
花費約 265 ms，而快速四連通法則只需要 4 
ms。此外，此快速四連通法亦具有去雜訊的
能力(noise filtering)。 
在本研究中，我們也提出了一個二階段
的浪花去除法；在執行浪花去除之前，我們
則 是 先 採 用 Carmona 等 人 所 提 出
angle-module rule [11]來移除移動物中的陰
影。在浪花去除的第一階段方法是參考植基
於顏色一致式定理(color constancy principle)
的陰影去除法[12]所提出的改良法；在此階
段 方 法 中 採 用 了 亮 度 扭 曲 (brightness 
distortion)及彩度扭曲(chromatic distortion)
來獲得浪花侯選點，亮度扭曲及彩度扭曲的
定義如公式(3)及(4)所示。圖 1 則為它們的
示意圖。 
),(
),(
),(),(),( yxBCK
yxBCK
yxBCKyxIyxHr −⋅=δ  (3) 
⎟⎟⎠
⎞
⎜⎜⎝
⎛
×
⋅= −
),(),(
),(),(cos),( 1
yxBCKyxI
yxBCKyxIyxCrδ  (4) 
 
   
       (a)                 (b) 
圖 1. 亮度扭曲及彩度扭曲的示意圖。(a)亮
度扭曲，(b)彩度扭曲。 
 
一個像素點若滿足以下式子(5)及(6)兩
條件的話，即將其歸類為浪花侯選點。式子
(5)及(6)的定義範圍便是一圓錐浪花體。 
21 ),(0 τδτ ≤≤< yxHr  (5) 
21 ),( θδθ << yxCr  (6) 
 
 
 2
 
       (c)                  (d) 
 
       (e)                  (f) 
圖 4. 不同影格區間下的浪花偵測結果。(a)
原始影像，(b)影格區間為 1，(c)影格區間為
2，(d)影格區間為 3，(e)影格區間為 5，(f)
影格區間為 10。 
 
第三個實驗模擬則是驗證本研究所提
出的漁船追蹤方法具有多漁船、重疊且大小
改變的追蹤效能，其模擬結果如圖 5 所示。 
 
 
       (a)                  (b) 
 
       (c)                  (d) 
 
(e) (f) 
圖 5. 多漁船追蹤結果。(a)第 k 影格，(b)第
(k+304)影格，(c)第(k+426)影格，(d)第(k+500)
影格，(e)第(k+600)影格，(f)第(k+700)影格。 
 
最後一個實驗則是模擬本研究所提出
的智慧型 DVR 箱網養殖監控系統的完整執
行結果；圖 6(a)為漁船偵測結果，圖 6(b)是
執行漁船追蹤，圖 6(c)則發現入侵物並發佈
警報給監控人員。測試的漁船視訊的影像大
小為 150200× ，整個測試的執行時間為平均
每張影格是 35 ms。 
 
 
(a) 
 
(b) 
 
(c) 
圖 6. 智慧型 DVR 箱網養殖監控系統執行
結果。(a)漁船偵測，(b)漁船追蹤，(c)入侵
物偵測及發佈警報。 
 
所以，本研究所提出的智慧型 DVR 箱
網養殖監控系統能達到漁船的主動偵測、追
蹤及入侵物的偵測與發佈警報的目的。因此
可大大降低監視人員的工作負荷及提升箱
網監控的安全性。故能有效地促進箱網養殖
的普及性。 
 
 4
 6
wave ripple removing,” Proceedings of 
the 22th Conference on Computer Vision, 
Graphics and Image Processing, pp. 
1638-1643, Nantou, Taiwan, 2009. 
[16] W.C. Hu, Y.J. Kuo and P.K. Chen, 
“Multi-intruder tracking and classification 
of visual surveillance in net cage system,” 
Proceedings of 2008 International 
Conference on Advanced Information 
Technologies, Taichung, Taiwan, 2008. 
 
附錄 
(請見下頁) 
∑∑
= =
+ −++
×
=
W
i
H
j
kk jifyjxifHW
yxMAD
0 0
1 ),(),(
1),(  (1) 
, where vector ),( yx  is the candidate motion vector, 
and ),( ⋅⋅kf  and ),(1 ⋅⋅+kf  refer to the template image 
block in the current frame and tested image block 
within the search region. 
The TSS algorithm is summarized as follows. The 
99×  square pattern is used and nine checking points 
are compared, including the center point of the pattern 
and eight checking points on the bounding of the 
pattern. The distance between a checking point and its 
neighbor checking point is 4 pixels. The search center 
is then moved to the checking point with minimum 
MAD. Next, the search pattern is switched from 99×  
square pattern to 55×  square pattern, and nine 
checking points are compared, including the center 
point of the pattern and eight checking points on the 
bounding of the pattern. The distance between a 
checking point and its neighbor checking point is 2 
pixels. The search center is then moved to the checking 
point with minimum MAD. Finally, the search pattern 
is switched from 55×  square pattern to 33×  square 
pattern. Find a checking point with minimum MAD as 
the best motion vector from these nine checking points. 
In contrast to the TSS algorithm, the FSS 
algorithm uses a smaller search pattern ( 55×  square 
pattern) in the first step. The FSS algorithm is 
summarized as follows. The first step examines nine 
checking points to find the one with the minimum 
MAD as new search center in the next step. The search 
pattern is varied according to the searching results. If 
the checking point with the minimum MAD 
corresponds to an edge point or a corner, the 55×  
search pattern is remained and the above process is 
repeated; whereas if the checking point with the 
minimum MAD is located at the center of the search 
pattern, the search pattern is switched from 55×  
square pattern to 33×  square pattern. Find a checking 
point with minimum MAD as the best motion vector 
from these nine checking points. 
The BBGDS algorithm relies on the assumption 
of center-based motion. The 33×  square pattern is 
used in the BBGDS algorithm. The BBGDS algorithm 
is summarized as follows. The first step examines nine 
checking points to find the one with the minimum 
MAD as new search center in the next step. If the 
checking point with the minimum MAD corresponds 
to an edge point or a corner, the above process is 
repeated; whereas if the checking point with the 
minimum MAD is located at the center of the search 
pattern, stop and the best motion vector is found. 
Two different search patterns are used in the DS 
algorithm, called as large diamond search pattern 
(LDSP) and small diamond search pattern (SDSP) [5]. 
The DS algorithm is summarized as follows. The first 
step examines nine checking points of LDSP to find 
the one with the minimum MAD as new search center 
in the next step. The search pattern is varied according 
to the searching results. If the checking point with the 
minimum MAD corresponds to an edge point or a 
corner, the LDSP is remained and the above process is 
repeated; whereas if the checking point with the 
minimum MAD is located at the center of the search 
pattern, the search pattern is switched from the LDSP 
to the SDSP. Find a checking point with minimum 
MAD as the best motion vector from these five 
checking points. 
A novel algorithm is suggested to challenge the 
DS algorithm, called the HEXBS algorithm. Two 
different search patterns are used in the HEXBS 
algorithm, called as large HEXBS pattern and small 
HEXBS pattern [6]. The HEXBS algorithm is 
summarized as follows. The first step examines nine 
checking points of large HEXBS pattern to find the 
one with the minimum MAD as new search center in 
the next step. The search pattern is varied according to 
the searching results. If the checking point with the 
minimum MAD corresponds to an edge point or a 
corner, the large HEXBS pattern is remained and the 
above process is repeated; whereas if the checking 
point with the minimum MAD is located at the center 
of the search pattern, the search pattern is switched 
from the large HEXBS pattern to the small HEXBS 
pattern. Find a checking point with minimum MAD as 
the best motion vector from these five checking points. 
Using these typical block-matching algorithms, 
the minimum search number of checking points for 
finding the best motion vector is 25, 17, 9, 13, and 11 
of TSS, FSS, BBGDS, DS, and HEXBS, respectively. 
 
3. Proposed adaptive template block 
 
 The proposed adaptive template block is built on 
the area ratio of the moving object in the successive 
frames. The proposed adaptive template block is 
described as follows. Suppose the width and height of 
the template image block in the k frame are W  and H , 
respectively. First, the search region RS  in the 1+k  
frame is obtained from the template image block in the 
k frame using equation (2).  
HWSR βα +=  (2) 
 Next, the background subtraction is used in the 
region RS  and the corresponding region of background 
image. Furthermore, schemes of the median filter, the 
62
Table 1. The performance of typical block-
matching algorithms with the fixed template 
block 
 
maxerr  aveerr  maxA  aveA  maxN  aveN  
TSS 8.75 5.41 1364 783.5 25 25 
FSS 9.39 5.30 1364 783.5 25 22.1 
BBGDS 9.39 5.30 1364 783.5 27 20.3 
DS 9.39 5.32 1364 783.5 21 19.4 
HEXBS 10.55 6.47 1364 783.5 17 14.9 
 
Table 2. The performance of typical block-
matching algorithms with the proposed 
adaptive template block 
 
maxerr  aveerr  maxA  aveA  maxN  aveN  
TSS 4.71 2.65 320 93.6 25 25 
FSS 5.12 3.02 320 92.0 25 22.2 
BBGDS 4.71 3.14 233 74.5 27 20.3 
DS 4.63 3.00 320 92.3 21 19.6 
HEXBS 6.81 4.10 320 97.1 17 15.0 
 
 Furthermore, using the proposed adaptive template 
block, the suitable bounding box of moving object 
would be obtained. The suitable bounding box of 
moving object would be useful for object recognition. 
For instance, Fig. 3(a) and Fig. 3(b) are the results of 
object tracking (in the 1+k  frame and 60+k  frame) 
using the DS algorithm with the fixed template block 
and the proposed template block, respectively. 
 
   
(a) 
   
(b) 
Fig. 3. The result of object tracking using the 
DS algorithm 
 
5. Conclusion 
 
 In this paper, the adaptive template block-based 
block matching is proposed successfully. The proposed 
adaptive template block is built on the area ratio of the 
moving object in the successive frames. The template 
block of block-matching algorithm would be adjusted 
to the moving object with different scales while the 
object moves from near to far or from far to near. 
Therefore, the block-matching algorithms with the 
proposed adaptive template block would obtain 
accurate and reliable object tracking while the moving 
object with different scales. 
 Experimental results demonstrate that the block-
matching algorithms with the proposed adaptive 
template block has better performance than ones with 
the fixed template block in the matching-center error, 
the matching-area error. Furthermore, using the 
proposed adaptive template block, the suitable 
bounding box of moving object would be obtained and 
it is very useful for pattern recognition. Therefore, the 
proposed adaptive template block-based block 
matching is very suitable for fast object tracking in 
visual surveillance. 
 
Acknowledgement—The author wish to express his 
appreciation to Mr. Yu-Jen Kuo for his help with the 
experiments. 
 
6. References 
[1] W. Hu, T. Tan, L. Wang, and S. Maybank, “A survey on 
visual surveillance of object motion and behavior”, IEEE 
Transactions on Systems, Man, and Cybernetics—Part C: 
Applications and Reviews, Vol. 34, No. 3, 2004, pp. 334-352. 
[2] R. Li, B. Zeng, and M.L. Liou, “A new three-step search 
algorithm for block motion estimation”, IEEE Transactions 
on Circuits and System for Video Technology, Vol. 4, 1994, 
pp. 433-442. 
[3] L.M. Po, and W.C. Ma, “A novel four-step search 
algorithm for fast block motion estimation”, IEEE 
Transactions on Circuits and System for Video Technology, 
Vol. 6, 1996, pp. 313-317. 
[4] L.K. Liu, and E. Feig, “A block-based gradient descent 
search algorithm for block motion estimation in video 
coding”, IEEE Transactions on  Circuits and Systems for 
Video Technology, Vol. 6, No. 4, 1996, pp. 419-422. 
[5] S. Zhu, and K.K. Ma, “A new diamond search algorithm 
for fast block-matching motion estimation”, IEEE 
Transactions on Image Processing, Vol. 9, No. 2, 2000, pp. 
287-290. 
[6] C. Z. Xiao and L. P. Chau, “Hexagon-based search 
pattern for fast block motion estimation”, IEEE Transactions 
on  Circuits and Systems for Video Technology, Vol. 12, No. 
5, 2002, pp. 349-355. 
64
subtraction, they are detected as moving objects. 
Therefore, they must be removed from moving objects. 
The concept of shadow detection [23], smoke 
detection [24], and fire detection [25] is worthy to refer 
in wave ripple detection. However, due to color of the 
wave ripple and ship being alike, wave ripple detection 
is more difficult than shadow detection, smoke 
detection, or fire detection. 
In this paper, we propose a two-stage scheme to 
obtain wave ripple detection. In the first stage scheme, 
we use the brightness distortion and chromatic 
distortion to obtain wave ripple candidates. Next, 
brightness variation is used to detect wave ripple form 
these candidates in the second stage scheme. 
Experimental results show that ship tracking with 
proposed wave ripple removing has good performance. 
The rest of this paper is organized as follows. A 
review of the improved full search block-matching 
algorithm is presented in Section 2. The proposed wave 
ripple removing is described in Section 3. Section 4 
presents experimental examples and evaluations of the 
results. Finally, conclusion is given in Section 5. 
 
2. REVIEW OF IMPROVED FULL SEARCH 
BLOCK-MATCHING ALGORITHM 
 
In this section, a review of the improved full search 
block-matching algorithm is described. The improved 
full search block-matching algorithm finds the best 
matching block among all the possible search positions 
in the modified search region. The modified search 
region is obtained using a coarse-to-fine scheme to find 
the minimum bounding box of possible moving object.  
The coarse-to-fine scheme is as follows. First, the 
coarse search region  is defined in equation (1), 
where  and 
RS
W H  are the width and height of the 
template image block, respectively, as shown in Fig. 2. 
                            HWSR βα +=  (1) 
 
 
                  (a)                                         (b) 
Fig. 2. Search region definition. (a) Template image 
block; (b) coarse search region. 
 
Next, the background subtraction is used in the 
region  and the corresponding region of background 
image. Furthermore, median filter, shadow removal, 
binary image, opening operation of morphological 
processing, and connected components labeling 
schemes are performed to obtain the possible regions of 
moving object, the fine search region , where the 
small region is removed if the area of the isolated region 
is smaller than the threshold  in the connected 
components labeling. In Fig. 3(b), the outer bounding 
box (blue) is the coarse search region , and the inner 
bounding box (red) is the fine search region . 
RS
RS ′
cT
RS
RS ′
 
 
                  (a)                                         (b) 
Fig. 3. Bounding box of possible moving object. 
                 (a) Original image; (b) fine search region. 
 
Finally, using equations (2) and (3), the best motion 
vector is found using the mean absolute distortion 
(MAD) by testing all the candidate blocks in the fine 
search region RS ′ , where vector  is the candidate 
motion vector, 
),( yx
),( ⋅⋅kf  and  refer to the template 
image block in the current frame and tested image block 
within the search region. Furthermore, the four 
conditions (checking the widths and heights of the 
template image and 
),(1 ⋅⋅+kf
RS ′ ) are used in the block-matching 
procedure to obtain accurate ship tracking. 
             ),(minarg),(
),(
yxMADyx
RSyx
bestbest ′∈=  (2) 
∑∑
= =
+ −++×=
W
i
H
j
kk jifyjxifHW
yxMAD
0 0
1 ),(),(
1),(  (3) 
The improved full search block-matching algorithm 
can greatly reduce the computational cost for obtaining 
the optimal result of motion estimation. The obtained 
results are similar to those obtained using the FS 
algorithm. 
 
3. WAVE RIPPLE REMOVING SCHEME 
 
The proposed wave ripple removing is a two-stage 
scheme. In the first stage scheme, the brightness 
distortion and chromatic distortion are used to obtain 
wave ripple candidates. The second stage scheme uses 
brightness variation to detect wave ripple form these 
candidates. 
The first stage scheme is the modified method of 
shadow elimination model based on the color constancy 
principle [26]. In the brightness distortion, we suppose 
that [ ]),(),,(),,(),( yxIyxIyxIyxI BGR=  and [ ]),(),,(),,(),( yxBCKyxBCKyxBCKyxBCK BGR=  
are the RGB components of the pixel  in the 
current image and background image, respectively. The 
brightness distortion 
),( yx
),( yxHrδ  is defined in equation (4) 
that is the difference between  and , ),( yxI ′ ),( yxBCK
thresholds , 100=cT 351 =τ , 1952 =τ , rad 1.01 =θ , 
rad 0.32 =θ  and  were set by experience. 6=Th
The first example was used to evaluate the 
robustness of the proposed method under varying 
illumination. Fig. 8 is the wave ripple detection under 
varying illumination, where Figs. 8(a)~8(c) are the 
cases of normal illumination, light illumination, and 
dark illumination, respectively. Left images of Figs. 
8(a)~8(c) are original images and right images of Figs. 
8(a)~8(c) are the wave ripple detection, where wave 
ripple is marked with red color and blue bounding box 
is the selected region for detecting wave ripple. Most 
wave ripple under varying illumination was detected 
using the proposed method. 
 
 
(a) 
 
(b) 
 
(c) 
Fig. 8. Wave ripple detection under varying 
illumination. (a) Normal illumination; (b) light 
illumination;   (c) dark illumination. 
 
Next, the stability of wave ripple detection under 
different interval of frames was estimated. Fig. 9(a) is 
the k frame in the ship sequence with 30 fps. Figs. 
9(b)~9(f) are the wave ripple detection under interval of 
1 frame, 2 frames, 3 frames, 5 frames, and 10 frames, 
respectively, where wave ripple is marked with red 
color and blue bounding box is the selected region for 
detecting wave ripple. In the brightness variation, 
, , , , and  were set in 
equation (8) under interval of 1 frame, 2 frames, 3 
frames, 5 frames, and 10 frames, respectively. Most 
wave ripple under different interval of frames was 
detected using the proposed method. 
30=n 15=n 10=n 6=n 3=n
 
 
                  (a)                                         (b) 
 
                  (c)                                         (d) 
 
                  (e)                                         (f) 
Fig. 9 Wave ripple detection under different interval of 
frames. (a) k frame; (b) interval of 1 frame; (c) 
interval of 2 frames; (d) interval of 3 frames; (e) 
interval of 5 frames; (f) interval of 10 frames. 
 
In ship tracking, a ship sequence with 30 fps was 
tested. The frame in the tested ship sequence is in BMP 
image format with a size of  pixels. Only the 
frames from the 106 frame to the 160 frame were 
selected to evaluate the performance of ship tracking 
using the improved full search block-matching 
algorithm with the proposed wave ripple removing. Fig. 
10 is the MAD (mean absolute distortion) search no. 
using the improved full search block-matching 
algorithm with/without the proposed wave ripple 
removing, where the template image of the ship is 
manually obtained in the 105 frame.  
150200×
The maximum, minimum, and average of MAD 
search no. using the improved full search block-
matching algorithm without wave ripple removing are 
28, 5, and 25.3, respectively. And, the maximum, 
minimum, and average of MAD search no. using the 
improved full search block-matching algorithm with the 
proposed wave ripple removing are 14, 1, and 4.9, 
respectively. Compared with the average of MAD 
search no., the MAD search no. using the proposed 
method is 19.5% of that obtained without wave ripple 
removing. Therefore, using the proposed method can 
greatly increase efficiency of ship tracking based on the 
improved full search block-matching algorithm. 
Furthermore, Fig. 11 is the result of ship tracking 
using the improved full search block-matching 
algorithm with the proposed wave ripple removing, 
surveillance,” Proceedings of the Second International 
Conference on Innovative Computing, Information and 
Control, Kumamoto, Japan, 2007. 
[7] H. Septian, J. Tao, and Y.P. Tan, “People counting by 
video segmentation and tracking,” Proceedings of 9th 
International Conference on Control, Automation, Robotics 
and Vision, pp. 1-4, 2006. 
[8] W.C. Hu, H.H. Hung, J.F. Hsu, C.N. Tseng, and H.T. Liu, 
“Back-Propagation neural network-based ship counting and 
trajectory classification for seaport video surveillance,” 
Proceedings of the 8th Conference on Information Technology 
and Applications in Outlying Islands (ITAOI2009), Kinmen, 
Taiwan, pp. 539-543, 2009. 
[9] T.Y. Chen, W.S. Chen, T.H. Chen, Y.C. Chang, D.J. 
Wang, “Ship-flow analysis and counting system based on 
image processing,” Proceedings of the Fourth International 
Conference on Intelligent Information Hiding and Multimedia 
Signal Processing, Harbin, China, pp. 655-658, 2008. 
[10] Q. Luo, T.M. Khoshgoftaar, A. Folleco, “Classification 
of ships in surveillance video,” Proceedings of the IEEE 
International Conference on Information Reuse and 
Integration, pp. 432-437, 2006. 
[11] F. Robert-Inacio, A. Raybaud, and É. Clément, 
“Multispectral target detection and tracking for seaport video 
surveillance,” Proceedings of the Image and Vision 
Computing New Zealand 2007, pp. 169-174, 2007. 
[12] W.C. Hu, C.Y. Yang, and Y.J. Kuo, “An improved full 
search block-matching algorithm based on modified search 
region for fast object tracking,” Proceedings of the 21th 
Conference on Computer Vision, Graphics and Image 
Processing (CVGIP2008), Yilan, Taiwan, 2008. 
[13] W.C. Hu, Y.J. Kuo, and P.K. Chen, “Multi-intruder 
tracking and classification of visual surveillance in net cage 
system,” Proceedings of 2008 International Conference on 
Advanced Information Technologies, Taichung, Taiwan, 2008. 
[14] W.C. Hu, C.Y. Su, C.C. Chuang, and C.W. Huang, 
“Intelligent visual surveillance in net cage,” Proceedings of 
the 20th Conference on Computer Vision, Graphics and Image 
Processing (CVGIP2007), pp. 158-164, Miaoli, Taiwan, 2007. 
[15] W. Hu, T. Tan, L. Wang, and S. Maybank, “A survey on 
visual surveillance of object motion and behavior,” IEEE 
Transactions on Systems, Man, and Cybernetics—Part C: 
Applications and Reviews, Vol. 34, No. 3, pp. 334-352, 2004. 
[16] K.R. Rao, and J.J. Hwang, Techniques and standards for 
image, video and audio coding, Prentice Hall, 1996. 
[17] R. Li, B. Zeng, and M.L. Liou, “A new three-step search 
algorithm for block motion estimation,” IEEE Transactions on 
Circuits and System for Video Technology, Vol. 4, pp. 433-
442, 1994. 
[18] L.M. Po, and W.C. Ma, “A novel four-step search 
algorithm for fast block motion estimation,” IEEE 
Transactions on Circuits and System for Video Technology, 
Vol. 6, pp. 313-317, 1996. 
[19] L.K. Liu, and E. Feig, “A block-based gradient descent 
search algorithm for block motion estimation in video 
coding,” IEEE Trans. Circuits and Systems for Video 
Technology, Vol. 6, No. 4, pp. 419-422, 1996. 
[20] S. Zhu, and K.K. Ma, “A new diamond search algorithm 
for fast block-matching motion estimation,” IEEE Trans. 
Image Processing, Vol. 9, No. 2, pp. 287-290, 2000. 
[21] C. Z. Xiao and L. P. Chau, “Hexagon-based search 
pattern for fast block motion estimation,” IEEE Trans. 
Circuits and Systems for Video Technology, Vol. 12, No. 5, pp. 
349-355, 2002. 
[22] S.Y. Huang, C.Y. Cho, and J.S. Wang, “Adaptive fast 
block-matching algorithm by switching search patterns for 
sequences with wide-range motion content,” IEEE Trans. 
Circuits and Systems for Video Technology, Vol. 15, No. 11, 
pp. 1373-1384, 2005. 
[23] A. Prati, I. Mikic, M.M. Trivedi, and R. Cucchiara, 
“Detecting moving shadows: algorithms and evaluation,” 
IEEE Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 25, No. 7, pp. 918-923, 2003. 
[24] F. Yuan, “A fast accumulative motion orientation model 
based on integral image for video smoke detection,” Pattern 
Recognition Letters, Vol.29, No.7, pp. 925-932, 2008. 
[25] T. Celik, H. Demirel, H. Ozkaramanli, and M. Uyguroglu, 
“Fire detection using statistical color model in video 
sequences,” Journal of Visual Communication and Image 
Representation, Vol. 18, No. 2, pp. 176-185, 2007. 
[26] M. Dahmane, and J. Meunier, “Real-time video 
surveillance with self-organizing maps,” Proceedings of the 
2nd Canadian Conference on Computer and Robot Vision, pp. 
136-143, 2005. 
Watermarking Scheme based on Wet Paper Coding (Speaker: Prof. Chin-Chen 
Chang, Taiwan)及 Robust Filtering on Hybrid Dynamical Systems with 
Uncertainties (Speaker: Prof. Peng Shi, UK)。由於時間有限，故只參與了張
真誠教授的演講場次，張教授目前為 IEEE Fellow 及 IEE Fellow，其題目
Watermarking亦是本人研究領域之一；張教授深入淺出的介紹Watermarking
技術，以及會中多位與會學者的提問，著實讓我受益良多。 
本人所發表的論文則是被安排在8/14日(第三天)上午08:30~10:20進行
的 Session C17: Innovative Computing for Image Analysis 的第 5 篇論文發
表，本人為該場次的共同主持人。在該 section 中共有六篇論文，除了兩篇
來自大陸的論文未出席報告外，所有作者均出席該 session 並發表論文，會
中討論相當熱烈，發表過程順利，也同時和與會學者交換研究心得與相關
問題討論，是一個成功的論文發表會。 
 
二、 與會心得 
此次國際研討會是在大陸瀋陽舉行，除了大陸及台灣的學者外，亦有
不少日本、英國、美國…等地的學者與會。除個人論文發表場次外，亦參
與了其他場次的論文發表，會中除了與論文作者有交談、互換研究心得。
本次出席會議的台灣學者(含研究生)都能如期出席發表論文口頭報告，是一
次成功的學術交流。透過會後休息時間，和與會的學者進行有關學術研究
的深度討論，此次研討會亦有多位國內學者參加，如高雄應用大學潘正祥
 2
