行政院國家科學委員會專題研究計畫成果
智慧型跌倒偵測系統之研究 
The Study of Video-based Human Fall Detection 
Systems 
計畫編號：NSC 100－2221－E011－134 
執行期限：100年 8月 1日至 101年 12月 31日 
主持人：陳郁堂 台灣科技大學電子系 
計畫參與人員：鄭凱文 劉殷助 曾柏叡 鍾紹鵬  
              台灣科技大學電子系 
英文摘要 
This project proposed and implanted a novel real-time human fall 
detection system. Because the system is based on a combination of 
skeletal features and various human shapes, it can distinguish between 
fall-down and fall-like incidents with a high degree of accuracy. Normally, 
complex 3-D models are used to extract human posture information. 
However, to reduce the high computational cost of human skeleton 
extraction, we propose using a 2-D skeleton model instead. The proposed 
2-D skeleton model only uses shape analysis to locate body parts without 
color cues. As a result, the model is effective in low light conditions. We 
apply the Douglas-Peucher algorithm to reduce the number of pixels in 
the human contour, which speeds up the human skeleton extraction 
process. Furthermore, we acquire an image of the human skeleton every 
0.4 seconds instead of in each frame, which enables us to detect changes 
in the victim’s skeleton during the fall.  
 
 
 
 
 
on simple features suffer from high false alarm rates because they fail to differentiate 
"fall-like" activities from "fall-down" ones. To provide a reliable fall detection system, 
an ingenious combination of several approaches is necessary. Hence, the intelligent 
combination of different fall detection approaches, which can increase detection 
accuracy while still satisfying the real-time constraint, has become a major research 
issue in human fall detection.  
3.文獻探討 
Many efforts have been made concerning fall detection. Wearable 
sensor-based devices (Zhang et al, 2006) such as accelerometers (Lindemann et al, 
2005) have been used to detect abnormal acceleration. However, this approach 
becomes useless if senior citizens do not wear the sensor device or the batteries within 
the sensors are dead. Several video-based fall detection technologies have been 
developed. For instance, the aspect ratio of the bounding box (William et al, 
2007)(Töreyin et al, 2005)(Vishwakarma et al, 2007), the ratio between the x-axis and 
y-axis, is used to detect a fall. When a fall-down incident occurs, the aspect ratio of 
the bounding box will change. A fall angle, the angle between ground and the person, 
is another popular approach (Vishwakarma et al, 2007). When this angle is less than 
45 degrees, a fall alarm is triggered. However, this approach may fail if the person 
falls toward the camera. The centroid of the person is also used to detect a fall-down 
proposed a fall detection approach based on the Motion History Image (MHI) (Bobick 
et al, 2001) and changes in human shape.  
Inspired by efficient human skeleton extraction (Hsu et al, 2008) and shape 
analysis in fall detection (Rougier et al, 2007), we propose a novel video-based 
human fall detection system that combines posture estimation and shape analysis. We 
attempt to use skeletal information to differentiate “fall-down” from “fall-like” 
activities. To alleviate the high computational cost of human skeleton extraction, we 
extract human posture based on 2-D skeleton models instead of complex 3-D ones 
despite the fact that 3-D human models provide more information than 2-D ones. We 
then apply the Douglas-Peucher algorithm (Douglas et al, 1973) to reduce the number 
of pixels in the human contour, which can effectively speed up human skeleton 
extraction since the computational cost of the 2-D extraction is proportional to the 
number of pixels in the human contour. Simultaneously, we acquire the human 
skeleton every 0.4 seconds instead of in each frame. Consequently, we can detect the 
change in skeletons in human fall detection instead of skeleton matching. The 
objective of the human fall detection system is to detect a fall-down incident rather 
than a fall-down posture. In summary, the proposed fall detection scheme consists of 
posture change detection, shape change detection and inactivity detection. We use a 
human skeleton to detect a large posture change. We then use an ellipse to fit a human 
comparison of the background subtraction approach and the Bayesian approach under 
the shadow of a foreground object is shown in Fig. 3. However, the details of 
foreground object segmentation and object tracking are beyond the scope of this 
paper.  
The proposed human fall detection system, shown in Fig. 4, integrates posture 
analysis, shape analysis and inactivity detection. We assume that a person is immobile 
on the floor after a fall and all video sequences are captured from a stationary camera. 
The human skeleton is first extracted through the depth-first search of Delaunay 
meshes. The distance between the two sampling skeletons beyond a threshold 
determines a posture change. We use an ellipse to approximate the human shape and 
the orientation of the ellipse and the ratio of its major and minor semi-axes to detect 
the human shape change. We then confirm a human fall incident by monitoring the 
inactivity of a person for a period of time.  
1. Posture Analysis with Human Skeleton 
We use the Douglas-Peucker algorithm (Douglas et al, 1973) to approximate the 
contour of foreground objects with fewer vertices. We next perform constrained 
Delaunay triangulation to partition a foreground object blob into triangular meshes, 
and extract the human skeleton through the depth first search on centers of triangular 
meshes. Finally, we calculate a distance map of the human skeleton, and detect the 
(1) endpoints of edge e  are on the boundary of C , and  
(2) no other vertex of S  is in the interior of C .  
Definition: Let G  be a straight-line planar graph. A triangulation T  is a 
constrained Delaunay triangulation of G  if each edge of G  is an edge of T  and 
for each remaining edge e  of T , there exists a circle C  with the following 
properties.  
(1) endpoints of edge e  are on the boundary of C , and  
(2) if any vertex v  of G  is in the interior of C , then it cannot be “seen" from 
at least one of the end points of e .  
After simplifying the human contour, we use Delaunay triangulation, well-studied 
in computational geometry, to partition foreground objects into triangular meshes. Fig. 
7 illustrates the Delaunay Triangulation. We can obtain the Delaunay meshes of a 
human object as follows.  
(1) Select boundary nodes of Delaunay meshes:  
A polygon is used to approximate the boundary of a human object. The polygon 
vertices are the boundary nodes of the Delaunay meshes. We use a simple heuristic to 
select boundary points with high curvatures as the boundary nodes of the Delaunay 
meshes.  
(2) Choose the interior nodes:  
(4) Perform the depth first search on G  and obtain a spanning tree F .  
(5) Find all leaf nodes L  and branch nodes B  of the spanning tree F.  
(6) Extract the skeleton S by connecting any two nodes in { }R L B C    if there 
exists a path between these two nodes.  
(iv). Distance Map of a Human Skeleton 
The distance map, also known as the distance transform (Borgefors, 1986), is 
employed to compute the distance between two sampling skeletons. In the distance 
transform of a binary map, the value of a pixel is the shortest distance to all pixels in 
the foreground object. The distance map of the binary image 1S , denoted as 1SDM , 
can be represented as follows :  
 
1
1
( ) min ( )S
q S
DM p Dist p q

   ﹐ (3) 
where ( )Dist p q  is the Euclidian distance between pixel p  and pixel q . Before 
calculating the distance between two skeletons, we must normalize them to the same 
size. Consequently, the distance of the two skeletons, 1S ,and 2S , denoted as 
Dist( 1S , 2S ), can be calculated as follows :  
 
1 21 2
1
( ) ( ) ( )S S
p
Dist S S DM p DM p
DM
    
 
  ﹐ (4) 
where DM   represents the image size of the distance map. Fig. 8 illustrates the 
distance map, and Fig. 9 illustrates the Delaunay triangulation, the human skeleton 
extraction, and the distance map of a skeleton.  
We then compute the major and the minor semi-axes of the ellipse, which correspond 
to, respectively, the maximum and minimum eigenvalues of the covariance matrix:  
 
2,0 1,1
1,1 0,2
 
 
 
 
 
 
 
 
J  (8) 
 
The maximum eigenvalue maxI  and the minimum eigenvalue minI  are given, 
respectively, by 
 
22
2 0 0 22 0 0 2 1 1
( )4
2
minI
          
  ﹐ (9) 
 
22
2 0 0 22 0 0 2 1 1
( )4
2
maxI
          
  ﹒ (10) 
 
The major and the minor semi-axes of the ellipse are then given, respectively, by 
 
11
84
3
4
( ) ( )maxa
min
I
I
I
  ﹐ (11) 
 
11
84
3
4
( ) ( )minb
max
I
I
I
  ﹒ (12) 
 
Finally, the ratio of the major and the minor semi-axes of the ellipse,  , can be 
defined as follows  
 
a
b
I
I
   ﹒ (13) 
relatively high. If it is not a fall-down incident, R  will be relatively low. To 
conform with the definition of a fall-down incident, we set the period of the time 
window (SW) from 0.4 second to 0.8 second in the calculation of R  and R .  
3. Fall-Down Confirmation 
We check the following two conditions to confirm to a fall-down.  
(1) The motion of the human object is smaller than the threshold for a period of time. 
(2) Both R  in Eq. (14) and R  in Eq. (15) are smaller than the threshold for a 
period of time.  
The first condition assures that the person is inactive for a period of time after a 
possible fall, whereas, the second condition guarantees that both the change rate in the 
orientation of the ellipse, which approximates the human shape, and the ratio of major 
and minor of the ellipse semi-axes approach zero within a fixed time interval, i.e., the 
human shape becomes immobile after a possible fall. 
 
EXPERIMENTAL RESULTS 
We implemented the proposed skeleton-based fall detection system on Intel’s 
OpenCV library (Bradski et al, 2008), and decoded the compressed video by mean of 
the FFMPEG library. All test videos were acquired from a single stationary and 
 false alarm rate
( )
FP
TN FP


 ﹒ 
1. EXPERIMENTAL RESULTS WITH DIFFERENT THRESHOLDS 
In the proposed fall detection system, thresholds in human fall detection such as 
skeleton change detection, ellipse orientation change detection, ellipse aspect ratio 
change detection and inactivity detection can influence the detection rate and the false 
alarm rate. To tune the performance of the proposed fall detection system, we 
conducted a series of experiments under different skeleton distance thresholds as 
shown in Table 2. In a trade-off between the detection rate and the false alarm rate, the 
skeleton distance = 0.056 can tune the system to a condition with a detection rate = 
90.91 % and a false alarm rate = 9.09 %. Table 3 shows major system thresholds for 
the proposed fall detection system in our experiments.  
In the posture analysis, a distance map of two sampling human skeletons is calculated 
every 0.4 second, and a human fall is detected if this distance map is larger than a 
threshold, i.e., only a drastic change in the human posture as discussed in Section II.1 
is accepted as showing human falling. On the other hand, the shape analysis only uses 
the change rate in the ellipse angle and the ratio between the major and minor 
semi-axes of the ellipse to detect human falling, i.e., only a drastic change in the 
human shape as discussed in Section II.2 is accepted as indicating human falling. 
Tables 4 and 5 show experimental results for the human skeleton match and the 
posture analysis respectively. The experimental results for shape analysis utilizing, the 
change ratio of two ellipse features, are tabulated in Table 6. From Tables 4 to 6, we 
can observe that the fall detection systems based on a single approach yield a high 
false positive rate and low detection accuracy because they cannot differentiate a 
sit-down from a fall-down.  
Table 4 The experimental results of the skeleton match 
 
Event  No of 
videos  
Detected 
falling  
Detected 
non-falling  
TP TN FP FN   
Falling  22  16  6  16 0 0 6   
Sit-down  8  1  7  0 7 1 0   
Squat 8 0  8 0 8 0 0   
Walking  8 0  8 0 8 0 0   
Running  8 0  8 0 8 0 0   
 
  
 Fall detection approach Detection rate  False alarm rate   
The skeleton match  0.727 0.031  
The posture analysis    1  0.34   
The shape analysis  0.909  0.16   
The proposed scheme  0.909  0.06   
 
  
Table 9 Comparison of the proposed scheme and the shape analysis in terms of the execution 
time, detection rate and false alarm rate 
 
Performance metric The proposed 
detection scheme  
The shape 
analysis  
Detection rate  90.9% 90.9 %   
False alarm rate  6.25 % 15.6 %   
Execution Time  4.21 sec  1.36 sec   
 
The experimental results for the proposed falling detection system are shown 
in Table 7. Two fall-down incidents were not detected because they were slow-speed 
fall incidents, which did not register as fast posture changes in the first step of the 
proposed approach. On the other hand, two sit-down activities were flagged fall 
incidents because fast sit-down activities trigger a posture change step in the proposed 
approach. Table 8 summarizes the performance of the four human fall detection 
approaches in terms of the detection rate and the false alarm rate. These results 
demonstrate that an intelligent combination of different fall detection approaches can 
provide reliable fall detection. Table 9 compares the proposed hybrid human detection 
approach with the shape analysis approach (Rougier et al, 2007) in terms of the 
Temporal Template," IEEE Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 23, No. 3, pp. 257 - 267. 
 
Borgefors Gunilla, 1986, ”Distance Transformations in Digital Images," Computer 
Vision, Graphics, and Image Processing, Volume 34, No. 3, Pages 344-371. 
 
Bradski, G. R. and Kaeher, A., 2008, Learning OpenCV: Computer Vision with 
OpenCV Library, O’Reilly Media, Inc., Sebastopol, CA, USA. 
 
Chew L. P., 1987, ”Constrained Delaunay Triangulations," ACM Proceedings of Third 
Annual Symposium on Computational Geometry, , pp. 215-222, Waterloo, Ontario, 
Canada. 
 
Douglas David and Peucker Thomas, 1973, ”Algorithms for The Reduction of The 
Number of Points Required to Represent A Digitized Line or Its Caricature," The 
Canadian Cartographer, Vol.10, No. 2, pp. 112-122. 
 
Hsu Y. T., Liao H. Y. M., and Chen C. C., Hsieh J. W., 2008, ”Video-based Human 
Movement Analysis and Its Application to Surveillance Systems," IEEE Transactions 
on Multimedia, Vol. 10, No. 3, pp. 372-392.  
 
Huang W., Gu I. Y. H., and Li Q. Tian L., 2003, ”Foreground Object Detection from 
Videos Containing Complex Background," Proceedings of the Eleventh ACM 
International Conference on Multimedia, pp.2 - 10, Berkeley, CA, USA. 
 
Lin Chia-Wen, Ling Zhi-Hong, Cheng-Yeng, and Kuo Chung J., 2007, 
“Compressed-domain Fall Incident Detection for Intelligent Homecare," Journal of 
VLSI Signal Processing System, Vol. 49, No. 3, pp. 393 - 408. 
 
Lindemann U., Hock A., and Stuber, M., 2005, ”Evaluation of A Fall Detector Based 
on Accelerometers: A Pilot Study," Medical and Biological Engineering and 
Computing, Vol. 43, No. 5, pp. 548 - 551. 
 
Pratt Willam, 2007, Digital Image Processing, 4th ed., John Wiley and Sons, Ltd., 
New York, USA. 
 
Rougier Caroline, Meunier Jean, St-Arnaud Alain, and Rousseau Jacqueline, 
2007, ”Fall Detection from Human Shape and Motion History Using Video 
Douglas David and Peucker Thomas, 1973, ”Algorithms for The Reduction of The 
Number of Points Required to Represent A Digitized Line or Its Caricature," The 
Canadian Cartographer, Vol.10, No. 2, pp. 112-122. 
 
Hsu Y. T., Liao H. Y. M., and Chen C. C., Hsieh J. W., 2008, ”Video-based Human 
Movement Analysis and Its Application to Surveillance Systems," IEEE Transactions 
on Multimedia, Vol. 10, No. 3, pp. 372-392.  
 
Huang W., Gu I. Y. H., and Li Q. Tian L., 2003, ”Foreground Object Detection from 
Videos Containing Complex Background," Proceedings of the Eleventh ACM 
International Conference on Multimedia, pp.2 - 10, Berkeley, CA, USA. 
 
Lin Chia-Wen, Ling Zhi-Hong, Cheng-Yeng, and Kuo Chung J., 2007, 
“Compressed-domain Fall Incident Detection for Intelligent Homecare," Journal of 
VLSI Signal Processing System, Vol. 49, No. 3, pp. 393 - 408. 
 
Lindemann U., Hock A., and Stuber, M., 2005, ”Evaluation of A Fall Detector Based 
on Accelerometers: A Pilot Study," Medical and Biological Engineering and 
Computing, Vol. 43, No. 5, pp. 548 - 551. 
 
Pratt Willam, 2007, Digital Image Processing, 4th ed., John Wiley and Sons, Ltd., 
New York, USA. 
 
Rougier Caroline, Meunier Jean, St-Arnaud Alain, and Rousseau Jacqueline, 
2007, ”Fall Detection from Human Shape and Motion History Using Video 
Surveillance," Proceedings of the 21st International Conference on Advanced 
Information Networking and Applications Workshops, pp. 875 – 880, Niagara Falls, 
Canada. 
 
Rougier Caroline, Meunier Jean, St-Arnaud Alain, and Rousseau Jacqueline, 
2008, ”Procrustes Shape Analysis for Fall Detection," The Eighth International 
Workshop on Visual Surveillance, pp. 50-62, Marseille, France. 
 
Töreyin B. U., Dedeoglu Y., and Cetin A. E., 2005, “HMM-based Falling Person 
Detection Using Both Audio and Video," Lecture Notes in Computer Science, vol. 
3766, pp.211-220 Springer-Verlag, Berlin 
  
Vishwakarma Vinay, Mandal Chittaranjan, and Sural Shamik, 2007, ”Automatic 
  
Fig. 1 The features of the fall-down incident 
 
 
 
Input video
Foreground Object 
Segmentation
Object Tracking
Fall Detection
Fall Alarm 
Generation
 
Fig. 2 The flowchart of the proposed fall detection system 
 
 
Object contour
Douglas-Peuker Algorithm
Delaunary Triangulation
Build skeleton tree
Distance transform
Distance map
 
 Fig. 8 An example of the distance map 
 
 
 
陳郁堂台灣科技大學電子系 
Joint IAPR International Workshops on Structural and 
Syntactic Pattern Recognition (SSPR 2012) and Statistical 
Techniques in Pattern Recognition (SPR 2012) 
國際會議出席報告 
1.參與會議經過 
第 21 屆 Joint IAPR International 
Workshops on Structural and 
Syntactic Pattern Recognition 
(SSPR 2012) and Statistical 
Techniques in Pattern Recognition 
(SPR 2012)會議於 2012 年 11 月 7 
日至 9 日，在日本廣島市宮島口的
Aki Grand Hotel 舉行。 會議所在地
風景如織，對面為宮島，列入日本三
大古跡，是日本人一生必遊的景點。 
本 會 議 是 國 際 型 態 辨 識 協 會 
(International Association of Pattern 
Recognition)每兩年一次盛會，吸引
來自來自 18 個國家百餘名型態辨識
(Pattern Recognition) 研 究 學 者 與
會。本次會議共發表 80 篇論文。今
年會議 Pierr Devijver 獎頒發給 來自
美國 Rensselar Polytechnic Institute 
的 George Nagy 教授，以表彰他從
1966 開始長達四十年在型態辨識領
域的貢獻。 
 
此次會議包含下列議題:圖型模型 
(Graphical Models), 圖 型 表 示 法
(Graphical-based Representation),  
核 心 方 法 (Kernel Methods for 
Structure data), 非 指 引 式 學 習
(Unsupervised Learning), 分群分析
(Clustering Analysis) 型態辨識在文
字形狀靜態影像與視訊的應用等， 
涵蓋各個型態辨識領域。 
 
本次會議三個 Invited Lecture 分 
別 Pierr Devijver 獎 得 主 George 
Nagy 教 授  發 表 “Estimation, 
Learning, Adaption: Systems that 
Improve with Use ”演講； Kenichi 
Kanatani 教 授 發 表 ”Optimization 
Technologies for Geometric 
Estimation: Beyond Minimization” 演
講 與 Ales Leonardis 教 授 發 表 
“Hierarchical Compositional 
Representations of Object Structure”.
為題的演講。 
 
 Kenichi Kanatani 教 授 發
表 ”Optimization Technologies for 
Geometric Estimation: Beyond 
Minimization 的演講中，談到在電腦
視覺最重要工作之一就是計算二度空
間或三度空間物件的幾何限制條件。
幾何條件限制就是以簡單方程式，表
示物件在一直線、或在同一個平面
上、或者相互水平、或進行幾何投
困難的情況，例如身份驗證，手寫字
符的識別，機器或結構監測…等。本
篇論文提出新的單類分類器演算法，
稱為單類隨機森林分類器 One-class 
Random Forests （ OCRF ） ， OCRF
是一個架構在隨機森林為基礎上的單
類分類方法。本篇 OCRF 的演算法包
含兩個隨機化原則—“裝袋”以及”隨機
特徵選取”。OCRF 算法的兩個主要
步驟(1)從目標數據的原始特徵空間中
提取預先檢驗的信息，以利匡正學習
過程。(2)隨機森林同時使用”隨機子
空間降維法”(RSM)以及“裝袋、隨機
特徵選取”來降低維度，並創造多樣性
的分類樹。總而言之，OCRF 方法利
用： 
(1) 相結合多元化的弱分類器，這是
眾所周知的增加分類器的準確度
的方法。 
(2) 為了有效地透過控制自己的位置
數量生成離群值，在訓練樣本和
功能時以二次採樣的方式訓練數
據集。 
  
荷蘭學者 Gerard Sanroma 等發表 
“Recognition of Long Term Behavior 
by Parsing Sequence of Short term 
Actions with a Stochastic Regular 
Grammar” 從視訊資料中辨識人類行
是個熱門研究題目。然而現有研究常
將問題限定在一小段時間內動作(稱為
簡短動作）的識別，對於較長時間的
複雜行為的研究較少。本篇論文提出
以隨機文法（stochastic grammar)方式
來識別長時間行為。這篇論文假設任
何簡短動作具有特定結構利用這個結
構來提高簡短動作的辨識結果。而複
雜 行 為 可 利 用 語 法 分 析 （ syntactic 
approach) 技巧建立模型，任何視訊
中 要 辨 識 的 行 為 可 以 用 文 法 法 則
(grammar rule)來表示。這個方法特別
適用於缺乏訓練資料的行為辨識，例
如識別具有威脅行為。 
首先對一個已知的集合萃取其軌跡信
息，最主要的目的是，計算測試資料
屬於各個已知動作的機率。為了進一
步減低雜訊，使用 PCA 對取得的特
徵向量重新做投影，再以 KNN 計算
各類別的相似度。 
簡短動作經常遵循某些前因後果的行
為模式，大部分這些行為模式都蘊含
幾十甚至上百個簡短動作所組成。所
以作者將複雜行為視為行為模式的”文
法規則”，因此，當要辨識複雜行為
時，可視為確認是否符合語意規則。 
 
西班牙學者 Adrian Perez 報告論文 
“Online_Metric_Learning_Methods 
Using Soft Margins and Least 
Squares Formulations” 
組織，分類或表示數據集是具有關鍵
的重要性在許多不同的應用領域，從
圖像分析等領域，模式識別或資料探
勘。這些基於距離的方法形成了一個
完善的方法類別來解決分類，回歸，
估計和聚類的問題。這類方法之效能
依賴於輸入樣本彼此之間關係以什麼
樣的機制表示。然而這些機制與物件
指標，指向鄰近區域最大密度的資料
點。若該資料點在鄰近區域密度最
大，則指標指向自己，此資料點為
Mode。所有匯流到此 Mode 的指標
集合成一個群集。 
kNN 與 Mean shift 分群演算法最大的
不同是 Mean shift 使用了固定的空間
視窗尺吋，然而 KNN 演算法使用了
固定鄰居數量。 
本篇論文比較 KNN mode seeking 及
Mean shift 分群演算法。在大規模問
體 ， 例 如 問 題 維 度 高 達 數 百 情 況
下， kNN 的效能比 Mean shift 演算
法來的好；在。在小規模資勞情況下
kNN 的效能比 Mean shift 演算法來的
差。 
 
由 NTT 日本學者 Makoto Yamada 
報吿論文   Change_point_detection 
in Time-Series Data by Relative 
Density Estimation。變化點檢測的目
的是從時間序列數據中發現突然變化
的樣本，這個問題在幾十年來已吸引
統計和資料探勘領域研究人員。變化
點檢測可分為即時性的變化點檢測和
回顧性的變化點檢測。即時性的變化
點檢測需要即刻的反應，例如機器人
控制應用。而回顧性的變化點檢測一
般需要較長的時間運算，其相關的應
用包含天候異常偵測、訊號切割和網
路入侵系統等。作者對回顧性的變化
點檢測方案，並提出了一種非參數方
法。作者提出了一個新的統計變化點
檢測的演算法，主要的概念是將非參
數之間的分歧估計的點檢測算法運用
到兩個分別為過去及現在的時間序列
片 段 。 其 中 分 歧 估 計 量 測 是 採 用
Relative Pearson divergence，非參
數變化點檢測演算法，例如 kernel 
density estimation 常用來估計過去及
現在時間序列片段的機率分佈。然而
curse of dimensionality，此方法在高
維度資料的環境下往往造成準確率的
下降。為了克服這個困難，本篇論文
提出了一個想法：直接估計密度比例
而不計算過去及現在時間序列片段的
機率分佈。這個密度比估計的合理性
的想法是，知道兩種密度意味著知道
知道的密度比，但反之則不然，如下
圖所示。因此，直接密度比估計大大
的簡化了密度估計所遭遇的因難。許
多演算法 (例如 Logistic 回歸方法、
KLIEP 等) 都是遵循這一理念。 
本篇論文的貢獻有兩方面，第一個貢
獻是應用最近提出的密度比估計的方
法稱為 unconstrained least-squares 
importance fitting（uLSIF）。uLSIF
的顯著優勢是它實現了最佳的非參數
收斂速度，它具有最佳的數值穩定
性，它比 KLIEP 更 Robust。本文的
第二個貢獻是將以 uLSIF 為基礎的變
化 點 檢 測 做 延 伸 ， 稱 為 Relative 
uLSIF（RuLSIF）“。RuLSIF 的基本
思想是考慮相對密度比，為了避免無
窮大密度比的情形發生。RuLSIF 被
證實擁有比普通 uLSIF 卓越的非參數
收斂性，這意味著 RuLSIF 提供了一
A Novel Shadow-Assistant Human Fall Detection
Scheme Using a Cascade of SVM Classifiers
Yie-Tarng Chen, You-Rong Lin, and Wen-Hsien Fang
Department of Electronic Engineering,
National Taiwan University of Science and Technology,
Taipei, Taiwan, R.O.C.
{ytchen,whf}@mail.ntust.edu.tw
Abstract. Visual recognition of human fall incidents in video clips has
been an active research issue in recent years, However, most published
methods cannot eﬀectively diﬀerentiate between fall-down and fall-like
incidents such as sitting and squatting. In this paper, we present a novel
shadow-assistant method for detecting human fall. Normally, complex
3-D models are used to estimate the human height. However, to reduce
the high computational cost, only the information of moving shadow is
used for this context. Because the system is based on a combination of
shadow-assistant height estimation, and a cascade of SVM classiﬁers,
it can distinguish between fall-down and fall-like incidents with a high
degree of accuracy from very short sequence of 1-10 frames. Our exper-
imental results demonstrate that under bird’s-eye view camera setting,
the proposed system still can achieve 100% detect rate and a low false
alarm rate, while the detection rate of other fall detection schemes have
been dropped dramatically.
Keywords: fall detection, SVM.
1 Introduction
In recent years, visual recognition of human fall incidents in video clips has been
an active research issue. In this paper, we consider the problem of using a mono
un-calibrated camera to detect if senior citizens fall over, called fall-down inci-
dents hereafter. Such incidents normally occur suddenly and take approximately
0.45 to 0.85 seconds. Both the posture and shape of the victim change rapidly,
and he/she usually lies inactive on the ﬂoor. Hence, drastic changes in the pos-
ture, shape and height of the body are key features in human fall detection.
However, modeling those features with low computational complexity is a not a
trivial task, especially for accurate human height estimation.
A number of fall detection schemes have been proposed [4-5]. Simple features
derived from shape analysis, such as the aspect ratio of the bounding box, the
 This work was supported by National Science Council of R.O.C. under contract NSC
100-222-E-011-134.
G.L. Gimel’ farb et al. (Eds.): SSPR & SPR 2012, LNCS 7626, pp. 710–718, 2012.
c© Springer-Verlag Berlin Heidelberg 2012
712 Y.-T. Chen, Y.-R. Lin, and W.-H. Fang
However, to reduce the high computational costs, the shadow-assistant approach
instead, even though it provides less information than 3-D models, but satisﬁes
the requirements of a real-time fall detection system. Furthermore, a fall into
any angle can be detected. Speciﬁcally, the proposed approach can successfully
detect fall toward camera with a low computational cost.
The contributions of this paper are two-fold:
1. We have address the use of shadow for visual recognition of human fall.
Although shadows have been used to measure the height of a building on
aerial images. To our knowledge, shadows are ﬁrst introduced to human
activity recognition in this paper.
2. We develop a fall detection system based on intelligent combination of shadow
analysis,shape analysis and motion analysis, achieve 100% detect rate and a
low false alarm rate from very short sequence of 1-10 frames while satisfying
the real-time constraint.
The remainder of the paper is organized as follows. Section 2 presents foreground
objects and moving shadows segmentation. In Section 3, we describe the novel
shadow-assistant detection scheme. The results of experiments are detailed in
Section 4 and Section 5 concludes the paper.
2 Foreground Objects and Moving Shadows Detection
Foreground object segmentation and moving shadows detection are important
preprocessing steps in human fall detection schemes. We use the statistical back-
ground subtraction and shadow detection algorithm [1] developed by Horprasert
et al.for this context. However, other foreground ground extraction and moving
shadow detection algorithms still can be applied to the proposed fall detection
scheme.
2.1 Background Modeling
In background modeling, we attempt to obtain a background model and its
parameters by several selected images. Each pixel in the background model is
assumed to be independent, and it can be represented as a tuple with four
parameters The background is modeled statistically on a pixel by pixel basis. A
pixel is modeled by a 4-tuple < Ei, Si, ai, bi >. where Si is a standard deviation
of color value. It normalizes the pixel color in this work. It is given by
Si = [σR(i), σG(i), σB(i)] (1)
where σR(i), σG(i), σB(i) are the standard deviations of the i-th pixel’s red,
green, blue values over N training frames. The expected color value of pixel i is
given by
Ei = [μR(i), μG(i), μB(i)] (2)
where μR(i), μG(i), μB(i) denote arithmetic means of the i-th pixel’s red, green,
blue values over N training frames. Let Ii = [IR(i), IG(i), IB(i)] represent the
714 Y.-T. Chen, Y.-R. Lin, and W.-H. Fang
3 Human Fall Detection System
3.1 System Description
After Foreground object segmentation and object tracking, the system begins to
perform fall detection. The proposed fall detection scheme as shown in Figure 2
consists of cascaded classiﬁers which integrates height estimation, posture anal-
ysis, shape analysis, and inactivity detection. We assume that a person is in an
upright posture when ﬁrst appearing in the video sequence and becomes immo-
bile on the ﬂoor after a fall. All video sequences are captured by a stationary
camera, which can be furnished in either a ﬂat-view or a bird view.
Since Histograms of Oriented Gradients (HOG)[2] detectors have shown to
give signiﬁcantly high performance in upright human detection, ﬁrst, an input
image is sent to the HOG-based upright posture detector. Next, any non-upright
human foreground is sent to a shadow-assistant falling posture detector as shown
in Figure 3, which performs height estimation and shape analysis to detect a
falling posture. Finally, we conﬁrm a fall incident by monitoring the inactivity
of the person by using a motion history image (MHI)[3].
For classiﬁcation in the upright posture detection,the falling posture detec-
tor and inactivity detector, we use state-of-the-art machine learning techniques-
support vector machines, which have been a popular approach for pattern
classiﬁcation and nonlinear regression because of its robustness even in the
absence of a rich set of training examples. The virtual height, the HOG vec-
tor, and MHI vector are major features in the proposed fall detection scheme,
which will be discussed in the following sections.
Fig. 2. The ﬂowchart of the shadow-assistant fall detector
716 Y.-T. Chen, Y.-R. Lin, and W.-H. Fang
Fa =
n∑
i=1
δ(M(i)− F ) (12)
If the shadow is occurring, both shadow analysis and shape analysis, such as the
aspect ratio of the bounding box, are used to detect the falling posture, whereas,
if the shadow is not available, only the shape analysis is considered to detect the
falling posture.
We assume that a person ﬁrst appears in the scene with an upright posture.
We can use the ﬁrst few images in the video sequence to detect the presence of
the shadow. If the upright detector is ﬂagged as positive and the shadow area is
approximate to zero, the shadow information cannot be used for human falling
detection. However, if the upright detector is ﬂagged as positive, and the shadow
area is larger than a threshold, the shadow information cannot be used to the
human fall.
B is the index of the shadow-assistant function in the human fall detection
system. If B = 1, the shadow-assistant function operates. On the other hand,
if B = 0 the shadow information will not be considered in the proposed human
fall detection scheme.
B =
{
1 if Ur(t) = 1 and S(t) = 1
0 if Ur(t) = 1 and S(t) = 0
(13)
where Ur(t) is the upright detector for frame(t) and Ur(t) = 1 if the upright
detector classiﬁes frame(t) as an upright human posture and Ur(t) = 0 otherwise.
S(t) is the shadow index for frame(t) and S(t) = 1 if the area of the human
shadow in frame(t) is larger than a predeﬁned threshold and S(t) = 0 otherwise.
3.4 Inactivity Detector
Motion History Image (MHI) [3] is deﬁned by a simple replacement and decay
operators:
Hτ (x, y, t) =
{
τ if D(x, y, t) = 1
max (Hτ (x, y, t− 1)− 1) otherwise
whereD(x, y, t) is a binary image sequence indicating region of motion, generated
by image diﬀering.
Motion History Image (MHI) is a scalar-value image where more recently
moving pixels are brighter. The Motion History Image can be used to represent
how motion the image is moving.
We check the following condition to conﬁrm the occurrence of a fall-down
incident: the Motion History Image (MHI) of the human object is lower than
the threshold Tp. This condition conﬁrms that the person is inactive for a period
of time after a fall.
718 Y.-T. Chen, Y.-R. Lin, and W.-H. Fang
Fig. 4. Parts of the test videos:(left three) walking, sitting-down, and falling down from
brid-view dataset, and (right two) bending and falling down from Shoaib dataset
Table 1. Comparison of fall detection
schemes for outdoor bird view data sets
approach TP FN TN FP Pd Pn
our approach 27 0 34 2 1.00 0.055
approach 2 20 7 25 11 0.74 0.31
approach 3 24 3 33 3 0.889 0.08
approach 4 25 2 31 5 0.926 0.138
Table 2. Comparison of fall detection
schemes for Shoaib data sets
approach TP FN TN FP Pd Pn
our approach 10 0 24 4 1.00 0.166
approach 2 8 2 23 5 0.80 0.217
approach 3 4 6 26 2 0.40 0.077
approach 4 10 0 14 14 1.00 0.500
5 Conclusion
We have presented a novel shadow-assistant human fall detection system which
can support diﬀerent viewpoints. The robust human fall detection scheme relies
on shadow and shape analysis to diﬀerentiate fall-down and fall-like incidents
under diﬀerent viewpoints. Our experiment results demonstrate that the pro-
posed system can achieve a high detection rate and low false alarm rate while
satisfying real-time constraints.
References
1. Horprasert, T., Harwood, D., Davis, L.: A Statistical Approach for Real-Time Ro-
bust Background Subtraction and Shadow Detection. In: IEEE International Con-
ference on Computer Vision, ICCV 1999, Frame-Rate Workshop, pp. 1–19. IEEE
Press, New York (1999)
2. Dalal, N., Triggs, B.: Histograms of Oriented Gradients for Human Detection. In:
IEEE Computer Society Conference on Computer Vision and Pattern Recognition,
CVPR 2005, pp. 886–893. IEEE Press, New York (2005)
3. Bobick, A., Davis, J.: The Recognition of Human Movement Using Temporal Tem-
plate. IEEE Transactions on Pattern Analysis and Machine Intelligence 23, 257–267
(2001)
4. Rougier, C., Meunier, J., St-Arnaud, A., Rousseau, J.: Fall Detection from Hu-
man Shape and Motion History Using Video Surveillance. In: the 21st International
Conference on Advanced Information Networking and Applications, Niagara Falls,
Canada, pp. 875–880. IEEE Press, New York (2007)
5. Hsu, Y.T., Liao, H.Y., Chen, M.C.C., Hsieh, J.W.: Video-based Human Movement
Analysis and Its Application to Surveillance Systems. IEEE Transactions on Mul-
timedia 10, 372–392 (2008)
100年度專題研究計畫研究成果彙整表 
計畫主持人：陳郁堂 計畫編號：100-2221-E-011-134- 
計畫名稱：智慧型跌倒偵測系統之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100% 
2 Yie-Tarng Chen, 
Yu-Ching Lin, and 
Wen-Hsien 
Fang , ＇＇A 
Video-based 
Human Fall 
Detection System 
for the Smart 
Home＇＇ in 
Journal of the 
Chinese 
Institute of 
Engineers, vol 
33, no 5, pp 
681-690, 2010. 
(SCI) 
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
國外 論文著作 
研討會論文 2 0 100% 
篇 
1 ＇A Hybrid 
Human Fall 
Detection 
Scheme＇ 
publication in 
2010 IEEE 
International 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
高齡化社會是世界趨勢，跌倒對老年人是非常危險的事，本計畫智慧型跌倒偵
測系統，能將能降低跌倒事件後遺症，本計畫提高跌倒偵測系統的準測性與即
時性，本計畫執行成果，以 OpenCV 完成跌倒偵測系統 prototype 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
