可供推廣之研發成果資料表 
■ 可申請專利  ■可技術移轉                            日期：98年 10月 22日 
國科會補助計畫 
計畫名稱：從單張影像做超解析度人臉影像合成:基於機械學習之
多解析度小波 
計畫主持人： 連震杰 
計畫編號：NSC 97-2221-E-006-212- 學門領域：EB 資訊學門二 
技術/創作名稱 
從單張影像做超解析度人臉影像合成:基於機械學習之多解析度小
波 
發明人/創作人 連震杰 
技術說明 
中文： 
我們將發展一個基於學習理論之合成超解析度影像系統，讓我們可
以由單張低解析影像合成出較高解析度的影像。整個系統將分成兩
個部分，分別是事先的訓練程序以及合成程序。為了合成出同時包
含整體影像架構及細部高頻細節的人臉影像，我們將引入了多重解
析度之小波合成。在訓練程序中，每一層解析度下的低解析度影像
都會被切成許多小區塊，進而由這些小區塊形成的集合建立出相對
應的特徵空間(eigenspace)，以減少在相似度比對所需花費的時
間。而在合成程序中，我們將視這些區塊為一馬可夫網路(Markov 
network)，並利用最大後驗概率(maximum a posteriori (MAP) )
從已建立好的資料庫裡找出最合適的區塊。實驗結果將顯示，我們
能合成出比由雙立方內插法(bi-cubic interpolation)得到的影
像更好的結果。 
 
英文： 
A learning-based super-resolution system consisting of training and 
synthesis processes is presented. In the proposed system, a 
multi-resolution wavelet approach is applied to carry out the robust 
synthesis of both the global geometric structure and the local 
high-frequency detailed features of a facial image. In the training 
process, the input image is transformed into a series of images of 
increasingly lower resolution using the Haar discrete wavelet transform 
(DWT). The images at each resolution level are divided into patches, 
which are then projected onto an eigenspace to derive the 
corresponding projection weight vectors. In the synthesis process, a 
low-resolution input image is divided into patches, which are then 
projected onto the same eigenspace as that used in the training process. 
Modeling the resulting projection weight vectors as a Markov network, 
附件二 
從單張影像做超解析度人臉影像合成:基於機械學習之多解析度小波 
Learning-Based Super-Resolution System Using Single Facial Image and 
Multi-Resolution Wavelet Synthesis 
 
計畫編號：NSC 97-2221-E-006-212- 
執行期間：2008年 08月 01日至 2009年 07月 31日 
 計畫主持人： 連震杰 國立成功大學資訊工程系所 (jjlien@csie.ncku.edu.tw) 
 計畫參與人員: 凃瀞珽博士班研究生助理, 張峻豪 碩士班研究生助理 
               劉子揚 碩士班研究生助理, 謝松憲 碩士班研究生助理 
 
中文摘要 
我們將發展一個基於學習理論之合成超解
析度影像系統，讓我們可以由單張低解析影
像合成出較高解析度的影像。整個系統將分
成兩個部分，分別是事先的訓練程序以及合
成程序。為了合成出同時包含整體影像架構
及細部高頻細節的人臉影像，我們將引入了
多重解析度之小波合成。在訓練程序中，每
一層解析度下的低解析度影像都會被切成
許多小區塊，進而由這些小區塊形成的集合
建立出相對應的特徵空間(eigenspace)，以
減少在相似度比對所需花費的時間。而在合
成程序中，我們將視這些區塊為一馬可夫網
路(Markov network)，並利用最大後驗概率
(maximum a posteriori (MAP) )從已建立
好的資料庫裡找出最合適的區塊。實驗結果
將顯示，我們能合成出比由雙立方內插法
(bi-cubic interpolation)得到的影像更
好的結果。 
 
關鍵字： 
超解度析影像,機械學習,多重解析度之小
波,合成,馬可夫網路,最大後驗概率。 
 
Abstract 
A learning-based super-resolution system 
consisting of training and synthesis processes 
is presented. In the proposed system, a 
multi-resolution wavelet approach is applied 
to carry out the robust synthesis of both the 
global geometric structure and the local 
high-frequency detailed features of a facial 
image. In the training process, the input image 
is transformed into a series of images of 
increasingly lower resolution using the Haar 
discrete wavelet transform (DWT). The 
images at each resolution level are divided 
into patches, which are then projected onto an 
eigenspace to derive the corresponding 
projection weight vectors. In the synthesis 
process, a low-resolution input image is 
divided into patches, which are then projected 
onto the same eigenspace as that used in the 
training process. Modeling the resulting 
projection weight vectors as a Markov 
network, the maximum a posteriori (MAP) 
estimation approach is then applied to identity 
the best-matching patches with which to 
reconstruct the image at a higher level of 
resolution. The experimental results 
demonstrate that the proposed reconstruction 
system yields better results than the bi-cubic 
spline interpolation method. 
 Fig. 1. Flowchart of SR system triaining process. The original input training image (Level 0) is 
successively transformed using Haar discrete wavelet transformation (DWT) to generate 
lower-resolution images (Levels 1 and 2, respectively) comprising four sub-bands. At each level, 
3x3 pixel patches from each sub-band are concatenated to form a 3×3×4-dimensional vector with 
a one patch-based eigenspace. These vectors are projected onto the eigenspace to generate a 
corresponding projection weight vector. The projection weight vectors produced at each level are 
grouped to form a projection weight database. 
 
The SR system consists of two basic 
processes, namely a training process and a 
synthesis (reconstruction) process. In the 
training process, the input image is 
decomposed into a series of increasingly 
lower-resolution images using a discrete 
wavelet transformation (DWT) technique. The 
image at each resolution level is divided into 
patches, which are then projected onto an 
eigenspace to compute the corresponding 
projection weight vectors. The projection 
weight vectors generated from all of the 
patches within the image at each level are 
grouped into a projection weight database. In 
the subsequent synthesis procedure, the input 
image is firstly interpolated to a double-size 
one (Fig.2, I). By applying three 
corresponding Haar filters on it, the three 
initial subbands are created. The three 
subbands together with the input image are 
then divided into patches, which are then 
mapped onto the eigenspace associated with 
the lowest-resolution input image in the 
training process. The resulting projection 
 
Fig. 2. Flowchart of SR system synthesizing process. The input image with a quarter-resolution 
of the desired output is interpolated and a Haar filter applied to produce four sub-bands. These 
sub-bands are then divided into patches and projected onto patch-based eigenspace 2 to generate 
the corresponding projection weights. Using the maximum a posteriori criterion, the projection 
weights are then compared with those within projection weight database 2. The best-fitting 
matches are used to improve the patches in the original input image, which is then synthesized 
using an inverse wavelet transformation process to construct a new image with twice the 
resolution of the original input image. Using this new image as an input, the reconstruction 
process is repeated using patch-based eigenspace 1 and projection weight database 1 to 
synthesize the required highest-resolution image. 
 
2.2 Patch-Based Eigenspace Construction 
As described in the previous section, four 
sub-band images are required for the wavelet 
reconstruction process. However, initially 
only a single low-resolution image is available. 
Therefore, the problem arises as to how the 
coefficients of the other three sub-bands may 
be estimated. In the current study, this 
problem is resolved by using a learning-based 
approach [1], [2] to estimate the missing 
high-frequency image details on the basis of 
 
Fig. 3. Each search vector is constructed by concatenating four 3x3-pixel patches from the four 
sub-band images. These search vectors are then compared with the weight projection vectors 
within the training database(s) to identify the best-fitting match. The training image patches 
corresponding to the identified weight projection vector are then mapped back to the input image. 
Note that the search vector and the training databases are modeled as a Markov network. 
 
network. In this network, the observed nodes, 
y, represent the transformed patches and the 
aim is to estimate the hidden nodes, x, from y. 
In the current network, the hidden nodes 
represent the fine details of the original 
images, i.e. the patches in subbands LH, HL 
and HH. Since the spatial relationship 
between x and y is modeled as a Markov 
network (see Fig. 3), the joint probability over 
the transformed patch y [7] can be expressed 
as follows:  
 
1 2 1 2
( , )
( , ,..., , , ,..., )
( , ) ( , )
N N
i j k k
i j k
p x x x y y y
x x x y
=
∏ Ψ ∏Φ  (1) 
 
where Ψ and Φ are the pair-wise compatibility 
functions learned; i and j are neighboring 
nodes; and N is the total number of patches in 
each subband.  
To estimate ˆ jx , which is the best match 
one of each patch, we adopt the MAP 
estimation described in [7] to  take the 
maximum over  the other variables in the 
posterior probability.  
 
1 1[ , ]
ˆ arg max max ( ~ , ~ )
ij
jMAP N Nall x i jx
x p y y x x
≠
= (2) 
According to the conditional probability 
and Bayes’ theorem, the posterior probability 
can be written as  
 
( , )
( , )( | )
( )
1 ( , ) ( , )i j k kki j
p x yp x y
p y
x x y x
Z
= =
Ψ Φ∏
,    (3) 
 
where Z is a normalization constant, therefore 
the probability of any given transformed patch 
for each node is proportional to the product of 
the pair-wise compatibility functions. 
In this Markov network, the relationship 
between the observation node and the hidden 
node is modeled by Ψ, and the relationship 
between the neighboring hidden nodes is 
modeled by Φ. In our work, we use Ψ to find 
the best matching one of each patch from 
training data, and Φ is used to make sure the 
neighboring patches connect with each other. 
The compatibility function Φ(x, y) is used to  
 
Fig. 5. Further results. 
 
corresponding eigenvalue of the eigenvector 
in our system. The compatibility function 
between the hidden nodes is defined as 
 
2 2
2| | / 2( , ) ji ijd di jx x e
σψ − −=
 
(5) 
where dij denotes the pixels in the overlapping 
region between node i and j, and σ2 is the 
standard deviation of the overlapping region. 
The pixels in the overlapping region should 
agree to guarantee that neighboring nodes are 
compatible.  The best match for each search 
vector is obtained by solving these 
compatibility functions. 
 
4. Experimental Results 
To evaluate the performance of the proposed 
SR system, a training database was compiled 
comprising 100 images. Although the figures 
presented in this study feature facial images, 
the current SR system is not limited to the 
processing of a specific class of images. 
Hence, a general training database was 
constructed containing images from the CMU 
PIE database, a self-compiled database of 
facial images, and the Internet, respectively. 
Note that the images were not pre-processed 
in any way. 
Increasing the patch size to 5×5 pixels was 
found to generate no significant improvement 
in the enlargement results. Typical 
experimental results obtained when processing 
facial images are shown in Fig. 3. In general, 
super-resolution can be performed using a 
variety of interpolation techniques, including 
the nearest-neighbor, bi-linear and bi-cubic 
spline schemes [10]. In the current study, the 
enlargement results obtained using the 
proposed SR system are compared with those 
obtained from the bi-cubic spline interpolation 
method. As shown in Figs. 4 and 5, the 
reconstruction results generated by the SR 
method are both quantitatively and 
qualitatively superior to those obtained using 
the interpolation technique. 
 
