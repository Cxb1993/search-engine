 I
中文摘要 
自動化文件摘要(Automated Text Summarization)之研究，探討如何分析、統
整與萃取文件中重要的資訊，並以簡明的形式呈現，可作為使用者或其他資訊系
統的判斷與決策依據。過去關於文件摘要的研究，大多著眼於單文件摘要。近來，
多文件摘要愈顯得重要。多文件摘要與單文件摘要最大的差異，在於過濾重複的
資訊(Anti-redundancy)，同時須避免重要資訊的流失。 
本計畫為三年期研究案，目的在於研究多文件自動摘要(Multidocument 
Summarization)、跨語言多文件摘要(Cross-Language Multidocument Summarization)
與使用者問答導向摘要(Query-Focused Multidocument Summarization)技術。 
z 第一年計畫: 多文件摘要技術之研究 
計畫目的在於研究並發展多文件自動摘要的技術，探討如何導出文件的結
構、如何組織文件的內容及如何表示所抽取出文件抽象涵義等議題。我們考量相
關文獻所提多文件摘要的方法之優缺點，並以先前我們所發展之單文件摘要方法
為基礎，加以改進以適用於多文件摘要。 
我們利用潛在語意分析(Latent Semantic Analysis, LSA)與主題關係地圖(Text 
Relationship Map)作為多文件分析模型。此模型將每個語句視為圖(Graph)中的一
個點，兩兩語句若相似度大於臨界值，則彼此間具有一連結，其中語句相似度的
計算採用 LSA 所倒出的概念空間模型，以達到具有語意判別的相似度計算。根
據主題關係地圖模型，我們提出兩種段落重要性評估模型，分別為 1) Global 
Bushy Path；2) Aggregate Similarity。依據上述兩種計算重要性的模型，我們修改
Maximal Marginal Relevance，提出新的摘要段落挑選方式，以達到多文件中去除
重複性(Redundancy)的要求。 
實驗評估採用 ROUGE 來計算專家所產出的摘要與機器所產出摘要中，平均
包含有多少個相同的字。我們以 ROUGE-1 為評估標準，實驗結果顯示 Model 1
獲得平均 ROUGE-1 分數為 0.3564，Model 2 獲得平均 ROUGE-1 分數為 0.3497。
比較 DUC 2003 的比賽結果，我們的方法亦有不錯的表現，約在中等以上。 
z 第二年計畫: 中英文多文件摘要技術之研究 
計 畫 目 的 在 於 發 展 多 語 多 文 件 摘 要 (Multilingual Multidocument 
Summarization)技術。研究內容著重於中英文混合式多文件摘要，研究議題為如
何跨越語言型態及結構的障礙，提出計算中英文語句相似度的方法。 
 
 III
英文摘要 
Automated text summarization investigates the process of extracting the most 
important information from a source (or sources), and presenting a summary to the 
user. In the past, much related work only focuses on single-document summarization. 
Multi-document summarization obtains increasing attentions in recent years. The 
distinction between single and multi-document summarization is that the latter has to 
handle anti-redundancy and to keep salient information meanwhile.  
This project is composed of three parts and was conducted in the past three years. 
The goal of this research is to investigate and develop the techniques focusing on 
multidocument summarization, cross-language multidocument summarization, and 
query-focused multidocument summarization. 
z The First-Year Project: A Study on Multidocument Summarization 
This principal objective of this project is to develop new approaches to address 
multi-document summarization. The research includes 1) Conceptual Modeling and 
Representation for Multiple Documents, 2) Paragraph Significances Measurement, 
and 3) Content Ordering for the summary. 
We exploit latent semantic analysis and text relationship map to derive 
conceptual model (or a graph model) for multiple documents. Based on the model, we 
propose two approaches to measure the significance of a paragraph. They are 1) 
Global Bushy Path, and 2) Aggregate Similarity. Moreover, we propose a novel 
paragraph re-ranking approach on the basic foundation of Maximal Marginal 
Relevance to extract salient paragraphs.  
The evaluation metric used in this project is ROUGE, which is the official 
evaluation tool at DUC 2004. We report ROUGE-1 as the official score for each 
proposed models. Model 1 obtained a value of 0.3564 while Model 2 obtained a value 
of 0.3497 for ROUGE-1. When compared with the official results at DUC 2003, our 
proposed methods are at the average position and obtained competitive results. 
z The Second-Year Project: A Study on Cross-Language Multidocument 
Summarization 
The principal objective of this project is to develop novel techniques to address 
multilingual, multidocument summarization. The main issue is to propose a method to 
compute the similarity between two short passages which are written in different 
languages. 
 V
目錄 
中文摘要 ……………………………………………………………………... I
英文摘要 ……………………………………………………………………... III
目錄 …………………………………………………………………………... V
圖目錄 ………………………………………………………………………... VI
表目錄 ………………………………………………………………………... VII
計畫概述 …………..…..……………………………………………………... 1
執行成果 ……………………………………………………………………... 2
參與人員 ……………………………………………………………………... 4
計畫分年報告 
第一年計畫報告 ……………………………………………………………... 5
第二年計畫報告 ……………………………………………………………... 37
第三年計畫報告 ……………………………………………………………... 60
著作發表 ……………………………………………………………………... 80
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 VII
表目錄 
Table 1: 參與人員及執行工作列表.............................................................................4 
Table 2: 研究項目與相關技術...................................................................................10 
Table 3: MMR-MD 中 Sim1 及 Sim2 的計算方式 .......................................................18 
Table 4: SIG 與 REL 的計算方式 ...............................................................................27 
Table 5: Model 1 的實驗結果 (ROUGE-1 Average) .................................................29 
Table 6: Model 2 的實驗結果 (ROUGE-1 Average) .................................................29 
Table 7: DUC 2003 的部分 Official Results ...............................................................30 
Table 8: General 詞群結果舉例 ..................................................................................52 
Table 9: Specific 詞群結果舉例..................................................................................53 
Table 10: 測試集文件群分析.....................................................................................53 
Table 11: 測試集中相異詞數目及其於平行語料庫中的涵蓋比例.........................54 
Table 12: Top10 相似度高之中英段落中正確對應數目...........................................54 
Table 13: 中英對照例一.............................................................................................55 
Table 14: 中英對照例二.............................................................................................55 
Table 15: 中英對照例三.............................................................................................55 
Table 16: 摘要資訊量涵蓋度及可讀性評估.............................................................56 
Table 17: 事件群 6 之摘要內容範例.........................................................................56 
Table 18: DUC 2005 example queries .........................................................................63 
Table 19: Settings of different models .........................................................................75 
Table 20 Parameter settings .........................................................................................75 
Table 21: recalls of ROUGE-2 and ROUGE-SU4.......................................................76 
 
 
 2
執行成果 
第一年成果 
第一年的研究內容著重於如何判別文件主題及抽取具有代表性的語句作為
候選摘要語句。 
我們考量相關文獻所提多文件摘要的方法之優缺點，並以先前我們所發展之
單文件摘要方法為基礎，加以改進以適用於多文件摘要。首先，我們利用潛在語
意分析(Latent Semantic Analysis, LSA)與主題關係地圖(Text Relationship Map)作
為多文件分析模型。此模型將每個語句視為圖(Graph)中的一個點，兩兩語句若
相似度大於臨界值，則彼此間具有一連結，其中語句相似度的計算採用 LSA 所
倒出的概念空間模型，以達到具有語意判別的相似度計算。 
根據主題關係地圖模型，我們提出兩種段落重要性評估模型，分別為 1) 
Global Bushy Path；2) Aggregate Similarity。其中 Global Bushy Path 以圖中各個點
所具有的連結數當作其重要性(Significance)；Aggregate Similarity 類似於 Global 
Bushy Paht，不同之處在於其計算所有連結的相似度總合，作為每個點重要性。
根據上述兩種計算重要性的模型，我們修改 Maximal Marginal Relevance，提出
新的摘要段落挑選方式，以達到多文件中去除重複性(Redundancy)的要求。 
實驗評估採用 ROUGE 來計算專家所產出的摘要與機器所產出摘要中，平均
包含有多少個相同的字。我們以 ROUGE-1 為評估標準，實驗結果顯示 Model 1
獲得平均 ROUGE-1 分數為 0.3564，Model 2 獲得平均 ROUGE-1 分數為 0.3497。
比較 DUC 2003 的比賽結果，我們的方法亦有不錯的表現，約在中等以上。 
第二年成果 
第二年的研究內容著重於中英文混合式多文件摘要，研究議題為如何跨越語
言型態及結構的障礙，提出計算中英文語句相似度的方法。 
我們提出一套中英概念空間擷取的方法。基於中英雙語平行語料庫
(Chinese-English Parallel Corpus)，進行中英文詞分群(Word Clustering)，以建立階
層式概念空間(Hierarchical Concept Space)。接著，將中英文語句對應至該階層式
概念空間中，透過此對應關係，可將關鍵詞向量空間表示式(Keyword-Level Vector 
Representation) 轉 換 至 概 念 向 量 空 間 表 示 式 (Concept-Level Vector 
Representation)。最後，於相同的概念空間中，便可計算任兩中中、中英及英英
語句的概念相似度。 
 4
參與人員 
Table 1: 參與人員及執行工作列表 
計畫項目 參與人員 服務單位 職稱 擔任工作 
第一年計畫 
第二年計畫 
第三年計畫 
楊維邦 國立交通大學 
資訊科學學系 
國立東華大學 
資訊管理學系 
教授 計畫主持人 
第一年計畫 
第二年計畫 
第三年計畫 
柯皓仁 國立交通大學 
資訊管理研究所 
教授 計畫參與人員 
第一年計畫 
第二年計畫 
第三年計畫 
葉鎮源 國立交通大學 
資訊科學學系 
博士生 文獻蒐集研讀、理論分
析、演算法設計及評估
方法設計 
第一年計畫 謝佩原 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
第一年計畫 梁哲瑋 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
第一年計畫 鄭佳彬 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
第二年計畫 劉政璋 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
第二年計畫 顧世彥 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
第二年計畫 王瓊婉 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
第三年計畫 林昕潔 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
第三年計畫 張家寧 國立交通大學 
資訊科學學系 
碩士生 文獻蒐集研讀、協助演
算法設計與實作 
 
 
 
 6
中文摘要 
自動化文件摘要(Automated Text Summarization)之研究，探討如何分析、統
整與萃取文件中重要的資訊，並以簡明的形式呈現，可作為使用者或其他資訊系
統的判斷與決策依據。過去關於文件摘要的研究，大多著眼於單文件摘要。近來，
多文件摘要愈顯得重要。多文件摘要與單文件摘要最大的差異，在於過濾重複的
資訊(Anti-redundancy)，同時須避免重要資訊的流失。另外，摘要內容排序(Content 
Ordering)，亦是多文件摘要必須探討的議題。 
本計畫為三年期研究案『多語言複合式文件自動摘要之研究』之第一年計
畫。本年度計畫之目的，在於研究並發展多文件自動摘要的技術，將探討如何導
出文件的結構、如何組織文件的內容及如何表示所抽取出文件抽象涵義等相關議
題。研究範疇包含：1) 文件模型的建構及表示；2) 文件主題偵測及重要性評估；
3) 摘要內容組織及排序。我們利用潛在語意分析(Latent Semantic Analysis)與主
題關係地圖(Text Relationship Map)作為多文件分析模型，提出兩種段落重要性評
估模型，分別為 1) Global Bushy Path；2) Aggregate Similarity。根據上述模型，
我們採用 Maximal Marginal Relevance，提出新的摘要段落挑選方式。 
實驗評估採用 ROUGE 來計算專家所產出的摘要與機器所產出摘要中，平均
包含有多少個相同的字。我們以 ROUGE-1 為評估標準，實驗結果顯示 Model 1
獲得平均 ROUGE-1 分數為 0.3564，Model 2 獲得平均 ROUGE-1 分數為 0.3497。
比較 DUC 2003 的比賽結果，我們的方法亦有不錯的表現，約在中等以上。 
關鍵詞：多文件自動摘要；潛在語意分析；主題關係地圖 
 
 
 
 
 8
1. 研究背景及目的 
今日電腦與資訊技術蓬勃發展的數位時代，網際網路已成為現代生活中不可
或缺的重要角色，更帶動人類文明往新的資訊紀元(Information Era)推進。拜科技
之賜，各種媒體資料的數位化；透過網際網路管道，大量且豐富的數位內容(Digital 
Content)得以無遠弗屆地傳播。就現況而言，各式各樣的資訊於網際網路中流通，
資訊的傳播不再單純藉由傳統平面媒體，人們亦漸漸習慣經由網路找尋所要的資
料。資訊的蒐集變得方便，然而亦衍生相關問題，如「資訊爆炸(Information 
Explosion)」。 
龐大的資訊量，使得搜尋及辨別有用資訊的困難度大幅提昇，如何快速且有
效地獲得真正符合自身需求的資訊，亦是目前熱門的研究議題。為解決此類問
題，使用者藉由輔助工具的幫助，得以快速獲知資料的意涵，期能正確地判斷是
否符合自身的需求。相關的輔助工具有：1) 搜尋引擎(Search Engine)及 2) 自動
摘要系統 (Automated Summarization)。其中，搜尋引擎扮演『資訊過濾器
(Information Filter)』的角色，其功用乃是分析檢索條件(Query)，搜尋與檢索條件
相關的資料；自動摘要系統則扮演『資訊監督者(Information Spotter)』的角色，
其功用在於分析、統整相關的資料，以簡明的形式呈現，以幫助使用者在最短時
間得知資料內容的意義[20]。 
自動摘要系統依原始資料之性質可分為： 
z 文件摘要(Text Summarization) – 原始資料為純文字。 
z 多媒體摘要(Multimedia Summarization) – 原始資料為影像及聲音。 
z 複合性摘要(Hybrid Summarization) – 原始資料綜合純文字和多媒體。 
本年度研究計畫主要著重於文件摘要技術的研發。以下深入針對何謂文件自
動化摘要，技術起源與發展，與摘要類型等作一詳盡介紹。 
1.1. 文件摘要介紹 
根據 Mani 與 Maybury 為文件自動摘要所下的定義[34]，自動化文件摘要乃
是從原始資料中精鍊出最重要資訊的過程，其結果即為該原始資料的精簡化版
本，且可作為人們或其他資訊系統的判斷與決策依據。 
Text summarization is the process of distilling the most important 
information from a source (or sources) to produce an abridged version for a 
particular user (or users) and task (or tasks). 
 10
由語言的角度來看，文件摘要亦可分為單語言文件摘要 (Mono-lingual 
Summarization)與多語言文件摘要(Multi-lingual Summarization)。多語言文件摘
要，如[55][10][57][29]。多語言摘要係指文件來源可能為不同語言或單文件中包
含不同語言等，此類摘要著重於克服各語言在型態、結構及用語習慣的差異，並
提供各語言間互相轉譯的能力。 
1.2. 研究目的與範疇 
本計畫為三年期研究案『多語言複合式文件自動摘要之研究』之第一年計
畫。本年度計畫之目的，在於研究並發展多文件自動摘要的技術，將探討如何導
出文件的結構、如何組織文件的內容及如何表示所抽取出文件抽象涵義等相關議
題。研究範疇包含： 
1. 文件模型的建構及表示 
2. 文件主題偵測及重要性評估 
3. 摘要內容組織及排序 
針對以上所述研究項目，我們採用先前研究單文件摘要所提出的方法 – 
LSA-based T.R.M. Approach [52]為基礎，加以改良以適用於多文件摘要的研究，
同時提出兩種評估段落(或語句)重要性的模型。同時，考慮到多文件摘要必須去
除重複性(Redundancy)的議題，我們利用 Maximum Marginal Relevance (MMR) [8]
來達成此目的。於第三章中，將對我們所提的摘要技術作詳盡的介紹。以下僅就
上述研究項目，整理所對應的採用方法。 
Table 2: 研究項目與相關技術 
研究項目 相關技術 
文件模型的建構及表示 1) Latent Semantic Analysis 
2) Text Relationship Map 
文件主題偵測及重要性評估 1) Global Bushy Path 
2) Average Similarity 
摘要內容組織及排序 MMR 
2. 相關研究 
近年來網際網路興起後，文件摘要從 80 年代的蟄伏期復甦又蓬勃發展起
來。總括而言，大部分文件摘要之研究著重於單文件摘要。目前的研究涵蓋資訊
擷取(Information Retrieval)與自然語言處理(Natural Language Processing)等技
術，除詞性分析、詞組分析，更運用 WordNet [39]等領域知識(Domain Knowledge)
 12
哥倫比亞大學亦針對新聞文章發展 Columbia Summarizer [36]。該系統依據
不同類型的文件整合不同的摘要技術，定義文件類型分為 1) 單一事件(Single 
Event)；2) 相關多事件(Multiple Related Event)；3) 傳記(Biography)；4) 相關事
件的討論議題(Discussion Issue)等。Figure 2 為該系統的系統架構圖，共分為三個
部分：Preprocessing、Routing 及 Summarizer Module。Preprocessing 將輸入的文
件轉換成統一的 XML 格式；Router 則依據輸入文件的類型轉送給適當的摘要
器；MultiGen [37]處理具有相同事件的文件集；DEMS (Dissimilarity Engine for 
Multi-document Summarization) [49]則依據輸入文件的特徵分析，處理多事件及傳
記等類型的摘要。目前，該系統已整合於線上新聞摘要系統 NewsBlaster [11]，
提供每日新聞主題偵測、追蹤及摘要服務。 
 
Figure 2: Columbia Summarizer 系統架構[36] 
 
 
Figure 3: GLEANS 系統架構圖[13] 
 
 14
 
Figure 4: GISTexter 系統架構[21] 
馬里蘭大學發展適用於大型文件集(Large Corpus)的摘要系統，名為 XDoX 
[23]，其處理的文件集大小約為 50-500 篇文章。該系統利用分群技術(Clustering)
將文件集分為幾個有意義的主題，接著以段落為單位，依據段落與主題群集的相
關程度作分類，最後依據不同的群集產生摘要，其流程如 Figure 5 所示。另外，
XDoX 提供使用者兩種不同的摘要結果，一為詳細的摘要，提供較豐富的資訊；
另一個則依據使用者的需求，如壓縮比等等，提供資訊量較少的摘要。 
 
Figure 5: XDoX 系統架構[23] 
 16
LSA+T.R.M.利用潛在語意分析(Latent Semantic Analysis)技術，以擷取文件
概念結構(Conceptual Structure)，即語意矩陣(Semantic Matrix)，可達到進行語意
層面分析之目的。同時，利用語意矩陣導出語句表示式(Sentence Representation)，
以建構主題相關地圖(Text Relationship Map)。最後，透過主題相關地圖，篩選重
要的語句成為摘要。針對語意矩陣的建構，我們考量單文件層面(Single-document 
Level)及文件集層面(Corpus Level)，並比較兩種模式之適用性。實驗收集 100 篇
關於政治類的中文文件。實驗結果顯示，我們所提的方法有良善的表現。當壓縮
比(Compression Ratio)為 30%時，平均而言，F-measure 為 0.4242。 
2.1. 文獻探討 
2.1.1. MEAD[38] 
MEAD [38]接受分群過後的文件集4，以語句(Sentence)為單位，針對每個文
件群(Document Cluster)抽取出具有代表性的語句為摘要。方法如 Figure 6 所示。
MEAD 考慮文件群中每個語句與群中心(Centroid)的相關度、語句的位置及該語
句與所屬文件中首句的相似度，以評估每個語句的重要性。同時對每個文件群抽
取出 ni*r 個語句，以組成摘要；其中，ni代表 Clusteri中語句的總數，r 代表壓縮
比。 
 
Figure 6: MEAD 運作原理示意圖 
評估語句的重要性，MEAD 考慮以下三個特徵，分別為 1) 語句所在的文件
群；2) 語句於文件中的位置，通常出現在文件中的首句可視為代表整篇文章，
因此加重這些語句的重要性；3) 語句如果與首句有關的話，亦加重該語句的重
要性。最後，MEAD 以線性組合(Linear Combination)綜合地評估語句的重要性，
如 Eq. (1)： 
 
                                                 
4 MEAD 接受相關的文件集，以產生摘要。然此處所提及之相關文件集，實為考慮 loosely-related 
documents。 
… 
Cluster1 Cluster2 Cluster3 
n1*r n2*r n3*r#(Sentence): 
 18
)],(max)1(),([max 21\ jiSSiSRS
def
SSSimQSSimArgMMR
ji ∈∈
−−= λλ  Eq. (2)
其中，S 代表以挑選出的語句集合，Si代表某個語句，Q 代表 Query，Sim1(Si,Q)
計算 Si與 Q 的相似度，Sim2(Si,Sj)計算 Si與 Sj的相似度。 
Table 3: MMR-MD 中 Sim1及 Sim2的計算方式[19] 
MMR-MD [19]延伸 MMR 的概念，針對多文件摘要提出適合的排序方式。
主要目標是使摘要語句對文件的主題和 Query 有極高的相似度，同時能夠降低摘
要中具有重覆意思的段落數目。MMR-MD 同時考慮到時間順序、專有名詞、對
主題的相似度以及代名詞的 Penalty。其挑選段落的方式，如 Eq. (3)： 
 20
1) Common = {c | concept_match(c, G1) & concept_match(c, G2)} 
2) Differences = (G1 ∪ G2) – Common 
concept_match(c, G) is true iff c1 ∈ G such that c1 is a topic term or c and c1 are 
synonyms. 
最後，透過分析 Common 及 Difference 中的關鍵詞，計算語句的重要性，並
挑選出重要的語句當成摘要結果。語句重要性的計算方式，如 Eq. (4)： 
∑= ∩∈== |)(| 1 }|{)(),(|)(| 1)( sci i sCommonwwscwherewweightscsscore  Eq. (4)
3. 研究方法 
我們以先前研究單文件摘要所提出的方法 – LSA-based T.R.M. Approach 
[52]為基礎，加以改良以適用於多文件摘要的研究，同時提出段落重要性評估的
三種模型。本節中，首先介紹潛在語意分析(Latent Semantic Analysis) [28]與主題
關係地圖(Text Relationship Map) [48]，最後說明我們所提出的多文件摘要技術模
型 – LSA-based MD-T.R.M. Approach。 
3.1. 潛在語意分析 (Latent Semantic Analysis) 
潛在語意分析 (Latent Semantic Analysis) [28]為以數學統計為基礎的知識模
型，其運作方式與類神經網路(Neural Net)相似。不同的是類神經網路以權重的傳
遞(Propagation)與回饋(Feedback)修正本身的學習；潛在語意分析則以奇異值分解
(Singular Value Decomposition, SVD)與維度約化(Dimension Reduction)為核心作
為邏輯推演的方式，其原理如 Figure 8 所示。 
潛在語意分析將文件或文件集表示為矩陣，透過 SVD 將文件所隱含的知識
模型，抽象轉換到語意空間(Semantic Space)，再利用維度約化萃取文件知識於語
意空間中重要的意涵。整個過程除可以將隱含的語意顯現出來外，更能將原本輸
入的知識模型提升到較高層次的語意層面。 
潛在語意分析的應用非常廣泛，包含資訊擷取、同義詞建構、字詞與文句相
關性判斷標準、文件品質優劣的判別標準及文件理解與預測等各方面的研究。 
 22
(Semantic Related Link)。依此原則可以建構出所有文件間的關係地圖。舉例來
說，Figure 9 中編號 17012 及 17016 的文章，二者的相似程度約 0.57，大於臨界
值 0.01，所以存在連結關係；而 8907 與 22387 的相似度則低於臨界值，因此於
主題關係地圖中並不存在連結。一般來說，具有連結的文章，可說它們之間具有
關聯性。 
[48]將主題關係地圖的概念應用於單文件摘要研究。以每個段落(Paragraph)
為單位計算兩兩段落的相似度，建構主題關係地圖7。當某個節點具有的連結數
愈多，則代表該節點所對應的段落和整篇文件中主題的相關度愈高。[48]依據連
結數目的多寡來決定摘錄段落順序，並提出以下三種方法以產生單文件摘要： 
1. Global Bushy Path 
首先定義任一節點的 Bushiness 為該節點與其他節點的連結數目；擁有
越多關聯連結的節點，表示該節點所對應的段落與其他段落所討論的主題相
似，因此，該段落可視為討論文件主題的段落。Global Bushy Path 將段落依
照原本出現在文件中的順序以及其連結個數由大而小的排列。接著，挑選排
名前 K 個段落(Top-K)，即為該文件的摘要。 
2. Depth-first Path 
Depth-first Path 選取某個節點 – 可能為第一個節點或是具有最多連結
的節點，接著每次選取於原始文件中順序與該節點最接近且與該節點相似度
最高的節點當作下一個節點，依此原則選取出重要而且連續的段落以形成文
件摘要。 
3. Segmented Bushy Path 
Segmented Bushy Path 分為兩個步驟，首先分析文件結構進行文件結構
切割(Text Segmentation)。接著針對每個 Segmentation 個別利用 Global Bushy 
Path 來選取重要的段落。為了保留所有 Segmentation 的內容，每個
Segmentation 至少要挑選出一個段落納入最後的摘要。 
                                                 
7 地圖上每個節點為文件中的某個段落；兩節點的連結，則表示兩節點的相似度大於臨界值。 
 24
表性，以篩選不具代表性之特徵，計算方式如 Eq. (5)9： 
)()(
),(),(
ypxP
yxPyxMI =  Eq. (5)
其中，x 與 y 為相鄰之兩個單字詞10，P(x)為 x 出現於文件集的個數，P(y)為
y 出現於文件集的個數，P(x, y)則為 x 與 y 共同出現的個數。為了更進一步篩選
出具有代表性的特徵，針對每個特徵計算其 IDF (Inverse Document Frequency) 
[3]，其計算如 Eq. (6)所示： 
n
NwIDF j log)( =  Eq. (6)
其中，wj 為一特徵關鍵詞，N 為文件集中段落的總數，n 為 wj 出現的段落總數。
當 IDF 值大於預設的臨界值，則表示該特徵具有代表性。 
 特徵擷取 
每個特徵的重要性，除了考慮每個特徵關鍵詞於段落出現的頻率外，亦考慮
每個特徵關鍵詞於文件集中的重要程度。定義其權重為 Kij，其計算如 Eq. (7)： 
ijiij LGK *=  Eq. (7)
假設文件集中段落的集合為 P = {Pj | Pj代表某一 Pk,l，即文件 Dl中 Pk 段落}，
Gi代表特徵關鍵詞 Wi於 P 集合中的分佈權重，Lij代表 Wi在 Pj中的分佈權重。
假設 cij為 Wi出現在 Pj中的次數，tj為 Wi出現在 P 集合中的次數，則 Wi在 Pj 中
的相對頻率計算方式如 Eq. (8)：  
i
ij
ij
t
cf =  Eq. (8)
接著，考慮 P 集合中 Wi的資訊分佈量(Entropy)，計算方式如 Eq. (9)： 
( ) ( )∑=−=
N
j
ijji ffi
N
E
1
log*
log
1
 
Eq. (9)
由 Eq. (9)可知當 fij等於 1 的時候，Ei的值為 0；當 fij等於 1/N 的時候，Ei的
值為 1。當 Ei的值越接近於 1 的時候，表示 Wi在 P 集合中的分佈越平均，Wi的
重要性便會降低；相反地，如果 Ei的值越接近 0 的時候，表示 Wi只出現在某些
                                                 
9計算三字詞之 MI 值則為 MI(x, y, z)。 
10 考慮二字詞或三字詞時，以段落為 window。 
 26
 Model 1: Global Bushy Value 
Global Bushy Value (GBV)12為主題相關地圖上任一節點與其他節點間
的連結數目；定義如 Eq. (12)所示，其中，Pi 為主題地圖上一節點。由此可
知，擁有越多關聯連結的節點，表示該段落與其他段落的寫作與用字方式相
似，並且討論的主題也相似，因此，該段落視為討論主題的段落。 
∑
∀
=
ijj PPP
iPGBV
link with  a has ,
1)(  Eq. (12)
 Model 2: Average Similarity 
相較於 Model 1 只考慮到主題相關地圖上每個節點的連結個數，我們參
考[26]，並考慮每個連結權重的方式，以 Aggregate Similarity 計算每個節點
的重要性，Aggregate Similarity 的示意圖如 Figure 11： 
 
Figure 11: 計算 Aggregate Similarity 的概念圖示[26] 
圖中的每個節點代表某個段落的向量表示法，每個連結代表兩個語句間
的相似度，任兩個語句的相似度即是計算相對應向量間的內積值。Aggregate 
Similari 之計算如 Eq. (13)： 
( ) ( )∑
≠∀
=
ilink with  a has 
,
PP
PP
jii
j
ij
PPsimPAvgSim  
Eq. (13)
其中，sim(Pi, Pj)為兩個節點間的相似度，即是計算相對應向量間 Cosine 值。
計算每個節點的 Aggregate Similarity，其好處在於除了考慮到每個節點的連
結個數，同時亦考慮到每個連結的權重值。 
                                                 
12 即[48]中定義之 Bushiness 值。 
 28
4. 結果與討論 
4.1. 測試資料集 
實驗中以 DUC (Document Understanding Conference)的 DUC 2003 資料為測
試對象，該年度的評比共分為四個項目：1) Task 1 – Very short summaries; 2) Task 
2 – Short summaries focused by events; 3) Task 3 – Short summaries focused by 
viewpoints; 4) Task 4 – Short summaries in response to a question。其中 Task 2 及
Task 3 為多文件摘要評比，然而因為我們所發展的摘要技術針對新聞事件多文件
摘要而設計，因此，我們使用 Task 2 的資料作為評估演算法好壞的資料集。 
Task 2 所提供的資料共有 30 個文件群(Document Clusters)，每個文件群中各
有約 10 篇新聞文章，且這 10 篇新聞文件皆是討論相同的新聞事件發展。Task 2
要求每個參與比賽的系統針對這 30 個文件群各產生約 100 字的摘要14。 
4.2. 評估方法 
DUC 從 DUC 2004 起採用 ROUGE (Recall-Oriented Understudy for Gisting 
Evaluation)[58]為評估工具，因此我們亦已該工具來評估演算法的好壞。DUC 
2003 的資料中，每個文件群皆由四個專家閱讀過所有文章後，針對該文件群所
討論的事件主題等資訊，以人工方式產出約 100 字的短摘要。ROUGE 以專家所
產出的摘要當參考答案，對照機器所產出的摘要內容，主要計算有平均有多少個
Word 被專家與機器所產生的摘要所共同包含。 
ROUGE 的評估主要有 ROUGE-1, ROUGE-2, …, ROUGE-N, ROUGE-L, 
ROUGE-WL。ROUGE-N 以 N 個字為單位計算 Recall 值, 如 ROUGE-2 為以
Bigram 為單位時所得到的 Recall。ROUGE-L 以 common string 為單位計算
Recall，ROUGE-WL 則為加權過後的 ROUGE-L。目前已經證明 ROUGE-1 的評
估分數比較接近專家所給定的評估分數，因此我們僅列出 ROUGE-1 的分數。 
4.3. 實驗結果 
實驗的參數設定，Model 1 的 α 值(亦即 Table 4 中的 α 值)動態設定為該 Pi
與目前所產生摘要段落集合中具有連結的 Pj個數。Eq. (14)中的 λ 值則設定為 0
到 50，以比較各種不同 λ值下對於摘要好壞的影響。 
                                                 
14 小於 100 字不予加分；多於 100 字則需先縮減為 100 字後再由評估工具計算分數。 
 30
Table 7: DUC 2003 的部分 Official Results 
SYSID ROUGE-1 SYSID ROUGE-1 
B 0.4467 17 0.3606 
C 0.4451 6 0.3598 
D 0.4358 20 0.3475 
E 0.4201 14 0.3362 
A 0.4149 23 0.3339 
H 0.4109 18 0.3297 
I 0.4001 21 0.3267 
G 0.3956 3 0.3170 
12 0.3918 2 0.3090 
F 0.3918 11 0.3068 
J 0.3883 19 0.3057 
16 0.3747 15 0.2943 
13 0.3698 10 0.2905 
26 0.3627 22 0.2565 
 32
參考文獻 
[1] Aone, C., Okurowski, M. E., Gorlinsky, J., & Larsen, B. (1999). A trainable 
summarizer with knowledge acquired from robust NLP techniques. Mani, I., & 
Maybury, M. (eds.), Advances in automated text summarization. Cambridge, 
Mass.: MIT Press. 
[2] Azzam, S., Humphreys, K., & Gaizauskas, R. (1999). Using coreference chains 
for text summarization. In Proceedings of the ACL’99 Workshop on Coreference 
and Its Application, Baltimore. 
[3] Baeza-Yates, R., & Ribeiro-Neto, B. (1999). Modern information retrieval. 
Harlow, UK: Addison-Wesley Longman Co Inc. 
[4] Barzilay, R., & Elhadad, M. (1997). Using lexical chains for text summarization. 
In Proceedings of the ACL/EACL’97 Workshop on Intelligent Scalable Text 
Summarization, Madrid, Spain (pp. 10-17). 
[5] Barzilay, R., McKeown, K. R., & Elhadad, M. (1999). Information fusion in the 
context of multi-document summarization. In Proceedings of the 37th 
Conference on Association for Computational Linguistics (ACL’99), College 
Park, Maryland, MD, USA (pp. 550-557). 
[6] Bellegarda, J. R., Butzberger, J. W., & Chow, Y. L. (1996). A novel word 
clustering algorithm based on latent semantic analysis. In Proceedings of IEEE 
International Conference on Acoustics, Speech, and Signal Processing, Vol. 1 
(pp. 172-175). 
[7] Boros, E., Kantor, P. B., & Neu, D. J. (2001). A clustering based approach to 
create multi-document summaries. In Proceedings of the Document 
Understanding Conference (DUC-2001), New Orleans, LSA, USA. 
[8] Carbonell, J., & Goldstein, J. (1999). The use of MMR, diversity-based 
reranking for reordering documents and producing summaries. In Proceedings of 
the 21st Annual International ACM SIGIR Conference on Research and 
Development in Information Retrieval (SIGIR’98), Melbourne, Australia (pp. 
335-336). 
[9] Chen, C. H., Basu, K., & Ng, T. (1994). An algorithmic approach to concept 
exploration in a large knowledge network. Technical report, MIS Department, 
University of Arizona, Tucson, AZ, USA. 
[10] Chen, H. H., & Lin, C. J. (2000). A multilingual news summarizer. In 
Proceedings of the 17th Conference on Computational Linguistics, Saarbrücken, 
Germany (pp. 159-165). 
[11] Columbia Newsblaster: summarizing all the news on the web. Available at 
http://www1.cs.columbia.edu/nlp/newsblaster. 
 34
Mani, I., & Maybury, M. (eds.), Advances in automated text summarization. 
Cambridge, Mass.: MIT Press. 
[25] Karamuftuoglu, M. (2002). An approach to summarization based on lexical 
bonds. In Proceedings of the Document Understanding Conference (DUC-2002), 
Philadelphia, PA, USA. 
[26] Kim, J. H., Kim, J. H., & Hwang, D. (2000). Korean text summarization using an 
aggregate similarity. In Proceedings of the 5th International ACM Workshop on 
Information Retrieval with Asian Languages, Hong Kong, China (pp. 111-118). 
[27] Kupiec, J., Pedersen, J., & Chen, F. (1995). A trainable document summarizer. In 
Proceedings of the 18th Annual International ACM SIGIR Conference on 
Research and Development in Information Retrieval (SIGIR’95), Seattle, WA, 
USA (pp. 68-73). 
[28] Landauer, T. K., Foltz, P. W., & Laham, D. (1998). An introduction to latent 
semantic analysis. Discourse Processes, 25, 259-284. 
[29] Lenci, A., Bartolini, R., Calzolari, N., Agua, A., Busemann, S., Cartier, E., 
Chevreau, K., & Coch, J. (2002). Multilingual summarization by integrating 
linguistic resources in the MLIS-MUSI project. In Proceedings of the 3rd 
International Conference on Language Resources and Evaluation (LREC’02), 
Las Palmas, Canary Island, Spain. 
[30] Lin, C. Y. (1999). Training a selection function for extraction. In Proceedings of 
the 8th International Conference on Information and Knowledge Management 
(CIKM’99), Kansas City, MO, USA (pp. 55-62). 
[31] Lin, C. Y., & Hovy, E. (2002). NeATS in DUC 2002. In Proceedings of the 
Document Understanding Conference (DUC-2002), Philadelphia, PA, USA. 
[32] Luhn, H. P. (1958). The automatic creation of literature abstracts. IBM Journal of 
Research and Development, 2(2), 159-165. 
[33] Mani, I., & Bloedorn, E. (1999). Summarizing similarities and differences 
among related documents. Information Retrieval, 1(1-2), 35-67. 
[34] Mani, I., & Maybury, M. (eds.) (1999). Advances in automated text 
summarization. Cambridge, Mass.: MIT Press. 
[35] Maosong, S., Dayang, S., & Tsou, B. K. (1998). Chinese word segmentation 
without using lexicon and hardcrafted training data. In Proceedings of the 17th 
International Conference on Computational Linguistics (COLING’98) and the 
36th Annual Meeting of the Association for Computational Linguistics (ACL’98) 
(COLING-ACL’98), Montreal, Quebec, Canada (pp. 1265-1271). 
[36] McKeown, K. R., Evans, D., Nekova, A., Barzilay, R., Hatzivassiloglou, V., 
Schiffman, B., Blair-Goldensohn, S., Klavans, J., & Sigelman, S. (2002). The 
Columbia Multi-document Summarizer for DUC 2002. In Proceedings of the 
 36
[49] Schiffman, B., Mani, I., & Concepcion, K. J. (2001). Producing biographical 
summaries: combing linguistic knowledge with corpus statistics. In Proceedings 
of European Association for Computational Linguistics. 
[50] TIPSTER Text Summarization Evaluation Conference (SUMMAC). Available at 
http://www.itl.nist.gov/iaui/894.02/related_projects/tipster_summac. 
[51] Wacholder, N. (1998). Simplex NPs clustered by head: a method for identifying 
significant topics in a document. In Proceedings of Workshop on the 
Computational Treatment of Nominals, COLING-ACL, Montreal, Canada (pp. 
70-79). 
[52] Yeh, J. Y., Ke, H. R., & Yang, W. P. (2004). Text summarization using a trainable 
summarizer and latent semantic analysis. Information Processing & Management: 
Special Issue on ICADL 2002. Accepted and to be appeared. (Recommended by 
ICADL 2002). 
[53] Young, S. R., & Hayes, P. J. (1985). Automatic classification and summarization 
of banking telexes. In Proceedings of the 2nd Conference on Artificial 
Intelligence Applications (pp. 402-408). 
[54] Zhang, Z., Blair-Goldensohn, S., & Radev, D. R. (2002). Towards CST-enhanced 
summarization. In Proceedings of the 18th National Conference on Artificial 
Intelligence (AAAI’02), Edmonton, Alberta, Canada (pp. 439-445). 
[55] 陳鈺瑾 (2000). 可調式之中文文件自動摘要. 碩士論文, 國立清華大學資訊
工程研究所, 新竹, 台灣. 
[56] 黃聖傑 (1999). 多文件自動摘要方法研究. 碩士論文, 國立台灣大學資訊工
程研究所, 台北, 台灣. 
[57] 蘇哲君 (2001). 中英雙語多文件自動摘要系統研究. 碩士論文, 國立台灣大
學資訊工程研究所, 台北, 台灣. 
[58] Lin, C-Y. 2004. ROUGE: a Package for Automatic Evaluation of Summaries. 
Proc. of the Workshop on the Text Summarization Branches Out (WAS), 
Barcelona, Spain, 2004. 
 
 
 
 
 
 
 
 
 
 
 38
中文摘要 
本計畫為三年期研究案 – 多語言複合式文件自動摘要之研究之第二年計
畫，其研究目的在於發展多語多文件摘要 (Multilingual Multidocument 
Summarization)技術。研究內容著重於中英文混合式多文件摘要，研究議題為如
何跨越語言型態及結構的障礙，提出計算中英文語句相似度的方法。 
研究方法中，我們提出一套中英概念空間擷取的方法。基於中英雙語平行語
料庫(Chinese-English Parallel Corpus)，進行中英文詞分群(Word Clustering)，以建
立階層式概念空間(Hierarchical Concept Space)。接著，將中英文語句對應至該階
層式概念空間中，透過此對應關係，可將關鍵詞向量空間表示式(Keyword-Level 
Vector Representation) 轉 換 至 概 念 向 量 空 間 表 示 式 (Concept-Level Vector 
Representation)。最後，於相同的概念空間中，便可計算任兩中中、中英及英英
語句的概念相似度。 
中英混合式詞分群可抽取出中文詞與英文詞間的關連。當分群的群數目越多
時，位於詞群中的中英文詞可互為翻譯；當分群的群數目越少時，位於詞群中的
中英文詞可視為相關。透過階層式概念空間相似度的組合，可得不錯的中英語句
對應。實驗結果顯示，考慮 Top 10 組中英對應段落，平均 Precision 約 57%為相
關。摘要內容的評估，則由專家進行評比。平均而言，資訊量涵蓋度為 7.06，可
讀性為 6.04。(其中，1 代表最差，5 代表普通，10 代表最好。) 
關鍵詞：多語多文件摘要；中英文語句相似度；階層式概念空間；概念對應 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 40
1. 研究背景及目的 
文件自動摘要(Automated Text Summarization)乃是從原始資料中精鍊出最重
要資訊的過程，其結果即為該原始資料的精簡化版本，且可作為人們或其他資訊
系統的判斷與決策依據[15]。 
Text summarization is the process of distilling the most important information from 
a source (or sources) to produce an abridged version for a particular user (or users) 
and task (or tasks). 
相關的研究起源於 1950 年代，初期以分析文件格式(Genre)為主[5], [13]，接
著以模板(Template)來辨認人、事、時、地、物，以達到分析文件涵蓋主題的目
的[22]。從 1990 年代開始，資訊擷取(Information Retrieval)的技術開始被應用於
文件摘要上 [4], [8], [9], [27]，此時期亦是單文件摘要 (Single Document 
Summarization)研究的高峰期。單文件摘要將文件精簡化，著重於刪減無用資訊。 
自從 2000 年開始，因為網路的發達，使得人們每天所接受的資訊量過於龐
大，更有賴於文件自動摘要以幫助過濾資訊。此時期的研究主要偏重於多文件自
動摘要(Multidocument Summarization)；多文件摘要針對多篇描述相似主題的文
件(Topically-Related Documents)，研究議題為偵測多文件中所提及的相異及相同
主題，並過濾出現於多文件中的重複性資訊。具代表性的研究有[2], [7], [14], 
[16]。2002 年開始，多語言文件摘要(Multi-lingual Document Summarization)的研
究開始進行，如[3], [4], [6], [28]。多語言文件摘要係指文件來源可為不同語言所
描述的文件，此類研究克服各語言型態、結構及用語習慣的差異，並提供語言間
互相轉譯的能力。 
本計畫為三年期研究計畫『多語言複合式文件自動摘要之研究』之第二年計
畫。研究內容為探討中英文雙語混合式文件自動摘要的可行性。中文與英文之型
態與結構皆有很大的差異，如何跨越語言的差異性，以分析中英文文件相似度乃
是本計畫主要的研究議題。 
多文件自動摘要中最重要的研究議題在於找出不同文件中相異及相同的部
份，透過分群的方法，將相似度高的語句聚集在一起。同一語句群中，所涵蓋的
資訊可視為相同；該語句群並可視為多文件中所提及的一個重要概念。同樣地，
跨語言多文件自動摘要的研究中，重要的議題在於如何計算任兩相同或相異語言
所構成語句間相似度，以便跨越語言的隔閡，達到將相似度高的語句聚集的目的。 
 
 42
News Cluster)以各個語言文件所分析得到的事件群當輸入，將語意相同的事件群
連結，以達到多語架構下事件群的分群。 
[4], [28]中對於中英文雙語事件群的連結有深入的探討。Figure 14 為其中英
文混合語句分群架構。其基本想法為中英文語句各自分群後，再利用群中中英文
語句的對應，以建立群間連結關係。 
 
Figure 14: 中英文混合語句分群架構 
他們提出五種中英文語句對應的策略： 
 策略一：完全不考慮位置及字詞歧義性的問題 
對於存在於英文語句與中文語句中所有名詞及動詞，利用中英字典翻
譯，並參考字詞於同義詞詞林[27]及 WordNet[17]中的關係，將所有相似的
字詞對個數加總即為相似度。 
 策略二：採取先佔原則，即每個字詞只能產生一個相似連結 
針對每個詞，考慮其對應到其他語言的詞間相似個數。如 Figure 15 所
示，C2 的比對對象為所有 E1 至 En。 
 
 44
 策略五：沒有歧義性的詞優先產生連結，並決定鄰近詞的區間位置關係 
以沒有歧義性的詞優先連結，並以兩兩無歧義詞作為比較區間。如 Figure 18
中，C2 的比對對象為 E2 至 E5。 
 
Figure 18: 策略五單一字詞相似比對示意圖 
不同於[3], [4], [28]，分別針對不同語言產生事件群，再利用語句對應的方式
連結不同語言的事件群；[6]直接利用翻譯軟體將不同的語言先翻譯為英文，在
同一語言的架構下，進行事件群的分群。其困難在於解決翻譯時所導入的雜訊及
錯誤，對分群時所造成的影響。解決的方法乃是利用 WordNet[17]，透過同義詞、
上位詞及下位詞等關係計算語句的相似度。Figure 19為哥倫比亞大學Newsblaster
系統所提出的多語多文件摘要架構。 
 
Figure 19: Columbia Newsblaster 多語言摘要系統架構 
 46
3.2 概念空間建構 
概念空間建構利用中英雙語平行語料庫，透過單字/詞分群以找出相關的中
英詞群集。同一中英詞群集中，所包含的中文詞或英文詞即可視為相對應的翻譯。 
3.2.1 前處理(Pre-processing) 
前處理對中英雙語平行語料庫進行斷詞切字的工作，並計算每個中英文詞於
相對應的段落16中所出現的頻率給予其特徵值，同時建構 Word-By-Paragraph 的
矩陣作為詞分群模組的輸入。此步驟中，我們分別利用中央研究院資訊科學所詞
庫小組所開發的中文斷詞系統[23]及 LT POS[12]進行中文與英文斷詞及詞性標
記工作。對於英文斷詞結果，同時去除停用詞 (Stop-Word)並利用 Porter’s 
Stemming[18]還原字根。 
 
 
Figure 20: 中英雙語混合式文件自動摘要架構 
 
 
                                                 
16 本計畫以段落(Paragraph)為一有意義的處理單位，亦可為語句(Sentence)或文件(Document)。 
C-Doc E-Doc 
Event-related Documents 
T.R.M. 
Multi-Doc 
Summarization
Pre-processing 
Word 
Clustering 
Bilingual 
Concept-base
C-E 
Parallel Corpus 
Summary 
Pre-processing 
Hierarchical 
Concept 
Mapping 
Similarity 
Matrix 
Computation 
C-Paragraphs E-Paragraphs 
C-ConceptVector 
E-ConceptVector 
Similarity 
Matrix 
Concept Space Training 
 48
3.2.2 詞分群(Word Clustering) 
詞分群的基本假設為當兩個中英詞出現於同一相對應段落中的頻率越相
近，則代表他們於中英雙語語料庫中所表現的意義越相像。基於此假設，概念空
間建構利用中英雙語平行語料庫，透過單字/詞分群以找出相關的中英詞群集。
同一中英詞群集中，所包含的中文詞或英文詞即可視為相對應的翻譯。 
我們採用 CLUTO[10]分群工具，利用 bisecting K-means 演算法[21]進行詞分
群；同時，我們將分群的結果分割成數個階層。越上層表示所選取的 K 值越小，
代表每個群所包含的中英詞越多，其表現的概念涵蓋越廣，中英詞間的關係可視
為概念層面(Concept-Level)相關；相反地，越下曾表示所選取的 K 值越大，代表
每個群所包含的中英詞越少，同一群集中的中英詞越有可能互為翻譯。 
Figure 22: (a) 說明詞分群利用中英詞出現頻率的特性，達到中英詞混合的分
群結果。其中，e1 與 c2 可視為相關或相對應的中英詞翻譯。Figure 22: (b)說明利
用詞分群所得到的概念空間，可將段落對應至以 C1 及 C2 兩概念所描述的向量表
示式。 
 
Figure 22: (a) 詞分群概念空間建構; (b) 段落對應於概念空間示意圖 
此外，對於出現於某個詞群中所有中英詞 wj，我們分別 Eq. (16)與 Eq. (17)
計算其內在 z-score (Internal z-score)及外在 z-score (external z-score)。其中， Ijs 為
wj 與其他所有位於同一群的詞間的平均相似度， Iju 為所有位於同一群的詞之 Ijs
平均值， Ijσ 為其標準差； Ejs 為 wj與其他所有位於不同群的詞間的平均相似度，
E
ju 為所有位於同一群的詞之 Ejs 平均值， Ejσ 為其標準差。 
P2 
P1
c1 
e1 
c2 
C2
C1
P1 
P2 
C1 
C2 
(a) (b) 
 50
>=< 0,...,0,,..., ,,1 CC PlPC wwP  
Eq. (20)
 
>=<
EE PmPE
wwP ,,1 ,...,,0,...,0  
Eq. (21)
3.3.2 階層式概念空間對應(Hierarchical Concept Mapping) 
概念空間建立模組中，我們分析不同層級的分群結果，並且建立階層式詞分
群。針對不同階層，可以把某個段落 P (PC或 PE)對應到該階層之概念空間中。 
依照 Eq. (20)或 Eq. (21)， >=< ++ PmlPlPlP wwwwP ,,1,,1 ,...,,,..., 。假設階層 h 之概
念空間共有 k 個概念群，分別為 C1, …, Ck，根據 Eq. (19)，Cj 可表示為
>=< ++ jjjj cmlclclcj wwwwC ,,1,,1 ,...,,,..., ，則我們定義 P 對應至 Cj的權重為 Eq. (22)。 
)(max ,,, jj CiPiiCP www ×=  
Eq. (22)
則 P 對應至階層 h 之概念空間表示式為 Eq. (23)。 
>=<
kCPCP
wwP ,, ,...,1  
Eq. (23)
計算不同階層的相似度考量，乃是因為當考慮越低階層時，即分群數目越多
時，所包含的概念群中雖然中英文的對應卻正確，但是當段落對應到該概念空間
時，因為概念空間維度被過度細分，可能導致原本有關係的兩段落，其概念相似
度變得越低。相反地，當考慮越高階層時，即分群數目越少時，其概念所涵蓋的
詞較多較廣，當段落對應到該概念空間時，可能導致原本沒有關係的兩段落，反
而變得有關係。為了解決上述問題，我們計算不同階層的相似度，並用線性組合
方式求得相似度。當階層越低時，我們給予較低的權重；相對地，階層較高時，
給予較高的權重。 
3.3.3 相似矩陣計算(Similarity Matrix Computation) 
概念空間建立模組中，我們分析不同層級的分群結果，並且建立階層式詞分
群。針對不同階層，可以把 Pi 或 Pj 對應到概念空間中，透過 Eq. (23)，可得到
Pi 或 Pj 對應於階層 h 的概念空間表示式，並計算位於不同階層中的概念空間相
似度，最後利用線性組合(Linear Combination)的方式，可得到任兩段落 PC與 PC
 52
假設 S 為已被選到當摘要之段落集合，SIG(Pi)代表 Pi 的連結數，REL(Pi, Pj)
為 Pi 與 Pj 關聯強度，其中 Pj 屬於 S 集合；當 Pi 與 Pj 於地圖上有連結時，便需
要付出代價α 。調整α ，可去除不同層級的重複。 
4. 結果與討論 
4.1 概念空間建構 
4.1.1 中英雙語平行語料庫 
我們收集民視英語新聞[25]之中英文對照新聞，涵蓋範圍從 2003 年 5 月至
2005 年 3 月，共 6,821 組中英文對照的段落。斷詞切字的結果，中文部份共 16,506
個相異名詞及 10,950 個相異動詞；英文部份共 10,687 個相異名詞及 2,767 個相
異動詞。 
4.1.2 中英文混合詞分群結果 
Table 8 舉例說明某一 General 階層的分群的結果。此表格中，中英文對應的
部份乃為人工對應的結果，就原本的詞群而言，並沒有該對應關係。由此表格可
知，當所選取的階層越高時，亦及所分群的群數目越少時，該詞群所涵蓋的概念
越廣，中文詞與英文詞間雖然有關係，但是並不能明確地知道其相關的對應翻譯。 
Table 8: General 詞群結果舉例 
中文詞 英文詞 
仙妮雅唐恩 shania 
仙妮雅唐恩 twain 
席琳狄翁 celine 
席琳狄翁 dion 
密西艾略特 missy 
密西艾略特 elliot 
傑西辛普森 – 
鄉村 – 
實力派 – 
嘻哈教母 – 
戴安基頓 dian 
戴安基頓 keaton 
 
 
 54
Table 11 為測試集中相異詞數目及其於中英雙語平行語料庫中涵蓋的比例。
平均而言，中文詞及英文詞分別約 74%及 86%涵蓋於平行語料庫中。 
Table 11: 測試集中相異詞數目及其於平行語料庫中的涵蓋比例 
語言及詞性 測試集中相異詞數目 涵蓋於平行語料庫數目 百分比 
中文名詞 3,408 2,452 72.0% 
中文動詞 2,870 2,281 79.5% 
英文名詞 1,993 1,614 81.0% 
英文動詞 893 811 91.0% 
4.2.2 段落對應結果 
Table 12 列出各個事件群中，考慮相似度最高的前 10 組中英對應段落，以
人工的方式標記是否相關的結果。該表格顯示平均約 57%的中英對應段落為相關
的對應(亦即，平均的 Precision 為 57%)18。同時，我們發現當事件群中中英文件
的關係越相關時，如事件群 5 與 6，其對應的結果越正確；當事件群中中英文件
的關係越不相關時，如事件群 3，其正確對應的數目便越低。 
Table 12: Top10 相似度高之中英段落中正確對應數目 
事件群 相關中英對應段落數目 
1 6 
2 5 
3 3 
4 6 
5 8 
6 8 
7 6 
8 5 
9 4 
10 6 
平均 5.7 
 
 
 
                                                 
18 初始實驗結果因測試集雜亂導致結果不佳。我們縮減測試集，使得中英文文章的數量相近得
到比較好的結果。 
 56
Table 16: 摘要資訊量涵蓋度及可讀性評估 
事件群 資訊量涵蓋度 可讀性 
1 7.2 5.5 
2 6.9 6.2 
3 5.5 5.4 
4 6.5 5.8 
5 8.2 6.8 
6 7.7 7.0 
7 7.3 6.5 
8 7.0 5.8 
9 7.5 5.6 
10 6.8 5.8 
平均 7.06 6.04 
Table 17 僅列出事件群 6 由系統所產生的摘要結果以供參考。 
Table 17: 事件群 6 之摘要內容範例 
他說，所謂搭橋，是為兩岸搭起互信之橋、合作之橋與溝通之橋。宋楚瑜也不
是任何人的信差。 (pno: 3; article: 6; pdate: 2005-05-25) 親民黨主席宋楚瑜今天
抵達北京，他感謝中共中央總書記胡錦濤的邀請，讓親民黨打破五十多年來兩
岸政治禁忌，和中國共產黨進行黨與黨對話。他說，親民黨相信 只要兩岸兄
弟一家親，一定可以找到方法，解決兩岸過去的誤解。 (pno: 1; article: 78; pdate: 
2005-05-25) 宋楚瑜的專機約在下午四時三十分抵達北京，中國國台辦主任陳
雲林等人到場迎接。 (pno: 2; article: 78; pdate: 2005-05-25) 他說，以親民黨主
席身分和親民黨和平工作團身分到北京，感謝中共黨中央與總書記胡錦濤的邀
請，讓親民黨打破五十多年來兩岸政治禁忌，親民黨能和中國曳?珔 i 行黨與黨
的對話。 (pno: 4; article: 78; pdate: 2005-05-25) 親民黨主席宋楚瑜今天與中國
共產黨總書記胡錦濤會面時表示，親民黨三點基本立場堅定不移，堅定支持九
二共識「一個中國」基本原則、從不認為台獨應是台灣選項、以及主張和平。
(pno: 1; article: 145; pdate: 2005-05-25) 胡錦濤說，國親兩黨主席連戰、宋楚瑜
來訪，大陸同胞和台灣同胞都給予支持與歡迎，表明兩岸同胞認為這些做法符
合他們的心願。 (pno: 9; article: 146; pdate: 2005-05-25) Soong, who arrived in 
Shanghai Friday on the third leg of his current nine-day visit to China, said when he 
meet with Chinese President Hu Jintao in Beijing May 12, he will urge China to 
adopt concrete measures to protect "taishang's" rights and interests. (pno: 2; article: 
4; pdate: 2005-05-25) Soong flew from Hunan Province to Beijing on the fifth and 
most important leg of his nine-day "bridge-building" visit to China, where he will 
hold talks with Chinese President Hu Jintao, who serves concurrently as general 
secretary of the Communist Party of China. (pno: 2; article: 46; pdate: 2005-05-25) 
 58
參考文獻 
[1] Barzilay, R., & Elhadad, M. (1997). Using lexical chains for text summarization. 
In Proceedings of the ACL/EACL’97 Workshop on Intelligent Scalable Text 
Summarization, Madrid, Spain (pp. 10-17). 
[2] Boros, E., Kantor, P. B., & Neu, D. J. (2001). A clustering based approach to 
create multi-document summaries. In Proceedings of the Document 
Understanding Conference (DUC-2001), New Orleans, LSA, USA. 
[3] H.-H. Chen, J.-J. Kuo, S.-J. Huang, C.-J. Lin and H.-C. Wung, “A 
Summarization System for Chinese News from Multiple Sources,” Journal of the 
American Society for Information Science and Technology, 54(13), 1224-1236, 
2003. 
[4] H.-H. Chen and C.-J. Lin, “A Multilingual News Summarizer,” Proceedings of 
the 18th International Conference on Computational Linguistics, pp. 159-165. 
[5] H. P. Edmundson, “New Methods in Automatic Extracting,” Journal of ACM 
(JACM), 16(2), 264-285, 1969. 
[6] D. Evans, J. L. Klavans, K. R. McKeown, “Columbia Newsblaster: Multilingual 
News Summarization on the Web,” Proceedings of Human Language Technology 
(HLT), Boston, MA, 2004. 
[7] Goldstein, J., Mittal, V., Carbonell, J., & Kantrowitz, M. (2000). Multi-document 
summarization by sentence extraction. In Proceedings the ANLP/NAACL 
Workshop on Automatic Summarization, Seattle, WA (pp. 40-48). 
[8] Gong, Y., & Liu, X. (2001). Generic text summarization using relevance measure 
and latent semantic analysis. In Proceedings of the 24th Annual International 
ACM SIGIR Conference on Research and Development in Information Retrieval 
(SIGIR’01), New Orleans, LA, USA (pp. 19-25). 
[9] Hovy, E., & Lin, C. Y. (1999). Automated text summarization in SUMMARIST. 
Mani, I., & Maybury, M. (eds.), Advances in automated text summarization. 
Cambridge, Mass.: MIT Press. 
[10] G. Karypis, “CLUTO: Software Package for Clustering High-Dimensional 
Datasets,” http://www-users.cs.umn.edu/~karypis/cluto/index.html. 
[11] Kupiec, J., Pedersen, J., & Chen, F. (1995). A trainable document summarizer. In 
Proceedings of the 18th Annual International ACM SIGIR Conference on 
Research and Development in Information Retrieval (SIGIR’95), Seattle, WA, 
USA (pp. 68-73). 
[12] Language Technology Group, “LT POS,” http://www.ltg.ed.ac.uk/software/pos/. 
[13] H. P. Luhn, “The automatic creation of literature abstracts,” IBM Journal of 
Research and Development, 2(2), 159-165, 1958. 
 60
 
 
 
 
 
 
 
 
 
 
多語言複合式文件自動摘要之研究 (3/3) 
 
 
 
 
 
 
 
 
 
 
計畫類別: 個別型計畫 
計畫編號: NSC-92-2213-E-009-126- 
執行期間: 2005/08/01 – 2006/07/31 
 
 
 
計畫主持人: 楊維邦 教授 
計畫參與人員: 柯皓仁 教授, 葉鎮源, 林昕潔, 張家寧 
 
 
 
 62
1.  Introduction 
Automated text summarization has been in existence since the 1950’s. By definition, 
it is the process of distilling the most important information from a source (or sources) 
to produce an abridged version for a particular user (or users) and task (or tasks) [18]. 
The technology can potentially ease the burden of information overload because only 
summaries need to be read or analyzed. For example, a search engine could provide 
summaries (e.g., snippets of texts) to help users spot desired documents in a short 
time. 
Over the past few years, text summarization has drawn tremendous interest from 
both the natural language processing and the information retrieval communities. DUC 
(Document Understanding Conference) [10] is one of the active forums for 
large-scale evaluations of summarization systems. Since 2001, DUC has held several 
evaluations, including single-document summarization, multidocument 
summarization, cross-lingual summarization and query-focused summarization. 
Query-focused multidocument summarization was first formally proposed and 
evaluated at DUC 2005. The task is, given a set of topic-related documents (i.e., a 
topic cluster), a query topic, and a user profile, to generate a brief, well-organized 
fluent summary for the purpose of answering users’ information needs. The query 
topic, illustrated in Table 18, models the real-world complex question-answering 
proposed in [2]. A user profile with a value of “general” or “specific” specifies the 
granularity required for the output summary. In essence, query-focused 
multidocument summarization integrates techniques of multidocument 
summarization and question-answering. From the viewpoint of multidocument 
summarization, it needs to generate not only a theme-relevant but also a 
query-relevant summary; while from the perspective of question-answering, the 
output summary can not just state a name, date, quantity, etc., which makes it more 
challenging. 
In this report, we propose an approach to address query-focused summarization. 
The method considers as the task a query-biased sentence retrieval task. In other 
words, only relevant sentences are included in the summary. It measures the relevance 
of a sentence to the query using a novel hybrid relevance analysis which linearly 
combines relevance measures from the vector space model and latent semantic 
analysis (LSA). The output summary is generated according to sentence salience 
which is estimated in terms of sentence relevance and low-level feature significance. 
 64
Approaches based on the graphic model have also been tried.  For example, 
Mani and Bloedorn [17] used a document graph to formulize relations between 
sentences inside a document. A spreading activation algorithm is applied to perform a 
query-biased summarization. Bosma [5] created a graphical representation for a 
document using the Rhetorical Structure Theory (RST) [19]. Based on the graph 
model, a graph search algorithm is exploited to identify relevant sentences. 
Some approaches use shallow semantic analysis. D’Avanzo and Magnini [7] 
exploited key-phrase extraction to identify relevant terms and used machine learning 
to select significant key-phrases. Summaries are generated according to relevance and 
coverage of keyphrases of a certain topic. Li et al. [15] built a query-oriented 
multidocument summarization system under the framework of MEAD [20] by 
integrating entity-based, pattern-based, term-based, and semantic-based features. 
Hovy et al. [13] proposed a method on the basis of the extraction of basic elements. A 
basic element, defined as a head-modifier-relation representation, is regarded as a 
basic unit to determine the salience of a sentence. 
In contrast, some approaches depend on deep discourse analysis. For instance, 
Schilder et al. [22] investigated a tree matching algorithm to obtain a tree similarity 
of dependency parse trees between a question and candidate answer sentences. 
Sentences with the highest similarities are extracted as the summary. Ye et al. [24] 
handled query-focused summarization by computing sentence semantic similarity via 
concept links. In their work, concept links were shown to outperform word 
co-occurrence since they highlight words that are semantically-related. A modified 
MMR for anti-redundancy was proposed by introducing semantic similarity into the 
original MMR [6]. Zhou et al. [26] combined lexical chains and document index 
graphics by adding verbs to chains. Sentences are scored according to the integrated 
chain structure. 
Last but not least, Seki et al. [23] proposed a summarizer that focuses on 
subjectivity analysis. Subjectivity refers to aspects of language description that are 
formed to express an author’s opinions, evaluations, and speculations. The 
summarizer generates summaries to reflect information needs based on subjectivity 
clues. Berger and Mittal [3] introduced a statistical model for query-relevant 
summarization. The parameters were learned with a collection of FAQs using 
maximum-likelihood estimation. Blair-Goldensohn [4] adapted a system originally 
designed to answer definitional and biographical questions and enhanced it with 
sophisticated question parsing, topic term identification, and passage retrieval. In 
 66
)1log(),( , += qttfqtw  Eq. (27)
where tft,q the frequency of term t in the query q. 
4)  Summary-Type Detection (refer to Section 4.3) 
This module determines whether the desired summary is specific or general 
according to the user profile. If a specific summary is expected, the number of named 
entities in a sentence is regarded as another feature and integrated into the sentence 
scoring function as well. 
5)  Relevance Analysis (refer to Section 4.1) 
Sentences are evaluated to obtain their relevance to the query by measuring their 
similarity. 
6)  Sentence Scoring (refer to Section 4.3) 
Sentence relevance and surface feature salience are combined to estimate the 
significance of a sentence. Sentences are ranked according to their scores for 
selection. 
7)  Redundancy Reduction (refer to Section 4.4) 
A modified MMR is employed to reduce information redundancy in the 
summary. 
8)  Summary Generation (refer to Section 4.5) 
This module selects salient sentences on the basis of sentence scores and 
re-orders sentences according to their original time and date of publication to form a 
summary. 
 68
∑
∈ +
+++=
⋅=
qt t
stqt sf
Ntftf
qsqssim
)
5.0
1log()1log()1log(
),(
,,
1
rr
 
Eq. (28)
4.1.2   Similarity Based on LSA: sim2(s, q) 
In recent years, LSA [9] has been profitably employed in information retrieval to 
derive inherent semantic structure from a corpus. We employ LSA to measure the 
semantic relevance of a sentence s to the query q. 
First, a word-by-sentence matrix, A, is built from all sentences, as presented in 
Eq. (29). In this matrix, columns represent sentences and rows denote unique words 
found in the collection. (Note: without loss of generality, m is greater than or equals 
to n.) The cell of row i and column j (i.e., ai,j), computed by Eq. (26), signifies the 
weight of a term ti in a sentence sj. 
nmmmm
n
n
n
aaat
aaat
aaat
sss
A
,2,1,
,22,21,22
,12,11,11
21
L
MOMMM
L
L
L
=  
Eq. (29)
Singular Value Decomposition (SVD) is then performed on A. The SVD 
projection of A is the product of U, Z and V: TUZVA = where U is an nm×  matrix 
of left singular vectors, Z is an nn×  matrix with a diagonal (σ1, …, σn)19 and zeros 
elsewhere, and V is an nn×  matrix of right singular vectors. In theory, U and V are 
both orthogonal matrices; there exists a property that UTU=VTV=I, where I is the 
identity matrix; Z could be interpreted as a semantic space (or the topic structure) 
derived from the corpus; U and V could be viewed as semantic representations of 
words and sentences in Z respectively.  
Finally, Dimension Reduction is applied to Z by keeping only k (k ≤ r) singular 
values to obtain an approximate Zk. A new matrix, A
~ , which denotes the semantic 
representation of A in Zk could be obtained by folding A into the reduced space Zk 
using Eq. (30).  
                                                 
19 If rank(A) = r, Z satisfies σ1≥σ2≥…≥σr>σr+1=…=σn=0. 
 70
to obtain its feature score. They are: 1) position; 2) average tf-idf weight of 
significant words; 3) similarity with title; 4) similarity with document centroid; and 5) 
similarity with topic centroid. 
f1 – position: it is believed that important sentences are usually located in 
particular positions in a document. Take a news article for instance, the first sentence 
always introduces the main topic or summarizes the whole story. The position score is 
defined in Eq. (34), which was proposed by Hirao, et al.  [12]. In Eq. (34), |D| is the 
number of words in the document D that contains s and NC(s) is the number of words 
appearing before s in D. On the basis of this mechanism, the first sentence obtains the 
highest score and the last has the lowest one. 
||
)(1)(1 D
sNCsf −=  
Eq. (34)
f2 – avg. tf-idf weight of significant words: generally, terms with higher term 
frequency and tf-idf values are more important, implying that a sentence with a higher 
summation of tf-idf values from its constituent words tends to be a substantial 
sentence. In previous studies, all words in a sentence are taken into account and the 
total score is averaged over the length of the sentence. In our work, in order to obtain 
a more precise weight for a sentence s, we only consider significant words in s. The 
average tf-idf score is computed as shown in Eq. (35), where w(t, s) is the weight in 
Eq. (26).  
),()(
tsignifican is ,
2 stwAveragesf
tst∈
=  Eq. (35)
A significant word is defined as a keyword t which satisfies the criterion shown in Eq. 
(36), where u is the mean and σ is the standard deviation of all w(t, C), and w(t, C) is 
the summation of all tf-idf values for t from all sentences in the document collection 
C. 
),(5.0 Ctwu ≤+ σ  Eq. (36)
f3 – similarity with title: there is no doubt that the title always sums up the main 
theme of a document. In other words, the more similar a sentence is with the title, the 
more important it is. This similarity is measured by Eq. (37) where stitle is the title 
sentence. 
 72
Recall that in Section 3, there is a module called summary-type detection. If the 
summary is specific, the number of named entities, denoted as fNE(s), is regarded as 
an additional feature considered in sig(s). The idea is, when a specific summary is 
needed, information containing named entities, such as person, location, date/time, 
and so on, becomes more important. Therefore, in this case, 
)()()( sfwsfwssig NENE
i
ifi
⋅+⋅= ∑ .  
4.4   Redundancy Reduction 
Carbonell and Goldstein [6] proposed Maximal Marginal Relevance (MMR) to 
reduce redundant information in the summary. The main idea is, when including a 
sentence s in the summary, the summarizer measures MMR for s to satisfy the 
following criteria: 1) the maximum relevance of s to the query q and 2) the minimum 
similarity of s to previously selected sentences in the summary. That is, s has high 
marginal relevance iff it is both relevant to q and contains minimal overlap with 
previously selected sentences. The MMR is defined in Eq. (41), where R is the ranked 
list of sentences, S is the set of sentences which are already selected in the summary, 
SIM1 is the similarity metric used in relevance ranking, and SIM2 is the similarity 
measured by the cosine value of two sentence vectors.  
)],(max)1(),([maxarg 21 iSsSRs
def
ssSIMqsSIMMMR
i∈−∈
⋅−−⋅≡ λλ  
Eq. (41) 
One shortcoming of MMR is that it does not consider the sentence representative 
power (e.g., surface feature salience). In our work, we propose a modified MMR, 
presented in Eq. (42), to integrate surface feature salience into the original MMR. In 
Eq. (42), δ and λ are weights to control the impact of sig(s), SIM1, and SIM2, sig(s), as 
mentioned in Section 4.3, is the score obtained from feature salience, SIM1 denotes 
the similarity metric proposed in Section 4.1, and SIM2 simply computes the cosine 
similarity. In general, a sentence which has a high feature score and is highly relevant 
to the query but has a lower similarity to sentences in the summary will be ranked in 
the topmost position. 
)],(max)1(                                                     
),()([maxarg
2
1
iSs
SRs
def
ssSIM
qsSIMssigRModifiedMM
i ∈
−∈
⋅−−
⋅+⋅≡
λ
λδ
 
Eq. (42)
 74
5.2 Evaluation Metric 
There were two evaluations conducted at DUC 2005. One automatically measured the 
consistence between reference summaries and machine-generated summaries using 
ROUGE (Recall-Oriented Understudy for Gisting Evaluation) [21]. The other was a 
manual evaluation which measured the quality of linguistic well-formedness and the 
responsiveness of each submitted summary using a set of quality questions. Since we 
did not participate in DUC 2005, we only report results evaluated by ROUGE. 
ROUGE is an automatic evaluation tool for automated text summarization. It 
measures the number of overlapping units, such as n-gram, word sequences, and word 
pairs between computer-generated summary and ideal summaries created by humans. 
There are several measurements, including ROUGE-N, ROUGE-L, ROUGE-W, and 
ROUGE-S.  DUC 2005 ran ROUGE-1.5.5 to compare human and system scores. 
Only the recalls of ROUGE-2 and ROUGE-SU4 were reported as the official 
ROUGE scores at DUC 2005. 
5.3 Experimental Settings 
In our experiments, we evaluated models with different settings to answer the 
following questions: 
Q1: Can the proposed hybrid relevance analysis achieve better 
performance when it is employed to estimate the relevance of a sentence to 
the query? 
Q2: Are surface features beneficial to improve the summarization 
performance? 
Q3:  Does the modified MMR outperform the original MMR? 
Table 19 lists these models. In the table, B1 and B2 are baselines, which only 
exploit the similarity metric proposed in [1] and the original MMR [6]. M10 is the 
system that integrates all proposed methods in this work. Others are listed here as 
references to obtain more clearly the impact of different factors. As for parameters (as 
listed in Table 20), they were set manually in these experiments. 
 
 76
M10>M6>M2). These results suggest that a hybrid relevance analysis which 
combines similarities computed from the vector space model and latent semantic 
analysis is a successful way to estimate a better sentence relevance to the query.  
Second, for those models in which surface features are taken into account but 
without MMR (see M1, M5, and M9), it is obvious that a scoring mechanism 
enhanced with low-level text features will improve the performance (e.g., M1>B1; 
M5>M3; M9>M7). It is noted that according to the results of our experiments, we 
found that a slightly smaller wsig obtains better results. This is because for 
query-relevant summarization, relevant sentences are much more important than 
those sentences with high shallow feature salience which might be interpreted as 
theme-relevant sentences. 
Finally, considering cases when the modified MMR was applied (see M2, M6, 
and M10), they outperformed models which use the original MMR (see B2, M4, and 
M8). A sentence, if it has high feature score and is highly relevant to the query but has 
lower similarity with sentences in the summary, will be ranked in the topmost 
position. This demonstrates that the modified MMR is a suitable module for 
query-focused multidocument summarization. 
Table 21: recalls of ROUGE-2 and ROUGE-SU4 
 Models R-2 Models R-SU4 
1 M10 0.075690 System 15 0.131633 
2 M6 0.073880 M10 0.129950 
3 M9 0.073780 System 17 0.129725 
4 System 15 0.072510 M6 0.127110 
5 M2 0.072280 M9 0.126870 
6 System 17 0.071741 M5 0.124430 
7 M5 0.071340 M2 0.124330 
8 M8 0.070110 M8 0.124270 
9 M4 0.070000 M4 0.123930 
10 M1 0.069720 M7 0.121750 
11 M7 0.068730 M1 0.121350 
12 B2 0.067690 B2 0.120200 
13 M3 0.067190 M3 0.119950 
14 B1 0.064830 B1 0.117550 
 78
[4] S. Blair-Goldensohn, From Definitions to Complex Topics: Columbia University 
at DUC 2005, Proc. of DUC 2005, Vancouver, Canada, 2005. 
[5] W. Bosma, Query-Based Summarization Using Rhetorical Structure Theory, Proc. 
of CLIN 2003, Belgium, 2003. 
[6] J. Carbonell and J. Goldstein, The Use of MMR, Diversity-Based Reranking for 
Reordering Documents and Producing Summaries, Proc. of SIGIR’98, Melbourne, 
Australia, 1998. 
[7] E. D’Avanzo and B. Magnini, A Keyphrase-based Approach to Summarization: 
the LAKE System at DUC-2005, Proc. of DUC 2005, Vancouver, Canada, 2005. 
[8] H. Daumé III and D. Marcu, Bayesian Query-Focused Summarization, Proc. of 
COLING/ACL 2006, Sydney, Australia, 2006. 
[9] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer and R. Harshman, 
Indexing by Latent Semantic Analysis, Journal of the American Society for 
Information Science, Vol. 41, No. 6, 1990, pp. 391-407. 
[10] Document Understanding Conference. Available at http://duc.nist.gov/. 
[11] B. Hachey, G. Murray and D. Reitter, Query-oriented Multi-document 
Summarization with a Very Large Latent Semantic Space, Proc. of DUC 2005, 
Vancouver, Canada, 2005.  
[12] T. Hirao, K. Takeuchi, H. Isozaki, Y. Sasaki and E. Maeda, NTT/NAIST’s Text 
Summarization Systems for TSC-2, Proc. of NTCIR 2003, Japan, 2003. 
[13] E. Hovy, C.-Y. Lin, and L. Zhou, A BE-based Multidocument Summarizer with 
Query Interpretation, Proc. of DUC 2005, Vancouver, Canada, 2005. 
[14] J. Jagadeesh, P. Pingali and V. Varma, A Relevance-Based Language Modeling 
Approach to DUC 2005, Proc. of DUC 2005, Vancouver, Canada, 2005.  
[15] W. Li, W. Li, B. Li, Q. Chen and M. Wu, The Hong Kong Polytechnic University 
at DUC2005, Proc. of DUC 2005, Vancouver, Canada, 2005. 
[16] C. Y. Lin, Training a Selection Function for Extraction, Proc. of CIKM’99, 
Kansas, MO, 1999. 
[17] I. Mani, and E. Bloedorn, Summarizing Similarities and Differences among 
Related Documents, Information Retrieval, Vol. 1, 1999, pp. 35-67. 
[18] I. Mani, and M. T. Maybury (Eds), Advances in Automated Text Summarization, 
Cambridge, MA: The MIT Press, 1999.  
[19] W. C. Mann, and S. A. Thompson, Rhetorical Structure Theory: Toward a 
Function Theory of Text Organization, Text, Vol. 8, No. 3, 1988, pp. 243-281. 
[20] MEAD, http://www.summarization.com/mead/. 
[21] ROUGE, http://www.isi.edu/~cyl/ROUGE/. 
[22] F. Schilder, A. McCulloh, B. T. McInnes, and A. Zhou, TLR at DUC: Tree 
Similarity, Proc. of DUC 2005, Vancouver, Canada, 2005.  
