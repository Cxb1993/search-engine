 一、 前言 
1.1 研究背景與動機 
視訊監控系統的技術日漸成熟與設備價格普及化，住家、商店、街道、路口、百貨公司、公
共設施等地方隨處可見。傳統類比式視訊監控系統將視訊儲存至錄影帶中，儲存資料量有限，也不
易長期保存。數位化視訊監控系統將視訊資料數值化儲存，並結合影像壓縮技術，減少資料的儲存
量。但是類比式與數位化的視訊監控系統都需要依賴人員無時無刻地緊盯著螢幕，觀看與分析視訊
內容，或在事發之後以人工瀏覽的方式還原事件發生的經過。為了準確與適時偵測異常事件的發
生，並發出警訊告知相關人員，避免或降低異常事件所造成的人員傷亡與財物損失，所以視訊監控
系統還需要具備事件偵測的能力，也就是結合電腦視覺(Computer Vision)的智慧型視訊監視系統。 
  智慧型視訊監視系統運用到動態偵測(Motion Detection)、圖型辨識(Pattern Recognition)與物件
追蹤(Object Tracking)等相關技術，進一步達到身份辨識與行為分析，並提供自動警訊通知與錄影追
蹤蒐證等服務功能，能通知相關人員在第一時間進行適當處理，事發後也能快速調閱相關視訊片段
以供參考，可以避免人為疏失與提高系統效率。為了使人們達到生活便利與營造安全環境，科技需
要不斷地向前邁進，隨處可見的視訊監視系統將全天候代替人眼監控危險事件，加強安全的維護。 
智慧型視訊監視系統因應地點與事件的不同，發展出不同的應用，與人類事件相關有行為辨識與異
常事件偵測等研究。以人臉上的特徵做為辨識依據，其應用有身份辨識系統、性別辨識系統與表情
辨識系統等；透過分析整體姿勢的影格(frame)序列，得知其運動狀態為正常或異常行為，其應用有
跌倒偵測、行搶偵測、翻牆偵測和球場異常活動偵測等。不同環境，不同訴求，也就需要不同的偵
測方法。 
  近年來提倡運動保健強身，帶動一股運動風潮，而大部份運動項目的場地在戶外。隨之，活
動場地不斷增加，硬體設備的品質也不斷提升，慢跑、球類運動、自行車、直排輪與滑板等運動項
目，都有其專屬的活動場地。但是大多數的場地沒有專屬管理員，即便有架設視訊監視器，數量眾
多的螢幕只依賴數名人員監看，不但無法同時監看多個螢幕的電視牆，而長時間工作所出現的疲勞
也會影響其判斷力，難以維持場內的安全與防止人為的破壞。智慧型球場視訊監視系統能準確分析
視訊內容，偵測異常活動的發生，有效節省人力資源，即使長時間運作也能準確偵測，大幅提升工
作效率。大多數球場是學校、企業與公家機關所建設，提供給學生、員工和一般民眾使用，並不是
私人財產，場地與設備遭到破壞將會影響大眾的權利。田徑場、球類場地與極限運動廣場等場地的
環境與器材的設置，都事先針對運動項目做過規劃，以達到運動的目的與使用的安全。在球類場地
內進行騎自行車、溜直排輪和玩滑板等運動被視為異常活動，這些運動項目的載具會破壞場地，造
成場地的不平坦與設備的毀損，進而造成人員受傷。球場為開放式戶外場地，只針對單人的活動偵
測是不符合真實環境的需求，在多人環境中需要考慮到人與人互動而產生的遮蔽(occlusion)問題，
被遮蔽人員將遺失部份的影像資料，使得部份特徵無法取得，增加後續行為分析的難度。  
     遮蔽問題一直是困難的挑戰，因為監視器的攝影視角有限，所以無法得知被遮蔽部份的影像。
解決遮蔽問題的研究大致上可分為兩類，一類為整合多臺監視器，各別從中取得特徵，利用每臺監
視器架設的位置而產生不同的視角，所以被遮蔽的部份與程度將有所不同，有助於獲得更多的個人
資訊，再把獲得的資訊彙整到系統中加以分析，但必須對多臺視訊內容做身份辨識以確保追蹤的目
標為同一人，也就需要大量的設備與運算成本。另一類為計算成本低的獨立監視系統，由於只有單
一固定視角，依賴單張影像所獲得的資訊不足以分析行為，必須利用連續影像來獲取更多時間與空
間的資訊，所以如何有效取得特徵將是重點之一。與遮蔽問題息息相關的技術就是物件追蹤，視訊
錄物件像素的色彩值以及其權重值做為物件模型的資訊，當遮蔽發生時，利用同一物件像素之間的
關聯性與物件的模型，將遮蔽情況分成物件間互動之遮蔽、受背景物件影響之遮蔽以及自我遮蔽等
三類，利用已建立的模型估測物件的位置，即使受遮蔽影響也能正確的追蹤物件。 
形狀模板[10, 11](Shape-Based Template)與骨架模板(Skeleton-Based Template)[12, 13]常被用來
比對物件行為活動之分析。Lam等人[10]分析每個人走路有不同速度與不同的步距，所以每個人之
週期模板形狀也不盡相同，因此可依據此特性建立走路週期之形狀模板。Ke等人[11]首先建立各種
行為之連續形狀模板，保存了動作連續性，接著將移動物件的形狀影像與資料庫內的模板比對，找
出最相似的模板，進而得到連續的移動物件姿勢，以及移動物件之細部動作。Hsieh等人[12]利用三
角測量(Triangulation)的技術，將物件輪廓內部切割成多個三角形，接著找出三角形的中心，連接這
些相鄰三角形的中心即可獲得三角化骨架，對人體姿勢的種類能呈現較多元的變化。Fujiyoshi 及
Lipton[13]提出星狀骨架，計算移動物件的中心(centroid)至輪廓上各點距離的曲線圖，因頭與四肢
通常是形狀的突出點，也就是相較於鄰近點至中心的距離較遠，所以分析曲線圖上波峰的位置，即
可得知頭與四肢在輪廓上的點，將中心與各點相連即可取得星狀骨架。 
 
三、 克服遮蔽影響之球場異常活動偵測方法 
本研究之方法主要分為移動物件偵測與行為偵測兩大流程，移動物件偵測找出影像中移動物
件，行為偵測則利用移動物件的輪廓，萃取出下肢角度，當遮蔽發生時，還原遮蔽之移動物件影像，
最後分析在連續影像中下肢角度變化的特性，判定是否進行異常活動。 
3.1 移動物件偵測 
    移動物件偵測可分為色彩空間轉換、前景偵測、雜訊濾除等步驟，詳細方法分述如后。 
 色彩空間轉換 
    將視訊由彩色轉換成灰階，降低計算維度，達到快速偵測移動物件，其轉換方法如公式(1)[15]: 
  I=0.2989×R+0.5870×G+0.1140×B                                             (1) 
其中 R、G與 B分別為組成彩色影像的三個矩陣，I為轉換後的灰階影像。 
 前景偵測 
    此步驟主要目的在於正確偵測出移動物件，本研究採用Jacques[16]所提出之背景去除法，
此方法主要利用連續的z張視訊框Vz(i,j)，產生一個供比對用的背景模型B(i,j)，如公式(2)所示， 












−
=










=
)ji,(V)ji,(Vmax 
)ji,(Vmax 
)ji,(Vmin 
j)d(i,
j)n(i,
j)m(i,
j)B(i,
1-zz
z
z
                                          (2) 
其中m(i,j)代表Vz(i,j)之最小灰階值，n(i,j)代表Vz(i,j)之最大灰階值，d(i,j)代表相鄰視訊框Vz-1(i,j)、Vz(i,j)
間之最大灰階差異值。輸入的視訊框It(i,j)經由比對B(i,j)，即可將背景與前景分離。本研究修正Jacques
等人[16]提出的前景像素判斷式，找出影像中亮度值變動的像素位置，修正後之判斷式如公式(3): 
  ( ) ( )( )( ) ( ) ( )( )( )( )


 −<∨+>
=
otherwise,0
,n,I,m,I,1
),(b
tt µµ kyxyxkyxyxif
yx                     (3) 
其中 b(x,y)=1 的像素所組成的影像就是前景物件，μ 是 d(i,j)值排序後之中位數(median)。本研究以
10秒連續影像建立背景模型，前景像素判斷式中變數 k設定為 2，前景偵測的結果如圖 1(b)所示，
為方便後續圖例說明，所有前景物改以黑色表示，背景以白色顯示。前景偵測之移動物件底部尚有
移動物件
遮蔽偵測
遮蔽影像還原
否
是
行為模板建立
角度萃取
輪廓萃取
異常活動
異常活動判定
 
圖 2 行為偵測流程 
 
 遮蔽偵測 
    為了判斷是否發生遮蔽，首先利用相鄰元素編號演算法(Connected Component Labeling) [15]標
記各區域，並賦予編號。由於物件的移動具有時間連續性與空間連續性，所以同一物件在相鄰兩張
影像中的位移量很小，如果重疊相鄰兩張影像，將發現有部分影像重疊，可利用此特性分辨與追蹤
連續影像中之移動目標。 
    經由計算移動物件個數與區域個數之關係，可藉以判斷遮蔽與否。以圖 3與表 1為例做說明，
圖 3為一段連續影像之示意圖，表 1為物件個數與區域個數之關係，在影像 1中沒有任何移動物件，
所以表格中物件的區域編號為 0；在影像 2中出現了物件 A，經相鄰元素編號演算法得知該區域為
編號 1，將其記錄在表格內；在影像 3中有兩個區域，經由上述追蹤方法得知區域 1與影像 2的區
域 1有重疊部分，故判定影像 2的物件 A出現在影像 3的區域 1，而物件 B沒有與前一張影像有重
疊的區域，故判定物件 B為視訊中的新物件且存在於區域 2；持續以此方法追蹤各物件在影像中存
在的區域，並將其結果記錄在表 1中；分析表格內各物件的區域編號之間的關係，即可以得知遮蔽
發生的開始點、結束點與参與遮蔽事件的物件；在表格中影像 7的欄位內物件 A、B都存在於區域
1內，故可判定物件 A、B發生遮蔽事件，且影像 7為遮蔽事件的開始點；由相鄰元素編號演算法
得知影像 9中有一個區域而影像 10中有兩個區域，且影像 10中兩個區域皆與影像 9中的同一區域
有重疊部分，故可判定影像 10為遮蔽事件的結束點。
  
(a)                (b) 
圖 4 走路行為之模板(a)雙腳站立(b)雙腳張開 
 
    計算每張影像的物件的像素個數，將其統計成曲線圖，如圖 5所示，由曲線圖分析得知，可取
物件面積變化曲線中兩個波谷之間的影像做為行為模板，如圖 5中虛線之間。取出之行為模板，如
圖 6所示。圖中模板的時間順序是從左至右，例如模板 t的左邊為 t-1時間的模板而右邊為 t+1時間
的模板；行為模板為一個有週期性的模板，當模板移動至最後時，又會接續至第一個模板，例如模
板 t+8與模板 t-7為連續的模板。 
 
 
圖 5 走路行為之物件面積變化曲線圖 
 
 
 
圖 6 走路之行為模板 
 
 遮蔽影像還原 
    假設遮蔽事件開始的時間點為 k，利用遮蔽開始之前三張物件影像 k-1、k-2與 k-3，如圖 7(a)，
並與行為模板比對，找出與其最相似的連續三張行為模板。比對方式是逐一統計與行為模板內連續
三張模板的重疊面積來計算其相似度，圖 7(b)中黑色部份為重疊面積，利用此方法找出相似度最高
的連續三張模板，如圖 7(c)框架內的三張模板 t+4、t+5與 t+6，所以由行為模板 t+7開始還原遮蔽
期間的物件影像。 
 
    本研究偵測的行為以下肢活動為主，所以使用下肢角度變化做為特徵。首先利用人體骨架找出
到下肢位置，骨架萃係取採用 Fujiyoshi等人[13]所提之星狀骨架，步驟說明如后: 
(1) 利用輪廓上的像素點座標求出中心，如圖 10(a)所示。 
(2) 以輪廓上最上方的像素為起始點，以逆時針的方式由起始點開始計算輪廓上像素點至中心的距
離，將其距離繪製成曲線圖，如圖 10(b)所示。 
(3) 曲線上許多雜訊不易進行偵測極值，使用線性平滑濾波器(Linear Smoothing Filter) 平滑曲線，
其結果如圖 10 (c)所示。 
(4) 透過差分法(Difference)找出曲線上的極值的位置，最後將曲線上極值對應到的像素與中心連
結，即可得到星狀骨架，如圖 10 (d)所示。 
 
(a)              (b)                    (c)              (d) 
圖 10 星狀骨架萃取(a)物件中心(b)距離曲線圖(c)平滑距離曲線圖(d)星狀骨架 
    
建構物件的星狀骨架後，經由人體骨架可找到下肢骨架，計算其夾角，即可獲得下肢角度。 
 異常活動判定 
    收集連續影像中物件的下肢角度，並將其繪製成下肢角度變化曲線圖，如圖 11 所示，分析曲
線的規律性和不正常變化，利用走路、跑步、騎自行車、溜直排輪和玩滑板的下肢角度都有其不同
週期性和角度變化特性，藉此判斷物件的活動是否正當。走路與跑步的下肢角度變化都是呈現規律
性的週期變化，如圖 11(a)、(b)所示，其變化都是一直重複著相似的振盪，只是跑步的角度週期變
化相對於走路較短，而溜直排輪的角度週期變化不同於走路與跑步，一開始的連續跨步加速的角度
變化與跑步相似，但是經過一段加速度後，溜直排輪者會出現雙腳站立滑行的動作特性，滑行中的
角度變化趨向於平坦，如圖 11(c)中影格 60之後的角度變化，可將此特性視為不正常下肢角度變化。 
 
 
 (a)                      (b)                          (c) 
圖 11 下肢角度變化曲線圖(a)走路(b)跑步(c)溜直排輪 
 
 12 
其中 min 與 max 分別為角度變化曲線上出現的最小值與最大值，count 為平緩震盪的像素累計個
數，d為 count等於 1時的物件中心座標，a(i)與 c(i)分別為在第 i張影格的物件下肢角度與物件中心座
標，α、β、γ與 μ都是閾值。當輸入角度與 min之絕對值差距不大於 α，則表示此像素可能在平坦曲線
上，此時 count值加一，而 count值累加到 γ時，表示平坦曲線已經持續一段時間；當曲線在波谷附近
時，其角度值很接近 min，導致 count 值錯誤累加，當曲線持續上升或下降時，其 min 或 max 可能會
持續更新，所以當更新次數超過 β，則 count歸零，重新累計平坦曲線；當 count值累加到 γ時且物件
的位移量不小於 μ，則判定異常活動發生。α、β 與 γ 分別設定為 30、10 與 25，根據實驗觀察分析得
知溜直排輪與玩滑板的人員開始滑行時，從滑行開始至偵測出異常活動的時間內，其滑行的移動距離
大多超過 50像素距離，故 μ值設定為 50即可修正因站立不動的誤判。 
四、 實驗結果與分析 
本節首先介紹實驗相關設備以環境，接著說明各項實驗之結果。 
4.1 實驗設備與環境 
實驗設備分述如下： 
 個人電腦: CPU-Intel Pentium(R) 3.0GHz，RAM=3.0GB，Hard Disk=500GB。 
 作業系統： Windows XP professional。 
 拍攝工具: SONY  HANDYCAM  DCR- HC1000 
 開發工具： MATLAB 2008B。 
本研究的實驗場景為戶外球場，拍攝工具採用單部固定式攝影機，輸入的影像大小為 320×240像
素，每秒顯示 30張影格。本研究不將天氣因素列入實驗，主要以晴天和陰天為主，並不考慮雨天，而
且一般情況中，在雨天的戶外球場不會有人員活動，偵測異常活動的時間設定為白天，夜晚不列入拍
攝時間，視訊內容包含跑步、走路、站立等正常活動和騎自行車、溜直排輪、玩滑板等異常活動。 
4.2 實驗結果分析 
本實驗驗證整體方法在實際環境異常活動偵測之適用性。限於篇幅，僅挑選五段具代表性之視訊
做說明，如圖 13所示。內容包含走路、跑步等正常活動與溜直排輪、玩滑板、騎自行車等異常活動。 
 
     
(a) 
 
(b) 
     
(c) 
 14 
五、結論與未來研究方向 
本研究改善單人之球場異常活動偵測，並引用背景模型做為判斷前景像素，以及陰影去除法，可
以切割出完整的移動物件，使用簡易的區域追蹤進行物件追蹤，以遮蔽事件發生之前建立的行為模板
為依據，還原因遮蔽影響的物件影像，以順利取得下肢角度，再利用平坦曲線偵測演算法，分析下肢
角度曲線變化，得到異常活動會因為站姿滑行而產生平坦曲線的特性，並加入物件的位移量修正因站
立不動而導致系統出現誤判的情況，最後以連續角度變化判斷是否發生異常行為。本研究提出之方法
能克服遮蔽影響正確偵測出異常活動發生。 
基於本研究所提之方法，後續可朝以下幾個方向深入研究。(1)複雜背景環境:當球場內有愈多人
活動時，則遮蔽影響愈嚴重，愈不容易還原遮蔽物件，換言之愈不容易偵測出異常活動。因此，必須
有更適合的方法以克服複雜背景之環境。(2)遮蔽條件限制因素:本研究所提之方法須假設移動物件發生
遮蔽前，各自有一小段獨立之活動週期，藉以建立該活動之模板，若進入場地前即發生遮蔽，則必須
有更好的方法以偵測異常活動。 
在本研究計畫支持下，已指導乙位碩士班研究生畢業[17]，部份成果已投稿至「2011年全國計算
機會議」，並正撰寫完整英文論文，預計投稿至影像處理與計算機視覺相關之 SCI期刊。 
參考文獻 
[1] T. Jabid, M. H. Kabir, and O. Chae, “Gender Classification using Local Directional Pattern (LDP),” 
International Conference on Pattern Recognition, pp. 2162-2165, Aug. 2010. 
[2] V. Blanz, and T. Vetter, “Face Recognition Based on Fitting a 3D Morphable Model,” IEEE Transactions 
on Pattern Analysis and Machine Intelligence, Vol.25, no.9, pp.1063-1074, Sep. 2003. 
[3] B. Huan, G. Tian, and H. Wu, “A Method for Fast Fall Detection Based on Intelligent space,” IEEE 
International Conference on Automation and Logistics, pp. 2260-2265, Sept. 2008. 
[4] C. H. Chuang, J. W. Hsieh, L. W. Tsai, S. Y. Chen, and K. C. Fan, “Carried Object Detection Using Ratio 
Histogram and its Application to Suspicious Event Analysis,” IEEE Transactions on Circuits and Systems 
for Video Technology, Vol. 19, issue 6, pp. 911-916, June 2009. 
[5] B. Shaghafi, and D. Rajan, “Human action recognition using Pose-based discriminant embedding” Signal 
Processing: Image Communication, May 2011. 
[6] I. Haritaoglu, L. S. Davis, “W4: real-time surveillance of people and their activities,” IEEE Transaction on 
Pattern Analysis and Machine Intelligence, Vol. 22, issue 8, pp. 809-830 ,Aug. 2000. 
[7]  C. Lerdsudwichai, M. Abdel, and A. N. Ansari, “Tracking multiple people with recovery from partial 
and total occlusion,” Pattern Recognition, Vol. 38, issue 7, pp. 1059-1070, July 2005. 
[8] L. Zhu, J. Zhou, and J. Song, “Tracking multiple objects through occlusion with online sampling and 
position estimation,” Pattern Recognition, Vol. 41, issue 8, pp. 2447-2460, Aug. 2008. 
[9] R. Vezzani, C. Grana, and R. Cucchiara, “Probabilistic people tracking with appearance models and 
occlusion classification : The AD-HOC system,” Pattern Recognition Letters, Vol. 32, NO. 6, pp. 
867-877, Apr. 2011. 
[10] T. H. W. Lam, R. S. T. Lee, D. Zhang, “Human gait recognition by the fusion of motion and static 
spatio-temporal templates,” Pattern Recognition, Vol. 40, issue 9, pp. 2563-2573, Sep. 2006. 
[11] Y. Ke, R. Sukthanker, and M. Hebert, “Event Detection in Crowded Videos,” IEEE International 
Conference on Computer Vision, pp.1-8, Oct. 2007. 
[12] J. W. Hsieh, Y. T. Hsu, H. Y. Liao, and C. C. Chen, “Video-Based Human Movement Analysis and Its 
Application to Surveillance Systems,” IEEE Transactions on Multimedia, Vol. 10, issue 3, pp. 372-384, 
Apr. 2008. 
[13] H. Fujiyoshi, and A. J. Lipton, “Real-time Human Motion Analysis by Image Skeletonization,” IEEE 
International Conference on Application of Computer Vision, pp. 15-21, Oct. 1998. 
[14] 王順吉、謝長愷、翁志嘉、婁德權、江清泉，“以視訊為基礎之球場異常活動偵測”，2009全國
計算機會議 (NCS 2009)，Workshop on Image Processing, Computer Graphics, and Multimedia 
Technologies, pp. 207-218, Nov.2009. 
[15] R. C. Gonzalez, and R. E. Woods, Digital image processing, Third edition, 2008. 
[16] J. C. S. Jacques, C. R. Jung, and S. R. Musse, “Background Subtraction and Shadow Detection in 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/03
國科會補助計畫
計畫名稱: 克服多人遮蔽影響之球場異常活動偵測
計畫主持人: 王順吉
計畫編號: 99-2221-E-606-018- 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
