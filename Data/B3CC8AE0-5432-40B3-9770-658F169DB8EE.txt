Չࡹଣ୯ৎࣽᏢہ঩཮ံշ஑ᚒࣴزीฝԋ݀ൔ֋!
ीฝӜᆀǺזଢ૶Ꮻᡏϐচғଯਏ౗ၗ਑Ӹڗᄤᔞਢᆅ౛Бݤ!
ीฝጓဦǺOTD!:7.3332.F.11:.183!
୺Չයज़ǺीฝԾ҇୯:7!ԃ19!Д12!ВԿ҇୯:8!ԃ18!Д42!ВЗ!
Ь࡭ΓǺ஭ҥѳ!
ीฝୖᆶΓ঩Ǻ೚ٍཧǴ໳ί৥Ǵ೚ᑯૠǴᎄৎܴ!
୯ҥҬ೯εᏢၗૻπำس!
ᄔा!
ʳ
༊Եڤ๻ໂط࣍ૠጩ౨Ժא֗౨ᄭຟઌᅝ
ڶૻΔڂڼڕ۶ၞ۩೏ய෷ऱᇷறᛀ౉ਢԫ
ଡૹ૞ᓰᠲΖءઔߒ൶ಘԱڕ۶੡
ˡˢ˥ˀ˹˿˴̆˻ʳ ੡ഗ៕հ༊Եڤ๻ໂ๻ૠԫጟᇷ
ற౉֧࿨ዌΖڇݶೂಖᖋ᧯Ղ૿ኔ܂౉֧࿨
ዌ׌૞ऱംᠲڇ࣍ᇷறޓᄅፖਐᑑޓᄅٌ
յ֧࿇ऱംᠲΖመװઔߒኙڼംᠲऱ๠෻ֱ
ڤΔڍאආش᧤ᙀۯܿࠐᇞެΖ܀ຍଡ܂ऄ
ءᔆՂ൅ࠐᠰ؆ ˥˔ˠ ़ၴऱᏁޣΔא֗և
९ऱၲᖲழၴΖլٵ࣍א࢓Δءઔߒ༼נԱ
ࠌشኔ᧯ۯܿऱֱڤࠐ๻ૠᇷற౉֧࿨
ዌΖ׌૞უऄਢΔݺଚᇞᤩኔ᧯ਐᑑऱழ
ଢΔᄎւ๺ڇԫࠄቃ٣वሐऱኔ᧯ۯᆜՂՈ
೚ԫࠄ൶༈Ζຍᑌԫࠐᇷறऱۯᆜ༉ױא۞
طฝ೯ΔՕՕ១֏ᇷறޓᄅא़֗ၴڃگऱ
ംᠲΖݺଚՈኙ༼נऱֱऄፖԫࠄਝڶऱ౉
֧࿨ዌ೚ԱֺለΔ࿨࣠᧩قݺଚऱֱऄՕ༏
໏נΖʳ
ʳ
ᣂ᝶ڗΚݶೂಖᖋ᧯ΔᚏژߓอΔ܂ᄐߓอΔ
ᇷற࿨ዌʳ
ʳ





ʳ
˜́ʳ ˸̀˵˸˷˷˸˷ʳ ˷˸̉˼˶˸̆ʿʳ ˡˢ˥ʳ ˹˿˴̆˻ʳ ̃̅˼̀˴̅˼˿̌ʳ
̆˸̅̉˸̆ʳ˴̆ʳ̆̇̂̅˴˺˸ʳ˹̂̅ʳ˵˼́˴̅̌ʳ˸̋˸˶̈̇˴˵˿˸̆ˁʳ˗̈˸ʳ̇̂ʳ
˿˼̀˼̇˴̇˼̂́̆ʳ̂́ʳ˹̂̅̀ʳ˹˴˶̇̂̅ʳ̂̅ʳ˶̂̆̇ʿʳ̀˴́̌ʳ˷˸̉˼˶˸̆ʳ
˴˿̆̂ʳ ˶̂́̆˼˷˸̅ʳˡˢ˥ʳ ˹˿˴̆˻ʳ ˴̆ʳ ̆̇̂̅˴˺˸ʳ ̂˹ʳ ˷̌́˴̀˼˶ʳ
˷˴̇˴ˁʳ˧˻˸ʳ̆˼˺́˼˹˼˶˴́˶˸ʳ̂˹ʳ˸˹˹˼˶˼˸́̇ʳ˼́˷˸̋˼́˺ʳ̂̉˸̅ʳ
ˡˢ˥ʳ˹˿˴̆˻ʳ˴̅˸ʳ́̂̇ʳ̂́˿̌ʳ̅˸˷̈˶˸˷ʳ˖ˣ˨ʳ˶̌˶˿˸̆ʳ˵̈̇ʳ
˴˿̆̂ʳ ̃̅̂˿̂́˺˸˷ʳ ̂̃˸̅˴̇˼́˺ʳ ̃˸̅˼̂˷̆ˁʳ ˛̂̊˸̉˸̅ʿʳ
˸̋˼̆̇˼́˺ʳ ˼́˷˸̋ʳ ̆̇̅̈˶̇̈̅˸̆ʳ ˴̅˸ʳ ˻˴̅˷˿̌ʳ ˴̃̃˿˼˶˴˵˿˸ʳ
˵˸˶˴̈̆˸ʳ̂˹ʳ̇˻˸ʳ̃˻̌̆˼˶˴˿ʳ˶̂́̆̇̅˴˼́̇̆ʳ̂˹ʳˡˢ˥ʳ˹˿˴̆˻ˁʳ
˦̂˹̇ʳ˿˼̆̇̆ʿʳ˴ʳ́˴̇˼̉˸ʳ˼́˷˸̋ʳ̆̇̅̈˶̇̈̅˸ʳ˹̂̅ʳˡˢ˥ʳ˹˿˴̆˻ʿʳ
˴̅˸ʳ̃̅̂̃̂̆˸˷ˁʳ˦̂˹̇ʳ˿˼̆̇̆ʳ̂̅˺˴́˼̍˸ʳ˷˴̇˴ʳ˼́ʳ̇˸̅̀̆ʳ̂˹ʳ
̃̂˼́̇˸̅̆ʳ ̂˹ʳ ̃˻̌̆˼˶˴˿ʳ ˴˷˷̅˸̆̆˸̆ʿʳ ̆̂ʳ ˴˷˷̅˸̆̆ʳ
̇̅˴́̆˿˴̇˼̂́ʳ˴́˷ʳ˼́˼̇˼˴˿˼̍˴̇˼̂́ʳ̆˶˴́ʳ˴̅˸ʳ́̂̇ʳ̅˸̄̈˼̅˸˷ˁʳ
˧˻˸ʳ˵˴̆˼˶ʳ˼˷˸˴ʳ˼̆ʳ̇̂ʳ˴˿˿̂̊ʳ˴ʳ́̈̀˵˸̅ʳ̂˹ʳ̃̅̂˵˸̆ʳ˹̂̅ʳ
˷˸ˀ̅˸˹˸̅˸́˶˼́˺ʳ ˴ʳ ˷˴̇˴ʳ ̃̂˼́̇˸̅ˁʳ ˜́̇˸̅˸̆̇˼́˺˿̌ʿʳ ̇˻˸ʳ
̃̅̂˵˸̆ʳ ̃̅̂̉˼˷˸ʳ ̂̃̃̂̅̇̈́˼̇˼˸̆ʳ ˹̂̅ʳ ˹˴̆̇ʳ ˹̂̅̊˴̅˷ʳ
̆˾˼̃̆ʳ̂́ʳ̆˸˴̅˶˻ˁʳ˦̂˹̇ʳ˿˼̆̇̆ʳ˴̅˸ʳ̇˻˸́ʳ˸̋̇˸́˷˸˷ʳ̇̂ʳ˵˸ʳ
̀̈˿̇˼˿˸̉˸˿ʳ ˹̂̅ʳ ̆˶˴˿˴˵˼˿˼̇̌ˁʳ ˧˻˸ʳ ̀̂̆̇ʳ ˴̇̇̅˴˶̇˼̉˸ʳ
̃̅̂̃˸̅̇̌ʳ ̂˹ʳ ̆̂˹̇ʳ ˿˼̆̇̆ʳ ˼̆ʳ ˼̇̆ʳ ̆˼̀̃˿˼˶˼̇̌ʿʳ ˴́˷ʳ ˼̇̆ʳ
˸˹˹˼˶˼˸́˶̌ʳ˻˴̆ʳ˵˸˸́ʳ̉˸̅˼˹˼˸˷ʳ˵̌ʳ̂̈̅ʳ˸̋̃˸̅˼̀˸́̇̆ˁʳ ʳ
ʳ
˞˸̌̊̂̅˷̆ˍʳ ˹˿˴̆˻ʳ ̀˸̀̂̅̌ʿʳ ̆̇̂̅˴˺˸ʳ ̆̌̆̇˸̀̆ʿʳ
̂̃˸̅˴̇˼́˺ʳ̆̌̆̇˸̀̆ʿʳ˷˴̇˴ʳ̆̇̅̈˶̇̈̅˸̆ʳ
!
!
!
!
Geometry Timing
Word size 2 Bytes Word read 110 ns
Capacity 32M words Word write 80 us
Block size 64K words Block erase 0.6 s
Block endurance 100K cycles
Table 1: The specification of a typical NOR flash [3].
must be kept in RAM (which is capable of in-place updates) to avoid the chicken-and-egg problem.
Such a RAM-space requirement is no doubt a burden for embedded devices. Second, the mapping
information is unknown unless the entire flash memory is scanned. Even worse, it is in volatile
memory. It contradicts that most embedded devices are required to be instantly operational after
power is on.
Soft lists, a native index structure over NOR flash, is proposed. The major difference from
existing approaches is the use of soft pointers. Soft lists are basically linear ordered lists, in which
data objects are organized in terms of soft pointers. Unlike an ordinary physical pointer, a soft
pointer simultaneously refers to many physical addresses. The key idea of using soft pointers is to
allow a number of probes when de-referencing a soft pointer. The meanings are twofold: First, it
is possible to move data objects around without invalidating any soft pointers. It greatly simplified
the procedure of free-space reclaiming. Second, on search of keys, it is possible to skip over a large
amount of data objects if a random object is probed. It is referred to as random forward skips in
the rest of this paper. Random forward skips are taken by just following any valid object found at
the first probe. Interestingly, in most of the cases, it is even not important to know which object is
intended to be referred to by a soft pointer.
Because soft pointers are based on physical addresses, the needs for address translation and
initialization scan are completely eliminated. Although search with a soft list is surprisingly fast,
after all it emulates a linearly ordered list. It is not guaranteed to scale well as the total number of
keys is very large. To deal with this problem, a soft list is extended to be multilevel. A multilevel
soft list is of a number of parallel independent soft lists, very similar to a skip list [10]. In a multilevel
soft list, a data object has multiple soft pointers, one for each different level. Every data object
hooks on the lowest-level soft list. The higher the level a soft list is, the lower the probability a data
object hooks on it. Note that random forward skips are still taken for soft lists at any level. On
search, high-level soft lists provide long-distance skips, and low-level soft lists are visited when the
searched key is being closely approached. A multilevel soft list provides very good scalability, and
its implementation is extremely simple. Even better, it is very friendly to flash memory because
no expensive writes are required for self-reorganizing. We have conduct a series of experiments and
comparison, for which we found that soft lists are much faster than linearly ordered lists and even
skip lists.
The rest of this paper is organized as follows: Section 2 summarizes prior work related to
implementing index structures over flash memory. Section 3 presents the design and implementation
of soft lists. Section 4 includes our experimental results, and Section 5 concludes this paper.
2 Motivation
2.1 Characteristics of NOR Flash
NOR flash memory, as a kind of non-volatile memory, is write-once and bulk-erase. Initially NOR
flash is entirely of free space. Data on NOR flash are byte-addressable, and a byte can be read for
infinite times. NOR flash can be repeatedly written, provided that each write goes to different byte.
However, successive writes to the same byte must be interleaved by block erasure. A NOR-flash
block is typically 128 KB [3]. To avoid erasing a block on every update, data are updated out of
place. The old versions of the updated data are considered as invalid. As writes keep arriving, the
amount of free space on NOR flash would become low. Space occupied by invalid data is reclaimed
by means of block erasure. Before a block is erased, all valid data on the block must be moved
away. Activities for space reclaiming are referred to as garbage collection.
Each NOR-flash block individually tolerate a number of erasure operations. The limit is typically
2
2.3 Related Work
There have been many excellent index structures developed for byte-addressable RAM or block-
based storage [2]. However, they are not directly applicable to flash memory. Prior work on
indexing over flash memory are mainly based on the use of logical addresses. Wu et al. [6] and
Xiang et al. [7] propose to implement B-tree over flash memory, and a node translation table is used
to map B-tree nodes to flash-memory pages. Lin et al. [5] propose a new design of hash tables for
flash memory, for which a bucket is mapped to a collection of related flash-memory pages. Actually,
maintaining the mapping of logical addresses to physical addresses is not an issue specific to index
structures. For flash-based disk emulation [1, 11, 16], the mapping is from disk-sector numbers to
flash-memory locations. A native flash file system [17, 18] should map an i-node number with a
byte offset to flash-memory addresses.
The use of logical addresses introduces two technical issues. The first problem is that a RAM-
resident translation table is required. The translation table costs precious RAM space and energy.
For reducing the RAM-space requirements, Chang et al. [11] developed a variable-granularity
scheme for address translation. Kim et al. [15] and Lee et al. [16] propose to reduce the table size
by adopting block-level translation instead of page-level translation. As to energy consumption,
although it is not formally addressed in past work, its significance can be verified by the following
observations: A typical SDRAM [4] needs 70 mA in operating mode, 20 mA in standby mode, and
160 mA for refresh every other 64 milli-seconds. A typical NOR flash [3] needs 30 mA in operating
mode, 30 mA for read/write/erase, and 10 µA in standby mode.
Besides the costs of space and energy, the other problem of using logical addresses is that the
mapping is unknown until the entire flash memory is scanned. Wu et al. [8] propose to incrementally
commit summary information onto flash memory to help to speed up the scanning procedure. Yim
et al. [9] propose to compress the entire mapping information and put it in some handy locations.
Regardless which techniques are taken for reducing RAM footprint and for shortening scanning
time, these overheads are inevitable. Different from prior work, this work considers organizing data
in terms of physical addresses. We aim at completely removing the needs for address translation
and initialization scan.
3 Design and Implementation
of Soft Lists
This section proposes soft lists. We shall first present simple soft lists, which emulate linearly
ordered lists. Simple soft lists are then extended to multilevel soft lists for better scalability.
3.1 Simple Soft Lists
3.1.1 Index Objects and Soft Pointers
An index object is the smallest unit for indexing with soft lists. It is of a key, a value, and a soft
pointer referring to another index object. Basically the length of the keys can be arbitrary, so there
can be infinitely many other keys between any two keys. For simplicity, we use fixed-length slots for
storing keys. A value is as large as a key in size. We assume that each update to the value rewrites
the entire index object. Note that the value can also be a soft pointer referring to a data page. For
the ease of presentation, index objects, objects, and keys are interchangeably used to refer to the
same thing in the rest of this paper.
As mentioned in Section 2.2, the physical residence of index objects may involuntarily be changed
because of the needs for garbage collection. Figure 2(a) shows an scenario, in which a block has
valid objects A, B, C, and D. To erase the block for garbage collection, beforehand all the valid
objects must be moved to a spare block. However it invalidates all the physical pointers previously
referring to the objects, as shown in Figure 2(b). To revise the physical pointers, objects a, b, c,
and d can be rewritten out of place. However, recursively another batch of object rewrites could be
triggered. Because free space is consumed before free space can be reclaimed, the system might be
deadlocked.
Soft pointers are proposed to approach the problem. The basic idea is to allow a number
of “probes” when referring to an index object. In other words, if an index object is involuntarily
4
10 15 40 55 70
(a)
(b)
41
10 15 40 55 7041
{40,70}
{10}
{41,200}
{15,55}
200
200
Target objects with 
buddy objects
Figure 4: (a) A linearly ordered list. (b) A soft list with soft pointers. The degree of the soft
pointers is two.
buddy objects of the soft pointers.
3.1.2 Search with Simple Soft Lists
This section introduces simple soft lists, which organize index objects with soft pointers. We are
particularly interested in how search is carried out with soft lists and how soft pointers benefit
search.
Let us first be focused on search with a linearly ordered list. A linearly ordered list is based on
physical pointers. With the example shown in Figure 4(a), to locate a key, starting from the first
index object, iteratively we move forward until the current key is no smaller than the key to find.
The desired key is found if the current key equals to it, otherwise it does not exists. So to locate
key 200, we need to visit 7 objects.
A soft list, which emulates a linearly ordered list, organizes index objects with soft pointers.
Figure 4(b) shows an example on soft lists, in which the degree of soft pointers is two. Different
from search with a linearly ordered list, we move forward until the keys of all the probed objects
are no smaller than the key to find. Note that, on de-referencing a soft pointer for search, it is not
required to distinguish its target object from the buddy objects.
For example, in Figure 4(b), suppose that we are to find key 200. In the beginning we start
from key 10, and the next keys may be 70 and then 200. Surprisingly, it takes only three steps. On
search, it is possible that we skip too far and must fall back to try again. For example, to search key
55, starting from 10, for the first trial we go to 70, which is larger than 55, so we fall back to 10 and
try again. For the second trial we get 15, which is smaller than 55, and the search continues. From
key 15, we go straight to 55 and report the key is found. The search takes three steps only. Another
case on search is that the desired key does not exist. If we are to search 16 for example, from key
10, key 15 is visited. From key 15, for the first trial we have key 40, which is larger than 16. For
the second trial, we have key 55, which is also larger than 16. After trying all the possibilities, it is
reported that key 16 can not be found.
Because buddy objects are random objects, on search with soft lists it is possible to skip over
a large amount of index objects. However, by this way backward moves are also possible. For
example, suppose that we are to search key 41 and currently we are at key 40. From key 40 it is
possible to move backward to key 10. In this case, we shall fall back to key 40 and try again, and
this time we shall find key 41. Backward moves are of course overheads of using soft lists, and we
shall address this issue again in Section 3.2.2. Algorithm 1 shows the procedure of searching with
a simple soft list.
3.1.3 Insertion/Deletion and Spare Pointers
Different from search, insertion/deletion involve modifications to soft lists. Let us first be focused on
insertion. Because soft lists emulate linearly ordered lists, a new object is always inserted right after
the object which’s key is immediately smaller than the new key. Let the object be the immediate
predecessor of the new object. If the new object is always written as a buddy object of the immediate
predecessor, then the predecessor’s soft pointer needs not change. However, it is infeasible because
the total number of buddy objects a soft pointer can have is limited. Instead, any free space is
6
key
value
A
B
C
The valid 
pointer
An invalid 
pointerA free slot
Figure 5: An index object, in which there are four spare slots. The object’s soft pointer is in turn
revised to refer to objects A, B, and C. The fourth slot is not yet used.
we have 55. Because both 40 and 55 are larger than 16, we stop here and report that the immediate
predecessor of 16 is 15. The procedure to find immediate predecessors is very similar to that in
Algorithm 1, except that, when the algorithm reports “NOT FOUND” (i.e., Step 12), “curr” is the
immediate predecessor. A new object is then inserted right after the immediate predecessor, and
then the inserted object refers to the predecessor’s prior target object.
Deletion is carried out with a similar procedure. The immediate predecessor of the deleted object
is first located, and then the predecessor’s soft pointer is revised to refer to the target object of the
deleted object.
3.2 Multilevel Soft Lists
This section shows how simple soft lists are extended to multilevel soft lists. The design of multilevel
soft lists is extremely simple, while they are expected to have good scalability when the total number
of keys is large.
3.2.1 Structure of Multilevel Soft Lists
With random forward skips, data access over simple soft lists can be much faster than over linearly
ordered lists. However its scalability is not guanranteed. One choice is to extend soft lists to
balanced trees (such as red-black trees), since essentially these index structures are organized by
lists. However, these trees require a large number of pointer updates for balancing activities, which
in turn trigger many rewrites of index objects.
Instead of balanced trees, we propose to extend simple soft lists to multilevel soft lists. A
multilevel soft list is composed by parallel independent simple soft lists, each of which is at different
levels. Level 0 is the lowest level. An index object has n + 1 soft pointers, one for each level.
The connectivity between index objects and lists at different levels is controlled by a parameter
0 < p < 1. Let q1, q2, ..., and qn be n randomly generated numbers which are between 0 and 1. Let
q0=0. An index object hooks on the i-th level soft list only if (q0 ≤ p) ∧ (q1 ≤ p) ∧ (q2 ≤ p) ∧ ...
∧ (qi ≤ p). In other words, the probability that an object hooks on the level-n soft list is p
n.
Figure 6 shows a four-level soft list, extended from the simple soft list in Figure 4. Readers may
notice that a multilevel soft list is structurally similar to a skip list [10]. Each index object hooks on
soft lists by means of soft pointers. Note that references for random forward skips of soft pointers
are not drawn. Search with a multilevel soft list is very similar to search with a simple soft list,
since conceptually we can treat all the soft pointers at different levels as one single soft pointer with
a large degree.
Suppose that we are to locate 41. For the ease of discussion, let’s first ignore buddy objects
when de-referencing soft pointers. Starting from the highest level of key 10, the next key is 200,
which is larger than 41. So we fall back to 10 and move downward to level two. This time we get
40, which is smaller than 41, so we move forward to it. From the second level of key 40, the next
key is 200, so again we fall back and move downward to level one, and finally 41 is found.
Algorithm 1 can be slightly revised to support search with multilevel soft lists: One variable
is needed to remember at which level currently we are, and search always starts from the highest
level. Step 12 of Algorithm 1 is revised as moving downward to the next level. But if we are already
8
Consider the gray section in Figure 7, which is the expected distance between an level-i object
and its target object, i.e., p−i. Let the degree of a soft pointer be d + 1. Since buddy objects are
randomly distributed, the expected distance between two adjacent buddy objects is N/d objects.
The probability of having short skips is
p−i
N/d
. Now consider a multilevel soft list with n levels, and we are to search the key of the rightmost
object. Let Ni be the total distance traveled at the level-i soft list. Before moving downward to
the level-(i − 1) soft list, the expected number of objects visited at level i is Nip
i. Therefore, the
expected number of short skips at all levels is
n−1∑
i=0
(
p−i
N/d
·Nip
i
)
. Because
∑
n−1
i=0
Ni = N , it becomes
1
N/d
·N = d
. Interestingly, it is independent of N , i, and p. If we take d = 5, then no matter how many
objects are there, the expected total number of short skips remains 4. Furthermore, as short skips
are compensated by long skips, the net effect of short skips could be negligible, especially when the
number of objects is large. We shall provide evaluation on this in our experiments.
3.3 Space Allocation and Wear Leveling
Index objects should be randomly distributed over the entire NOR flash because the buddy objects
of a soft pointer are expected to be random objects. As readers may notice while reading on, the
design of multilevel soft lists highly relies on randomness. The rationales behind are 1) to benefit
search by random forward skips and 2) to properly estimate the costs of short skips.
For this purpose, we choose to allocate free space from a randomly selected block. Free space is
allocated to an index object when 1) the object is newly inserted, 2) the object is rewritten to change
its value, and 3) the object is rewritten to refresh all its spare pointers. As free space in blocks keep
being consumed, block erasure is then needed to reclaim space occupied by invalid objects. Suppose
that a block has been chosen as a victim for erasure (how it is chosen is discussed later). Before the
victim block is erased, the turnstile it belongs to is rotated until all the valid objects in the block
are shifted to a spare block, as mentioned in Section 3.1.1. However, as readers may notice, if the
spare block is far behind the victim block, then all the blocks in-between are involved, and a lot of
block erasure and valid-object copy are needed.
Alternatively, we can choose to directly shift all the valid objects from the victim block to the
spare block. The victim block is then erased. The benefit of this approach is that it does not involve
the blocks between the victim block and the spare block. The drawback of this approach is that
the maximum number of probes needed by intra-turnstile reference and inter-turnstile reference to
locate a target object become the same. However, as mentioned in 3.1.2, most of the time, it is
not even necessary to tell the target object from buddy objects. Besides, NOR flash reads much
faster than writes, so the extra reads can be compensated by reduced data write and block erasure.
Comparing to rotating turnstiles, wear leveling with this method needs more discussions.
Wear leveling is to evenly erase all the blocks so that the appearance of the first bad block
is postponed as late as possible. The cause of uneven lifetime of blocks is closely related to free-
space allocation. If frequently updated objects are clustered together in blocks, blocks will not be
evenly erased because garbage collection favors blocks having many invalid objects. Our free-space
allocation policy favors not only to distribute (buddy) objects over blocks randomly but also to
direct block erasure to all the blocks evenly. It is to write new objects to free space allocated from
randomly chosen blocks. By this way localities in access pattern are largely weakened, and invalid
objects could be evenly distributed over blocks. Therefore, the overheads of erasing different blocks
would be close. On space allocation, if a random block is chosen but there is no free space left, then
the block becomes a victim block. Because the selection is completely random, even if a block is of
a lot of immutable objects, eventually it will be chosen for erasure in favor of wear leveling.
10
(a) Sequential (b) Random distribution (c) Normal distribution     
1
10
100
1000
3,000 6,000 9,000 12,000
Total numbers of objects
SSL, 10^9-words reads
LOL, 10^9-words reads
SSL, 10^6-words writes
LOL, 10^6-words writes
SSL, 10^4-blocks erasure
LOL, 10^4-blocks erasure
1
10
100
1000
3,000 6,000 9,000 12,000
Total numbers of objects
1
10
100
1000
3,000 6,000 9,000 12,000
Total numbers of objects
Figure 9: The total numbers of reads, writes, and block erasure of SSL and LOL with respect to
different total numbers of keys and different access patterns. Note that the Y-axes are of logarithmic
scales.
frequencies over keys. The mean of the distribution is the median of all the keys, and the variance
is one-sixth the total number of the keys. The total number of keys varies from 2,000 to 16,000.
Figure 8 shows the total number of word reads with difference access patterns. Read overheads
comes from traversing SSL or LOL for locating a key and scanning spare pointers to find the valid
pointer. LOL’s total number of reads increases linearly with the total number of keys, as it performs
linear search. Because of random forward skips, the total numbers of reads of SSL are significantly
smaller than that of LOL in all the cases. Interestingly, SSL’s total number of reads gradually
decrease as the total number of keys is large. The rationale is that, when the total number of keys
is small, the possibility is high that a soft pointer’s buddy object is an invalid object. If an invalid
object is probed, probing is carried on until an valid object is found. Very likely that the target
object is found as the first valid object, and in this case random forward skips are not taken. If the
total number of (valid) objects is large, then random forward skips are taken with high frequencies.
It can be verified by results in Table 2, which show the average skip distance of SSL and LOL. The
skip distances of SSL are much longer than that of LOL.
Another observation on Figure 8 is that SSL’s performance is not much affected by different
access patterns. It is a characteristic of using soft pointers. Since the key of buddy objects are
random objects, the total numbers of objects visited for finding different keys are close. On the
other hand, LOL is very slow on sequential access because it uses linear search.
total # of keys 3,000 6,000 9,000 12,000
LOL 1.0 1.0 1.0 1.0
SSL 6.0 16.3 29.5 42.9
Table 2: The average skip distances of LOL and SSL with respect to different total numbers of keys.
The access pattern is a normal distribution.
4.2.2 Insertions and Deletions
This part of experiments examine SSL’s performance with updates. Each run of experiments still
uses the same setup procedure. After setup, all the keys are updated with the three access patterns.
For updating a key, the key is first deleted and then re-inserted. It intends to introduce the needs
for pointer updates.
Figure 9 shows the total numbers of reads, writes, and block erasure of SSL and LOL with
respect to different total numbers of keys and different access patterns. Note that the Y-axes are
of logarithmic scales. For reads, SSL still win its edge over LOL. Although it can not easily be seen
in the figures, the advantage is not that significant as in read-only queries. That is because SSL
spends extra reads to locate the immediate predecessor of a deleted/inserted object, as mentioned
in Section 3.1.3. Nevertheless, SSL still reads a much smaller amount of words than LOL.
For writes, SSL writes slightly more words than LOL. Note that the overheads of writes do not
include those for garbage collection. In average SSL requires 20% more word writes than LOL. That
is because logical pointers of LOL are not affected by out-place updates. We must emphasize that,
12
(a) (b)
1
10
100
1000
1 2 3 4 5 6
Total numbers of levels
MSL, 10^6-words reads
SKL, 10^6-words reads
0
100
200
300
400
4 3 2 1 0
Level numbers
Av
era
ge
 sk
ip 
dis
tan
ce
s
MSL
SKL
Figure 11: (a) The total number of words that MSL and SKL read with respect to different total
numbers of levels. The access pattern is to query with a normal distribution. (b) The average skip
distances at different levels of MSL and SKL. The total number of levels is five. The Y-axes are of
logarithmic scales.
(a) (b)
1
10
100
1000
1 3 5
Total numbers of levels
MSL, 10^7-words reads
SKL, 10^7-words reads
MSL, 10^6-words writes
SKL, 10^6-words writes
MSL, 10^5-blocks erasure
SKL, 10^5-blocks erasure
0
100
200
300
4 3 2 1 0
Level numbers
Av
er
ag
e s
kip
 di
sta
nc
es
MSL
SKL
Figure 12: (a) The overheads of reads, writes, and erasure of MSL and SKL with respect to different
total numbers of levels. The access pattern is to update with a normal distribution. (b) The average
skip distances at different levels of MSL and SKL. The total number of levels is five. The Y-axes
are of logarithmic scales.
4.3 Multilevel Soft Lists
In this section, multilevel soft lists are evaluated and compared against skip lists [10]. We are
particularly interested in whether multilevel soft lists provide good scalability as skip lists do. In
our experiments, skip lists are implemented based on pointers of logical addresses, as is LOL. In the
rest of this paper, let multilevel soft lists be denoted as MSL, and SKL refer to skip lists.
We shall first confine our attention to read-only queries. The same setup procedure for SSL/LOL
is used. The total number of keys inserted is 12,000, and the access pattern is a normal distribution
of query frequencies over keys. The probability parameter p is 0.25, as suggested in [10]. The total
number of levels that MSL and SKL have vary from 1 to 6. Figure 11(a) shows the read overheads
of MSL and SKL with respect to different total numbers of levels. MSL uses much fewer word
reads than SKL when the total number of level is small. As the total number of levels increases, as
expected, the read overheads of SKL dramatically decrease. The read overheads of MSL also drop
exponentially as the total number of levels increases. But MSL’s read overheads do not drop as fast
as that of SKL, because MSL’s read overheads are already very low when there is only one level.
For MSL, let the average skip distance be defined as the average number of objects in MSL skipped
over when de-referencing a soft pointer. The average skip distance of SKL is defined accordingly.
Figure 11(b) shows the average skip distances with respect to different levels. The total number of
levels is five. We can see that, even with the presence of short skips (as mentioned in 3.2.2), MSL
still skips further than SKL at every level.
The next part of experiments are on update operations. Experimental setup is the same as
that of SSL/LOL. Figure 12(a) shows the overheads of MSL and SKL with respect to different
total numbers of levels. As Figure 12(a) shows, MSL still read much fewer words than SKL in
all cases. Even with the extra cost of finding immediate predecessors for updates, the results in
Figure 12(a) are close to that in Figure 11(a). It means that the overheads of finding predecessors
are insignificant. Like the experiments for read-only queries, both MSL and SKL greatly reduce
the read overheads as the total number of levels is large. MSL still outperforms SKL in terms of
the average skip distances at every level, as shown in Figure 12(b). And, as expected, MSL writes
slightly more words than SKL, but their erasure overheads are close.
14
[3] Samsung Electronics Company, “K8C1215ETM 32M x16 MLC NOR Flash Data Sheet”.
[4] Samsung Electronics Company, “K4S561632J 4M x 16Bit x 4 Banks SDRAM Data Sheet”.
[5] S. Lin, D. Zeinalipour-Yazti, V. Kalogeraki, D. Gunopulos, W. A. Najjar, “Efficient Indexing
Data Structures for Flash-Based Sensor Devices,” ACM Transactions on Storage, Volume 2 ,
Issue 4, 2006.
[6] C. H. Wu, T. W. Kuo, and L. P. Chang, “An Efficient B-Tree Layer Implementation for Flash-
Memory Storage Systems,” ACM Transactions on Embedded Computing Systems, Volume 6,
Issue 3, 2007.
[7] X. Y. Xiang, L. H. Yue, Z. Z. Liu, and P. Wei, “A Reliable B-Tree Implementation over Flash
Memory,” in Proceedings of the ACM Symposium on Applied Computing, 2008.
[8] C. H. Wu, T. W. Kuo, and L. P. Chang “The Design of efficient initialization and crash recovery
for log-based file systems over flash memory,” ACM Transaction on Storage, Volume 2, Issue
4, 2006.
[9] K. S. Yim, J. H. Kim, and K. Koh, “A Fast Start-Up Technique for Flash Memory Based
Computing Systems,” in Proceedings of the ACM Symposium on Applied Computing, 2005.
[10] W. Pugh, “Skip Lists: A Probabilistic Alternative to Balanced Trees,” Communications of the
ACM, Vol. 33, No. 6, 1990.
[11] L. P. Chang and T. W. Kuo, “Efficient Management for Large-Scale Flash-Memory Storage
Systems with Resource Conservation,” ACM Transactions on Storage, Volume 1, Issue 4, 2005.
[12] Li-Pin Chang , “On Efficient Wear-Leveling for Large-Scale Flash-Memory Storage Systems,”
in Proceedings of the 22nd ACM Symposium on Applied Computing, 2007.
[13] D. W. Jung, Y. H. Chae, H. S. Jo, J. S. Kim, and J. W. Lee, “A Group-Based Wear-Leveling
Algorithm for Large-Capacity Flash Memory Storage Systems,” in Proceedings of the Interna-
tional Conference on Compilers, Architecture, and Synthesis for Embedded Systems, 2007.
[14] Y. H. Chang, J. W. Hsieh, T. W. Kuo, “Endurance Enhancement of Flash-Memory Storage
Systems: An Efficient Static Wear Leveling Design,” in Proceedings of the 44th Annual Con-
ference on Design Automation, 2007.
[15] J. Kim, J. M. Kim, S. H. Noh, S. L. Min, and Y. Cho, “A Space-Efficient Flash Translation
Layer for Compactflash Systems,” IEEE Transactions on Concumer Electronics, Vol. 48, No.
2, 2002.
[16] S. W. Lee, D. J. Park, T. S. Chung, D. H. Lee, S. W. Park, and H. J. Song, “A Log Buffer-
Based Flash Translation Layer Using Fully-Associative Sector Translation,” ACM Transactions
on Embedded Computing Systems, Vol 6, Issue 3, 2007.
[17] E. Gal and S. Toledo, “A Transactional Flash File System for Microcontrollers,” in Proceedings
of the USENIX Annual Technical Conference, 2005.
[18] D. Woodhouse, “JFFS: The Journalling Flash File System,” Proceedings of Ottawa Linux
Symposium, 2001.
16
出席國際學術會議心得報告 
                                                             
計畫編號  NSC 96-2221-E-009-072 
計畫名稱 快閃記憶體之原生高效率資料存取暨檔案管理方法 
出國人員姓名 
服務機關及職稱 
張立平 
國立交通大學資訊工程系 助理教授 
會議時間地點 Fortaleza, Brasil, 3/15~3/21 
會議名稱 ACM Symposium on Applied Computing 2008 
發表論文題目 A Self-Balancing Striping Scheme for NAND-flash Storage Systems 
 
一、參加會議經過 
 
目的： 
本次出差的目的是參加 ACM SAC 2008 研討會，SAC 為 ACM SIGAPP 所舉辦
的技術會議。會議的地點這次在巴西的 Fortaleza，為巴西東北方海岸的大都
市。本次會議，我共計發表兩篇論文，第一篇關於快閃記憶體平行架構中，透
過冗餘編碼的方法，達成動態負載平衡的法。第二篇論文則探討即時系統中，
使用 DVS (dynamic voltage scaling)的技巧達成省電效果時，所產生各個 task 
之間互相干擾的問題。本次會議（暨過去數年）的論文接受率在 25% 左右，因
此競爭可謂相當激烈。 
 
過程： 
 
這次參加會議，我發表的兩篇論文各在不同的 track，分別是 ATOS track
以及 RTS track。其中 RTS是在第一天，而 ATOS 是在第三天。會場是在 Fortaleza 
source code 的困難度與規模在哪邊，並且了解需要修改哪些地方。算是一個
很好的實務經驗的分享。接下來的論文，則討論了快閃記憶體檔案系統的安全
刪除檔案機制。此技術相當實用，尤其我們前一陣子才發生知名藝人記憶卡中
已經刪除的不雅照片被有心人士回復的案例。另一篇論文則探討了以即時工作
執行期間的 WCET(worst-case execution time)的機率分佈，並依照這樣的分佈
來探討了如何透過動態電壓調整來最小化期望之能源消耗。我個人則發表了一
篇關於固態硬碟內部平行架構上動態負載平衡的技術。基本上想法是透過將熱
門資料加入冗餘資訊並加以編碼，並將資料打散在很多獨立的記憶庫上。而透
過這樣的編碼與資料擺設方式，我們可以在執行的時候，動態地從比較不忙碌
的記憶庫取出一些資料，將原始資料倒轉解碼回來。 
 
 
二、與會心得 
 
在會議過程中，與不少外國學者交換了意見，也碰到不少台灣的教授。過程
中我發現，快閃記憶體相關管理議題，目前國際學者投入的質與量有逐年提昇
的趨勢。對我個人來說，可以算是一個好消息。 
參加這次會議，我覺得這次主辦單位辦得很用心，不論是空間，餐點等等都
很不錯，而且工作人員也很熱心。不過，因為會議地點相當奇特，周遭皆為貧
民窟，因此治安狀況相當不理想。據說有與會人士在飯店外面遭搶的狀況。 
此次會議的註冊政策方面，採用了比較革新的方式。也就是註冊的時候可以
選擇不要紙本的 proceedings。我個人相當贊同這樣的作法，畢竟現在大家找論
