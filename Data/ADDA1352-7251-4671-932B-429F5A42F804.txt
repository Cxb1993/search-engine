 2 
In this research, we proposed three new strategies to overcome the swarm stagnation 
problem of PSO and applied the proposed PSO to solve the Markowitz’s mean-variance model 
with five benchmark data sets contained in the OR library [3]. For each data set, the OR library 
provides an exact efficient frontier for reference. Computational results showed that the new 
strategies help overcome the swarm stagnation problem for a basic PSO and improve its 
explorative capability. In addition, for each benchmark data set, the proposed PSO algorithm 
generated an efficient frontier closer to the referred efficient frontier than those generated by 
genetic algorithms, tabu search, and simulated annealing for all the test data sets.  The rest of 
this paper is organized as follows. Section 2 presents literature reviews on PSO and 
Markowitz’s model. Section 3 presents the proposed PSO as well as the way to apply it to solve 
Markowitz’s model. The computational results are discussed in Section 4 and Section 5 
concludes some findings in this paper. 
 
 
2. Literature Review 
In this section, we first review the PSO and the parameters that may affect its performance. 
Then, we describe the standard Markowitz model and illustrate the way to generate the efficient 
frontier.   
2.1 Particle Swarm Optimization 
Particle swarm optimization (PSO), similar to evolutionary algorithms, is a 
population-based search algorithm. Particle, a member in a population, searches a solution 
space by dynamically adjusting its position (a solution in the solution space) according to its 
own experience and the experiences of all the particles in the population [1, 12, 13]. The 
position of a particle is described as follows: 
)1()()1(  tVtxtx iii             (1) 
Where )(txi denotes the current position of particle i in the search space at time step t. The 
position of the particle is changed by adding a velocity )1( tVi to the current position and 
)1( tVi  is calculated as follows: 
))((()))((())()1( 21 txprandctxprandctVwtV igiiii      (2) 
Where )(tVi  is the velocity of particle i at time step t. The inertia weight, w, is a parameter used 
to weight the contribution of the previous velocity on the new velocity; it is designed as a 
mechanism to control the exploration and exploitation abilities of PSO [1, 4, 19, 20]. The 
personal best position, pi , is the best position that particle i has ever visited, and the global best 
position, pg, is the best position that all the particles have ever visited. The c1 and c2 are positive 
constants used to scale the contribution of the personal best solution and the global best 
solution respectively, and rand() is a random value sampled from a uniform distribution with a 
range of [0, 1]. Therefore, the term, ))((()1 txprandc ii  , refers to the effect of personal 
experience on particle i (social learning) and the term, ))((()2 txprandc ig   , refers to the 
effect of global experience on particle i (social influence). Population size and termination 
criterion are two other parameters needed to be determined when implementing PSO. The 
maximum number of time steps, tmax, is a commonly used termination criterion. The procedure 
of a basic PSO can be summarized as follows: 
Step 1: Randomly generate a population with M particles at initial time step (t = 0). 
Step 2: Calculate the objective value for each particle in the population and find the personal 
 4 
Rexp be the desired expected return, 
then the standard Markowitz mean –variance model is presented as follows: 
N N
=1 =1
N
exp
=1
(1)                                                                                                 
    subject to 
                =                                  
i j ij
i j
i i
i
Min w w
w u R
 

N
=1
(2)
(3)
                                                             
                =1                                                                                                     
       
i
i
w
         0 1  ,     = 1,...,                                                                    iw i N 
 
Equation (1) minimizes the total variance (risk) associated with the portfolio; Equation (2) 
ensures that the portfolio has an expected return of Rexp; Equation (3) ensures that the 
proportions add to one. Solving the model with different levels of expected return, we can 
produce different combinations of expected returns and risks that can trace out an efficient 
frontier.  Chang et al. [3] modified the model by introducing a parameter, λ, to weight the 
relative importance of the expected return and the risk. The case λ=0 represents a case that 
maximizes portfolio expected return (without caring the risk), and the case λ=1 is the case that 
minimizes the total risk with selected portfolio (without caring the expected return). Between 
the two extreme cases, λ represents a tradeoff between the risk and the expected return. 
 
 
N N N
=1 =1 =1
N
=1
               - 1-
          
             subject to 
                         =1
                         0 1  ,     = 1,...,                   
i j ij i i
i j i
i
i
i
Min w w w u
w
w i N
  
   
     
  
 
 

                                                             (10)
 
 
3. Proposed particle swarm optimization for portfolio selection 
We propose three strategies to help overcome the swarm stagnation for the basic PSO and 
improve its explorative capability. Strategy one proposes to utilize multiple global best 
solutions for the particles in each population. In this research, the top three solutions, denoted 
as pg1, pg2, and pg3, are chosen to be the global best solutions. Then in each time step, the 
population is equally divided into three groups and pg1 is used as the global best solution for 
calculating the velocity for the particles in the first group, pg2 is used as the global best solution 
for calculating the velocity for the particles in the second group; however, by trial-and-error, the 
average of the three global best solutions, (pg1+pg2+pg3)/3, is used as the global best solution for 
calculating the velocity for the particles in the third group. Strategy two proposes to use the idea 
of the mutation operation of genetic algorithms. It sets a threshold value for the velocity for 
each particle. If, during the search of PSO, the velocity of a particle is less than the threshold 
 6 
data set, these three heuristics were applied to the model (equations (5)-(7)) with fifty different 
λ values equally spaced in [0, 1] to generate 50 pairs of mean return and risk; the average 
percentage deviation of the fifty pairs of solutions from the corresponding efficient frontier is 
used to evaluate the performance of the heuristics.      
 The proposed PSO was also applied to the model with the same fifty different λ values to 
generate 50 pairs of mean return and risk for the data sets. We first applied the algorithm with 
different combinations of the strategies to the first data set, Hang Seng 31, and compared their 
performance to investigate the effects of the proposed strategies on the basic PSO algorithm. 
Then we applied the proposed PSO with the best combination of the strategies to the other four 
data sets and compared the average percentage deviation produced by the proposed PSO with 
those produced by the three heuristics, GA, SA, and TS, developed by Chang et al [3]. Table 1 
presents the average percentage deviations between the efficient frontiers, produced by the 
proposed PSO with different combinations of the strategies, and the exact efficient frontier for 
Hang Seng 31. A three-dimension array is used to denote the combinations. The first element in 
the array refers to the condition of the first strategy: 1 means the strategy is used and 0 means 
the strategy is not used. The second and the third elements in the array similarly refer to the 
condition of the second and the third strategy respectively. The proposed PSO with an array (0, 
0, 0) refers to the basic PSO algorithm that does not utilize any of the three strategies. The 
average percentage deviations produced by the proposed PSO with (0, 0, 0), (1, 0, 0), (0, 1, 0) 
and (0, 0, 1) are 1.77e-03, 4.49e-04, 2.31e-007 and 2.30e-05 respectively.  These results show 
that all the proposed strategies are able to improve the effectiveness of the basic PSO, but the 
effect of the second strategy is much stronger than the other two strategies.  This may conclude 
that although all the three strategies are able to help overcome the swarm stagnation for the 
basic PSO algorithm, the second strategy is much more advanced than the other two strategies. 
Furthermore, the results produced by the proposed PSO with (0, 1, 0), (0, 1, 1) and (1, 1, 0) 
show that the third strategy further improves the performance of the proposed PSO with (0, 1, 
0); it reduces the average percentage deviation from 2.31e-005 to 5.22e-006. However, the 
results show that the first strategy and the second strategy have strong interaction. The average 
percentage deviation produced by the proposed PSO with (1, 1, 0) is 6.90e-05, which 
significantly worsens the average percentage deviation (2.31e-007) produced by the proposed 
PSO with (0, 1, 0). At last, the results of the proposed PSO with (0, 1, 1) and (1, 1, 1) show that 
the first strategy slightly improves the performance of the proposed PSO with (0, 1, 1); it 
reduces the average percentage deviation from 5.22e-006 to 4.30e-006.  
Table 1 concludes that the proposed PSO with (1, 1, 1) produced the best result, so it was 
applied to the other four data sets. Table 2 presents the average percentage deviations produced 
by the proposed PSO, the basic PSO, the constriction PSO,  and the heuristics, GA, SA and TS, 
developed by Chang et al. [3] for all the five data sets. The mean percentage deviations show 
that the proposed PSO outperforms the basic PSO and the constriction PSO in all the data sets. 
This confirms that the proposed PSO is able to help overcome the swarm stagnation for the 
basic PSO algorithm and improve its explorative capability. In addition, the mean percentage 
deviations show that the proposed PSO outperforms GA, SA and TS in all the data sets. This 
concludes that the proposed PSO is an effective algorithm for the candidate problem. 
Furthermore, Chang et al. [3] showed that the number of solutions searched using their GA, SA 
and TS to generate a pair of mean return and risk on an efficient frontier is 1000*N (N is the 
number of assets in a data set), so the number of solutions searched using Chang et al.’s [3] GA, 
SA and TS for Hang Seng 31 is 31,000, for DAX 85 is 85,000, and so on. However, the number 
of solutions searched using the proposed PSO is 300,000 for all the data sets. Therefore, the GA, 
SA and TS heuristics are more efficient than the proposed PSO. 
 
  
PSO is more effective than the GA, SA and TS developed by Chang et al. for generating 
efficient frontiers for the candidate problem with the five benchmark data sets.  
As mentioned, many PSO algorithms have been applied to solve complicated 
optimization problems; the proposed strategies are worthwhile to work with other PSO 
algorithms for solving optimization problems. 
 
 
  
international conference on evolutionary computation, pp 69–73. IEEE Press, Piscataway, 
NJ. 
20. Trelea IC (2003) The particle swarm optimization algorithm: convergence analysis and 
parameter selection. Information Processing Letter 85: 317–325. 
21. Van Den Bergh F, Engelbrecht AP (2002) A new locally convergent particle swarm 
optimizer. Proceedings of IEEE conference on systems, man and cybernetics, Hammamet, 
Tunisia. 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：陳春龍 計畫編號：99-2221-E-004-003- 
計畫名稱：運用新的粒子群演算法求解馬可維茲資產組合選擇模型 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
