2 
 
2008). In some cases, two relevant terms never occur with each other. They will not be found 
by the traditional methods. In other cases, a term may have more than one meaning. A very 
famous example is that “java” has at least two well-known meanings: it can be either a 
location (Java Island) or a programming language. The relevant terms of java for these two 
meanings are obviously different. The traditional methods cannot distinguish between these 
two meanings and the suggested terms may be a mixture of both meanings (Chen et al., 
2008).  
Most traditional methods are lacking to identify the semantic relationships between 
terms. Although some researchers (Abhishek and Hosanagar 2007; Amiri et al., 2008; Joshi 
and Motwani 2006) claim that their method can suggest terms with the feature of semantic 
relationship, but they are neither available on the Internet nor obtainable the degree of 
similarity between terms. In this research, we focus on the problem of using several semantic 
analysis methods, including Latent Semantic Indexing (LSI), Probabilistic LSI (PLSI), and 
Keyword Relationship Graph (KRG), to implement a term suggestion system. Our system not 
only has the ability to identify the semantic relationships between terms but also has the 
ability to calculate the similarity degree between terms. Furthermore, PLSI may take a lot of 
iterations to reach a local optimal solution. To save the computing resource of PLSI, we then 
design an intelligent stopping strategy to halt PLSI’s process. The goal of this strategy is not 
to reach a local optimal solution, but rather to reach an effective solution.  
We make two contributions in this research. First, we implement a prototype system, 
which is based on the concept of LSI and PLSI. Based on the characteristics of LSI and PLSI 
(Deerwester et al., 1990; Hofmann 1999), our system can gracefully deal with the problems 
of synonymy and polysemy. Second, we design a dynamic stopping strategy of PLSI to 
provide an effective solution. According to the results of simulation analysis, we conclude 
that our strategy can yield an effective solution in a comparatively short amount of time.  
The rest of this research is organized as follows. The next section briefly reviews some 
related work. In section 3, the details of our proposed system are described. We present some 
experimental results in Section 4. Finally, we conclude this research with future work in 
Section 5.  
Term Suggestion Methods 
According to related researches (Chen et al., 2008; Ferragina and Guli 2008; Joshi and 
Motwani 2006; Wang et al., 2008), term suggestion can be broadly divided into three 
categories: proximity search, query log analysis, and Web snippet analysis. Table 1 shows the 
comparison of advantages and disadvantages between different categories. 
 
4 
 
(2006) 
Chen and Zhang 
(2009) 
  
Web snippet analysis 
Wu and Chen 
(2003) 
 (Highlight) http://highlight.njit.edu/ 
Carpineto and Romano  
(2004) 
 (Credo) http://credo.fub.it/  
Osinski and Weiss  
(2005) 
 (Carrot2) http://search.carrot2.org/ 
Radovanović and Ivanović 
(2006)  
 (CatS) http://stribog.im.ns.ac.yu/cats/servlet/CatS  
Segev et al.  
(2007) 
 (Clusty) http://clusty.com/ 
Ferragina and Guli  
(2008)  
 (SnakeT) http://snaket.di.unipi.it/  
KRG + LSI + PLSI 
Cayley Group 
(2009) 
 (VLDP_KRG) http://cayley.sytes.net/VLDP_KRG  
 
For the second category, query log analysis, it analyzes the content of query logs to find 
out the co-occurrence relationships between terms and suggest similar terms starting from the 
seed term (Google 2006; Mei et al., 2008; Yahoo 2006). Since this category uses a term 
matching method to implement it, the most popular search terms related to the seed term 
should be suggested (Mei et al., 2008). However, it also cannot produce relevant terms that do 
not contain the seed term (Abhishek and Hosanagar 2007). Google and Yahoo officially 
released Google AdWords (GAwords) (Google 2006) and Yahoo Search Marketing (YSM) 
(Yahoo 2006) systems, respectively, which are two famous commercial products that belong 
to this category. Chen and Zhang (2009) proposed a personalized query suggestion approach 
that uses the query-concept bipartite graphs and concept relation trees to update the weight of 
every candidate suggested terms. 
For the third category, Web snippet analysis, it first sends the seed term to multiple 
search engines. Then, it collects all snippets that are summarized by remote search engines. 
Finally, it uses several document cleaning and pattern matching techniques to analyze 
snippets. All terms or phrases appeared on the results of document cleaning and pattern 
matching that can be considered as the candidate suggested terms (Ferragina and Guli 2008; 
Wang et al., 2008). Since this category uses a natural language processing method to 
implement it, it can suggest the terms with semantic relationships and variable word length 
(Ferragina and Gulli 2004). However, it fails to suggest such terms that do not appear on 
snippets. Wu and Chen (2003) released a Highlight system that adopts a lexical analysis and a 
6 
 
the Probability of Query and Document (PQD) occurring in a mixture of latent topics, based 
on the models of LSI and PLSI. The system flow chart of VLDP is shown in Figure 1. First of 
all, in the Vector Space Model (VSM) step, we use a search engine to transform the query 
logs and Web pages into a VSM matrix. Secondly, in the LSI step, we use a truncated SVD 
technique to transform the VSM matrix into the LSI model. Thirdly, in the Dual Probability 
step, we use a dual probability model to transform the LSI model into the probability form of 
LSI. This step serves not only to transform the LSI model into the probability form, but also 
to obviate a problem of SVD that may introduce negative values in the decomposition process 
and such values cannot be treated as a probability distribution. Finally, in the PLSI step, we 
use an EM algorithm to transform the probability form of LSI into the PLSI model, which is 
final training parameter. 
 
<~~~Figure 1 in here~~~> 
VSM Step 
In this research, we use the VSM model to represent the similarity feature between terms 
that appears in a collection of documents. In this step, we use a search engine to transform all 
collected query logs and Web pages into a VSM matrix as shown in the following figure, 
where M is all collected terms in a log file and N is all collected Web pages in our search 
engine. 
 
<~~~Figure 2 in here~~~> 
 
In our prototype system, we used the source of AOL Query Log (AOL 2006), which 
consists of about 20 million instances of queries collected from about 650 thousand users, as 
our main collected terms, and the cached pages of our search engine, which consist of about 
100 million Web pages collected from the Internet, as our collected Web pages. 
For each entry of the VSM matrix, vsm(qi,dj), we refer to our previous project (Chen and 
Luh 2005). This project is based on the primacy effect of browsing behavior (Morris and 
Maisto 2001); that is, users prefer top ranking items in the search results, and this preference 
always gradually decreases. Based on the primacy effect, we define a User Behavior Function 
(UBF) to express the behavior of human browsing as follows: 
 

 objxobjxUBF ),(    (where 0<<1 and <0) (1) 
 
where  is the degree of user preference for the first item; xobj is the relative order of the 
object obj within an ordered item list x; and  is the decline degree of the user preference. 
8 
 
  
M
i kikikik
uquqzqpU
1
22 )exp(/)exp()|(  (4) 
 
k
k kkkk
ffzp
1
)(/)()(   (5) 
  
N
j kjkjkjk
vdvdzdpV
1
22 )exp(/)exp()|(  (6) 
 
where p(qi|zk), p(zk), and p(dj|zk) are all PLSI parameters defined in section 3.1.4, and uk, k, 
and vk are all LSI parameters previously defined in section 3.1.2. 
PLSI Step 
The LSI model explores the structure of term co-occurrence and solves the problem of 
synonym very well. However, it brings noise while reducing the dimensionality because it is 
unable to recognize the polysemy of a same term in different latent topics. Hofmann (1999) 
proposed a PLSI model to provide a probabilistic version of LSI that attempts to capture the 
polysemy terms from all collected terms and Web pages. 
The PLSI model is based on a statistic model called aspect model, which can be utilized 
to identify the hidden semantic relationships among terms. For the given aspect model, PLSI 
supposes that a term qi and a Web page dj exist as a mixture of latent topics Z={z1,…,zk}. 
PLSI then computes relevant probability distributions pqd(qi,dj) by selecting the parameters of 
PLSI that maximize the probability of observed data, i.e., the likelihood function. 
Now, let us formally describe how to calculate the training parameter, called PQD 
matrix (Figure 3), by the PLSI model. 
 
<~~~Figure 3 in here~~~> 
 
To calculate the entry of PQD matrix, pqd(qi,dj), we first need to define the following 
probability notations: 
 p(qi) denotes the probability that a particular term qi will be selected. 
 p(zk|qi) denotes the posterior probability of a latent topic zk given the observation qi. 
 p(qi|zk) denotes the posterior probability of qi given the observation zk. 
 p(dj|zk) denotes the posterior probability of a particular Web page dj given the 
observation zk. 
 
According to these definitions, PLSI first calculate the joint probability of an observed 
pair, pqd(qi,dj), by summing over all possible choices of k from which the observation has  
been generated, as shown in the following equation: 
10 
 
 
k
k kjkkikjkkijik
zdpzpzqpzdpzpzqpdqzp
1
)|()()|(/)|()()|(),|(  (10) 
 
3. Finally, in the maximization step, PLSI applies the Lagrange multipliers method (see 
(Hofmann 2001) for details) to solve the constraint maximization problem to get the 
following equations for re-estimated the PLSI parameters as follows: 
 
    
N
j
M
i
N
j jikjijikjiki
dqzpdqvsmdqzpdqvsmzqp
1 1 1
),|(),(/),|(),()|(  (11) 
      
M
i
N
j
M
i
N
j jijikjik
dqvsmdqzpdqvsmzp
1 1 1 1
),(/),|(),()(  (12) 
    
M
i
M
i
N
j jikjijikjikj
dqzpdqvsmdqzpdqvsmzdp
1 1 1
),|(),(/),|(),()|(  (13) 
 
Now we can substitute equations (11) to (13) into equations (8) and (9) that will result in 
the monotonically increasing of the total likelihood function Ln(qi,dj) of the observation data. 
The executing of expectation and maximization steps are repeating until a stopping criterion 
is reached. 
Let us now discuss the stopping criterion of PLSI in detail. According to relevant 
literatures, the stopping criterion of PLSI can be defined as: (1) a local optimal solution is 
reached (Hanselmann et al., 2008; Wu et al., 2008); or (2) a predefined number (iterations or 
threshold) is reached (Park and Ramamohanarao 2009; Xue et al., 2008). 
For the first case, “a local optimal solution is reached”, we define the local optimal 
solution is reached if the improvement value between two consecutive iterations (In) is less 
than an allowable value (). 
 
nI  
where 
),(),( 1 jinjinn dqLdqLI   
(14) 
 
For the second case, “a predefined number is reached”, it is hardly to claim what the 
best predefined number should be. On the one hand, a large number may waste a significant 
amount of computing resources on relatively slim improvement. On the other hand, a small 
number may result in a premature convergence. It will be an effective solution if the required 
number of iterations is dynamically determined by the status of improvement history 
progress. 
12 
 
(CNn) exceeds the benefit obtained from the increase in the cumulative probability of success 
(MANn), as shown in the following figure. 
 
<~~~Figure 4 in here~~~> 
KRG Stage 
The main purpose of this stage is to rank all suggested terms according to the edge 
weight of the KRG graph, which is derived from the training parameter of previous stage. The 
system flow chart of KRG is shown in Figure 5. First of all, in the KRG without Edge Weight 
step, we apply the Breadth First Search (BFS) algorithm and the concept of inverted index to 
build a KRG graph. Secondly, in the KRG with Edge Weight step, we measure the similarity 
degree between terms based on the edge weight of the KRG graph. 
 
<~~~Figure 5 in here~~~> 
KRG without Edge Weight Step 
KRG is a relatively new graph concept that is applied to filtering a large database (Chen 
et al., 2009; Zhou and Pei 2009). In the concept of KRG graph, a node corresponds to a term 
and an edge indicates there is a relationship between terms present in the database. The 
weight of an edge is used to measure the importance of this relationship. Following the 
concept of KRG, we define our graph terminology as follows. 
In our definition of KRG(V,E,W), based on a given query qi, V is a set of nodes, each of 
which corresponding to a candidate term qct listed in the VSM matrix. E is a set of directed 
edges, an edge (qi,qct) represents that these two terms exist in a semantic relationship and qct is 
suggested from qi. W is a set of weight vectors, each of which using to measure the degree of 
similarity between the edge (qi,qct). 
 
Definition 1. The semantic relationship between qi and qct 
Two terms, qi and qct, exist in a semantic relationship if and only if these two terms have at 
least one of the following relationships: equivalence, hierarchy, and association. First of all, if 
qi and qct share a same concept, these two terms exist in an equivalence relationship. Secondly, 
if qi and qct exist in a parent-child relationship through an intermediate term, these two terms 
exist in a hierarchy relationship. Finally, if qi and qct exist in an ancestor-descendant 
relationship through a series of intermediate terms, these two terms exist in an association 
relationship. 
 
<~~~Figure 6 in here~~~> 
14 
 
semantic relationship is 6531
542 qqqq
ddd  ). Finally, for the association 
relationship, the list of directed edge based on q1 is E<(q1,q6)>. 
KRG with Edge Weight Step 
Although in the previous step, BuildKRG uses the parameter MaxRunLen to reduce the 
size of KRG, but we still need to prune the number of directed edges in advance. That is, if the 
edge weight of KRG is less than a relatively small edge weight, we do not further consider it 
in further recursive calls. In summary, the edge weight of KRG is not only used to determine 
the degree of similarity between terms, but also used to discard the candidate terms with a 
relatively small edge weight. 
Let us now discuss how to calculate the edge weight of KRG (line 16 in the BuildKRG 
algorithm). In this step, we use the cosine similarity metric to transform the training 
parameter of the VLDP stage, PQD matrix, into the edge weight of KRG by the following 
equation:  
 





N
j jct
N
j ji
N
j jctji
cti
dqpqddqpqd
dqpqddqpqd
qqSim
1
2
1
2
1
),(),(
),(),(
),(  (18) 
 
where pqd(qm,dj), m{i,ct}, is the entry of PQD matrix, which is the joint probability of an 
observed pair (qm,dj). For example, in Figure 9, the degree of similarity of the directed edge 
(“susan boyle”, “i dreamed a dream”) is 49%. 
 
<~~~Figure 9 in here~~~> 
 
Example 2. KRG with Edge Weight Step 
According to the result of example 1, the set of directed edges is E<(q1,q2), (q1,q3), (q1,q4), 
(q1,q5), (q1,q6)>. Figure 10 shows a partial example of the PQD matrix via the VLDP stage. 
 
<~~~Figure 10 in here~~~> 
 
Table 3 lists the edge weight of KRG by equation (18). In this graph, we discard the candidate 
term q4 since its directed edge with a relatively small edge weight. 
 
Table 3: A partial example of the KRG graph 
V q2 q3 q4 q5 q6 
E (q1, q2) (q1, q3) (q1, q4) (q1, q5) (q1, q6) 
16 
 
 
For comparison purpose, we then average all PR@K values for each evaluated system 
as shown in Table 4. According to the results of Table 4, we find that VLDP_KRG is better 
than other systems at least 7.8 percent on average. 
 
Table 4: Average PR@K values for different systems 
 Average PR@3 Average PR@5 Average PR@7 Average PR@10 
GPS 0.659 0.608 0.565 0.504 
GAwords 0.776 0.751 0.701 0.640 
YSM 0.786 0.750 0.703 0.642 
Highlight 0.731 0.686 0.633 0.576 
Credo 0.607 0.563 0.511 0.453 
Carrot2 0.776 0.738 0.680 0.621 
CatS 0.504 0.481 0.427 0.362 
Clusty 0.821 0.791 0.728 0.670 
SnakeT 0.796 0.759 0.701 0.651 
VLDP_KRG 0.887 0.853 0.811 0.737 
 
For all quantitative analyses, we used a SPSS statistical software and the level of 
statistical significance was set at p<0.05. We first used the Analysis of Variance (ANOVA) 
test to determine whether there was a statistically significant difference in the performance of 
different systems. The results of one-way ANOVA test are presented in Table 5. According to 
the results of one-way ANOVA test shown in Table 5, the difference is statistically significant 
at the 95% confidence level. We then conducted a post host Fisher’s Least Significant 
Different (LSD) test for pair-wise comparison at the 5% significant level. Since the results of 
LSD are long-winded and complicated, we encourage the readers who are interesting to our 
full-length report (CayleyGroup 2010). According to the results of LSD, our system is found 
to be significantly better than other systems. 
 
Table 5: The results of one-way ANOVA test 
  Sum of Squares df Mean Square F Sig. 
PR@3 
Between Groups 3.714 9 0.413 378.144 0 
Within Groups 0.338 310 0.001 
  
Total 4.052 319 
   
PR@5 
Between Groups 3.758 9 0.418 405.525 0 
Within Groups 0.319 310 0.001 
  
Total 4.077 319 
   
18 
 
than 77 since we simulate additional 48 (77–29) iterations and obtain additional L only 
21.889 (537.459–515.47). That is, we perform additional computing resources than the 
second case that may result in inappreciable improvement. 
 
<~~~Figure 12 in here~~~> 
 
To verify whether the second case is an effective solution, we further simulate 1000 
times about the Cost/Performance Ratio (CPR) of the simulation results calculated by the 
second case (“n=system”) with some predefined numbers of iterations. The predefined 
numbers of iterations are “n=20”, “n=40”, “n=60”, “n=80”, and “n=100”. 
In our CPR metric, we first need to define a Performance Rate (PR) metric between the 
real L achieved by the n
th
 iteration (Ln(qi,dj)) and the local optimal L (Loptimal(qi,dj)) as follows: 
 
),(/),( jioptimaljinn dqLdqLPR   
where 
),100,80,60,40,20( systemn   
(20) 
 
Figure 13 is the PR distribution over 1000 simulation runs. For demonstrating purpose, 
the dot in Figures 13 and 14 is the average value over 50 simulation runs. The average PR 
values for different ns are 0.896464 (n=20), 0.986531 (n=40), 0.998265 (n=60), 0.999788 
(n=80), 0.999984 (n=100), and 0.959145 (n=system), respectively. The standard deviation for 
all PR values is 0.040783. 
 
<~~~Figure 13 in here~~~> 
 
In our CPR metric, we then need to define a Cost Rate (CR) metric between the real 
required number of iterations achieved by the n
th
 iteration (RQNn) and the local optimal 
(RQNoptimal) as follows: 
 
optimalnn RQNRQNCR /  (21) 
 
A lower CR value is benefit for the computing resources. However, a lower CR value 
will result in a lower PR value. Figure 14 is the CR distribution over 1000 simulation runs. 
The concept of CR metric is the ratio of the number of iterations required by a specific 
iteration (n) and the local optimal solution (optimal). Obviously, a lower CR value indicates 
that the cost of iteration n is low compared to the local optimal solution. The average CR 
20 
 
relationships, including synonymy and polysemy, but also the ability to calculate the 
similarity degree between terms. LSI and PLSI are designed to solve these two problems. 
That is, our mixed method can be applied to solve the following problem: finding any two 
objects with a semantic relationship and calculating the similarity degree between these two 
objects. Currently, we run the VLDP stage in a batch processing mode because the computing 
time of LSI and PLSI is very time-consuming. In the future, we plan to integrate the 
technology of Web snippet analysis into our VLDP stage to suggest up-to-date terms. 
 
References 
 
Abhishek, V., & Hosanagar, K. (2007). Keyword Generation for Search Engine Advertising 
using Semantic Similarity between Terms. Proceedings of the Ninth International 
Conference on Electronic Commerce, pp. 89-94. 
Agirre, E., & Edmonds, P. (2006). Text, Speech and Language Technology, Volume 33 - Text 
Speech and Language Technology (Chapter 6: Unsupervised Corpus-Based Methods 
for WSD), Springer Press. 
Amiri, H., AleAhmad, A., Rahgozar, M., & Oroumchian, F. (2008). Keyword Suggestion Using 
Concept Graph Construction from Wikipedia Rich Documents. Proceedings of the 30th 
European Conference on Information Retrieval.  
AOL. (2006). AOL Search Data. Retrieved 30 March 2010 available at: 
http://www.gregsadetsky.com/aol-data/  
AOL. (2008). AOL Search - 2008 Year End Hot Searches. Retrieved 30 March 2010 available at: 
http://about-search.aol.com/hotsearches2008/index.html  
Carpineto, C., & Romano, G. (2004). Exploiting the Potential of Concept Lattices for 
Information Retrieval with CREDO. Journal of Universal Computer Science, 10(8), 
985-1013. 
CayleyGroup. (2010). VLDP_KRG's Evaluation Results. Retrieved 30 March 2010 available at: 
http://cayley.sytes.net/vldp_krg/OUTPUT_VLDP_KRG.htm  
Chen, L.-C., & Luh, C. J. (2005). Web Page Prediction from MetaSearch Results. Internet 
Research: Electronic Networking Applications and Policy, 15(4), 421-446. 
Chen, L. C., Luh, C. J., & Jou, C. (2005). Generating Page Clippings from Web Search Results 
Using a Dynamically Terminated Genetic Algorithm. Information Systems, 30(4), 
299-316. 
22 
 
Hofmann, T. (2001). Unsupervised Learning by Probabilistic Latent Semantic Analysis. 
Machine Learning, 42(1), 177-196. 
Hofmann, T. (2004). Latent Semantic Models for Collaborative Filtering. ACM Transactions on 
Information Systems, 22(1), 89-115. 
Joshi, A., & Motwani, R. (2006). Keyword Generation for Search Engine Advertising. 
Proceedings of the Sixth IEEE International Conference on Data Mining, pp. 490-496. 
Lycos. (2008). Top Search Terms for 2008. Retrieved 30 March 2010 available at: 
http://www.lycos.com  
Mei, Q., Zhou, D., & Church, K. (2008). Query Suggestion Using Hitting Time. Proceeding of 
the 17th ACM Conference on Information and Knowledge Mining, pp. 469-478. 
Metzler, D., & Croft, W. B. (2007). Latent Concept Expansion Using Markov Random Fields. 
Proceedings of the 30th Annual International ACM SIGIR Conference on Research and 
Development in Information Retrieval, pp. 311-318. 
Morris, C. G., & Maisto, A. A. (2001). Psychology: An Introduction, Prentice Hall Press. 
Osinski, S., & Weiss, D. (2005). A Concept-Driven Algorithm for Clustering Search Results. 
IEEE Intelligent Systems, 20(3), 48-54. 
Park, L. A. F., & Ramamohanarao, K. (2009). Efficient Storage and Retrieval of Probabilistic 
Lantent Semantic Information for Information Retrieval. The VLDB Journal, 18(1), 
141-155. 
Radovanović, M., & Ivanović, M. (2006). CatS: A Classification-Powered Meta-Search Engine. 
Advances in Web Intelligence and Data Mining, 23(1), 191-200. 
RapidKeyword. (2006). Rapid Keyword – Keyword Research Software and Keyword Generator 
Tools. Retrieved 30 March 2010 available at: http://www.rapidkeyword.com/  
Segev, A., Leshno, M., & Zviran, M. (2007). Context Recognition Using Internet as a 
Knowledge Base. Journal of Intelligent Information Systems, 29(3), 305-327. 
Wan, X. (2009). Combining Content and Context Similarities for Image Retrieval Lecture Notes 
in Computer Science, 5478(1), 749-754. 
Wang, J., Mo, Y., Huang, B., Wen, J., & He, L. (2008). Web Search Results Clustering based on 
a Novel Suffix Tree Structure. Lecture Notes in Computer Science, 5060(1), 540-554. 
Wu, H., Wang, Y., & Cheng, X. (2008). Incremental Probabilistic Latent Semantic Analysis for 
Automatic Question Recommendation. Proceedings of the 2008 ACM Conference on 
Recommender Systems, pp. 99-106. 
Wu, Y.-F., & Chen, X. (2003). Extracting Features From Web Search Returned Hits for 
Hierarchical Classification. Proceedings of the International Conference on 
Information and Knowledge Engineering, pp. 103-108. 
24 
 
List of Figures 
 
Dual Probability Step
Symbol  : p(qi|zk), p(zk), p(dj|zk)
Equation: (4), (5), (6)
uk, sk, vk
PLSI Step
Symbol  : pqd(qi, dj)
Equation: (8)
vsm(qi, dj)
p(zk|qi, dj)
Stop EM Step
Equation: (14), (17)
Maximization Step
Symbol  : p(qi|zk), p(zk), p(dj|zk)
Equation: (11), (12), (13)
p(qi|zk), p(zk), p(dj|zk)
p(qi|zk), p(zk), p(dj|zk)No
Collected Web PagesQuery Log
qi dj
vsm(qi, dj)
KRG 
Stage
VSM
PQD
Expectation Step
Symbol  : p(zk|qi, dj)
Equation: (10)
LSI Step
Symbol  : Uk, åk, Vk
Equation: (3)
VSM Step
Symbol  : vsm(qi, dj)
Equation: (2)
VSM
Yes
 
Figure 1: The system flow chart of VLDP 
 
 
 
 
 
 
 
 
 
 
 
 
 
26 
 
 
Figure 3: Organization of PQD matrix 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
28 
 
qi
VLDP Stage
VSM
vsm(qi, dj) pqd(qi, dj)
KRG with Edge Weight Step
Symbol  : KRG(V,E,W)
Equation: (18)
KRG without Edge Weight Step
Symbol  : KRG(V, E)
PQD...
qi
qct(1)
qct(2)
qct(Len-1)
qct(Len)
KRG without edge weight
qi Final Result
KRG with edge weight
 
Figure 5: The system flow chart of KRG 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
30 
 
 
Figure 7: The pseudo code of BuildKRG 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
32 
 
 
Figure 9: The output of our proposed system for qi is “susan boyle” 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
34 
 
 
Figure 11: The precision at the first K suggested terms for K={3, 5, 7, 10} 
 
 
 
 
 
 
 
 
 
 
 
36 
 
 
Figure 13: Performance rate distribution over 1000 simulation runs 
 
 
 
 
 
 
 
 
 
 
 
 
 
38 
 
計畫成果自評 
 本計畫完成計畫所提之構想，基於 PLSA模型所建找們置之詞語建議系統，基於此
模型我們所建置的系統除了能解決語言學所欲解決之同義詞及一詞多義問題，而且我們
還能計算查詢與每個建議詞語之關聯程度。我們的計畫完成下列的期刊論文的出版（含
接受）。 
1. 陳林志、許富翔、劉英和、陳大仁 (2011)，利用LSA 與GA 之線上新聞查詢建議，
電子商務研究，已接受(TSCI) 
2. Lin-Chih Chen (2011), Next Generation Search Engine for the Result Clustering 
Technology, Next Generation Search Engines: Advanced Models for Information 
Retrieval, accepted 
3. 陳林志、劉英和、陳大仁(2011)，基於大眾意見分析所建置之擬人化剪報系統，電
子商務研究， 已接受(TSCI) 
4. Lin-Chih Chen (2011), Building a Web-Snippet Clustering System Based on a Mixed 
Clustering Method, Online Information Review, accepted, 35 (4), pp. ???-??? (SSCI, IF = 
1.423, 19/66, Rank A) 
5. Lin-Chih Chen (2011), An Automatic Machine Learning Method for the Study of 
Keyword Suggestion, Machine Learning Algorithms for Problem Solving in 
Computational Applications: Intelligent Techniques, accepted 
6. Lin-Chih Chen, “Building a term suggestion and ranking system based on a probabilistic 
analysis model and a semantic analysis graph”, Decision Support System, Conditional 
accept 
7. Lin-Chih Chen, “Cayley Scholar: A post-search academic search engine based on 
clustering techniques”, Decision Support System, Submitted 
 
我們的計畫完成下列的研討會論文的出版。 
8. 陳林志，許富翔，劉英和，陳大仁，「線上新聞查詢建議-利用LSA與GA」，EC2010 
第十四屆電子商務研討會，台北大學，2010 (佳作論文)  
9. 陳林志，劉英和，陳大仁，「基於大眾意見分析所建置之擬人化剪報系統」，EC2010 
第十四屆電子商務研討會，台北大學，2010 (佳作論文)  
 
最後，我們也實作完成此一詞語建議系統，其網址為http://cayley.sytes.net/VLDP_KRG 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：陳林志 計畫編號：99-2221-E-259-023- 
計畫名稱：基於 Probabilistic Latent Semantic Analysis 之詞語建議系統 
量化 
成果項目 
實際已達
成數（被接
受或已發
表） 
預期總達成
數(含實際
已達成數)
本計畫
實際貢
獻百分
比 
單位
備註（質化說明：如數
個計畫共同成果、成果
列 為 該 期 刊 之 封 面 故
事...等） 
期刊論文 2 2 100% 
1.陳林志、劉英和、陳大仁
(2011)，基於大眾意見分析
所建置之擬人化剪報系
統，電子商務研究，已接受
(TSCI) 
2.陳林志, 許富翔, 劉英
和, 陳大仁, ’線上新聞
查詢建-利用 LSA 與 GA’, 
電子商務研究, 已接受
(TSCI) 
研究報告 /技術報
告 1 1 100% 
1. 基 於 Probabilistic 
Latent Semantic Analysis
之詞語建議系統，國科會專
題 研 究 計 畫 (NSC 
99-2221-E-259-023) ，
2010/08/01~2011/07/31，
已結案 
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次
 
研討會論文 2 2 100% 
1. 陳林志，許富翔，劉英
和，陳大仁，「線上新聞查
詢建議-利用 LSA 與 GA」，
EC2010 第十四屆電子商務
研討會，台北大學，2010 
(佳作論文)  
2. 陳林志，劉英和，陳大
仁，「基於大眾意見分析所
建置之擬人化剪報系統」，
EC2010 第十四屆電子商務
研討會，台北大學，2010 
(佳作論文) 
 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次
 
其他成果 
(無法以量化表達之
成果如辦理學術活
動、獲得獎項、重要
國際合作、研究成果
國際影響力及其他
協助產業技術發展
之 具 體 效 益 事 項
等，請以文字敘述填
列。) 
我 們 也 實 作 完 成 此 一 詞 語 建 議 系 統 ， 其 網 址 為
http://cayley.sytes.net/VLDP_KRG 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
