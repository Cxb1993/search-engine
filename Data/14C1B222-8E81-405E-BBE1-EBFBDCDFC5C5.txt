關鍵詞：演算法、字串、樹、網絡、DNA 編碼、迴文、演化歷史樹、生物網路、字尾樹 
Keywords: algorithm, string, tree, network, DNA encoding, palindrome, evolutionary history 
tree, biological network, suffix tree 
 
成果報告內容 
 
As described in our plans, we chose three commonly used information structures: strings (in 
Project 2), trees (in Project 3), and graphs (in Project 4).  We have successfully applied them to 
different biological problems.  In Project 2, we developed efficient algorithms to detect 
palindromes in a text; in Project 3, we designed polynomial-time algorithm to reconstruct 
minisize evolutionary history trees and study the NP-hardness and approximation algorithms of 
the minisum evolutionary history tree construction; in Project 4, we devised protein-protein 
interaction networks.  The improvement to the data structure of suffix trees by Project 5 was 
also applied in each sub-projects. 
 Here is a brief introduction to the achievements of each sub-project.  Three DNA-based 
encryption and description algorithms are proposed in Project 1.  We also evaluate the 
difficulties to break those crypto systems in this study.  Two suffix-tree based algorithms to 
identify all palindromes in a string are provided in Project 2.  Their time complexities are also 
analyzed, and along with this analysis we conclude that our algorithms are optimal.  A model for 
the reconstruction of evolutionary trees is presented in Project 3.  An approximation algorithm 
based on minimum-spanning trees is developed in this project.  We strongly expect that the 
problem showed here is in fact NP-complete, and thus there is no polynomial-time algorithm  
for it unless P=NP.  A protein-to-protein-interaction network is modeled in Project 4.  We 
successfully applied techniques in graph theory to identify protein to protein interactions.  The 
implementation for our approach is announced on the web (http://140.130.34.100/main.php).  
Moreover, extensive study on the experiments also finished at current stage in this project.  In 
Project 5, we re-designed the data structure for implementing suffix trees.  Based on this design, 
we showed that our approach is suitable for DNA or RNA sequences.   
 
The following is part of our publications related to this general project, and some of them 
can be downloaded at the web site http://par.cse.nsysu.edu.tw/~algo/. 
¾ K. W. Liu and R. C. T. Lee, “An Exact String Matching Algorithm Based upon the Single 
Character Matching Mechanism,” in the 25th Workshop on Combinatorial Mathematics and 
Computation Theory, 2008. 
¾ C. W. Lu and R. C. T. Lee, “An Approximate String Matching Algorithm Based upon the 
Candidate Elimination Method,” in the 25th Workshop on Combinatorial Mathematics and 
Computation Theory, 2008. 
¾ L. C. Chen and R. C. T. Lee, “Finding All Approximate Palindromes,” in the 25th Workshop 
on Combinatorial Mathematics and Computation Theory, 2008. 
¾ H. M. Chen and R. C. T. Lee, “An Exact String Matching Algorithm Based upon the 
Substring Encoding Method,” in the 25th Workshop on Combinatorial Mathematics and 
Computation Theory, 2008. 
¾ K.R. Chuang, R.C.T. Lee and C.H. Huang, "Finding all Palindrome Subsequences in a String," 
¾ J. J. Liu, G. S. Huang, Y. L. Wang, R. C. T. Lee, “Edit Distance for a Run-Length-Encoded 
String and an Uncompressed String,” Information Processing Letters, Vol. 105 (1), pp. 
12--16, 2007. 
¾ G. S. Huang, J. J. Liu, Y. L. Wang, “Sequence Alignment Algorithms for 
Run-Length-Encoded Strings,” in the 14th Annual International Computing and 
Combinatorics Conference (COCOON 2008), LNCS 5092, pp. 319--330, 2008. 
Moreover, there are a bunch of master’s theses which were partly supported by this general 
project.   
1. 潘鈺梅：A*演算法在片段限制最長共子序問題之應用(Application of the A* 
Algorithm to Solve the Longest Common Subsequence from Fragments Problem) 碩
士. 國立暨南國際大學 (2005) (李家同指導) 
2. 陳建國：在DNA序列上找所有的連續重覆子序列(Finding All Tandem Arrays in 
DNA Sequences) 碩士. 國立暨南國際大學 (2005) (李家同指導) 
3. 黃志彬：演化歷史樹(On Evolutionary History Trees) 碩士. 國立暨南國際大學 
(2005) (李家同指導) 
4. 楊朝淵：一個用來解決允許k個錯誤的字串比對的新演算法(A New Algorithm for 
Solving the String Matching with k-Mismatches Problem) 碩士. 國立暨南國際大學 
(2005) (李家同指導) 
5. 賴志軍：在實驗模型下建構二元演化樹(Constructing the Binary Evolutionary Tree in 
An Experiment Model) 碩士. 國立暨南國際大學 (2005) (李家同指導) 
6. 陳世群：以有限長度的重複片段來壓縮去氧核醣核酸序列(A Data Compression 
Algorithm for DNA Sequences Using Factors of Limited Length) 碩士. 國立暨南國
際大學 (2005) (李家同指導) 
7. 潘世璋：使用字尾樹解決迴文偵測問題(Solving the palindrome detection problem 
based upon suffix trees) 碩士. 國立暨南國際大學 (2005) (李家同指導) 
8. 王惟綸：具限制性之最長共同子序列問題(Longest common subsequence with 
constraints) 碩士. 國立暨南國際大學 (2006) (李家同指導) 
9. 陳震威：成對DNA序列重組問題(On the twin DNA sequences assembly problem) 碩
士. 國立暨南國際大學 (2006) (李家同指導) 
10. 許宏誌：以DNA序列特性為基礎的加密方法(Encryption methods based upon DNA 
sequences) 碩士. 國立暨南國際大學 (2006) (李家同指導) 
11. 陳宏杰：常數空間的字串比對演算法之比較分析(A review of string matching 
algorithms with constant space) 碩士. 國立暨南國際大學 (2006) (李家同指導) 
12. 阮理洲：產生一個擁有特別屬性的字串(On the generation of words with special 
properties) 碩士. 國立暨南國際大學 (2006) (李家同指導) 
13. 溫文宏：最長迴文子序列和最長重覆子序列(Longest palindrome and tandem repeat 
subsequences) 碩士. 國立暨南國際大學 (2006) (李家同指導) 
14. 古宗翰：嵌入式三角化圖形(Embedded triangular graphs) 碩士. 國立暨南國際大學 
(2007) (李家同指導) 
15. 莊國榮：找出所有迴文子序列與最長共同迴文子序列(Finding all palindrome 
subsequences and longest common palindrome subsequences) 碩士. 國立暨南國際大
 Finding All Tandem Arrays in DNA Sequences 
 
Jian-Guo Chen and Chia-Tung Lee 
Computer Science and Information Engineering Department 
National Chi-Nan University 
rctlee@ncnu.edu.tw 
 
Abstract 
 
A tandem array is a substring of the form kx , 
where x is any unspecific substring and k is at 
least two (when k is 2, 2x  is also called a 
tandem repeat or square). A non-extendable 
tandem array occurring in string S is a tandem 
array kx  which are not followed or preceded by 
another occurrence of x in S. The problem of this 
thesis is defined as follows: Given a string S of 
length n, find all non-extendable tandem arrays of 
S. In the thesis, we present an O(nlogn) algorithm 
for the problem. The algorithm is based on a 
variation of an O(nlogn) algorithm for finding all 
squares in S. Instead of directly finding all 
non-extendable tandem arrays, we first find all 
squares and then use them to construct all 
non-extendable p-periodic substrings whose 
definition follows: A non-extendable p-periodic 
substring is a substring Y  with maximal length 
m such that the ith character is equal to the ( )pi + th character of Y for all { }pm1i −∈ ,,K  
and ⎣ ⎦ 2pm ≥/ . With all non-extendable 
p-periodic substrings found, we can easily 
determine all non-extendable tandem arrays at 
once. 
 
 
1  Introduction 
 
In DNA sequences, there exists a category of 
consecutively repetitive substrings of the form 
kx , where x is any unspecified substring, and k is 
an integer with at least two [16]. Such a substring 
kx  is called a tandem array. For example, 
abcabcabc of the form 3abc  is a tandem array. 
When k is 2, kx  is also called a tandem repeat or 
square. For example, aa, abab and abbabb are 
squares. The problem of finding all tandem arrays 
(or squares) in a string has been found to play an 
important role in biology [10, 4, 5, 18, 6, 3, 14]. A 
number of researches concerning the problem 
have been published [4, 10, 5, 16, 18, 15, 1, 2, 8]. 
The work by Stoye and Gusfiled [16] has provided 
an optimal algorithms for detection of all tandem 
arrays (or squares) in a string of length n using a 
suffix tree in time O(nlogn). Now we study an 
interesting kind of tandem arrays which is 
composed of non-extendable tandem arrays 
occurring in a string S, that is, those tandem arrays 
kx  which are not followed or preceded by 
another occurrence of x in S. For example, 
ababababab is a non-extendable tandem arrays in 
cabababababc while ababab is not. The set of such 
tandem arrays represents in a compact way all 
tandem arrays in S. It is known that there may be 
up to O(nlogn) tandem arrays, even if only 
non-extendable tandem arrays are considered [7, 
12, 16]. An optimal algorithm using a suffix tree to 
find such tandem arrays was proposed in [16]. 
However, the data structure of suffix trees is hard 
to be implemented. Therefore, it will be very 
useful to design an optimal algorithm which is 
capable of finding all non-extendable tandem 
arrays in a string using easy-to-implement data 
structures. In this thesis, we present an 
easy-to-implement and optimal algorithm to find 
all non-extendable tandem arrays in a string. The 
algorithm is based on an O(nlogn) algorithm for 
finding all squares in a string with length n, which 
appeared in [15]. By means of the algorithm, a 
simple approach can be constructed to find all 
non-extendable tandem arrays in the same time 
complexity. In Section 2, a simple approach for 
finding all non-extendable tandem arrays is 
presented. Section 3 proves its time complexity in 
order to hold its optimality and Section 4 shows an 
example for the simple approach. Finally, we shall 
conclude our approach and give the future works 
for it in the last section. 
 
Throughout this thesis, the following notations 
are used. For a string S, is  denotes the ith 
character of S while j1ii sss K+  denotes a 
substring of S starting at the ith character and 
ending at the jth character. The length of S is 
denoted by S . Prefixes and Suffixes of a string S 
are i21 sss K  and S1ii sss K+  where 
Si1 ≤≤ , respectively. For two strings P and Q, 
PQ denotes a string formed by concatenating P 
and Q. 
 
 
2  A simple approach to detecting all 
non-extendable tandem arrays 
 
In the section, we present an O(nlogn) 
algorithm for detecting all non-extendable tandem 
arrays in a string of length n. The algorithm is  
  
 
Figure 3  The preorder of the Findsquares algorithm 
 
S
4 4 4 4
8 8
16
2 2 2 2 2 2 2 2
10
1
2
3
4
6
5 7
8
9 11
12
13
14
15  
 
Figure 4 The in-order of the Findsquares algorithm 
 
A trick allows us to make the order of recursive 
calls appear from left to right of S. The trick is to 
change the preorder into an in-order by 
exchanging findsquares( ⎡ ⎤2n21 sss /K ) and 
newsquare( ⎡ ⎤2n21 sss /K , ⎡ ⎤ ⎡ ⎤ n12n12n sss K++ // ) 
in [15]. For the example of Figure 3, its in-order is 
shown in Figure 4. With the in-order, we can make 
the squares of length 2p found recursively appear 
from left to right of S. The problem is how to 
extend from left to right of S the squares of length 
2p to construct non-extendable p-periodic 
substrings. We now introduce two auxiliary tables 
for constructing non-extendable p-periodic 
substrings. Suppose we are given a string 
n21 sssS K= . The first table is called the Start 
Table of S and the second one is called the End 
Table of S. The entries of the Start Table and the 
End Table of S are denoted as START[p]’s and 
END[p]’s, respectively, where ⎣ ⎦2np1 /≤≤ . 
For each p, we store the starting position and the 
ending position of a current leftmost p-periodic 
substring of S into START[p] and END[p], 
respectively. With these two tables, we can easily 
determine whether a current leftmost p-periodic 
substring is a rightmost p-periodic substring. 
Suppose that there are squares of length 2p with 
consecutive ending positions appearing after the 
current leftmost p-periodic substring. 
 
In other words, there is a p-periodic substring Y 
appearing after the current leftmost p-periodic 
substring. There are two cases: 
 
Case 1: END[p] is not followed by the ending 
position of the leftmost square Q with length 2p in 
Y. 
  
Algorithm newperiodic(P, Q, d) 
 
Let the Prefix Table of Q, the Suffix Table for P and Q, the Prefix Table of rP  (the reverse of P) and the 
Suffix Table for rQ  (the reverse of Q) and rP  be ][iPREFQ ’s, [ ]iSUFFP ’s, ][iPREF rP ’s and [ ]iSUFF rQ , respectively. 
 
Input: a string P of length k, a string Q of length m and an integer d. 
Output: partial non-extendable i-periodic substrings for all i where ( )mki1 ,min≤≤ . 
 
function newperiodic(P, Q, d){ // start of function 
Construct ][iPREFQ ’s, [ ]iSUFFP ’s, ][iPREF rP ’s and [ ]iSUFF rQ . [ ] ;01mPREFQ =+  [ ] ;01kPREF rP =+  
for ( )( )++≤= imki1i ;,min; { //start of for loop 
[ ]
[ ]( );,min ; 1iPREFi1i2drlast iSUFFi2drfirst QP ++−+=
−+=
 
[ ]( )
[ ]( ) ; ;,min i2iSUFFi2dllast i21iPREFi1i2dlfirst r rQ P+−−=
+++−−=
 
    if( rlastrfirstllastlfirst ≤=≤ ){ 
if(START[i] = 0 and END[i] = 0){START[i] = lfirst; END[i] = rlast;} 
else{ 
if(lfirst = END[i] + 1){END[i] = rlast;} 
else{ 
       There is a non-extendable i-periodic substring starting at START[i] and ending at END[i]. 
        START[i] = lfirst; END[i] = rlast; 
         } 
          } 
    }else{ // start of else 
if ( )llastlfirst ≤ { 
if(START[i] = 0 and END[i] = 0){START[i] = lfirst; END[i] = llast;} 
else{ 
if(lfirst = END[i] + 1){ 
          There is a non-extendable i-periodic substring starting at START[i] and ending at llast. 
            }else{ 
      There is a non-extendable i-periodic substring starting at START[i] and ending at 
END[i]. 
 There is a non-extendable i-periodic substring starting at lfirst and ending at llast. 
                } 
                START[i] = 0; END[i] = 0; 
} 
          } 
      if ( )rlastrfirst ≤ { 
if(START[i] = 0 and END[i] = 0){START[i] = rfirst; END[i] = rlast;} 
else{ 
     There is a non-extendable i-periodic substring starting at START[i] and ending at END[i]. 
        START[i] = rfirst; END[i] = rlast; 
            } 
} 
       } // end of else 
} // end of for loop 
} // end of function 
 
The above algorithm is easily modified to report 
non-extendable tandem arrays in non-extendable 
p-periodic substrings. The whole algorithm for 
finding all non-extendable tandem arrays, denoted 
by Algorithm Findtarrays, is shown in the 
following. 
  
 
Figure 7  The inorder of the Findsquares algorithm for S = cbcabcabcababcab 
 
where 1sP =  and 2sQ = . In this case, no (P, 
Q)-square is found in cbss 21 = . The reason that 
cbss 21 =  is the first substring to be processed is 
from the in-order of the approach shown in Figure 
7.  
 
As a result, the second substring to be processed is 
cbcassss 4321 = . This substring shows no (P, 
Q)-square where 21 ssP =  and 43 ssQ = . We 
keep finding (P, Q)-squares in caPQ =  where 
3sP =  and 4sQ = . There exits no (P, 
Q)-square. When the substring 
cbcabcabssssssss 87654321 =  is processed, two 
squares of length 6 ending at position 7 through 8 
of S, namely 765432 ssssss  and 876543 ssssss , 
form a current leftmost 3-periodic substring, 
which starts at position 2 and ends at position 8 of 
S. Hence, Table 1 and 2 are updated with START[3] 
= 2 and END[3] = 8, as shown below: 
 
 The Start Table of S = cbcabcabcababcab 
i 1 2 3 4 5 6 7 8
START[i] 0 0 2 0 0 0 0 0
 
The End Table of S = cbcabcabcababcab 
i 1 2 3 4 5 6 7 8
END[i] 0 0 8 0 0 0 0 0
 
Conforming to the in-order in Figure 7, we can see 
that no (P, Q)-square is found in bcss 65 = , 
bcabssss 8765 =  and abss 87 = . However, 
when babcabcbcabcabcassss 16321 =L  is met, 
we find three squares of length 6 ending at 
position 9 through 11 of S. At the time, END[3] is 
examined in order to extend the current 3-periodic 
substring into a longer one. In this case, we find 
that END[i] + 1 is equal to 9. This means that the 
current 3-periodic substring starting at START[3] 
and ending at END[3] can be extended a longer 
one starting at START[3] and ending at 11, namely 
bcabcabcabssssssssss 111098765432 = . At the 
same time, END[3] is updated with 11. Now Table 
3-2 becomes: 
 
The End Table of S = cbcabcabcababcab 
i 1 2 3 4 5 6 7 8
END[i] 0 0 11 0 0 0 0 0
 
Likewise, a leftmost 2-periodic substring starting 
at position 10 and ending at position 13, namely 
ababssss 13121110 =  is found in 
cababcabssssssss 161514131211109 = . Plus, the 
Start and the End Table are updated with START[2] 
= 10 and END[2] = 13, as shown in the following. 
 
 The Start Table of S = cbcabcabcababcab 
i 1 2 3 4 5 6 7 8
START[i] 0 10 2 0 0 0 0 0
 
The End Table of S = cbcabcabcababcab 
i 1 2 3 4 5 6 7 8
END[i] 0 13 11 0 0 0 0 0
 DNA Based Encryption Methods 
 
H. Z. Hsu and R. C. T. Lee 
Department of Computer Science 
National Chi Nan University 
Puli, Nantou Hsieh, Taiwan 545 
All correspondences to rctlee@ncnu.edu.tw 
 
 
Abstract 
 
In this paper, we shall point out that the DNA 
sequences possess some interesting properties 
which we can utilize to encrypt data.  We 
presented three methods, the insertion method, 
the complementary pair method and the 
substitution method.  For each method, we 
secretly select a reference DNA sequence S and 
incorporate the secret message M into it such 
that we obtain S’.  We send this S’, together 
with many other DNA, or DNA-like sequences to 
the receiver.  The receiver is able to identify the 
particular sequence with M hidden in it and 
ignore all of the other sequences.  He will also 
be able to extract M. 
 
 
1  Introduction 
 
In recent years, much research work has been 
done on DNA based encryption schemes [6, 9, 
12].  Most of them use biological properties of 
DNA sequences.  The encryption method 
introduced in this paper does not make use of the 
biological properties.  Instead, we shall use the 
following properties of DNA sequences. 
 
A DNA sequence is a sequence consisting of 
four alphabets: A, C, G and T.  Each alphabet is 
related to a nucleotide.  It is usually quite long.  
For instance, the following are two DNA 
sequences.     
 
The first one is a segment of DNA sequence 
of Litmus, its real length is with 2856 
nucleotides long: 
ATCGAATTCGCGCTGAGTCACAATTCGCG
CTGAGTCACAATTCGCGCTGAGTCACAAT
TGTGACTCAGCCGCGAATTCCTGCAGCCC
CGAATTCCGCATTGCAGAGATAATTGTATT
TAAGTGCCTAGCTCGATACAATAAACGCC
ATTTGACCATTCACCACATTGGTGTGCAC
CTCCAAGCTCGCGCACCGTACCGTCTCGA
GGAATTCCTGCAGGATATCTGGATCCACG
AAGCTTCCCATGGTGACGTCACC 
[14]. 
 
The second one is a segment of DNA 
sequence of Balsaminaceae, its real length is 
with 2283 nucleotides long: 
TTTTTATTATTTTTTTTCATTTTTTTCTCAG
TTTTTAGCACATATCATTACATTTTATTTTT
TCATTACTTCTATCATTCTATCTATAAAATC
GATTATTTTTATCACTTATTTTTCTAATTTC
CAATATTTCATCTAATGATTATATTACATTA
AAGAAATCGGTTAAAAGCGACTAAAAAT
CAATCTGGAACAAGGCTTAGTTTATTTAAT
ATATTATTTTATGTAATTTCTATTGAAAAAT
TAGTTAAAAGGCAAGTATTTGAGAT [14]. 
 
We can now easily see one special property of 
DNA sequences:  There is almost no difference 
between a real DNA sequence and a faked one.  
This is a property which we shall exploit in our 
research. 
 
There is another fact which is quite useful to 
us:  There are a large number of DNA 
sequences publicly available in various web-sites, 
such as [14].  A rough estimation would put the 
number of DNA sequences publicly available to 
be around 55 million [14]. 
 
By using the above facts, we designed three 
DNA based encryption methods.  All of these 
methods would secretly select a reference 
sequence S from publicly available DNA 
sequences.  Only the sender and the receiver 
are aware of this reference sequence.  The 
sender would transform this selected DNA 
sequence S into a new sequence S’ by 
incorporating the DNA sequence S with the 
secret message M.  This transformed sequence 
S’ is sent by a sender to the receiver together 
with many other DNA sequences.  The receiver 
would then examine all of the received 
sequences, identify S’ and recover the secret 
message M. 
 
 
Step 1. 
Step 5. Return S3. 
 
S3 is sent to the receiver together with many 
other DNA sequences.  The receiver uses the 
following algorithm to decrypt. 
 
Algorithm 2-2 Decryption Algorithm for 
Method 1 
Input: A set of DNA sequences, one of 
which has the secret message M 
hidden in it by using Algorithm 2.1, 
a reference DNA sequence S and a 
binary coding scheme. 
Output: The secret message M. 
Step 1. Generate numbers k’s and r’s 
denoted as n  and p  
by using the same random number 
generator with the same seed of the 
encoding scheme. 
kkk ...21 rrr ...21
Step 2. For a DNA sequence S’ of the set, 
code S’ into a binary sequence by 
using the binary coding used by the 
sender and use ,..., 2211 krkr ++  to 
divide the binary sequence into  
binary segments. 
Step 3. For each segment of the first p 
segments of S’, extract the first ri 
bits, called mi. 
Step 4. For each segment of the first p 
segments of S’, extract the last ki bits, 
called si. 
Step 5. Concatenate all mi’s to be M and all 
sj’s, to be S1. 
Step 6. Transform S1 to be a DNA sequence 
by using the same rule.  If S1 is not 
a prefix of S, go to Step 2. 
Step 7. Return M. 
 
For an intruder to find out the secret message, 
he must be equipped as follows.  (1) He must 
know precisely the reference DNA sequence S.  
Since there are roughly 55 millions DNA 
sequences available publicly, it is extremely hard 
to guess one.  (2) He has to know the random 
number generator and the two seeds used.  (3) 
He has to know the binary coding scheme. 
 
 
3  Method 2: the Complementary 
Pair Approach 
 
In this section, we shall illustrate Method 2, 
the complementary pair approach.  In RNA 
sequence, we often have the so-called base pairs 
[4, 8, 13].  We cannot elaborate the detailed 
meaning of the base pairs of RNA in this paper.  
For us, we may just define our own 
complementary pairs.  That is, for each 
alphabet, we assign a unique counterpart for it.  
For instance, we may have the following base 
pair rule: 
(A T) (C A) (G C) (T G). 
as discussed in Section 1.  Then the 
complementary sequence of AATGC will be 
TTGCA.   
 
In the sequence: 
“ATCTGAATGCTTGTCTATTGCATCAAT”, 
complementary substrings occur, as indicated by 
the bold characters.  To find the longest 
complementary substrings, we may use dynamic 
programming approach [1].  Let us assume that 
we have the secret message M which has even 
number of bits.  Note that it is always 
reasonable to assume so because we may always 
use even number of bits to code. To give an 
example, assume that M=0110.  Again, as in 
Method 1, we assume that we have a reference 
sequence S.  Let us assume it to be 
S=ACGGTCGTTCCCTAGTTG.  Our Method 
2 will work as follows: 
 
Step 1. Artificially generate a sequence without 
any complementary substrings and 
consisting of A, C, G and T only.  
Assume that the sequence is 
L=ACGGTCTCATCAATGCTTCAGT. 
 
Step 2. Divide M into segments such that each 
segment contains even number of bits.  
Thus, in our case, we have 01 and 10.  
We code 01 and 10 according to some 
coding rule.  By using the coding rule 
given in the previous section, 01 and 10 
will be coded as C and G respectively. 
 
Step 3. Generate two complementary strings 
with length k and insert them into L.  
Assume k=5 and we have the following 
two complementary strings: (AAGCT  
TTCAG) and (ACCTG  TAAGC).  
The sequence L now becomes L’= ACG 
AAGCT GTCT TTCAG CAT 
ACCTG CAAT TAAGC GCTTCAGT. 
 
Step 4. Insert the first(second) alphabet of the 
secret message one alphabet before the 
first(second)  complementary string.  
The string becomes:  L’= ACCG 
AAGCT GTCT TTCAG CAGT 
ACCTG CAAT TAAGC GCTTCAGT. 
 
Step 5. Use a random number generator to 
select two positive integers j and i.  
Assume j=2 and i=4.  Insert substrings 
 
substrings ag and ag’, check whether 
the substring with length i-1 starting 
from one alphabet after ag’ is the 
same with S[jg,jg+i] or not.  If they 
are not the same, ignore L” and go to 
Step 1. 
Step 3. For each pair of complementary 
substrings ag and ag’, extract the 
alphabet one alphabet before ag, 
called mg. 
Step 4. Concatenate all mg‘s to be M. 
Step 5. Return M. 
 
An intruder should have the following 
information.  First, he should know the 
reference DNA sequence.  Second, he should 
have the complementary rule.  Third, he should 
know the positive integers j and i to make an 
authentication to the reference DNA sequence.  
Fourth, he should know the binary coding rule.  
Fifth, he must know the correct lengths of the 
complementary pair substrings. 
 
 
4  Method 3: the Substitution 
Approach  
 
For this method, we also will use a reference 
sequence S.  Let us assume that 
S=ACGGAATTGCTTCAG and the secret 
message M=m1m2…mp is 0111010.  The length 
of S is 15 and is larger than the length of M, p, 
which is 7 in this case.  For illustration, assume 
that the complementary rule is the same as given 
in the above sections.  That is, the rule is as 
follows: ((A T) (C A) (G C) (T G)). 
 
Our main idea is as follows: 
Step 1. Suppose the length of the reference 
sequence S is 15.  Select p distinct 
numbers randomly from 1 to 15, p is 
equal to 7 in this case.  Assume that 
they are sorted as 2, 3, 5, 10, 12, 13 and 
15.  Let A=A1, A2, …, 
Ap={2,3,5,10,12,13,15}. 
 
Step 2. Transform S into S’ by the following 
rule: 
For all i from 1 to 15, 
if i is equal to some Aj and mj is 1,  
, set Spj ≤≤1 i to , )( iSC
if i is equal to some Aj and mj is 0, 
do not change Si, and 
if i is not equal to any Aj, set Si to 
. ))(( iSCC
Thus S’=GCCATGCCAACTAGG. 
 
Step 3. Send S’ to the receiver with many other 
sequences. 
 
The receiver would not need to generate the 
set A.  After receiving a set of sequences, he 
will check all positions of each sequence S’ in 
the set.  There are only three possible cases:  
(1) S’i is the same with Si (The secret bit mj is 
equal to 0).  (2)  S’i is (The secret bit m)( iSC j 
is equal to 1).  (3) S’i is .  If there 
exists one j such that S’
))(( iSCC
j and Sj are not of the 
above three cases, it means that the sequence 
should be ignored.   
 
In the following, we present the algorithms for 
Method 3. 
 
Algorithm 4-1 Encryption Algorithm for 
Method 3 (Substitution Approach) 
Input: A DNA sequence S, the secret 
message M=m1m2…mp and a 
complementary rule. 
Output: An encrypted DNA sequence S”. 
Step 1. Use a random number generator to 
generate a set of available integer 
sequences, called set A.  The 
number of A is p, the length of M. 
Step 2. Initialize i and j to 1. 
Step 3. For each element Si of S, do the 
following operations: 
if i is equal to some Aj and mj 
is 1, pj ≤≤1 , change Si to ,  )( iSC
if i is equal to some Aj and mj 
is 0, do not change Si, 
if i is not equal to any Aj, set Si 
to the double-complement of itself.1 
Step 4. Return S’. 
 
Algorithm 4-2 Decryption Algorithm for 
Method 3 (Substitution Approach) 
Input: A set of DNA sequences, the 
reference sequence S and the 
complementary rule. 
Output: Secret message M. 
Step 1. Initialize i and j equal to 1. 
Step 2. For the next sequence S’ of the 
sequence set, do the following 
operations: 
For each Si: 
if there exists a j such that 
such that )'(',' jjjj SCSSS ≠≠ and 
))((' jj SCCS ≠ , ignore S’; otherwise, 
if S’i is the same with Si, 
setmj=0 and increment j,  
else if S’i is the same with 
, set m)( iSC j=1 and increment j. 
Step 3. Concatenate all mj,’s to be M and 
return M. 
 
 
 Looking for All Palindromes in a String 
 
Shih Jang Pan and R. C. T. Lee 
Department of Computer Science and Information Engineering, National Chi-Nan 
University, Puli, Nantou Hsien, 545, Taiwan, ROC 
sjpan@algdoc.csie.ncnu.edu.tw, rctlee@ncnu.edu.tw 
 
 
Abstract 
 
A palindrome is a string of the form αα', where α 
and α' are also strings and reverse to each other. The 
problem of the paper is defined as follows: given a 
string S of length n, find all palindromes occurring in 
the given string S. In the paper, we present an 
algorithm based on suffix trees to find palindromes.  
Our algorithm will find all maximum palindromes 
which are not contained in any other palindromes. 
After finding maximum palindromes, we utilize 
eliminating operations to find other palindromes 
which are contained in maximum palindromes.  
 
 
1 Introduction 
 
Let us first define palindromes. Given a 
string nαααα L21= , 11' αααα L−= nn is called 
the reverse of α. The string αα' is called a palindrome. 
For example, abba and cdaadc are both palindromes. 
To look for DNA sequences containing palindromes 
is important in biology. Many researchers have 
discussed the palindrome problem [2] [3] [4]. 
 
Suffix trees have been used extensively by many 
algorithms [1]. Gusfield proposed an algorithm based 
on suffix trees to find all tandem repeats in a given 
DNA sequence [5]. In this paper, we modify the idea 
in [5] and present a suffix tree approach to deal with 
the palindrome problem. 
 
2 A suffix tree approach to detect all 
palindromes 
 
2.1 Term definition 
 
Given an input string K, we first add a character $ 
which does not occur in K to the end of the input 
string. The new string is denoted as K1. Then, we 
reverse the given string K and add a character $' 
which does not occur in the string to the end of the 
reversed string. The new string is denoted as 1K− . 
We now construct a suffix tree for both K1 and 
1K− .  
Assume that we have cbaab$1 =K  and 
baabc$'1 =− K . We will construct a suffix tree for 
1K  and 1K− . To clearly describe the suffix tree, we 
need many indices for nodes of it. They will be 
explained below. 
(1) Rule 1: Each leaf node is associated with 
either K1 or –K1, indicated by the $  or $'  
on the edge ending at the leaf node as 
indicated in Fig. 1(a).  
(2) Rule 2: If a leaf node is associated with 
K1(–K1) there is an index if ( ir ), indicating 
the starting location of the associated string. 
The index if ( ir ) is in regular type (italic 
type) as indicated in Fig. 1(a).  
(3) Rule 3: For each node, except the root node, 
the collection of leaf indices below the node 
is called forward collection or reversed 
collection for K1 or –K1. The indices 
collected in forward and reversed 
collections are enclosed in ( ) parentheses. If 
the numbers inside the parenthesis are in 
regular type (italic type), they are associated 
with 1K ( 1K− ) as indicated in Fig. 1(b). 
 We further have Rule 4 as follows: 
(4) Rule 4: For each node, the length from the 
root to the node is denoted as )(vD .  
)(vD  is shown in [ ] bracket as shown in 
Fig. 2.  
The above results are merged and shown in Fig. 3. 
For our algorithm of palindrome finding, we need the 
following terms as defined below. 
(1) Eliminating operation: Given a palindrome 
string nsssS L21= , the eliminating 
operation deletes the first and last characters 
of the given string S . The remaining string 
12' −= nssS L is also a palindrome. For 
example, abba is generated from cabbac by 
an eliminating operation. 
(2) Maximum Palindromes: A substring T of 
S  is a maximum palindrome of S if T  
is not contained any other palindrome of S . 
For example, in the string dcabbace, the 
substring cabbac is a maximum palindrome 
while abba is not. 
  
Figure 3  
 
Figure 4  
 
if + ir = (n − D(v) + 2) holds for such rf ii  and . The 
substring corresponding to this node is abba which is 
a maximum palindrome.  
 
By using eliminating operation, we get another 
palindrome bb. For other nodes, the formula does not 
hold. So there are not other maximum palindromes. 
We can easily see that we can find another two 
maximum palindromes at the other two pointed 
nodes. They are bbaabb and bb. We would like to 
point out that we may find another bb which is a 
palindrome, but not a maximum palindrome.  
 
 In the following, we present the algorithm for 
finding all maximum palindromes. 
 
Algorithm 
Input: a string S  with length n . 
Output: all palindromes which occur in S . 
1. Add a character $  which does not occur in 
S  to the end of S . The new string is 
denoted as 'S . 
2. Add a character $'  which does not occur in 
the string to the end of the reversed input 
string S− . The new string is denoted 
as 'S− . 
3. Construct the suffix tree for 'S  and 'S− . 
 Reference 
 
[1] D. Gusfield. Algorithms on Strings, Trees, and 
Sequences. Cambridge University Press,1997. 
[2] G. Manacher. A New linear-Time "On-Line" 
Algorithm for Finding the Smallest Initial 
Palindrome of a String. Journal of the 
Association for Computing Machinery, 1975. 
[3] A. Porto, V. Barbosa. Finding Approximate 
Palindromes in Strings. Pattern Recognition, 
2002. 
[4] R. Gupta, A. Mittal, V. Narang, S. Wing-Kin. 
Detection of Palindromes in DNA Sequences 
Using Periodicity Transform. IEEE International 
Workshop on Biomedical Circuits & Systems, 
2004. 
[5] J. Stoye, D. Gusfield. Simple and flexible 
detection of contiguous repeats using a suffix 
tree. Theoretical Computer Science, 2002. 
We may align the strings as follows: 
 
X = a a t - - c t 
 Y = a a t g a - g 
 
As can be seen, X can be transformed to Y by 
executing two insertions, one deletion and one 
substitution.  It can also be proved that the edit 
distance between X and Y is 4.  
 
It is well known that the edit distance finding 
problem is equivalent to the longest common 
subsequence finding problem.   
 
2.1  The Edit Graph Shortest Path Problem 
 
In this section, we are interested in the longest 
common subsequence from fragments problem.  
In this section, we shall show that this problem 
can be viewed as a graph searching problem.  
The graph is defined an edit graph and the 
problem is to find a shortest path from a certain 
starting node to a certain terminal node.  
Let us illustrate the edit graph through an 
example.  Suppose we are given X=tacat and 
Y=actat, the edit graph of X and Y is showed in Fig. 
1.  In the edit graph, for a node p, let x(p) and y(p) 
to be the x-coordinate and y-coordinate of p, 
respectively.  For instance, for node (2, 3), x((2, 
3))=2 and y((2, 3))=3.  
 
 
Fig. 1. The shortest path of two strings X=tacat 
and Y=actat and the set M={f(2, 1, 2), f(1, 3, 2), f(4, 4, 2)}. 
 
Suppose we further have fragments ta, ac and at.  
Then we denote these fragments as diagonal paths.  
We denote a path by (i, j, k) where i, j and k stand 
for the starting positions in X and Y and the length 
of the matching substring, respectively.  For 
instance, given two strings X=tacat and Y=actat 
and M={f(2, 1, 2), f(1, 3, 2), f(4, 4, 2)}, f(2, 1, 2), f(1, 3, 2) and 
f(4, 4, 2) represent the three common substrings ac, ta 
and at, of X and Y, respectively. 
In addition, for a fragment f, the node (i-1, j-1) 
of f is denoted as start(f) and the node (i+k-1, 
j+k-1) of f is denoted by end(f).  For example, 
consider Fig. 1.  start(f(2, 1, 2)) is the node (1, 0) 
and start(f(4, 4, 2)) is the node (3, 3). 
For each horizontal and vertical edge, we 
associate it with cost 1 and for each diagonal edge, 
we associate it with cost 0.  Our longest common 
subsequence from fragments problem can now be 
viewed as a shortest path finding problem where 
the path is from (0, 0) to (m, n).  In Fig. 1, the 
black path it the shortest path from (0, 0) to (5, 5). 
After obtaining the shortest path, we obtain the 
solution by only retaining the substring in the 
fragments.  There for the case shown above, the 
found solution is acat. Now, let us consider a 
situation.  Would all fragments appear in the 
found shortest path?  The answer is “Not 
necessarily”.  For example, consider Fig. 1, 
fragment f(1, 3, 2) doesn’t appear in the found 
shortest path of X and Y and the set M.  Thus we 
proposed a new method using A* algorithm to 
solve the problem.  Through this method, we can 
filter out the fragments which wouldn’t appear in 
the solution, and it can efficiently find the 
solution.  
 
3 The A* Algorithm 
 
In this chapter, we shall introduce the A* 
algorithm for the shortest path finding problem.  
The edit distance is used to be the cost measure 
through this chapter.  In the edit graph, for each 
horizontal and vertical edge, we associate it with 
cost 1 and for each diagonal edge, and we 
associate it with cost 0.  In the following, we 
shall use one simple example to informally 
illustrate the basic idea of the A* algorithm.  
Consider Fig. 1.  It’s the edit graph of two 
strings X=tacat and Y=actat and a set M={f(2, 1, 2), f 
(1, 3, 2), f(4, 4, 2)}.  In the execution of the A* 
algorithm, there are two sets, found and unfound.  
At the beginning, the found is null and unfound 
stores the two nodes (0, 0) and (m, n) and the three 
given fragments, f(2, 1, 2), f (1, 3, 2) and f(4, 4, 2). 
In the first step, node (0, 0) is selected from 
unfound to found, because there is no cost between 
it and the starting position of the shortest path 
from (0, 0) to (m, n).  Then, expand the selected 
node (0, 0) to the elements in unfound as shown in 
Fig. 2, and the costs of the paths from (0, 0) to all 
elements in unfound are obtained.  For example, 
the cost of the path from (0, 0) to f(2, 1, 2), f(1, 3, 2), f(4, 
4, 2) and (m, n) are 1, 2, 6 and 10, reapectively. 
By the A* algorithm, for each element in 
unfound, the cost of the path from it to the ending 
node (m, n) is estimated.  The details of the 
estimating method will be discussed later.  Since 
the cost of the paths from each element in unfound 
0 1 2 3 4 5
0
1
2
3
(m, 0)
(0, n)
(m, n)
(0, 0)
4
t
a
c
a
t
a c t a t
5
f(2,1,2)
f(1,3,2)
f(4,4,2)
~241~
consider the fragment f(3, 2, 2).  Any solution 
consisting of this fragment will not contain use the 
fragment f(2, 4, 2).  Therefore, when we consider f(3, 
2, 2), we may ignore f(2, 4, 2).  We now define the 
domination relation as follows: For two fragments 
f and f′, f′ is dominated by f, if x(end(f′)) > x(end(f)) 
and y(end(f′)) > y(end(f)).  In our algorithm, 
suppose we are considering a fragment f, we shall 
ignore all of the fragments which are not 
dominated by f.  For instance, in Fig. 6, f(3, 2, 2) 
dominates f(5, 7, 2), f(7, 4, 2) and f(8, 6, 2).  f(2, 4, 2) 
dominates f(3, 6, 2), f(8, 6, 2) and f(5, 7, 2), and f(7, 4, 2) 
dominates f(8, 6, 2). 
 
Fig. 6. The edit graph of two strings X=atcggatcgc 
and Y=ccgtccgac and a set M={f(2, 4, 2), f(3, 2, 2), f(3, 6, 
2), f(5, 7, 2), f(7, 4, 2), f(8, 2, 2), f(8, 6, 2)}. 
 
In addition, for two fragments f and f′, we 
define Len(f, f′) as the number of horizontal and 
vertical edges between f and f′.  Let us consider 
Fig. 6.  Len(f(2, 4, 2), f(3, 6, 2)) is 1.  Len(f(2, 4, 2), f(5, 7, 
2)) is 2.  Len(f(2, 4, 2), f(8, 6, 2)) is 4. 
 
3.1 The Algorithm 
 
The algorithm proposed in this paper consists of 
two phases, preprocessing and main algorithm.  
In Step 3 of the main algorithm as below, E*(f) has 
to be used in for loop.  For each fragment f, since 
E*(f) doesn’t change, we only compute E*(f) once 
for each f.  In the preprocessing, we compute 
E*(f) for each f.  In the main algorithm, a value 
Link is prepared for each fragment f and it will be 
used in recovering the shortest path step. 
 
Let Par be pointer. 
Input: Two strings X=x1x2…xm and Y=y1y2…yn, 
and a set M of fragments. 
Output: A shortest path from (0, 0) to (m, n) 
 
Step 1.  Consider two nodes (0, 0) and (m, n) as 
fragments f(1, 1, 0) and f(m, n, 0), respectively.  Put 
fragments f(1, 1, 0) and f(m, n, 0) and set M into set 
unfound.  Let set found=φ.  
 
Step 2.  For each fragment f in set unfound 
except fragment f(1, 1, 0), let D(f)=∞ and Dist*(f)=
∞.  For f(1, 1, 0), let D(f(1, 1, 0))=0 and Dist*( f(1, 1, 
0))=E*(f(1, 1, 0)).   
 
Step 3.   
Do until f = f(m, n, 0) 
Select f from set unfound such that Dist*(f) is 
the smallest, and remove f from unfound to 
found. 
For every f′ in unfound which is dominated by f 
do  
     Let )( fD ′ = D(f) + Len( f, f′).   
     If )()( fDfD ′<′ , set f′.Link = f.   
     Let D(f ′) = min{D(f ′), )( fD ′ }.  
     Let Dist*( f ′) = D(f ′)+E*( f ′).  
End For 
End Do  
 
Step 4.  Set Par = f(m, n, 0). 
While Par is not null 
    Print (i, j) pair pointed to by Par 
    Advance Par 
End While 
 
 
Fig 7. Given fragments distributed over the edit 
graph where the dotted fragments are not selected 
by the A* algorithm. 
 
If the given fragments are distributed over the 
diagonal line of the edit graph, the A* algorithm 
can not filter out many fragments which will not 
appear in the solution.  For instance, in Fig. 7, the 
fragments are distributed over the diagonal line of 
0 1 2 3 4 5
0
1
2
3
4
(0, 0)
5
t
c
g
g
a
c c g t c
a
6
6 7 8 9
(0, n)
(m, n)
g a cc
7
8
9
10
c
g
c
t
(0, 0)
f(3,2,2)
f(2,4,2)
f(3,6,2)
f(5,7,2)
f(7,4,2)
f(8,2,2) f(8,6,2)
A  G  G  T  C  G  G  T  C  A  A  A  C  T  G  G  T  G  G  T  C  A  T  T  G  G  T
G  
G  
T  
A
A  
G  
G  
T  
C  
C  
C  
T  
G  
G  
T  
G  
G    
T  
T  
G  
G  
T
~243~
 
5  Conclusion 
 
In this paper, we proposed the application of the 
A* algorithm to solve the longest common 
subsequence from fragments problem.  The A* 
algorithm can successfully filter out some 
fragments which wouldn’t appear in solutions, and 
efficiently find a solution.  If given fragments are 
distributed over the edit graph, the method can 
ignore a lot fragments.  The method is quite 
efficient as the number of fragments which are 
needed to be computed is smaller than the 
dynamic programming approach proposed in 
Baker and Giancarlo.  In general cases, a few 
fragments are computed in solving the problem.  
However, in worst cases, all fragments are needed 
to be computed in solving process. 
 
 
References 
 
[1] Faster Algorithms for String Matching with k 
Mismatches, Amir, A., Lewenstein, M. and 
Porat, E., Journal of Algorithms, Vol. 50, 
2004, pp. 257-275.  
[2] Sparse Dynamic Programming for Longest 
Common Subsequence from Fragments, 
Baker, B. S. and Giancarlo, R., Journal of 
Algorithms, Vol. 42, 2002, pp. 231-254.  
[3] Approximation Algorithms for Multiple 
Sequence Alignment, Bafna, V., Lawler, E. L. 
and Pevzner, P. A., Theoretical Computer 
Science, Vol. 182, 1997, pp. 233-244. 
[4] A Fast String Searching Algorithm, Boyer, R. 
S. and Moore, J. S.,  Communication of the 
ACM, Vol. 20, 1977, pp. 762-772. 
[5] The Multiple Sequence Alignment problem in 
Biology, Carrillo, H. and Lipman, D. J., 
SIAM Journal on Applied Mathematics, Vol. 
48, 1988, pp. 1073-1082. 
[6] Jewels of Stringology, Crochemore, M. and 
Rytter, W., World Scientific, 2002.  
[7] A Linear Space Algorithm for Computing 
Maximal Common Subsequences, Hirschberg, 
D. S., Communications of the ACM, Vol. 18, 
No. 6, 1975, pp. 341-343. 
[8] A Fast Algorithm for Computing Longest 
Common Subsequences, Hunt, J. W. and 
Szymanski, T. G., Communications of the 
ACM, Vol. 20, No. 5, 1977, pp. 350-353. 
[9] Fast Pattern Matching in Strings, Knuth, D., 
Morris, J. and Pratt, V., SIAM Journal on 
Computing, Vol. 6, 1977, pp. 323-350. 
[10] Introduction to the Design and Analysis of 
Algorithms, Lee, R. C. T., Chang, R. C., 
Tseng, S. S. and Tsai, Y. T., Flag Corporation, 
Second Edition, ISBN:957-717-777-8, 1991. 
[11] Identification of common Molecular 
Subsequences, Smith, T. F. and Waterman, M. 
S., Journal of Molecular Biology, Vol. 147, 
1981, pp. 195-197. 
[12] Alignments Without Low-Scoring Regions, 
Zhang, Z., Berman, P. and Miller, W., 
Research in Computational Molecular 
Biology (RECOMB), Vol. 5, 1998, pp. 
294-301.  
 
 
 
~245~
The following words will be generated by the
function φ(fn):
f0 = a
f1 = φ(f0) = φ(a) = b
f2 = φ(f1) = φ(b) = ab
f3 = φ(f2) = φ(ab) = bab
f4 = φ(f3) = φ(bab) = abbab
f5 = φ(f4) = φ(abbab) = bababbab
f6 = φ(f5) = φ(bababbab) = abbabbababbab
We ﬁrst show that φ(fn) is an n-Fibonacci word
generating function..
Property 2.1. fn = fn−2 + fn−1, for n ≥ 2.
Proof. Note that, f0 = a, f1 = b and f2 = ab =
f0 + f1. Thus n = 2 is valid.
Assume that fk = fk−2 + fk−1 for k = 2, 3, · · · , n.
Next, consider
fk+1 = φ(fk)
= φ(fk−2 + fk−1)
= φ(fk−2) + φ(fk−1)
= fk−1 + fk
Therefore, fn is a Fibonacci word.
Before we describe the properties of Fibonacci
words generated by φ, we deﬁne some notations.
The kth character of nth word fn, which is gener-
ated by φ, is denoted as cn,k.
For example: c4,2 is b, c5,2 is a.
Property 2.2. cn,1 + cn,2 = cn+1,2 +
cn+1,1 for n ≥ 2
Property 2.3. The suﬃx of words generated by
φ are ab for all n.
The above two properties are obvious, we omit
the proof.
Let fsn be the suﬃx of the n
th word whose
length is |fn| − 2.
Example: f5=bababbab, fs5=babbab.
Let (fn)R be the reverse word of fn.
Example: (f5)R=babbabab, (fs5 )
R=babbab.
Property 2.4. fsn = (f
s
n)
R for n ≥ 3
Proof. (By induction) Note that, f3 = bab and
fs3 = b = (f
s
3 )
R, n=3 is true.
Assume that fsk = (f
s
k)
R is true for 3 ≤ k < n.
We want to show that n = k is also true.
By deﬁnition, we have
fk = ck,1 + ck,2 + fsk
and
fk = fk−2 + fk−1
Thus,
ck,1 + ck,2 + fsk = ck−2,1 + ck−2,2 + f
s
k−2 + fk−1
By Property 2.2, we have ck,1 + ck,2 = ck−2,1 +
ck−2,2.
Therefore,
fsk = f
s
k−2 + fk−1
and
fsk = f
s
k−2 + ck−1,1 + ck−1,2 + f
s
k−1
Thus,
(fsk−2 + ck−1,1 + ck−1,2 + f
s
k−1)
R
= (fsk−1)
R + ck−1,2 + ck−1,1 + (fsk−2)
R
= (fsk−1)
R + ck−2,1 + ck−2,2 + (fsk−2)
R
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-183-
bonacci words.
Proof. Essentially, we want to prove that{
fn = fn−2 + fn−1 if n is even
fn = fn−1 + fn−2 if n is odd.
(1)
Note that Equation (1) is true for n = 2, 3, 4,
because f2 = ab = f0 + f1, f3 = abb = f2 + f1,
f4 = ababb = f2 + f3.
Assume that{
fi = fi−2 + fi−1 if i is even
fi = fi−1 + fi−2 if i is odd,
for i = 2, 3, · · · , n.
We now show that{
fi+1 = fi−1 + fi if i+ 1 is even
fi+1 = fi + fi−1 if i+ 1 is odd.
Consider i+ 1 is odd, i will be even.
fi+1 = ϕ((fi)R)
= ϕ((fi−2 + fi−1)R)
= ϕ((fi−1)R) + ϕ((fi−2)R)
= fi + fi−1
Similarly, fi+1 = fi−1 + fi, if i+ 1 is even.
We give several other functions in Table 2 which
also generate alternating Fibonacci words.
Table 2: The Other Alternating Fibonacci Word
Generation Functions
ϕ1 f0 = a ϕ1(a) = b fn = ϕ1((fn−1)R)
ϕ1(b) = ba
ϕ2 f0 = a ϕ2(a) = ab fn = ϕ2((fn−1)R)
ϕ2(b) = a
ϕ3 f0 = a ϕ3(a) = ba fn = ϕ3((fn−1)R)
ϕ3(b) = a
4 Block Palindrome
In this section, we shall introduce a new term,
the block reverse concept: Let x and y be two
strings, where x = x1 +x2, y = y1 + y2 and |x1| =
|x2| = |y1| = |y2|. y is a block reverse of x if
y1 = x2 and y2 = x1. For instance, y = ba is a
block reverse of x = ab. Besides, y = baab is a
block reverse of x = abba. We shall use xBR to
denote the block reverse of x.
Having deﬁned block reverse, we shall deﬁne
the block palindrome as follows: If |S| = 4, then
S is a block palindrome if and only if S is a palin-
drome. If |S| = 2n > 4, S is a block palindrome
if and only if S = S1 + S2, |S1| = |S2|, S2 is a
block reverse of S1 and both S1 and S2 are block
palindromes.
For instance, According to our deﬁnition, S =
abbabaabbaababba is a block palindrome, because
S can be divided into S1 = abbabaab and S2 =
baababba, |S1| = |S2|, S2 is a block reverse of S1,
and S1 and S2 are both block palindromes.
We propose a word generating function χ(fn)
as follows:
χ(x1x2 · · ·xm) = χ(x1)χ(x2) · · ·χ(xm),
xi ∈ {a, b}
χ(a) = ab, χ(b) = ba, f0 =
a, fn = χ(fn−1).
The following words will be generated by the
function χ(fn) and all are block palindrome:
f0 = a
f1 = χ(f0) = χ(a) = ab
f2 = χ(f1) = χ(ab) = abba
f3 = χ(f2) = χ(abba) = abbabaab
f4 = χ(f3) = χ(abbabaab) = abbabaabbaababba
f5 = χ(f4) = χ(abbabaabbaababba)
= abbabaabbaababbabaababbaabbabaab
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-185-
. For example:
w3 = abbcbcca
w4 = w3 + w
suf
2
3 + w
suf
4
3 + w
pre
4
3
= abbcbcca+ bcca+ ca+ ab
= abbcbccabccacaab
The generating function ξ(fn) has the following
properties:
Property 5.1. ξ(fn) generates suﬃx-preﬁx Fi-
bonacci words.
Proof. First, we consider n=3.
Because w3 = abbcbcca = abbc + bc + c + a =
w2 + w
suf
2
2 + w
suf
4
2 + w
pre
4
2
Therefore, n = 3 holds.
Assume n=k holds. That is,
wk = wk−1 + w
suf
2
k−1 + w
suf
4
k−1 + w
pre
4
k−1
Let us consider n=k+1,
wk+1 = ξ(wk)
= ξ(wk−1 + w
suf
2
k−1 + w
suf
4
k−1 + w
pre
4
k−1)
= ξ(wk−1) + ξ(w
suf
2
k−1) + ξ(w
suf
4
k−1) + ξ(w
pre
4
k−1)
= wk + w
suf
2
k + w
suf
4
k + w
pre
4
k
Thus, we proved.
Property 5.2. |wn| = 2|wn−1|
Example: w3 = abbcbcca, |w3| = 8, w4 =
abbcbccabccacaab, |w4| = 16.
Property 5.3. |wn| = 2n
Example: w4 = abbcbccabccacaab, |w4| = 24 =
16.
Property 5.4. w
pre
2k
n = ξ(w
pre
2k
n−1) where k =
1, 2, · · · , n− 1
Example: w3 = abbcbcca, w4 =
abbcbccabccacaab,
w
pre
4
3 = ab, w
pre
4
4 = ξ(ab) = abbc
Property 5.5. w
suf
2k
n = ξ(w
suf
2k
n−1) where k =
1, 2, · · · , n− 1
Example: w3 = abbcbcca, w4 =
abbcbccabccacaab,
w
suf
4
3 = ca, w
suf
4
4 = ξ(ca) = caab
6 Conclusions
In this paper, we propose some new word gen-
eration functions and study his properties. These
functions include Fibonacci words, alternating Fi-
bonacci words, the block palindrome words and
the suﬃx-preﬁx Fibonacci words.
Some new applications of generating functions
on algorithmic art are very interesting. In the fu-
ture, we will apply these generating function to
the algorithmic art, such as music or visual art.
References
[1] Jean-Paul Allouche, Michael Baake, Julien
Cassaigne, and David Damanik. Palindrome
complexity. Theoretical Computer Science,
292:9–31, 10 January 2003.
[2] Tom C. Brown. Applications of standard
sturmian words to elementary number the-
ory. Theoretical Computer Science, 273:5–9,
February 28 2002.
[3] H. Bruin and O. Volkova. The complexity of
ﬁbonacci-like kneading sequences. Theoretical
Computer Science, 337:379–389, 9 June 2005.
[4] W.-F. Chuan. Fibonacci words. Fibonacci
Quarterly, 30:68–76, 1992.
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-187-
On the Minimum Weighted Feedback Vertex Set Problem on the Parallel 
and Serial Connection of Diamonds 
 
Yen-Lian Chen, Y. L. Wang and Chia-Tung Lee 
Information Management  
National Chi Nan University, Nantou, Taiwan, ROC 
ylchen@alg.csie.ncnu.edu.tw, yuelwang@ncnu.edu.tw, retlee@ncnu.edu.tw
  
 
 
Abstract
In this paper, we introduce two variations of 
diamond graphs.  One is the parallel connection 
of two diamond and the other is the serial 
connection of two diamonds.  We shall propose a 
simple algorithm to solve the minimum weighted 
feedback vertex problem in the two kinds of 
diamonds. 
1  Introduction 
 
In this paper, we are concerned with the 
weighted feedback vertex set problem which is 
defined as followsΚ  We are given an undirected 
graph G = (V, E) where every vertex v  V has a 
weight c(v).  A feedback vertex set (FVS) of G is 
a subset D V of vertices such that each cycle in 
G contains at least one vertex in D, i.e, the 
subgraph G’ induced by the set V\D of vertices is 
acyclic.  The weighted feedback vertex set 
problem (WFVS) on a graph G is to find an FVS 
of minimum cost, where the weight of the set is 
the sum of the weights of its elements.   
 
We shall give an example as follows. Consider 
Figure 1.  There are many feedback vertex sets. 
For example, D1 = {v1, v3} is a feedback vertex set.  
The cost of D1 is c(v1) + c(v3) = 32 + 28 = 60. 
Another example is D2 = {v2, v5} is a feedback 
vertex set.  The cost of D2 is c(v2) + c(v5) = 24 + 
18 = 42. Finally, let D3 be {v3}.  The cost of D3 is 
c(v3) = 28. We can see that D3 is a minimal cost 
feedback vertex set in this example. 
 
The FVS problem on general graph is NP-hard 
[5].  For the WFVS problem the best known 
approximation algorithm has approximation ratio 
2(see, for example, [2,1]).  This problem 
becomes polynomial when addressed on interval 
graphs [7], convex bipartite graphs [3] and 
permutation graphs [6].  In this paper, we shall 
consider a special kind of graphs, namely the 
parallel and serial connection of two diamonds.   
 
A weighted diamond Dr,z = (V,E,w) with apices 
r and z (r, z
V ), is an undirected and vertex 
weighted graph where (i) each v
V is included in 
at least one path between r and z and (ii) Dr,z \ {z} 
is a tree.  For example, Figure 2 illustrates three 
graphs. Figure 2(a) is a weighted diamond graph. 
Figures 2(b) and 2(c) are not weighted diamond 
graphs. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
         Figure 1. A general graph. 
 
It was proved that the minimum weighted 
feedback vertex set problem can be solved on 
diamond graph in linear time by using a dynamic 
programming algorithm [4].  In this paper, we 
extend the idea of diamonds by parallel and serial 
connection of two diamonds.  Figure 3 shows a 
parallel connection of two diamonds and Figure 4 
shows a serial connection of two diamonds. 
 
In the following, we shall first give a brief 
review of the linear algorithms to solve the 
minimum weighted feedback vertex set problem 
on diamonds.  Then we shall show how we can 
use this algorithm to find a minimum feedback 
vertex set on two diamonds connected in either 
parallel or serial. 
 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-251-
Section 2. Solving the Minimum WFVS 
Problem on Diamonds 
We can see that every weighted feedback vertex 
set on a diamond Dr,z = (V,E,w) is one of the 
following three kinds of solutions. 
(1) D1: A minimum weighted feedback vertex  
 set of Dr,z which contains z.  In this case, 
 {z} itself must be a solution. 
(2) A solution which does not contain z.  In 
 this case, there are again two subclasses: 
   (a) D2: A minimum weighted feedback 
 vertex set of Dr,z which does not contain z 
 and Dr,z - D2 contains exactly one path 
 between r and z. 
 (b) D3: A minimum weighted feedback 
 vertex set of Dr,z which does not contain z 
 and Dr,z - D3 contains no path between r 
 and z.   
For example, consider Figure 5. 
     
For the diamond graph in Figure 5, there are 
three solutions for the minimum WFVS problem 
on this diamond graph and they are shown in 
Figure 6. 
 
Section 3. The Minimum Weighted 
Feedback Vertex Set Problem on the 
Parallel Connection of Two Diamond 
Graphs
 
In this section, we consider the parallel 
connection of two diamonds.  Let these two 
diamonds be denoted as G1 = (V1, E1, w1, r1, z1) 
and G2 = (V2, E2, w2, r2, z2).  Then we define the 
followingΚ 
(1) D11 (respectively, D21) is a minimum 
 feedback vertex set of G1(respectively, G2) 
 under the condition that 11 -D, zrD 11 
 (respectively, 22 - D, zrD 21) exactly 
 contains z1 (respectively, z2). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(2) D12 (respectively, D22) is a minimum 
 feedback vertex set of G1 (respectively, G2) 
 under the condition that 1  - D1 , zrD 12 
 (respectively,
22
 - D, zrD 22) exactly 
 contains one path between r1 and z1(r2 and 
 z2). 
Figure 6. A graph illustrating the solution for weighted diamond graph. 
(3) D13 (respectively, D23) is a minimum 
 feedback vertex set of G1 (respectively, G2) 
 under the condition that 11  - D, zrD 13 
 (respectively, 22  - D, zrD 23) contains no 
 path between r1 and z1(respectively, r2 and 
 z2). 
 
Let parallel diamond be denoted as G = (V, E, w, 
r, z).  Having found D11, D12, D13, D21, D22 and 
D23 in G, we can merge them into the following 
eight solutionsΚ   
(1) D11  Ж D21 is a minimum feedback vertex 
 set of G.  The set exactly contains two 
 lower apexes is z1 and z2. 
(2) D11  Ж D22 is a minimum feedback vertex 
 set of G. The set exactly contains the lower 
 apex of G1 and a one path solution of G2. 
(3) D11  Ж D23 is a minimum feedback vertex 
 set of G.  The set exactly contains the 
 lower apex of G1 and a no path solution of 
 G2. 
(4) D12  Ж D21 is a minimum feedback vertex 
 set of G.  The set exactly contains a one 
 path  solution of G1 and the lower apex of 
 G2. 
(5) D12  Ж D23 is a minimum feedback vertex set 
 of G.  The set exactly contains a one 
 path  solution of G1 and a no path solution 
 of G2. 
(6) D13  Ж D21 is a minimum feedback vertex 
 set of G.  The set exactly contains a no path 
 solution of G1 and lower apex of G2. 
(7) D13  Ж D22 is a minimum feedback vertex 
 set of G.  The set exactly contains a no path 
 solution of G1 and a one path solution of G2. 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-253-
give an example as Figure 8 and calculate as 
follows. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
          Figure 8 Serial connection. 
 
At first we can obtain the sets of vertices in D11, 
D12, D13, D21, D22, and D23 and which are {7}, {4, 
3}, {2, 3}, {14}, {9, 13}, and {9, 10} and their 
costs are 30, 8, 12, 30, 6, and 7, respectively. 
 
Finally, we can merge them into the following 
nine solutions and we select the minimum 
weighed set from eight solutions the as minimum 
weighted feedback vertex set. 
 
(1) D11ЖD21 = {7, 14}, cost 60. 
(2) D11ЖD22 = {7, 9, 13}, cost 36. 
(3) D11ЖD23 = {7, 9, 10}, cost 37. 
(4) D12ЖD21 = {3, 4, 14}, cost 38. 
(5) D12ЖD23 = {3, 4, 9, 10}, cost 15. 
(6) D13ЖD21 = {2, 3, 14}, cost 42. 
(7) D13ЖD22 = {2, 3, 9, 13}, cost 18. 
(8) D13ЖD23 = {2, 3, 9, 10}, cost 19. 
(9) D12ЖD22 = {4, 3, 9, 13}, cost 14. 
 
We will select Min{{7, 14}, {7, 9, 13}, {7, 9, 
10}, {3, 4, 14}, {3, 4, 9, 10}, {2, 3, 14}, {2, 3, 9, 
13}, {2, 3, 9, 10}, and {4, 3, 9, 13}}.  The 
minimum feedback vertex set is {3, 4, 9, and 13}, 
cost 14. 
 
 
Section 5.  Conclusion 
In this paper, we have presented the parallel and 
serial connection of diamond graphs and shown 
that it is possible to solve WFVP on them in linear 
time. In the future, we shall try to extend our 
results to tackle the series and parallel graphs [8, 9, 
10, 11] constructed out of diamond graphs. 
 
 
Reference: 
[1] V. Bafna, P. Berman, T. Fujito, Constant ratio 
approximations of the weighted  feedback 
vertex set problem for undirected graphs, in: 
ISAAC95, Algorithms and  Computation, in: 
Lecture Notes in Comput. Sci., vol. 1004, 
Springer-Verlag, Berlin, 1995, pp. 142–151. 
[2] A. Becker, D. Geiger, Approximation 
algorithms for the loop cutset problem, in: 
Proc. 10th Conf. on Uncertainty in Artificial 
Intelligence, 1994, pp. 60–68. 
[3] M.S. Chang, Y.D. Liang, Minimum feedback 
vertex sets in cocomparability graphs and 
convex bipartite graphs, Acta Inform. 34 
(1997) 337–346. 
[4] F. Carrabs, R. Cerulli, M. Gentili, G. Parlatob, 
A linear-time algorithm for the weighted 
feedback vertex problem on diamonds, 
Inform. Process. Lett. 94 (2005) 29–35.  
[5] M.R. Garey, D.S. Johnson, Computers and 
Intractability: A Guide to the Theory of 
NP-Completeness, Freeman, San Francisco, 
CA, 1979. 
[6] Y.D. Liang, On the feedback vertex set 
problem in permutation graphs, Inform. 
Process. Lett. 52 (1994) 123–129. 
[7] C.L. Lu, C.Y. Tang, A linear-time algorithm 
for the weighted feedback vertex problem on 
interval graphs, Inform. Process. Lett. 61 
(1997) 107–111. 
[8] Simon, S and Lee, R. C. T., On the Optimal 
Solution to AND/OR Series Parallel Graphs, 
Journal of the ACM, Vol. 18, No. 3, 1979, pp. 
354-357.  
[9] Takao Nishizeki, Jens Vygen, Xiao Zhou The 
edge-disjoint paths problem is NP-complete 
for series-parallel graphs, Journal of 
Algorithms, 115,(2001), 177-186 
[10] T. Nishizeki, J. Vygen and X. Zhou, The 
edge-disjoint paths problem is NP-Complete 
for series-parallel graphs, Proc. of the Third 
Conference on Integer Programming and 
Combinatorial Optimiation, (1993), 129-145. 
[11] Xiao ZHOU, Takao NISHIZEKI, Efficient 
algorithms for weighted colorings of 
series-parallel graphs.[Proc. of ISAAC 2001, 
Lect Notes in Comp. Sci, 2223, (2001), 
514-524] 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-255-
 
(c) An embedded triangular graph with 7 vertices 
 
Figure 2 Examples of embedded triangular graphs. 
 
3.  The Edge Pancyclic Property of 
Embedded Triangles. 
 
Definition of -cycle edge: k
Given a graph , an edge is a -cycle 
edge if and only if it is contained in a cycle of 
length [6].   
)(V,EG  k
k
 
Definition of Edge Pan-cyclic: 
A graph  with  vertices is edge pancyclic if 
all edges in  are -cycle, for all , where 
[5]. 
G n
G k k
nk 3
Theorem 3.1: Every embedded triangular graph is 
an edge pan-cyclic graph. 
 
Proof:   
 We prove this theorem by mathematical 
induction.  First, let us consider an embedded 
graph with 3 vertices which is the basis.  This 
graph is a 1-triangle embedded triangular graph.  
It is easy to prove that every 1-edge is a 3-cycle 
edge.  Therefore, the embedded triangular graph 
with 3 vertices is an edge pancyclic graph. 
Next, let us assume that the embedded 
triangular graph with  vertices is an edge 
pancyclic graph.  That is, all edges in the graph 
are -cycle, where 
n
k nk 3 . 
Now, let us consider the embedded graph with 
 vertices.  By the definition of embedded 
triangular graph, vertex  is inside a 
-triangle and is connected to three vertices 
of an -triangle.  These newly constructed 
triangles are -triangles.  We want to 
show that all edges in the embedded triangular 
graph with  vertices are -cycle, where 
.  We need to show (1) For every 
,
1n
1nv
2)( n
2)( n
1)( n
1n k
13  nk
j 21  nj , a -edge is -cycle for j k
13  nk .  (2) The -edges are 
-cycle for 
)1( n
k 13  nk . 
(1) By the inductive hypothesis, for every 
,j 21  nj , a -edge is -cycle for j k
nk 3 .  We now show that such a -edge is 
also 
j
)1( n -cycle.  We have to discuss two 
cases:  
Case 1: Assume that  is inside a certain 1nv
)2( n -triangle.  Consider any edge of this 
triangle.  This edge must be a -edge and 
connected to .  Now,   without loss of 
generality, we assume that the embedded 
triangular graph with 
j
1nv
)1( n  vertices starts with 
321 vvv , i.e., a triangle with three vertices, , 
 and .  There exists a graph obtained by 
deleting, say , is also an embedded triangular 
graph with  vertices.  By the definition of 
embedded triangular graphs, the -edge 
mentioned above must be in this embedded 
triangular graph with  vertices.  By the 
inductive hypothesis, this -edge is -cycle for 
1v
2v 3v
1v
n
j
n
j k
nk 3 .  Thus there exists a cycle  of 
length  containing the -edge.  Since  is 
of length , it must contain every vertex of the 
graph.  Thus, C  contains vertex  and 
consequently an edge connected to .  Without 
loss of generality, we assume this edge is 
C
n j C
n
2v
2v
32vv .  
Thus we can find a cycle of length )1( n  
containing the -edge by replacing j 32vv  by 
12vv  and 31vv  in the embedded triangular graph 
with )1( n  vertices starting with . 321 vvv
Case 2: Now, we consider those -edges 
which are not connected to .  Note that any 
cycle with  edges which contains the -edge 
must contain an 
j
1nv
n j
)2( n -edge; otherwise, it 
cannot be a cycle with  edges in the embedded 
triangular graph with  vertices.  Without loss 
of generality, we assume that this -edge is 
n
n
)2( n
 1 nn vv  .  Now, we can construct a cycle of length 
)1( n  by using two -edges, 1)( n
 11  nn vv and  1 nn vv  , to replace the 
2)( n -edge,  1 nn vv  .  Thus, every -edge is 
also 
j
)1( n -cycle, for 21  nj . 
(2) Consider any 1)( n -edge  1npvv .  This 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-274-
By the definition of embedded triangular graph, 
vertex  is inside a -triangle and is 
connected to three vertices of an -triangle.  
These newly constructed triangles are 
-triangles.  We want to show that there 
exists a path of length  between any two 
difference vertices  and  which contains 
two -triangle edges in an embedded 
triangular graph with n  vertices, where 
.  We need to show (1) There exists a 
path of length  between any two difference 
vertices  and  which contains two 
-triangle edges in an embedded triangular 
graph with  vertices, .  (2) 
There exists a path of length  between  
and  which contains two -triangle 
edges in an embedded triangular graph with  
vertices, where 
nv 3)( n
3)( n
2)( n
1n
iv jv
2)( n
nji 1
1n
iv jv
2)( n
n 11   nji
1n kv
nv 2)( n
n
11  nk . 
(1) By the inductive hypothesis, there exists a 
path of length  between any two difference 
vertices  and  which contains two 
-triangle edges, where 
2n
iv jv
3)( n 11  nji .  
We can easily find a path of length  between 
 and  by replacing a -triangle edge 
by two -edges.  Thus there exists a path 
of length  between any two difference 
vertices  and  which contains two 
-triangle edges, where 
1n
iv jv 3)( n
2)( n
1n
iv jv
2)( n 11  nji . 
(2) Without loss of generality, we assume that 
the embedded triangular graph with n  vertices 
start with .  There exists a graph 
obtained by deleting, say , is also an embedded 
triangular graph with 
321 vvv
1v
1n  vertices and this 
embedded triangular graph of  vertices must 
be an embedded triangular graph which starts with 
.  By the inductive hypothesis, there 
exists a path of length  between  and 
 which contains two -triangle edges in 
the embedded triangular graph , where 
.  By the definition of embedded 
triangular graphs, one of ,  and  is just 
connected to 3 vertices in .  Without 
loss of generality, we assume this vertex is .  
Since a path of length  between  and 
 which contains two -triangle edges, 
where , must contain .  Thus by 
the definition of embedded triangular graphs, the 
path of length  between  and  
which contains two -triangle edges, where 
1n
432 vvv
2n kv
nv 2)( n
432 vvv
12  nk
2v 3v 4v
432 vvv
2v
2n kv
nv 2)( n
13  nk 2v
2n kv nv
2)( n
13  nk , must contain a 1-edge of the 
embedded triangular graph .  This 
1-edge of the embedded triangular graph  
may be 
432 vvv
432 vvv
32vv  or 42vv .  Thus we can find a path 
of length 1)( n  between  and  which 
contains two 
kv nv
2)( n -triangle edges by replacing 
the 1-edge by 12vv  and 31vv (or 12vv  and 
41vv ), where 13  nk .  Since there exists a 
path of length 2n  between  and  
which contains two 
nv 2v
2)( n -triangle edges and 
 is adjacent to , we can find a path of length 1v 2v
1n  between  and  by concatenating  
and the path between  and .  Finally we 
shall show you that there exists a path of length 
nv 1v 1v
nv 2v
1)( n  between  and .  By the inductive 
hypothesis, there must exist a path of length 
nv 2v
3)( n  between  and  which contains two nv 3v
2)( n -triangle edges and this path does not 
contain .  We can find a path of length 2v
2)( n  by concatenating  and the path of 
length 
2v
3)( n  between  and  which 
contains two 
nv 3v
2)( n -triangle edges.  Finally we 
can find a path of length  between  
and  which contains two -triangle 
edges by replacing 
1)( n nv
2v 2)( n
32vv  by 12vv  and 31vv .  
This completes the proof. 
Theorem 4.2: Every embedded triangular graph is 
a panconnected graph. 
 
Proof:  
First , let us consider an embedded triangular 
graphs with 3.  In this embedded graph, the 
distance between every two vertices is 1.  It is 
easy to prove that the graph is panconnected.   
We assume that the embedded triangular graph 
with vertices is a panconnected graph.  This 
means that for every  and  
n
iv jv 11  nji , 
there is a path between  and  with length 
 such that 
iv jv
l 1 nl),vd(v k1n .  Now, let us 
consider the embedded graph with  vertices.  
We need to show (1) For every two vertices  
and  in this graph, there also exists a path of 
length , where 
1n
iv
jv
n nji 1 . (2) For  and 
, there exists a path of length , where 
1nv
kv l
nl),vd(v k1n   and nk 1 .  
By assumption, there exists a path joining any 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-276-
 Application of a Modified Convolution Method to 
Exact String Matching 
K.W. Liu1, R.C.T. Lee2 and C.H. Huang 3* 
1, 2 Department of Computer Science, National Chi Nan University, Puli, Nantou 
Hsieh, Taiwan 545 
3 Department of Computer Science and Information Engineering, National Formosa 
University, 64,Wen-Hwa Road, Hu-wei, Yun-Lin, Taiwan 632. 
* Corresponding author: chhuang@sunws.nfu.edu.tw
Abstract
The problem of exact string matching is to find all 
locations at which a query of length m matches a 
substring of a text of length n. In this paper, we first find 
out all relative suffixes of this query on the text, and we 
look backward to find out the corresponding prefixes of 
this query on the text. In order to get this effort, we make 
use of a wide window[R.1] whose size is equal to 2m-1. 
Logic operation in CPU is the main process for all 
calculations. We directly use the logic operations to 
speed up the matching. Because the query can be 
represented as the bit vector, we save the space 
complexity. We get the optimal solution for exact string 
matching.   
Keywords: convolution method; bit-vector; Wide 
Window approach; String matching 
 
 
1.  Introduction 
Many approaches use automaton[R.4] and suffix 
tree[R.5] to get the exact string matching. Using 
automaton and suffix tree methods have the advantage 
of theoretical explanation. But we need a complicated 
programming to appear the idea of automaton and suffix 
tree. In practice we can use the convolution method 
[R.2]to get the exact string matching. But the original 
convolution method is taken the disadvantage of big 
space and time complexity. In this paper, we use bits (1 
and 0) and bit level operation (in this paper we use AND 
and SHIFT) to simulate as convolution method. Among 
all of the mathematical operation, the bit level 
operations are faster than any other operations in CPU. 
Good preprocessing of pattern makes the string 
matching speed up. More of the string matching 
algorithms need to make the complicated preprocessing 
of pattern. In this paper we make a simple preprocessing 
of pattern. We use bits (0, 1) to representing the pattern 
in preprocessing. Time complexity for our preprocessing 
is O(m). Space complexity for our preprocessing is O(m) 
bit.  
The exact string matching problem is defined as 
follows: Given a text string T = t1t2t3…tn and a pattern 
string P = p1p2p3...pm. The length of the pattern string is 
always smaller the length of the text string. We find all 
occurrences of the pattern string within the text string. 
Example:  Given: a text string T and a pattern string P 
T = ababababaabbaabbabababa 
P = aabbaabb  
 
Sliding window method is the very simple method to 
solve the exact string matching problem. See Figure 1.1 
for an example. 
          Figure 1.1 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-411-
  
Figure 3.1  
 
We check the numbers among the results. If the value 
is equal to its position, we conclude that a suffix of P 
equal to a prefix of T2. 
The convolution method works, but the complexity is 
not good enough. With the convolution method, the time 
complexity is O(n2) and O(mn) additional space. To 
reduce the overhead, we proposed a modified 
convolution method.  As in Figure 3.2, to speed up, the 
“multiplication” and “addition” operations can be 
replaced with “shift” and “and” operations.  
 
We may also use the logic operator (AND &) to find all 
prefixes of T2 which are equal to some suffixes of P. 
      Figure 3.2 
 
Similarly, we may use the modified convolution method 
to find all suffixes of T1 which are equal to some 
prefixes of as Figure 3.3. 
 
T1 = aaba , P  = abcbd , Pr =dbcda  
           Figure 3.3 
 
4.  The Algorithm  
Let us consider the following case: 
          T = bcbdc 
          P = abcbd 
Our job is to determine whether there is a prefix in T 
which is a suffix of P. Indeed, in this case, we have 
4-prefix of T (bcbd) which is also the 4-suffix of P. 
 As indicated before, we may use modified 
convolution.  
  
 
Figure 4.1 
 
Definition 3. Given a string S = s1s2…sn and a character 
, the -bit pattern of S is defined as b1b2…bn where 
bi=1 if si =  and bi=0 if otherwise. 
Taking S = abcbd as an example: 
a-bit pattern of S  = 1 0 0 0 0  
b-bit pattern of S  = 0 1 0 1 0 
c-bit pattern of S  = 0 0 1 0 0  
d-bit pattern of S  = 0 0 0 0 1 
We can now observe that  
1. V1 = b-bit pattern of P as we are comparing T[1] 
= b with P, 
2. V2 = c-bit pattern of P as we are comparing T[2] 
= c with P, 
3. V3 = b-bit pattern of P as we are comparing T[3] 
= b with P, 
4. V4 = d-bit pattern of P as we are comparing T[4] 
= d with P, 
5. V5 = c-bit pattern of P as we are comparing T[5] 
= c with P. 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-413-
                  Figure 4.6 
            Figure 4.7 
 
  We have found one suffix which is 4-suffix. The 
corresponding prefix which we need to find is 
(|P|-4)-prefix. If we found, we got a matching. 
Having constructed the character bit pattern of 
reversed P, we may use the character bit pattern of 
reversed P to find whether the suffix of T1 is equal to the 
prefix of P as shown in Figure 4.8 to Figure 4.11.  
 
   Figure 4.8 
   Figure 4.9 
   Figure 4.10 
  Figure 4.11 
 
5.  Analysis of Complexities 
 In the preprocessing, we make the bit pattern of 
pattern P and the bit pattern of reversed P. We represent 
P as the bit pattern whose length is |P|. 
 
Proposition 1.. The space complexity for preprocessing 
is O(m) bits. 
 Preprocessing is linear time complexity, since the 
entire preprocessing just need to read P one time. 
 
Proposition 2. The time complexity for preprocessing is 
O(m). 
The length of text string |T| is n and the length of 
pattern string |P| is m. Therefore we have n/m wide 
windows. For each wide window, we need 2m 
comparisons in worst case. So the total time needed is 
O(n) in worst case ( 2m × n/m = 2n). 
 
Proposition 3. The time complexity for searching is 
O(n). 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-415-
Solving the Subcircuit Matching Problem  
by Using Encoded Matrix Method 
 
Chia Shin Ou and R. C. T. Lee 
Department of Communication Engineering 
National Chi Nan University, Puli, Nantou Hsien, 545, Taiwan ROC 
csou@alg.csie.ncnu.edu.tw 
rctlee@ncnu.edu.tw 
 
 
Abstract
 
The problem of finding subcircuit in a 
larger main circuit is an important issue recently.  
In this problem, we are given a main circuit and 
a subcircuit.  Our job is to find all occurrences 
of the subcircuit in the main circuit.  In this 
paper, we propose a method to solve the 
subcircuit matching problem by encoding a 
circuit into a connection matrix consisting of 
positive integers where each row and column 
corresponding to a component in the circuit. Our 
approach eliminates a row and its corresponding 
column in the matrix of the main circuit which 
cannot be any candidate of any component in the 
subcircuit.  We have a mechanism to extract 
subcircuits from the surviving matrix.  It is 
proved in the paper that our algorithm is sound 
and complete.  
 
 
1  Introduction 
 
 The subcircuit finding problem is defined 
as follows:  We are given a subcircuit , and 
a main circuit , which is usually much larger 
than the subcircuit. Our job is to determine 
whether  exists in G .  Finding a subcircuit 
in the main circuit is a very important issue in 
analog circuit design because we often have to 
modify the subscircuit which may exist every 
where in the main circuit.  Some research has 
been done in this field [1, 2, 3, 4].  Chang, 
Tzeng, and Lee use a recursive graph 
identification scheme and a weighted value to 
each node in graph to reduce the run time[1].  
SubGemini[2] uses the partitioning and 
relabeling algorithm to find all subcircuits in 
large circuit.  SUBGEN[3] describes an 
approach by using genetic algorithm, and Zhang 
and Wunsch II provide an algorithm for the 
subcircuit finding algorithm by using fuzzy 
attributed graph[4].  Our approach is to encode 
a circuit into a symmetrical matrix containing 
positive integers.  We then provide four rules to 
eliminate entries in the matrix corresponding 
to .  We also provide a mechanism to 
determine whether the surviving matrix contains 
integer number of submatrices corresponding 
to .  If this is the case, we have found 
matchings.  
S
G
S
G
S
 
 
2.1 The Main Idea of Our Method 
In our paper, the components in the circuits 
are limited to eight kinds, as illustrated in Fig. 1. 
 
Fig.1 
 
 In an analog circuit, connections are made 
between two terminals.  For example, the drain 
of a transistor may be connected to the source of 
another transistor.  In the first step, if a terminal 
x  of a component is connected to a terminal 
y  of another component,  and 1),( yxV
0),( yxV  if otherwise.  Some examples 
are in Fig. 2. 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-355-
0s
0g
1d
Terminal The value of this matrix is 
1*4+0*2+0*1=4
other Device
MOS
dg
s
MOS
Resistor
0*1
1*4
100Terminal
sgd
The value of this matrix is 
0*4+0*2+1*1=1
dg
s
MOS
Resistor
other Device
MOS
1*1
Fig. 7 
 
4MOS
other Device
1other Device
MOS
 
Fig. 8 
 
Case 3: Two Other Components.
Suppose that a terminal of a resistor is 
connected to a terminal of a capacitor.  The 
connection matrix between resistor and capacitor 
is shown in Fig. 9 and we encode the connection 
matrix into a positive integer which is shown in 
Fig. 10.   
1Terminal
Terminal
The value of this matrix is 1*1=1
other Device
other Device
Resistor
Capacitor 1*1
Fig. 9 
1
other Device
other Device  
Fig. 10 
 
Through this way, the two matrices 
encoding the terminals in Fig. 11 are now 
transformed into matrices encoding the 
connection of components.   
 
Fig. 11 
 
 
2.2 The Checking Rules of Our 
Algorithm
We denote the encoded matrix for the main 
circuit  as .  Our 
algorithm is an algorithm which checks whether 
an entry in  can be a candidate for an 
entry in .  If an entry 
)(SG ))()(( SMGM
)(GM
)(SM x  of  
cannot be the candidate of any entry 
)(GM
y  in 
, )(SM x  will be eliminated.   
Rule 1: Suppose we consider a component x  
in  and a component S y  in G .  Let the 
number of some type of components connected 
to x  in be and the number of the 
same type of components connected to 
S a
y  be 
. If b y is a candidate for matching x ,  
must be smaller than or equal to . 
a
b
 
We show an example in Fig. 12. 
P1 P2 P3 N1 N3 N4N2
P1
P2
P3
N1N2
N3
N4
VDD G
VDD
G
P’1 P’2 N’1 N’2 VDD’ G’
P’1P’2
N’1
N’2
VDD
G
1 3 NMO  1PMOS S VDD 1 2 NMOS 1 VDPMOS D
G S
1 PMOS 1 NMOS 1 GND 2 PMOS 1 NMOS
P1 P1’
N3 N1’
Fig. 12 
 
In this case, P1 is connected to one PMOS, 
three NMOS’s and one VDD, and P1’ is 
connected to one PMOS, two NMOS’s and one 
VDD.  P1 is a candidate for matching P1’.  In 
another case, N3 is connected to one PMOS, one 
NMOS and one GND, and N1’ is connected to 
two PMOS, one NMOS.  N3 is not a candidate 
for matching N1’. 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-357-
0      0 
0      0
P1’
N2’
P1’N2’ does not match P1N1
0    127
127    0
P1’ N1’
P1’
N1’
P1’N1’ match P1N1
P1’ N2’
Fig. 16 
 
 
2.3 Our Algorithm 
Subcircuit matching algorithm 
Input :   A main circuit  and a subcircuit 
 
G
S
 
Output :  All of the locations of subcircuits in 
 matching S . G
 
Step 1. Transform  and  into their 
connection matrices. 
S G
 
Step 2.  Encode the matrices. into  and 
. 
)(SM
)(GM
 
Step 3.   For each row x  of , check 
whether 
)(GM
x  is a candidate of a row 
y  in .  Delete )(SM x  and its 
corresponding columns if and only if 
it is found, by using Rules 1 to 4, that 
x  is not a candidate of any row y  
in .  If no row is deleted in 
this step, go to Step 5; otherwise, go 
to Step 4. 
)(SM
 
Step 4.   If  is smaller than , 
end the algorithm and report that 
there is no subcircuit matching in 
.  Otherwise, go to Step 3. 
)(GM )(SM
G
 
Step 5.   If solutions are found after application 
of Rule 5, report all such solutions in 
; otherwise, report that no solution 
is found. 
G
 
 
3. The Soundness and Completeness 
of Our Algorithm 
 We first show the soundness of our 
algorithm.  By soundness, we mean that every 
solution we find is a correct one.  Suppose 
otherwise.  Then there must be a case where a 
component  in  is matched to a 
component  in  and the connection 
between 
)'(' yx G
)(yx S
x  and y  is different from that 
between  and .  But this is impossible 
because of Rule 5 and Rule 3. 
'x 'y
 
 By completeness, we mean that every 
solution in  is found by our algorithm. 
Suppose a subcircuit 
G
A  in G  matching  
exists and is not found by algorithm.  There 
must exist a component  of 
S
'x A  which is 
deleted by our algorithm.  But, our algorithm 
deletes  if and only if  is not a 
candidate for any component in .  Thus 
 does not match any component of .  
Thus 
'x 'x
S
'x S
A  cannot match , a contradiction.   S
 
 
4. Experiments 
We wrote a C language problem to test and 
verify our algorithm.  Since many circuits are 
in the form of a HSPICE program,  we have 
also developed a C language program to 
transform a HSPICE program defining a circuit 
into the connection matrix corresponding to this 
circuit. 
 
Experiment 1 
The main circuit of the first experiment is 
shown in Fig. 17(a) and we found the subcircuit 
which is shown in Fig. 17(b).  All of the 
circuits can be found in [2]. The time needed is 
0.013 second. 
Fig. 17 
 
Experiment 2 
The main circuit of the second experiment 
is shown in Fig. 18 and we found the subcircuits 
shown in Fig. 19(a) and Fig. 19(b).  There are 2 
subcircuits of Fig. 19(a) in the main circuit and 
we found them all.  Simliarly, we found 2 
subcircuits in Fig. 19(b) in the main circuit.  
The time needed for the subcircuit in Fig. 19(a) 
is 0.026 second and that needed for the 
subcircuit in Fig. 19(b) is 0.019 second. 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-359-
Fig. 23 
 
 
5. Conclusion 
In the paper, we proposed an algorithm to 
solve the subcircuit matching problem.  Our 
algorithm transforms circuits into matrices with 
positive integers.  By deleting non-candidates 
of components in the matrix corresponding to 
the main circuit, we can find all subcircuits in 
the main circuit.  Besides, all subcircuits which 
we find are correct. 
 
 
6. References 
[1] W. S. Chang, S. D. Tzeng, and C. Y. Lee, 
“Novel Subcircuit Extraction Algorithm by 
Recursive. Identification Scheme”, IEEE 
International Symposium on. Circuits and 
Systems, pp. 491-494, 2001. 
[2] Miles Ohlrich, Carl Ebeling, Eka Ginting, 
and Lisa Sather, “SubGemini: Identifying 
SubCircuits using a Fast Subgraph 
Isomorphism Algorithm, “ ACM/IEEE 
Design Automation Conference, pp. 31-37, 
June 1993. 
[3] N. Vijaykrishnan and N. Ranganathan, 
"SUBGEN: A. Genetic Approach for 
Subcircuit Extraction,. " 9'*. International 
Conference on VLSl Design, January 1996. 
[4] Nian Zhang and Donald C. Wunsch II, “A 
Fuzzy Attributed Graph Approach to 
Subcircuit Extraction Problem”, The IEEE 
International Conference on Fuzzy Systems, 
St. Louis, MO, May 25-28, 2003. 
 
 
Acknowledgements:  We are grateful to 
Professor Jenn-Chyou Bor of the National Tsing 
Hua University who provided us with the main 
circuit in Experiment 3 and Mr. H. Y. Fan who 
provided us with the main circuit in Experiment 
4. 
 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-361-
which is denoted as (1, 8) (3, 6). 
 
Figure 2 
 
The k-palindrome subsequence has one 
property which is that the k-palindrome 
subsequence is based up on k-1-palindrome 
subsequence and 1-palindrome subsequence.  
Let k-1-palindrome be (i1, j1) … (ik-1, jk-1) and 
1-palindrome subsequence be (i’, j’).  The 
k-palindrome subsequence, (i1, j1) … (ik-1, jk-1) (i’, 
j’), can be found from k-1-palindrome 
subsequence and 1-palindrome subsequence, if 
the i’ > ik-1 and j’ < jk-1.  For example, given a 
string S = ACGATGTAC then CC, CAAC and 
CATTAC are palindrome subsequences of S. CC 
is a 1-palindrome subsequence denoted (2, 9) 
(Figure 3(a)), AA is also a 1-palindrome 
subsequence denoted (4, 8) and TT is also a 
1-pailindrome subsequence denoted (5, 7).  
CAAC is a 2-palindrome subsequence denoted 
(2, 9) (4, 8) which is based upon 1-palindrome 
subsequence (Figure 3(b)). CATTAC is a 
3-palindrome subsequence denoted (2, 9) (4, 8) 
(5, 7) which is based upon 2-palindrome 
subsequence and 1-palindrome subsequence. 
 
(a) The matched pair of CC 
 
(b) The matched pairs of 
CAAC
 
(c) The matched pairs of CATTAC 
Figure 3 
 
According to the above property of 
k-palindrome subsequence, we can use it to find 
all palindrome subsequences.  For example, 
given a string S = ACGATGTAC, we can use it 
to find all palindrome subsequences of S as 
follows: 
 
S1 S2 S3 S4 S5 S6 S7 S8 S9
A C G A T G T A C 
First, we find all matched pairs of S and 
each matched pair is a 1-palindrome 
subsequence. 
 
(1, 4) AA 
(1, 8) AA 
(2, 9) CC 
(3, 6) GG 
(4, 8) AA 
(5, 7) TT 
 
After all 1-palindrome subsequences of S 
are found, we can find all 2-palindrome 
subsequences based upon them. 
 
(1, 8) (3, 6) AGGA 
(1, 8) (5, 7) ATTA 
(2, 9) (3, 6) CGGC 
(2, 9) (4, 8) CAAC 
(2, 9) (5, 7) CTTC 
(4, 8) (5, 7) ATTA 
 
After finding all 2-palindrome 
subsequences, we can find all 3-palindrome 
subsequences based upon 2-palindrome 
subsequence and 1-palindrome subsequence. 
 
(2, 9) (4, 8) (5, 7) CATTAC 
  
The recursive process continues until all 
palindrome subsequence are found out. 
 
 
3. The Algorithm 
 
We proposed an algorithm to solve the 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-372-
(5, 7)}, U2 = {} 
(1-1) 
We take the 1-palindrome subsequence (1, 4) 
from U1. 
For all 1-palindrome subsequences from U1, 
there is no 1-palindrome subsequence  (i’, j’) 
which satisfies that i’ > 1 and j’ < 4. 
U2 = {} 
(1-2) 
We take the 1-palindrome subsequence (1, 8) 
from U1. 
For all 1-palindrome subsequences from U1, 
there is a 1-palindrome subsequence (3, 6) 
which satisfies that 3 > 1 and 6 < 8. We 
combine (1, 8) with (3, 6) to be 2-palindrome 
subsequence (1, 8) (3, 6) and add it into the 
set U2. 
U2 = {(1, 8) (3, 6)} 
There is another 1-palindrome subsequence 
(5, 7) which can satisfy that 5 > 1 and 7 < 8. 
We combine (1, 8) with (5, 7) to be 
2-palindrome subsequence (1, 8) (5, 7) and 
add it into the set U2. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7)} 
There is no 1-palindrome subsequence which 
can be satisfied. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7)} 
(1-3) 
We take the 1-palindrome subsequence (2, 9) 
from U1. 
There is a 1-palindrome subsequence (3, 6) 
which can be satisfied. We combine (2, 9) 
with (3, 6) to be 2-palindrome subsequence (2, 
9) (3, 6) and add it into the set U2. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 6)} 
There is another 1-palindrome subsequence 
(4, 8) which can be satisfied. We combine (2, 
9) with (4, 8) to be 2-palindrome subsequence 
(2, 9) (4, 8) and add it into the set U2. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 6), 
(2, 9) (4, 8)} 
There is another 1-palindrome subsequence 
(5, 7) which can be satisfied. We combine (2, 
9) with (5, 7) to be 2-palindrome subsequence 
(2, 9) (5, 7) and add it into the set U2. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 6), 
(2, 9) (4, 8), (2, 9) (5, 7)} 
There is no 1-palindrome subsequence which 
can be satisfied. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 6), 
(2, 9) (4, 8), (2, 9) (5, 7)} 
(1-4) 
We take the 1-palindrome subsequence (3, 6) 
from U1. 
Check all 1-palindromes from U1.  
There is no 1-palindrome which can be 
satisfied. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 6), 
(2, 9) (4, 8), (2, 9) (5, 7)} 
(1-5) 
We take the 1-palindrome (4, 8) from U1. 
Check all 1-palindromes from U1.  
There is a 1-palindrome (5, 7) which can be 
satisfied. We combine (4, 8) with (5, 7) to be 
2-palindrome (4, 8) (5, 7) and add it into the 
set U2. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 6), 
(2, 9) (4, 8), (2, 9) (5, 7), (4, 8) (5, 7)} 
There is no 1-palindrome which can be 
satisfied. 
U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 6), 
(2, 9) (4, 8), (2, 9) (5, 7), (4, 8) (5, 7)} 
(1-6) 
We take the 1-palindrome (5, 7) from U1. 
Check all 1-palindromes from U1.  
There is no 1-palindrome which can be 
satisfied. 
 
(2) k = 3, U1 = {(1, 4), (1, 8), (2, 9), (3, 6), (4, 8), 
(5, 7)}, U2 = {(1, 8) (3, 6), (1, 8) (5, 7), (2, 9) (3, 
6), (2, 9) (4, 8), (2, 9) (5, 7), (4, 8) (5, 7)}, U3 = 
{} 
(2-1) 
We take the 2-palindrome (1, 8) (3, 6) from 
U2. 
Check all 1-palindrome from U1. 
There is no 1-palindrome which can be 
satisfied. 
U3 = {} 
(2-2) 
We take the 2-palindrome (1, 8) (5, 7) from 
U2. 
Check all 1-palindrome from U1. 
There is no 1-palindrome which can be 
satisfied. 
U3 = {} 
(2-3) 
We take the 2-palindrome (2, 9) (3, 6) from 
U2. 
Check all 1-palindrome from U1. 
There is no 1-palindrome which can be 
satisfied. 
U3 = {} 
(2-4) 
We take the 2-palindrome (2, 9) (4, 8) from 
U2. 
Check all 1-palindrome from U1. 
There is a 1-palindrome (5, 7) which can be 
satisfied. We combine (2, 9) (4, 8) with (5, 7) 
to be 3-palindrome (2, 9) (4, 8) (5, 7) and add 
it into the set U3. 
U3 = {(2, 9) (4, 8) (5, 7)} 
(2-5) 
We take the 2-palindrome (2, 9) (5, 7) from 
U2. 
Check all 1-palindrome from U1. 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-374-
String Matching Algorithms Based upon the Uniqueness Property 
Chia-Wei Lu and R. C. T. Lee 
Department of Computer Science and Information Engineering 
National Chi Nan University, Nantou, Taiwan, ROC 
cwlu@alg.csie.ncnu.edu.tw, rctlee@ncnu.edu.tw 
 
 
Abstract
 
In this paper, we consider the exact string 
matching problem which is to determine all of the 
locations of a pattern string appearing in a text 
string.  We first point out a uniqueness property 
of a given pattern.  We then propose three some 
algorithms to solve the exact string matching 
problem based upon the uniqueness property.  
Experimental results showed that two of our 
algorithms are faster than the KMP and 
Boyer-Moore algorithms.  For a text of 250000 
characters with a vocabulary of four characters a 
pattern with 8000 characters, one of our 
algorithms took 1.412ms to solve the exact 
matching problem.  For the same data, another 
algorithm took only 1.06ms. 
 
 
Introduction 
 
In this paper, we are concerned with the exact 
string matching problem in which we are given a 
pattern  and a text , 
, and we are asked to find all occurrences of 
mpppP ...21 ntttT ...21
mn 
P  in T .  Much research has been done in the 
area [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 and 
15]. 
In almost all algorithms, we open a window in 
T  with size  and try to see whether m P  
matches with the substring in this window.  A 
straight forward approach is to compare the 
substring in the window with P  character by 
character from left to right.  If a mismatch is 
found, move the pattern one step to the right.  
This operation is equivalent to opening a new 
window and we may repeat the above describe 
operation again and again.  This approach is an 
exhaustive search approach because every 
substring is compared.  
Nearly all exact string matching algorithms 
try to avoid exhaustive search.  In the following, 
we shall introduce a rule, called the suffix to 
prefix rule, which allows us to avoid an exhaustive 
search.  
 
 
Section 1. The Suffix to Prefix Rule 
 
Let us consider Figure 1-1.  Suppose we 
have longest suffix  of a window which is also 
a prefix of 
u
P , we can move P  in such a way 
that the prefix  of u P  matches with the suffix 
 of the window. u
 
u
u
(b)
T
P
(a)
uT
P u
 
Figure 1-1 
 
Many string matching algorithms use this 
suffix to prefix rule [3, 5, 6, 11, 12, 13 and 14].  
This suffix to prefix rule is a general principle.  It 
may be used together with other rules.  For 
instance, the window doesn’t have to be of size 
.  A smaller window may be used.  Besides, 
as shown in Figure 1-1, it would be desirable if  
is very small because a small would enhance a 
long movement of 
m
u
P . 
In the next section, we shall introduce a new 
concept, based upon the uniqueness property, 
which will make the suffix to prefix rule a very 
efficient rule when it is used. 
 
 
Section 2. The Uniqueness Property of 
a String 
 
Consider a pattern P .  In P , let us find a 
substring which occurs in P  only once.  For 
instance, for P  = CATAGTAGCCT, there are 
many such substrings.  Suppose we use the 
substring CC and in some instance, CC in P  
matches CC in  exactly, as shown in Figure 
2-1. 
T
T:  CTAGCGTAGACCATAGΞ
P:       CATAGTAGCCT  
Figure 2-1 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-385-
V , it would update the value of l  and try to 
find the longest prefix with unique suffix which 
length isʳ 1V .  It will stop when 
mlVV (=  12 , and return the indexes of inV
P ,  and the variable l . vv ji ,
 
II. Searching phase 
 
In searching phase, it would open a window 
 with length  to 
match with 
1, miiT )11(  mni m
P  and move P  from left to right.  
In every window , we first match the 
substring  with , and there are two 
cases shown as following:  
1, miiT
V
vv jiiiT  ,
 
Case 1:  
If there is a mismatch when we match the 
substring  with , we move V
vv jiiiT  , P  by 
one step.(Shown in Figure 3-3(a)) 
 
Case 2: 
If  matches with , we match the 
other positions of 
V
vv jiiiT  ,
P  with , and no 
matter whether there is a mismatch occurring or 
not, we can move P by  steps. (Shown in Figure 
3-3(b)) 
1, miiT
l
 
 
V
V
V
i i+iv i+jv
iv jv
(a). V mismatches with ,v vi i i jT   . 
iv jv
T
P
P
 
V
V
u V
l
i i+ iv i+ jv
iv jv
(b). V matches with ,v vi i i jT   . 
iv jv
T
P
P
Figure 3-3. Searching phase of Algorithm 1. 
 
III. Pseudo code 
 
Input: P and T. 
Output: The positions which P occurs in T. 
 
/* Preprocessing phase */ 
for all  =
c
    tmp[c] = 0;  
for(i=0; i<m; i++){ 
    if(tmp[pattern[i]] == 0){ 
        iji vv  ; 
        l = i; 
    } 
    tmp[pattern[i]] = i; 
} 
length=1; 
k = 1; 
while( mlk = ){ 
    for(i=m- length; i> lk = ; i--){ 
         if( is unique in 
){ 
lengthiiP ,
lengthiP ,1
             = i; vi
             = i+ length; vj
             l = i+ length 
-border( ); lengthiiP ,
             k=0; 
             break; 
         } 
    } 
    length++; 
    k++; 
} 
 
/* Searching phase */ 
for(i=0;i< PT  ;i++){ 
     Step 1: Match  with . 
vv jiP , vv jiiiT  ,
     if (  mismatch with )  
vv jiP , vv jiiiT  ,
       Move P one step and go to Step 1. 
 
     Step 2: Match P with (ignore 
) 
1, miiT
vv jiP ,
     if (P mismatch with )  1, miiT
Move P by l steps and go to Step 1. 
 
     else output i, and move P by l steps. 
} 
 
In the best case, the substring V  is .  
Every time in case 2 of searching phase, we can 
move 
mp
P by . m
In the worst case, the substring V  is , 
that is, all the characters of 
1p
P  are the same, and 
we could always move P  only one step in the 
searching phase. 
 
 
 
 
 
Section 4. Algorithm 2-Longest 
Substring with Unique Character 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-387-
 x
x
i i+j-1
j
(b) jp  matches with 1i jt    
T
P
P
x
j-l
xx
jj-ll
 Figure4-5 
 
III. Pseudo code 
 
Input: P and T. 
Output: The positions which P occurs in T. 
 
/* Preprocessing phase */ 
for all  =
c
    tmp[c] = 0;  
for(i=0; i<m; i++){ 
    if(tmp[pattern[i]] == 0){ 
        l = i; 
        j = i; 
    } 
    tmp[pattern[i]] = i; 
} 
for all  =
c
    tmp[c] = 0;  
      
for(i= m; i>0; i--){ 
    if(tmp[pattern[i]] –i > l){ 
         l = tmp[pattern[i]] –i; 
         j = i; 
    } 
    tmp[pattern[i]] = i; 
} 
Go to Searching phase 
 
/* Searching phase */ 
for(i=0;i< PT  ;i++){ 
   Step 1: Match  with . jp 1 jit
   if (  mismatches with )  jp 1 jit
Move P one step and go to Step 1. 
 
   Step 2: Match P with (ignore 
) 
1, miiT
jp
   if (P mismatches with )  1, miiT
Move P by l steps and go to Step 1. 
  
else output i, and move P by l steps. 
} 
 
The preprocessing can be done in linear time, 
and it has the better efficiency in searching time 
than Algorithm 1. 
 
 
Section 5. Algorithm 3-The Unique 
Pairwise Substring Algorithm 
 
Let us consider the case when P = 
GCGCACTCGTCT.  There are many unique 
substrings in this pattern.  For instance, CGC is a 
unique substring of P . But, there is another 
substring, namely CTC, which is quite similar to it, 
and we shall later explain this special uniqueness 
property.  In the following, we first give this kind 
of substring precise definition. 
Given a string X , a substring 
 is called a unique pairwise 
substring if it satisfies the condition that  
 occurs in the prefix  
of 
jjii xxxx 11... 
jjii xxxx 11...  jj- x...xxx 121
X  exactly once for any . 11...  ji xx
For example, if P = 
CACTCAGCCACTCGC, we may use TCG as our 
selected pairwise substring.  Note that TCG is 
unique in CACTCAGCCACTCG and there is no 
other T x G occurring in CACTCAGCCACTCG 
for any x .  In some instance, the characters T 
and G of the substring match the characters T and 
G of T x G in T exactly for any x , and we could 
move P  by 12 steps as shown in Figure 5-1. 
 
P:         CACTCAGCCACTCGC
T: CAGGGAGCTAGCTAGGTAGACTACGATCGATGCCCGCAT… 
P:         CACTCAGCCACTCGC
Figure 5-1 
 
I. Preprocessing phase 
 
There are many such unique pairwise 
substrings, and this algorithm will select the one 
which is located at rightest in the pattern.  Record 
the positions of first and last character of the 
selected substring as  and v .  Let  be 
equal to .  Return ,  and l . 
vi j l
vi vi vj
 
II. Searching phase 
 
When we search the positions where P  
occurs in T , we open a window  with 
length  to match 
1, miiT
m P  and move P  from left 
to right.  When we match P  with , we 
first match the characters  with ,  
with , and there are two cases shown in the 
following: 
1, miiT
vip 1 viit vjp
1 vjit
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-389-
Table 7-1. (n = 100,000) 
m \ 10-3 sec Algorithm 1 Algorithm 2 Algorithm 3 BM KMP Brute-force
50 1.758 1.180 1.341 1.559 5.397 6.815 
100 1.506 1.152 0.823 1.294 4.306 7.118 
500 1.026 0.830 0.589 0.957 4.289 6.414 
1000 1.089 0.991 0.743 1.004 4.578 6.847 
2000 0.927 0.705 0.653 0.876 4.699 6.526 
4000 0.970 0.714 0.602 0.788 5.300 6.422 
8000 1.074 0.725 0.503 0.834 4.338 5.778 
Table 7-2. (n = 250,000) 
m \ 10-3 sec Algorithm 1 Algorithm 2 Algorithm 3 BM KMP Brute-force
50 4.626 3.034 3.664 3.911 11.654 16.091 
100 5.000 2.846 2.189 3.499 12.217 16.471 
500 2.666 2.085 1.343 2.501 12.141 15.904 
1000 2.821 2.451 1.526 2.511 12.449 15.905 
2000 2.172 1.661 1.397 1.920 12.020 15.995 
4000 2.169 1.573 1.218 1.828 12.479 14.878 
8000 1.797 1.412 1.060 1.508 10.779 14.973 
 
Section 7. Conclusions
 
In this paper, we have proposed three 
algorithms based upon the uniqueness property of 
a pattern.  Experimental results show that our 
algorithms are quite efficient.  Two of our 
algorithms are faster than the KMP and BM 
algorithms.  In the future, we plan to do more 
research on the pre-processing stage.  That is, we 
would like to develop good algorithms to do the 
pre-processing as we note that the pre-processing 
needed in each of our algorithms is an interesting 
problem in algorithm design.  Furthermore, we 
would like to do more theoretical analysis of our 
algorithms.  
References 
 
[1] Apostolico, A., Giancarlo, R., 1986, The 
Boyer-Moore-Galil string searching 
strategies revisited, SIAM Journal on 
Computing 15(1):98-105. 
[2] Apostolico, A., Crochemore, M., 1991, 
Optimal canonization of all substrings of a 
string, Information and Computation 
95(1):76-95. 
[3] Boyer, R.S., Moore, J.S., 1977, A fast string 
searching algorithm. Communications of 
the ACM. 20:762-772. 
[4] Colussi, L., 1991, Correctness and 
efficiency of the pattern matching 
algorithms, Information and Computation 
95(2):225-251. 
[5] Crochemore, M., Czumaj, A., Gasieniec, L., 
Jarominek, S., Lecroq, T., Plandowski, W., 
Rytter, W., 1992, Deux méthodes pour 
accélérer l'algorithme de Boyer-Moore, in 
Théorie des Automates et Applications, 
Actes des 2e Journées Franco-Belges, D. 
Krob ed., Rouen, France, 1991, pp 45-63, 
PUR 176, Rouen, France. 
[6] Colussi, L., 1994, Fastest pattern matching 
in strings, Journal of Algorithms. 
16(2):163-189. 
[7] Charras, C., Lecroq, T., Pehoushek, J.D., 
1998, A very fast string matching algorithm 
for small alphabets and long patterns, in 
Proceedings of the 9th Annual Symposium 
on Combinatorial Pattern Matching , M. 
Farach-Colton ed., Piscataway, New Jersey, 
Lecture Notes in Computer Science 1448, 
pp 55-64, Springer-Verlag, Berlin. 
[8] Galil, Z., Seiferas, J., 1983, Time-space 
optimal string matching, Journal of 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-391-
The Application of Convolution to Suffix to Prefix Rule for the Exact 
String Matching Problem 
Zhong He Chen and R. C. T. Lee 
Department of Computer Science and Information Engineering 
National Chi Nan University, Puli, Nantou Hsien, 545, Taiwan ROC 
zhchen@alg.csie.ncnu.edu.tw 
rctlee@ncnu.edu.tw
 
Abstract
In this paper, we consider the exact string 
matching problem.  We first point out a rule, 
called the suffix to prefix rule, which can be used 
to avoid the brute-force sliding window 
approach.  The Backward Nondeterministic 
Matching algorithm, Backward Oracle 
algorithm and Reverse Factor algorithm all use 
this rule.  To implement this rule, we have to 
find the longest suffix of text T which is equal to 
a prefix of pattern P.  In this paper, we point out 
that convolution can be used to do this.  As can 
be seen, the convolution technique is easy to 
understand and easy to program.  
 
 
1 The Exact String Matching 
Problem 
1.1   Background 
String matching is a classical problem in 
computer science and can be applied to 
encryption, compression, DNA sequences 
analysis, imaging processing, and etc.  Some 
searching engines such as yahoo, google and 
Wikipedia also apply the technique.  There are 
many algorithms for solving the exact string 
matching problem, such as MP algorithm [9], 
KMP algorithm [6], Boyer-Moore algorithm [11], 
Smith algorithm [13], Backward 
Nondeterministic Matching algorithm [10], 
Horspool algorithm [5], Shift-And algorithm[15],  
and etc. 
 
 
1.2   Terminology 
Definition 1.1:  
Match 
Given a text T=t1t2t3…tn and a pattern 
P=p1p2p3...pm, if there exits a location i in T such 
that titi+1…ti+m-1 is equal to p1p2p3...pm.  We say 
that P has a match at location i in T. 
For example, we are given a text T =AT 
TGCCAA TGCCA CCA and a pattern P 
=TGCCA. 
T =AT TGCCAATG CCA CCA 
P =   TGCCA 
As the example shown above, P has a match at 
location 3 in T. 
Definition 2.1:  
Exact String Matching Problem 
Given a text T=t1t2t3…tn and a pattern 
P=p1p2p3...pm, find all the i in T such that 
titi+1…ti+m-1 is equal to p1p2p3...pm . 
For example, we are given a text T =AT 
TGCCAA TGCCA CCA and a pattern P 
=TGCCA. 
T =ATTGCCAATG CCA CCA 
P =  TGCCA 
T =ATTGCCAATGCCA CCA 
P =           TGCCA 
In this case, P has two matches, location 3 
and 9. 
 
 
1.3  A brute-force algorithm 
    It is easy to design a brute-force algorithm 
to solve the exact matching problem.  Suppose 
that we are given a text of length n and a pattern 
of length m.  A brut-force algorithm compares 
all n-m+1 locations in text T which are possibly 
a match of P.  A simple brute-force algorithm is 
shown as following.  
Algorithm Brute-Force Algorithm for Exact 
String Matching 
Input: A text T = t1t2…tn and a pattern P =
p1p2p3...pm. 
Output: find all the i in T such that titi+1…ti+m-1 
is equal to p1p2p3...pm . 
 
for i = 1 to n – m + 1 do 
if  is equal to  then m 1, mjjP ,1 T
Report that P appears at position i in T; 
endif
endfor
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-393-
                                 Fig 2.5
 
An Algorithm for suffix to prefix rule is shown 
as following: 
Algorithm SuffixToPrefixRuleExactMatching 
Input: A text T of length n and a pattern P of 
length m 
Output: All occurrences of P in T
Step 1.  Let the start position of the window of 
length of m be 1. 
Step 2.  If the start position of the window is 
less than n-m+1, go to step3; 
otherwise, end this algorithm. 
Step 3.  Find the longest suffix X of the window
which is also a prefix of P and goes to 
step 4. 
Step 4.  If the length of X is m, report there is a 
match.  Go to Step 5. 
Step 5.  Let the start position of the window = 
the start position of the window + m- 
length of X.  Go to Step 2. 
This suffix to prefix rule has been used by 
several researchers to design exact string 
matching algorithms such as the Reverse Factor 
algorithm [8], the Backward Nondeterministic 
Matching algorithm [10] and the Backward 
Oracle Matching algorithm [1].  The problem is 
how to find the longest of suffix U which is 
equal to a prefix of P.       
The Reverse Factor algorithm uses 
automaton to find the longest of suffix U which 
is equal to a prefix of P.  The Backward 
Nondeterministic Matching algorithm uses 
bit-parallel to solve the problem and the 
Backward Oracle algorithm uses a data structure 
called “oracle” to solve the problem. 
 In this paper, we shall show that 
convolution can be easily used to find such a 
longest suffix U. 
 
 
3  Convolution 
Convolution is a technique widely used in 
communication [2], [4], [7], [12].  For 
application of convolution to string matching, 
consult [14]. 
Definition 3.1 Convolution in Discreet Case 
Let X= x 1 x 2…xm. and Y = y 1 y 2…yn.  Let 4  
and >  be two functions.  The convolution of 
X and Y is Z = z0, z1,…zn+m where zk =  kji 
>
xi 4 yj ,for  k=0,1…m+n. 
    To find the convolution of two strings X 
and Y, we may define 4  to be as following: 
xi 4 yj = 1 if xi = yj
xi 4 yj = 0 if xiЋyj
>  is just the addition function. 
Besides, we always find the convolution of X 
and Y  where Y  is the reverse of Y, as shown 
below: 
                
Fig3.1 
 
Then we get the result of convolution of T and P 
as shown in Fig 3.2. 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-395-
 We call the lowest column “F-vector” as 
indicated in Fig 4.2. 
             Fig 4.2 
 
If the i-th value counted from right to left of 
F-vector is exactly equal to i, we know that the 
suffix of text T of length i is also a prefix of 
pattern P.  From the example above, we can see 
that the third value of F-vector is also three as 
shown in Fig 4.3. 
 
Fig 4.3 
 
So, we know that “bac” is a suffix of T of 
length three which is also a prefix of pattern P.  
In this way, we can find out all the suffixes of T
which is also a prefix of pattern P.  Thus, we 
can also find the longest suffix of T which is also 
a prefix of pattern P by using convolution. 
 
Algorithm FindTheLongestSuffixU 
Input: A string X = x 1, x 2, x3…xm and a string Y 
=y1,y1, y3,…, ym. 
Output: The longest suffix U of X which is also a 
prefix of Yn 
Step 1. Do a convolution of X and Y and get 
F-vector.  Go to step 2. 
Step 2. Set i=1 and denote the length of U be |U|. 
Step 3. If iʳ Љʳ ̀ʿʳ˺̂ʳ̇̂ step 4. Otherwise, go to 
step5. 
Step 4. If the i-th value counted from right to left 
of F-vector is exactly equal to i, Set |U | 
= i.  Let i =i+1 and go to step3. 
Step 5. Report U =xm-|U|+1, xm-|U|+2, xm-|U|+3,…xm-1,
xm.
 
 
4.2  The Bit-Pattern Approach 
The Bit-Pattern Approach can be seen as a 
modified convolution.  The Bit-Pattern 
Approach can be used to find the longest suffix 
of text T which is also a prefix of pattern P. 
Given a string X = x1 x2 x3…xn and a character 
Ӫ, theӪ-bit pattern of X is defined as b1b2
b3…bn where bi =1 if xi =Ӫ  and bi=0 if 
otherwise. 
For example, X = bacc.  
a-bit pattern of X is 0100. 
b-bit pattern of X is 1000. 
c-bit pattern of X is 0011. 
We give an example first.  Suppose that we are 
given a text T = cbac and a pattern P = bacc. 
And the bit pattern of every character of the 
alphabet of T is shown as below: 
a-bit pattern of T is 0010. 
b-bit pattern of T is 0100. 
c-bit pattern of T is 1001. 
In the convolution of X and P is shown in Fig 
4.4.  We can observe that we can use 
bit-pattern to achieve convolution.  
              Fig 4.4 
 
    Now, we use ADD operation instead of the 
ADD operation above as shown above: 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-397-
[6] Knuth, D.E., Morris Jr, J.H., and Pratt, V.R., 
Fast pattern matching in strings, SIAM 
J.Comput., Vol. 6(1), 1977, pp. 323-350. 
[7]H. Kwakernaak and R. Sivan,Modern Signals 
and Systems,Prentice-Hall,1991. 
[8] T. Lecroq, A variation on the Boyer-Moore 
algorithm, Theoretical Computer Science, Vol. 
92(1), 119-144, 1992 
[9]Morris, J. H., Jr. and Pratt, V. R., A Linear 
Pattern-Matching Algorithm, Report 40, 
University of California, Berkeley, 1970. 
[10]G. Navarro and M. Raffinot, Fast and 
flexible string matching by combining 
bit-parallelism and suffix automata, ACM 
Journal of Experimental Algorithmics, Vol. 5(4), 
2000 
[11]R. S. and Moore, J. S. Boyer, A Fast String 
Searching Algorithm, Communication of the 
ACM, Vol. 20, 1977, pp. 762-772. 
[12]M.Selik,R.Baraniuk,Properties of 
Convolution,The Connexions Project and 
licensed under the Creative Commons 
Attribution License,2006 
[13]P.D. Smith, Experiments with a very fast 
substring search algorithm, Software—Practice 
and Experience, Vol. 21(10), 1991, 
pp.1065–1074  
[14]B.H. Wu, Convolution and Its Applications 
to Sequence Analysis, M.D., National Chi-Nan 
University, 2004 
[15]S.Wu and U.Manber, Fast text searching 
allowing errors, Communications of the ACM, 
Vol. 35(10), pp.83-91, 1992 
 
The 24th Workshop on Combinatorial Mathematics and Computation Theory
-399-
right most location of x  in )1,1( −mP .  If it 
is located in location d  in P , we move 
1+− dm  steps.  If x  does not appear in P , 
we move m  steps.  Thus, for our case, 
if a=x , we can move P  4 steps to the right 
and if g=x , we can move P  one step to the 
right and if c=x , we move 5 steps to the right. 
The following shows how the Horspool 
algorithm works. 
 
Let 
 
 
Step 1 
*
a g a g a a g c t a g g g a
1 2 3 4 5 6 7 8 9 10 11 12 13 14
T =
P = a g g g a
1 2 3 4 5
x
 
Step 2 
*
a g a g a a g c t a g g g a
1 2 3 4 5 6 7 8 9 10 11 12 13 14
T =
P = a g g g a
1 2 3 4 5
x
 
Step 3 
*
a g a g a a g c t a g g g a
1 2 3 4 5 6 7 8 9 10 11 12 13 14
T =
P = a g g g a
1 2 3 4 5
 
Here we found a match. 
 
There are two other algorithms, namely Raita 
algorithm and Nebel algorithm, which use the 
single character rule.  In both algorithms, the 
last character in the window is used.  But they 
have different ways to match a character in T  
with a character in P .  Horspool algorithm 
scans the pattern from right to left.  In the Raita 
algorithm, we first compare the last character in 
pattern, then the first and finally the middle one.  
The Nebel algorithm scans the pattern from the 
least frequent character to the most frequent one. 
 
 
3.  Our Algorithm 
 
Our algorithm is also based upon the single 
character matching rule.  Consider the case 
where we are using a window to match the 
pattern P .  Suppose we select an i and the 
character matched with ip  is x .  In P , the 
right most location of x before ip is j .  Then 
the number of steps which we can move P  
safely, if we have to do so, is ),( ixShift  which 
is equal to 1+− ji .  Let the alphabet set of P  
be A .  Then the average number of steps which 
can be moved if location i  is used is 
      
A
ixShift
iMV Ax
∑
∈=
),(
)( . 
We calculate )(iMV  for mi ≤≤1  and we 
choose the i  with the largest )(iMV .  Consider 
P  = aacatgggtattgatcttg. For 19=i  we 
have 5)19,a( =Shift , 6)19,g( =Shift  , 
1)19,t( =Shift  , 3)19,c( =Shift .  Thus,  
( ) 75.3
4
3165)19( =+++=MV  .  It can also be seen 
that 75.4
4
19)16( ==MV . To find the largest )(iMV , 
we perform a linear scan of P .  Let 
caaaA ,,, 21 K=  be the set of alphabets.  We 
define )( ji ad  as follows: If ja  appears 
before 1+ip , )( ji ad  is the right most location 
of ja  before location )1( +i ; otherwise, 
0)( =ji ad .  Thus, for every i , we have a 
( ))(),(),( 21 ciiii adadadV L= .  However, when 
we compute 1+iV , we only have to change one 
element of iV .  That is, we only change 
)( 11 ++ ii pd  to be 1+i .  Once we get the iV  
vector, we know that the nearest ja  to the left 
of location 1+i  has )(1 ji adi −+ positions.  
For each i , we compute  
 ∑
=
−+=
c
j
ji adiiMV
1
)(1)( .  
 
We only remember the iV with the 
largest )(iMV .  Suppose the best i  is found, 
let 1+= iib  .  Let )( xShift , with one 
parameter, be a vector who stores the distance 
between the character x  and bip , where 
Ax ∈  , x is right most and before bip .  
We then calculate  )(xShift  as follows: 
 =)( xShift ( )xdi bib −+1 , Ax∈ . 
In the searching phase, in each search window, 
we first compare 
bip  with the corresponding 
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-233-
The searching is done as follows: 
 
Step 1 
 
Shift(t) is 5. We move P 5 positions. 
 
Step 2 
 
Shift(g) is 1. We move P 1 positions. 
 
Step 3 
 
Here we found a match. Shift(c) is 5.  We 
move P 5 positions.  Out of range, searching 
phase is terminated. 
 
 
4.  Experimental Results 
 
We performed experiments on a DNA 
sequence with size 36436 and used it as the text 
string T .  We repeatedly randomly took a 
substring from a DNA and used it as the pattern 
string P .  We used six different lengths of P .  
For each length, we randomly extracted a 
substring with such length twenty times.  That 
is, for each length, twenty sP'  were generated.  
The Horspool algorithm and our algorithm were 
tested on all of the data.  We recorded the 
average number of character comparisons in the 
searching phase for both algorithms and the 
result is shown in the following chart.  It can be 
seen that our algorithm needs much smaller 
number of character comparisons than that need 
by the Horspool algorithm. 
 
  
Fig 3: The average number of character 
comparisons in searching phase for Horspool 
and our algorithm, text length 36436, pattern 
length 10, 15, 20, 25, 30, 25. 
 
 
5.  Concluding Remarks and Future 
Research 
 
We have proposed a rule to select an 
appropriate character so that the single character 
approach can become efficient.  Experimental 
results show that our algorithm performs better 
than the Horspool algorithm. We believe that our 
idea can be used to solve approximate string 
matching problems [3, 14, 18, 19, 20, 24, 25, 29, 
33, 35, 36]. 
 
 
References 
 
[1] A. V. Aho. Algorithms for finding 
patterns in strings. Handbook of 
Theoretical Computer Science, Volume 
A, Algorithms and complexity, 1990, 
pp. 255-300. 
[2] A. Apostolico and M. Crochemore. 
Optimal canonization of all substrings 
of a string. Information and 
Computation, Vol. 95, No. 1, 1991, pp. 
76-95. 
[3] A. Amir, D. Keselman, G. M. Landau, 
M. Lewenstein, N. Lewenstein and M. 
Rodeh. Text indexing and dictionary 
matching with one error. Journal of 
Algorithms, Vol. 37, 2000, pp. 309-325.
[4] R. A. Baeza-yates and M. Régnier. 
Average running time of the Boyer- 
Moore-Horspool algorithm. Theoretical 
Computer Science, Vol. 92, No. 1, 1992, 
pp. 19-31. 
[5] D. Beauquier, J. Berstel and P. 
Chrétienne. Éléments d'algorithmique. 
1992, Chapter 10, pp. 337-377, 
Masson, Paris. 
[6] R. A. Baeza-yates and G. H. Gonnet. 
A new approach to text searching. 
Communication of the ACM, Vol. 35, 
No. 10, 1992, pp. 74-82. 
[7] R. S. Boyer and J. S. Moore. A fast 
string searching algorithm. 
Communications of the ACM, Vol. 20, 
1977, pp. 762-772. 
[8] T. Berry and S. Ravindran. A fast string 
matching algorithm and experimental 
results. Proceedings of the Prague 
Stringology Club Workshop`99, 1999, 
pp. 16-26. 
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-235-
[36] W. Sun and U. Manber. Fast text 
searching: allowing errors. 
Communications of the ACM, Vol. 35, 
1992, pp. 83-91. 
[37] R. F. Zhu and T. Takaoka. On 
improving the average case of the 
Boyer-Moore string matching 
algorithm. Journal of Information 
Processing, Vol. 10, No. 3, 1987, pp. 
173-177. 
 
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-237-
  
Our approach is based upon the following 
lemmas: 
 
Lemma 2  If kPNSN
Cc
c
i
kmc   ))()((
1
>−∑
∈ −
, then 
kPSED ix >),(  for kmxkm +≤≤−     . 
 
Proof. Since 1Cc∈ , by definition, 
)()( PNSN c
i
kmc >− .  Consider the substrings 
i
kmS 1+− , 
i
kmS 2+− , …, 
i
kmS + . We have >)( ixc SN  
)()( PNSN c
i
kmc >−  if kmxkm +≤≤−  
because i kmS −  is a prefix of the substring ixS .  
By assumption, kPNSN
Cc
c
i
kmc   ))()((
1
>−∑
∈ −
.  
Then ∑∑
∈ −∈
−>−
11
)(())()((
Cc
i
kmc
Cc
c
i
xc SNPNSN  
kPNc >))( , for kmxkm +≤≤− . Thus, 
kPNSN
Cc
c
i
xc >−∑∈ 1 ))()(( .  That is, we need at 
least 1+k  operations of insertion on P  to 
transform P  into ixS , for kmxkm +≤≤− .  
Thus kPSED ix >),( , for kmxkm +≤≤− . 
The following lemma can be proved by using 
similar reasoning. 
 
Lemma 3  If kSNPN
Cc
i
kmcc   ))()((
2
>−∑
∈ +
, then 
kPSED ix >),(  for kmxkm +≤≤− . 
 
Theorem 1  If kPNSN
Cc
c
i
kmc   ))()((
1
>−∑
∈ −
 or 
kSNPN
Cc
i
kmcc   ))()((
2
>−∑
∈
+ , we can eliminate 
position i  of T .  That is, we prune all 
substrings ixS , for 0>x  out of consideration. 
 
Example: 
Let ""ecfdccabfaP= , ggdegacgegfaaaebfaT "=  
"egffadfbfgdgecgagbgabe , 2=k  and  ,{a=Σ   
} , , , , , gfedcb . We first compute the values 
2)( =PNa , 1)( =PNb , 3)( =PNc , 
1)( =PNd , 1)( =PNe , 2)( =PN f , 
0)( =PN g .  We can eliminate all positions of 
T  except  Position 3 because only Position 3 
of T  does not satisfy the conditions in 
Theorem 1.  For example, consider 5=i .  
""512
5 egaaebfaacgdSS km ==+ .  We have 
4)( 5 =+kma SN , 1)( 5 =+kmb SN , 1)( 5 =+kmc SN , 
1)( 5 =+kmd SN , 2)( 5 =+kme SN , 1)( 5 =+kmf SN , 
and 2)( 5 =+kmg SN .  Thus, we have 
)()( 5 kmcc SNPN +>  and )()( 5 kmff SNPN +> .  
))()(())()(( 5
or  
kmcc
fcx
i
kmxx SNPNSNPN += +
−=−∑  
kSNPN kmff >=−+−=−+ + 31)(21)(3))()(( 5 .  
Therefore, Position 5 can be eliminated. 
Based on Theorem 1, we present an algorithm 
to solve the approximate string matching 
problem. 
 
I. Preprocessing Phase 
In the preprocessing phase, we use an array 
)(cNumP  to record the number of character c  
in P , )(PNc , Σ∈∀c .  This can be done by 
a linear scan of P . 
 
II. Searching Phase 
For a position i  of T , we first examine 
whether the position i  satisfies any one of the 
conditions in Theorem 1.  If it does, we would 
not check all the substrings ixS , 0>x ;  
otherwise, we check the substrings ixS , 
kmxkm +≤≤− , by the dynamic 
programming method.  Note that we only have 
to compute the edit distance between 
)1,( k-miiT ++  and ),1( mP . 
 
 
 
 
 
 
 
 
 
 
 
 
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-239-
  
tackle the exact string matching problem.  We 
have already done some experiments and it 
seems that our idea is very good for natural 
language data. 
 
References 
 
[1] Amir, A., Keselman, D., Landau, G. M., 
Lewenstein, M., Lewenstein, N. and Rodeh, 
M., Text Indexing and Dictionary Matching 
with One Error, Journal of Algorithms, Vol. 
37, 2000, pp.309-325. 
[2] Fredriksson, K., Navarro, G., 
Average-Optimal Multiple Approximate 
String Matching, ACM Journal of 
Experimental Algorithmics, Vol. 9, No. 1.4, 
2004, pp.1-47. 
[3] Hyyrö, H., Bit-parallel approximate string 
matching algorithms with transposition, 
Journal of Discrete Algorithms, Vol. 3, 2005, 
pp.215-229. 
[4] Huynh, T. N. D., Hon, W. K., Lam, T. W. 
and Sung, W. K., Approximate String 
Matching Using Compressed Suffix Arrays, 
Theoretical Computer Science, Vol. 352, 
2006, pp.240-249. 
[5] Holub, J., Melichar, B., Approximate string 
matching using factor automata, Theoretical 
Computer Science, Vol. 249, 2000, 
pp.305-311. 
[6] Hyyrö, H. and Navarro, G., Bit-parallel 
Witnesses and their Applications to 
Approximate String Matching, Algorithmica, 
Vol. 41, No. 3, 2005, pp.203-231. 
[7] Landau, G. and Vishkin, U., Fast Parallel 
and Serial Approximate String Matching, 
Journal of Algorithms, Vol. 10, 1989, 
pp.157-169. 
[8] Navarro, G. and Baeza-Yates, R., Very fast 
and simple approximate string matching, 
Information Processing Letters, Vol. 72, 
1999, pp.65-70. 
[9] Navarro, G. and Baeza-Yates, R., A Hybrid 
Indexing Method for Approximate String 
Matching, Journal of Discrete Algorithms, 
Vol.1, No.1, 2000, pp.205-239. 
[10] Needleman, S. B. and Wunsch, C. D., A 
general method applicable to the search for 
similarities in the aminoacid sequence of 
two proteins, Journal of Molecular Biology, 
Vol. 48, 1970, pp.443-453. 
[11] Sellers, P. H., String Matching with Errors, 
Journal of Algorithms, Vol. 20, No. 1, 1980, 
pp.359-373. 
[12] Tarhio, J. and Ukkonen, E., Approximate 
Boyer-Moore String Matching, SIAM 
Journal on Computing, Vol. 22, No. 2, 1993, 
pp.243-260. 
[13] Wu, S. and Manber, U., Fast Text Searching: 
Allowing Errors, Communications of the 
ACM, Vol. 35, 1992, pp.83-91. 
 
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-241-
2focus on algorithms to find the edit distance 
between two strings, and many of them [1, 3, 4, 6, 
7, 10, 11, 12, 14, 15, and 16] use the following 
rule: Consider the two strings 21 AAA   and 
21BBB  , if 22 BA   and kBAED ),( 11  , then 
kBAED ),(  .
There are two approaches to solve the 
approximate string matching problem. The first 
approach [12, 2, 10, 11 and 15] is a local approach 
which computes ),( SPED  where S  is a 
substring of T  starting from each location i .
That is, for every possible position i , we test 
whether there exists a substring S  of T
starting from this location such that kSPED ),( .
Another approach [16], named Approach 2, is a 
global approach which can solve the problem in 
O( 
	




w
mnk ) time-complexity where w  is the word 
size. We shall use the technique in [16] to solve 
the problem. 
In the above, we only talked about one case.  
In the following, we give the precise definition of 
1S  and 2S  for all cases.  
Case 1: We find even approximate palindromes. If 
 21 ni  , let 1S  be ),1( iT  and 2S  be 
}),2min{,1( nkiiT  ; otherwise, let 1S  be 
)},1,12(max{ ikniT   and 2S  be 
),2( niT  .
Case 2:  We find odd approximate palindromes. 
If  21 ni  , let 1S  be ),1( iT  and 2S  be 
}),12min{,2( nkiiT  ; otherwise, let 1S  be 
)},1,22(max{ ikniT   and 2S  be 
),2( niT  .
Essentially, for each location i  in T , we 
compute the edit distance between 1S  and 2S .
Given two strings ,'211 mpppS 
'212 ntttS   and k , we define 
'.0and'0where
,
.otherwise,0
)),1(),,1((if,1
),( 21
mjni
kiSjSED
jiM k



 

     
We now use dynamic approach to find ),( jiM k .
Let ),( jiM kI , ),( jiM
k
D  and ),( jiM
k
S  denote 
the ),( jiM k  related to insertion, deletion and 
substitution respectively, where 










.otherwise,0
1)1,1(andor
1),1(,if,1
),(
1
jiMpt
jiMpt
jiM kji
k
ji
k
I ,










.otherwise,0
1)1,1(andor
1)1,(,if,1
),(
1
jiMpt
jiMpt
jiM kji
k
ji
k
D
and










.otherwise,0
1)1,1(andor
1)1,1(andif,1
),(
1
jiMpt
jiMpt
jiM kji
k
ji
k
S
After every ),( jiM kI , ),( jiM
k
D  and 
),( jiM kS  are found, we can determine ),( jiM
k
by ),( jiM k = ),( jiM kI or ),( jiM
k
D or ),( jiM
k
S
where “or” is the “logical or” operation . 
Our algorithm is presented in the following: 
Input: A string ....21 ntttT   and k.
Output: All occurrences of approximate palindromes 
of T with error 'k .
for i=1 to n do
    for kk  '0  do  
     for ''0''0 mjandni   do 
     








otherwise0
''0if,1)0,'(
''0if,1)',0(
)','( '
'
' kiiM
kjjM
jiM k
k
k
      )','(' jiM k )','(' jiM kI or )','(
' jiM kD    
                     or )','(' jiM kS ;
         end for 
    end for 
end for 
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-243-
4443-453.
[13] Porto, A. H. L and Barbosa, V. C., 
Finding approximate palindromes in 
strings, Pattern Recognition, Vol.35, 
2002, pp. 2581-2591.
[14] Sellers, P. H., String Matching with 
Errors, Journal of Algorithms, Vol. 20, 
No. 1, 1980, pp. 359-373. 
[15] Tarhio, J. and Ukkonen, E., Approximate 
Boyer-Moore String Matching, SIAM 
Journal on Computing, Vol. 22, No. 2, 
1993, pp. 243-260.
[16] Wu, S. and Manber, U., Fast Text 
Searching: Allowing Errors, 
Communications of the ACM, Vol. 35, 
1992, pp. 83-91.
   
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-245-
 xxdxdxdP ken L21=′ .  For example, for 
drccdstaacceeP =' , ccccPen 45=′ . 
 We now use the same method to encode 
T .  Let aactcgacgctcactacgactT =  and 
actacgactP =  .  We select t  which has the 
smallest frequency in P .  Then ttPen 5=′ .  
T  is coded as enT ′  by using the same coding 
method.  Thus we obtain ttttTen 625=′ . 
To give the reader some feeling about our 
algorithm, consider the following text T : 
“Under the wide and starry sky, dig the grave 
and let me lie.  Home is the sailor, home from 
sea, and the hunter from the hill.”  Suppose the 
pattern P  is “Home is the sailor”.  Let us 
assume that we select the character “ i ”.  Then 
iiPen 6=′  and iiiiiiTen 36661816=′ .  We can 
now easily see that enP′  exists in enT ′ . 
 
 
Section 3. Matching and Examination 
 
3.1 Matching Phase 
After T and P  have been encoded to 
enT ′  and enP′ , we have to check whether enP′  occurs in enT ′  or not.  Thus this is an exact 
string matching problem.  Any exact string 
matching algorithm  [1, 2, 3, 4, 5, 6, 7, 8, R92, 
9, 10, 11 and 12] can be used.  But, since both 
text and pattern strings are much simplified, we 
recommend to use the quick search algorithm 
[S90].  We just show describe the outline here. 
Suppose that P  is aligned to a window 
of T as shown in Fig. 3-1 below.  We  
perform a pair-wise comparing between text T  
and pattern P  from left to right. Assume that 
the first mismatch occurs when comparing 
1−+ist  with ip .  As shown, the character next 
to the last character of the window is x  and 
assume that x  appears in location j  of P . 
We can shift the pattern )( jm −  positions to 
the right  as shown in Fig.3-2.  If . x  does 
not appear in P , we move 1+m  steps to the 
right. 
 
 
   Fig. 3-1 
    Fig. 3-2  
 
Example 1: Let 
abbccccabbababcccabbT = and ccabbabP = .  
We select the character “ a ” for our encoding.  
We select the substring abbaP =′ , and we 
have aaPen 2=′ .  Then, we encode T , 
aaaaaTen 6241=′ . 
aaP
aaaaaT
en
en
2
6241
=′
=′
 
Mismatch occurs, slides enP′  4 steps. 
aaP
aaaaaT
en
en
2         
6241
=′
=′
 
Match occurs, record position 5 and slides enP′  
4 steps. Terminate the matching phase. 
 
Example 2: Let 
attaatcaaaaaaaaatcacT =  and 
tcaatcatctaaP = .  Assume that we select 
character “ c ”, then we obtain cccTen 61=′  and 
cccPen 42=′ .  Now we can easily see that enP′  
doesn’t exist in enT ′ . In such situation, we do not 
need to examine. 
 
 
3.2 Examination Phase 
 
If enP′  exactly matches starting at 
position i  of enT ′ , we need to know the 
corresponding position of T  which 
should be examined.  Let q  denote 
most left side position of x  in P , 
r denote most left side position of x  in 
T .  We define a function )(iPos  to 
calculate the corresponding position of 
T  while enP′  matches at position i  of 
enT ′ .  We define )(iPos  as following:  
number. a is )( if ,
character. a is )( if ,
)(
1
))(( where
   ,))(()(
xT
xT
xT
xTf
xTfiPos
en
en
en
en
ix
en
′
′
⎩⎨
⎧
′=′
′= ∑
≤
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-247-
 encode enP′  and enT ′ , where the number 
of x  in T  is α  and the number of x  
in P  is β .  The number of numerals 
in enT ′  is at most 1−α , and that in enP′  
is at most 1−β .  Thus 
12)1( −=−+≤′ αααenT  and  
12)1( −=−+≤′ βββenP .  By definition, 
Σ≥α  T  and Σ≥ β  P .  Therefore, we 
have Σ=Σ≅Σ
−≤′ 2212  α
α
α
α
T
Ten  and 
Σ=Σ≅Σ
−≤′ 2212  β
β
β
β
P
Pen .  This analysis 
shows that our compression scheme is quite 
effective. For the DNA type data, both text and 
pattern are compressed to half of their sizes.  If 
the data are English language sentences, both 
text and pattern will be compressed to roughly 
15% of their original sizes. 
 
 
Section 6. Experiments 
 
We wrote a program to implement our 
encoding method.  In our experiments, we 
recorded the ratio of the size of the compressed 
data and that of the original data.  Each result is 
the average of 100 experiments with different 
P ’s and T ’s. 
 
Experiment 1: Natural Language 
Data 
We randomly selected a part of an English 
article with length 5000 to be text T , and a part 
of it with length 10, 20, 30 and 40 to be pattern 
P .  The results are shown in Table 6-1. 
 
Table 6-1 
ration compressio:ℜ  
 
Experiment 2: DNA Type Data 
We randomly selected a part of a DNA 
sequence with length 5000 to be text T , and a 
part of it with length 10, 20, 30 and 40 to be 
pattern P .  The results are shown in Table 6-2.
  
   Table 6-2 
P T enP ′ enT ′  ℜ of P  ℜ ofT
10 5000 3.4 2377 34% 47.54%
20 5000 4.3 2048.9 21.5% 40.98%
30 5000 7.4 2246.8 24.67% 44.94%
40 5000 11 2310.4 27.5% 46.21%
ration compressio:ℜ  
 
Section 7. Conclusion Remarks 
 
In this paper, we have proposed an 
encoding approach to compress pattern and text. 
The experiment shows that our algorithm is quite 
efficient. Further more, we plan to analyze the 
time complexity in average case. In the future, 
we also try to solve approximate string matching 
problem by using our approach.  
 
 
Reference 
 
[1] Algorithms for finding patterns in 
strings, Aho, A. V., in Handbook of 
Theoretical Computer Science, 
Volume A, Algorithms and complexity, 
1990, pp. 255-300. 
 
[2] Éléments d'algorithmique, Beauquier, 
D., Berstel, J. and Chrétienne, P., 
1992, Chapter 10, pp. 337-377, 
Masson, Paris. 
[3] A new approach to text searching, 
Baeza-yates, R. A. and Gonnet, G. H., 
Communication of the ACM, Vol. 35, 
No. 10, 1992, pp. 74-82. 
[4] A fast string search algorithm, Boyer, 
R. S. and Moore, J. S., Comm. ACM, 
20, 1977, pp. 762–772. 
[BR92] Average running time of the 
Boyer-Moore-Horspool algorithm, 
P  T  enP′  enT ′  ℜ ofT  ℜ of P
10 5000 3.2 961.3 19.23% 32% 
20 5000 3.3 775.2 15.5% 16.5% 
30 5000 3.4 722.3 14.45% 11.33%
40 5000 3.6 737.3 14.75% 9% 
The 25th Workshop on Combinatorial Mathematics and Computation Theory
-249-
