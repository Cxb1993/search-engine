 2
一、中英文摘要 
在過去的十多年來，後設經驗法則演算法在解決困難的最佳化問題上已經展現了強
大的計算能力，而這些問題正是傳統最佳化方法及數學規劃方法不適用的對象。許多影像
處理的基本工作，例如影像量化、切割、及疊合，也是非常耗費計算量才能求得最佳解，
所以研究者開始尋找替代的計算方案，例如後設經驗法則演算法。我們的初步調查研究顯
示，大部份使用後設經驗法則演算法的影像處理應用選擇基因演算法做為它們的主要求解
工具。然而，自 1990 年以來，許多新的後設經驗法則演算法陸續發展出來，例如螞蟻族
群最佳化、粒子群最佳化、禁制搜尋法、以及散佈搜尋法。許多應用實例展現這些方法在
某些領域可以比基因演算法更加精確且有效率。 
此多年期專題計畫已完成一個可呼叫式的程式庫，包含這些新後設經驗法則已標準
化的處理單元，以利實作相關的演算法。對於每一個影像處理工作，探尋各種可能的後設
經驗法則演算法應用模式，進行深入的評估及分析，包括精確度評估、效能評估、收斂分
析、以及最差例分析等。此多年期專題計畫已產出多篇高品質的研究論文，並提供有價值
的程式庫及資料集給產學界應用。 
 
關鍵字 影像處理、後設經驗法則演算法、螞蟻族群最佳化、粒子群最佳化、禁制搜尋
法、散佈搜尋法 
 
Abstract 
In the last decade, metaheuristics have shown their powerful computational ability in 
solving complex optimization problems to which the traditional optimization techniques and the 
mathematical programming approaches are ill-suited. Many fundamental tasks in Image 
Processing (IP), for example, image quantization, segmentation, and registration, are also 
computationally intensive to obtain the optimal solutions and the researchers seek to find other 
alternatives such as metaheuristics. We have made a preliminary survey which reveals that most 
metaheuristic-based IP applications chose genetic algorithms (GA) as their main approach. 
However, since 1990’s new metaheuristics, namely the ant colony optimization, particle swarm 
optimization, tabu search, and scatter search, have been introduced and many applications 
manifested that these methods could be more effective and efficient than GA in some domains.  
During this multi-year project, we have built up a callable library containing standardized 
components of metaheuristics that can be used to implement the IP applications. For each image 
processing task, various applications using metaheuristics have been exploited. In-depth 
evaluations and analyses including effectiveness evaluation, efficiency evaluation, convergence 
analysis, and worst-case analysis, have also been conducted. With this project, we have written 
quality research papers and provided a valuable callable library and datasets to the academic and 
industrial communities. 
 
Keywords: Image processing, metaheuristic, ant colony optimization, particle swarm 
optimization, tabu search, scatter search. 
 
二、計畫緣由與目的 
It has been a challenging problem to derive optimal solutions in many fundamental tasks 
conducted in Image Processing (IP) field such as color quantization, multilevel thresholding, 
polygonal approximation, image registration, just to name a few. The main reason is that these 
tasks deal with digital images with discrete (discontinuous) pixels whose gray level distributions 
 4
 
三、研究方法 
3.1 Identification of IP tasks 
We have chosen four prominent IP tasks for testing in this study. The formulations of these 
tasks are described as follows. 
 
Multilevel thresholding problem (MTP) 
 Let the gray levels of a given image range over [0, L-1] and h i( )  denote the occurrence of 
gray level i. Let N h i
i
L
=
=
−∑ ( )
0
1
, P h i
Ni
=
( ) , for 0 1≤ ≤ −i L . The purpose of MTP is to search the 
gray level thresholds such that the thresholded image optimizes an objective function. We present 
two broadly used objective functions as follows. 
z Bi-level Kapur objective function 
 maximize f t H H( ) = +0 1 , 
where 
 ω 0
0
1
=
=
−∑ Pi
i
t
,  H
P Pi i
i
t
0
0 00
1
= −
=
−∑
ω ω
ln ,  
 ω 1
1
=
=
−∑ Pi
i t
L
,  H
P Pi i
i t
L
1
1 1
1
= −
=
−∑ω ωln ,  
and the optimal threshold is the gray level that maximizes objective function f t( ) . 
z Bi-level Otsu objective function 
 maximize f t( ) ( )= −ω ω µ µ0 1 0 1 2 , 
where 
 ω 0
0
1
=
=
−∑ Pi
i
t
, µ
ω0 00
1
=
=
−∑ i Pi
i
t
, 
 ω 1
1
=
=
−∑ Pi
i t
L
, µ
ω1 1
1
=
=
−∑ i Pi
i t
L
, 
and the optimal threshold is the gray level that maximizes objective function f t( ) . 
 Assume that we want to search c  optimal thresholds [ , ,..., ]t t tc1 2 , both of Kapur and Otsu 
methods must exhaustively search all possible values of [ , ,..., ]t t tc1 2 . This will result in a 
complexity of O Lc( )  which grows exponentially with the number of thresholds.  
 
Polygonal approximation problem (PAP) 
 Given a digital curve represented by a set of N points, S = {x0, x1, ..., xN-1} where x(i+1)  mod N 
is considered as the succeeding point of xi. We define arc xixj as the collection of those points 
 6
Nevertheless, the ideal transformation usually does not hold under many real situations such as 
the existence of missing and spurious points and the distortion of patterns, resulting in a 
registration error. Two error dissimilarity measures between two aligning point patterns are 
broadly used in the literature to assess the quality of the registration result. 
z Agrawal’s Heuristic Dissimilarity (AHD) Measure          Let Ω  be the set of point 
correspondences between the two patterns with ( )mn,min≤Ω . The registration error of Ω  
with respect to transformation T can be evaluated using the integral squared error defined as 
 
( )∑ Ω∈ −= ji ba ji baT,
22 )(ε  
where •  indicates the vector length in the Euclidean space. Agrawal et al. (1994) proposed 
an overall registration dissimilarity measure as  
 ( )



=Ω∞
≥Ω







−Ω
−




−Ω
−
+
Ω=
2 ,1 ,0                                             
  3
2
2log
2
21
, 2
2 mm
sBAAHD
ε  
The AHD measure is normalized with the scale factor s and includes a penalty term for the 
unregistered points in the searched pattern. 
z Partial Hausdorff Distance (PHD)        Huttenlocher et al. (1993) used the directed 
partial Hausdorff distance from A to B as 
 
( ) jiBbth Aak baTKBADPHD ji −= ∈∈ )(min,  
where Kth returns the kth smallest value of 
jiBb
baT
j
−
∈
)(min  for all Aai ∈ . The directed partial 
Hausdorff distance from B to A can be analogously defined as 
 
( ) )(min, ijAath Bbk aTbKABDPHD ij −= ∈∈   
Finally, the partial Hausdorff distance from both patterns is given by 
 ( ) ( ) ( )( )ABDPHDBADPHDBAPHD kkk ,  ,,max, =   
In contrast to AHD, the PHD measure only takes into account the registered points such that 
the situation of incomplete registration can be accommodated.  
 
Relevance feedback (RF) 
Due to the rapid development in computer and network technologies, the volumes of 
modern image repositories have been overwhelming. In this context, traditional image retrieval 
based on textual indexing is laborious, thus inviting the implementation of content-based image 
retrieval (CBIR). Relevance feedback (RF) is an iterative procedure which refines the 
content-based retrievals by utilizing the user’s relevance feedback marked on retrieved results. 
Fig. 1 depicts the flow diagram of our system. The user starts a new query session by submitting 
a query image sample Q(0), the number in the parenthesis indicates the number of feedback  
 8
belonging to the same cluster would be processed using the same RF model. The determination of 
the number of clusters is a tradeoff between retrieval precision and computational efficiency. The 
larger this number, the higher the final retrieval precision is, while inducing a greater number of 
iterations to train well the model base. We have found empirically that the precision improvement 
is negligible when the number of clusters/models exceeds one tenth of the database size but that 
entails increase in training time.  
For the given query Q(0), the closest query cluster in the model base is identified according 
to equation (2), and the corresponding RF model with parameter values (α, β, γ and wi, i = 1, 
2, …, r) are retrieved for formulating this query. These parameter values are optimally tuned by 
the metaheuristic algorithm through the relevance feedback iterations as noted in the next 
subsection. Upon termination of the relevance feedback procedure, the final best RF parameter 
values are employed to update the closest cluster of Q(t) in the model base. 
Now we describe the optimization of RF parameter values and the query reformulation. The 
index t of feedback iteration starts with 0 and is increased by one every time an iteration of 
feedback is performed. Let us denote the query and the RF model parameters derived at feedback 
iteration t by Q(t), α(t), β(t), γ(t) and wi(t), respectively. We differentiate the processes for t = 0 
and t > 0 and describe them separately as follows. 
For the iteration with t = 0, the initial query Q(0) is reformulated according to the retrieved 
RF model parameters and is then used for similarity matching. After all the database images have 
been compared with Q(0), the final list Σ(0) of the top v most similar images is returned for the 
user’s inspection. If the user is satisfied with Σ(0), the session is terminated directly without 
performing the model cluster update because there is no user’s feedback and the RF parameter 
values were not changed. Otherwise, the user activates a new relevance feedback iteration (t = t + 
1) by marking relevant and irrelevant images in Σ(0). 
Now we describe the operations performed in the feedback iterations with t > 0. Let us 
assume the particle swarm optimization (PSO) is adopted as the metaheuristic algorithm. The 
PSO optimization mechanism is initialized when t = 1, and a swarm of S particles are created. 
Instead of creating the particles at random, the particles are initialized by taking the RF model 
parameter values (α(0), β(0), γ(0), w1(0), w2(0), …, wr(0)) to expedite the optimizing speed. Let 
us denote the initial swarm by (αi(0), βi(0), γi(0), ( )01iw , ( )02iw , …, ( )0irw ), i = 1, 2, …, S. These 
particles are then modified using the particle movement formulas, and the new positions of the S 
particles are obtained (note that the relevance weights should again be normalized after the 
modification). The general form for the particle update at feedback iteration t can be described by 
(αi(t), βi(t), γi(t), ( )twi1 , ( )twi2 ,…, ( )twir ) ← (αi(t-1), βi(t-1), γi(t-1), ( )11 −twi , ( )12 −twi , …, ( )1−twir ), 
i = 1, 2, …, S.  
At the PSO-based query reformulation stage, S queries are produced (i.e., the query Q(0) is 
 10
be updated can be replaced by a linear combination of the old entry values and the optimal query 
Q* and the RF model parameters contained in gbest.  
 
3.2 Identification of metaheuristics  
We have identified the functional components of various metaheuristics such as genetic 
algorithm (GA), simulated annealing (SA), particle swarm optimization (PSO), scatter search 
(SS), ant colony optimization (ACO), and tabu search (TS). In the following, we present some of 
them for illustration. 
 
Particle Swarm Optimization 
Particle swarm optimization (PSO) is a new evolutionary algorithm proposed in [3]. PSO is 
bio-inspired and it models the social dynamics of bird flocking. A large number of birds flock 
synchronously, change direction suddenly, scatter and regroup iteratively, and finally perch on a 
target. This form of social intelligence not only increases the success rate for food foraging but 
also expedites the process. The PSO algorithm facilitates simple rules simulating bird flocking 
and serves as an optimizer for continuous nonlinear functions. The general principles of the PSO 
algorithm can be outlined in the following features. 
z Particle representation   The particle in the PSO is a candidate solution to the underlying 
problem and move iteratively and objectively in the solution space. The particle is 
represented as a real-valued vector rendering an instance of all parameters that characterize 
the optimization problem. We denote the ith particle by ( ) dTidiii RpppP ∈= ,...,, 21 , where d is the 
number of parameters. 
z Swarm   The PSO explores the solution space by flying a number of particles, called 
swarm. The initial swarm is generated at random and the size of swarm is usually kept 
constant through iterations. At each iteration, the swarm of particles search for target optimal 
solution by referring to previous experiences. 
z Personal best experience and swarm’s best experience   The PSO enriches the swarm 
intelligence by storing the best positions visited so far by every particle. In particular, 
particle i remembers the best position among those it has visited, referred to as pbesti, and 
the best position by its neighbors. There are two versions for keeping the neighbors’ best 
position, namely lbest and gbest. In the local version, each particle keeps track of the best 
position lbest attained by its local neighboring particles. For the global version, the best 
position gbest is determined by any particles in the entire swarm. Hence, the gbest model is 
a special case of the lbest model. It has been shown that the local version is often better, 
particularly the one using random topology neighborhood where each particle generates L 
links at random after each iteration if there has been no improvement i.e. if the best solution 
 12
the reference set for inclusion as new members. A simple option to update the reference set is 
to include the best solution as the first member and then select the remaining members 
according to their solution quality relative to the objective value. However, the next solution 
to be selected must satisfy the minimum diversity criterion requesting that the minimum 
distance between this solution and the members currently in the reference set is greater than a 
specified threshold.  
z Subset generation method     Subsets from the reference set are successively generated as 
a basis for creating combined solutions. The simplest implementation is to generate all 
2-element subsets consisting of exactly two reference solutions. It has been empirically 
shown that the subset generation method employing 2-element subsets can be quite effective, 
though systematic procedures for generating key subsets consisting of larger numbers of 
elements invite further investigation. 
z Solution combination method     Each subset produced by the subset generation method is 
used to create one or more combined solutions. The combination method for solutions 
represented by continuous variables employs linear combinations of subset elements, not 
restricted to convex combinations. The weights are systematically varied each time a 
combined solution is generated.  
 
Ant colony optimization 
 The general principles for the Ant colony optimization (ACO) [2] simulation of real ant 
behavior are as follows. 
z Initialization. The initialization of the ACO includes two parts: the problem graph 
representation and the initial ant distribution. First, the underlying problem should be 
represented in terms of a graph, G = <N, E>, where N denotes the set of nodes, and E the set of 
edges. The graph is connected, but not necessarily complete, such that the feasible solutions to 
the original problem correspond to paths on the graph which satisfy problem-domain 
constraints. Second, a number of ants are arbitrarily placed on the nodes chosen randomly. 
Then each of the distributed ants will perform a tour on the graph by constructing a path 
according to the node transition rule described next. 
z Node transition rule.  The ants move from node to node based on a node transition rule. 
According to the problem-domain constraints, some nodes could be marked as inaccessible for 
a walking ant. For example, in the traveling salesman problem, we can mark the nodes which 
an ant has visited as inaccessible to let the ant visit every node of the graph in finite steps. The 
node transition rule is probabilistic. For the kth ant on node i, the selection of the next node j to 
follow is according to the node transition probability, 
 14
number of running cycles, the CPU time limit, or the maximal number of cycles between two 
improvements of the global best solution. 
 
Tabu search 
Tabu search (TS) is a metaheuristic method which guides a local search procedure to 
effectively explore the solution space of optimization problems. It was first introduced by Glover 
[5, 6] and has exhibited successful applications for solving many complex problems. TS has the 
following distinctive features which make it unique from other metaheuristics.  
z Configuration is a trial solution to the underlying optimization problem. A solution 
configuration x = [x1, x2, …, xn] is composed of a vector of n decision variables each of 
which has been assigned a value.  
z A move function denoted by S(⋅) is an alteration procedure performed on a configuration 
such that a neighboring configuration can be obtained, viz., )(xSx =′  where x′  is a 
neighboring configuration of x. As such the solution space can be exploited through 
successive moves. The alteration procedure is usually a little change on the values of a small 
subset of decision variables such that good quality solutions will not be passed over. For the 
case of combinatorial optimization, this procedure can be easily devised such as performing 
random perturbations on the values of a few decision variables or swapping the values 
among them. However, it should be carefully designed if continuous optimization is 
considered.  
z Neighborhood Ω(⋅) of a configuration is the set of all neighboring configurations that can be 
obtained through a candidate move, namely { })(   )( xSxxx =′′=Ω . Since the cardinality of 
Ω(x) could be large, in which case one can perform a subset of all possible moves.  
z Tabu restriction is the key spirit of tabu search which forbids a recent move to be reversed. 
This is facilitated by managing a special memory structure called tabu list which records the 
last moves recently visited in a given historical period. All the moves tallied in the tabu list 
are classified as tabu-active and are excluded from the neighborhood Ω(x), and thus become 
inaccessible. The tabu list has a fixed length. When the tabu list is full, the oldest element 
should be removed before the new element can be inserted, i.e., the tabu list is circular. 
Consequently, each tabu move will be freed and resume its accessibility after certain 
iterations depending on the length of the tabu list. 
z Aspiration level: the tabu status of a move can be overruled if certain aspiration level criteria 
are satisfied. For instance, if a tabu move will lead to a solution that is better than the best 
solution visited so far, then one can take this move by overriding the tabu restriction. 
Aspiration level provides a degree of freedom in accepting a tabu move that reaches a 
threshold of attractiveness.  
 16
Two real images named Lenna and Pepper are used (see Figs. 2(a)-2(b)). Their gray level 
histograms are shown in Figs. 2(c)-2(d). For Kapur and Otsu objectives, we must input the 
number of thresholds in order to get the results. We construct a 5-level hierarchical order of 
thresholds for each image, since the number of thresholds is hardly more than five in real 
applications. The individual hierarchical order and the corresponding uniformity measures 
obtained by using PSO and GA, respectively, are presented in Tables 2-3. The multiple threshold 
values produced by PSO and GA are very close, meaning that they are likely to be the local 
optimal ones. Furthermore, PSO and GA save a lot of computational time compared to traditional 
computation techniques with Kapur and Otsu objectives.  
 
Fig. 2. Test images and the corresponding histograms. 
 
Table 2 The hierarchical thresholds and uniformity measures of tested images by 
using PSO. 
Images Hierarchical order of thresholds Uniformity measures 
Lenna 125 0.882989 
 101,155 0.888467 
 90,133,174 0.917521 
 85,121,150,182 0.933261 
 84,147,142,164,189 0.938547 
Pepper 92 0.787444 
 84,149 0.868958 
 18
                    
       (a)                     (b)                        (c) 
Fig. 3. Three test curves: (a) leaf curve, (b) chromosome curve, (c) semicircle curve. 
 
Table 3. The comparative results on synthesized curves using competing 
metaheuristics 
  GA TS ACO PSO 
 ε M ( Mσ ) t M ( Mσ ) t M ( Mσ ) t M ( Mσ ) t 
 150 15.6 (0.6) 0.4 10.6 (0.5) 0.1 11.0 (0.0) 0.9 10.7 (0.5) 0.4 
 100 16.3 (0.5) 0.3 13.7 (0.6) 0.1 12.6 (0.2) 0.8 12.4 (0.5) 0.3 
Leaf 90 17.3 (0.5) 0.3 14.6 (0.5) 0.1 12.8 (0.3) 0.9 13.0 (0.0) 0.3 
(N=120) 30 20.5 (0.6) 0.3 20.1 (0.5) 0.1 16.6 (0.4) 0.9 16.6 (0.5) 0.3 
 15 23.8 (0.6) 0.3 23.1 (0.5) 0.1 19.7 (0.3) 0.9 20.0 (0.0) 0.2 
 30 7.3 (0.4) 0.2 6.7 (0.4) 0.1 6.0 (0.0) 0.4 6.0 (0.0) 0.2 
 20 9.0 (0.6) 0.2 8.0 (0.3) 0.1 7.6 (0.3) 0.5 7.6 (0.7) 0.2 
 10 10.2 (0.4) 0.2 11.0 (0.4) 0.1 10.0 (0.3) 0.5 10.5 (0.5) 0.1 
(N=60) 8 12.2 (0.5) 0.2 12.2 (0.5) 0.1 11.0 (0.4) 0.5 11.0 (0.0) 0.1 
 6 15.2 (0.6) 0.2 14.4 (0.5) 0.1 12.2 (0.3) 0.5 12.4 (0.7) 0.1 
 60 13.2 (0.4) 0.3 11.0 (0.4) 0.1 10.0 (0.0) 0.8 10.0 (0.0) 0.3 
 30 13.9 (0.7) 0.3 13.6 (0.5) 0.1 12.0 (0.0) 0.8 12.1 (0.3) 0.3 
Semicircle 25 16.8 (0.7) 0.3 14.9 (0.6) 0.1 13.0 (0.0) 0.7 13.2 (0.4) 0.3 
(N=102) 20 19.2 (0.6) 0.3 16.2 (0.6) 0.1 15.8 (0.4) 0.7 14.6 (0.7) 0.2 
 15 23.0 (0.9) 0.3 18.3 (0.7) 0.1 16.8 (0.4) 0.7 15.8 (1.2) 0.2 
 
Point pattern registration (PPR) 
The comparative performance of competing algorithms is evaluated with different 
datasets containing various numbers of data points (n), in particular, n = 50, 250, and 500, 
respectively. For a fair comparison, all competing algorithms are terminated when they have 
consumed 4000 times of fitness evaluations because solution fitness is the most informative 
element and is also the most time consuming component. In all experiments, PSO is executed 
with 20 particles, SS maintains a reference set containing 20 elite solutions, and GA is conducted 
with 20 chromosomes. It is worth noting that SA is a single agent search algorithm instead of a 
population-based one, we thus let SA execute with 4000 iterations. The numerical results for each 
dataset are the mean value and the standard deviation (σ) from 30 independent runs and they are 
Chromosome 
 20
 RSTPA 22.4 (0.6) 14.1 (0.1) 23.8 (0.6) 16.0 (2.1) 36.4 (2.2) 17.2 (0.3) 24.8 (1.8) 15.4 (0.1) 
 RSTDA 0.0 (0.0) 11.8 (0.1) 0.1 (0.1) 12.3 (5.3) 29.5 (1.9) 16.9 (0.2) 1.4 (1.4) 12.9 (0.1) 
250 RST 0.0 (0.0) 288.3 (1.8) 0.3 (0.2) 312.0 (5.3) 149.7 (4.8) 374.0 (2.1) 1.0 (1.1) 315.3 (1.3)
 RSTP 19.8 (0.1) 289.3 (1.7) 20.5 (0.2) 306.7 (2.2) 37.2 (2.1) 347.9 (2.3) 22.0 (1.0) 314.0 (0.3)
 RSTPA 24.1 (1.5) 341.6 (1.9) 25.8 (0.4) 369.6 (14.9) 168.9 (6.1) 427.9 (2.9) 30.4 (5.0) 376.8 (1.8)
 RSTDA 0.0 (0.0) 283.8 (0.2) 0.1 (0.0) 269.8 (7.6) 116.8 (3.9) 346.0 (1.9) 2.4 (2.6) 312.8 (1.4)
500 RST 0.0 (0.0) 1148.8 (2.2) 0.1 (0.1) 1132.3 (26.3) 9.7 (0.7) 1386.7 (6.2) 1.2 (1.0) 1259.0 (1.1)
 RSTP 18.4 (0.1) 1147.3 (2.7) 19.0 (0.1) 1215.4 (21.7) 24.5 (1.2) 1382.2 (8.1) 22.4 (2.4) 1259.3 (3.1)
 RSTPA 53.7 (2.1) 1385.5 (8.0) 56.6 (0.8) 1305.2 (35.8) 70.4 (4.5) 1656.1 (9.3) 71.7 (14.7) 1497.4 (2.2)
 RSTDA 0.0 (0.0) 1130.9 (2.7) 0.1 (0.1) 1090.8 (13.6) 76.2 (3.8) 1366.8 (8.6) 0.9 (0.9) 1234.7 (2.2)
 
Relevance feedback (RF) 
 Fig. 4 shows the average precision rate (PR) performance, by presenting each database 
image as a query, with the number of feedback iterations (t) obtained using the competing 
methods. Among all the methods, QVM and FRE seem to perform worst and they are able to 
improve the precision rate by only 10% after consuming nine iterations of feedback. The 
SVM-active method enhances the retrieval performance for about 20% for the same number of 
feedback iterations, but the major improvement is observed after the third iteration of feedback. 
This is because SVM-active applies successive two-class classifier training and requires a 
sufficient number of training samples to predict accurately non-linear classification boundaries, 
while both QVM and FRE modify progressively the query vector and feature weight, and usually 
obtain a significant improvement after the first two feedback iterations. It is noteworthy that none 
of the three methods exploits long-term information through multiple query sessions, so the 
retrieval performance is significantly surpassed by the Log-based and Adaptive/metaheuristic 
methods that conduct a form of long-term learning. 
 It is seen that the performance of Adaptive/metaheuristic and Log-based methods is 
comparable after the third iteration of feedback, but the Adaptive/metaheuristic method clearly 
outperforms the Log-based one in the first display and those in the first two feedback iterations. 
In fact, the Log-based method accumulates incrementally the users’ feedback information in a log 
and utilizes relevant and irrelevant images specified in the current feedback iteration as the seeds 
to search through the logs. Thus, more training samples are obtained and the retrieval 
performance starts improving from the first feedback iteration, but not in the first display. By 
contrast, the proposed Adaptive/metaheuristic method accesses the RF model base and applies the 
optimal model parameter values to determine the first display, thus yielding significant 
improvement in the precision rate at the start up of the system.  
 22
burden of many feedback interactions. 
 
五、計畫成果自評 
The scheduled tasks of this project have been accomplished successfully including (a) the 
study of IP and metaheuristics articles, (b) the identification of IP tasks, (c) the identification of 
new metaheuristics components, (d) system design and analysis, (e) a callable library, 
MetaYourHeuristic, (f) evaluation and analysis, and (g) international consultants.  
The achievement of this multi-year project is tremendous. Part of our research has been 
published in international journals and conferences [7-14]. We’ve also created a complimentary 
web site (http://intelligence.im.ncnu.edu.tw) for reporting the detailed experimental results. The 
user manual of our callable library, MetaYourHeuristic, is given in the Appendix. With this 
program library, we establish intensive collaborations with world-known researchers such as Prof. 
Fred Glover (the inventor of Tabu Search) and Prof. Bir Bhanu (the distinguished Professor of 
UCR and IEEE Fellow). We have coauthored several quality papers [7, 8, 10, 13] and exchanged 
Ph.D. students.  
 
六、參考文獻 
[1] Special issue on genetic algorithms, Pattern Recognition Letters 16 (8), 1995. 
[2] M. Dorigo, Optimization, learning, and natural algorithms, Ph.D. Thesis, Dip. Elettronica e 
Informazione, Politecnico di Milano, Italy, 1992. 
[3] J. Kennedy and R.C. Eberhart, “Particle swarm optimization,” Proceedings of the IEEE 
International Conference on Neural Networks, IV, 1995, 1942-1948. 
[4] M. Laguna and R. Marti, Scatter Search, Kluwer Academic Publishers, Boston, 2003. 
[5] F. Glover, "Tabu search - Part I," ORSA J. Comput. 1 (1989) 190-206. 
[6] F. Glover, "Tabu search - Part II," ORSA J. Comput. 2 (1990) 4-32. 
[7] P. Y. Yin, F. Glover, M. Laguna and J. X. Zhu, “Scatter PSO – A More Effective Form of 
Particle Swarm Optimization”, Proceedings of IEEE Congress on Evolutionary 
Computation (CEC) 2007, Singapore, 2007. pp. 2289-2296. 
[8] P. Y. Yin and F. Glover, “Hidden (Tabu) Secrets of Successful Evolutionary Search 
Methods”, Proceedings of IEEE Congress on Evolutionary Computation (CEC) 2007, 
Singapore, 2007. (Invited Speaker) 
[9] Peng-Yeng Yin and Yi-Min Liu, “Adaptive relevance feedback model selection for 
content-based image retrieval”, to appear in The Imaging Science Journal. 
[10] Peng-Yeng Yin, Fred Glover, Manuel Laguna and Jia-Xian Zhu, “Cyber swarm 
algorithms – improving particle swarm optimization using adaptive memory strategies,” 
European Journal of Operational Research 201(2), 1 March, 2010, 377-389. 
 1
目錄 
第一章 Meta Your Heuristic 架構 .......................................... 4 
1.1 PSO ........................................................................................................4 
1.1.1 粒子群最佳化介紹........................................................................4 
1.1.2 多目標粒子群最佳化....................................................................7 
1.1.2.1 多目標問題介紹....................................................................7 
1.1.2.2 多目標粒子群最佳化流程....................................................8 
1.1.3 類別介紹......................................................................................10 
1.1.3.1 Init() ......................................................................................10 
1.1.3.2 CollectiveInit()......................................................................11 
1.1.3.3 SetNonDominateNumber() ...................................................11 
1.1.3.4 FindMin()..............................................................................11 
1.1.3.5 Update() ................................................................................11 
1.1.3.6 RunProcedure() .....................................................................12 
1.1.3.7 UpdateProcedure() ................................................................12 
1.1.3.8 TwoPointUpdate().................................................................12 
1.1.3.9 ThreePointUpdate()...............................................................13 
1.1.3.10 FindPbest()..........................................................................13 
1.1.3.11 FindLbest()..........................................................................13 
1.1.3.12 FindRefSet()........................................................................13 
1.1.3.13 FindGbest() .........................................................................14 
1.1.3.14 Run() ...................................................................................14 
1.1.3.15 GetPositionFitness()............................................................14 
1.1.3.16 Fitness()...............................................................................14 
1.1.3.17 FitnessMulti()......................................................................14 
1.2 ACO .....................................................................................................16 
1.2.1 螞蟻演算法介紹..........................................................................16 
1.2.2 類別介紹......................................................................................19 
1.2.2.1 Init() ......................................................................................19 
1.2.2.2 FindFirstNode().....................................................................20 
1.2.2.3 UpdateAllowNode()..............................................................20 
1.2.2.4 StateTransitionRule() ............................................................20 
1.2.2.5 LocalPheromoneUpdate() .....................................................21 
1.2.2.6 GlobalPheromoneUpdate() ...................................................21 
1.2.2.7 FindGbest() ...........................................................................21 
1.2.2.8 GenerateAntPath() ................................................................21 
 3
1.6.2.1 Init() ......................................................................................53 
1.6.2.2 Run() .....................................................................................54 
1.6.2.3 InitVisibility() .......................................................................54 
1.6.2.4 Fitness().................................................................................55 
1.7 Scatter Search.......................................................................................56 
1.7.1 擴散式搜尋法介紹......................................................................56 
1.7.2 類別介紹：..................................................................................58 
1.7.2.1 Init() ......................................................................................58 
1.7.2.2 Diversification_Generation_Method()..................................59 
1.7.2.3 Run() .....................................................................................59 
1.7.2.4 Improvement_Method_First()...............................................59 
1.7.2.5 Improvement_Method()........................................................60 
1.7.2.6 twoCombine() .......................................................................60 
1.7.2.7 Update() ................................................................................60 
1.7.2.8 StaticUpdate () ......................................................................60 
1.7.2.9 Fitness().................................................................................60 
第二章 使用說明 .................................................................... 62 
2.1 開發工具..............................................................................................62 
2.2 問題......................................................................................................62 
2.3 共同變數和呼叫..................................................................................62 
2.4 演算法編碼、呼叫方式、詳細流程..................................................66 
2.4.1 PSO ..............................................................................................66 
2.4.2 ACO .............................................................................................76 
2.4.3 TS.................................................................................................82 
2.4.4 GA................................................................................................88 
2.4.5 SA ..............................................................................................100 
2.4.6 GRASP.......................................................................................107 
2.4.7 Scatter Search.............................................................................112 
附錄一、 ................................................................................ 116 
錯誤訊息代碼表................................................................................................116 
 5
iii vxx +=                                                       (2) 
vi為第 i 個粒子的速度，vi會受到 Vmax的限制，以防止粒子過份移動，而
超出了搜尋的空間；c1、c2 為學習因子或稱加速常數；rand()為介於 0 到 1 之
間的亂數；pi為第 i 個粒子的 pbest；pg 為 gbest；xi為第 i 個粒子目前所在的
位置。 
(6) 檢查所預設的任何停止條件，若判斷為否則至步驟 2，判斷為是則至步驟 7。 
(7) 結束。輸出最佳解或最佳近似解。 
 
Clerc, (1999)在位移向量的更新上加入了壓縮因子(Constriction factor)K，K
為一權重變數用來調整係數大小，位移更新法則與 K 的計算式如公式(5)所示，
當 c1 = c2 = 2.05 時，則 K=0.729，此位移向量更新公式的參數值因為有很好的收
斂行為，被大多數的研究學者所採用。壓縮因子法以數學模式為架構基礎，除了
確保程式能逐步達到收斂的效果外，也能避免程式過早收斂，由於有不錯的效
果，因此至今多數的粒子群最佳化的應用都是以壓縮因子版本為主。 
隨機產生各粒子
初始速度和位置
評估各個粒子
適應函數值 
記錄 pbest 
記錄 gbest 依式(1)、式(2)更新各粒子速度及位置
輸出解
終止? 
否
是
圖 1. 粒子群最佳化流程圖
1 
2 
3 
4 5 
6 
7 
 7
RefSet)(Laguna and Marti, 2003)用來存放在搜尋過程中所看過前幾名的解，
RandomPoint 則是指在變數範圍內，隨機產生一個亂數解，而兩點引導的粒子速
度產生公式如式(6)和式(8)所示，三點引導的粒子速度產生公式如式(7) 和式(8)
所示。 
( ) 







−
+
+
++= iii xcwcw
gpcwgpcwccvKv
2211
222111
21                           (6) 
( ) 







−
++
++
+++= iii xcwcwcw
gpcwgpcwgpcwcccvKv
332211
333222111
321       (7) 



∈
3
,0 max
cUck                              (8) 
wk 第 k 個經驗值的權重，在此演算法中三個經驗值視為同等重要，因此 w1~w3
皆為 1，ck 則是指為 k 個經驗值的學習因子，gpk為第 k 個引導點，而每個引導點
皆有五種選擇，分別為 pbest、gbest、lbest、RefSet、RandomPoint。 
 
1.1.2 多目標粒子群最佳化 
1.1.2.1 多目標問題介紹 
當一個最佳化的問題擁有二個以上的目標式時，此問題即為一個多目標的問
題，可以表示成如下的形式： 
lknjmiXgXgXf kjiSX ≤≤≤≤≤≤≥=∈ 1 ,1 ,20)(,0)( subject to    )(min
 多目標的問題也較符合真實世界的需求，舉例來說，在工廠生產製造時，我
們往往期望高收入的獲得，低成本的支出。 
 
1.1.2.1.1 支配關係 
在衡量一個多目標的最佳化問題時，一個解當中存在多個適合度(fitness)的
值，因此解與解之間存在著支配關係。當某一個解 A 當中所有適合度(fitness)的
 9
(2) 依據目標函數計算其適合度(fitness)。 
(3) 檢查每個粒子，是否支配目前的 pbest，如果是則以粒子目前的位置取代
pbest。 
(4) 檢查每個粒子的適合度是否被 gbest 中粒子所支配，如果都沒有被支配，則
將此粒子加入 gbest。 
(5) 檢查 gbest 中的粒子，若其中任一粒子被新加入的支配，則將被支配的粒子
移出 gbest。 
(6) 依據式(1)、式(2)更新每一個粒子的速度與位置。 
vi為第 i 個粒子的速度，vi會受到 Vmax的限制，以防止粒子過份移動，而
超出了搜尋的空間；c1、c2 為學習因子或稱加速常數；rand()為介於 0 到 1 之
間的亂數；pi為第 i 個粒子的 pbest；pg 為 gbest；xi為第 i 個粒子目前所在的
位置。 
(7) 檢查所預設的任何停止條件，若判斷為否則至步驟 2，判斷為是則至步驟 7。 
(8) 結束。輸出最佳解或最佳近似解集合。 
 
 11
VariableLowerbound 和 VariableUpperbound 會有兩種變數型態的原因乃在於要解
決不同變數範圍的問題，當所輸入的 VariableLowerbound 和 VariableUpperbound
為 double 型態，表示要解決的問題的每一維的變數範圍皆是相同，反之，當輸
入的變數為 double[]型態，表示所要解決的問題每一維的變數範圍皆不相同，而
RepeatableOption 則是提供使用者依不同的問題來選擇所需的編碼，而此類別提
供兩種編碼分別為重覆問題和不重覆問題的編碼。VariableObjectiveNumber 是使
用者若需要解多目標問題時，指定目標式的個數。 
1.1.3.2 CollectiveInit() 
由於 Init()為一個多型的類別，所以不論是同一變數範圍或是不同變數範圍
的問題，除了變數範圍的初始化不同之外，其餘初始部分皆是相同，因此利用
CollectiveInit 類別來初始 Init 多型類別共同初始化的部分。 
1.1.3.3 SetNonDominateNumber() 
輸入變數定義 
MaxNonDominateNumber int 型態，最大可以儲存非支配解的個數 
 此函式可以設定用來儲存非支配解空間的大小，系統預設為 500。當非支配
解的個數超過此大小時，會計算每個點的分散度，並將最小分散度的點移除，將
新的點加入。 
1.1.3.4 FindMin() 
輸入變數定義 
Array double[]型態，陣列。 
當輸入一個陣列，此類別可以找出陣列中最小值的陣列索引(Index)，並回傳
一個 int 型態的陣列索引。 
1.1.3.5 Update() 
輸入變數定義 
FirstGuidingPoint  string 型態，第一個引導點。 
SecondGuidingPoint string 型態，第二個引導點。 
 13
k int 型態，第 k 個 RefSet 成員。 
TwoPointUpdate 是一個多型類別，從 Update 類別得知使用者所輸入那兩個
引導點之後，即可依照所輸入的引導點進行粒子的速度及位置更新。可將
TwoPointUpdate 類別分為兩種輸入型態，第一種輸入 i、j 變數，表示 Update 中
的 FirstGuidingPoint 和 SecondGuidingPoint 沒有 RefSet 引導點，第二種則是輸入
i、j、k 變數，表示 Update 中的 FirstGuidingPoint 和 SecondGuidingPoint 有 RefSet
引導點。 
1.1.3.9 ThreePointUpdate() 
輸入變數定義 
i int 型態，第 i 個粒子。 
j int 型態，第 j 維。 
k int 型態，第 k 個 RefSet 成員。 
ThreePointUpdate 是一個多型類別，從 Update 類別得知使用者所輸入那三個
引導點之後，即可依照所輸入的引導點進行粒子的速度及位置更新。可將
ThreePointUpdate 類別分為兩種輸入型態，第一種輸入 i、j 變數，表示 Update
中的 FirstGuidingPoint、SecondGuidingPoint 和 ThirdGuidingPoint 沒有 RefSet 引
導點，第二種則是輸入 i、j、k 變數，表示 Update 中的 FirstGuidingPoint、
SecondGuidingPoint 和 ThirdGuidingPoint 有 RefSet 引導點。 
1.1.3.10 FindPbest() 
如圖 1 的步驟 3，檢查是否更新每個粒子的 pbest。 
1.1.3.11  FindLbest() 
檢查是否更新每個粒子的 lbest。 
1.1.3.12  FindRefSet() 
輸入變數定義 
i int 型態，第 i 個粒子。 
檢查第 i 個粒子是否可以更新 RefSet。 
 15
FitnessMulti 是多目標問題時使用的適合度函式，使用者可以覆寫(override)
的類別。使用者可以自定義目標函數或適合度函數，並回傳一個 double 型態的
適合度陣列索引。 
 17
有相同的機率選擇往 C 或往 D 方向前進。但是因為路徑 BCE 較路徑 BDE 來的
短，所以選擇路徑 BCE 的螞蟻會較快通過障礙物而留下完整的費洛蒙，所以當
螞蟻從 F 點行進到 E 點時，就比較可能選擇費洛蒙濃度高的路徑 ECB，而流下
更多的費洛蒙。到最後，幾乎所有的螞蟻都會延著路徑 BCE 行走，而形成 A 到
F 的最短路徑。螞蟻演算法就是根據螞蟻總能尋求最短路徑的機制而發展出來的
一種最佳化演算法。 
 茲將螞蟻演算法的流程圖如圖 5 所示，其步驟說明如下： 
(1) 在演算法開始進行之前，所有路徑會先流下固定量的初始費洛蒙，也就是
Cij =τ ， ji,∀ 。其中 C 為一常數， ijτ 為點 i 到點 j 路徑上的費洛蒙濃度。設
定初始費洛蒙的目的是要加快收斂的速度。 
(2) 根據問題類型及問題的變數範圍，以隨機的方式產生第 k 隻螞蟻第 1 維的變
數。 
(3) 此規則決定第 k 隻螞蟻由 node i 移動至 node j 的機率值 kijp ： 
 
             



∉
= ∑
∉
otherwise,,0  
 if,
)()(
)()(
k
tabul
ilil
ijij
k
ij
tabuj
p
k
βα
βα
ητ
ητ
                   (9) 
  
ijη 是 node i 至 node j 的可見度(visibility value)，由 local search 的角度出發，
也就是貪婪的區域搜尋法則(greedy heuristic)。以尋找最短路徑為例，可以令
ijη 為 node i 至 node j 的路徑長度的倒數，所以此路徑愈短， ijη 值愈大，愈能
吸引螞蟻行走該路徑。而 ijτ 是代表全域的觀點，也就是以整條路徑全部走完
後，再依據路徑的品質好壞(總路徑長度的倒數)，來更新 ijτ 。而 α，β 則為決
定 τ 與 η 重要性的加權值。 
 19
 
1.2.2 類別介紹 
1.2.2.1 Init() 
輸入變數定義 
PopulationSize  int 型態，粒子數。 
VariableDimension  int 型態，變數維度。 
VariableLowerbound double 或 double[]型態，變數的下界。 
VariableUpperbound double 或 double[]型態，變數的上界。 
RepeatableOption  string 型態，是否為重覆問題的選項。 
CycleOption   string 型態，是否為 Cycle 問題的選項。 
這個類別為初始化類別也是一個多型類別，使用者可依不同的問題類型，輸
入所需的變數值，而 Init 類別的輸入型態可依 VariableLowerbound 和
VariableUpperbound 分為兩種，第一種為每一維都是同一變數範圍的問題，第二
初始費洛蒙
選擇第 k 隻
螞蟻起始點 k<=AntSize
j<=Dim
狀態轉換規則 區域費洛蒙更新 
i=1 j=1
是
是
j = j+1 
k=k+1
否
否
全域費洛蒙更新
輸出解 
圖 5. 螞蟻演算法流程圖 
1 
2
3 4
5 
6
 21
Alpha double 型態，狀態轉換規則中的 α值，決定τ的加權值。 
Beta  double 型態，狀態轉換規則中的 β 值，決定 η的加權值。 
如圖 5 的步驟 3 所示，算出第 i 隻螞蟻由第 j 維移動至第 j+1 維的所有機率
值，並藉由俄羅斯輪盤挑選出第 j+1 維變數。 
1.2.2.5 LocalPheromoneUpdate() 
輸入變數定義 
LocalPersistenceRate  double 型態，費洛蒙的殘留率。 
LocalConstant    double 型態，初始費洛蒙，一個非常小的常數。 
如圖 5 的步驟 4 所示，根據傳入的 LocalPersistenceRate 及 LocalConstant 進
行區域費洛蒙更新。 
1.2.2.6 GlobalPheromoneUpdate() 
輸入變數定義 
GlobalPersistenceRate  double 型態，費洛蒙的殘留率。 
GlobalConstant   double 型態，一個常數。 
如圖 5 的步驟 5 所示，根據傳入的 GlobalPersistenceRate 及 GlobalConstant
進行全域費洛蒙更新。 
1.2.2.7 FindGbest() 
檢查是否更新 gbest。 
1.2.2.8 GenerateAntPath() 
輸入變數定義 
Alpha double 型態，狀態轉換規則中的 α 值，決定τ的加權
值。 
Beta double 型態，狀態轉換規則中的 β 值，決定 η的加權
值。 
LocalPersistenceRate  double 型態，區域費洛蒙更新，費洛蒙的殘留率。 
LocalConstant    double 型態，初始費洛蒙，一個非常小的常數。 
 23
取得第 i 隻螞蟻的適合度。 
1.2.2.11 InitVisibility() 
InitVisibility 是使用者可以覆寫(override)的類別，使用者可以自行定義
Visibility 這個公開(public)的二維陣列。 
1.2.2.12 Fitness() 
輸入變數定義 
Solution  double[]型態，解。 
Fitness 是使用者可以覆寫(override)的類別，使用者可以自定義目標函數或適
合度函數，並回傳一個 double 型態的適合度。 
 25
開始 
1.初始化變數與最佳解 
  計數器 = 0
2. 依據產生鄰居策略，產生並所有鄰居解 
3. 計算適合度 
4. 根據適合度做排序 
5. 找出符合下兩項特性的解： 
A. 非禁忌的最佳解 
B. 為禁忌但符合勇氣程度準則的解 
6. 針對上述的評估結果進行移動，並更新禁忌名單 
7. 若移動所得的解比目前最佳解還好則更新最佳解之記錄 
8.計數器
終止條件?
更新計數器 
9.輸出最佳解 
結束
YES 
NO 
圖 6. 禁忌搜尋法流程 
 27
1.3.1.1 產生鄰居策略 
z Two-Swap 
隨機決定兩點位置，把兩點的值互換 
 
    2 1 5 3 4  
Initial solution  5 3 2 1 4  
2 3 5 1 4 2 3 1 5 4  
    2 3 4 1 5  
    4 3 5 1 2  
 
z Inversion 
 隨機決定兩點位置，把兩點間的值做翻轉 
 
    4 1 5 3 2  
Initial solution  1 5 3 2 4  
2 3 5 1 4 2 4 1 5 3  
    2 1 5 3 4  
    3 2 5 1 4  
 
z TwoListRnd 
 隨機決定兩點位置，隨機挑選合理解， 
 這裡假設合理解範圍是 1~10 
    2 6 5 3 4  
Initial solution  1 3 5 7 4  
2 3 5 1 4 2 4 5 8 4  
    2 1 5 3 4  
    9 2 5 1 4  
 
 
 29
1.3.2 類別介紹 
1.3.2.1 Init() 
輸入變數定義 
NeighborSize   int 型態，鄰居數。 
VariableDimension  int 型態，變數維度。 
VariableLowerbound int 或 int[]型態，變數的下界。 
VariableUpperbound int 或 int[]型態，變數的上界。 
RepeatableOption  string 型態，是否為重覆問題的選項。 
TabulistSize   int 型態，決定禁忌名單長度 
 
使用者可依不同的問題類型，輸入所需的變數值，而 Init 類別的輸入型態可
依 VariableLowerbound 和 VariableUpperbound 分為兩種，第一種為每一維都是同
一變數範圍的問題，第二種則是每一維都是不同變數範圍的問題。
VariableLowerbound 和 VariableUpperbound 會有兩種變數型態的原因乃在於要解
決不同變數範圍的問題，當所輸入的 VariableLowerbound 和 VariableUpperbound
為 int 型態，表示要解決的問題的每一維的變數範圍皆是相同，反之，當輸入的
變數為 int[]型態，表示所要解決的問題每一維的變數範圍皆不相同，而
RepeatableOption 則是提供使用者依不同的問題來選擇所需的編碼，而此類別提
供兩種編碼分別為重覆問題和不重覆問題的編碼。 
 
1.3.2.2 Run() 
輸入變數定義 
MaxEvaluation     int 型態，最大的目標函式評估次數。 
Strategy             string 型態，產生鄰居的策略。 
Aspiration           double 型態，勇氣程度機率。 
Run 為一個多型類別，共有兩種輸入型態，第一種只需輸入 MaxEvaluation，
 31
 
1.3.2.7 GenerateNeighbors() 
輸入變數定義 
Strategy          string 型態，可以參考策略設計下的節點，共有三種策略。 
此類別要注意如果 RepeatableOption 選擇是重覆問題編碼，可支援的策略
TwoListRnd，反之如果選擇是不重覆問題編碼，可支援的策略共有 Inversion 及 
TwoSwap。  
 
1.3.2.8 CheckNeighborCount() 
此類別根據 NeighborSize、VariableDimension 與 Strategy 三個變數條件判斷
使用者所設定的鄰居數量是否在合理範圍內，若不合理，超出了可產生的最大鄰
居數，將會導致結果錯誤，為防此舉因此先發出錯誤訊息告知使用者並中止程序。 
 33
1.4  GA 
1.4.1 基因演算法介紹 
由達爾文進化論的觀點，物種靠不斷的演化而產生最適合生存的物種。基
因演算法即是此一論點出發，模擬自然界的生存方式，對既定問題求最佳解。基
因演算法的基本理論是由密西根大學的賈賀蘭(John Holland)教授於 1975 年首先
提出的，是基於自然選擇過程的一種最佳化搜尋機構。其基本精神在於仿效生物
界中物競天擇、優勝劣敗的自然進化法則，它能夠選擇物種中具有較好特性的上
一母代，並且隨機性的相互交換彼此的基因資訊，以期望能產生較上一代母代更
加優秀的子代，如此重複下去以產生適應性最強的最佳物種。 
基因演算法中有一組解族群(Population)，就像生物的染色體一般。依照不
同類型的問題，可藉由不同的編碼方式(Coding)去顯示不同的問題特性，而再由
適合函數表現染色體解的好壞程度。透過基因演算法中的複製(Reproduction)、
交配(Crossover)、突變(Mutation)及淘汰的機制，染色體以世代的改進方式，直到
達到終止的條件。 
此 GA 的流程圖如圖 8 所示，其步驟說明如下： 
步驟一：初始化母體(initialization)隨機產生 N 個個體(或稱染色體)，而 N 稱
為母體大小(population size) 
步驟二：評估個體，計算出每一個個體的適合度值(fitness value) 
步驟三：再生(reproduction)依據個體(individual)的適合度值(fitness value)及
再生機制(reproduction mechanism)產生新的母體(population) 
步驟四：交配 (crossover)依據交配率 (crossover rate)選出若干個個體
(individuals)來進行交配的運作。 
步驟五：突變 (mutation) 依據突變率 (mutation rate)選出若干個個體
(individuals)來進行突變的運作。 
步驟六：結束測試(termination test)依據預先設定的演化程式結束條件，判
 35
z 基因編碼(Coding) 
在進行基因演算法時，需將每一個可行解編成一個字串，字串必須要能表
達出這個可行解的特性，編碼的方式大概可分為三種：整數、實數與二進位型。 
z 染色體數目 
染色體個數的多寡有兩個方面可以討論：1.染色體數目多就表示物種的種類
可能比較多，演化時可以朝著許多不同的方向演化，若是數目太少就會造成演化
的選擇不多，很快就使得演化到了瓶頸。2.可是當數目多，相對的花在計算每一
代各個染色體的適應度上的時間便會大增。 
z 複製方法(Reproduction) 
    複製的目的是為了找出取代較差母代的染色體，這個運算機制將會找出較佳
的染色體，使其可以有較佳的機率保留下來。常用的複製方法有兩種，一種是放
回的隨機抽樣(輪盤法)如下，這是將染色體的適合度函數除以所有染色體的適合
度函數值的總合，各染色體求出的值稱為適合值比率，在依各適合值比率大小隨
機選取。另一種方法是不放回的隨機抽樣，是將各染色體的適合度函數除以此代
所有染色體的適合度函數值的平均值，求出各染色體的適合值比率，此數值將會
有整數值及小數值，整數值代表此染色體至少要被複製幾次的部份，小數值利用
輪盤法隨機被選取要複製的機率。 
 
z 精英策略(elitist) 
    此策略執行在輪盤法或競賽法之前，預先保留前幾名較佳的染色體進
入下一代，通常以 10%當作比例，假使每一代的人口為 40 人，那在計算完子代
的適應值之後，便把父代加子代共 80 人做適應值的排序，並優先保留前 4 名進
入下一代，剩下的 36 名才由輪盤法或競賽法挑選。 
 37
z 交配(Crossover) 
交配的目的是為了讓染色體之間互相交換有用的基因，使新染色體有機會
產生組合更高的適合度，以達成不斷演化的目的。對整數型編碼來說，較常見的
交配方法有以下幾種。 
 
(1). PMX(Partially Matched Crossover)： 
母代 1：1 2 3 4 5 6 7 8 9 
隨機產生兩切點 
母代 2：5 6 9 8 7 1 4 2 3 
子代 1：1 2 9 8 7 6 7 8 9 
兩切點中的基因對調 
子代 2：5 6 3 4 5 1 4 2 3 
子代 1：1 2 9 8 7 6 5 4 3 
將切點外重複機因對調 
子代 2：7 6 3 4 5 1 8 2 9 
 
 39
(3).  SX（Simple Crossover）： 
母代 1：1 2 3 4 5 6 7 8 9 
隨機產生一切點 
母代 2：5 6 9 8 7 1 4 2 3 
 
母代 1：1 2 3 5 6 9 8 7 4 
保留切點左邊的基因，而切點右 
邊的以另一個染色體順序填入 
母代 1：5 6 9 1 2 3 4 7 8 
 
 
(4).  Arithmetical Crossover： 
假使 1x 和 2x 是欲進行交配的兩個個體，則經過交配後而產生的兩個新後代
分別為 21'1 )1( xxx λλ −+= 和 12'2 )1( xxx λλ −+= 。隨機數 [ ]1,0∈λ 。此方法主要利
用凸集合的特性，當 Dxx ∈21 , ，我們可以稱此交配運算為 guaranteed average 
crossover 當 2/1=λ 時。 
 
z 突變(Mutation) 
突變也是用來產生子代的一種方法，為了防止複製與交配過程中；忽略有
機會在後來的世代找到好解的基因串。以下為常見的突變方式： 
 
(1).  鄰近兩點變換 
1 2 3 4 5 6 7 8 9 
 
1 2 3 5 4 6 7 8 9 
 
(2).  隨機兩點變換 
1 2 3 4 5 6 7 8 9 
 41
PopulationSize  int 型態，染色體數。 
VariableDimension1   int 型態，變數維度 1 的長度。 
VariableDimension2   int 型態，變數維度 2 的長度。 
VariableLowerbound double 或 double[]型態，變數的下界。 
VariableUpperbound double 或 double[]型態，變數的上界。 
Encoding            string 型態，染色體的編碼。 
RepeatableOption  string 型態，是否為重覆問題的選項。 
這個類別為初始化類別，共有 4 個多型函數供使用者呼叫，使用者可彈性地
改變染色體的表達型態來讓演算法可以更佳地解決問題。VariableDimension1 為
染色體的 row length，VariableDimension2 為染色體的 column length，當解決 TSP
問題的時候，因為只需要一條 TSP 路徑即可表達一組 solution，所以此時分別設
VariableDimension1 和 VariableDimension2 為 1 和城市總數，當解決這類一維染
色體的問題的時候，可以呼叫只有一個 VariableDimension 當作參數的 Init 函數。
當欲解決的問題為二維染色體的時候，例如學生的學習路徑最佳化問題，假如有
5 個學生必須個別參與 10 個學習活動，老師就必須安排這 10 位學生的學習路
徑，此問題的染色體可以表示成 5×10 的矩陣，等同於是安排 5 個 TSP 路徑，當
染色體為二維的時候，可以呼叫有二個 VariableDimension 當作參數的 Init 函數，
並分別設 VariableDimension1 和 VariableDimension2 為 5 和 10。Init 類別的輸入
型態可依 VariableLowerbound 和 VariableUpperbound 分為兩種，第一種為每一維
都是同一變數範圍的問題，第二種則是每一維都是不同變數範圍的問題。
VariableLowerbound 和 VariableUpperbound 會有兩種變數型態的原因乃在於要解
決不同變數範圍的問題，當所輸入的 VariableLowerbound 和 VariableUpperbound
為 double 型態，表示要解決的問題的每一維的變數範圍皆是相同，反之，當輸
入的變數為 double[]型態，表示所要解決的問題每一維的變數範圍皆不相同，而
RepeatableOption 則是提供使用者依不同的問題來選擇所需的編碼，而此類別提
供兩種編碼分別為重覆問題和不重覆問題的編碼。 
 43
1.4.2.5 Fitness() 
輸入變數定義 
Solution  double[]型態，解。 
Fitness 是使用者可以覆寫(override)的類別，使用者可以自行定義目標函數或
適合度函數，並回傳一個 double 型態的適合度。當問題的染色體被初始化為二
維，必須把一維的染色體轉成二維的染色體再進行適合度函數值的計算。 
 
 45
 
(1) 若 f(s’(k)) < f(s(k))，代表新的解可以得到更小的成本，因此勢必可取代目前
解。 
(2) 若 f(s’(k)) > f(s(k))，雖然新的解沒有比目前解更好，但仍然給予一個機率值
保留新的解。在此我們也可觀察到，如果 f(s’(k))愈大的話，能被保留下來的
機率就愈小；且隨著退火的過程，溫度下降，也會使得新的解可通過的機率
變小。 
 47
流程步驟說明如下： 
(1) 產生一個任意初始解，以目前解 Ac代稱，並設為最佳解 Ab。 
(2) 由此目前解 Ac產生下一個新解 At，產生方法可以有許多不同的設計，例如使
用「兩點交換」即是一種方法。 
(3) 判斷 At的目標函式值 Jt是否小於 Ac的目標函式值 Jc： 
(a) 若是，則接受 At成為 Ac。 
(b) 若不是，則給予一個機率值 y，若 y 通過保留機率的門檻，即接受 At
成為 Ac。反之，如果沒有通過保留機率，則跳至步驟 5。 
(4) 當 At成為 Ac後，接著判斷 Jt是否小於最佳解 Ab 的目標函式值 Jb，如果也是，
則讓 At成為 Ab。 
(5) 判斷尋找新解的次數是否仍小於 Lk： 
(c) 若是，則從第 2 步驟開始再找下一個 At。 
(d) 若不是，即達到熱平衡。 
(6) 調降溫度，並判斷此溫度是否已達冰點( Tk<ε)： 
(e) 若是，終止整個演算法並輸出最佳解 Ab 與目標函式解 Jb。 
(f) 若不是，則回到第 2 步驟開始新一個 Tk 的熱平衡過程。 
此外，關於 Markov chains 的長度，若我們設置在每個溫度下的長度 Lk 是變
動的，即 Lk+1=βLk，如果 β=1.1，那麼隨著溫度變動的次數，Lk的值在溫度愈低
時會愈大，搜尋答案的時間愈長，於是我們應該設置一個 Lk 的上限值，以防止
過長的計算時間。 
 
 
 
 
 
 
 49
Lk                  int 型態，即為 Markov chains 的長度 Lk。 
T0              double 型態，初始溫度。 
Mu        double 型態，即為降溫比例 µ。 
Run 為一個多型類別，共有三種輸入型態，第一種只需輸入 MaxEvaluation，
也就是目標函式總共評估的次數上限，在此以目標函式的評估次數作為演算法終
止條件，且系統直接預設 Lk=100，T0=1000，Mu=0.9；第二種為除了輸入
MaxEvaluation 之外，使用者可以自行輸入 Lk、T0 與 Mu；第三種則是以冰點 ε
作為演算法終止條件，因此輸入 Epsilon 的值而非 MaxEvaluation，至於 Lk、T0
和 Mu 仍然是由使用者自行決定輸入。 
 
1.5.2.3 FirstSolution() 
此類別依據 Encoding 和 RepeatableOption 兩變數來產生初始解。 
 
1.5.2.4 NextTrialSolution() 
此類別依據 Encoding 和 RepeatableOption 兩變數來決定產生下一個解的方
式，並對目前解作擾動，然後得到新的解。如果是可重覆的整數問題，使用
TwoListRnd 方法，在目前解中挑選任意兩點換成其他值，得到新的解；如果是
可重覆的二元(0、1)整數問題，則採用 Flip_mutation 方法，在目前解中給予某個
突變比例，0 換成 1、1 換成 0 得到新的解，此外，二元問題也可視同整數問題
解決；如果是可重覆的實數問題，則使用 Gaussian_mutation 方法，在目前解中
給予某個突變比例，突變後的值視高斯突變的結果而定，完成後即得到新的解。
至於不可重覆的問題，則使用 TwoSwap 方法，在目前解中任選兩點互換值成為
新的解。  
 
1.5.2.5 GetTk() 
此類別在使用者呼叫後，會回傳溫度 Tk 的值，因此使用者可以隨時得知當
下的 Tk 為何，或許是在解問題的最後將 Tk 印出，當作一個評估的標準。 
 51
1.6 GRASP 
1.6.1 GRASP 介紹 
GRASP 是由 Feo 和 Resende 兩人在 1995 年所提出來的演算法，這個演算法
很適合用來解組合最佳化的問題，演算法的流程主要是不斷的 multi-start 或
iterative process，每一個 iteration 主要是由兩個 phases 所組成，一個是
Construction，另一個是 Local Search。任一 iteration 利用 Construction phase 來隨
機產生一個 feasible solution，接著再使用 Local Search 來讓這個 feasible solution
爬到 local optimal，如此反覆的 process 就是 GRASP 的主要流程。 
圖 10 為 GRASP 的 Pseudo-codes，程式的中止條件為演化 Max_Iterations 代，
Seed 通常以時間當作參數。圖 11 和圖 12 各為 Construct 和 Local Search 的
Pseudo-codes。 
 
 
 
     圖 10.  GRASP 流程 
 
 
 
 
 
 53
    圖 12 為 Local Search phase 的 Pseudo-codes，Local Search 的實做可以採用兩
種策略，一種是 Best-Improving，另一種是 First-Improving。Best-Improving 是在
找過一部分的鄰居之後才把目前的 solution 更新成為最好的 solution。而
First-Improving 為當找到一個鄰居的 solution 比目前的 solution 還好，就馬上把目
前的 solution 更新成為剛找到的鄰居 solution。 
 
 
     圖 12  Local Search phase 
 
 
1.6.2 類別介紹 
1.6.2.1 Init() 
輸入變數定義 
VariableDimension    int 型態，變數維度。 
VariableLowerbound   int 或 int[]型態，變數的下界。 
VariableUpperbound   int 或 int[]型態，變數的上界。 
RepeatableOption    string 型態，是否為重覆問題的選項。 
Alpha            double 型態，restriction criterion α。 
IterationOfLocalSearch   int 型態，此為 local search 的中止條件。 
 
這個類別為初始化類別也是一個多型類別，使用者可依不同的問題類型，輸
入所需的變數值，而 Init 類別的輸入型態可依 VariableLowerbound 和
 55
CPU，Visbility[i][j]，i = 0 ~ 4，j = 0 ~ 2，即為第 i 個工作指派給第 j 個 CPU 的成
本。 
 
1.6.2.4 Fitness() 
輸入變數定義 
Solution  double[]型態，解。 
Fitness 是使用者可以覆寫(override)的類別，使用者可以自行定義目標函數或
適合度函數，並回傳一個 double 型態的適合度。 
 57
隨機取代其中一個維度(Dimention)，而對於不重複的離散型問題(ex:TSP
問題)將採用 TwoSwap 方法，隨機調換兩個維度，使其仍然維持合理解的
情況。 
(3) 參考解集合(RefSet)更新方法：RefSet 中主要包含了兩種特性的解，
一種為高品質的解，另一種為多樣性較高的解，利用結合此集合中的解來
產生品質或多樣性較佳的解後，開始更新 RefSet 中的解，在 RefSet 中解的
數量為 b，而初始解的數量為 P，則 P > b，通常設定為 P = 10b，在兩層
架構中(b=b1+b2)，b1 中包含較高品質的解，b2 中包含多樣性較高的解，
而多樣性較高的計算方式為與 RefSet 中的解計算最短距離，如果以最小化
的問題為例，假使 ( ) ( )1bxfxf < 則 x 替換 1bx ，或者當 ( ) ( )bxdxd minmin > 時替
換 bx 。本程式將預設方式 b 的大小為 P/10，或者使用者可以自行定義 b、
b1、b2 大小。 
(4) 產生子集合：此步驟為挑選 RefSet 中的解作為下一步驟結合方法的
子集合，而挑選的方法不像是基因演算法(GA)中可以任意重覆的挑選父
代，挑選的方式有四種方法，但其中最有效益的方法就也就是本程式所使
用的方法，挑選方法為任意挑不重複的兩個解作為子集合。 
(5) 結合方法：這個步驟將會把各個子集合中的解藉由各種方式結合後
產生新的解，其中可以採用基因演算法(GA)中的各種交配方法將解結合，
而本程式對於連續型問題則利用線性權重的方式將解結合(如圖 13)，對於
離散型的方法則使用 Path Relinking 方法。 
(6) 更新方法：更新 RefSet 的方法可以分為靜態更新(Static update)以及
動態更新(Dynamic update)，其中靜態更新代表所有子集合結合後，產生完
所有新的解後才開始更新 RefSet，而動態更新則是當子集合在結合時(尚未
產生完所有解時)就立即開始更新 RefSet。在本程式中使用者可以在 Init()
 59
 
這個類別為初始化類別是一個多型類別，使用者可依不同的問題類型，輸入
所需的變數值，而 Init 類別的輸入型態可依 VariableLowerbound 和
VariableUpperbound 分為兩種，第一種為每一維都是同一變數範圍的問題，第二
種則是每一維都是不同變數範圍的問題。VariableLowerbound 和
VariableUpperbound 會有兩種變數型態的原因乃在於要解決不同變數範圍的問
題，當所輸入的 VariableLowerbound 和 VariableUpperbound 為 double 型態，表示
要解決的問題的每一維的變數範圍皆是相同，反之，當輸入的變數為 double[]型
態，表示所要解決的問題每一維的變數範圍皆不相同，而 RepeatableOption 則是
提供使用者依不同的問題來選擇所需的編碼，而此類別提供兩種編碼分別為重覆
問題和不重覆問題的編碼。Enocding 為 Solution 的編碼型態，分為整數、實數及
二元。 
UpdateType預設為Static模式，使用者可以再呼叫時選擇是否需要加入動態更新。 
1.7.2.2 Diversification_Generation_Method() 
 此函數會依據使用者於 Init()函式中所輸入的編碼型態(Enocding)以及是否
重複(RepeatableOption)產生符合型態且具多樣性的解。  
1.7.2.3 Run() 
MaxEvaluation  int 型態，目標函式評估次數。 
First_SearchTime  int 型態，初次執行 Improvement_Method 的次數。 
SearchTime  int 型態，子集合經結合方法後執行 Improvement_Method
的次數。 
 Run 為一個多型類別，共有兩種輸入型態，第一種只需輸入 MaxEvaluation，
系統直接預設 First_SearchTime= Iteration*1%，SearchTime=4，第二種為除了輸
入 MaxEvaluation 之外，使用者可以自行輸入各別 Improvement_Method 執行的
次數， 
1.7.2.4 Improvement_Method_First() 
 此為初次執行改進方法所執行的函式，此函數會依據使用者於 Init()函式中
所輸入的編碼型態(Enocding)以及是否重複(RepeatableOption)對任一維度執行
 61
 
 
 
 63
advanced call 則是針對一些對於演算法較熟練的使用者。而在問題的解重不重複
方面，對於 PSO、ACO、TS 的方法 Init( )最後一個參數是根據問題的不同所傳
進的參數也有所不同（而 GA 的方法 Init( )是多型，所以不一定是最後一個參數，
可能是倒數第二個參數，因此使用者需自行決定要使用哪一種 Init( )多型來輸
入），如果問題的解是可以重複的（例如 Rosenbrock、Rastrigin…等函數問題、
TAP、RAP），傳進的參數為「Repeatable」；問題的解是不可重複的（例如 TSP），
傳進的參數為「Nonrepeatable」。假如使用者不曉得該完整的寫出「Repeatable」
和「Nonrepeatable」，則可以利用 Metaheuristic class 來選擇 RepeatableOption，之
後再選擇 Repeatable 或 Nonrepeatable 即可（如圖 15 為 Metaheuristic class 底下的
RepeatableOption 的結構）。 
 
 
 
而也可根據演算法的不同，利用 PSOOption、ACOOption、TSOption、GAOption
來選擇（圖 16 以 PSOOption 為例）。 
 
 
上圖的 PSOOption 可以用 ACOOption、TSOption、GAOption 來取代，根據不同
的演算法來選擇。 
圖 15.  RepeatableOption 結構
圖 16.  PSOOption 結構 
 65
 
 
(4). 在參考找到 Metaheuristic，可以看到所有 Metaheuristic 的物件、方法（如
圖 21） 
 
 
 
    Include 完 Metaheuristic.dll 之後，接下來在程式部分，第一步 using 
Metaheuristic （如圖 22 ），這一個步驟很重要，因為若沒有 using 
圖 20.  選擇 Metaheuristic.dll 
圖 21.  可參考的物件、方法 
 67
 
 
z Simple call 
    PSO 的 simple call 只有一個方法 Run( )，而 Run( )要傳進的參數則是 fitness
函式的計算次數（圖 24，執行的次數為 10000 次），而方法 Run( )裡預設的策略
為更新 Pbest 和 Gbest 的流程。 
 
 
z Advanced call 
    PSO 可以根據使用者的需求來決定要使用兩點引導還是三點引導，例如：兩
點引導可利用 Pbest 和 Gbest 或 Pbest 和 Reference set…等，三點引導可利用
Pbest、Gbest 和 Reference set，或是利用 Pbest、Gbest 和 Lbest…等。若使用者對
PSO 的策略或流程非常熟悉，可以選擇利用 advanced call，假設使用者選擇用三
點引導，Pbest、Gbest、Reference set，因為 Reference set 預設的大小是 10，若使
用者想改變 Reference set 的大小必須 override Reference set 的大小（圖 25 假設
Reference set 的大小要改為 15）。 
 
 
接下來在方法 Update( )裡就必須填入 Pbest、Gbest、和 RefSet（圖 26）。 
 
 
    若使用者選擇第三點引導利用 Lbest 來當引導，Lbest 預設的大小是 3，使用
者若想改變 Lbest 大小則必須 override Ｌ的大小（圖 27 假設 L 大小改為 5）。 
圖 23.  傳入實數解 
圖 24.  Run() 
圖 25.  設定 Reference set size
圖 26.  選擇 Update()的策略 
 69
z 詳細描述 library 利用 PSO 解問題的使用流程 
    以下 PSO 針對連續問題和離散問題來詳細描述我們的 library 該如何使用，
從 include Metaheuristic 到建立物件的流程在 2.3 節（共同變數和呼叫）已經詳細
說明過了，接下來針對連續和離散問題在步驟上的不同加以說明。 
一. 離散問題（像是組合最佳化問題）可能必須讀進許多檔案，例如：TSP 必須
讀入城市之間的距離或是每個城市的座標，TAP 必須讀入通訊成本、執行成
本、cpu 記憶體上限、任務所需記憶體…等等。 
二. 初始化，在初始化方面因為 Init( )是多型的方法，Init( )要傳的參數照順序分
別為：小鳥大小、變數維度、變數下限、變數上限、問題的解為可重覆或不
可重複。不同的地方在於有些問題每個變數的範圍上限和下限都不一樣，像
是 RAP，每個工廠的資源數上限和下限都不同，因此若每個變數範圍都不同，
則傳進來的變數上限和下限就必須用陣列（如圖 31，初始化分別是：40 隻小
鳥、變數維度 5、array1 為每個變數的下限、array2 為每個變數的下限、問題
的解可重複）。 
 
 
 
    若每個變數範圍都相同，則只需傳單一值進來即可。若要解多目標的
問題，則必須在初始化的時候指定目標式的個數。（如圖 32，初始化分別是：
40 隻小鳥、變數維度 30、每個變數的下限為-30、上限為 30、問題的解可
重複）。 
 
 
三. override fitness，所傳的參數為實數解，因此若是像 TSP、TAP、RAP 這類的
圖 31.  變數範圍不同 
圖 32.  變數範圍相同 
 71
 PSO - TSP（advanced call） 
初始化 : advanced call，利用方法 Update( )，三點引導：Pbest、Gbest 和 Lbest，
在利用 Lbest 策略時，必須要 override L 大小，若沒有 override，則預設大小
為 3。 
 
 
 
 
 
 
 
 73
 PSO - RAP（advanced call） 
初始化 : advanced call，利用方法 Update( )，三點引導：Pbest、Gbest 和
RefSet，在利用 RefSet 策略時，必須要 override Reference set 大小，若沒有
override，則預設大小為 10（下圖為利用 PSOOption 選擇第三點引導）。 
 
 
 
 
 
 
 
 75
 PSO – ZDT1 函數（simple call） 
初始化：首先呼叫 Init()函式，最後一個參數輸入目標式的個數。使用 Simple call，
呼叫 Run 規定適合度函式(fitness fuction)為 40000 次。最後非支配解集合的所有
變數會存在 double[] NonDominate[int NumberOfNondominate, int Dimension]中，
而 值 會 存 在 double[] NonDominateFitness[int NumberOfNondominate, int 
ObjectiveNumber]中。非支配解的個數可以由 CountNonDominate 得知。呼叫與取
得 fitness 的方式可以由下範例得知。 
 
 
 
 
 77
洛蒙更新 (Global Pheromone Update)以及區域費洛蒙更新 (Local Pheromone 
Update) 全域費洛蒙及區域費洛蒙的更新會依照你所設定輸入的參數值。 
 
 
ACO 的 Advanced Call 分為有區域費洛蒙更新(Local Pheromone Update) : 
 
 
以及沒有區域費洛蒙更新(Local Pheromone Update) : 
 
 
以上兩種，同樣會依據使用者有沒有輸入區域費洛蒙參數來決定要不要加入區域
費洛蒙更新。 
z 詳細描述 library 利用 ACO 解問題的使用流程 
    以下 ACO 針對離散問題來詳細描述我們的 library 該如何使用，從 include 
Metaheuristic 到建立物件的流程在 3.3 節（共同變數和呼叫）已經詳細說明過了，
接下來針對連續和離散問題在步驟上的不同加以說明。 
一. 離散問題（像是組合最佳化問題）可能必須讀進許多檔案，例如：TSP 必須
讀入城市之間的距離或是每個城市的座標，TAP 必須讀入通訊成本、執行成
本、cpu 記憶體上限、任務所需記憶體…等等。 
圖 36.  第二種 Run 方法 
圖 37.  區域費洛蒙更新 
圖 38.  沒有區域費洛蒙更新 
 79
五. 演算法解各個問題的範例 : 
 ACO - TSP（advanced call） 
初 始 化  : advanced call ， Iteration=1000, Alpha=1, Beta=5, 
GlobalPersisitenceRate=0.9, GlobalConstant=1。 
 
 
 
 
 ACO - TAP（advanced call） 
初 始 化  : advanced call ， Iteration=1000, Alpha=1, Beta=5, 
GlobalPersisitenceRate=0.9, GlobalConstant=1。 
 81
 
 
 
 
 
 
 
 
 
 ACO – PAP（advanced call） 
初始化 : simple call，Iteration=10000。 
 83
Tabu 的編碼為整數編碼。因此使用者在寫 fitness 方法的時候傳進去的解必
須是整數，因此本 library 所提供的基本 Tabu 不能夠解連續函數的問題。 
 
 
z Simple call 
Tabu 的 simple call 為基本的 Run(目標函式評估次數)函式： 
 
 
輸入目標函式評估次數 MaxEvaluation 的參數後，演算法的整個演化過程即
會直到滿足評估次數為止。在鄰居產生策略方面，本 library 提供了三種策略，
分別為兩點交換(Two swap)、反轉(Inversion)以及 TwoListRnd。藉由 simple call，
使用者不需自行設定，而是由程式預設為「Two swap」，至於勇氣程度的預設值
則是「0.3」。 
z Advanced call 
相對於 Tabu 的 simple call，在 advanced call 中，使用者可以自行設定鄰居的
產生策略以及勇氣程度值。呼叫的函式為 Run(目標函式評估次數，鄰居產生策
略，勇氣程度)： 
 
 
使用者如果不知道該如何決定要使用哪些策略，可以利用 TSOption class，
根據問題的編碼是否重覆來選擇 Inversion、TwoSwap、TwoListRnd 策略，這些
可以由使用者自己決定，如圖 43。 
 
TSOption.Strategy 
TSOption.Strategy.Repeatable.TwoListRnd 
TSOption.Strategy.Nonrepeatable.TwoSwap 
TSOption.Strategy.Nonrepeatable.Inversion 
圖 40.  傳入整數解 
圖 41.  基本 Run() 
圖 42.  輸入策略及勇氣程度的 Run() 
 85
 
最後的兩個參數是根據問題的不同所傳進的參數也有所不同，如果問題的解
是可以重複的（例如 TAP、RAP），傳進參數「Repeatable」，若問題的解是
不可重複的（例如 TSP），則傳進參數為「Nonrepeatable」。假如使用者不曉
得該如何完整的拼出「Repeatable」、「Nonrepeatable」，則可以利用 TSOption 
class 來選擇 RepeatableOption，之後再選擇 Repeatable 或是 Nonrepeatable 即
可。接著再設定 Tabu list 的長度。 
三. override fitness，所傳的參數為整數解。 
四. 接下來就是演算法的流程，使用者可以選擇要用 simple call 或 advanced call。 
五. 演算法解各個問題的範例 : 
 Tabu - TSP（advanced call） 
初始化 : advanced call，目標函式評估次數=10000，鄰居的產生策略使用兩
點交換(TwoSwap)，勇氣程度為 0.3 
 
 Tabu - TAP（advanced call） 
初始化 : advanced call，目標函式評估次數=10000，鄰居的產生策略使用兩
點交換(TwoSwap)，勇氣程度為 0.3 
圖 45.  變數範圍相同 
 87
 
 
 
 
 
 
 
 
 
 
 
 Tabu - PAP（simple call） 
初始化 : simple call，目標函式評估次數=10000 
 89
GA 的編碼必須依問題的解為重複或不可重複來區分，問題的解可重複編碼
分為三種，實數、整數、布林（0 – 1），不可重複為整數和實數兩種，因此使用
者必須自行判斷問題後再來決定編碼屬於哪一種。像是 Rosenbrock、Rastrigin…
等函數問題為問題的解可重複，因此必須選擇實數編碼，而離散問題就根據問題
的解可重覆或不可重複來決定利用實數、整數或布林編碼，例如 TSP 為不可重
複的解，因此必須用整數編碼，而 PAP 為可重複的解必須用布林編碼，但是計
算 Fitness 時，傳進方法 Fitness( )裡還是要宣告成浮點數（double），如圖 46。 
 
 
 
z Simple call 
GA 的 simple call 只有一個方法 Run( )，只要傳進演算法所需執行的 fitness
計算次數和交配突變機率即可。Run( )裡預設的策略為： 
一. 天擇部分為 Tournament 
二. 交配依照編碼的不同可分為四種，預設的交配率為 0.9 
- 實數：Arithmetic 
- 可重複的整數：Multi Point 
- 不可重複的整數：Order 
- 布林：Multi Point 
三、突變依照編碼的不同可分為四種，預設的突變率為 0.1 
- 實數：Uniform 
- 可重複的整數：Uniform 
- 不可重複的整數：兩點交換 
- 布林：單點翻牌（flip） 
圖 46. 程式範例 
 91
兩種策略 ；整數編碼有隨機產生兩個位置交換、Uniform 兩種策略；不可重複
的整數編碼有隨機產生兩個位置交換策略；布林編碼有三種策略，隨機產生兩個
位置交換、隨機一個 Bit 翻牌（即 0 變 1、1 變 0）、隨機兩個 Bit 翻牌。因此在
方法 SetStrategy( )裡輸入使用者想選擇的策略。若使用者不清楚有哪些策略可選
擇，則可以使用 GAOption class 結構底下的 Mutation 來選擇，Mutation 底下根據
問題可分為 Binary、RealNumber、RepeatableInteger、NonRepeatableInteger，使
用者可根據問題的類型選擇適當的策略。 
 
    根據以上天擇、交配、突變的策略，使用者可以選擇要利用哪些策略進行
advanced call。 
z 詳細描述 library 利用 GA 解問題的使用流程 
    以下 GA 針對連續問題和離散問題來詳細描述我們的 library 該如何使用，
從 include Metaheuristic 到建立物件的流程在 2.3 節（共同變數和呼叫）已經詳細
說明過了，接下來針對連續和離散問題在步驟上的不同加以說明。 
一. 離散問題（像是組合最佳化問題）可能必須讀進許多檔案，例如：TSP 必須
讀入城市之間的距離或是每個城市的座標，TAP 必須讀入通訊成本、執行成
本、cpu 記憶體上限、任務所需記憶體…等等。 
二. 初始化，在初始化方面因為 Init( )是多型的方法，Init( )要傳的參數照順序分
別為：人口數、變數維度、變數下限、變數上限、編碼方式、問題的解為可
重覆或不可重複。不同的地方在於有些問題每個變數的範圍上限和下限都不
一樣，像是 RAP，每個工廠的資源數上限和下限都不同，因此若每個變數範
圍都不同，則傳進來的變數上限和下限就必須用陣列(如圖 48 為變數範圍不
一樣的例子，初始化分別是：人口數大小為 40、變數維度 5、array1 為每個
變數的下限、array2 為每個變數的上限、整數編碼、問題的解可重複)。 
 
 93
 
 TAP fitness 
 
 95
 PAP fitness 
 
 97
 
 
以下為 GA 解各個問題 call function 的範例 : 
 GA - Rosenbrock 函數 
初始化 : simple call，利用 Run( )，基本的 GA 流程天擇。 
 
 99
 GA - RAP（advanced call） 
初始化 : advanced call，可監控每一代的 GBest 的進步速率。 
 
 GA - PAP（advanced call） 
初始化 : advanced call，可監控每一代的 GBest 的進步速率。解此問題採用
二元編碼。 
 
 101
 
 
其兩者的差異在於傳進的第一個參數--「MaxEvaluation」和「Epsilon」，這
只是程式終止條件的不同，使用者可視其程式想以何者為終止條件來選用，如果
想以目標函式評估的次數為控制程式終止的條件，則可選用前者；如果想以溫度
的最低門檻值 Epsilon 為條件，則選用後者。 
z 詳細描述 library 利用 SA 解問題的使用流程 
以下 SA 針對連續問題和離散問題來詳細描述我們的 library 該如何使用，從
include Metaheuristic 到建立物件的流程在 2.3 節（共同變數和呼叫）已經詳細說
明過了，接下來針對連續和離散問題在步驟上的不同加以說明。 
一. 離散問題（像是組合最佳化問題）可能必須讀進許多檔案，例如：TSP 必須
讀入城市之間的距離或是每個城市的座標，TAP 必須讀入通訊成本、執行成
本、cpu 記憶體上限、任務所需記憶體…等等。 
二. 初始化，在初始化方面因為 Init( )是多型的方法，Init( )要傳的參數照順序分
別為：變數維度、變數下限、變數上限、編碼方式、問題的解為可重覆或不
可重覆。不同的地方在於有些問題每個變數的範圍上限和下限都不一樣，像
是 RAP，每個工廠的資源數上限和下限都不同，因此若每個變數範圍都不同，
則傳進來的變數上限和下限就必須用陣列(如圖 54，初始化為：變數維度 5，
array1 為每個變數的下限、array2 為每個變數的上限，編碼方式為整數，問題
的解可重覆)。 
 
 
 
若每個變數範圍都相同，則只需傳單一值進來即可(如圖 55，初始化為：變
數維度 29，每個變數的下限值為 1、上限值為 29，編碼方式為整數，問題
圖 54.  變數範圍不同 
圖 53.  以 Epsilon 為終止條件的 Run() 
 103
 SA - TSP（advanced call） 
初始化：advanced call，目標函式評估次數 = 40000，Lk=500，初始的溫度
T0=100，Mu=0.8 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 105
 SA - RAP（advanced call） 
初始化：advanced call，Epsilon = 0.001，Lk=100，初始的溫度 T0=1000，
Mu=0.9 
 
 
 
 
 
 
 
 
 
 
 
 107
2.4.6  GRASP 
z GRASP 編碼 
GRASP 內建只有整數編碼，在程式呼叫的時候並不需要選擇編碼的型態，
整數編碼又可以依據重複或不可重複來區分，可分為不可重複的整數問題和可重
複的整數問題，其中可重複的整數問題又包含了布林編碼問題，例如 PAP 為可
重複的布林編碼問題，當解布林編碼問題的時候，只需要設定問題的下限和上限
各為 0 跟 1 即可。 
 
z Simple call 
GRASP 的 simple call 為呼叫基本的 Run()函式： 
 
 
輸入目標函式評估次數 MaxEvaluation 的參數後，演算法的整個演化過程即
會直到滿足評估次數為止。 
 
 
 
 
 
 
 
 
 
 
 
圖 56.  基本 Run() 
 109
假如使用者不曉得該如何完整的拼出「Repeatable」或是「Nonrepeatable」，
可以利用 GRASPOption class 來選擇 RepeatableOption 時則可再選擇
Repeatable 或是 Nonrepeatable。 
三. override fitness，使用者依據問題來決定解為實數或整數，像 TSP、TAP、RAP
這類的組合最佳化問題，這些所傳進的參數都是整數型態。 
四. 接下來就是演算法的流程，使用者只要設定 Initial 的參數和 Visibility 之後，
可呼叫 Run()並給予計算目標函數值的次數即可完成演算的流程。 
五. 演算法解各個問題的範例： 
 
 GRASP - TSP 
初始化：目標函式評估次數 = 40000 
 
 
 
 
 
 
 
 
 
 111
 GRASP - PAP 
初始化：目標函式評估次數 = 40000 
 
 
 113
 
 
使用者利用 SSOption class 的範例如下，假設使用者使用動態更新 RefSet。 
 
z 詳細描述 library 利用 SS 解問題的使用流程 
    以下 SS 針對連續以及離散問題來詳細描述我們的 library 該如何使用，從
include Metaheuristic 到建立物件的流程在 2.3 節（共同變數和呼叫）已經詳細說
明過了，接下來針對連續和離散問題在步驟上的不同加以說明。 
一. 離散問題（像是組合最佳化問題）可能必須讀進許多檔案，例如：TSP 必須
讀入城市之間的距離或是每個城市的座標，TAP 必須讀入通訊成本、執行成
本、cpu 記憶體上限、任務所需記憶體…等等。 
二. 初始化，在初始化方面因為 Init( )是多型的方法，Init( )要傳的參數照順序分
別為：初始解的數量、變數維度、變數下限、變數上限、問題的解為可重覆
或不可重複以及更新 RefSet 的方式。 
    不同的地方在於有些問題每個變數的範圍上限和下限都不一樣，像是
RAP，每個工廠的資源數上限和下限都不同，因此若每個變數範圍都不同，
則傳進來的變數上限和下限就必須用陣列；若每個變數範圍都相同，則只需
傳單一值進來即可。另外最後一兩個參數是根據問題的不同所傳進的參數也
有所不同，如果問題的解是可以重複的（例如連續函數問題、TAP、RAP），
傳進的參數為「Repeatable」；問題的解是不可重複的（例如 TSP），傳進的參
數為「Nonrepeatable」。假如使用者不曉得該完整的寫出「Repeatable」、
「Nonrepeatable」，則可以利用 TSOption class 來選擇 RepeatableOption，之後
再選擇 Repeatable 即可。 
三. override fitness，所傳的參數為實數解，對於各種編碼需求則對小數四捨五入
圖 64  Metaheuristic.SSOption.EncodingType 
 115
 
 
 SS - PAP（simple call） 
初始化 : simple call，選擇二元編碼以及可重複 
 
 
