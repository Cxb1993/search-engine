在此結案報告中，我們附上將於 12 月底於 2011 Cross-Strait Conference on Information 
Science and Technology and iCube (CSCIST 2011 and iCube 2011) 發表的論文，最後並
節錄一些影像拼接的成果。 
 
A. Paper to be published on CSCIST 2011 & iCube 2011 
 
KD-Tree based Nearest Neighbor Search Methods for 
High Dimensional Data 
 
Abstract: Finding nearest neighbors without training in advance has many applications, 
such as  image mosaic, image matching, image retrieval, and image stitching. When the 
quantity of data is huge and dimension is high, how to efficiently find the nearest 
neighbor becomes very important. In this article, we compare several variations of 
KD-trees in searching nearest neighbor problem. Tested by extended synthetic data bases, 
we concluded that KD-tree based methods work better for related data rather than 
randomly uncorrelated data. Also, multiple trees are more efficient than single tree 
searching under the same number of nearest neighbors. 
Keywords: feature point; KD-tree; Arbitrary KD-tree (KDA); nearest neighbor 
 
基於 KD 樹的高維度資料最近鄰居搜尋法 
 
摘   要 ：尋找事先未經訓練的最近鄰居，有許多的應用，例如: 馬賽克圖片，影
像匹配，影像檢索，影像縫合。當資料量是大量的而且資料的維度高，如何有效地
找到最近的鄰居就顯得非常重要。在這篇文章中，我們比較若干 KD-樹的變化型以
搜索最近鄰居。基於合成資料的測試，我們得出的結論是 KD 樹的方法運作在有相
關性資料比運作在不相連性的隨機資料好。此外，多棵樹比單棵樹在相同數目的最
近鄰居搜尋下更有效。 
         關鍵詞 ：特徵點; KD-樹; 任意 KD-樹 (KDA); 最近鄰居 
 
1 前言 
許多的日常影像應用技術，如：物件辨識(object 
recognition) 、 追蹤 (tracking) 、 影像的縫合 (image 
stitching)、融合(fusion)等，都是藉由特徵點(feature 
point or key point) 的偵測與比對來達成, 然而現實影
像中經常有著雜訊、物件被遮蔽、亮度改變、視角不
同、縮放、旋轉等問題存在，因此如何偵測與描述特
徵點使其具有強健性是許多研究的重要議題是個重
要的步驟。 
特徵點有不同的表示方式，除了傳統的邊
(edge) 、角點(corner) 以外，近期有[8]利用 histograms
去計算 local features 轉成 bag of words 來表示；[7] 先
找出 ROI(region of interest)，然後使用 Pyramid 
Histogram Of visual Words (PHOW) 和 Pyramid 
Histogram of edge-orientations gradients (PHOG)來表
示 visual words。這些方法在影像分類以及場景辨識上
有相當好的成效，然而他們都需要事先訓練以建立特
徵描述子的資料庫，才能與測試的影像進行比對，進
而得到準確的比對結果[1][3][4][6][7]。對於不在訓練
範圍的影像將無法正確比對，造成影像比對的資料有
所限制。 Lowe 所提出的 Scale-Invariant Feature 
Transform (SIFT)則是不需要事前訓練的技術，可以被
用來偵測並描述影像中的局部特徵。利用 DoG 
(difference of Gaussian)和 尺度空間(scale space)，
SIFT 特徵點對於影像的放大縮小、旋轉，甚至光線、
雜訊、少許視角改變都具有強健性，是目前廣被使用
的技術[2][5][6][8][10]。要實現上述的影像應用還必須
藉由特徵點比對(Feature matching)。由於特徵點的個
數往往達數百個甚至上千個，再加上高維度的複雜
性，增加了特徵比對的困難度。 
 
2 特徵點比對方法 
演算法, 平分每一層左右兩邊的樹是利用先取出資
料中最大的變異數再從這最大變異數的維度算出中
間值下去分。相反地, The randomized KD-Trees 是任
意從前 5 個維度（具有最大變異數的維度）挑選維度
下去分,再從這被選中的維度,依此維度的中間值把
資料分成左右兩邊,重複上述的步驟, 建構出樹的架
構。由於選擇切割的維度時是在 5 個維度間任意選
取，因此不同選擇就得到不同的樹結構，因此可以很
容易的得到多棵樹的結構。 
3 實驗結果 
本文所做的實驗是使用 Matlab 和 C 的程式語言, 
於 Apple Mac Pro 電腦上，進行所測試的資料分兩類，
平均分配 (uniform)的方式以及常態分配 (normal)的
方式產生。資料的維度分 500, 200, 以及 100, 資料
筆數分 2000 和 500。平均分配的資料範圍是在 0-100
之間，而常態分配的資料範圍是平均值 50 標準差
25(μ=50,σ=25) 。測試的方法分單棵樹與多棵樹，說
明如下： 
z 單 棵 樹 ： 我 們 比 較 傳 統 的 KD-Tree ，
KD-Tree(arbitrary)，和 Randomized KD-Trees，
在搜尋最接近的鄰居數目 K 以 1、10、20、50、
100。 
z 多棵樹：利用 Randomized KD-Trees 來做 10 棵
樹(KDR10)和 20 棵樹(KDR20)的比較最近鄰居
的數目 K，而 K 是以建立多少棵樹的數目加上
要找出多少的鄰居數, 如 10 棵樹來說, K 就是
以 10、20、50、100, 而 20 棵樹來說, K 就是
以 20、50、100。 
所有本文中的單棵 KD-Tree 和多棵 KD-Trees 都
是以 Best-Bin-First (BBF) 和維持一個 priority queue
的方式[19],找出最近的鄰居數目, 以利於之後做影
像比對和拼接。BBF 是一種應用在搜尋演算在高維度
的空間裡, 它可以有效率地找出最鄰近的鄰居[19]。
在 KD-Tree 的應用中，BBF 利用一個 priority queue 
記錄所有query point對經過的節點的距離並予以排序, 
而下一次回溯時便會根據priority queue中最近的節點
的位置，到其另一（尚未走過的）超空間中繼續尋找
最近鄰居。在本實驗中，如果多棵樹仍以一個 priority 
queue 來記錄 query point 在每一棵樹與節點的距離，
回溯時則依最近距離的那棵樹的那個節點繼續尋找
最近鄰居。以這樣的方式，可以考慮多棵樹的最佳情
形，增加找到最近鄰居的機率。當然，所付出的代價
是要建構多棵樹的時間與記憶空間。 
實驗結果整理於下，在 Figure 2 (維度 D = 500)、
Figure 3 (維度D = 200)、Figure 4 (維度D = 100)中, 都
針對不同維度二種不同的合成資料(uniform [0,100]& 
normal  (μ=50,σ=25) ),在 2 組資料量 (N=500 & 
N=2000)的情況下, 先建構好本文中所提的單棵
KD-Tree和多棵KD-Trees, 分別搜尋出最近鄰居數目
K。在此，最近鄰居數目即是在樹中所找到的葉子資
料點(leaf nodes)。單棵樹的 K 以 1、10、20、50、100
為基礎, 而多棵樹的 K 以 10、20、50、100 (10 棵樹)
和 20、50、100 ( 20 棵樹)為主,我們各方法每一回合
都做 100 次,是利用 100 個 query points 分別去找出各
方法所需要的 K,再把輸出結果統計出來取平均, 與
linear search 比較。可是在 KDA1 和 KDR1 針對一個
query 重複搜尋 5 次在不同的樹狀結構，因為這兩種
都是隨機的方式，為了求取公正的準確度，做一次是
不夠的。 
再來，從這 12 個分析圖中，可以觀察出高斯分
佈的合成資料會比平均分佈的準確度來的好，因為高
斯分佈的資料比較集中有規律性；而平均分佈是零散
隨機的分配，沒有一定的規律存在。在本文所提出的
搜尋方法上,以合成資料分析出單棵樹 ( KD, KDA1, 
KDR1 ) 的表現以 KD 與 KDR1 的表現不相上下，然
而當回溯次數增加時，KDA1 的表現也逐漸改善；多
棵樹 ( KDR10, KDR20 )以 20 棵勝出，但是差異並不
是很明顯尤其是比較 100 個資料點的時候(100 leaf 
nodes, when K = 100 )。如果從 K-NN 的準確度中,單
棵樹和多棵樹合併起來比較，20 棵的準確度比較高，
比較有效率。 
4 結論與未來方向  
我們提出一個 Arbitrary KD-Tree (KDA) ,用隨機
的方式去取維度再算中間值, 與傳統的 KD- Tree 不
同, 目前實驗結果顯示，KDA 的效果並不如其他的
方法，但是此方法在建構上十分迅速（不需要針對每
一個維度計算變異量），而且當回溯數量高的時候，
它的表現與其他比較的方法亦相差不遠。接下來,我
們將會進階到多棵樹,也就是建構 KDA10 & KDA20
並且與 KDR10 & KDR20 比較成效。 
高 維 度 資 料 一 向 具 有 挑 戰 性 (curse of 
dimensionality)，然而處理高維度的資料又是不可避免
的工作，如基因資料，一個人類染色體的基因數在二
萬個以上，表示一筆人類基因資料的維度就是二萬多
 6
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
(a)  Uniform (dim=200, 2000 data) (b) Normal (dim=200, 2000 data) 
 
 
(c)  Uniform (dim=200, 500 data) (d)  Normal (dim=200, 500 data) 
0
0.1
0.2
0.3
0.4
0.5
1 10 20 50 100
Pr
ec
is
io
n 
ra
te
K(KNN)
KD
KDA1
KDR1
KDR10
KDR20
  
(a)  Uniform (dim=100, 2000 data) (b)  Normal (dim=100, 2000 data) 
  
(c)  Uniform (dim=100, 500 data) (d)  Normal (dim=100, 500 data) 
圖 4. 在維度 D=100 和資料量 N=2000&500 條件下，(a)(c)是平均分佈的資料，(b)(d)是高斯分佈的資料，用單棵樹和多棵樹去搜尋
出 KNN 和統計其準確度。圖表橫軸是所考慮的 k 鄰居數目，縱軸是 k 鄰居中包含真正最近鄰居的正確率。 
圖 3. 在維度 D=200 和資料量 N=2000&500 條件下，(a)(c)是平均分佈的資料，(b)(d)是高斯分佈的資料，用單棵樹和多棵樹去搜尋
出 KNN 和統計其準確度。圖表橫軸是所考慮的 k 鄰居數目，縱軸是 k 鄰居中包含真正最近鄰居的正確率。 
 8
 
 
 
 
 
(a) 5 張原影像 (b)利用此 5 張影像的拼接結果 
 
 
 
 
 
 
     
 
 
   
 10
 
Uniform (dim=200, 2000 data) Normal (dim=200, 2000 data) 
Uniform (dim=500, 2000 data) Normal (dim=500, 2000 data) 
KDAn 代表以 KDA 的方式建立 n 棵樹; KDRn 代表以 KDR 的方式建立 n 棵樹. 當資料量高 (2000 筆 在不同的維度下 200 
& 500) 在找最近 k 鄰居 (K=20,50, 100, 200) 時，無論資料是以 Uniform  or  Normal 的方式合成的，KDA10 & KDA20 都
表現的比 KDR10 & KDR20 來的好。 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：顏淑惠 計畫編號：99-2221-E-032-060- 
計畫名稱：一個強健有效率的特徵萃取比對系統─應用於環場影像 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件 1 
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
