 1
目  錄 
摘  要 .................................................................................................................................................. 2 
一、緒論 .............................................................................................................................................. 2 
二、系統架構 ...................................................................................................................................... 4 
三、離散餘弦轉換 .............................................................................................................................. 5 
四、SOM 與向量量化編碼 ................................................................................................................ 6 
五、影像重建與效能評估 .................................................................................................................. 7 
六、模擬結果 ...................................................................................................................................... 7 
參考文獻 .............................................................................................................................................. 9 
計畫成果自評 .................................................................................................................................... 10 
 4
簡化編碼和壓縮資料量的目的，這亦是不同
於純量編碼之處。向量編碼的關鍵在於編碼
簿的好壞，這牽涉到編碼簿本身的大小、碼
向量的維度以及編碼簿中碼向量的通用性，
而讓編碼簿具有較佳分類碼向量一直是最終
的目標。因此，其研究的重點和可能改進之
處不外乎能夠快速搜尋的向量量化、碼向量
索引值的壓縮編碼以及混合型式的向量量化
這幾個方向。 
類神經網路(Artificial Neural Networks，
ANN)[16]-[18]的發展提供了向量量化一個非
常有效的工具，並能增進編碼簿的能力與強
健性(Robustness)。不同於以上之方法，類神
經網路是以模擬人腦思維的模式所發展的理
論，具有強大的學習 (Learning)、容錯(Fault 
Tolerance)、平行處理(Parallel Processing)和聯
想記憶(Associative Memory)等能力，可廣泛
地應用在不同的領域當中，例如影像處理、
信號處理、型態識別、系統鑑別、及非線性
系統最佳化等，經多年的驗證都有不錯的成
果產生。 
一般的類神經網路是由多個神經元
(Neurons)組成，輸入資料在乘上連接權值後
經過一非線性之轉換函數而得到單層之輸
出，並以層層相連的方式，如輸入層、隱藏
層及輸出層等串接組成一網路架構。在神經
生理學研究發現，人腦由巨量的神經細胞組
成，但並非所有的神經細胞都起同樣的作
用；不同空間區域的神經細胞分工有所不
同，各區域對應不同的外部刺激；相似的外
部刺激在大腦的相鄰近位置上會引起最大的
響應，因此輸出神經元之間發生空間藕合，
產生了交互作用。據此，Kohonen 於 1980
年[19]提出了另一種類神經網路的架構，稱之
為自組織特徵映射(Self-Organization Feature 
Map；簡稱為 SOFM 或 SOM)，來模擬前述
人腦的相鄰神經細胞間的藕合功能。 
SOM 具有「物以類聚」的特性，各神經
元間會相互影響，以競爭性學習(Competitive 
Learning) 的 方 法 和 優 勝 者 激 發
(Winner-Take-All)的模式來決定網路中各神
經元的狀態。訓練的過程中，輸出層具有網
路拓樸(Topology)，鄰近區域(Neighborhood)
的輸出神經元間會相互影響；在學習完畢
後，其輸出神經元相鄰近者會具有相似的響
應，也具有相似的連結權值。鄰近區域間交
互作用的關係，以網路拓樸決定鄰近區域的
神經元方向位置，而優勝神經元鄰近的其他
神經元，則依「物以類聚」的特性與優勝神
經元同時做移動，以達到分類的目的。SOM
是採用無監督式學習 (Unsupervised Neural 
Network)的網路模式，從原始輸入資料中取
得訓練範例，而從中學習範例的內在聚類
(Clustering)規則，以應用於其他的問題。因
此在訓練完成之後，能對全新的輸入變數推
論或分類它與那些訓練範例隸屬於同一聚
類，極為適合在聚類分析和形體識別的應用
上。因而利用 SOM 類神經網路作分類的最大
優點之一是不需事先知道輸入原始資料中特
徵歸屬(Membership)的情況。在向量量化問
題的應用上此點是相當重要的，不僅對不同
的輸入資料能有正規化(Generalization)的效
果，且能對量化後的空間維度作彈性的分配
與調整。 
雖然在應用 DCT 和類神經網路等方法
於影像壓縮已有許多之探討[20]-[23]，本研究
主要之貢獻與新創之部分在於結合各方法之
優點，形成一套整合型之處理過程；此外加
入分頻處理的觀念，能更細緻的分析影像的
內容。針對轉換後特徵顯著的部分保留較完
整的訊息，以提昇處理之品質；而其他部份
則做較高幅度之壓縮，以提高壓縮比，並改
善系統之效率。因而本研究在品質不變的前
提下，能有效提高資料傳輸之速度並降低資
料儲存所須之空間。 
 
二、系統架構 
本研究所提出之整合式分頻 DCT 和以
SOM 做向量量化架構下的失真壓縮流程如
圖 1 所示。 
主要分成幾個部份。第一部份是前處
理，包含影像向量或區塊化、DCT 與低通濾
波器。影像向量化是把影像分割為固定大小
的區塊，並針對每一區塊做個別處理，以降
低運算之複雜度，這個過程一般稱之為向量
化(Vectorization)，而 DCT 則是將向量化後的
影像方塊進行轉換，以得到影像方塊的頻域
資訊，這些頻域資訊在經過分頻與低通濾波
的處理才完成初步的資料簡化；上述步驟我
們統稱為前處理(Preprocessing)。第二個部份
則是依據 SOM 的訓練結果來完成向量量
化，編碼簿和碼向量索引即是在這個階段產 
 6
單一頻率，即是該頻率之基底函數以相對應
之轉換係數加權後的結果。採用 SBC 的優點
在於依照每個次頻帶而使用不同數量的位元
數，故每個次頻帶的量化係數及重建誤差就
可分別控制，因此重建誤差的頻譜形狀可以
控制成頻率的函數。依此推論，我們可以依
據每個次頻帶的特性使用不同的編碼方法。
在比較低頻的次頻帶中，因為它含有原訊號
的大部份能量，因此我們可以使用較高的位
元率來編碼；一般在最低頻的次頻帶，使用
無失真編碼法即可完整重建該次頻帶。至於
高頻的次頻帶，它所含的能量很少，因此可
以使用低位元率做編碼，為較粗糙的壓縮編
碼方式。 
基於二維 DCT 轉換後具有分離高低頻
能量的特性，以 8×8 的方塊為例，其頻域由
低頻至高頻的排列方式如圖 2 表示。左上角
0 的位置，一般稱為直流係數(DC)；1 至 63
稱為交流係數(AC)；由 0 至 63 依序排列方
式，呈鋸齒狀(Zig-Zag)或"之"型排列。 
以 DCT 轉換後的結果來觀察，大部分影
像方塊約有 80%以上的能量是集中在 DC 部
分，為避免較高的失真，可把 DC 直流係數
直接編碼後傳遞出去或儲存起來，而 AC 交
流係數則被用來作進一步的處理。因直接傳
送 DC 的數值在過程上會造成嚴重負擔，故
Cham[27]提出一種方法來已 AC 值估算 DC
值，使 DC 值完全不用送出，大幅降低了
BPP(Bit per pixel)，故本方法亦將於本計劃中
做驗證。 
0 1 5 6 14 15 27 28
2 4 7 13 16 26 29 42
3 8 12 17 25 30 41 43
9 11 18 24 31 40 44 53
10 19 23 32 39 45 52 54
20 22 33 38 46 51 55 60
21 34 37 47 50 56 59 61
35 36 48 49 57 58 62 63
 
圖 2  空間頻率係數排列順序。 
此外再就 AC 之係數觀察，影像大部份
的資訊、特徵和能量集中在係數矩陣的左上
角即低頻部分，而較少的影像特徵是分散在
高頻的部分；故就影像壓縮而言，當我們著
重於影像的重建品質時，可保留較多的高頻
係數以獲得較多的影像特徵和資訊；若著重
的是壓縮比率，則需保留最少的低頻係數做
為重建端的影像訊息來源。保留係數的方法
只需以一低通濾波器即可完成。利用低通濾
波器不僅能控制被保留係數的數量，又能減
低影像向量的維度，以利於降低向量量化搜
尋空間的複雜度，並增加編碼簿的分類能力。 
 
四、SOM 與向量量化編碼 
SOM 類神經網路的基本架構不同於傳
統的類神經網路架構，它只需要輸入層與輸
出層的結構，如圖 3 所示。輸入層即為訓練
樣本的輸入向量，其神經元數目依各問題輸
入特徵向量而不同；輸出層則代表聚類
(Clustering)，其神經元數目則可依所期望之
輸出種類來決定。對於影像的向量量化而
言，輸入向量為影像向量或特徵向量，而經
訓練之後輸出層聚類的結果即形成編碼簿，
每一個輸出神經元所代表的就是編碼簿中的
碼向量索引，而各神經元所對應之碼向量即
為連結權值。 
 
 
 
 
 
 
 
 
 
圖 3   SOM 類神經網路的網路架構 
 
SOM 是採取非監督式的學習演算法，將
高維度的輸入向量映射至一維或二維的輸出
神經元陣列，針對各輸入向量不需事先確定
所求的分類輸出結果，由神經網路自身對輸
入資料作出綜合、歸納和統計，調整各神經
元間的連結權值，使網路自適應地發展成為
對不同輸入信號模式作出特殊的響應。網路
拓樸是指輸出神經元的排列方式，一般大多
採二維的矩形或六角形輸出模式。SOM 的輸
出層神經元間相對位置具有相互影響的意義
存在，對於不同的拓樸型式會有不同的分類
結果。我們可以將輸入向量視為 n 維的影像
向量，映射至一至二維的輸出神經元陣列，
藉由這個映射的動作，將原本存在於訓練樣
本輸入向量之間的相對距離關係，能保留在
輸出神經元之間。簡單地說，彼此相鄰近的
連結權值 
輸出層: 代表聚類 
(二維矩形拓樸座標)
 拓樸座標
x軸 
拓樸座標
y軸 
輸入層:輸入向量
 8
為對 Lena 和 Cameraman 保留 8 個 DCT 係數
值的比較。當保留 8 個 DCT 係數時，其還原
之PSNR值仍可維持37dB以上的高重建品質
影像。由此可推得 DCT 影像轉換的效率極
高，原本影像向量維度是 4×4=16，只要取 8
個維度即可，失真完全是在可以接受的範圍
之內。被保留的係數將做為 SOM 類神經網路
的輸入向量。 
表 1  取 8 個 DCT 係數後還原之比較。 
Lena Cameraman 
RMSE PSNR RMSE PSNR
2.915 38.8381 1.619 43.945
單位：PSNR（dB） 
在 SOM 訓練樣本的選取上，主要採自類
型不同的影像特徵，目的在於產生通用的編
碼簿(Global Codebook)，如此所得的編碼簿
才能保證各種影像都有平均水準的效率。在
編碼簿大小的選取上，我們選擇 256 大小的
編碼簿作為模擬結果分析的依據，意即需要
8 位元來編所有的碼向量，因此其位元率(Bits 
Per Pixel)為 00.5bpp。 
DCT 轉換後保留之係數是直接送至
SOM 做分類或向量量化的工作，我們選取了
上百個具代表性的影像方塊來訓練 SOM，並
建立編碼簿。 
若加入分頻處理的過程則能得到更好的
結果。對 Lena 和 Cameraman 模擬測試的結
果分別如表 3 和表 4 所示。利用分頻編碼的
觀念，將 DCT 轉換後的高低頻係數分離，針
對轉換後大部份影像特徵集中在 DC 係數
值，所以 DC 係數值我們選擇不做任何處理，
直接送至解碼端；對於 AC 係數值，做向量
量化處理，同樣利用 SOM 類神經網路訓練生
成 AC 編碼簿。若同樣依照低通濾波保留序
號在前面的八個轉換後之係數值，採取分頻
編碼的壓縮架構其重建品質可高出 1~3dB，
主要的原因在於我們選擇不對 DC 係數值做
任何處理的緣故。再者，保留相同的轉換係
數值，對採用分頻編碼的壓縮架構而言，其
SOM 類神經網路的輸入向量維度因取出 DC
係數值而少了一個維度，因此，SOM 類神經
網路的輸入向量維度減少，權值空間較為平
滑，學習與訓練過程的運算量與複雜度降
低，所以比較容易尋得最佳化的編碼簿，這
也是本計劃採用分頻編碼壓縮架構的目的。
雖然位元率提高了約 0.5 個 bpp，也就是說以
保留 8 個位元來編所有的碼向量，其位元率
為 1bpp。但以此相似壓縮比的程度而言，單
純使用 DCT 是無法達到如此高的 PSNR。 
表 2  分頻重建 Lena 後之結果。 
 Codebook Size PSNR 
SOM 256 29.0543
SOM with 
Sub-band 256 31.1021
 
表 3 分頻重建 Cameraman 後之結果 
 Codebook Size PSNR
SOM 256 28.4895
SOM with 
Sub-band 256 31.0954
圖 4 至圖 5 分別為 Lena 和 Cameraman
在不同狀況下之重建影像。圖 4 為使用
Kohonen 之 SOM 編碼，取 256 個 codeword
之結果，PSNR 為 32.41dB；圖 5 為使用
Kohonen 之 SOM 編碼，取 256 個 codeword
外加分頻處理的結果， PSNR 提昇至
36.53dB。無論就數字上或視覺上的觀察，我
們都可發現加了分頻處理會使 PSNR 大幅提
昇，同時因為 256 個 codeword 和 128 個
codeword 之 PSNR 並無太大差異，在 VQ 的
複雜度上亦能降低許多。 
 
圖 4  利用 SOM 與 256 個 codeword 重建
Lena 之影像。 
 10
Proceedings of 2002 International Confe-
rence Machine Learning and Cybernetics, 
vol. 4, pp. 1778-1780, Nov. 2002. 
[12] N. M. Nasrabadi and R. A. King, “Image 
Coding using Vector Quantization: a re-
view,” IEEE Trans. on Communication, 
vol. 36, no. 8, pp. 957-971, Aug. 1988. 
[13] Dong Sik Kim, and Sang Uk Lee, “Image 
Vector Quantizer Based on a Classifica-
tion in the DCT Domain,” IEEE, Trans. on 
Communication, vol. 39, no. 4, Apr 1991. 
[14] R. M. Gray, “Vector Quantization,” IEEE 
Acoust., Speech, Signal Processing Maga-
zine., pp. 9-31, Apr. 1984. 
[15] A. Gersho and Robert M. Gray, Vector 
Quantization and Signal Compression.  
London:Kluwer, 1992. 
[16] D. E. Rumelhart, G. E. Hinton and R. J. 
Williams, Parallel Distributed Processing, 
Cambridge, Massachusetts: The MIT 
Press, 1986. 
[17] R. P. Lippmann, “An Introduction to 
Computing with Neual Nets,” IEEE ASSP 
Magazine, pp. 4-22, Apr. 1987. 
[18] S. Haykin, Neural Networks: A Compre-
hensive Foundation, 2nd ed., Prentice Hall, 
1998. 
[19] T. Kohonen, Self-Organization Maps, 
Springer-Verlag, New York, 1997 
[20] K. S. Ng and L. M. Cheng, “Artificial 
Neural network for Discrete Cosine 
Transform and Image Compression,” 
Proceedings of the 4th IEEE ICDAR, pp. 
675-678, 1997. 
[21] Veleva, L.V.; Kunchev, R.K. ,“Adaptive 
speech coding with DCT and neural net 
vector quantisation,” Electronics Letters 
vol. 29, no. 8, pp.704–705, 15 April 1993. 
[22] Harandi, M.T.; Gharavi-Alkhansari, M., 
“Low bitrate image compression using 
self-organized Kohonen maps,” Proceed-
ings of 2003 International Conference on 
Image Processing, vol. 2, pp. II-267-70, 
Sept. 2003. 
[23] Chang, P.R.; Hwang, K.S.; Gong, H.M., 
“A high-speed neural analog circuit for 
computing the bit-level transform image 
coding,” IEEE Transactions on Consumer 
Electronics, vol. 37,  no. 3, pp. 337-342, 
Aug 1991. 
[24] Da Silva, E.A., Ghanbari, M., ”A DCT- 
based aliasing cancellation method in 
subband coding,” IEEE Transactions on 
Circuits and Systems for Video Technology, 
vol. 3, no. 5, pp. 384-387, Oct. 1993. 
[25] Sundsbo, I.; Ramstad, T.A., “Synthesis 
filterbank with low hardware complexity 
for subband image coding,” IEEE Trans-
actions on Image Processing, vol. 7, no.12, 
pp. 1717-1724, Dec. 1998. 
[26] Mukherjee, J.; Mitra, S.K.; “Image resiz-
ing in the compressed domain using sub-
band DCT,” IEEE Transactions on Cir-
cuits and Systems for Video Technology, 
vol. 12, no. 7, pp.620-627, July 2002. 
[27] Tse, F.-W.; Cham, W.-K.; Liu, J.Z.; “DC 
coefficient restoration technique and its 
application to image coding,” IEE Pro-
ceedings on Vision, Image and Signal 
Processing, vol. 149, no. 5, pp. 272-282, 
Oct. 2002. 
 
計畫成果自評 
本研究以神經網路之向量量化與分頻
DCT 為基礎，對影像壓縮之法則開發及其
效能加以研究。在資訊時代科技不斷日新月
異的今天，數位影像的應用將更加廣泛與需
要，但因有許多瓶頸的存在使得很多領域都
尚待推廣與開發，例如影音電話，無線影音
傳輸，和影像資料庫之儲存等，若影像壓縮
技術在運算速度、壓縮比、信號雜訊比與功
率消耗等功能上能夠更進一步的提昇，則許
多應用上的問題都將能一一突破。本研究所
提出之方法整合了現今所使用各種方法之優
點，並改進了其缺點與限制，大幅提高壓縮
比與信號雜訊比，因而在資料之傳輸上能夠
提昇速度，在資料之保存上亦能降低儲存所
須之空間，因此本研究對影像處理的基礎理
論和實際應用都會有長足的貢獻。而神經網
路的並行處理架構能以即時的方式處理問
題，只需要簡單的硬體設備與法則就能快速
的執行。 
本計劃於 DCT 分頻編碼與 SOM 壓縮上
成功達成預期目標，並得到優異之結果，有
效提升壓縮比與運算速度。然而設備採購因
中信標重開因素而延遲取得，加上部份程式
設計工作不如預期來的順利，故本計劃原想
在小波轉換上亦與 DCT 一併作比較，但此部
