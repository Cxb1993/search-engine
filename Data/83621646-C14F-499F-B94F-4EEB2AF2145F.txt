Fig. 1. Block diagram of an MFCC front-end inserted with a frequency
masking module. Note that the frequency masking operation can be iterated.
• p[n] is processed to obtain the spectral mask M [n], i.e.,
M [n] =
∑
m
p[m]ψ(Ω(ωn)− Ω(ωm))∑
m
ψ(Ω(ωn)− Ω(ωm))
, (3)
where ψ(Ω) is the critical-band masking curve [9]
ψ(Ω) =


0, Ω < −1.3,
102.5(Ω+0.5), −1.3 ≤ Ω ≤ −0.5,
1, −0.5 < Ω < 0.5,
10−1.0(Ω−0.5), 0.5 ≤ Ω ≤ 2.5,
0, Ω > 2.5.
(4)
• The masked spectrum is the obtained by
pˆ[n] = max {p[n],M [n]} . (5)
In (5), spectral values above the spectral mask remain un-
changed, while values under the mask are replaced by the
masking values. That is the essence of masking.
The proposed correlational masking effects is implemented
through the modification of the masking curve. Note that the
frequency masking stage can be applied iteratively as shown
in Fig 1.
III. MODEL ANALYSIS
A. Model for the Basilar Membrane
Different parts of the basilar membrane respond differently
to the audio signals. This is known as the tonotopic property.
In particular, the position of the maximum displacement of
the basilar membrane depends on the spectral content of the
incoming signal. The detailed relation of this dependency has
been described by Be`ke`sy [10], [11].
In this paper, we propose to model the basilar membrane
as a cascade system of simple harmonic oscillators as shown
in Fig 2. We are interested in the coupled motions of the
oscillators under the external force caused by the fluids in the
cochlear.
B. Damped Simple Harmonic Oscillation
The driving force for the oscillators is assumed to be a
time-varying short-time stationary signal f(t; τ), where τ is
the frame index, t is the sample index.
Note that f(t; τ) can be seen as a finite-duration signal or
one period of a periodic extension. Using the Fourier analysis,
we can decompose f(t; τ) by the sinusoidal functions
f(t; τ) =
∑
n
cn(τ) cos(ωnt+ θn(τ)), (6)
where ωn = 2piT n = ω0n, with T being the frame size. Since
it is algebraically convenient to work in the complex domain,
we re-write (6) as
f(t; τ) = Re
{
f˜(t; τ)
}
= Re
{∑
n
c˜n(τ)e
jωnt
}
, (7)
where c˜n(τ) = cn(τ)ejθn(τ).
When the external force is a complex exponential function
of frequency ω, it can be shown that the magnitude response
and the phase shift of a damped simple harmonic oscillator
with mass m, natural frequency ω0, and damping coefficient
γ are respectively
A(ω) =
1
m
1
|ω20 − ω
2 + j2γω|
, (8)
and
θ(ω) = tan−1
(
2γω
ω2 − ω20
)
. (9)
Neglecting the phase shift, the magnitude response of an oscil-
lator in frame τ with the driving force (6) is the superposition
of the contributions of all complex exponentials
A(τ) =
∑
n
cn(τ)
m
1
|ω20 − ω
2
n + j2γωn|
. (10)
Note that m, γ, and ω0 are dependent on the oscillator.
C. Correlational Masking Effect
From (10), the magnitude response for oscillator k is
Ak(τ) =
∑
n
cn(τ)
mk
1
|ω20,k − ω
2
n + j2γkωn|
(11)
The resonant frequency ω∗k for oscillator k is defined to be the
frequency with the maximum magnitude response. According
to (8),
ω∗k =
√
ω20,k − 2γ
2
k. (12)
Singling out the term r(k) with frequency closest to ω∗k, i.e.,
ωr(k) ≈ ω
∗
k,
we can re-write the summation in (11) as
Ak(τ) ≈
cr(k)(τ)
mk
1
|ω20,k − ω
∗
k
2 + j2γkω∗k|
+
∑
n6=r(k)
cn(τ)
mk
1
|ω20,k − ω
2
n + j2γkωn|
,
(13)
Table II and Table III list the recognition accuracies for it-
erative frequency masking operations using CMC and CRMC.
One can see that the recognition performance of both CMC
and CRMC further improves with the number of iterations.
For the CMC-case, with 5 times of iteration, we get the
most relative improvement of 28.3%. For the For the CRMC-
feature, with 3− 4 times of iteration, we get the most relative
improvement of 30.3%. The results show that the mismatch
between the clean and the noisy features are reduced with
iterative masking.
TABLE II
Percentage word accuracy rates of the Aurora 2.0 clean-training tasks with
the 0− 20 dB SNR test data with iterative frequency masking using the
critical-band masking curve (CMC). The results of different numbers of
iteration are compared.
no. iter. Set A Set B Set C Avg. rel. imp.
baseline = 61.3 55.8 66.1 60.1 =
CMS = 66.2 70.8 64.9 67.8 19.3
CMS+CMC 1 68.1 72.2 67.1 69.6 23.8
CMS+CMC 2 69.1 73.0 68.3 70.5 26.1
CMS+CMC 3 69.9 73.2 69.4 71.1 27.7
CMS+CMC 4 70.1 73.0 69.6 71.2 27.8
CMS+CMC 5 70.5 73.0 69.9 71.2 28.3
TABLE III
Percentage word accuracy rates of the Aurora 2.0 clean-training tasks with
the 0− 20 dB SNR test data with iterative frequency masking using the
correlational masking effect (CRMC). The results of different numbers of
iteration are compared.
no. iter. Set A Set B Set C Avg. rel. imp.
baseline = 61.3 55.8 66.1 60.1 =
CMS = 66.2 70.8 64.9 67.8 19.3
CMS+CRMC 1 68.9 72.6 68.2 70.2 25.9
CMS+CRMC 2 70.1 73.0 69.5 71.1 27.7
CMS+CRMC 3 71.2 73.9 71.0 72.2 30.3
CMS+CRMC 4 71.2 73.6 71.3 72.2 30.3
CMS+CRMC 5 70.9 73.0 71.2 71.8 29.4
V. CONCLUSION AND FUTURE WORK
In this paper we investigate a noise-robust front-end pro-
cessing method based on frequency masking effects. We use
a cascade system of simple harmonic oscillators to model
the basilar membrane in the human auditory system. The
coupled motion of the oscillators induces the correlational
masking effect. Based on the correlational masking effect,
we implement a signal-processing module to simulate the
frequency masking effect.
We evaluate the noise-robustness of our method on the
Aurora 2.0 mismatched tasks. Results show that the proposed
method outperforms the well-known critical-band masking
curve. Moreover, iterative operation of the proposed frequency
masking further increases the improvement.
In the future, it will be interesting to investigate different
aspects of the coupled motion. In this paper, we argue that the
motions of the coupled oscillators are correlational. However,
we can also argue that there is a causal factor in the coupled
motion since the oscillators are physically connected. Finally,
it may be possible to combine both aspects for a comprehen-
sive auditory model for frequency masking to achieve noise-
robustness.
REFERENCES
[1] H. Hermansky and N. Morgan, “RASTA processing of speech,” IEEE
Transactions on Speech and Audio Processing, vol. 2, no. 4, pp. 578–
589, 1994.
[2] D. Kim, S. Lee, and R. Kil, “Auditory processing of speech signals
for robust speech recognition in real-world noisy environments,” IEEE
Transactions on Speech and Audio Processing, vol. 7, no. 1, pp. 55–69,
1999.
[3] L. Turicchia and R. Sarpeshkar, “A bio-inspired companding strategy
for spectral enhancement,” IEEE Transactions on Speech and Audio
Processing, vol. 13, no. 2, pp. 243–253, 2005.
[4] H. Fletcher, “Auditory patterns,” Reviews of Modern Physics, vol. 12,
no. 1, pp. 47–65, 1940.
[5] J. Johnston, “Transform coding of audio signals using perceptual noise
criteria,” IEEE Journal on selected areas in communications, vol. 6,
no. 2, pp. 314–323, 1988.
[6] H. Fletcher and W. Munson, “Loudness, its definition, measurement and
calculation.” Journal of the Acoustical Society of America, vol. 5, pp.
82–108, 1933.
[7] K. Paliwal and B. Lilly, “Auditory masking based acoustic front-end for
robust speech recognition,” in Proceedings of IEEE TENCON, vol. 1,
1997, pp. 165–168.
[8] K. Paliwal, B. Shannon, J. Lyons, and K. Wo´jcicki, “Speech-Signal-
Based Frequency Warping,” IEEE Signal Processing Letters, vol. 16,
no. 4, p. 319, 2009.
[9] H. Hermansky, “Perceptual linear predictive (PLP) analysis of speech,”
Journal of the Acoustical Society of America, vol. 87, no. 4, pp. 1738–
1752, 1990.
[10] G. Von Be´ke´sy and E. Wever, Experiments in hearing. McGraw-Hill
New York, 1960.
[11] L. E. Kinsler, Fundamentals of acoustic. John Wiley and Sons, 1982.
[12] D. Pearce and H. Hirsch, “The AURORA experimental framework for
the performance evaluation of speech recognition systems under noisy
conditions,” in ICSA ITRW ASR2000, September 2000.
[13] S. Furui, “Cepstral analysis technique for automatic speaker verifica-
tion,” IEEE Transactions on Acoustics, Speech and Signal Processing,
vol. 29, no. 2, pp. 254–272, 1981.
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳嘉平 計畫編號：98-2221-E-110-064- 
計畫名稱：聽覺生理分析與心理聲學實驗於自動語音辨識系統噪音強健性之應用 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
