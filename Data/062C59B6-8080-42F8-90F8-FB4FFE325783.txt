A CONTENT AUTHENTICATION SCHEME FOR IMAGES/VIDEOS
BASED ON FEATURE EXTRACTION AND DIGITAL WATERMARKING
Po-Chyi Su, Hung-Min Chang and Ming-Lun Li
Department of Computer Science and Information Engineering
National Central University, Jhongli, Taiwan
ABSTRACT
A content authentication scheme for digital images/videos
by using reliable feature extraction and digital watermarking
is proposed in this research. In order to avoid the content
from being unnoticeably tampered by using digital editing fa-
cilities, reliable visual features are extracted as the authentica-
tion code and transmitted along with the images/videos. The
features are sensitive to malicious modification of data but are
resilient to allowed lossy compression. The integrity of con-
tent in a picture or a frame can thus be guaranteed by com-
paring the similarity between the transmitted authentication
code and the extracted feature. For videos, we further embed
digital watermarks into frames to ensure the frame order so
that frame dropping, swapping or insertion can be reflected
from the watermark detection. Assuming that video surveil-
lance systems will adopt H.264/AVC for storing/transmitting
the recorded visual information, we develop the digital water-
marking algorithm under the structure of this state-of-the-art
video codec. Experimental results will show the feasibility of
the proposed scheme.
1. INTRODUCTION
The creation and distribution of digital contents have become
increasingly convenient these days thanks to the rapid growth
of digital signal processing techniques and broadband net-
working infrastructure. Editing digital images/videos, which
was thought to be only achievable by professionals, can now
be done with inexpensive and widely available software and
hardware. This convenience brought by the digital technol-
ogy definitely benefits most of the content users but may raise
certain concerns. First of all, protection of the copyrighted
multimedia materials, including digital music, movies or even
books, without deterring the users from embracing the digi-
tal media, remains an issue to investigate. The other issue is
related to content authentication. The integrity of digital im-
ages/videos may be questioned because of its ease of editing,
especially when these digital data are brought to the court as
a proof of evidence.
Furthermore, it should be noted that a lot of surveillance
cameras are deployed nowadays, indoors or outdoors, to main-
tain the safety of people or security of properties. More and
more surveillance cameras will use digital formats to store
the recorded videos to facilitate efficient storage and trans-
mission. The visual data from surveillance system will surely
have a greater deal of importance and their authenticity should
be further ensured so that they can serve as reliable and effec-
tive evidence without doubt.
The conventional method to authenticate digital message
involves calculating a cryptographic checksum or a digest from
the digital message and sent along. When the recipient re-
ceives both the message and the digest, the same calculation
on the received message will be performed to generate a new
digest. The received digest is compared to the calculated one
to determine if the message has been modified. One single bit
error will result in a different digest. Although conventional
authentication techniques perform well when we require bit-
by-bit accuracy, the scenario for digital images and videos
may be different. Multimedia users pay more attention to the
content than specific digits or pixels. They care more about
whether the meaning of data has been changed, instead of
sparse binary errors, which may be caused by transmission,
storage or data processing procedures. Therefore, such nor-
mal data processing procedure as lossy compression should
be allowed since it doesn’t affect the viewers’ normal usage.
In addition, in authenticating digital images/videos that could
be tampered, it may be necessary to determine which part of
the data has been modified so as to help identify the attack-
ers’ motivation. We thus redefine the authentication for im-
ages/videos as a process that determines if the visual content
is intact and signals/locates malicious tampering otherwise.
The motivation can be illustrated in Fig.1(a), which shows
the original image and Fig.1(b), which illustrates a malicious
tampering; the date of picture was modified and an object on
the desk and a note on the monitor were removed. The con-
tent has been changed so the authentication process should
help locate these tampered regions.
Many multimedia authentication techniques have been pro-
posed in the past few years [13]. These techniques can be
roughly divided into two categories: signature-based approaches
and watermarking-based approaches. Signatured-based ap-
proaches are similar to conventional approaches in that the
digest or signature is generated and appended to the data for
authentication. However, the extracted digest will be required
In this research, we will adopt the signature-based approach
as the backbone of the authentication scheme with good abil-
ity of locating tampered regions.
The method of digital watermarking has the advantage
of avoiding the need of accessory data. One may suggest
to embed the authentication code by digital watermarking.
However, digital watermarking has a strict capacity limit. It
will be very challenging to embed the whole authentication
code in the host image/video, given the requirement of im-
perceptibility and resisting lossy compression. Besides, dig-
ital images/videos have to be compressed before storage or
transmission. Embedding a digital watermark is equivalent
to adding redundancy to the host data so careless embedding
may increase the compressed data size significantly. These
drawbacks prevent us from embedding the authentication code
by digital watermarking techniques. Nevertheless, we choose
to use the inseparability of digital watermark and the host con-
tent to further protect video data. Digital videos have a large
number of frames and a simple attack to change the content
is to remove, swap or insert frames. Although these attacks
can also be revealed by the signature-based approach, the lost
of synchronization between the authentication code and the
video frames may only signal the first frame that a malicious
attack was applied, instead of showing the attack details. In
our scheme, we use robust watermarking, instead of fragile
watermarking, to help ensure the correct frame order. We em-
bed consecutive frames with the robust watermarks, which
represent the serial numbers of frames. If the detected water-
mark doesn’t follow the original order, we may conclude that
the frame order has been changed.
We assume that the video surveillance system will use
H.264/AVC for video compression because of its excellent
coding performance. Given the fact that H.264/AVC coding
process is already quite complex, the digital video watermark-
ing that we developed is tied to H.264/AVC so that the compu-
tational load can be reduced. The details of our watermarking
scheme is described in Section 4.
3. RELIABLE FEATURE EXTRACTION
We first describe our signature-based approach, in which re-
liable feature will be extracted from digital images/videos as
the authentication code. These features are essential parts of
visual content and modification of them will result in content
changes.
3.1. Block-based Authentication
Since the length of authentication code has to be small, di-
mension reduction of the original data is necessary. We adopt
a block-based approach. Given an image/video frame, I , we
first extract its luminance component for processing. Then
we down-sample the luminance of I by calculating the aver-
age values of 4 × 4 blocks as shown in Fig.2. Besides the
advantage of data size reduction without losing the meaning
of content, the choice of block size also complies with the
block size of coding units in H.264/AVC video compression.
One may question that the down-sampling process may lose
details of visual data. However, in our opinion, a “useful”
modification of content should be able to change its meaning
and 4×4 down-sampled version, Id should still keep the most
significant visual information.
(a) (b) (c)
Fig. 2. (a) The original image, (b) the down-sampled image
to be investigated and (c) the DC image.
Let’s take a look at a numerical example. For a CIF frame
with resolution 352 × 288, the size of Id is 88 × 72 bytes,
which is still too large to be an authentication code. We thus
further divide Id into subblocks for feature extraction. The
size of subblock may be chosen to be 4×4 again, or even 8×8,
if a smaller authentication code is required, such in the video
applications. Features will be extracted from subblocks. A
straightforward method is to calculate the mean value of the
divided subblocks. If we use k bits to represent each mean
value, the resulting size of authentication code can be reduced
to 22 × 18 × k bits for 4 × 4 subblocks or 11 × 9 × k bits
for 8× 8 subblocks. Fig.2(c) shows the extracted feature, i.e.
the so-called “DC image”, in which 4 × 4 subblock size is
chosen and k is equal to 4. It should be noted that using fixed
number of bits to represent a number is a process of Scalar
Quantization (SQ).
Fig.3 shows the problem of this intuitive approach. As-
sume that Fig.3(a) is the original frame and Fig.3(b) is the
tampered frame by imposing a walking person. Fig.3(c) shows
the authentication result of merely using mean values of sub-
blocks. Some tampered regions are not located because of
the similar colors between the object and background. What
could be more serious is that the attacker may try to modify
the content but keep the mean value of a block the same. For
example, a uniform block may be changed to having two very
different colors with the same number of pixels.
3.2. Vector Quantization for Feature Code Generation
To alleviate this problem, we use Vector Quantization (VQ),
in which we group the source data into blocks or vectors and
represent each block with a single index. To be more specific,
a vector quantizer Q of dimension K and size N is a mapping
from a vector in K-dimensional Euclidean space RK into a
Subblock Xd
Md=Mean{Xd}
X=Xd-Md
SVD{X}
1 ?Tλλ >
Cu Cv
Vector 
QuantizationScalar
Quantization
Compression
Encryption
Authentication code
Yes
No
u1, v1
Md
SQ Index: ds
VQ Indices: du,dv
VQ info. 
bit db=0
VQ info. bit db=1
Fig. 5. The process of generating authentication code.
where x = [x1, . . . , xK ], y = [y1, . . . , yK ]. It should be
noted that L-2 norms of u1 and v1 are equal to 1 so they
can be viewed as points on K-dimensional hypersphere. The
length of arc between the two points x and y is
Arc(x,y) = 1× θ = cos−1 x · y‖x‖‖y‖ = cos
−1{x · y}. (5)
When x = y, Arc(x,y) = 0, which means the distance is
0. The longest distance is pi/2 when x is perpendicular to
y. Calculating the inner product is surely more efficient than
L-2 norm. Besides, both (u1,v1) and (−u1,−v1) are allow-
able for the same data as X = UΛVT = (−U)Λ(−V)T .
Therefore, the absolute value is used and Dist(±x,±y) will
have the same value. We only need to make sure that, if the
codeword u(i)1 is selected for u1 and v
(j)
1 is selected for v1,
u1 · u(i)1 and v1 · v(j)1 should be of the same sign.
To construct a good codebook for u1 and v1, we adopt
the “maximum distance” (MD) method, which was proposed
by Katsavounidis and Kuo [4] for codebook initialization. We
modify the procedure (illustrated by making Cu) as follows:
1. Select a vector in the training set as the 1st codeword.
2. Calculate the distance of all training vectors from the
first codeword and choose the vector with the largest
distance as the second codeword. Then we have a code-
book of size 2.
3. With a codebook size n, n = 2, 3, . . ., we compute the
distance between any remaining training vector u˜ and
all existing codewords and call the smallest value the
distance between u˜ and the codebook. Then the train-
ing vector with the largest distance from the codebook
is chosen to be the (n+ 1)th codeword. The procedure
stops when we obtain a codebook of size N .
The commonly used GLA may not be suitable in our case
since the centroids calculated in each iteration may not have
unit norm. Besides, the MD method tries to find a codebook
with codewords separated from each other as much as pos-
sible. Compared with GLA-based VQ algorithms such as
TSVQ, it will be much less common to have two similar code-
words in the codebook generated by the MD method. In addi-
tion, the resulting codewords of the MD method will contain
more information to better represent blocks with many edges
while TSVQ codewords tend to be uniform and may not be
appropriate in our case. Finally, we may need different code-
books in our applications and varying codebooks can be easily
constructed by selecting different initial vectors.
3.3. The Authentication Process
The authentication process is described as follows. The two
inputs to the authenticator are subblock X and the authenti-
cation code, FC(r). The subblock X goes through the same
code generation process as shown in Fig.5 to produce FC(x).
The received SQ index, d(r)s , and the extracted SQ index, d
(x)
s ,
are first compared. The blocks are determined as being tam-
pered when |d(r)s − d(x)s | > 1. If the SQ indices are identical,
we will check whether the VQ information bits, d(r)b and d
(x)
b
are the same. The case of unequal values will incur a further
checking process. Otherwise, the subblocks will be identified
as being authentic if d(r)b = d
(x)
b = 0 since they are uniform
blocks and VQ is not necessary. If VQ is required, the VQ
indices will be compared to see if the blocks contain the same
content. It should be noted that the subblock vector may lo-
cate at the middle point of two codewords. Given that u(r)1
is the received codeword while u(x)1 is the closest codeword
calculated by analyzing the extracted u1. The block will be
identified as being authentic if
|Dist(u(r)1 ,u1)−Dist(u(x)1 ,u1)| < Tu, (6)
where Tu is a pre-determined threshold. The same checking
process will be applied to v1.
We may have different VQ information bits, i.e. d(r)b =
1, d(x)b = 0 or d
(r)
b = 0, d
(x)
b = 1. The former case may hap-
pen when the details of subblock were lost after lossy com-
pression so the receiver classifies the subblock as a uniform
one. As the received authentication code is assumed to be re-
liable, we will still check u1,v1 by using VQ and compare
the indices with the received VQ indices, d(r)u and d
(r)
v . In the
latter case, the VQ information bit is set as 1 in the receiver
side but not in the sender side. We will investigate whether
λ1 is close to the threshold Tλ, which is used for determining
the value of VQ information bit. If not, we may identify the
block as a tampered block although SQ indices are the same.
4. DIGITAL VIDEO WATERMARKING IN H.264/AVC
To further protect digital videos, we adopt digital watermark-
ing techniques to ensure the correct frame order. By embed-
Therefore, we can only embed the watermark in the residues
of I macroblocks. The intra prediction will make the exact
values of transform coefficients in the luma block unavailable
in the encoding process. The luminance masking in Watson’s
model only dependents on the DC value of transform block
and some global settings. In the encoding process, we can
calculate the average value in the pixel domain to determine
the DC value so that the luminance masking can be decided.
The lowest three frequency terms, including the DC value,
will be excluded from watermark embedding to avoid caus-
ing unpleasant artifacts. It should be noted that ai,j,k will be
transferred to the quantization value, aqi,j,k, which is rounded
to be an integer, to determine the allowable amount of quan-
tization modification.
The spread-spectrum watermarking approach is adopted.
We generateW near-orthogonal bipolar sequences taking val-
ues 1 and −1 as the watermark sequences. A serial number
Nf ∈ {0,W − 1} is assigned to each watermark sequence
and will be the information we would like to embed in a
frame. The orthogonal sequence, w, will be randomized with
a random sequence, r, before embedding so as to increase
the difficulty of “guessing” the watermark sequence by at-
tackers. The random sequence r should depend on the frame
content so some image hashing algorithms can be used to de-
rive a compression-resilient hash serving as a seed to generate
r. Besides, the content-dependent watermark may avoid the
“copy attack”[7]. For a quantization index, qi,j,k, the water-
marked value , q′i,j,k, is calculated by
q′i,j,k =
{
0, qi,j,k = 0
qi,j,k + {rn × wNfn } × aqi,j,k, otherwise.
(9)
rn and w
Nf
n are the nth components of the random sequence
and the Nf -th watermark sequence respectively. The value n
is equal to k× 13+4× i+ j. It should be noted that only the
non-zero quantization indices will be watermarked to avoid
increasing the video sequence dramatically.
4.2. Watermark Detection
The watermark detection is based on the following equation:
ρp =
1
cp
∑
qˆi,j,k 6=0
qˆi,j,k × (rn × wNpn ), (10)
where cp is the number of nonzero qˆ and p ∈ {0, · · · ,W−1},
n = k×13+4× i+ j. It should be noted that the watermark
detection will be applied in all of the frames, not just I-slices.
In other words, we will detect the watermark in residues of
P-slices too so that the change of coding structure may not
affect watermark detection. The random sequence r will also
depend on the frame content as the embedder side. The de-
tection seems a sub-optimum method since we do not evalu-
ate the luminance masking in the decoder side. One reason
comes from the fact that the DC term will not be available
in the decoding process as intra and inter prediction are used.
However, it can be proved that this detection metric shown
in Eq.(10) performs well when the original host data follows
a Laplacian distribution and the distribution of quantization
indices in H.264/AVC should be of this case.
5. EXPERIMENTAL RESULTS
In the feature extraction for authentication, both images and
videos are tested to show the effectiveness. First of all, we
would like to test the false positive rates, which means the
probability that the authentication scheme wrongly signals the
case of tampering when the image or video is only processed
by lossy compression. We compress 520 images by JPEG
compression and change the quality factors (QF) from 100 to
0 as shown in Fig. 6. We use three different VQ codebook
sizes: 64, 128, 256, for both Cu and Cv . It can be observed
that the false alarm rate is lower than 10−3 even when QF is
close to 0 since the most important features are extracted. Fig.
6 (b) shows the false alarm rate for H.264/AVC compressed
videos under different quality parameters (QP), given that the
video may be transcoded to lower bit-rates. The false positive
rates are still low as expected. Next, we modify the visual
content to test the ability of locating tampered regions. The
detection result of the attack shown in Fig.1 and Fig.3 are
demonstrated in Fig.7(a) and Fig.7(b), respectively. All the
tampered regions are identified.
020406080100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x 10−3
JPEG Quality Factor
Fa
ls
e 
Al
ar
m
 R
at
e
codebook size 64
codebook size 128
codebook size 256
(a)
24 25 26 27 28 29 30 31 32
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
x 10−3
H.264/AVC QP control
Fa
ls
e 
al
ar
m
 ra
te
codebook size 64
codebook size 128
codebook size 256
(b)
Fig. 6. The false alarm rate for (a) JPEG-compressed images
and (b) H.264/AVC videos.
The result of watermark detection is illustrated in Fig.8.
Digital watermarks are embedded into residues of I-slices with
the PSNR decrease less than 1.5dB, and the detection is ap-
plied to all frames. In Fig.8(a), the largest response value in
each frame is shown, which is much higher than other val-
ues. Fig.8(b) demonstrates the watermark detection by us-
ing different values of QP for transcoding and the responses
of I-slices are shown. A larger QP value indicates a lower
bit-rate so the response decreases but is still large enough for
ambiguously claiming the existence of a watermark. We then
consider the possible case that the coding structure is changed
by transcoding. Fig.8(c) shows that every other I-slice of the
???????????? 
                                                             
???? 95-2221-E-008-089- 
???? ??????????????????? 
?????? 
??????? 
??? 
??????????????? 
?????? Boston, MA, USA 
???? SPIE, Optics East, Multimedia Systems and Applications IX 
?????? Transition logo detection for sports videos highlight extraction 
 
???????? 
 
On Oct. 3rd, 2006, I arrived in Boston, MA, USA with Prof. Min-Kuan Chang at National 
Chung-Hsing University to attend this SPIE conference, where I served as a member of 
conference committee and was responsible for call-for-paper and the subsequent paper 
reviewing. The conference was held in the Boston convention center each year and 
“Multimedia Systems and Applications” is one of the parts in Communication and ITCom.  
 
In our section, we presented a highlight 
extraction scheme for sports videos. The approach 
makes use of the transition logos inserted preceding 
and following the slow motion replays by the 
broadcaster, which demonstrate highlights of the game. 
The procedures can be roughly described as follows. 
First, the features of a MPEG compressed video are 
retrieved for subsequent processing. After the shot 
boundary detection procedure, the processing units are 
formed and the units with fast moving scenes are then 
selected. Finally, the detection of overlaying objects is 
performed to signal the appearance of a transition 
logo.  
Some questions were raised. We were asked 
whether the different types of logo will affect the system performance. We replied that several 
different games broadcasted by varying TV stations were extensively tested in our experiments 
since generality is certainly one of our major objectives. Then one researcher suggested that 
majority voting method should be used so that some wrong detection cases can be avoided. We 
replied that this direction was exactly what we have been doing and viewed as a future work at 
that time. One short-coming of this majority voting methodology is that the same situation 
