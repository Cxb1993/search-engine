real-coded GA-based PSO (RGA-PSO) method. The 
proposed AIA-PSO method uses an outer AIA to find the 
optimal parameter settings of an inter PSO method, 
and employs the inter PSO approach to solve an 
optimization problem (an UGO or CGO problem). The 
proposed RGA-PSO method uses an outer RGA to find the 
optimal parameter settings of an inter PSO method, 
and employs the inter PSO approach to solve an 
optimization problem (an UGO or CGO problem). 
Performances of the proposed AIA-PSO and RGA-PSO 
algorithm are evaluated using a set of UGO and CGO 
problems. Moreover, this project will compare the 
numerical results of the AIA-PSO and RGA-PSO methods 
with those of collected from literature. Finally, 
this project will develop an AIA-PSO and a RGA-PSO 
numerical analysis toolbox by using MATLAB and apply 
them to solve real-world engineering design problem 
collected from cooperating factory in this project. 
The proposed toolbox is expected to reduce the time 
in product development stage. 
英文關鍵詞： constrained global optimization, unconstrained global 
optimization, particle swarm optimization, artificial 
immune algorithm, real-coded genetic algorithm, 
nonlinear programming 
 
Hindawi Publishing Corporation
Mathematical Problems in Engineering
Volume 2012, Article ID 841410, 36 pages
doi:10.1155/2012/841410
Research Article
Solving Constrained Global Optimization Problems
by Using Hybrid Evolutionary Computing and
Artificial Life Approaches
Jui-Yu Wu
Department of Business Administration, Lunghwa University of Science and Technology, No. 300,
Section 1, Wanshou Road, Guishan, Taoyuan County 333, Taiwan
Correspondence should be addressed to Jui-Yu Wu, jywu@mail.lhu.edu.tw
Received 28 February 2012; Revised 15 April 2012; Accepted 19 April 2012
Academic Editor: Jung-Fa Tsai
Copyright q 2012 Jui-Yu Wu. This is an open access article distributed under the Creative
Commons Attribution License, which permits unrestricted use, distribution, and reproduction in
any medium, provided the original work is properly cited.
This work presents a hybrid real-coded genetic algorithm with a particle swarm optimization
RGA-PSO algorithm and a hybrid artificial immune algorithm with a PSO AIA-PSO
algorithm for solving 13 constrained global optimization CGO problems, including six nonlinear
programming and seven generalized polynomial programming optimization problems. External
RGA and AIA approaches are used to optimize the constriction coeﬃcient, cognitive parameter,
social parameter, penalty parameter, and mutation probability of an internal PSO algorithm. CGO
problems are then solved using the internal PSO algorithm. The performances of the proposed
RGA-PSO and AIA-PSO algorithms are evaluated using 13 CGO problems. Moreover, numerical
results obtained using the proposed RGA-PSO and AIA-PSO algorithms are compared with those
obtained using published individual GA and AIA approaches. Experimental results indicate that
the proposed RGA-PSO and AIA-PSO algorithms converge to a global optimum solution to a
CGO problem. Furthermore, the optimum parameter settings of the internal PSO algorithm can
be obtained using the external RGA and AIA approaches. Also, the proposed RGA-PSO and AIA-
PSO algorithms outperform some published individual GA and AIA approaches. Therefore, the
proposed RGA-PSO and AIA-PSO algorithms are highly promising stochastic global optimization
methods for solving CGO problems.
1. Introduction
Many scientific, engineering, and management problems can be expressed as constrained
global optimization CGO problems, as follows:
Minimize fx,
s.t. gmx ≤ 0, m  1, 2, . . . ,M,
Mathematical Problems in Engineering 3
candidate solutions to increase the diversity of the candidate population. For instance, Abd-
El-Wahed et al. 14 developed an integrated PSO algorithm and GA to solve nonlinear
optimization problems. Additionally, Kuo and Han 15 presented a hybrid GA and PSO
algorithm for bilevel linear programming to solve a supply chain distribution problem.
Furthermore, Shelokar et al. 16 presented a hybrid PSOmethod and ant colony optimization
method for solving continuous optimization problems. Finally, Hu et al. 17 developed an
immune cooperative PSO algorithm for solving the fault-tolerant routing problem.
Compared to the above hybrid CI algorithms, this work optimizes the parameter
settings of an individual CI method by using another individual CI algorithm. A standard
PSO algorithm has certain limitations 17, 18. For instance, a PSO algorithm includes
many parameters that must be set, such as the cognitive parameter, social parameter, and
constriction coeﬃcient. In practice, the optimal parameter settings of a PSO algorithm are
tuned based on trial and error and prior knowledge is required to successfully manipulate
the cognitive parameter, social parameter, and constriction coeﬃcient. The exploration and
exploitative capabilities of a PSO algorithm are limited to optimum parameter settings.
Moreover, conventional PSO methods involve premature convergence that rapidly losses
diversity during optimization.
Fortunately, optimization of parameter settings for a conventional PSO algorithm
can be considered an unconstrained global optimization UGO problem, and the diversity
of candidate solutions of the PSO method can be increased using a multi-nonuniform
mutation operation 19. Moreover, the parameter manipulation of a GA and AIA method
is easy to implement without prior knowledge. Therefore, to overcome the limitations of
a standard PSO algorithm, this work develops two hybrid CI algorithms to solve CGO
problems eﬃciently. The first algorithm is a hybrid RGA and PSO RGA-PSO algorithm,
while the second algorithm is a hybrid AIA and PSO AIA-PSO algorithm. The proposed
RGA-PSO and AIA-PSO algorithms are considered to optimize two optimization problems
simultaneously. The UGO problem optimization of cognitive parameter, social parameter,
constriction coeﬃcient, penalty parameter, and mutation probability of an internal PSO
algorithm based on a penalty function approach is optimized using external RGA and AIA
approaches, respectively. A CGO problem is then solved using the internal PSO algorithm.
The performances of the proposed RGA-PSO and AIA-PSO algorithms are evaluated using a
set of CGO problems e.g., six benchmark NLP and seven GPP optimization problems.
The rest of this paper is organized as follows. Section 2 describes the RGA, PSO
algorithm, AIA, and penalty function approaches. Section 3 then introduces the proposed
RGA-PSO and AIA-PSO algorithms. Next, Section 4 compares the experimental results of
the proposed RGA-PSO and AIA-PSO algorithms with those of various published individual
GAs and AIAs 9, 10, 20–22 and hybrid algorithms 23, 24. Finally, conclusions are drawn
in Section 5.
2. Related Works
2.1. Real-Coded Genetic Algorithm
GAs are stochastic global optimization methods based on the concepts of natural selection
and use three genetic operators, that is, selection, crossover, and mutation, to explore and
exploit the solution space. RGA outperforms binary-codedGA in solving continuous function
optimization problems 19. This work thus describes operators of a RGA 25.
Mathematical Problems in Engineering 5
2.2. Particle Swarm Optimization
Kennedy and Eberhart 26 first introduced a conventional PSO algorithm, which is inspired
by the social behavior of bird flocks or fish schools. Like GAs, a PSO algorithm is a
population-based algorithm. A population of candidate solutions is called a particle swarm.
The particle velocities can be updated by 2.5, as follows:
vj,n
(
gPSO 	 1
)
 vj,n
(
gPSO
)
	 c1r1j
(
gPSO
)[
plbj,n
(
gPSO
) − xj,n
(
gPSO
)]
	 c2r2j
(
gPSO
)[
p
gb
j,n
(
gPSO
) − xj,n
(
gPSO
)]
j  1, 2, . . . ,psPSO, n  1, 2, . . . ,N,
2.5
vj,ngPSO 	 1  particle velocity of decision variable xn of particle j at generation gPSO 	 1,
vj,ngPSO  particle velocity of decision variable xn of particle j at generation gPSO, c1 
cognitive parameter, c2  social parameter, xj,ngPSO  particle position of decision variable
xn of particle j at generation gPSO, r1,jgPSO, r2,jgPSO  independent uniform random
numbers in the interval 0, 1 at generation gPSO, plbj,ngPSO  best local solution at generation
gPSO, p
gb
j,ngPSO  best global solution at generation gPSO, psPSO  population size of the PSO
algorithm.
The particle positions can be computed using 2.6, as follows:
xj,n
(
gPSO 	 1
)
 xj,n
(
gPSO
)
	 vj,n
(
gPSO 	 1
)
j  1, 2, . . . ,psPSO, n  1, 2, . . . ,N. 2.6
Shi and Eberhart 27 developed amodified PSO algorithm by incorporating an inertia
weight ωin into 2.7 to control the exploration and exploitation capabilities of a PSO
algorithm, as follows:
vj,n
(
gPSO 	 1
)
 ωinvj,n
(
gPSO
)
	 c1r1j
(
gPSO
)[
plbj,n
(
gPSO
) − xj,n
(
gPSO
)]
	 c2r2j
(
gPSO
)[
p
gb
j,n
(
gPSO
) − xj,n
(
gPSO
)]
j  1, 2, . . . ,psPSO, n  1, 2, . . . ,N.
2.7
A constriction coeﬃcient χ was inserted into 2.8 to balance the exploration and
exploitation tradeoﬀ 28–30, as follows:
vj,n
(
gPSO 	 1
)
 χ
{
vj,n
(
gPSO
)
	 ρ1
(
gPSO
)[
plbj,n
(
gPSO
) − xj,n
(
gPSO
)]
	 ρ2
(
gPSO
)[
p
gb
j,n
(
gPSO
) − xj,n
(
gPSO
)]}
j  1, 2, . . . ,psPSO, n  1, 2, . . . ,N,
2.8
Mathematical Problems in Engineering 7
2.3.2. Selection Operation
The selection operation, which is based on the immune network principle 31, controls the
number of antigen-specific Abs. This operation is defined according to Ab-Ag and Ab-Ab
recognition information, as follows:
prj 
1
N
N∑
n1
1
ednj
,
dnj 
∣
∣
∣
∣
x∗n − xnj
x∗n
∣
∣
∣
∣, j  1, 2, . . . , rs, n  1, 2, . . . ,N,
2.11
where prj  probability that Ab j recognizes Ab
∗ the best solution, x∗n  the best Ab
∗ with
the highest Ab-Ag aﬃnity, xnj  decision variables xn of Ab j, rs  repertoire population
size of the AIA.
The Ab∗ is recognized by other Abj in a current Ab repertoire. Large prj implies that
Abj can eﬀectively recognize Ab∗. The Abj with prj that is equivalent to or larger than the
threshold degree prt is reproduced to generate an intermediate Ab repertoire.
2.3.3. Hypermutation Operation
Multi-nonuniform mutation 19 is used as the somatic hypermutation operation, which can
be expressed as follows:
xtrial,n 
{
xcurrent,n 	 xun − xcurrent,npert
(
gAIA
)
, if U40, 1 < 0.5,
xcurrent,n −
(
xcurrent,n − xln
)
pert
(
gAIA
)
, if U40, 1 ≥ 0.5,
2.12
where pertgAIA  {U50, 11 − gAIA/gmax,AIA}2  perturbation factor, gAIA  current
generation of the AIA, gmax,AIA  maximum generation number of the AIA, U40, 1 and
U50, 1  uniform random number in the interval 0, 1.
This operation has two tasks, that is, a uniform search and local fine-tuning.
2.3.4. Receptor Editing Operation
A receptor editing operation is developed using the standard Cauchy distribution C0, 1,
in which the local parameter is zero and the scale parameter is one. Receptor editing is
performed using Cauchy random variables that are generated from C0, 1, owing to their
ability to provide a large jump in the Ab-Ag aﬃnity landscape to increase the probability of
escaping from the local Ab-Ag aﬃnity landscape. Cauchy receptor editing can be defined by
xtrial  xcurrent 	U50, 12 × σ, 2.13
where σ  σ1, σ2, . . . , σN
T , vector of Cauchy random variables, U50, 1  uniform random
number in the interval 0, 1.
This operation is employed in local fine-tuning and large perturbation.
Mathematical Problems in Engineering 9
Procedure external RGA
begin
gRGA ← 0
Step 1: Initialize the parameter settings
a parameter setting
b generate initial population
While gRGA ≤ gmax,RGAdo
Step 2: Compute the fitness function value
Candidate
solution
x∗PSO
Step 3: Implement a selection operation
For each candidate solution j, j = 1, 2,..., psRGA / 2 do
Step 4: Perform a crossover operation
endIf
endFor
Step 5: Conduct a mutation operation
For each candidate solution j, j 1, 2,..., psRGAdo
≤ pm , RGAthen
endIf
endFor
Step 6: Implement an elitist strategy
gRGA ← gRGA 1
end
end
end
Procedure internal PSO Algorithm
gPSO ←0
Step 1 Create an initial particle swarm
a parameter settings from RGA
b generate initial particle swarm
While executing time the predefined fixed total time
Step 2 Calculate the objective function value
Step 3 Update the particle velocity and position
For each candidate particle
Step 4 Implement a mutation operation
endIf
Step 5 Perform an elitist strategy
endFor
gPSO ← gPSO 1
end
end
ρχ pm,PSOj, j= 1, 2,..., psRGA
fitness j = f (x∗PSO)
if rand (·) ≤ pcthen
c1 c2
j, j= 1, 2,..., psPSO do
if rand (·) ≤ pm, PSO then
if rand (·)
Figure 1: The pseudocode of the proposed RGA-PSO algorithm.
Candidate solution1 c2
c2
c2
c1
c1
c1
Candidate solution 2
ρ
ρ
ρCandidate solution psRGA
...
pm,PSO
pm,PSO
pm,PSO
χ
χ
χ fitnesspsRGA
fitness2
fitness1
Figure 2: Chromosome representation of the external RGA.
External RGA
Step 1 initialize the parameter settings. Parameter settings are given such as psRGA,
crossover probability pc, mutation probability of the external RGA approach pm,RGA, the lower
and upper boundaries of these parameters c1, c2, χ, ρ, and the mutation probability of the
internal PSO algorithm pm,PSO. The candidate solutions individuals of the external RGA
represent the optimized parameters of the internal PSO algorithm. Finally, Figure 2 illustrates
the candidate solution of the external RGA approach.
Mathematical Problems in Engineering 11
is evaluated. Here, a pairwise comparison is made between the fxPSO,j value of
candidate solutions in the new and current particle swarms. A situation in which
the candidate solution j j  1, 2, . . . ,psPSO in the new particle swarm is superior to
candidate solution j in the current particle swarm implies that the strong candidate
solution j in the new particle swarm replaces the candidate solution j in the current
particle swarm. The elitist strategy guarantees that the best candidate solution is
always preserved in the next generation. The current particle swarm is updated to
the particle swarm of the next generation.
Internal steps 2 to 5 are repeated until the gmax,PSO value of the internal PSO algo-
rithm is satisfied.
End
Step 3 implement selection operation. The parents in a crossover pool are selected using
2.1.
Step 4 perform crossover operation. In GAs, the crossover operation performs a global
search. Thus, the crossover probability pc usually exceeds 0.5. Additionally, candidate
solutions are created using 2.3.
Step 5 conduct mutation operation. In GAs, the mutation operation implements a local
search. Additionally, a solution space is exploited using 2.4.
Step 6 implement an elitist strategy. This work updates the population using an elitist
strategy. A situation in which the fitnessj of candidate solution j in the new population is
larger than that in the current population suggests that the weak candidate solution j is
replaced. Additionally, a situation in which the fitnessj of candidate solution j in the new
population is equal to or worse than that in the current population implies that the candidate
solution j in the current population survives. In addition to maintaining the strong candidate
solutions, this strategy eliminates weak candidate solutions.
External Steps 2 to 6 are repeated until the gmax,RGA value of the external RGA approach
is met.
3.2. AIA-PSO Algorithm
Figure 4 shows the pseudocode of the proposed AIA-PSO algorithm, in which the external
AIA approach is used to optimize the parameter settings of the internal PSO algorithm and
the PSO algorithm is used to solve CGO problems.
External AIA
Step 1 initialize the parameter settings. Several parameters must be predetermined. These
include rs and the threshold for Ab-Ab recognition prt, as well as the lower and upper
boundaries of these parameters c1, c2, χ, ρ, and pm,PSO. Figure 5 shows the Ab and Ag
representation.
Mathematical Problems in Engineering 13
ρχ pm,PSOc1 c2
Procedure external AIA
begin
Step 1: Initialize the parameter settings
while gAIA < gmax,AIA do
Step 2: Evaluate the Ab-Ag aﬃnity
Ab∗ ←max affinityj , j 1, 2, . . ., rs
Step 3: Perform clonal selection operation
for each Abj , j 1, 2, . . ., rs do
if prj ≥ prt then
promote clone
else
suppress
endIf
endFor
Step 4: Implement aﬃnity maturation
for each promoted Abj do
somatic hypermutation
else
receptor editing
endIf
endFor
Step 5: Introduce diverse Abs
Step 6: Update an Abrepertoire
gAIA ← gAIA 1
endwhile
end
end
Procedure internal PSO Algorithm
gPSO ← 0
Step 1 Create an initial particle swarm
a parameter settings from RGA
b generate initial particle swarm
while executing time ≤ the predefined fixed total time do
Step 2 Calculate the objective function value
Step 3 Update the particle velocity and position
For each candidate particle j, j 1, 2,..., psPSOdo
Step 4 Implement a mutation operation
endIf
Step 5 Perform an elitist strategy
endFor
gPSO ← gPSO 1
end
end
−1 × x∗PSO
gAIA ← 0
if rand (·) ≤ 0.5 do
if rand (·) ≤ pm, PSO then
Figure 4: The pseudocode of the AIA-PSO algorithm.
Step 5 introduce diverseAbs. Based on the bonemarrow operation, diverseAbs are created
to recruit the Abs suppressed in external Step 3.
Step 6 update an Ab repertoire. A new Ab repertoire is generated from external Steps 3–
5. The Ab-Ag aﬃnities of the Abs in the generated Ab repertoire are evaluated. This work
presents a strategy for updating the Ab repertoire. A situation in which the Ab-Ag aﬃnity of
Ab j in the new Ab repertoire exceeds that in the current Ab repertoire implies that a strong
Ab in the new Ab repertoire replaces the weak Ab in the current Ab repertoire. Additionally,
a situation in which the Ab-Ag aﬃnity of Ab j in the new Ab repertoire equals to or is worse
than that in the current Ab repertoire implies that the Ab j in the current Ab repertoire
survives. In addition to maintaining the strong Abs, this strategy eliminates nonfunctional
Abs.
External Steps 2–6 are repeated until the termination criterion gmax,AIA is satisfied.
4. Results
The 13 CGO problems were taken from other studies 1, 20, 21, 23, 34. The set of CGO
problems comprises six benchmark NLP problems TPs 1–4 and 12–13, and seven GPP
problems, in which TP 5 alkylation process design in chemical engineering, TP 6 optimal
reactor design, TP 12 a tension/compression string design problem, and TP 13 a pressure
vessel design problem are constrained engineering problems, were used to evaluate the
performances of the proposed RGA-PSO and AIA-PSO algorithms. In the appendix, the
objective function, constraints, boundary conditions of decision variables, and known global
Mathematical Problems in Engineering 15
Table 1: The parameter settings for the RGA-PSO and AIA-PSO algorithms.
Methods Parameter settings Search space
The external RGA
pc  1
pm,RGA  0.15 χl, χu  0.1, 1
psRGA  10 cl1, c
u
1   0.1, 2
gmax,RGA  3 cl2, c
u
2   0.1, 2
The external AIA
prt  0.9 ρl, ρu  1×109, 1 × 1011
rs  10 plm,PSO, p
u
m,PSO  0.1, 0.5
gmax,AIA  3
The internal PSO algorithm
psPSO  100
xln, x
u
n for a CGO problemgmax,PSO  3500 for TPs 1–4
gmax,PSO  3000 for TPs 5–13
χl, χu: the lower and upper boundaries of parameter χ.
cl1, c
u
1 : the lower and upper boundaries of parameter c1.
cl2, c
u
2 : the lower and upper boundaries of parameter c2.
ρl, ρu: the lower and upper boundaries of parameter ρ.
plm,PSO, p
u
m,PSO: the lower and upper boundaries of pm,PSO for the internal PSO algorithm pm,PSO.
4.1. Comparison of the Results Obtained Using the RGA-PSO
and AIA-PSO Algorithms
Table 2 summarizes the numerical results obtained using the proposed RGA-PSO and AIA-
PSO algorithms for TPs 1–13. Numerical results indicate that the RGA-PSO and the AIA-PSO
algorithms can obtain the global minimum solution to TPs 1–11, since each MAPE% is small.
Moreover, the best, median, worst, and S.D. of objective function values obtained using the
RGA-PSO andAIA-PSO solutions are identical for TPs 1, 2, 3, 4, 6, 7, 8, 9, and 11. Furthermore,
the worst values obtained using the AIA-PSO algorithm for TPs 5 and 13 are smaller than
those obtained using the RGA-PSO algorithm. Additionally, t-test is performed for each TP,
indicating that the mean values obtained using the RGA-PSO and AIA-PSO algorithms are
statistically significant for TPs 5, 10, 12, and 13, since P value is smaller than a significant level
0.05. Based on the results of t-test, the AIA-PSO algorithm yields better mean values than the
RGA-PSO algorithm for TPs 5, 12, and 13, and the AIA-PSO algorithm yields worse mean
value than the RGA-PSO algorithm for TP 10.
Tables 3 and 4 list the best solutions obtained using the RGA-PSO and AIA-PSO
algorithms from TPs 1–13, respectively, indicating that each constraint is satisfied i.e., the
violation of each constraint is accurate to at least five decimal places for every TP. Tables
5 and 6 list the best parameter settings of the internal PSO algorithm obtained using the
external RGA and AIA approaches, respectively.
4.2. Comparison of the Results for the Proposed RGA-PSO and AIA-PSO
Algorithms with Those Obtained Using the Published Individual GA
and AIA Approaches and Hybrid Algorithms
Table 7 compares the numerical results of the proposed RGA-PSO and AIA-PSO algorithms
with those obtained using published individual GA and AIA approaches for TPs 1–4. In this
table, GA-1 is a GA with a penalty function methods, as used by Michalewicz 20. Notably,
Mathematical Problems in Engineering 17
Ta
b
le
2:
C
on
ti
nu
ed
.
T
P
nu
m
be
r
G
lo
ba
l
op
ti
m
um
M
et
ho
d
s
B
es
t
M
ea
n
M
ed
ia
n
W
or
st
M
A
PE
%
S.
D
.
M
C
C
T
s
ec

P
va
lu
e
T
he
pr
op
os
ed
A
IA
-P
SO
−5
.7
39
8
−5
.7
39
8
−5
.7
39
8
−5
.7
39
8
2.
42
E
−0
4
7.
74
E
−0
6
32
9.
12
8
−8
3.
25
4
T
he
pr
op
os
ed
R
G
A
-P
SO
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
5.
13
E
−0
3
1.
26
E
−0
6
21
1.
91
0.
29
1
T
he
pr
op
os
ed
A
IA
-P
SO
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
5.
13
E
−0
3
6.
85
E
−0
7
21
3.
01
9
−6
.0
48
2
T
he
pr
op
os
ed
R
G
A
-P
SO
−6
.0
44
1
−5
.9
88
3
−5
.9
96
8
−5
.8
05
1
0.
99
1
0.
05
44
0.
72
0.
57
7
T
he
pr
op
os
ed
A
IA
-P
SO
−6
.0
46
7
−5
.9
82
8
−5
.9
97
9
−5
.8
27
4
1.
08
2
0.
05
44
1.
42
10
63
00
T
he
pr
op
os
ed
R
G
A
-P
SO
62
99
.8
37
4
62
99
.8
41
2
62
99
.8
41
9
62
99
.8
42
8
2.
52
E
−0
3
1.
42
E
−0
3
22
4.
13
0.
00
1∗
T
he
pr
op
os
ed
A
IA
-P
SO
62
99
.8
39
5
62
99
.8
42
0
62
99
.8
42
3
62
99
.8
42
5
2.
51
E
−0
3
6.
83
E
−0
4
22
3.
91
11
10
12
2.
69
64
T
he
pr
op
os
ed
R
G
A
-P
SO
10
12
2.
47
32
10
12
2.
49
25
10
12
2.
49
25
10
12
2.
64
44
2.
01
E
−0
3
2.
26
E
−0
2
34
0.
89
0.
88
4
T
he
pr
op
os
ed
A
IA
-P
SO
10
12
2.
48
52
10
12
2.
49
20
10
12
2.
49
27
10
12
2.
49
31
2.
02
E
−0
3
1.
85
E
−0
3
33
8.
37
12
—
T
he
pr
op
os
ed
R
G
A
-P
SO
0.
01
26
92
0.
01
27
24
0.
01
27
21
0.
01
27
84
—
1.
46
E
−0
5
29
3.
67
0.
01
4∗
T
he
pr
op
os
ed
A
IA
-P
SO
0.
01
26
67
0.
01
27
15
0.
01
27
19
0.
01
27
78
—
2.
00
E
−0
5
29
6.
15
13
—
T
he
pr
op
os
ed
R
G
A
-P
SO
58
85
.3
01
8
58
95
.0
38
1
58
85
.3
32
6
60
05
.4
35
1
—
24
.3
3
29
1.
17
0.
01
9∗
T
he
pr
op
os
ed
A
IA
-P
SO
58
85
.3
24
9
58
86
.5
42
6
58
85
.3
32
3
59
06
.7
40
4
—
4.
54
29
2.
16
T
he
“—
”
d
en
ot
es
un
av
ai
la
bl
e
in
fo
rm
at
io
n,
an
d
∗ r
ep
re
se
nt
s
th
at
th
e
m
ea
n
va
lu
es
ob
ta
in
ed
us
in
g
th
e
R
G
A
-P
SO
an
d
A
IA
-P
SO
al
go
ri
th
m
s
ar
e
st
at
is
ti
ca
lly
d
iﬀ
er
en
t.
Mathematical Problems in Engineering 19
Table 4: The best solutions obtained using the AIA-PSO algorithm from TPs 1–13.
TP number fx∗AIA-PSO x
∗
AIA-PSO
1 24.358
x∗AIA-PSO  2.18024296, 2.35746157, 8.75670935, 5.11326109,
1.03976363 1.54784227, 1.32994030, 9.83127443, 8.27618717,
8.32717779
gmx∗AIA-PSO  −0.000071 ≤ 0,−0.003699 ≤ 0,−0.000440 ≤
0,−0.684025 ≤ 0,−0.000086 ≤ 0,−0.001024 ≤ 0,−5.973866 ≤
0,−47.371958 ≤ 0
2
−30665.539
x∗AIA-PSO  78, 33, 29.99525527, 45, 36.77581286
gmx∗AIA-PSO  −92.000000 ≤ 0, 5.57E − 08 ≤ 0,−8.840500 ≤
0,−11.159500 ≤ 0, 2.76E − 07 ≤ 0,−5.000000 ≤ 0
3 680.633
x∗AIA-PSO  2.32925164, 1.95481519, −0.47307614, 4.35691576,−0.62313420, 1.05236194, 1.59750978
gmx∗AIA-PSO  −4.26E − 06 ≤ 0,−252.612733 ≤ 0,−144.741194 ≤
0,−1.00E − 05 ≤ 0
4 −15
x∗AIA-PSO  1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1
gmx∗AIA-PSO  0 ≤ 0, 0 ≤ 0, 0 ≤ 0,−5 ≤ 0,−5 ≤ 0,−5 ≤ 0, 0 ≤ 0, 0 ≤
0, 0 ≤ 0
5 1227.1598
x∗AIA-PSO  1697.91645044, 53.78132825, 3031.07989059, 90.12651301,
94.99999995, 10.48103708, 153.53594861
gmx∗AIA-PSO  1.000000 ≤ 1, 0.980100 ≤ 1, 1.000002 ≤ 1, 0.980099 ≤
1, 0.990562 ≤ 1, 1.000001 ≤ 1, 1.000002 ≤ 1, 0.976715 ≤ 1, 1.000001 ≤
1, 0.459425 ≤ 1, 0.387515 ≤ 1, 0.981856 ≤ 1, 0.987245 ≤ 1,−8.302533 ≤
1
6 3.9516
x∗AIA-PSO  6.44373647, 2.23335111, 0.68233303, 0.60026617,
5.93745119, 5.53146186, 1.01862958, 0.40673661
gmx∗AIA-PSO  0.999999 ≤ 1, 0.999999 ≤ 1, 0.999994 ≤ 1, 0.999985 ≤
1
7 −5.7398 x
∗
AIA-PSO  8.13042985, 0.61758136, 0.56393603, 5.63618191
gmx∗AIA-PSO  0.999999 ≤ 1, 0.999998 ≤ 1
8 −83.2497 x
∗
AIA-PSO  88.35635930, 7.67202113, 1.31765768
gmx∗AIA-PSO  3.00E − 18 ≤ 1
9 −6.0467
x∗AIA-PSO  6.46393173, 0.67575021, 1.01188804, 5.94072071,
2.24639462, 0.60683404, 0.39677469, 5.52596342
gmx∗AIA-PSO  0.999980 ≤ 1, 0.999999 ≤ 1, 0.998739 ≤ 1, 0.999928 ≤
1
10 6299.8395
x∗AIA-PSO  108.97708780, 85.02248757, 204.45439729
gmx∗AIA-PSO  1.000003 ≤ 1
11 10122.4852
x∗AIA-PSO  78, 33, 29.99571251, 45, 36.77534593
gmx∗AIA-PSO  −0.309991 ≤ 1, 1.000001 ≤ 1,−0.021380 ≤
1, 0.621403 ≤ 1, 1.000001 ≤ 1, 0.681517 ≤ 1
12 0.012667
x∗AIA-PSO  0.05164232, 0.35558085, 11.35742676
gmx∗AIA-PSO  −8.83E − 05 ≤ 0,−3.04E − 05 ≤ 0,−4.050924 ≤
0,−0.728518 ≤ 0
13 5885.3310
x∗AIA-PSO  0.77816843, 0.38464909, 40.31961929, 199.99999330
gmx∗AIA-PSO  2.22E − 07 ≤ 0, 7.80E − 08 ≤ 0,−0.006015 ≤
0,−40.000007 ≤ 0
Mathematical Problems in Engineering 21
Table 7: Comparison of the results of the proposed RGA-PSO and AIA-PSO algorithms and those of the
published individual GA and AIA approaches for TPs 1–4.
TP
number
Global
optimum Methods Best Mean Median Worst MAPE%
GA-1 20 24.690 — 29.258 36.060 —
GA-2 21 24.372 — 24.409 25.075 —
GA-3 9 24.935 27.314 27.194 33.160 12.377
1 24.306 AIA-1 22 24.506 25.417 — 26.422 —
AIA-2 10 24.377 24.669 24.663 24.988 1.495
The proposed
RGA-PSO 24.323 24.568 24.521 24.831 1.078
The proposed
AIA-PSO 24.358 24.579 24.564 24.809 1.125
GA-1 20 — — — — —
GA-2 21 — — — — —
GA-3 9 −30665.526 −30662.922 −30664.709 −30632.445 8.53E − 03
2 −30665.539 AIA-1 22 −30665.539 −30665.539 — −30665.539 —
AIA-2 10 −30665.539 −30665.526 −30665.527 −30665.506 4.20E − 05
The proposed
RGA-PSO −30665.539 −30665.539 −30665.539 −30665.534 1.34E − 06
The proposed
AIA-PSO −30665.539 −30665.539 −30665.539 −30665.539 9.95E − 07
GA-1 20 680.642 — 680.718 680.955 —
GA-2 21 680.634 — 680.642 680.651 —
GA-3 9 680.641 680.815 680.768 681.395 2.72E − 02
3 680.630 AIA-1 22 680.631 680.652 — 680.697 —
AIA-2 10 680.634 680.653 680.650 680.681 3.45E − 03
The proposed
RGA-PSO 680.632 680.640 680.639 680.658 1.46E − 03
The proposed
AIA-PSO 680.633 680.640 680.640 680.657 1.50E − 03
GA-1 20 −15 −15 −15 −15 —
GA-2 21 — — — — —
GA-3 9 −13.885 −12.331 −12.267 −10.467 17.795
4 −15 AIA-1 22 −14.987 −14.726 — −12.917 —
AIA-2 10 −14.998 −14.992 −14.992 −14.988 5.08E − 02
The proposed
RGA-PSO −15 −15 −15 −15 1.27E − 06
The proposed
AIA-PSO −15 −15 −15 −15 1.20E − 10
The “—” denotes unavailable information.
the worst values obtained using RGA-PSO and AIA-PSO algorithms are smaller than those
obtained using the GA-1, GA-2, GA-3, AIA-1, and AIA-2 approaches. For solving TP 2, the
median and worst values obtained using the RGA-PSO and AIA-PSO algorithms are smaller
than those obtained using the GA-3 method. For solving TP 3, the median and worst values
Mathematical Problems in Engineering 23
Ta
b
le
9:
C
om
pa
ri
so
n
of
th
e
nu
m
er
ic
al
re
su
lt
s
of
th
e
pr
op
os
ed
R
G
A
-P
SO
an
d
A
IA
-P
SO
al
go
ri
th
m
s
an
d
th
os
e
of
th
e
pu
bl
is
he
d
in
d
iv
id
ua
lA
IA
an
d
R
G
A
fo
r
T
Ps
5–
13
.
T
P
nu
m
be
r
G
lo
ba
lo
pt
im
um
M
et
ho
d
s
B
es
t
M
ea
n
M
ed
ia
n
W
or
st
M
A
PE
%
5
12
27
.1
97
8
A
IA
-2
1
0
12
27
.3
19
1
12
28
.6
09
7
12
27
.8
21
6
12
39
.5
20
5
1.
15
E
−0
1
G
A
-3
9

12
28
.5
11
8
12
79
.3
82
5
12
63
.2
58
9
14
81
.3
71
0
4.
26
6
T
he
pr
op
os
ed
R
G
A
-P
SO
12
27
.2
32
1
12
28
.8
47
1
12
28
.3
93
5
12
31
.6
00
3
1.
34
E
−0
1
T
he
pr
op
os
ed
A
IA
-P
SO
12
27
.1
59
8
12
28
.1
80
0
12
27
.9
76
2
12
29
.6
59
0
8.
02
E
−0
2
6
3.
95
11
A
IA
-2
1
0
3.
95
18
4.
10
05
4.
04
60
4.
29
97
3.
78
1
G
A
-3
9

3.
96
97
4.
14
40
4.
13
58
4.
37
43
4.
88
1
T
he
pr
op
os
ed
R
G
A
-P
SO
3.
95
21
3.
95
77
3.
95
66
3.
97
22
1.
67
E
−0
1
T
he
pr
op
os
ed
A
IA
-P
SO
3.
95
16
3.
95
81
3.
95
69
3.
97
35
1.
77
E
−0
1
7
−5
.7
39
8
A
IA
-2
1
0
−5
.7
39
8
−5
.7
39
8
−5
.7
39
8
−5
.7
39
6
6.
03
E
−0
4
G
A
-3
9

−5
.7
39
8
−5
.7
37
5
−5
.7
38
3
−5
.7
31
6
3.
98
E
−0
2
T
he
pr
op
os
ed
R
G
A
-P
SO
−5
.7
39
8
−5
.7
39
8
−5
.7
39
8
−5
.7
39
8
2.
54
E
−0
4
T
he
pr
op
os
ed
A
IA
-P
SO
−5
.7
39
8
−5
.7
39
8
−5
.7
39
8
−5
.7
39
8
2.
42
E
−0
4
8
−8
3.
25
4
A
IA
-2
1
0
−8
3.
25
04
−8
3.
24
99
−8
3.
24
99
−8
3.
24
96
4.
93
E
−0
3
G
A
-3
9

−8
3.
24
97
−8
3.
24
90
−8
3.
24
94
−8
3.
24
61
6.
06
E
−0
3
T
he
pr
op
os
ed
R
G
A
-P
SO
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
5.
13
E
−0
3
T
he
pr
op
os
ed
A
IA
-P
SO
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
−8
3.
24
97
5.
13
E
−0
3
9
−6
.0
48
2
A
IA
-2
1
0
−6
.0
47
1
−5
.9
79
5
−6
.0
13
8
−5
.7
15
9
1.
13
6
G
A
-3
9

−6
.0
41
7
−5
.8
60
2
−5
.8
77
2
−5
.6
81
5
3.
10
8
T
he
pr
op
os
ed
R
G
A
-P
SO
−6
.0
44
1
−5
.9
88
3
−5
.9
96
8
−5
.8
05
1
0.
99
1
T
he
pr
op
os
ed
A
IA
-P
SO
−6
.0
46
6
−5
.9
80
8
−5
.9
96
9
−5
.8
27
4
1.
08
2
10
63
00
A
IA
-2
1
0
62
99
.8
23
2
62
99
.8
38
8
62
99
.8
40
3
62
99
.8
49
4
2.
56
E
−0
3
G
A
-3
9

62
99
.8
39
9
62
99
.8
54
6
62
99
.8
45
3
62
99
.9
40
7
2.
31
E
−0
3
T
he
pr
op
os
ed
R
G
A
-P
SO
62
99
.8
37
4
62
99
.8
41
2
62
99
.8
41
9
62
99
.8
42
8
2.
52
E
−0
3
T
he
pr
op
os
ed
A
IA
-P
SO
62
99
.8
39
5
62
99
.8
42
0
62
99
.8
42
3
62
99
.8
42
5
2.
51
E
−0
3
11
10
12
2.
69
64
A
IA
-2
1
0
10
12
2.
43
43
10
12
2.
50
14
10
12
2.
50
23
10
12
2.
62
71
1.
93
E
−0
3
G
A
-3
9

10
12
2.
48
09
10
12
5.
24
41
10
12
3.
97
91
10
15
5.
13
49
2.
58
E
−0
4
T
he
pr
op
os
ed
R
G
A
-P
SO
10
12
2.
47
32
10
12
2.
49
25
10
12
2.
49
25
10
12
2.
64
44
2.
01
E
−0
3
T
he
pr
op
os
ed
A
IA
-P
SO
10
12
2.
48
52
10
12
2.
49
20
10
12
2.
49
27
10
12
2.
49
31
2.
02
E
−0
3
12
—
A
IA
-2
1
0
0.
01
26
65
0.
01
27
03
0.
01
27
19
0.
01
27
25
—
G
A
-3
9

0.
01
26
65
0.
01
27
39
0.
01
27
17
0.
01
34
71
—
T
he
pr
op
os
ed
R
G
A
-P
SO
0.
01
26
92
0.
01
27
24
0.
01
27
21
0.
01
27
84
—
T
he
pr
op
os
ed
A
IA
-P
SO
0.
01
26
67
0.
01
27
15
0.
01
27
19
0.
01
27
78
—
Mathematical Problems in Engineering 25
Table 10: Results of t-test for TPs 5–13.
TP number GA-3 versusAIA-2
GA-3 versus
RGA-PSO
GA-3 versus
AIA-PSO
AIA-2 versus
RGA-PSO
AIA-2 versus
AIA-PSO
RGA-PSO
versus AIA-PSO
5 0.000∗ 0.000∗ 0.000∗ 0.485 0.163 0.002∗
6 0.112 0.000∗ 0.000∗ 0.000∗ 0.000∗ 0.682
7 0.000∗ 0.000∗ 0.000∗ 0.000∗ 0.000∗ 0.358
8 0.000∗ 0.000∗ 0.000∗ 0.000∗ 0.000∗ 0.291
9 0.000∗ 0.000∗ 0.000∗ 0.516 0.814 0.577
10 0.000∗ 0.000∗ 0.000∗ 0.009∗ 0.001∗ 0.001∗
11 0.000∗ 0.000∗ 0.000∗ 0.069 0.013∗ 0.884
12 0.049∗ 0.389 0.178 0.000∗ 0.007∗ 0.014∗
13 0.003∗ 0.001∗ 0.000∗ 0.240 0.000∗ 0.019∗
∗Represents that the mean values obtained using two algorithms are statistically diﬀerent.
Table 11: Comparison of the numerical results of the proposed RGA-PSO and AIA-PSO algorithms and
those of the published hybrid algorithms for TPs 12-13.
TP number Methods Best Mean Median Worst S.D.
12
CDE 23 0.0126702 0.012703 — 0.012790 2.7E − 05
NM-PSO 24 0.0126302 0.0126314 — 0.012633 8.73E − 07
The proposed
RGA-PSO 0.012692 0.012724 0.012721 0.012784 1.46E − 05
The proposed
AIA-PSO 0.012667 0.012715 0.012719 0.012778 2.00E − 05
13
CDE 23 6059.7340 6085.2303 — 6371.0455 43.01
NM-PSO 24 5930.3137 5946.7901 — 5960.0557 9.16
The proposed
RGA-PSO 5885.3018 5895.0381 5885.3326 6005.4351 24.33
The proposed
AIA-PSO 5885.3310 5886.5426 5885.3323 5906.7404 4.54
the numerical results of the CDE, NM-PSO, RGA-PSO, andAIA-PSOmethods for solving TPs
12−13. The table indicates that the best, mean, and worst values obtained using the NM-PSO
method are superior to those obtained using the CDE, RGA-PSO, and AIA-PSO approaches
for TP 12. Moreover, the best, mean, and worst values obtained using the AIA-PSO algorithm
are better than those of the CDE, NM-PSO, and RGA-PSO algorithms.
According to the No Free Lunch theorem 35, if algorithm A outperforms algorithm
B on average for one class of problems, then the average performance of the former must
be worse than that of the latter over the remaining problems. Therefore, it is unlikely that
any unique stochastic global optimization approach exists that performs best for all CGO
problems.
Mathematical Problems in Engineering 27
Appendices
A. TP 1 [20, 21]
TP 1 has ten decision variables, eight inequality constraints, and 20 boundary conditions, as
follows:
Minimize fx  x21 	 x
2
2 	 x1x2 − 14x1 − 16x2 	 x3 − 102
	 4x4 − 52 	 x5 − 32 	 2x6 − 12
	 5x27 	 7x8 − 112 	 2x9 − 102 	 x10 − 72 	 45
Subject to g1x ≡ −105 	 4x1 	 5x2 − 3x7 	 9x8 ≤ 0,
g2x ≡ 10x1 − 8x2 − 17x7 	 2x8 ≤ 0,
g3x ≡ −8x1 	 2x2 	 5x9 − 2x10 − 12 ≤ 0,
g4x ≡ 3x1 − 22 	 4x2 − 32 	 2x23 − 7x4 − 120 ≤ 0,
g5x ≡ 5x21 	 8x2 	 x3 − 62 − 2x4 − 40 ≤ 0,
g6x ≡ x21 	 2x2 − 22 − 2x1x2 	 14x5 − 6x6 ≤ 0,
g7x ≡ 0.5x1 − 82 	 2x2 − 42 	 3x25 − x6 − 30 ≤ 0,
g8x ≡ −3x1 	 6x2 	 12x9 − 82 − 7x10 ≤ 0,
− 10 ≤ xn ≤ 10, n  1, 2, . . . , 10.
A.1
The global solution to TP 1 is as follows:
x∗  2.171996, 2.363683, 8.773926, 5.095984, 0.9906548,
1.430574, 1.321644, 9.828726, 8.280092, 8.375927,
fx∗  24.306.
A.2
Mathematical Problems in Engineering 29
The global solution to TP 3 is
x∗  2.330499, 1.951372,−0.4775414, 4.365726,−0.6244870, 1.038131, 1.594227,
fx∗  680.630.
C.2
D. TP 4 [20, 21]
TP 4 involves 13 decision variables, nine inequality constraints, and 26 boundary conditions,
as follows:
Minimize fx  5
4∑
n1
xn − 5
4∑
n1
x2n −
13∑
n5
xn
Subject to g1x ≡ 2x1 	 2x2 	 x10 	 x11 − 10 ≤ 0,
g2x ≡ 2x1 	 2x3 	 x10 	 x12 − 10 ≤ 0,
g3x ≡ 2x2 	 2x3 	 x11 	 x12 − 10 ≤ 0,
g4x ≡ −8x1 	 x10 ≤ 0,
g5x ≡ −8x2 	 x11 ≤ 0,
g6x ≡ −8x3 	 x12 ≤ 0,
g7x ≡ −2x4 − x5 	 x10 ≤ 0,
g8x ≡ −2x6 − x7 	 x11 ≤ 0,
g9x ≡ −2x8 − x9 	 x12 ≤ 0,
0 ≤ xn ≤ 1, n  1, 2, . . . , 9,
0 ≤ xn ≤ 100, n  10, 11, 12,
0 ≤ x13 ≤ 1.
D.1
The global solution to TP 4 is
x∗  1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, fx∗  −15. D.2
E. TP 5 (Alkylation Process Design Problem
in Chemical Engineering) [1]
TP 5 has seven decision variables subject to 12 nonconvex, two linear, and 14 boundary
constraints. The objective function is to improve the octane number of some olefin feed
Mathematical Problems in Engineering 31
Table 12: Coeﬃcients for TP 5.
l ωl l ωl l ωl
1 1.715 16 0.19120592E − 1 31 0.00061000
2 0.035 17 0.56850750E 	 2 32 0.0005
3 4.0565 18 1.08702000 33 0.81967200
4 10.000 19 0.32175000 34 0.81967200
5 3000.0 20 0.03762000 35 24500.0
6 0.063 21 0.00619800 36 250.0
7 0.59553571E − 2 22 0.24623121E 	 4 37 0.10204082E − 1
8 0.88392857 23 0.25125634E 	 2 38 0.12244898E − 4
9 0.11756250 24 0.16118996E 	 3 39 0.00006250
10 1.10880000 25 5000.0 40 0.00006250
11 0.13035330 26 0.48951000E 	 6 41 0.00007625
12 0.00660330 27 0.44333333E 	 2 42 1.22
13 0.66173269E − 3 28 0.33000000 43 1.0
14 0.17239878E − 1 29 0.02255600 44 1.0
15 0.56595559E − 2 30 0.00759500
F. TP 6 (Optimal Reactor Design Problem) [1]
TP 6 contains eight decision variables subject to four nonconvex inequality constraints and
16 boundary conditions, as follows:
Minimize fx 
(
0.4x0.671 x
−0.67
7 	 0.4x
0.67
2 x
−0.67
8 	 10 − x1 − x2
)
s.t. g1x  0.0588x5x7 	 0.1x1 ≤ 1,
g2x  0.0588x6x8 	 0.1x1 	 0.1x2 ≤ 1,
g3x  4x3x−15 	 2x
−0.71
3 x
−1
5 	 0.0588x
−1.3
3 x7 ≤ 1.
g4x  4x4x−16 	 2x
−0.71
4 x
−1
6 	 0.0588x
−1.3
4 x8 ≤ 1, 0.1 ≤ xn ≤ 10, n  1, 2, . . . , 8.
F.1
The global solution to TP 6 is
x∗  6.4747, 2.2340, 0.6671, 0.5957, 5.9310, 5.5271, 1.0108, 0.4004, fx∗  3.9511. F.2
Mathematical Problems in Engineering 33
The global solution to TP 9 is
x∗  6.4225, 0.6686, 1.0239, 5.9399, 2.2673, 0.5960, 0.4029, 5.5288, fx∗  −6.0482. I.2
J. TP 10 [34]
TP 10 contains three decision variables subject to one nonconvex inequality constraint and
six boundary conditions, as follows:
Minimize fx 
(
5x1 	 50000x−11 	 20x2 	 72000x
−1
2 	 10x3 	 144000x
−1
3
)
s.t. g1x  4x−11 	 32x
−1
2 	 120x
−1
3 ≤ 1, 1 ≤ xn ≤ 1000, n  1, 2, 3.
J.1
The global solution to TP 10 is
x∗  107.4, 84.9, 204.5, fx∗  6300. J.2
K. TP 11 [1, 34]
TP 11 involves five decision variables, six inequality constraints, and ten boundary condi-
tions, as follows:
Minimize g0x 
(
5.3578x23 	 0.8357x1x5 	 37.2392x1
)
s.t. g1x  0.00002584x3x5 − 0.00006663x2x5 − 0.0000734x1x4 ≤ 1,
g2x  0.000853007x2x5 	 0.00009395x1x4 − 0.00033085x3x5 ≤ 1,
g4x  0.00024186x2x5 	 0.00010159x1x2 	 0.00007379x23 ≤ 1,
g3x  1330.3294x−12 x
−1
5 − 0.42x1x−15 − 0.30586x−12 x23x−15 ≤ 1,
g5x  2275.1327x−13 x
−1
5 − 0.2668x1x−15 − 0.40584x4x−15 ≤ 1,
g6x  0.00029955x3x5 	 0.00007992x1x3 	 0.00012157x3x4 ≤ 1,
78 ≤ x1 ≤ 102, 33 ≤ x2 ≤ 45, 27 ≤ x3 ≤ 45, 27 ≤ x4 ≤ 45, 27 ≤ x5 ≤ 45.
K.1
The global solution to TP 11 is
x∗  78.0, 33.0, 29.998, 45.0, 36.7673, fx∗  10122.6964. K.2
L. TP 12 (a Tension/Compression String Design Problem) [23]
TP 12 involves three decision variables, six inequality constraints, and six boundary
conditions. This problem is taken from Huang et al. 23. This problem attempts to minimize
Mathematical Problems in Engineering 35
2 L. Kit-Nam Francis, “A generalized geometric-programming solution to economic production
quantity model with flexibility and reliability considerations,” European Journal of Operational Research,
vol. 176, no. 1, pp. 240–251, 2007.
3 J. F. Tsai, “Treating free variables in generalized geometric programming problems,” Computers &
Chemical Engineering, vol. 33, no. 1, pp. 239–243, 2009.
4 P. Xu, “A hybrid global optimization method: the multi-dimensional case,” Journal of Computational
and Applied Mathematics, vol. 155, no. 2, pp. 423–446, 2003.
5 C. A. Floudas, Deterministic Global Optimization, Kluwer Academic, Boston, Mass, USA, 1999.
6 C. I. Sun, J. C. Zeng, J. S. Pan et al., “An improved vector particle swarm optimization for constrained
optimization problems,” Information Sciences, vol. 181, no. 6, pp. 1153–1163, 2011.
7 I. G. Tsoulos, “Solving constrained optimization problems using a novel genetic algorithm,” Applied
Mathematics and Computation, vol. 208, no. 1, pp. 273–283, 2009.
8 K. Deep and Dipti, “A self-organizing migrating genetic algorithm for constrained optimization,”
Applied Mathematics and Computation, vol. 198, no. 1, pp. 237–250, 2008.
9 J. Y. Wu and Y. K. Chung, “Real-coded genetic algorithm for solving generalized polynomial
programming problems,” Journal of Advanced Computational Intelligence and Intelligent Informatics, vol.
11, no. 4, pp. 358–364, 2007.
10 J. Y. Wu, “Solving constrained global optimization via artificial immune system,” International Journal
on Artificial Intelligence Tools, vol. 20, no. 1, pp. 1–27, 2011.
11 L. A. Zadeh, “Fuzzy logic, neural networks, and soft computing,” Communications of the ACM, vol. 37,
no. 3, pp. 77–84, 1994.
12 A. Konar, Computational Intelligence-Principles, Techniques and Applications, Springer, New York, NY,
USA, 2005.
13 H. Poorzahedy and O. M. Rouhani, “Hybrid meta-heuristic algorithms for solving network design
problem,” European Journal of Operational Research, vol. 182, no. 2, pp. 578–596, 2007.
14 W. F. Abd-El-Wahed, A. A. Mousa, and M. A. El-Shorbagy, “Integrating particle swarm optimization
with genetic algorithms for solving nonlinear optimization problems,” Journal of Computational and
Applied Mathematics, vol. 235, no. 5, pp. 1446–1453, 2011.
15 R. J. Kuo and Y. S. Han, “A hybrid of genetic algorithm and particle swarm optimization for solving
bi-level linear programming problem—a case study on supply chain model,” Applied Mathematical
Modelling, vol. 35, no. 8, pp. 3905–3917, 2011.
16 P. S. Shelokar, P. Siarry, V. K. Jayaraman, and B. D. Kulkarni, “Particle swarm and ant colony
algorithms hybridized for improved continuous optimization,” Applied Mathematics and Computation,
vol. 188, no. 1, pp. 129–142, 2007.
17 Y. Hu, Y. Ding, and K. Hao, “An immune cooperative particle swarm optimization algorithm for fault-
tolerant routing optimization in heterogeneous wireless sensor networks,” Mathematical Problems in
Engineering, vol. 2012, Article ID 743728, 19 pages, 2012.
18 X. Zhao, “A perturbed particle swarm algorithm for numerical optimization,” Applied Soft Computing,
vol. 10, no. 1, pp. 119–124, 2010.
19 Z. Michalewicz, Genetic Algorithms + Data Structures = Evolution Programs, Springer, New York, NY,
USA, 1994.
20 Z. Michalewicz, “Genetic algorithm, numerical optimization, and constraints,” in Proceedings of the
6th International Conference on Genetic Algorithms, pp. 151–158, San Mateo, Calif, USA, 1995.
21 K. Deb, “An eﬃcient constraint handlingmethod for genetic algorithms,” Computer Methods in Applied
Mechanics and Engineering, vol. 186, no. 2–4, pp. 311–338, 2000.
22 N. Cruz-Corte´s, D. Trejo-Pe´rez, and C. A. Coello Coello, “Handling constraints in global optimization
using an artificial immune system,” in Proceedings of the 4th International Conference on Artificial Immune
Systems, pp. 234–247, Banﬀ, Canada,, 2005.
23 F.-Z. Huang, L. Wang, and Q. He, “An eﬀective co-evolutionary diﬀerential evolution for constrained
optimization,” Applied Mathematics and Computation, vol. 186, no. 1, pp. 340–356, 2007.
24 E. Zahara and Y. T. Kao, “Hybrid Nelder-Mead simplex search and particle swarm optimization for
constrained engineering design problems,” Expert Systems with Applications, vol. 36, no. 2, part 2, pp.
3880–3886, 2009.
25 C. R. Houck, J. A. Joines, and M. G. Kay, “A genetic algorithm for function optimization: a matlab
implementation,” in NSCU-IE TR 95-09, North Carolina State University, Raleigh, NC, USA, 1995.
26 J. Kennedy and R. Eberhart, “Particle swarm optimization,” in Proceedings of the IEEE International
Conference on Neural Networks, pp. 1942–1948, Perth, Australia, 1995.
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/08
國科會補助計畫
計畫名稱: 使用人工免疫算法基礎的粒子群最佳化方法求解工程設計問題
計畫主持人: 吳瑞煜
計畫編號: 100-2622-E-262-006-CC3 學門領域: 作業研究 
研發成果名稱
(中文) 使用人工免疫算法基礎的粒子群最佳化方法求解工程設計問題
(英文) Artificial immune algorithm based particle swarm optimization method for solving 
engineering design problems
成果歸屬機構
龍華科技大學 發明人
(創作人)
吳瑞煜
技術說明
(中文) 許 多 科 學 與 工 程 設 計 問 題 可 以 被表述成受限制全域最佳化 
(constrained global 
optimization, CGO) 問題。一個無限制全域最佳化(unconstrained global 
optimization, UGO) 問 
題是CGO 問題的一種特例。UGO 問題是指一個目標函數受限制於邊界條件。像是
基 
因演算法(genetic algorithm, GAs)、粒子群最佳化(particle swarm 
optimization, PSO) 
與人工免疫算法(artificial immune algorithms, AIAs)這類的隨機全域最佳化
(stochastic 
global optimization)方法可以克服一些以梯度算法為基礎的傳統非線性規劃
(nonlinear 
programming, NLP)方法的限制。傳統的NLP 技術是局部最佳化方法。因此， 本
計畫 
提出一個有效率的AIA 基礎的PSO 算法，本計畫將其命為AIA-PSO 方法。本計畫
所 
提出的AIA-PSO 算法使用一個外部的AIA 獲得一個內部的PSO 方法的最佳參數設
定 
值， 並使用一個內部的PSO 方法求解最佳化問題(UGO 或CGO 問題)。此AIA-PSO 
算法的性能(performance)將藉由一系列的UGO 與CGO 問題而加以評估。此外，
本計 
畫將比較AIA-PSO 方法與文獻上已發表的實驗結果。最後， 本計畫將使用
MATLAB 
開發一個AIA-PSO 數值分析工具箱， 並應用此工具箱求解從合作廠商所蒐集而
來的 
真實世界的工程設計問題， 此工具箱期望能縮短合作廠商在產品研發設計階段( 
例 
如： 模具開模)所需的時間， 進而提升該廠商在經營上的競爭力。
(英文) Many science and engineering design problems can be expressed as constrained global 
optimization 
(CGO) problems. An unconstrained global optimization (UGO) problem, which an 
objective function is 
constrained by boundaries conditions, is a special case of the CGO problems. The 
proposed AIA-PSO method uses an outer AIA to find the optimal parameter settings of 
an inter PSO method, and employs the inter PSO approach to solve an optimization 
problem (an UGO or CGO problem). This project will develop an AIA-PSO numerical 
analysis toolbox by using MATLAB and apply it to solve real-world engineering design 
problem collected from cooperating factory in this project. The proposed 
toolbox is expected to reduce the time in product development stage.
產業別 金屬業
技術/產品應用範圍
無限制全域最佳化(unconstrained global optimization)與受限制全域最佳化
(constrained global optimization)問題
技術移轉可行性及
預期效益
1. 縮短產品研發設計所需的時間。2. 減少材料之耗費。3. 增加與同業間的競爭力。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
Engineering Design 
Optimization Problems,＇ 
The Sixth International 
Conference on Genetic and 
Evolutionary Computing, 
Kitakyushu, Japan, 25-28 
August, 2012, pp. 404-408 
(EI) NSC 
100-2622-E-262-006-CC3 
2. Jui-Yu Wu*, ＇Hybrid 
Artificial Immune 
Algorithm and Particle 
Swarm Optimization for 
Solving Unconstrained 
Global Optimization 
Problems,＇ The 2012 
International Symposium 
on Computer, Consumer and 
Control, Taichung, 
Taiwan, 4-6 June, 2012, 
pp. 40-43. (EI) NSC 
100-2622-E-262-006-CC3 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次
 
其他成果 
(無法以量化表達之
成果如辦理學術活
動、獲得獎項、重要
國際合作、研究成果
國際影響力及其他
協助產業技術發展
之具體效益事項
等，請以文字敘述填
列。) 
AIA-PSO 與 RGA-PSO數值分析工具箱 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
科 
教 
處 電腦及網路系統或工具 0  
