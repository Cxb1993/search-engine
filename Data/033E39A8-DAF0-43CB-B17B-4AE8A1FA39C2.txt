 
 
1
1. Introduction 
Having been grown rapidly during the past few decades in the credit industry, financial 
institutions would be impossible to decide whether to grant credit to customers without using various 
automatic analysis techniques. With the increased competition in the financial industry, the banks find 
it harder to develop new customers. The cost of attracting new customers increases rapidly, so 
retaining existing customer is a must for all banks. The banks may easily lose customers if they 
cannot satisfy them with quality and good service. That is to say, the customers will choose other 
banks that can provide better services. Although contemporary marketing treats customers as valuable 
assets, it is crucial to extract knowledge from huge numbers of consumers’ data collected by the credit 
department of banks to maintain the viability and optimize credit book. Financial institutions invest 
large amounts of resources to understand and explore the contribution of their existing customers. 
Through analysis of customer contribution, they can identify valuable customers and further make 
efforts to retain and enhance their contributions, increase customer satisfaction, lead to better bank 
customer relationship, and locate causes of customer loss. The analytic results serve as important 
references for marketing and decision making.  
However, it is not sufficient to identify valuable customers solely based on their payment 
histories. A customer pays his bills on time might also involve in risky behaviors at the same time. As 
the delinquencies and charge-offs soar, the problem of personal bankruptcy has become an 
international concern yet little understood [23]. Therefore credit risk assessment is crucial for 
financial institutions especially in this era of economic globalization. Recently, several financial crises, 
 
 
3
choose the free parameters of an SVM model. In order to further understand the impact of searching 
the parameters setup, this study proposes a hybrid approach by using particle swarm optimization 
(PSO) as a supporting tool to search the optimal parameters of the SVM model.  
To demonstrate the feasibility and effectiveness of behavioral scoring using the above-mentioned 
techniques, behavioral scoring tasks are performed on one bank credit card dataset in Taiwan. In order 
to minimize the possible bias and provide a reliable estimate, a five-fold cross-validation scheme will 
be conducted to test the scoring capability of the proposed model. The remainder of the paper is 
organized as follows: An overview of credit and behavioral scoring models is given in Section 2. 
Section 3 provides a brief outline of linear discriminant analysis, multinomial logistic regression, 
neural networks, multivariate adaptive regression splines, support vector machine, and particle swarm 
optimization. The empirical results of behavioral scoring models using LDA, MLR, BPN, MARS, 
SVM, and hybrid PSO+SVM are provided in Section 4. Finally Section 5 concludes the study and 
discusses the possible further research areas. 
2. Credit and behavioral scoring models 
Credit risk management has become one of the most important tasks in the credit industry. Credit 
scoring and its derivative, behavioral scoring, are primary techniques that help organizations decide 
whether to grant credit to consumers based on the credit risk of applicants [86]. The objective of both 
credit and behavioral scoring models is to assign consumers to either a ‘good credit’ group that is 
likely to repay financial obligation or a ‘bad credit’ group whose application should be denied because 
of its high possibility of defaulting on the financial obligation. Therefore credit scoring lies in the 
 
 
5
3. Research methodology  
3.1 Linear discriminant analysis  
Discriminant analysis was first proposed by Fisher [25] in the 1930s as a classification technique. 
Up to date, it has been reported as the most commonly utilized statistical technique in handling 
classification problems [53]. As to the statistical assumptions in implementing discriminant analysis, 
Johnson and Wichern [44] explicated that discriminant analysis requires the data to be independent 
and normally distributed while the covariance matrix is also required to comply with the variation 
homogeneity assumption. If the covariance matrices of the given populations are not equal, then the 
separation surface of the discriminant function is quadratic and hence the quadratic discrininant 
analysis (QDA) needs to be used. Despite the fact that LDA is only a special case of QDA with 
stronger assumptions which should restrict its applications, in fact LDA has been reported to be a 
more robust method when the theoretical presumptions are violated [21, 80, 81]. And hence the LDA 
approach will be used in building the behavioral scoring model in this paper. 
Discriminant analysis has been widely devoted to a considerably wide range of application areas, 
such as medicine, business, education, marketing research, finance, chemistry, biology, engineering 
and archaeology [1, 18, 48, 54, 89]. Discriminant analysis is one of the first widely adopted statistical 
methodologies in building credit scoring models. A number of studies [6, 21, 66, 71, 77, 87] also 
proposed using discriminant analysis in building scoring models. 
3.2. Multinomial logistic regression 
Logistic regression (LR) is a widely used statistical modeling technique in which the probability 
 
 
7
Logistic regression models have been widely used in social research, medical research, 
biological research, food science, design, control, bankruptcy prediction, market segmentation, and 
customer behaviors [45, 52, 84, 91, 94]. Logistic regression has also been explored by [35, 43, 51, 93] 
in building credit scoring models for personal loan, business loan, and credit card applications. 
3.3 Artificial neural networks  
A neural network, modeled following the neural activity in the human brain, is a 
computer-intensive, algorithmic procedure for transforming inputs into desired outputs using highly 
interconnected networks of relatively simple processing elements. Neural networks are increasingly 
found to be useful in modeling non-stationary processes due to their associated memory 
characteristics and generalization capabilities [2, 11, 33, 78, 83]. Neural networks have been widely 
used in engineering, science, education, social research, medical research, business, finance, 
forecasting, and related fields [56, 57, 78, 83, 91, 96]. Neural networks have also been explored in 
handling credit and behavioral scoring problems [4, 7, 20, 28, 29, 41, 42, 55, 60, 61, 72, 74, 75, 79, 88, 
91, 92]. The majority of the above references have reported that the scoring accuracies of neural 
networks are better than those using traditional statistical and parametric approaches. 
3.4 Multivariate adaptive regression splines  
Multivariate adaptive regression splines, a nonlinear and non-parametric regression methodology, 
is first proposed by Friedman [26] as a flexible procedure which models relationships that are nearly 
additive or involve interactions with fewer variables. The modeling procedure of MARS is basically 
 
 
9
The optimal MARS model is selected in a two-stage process. Firstly, MARS constructs a very 
large number of basis functions to overfit the data initially, where variables are allowed to enter as 
continuous, categorical, or ordinal—the formal mechanism by which variable intervals are defined, 
and they can interact with each other or be restricted to enter in only as additive components. In the 
second stage, basis functions are deleted in the order of least contributions using the generalized 
cross-validation (GCV) criterion [15]. A measure of variable importance can then be assessed by 
observing the decrease in the calculated GCV when a variable is removed from the model. This 
process will continue until the remaining basis functions all satisfying the pre-determined 
requirements. The GCV can be expressed as follows 
2^ ^
2
1
1 ( )( ) ( ) [ ( )] / 1
N
i iM M
i
C MLOF f GCV M y f x
N N=
⎡ ⎤= = − −⎢ ⎥⎣ ⎦∑  (4)
where there are N observations, and C(M) is the cost-penalty measures of a model containing M basis 
functions (therefore the numerator measures the lack of fit on the M basis function model fM(xi) and 
the denominator denotes the penalty for model complexity C(M)). 
MARS can also handle the missing-value problems using dummy variable skills. By allowing 
any arbitrary shape for the function and interactions, MARS is capable of tracking very complex data 
structures that often hide in high-dimensional data. Please refer to [26] for more details regarding the 
model building process. 
MARS has been widely used in modeling problems in the areas of forecasting and classification 
problems [17, 27, 30, 50, 58, 68, 70]. For a detailed list regarding the referred articles using MARS, 
 
 
11
The SVM works very well when dealing with the high-dimensional data and therefore avoids the 
curse of dimensionality problem. It has been widely used in modeling credit and behavioral scoring 
problems [10, 39, 40, 59, 65, 82]. For a detailed introduction, the readers are referred to recent 
textbooks or articles such as [9, 31]. 
3.6. Particle swarm optimization 
Particle swarm optimization is a population-based heuristic method developed by Kennedy and 
Eberhart in 1995 [46]. The PSO algorithm is inspired by the collective motion of biological organisms, 
such as bird flocking and fish schooling, to simulate the seeking behavior to a food source. A PSO 
algorithm is initialized with a population of random particles treated as a point in D-dimensional 
search space. To find the optimum solution, each particle adjusts the direction through the best 
experience which it has found (pbest) and the best experience been found by all other members 
(gbest). Therefore, the particles fly around in a multidimensional space towards the better area over 
the search process. 
The PSO system initially has a population of random solutions and then searches for optimum 
solution by updating process. Each particle consists of three vectors: the position for ith individual 
particle xi = (xi1, xi2, ... , xiD), the best previous position that the ith particle has found pi = (pi1, pi2 , ... , 
piD), and its velocity vi = (vi1, vi2 , ... , viD). The performance of each particle is measured using a 
fitness function varying from problem in hand. During the iterative procedure, the particle’s velocity 
and position are updated by 
 
 
13
on one bank credit card dataset in Taiwan. The dataset consists of totally 5000 cardholders. Each 
cardholder in the dataset contains 43 variables, such as demographics, credit history, account balances, 
payment history, etc., which are used to describe the cardmember’s characteristics, credit status as 
well as credit card usage behavior. The dataset are divided into four groups: transactor users, revolver 
users, inactive users without using their credit cards, and bad credit customers. The number of the four 
groups is 1770, 1170, 1510, and 550. Table 1 summarizes the distribution of the dataset. 
<Insert Table 1 here> 
In order to minimize the possible bias associated with the random sampling of the training and 
testing samples, researchers tend to use n-fold cross-validation scheme in evaluating the classification 
capability of the built model. In n-fold cross-validation, the entire dataset is randomly split into n 
mutually exclusively subsets (also called folds) of approximately equal size with respect to the ratios 
of different populations. The classification model will then be trained and tested n times. Each time 
the model is built using (n－1) folds as the training sample and the remaining single fold is retained 
for testing. The training sample is used to estimate the behavioral scoring model’s parameters while 
the retained holdout sample is used to test the generalization capability of the built model. The overall 
classification accuracy of the built model is then just the simple average of the n individual accuracy 
measures. The five-fold cross-validation will be adopted; therefore there are 1000 customers in each 
fold of the dataset. The detailed behavioral scoring results using the above-mentioned modeling 
techniques can be summarized as follows. 
 
 
15
<Insert Table 3 here> 
4.3 Backpropagation neural networks model 
Since Vellido et al. [91] pointed out that close to 80% of business applications using neural 
networks will adopt the BPN training algorithm, this study will also use the popular BPN in building 
the credit scoring model. As recommended by Cybenko [16], Hornik, Stinchcombe, and White [36] 
and Zhang et al. [96] that the single hidden layer network is sufficient to model any complex system, 
the designed network will have only one hidden layer. There are 43 input nodes in the input layer and 
4 output nodes. As the issue of determining the optimal number of hidden nodes is a crucial yet 
complicated one, the most commonly used way in determining the number of hidden nodes is via 
experiments or trial and error [34, 62, 85, 95]. We, therefore, will also use the trial-and-error approach 
with the range from 23 to 88 neurons to determine the appropriate number of hidden nodes for the 
desired networks. The training of a network is implemented with various learning rates ranging from 
0.01 to 0.9 (almost all the network structure cannot converge with a learning rate greater than 0.9) and 
training lengths ranging from 16,000 to 400,000 iterations until the network converges. Network 
weights will be reset for each combination of the network parameters such as learning rates and 
momentum. 
As the training of any neural network is itself a stochastic process, the reported neural network 
result is therefore the medium value (avoid possible extreme values due to better/poorly trained 
networks) of 20 repetitive trials. The network topology with the highest correct classification rate is 
 
 
17
parameters correctly, which plays an important role in good generalization performance. However, no 
general guidelines are available to choose the free parameters of an SVM model. The selection is 
usually based on trial-and-error method or user’s prior knowledge and/or expertise.  
This study used a ‘grid-search’ method [38] to find the best combination of parameters. The grid 
search is a straightforward method using exponentially growing sequences of C and γ to identify good 
parameters (for example, C=2-5, 2-3, 2-1, … , 215). Since doing a complete gird search is very 
time-consuming for large dataset, a two-step search process—beginning with a coarse grid and 
followed by a finer grid search—was conducted to select the model parameters. Five SVM behavioral 
scoring models were built, and the cross-validation results of these models are presented in Table 6. 
From the results in Table 6, we can observe that the average correct classification rates for the five 
folds are 93.00%, 94.40%, 94.00%, 93.30%, and 93.30%, respectively, with mean equals to 93.60%. 
Among the four groups of customers, group 4 achieves the highest classification accuracy between 
94.55% and 99.09% for each fold, with average accuracy of 96.91%, while group 2 has the lowest 
classification accuracy ranging from 88.89% to 91.45%. 
<Insert Table 6 here> 
4.6 PSO+SVM model 
Instead of randomly choosing the values of the SVM model parameters, this study systematically 
examined a series of combinations of parameter values to build SVM behavioral scoring models by 
using a well-known ‘grid-search’ method. However, the grid search method scales exponentially in 
 
 
19
As shown in Table 6–7, the classification accuracy achieved by PSO+SVM is slightly superior to 
that of SVM. Regarding the computation time, the training time of PSO+SVM is shorter than that of 
SVM, a reduction of 32.4 minutes (about 9%). It must be noted that the modeling time of SVM is 
related to the predefined searching space and grid resolution of parameters. And a two-step search 
process was used in training SVM, which can save a lot of modeling time. Different datasets and 
predefined settings may obtain different results. For example, if the better region found by step one is 
very large, the training time in step two will become much longer.  
4.7 Comparison of results of different behavioral models 
Finally, in order to evaluate whether the proposed PSO+SVM model is superior to the other ones 
used in this study, some statistical tests are applied. The empirical results of six techniques based on 
one dataset are quite consistent, as can be seen in Table 8, and the rank-based nonparametric tests may 
not have enough power to detect the real difference among these models, so both parametric and 
nonparametric tests are conducted. A nonparametric Friedman test and a parametric 
repeated-measures ANOVA test are used to compare the performances of six methods. The result 
based on Friedman test rejected the null hypothesis (p-value = 0.0002), which indicates that the 
accuracy rates of these models are not equal. Then a post-hoc test needs to be proceeded—all 
classifiers are compared to each other; however, these test results are very sensitive to the significance 
level, the number of dataset and the number of modeling algorithms. For example, five-fold 
cross-validation and six classification techniques are used in this study, and if the significance level α 
 
 
21
due to the impact of serious financial crises. Behavioral scoring is a widely used tool for financial 
institutions to continually assess the ongoing credit risks and consumer behavior of their existing 
customers. This paper investigates the classification capability of five modeling techniques in building 
behavioral scoring tasks. In addition, this study proposed a PSO+SVM method to address the 
potential model selection problem of SVM when grid search method is adopted. Experimental results 
indicated that PSO+SVM model has better overall classification accuracy than those of the other 
models. However, the overall classification accuracy is not the only criterion to assess the capability 
of the built model. For example, if the business strategy of the financial institution is to have a black 
list on bad credit accounts, MLR model then can be used to accomplish this goal as it achieved the 
highest classification accuracy in group 4 (see Table 9). On the other hand, if the business strategy is 
to identify inactive customers who are at risk of being lost to a competitor, then PSO+SVM model 
should be used for this task. 
Moreover, it is evident from Table 8 that the overall accuracy of PSO+SVM is slightly superior 
to that of SVM, and the training time of the former is faster than that of the latter. Thus, we can 
conclude that the proposed method is an efficient alternative to the widely used grid search method. It 
should also be noted that the training time of these models are from a few minutes to several days, if 
fast response is one of the key concerns, then the speedy modeling techniques—DA, MARS, 
MLR—should be taken into account as model building tools.  
Future studies may aim at collecting more important independent variables that will increase the 
 
 
23
Knowledge Discovery 2 (1998) 121–167. 
[10] W.-H. Chen, J.-Y. Shih, A study of Taiwan’s issuer credit rating systems using support vector 
machines, Expert Systems with Applications 30 (3) (2006) 427–435. 
[11] B. Cheng, D.M. Titterington, Neural network: A review from a statistical perspective (with 
discussion), Statistical Science 9 (1994) 2–54. 
[12] M. Clerc, J. Kennedy, The particle swarm: Explosion, stability, and convergence in a 
multi-dimensional complex space, IEEE Transactions on Evolutionary Computation 6 (1) (2002): 
58–73. 
[13] D.R. Cox, Analysis of Binary Data, Methuen, London, 1970. 
[14] D.R. Cox, E.J Snell, Analysis of Binary Data, Chapman & Hall, London, 1989. 
[15] P. Craven, G. Wahba, Smoothing noisy data with spline functions. Estimating the correct degree 
of smoothing by the method of generalized cross-validation, Numberische Mathematik 31 (1979) 
317–403. 
[16] G. Cybenko, Approximation by superpositions of a sigmoidal function, Mathematical Control 
Signal Systems 2 (1989) 303–314. 
[17] J.G. De Gooijer, B.K. Ray, H. Krager, Forecasting exchange rates using TSMARS, Journal of 
International Money and Finance 17 (3) (1998) 513–534. 
[18] E.B. Deakin, A discriminant analysis of predictors of business failure, Journal of Accounting 
Research 10 (1972) 167–179. 
[19] J. Demšar, Statistical comparisons of classifiers over multiple data sets, The Journal of Machine 
Learning Research 7 (2006) 1–30. 
[20] V.S. Desai, J.N. Conway, G.A. Overstreet Jr., Credit scoring models in the credit union 
environment using neural networks and genetic algorithms, IMA Journal of Mathematics Applied 
in Business and Industry 8 (1997) 324–346. 
[21] V.S. Desai, J.N. Crook, G.A. Overstreet Jr., A comparison of neural networks and linear scoring 
models in the credit union environment, European Journal of Operational Research 95 (1996) 
24–37. 
[22] W.R. Dillon, M. Goldstein, Multivariate Analysis Methods and Applications, Wiley, New York, 
1984. 
[23] J.M. Donato, J.C. Schryver, G.C. Hinkel, R.L. Schmoyer Jr., N.W. Grady, M.R. Leuze, Mining 
multi-dimensional data for decision support, Future Generation Computer Systems 15 (1999) 
 
 
25
[39] C.-L. Huang, M.-C. Chen, C.-J. Wang, Credit scoring with a data mining approach based on 
support vector machines, Expert Systems with Applications 33 (4) (2007) 847–856. 
[40] Z. Huang, H. Chen, C.-J. Hsu, W.-H. Chen, S. Wu, Credit rating analysis with support vector 
machines and neural networks: a market comparative study, Decision Support Systems 37 (2004) 
543–558. 
[41] I. Jagielska, J. Jaworski, Neural network for predicting the performance of credit card accounts, 
Computational Economics 9 (1) (1996) 77–82. 
[42] H.L. Jensen, Using neural networks for credit scoring, Managerial Finance 18 (1992) 15–26. 
[43] D.N. Joanes, Rejecting inference applied to logistic regression for credit scoring, IMA Journal of 
Mathematics Applied in Business and Industry 5 (1993) 35–43. 
[44] R.A. Johnson, D.W. Wichern, Applied Multivariate Statistical Analysis, 4th ed., Prentice-Hall, 
New Jersey, 1998. 
[45] O.W. Kay, A. Warde, L. Martens, Social differentiation and the market for eating out in the UK, 
International Journal of Hospitality Management 19 (2) (2000) 173–190.  
[46] J. Kennedy, R.C. Eberhart, Particle swarm optimization, Proceedings of the IEEE International 
Joint Conference on Neural Networks IV, 1995, pp. 1942–1948.  
[47] J. Kennedy, R. C. Eberhart, Y. Shi, Swarm Intelligence, Morgan Kaufmann, San Francisco, CA, 
2001. 
[48] J.C. Kim, D.H. Kim, J.J. Kim, J.S. Ye, H.S. Lee, Segmenting the Korean housing market using 
multiple discriminant analysis, Construction Management and Economics 18 (2000) 45–54. 
[49] G. Kou, Y. Peng, Y. Shi, M. Wise, W. Xu, Discovering credit cardholders’ behavior by multiple 
criteria linear programming, Annals of Operations Research 135 (1) (2005) 261–274. 
[50] P.M. Kuhnert, K.-A. Do, R. McClure, Combining nonparametric models with logistic regression: 
an application to motor vehicle injury data, Computational Statistics and Data Analysis 34 (2000) 
371–386. 
[51] E.K. Laitinen, Predicting a corporate credit analyst’s risk estimate by logistic and linear models, 
International Review of Financial Analysis 8 (2) (1999) 97–121. 
[52] E.K. Laitinen, T. Laitinen,. Bankruptcy prediction: Application of the Taylor’s expansion in 
logistic regression, International Review of Financial Analysis 9 (4) (2000) 327–349. 
[53] G. Lee, T.K. Sung, N. Chang, Dynamics of modeling in data mining: interpretive approach to 
bankruptcy prediction, Journal of Management Information Systems 16 (1999) 63–85. 
 
 
27
797–803. 
[69] H.J. Noh, T.H. Roh, I. Han, Prognostic personal credit risk model considering censored 
information, Expert Systems with Applications, 28 (4) (2005) 753–762. 
[70] C. Ohmann, V. Moustakis, Q. Yang, K. Lang, Evaluation of automatic knowledge acquisition 
techniques in the diagnosis of acute abdominal pain, Artificial Intelligence in Medicine 13 (1996) 
23–36. 
[71] G.A. Overstreet Jr., E.L. Bradley Jr., R.S. Kemp, The flat-maximum effect and generic linear 
scoring model: a test, IMA Journal of Mathematics Applied in Business and Industry 4 (1992) 
97–109. 
[72] P.-S. Deng, Automatic knowledge acquisition and refinement for decision support: a 
connectionist inductive inference model, Decision Sciences 24 (2) (1993) 371–393. 
[73] F.C. Pampel, Logistic Regression—A Premier, Sage, Thousand Oaks, 2000. 
[74] S. Piramuthu, Financial credit-risk evaluation with neural and neurofuzzy systems, European 
Journal of Operational Research 112 (1999) 310–321. 
[75] S. Piramuthu, M.J. Shaw, J.A. Gentry, A classification approach using multi-layered neural 
networks, Decision Support Systems 11 (5) (1994) 509–525. 
[76] R. Poli, J. Kennedy, T. Blackwell, Particle swarm optimization: An overview, Swarm 
Intelligence 1 (2007) 33–57. 
[77] A.K. Reichert, C.C. Cho, G.M. Wagner, An examination of the conceptual issues involved in 
developing credit-scoring models, Journal of Business and Economic Statistics 1 (1983) 
101–114. 
[78] B. Repley, Neural networks and related methods for classification (with discussion), Journal of 
the Royal Statistical Society B56 (1994) 409–456. 
[79] L. Richeson, R.A. Zimmermann, K.G. Barnett, Predicting consumer credit performance: can 
neural networks outperform traditional statistical methods? International Journal of Applied 
Expert Systems 2 (2) (1994) 116–130. 
[80] M.S. Sanchez, L.A. Sarabia, Efficiency of multi-layered feedforward neural networks on 
classification in relation to linear discriminant analysis, quadratic discriminant analysis and 
regularized discriminant analysis, Chemometrics and Intelligent Laboratory Systems 28 (1995) 
287–303. 
[81] S. Sharma, Applied Multivariate Techniques, Wiley, New York, 1996. 
 
 
29
 
 
 
31
Table 3.  Cross-validation results of the MLR models. 
Behavioral scoring results 
Fold 
number {1-1} {2-2} {3-3} {4-4} 
Average correct 
classification rate
1 
82.49% 
(292/354) 
85.04% 
(199/234) 
86.09% 
(260/302) 
99.09% 
(109/110) 
86.00% 
(860/1000) 
2 
80.79% 
(286/354) 
88.46% 
(207/234) 
84.77% 
(256/302) 
100.00% 
(110/110) 
85.90% 
(859/1000) 
3 
85.03% 
(301/354) 
86.32% 
(202/234) 
85.76% 
(259/302) 
100.00% 
(110/110) 
87.20% 
(872/1000) 
4 
77.40% 
(274/354) 
89.32% 
(209/234) 
83.77% 
(253/302) 
100.00% 
(110/110) 
84.60% 
(846/1000) 
5 
81.92% 
(290/354) 
83.76% 
(196/234) 
84.77% 
(256/302) 
100.00% 
(110/110) 
85.20% 
(852/1000)  
Mean 81.53% 86.58% 85.03% 99.82% 85.78% 
 
Table 4.  Cross-validation results of the BPN models 
Behavioral scoring results 
Fold 
number {1-1} {2-2} {3-3} {4-4} 
Average correct 
classification rate
1 
96.33% 
(341/354) 
87.61% 
(205/234) 
88.08% 
(266/302) 
93.64% 
(103/110) 
91.50% 
(915/1000) 
2 
95.20% 
(337/354) 
87.61% 
(205/234) 
91.39% 
(276/302) 
93.64% 
(103/110) 
92.10% 
(921/1000) 
3 
96.61% 
(342/354) 
88.89% 
(208/234) 
91.72% 
(277/302) 
94.55% 
(104/110) 
93.10% 
(931/1000) 
4 
94.07% 
(333/354) 
88.89% 
(208/234) 
92.05% 
(278/302) 
88.18% 
(97/110) 
91.60% 
(916/1000) 
5 
95.76% 
(339/354) 
85.04% 
(199/234) 
90.07% 
(272/302) 
90.91% 
(100/110) 
91.00% 
(910/1000)  
Mean 94.99% 87.61% 90.66% 92.18% 91.86% 
 
 
 
33
Table 7.  Cross-validation results of the PSO+SVM models 
Behavioral scoring results 
Fold 
number {1-1} {2-2} {3-3} {4-4} 
Average correct 
classification rate
1 
95.76% 
(339/354) 
90.17% 
(211/234) 
92.05% 
(278/302) 
96.36% 
(106/110) 
93.40% 
(934/1000) 
2 
96.89% 
(343/354) 
90.60% 
(212/234) 
95.03% 
(287/302) 
95.45% 
(105/110) 
94.70% 
(947/1000) 
3 
96.33% 
(341/354) 
90.17% 
(211/234) 
94.04% 
(284/302) 
97.27% 
(107/110) 
94.30% 
(943/1000) 
4 
96.89% 
(343/354) 
90.17% 
(211/234) 
92.72% 
(280/302) 
95.45% 
(105/110) 
93.90% 
(939/1000) 
5 
93.79% 
(332/354) 
90.17% 
(211/234) 
93.38% 
(282/302) 
98.18% 
(108/110) 
93.30% 
(933/1000) 
Mean 95.93% 90.26% 93.44% 96.55% 93.92% 
 
Table 8.  Summarized credit scoring results of the six constructed models. 
Fold 
number 
LDA MLR BPN MARS SVM 
PSO 
+SVM 
1 81.00% 86.00% 91.50% 86.10% 93.00% 93.40% 
2 81.30% 85.90% 92.10% 89.30% 94.40% 94.70% 
3 81.50% 87.20% 93.10% 84.70% 94.00% 94.30% 
4 81.10% 84.60% 91.60% 87.30% 93.30% 93.90% 
5 81.20% 85.20% 91.00% 85.00% 93.30% 93.30% 
Mean 81.22% 85.78% 91.86% 86.76% 93.60% 93.92% 
 
 
 
35
Figure 
 
 
 
 
Feature space 
Optimal separating hyperplane in 
the feature space 
Input space 
Fig. 1.  The SVM maps the input space into high-dimensional feature space and then constructs 
an optimal separating hyperplane in the feature. 
 2
 
圖1 Prof. Suh 演講 
 
圖2 Prof. Lo 演講 
 
為了參加此一盛會，本人由國科會計劃 (NSC 97-2221-E-030-011-MY2) 之出席國際會議
項目補助費用發表論文，名稱為：『Stock Index Prediction: A Comparison of MARS, BPN and 
SVR in an Emerging Market』。 
 
二、與會心得與建議 
此次會議個人最大的收穫為至各場次聽取不同學者的研究成果，透過聽取不同學者對於
他們各自所專長的研究專長所提出的新的研究理論與應用發展，讓個人不僅能在自己所專
門的研究方向有所學習新事物，還可以瞭解各個不同領域的未來研究之方向及趨勢。而在
個人報告的部分，透過跟與會學者的討論，可以讓本人的研究更加的完整與深入，可謂受
益良多。 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
協助金融機構增加信用評等可以使用之工具及競爭力，對協助產業發展有相當
貢獻。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
