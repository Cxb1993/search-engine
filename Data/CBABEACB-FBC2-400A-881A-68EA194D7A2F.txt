sequence based on the characteristics of the 
sequence. However, previous researches reveal two 
major problems. First, previous works simply utilizes 
all found sequential patterns as features to 
construct classification models. The large sequential 
patterns might contain redundant and non-
discriminative patterns that often over fit the 
classification model and deteriorate the 
classification accuracy. Second, they seldom discuss 
the part of similarity in sequence similarity measure 
that affects the classification accuracy. For this 
two reasons, this research presents a sequence 
classification methodology to help decision makers 
make better business strategies to satisfy their 
various customers.  
In the first year, the proposed sequence 
classification methodology includes two main stages. 
The first stage is sequential pattern mining, which 
employs ClosedSpan algorithm to discover closed 
sequential patterns in the large database. The second 
stage is sequence classification method, which 
contains sequence similarity measure, sequence 
classification model establishment, and model 
optimization procedure. In the second year, we 
proposed a time-interval sequence classification 
methodology. The first stage is to employ time-
interval sequential pattern mining to obtain frequent 
time-interval sequential patterns. The second stage 
is to increase classification accuracy by the 
proposed sequence classification method. A set of 
sequence datasets is employed to test the 
classification method. The experiment results 
indicate the proposed sequence classification method 
is feasible and efficient. 
 
英文關鍵詞： Sequential pattern mining, Sequence classification, 
Sequence similarity measure, Particle swarm 
optimization, Time-interval sequential pattern 
mining. 
 
 1 
行政院國家科學委員會專題研究計畫成果報告 
以消費者行為序列探勘為基礎之分類模型 
 
中文摘要 
在現今競爭激烈與環境變化快速的商業環境中，企業若能掌握正確的時機，提供其顧
客所需，將會比其他競爭者更有立足與生存的機會。為了滿足顧客需求，對公司決策者而
言，能確實掌握顧客的消費行為模式是相當重要的工作。事實上，企業內部的確掌握了顧
客的消費紀錄，包括交易內容、詢問記錄及顧客資料等，然而這些資料往往龐大且紊亂，
造成顧客行為分析工作的困難。資料探勘技術中廣為人知的「序列樣式探勘」與「序列分
類」技術將可解決上述問題。「序列樣式探勘」技術可偵測出資料庫中較常發生的序列樣式，
而「序列分類」技術藉由其所建立之序列模型，可預測一新的序列最有可能所屬的類別，
故常被應用於許多實例當中。在以往的研究中，序列樣式探勘出來的序列樣式太多，造成
多餘和沒有意義的序列樣式存在。此外，序列相似性測量無法完整的衡量出序列樣式間的
關係。因此本計畫發展一個二年期的以消費者行為序列探勘為基礎之分類模型，幫助管理
者做出更有效的決策以滿足客戶需求。第一年計畫提出了一個兩階段的分類模型，第一階
段以 ClosedSpan 演算法從資料庫中挖掘出頻繁的 closed 序列樣式，將較常出現的客戶行為
模式找出；第二階段為序列的分類方法，包含序列相似性測量、分類模型之建立，以及模
型最佳化三個部分。第二年計畫的重點為考量事件發生時間間隔(Time-Interval)的序列樣
式，並為此一序列樣式發展一個可以快速得到時間間隔序列樣式間相似程度的方法；此外，
第二年計畫修正第一年計劃的分類模型，使得許多「hard-to-classify」的序列樣式可以更精
準地被分類。本計畫應用多筆資料來測試所提出的序列分類方法，實驗結果證明本計畫所
提出的序列分類方法是可行且有效率的。 
 
關鍵詞：序列樣式探勘、序列分類、序列相似度量測、粒子群最佳化演算法、時間間隔序
列樣式 
 
 3 
 
一、 報告內容 
1. Introduction 
To survive in current competitive and fast-changed business environment, enterprises need 
to know their customers behavior in depth to provide the right services to customers at right time. 
However, the customer databases in enterprises are usually large and disordered which makes 
customer behavior analysis difficult. Sequential pattern mining and sequence classification are 
two popular data mining methods to explore customer behavior. The former can discover frequent 
occurring patterns, while the latter can assign a most probable class label to a given sequence 
based on the characteristics of the sequence. Recently, several compound classification methods 
that integrate more than one data mining technologies have been discussed. These compound 
methods utilize the advantage of individual data mining technique and try to achieve higher 
classification accuracy of sequence classifiers. Among them, sequential pattern mining (SPM) 
based sequence classifiers receive much attention ([7, 12, 13, 17]. Typically, the SPM-based 
sequence classifiers can be decomposed as two stages. In the first stage, sequential pattern mining 
approach is applied to extract frequent sequential patterns from a large database. Then, the 
extracted sequential patterns are considered as important features and used to build the 
classification model in the second stage.  
It is a promising direction to integrate different types of data mining methods to form a new 
methodology for solving complex data mining problems. Meanwhile, they can provide users with 
more mining information than the other methods. However, previous SPM-based sequence 
classification methods reveal two major problems. First, previous works simply utilizes all found 
sequential patterns as features to construct classification models. However, the numbers of 
extracted sequential patterns might be large. Moreover, the large sequential patterns contain 
redundant and non-discriminative patterns that often over fit the classification model and 
deteriorate the classification accuracy [10]. Therefore, how to select minimum number of 
sequential patterns as representative features should be very important.  
Second, sequence similarity measure might significantly affect the accuracy of classification. 
For example, the pattern scoring function (PSF) proposed by [9] is a complete matching method 
based on the existence or not of a pattern in a sequence. In sequential pattern mining procedure, 
they incorporated gap constraints to extract sequential patterns. However, the setting of gap 
constraints will affect not only the number of extracted sequential patterns but also classification 
accuracy. How to set gap constraints is an important key factor for improving classification 
accuracy. In addition, the PSF cannot enough represent the similarity between sequences and 
patterns. Example, there are two sequences <a, b, c> and <a, c, b>. The gap constraint is set as 1 
(extract only contiguous subsequences as sequential patterns), then the sequential pattern <a, b> 
is gotten. In PSF procedure, the <a, b> is complete matching in the <a, b, c> but is not matching 
in the <a, c, b>. It caused the similarity value of <a, b> and <a, c, b> is zero. Intuitively, they 
 5 
Smaragdis and Raj [15] extended non-negative representations of spectrograms to design a 
Markov selection model that is able to recognize sequences even when they are presented mixed 
together. They did so without the need to perform separation on the signals. Lipeika [14] deals 
with the use of formant features in dynamic time warping based speech recognition. These 
features can be simply visualized and give a new insight as understanding the reasons of speech 
recognition errors. They are to optimize formant feature based isolated word recognition 
performance by varying processing parameters of the recognition system as well as to find 
improvements of the recognition system. 
Recently, some researches utilized sequential pattern mining technique to enhance 
computational efficiency for the sequence classification problem. Sequential pattern mining can 
find frequent sequential patterns from a large database. The extracted sequential patterns are 
considered as important features and used to build the classification model. Lesh et al. [12] 
proposed an algorithm for sequence classification using frequent patterns as features in the 
classifier. In their algorithm, subsequences are extracted and transformed into sets of features. 
After feature extraction, general classification algorithms such as Naïve Bayes, SVM or neural 
network can be used for classification. Lesh et al. [13] proposed a scalable feature mining 
algorithm to act as the preprocessor to select features for standard classification algorithm such as 
Winnow and Naïve Bayes. By adapting scalable and disk-based data mining algorithms, they are 
able to classify the sequences efficiently. Exarchos et al., [6] proposed a novel classification 
method for biological data. They utilized cSPADE (Sequential PAttern Discovery using 
Equivalence classes) for the analysis of protein sequence. These sequential patterns are extracted 
by cSPADE to characterize each class (protein fold). In addition, a classifier uses the extracted 
sequential patterns to classify proteins in the appropriate fold category. Exarchos et al. [7] 
presented a novel methodology for sequence classification, based on sequential pattern mining 
and optimization algorithms. The sequential pattern mining algorithm is applied to extracted 
sequential patterns from a set of sequences. Then, the score of every pattern with respect to each 
sequence is calculated using a scoring function and the score of each class under consideration is 
estimated by summing the specific pattern scores. Each score is updated and multiplied by a 
weight. The optimization technique is employed to estimate the weight values and achieve 
optimal classification accuracy. 
 
3. The first year - The sequential pattern mining based sequence classification Framework 
A sequential pattern mining based sequence classification framework, as shown in Figure 1, is 
proposed. In the first stage, the concept of closed mining [19] is utilized to generate the closed 
sequential patterns for every class in the database.  
 
 7 
support in the database. The advantage of closed sequential pattern mining may significantly 
reduce the number of patterns generated and is information lossless because it can be used to 
derive the complete set of sequential patterns. Therefore, this research adopts the advantage of 
closed sequential pattern mining to resolve generating an exponentially large number of 
sequential patterns.  
The preliminary concepts according to closed sequential pattern mining algorithm are given 
as follow.  Given two sequences, s = <t1, …, tm> and p = < '1t , …, 
'
nt >, s p means s concatenates 
with p. It can be itemset-extension, s i p = <t1, …, tm   '1t , …, 'nt  > if mtk , ;,'1 jktj   
or sequence-extension, s s p = <t1, …, tm, '1t , …, 'nt  >. If 's  = p s, p is a prefix of 's  and s is 
a suffix of 's . An s-projected database is defined as cPH  = { p | ,' PHs   's = r  p s.t. r is the 
minimum prefix containing s. 
The set of frequent sequential patterns, FS, includes all the sequences whose support is no 
less than min_sup. The set of closed frequent sequential pattern, CS, is defined as CS = 
{ | FS and   FS such that    and support ( ) = support ( )}. Since CS includes 
no sequence which has a super-sequence with the same support, CS   FS, the problem of 
closed sequence mining is to find CS above a minimum support threshold.  
The pseudo code for the closed sequential pattern mining algorithm is shown in Figure 2. 
The inputs to the CloSpan are sequence database cPH and min_sup. The output is the complete 
closed sequential pattern set FPc. The algorithm first sorts every itemset and removes infrequent 
items, as shown in line 1. Then all frequent 1-item sequence is stored in S1 and is input to 
subroutine CloSpan, as shown in lines 2-4. The subroutine CloSpan can generate a superset of 
closed frequent sequence. Finally, the non-closed sequences are eliminated from FPc, as shown in 
line 5. The CloSpan first scans cPH  once to find every frequent items   then to assembly to 
the element of s or to append to s to form a sequential pattern, as shown in line 1. Line 3 shows 
the termination condition: when the number of sequences in the s-projected database is less than 
min_sup, it is unnecessary to extend s anymore. For each sequence s and its projected database, it 
performs itemset-extension (line 5) and sequence-extension (line 7) recursively until all the 
frequent sequences are discovered. 
  
 9 
3.2.2 A sequence classification model 
As mentioned before, the sequential patterns in FPc are frequent patterns appeared in PHc. 
Therefore, this research takes the sequential patterns in FPc to represent the all sequences in class 
c. If a new sequence s is similar to the sequential patterns in FPc, the new sequence s has more 
chance belonging to class c. However, not all sequential patterns have the same classification 
judgment capability. Thus, each sequential pattern in FPc should be assigned an important weight 
to reflect its own importance. Similarly, different frequent pattern set FPc might have different 
affection to the class prediction result since the representatives of sequential patterns in FPc is 
different. Therefore, each frequent pattern set FPc should be assigned an important weight to 
reflect its judgment importance also.  
Based on the above concept, the following notations are defined. Let fpc,k be the kth 
sequential pattern in FPc, pwc,k be the important weight of fpc,k, and cwc be the important weight 
of FPc. According to Equation (1), the similarity between sequential pattern fpc,k and a new 
sequence s, denoted as Sim(fpc,k, s), can be derived. Therefore, based on majority voting scheme, 
the sequence similarity model is modeled as: 
 







  
 ||,...,2,1
,,
,...,2,1 ||
),(
maxarg)(
cFPk
c
kckc
c
nc FP
sfpSimpw
cwxClassifier                       (3) 
 
All weights are assigned as 1 at the initial stage to indicate they are equally important, but 
will be automatically adjusted by the particle swarm optimization (PSO) algorithm later. 
A labeled instance is a pair <s, y> where s is a sequence and y is the discrete class label 
associated with x where {1, 2,..., }y n . Let a testing set TS’ is a set of labeled instances where 
TS’ = {<s1, y1>, <s2, y2>, …, <sm, ym>}. The prediction accuracy of the classification is calculated 
as: 
1,...,| '|
( ( ) )
| ' |
j jj TS
I Classifier s y
accuracy
TS
                                   (4) 
where )(I  is an indicator function that returns the value 1 if its argument is true and 0 
otherwise. 
 
3.2.3 Particle swarm optimization 
It is clear that the two sets of weights ( ,c kpw  and ccw ) in Equation (3) might dramatically 
affect the accuracy of the proposed sequence similarity classifier. Therefore, this research 
employs particle swarm optimization (PSO) algorithm (Kennedy and Eberhart, 1995) to find the 
best weights. The coding procedure for the PSO algorithm is relatively simple and easy. 
Moreover, the computation complexity and running time of the PSO is much lower [2].  
Given a training set TS, the objective function of the PSO optimization method is to 
 11 
vmax for all i and d to keep off trapping in a local area. Subsequently, as shown from lines 4 to 21, 
t
ix  are iteratively modified until the stopping criterion is reached. The stopping criterion is 
reached when the error of all objective values obtained by the particles within one iteration is 
smaller than 5% (i.e. STD <= 0.05).  
 
Algorithm PSO_method(TS, pn, vmax, w, c1, c2) 
01 Set 0
,i dx  as 1 for i = 1 to pn, d =1 to D; 
02 Set 0
,i dv  as a random value in [-vmax, vmax] for i = 1 to pn, d =1 to D; 
03 Calculate the fitness function 0( )if x  for i = 1 to pn; 
04 t = 1; 
05 while (stopping criteria is not reached){ 
06      for (i = 1; i <= pn ;i++) {    
07         if ( ( )tif x  >= 
1( )tif x
 ) {    
08           tidp  = 
t
idx  , for d = 1, 2 … , 1( )
n
cc
q n  ; // Set the local best value 
09         } 
10      } 
11      for (i = 1; i++; i <= pn) {  
12         if ( ( )tif x  == =1,...max ( )
t
ii pn
f x ) { 
13           tgdp = 
t
idx  , for d = 1, 2 … , 1( )
n
cc
q n  ;  // Set the global best value 
14         } 
15      } 
16      for (i = 1; i++; i <= pn) { 
17         tidv  = w
1t
idv
  + c1r1( tidp -
t
idx ) + c2r2(
t
gdp - 
t
idx );  // update 
t
idv  
18         tidx  = 1tidx   + 1tidv  ;    // update 
t
idx   
19      } 
20      t = t + 1; 
21 } 
22 return the particle with highest fitness value; 
Figure 3. The pseudo code of the PSO method for weight adjustment 
 
 
4. The second year - the time-interval sequential pattern mining based sequence 
classification Framework 
A time-interval sequential pattern mining based sequence classification framework, as shown 
in Figure 4, is proposed. In the first stage, the concept of time-interval sequential pattern mining 
is utilized to generate the time-interval sequential patterns for every class in the database.  
 
 13 
transactions in TD containing Sb is greater than or equals to the user-specified minimum support 
(called min_sup). Given a sequence database TD and min_sup, time-interval sequential pattern 
mining is to determine all the time-interval sequential patterns in TD whose supports are more 
than or equal to min_sup. 
In this study, the I-PrefixSpan algorithm proposed by Chen et al. [21] is used to generate the 
time-interval sequential patterns since its high computation efficiency. Three important concepts 
used in the I-PrefixSpan algorithm are introduced as follows. First, given a sequence Sa = ((a1, t1), 
(a 2, t2), …, (a n, tn)) and a time-interval sequence Sb = (b1, &1, b2, &2, …, &m-1, bm) where m n, 
Sb is a time-interval prefix of Sa if and only if (1) bi = ai for 1 im; (2) ti – ti-1 satisfies the 
condition of &i-1 for 1  i  m-1. Second, assume that Sb is a time-interval subsequence of 
sequence Sa and that i1<i2<…<im are the indexes of the elements in Sa which match the elements 
of Sb. A subsequence Sa’ = ((a’1, t’1), (a’2, t’2), (a’3, t’3), …, (a’p, t’p)) of Sa, where p= m + n – im, 
is called a projection of Sa with respect to Sb if and only if (1) Sb is a time-interval prefix of Sa’; (2) 
the last n – im elements of Sa’ are the same as the last n – im elements of Sa. Third, let Sa’ = ((a’1, 
t’1), (a’2, t’2), (a’3, t’3), …, (a’j, t’j)) be the projection of sequence Sa with respect to time-interval 
sequence Sb = (b1, &1, b2, &2, …, &k-1, bk). Then sequence Sc = ((a’k+1, t’k+1), (a’k+2, t’k+2), …, (a’j, 
t’j)) is called the postfix of Sa with respect to prefix Sb. 
The pseudo-code of the I-PrefixSpan algorithm is described in Figure 5. The α-projected 
database, denoted as |TD  , is defined by the collection of postfixes for the sequences in database 
TD with respect to α. A table TI_Table is used to store this type of relation, where column 
corresponds to an item and a row corresponds to a time-interval in TI. Each cell TI_Table (Ii, f) in 
the table records the number of transactions in |TD   that contain item f and the time difference 
between this item and the last item of α lies within Ii. Processing every transaction in |TD   
sequentially enables the table to be formed and the cells which are frequent to be identified. If the 
cell TI_Table (Ii, f) is a frequent cell, (Ii, f) can be appended to α to yield a time-interval 
sequential pattern α', and to construct the α'-projected database |TD  . Recursively discovering 
the time-interval sequential patterns in '|TD   finally yields all the time-interval sequential 
patterns in TD. 
 
Subroutine I-PrefixSpan(α, l,TD  ) 
01 Scan TD   one time. 
02 if l = 0, then find all frequent items in TD  . 
03   for every frequent item f, Append f to α as α’. 
04   Output all α’. 
05 if l > 0, then construct TI_Table by scanning all the transactions in TD  . 
06   for every frequent cell TI_Table(Ii, f), Append (Ii, f) to α as α’. 
07   Output all α’. 
08 for each α’, construct α’-projected database 'TD  ,  
09    and call I-PrefixSpan (α’, l+1, 'TD  ). 
Figure 5. The pseudo-code of the I-PrefixSpan algorithm 
 
4.2 Stage 2: Time-interval Sequence Classification Method 
 15 
“insertion” are used. The cost of taking required edit operations that change ( pb , &
b
p ) in Sb to 
( pa , &
a
p ) in Sa is defined as: 
 
, ,
, ,
1                     if insertion or deletion
1                     if substitution (with different priori items)
0     if substitution (with the same priori item)
0                   
a b p
a b p
Cost    
  if no change 

          (11) 
where , ,a b p  is defined in Equation (10) and ζ is the maximum degree of time-interval affection. 
In this study, ζ is recommended as the value less than 0.5.  
 
4.2.2 Particle Swarm Optimization - AdaBoost sequence classification method 
After completing compact sequential pattern mining in the first stage, the extracted sequential 
patterns in CSP are considered to be important features representing the sequences in TrainSD. 
However, some patterns are hard to classify since they are minor minority and irregular. The 
Particle Swarm Optimization - AdaBoost sequence classification method is proposed to solve this 
hard-to-classify pattern problem. The boosting mechanism adaptively increases the weights of 
hard-to-classify patterns so that these patterns have more opportunities to be selected for building 
PSO-based sequence classifiers, referred to as PSOSeqClassifier. In each PSOSeqClassifier, PSO 
is used to optimize two sets of weights (one for patterns and one for classes) to maximize the 
classification accuracy of the PSOSeqClassifier. 
The Particle Swarm Optimization - AdaBoost sequence classification method uses the 
Adaptive Boosting (AdaBoost) mechanism. Let the set of compact sequential patterns be CSP = 
{<cspi, ci>| i=1,…,m} where cspi denotes the ith compact sequential pattern; ci is the class label 
associated with cspi where },...,2,1{ nci  . In addition, the set of weights for corresponding 
patterns are {w1, w2, ..., wm}. Initially, equal weights (i.e. 1/m) are assigned to all compact 
sequential patterns so that they have the same probability of being chosen for training. The 
number of boosting rounds, N, is determined by the user. In each round, a sample training pattern 
set (STPk) is obtained according to the weights of the compact sequential patterns. Based on the 
sample training patterns in STPk, a PSOSeqClassifierk, is built (see Section 3.2.2 and Section 
3.2.3 for details). The error rate of each classifier PSOSeqClassifierk is calculated as: 


  

m
i
iikik ccspsifierPSOSeqClasIwm 1
)])(([1
                              
(12)
 
where )(I  is an indicator function that returns the value 1 if its argument is true and 0 
otherwise. If εk is larger than 0.5, the algorithm resets the weights of all examples as 1/m and goes 
back to the beginning of the boosting stage. Otherwise, the importance of a PSOSeqClassifierk is 
given by 
 17 
14. PSO-AB(S) =   Nk kkc cSsifierPSOSeqClasI1 ))((maxarg  . 
Figure 6. Pseudo-code of the Particle Swarm Optimization - AdaBoost sequence classification 
algorithm. 
 
5. Experimental Illustration 
A synthetic sequence dataset is used to show the feasibility for the proposed sequence 
classification method. In the experiment, Apriori-like algorithm, Maximal mining and pattern 
scoring function (PSF) are employed for comparison. The Apriori-like algorithm, which is 
proposed by Agrawal and Srkant [1], is to find all (complete) frequent sequential patterns. The 
maximal frequent sequential pattern mining algorithm, which is proposed by Guan et al. [9], 
provides a minimal representation of patterns without considering their support information. In 
addition, the pattern scoring function (PSF) proposed by Exarchos et al. [7], is utilized to measure 
the similarity between sequence and pattern. For the synthetic sequence dataset, there are totally 
200 sequences in the dataset where a sequence belongs to one of 4 class labels (c =1, 2, 3, 4). 
Each sequence is randomly generated by the set of 11 activity items I = {A, B, C, …, G} with the 
length of [5, 8]. In the following paragraph, we discuss the performance of proposed method 
under different sequential pattern mining methods and different similarity measurements. 
 
 Effects of different mining algorithms 
Table 1 shows the total numbers of patterns for all class in three sequential pattern mining 
algorithm for the synthetic sequence dataset. For this three algorithms, when min_sup value 
increases, the number of generated patterns decreases. In addition, the number of patterns 
generated by Apriori-like algorithm is larger than Closed and Maximal mining algorithm. 
 
Table 1 the number of patterns for three sequential pattern mining algorithms under different 
min_sup. 
      min_sup 
Pattern 
0.1 0.2 0.3 0.4 
Apriori-like 175 75 52 33 
Closed 129 59 42 27 
Maximal 54 27 19 19 
 
Figure 7 shows the classification accuracy results with pattern scoring function similarity 
measurement method different min_sup values. It is observed that classification accuracy 
gradually decreases when min_sup values increases. The lowest accuracy happens when the 
classification model with maximal mining algorithm, while the highest accuracy happens when 
the classification model applying apriori-like algorithm. The Accuracy with apriori-like algorithm 
is always higher than that of closed and maximal mining algorithm except when min_sup is 30%. 
Especially, the accuracy with maximal mining algorithm is the lowest than apriori-like and closed 
algorithm. The maximal mining algorithm can provide a compact representation of frequent 
 19 
 
 
Figure 9. Computational time under different min_sup values 
 
 Effects of different similarity measurement methods 
Table 2 shows that the classification accuracy of two similarity measurement methods under 
three mining methods. It is observed that the classification accuracy with SSM always has a 
higher accuracy then PSF similarity measurement. The maximal mining algorithm used in PSF 
and SSM has the lowest accuracy than other two mining algorithm. The classification accuracy 
with SSM is higher than the accuracy with PSF by three mining algorithm. The experiment shows 
that the SSM is proper applied in sequence classification than PSF similarity measurement. 
 
Table 2 Classification accuracy with different similarity measurement method 
min_sup 
PSF SSM 
Apriori-like Closed Maximal Apriori-like Closed Maximal 
0.1 77.5 72.5 47.5 90 95 87.5 
0.2 77.5 70 40 87.5 92.5 85 
0.3 67.5 72.5 52.5 90 90 82.5 
0.4 65 65 45 90 90 87.5 
Average 71.875 70 46.25 89.375 91.875 85.625 
 
5 Conclusions 
Nowadays, how to seizing customer behavior and making proper business strategies to 
different types of customers are important issues for enterprises. Therefore, applying 
classification technique to discriminate customer behavior becomes an important research topic. 
Two popular data mining techniques, sequential pattern mining and sequence classification, has 
been employed to discover customer behavior recently. However, previous researches reveal two 
major problems. First, previous works simply utilizes all found sequential patterns as features to 
construct classification models. The large sequential patterns might contain redundant and 
 21 
二、參考文獻 
References 
[1]  Agrawal, R., Srikant, R. (1995). Mining sequential patterns. In: Proceedings of the Eleventh 
International Conference on Data Engineering. Taipei, Taiwan, 3-14. 
[2]  Arumugam, M.S., Rao, M.V.C., Chandramohan, A. (2008). A new and improved version of 
particle swarm optimization algorithm with global–local best parameters. Knowledge 
Information System, 16 (3), 331-357. 
[3]  Deshpande, M., Karypis, G. (2002). Evaluation of techniques for classifying biological 
sequences advances in knowledge discovery and data mining. In M.-S. Chen, P. Yu & B. Liu 
(Eds.), (Vol. 2336, pp. 417-431): Springer Berlin / Heidelberg. 
[4]  De Souza Rodrigues, T., Cardoso, F. C., Teixeira, S. M. R., Oliveira, S. C., Braga, A. P. (2011). 
Protein classification with extended-sequence coding by sliding window. IEEE/ACM 
Transactions on Computational Biology and Bioinformatics, 8, 1721-1726. 
[5]  Eberhart, R.C., Shi, Y. (2001). Particle swarm optimization: developments, applications and 
resources. In: Proceedings of the IEEE Conference on Evolutionary Computation, ICEC 1, 
81-86. 
[6]  Exarchos, T. P., Papaloukas, C., Lampros, C., Fotiadis, D. I. (2008). Mining sequential 
patterns for protein fold recognition. Journal of Biomedical Informatics, 41, 165-179. 
[7]  Exarchos, T. P., Tsipouras, M. G., Papaloukas, C., Fotiadis, D. I. (2009). An optimized 
sequential pattern matching methodology for sequence classification. Knowledge and 
Information Systems, 19, 249-264. 
[8]  Fayyad, U.M., Piatetsky-Shapiro, G., Smyth, P. (1996). From data mining to knowledge 
discovery: an overview. in: Advances in Knowledge discovery and Data Mining, AAAI 
Press/MIT Press, pp. 1-36. 
[9]  Guan, E.Z., Chang, X.Y., Wang, Z., Zhou, C.G. (2005). Mining Maximal Sequential patterns.  
In IEEE, pp. 525-528. 
[10]  Han, J., Cheng, H., Xin D., Yan, X. (2007). Frequent pattern mining: current status and 
future direction. Data Mining and Knowledge Discovery, 15(1), 55-86. 
[11]  Kennedy, J., Eberhart, R. (1995). Particle swarm optimization. In Proceedings of the IEEE 
International Conference on Neural Networks. Part 1 (of 6) (Vol. 4, pp. 1942-1948). Perth, 
Aust. 
[12]  Lesh, N., Zaki, M. J., Ogihara, M. (1999). Mining features for sequence classification. Fifth 
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 
pp.342-346, 1999. 
[13]  Lesh, N., Zaki, M. J., Ogihara, M. (2000) Scalable feature mining for sequential data. IEEE 
Intelligent Systems and Their Applications, 15, 48-56. 
[14]  Lipeika, A. (2010) Optimization of formant feature based speech recognition. Informatica, 
21, 361-374. 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                         102年 10  月 20  日 
報告人姓名 
 
蔡介元 
 
服務機構
及職稱 
元智大學工管系 
教授 
時間 
會議地點 
2013/7/22 – 2013/7/26, 
Kyoto, Japan 
本會核定
補助文號
NSC100-2628-E-155-005-MY2 
會議 
名稱 
 (中文)  
 (英文) The 37th Annual International Computer Software & Applications 
Conference (COMPSAC 2013) 
發表 
論文 
題目 
 (中文) 
 (英文)  A Customized Visiting Route Service under RFID Environment 
報告內容應包括下列各項： 
 
一、 參加會議經過 
    COMPSAC (Computers, Software, and Applications)是 IEEE的旗艦級研討會，目前已
進入第三十七屆，本次的會議主題為「The Expanding Sphere of Software and Data」，主
要探討目前數位社會、電腦人機系統、語意網、行動計算等重要議題。本人此次參加的
為合併舉辦的 The 6th IEEE International Workshop on Service Science & Systems，會中有
許多有關 Service相關的議題，例如網路服務、健康提醒服務、及行動服務等。今年在
日本京都 Kyoto Terrsa舉辦，有京都大學、Iowa State University等學術機構協辦，為期
五天。在會議進行過程中，可以聽取來自世界各地的學者所從事的研究成果，並一起討
論研究心得。另外，本人也聆聽了數個所感興趣的研究主題，以及和海報論文作者討論
等，除了可以訓練自己英文聽與說的能力外，其他學者的研究方法也是本人能夠學習的
目標。本人此次的報告重點如下： 
 
How to provide a high quality service according to consumer preference becomes a critical 
issue for amusement park to survive in a rapidly changing environment. To fulfill the need, 
this research proposes a customized visiting route service that provides tourists what facilities 
they should visit and in what order. In the studied environment, all regions are covered by 
Radio-Frequency Identification (RFID) readers so that the visiting behavior of a tourist (i.e. 
visiting location, sequences, and corresponding timestamps) can be collected and stored in a 
route database. The proposed route recommendation service consists of two major modules. 
The first module is to discover the frequent Location-Item-Time (LIT) sequential patterns 
using the proposed sequential pattern mining procedure. In the second module, the route 
suggestion procedure will filter the LIT sequential patterns under the constraints of 
intended-visiting time, favorite regions with its related visiting time, and favorite recreation 
facilities, then select the top-k suggested routes to guide the visitors. To show the feasibility of 
the proposed route recommendation system, the Tokyo DisneySea in Japan is used as an 
example. Based on the experimental results, it is clear that the recommended route can not 
only follow previous tourists’ visiting experiences but also satisfy the visitor’s customized 
requirement. 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2013/10/21
國科會補助計畫
計畫名稱: 以消費者行為序列探勘為基礎之分類模型
計畫主持人: 蔡介元
計畫編號: 100-2628-E-155-005-MY2 學門領域: 資訊系統
無研發成果推廣資料
中，詳細資料如
下： 
Tsai, 
Chieh-Yuan*, 
Chen, Chih-Jung, 
2013, “A PSO-AB 
Classifier for 
Solving Sequence 
Classification 
Problems,＂ 
Applied Soft 
Computing. (In 
Review) [SCI] 
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100%  
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100% 訓練外國碩士生研究人力 1 人次 
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
這個計畫的研究成果已被出刊，詳細資料如下： 
Tsai, Chieh-Yuan, Chen, Chih-Jung, Chien, Chun-Ju, 2013, “A time-interval 
sequence classification method,＂ Knowledge and Information Systems, Vol. 37, No. 
2, pp. 251-278. [SCI] 
 
另一篇文章已投稿，目前為審查中，詳細資料如下： 
Tsai, Chieh-Yuan*, Chen, Chih-Jung, 2013, “A PSO-AB Classifier for Solving 
Sequence Classification Problems,＂ Applied Soft Computing. (In Review) [SCI] 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
預期貢獻 
 對於產業方面 
在現今競爭激烈與環境變化快速的商業環境中，企業若能掌握正確的時機，提供其顧客所
需，將會比其他競爭者更有立足與生存的機會。為了滿足顧客需求，對公司決策者來說，
能確實掌握顧客的消費行為模式是相當重要的工作。雖然企業內部掌握了顧客的消費紀
錄，然而這些資料往往龐大且紊亂，造成顧客行為分析之工作進行困難。因此，本計畫的
執行將可以協助企業管理者快速地對新客戶的序列進行分析，並準確地預測目標客戶所屬
的分類。 
 
 對於學術貢獻方面 
誠如在研究問題中所述，目前序列分類的研究除了在生物蛋白質序列分類的應用外，未能
有學者將之應用於客戶關係管理中的顧客分類。此外，目前的序列樣式探勘方法多未能將
