2 
本研究的成果已投稿 ACM Transactions on Design Automation of 
Electronic Systems, 目前進行revised 中. 
“In-place Depth-First Branch-and-Bound Search for the Resource 
Constrained Scheduling Problem during High Level Synthesis” 
CHENG-JUEI YU, YI-HSIN WU, AND SHENG-DE WANG 
4 
可利用之產業 
及 
可開發之產品 
 
影音設備IC設計 
技術特點 
本發明係有關於一種管線化移動估測器及管線化移動估測系
統，可使每個處理單元各自處理一個目前區塊及對應之一個
參考區塊的資料，如此，處理單元之間不需進行接線，而能
降低電路複雜度、並減少所需面積。再者，還能避免於此些
處理單元之間傳遞計算結果，從而降低所需的計算時間。  
推廣及運用的價值 
本發明是有關於一種估測器及估測系統，且特別是有關於一
種管線化移動估測器及管線化移動估測系統。  
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位研發成果推廣單位（如
技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
 
[Sllame and Drabek 2002], and [Krishnan and Katkoori 2006] use various heuristics to 
find good designs.  
Besides heuristic algorithms, mathematical formulations are a kind of approaches to 
exactly solve the scheduling problem. Methodologies presented in [Hwang et al. 1991; 
Gebotys and Elmasry 1993; Chaudhuri et al. 1994] are such mathematical approaches 
that formulate the synthesis problem as an integer linear programming (ILP) problem, 
which is NP-complete in general and involves the optimization of a linear objective 
function, subject to linear equality and inequality constraints. These approaches give 
optimal solutions, but their computational complexity is exponential; as the number of 
variables in the formulations increases very rapidly with the size of the DFG, tight 
resource constraints can cause ILP models to take inordinately long to be solved 
[Narasimhan and Ramanujam 2001].  
Another approach for exactly solving this problem is using graph search algorithms, 
which are a general algorithmic method for finding optimal solutions of various 
optimization problems. Two such algorithms are BULB [Narasimhan and Ramanujam 
2001] and A* approach [Wu et al. 2009]. BULB uses a branch-and-bound search method 
which is basically an enumeration approach in a fashion that prunes inferior design points, 
and tries to decompose the scheduling problem into a number of smaller subproblems, 
many of which need not be solved because of the use of upper- and lower-bounding 
techniques. However, refer to the results provided by RECALS II [Rim and Jain 1994], 
the schedules produced by BULB can be further improved. The A* approach traverses 
the search space with the help of an admissible heuristic proposed by Langevin and 
Cenry [1996] to guide the path extraction. For a given consistent heuristic, the A* 
algorithm is guaranteed to find an optimal goal with the minimum number of nodes 
expanded among all algorithms [Zhang 1999]. However, compared to BULB, the run 
times of the A* approach are too long, and its space complexity is exponential [Russell  
and Norvig 2003], resulting in a chance of running out of space such that it cannot 
guarantee the solution optimality.  
In this paper, we present a search strategy using the depth-first branch-and-bound 
(DFBnB) method [Zhang 1999] for computing exact solutions to the RCS problem. 
Instead of using naïve DFBnB whose space complexity is linear in the search depth, we 
propose a modified version of DFBnB, which is an in-place algorithm [Cormen et al. 
2001] that only needs a small, constant amount of extra storage space during the search 
process. Using a lexicographical ordering method described in [Knuth 2006] for 
generating combinations, the in-place algorithm visits search nodes in such a way that 
solution achieved so far, can be updated when a leaf is visited. The completion of the 
search process occurs when α reaches C(r), or all the search tree is traversed. 
 
 
Fig. 1  The search tree.  
 
DFBnB, best-first search (BFS), iterative-deepening (ID), and recursive best-first 
search (RBFS) are various search strategies that can traverse a search tree. However, as 
discussed in [Zhang and Korf 1995], the space complexity of BFS (as well as A*) is 
typically exponential, ID should be applied to problems that cannot be represented by 
bounded-depth trees, and RBFS should be adopted on a problem that can be solved in 
polynomial time. DFBnB is the best, however, on a problem that requires exponential 
computation, and whose search space can be represented by a bounded-depth tree. 
Therefore, for the RCS problem we choose DFBnB to be the search strategy. 
Fig. 2 shows the naïve procedure of DFBnB (with a slight modification of discarding 
edge costs since each of them is identical in our approach) introduced by W. Zhang 
[1999], which is invoked with NaïveDFBnB( r, C(r), ∞ ). In the procedure, all k children 
n1, n2, …, nk of search node n are generated and each of them is evaluated by C(ni) to 
check whether the search should be deepened or not. If some child ni is a goal node such 
that h(
in
U ) equals 0, the upper bound α is updated. In addition, if α reaches the lower 
bound of the DFG, an exception is reported to indicate the completion of the search 
process.  
Conceptually, the procedure of DFBnB starts from the root, and has the following 
three different actions at each search node: a) branches to its leftmost (first) child b) 
bounds to its right sibling, and 3) jumps (backtracks) to its uncle when all its siblings are 
visited. Since for a given DFG and some resource constraints there are typically many 
As introduced by Knuth [2006], instead of merely generating all combinations, we 
often prefer to visit them in such a way that each one is obtained by making only a small 
change to its predecessor. For instance, as shown in Fig. 3 which is a lexicographical 
order of 





5
10
 = 252 combinations, the ith combination can be obtained from the i-1th by 
applying Algorithm L specified in [Knuth 2006]. Thus, let the ith combination be exactly 
the ith child of search node n, we can orderly visit all Kn children appeared in (1) without 
keeping any parent nodes in memory. 
 
Fig. 3.  The lexicographical order of 





5
10
 = 252 combinations. Each column represents 
a combination with 5 light cells selected out of 10. 
 
Typically a DFG may have two or more resource classes, say multiplier β and adder 
γ, such that we have to generate combinations for β and γ separately. Fig. 4 specifies 
the method of enumerating the next combination (or right sibling, equivalently) of search 
node n, consider resource classes β and γ. When the enumeration of combinations for 
β is finished, we reinitialize the combination for  β and advance to the enumeration of 
combinations for γ. 
______________________________________________________________ 
 
NextCombination( n ): 
if n has next combination for β 
apply Algorithm L for β 
/* enumeration of combinations for β is finished */ 
else if  n has next combination for γ 
reinitialize the combination for  β 
apply Algorithm L for γ 
/* both enumerations are finished */ 
else return null 
______________________________________________________________ 
 
Fig. 4.  Enumerate the next combination of n, consider resource classes β and γ. 
 
 
Child( n ): 
assign the first Xm out of Ym operations at Rn to time-step d(n)+1 
d(n) ← d(n) + 1 
update Rn 
______________________________________________________________ 
 
Sibling( n ): 
n ← NextCombination( n ) 
if  n = null 
n ← Parent( n ) 
return Sibling( n ) 
else return  n  
______________________________________________________________ 
 
Parent( n ): 
if  d(n) = 1  
raise SearchCompleteException 
else  
d(n)← d(n) - 1 
update Rn 
end 
______________________________________________________________ 
 
Fig. 6.  Tree traversal operations. 
 
Recall that the lower bound on the completion time of partial schedule Pn is 
determined by C(n) = d(n) + h(Un). Since the number of partial schedules is generally 
very high in the design space search, the estimate function h for partial schedules should 
be faster than that for the entire DFG. One method of computing h is proposed by 
Tiruvuri and Chung [1998], denoted Ψ, which has the computational complexity of O(n 
+ c2), where n is the number of nodes in the DFG and c is the critical path. Another 
method proposed by Langevin and Cenry [1996], denoted Ω, has a higher complexity, 
O(n2 + c2), which recursively applies the algorithm proposed by Rim and Jain [1994] by 
n times. Though Ω is slower, sometimes it can produce tighter bounds than Ψ. Therefore, 
since the lower bound for the entire DFG, C(r), needs to be accurate and is computed 
only once before the search, we use Max(Ψ, Ω) to determine the value of C(r). Besides, 
the faster one Ψ is used for computing h(Un) during the search execution. 
 
4. EXTENSIONS 
 Our approach is basically designed for unit-cycle operations. For supporting pipelined 
and multicycle operations, we follow the same idea discussed in [Rim and Jain 1994; Wu 
2  2 
3  3 
18 
17 
<0.01 
<0.01 
18 
17 
 <0.01 
 <0.01 
18 
17 
0.09 
0.08 
18 
- 
18 
17 
ARF 1  1 
2  1 
2  2 
3  1 
4  1 
3  2 
3  3 
4  2 
34 
18 
18 
16 
16 
15 
15 
11 
11.22 
0.29 
2.34 
<0.01 
<0.01 
10.90 
11.35 
<0.01 
34 
18 
18 
16 
16 
15 
15 
11 
2.1 
2.7 
5.5 
3.4 
3.4 
33.9 
32.7 
3.2 
34 
18 
18 
16 
16 
15 
15 
11 
0.07 
0.87 
0.19 
2.36 
0.45 
2.12 
1.92 
0.22 
34 
18 
- 
16 
- 
15 
15 
- 
34 
18 
- 
16 
- 
15 
- 
11 
FDCT 1  1 
2  1 
2  2 
2  3 
3  2 
3  3 
3  4 
4  2 
4  3 
4  4 
4  5 
5  4 
5  5 
8  4 
34 
26 
18 
18 
14 
14 
14 
13 
11 
11 
11 
10 
10 
08 
0.01 
<0.01 
†† 
<0.01 
213.25 
1.03 
†† 
<0.01 
107.03 
<0.01 
<0.01 
<0.01 
<0.01 
<0.01 
34 
26 
18 
18 
14 
14 
14 
13 
11 
11 
11 
10 
10 
08 
1.1 
1.0 
1.3 
1.6 
1.4 
1.5 
85.3 
15.9 
2.2 
250.9 
308.7 
1.6 
1.2 
1.5 
34 
26 
18 
18 
14 
14 
14 
13 
11 
11 
11 
10 
10 
08 
0.38 
0.05 
0.23  
0.11 
0.23 
0.11 
0.06 
  4.91 
101.08 
100.46 
119.89 
0.04 
0.04 
0.03 
34 
- 
18 
- 
14 
14 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
2 
times 
unfolded 
EWF 
1  1 
2  1 
1  2 
2  2 
1  3 
2  3 
3  3 
56 
56 
41 
35 
41 
35 
33 
<0.01 
<0.01 
0.04 
0.02 
0.04 
0.01 
<0.01 
56 
56 
40 
35 
40 
34 
33 
43.3 
44.1 
12.1 
8.8 
12.1 
3.8 
3.4 
 
 
† 
 
† 
† 
56 
56 
40 
35 
40 
34 
33 
2.09 
2.06 
2.05 
2.10 
2.06 
2.01 
1.98 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
3 
times 
unfolded 
EWF 
1  1 
2  1 
1  2 
2  2 
1  3 
2  3 
3  3 
84 
84 
61 
52 
61 
52 
49 
<0.01 
<0.01 
0.08 
0.04 
0.08 
2460 
<0.01 
84 
84 
59 
52 
59 
50 
49 
451.4 
460.0 
136.3 
111.3 
136.6 
66.4 
61.6 
 
 
† 
 
† 
† 
84 
84 
59 
52 
59 
50 
49 
12.12 
12.19 
12.91 
15.73 
13.02 
12.05 
11.67 
84 
- 
- 
52 
- 
50 
49 
84 
- 
- 
52 
- 
50 
49 
Bench- 
mark 
# of 
*p, a 
BULB 
#steps 
BULB 
sec. 
A* 
#steps 
A* 
sec. 
DFBnB 
#steps  
DFBnB 
sec. 
DPS 
#steps 
RECALS 
II  #steps 
EWF 1  1 
1  2 
28 
19 
<0.01 
0.04 
28 
19 
0.7 
0.1 
28 
19 
0.13 
0.13 
- 
- 
28 
19 
exponential in the search depth. We demonstrated the effectiveness of our approach by 
comparing the run times and the produced schedule lengths to the BULB [Narasimhan 
and Ramanujam 2001] and A* approach [Wu et al. 2009]. The experimental results show 
that in most cases, our algorithm is much faster than A* approach, and in some larger-
sized problems, our approach can produce superior schedules than BULB. Therefore, our 
work eliminates the need of replacing exact techniques with heuristic-based approaches 
in an effort to obtain good solutions within acceptable runtimes, and can solve the 
scheduling problems by using a simple platform running a search algorithm. 
 
REFERENCES 
SLLAME, A.M. AND DRABEK, V. 2002. An efficient list-based scheduling algorithm for high-level synthesis. 
In Digital System Design, 2002. Proceedings. Euromicro Symposium on, 316-323. 
 
HWANG, C.T., LEE, J.H. AND HSU, Y.C. 1991. A formal approach to the scheduling problem in high level 
synthesis. Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on 10, 464-475. 
 
GEBOTYS, C.H. AND ELMASRY, M.I. 1993. Global optimization approach for architectural synthesis. 
Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on 12, 1266-1278. 
 
GAJSKI, D.D. AND RAMACHANDRAN, L. 1994. Introduction to high-level synthesis. Design & Test of 
Computers, IEEE 11, 44-54. 
 
TIRUVURI, G. AND CHUNG, M. 1998. Estimation of lower bounds in scheduling algorithms for high-level 
synthesis. ACM Trans. Des. Autom. Electron. Syst. 3, 162-180. 
 
PARK, I.C. AND KYUNG, C.M. 1993. FAMOS: an efficient scheduling algorithm for high-level synthesis. 
Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on 12, 1437-1448. 
 
NESTOR, J.A. AND KRISHNAMOORTHY, G. 1993. SALSA: a new approach to scheduling with timing 
constraints. Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on 12, 1107-1122. 
 
KRISHNAN, V. AND KATKOORI, S. 2006. A genetic algorithm for the design space exploration of datapaths 
during high-level synthesis. Evolutionary Computation, IEEE Transactions on 10, 213-229. 
 
LANGEVIN, M. AND CERNY, E. 1996. A recursive technique for computing lower-bound performance of 
schedules. ACM Trans. Des. Autom. Electron. Syst. 1, 443-455. 
 
NARASIMHAN, M. AND RAMANUJAM, J. 2001. A fast approach to computing exact solutions to the 
resource-constrained scheduling problem. ACM Trans. Des. Autom. Electron. Syst. 6, 490-500. 
 
RIM, M. AND JAIN, R. 1994. Lower-bound performance estimation for the high-level synthesis scheduling 
problem. Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on 13, 451-458. 
 
PARK, N. AND PARKER, A.C. 1988. Sehwa: a software package for synthesis of pipelines from behavioral 
specifications. Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on 7, 356-370. 
 
CHAUDHURI, S., WALKER, R.A. AND MITCHELL, J.E. 1994. Analyzing and exploiting the structure of the 
constraints in the ILP approach to the scheduling problem. Very Large Scale Integration (VLSI) Systems, IEEE 
Transactions on 2, 456-471. 
 
WU, Y.H., YU, C.J. AND WANG, S.D. 2009. Heuristic algorithm for the resource constrained scheduling 
problem during high-level synthesis. Computers & Digital Techniques, IET 3, 43-51. 
 
W. Zhang. State Space Search: Algorithms, Complexity and Applications. New York: Springer-Verlag, 1999. p. 
145. 
 
A System-level Power Estimation Approach based 
on RTL Macro-Modeling and Using SystemC 
摘要 
因為系統單晶片(SoC)的快速發展尤其對可攜式的電子產品的高度需求量，為
了讓使用者能在有限的電池能量下，有更長的使用時間，因此功率消耗成為另一
個設計限制因素。再加上快速導入市場時程的壓力，系設計者需要能在更早設計
階段即對功率消耗作評估分析並加速系統設計的時程。因此在本研究中，主要探
討的主題即為系統層級的功率消耗評估方法，基於現今主要的設計方法－矽智產
(Intellectual Property，IP)重覆使用的概念下，我們應該亦能夠加入 IP 資訊再次利
用的考量點。因此在本研究中基於這個基本概念，延伸出一些新的看法。同時對
於重覆使用資訊的方式，我們採用 Macro-Modeling 方式來重建功率消耗訊息的相
關資訊庫，即為量測較低階級的最小操作行為模型的功率消耗資訊，並且於系統
層級重新使用之，因此我們可基於這樣的操作行為模型去建構出系統層級的架構，
進而完成系統層級的功率消耗評估模型。由實驗模擬分析的結果可得知，我們可
藉由系統層級的抽象化進而提供更為快速的模擬驗證環境並提供某程度上的準確
性；相較暫存器傳輸層級(RTL)的方法，我們的方法所評估出的功率消耗分析數據
同樣可達相當接近的準確性；而驗證所需的時間，依所架構的環境複雜度，有加
速數十倍到數百倍之差。 
 
關鍵字：系統層級，功率消耗評估，SystemC 
1. 緒論 
1.1 簡介 
由於可攜帶式系統的高度市場需求以及各種電子產品整合度越來越高，尤其
是在可攜帶式電子消費產品，例如個人行動電話、個人數位助理(PDA)與筆記型電
腦等產品的體積越來越靈巧，但是功能的需求也越來越來多，因此內部晶片電路
越設計越複雜，電路面積也越來越大。 
隨著製程技術的進步，電子產品中的晶片設計走向SoC已經是大勢所趨了。尤
其現今電路設計中，要求高輸出率與低總時間延遲之情況下，操作速度朝向極限
邁進，導致功率消耗大大的增加，並且產生了冷卻散熱的成本以及產品可靠度的
問題。 
高效能晶片的共同特點是高整合密度和高時脈頻率，如此功率消耗以及溫度
都將因操作時脈頻率增加而增加。由於消耗的熱能必須有效的移出以使得晶片的
溫度能保持在可接受的範圍，晶片封裝、冷卻以及散熱的成本均變成這些電路的
重要限制因素。尤其攜帶式系統是以電池為主要能量來源，為一個有限能量的系
統，需要的是低功率消耗和高吞吐量這二大特性，換言之，功率消耗成為在系統
效率之外的一個設計限制因素。因此在現代化的數位系統設計中，如何在功率消
耗和系統效能的取捨，取得一個帄衡點成為一個新的系統設計議題。 
  功率消耗的問題考慮已漸漸被提前到系統設計階段。隨著 SoC 低功率消耗的
設計限制漸為重要，已逐漸推往較高層次的設計階段。再加上快速導入市場時程
的壓力，傳統的設計流程往往是最後的設計階段才能得知功率消耗是否符合設計
限制，倘若不合乎設計限制就得重新設計，直到符合設計規格。但是這個方法有
著耗時設計問題以及設計成本過高的問題。因此系統設計者若能在較早的設計階
段中，正視功率消耗的問題，對於傳統設計方式的缺點就能克服並且避免掉。 
  系統單晶片要成功實現，設計者將要面臨龐大系統規格的設計與硬體驗證的
諸多挑戰。過去設計流程中使用 C/C++ 來作為系統演算法層次的功能驗證，用硬
2. 相關研究與背景知識 
 
在這章節分為二個部分作討論，第一部分針對SystemC相關背景知識作介紹，
第二部分對先前有關系統層級功率消耗分析的相關研究工作做概要性介紹。 
 
2.1 SystemC 程式語言 
SystemC[27]是 1999 年 9 月時由 EDA 廠商與 ARM、ST、NEC、Motorola 等
組成的 OSCI (Open SystemC Initiative)組織所訂定的系統與硬體模型建構語言，它
新增許多支援硬體觀念的 C++類別，還有各種硬體描述的資料型別。 
制訂 SystemC 的主要目的是想讓系統、軟體和硬體工程師使用相同的程式語
言來做開發產品，避免溝通不良的情況並能夠利用 SystemC 模型建立系統帄台進
行硬體/軟體的共同設計，這樣將能夠確定硬體實現方法和軟體實現方法之間的折
衷並簡化設計流程，提早產品上市時間。 
 
2.1.1 什麼是 SystemC 
SystemC 建立在 C++程式語言基礎之上。C++是一種可延展的物件導向建構語
言。SystemC 擴展了 C++語言的功能，使其能對硬體架構進行建構描述。SystemC
引入了一些重要的概念進入 C++，例如多程序的並行性、具時間性的事件和各式
各樣的資料型別。SystemC 增加一個類別(Class)函式庫而延展了 C++語言的功能。
此類別函式庫不是對 C++作修改，而是一個採用標準合法 C++程式碼，所編制而
成的各種函式，資料型別以及其他語言結構的函式庫。簡而言之，SystemC 的本質
上就是 C++。 
類別函式庫提供功能強大的機制去架構出具有硬體時間、同時進行、有互動
行為的系統架構。這些機制完全建立在用於 C++語言的類別結構之上。因此，
2.1.2 SystemC 與其他語言的比較 
嚴格地說，SystemC 並非是程式語言，而是一個基於 C++語言並建好的類別函
式庫。但相較其他語言，SystemC 有著相對容易的建構的特性以及彈性。正因為基
於 C++的標準，其提供了硬體和軟體之間提供了一個共通的語言。 
有幾個語言也是用來處理各式各樣的系統設計的問題，雖然 Ada 和 Java 已被
證明他們的價值，但在現今嵌入式系統設計的領域中，C/C++早已廣泛使用，具有
其權威性的影響力。硬體描述語言 VHDL 和 Verilog 是用來模擬及合成數位電路之
用。Vera 和 e 是複雜的 ASIC2功能驗證的一個選擇語言。SystemVerilog 為一個新
的語言引入用來處理硬體導向的系統設計問題。Matlab 和其他工具軟體如 SPW 和
System Studio 廣泛地被用來捕捉系統的需求規格以及用來發展數位訊號處理的演
算法。 
圖表 2.2 標示出上述所談及各個語言之所要處理的應用問題，對時可以發現除
了各個程式語言都有主要處理的領域之外，也可發現有一些重疊的地方。 
 
圖表 2.2 SystemC 與其他語言的比較 (source [25]) 
                                                     
2
 ASIC（Application Specific Integrated Circuit）是依特定用途而設計的特殊規格邏輯
IC。ASIC 一般並沒有標準規格，但依設計方式的不同，又可分為 PLD、閘排列、電路
元設計及全客戶設計等。  
2.2.1 軟體的系統層級功率消耗分析 
  Dalal, V. and Ravikumar, C. P[10]採用基於追蹤(trace)方式的功率消耗評估方法，
功率消耗為基於CMOS的假設，因此在軟體端的考慮即為處理器、記憶體電路、以
及系統匯流排的電子電路開關活動的功率消耗模型，電容的充放電根據前後的狀
況而定，例如一個8位元(bit)的匯流排，假設資料由’001000101’變為’100100010’即
有六次的轉換或切換。藉由ARM[22]軟體開發工具套件所包含的ARM處理器的指
令集模擬器ISS(Instruct Set Simulator)，稱之為ARMulator[22]，能在沒有真實地去
存取硬體的情形下模擬並執行ARM應用程式，ARMulator提供了一個追蹤的工具，
使得設計者可以經由追蹤的方式而取得執行的指令、記憶體的存取型別，以及任
何在執行中間所發生的事件。例如這個追蹤工具可提供我們像S-cycles(Sequential 
Access Cycle)，N-cycles(Non-Sequential Access Cycle)，和I-cycles(Internal Access 
Cycle)的資訊給使用者。最後根據追蹤所提供的周期數(Cycle)以及統計量化計算而
取得的相對功率消耗消耗數值。但此方法的適用性只適用於特定的架構－ARM7 
系列處理器，其適用範圍性就大大折扣。 
同樣也有一些研究是基於指令集模擬器所有擁有的特性或整合有功率消耗評
估 指 令 集 模 擬 器 的 相 關 研 究 [17][18][19] ， 例 如 使 用 SimpleScalar[14] 、
SimplePower[15]、Sim-Panalyzer[16]藉由模擬器本身所擁有的功率消耗評估能力進
而延伸的相關研究工作。藉由ARMulator指令集模擬器的功率消耗分析相關研究
[20][21]，ARMulator本身並沒有提供ARM處理器相關指令集的功率消耗資訊，所
提供能處理以及參考的只有程式執行的周期數及運算處理時間的資訊，為了達到
功率消耗評估的能力，藉由引入DC-DC能量轉換模型的整合，形成基於周期精確
的功率消耗模擬分析，其中DC-DC能量轉換模型會對個別元件加總計算個別的每
一個周期的電流值，最後即能得到系統元件的總消耗能量。 
 
2.2.3 AMBA 匯流排的系統層級功率消耗分析 
關於對於AMBA匯流排功耗模型的討論[11]，表格2.1呈現了其所選取且分析的
個別指令集所耗費之帄均能量，使得能經由這些功率消耗資訊來實行功率消耗分
析及最佳化的可能性，同時表格2.1內也呈現了，當其操作於100MHz的時脈頻率以
及總操作時間為50μs的模擬過程中的總消耗能量值。同時也可以從表格2.1的實驗
數據中了解到一個重要的特性，整個能量消耗對於單獨匯流排仲裁機制(Arbitration)
所佔的比例只有12.69%，而佔總能量消耗的87.31%其主要處理的內容為資料傳輸
中間並而沒有匯流排的交握，基於此範例的架構也告知了一個減少功率消耗最佳
化的方法及結論，即專注於AHB資料路徑的部分，可達到最有可能減少功率消耗
機會。 
 
表格 2.1 AMBA AHB 匯流排指令能量消耗分析(source [11]) 
Instruction 
Average 
energy 
Total energy 
per instruction 
IDLE_HO_IDLE_HO 14.7 pJ 96.5 μJ 11.49% 
IDLE_HO_WRITE 16.7 pJ 0.5 μJ 0.06% 
READ_WRITE 19.8 pJ 417.7 μJ 49.75% 
READ_IDLE_HO 22.4 pJ 9.6 μJ 1.14% 
WRITE_READ 14.7 pJ 315.3 μJ 37.56% 
Total simulation energy 839.6 μJ 100 % 
 
  
能完成。在實驗中[9]也指出了在額外多了數個功率消耗分析監視模組元件加入模
擬驗證，勢必形成模擬驗證上的負擔。 
 
 
 
圖表 2.4 基於異質監視模組的系統層級功率消耗分析架構 
 
2.3 摘要 
在完成相關研究以及背景知識的說明，在下一章節專門對於現有的暫存器傳
輸層級的功率消耗分析方法作相關的解析，並對一些實作缺點及不便之處給予點
出並說明，最後摘要二個解決的方式，並提出我們的想法。 
  
信號切換頻率。 
XPower 把個各元件的功率消耗求和加總後作為 FPGA/CPLD 的整體功率消耗，
每個元件的功率消耗可以表示為： 
 
                          𝑃 = 𝛼 × 𝐶 × 𝑉2 × 𝐹                            (1) 
 
其中的 P 為功率消耗，單位為瓦(W)；C 為電容，單位為法拉(F)；α 為元件在
系統中的切換翻轉頻率(即單位時脈周期的帄均切換變動次數)；F 為其操作頻率
(Hz)；V 為操作工作電壓，單位為伏特(V)。 
電容值取決於使用者的設計，因此在選定裝置元件，完成布局和繞線(Place and 
Route)之後，電容值也隨之確定，操作工作電壓可以在 XPower 軟體界面中設置。
α×F 為單位時間中信號的切換翻轉次數，其中 F(即元件的切換翻轉頻率)是最難以
確定的參數，設計者可經由設定預設的切換翻轉活動頻率，在 XPower 的使用者界
面中對特定信號指定個別的切換翻轉活動頻率，或者讀取 HDL 模擬器所轉儲生成
的 VCD 文件等方式為 XPower 提供這個參數。在本研究中選用讀取 HDL 模擬器
所轉儲生成的 VCD 文件方式來確保參數取得的準確性。 
 
3.3 使用 XPower 分析功率消耗 
當設計完成布局繞線之後，在Xilinx ISE專案瀏覽器中即可直接啟動XPower，
這時 XPower 會自動讀入系統設計檔案(.NCD)、實體限制設定檔案(.PCF)、整體系
統環境的設定檔(.XML)，如下圖表 3.1 顯示的訊息視窗，設計者根據需求再載入信
號模擬轉儲檔案(.VCD/.XAD)並設置相關參數之後，即可產生 XPower 的功率消耗
分析報告。 
對於 VHDL 語言，使用 ModelSim SE 時如圖表 3.3，可以在 do 文件中加入以
下的語法以便產生 VCD 檔案。 
 
 
 
 
因此使用 VCD 檔案有其方便性、估計準確的特性，因此在本研究實驗中採用
之。 
然而，當電路設計較大時或者模擬時間較長時，VCD 檔案也將隨之增大，
XPower 功率消耗分析模擬器載入 VCD 檔的時間也同時由長達數分鐘變至長達數
小時之久，因此容易讓使用者會有 XPower 程式當掉的錯覺。尤其 VCD 檔很容易
產生超過 1GB 以上的信號資料，都是很常見的情形，因此 Xilinx 公司提供了一些
解決方案[21]，以解決 VCD 檔案過大的問題；建議設計者將整個設計區分為數個
獨立模組作功率消耗分析，然後最後再加總全部模組所得到的功率消耗評估結果，
但是此種方法只適用於對動態(dynamic)功率消耗分析結果，對於靜態(quiescent)功
率消耗分析結果作加總的方式並不適用之。 
另一個替代方式為使用 Xilinx ISE 提供一個內建的 Perl script-vcd2xad.pl 
[28,29]，如圖表 3.4 所顯示，vcd2xad.pl 提供給設計者去預先轉換成較小的格式－
XAD 檔案，此 XAD 檔案同樣可以提供 XPower 加載並分析功率消耗處理用。同樣
地，在檔案格式轉換的過程中，VCD 檔案所佔空間愈大時，所需消耗的轉檔時間
相對地增加。換言之，先前 VCD 加載處理時間過長的問題已轉嫁於至此，但此方
法可以避免 XPower 加載時讓使用者有 XPower 程式當掉的錯覺。 
  
vcd file my_design.vcd 
vcd add testbench/uut/* 
圖表 3.3 使用 VHDL 程式語言產生 VCD 檔案之語法 
  
 
圖表 3.5 XPower 功率消耗分析流程 
 
4. 系統層級的功率消耗分析 
 
4.1 基本構想 
隨著次微米技術的進步，複雜的系統可以被整合在同一個晶片上，為了節省
設計成本與縮短設計時間，發展矽智產元件(IP)與再利用(Reuse)的設計方法已成為
最佳的解決方案。 
為了加速產品上市，設計者必需藉由再次利用重要的 IP 元件來避免重覆已設
計的工作。因此要能成功整合 IP，得從選擇一個可信賴的 IP 提供廠商開始，好的
IP 提供廠商必須能夠解決一連串的問題，所以不僅僅是提供 IP 的品質，還必須對
於整體有相關支援，這包括詳細的文件說明、稱職的產品應用工程師以及適時在
工程上的支援等。一套完整的服務應該包括暫存器傳輸層級的程式碼、驗證的環
境、合成、布局和繞線導引摘要，以及相關功能的文件說明。就微處理器或是可
編程序的數位訊號處理器的廠商而言，即須提供一些工具資源來支援是很重要的，
並且應該要有編譯器、作業系統、開發函式庫以及相關應用軟體。 
因此在提倡矽智產元件再利用的設計概念的同時，如果能對帶有的相關規格
資訊再次利用，例如詳細的功率消耗訊息；藉由再利用的動機而形成 IP 功率消耗
資料庫，但是往往其功率消耗資訊所提供的詳細程度並不足夠。 
因此我們所提出的系統層級 功率消耗評估方法，主要是再利用功率消耗資訊
的觀念，但是在系統層級作分析時，所需要的功率消耗資訊並不存在，因此在此
我們需要假設此功率消耗資訊是存在的，並補足這些功率消耗資訊以便再利用。
因此我們作了一個假設：這個功率消耗資訊可能是 IP 提供者已提供的資訊或是從
其他第三方取得的資訊。 
為了滿足這個假設，我們在此提出一個在暫存器傳輸層級功率消耗資訊取得
的方法：重新對暫存器傳輸層級的程式碼進行時序圖細部解析或特定行為作細部
模擬，並對各個區段作時序圖截取。然後對各個拆解的行為模式作 XPower 的評估
 Etotal = Etotal ,op 1 + Etotal ,op 2 + Etotal ,op 3 + Etotal ,op 4 + Etotal ,op 5 +  …     (2) 
 
 
 
 
 
 
Etotal ,op 1 =  Eop 1 × Top 1 
Etotal ,op 2 =  Eop 2 × Top 2 
Etotal ,op 3 =  Eop 3 × Top 3 
Etotal ,op 4 =  Eop 4 × Top 4 
Etotal ,op 5 =  Eop 5 × Top 5 
……
                       (3) 
 
其中Etotal 為整體的總能量消耗。Etotal ,op 1、Etotal ,op 2、Etotal ,op 3、Etotal ,op 4、
Etotal ,op 5等表示為操作個別操作行為所占的總能量消耗。Eop 1、Eop 2、Eop 3、Eop 4、
Eop 5等表示為單一操作一次操作行為的能量消耗。Top 1、Top 2、Top 3、Top 4、Top 5表
示為個別操作行為的操作總次數。 
每次操作行為的能量消耗值計算，我們採用 Macro-Modeling 即為一個基於一
個已有的技術或具有實作可能性的技術去完成量測功率消耗特徵方法，簡而言之，
這些功率消耗數值可由較低層級已有的功率消耗評估方法進行量測。基於這樣的
觀念再利用較低層級的功率消耗資訊正好與我們先前假設的 IP 規格資訊再利用觀
念不謀而合。因此採用 Macro-Modeling 的方式，即有機會於較高設計階段且沒有
實際功率消耗資訊可驗證的硬體系統架構下，來進行評估功率消耗。在下一小節，
我們將說明如何量測操作行為的功率/能量消耗值。 
 
 
 
 
4.3 功率消耗資訊的取得 
基於 Macro-Modeling 的方式，我們重新於較低層級量測個別單一操作行為的
功率消耗值。在前一章節已說明了如何在 XPower 作功率消耗評估的模擬，對於較
完成收集個別操作行為的時序圖時，再經由 XPower 作功率消耗分析評估。因
此單次操作行為即可用以下的方程式運算出。 
Eoperation =  Poperation × toperation                      (4) 
其中 Eoperation   為每次操作行為的消耗能量； 
             Poperation  為每次操作行為的帄均消耗功率值； 
            toperation  為每次操作行為的執行時間。 
  總結使用 Macro-Modeling 的設計步驟： 
(1) 解析其模組不可分割的函式/操作行為/程序等硬體的操作特性。 
(2) 撰寫硬體操作特性的個別測詴程式。 
(3) 模擬個別的硬體操作特性，並收集其時序圖 VCD 檔。 
(4) 使用XPower加載VCD檔來分析功率消耗，建立其功率消耗資訊資料庫。 
(5) 基於模組的硬體操作特性去撰寫成 SystemC模組，並加入功率消耗資訊。 
(6) 使用系統層級的硬體模組作模擬並分析其功率消耗。 
 
 
圖表 4.2 具有功率消耗資訊的 IP 模組建構示意圖 
  
RGB 三顏色的資料。 
(2) 溝通(Communication)、控制信號(Control Signal)： 
每個硬體區塊在操作時必定是輸入相關信號，而產生相對映的操作模式及
行為。而在操作硬體作特定的計算功能時，也必需輸入相關待計算的數據
資料，才是一個有意義的計算操作，同時也會產生並輸出相關已計算的數
據資料。因此這部分可根據其硬體的控制信號狀態作為劃分依據，例如常
見的硬體狀態有輸入、輸出、硬體重置等狀態。因此劃分操作行為的依據
點即可為硬體的操作特性和溝通行為作為劃分依據點。 
 
根據以上的操作行為分類要點，最後再分別於操作行為加上經由較低層級量
測到的功率消耗資訊，即可構成擁有功率消耗資訊的模組，並於模擬分析時提供
設計者相關的功率消耗資訊。形成可於系統層級作功率耗分析的可能性。 
 
4.5 模組功率消耗資訊的維護性–使用 C/C++巨集定義 
  就系統整體設計考量點而言，已大量採用模組化的方式來設計整個系統。其
主要目的就是為了可以增加各模組之間替換的便利性。因此在功率消耗資訊加入
的同時，我們理應同時去考量其維護的便利性。在管理功率消耗資訊的方式，採
用了 C/C++常見的預先處理使用巨集定義的機制來管理之，由於使用 C/C++巨集
定義的方式，可使得在硬體的程式碼維護方式便捷許多並不需要深入修改，不會
因為替換採用不同的硬體技術時，產生功率消耗的不同，而需要深入修改硬體區
塊的程式碼，如此可以避免一些不可預測的人為問題。當使用不同的硬體技術，
例如當設計的硬體採用的元件裝置其技術由 Virtex-II 系列轉換使用 Spartan-II 系列
的技術時，其功率消耗值勢必不同。此時只需對巨集定義檔案作修改即可，不需
要深入修改其他程式碼，以達到方便維護管理之用途。 
5. 模擬實驗與結果 
 
在本章節，我們將分別以三個不同的特定應用 IP 來驗證前二章節所討論的系
統層級和暫存器傳輸層級二者之間的功率消耗分析評估的方法。 
 
首先簡述實驗中所採用的環境以及相關設定條件的內容。 
1. 實驗硬體帄台： 
Intel Pentium4 550 CPU，2G RAM 的硬體帄台下完成模擬驗證等工作。 
2. 工具軟體方面： 
在暫存器傳輸層級全部採用 Xilinx ISE 9.1 為開發環境，同時並使用
ModelSim SE 作為 HDL 模擬器去收集執行過程的時序圖 VCD 檔案，最後
再經由 Xilinx 的 XPower 作功率消耗模擬分析。而在系統層級會採用三種
不同的開發環境(CoWare Platform Architect[37]、OSIC SystemC[39]、ARM 
SoC Designer[38])來建構特定應用 IP，進而說明方法的適用性。 
3. 程式實作方面： 
在暫存器傳輸層級統一採用 Virtex 系列的 FPGA 技術，其中採用的目標硬
體裝置為 xc2v250-6fg456 (Device:XC2V250、Package:FG456、Speed:-6)並
操作在 100MHz，其餘的裝置資訊我們全採用預設的設定值(例如操作電壓、
發熱量的資訊)。在系統層級實作相對映功能的 SystemC 硬體區塊模組，
最後模擬驗證其中二者之間的差異性。 
 
以下我們將分為三個不同的應用程式來實驗並於 5.1，5.2，5.3 節分別討論，
最後於 5.4 節總結摘要之。 
5.1 實驗一：JPEG 編碼器 
JPEG 是靜止影像編碼方式的國際標準。現今如彩色傳真和簡易電視電話的影
5.1.1 DCT HDL 程式實作部分 
而 HDL 的部分我們同樣需要實作 DCT 的硬體設計，並且在 Xilinx ISE 中作完
合成、轉譯、對映、布局和繞線。在完成布局和繞線之時，我們已可以經由 XPower
取得靜態的功率消耗資訊，靜態功率消耗值的決定是取決於裝置元件的選擇，所
以此時的裝置元件是沒有任何的輸出入訊號。然而我們尚需要藉由 ModelSim SE - 
HDL 模擬器和測詴程式作更詳細且完整的模擬並收集時序圖 VCD 檔，再經由
XPower 功率消耗分析模擬器的分析模擬才能得到整體元件的帄均功率消耗。此時
所得的帄均功率消耗值即為已包含了靜態功率消耗值和動態功率消耗值。最後再
經由操作執行時間利用下方的方程式計算，即可達到整體的能量消耗。但是愈詳
盡的模擬，其模擬的時間會愈長；同時所紀錄下的 VCD 檔其檔案大小也會因此遞
增。形成 XPower 在處理 VCD 檔案時所造成的耗時評估主要因素。 
 
Ptotal = PQuiescent + PDynamic                              (5) 
 
Etotal = EQuiescent + EDynamic  ,                           (6) 
=  PQuiescent + PDynamic  × Ttotal  , 
                                               =  Ptotal × Ttotal  
 
其中   Ptotal   為整體的帄均功率消耗 
     PQuiescent  為整體的帄均靜態功率消耗 
     PDynamic  為整體的帄均動態功率消耗 
       Etotal   為整體的總能量消耗 
     EQuiescent  為整體的靜態能量消耗 
       EDynamic  為整體的動態能量消耗 
       Ttotal   為整體的操作執行時間 
操作行為時序圖 VCD 檔來計算功率消耗值，就 DCT IP 的實驗中我們將其劃分為
五種操作行為函式(initial/reset、input、output、do_dct、idle)，因此我們需要分別
撰寫測詴程式並取得五種不同的時序圖 VCD 檔，然後在 XPower 中得到個別操作
行為的總功率消耗值同時間紀錄其執行時間。在完成五種不同的操作行為能量消
耗評估後，我們即可將這些功率消耗值資訊加入 SystemC 的 DCT 模組，形成一個
可提供即時功率消耗值資訊的模組，因此將其應用到系統架構模擬的同時，此模
組即能提供給系統設計者其功率/能量消耗值。 
 
 
 
 
5.1.3 DCT SystemC 程式實作部分 
在 SystemC 的部分，將以 JPEG 編碼器程式為例，圖表 5.3 顯示此 JPEG 編碼
器程式輸出入流程，為以 PPM(Portable Pix Map)型式的影像輸入，且以基本方式轉
換成 JPEG 型式。其中 DCT 區塊即為我們作為驗證的部分，DCT_one_block 經由
軟硬體切割的程序(Hardware/Software Partitioning)，將 DCT_one_block 轉換成
SystemC 硬體模組，並架構至 CoWare Platform Architect 帄台上，如圖表 5.5 系統
整體硬體架構，圖表 5.6 軟體模擬結果，形成一個可執行軟硬體共同模擬的環境，
為一個 JPEG 編碼系統並且有一硬體 DCT 模組，此 DCT 區塊即為在實驗一中的主
要角色。 
 
// Power information from XPOWER Analysis 
// Xilinx Device Part: 2v250fg456-6 
// Power Unit : uJ 
// filename : DCT_POWER.h 
 
#define  IDEL_POWER      6906000 
#define  DO_DCT_POWER  108638320 
#define  INPUT_POWER   249337600 
#define  OUTPUT_POWER  380379520 
#define  RESET_POWER    21853250 
圖表 5.2 DCT_POWER.h –功率消耗資訊的巨集定義 
圖表 5.2 呈現 C/C++巨集定義的方式，可以很明顯看的出其方便性及維護便利性，
在功率消耗資訊值需要變動時，我們只需要修改預先定義的巨集檔，並不需深入
修改 DCT 模組的程式碼內容。 
 
 
圖表 5.4 具有功率消耗資訊的 DCT IP 模組建構示意圖 
 
 
  
5.1.4 DCT 實驗結果及模擬 
下圖表 5.7 所呈現是 DCT 的運算次數每次遞增 10 倍並量測其能量消耗。圖表
橫軸表 DCT 的運算次數，縱軸表消耗的能量。圖表 5.7 中的百分比數值表示暫存
器傳輸層級(RTL)與 SystemC 兩者之間的功率消耗相對誤差值，可明顯看到二者之
間是呈現小於 0.2%的誤差值，也就是說使用系統層級的方式也是有一定的精確
度。 
 
 
圖表 5.7 DCT IP 模組之功率消耗分析比較 
  
5.2 實驗二：CRC32 
CRC 的英文全稱為 Cyclic Redundancy Check(Code)，中文名稱為循環冗餘校
驗(碼)，為一種線性分組碼，編碼和解碼方法簡單，檢錯和糾錯能力強，在通信系
統及其他序列資料的傳輸已廣泛運用之。 
 
5.2.1 CRC32 HDL 程式實作部分 
HDL 程式碼的部分是源自於[33]，一個使用 Virtex 裝置並實作出 IEEE 802.3 
CRC 的 IP 參考設計範例，提供了 CRC-8，CRC-12，CRC-16 和 CRC-32。在此實
驗中我們僅採用 CRC-32 來驗證。 
 
5.2.2 CRC32 系統層級模組之功率消耗資訊的取得 
在建構過程中，如圖表 5.10 所示，此 CRC32 的實驗中我們將其劃分為五種操
作行為函式(initialize、shift、calculate、result_output、idle)，因此我們需要分別撰
寫測式程式並取得五種不同的時序圖 VCD 檔，然後在 XPower 中得到個別操作行
為的總功率消耗值同時紀錄其執行時間。在完成能量消耗評估後，我們即可將這
些功率消耗資訊加入 SystemC 的 CRC32 模組，形成一個可提供即時功率消耗資訊
的模組，因此將其應用到系統架構模擬的同時，此模組即能提供給系統設計者其
功率/能量消耗值。 
  同樣地，如圖表 5.9 所示，使用 VCD 檔的方式收集功率消耗評估所需的內部
訊號資訊，可避免使用者自行定義的輸入所造成的誤差，同時也可以免除繁複的
輸入資料過程。圖表 5.9 可明顯看出 VCD 檔內 Signals 欄所紀錄的訊號資訊項目，
其中已詳細地記載著輸出入的訊號資料以及內部運算的訊號資料。 
5.2.3 CRC32 SystemC 程式實作部分 
在此實驗，我們採用不同的 SystemC 開發環境，採用的為 OSCI 工作組織所發
表的 SystemC 2.1 程式語言，目前也已成為 IEEE 1666 SystemC 標準。我們將
SystemC 的模組以及 OSCI SystemC 模擬環境架設至 Linux 工作站上，同樣採用
C/C++預先處理器巨集定義的方式來管理維護。 
關於 SystemC 的原始程式碼，此實作內容為一個計算某檔案的 CRC32 值；因
此輸入為一個檔案名稱，並計算其檔案的 CRC32 值。圖表 5.11 呈了架構於 OSCI
上的檔案階層關連性，在 CRC_POWER.h 檔案中，即為前述使用 C/C++巨集的方
式來管理維護用，所記載的只有功率消耗的資訊；圖表 5.12 呈現出架構的模擬示
意圖，CRC32 模組用於計算待測檔案的 CRC32 數值，測詴帄台(Testbench)模組負
責待測檔案的預先處理，兩者之間經由 FIFO 的通道作溝通，來完成資料傳輸及控
制之用途。其中由於實作必須對照 HDL 的程式碼其特性，所以我們可以容易地觀
察出(如圖表 5.13)，其計算量將會是等同檔案大小的位元組(byte)值。 
架構於 OSCI 環境下的 CRC32 實作示意圖： 
 
圖表 5.11 CRC-32 SystemC 實作的檔案階段關係 
 
5.2.4 CRC32 實驗結果及模擬 
下圖表 5.14 所呈現是 CRC32 範例，其對於不同檔案大小分別計算 CRC32 值，
並以位元組(byte)為單位的運算量作每次遞增 10 倍量測其能量消耗。圖表 5.14 橫
軸表詴驗檔案其大小以位元組(byte)為單位(K 為 1000 倍)，縱軸表消耗的能量。圖
表5.14中的百分比數值表示暫存器傳輸層級(RTL)與SystemC兩者之間的功率消耗
相對誤差值，可明顯看到二者之間是呈現小於 0.4%的誤差值，也就是說使用系統
層級的方式同樣也是一定的精確度。 
 
 
圖表 5.14 CRC-32 IP 模組之功率消耗分析比較 
 
  
5.3 實驗三：色彩空間轉換 - RGB 轉 YCbCr 
顏色有幾個以數位表現的方法，如圖表 5.16 所示，其中代表性之一的方法如
RGB 和 YCbCr。RGB 是顏色三原色，R(紅色)，G(綠色)，B(藍色)以整數值(0~255)
表示。YCbCr 為 Y(亮度成份)，Cb(色差成份，綠色亮度成份)，Cr(色差成份，紅
色亮度成份)。色彩空間轉換目前已大量地應用於影音影像編碼的設計。主要原因
是人類的眼睛對顏色的變化(Cr 和 Cb 成份)比亮度的變化更敏感，保持 Y 成份而取
得 Cr，Cb 成份，可以抑制畫質變差及減少資料量的處理。 
 
 
圖表 5.16 顏色轉換電路概要 
 
 
5.3.1 RGBtoYCbCr HDL 程式實作部分 
HDL程式碼的部分是源自於[34]，為一個使用 Spartan-IIE 裝置(2S50E-6TQ144)
的 IP 參考設計實作。在此實驗中我們重新修改並操作合成、轉譯、佈局和繞線於
Virtex-2 裝置作再次的驗證。 
 
  
 
圖表 5.18 RGBtoYCbCr 時序圖 
 
5.3.3 RGBtoYCbCr SystemC 程式實作部分 
在 SystemC的實作部分，此RGB轉YCbCr模組我們架設於ARM SoC Designer 
(MaxSim)開發環境如下圖表5.19所示，採用另一個測詴帄台模組來完成驗證模擬，
在 Console 視窗對話框的畫面中於執行過程即可得知其功率消耗的資訊。 
 
 
圖表 5.19 RGBtoYCbCr 於 ARM RealView SoC Designer 的模擬執行結果 
同樣地我們對於運算量達到 107 次時，對二者之間所需的功率消耗模擬之操作
時間作分析比較。圖表縱軸表所需的功率消耗分析操作成本比例值。如下圖表 5.21
所呈現出的為於二個不同層級之間所需功率消耗分析成本的比較圖表，即為暫存
器傳輸層級(RTL)和 SystemC 之間執行操作模擬、分析功率消耗所需的執行總時間
的比例。從圖表 5.21 上所示暫存器傳輸層級(RTL)所需花費的時間是 SystemC 的
607 倍之久。 
 
 
圖表 5.21 RGBtoYCbCr IP 模組之功率消耗分析操作成本比較 
  
6. 結論與未來工作 
6.1 結論 
在本研究中，我們主要專注於對協力處理機 (Coprocessor)或是特定應用
IC(ASIC)提出一個可於系統層級執行功率消耗評估的方法。然而，在系統層級並
沒有真實的硬體架構環境，更沒有功率消耗的資訊存在。因此採用了
Macro-Modeling的方式從較低層級去量測並補足在系統層級所沒有提供的功率消
耗資訊；因此採用Macro-Modeling方式所建構的SystemC模組，能在沒有真實硬體
架構下的系統層級作完整的模擬驗證並提供功率消耗資訊。 
在IP模組建構的方面，我們也提供了一些分析要點及建構摘要及指引，採用不
可分割的操作行為特性去創建SystemC硬體模組。 
在模組設計的同時，我們並不需要去增加任何的函式庫或模組，更不需去對
SystemC的函式庫作任何的修改，因此程式碼的適用範圍並不受於任何環境或程式
語言，其為明顯可見的。同時也引入維護便利性的設計考量觀點，採用C/C++常見
的寫作技巧來達到程式碼方便維護之用途。 
在實驗中，証明了我們的方法就系統層級和暫存器傳輸層級相比較，在系統
層級同樣能提供設計者有一定品質的功率消耗資訊，且二者之間只有極小的誤差
值；同時採用系統層級作功率消耗模擬分析能藉由抽象化的影響而加速分析結果
的取得，解決使用暫存器傳輸層級的方法當設計過大或者需長時間的模擬分析時
候，所造成的耗時分析的問題，二者之間的模擬操作時間呈現了有數十倍的時間
差至數百倍之多。換言之，就真實時間和單位而言，二者之間是數分鐘與數小時
之比。另外，實驗的模擬帄台採用了三種不同的 SystemC 開發驗證環境，並於這
三個不同的開發環境上成功實作出，並執行完整的模擬，在在地說明我們的方法
其適用性不會因為環境的不同而改變。 
參考文獻 
[1] S. Swan, “An Introduction to System Level Modeling in SystemC 2.0,” White 
paper, http://www.systemc.org, May 2001. 
[2] SystemVerilog, http://www.systemverilog.org/. 
[3] T. K. Tan, A. Raghunathan, G. Lakshminarayana, and N. K. Jha, "High level 
software energy macro-modeling," in Proc. Design Automation Conf., 2001, pp. 
605--610. 
[4] Tan, T. K., Raghunathan, A., and Jha, N. K. "Energy macro modeling of embedded 
operating systems," Trans. on Embedded Computing Sys. pp. 231--254, Feb. 2005. 
[5] Nitesh Goyal, "Macro-modeling and energy efficiency studies of file management 
in embedded systems with flash memory," MASTER Thesis, in Texas A&M 
University, May 2005. 
[6] S. Xanthos, A. Chatzigeorgiou, and G. Stephanides. "Energy Estimation with 
SystemC: A Programmer's Perspective," in Proc. of the 7th Int. Conf. on Systems, 
Computational Methods in Circuits and Systems Applications, July 7, 2003. 
[7] Robertas Damasevicius, "Estimation of Design Characteristics at RTL Modeling 
Level Using SystemC," Information Technology And Control, 2006, vol.35, no.2, 
pp. 117--123. 
[8] Jinwen Xi, Zhaohui Huang, Peixin Zhong, "Energy macro-modeling of embedded 
microprocessor using SystemC," Electro Information Technology IEEE 
International Conference, May 2005. 
[9] Bansal, N., Lahiri, K., Raghunathan, A., and Chakradhar, S. T. 2005. “Power 
Monitors: A Framework for System-Level Power Estimation Using Heterogeneous 
Power Models,” In Proceedings of the 18th international Conference on VLSI 
Design Held Jointly with 4th international Conference on Embedded Systems 
pp. 867--872. 
[21] Benini, L. Ferrero, M. Macii, A. Macii, E. Poncino, M., "Power analysis of 
software-implemented digital filters: a case study", Electrotechnical Conference, 
2000, vol.2, pp. 595--598. 
[22] ARM Software Development Toolkit, http://www.arm.com/ 
[23] Givargis, T. D., Vahid, F., and Henkel, J. “Instruction-based System-Level power 
evaluation of system-on-a-chip peripheral cores,” In Proceedings of the 13th 
international Symposium on System Synthesis, September 20, 2000, pp. 163--169. 
[24] Claudio Talarico , Jerzy W. Rozenblit , Vinod Malhotra , Albert Stritter, "A New 
Framework for Power Estimation of Embedded Systems", Computer, vol.38 no.2, 
p.71--78, February 2005. 
[25] David C. Black and Jack Donovan, "SYSTEMC: FROM THE GROUND UP," 
Kluwer Academic Publishers, 2004. 
[26] IEEE1666TM Standard SystemC Language Reference Manual, http://www.ieee.org/ 
[27] OSCI SystemC 2.1/2.0 Language Reference Manual, http://www.systemc.org 
[28] XPower Analyzer FAQ, http://www.xilinx.com/ 
[29] Xilinx Solution 15492－General tips on reducing VCD file size using ModelSim, 
http://www.xilinx.com/ 
[30] 大村正之、深山正幸 原著，溫榮弘 編譯，”C/C++ VLSI 設計”，全華科技圖
書股份有限公司，2005 
[31] Latha Pillai, "Xilinx Reference Design XAPP610 (v1.3) - Video Compression 
Using DCT", March 3, 2005. 
[32] Latha Pillai, "Xilinx Reference Design XAPP611 (v1.2) - Video Compression 
Using IDCT", June 3, 2005. 
[33] Chris Borrelli, "Xilinx Reference Design XAPP209 (v1.0) - IEEE 802.3 Cyclic 
Redundancy Check", March 23, 2001. 
 2009 年 IEEE Symposium on Field-
Programmable Custom Computing 
Machines 
 參加國際會議報告 
 
 
 
 
王勝德 教授 
國立台灣大學電機工程學系教授 
 
 
 
 
 
 
 
  
 
(and vice versa) 
Languages and Compilers 
 New languages and development environments to describe spatial or hybrid 
applications 
 Tools to make run-time reconfiguration more accessible to application 
designers 
 Compilation and CAD techniques for reconfigurable computing systems and 
other spatial computers Run-Time Systems and Run-Time Reconfiguration 
 Operating system techniques to manage run-time reconfiguration of 
resources in reconfigurable computing or spatial computing systems 
 Run-time CAD algorithms to support the above techniques or improve fault 
tolerance/avoidance 
 Use of reconfigurability to build evolvable or adaptable computing systems 
 Novel uses of run-time reconfiguration in application-specific systems 
Applications 
 Novel applications that use reconfigurability to customize hardware for 
scientific computation, mobile communications, medical image processing, 
data and communication security, network infrastructure and other 
embedded systems 
 Comparison of application implementations on different spatial hardware, 
such as GPGPUs, multi-core processors, and FPGAs. 
 
會議心得 
本次會議我發表的論文安排在 poster section 3: 
Context Sharing for Area Efficiency of Regular Expression Pattern Matching on 
FPGA, Yuan-Chin Wen, Henry Yu and Sheng-De Wang 
 1 
 
Abstract—Network Intrusion Detection System (NIDS) utilizes 
complex strings to perform inspection over the raw traffic from 
networks. The goal is to identify whether this traffic is intrusive or 
not. Complex strings, also known as signatures, are on behalf of 
various behaviors of attacks. Most of signatures are composed of 
normal characters and regular expressions which are provided by 
illustrious network security software such as SNORT and Bro. 
With rapid growing of Perl compatible regular expressions 
(PCREs) used in SNORT, more and more resources are required 
to store these increasing rules. Therefore, the trend is towards 
minimizing designs of logic block and architecture on 
field-programmable gate array (FPGA). In this paper, we propose 
a novel method, named context sharing (CS), to minimize the size 
of NFAs. We also create a circuit generator, called Rx2V, to gen-
erate pattern matching engines corresponding to given PCREs. 
Finally we conduct experiments and obtain results showing that 
CS can achieve 41.7% reduced usage of logic cells (LCs) on 
FPGA. 
 
 Index Terms—Intrusion detection, pattern matching, regular 
expression, field programmable gate array 
 
I. INTRODUCTION 
ITH common uses of web services and Internet applica-
tions, network security systems have attracted more and 
more attention. In case some malicious network traffic contains 
particularly designated strings, said signatures, these packets in 
the traffic are probably trying to break in intrusively or attempt 
to launch attacks that cause services unavailable from victim 
systems or web sites. These attacks are also known as denial of 
service (DOS). Signature-based NIDS generally utilizes com-
plex signatures to look through network traffic to identify 
whether the traffic is hostile to the system. As soon as any 
malicious packet is detected by a matched pattern, the NIDS 
will execute a corresponding emergent process or issue an alert 
for analysis or forensics. 
 Most end-users, even system administrators, rely on plenty 
of anti-virus software and network monitoring tools. Due to 
sequential pattern-matching, these software-based tools have 
 
 
This work is supported by iCAST, The International Collaboration for 
Advancing Security Technology, was established in the 1
st
 quarter of 2006 to 
start a three year international collaboration project of research and develop-
ment in the area of Information Security. This mission-oriented project was 
granted by the National Science Council (NSC) of Taiwan to strengthen in-
formation and communication security within all Taiwan’s academic, gov-
ernment, industry and service sectors 
Y.C. Wen, Henry Yu and S. –D. Wang are with Division of Computer 
Science, Department of Electrical Engineering, National Taiwan University, 
Taipei, TAIWAN  
(email: {puff, henry}@hpc.ee.ntu.edu.tw; sdwang@ntu.edu.tw) 
shortcomings that are incapable of catching up high throughput 
interfaces such as 10 Gbps Ethernet or Infiniband. On the other 
hand, the number of vulnerabilities is rapidly on the increase; 
meanwhile, security communities need to provide more com-
plicated patterns to describe these malicious signatures. Fig. 1 
shows that more and more various intrusions have been dis-
covered. In other words, the signatures corresponding to these 
intrusions are also rapidly increasing. For example, in SNORT 
2.1 and 2.8, there are 3108 and 9854 rules respectively. The 
growing ratio for the two verisons is 317%. On the other hand, 
non-duplicate PCREs in SNORT 2.1 and 2.8 are 324 and 1941 
respectively. The growing ratio is 599%. Moreover, with such 
high rapid increase of rules, it is difficult to update large 
amount of rules for NIDS within a short interval of time. For 
the rules in SNORT, the analysis in [1] points out that the pat-
tern-matching procedure consumes about 80% of processing 
time. On the whole, an accelerative, scalable, and flexible 
method is demanded to solve above problems. 
 
 
Fig. 1. SNORT rules statistics 
 
Before minimizing the size of NFA, here comes one example 
to present the problem of applying sharing methods in 
NFA-based pattern matching on FPGA. Traditionally, we im-
plement one NFA corresponding to one rule in Fig. 2. These 
NFAs are independent with each other. However, in our anal-
ysis, many similar rules possess very little difference even only 
one character. For example, in Fig. 2, considering rules net-
bios2467, netbios2470, and netbios2473 under the netbios rule 
set in SNORT 2.8, we will waste many logic cells (LCs) on 
FPGA to build identical circuit blocks. If we could provide 
methods to group common substrings between those indepen-
dent NFAs, we may save lots of LCs to achieve area efficiency. 
0
1000
2000
3000
4000
5000
6000
7000
8000
9000
10000
2.1 2.2 2.4 2.6 2.8
SNORT statistics
Rules
PCREs
Context Sharing for Area Efficiency of Regular 
Expression Pattern Matching on FPGA 
Yuan-Chin Wen, Henry Yu, and Sheng-De Wang 
         
W 
 3 
Fig. 5. Using delay logic to keep signal from prior state Fig. 6. CS architecture 
       
In general, most memory accessing relies on the given ad-
dress of data location. However, it is infeasible address by 
address to find the location of specific data. Therefore, a type of 
memory uses a mechanism looking for the content by using the 
address that depends on a part of data content. The memory 
adopting this mechanism is called CAM.  
Bu et al. [8] presented a CAM-based solution to NIDS at line 
speed over 2 Gbps and pointed out that improving technologies 
of VLSI can further enable CAM-based approaches to meet 10 
Gbps. Sourdis et al. applied character pre-decoding, shift reg-
ister based lookup table with 16 bits (SRL16) of Xilinx FPGA 
and pipelining technologies to catch up throughput almost 10 
Gbps. Yu et al. [10] utilized TCAM to process complex pat-
terns such as correlated patterns and patterns with negations 
and wildcards. In their design, it is able to work 2Gbps with 240 
KB TCAM. 
 
III. CONTEXT SHARING FOR AREA EFFICIENCY 
In Section I, we have addressed the false-positive problem 
that we would encounter if we apply common prefix sharing 
method for common infix/postfix sharing. In this section, we 
are going to discuss and provide a novel method to solve the 
context sharing problem. Part A discusses the architecture of 
CS and proves the feasibility of the design. Part B points out the 
advantages and features of our method. Part C provides the 
constraint in this method. 
A. Context Sharing 
To solve above problem, we need a new mechanism to keep 
track of positive signals triggered by which prior state of each 
NFA[7]. Besides keeping track of the positive signal, we can 
also “delay” the signal from the prior state of each NFA before 
completing the match of the common context sharing module. 
Hence, we modify the erroneous design in Fig. 4 to the CS 
approach in Fig. 5. In this way, our design is able to achieve 
common infix and postfix sharing. Moreover, this mechanism 
supports not only simple strings composed of printable and hex 
characters pattern matching but also complicated PCREs 
composed of printable, meta-characters, modifiers, etc. 
To prove our method, consider m regular expressions, said 
Rx1, Rx2, Rx3, …, Rxm. Assume these m regular expressions 
contain a common infix as a sub regular expression which is 
Rxcomm.. Then we can rewrite the regular expressions into Rxj = 
{Rxpre_jRxcommRxpost_j| ∀ j ∈ Z
+
, 1 ≤ j ≤ m, (Rxpre_j, Rxcomm, 
Rxpost_j) ∈ regular expression}. In Fig. 6, if ∃ i ∈ Z
+
, 1 ≤ i ≤ m: 
Rxpre_iRxcommRxpost_i is embedded in the incoming traffic, then 
in the beginning, Rxpre_i will be matched and fan-out the posi-
tive signals to Rxcomm and the delay blocks. The delay clock 
cycles depend on the length of Rxcomm. For example, if the 
length of Rxcomm is n, then one signal will spend n clock cycles 
passing through the states of Rxcomm in NFAi. On the other hand, 
the other signal will take n clock cycles to pass through the 
delay block. After an “and” operation, the signals will converge 
and pass through Rxpost_i to complete this pattern matching and 
issue a correct alert. 
B. Features 
There are three features in our CS approach. First, for m 
regular expressions, Rxj = {Rxpre_jRxcommRxpost_j| ∀ j ∈ Z
+
: 1 ≤ j 
≤ m , (Rxpre_j, Rxcomm, Rxpost_j) ∈ regular expression, Rxpre_j can 
be null}. For example, consider two NFAs said 
Rxpre_1RxcommRxpost_1 and Rxpre_2RxcommRxpost_2. Assume Rxpre_2 
is null. If the incoming traffic contains the pattern 
Rxpre_1RxcommRxpost_1, then after match of Rxpre_1Rxcomm, the 
signal will go through Rxpost_1 and does not go through Rxpost_2 
because there is no signal from the delayed circuit in NFA2. It is 
the same way to prove if the incoming traffic contains the pat-
tern RxcommRxpost_2.  
Second, for m regular expressions, Rxj = 
{Rxpre_jRxcommRxpost_j| ∀ j ∈ Z
+
: 1 ≤ j ≤ m , (Rxpre_j, Rxcomm, 
Rxpost_j) ∈ regular expression, Rxcomm can be shared if 
Rxpre_j⊂Rxpre_kRxcomm ∀ j, k ∈ Z
+
, j≠k, 1 ≤ j, k ≤ m }. The proof 
method is similar to the first feature. 
Third, for m regular expressions, Rxj = {Rxpre_jRxin_jRxpost_j| 
∀ j ∈ Z+: 1 ≤ j ≤ m , (Rxpre_j, Rxin_j, Rxpost_j) ∈ regular expression, 
Rxin_j ⊂ Rxin_k ∀ j, k ∈ Z
+
, j≠k, 1 ≤ j, k ≤ m }. In the feature, it  
 5 
 
 
Fig. 8. Basic components Fig. 9. PCRE:”/((a?b)+c)*[^0-9]{3}/” to NFA
After implementing these basics components, we regard 
these components as a separated module and refer to given 
PCREs to integrate these modules to the corresponding NFA. 
For example, pattern PCRE:”/((a?b)+c)*[^0-9]{3}/” is a com-
plicated regular expression. Required components are listed in 
Fig. 8. First, we need an at-most-once module in Fig. 8(c) to be 
appended after “a”. Then we append an at-least-once module in 
Fig. 8(b) after “(a?b)”. Third, we use a kleen-star which means 
the assigned PCRE can appear any times in Fig. 8(a) after 
“((a?b)+c)”. Fourth, we append a repetition module in Fig. 8(d) 
and specify the repeated times after the class range “[^0-9]”. 
The result is depicted in Fig. 9. 
B. Rx2V 
In Fig. 1, we can see that the number of rules in the latest 
SNORT 2.8 is 9854. And there are 91776 characters in the 
content. As for PCRE, it appears to have 12778 instances dis-
tributed in all rules. After removing duplications, we find 1941 
various PCREs in SNORT 2.8. With these enormous patterns, it 
costs an arm and a leg to implement circuit blocks manually for 
NFA-based NIDS. For example, a PCRE like 
/^Host\x3A[^\r\n]*www\.hithopper\.com/smi, may cost about 
20 minutes. For 1941 PCREs in SNORT 2.8, it takes 647 hours. 
In other words, we would spend 27 days accomplishing PCRE 
in SNORT 2.8. Therefore, a fast and complete circuit generator 
that can automatically generate NFA for FPGA form SNORT 
rules is indeed required. 
In Fig. 10, there are five steps during execution of Rx2V 
described as follows: 
step 1. Change to the specified directory then retrieve all pat-
terns followed by “PCRE:”. Then Remove duplicated 
patterns. 
step 2. In implementing the CS method, we shall find common 
prefix first because it costs nothing for sharing. Then find 
common infix and postfix. We apply a greedy algorithm 
to find the longest common sub-pattern. For example, in 
Fig. 7, we chose “cdef” to be sub-NFA and specify dif-
ferent length for each delay block of shared rules. Before 
selecting common infix and postfix, we must refer to the 
constraints listed in TABLE 2. 
step 3. Parse modifiers such as multiple lines match(/m), case 
insensitive match(/i), dot matches newlines(/s). 
step 4. Parse operations such as the asserting start and end of 
string(/^Rx$/), wildcard(.), character class([Rx]), sub 
pattern, at most once(?), at least once(+), kleen-star(*), 
repetition(Rx{M}, Rx{M, }, Rx{M, N}), and other me-
ta-characters. 
step 5. Generate Verilog hardware description language codes 
for synthesis. 
 
Retrieve PCRE from 
SNORT rules
Context Sharing
Parse modifiers(/m, /i, /s)
Basic(^, 
$, |, \)
Generate Verilog 
Classes([ab], 
[^ab], [A-Z])
Advanced(*, +, ?, 
{m}, {M,}, {M, N})
Hex and meta-
char(\xFF, \char)
 
 
Fig. 10. Flow of Rx2V 
 
V. EXPERIMENTS 
In our system, we apply the latest version, 2.8, of Snort to 
build NFA-based NIDS on FPGA. We have implemented 
Rx2V to generate the given PCREs to corresponding NFA. We 
also adopt our proposed method, CS, to minimize slices used on 
FPGA. In this section, we will discuss our experimental results. 
Our experimental device is Xilinx Virtex-II Pro 50 FPGA 
which consists of 47232 slices [12]. We synthesize these gen-
erated NFA by the commercial tool Xilinx ISE 9.2.04i. 
 
 
