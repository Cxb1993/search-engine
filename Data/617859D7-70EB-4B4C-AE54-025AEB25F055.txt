∑∑
=
=
−
−
=
n
i
i
n
i
i
x
n
xx
DCV
1
1
2
1
)(
)(      (1) 
where x  denotes the average of the physiochemical value 
for the whole complex. 
PCA is an un-supervised method for data dimensionality 
reduction.  This method aims to find projection of data with 
the maximum variance. The k-th largest eigenvalue 
corresponds to the k-th principle component.  
LR is a special form of regression in which the dependent 
variable is a binary (dichotomous) variable. Machine 
learning method SVM is used to train the input feature 
vectors. In particular, the LIBSVM [20] is used for complex 
classification in our study. LIBSVM provide several kernel 
function for classification, i.e. linear, polynomial, sigmoid 
and radial basis function (RBF). 
Randomized samples are generated in order to train 
protein complex classification using SVM. Tests are 
performed in which assignment of protein subunits is 
randomized while keeping seven subunits for each complex 
in forming random complexes.  
Since the random set will resulted in trivial classification, 
therefore, we made use of the BioGrid PPI data [21], input 
that in COACH [22] to generated a set of 542 pseudo-
complexes. COACH is a protein complex prediction method 
which infers complexes using graph clustering techniques. 
This set of pseudo-complexes is put together with the 
random set to form the complete randomized set. Then, the 
physiochemical values for each of the complex in the 
randomized set are computed. The results of the randomized 
set are taken together with the original complexes’ values to 
form the training set, and input into the SVM for training.  
III. RESULTS 
A. Hydrophoblic and hydrophilic properties  
The hydrophoblic (Hb) and hydrophilic (Hp) values for 
the amino acids in each subunit are added together. Since 
both the Hb and Hp values vary from subunit to subunit 
within a complex, therefore, their averages are computed, 
and these two averages are used to represent the whole 
complex.  
B. pI value 
The pI value for every protein complex’s subunit is 
obtained from Protoparm. For each complex, the CV for pI 
is computed, after that we grouped the values CV into a 10% 
interval. And the plot of the relative frequency versus the 
10% interval is shown in Figure 1. It is found that 86.6% of 
the complexes have a CV less than or equal to 0.3. 
 
 
Figure 1.  The plot of relative frequecny of coefficient of variation of 
protein conplex (CORUM) pI value. Numbers 1, 2 … etc. stand for the 0-
0.1, 0.1-0.2 interval respectively. 
C.  Half-life  
It is found that all the protein subunit sequences obtained 
from CORUM begin with the amino acid, methionine (M), 
except a small number (seven) of subunits. Therefore, the 
half-life is not used for the protein complex classification 
purpose simply because it is a trivial classification.  
D. Length distribution of subunits within a complex 
Length of every protein subunits for the human 
complexes obtained from CORUM are computed. For each 
complex, the CV is computed, then we group the CV into a 
10% interval, the plot of the relative frequency versus the 
10% interval is shown in Figure 2. 
 
Figure 2.  The plot of relative frequecny of coefficient of variation of 
protein conplex (CORUM) subunit length. Numbers 1, 2 … etc. stand for 
the  0-0.1, 0.1-0.2 interval respectively. 
It is found that 92.6% of the complexes have a CV less 
than or equal to 1.0. 
E. Amino acid compositions 
The normalized 20 amino acids (aa) compositions for 
every complex are deduced from the subunits’ sequences. 
For every aa composition value, it is summed and averaged 
over all the complexes. Then, we compared the 20 
composition values, and identified the largest, the middle 
and the smallest amino acids compositions, i.e. leucine (L), 
[17] J. Kyte and R. F. Doolittle, (1982) “A simple method for displaying 
the hydropathic character of a protein,” Journal Molecular Biology, 
vol. 157, 1982, pp. 105-132. 
[18] Gasteiger et al., “Protein Identification and Analysis Tools on the 
ExPASy Server,” in John M. Walker (ed): The Proteomics Protocols 
Handbook, Humana Press, 2005, pp. 571-607.  
[19] http://tw.expasy.org/tools/protparam-doc.html  
[20] http://www.csie.ntu.edu.tw/~cjlin/libsvm/  
[21] Breitkreutz et al.: The BioGRID Interaction Database: 2008 update.  
Nucleic Acids Res., 2008, 36, pp. D637-D640. 
[22] Xiaoli Li, Min Wu, Chee-Keong Kwoh and See-Kiong Ng, 
“Computational approaches for detecting protein complexes from 
protein interaction networks: a survey,”. BMC Genomics, 2010, 
11(suppl 1), 2010, S3. 
 
 表 Y04 
2
報告內容應包括下列各項： 
一、 參加會議經過 
 
The Third International Conference on Computer Research and Development (ICCRD2011) 
is held at Shanghai (Rendezvous Merry Hotel Shanghai) from Mar. 11 – 13, 2011 (ICCRD2011).  
 
The conference continues to be a very special IEEE conference series with three main goals: 
(i) It intends to provide a forum for high quality interdisciplinary discussions on the various 
aspects of the convergence between computer theory and technologies. 
(ii) To focus on practical problems related to the design, deployment and utilization of 
information and networking systems. 
(iii) To create a congenial environment for friendships to develop and cooperation to blossom 
among tenants of many disciplines and from many countries. 
 
The ICCRD2011 conference chairs invited and arranged three Keynote Speeches. The three 
speakers are: 
(i) Prof. Wang Jun, The Chinese University of Hong Kong, Hong Kong, 
(ii) Prof. Chin-Chen Chang, IEEE Fellow, Feng Chia University, Taiwan, and 
(iii) Prof. Soumaya Yacout, École Polytechnique de Montréal, Canada. 
 
The scientific program of ICCRD included keynote talks, and many oral presentations. I had 
an oral presentation on Mar. 12 (Friday) 5 p.m. The title of my presentation is “Protein Complexes 
Subunits Interaction Topology and Sequence Identity”. It is a 20 minutes talk including a 5 
minutes question and answer time. This work is published in the Proceeding of the 2011 3rd IEEE 
International Conference on Computer Research and Development, page 229 to 232. 
A variety of machine learning papers were presented at this conference and the topics include 
Bayesian belief networks, multilayer neural network trained with the genetic algorithm, naive 
Bayesian classifier, fuzzy c-means clustering, and model of network topology. 
 
二、 與會心得 
 
There are several well presented talks in this conference. Attended talks with their titles and 
brief contents are listed in below. 
 
Keynote Speech 
This session had three invited speakers to give a 45 minutes keynote speech. After the 
presentation is a five minutes opening discussion.  
 
Multiple-winner take all networks 
Prof. Wang Jun  
The Chinese University of Hong Kong, Hong Kong 
 
K-winner take all (kWTA) selects the k largest input out of n input such as sorting , KNN, 
k-mean clustering 
It is a building block for many algorithms, such as ART, SOM. MWTA is not a NP hard 
problem. 
⎩⎨
⎧==
0
____1
)(
winnerisitif
ukWTAx ii  
it is an integer programming (IP) problem 
∑∑
==
=
n
i
ii
n
i
i kxtosubjectxu
11
__)max(   
 表 Y04 
4
∩ G pixel (3 and 2) is cyan in color, the CIT gives R. 
Two main advantages of this method, (i) no key and complicated mathematics operation is needed, 
and (ii) information is hidden in cover image. 
 
 
cbmLAD data mining using logical analysis of data in condition based maintenance (cbm) 
Prof Soumaya Yacout  
École Polytechnique de Montréal, Canada 
 
Outline of the talk 
new for new paradigm in decision making 
dating using logical analysis (LA) of data 
application of LA in decision making 
conclusion 
 
Application – healthcare depend heavily on interview data and statistical analysis. To remedy 
this limitation Janice Moore (2002) suggest that adopt include not only multiple methods but also 
multiple form of data that consider phenomena comphrensively in all form 
Data mining can extract knowledge from large data set in order to find meaningful pattern 
and rule. 
Andrew Kusiac – innovation is both high in marke t relevance and market acceptance 
Flow of data-driven innovation – database Æ data cleaning Æ data warehouse Æ task 
relevance data Æ find pattern Æ generating a training data set Æ knowledge discovery Æ 
prediction and optimization 
LAD is a data mining AI approach on finding useful pattern of information 
The method of LAD classification is first proposed by Rutgers University (RUTCOR), 
Hammer at 2005 (also see Hammer, LAD overview 2006). 
This method has to do with analysis of Boolean function and combinotrial algorithm, 
extractioin of specific phenomena form large amount of data, it is a supervised learning method 
(denote the classification information already) 
LAD can analyzed time series, nomial, real number data 
Author presented a simple example to illustrate the LAD concept. 
numerical data (Kurtosis value, KV) 
  
class KV 
positive class . 
. 
. 
 
negative class . 
. 
. 
 
perform data binarization Æ pattern generation algorithm (PGA) Æ theory formation 
(classification function) 
PGA: mixing integer linear programming, control difference between class 
Let Δ = [ -1, 1], negative value mean more pattern of sickness, zero means one cannot 
classify. 
LLkk NwPw ∑∑ −+ −=Δ 14
1
16
1
 
where wk , P and N denote the normalized weight, positive and negative class respectively. 
 表 Y04 
6
2)()()( |)0(|))0(()0( iii AuPP ==  
2)(2)()( |)(||)(|))(( mLAmAmuP iii −+=  
2)(2)()( |)2/(||))2/(())(( WAWuPNuP iii ==  
where m=1,2,…,W/2-1, u(m) is the m-th spatial frequency and is defined only for the zero and 
positive frequencies. 
The results show that the method based on NPS to calculate total noise to assess the 
non-uniformity of the prints is simple and effective. 
 
 
Multilayer Neural Network trained with the Genetic Algorithm – knowledge-based forcasting 
system 
Andrian Kurniady and Raymondus Kosala 
 
Genetic algorithms simulate biological evolution by maintaining a set of states in a population 
and evolve the states in several iterations. It is expected that by the end of the simulation, the 
population contains several states that are good enough as a solution.  
Artificial neural network (ANN), or sometimes called neural network (NN), is yet another 
concept derived frombiology. There are several kinds of network topologies in ANN, e.g. some are 
categorized as the feed-forward network and the recurrent network. Typicaly feed-forward 
network is trained with the back-propagation algorithm or genetic algorithm can also be used. 
The naive Bayes classifier is one of the simplest statistically based classifier. It is based on 
observed probability of past examples regarding the evidences related to an observed 
classification. This kind of classifier is possible by means of the use of Bayes theorem. The 
classification is derived by comparing the likelihood of each possible classification given the set of 
evidences. 
In the present study, the Genetic Algorithms is used to evolve the weights of the multilayer 
network, as a replacement to the traditional Back-Propagation algorithm. An incrementally trained 
Naive Bayesian classifier to classify the news stories automatically is also implemented. The agent 
is measured for its performance on the specified historical stock price data. 
Although the agent does not consistently outperform the benchmarks, it does have its own 
advantages in terms of stability. The second test tries to find out whether news improves the 
agent’s prediction accuracy. We find that in certain stocks and the index, the inclusion of news 
does improve the prediction accuracy. 
 
Fuzzy C-means clustering 
Jingpan Liu,Lianfen Huang and Jianan Lin 
 
FCM algorithm is one of most important and popular fuzzy clustering algorithms. At present, 
this algorithm (developed by Dunn in 1973 and improved by Bezdek in 1981) has been extensively 
used in feature analysis, pattern recognition, image processing, classifier design, etc. It is the 
process of grouping a data set in a way that the similarity between data within a cluster is 
maximized while the similarity between data of different clusters is minimized. This clustering 
method is essentially an iterative procedure. This iteration is based on minimizing an objective 
function that symbolizes the distance from any given data point to a cluster center weighted by that 
data point's membership rank. The purpose of clustering is to distinguish mosaic block from all the 
image blocks, so we classify all of the blocks into two clusters. 
Experimental results show that our algorithm could differentiate Chinese character with real 
mosaic block. 
 
LEETAR: A NEW HIERARCHICAL-STRUCTURAL TOPOLOGY GENERATOR 
 表 Y04 
8
Random forest has recently attracted a lot of attention in computer vision. It has been used for 
a large number of classification tasks. A typical random forest consists of a set of binary decision 
trees. Decision trees are constructed first. The random forests consist of a collection of randomized 
binary trees. Each tree is constructed recursively starting from the root in a top-down manner. 
Each tree is built based on the collection of patches drawn from the training data. Random Forest 
is composed of multiple independently learnt random decision trees. Each tree is built based on the 
set of patches. Importantly, the building process employs all the supervision available for the 
training data.  
During training, each non-leaf node in each tree is assigned a binary test that is applicable to 
any data sample. The set of leaf nodes of each tree in the forest can be regarded as a Hough-voting 
discriminative codebook; during testing, each leaf node makes a probabilistic decision whether a 
patch corresponds to a part of the object or to the background, and casts a probabilistic vote about 
the centroid position with respect to the patch center. Random Forest is efficient during testing, 
since matching a sample against a tree is logarithmic in the number of leaves. 
 
 
三、 考察參觀活動(無是項活動者省略) 
    Null 
 
四、 建議 
I had a dinner table discussions with the following participants during the ICCRD 2011 
conference, 
Professor Xie Rong, International School of Software, Wuhan University. 
Professor Sufian A Forawi, The British University in Dubai, United Arab Emirates. 
Professor Bhekisipho Twala, University of Johannesburg, South Africa. 
In summary, I had several nice discussions with some of the speakers in the conference. 
The level and quality of the talks are in general good.  
 
五、 攜回資料名稱及內容 
Conference document: 
(1) CD for ICCRD 2011 
(2) Zhang Ting, Proceedings of ICCRD, IEEE press. 
 
六、 其他 
    null 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：黃建宏 計畫編號：99-2221-E-150-067- 
計畫名稱：蛋白質複合體之研究 - 利用機器學習方法預測複合體及建構複合體交互作用網路 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 0 100%  
博士生 1 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
