行政院國家科學委員會補助專題研究計畫 
□期中進度報告 
□期末報告 
應用發音知識源於多樣化語言之語音處理—應用發音知識源於
多語言語音信號噪音強健性處理之研究 
計畫類別：□個別型計畫   ■整合型計畫 
計畫編號：NSC 99－2221－E－110－050－MY3 
執行期間：99 年 8月 1日至 102年 7月 31日 
執行機構及系所：國立中山大學資訊工程學系 
計畫主持人：陳嘉平 
共同主持人： 
計畫參與人員：碩博士生 
本計畫除繳交成果報告外，另含下列出國報告，共 3 份： 
□移地研究心得報告 
■出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □涉及專利或其他智慧財產權，■一年□二年後可公開查詢 
中   華   民   國  102 年 10 月 31 日
  
 
Abstract 
We have focused on noise-robust spoken language processing techniques during this research 
project, specifically by combining multi-lingual speech data and speech attribute features. In the first 
year, we collected a multi-accent Mandarin database (MAM) from international students and analyzed 
the articulation variation due to accents. In addition, we implemented a voice-interface system using 
Google-map on smart phone. In the second year, we improved the performance of noise-robust speech 
recognition system by a novel Gaussian mixture model feature compensation and energy rescaling. In 
addition, we built an emotional speech synthesis system based on model interpolation of hidden Markov 
models. Furthermore, we created a polyglot speech synthesis using articulatory features based on neural 
network speech attribute detectors. In the third year, we implemented a Java-based speech recognition 
system, and used model adaptation techniques to effectively deal with the variation due to accents and 
environmental factors. In addition, we built a prototype system for song synthesis. Overall, it is happy to 
see that the researches on multi-lingual, multi-accent have been promoted, especially regarding 
articulation features, due to this research project. 
Keywords: multilingual speech, noise-robustness, speech attribute detection, articulatory features, 
speech synthesis, singing voice synthesis 
  
而下的(top-down)，由句子、詞、字、音、乃至於狀態。這兩種系統的效能比較請參考 [Ma 2006]。
這兩種想法並非矛盾而無法並存。實際上，以偵測器為基礎的系統可以與一般的系統做整合。這
個部分的初步結果請參考 [Siniscalchi 2006]。 
研究目的 
在這樣的背景下，本計畫的研究主題在於應用發音知識源於噪音強健性語音信號處理，包括
噪音強健性偵測器系統、利用偵測器之噪音強健性語言辨識系統、以及整合偵測器之噪音強健性
語音辨識系統。質言之，本計畫的主要目標在探討偵測器系統本身之噪音強健性，以及偵測器系
統改善語言、語音辨識系統噪音強健性之效益。本計畫的研究目的，在於系統性地改善現有的語
音系統之噪音強健性，包括辨識與合成等等應用。因為發音屬性是比較不受噪音影響的，在有噪
音的情況下，屬性偵測器結果相對於基於頻譜的特徵參數較為可靠。 
參考文獻 
[Lee 2007] Chin-Hui Lee, M. A. Clements, S. Dusan, E. Fosler-Lussier, K. Johnson, B.-H. 
Juang, L. R. Rabiner, “An Overview on Automatic Speech Attribute Transcription (ASAT)”, in 
Proceedings of INTERSPEECH 2007 
[Siniscalchi 2008a] S. M. Siniscalchi, T. Svendsen, and C.-H. Lee, “A Penalized Logistic 
Regression Approach to Detection Based Phone Classification”, in Proceedings of 
INTERSPEECH 2008 
[Lyu 2008] D.-C. Lyu, S. M. Siniscalchi, T.-Y. Kim, and C.-H. Lee, “Continuous Phone 
Recognition without Target Language Training Data”, in Proceedings of INTERSPEECH 2008 
[Siniscalchi 2007] S. M. Siniscalchi, T. Svendsen, and C.-H. Lee, “Towards Bottom-Up 
Continuous Phone Recognition”, in Proceedings of ASRU 2007 
[Siniscalchi 2008b] S. M. Siniscalchi, T. Svendsen, and C.-H. Lee, “Toward A Detector-Based 
Universal Phone Recognizer”, in Proceedings of ICASSP 2008 
[Bromberg 2007] Bromberg et al., “Detection-Based ASR in the Automatic Speech Attribute 
Transcription Project”, in Proceedings of INTERSPEECH 2007 
[Siniscalchi 2009] S. M. Siniscalchi, J. Reed, T. Svendsen, and C.-H. Lee, “Exploring 
Universal Attribute Characterization of Spoken Languages for Spoken Language Recognition”, 
  
Technical Report No. 13, Acoustics Laboratory, MIT, 1952 
 
研究成果、結論與討論 
1. 聲控 Google地圖 
  本研究整合聲控技術於 Google地圖。也就是說，原本利用滑鼠或鍵盤的地圖操作，改由聲
控來進行。系統不同處在於所有的語音運算處理都是在客戶端上執行。在語料庫方面，錄製了 100
個熱門的台灣景點與一些特定的地圖控制指令作為訓練語料。在我們的實驗中，使用了不同的訓
練方式來訓練聲學模型、設計字典和語言模型並估算我們系統的效能。在系統實際使用情況，透
過位置、控制和座標不同部分的聲控操作，便可循序地移動地圖中心到達指定的搜尋景點。不同
使用者針對數個特定位置進行估算，整體搜尋過程平均花費 20.8秒，其中大部分時間都是花費在
錄音階段。 
以往在使用遙控器進行遙控時，因為紅外線容易受到距離、角度以及阻隔物的限制干擾。如
今可以透過聲控技術讓使用者突破空間的限制，藉由聲控就可以直接操作電子裝置。Google 地圖
是著名的網路地圖應用和技術服務，提供了包括街景地圖、路線規劃以及觀光資訊服務。最重要
的是使用者可以依據個人喜好，修改應用程式介面(Application programming interface, API)，嵌入
地圖到第三方網站上。在研究中，將語音辨識應用程式與 Google 地圖兩者整合，在 Silverlight 上
建構系統。 
賽微科技集團開發在手機上的賽微聲控應用程式支援多國語言的語音辨識，它不僅提供了語
音撥號、聲控，來達到提升使用者和手機之間的互動。在，透過語音分析與嘴型偵測為基礎的聲
控介面，能夠使得使用者自由地控制機器手臂作出精準的三維度空間運動。此外，Google地圖(API)
還提供在 Google地圖上相關應用服務。API不僅提供使用者可以增加自己喜好的地圖操作功能之
外，還可以將具有個人風格的 Google地圖嵌入在個人網頁上。在中，此應用系統不僅可以以客家
話作語音辨識，找出搜尋的地圖位置外，其系統上還提供了所搜尋地點的相關地理資訊。這就是
一個整合語音辨識和 Google 地圖的應用程式例子。 
事先利用錄製好的語音資料來擷取梅爾頻率倒頻譜係數(Melfrequency cepstral coefficients, 
MFCC)，接著再使用這些參數資訊、相關的設定檔文件和其訓練音檔對應的標記文件來訓練隱藏
馬可夫模型，完成第一階段的訓練步驟。接著再使用不同於訓練語音資料的未知語音資料，同樣
進行 MFCC 參數擷取，之後經由 HTK 辨識工具會從訓練好的模型中找出最佳的模型，再與設定
好的對應字典檔以及文法所產生的詞彙網路做比對，產生最後的辨識結果，完成第二階段的辨識
  
以有效的估算噪音的特徵參數並利用簡單的方法達到減噪的效果，在 AURORA 2.0 語料庫上我們
提出的方法相對於傳統的方法更可達到 24.9%的相對改善率。 
隨著科技的發展，人與電腦的溝通方式也不斷的演進，在現今 Google 的 Google Voice Search
以及 Apple 的 Siri 已經證明語音人機介面的成功，然而在各種不同環境的應用對於自動語音辨識
(Automatic Speech Recognition, ASR)仍是一項課題，在外在環境的影響下使得測試資料與訓練資料
不匹配的問題仍然存在，因此噪音強健性(noise robustness)成為一個重要的目標。 
在傳統方法中已有提出用於實現噪音強健性，在語音強化技術方面，常見的方法包含頻譜消
去法(spectral substraction)及 Wiener濾波器(Wiener filter)，而在強健性語音特徵方面，常見的方法
為倒譜均值消去法 (cepstral mean subtraction，CMS)、倒譜變異數正規化 (cepstral variance 
normalization，CVN)及直方圖均衡化(histogram equalization,HEQ)。最近機於樣本(exemplar)的方
法，如稀疏表示(sparse representation)、audio implanting和 compressive sensing，擁有良好的成效。 
高斯混和模型已廣泛應用於語者辨識和聲音轉換，一類用於模型平行語料的 GMM已成功用
於噪音強健性辨識上，近來應用考慮相鄰音框之間的相依性，執行語音特徵內部的連續性限制。 
在傳統的MMSE補償下，補償特徵需要乾淨語料特徵的 GMM平均向量加權總和，每個特徵
向量都是獨立補償，因此連續音框之間的連續性和相依性並沒有明確納入，我們提出的方法不再
採用平均向量加權總和，而是基於減去從噪音語料特徵取得的估計偏差值，如字面上意思的”減去
噪音”。 
此提出的新方法在噪音環境(-5-20dB)比語料庫 baseline以及傳統MMSE 取得更佳的表現，並
且在乾淨的環境並沒有下降。相對於語料庫 baseline，平均字錯率的相對改善率為
52.4%(39.9%-19.0%)，相對於傳統 MMSE 則為 24.9%(25.3%-19.0%)，此結果顯示直接減去噪音估
計的影響能帶來更佳的表現，比以往的方法更具有強健性。 
在實驗中可看出些問題，其中一個是模型的不匹配，此是因為訓練資料的不足所導致，噪音
環境的差異使得利用最小均方誤差估算特徵參數時會產生相當大的誤差，另一個為分類的準確
率，在噪音分類器的分類下我們找到的是近似的噪音環境，既使如此在完全匹配的情況下也不能
百分之百找到其正確的噪音環境，也導致其結果還有改善空間。 
實驗中 GMM 的 mixture 數量為一個可變參數，當越來越多的資料或測試環境加入時，提高
此數量可達到較好的表現，因此在未來延伸工作上實作於其他語料庫如 AURORA 3.0，並且研究
其擴展性，事實上，即使是跨語言也可合理的試圖補償。 
  
有倒頻譜平均消去法(cepstral mean subtraction, CMS) 、倒頻譜正規化法(cepstral mean and variance 
normalization, CVN)、聲道長度正規化法(vocal tract length normalization, VTLN) 、統計圖等化法
(histogram equalization, HEQ) 、特徵空間旋轉法(feature space rotation, FSR)、頻譜熵值特徵(spectral 
entropy feature) 等。而後端處理的部分為聲學模型的調適(acoustic model adaptation)，主要藉由對
目標背景雜訊調整聲學模型，期望調適後的模型可以適用於新的環境。這類的方法優點是僅需要
少量的語料就能對聲學模型進行調適；缺點是在進行即時調適時，計算量過大。常見的方法有最
大相似度線性迴歸法(maximum likelihood linear regression, MLLR) 、最大事後機率法則(maximum 
a posteriori, MAP)，以及平行模型合併法(parallel model combination, PMC)。 
我們主要的研究是朝強健性語音特徵的方向進行。將語音訊號來擷取特徵參數，並對其對數
能量 (Log energy) 或第零階的倒頻譜係數 (c0) 進行重刻。此作法主要目的是希望能夠使得雜訊
語音的能量特徵值近似於乾淨語音，以提高辨識的準確度。 
能量特徵重刻在強健性語音辨識的領域中是屬於特徵補償的一種，主要的目的是希望透過調
整能量特徵以減少乾淨與含噪音特徵兩者的差異性。我們觀察能量特徵的變化，發現一段雜訊語
音中有語音的段落，其能量值偏高；反之，非語音的部分，能量值偏低。基於此現象，本論文提
出 DEFR 的方法對能量特徵作進一步的處理。此方法主要分為語音活動偵測、分段對數尺度函數
與參數搜尋法三個部分。我們利用低頻譜之語音活動偵測來取得語音與非語音出現的時間點，並
利用分段對數尺度函數決定能量參數調整的權重值。而分段對數尺度函數所使用的參數是由參數
搜尋法自動決定。 
在語音訊號處理系統中，語音訊號常常受到環境噪音的影響，使得系統效能低落。因此發展
了語音活動偵測來判斷訊號中語音與非語音的位置。我們觀察語音在各個頻帶間能量的變化，發
現無論任何種類的噪音，在頻帶[0; 50Hz] 之間都有相當比例的能量。藉由此特性，我們計算每個
音框的低頻帶頻譜能量，並根據能量值，判斷該語音音框是否為純雜訊音框或是含語音的音框。
分段對數尺度函數是為了使含語音的能量能夠確實地保留原有的能量值，而非語音的能量能夠大
幅度地下降，以增加語音與非語音能量的差異性。 
自動語音辨識系統中，前端特徵擷取的方式對辨識率的影響相當大，然而特徵向量中最重要
的參數為對數能量與第零階倒頻譜參數。這兩種參數為語音訊號在各個頻帶間的整體表現，因此
極具重要性。我們針對這兩種能量特徵提出了資料驅動能量特徵重刻法，並以 MFCC 與 TECC 為
基準對其能量特徵做調整。此方法藉由 VAD 偵測出語音與非語音出現之段落，再利用分段對數
尺度函數給予不同的權重，重新計算其能量值，以補償語音在噪音環境下的失真。而分段對數尺
度函數的設計理念來自於雜訊語音其能量特徵值相對較高，非語音處之能量特徵值普遍偏低的特
性，希望增加語音與非語音之能量的差異性，故給予不同尺度的權重。其函數所使用的參數是由
  
結果。在辨識之前或辨識的過程中，應用程式可以對每一個模組發出控制命令，讓模組與模組之
間可以有效的作運用。為了讓應用程式與開發人員能夠追蹤解碼器總計訊息，如詞錯誤率、運行
速度及記憶體使用情況等等，Sphinx-4 提供了大量工具。跟其它的系統相比，這些工具是高可配
置度的，讓使用者能夠更容易的在系統分析中使用。 
我們建立的系統採用主從式架構，伺服端透過網路來同時服務多個用戶端，而用戶端負責錄
製或選取音檔，再將音檔與透過網際網路傳至伺服端，伺服端收到音檔後馬上開始進行辨識、調
適等動作，最後再將結果透過網際網路回應給用戶端。使用主從式架構可以達到軟體專業分工的
目標，電腦作業將不受時空的限制，各項作業所採用的功能模組分配、設計、開發、建置具更大
的彈性與便利，並將人機介面處理完全交由用戶端來處理大幅減輕伺服端主機的工作量。 
我們使用到的語料庫有 AURORA2、EAT DIGIT 以及利用 Android 錄製的 NOISE1 語料庫。
AURORA2 語料是用來訓練數字語音辨識系統的基礎聲學模型，而 EAT DIGIT 與 NOISE1 則是作
為聲學模型調適實驗之調適與測試資料。其中，EAT DIGIT 為從 EAT語料庫篩選出純英文數字語
句集合而成，而 NOISE1 語料庫則是利用 Android 系統之行動裝置錄製不同環境、語者之乾淨及
噪音語料。 
利用 EAT DIGIT 語料庫我們做了三項實驗：英語系與非英語系腔調比較、調適句數與效果比
較、跨裝置調適效果比較。而利用 NOISE1 語料庫我們也進行了三項實驗：調適句數與效果比較、
噪音環境差異調適效果比較、裝置差異調適效果比較。實驗使用 39維梅爾倒頻譜係數作為特徵參
數，利用高斯混合模型訓練上下文相關詞相關音素隱藏式馬可夫模型。 
在 EAT DIGIT 的實驗中，腔調方面，無論調適與否，英語系測試語料的辨識率都比非英語系
高。調適句數方面，結果顯示，使用 100 句以內的句數可以得到較好的投資報酬率。而裝置方面
差別並不大，大致上呈現 MIC>PSTN>GSM 的狀況，主要差異還是在於英語系測試語料的辨識率
比非英語系高。 
在 NOISE1 的實驗中，句數實驗的結果顯示，在單人語料使用 25句以內就能得到很好的投資
報酬率。而在噪音環境差異實驗方面，在利用多環境語料模型經過 25句調適之後，在四種測試環
境下都能達到 90%以上的辨識率，平均更能達到 95%以上的辨識率。最後在裝置差異實驗中，在
未調適時，裝置的辨識率有明顯的差異，使用 DHD時平均只有接近 60%的正確率、使用 WFS 時
則有超過 80%的正確率，但在經過 25句調適之後，所有模型的辨識率都可以達到 95%以上。 
總而言之，這個系統擁有網路語音辨識、調適及語料收集的功能，並能夠在使用的過程中將
語料收集至伺服端。對於這個平台我們跨出的一步是將這個系統整合出來，提供原始碼讓任何有
  
在國內，清華大學也有以語料庫為主的歌聲合成研究。其方法為，以動態規劃的方式定義目
標和串接兩種距離函數，來求取單音節、連音和歌曲三種語料庫的最佳合成單元。台灣科技大學
古鴻炎教授，在歌手聲音的合成，及電腦音樂方面也有相關的研究。主要採用諧波加噪音模型
(Harmonic plus Noise Model, HNM)方式合成中文歌聲。 
之後，台灣科技大學王如江，在 HNM 上加上歌聲表情參數的分析。其方法為，根據錄製真
人所唱的歌聲，分析各音符的基週軌跡、音量、音長、波形包絡等表情參數，再結合表情參數到
HNM 系統裡去合成出歌聲訊號。從結果上來看，加上表情參數的合成歌曲可以改善合成歌聲的
品質。基週同步疊加法 (Pitch Synchronous Overlap and Add, PSOLA) 主要是為了解決文字轉語音
(Text to Speech, TTS) 上合成品質的問題，他同時也提供了音高升降的處理。 
在語音合成的處理上，大致分為兩種。一種為時域上波形的改良；一種為頻域上處理頻譜的
特徵。PSOLA 演算法可分為時域上基週同步疊加法和頻域上基週同步疊加法兩種。頻域上基週同
步疊加法是將語音訊號轉到頻域上做處理，處理完之後再轉回時域上。TD-PSOLA 則是運用窗函
數直接在時域上對波形做處理。現今，語音合成已有廣泛的應用，但歌聲合成這方面的研究還不
普遍，尤其是在台灣。在台灣，歌聲方面的合成並不多，故引起動機來進行這次的研究。 
我們的方法是以時域上基週同步疊加法為基礎，來對錄製的合成單元做時域上的修改。接著
實作出一個能夠合成出自然歌聲的合成系統。其中，要注意轉音的處理、音量的處理、音節連結
上的處理和音節時間的對應，且音色要盡量保持不變。另外，還要能夠使合成出來的歌聲，與配
樂同步播放。 
我們採用時域上基週同步疊加法來處理合成單元。之後實作一個串接式的歌唱合成系統，用
來產生具有配樂的合成歌聲。我們分別錄製 3 組不同音高的語料庫，來當作合成單元。根據 100 首
左右的 MIDI 歌曲的資訊來分析訊息，並蒐集歌曲的歌詞和所對應的音節。 
根據本系統，使用者可以選擇想要合成的歌曲，並且修改歌曲整體上的音符編號和音節。歌
曲的合成中，包括了合成單元的挑選、音量正規、力度處理、音節連接時漸弱的處理等等，最後
將產生出來的合成歌聲與配樂同步結合。接著利用主觀評測方式來分析此系統的優、缺點並做改
進。 
 
 2 
machines. We submitted a paper using the empirical mode decomposition method 
for noise-robustness of speech recognition systems and got accepted. So we 
had to attend this conference. 
二、與會心得 
It is truly rewarding to be able to exchange ideas with people working on 
the same research fields. The keynote speeches are great! During oral 
presentations or poster presentations, people ask many questions to the 
presenters. Such interaction is much better than just reading/writing the 
papers. 
I learned new things and at the same time got new ideas on old subjects. They 
provide critical opportunities for the future research topics of my research 
team. I also had many opportunities to discuss with researchers with the same 
research interests for possible collaborations. 
三、發表論文全文或摘要 
Please refer to the conference proceedings. 
四、建議 
none 
五、攜回資料名稱及內容 
Conference proceedings 
六、其他 
none 
 2 
The ACL-HLT is a first-class conference without question. There was nothing 
but the best in the area of natural language processing. This is the first 
time that I participated in an international top conference focused on natural 
language processing. The styles of computational linguists and speech 
processing community are quite different. 
One special arrangement of this conference is that the candidates for the 
best paper nominee were given the same time slots (morning session) of keynote 
speeches. One can see that the young talents are highly regarded.  
三、發表論文全文或摘要 
Please refer to the conference proceedings. 
四、建議 
none 
五、攜回資料名稱及內容 
Conference proceedings 
六、其他 
none 
 2 
The APSIPA is young and the conference is diverse. It has the mission to gather 
research works from the Asia-Pacific area. Contributions from USA, Japan, 
Taiwan, China, Korea, Singapore, and many other countries in this geographic 
area are abundant. The overall quality of the presentation is very high. The 
areas are quite diverse, including audio-, video-, image-, bio- signal 
processing, and communication systems. 
三、發表論文全文或摘要 
Please refer to the conference proceedings. 
四、建議 
none 
五、攜回資料名稱及內容 
Conference proceedings 
六、其他 
none 
99年度專題研究計畫研究成果彙整表 
計畫主持人：陳嘉平 計畫編號：99-2221-E-110-050-MY3 
計畫名稱：應用發音知識源於多樣化語言之語音處理--應用發音知識源於多語言語音信號噪音強健性
處理之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 2 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 12 0 100%  
博士生 1 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 3 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 9 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
