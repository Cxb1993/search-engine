called Modified Empirical Mode 
Decomposition (MEMD). It is a fully data 
driven method without using any 
pre-determined filter [8], wavelet function [11] 
or Fourier-wavelet basis [15] and the 
recognition rate is better than the method 
using EMD for feature extraction. Therefore, 
the proposed MEMD approach is used to 
extract residual components from iris images 
as features for recognition. 
This paper is organized as follows. Section 2 
introduces preprocessing procedures for iris 
images. Section 3 and Section 4 describe the 
details of our proposed approach for feature 
extraction and matching. Experimental results 
are demonstrated and discussed in Section 5, 
prior to Conclusions in Section 6. 
 
2. Iris Image Preprocessing 
An eye image contains not only the part of iris 
but also some irrelevant parts such as eyelid, 
pupil etc. So, a captured iris image cannot be 
used directly. After the iris captures and before 
the feature extraction, three steps are 
performed: The first step is to locate the iris 
area. Then, the located iris is normalized and 
converted to a rectangular window with a 
fixed size in order to achieve the approximate 
scale invariance. Finally, illumination and 
contrast problems are eliminated from the 
normalized image by image enhancement, and 
the irrelevant parts (such as eyelid, pupil, and 
eyelashes, etc.) are removed from the 
normalized image as much as possible. 
 
2.1. Iris Localization 
 
Detect boundary (pupil, iris and eyelid) for 
finding the region of interest in iris image. 
Generally speaking, traditional methods spend 
considerable time for iris location [18, 6]. To 
increase the time efficiency, herein, we 
propose a fast method to increase speed and 
accuracy for iris location. The method is based 
on the Thales' theorem that the diameter of a 
circle always subtends a right angle to any 
point on the circle’s circumference. Fig. 1 
shows that the Thales' theorem is applied to 
find the inner and outer boundaries of iris. 
0 0 0( , )P x y
3 3 3( , )P x y
1 1 1( , )P x y 2 2 2( , )P x y
( , )p p pP x ypR
iR
0P
5 5 5( , )P x y
6 6 6( , )P x y
4 4 4( , )P x y
( , )i i iP x y
 
(a) (b) 
Fig. 1: Thales' theorem is applied to find (a) the inner 
and (b) the outer boundary of iris. 
 
Locating the iris area is not the main issue in 
this article, only the essential points for iris 
location are described as follows. First, the 
basic morphological operators of dilation and 
erosion are used in order to obliterate the 
illumination influence inside the pupil. Then, 
a point inside the pupil is found using the 
method of minimum local block mean. 
Therefore, the center point of the block is the 
target point 0P  and its coordinate can be 
computed. Second, the target point is used as 
the starting point by the edge detection to 
locate three more points ( 1 2 3, ,P P P  and 4 5 6, ,P P P ) 
along the inner and outer iris boundaries, 
respectively. Finally, we apply Thales' 
theorem that the circumferential angle faced 
by the diameter is a right angle in a circle to 
calculate the circle parameters such as the 
circle center ( pP and iP ) and its radius 
( pR and iR ). 
 
2.2. Iris Normalization 
 
Uniform ROI from different iris scale to a 
normalized template, which reduces the 
distortion of iris caused by the variation of the 
illumination, distance from camera and other 
factors. Normalization process involves in 
unwrapping the iris and converting it into its 
equivalent polar coordinates. We transform 
the circular iris area into a block using 
Daugman’s Rubber sheet model [18, 19]. The 
pupil center is considered as the reference 
point and a remapping formula is used to 
convert the points on the Cartesian scale to the 
polar scale. In our experiment, the radial 
resolution and the angular resolution are set to 
64 and 512 pixels, respectively. For every 
pixel in the iris area, an equivalent position is 
found on polar coordinates. The normalized 
image is then interpolated into the size of the 
original image which is a rectangular template. 
Figure 2 illustrates the preprocessing process 
for the iris image. 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: Preprocessing of the iris image. 
 
2.3. Image Enhancement 
 
1. Iris Location 
5 10 15 20 25 30 35 40 45 50
-2
0
2
(a)
Ir
is
 S
ig
na
l
5 10 15 20 25 30 35 40 45 50
-2
0
2
Ir
is
 S
ig
na
l
(b)
5 10 15 20 25 30 35 40 45 50
-2
-1
0
1
2
Ir
is
 S
ig
na
l
(c)  
Fig. 5: The smoothing process ((a)-(c)) of the local 
mean function using successive applications of a 
moving average, (c) the final smoothed local mean 
function (red curve, also shown in Fig. 4). 
 
The MEMD principle is similar to EMD that 
a signal is decomposed into a sum of intrinsic 
mode functions (IMFs). Also, it has to satisfy 
two conditions as same as the EMD. The two 
conditions satisfy the physically necessary 
conditions to define a meaningful 
instantaneous frequency. Otherwise, if blindly 
applied to any analytic signal, the 
instantaneous frequency may result in a few 
paradoxes [23-24]: it may go beyond the band 
for bandlimited signal or it may not represent 
one of the frequencies in the Fourier spectrum 
in the global sense. Thus, those two conditions 
for an IMF allow the calculation of a 
meaningfully instantaneous frequency. 
Specifically, the first condition is similar to 
the narrow-band requirement, whereas the 
second condition modifies a global 
requirement to a local one by using the local 
mean defined by the local maxima points and 
the local minima points, and is necessary to 
certify that the instantaneous frequency will 
not have unnecessary fluctuations as induced 
by asymmetric waveforms. To make use of 
MEMD for practical applications, the signal 
must have at least two extrema—one 
maximum and one minimum to be 
successfully decomposed into individual IMFs. 
These IMF components are obtained from the 
signal by means of an algorithm called sifting 
process. This algorithm extracts locally for 
each mode the highest frequency oscillations 
out of the original signal. 
Given those two definitive requirements 
for an IMF, the sifting process to extract IMFs 
from a given signal ( )z t , 1,...,t T=  is 
described as follows. 
1) Identify all the maxima and minima in ( )z t . 
2) Calculate the local mean of each two 
successive extrema using formula (2). 
3) The local means are smoothed using 
moving averaging from a smoothly varying 
continuous local mean function ( )m t . 
4) Extract the details by ( ) ( ) - ( )d t z t m t= . 
5) Check the properties of ( )d t : 
• If the above-defined two conditions are 
met, an IMF is derived and ( )z t  is 
replaced with the residual ( ) ( ) - ( )r t z t d t= ; 
• If ( )r t  is not an IMF, then replace ( )z t  
with ( )d t . 
6) Repeat Steps 1)–5) until the residual 
satisfies pre-defined stopping criteria. 
At the end of this process, the original signal 
( )z t  can then be reconstructed, using the 
following equation 
1
( ) ( ) ( )
n
i n
i
z t c t r t
=
= +∑            (3) 
where n  is the number of IMFs, ( )nr t  
denotes the final residue which can be 
interpreted as the dc component of the signal, 
and ( )ic t  are nearly orthogonal to each other, 
and all have nearly zero means. Due to this 
iterative procedure, none of the sifted IMFs is 
derived in closed analytical form. 
In fact, after a certain number of iterations, 
the produced signals do not carry significant 
physical information. To avoid this situation, 
we can stop the sifting process by limiting the 
normalized standard deviation (SD), 
computed from two consecutive sifting results. 
The SD is defined as 
2
1
2
1
( ) ( )
SD=
( )
T
j j
t j
z t z t
z t
+
=
−∑           (4) 
the SD is usually set between 0.2 and 0.3.  
By the nature of the decomposition 
procedure, the data is decomposed into n 
fundamental components, each with distinct 
time scale. More specifically, the first 
component associates with the smallest time 
scale corresponding to the fastest time 
variation of data. As the decomposition 
process proceeds, the time scale increases, and 
hence, the mean frequency of the mode 
decreases. Based on this observation, we may 
devise a general purpose time-space filtering 
as 
1
( ) ( )
h
lh i
i
z t c t
=
=∑              (5) 
where , 1,..., , .l h n l h∈ ≤⎡ ⎤⎣ ⎦  For example, when 
1l =  and h n< , it is a high-pass filtered signal; 
when 1l >  and h n= , it is a low-pass filtered 
signal; when 1 l h n< ≤ < , it is a band-pass 
filtered signal. The above equation forms the 
basis to our application of iris data described 
below, where we use it as a low-pass filtering. 
To associate with iris recognition, we also 
rate (FAR) versus false reject rate (FRR) is 
used. It denotes that the intra- and inter-class 
are inseparable while the Az value is equal to 
0.5. Hence, ROC curve is normally used to 
measure the accuracy of matching process 
showing the achieved performance of an 
algorithm. Meanwhile, the equal error rate 
(EER) is also used for performance evaluation. 
The crossover point of FAR versus FRR is the 
value of the EER. The smaller the EER value 
is the better performance the algorithm can 
accomplish. In the recognition mode, the 
correct recognition rate (CRR) is adopted to 
assess the efficacy of the algorithm. 
 
5.1. Iris Database 
 
In our experiments, the test data set is from 
the CASIA Iris Database [26]. Each image has 
the resolution of 320 280×  in 8-bit gray level. 
This database includes 1,992 iris images from 
249 different eyes (hence, 249 different 
classes) with 8 each. The images are acquired 
during different sessions and the time interval 
between two collections is at least one month. 
In our experiments, three images from each 
class are randomly selected to constitute the 
training set, so the entire training set has 747 
images. The other five images of each class 
are used as the test set with the number of 
1,245 images. Using those 1,992 different iris 
images from the CASIA Iris Database, the 
experiments conducted below are running on 
the computing environment of 1.8GHz PC 
with 736MB RAM using Matlab 6.5. 
 
5.2. Recognition Results 
 
Table 1 demonstrates promising recognition 
results achieved by our proposed MEMD 
method using three similarity measures from 
(8)-(10). Note that performance differences 
are not very significant while different 
similarity measures are used. Only a slightly 
higher recognition rate of 99.31% is 
accomplished by using the MED similarity 
measure in the identification tests. The 
verification results are also shown in Figure 7. 
The horizontal axis of Figure 7 is spread out 
using the logarithmic scale. The achieved Az 
value (the area under the ROC curve) is up to 
0.9927 by the MED similarity measure. 
Therefore, experimental results show that the 
proposed iris representation is effective for 
recognition and the MEMD approach can 
really extract the promising feature from each 
iris image. 
 
5.3 Comparison between MEMD and EMD 
 
This paper presents the proposed MEMD 
method and illustrates its performance in iris 
recognition. MEMD can separate the iris 
signal into a small set of components and each 
one could be associated with some aspects of 
cognitive function. 
Although using MEMD on sample test 
signals produces similar results to those 
generated by EMD, significant differences 
between these two schemes should be noted.  
The MEMD iteration process using smoothed 
local means appears to be a gentler way of 
decomposing the data than the cubic spline 
approach used by EMD. This can be seen in 
Fig. 8, which compares the intrinsic mode 
functions calculated by MEMD with the 
equivalent EMD IMFs. 
 
Table 1 Recognition rates of MEMD by different 
measures 
Similarity measure Correct recognition rate (CRR) 
MED  99.31% 
Cosine  98.78 % 
HD  98.32% 
10
-3
10
-2
10
-1
10
0
10
1
10
2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
FalsePositiveRate(FalseMatchRate)
T
ru
eP
os
iti
ve
R
at
e(
1-
F
al
se
 N
on
-M
at
ch
 R
at
e)
ROC Curve of MEMD feature with three different similarity measures
HD
Cosine
MED
Az(HD) = 0.9887
Az(Cosine) = 0.9915
Az(MED) = 0.9927
 
Fig. 7: The ROC curve of MEMD method with 
different similarity measures. 
-2
0
2
IM
F
1
-5
0
5
IM
F
2
-2
0
2
IM
F
3
50 100 150 200
-2
0
2
IM
F
4
 
Fig. 8: Comparison between MEMD and EMD intrinsic 
mode functions. This figure compares four MEMD 
IMFs (shown in blue) with the four EMD IMFs (shown 
in red) generated from the same iris signal. 
 
10
-3
10
-2
10
-1
10
0
10
1
10
2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
FalsePositiveRate(FalseMatchRate)
T
ru
eP
os
iti
ve
R
at
e(
1-
F
al
se
 N
on
-M
at
ch
 R
at
e)
ROC Curve of four methods with Cosine measures
Empirical Mode Decomposition
Gaussian-Hermite moment
Fourier-Wavelet feature
Proposed method
 
Fig. 9: The ROC curve of different methods using the 
cosine similarity measure. 
 
REFERENCES 
 
[1] S. N., Yanushkevich, “Synthetic Biometrics: A 
Survey”, in the Proceedings of International Joint 
Conference on Neural Networks, pp.676 – 683, 2006. 
[2] B. Miller, “Vital Signs of Identity,” IEEE Spectrum, 
Vol. 31, pp. 22-30, 1994. 
[3] T. Mansfield, G. Kelly, D. Chandler, and J. Kane, 
“Biometric Product Testing Final Report,” issue 1.0, 
National Physical Laboratory, March 2001. 
[4] J. Daugman, “High Confidence Visual Recognition 
of Persons by a Test of Statistical Independence,” IEEE 
Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 15, No. 11, pp. 1148-1161, Nov. 1993. 
[5] W. W. Boles, and B. Boashash, “A Human 
Identification Technique Using Images of the Iris and 
Wavelet Transform,” IEEE Transactions on Signal 
Processing, Vol. 46, No. 4, pp.1185- 1188, April 1998. 
[6] R. Wildes, J. Asmuth, G. Green, S. Hsu, R. 
Kolczynski, J. Matey, and S. McBride, “A 
Machine-Vision System for Iris Recognition,” Machine 
Vision and Applications, Vol. 9, No.1, pp. 1-8, 1996. 
[7] L. Ma, T. Tan, Y. Wang, and D. Zhang, “Personal 
Identification Based on Iris Texture Analysis,” IEEE 
Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 25, No. 12, pp. 1519-1533, Dec. 
2003. 
[8] L. Ma, T. Tan, Y. Wang, and D. Zhang, “Local 
Intensity Variation Analysis for Iris Recognition,” 
Pattern Recognition, Vol. 37, pp. 1287-1298, 2004. 
[9] L. Ma, T. Tan, Y. Wang, and D. Zhang, “Efficient 
Iris Recognition by Characterizing Key Local 
Variations,” IEEE Transactions on Image Processing, 
Vol. 13, No. 6, pp. 739-750, June, 2004. 
[10] O. D. Trier, A. K. Jain, and T. Taxt, “Feature 
Extraction Methods for Character         
Recognition – A Survey,” Pattern Recognition, Vol. 29, 
pp. 641-662, 1996. 
[11] I. Daubechies, Ten Lectures on Wavelets, SIAM, 
Philadelphia, Pennsylvania, 1992. 
[12] S. S. Wang, P. C. Chen, and W. G. Lin, “Invariant 
Pattern Recognition by Moment Fourier descriptor,” 
Pattern Recognition, vol. 27, pp. 1735-1742, 1994. 
[13] G. H. Granlund, “Fourier Processing for 
Handwritten Character Recognition,” IEEE 
Transactions on Computer, Vol. 21, pp. 195-201, 1992. 
[14] P. Wunsch, A. F. Laine, “Wavelet Descriptors for 
Multiresolution Recognition of Handprinted 
Characters,” Pattern Recognition, Vol. 28, pp. 
1237-1249, 1995. 
[15] P. S. Huang, C. S. Chiang, and J. R. Liang, “Iris 
Recognition Using Fourier-Wavelet Features”, Lecture 
Notes in Computer Science (LNCS), Vol. 3546, pp. 
14-22, 2005. 
[16] N. Huang, Z. Shen, S. Long, M. Wu, H. Shih, Q. 
Zheng, N. Yen, C. Tung, and H. Liu, “The Empirical 
Mode Decomposition and Hilbert Spectrum for 
Nonlinear and Non-stationary Time Series Analysis,” 
Proc. of the Royal Society of London, Vol. 454, pp. 
903–995, 1998. 
[17] X. Ye, Z. Zhuang and Y. Zhuang, “A New and Fast 
Algorithm of Iris Location,” Computer Engineering 
and Applications, Vol. 30, pp.54-56, 2003. 
[18] J. Daugman, “How Iris Recognition Works”, IEEE 
Transactions on Circuits and  Systems for Video 
Technology, Vol. 14, No. 1, pp.21-30, 2004. 
[19] J. Daugman, “Statistical Richness of Visual Phase 
Information: Update on Recognizing Persons by Iris 
Patterns,” International Journal on Computer Vision, 
Vol. 45, no. 1, pp. 25-38, 2001. 
[20] Hanho Sung, Jaekyung Lim, Ji-hyun Park and 
Yillbyung Lee, “Iris Recognition Using Collarette 
Boundary Localization,”  in the Proceedings of the 
17th International Conference on Pattern Recognition, 
Vol. 4, pp. 857-860, Aug. 2004.  
[21] W. Huang, Z. Shen, N. E. Huang, and Y. C. Fung, 
“Engineering analysis of biological variables: An 
example of blood pressure over 1 day,” Proceedings of 
the National Academy of Sciences of the United States 
of America, Vol. 95, pp. 4816–4821, 1998. 
[22] H. Liang, Z. Lin, and R. W. McCallum, “Artifact 
reduction in electrogastrogram based   on the 
empirical model decomposition method,” Medical & 
Biological Engineering & Computing, Vol. 38, pp. 
35–41, 2000. 
[23] B. Boashash, “Estimating and interpreting the 
instantaneous frequency of a signal-part  I: 
Fundamentals,” Proceedings of IEEE, Vol. 80, pp. 
520–538, 1992. 
[24] L. Cohen, Time-Frequency Analysis. Englewood 
Cliffs, NJ: Prentice-Hall, 1995. 
[25] G. Rilling, P. Flandrin, and P. Goncalves, “On 
empirical mode decomposition and its algorithms,” in 
Proc. IEEE-EURASIP Workshop on Nonlinear Signal 
and Image Processing, 2003. 
[26] Institute of Automation, Chinese Academy of 
Science, CASIA Iris Image Database. 
http//www.sinobiometrics.com/chinese/chinese.htm. 
[27] C. M. Bishop, Neural Networks for Pattern 
Recognition, Oxford University Press, 1996. 
 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                              95 年 10 月 20 日 
報告人姓名 黃炳森 
服務機構
及職稱 
 
國防大學中正理工學院電機系 
 
     時間 
會議 
     地點 
95 年 10 月 8 日至 11 日 
美國亞特蘭大 
本會核定
補助文號 NSC-95-2922-1-014-003 
會議 
名稱 
 (中文)2006 年 IEEE 國際影像處理會議 
 (英文)2006 IEEE International Conference on Image Processing 
發表 
論文 
題目 
 (中文)運用經驗模態分解法於虹膜識別 
 (英文)An Empirical Mode Decomposition Approach for Iris Recognition 
報告內容應包括下列各項： 
一、參加會議經過 
International Conference on Image Processing 是 IEEE 學會每年都舉辦一次的影像處理
研討會，在影像處理研究領域中是極重要且具代表性的國際學術會議。本研討會於 10 月 8 日至
11 日在美國喬治亞州的亞特蘭大市舉辦，大會會場是在市中心的 Marriott Marquis Hotel 內的國際
會議廳。本次會議一共收到了 1681 篇來自 40 幾個國家的投稿論文，最後只有 816 篇論文被接受，
並分別發表在 22 個 oral sessions、46 個 poster sessions，以及 8 個 special sessions 中。會議中的主
要議題則包含了影像分類、動態影像追蹤、目標偵測及生物識別等多個與影像處理有關的領域。
10/8 是本次 ICIP 會議的第一天，本日共安排了七個 Tutorial，請來世界各地知名的研究學者
為大家上課，分別由 Ahmet M.、Metin N. Gurcan、Nasser Kehtarnavaz and Thomas E. Madden、
Thomas Wiegand、S. Kevin Zhou and Richard Baraniuk 與 Rice 所主講。自 10/9 起，大會就開始安
排論文的發表，由於本會議的論文的數量相當多，所探討的領域也包羅萬象，因此會議議程被分
成多個主題，每天的上午都各有一個 Oral Session 與 Poster Session，而下午則各有兩個 Oral Session
與 Poster Session。本次會議一直進行到 10/11 晚上 17:30 才結束。 
本次會議，我與學生也有發表一篇 poster 論文，題目是『An Empirical Mode Decomposition 
Approach for Iris Recognition』。時間被安排在 10/9 的上午 9:40 ~ 12:40，場次於 Marriott Marquis
飯店的 International South 所舉行的 Fingerprint and Iris Analysis Session 中發表，本 Session 的主席
是來自 Siemens 公司的 Imre Varga，報告過程中，很高興與多位此一領域的專家學者交換心得，
對於我未來在此方面的研究頗有助益。當天下午 17:30-19:30 我也參加了 MATLAB 所舉辦的
Tutorial session, 內容介紹程式設計時該注意之技巧，獲益良多。 
 
二、與會心得 
最近幾年的 ICIP 會議中，full registration 都不含列印的論文集，而只有論文集的資料 CD 
片。此次未將每篇論文摘要印出，只依據論文題目，有時難以判斷對何者較感興趣，也無法在會
議進行的幾天中的展場事先研讀，有些可惜。 
