1行政院國家科學委員會專題研究計畫成果報告
可延後付款之供應鏈存貨模式-訂價與最佳批量策略
Optimal pricing and lot-sizing strategies with trade credit financing for
cooperative and non-cooperative supply chain inventory models
計 畫 編 號：NSC 97-2212-E-007-098
執 行 期 限：87 年 8 月 1 日至 88 年 7 月 31 日
主 持 人：陳茂生 國立清華大學工業工程與工程管理系
計畫參與人員：
一、中文摘要
在供應鏈系統中,通常賣方會容許買方在一
個期限內M延後付款,而不必加收延後付款的
利息,但如付款超過給定期限 M,未償付的部
份就要加計利息,而這些買家也可能再提供他
的客戶一延後付款期限 N,這種策略不但可以
吸引新客戶,同時也可避免價格惡性競爭。本
研究考慮供應鏈系統中,貨品有耗損退化性以
及上下游廠家各提供延後付款策略,建立模式
以求解最佳補貨策略等。當貨品退化率適當
小時,採用算數平均數大於等於幾何平均數的
關係,我們即可求解最佳解,對退化率較大的
情況,我們也推導理論依據用於求解,同時也
提供數值範例闡述求解方法。
關鍵詞:存貨,經濟生產量,交易賒欠,退化性
貨品,延後付款,算數平均數,幾何平均數。
Abstract: In a supply chain, the vendor often
offers its buyers a fixed credit period M to settle
the account. These buyers may also provide
their customers a trade credit period N. The
benefits of trade credit are not only to attract
new buyers but also to avoid lasting price
competition. In this research, we consider
up-stream and down-stream trade credits in a
supply chain and propose a generalize EPQ
model for solving the optimal manufacturer’s
replenishment policies with deteriorating items.
We propose a simple arithmetic-geometric
inequality method to find the optimal solution
when the deterioration rate is sufficiently small.
We also develop the proper theoretical results to
obtain the optimal solution when the
deterioration rate is not sufficiently small.
Finally, numerical examples are presented to
illustrate the proposed model and its optimal
solution.
Keywords: Inventory; EPQ; Trade Credits;
Deteriorating item; Permissible delay in
payments; Arithmetic mean; Geometric mean;
Introduction
Goyal (1985) was the first proponent for
developing an economic order quantity (EOQ)
model under the conditions of permissible delay
in payments. Shah (1993) considered a
stochastic inventory model when items in
inventory deteriorate and delays in payments
are permissible. Aggarwal and Jaggi (1995)
extended Goyal’s model to allow for
deteriorating items. Next, Jamal et al. (1997)
further generalized Aggarwal and Jaggi’s model
to allow for shortages. Teng (2002) amended
Goyal’s model by considering the difference
between unit price and unit cost and established
an easy analytical closed-form solution to the
problem. Chung and Huang (2003) generalized
Goyal’s EOQ model to an economic production
quantity (EPQ) model in which the selling price
is the same as the purchase cost. Huang (2003)
extended Goyal’s model to the case in which
the supplier offers the retailer the permissible
delay period M (i.e., the upstream trade credit),
and the retailer in turn provides the trade credit
period N (with N M) to its customers (i.e.,
the downstream trade credit). Teng and Goyal
(2007) amended Huang’s model by 
complementing his shortcomings. Recently,
Liao (2008) extended Huang’s model to analyze
the impact of the two-level trade credit on EPQ
model for deteriorating items. Chang et al.
(2008) reviewed the contributions on the
literature in modeling of inventory lot-sizing
under trade credits.
Liao (2008) proposed an EOQ model with
3cost for the manufacturer as
1 1( )
ATVC T
T
 +
T
h
2
{ ]1)[( 11   teDP t  +
]1)([ 1
)( 1  tTeD tT  }+ cDPt
T
c 1 +
2
)(
]1)([
2
)(
2
NMD
T
sI
MNTe
D
T
cI
eMNTp  

 .(6)
Sub-case 1-2: NTM 
In this sub-case, the manufacturer receives
the total revenue at time T + N, and is able to
pay the supplier the total purchase cost at time
M. Since the customer last payment time T + N
is shorter than the supplier credit period M, the
manufacturer faces no interest charged.
Therefore, the annual capital opportunity cost is
given by
T
sI e { NTN dttNTD )( + )]([ NTMDT  }
=
T
sI e [
2
2DT + )( NTMDT  ]. (7)
By using (7), we obtain the annual total
relevant cost for the manufacturer as
1 2 ( )
ATVC T
T
 +
T
h
2
{ ]1)[( 11   teDP t  +
]1)([ 1
)( 1  tTeD tT  }+ cDPt
T
c 1 –
T
sIe [
2
2DT + )( NTMDT  ]. (8)
Case 2: MN 
In this case, the down-stream trade credit
period N is equal to or larger than the up-stream
credit period M. Consequently, there is no
interest earned for the manufacturer. In addition,
the manufacturer must finance all purchase cost
at time M at an interest charged pI per dollar per
year, and start to payoff the loan after time N.
Hence, the capital opportunity cost is given by
])1()[( )(1    NTN tNTp dte
D
PtMN
T
cI 

1 2[( ) ( 1)]
p TcI DN M Pt e T
T
     
. (9)
By (9), we obtain the annual total relevant
cost for the manufacturer as
2 ( )
ATVC T
T
 +
T
h
2
{ ]1)[( 11   teDP t  +
]1)([ 1
)( 1  tTeD tT  }+ cDPt
T
c 1 +
)]1()[( 21  Te
D
PtMN
T
cI Tp 

 . (10)
Optimal solution
To obtain the explicit closed-form solution
and meaningful managerial implications, we
will discuss the case in whichis sufficiently
small first and then the other case in whichis
not sufficiently small.
Case A:is sufficiently small
In this case, we know from (4) that 1t
PDT / . Using Taylor approximation,
2
)(
1
2T
Te T
  , (11)
we get
)(11 TTVC  
2 2( ) ( )
2 2 2
p e
cI sID T N M D M NhDTA
T T T
     
=
T
NMDcIsIA pe
2
)()(2 2 +
2
)( DTcIh p
)( NMDcI p  . (12)
As we know, the arithmetic mean is always
greater than or equal to the geometric mean. In
short, for any two real positive numbers, say a
and b , we have
2
a b
ab
  . (13)
The equation holds only if a b . Hence, if
0)()(2 2  NMDcIsIA pe , and
T
NMDcIsIA pe
2
)()(2 2 =
2
)( DTcIh p > 0,
or
DcIh
NMDcIsIA
T
p
pe
)(
)()(2 2*
11 

 
, (14)
then the optimal annual total relevant cost
)(11 TTVC  11TVC (
*
11T )
= ])()(2[)( 2NMDcIsIADcIh pep 
)( NMDcI p  . (15)
Hence, we obtain *11T is the optimal cycle time
for Sub-case 1-1: NTM  .
Using the similar argument, we obtain
)(21 TTVC  
T
A +
2
hDT –
T
sI e [
2
2DT + )( NTMDT  ]
2
2
A
T
 +
2
)( DTsIh e )( NMDsI e  . (16)
Hence, the optimal cycle time for Sub-case 1-2:
NTM  is to find * 21T so that
T
A
2
2 =
2
)( DTsIh e ,
which in turn implies
*
21T )](/[2 esIhDA   . (17)
Consequently, the optimal annual total relevant
cost
5that if 2)(2 NMDsIA e  then the solution to
(28) *11T not only exists but also is unique.
Using the analogous argument, letting
dTTdTVC /)(21 = 0, we find the optimal
*
21T is
determined by
A +
2
1
1
( ) ( ) 0
2
esI DTdth c P T t
dT


    , (29)
Let
2
1
1 2 1
( )( ) ( ) 0
2
esI DTdth c PH T A T t
dT


    
Then we have:
)0(21H = A < 0,  )(lim 21 THT > 0, and
2
1 1 1
2
( ) ( )dH T d th c PT
dT dT


  + DTsI e > 0.
Therefore, the solution to (29) * 21T not only
exists but also is unique.
Based on the above arguments, we obtain the
following theorem.
Theorem 2.
(a) If 2)(2 NMDsIA e  , then there exists a
unique solution *11T in (28) which
minimizes )(11 TTVC  .
(b) There exists a unique solution * 21T in (29)
which minimizes )(21 TTVC  .
Proof. It immediately follows from the above
arguments.
Next, based on the above results and the
definition of )(1 TTVC for Case 1: MN  , we
have
1 1
1
1 2
( ), if
( )
( ), if
TVC T T M N
TVC T
TVC T T M N


   
. (30)
Since
)(11 NMTVC  = )(21 NMTVC  , )(1 TTVC is
continuous and well defined. The above
arguments show that )(11 TTVC  (or )(21 TTVC  )
is a continuous differentiable function of T with
a derivative that changes sign only once at
*
11T (or
*
21T ) from negative to positive. It implies
that )(1 TTVC assumes its global minimum at
point *1T . In addition, letting NMT  , we
obtain
2
11
/
11 )/()()( NMNMHNMTVC   , (31)
2
21
/
21 )/()()( NMNMHNMTVC   , (32)
and
)(/ 11 NMTVC  = )(/ 21 NMTVC  . (33)
Letting 2= )(/ 11 NMTVC  = )(/ 21 NMTVC  , we
have the following results.
Theorem 3. MN  ,
(a) If 02  , then *11* TT .
(b) If 02  , then * 21* TT .
(c) If 02  , then NMTTT   * 21*11* .
Proof.
If 02  , which implies that *11T  NM  ,
*
21T  NM  and )(1 TTVC has the minimum
value at T = *11T when NMT  . Because
)(21 NMTVC  = )(11 NMTVC 
> )( *1111  TTVC , )(1 TTVC has the minimum
value at *11T for T > 0. Hence, we conclude
that )( *11 TTVC = )(
*
111 TTVC . The proof of
Theorem 3(A) is completed. Using the similar
arguments, the proofs of Theorem 3(B) and 3(C)
can also be completed.
For Case 2: MN  , using the analogous
argument as Case 1 and dTTdTVC /)(2 = 0, we
can find the optimal *2T which is determined by
1 1
1 1
( ) ( ) [ ( ) ( )p
dt dth c PA T t cI N M Pt TP N M
dT dT


      +
2 ( 1)] 0
T TD e Te     
(34)
The solution *2T in (34) which minimizes
)(2 TTVC not only exists but also is unique.
Consequently, using Theorems 2 and 3 and (34),
we can determine the optimal solution for the
case in which the deterioration rate is not
sufficiently small.
Numerical Examples
To illustrate the above results, we provide the
following numerical examples.
Example 1: Given D = 1000 unit/year, P =
3000 unit/year, c = $20/unit, s = $60/unit, h =
$5/unit/year, pI =0.15/year, eI = 0.1/year, M =
0.25 year, N =0.1 year and = 0.01. Since 
is sufficiently small, we can use Taylor
approximation to find the optimal solution. In
addition, N < M. By using the results in
Theorem 1, we obtain the computation results
for the optimal values of *T and )( *TTVC
with respect to different values of the set-up
cost A are shown in Table 1. Table 1 reveals
that the higher the set-up cost A, the higher
optimal cycle time *T , as well as the higher
annual total relevant cost )( *TTVC .
Consequently, we have the following
7$100/order, M = 0.1 year and N = 0.12 year. We
know N > M. For = {0.15, 0.20, 0.25, 0.30},
using Equation (34), the optimal solutions with
respect to different values of deterioration rate 
are shown in Table 5. Table 5 indicates that if M
< N, then a higher value of  causes a higher
value of )( *TTVC , but a lower value of *T . As
a result, the managerial insight in this case is
exactly the same as in Example 2.
Table 5: Computation results with
respect to different values of 
 *T )( *TTVC
0.15 *
2T = 0.174242 1169.5734
0.20 *
2T = 0.165820 1227.2077
0.25 *
2T = 0.158504 1282.2384
0.30 *
2T = 0.152072 1334.9866
Conclusions
In this research, we proposed a generalized
model with both up-stream and down-stream
trade credits. In addition, we have relaxed the
dispensable assumption of N < M and ep II  .
In order to obtain the explicit closed-form
solution and meaningful managerial implications,
we have used Taylor approximation to discuss the
case in which deterioration rate is sufficiently
small. Moreover, we have proposed a simple
arithmetic-geometric inequality method easily to
obtain the optimal solution for this case. Then we
have developed several theoretical results to find
the optimal solution for the other case in which
the deterioration rate is not sufficiently small.
Finally, we have provided several numerical
examples to illustrate the proposed model and its
optimal solution. Based on those computational
results, we have provided several managerial
insights.
References
[1] Aggarwal, S. P. and Jaggi, C.K. (1995).
Ordering policies of deteriorating items under
permissible delay in payment. Journal of the
Operational Research Society 46, 658-662.
[2] Chang, C. T., Teng, J. T., and Goyal, S. K.
(2008). Inventory lot-size models under trade
credits: a review. Asia Pacific Journal of
Operational Research 25, 89-112.
[3] Chung, K.J. and Huang, Y.F. (2003). The
optimal cycle time for EPQ inventory model
under permissible delay in payments.
International Journal of Production Economics
84, 307-318.
[4] Goyal, S. K. (1985). Economic order
quantity under conditions of permissible delay
in payments. Journal of the Operational
Research Society 36, 335-338.
[5] Huang, Y. F. (2003). Optimal retailer’s
ordering policies in the EOQ model under trade
credit financing. Journal of the Operational
Research Society 54, 1011-1015.
[6] Jamal A. M. M., Sarker B. R. and Wang, S.
(1997). An ordering policy for deteriorating
items with allowable shortage and permissible
delay in payment. Journal of the Operational
Research Society 48, 826-833.
[7] Liao, J. J. (2008). An EOQ model with
noninstantaneous receipt and exponentially
deteriorating items under two-level trade credit.
International Journal of Production Economics
113, 852-861.
[8] Shah, N. H. (1993). Probabilistic time-
scheduling model for an exponentially decaying
inventory when delay in payment is permissible.
International Journal of Production Economics,
32, 77-82.
[9] Teng, J. T. (2002). On the economic order
quantity under conditions of permissible delay
in payments. Journal of the Operational
Research Society 53, 915-918.
[10] Teng, J. T. and Goyal, S. K. (2007).
Optimal ordering policies for a retailer in a
supply chain with up-stream and down-stream
trade credits. Journal of the Operational
Research Society 58, 1252-1255.
[11] Teng, J. T. and Chang, C. T. (2009).
Optimal manufacturer’s replenishment policies
in the EPQ model under two levels of trade
credit policy. European Journal of Operational
Research, 196, 177-185.
2國), Steve Gallivan(英國)三位國際著名學者做大會專題演說。
二. 與會心得與建議
本次大會參加數個論文發表場次也有機會和幾位來自業界的專業
人員交流,他們普遍認為業界做的相關研究較契合實際應用,探討問題
也較深入,學界往往對實務不夠膫解,許多設定失之偏頗,考慮常不夠週
詳,發表論文的教授聽過業界人士的發問建議後,也覺得找到更多研究
題材,研究內容經修正後會更充實週全。的確實務問題因時、地、人、
物…等影響,有相當大的變化,為了要解決實務問題常可啟發新的研究
方向,找到新的研究題材。
我國目前有數十位 INFORMS 會員,也成立 INFORMS 海外分會,
一直和總會有密切聯續,在近年適當時機,我們也建議爭取主辦這一國
際囑目的國際會議。
三、攜回資料
1. 2009 CORS-INFORMS Joint International Meeting:議程與論文摘要集
2. The Franz Edelman Award Achievement in Operations Research 2008
(DVD)
41. Introduction
Integer programming is a fascinating and difficult branch of mathematical optimization
with numerous applications in engineering, the physical sciences, the social sciences,
economics and management. It becomes a subject of ever-increasing interest to
engineers, computer scientists, operations researchers, mathematicians, and practicianes.
The past four decades have witnessed extensive computational and theoretical efforts
[Hausm 1978] [Kasti 1976] [Von 1981, 1984, 1987]. Considerable progress has been
made and some important results are now available. [Stani 1990], [Schri 1986] [Sierk 2002]
[Wolse 1998] are excellent references for a detailed account of this subject. The
theoretical interest is due to its simplicity in modeling. It allows that more complex
optimization models can be solved through a series knapsack-type subproblems. From
the practical point of view, it can model many industrial and management situations such
as captital budgeting [Pater 1974] [Weing 1966], cargo loading, cutting stock[Sierk
2002], reliability optimization [Kuo 2000, 2003], and resource allocation [Brett 1995]
[Kodia 1998] etc.
In this research, we consider the nonlinear knapsack problem (NKP) which is a
generalization of linear case of knapsack problems. Many researchers indicated that
these problems also play an important role in the theory of integer programming[Marte
1990] [Kelle 2004] [Frevi 2004] [Nemha 1989] [ Li 2006]. A mathematical formulation
of the multi-dimensional nonlinear knapsack problem is given as follows:
1
1
(NKP) maximize ( )
subject to ( ) , 1, 2, , ,
0 , integer, 1, 2, , .
n
j j
j
n
ij j i
j
j j j
f x
g x b i m
x u x j n


 
  

 

The assumptions are:
(i) ui is +or a positive integer, i = 1, 2, . . . , n.
(ii) The functions fj(xj), j = 1, 2, . . . , n, are concave and increasing.
(iii) The functions gij(xj), i = 1, 2, . . . , m, j = 1, 2, . . . , n, are convex and increasing.
If uj = 1 for each j, then NKP can be reduced to a linear 0-1 knapsack problem, So, in
this research, we consider the cases with uj > 1 for each j. If uj =for each j, then it is
called unbounded nonlinear knapsack problem. A generalization of these models occur
when n variables are partitioned into p groups J1, J2, . . . , Jp and it is specified that at
most one variable in each group can be set to be positive. Such models are called
6Roughly speaking, as the name indicates, this approach consists of changing the current
solution in a locally best way to obtain a new solution. A general formulation is given as
follows: (a) For each j, assign some efficiency score Ej to variable xj. Restrict attention
to variables that have not previously been given specific values or to variables whose
range have not been significantly restricted on a recent iteration. (b) Choose one or more
variables with highest scores. (c) If all variables have been constrained to specific values,
stop. Otherwise, go to (1). It also can be regarded as a steepest ascent scheme since it
goes through the whole set then pick the best one in each iteration. In spite of the
simplicity of this framework, a variety of specific heuristic and exact algorithms, old and
new are encompassed within it. However, it has propensity to prematurely converge to a
local optimum. One way of avoiding this is to allow the exploration of a wider range of
solution space by introducing randomness in the search procedure. Thus, the modern
heuristic methods which include ant algorithm, genetic algorithm and simulate annealing
are designed to escape from the local optimum traps. Although they still do not
guarantee an optimum solution, they have been proved to work exceptionally well in
practice and have many advantages including versatility, efficiency and simplicity.
Probabilistic search is different from the conventional deterministic methods, such as the
local search methods by introducing randomness into the search procedure. These
methods have the following advantages (1) They are rather simple to implement. (2)
They are very general and can be implemented to a wide variety of problems. For
example, there is no need for differentiable function of real-valued parameters and it
needs no explicit constraint formulations. (3) They can be implemented in parallel. (4)
They have been proved to be very successful in finding good and fast approximation
solutions for hard optimization problems.
2. Linearization of NKP
Since fj(xj) is a concave function and gij(xj) is a convex function for each i and j, It turns
out that NKP can be converted into a linear multidimensional knapsack problem by
piecewise linear approximation on the interval [0, uj] for each j.
For each j, we partition the interval [0, uj] into subintervals [uj0, uj1], ... , [uj k-1,uj k], ... ,
1[ , ]j jje jeu u where 0 0, jj je ju u u  , Let
1
, 0
ju
j jk jk jk
k
x x x u

   ,
1( ) ( )jk j jk j j kf f u f u   , 1( ) ( )ijk ij jk ij j kg g u g u   . By monotonicity, fjk0, gijk0 for
each i, j and k. NKP is thus converted into the following piecewise linear approximation
80 , 1, 2, ... , ,j jx u j n  
Let ( )jx
 x be the optimal solution of relaxed LMKP. We may then solve the
following reduced 0-1 knapsack problem.
(P1)
1
maximize
n
j j j j
j
c x x x 

    
1
subject to , 1, 2, ... , ,
n
ij j j j i
j
a x x x b i m 

      
0, 1, 1, 2, ... , ,jx j n 
wherekis the greatest integer such thatkk andkis the smallest integer such that
kk.
We may also consider the following alternate reduced problems.
(P2)
1
maximize 1
n
j j j j
j
c x x x 

     
1
subject to 1 , 1, 2, ... , ,
n
ij j j j i
j
a x x x b i m 

       
0, 1, 1, 2, ... , ,jx j n 
(P3)
1
maximize 0.5
n
j j j j
j
c x x x 

     
1
subject to 0.5 , 1, 2, ... , ,
n
ij j j j i
j
a x x x b i m 

       
0, 1, 1, 2, ... , ,jx j n 
(P4)
1
maximize 0.5
n
j j j j
j
c x x x 

     
1
subject to 0.5 , 1, 2, ... , ,
n
ij j j j i
j
a x x x b i m 

       
0, 1, 1, 2, ... , ,jx j n 
The genetic algorithm is then applied to solve (P1) ,(P2),.(P3), and (P4).
4. A Genetic algorithms for 0-1 multidimensional knapsack problem
0-1 multidimensional knapsack problem (0-1 MKP) has been extensively
discussed because of its wide applicability and theoretical importance. An overview of
the 0-1 MKP can be found in [Kelle 2004] [Frevi 2004]. For simplicity, it is
mathematically formulated as follows.
(0-1 MKP)
1
maximize ,
n
j j
j
c x


1
subject to , 1, 2, ... , ,
n
ij j i
j
a x b i m

 
0, 1, 1, 2, ... , ,jx j n 
where all cj, aij and bi are nonnegative values. Without loss of generality, we assume that
10
offspring based on their fitness to form a new population. The
crossover-mutation-evaluation-selection cycle is repeated until the user-specified
termination criterion is reached.
In order to identify the effective and ineffective items, we adopt the optimal dual
solution of LP relaxation of the 0-1 MKP as the surrogate coefficients (si). Suppose xj
has surrogate ratio jSRe which is defined by equation (1) and without loss of generality,
we assume that 1 2 ... nSR SR SRe e e   . By the theory of linear program, we have the
following properties: (i) the items with 1jSRe  are mainly the basic variables in the
optimal solution of the LP-relaxed MKP. (ii) the items with 1jSRe  are the nonbasic
variables at lower bound in the optimal solution of the LP-relaxed MKP. (iii) the items
with 1jSRe  are the nonbasic variables at upper bound in the optimal solution of the
LP-relaxed MKP. So we will divide the items (variables) of a given 0-1 MKP into three
parts: The first part (denoted by P1) includes the items with larger surrogate ratios
( 1jS Re  , the second part (P2) is composed of the items with 1
j
SRe  and the third part
(P3) is made up of the items with smaller surrogate ratios ( 1jSRe  ). The basic idea is to
find two positions (CP1 and CP2) to divide {1, 2, ... , n} into three parts such that P1 =
{ j | j < CP1}, P2 = { j | CP1jCP2} and P3 = { j | j > CP2} . We will let xj =1, jP1
and xj = 0, jP3 before executing the proposed genetic algorithm. A procedure for
identifying CP1 and CP2 is given as follows. Let
min{ | 1, 1,2, ... , }jmin SRC j e j n   and max{ | 1, 1,2, ..., }.jmax SRC j e j n  
For a given parameter W, 0 < W < 1, we let
1 2, .min maxCP C W n CP C W n     
Computational results show that W = 0.15 will give good performance for the problems
with 1,000n10,000 and 500m5,000. For the larger problem, we suggest to use
smaller w.
There exist three schemes for GAs to deal with a constrained optimization problem,
including penalizing scheme, encoding scheme and repairing scheme. The
repairing-based GAs also use a repairing operator additionally after crossover and
mutation operations. The penalizing-based GAs for the 0-1 MKP frequently suffer from
the feasibility problem. It may converge in a completely infeasible population, especially
when the ratio of the feasible region to the search space is low. Existing encoding-based
GAs for the 0-1 MKP have been shown to have weaker locality, heritability and heuristic
bias, which are essentials for good performance of evolutionary search [Raidl 2005]. In
addition, the recently work based on these two strategies for the 0-1 MKP [Gottl 2000]
[Raidl 1999] [Uyar 2005] and some of Raidl’s [Raidl 2005] still can not be more
effective than the repairing-based GAs proposed by Chu and Beasley [Chu 1998]. In this
research, we adopt the repairing scheme and the procedure of proposed GA is shown in
Procedure 1.
A Hybrid Genetic Algorithm
Procedure 1: Proposed genetic algorithm
begin
t ← 1;
initialize P(t);
evaluate P(t);
while ( not termination condition ) do
recombine P(t) to generate O(t); /* apply crossover and mutation */
repair O(t);
12
Table 5.1 Outline of the three genetic algorithms
Algorithm CGA [Chu 1998] RGA [Raidl 2005] HGA
Preprocessing None None Variable reduction procedure
Initialization Randomization
Based on the optimal
solution of
LP-relaxed MKP
Based on the surrogate
information and the optimal
solution of LP-relaxed
Crossover Uniform Uniform Fitness-guided
Mutation Uniform Uniform Heuristic
Repairing Based on surrogateinformation
Based on surrogate
information
Hybridize surrogate
information with greedy
heuristics
Selection (μ+λ) selection (μ+λ) selection Hybridize roulette wheelselection with(μ+λ) selection
Remark: HGA is the proposed GA.
We code HGA by using C language and develop it on the integrated development
environment called Dev C++. The LP-relaxed MKP is solved by using the mathematical
programming solver called LINGO (Version 8.0). For Chu and Raidl’s algorithms, since
the original codes are not available to us, we code them ourselves based on the
descriptions mentioned in the corresponding papers. All of the computational study are
ran on the PC with Pentium 4 2.8G Hz CPU.
To illustrate the computational results, we define the following notations and
performance indexes.
(1) α: the tightness ratio, which is used to set bi as in Equation (2).
1
, 1, 2, ... , .
n
i ijj
b a i m   (2)
(2) β: the density ratio, which is the percentage of nonzero values in the constraint
matrix [aij].
(3) z*: the best objective value found.
(4) Avg z*: average of z*.
(5) lpgap = 100*( LPz  *z )/ LPz (in %) where LPz is the optimal objective value of
the LP-relaxed MKP.
(6) Avg lpgap: average of lpgap (in %).
(7) rgap = 100*( *maxz  *z )/ *maxz (in %) where *maxz is the highest objective value
among the three algorithms.
(8) Avg rgap: average of rgap (in %).
(9) *t : the time used to reach z* (in seconds).
(10) Avg t*: average of t* (in secs).
(11) G : total generations ran. For each algorithm, on average, each generation
examines 50 offspring (solutions).
(12) T : the total execution time.
(13) Avg T : average of T.
(14) #best : the frequency of obtaining *maxz (including ties).
We first conduct the computational study based on two popular 0-1 MKP problem
sets. The largest problem of them is up to 2500 items and 100 constraints. HGA will be
evaluated on these publicly accessible problem sets and compared with the results from
literature.
5. 1 Medium-scale problems from OR-Library
14
As shown in Table 3, HGA also outperforms CGA and RGA in which the variable
reduction procedure is incorporated.
We compare HGA with CPLEX and branch and bound algorithm [Osori 2002] in
Table 4.
Table 5.4 Comparison with the experimental results from exact algorithms
Problem set ORL-0.25 ORL-0.5 ORL-0.75
Method CPLEX B&B-O HGA CPLEX B&B-O HGA CPLEX B&B-O HGA
Avg z* 115497 115520 115560 216151 216180 216213 302366 302373 302401
Remark 1: Each set has 10 problems.
2: The version of CPLEX is 6.5.2. The results are from [Osori 2002]. In all of
the 30 problems, it terminated because of reaching 250 MB
treesize memory.
3: B&B-O is the branch and bound algorithm developed by [Osori 2002]. The
results are from [Osori 2002]. In all of the 30 problems, it terminated because
of reaching 10800 seconds solution time (CPU: Pentium III 450 MHz).
5. 2 Medium-scale problems from Hearin center for enterprise science
The second medium-scale problem set contains 5 largest 0-1 MKP from Hearin
center for enterprise science (available at http://hces.bus.olemiss.edu/tools.html). Each
of them has different (n, m) and the largest one contains 2500 items and 100 constraints.
They were generated by Glover [Glove 1996]. For each problem, we derive its reduced
version based on the proposed variable reduction procedure (W = 0.15). The resulting
problem set is denoted by HCES-R and the original one is denoted by HCES.
Table 5.5 Experimental results of the three algorithms for no redundant reduced
problems
Problem set HCES-R
Method CGA RGA HGA
Avg z* 49671 49718 49725
Avg lpgap(%) 0.1691 0.0871 0.0007
Avg rgap(%) 0.0972 0.0152 0
Avg t*(secs) 909 591 4550
Avg G 1367292 1526951 578219
Avg △(%) 4.8771 4.9556 4.9700
#best 0 0 5
Remark 1: The running time of each algorithm for each problem is 5400 seconds.
2: CGA, RGA solve HCES; HGA solves HCES-R.
3: Each set has 5 problems and the average terms are the average of the results
from 5 problems.
Table 5.6 Experimental results of the three algorithms for no redundant reduced
problems
16
Table 5.8 Results of the three algorithms for no redundant reduced problems
Problem set m = 200 m = 500 m = 1000
Method CGA RGA HGA CGA RGA HGA CGA RGA HGA
Avg z* 1158197 1158932 1159211 1150786 1151331 1151875 1146698 1147383 1148087
Avg lpgap(%) 0.2584 0.1951 0.1711 0.3129 0.2657 0.2186 0.3760 0.3165 0.2553
Avg rgap(%) 0.0874 0.024 0 0.0945 0.0472 0 0.121 0.0614 0
Avg t*(secs) 6962 5870 5552 8259 7473 6706 8417 7037 6320
Avg G 61040 61103 41037 23355 22414 16006 8614 6133 7846
Avg △(%) 5.5062 5.5661 5.5888 8.2078 8.2512 8.2945 10.2745 10.3281 10.3831
#best 0 0 10 0 0 10 0 0 10
Remark 1: For each problem in these problem sets, n = 5000,α= 0.25 andβ= 1.
2: CGA and RGA solve non-reduced problems.
HGA solves reduced problems.
3: The running time of each algorithm for each problem is 9000 seconds.
Table 5.9 Experimental results of the three algorithms
Problem set α = 0.01 α = 0.1 α = 0.25
Method CGA RGA HGA CGA RGA HGA CGA RGA HGA
Avg z* 66930 67890 69053 715120 715976 716987 715120 715976 716987
Avg lpgap(%) 8.706 7.397 5.811 0.799 0.680 0.540 0.799 0.680 0.540
Avg rgap(%) 3.074 1.684 0.000 0.260 0.141 0.000 0.260 0.141 0.000
Avg t*(secs) 8535 6098 4721 8405 7786 7391 8405 7786 7391
Avg G 3103 3060 25535 2880 2869 12450 2880 2869 12450
#best 0 0 10 0 0 10 0 0 10
Remark 1: For each problem in these problem sets, n = 7500, m = 500 andβ= 1.
2: CGA and RGA solve non-reduced problems. HGA solves reduced problems.
Table 5.10 Experimental results of the three algorithms
Problem set β= 0.25 β= 0.5 β= 0.75
Method CGA RGA HGA CGA RGA HGA CGA RGA HGA
Avg z* 680854 681799 683760 835946 836660 837974 993060 993614 994522
Avg lpgap(%) 1.299 1.162 0.878 0.760 0.675 0.519 0.500 0.445 0.354
Avg rgap(%) 0.425 0.287 0.000 0.242 0.157 0.000 0.147 0.091 0.000
Avg t*(secs) 8395 7402 3500 6823 7317 5640 7342 6613 6536
Avg G 4525 4438 16571 5031 6193 18024 5008 4947 19081
#best 0 0 10 0 0 10 0 0 10
Remark 1: For each problem in these problem sets, n = 5000, m = 500,α= 0.25.
2: CGA and RGA solve non-reduced problems. HGA solves reduced problems.
6. Computational Results for LMKP
The genetic algorithm Procedure 1 is then applied to solve (P1) ,(P2), (P3), and (P4).
Table 6.1 Experimental results with W =0.15 for automatic generated general LP problems.
18
4: (P1), (P2), (P3) and (P4) solves reduced problems with no redundant constraint.
Table 6.4 Experimental results with W =0.15 for automatic generated general LP problems.
Problem Set m = 200
Reduced Problem (P1) (P2) (P3) (P4)
Avg z* 12698353 12698314 12621450 12698260
Avg lpgap(%) 0.0079 0.0082 0.6245 0.0086
Avg t*(secs) 2802 2981 21 3371
Avg G 168271 43805 2699876 269777
#best 6 4 0 2
Remark 1: For each problem in these problem sets, n = 5000,α= 2~10 andβ= 1.
Remark 2: The running time of each algorithm for each problem is 9000 seconds.
Remark 3: Each set has 10 problems and the average terms are the average of the results
4: (P1), (P2), (P3) and (P4) solves reduced problems with no redundant constraint.
Table 6.5 Experimental results with W =0.15 for automatic generated general LP problems.
Problem Set m = 1000
Reduced Problem (P1) (P2) (P3) (P4)
Avg z* 10528492 10528461 10508738 10528324
Avg lpgap(%) 0.0173 0.0176 0.2052 0.0189
Avg t*(secs) 2957 4748 2 4949
Avg G 93488 71912 1709200 107506
#best 8 1 0 1
Remark 1: For each problem in these problem sets, n = 5000,α= 2~10 andβ= 1.
Remark 2: The running time of each algorithm for each problem is 9000 seconds.
Remark 3: Each set has 10 problems and the average terms are the average of the results
4: (P1), (P2), (P3) and (P4) solves reduced problems with no redundant constraint.
Table 6.6 Experimental results W =0.15 for automatic generated general LP problems.
Problem Set β= 0.25
Reduced Problem (P1) (P2) (P3) (P4)
Avg z* 10148288 10148320 8619459 10148065
Avg lpgap(%) 0.0396 0.0393 15 0.0418
Avg t*(secs) 3758 3463 5200 3636
Avg G 29000 48574 35301 40347
20
approach. We also conduct some computational study based on medium-scale problem
sets and several randomly generated large-scale problem sets.
References:
[Balas 1980] Balas, E.; Zemel, E., “An algorithms for large zero-one knapsack problem”, Operations
Research, Vol. 28, pp.1130-1154.
[Beasl 1990] Beasley, J., “OR-Library: Distributing test problems by electronic mail,” Journal of the
Operational Research 41, 1068-1072 (http://www.ms.ic.ac.uk/info.html).
[Biond 1969] Biondi, E.; Schmid, R., “ An approximation algorithm for discrete linear 
programming,” IEEE Transactions on System Science and Cybernetics, Vol. 5, 65-70.
[Bonab 1999] Bonabeau, Rric; Marco Dorigo, and Guy Theraulaz, Swarm Intelligence: From
Natural to Artificial Intelligence, Oxford University Press, Oxford.
[Billi 1996] Billionnet, A., Linear programming for the 0-1 quadratic knapsack problem, European
Journal of Operational Research 92: 310 1996.
[Brett 1995] Bretthauer, K.; Shetty, B., The nonlinear resource-allocation problem, Operations Research
43 (4): 670-683 jul-aug 1995.
[Brett 1996] Bretthauer, K., A projection method for the integer quadratic knapsack problem, Journal of
the Operational Research Society 47: 457 1996.
[Brett 1997] Bretthauer, K.; Shetty, B., Quadratic resource allocation with generalized upper bounds,
Operations Research Letters 20 (2): 51-57 feb 1997
[Brett 2002a] Bretthauer, K.; Shetty, B., The nonlinear knapsack problem - algorithms and applications,
European Journal of Operational Research 138 (3): 459-472 may 1 2002.
[Brett 2002b] Bretthauer, K.; Shetty, B., A pegging algorithm for the nonlinear resource allocation
problem, Computers & Operations Research 29 (5): 505-527 apr 2002.
[Brett 2003] Bretthauer K., Shetty, B., Syam, S., A specially structured nonlinear integer resource
allocation problem, Naval Research Logistics 50 (7): 770-792 oct 2003.
[Capra 1999] Caprara, A., Exact solution of the quadratic knapsack problem, INFORMS Journal on
Computing 11 : 125 1999
[Chern 1980] Chern, Maw-Sheng, Polynomial Approximation Algorithms for Generalized
Multidimensional Knapsack Problem, Ph.D. Thesis, Department of Management Sciences,
University of Waterloo.
[Chern 1992] Chern, M., On the computational-complexity of reliability redundancy allocation in a series
system, Operations Research Letters 11 (5): 309-315 Jun 1992.
[Chu 1998] Chu, P. C.; Beasley, J.E. , A genetic algorithm for the multidimensional knapsack
problem, Journal of Heuristics, Volume 4, Number 1, pp. 63-86
[Coit 1996a] Coit, D.; Smith, A., Reliability optimization of series-parallel systems using a genetic
algorithm, IEEE Transactions on Reliability 45 (2): 254& JUN 1996
[Coit 1996b] Coit, D.; Smith, A., Solving the redundancy allocation problem using a combined neural
network/genetic algorithm approach, Computers & Operations Research 23 (6): 515-526 JUN 1996.
[Corne 1999] Corne, David; Dorigo, Marco; and Fred Glover, New Ideas in Optimization, The
McGraw-Hill Companies.
[Dabae 1979] Dabaev, Dzh. A., Mamedov, K. Sh., and Mekh\tiev, M. G., “Methods of constructing 
suboptimal solutions of multi-dimensional knapsack problems,” U.S.S.R. Comput. Maths Math Phys.,
Vol.18, 82-91.
[Dasgu 1999] Dasgupta, D. (ed.), Artificial Immune Systems and Their Applications,
Springer-Verlag.
[Dorig 1992] Dorigo, M., Optimization, Learning and Natural Algorithms, (in Italian). PhD thesis,
Dipartimento di Elettronica, Politecnico di Milano, IT.
[Dorig 1996] Dorigo, M., V. Maniezzo, and A. Colorni, “The ant system: Optimizatoin by a colony 
of cooperating agents,” IEEE Transactions on Systems, Man, and Cybernetics - Part B, 26(1): 29-41.
[Dorig 2004] Dorigo, Marco; Thomas Stützle, Ant colony optimization, Cambridge, Mass., MIT
Press, c2004.
22
[Kelle 2004] Kellerger, Hans; Pferschy, Ulrich; and David Pisinger, David, Knapsack Problems,
Springer.
[Khuri 1994] Khuri, S.; T. Baeck, J. Heitkoeter, “The zero/one multiple knapsack problem and 
genetic algorithms,” The 1994 ACM Symposium on Applied Computing, SAC'94, Phoenix, Arizona.
[Kohli 1992] Kohli, Rajeev, Krishnamurti, Ramesh, A total-value greedy heuristic for the integer
knapsack problem, Operations Research Letters (12)2, pp. 65-71
[Kohli 1995] Kohli, Rajeev, Krishnamurti, Ramesh, Joint performance of greedy heuristic for the
integer knapsack problem, Discrete Applied Mathematics, 56, 37-48.
[Kodia 1998] Kodialam, M., Algorithms for separable nonlinear resource allocation problems, Operations
Research 46 : 272 1998.
[Korne 1989] Korner, F., A hybrid method for solving nonlinear knapsack-problems, European Journal of
Operational Research Society 38 (2): 238-241 jan 25 1989.
[Kultu 2003] Kulturel-Konak, S.; Smith, A.; Coit, D., Efficiently solving the redundancy allocation
problem using tabu search, IIE Transactions 35 (6): 515-526 JUN 2003
[Kuno 1999] Kuno, T., Solving a class of multiplicative programs with 0-1 knapsack constraints, Journal
of Optimization Theory and Applications 103 (1): 121-135 oct 1999.
[Kuo 2000] Kuo, W, ; Prasad, V., An annotated overview of system-reliability optimization, IEEE
Transactions on Reliability 49 (2): 176-187 jun 2000.
[Kuo 2003] Way Kuo and Ming J. Zuo, Optimal reliability modeling: principles and applications, John
Wiley & Sons, Inc., 2003.
[Liang 2004] Liang, Y., Smith, A., An ant colony optimization algorithm for the redundancy allocation
problem (RAP), IEEE Transactions on Reliability 53 (3): 417-423 SEP 2004.
[Li 2006] Li, Duan; Sun, Xiaoling., Nonlinear Integer Programming, 2006, Springer., U.S.A.
[Li 1996a] Li, J.; Jia, X., A bound heuristic algorithm for solving reliability redundancy optimization,
Microelectronics and Reliability 36 (3): 335-339 MAR 1996
[Li 1996b] Li, J., A bound dynamic programming for solving reliability redundancy optimization?
Microelectronics and Reliability 36 (10): 1515-1520 OCT 1996
[Li 1997] Li, J.; Jia, X., A new partial bound enumeration technique for solving reliability redundancy
optimization, Microelectronics and Reliability 37 (2): 237-242 FEB 1997.
[Li 2006] Li, Duan and Sung, Xiaoling, Nonlinear Integer Programming, Springer, U.S.A., 2006.
[Loulo 1979] Loulou, R. ; Michaelides, E., “New greedy-like heuristics for multi- dimensional
knapsack problem,” Operations Research, Vol.27-6, 1101-1114.
[Mathu 1983] Mathur K., Salkin H., Morito S., A branch and search algorithm for a class of nonlinear
knapsack-problems, Operations Research Letters 2 : 155 1983.
[Lin 1998] Lin, Y. H. Edward, “A bibliographical survey on some wel-known non-standard knapsack
problems,” Information Systems and Operations Research, Vol. 36, No. 4, pp. 274-317.
[Magaz 1984a] Magazine, M. J.; Chern, Maw-Sheng, A note on approximation schemes for
multidimensional knapsack problem, Mathematics of Operations Research, Vol. 9, 244-247.
[Marte 1981] Martello, Silvano; Paolo Toth, Heuristic algorithms for the multiple knapsack problems,
Computing, 27, 93-112.
[Marte 1990] Martelo, Silvano; Paolo Toth, “Knapsack Problems, Algorithms and Computer
Implementations,” JohnWiley & Sons, New York.
[Mathu 1986] Mathur, K., A note on a general nonlinear knapsack-problem, Operations Research Letters
5 : 79 1986
[Melma 2000] Melman, A.; Rabinowitz, G., An efficient method for a class of continuous nonlinear
knapsack problems, SIAM Review 42 (3): 440-448 sep 2000.
[Miche 1996] Michelon, P., Lagrangean methods for the 0-1 quadratic knapsack problem, European
Journal of Operational Research 92 : 326 1996
[Melma 2000] Melman, A.; Rabinowitz, G., An efficient method for a class of continuous nonlinear
knapsack problems, SIAM Review 42 (3): 440-448 sep 2000.
[Misra 1991a] Misra, K., Search procedure to solve integer programming-problems arising in
reliability-design of a system, International Journal of Systems Science 22 (11): 2153-2169 NOV 1991.
