 I
摘要 
在語者辨認中，能有效地訓練語者模型是非常重要的，因為這
對最後的辨識效果是有極大影響性。時至今日，傳統的語者模型仍都
是以最大相似度為訓練模型的準則，這在擁有大量訓練語料之下確實
能達到很好的效果，然而在少量訓練語料下卻不盡理想。最大相似度
估計的方法是採用同一位語者的所有訓練語料來訓練出此語者之模
型，與其它競爭語者的訓練語料之間並無關聯，如此訓練方式雖然可
以找到近似該語者特性的模型參數，但卻沒有考慮到辨認時語者模型
間彼此相互影響的關係，因此在辨識上比較會有模型混淆的結果。因
此近幾年來有所謂的鑑別式聲學模型訓練方法被提出來，其方法並不
以最大化訓練聲學語料的相似度為目標，而是以最小化分類(或辨識)
錯誤為目標。  
在本計畫中，我們使用最小錯誤鑑別式法則重新去訓練語者模
型，並提出了三個改善傳統最小錯誤鑑別式法則的方法。此外，還把
最小錯誤鑑別式運用在特徵語音調適法上，因為最小錯誤鑑別式方法
受劣質近似模型的影響比最大相似度方法來得小。於是我們提出一個
結合最小錯誤鑑別式和特徵語音調適法的改善，增加在極少訓練語料
時的強健性，以及降低建構聲學空間時造成劣質近似模型的影響性。 
 
 III
目錄 
摘要................................................................................................................Ⅰ 
目錄................................................................................................................ Ⅲ 
附圖目錄 ....................................................................................................... Ⅵ 
附表目錄 ......................................................................................................Ⅶ 
第一章 緒論 ................................................................................................... 1 
1.1 研究動機 ..........................................................................................1 
1.2 語者辨識概述 ..................................................................................2 
1.3 語者調適技術概述 ..........................................................................4 
1.4 研究方向 ..........................................................................................5 
1.5 章節概要 ..........................................................................................7 
第二章 語者識別之基本技術 ..................................................................... 8 
2.1 特徵參數擷取 ..................................................................................8 
2.2 語者模型建立 ............................................................................... 12 
     2.2.1 高斯混合模型..................................................................... 13  
     2.2.2 語者模型訓練流程............................................................. 14 
     2.2.3 向量量化............................................................................. 16  
     2.2.4 EM 演算法 .......................................................................... 19  
 V
5.1 結論 ............................................................................................... 50 
5.2 未來展望 ....................................................................................... 51 
參考文獻 ....................................................................................................... 52 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 VII
附表目錄 
表 4.1  改善的 MCE 在不同門檻值下的情況 ....................................... 44 
表 4.2  改善的 MCE 在不同語料下的情況 ........................................... 46 
表 4.3  改善的 MCE 與傳統的 MCE 比較的結果 ................................ 48 
表 4.4  ML/Eigenvoices 與改善的 MCE/Eigenvoices 比較的結果..... 49 
 
 
 2
需要安全性的門禁系統、銀行電話轉帳服務以及最近新起的線上交
易服務，用途可說是相當多元化。 
 
1.2 語者辨識概述 
語者辨識的目的是藉由分析聲音波形中蘊藏的語者資訊，找出
最接近此聲紋特性的語者，進而判斷出該發聲者的身分。在語者辨
識之前，使用者必須提供適當的聲音語料，來訓練好語者的模型，
以便在辨識時將欲辨識的語音與已註冊語者的語音模型做比對，利
用它們的相似度來做最後的辨識。 
典型的語者辨識可分為兩大類：語者識別(Speaker Identification)
和語者確認(Speaker Verification)。語者識別是指使用者錄製一段語
音，系統會在所有註冊語者中找出一個聲音特性最相近的語者；而
語者確認則是使用者輸入一段語音與他所宣稱的身份，然候系統會
判別此使用者是否即為其宣稱之語者身分，故語者確認是一種接受
或拒絕的處裡程序。如圖 1.1 中的語者辨識系統之基本架構所示，
由輸入的語音訊號求取特徵參數，再經由訓練產生的語者模型進行
語者識別或確認。 
 
 
 4
說話內容，因為此模式下的語者模型是代表語者的聲紋特性，並未
含文字意義上的特性。文字特定雖然表現較佳，但最大缺憾是可能
被仿製的錄音所矇騙；而文字不特定的辨識率雖然比較低，但卻是
較人性化。在本計畫主要是針對文字不特定模式，建立一套中文連
續語音的語者辨識系統，使得語者辨識能廣泛的應用於生活中。 
 
1.3 語者調適技術概述 
語者調適是為了讓使用者能夠以少量的語料，針對語者不特定
(Speaker Independent, SI)模型來做調適，以獲得語者特定(Speaker 
Dependent, SD)模型，如圖 1.2 所示。 
 
 
 
 
 
系統調適的過程可分為遞增調適法(Incremental adaptation)和批
次調適法(Batch adaptation)，遞增調適法是指每收集到一句調適語料
就調適一次；而批次調適法則是將該語者所有欲調適的語料收集起
來後才進行調適。此外，調適語者的說話內容可分為兩類: 監督式
圖 1.2 語者調適系統之基本架構 
取得
分最
高者 識別 
結果 
調適
語料 
語者調適 
SI 
model 
SD 
model 語者辨識 
測試
語料
 6
素(phoneme)，每一個音素再用一個 HMM 來描述。 
z 高斯混合模型(Gaussian Mixture Model, GMM)[12]：GMM 是
HMM 的簡化，做法是把該語者的聲學特性作分群，然後每一群
聲學特性用一個高斯密度分佈描述。 
z 類神經網路(Neural Networks, NN)：NN 是求得一個鑑別函式使
得所有語者可以區分的最好，缺點是每一個語者加入時，鑑別
函式必須重新計算。 
對於文字不特定模式的語者辨識系統而言，大多使用高斯混合模
型，本計畫也以高斯混合模型為基礎來建立系統，但由於此模型需
要大量訓練語料且訓練時間較久，因此往後的研究都會改以結合語
者調適技術與高斯混合模型的方式來產生語者模型，以便加快模型
訓練的速度及降低訓練語料量的需求。 
 
 
 
 
 
 
 
 8
第二章   語者識別之基本技術 
 
每個人所發出的聲音都有其特質，因此我們可以找出語者之間
的差異性，用它來建立專屬於此語者的模型，以建行語者辨識的工
作。在第一章有提到，語者辨識分為訓練和辨認兩部分:訓練部份主
要為擷取註冊語者的特徵參數，並建立每位語者的聲紋模型；而辨
認部份則是將測試者之特徵參數和已註冊語者模型進行比對。本章
中將介紹中文連續語音信號的信號前處理過程、特徵參數擷取方
法、語者模型架構簡述與建立過程、語者識別以及調適技術。 
 
2.1 特徵參數擷取(Feature Extraction) 
語音訊號是一種龐大的資料型態，不可能將原始語音的樣本全
部儲存下來做處理，因此必須針對語音的特性求取適當的特徵參
數，才能進行後續的訊號處理。藉著觀察語音訊號我們發現，在時
域上，語音訊號的變化是非常快速地，但若轉由頻域觀察其頻譜
(spectrum)則不會隨時間而有急遽的變化，有著短時間穩定(short 
time stationary)的特質，此特質將有助於分析語音訊號。因此我們將
輸入的語音訊號分割成一小段一小段的序列，每一個小段稱為一個
連音框(frame)，並且音框與音框之間可以有部份的重疊，再對每一
 10
+6dB/oct 斜率之高頻率提昇特性。所以我們首先利用短時間穩定的
特性將原始語音訊號切割成都多個獨立音框，再將音框內的語音訊
號通過一階高通濾波器做預強調(Pre-emphasis)處理，用以補償訊號
在接收時高頻能量上的損失，猶如以下的高頻濾波器： 
1( ) ( ) ( ) (1 0.95 ) ( )Y z H z X z z X z−= = −              (2.1)  
      1( ) 1 a ,  for  a=0.9~1H z z−= −  
而以時域觀點而言，原取樣值 [ ]x n 通過高頻濾波後變成 [ ]y n  
      [0] [0]y x=  
  [ ] [ ] [ ]0.95 ,1y n x n x n n L= − ≤ ≤                 (2.2)  
其中 L 為每個音框所含之取樣點數。此外，為了讓各個音框在頻譜
上的能量更集中，每個音框內的取樣值再乘上一個漢明視窗
(hamming window)，其方程式為： 
     [ ] [ ] [ ]s n y n h n= ×  
2[ ] 0.54 0.46cos
1
ny n
n
π⎧ ⎫⎛ ⎞⎨ ⎬⎜ ⎟⎝ ⎠⎩ ⎭= × − −                 (2.3)  
然而，特徵參數的求取是以音框為單位，且每個音框皆可求出一組
特徵向量，但在求倒頻譜特徵參數前須先求得另一組線性預估係
數，而線性預估原理是假設目前的取樣點可以由先前 P 個取樣點以
 12
1 1
c a=                                       (2.8)  
[ ] [ ] 1
1
   ,1
n
k
k
n
c n a n c k a n k n p
−
=
⎛ ⎞ ⎡ ⎤ ⎡ ⎤⎜ ⎟ ⎣ ⎦ ⎣ ⎦⎝ ⎠= + − ≤ ≤∑          (2.9)  
1
   ,[ ] (1 )
P
m n m
k
kc n a c n p
n −=
= − ≥∑                  (2.10)  
其中 n 為線性預估係數的階數，p 為倒頻譜係數的維度。再者可由
倒 頻 譜 係 數 進 一 步 求 得 轉 移 倒 頻 譜 係 數 (delta-ceptral 
coefficients) ncΔ ： 
  
2
( )( )
( )
K
n
n k K
Kn
k K
k c t kc t
c t
t k
=−
=−
⋅ +∂Δ = =∂
∑
∑
              (2.11)  
 
2.2 語者模型建立 
高斯混合模型(Gauusian Mixture Model, GMM)已經成為不特定
文字語者辨識系統中最主要的建模方法，更由於訓練語料量有其限
制以至不易建立隱藏式馬可夫模型(Hidden Markov Model, HMM)為
架構的音節模型來當作語者模型，於是高斯模型將是更適合用來建
立語者模型的選擇，因此本計畫亦以此訓練速度較快、訓練程序較
簡單的高斯混合模型來建立每位語者模型。 
 
 
 
 14
2.2.2 語者模型訓練流程 
在建構語者模型過程中，我們須找出每一個語者其高斯混合模
型的平均值向量、共變異矩陣與混合權值參數的初始值，故我們先
利用向量量化(Vector Quantization, VQ)的方法對訓練語料求得所需
之初始值，而向量量化使用二值分裂法(LINE-BUZO-GRAY, LBG)
演算法將所有語音樣本分為若干個類別，並以向量量化所得之代表
點作為初始值，爾後再藉由期望值最大化(Expectation Maximization, 
EM)[15]演算法去重新估測模型參數之平均值向量及共變異矩陣，並
使得高斯混合模型的參數達到收斂。語者模型訓練之流程圖如圖
2.2： 
 
 
 
 
 
 
 
 
 
 16
2.2.3 向量量化 
在訊號壓縮中，VQ 是一項廣泛應用的技術，它可以將一堆看
似雜亂無章的隨機向量集中成幾個具代表性的點或碼字 (code 
words)，以便記錄樣本點在向量空間中的位置。利用 VQ 可以將大
量的語音樣本作分類，但是卻無法將樣本在向量空間的分佈形狀及
大小描述出來。因此若能將向量量化與高斯機率分佈作結合，則不
但可以記錄大量樣本中各種類別在向量空間中的位置，也能描述這
些類別在向量空間中的形狀及大小。在本計畫中，我們將利用向量
量化中的 LBG 演算法來求取高斯混合模型參數的初始值，其演算法
的步驟及流程如下： 
圖 2.3 為 LBG 訓練流程圖 
<Step 1>求出整體特徵向量的平均值，當作起始值。 
1
1 T
t
t
x
T
μ
=
= ∑ G                              (2.15)  
<Step 2>將每一個平均值分裂成兩個，ε 為分裂係數，在此採用 0.01。 
 
(1 )
(1 )
m m
m m
μ μ ε
μ μ ε
+
−
= −
= +
G G
G G                      (2.16)  
<Step 3>利用 k-mean 演算，將所有特徵向量依步驟 2 所分裂出的平
均值
m
μG 重新分類。 
<Step 4>更新平均值
m
μG ，依步驟 3 分類的結果計算出每個群集新的
 18
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖 2.3 二值分裂法訓練流程圖 
訓練語句特徵向量 
},...,,{ 21 NxxxX
GGG=  
m=1 
m=2*m 
是 否 
m<M 結束 
否 是 
(D-D’)/D<δ 
求整體平均值 
分裂每個群集的
平均值 
特徵向量分類 
求各群集的平均
值
計算D 
DISTORTION 
D’=D 
 20
的參數值達到最佳化為止。 
Mixture Weights： 
1
1 ( | , )
T
ti t
p p i x
T
λ
=
= ∑ G                       (2.19)  
Means： 
1
1
( | , )
( | , )
T
t t
t
Ti
t
t
p i x x
p i x
λ
μ
λ
=
=
= ∑
∑
G G
G                          (2.20)  
Variances： 
2
21
1
( | , )
( | , )
T
t t
t
Ti i
t
t
p i x x
p i x
λ
μ
λ
=
=
∑ = −∑
∑
G G
G                 (2.21)  
其中 
1
( )
( | , )
( )
i i t
Mt
tk k
k
p b x
p i x
p b x
λ
=
=
∑
GG
G                      (2.22)  
 
 
 
 
 
 
 
 22
通常在調適模型參數時，調整平均值參數是最有效的方式，至
於調整模型參數中的變異數參數或權重參數並沒有太大的影響，所以
變異數 2σ 及權重參數直接以UBM的參數代替。假設平均值μ為一隨
機變數，其事前機率分佈亦假設為高斯分佈 2( , )N ρ τ ，則從n個調適
語料對μ的最大事後機率估測值為： 
   
2 2
2 2 2 2
ˆ
MAP
n o
n n
τ σμ ρσ τ σ τ= ++ +               (2.23)  
其中o表示n個調適語料的平均值。 
在實際應用中，上式的 ρ 可以用訓練良好的通用背景模型來代
替，而 2τ 不一定要求出，將式子(2.25)右側的分子、分母同除以 2τ ，
可推得： 
   ˆ
MAP SI
n ro
r n r n
μ μ= ++ +                   (2.24)  
其中， r 相當於
2
2
σ
τ ，為一項可調的參數，並沒有實際去估計。而由
上式可以看出，貝氏調適法的精神是將通用背景模型與調適語料的統
計特性作加權平均：當調適語料不足時，能充分使用通用背景模型豐
富的語音特性來補助；當調適語料充足時，亦能有效地利用到調適語
料，達到良好輔助的調適效果。 
如同EM演算法，調適高斯混合模型其模型參數也是經過兩個步
驟的估測過程而得。第一個步驟和EM演算法中「預估參數」的步驟
 24
   
1
Pr( | )
T
ti t
n i x
=
=∑                          (2.26)  
   
1
1( ) Pr( | )
T
t ti ti
E x i x x
n =
= ∑                    (2.27)  
   2 2
1
1( ) Pr( | )
T
t ti ti
E x i x x
n =
= ∑                   (2.28)  
這三項參數即是前面所提到的充分統計量－機率計數值、一次矩和二
次矩。最後，將這些調適語料的充分統計量透過下列的算式來更新原
來通用背景模型每個高斯分佈的參數值，成為調適後語者模型的參數
值： 
   ˆ [ / (1 ) ]w w
i i i i i
w n T wα α γ= + −                   (2.29)  
   ˆ ( ) (1 )m m
i i i i i
u E xα α μ= + −                     (2.30)  
  2 2 2 2 2ˆ ( ) (1 )( )v v
i i i i i i i
E x uσ α α σ μ= + − + − G           (2.31)  
前面介紹貝氏調適法時曾經提過，在調適高斯混合模型參數時，
調整模型參數中的平均值參數通常是最有效的方式，因此在本計畫中
也只調適每個高斯分佈的平均值向量，亦即在做調適時只計算(2.30)
式，其他參數如變異數和權重參數則以UBM的參數值替代。而式子
(2.30)所描述的平均值參數更新方程式其實是由一般MAP的估測公式
推導而來，但在推導的過程中多加了事前機率分佈的限制。 
對於每個高斯分佈的平均值參數，語料相關的調適係數 m
i
α 定義
如下式所示： 
 26
    首先我們將藉由R個利用充足語料訓練好的語者特定模型來開
始，從語者模型中取出其各個高斯分佈的平均值做為參數，此平均值
向量之維度為n，然後將這些參數串接成一個超大D 維度的向量，稱
之為supervector，因此R個語者模型就會產生R個supervector。在這邊
我們使用貝式調適法來訓練模型，而不用傳統的ML/GMM來訓練模
型，這是因為在特徵語音調適法中，雖然supervector的向量是可以任
意排列，但必須向量間的維度要保持一致性，也就是說相同的維度必
須對應至同一高斯分佈及同一維度。在向量的排列上我們可以控制其
對齊方式，如圖2.4所示。但在語者模型本身的參數特性分佈卻無法
掌握，因此我們利用貝式調適法來限制語者模型中高斯混合的特性，
藉由參考同一個背景模型調適出的模型參數會有相同的分佈情形，這
樣就可以真正達到supervector中參數維度對應的要求。 
 
 
 
 
 
 
 
 28
若以調適語者模型的高斯分佈來看，其調適後的平均值向量為： 
(2.34)  
    由以上看來，特徵空間其實就是一個萃取出眾人聲學參數精華後
所組成之可信賴的聲學空間，所以在空間中的任一點即象徵著一位語
者所表現出的語音特性。當給定調適語料後，我們唯一要做的就是在
空間中找尋調適語者最可能的所在位置，而從式子 (2.34)可看到我們
所需就是求出其線性組合的係數，因此我們利用最大相似度特徵分解
(Maximum Likelihood Eigen Decomposition, MLED)來估算出此係數。 
 
(2.35)  
 
 
其中 ( ) ( )sm tγ 表示在時間 t 的音框位於第 s 個狀態中第m個高斯分佈的
發生機率值； ( ) ( )sme j 代表第 j 個基底向量中，對應於第 s個狀態中第m
個高斯分佈的區段； 1mC− 為第 s 個狀態中第m個高斯分佈的共變異矩
陣之反矩陣； tO 為時間 t 的觀測值； ( )w k 即所估測的一組座標係數
中，對應於第k 個基底向量的係數值。從 (2.35)式可知K個係數便會有
K條等式，因而組成一個K元一次方程式，而這組方程式的解就是估
算調適語者所對應的線性組合係數，於是最後我們將MLED所求得的
( ) ( ) ( ) 1
( ) ( ) ( ) 1 ( )
1
j=1 K
( ) ( )
( ) ( ) ( ) ( )
                                                                        
Ts s s
m m m t
s m t
K Ts s s s
m m m m
s m t k
t e j C O
t w k e k C e j
γ
γ
−
−
=
⎡ ⎤⎣ ⎦
⎧ ⎫⎡ ⎤ ⎡ ⎤= ⎨ ⎬⎣ ⎦ ⎣ ⎦⎩ ⎭
×
∑∑∑
∑∑∑ ∑
"
( ) ( )
1
( ) ( )
Ks s
m m
j
w j e jμ
=
= ∑
 30
2.4 語者識別 
在聲學特性上，因為每位語者所發出語音皆不相同，所以在文
字不特定語者識別系統中，每一個訓練出來的語者模型都包含自己
本身的語音特徵，而語者識別即是將測試者的語句與一群固有的語
者模型作比對，並根據 Likelihood Function ( | )
k
p X λ 從中挑選出最相
似的語者模型，其數學模型描述如下： 
對於一群語者 {1,2, , }s S= … ，我們以高斯混合模型
1 2
, ,...,
S
λ λ λ 來
代表。針對一段測試語句
1 2
{ , , , }
t
X x x x= G G G" ，嘗試在這一群語者模型
中找到一個事後機率值最大的模型： 
1 k S
sˆ arg max ( | )
k
p Xλ
≤ ≤
=
                
(2.36)  
其中 sˆ 表示所識別出之語者，而上式即所謂之最大事後機率法則
(Maximum a Posteriori Criterion)。然而再根據貝式定理，上式則可
以改寫為： 
1
( | ) ( )
sˆ arg max
( )
k k
k S
p X p
p X
λ λ
≤ ≤
=            (2.37)  
若假設每一個語者模型出現的機率相同 ( ) 1
k
p λ = ，則上式可再簡化
成下式： 
{ }S arg max ( | )kk p X λ=                   (2.38)  
 
 32
第三章   最小錯誤鑑別式 
 
本章將介紹最小錯誤鑑別式 (Minimum Classification Error, 
MCE)的訓練方法，並且利用綜合機率減少演算法 (Generalized 
Probabilistic Descent, GPD)[17]去更新語者模型的參數。 
在前人所提出的(Maximium Model Distance, MMD)[18]中，只
選擇了一位去當做競爭語者，這樣會導致系統收斂速度慢並且會更
容易落在區域解而不是最佳解，所以我們提出了三個改善傳統 MCE
的方法。 
1. 增加了一個門檻值去做競爭語者的篩選，依據跟正確語者相近
的程度來挑選競爭語者，這樣聽起來比較合理而且會使得在計
算新的語者模型時，不會把不必要的資訊給加進去，也不會遺
失重要的資訊。 
2. 在所有的鑑別式訓練法則中都比 ML 要來的花費計算量，有鑑
於此，我們提出一個更有效率的鑑別函式，這會大幅加快整個
語者系統的訓練速度。 
3. 在傳統的MCE中，語者模型參數調整量的權重ε 是一個定值，這
表示離正確語者比較近的競爭語者模型和比較遠的競爭語者模
型，它們的模型參數調整量是一樣的!這會讓已經落在正確的聲
 34
錯誤鑑別準則(Misclassification measure) 
( ; ) ( ; ) ( ; )k k kd X g X G Xλ λ λ= − +        (3.3) 
( ; ) ( ; )k n nG X W g Xλ λ= ⋅∑         (3.4) 
( ; )
( ; )
n s
n
s
n
g XW
g X
λ
λ
=
∑
          (3.5) 
由式子(3.3)我們可以得知一個正確的語者分數 ( ; )kg X λ 與其它競爭語
者分數 ( ; )kG X λ 之間的差距關係。而權重 nW 定義為競爭語者分數的正
規化。 
1
1 exp( )
( )
kd
l dk γ θ= + − +            (3.6) 
'( ) ( ) (1 ( ))k k kd d dγ= ⋅ ⋅ −A A A  
再來我們定義一個 Loss Function ( )l dk 去描述正確語者模型與其
它競爭語者模型的關係，再對模型參數調整使得 ( )l dk 最小化，這樣
可以得到較好的語者模型。我們通常令θ =0，γ ≥1。 
 
 
 
      
          
 
 
 36
經由推導可得調整語者參數模型( smdμ 、 smdσ 、 smp )的公式 
1. smdμ  
( ; )( 1) ( )s s smd md s
md
l Xn n λμ μ ε μ
∂+ = − ∂            (3.9) 
( ; )s s s
s s
md s md
l X l d
d
λ
μ μ
∂ ∂ ∂=∂ ∂ ∂   
( ) (1 ( ))s s s
s
l d d
d
γ∂ = ⋅ ⋅ −∂ A A  
( ) ( )                                         ; 
( )
( ) ( )                                       ; 
( )
s s s
m m t t md
s s
t mds
s s s s
md m m t t md
s s s
t md
p b x x u s k
B xd
p b x x uW s k
B x
σ
μ
σ
⎧ −− =⎪∂ ⎪= ⎨∂ −⎪ ≠⎪⎩
  
2. smdσ  
( ; )( 1) ( )s s smd md s
md
l Xn n λσ σ ε σ
∂+ = − ∂           (3.10) 
( ; )s s s
s s
md s md
l X l d
d
λ
σ σ
∂ ∂ ∂=∂ ∂ ∂   
( ) (1 ( ))s s s
s
l d d
d
γ∂ = ⋅ ⋅ −∂ A A  
2
2
( ) ( ) 1                                         ; 
( )
( ) ( ) 1                                        ; 
( )
s s s
m m t md
s s
t m
s
s
s s smd
m m t md
s s s
t m
p b x x t u s k
B xd
p b x x t uW s k
B x
σ
σ
σ
⎧ ⎡ ⎤⎛ ⎞−⎪ ⎢ ⎥− − =⎜ ⎟⎪ ⎢ ⎥⎝ ⎠∂ ⎣ ⎦⎪= ⎨∂ ⎡ ⎤⎪ ⎛ ⎞−⎢ ⎥− ≠⎪ ⎜ ⎟⎢ ⎥⎝ ⎠⎣ ⎦⎩

⎪
 
3. smp  
( ; )( 1) ( )s s sm m s
m
l Xp n p n
p
λε ∂+ = − ∂           (3.11) 
( ; )s s s
s s
m s m
l X l d
p d p
λ∂ ∂ ∂=∂ ∂ ∂   
( ) (1 ( ))s s s
s
l d d
d
γ∂ = ⋅ ⋅ −∂ A A  
 38
 
圖 3.1  MCE 之訓練流程圖 
 
 
 
 
 
 
 
 
調適語料 
語者辨識 
其它競爭語者 正確語者 
模型重估 
最小錯誤鑑別式 
GMM 
 40
第四章  實驗結果 
本章內容主要是將之前幾個章節所介紹的理論、方法，討論在
不同情況下，進行語者辨認的一些實驗並加以分析討論。 
 
4.1  實驗環境 
本系統的執行環境是在個人電腦上，CPU 為 AMD 2GHz，記憶體
512MB；語音輸入介面為 Microphone，取樣頻率為 8KHz，資料型態
為 16-bit PCM 格式。 
語音資料採不定音框數切割，音框大小為 30ms（取樣點數為 240
點），音框間重疊 20ms，每個音框的特徵參數共有 28 維：14 維度的
LPC Cepstral Coefficients﹔14 維度的 Delta LPC Cepstral 
Coefficients。 
本計畫所使用的語料是來自於「中華民國計算語言學會」所提
供的《MAT-2000 台灣國語語音資料庫》。此資料庫為透過電話網路
經由電腦錄製，語句內容為中央研究院所設計。與「台灣大學、成
功大學、交通大學」這三個學校分別提供一百人，總共三百人的
《TCC-300 台灣國語語音資料庫》。  
 
 42
4.2 MCE 實驗 
在此章實驗中，系統語者辨識率的計算方法為 
正確識別語者身分的句數語者辨識率(%)= ×100測試語料的總句數
增加的語者辨識率增益語者辨識率(%)= ×100100%-原本語者辨識率
 
 
4.2.1 模型的遞迴次數之實驗 
  本計畫使用 MCE 去一次又一次的遞迴語者模型，以便建立出
最佳化的語者模型，因為在辨識之前不知道必須選取哪一次遞迴的
語者模型較好，故本實驗的目的為測試出要選擇哪個遞迴的語者模
型。以下的實驗皆使用 100 位語者，語者特定模型的高斯分佈個數
均設定為 64。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 44
語料，2 句測試語料。 
【實驗數據】 
門檻值 調適時間(分) baseline 改善的 MCE 
0.9 59 94.5% 
0.8 217 96% 
0.7 608 95.5% 
0.6 1023 
 
 
 
93% 
 
95% 
表 4.1 改善的 MCE 在不同門檻值下的情況 
【結果討論】 
由表 4.1 可以看出，門檻值愈低時，其調適時間大幅增加，但
辨識率卻沒有相對的增加。因為把那些已經跟正確語者距離很遠的
競爭語者模型再度的調適，會使競爭語者模型偏離自已所屬於的聲
學空間位置，故我們選取效率最好的門檻值 0.8 來當做之後實驗的
數值。 
 
 
 
 
 
 46
4.2.4 語料長度對 MCE 之影響 
本實驗主要是利用訓練與測試語料句數的多寡，亦即當 baseline 
模型訓練的好或壞時，改善的 MCE 所能提升多少幅度的辨識率。
當想要在低辨識率的 baseline 有所提升時並不難，但如果想要在高
辨率的 baseline 再度提升的話，這就是現今語音語者學家和本計畫
所研究的重點。所以我們使用了增益辨識率這個算法，特別能看出
在高辨率 baseline 時候所提升的幅度。 
【實驗數據】 
語料庫與 
語者人數 
訓練/測試 
語料句數 
baseline 改善的 
MCE 
增益辨識率
2/1 57% 77% 46.51% 
5/2 93% 96% 42.29% 
 
MAT2000 
100 人 
7/3 97.33% 98% 25.09% 
TCC300 
300 人 
 
10/2 
 
94.5% 
 
95.5% 
 
18.18% 
表 4.2 改善的 MCE 在不同語料下的情況 
 
 
 
 
 48
【實驗數據】 
模型調適方
法 
競爭語者數
目 
調 適 時 間
(分) 
baseline 辨識率 
5 位 129 94.5% 
10 位 215 95% 
20 位 430 96% 
 
 
傳統的 
MCE 
40 位 721 95.5% 
門檻值 0.9 59 94.5% 
0.8 217 96% 
 
改善的 
MCE 
0.7 608 
 
 
 
93% 
95.5% 
表 4.3 改善的 MCE 與傳統的 MCE 比較的結果 
【結果討論】 
由表 4.3 得知當傳統的 MCE 與改善的 MCE 在相同辨識率時，
改善的 MCE 所使用的調適時間都比較少。在最高辨識率 96%時，傳
統的 MCE 所花費的時間為 430 分鐘，而改善的 MCE 所花費的時間
卻為 217 分鐘，至少省了一半多的時間。因為改善的 MCE 使用了
最有效率的鑑別函式，所以不會降低辨識率，還有使用門檻值去篩
選競爭語者數目，才不會在每次遞迴調整時競爭語者數目都固定。 
 50
第五章 結論與未來展望 
5.1 結論 
在本計畫中我們提出了新的語者模型調適架構，主要是為了建
立出一套有實用性和強健性的語音辨識系統，所使用的技術不以最
大相似度演算法為準則，而以最小錯誤分類演算法為準則。傳統的
MCE 方法雖然可以在少量語料訓練模型時大幅度的提升辨識率，但
相對的也耗費了更多訓練的時間，調適語料和競爭語者數目的選擇
更是難以決定!並且傳統的 MCE 在大量語料訓練下相對於用 GMM
來訓練模型，辨識率上升的幅度就有限。有鑑於此，在本計畫中提
出了三個改善傳統的 MCE 演算法。在實驗結果中，改善的 MCE 所
花費的訓練時間比傳統的 MCE 少的多，這表示在本計畫所提出的
方法應用於語者系統時，有更好的效果。 
 
 
 
 
 
 
 
 
 52
參考文獻 
[1] X. Huang, A. Acero and H. W. Hon, Spoken Language 
Processing, Prentice Hall, 2001. 
[2] L. R. Rabiner and B. H. Juang, Fundamentals of Speech 
Recognition, Prentice Hall, New Jersey, 1993. 
[3] G.R. Doddington: Speaker Recognition-Identifying People by 
Their Voices. Proceedings of IEEE, Vol. 73, No. 11, 1986, pp. 
1651-1644. 
[4] J. L. Gauvain and C. H. Lee, “Maximum a Posteriori 
Estimation for Multivariate Gaussian Mixture Observations 
of Markov Chains,”IEEE Trans. Speech and Audio 
Processing, vol. 2, no. 2, pp. 291-298,April 1994. 
[5] R. Kuhn, J. C. Junqua, P. Nguyen and N. Niedzielski, “Rapid 
Speaker Adaptation in Eigenvoice Space,” IEEE Trans. 
Speech and Audio Processing, vol. 8, no. 6, pp. 695-707, 
November 2000. 
[6] B.H Juang, W. Hou, C.H Lee, “Minimum classification error 
rate methods for speech recognition:’ IEEE Trans. on Speech 
and Audio Processing. vol. 5, pp. 257-265, May 1997. 
[7] O. Siohan, A. E. Rosenberg, and S. Parthasarathy, “Speaker 
identification using minimum classification error training,” 
ICASSP-98, vol.1, pp.109–112, May 1998. 
[8] J. McDonough, T. Schaaf, A. Waibel, “On maximum mutual 
information speaker-adapted training” Acoustics, Speech, and 
Signal Processing, 2002. Proceedings. (ICASSP '02). IEEE 
 54
[16] D. Reynolds and T. Quatieri, Speaker Verification Using 
Adapted Gaussian Mixture Models, in Digital Signal 
Processing A Review Journal, vol. 10, no. 1-3, pages19-41, 
Academic Press, 2000. 
[17] W. Chou, C.-H. Lee and B.-H. Juang, “Segmental GPD 
training of an hidden Markov model based speech 
recognizer,” Proc. ICASSP-92, pp. 473–476. 
[18] Q.Y  Hong,  S. Kwong , “Discriminative training for 
speaker identification based on maximum model distance 
algorithm”, Acoustics, Speech, and Signal Processing, 2004. 
Proceedings. (ICASSP '04). IEEE International Conference 
on Volume 1,  17-21 May 2004 Page(s):I - 25-8 vol.1 
[19] F. Valente, C. Wellekens, “Minimum classification 
error/eigenvoices training for speaker identification” 
Acoustics, Speech, and Signal Processing, 2003. Proceedings. 
(ICASSP '03). 2003 IEEE International Conference on 
Volume 2,  6-10 April 2003 Page(s):II - 213-16 vol.2 
[20] Y. Kida, H. Yamamoto, C. Miyajima, K. Tokuda, T 
Kitamura, , “Minimum Classification Error Interactive 
Training for Speaker Identification”, Acoustics, Speech, and 
Signal Processing, 2005. Proceedings. (ICASSP '05). IEEE 
International Conference on Volume 1,  March 18-23, 2005 
Page(s):641 – 644 
[21] 賴彥輔， “語者辨識之研究＂ ，國立中央大學電機工程
研究所碩士論文，民國九十二年。 
