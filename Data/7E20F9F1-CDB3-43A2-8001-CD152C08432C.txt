I摘要
在一般遠端遙控機器人系統的各種感測器資訊裡，視覺回饋是使用者操控時藉以產生空
間臨場感最為直覺的工具。而為了提升使用者控制遠端機器人的效率，各種採用特殊廣
角度鏡頭視覺感測器的機器人視覺系統紛紛被設計出來，以盡可能地取得大量的視覺資
訊。然而這些經由特殊廣角度鏡頭設計的視覺感測器卻會引起影像嚴重的畸變
（distortion），必須採用影像演算法進一步校正畫面後，使用者才得以正常辨認畫面內
容。
本計劃針對遠端遙控機器人的視覺回饋，設計並建構出一套具有廣視野畫面臨場感的系
統。採用三台一般市售網路攝影機（webcam）與兩片反射平面鏡設計組合而成的光學系統，
可達到非同步拍攝具相同視點（point-of-view）但不同視野（field-of-view）的多重畫面；再
交由利用 DirectShow 設計之影像處理 PanMultiCamFilter 整併多視野畫面。本廣視野視覺感測
器搭配可程式化控制馬達，可提供更有彈性之水平視野拍攝範圍，且透過一般網路將廣視野
影像回饋傳送至遠端使用者介面。完成一高臨場感且具低畸變畫面特性之廣視野視覺感測器。
Abstract
Among all sensory data of a remote controlled robot system, visual feedback provides the most
straightforward information on constructing spatial presence for users. For the efficiency of
controlling remote robots, many visual feedback systems with special wide-angle lenses on
cameras were designed to capture massive images. However, these special wide-angle lenses
will cause image distortion heavily. Image must be corrected by image processing algorithms
before it could be recognized by users.
This project focuses on establishing a visual feedback system which provides wide FOV
(field-of-view) presence in remote controlled robots. A new optical system combined with three
webcams and two flat mirrors could asynchronously capture multiple images with different FOV
from the same POV (position-of-view). These images were then merged and transformed by the
PanMultiCamFilter, developed from the DirectShow. By joining a bearing mechanism with a
programmable motor controller, the wide FOV visual feedback system could provide more flexible
horizontal FOV. Those images captured by the system were transferred to remote user interface (UI)
through networks. At the end, a wide FOV visual feedback system was created with high presence
and low image distortion for remote controlled robots.
中文關鍵詞: 行動機器人、遠端遙控、影像串流、人機介面、廣視野
Keyword: mobile robot, teleoperation, video stream, human computer interface, wide FOV
2介面的範疇[6]；而本研究系統著重在應用於遠端遙控機器人之視覺感測系統。
1.4 研究方法
1.4.1. 硬體
發展目標在於整合遠端遙控機器人系統中之必要模組，且針對視訊回饋的部份特別設
計並架設客製化硬體。
1.4.1.1. 已建置內容
機器人硬體部份採用的是 Activemedia Pioneer 3 mobile robot 為實驗平台，並於 Pioneer
3 上配置由三顆 Logitech QuickCam Pro 4000 網路攝影機組合而成的影像擷取攝影機
組，攝影機組與 Pioneer 3 之間的旋轉馬達支軸採用 Lego 挑戰計畫組的積木建構；馬
達旋轉訊號的傳遞使用 Lego Mindstorm RCX command center 控制器來下達指令。硬體
部分完成後如下圖一：
圖一 廣視野遙設系統安裝於行動機器人 P3-DX
1.4.1.2. 如何建置
Acrivemedia Pioneer 3 為既有之 mobile robot 實驗平台，故實驗硬體設計重點在於影像
擷取攝影機組的建置上。攝影機元件採用一般常見的市售網路攝影機進行組裝（型號：
Logitech QuickCam Pro 4000）。為求得在多部攝影機畫面中，無論視線朝向何方，畫面
中心原點均能保持不動；因此設計出利用鏡面反射原理之影像擷取攝影機組，如下圖
二。
4的模組。
1.4.2.1. 已建置內容
影像整合之核心部份，採用 Microsoft DirectShow 技術，完成一 transform filter –
“PanMultiCAM filter”。此 filter 支援：
1. 水平搖攝模擬－可以有段或無段式來模擬攝影機水平左右搖攝。
2. 多攝影機影像來源－可接兩台以上支援標準 WDM（Windows Driver Model）或 VFW
（Video for Windows）驅動格式之不同廠牌 USB 攝影機。
1.4.2.2. 如何建置
為了能確切掌握多攝影機之影像畫面接合以及減少影像處理的資料流程，我們排除由
Sun 公司開發的 JMF（Java Media Framework）技術，避免在 JVM（Java Virtual Machine）
平台上執行效能不彰的影響。
DirectX 是 Microsoft 在 Windows 平台上提供發展高性能圖形、聲音、輸入、輸出以及
網路遊戲的一套 API。透過 DirectX API 所提供的介面，開發人員可以盡情地使用硬體
可能帶來的高性能，而無需關心硬體的實際執行細節。此外，DirectX 採用了 COM
（Component Object Model）標準，使得開發 DirectX 的程式就如同開發軟體 IC 般具
有動態替換程式模組元件的能力，同時用戶端程式與 COM 元件之間的溝通也能遵循
共同的合作標準。
本系統核心部份主要採用 Microsoft 的 DirectShow 技術，DirectShow 為 DirectX 下專為
Windows 平台上專為處理各種格式的媒體文件播放、影音視訊擷取等高性能要求的多
媒體應用成員。DirectShow 使用 Filter Graph 的模型來管理整個媒體資料數據的處理過
程，參與媒體數據處理的各個功能模組叫做 filter，而各個 filter 在 Filter Graph 中按一
定的順序串連起來成為一條處理媒體資料的 ”流水線”。
一般 filter分成三大類：Source Filters、Transform Filters和Rendering Filters。Source Filters
主要負責獲取媒體樣本數據，媒體來源可以是本地或是 Internet 上的文件、視訊擷取卡
或是網路攝影機（遵循 WDM 或 VFW 驅動格式的硬體），然後將媒體樣本數據往下傳
輸。Transform Filters 主要負責媒體樣本數據的格式轉換，像是影像與聲音頻道的分離
或是合成、解碼或是編碼等等，然後將媒體樣本數據繼續往下傳輸。Rendering Filters
主要負責媒體樣本數據的最後呈現，將數據送給顯示卡或是音效卡，進行多媒體的播
放或是輸出成檔案進行儲存。
6黑色，如圖四所示。整合後之影像與攝影機控制介面請見圖五。
圖四 平移畫面來源以便合成影像
圖五 控制者所看到的整合後影像與控制元件
81.4.2.3. 建置成果與難題
透過兩類子系統的開發與整併，我們建置了機器人系統中的核心視訊回饋模組。目前
實驗設計中僅連接三台網路攝影機，因此我們可透過 PanMultiCAM filter 得到由三台
攝影機擷取畫面組成的單一廣視野影像，其視角可達到 42*3=126 度的效果。另外，本
視訊回饋模組無需特殊硬體平台支援，可由一般市售、合於基本 WDM 或 VFW 驅動
格式之網路攝影機連接組合完成。
開發過程中，首先面臨到的問題就是 COM 軟體技術的掌握，以及 Microsoft DirectShow
的各類 filter 元件特性與媒體資料的流動技術。每個 filter 都是一個 COM 元件，每一
個媒體數據樣本也都是一個 COM 元件，元件與元件之間的溝通透過互相叫用彼此的
介面（interface）來完成。每個 COM 元件的生命週期，隨著自身介面被查詢使用時而
增加，也隨著外部查詢完畢的釋放介面而減少；當沒人參考到這 COM 元件時，該 COM
元件將自動自我銷毀。因此，想要正確的連接每個 filter（COM 元件），就必須精確的
掌握每個 Filter 提供的介面，是何時、何者、如何去查詢調用它的。由於相關技術資
料不易取得，因此這些經驗(know-how)的累積花了許多時間。
1.5 結果與討論
本研究成功地實作出一應用於遠端遙控機器人之廣視野影像攝影系統。比較不同的視覺
感測系統種類，會發現使用單攝影機雖然輕薄短小，但取得畫面資訊過少不易觀察；改
良使用廣角鏡頭與全向攝影機取得超寬廣視野卻又會引發必須修正的畸變問題。本研究
系統採用組合平面鏡與一般單鏡頭攝影機的結構克服曲透鏡光學設計上的畸變，並保有
同一 POV 下之廣視野臨場感。在軟體方面則開發出取得攝影機拍攝畫面後之影像處理程
序，從單台攝影機畫面的水平搖攝處理，支援多台攝影機之架構，到最後循序漸進突破
DirectShow 之 filter framework，設計出有效率且能與多攝影機搭配的影像處理核心－
PanMultiCamFilter。接著增加的使用者介面則將使用者任意觀察視野範圍的能力延伸到
遠端機器人上。最後考慮可視範圍的彈性，我們也將 Lego 控制系統與步進馬達加入本研
究之視覺感測系統中，使得搭載本廣視野影像回饋系統的遠端遙控機器人，在使用者可
操作機器人進入的空間內任意地探索。
後續的工作可分作以下數個方面考量：
 使用者介面與遠端視野臨場感對應模型之研究：考慮使用者操作系統時，其心智模
型與系統之視覺回饋如何相對應，是否能透過使用者介面的改良提升使用者操作系
統的效率。
 軟硬體元件之改善：本研究開發之視覺系統，在硬體設備上還有許多改進空間，輕
巧化是未來追求的目標之ㄧ，同時更換效率更高的裝置也能提昇操作時的流暢感。
 降低網路模組傳輸量：在不影響畫面更新率的條件之下，加入影像編碼 filter 降低傳
輸資料量；或使用雙緩衝區分別維護伺服端與客戶端之影像，根據遠端拍攝畫面的
更新速度來傳輸影像區塊。
遠端遙控機器人的視覺回饋系統還有很長遠的發展空間，無論是硬體的影像感測元件，
日本バーチャルリアリティ学会第11回大会論文集(2006年9月)
広視域ビデオ源によりテレイグジスタンスシステムに 
おけるビデオフィードバック遅延の改善法 
 
An Approach to Compensate Video Feedback Delay of Telepresence Systems by Utilizing
Wide Field of View Video Source
 
鄧惟中，施景元 
Wei-Chung Teng and Ching-Yuan Shih
 
台湾科技大学 資訊工程系(情報工学系) 
(〒106 #43,Sec.4,Keelung Rd., Taipei, Taiwan, weichung@mail.ntust.edu.tw) 
 
Abstract: One of the bottlenecks in telepresence systems is that only limited size of video feedback allowable
due to communication bandwidth restriction. A PTZ camera partially solves this problem by providing pan
and tilt freedom. However, the extra instructions on camera and bigger time delay jitter introduce more issues
to solve. In this paper, an approach utilizing wild FOV video source is developed to compensate time delay
from motion lag of PTZ camera and to aim on clearer image when the operators changes his/her view. A
mobile robot equipped with multiple cameras arranged in a circular fashion is used for demonstration.
Key Words: telepresence, video feedback, field of view. 
 
1.Introduction 
A prerequisite for telepresence systems, or 
telexistence systems, is that the teleoperator be 
directly and continuously controlled by human in 
real-time fashion. Since human operators may only know 
remote environment via sensory feedback from remote 
site, it’s obvious that system designer should make sure 
the operator receives real-time sensory feedback of 
remote environment as much as possible. It’s well known 
that video feedback is much important than other 
sensory feedback, yet ironically enough this video 
feedback usually suffers the highest time delay and 
with highly restricted field of view (FOV) due to 
communication bandwidth limit[1]. 
In the last decade, we observed many mobile vehicles 
equipped with only one camera which provides about 38 
to 42 degrees of FOV. These mobile vehicles are 
connected with wireless communication and some even 
don’t have a proprietary communication channel. As a 
result, any attempt to send more than one camera video 
feedback under this kind of configuration becomes 
impractical[2]. A PTZ camera may partially solve this 
problem by providing pan and tilt rotation freedom, by 
which the operator may rotate the camera to browse 
surrounding environment just like rotating his head. 
However, extra instructions on camera mean more jobs 
to the operator, and time delay jitter also grows during 
the rotating period due to camera’s motion lag. To 
compensate the hazard comes from rotate operation on 
camera, we propose an approach utilizing wild FOV video 
source. The idea is to let the robot equipped with 
superfluous cameras directing to non-overlapping 
angles of view, and only the part asked by human is 
transmitted. 
 
2.Design of a Wild FOV Video Source 
2.1Web Cameras with Mirrors 
There are many possible ways to fetch a wild FOV video 
source, but most of these methods required expensive 
devices. Here we present a simple and low cost design 
for a wilder video source. 
Our origin idea is to arrange all cameras in a 
circular fashion, each directing to non-overlapping 
angles of view, and there shouldn’t be gap between 
adjoining angles of view. As a result, the lens of all 
cameras must be placed in origin of a circle, which is 
practically impossible. Instead we arrange three 
cameras in the way showed in figure 1. The bold vertical 
lines stand for mirrors. Let α be the angle of view 
of camera,β be the included angle between mirror and 
the edge of center camera C0’s angle of view, γ be the 
shortest radius of circle that covers the whole mirrors, 
可供推廣之研發成果資料表
■ 可申請專利 ■ 可技術移轉 日期：96 年 9月 29 日
國科會補助計畫
計畫名稱：應用廣視野來源影像改進網路遙控自走機器人操作介面
之研究
計畫主持人：鄧惟中
計畫編號：NSC 94－2213－E－011－057 學門領域：資訊學門二
技術/創作名稱 廣視野影像攝影系統
發明人/創作人 施景元、鄧惟中
技術說明
中文：本技術硬體方面採用一般網路攝影機與反射平面鏡設計組合
而成，可達到非同步拍攝具相同投影中心但不同視野的多重畫面。
且依據反射定律，針對攝影機與反射鏡面的擺設方式進行設計，可
將攝影機擷取影像排列成一類似全景之畫面。完成一高臨場感且具
畫面低畸變特性之廣視野視覺感測器。
英文：This new visual system combined with webcams and flat mirrors
could asynchronously capture multiple images with different FOV
(field-of-view） from the same center of projection. And according to
law of reflection, captured images could be aligned into a panoramic
image. At the end, a wide FOV visual feedback system was created
with high presence and low image distortion.
可利用之產業
及
可開發之產品
以畫面錄像為基礎之監控系統，如 IPCam。
技術特點
本技術雛型在畫面上可取得比單一廣角鏡頭還寬廣之視野範圍，運
算時間上低於全向攝影機必須採用複雜影像投影計算之時間。並以
較低之硬體建置成本完成如同全景攝影機單張同樣視野範圍之拍
攝，同時因網路攝影機之即時性，可帶來比全景攝影機更動態之視
覺效果。
推廣及運用的價值
本技術可用低成本建構出廣視野且低畸變之攝影系統
附件二
1出席國際學術會議心得報告
計畫編號 NSC94-2213-E-011-057
計畫名稱 應用廣視野來源影像改進網路遙控自走機器人操作介面之研究
出國人員姓名
服務機關及職稱
姓名: 鄧惟中
服務機關及職稱: 台灣科技大學資訊工程系助理教授
會議時間地點
時間: 2006 年 9 月 7~9 日
地點: 日本宮城縣仙台市
會議名稱
中文: 日本虛擬實境學會第十一次大會
英文: The 11th Virtual Reality Society of Japan Annual Conference
發表論文題目 An Approach to Compensate Video Feedback Delay of Telepresence Systemsby Utilizing Wide Field of View Video Source
一、參加會議經過
此次會議在仙台市的青年文化中心舉行，仙台市不但有多處的歷史觀光景點，也是
日本東北大學的所在地。青年文化中心位於市郊，由仙台火車站搭乘地下鐵，約 15 分鐘
即可抵達。由於附近少有建物，因此呈現出如在郊外的悠閒氣氛。同時為了推廣虛擬實
境技術的認知度，日本虛擬實境學會在文化中心附近的仙台市科學館也同時舉辦了「東
北 VR 研究的現在展」、「日本 VR 研究的歷史展」等四個活動，開放給一般民眾參觀。
報告人於會議前一天晚上到達下榻旅館，並於 9 月 7 日當天上午 8:45 準時抵達會場報到。
日本虛擬實境學會的成員幾乎都是日本的研究者，因此論文發表也是以日語為主，但偶
而可見用英語發表的研究。報告人在攻讀博士期間即為會員，因此熟面孔也不少。這是
回台後第一次回籠參加。
此次會議分三個場所同時進行，因此參加者必須選擇聆聽的研究擇一參加，偶而也
必須在 session 途中轉換場地以聆聽不同主題的發表。另外在文化中心一樓右側的交流
廳，提供了 10 數個攤位作為學術展示與企業展示用途。整個會議的程序如表一所示，灰
底者是報告人參與聆聽的場次。這次的會議，共有 167 篇論文發表、3 件藝術展示、13
件技術展示與 19 件企業展示。在第三天的特別演講之後，尚有兩場表演，不過報告人在
特別演講之後即離開會場，因此不予列出。
3如何使用在開發 VR 應用上，他並舉了幾個本身實驗室開發的系統實例說明。
報告人受益最大的是第二個部份。鈴木教授首先舉瀑布為例，說明若受測者只聽瀑
布的聲音而沒有看到瀑布的影像，則有些人會將瀑布的聲音誤以為是電視在切換到
無訊號頻道時的雜音，也因此產生嫌惡感。但當受測者看到瀑布的畫面後，立刻能
將同樣的聲音解讀為瀑布的水聲，對同一個聲音的感覺也立刻從嫌惡轉為喜好。第
二個例子是光速與音速的比較：30 公尺遠的音源(例如一個鋼琴演奏者與台下的觀
眾)所產生的聲音在傳達至受測者的耳朵時，聲音已經比影像慢了 100ms，而另一方
面實驗也証明當影像與聲音差距 50ms 以上時，人即可察覺這個差異。照理，我們對
距離 15 公尺以外有動作的音源，均能感受到聲音的延遲，但是我們在日常生活中甚
至不會察覺到 30 公尺外音源的延遲。鈴木教授透過實驗發現了人類對 20 公尺內的
音源，會自動在腦中作延遲補償，讓聲音與影像在腦中同步。20 至 40 公尺的音源，
雖然不會完美的補償其延遲，但仍然能達到同步的效果。從這個例子也可以發現，
研究聲音的處理必須要從多型態這個角度著手，才得窺其全貌。接下來的例子則討
論了人腦會解釋視覺與聽覺的變化來修正自己在運動時的軀體感覺，因而了解自己
身體與週遭環境的關係如前進、後退、迴旋等。
2. 特別演講 2: “境界知”與 VR
講者瀨名秀明是藥學博士，卻因個人興趣而成為科幻小說作家，2006 年開始被東北
大學機械系聘為特任教授。由於這場演講開放一般民眾參加，因此演講中所有的主
張均盡可能用一般常見的例子來說明。瀨名博士自創了所謂“境界知”的用語，用
來表達人類的異樣感知能，也就是可以分辨正常和異樣的境界的能力。演講的內容
也分為三個部份。第一個部份描述人類在彼此溝通，或是接觸新環境的時候，都能
夠感受到自己與他人之間、或是與環境之間的異常，並且人具有改變與外界溝通的
規則（template），來消弭異常的能力。用一般的話來說，就是人有學習與他人溝通，
或是適應新環境的能力。第二個部份談到人也有切換視角的能力，因此小說家或導
演在創作作品時，可以透過視角的切換來讓讀者或觀眾隨著視角來體會作品描述的
情境。另外，人本身也有「退一步海闊天空」的能力，在需要冷靜的狀況時可以將
自己的視角由第一人稱轉換為第三人稱的客觀角度，以避免自己身陷迷局而不自
知。最後，講者認為 VR 技術應可以應用於訓練人切換視角的能力上，讓自己得以用
適當的角度來對應各種情境。
3. Telexistence 1 session: Telexistence 是東京大學 Tachi 教授自創的語彙，基本
上與 telepresence 一字等義。這個場次的五個發表中也有四個是 Tachi 教授研究室
的成果。該研究室目前主要開發的是可以達到所謂相互 telepresence 效果的系統，
亦即操作者一邊透過操作遠端機器人來達到自己如同身在遠端的效果，另一方面使
用者的表情與外觀姿勢也同時被投影到機器人身上，因此遠端的其他人也可以透過
機器人與操作者互動。
4. Visual Display (IPT) session: 本場次共有六個關於融入式投影技術(Immersive
Projection Technology)的論文發表。較引人注目的是九州大學提出了用水槽底部
作為立體畫面螢幕的提案，引起廣泛的討論。另外八戶工業大學則發表了可以取得
全方位影像深度資訊的方法。
5. Force Display (application) session: 本場次共有六個論文發表。東京農工大的
1出席國際學術會議心得報告
計畫編號 NSC94-2213-E-011-057
計畫名稱 應用廣視野來源影像改進網路遙控自走機器人操作介面之研究
出國人員姓名
服務機關及職稱
姓名: 鄧惟中
服務機關及職稱: 台灣科技大學資訊工程系助理教授
會議時間地點
時間: 2006 年 9 月 7~9 日
地點: 日本宮城縣仙台市
會議名稱
中文: 日本虛擬實境學會第十一次大會
英文: The 11th Virtual Reality Society of Japan Annual Conference
發表論文題目 An Approach to Compensate Video Feedback Delay of Telepresence Systemsby Utilizing Wide Field of View Video Source
一、參加會議經過
此次會議在仙台市的青年文化中心舉行，仙台市不但有多處的歷史觀光景點，也是
日本東北大學的所在地。青年文化中心位於市郊，由仙台火車站搭乘地下鐵，約 15 分鐘
即可抵達。由於附近少有建物，因此呈現出如在郊外的悠閒氣氛。同時為了推廣虛擬實
境技術的認知度，日本虛擬實境學會在文化中心附近的仙台市科學館也同時舉辦了「東
北 VR 研究的現在展」、「日本 VR 研究的歷史展」等四個活動，開放給一般民眾參觀。
報告人於會議前一天晚上到達下榻旅館，並於 9 月 7 日當天上午 8:45 準時抵達會場報到。
日本虛擬實境學會的成員幾乎都是日本的研究者，因此論文發表也是以日語為主，但偶
而可見用英語發表的研究。報告人在攻讀博士期間即為會員，因此熟面孔也不少。這是
回台後第一次回籠參加。
此次會議分三個場所同時進行，因此參加者必須選擇聆聽的研究擇一參加，偶而也
必須在 session 途中轉換場地以聆聽不同主題的發表。另外在文化中心一樓右側的交流
廳，提供了 10 數個攤位作為學術展示與企業展示用途。整個會議的程序如表一所示，灰
底者是報告人參與聆聽的場次。這次的會議，共有 167 篇論文發表、3 件藝術展示、13
件技術展示與 19 件企業展示。在第三天的特別演講之後，尚有兩場表演，不過報告人在
特別演講之後即離開會場，因此不予列出。
3如何使用在開發 VR 應用上，他並舉了幾個本身實驗室開發的系統實例說明。
報告人受益最大的是第二個部份。鈴木教授首先舉瀑布為例，說明若受測者只聽瀑
布的聲音而沒有看到瀑布的影像，則有些人會將瀑布的聲音誤以為是電視在切換到
無訊號頻道時的雜音，也因此產生嫌惡感。但當受測者看到瀑布的畫面後，立刻能
將同樣的聲音解讀為瀑布的水聲，對同一個聲音的感覺也立刻從嫌惡轉為喜好。第
二個例子是光速與音速的比較：30 公尺遠的音源(例如一個鋼琴演奏者與台下的觀
眾)所產生的聲音在傳達至受測者的耳朵時，聲音已經比影像慢了 100ms，而另一方
面實驗也証明當影像與聲音差距 50ms 以上時，人即可察覺這個差異。照理，我們對
距離 15 公尺以外有動作的音源，均能感受到聲音的延遲，但是我們在日常生活中甚
至不會察覺到 30 公尺外音源的延遲。鈴木教授透過實驗發現了人類對 20 公尺內的
音源，會自動在腦中作延遲補償，讓聲音與影像在腦中同步。20 至 40 公尺的音源，
雖然不會完美的補償其延遲，但仍然能達到同步的效果。從這個例子也可以發現，
研究聲音的處理必須要從多型態這個角度著手，才得窺其全貌。接下來的例子則討
論了人腦會解釋視覺與聽覺的變化來修正自己在運動時的軀體感覺，因而了解自己
身體與週遭環境的關係如前進、後退、迴旋等。
2. 特別演講 2: “境界知”與 VR
講者瀨名秀明是藥學博士，卻因個人興趣而成為科幻小說作家，2006 年開始被東北
大學機械系聘為特任教授。由於這場演講開放一般民眾參加，因此演講中所有的主
張均盡可能用一般常見的例子來說明。瀨名博士自創了所謂“境界知”的用語，用
來表達人類的異樣感知能，也就是可以分辨正常和異樣的境界的能力。演講的內容
也分為三個部份。第一個部份描述人類在彼此溝通，或是接觸新環境的時候，都能
夠感受到自己與他人之間、或是與環境之間的異常，並且人具有改變與外界溝通的
規則（template），來消弭異常的能力。用一般的話來說，就是人有學習與他人溝通，
或是適應新環境的能力。第二個部份談到人也有切換視角的能力，因此小說家或導
演在創作作品時，可以透過視角的切換來讓讀者或觀眾隨著視角來體會作品描述的
情境。另外，人本身也有「退一步海闊天空」的能力，在需要冷靜的狀況時可以將
自己的視角由第一人稱轉換為第三人稱的客觀角度，以避免自己身陷迷局而不自
知。最後，講者認為 VR 技術應可以應用於訓練人切換視角的能力上，讓自己得以用
適當的角度來對應各種情境。
3. Telexistence 1 session: Telexistence 是東京大學 Tachi 教授自創的語彙，基本
上與 telepresence 一字等義。這個場次的五個發表中也有四個是 Tachi 教授研究室
的成果。該研究室目前主要開發的是可以達到所謂相互 telepresence 效果的系統，
亦即操作者一邊透過操作遠端機器人來達到自己如同身在遠端的效果，另一方面使
用者的表情與外觀姿勢也同時被投影到機器人身上，因此遠端的其他人也可以透過
機器人與操作者互動。
4. Visual Display (IPT) session: 本場次共有六個關於融入式投影技術(Immersive
Projection Technology)的論文發表。較引人注目的是九州大學提出了用水槽底部
作為立體畫面螢幕的提案，引起廣泛的討論。另外八戶工業大學則發表了可以取得
全方位影像深度資訊的方法。
5. Force Display (application) session: 本場次共有六個論文發表。東京農工大的
5日本バーチャルリアリティ学会第11回大会論文集(2006年9月)
広視域ビデオ源によりテレイグジスタンスシステムに 
おけるビデオフィードバック遅延の改善法 
 
An Approach to Compensate Video Feedback Delay of Telepresence Systems by Utilizing
Wide Field of View Video Source
 
鄧惟中，施景元 
Wei-Chung Teng and Ching-Yuan Shih
 
台湾科技大学 資訊工程系(情報工学系) 
(〒106 #43,Sec.4,Keelung Rd., Taipei, Taiwan, weichung@mail.ntust.edu.tw) 
 
Abstract: One of the bottlenecks in telepresence systems is that only limited size of video feedback allowable
due to communication bandwidth restriction. A PTZ camera partially solves this problem by providing pan
and tilt freedom. However, the extra instructions on camera and bigger time delay jitter introduce more issues
to solve. In this paper, an approach utilizing wild FOV video source is developed to compensate time delay
from motion lag of PTZ camera and to aim on clearer image when the operators changes his/her view. A
mobile robot equipped with multiple cameras arranged in a circular fashion is used for demonstration.
Key Words: telepresence, video feedback, field of view. 
 
 
1.Introduction 
A prerequisite for telepresence systems, or 
telexistence systems, is that the teleoperator be 
directly and continuously controlled by human in 
real-time fashion. Since human operators may only know 
remote environment via sensory feedback from remote 
site, it’s obvious that system designer should make sure 
the operator receives real-time sensory feedback of 
remote environment as much as possible. It’s well known 
that video feedback is much important than other 
sensory feedback, yet ironically enough this video 
feedback usually suffers the highest time delay and 
with highly restricted field of view (FOV) due to 
communication bandwidth limit[1]. 
In the last decade, we observed many mobile vehicles 
equipped with only one camera which provides about 38 
to 42 degrees of FOV. These mobile vehicles are 
connected with wireless communication and some even 
don’t have a proprietary communication channel. As a 
result, any attempt to send more than one camera video 
feedback under this kind of configuration becomes 
impractical[2]. A PTZ camera may partially solve this 
problem by providing pan and tilt rotation freedom, by 
which the operator may rotate the camera to browse 
surrounding environment just like rotating his head. 
However, extra instructions on camera mean more jobs 
to the operator, and time delay jitter also grows during 
the rotating period due to camera’s motion lag. To 
compensate the hazard comes from rotate operation on 
camera, we propose an approach utilizing wild FOV video 
source. The idea is to let the robot equipped with 
superfluous cameras directing to non-overlapping 
angles of view, and only the part asked by human is 
transmitted. 
 
2.Design of a Wild FOV Video Source 
2.1Web Cameras with Mirrors 
There are many possible ways to fetch a wild FOV video 
source, but most of these methods required expensive 
devices. Here we present a simple and low cost design 
for a wilder video source. 
Our origin idea is to arrange all cameras in a 
circular fashion, each directing to non-overlapping 
angles of view, and there shouldn’t be gap between 
adjoining angles of view. As a result, the lens of all 
cameras must be placed in origin of a circle, which is 
practically impossible. Instead we arrange three 
cameras in the way showed in figure 1. The bold vertical 
