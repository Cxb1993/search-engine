  
 
中文摘要 
 
可攜式電子設備的普遍和感測技術的成熟，以
普及運算技術打造智慧生活空間不再是幻
想。上述元件受限於電力容量及運算功能，當
智慧生活空間所提供的服務品質與所需的運
算量息息相關時，此類元件無法滿足人類對精
確資訊取得的需求。由於網路頻寬日益提昇，
利用遠端的高速工作站提供即時服務是可行
的方式。然而網路頻寬共享的特性，使得資料
傳送時可能出現斷斷續續的情況，造成運算工
作站效能降低。此研究計劃，將探討如何在資
料傳送可能出現斷斷續續的情況下，讓運算工
作站維持高運算效能。我們採用的方式是針對
工作的特性找出執行該工作的最佳資料傳送
序列。該序列可使運算工作站在網路擁擠時仍
能維持運算端持續運算。研究分為八個子題：
(1)提出網路運算模型 (2)針對大運算量需求
之應用發展「完全支配傳送序列」演算法 (3)
提出適用於單一資料來源之最佳傳送序列的
定義 (4)針對本質屬於 NP-Hard 的「最佳傳送
序列」問題提出以基因演算法搜尋近似解的架
構 (5)建立適用於多個資料來源的網路運算
模型 (6)提出適用於多個資料傳送來源之最
佳傳送序列的定義 (7)探討多個資料來源端
在運算端所能達成的最佳與最糟的運算效能
並研究運算端效能的期望值 (8)研究漸進式
運算的模式對記憶體需求量的影響。 
 
關鍵詞：網路運算，漸進式運算，平行與分散
式計算，演算法。 
 
Abstract 
 
Due to the advances in the technology of port-
able electronic devices and tiny sensing devices, 
the fundamental enabling ubiquitous computing 
environment is mature. Based on the technology, 
the smart space that leads to a better living envi-
ronment is ready for deployment. However, due 
to the power constraint of the low-end devices, 
their computing capability is limited. If the qual-
ity of a service depends on the computing capa-
bility of a device, then the device cannot fulfill 
the computational requirement of a high quality 
service. Since the networking technology is in-
creasing, therefore, a low-end device can still be 
used in work places with connections to power-
ful computing and storage servers on the net-
work to provide quality service. However, the 
network is a non-dedicated resource in general. 
Many other computers can share its bandwidth. 
It leads to that the server may receive data items 
intermittently and results in degenerating the 
performance of the server. In this two-year re-
search project, we will study the technique of 
squeezing the computing power by employing a 
dominant input data sequence. There are eight 
topics will be investigated: (1) proposing net-
work incremental computing model for the sin-
gle source of input stream; (2) developing fully 
dominant sequence algorithms for the computa-
tional intensive applications such as the Linpack 
library; (3) proposing a reasonable definition of 
optimal data sequences of a single source for the 
problems without any fully dominant sequence; 
(4) proposing a genetic algorithm framework for 
the optimal sequence finding problem, which is 
NP-hard in the strong sense; (5) proposing net-
work incremental computing model for multiple 
sources of input stream; (6) proposing a reason-
able definition of optimal data sequences, which 
is formed by interleaving the data items from 
multiple sources; (7) proposing an framework 
for developing the upper and lower bounds on 
the execution time of the server which receives 
input stream from multiple sources, and for de-
riving its expected execution; and (8) investi-
gating the impact of incremental computing 
technique on memory space needed by the 
server site. 
 
Keywords: Network computing, Incremental 
computing, Parallel and distributed computing, 
Algorithm. 
I 
  
的資源，運算工作站的工作排程器（task 
scheduler）會因本身應處理工作的負載與優
先序來決定計算資源的分配。我們假設每一
筆信息到達的間隔為 1 秒且第一筆信息到
達的時間為第零秒，除此之外，我們亦假設
第三筆信息到達前，運算工作站可以提供此
工作每秒 c2 個計算的運算能力，在第三筆
信息到達後，因為運算工作站的負載增加，
工作排程器將運算工作站提供給執行此工
作的計算能力調降為每秒 c 個計算的運算
能力。以 D1D2D3D4順序傳送需要 2+2c 秒才
能完成工作，以 D3D4D1D2 順序傳送需要 4
秒就可以完成工作。因此我們知道若能將啟
動運算量大的資料先傳，則可以避免因運算
工作站負載改變而造成執行時間的延長。綜
合以上的例子可知，資料傳送的順序會影響
工作完成的時間，只要針對工作的計算特性
設計資料傳送的順序，則不論是在網路穩定
計算資源固定、網路不穩定計算資源固定或
網路穩定計算資源不固定的情況下都可以
獲得較短的執行時間，甚至我們相信在網路
不穩定計算資源不固定的情況下一樣可以
獲得較短的執行時間。 
 
三、文獻探討 
 
在網路運算平台上如何降低執行工作
時所需之通信所帶來的額外負荷，長久以來
就是研究的重點[2, 8, 9, 10, 11]。在[2]中，
作者討論如何以本網路(In-network)從事該
感測網路所需的運算，在該篇論文中，作者
將感應器送出的一連串的訊號看成資料
流，因此作者將此類問題轉化成 network 
flow optimization 的問題，並提出有效率的
演算法。在[8]中，作者提出 fastest nodes first
的方法，作者已證明了他的方法保證可以讓
異質性(heterogeneous)系統上執行廣播的時
間與最佳時間的差距在兩倍以內。在 [9]
中，四階段的多對多通信演算法被提出來解
決當各個訊息的長度有相當大的差異時所
造成的通信時間延遲，前兩個通信階段他們
將來源端傳送至相同目的的訊息平均分配
至各個節點，此階段的目的在於重組訊息的
内容，使得在執行後兩個通信階段時每個來
源節點將資料傳送至他們的最終目的節點
時不會產生衝突，他們的通信演算法亦降低
通信的啟動(start-up)時間與各個通信節點
所需的緩衝區(buffer)。在[10]中，一種稱作
load-skewing 的工作分配技術被提出，利用
這種技術可以使得以匯流排連接的叢集工
作站在通信的時候避免了在傳送信息時互
相競爭匯流排的使用權。在[11]中，作者採
用訊息切割(message partitioning)的技術，將
運算單元之間訊息交換的次數降到最低而
且也不會因信息的長度有大差異而造成傳
送時產生衝突。以上的技術可用來發展獨佔
性(dedicated)的運算環境中所用到的通信程
式庫或設計編譯器，以增加運算的效能。但
在非獨佔性的網路運算環境，會有工作之間
會互相競爭資源，因此依演算法的既定步驟
來執行通信或運算可能無法達到預期的效
能目標。因此有些研究針對此種情況來尋求
解決之道。目前有些論文討論如何在分散式
非獨佔性或資源有限的環境中執行計算以
有效率的完成工作，在 [7]中，作者探討資
源分配的問題，他們以目前系統的狀態(例
如：運算資源使用率、每單位時間內新增的
工作數、每單位時間內完成的工作數…)及
工作的特性(例如：該工作的工作量，是否
可切割…)來調適工作的分配而發展出 Grid 
Harvest Service 的架構提供系統在資源供應
不穩定時仍然能有很好的系統效率。在 [4]
中，作者以固定的資料量下所能引起的運算
量針對三種常用的應用提出資料傳送的最
佳順序，此種傳送順序可以提昇網路頻寬共
享環境中運算端 CPU 的使用率。在[6]中，
作者提出 iScheduler 的排程器，該排程器是
application aware，也就是 iScheduler 會動態
的去收回已分配給某個工作的資源，將資源
重新分配，以滿足某些工作在時間上的限
制。另外有些研究是針對記憶體容量受限的
情況來探討。當從事運算的設備記憶體有限
時，我們可以用較少量的資料來從事運算，
然而所獲得的結果會較不精確，在[1]中，
作者提出以 offloading 的技術以便在記憶體
有限的環境中仍能不降低結果的精確度的
2 
  
 Cho-Chin Lin and Hao-Yun Yin, “On the 
assessment of input streams for incremental 
network computing”  submitted to Journal of 
Parallel and Distributed Computing. 
 林作俊、許致軒、” Linux 叢集電腦程序
群組即時監控系統之實現” submitted to NCS 
2007. 
 
運算核心與資料庫於解決問題時，遠端資
料庫透過網路傳送資料時應如何與資源共享
之運算核心搭配以盡快計算出結果。我們在發
表論文中有詳細的分析及證明，我們發現只要
依所欲解決問題之資料相依性及相依資料所
構成的運算量來考慮，則可以有效地利用資源
共享之運算核心所提供的運算資源在最短的
時間獲得想要的結果。在我們亦探討
Client-Server 的運算模式中某些科學計算問題
之通信與計算的關係與執行時所需時間的上
限與下限。在此篇研究報告中我們證明了
Client-Server 模型在某些重要科學運算在運算
時間上的特性，我們亦考慮了 regular 和 sparse
兩種不同的資料形態。除了以上的論文，我們
亦設計了網路運算模擬器。此模擬器可以指定
多個資料傳送端，且各端可以特定的模式傳送
資料並在運算端執行指定的運算，此模擬器可
以算出多個資料傳送端執行某特定運算所需
的時間。在此研究中我們考慮資料的傳遞是以
fine-grained messages 的形式來實現。我們
亦發展程序自我移轉機制免除週期性之狀態
儲存所帶來的額外負擔。我們以函式庫的型態
呈現，讓使用者在設計程式時可以透過此函式
庫依自行訂定的移轉策略，在必要的時機才執
行即時的狀態儲存並啟動程序轉移。此函式庫
接受四個程式測試，分別為連續加法、矩陣相
乘、數字排序、最少擴張樹，皆能在移轉後正
確的計算出結果 
  
六、參考文獻 
 
[1] Xiaohui Gu, Klara Nahrstedt, Alan Messer, 
Ira Greenberg and Dejan Milojicic, Adap-
tive Offloading Inference for Delivering 
Applications in Pervasive Computing En-
vironment, Proceedings of the first IEEE 
International Conference on Pervasive 
Computing and Communications, pp. 1-8, 
2003. 
[2] Bo Hong and Viktor K Prasanna, Optimiz-
ing a Class of In-network Processing for 
Applications in Networked Sensor Systems, 
Proceedings of The 1st IEEE International 
Conference on Mobile Ad-hoc and Sensor 
Systems, October 2004. 
[3] Edgar T. Kalns and Lionel M. Ni, Processor 
Mapping Techniques Toward Efficient data 
Redistribution, IEEE Transactions on Par-
allel and Distributed Systems, Vol. 6, No. 
12, pp. 1234-1247, 1995. 
[4] Cho-Chin Lin, Tsan-Sheng Hsu, and 
Da-Wei Wang,  Bounds on Client-Server 
Incremental Computing, IEICE Trans. on 
Fundamentals of Electronics, Communica-
tions and Computer Sciences, vol. e89-a, no. 
5, pp. 1198-1206, 2006. 
[5] Ali Pinar and Bruce Hendrickson, Inter-
processor Communication with Limited 
memory,  IEEE Transactions on Parallel 
and Distributed Systems, Vol. 15, No. 7, pp. 
606-616, 2004. 
[6] Jon B. Weissman, Lakshman Rao Abburi 
and Darin England, Integrated Scheduling: 
the Best of Both Worlds, Journal of Parallel 
and Distributed Computing, 63, pp. 
649-668, 2003. 
[7]  Ming Wu and Xian-He Sun, A General 
Self-adaptive Task Scheduling System for 
Non-dedicated Heterogeneous Computing, 
Proceedings of the IEEE International 
Conference on Cluster Computing, pp. 
354 – 361, 2003 
[8]  P. Liu, Broadcast scheduling optimization 
for heterogeneous cluster systems, Journal 
of Algorithms, 42(1),  pp. 135-152, 2002. 
[9]  W. Liu, C. L. Wang and V. K. Prasanna, 
Portable and Scalable Algorithm for ir-
regular all-to-all communication, Journal of 
Parallel and Distributed Computing, 
62(10) , pp 1493-1526, 2002. 
[10] W. M. Lin and W. Xie, Load-skewing task 
assignment to minimize communication 
conflicts on network of workstations, Paral-
4 
出席國際學術會議心得報告 
                                                             
一、參加會議經過 
此次會議的主軸涵蓋了 Parallel Architectures，Advanced Network Technologies，Parallel 
Algorithms，Peer-to-Peer Technologies，Grid Computing…等等，總共 18 個 sections。此研討會
總共有來自 9 個國家 179 篇的論文投稿，被接受的 40 篇被安排在會議中的 3 個 parallel tracks
發表，所有發表的論文皆收錄於 Springer 的 Lecture Notes in Computer Science。本人亦擔任此
會議 Advanced Network Technologies II 的議程主席，此 session 共有 3 篇論文發表。此研討的 
keynote speakers為Prof. Rein Hartenstein, Kaiserslautern University, Germany 及Prof. Hai Zhuge, 
Chinese Academy of Science, China。講題分別為”Reconfigurable Computing and the von 
Neumann Syndrome” 及”RSM-based Gossip on P2P Network”。除了仔細聆聽相關的文章發表，
亦與 Viktor. K. Prasanna, University of Southern California 和 Cho-Li Wang, University of Hong 
Kong 一起前往浙江大學參訪 Prof. Kai Hwang 所主持的實驗室。 
 
二、與會心得 
由於網際網路的進步，不論是資料的擷取，或是計算資源的共享，都已經可以輕而易舉的
實現，但要如何獲得最有用的資料，及如何有效使用網路上所提供的資源，通信時間成為關
鍵的議題，許多發展出來減少通信時間的方法純粹只從減少通信時間的觀點來研究，雖然在
這方面學術界發展出許多好技術，但碰到網路壅塞的問題或是頻寬不足的問題時則還是有很
多的困難尚待克服。LUD 在科學運算上是相當重要，我的論文是將 LUD 的演算架構加以解
析，展現其執行時每一筆資料在運算端所能啟動的運算，以導出最佳化的傳送順序。我發表
論文時，除了在會場以簡略的方式回答所提出的問題，更在會後更進一步交換此類技術所可
能應用的範圍的想法。在會議中有人針對此研究提出最值得深思的建議為：可探討將此技術
用於多處理器電腦之編譯器以降低匯流排擁擠所導致效能降低。此會議接受 40 篇論文發表，
數量不多，因此每一篇論文皆有充份的時間發表與討論，且參與者的研究領域較近，因此在
討論下往往可獲得很大的助益，因本人對此研討會積極參與，獲推薦為下一屆的議程委員。 
在 keynote speakers 的演講方面，雖然兩個講者所講的內容皆相當精彩，我對第一個講者的內
容特別感興趣，因為 reconfigurable computing 在十幾年前已被提出，也做了不少學理上的研
究，但離實際應用尚有一段距離，目前 FPGA 的成熟，似乎為 reconfigurable computing 的前
程鋪設了一條路，但其中一的很重要的主題為如何為 FPGA 定義一個有意義的 programming 
model，以方便程式設計與效能評估，是一個很值得挑戰的方向。 
計畫編號 NSC95-2221-E-197-013 
計畫名稱 資料傳送序列對網路運算效能之研究(I) 
出國人員姓名 
服務機關及職稱 
林作俊 
國立宜蘭大學電子工程系副教授 
會議時間地點 Hangzhou, China, June 11-13,  2007 
會議名稱 The 7th International Conference on Algorithms and Architectures for Parallel Processing 
發表論文題目 A Dominant Input Stream for LUD Incremental Computing on a Contention Network
404 C.-C. Lin
The basic arithmetic operations for a server to compute f(x) are: one square
operation, one square root operation, one reciprocal operation and two addition
operations. Assume each basic arithmetic operation takes one clock and the
arriving interval of the three data items are g0 clocks and g1 clocks. If the input
stream is d2d1d0 then the time to complete the task is g0 + g1 + 7. If the input
stream is d0d1d2 then the time to complete the task is g0 + max{g1,max{5 −
g0, 0} + 1} + 1. Since g0 + g1 + 7 ≥ g0 + max{g1,max{5 − g0, 0} + 1} + 1, it
is obvious that the ﬁrst input stream is worse than the second input stream. It
implies that the computation and communication issues are closely inter-wined
in the network-based computing and should be studied together.
LU decomposition (LUD) can be applied to solve systems of linear equations.
A best input stream of an application maximizes the CPU utilization for any
network traﬃc pattern at any time. This research studies whether it is possible
to ﬁnd a best input stream for an existing LUD algorithm. The steps to build a
best input stream for LUD in linear time are given in this paper. The compressed
format for sending elements of a sparse matrix is also studied. The nonexistence
of dominant input streams is proved for the sparse case. This paper is organized
as follows. In Sect. 2, background and related works are discussed. General no-
tations used in this paper are deﬁned in Sect. 3. In Sect. 4, the theorems as the
foundation of ﬁnding a best input stream are developed and a best input stream
is proposed. In Sect. 5, the comparison of the completion times of performing
LUD using a dominant input stream and another input stream is conducted.
In Sect. 6, the compressed format for sending input data is studied. Finally,
concluding remarks are given in Sect. 7.
2 Background and Related Works
Communication has been recognized as the major overhead of executing an ap-
plication across the network. To minimize the communication overhead, many
software-based mechanisms have been developed by optimizing the communi-
cation modules [10], [11]. Other techniques based on communication scheduling
have also been proposed to improve the eﬃciency of complicated communica-
tion routines [1], [8], [9], [13], [14]. In [1], eﬀective heuristic algorithms called
fastest edge ﬁrst and earliest completing edge ﬁrst were proposed to reduce the
communication time for distributed heterogeneous systems. The authors showed
that their heuristics have achieved significant performance improvement over
previous approaches. In [8], an eﬀective heuristic called fastest nodes ﬁrst (FNF)
was proposed to reduce the broadcast time for heterogeneous cluster systems.
The author also showed that the FNF heuristic guarantees the total commu-
nication time to be within twice of the time from an optimal schedule. In [9],
[13], a two-phase communication algorithm was proposed to attack the commu-
nication delay occurred by messages with large variance in length. In the first
phase, each processor evenly distributes the data to be moved to the same des-
tination among the processors. In the second phase, each processor sends the
data received from the first phase to their final destinations. In [14], an eﬃcient
406 C.-C. Lin
 
d
ija  
(a) i ≤ j
 
d
ija  
(b) i > j
Fig. 1. The data dependency of adij
of critical steps are considered for LUD: scalar multiplication/division denoted
by mul/div and scalar addition/subtraction denoted by add/sub.
A recurrence relation of LUD computation which decomposes a matrix A =
[aij ], 0 ≤ i, j < n, into an upper triangular matrix U = [uij ] and a lower
triangular matrix L = [lij ] is given as follows.
Ad = LUD(A) =
(
1 w
v/a00 LUD(A′ − vw/a00)
)
. (1)
where A′ is formed by deleting the first row and first column of A, v is a column
vector (a10, a20, a30 · · ·an−1 0) and w is a row vector (a01, a02, a03 · · · a0n−1). Let
Ad = [adij ]. The elements of matrices L and U are given as follows: lij = adij
if i > j ; lij = 1 if i = j ; lij = 0 if i < j and uij = adij if i ≤ j ; uij = 0 if
i > j. The recurrence implies that the elements in LUD(A′ −vw/a00) depends on
the values of w and v/a00. The incremental algorithm considered in this paper
for performing LUD implements the recurrence given in (1). Interested readers
should refer to [2] for detail on the topic of solving systems of linear equations.
Deﬁne active matrix EA = [eij ] as a (n+1)×(n+1) matrix, where −1 ≤ i, j < n.
In the matrix, eij = 1 or 0. eij = 1 implies that the ﬁnal value of adij has been
obtained and can be used to derive other elements of Ad. Based on (1), the
value of adij , i ≤ j, depends on the values of adi0, adi1 · · ·adi i−1 and the values of
ad0j , a
d
1j · · ·adi−1 j as shown in Figure 1(a). The value of adij , i > j, depends on the
values of adi0, a
d
i1 · · ·adi j−1 and the values of ad0j , ad1j · · · adj j as shown in Fig. 1(b).
To give the recurrence for eij , some notations are deﬁned ﬁrst. ω(E(i, ∗), k,∧)
and ω(E(∗, j), k,∧) denote ei−1∧ei0∧ei1∧· · ·∧eik and e−1 j ∧e0j ∧e1j ∧· · ·∧ekj ,
respectively. The receipt of data item aij by the computation server is indicated
using the function h¯(aij). h¯(aij) = 1 if aij is received by the computation server;
h¯(aij) = 0, otherwise. Thus, the recurrence for eij is given as follows.
eij =
⎧⎨
⎩
1 if i = −1 or j = −1 .
ω(E(i, ∗), i−1,∧) ∧ ω(E(∗, j), i−1,∧) ∧ h¯(aij) if 0 ≤ i ≤ j < n .
ω(E(i, ∗), j−1,∧) ∧ ω(E(∗, j), j,∧) ∧ h¯(aij) if 0 ≤ j < i < n .
(2)
408 C.-C. Lin
Lemma 1. Let PAm be symmetrically compact and PA′m be compact. Then,(PAm ,mul/div) ≥ (PA′m ,mul/div)
Proof. Let (R
′
k, C
′
k) be the growing 2-tuple or the empty 2-tuple with the small-
est index k in the compact layout PA′m . Assume |R
′
k| + |C
′
k| = b < 2(n − k) − 1.
The number of executable mul/div operations using the elements in R
′
k and C
′
k
is |R′k|(b − |R
′
k|) or 0. It is equal to 0 if akk 
∈ R
′
k. If b is even and akk ∈ R
′
k then
the maximum value of |R′k|(b − |R
′
k|) is b
2
4 when |R
′
k|= |C
′
k|= b2 . If b is odd and
akk ∈ Rk then the maximum value of |R′k|(b−|R
′
k|) is b
2−1
4 when |R
′
k|= b+12 and
|C ′k|= b−12 . In either of the cases, a symmetrically compact layout satisﬁes the
requirement to maximize |R′k|(b − |R
′
k|). unionsq
Based on the recurrence in (2), the number of executable mul/div operations
(PAm ,mul/div) can be computed as follows:
(PAm ,mul/div) =
n−2∑
=0
n−1∑
i=+1
n−1∑
j=
(ei ∧ ej) . (3)
The equivalence of two 2-tuples (Rk, Ck) and (R
′
k, C
′
k) means Rk = R
′
k and
Ck = C
′
k. The following lemma states that two symmetrically compact layouts
PAm and PA′m have the same number of executable mul/div operations even
though the growing tuples (Rk, Ck) 
= (R′k, C
′
k).
Lemma 2. Let PAm and PA′m be symmetrically compact.Then,(PAm ,mul/div)
= (PA′m ,mul/div).
Proof. PAm and PA′m are symmetrically compact. Assume (Ri, Ci) and (R
′
i, C
′
i)
are full for 0 ≤ i < k, and (R′k, C
′
k) and (Rk, Ck) are growing symmetrically. We
have |Ri| = |R′i| and |Ci| = |C
′
i | for 0 ≤ i ≤ k. It implies that
∑k
i=0 |Ri| · |Ci| =∑k
i=0 |R
′
i| · |C
′
i |. That is, (PAm ,mul/div) = (PA′m ,mul/div). unionsq
The following theorem shows that a symmetrically compact layout is optimal.
Theorem 1. Let PAm be symmetrically compact. Then, (PAm ,mul/div) ≥
(PA∗m ,mul/div), where PA∗m is any other not symmetrically compact layout.
Proof. Let (R∗k, C
∗
k ) be the growing or empty 2-tuple with the smallest index k in
PA∗m . Assume |R∗k|+|C∗k | = b and
∑n−1
i=k+1(|R∗i |+|C∗i |) = b
′
. If b+b
′ ≤ 2(n−k)−1,
then the elements in (R∗i , C
∗
i )’s for k < i < n are removed and b
′
elements are
added symmetrically to (R∗k, C
∗
k). The new layout denoted as PA′m is a sym-
metrically compact layout. Based on (2), (3) and Lemma 2, it is obvious that
(PAm ,mul/div) = (PA′m ,mul/div) ≥ (PA∗m ,mul/div). If b+b
′
> 2(n−k)−1,
then delete 2(n−k)−1− b elements in (R∗i , C∗i )’s starting from the 2-tuple with
the largest index, where k < i < n, and add 2(n−k)−1−b elements to (R∗k, C∗k).
410 C.-C. Lin
 
a00 a01 a02 
   
a10 a11 a12 
   
a20 a21 a22 
   
      
      
      
(a) PA9
 
a00 a01 a02 
   
a10 a11 a12 
   
a20 a21 
    
a30 a31 
    
  
 
     
   
 
     
(b) PA10
Fig. 3. The layouts used in the proof of Theorem 3
Theorem 3. There is no dominant input stream for LUD regarding add/sub
operation.
Proof. Assume A is a 6 × 6 matrix. If the computation server receives 9 data
items, the maximum value of (PA9 , add/sub) is 5. It occurs when Ri ={aii, ai i+1
· · · ai 2} and Ci = {ai+1,i, ai+2 i · · ·a2 i} for 0 ≤ i ≤ 2; |Ri| = |Ci| = 0 for 3 ≤ i ≤ 5
as shown in Fig. 3(a). If the computation server receives 10 data items, the
maximum value of (PA10 , add/sub) is 6. It occurs when Ri = {aii, ai i+1 · · ·ai 2}
and Ci = {ai+1,i, ai+2 i · · · a3 i} for 0 ≤ i ≤ 1; |Ri| = |Ci| = 0 for 2 ≤ i ≤
5 as shown in Fig. 3(b). Since A9 
⊆ A10, Thus, there is no dominant input
stream. unionsq
5 Performance Evaluation
In this section, the performance of a dominant input stream for mul/div is eval-
uated by comparing its execution time with that of another input stream which
sends the matrix elements in a traditional order.
Let I = d0d1d2 · · · dn2−1 be the dominant input stream as given in Theorem 2.
The order of sending matrix elements is expressed by a one-to-one function σ.
It maps a pair of integers (i, j) to an integer σ(i, j), where 0 ≤ i, j < n and
0 ≤ σ(i, j) < n2. That is, dσ(i,j) = aij . The function σ is given as follows:
σ(i, j) =
⎧⎨
⎩
∑i−1
=0(|R| + |C|) if i = j.∑j−1
=0(|R| + |C|) + 2(i − j) − 1 if i > j.∑i−1
=0(|R| + |C|) + 2(j − i) if i < j.
The function alternately assigns the elements in Ri and Ci to consecutive posi-
tions starting at 0 and proceeds to assign the elements in Ri+1 and Ci+1 after all
the elements in Ri and Ci have been assigned. Since the dominant input stream
is a symmetrically compact, the number of executable mul/div operations based
on the elements in Ri and Ci is |Ri| · |Ci|. Denote Fσ(i,j) as the total executable
412 C.-C. Lin
The curve of F
′
ρ(i,j) for incremental LUD computation on a matrix of 10× 10 is
illustrated in Fig. 4. In the ﬁgure, the number of executable mul/div operations
triggered by input stream I
′
is always less than that triggered by I for the ﬁrst
k data items, 0 ≤ k < n2.
The diﬀerence in the numbers of executable mul/div operations between a
pair of input sub-streams of length k is deﬁned as their kth gap. That is, the kth
gap is Fk−1 −F ′k−1. The gaps for the two input streams I and I
′
, for 1 ≤ k ≤ n2,
are also illustrated in Fig. 4. The maximum of the gaps is 121 when the ﬁrst
50 data items have arrived at the computation server. Let t0 and t1 denote
the time that the ﬁrst data item arrives at the computation provider and the
time the computation provider complete all the computations, respectively. The
execution time is deﬁned as t1 − t0. In [6], the completion time of executing an
application J was shown to be WJ + Δmax. Note that WJ is the number of
total computations needed to complete the application J . The amount of delay
Δmax is deﬁned as the maximum of ({Gi − Fi|0 ≤ i < n2 − 1} ∪ {0}), where Gi
is the number of CPU cycles available for the computation server to execute the
task before the i+1th data item arrives. Let the completion times of performing
LUD using I and I
′
be T = WJ + Δmax and T
′
= W
′
J + Δ
′
max, respectively.
Since I and I
′
are used to perform LUD of the same problem size, WJ = W
′
J .
It is known that Δ
′
max ≥ Δmax. Thus, T
′ ≥ T . Consider the case: Gi = Fi for
0 ≤ i < n2−1 under the assumption that one mul/div operation takes 1 CPU
cycle and one add/sub operation takes 0 CPU cycle. The diﬀerence in their
completion time can be calculated as follows:
T
′ − T = Δ′max − Δmax
= max{Fi − F ′i |0 ≤ i < n2−1} − 0 because Gi = Fi
= 121 cycles .
Thus, performing LUD using the dominant input stream can take up to 121
CPU cycles less than that using the other input stream. The data-sending order
in a dominant stream does not meet the traditional order in storing the matrix
elements in memory, thus, dynamically reorganizing data is necessary. However,
the overhead of reorganizing matrix elements can be eliminated by assigning the
elements to their proper addresses once the elements are going to be stored in
memory.
6 Sparse Incremental LU Decomposition
In this section, performing LUD on a sparse matrix A of n × n is considered,
where only non-zero data items are sent, and all unsent data items are assumed
to be zero and are known to the computation server. The format of sending data
is named as compressed format. The ﬁnal value of adij , i ≤ j, can be directly
computed if ai0 = ai1 = · · · = ai i−1 = 0 or a0j = a1j = · · · = ai−1 j = 0. The
ﬁnal value of adij , i > j, can be directly computed if (ai0 = ai1 = · · · = ai j−1 = 0
or a0j = a1j = · · · = aj−1 j = 0) and ejj = 1. Note that in the case of a
