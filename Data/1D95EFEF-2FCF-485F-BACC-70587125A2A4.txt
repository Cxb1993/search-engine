in Medicine，也部份被發表在旗艦級的 IEEE 國際會議。 
中文關鍵詞： 盲蔽訊號源分離、凸分析及凸優化、高光譜影像分析、生醫
影像分析、癌症檢測、強健性最佳化、模型階數之選擇 
英 文 摘 要 ： English abstract is given in the report. 
英文關鍵詞： Blind source separation, convex analysis and 
optimization, hyperspectral image analysis, 
biomedical image analysis, cancer detection, robust 
optimization, model order selection 
 
I 
 
目錄 
一、中、英文摘要及關鍵詞 (keywords) ............................................................ II 
二、報告內容 ......................................................................................................... 1 
前言與研究目的 ............................................................................................... 1 
文獻探討 ........................................................................................................... 2 
研究方法 ........................................................................................................... 2 
結果與討論（含結論與建議） ....................................................................... 2 
Summary of research results in Hyperspectral Image Analysis………….5 
Summary of research results in Biomedical Image Analysis ……..……13 
三、國科會補助專題研究計畫成果報告自評表 ............................................... 15 
附錄 
III 
 
中文摘要：在此三年期計畫期間（2010/8/1~2013/7/31），在應用於高光譜影像、和生物醫學影像分
析上之先進盲蔽訊號源分離（blind source separation, BSS）方法上，我們已經獲得了新穎、原創、且
具前瞻性的研究貢獻。我們主要著重於模型階數之選擇、資料維度及雜訊之降低、強健分離準則之建
立、訊號源辨識能力之分析、演算法之開發、收斂性之分析、在仿真及真實數據上之性能分析、以及
降低即時實現之複雜度。 
  由於有限的空間解析度，用於探索有趣的地質學或天體學領域之遙感高光譜數據（來自衛星或空
載的感測器）存在著像素混合問題。因此，為了有效分析高光譜數據，在雜訊及異常值（outlier）存
在的狀況下（此二者乃數十年來高光譜數據分析研究人員所面臨的主要挑戰性問題），我們在凸分析
及凸優化理論的基礎上提出了新穎的演算法，藉以可靠地估計端元（訊號源）之個數，強有力且強健
地降低資料維度，以及有效地解析數據（訊號源分離）。我們也對著名的 Winter準則和 Craig準則進
行了理論分析，並且部分地推導出此二準則的訊號源辨識能力之必要條件和充分條件。這些理論分析
也增進了高效率的高光譜數據離析演算法之發展。 
  動態對比增強磁共振影像（dynamic contrast enhance magnetic resonance imaging, DCE-MRI）中的
有限空間解析度和部分體積效應，嚴重限制了用於早期疾病（癌症）檢測之 DCE-MRI影像分析。因
此，為了生物醫學上的 DCE-MRI數據分析，我們已開發、改進、且驗證了數個強大的非監督之非負
盲蔽訊號源分離方法，藉以剖析和描繪 DCE-MRI影像中的複合識別標誌、和對應之動力學參數，從
而可增進有效的早期疾病檢測。特別是，我們已經開發出用於乳癌和攝護腺癌患者的癌症分析之盲蔽
訊號源分離演算法。由於動脈輸入函數（arterial input function, AIF）之量化是 DCE-MRI影像的定量
誤差主要原因之一，因此我們也提出了一個新穎的盲蔽訊號源分離演算法來準確地估計 AIF。 
  這些用於高光譜影像、和生物醫學影像分析而開發的盲蔽訊號源分離演算法，可促使盲蔽訊號源
分離在其理論基礎、演算法、及實現上顯著的進展。對這些開發出的演算法我們已大量地以仿真和真
實的數據集進行測試，這些研究成果也已全部發表在國際頂級期刊，如 IEEE Transactions on 
Geoscience and Remote Sensing, IEEE Transactions on Medical Imaging, Bioinformatics, Magnetic 
Resonance in Medicine，也部份被發表在旗艦級的 IEEE國際會議。 
 
中文關鍵詞: 盲蔽訊號源分離、凸分析及凸優化、高光譜影像分析、生醫影像分析、癌症檢測、強健
性最佳化、模型階數之選擇。
2 
 
volume effect of the observed images due to the limited spatial resolution of the DCE-MR images. Such a 
problem is formally referred to as the tissue heterogeneity problem, that is, each observed pixel is 
contributed from the signals responded by multiple (correlated) biomarkers (sources). The biomedical image 
analysis (BIA) of DCE-MRI data aims to tackle this tissue heterogeneity problem and thereby extract the 
underlying cancer tissue information. Basically, the BIA is a BSS problem which aims to study the behavior 
of the biomarkers in normal and cancer tissues, and such an analysis (aka pharmacokinetic analysis) 
potentially yields vital information for early-stage cancer diagnosis and prognosis, which will potentially 
improve the current poor survival rate of patients suffering from a variety of cancers/tumors. 
Both the HIA and BIA have a lot in common with that of BSS. However, the interdependence and 
nonstationarity nature of the sources (abundance maps in HIA and the tissue distributions in BIA) has 
become the major obstacle in direct utilization of statistical BSS approaches, such as independent 
component analysis (ICA) based methods. The drawbacks of the existing BSS algorithms for HIA and BIA 
includes (i) unrealistic (statistical) assumptions on the sources; (ii) unreliable estimation of the number of 
sources; (iii) lack of rigorous theoretical analysis for source identifiability; (iv) lack of serious consideration 
of noise and outliers; (v) sensitivity to initializations and uncertain priors; (vi) intractable computational 
complexities, etc. Hence, in this research project, under realistic multi-input multi-output signal models for 
the observed hyperspectral and biomedical data, and exploiting the inherent diversities, we have designed 
and developed cutting-edge advanced BSS algorithms for HIA and BIA, based on the advanced convex 
analysis and optimization theory (which recently has drawn extensive attention in signal processing and 
communications). The developed BSS algorithms include model order selection, dimension/noise reduction, 
robust separation criterion establishment, source identifiability analysis, algorithm development, 
performance analysis, and complexity reduction for real-time implementations. The developed algorithms 
have been substantially tested with synthetic and real data, and when compared with existing state-of-the-art 
BSS algorithms, our proposed algorithms exhibited significant improvement in accurately estimating the 
sources in both HIA and BIA. The developed BSS algorithms have been published in top-tier international 
Journals and Conferences. 
 
文獻探討:  
Please see the attached papers in the Appendix for the detailed information. 
 
研究方法:  
Please see the attached papers in the Appendix for the detailed information. 
 
結果與討論（含結論與建議）:  
In this section, we will briefly present some of our newly invented advanced BSS algorithms for HIA and 
BIA. For HIA, the effectiveness of the BSS algorithms always suffers (sometimes miserably) from the noise 
in the hyperspectral observations. To improve the performance of BSS algorithms under such condition, we 
have employed a chance-constrained optimization strategy and successfully devised a robust BSS algorithm, 
called robust minimum volume enclosing simplex (RMVES) algorithm (see [J1], [T1], below). Rigorous 
considerations of noise and outliers present in hyperspectral images are addressed under a novel max-min 
4 
 
awarded “The Best Ph.D Dissertation Award” from IEEE Geoscience and Remote Sensing Society, Taipei 
Chapter. He is currently a post doctor of my research lab (Wireless Communications & Signal Processing, 
WCSP lab), and continues focusing his research on BSS algorithms for hyperspectral and biomedical image 
analysis. 
 
Summary: Our research in developing advanced BSS methods for HIA and BIA has led to 7 international  
journal papers including 4 published in IEEE Transactions on Geoscience and Remote, one each in IEEE 
Transactions on Biomedical Imaging, Bioinformatics, Magnetic Resonance in Medicine, 12 IEEE 
international conference papers, and 1 Ph.D. dissertation that has received best Ph.D. dissertation award 
from IEEE TGRS Society, Taipei Chapter. We would like to mention that very few highly reliable and 
tractable HIA and BIA algorithms were reported in the open literature, and we are one of the leading groups 
in HIA and BIA right from the problem definition and formulation, establishment of unmixing criteria, 
theoretical proof and analysis, algorithm developments, to real data tests and validation. We optimistically 
believe that our research results summarized above will create significant impact on a wide range of research 
communities including hyperspectral imaging and biomedical imaging, and thereby promote our 
international recognition and visibility. 
6 
 
alternating optimization. The resulting algorithm turns out to be an N-FINDR variant, but, with the proposed 
formulation, we can pin down some of its convergence characteristics. Another is by successive 
optimization; interestingly the resulting algorithm is found to exhibit some similarity to vertex component 
analysis (VCA). Hence, the framework provides linkage and alternative interpretations to these existing 
algorithms. Furthermore, we propose a robust worst-case generalization of the Winter problem for 
accounting for perturbed pixel effects in the noisy scenario. An algorithm combining alternating optimization 
and projected sub-gradients is devised to deal with the problem. We use both simulations and real data 
experiments to demonstrate the viability and merits of the proposed algorithms. 
 
[J3] A. Ambikapathi, T.-H. Chan, Chong-Yung Chi, and K. Keizer, “Hyperspectral data geometry based 
estimation of number of endmembers using p-norm based pure pixel identification,” IEEE Trans. 
Geoscience and Remote Sensing, vol. 51, no. 5, pp. 2753-2769, May 2013. Citations: 1 by SCI and 3 by 
Google Scholar (Impact factor: 3.467) (JCR Journal Ranking: 13/242)  
 
Abstract: Hyperspectral endmember extraction is a process to estimate endmember signatures from the 
hyperspectral observations, in an attempt to study the underlying mineral composition of a landscape. 
However, estimating the number of endmembers, which is usually assumed to be known a priori in most 
endmember estimation algorithms (EEAs), still remains a challenging task. In this work, assuming 
hyperspectral linear mixing model, we propose a hyperspectral data geometry based approach for estimating 
the number of endmembers by utilizing successive endmember estimation strategy of an EEA. The approach 
is fulfilled by two novel algorithms, namely geometry based estimation of number of endmembers - convex 
hull (GENE-CH) algorithm and affine hull (GENE-AH) algorithm. The GENE-CH and GENE-AH 
algorithms are based on the fact that all the observed pixel vectors lie in the convex hull and affine hull of 
the endmember signatures, respectively. The proposed GENE algorithms estimate the number of 
endmembers by using the Neyman-Pearson hypothesis testing over the endmember estimates provided by a 
successive EEA until the estimate of the number of endmembers is obtained. Since the estimation accuracies 
of the proposed GENE algorithms depend on the performance of the EEA used, a reliable, reproducible, and 
successive EEA, called p-norm based pure pixel identification (TRI-P) algorithm is then proposed. The 
performance of the proposed TRI-P algorithm, and the estimation accuracies of the GENE algorithms are 
demonstrated through Monte Carlo simulations. Finally, the proposed GENE and TRI-P algorithms are 
applied to real AVIRIS hyperspectral data obtained over the Cuprite mining site, Nevada, and some 
conclusions and future directions are provided. 
 
[J4] T.-H. Chan, A. Ambikapathi, W.-K. Ma, and Chong-Yung Chi, “Robust affine set fitting and fast 
simplex volume max-min for hyperspectral endmember extraction,” IEEE Trans. Geoscience and Remote 
Sensing, vol. 51, no. 7, pp.3982-3997, July 2013. Citations: 0 by SCI and 1 by Google Scholar (Impact 
factor: 3.467) (JCR Journal Ranking: 13/242)  
 
Abstract: Hyperspectral endmember extraction is to estimate endmember signatures (or material spectra) 
from the hyperspectral data of an area for analyzing the materials and their composition therein. The 
presence of noise and outliers in the data poses a serious problem in endmember extraction. In this work, we 
8 
 
the endmember signatures, respectively. The proposed GENE algorithms estimate the number of 
endmembers by using the Neyman-Pearson hypothesis testing over the endmember estimates provided by a 
successive EEA until the estimate of the number of endmembers is obtained. Since the estimation accuracies 
of the proposed GENE algorithms depend on the performance of the EEA used, a reliable, reproducible, and 
successive EEA, called p-norm based pure pixel identification (TRI-P) algorithm is then proposed. 
Monte-Carlo simulations and real data experiments on AVIRIS hyperspectral data obtained over the Cuprite 
mining site, Nevada are performed to demonstrate the efficacy of the proposed RAVMAX, RMVES, GENE, 
and TRI-P algorithms. We believe that the proposed chance constrained robust algorithms for hyperspectral 
unmixing, and data geometry based algorithms for estimating the number of endmembers, will provide a 
new dimension in analyzing hyperspectral data where noise is always present. 
 
[C1] A. Ambikapathi, T.-H. Chan, Chong-Yung Chi and Kannan Keizer, “Two effective and computationally 
efficient pure-pixel based algorithms for hyperspectral endmember extraction,” in Proc. IEEE ICASSP-2011, 
Prague, Czech Republic, May 22-27, 2011, pp. 1369-1372.  
 
Abstract: Endmember extraction is of prime importance in the process of hyperspectral unmixing so as to 
study the mineral composition of a landscape from its hyperspectral observations. Though, a whole bunch of 
pure-pixel based endmember extraction algorithms exists, the quest for a reliable, repeatable, and 
computationally efficient endmember extraction algorithm still prevails. In this work, we propose two 
pure-pixel based endmember extraction algorithms called simplex estimation by projection (SIMPLE-Pro) 
algorithm and p-norm based pure pixel identification (TRI-P) algorithm. The end member identifiability of 
the proposed two algorithms is theoretically proved under the pure pixel assumption. Both algorithms never 
require any initializations and hence they are repeatable. Monte Carlo simulations are performed to 
demonstrate the superior efficacy and computational efficiency of the proposed two algorithms over some 
existing benchmark endmember extraction algorithms. 
 
[C2] T.-H. Chan, W.-K. Ma, A. Ambikapathi and C.-Y. Chi, “Robust endmember extraction using worst-case 
simplex volume maximization,” in Proc. Third IEEE Workshop on Hyperspectral Image and Signal 
Processing: Evolution in Remote Sensing (WHISPERS), Lisbon, Portugal, June 6-9, 2011. (This paper was 
awarded the “Best Paper Award” in WHISPERS-2011)  
 
Abstract: Winter’s maximum-volume simplex approach is an efficient and representative endmember 
extraction approach, as evidenced by the fact that N-FINDR, one of the most widely used class of 
endmember extraction algorithms, employs simplex volume maximization as its criterion. In this work, we 
consider a robust generalization of Winter’s maximum-volume simplex criterion for the noisy scenario. Our 
development is based on an observation that the presence of noise would tend to expand the observed data 
cloud geometrically. The proposed robust Winter criterion is based on a max-min or worst case approach, 
where we attempt to counteract the data cloud expansion effects by using a shrunk simplex volume as the 
metric to maximize. The proposed criterion is implemented by a combination of alternating optimization and 
projected sub-gradients. Some simulation results are presented to demonstrate the performance advantages 
10 
 
[C5] T.-H. Chan, J.-Y. Liu, A. Ambikapathi, W.-K. Ma, C.-Y. Chi, “Fast algorithms for robust hyperspectral 
endmember extraction based on worst-case Simplex volume maximization,” in Proc. 2012 IEEE 
International Conference on Acoustics, Speech, and Signal Processing, Kyoto, Jap an, Mar. 25-30, 2012.  
 
Abstract: Hyperspectral endmember extraction (EE) is to estimate endmember signatures (or material 
spectra) from the hyperspectral data of an unexplored area for analyzing the materials and their composition 
therein. However, the presence of noise in the data posts a serious problem for EE. Recently, robustness 
against noise has been taken into account in the design of EE algorithms. The robust maximum volume 
simplex criterion has been shown to yield performance improvement in the noisy scenario, but its real 
applicability is limited by its high implementation complexity. In this paper, we propose two fast algorithms 
to approximate this robust criterion, which turns out to deal with a set of partial max-min optimization 
problems in alternating manner and successive manner, respectively. Some Monte Carlo simulations 
demonstrate the superior computational efficiency and efficacy of the proposed robust algorithms in the 
noisy scenario over some benchmark EE algorithms. 
 
 
[C6] A. Ambikapathi, T.-H. Chan, C.-Y. Chi, “Convex geometry based estimation of number of endmembers 
in hyperspectral images,” in Proc. 2012 IEEE International Conference on Acoustics, Speech, and Signal 
Processing, Kyoto, Japan, Mar. 25-30, 2012, pp. 1233-1236. 
 
Abstract: Hyperspectral unmixing is a process of decomposing the hyperspectral data cube into endmember 
signatures and their corresponding abundance maps. For the unmixing results to be completely interpretable, 
the number of materials (or endmembers) present in that area should be known a priori, which however is 
unknown in practice. In this work, we use hyperspectral data geometry and successive endmember 
estimation strategy of an endmember extraction algorithm (EEA) to develop two novel algorithms for 
estimating the number of endmembers, namely geometry based estimation of number of endmembers - 
convex hull (GENE-CH) algorithm and affine hull (GENE-AH) algorithm. The proposed GENE algorithms 
estimate the number of endmembers by using Neyman-Pearson hypothesis testing over the endmembers 
sequentially estimated by an EEA until the estimate of the number of endmembers is obtained. Monte-Carlo 
simulations demonstrate the efficacy of the proposed GENE algorithms, compared to some existing 
benchmark methods for estimating number of endmembers. 
 
[C7] Y.-S. Shen, T.-H. Chan, S. Bourguignon, and C.-Y. Chi, “Spatial-spectral unmixing of hyperspectral 
data for detection and analysis of astrophysical sources with the MUSE instrument,” in Proc. Fourth IEEE 
Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS), 
Shanghai, China, June 5-7, 2012.  
 
Abstract: Detection and analysis of astrophysical sources from the forthcoming MUSE instrument is of 
greatest challenge mainly due to the high noise level and the three-dimensional translation variant blur effect 
of MUSE data. In this work, we use some realistic hypotheses of MUSE to reformulate the data convolution 
model into a set of linear mixing models corresponding to different, disjoint spectral frames. Based on the 
12 
 
 
Abstract: Hyperspectral unmixing (HU) is a process to extract the underlying endmember signatures (or 
simply endmembers) and the corresponding proportions (abundances) from the observed hyperspectral data 
cloud. The Craig’s criterion (minimum volume simplex enclosing the data cloud) and the Winter’s criterion 
(maximum volume simplex inside the data cloud) are widely used for HU. For perfect identifiability of the 
endmembers, we have recently shown in that the presence of pure pixels (pixels fully contributed by a single 
endmember) for all endmembers is both necessary and sufficient condition for Winter’s criterion, and is a 
sufficient condition for Craig’s criterion. A necessary condition for endmember identifiability (EI) when 
using Craig’s criterion remains unsolved even for three-endmember case. In this work, considering a 
three-endmember scenario, we endeavor a statistical analysis to identify a necessary and statistically 
sufficient condition on the purity level (a measure of mixing levels of the endmembers) of the data, so that 
Craig’s criterion can guarantee perfect identification of endmembers. Precisely, we prove that a purity level 
strictly greater than 1/√2 is necessary for EI, while the same is sufficient for EI with probability-1. Since the 
presence of pure pixels is a very strong requirement which is seldom true in practice, the results of this 
analysis foster the practical applicability of Craig’s criterion over Winter’s criterion, to real-world problems. 
 
 
[C11] A. Ambikapathi, T.-H. Chan, C.-H. Lin, and Chong-Yung Chi, “Convex geometry based 
outlier-insensitive estimation of number of endmembers in hyperspectral images,” in Proc. 5th IEEE 
WHISPERS, Gainesville, Florida, USA, June 25-28, 2013.  
 
Abstract: Accurate estimation of number of endmembers in a given hyperspectral data plays a vital role in 
effective unmixing and identification of the materials present over the scene of interest. The estimation of 
number of endmembers, however, is quite challenging due to the inevitable combined presence of noise and 
outliers. Recently, we have proposed a convex geometry based algorithm, namely geometry based 
estimation of number of endmembers - affine hull (GENE-AH) [1] to reliably estimate the number of 
endmembers in the presence of only noise. In this paper, we will demonstrate that the GENE-AH algorithm 
can be suitably used for reliable estimation of number of endmembers even for data corrupted by both 
outliers and noise, without any prior knowledge about the outliers present in the data. Initially, the 
GENE-AH algorithm (alongside with its inherent endmember extraction algorithm: p-norm-based pure pixel 
identification (TRI-P) algorithm) is used to identify the set of candidate pixels (possibly including the outlier 
pixels) that contribute to the affine dimension of the hyperspectral data. Inspired by the fact that the affine 
hull of the hyperspectral data remains intact for any data set associated with the same endmembers (that may 
not be in the data set), using GENE-AH again on the corrupted data with the identified candidate pixels 
removed, will yield a reliable estimate of the true affine dimension (number of endmembers) of that given 
data. Computer simulations under various scenarios are shown to demonstrate the efficacy of the proposed 
methodology. 
 
 
14 
 
geometry analysis, and compartmental modeling approaches. The open-source MATLAB software of 
CAM-CM is publicly available from the Web.  
 
[J7] Y.-C. Lin, T.-H. Chan, Chong-Yung Chi, S.-H. Ng, H.-L. Liu, K.-C. Wei, Y.-Y. Wai, C.-C. Wang, and 
J.-J. Wang, “Blind estimation of arterial input function in dynamic contrast-enhanced MRI using purity 
maximization,” Magnetic Resonance in Medicine, vol. 68, no. 5, pp. 1439-1449, Nov. 2012. Citations: 1 by 
SCI and 3 by Google Scholar (Impact factor: 3.267) (JCR Journal Ranking: 22/120) 
 
Abstract: Uncertainty in arterial input function (AIF) estimation is one of the major errors in the 
quantification of dynamic contrast enhanced MRI. A blind source separation algorithm was proposed 
to determine the AIF by selecting the voxel time course with maximum purity, which represents a minimal 
contamination from partial volume effects. Simulations were performed to assess the partial volume effect 
on the purity of AIF, the estimation accuracy of the AIF, and the influence of purity on the derived kinetic 
parameters. In vivo data were acquired from six patients with hypopharyngeal cancer and eight rats with 
brain tumor. Results showed that in simulation the AIF with the highest purity is closest to the true AIF. In 
patients, the manually selection had reduced purity, which could lead to underestimations of Ktrans and Ve 
and an overestimation of Vp when compared with those obtained by the proposed blind source separation 
algorithm. The derived kinetic parameters in the tumor were more susceptible to the changes in purity when 
compared with those in the muscle. The animal experiment demonstrated good reproducibility in blind 
source separation- AIF derived parameters. In conclusion, the blind source separation method is feasible and 
reproducible to identify the voxel with the tracer concentration time course closest to the true AIF. 
 
[C12] A. Ambikapathi, T.-H. Chan, K. Keizer, F.-S. Yang, and C.-Y. Chi, “An NBSS algorithm for 
pharmacokinetic analysis of prostate cancer using DCE-MR images,” in Proc. IEEE 2012 International 
Symposium on Biomedical Imaging, Barcelona (ISBI), Spain, May 2-5, 2012, pp. 566-569.  
 
Abstract: Dynamic contrast enhanced magnetic resonance (DCE-MR) imaging is an exciting tool to study 
the pharmacokinetics of a suspected tumor tissue. Nonetheless, the inevitable partial volume effect in 
DCE-MR images may seriously hinder the quantitative analysis of the kinetic parameters. In this work, 
based on the conventional three-tissue compartment model, we propose an unsupervised non-negative blind 
source separation (nBSS) algorithm, called time activity curve (TAC) estimation by projection (TACE-Pro), 
to dissect and characterize the composite signatures in DCE-MR images of patients with prostate cancers. 
The TACE-Pro algorithm first identifies the TACs (up to a scaling ambiguity) with theoretical support. Then 
the problem of scaling ambiguity and the estimation of kinetic parameters is handled by pharmacokinetic 
model fitting. Some Monte Carlo simulations and real DCE-MR image experiments of a patient with 
prostate cancer were performed to demonstrate the superior efficacy of the proposed TACE-Pro algorithm. 
Furthermore, the real data experiments revealed the consistency of the extracted information with the biopsy 
results. 
 
 1 
出席 ISITCE 2010會議心得報告 
                                                             
計畫編號 99-2221-E-007-003-MY3 
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 8/19/2010-8/20/2010, Pohang, Korea  
會議名稱 2010 The 2nd International Symposium on IT Convergence Engineering 
演講題目 Non-Negative Blind Source Separation for Biomedical Image Analysis 
 
 
一、參加會議經過 
筆者於 99年 8月 18日(Wednesday)從桃園中正機場出發，於下午抵達 Pohang, Korea and checked 
in POSTECH。The following is a summary of the major activities and events that I participated in. 
 
8/18 (Wednesday):  
8/19 (Thursday):  
09:15-09:40 Opening Remarks & Introduction 
09:40-09:50 Welcoming Address 
09:50-10:00 Congratulatory Remarks 
10:00-10:40 Keynote Speech 1 Bio-Inspired Research for New Generation Network 
10:40-11:20 Keynote Speech 2 Vehicular Networks and Telematics Applications: Challenges and 
Opportunities 
11:20-12:00 Keynote Speech 3 Green Networks: Reducing Direct and Induced Energy 
Consumption 
14:00-14:30 Convergence of IT in Healthcare: Challenges and Opportunities 
14:30-15:00 Bioelectronics: Challenges, Pitfalls, Perspectives 
15:00-15:30 Non-Negative Blind Source Separation for Biomedical Image Analysis 
15:30-16:00 Sting: A New Platform for Label-Free Biosensing 
16:00-16:30 Multichannel Flexible and Biocompatible Microelectrode for biomedical applications 
16:45-17:15 Stateless and Practical Geographic Routing for Wireless Sensor Networks 
17:15-17:45 Towards Building a Secure Infrastructure on Internet 
17:45-18:15 Building Domain-Specific Search Engine 
18:30-20:30 Symposium Banquet 
 
 1
受邀於香港中文大學訪問演講、參加 2010 IEEE International Conference 
on Image Processing (ICIP-2010, 9/26-29, 2010)心得報告  
2010/10/4  
 
計畫編號 NSC 99-2221-E-007-003-MY3 
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授 
參訪地點 2010/9/26-9/29 The Hong Kong Convention and Exhibition Center  
2010/9/27     The Chinese University of Hong Kong  
 
 
一、參訪香港中文大學訪問演講及參加 ICIP-2010會議經過 (9/26-29)  
 
筆者於 99年 9月 26日(日)上午從桃園機場出發，於當日下午抵達香港，入住位於香港
沙田的 Hyatt Regency Hong Kong旅館。 
 
9月 26日(日)  15:00-18:00 至 2010 ICIP會場(香港會議展覽中心)完成註冊手續。 
 
9月 27日(一)  11:00-17:00訪問香港中大文學，於當日下午 2:30給一場演講如下:  
 
Title: Non-negative Blind Source Separation for Biomedical Image Analysis  
 
Abstract: Non-negative blind source separation (nBSS) is an essential technique to extract non-negative 
source signals from observations without information on how the source signals are mixed in the 
observations. Significant endeavors in developing nBSS are driven by the growing demand in qualitative 
yet quantitative biomedical image analysis. The primary challenge of the existing imaging modalities is 
the inadequate spatial resolution, which consequently makes the value of each image pixel, a mixture of 
multiple non-negative dependent source signals (e.g., normal and tumor tissues in biomedical images). 
Such “mixed pixel problem” would seriously degrade the efficacy of image analysis tools for clinical 
cancer diagnosis. In this talk, two novel nBSS algorithms, namely, non-negative least correlated 
component analysis (nLCA) [1] and convex analysis of mixtures of non-negative sources (CAMNS) [2], 
will be introduced, which, in contrast to independent component analysis based nBSS methods, were 
recently invented without any source statistical independence assumption. What makes these algorithms 
exceptional is their ability to exploit convex analysis and optimization theory to pave the way for novel 
 
THE CHINESE UNIVERSITY OF HONG KONG 
Department of Electronic Engineering 
 
SEMINAR 
 
Non-negative Blind Source Separation for Biomedical Image Analysis  
By 
Professor Chong-Yung Chi 
Institute of Communications Engineering, & Department of Electrical Engineering 
National Tsing Hua University, Hsinchu, Taiwan 
 
Date:  27 Sept, 2010 (Monday)       
Time:  2:30 pm – 4:00 pm              
Venue:         Room 222, Ho Sin Hang Engineering Building, CUHK 
 
Abstract: 
Non-negative blind source separation (nBSS) is an essential technique to extract non-negative source signals from 
observations without information on how the source signals are mixed in the observations. Significant endeavors 
in developing nBSS are driven by the growing demand in qualitative yet quantitative biomedical image analysis. 
The primary challenge of the existing imaging modalities is the inadequate spatial resolution, which consequently 
makes the value of each image pixel, a mixture of multiple non-negative dependent source signals (e.g., normal 
and tumor tissues in biomedical images). Such “mixed pixel problem” would seriously degrade the efficacy of 
image analysis tools for clinical cancer diagnosis. In this talk, two novel nBSS algorithms, namely, non-negative 
least correlated component analysis (nLCA) and convex analysis of mixtures of non-negative sources (CAMNS), 
will be introduced, which, in contrast to independent component analysis based nBSS methods, were recently 
invented without any source statistical independence assumption. What makes these algorithms exceptional is 
their ability to exploit convex analysis and optimization theory to pave the way for novel nBSS criteria along with 
rigorous theoretical proof for perfect source separation. Furthermore, they can be efficiently implemented by 
using any readily available convex optimization solvers and MATLAB source codes of nLCA and CAMNS can 
be found at http://www.ee.nthu.edu.tw/cychi/. We will present some interesting experimental results with real 
dynamic fluorescent images, dynamic contrast-enhanced magnetic resonance images (DCE-MRI), and 
fluorescence microcopy images, which are highly consistent with biomedical and biological expectation. 
 
Biography: 
Dr. Chi received the Ph.D. degree in Electrical Engineering from the University of Southern California, Los 
Angeles, California, in 1983. From 1983 to 1988, he was with the Jet Propulsion Laboratory, Pasadena, California. 
He has been a Professor with the Department of Electrical Engineering since 1989 and the Institute of 
Communications Engineering (ICE) since 1999 (also the Chairman of ICE during 2002-2005), National Tsing 
Hua University, Hsinchu, Taiwan. He has published more than 160 technical papers, including more than 50 
journal papers (mostly in IEEE Trans. Signal Processing), 2 book chapters and more than 100 peer-reviewed 
conference papers, as well as a graduate-level textbook, Blind Equalization and System Identification, Springer-
Verlag, 2006. His current research interests include signal processing for wireless communications, convex 
analysis and optimization for blind source separation, biomedical and hyperspectral image analysis.  
 
Dr. Chi is a senior member of IEEE. He has been a Technical Program Committee member for many IEEE 
sponsored and co-sponsored workshops, symposiums and conferences on signal processing and wireless 
communications, including Co-organizer and General Co-chairman of 2001 IEEE Workshop on Signal 
Processing Advances in Wireless Communications (SPAWC), and Co-Chair of Signal Processing for 
Communications (SPC) Symposium, ChinaCOM 2008 & Lead Co-Chair of SPC Symposium, ChinaCOM 2009. 
He is currently serving as Track Chair for MIMO, Signal Processing, and Smart Antennas, 2011 IEEE Radio and 
Wireless Symposium in Radio and Wireless Week (RWW) 2011. He was an Associate Editor of IEEE Trans. 
Signal Processing (5/2001~4/2006), IEEE Trans. Circuits and Systems II (1/2006-12/2007), IEEE Trans. Circuits 
and Systems I (1/2008-12/2009), Associate Editor of IEEE Signal Processing Letters (6/2006~5/2010), and a 
member of Editorial Board of EURASIP Signal Processing Journal (6/2005~5/2008), and an editor 
(7/2003~12/2005) as well as a Guest Editor (2006) of EURASIP Journal on Applied Signal Processing. Currently, 
he is a member of IEEE Signal Processing Committee on Signal Processing Theory and Methods. 
 
ALL ARE WELCOME 
For enquiries: Prof. W.-K. Ma (wkma@ee.cuhk.edu.hk), Tel: 31634350 
 2 
5/24 (Tuesday): Participated in  
(a) plenary talk (9:00-9:45): Making Sense of a Zettabyte World (by Henry Tirri)  
(b) attended 3 technical sessions as follows:  
1. SPCOM-P1 (10:15-12:15): Capacity, Networking, and Coding 
2. SAM-P2 (13:45-15:45): Source Localization, and  
3. SPCOM-P3 (16:15-18:15): Resource Allocation and Game Theory.  
(c) SPCOM committee meeting (in the evening)  
 
5/25 (Wednesday): Participated in 3 technical sessions as follows:   
1. SPCOM-P4 (09:30:-11:30): MIMO Communications  
2. SPCOM/SAM-P5 (13:45-15:45): MIMO and Sensor Networks  
3. SPCOM-P6 (16:15-18:15): Relay Communication Networks  
 
5/26 (Thursday): Participated in 3 technical sessions as follows:  
1. SPCOM-P7 (09:30:-11:30): Interference Alignment and Multiuser MIMO; 
presented our paper #1 (by Wei-Chiang Li) 
2. IVMSP-P11 (13:45-15:45): Optical Imaging and Remote Sensing; presented our 
paper #2 (by C.-Y. Chi)  
3. SPCOM-P9 (16:15-18:15): Secrecy and Communications; served as session chair.  
 
5/27 (Friday): Participated in 3 technical sessions as follows:  
1. SPCOM-P10 (09:30:-11:30): Channel Estimation  
2. SPCOM-P11 (13:45-15:45): Time Synchronization and Localization  
3. SPCOM-L8 (16:15-18:15): Beamforming and MIMO; presented our paper #3 (by 
Tsung-Hui Chang)  
 
5/28-5/29: Flied from Prague (in the morning 5/28) back to Taiwan, and arrived in桃園中正機場 in 
the morning 5/29。  
 
攜回資料：ICASSP-2011會議論文集之隨身碟一支。  
 
二、與會心得 
 
在本次會期中，筆者所發表 3 篇論文受到許多國際專家學者的關注，在吸收新知及建
立人際關係受益良多。 
 
致謝：感謝國科會補助旅費 for the participation of ICASSP-2011。 
 
link interference as noise), the achievable rate of the ith transmitter-
receiver pair is given by
ri
(
{hki}Kk=1, {wk}Kk=1
)
= log2
(
1 +
∣∣hHiiwi∣∣2∑
k =i |hHkiwk|2 + σ2i
)
.
In this paper, we assume that the channel coefficients hki are
block-faded, and that the transmitters can only acquire the statistical
distribution of the channels. In particular, the elements of hki are
assumed to be circularly symmetric complex Gaussian distributed
with covariance matrix equal to Qki  0 (positive semidefinite),
i.e., hki ∼ CN (0,Qki), for all k, i = 1, . . . ,K. Let Ri > 0 be
the target transmission rate of receiver i. Due to channel fading, the
receivers’ performance may suffer from outage; that is, it would have
a nonzero probability such that ri
({hki}Kk=1, {wk}Kk=1) < Ri. The
i-outage achievable rate region is defined as follows:
Definition 1 [6] Let Pi > 0 denote the power constraint of trans-
mitter i, and let i ∈ (0, 1] denote the maximum tolerable out-
age probability of receiver i, for i = 1, . . . ,K. The rate tuple
(R1, . . . , RK) is said to be achievable if
Pr
{
ri
(
{hki}Kk=1, {wk}Kk=1
)
< Ri
}
≤ i, i = 1, . . . , K
for some (w1, . . . ,wK) ∈ W1 × · · · × WK where Wi  {w ∈
C
Nt | ‖w‖2 ≤ Pi}. The i-outage achievable rate region is given by
R =
⋃
wi∈Wi,
i=1,...,K
{
(R1, . . . , RK)| Pr
{
ri
({hki}Kk=1, {wk}Kk=1) < Ri}
≤ i, i = 1, . . . ,K
}
.
Given the outage specifications 1, . . . , K , it is desirable to
optimize the beamforming vectors {wk}Kk=1 such that the system
can operate on the so-called Pareto boundary of the achievable rate
region R [6], with system utilities such as the (weighted) sum of
R1, . . . , RK being maximized. To this end, we consider the follow-
ing weighted sum rate maximization problem
max
wi∈C
Nt ,Ri≥0,
i=1,...,K
K∑
i=1
αiRi (2a)
s.t. Pr
{
ri
(
{hki}Kk=1, {wk}Kk=1
)
< Ri
}
≤ i,
i = 1, . . . ,K, (2b)
‖wi‖2 ≤ Pi, i = 1, . . . ,K, (2c)
where αi ≥ 0 is the priority weight for the ith transmitter-receiver
pair. Solving problem (2) is challenging because the outage con-
straints in (2b) are difficult to handle. One possible approach to solv-
ing problem (2) is to first obtain a set of Pareto-optimal rate tuples
(R1, . . . , RK) by discretizingR using an exhaustive search method
reported in [6], followed by picking the one that corresponds to the
largest value of
∑K
i=1 αiRi. The complexity of this approach, how-
ever, increases exponentially with K(K − 1)1. In the next section,
based on convex approximation techniques, we present a suboptimal
approach for efficiently handling problem (2).
1The exhaustive search method in [6] samples the achievable rate region
R by discretizing the cross-link interference into a finite number of levels.
LetM be the number of discretization levels. This method then needs to list
a total number of MK(K−1) rate tuples, and finds the one with maximum
∑K
i=1 αiRi. For a rough case ofM = 10 andK = 3, this method requires
to search over 106 rate tuples, which is computationally prohibitive.
3. PROPOSED CONVEX APPROXIMATIONMETHOD
3.1. Closed-Form Expression of Outage Probability
While the probability constraints in (2b) seem intractable, there ac-
tually exist closed-form expressions. To show this, it is noted that
each of the probability in (2b) can be expressed as
Pr
{ ∣∣hHiiwi∣∣2∑
k =i |hHkiwk|2 + σ2i
< 2Ri − 1
}
(3)
which is the left tail probability of the ratio of the exponential ran-
dom variable |hHiiwi|2 to the sum of independent exponential ran-
dom variables |hHkiwk|2 for k = i. According to [8, Appendix I],
(3) has a closed-form expression as
1− e
−(2Ri−1)σ2
i
w
H
i
Qiiwi
∏
k =i
w
H
i Qiiwi
w
H
i Qiiwi + (2
Ri − 1)wHk Qkiwk
. (4)
Hence problem (2) can be equivalently represented by
max
wi∈C
Nt ,Ri≥0,
i=1,...,K
K∑
i=1
αiRi (5)
s.t. ρie
(2Ri−1)σ2
i
w
H
i
Qiiwi
∏
k =i
(
1+
(2Ri − 1)wHk Qkiwk
w
H
i Qiiwi
)
≤ 1,
‖wi‖2 ≤ Pi, i = 1, . . . , K,
where ρi  1− i. It can be seen that (5) is a nonconvex optimiza-
tion problem. Next, we show how to approximate problem (5) by a
convex optimization problem.
3.2. Proposed Convex Approximation Formulation
The approximation method to be presented is conservative, in the
sense that the obtained approximate solution is guaranteed to be fea-
sible to problem (2). To illustrate the proposed method, let us define
exki  Tr(WkQki), e
yi  2Ri − 1, (6a)
zi 
2Ri − 1
Tr(WiQii)
= eyi−xii , (6b)
Wi  wiw
H
i , (6c)
where xki, yi, zi ∈ R are introduced slack variables for k, i =
1, . . . ,K, and Tr(·) denotes the trace of a matrix. Substituting (6)
into (5) yields the following problem
max
Wi∈H
Nt ,Ri≥0,
xki,yi,zi∈R,
k,i=1,...,K
K∑
i=1
αiRi, (7a)
s.t. ρieσ
2
i
zi
∏
k =i
(
1 + e−xii+xki+yi
) ≤ 1, (7b)
Tr(WkQki) ≤ exki , k ∈ Kci , (7c)
Tr(WiQii) ≥ exii , (7d)
2Ri ≤ eyi + 1, (7e)
eyi−xii ≤ zi, (7f)
Tr(Wi) ≤ Pi, (7g)
Wi  0, rank(Wi) = 1, i = 1, . . . ,K, (7h)
3369
0.2 0.4 0.6 0.8 1
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
η
A
v
e
ra
g
e
 A
ch
ie
v
a
b
le
 S
u
m
 R
a
te
 (
b
it
s/
se
c/
H
z)
 
 
Optimal Sum Rate by [6]
Proposed Method
TDMA
1/σ
2
=20dB
1/σ
2
=0dB
1/σ
2
=10dB
Fig. 1. Average achievable sum rate versus η for K = 2, Nt = 4,
and rank(Qki) = 4 for all k, i.
and set 1 = · · · = K = 0.1, i.e., 10% outage probability. For the
proposed approximation algorithm (Algorithm 1), we set δ = 10−2
and use CVX [7] to handle the associated problem (12). All the
simulation results were obtained by averaging over 500 trials.
In the first example, we examine the approximation accuracy
of the proposed method by comparing with the optimal sum rate
obtained by the exhaustive search method in [6]. Figure 1 shows the
simulation results of average achievable rate versus η for K = 2
and Nt = 4. The achievable rate of the simple TDMA scheme
is also shown in this figure. Firstly, one can see from this figure
that the sum rate achieved by the proposed method approaches that
of TDMA with increased η; TDMA exhibits a constant sum rate
for all η because there is no cross-link interference for this scheme.
Secondly, we observe that the proposed method can exactly attain the
average optimal sum rate for 1/σ2 = 0 dB and 1/σ2 = 10 dB. For
1/σ2 = 20 dB and for η ≥ 0.5 (interference dominated scenarios),
it can be observed that there is a small gap between the rate achieved
by the proposed method and the optimal rate. Nevertheless, this gap
is within 3% of the optimal sum rate on average.
In the second example, we compare the proposed method with
the MRT scheme and TDMA for Nt = K = 4. Figure 2 shows
the results of average sum rate versus 1/σ2. Note that, for the case
of K = 4, the exhaustive search method in [6] is too complex to
implement, and thus no result for the optimal sum rate is shown.
From Fig. 2, we can observe that the proposed method achieves the
highest sum rate among the three methods, no matter when η = 0.2
or η = 1. One can also see that, for η = 0.2 and 1/σ2 < 5 dB,
MRT can yield a sum rate comparable to the proposed method and
outperforms TDMA; whereas TDMA performs better for η = 1.
In order to compare with the ZF scheme, in the third example,
we extend the number of antennas to 8 (Nt = 8) and constrain the
ranks of all channel covariance matrices to 2. The simulation results
are shown in Fig. 3. As seen from this figure, the proposed method
still performs best compared to the other three schemes. On the other
hand, one can see that ZF can achieve a higher average sum rate than
TDMA, and also outperforms MRT for η = 1.
5. REFERENCES
[1] V. R. Cadambe and S. A. Jafar, “Interference alignment and degrees of
freedom of the d-user interference channel,” IEEE Trans. Inf. Theory,
vol. 54, pp. 3425–3441, Aug. 2008.
[2] X. Shang, B. Chen, and H. V. Poor, “On the optimality of beamforming
0 5 10 15 20
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
1/σ
2
 (dB)
A
v
e
ra
g
e
 A
c
h
ie
v
a
b
le
 S
u
m
 R
a
te
 (
b
it
s
/s
e
c
/H
z
)
 
 
Proposed Method, η=0.2
Proposed Method, η=1
MRT, η=0.2
MRT, η=1
TDMA
Fig. 2. Average achievable sum rate versus 1/σ2 for K = Nt = 4,
and rank(Qki) = 4 for all k, i.
0 5 10 15 20
0
1
2
3
4
5
6
7
8
9
10
1/σ
2
 (dB)
A
v
e
ra
g
e
 A
c
h
ie
v
a
b
le
 S
u
m
 R
a
te
 (
b
it
s
/s
e
c
/H
z
)
 
 
Proposed Method, η=0.2
Proposed Method, η=1
MRT, η=0.2
MRT, η=1
ZF
TDMA
Fig. 3. Average achievable sum rate versus 1/σ2 for K = 4, Nt =
8, and rank(Qki) = 2 for all k, i.
for multi-user MISO interference channels with single-user detection,”
in Proc. IEEE GLOBECOM, Honolulu, Hawaii, USA, Nov. 30-Dec. 4,
2009, pp. 1–5.
[3] E. A. Jorswieck, E. G. Larsson, and D. Danev, “Complete characteriza-
tion of the Pareto boundary for the MISO interference channel,” IEEE
Trans. Signal Process., vol. 56, pp. 5292–5296, July 2008.
[4] R. Zhang and S. Cui, “Cooperative interference management with MISO
beamforming,” IEEE Trans. Signal Process., vol. 58, pp. 5450–5458,
Oct. 2010.
[5] E. G. Larsson, E. A. Jorswieck, J. Lindblom, and R. Mochaourab,
“Game theory and the flat-fading Gaussian interference channel,” IEEE
Signal Process. Mag., pp. 18–27, Sept. 2009.
[6] J. Lindblom, E. Karipidis, and E. G. Larsson, “Outage rate regions for
the MISO IFC,” in Proc. 43rd Asilomar Conference, Pacific Grove, CA,
Nov. 1-4, 2009, pp. 1120–1124.
[7] M. Grant and S. Boyd, “CVX: Matlab software for disciplined convex
programming,” http://stanford.edu/∼boyd/cvx, June 2009.
[8] S. Kandukuri and S. Boyd, “Optimal power control in interference-
limited fading wireless channels with outage-probability specifications,”
IEEE Trans. Wireless Commun., vol. 1, pp. 46–55, Jan. 2002.
[9] Z.-Q. Luo, W.-K. Ma, A. M.-C. So, Y. Ye, and S. Zhang, “Semidefinite
relaxation of quadratic optimization problems,” IEEE Signal Process.
Mag., pp. 20–34, May 2010.
3371
R
N is the nth abundance vector comprisingN fractional abundances
and L is the total number of observed pixel vectors.
EE algorithms aim to estimate the endmember signature matrix
A from the observed hyperspectral pixel vectors (or simply pixels)
x[1], . . . ,x[L], assuming that N is known a priori. The following
are the general assumptions in HU:
(A1) (Non-negativity condition) si[n] ≥ 0 ∀i, n.
(A2) (Full additivity condition)   N
i=1 si[n] = 1 ∀n.
(A3) min{L,M} ≥ N andA is of full column rank.
(A4) (Pure pixel assumption) There exists an index set
{l1, l2, . . . , lN}, such that x[li] = ai, for i = 1, . . . , N .
3. DIMENSION REDUCTION
Like many other HU algorithms [1], we begin with dimension reduc-
tion of the observed pixels. The affine set fitting procedure in [10] is
utilized for dimension reduction. The dimension-reduced pixel vec-
tors x˜[n] are obtained by the following affine transformation of x[n]:
x˜[n] = CT (x[n]− d) ∈ RN−1, (2)
where (C,d) is the affine set fitting solution given by
d =
1
L
L

n=1
x[n], (3)
C = [ q1(UU
T ), q2(UU
T ), . . . , qN−1(UU
T ) ], (4)
in whichU = [ x[1]− d, . . . ,x[L]− d ] ∈ RM×L, and qi(UUT )
denotes the unit-norm eigenvector associated with the ith principal
eigenvalue of the matrixUUT . Further, due to (A2), and by substi-
tuting the signal model (1) into (2), we have
x˜[n] =
N

j=1
sj [n]αj , (5)
where
αj = C
T (aj − d) ∈ R
N−1 (6)
is the jth dimension-reduced endmember, by finding which, the cor-
responding aj can be obtained by aj = Cαj + d,∀j [10]. Also, it
follows from (5) that under (A4),
x˜[li] = αi, ∀i, (7)
and x˜[n] lies in the simplex [11] formed by α1, . . . ,αN [10].
4. SIMPLEX ESTIMATION BY PROJECTION
In this section, let us present the new EE algorithm, SIMPLE-Pro.
We begin by considering the p-norm of the dimension-reduced data
cloud X˜ = [ x˜[1], . . . , x˜[L] ]. By the triangle inequality, (A1), and
(A2), one can infer from (5) that for all n,
‖x˜[n]‖p ≤
N

i=1
si[n]‖αi‖p ≤ max
i=1,...,N
{‖αi‖p}, (8)
where p ≥ 1. The inequality in (8) holds with equality if and only if
n = li (a pure pixel index) for any i ∈ arg maxk=1,...,N{‖αk‖p}
(by (7)). Thus, a dimension-reduced endmember can be identified as
stated in the following lemma:
Lemma 1. Under (A1)-(A4), a dimension-reduced endmember can
be identified by
αi = x˜[li], (9)
for any li ∈ arg maxn=1,...,L{‖x˜[n]‖p}.
α1
(0, 0)
α2
d
x˜[n]
yTd = 0
x˜[n]Td
α3 = x˜[l3], l3 ∈ arg minn{x˜[n]
Td}
Fig. 1. Illustration of SIMPLE-Pro for N = 3. Assume that α1 and
α2 have been found. The vector d is orthogonal to the affine hull of
α1 and α2 and the third endmember is found as α3 = x˜[l3], where
l3 ∈ arg minn=1,...,L{x˜[n]
T d}.
Now, suppose that the dimension-reduced endmembers
α1, . . . , αk (where k < N ) are already identified. To find the other
endmembers, we consider the following optimization problem:
min
d∈RN−1
‖d‖22 (10)
s.t. d ∈ aﬀ{α1, . . . ,αk},
where aﬀ{α1, . . . ,αk} is the affine hull of {α1, . . . ,αk}, defined
as [11]
aﬀ{α1, . . . ,αk} =   x =
k

i=1
θiαi 



1
T
k θ = 1, θ ∈ R
k  , (11)
in which θ = [θ1, . . . , θk]T . Note that (10) is a quadratic convex
problem, and it can be easily shown that its closed-form solution is:
d
 = (I−BB†)αk = P
⊥
Bαk, (12)
whereB = [α1 − αk, . . . ,αk−1 − αk] ∈ R(N−1)×(k−1) and P⊥B
is the orthogonal complement projector of B. By projecting all the
dimension-reduced data onto d, and by (A1) and (A2), we have
x˜[n]Td =
N

i=1
si[n]α
T
i d
 ≥ min
i=1,...,N
{αTi d
}, (13)
and the inequality in (13) holds with equality if and only if n = lz
for any z ∈ arg mini{αTi d}. The (k + 1)th dimension-reduced
endmember can then be found as αk+1 = x˜[lz] where
lz ∈ arg min
n=1,...,L
{x˜[n]T d}. (14)
The above procedure is illustrated in Figure 1, for the N = 3 case.
Next, in the following lemma we show that x˜[lz] is different from
those endmember estimates already found.
Lemma 2. Suppose that {α1, . . . ,αk} is the set of endmembers
already found and d is obtained by (12). Then, under (A1)-(A4),
x˜[lz] ∈ {αk+1, ..., αN} for any lz ∈ arg minn=1,...,L{x˜[n]T d}.
Proof: It is well known that the projector P⊥B satisfies P⊥BB = 0,
implying
P
⊥
B(αq − αk) = 0, q = 1, . . . , k − 1. (15)
1370
Table 3. Average φen (degrees) and average computation time Tc (secs) over the various EE methods for different purity levels (ρ) and SNRs.
Methods ρ
φen (degrees)
Tc (secs)SNR (dB)
0 5 10 15 20 25 30 35 40
N-FINDR
0.6 19.61 14.95 11.13 9.14 8.41 8.42 8.57 8.53 8.60
0.8 19.08 14.49 10.39 8.03 6.51 6.31 5.31 5.25 5.25 3.61
1 19.06 14.42 10.55 8.02 5.47 2.93 1.38 0.85 0.53
VCA
0.6 19.34 14.75 10.84 8.74 8.00 7.71 8.32 9.13 9.19
0.8 18.94 14.14 10.24 7.87 6.61 5.92 8.01 7.60 7.12 0.66
1 18.83 14.14 10.15 8.03 5.86 3.72 8.49 7.56 6.25
SGA
0.6 18.77 14.16 10.68 8.69 7.83 7.74 7.72 7.58 7.61
0.8 18.30 13.89 10.12 7.77 6.72 6.09 5.62 5.49 5.37 0.35
1 18.40 13.93 10.20 8.02 6.09 3.37 1.24 0.75 0.41
SIMPLE-Pro
0.6 19.09 14.27 10.58 8.63 7.89 7.92 7.83 7.65 7.63
0.8 18.49 13.63 10.18 7.78 6.50 6.25 5.74 5.67 5.48 0.21
1 18.34 13.74 10.07 7.99 5.93 3.63 1.32 0.79 0.47
0.6 19.98 14.77 10.99 8.45 7.92 7.79 7.66 7.77 7.74
TRI-P 0.8 19.42 14.35 10.11 7.79 6.41 5.70 5.14 4.78 4.54 0.22
(p = 2) 1 19.40 14.53 10.25 7.69 5.68 3.19 1.13 0.63 0.36
6. SIMULATIONS AND CONCLUSIONS
The performance evaluation of the proposed two EE algorithms,
SIMPLE-Pro and TRI-P (with p = 2), by simulation is presented
in this section. Other EE algorithms that are compared are N-
FINDR, VCA, and SGA. The root-mean-square (rms) spectral angle
φen [7,10] between the true and the estimated endmember signatures
is used as the performance index. In the simulations the number of
endmembers is 12 (N = 12) and the number of observed pixels is
1000 (L = 1000). The endmember signatures are chosen from the
USGS library [12], and it has 224 bands (M = 224). In each run,
1000 noise-free observed pixel vectors were synthetically generated
following the signal model in (1), and the abundance vectors s[n]
were generated following Dirichlet distribution (as in [7]), for dif-
ferent purity levels ρ [10]. The noisy data were generated by adding
independent and identically distributed zero-mean Gaussian noise to
the noise-free data for different signal-to-noise ratios (SNRs), where
SNR=   Ln=1 ‖x[n]‖
2
2/MLσ
2 and σ2 is the noise variance. For
each scenario 100 independent runs are performed and the average
φen (over 100 runs) and the average computation time Tc (over all
the scenarios under consideration) of each algorithm (implemented
in Matlab R2008a and running in a desktop computer equipped with
Dual Core CPU 2.80 GHz, 2 GB memory) are calculated, for differ-
ent purity levels (ρ = 0.6, 0.8, 1) and SNRs ranging from 0 dB to
40 dB, in steps of 5 dB.
The obtained simulation results are shown in Table 3. The bold-
faced numbers in Table 3 correspond to the minimum rms spectral
angle for a specific pair of (ρ, SNR), over all the algorithms under
test. It can be observed from Table 3 that although the performances
of all the EE algorithms are competitive, SIMPLE-Pro and TRI-P
still outperform the other algorithms in most of the scenarios. On
the other hand, the average computation times (Tcs) for SIMPLE-
Pro and TRI-P are almost the same and they are about 17 times, 3
times and 1.5 times smaller than that of N-FINDR, VCA, and SGA,
respectively. These simulation results demonstrate the efficacy and
computational efficiency of the proposed two EE algorithms.
In summary, we have presented two effective and computation-
ally efficient EE algorithms namely, SIMPLE-Pro and TRI-P and
we have theoretically proved their endmember identifiability under
the assumptions (A1)-(A4). It is shown via simulations that either
SIMPLE-Pro or TRI-P yields the best performance in most of the
scenarios under consideration, and the computational complexities
of SIMPLE-Pro and TRI-P are lower than some existing benchmark
EE algorithms. The application of SIMPLE-Pro and TRI-P algo-
rithms to real hyperspectral data is currently under investigation.
7. REFERENCES
[1] N. Keshava and J. Mustard, “Spectral unmixing,” IEEE Signal Process.
Mag., vol. 19, no. 1, pp. 44-57, Jan. 2002.
[2] J. W. Boardman, F. A. Kruse, and R. O. Green, “Mapping target signa-
tures via partial unmixing of AVIRIS data,” in Proc. Summ. JPL Air-
borne Earth Sci. Workshop, Pasadena, CA, Dec. 9-14, 1995, pp. 23-26.
[3] M. E. Winter, “N-findr: An algorithm for fast autonomous spectral
end-member determination in hyperspectral data,” in Proc. SPIE Conf.
Imaging Spectrometry, Pasadena, CA, Oct. 1999, pp. 266-275.
[4] A. Ifarraguerri and C.-I. Chang, “Multispectral and hyperspectral im-
age analysis with convex cones,” IEEE Trans. Geosci. Remote Sens.,
vol. 37, no. 2, pp. 756-770, Mar. 1999.
[5] C. I. Chang, C. C. Wu, W. M. Liu, and Y. C. Ouyang, “A new grow-
ing method for simplex-based endmember extraction algorithm,” IEEE
Trans. Geosci. Remote Sens., vol. 44, no. 10, pp. 2804-2819, Oct. 2006.
[6] C. I. Chang, C. C. Wu, C. S. Lo, and M. L. Chang, “Real-time simplex
growing algorithms for hyperspectral endmember extraction,” IEEE
Trans. Geosci. Remote Sens., vol. 48, no. 4, pp. 1834-1850, Apr. 2010.
[7] J. M. P. Nascimento and J. M. B. Dias, “Vertex component analysis:
A fast algorithm to unmix hyperspectral data,” IEEE Trans. Geosci.
Remote Sens., vol. 43, no. 4, pp. 898-910, Apr. 2005.
[8] T.-H. Chan, C.-Y. Chi, W.-K. Ma, and A. Ambikapathi, “Hyperspec-
tral unmixing from a convex analysis and optimization perspective,” in
Proc. First IEEE WHISPERS, Grenoble, France, Aug. 26-28, 2009.
[9] D. Heinz and C.-I. Chang, “Fully constrained least squares linear
mixture analysis for material quantification in hyperspectral imagery,”
IEEE Trans. Geosci. Remote Sens., vol. 39, no. 3, pp. 529-545, 2001.
[10] T.-H. Chan, C.-Y. Chi, Y.-M. Huang, and W.-K. Ma, “A convex analy-
sis based minimum-volume enclosing simplex algorithm for hyper-
spectral unmixing,” IEEE Trans. Signal Processing, vol. 57, no. 11,
pp. 4418-4432, Nov. 2009.
[11] S. Boyd and L. Vandenberghe, Convex Optimization, UK: Cambridge
Univ. Press, 2004.
[12] Tech. Rep., Available online: http://speclab.cr.usgs.gov/
cuprite.html.
1372
that si(t) has zero mean and E{|si(t)|2} = 1 for all i. The SINR of
receiver i can be obtained from (1) as
SINRi =
|hHi wi|2∑K
k =i |hHi wk|2 + σ2i
. (2)
The goal of transmit beamforming is to design the beamforming vec-
tors {wi}Ki=1 such that each of the receivers can achieve a desired
SINR performance. To this end, the following design formulation
has been frequently employed:
min
wi∈C
Nt ,
i=1,...,K
K∑
i=1
‖wi‖2 (3a)
s.t.
|hHi wi|2∑K
k =i |hHi wk|2 + σ2i
≥ γi, i = 1, . . . ,K, (3b)
where ‖ · ‖ denotes the vector Euclidean norm, and γi > 0 stands
for the preset target SINR value of receiver i. The design problem
(3) aims to find a most power efficient beamforming solution such
that the target SINR requirements γi are satisfied. There is more
than one way to solve problem (3); e.g., by using uplink-downlink
duality, by using SDR, or by using a second-order cone program
(SOCP) reformulation [7, 8]. Readers are referred to the literature,
such as [9], for coverage of this aspect.
2.1. Probabilistic SINR Constrained Robust Beamforming
The conventional design formulation in (3) assumes that the trans-
mitter has perfect knowledge of the channels {hi}Ki=1. In practical
wireless environments, however, the transmitter may only have in-
accurate CSI due to imperfect channel estimation and limited feed-
back. Let h¯1, . . . , h¯K ∈ CNt denote the channel estimates at the
transmitter. The true channels can be expressed as
hi = h¯i + ei, i = 1, . . . ,K, (4)
where ei ∈ CNt represents the CSI error vector. In the presence
of CSI errors, the beamforming solution of problem (3), denoted by
{wi }Ki=1, may no longer guarantee the SINR requirements in (3b),
that is, for some ei, it is possible to have
|(h¯i + ei)Hwi |2∑K
k =i |(h¯i + ei)Hwk|2 + σ2i
< γi. (5)
It is desirable to design the beamforming vectors {wi}Ki=1 such that
(5) occurs only with a small probability.
To this end, we assume that the CSI errors are complex Gaus-
sian random vectors with zero mean and covariance matrix Ci  0
(positive semidefinite, PSD), i.e.,
ei ∼ CN (0,Ci), i = 1, . . . ,K. (6)
This model is particularly suitable for CSI errors caused by imperfect
channel estimation. Let ρi ∈ (0, 1] denotes the maximum tolerable
SINR outage probability of receiver i. We consider the following
robust beamforming design formulation [2]:
min
wi∈C
Nt ,
i=1,...,K
K∑
i=1
‖wi‖2 (7a)
s.t. Pr
{
|(h¯i + ei)Hwi|2∑K
k =i |(h¯i + ei)Hwk|2 + σ2i
≥ γi
}
≥ 1− ρi,
i = 1, . . . ,K. (7b)
It can be seen that problem (7) finds a most power efficient beam-
forming solution such that the 1 − ρi SINR satisfaction probability
is achieved. Solving problem (7) is a challenging task because the
probabilistic SINR constraints in (7b) have no closed-form expres-
sion and are not convex in general. To obtain approximate solutions
satisfying (7b), efficient convex conservative formulations have been
proposed; see [2, 4]. In the next section, we present a new conser-
vative formulation for problem (7) that will be shown to outperform
the existing methods.
3. PROPOSED CONSERVATIVE FORMULATION
3.1. Bernstein-type Inequality Based Conservative Approach
To present the proposed method, let us express the CSI errors as
ei = C
1/2
i vi, i = 1, . . . , K, (8)
where C1/2i  0 is the PSD square root of Ci, and vi ∈ CNt
is a normalized complex Gaussian random vector with zero mean
and covariance matrix I (the Nt by Nt identity matrix), i.e., vi ∼
CN (0, I). With this expression, the probabilistic constraints in (7b)
can be expressed as
Pr
{
v
H
i Qi(w1, . . . ,wK)vi + 2Re
{
v
H
i ui(w1, . . . ,wK)
}
≥ ci(w1, . . . ,wK)
}
≥ 1− ρi, i = 1, . . . ,K, (9)
whereRe{·} represents the real part of the associated argument, and
Qi(w1, . . . ,wK)  C
1/2
i
( 1
γi
wiw
H
i −
∑
k =i
wkw
H
k
)
C
1/2
i , (10a)
ui(w1, . . . ,wK)  C
1/2
i
( 1
γi
wiw
H
i −
∑
k =i
wkw
H
k
)
h¯i, (10b)
ci(w1, . . . ,wK)  σ
2
i − h¯Hi
( 1
γi
wiw
H
i −
∑
k =i
wkw
H
k
)
h¯i. (10c)
Note that (9) is a probability inequality involving a quadratic form
of complex Gaussian random variables. The idea of conservative ap-
proaches is to find computationally tractable forms that are sufficient
to achieve (9). To implement this idea, we use the following lemma:
Lemma 1 [6] Let G = vHQv + 2Re{vHu} where Q ∈ HNt is
a complex Hermitian matrix2, u ∈ CNt , and v ∼ CN (0, I). Then
for any δ > 0, we have
Pr
{
G ≥ Tr(Q)−
√
2δ
√
‖Q‖2F +2‖u‖2 − δs+(Q)
}
≥ 1− e−δ,
(11)
where s+(Q) = max{λmax(−Q), 0} in which λmax(−Q) denotes
the maximum eigenvalue of matrix−Q, and ‖·‖F denotes the matrix
Frobenius norm.
The inequality in (11) is a Bernstein-type inequality, which bounds
the probability that the quadratic form G of complex Gaussian ran-
dom variables deviates from its mean Tr(Q). Let δ  − ln(ρ)
where ρ ∈ (0, 1]. Lemma 1 implies that the inequality
Pr
{
v
H
Qv + 2Re{vHu} ≥ c
}
≥ 1− ρ (12)
2Here, HN is the set of all N -by-N complex Hermitian matrices.
3081
5 10 15 20 25
0
10
20
30
40
50
60
70
80
90
100
F
e
a
s
ib
ili
ty
 r
a
te
 (
%
)
 
 
Proposed formulation (16) with bisection
Formulation in [4] with bisection
Formulation I in [2] with bisection
Proposed formulation (16)
Formulation in [4]
Formulation I in [2]
γ (dB)
Fig. 1. Feasibility rate (%) versus target SINR γ.
As seen, the proposed formulation in (16) exhibits a higher feasibil-
ity rate than the other two methods. When the bisection technique is
employed, we can see that all methods have improved performance;
whereas the proposed method still has the highest feasibility rate.
In the second example, we compare the average transmission
powers of the three formulations. Five hundred sets of {h¯i}3i=1 were
randomly generated, and 135 sets of them were selected for which
all the methods under test are feasible for γ = 11 dB. The 135 sets
of channel estimates were used to test the six methods for various
values of γ, and the average transmission power of each method was
obtained by averaging over these channel realizations. Note that the
average power would be set to infinity if there exist at least one chan-
nel realizations such that the method under test is infeasible. Figure 2
shows the simulation results. One can observe from this figure that
the proposed method yields less average transmission powers than
the other two methods, regardless of whether bisection is used or
not. In fact, it is observed in simulations that the proposed method
always consumes the least power for every feasible channel realiza-
tion. The results in Fig. 1 and Fig. 2 imply that the proposed method
is amenable to support a wider range of target SINRs.
In the last example, we examine the average computation time
(in seconds) of CVX for solving the proposed method and the meth-
ods in [2] and [4]. The simulation results for γ = 7 dB over 50
feasible channel realizations are shown in Fig. 3. We can see that
the proposed method has a larger computation time than the method
in [4]; this shows that there is a tradeoff between complexity and
performance for these two methods. On the other hand, we can ob-
serve from this figure that both the proposed method and that in [4]
are computationally cheaper than the method in [2], especially when
Nt = K ≥ 3.
5. REFERENCES
[1] B. K. Chalise, S. Shahbazpanahi, A. Czylwik, and A. B. Gershman,
“Robust downlink beamforming based on outage probability specifica-
tions,” IEEE Trans. Wireless Commun., vol. 6, no. 10, pp. 3498–3503,
Oct. 2007.
[2] M. B. Shenouda and T. N. Davidson, “Probabilistically-constrained ap-
proaches to the design of the multiple antenna downlink,” in Proc. 42nd
Asilomar Conference, Pacific Grove, Oct. 26-29, 2008, pp. 1120–1124.
[3] ——, “Outage-based designs for multi-user transceivers,” in Proc.
IEEE ICASSP, Taipei, Taiwan, Apr. 19-24, 2009, pp. 2389–2392.
[4] K.-Y. Wang, T.-H. Chang, W.-K. Ma, and C.-Y. Chi, “A semidefinite
relaxation based conservative approach to robust transmit beamform-
1 3 5 7 9 11 13 15 17 19 21
−15
−10
−5
0
5
10
15
20
25
A
v
e
ra
g
e
 t
ra
n
s
m
is
s
io
n
 p
o
w
e
r 
(d
B
)
 
 
Formulation I in [2]
Formulation in [4] 
Proposed formulation (16)
Formulation I in [2] with bisection
Formulation in [4] with bisection 
Proposed formulation (16) with bisection 
4
5
6
7
8
 
 
γ (dB)
Fig. 2. Average transmission power (dB) versus target SINR γ.
1 2 3 4 5 6 7 8 9 10 11
0
10
20
30
40
50
60
70
80
90
100
110
A
v
e
ra
g
e
 c
o
m
p
u
ta
ti
o
n
 t
im
e
 (
s
e
c
s)
 
 
Formulation I in [2]
Proposed formulation (16)
Formulation in [4]
Nt = K
Fig. 3. Average computation time (secs) versus number of transmit
antennas Nt (Nt = K).
ing with probabilistic SINR constraints,” in Proc. EUSIPCO, Aalborg,
Denmark, Aug. 23-27, 2010, pp. 407–411.
[5] A. Ben-Tal and A. Nemirovski, “On safe tractable approximations
of chance-constrained linear matrix inequalities,” Math Oper. Res.,
vol. 34, no. 1, pp. 1–25, Feb. 2009.
[6] I. Bechar, “A Bernstein-type inequality for stochastic processes
of quadratic forms of Gaussian variables,” avaliable online:
http://arxiv.org/abs/0909.3595.
[7] F. Rashid-Farrokhi, K. J. R. Liu, and L. Tassiulas, “Transmit beam-
forming and power control for cellular wireless systems,” IEEE J. Sel.
Areas Commun., vol. 16, no. 8, pp. 1437–1450, Oct. 1999.
[8] M. Bengtsson and B. Ottersten, “Optimal and suboptimal transmit
beamforming,” Chapter 18 in Handbook of Antennas in Wireless Com-
munications, L. C. Godara, Ed., CRC Press, Aug. 2001.
[9] A. B. Gershman, N. D. Sidiropoulos, S. Shahbazpanahi, M. Bengtsson,
and B. Ottersten, “Convex optimization-based beamforming,” IEEE
Signal Process. Mag., pp. 62–75, May 2010.
[10] Z.-Q. Luo, W.-K. Ma, A. M.-C. So, Y. Ye, and S. Zhang, “Semidefinite
relaxation of quadratic optimization problems,” IEEE Signal Process.
Mag., pp. 20–34, May 2010.
[11] M. Grant and S. Boyd, “CVX: Matlab software for disciplined convex
programming,” http://stanford.edu/∼boyd/cvx, Jun. 2009.
3083
 2 
(c) Tue -Ses2-O (11:20-12:20): Applications of Machine Learning  
(d) Tue -Ses3-S (13:20-15:00): Special Session 
(e) Tue -Ses4-C (15:30-16:30): MLSP Data Competition 
(f) Tue -Ses5-O (16:30-17:30): Information-Theoretic Learning 
(g) 19:00-22:00: Banquet Dinner 
 
9/21 (Wednesday): Participated in  
(a) Keynote Speech (8:50-9:50): Large-scale Audio and Video Content Analysis and 
Identification (by Dr. Kunio Kashino, NTT Communication Science Laboratories, 
Japan)  
(b) Wed-Ses1-O (10:20-11:20): Independent Component Analysis  
(c) Wed -Ses2-O (11:20-12:20): Learning Theory and Algorithms 
(d) 參訪北京交通大學，並公開演講，講題及摘要如下(演講公告請參閱附件一 ):  
Title: Distributed Robust Multi-Cell Coordinated Beamforming with Imperfect 
CSI: An ADMM Approach  
Abstract: Multi-cell coordinated beamforming (MCBF), where multiple base stations (BSs) 
collaborate with each other in the beamforming design for mitigating the inter-cell interference, has 
been a subject drawing great attention recently. Most MCBF designs assume perfect channel state 
information (CSI) of mobile stations (MSs); however CSI errors are inevitable at the BSs in practice. 
Assuming elliptically bounded CSI errors, this paper studies the robust MCBF design problem that 
minimizes the weighted sum power of BSs subject to worst-case signal-to-interference-plus-noise 
ratio (SINR) constraints on the MSs. Our goal is to devise a distributed optimization method that can 
obtain the worst-case robust beamforming solutions in a decentralized fashion, with only local CSI 
used at each BS and little backhaul signaling for message exchange between BSs. However, the 
considered problem is difficult to handle even in the centralized form. We first propose an efficient 
approximation method in the centralized form, based on the semidefinite relaxation (SDR) technique. 
To obtain the robust beamforming solution in a decentralized fashion, we further propose a 
distributed robust MCBF algorithm, using a distributed convex optimization technique known as 
alternating direction method of multiplier (ADMM). We analytically show the convergence of the 
proposed distributed robust MCBF algorithm to the optimal centralized solution and its better 
bandwidth efficiency in backhaul signaling over the existing dual decomposition based algorithms. 
Simulation results are presented to examine the effectiveness of the proposed SDR method and the 
distributed robust MCBF algorithm.  
 
9/22 (Thursday): 參訪北京清華大學，並公開演講，講題及摘要如上(演講公告請參閱附件二) 
9/23 (Friday): 從北京首都機場搭機返台，於中午返抵桃園國際機場。 
 
攜回資料：MLSP-2011會議論文集之隨身碟一支。  
Distributed Robust Multi-Cell Coordinated 
Beamforming with Imperfect CSI: An ADMM Approach
“与大师面对面”名师讲坛
Bibliography
Chong-Yung Chi (祁忠勇 ) rece ived the Ph .D .
degree in Electrical Engineering from the University
of Southern California, Los Angeles, California, in
1983. From 1983 to 1988, he was with the Jet
Propulsion Laboratory, Pasadena, California. He has
been a Professor with the Department of Electrical
E n g i n e e r i n g s i n c e 1 9 8 9 a n d t h e I n s t i t u t e o f
Communications Engineering (ICE) since 1999 (also
the Chairman of ICE during 2002-2005), National
Tsing Hua Universi ty, Hsinchu, Taiwan. He has
Published more than 170 technical papers, including more
than 60 journal papers (mostly in IEEE Trans. Signal Processing), 2 book chapters
and more than 100 peer-reviewed conference papers, as well as a graduate-level
textbook, Blind Equalization and System Identification, Springer-Verlag, 2006. His
current research interests include signal processing for wireless communications,
convex analysis and optimization for blind source separation, biomedical and
hyperspectral image analysis.
Dr. Chi is a senior member of IEEE. He has been a Technical Program Committee
member for many IEEE sponsored and co-sponsored workshops, symposiums and
conferences on signal processing and wireless communications, including Co-
organizer and General Co-chairman of 2001 IEEE Workshop on Signal Processing
Advances in Wireless Communications (SPAWC), and Co-Chair of Signal
Processing for Communications (SPC) Symposium, ChinaCOM 2008 & Lead Co-
Chair of SPC Symposium, ChinaCOM 2009. He was an Associate Editor of IEEE
Trans. Signal Processing (5/2001~4/2006), IEEE Trans. Circuits and Systems II
(1/2006-12/2007), IEEE Trans. Circuits and Systems I (1/2008-12/2009), Associate
Editor of IEEE Signal Processing Letters (6/2006~5/2010), and a member of
Editorial Board of EURASIP Signal Processing Journal (6/2005~5/2008), and an
editor (7/2003~12/2005) as well as a Guest Editor (2006) of EURASIP Journal on
Applied Signal Processing. He was a member of IEEE Signal Processing Committee
on Signal Processing Theory and Methods (2005-2010). Currently, he is a member
of IEEE Signal Processing Committee on Signal Processing for Communications
and Networking.
Abstract
Multi-cell coordinated beamforming (MCBF), where multiple base
stations (BSs) collaborate with each other in the beamforming
design for mitigating the inter-cell interference, has been a subject
drawing great attention recently. Most MCBF designs assume
perfect channel state information (CSI) of mobile stations (MSs);
however CSI errors are inevitable at the BSs in practice. Assuming
elliptically bounded CSI errors, this paper studies the robust
MCBF design problem that minimizes the weighted sum power of
BSs subject to worst-case signal-to-interference-plus-noise ratio
(SINR) constraints on the MSs. Our goal is to devise a distributed
optimization method that can obtain the worst-case robust
beamforming solutions in a decentralized fashion, with only local
CSI used at each BS and little backhaul signaling for message
exchange between BSs. However, the considered problem is
difficult to handle even in the centralized form. We first propose an
efficient approximation method in the centralized form, based on
the semidefinite relaxation (SDR) technique. To obtain the robust
beamforming solution in a decentralized fashion, we further
propose a distributed robust MCBF algorithm, using a distributed
convex optimization technique known as alternating direction
method of multiplier (ADMM). We analytically show the
convergence of the proposed distributed robust MCBF algorithm to
the optimal centralized solution and its better bandwidth efficiency
in backhaul signaling over the existing dual decomposition based
algorithms. Simulation results are presented to examine the
effectiveness of the proposed SDR method and the distributed
robust MCBF algorithm.
Address: 九教北307B会议室
Time: 2011-9-21 15:00
Liaison professor:裘正定教授
2011 IEEE International Workshop on Machine Learning for Signal Processing
September 18-21, 2011, Beijing, China
978-1-4577-1623-2/11/$26.00 c©2011 IEEE
FAST ALTERNATING VOLUME MAXIMIZATION ALGORITHM FOR BLIND SEPARATION
OF NON-NEGATIVE SOURCES
Tsung-Han Chan†, Chang-Jin Song†, ArulMurugan Ambikapathi†, Chong-Yung Chi†, and Wing-Kin Ma∗
†Inst. Commun. Eng., National Tsing Hua Univ. ∗Dept. Electronic Eng., Chinese Univ. Hong Kong
Hsinchu, 30013 Shatin, N.T., Hong Kong
E-mail: {tsunghan@mx,cychi@ee}.nthu.edu.tw E-mail: wkma@ieee.org
ABSTRACT
We recently reported an iterative non-negative blind source sepa-
ration (nBSS) method, called convex analysis of mixtures of non-
negative sources via alternating volume maximization (CAMNS-
AVM) [1], and demonstrated that it provides promising separation
performance in image analysis. Nonetheless, the amount of data
may be quite large in practical applications, and this may limit
the real-time applicability of CAMNS-AVM. In this paper, we pro-
pose a fast CAMNS-AVM algorithm involving three complexity re-
duction methods, specifically problem equivalence, redundant con-
straints removal, and customized algorithm implementation. The
problem equivalence provides sufficiency in solving one linear pro-
gram (LP) for each partial volume maximization problem, rather
than the two LPs required by the original CAMNS-AVM. Then,
we remove redundant constraints of each LP involved in CAMNS-
AVM by using Quickhull algorithm to enumerate all the extreme
points of the constraint-set-constructed convex hull. Finally, we im-
plement a customized primal-dual interior-point method (IPM) for
LP. Some Monte Carlo simulation results demonstrate that the fast
CAMNS-AVM algorithm is thirty times more computationally effi-
cient than the original CAMNS-AVM algorithm, without any perfor-
mance loss.
Index Terms— Non-negative blind source separation, Com-
plexity reduction, Alternating volume maximization, Linear pro-
gramming, Interior-point method
1. INTRODUCTION
Non-negative blind source separation (nBSS) is a signal processing
procedure to separate non-negative source signals from the given ob-
servations without any prior information about how the non-negative
sources are linearly mixed, and it has been applied to a wide range
of science and engineering problems, such as biomedical image
analysis [2], hyperspectral image analysis [3], and analytical chem-
istry [4]. The sources of interest in these real-world applications
(e.g., tissue responses and mineral distributions) are in general statis-
tically correlated, which makes the application of most non-negative
independent component analysis (ICA) methods ineffective [5, 6].
Advances in nBSS without involving any statistical assumptions in-
clude non-negative matrix factorization (NMF) [7] and convex anal-
ysis of mixtures of non-negative sources (CAMNS) [1, 8], to name
a few. NMF may suffer from non-unique decomposition issues [7]
and some remedies by considering the sparseness of the sources were
This work is supported by the National Science Council under Grants
NSC 99-2221-E-007-003-MY3, and by a General Research Fund of
Hong Kong Research Grant Council (Project No. CUHK415509).
reported in [9]. CAMNS [1, 8] is a convex geometry based frame-
work, where the nBSS problem is formulated as a problem of find-
ing the extreme points of an observation-constructed polyhedral set.
Two methods for practically locating the extreme points were re-
ported [1,8]. One is called CAMNS-LP [8] that uses linear program
(LP) and the orthogonal projection to find the extreme points in a
systematic manner, while the other called CAMNS via alternating
volume maximization (CAMNS-AVM) [1] shows better robustness
against model mismatches than CAMNS-LP. However, in practical
applications, the size of the data to be processed may be quite large,
and thus hinder their real-time applicability.
In this paper, three complexity reduction methods, namely prob-
lem equivalence, redundant constraints removal, and customized al-
gorithm implementation, are proposed for improving the speed of
CAMNS-AVM algorithm. In the original CAMNS-AVM [1], the
volume maximization problem can be handled by alternating op-
timization, and each associated partial maximization problem re-
quires solving two linear programs (LPs). We first show that the
volume maximization problem has an equivalent problem, by virtue
of which each partial maximization problem involves solving one
LP to obtain the global optimal solution of the original partial max-
imization problem. Furthermore, because each LP considered may
involve lots of redundant linear inequality constraints, the second
method is to remove those redundant constraints. We first trans-
form the constraint set into an equivalent convex hull representa-
tion, by virtue of which the redundant constraint removal problem
is converted into an extreme point enumeration problem. Then, the
extreme points can be identified by the well-known Quickhull algo-
rithm [10]. The third method is to implement a customized primal-
dual interior-point method (IPM) for solving LPs. Finally, some
simulation results demonstrate the computation efficiency of the pro-
posed fast CAMNS-AVM over the original CAMNS-AVM.
Notations: 1N , IN , and ei represent the N × 1 all-one vector,
the N ×N identity matrix, and the unit column vector with the ith
entry equal to 1, respectively; “  ”, “ ◦ ”, and “‖ · ‖2” stand for
componentwise inequality, Hadamard product, and Euclidean norm,
respectively; x−1 and [x]i denote the componentwise inverse of x
and the ith element of x, respectively; diag(x) is the diagonal ma-
trix with its diagonal entries being the elements of x and det(X)
denotes the determinant of the square matrixX.
2. REVIEW OF CAMNS-AVM ALGORITHM
Consider a scenario that there areM noise-free observations which
are linearly mixed from N sources, as given below:
xi =
N∑
j=1
aijsj , i = 1, . . . ,M, (1)
2.2. Alternating Volume Maximization for CAMNS
The volume maximization problem is formulated as follows [1]:
{β1 , . . . ,βN} = arg max
β1,...,βN∈F
vol(β1, . . . ,βN ) (7)
≡ arg max
β1,...,βN∈F
|det (Δ(β1, . . . ,βN ))| , (8)
where vol(β1, . . . ,βN) is the volume of conv{β1, . . . ,βN} [11],
Δ(β1, . . . ,βN) =
[
β1 · · · βN
1 · · · 1
]
∈ RN×N , (9)
and {β1 , . . . ,βN} is the estimate of the set of extreme points
{α1, ...,αN}.
Problem (8) is a difficult, nonconvex problem, but it can be
handled by alternating optimization. Consider the cofactor expan-
sion for det(Δ(β1, . . . ,βN)) along the jth column for any j ∈
{1, . . . , N}:
det(Δ(β1, . . . ,βN )) = b
T
j βj + (−1)N+jdet(BNj) (10)
where bj = [(−1)i+jdet(Bij)]N−1i=1 and Bij is the submatrix of
Δ(β1, . . . ,βN) with ith row and jth column removed. The par-
tial maximization with respect to βj with all the other βis fixed is
expressed as follows:
max
βj∈F
|bTj βj + (−1)N+jdet(BNj)|. (11)
Such a partial maximization problem can be globally solved by the
following two LPs:
p = max
βj∈F
bTj βj + (−1)N+jdet(BNj), (12a)
q = min
βj∈F
bTj βj + (−1)N+jdet(BNj). (12b)
The optimal solution of (11) is chosen as the optimal solution of
(12a) if |p| > |q|, and is that of (12b) if |q| > |p|. Problem (12)
can be implemented by available LP solvers, such as SeDuMi [12]
and CVX [13]. The partial maximization problem (12) is solved
cyclically (i.e., j := (j modulo N ) +1) until some predefined stop-
ping rule is satisfied. Here, each cycle corresponds to an update of
{β1, ...,βN}. Denoting the outcome of the above described alter-
nating volume maximization process by {βˆ1, . . . , βˆN}, the sources
can be estimated by
sˆj = Cβˆj + d. (13)
The CAMNS-AVM algorithm is summarized in Table 1.
3. FAST CAMNS-AVM ALGORITHM
In this section, we propose three complexity reduction methods for
CAMNS-AVM (respectively in each subsection) so that its compu-
tational efficiency can be significantly improved.
3.1. Volume maximization problem equivalence
We first show the Problem (8) can be simplified. By basic matrix
analysis, det(G) = −det(H) ifH results fromG by interchanging
any two column or row vectors. Then, an optimal solution of (8) such
that det(Δ(β1 , . . . ,β

N )) ≥ 0 always exists. Problem (8) therefore
can be simplified to
max
β1,...,βN∈F
det(Δ(β1, . . . ,βN)). (14)
Table 1. CAMNS-AVM algorithm.
Given a convergence tolerance ε > 0,C and d obtained by (3), and
the set of dimension-reduced observations X = {CT (xi −
d), i = 1, . . . ,M }.
Step 1. initialize β1, . . . ,βN by randomly choosing N vectors from
X , compute  := | det(Δ(β1, . . . ,βN))|, and set j := 1.
Step 2. update bj := [(−1)i+jdet(Bij)]N−1i=1 where Bij is a sub-
matrix of Δ(β1, . . . ,βN ) with the ith row and jth column
removed.
Step 3. solve the LPs (12a) and (12b) by SeDuMi [12] or CVX [13]
and obtain their optimal solutions, denoted by β¯j and β
j
,
respectively.
Step 4. if |p| > |q|, then update βj := β¯j ; otherwise, update
βj := β
j
.
Step 5. if (j modulo N) = 0, then j := j + 1, and go to Step 2,
else compute ′ := |det(Δ(β1, . . . ,βN))|,
if |′ − |/ < ε, then βˆi = βi for i = 1, . . . , N ,
otherwise, set ′ := , j := 1, and go to Step 2.
Step 6. output the source estimates sˆj = Cβˆj + d, j = 1, . . . , N .
By the cofactor expansion for det(Δ(β1, . . . ,βN )) in (10), the par-
tial maximization problem associated with (14) can be solved by
considering only (12a) rather than by the two LPs (12a) and (12b)
in the original CAMNS-AVM. In the next two subsections, we will
present how the computational complexity in solving the LP in (12a)
can be further reduced.
3.2. Removal of Redundant Constraints
As observed in Figure 2, the polyhedral set F is the set of inter-
section of L halfspaces, in which there may exist many redundant
constraints. We derive an equivalent representation of F that in-
volves a much less amount of inequality constraints, as described in
the following proposition:
Proposition 1. The polyhedral set F given by (5a) is identical to
F = {α ∈ RN−1 | C¯α+ d¯  0}, (15)
where C¯ = [cl1 , . . . , clr ]
T and d¯ = [dl1 , . . . , dlr ]
T . Here,
{cl1/dl1 , . . . , clr/dlr} is the set of the extreme points of
conv
{
c1/d1, . . . , cL/dL
}
and r is the number of its extreme points.
The proof of Proposition 1 is given in Appendix. Proposition 1 trans-
forms the problem of redundant constraints removal for F to the
problem of finding extreme points of conv
{
c1/d1, . . . , cL/dL
}
, or
known as the extreme point enumeration problem in the optimization
literature.
Extreme point enumeration has been widely investigated in the
past three decades [14]. The complexity of the existing extreme
point enumeration algorithms would increase exponentially with the
number of data points. Nevertheless, Quickhull, a well-known point
enumeration algorithm [10], has been found to be computationally
efficient in many practical applications [15]. In our simulations to
be presented in Section 4, we use Quickhull algorithm to find the
extreme points of conv
{
c1/d1, . . . , cL/dL
}
, and the extra compu-
tation time overhead of Quickhull is also taken into account while
calculating the total time consumption of the proposed fast CAMNS-
AVM algorithm.
Table 4. The average SSE and the computation time T per realization for performance and complexity comparison of the original CAMNS-
AVM (Case A) with different complexity reduction methods used (Cases B, C, and D), where Case D is the proposed fast CAMNS-AVM
algorithm.
Methods number of constraints SSE (dB) T (secs)
Case A:
Original CAMNS-AVM
L =76800 17.46 103.22
-using SeDuMi to solve 2 LPs in (12)
Case B:
CAMNS-AVM
L =76800 17.46 59.33
-using SeDuMi to solve 1 LP in (12a)
Case C:
(i) CAMNS-AVM
L =76800 17.46 22.82
-using customized IPM to solve (12a)
(ii) CAMNS-AVM
r =976 17.46 4.39
-using Quickhull to find (15) and SeDuMi to solve (12a)
Case D:
Fast CAMNS-AVM
r =976 17.46 3.27
-using Quickhull to find (15) and customized IPM to solve (12a)
T in Case B is almost twice less than that in Case A. By using the
customized IPM and the warm start mechanism, the computation
time T in Case C(i) is more than twice less than that in Case B,
while the computation time T in Case C(ii) is significantly smaller
than that in Case B, because all the redundant inequality constraints
((L − r)/L ≈ 98.73%) in F have been removed. The computa-
tion time T in Case D is less than that in Case C(i) and Case C(ii) by
around 19 and 1 seconds, respectively. As a result, the total computa-
tion time of the proposed fast CAMNS-AVM (Case D) is more than
thirty times less than that of the original CAMNS-AVM (Case A).
Let us emphasize again that the computation time overhead required
by Quickhull algorithm has been incorporated in whole computation
time calculation for Case C and Case D.
One typical realization among the 100 independent runs is
shown in Figure 3, where all of the separated images have been prop-
erly ordered for ease of visual comparison. One can see that the im-
ages extracted by the original CAMNS-AVM and the proposed fast
CAMNS-AVM are exactly the same, which again validates that the
fast CAMNS-AVM algorithm achieves the same performance with
much less computation time.
5. CONCLUSION
We have proposed a fast CAMNS-AVM algorithm given in Table 3
which employs the three computational complexity reduction meth-
ods, namely problem equivalence, redundant constraints removal,
and customized IPM implementation, to reduce the computational
complexity of the original CAMNS-AVM without any performance
loss. The presented simulation results have shown that any combi-
nations of the three proposed complexity reduction methods can im-
prove the computational efficiency of the original CAMNS-AVM,
and the proposed fast CAMNS-AVM algorithm (with all the three
proposed methods applied) is much faster (thirty times) than the
original CAMNS-AVM. From the algorithm implementation point
of view, the former is therefore much more suitable for practical ap-
plications than the latter in spite of the same performance.
6. APPENDIX
Since xi  0, ∀i in image applications and the data where xi[n] =
0, ∀i can be removed without loss of practicality, we have d  0 by
(3). Then, an equivalent form of (5b) can be written as
F = {α ∈ RN−1 ∣∣ vTα ≤ 1,v ∈ V}, (23)
where vn = −cn/dn and V = {v1, . . . ,vL}. It has been pointed
out in [17] that F is known as the polar dual of V . Hence, we have
the following property
Property 1. ( [17]) A vector vn ∈ V is (not) an extreme point of
conv{V} if and only if vTnα ≤ 1 is active (redundant) in F .
Suppose that vl1 , . . . ,vlr are the extreme points of conv
{V}. By
(23) and Property 1, F can be fully represented by the active con-
straints; i.e.,
F = {α ∈ RN−1∣∣ vTα ≤ 1, v ∈ {vl1 , . . . ,vlr}}. (24)
Hence, (15) directly follows from (24). 
7. REFERENCES
[1] W.-K. Ma, T.-H. Chan, C.-Y. Chi, and Y. Wang, “Convex anal-
ysis for non-negative blind source separation with application
in imaging,” in Chapter 7, Convex Optimization in Signal Pro-
cessing and Communications, Editors: D. P. Palomar and Y. C.
Eldar, UK: Cambridge University Press, 2010.
[2] Y. Wang, J. Xuan, R. Srikanchana, and P. L. Choyke, “Modeling
and reconstruction of mixed functional and molecular patterns,”
Intl. J. of Biomed. Imag., vol. 2006, pp. 1–9, 2006.
[3] N. Keshava and J. Mustard, “Spectral unmixing,” IEEE Signal
Process. Mag., vol. 19, no. 1, pp. 44–57, Jan. 2002.
[4] E. R. Malinowski, Factor Analysis in Chemistry, John Wiley,
New York, 2002.
[5] M. D. Plumbley, “Algorithms for non-negative independent
component analysis,” IEEE Trans. Neural Netw., vol. 14, no.
3, pp. 534–543, 2003.
[6] S. Moussaoui, D. Brie, A. Mohammad-Djafari, and C. Carteret,
“Separation of non-negative mixture of non-negative sources us-
ing a Bayesian approach and MCMC sampling,” IEEE Trans.
Signal Process., vol. 54, no. 11, pp. 4133–4145, Nov. 2006.
[7] D. Lee and H. S. Seung, “Learning the parts of objects by non-
negative matrix factorization,” Nature, vol. 401, pp. 788–791,
Oct. 1999.
[8] T.-H. Chan, W.-K. Ma, C.-Y. Chi, and Y. Wang, “A convex anal-
ysis framework for blind separation of non-negative sources,”
IEEE Trans. Signal Process., vol. 56, no. 10, pp. 5120–5134,
Oct. 2008.
[9] P. O. Hoyer, “Non-negative matrix factorization with sparseness
constraints,” J. of Mach. Learn. Research, vol. 5, pp. 1457–
1469, 2004.
[10] C. B. Barber, D. P. Dobkin and H. Huhdanpaa, “The quickhull
algorithm for convex hulls,” ACM Trans. Math. Software, vol.
22, pp. 469–483, 1996.
 1 
出席 ICASSP-2012國際學術會議心得報告 
                                                             
計畫編號 NSC 99-2221-E-007-003-MY3  
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 3/25/2012-3/30/2012, Kyoto, Japan  
會議名稱 
2012 IEEE International Conference on Acoustics, Speech, and Signal Processing 
(ICASSP-2012)  
發表論文題目 
#1.  Optimal Transmission Strategy For Outage Rate Maximization in MISO 
Fading Channels With Training (Kun-Yu Wang, Tsung-Hui Chang, Wing-Kin 
Ma, Chong-Yung Chi)  
#2.  Convex Geometry Based Estimation of Number in Hyperspectral Images 
(ArulMurugan Ambikapathi, Tsung-Han Chan, Chong-Yung Chi)  
#3.  Fast Algorithms for Robust Hyperspectral Endmember Extraction Based on 
Worst-Case Simplex Volume Maximization (Tsung-Han Chan, Ji-Yuan Liu, 
ArulMurugan Ambikapathi, Wing-Kin Ma, Chong-Yung Chi)  
 
一、參加會議經過 
 
筆者於 101年 3月 25日 (Sunday morning) 從桃園中正機場出發，於 3月 25日 (Sunday afternoon)
抵達 Kyoto, Japan. The following is a summary of the major activities and events that I participated 
in. 
 
3/25(Saturday): Tour at Kyoto.   
3/26 (Monday):  
(a) 完成報到手續 and met international friends and experts;  
(b) attended Tutorial 8 (09:30-12:30): Very Large MIMO systems (by Erik G. Larsson, 
Linkoping University and Fredrik Tufvesson, Lund University);   
(c) attended Tutorial 11 (14:00-17:00): Convex and Non-convex Approaches for 
Low-dimensional Models (by Volkan Cevher, Ecole Polytechnique Federale de Lausanne, 
and Mario Figueiredo, Institute de Telecomunicacoes, Instituto Superior Tecnio)  
 
3/27 (Tuesday): Participated in  
(a) 09:30-11:30 Opening Ceremony and Awards; 
(b) 12:30-14:00 IEEE Transactions on Signal Processing Editorial Board Meeting;  
(c) 14:00-16:00 SPCOM-P1.9： served as the Session Chair and presented Paper #1 (Optimal 
CONVEX GEOMETRY BASED ESTIMATION OF NUMBER OF ENDMEMBERS IN
HYPERSPECTRAL IMAGES
ArulMurugan Ambikapathi, Tsung-Han Chan, and Chong-Yung Chi
Inst. Commun. Eng., National Tsing Hua Univ., Hsinchu, Taiwan
E-mail: aareul@ieee.org,(tsunghan@mx,cychi@ee).nthu.edu.tw
ABSTRACT
Hyperspectral unmixing is a process of decomposing the hyperspec-
tral data cube into endmember signatures and their corresponding
abundance maps. For the unmixing results to be completely inter-
pretable, the number of materials (or endmembers) present in that
area should be known a priori, which however is unknown in prac-
tice. In this work, we use hyperspectral data geometry and succes-
sive endmember estimation strategy of an endmember extraction al-
gorithm (EEA) to develop two novel algorithms for estimating the
number of endmembers, namely geometry based estimation of num-
ber of endmembers - convex hull (GENE-CH) algorithm and affine
hull (GENE-AH) algorithm. The proposed GENE algorithms esti-
mate the number of endmembers by using Neyman-Pearson hypoth-
esis testing over the endmembers sequentially estimated by an EEA
until the estimate of the number of endmembers is obtained. Monte-
Carlo simulations demonstrate the efficacy of the proposed GENE
algorithms, compared to some existing benchmark methods for esti-
mating number of endmembers.
Index Terms— Hyperspectral unmixing, Successive endmem-
ber extraction, Estimation of number of endmembers, Neyman-
Pearson hypothesis testing
1. INTRODUCTION
Hyperspectral unmixing (HU) is a process of decomposing the hy-
perspectral observations over multiple bands into a collection of
endmember signatures and their corresponding proportions or abun-
dances, under the assumption that the number of substances (or end-
members) present in that geographical area of interest is given a pri-
ori. Existing methods for estimating the number of endmembers can
be broadly classified into two categories: information theoretic cri-
teria based methods and eigenvalue thresholding methods. The in-
formation theoretic criteria based algorithms include Akaike’s infor-
mation criterion (AIC) [1], minimum description length (MDL) [2],
and Bayesian information criterion (BIC) [3], to name a few. The
estimation results of these algorithms may suffer from model mis-
match errors resulting from incorrect prior information [4]. The
eigenvalue thresholding based algorithms include Neyman-Pearson
detection theory based method [5] (also referred to as virtual dimen-
sionality (VD) in [4]), and hyperspectral signal subspace identifica-
tion by minimum error (HySiMe) [6], to name a few.
In this work, we propose two hyperspectral data geometry based
algorithms for estimating the number of endmembers, namely ge-
ometry based estimation of number of endmembers - convex hull
(GENE-CH) algorithm and affine hull (GENE-AH) algorithm. The
proposed algorithms exploit successive estimation property of a
pure-pixel based EEA, and aim to decide when the EEA should stop
This work was supported by the National Science Council (R.O.C.) un-
der Grant NSC 99-2221-E-007-003-MY3.
estimating the next endmember. The GENE-CH and GENE-AH al-
gorithms are devised based on the data geometry fact that all the
observed pixel vectors should lie in the convex hull (CH) and affine
hull (AH) of the endmember signatures, respectively. In the noisy
scenario, the decision of whether the current endmember estimate
is in the CH/AH of the previously found endmembers can be for-
mulated as a binary hypothesis testing problem, which can be dealt
using Neyman-Pearson detection theory. The performances of the
proposed GENE algorithms are demonstrated through Monte-Carlo
simulations for various scenarios.
The notations used throughout this paper are standard. RM and
R
M×N represent a set of real M × 1 vectors and M × N matri-
ces, respectively, 1N represents an N × 1 all-one vector and 0 is
an all-zero vector of proper dimension. The symbol  denotes the
componentwise inequality, ‖ ·‖2 represents the Euclidean norm, and
N (μ,Σ) denotes Gaussian distribution with mean vector μ and co-
variance matrix Σ.
2. PROBLEM STATEMENT AND ASSUMPTIONS
Owing to low spatial resolution, each observed pixel vector repre-
sents a mixture of multiple distinct substances and each pixel vector
of the hyperspectral images measured over M spectral bands can
then be represented by the following M ×N linear mixing model:
y[n] = x[n] +w[n], (1)
x[n] = As[n] =
N∑
i=1
si[n]ai, ∀n = 1, . . . , L. (2)
In (1), y[n] = [ y1[n], . . . , yM [n] ]T denotes the nth observed pixel
vector comprising M spectral bands, x[n] = [ x1[n], . . . , xM [n] ]T
is its noise-free counterpart, and w[n] = [ w1[n], . . . , wM [n] ]T is
the noise vector. In (2), A = [ a1, . . . ,aN ] ∈ RM×N is the end-
member signature matrix with the ith column vector ai being the ith
endmember signature, s[n] = [ s1[n], . . . , sN [n] ]T ∈ RN is the
nth abundance vector comprising N fractional abundances, and L is
the total number of observed pixels. The noise vector w[n] is inde-
pendent and identically distributed (i.i.d.) zero-mean Gaussian with
covariance matrix D = E{w[n]w[n]T } = diag(σ21 , . . . , σ
2
M ), an
M ×M diagonal matrix with the ith diagonal entry σ2i denoting
the noise variance in the ith spectral band.
Estimation of the number of endmembers is to estimate N from
the given hyperspectral data y[1], ...,y[L]. Generally, hyperspectral
image analysis has the following standard non-statistical assump-
tions: (A1) si[n] ≥ 0 ∀i, n, (A2)
∑N
i=1 si[n] = 1 ∀n, (A3)
min{L,M} ≥ N and A is of full column rank, (A4) (Pure pixel
assumption) there exists at least an index set {l1, . . . , lN} such that
x[li] = ai, for i = 1, . . . , N .
Two important convex geometry concepts, namely affine hull
and convex hull [7], which will play a significant role in the en-
1233978-1-4673-0046-9/12/$26.00 ©2012 IEEE ICASSP 2012
• If x˜[lk] ∈ conv{x˜[l1], . . . , x˜[lk−1]}, then it implies that
x˜[lk]−
∑k−1
i=1 θ
′
ix˜[li] = 0, for some θ
′
= [θ
′
1, . . . , θ
′
k−1]
T 
0, 1Tk−1θ
′
= 1. In the noise-free case (i.e., y˜[li] = x˜[li], for
all i), θ = θ
′
and e = 0, while in the presence of noise
θ 	 θ
′
, implying that e can be approximated as a random
vector with distribution N (0, ξΣ) where Σ has been de-
fined in (10) and
ξ = 1 + θ21 + θ
2
2 + · · ·+ θ
2
k−1 (21)
since w˜[n] is i.i.d.
• If x˜[lk] 
∈ conv{x˜[l1], . . . , x˜[lk−1]}, then e ∼ N (μk, ξΣ).
Now let us define
r = eT (ξΣ)−1e. (22)
When x˜[lk] ∈ conv{x˜[l1], . . . , x˜[lk−1]}, it is easy to see that r can
be approximated as a random variable following central Chi-square
distribution χ2(Z), and otherwise r follows non-central Chi-square
distribution Nχ2(Z,μk) [11] where Z = Nmax−1 denotes the de-
grees of freedom. Hence, we consider the following two hypotheses:
H0 (x˜[lk] ∈ conv{x˜[l1], . . . , x˜[lk−1]}) : r ∼ χ
2(Z),
H1 (x˜[lk] 
∈ conv{x˜[l1], . . . , x˜[lk−1]}) : r ∼ Nχ
2(Z,μk).
Since μk is unknown so is Nχ2(Z,μk), we use Neyman-Pearson
classifier rule for the above hypothesis testing problem:
DecideH0 if r < κ (23a)
DecideH1 if r > κ, (23b)
Denoting the probability density function (pdf) of the central Chi-
square distribution by fχ2(x, Z), we define
ψ(r) 
∫ ∞
r
fχ2(x,Z)dx = 1−
γ(r/2, Z/2)
Γ(Z/2)
, (24)
where γ(x/2, Z/2) is the lower incomplete Gamma function [12].
Then, by Neyman-Pearson lemma [9], the optimal threshold κ for
problem (23) satisfies
ψ(κ) = PFA, (25)
where PFA is the preassigned acceptable false alarm rate. There is no
closed-form expression for the inverse function of ψ(·), and hence
we formulate the decision rule in (23) to
DecideH0 if ψ(r) > PFA, (26a)
DecideH1 if ψ(r) < PFA. (26b)
The integral ψ(r) defined in (24) can be easily computed by using
available packages such as MATLAB. Once ψ(r) is evaluated, one
of the two hypotheses is decided, based on (26). The pseudo-code of
the proposed GENE-CH algorithm is given in Table 1.
4.2. GENE-Affine Hull (GENE-AH) Algorithm
When (A4) is violated, the dimension-reduced endmembers esti-
mated by an EEA can also be expressed as in (14), where
x˜[li] =
N∑
j=1
sj [li]αj , ∀i = 1, . . . , k. (27)
Table 1. Pseudo-codes of GENE-CH and GENE-AH algorithms.
Given noisy hyperspectral data y[n], maximum number of endmembers
N ≤ Nmax ≤ M , false alarm probability PFA, and estimate of
noise covariance matrix D; a chosen successive EEA.
Step 1. Compute (C,d) given by (6) and (7).
Step 2. Obtain the first pixel index l1 by the successive EEA and compute
y˜[l1] by (5). Set k = 2.
Step 3. Obtain the kth pixel index lk by the successive EEA and compute
y˜[lk] by (5), and form Ak−1 by (17).
Step 4. Use Sedumi [10] to solve
problem (16) for GENE-CH
problem (28) for GENE-AH
for the optimal θ and e = y˜[lk]−Ak−1θ.
Step 5. Compute r = eT (ξΣ)−1e, where ξ = 1 + θTθ and Σ =
C
TDC, and ψ(r) by (24).
Step 6. If ψ(r) > PFA, then output k − 1 as the estimate of N , else
k := k + 1 and if k ≤ Nmax go to Step 3.
For such hyperspectral data, it can be shown that GENE-CH may
result in an overestimation of the number of endmembers. Hence we
next propose the GENE-AH algorithm which does not require the
pure pixel assumption (A4). The GENE-AH algorithm uses the fact
(F2), which states that in the noise-free case, the affine dimension
of aﬀ{x˜[1], . . . , x˜[L]} is N − 1. This implies that in the noise-free
case, if x˜[lk] ∈ aﬀ{x˜[l1], . . . , x˜[lk−1]}, then k ≥ N+1. Here again
we use Neyman-Pearson hypothesis [9] testing to find the smallest
k such that the hypothesis x˜[lk] ∈ aﬀ{x˜[l1], . . . , x˜[lk−1]} is true
with the given PFA, based on noisy y˜[l1], . . . , y˜[lk]. As in (16), we
consider solving the following constrained least squares problem:
θ
 = arg min
1
T
k−1
θ=1
‖y˜[lk]−Ak−1θ‖
2
2, (28)
whereAk−1 has been defined in (17). By defining the optimal fitting
error vector e as in (18), we have the following inferences:
• if x˜[lk] ∈ aﬀ{x˜[l1], . . . , x˜[lk−1]}, then it can be approxi-
mated that e ∼ N (0, ξΣ).
• if x˜[lk] 
∈ aﬀ{x˜[l1], . . . , x˜[lk−1]}, then e ∼ N (μk, ξΣ),
where μk, ξ, and Σ have been defined in (20), (21), and (10),
respectively. Defining the random variable r as in (22), a similar
Neyman-Pearson hypothesis testing procedure can be devised for
GENE-AH to estimate the number of endmembers present in the
data. The procedure for GENE-AH is also summarized in Table 1.
Most existing benchmark algorithms are directly or indirectly
developed based on that the range space of the endmembers is the
same as that of the hyperspectral data, i.e., they are based only on
(A3) (or subspace geometry). However, the GENE algorithms not
only make use of (A3), but also (A2) (or affine geometry) for GENE-
AH algorithm, and (A1) and (A2) (or convex geometry) for GENE-
CH algorithm. The advantages of considering the assumptions (A1)
and (A2) on abundances will be more evident in the simulations.
It should be noted that the performance of both GENE-CH and
GENE-AH algorithms depends on the performance of the succes-
sive EEA used. Hence, the successive EEA algorithm employed by
both GENE-CH and GENE-AH algorithms need to be reproducible
(without any initialization) and can sequentially provide endmem-
ber estimates without repetition. For instance, one successive EEA
recently proposed in [13], called p-norm based pure pixel identifi-
cation (TRI-P) algorithm, not only possesses the above performance
1235
FAST ALGORITHMS FOR ROBUST HYPERSPECTRAL ENDMEMBER EXTRACTION
BASED ON WORST-CASE SIMPLEX VOLUME MAXIMIZATION
Tsung-Han Chan†, Ji-Yuan Liou†, ArulMurugan Ambikapathi†, Wing-Kin Ma∗ and Chong-Yung Chi†
†Inst. Commun. Eng., National Tsinghua Univ. ∗Dept. Electronic Eng., Chinese Univ. Hong Kong
Hsinchu, Taiwan Shatin, N.T., Hong Kong
E-mail: {thchan,aareul}@ieee.org E-mail: wkma@ieee.org
ABSTRACT
Hyperspectral endmember extraction (EE) is to estimate endmem-
ber signatures (or material spectra) from the hyperspectral data of an
unexplored area for analyzing the materials and their composition
therein. However, the presence of noise in the data posts a serious
problem for EE. Recently, robustness against noise has been taken
into account in the design of EE algorithms. The robust maximum-
volume simplex criterion [1] has been shown to yield performance
improvement in the noisy scenario, but its real applicability is lim-
ited by its high implementation complexity. In this paper, we pro-
pose two fast algorithms to approximate this robust criterion [1],
which turns out to deal with a set of partial max-min optimization
problems in alternating manner and successive manner, respectively.
Some Monte Carlo simulations demonstrate the superior computa-
tional efficiency and efficacy of the proposed robust algorithms in
the noisy scenario over the robust algorithm in [1] and some bench-
mark EE algorithms.
Index Terms— Hyperspectral images, Robust endmember ex-
traction, Simplex volume maximization, Fast algorithms
1. INTRODUCTION
Hyperspectral endmember extraction (EE) has been applied in many
fields, such as space object detection, environmental monitoring and
military surveillance [2]. However, the presence of noise in hy-
perspectral data is inevitable, and may seriously degrade the per-
formance of EE algorithms. Existing efforts that account for noise
effects include joint Bayesian algorithm (JBA) [3], split augmented
Lagrangian (SISAL) [4], robust minimum volume enclosing algo-
rithm (RMVES) [5], and others [6], but none of them are based on
popular Winter’s maximum-volume simplex criterion [7–9].
Very recently, we have proposed a robust generalization of Win-
ter’s criterion in the noisy scenario [1], and formulated the robust
Winter criterion as a worst-case simplex volume maximization prob-
lem. An algorithm called worst-case alternating volume maximiza-
tion (WAVMAX) that practically realizes the robust Winter criterion
has also been proposed [1], but it is quite computationally expen-
sive for large data sizes. In this work, we develop two computa-
tionally efficient algorithms to implement the robust Winter criterion
reported in [1]. The proposed algorithms, named alternating decou-
pled volume max-min (ADVMM) and successive decoupled volume
max-min (SDVMM), deal with the worst-case simplex volume max-
imization problem by alternating optimization and by successive op-
timization, respectively. These optimization principles have been ex-
ploited by predecessors of ADVMM and SDVMM; i.e., alternating
This work was supported by the National Science Council (R.O.C.) un-
der Grant NSC 99-2221-E-007-003-MY3, and by a General Research Fund
of Hong Kong Research Grant Council (Project No. CUHK415509).
volume maximization (AVMAX) and successive volume maximiza-
tion (SVMAX) [1] that fulfill the original Winter’s criterion. Some
simulations are presented to demonstrate the efficiency and efficacy
of the proposed fast robust algorithms.
Notations: RN and RM×N denote set of real N × 1 vectors and
set of real M × N matrices, respectively; 1N , IN , and ei repre-
sent N × 1 all-one vector, N ×N identity matrix, and unit column
vector with the ith entry equal to 1, respectively; “  ”, “‖ · ‖”,
and “ \ ” stand for componentwise inequality, Euclidean norm, and
set difference, respectively; det(X) and X† denote the determinant
and pseudo-inverse of the matrix X, respectively; [x]1:i is an i × 1
column vector formed by the first i elements in x.
2. PROBLEM STATEMENT AND ASSUMPTIONS
Consider a M ×N linear spectral mixing model [2]:
y[n] = As[n] +w[n], n = 1, . . . , L, (1)
where y[n] = [ y1[n], . . . , yM [n] ]T ∈ RM is the nth ob-
served noisy pixel vector comprising M spectral bands, A =
[ a1, . . . ,aN ] ∈ R
M×N denotes the signature matrix whose
ith column vector ai is the ith endmember signature, s[n] =
[ s1[n], . . . , sN [n] ]
T ∈ RN is the nth abundance vector compris-
ing N fractional abundances, L is the total number of pixels, and
w[n] = [ w1[n], . . . , wM [n] ]
T ∈ RM is the zero-mean random
isotropic noise vector with covariance matrix σ2IM where σ2 is the
noise variance.
Endmember extraction problem is to estimate a1, . . . ,aN from
the given observed pixel vectors y[1], . . . ,y[L] with prior knowl-
edge of the number of endmembers N , under the following general
assumptions [2]: (A1) si[n] ≥ 0 for all i and n; (A2)
∑N
i=1 si[n] =
1 for all n; (A3) min{L,M} ≥ N and A is of full column rank;
(A4) (Pure pixel assumption) there exists at least a set of indices {1,
2, . . . , N} such that x[i] = ai for i = 1, . . . , N .
As a common preprocessing step in hyperspectral image anal-
ysis [2], we obtain the dimension reduced observed pixel vectors
y˜[n] ∈ RN−1 by the following affine transformation [1]:
y˜[n]  CT (y[n]− d), n = 1, . . . , L, (2)
where d = 1
L
∑L
n=1 y[n], C = [q1(UU
T ), . . . , qN−1(UU
T )],
U = [ y[1] − d, . . . ,y[L] − d ] ∈ RM×L, and qi(UUT ) denotes
the unit-norm eigenvector of UUT associated with the ith principal
eigenvalue. Substituting (1) into (2) yields
y˜[n] =
N∑
i=1
si[n]αi + w˜[n], n = 1, . . . , L. (3)
where αi = CT (ai − d) ∈ RN−1 is the ith dimension-reduced
endmember and w˜[n]  CTw[n] is still the random isotropic noise
1237978-1-4673-0046-9/12/$26.00 ©2012 IEEE ICASSP 2012
Table 1. The pseudo-codes of the proposed ADVMM and SDVMM algorithms for problem (4).
ADVMM Algorithm SDVMM Algorithm
Given tolerance ε > 0, back-off distance r, Y˜ and N .
S1. randomly select (θˆ1, . . . , θˆN) from {ei}Li=1 and set uˆ1 = · · · =
uˆN = 0.
S2. set j := 1,  := det(Δ(Y˜θˆ1 − uˆ1, . . . , Y˜θˆN − uˆN )).
S3. compute kj by (10), and update uˆj by (12) and θˆj by (13).
S4. if (j modulo N) = 0, then j := j + 1 and go to S3,
else compute ¯ = det(Δ(Y˜θˆ1 − uˆ1, . . . , Y˜θˆN − uˆN )).
S5. if |¯− |/ > ε, then set  := ¯, j := 1, and go to S3,
else output νˆj = Y˜θˆj − uˆj , ∀j as an approximate solution to (4).
Given back-off distance r, {y˜[n]}Ln=1 and N .
S1. construct y¯[n] = [y˜[n]T 1]T , ∀n and set Ĥ1:0 = IN and j = 0.
S2. update j := j + 1 and obtain wˆj by (23), and zˆj by (20).
S3. set [zˆj ]N = 0, update Ĥ1:j := [Ĥ1:(j−1) wˆj − zˆj ] and go to S2
until j = N .
S4. output νˆj = [wˆj ]1:N−1 − [zˆj ]1:N−1, ∀j as an approximate solution
to (4).
4.2. SDVMM Algorithm
By letting wi = [vTi 1]
T , zi = [uTi 0]
T and y¯[n] = [y˜[n]T 1]T ,
problem (4) can be rewritten as
max
wi∈F,
i=1,...,N
{
min
‖zi‖≤r,
e
T
Nzi=0, ∀i
∣∣∣∣det([w1 − z1, . . . ,wN − zN ])
∣∣∣∣
}
(14)
where F = conv{y¯[1], . . . , y¯[L]}. It has been shown in [1, Lemma
3] that problem (14) can be equivalently represented by
max
wi∈F,
i=1,...,N
min
‖zi‖≤r,
e
T
Nzi=0,∀i
N∏
j=1
f((w1, z1), ..., (wj , zj)) (15)
where
f((w1, z1), ..., (wj , zj)) = ‖P
⊥
H1:(j−1)
(wj − zj)‖, (16)
in which H1:j = [w1 − z1, . . . ,wj − zj ], P⊥H1:j = IN −
H1:j(H
T
1:jH1:j)
†HT1:j is the orthogonal complement projector of
H1:j , and P⊥H1:0 = IN . Solving problem (15) w.r.t. 2N -tuple
(w1, . . . ,wN , z1, . . . , zN ) is difficult. We approximate problem
(15) by successive optimization as follows:
(wˆj , zˆj) =
arg max
wj∈F
min
‖zj‖≤r,
e
T
Nzj=0
f((wˆ1, zˆ1), ..., (wˆj−1, zˆj−1), (wj , zj)) (17)
from j = 1 toN . The solution (wˆj , zˆj) can be obtained by handling
the jth max-min subproblem with the previous (j−1)max-min sub-
problem solutions wˆ1, . . . , wˆj−1, zˆ1, . . . , zˆj−1 given. Unlike alter-
nating optimization, the methodology presented here is initialization
free and only needs to solve (17) successively for j = 1, ..., N .
The issue that remains is how we handle each difficult (non-
convex) max-min subproblem (17). By relaxing eTNzj = 0, it can
be shown that a closed-form solution to (17) exists. To see this, by
(16), problems (17) with eTNzj = 0 relaxed is
max
wj∈F
min
‖zj‖≤r
∥∥∥P⊥
Ĥ1:(j−1)
(wj − zj)
∥∥∥ , j = 1, . . . , N. (18)
The inner problem of (18) for any wj ∈ F is given by
zˆj = arg min
‖zj‖2≤r
∥∥∥P⊥
Ĥ1:(j−1)
(wj − zj)
∥∥∥. (19)
Problem (19) is convex and Slater’s condition holds. The optimal
solution of problem (19) can be derived by Karush–Kuhn–Tucker
(KKT) conditions, as stated in the following lemma:
Lemma 1. For any wj ∈ F , problem (19) has an analytical solu-
tion given by
zˆj = rP
⊥
Ĥ1:(j−1)
wj
/
‖P⊥
Ĥ1:(j−1)
wj‖, wj ∈ W(r), (20)
zˆj ∈ { zj
∣∣ P⊥
Ĥ1:(j−1)
(wj − zj) = 0 }, wj ∈ R
N \W(r), (21)
where W(r) =
{
w ∈ RN
∣∣ ‖P⊥
Ĥ1:(j−1)
w‖ > r
}
.
Proof: The proof of Lemma 1 is given in Appendix. 
It is trivial to see that the solution (21) always yields zero objec-
tive value in (18), and hence the optimal solution (20) is considered.
Substituting (20) into (18) yields
max
wj∈F
⋂
W(r)
∥∥∥P⊥
Ĥ1:(j−1)
wj
∥∥∥. (22)
The optimal solution of (22) can be easily obtained by following the
proof in [1, Lemma 4]; it is given by
wˆj = y¯[],  = arg max
n∈Nj
‖P⊥
Ĥ1:(j−1)
y¯[n]‖, (23)
where Nj =
{
n
∣∣ ‖P⊥
Ĥ1:(j−1)
y¯[n]‖ > r, n = 1, ..., L
}
.
We should mention that the constraint wj ∈ W(r) is to ensure
the meaningful solution of problem (18). In fact, one can properly
choose an r such that wj ∈ W(r), j = 1, ..., N are all satisfied.
Also, if the (wˆj , zˆj) is obtained, we can artificially set [zˆj ]N = 0 to
ensure the feasibility of (wˆj , zˆj) to problem (17). The pseudo-codes
of the SDVMM algorithm are given in Table 1 (right part).
5. SIMULATION AND CONCLUSION
Monte Carlo simulations of 100 independent runs are performed to
demonstrate the performance of the proposed ADVMM and SD-
VMM algorithms1, compared to the four existing methods, SQ-N-
FINDR [7], SC-N-FINDR [7], SGA [8], and WAVMAX [1]. The
root-mean-square (rms) spectral angle distance, denoted as φ (in de-
grees), was used as the error performance measure [1]. The com-
putation time T (in secs) of each algorithm (implemented in Math-
works Matlab R2008a) running in a desktop computer equipped with
Core i7-930 CPU 2.80 GHz, 12GB memory is used as our compu-
tational complexity measure. In each run, the observed data were
synthetically generated following (1) where N = 8 endmember sig-
natures withM = 224 bands were selected from the U.S. geological
survey (USGS) library [10], the abundance vectors were generated
following Dirichlet distribution [1], and zero-mean white Gaussian
noise vectors were added for different signal-to-noise ratios (SNRs),
1A Matlab implementation is provided at http://mx.nthu.edu.
tw/˜tsunghan
1239
OPTIMAL TRANSMISSION STRATEGY FOR OUTAGE RATE MAXIMIZATION IN MISO
FADING CHANNELS WITH TRAINING
Kun-Yu Wang, Tsung-Hui Chang, Wing-Kin Ma†, and Chong-Yung Chi
 Institute of Commun. Eng. & Department of Elect. Eng.
National Tsing Hua University,
Hsinchu, Taiwan 30013
E-mail: {kunyuwang7, tsunghui.chang}@gmail.com, cychi@ee.nthu.edu.tw
† Department of Electronic Eng.
Chinese University of Hong Kong,
Shatin, Hong Kong
E-mail: wkma@ieee.org
ABSTRACT
In this paper, we consider a single-user multiple-input single-output
(MISO) fading channel with training, and investigate optimal train-
ing and data transmission strategies for outage rate maximization.
The receiver obtains instantaneous channel estimates through train-
ing; while the transmitter knows only the statistical information of
the channel. We present analytical, closed-form solutions for the op-
timal training power and optimal data transmit covariance matrix.
In particular, explicit numbers of antennas required for optimal data
transmission are analyzed. Numerical results are presented to vali-
date our analysis.
Index Terms— multiple-input single-output, training design,
transmitter design, outage rate maximization.
1. INTRODUCTION
Multiple transmit antennas can improve the capacity of wireless fad-
ing channels, provided that the receiver knows the channel state in-
formation (CSI). To enable the receiver to learn the CSI, the trans-
mitter has to send training signals before data transmission. Given
a total energy constraint for training and data transmission, it is of
great importance to investigate optimal training and data transmis-
sion strategies for maximizing the system throughput [1].
In this paper, we consider a single-user wireless multiple-input
single-output (MISO) system. The channel between the transmitter
and the receiver is assumed to be independent and identically dis-
tributed (i.i.d.) Rayleigh faded, and remains unchanged during each
transmission block. Each transmission block consists of a training
phase, which enables channel estimation at the receiver, and a data
transmission phase. The transmitter is assumed to have no instanta-
neous CSI. Under the same system setup but with multiple antennas
at the receiver, optimal training and data transmission designs for er-
godic rate maximization have been studied in [1]. In contrast to the
ergodic performance, outage rate performance is more suitable for
delay-limited applications such as voice and video communications.
The data transmission strategies for optimal outage rate performance
is, however, quite different from that for optimal ergodic rate perfor-
mance, and is more difficult to analyze in general. In particular,
assuming perfect CSI at the receiver, it was first observed in [2] and
later proved in [3] that the optimal strategy for outage rate perfor-
mance is to use only a fraction of the total number of antennas for
data transmission, in contrast to its ergodic counterpart where using
all antennas is always optimal [2, 4]. However, analytic conditions
This work is supported in part by the National Science Council, R.O.C.,
under Grant NSC-99-2221-E-007-052-MY3, and in part by a Direct Grant
awarded by The Chinese University of Hong Kong (Project Code 2050489).
for the required number of antennas for optimal data transmission
are still unknown in general [3].
Our focus in this paper is to study the joint training and data
transmission design problem for optimizing the outage rate perfor-
mance. In particular, we aim to jointly optimize the training power
and the data transmit covariance matrix in order to maximize the out-
age rate under a total energy constraint. It turns out that the optimal
training power for the outage rate maximization problem is identical
to that for the ergodic rate maximization problem studied in [1] and
has closed-form solutions. For the optimal data transmit covariance
matrix, we also present analytic closed-form solutions with explicit
number of antennas required for optimal data transmission. Our an-
alytic results extend upon the results in [3] by applying theorems
on the extremal probabilities of quadratic forms of Gaussian random
variables in [5]. Numerical results are presented to verify our theo-
retical claims.
2. SIGNAL MODEL AND PROBLEM STATEMENT
Consider a single-user MISO wireless system, where the transmitter
is equipped with Nt antennas. We assume a block fading channel.
Specifically, the channel vector between the transmitter and the re-
ceiver, denoted by h ∈ CNt , is assumed to be circularly symmetric
complex Gaussian distributed with zero mean and covariance matrix
σ2hINt (an Nt ×Nt identity matrix), i.e., h ∼ CN (0, σ
2
hINt), and
the coefficients of h remain static in one transmission block but can
vary from block to block. Each transmission block consists of two
phases – a training phase with length Tc, followed by a data trans-
mission phase with length Td.
In the training phase, the transmitter sends a training signal to
enable channel estimation at the receiver. Assume that the transmit-
ter employs the optimal training scheme in [6], with Pc being the av-
erage training power, and that the receiver performs linear minimum
mean squared error (LMMSE) channel estimation. Denote hˆ ∈ CNt
as the LMMSE channel estimate, and ec = h− hˆ as the estimation
error vector. Both ec and hˆ are complex Gaussian distributed with
zero mean and covariance matrices σ2eINt and (σ
2
h − σ
2
e)INt , re-
spectively [6], where
σ2e =
(
1
σ2h
+
TcPc
Ntσ2
)−1
, (1)
and σ2 is the additive Gaussian noise power at the receiver.
The receiver will use the channel estimate hˆ for data reception
in the data transmission phase. Since it is difficult to obtain exact
formulas for the channel capacity in the presence of channel estima-
tion error [1, 7], we consider achievable lower bounds that possess
2945978-1-4673-0046-9/12/$26.00 ©2012 IEEE ICASSP 2012
We can observe from problem (9) that the inequality constraint in
(9b) must hold with equality when the optimal Q˜ andR are achieved.
As a result, the optimal Q˜ must be the one that minimizes the proba-
bility function in (9b) since it always admits a higher outage rate R.
It follows from the two observations that
Pmin(γ
)  min
Tr(Q˜)=1,Q˜0
Prob
{
uˆ
H
Q˜uˆ ≤ γ
}
= ρ, (10)
where
γ 
2R
/T¯d − 1
α(P c )
, (11)
and R denotes the optimal outage rate. According to (10) and (11),
once we can fully characterize Pmin(·), then the optimal outage rate
R can be simply obtained as
R = T¯d log2(1 + α(P

c )P
−1
min(ρ)), (12)
where P−1min(·) is the inverse function of Pmin(·).
We therefore focus on analyzing the following function
Pmin(x) = min
Tr(Q˜)=1,Q˜0
Prob
{
uˆ
H
Q˜uˆ ≤ x
}
, (13)
where uˆ ∼ CN (0, INt). To this end, consider the eigenvalue de-
composition of Q˜ = UΛ˜UH , where U ∈ CNt×Nt is a unitary
matrix and Λ˜ ∈ RNt×Nt is a diagonal matrix with eigenvalues
λ˜1, . . . , λ˜Nt ≥ 0 being the diagonal elements. Since Gaussian ran-
dom variables are invariant with unitary transformation, the prob-
ability function in (13) can be written as Prob{uˆHΛ˜uˆ ≤ x} =
Prob{
∑Nt
i=1 λ˜i|uˆi|
2 ≤ x}, where uˆi denotes the ith entry of uˆ.
Further define vi ∼ N (0, 1), i = 1, . . . , 2Nt, as independent real-
valued Gaussian random variables and let
λ2k = λ2k−1 = λ˜k/2, k = 1, . . . , Nt. (14)
By the fact of |uˆk|2 = (v22k + v
2
2k−1)/2, k = 1, . . . , Nt, Pmin(x)
in (13) can be expressed as
Pmin(x) = min∑2Nt
i=1
λi=1,
λ2k=λ2k−1≥0,k=1,...,Nt
Prob
{
2Nt∑
i=1
λiv
2
i ≤ x
}
. (15)
It has been shown in [3] that Pmin(x) is the cumulative distri-
bution function (CDF) of a central chi-square random variable with
certain even number degrees of freedom (DoFs), say 1 ≤ d ≤ 2Nt;
i.e.,
Pmin(x) = Prob
{
1
d
d∑
i=1
v2i ≤ x
}
. (16)
However, it is still not clear how to analytically determine d in gen-
eral. Here we resolve this issue by presenting an exact expression of
Pmin(x). Our analysis relies on the fact of (16) and the theorems
on the extremal probabilities of quadratic forms of Gaussian random
variables in [5]. To elaborate upon this, we first define some useful
notations:
Definition 1 For positive integers d ≥ 1 and 	 ≥ 1, x(d, d+	) rep-
resents the point at which the CDFs Fd(x)  Prob
{
d−1χ2d ≤ x
}
and Fd+(x) intersect, where χ2d denotes the central chi-square ran-
dom variable with d DoFs. The notation
p(d, d+ 	) = Fd(x(d, d+ 	)) = Fd+(x(d, d+ 	)) (17)
represents the corresponding probability value of x(d, d+ 	).
Moreover, x(d, d+ 	) and p(d, d+ 	) have the following mono-
tonic properties:
Lemma 2 [5] i) x(d, d + 	) is unique, larger than one, and de-
creases to one as d increases; ii) p(d, d+ 	) is greater than 0.5, and
decreases to 0.5 as d increases.
By Lemma 2, we can define x(0, 	)  ∞ and p(0, 	)  1 for
any 	. Precise values of x(d, d+	) and p(d, d+	) for d ≥ 1 and 	 ≥
1 can be computed numerically. Using the notations in Definition 1
and Lemma 2, we prove in Section 4 the following proposition on
the solution of (15).
Proposition 1 Pmin(x) in (15) is continuous and monotonically in-
creasing in x, and can be explicitly expressed as
Pmin(x) =
⎧⎨
⎩
F2n(x), ∀x ∈ [x(2n, 2n+ 2), x(2n− 2, 2n)),
n = 1, . . . , Nt − 1,
F2Nt (x), ∀x ∈ [0, x(2Nt − 2, 2Nt)).
Proposition 1 shows that Pmin(x) is composed of F2n(x), n =
1, . . . , Nt in a piece-wise manner. Combining Proposition 1, Defini-
tion 1 and (10), and by the monotonicity of Pmin(x), we can obtain
explicit expression of P−1min(ρ) as
P−1min(ρ) =
⎧⎨
⎩
F−12n (ρ), ∀ρ ∈ [p(2n, 2n+ 2), p(2n− 2, 2n)),
n = 1, . . . , Nt − 1,
F−12Nt (ρ), ∀ρ ∈ [0, p(2Nt − 2, 2Nt)).
(18)
Then the optimal outage rate R of problem (3) can be obtained by
(18) and (12). Equation (18) also implies that the optimal DoFs in
(16) is given by
d =
⎧⎨
⎩
2n, ∀ρ ∈ [p(2n, 2n+ 2), p(2n− 2, 2n)),
n = 1, . . . , Nt − 1,
2Nt, ∀ρ ∈ [0, p(2Nt − 2, 2Nt)).
(19)
With d, the optimal Q˜ can be obtained as
Q˜
 = UΛ(d/2)(U)H , (20)
whereU ∈ CNt×Nt can be an arbitrary unitary matrix andΛ(d/2)
∈ RNt×Nt is a diagonal matrix with the first d/2 diagonal elements
being nonzero and equal to 2/d (due to Tr(Q˜) = 1).
It is interesting to note from (19) and (20) that it is not necessary
to use all the DoFs for optimal data transmission, especially when ρ
is high; this result is in strong contrast to that in [2,4] for ergodic rate
maximization where it is shown that using all the available DoFs,
i.e., Q˜ = (1/Nt)INt , is always optimal. One can also see from
(19) and (20) that for ρ ≥ p(2, 4) = 0.7153, d = 2 and thus using
only one antenna for data transmission is sufficient to be optimal.
Conversely, when ρ < p(2Nt − 2, 2Nt) (where p(2Nt − 2, 2Nt) >
0.5), d = 2Nt and hence the optimal transmission strategy is to
equally allocate powers to all Nt antennas. For the other cases, it
is sufficient to use only a fraction of Nt antennas for optimal data
transmission.
In Fig. 2, we present the simulation results of the outage rate
achieved by the optimal strategy in (19) and (20). The maximum
achievable outage rates of the single-antenna transmission strategy
(which corresponds to Q˜ = Λ(1)) and the all-antenna transmission
strategy (which corresponds to Q˜ = (1/Nt)INt ) are also presented.
We can see from this figure that the numerical results are consistent
with our analytical results presented in this subsection.
2947
 1 
出席 IEEE ISBI-2012國際學術會議心得報告 
                                                             
計畫編號 NSC 99-2221-E-007-003-MY3  
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術  
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 5/2/2012-5/5/2012, Barcelona, Spain  
會議名稱 2012 IEEE International Symposium on Biomedical Imaging (ISBI-2012)  
發表論文題目 
#1.  An NBSS Algorithm for Pharmacokinetic Analysis of Prostate Cancer Using 
DCE-MRI Images (ArulMurugan Ambikapathi, Tsung-Hui Chang, Kannan 
Keizer, Fei-Shih Yang, Chong-Yung Chi)   
 
一、參加會議經過 
 
筆者於101年4月29日 (Sunday evening) 從桃園中正機場出發，於4月30日 (Monday afternoon)
抵達 Barcelona, Spain, 進駐旅館 Hotel Diagonal Zero。The following is a summary of the major 
activities and events that I participated in. 
 
5/1 (Tuesday): Rest and tour in Barcelona.   
5/2 (Wednesday):  
(a) 完成報到手續 and met international friends and experts  
(b) (08:00-12:30) attended CH5: High Angular Resolution Diffusion Imaging   
(c) (15:30-17:00) attended WE-PO.PA (Computer Aided Diagnosis A, Diffusion and Functional 
MR imaging A, Image Acquisition and Reconstruction A) and WE-PO.PB (Cardiac and 
Vascular Imaging A, Registration, Segmentation and Feature Detection in Microscopy A, 
Medical and Biological Applications of Microscopy A, Image Acquisition and 
Reconstruction: Applications)  
  
5/3 (Thursday):  
(a) (08:30-09:15) attended SF-3: Can We Infer Active Brain Regions from Multivariate Pattern 
Analysis of Functional MRI?   
(b) (09:30-11:00) attended TH-AM1.02: Image Reconstruction: MRI  
(c) (11:30-13:00) attended TH-AM2.03: Image Analysis: PET, SPECT, CT  
(d) (14:30-15:30) attended PLEN-2: Dr. Jurgen Popp (Friedrich-Schiller University, Germany)- 
The Broad Range of Raman-Based Spectral Imaging for Biomedical Analytics  
(e) (15:30-15:00) attended TH-PO.PA (Medical Image Analysis: Applications B, Diffusion and 
 3 
附件一： 
 
where Cf (t) and Cs(t) are the tracer concentrations of the inter-
stitial space in the fast and slow flow pools at time t, respectively;
Cp(t) is the tracer concentration in arterial (plasma) input function
at time t; Cms(t) is the measured tracer concentration at time t; K transf
and K transs (in min
−1) are the unidirectional transfer constants from
plasma to fast and slow flow pools, respectively; kep,f and kep,s (in
min−1) are the flux rate constants from fast and slow flow pools to
plasma, respectively. Equations (1)-(3) can be solved for Cf (t) and
Cs(t) in terms of the rate constants and the solutions are given by
Cf (t) = K
trans
f Cp(t)⊗ exp(−kep,f t), (4)
Cs(t) = K
trans
s Cp(t)⊗ exp(−kep,s t). (5)
Let ap(t) = Cp(t), af (t) = Cp(t) ⊗ exp(−kep,f t), and as(t) =
Cp(t)⊗ exp(−kep,s t). Consider the discretized signal model with
temporal resolution Δt, and denote the tracer concentration mea-
sured at time tm = (m − 1)Δt in the pixel n by Cms(n, tm).
Then, by (4) and (5), temporal patterns of Cms(n, tm) (given by (3)
in the nth pixel) can be expressed as the following latent variable
model [7]:
x[n] = [ ap af as ] k[n] ∈ R
M , n = 1, ..., L, (6)
where x[n] = [Cms(n, t1), . . . , Cms(n, tM )]T , ap ∈ RM is the ar-
terial input function (AIF) which is the plasma TAC, and af ∈ RM
and as ∈ RM are the TACs of fast and slow flow tissues, respec-
tively, (which are also represented by aj = [aj(t1), . . . , aj(tM )]T ∈
R
M , j ∈ {p, f, s} below, for ease of the ensuing development), and
k[n] = [Kp[n], K
trans
f [n], K
trans
s [n]]
T ∈ R3 is a vector containing
the kinetic parameters in the nth pixel. In addition, M is the num-
ber of sampling time points and L is the total number of pixels.
Therefore we have
af = D(kep,f )ap, (7)
as = D(kep,s)ap, (8)
where D(x) is an M ×M lower triangular matrix with the (i, j)th
entry being
Dij(x) =
 
Δt exp(−(i− j)xΔt), i ≥ j,
0, i < j.
(9)
The aim of this work is to estimate TACs ap, af , as and the
kinetic parameters k[1], ...,k[L] from the given DCE-MR data
x[1], ..., x[L]. Some general assumptions are as follows:
(A1) The components of k[n] are non-negative.
(A2) The TACs ap, af , as are linearly independent.
(A3) (Pure pixel assumption)
- In the entire image, there exists a pure artery pixel index
lp such that K transf [lp] = K
trans
s [lp] = 0 and Kp[lp] = 0,
leading to x [lp] = Kp[lp]ap.
- In the prostate gland, there exists an index set {lf , ls} such
that x [lj ] = K transj [lj ]aj for j ∈ {f, s}.
(A4) (Physical assumptions) [6]
- Blood plasma volume Kp[n] ≤ 1, ∀n.
- Flux rate constant is greater than transfer constant in both
fast and slow flow pools, i.e., kep,f ≥ K transf [n] and kep,s ≥
K transs [n], ∀n.
- The unidirectional transfer constant is larger in fast flow tis-
sue than in slow flow tissue, i.e., K transf [n] ≥ K
trans
s [n], ∀n.
Assumptions (A1), (A2), (A4) are the assumptions widely used in
DCE-MR image analysis [7]. Assumption (A3) means that within
the prostate gland the distributions of the fast and slow flow tissues
are not fully overlapped. Moreover, because a pure artery pixel in
the prostate gland may not be acquired/imaged, we instead assume
that in the entire image there exists a pure artery pixel, possibly cor-
responding to internal pudendal artery or inferior vesical artery or
middle rectal artery.
3. TAC ESTIMATION BY PROJECTION
In this section, we propose an unsupervised nBSS algorithm, namely
TAC Estimation By Projection (TACE-Pro) for pharmacokinetic
analysis of DCE-MR image data.
3.1. Estimation of Pure Pixel Indices
We first present how to sequentially estimate the pure pixel indices
corresponding to the TACs of plasma, fast flow, and slow flow re-
gions, from the DCE-MR image data. The estimated pure pixel
indices are then used to estimate the associated TACs and kinetic
parameters, as presented in the subsequent subsection.
To begin with, we first normalize the DCE-MR data (6) as
x¯[n]  x[n]/(1TMx[n]) (10)
= k¯p[n]a¯p + k¯f [n]a¯f + k¯s[n]a¯s, n = 1, ..., L, (11)
where a¯j = aj/1TMaj for j ∈ {p, f, s} denote the normal-
ized TACs, and k¯p[n] = Kp[n](1TMap)/1
T
Mx[n] and k¯j [n] =
Ktransj [n](1
T
Maj)/1
T
Mx[n] for j ∈ {f, s} are the normalized ki-
netic parameters. It can be easily verified that

i∈{p,f,s}
k¯i[n] = 1. (12)
With the normalized data (10), the first pure pixel index, lp, can be
estimated. It has been proved in [8] that by (12) and under (A1)-(A3)
the normalized AIF and its pure pixel index can be identified by
a¯p = x¯[lp], lp ∈ arg maxn∈I{‖x¯[n]‖}, (13)
where I is the set of pixel indices over the entire image.
Next, the question that remains is how to estimate the rest of the
pure pixel indices, say {lf , ls}. Though in this work we have consid-
ered the three-tissue compartment model with total number of tissue
compartments N = 3, in the ensuing development, the normalized
model in (10) can be generalized to any N tissue compartments as
x¯[n] =
N

j=1
k¯j [n]a¯j , n = 1, ..., L, (14)
where k¯1[n] = k¯p[n], and a¯1 = a¯p has been estimated by (13). To
estimate the pure pixel indices {lj}Nj=2 in a sequential manner, we
first obtain the mean-removed data
x˜[n] = x¯[n]− μ¯ =
N

i=1
k¯i[n]βi, (15)
where μ¯ =  L
n=1 x¯[n]/L is the mean of the normalized data, and
βi = a¯i− μ¯ is the unknown mean-removed TACs. Suppose that the
mean-removed TACs β1, ..., βj (where j < N ) have already been
identified. To identify the next mean-removed TAC βj+1, we first
find a normal vector [9] to the affine set formed by β1, ..., βj :
d
 = arg min
d∈aff{β1,...,βj}
‖d‖2 = P⊥Bβj , (16)
567
3(a) shows the estimated TACs both before (discrete points) and after
(continuous curves) model fitting for slices 12, 15, 18, and 22. Fig-
ure 3(b) shows the corresponding estimated kinetic parameter maps.
It can be observed that the slow flow TAC has lower washout rate
kˆep,s, and kˆep,f is much higher than kˆep,s. Also, the fast flow tis-
sue for all the slices are almost dominant in both sides of peripheral
and central zones of the prostate gland, while the plasma volume and
the slow flow tissue are relatively inactive. These results are highly
consistent with the biopsy results (Figure 2).
6. CONCLUSION
We have presented an effective TAC estimation algorithm, namely
TACE-Pro, followed by estimation of kinetic parameters through
pharmacokinetic model fitting, for prostate DCE-MR image analy-
sis. We have evaluated the TACE-Pro algorithm with the synthetic
DCE-MRI data and real DCE-MRI images with prostate cancer.
Simulation results have shown that the proposed method TACE-Pro
performs well for all the scenarios (early-stage, moderate, and active
tumor). For real data experiments, we have estimated the tissue
TACs, kinetic parameter values, and kinetic parameter maps, which
show high consistency with the biopsy results.
7. REFERENCES
[1] A. Jemal, R. Siegel, E. Ward, T. Murray, J. Xu, C. Smigal, and M. J.
Thun, “Cancer statistics, 2010,” CA: A Cancer Journal for Clinicians,
vol. 60, no. 5, pp. 277-300, Sep. 2010.
[2] M. A. Khan and A. W. Partin, “Management of patients with
an increasing prostate-specific antigen after radical prostatectomy,”
Current Urology Reports, vol. 3, no. 3, pp. 179-187, Jun. 2004.
[3] M. D. Plumbley, “Algorithms for non-negative independent component
analysis,” IEEE Trans. Neural Netw., vol. 14, no. 3, pp. 534-543, May
2003.
[4] D. D. Lee and H. S. Seung, “Learning the parts of objects by non-
negative matrix factorization,” Nature, vol. 401, no. 6755, pp. 788-791,
Aug. 1999.
[5] A. Ambikapathi, T.-H. Chan, C.-Y. Chi, and K. Keizer, “Two effective
and computationally efficient pure-pixel based algorithms for hyper-
spectral endmember extraction,” in Proc. IEEE ICASSP-2011, Prague,
Czech Republic, May 22-27, 2011, pp. 1369-1372.
[6] P.S. Tofts and A.G. Kermode, “Measurement of the blood-brain bar-
rier permeability and leakage space using dynamic MR imaging. 1.
Fundamental concepts,” Magnetic Resonance in Medicine, vol. 17, pp.
357-367, Feb. 1991.
[7] Y. Wang, 1. Xuan, R. Srikanchana, and P. L. Choyke, “Model-
ing and reconstruction of mixed functional and molecular patterns,”
International Journal of Biomedical Imaging, Article ID: 29707, pp.
1-9, 2006.
[8] Y.-C. Lin, T.-H. Chan, C.-Y. Chi, S.-H. Ng, H.-L. Liu, K.-C. Wei, Y.-
Y. Wai, C.-C. Wang, and J.-J. Wang, “Blind estimation of arterial input
function in dynamic contrast-enhanced MRI using purity maximiza-
tion,” to appear in Magnetic Resonance in Medicine, 2012.
[9] S. Boyd and L. Vandenberghe, Convex Optimization, UK: Cambridge
Univ. Press, 2004.
[10] P. T. Boggs and J. W. Tolle, “Sequential quadratic programming,” Acta
Numerica, pp. 1-51, 1996.
[11] J. F. Sturm, “Using SeDuMi 1.02, a MATLAB toolbox for optimization
over symmetric cones,” Optimiz. Methods Softw., vol. 11–12, pp. 625–
653, 1999.
[12] M. Grant and S. Boyd. CVX: Matlab software for disciplined convex
programming, version 1.21. http://cvxr.com/cvx, Oct. 2010.
[13] C. Yang, G. S. Karczmar, M. Medved and W. M. Stadler, “Estimat-
ing the arterial input function using two reference tissues in dynamic
contrast-enhanced MRI studies: Fundamental concepts and simula-
tions,” Magnetic Res. in Medicine, vol. 52, pp. 1110-1117, Nov. 2004.
Apex ~ 10
th
 slice
Base ~ 29
th
 slice
Right Left
Top
Middle
Bottom
Right Left
90% 85%
90%
45%
80%
90%
95% 90%
90%
95%
50%
95%
Fig. 2. Position of biopsy examination (left) and biopsy examination
results showing the percentage of tumor tissues (right).









 6OLFH 









 6OLFH 
         









WLPHPLQV
1R
UP
DOL
]H
GF
RQ
FH
QWU
DWL
RQ
6OLFH 









 6OLFH 
1R
UP
DOL
]H
GF
RQ
FH
QWU
DWL
RQ
1R
UP
DOL
]H
GF
RQ
FH
QWU
DWL
RQ
1R
UP
DOL
]H
GF
RQ
FH
QWU
DWL
RQ
         
WLPHPLQV
         
WLPHPLQV
         
WLPHPLQV
EHIRUHPRGHOILWWLQJEHIRUHPRGHOILWWLQJaˆp aˆfaˆf aˆsaˆs
kˆep,f = 0.4301 min
−1
kˆep,s = 0.0381 min
−1
kˆep,f = 0.5970 min
−1
kˆep,s = 0.1600 min
−1
kˆep,f = 0.5871 min
−1
kˆep,s = 0.1087 min
−1
kˆep,f = 0.4526 min
−1
kˆep,s = 0.0925 min
−1
(a)
3ODVPDYROXPH )DVWIORZPDS 6ORZIORZPDS
6OLFH
6OLFH
6OLFH
6OLFH






Kˆp[n] Kˆ transf [n] Kˆ
trans
s [n]
(b)
Fig. 3. (a) The estimated TACs aˆp, aˆf , aˆs (normalized such that
1
T
M aˆp = 1
T
M aˆf = 1
T
M aˆs = 1), for slices 12, 15, 18, and 22 us-
ing TACE-Pro algorithm, and (b) the estimated kinetic parameter (or
tissue) maps corresponding to the model fitted TACs in (a).
569
 2 
6/6 (Wednesday):  
(a) (08:30-09:30) Plenary 2: Planetary Hyperspectral Imagery, from remote characterizations 
down to microscopic in situanalysis  
Speaker: Dr. Jean-Pierre Bibring, Professor of Physics, University of Paris, Orsay, France, 
and Astrophysicist at IAS, Insitut d’Astrophysique Spatiale, Orsay   
(b) (09:30-11:10) Session wed-o-1-b: Extraterrestrial Sensing/ Change Detection; present our 
Paper (#1): SPATIAL-SPECTRAL UNMIXING OF HYPERSPECTRAL DATA FOR 
DETECTION AND ANALYSIS OF ASTROPHYSICAL SOURCESWITH THE MUSE 
INSTRUMENT (Yu-Shiuan Shen, Tsung-Han Chan, Sebastien Bourguignon and 
Chong-Yung Chi)  
(c) (11:40-13:00) Session wed-p: Poster  
(d) (14:00-15:40) Session wed-o-2-a: Classification (2)  
 
6/7 (Thursday):  
(a) (08:30-09:30) Plenary 3: Monitoring Canopy Chemistry with Next Generation Imaging 
Spectrometer from Satellites  
Speaker: Dr. Susan L. Ustin, Dept of Land, Air and Water Resource, Uni. Of California, 
Davis, USA  
(b) (09:30-11:10) Session thu-o-1-b: Noise Reduction  
(c) (11:40-13:00) Session thu-p: Poster  
(d) (14:00-15:40) Session thu-o-2-a: Classification (3)  
(a) (16:10-18:10) Session thu-o-3-a: Band Selection, Feature Extraction; present our  
Paper (#2): OUTLIER-ROBUST DIMENSION REDUCTION AND ITS IMPACT ON 
HYPERSPECTRAL ENDMEMBER EXTRACTION (Hao-En Huang, Tsung-Han Chan, 
ArulMurugan Ambikapathi, Wing-Kin Ma, Chong-Yung Chi)  
 
6/8 (Friday):  
(a) (14:00-17:30) visited Professor Liqing Zhang (張麗清), MOE-MSR Joint Key Lab of 
Intelligence Computing, Department of Computer Science and Engineering, Shanghai Jiao 
Tong University; visited his labs and delivered an invited talk with title and abstract as 
follows: 
Title: CONVEX ANALYSIS BASED NON-NEGATIVE BLIND SOURCE SEPARATION AND 
ITS APPLICATIONS  
Abstract: Convex Optimization has been recognized as a powerful tool for solving a wide 
range of scientific and engineering problems, if the problem of interest can be advisably 
formulated into a convex optimization problem. A number of endeavors of using convex 
optimization can be extensively seen in applications to signal processing and 
communications engineering over the last decade, as we have been successfully applying 
SPATIAL-SPECTRAL UNMIXING OF HYPERSPECTRAL DATA FOR DETECTION AND
ANALYSIS OF ASTROPHYSICAL SOURCES WITH THE MUSE INSTRUMENT
Yu-Shiuan Shen†, Tsung-Han Chan†, Se´bastien Bourguignon∗ and Chong-Yung Chi†
†Inst. Commun. Eng., National Tsing Hua Univ. ∗LUNAM Universite´, Ecole Centrale de Nantes,
Hsinchu, Taiwan IRCCyN UMR CNRS 6597, 1 rue de la Noe¨,
E-mail: yushiuan08@gmail.com B.P. 92101, 44321 Nantes Cedex 3, France
{tsunghan@mx,cychi@ee}.nthu.edu.tw E-mail: Sebastien.Bourguignon@irccyn.ec-nantes.fr
ABSTRACT
Detection and analysis of astrophysical sources from the forthcom-
ing MUSE instrument is of greatest challenge mainly due to the high
noise level and the three-dimensional translation variant blur effect
of MUSE data. In this work, we use some realistic hypotheses of
MUSE to reformulate the data convolution model into a set of linear
mixing models corresponding to different, disjoint spectral frames.
Based on the linear mixing models, we propose a spatial-spectral un-
mixing (SSU) algorithm to detect and characterize the galaxy spec-
tra. In each spectral frame, the SSU algorithm identifies the pure
galaxy regions with a theoretical guarantee, and estimate spectra
based on a sparse approximation assumption. The full galaxy spectra
can finally be recovered by concatenating the spectra estimates asso-
ciated with all the spectral frames. The simulations were performed
to demonstrate the efficacy of the proposed SSU algorithm.
Index Terms— MUSE instrument, astrophysical hyperspectral
data, galaxy spectra, spatial-spectral unmixing, sparse representation
1. INTRODUCTION
MUSE (Multi-Unit Spectroscopic Explorer) is a very powerful inte-
gral field spectrograph, planned to be commissioned at Very Large
Telescope (VLT) in Chile in the near future. MUSE will pro-
vide massive hyperspectral astrophysical data cube with images of
300 × 300 pixels and up to 4000 spectral bands, ranging from the
visible to near-infrared (465nm to 930nm) wavelength. The data
provided by MUSE will be in a very noisy condition with highly
spectrally-varied power distribution, caused by the strong parasite
emission of the atmosphere at specific wavelengths and by the in-
strumental limitations. In addition, when observed through MUSE,
each source will be spread in spatial and spectral domains in the
cube with the three-dimensional point spread function (PSF) due to
the instrument and atmospheric effects [3].
Present efforts for analyzing the MUSE hyperspectral data can
be mainly categorized by two groups: one for very distant galax-
ies [1, 2] while the other for stellar spectra [3]. In [1], under the
hypothesis that spectra should be in sparse form, spectra restoration
from line spread function (LSF) contaminated MUSE data can be
accomplished by solving an `1-norm minimization problem, where
a dictionary of elementary spectral features must be advisably given
in advance. In [2], Bourguignon et al. consider the restoration prob-
lem with the PSF taken into account, employ sparse approximations
to solve joint spatial-spectral restoration for full data cube, instead
of objects only, and use prior knowledge of the field spread func-
tion (FSF) to retrieve the abundance maps. In the other group that
This work is supported by National Science Council (R.O.C.) under
Grant NSC 99-2221-E-007-003-MY3.
considers stellar spectra, [3] presents a instantaneous, spectrally in-
variant linear mixing model and uses existing method, non-negative
matrix factorization (NMF), to extract stellar spectra, but it cannot
distinguish star types.
In this paper, we propose a spatial-spectral unmixing (SSU) al-
gorithm to detect spectra and abundance maps associated with all the
objects in order to characterize very distant emitting astrophysical
sources from the PSF-corrupted MUSE data. We first reformulate
the convolution model (for whole spectral range) into several linear
mixing models associated with distinct, disjoint spectral frames. In
each spectral frame, based on the pure pixel assumption, the pro-
posed SSU algorithm identifies the pure galaxy regions. By consid-
ering the fact that each galaxy spectrum can be well approximated
by suitable sparse representation [1], the estimation of galaxy spec-
tra is formulated as a convex `1-norm minimization problem. The
estimation of abundance maps can be formulated as a non-negative
least-squares problem. Both problems can be solved by any available
convex optimization solvers. Finally, the complete estimated spectra
are obtained from those estimates of all the spectral frames through
an advisable permutation. Some simulation results are presented to
demonstrate the efficacy of the proposed SSU algorithm.
Notations: R (R+), RN (RN+ ) and RM×N (RM×N+ ) denote set
of real (non-negative real) numbers, N × 1 vectors and M × N
matrices, respectively; δ[x] is the discrete-time impulse function of
x; 1 is an all-one column vector with proper dimension; “‖ · ‖p”,
“‖ · ‖F ” and “d·e” stand for p-norm, Frobenius norm, and ceiling
function, respectively; P⊥C is the orthogonal complement projector
of matrixC.
2. PROBLEM STATEMENT
As reported in [1–3], MUSE data can be modeled by
y[r, λ] = x[r, λ] + w[r, λ] ∈ R, ∀r, λ, (1)
where y[r, λ] is the value of the MUSE data at voxel [r, λ], x[r, λ]
is the noise-free counterpart, and w[r, λ] is the noise. Also, r ∈ R2
denotes the 2-D spatial coordinate and λ ∈ R+ denotes the wave-
length. The noise-free MUSE data can be written as:
x[r, λ] =
N∑
i=1
xi[r, λ], ∀r, λ, (2)
where xi[r, λ] is the contribution of the ith galaxy to the voxel [r, λ]
after taking into account the PSF effect and N is the number of
galaxies. Moreover, suppose that there are Pi pixels correspond-
ing to the ith galaxy and each galaxy has a set of pixel indices
Ii = {r1i , r2i , . . . , rPii } for i = 1, . . . , N . Hence, the ith galaxy
Besides, we make two assumptions to the linear mixing model (8):
(A1) min{L, 2KF−2KL+1} ≥ N and the LSF corrupted galaxy
spectra {Hm1 am1 , . . . ,HmNamN} are linearly independent.
(A2) (Pure pixel assumption) The pure pixel region associated with
the ith galaxy is identical for all the spectral bands, and there
exists a set of indices {`m1 , ..., `mN} such that xm[`mi ] =
smi [`
m
i ]H
m
i a
m
i , ∀ i.
Assumption (A1) describes the fact that the number of galaxies of
interest are less than the number of pixels and the number of spectral
bands in each spectral frame. Assumption (A2) is realistic because
the object field is not very dense, as illustrated in Figure 1.
I1
I2
I3
Fig. 1. Illustration of (A2). Three galaxies located at I1, I2, I3 and
their associated abundance supports (through the FSF) are marked
by respective color regions. The so-called pure pixel regions are
denoted by the oblique line regions.
4. THE PROPOSED SSU ALGORITHM FOR MUSE DATA
In this section, we elaborate the procedure of the proposed SSU al-
gorithm for analyzing MUSE data.
4.1. Noise Pre-Whitening and Noise Reduction
As the covariance matrix of noise at each pixel (i.e.,Σm[n], ∀n) are
known in advance [2], we perform noise-prewhitening as follows
ym[n] , Σm[n]
− 1
2ym[n] (9)
=
N∑
i=1
smi [n]Σm[n]
− 1
2H
m
i a
m
i +Σm[n]
− 1
2wm[n], ∀n,
where the noise term Σm[n]−1/2wm[n] becomes white Gaussian
[1, 2]. Then, by letting Vm ∈ R(2KF−2KL+1)×N be the matrix
containing the first N left singular vectors of [ ym[1], . . . ,ym[L] ]
and since Σm[n] = σ[n]Cm, we can obtain the noise reduced data
y˜m[n] , VmV
T
mym[n] =
N∑
i=1
emi [n]b
m
i + vm[n], ∀n, (10)
where emi [n] = σ[n]−1/2smi [n], bmi = VmVTmC
−1/2
m H
m
i a
m
i , and
vm[n] = VmV
T
mΣm[n]
−1/2wm[n].
4.2. Pure Pixel Indices Search
The noise reduced data (10) will then be used to estimate pure pixel
indices. We first normalize the noise reduced data (10) as
y¯m[n] , y˜m[n]/1
T
y˜m[n] =
N∑
i=1
e¯mi [n]b¯
m
i + v¯m[n], ∀n, (11)
where e¯mi [n] = emi [n]1Tbmi /1T y˜m[n] denotes the normalized
abundance fraction, b¯mi = bmi /1Tbmi denotes the ith normalized
LSF corrupted galaxy spectrum, and v¯m[n] = vm[n]/1T y˜m[n] de-
notes the normalized noise. Since vm[n] is zero-mean, one can eas-
ily show that
N∑
i=1
e¯mi [n] ∼= 1, ∀n. (12)
It has been shown in [4, Lemma 4] that under (F1), (A1), (A2)
and the absence of noise (i.e.,∑Ni=1 e¯mi [n] = 1, ∀n), the pure pixel
indices can be identified by
`mj ∈
{
arg maxn=1,...,L ‖y¯m[n]‖2, j = 1
arg maxn=1,...,L ‖P⊥Γ1:(j−1) y¯m[n]‖2, j > 1
(13)
where Γ1:k = [y¯m[`m1 ], . . . , y¯m[`mk ]]. We denote the extracted pure
pixel indices in the noisy scenario by {ˆ`m1 , . . . , ˆ`mN}.
4.3. Galaxy Spectra Unmixing
Given the pure pixel indices {ˆ`m1 , . . . , ˆ`mN} estimated above, by (9)
and (A2), we have
ym[ˆ`
m
i ]=s
m
i [ˆ`
m
i ]Σm[ˆ`
m
i ]
− 1
2H
m
i a
m
i +Σm[ˆ`
m
i ]
− 1
2wm[ˆ`
m
i ],∀i. (14)
Also, we suppose that each galaxy spectrum ami can be sparsely
represented by a dictionary [1]:
a
m
i = Dmu
m
i , i = 1, . . . , N, (15)
where umi is a sparse vector, and Dm ∈ R(2KF+1)×22604 is the dic-
tionary matrix composed of line spectra, step-like spectra and con-
tinuous spectra. Substituting (15) into (14) yields
ym[ˆ`
m
i ]=Σm[ˆ`
m
i ]
− 1
2H
m
i Dmµ
m
i +Σm[ˆ`
m
i ]
− 1
2wm[ˆ`
m
i ], ∀i, (16)
where Σm[ˆ`mi ], Hmi , Dm are known a priori, and µmi ,
smi [ˆ`
m
i ]u
m
i should be sparse since umi is sparse. Hence, we
can estimate µˆmi , ∀i by solving the following `1-norm mini-
mization problem subject to the maximum fitting error in (16)
upper-bounded by ε ,
√
2KF − 2KL + 1 (standard deviation of
Σm[ˆ`
m
i ]
−1/2wm[ˆ`
m
i ]):
µˆ
m
i =arg min
‖ym[ˆ`
m
i ]−Σm[
ˆ`m
i ]
−
1
2H
m
i Dmµ
m
i ‖2≤ε
‖µmi ‖1, ∀i. (17)
The scaled galaxy spectra can be estimated by
smi [ˆ`
m
i ]a
m
i = s
m
i [ˆ`
m
i ]Dmu
m
i = Dmµˆ
m
i , ∀i. (18)
By (9) and (18), we can estimate the scaled abundance fractions
κmi [n] , s
m
i [n]/s
m
i [ˆ`
m
i ], ∀i, n, (19)
by solving the non-negative least-squares problem
min
κmi [n]≥0,
i=1,...,N
‖ym[n] −
N∑
i=1
κmi [n]Σm[n]
− 1
2H
m
i Dmµˆ
m
i ‖2. (20)
Note that (17) and (20) are convex and can be solved by any stan-
dard convex optimization solvers, such as CVX [5]. The issue that
remains is how to fix the scaling ambiguity smi [ˆ`mi ] in (18) and (19).
Under (F2) and (19), we can further estimate the scale factors by
L∑
n=1
κmi [n] =
L∑
n=1
smi [n]/s
m
i [ˆ`
m
i ] = 1/s
m
i [ˆ`
m
i ]
=⇒ sˆmi [ˆ`mi ] = 1/
L∑
n=1
κˆmi [n], i = 1, . . . , N. (21)
OUTLIER-ROBUST DIMENSION REDUCTION AND ITS IMPACT ON HYPERSPECTRAL
ENDMEMBER EXTRACTION
Hao-En Huang†, Tsung-Han Chan†, ArulMurugan Ambikapathi†, Wing-Kin Ma∗, Chong-Yung Chi†
†Institute of Communications Engineering, National Tsing Hua Univ., Hsinchu, Taiwan
∗Department of Electronic Engineering, Chinese Univ. Hong Kong, Shatin, N.T., Hong Kong
E-mail: b23004705@hotmail.com; {thchan,aareul,wkma}@ieee.org;cychi@ee.nthu.edu.tw
ABSTRACT
Hyperspectral endmember extraction is a process to extract end-
member signatures from the observed hyperspectral data of an area.
The presence of outliers in the data has been proved to pose a seri-
ous problem in endmember extraction. In this paper, unlike conven-
tional outlier detectors which may be sensitive to window settings,
we propose a robust affine set fitting (RASF) algorithm for joint di-
mension reduction and outlier detection without any window setting.
Given the number of endmembers in advance, the RASF algorithm
is to find a data-representative affine set from the corrupted data,
while making the effects of outliers minimum, in the least-squares
error sense. The proposed RASF algorithm is then combined with
Neyman-Pearson hypothesis testing, termed RASF-NP, to further es-
timate the number of outliers present in the data. Computer simula-
tions demonstrate the efficacy of the proposed method, and its impact
on existing endmember extraction algorithms.
Index Terms— Hyperspectral images, Robust dimension reduc-
tion, Endmember extraction
1. INTRODUCTION
In the past several years, endmember extraction using hyperspectral
images has been widely investigated and proven to be valuable in
many applications, including geology, hydrology, urban planning,
geography, cadastral mapping, cartography, and military [1]. How-
ever, the presence of outliers in the hyperspectral data is inevitable
in practice, and may seriously affect the analysis of hyperspectral
data. The outliers are thought of as the pixels that appear to deviate
markedly from the rest of the data. Two definitions of outlier pixels
have been presented in [2, 3]. The first one refers to the pixels that
provide constant or error readout, also called “dead” or “bad” pixels.
Possible causes include detector failure, errors during data transfer,
and improper data correction. The second one refers to the pixels
that have rather different spectral signatures from the background
representative. These pixels are also commonly called targets in the
domain of hyperspectral anomaly detection.
Present outlier detection (OD) methods conceptually detect the
outliers based on some sort of distance measure between outliers
and background representative. The RX algorithm [4], known as
a benchmark OD algorithm, assumes that all the background pixel
vectors have the same multivariate normal distribution, and uses a
sliding window scheme to compute the background covariance ma-
trix. In the sliding window, the centered pixel and the rest of pixels
correspond to the tested target and background, respectively. Since
This work is supported by National Science Council (R.O.C.) under
Grant NSC 99-2221-E-007-003-MY3, and by a General Research Fund of
Hong Kong Research Grant Council (Project No. CUHK415509).
some probable outliers may be taken in the background region of the
window, the calculation of the background covariance matrix is not
accurate anymore, leading to performance degradation of RX algo-
rithm. To properly mitigate this problem, random-selection-based
anomaly detector (RSAD) [5] is reported to robustly compute back-
ground information, intending to take as few outliers involved in
background as possible. But it may spend much more computation
time.
In this paper, we focus not only on the OD problem, but also
on the dimension reduction. We develop a robust affine set fitting
(RASF) algorithm, a robust version of the affine set fitting (ASF) [6],
for joint dimension reduction and outlier detection. Assuming the
number of endmembers and outliers are known in advance, RASF
is to find a contamination-free, data-representative affine set from
the corrupted data, while minimizing the outlier effects in the least-
squares error sense. The proposed RASF algorithm does not rely on
any sliding window setting, and is implemented by alternating opti-
mization. Furthermore, we incorporate the estimation of the number
of outliers in the RASF algorithm, by Neyman-Pearson hypothesis
testing; the resulting algorithm will be called RASF-NP. Simulations
will show the effectiveness of the proposed RASF and RASF-NP al-
gorithms, and comparison of the RASF-NP algorithm with RSAD
method [5], and the impact of the RASF-NP algorithm on some ex-
isting benchmark endmember extraction algorithms (EEAs).
Notations: RN and RM×N denote set of real N × 1 vectors
and set of real M × N matrices, respectively; 0 is the all-zero vec-
tor with proper dimension; IN represents N × N identity matrix;
“‖ · ‖” stands for Euclidean norm; N (µ,Σ) denotes the Gaussian
distribution with mean vector µ and covariance matrix Σ; P⊥C is
the orthogonal complement projector of matrix C; d·e denotes the
ceiling function.
2. PROBLEM STATEMENT AND ASSUMPTIONS
Consider an M ×N linear spectral mixing model [7]:
y[n] = As[n] +w[n] + z[n],
= x[n] +w[n] + z[n], n = 1, . . . , L, (1)
where y[n] = [ y1[n], . . . , yM [n] ]T ∈ RM is the nth observed
pixel vector comprising M spectral bands, x[n],As[n] is the noise
and outlier free counterpart, in which A = [ a1, . . . ,aN ] ∈
R
M×N denotes the signature matrix whose ith column vector ai
is the ith endmember signature (or simply, endmember), s[n] =
[ s1[n], . . . , sN [n] ]
T ∈ RN is the nth abundance vector com-
prising N fractional abundances, L is the total number of pixels,
w[n] = [ w1[n], . . . , wM [n] ]
T ∼ N (0, σ2IM ) where σ2 is the
noise variance, and z[n] denotes the outlier vector which only ap-
Table 1. The pseudo-codes of the proposed RASF and RASF-NP algorithms.
RASF Algorithm RASF-NP Algorithm
Given A convergence tolerance ε > 0, hyperspectral data {y[n]}Ln=1,
the number of endmembers N , and the number of outliers Z.
S1. Initialize zˆ1 = · · · = zˆL = 0, and iteration number k := 1.
S2. Update the solution of inner minimization problem, dˆ, Cˆ, and
{xˆn}Ln=1 by (5), (6), and (7), respectively.
S3. Update the solution of outer minimization problem {zˆn}Ln=1 by (9)
S4. Calculate fitting error %(k) =
∑L
n=1 ‖y[n] − xˆn − zˆn‖2.
S5. If k = 1 or (%(k − 1) − %(k))/%(k − 1) > ε , update k by k + 1
and go to S2, else output the approximate robust affine set parameters
(Cˆ, dˆ) and the outlier pixel indices Iˆ = {ˆ`1, ..., ˆ`Z}.
Given Upper and lower bounds of the number of outliers (up, lo), the
number of endmembers N , hyperspectral data {y[n]}Ln=1, the noise
covariance matrix σ2IM , and the false alarm rate PFA.
S1. Initialize K1 = d(lo + up)/2e (an integer), and set i := 1.
S2. Obtain {xˆn, zˆ[n]}Ln=1, (Cˆ, dˆ) by the RASF, and e[n] by (10).
S3. Compute {rn}Ln=1 by (11) and find their maximum rˆ by (16).
S4. If ψ(rˆ) > PFA, update up := Ki, otherwise update lo := Ki. Then,
compute Ki+1 = d(up + lo)/2e.
S5. If Ki 6= Ki+1, update i := i + 1 and go to S2, else obtain the
estimate Zˆ = Ki and the estimate (Cˆ, dˆ).
where η is a parameter determined by the preassigned false alarm
rate PFA. Denoting the probability density function (pdf) of the
central Chi-square distribution by fχ2(x,M), we define
ψ(rn) ,
∫ ∞
rn
fχ2(x,M)dx = 1− γ(rn/2,M/2)Γ(M/2) , (14)
where γ(x/2,M/2) is the lower incomplete Gamma function [9].
Then, by Neyman-Pearson lemma [10], the optimal threshold η for
problem (13) must satisfyψ(η) = PFA. Although there is no closed-
form expression for the inverse function of ψ(·), the decision rule in
(13) can be equivalently formulated as
DecideH0 if ψ(rn) < PFA, ∀n ∈ L\{ˆ`1, ..., ˆ`K}, (15a)
DecideH1 if ∃n ∈ L\{ˆ`1, . . . , ˆ`K} such that ψ(rn) > PFA.
(15b)
By the decision rule (15), we need to test at most ψ(r1), ..., ψ(rL) to
decide whether the current K is overestimation H0 (K ≥ Z) or un-
derestimationH1 (K < Z). Because ψ(·) is a monotone decreasing
function, we can further simplify the decision rule by defining
rˆ = max
n∈L\{ˆ`1,..., ˆ`K}
rn, (16)
Then, hypothesis testing in (15) becomes
DecideH0 if ψ(rˆ) > PFA, (17a)
DecideH1 if ψ(rˆ) < PFA. (17b)
Once ψ(rˆ) is evaluated, one of the above two hypotheses is decided.
The pseudo codes proposed RASF-NP algorithm are also given in
Table 1 (right part).
5. SIMULATION AND CONCLUSION
Monte Carlo simulations of 100 independent runs are presented to
demonstrate the performance of the proposed RASF and RASF-NP
methods in this section. In each run, the observed data were syn-
thetically generated following (1) where N = 8 endmembers with
M = 224 bands were selected from the U.S. geological survey
(USGS) library, the number of pixels L is set to 1000, the abundance
vectors were generated following Dirichlet distribution [6], and zero-
mean white Gaussian noise vectors were added for different signal-
to-noise ratios (SNRs), where SNR =∑L
n=1 ‖x[n]‖2/σ2ML. Be-
sides, the outliers were also added to the noisy data, where the outlier
indices `1, . . . , `Z were randomly selected from {1, . . . , L}, and the
associated outliers were generated by
z[`i] = cκi, i = 1, . . . , Z, (18)
in which each element of κi is a zero-mean unit-variance Laplacian
random variable, and c is a scalar adjusted to satisfy signal-to-outlier
ratio (SOR) specification, where
SOR =
∑L
n=1 ‖x[n]‖22/L∑Z
i=1 ‖z[`i]‖22/Z
. (19)
The generation of outliers using Laplacian distribution is to fulfill
the belief that the outliers should be heavily tailed in distribution,
which is highly peaked at zero and falls off more slowly than Gaus-
sian distribution in the tail. When SNR≥SOR, the outlier pixels
y[`1], ...,y[`Z ] are corrupted by the outliers z[`1], ..., z[`Z ] more
seriously than the noise; otherwise, the case of SOR≥SNR means
that the effects of the outliers z[`1], ..., z[`Z ] are smaller than the
noise effects, thereby making the outlier pixels y[`1], ...,y[`Z ] not
much different from the rest of the observed pixel vectors.
Three performance indices were used in the simulations. The
distance between the true affine setA(C,d) and the estimated affine
set A(Cˆ, dˆ), denoted by Daff , for evaluation of the accuracy of the
RASF is defined as
Daff =
‖CCT − CˆCˆT ‖F√
2
+
‖P⊥Cd−P⊥Cˆdˆ‖
‖P⊥
C
d‖+ ‖P⊥
Cˆ
dˆ‖ , (20)
where ‖ · ‖F stands for Frobenius-norm. The first term, in range
[0, 1], is called the projection F-norm [12] and it measures the dis-
tance between the range space of C and Cˆ, and the second term
in range [0, 1] quantifies the error between P⊥Cd and P⊥Cˆdˆ. The
root-mean-square (rms) spectral angle distance between the true end-
members and estimated endmembers, denoted by φ (in degrees), was
used as an accuracy measure of EEAs [6]. The smaller the values of
Daff (or φ), the better the accuracy of the affine set estimates (or the
endmember estimates). The computation time T (in seconds) of each
algorithm (implemented in Mathworks Matlab R2008a) running in a
desktop computer equipped with Core i7-930 CPU 2.80 GHz, 12GB
memory is used as the computational complexity measure.
The first simulation examines the performance of the proposed
RASF with different choices of the number of outliers K. Fig-
ure 1 shows the average Daff of ASF and RASF with K =
2%L, 5%L, 8%L for Z = 5%L, SNR=15, 25, 35, 45,∞ dB and
SOR=15, 25 dB. It can be observed that RASF algorithm perfectly
identifies the true affine set when SNR=∞ and K ≥ Z. One can
also notice that RASF outperforms ASF for all the values of K un-
der test when SOR ≤ SNR, and that the RASF algorithm in the case
ofK ≥ Z outperforms the case ofK < Z for SOR≤ SNR. This im-
plies that as long as the outlier pixels were corrupted by outliers more
heavily than noise, the RASF algorithm can always mitigate the out-
lier effects. On the other hand, if the outliers have lower power than
noise, they are simply treated as noise.
 1 
出席 ICASSP-2013國際學術會議心得報告 
                                                             
計畫編號 NSC 99-2221-E-007-003-MY3  
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 5/26-5/31 2013, Vancouver, Canada  
會議名稱 2013 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP-2013)  
發表論文題目 
#1.  Outage constrained weighted sum rate maximization for MISO interference 
channel by pricing-based optimization (W.-C. Li, T.-H. Chang, C. Lin, and 
Chong-Yung Chi)   
#2.  On the endmember identifiability of Craig's criterion for hyperspectral 
unmixing: A statistical analysis for three-source case (C.-H. Lin, A. 
Ambikapathi, W.-C. Li, and Chong-Yung Chi)   
 
一、參加會議經過 
 
筆者於 102年 5月 26日 (Sunday night) 從桃園中正機場出發，於 5月 26日 (Sunday night)抵
達 Vancouver, Canada, and checked in the hotel (Holiday Inn & Suites, Vancouver). The 38th 
ICASSP-2013, a flagship international conference on Signal Processing, was held in Vancouver 
convention center, 5/26-5/31. The total submissions of regular papers reached 3314 (a record number 
in the history of ICASSP submission since early 1970’s), and 1725 papers were accepted. The 
following is a summary of the major activities and events that I participated in during the period of 
ICASSP-2013.  
 
5/27 (Monday): 完成報到手續 and met some international friends and experts. The conference 
venue (Vancouver convention center) is on the beautiful coast. A lot of people enjoyed the 
beautiful scene every day.  
 
5/28 (Tuesday): Main activities are as follows:  
(a) 10:50-12:50: Served as the Session Chair of SPCOM-P (Sensor Networks I). This poster 
session includes 14 excellent papers, drawing the attention of a lot of audience with 
intensive interactions with the presenters;  
(b) 12:50-14:20: Attended IEEE Transactions on Signal Processing (TSP) Editorial Board 
Meeting, discussing various issues on paper submissions, reviews, etc. TSP has been long 
recognized as one of the best international journal on Signal Processing. I am glad to serve 
 3 
Workshop SPAWC-2014 (to be held in Toronto, June 2014).  
 
5/30 (Thursday): Main activities are as follows:   
(a) 10:30-12:30: Attended IVMSP- P10 (Remote Sensing) where, in parallel with the other 13 
papers, we presented Paper #2 (On the endmember identifiability of Craig's criterion for 
hyperspectral unmixing: A statistical analysis for three-source case). Our paper, presented by 
my Ph.D. student Wei-Chiang Li and myself, has drawn quite some international experts’ 
attention in hyperspectral unmixing research, won high appreciation. The journal version 
paper has been under preparation at the final stage and should be submitted for publication 
in June. A photo of mine is attached during the presentation.  
 
 
5/31 (Friday): Since all my missions have been accomplished. So I just listed to some paper 
presentations that I am interested in, and making friends with international experts and researchers, 
during the day time. Then I left for Vancouver international airport in the evening to fly back (my 
flight is EVA air 02:20, Jun 1), and arrived at Taoyuan international airport around 5 am, June 2 
(Sunday).  
 
攜回資料：ICASSP-2013會議論文集之隨身碟一支。  
 
 
 
OUTAGE CONSTRAINED WEIGHTED SUM RATE MAXIMIZATION FOR MISO
INTERFERENCE CHANNEL BY PRICING-BASED OPTIMIZATION
Wei-Chiang Li?, Tsung-Hui Chang†, Che Lin?, and Chong-Yung Chi?
? Institute of Communications Engineering & Department of Electrical Engineering,
National Tsing Hua University, Hsinchu, Taiwan 30013
† Department of Electronic and Computer Engineering
National Taiwan University of Science and Technology, Taipei, Taiwan 10607
E-mail: {weichiangli, tsunghui.chang}@gmail.com, {clin, cychi}@ee.nthu.edu.tw
ABSTRACT
This paper considers beamforming designs for weighted sum rate
maximization (WSRM) in a multiple-input single-output interfer-
ence channel subject to probability constraints on the rate outage.
We claim that the outage probability constrained WSRM problem is
an NP-hard problem, and therefore focus on devising efficient ap-
proximation methods. In particular, inspired by an insightful prob-
lem reformulation, a pricing-based sequential optimization (PSO)
algorithm is proposed for efficiently handling the considered out-
age constrained WSRM problem. We show that the proposed PSO
algorithm has semi-analytical beamforming solutions in each itera-
tion, and hence can be efficiently implemented. Moreover, the PSO
algorithm upon convergence can reach a point satisfying Karush-
Kuhn-Tucker (KKT) conditions of the original outage constrained
problem. Simulation results show that the proposed PSO algorithm
not only can yield competing weighted sum rate performance, but
also is computationally more efficient than the existing method [1].
Index Terms— Interference channel, weighted sum rate maxi-
mization, outage probability, transmit beamforming
1. INTRODUCTION
Inter-cell cooperation has been recognized essential to improving
the spectral efficiency of wireless cellular networks [2]. Consider
a multiple-input single-output interference channel (MISO IFC) [3]
where K multi-antenna transmitters simultaneously communicate
with K single-antenna receivers over a common frequency band.
When instantaneous channel state information (CSI) is available at
the transmitters, it has been shown that transmit beamforming is
a Pareto optimal transmission strategy for the MISO IFC [3, 4].
However, practically finding such optimal beamformers is a diffi-
cult task. In fact, it has been shown that beamforming design prob-
lems for maximizing a class of commonly used rate utilities, (e.g.,
the weighted sum rate) are NP-hard in general [5]. Consequently,
many research efforts have been devoted to investigate suboptimal
but computationally efficient approximation algorithms [5, 6].
Considering that it is not always feasible to obtain instantaneous
CSI, especially in fast fading scenarios, there are parallel works
that study the MISO IFC with only channel distribution information
(CDI) available at the transmitters [7, 8]. For example, assuming
that each MISO channel is (circularly symmetric) complex Gaussian
distributed, the authors in [7] characterized the structure of Pareto
optimal beamformers for an ergodic achievable rate region. The
This work is supported by National Science Council, R.O.C., under
Grant NSC-99-2221-E-007-052-MY3 and Grant NSC 101-2218-E-011-043.
authors of [8, 9] instead considered an outage constrained scenario
where the probability of the rate outage is constrained to be no larger
than a predefined, usually small value. In particular, the works in
[8, 9] studied the outage constrained achievable rate region for a
two-user MISO IFC, and presented a numerical method for attaining
the Pareto boundary. This method, however, has a complexity that
increases exponentially with the number of users.
In this paper, we assume that only CDI is available at the trans-
mitters, and study the beamforming design problem for weighted
sum rate maximization (WSRM) under outage probability con-
straints. The goal is to develop efficient algorithms for obtaining the
outage constrained optimal beamformers. However, our complexity
analysis shows that such outage constrained WSRM problem is
intricate – it is NP-hard in general. We thereby focus on devising ef-
ficient approximation methods. In particular, by carefully inspecting
the constraint structure, we reformulate the original outage con-
strained problem as a form that is analogous to the WSRM problem
with instantaneous CSI in [5]. This intriguing connection inspires
us to propose a pricing-based sequential optimization (PSO) algo-
rithm [10] for efficiently handling the considered outage constrained
WSRM problem. We show that the proposed PSO algorithm can
improve the system sum rate from iteration to iteration, and, when
upon convergence, can reach a Karush-Kuhn-Tucker (KKT) point
of the original problem. Moreover, the subproblem involved in each
iteration has semi-analytical solutions which can be implemented
efficiently. The presented simulation results show that the PSO algo-
rithm is computationally more efficient than the previously proposed
distributed SCA (DSCA) algorithm in [1], though both methods can
yield almost the same sum rate performance.
2. SIGNAL MODEL AND PROBLEM STATEMENT
We consider a MISO IFC consisting of K pairs of multiple-antenna
transmitters and single-antenna receivers. Each transmitter is
equipped with Nt antennae, and communicates with its intended
receiver using transmit beamforming. The transmit signal from
transmitter i is given by wisi, where si ∼ CN (0, 1) is the informa-
tion signal for receiver i, andwi ∈ CNt is the associated beamform-
ing vector, for i = 1, . . . ,K. Let hik ∈ CNt denote the channel
vector between transmitter i and receiver k, for all i, k = 1, . . . ,K.
Here, we assume that each hik ∼ CN (0,Qik) with Qik  0
(positive semidefinite) denoting the channel covariance matrix. The
received signal at receiver i is given by
xi = h
H
iiwisi +
K∑
k=1,k 6=i
h
H
kiwksk + ni, (1)
where ξi({w¯k}k 6=i) is the unique solution to Φi(x|{w¯k}k 6=i) = 11.
The terms−piikwHi Qikwi, k 6= i, respectively weighted by the unit
prices {piik}k 6=i, in the objective function imply that the throughput
of user i is maximized at the cost of the interference induced by
transmitter i to the other receivers. For notational simplicity, let us
denote
Iik , w
H
i Qikwi (I¯ik , w¯
H
i Qikw¯i)
for all i, k = 1, . . . ,K. Moreover, define
U({Ij`}
K
j,`=1) ,
K∑
i=1
αi log(1 + ξi({Iki}k 6=i)Iii) (9)
as an alternative expression of the objective function of (7), where
ξi({Iki}k 6=i) , ξi({wk}k 6=i) (by (4), (5) and (6)) for all i =
1, . . . , K. According to [10, 14], the unit prices are given by
piik = −
1
αi
∂U({Ij`}
K
j,`=1)
∂Iik
∣∣∣∣∣
Ij`=I¯j` ∀j,`
(10)
for all k 6= i. Specifically, by (9) and by applying the implicit func-
tion theorem [15] for computing the gradient of ξk({Ijk}j 6=k) with
respect to Iik, one can show that piik has an explicit form as
piik =
αk
αi
I¯kkξk({I¯jk}j 6=k)
1 + I¯kkξk({I¯jk}j 6=k)
[(
σ2k+
∑
` 6=i,k
I¯`k
1 + I¯`kξk({I¯jk}j 6=k)
)
×
(
1+I¯ikξk({I¯jk}j 6=k)
)
+I¯ik
]−1
. (11)
The optimization steps of the proposed PSO algorithm for handling
problem (7) (i.e., problem (2)) is presented in Algorithm 1.
Algorithm 1 Proposed PSO algorithm for problem (7)
1: Given an initial set of w¯1, . . . , w¯K satisfying (7b);
2: Set I¯ik := w¯Hi Qikw¯i ∀i, k = 1, . . . ,K, and compute
ξk({I¯jk}j 6=k), k = 1, . . . ,K, by bisection;
3: repeat
4: for i = 1, . . . , K do
5: Compute the unit prices {piik}k 6=i by (11);
6: Solve problem (8) by Proposition 2 below to obtain an
optimal solution w?i , followed by updating w¯i withw?i ;
7: Update I¯ik = w¯Hi Qikw¯i, k = 1, . . . , K, and compute
ξk({I¯jk}j 6=k), k = 1, . . . ,K;
8: end for
9: until the predefined stopping criterion is met.
10: Output (w¯1, . . . , w¯K) as an approximate solution to (7).
While Algorithm 1 seems to be a straightforward application of
the pricing-based method in [10, 14] to problem (7), it is actually
not obvious to see whether Algorithm 1 can reach any interesting
point of problem (7). This is mainly because ξ1({Ik1}k 6=1), . . . ,
ξK({IkK}k 6=K) are implicit. To answer the above question, let us
analyze the relation between problem (8) and the original problem
(7). The following lemma is needed in the subsequent analysis.
Lemma 1 For each i ∈ {1, . . . ,K} and k ∈ {1, . . . ,K}\{i},
the individual rate log(1 + ξk({Ijk}j 6=k)Ikk) is strictly convex in
Iik ≥ 0 for any given {Ijk ≥ 0}j 6=i.
1Since Φi(x|{w¯k}k 6=i) in (4) is strictly increasing in x, and
Φi(ξi({w¯k}k 6=i)|{w¯k}k 6=i) = 1. The value ξi({w¯k}k 6=i) can easily be
obtained via a bisection method.
The proof of Lemma 1 is presented in the Appendix. By Lemma 1,
(10), and by the first-order condition of convex functions, we have
αk log
(
1 + ξk({I¯jk}j 6=k,i, Iik)I¯kk
)
≥ αk log(1 + ξk({I¯jk}j 6=k,i, I¯ik)I¯kk)− αipiik(Iik − I¯ik),
for all k ∈ {1, . . . ,K}\{i}. Hence, it follows from (9) and the
above inequality that
U(Ii1, . . . , IiK , {I¯j1, . . . , I¯jK}j 6=i)
≥ αi log(1 + ξi({I¯ki}k 6=i)Iii)− αi
∑
k 6=i
piik(Iik − I¯ik)
+
∑
k 6=i
αk log(1 + ξk({I¯jk}j 6=k,i, I¯ik)I¯kk) (12)
, U
(i)
LB({Ii`}
K
`=1
∣∣{I¯j1, . . . , I¯jK}j 6=i).
Since the sum of the first two terms on the right hand side of (12) is
proportional to the objective function in (8), optimizing problem (8)
for user i is equivalent to maximizing the lower bound U (i)LB.
More importantly, one can check that U (i)LB is locally tight, in the
sense that
U
(i)
LB({I¯i`}
K
`=1
∣∣{I¯j1, . . . , I¯jK}j 6=i) = U({I¯j`}Kj,`=1), (13)
for i = 1, . . . ,K. Therefore, using an argument similar to [14,
Lemma 1], one can show that the weighted sum rate U({I¯j`}Kj,`=1)
achieved by w¯1, . . . , w¯K in Algorithm 1 would be non-decreasing
from one iteration to another. This, together with the fact that
U({I¯j`}
K
j,`=1) is bounded due to the power constraints (7b), implies
that U({I¯j`}Kj,`=1) eventually will converge. Besides, U
(i)
LB has
locally tight gradients, i.e.,
∂U
(i)
LB({I¯i`}
K
`=1
∣∣{I¯j1, . . . , I¯jK}j 6=i)
∂Iik
=
∂U({I¯j`}
K
j,`=1)
∂Iik
, (14)
for all k, i = 1, . . . ,K. This property can be exploited to show that
Algorithm 1, upon the convergence of (w¯1, . . . , w¯K), attains a KKT
point of problem (7). The detailed derivations are omitted here due
to space limit. We summarize the above analyses in the following
proposition.
Proposition 1 The weighted sum rate U({I¯j`}Kj,`=1) achieved in
each iteration of Algorithm 1 converges monotonically. Moreover,
any convergent point of (w¯1, . . . , w¯K) is a KKT point of (7).
4.3. Efficient Implementation of PSO Algorithm
An important computational aspect of Algorithm 1 lies in how to ef-
ficiently solve problem (8), which is not convex. A similar problem
was studied in [10] for the WSRM problem with instantaneous CSI;
however, the approach to handling such problem is via linear ap-
proximation, and hence is suboptimal. We herein provide the global
optimal solution to problem (8) in a semi-analytical form.
The proposed approach is based on the popular semidefinite re-
laxation (SDR) technique [16]. In particular, we relax the rank-one
matrix wiwHi to a rank-unconstrained positive semidefinite matrix
Wi  0, and consider the following convex problem
max
Wi0
log
(
1+ξi({I¯ki}k 6=i)Tr(WiQii)
)
−Tr
(
Wi
∑
k 6=i
piikQik
)
s.t. Tr(Wi)≤Pi. (15)
A key finding is that the SDR problem (15) has a rank-one optimal
solution, as stated in the following proposition.
7. REFERENCES
[1] W.-C. Li, T.-H. Chang, C. Lin, and C.-Y. Chi, “Coordinated beamform-
ing for multiuser MISO interference channel under rate outage con-
straints,” to appear in IEEE Trans. Signal Process.
[2] E. G. Larsson and E. A. Jorswieck, “Competition versus cooperation on
the MISO interference channel,” IEEE J. Sel. Areas Commun., vol. 26,
pp. 1059–1069, Sep. 2008.
[3] E. A. Jorswieck, E. G. Larsson, and D. Danev, “Complete characteriza-
tion of the Pareto boundary for the MISO interference channel,” IEEE
Trans. Signal Process., vol. 56, pp. 5292–5296, July 2008.
[4] X. Shang, B. Chen, and H. V. Poor, “Multiuser MISO interference
channels with single-user detection: Optimality of beamforming and
the achievable rate region,” IEEE Trans. Inf. Theory, vol. 57, pp. 4255–
4273, July 2011.
[5] Y.-F. Liu and Z.-Q. Luo, “Coordinated beamforming for MISO inter-
ference channel: Complexity analysis and efficient algorithms,” IEEE
Trans. Signal Process., vol. 59, pp. 1142–1157, Mar. 2011.
[6] R. Zhang and S. Cui, “Cooperative interference management with
MISO beamforming,” IEEE Trans. Signal Process., vol. 58, pp. 5450–
5458, Oct. 2010.
[7] E. Bjo¨rnson, R. Zakhour, D. Gesbert, and B. Ottersten, “Cooperative
multicell precoding: Rate region characterization and distributed strate-
gies with instantaneous and statistical CSI,” IEEE Trans. Signal Pro-
cess., vol. 58, pp. 4298–4310, Aug. 2010.
[8] J. Lindblom, E. Karipidis, and E. G. Larsson, “Outage rate regions for
the MISO IFC,” in Proc. Asilomar Conference on Signals, Systems and
Computers, Pacific Grove, CA, Nov. 1-4, 2009, pp. 1120–1124.
[9] ——, “Outage rate regions for the MISO interference channel: Defini-
tions and interpretations,” http://arxiv.org/abs/1106.5615v1.
[10] D. A. Schmidt, C. Shi, R. A. Berry, M. L. Honig, and W. Utschick,
“Distributed resource allocation schemes: Pricing algorithms for power
control and beamformer design in interference networks,” IEEE Signal
Process. Mag., vol. 26, pp. 53–63, Sep. 2009.
[11] J. Lindblom, E. G. Larsson, and E. A. Jorswieck, “Parameterization
of the MISO interference channel with transmit beamforming and par-
tial channel state information,” in Proc. Asilomar Conference on Sig-
nals, Systems and Computers, Pacific Grove, CA, Oct. 26-29, 2008, pp.
1103–1107.
[12] R. M. Karp, “Reducibility among combinatorial problems,” in 50 Years
of Integer Programming 1958-2008, M. Ju¨nger, T. M. Liebling, D. Nad-
def, G. L. Nemhauser, W. R. Pulleyblank, G. Reinelt, G. Rinaldi, and
L. A. Wolsey, Eds. Springer Berlin Heidelberg, 2010, ch. 8, pp. 219–
241.
[13] Z.-Q. Luo and S. Zhang, “Dynamic spectrum management: Complex-
ity and duality,” IEEE J. Sel. Topics Signal Process., vol. 2, pp. 57–73,
Feb. 2008.
[14] C. Shi, R. A. Berry, and M. L. Honig, “Monotonic convergence of dis-
tributed interference pricing in wireless networks,” in Proc. IEEE ISIT,
Seoul, Korea, June 28-July 3, 2009, pp. 1619–1623.
[15] S. G. Krantz and H. R. Parks, The Implicit Function Theorem: History,
Theory, and Applications. Boston, MA: Birkha¨user, 2002.
[16] Z.-Q. Luo, W.-K. Ma, A. M.-C. So, Y. Ye, and S. Zhang, “Semidefinite
relaxation of quadratic optimization problems,” IEEE Signal Process.
Mag., vol. 27, pp. 20 –34, May 2010.
[17] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge, UK:
Cambridge University Press, 2004.
[18] M. Grant and S. Boyd, “CVX: Matlab software for disciplined convex
programming, version 1.21,” http://cvxr.com/cvx, Apr. 2011.
and by (A3) conv{a1, . . . ,aN} is a simplex [9] [10]. As there exists
a one-to-one relationship between xn and sn, for all n, the ensuing
EI analysis will be based on sn. As a first step in this direction of
EI, in this work, we will consider N = 3 (in which case the simplex
conv{a1,a2,a3} is a triangle and its interior) and L → ∞ (note
that the number of pixels can be very large in reality [2]). Precisely,
our aim is to find the conditions on sn, for which the vertices of the
minimum volume simplex enclosing xn, for all n (Craig’s criterion)
will exactly be {a1,a2,a3}. Below, we define some parameters,
sets, and their properties (some illustrated in Figure 1), which will
be extensively used in the ensuing analysis.
Definitions and Properties:
• Given an observed data xn, we define its pixel purity index to be
ρn , ‖sn‖, where sn is the corresponding abundance vector of
xn. ρn ∈ [1/
√
N = 1/
√
3, 1] and the bounds are due to (A1)
and (A2) [7].
• ρn indicates the quantitative dominance of an endmember ai in
the observed data xn =
∑
3
i=1 sinai [7]. For instance, ρn = 1
indicates that the pixel is completely dominated by an endmember
and ρn = 1/
√
3 indicates that the pixel is heavily mixed, as it is
equally contributed by all the 3 endmembers.
• Let Te , {s = [s1, s2, s3]T ∈ R3|si ≥ 0,∑3i=1 si = 1} =
conv{e1, e2, e3}, where e1, e2, e3 ∈ R3. Note that Te is an equi-
lateral triangle.
• For each ρ ∈ [1/√3, 1], let R(ρ) , Te⋂{s ∈ R3| ‖s‖ ≤ ρ}.
Then, R(ρ1) ⊆ R(ρ2), ∀1/
√
3 ≤ ρ1 ≤ ρ2 ≤ 1.
• Let C(ρ) , aff{e1, e2, e3}⋂{s ∈ R3| ‖s‖ ≤ ρ}, which is a
nonempty disc when ρ ∈ [1/√3, 1], and let r(ρ) be its radius. It
is obvious that C(ρ1) ⊆ C(ρ2), ∀1/
√
3 ≤ ρ1 ≤ ρ2 ≤ 1.
• As Te ⊆ aff{e1, e2, e3}, note that R(ρ) = Te⋂ C(ρ). Also
R(1) = Te and R(ρ) = C(ρ), ∀ρ ∈ [1/
√
3, 1/
√
2].
• For each simplex T in aff{a1,a2,a3} or aff{e1, e2, e3}, we de-
fine vol(T ) to be the Lebesgue measure of T with respect to its
affine hull [11]. In our case of N = 3, vol(T ) is just the area of
T .
• Note that C(1/√2) is exactly the inner tangent circle of the equi-
lateral triangle Te, and thus [12]
vol(Te) = 3
√
3r2(1/
√
2). (2)
e1
[1, 0, 0]
e2
[0, 1, 0]
e3
[0, 0, 1]
r(ρ)
C(ρ)
R(ρ)
TeR3
Fig. 1. Figure illustrating some notations used in the sequel.
• Let Ta , conv{a1,a2,a3} ⊆ RM be the simplex that has ver-
tices a1, a2, and a3. Also by (A1) and (A2), xn ∈ Ta and
sn ∈ Te, for all n.
• We can define a one-to-one transformation T : R3 → RM , to be
the unique linear transformation such that T (ei) = ai for i =
1, 2, 3. Clearly, T (v) = Av for each v ∈ R3. Therefore, each
vector in Te can be uniquely mapped to a vector in Ta, and vice
versa.
• Since T is linear and it maps the aff{e1, e2, e3} onto the
aff{a1,a2,a3}, due to (A3), there exists a positive number α > 0
such that
vol(T (Tg)) = α · vol(Tg), ∀ Tg ⊆ aff{e1, e2, e3}, (3)
vol(T−1(Th)) = α−1 · vol(Th),∀ Th ⊆ aff{a1, a2,a3}, (4)
where Tg and Th are simplexes. To determine the con-
stant α, we note that vol(Ta) = vol(conv{a1, a2,a3}) =
vol(T (conv{e1, e2, e3})) = α · vol(conv{e1, e2, e3}), and thus
α = vol(Ta)/vol(Te).
• For each bounded subset U in aff{a1,a2,a3} or aff{e1, e2, e3},
let MVES(U) be the collection of all the minimum volume en-
closing simplexes (triangles for N = 3) that contain U .
• For a given set U ⊆ R3, the conv(U) is defined as the the inter-
section of all the convex sets which contain U [13].
• Let XL , {x1, . . . ,xL} denotes a data set, and define the abun-
dance set of XL to be SL , {s1, . . . , sL} where sn is the corre-
sponding abundance vector of xn.
Now we can proceed to define a very important concept called
purity level.
Definition 1 (Purity Level) A data setXL is said to have purity level
ρ ∈ [1/√3, 1], if each vector in its corresponding abundance set SL
is independently generated with a probability density function (pdf)
f : R(ρ)→ [0,∞) that satisfies
(A4)
∫
s∈D
f(s)ds > 0, ∀D ⊆ R(ρ) with vol(D) > 0. (5)
More generally, for a set, limL→∞ XL, with purity level ρ, it can be
shown that
Pr{sup{ lim
L→∞
{ρ1, . . . , ρL}} = ρ} = 1, (6)
where sup{·} denotes supremum of a set and ρn is the pixel purity
index of xn ∈ XL. Also note that the pdf in (5) is also very gen-
eral and any meaningful pdf for sn will satisfy (5). For instance, the
Dirichlet distribution considered in [14] (for sn) satisfies this prop-
erty. The following well-know property [12] will be handy in the EI
analysis presented in Section 3:
Property 1 If C is a disc with radius r, then MVES(C) is exactly the
collection of all equilateral triangles with bd(C) as its inner tangent
circle, and they have volume 3
√
3r2. Conversely, if a triangle T ⊃
C and vol(T ) = 3√3r2, then T must be an equilateral triangle.
3. ENDMEMBER IDENTIFIABILITY OF MVES
In this section, we will derive the conditions for perfect EI of the
Craig’s criterion under the premises of (A1) to (A4). The main re-
sults are given in the following theorem:
Theorem 1 Assume that the data set XL has purity level ρ ∈
[1/
√
3, 1], for any L ∈ Z+, and ρ? , 1/
√
2. Then the following
statements are true for endmember identifiability of Craig’s crite-
rion:
1 ≥ Pr{S⋂i 6= ∅ for all i ∈ {1, ..., 8}} = 1 − Pr{S ⋂i =
∅ for some i ∈ {1, ..., 8}} ≥ 1 − ∑8i=1 Pr{S⋂i = ∅} =
1−∑8i=1 0 = 1, that is
Pr{S
⋂
i 6= ∅ for all i ∈ {1, ..., 8}} = 1. (16)
Now we define two events E1 and E2, and show that E1 implies E2.
E1: S
⋂
i 6= ∅ for all i ∈ {1, ..., 8}, (17)
E2: y ∈ conv(S). (18)
Assume that E1 is true. Then there exists eight vectors sy1 , ..., s
y
8 ∈
S such that syi ∈ i for each i = 1, . . . , 8. But 9 must be con-
tained in conv(sy1 , ..., s
y
8 ). Thus, y ∈ 9 ⊆ conv(sy1 , ..., sy8 ) ⊆
conv(S), i.e., E2 is true. Then we have from (16) that 1 =
Pr{E1} ≤ Pr{E2} ≤ 1, i.e.,
Pr{y ∈ conv(S)} = 1 for each y ∈ Y. (19)
But Y can be represented as {y1,y2,y3, ...} since it is count-
able. Thus we have 1 ≥ Pr{Y ⊆ conv(S)} = 1 − Pr{yi /∈
conv(S) for some i ∈ Z+} = 1 − Pr{⋃∞i=1{yi /∈ conv(S)}} ≥
1−∑∞i=1 Pr{yi /∈ conv(S)} = 1−∑∞i=1 0 = 1 (by (19)), that is
Pr{Y ⊆ conv(S)} = 1. However, this implies
Pr{conv{Y} ⊆ conv(S)} = 1. (20)
To show int(R(ρ)) ⊆ conv{Y}, we fix z ∈ int(R(ρ)) and
then prove that z ∈ conv{Y}. Since int(R(ρ)) is open, there exists
ε′′ > 0 and a square (z; ε′′) with center z and side length ε′′ such
that (z; ε′′) ⊆ int(R(ρ)). As before, we evenly divide (z; ε′′)
into 9 sub-squares with side length ε′′′ = ε′′/3, and label them by
′1,
′
2, ...,
′
9 (in the same order as in Figure 2). Since vol(′i) =
(ε′′′)2 = (ε′′)2/9 > 0 and Y is dense in int(R(ρ)), there exist eight
vectors sz1, ..., s
z
8 ∈ Y such that szi ∈ i for each i = 1, 2, ..., 8.
Clearly, 9 must be contained in conv{sz1, ..., sz8}, so we have z ∈
9 ⊆ conv{sz1, ..., sz8} ⊆ conv{Y}. Thus we have shown that
int(R(ρ)) ⊆ conv{Y}. (21)
Therefore, we have from (20) and (21) that Pr{int(R(ρ)) ⊆
conv(S)} = 1. 
4.3. Proof of Lemma 3:
(Necessity) We prove the necessity by contradiction. Suppose that
ρ ∈ [1/√3, 1/√2]. Then R(ρ) = C(ρ), which is a disc on
aff(e1, e2, e3) with radius r(ρ) (see Figure 3). Thus, by Property
1, MVES(R(ρ)) is exactly the collection of infinitely many equilat-
eral triangles with bd(C(ρ)) as inner tangent circle. Hence, Te is not
the unique MVES of R(ρ), i.e., MVES(R(ρ)) 6= {Te}.
(Sufficiency) Fix ρ ∈ (1/√2, 1]. Suppose that ρ˜ ∈ [1/√2, 1]. Then
we have from definition of R(ρ) that
R(1/
√
2) ⊆ R(ρ˜) ⊆ R(1) = Te. (22)
Let Tρ˜ ∈ MVES(R(ρ˜)), for each ρ˜ ∈ [1/
√
2, 1]. Then one can infer
from (22) that
vol(T
1/
√
2
) ≤ vol(Tρ˜) ≤ vol(Te). (23)
Since R(1/√2) is exactly the disc C(1/√2), by Property 1 and by
(2), we have vol(T
1/
√
2
) = 3
√
3r2(1/
√
2) = vol(Te). Hence, the
inequalities in (23) hold with equalities, i.e.,
vol(Tρ˜) = vol(Te) = 3
√
3r2(1/
√
2), ∀ρ˜ ∈ [1/
√
2, 1]. (24)
e1e1
e2e2 e3e3
R(ρ)
(ρ < 1/
√
2)
R(ρ)
(ρ > 1/
√
2)
R3
Fig. 3. R(ρ) when ρ < 1/√2 (left) and when ρ > 1/√2 (right).
On the other hand, let 1/
√
2 ≤ ρ′ ≤ ρ′′ ≤ 1, it is straightforward to
see that R(ρ′) ⊆ R(ρ′′) ⊆ Tρ′′ , so Tρ′′ ∈ MVES(Tρ′′), is also an
MVES of R(ρ′) (by (24)), which implies
MVES(R(ρ′′)) ⊆ MVES(R(ρ′)), for 1/
√
2 ≤ ρ′ ≤ ρ′′ ≤ 1.
(25)
We would like to note that, since R(1) = Te, MVES(R(1))
is exactly the singleton {Te}, and, by (25), we know that Te ∈
MVES(R(ρ)).
Thus, what remains to be proved in Lemma 3 is to show that
MVES(R(ρ)) is exactly the singleton {Te}. We prove this by
contradiction. Suppose that there exists a simplex T ′e such that
T ′e ∈ MVES(R(ρ)) and T ′e 6= Te. By (25), T ′e is also an MVES
of R(1/√2) = C(1/√2), and it must be an equilateral triangle
with bd(C(1/√2)) as inner tangent circle. Let t be an intersec-
tion point of T ′e and C(1/
√
2), i.e., t ∈ bd(T ′e ) ∩ bd(C(1/
√
2)).
It is obvious that t ∈ bd(C(1/√2)) ⊆ int(C(ρ)). On the other
hand, since T ′e 6= Te, the intersection points of T ′e and C(1/
√
2)
must be different from those of Te and C(1/
√
2). Hence, t 6∈
bd(C(1/√2)) ∩ bd(Te), but this together with t ∈ bd(C(1/
√
2))
gives t ∈ int(Te). Thus t ∈ [bd(T ′e ) ∩ int(C(ρ))] ∩ [int(C(ρ)) ∩
int(Te)] = [bd(T ′e ) ∩ int(C(ρ))] ∩ int(R(ρ)). It is obvious that
[bd(T ′e ) ∩ int(C(ρ))] ⊆ bd(T ′e ∩ C(ρ)), thus we obtain
t ∈ bd(R′(ρ)) ∩ int(R(ρ)), (26)
where R′(ρ) , T ′e ∩ C(ρ). However, since T ′e ∈ MVES(R(ρ)),
we have R(ρ) ⊆ T ′e , and hence R(ρ) ⊆ R′(ρ). Thus we have
bd(R′(ρ)) ∩ int(R(ρ)) = ∅, which contradicts (26). Therefore,
{Te} must be the unique MVES of R(ρ). 
5. CONCLUSION AND FUTURE DIRECTION
Considering a three-endmember case, the EI analysis for the end-
member identifiability of MVES, results in a necessary condition
and statistically sufficient condition on the purity level, as stated and
proved in Theorem 1. The condition in Theorem 1 reveals that un-
like Winter’s criterion (where presence of pure pixels for all end-
members i.e., ρ = 1 is both necessary and sufficient), the condition
required for EI of Craig’s criterion (MVES) is much more realistic
(1/√2 < ρ ≤ 1) as presence of pure pixels is not necessary. This
result fosters the practical applicability of Craig’s criterion based al-
gorithms for HU. Interestingly, the Craig’s MVES concept is not
only used in HU, but also widely used in other blind source separa-
tion problems such as biomedical image analysis, gene micro array
data analysis etc. The identifiability analysis presented in this paper
is a first step in this direction and generalizing the above analysis to
any N > 3 is currently under investigation.
 1 
出席 IEEE ChinaSIP-2013國際學術會議心得報告 
                                                             
計畫編號 NSC 99-2221-E-007-003-MY3  
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 7/06-7/10, 2013, Beijing, China  
會議名稱 2013 IEEE China Summit & International Conference on Signal and Information Processing (ChinaSIP-2013)   
特約邀請演講題目 Convex Geometric Analysis for Non-negative Blind Source Separation (Chong-Yung Chi)   
 
一、參加會議經過 
 
筆者於 102年 7月 06日 (Saturday afternoon) 從桃園中正機場出發，晚上９點抵達中國北京。 
The following is a summary of the major activities and events that I participated in during the 2013 
IEEE China Summit and International Conference on Signal and Information Processing 
(ChinaSIP-2013)。ChinaSIP是特為中國地區訊號及資訊處理學術領域之眾多學者、專家及研究
人員而新成立的會議，相當於 IEEE ICASSP國際會議之等級。 
 
7/07 (Sunday): 完成報到手續 and met international friends and experts  
 
7/08 (Monday): met international friends and experts; participated in  
(a) 09:00-10:00 Plenary talk: “DSP on Graphs” (by Jose M. F. Moura)  
(b) 10:20-12:00 SS3 Practical Applications: Advanced Signal and Array  
(c) 13:20-15:00 Invited Trend/Overview Talks (by Sadaoki, Tokyo Institute of Technology; 
C.-C. Mari Ostendorf, University of Washington; and Zhi-Quan Lou, University of 
Minnesota).  
(d) 15:20-17:00 Invited Trend/Overview Talks (by Kuo, University of Southern California; 
Charles Boumen, Purdue University; En-Hui Yang, University of Waterloo) 
 
7/09 (Tuesday):  
(a) 13:20-15:00 Trends in Signal Processing I: I served as the session chair, and gave an 
invited talk, “Convex Geometric Analysis for Non-negative Blind Source Separation.” My 
talk drew a lot of good response and feedback from the audience, demonstrating our 
researches are cutting edge and high impact researches. The abstract post at the conference 
 3 
Due to my successful invited talk at IEEE ChinaSIP 2013, July 6-10, I was invited by Prof. 
Ce Zhu (together with other participants listening to my talk), University of Electronic 
Science and Technology, Cheng-Du, China, to offer a 2-week short course, Convex 
Optimization from Fundamentals to Applications, in October-November time frame, in order 
to initiate joint research exploration. The purpose for this short course is that participants can 
smoothly and efficiently learn how to solve an optimization problem, from the fundamental 
theory, problem definition, reformation into a convex problem, analysis, algorithm 
implementation, to cutting edge researches (like an exploration journey rather than pure 
mathematics) in signal processing, communications, etc. On the other hand, currently, two 
visiting students, one from Peking University and one from France in my group for their 
Summer intern and joint research exploration; an Indian student and a student form 蘭州大
學 will join my group to pursue Master and Ph.D. degree Fall 2013. Hopefully, we can make 
high-quality and high-impact research contributions to promote our international recognition.    
 
致謝：感謝國科會補助旅費 for the participation of IEEE ChinaSIP-2013。 
 
file:///C|/Users/cychi/Desktop/新增資料夾/TSP.htm[2013/7/30 上午 08:13:59]
Tan Lee, 
The Chinese
University of Hong
Kong
could be linguistic, paralinguistic and non-linguistic in nature. For music signals,
pitch is the most prominent and ubiquitous feature in almost all aspects. Pitch
estimation refers to the process of automatically determining the fundamental
frequency (F0) of an acoustic signal. It can be done by exploiting the time-domain
waveform periodicity, and/or the frequency-domain harmonicity of the signal. These
signal characteristics would be greatly distorted when the signal is contaminated by
background noise or interfered by other sound sources. Effective approaches to
robust pitch estimation include the use of multiple and complementary pitch
representations, the incorporation of human auditory processing mechanisms, and
the use of prior signal and noise models with advanced machine learning
techniques. In this talk, we will discuss the major challenges of robust pitch
estimation for speech and music signals in both single-source and multi-source
scenarios. By comparing and evaluating the state-of-the-art algorithms, we attempt
to identify the key directions for future research in this area. New applications of
auditory pitch analysis will also be presented.
Ta-Sung Lee, 
National Chiao Tung
University
Topic: Signal Processing for Next Generation Mobile Broadband
Communications
Abstract: Signal processing has been an active research area in mobile
communications in the past two decades. In recent years, there has been an
explosive growth of signal processing research addressing different aspects of next
generation mobile broadband communications to meet new challenges such as
super high spectrum efficiency, real-time access, and uniform user experiences in a
cell. In this talk, we will briefly review the current status of the LTE-Advanced
standard and identify several challenges as well as research opportunities for signal
processing in the development of future mobile broadband technologies. In
particular, challenges and potential solutions for heterogeneous networks,
interference management and large scale multi-antenna systems will be addressed.
Xiang-Gen Xia,
University of
Delaware and
Chonbuk National
University
Topic: Robust Remaindering and Signal Processing
Abstract: Robust remaindering problem is how to robustly determine a large
integer from its erroneous remainders. This problem has many applications
including frequency determination from multiple undersampled waveforms, such as
phase unwrapping in SAR imaging of moving targets. When the remainders are
error free, Chinese remainder theorem (CRT) provides a solution. However, it is
well-known that CRT is not robust. This talk is about the latest developments on
this topic.
Abdelhak Zoubir,
Technische
Universität Darmstadt
Topic: Robust Statistics for Signal Processing  
Abstract:Statistical signal processing often relies on strong and precise
assumptions, e.g. optimal estimators, detectors and filters are derived based on a
particular parametric model or a probability distribution of the signal and/or noise or
interference. Optimality, however, is only achieved when the underlying
assumptions hold, and the performance of optimal procedures deteriorates
significantly, even for minor departures from the assumed model. Measurement
campaigns have revealed the presence of heavy tailed or impulsive interference,
which can cause conventional signal processing techniques, especially the ones
derived using the nominal Gaussian probability model, to be biased or to even
break down. The occurrence of impulsive interference has been reported, for
example, in outdoor mobile communication channels, due to switching transients in
power lines, and in radar and sonar systems as a result of natural or man-made
electromagnetic and acoustic interference. Moreover, impulsive interference occurs
in biomedical sensor array measurements of the brain activity (MRI) in various
regions of the human brain, where a complex tissue structure is known to exist. In
geolocation position estimation and tracking, non-line-of-sight signal propagation,
caused by obstacles such as buildings or trees, results in outliers in the
 1 
出席 ISITCE 2010會議心得報告 
                                                             
計畫編號 99-2221-E-007-003-MY3 
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 8/19/2010-8/20/2010, Pohang, Korea  
會議名稱 2010 The 2nd International Symposium on IT Convergence Engineering 
演講題目 Non-Negative Blind Source Separation for Biomedical Image Analysis 
 
 
一、參加會議經過 
筆者於 99年 8月 18日(Wednesday)從桃園中正機場出發，於下午抵達 Pohang, Korea and checked 
in POSTECH。The following is a summary of the major activities and events that I participated in. 
 
8/18 (Wednesday):  
8/19 (Thursday):  
09:15-09:40 Opening Remarks & Introduction 
09:40-09:50 Welcoming Address 
09:50-10:00 Congratulatory Remarks 
10:00-10:40 Keynote Speech 1 Bio-Inspired Research for New Generation Network 
10:40-11:20 Keynote Speech 2 Vehicular Networks and Telematics Applications: Challenges and 
Opportunities 
11:20-12:00 Keynote Speech 3 Green Networks: Reducing Direct and Induced Energy 
Consumption 
14:00-14:30 Convergence of IT in Healthcare: Challenges and Opportunities 
14:30-15:00 Bioelectronics: Challenges, Pitfalls, Perspectives 
15:00-15:30 Non-Negative Blind Source Separation for Biomedical Image Analysis 
15:30-16:00 Sting: A New Platform for Label-Free Biosensing 
16:00-16:30 Multichannel Flexible and Biocompatible Microelectrode for biomedical applications 
16:45-17:15 Stateless and Practical Geographic Routing for Wireless Sensor Networks 
17:15-17:45 Towards Building a Secure Infrastructure on Internet 
17:45-18:15 Building Domain-Specific Search Engine 
18:30-20:30 Symposium Banquet 
 
 1
受邀於北京清華大學開授短期課程、北京交通大學訪問演
講、中國科學院(北京)訪問演講心得報告 
2010/9/8 
 
計畫編號 NSC 99-2221-E-007-003-MY3 
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授 
參訪地點 
2010/8/22-9/04 北京清華大學  
2010/8/25     北京交通大學  
2010/9/01     中國科學院科(北京) 對地觀測與數字地球科學中心 
 
一、北京清華大學開授短期課程、北京交通大學訪問演講、中國科學院(北京) 訪問演
講經過 (8/22-9/04)  
 
筆者於 99年 8月 22日(日) 中午從桃園機場出發，於當日下午約 4點抵達北京，住進
清華大學之甲所(campus hotel)。 
 
8月 23日(一) 09:00-12:00於北京清華大學給第一場演講如下:   
 
Talk A: QoS-Based Transmit Beamforming in the Presence of Eavesdroppers: An 
Optimized Artificial-Noise-Aided Approach  
 
Abstract: Secure transmission techniques have been receiving growing attention in recent years, as a 
viable, powerful alternative to blocking eavesdropping attempts in an open wireless medium. This talk 
proposes a secret transmit beamforming approach using a quality-of-service (QoS)-based perspective. 
Specifically, we establish design formulations that i) constrain the maximum allowable 
signal-to-interference-and-noise ratios (SINRs) of the eavesdroppers, and that ii) provide the intended 
receiver with a satisfactory SINR through either a guaranteed SINR constraint or SINR maximization. The 
proposed designs incorporate a relatively new idea called artificial noise (AN), where a suitable amount of 
AN is added in the transmitted signal to confuse the eavesdroppers. Our designs advocate joint 
optimization of the transmit weights and AN spatial distribution in accordance with the channel state 
information (CSI) of the intended receiver and eavesdroppers. Our formulated design problems are shown 
to be NP-hard in general. We deal with this difficulty by using semidefinite relaxation (SDR), an 
approximation technique based on convex optimization. Interestingly, we prove that SDR can exactly 
 3
Abstract: Non-negative blind source separation (nBSS) is an essential technique to extract non-negative 
source signals from observations without information on how the source signals are mixed in the 
observations. Significant endeavors in developing nBSS are driven by the growing demand in qualitative 
yet quantitative biomedical image analysis. The primary challenge of the existing imaging modalities is 
the inadequate spatial resolution, which consequently makes the value of each image pixel, a mixture of 
multiple non-negative dependent source signals (e.g., normal and tumor tissues in biomedical images). 
Such “mixed pixel problem” would seriously degrade the efficacy of image analysis tools for clinical 
cancer diagnosis. In this talk, two novel nBSS algorithms, namely, non-negative least correlated 
component analysis (nLCA) [1] and convex analysis of mixtures of non-negative sources (CAMNS) [2], 
will be introduced, which, in contrast to independent component analysis based nBSS methods, were 
recently invented without any source statistical independence assumption. What makes these algorithms 
exceptional is their ability to exploit convex analysis and optimization theory to pave the way for novel 
nBSS criteria along with rigorous theoretical proof for perfect source separation. Furthermore, they can be 
efficiently implemented by using any readily available convex optimization solvers and MATLAB source 
codes of nLCA and CAMNS can be found at http://www.ee.nthu.edu.tw/cychi/. We will present some 
interesting experimental results with real dynamic fluorescent images, dynamic contrast-enhanced 
magnetic resonance images (DCE-MRI), and fluorescence microcopy images, which are highly consistent 
with biomedical and biological expectation. 
於演講中與出席師生們(袁保宗教授主持)充分討論研究問題，互動良好，受益良多。 
 
8月 30日(一) 09:00-12:00 & 14:00-15:00  
講述短期課程：Convex optimization problems (II): Second-order Cone and 
Semidefinite Programs  
8月 31日(二) 09:00-12:00 & 14:00-15:00  
講述短期課程：Duality  
 
9月 1日(三) 09:00-12:00參訪中國科學院(北京)並給一場演講如下:  
 
Talk C: Hyperspectral Unmixing: From a Convex Analysis and Optimization 
Perspective 
 
Abstract: In hyperspectral remote sensing, unmixing a data cube into the spectral signatures of 
endmembers and their corresponding abundance fractions plays a crucial role in analyzing the 
mineralogical composition of a solid surface. Such an unmixing problem has a lot in common with 
non-negative blind source separation problem. This talk describes a novel convex analysis and 
optimization perspective to hyperspectral unmixing. Our endeavor is not only motivated by the recent 
prevalence of convex optimization in signal processing, but also by the nature of hyperspectral 
unmixing (specifically, non-negativity and full additivity of abundances) that makes convex analysis 

学 术 报 告
 
题目：
 
Non-negative Blind Source Separation for   
Biomedical Image Analysis 
报告人：Professor  Chong-Yung Chi 
时间：
 
2010年8月28日上午10:00 
地点：
 
九教北609 
Abstract
Biography
Non-negative blind source separation (nBSS) is an essential technique to extract non-negative 
source signals from observations without information on how the source signals are mixed in the 
observations. Significant endeavors in developing nBSS are driven by the growing demand in 
qualitative yet quantitative biomedical image analysis. The primary challenge of the existing 
imaging modalities is the inadequate spatial resolution, which consequently makes the value of 
each image pixel, a mixture of multiple non-negative dependent source signals (e.g., normal and 
tumor tissues in biomedical images). Such “mixed pixel problem” would seriously degrade the 
efficacy of image analysis tools for clinical cancer diagnosis. In this talk, two novel nBSS algorithms, 
namely, non-negative least correlated component analysis (nLCA) and convex analysis of mixtures 
of non-negative sources (CAMNS), will be introduced, which, in contrast to independent component 
analysis based nBSS methods, were recently invented without any source statistical independence 
assumption. What makes these algorithms exceptional is their ability to exploit convex analysis and 
optimization theory to pave the way for novel nBSS criteria along with rigorous theoretical proof for 
perfect source separation. Furthermore, they can be efficiently implemented by using any readily 
available convex optimization solvers and MATLAB source codes of nLCA and CAMNS can be 
found at http://www.ee.nthu.edu.tw/cychi/. We will present some interesting experimental results 
with real dynamic fluorescent images, dynamic contrast-enhanced magnetic resonance images 
(DCE-MRI), and fluorescence microcopy images, which are highly consistent with biomedical and 
biological expectation.
Chong-Yung Chi
 
(祁忠勇) received the Ph.D. degree in Electrical 
Engineering from the University of Southern California, Los Angeles, 
California, in 1983. From 1983 to 1988, he was with the Jet Propulsion 
Laboratory, Pasadena, California. He has been a Professor with the 
Department of Electrical Engineering since 1989 and the Institute of 
Communications Engineering (ICE) since 1999 (also the Chairman of 
ICE during 2002-2005), National Tsing
 
Hua
 
University, Hsinchu, 
Taiwan. He has published more than 160 technical papers, including 
more than 50 journal papers (mostly in IEEE Trans. Signal 
Processing), 2 book chapters and more than 100 peer-reviewed 
conference papers, as well as a graduate-level textbook, Blind 
Equalization and System Identification, Springer-Verlag, 2006. His 
current research interests include signal processing for wireless 
communications, convex analysis and optimization for blind source 
separation, biomedical and hyperspectral
 
image analysis. 
计算机学院信息所
日程安排 
时间：2010年 9月 1日（周三）上午 9:00开始 
地点：中国科学院对地观测中心东区 708会议室 
时  间 内   容 报告人 
09:00～12:00 
学术报告：Hyperspectral Unmixing: from a 
Convex Analysis and Optimization Perspective 祁忠勇教授
交流讨论 
12:00～13:30 午餐 
14:00～17:00 
学术交流：The Impact of Initial Spectral-based 
Classification Performance on the MRF 
Approach for Hyperspectral Imagery Mapping 
李山山 
学术交流：Endmember Extraction of  
Hyperspectral Remote Sensing Images Based on 
the Ant Colony Optimization (ACO) Algorithm 
孙  旭 
学术讨论 
17:30～ 晚宴 
 
 2
nBSS criteria along with rigorous theoretical proof for perfect source separation. Furthermore, they can be 
efficiently implemented by using any readily available convex optimization solvers and MATLAB source 
codes of nLCA and CAMNS can be found at http://www.ee.nthu.edu.tw/cychi/. We will present some 
interesting experimental results with real dynamic fluorescent images, dynamic contrast-enhanced 
magnetic resonance images (DCE-MRI), and fluorescence microcopy images, which are highly consistent 
with biomedical and biological expectation. 
 
於演講中與出席師生們(電子工程系馬榮健教授主持)充分討論研究問題，互動良好，受
益良多。 
 
9月 28日(二) Attend ICIP-2010  
Plenary talk: Visual Signal Analysis and Compression: Rethinking Texture (9:00-10:00)  
Speaker: Prof. Thrasyvoulos N. Pappas, Northwestern University  
Technical Session: Linear and Nonlinear Image Filtering (10:15-13:25)  
Technical Session: Classification III (10:15-13:25)  
Technical Session: Scene Analysis I (14:45-17:55)  
Technical Session: 3D Modeling, Synthesis and Processing (14:45-17:55)  
 
9月 29日(一) Attend ICIP-2010  
Plenary talk: Multimdedia Social Networking: A New Paradigm for Signal and Image  
Processing (9:00-10:00)  
Speaker: Prof. K. J. Ray Liu, University of Maryland, College Park  
Technical Session: Compressive Sensing (10:15-13:25)  
Technical Session: Image Enhancement III (10:15-13:25)  
Technical Session: Segmentation and Quantitative Analysis III (10:15-13:25)  
 
與各國專家學者廣泛交換研究經驗，在吸收新知及建立人際關係受益良多。筆者於 99
年 9月 29日下午從香港出發，於當日晚上抵達桃園機場。 
 
攜回資料：ICIP-2010會議論文集之光碟一片。  
 
二、致謝：感謝國科會補助旅費參訪香港中大文學、參加 IEEE ICIP 2010 研討會。  
 
三、附件：附上演講公告。 
 1 
出席 ICASSP-2011國際學術會議心得報告 
                                                             
計畫編號 
1. NSC 99-2221-E-007-003-MY3  
2. NSC 99-2221-E-007-052-MY3 
計畫名稱 
1. 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
2. 用於快速塊狀衰減通道中合作式多輸入多輸出-正交分頻多工系統之非同調偵
測、通道估計與通道解碼 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 5/22/2011-5/27/2011, Prague, Czech Republic  
會議名稱 2011 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP-2011)  
發表論文題目 
#1.  A Convex Approximation Approach to Weighted Sum Rate Maximization of 
Multiuser MISO Interference Channel Under Outage Constraints (Wei-Chiang 
Li, Tsung-Hui Chang, Che Lin, Chong-Yung Chi)  
#2.  Two Effective and Computationally Efficient Pure-Pixel based Algorithms for 
Hyperspectral Endmember Extraction (ArulMurugan Ambikapathi, Tsung-Han 
Chan, Chong-Yung Chi, Kannan Keizer)  
#3.  Probabilistic SINR Constrained Robust Transmit Beamforming: A 
Bernstein-Type Inequality Based Conservative Approach (Kun-Yu Wang, 
Tsung-Hui Chang, Wing-Kin Ma, Anthony Man-Cho So, Chong-Yung Chi) 
 
一、參加會議經過 
 
筆者於 100年 5月 19日 (Thursday) 從桃園中正機場出發，於 5月 20日 (Friday) 抵達 Prague, 
Czech. The following is a summary of the major activities and events that I participated in. 
 
5/21 (Saturday): Tour at Karlovy Vary  
5/22 (Sunday):  
(a) 完成報到手續 and met international friends and experts;  
(b) attended Tutorial 2 (14:00-17:00): Variational Inequality(VI) Theory: A Mathematical 
Framework for Multiuser Communication Systems and Signal Processing (by Daniel P. 
Palomar and Gesualdo Scutari)   
 
5/23 (Monday): Participated in  
(a) Tutorial 7 (09:00-12:00): Game Theory in Signal Processing and Communications (by 
Eduard A. Jorswieck and Erik G. Larsson);  
(b) tour at Prague castile.  
A CONVEX APPROXIMATION APPROACH TO WEIGHTED SUM RATE MAXIMIZATION
OF MULTIUSER MISO INTERFERENCE CHANNEL UNDER OUTAGE CONSTRAINTS
Wei-Chiang Li, Tsung-Hui Chang, Che Lin, and Chong-Yung Chi
Institute of Communications Engineering & Department of Electrical Engineering
National Tsing Hua University,
Hsinchu, Taiwan 30013
E-mail: {weichiangli, tsunghui.chang}@gmail.com, {clin, cychi}@ee.nthu.edu.tw
ABSTRACT
This paper considers weighted sum rate maximization of multiuser
multiple-input single-output interference channel (MISO-IFC) un-
der outage constraints. The outage-constrained weighted sum rate
maximization problem is a nonconvex optimization problem and is
difficult to solve. While it is possible to optimally deal with this
problem in an exhaustive search manner by finding all the Pareto-
optimal rate tuples in the (discretized) outage-constrained achiev-
able rate region, this approach, however, suffers from a prohibitive
computational complexity and is feasible only when the number of
transmitter-receive pairs is small. In this paper, we propose a convex
optimization based approximation method for efficiently handling
the outage-constrained weighted sum rate maximization problem.
The proposed approximation method consists of solving a sequence
of convex optimization problems, and thus can be efficiently imple-
mented by interior-point methods. Simulation results show that the
proposed method can yield near-optimal solutions.
Index Terms— Multiuser interference channel, weighted sum
rate maximization, outage probability, convex optimization
1. INTRODUCTION
Recently, interference management for improving spectral efficiency
of wireless multiuser systems has been a research topic drawing
significant attention [1]. This paper considers the K-user multiple-
input single-output interference channel (MISO-IFC) where K
multi-antenna transmitters simultaneously communicate withK re-
spective single-antenna receivers over a common frequency band.
This MISO-IFC arises, for example, in multicell wireless systems
where each of the base stations is equipped with multiple antennas
and each mobile station has only one antenna. Under the assumption
that the transmitters have the perfect channel state information, and
that the receivers employ single-user detection, it has been shown
that transmit beamforming is an optimal transmission scheme to
attain the Pareto boundary of the achievable rate region of MISO-
IFC [2]. The structure of the Pareto-optimal beamforming schemes
has also been studied in [3, 4]. A game-theoretic approach for
MISO-IFC has been presented in [5].
This paper assumes that the channel coefficients are block-faded,
and that the transmitters know only the statistical distribution of the
channels. Specifically, each channel is assumed to be circularly
symmetric complex Gaussian distributed, with a covariance matrix
known to the transmitters. Under limited delay constraints and due
This work is supported by National Science Council, R.O.C., under
Grants NSC 98-2219-E-007-003, NSC 98-2219-E-007-005, NSC 99-2221-
E-007-052-MY3 and NSC99-2221-E-007-089-MY3.
to channel fading, the receivers’ performance may suffer from out-
age. Assuming that the transmitters employ transmit beamforming,
the achievable rate region of MISO-IFC under outage constraints
on receivers’ performance has been investigated in [6]. While this
outage-constrained achievable rate region is not known analytically
so far, it has been shown that this region can be found numerically
using an exhaustive search method [6]. This method, unfortunately,
has a complexity that increases exponentially with K(K − 1), and
therefore is not feasible in practice.
In this paper, we investigate efficient approaches to achieving
Pareto-optimal beamforming solutions that maximize the achievable
weighted sum rate. To this end, we study the design formulation that
maximizes the weighted sum rate subject to outage constraints and
individual power constraints. Due to the nonconvextity of the out-
age constraints, solving the weighted sum rate maximization prob-
lem is a challenging task. To efficiently deal with this problem, we
propose a sequential convex approximation method. The proposed
approximation method is conservative in the sense that the obtained
approximate beamforming solutions are guaranteed to be feasible
and satisfy the outage constraints of the original problem. Since the
proposed method only involves solving convex optimization prob-
lems, it can be efficiently implemented by interior-point methods in
a polynomial-time complexity [7]. The presented simulation results
show that the proposed approximation method can provide near-
optimal performance and outperform the existing maximum-ratio
and zero-forcing transmission strategies.
2. SIGNALMODEL AND PROBLEM STATEMENT
We consider the K-user MISO interference channel where each of
the transmitters has Nt antennas and all the receivers are equipped
with a single antenna. All the transmitters employ transmit beam-
forming to transmit information signals to their respective receivers.
Let si(t) denote the information signal sent from transmitter i, and
let wi ∈ CNt be the associated beamforming vector. The received
signal at receiver i is given by
xi(t) = h
H
iiwisi(t) +
K∑
k=1,k =i
h
H
kiwksk(t) + ni(t), (1)
where hki ∈ CNt denotes the channel vector from transmitter k
to receiver i, and ni(t) is the additive noise of receiver i. The
noise ni(t) is assumed to be complex Gaussian distributed with zero
mean and variance σ2i > 0, i.e., ni(t) ∼ CN (0, σ2i ). Assuming
that si(t) ∼ CN (0, 1) and that the receivers decode the informa-
tion message using single-user detection (which treats the cross-
3368978-1-4577-0539-7/11/$26.00 ©2011 IEEE ICASSP 2011
where Kci  {1, . . . ,K}\{i}, and (7h) is due to (6c). Notice that
we have replaced the equalities in (6a) and (6b) with inequalities as
in (7c) to (7f). It is not difficult to verify that all the inequalities in
(7c) to (7f) would hold with equalities at the optimum; otherwise a
larger optimal weighted sum rate can always be obtained. Therefore,
problem (7) is equivalent to problem (5).
One can see that the objective function and most of the con-
straints of problem (7) are convex, except the constraints in (7c)
and (7e), and the nonconvex rank-one constraints in (7h). Let
({w¯i}Ki=1, {R¯i}Ki=1) be a feasible point of problem (2). Define
x¯ki  ln(w¯
H
k Qkiw¯k), k ∈ Kci , (8a)
y¯i  ln(2
R¯i − 1), (8b)
for i = 1, . . . ,K. Then {{x¯ki}k =i, y¯i}Ki=1 together with R¯i, x¯ii 
ln(w¯Hi Qiiw¯i), W¯i  w¯iw¯Hi and z¯i  ey¯i−x¯ii for i = 1, . . . ,K,
are feasible to problem (7). We aim to conservatively approximate
(7c) and (7e) with respective to the point {{x¯ki}k =i, y¯i}Ki=1. Since
exki is convex, its first-order approximation at x¯ki, i.e., ex¯ki(xki −
x¯ki + 1), is a global underestimate of exki . Hence it is sufficient to
achieve (7c) by considering the following linear constraint
Tr(WkQki) ≤ ex¯ki(xki − x¯ki + 1), (9)
for k ∈ Kci . To approximate (7e), we consider the following lower
bound for eyi + 1:(
eyi
θi1(y¯i)
)θi1(y¯i) ( 1
θi2(y¯i)
)θi2(y¯i)
≤ eyi + 1, (10)
where θi1(y¯i) = ey¯i/(ey¯i + 1) and θi2(y¯i) = 1/(ey¯i + 1). Equa-
tion (10) is obtained from the inequality of arithmetic and geometric
means. By (10), a sufficient condition for (7e) can be obtained as
(θi1(y¯i))
θi1(y¯i)(θi2(y¯i))
θi2(y¯i)e(ln 2)Ri−θi1(y¯i)yi ≤ 1, (11)
for i = 1, . . . , K, which are convex constraints. By replacing (7c)
and (7e) with (9) and (11), respectively, and by ignoring the noncon-
vex rank-one constraints in (7h), we obtain the following approxi-
mation formulation for problem (7):
max
Wi∈H
Nt ,Ri≥0,
xki,yi,zi∈R,
k,i=1,...,K
K∑
i=1
αiRi, (12)
s.t. ρieσ
2
i
zi
∏
k =i
(
1 + e−xii+xki+yi
) ≤ 1,
Tr(WkQki) ≤ ex¯ki(xki − x¯ki + 1), k ∈ Kci ,
Tr(WiQii) ≥ exii ,
Θi(y¯i)e
(ln 2)Ri−θi1(y¯i)yi ≤ 1,
eyi−xii ≤ zi,
Tr(Wi) ≤ Pi, Wi  0, i = 1, . . . ,K,
where Θi(y¯i)  (θi1(y¯i))θi1(y¯i)(θi2(y¯i))θi2(y¯i). Problem (12) is a
convex optimization problem; it can be efficiently solved by standard
convex solvers such as CVX [7].
The idea of removing the nonconvex rank-one constraints of
{Wi}Ki=1 in (12) is known as semidefinite relaxation (SDR) in con-
vex optimization theory [9]. SDR is in general an approximation
because the optimal {Wi}Ki=1 of problem (12) may not be of rank
one. Surprisingly, it is found that, for all the problem instances we
tested in simulations, problem (12) always yields rank-one optimal
solution, {Wi}Ki=1, i.e., Wi = wi(wi)H for all i, provided that
Wi = 0. This implies that an approximate beamforming solution to
(2) can be directly obtained by decomposing the optimal {Wi}Ki=1
of (12).
3.3. Sequential Convex Approximations
The formulation (12) is obtained by approximating problem (2) with
respect to the feasible point ({w¯i}Ki=1, {R¯i}Ki=1) [see (8)]. It is pos-
sible to further improve the approximation performance by solving
problem (12) iteratively with the optimal ({wi}Ki=1, {Ri}Ki=1) at the
current iteration used as the feasible point ({w¯i}Ki=1, {R¯i}Ki=1) for
the next iteration. The proposed sequential approximation algorithm
is summarized in the following Algorithm 1:
Algorithm 1 Proposed sequential convex approximation algorithm
for solving problem (2)
1: Input a feasible point ({w¯i}Ki=1, {R¯i}Ki=1) of problem (2), and
a solution accuracy δ > 0.
2: Obtain {{x¯ki}k =i, y¯i}Ki=1 by (8) and obtain θi1(y¯i) =
ey¯i/(ey¯i + 1) and θi2(y¯i) = 1/(ey¯i + 1) for i = 1, . . . , K.
3: Solve problem (12) to obtain the optimal beamforming matrices
{Wi }Ki=1 and rates {Ri }Ki=1.
4: Obtain wi by decomposition of Wi = wi (wi )H for i =
1, . . . ,K.
5: Output the approximate beamforming solution (w1 , . . . ,wK)
and achievable rate tuple (R1 , . . . , RK) if |
∑K
i=1 αiR

i −∑K
i=1 αiR¯i|/
∑K
i=1 αiR¯i < δ; otherwise update w¯i := w

i
and R¯i := Ri for all i, and go to Step 2.
A feasible point to initialize Algorithm 1 can be easily obtained
by some heuristic transmission strategies. For example, one can ob-
tain a feasible point ({w¯i}Ki=1, {R¯i}Ki=1) of problem (2) through the
simple maximum-ratio transmission (MRT) strategy. In this strategy,
the beamforming vectors {w¯i}Ki=1 are simply set to w¯i =
√
Piqi
where qi ∈ CNt , ‖qi‖ = 1, is the principal eigenvector of Qii for
i = 1, . . . ,K. For the ith transmitter-receiver pair, the associated
i-outage achievable rate of MRT is given by the maximum R¯i that
satisfies the following inequality [see (5)]
ρie
(2R¯i−1)σ2
i
w¯
H
i
Qiiw¯i
∏
k =i
(
1+
(2R¯i − 1)w¯Hk Qkiw¯k
w¯
H
i Qiiw¯i
)
≤ 1.
Analogously, one can also obtain a feasible point of (2) by the zero-
forcing (ZF) transmission strategy, provided that the column space of
Qii is not subsumed by the column space of
∑K
k =iQik , for all i =
1, . . . ,K. In the next section, we present some simulation results to
demonstrate the efficacy of the proposed approximation algorithm.
4. SIMULATION RESULTS AND DISCUSSIONS
In the simulations, we consider the multiuser MISO-IFC as de-
scribed in Section 2. For simplicity, all the receivers are assumed
to have the same noise power, i.e., σ21 = · · · = σ2K  σ2, and all
the power constraints are set to one, i.e., P1 = · · · = PK = 1.
The channel covariance matricesQki were randomly generated. We
normalize the maximum eigenvalue of Qii, i.e., λmax(Qii), to one
for all i, and normalize λmax(Qki) to a value η ∈ (0, 1] for all
k ∈ Kci , i = 1, . . . ,K. The parameter η, thereby, represents the
relative cross-link interference level. If not mentioned specifically,
the ranks of Qki are all set to Nt. We consider the sum rate maxi-
mization problem by setting α1 = · · · = αK = 1 for problem (2),
3370
TWO EFFECTIVE AND COMPUTATIONALLY EFFICIENT PURE-PIXEL BASED
ALGORITHMS FOR HYPERSPECTRAL ENDMEMBER EXTRACTION
ArulMurugan Ambikapathi, Tsung-Han Chan, Chong-Yung Chi, and Kannan Keizer
Inst. Commun. Eng., National Tsing Hua Univ., Hsinchu, Taiwan 30013.
E-mail: aareul@ieee.org,{tsunghan@mx,cychi@ee}.nthu.edu.tw
ABSTRACT
Endmember extraction is of prime importance in the process of hy-
perspectral unmixing so as to study the mineral composition of a
landscape from its hyperspectral observations. Though, a whole
bunch of pure-pixel based endmember extraction algorithms exists,
the quest for a reliable, repeatable, and computationally efficient
endmember extraction algorithm still prevails. In this work, we pro-
pose two pure-pixel based endmember extraction algorithms called
simplex estimation by projection (SIMPLE-Pro) algorithm and p-
norm based pure pixel identification (TRI-P) algorithm. The end-
member identifiability of the proposed two algorithms is theoreti-
cally proved under the pure pixel assumption. Both algorithms never
require any initializations and hence they are repeatable. Monte
Carlo simulations are performed to demonstrate the superior effi-
cacy and computational efficiency of the proposed two algorithms
over some existing benchmark endmember extraction algorithms.
Index Terms— Hyperspectral images, Endmember extraction,
Pure pixels, Endmember identifiability
1. INTRODUCTION
Hyperspectral unmixing (HU) is a process of extracting endmember
signatures and their corresponding abundance maps from the mea-
sured hyperspectral images, over a scene of interest [1]. Existing
HU algorithms can basically be classified into two groups, one fo-
cusing on pure pixels (pixels in the observed hyperspectral data, that
are contributed by a single endmember only) and the other with-
out relying on pure pixels. Based on the linear mixing model (to
be discussed later), identifying those pure pixels in the data cloud
will directly yield the endmember signatures. Thus, the pure-pixel
based algorithms aim to find the pure pixels in the given observa-
tions, and thus can only estimate the endmember signatures. Hence,
those algorithms are aptly called as endmember extraction (EE) al-
gorithms, and they are the ones considered in this work. EE algo-
rithms currently available in the literature, include pixel purity index
(PPI) [2], N-finder (N-FINDR) [3], convex cone analysis (CCA) [4],
simplex growing algorithm (SGA) [5] [6], vertex component analy-
sis (VCA) [7], and alternating volume maximization (AVMAX) [8],
to name a few. Once the pure pixels (endmember signatures) are
identified by EE algorithms, the corresponding abundance estimates
can be obtained by using the fully constrained least squares (FCLS)
algorithm [9].
Some issues associated with the above mentioned algorithms are
discussed next. Firstly, for noisy observations, EE algorithms such
as PPI, N-FINDR, and VCA are sensitive to initialization and hence
This work was supported by the National Science Council (R.O.C.) un-
der Grants NSC 99-2221-E-007-003-MY3 and NSC 96-2628-E-007-003-
MY3.
are not repeatable [5]. Secondly, though the computational com-
plexity of EE algorithms is generally lower when compared to that
of HU algorithms without relying on the pure pixels, it increases
with the number of pixels and the number of endmembers present in
the given hyperspectral data. Hence, a computationally efficient EE
algorithm will always be preferred for real-time analysis of hyper-
spectral data. More importantly, rigorous theoretical proofs for the
endmember identifiability of the above mentioned algorithms (ex-
cept for AVMAX) are yet to be investigated.
The prime focus of this work is to propose reliable, repeatable
and computationally efficient pure-pixel based algorithms for end-
member extraction, along with a theoretical guarantee for their end-
member identifiability. In this regard, we propose two endmem-
ber extraction algorithms, namely simplex estimation by projection
(SIMPLE-Pro) and p-norm based pure pixel identification (TRI-P,
abbreviated for Triple-P). As in the aforementioned EE algorithms,
we begin with the linear mixing model for HU [2–8]. In our first
algorithm (SIMPLE-Pro), the principle is to project the data onto a
vector orthogonal to the affine hull of already found endmember sig-
natures. The index corresponding to the minimum of the projected
values yields a new pure pixel. In the second algorithm (TRI-P), the
data are projected onto a subspace orthogonal to already found end-
member signatures, and maximum p-norm is used to identify a new
pure pixel. In both algorithms, prior to endmember extraction, the
affine set fitting procedure [10] is used for dimension reduction, and
then maximum p-norm is used to find the first endmember signature.
The notations used in this paper are briefed as follows: RM and
R
M×N represent the set of realM×1 vectors andM×N matrices,
respectively, 1N represents the N × 1 all-one vector, and IN is the
N×N identity matrix. The symbol ‖ ·‖p represents the p-norm and
Q† stands for Moore-Penrose pseudo-inverse of matrixQ.
2. LINEAR MIXINGMODEL
Consider a scenario in which a hyperspectral sensor withM spectral
bands measures solar electromagnetic radiations reflecting from N
distinct substances, over a scene of interest. Due to low spatial res-
olution, each pixel vector of the measured hyperspectral image cube
can be described by anM ×N linear mixing model [1, 3, 7]:
x[n] = As[n] =
N
 
i=1
si[n]ai, ∀n = 1, . . . , L, (1)
where M is the number of spectral bands and N is the num-
ber of endmembers present in the scene. Further, x[n] =
[ x1[n], . . . , xM [n] ]
T is the nth pixel vector in the hyperspectral
observation, A = [ a1, . . . , aN ] ∈ RM×N denotes the endmember
signature matrix whose ith column vector ai is the ith endmember
signature (or simply endmember), s[n] = [ s1[n], . . . , sN [n] ]T ∈
1369978-1-4577-0539-7/11/$26.00 ©2011 IEEE ICASSP 2011
It follows that P⊥Bαk = P⊥Bαq, q = 1, . . . , k − 1. By pre-
multiplying by αTq on both sides, we get
α
T
q P
⊥
Bαk = α
T
q P
⊥
Bαq, q = 1, . . . , k − 1. (16)
Since the projector P⊥B is positive semi-definite; i.e., αTq P⊥Bαq ≥
0, we have
α
T
q d
 = αTq P
⊥
Bαq ≥ 0, q = 1, . . . , k − 1. (17)
Moreover, it is straightforward to see from (12) thatαTk d ≥ 0. Due
to the nature of {x˜[n]}Ln=1, which is centered at the origin, there
exists at least one vector in {x˜[n]}Ln=1 such that x˜[n]T d < 0. This
can also be justified by the fact that there exists pixel vectors on
either side of the hyperplane {y ∈ RN−1 | yTd = 0}. Therefore
(14) will never yield an index that was already identified; i.e., the
new index lz ∈ {l1, . . . , lk} and further, due to (13), the obtained
index must be a pure pixel index. Thus x˜[lz] ∈ {αk+1, ..., αN}. 
By repeating the above procedure for k = 1, . . . , N − 1, all
the dimension-reduced endmembers can be identified. The resulting
EE algorithm is the SIMPLE-Pro algorithm, which is summarized in
Table 1.
Table 1. Simplex estimation by projection (SIMPLE-Pro) algorithm.
Given dimension-reduced observations x˜[n], and the number of
endmembers N .
Step 1. Find l1 ∈ arg maxn{‖x˜[n]‖p}. Set α1 = x˜[l1] and
k = 1.
Step 2. Define the matrix B = [α1 − αk, . . . ,αk−1 − αk] and
find the vector d as given by (12).
Step 3. Update k := k + 1 and then obtain αk = x˜[lk] for any
lk ∈ arg minn=1,...,L{x˜[n]
Td}.
Step 4. Go to Step 2 until k = N − 1.
Step 5. Output the dimension-reduced endmember estimates
α1, ..., αN .
5. P -NORM BASED PURE PIXEL IDENTIFICATION
In this section, we present yet another EE algorithm namely the TRI-
P algorithm to find the dimension-reduced endmembers. Unlike the
previous EE algorithm, here we begin by incorporating the assump-
tion (A2) in (5) so that we have the following augmented dimension-
reduced data:
x¯[n] =  
x˜[n]
1 
=
N

i=1
si[n]α¯i ∈ R
N , (18)
where α¯i = [αTi 1]T , i = 1, . . . , N are the augmented dimension-
reduced endmembers. As in SIMPLE-Pro, following the steps
leading to Lemma 1, one can show that a pure pixel index
(and therefore an endmember) can be perfectly identified from
arg maxn=1,...,L{‖x¯[n]‖p}, under (A1)-(A4) (see (8)).
Suppose that α¯i is already found. To find a new endmember
different from α¯i, we consider the following subspace projection:
x[n] = P⊥
α¯i
x¯[n] =
N

k=1,k =i
sk[n]P
⊥
α¯i
α¯k,∀n, (19)
whereP⊥
α¯i
= IN −α¯i(α¯
T
i α¯i)
−1α¯Ti is the orthogonal complement
projector of α¯i. Then, a new dimension-reduced endmember can be
identified as stated in the following lemma:

α¯1
(0, 0)
α¯2
x¯[n]
x[n]
P⊥α¯1α¯1 = 0
Fig. 2. Illustration of TRI-P for N = 2. Assume that α¯1 has been
found. α¯2 = x¯[l2], where l2 ∈ arg maxn=1,...,L{‖x[n]‖p}, and
x[n] is given by (19).
Lemma 3. Suppose that α¯i has been found. Then, under (A1)-
(A4), a new dimension-reduced endmember can be identified by
αj = x˜[lj ] (20)
for any lj ∈ arg maxn=1,...,L‖P⊥α¯i x¯[n]‖p and αj = αi.
Proof: By the triangle inequality, (A1), (A2), and (18), we have
‖P⊥
α¯i
x¯[n]‖p ≤

k =i
sk[n]‖P
⊥
α¯i
α¯k‖p ≤ max
k =i
{‖P⊥
α¯i
α¯k‖p}. (21)
The inequality in (21) holds with equality if and only if n = lj
for any j ∈ arg maxk =i {‖P⊥α¯i α¯k‖p}. So one can find a
new dimension-reduced endmember αj = x˜[lj ] for any lj ∈
arg maxn=1,...,L{‖P
⊥
α¯i
x¯[n]‖p} and αj = αi. 
To find the next dimension-reduced endmember, the projected
data x[n] is again projected onto to a subspace orthogonal to the
previously found endmember; P⊥
α¯j
x[n]. Then by Lemma 3, one
can identify another new dimension-reduced endmember. The pro-
cedure is repeated until all theN endmembers are found. The above
endmember estimation methodology is the TRI-P algorithm which
is summarized in Table 2. Figure 2 illustrates the idea of TRI-P for
the N = 2 case.
Table 2. p-norm based pure pixel (TRI-P) algorithm.
Given dimension-reduced observations x˜[n], x¯[n] given by (18),
and no. of endmembers N . Set i = 1 and x[n] = x¯[n].
Step 1. Obtain α¯i = x[li] for any li ∈ arg maxn{‖x[n]‖p}.
Step 2. Calculate P⊥
α¯i
= IN − α¯i(α¯
T
i α¯i)
−1α¯Ti , and update
x[n] := P⊥
α¯i
x[n].
Step 3. Update i := i + 1, and go to Step 1 if i ≤ N .
Step 4. Output x˜[l1], ..., x˜[lN ] as the estimates of α1, ..., αN .
Remarks: Existing pure-pixel based EE algorithms such as PPI,
VCA, N-FINDR and SGA require initializations. For both of the
proposed algorithms SIMPLE-Pro and TRI-P, there is no need of
any initialization, and hence they are repeatable. While both TRI-P
algorithm and VCA [7] involve the notion of orthogonal complement
projections, there exists a subtle algorithmic difference between the
two: VCA involves some sort of random vector projection in end-
member estimation, but there is no randomness involved in TRI-P.
1371
PROBABILISTIC SINR CONSTRAINED ROBUST TRANSMIT BEAMFORMING:
A BERNSTEIN-TYPE INEQUALITY BASED CONSERVATIVE APPROACH
Kun-Yu Wang, Tsung-Hui Chang, Wing-Kin Ma†, Anthony Man-Cho So‡, and Chong-Yung Chi
 Institute of Commun. Eng.
National Tsing Hua University,
Hsinchu, Taiwan 30013
E-mail: {kunyuwang7,tsunghui.chang}@gmail.com,
cychi@ee.nthu.edu.tw
† Dept. of Electronic Eng.
Chinese Univ. of Hong Kong,
Shatin, Hong Kong
E-mail: wkma@ieee.org
‡ Dept. of Sys. Eng. & Eng. Mgmt.
Chinese Univ. of Hong Kong,
Shatin, Hong Kong
E-mail: manchoso@se.cuhk.edu.hk
ABSTRACT
Recently, robust transmit beamforming has drawn considerable at-
tention because it can provide guaranteed receiver performance in
the presence of channel state information (CSI) errors. Assuming
complex Gaussian distributed CSI errors, this paper investigates the
robust beamforming design problem that minimizes the transmission
power subject to probabilistic signal-to-interference-plus-noise ratio
(SINR) constraints. The probabilistic SINR constraints in general
have no closed-form expression and are difficult to handle. Based on
a Bernstein-type inequality for quadratic forms of complex Gaussian
random variables, we propose a conservative formulation to the ro-
bust single-cell beamforming design problem. The semidefinite re-
laxation technique can be applied to efficiently handle the proposed
conservative formulation. Simulation results show that, in compari-
son with existing methods, the proposed method is more power effi-
cient and is able to support higher target SINR values for receivers.
Index Terms— Robust transmit beamforming, semidefinite re-
laxation, convex optimization.
1. INTRODUCTION
Linear transmit beamforming has been recognized as a powerful
technique since it can achieve a large fraction of capacity with low
implementation complexity. Conventionally, it is assumed that the
transmitter has perfect channel state information (CSI) of the re-
ceivers, and the beamforming vectors are optimized such that the
signal-to-interference-plus-noise ratio (SINR) requirements of the
receivers can be satisfied. In practical situations, however, the CSI
at the transmitter is inevitably subject to errors due to finite-energy
training and limited feedback. The presence of CSI errors will result
in receivers’ performance outage. Therefore, robust transmit beam-
forming designs that take the CSI errors into consideration [1, 2, 3, 4]
are of great importance.
In this paper, we assume that the CSI errors are complex Gaus-
sian distributed and study the stochastic robust beamforming design
problem under a single-cell system with multiple single-antenna re-
ceivers. Specifically, we study the robust design formulation that
minimizes the transmission power subject to probabilistic SINR con-
straints on the receivers [2]. The probabilistic SINR constraints guar-
antee the receivers’ SINR requirements to be satisfied with a pre-
This work is supported in part by National Science Council, R.O.C.,
under Grants NSC 98-2219-E-007-005 and NSC 99-2221-E-007-052-MY3,
and in part by a General Research Fund of Hong Kong Research Grant Coun-
cil (CUHK 415908) and by the Grant Project #MMT-p2-09 of the Shun Hing
Institute of Advanced Engineering, The Chinese University of Hong Kong.
determined, high probability (i.e., a low outage probability). The
robust design problem is difficult to solve because the probabilistic
SINR constraints in general do not have closed-form expression and
are not convex. To efficiently handle this problem, so-called con-
servative approaches that aim to obtain efficient approximate solu-
tions guaranteeing the probabilistic SINR requirements are proposed
[2, 4]. In particular, the authors of [2] used the results in [5] to show
that an approximate solution of the robust design problem can be ef-
ficiently obtained by solving a semidefinite program (SDP). In [4], a
more efficient conservative formulation is presented which also in-
volves solving an SDP.
In this paper, we present a new conservative approach to the
probabilistic SINR constrained robust beamforming problem. The
idea of the proposed method is based on the observation that each of
the probabilistic SINR constraints involves a quadratic form of com-
plex Gaussian random variables, which allows us to use a Bernstein-
type inequality1 [6] to bound the outage probability. By recognizing
that the Bernstein-type inequality can be reformulated as a system of
conic inequalities, we obtain a new conservative formulation of the
robust beamforming problem. Although the proposed formulation
is still a nonconvex optimization problem, it can be handled very
effectively by a convex relaxation method, called semidefinite re-
laxation (SDR). The presented simulation results show that the pro-
posed method is more power efficient and less conservative com-
pared to existing methods.
2. SIGNALMODEL AND PROBLEM STATEMENT
We consider a multiuser wireless system consisting of a multiple-
antenna transmitter andK single-antenna receivers. The transmitter,
equipped withNt antennas, wants to communicate with the receivers
using transmit beamforming. Let si(t) denote the information signal
for receiver i. The transmit signal is given by
∑K
i=1wisi(t) where
wi ∈ CNt is the beamforming vector for si(t). The received signal
at receiver i is given by
yi(t) = h
H
i
(
K∑
k=1
wksk(t)
)
+ ni(t), (1)
where hi ∈ CNt denotes the channel vector of receiver i, and ni(t)
is the additive noise at receiver i. It is assumed that ni(t) has zero
mean and variance equal to σ2i > 0 for all i = 1, . . . , K. Assume
1Roughly speaking, a Bernstein-type inequality is one which bounds the
probability that a sum of random variables deviates from its mean.
3080978-1-4577-0539-7/11/$26.00 ©2011 IEEE ICASSP 2011
holds true if the following inequality is satisfied
Tr(Q)−
√
2δ
√
‖Q‖2F + 2‖u‖2 − δs+(Q) ≥ c. (13)
Equation (13) thus serves as a conservative formulation for (12).
Now, a crucial observation is that (13) can be represented by
Tr (Q)−
√
2δx− δy ≥ c, (14a)√
‖Q‖2F + 2‖u‖2 ≤ x, (14b)
yI+Q  0, (14c)
y ≥ 0, (14d)
where x, y ∈ R are slack variables. By defining
δi  − ln(ρi), i = 1, . . . , K, (15)
and applying (14) to (9), we obtain the following problem
min
wi∈C
Nt ,xi,yi∈R,
i=1,...,K
K∑
i=1
‖wi‖2 (16)
s.t. Tr (Qi(w1, . . . ,wK))−
√
2δixi − δiyi
≥ ci(w1, . . . ,wK), i = 1, . . . ,K,∥∥∥∥
[
vec (Qi(w1, . . . ,wK))√
2ui(w1, . . . ,wK)
]∥∥∥∥≤ xi, i = 1, . . . ,K,
yiI+Qi(w1, . . . ,wK)  0, i = 1, . . . ,K,
yi ≥ 0, i = 1, . . . ,K
as a conservative formulation for problem (7), where vec(·) denotes
the column-by-column matrix vectorization.
Our derived conservative formulation (16) is desirable since it
has closed-form expressions with the constraints. However, prob-
lem (16) is nonconvex, owing to the fact that Qi(w1, . . . ,wK),
ui(w1, . . . ,wK) and ci(w1, . . . ,wK) are indefinite quadratic in
{w1, . . . ,wK} [see (10)]. Next, we will handle this problem by
using the SDR technique [10].
3.2. Semidefinite Relaxation
To apply SDR to the conservative formulation (16), we let Wi =
wiw
H
i , for i = 1, . . . ,K. By replacingwiwHi withWi in (10) and
then constrainingWi to be positive semidefinite only, we obtain the
following problem
min
Wi∈H
Nt ,xi,yi∈R,
i=1,...,K
K∑
i=1
Tr(Wi) (17a)
s.t. Tr (Qi(W1, . . . ,WK))−
√
2δixi − δiyi
≥ ci(W1, . . . ,WK), (17b)∥∥∥∥
[
vec (Qi(W1, . . . ,WK))√
2ui(W1, . . . ,WK)
]∥∥∥∥ ≤ xi, (17c)
yiI+Qi(W1, . . . ,WK)  0, (17d)
yi ≥ 0, Wi  0, i = 1, . . . ,K, (17e)
where, with a slight abuse of notations, we define
Qi(W1, . . . ,WK)  C
1/2
i
( 1
γi
Wi −
∑
k =i
Wk
)
C
1/2
i ,
ui(W1, . . . ,WK)  C
1/2
i
( 1
γi
Wi −
∑
k =i
Wk
)
h¯i,
ci(W1, . . . ,WK)  σ
2
i − h¯Hi
( 1
γi
Wi −
∑
k =i
Wk
)
h¯i,
for i = 1, . . . ,K. Note that the constraints in (17b), (17c) and
(17d) are respectively a linear constraint, a convex second-order cone
(SOC) constraint and a convex PSD constraint. Hence problem (17)
is a convex conic problem and can be efficiently solved by standard
solvers such as CVX [11].
The SDR problem (17) is in general a relaxation of problem (16)
because the associated optimal {Wi}Ki=1 may not be of rank one. If
the optimal {Wi}Ki=1 of (17) is of rank one, i.e.,Wi = wiwHi for
all i, then {wi}Ki=1 is an optimal solution to problem (16); otherwise
additional solution approximation procedures to turn the optimum
{Wi}Ki=1 into a rank-one approximate solution of problem (16) is
needed [10]. Fortunately and rather surprisingly, it is found by simu-
lations that problem (17) always yields rank-one optimal {Wi}Ki=1.
This implies that the globally optimal solution of the conservation
formulation (16) may be attained by SDR, at least for all the problem
instances we tested in simulations. Also, under the same argument,
the feasibility of (16) may be equivalent to that of (17).
3.3. Reducing the Level of Conservatism by Bisection
Analogous to the methods presented in [2, 4], it is found that the
proposed conservative formulation (16) with δi set as in (15) may
yield beamforming solutions that correspond to an SINR satisfaction
probability [in (7b)] much higher than 1−ρi. According to (11), the
SINR satisfaction probability achieved by formulation (16) can be
reduced by decreasing the parameter δi. Hence the bisection method
presented in [2, 4] can be used to reduce the level of conservatism of
problem (16).
To illustrate how this method works, let us assume that all the re-
ceivers have the same SINR outage probability, i.e., ρ  ρ1 = · · · =
ρK . Thus we can let δ  δ1 = · · · = δK [see (15)]. For a given
δ, one can obtain a beamforming solution by solving (16) and use
the validation procedure in [5] to test if the associated probabilistic
SINR constraints in (7b) are empirically satisfied or not. If yes, the
parameter δ can be reduced; otherwise it should be increased. The
procedure is repeated until a predefined stopping criterion is met.
Readers are referred to [2, 4] for further details.
4. SIMULATION RESULTS AND DISCUSSIONS
In this section, we present some simulation results to demonstrate the
performance of the proposed method. We consider the wireless sys-
tem as described in Section 2 with three antennas at the transmitter
and with three receivers (Nt = K = 3). For simplicity, we con-
sider independent and identically distributed (i.i.d.) complex Gaus-
sian CSI errors, i.e., Ci = I for all i, and set  = 0.002. The noise
variances of all receivers are set to 0.01 (σ21 = σ22 = σ23 = 0.01),
and the outage probabilities are set to 0.1 (ρ1 = ρ2 = ρ3 = 0.1),
i.e., 90% satisfaction probability. The target SINR values of all re-
ceivers are also set to be the same, i.e., γ  γ1 = γ2 = γ3. We com-
pare the proposed conservative formulation in (16) with the method
presented in [4] and the Formulation I in [2]. The bisection tech-
nique mentioned in Section 3.3 was also implemented for the three
methods under test. The parameter setting of this technique follows
that in [4]. All three methods were implemented using CVX [11].
Since a less conservative method is more likely to be feasible, in
the first example, we examine the feasibility rates of the three meth-
ods under test and their bisection counterparts. To this end, 500 sets
of channel estimates {h¯i}3i=1 were generated according to complex
Gaussian with zero mean and covariance matrix I. Figure 1 shows
the simulation results of feasibility rate (%) versus target SINR γ.
3082
 1 
出席 2011 IEEE MLSP Workshop國際學術會議心得報告 
                                                             
計畫編號 NSC 99-2221-E-007-003-MY3  
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 9/18/2011-9/21/2011, Beijing, China 
會議名稱 
IEEE International Workshop on Machine Learning for Signal Processing 
(MLSP-2011) 
發表論文題目 
#1.  Fast Alternating Volume Maximization Algorithm For Blind Separation Of 
Non-Negative Sources (Tsung-Han Chan, Chang-Jin Song, Arulmurugan 
Ambikapathi, Chong-Yung Chi, Wing-Kin Ma)  
 
一、參加會議經過 
 
筆者於 100年 9月 18日 (Sunday) 從桃園中正機場出發，於當日下午抵達北京首都國際機場，
接著入住紫光國際交流中心。The following is a summary of the major activities and events that I 
participated in. 
 
9/18 (Sunday): 完成報到手續 in the late afternoon  
9/19 (Monday): Participated in  
(a) Keynote Speech (9:00-10:00): Machine Learning for Problem Solving (by Prof. 
Biing-Hwang (Fred) Juang, Georgia Institute of Technology, USA)  
(b) Mon-Ses1-O (10:30-11:30): Speech and Audio Processing  
(c) Mon-Ses2-O (11:30-12:30): Source Aeparation  
筆者於11:30~11:50口頭發表上述論文#1。 
(d) Keynote Speech (13:30-14:30): Research for Wonderful Future Embedded Applications 
(by Dr. Yimin Zhang, Intel Labs China, China)  
(e) Mon-Ses3-O (14:30-15:30): Image and Video Processing 
(f) Mon-Ses4-O (16:00-17:00): Pattern Recognition and Classification 
(g) Mon-Ses5-P (17:00-19:00): Poster and Demo Session 1 
 
9/20 (Tuesday): Participated in  
(a) Keynote Speech (8:50-9:50): Bayesian SSVEP/NIRS-based Brain Signal Decoding with 
Monte Carlo Implementations (by Dr. Takashi Matsumoto, Waseda University, Japan)  
(b) Tue-Ses1-O (10:20-11:20): Bayesian Learning  
 3 
 
二、與會心得 
 
在本次會期中，the number of participants from Mainland China in much larger than that 
from any other county, and lots of good papers in the conference can be seen, including 筆
者所發表 1篇論文受到許多國際專家學者的關注，在吸收新知及建立人際關係受益良
多。筆者於北京交通大學及清華大學公開演講，受到熱烈響應，並討論進行中之合作
研究項目。 
 
致謝
 
：感謝國科會補助旅費 for the participation of IEEE MLSP-2011。 
附件一: 筆者受邀至北京交通大學公開演講公告。 
附件二: 筆者受邀至北京清華大學公開演講公告及演講中之照片一張。 
 
 4 
附件二 
 
 
where aij denotes the unknown mixing coefficient between the ith
observation xi = [xi[1], . . . , xi[L]]T and the jth source sj =
[sj [1], . . . , sj [L]]
T , and L  max{M,N} is the data length.
The goal of CAMNS-AVM is to estimate the sources s1, . . . , sN
from the given observations x1, . . . ,xM , assuming prior knowledge
ofN given and under the following assumptions:
(A1) For all j = 1, . . . , N , sj  0.
(A2) For each i ∈ {1, . . . , N}, there exists an (unknown) index i
such that si[i] > 0 and sj [i] = 0, ∀j = i.
(A3) For all i = 1, . . . ,M ,
∑N
j=1 aij = 1.
(A4) M ≥ N andA  [aij ]M×N is of full column rank.
Assumption (A1) holds true for image signals. Assumption (A2) is
valid for high contrast source images, especially with applications
in biomedical image analysis [2]. Assumption (A3) is automatically
satisfied in magnetic resonance imaging (MRI) due to the partial vol-
ume effect [2]. When violated, (A3) can be enforced through sum-
based normalization [8]. Assumption (A4) is a general assumption
in nBSS.
Next, we briefly review the CAMNS criterion [1, 8] and the
CAMNS-AVM [1].
2.1. CAMNS Criterion
We first construct the polyhedral set S from the observations as fol-
lows:
S = { x ∈ RL | x = Cα+ d  0, α ∈ RN−1} (2)
whereC and d are given by
d =
1
M
M∑
i=1
xi, C = [ q1(UU
T ), . . . , qN−1(UU
T ) ] (3)
in which U = [ x1 − d, . . . ,xM − d ] ∈ RL×M and qi(UUT )
denotes the unit-norm eigenvector associated with the ith principal
eigenvalue of UUT . Under assumptions (A1)-(A4), it has been
shown in [8] that S is identical to the source convex hull; i.e.,
S = conv{s1, . . . , sN} 
{
s =
N∑
i=1
θisi
∣∣∣∣ θ  0, 1TNθ = 1
}
,
where θ = [θ1, . . . , θN ]T . A point x ∈ conv{s1, . . . , sN} is called
an extreme point of conv{s1, . . . , sN} if it cannot be a nontrivial
convex combination of s1, . . . , sN ; i.e.,
x =
N∑
i=1
θisi (4)
for all θ  0, 1TNθ = 1, and θ = ei for any i. It has also been
shown in [8] that the N extreme points of S are exactly the true
sources s1, . . . , sN . This has led to the following nBSS criterion:
CAMNS criterion [8]: Find all the N extreme points of the
polyhedral set S in (2). Output the obtained extreme points
{sˆ1, . . . , sˆN} as the estimated sources.
In [8], we have developed CAMNS-LP to enumerate the N extreme
points of S in a systematic manner.
To shed some light into the CAMNS-AVM algorithm [1] which
offers better robustness against model mismatch with (A2) than
CAMNS-LP, the pre-image of S under the affine mapping x =
Cα+ d is considered:
F = {α ∈ RN−1 ∣∣Cα+ d  0 } (5a)
=
{
α ∈ RN−1 ∣∣ cTnα+ dn ≥ 0, n = 1, . . . , L }, (5b)
where cTn is the nth row vector of C and dn is the nth element of d.
There exists a one-to-one mapping between extreme points of S and
F [8], as stated below:
Alternative CAMNS criterion [8]: Find all the N extreme points
of the polyhedral set F given by (5a) and denote the obtained
extreme points by {αˆ1, . . . , αˆN}. Output
sˆi = Cαˆi + d, i = 1, . . . , N, (6)
as the estimated sources.
Figure 1 illustrates the one-to-one affine mapping between the
vectors in S and F forN = 3. The polyhedral sets S and F , respec-
tively, contain onlyN extreme points under assumptions (A1)-(A4).
Nevertheless, in practical scenarios where the assumption (A2) is not
perfectly satisfied, the number of extreme points in F could be more
than N . A pictorial illustration of such a case is given in Figure 2.
One can see that the polyhedral set F is not a simplex anymore but
still exhibits a geometric structure similar to simplex. One would ex-
pect that the maximum-volume simplex inside F could serve as the
best approximation to F [1]. CAMNS-AVM algorithm that finds the
N extreme points of the maximum-volume simplex withinF will be
briefly reviewed.
0
FS
R
L
R
N−1
s
α
s1
s2
s3
α1
α2 α3
s = Cα + d
Fig. 1. A geometrical illustration of the one-to-one mapping between
S and F for N = 3 under assumptions (A1)-(A4).
F
cTLα + dL ≥ 0c
T
2α + d2 ≥ 0
cT1α + d1 ≥ 0
Fig. 2. A geometrical illustration ofF forN = 3 and when assump-
tion (A2) is not perfectly satisfied.
3.3. Customized Primal-dual Interior-Point Method for LP
Our aim herein is to develop a customized LP solver for Problem
(12a) that enables self-defined initialization, which is not an avail-
able option for general-purpose solvers such as SeDuMi and CVX
[12, 13]. The development is based on the primal-dual IPM by S.
Boyd et al. [16, Chapter 11.7]. By Proposition 1, the LP in (12a) is
equivalent to
min
βj
− bTj βj
s.t. − C¯βj − d¯  0,
(16)
where (−1)N+jdet(BNj) is ignored since BNj does not depend
on βj . The IPM iteratively updates the primal-dual variable (βj ,λ)
by (βj + γΔβj ,λ + γΔλ) where (Δβj ,Δλ) and γ denote the
search direction and the step size, respectively. By solving the mod-
ified Karush-Kuhn-Tucker (KKT) conditions with the first-order-
approximation, (Δβj ,Δλ) can be obtained as follows:
Δβj = (C¯
TDC¯)−1(C¯TDr2 − r1), (17a)
Δλ = D(r2 − C¯Δβj), (17b)
where
D = diag(λ ◦ (C¯βj + d¯)−1), (18)
r1 = −bj − C¯Tλ, (19)
r2 = −(C¯βj + d¯) + (1/t)λ−1, t > 0. (20)
The step size γ ∈ (0, 1] can be chosen as any value such that λ +
γΔλ  0 and C¯(βj + γΔβj) + d¯  0. We first compute the
corresponding largest step size γ as follows
γˆ = sup{γ ∈ (0, 1] ∣∣ λ+ γΔλ  0, C¯(βj + γΔβj) + d¯  0}
= min
{
1,min
{
− [λ]i
[Δλ]i
∣∣∣ [Δλ]i < 0
}
,
min
{
− [C¯βj + d¯]i
[C¯Δβj ]i
∣∣∣ [C¯Δβj ]i < 0
}}
. (21)
Then, a step size can be determined as γ = 0.99γˆ to ensure λ +
γΔλ  0 and C¯(βj + γΔβj) + d¯  0. With the duality gap
setting as given in [16], the customized IPM for (16) is described in
Table 2.
Table 2. Customized primal-dual IPM for (16).
Given a primal-dual strictly feasible initial point (βj ,λ), μ = 10,
and a solution accuracy  > 0.
Step 1. calculate the surrogate duality gap ηˆ(βj ,λ) = (C¯βj +
d¯)Tλ and determine t := μr/ηˆ(βj ,λ).
Step 2. compute (Δβj ,Δλ) given by (17).
Step 3. compute γˆ by (21) and the step size γ = 0.99γˆ.
Step 4. update βj := βj + γΔβj and λ := λ+ γΔλ.
Step 5. go to Step 1 until ηˆ(βj ,λ) ≤ .
With all the above complexity reduction methods applied to
CAMNS-AVM, we come up with the fast CAMNS-AVM algorithm
given in Table 3. The key differences between the original CAMNS-
AVM and the fast CAMNS-AVM lie in Step 1 and Step 4 (in Table
3), which are elaborated in the following remarks:
(R1) Step 1 is to remove the redundant constraints in F . Since F ,
represented by (C¯, d¯) (by Proposition 1), is uniquely deter-
mined by only r  L linear inequalities, the complexity of
each partial maximization problem (12a) can be significantly
reduced.
(R2) Step 4 involves two computational efficiency improvements.
One is that we only need to solve one LP (16) rather than two
LPs (12) required in the original CAMNS-AVM (see Step 3 in
Table 1). This implies that the complexity of CAMNS-AVM
can be reduced by one half. Moreover, the optimal βj obtained
by the customized LP at the current cycle can be used to ini-
tialize the LP at the next cycle. This mechanism is called the
warm start which further accelerates CAMNS-AVM.
Table 3. Fast CAMNS-AVM algorithm.
Given a convergence tolerance ε > 0,C and d obtained by (3), and
the set X = {CT (xi − d), i = 1, . . . ,M }.
Step 1. obtain (C¯, d¯) by Quickhull [10] as presented in Section 3.2.
Step 2. initialize β1, . . . ,βN by randomly choosing N vectors from
X , compute  := det(Δ(β1, . . . ,βN )), and set j := 1.
Step 3. update bj := [(−1)i+jdet(Bij)]N−1i=1 where Bij is a sub-
matrix of Δ(β1, . . . ,βN ) with the ith row and jth column
removed.
Step 4. solve the LP (16) by the customized primal-dual IPM (Table
2) with the iterate βj at the previous cycle and λ = (C¯βj +
d¯)−1 as the initial points to obtain an optimal solution βj .
Step 5. if (j modulo N) = 0, then j := j + 1, and go to Step 3,
else compute ′ := det(Δ(β1, . . . ,βN)),
if |′ − |/ < ε, then βˆi = βi for i = 1, . . . , N ,
otherwise, set ′ := , j := 1, and go to Step 3.
Step 6. output the source estimates sˆj = Cβˆj + d, j = 1, . . . , N .
4. SIMULATIONS
A Monte Carlo simulation with 100 independent runs is presented
to demonstrate the proposed fast CAMNS-AVM. In each run, we
synthetically generated 7 mixtures from 7 human face images (M =
N = 7 and L = 76800), taken from [1]. A sum square error (SSE)
between sˆi and si is used as the performance measure [1]:
SSE = min
π∈ΠN
N∑
i=1
∥∥∥∥si − ‖si‖2‖sˆπi‖2 sˆπi
∥∥∥∥
2
2
(22)
where π = (π1, . . . , πN ), and ΠN = {π ∈ RN | πi ∈
{1, 2, . . . , N}, πi = πj for i = j} is the set of all the permuta-
tions of {1, 2, ..., N}. In addition, the computation time T (in secs)
of the method (implemented in Mathworks Matlab R2008a) running
on a desktop computer equipped with Core 2 Duo CPU 2.33GHz,
4GB memory is used as our computational complexity measure.
The average SSE and computation time T per realization are
shown in Table 4. In Case A, the original CAMNS-AVM (in Table
1) is used. In Case B, we consider the CAMNS-AVM with Steps 3
and 4 (in Table 1) replaced by solving (12a) only. Case C is similar
to Case B except that in Case C(i), (12a) is solved by the customized
IPM and in Case C(ii), F given by (12a) is further replaced by (15),
found by Quickhull [10]. Finally, Case D is for the fast CAMNS-
AVM (given in Table 3). One can see that the average SSEs are the
same for all the cases, and the computational efficiency literally im-
proves from Case A to Case D. In particular, the computation time
(a)
(b)
(c)
(d)
Fig. 3. Human face images: (a) the sources, (b) the observations (mixtures of the sources), and the extracted sources obtained by (c) CAMNS-
AVM and (d) fast CAMNS-AVM.
[11] G. Strang, Linear Algebra and Its Application, CA: Thomson,
4th edition, 2006.
[12] J. F. Sturm, “Using SeDuMi 1.02, a MATLAB toolbox for
optimization over symmetric cones,” Optimization Methods and
Software, vol. 11-12, pp. 625–653, 1999.
[13] M. Grant and S. Boyd, “CVX: Matlab software for disci-
plined convex programming, version 1.21,” http://cvxr.
com/cvx, Sept. 2010.
[14] K. G. Murty, “A problem in enumerating extreme points, and
an efficient algorithm for one class of polytopes,” Optimization
Letters, vol. 3, no. 2, pp. 211–237, 2009.
[15] F.-Y.Wang, C.-Y. Chi, T.-H. Chan, and Y. Wang, “Nonnegative
least correlated component analysis for separation of dependent
sources by volume maximization,” IEEE Trans. Pattern Analy-
sis and Machine Intelligence, vol. 32, no. 5, pp. 875-888, May
2010.
[16] S. Boyd and L. Vandenberghe, Convex Optimization, Cam-
bridge Univ. Press, 2004.
[17] S. Jibrin, A. Boneh, and R. J. Caron, “Probabalistic algorithms
for extreme point identification,” Journal of Interdisciplinary
Mathematics, vol. 10, pp. 131–142, 2007.
 2 
Transmission Strategy For Outage Rate Maximization in MISO Fading Channels 
With Training).  
 
3/28 (Wednesday): Participated in  
(a) 12:30-14:00 Signal Processing for Communications & Networking (SPCOM) TC Meeting  
(b) attended some poster technical sessions  
 
3/29 (Thursday): Participated in   
1. 10:30-12:30 IVMSP-P7.1：presented Paper #2 (Convex Geometry Based 
Estimation of Number in Hyperspectral Images)  
2. 10:30-12:30 IVMSP-P7.1：presented Paper #3 (Fast Algorithms for Robust 
Hyperspectral Endmember Extraction Based on Worst-Case Simplex Volume 
Maximization)  
3. 12:30-14:00: IDSP-SC Meeting  
 
3/30 (Friday): Participated in:  
1. 09:30:-11:30 SAM-L4 (Joint SAM/SPCOM Session) Relay-Assisted 
Communication  
2. 12:30-14:00 Signal Processing Education SC  
 
3/31 (Saturday): Flied from Kyoto (noon) back to Taiwan, and arrived in桃園中正機場 in the late 
afternoon。  
 
攜回資料：ICASSP-2012會議論文集之隨身碟一支。  
 
二、與會心得 
 
在本次會期中，筆者所發表 3 篇論文受到許多國際專家學者的關注，在吸收新知及建
立人際關係受益良多。來自中國大陸的論文及參與者比往年增加許多，也顯示中國大
陸的快速發展及增進其國際影響力，由於中國優秀人才之展現已為各國爭取之對象。
國內有志於高科技之研發研究生已大不如前，而開放招生陸生之辦法限制過多，對我
們爭取優秀人才之競爭力極為不利，盼政府盡速修改，以利研究發展水平之維持及提
升。 
 
致謝：感謝國科會補助旅費 for the participation of ICASSP-2012。 
 
suing development, are briefly introduced here. The affine hull of
{a1, . . . ,aN} ⊂ R
M is defined as
aﬀ{a1, . . . ,aN} =
{
x =
N∑
i=1
θiai
∣∣∣∣1TNθ = 1,θ ∈ RN
}
, (3)
where θ = [θ1, . . . , θN ]T . Its affine dimension P is no larger than
N − 1. If {a1, . . . ,aN} is affinely independent (i.e., the vectors
a1−aN , . . . ,aN−1−aN are linearly independent), thenP = N−1.
The convex hull of {a1, . . . ,aN} ⊂ RM is defined as
conv{a1, . . . ,aN} =
{
x =
N∑
i=1
θiai
∣∣∣∣1TNθ = 1, θ  0
}
. (4)
The convex hull conv{a1, . . . , aN} is called an N − 1 dimensional
simplex in RM if {a1, . . . ,aN} ⊂ RM is affinely independent.
Such a simplex conv{a1, . . . ,aN} has only N extreme points (ver-
tices), exactly being a1, . . . ,aN .
3. DIMENSION REDUCTION AND DATA GEOMETRY
The proposed GENE algorithms (to be presented in Section 4) esti-
mates N using the endmember estimates provided by a successive
EEA, and hence the specified dimension reduction with N unknown
for any reliable successive EEA is presented.
Assume that we only have prior knowledge on the maximum
bound of the number of endmembers Nmax where N ≤ Nmax ≤
M . In the noisy scenario, similar to the dimension reduction pro-
cedure in [8], the dimension-reduced pixel vectors y˜[n] can be ob-
tained by the following affine transformation of y[n]:
y˜[n] = CT (y[n]− d) ∈ RNmax−1, (5)
where
d =
1
L
L∑
n=1
y[n] =
1
L
L∑
n=1
x[n] +
1
L
L∑
n=1
w[n], (6)
C = [ q1(UyU
T
y − LD), . . . , qNmax−1(UyU
T
y − LD) ], (7)
in which Uy = [ y[1] − d, . . . ,y[L] − d ] ∈ RM×L, and qi(R)
denotes the unit-norm eigenvector of R associated with the ith prin-
cipal eigenvalue. In practical situations, the multiple regression anal-
ysis based noise covariance estimation method reported in HySiMe
[6] can be used to estimate D. Further, due to (1), (2), and (A2), we
have
y˜[n] = x˜[n] + w˜[n], n = 1, . . . , L, (8)
where
x˜[n] =
N∑
i=1
si[n]αi, n = 1, ..., L, (9)
in which αi = CT (ai − d) ∈ RNmax−1 is the ith dimension-
reduced endmember, and w˜[n]  CTw[n] ∈ RNmax−1 is i.i.d.
Gaussian noise with zero mean and covariance matrix Σ given by
Σ = CTDC ∈ R(Nmax−1)×(Nmax−1). (10)
Some convex geometries of the noise-free dimension-reduced
data x˜[n] given by (9) which will lay a solid platform for the ensuing
algorithmic developments, are as follows:
(F1) By (A1)-(A4), any dimension-reduced pixel vectors x˜[n]
should lie in conv{α1, . . . ,αN} and
conv{x˜[1], . . . , x˜[L]} = conv{α1, . . . ,αN}, (11)
where conv{α1, . . . ,αN} is a simplex withN extreme points
being α1, . . . ,αN .
(F2) Considering only (A2) and (A3), any dimension-reduced pixel
vectors x˜[n] should lie in aﬀ{α1, . . . ,αN} and
aﬀ{x˜[1], . . . , x˜[L]} = aﬀ{α1, . . . ,αN}, (12)
where its affine dimension is equal to N − 1.
4. GEOMETRY BASED ESTIMATION OF NUMBER OF
ENDMEMBERS (GENE) ALGORITHMS
In the first subsection, suppose that (A1)− (A4) hold true. Then, the
corresponding noisy pixels are given by
y˜[li] = αi + w˜[li], ∀i = 1, . . . , N. (13)
We propose the GENE-CH algorithm based on the convex hull ge-
ometry (F1). For data with (A4) violated, the GENE-AH algorithm
is proposed in the subsequent subsection.
4.1. GENE-Convex Hull (GENE-CH) Algorithm
Suppose that a reliable, successive EEA has found the pixel indices
l1, . . . , lN , lN+1, . . . , lk−1, lk, in which l1, . . . , lN are pure pixel in-
dices and k ≤ Nmax. Then by (8),(9), and (13),
y˜[li] = x˜[li] + w˜[li], i = 1, . . . , k, (14)
where
x˜[li] =
{
αi, i = 1, . . . , N,∑N
j=1 sj [li]αj , i = N + 1, . . . , k.
(15)
As has been depicted in (F1), the total number of extreme points in
conv{x˜[1], . . . , x˜[L]} is N in the absence of noise. That is to say,
if x˜[lk] ∈ conv{x˜[l1], . . . , x˜[lk−1]}, then it can be inferred by (15)
that all the endmembers are already found, i.e., k ≥ N + 1. How-
ever, in a real scenario, since only noisy y˜[l1], . . . , y˜[lk] are avail-
able (rather than x˜[l1], . . . , x˜[lk]), we propose a Neyman-Pearson
hypothesis [9] testing based method to determine whether x˜[lk] ∈
conv{x˜[l1], . . . , x˜[lk−1]}, or not, based on noisy y˜[l1], . . . , y˜[lk].
The idea is to find the smallest k for which y˜[lk] is closest to
conv{y˜[l1], . . . , y˜[lk−1]} in some optimal sense. To do so, let us
consider the following constrained least squares problem:
θ
 = arg min
θ0,1T
k−1
θ=1
‖y˜[lk]−Ak−1θ‖
2
2, (16)
where
Ak−1 = [y˜[l1], . . . , y˜[lk−1]] ∈ R
(Nmax−1)×(k−1). (17)
The optimization problem in (16) is convex and can be solved by
using available convex optimization solvers such as SeDuMi [10].
Then, the optimal fitting error vector e is given by
e = y˜[lk]−Ak−1θ
 (18)
= μk +
(
w˜[lk]−
k−1∑
i=1
θi w˜[li]
)
∈ RNmax−1, (19)
where the second equality is due to (14), and
μk = x˜[lk]−
k−1∑
i=1
θi x˜[li]. (20)
Then the following can be observed from (19):
1234
Table 2. Mean±standard deviation of the estimated number of endmembers for various algorithms over 100 independent runs for various
PFA (whenever applicable), number of endmembers N , and purity levels ρ, as well as SNR=30 dB, Nmax = 25, L = 5000, and M = 224.
Methods PFA
ρ = 1, SNR=30 dB N = 8, SNR=30 dB
Number of Endmembers N Purity Level ρ
8 12 16 20 0.8 0.85 0.9 0.95
GENE-CH (TRI-P, p = 2)
10−4 8.02±0.17 12.04±0.19 15.77±0.46 19.78±0.50 12.82±2.94 10.97±2.38 9.28±1.28 8.33±0.58
10−5 8.00±0 12.03±0.17 15.77±0.46 19.74±0.52 12.13±2.70 10.23±1.92 8.85±0.98 8.17±0.45
10−6 8.00±0 12.02±0.14 15.72±0.47 19.70±0.52 11.65±2.69 9.85±1.71 8.61±0.92 8.11±0.38
GENE-AH (TRI-P, p = 2)
10−4 8.00±0 12.00±0 14.76±0.42 17.75±0.50 8.02±0.14 8.01±0.09 8.00±0 8.01±0.09
10−5 8.00±0 12.00±0 14.57±0.49 17.51±0.54 8.00±0 8.01±0.09 8.00±0 8.00±0
10−6 8.00±0 12.00±0 14.32±0.46 17.17±0.66 8.00±0 8.00±0 8.00±0 8.00±0
HYSIME [6] – 8.00±0 12.00±0 14.00±0 16.15±0.35 8.00±0 8.00±0 8.00±0 8.00±0
HFC [4]
10−4 5.00±0 7.14±0.68 8.66±0.27 4.19±0.63 5.00±0 5.00±0 5.00±0 5.00±0
10−5 5.00±0 6.44±0.53 7.93±0.25 3.67±0.60 5.00±0 5.00±0 5.00±0 5.00±0
10−6 5.00±0 6.10±0.46 7.76±0.47 3.23±0.52 5.00±0 5.00±0 5.00±0 5.00±0
NW-HFC [4]
10−4 5.00±0 7.18±0.70 9.15±0.35 6.23±0.69 5.00±0 5.00±0 5.00±0 5.00±0
10−5 5.00±0 6.46±0.62 8.97±0.30 5.46±0.77 5.00±0 5.00±0 5.00±0 5.00±0
10−6 5.00±0 5.96±0.58 8.80±0.42 4.78±0.70 5.00±0 5.00±0 5.00±0 5.00±0
merits, but also is reliable with theoretical support for endmember
identifiability for the noise-free case. Therefore, TRI-P algorithm is
a good EEA candidate for the proposed GENE algorithms.
5. SIMULATIONS AND CONCLUSION
One hundred Monte-Carlo runs are performed to study the effec-
tiveness of the proposed GENE-CH and GENE-AH algorithms that
employ TRI-P with p=2 (i.e., 2-norm) [13] to acquire endmember es-
timates for various scenarios. Algorithms considered for comparison
are HySiMe [6], HFC [4], and NW-HFC [4]. The GENE algorithms,
HFC, and NW-HFC are evaluated under the following false alarm
probabilities: 10−4, 10−5 and 10−6, and for GENE and NW-HFC
algorithms, the true noise covariance matrix is supplied for each sim-
ulated realization. The endmembers are chosen from the USGS li-
brary [14] with M = 224. The maximum bound of the number of
endmembers used in GENE algorithms is Nmax = 25. The abun-
dance vectors s[n], n = 1, . . . , L are generated by following the
Dirichlet distribution [8] for generating synthetic data with different
purity levels ρ (defined as ρ = max{‖s[n]‖2 , n = 1, . . . , L} [8]).
Table 2 displays mean±standard deviation of the number of end-
members estimated by the algorithms under test for two scenarios,
where all the hyperspectral data with L = 5000 are corrupted by
white Gaussian noise [8] with SNR = 30 dB. The estimated number
of endmembers closest to the true number of endmembers are high-
lighted by bold-faced numbers. In the first scenario, the number of
endmember N is allowed to vary as 8, 12, 16 and 20, while maintain-
ing the purity level ρ = 1 (indicating the existence of pure pixels in
the data). It can be observed that for higher number of endmembers
N = 16, 20 GENE-CH yields the best performance followed by
GENE-AH. For N = 8, 12 both GENE-AH and HySiMe yield best
performance. In the second scenario where the purity level ρ of the
hyperspectral data varies from 0.8 to 0.95 (indicating no pure pixels
in the data) while maintaining N = 8, it can be readily seen that
when purity level is smaller, GENE-CH overestimates the number
of endmembers. On the other hand, GENE-AH with PFA = 10−6
and HySiMe correctly estimate the number of endmembers.
In conclusion, we have presented two convex geometry based al-
gorithms for estimating the number of endmembers, namely GENE-
CH and GENE-AH algorithms, based on (F1) and (F2), respectively.
The GENE algorithms employ a Neyman-Pearson hypothesis testing
strategy and they must operate in conjunction with a successive EEA
in a synchronization fashion. Simulation results confirm the superior
efficacy of the proposed GENE-CH and GENE-AH algorithms over
some existing benchmark methods, because of more focused geom-
etry (convex and affine sets rather than range space) considered for
the hyperspectral data.
6. REFERENCES
[1] H. Akaike, “A new look at the statistical model identification,” IEEE
Trans. Automat. Control, vol. AC-19, no. 6, pp. 716-723, Dec. 1974.
[2] J. Rissanen, “Modeling by shortest data description,” Automatica, vol.
14, no. 5, pp. 465-471, Sep. 1978.
[3] G. Schwarz, “Estimating the dimension of a model,” The Annals of
Statistics, vol. 6, no. 2, pp. 461-464, Mar. 1978.
[4] C.-I. Chang and Q. Du, “Estimation of number of spectrally distinct
signal sources in hyperspectral imagery,” IEEE Trans. Geosci. Remote
Sens., vol. 42, no. 3, pp. 608-619, Mar. 2004.
[5] J. Harsanyi, W. Farrand, and C.-I Chang, “Determining the number
and identity of spectral endmembers: An integrated approach using
Neyman-Pearson eigenthresholding and iterative constrained RMS er-
ror minimization,” in Proc. 9th Thematic Conf. Geologic Remote Sens-
ing, Feb. 1993.
[6] J. M. B. Dias and J. M. P. Nascimento, “Hyperspectral subspace iden-
tification,” IEEE Trans. Geosci. Remote Sens., vol. 46, no. 8, pp. 2435-
2445, Aug. 2008.
[7] S. Boyd and L. Vandenberghe, Convex Optimization, UK: Cambridge
Univ. Press, 2004.
[8] A. Ambikapathi, T.-H. Chan, W.-K. Ma, and C.-Y. Chi, “Chance-
constrained robust minimum-volume enclosing simplex algorithm for
hyperspectral unmixing,” IEEE Trans. Geosci. Remote Sens. - Special
Issue on Spectral Unmixing of Remotely Sensed Data, vol. 49, no. 11,
pp. 4194-4209, Nov. 2011.
[9] L. C. Ludeman, Random Processes Filtering, Estimation, and Detec-
tion, Wiley-Interscience Publication, 2003.
[10] J. F. Sturm, “Using SeDuMi 1.02, a MATLAB toolbox for optimization
over symmetric cones”, Optimization Methods and Software vol. 11-
12, pp. 625-653, 1999.
[11] M. Evans, N. Hastings, and B. Peacock, Statistical Distributions, 2nd
ed., Wiley-Infterscience Publication, 1993.
[12] G. Arfken and H. Weber, Mathematical Methods for Physicists, Har-
court Academic Press, 2000.
[13] A. Ambikapathi, T.-H. Chan, C.-Y. Chi and K. Keizer, “Two effective
and computationally efficient pure-pixel based algorithms for hyper-
spectral endmember extraction,” in Proc. IEEE ICASSP, Prague, Czech
Republic, May 22-27, 2011, pp. 1369-1372.
[14] R. N. Clark, G. A. Swayze, A. Gallagher, T.V. King, and W. M. Calvin,
“The U.S. geological survey digital spectral library: Version 1: 0.2 to
3.0,” U. S. Geol. Surv., Open File Rep. pp. 93-592, 1993.
1236
vector due to CTC = IN−1. After dimension reduction, the aim
now is to estimate α1, . . . ,αN from the dimension reduced ob-
served pixel vectors y˜[1], . . . , y˜[L]. Onceα1, . . . ,αN are obtained,
one can simply recover the endmember estimates by the affine trans-
formation ai = Cαi + d, i = 1, . . . , N.
3. BRIEF REVIEW OF WORST-CASE WINTER’S
ENDMEMBER EXTRACTION PROBLEM
Winter proposed an EE criterion which states that in the presence
of pure pixels, the true endmembers can be determined by find-
ing the vertices of the maximum-volume simplex inside the data
cloud y˜[1], . . . , y˜[L] [9]. However, a fact is mentioned in [1] that
in the presence of additive noise, the simplex volume yielded by
Winter’s criterion may be larger than that of the true simplex. In
other words, the endmember estimates obtained by Winter’s crite-
rion may be away from the true endmembers when the observed data
are corrupted by noise. To mitigate such effects, we have proposed
an idea [1] to pull back the estimates obtained by Winter’s criterion
by a suitable margin such that (ν1, . . . ,νN ) are closer to the true
endmembers (α1, . . . ,αN). This idea, as illustrated in Figure 1,
can be formulated as the following problem [1]:
max
vi∈R
N−1,
i=1,...,N
{
min
‖ui‖≤r,
i=1,...,N
∣∣∣∣det(Δ(v1 − u1, . . . ,vN − uN ))
∣∣∣∣
}
s.t. vi ∈ conv{y˜[1], . . . , y˜[L]}, i = 1, . . . , N,
(4)
where each ui lying in a norm ball {u ∈ RN−1 | ‖u‖ ≤ r} is the
pull-back vector, r is the maximum back-off distance,
Δ(t1, . . . , tN ) =
[
t1 · · · tN
1 · · · 1
]
∈ RN×N
for any ti ∈ RN−1, and conv{y˜[1], . . . , y˜[L]} is defined as
conv{y˜[1], . . . , y˜[L]} =
{
y =
L∑
n=1
θny˜[L]
∣∣∣ θ  0, 1TLθ = 1},
(5)
where θ = [θ1, ..., θL]T . Denoting the optimal solution of problem
(4) by (vˆ1, . . . , vˆN , uˆ1, . . . , uˆN ), the robust endmember estimates
are obtained by
νˆi = vˆi − uˆi, i = 1, . . . , N. (6)
true endmembers
robust Winter estimates
original Winter estimates
conv{y˜[1], ..., y˜[L]}
r
r
r
α1
α2
α3
ν1
ν2
ν3
v1
v2
v3
y˜[n]
Fig. 1. Illustration of robust Winter’s EE problem for N = 3.
In [1], we have proposed an algorithm for handling problem
(4). Called WAVMAX, the algorithm demonstrates performance im-
provement in the noisy scenario. However, WAVMAX is expensive
to implement.
4. FAST ALGORITHMS FOR WORST-CASE WINTER’S
ENDMEMBER EXTRACTION PROBLEM
In this section, we propose two fast algorithms for dealing with the
worst-case Winter’s problem (4). We utilize alternating optimization
and successive optimization to approximate the max-min problem
(4) by a sequence of max-min subproblems, leading to alternating
decoupled volume max-min (ADVMM) and successive decoupled
volume max-min (SDVMM) algorithms, respectively.
4.1. ADVMM Algorithm
By letting Y˜ = [ y˜[1], . . . , y˜[L] ] ∈ R(N−1)×L, vi = Y˜θi, and
the property det(PΔ) = ±det(Δ) for any permutation matrix P,
problem (4) can be expressed as
max
θi∈S,
i=1,...,N
{
min
‖ui‖≤r,
i=1,...,N
det(Δ(Y˜θ1 − u1, . . . , Y˜θN − uN ))
}
(7)
where S = {θ ∈ RL | θ  0, 1TLθ = 1}. Optimizing θ1, . . . ,θN
and u1, . . . ,uN jointly in (7) is quite challenging. By alternating
optimization, let us consider the partial max-min problem of (7)
with respect to (w.r.t.) the pair (θj ,uj) while fixing the other pairs
(θi,ui) for i = j. The jth partial max-min problem is represented
by
max
θj∈S
{
min
‖uj‖≤r
det(Δ(Y˜θˆ1 − uˆ1, . . . , Y˜θˆN − uˆN ))
}
. (8)
The partial max-min problems (8) for j = 1, . . . , N are conducted
cyclically until some stopping criterion is satisfied.
Next, we will present how to solve the partial max-min prob-
lem (8). By applying a cofactor expansion of det(Δ(Y˜θˆ1 −
uˆ1, . . . , Y˜θˆN − uˆN )) along jth column, we have
k
T
j (Y˜θj − uj) + (−1)
N+jdet(QNj), (9)
where
kj = [(−1)
i+jdet(Qij)]
N−1
i=1 ∈ R
N−1 (10)
is a vector with ith element equal to (−1)i+jdet(Qij) and Qij ∈
R
(N−1)×(N−1) is a submatrix of Δ(Y˜θˆ1 − uˆ1, . . . , Y˜θˆN − uˆN)
with the ith row and the jth column removed. Then, problem (8) is
equivalent to
max
θj∈S
{
min
‖uj‖≤r
k
T
j (Y˜θj − uj)
}
, (11)
where the term (−1)N+jdet(QNj) independent of (θj ,uj) is re-
moved without loss of optimality. In addition, since θj and uj are
decoupled, the above problem can be handled by solving the follow-
ing problems separately:
uˆj = arg max
‖uj‖≤r
k
T
j uj = rkj/‖kj‖, (12)
θˆj = arg max
θj∈S
k
T
j Y˜θj = e,  = arg max
n=1,...,L
k
T
j y˜[n], (13)
where uˆj in (12) is obtained by Cauchy-Schwarz inequality and θˆj
in (13) can be obtained by [1, Lemma 2]. The pseudo-codes of the
proposed ADVMM are given in Table 1 (left part).
1238
Table 2. Performance comparison of average φ (degrees) and average T (secs) over some existing EE methods.
Algorithms
Case I: M = 224, N = 8, L = 1000 Case II: M = 224, N = 8, SNR= 15 dB
SNR (dB) Number of pixels (L)
5 10 15 20 25 ∞ 250 500 1000 2000 4000 8000
SGA [8]
φ 13.92 8.06 3.34 1.73 0.96 0.00 5.32 3.95 3.34 3.01 2.97 2.94
T 0.126 0.124 0.116 0.113 0.111 0.111 0.118 0.192 0.255 0.577 1.054 2.231
SQ-N-FINDR [7]
φ 14.13 8.06 3.50 1.86 1.07 0.00 5.23 4.08 3.50 3.19 3.11 3.11
T 0.179 0.164 0.138 0.130 0.120 0.110 0.109 0.179 0.247 0.556 0.907 1.664
SC-N-FINDR [7]
φ 14.90 8.50 3.92 2.00 1.08 0.00 5.99 4.66 3.92 3.52 3.54 3.34
T 0.068 0.066 0.059 0.056 0.055 0.054 0.066 0.096 0.120 0.244 0.384 0.649
WAVMAX [1]
φ 13.30 8.10 3.15 1.75 1.03 0.00 5.24 4.01 3.15 2.92 2.73 2.58
T 42.879 55.778 43.853 45.579 46.696 39.285 11.518 30.861 65.850 233.859 778.585 2997.140
ADVMM
φ 12.95 7.27 3.15 1.75 1.03 0.00 5.16 3.87 3.15 2.85 2.70 2.61
T 0.042 0.038 0.027 0.020 0.017 0.015 0.066 0.073 0.072 0.111 0.166 0.218
SDVMM
φ 13.50 7.45 3.00 1.59 0.90 0.00 5.04 3.66 3.00 2.69 2.49 2.42
T 0.028 0.026 0.019 0.016 0.014 0.014 0.049 0.056 0.060 0.099 0.149 0.184
where SNR =
∑L
n=1 ‖x[n]‖
2/σ2ML. For the proposed methods,
the convergence tolerance ε = 5× 10−5 and r = 1.3σ, where noise
power σ is assumed to be known.
Table 2 shows the average φ and T per realization over various
algorithms. The minimum φ and T for a specific SNR or L are high-
lighted by bold-faced numbers. In Case I, ADVMM outperforms the
other algorithms for SNR= 5, 10 dB, and SDVMM performs best
for SNR≥ 15 dB. In Case II, the performance of SDVMM is better
than the other algorithms for various values of L under test. Besides,
the proposed ADVMM and SDVMM algorithms are faster than all
the other existing methods, and are more than 1000 times faster than
WAVMAX.
In conclusion, we have developed two fast, noise-robust Winter
criterion based hyperspectral EE algorithms, namely ADVMM and
SDVMM, by using alternative and successive optimization strate-
gies, respectively. Simulation results have shown superior efficacy
and computational efficiency of the proposed methods over some
existing benchmark EE algorithms.
6. APPENDIX
The KKT conditions of Problem (19) are as below:(
P
⊥
Ĥ1:(j−1)
+ λˆIN
)
zˆj = P
⊥
Ĥ1:(j−1)
wj , (24a)
λˆ(‖zˆj‖
2 − r2) = 0, (24b)
‖zˆj‖
2 − r2 ≤ 0, λˆ ≥ 0, (24c)
where zˆj and λˆ are primal and dual optimal points of (19). By (24a),
(24c), we have
‖P⊥
Ĥ1:(j−1)
wj‖ ≤ ‖P
⊥
Ĥ1:(j−1)
+ λˆIN‖‖zˆj‖ ≤ (1 + λˆ)r, (25)
where the first inequality is due to the inequality of the operator
norm, and the second inequality is due to the eigenvalues of a pro-
jection matrix equal to either zero or one.
Two cases on wj ∈ F are considered: (C1) wj ∈ W(r) and
(C2) wj ∈ RN \ W(r). We first consider (C1). By (C1) and (25),
we can have λˆ > 0, which implies P⊥
Ĥ1:(j−1)
+ λˆIN is of full rank.
Then, (24a) becomes
zˆj = (P
⊥
Ĥ1:(j−1)
+ λˆIN )
−1
P
⊥
Ĥ1:(j−1)
wj . (26)
By idempotence property and eigenvalue decomposition of
P⊥
Ĥ1:(j−1)
and through some mathematical derivations, (26) can be
shown to be
zˆj =
1
1 + λˆ
P
⊥
Ĥ1:(j−1)
wj . (27)
By (27) and λˆ > 0, (24b) becomes ‖zˆj‖ = ‖ 1
1+λˆ
P⊥
Ĥ1:(j−1)
wj‖ =
r, which yields
λˆ = r−1‖P⊥
Ĥ1:(j−1)
wj‖ − 1. (28)
Therefore, by (27) and (28), the solution (20) can be obtained.
We next consider (C2); i.e., wj ∈ RN \ W(r). As it can be
shown by (28) that λˆ > 0 implies (C1), then by contradiction, (C2)
implies λˆ = 0. Hence (24a) reduces to
P
⊥
Ĥ1:(j−1)
zˆj = P
⊥
Ĥ1:(j−1)
wj , (29)
which leads to (21). 
7. REFERENCES
[1] T.-H. Chan, W.-K. Ma, A. Ambikapathi, and C.-Y. Chi, “A simplex
volume maximization framework for hyperspectral endmember extrac-
tion,” to appear in IEEE Trans. Geoscience and Remote Sensing - Spe-
cial Issue on Spectral Unmixing of Remotely Sensed Data, 2011.
[2] N. Keshava and J. Mustard, “Spectral unmixing,” IEEE Signal Process.
Mag., vol. 19, no. 1, pp. 44-57, Jan. 2002.
[3] N. Dobigeon, S. Moussaoui, M. Coulon, J.-Y. Tourneret, and A. O.
Hero, “Joint Bayesian endmember extraction and linear unmixing for
hyperspectral imagery,” IEEE Trans. Signal Processing, vol. 57, no.
11, pp. 4355-4368, Nov. 2009.
[4] J. M. B. Dias, “A variable splitting augmented Lagrangian approach
to linear spectral unmixing,” in Proc. First IEEE Workshop on Hyper-
spectral Image and Signal Processing: Evolution in Remote Sensing,
Grenoble, France, Aug. 26-28, 2009.
[5] A. Ambikapathi, T.-H. Chan, W.-K. Ma, and C.-Y. Chi, “Chance con-
strained robust minimum volume enclosing simplex algorithm for hy-
perspectral unmixing,” to appear in IEEE Trans. Geoscience and Re-
mote Sensing - Special Issue on Spectral Unmixing of Remotely Sensed
Data, 2011.
[6] A. Zare and P. Gader, “L1-endmembers: A robust endmember detec-
tion and spectral unmixing algorithm,” in Proc. of SPIE, vol. 7695, p.
76951L, Dec. 9-14, 2010.
[7] C.-C. Wu, S. Chu, and C.-I Chang, “Sequential N-FINDR algorithms,”
in Proc. of SPIE, vol. 7086, Aug. 2008.
[8] C.-I Chang, C.-C. Wu, C.-S. Lo, and M.-L. Chang “Real-time simplex
growing algorithms for hyperspectral endmember extraction,” IEEE
Trans. Geosci. Remote Sens., vol. 48, no. 4, pp. 1834-1850, April 2010.
[9] M. E. Winter, “N-findr: An algorithm for fast autonomous spectral
end-member determination in hyperspectral data,” in Proc. SPIE Conf.
Imaging Spectrometry, Pasadena, CA, Oct. 1999, pp. 266-275.
[10] Tech. Rep., Available online: http://speclab.cr.usgs.gov/
cuprite.html.
1240
closed-form expressions. In particular, assuming that the input data
signal x(t) ∈ CNt has zero mean and covariance matrix Q  0
(positive semidefinite), an achievable rate is given by [1, 7]
T¯d log2
(
1 +
hˆHQhˆ
σ2eTr(Q) + σ2
)
bits/sec/Hz, (2)
where T¯d = Td/(Tc + Td), and Tr(Q) is the trace of matrix Q.
The scenario under consideration is that there is no instanta-
neous channel estimate feedback from the receiver, and that the trans-
mitter knows only the statistical information of hˆ. Under such cir-
cumstances, our goal is to jointly optimize the training power Pc and
the transmit covariance matrixQ such that the ρ-outage rate, i.e., the
achievable rate for which the probability of rate outage is no larger
than ρ ∈ [0, 1), can be maximized. Mathematically, this outage
constrained design can be formulated as the following optimization
problem:
max
Q∈HNt ,Pc,R∈R
R (3a)
s.t. Prob
{
T¯d log2
(
1+
hˆHQhˆ
σ2eTr(Q) + σ2
)
<R
}
≤ρ,
(3b)
TcPc +Tr(Q)Td ≤ Emax, (3c)
Pc ≥ 0, R ≥ 0, Q  0, (3d)
where Emax > 0 is the maximum energy constraint. The joint train-
ing and data transmission design problem in (3) is difficult to handle
due to the probability constraint (3b). In the next section, we show
how explicit solutions of Pc, Q and R for problem (3) can be ana-
lytically obtained.
3. OPTIMAL TRANSMISSION STRATEGY
As will be seen soon, the optimal Pc and Q can be obtained sepa-
rately; they are respectively presented in the subsequent two subsec-
tions.
3.1. Optimal Training Power Design
Let us express
Q = Tr(Q)Q˜ and hˆ =
(
σ2h − σ
2
e
)1/2
uˆ (4)
where Q˜  0, Tr(Q˜) = 1, and uˆ ∼ CN (0, INt) are power nor-
malized counterparts of Q and hˆ, respectively. Note that the en-
ergy constraint (3c) will hold with equality when the optimal R is
achieved; otherwise one can always obtain a higher rate R by scal-
ing up Tr(Q). Hence one can write (3c) as
Tr(Q) = (Emax − TcPc)/Td. (5)
By (4) and (5), one can express problem (3) as
max
Pc,R≥0,
Q˜0,Tr(Q˜)=1
R (6a)
s.t. Prob
{
T¯d log2(1+α(Pc)uˆ
H
Q˜uˆ)<R
}
≤ρ, (6b)
α(Pc) =
(σ2h − σ
2
e)(Emax − TcPc)/Td
σ2e(Emax − TcPc)/Td + σ2
. (6c)
−15 −10 −5 0 5 10 15 20
0
1
2
3
4
5
6
M
a
x
im
u
n
 o
u
ta
g
e
 r
a
te
 (
b
it
s
/s
e
c
/H
z
)
Pc (dB)
P 
c
Fig. 1: Maximum outage rate versus training power. The optimal
training power P c = 7.499 dB.
It is not difficult to verify from (6) that the optimal Pc, denoted
by P c , is the one that maximizes α(Pc). Interestingly, the optimal
training power for the rate outage maximization problem (3) is iden-
tical to that in [1] for ergodic rate maximization. A closed-form so-
lution of P c has been derived in [1, Theorem 2] and is summarized
in the following lemma:
Lemma 1 The optimal training power P c to problem (3) is given
by
P c =arg max
Pc≥0
α(Pc)=
⎧⎨
⎩
(1− ϕ1)Emax/Tc, Td > Nt,
Emax/(2Tc), Td = Nt,
(1− ϕ2)Emax/Tc, Td < Nt,
(7)
where ϕ1 = ξ −
√
ξ(ξ − 1), ϕ2 = ξ +
√
ξ(ξ − 1), and
ξ =
σ2Nt + σ
2
hEmax
σ2hEmax
(
1− Nt
Td
) . (8)
While the rate outage maximization problem in (3) and the er-
godic rate maximization problem in [1] have the same strategy in
allocating the training and data powers, as one will see later, the out-
age rate maximization problem (3) can have a very different data
transmission strategy from its ergodic counterpart in [1].
Before proceeding to the optimal Q˜, let us present a simulation
example demonstrating the importance of optimal training power de-
sign. Figure 1 displays the maximum outage rate versus training
power Pc, for Nt = 4, Tc = Nt, and Td = 40Nt. The chan-
nel variance σ2h = 1, noise variance σ
2 = 0.01, energy constraint
Emax = 164 (i.e., the average transmit power Emax/(Tc+Td) = 1),
and outage probability ρ = 0.1. The normalized data covariance ma-
trix Q˜ = (1/Nt)INt , which will be shown to be the optimal strategy
under this simulation setting. One can observe from Fig. 1 that an
improper training power can result in dramatic rate reduction.
3.2. Optimal Transmit Covariance Matrix Design
Given the optimal training power P c , (6) can be simplified to
max
R≥0,
Q˜0,Tr(Q˜)=1
R (9a)
s.t. Prob
{
T¯d log2(1+α(P

c )uˆ
H
Q˜uˆ)<R
}
≤ρ. (9b)
2946
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
3
3.5
4
4.5
5
5.5
6
6.5
7
7.5
M
a
x
im
u
m
 o
u
ta
g
e
 r
a
te
 (
b
it
s
/s
e
c
/H
z
)
 
 
Optimal transmission strategy
All-antenna transmission strategy
Single-antenna transmission strategy
 
 
0.5 0.6 0.7 0.8
6
6.5
ρ
Fig. 2: Maximum outage rate versus outage probability ρ of different
transmission strategies. Nt = 10, Tc = Nt, Td = 40Nt, σ2h = 1,
σ2 = 0.01, and Emax/(Tc + Td) = 1.
4. PROOF OF PROPOSITION 1
We first review some important analysis results in [5]. Specifically,
in [5], it was shown that the following function
P¯min(x)  min
λi≥0, i=1,...,2Nt,
∑2Nt
i=1
λi=1
Prob
{
2Nt∑
i=1
λiv
2
i ≤ x
}
, (21)
where vi ∼ N (0, 1), is continuous and monotonically increasing,
and has a closed-form expression as
P¯min(x) =
⎧⎨
⎩
Fd(x), ∀x ∈ [x(d, d+ 1), x(d− 1, d)),
d = 1, . . . , 2Nt − 1,
F2Nt(x), ∀x ∈ [0, x(2Nt − 1, 2Nt)).
(22)
Figure 3 illustrates P¯min(x). However, the above result is not di-
rectly applicable to (15) since the latter has the additional constraint
of λ2k = λ2k−1 ≥ 0, k = 1, . . . , Nt. By the fact of (16), this con-
straint is equivalent to limiting the optimal d to be an even number.
Therefore, for the case of x ∈ [x(2n, 2n+1), x(2n−1, 2n)), where
n ≥ 1 is an integer, we can directly obtain from (22) that d = 2n;
i.e.,
Pmin(x) = F2n(x) ∀x ∈ [x(2n, 2n+ 1), x(2n− 1, 2n)). (23)
Now let us consider the case of x ∈ [x(2n − 1, 2n), x(2n −
2, 2n− 1)). We have to choose 1 ≤ d ≤ 2Nt among even numbers
such that Fd(x) is minimum in the interval [x(2n− 1, 2n), x(2n−
2, 2n− 1)). We will use the following lemma:
Lemma 3 [5, Proposition 1′] For any integers d2 > d1 > 0, there
exists a unique point x(d1, d2) ∈ [x(d2−1, d2), x(d1, d1+1)] such
that Fd2(x) ≥ Fd1(x) for x ≥ x(d1, d2), and Fd2(x) < Fd1(x)
for x ∈ (0, x(d1, d2)).
Let d˜ > 2n be an even number. By Lemma 3, there exists a point
x(2n, d˜) ∈ [x(d˜− 1, d˜), x(2n, 2n+1)) such that Fd˜(x) ≥ F2n(x)
for x ≥ x(2n, d˜), and Fd˜(x) < F2n(x) for x ∈ (0, x(2n, d˜)), i.e.,
x(2n, d˜) is the crossing point. Therefore, F2n(x) is the minimum
p(d−1, d)
p(d, d+1)
p(d+1, d+2)
p(2Nt−1, 2Nt)
...
0.5
P¯min(x)
1 x(2Nt−1, 2Nt) · · · x(d+1, d+2) x(d, d+1) x(d−1, d)
x
0
Fd+1(x)
Fd(x)
F2Nt(x)
Fig. 3: Illustration of P¯min(x) in (22).
CDF in the interval [x(2n−1, 2n), x(2n−2, 2n−1)) compared to
any other Fd˜(x) with even number d˜ > 2n. Analogously, one can
show that F2n−2(x) is the minimum CDF in the interval [x(2n −
1, 2n), x(2n− 2, 2n − 1)) compared to any other Fd˜(x) with even
number d˜ < 2n− 2.
What remains is to choose between F2n(x) and F2n−2(x). Ap-
plying Lemma 3 to F2n(x) and F2n−2(x) again, we can obtain that
there exists a point x(2n−2, 2n) ∈ [x(2n−1, 2n), x(2n−2, 2n−
1)) such that F2n(x) ≥ F2n−2(x) for x ≥ x(2n − 2, 2n), and
F2n(x) < F2n−2(x) for x ∈ (0, x(2n− 2, 2n)). This implies that
Pmin(x) = F2n(x) ∀x ∈ [x(2n− 1, 2n), x(2n− 2, 2n)). (24)
By using similar argument to the interval [x(2n+1, 2n+2), x(2n, 2n
+ 1)), we can also obtain
Pmin(x) = F2n(x) ∀x ∈ [x(2n, 2n+ 2), x(2n, 2n+ 1)). (25)
Combining (23), (24), and (25), we conclude with
Pmin(x) = F2n(x) ∀x ∈ [x(2n, 2n+ 2), x(2n− 2, 2n)), (26)
for n = 1, . . . , Nt − 1, and
Pmin(x) = F2Nt (x) ∀x ∈ [0, x(2Nt − 2, 2Nt)). (27)
The proof is thus completed. 
5. REFERENCES
[1] B. Hassibi and B. M. Hochwald, “How much training is needed in
multiple-antenna wireless links,” IEEE Trans. Inf. Theory, vol. 49, no. 4,
pp. 951–963, Apr. 2003.
[2] E. Telatar, “Capacity of multi-antenna Gaussian channels,” Bell Labs
Tech. J., vol. 10, no. 6, pp. 585–595, Nov./Dec. 1999.
[3] E. A. Jorswieck and H. Boche, “Outage probability in multiple antenna
systems,” European Trans. Telecommun., vol. 18, no. 3, pp. 217–233,
Apr. 2007.
[4] ——, “Optimal transmission strategies and impact of correlation in mul-
tiantenna systems with different types of channel state information,”
IEEE Trans. Signal Process., vol. 52, no. 12, pp. 3440–3453, Dec. 2004.
[5] G. J. Sze´kely and N. K. Bakirov, “Extremal probabilities for Gaussian
quadratic forms,” Probability Theory and Related Fields, vol. 126, no. 2,
pp. 184–202, Jun. 2003.
[6] T. F. Wong and B. Park, “Training sequence optimization in MIMO sys-
tems with colored interference,” IEEE Trans. Commun., vol. 52, no. 11,
pp. 1939–1947, Nov. 2004.
[7] T. Yoo and A. Goldsmith, “Capacity and power allocation for fading
MIMO channels with channel estimation error,” IEEE Trans. Inf. Theory,
vol. 52, no. 5, pp. 2203–2214, May 2006.
2948
 2 
Functional MR Imaging B, Computer Aided Diagnosis B, Image Acquisition and 
Reconstruction B) including our poster paper (請參見附件一: our poster照片) and 
TH-PO.PB (Tracking in Live Cell Microscopy A, Registration, Segmentation and Feature 
Detection in Microscopy B, Image Registration, Cardiac and Vascular Imaging B)  
(f) (17:00-18:30) attended TH-PM1.02: Sparse Methods II  
 
5/4 (Friday):  
(a) (08:30-09:15) attended SF-6: Discrete Optimization for Medical Image Registration and 
Segmentation   
(b) (09:30-11:00) attended FR-AM1.04: Sparse Methods for Signal Reconstruction and Medical 
Image Analysis (SS)  
(c) (11:30-13:00) attended FR-AM2.04: Dynamic Imaging  
(d) (14:30-15:30) attended PLEN-3: Dr. Emmanuel Candes (Stanford University, USA)- 
Compressive Sensing for Faster Imaging  
(e) (15:30-17:00) attended FR-PO.PA (Brain Imaging A, Image Guided Therapy and 
Interventions, Ultrasound A, Medical Image Analysis: Applications A) and FR-PO.PB 
(Image Segmentation A, Tracking in Live Cell Microscopy B, Signal Molecule and Electron 
Microscopy B, Computation Techniques in Microscopy B)  
 
5/5 (Saturday): Due to flight constraint, I was unable to attend the technical program today. Flied 
from Barcelona (in the morning) back to Taiwan, and arrived in桃園中正機場 in the 
morning on 5/6。  
 
 
攜回資料：ISBI-2012會議論文集之光碟一片。  
 
 
二、與會心得 
 
在本次會期中，筆者所發表 1 篇論文，在吸收新知及建立人際關係受益良多。由於第
一次參加此領域之重要國際會議，來自台灣之論文僅有 3篇(兩篇台大及一篇清大)，研
究能量、國際視野及肯定均需努力加強。國內有志於高科技之研發研究生已大不如前，
而開放招生陸生之辦法限制過多，對我們爭取優秀人才之競爭力極為不利，盼政府盡
速修改，以利研究發展水平之維持及提升。 
 
致謝：感謝國科會補助旅費 for the participation of IEEE ISBI-2012。 
AN NBSS ALGORITHM FOR PHARMACOKINETIC ANALYSIS OF PROSTATE CANCER
USING DCE-MR IMAGES
ArulMurugan Ambikapathi†, Tsung-Han Chan†, Kannan Keizer†, Fei-Shih Yang‡, and Chong-Yung Chi†
†Institute of Communications Engineering, National Tsing Hua University, Hsinchu, Taiwan
‡Department of Radiology, Mackay Memorial Hospital, Taipei, Taiwan
E-mail: {aareul,thchan}@ieee.org;mmh80@ms2.mmh.org.tw;cychi@ee.nthu.edu.tw;
ABSTRACT
Dynamic contrast enhanced magnetic resonance (DCE-MR) imag-
ing is an exciting tool to study the pharmacokinetics of a suspected
tumor tissue. Nonetheless, the inevitable partial volume effect in
DCE-MR images may seriously hinder the quantitative analysis of
the kinetic parameters. In this work, based on the conventional
three-tissue compartment model, we propose an unsupervised non-
negative blind source separation (nBSS) algorithm, called time ac-
tivity curve (TAC) estimation by projection (TACE-Pro), to dissect
and characterize the composite signatures in DCE-MR images of pa-
tients with prostate cancers. The TACE-Pro algorithm first identifies
the TACs (up to a scaling ambiguity) with theoretical support. Then
the problem of scaling ambiguity and the estimation of kinetic pa-
rameters is handled by pharmacokinetic model fitting. Some Monte
Carlo simulations and real DCE-MR image experiments of a patient
with prostate cancer were performed to demonstrate the superior ef-
ficacy of the proposed TACE-Pro algorithm. Furthermore, the real
data experiments revealed the consistency of the extracted informa-
tion with the biopsy results.
1. INTRODUCTION
Prostate cancer is a most common cancer in men and the number
of patients with prostate cancer is considerably increasing world-
wide. It is also one of the most high-risk types of cancers and it is
among the leading causes of cancer deaths [1,2]. DCE-MR imaging
is a powerful imaging modality suitable for early stage diagnosis of
prostate cancer. The analysis of the pharmacokinetic model of the
DCE-MR images is to estimate kinetic, physiological parameters of
tissues. Although the kinetic parameters have shown to be relevant
to cancer diagnosis, response of therapy and the survival rate, the
inevitable partial volume effect in DCE-MR images still hinders the
quantitative analysis of the kinetic parameters. Partial volume ef-
fect is a phenomenon that the signal at each pixel of DCE-MR im-
age data set is a weighted composition of time activities of more
than one distinct tissue irrespective of the spatial resolution. Current
methods for pharmacokinetic analysis are based on the approaches
reported in [3, 4]. Major limitations of these methods include unre-
alistic assumption on the compartment model that the tissue kinetics
are statistically independent, intractable computational complexity,
and sensitivity to initialization.
In this work, for the pharmacokinetic analysis of DCE-MR im-
ages of prostate cancer, we develop an unsupervised non-negative
blind source separation (nBSS) algorithm, namely time activity
This work was supported in part by National Science Council (R.O.C.)
under Grant NSC 99-2221-E-007-003-MY3 and in part by NTHU and
Mackay memorial hospital under Grant 100N2742E1.
.I
WUDQV
9DFXODUSODVPDVSDFH
)DVWIORZ
SRRO
6ORZIORZ
SRRO
.V
WUDQV NHSVNHSI
Fig. 1. Schematic diagram of three-tissue compartmental model.
curve (TAC) estimation by projection (TACE-Pro), motivated by
our previous work in hyperspectral image analysis (for spectral sig-
nature identification of disparate minerals in remote sensing) [5].
The TACE-Pro algorithm first identifies the TACs up to a scaling
ambiguity. The issue of scaling ambiguity is then handled by phar-
macokinetic model fitting, which is implemented using sequential
quadratic programming (SQP) solvers. Finally, the estimation of
the kinetic parameters using the obtained TACs can be formulated
as a convex constrained least-squares problem and can be solved by
available convex optimization solvers. The simulation and experi-
mental results are presented to demonstrate the superior efficacy of
TACE-Pro algorithm.
The notations used in this paper are briefed as follows: RM rep-
resents the set of real M×1 vectors, 1N represents the N×1 all-one
vector, and IN is the N ×N identity matrix. ⊗ represents convolu-
tion operation. The symbol ‖ · ‖ represents the Euclidean norm and
X
† stands for Moore-Penrose pseudo-inverse of matrix X.
2. PROBLEM STATEMENT
In 1991, Tofts et al. [6] proposed a compartmental model to analyze
T1-weighted DCE-MR images. In the presence of tumor, the tissue
compartment model consists of fast flow and slow flow pools [7],
as shown in Figure 1. There are three principal parameters of in-
terest, namely the unidirectional transfer constant (K trans), the flux
rate constant (kep), and the extravascular extracellular space (EES)
plasma fractional volume (Kp). The dynamic tracer concentrations
are governed by a set of first-order differential equations [6]:
dCf (t)
dt
+ kep,fCf (t) = K
trans
f Cp(t), (1)
dCs(t)
dt
+ kep,sCs(t) = K
trans
s Cp(t), (2)
Cms(t) = KpCp(t) + Cf (t) + Cs(t), (3)
566978-1-4577-1858-8/12/$26.00 ©2012 IEEE ISBI 2012
where aff{β1, . . . ,βj} = {y =  
j
i=1 ϑiβi|1
T
j ϑ = 1, ϑ ∈ R
j}
in which ϑ = [ϑ1, . . . , ϑj ]T [9], and P⊥B = IN−1 − BB
† is the
orthogonal complement projector of B  [β1 − βj , . . . ,βj−1 −
βj ] ∈ R
(N−1)×(j−1) . Then, by (A1), (A3), and (15), we have
x˜[n]Td =
N

i=1
k¯i[n]β
T
i d
 ≥ min
i=1,...,N
{βTi d
}. (17)
where the equality holds if and only if n = lz (a pure pixel index)
for any z ∈ arg mini{βTi d
}. Following the proof in [5, Lemma 2]
and assuming that βTi d
, i = 1, . . . , N are distinct, one can show
that under (A1)-(A3), the new mean-removed TAC and its pure pixel
index can be estimated by
x˜[lz] ∈ {βj+1, ..., βN}, lz ∈ arg min
n=1,...,L
x˜[n]Td. (18)
The above procedure given by (16) and (18) will be repeated until
all the rest of pure pixel indices {lj}Nj=2 are found.
3.2. Estimation of TACs and Kinetic Parameters
Given the pure pixel indices {lˆp, lˆ2, lˆ3} = {lˆp, lˆf , lˆs} (for N = 3)
estimated above, by (6)-(8) and (A3), we have
aˆp = x[lˆp]/Kp[lˆp], (19)
x[lˆj ] = K
trans
j [lˆj ] aˆj = K
trans
j [lˆj ] D(kep,j) aˆp, j ∈ {2, 3}.
(20)
Substituting (19) into (20) yields
x[lˆj ] = K
trans
j [lˆj ]D(kep,j)x[lˆp]/Kp[lˆp], j ∈ {2, 3}, (21)
where x[lˆp], x[lˆ2], and x[lˆ3] are known. Hence, based on (A4), we
can estimate the kinetic parameters for the tissue TACs by the fol-
lowing non-negative least-squares problem
min
0≤Kp [lˆp]≤1,
0≤Ktransj [lˆj ]≤kep,j ,
j∈{2,3}

j∈{2,3}
‖x[lˆj ]−
K transj [lˆj ]
Kp[lˆp]
D(kep,j)x[lˆp]‖
2. (22)
The above nonconvex problem can be handled by using sequential
quadratic programming (SQP) [10] solvers. By (A4) (w.l.o.g), if
kˆep,2 > kˆep,3, then kˆep,f = kˆep,2, kˆep,s = kˆep,3, Kˆtransf [lˆf ] =
Kˆtrans2 [lˆ2], and Kˆ
trans
s [lˆs] = Kˆ
trans
3 [lˆ3]. Denoting a solution of (22)
by {Kˆ transf [lˆf ], kˆep,f , Kˆ
trans
s [lˆs], kˆep,s, Kˆp[lˆp]}, then the true AIF
aˆp, and the tissue TACs aˆf , aˆs can be estimated by
aˆp = x[lˆp]/Kˆp[lˆp], (by (19)) (23)
aˆj = D(kˆep,j)aˆp, j ∈ {f, s}. (by (7) and (8)) (24)
Finally, based on (6), we can estimate the kinetic parameters for
every pixel by solving
kˆ[n] = arg min
0≤Kp [n]≤1,
0≤Ktranss [n]≤K
trans
f [n]
‖x[n]− [aˆp aˆf aˆs]k[n]‖
2, (25)
for n = 1, ..., L. Problem (25) is convex and can be solved by stan-
dard convex optimization solvers, such as SeDuMi [11] and CVX
[12].
The entire procedure described above is the proposed TACE-Pro
algorithm that estimates the TACs (aˆp, aˆf , aˆs), flux rate constants
(kˆep,f , kˆep,s), and the maps of kinetic parameters (kˆ[n], ∀n).
.
Table 1. Mean±standard deviation of the estimated flux rate con-
stants (kˆep,f , kˆep,s) obtained by TACE-Pro algorithm over 100 inde-
pendent runs for different random tissue maps and different SNRs.
kˆep
Scenario 1: Scenario 2: Scenario 3:
SNR kep,f = 1.625 kep,f = 3.25 kep,f = 6.5
(dB) kep,s = 0.33 kep,s = 0.33 kep,s = 0.33
20
kˆep,f 1.96±0.06 3.80±0.14 9.07±1.18
kˆep,s 0.40±0.01 0.40±0.01 0.41±0.01
30
kˆep,f 1.73±0.07 3.46±0.05 6.88±0.19
kˆep,s 0.35±0.01 0.35±0.00 0.35±0.00
40
kˆep,f 1.66±0.01 3.31±0.07 6.62±0.07
kˆep,s 0.33±0.00 0.33±0.00 0.33±0.00
4. SIMULATIONS
Since exact ground truths are not available for real DCE-MR image
data, the performance of the proposed nBSS algorithm, TACE-Pro,
is first evaluated with simulated data. To the best of our knowledge,
the proposed TACE-Pro is the first nBSS algorithm specifically de-
signed for DCE-MR image analysis of prostate cancer, and hence
it is alone considered for the simulations. In the simulations, the
number of compartment N was set to 3. The AIF ap was gener-
ated by the population average model [13] with temporal resolution
Δt = 4 seconds for 8-min period (M = 120), and the fast and
slow TACs, af given by (7) and as given by (8), can also be gen-
erated by using kep,f ∈ {1.625, 3.25, 6.5} and kep,s = 0.33. We
then generated L = 5000 DCE-MR image pixels x[n] defined
in (6) by using the following parameters: fast flow maps gener-
ated with K transf ∈ {0.5, 1, 2}, slow flow maps generated with
K transs = 0.1, and plasma maps generated with Kp[n] = 0.05.
Scenario 1: (K transf [n], kep,f ) = (0.5, 1.625) is to simulate the
tissue of early-stage tumor; Scenario 2: (K transf [n], kep,f ) =
(1, 3.25) is to stimulate tissue of moderate tumor; Scenario 3:
(K transf [n], kep,f ) = (2, 6.5) is to simulate the tissue of active tumor.
Moreover, the observed pixel vectors x[n] were artificially added
with Gaussian white noise with zero mean and covariance matrix
σ2IM so as to satisfy the signal-to-noise ratio (SNR) specification
SNR   Ln=1 ‖x[n]‖
2/σ2ML where σ2 is the noise variance. Ta-
ble 1 shows the mean±standard deviation of the flux rate constants
(kˆep,f , kˆep,s) estimated by TACE-Pro algorithm over 100 indepen-
dent runs for different random tissue maps and for different SNRs.
In each run, while solving (22), five different sets of random initial-
izations were used and the estimates with the least fitting error were
considered as the solution for (22). It can be seen that in all the three
scenarios, as the SNR increases, the mean values of the estimates
get closer to the true values of the respective flux rate constants, and
the standard deviations approach zero.
5. EXPERIMENTAL RESULTS
In real data experiments, we demonstrate the efficacy of the proposed
method with T1-weighted DCE-MR images of a 72-year-old patient
who has been confirmed to have prostate cancer based on biopsies.
The DCE-MR image data set was acquired at Mackay Memorial
Hospital, Taipei, Taiwan using Philips Achieva 3-Tesla MRI scanner.
The acquired three-dimensional data set with 4 mm slice thickness,
0.45 mm pixel spacing, 10◦ field of view, and in-plane matrix size
256×256 were taken every 30 seconds for a total of 10 minutes after
the injection of gadolinium DTPA. Figure 2 shows the biopsy results
of the patient, where each percentage number denotes the proportion
of tissue in that area containing cancer tissue. For this real data set,
TACE-Pro algorithm has been applied while fixing N = 3. Figure
568
 1 
出席 IEEE WHISPERS-2012國際學術會議心得報告  
                                                             
計畫編號 NSC 99-2221-E-007-003-MY3  
計畫名稱 應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術  
出國人員姓名 
服務機關及職稱 
祁忠勇 
國立清華大學通訊工程研究所 教授  
會議時間地點 6/4/2012-6/7/2012, Shanghai, China  
會議名稱 2012 IEEE Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS-2012)  
發表論文題目 
#1. SPATIAL-SPECTRAL UNMIXING OF HYPERSPECTRAL DATA FOR 
DETECTION AND ANALYSIS OF ASTROPHYSICAL SOURCESWITH THE 
MUSE INSTRUMENT (Yu-Shiuan Shen, Tsung-Han Chan, Sebastien 
Bourguignon and Chong-Yung Chi)   
#2. OUTLIER-ROBUST DIMENSION REDUCTION AND ITS IMPACT ON 
HYPERSPECTRAL ENDMEMBER EXTRACTION (Hao-En Huang, Tsung-Han 
Chan, ArulMurugan Ambikapathi, Wing-Kin Ma, Chong-Yung Chi)  
 
一、參加會議經過 
 
筆者於 101年 6月 3日 (Sunday morning) 從桃園中正機場出發，於 6月 3日 (Sunday afternoon)
抵達上海, 進駐同濟戴斯酒店。The following is a summary of the major activities and events that I 
participated in.  
 
6/4 (Monday):   
(a) 上午完成報到手續 and met international friends and experts  
(b) (14:00-18:00) Tutorial 1: Spectral Unmixing of Hyperspectral Data  
Speaker: Professor Antonio J. Plaza, Department of Technology of Computers and 
Communications, University of Extremadura, Spain  
 
6/5 (Tuesday):  
(a) (09:00-10:00) Plenary 1: The Process of Hyperspectral Remote Sensing in China 
            Speaker: Professor Qingxi Tong, Peking University, China  
(b) (10:30-12:10) Session tue-o-1-a: Classification (1)  
(c) (13:30-15:10) Session tue-o-2-b: Anomaly and Target Detection  
(d) (15:40-17:40) Session tue-o-3-a: Unmixing (1)  
  
 
 3 
convex optimization to solving various problems in blind source separation and multiple 
input multiple output (MIMO) communications over the last 7 years. In this talk, we will 
give a comprehensive introduction to criterion design, problem formulation, and convex 
optimization for NON-NEGATIVE BLIND SOURCE SEPARATION, and ITS 
APPLICATIONS in biomedical image analysis and hyperspectral image analysis. Unlike 
most existing blind source separation algorithms, the algorithms presented in this talk are 
completely free of any statistical assumptions, and apart from having closed-form solutions 
for some special cases, simulations and real data experiments confirms that they yield better 
separation of the sources for all scenarios when compared with existing benchmark blind 
source separation algorithms. These successful endeavors further motivate us to apply 
convex optimization to some newly emerging applications, such as analytical chemistry, and 
many new interdisciplinary science and engineering applications.  
(b) 晚上8:05於上海浦東國際機場搭機返國，於晚上10點抵達桃園國際機場。 
 
 
攜回資料：WHISPERS-2012會議論文集之光碟一片。  
 
 
二、與會心得 
 
在本次會期中，筆者所發表 2 篇論文，在吸收新知及建立人際關係受益良多。中國大
陸過去三十年在太空及遙感研究領域及進展十分令人印象深刻，尤其武漢大學、中科
院及北京大學等，研究陣容均十分強大。然而，國內在此領域之研究能量、國際視野
及肯定均有待加強。國內有志於高科技之研發研究生已大不如前，而開放招生陸生之
辦法限制過多，對我們爭取優秀人才之競爭力極為不利，盼政府盡速修改，以利研究
發展水平之維持及提升。  
 
由於筆者於 6 月 8 日訪問上海交大，與張麗清教授就研究合作充分交換意見，並獲至
共識，將規劃邀請筆者明年至上海交大開授短期課程，並藉此啟動合作研究項目。  
 
致謝：感謝國科會補助旅費 for the participation of IEEE WHISPERS-2012。 
 
contribution xi[r, λ] in (2) can be further expressed as the following
convolution model:
xi[r, λ] =
∑
z
∑
µ
(
Pi∑
j=1
ci[j]ai[µ]δ[z − rji ]
)
Hz,µ[r, λ], ∀i, (3)
where
∑Pi
j=1 ci[j]ai[µ]δ[z− rji ] is the contribution of the ith galaxy
spectrum ai[µ], up to an unknown proportional factor ci[j] at jth
pixel in Ii, to the voxel [z, µ], and Hz,µ[r, λ] is the contribution of
the PSF of voxel [z, µ] to voxel [r, λ]. Since the PSF is translation
variant, it can not be written in the form H(r− z, λ− µ).
The problem of spatial-spectral unmixing is to estimate the
galaxy spectra a1[λ], . . . , aN [λ], ∀λ from the given MUSE data
cube y[r, λ], ∀r, λ, under the following general assumptions:
(C1) The sum of factors associated with all the pixels in each
galaxy is equal to unity, i.e.,
∑Pi
j=1 ci[j] = 1, i = 1, . . . , N.
(C2) The PSFs are spatially invariant for each galaxy Ii, i.e.,
Hz,µ[r, λ] = H
i
µ[r− z, λ], z ∈ Ii, i = 1, . . . , N.
(C3) The PSF is separable in terms of FSF Fz,µ[r] ∈ R+ and LSF
Lz,µ[λ] ∈ R+, i.e., Hz,µ[r, λ] = Fz,µ[r]Lz,µ[λ] ∈ R+.
(C4) The FSF changes slowly spectrally, i.e.,
Fz,µ[r] = Fz,λm [r], µ ∈ Λm,
where Λm = {λm + i∆λ}KFi=−KF for some KF and m =
1, . . . , Q, in which ∆λ is the spectral resolution and Q ,
dM/(2KF+1)e is the total number of spectral frames, where
M is the total number of spectral bands. The sum of the FSF
coefficients is equal to unity, i.e.,
∑
r
Fz,µ[r] = 1, ∀z, µ.
(C5) The LSF only spreads over few spectral samples, i.e.,{
Lz,µ[λ] > 0, if λ ∈ {µ+ k∆λ}KLk=−KL
Lz,µ[λ] = 0, otherwise
for some small KL, and the sum of the LSF coefficients is
equal to unity, i.e.,
∑
λ Lz,µ[λ] = 1, ∀z, µ.
Assumptions (C1), (C4) and (C5) are realistic for MUSE data [3].
Assumption (C2) is due to the fact that all the pixel locations in Ii
are basically close to each other. Assumption (C3) is widely used
in the MUSE studies [2,3]. From (C2)− (C4), the FSFs and LSFs
located at the voxels of the ith galaxy can be expressed as:
Fz,µ[r] = F
i
λm [r− z], z ∈ Ii, µ ∈ Λm, (4a)
Lz,µ[λ] = L
i
µ[λ], z ∈ Ii, (4b)
which will be utilized to derive the linear mixing models of the
MUSE data for different, disjoint spectral frames.
3. LINEAR MIXING MODEL FORMULATION
From (3) and under (C2), we can have
xi[r, λ] =
∑
µ
ai[µ]
Pi∑
j=1
ci[j]H
i
µ[r− rji , λ]
=
Q∑
m=1
(
Pi∑
j=1
ci[j]F
i
λm [r− rji ]
) ∑
µ∈Λm
ai[µ]L
i
µ[λ], (5)
where the second equality holds due to (4). Substituting (5) into (2)
yields
x[r, λ]=
Q∑
m=1
N∑
i=1
(
Pi∑
j=1
ci[j]F
i
λm [r− rji ]
) ∑
µ∈Λm
ai[µ]L
i
µ[λ]. (6)
Considering the mth, shorten, spectral frame Ψm , {λm +
i∆λ}KF−KLi=−KF+KL , by (C5), (6) can be written as
x[r, λ]=
N∑
i=1
(
Pi∑
j=1
ci[j]F
i
λm [r− rji ]
) ∑
µ∈Λm
ai[µ]L
i
µ[λ], λ∈ Ψm,
(7)
which only involves the information of the mth spectral frame for
m = 1, . . . , Q.
In order to have a vector-matrix representation of (7), let us per-
form the following change of variables:
• The noise-free data associated with the mth frame at pixel n:
xm[n] , [ x[r, λ] ]λ∈Ψm ∈ R2KF−2KL+1+ ,
where [ x[r, λ] ]λ∈Ψm denotes a column vector comprising x[r, λ]
for all λ in the set Ψm, and n = (r1 − 1)Z + r2, in which ri is
the ith entry of r and Z is the width of MUSE image.
• The ith galaxy spectrum in the mth spectral frame:
a
m
i , [ ai[µ] ]µ∈Λm ∈ R2KF+1+ .
• The contribution of ith galaxy (through the FSF) to the mth spec-
tral frame at pixel n, or called the abundance fraction:
smi [n] ,
Pi∑
j=1
ci[j]F
i
λm [r− rji ] ∈ R+.
• The matrix form of the LSF of ith galaxy associated with the mth
spectral frame Hmi ∈ R(2KF−2KL+1)×(2KF+1)+ , whose (p, q)th
element Hmi (p, q) is
Liλm−(KF−KL)∆λ+(q−1)∆λ[λm−(KF−KL)∆λ+(p−1)∆λ],
which is nonzero over the following set (by (C5))
{(p, q) | 1 ≤ p ≤ 2KF − 2KL + 1, p ≤ q ≤ p+ 2KL}.
With xm[n], ami , smi [n], Hmi defined above, and by (1) and (7),
the noisy MUSE pixel vector associated with the mth spectral frame
ym[n] , [ y[r, λ] ]λ∈Ψm for m ∈ {1, 2, ..., Q} can be expressed as
ym[n] =
N∑
i=1
smi [n]H
m
i a
m
i +wm[n], n = 1, ..., L, (8)
where wm[n] , [ w[r, λ] ]λ∈Ψm ∈ R2KF−2KmL+1 is a zero-mean
Gaussian noise vector with covariance matrixΣm[n] = σ[n]Cm, in
whichCm is a known diagonal matrix, σ[n] is a known constant [1],
and L is the total number of observed pixel vectors.
Now, the problem to be solved for each spectral frame becomes a
blind source separation problem for the estimation of galaxy spectra
am1 , . . . ,a
m
N , with the given noisy pixel vectors ym[1], . . . ,ym[L]
given by (8) , LSF matrices {Hmi }Ni=1, and the number of galaxies
N . The full spectra a1, . . . ,aN can finally be obtained from the
spectra estimates of all the Q frames. Based on (C1) − (C4), we
have the following two facts:
(F1) Abundance fractions are non-negative, i.e., smi [n] ≥
0, ∀ i, n,m.
(F2) Sum of all the abundance fractions of ith galaxy is equal to
unity for each spectral band, i.e.,
∑L
n=1 s
m
i [n] = 1, ∀ i,m.
Table 1. The pseudo-codes of the proposed SSUm and SSU algorithms.
SSUm Algorithm SSU Algorithm
Given {ym[n]}Ln=1, N , {Σm[n]}Ln=1, {Hmi }Ni=1 and Dm.
Step 1. obtain ym[n], ∀n by (9), y˜m[n], ∀n by (10) and y¯m[n], ∀n by
(11). Then, obtain {ˆ`m1 , . . . , ˆ`mN} by (13).
Step 2. obtain µˆmi , ∀i by (17) and then obtain {κˆmi [n]}Ni=1, ∀n by (20).
Step 3. obtain aˆmi , ∀i by (22).
Step 4. obtain {sˆmi [n]}Ni=1, ∀n by (23) and then obtain sˆmi , ∀i by (24).
Step 5. output {aˆm1 , . . . , aˆmN} as the estimated galaxy spectra and
{sˆm1 , . . . , sˆmN} as the estimated abundance maps.
Given {ym[1], . . . ,ym[L]}Qm=1, N , and initial m = 1.
Step 1. obtain {(aˆm1 , sˆm1 ), . . . , (aˆmN , sˆmN )} by the proposed SSUm algo-
rithm.
Step 2. obtain Pˆm by (25).
Step 3. obtain Bˆm by (26).
Step 4. if m < Q, then set m := m+ 1, and go to Step 1,
else output the the ith column of Aˆ = [BˆT1 , BˆT2 , . . . , BˆTQ]T as
the estimated spectrum of the ith galaxy for all i.
Substituting (21) into (18) and (19), the estimated galaxy spectra and
abundance fractions in the mth spectral frame can be recovered by
aˆ
m
i = Dmµˆ
m
i
L∑
n=1
κˆmi [n], ∀i. (22)
sˆmi [n] = κˆ
m
i [n]/
L∑
n=1
κˆmi [n], ∀i, n. (23)
The estimates by (23) are collected as column vectors
sˆ
m
i = [sˆ
m
i [1], . . . , sˆ
m
i [L]]
T , ∀i. (24)
The above procedure presented in subsections 4.1, 4.2, 4.3 for
estimating the galaxy spectra {aˆm1 , . . . , aˆmN} and abundance maps
{sˆm1 , . . . , sˆmN} associated with the mth spectral frame is termed as
SSUm and summarized in Table 1 (left part).
4.4. Whole Galaxy Spectra Combining
So far, there is still an ambiguity yet to be solved— order mismatch
of the estimated spectra and abundance maps from frame to frame.
It can be resolved by permuting {(aˆmi , sˆmi ), i = 1, . . . , N} so as
to have the best match with that of the first frame. The permutation
matrix can be obtained by solving the following problem [6]:
Pˆm = arg min
Pm∈Φ
∥∥∥Sˆ1 − SˆmPm∥∥∥
F
, (25)
where Sˆm = [sˆm1 , . . . , sˆmN ] and Φ is the set of N ×N permutation
matrices. Then, we can obtain the column-permutation fixed Aˆm as
Bˆm = AˆmPˆm ∈ R(2KF+1)×N , (26)
where Aˆm = [aˆm1 , . . . , aˆmN ].
Repeating the above procedure for all the spectral frames m =
1, ..., Q, and concatenating all the obtained Q galaxy spectra esti-
mated by (26) provides
Aˆ = [BˆT1 , Bˆ
T
2 , . . . , Bˆ
T
Q]
T ∈ RM×N , (27)
where the ith column of Aˆ is the final spectrum estimate of the ith
galaxy. We summarize the SSU algorithm in Table 1 (right part).
5. SIMULATION AND CONCLUSION
In this section, we use synthetic MUSE data to test the performance
of the proposed SSU algorithm. The results for the estimated galaxy
spectra and abundance maps are shown in Figures 2-4 in the sup-
plementary document at http://www.ee.nthu.edu.tw/cychi/
SSD_SuppDoc.pdf, due to the space limit. We simulate a 5 × 5
spatial dimension scene, composed of three galaxies N = 3: One
corresponds to extended source containing two pixels with factors
c1[j] = 0.5, j = 1, 2, while the other two are close sources each
of which containing 1 pixel with factors ci[1] = 1, i = 2, 3, as
shown in Figure 2(a). The associated three galaxy spectra were
generated by linear, random superposition of the synthesized dic-
tionary [1]. The synthetic noise-free data were generated following
(6) for Q = 2, where FSFs all are 3× 3 circular Gaussian with dif-
ferent variances, and LSFs are of 2KL+1 = 11-point Gaussian with
different variances, shown in Figure 2(b). Then we added zero mean
Gaussian noise vectors with the same covariance as in [2, Fig. 1] for
each pixel to obtain the observed noisy data shown in Figure 2(c).
Two performance indices were used in the simulations. The root-
mean-square (rms) spectral angle distance between simulated galaxy
spectra and their estimates, denoted as φ (in degrees), was used as the
error performance measure [4]. The computation time T (in secs) of
the algorithm (implemented in Mathworks Matlab R2008a) running
in a desktop computer equipped with Core i7-930 CPU 2.80 GHz,
12GB memory was used as the computational complexity measure.
The proposed SSU algorithm was applied to the noise-free and
noisy data. The rms spectral angles and computation time of the
SSU algorithm for the noise-free data are φ = 0.09 (degrees)
and T = 153.16 (secs), respectively, and those for noisy data are
φ = 14.07 (degrees) and T = 173.28 (secs), respectively. The
corresponding results for noise-free and noisy data are demonstrated
in Figure 3 and Figure 4, respectively. One can see that the pro-
posed SSU algorithm performs well for both cases. Especially, for
the noiseless case, almost perfect unmixing is achieved in spite of
some small error (i.e., φ ≈ 0) because the `1-norm minimization is
an approximation for sparse representation of the galaxy spectra [7].
In conclusion, we have presented an SSU algorithm to process
MUSE data for estimation of galaxy spectra. The simulation results
have shown the superior efficacy of the proposed SSU algorithm.
6. REFERENCES
[1] S. Bourguignon, D. Mary and E. Slezak, “Restoration of astrophsical
spectra with sparsity constraints: models and algorithms,” IEEE Jour-
nal of Selected Topics in Signal Processing, vol. 5, no. 5, pp. 1002-
1013, Sept. 2011.
[2] S. Bourguignon, H. Carfantan, E. Slezak and D. Mary, “Sparsity-based
spatial-spectral restoration of MUSE astrophysical hyperspectral data
cubes,” in Proc. IEEE WHISPERS, Lisbon, Portugal, June 6-9, 2011.
[3] I. Meganem, Y. Deville, S. Hosseini, H. Carfantan and M. S. Karoui,
“Extraction of stellar spectra from dense fields in hyperspectral MUSE
data cubes using non-negative matrix factorization,” in Proc. IEEE
WHISPERS, Lisbon, Portugal, June 6-9, 2011.
[4] T.-H. Chan, W.-K. Ma, A. Ambikapathi and C.-Y. Chi, “A simplex
volume maximization framework for hyperspectral endmember extrac-
tion,” IEEE Trans. Geoscience and Remote Sensing, vol. 49, no. 11, pp.
4177-4193, Nov. 2011.
[5] M. Grant and S. Boyd. CVX: Matlab software for disciplined convex
programming, version 1.21. http://cvxr.com/cvx, Oct. 2010.
[6] P. Tichavsky´ and Z. Koldovsky´, “Optimal pairing of signal components
separated by blind techniques,” IEEE Signal Processing Letters, vol.
11, no. 2, pp. 119-122, Feb. 2004.
[7] R. Baraniuk, “Compressive sensing,” IEEE Signal Processing Maga-
zine, vol. 24, no. 4, pp. 118-121, July 2007.
pears at Z pixels, i.e.,
z[n] 6= 0, n ∈ I , {`1, ..., `Z},
z[n] = 0, n ∈ L \ I,
where L = {1, 2, ..., L} and I is the set of outlier pixel indices.
Outlier-robust dimension reduction is to find an affine set repre-
sentation for the corruption-free data x[n] from the corrupted data
y[n] with prior knowledge of N . Some general assumptions for
analysis of hyperspectral images are as follows [7]: (A1) si[n] ≥ 0
for all i and n; (A2)∑N
i=1 si[n] = 1 for all n; (A3) min{L,M} ≥
N and A is of full column rank.
As has been shown in [6], the affine hull of contamination-free
pixels x[n] is identical to that of endmembers a1, . . . ,aN :
A(C,d) , aff{x[1], ...,x[L]} = aff{a1, . . . ,aN} (2)
= {Cα+ d | α ∈ RN−1},
for some (C,d) ∈ RM×(N−1) × RM , α ∈ RN−1. The endmem-
ber affine set parameter (C,d) has a closed-form solution for the
case when x[1], . . . ,x[L] are available. However, what we have in
practice is the noisy, outlier-contaminated, observed pixel vectors
{y[n]}Ln=1, and therefore obtaining an accurate estimate of (C,d)
from {y[n]}Ln=1 is a challenging problem.
3. ROBUST AFFINE SET FITTING ALGORITHM
In this section, we present the RASF algorithm for estimation of
(C,d) from {y[n]}Ln=1, with the prior knowledge of the number of
outliers Z. Consider the RASF problem as follows:
min
num{z1,...,zL}≤Z
{
min
xn∈A(C,d),∀n
C
T
C=IN−1
L∑
n=1
‖y[n] − xn − zn‖22,
}
(3)
where num{z1, ..., zL} denotes the number of nonzero vectors in
{z1, ..., zL}. The objective of (3) is to seek an (N−1)−dimensional
affine set A(C,d) with the minimum projection error with respect
to (w.r.t.) y[n] and with minimum effect of outliers z[n]. It can be
readily noted that problem (3) is nonconvex, and hence we resort to
alternating optimization to handle problem (3) as follows:
(1) Problem (3) w.r.t. variables {xn}Ln=1, C, and d:
min
xn∈A(C,d), C
T
C=IN−1
n=1,...,L
L∑
n=1
‖(y[n]− zˆn)− xn‖22, (4)
for any given {zˆ1, ..., zˆL} that satisfies num{zˆ1, ..., zˆL} ≤ Z.
Following the proof in [6, Proposition 1], problem (4) can be shown
to have an analytical solution given by
dˆ =
1
L
L∑
n=1
(y[n]− zˆn), (5)
Cˆ = [q1(UU
T ),q2(UU
T ), ...,qN−1(UU
T )], (6)
xˆn = CˆCˆ
T (y[n]− zˆn − dˆ) + dˆ, n = 1, ..., L, (7)
where U,[(y[1]− zˆ1)− dˆ, ..., (y[L]− zˆL)− dˆ], and qi(UUT )
denotes the unit-norm eigenvector associated with the ith principal
eigenvalue of UUT .
(2) Problem (3) w.r.t. variables {zn}Ln=1:
min
num{z1,...,zL}≤Z
L∑
n=1
‖(y[n]− xˆn)− zn‖22, (8)
for any given {xˆn}Ln=1 ⊂ A(Cˆ, dˆ). It is trivial to see that the
solution of the above problem is
zˆn =
{
y[n]− xˆn, n ∈ {ˆ`1, ..., ˆ`Z}
0, n ∈ L \ {ˆ`1, ..., ˆ`Z} (9)
where ˆ`i is the index of the ith largest value in (‖y[1] −
xˆ1‖, ..., ‖y[L]− xˆL‖).
We generate a solution of problem (3) by handling the above
two partial minimization problems alternatively until some stopping
criterion is met. The pseudo-codes of the RASF algorithm for (3)
are given in Table 1 (left part).
4. ESTIMATION OF THE NUMBER OF OUTLIERS USING
THE RASF ALGORITHM
This section proposes the RASF-NP algorithm that equips the RASF
algorithm with the capability of estimating the number of outliers
by using Neyman-Pearson hypothesis testing. Let us consider the
RASF problem (3) with Z being replaced by an initial guess K.
Suppose that K ≥ Z and I ⊂ {ˆ`1, ..., ˆ`K}. When K = Z, the cor-
responding RASF solution {xˆn, zˆn}Ln=1 is exactly a local optimal
approximation of {x[n], z[n]}Ln=1 . Hence, it can be easily inferred
from (9) that when K > Z, the rest of K − Z estimated outliers
will be around zero as z[n] = 0 for pixel indices other than those in
I. Then, by (1) the fitting error vector of the RASF problem can be
expressed as
e[n] , y[n]− xˆn − zˆn = µn +w[n], n = 1, ..., L, (10)
where µn,x[n] + z[n] − xˆn − zˆn. There are two observations on
e[n] given by (10) as follows:
• If K ≥ Z, e[n] can be approximated to a zero-mean Gaus-
sian random vector for all n 6= ˆ`i, i = 1, . . . ,K; i.e., e[n] ∼
N (0, σ2IM ), ∀n ∈ L\{ˆ`1, ..., ˆ`K}.
• If K < Z, there exists at least one e[n] ∼ N (µn, σ2IM ), where
n ∈ L\{ˆ`1, ..., ˆ`K}.
Define
rn = e[n]
T (σ2IM )
−1
e[n], n = 1, ..., L, (11)
where the noise power σ2 is assumed to be known, and in practice, it
can be estimated by multiple regression method [8]. When K ≥ Z,
it is easy to see that rn,∀n ∈ L\{ˆ`1, ..., ˆ`K} can be approximated
as central Chi-square random variables χ2(M), otherwise there ex-
ists at least one rn for n ∈ L\{ˆ`1, ..., ˆ`K} being non-central Chi-
square distributed Nχ2(M,µn), where M denotes the degrees of
freedom. Hence, we consider the following binary hypothesis test-
ing problem:
H0 (K ≥ Z) : rn ∼ χ2(M), ∀n ∈ L\{ˆ`1, ..., ˆ`K} (12a)
H1 (K < Z) : ∃ rn ∼ Nχ2(M,µn), n ∈ L\{ˆ`1, . . . , ˆ`K}.
(12b)
Since µn is unknown in Nχ2(M,µn), we use Neyman-Pearson
classifier rule for the above hypothesis testing problem:
DecideH0 if rn < η, ∀n ∈ L\{ˆ`1, ..., ˆ`K}, (13a)
DecideH1 if ∃n ∈ L\{ˆ`1, . . . , ˆ`K} such that rn > η, (13b)
15 20 25 30 35 40 45 50
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
SNR(dB)
 
 
ASF   (SOR=15 dB)
RASF (SOR=15 dB, K=2%L)
RASF (SOR=15 dB, K=5%L)
RASF (SOR=15 dB, K=8%L)
ASF   (SOR=25 dB)
RASF (SOR=25 dB, K=2%L)
RASF (SOR=25 dB, K=5%L)
RASF (SOR=25 dB, K=8%L)
∞
av
er
ag
e
D
a
ff
Fig. 1. Performance comparison of average Daff of ASF and RASF
with different preset values of K for Z = 5%L, SOR= 15, 25 dB,
and various SNR values.
The second simulation evaluates the estimation accuracy and
computational efficiency of the proposed RASF-NP algorithm in
comparison with the existing RSAD algorithm [5]. Table 2 shows
the average number of outliers estimated by RASF-NP and RSAD
algorithms with PFA = 10−4, 10−5, 10−6, and the average compu-
tation time T for Z = 5%L, SNR=15, 25 dB and SOR=10, 20 dB.
One can see that the estimated number of outliers Zˆ obtained by the
RASF-NP and RASD algorithms are quite comparable, but RASF-
NP spends much less computation time than RSAD in more than one
order. The reason is that RSAD repeatedly, randomly selects pixels
as background and so will cost lots of computational time. More-
over, the two algorithms all perform well for SOR<SNR, but for
SOR>SNR, both of them do not perform well since most outliers
are treated as noise. We should emphasize again that unlike RSAD
only detects outliers, the proposed RASF-NP not only detects out-
liers, but also provides the corruption-free affine set for dimension
reduction.
The third simulation investigates the impact of the proposed
RASF-NP to some existing EEAs [1, 11]. Table 3 tabulates the av-
erage φ of VCA, SGA, N-FINDR, AVMAX, and SVMAX, with
dimension reduction using RASF-NP algorithm (PFA = 10−6)
and ASF, for Z = 5%L, SNR= 15 dB and various SOR=
5, 7, 11, 14, 17 dB. It can be seen that the performances of all the
EEAs with ASF used improve as the SOR increases, and the RASF-
NP algorithm substantially boosts the performances of all the EEAs
in the presence of outliers. Besides, all the EEAs with RASF-NP
used perform equally well for all SORs, implying that the RASF-NP
can be in conjunction with any EEAs to provide better endmember
estimates than the ASF.
In conclusion, we have presented the RASF algorithm for joint
dimension reduction and outlier removal, and the RASF-NP algo-
rithm to estimate the number of outliers, apart from robust dimen-
sion reduction and outlier detection. The proposed RASF-NP out-
performs RSAD in terms of computational load by more than one
order, and any EEAs in conjunction with the former will provide
better endmember estimates, especially for lower SORs.
6. REFERENCES
[1] J. M. Bioucas-Dias and A. Plaza, “Hyperspectral unmixing: Geomet-
rical, statistical, and sparse regression-based approaches,” in Proc.
of SPIE - Image and Signal Processing for Remote Sensing XVI, vol.
7830, Toulouse, France, Sept. 20, 2010, pp. 783 00A.
[2] T. Han, D. G. Goodenough, A. Dyk, and J. Love, “Detection and
correction of abnormal pixels in hyperion images,” in Proc. IEEE Int.
Geosci. and Remote Sens. Symp., vol. 3, June 25-26, 2002, pp. 1327–
1330.
Table 2. Performance comparison of average number of the outliers
Zˆ (%L) estimated by the RASF-NP algorithm and the RSAD algo-
rithm, and T (seconds) for true number of outliers Z = 5%L, and
various SNRs and SORs.
SNR (dB)
SOR (dB) PFA 15 25
RASF-NP RSAD RASF-NP RSAD
10−4
Zˆ 5.00 5.00 5.00 5.00
T 2.56 53.37 1.39 45.61
10
10−5
Zˆ 5.00 5.00 5.00 5.00
T 2.56 50.58 1.39 40.40
10−6
Zˆ 5.00 4.99 5.00 5.00
T 2.56 53.87 1.39 38.44
10−4
Zˆ 1.00 0.02 5.00 5.00
T 0.93 50.44 0.75 52.91
20
10−5
Zˆ 1.00 0.00 5.00 4.99
T 0.93 45.25 0.75 53.60
10−6
Zˆ 1.00 0.00 5.00 4.99
T 0.93 40.74 0.75 54.27
Table 3. Performance comparison of average φ (degrees) over some
existing EEAs with RASF-NP (PFA = 10−6) used and ASF used
for Z = 5%L, SNR= 15 dB, and various SORs.
EEAs Dimension SOR (dB)Reduction 5 8 11 14 17
VCA RASF-NP 5.43 3.37 3.44 3.42 3.43ASF 17.31 10.46 5.66 4.18 3.74
SGA RASF-NP 5.01 3.09 3.09 3.09 3.13ASF 15.39 9.58 5.11 3.55 3.22
N-FINDR RASF-NP 5.14 3.22 3.21 3.22 3.24ASF 17.33 10.15 5.05 3.57 3.30
AVMAX RASF-NP 5.18 3.21 3.20 3.23 3.25ASF 17.41 10.51 5.40 3.78 3.36
SVMAX RASF-NP 5.08 3.07 3.07 3.07 3.11ASF 17.46 9.59 5.06 3.46 3.22
[3] D. Stein, S. Beaven, L. Hoff, E. Winter, A. Schaum, and A. Stocker,
“Anomaly detection from hyperspectral imagery,” IEEE Signal Pro-
cess. Mag., vol. 19, no. 1, pp. 58–69, Jan. 2002.
[4] I. S. Reed and X. Yu, “Adaptive multiple-band CFAR detection of
an optical pattern with unknown spectral distribution,” IEEE Trans.
Acoust., Speech, Signal Process., vol. 38, no. 10, pp. 1760–1770, 1990.
[5] Bo Du and Liangpei Zhang, “Random-selection-based anomaly detec-
tor for hyperspectral imagery,” IEEE Trans. Geoscience and Remote
Sensing, vol. 49, pp. 1578–1589, May, 2011.
[6] T.-H. Chan, C.-Y. Chi, Y.-M. Huang, and W.-K. Ma, “A convex anal-
ysis based minimum-volume enclosing simplex algorithm for hyper-
spectral unmixing,” IEEE Trans. Signal Processing, vol. 57, no. 11,
pp. 4418–4432, Nov. 2009.
[7] N. Keshava and J. Mustard, “Spectral unmixing,” IEEE Signal Pro-
cess. Mag., vol. 19, no. 1, pp. 44–57, Jan. 2002.
[8] J. M. Bioucas-Dias and J. M. P. Nascimento, “Hyperspectral subspace
identification,” IEEE Trans. Geosci. Remote Sens., vol. 46, no. 8, pp.
2435V2445, Aug. 2008.
[9] G. Arfken and H. Weber. Mathematical Methods for Physicists. Har-
court Academic Press, 2000.
[10] L. C. Ludeman. Random Processes Filtering, Estimation, and Detec-
tion. Wiley-Interscience Publication, 2003.
[11] T.-H. Chan, W.-K. Ma, A. Ambikapathi, and C.-Y. Chi, “A simplex
volume maximization framework for hyperspectral endmember extrac-
tion,” IEEE Trans. Geoscience and Remote Sensing - Special Issue on
Spectral Unmixing of Remotely Sensed Data, vol. 49, no. 11, pp. 4177
- 4193, Nov. 2011.
[12] A. Edelman, T. A. Arias, and S. T. Smith, “The geometry of algorithms
with orthogonality constraints,” SIAM Journal on Matrix Analysis and
Applications, vol. 20, no. 2, pp. 303–353, 1999.
 2 
as an Associate Editor for many years handling the paper review process of more than 150 
TSP papers over the last decade;  
(c) 15:30-17:30 Attended SPCOM-P4.12 (Resource Allocation I) where we presented our 
Paper #1 (Outage constrained weighted sum rate maximization for MISO interference 
channel by pricing-based optimization). This paper is mainly presented by my Ph.D. student 
Wei-Chiang Li. His presentation drew the attention of a lot of the audience, indicating the 
good-quality of the paper and successful presentation due to his good preparation 
beforehand. A photo of Wei-Chiang is attached below.  
 
(d) 18:30-20:00: Attended Senor Array and Multichannel (SAM) TC Dinner Meeting. Since I 
am a new elected member, I introduced myself and my research areas at the beginning of the 
meeting. The SAM TC Chair assigned me as the chair of a COM-subcommittee, to select 
paper candidates for the nominations of paper awards (including Best paper Award, Young 
Author Best Paper Award, etc.) in communications belonging to SAM domain.  
 
5/29 (Wednesday): Main activities are as follows:  
(a) 10:30-12:30: Served as the Session Chair of SAM-L2 (Compressive Sensing and Sparse 
Modelling). In this oral session, there were 6 excellent papers presented by the respective 
authors. There are also many interactions (questions and answers) between the presenters 
and the audience (around 50);  
(b) 12:30-14:00: Attended IEEE SP Society, Signal Processing for Communications & 
Networking TC Meeting (SPCOM), mainly discussing the award nomination and the 
 4 
二、與會心得 
 
在本次會期中，筆者所發表 2 篇論文受到許多國際專家學者的關注，在吸收新知及建
立人際關係受益良多。來自中國大陸的論文及參與者比往年增加許多，也顯示中國大
陸的快速發展及增進其國際影響力，由於中國優秀人才之展現已為各國爭取之對象。
國內有志於高科技之研發研究生已大不如前，而開放招生陸生之辦法限制過多，對我
們爭取優秀人才之競爭力極為不利，盼政府盡速修改，以利研究發展水平之維持及提
升。 International collaboration has been an effective way to keep our research quality and 
recognition in the international communities. A French graduate student and a Chinese student 
(Peking University) will join my group for the Summer intern in early July.  
 
During ICASSP-2013, I also met a young researcher, Dr. Ya-Feng Liu, and was invited to give a talk 
at Chinese Academy of Sciences, Beijing, July 23. I accepted this invitation because I am going to 
give an invited talk at the special session, “Trends in Signal Processing”, IEEE 2013 ChinaSIP, 
Beijing, July 6-10, followed by offering an invited 2-week short course, ``Convex Optimization from 
Fundamentals to Applications” at Beijing Jiaotong University, 7/12-7/25.  
 
致謝：感謝國科會補助旅費 for the participation of ICASSP-2013。 
 
where ni ∼ CN (0, σ2i ) is the additive noise at receiver i with vari-
ance σ2i > 0. Assume that each receiver i decodes the informa-
tion signal si by single user detection, i.e., treating the cross-link
interference as noise. Then, the instantaneous achievable rate (in
nats/sec/Hz) of the ith transmitter-receiver pair is given by
ri
(
{hki}
K
k=1, {wk}
K
k=1
)
= log
(
1 +
∣∣hHiiwi∣∣2∑
k 6=i |h
H
kiwk|
2
+ σ2i
)
.
In this paper, we consider a scenario where the transmitters have
knowledge of CDI only, i.e., the channel covariance matrices Qik,
i, k = 1, . . . ,K. Under such circumstances, given a transmission
rate Ri for the ith transmitter-receiver pair, receiver i may suffer
from the rate outage, i.e., ri({hki}Kk=1, {wk}Kk=1) < Ri. Our
goal is to provide quality of service guaranteed within a tolerable
outage probability for the receivers, while maximizing the system
throughput (i.e., the sum rate) at the same time. Specifically, given
i ∈ (0, 1) as the maximum tolerable outage probability for each
receiver i, we consider the following beamforming design problem
[1, 11]
max
wi∈C
Nt ,Ri≥0,
i=1,...,K
K∑
i=1
αiRi (2a)
s.t. Prob
{
ri({hki}
K
k=1, {wk}
K
k=1) < Ri
}
≤ i, (2b)
‖wi‖
2
2 ≤ Pi, i = 1, . . . ,K, (2c)
where α1, . . . , αK > 0 are priority weights, and P1, . . . , PK >
0 are the power constraints. Notice that, in (2b), the rate outage
probabilities are constrained no higher than i, for i = 1, . . . ,K.
3. THE PROBLEM NATURE
It has been shown in [1] that each of the outage constraints in (2b)
has an equivalent closed-form expression, given by
ρie
(2Ri−1)σ2
i
w
H
i
Qiiwi
∏
k 6=i
(
1+
(2Ri − 1)wHk Qkiwk
wHi Qiiwi
)
≤ 1, (3)
where ρi , 1 − i, i = 1, . . . ,K. As one can see, the outage
constraint in (3) has a non-convex, complicated structure, and thus
solving (2) seems to be a challenging task. Therefore, a fundamental
question is whether the outage constrained problem (2) is truly a dif-
ficult problem in terms of computational complexity. The following
theorem gives the answer.
Theorem 1 Problem (2) is NP-hard in general.
In fact, one can show that problem (2) is NP-hard even whenNt = 1,
i.e., when only the transmit powers (without beamforming direction)
are optimized. The proof is to construct a polynomial time transfor-
mation from the Max-Cut problem, which is known to be NP-hard
[12], to problem (2), thereby implying the NP-hardness of the latter
problem. Due to space limit, we leave the detailed proof to our fu-
ture publication. It is worthwhile to note here that Theorem 1 can
be regarded as an outage constrained counterpart of the complex-
ity analysis result in [5, 13], where it was shown that the weighted
sum rate maximization (WSRM) problem with instantaneous chan-
nel state information (CSI) is NP-hard.
Theorem 1 implies that it is unlikely to globally solve prob-
lem (2) in a polynomial-time complexity. Therefore, one may have
to consider approximation methods, in order to deal with instances
wherein a large number of transmitter-receiver pairs exist. In the
next section, we propose a pricing-based sequential (block coordi-
nate) optimization method for efficiently handling the considered
problem (2).
4. PROPOSED PRICING-BASED ALGORITHM
4.1. Equivalent Formulation
Due to the complex constraint structure in (3), it is not easy to apply
general approximation methods to problem (2) (with (2b) replaced
by (3)) in its current form. In view of this, we first present in this
subsection an alternative formulation for problem (2) which, as one
will see, can reveal useful insights for efficient approximation.
To this end, let us define
Φi(x|{wk}k 6=i) , ρie
σ2i x
∏
k 6=i
(1 + (wHk Qkiwk) · x). (4)
Then, (3) can be written as Φi((2Ri − 1)/wHi Qiiwi|{wk}k 6=i) ≤
1, i = 1, . . . , K. Furthermore, because both
∑K
i=1 αiRi and Φi are
strictly increasing in (R1, . . . , RK), it must be true that (3) holds
with equality for problem (2), i.e.,
Φi
(
2Ri − 1
wHi Qiiwi
∣∣∣∣ {wk}k 6=i
)
= 1, i = 1, . . . ,K, (5)
On the other hand, each Φi(x|{wk}k 6=i) is strictly increasing in x;
therefore, there exists a unique positive value ξi({wk}k 6=i) such that
Φi(ξi({wk}k 6=i)|{wk}k 6=i) = 1. As a result, constraint (5) holds if
and only if
2Ri−1
wHi Qiiwi
=ξi({wk}k 6=i), i = 1, . . . ,K. (6)
By (6), problem (2) can be concisely expressed as
max
wi∈C
Nt
i=1,...,K
K∑
i=1
αi log(1 + ξi({wk}k 6=i)w
H
i Qiiwi) (7a)
s.t. ‖wi‖2 ≤ Pi, i = 1, . . . ,K, (7b)
There are two interesting observations about (7). Firstly, one can
observe that each ξi({wk}k 6=i), though being implicit, characterizes
the impact of cross-link interference plus noise on receiver i, for
i = 1, . . . ,K. Secondly, by comparing (7) with its instantaneous-
CSI counterpart in [5, Eqn. (3)], an intriguing analogy between
the two problems in mathematical formulation is observed. This
motivates the use of a pricing-based sequential optimization (PSO)
method, which was used in [10, 14] for the instantaneous-CSI case
[5, Eqn. (3)], for handling the outage constrained problem (2) in the
subsequent two subsections.
4.2. Pricing-based Sequential Optimization Algorithm
The proposed PSO algorithm for problem (2) is an iterative algo-
rithm which optimizes the beamforming vectors w1, . . . ,wK in a
round-robin fashion. Specifically, in an iteration for optimizing wi,
given a set of w¯1, . . . , w¯K (that are feasible to (7b)), we seek to
update w¯i by solving the following problem
max
wi
log(1 + ξi({w¯k}k 6=i)w
H
i Qiiwi)−
∑
k 6=i
piikw
H
i Qikwi
s.t. ‖wi‖2≤Pi, (8)
Proposition 2 Let µ?i ≥ 0 denote the optimal dual variable asso-
ciated with the power constraint in (15), and let Ri = µ?i INt +∑
k 6=i piikQik, where INt is an Nt×Nt identity matrix. Then, there
exists a principal eigenvector of R−1/2i QiiR−1/2i , denoted by ν?i ,
such thatW?i = w?i (w?i )H is optimal to problem (15), where
w
?
i =
√
p?iR
−1/2
i ν
?
i (optimal to problem (8))
p?i = max
(
1−
1
λ?i ξi({I¯ki}k 6=i)
, 0
)
,
and λ?i is the maximum eigenvalue ofR−1/2i QiiR−1/2i .
The proof of Proposition 2 is omitted here due to space limit.
It can be shown that µ?i can be computed by simple bisection, and
thus w?i can be obtained efficiently. More specifically, since the
major computation load of computing w?i lies in matrix inversion
and eigenvalue decomposition each having a complexity order of
O(N3t ), the complexity order of solving (8) is roughly given by
O(N3t log(1/ε1)), where ε1 > 0 is the solution accuracy of the
bisection search for µ?i . As a result, the overall complexity order
of Algorithm 1 is κ1KO(N3t log(1/ε1)), where κ1 denotes the to-
tal number of round-robin iterations (steps 3 to 8 in Algorithm 1).
Note that, for the DSCA algorithm in [1], the subproblem for each
transmitter is implemented by interior-point methods. Hence, the
DSCA algorithm has an overall complexity order of κ2KO((N6.5t +
K3.5) log((Nt + K)/ε2)) where κ2 is the total number of round-
robin iterations and ε2 > 0 is the solution accuracy of interior-point
methods [17]. One can see that the complexity order of PSO algo-
rithm is lower than that of the DSCA algorithm. Thus, it is expected
that the PSO algorithm is computationally more efficient than the
DSCA algorithm, which will be verified by the simulation results.
5. SIMULATION RESULTS AND DISCUSSIONS
For simplicity, it is set that σ21 = · · · = σ2K , σ2 and P1 = · · · =
PK = 1. The tolerable outage probability is set to 10%, i.e., 1 =
· · · = K = 0.1. The channel covariance matrices {Qik}Ki,k=1 are
randomly generated with full rank, and the maximal eigenvalues of
{Qik}
K
i,k=1 are normalized to λmax(Qii) = 1 and λmax(Qik) = η
for all k 6= i; therefore, 0 ≤ η ≤ 1 reflects the strength of cross-
link channels. Algorithm 1 stops when the difference between the
weighted sum rates U({I¯j,`}Kj,`=1) of two consecutive round-robin
iterations is no larger than 0.1% of that in the previous iteration. All
simulation results are averaged over 500 realizations of {Qik}Ki,k=1.
We first examine the efficacy of the PSO algorithm (Algorithm
1) by comparing it with the DSCA algorithm in [1] and the naive
maximum-ratio transmission (MRT) strategy. Figure 1 shows the
average weighted sum rate versus 1/σ2 for K = 4 and Nt = 4. It
can be seen that the PSO algorithm and the DSCA algorithm yield
almost the same weighted sum rate performance, and they outper-
form the MRT strategy.
In Fig. 2, we compare the average computation time (in seconds)
of the PSO algorithm and the DSCA algorithm versus the number of
users K, for 1/σ2 = 10 dB, η = 0.5, and Nt = 4 and 8. The sub-
problems involved in the DSCA algorithm are handled by CVX [18].
Note that the computation time of the PSO algorithm increases al-
most linearly with K, whereas that of the DSCA algorithm increases
much faster with K. According to Fig. 2, the PSO algorithm is about
103 times faster than the DSCA algorithm.
6. APPENDIX: PROOF OF LEMMA 1
We show that ∂ log(1 + ξk({Ijk}j 6=k)Ikk)/∂Iik is strictly increas-
ing in Iik ≥ 0, which implies that log(1+ξk({Ijk}j 6=k)Ikk) is con-
0 5 10 15 20
0
0.5
1
1.5
1/σ2 (dB)
Av
er
ag
e 
W
ei
gh
te
d 
Su
m
 R
at
e 
(bi
ts/
se
c/H
z)
 
 
PSO Algorithm, η=0.2
PSO Algorithm, η=1.0
DSCA Algorithm, η=0.2
DSCA Algorithm, η=1.0
MRT, η=0.2
MRT, η=1.0
Fig. 1. Average achievable sum rate versus 1/σ2 for K = Nt = 4,
and rank(Qki) = 4 for all k, i.
2 4 6
0
100
200
300
400
500
600
700
K
A
v
e
ra
g
e
 T
im
e
 C
o
n
su
m
p
ti
o
n
 (
se
cs
)
 
 
DSCA, N t =4
DSCA, N t =8
2 4 6
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
K
A
v
e
ra
g
e
 T
im
e
 C
o
n
su
m
p
ti
o
n
 (
se
cs
)
 
 
PSO, Nt =4
PSO, Nt =8
Fig. 2. Average computation time of the PSO algorithm and the
DSCA algorithm versus K, for Nt = 4, 8, 1/σ2 = 10 dB, and
η = 0.5.
vex in Iik ≥ 0 [17], using the two properties of ξk({Ijk}j 6=k): 1)
ξk({Ijk}j 6=k) is strictly decreasing in Iik ≥ 0; 2) Iik ·ξk({Ijk}j 6=k)
is strictly increasing in Iik ≥ 0.
To prove the first property, observe from (4) thatΦk(x|{Ijk}j 6=k)
is strictly increasing in x > 0 and Iik ≥ 0. Thus, the function
ξk({Ijk}j 6=k), which satisfies Φk(ξk({Ijk}j 6=k)|{Ijk}j 6=i) = 1
uniquely, is strictly decreasing in Iik ≥ 0. To show the second prop-
erty, suppose that I ′ik < I ′′ik, and define ξ′k = ξk({Ijk}j 6=i,k, I ′ik)
and ξ′′k = ξk({Ijk}j 6=i,k, I ′′ik). By the definition of ξk({Ijk}j 6=k),
we have Φk(ξ′k|{Ijk}j 6=i,k, I ′ik) = Φk(ξ′′k |{Ijk}j 6=i,k, I ′′ik) = 1.
Moreover, ξ′k > ξ′′k by the first property. Therefore, the following
chain holds
1 =ρk exp(σ
2
kξ
′
k)(1 + I
′
ikξ
′
k)
∏
` 6=i,k
(1 + I`kξ
′
k) (by (4))
=ρk exp(σ
2
kξ
′′
k )(1 + I
′′
ikξ
′′
k )
∏
` 6=i,k
(1 + I`kξ
′′
k )
<ρk exp(σ
2
kξ
′
k)(1 + I
′′
ikξ
′′
k )
∏
` 6=i,k
(1 + I`kξ
′
k)
which implies I ′ikξ′k < I ′′ikξ′′k . By these two properties, and by (11)
and the fact of ∂ log(1 + ξk({Ijk}j 6=k)Ikk)/∂Iik = − αiαk piik (see
(9) and (10)), one can verify that ∂ log(1+ ξk({Ijk}j 6=k)Ikk)/∂Iik
is strictly increasing in Iik ≥ 0. This completes the proof. 
ON THE ENDMEMBER IDENTIFIABILITY OF CRAIG’S CRITERION FOR
HYPERSPECTRAL UNMIXING: A STATISTICAL ANALYSIS FOR THREE-SOURCE CASE
Chia-Hsiang Lin∗, ArulMurugan Ambikapathi∗, Wei-Chiang Li, and Chong-Yung Chi
Institute of Communications Engineering, National Tsing Hua University, Hsinchu, Taiwan
E-mail: stevenmathmath@gmail.com;aareul@ieee.org;weichiangli@gmail.com;cychi@ee.nthu.edu.tw;
ABSTRACT
Hyperspectral unmixing (HU) is a process to extract the underlying
endmember signatures (or simply endmembers) and the correspond-
ing proportions (abundances) from the observed hyperspectral data
cloud. The Craig’s criterion (minimum volume simplex enclosing
the data cloud) and the Winter’s criterion (maximum volume sim-
plex inside the data cloud) are widely used for HU. For perfect iden-
tifiability of the endmembers, we have recently shown in [1] that the
presence of pure pixels (pixels fully contributed by a single endmem-
ber) for all endmembers is both necessary and sufficient condition
for Winter’s criterion, and is a sufficient condition for Craig’s crite-
rion. A necessary condition for endmember identifiability (EI) when
using Craig’s criterion remains unsolved even for three-endmember
case. In this work, considering a three-endmember scenario, we en-
deavor a statistical analysis to identify a necessary and statistically
sufficient condition on the purity level (a measure of mixing levels
of the endmembers) of the data, so that Craig’s criterion can guar-
antee perfect identification of endmembers. Precisely, we prove that
a purity level strictly greater than 1/
√
2 is necessary for EI, while
the same is sufficient for EI with probability-1. Since the presence
of pure pixels is a very strong requirement which is seldom true in
practice, the results of this analysis foster the practical applicability
of Craig’s criterion over Winter’s criterion, to real-world problems.
Index Terms— Hyperspectral unmixing, minimum volume en-
closing simplex, purity level, endmember identifiability, statistical
analysis
1. INTRODUCTION
Hyperspectral unmixing (HU) is a powerful multidimensional im-
age analysis tool to dissect and characterize the endmember signa-
tures (reflection coefficients of a material) and their corresponding
abundances (fractional distributions of a material), from the mea-
sured hyperspectral data [2]. The applications of HU include space
object identification, military surveillance, retinal analysis, etc., [3].
Based on the seminal works of Craig [4] and Winter [5], a number
of powerful HU algorithms have been proposed, and they are re-
cently summarized in [6]. The Craig’s criterion in [4] (and the Win-
ter’s criterion in [5]) claims that the vertices of the minimum volume
simplex enclosing the hyperspectral data cloud (the vertices of the
maximum volume simplex inside the data cloud) will yield high fi-
delity estimates of the endmembers. The Craig’s criterion and the
Winter’s criterion were theoretically analyzed recently in [1], where
the necessary and sufficient condition for endmember identifiability
(EI) (which is the ability to yield the true endmembers) using Win-
ter’s criterion is shown to be the existence of pure pixels (pixels that
∗Contributed equally. This work was supported in part by National Sci-
ence Council (R.O.C.) under Grant NSC 99-2221-E-007-003-MY3 and in
part by NTHU and Mackay memorial hospital under Grant 100N2742E1.
are completely contributed by a single endmember) for all endmem-
bers. In reality, the presence of pure pixels for all the endmembers is
seldom true and hence draws a limit on the practical applicability of
Winter’s criterion.
In [1], it has also been proved that the existence of pure pixels
for all the endmembers is a sufficient condition for EI of Craig’s cri-
terion. But, intuitively, geometrically, and by simulations, it can be
verified that Craig’s criterion can yield perfect identifiability even
when the sources are (relatively) highly mixed [7]. However, theo-
retical analysis of the condition on the mixing level of the sources
(i.e., purity levels) for the Craig’s criterion to yield the endmember
is complicated and remains unsolved for about two decades. In this
work, considering a three-source case, we statistically analyze the
conditions on the data purity level for which the Craig’s criterion
can uniquely identify the true endmembers. We begin by studying
the relationship between the observations and their corresponding
abundances. Then, under a statistical framework, by exploiting the
convex geometry of the abundances and by analyzing the property
of the minimum volume enclosing simplex (MVES), we derive the
conditions for EI of Craig’s criterion.
Notations: RM and Z+ represent the set of real M × 1 vectors
and nonnegative integers, respectively. The symbol ‖ · ‖ represents
the Euclidean norm. ei is a unit vector with the ith entry equal to 1.
Convex hull and affine hull [8] of a set of vectors a1, . . . ,aN is rep-
resented as conv{a1, . . . ,aN}, and aff{a1, . . . ,aN}, respectively.
The relative interior and relative boundary of a set A are denoted
as int(A) and bd(A), respectively. Pr{·} denotes the probability
function.
2. SIGNAL MODEL AND ASSUMPTIONS
For the purpose of analysis, we consider a noise-free signal model.
Following a linear mixing model [1]- [6], each pixel vector (or sim-
ply pixel, for convenience) in the observed data xn can be repre-
sented as:
xn = Asn =
N∑
i=1
sinai, ∀n = 1, . . . , L, (1)
where xn = [x1n, . . . , xMn]T denotes the nth observed pixel
vector comprising M spectral bands, ai is the ith endmember
signature, sn = [s1n, . . . , sNn]T ∈ RN is the nth abundance vector
comprising N fractional abundances, and L is the total number
of observed pixels. Standard assumptions pertaining to the signal
model in (1) are (A1) sin ≥ 0, ∀i, n; (A2)∑Ni=1 sin = 1, ∀n; (A3)
M ≥ N , and A = [a1, . . . ,aN ], where ai is the ith endmember,
is of full column rank [1], [2], [6], [7]. Under (A1) and (A2), it
can be noted that the observed pixels xn are convex combinations
of a1, . . . ,aN , with s1n, . . . , sNn as the unique combining coeffi-
cients, for each xn. In other words, xn ∈ conv{a1, . . . ,aN}, ∀n,
(S1): If MVES(XL) = {Ta}, then ρ > ρ?.
(S2): If ρ > ρ?, then Pr{MVES(X ) = {Ta}} = 1, where X ,
limL→∞ XL.
Proof: We begin to prove Theorem 1 by first observing the mu-
tual uniqueness of Ta and Te, as stated and proved in the following
Lemma:
Lemma 1 (Mutual Uniqueness Property)
(L1): MVES(XL) = {Ta} if and only if MVES(SL) = {Te},
(L2): MVES(X ) = {Ta} if and only if MVES(S) = {Te}, where
S , limL→∞ SL.
The proof of Lemma 1 is presented in Appendix 4.1. Due to the
mutual uniqueness of the MVES of XL and SL, by considering SL
we can prove (S1) by contradiction, as follows:
Suppose that 1/
√
3 ≤ ρ ≤ 1/√2. Then, according to (A4), we
have SL ⊆ R(ρ) = C(ρ), which implies
vol
(U) ≤ vol(V),∀U ∈ MVES(SL), ∀V ∈ MVES(R(ρ)). (7)
Furthermore, since R(ρ) = C(ρ) is a disc with radius r(ρ) when
1/
√
3 ≤ ρ ≤ 1/√2, we have from Property 1 that MVES(R(ρ))
is the collection of all equilateral triangles with bd
(R(ρ)) as inner
tangent circle. As a result (from (2)),
vol
(V) = 3√3r2(ρ) ≤ vol(Te),∀V ∈ MVES(R(ρ)). (8)
By (7) and (8), vol(U) ≤ vol(Te) for all U ∈ MVES(SL). Ob-
viously when the strict inequality holds, Te 6∈ MVES(SL). On the
other hand, when the inequality holds with equality, all the elements
in MVES
(R(ρ)), which are infinitely many, are MVES of SL, so
MVES(SL) 6= {Te}, which, along with (L1) of Lemma 1, com-
pletes the proof of (S1) in Theorem 1.
The proof of (S2) of Theorem 1 involves the randomness of SL.
In view of this, we are motivated to study the EI in asymptotic sense.
The key result for this proof is stated and proved in the following
lemma.
Lemma 2 Suppose that XL has purity level ρ ∈ [1/
√
3, 1]. Then,
Pr
{
int(R(ρ)) ⊆ conv(S) ⊆ R(ρ)} = 1. (9)
The proof of Lemma 2 is presented in Appendix 4.2. As it is obvious
that MVES(R(ρ)) = MVES(int(R(ρ))) and MVES(conv(S)) =
MVES(S), then from Lemma 2 we have
Pr
{
MVES(S) = MVES(R(ρ))} = 1. (10)
The above result in (10), relates the EI by the MVES of S to that
by the MVES of R(ρ), where the latter is deterministic and hence
more tractable. Indeed, we can identify the necessary and sufficient
condition on the purity level ρ for the EI by the MVES of R(ρ) as
described in Lemma 3 below.
Lemma 3 MVES(R(ρ)) = {Te} if and only if ρ ∈ (1/
√
2, 1].
The proof of Lemma 3 is presented in Appendix 4.3. Combining
(10) and Lemma 3, we can obtain
Pr
{
MVES(S) = {Te}
}
= 1,
which together with (L2) of Lemma 1 directly yields (S2) of Theo-
rem 1 and thereby completes the proof of Theorem 1. 
4. APPENDIX
4.1. Proof of Lemma 1:
(L1): (Necessity) We will prove by contradiction. Assume
MVES(SL) 6= {Te}, then there exists a simplex T ′e ⊆
aff{e1, e2, e3} such that
SL ⊆ T ′e , (11)
T ′e 6= Te, (12)
vol(T ′e ) ≤ vol(Te). (13)
Then we have from (12) and the fact that the linear transforma-
tion T is one-to-one, that T (T ′e ) 6= T (Te) = Ta. But T (T ′e ) ⊆
aff{a1,a2, a3} also satisfies
XL = ASL = T (SL) ⊆ T (T ′e ), (14)
vol(T (T ′e )) = α · vol(T ′e )
= (vol(Ta)/vol(Te)) · vol(T ′e ) ≤ vol(Ta), (15)
where (14) is due to (11), and (15) is due to (3) and (13). Therefore,
there exists a simplex T (T ′e ) 6= Ta that encloses XL (by (14))
and has volume not greater than Ta (by (15)), which implies that
MVES(XL) 6= {Ta}. Thus the necessity of (L1) is proved.
(Sufficiency) This can be proved by following a procedure similar to
the above proof of necessity.
(L2): By replacing XL, SL in the above proof by X , S respectively,
both necessity and sufficiency of (L2) can be proved. 
4.2. Proof of Lemma 2:
Since S ⊆ R(ρ) by the definition of purity level, conv(S) ⊆ R(ρ)
is true due to the convexity of R(ρ). Therefore, it suffices to show
that Pr
{
int(R(ρ)) ⊆ conv(S)} = 1.
Let Y , {q ∈ int(R(ρ))|q ∈ Q3} be the collection of all
rational points in int(R(ρ)), where Q3 denotes the set of rational
3× 1 vectors. Then Y is countable and dense in int(R(ρ)) [11].
Fix y ∈ Y . Since int(R(ρ)) is open and Y ⊆ int(R(ρ)), there
exists ε > 0 and a square (y; ε) with center y and side length ε
such that (y; ε) ⊆ int(R(ρ)) [15] (see Figure 2).
9
3 4 5
6
7
2
81
e1
e2 e3
ε
ε
ε
ε
ε′ε′ ε′
ε′
ε′
ε′
y
R3
enlarged
Fig. 2. A square (y; ε) with center y ∈ Y and side length ε, and
its partition
Now we evenly divide (y; ε) into 9 sub-squares with side
length ε′ = ε/3, and label them by 1, ...,9 (see Figure 2).
Since vol(i) = (ε′)2 = ε2/9 > 0, we have from (A4) that
p ,
∫
s∈i f(s)ds ∈ (0, 1], and therefore Pr{S
⋂
i = ∅} =
limL→∞(1 − p)L = 0 for each i = 1, . . . , 8. Then we have
6. REFERENCES
[1] T.-H. Chan, W.-K. Ma, A. Ambikapathi and C.-Y. Chi, “A simplex
volume maximization framework for hyperspectral endmember extrac-
tion,” IEEE Trans. Geosci. Remote Sens., vol. 49, no. 11, pp. 4177-
4193, Nov. 2011.
[2] N. Keshava and J. Mustard, “Spectral unmixing,” IEEE Signal Process.
Mag., vol. 19, no. 1, pp. 44-57, Jan. 2002.
[3] P. Shippert, “Why use hyperspectral imagery?,” Photogram., Eng., and
Remote Sensing, vol. 70, no. 4, pp. 377-380, Apr. 2004.
[4] M. D. Craig, “Minimum-volume transforms for remotely sensed data,”
IEEE Trans. Geosci. Remote Sens., vol. 32, no. 3, pp. 542-552, May
1994.
[5] M. E. Winter, “N-findr: An algorithm for fast autonomous spectral
end-member determination in hyperspectral data,” in Proc. SPIE Conf.
Imaging Spectrometry, Pasadena, CA, Oct. 1999, pp. 266-275.
[6] J. M. Bioucas-Dias, A. Plaza, N. Dobigeon, M. Parente, P. G. Q. Du,
and J. Chanussot, “Hyperspectral unmixing overview: Geometrical,
statistical, and sparse regression-based approaches,” IEEE J. of Sel.
Topics in Applied Earth Obs. and Remote Sensing, vol. 5, no. 2, pp.
354-379, June 2012.
[7] T.-H. Chan, C.-Y. Chi, Y.-M. Huang, and W.-K. Ma, “A convex anal-
ysis based minimum-volume enclosing simplex algorithm for hyper-
spectral unmixing,” IEEE Trans. Signal Processing, vol. 57, no. 11,
pp. 4418-4432, Nov. 2009.
[8] S. Boyd and L. Vandenberghe, Convex Optimization, UK: Cambridge
Univ. Press, 2004.
[9] A. Ambikapathi, T.-H. Chan, C.-Y. Chi, and K.Keizer, “Hyperspectral
data geometry based estimation of number of endmembers using p-
norm based pure pixel identification,” to appear in IEEE Trans. Geosci.
Remote Sens., 2012 (currently available at IEEE Xplore).
[10] A. Ambikapathi, T.-H. Chan, W.-K. Ma, and C.-Y. Chi, “Chance con-
strained robust minimum volume enclosing simplex algorithm for hy-
perspectral unmixing,” IEEE Trans. Geosci. Remote Sens., vol. 49, no.
11, pp. 4194-4209, Nov. 2011.
[11] R. L. Wheeden and A. Zygmund, Measure and Integral: An Introduc-
tion to Real Analysis, Marcel Dekker Inc., New York, 1977.
[12] B. J. McCartin, Mysteries of the Equilateral Triangle, Hikari Ltd.,
2010.
[13] D. P. Bertsekas, Convex Optimization Theory, Athena Scientific, 2009.
[14] J. Nascimento and J. Bioucas-Dias, “Hyperspectral unmixing based on
mixtures of Dirichlet components,” IEEE Trans. Geosci. Remote Sens.,
vol. 50, no. 3, pp. 863-878, Mar. 2012.
[15] T. M. Apostol, Mathematical Analysis, 2nd Edition, Pearson Edu. Tai-
wan Ltd., 2007.
 2 
website as follows: http://www.chinasip2013.org/TSP.htm  
(請參閱附件一: Special Session of Trends in Signal Processing)  
(b) 15:20-17:00 Trends in Signal Processing II: I also served as the session chair.  
 
7/10 (Wednesday): Visit Tsinghua University, Beijing and gave an invited talk as follows:  
Topic: Efficient Beamforming Algorithms for Outage Constrained Weighted Sum-Rate 
Maximization in MISO Interference Channel  
Abstract: The beamforming design for weighted sum rate maximization in a multiple-input 
single-output (MISO) interference channel (IFC) with only channel distribution information (CDI) 
available at the transmitters has drawn extensive attention recently. In this talk, we present some 
new results on the transmit beamforming design under individual transmit power constraints and 
rate outage constraints. First of all, a recently proposed successive convex approximation (SCA) 
algorithm to search for a stationary solution in polynomial time is introduced. In spite of good 
performance of the SCA algorithm, it is computationally too expensive to handle the problem 
instances with a large number of transmitters and receivers. Then we prove that the considered 
design problem is NP-hard in general. Then we present a more efficient approximation algorithm 
based on the idea of interference pricing. The simulation results demonstrate that the pricing-based 
algorithm yields almost the same performance as the SCA algorithm, while the former is much 
more computationally efficient than the latter, thereby leading to more practical usefulness.  
 
攜回資料：ChinaSIP-2013會議論文集之隨身碟一支。  
 
二、與會心得 
 
在本次會期中，筆者之特約邀請演講受到許多大陸及國際專家學者的關注，在吸收新
知及建立人際關係受益良多。也顯示中國大陸的快速發展及增進其國際影響力，由於
中國優秀人才之展現已為各國爭取之對象。國內有志於高科技之研發研究生已大不如
前，而開放招生陸生之辦法限制過多，對我們爭取優秀人才之競爭力極為不利，盼政
府盡速修改，以利研究發展之國際競爭力。  
 
International collaboration has been an effective way to keep our research quality and 
recognition in the international communities. Over the last decade, we have been engaged in 
international collaboration with experts in Virginia Tech, The Chinese University Hong Kong, 
University of Minnesota, Tsinghua University (Beijing), Beijing Jiaotung University, and 
Tianjin University, thereby having accomplished many high-quality cutting edge research 
works published in flagship international journals and conferences. We will further enhance 
our international collaboration.  
 
file:///C|/Users/cychi/Desktop/新增資料夾/TSP.htm[2013/7/30 上午 08:13:59]
Organizers: Jonathan MANTON and Liuqing YANG
Session Chair: Chong-Yung CHI
Trends in Signal Processing
This special session hosts six leading international researchers, each invited to present an overview of an area of
signal processing of his choosing. Each talk will be approximately 20 minutes long, followed by 10 minutes of
questions from the audience. 
Speaker Topic and Abstract
Chong-Yung Chi, 
National Tsing Hua
University
Topic: Convex Geometric Analysis for Non-negative Blind Source
Separation 
Abstract: Despite the tremendous advances made in imaging methodologies and
equipments, often most of the real world observations are mixtures of the true
sources. Blind Source Separation (BSS) is a signal processing methodology to
extract the sources from the mixed observations, devoid of (or with very limited)
prior knowledge about the sources and how those sources are mixed in the
observations. Inherently, many of the real world sources and their observations are
non-negative in nature (e.g., imaging applications such as biomedical imaging,
hyperspectral imaging, micro-array data etc.), and thereby naturally leading to a
specific class of BSS, namely non-negative BSS (nBSS). Till date, many useful
nBSS algorithms, centered around independent component analysis (ICA) and non-
negative matrix factorization (NMF), have been reported. Originated from
philosophies that are different from successfully developed nICA and NMF
algorithms, there is a branch of nBSS methods exploiting the intriguing convex
geometry of the sources. In this talk, we intend to give a historical review of nBSS
methods, and present some representative and state-of-the-art convex geometry
based nBSS (CG-nBSS) algorithms in a unified perspective manner, together with
novel experimental results for some practical applications. Finally, we conclude with
the research trend of nBSS for solving hidden challenges and bottlenecks in related
science and engineering applications.
Robert Cui, 
Texas A&M University
Topic: Big Data Oriented Network Information Processing 
Abstract: In this talk we will focus on large-scale signal processing and
information delivery over networks. We will start with the highlights of some key
challenges, and argue that one promising solver is distributed information
processing. Afterwards, we will instantiate the problem with several concrete
examples namely, the large-scale distributed estimation problem, distributed
detection problem, and distributed storage problem. Then we will open the floor for
discussions.
Topic: Robust Pitch Estimation for Speech and Music 
Abstract: Pitch is an important attribute of auditory signals, including speech and
music. In human speech communication, pitch carries abundant information, which
Home
Call for Papers
Call for Journal Presentations
Call for Sponsorship
Letter from President
Committees
Plenary Talks
Trends in Signal Processing
Special Sessions
Meet and Ask Leaders
Industry Forum
Summer School
Important Dates
Paper Submission
Registration
Program
Local Informaiton
Videos & Photos
file:///C|/Users/cychi/Desktop/新增資料夾/TSP.htm[2013/7/30 上午 08:13:59]
measurements, to which conventional position estimation methods are very
sensitive. Consequently, in these situations, there is a need for robust statistical
signal processing methods. With the increase of complexity of engineering system
design and the lack of predictability of natural as well as man-made interference,
systems that are resistant to deviations from the assumed model are more
important than ever before.
               
99年度專題研究計畫研究成果彙整表 
計畫主持人：祁忠勇 計畫編號：99-2221-E-007-003-MY3 
計畫名稱：應用於生物醫學影像與超光譜影像分析之前瞻盲蔽訊號源分離技術 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 0 100%  
博士生 1 0 100%  
博士後研究員 2 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 0 100% 
人次 
 
期刊論文 7 7 80%  
研究報告/技術報告 0 0 100%  
研討會論文 12 12 80% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
