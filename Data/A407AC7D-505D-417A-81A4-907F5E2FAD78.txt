 1
根據情緒自動配樂之美術影像幻燈展示系統 
 
 
ABSTRACT 
In this report, we propose the emotion-based Impressionism slideshow system with automatic music 
accompaniment. While conventional image slideshow systems accompany images with music manually, 
our proposed approach explores the affective content of painting to automatically recommend music 
based on emotions. This is achieved by association discovery between painting features and emotions, 
and between emotions and music features respectively. To generate more harmonic Impressionism 
presentation, a linear arrangement method is proposed based on modified traveling salesman algorithm. 
Moreover, some animation effects and synchronization issues for affective content of Impressionism 
fine arts are considered. Experimental result shows our emotion-based accompaniment brings better 
browsing experience of aesthetics. 
 
1. INTRODUCTION 
 
There was a painting-music flash movie, “Vincent”, composed by England’s singer Don Mclean for 
the impressionism artist Vincent Van Gogh, distributed over the internet. Along with Mclean’s epic-like 
tone, this movie leads us to the deepest inner world and the soulful sympathy of Van Gogh. The 
consonance between painting and music is important for fine art slideshow. 
Some works have been done on slideshow system for photos. The work proposed by Hua et al. [3], 
arranges photos by time, scene, or content similarity with incident music. They also proposed a system, 
Photo2Video [4], to convert photos to motion video with designated music. Photo2Video explores 
attentive area, topic, and human face of photos and applied “Ken Burns” effects for motion photo clip. 
Another work proposed by Chen et al. [1] generates music-driven photo slideshow where each frame is 
tiled by multiple photos. 
Basically, painting in digital form is one type of photos. Those systems developed for photo 
slideshow may be employed for painting. However, some characteristics are distinguished painting from 
photo [2]. Spatial variations of color and number of unique colors in paintings are larger than real scenes. 
Perceptual edges in photos of real scenes are intensity edges while those of paintings are pure color 
 3
beat with painting display. Moreover, for the gaps between each painting and each music clip, some 
strategies are applied to smooth the disharmony. 
 
 
Figure 2. Flowchart of proposed slideshow system. 
 
3. PAINTING-EMOTION DISCOVERY 
3.1 Painting Features 
Painting is characterized by color, light, texture, line, etc. Among them, the first three affects emotions 
strongly. Emotions are sensitive to color. For example, Van Gogh’s “The Night Café” tried to express 
with red and green the terrible passions of human nature. For color and light, we extract dominant color, 
color coherence vector (CCV), and color moment. The extent of coarseness in the surface of painting is 
decided by texture. There exists relationship between brushwork and texture. For texture, we extract 
some statistic measures from gray level co-occurrence matrix (GLCM), and compute the primitive 
length of texture. 
Dominant Color We calculate the color histogram of a painting. Those colors occur below 10% of area 
would be omitted. In color description, since the property of impressionists are good at presenting color 
change by complementary colors, like Van Gogh’s “Wheatfield with Crows”, we utilize the opponent 
color theory formulated by Ewald Hering based on artistic color concepts, in which L means luminance, 
S means red-green channel, and LM means yellow-blue channel.  
Color Coherence Vector Since the color histogram’s lack of spatial information, we employ another 
histogram-based approach for comparing images. The color coherence is defined as the degree to which 
pixels of that color are the members of those large similarly-colored regions, so the pixels would be 
categorized into coherence or incoherence. 
 5
 
Figure 3. Painting Affinity Graph. 
 
In our approach, we call it painting affinity graph (PAG). In PAG, we create an object vertex for 
each painting. For each painting object vertex, two types of attribute vertices, emotion and painting 
feature are created and connected. Five painting feature attribute vertices are created for each painting 
object vertex, including dominant color, CCV, color moment, GLCM and primitive length. For a 
painting with m emotions, m emotion attribute vertices are created. NN-link is constructed between two 
emotion attribute vertices if both are of the same emotion. Nearest neighbor of NN-link between two 
painting feature attribute vertices is determined by the similarity measure of respect painting feature. 
Figure 3 shows an example of PAG for three annotated painting. The painting object p1, with features 
{fa1, fb1, fc1, fd1, fe1}, is annotated with emotions {e1, e2}. Given an un-annotated painting Q with 
painting features {faq, fbq, fcq, fdq, feq}, PAG will find the most likely emotions based on the affinity.  
4. MUSIC ACCOMPANIMENT 
4.1 Emotion-based Clustering 
To recommend music based on the emotions, we have to organize paintings such that those with 
similar emotions are grouped in a cluster and find out the common emotions of each cluster.  
We employ the ROCK algorithm [8] for emotion-based clustering. ROCK is a novel clustering 
algorithms for data with boolean and categorical attributes. 
4.2 Music-emotion Association Discovery 
For each cluster of paintings, one music clip is recommended for accompaniment. The basic idea to 
music recommendation is based on each cluster’s common emotions explored by the painting-emotion 
discovery component. To find the recommended music, association discovery between emotions and 
music features is performed. The music features used in this work are melody, rhythm and tempo, which 
 7
cluster. Having computed the dissimilarity for each pair of paintings and constructed the corresponding 
complete graph, we model the intra-cluster arrangement as the bottleneck Traveling Salesman Problem 
(TSP) from developed algorithm, which tries to find the Hamilton cycle with the minimal length of the 
longest edge. An example is illustrated in Figure 5.  
For inter-clustering arrangement, the display order among clusters is scheduled. We compute the 
dissimilarity between each pair of clusters, which is defined as the dissimilarity between the last painting 
of one cluster and the first painting of the other cluster. While inter-cluster dissimilarity is asymmetric, 
we model the inter-cluster arrangement problem as the Asymmetric Traveling Salesman Problem. There 
exist several heuristic algorithms for Bottleneck and Asymmetric Traveling Salesman Problems. 
 
Figure 5. Intra-cluster arrangement. 
 
 
Figure 6. An example of zooming and panning. 
5.2 Close-up Animation 
To highlight the spatial information of affective content of painting, along with the temporal 
feelings of music, we create the animated effects into each interval of painting display by motion 
patterns, such as panning and zooming. For these motion patterns, we have to extract some close-up 
areas in each painting and treat it as key-frames. In this work, the ROI is adopted as the close-up area. 
The ROIs are determined by face detection and attention model of saliency map. Figure 6 is an example 
of animation. 
5.3 Synchronization and Rendering 
The effects of synchronization of temporal structure between paining and accompanied music play 
 9
Bach, Beethoven, Brahms, Chopin, Debussy, Handel, Mendelssohn, Mozart, Ravel, Schumann and 
Tchaikovsky. These music objects in MIDI format are collected from web sites 
http://www.kunstderfuge.com/ and http://www.classicalmusicmidipage.com/. These music objects are 
segmented into clips by our previous work [5]. The emotion model adopted in this experiment is 
Russell’s circumplex model. Two painting sets used and the ordered music to accompany with are listed 
in Table 1.  
The slideshows created by ACDSee (http://www.acdsystems.com) and Photo Story 
(http://www.microsoft.com), are employed in this experiment for comparison. The ACDSee generates 
one-by-one presentation and is not able to accompany images with music. Photo Story supports some 
camera effects on photo display, and it is affordable to synchronize between photo and music. However, 
for those existed music, Photo Story must designate manually. 
Table 1. Description of painting sets to be evaluated. 
 
　 Painting set 1 　 Painting set 2 
　 Number of paintings = 65 　 Number of paintings = 61 
　 Display length = 5 min. 41 sec. 　 Display length = 5 min. 17 sec. 
1. “Song without Words, Op.19, No.5” of Mendelssohn 
2. “Clair de Lune” of Debussy 
3. “Nocturne No.9 in B major, Op.32, No.1” of Chopin 
1.“Moonlight Sonata, No.14, Mv.1” of Beethoven 
2.“Scenes from Childhood, Op.15, No. 7” of 
Schumann 
 
Table 2. List of five criteria for evaluation. 
 
Emotionality (Emo) 　 Do you think it reach emotional coordination? 
Aesthetics (Aes) 　 How do you feel the presentation of appearance? 
Experience (Exp) 　 Do you think it reach appreciation aesthetics? 
Atmosphere (Atm) 　 How do you feel the audiovisual effect? 
Acceptance (Acc) 　 Do you want to use it to taste fine-art? 
We invited 18 persons to participate this experiment. Each person is asked to view the slideshows. 
The accompanied classical music is of the same length. Then they are asked to give scores from 1 to 10 
to express their satisfaction for the questions listed in Table 2, that higher score indicates better 
satisfaction. 
We set the score of ACDSee to 5 as the baseline. Figure 8 shows the results of subjective 
evaluations. It is observed that our system gets higher satisfaction than others on average, especially for 
the criterion of emotionality and experience. This comes from the consideration of the affective content 
in our proposed approach. However, there is little difference between ours and Photo Story for the 
 11
[5] Kuo, F. F., Chiang, M. F., Shan, M. K. and Lee, S. Y. Emotion-based Music Recommendation by 
Association Discovery from Film Music, In Proc. of ACM Intl. Conference on Multimedia (MM’05), 
2005. 
[6] Pan, J. Y., Yang, H. J., Faloutsos, C. and Duygulu, P. Automatic Multimedia Cross-modal 
Correlation Discovery. In Proc. of Intl. Conference on Knowledge Discovery and Data Mining 
(KDD’04), 2004. 
[7] Rubner, Y., Tomasi, C. and Guibas L. The Earth Mover’s Distance as a Metric for Image Retrieval. 
Intl. Journal of Computer Vision, 40(2), 2000. 
[8] Sudipto, G., Rajeev, R., and Kyuseok,  S. ROCK: A Robust Clustering Algorithm for Categorical 
Attributes. Information Systems, 25(5), 2000. 
