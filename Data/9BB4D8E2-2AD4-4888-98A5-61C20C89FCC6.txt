accuracy will eventually decline when the ratio of 
the number of the training pixels and the 
dimensionality cannot be maintained at or above some 
minimum value to achieve statistical confidence. In 
general, four approaches were used to mitigate Hughes 
phenomenon: the first method is the semi-supervised 
learning (SSL) algorithm which increases the number 
of training samples by classifying unknown samples 
and selecting representatives from them. The second 
method is dimensionality reduction method which 
reduces the number of features of samples by means of 
feature extraction or feature selection. The third 
method is regularization which improves the 
estimation of parameters. The fourth method is to 
improve the design of classifiers. 
In recent years considerable concern has arisen over 
the kernel method and SSL method in remotely sensed 
hyperspectral image classification research. 
Therefore, based on the proposed nonparametric 
feature extraction, namely cosine-based nonparametric 
feature extraction (CNFE), the kernel version of CNFE 
(namely KCNFE) and a semi-supervised version of CNFE 
(namely SSCNFE) were proposed in this study. 
 
英文關鍵詞： remotely sensed hyperspectral image, feature 
extraction, classifier, kernel method, semi-
supervised learning 
 
II 
 
表目錄 
表 1 INDIAN PINES SITE 影像各類別所含有之圖素 ................................................... 10 
表 2 SALINAS 資料集各類別所含有之圖素 .............................................................. 11 
表 3 PAVIA UNIVERSITY 各類別所含有之圖素 ........................................................... 12 
表 4 使用 1NN 辨識器在 INDIAN PINES 資料集的最佳平均辨識率(ACC)、標準差
(STD)與轉換空間維度(P) .................................................................................... 14 
表 5 使用 SVM 辨識器在 INDIAN PINES 資料集的最佳平均辨識率(ACC)、標準差
(STD)與轉換空間維度(P) .................................................................................... 14 
表 6 SSCNFE 在 INDIAN PINES、PAVIA UNIVERSITY 與 SALINAS 資料集上的最佳平
均辨識率、對應之標準差與維度...................................................................... 18 
表 7 INDIAN PINES 資料集上的平均辨識率(“ACC”)與標準差(“STD”) ...................... 23 
表 8 PAVIA UNIVERSITY 資料集上的平均辨識率(“ACC”)與標準差(“STD”) .............. 23 
表 9 SALINAS 資料集上的平均辨識率(“ACC”)與標準差(“STD”) .............................. 23 
 
IV 
 
中文摘要及關鍵詞 
高光譜遙測影像資料來自於數百個感測器在可見光與不可見光的光譜範圍
內測量到的波段訊息，因此能夠提供更多、更有用的訊息。然而，地表真實資
料(ground truth)的取得一般來說成本頗高，因此可用的訓練樣本數通常是一個
重要的議題。因為樣本數不足使得辨識器內的參數估計誤差大，一般化能力
(generalization ability)也會因此而受限。Hughes phenomenon 是 Hughes 在 1968
年提出，主要是在描述當樣本點(N)與於維度(p)的比例如果不能維持在某個比率
R 時(R=N/p 或 p/N)，則辨識率會隨著維度數的增加而下降因此為了減低 Hughes 
phenomenon 影響就必須維持住這個比率或是改善參數估計以提升辨識率，方法
上大致有：一是想辦法增加樣本數的半監督式學習(semi-supervised learning, SSL)
演算法；另一是在樣本固定下，設法降低維度(dimensionality reduction)；三為
提升參數估計的正規化法(regularization)；四是改善辨識器的設計，例如多重辨
識器。 
近來，核方法(kernel method) 和半監督式學習(semi-supervised learning, SSL)
演算法等議題在解決高光譜影像資料分類時，受到相當多的關注。因此，本計
畫旨在基於研究者提出之無參數特徵萃取法 cosine-based nonparametric feature 
extraction (CNFE) 發 展 出 kernel-based CNFE(KCNFE) 與 半 監 督 式
(semi-supervised) CNFE (SSCNFE)等可用於高光譜遙測影像分類的技術。 
 
 
 
 
關鍵詞：高光譜遙測影像、特徵萃取、辨識器、核方法、半監督學習演算法 
  
1 
 
一、前言 
樣式辨識(pattern recognition)技術通常假定存在足夠的樣本數，使得辨識系
統參數得以正確估計。然而，這樣的假設對於遙測影像資料未必成立，因為蒐集
地表之真實類別資料(ground-truth data)在遙測影像資料的代價通常是相當昂貴
的。隨著科技的進步，感測系統設計變得越來越精密也越來越複雜，因此用來描
述物件的特徵數(維度)也越來越多。高光譜遙測影像資料來自於數百個感測器在
可見光與不可見光的光譜範圍內測量到的波段訊息，因此能夠提供更多、更有用
的訊息。在高光譜影像資料中，相鄰波段間的波長位置非常接近，因此可將其視
為近連續性的光譜資訊。就技術層面而言，波段愈多，愈有利於影像資料的偵測
(detection)與分類(classification)，因此，高光譜遙測影像資料也讓使用者得以進
行一些以傳統單一波段或多波段遙測資料較不易施行的複雜分析與應用，如：資
源探索和生態保育。然而，高光譜影像資料與多波段資料處理是不同的，因此也
就存在許多挑戰。 
因為地表真實資料的取得的成本頗高，因此可用的訓練樣本數通常是一個重
要的議題。Hughes phenomenon [1]是 Hughes 在 1968 年提出，主要是在描述當樣
本點(N)與於維度(p)的比例如果不能維持在某個比率 R 時(R=N/p 或 p/N)，則辨識
率會隨著維度數的增加而下降[2]-[3]，如下圖 1 所示。 
 
圖 1. Hughes phenomenon 
從另一個觀點來看，因為樣本數不足使得辨識器內的參數估計誤差大，一般化能
力(generalization ability)也會因此而受限。因此為了減低 Hughes phenomenon 影響
就必須維持住這個比率或是改善參數估計以提升辨識率，方法上大致有：一是想
辦法增加樣本數的半監督式學習(semi-supervised learning, SSL)演算法 [4]-[7], 
[36]-[41]；另一是在樣本固定下，設法降低維度(dimensionality reduction) [8]-[9]；
三為提升參數估計的正規化法(regularization) [10]；四是改善辨識器的設計，例
如多重辨識器[11]-[18]。半監督式演算法主要是先利用少數訓練樣本來訓練辨識
3 
 
三、文獻探討 
A. 無參數線性特徵萃取法 CNFE 
特徵萃取(feature extraction)主要藉由估算組內分散矩陣(within-class scatter 
matrix, 記為 Sw)和組內分散矩陣(between-class scatter matrix, 記為 Sb)來找到轉換
矩陣A使得經過A投影後的資料能夠使同一組資料越集中越好，不同類別的資料
分得越開越好，用來算出A的最佳化準則為： 
A = argmax
A
tr((ATSwA)
¡1ATSbA) 
上式最佳化問題相當於解廣義特徵值分解問題 (generalized eigenvalue 
decomposition problem ) 
Sbvi = ¸iSwvi; i = 1; 2; : : : ; p， 
其中 p  轉換後空間的維度數(dimensionality), ¸i和vi分別表示S¡1w Sb的特徵值
(eigenvalue)與特徵向量 (eigenvector)，且  ¸1 ¸ ¸2 ¸ ¢ ¢ ¢ ¸ ¸p，則轉換矩陣 
A = [v1; v2; : : : ; vp]。得到轉換矩陣A後可將原始資料進行降維投影，得到新的資
料集X0 = ATX 2 Rp£N 。常見的參數型特徵萃取法線性區別分析 (linear 
discriminant analysis, LDA)之組內分散矩陣SLDAw 和組間分散矩陣SLDAb 定義如
下： 
 
SLDAw =
LX
i=1
PiSi,                    (1)
 
SLDAb =
LX
i=1
Pi(mi ¡m)(mi ¡m)T            (2)
     
其中mi與m分別表示類別i的組平均和樣本平均，Si和S分別表示類別i的變異數
矩陣和樣本變異數矩陣，Pi為類別i的先驗機率。因為模式限制，可以萃取至多
類別數(L) - 1 個特徵。因萃取 L-1 個特徵有時候並不夠，研究者所提出無參數特
徵萃取法 CNFE 可以不受此限，理論上可以對整個空間進行轉換，也就是 p=d。
特徵萃取目的在於希望讓投影後的同類資料越接近越好，不同類的資料分得越開
越好，如此將有利於分類。因此，對於在類別邊界的那些點應該給予比較重的加
權，使得投影後的資料能夠符合上述原則，CNFE 乃是結合此二概念發展出來的
無參數線性特徵萃取法。CNFE 的組內分散矩陣和組內分散矩陣估算式如下： 
CNFE 的組內分散矩陣SCNw 定義如下： 
SCNw =
LX
i=1
Pi
NiX
`=1
w
(i;i)
`
³
x
(i)
` ¡Mi(x(i)` )
´ ³
x
(i)
` ¡Mi(x(i)` )
´T
,    (3) 
其中 w(i;i)`  是加權函數其利用cosθ在相似度測量(similarity measure) 的概念所定
義出來的，定義如下 
w
(i;i)
` = 1 ¡
(³
(i;i)
` )
r1PNi
t=1(³
(i;i)
t )
r1
,              (4) 
5 
 
Step 6) 對每個特徵向量進行調整vi = vi=
p
vTi S
CN
w vi後組成轉換矩陣
A = [v1; v2; : : : ; vp] 2 Rd£p. 
本研究使用的軟體為 MATLAB，適合矩陣式的數值運算，為加速計算速度與
kernel 版本之導出，我們重新 CNFE 推導為矩陣模式，請參考附錄一。 
B. 核方法(Kernel Method) 
自從 SVM 成功的被應用到各領域以後，核方法(kernel method)已經各研究領
域重要的理論之一。核方法主要的概念是：將原始資料藉由一個非線性函數映射
Á至一個合宜的特徵空間F (feature space)，亦即Á : Rd !F，理論上最好是讓資
料成為線性可分割(linearly separable)的空間，如下圖 3 所示。圖中意味著在特徵
空間的線性平面，在原始空間中代表著非線性的切割平面。因為直接在原始空間
中找到合適的非線性演算法比較不容易，而核方法是一個擴展線性演算法成為非
線性演算法的重要技巧且有著許多的優點，近來已經成為一項重要的技術。在計
算方面，利用核函數(kernel function)搭配原始空間中的資訊便能計算出特徵空間
中樣本與樣本之間的內積·(x; y) =< Á(x); Á(y) >，因此演算法經由適度的數學推
導即可利用核函數逕行相關的計算，毋須將資料一一映射到特徵空間，此即所謂
的 kernel trick [42]。因此，當選用不同的核函數和不同的參數都代表映射到不同
的特徵空間，再從演算法的表現即可瞭解資料是否映射到合宜的特徵空間。因此
不同特性的遙測資料，可以先藉由調整核函數及其對應之參數，找出適合此資料
型態的特徵空間後，再進行影像的特徵萃取與分類的工作。 
 
圖 3 利用一個非線性特徵函數Á(x1; x2) = (x21;
p
2x1x2; x
2
2)將原空間的樣本點映
到一個較高維度的特徵空間中 
令Á為一將樣本資料由原始空間Rd映射到特徵空間F (高維度甚至是無限高
維度空間)的非線性映射  
Á : Rd ! F ; x 7! Á(x) 
設L表樣本個數類別數， Ni為類別 i 的訓練樣本，所以
PL
i=1 Ni = N。令
X Ti = [Á(x(i)1 ); : : : ; Á(x(i)Ni)]和X T = [X T1 ; : : : ;X TL ]分別表示第i類映射後的資料矩陣
7 
 
machines (TSVMs) [42]和 graph-based methods [36]-[38]。  
SSL 有三個眾所周知來闡述 SSL 概念的合理性的假設。第一個是半監督平
滑假設(semi-supervised smoothness assumption)： “如果有兩個點x1與x2在所處的
空間中接近的話，那麼這兩個對應的輸出y1與y2也應該很靠近”。基於這樣的假
設，就可以將有限訓練樣本集(finite training set)擴充成為大的或是無限大的樣本
集。 第二個假設是：群聚假設(cluster assumption)，如果兩個點在同一個群聚的
話，他們應該是屬於同一個類別。群聚假設可視為半監督平滑假設的特例。第三
個假設是：流形(manifold) 假設，高維度資料可用一個低維度的流形來表徵。 事
實上，未判定的樣本未必保證能夠改善辨識效能[43]-[45]，也就是說，效能可能
因為對於資料模型的假設或是利用未判定的樣本取得的訊息或是類別錯誤而導
致下降, 唯有當模式正確或訊息引用正確時，效能才會提升。SSL 可視為監督式
與半監督式學習法的結合。通常，資料集X 2 R(l+u)£d 被分為兩個子集: 一個是
標 籤 化 的 樣 本 集 (labeled set) Xl = fx1; : : : ;xlg其 對 應 的 類 別 標 籤 為 
Yi = fy1; : : : ; ylg ； 另 一 個 為 未 標 籤 的 資 料 集 (unlabeled set) 
Xu = fxl+1; : : : ;xl+ug。 
自我訓練學習法是最常用的方法之一，開始時先用小量具類別的訓練樣本來
辨識未標籤化的測試樣本，使之成為半監督式樣本，然後再利用半監督式樣本來
健全辨識器的學習，可以採用增加半監督式樣本或更新標籤的方式來改善辨識器
的學習。在自我訓練學習法中，辨識器使用自己預測的樣本教自己學得更好，這
樣的方法通常也稱 self-teaching or bootstrapping [37].  
D. 模糊 K 最近鄰辨識器(fuzzy K-nearest neighbor classifier，簡稱 FKNNC) 
K 最近鄰辨識器(K-nearest neighbor classifier，簡稱 KNN) [47]，是概念簡單
且常用的非線性辨識器，其利用「近朱者赤，近墨者黑」的概念，找出距離測試
樣本z最近的 K 個訓練樣本之類別中最多者為z的類別，亦即採用投票法(majority 
vote)來決定z的類別。模糊 K 最近鄰辨識器(fuzzy K-nearest neighbor classifier，
簡稱 FKNN)[30]。引入模糊隸屬度(membership grade, MD)來加權距離，冀能提
升辨識率，其模糊化機制(fuzzification mechanism)定義如下： 
¹j(x
(i)
` ) =
½
0:51 + 0:49£ nj
k1
if j = i
0:49£ nj
k1
if j 6= i                 (10) 
其中x(i)` 表示在第i類中之第`個訓練樣本，k1為一給定常數，表示找x
(i)
` 附近k1個近
鄰來決定x(i)` 的隸屬度向量，nj表示在k1個樣本中屬於第j類的樣本數，所以可以
得到PLj=1 nj = k1。由(10)可以知道，因為x(i)` 類別已知，故最小的隸屬度訂為 0.51，
以處理周遭都是其他類別的樣本時，其隸屬度仍以該類別最高。因此每個訓練樣
本對應到一組隸屬度向量¹(x(i)` ) = [¹1(x(i)` ); : : : ; ¹L(x(i)` )]，事實上¹(x(i)` )包含的隸
屬度可將之分為組內隸屬度 (within-class membership grade)與組間隸屬度
(between-class membership grade)。如果¹i(x(i)` ) = 1則表示x(i)` 附近皆為同一類別的
樣本，一般而言x(i)` 可視為遠離分類邊界(classification boundary)的樣本點；反之，
9 
 
之樣本數，形成訓練樣本和測試樣本。 
  
11 
 
 
表 2 Salinas 資料集各類別所含有之圖素 
類別 類別名稱 圖素數 類別 類別名稱 圖素數
1 Brocoli_green_weeds_1 2009 9 Soil_vinyard_develop 6203 
2 Brocoli_green_weeds_2 3726 10 
Corn_senesced_green_we
eds 
3278 
3 Fallow 1976 11 Lettuce_romaine_4wk 1068 
4 Fallow_rough_plow 1394 12 Lettuce_romaine_5wk 1927 
5 Fallow_smooth 2678 13 Lettuce_romaine_6wk 916 
6 Stubble 3959 14 Lettuce_romaine_7wk 1070 
7 Celery 3579 15 Vinyard_untrained 7268 
8 Grapes_untrained 11271 16 Vinyard_vertical_trellis 1807 
合計：54129 
 
 
圖 6 Salinas 影像。左圖為 Sample band of SalinasUniversity dataset; 右圖為其
ground truth 
3. Pavia University 資料集 
Pavia University[48] (如圖 7 所示)資料集為一維度數 103，原影像大小為 610
圖素 x610 圖素資料，但有些資料因為並無訊息，捨棄後使用之影像大小為 610
圖素 x340 圖素，包含 9 個類別，共 42776 個樣本點，其餘為設定為背景，各類
類別名稱與對應之圖素數詳如表 3。 
   
50 100 150 200
50
100
150
200
250
300
350
400
450
500
50 100 150 200
50
100
150
200
250
300
350
400
450
500
13 
 
故，可以得到 
A = [v1; : : : ; vm] =XT [Ã1; : : : ; Ãm] =XTª,      (12)               
則 
AT S©wA = (X T ª)TX T WXX T ª = ªTXX T WXX T ª = ªT KWKª,   (13) 
同理， 
AT S©wA = ª
TK(B ¡W )Kª               (14) 
其中 K = XXT為核矩陣。如(17)所示，計算轉換矩陣A等同於計算ª。接著，我
們可以利用解廣義特徵值問題來得到Ãi: 
¸(KWK)Ãi = K(B ¡W)KÃi              (15) 
從上式可得知在特徵空間的特徵向量Ãi 可以由核矩陣K計算得到。  
接下來運用 GDA [22]中所使用的方式可以得到較佳的特徵值。首先，先對K
進行特徵值分解，假設K = P¡PT  帶入上式(18)，並乘上ÃTi 後可以得到 
¸ÃTi (P¡P
T WP¡P T )Ãi = Ã
T
i P¡P
T (B ¡W )P¡P T Ãi       (16) 
令 i¯ = ¡PTÃi，則¯i可以由解下列問題之廣義特徵值分解得到  
¸(PTWP )¯i = P
T (B ¡W)P¯i,             (17) 
顯而易見的，¯i為(PTWP)¡1PT(B¡W)P的特徵向量。 然而，矩陣(PTWP)¡1 
可能會奇異(singular)或接近奇異(nearly singular)，因此使用下方 regularization 來
減緩奇異問題(singularity problem) 
PTWP = (1¡ t)£ (PTWP) + t£ diag(PTWP ),      (18) 
其中 t 為正規化參數(regularization parameter)。一旦¯i取得後，Ãi = P¡¡1¯i就
可以被計算；同樣地，特徵空間的正規化特徵向量vi = Ãip
ÃTi KÃi
 就可以被算出，
所以轉換矩陣A就可得到。 
最後，測試樣本點z在特徵空間的投影向量可以被算出 
 < vi;©(z) >=
LX
i=1
NiX
`=1
®i`·(x
(i)
` ; z); for i = 1; : : : ;m.     (19) 
值得注意的是，我們可以發現投影向量可以藉由核函數計算得到，再次運用
kernel trick 個概念。 
在研究中，我們使用 Indian Pines 資料集來探究 KCNFE 的有效性。 有些類
別由於樣本數不夠，因此我們選定 9 個類別的樣本點，並將之隨機分為互斥的
4757 訓練樣本與 4588 測試樣本。我們設計三個實驗從整個訓練樣本集隨機選取
5%, 10% and 25%不同比率的訓練樣本，每個實驗重複 10 次，並計算其平均辨識
率與標準差。兩個線性特徵萃取 NWFE [17] 和 CNFE 與兩個基於核方法的特徵
萃取法 KNWFE [18]與 GDA 被引入來與 KCNFE 進行比較。另外，使用兩個非
線性辨識器 1NN 和 SVM 來辨識特徵萃取後的樣本。使用的核函數(kernel 
function)為 Gaussian RBF kernel。另外，為探究合成核函數的效益，我們根據核
15 
 
KNWFE 
(RBF) 
82.7 
(1.1, 11) 
86.1 
(1.0,15) 
90.1 
(0.4, 14) 
KCNFE 
(RBF) 
85.1 
(1.1, 14) 
89.1 
(0.9, 12) 
92.3 
(0.4, 15) 
KCNFE 
(RBF+SAM) 
84.6 
(0.6, 13) 
88.8 
(0.8, 11) 
92.3 
(0.5, 15) 
KCNFE 
(RBF×SAM) 
84.6 
(0.5, 13) 
89.1 
(0.7, 11) 
92.4 
(0.4, 15) 
上表結果整理如下： 
1) 不論使用何種辨識器，KCNFE 的效能在所有的情況下皆優於 CNFE 顯現非
線性特徵萃取法的研發確有其必要性。 
2) 不論使用何種辨識器，KCNFE 的效能亦優於其他的線性特徵萃取法與非線
性特徵萃取法，顯示其能萃取較優的特徵。 
3) 使用 SVM 當辨識器的效能優於使用 1NN 辨識器。 
4) 在大部分的情形下，KCNFE 的標準差都比較小，顯示 KCNFE 較穩定。  
5) 萃取超過L-1 個維度確有其必要性，因此無參數特徵萃取優於GDA與LDA。 
6) 使用合成核函數 RBF£SAM 的效益較使用單一核函數 RBF 穩定。 
7) 圖 8中紅色實線區塊顯示使用合成的核函數與使用單一核函數或線性特徵萃
取的差異；紅色虛線區塊顯示使用 KCNFE 與 CNFE 萃取法的差異。 
 
 
 
 
(a) CNFE+SVM (b) KCNFE(RBF)+SVM 
17 
 
丟棄，並設定acc0 = acc0 ¡ ±(± > 0)，以利重新選取新的候選集。由上述可以發
現，我們可以利用新的類別標籤Y^ (i+1)u 去選取新的X^(i+1)t ，且加入下次選取的樣本
的k折交叉驗證辨識率要比前次的還要高，確保更新的樣本可以讓系統更好，並
重複上述演算法，直到類別標籤不再變化或是疊代次數達到規定為止。綜合上述
所提出的演算法主要精神是利用 smoothness assumption與 cluster assumption的精
神，選取初始訓練樣本集中每個樣本附近的點來當半監督式樣本加入原本的訓練
樣本集來更新類別標籤，直到標籤穩定為止。此外，對於加入的半監督樣本使用
k-fold CV 辨識率來判定是否為有助於辨識的樣本。 
(a) SSCNFE 
本計畫所提出的半監督式演算法使用在 CNFE 使之成為半監督
(semi-supervised)CNFE，稱為 SSCNFE，則再進行部分修訂即可，SSCNFE 演算
法說明如下： 
Input: Xl, Yl, Xu, K 
Output: Y^  
Iterate 
Step 1) 根據初始訓練樣本集Xl = X(0)l ，利用Xl來計算 CNFE 的投影矩陣
A(i) 2 Rd£p，利用 KNN 辨識器來對投影後的p維訓練樣本與投影
後的p維測試樣本進行辨識，得到類別標籤Y^ (i)u  
Step 2) 計算訓練樣本集Xl投影後p維樣本的k-fold CV 辨識率, acc0. 
Step 3) 根據Y^ (i)u ,找到每個訓練樣本附近的t個測試樣本來組成半監督樣本
集X^(i)t μXu，並計算Xl [ X^(i)t 投影後的k-fold CV 辨識率acc(i)。若
acc(i) > acc0 則 Xl = Xl [ X^(i)t 且 設 定 acc0 = acc(i) ； 若
acc(i) <= acc0則acc0 = acc0¡ ± 
Step 4)利用新的Xl來計算新的 CNFE 的投影矩陣A(i+1) 2 Rd£p，KNN 利用
投影後的訓練樣本來對投影後的測試樣本進行辨識，得到新的類
別標籤Y^ (i+1)u 後，回到 Step 3 
Until convergence to Y^ (1)u  
Y^ = Y^
(1)
u  
 
為測試所提出之半監督式演算法，本研究將於 Indian Pines、Salinas 與 Pavia 
University 三個影像資料中隨機選取每個類別訓練樣本數為Ni = 3、Ni = 5與
Ni = 10，測試樣本皆為 400 個的情況下來測試所提出演算法的效果。每個試驗
將重複 10 次。試驗參數設定 KNN 辨識器的 K=1，計算 CV 辨識率維度訂在L-1
維，Ni=3 時，k = 3，Ni=5, 10 時，k=5，±=0.05。  
19 
 
 
(a) (b) (c) 
圖 9 CNFE 與 SSCNFE 在 10 個資料集訓練樣本數Ni = 3的情況下萃取 1-20 維時
每個維度的平均辨識率。 
 
圖 10 CNFE 與 SSCNFE 在 Pavia University 資料集每類訓練樣本數Ni = 3的 10
個隨選資料集的表現 
0 5 10 15 20
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
Averaged Results:paviaUN3T400
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.35
0.4
0.45
0.5
0.55
0.6
Number of Features
A
cc
ur
ac
y
Averaged Results:IndianPinesN3T400
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
Number of Features
A
cc
ur
ac
y
Averaged Results:SalinasN3T400
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
Number of Features
A
cc
ur
ac
y
paviaUN3T400d1
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d2
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d3
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d4
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d5
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d6
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d7
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d8
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d9
 
 
CNFE+1NN
SS-CNFE+1NN
0 5 10 15 20
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
Number of Features
A
cc
ur
ac
y
paviaUN3T400d10
 
 
CNFE+1NN
SS-CNFE+1NN
21 
 
Step 2) 利用 FKNN 辨識器計算訓練樣本集Xl的k-fold CV 辨識率, acc0.
Step 3) 根據Y^ (i)u ,找到每個訓練樣本附近的t個測試樣本來組成半監督樣
本集X^(i)t μXu，並計算Xl [ X^(i)t 的k-fold CV 辨識率acc(i)。若
acc(i) > acc0 則 Xl = Xl [ X^(i)t 且 設 定 acc0 = acc(i) ； 若
acc(i) <= acc0則acc0 = acc0¡ ± 
Step 4) FKNNC 利用新的Xl來對測試樣本進行辨識，得到新的類別標籤
Y^
(i+1)
u 後，回到 Step 3 
Until convergence to Y^ (1)u  
Y^ = Y^
(1)
u  
 
本研究將於 Indian Pines、Salinas 與 Pavia University 三個資料集中隨機選取
每個類別訓練樣本數為Ni = 5、Ni = 10與Ni = 20，測試樣本皆為 400 個的情況
下來測試所提出半監督式 FKNNC 演算法(稱為 SSFKNNC)的效果。為了比較
SSFKNNC 的有效性，另外兩個辨識器 KNNC 與 FKNNC 被用來與之作比較。本
研究中的參數設定所有 KNN 辨識器的 K=3, m=2，k1 = 3。計算 CV 辨識率時，
k=5，±=0.05。圖 13、圖 14 與圖 15 分別為在 Indian Pines、Pavia University 與
Salinas 影像資料上的表現，我們一樣可以發現 SSFKNNC 的表現優於其他兩個
辨識器。圖 16 為 KNNC、FKNNC 與 SSFKNNC 在 Pavia University 影像 10 個
資料集(Ni = 5)的 10 次疊代辨識率。另外，表 7 到表 9 為三個辨識器在三個影像
資料之 10個隨機資料集的平均辨識率與標準差。Indian Pines資料集上，在Ni = 5, 
Ni = 10與Ni = 20的情況下，分別有 5%、3.5%與 1.9%的差異；在 Pavia University
資料集上，分別有 2.3%、2%與 1.7%的差異；在 Salinas 資料集上，分別有 4.5%、
2.9%與 1.2%的差異。 
 
圖 13. KNNC、FKNNC 與 SSFKNNC 在 Indian Pines 資料集辨識率(Ni = 5) 
1 2 3 4 5 6 7 8 9 10
0.44
0.46
0.48
0.5
0.52
0.54
0.56
0.58
0.6
0.62
Dataset
A
cc
ur
ac
y
Dataset: IndianPines(Ni=5)
 
 
KNNC
FKNNC
SSFKNNC
23 
 
表 7 Indian Pines 資料集上的平均辨識率(“acc”)與標準差(“std”) 
Classifier 
Ni=5 Ni=10 Ni=20 
acc§std acc§std acc§std 
KNNC 49.4§2.7 57§2.1 64.1§0.9 
FKNNC 52.4§2.2 59.2§2.8 64.3§0.8 
SSFKNNC 57.4§2.5 62.7§2.1 66.2§1.2 
 
表 8 Pavia University 資料集上的平均辨識率(“acc”)與標準差(“std”) 
Classifier 
Ni=5 Ni=10 Ni=20 
acc§std acc§std acc§std 
KNN 70.1§1.7 72.9§1.6 76.3§1.1 
FKNN 71.3§1.8 73.5§1.7 76.2§1.0 
SSFKNN 73.6§1.7 75.5§1.9 77.9§1.3 
 
表 9 Salinas 資料集上的平均辨識率(“acc”)與標準差(“std”) 
Classifier 
Ni=5 Ni=10 Ni=20 
acc§std acc§std acc§std 
KNN 81.8§1.0 86.2§1.0 89.0§0.8 
FKNN 82.8§1.3 86.9§1.1 89.5§0.7 
SSFKNN 87.3§1.4 89.8§0.9 90.7§0.6 
五、結果與討論（含結論與建議） 
以往發展非線性特徵萃取法是比較困難的，然自從 SVM 利用核方法來建造
非線性辨識器的方式，開展了近一、二十年來核方法結合演算法的研發。在特徵
萃取領域 KPCA 與 GDA 的相繼出現，也代表了線性非監督式特徵萃取與線性監
督式特徵萃取法核化的里程碑，讓非線性特徵萃取法依附在線性特徵萃取法，成
為一體兩面的特徵萃取法。換句話說，只要發展出線性特徵萃取法，就可以藉由
kernel 技術推導成為核化的非線性特徵萃取法。 
本研究基於無參數特徵萃取法 CNFE 發展的 KCNFE 中相關推導過程，為監
督式無參數特徵萃取法提供一個演算的基礎架構；當然，由上述的實驗我們可以
發現在 Indian Pines 資料上面 KCNFE 的表現優於 CNFE，尤其是當使用合成核函
數時，更可得到較穩定的效果。 
另外，在半監督式演算法導入 CNFE 成為 SSCNFE 的實驗中，我們可以發
現，半監督式演算法可以讓 CNFE 的表現提升，且上升的速度較為在低維度時就
可以提升到相當的程度，獲致不錯的效益。當然，我們在本計畫中也將演算法應
25 
 
附錄 一 CNFE 的矩陣表徵 
 
Definition 1. The mean of the class j is 
mj =
1
Nj
NjX
k=1
x
(j)
k = X
T
j 1j 
where XTj = [x
(j)
1 ; : : : ;x
(j)
Nj
] and 1j = [1=Nj; 1=Nj; : : : ; 1=Nj]T 2 RNj. 
Definition 2. The local mean of x(i)`  in the class j is defined as 
 mj(x(i)` ) =
1
k
kX
s=1
x
(j)
sNN = X
T
j i
(j)
`   
where XTj = [x
(j)
1 ; : : : ;x
(j)
Nj
], i(j)` = [i1; : : : ; iNj ]
T ,8it 2 f1k ;0g; t = 1; : : : ;Nj and PNj
t=1 it = 1. 
 
 
Definition 3. The within-class scatter matrix of CNFE is defined as 
SCNw =
LX
i=1
Pi
NiX
`=1
w
(i;i)
`
³
x
(i)
` ¡mi(x(i)` )
´³
x
(i)
` ¡mi(x(i)` )
´T
  
where Pi is the prior probability of class i, and the weight function !
(i;i)
`  is 
 !(i;i)` = 1¡
³
(i;i)
`PNi
t=1 ³
(i;i)
t
 
with 
 ³(i;i)` =
¯¯¯
(x
(i)
` ¡mi(x(i)` ))T (x(i)` ¡mi)
¯¯¯
kx(i)` ¡mik2
. 
Definition 4. The between-class scatter matrix of CNFE is defined as 
 SCNb =
LX
i=1
Pi
LX
j=1;
j 6=i
NiX
`=1
w
(i;j)
`
³
x
(i)
` ¡mj(x(i)` )
´ ³
x
(i)
` ¡mj(x(i)` )
´T
 
where the weight function !(i;j)`  is 
27 
 
¯¯¯
(x
(i)
` ¡mj(x(i)` ))T (x(i)` ¡mj)
¯¯¯
= x
(i)
`
T
x
(i)
` ¡ x(i)`
T
mj ¡ (mj(x(i)` ))Tx(i)` + (M j(x(i)` ))Tmj
= kx(i)` k2 ¡ x(i)`
T
Xj1j ¡ (XTj i(j)` )Tx(i)` + (XTj i(j)` )T (XTj 1j)
= kx(i)` k2¡ < x(i)` ;Xj1j > ¡ < XTj i(j)` ;x(i)` > +(i(j)` )TXjXTj 1j
= kx(i)` k2¡ < x(i)` ;Xj1j > ¡ < XTj i(j)` ;x(i)` > +(i(j)` )TXjXTj 1j
 
Thus, we have ¯¯¯
(x
(i)
` ¡mj(x(i)` ))T (x(i)` ¡mj)
¯¯¯
 
= kx(i)` k2¡ < x(i)` ;Xj1j > ¡ < XTj i(j)` ;x(i)` > +(i(j)` )TXjXTj 1j 
Applying Lemma 5 and Lemma 6, the weights !(i;i)`  and !
(i;j)
`  can be computed via 
inner product.  
Theorem 7. Suppose that 
 ¤(i;i)W = diag(w
(i;i)
1 ; : : : ; w
(i;i)
Ni
), XT = [XT
1
; : : : ; XTL ] and I(i;i) 2RNi£Ni is a matrix 
with the `th row vector (i(i)` )T , ` = 1; : : : ;Ni, thus the within-class scatter matrix 
becomes 
SCNw = X
T WX , 
whereW = W1¡W2¡WT2 +W3, and 
W1 = diag(P1¤
(1;1)
W ; : : : ;PL¤
(L;L)
W ), 
W2 = diag(P1¤
(1;1)
W I
(1;1); : : : ;PL¤
(L;L)
W I
(L;L)), and 
W3 = diag(P1(I
(1;1))T¤
(1;1)
W I
(1;1); : : : ;PL(I
(L;L))T¤
(L;L)
W I
(L;L)), and  
(I(i;i))T = [i
(i)
1 ; : : : ; i
(i)
Ni
] 
Proof.  
The within-class scatter matrix SCNw  is given by 
SCNw =
LX
i=1
Pi
NiX
`=1
w
(i;i)
`
³
x
(i)
` ¡mi(x(i)` )
´ ³
x
(i)
` ¡mi(x(i)` )
´T
 
Since 
29 
 
¡[XT1 ; : : : ;XTL ]
264 P1(I
(1;1))T ¤
(1;1)
W 0
. . .
0 PL(I
(L;L))T ¤
(L;L)
W
375
264 X1...
XL
375 
¡[XT1 ; : : : ;XTL ]
264 P1(I
(1;1))T ¤
(1;1)
W I
(1;1) 0
. . .
0 PL(I
(L;L))T ¤
(L;L)
W I
(L;L)
375
264 X1...
XL
375
= XT (W1 ¡W2 ¡WT2 + W3)X = XTWX                            
where W1 = diag(P1¤(1;1)W ; : : : ; PL¤
(L;L)
W ); 
W2 = diag(P1¤
(1;1)
W I
(1;1); : : : ; PL¤
(L;L)
W I
(L;L)); and 
W3 = diag(P1(I
(1;1))T¤
(1;1)
W I
(1;1); : : : ; PL(I
(L;L))T¤
(L;L)
W I
(L;L)). 
Theorem 8. Suppose that  
¤
(i;j)
B = diag(w
(i;j)
1 ; : : : ; w
(i;j)
Ni
) 
The between-class scatter matrix becomes 
SCNb = X
T(B¡W)X, 
where B = B1 ¡B2 ¡BT2 +B3 and W = W1¡W2¡WT2 +W3,  
,B1 = diag(P1
LX
j=1
¤
(1;j)
B ; : : : ; PL
LX
j=L
¤
(L;j)
B ) 
B2 =
264 P1¤
(1;1)
B I
(1;1) : : : P1¤
(1;L)
B I
(1;L)
...
. . .
...
PL¤
(L;1)
B I
(L;1) : : : PL¤
(L;L)
B I
(L;L)
375, and 
B3 =
LX
i=1
Pi
264 (I
(i;1))T ¤
(i;1)
B I
(i;1) 0
. . .
0 (I(i;L))T ¤
(i;L)
B I
(i;L)
375
.
 
Proof. 
The between-class scatter matrix SCNb  is 
 SCNb =
LX
i=1
Pi
LX
j=1;
j 6=i
NiX
`=1
w
(i;j)
`
³
x
(i)
` ¡mj(x(i)` )
´ ³
x
(i)
` ¡mj(x(i)` )
´T
 
Applying the above deduced results, we obtain 
SCNb =
LX
i=1
Pi
LX
j=1;
j 6=i
NiX
`=1
w
(i;j)
`
³
x
(i)
` ¡mj(x(i)` )
´ ³
x
(i)
` ¡mj(x(i)` )
´T
 
31 
 
¡XT WX 
= [XT1 ; : : : ;X
T
L]
264 P1
PL
j=1 ¤
(1;j)
B 0
. . .
0 PL
PL
j=1 ¤
(L;j)
B
375
264 X1...
XL
375 
¡[XT1 ; : : : ; XTL ]
264 P1¤
(1;1)
B I
(1;1) : : : P1¤
(1;L)
B I
(1;L)
...
. . .
...
PL¤
(L;1)
B I
(L;1) : : : PL¤
(L;L)
B I
(L;L)
375 X 
¡[XT1 ; : : : ;XTL ]
264 P1(I
(1;1))T ¤
(1;1)
B : : : P1(I
(1;L))T¤
(1;L)
B
...
. . .
...
PL(I
(L;1))T ¤
(L;1)
B : : : PL(I
(L;L))T ¤
(L;L)
B
375 X 
+XT
(
LX
i=1
Pi
264 (I
(i;1))T ¤
(i;1)
B I
(i;1)) 0
. . .
0 (I(1;L))T ¤
(i;L)
B I
(1;L)
375)X 
= XT (B1 ¡B2 ¡BT2 + B3)X¡XTWX = XT (B¡W)X 
where 
B1 =
264 P1
PL
j=1 ¤
(1;j)
B 0
. . .
0 PL
PL
j=1 ¤
(L;j)
B
375, 
B2 =
264 P1¤
(1;1)
B I
(1;1) : : : P1¤
(1;L)
B I
(1;L)
...
. . .
...
PL¤
(L;1)
B I
(L;1) : : : PL¤
(L;L)
B I
(L;L)
375,  
B3 =
LX
i=1
Pi
264 (I
(i;1))T ¤
(i;1)
B I
(i;1) 0
. . .
0 (I(1;L))T ¤
(i;L)
B I
(1;L)
375, and 
and B = B1¡B2¡BT2 +B3. 
Thus, we justify 
SCNb = X
T (B ¡ W)X. 
  
33 
 
 
35 
 
 
  
37 
 
 
  
39 
 
 
41 
 
REFERENCES 
[1] G. F. Hughes, “On the mean accuracy of statistical pattern recognizers,” IEEE 
Trans. Inf. Theory, vol. IT-14, no. 1, pp. 55–63, Jan. 1968. 
[2] D. A. Landgrebe, Signal Theory Methods in Multispectral Remote Sensing, John 
Wiley and Sons, Hoboken, NJ: Chichester, 2003. 
[3] P.K. Varshney and M.K. Arora, Advanced Image Processing Techniques for 
Remotely Sensed Hyperspectral Data, Springer, Berlin: 2004. 
[4]  S. Goldman and Y. Zhou, “Enhancing supervised learning with unlabeled data”. 
In Proceedings of the Seventeenth International Conference on Machine 
Learning, San Francisco, CA, 2000, pp.327-334. 
[5]  J. Crook and J. Banasik, “Sample selection bias in credit scoring models”. 
International Conference on Credit Risk Modeling and Decisioning, Philadelphia, 
PA, 2002. 
[6]  Q. Jackson and D.A. Landgrebe, “An Adaptive Classifier Design for 
High-Dimensional Data Aanlysis with a Limited Training Data Set”, IEEE 
Geoscience and Remote Sensing, vol. 39, no. 12, pp. 2664-2679, 2001. 
[7] O. Chapelle, N. Schölkopf and A. Zien (Eds.), Semi-supervised Learning. MIT 
Press: Cambridge, 2006. 
[8] B-C. Kuo and D. A. Landgrebe, “A Covariance Estimator for Small Sample Size 
Classification Problems and Its Application to Feature Extraction,” IEEE 
Transactions on Geoscience and Remote Sensing, vol. 40, no. 4, pp. 814-819, 
2002. 
[9] J-M. Yang, P-T. Yu, and B-C. Kuo, ”A Nonparametric Feature Extraction and Its 
Application to Nearest Neighbor Classification for Hyperspectral Image Data,”  
IEEE Transactions on Geoscience and Remote Sensing, vol.48, no.3, pp. 1279 - 
1293, Mar. 2010. 
[10]  B-C. Kuo and D. A. Landgrebe, “Regularized Covariance Estimators for 
Hyperspectral Data Classification and Its Application to Feature Extraction,” 
International Geoscience and Remote Sensing Symposium, June 24-28, 2002. 
[11]  T.K. Ho, “The Random Subspace Method for Constructing Decision Forests,” 
IEEE Trans. Pattern Anal. Mach. Intell., vol. 20, no. 8, pp. 832-344, Aug., 1998. 
[12]  M. Skurichina and R. P. W. Duin, “Bagging, Boosting and the Random Subspace 
Method for Linear Classifiers,” Pattern Analysis & Applications, vol. 5, no. 8, pp. 
121-135, 2002. 
[13]  E.J. Ferreira and R.C.T. Pereira, “Random subspace method for analysing coffee 
with electronic tongue,” Electronics Letters, vol. 43, no. 21, pp. 1138 – 1139, 
2007. 
[14]  B-C. Kuo, H-C. Liu, Y-C. Hsieh, and R-M. Chao ; “A random subspace method 
43 
 
ftp://ftp.ecn.purdue.biehl/PC_Multispec/ThyFiles.zip (ground truth) 
[29] J. Ham, Y. Chen, M. Crawford, and J. Ghosh, “Investigation of the Random 
Forest Framework for Classification of Hyperspectral Data,” IEEE Trans. Geosci. 
Remote Sens., vol. 43, no. 3, pp. 492-501, March 2005. 
[30] J. M. Keller, M. R. Gray, and J. A. Givens, Jr., “A fuzzy K-nearest neighbor 
algorithm,” IEEE Trans. Syst., Man, Cybern., vol. SMC-15, no. 4, pp. 580-585, 
Jul./Aug. 1985. 
[31] J. Kennedy and R.C. Eberhart, “Particle Swarm Optimization,” Proc. IEEE 
International Conf. Neural Networks, vol. 4, pp. 1942-1948, 1995. 
[32] A. S. Milman, Mathematical Principles of Remote Sensing: Making Inference 
from Noisy Data, Sleeping Bear Press: 1999. 
[33] B-C. Kuo and D.A. Landgrebe, “Nonparametric weighted feature extraction for 
classification,” IEEE Trans. Geosci. Remote Sens., vol. 42, no. 5, pp.1096-1105, 
May 2004. 
[34] O. Chapelle, J. Weston and B. Schölkopf , “Cluster Kernels for Semi-Supervised 
Learning”, Advances in Neural Information Processing Systems, vol. 15, pp. 
585-592, 2003. 
[35] D. Tuia, G and Camps-Valls, “Semisupervised Remote Sensing Image 
Classification with Cluster Kernels”, IEEE Trans. Geosci. Remote Sens. Letters, 
vol. 6, no. 2, pp.224-228, Apr. 2009. 
[36] G. Camps-Valls, T. Bandos, and D. Zhou, “Semi-Supervised Graph-Based 
Hyperspectral Image Classification,” IEEE Trans. On Geoscience and Remote 
Sensing, vol. 45, no. 10, pp.3044-3054, 2007. 
[37] X. Zhu, “Semi-Supervised Learning Literature Survey,” Computer Sciences TR 
1530. University of Wisconsin- Madison, 2008. 
[38]  S. Liu, X. Zhao, J. Zou and H. Xu, “A Semi-Supervised Approach Based on 
k-Nearest Neighbor,” Journal of Software, vol. 8, no. 4, pp.768-775, 2013. 
[39] Y. Song, F. Nei, C. Zhang and S. Xiang, ” A unified framework for 
semi-supervised dimensionality reduction,” Pattern Recognition, vol. 41, pp. 
2789-2799, 2008. 
[40] C. Rosenberg, M. Hebert, & H. Schneiderman, “Semi-supervised self-training of 
object detection models,” Seventh IEEE Workshop on Applications of Computer 
Vision, 2005, pp.29-36. 
[41] T. Mitchell, “The Role of Unlabeled Data in Supervised Learning,” in 
Proceedings of the Sixth International Colloquium on Cognitive Science. San 
Sebastian, Spain, 1999. 
[42] V. N. Vapnik. Statistical learning theory. John Wiley & Sons, 1998. 
[43] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell, “Text classification from 
國科會補助計畫衍生研發成果推廣資料表
日期:2014/01/29
國科會補助計畫
計畫名稱: 基於無參數特徵萃取法之高光譜遙測影像資料分類之技術研發
計畫主持人: 楊晉民
計畫編號: 100-2218-E-142-002-MY2 學門領域: 航太技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
