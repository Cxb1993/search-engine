 2
obtained for various noise ratios. In fact, 
the filter does not need to exploit the 
threshold parameter for fuzzy filtering. 
With this new filtering framework, the 
proposed filter can perform significantly 
better than other median-based filters in 
terms of both noise suppression and detail 
preservation. Furthermore, the new filter 
also shows its excellent robustness at 
different impulsive ratios. 
 
二、支撐向量機法(SVMs)：  
Support vector machines (SVMs) 
have been recently proposed as new kinds 
of feedforward networks for pattern 
recognition because of their high 
generalization capability without priori 
knowledge. Based on the structure risk 
minimization, the support vector machine 
is a classifier used to find the hyperplane 
that maximizes the margin between 
classes. Without loss of generality, the 
theory of SVMs can be illustrated through 
a two-class classification problem. In this 
work, the SVM technique will be 
employed to classify a signal as either 
noise-corrupted or noise-free. 
Let },,1),,{( Niyx ii   be a 
training data set of N  data points, where 
n
i Rx   and }.1,1{iy  The training 
goal of the SVM is to find an optimal 
hyperplane that maximally separates of 
training data set Into two classes. The 
margin can be seen as a measure of the 
generalization ability; that is, the larger 
the margin, the better the generalization 
expected. The optimization problems in 
linearly inseparable and nonlinearly 
inseparable cases are discussed as follows. 
For the linearly inseparable case, the 
optimal classification hyperplane is found 
by solving the following quadratic 
programming (QP) problem: 
min 

 N
i
iCWWJ
1
2
2
1),(   
s.t.  ,1][ iii bxWy          (2.1) 
,,,2,1,0 Nii   
where W  is a weight vector, i  is a 
non-negative variable, b  is a bias of 
hyperplane and C  is a predefined 
positive constant. The optimization 
problem (2.1) can be rewritten as 
max 


 N
i
ijij
N
ji
iji xxyyM
11,2
1)(   
s.t. ,0
1


i
N
i
i y                  (2.2) 
   .,,2,1],,0[ NiCi   
By solving (2.2), we can get the optimal 
hyperplane 
.0
1


bxxy
N
i
iii             (2.3) 
Therefore, the linearly inseparable 
discrimination function is in the form 
)(xf sgn ],[
1
bxxy ii
N
i
i 

      (2.4) 
where sgn    stands for the bipolar sign 
function and nonnegative variables i  
are the Lagrange multipliers. 
For the nonlinearly inseparable case, 
the original data is projected into a certain 
high dimensional Euclidean space H  by 
a nonlinear map .: HRn   The 
kernel function ),( ji xxK  is introduced 
such that it is not necessary to get to the 
bottom of )( . Hence, the optimal 
decision can be found by solving the 
following dual problem 
max 
),(
2
1)(
1 11
j
N
i
N
j
ijiji
N
i
i xxKyyQ 
 
   
s.t. ,0
1


N
i
ii y                 (2.5) 
.,,2,1,0 NiCi    
By solving (2.5), we can get the optimal 
hyperplane with the maximal margin 
.0),(
1


bxxKy
N
i
iii           (2.6) 
Therefore, the nonlinearly inseparable 
discrimination function that separates the 
training data into two classes is in the 
 4
integer weight, and )(10 kxw n  means 
that there are 0w  copies of input pixel 
)()( 1 kxkx n . 
Definition 3: )()()( 3 kckxkl  .   
Definition 4: )()()( 5 kckxke  .   
If the variable )(kl  is applied, then a 
pixel on an edge component in the filter 
window }{kw  will not be detected as 
noise because of the small )(kl  value. In 
addition, if the variable )(ke  is applied, 
then a pixel on a line component in the 
filter window }{kw  will not be detected 
as noise because of the small )(ke  value. 
In this work, according to the above 
three feature variables )(),( klkc  and 
)(ke , the feature vectors are given by 
))(),(),((}{ keklkckf  .          (3.1) 
The feature vectors }{kf  serve as the 
input data set to the SVM impulse detector. 
This feature information will be also used 
in the filtering stage. 
3.2.2 Training the SVM classifier 
The optimal separating hyperplane 
can be obtained through a training process 
by using a set of supervised class labels 
for the training corrupted image. The 
input in the training process is the set of 
unsupervised features }.{kf Figure 3 
shows the feedforward network 
architecture of the SVM impulse detector 
that identifies noise-free pixels and noise- 
corrupted pixels. This efficient design can 
minimize the risks of misclassification not 
only in the training set (i.e. training errors) 
but also in the test set (i.e. generalization 
errors). 
3.3 Noise filtering 
If the input pixel is classified as 
impulsive noise according to its SVM 
detector )(k , then the proposed fuzzy 
averaging (FA) filter is activated. 
Otherwise, the input pixel is not replaced. 
Since non-homogeneous neighborhoods 
may exist in the filter window, it is better 
to incorporate the knowledge of the other 
pixels to improve the filtering 
performance. This is where the fuzzy 
approach comes into play. The output 
)(' ky of the first-pass filter for the input 
)(kx  is given by 
 )())(1(
)(
)()(
)()(
1
1' kxk
km
kmkx
kky S
f
f
S
f
ff
 



 .            
(3.2) 
Each )(kx f  is multiplied by a 
corresponding weight )(km f  indicating 
in which degree the pixel should be used 
to filter the central pixel ).(kx  To obtain 
the weight )(km f , we have constructed a 
fuzzy set called SIMILAR. The fuzzy set 
is represented by the membership function 
SIMILAR shown in Fig. 4, denoted as 
SIMILAR . The membership value indicates 
to which degree a certainty difference 
value to )(kROM can be considered as a 
similar to the observed neighborhood. 
Now, the weight )(km f is defined as 
)).(()( kdifkm fSIMILARf    
   To calculate the )),(( kdif fSIMILAR  we 
first compute the rank-ordered mean value 
(ROM) difference gray level )(1 kd  in the 
window }{kw  as follows: 
)()(1
1
kdifkd
S
f
f

     (3.3) 
where )()()( kROMkxkdif ff   is the 
difference gray level between )(kx f  and 
the rank-ordered mean value in the 
window }{kw . In addition, the parameter 
)(2 kd  in  Fig. 4 can be decided as 
follows: 
        )(1)1()(2 kdkd          (3.4) 
where the parameter   is empirically set 
to be 0.2 for the best choice. Therefore, 
the larger the parameter )(1 kd , the larger 
the uncertainty interval )](2),(1[ kdkd  
should be. Finally, the corresponding 
 6
removal of impulse noise from highly 
corrupted images,” IEEE Trans. 
Circuits Syst.-II: Analog and Digital 
Signal Processing, vol. 46, pp. 78-80, 
1999. 
[4] T.-C. Lin and P.-T. Yu, “Adaptive 
two-pass median filter based on 
support vector machine for image 
restoration,” Neural Computation, 
vol. 16, pp. 333-354, 2004. 
[5]  T. Sun and Y. Neuvo, 
“Detail-preserving median based 
filters in image processing,” Pattern 
Recognition Letters, vol. 15, pp. 
341-347, 1994. 
[6] R. Garnett, T. Huegerich, C. Chui and 
W. He, “A universal noise removal 
algorithm with an impulse detector,” 
IEEE Trans. Image Processing, vol. 11, 
pp. 1747-1754, 2005. 
[7] K. Arakawa, “Median filters based on 
fuzzy rules and its application to 
image restoration,” Fuzzy Sets and 
Systems, vol. 77, pp. 3-13, 1996. 
[8] T.-C. Lin and P.-T. Yu, “Partition fuzzy 
median filter based on fuzzy rules for 
image restoration,” Fuzzy Sets and 
Systems, vol. 147, pp. 75-97, 2004. 
[9] T.-C. Lin and P.-T. Yu, “Thresholding 
noise-free ordered mean filter based 
on Dempster-Shafer theory for image 
restoration,”  IEEE Trans. Circuits 
and Systems-I: Regular Papers, vol. 
53, pp. 1057-1064, 2006. 
[10] L. Zadeh, “A simple view of the 
Dempster-Shafer theory of evidence 
and its implication for the rule of 
combination,” AI Mag., vol. 7 pp. 
85-90, 1986. 
[11] P. Smets, “The combination of 
evidence in the transferable belief 
model,” IEEE Transactions on 
Pattern Analysis and Machine 
Intelligence, vol.12, pp. 447-458, 
1990. 
[12] T. Chen, K. K. Ma and L. H. Chen, 
“Tri-state median filter for image 
denoising,” IEEE Trans. Image 
Processing, vol. 8, pp. 1834-1838, 
December 1999. 
[13] S. Le Hégarat-Mascle, D. Richard 
and C. Ottlé, “Multi-scale data fusion 
using Dempster-Shafer evidence 
theory,” Integrated Computer-Aided 
Engineering, vol. 10, pp. 9-22, 2003. 
[14] S. Schulte, V. D. Witte, M. 
Nachtegael, D. V. der Weken and E. 
E. Kerre, “Fuzzy random impulse 
noise reduction method,”  Fuzzy 
Sets and Systems, vol. 158, pp. 
270-283, 2007. 
[15] T.-C. Lin, “Progressive decision- 
based mean type filter for image 
noise suppression,” Computer 
Standards & Interfaces, vol. 30, pp. 
106-114, 2008. 
[16] Tzu-Chao Lin, “Partition belief 
median filter based on 
Dempster-Shafer theory in image 
processing,” Pattern Recognition, vol. 
41, issue 1, pp. 139-151, January 
2008. 
[17] Tzu-Chao Lin, Mu-Kun Liu and 
Chien-Ting Yeh, “Two-pass 
switching filter based on 
modification of Dempster’s 
combination rule for fuzzy image 
restoration,” IEEE World Congress 
on Computational Intelligence 
(FUZZ-IEEE 2008), Hong Kong, 
June 1-6, 2008. 
[18] Tzu-Chao Lin, Mu-Kun Liu and 
Chien-Ting Yeh, “A new ART-LMS 
neural network for the image 
restoration,” the 15th International 
Conference on Neural Information 
Processing (ICONIP 2008), 
Auckland, New Zealand, Nov 25-28, 
2008.
 8
 Feature 
Extraction 
SVM impulse 
Detector 
Fig. 1. SVM impulse detector. 
)(kx  SVM 
Training )(k  
              
 
(b) Second-pass filter. 
Fig. 2. The noise filtering process of the proposed filter. 
)(k  SVM 
Detector 
)(k  Decision 
Detector 
)(ky  
Fuzzy 
Filter 
 
)(kx  
(a) First-pass filter. 
Switch 
)(' ky  
ROM 
Filter 
 
Switch 
)(' ky  
 
 
 10
   
             (a)                                (b) 
   
             (c)                                (d) 
   
             (e)                                (f) 
Fig. 5. Subjective visual quality of restored image ‘Cameraman’ (a) original image, (b) 
corrupted image by 20% random-valued impulse and filtered by (c) MED filter, (d) FM 
filter, (e) ATM filter, and (f) New filter. 
 
 12
可供推廣之研發成果資料表 
 可申請專利   可技術移轉                                 日期： 年 月 日 
國科會補助計畫
計畫名稱：型態二模糊理論與支撐向量機法之智慧型分類學習機制
之分析與設計和影像復原系統之應用 
計畫主持人：林子超         
計畫編號：NSC 97-2221-E-274 -010-  學門領域：人工智慧 
技術/創作名稱  SVM-fuzzy-based 影像復原系統 
發明人/創作人 林子超 
技術說明 
中文： 
     基於支撐向量機法，使用特徵萃取技術，處理不精確、含糊、
及不確定之資訊，以判斷影像之像素是否受污染，即設計一有效的
雜訊偵測器—SVM-based 之影像濾波器，以解決影像復原時會破壞
細微影像之現象。基於模糊理論(fuzzy theory)、可能度理論
(possibility theory)，使用 ART 類神經網路分類學習機制，設計
一自適性的 ROM 濾波器(adaptive ROM filter)，增進決策式濾波
器的效能。 
 
英文： 
    This novel filter basically employs an SVM impulse detector to 
judge whether an input pixel is noisy or not. If a noisy pixel is detected, 
the fuzzy filter is triggered to replace it. Otherwise, it keeps unchanged. 
Then, to improve the quality of the restored image, an adaptive ROM
filter based on fuzzy theory is activated. The optimal weights of the 
adaptive ROM filter are obtained by using ART neural network. 
Experimental results demonstrate that our scheme outperforms other 
decision-based median filters in terms of both noise suppression and 
detail preservation.  
可利用之產業 
及 
可開發之產品 
資訊工業相關產業； 
訊號處理、影像復原系統及影像濾波器。 
技術特點 效能比傳統方法佳。 
推廣及運用的價值 具推廣價值於影像感應處理器上。 
 
附件二 
09:00-10:40  Session S2 [robotics, Malborough 2] (paper ID 5, 10, 17, 20) chair: Y. Jin  
10:40-11:00  Coffee served 
11:00-12:00  Session S3 [pattern recognition, Marlborough 1] (paper ID 6, 8, 13), chair: L. Patel 
11:00-12:00  Session S4 [neuroevolution, room Marlborough 2] (paper ID 7, 18, 21), chair: G.Marcus 
12:00-12:10  Closing of the NNN08 (Marlborough 1) 
12:30-13:30  Lunch served 
ICONIP 2008  
Tue, 25.11  
Tutorials     
08:50-10:30  Tut1 (I. Farkas, NZ3), T2 (J. Sima, NZ4), 
10:30-10:50  Coffee served 
10:50-12:30  T3 (A. Leung, NZ3), T4 (L.Benuskova, NZ4) 
12:30-13:30  Lunch served   
13:30-13:45  Opening, Chair N. Kasabov, NZ1-2 
13:50-14:40  Plenary 1 (A,B): K.Doya  NZ1-2,  L.Xu NZ3 
14:50-15:30  Invited 1 (A,B,C):  A.Cichocki NZ1-2, B.Gabrys NZ3, M.Paulin NZ4 
15:30-15:50  Coffee served 
15:50-17:30  Parallel sessions TuA1 (1 NZ1-2, 2 NZ3, 3 NZ4, 4 Marlb1, 5 Marlb2, 6 Marlb3):
17:30-17:40  Break 
17:40-19:00  Parallel sessions TuA2 (1,2,3,4,5,6) 
19:00-22:00  APNNA Board meeting 
Wed 26.11. 
08:50-09:40  Plenary 2 (A,B): Amari NZ1-2, Villa NZ3 
09:50-10:30  Invited 2 (A,B,C):  R.Duro NZ1-2, S. B Cho NZ3, Naryanan NZ4 
10:30-10:50  Coffee served    
10:50-12:30  Parallel sessions WM (1,2,3,4,5)  + Panel 1 (NZ1-2) 
12:30-13:30  Lunch  served 
13:30-14:20  Plenary 3 (A,B): Yamakawa NZ1-2, Mandic NZ3 
14:30-15:10  Invited 3 (A,B,C): W.Duch NZ1-2, Y.Kadobayashi NZ3, G.Marcus NZ4 
15:10-15:30  Coffee served, 
15:30-16:50  Parallel sessions WA1 (1,2,3,4,5,6) 
16:50-17:00  Break 
17:00-18:00  Parallel sessions WA1 (1,2,3,4,5,6) 
18:00-19:00  Poster session and demonstrations 
19:30-22:30  Banquet and awards 
Thu 27.11.  
08:50-09:40  Plenary 4 (A,B): Usui NZ1-2,  Koenig NZ3,  M.Harvensalo NZ4 
09:50-10:30  Invited 4 (A,B,C):  Jun Wang NZ1-2,  Y. Jin NZ3, R.Klette NZ4 
10:30-10:50  Coffee served 
10:50-12:30  Parallel sessions ThM (1,2,3,4,5)  + Panel 2 (NZ1-2) 
12:30-13:30  Lunch  served 
A New ART-LMS Neural Network for the Image Restoration  
Tzu-Chao Lin, Mu-kun Liu, Chien-Ting Yeh 
 
Department of Computer Science and Information Engineering 
Wufeng Institute of Technology, Chiayi, Taiwan 62153, R.O.C. 
 tclin@mail.wfc.edu.tw 
Abstract. A novel neural network design–the adaptive resonance theory least mean square (ART-LMS) neural network–is 
proposed for the restoration of images corrupted by impulse noise. The network design is based on the concept of 
counterpropagation network (CPN). There is a vigilance parameter the ART network uses to automatically generate the 
cluster layer node for the Kohonen learning algorithm in CPN. In addition, the LMS learning algorithm is used to adjust the 
weight vectors between the cluster layer and the output layer for the Grossberg learning algorithm in CPN. The advantages of 
the ART-LMS network include an effective solution to the initial weight problem and a good ability to handle the cluster 
layer nodes for the CPN learning process. Experimental results have demonstrated that the proposed filter based on 
ART-LMS outperforms many well-accepted conventional as well as new filters in terms of noise suppression and detail 
preservation.  
Keywords: neural network; adaptive resonance theory; filter; impulse noise.  
1   Introduction 
Efficient removal of impulse noise from digital images has been important preprocessing tasks that must be carried out without 
harming the image details [1]. Neural networks have been a growing research interest in recent years, especially when it comes 
to nonlinear filtering techniques for image restoration. The network models include the backpropagation (BP), self-organizing 
feature map (SOFM) and counterpropagation network (CPN) models, etc. [2-6].  
The competitive learning algorithm of the CPN Kohonen layer is a gradient-based unsupervised learning algorithm. It works 
best when the patterns are tightly clustered in distinct groups. However, under such a design, a neuron’s initial weight vector 
can be located so far away from any input vectors that it is far from being competitive and therefore never learns. To make a 
difference, in this paper, we shall propose a new neural network called ART-LMS where the Kohonen layer and Grossberg 
layer in CPN are replaced by the adaptive resonance theory (ART) and least mean square (LMS) algorithm, respectively [7-8].  
Since the center weighted median (CWM) filters fail to suppress noise to a satisfactory degree while preserving image 
details [10], we propose a neural-based CWM (NCWM) filter with an adjustable center weight. The adaptive weight for 
efficient removal of impulse noise without distorting image details that the proposed filter features is controlled by the 
ART-LMS neural network. The ART-LMS neural network is employed to obtain the optimal center weight. Experimental 
results demonstrate that the new filter based on the ART-LMS neural network outperforms many well-accepted conventional 
as well as new filters in terms of both noise suppression and detail preservation. 
The rest of this paper is organized as follows. Section 2 is the illustration of the ART-LMS neural network. Section 3 
describes how ART-LMS works to achieve image restoration. Then, Section 4 presents the results of some extensive 
experiments. Finally, Section 5 offers our conclusions. 
2   ART-LMS Neural Network  
Based on the framework of the CPN, we have developed the ART-LMS network to design the weight controller of the 
proposed NCWM filter. Figure 1 shows the topology of a three-layered ART-LMS network. The first layer is for input, the 
second is the competitive layer (ART layer), and the third is the layer of output nodes (LMS layer).The nodes in each layer are 
as Fig. 1 shows, fully interconnected to the nodes in the adjacent layer. The cluster layer can determine whether a new training 
pattern should be classified into a specific cluster or a new node should be automatically generated depending on the vigilance 
parameter. This way, unlike what happens with conventional unsupervised learning algorithms, the appropriate initial weights 
can be automatically obtained [11]. 
The nodes in the cluster layer compete (winner-take-all) for the input vector to be classified. The node with the largest 
similarity jS is the winner and sends a signal 1 to the output layer. Then, only the weight vector piw  from the winner ( p -th 
node) in the cluster layer to the input layer is updated by using the following learning rule. 
                                                       




0)1(,0
0)1()),(()()(
)1(
tw
twtwxntw
tw
pi
pipipi
pi

                                                    (1) 
where the learning rate )(n  is a function of the learning epoch n , such as )1()( 0 T
nn   , defined with a predetermined 
constant 0.10 0    and the total number of learning epochs .T  Notably, the weight vectors to the loser nodes stay 
unchanged.  
Meanwhile, only the weight in the output layer connected to the winner node is updated by using the least mean square 
(LMS) learning algorithm. The learning rule updates the weight kpv  from the output layer to the cluster node as follows.  





0)1(,0
0)1(|,||)(|)()(
)1(
tv
tvdxtentv
tv
kp
kpkp
kp

                                                (2) 
where the learning rate )(n  is also a function of the learning epoch ,n  such as )1()( 0 T
nn   , defined with a 
predetermined constant 0.10 0    and the total number of learning epochs .T  The variable x  is the real corresponding 
input value, and the error )(te  is the difference between the desired output d  and the physical output .ky  In order to improve 
the convergent speed, the algorithm iterates the process until the average difference of the distortion mean square error ( AMSE ) 
falls below a threshold .  
3   Image Restoration by ART-LMS  
A. 3.1 The Structure of the NCWM Filter   
Let }1,1|),{( 2121 WkHkkkC   denote the pixel coordinates of the noisy image corrupted by impulse noise, where 
H  and W  are the image height and width, respectively. Let )(kx  represent the input pixel value of the noisy image at location 
.Ck  At each location ,k  the observed filter window }{kw  whose size is 12  nN ( n  is a non-negative integer) is defined 
in terms of the coordinates symmetrically surrounding the input pixel )(kx . 
},,,1,,,2,1:)({}{ Nnnfkxkw f                                                              (3) 
where the input pixel )()( 1 kxkx n  is the center pixel. The output of the CWM filter is }),{()( kwMEDky cc  where MED  
denotes the median operation and odd c  ),,5,3,1( Nc   denotes the center weight. Now we have 
)},(,),(),(),(,),({}{ 211 kxkxkxckxkxkw Nnnnc                                        (4) 
where   represents the repetition operation. That is, the CWM filter outputs the median value of those cn 2  pixel values. 
However, the non-adaptive CWM filter processes the whole noisy image in a uniform way, making room for excessive or 
insufficient smoothing. To fix the drawback of lack of flexibility, the center weight c  in ],0[ N  is made adjustable within the 
filter window }{kwc  by using the proposed ART-LMS network. 
The framework of the proposed NCWM filter is illustrated in Fig. 2. It is composed of three parts: an observation vector for 
feature extraction, an ART-LMS weight controller, and a CWM filter. At first, according to the feature extraction result for the 
input vector, the ART-LMS weight controller gives the weight c  to the CWM filter. To improve the filtering performance, the 
noise filtering procedure is progressively applied through several iterations.  
                        
  
 
 
 
 
 
Feature 
Extraction 
Input 
)(kx  
Output
)(ky
ART-LMS
Weight 
Controller
CWM 
Filter 
}{kF  c
Iteration 
Fig. 2. The structure of NCWM filter. 
                   
                                  
Table 1. Comparative restoration results in MSE and MAE for 20% impulse noise. 
Images 
Goldhill Boat Lake Couple Lena Filters  
MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE 
MED 69.51 4.84 62.89 3.92 106.69 5.71 99.11 5.43 43.69 3.46 
CWM [10] 71.31 3.72 69.23 3.12 107.02 4.34 93.15 4.23 51.86 2.76 
FM [12 ] 43.25 3.05 44.24 2.73 73.33 3.68 70.81 3.48 32.34 2.43 
PFM [1] 36.76 2.52 36.05 2.24 62.81 3.16 64.94 2.86 24.66 1.94 
ACWM [13] 36.08 2.41 35.31 2.05 61.48 2.89 61.43 3.02 25.26 1.81 
CPN [4] 50.84 3.68 47.41 3.02 82.58 4.40 84.02 4.40 30.84 2.58 
NCWM 35.14 2.35 34.12 2.00 58.74 2.79 59.92 2.98 23.42 1.74 
 
 
                         
50
60
70
80
90
100
110
120
5 15 35 55 75 95 115 135 155 300
cluster number
M
S
E
    
                           Fig. 3. MSE versus cluster number for the training process. 
 
                       
30
60
90
120
150
180
210
240
270
300
330
1 2 3 4 5 6 7 8 9 10 50
epoch number
M
S
E
         
                                 Fig. 4. MSE versus epoch number for the training process. 
5.   Conclusions  
In this paper, a novel neural network for image restoration is proposed, and a new filter built on top of the proposed ART-LMS 
network is presented to preserve more image details while effectively suppressing impulse noise. ART-LMS is a 
self-organizing neural network on the basis of adaptive resonance theory (ART) and least mean square (LMS) algorithm. 
ART-LMS uses the vigilance to dynamically create the cluster layer nodes. Thus, LMS algorithm is employed to obtain the 
optimal center weight for each cluster independently. Owing to the optimal weight of each cluster, the mean square error of the 
filter output can be minimized. The experimental results have demonstrated that the new NCWM filter is superior to a number 
of conventional as well as new filters in terms of the noise suppression and image detail preservation. 
 
Acknowledgment 
