 I 
Table of Content 
一、 中文摘要   .............................................................................................................................. 1
二、 英文摘要(Abstract)   ............................................................................................................. 1
三、 背景和目的  ........................................................................................................................... 1
四、 研究方法   .............................................................................................................................. 2
1. Algorithm/architecture co-design   ..................................................................................... 2
2. Algorithm exploration   ....................................................................................................... 3
3. Algorithmic intrinsic complexity metrics extraction   ........................................................ 4
1) Number of operations.   ................................................................................................... 4
2) Degree of parallelism.   .................................................................................................... 4
3) Pipeline depth:.   .............................................................................................................. 4
4) Memory size and configuration   ..................................................................................... 4
5) Data transfer and bandwidth.   ....................................................................................... 5
4. Architecture exploration   ................................................................................................... 5
1) Software/Hardware partition.   ....................................................................................... 5
2) Tradeoff between bandwidth and internal buffer based on various dataflow.   ........... 6
3) Clock frequency   ............................................................................................................. 6
4) Architecture exploration formulation   ........................................................................... 7
5. Dataflow model   .................................................................................................................. 8
五、 結果與討論  ........................................................................................................................... 9
1. First year   ............................................................................................................................ 9
2. Second year   ........................................................................................................................ 9
3. Third year   .......................................................................................................................... 9
六、 相關著作   ............................................................................................................................ 10
七、 參考文獻   ............................................................................................................................ 10
 2 
the concept of electronic system level (ESL) 
design methodologies and tools. Intellectual 
property (IP) appears to be a reusable compo-
nent for reducing design time costs, but how to 
optimize and integrate many of these IPs re-
mains challenging.  
 There exists a gap between the different 
considerations of algorithm and architecture 
designs. Algorithm designs focus on an appli-
cation’s performance and time complexity, but 
they cannot be realistically implemented on 
Very Large Scale Integration (VLSI). The time 
complexity metric omits too much information 
to represent the cost of the architectural imple-
mentation. Besides, when the algorithm is de-
cided, the design space is limited by the opti-
mization degree of SoCs [15]. If we use tradi-
tional waterfall design methodologies [16] in 
system design, failures in the integration of 
hardware and software may result or a physical 
specification may not be produced. 
Figure 1 shows a system composed of all the 
feasible VLSI implementation instances for a 
specific application. Its design space is com-
posed of an n-tuple of space spanned by several 
parameters or decisions made in each abstrac-
tion level of the design flow. The design details 
are added, when design at the lower abstraction 
level. The different design spaces are separated 
by system specification, algorithmic subspace 
exploration, architectural subspace exploration, 
micro-architecture subspace exportation, and 
circuit/refinement subspace exploration/design.  
We present a novel ESL AAC methodology 
[1][2][3] to concurrently explore the design 
space of algorithms and architectures based on 
intrinsic complexity extraction and analysis, 
which exhibits essential architectural informa-
tion in early design phases. The intrinsic com-
plexity, whose definitions include the number 
of operations, memory configuration, memory 
bandwidth, data transform, pipeline depth, and 
degree of parallelism [1], is more compact than 
traditional time complexity in system design. 
The different data granularities and dataflows 
[8] allow us to explore the architecture imple-
mentation cost [4]. To rapidly and automatical-
ly explore the architectural space, we develop a 
CAD tool that provides an intrinsic complexity 
analysis, and dataflow and architectural cost 
factors for emerging platforms, such as ASIC 
and reconfigurable architectures. 
四、 研究方法 
1. Algorithm/architecture co-design 
To develop a specific application, the design 
space used is a set representing all of the realis-
tic solutions for a VLSI implementation. The 
design subspace is therefore spanned by dif-
ferent attributes and contains various instances 
or realizations at distinct levels of abstraction. 
As the design goes into lower abstraction levels, 
more and more details are involved, and the 
subspace of lower abstraction levels becomes 
larger and larger. System designs shield the de-
sign details at higher levels of abstraction for 
complicated SoC designs. Therefore, traditional 
system designs generally use top-down design 
methodologies to gradually explore each level 
of abstraction. To avoid limiting low level de-
sign spaces and increase flexibility, we extract 
some important design factors at low levels and 
combine the optimal processes of algorithms 
and architectures. The floorplan of the physical 
design is also considered because the intercon-
nection delay is the most important factor that 
influences performance in nanotechnology. The 
spirit of algorithm and architecture co-design is 
based on the ability to concurrently explore al-
gorithm and architectural spaces and extract 
intrinsic complexity metrics to characterize 
significant architectural information that can be 
back-annotated in the early design phases (Fig. 
3). The back-annotated data can reduce design 
costs and explore optimal solutions incessantly. 
Figure 2 illustrates the design flow of our 
proposed AAC methodology in detail. The re-
quirements of a specific application are defined 
and the system design takes into account design 
constraints. For example, in compression, users 
specify profiles and levels. Using specifications 
to find the minimal cost is the designer’s 
Fig. 1 Level of abstraction 
 4 
 
3. Algorithmic intrinsic complexity me-
trics extraction 
After algorithm exploration, architecture de-
signers can analyze the intrinsic complexity 
metrics that provide important factors for map-
ping the algorithm to the architecture. The me-
trics to be used in software-hardware partition-
ing must not be biased toward either the soft-
ware or hardware. We select crucial complexity 
characteristics based on the following:  
1) Number of operations: The first step 
to analyze the algorithm is to estimate the 
number of operations per second for real-time 
systems. The various operations represent 
different performances and power 
consumptions of multi-format platforms. We 
also separate addition, subtraction, 
multiplication, division, shift, absolute value, 
and logical operations. For profiling on the 
central processing unit (CPU), different CPU 
cycles are used according to the instruction set. 
For ASIC or reconfigurable architectures, 
various operations will consume distinct cells 
or configurable logic blocks. Division is the 
most complicated arithmetic operation because 
it can be implemented by both substraction and 
addition. Shifts, which are the easiest 
operations, can be performed by simply using 
the interconnect. Logical operations, such as 
larger than, equal to, or smaller than, use bits 
comparisons to implement.  
The precision must also be considered in 
complexity analyses because the gate-count and 
power consumption are related to the bit width. 
Specifications for the algorithm performance 
determine the precision of the system. Fixed-t 
or floating-points are also important features 
for intrinsic complexity characterization. 
2) Degree of parallelism: The degree of 
parallelism is a significant research topic 
because it is related to issues of high 
performance or low powers for architecture 
designs. The data processing dependency 
decides the degree of parallelism. If the 
algorithm provides good performance, it 
generally has a lower degree of parallelism. To 
implement on hardware, the metric reveals the 
maximum processing element and analyzes the 
datapath. To implement on software, designers 
can choose a suitable CPU architecture, such as 
very long instruction word (VLIW), single 
instruction multiple data (SIMD), and 
multi-core platforms. The parallelism is 
transparent to either software or hardware.  
Figure 5 shows a four-tap finite impulse re-
sponse filter. If we use only an adder and a 
multiplier, four cycles are required to complete 
all the operations. We also can sacrifice the 
more areas like four adders and four multipliers 
to use one cycle. The high degree of parallelism 
increases the throughput of the application. 
Thus, we can obtain the original throughput 
and spread the maximum degree of parallelism 
to decrease the supply voltage by utilizing a 
low power design. 
3) Pipeline depth: Data processing can 
maybe processed several times, it should be 
stored for providing any stage to use. For 
example,  Fig. 6 produce the local buffer to 
store the result. Beside, pipeline depth sets the 
lower bound of the clock rate for real-time 
system. 
4) Memory size and configuration: 
According to algorithm requirements, data 
must be stored in the memory to process 
updates and feedback. In the system, the 
memory configuration corresponds to specific 
algorithms. Lifetime analysis can estimate the 
memory size. The key point here is that the 
data must store, fetch, and configure using the 
optimal methods. If the design is implemented 
in hardware, some data can be saved in the 
local memory in a manner based on the 
pipelines, which is also based on the dataflow 
of the algorithm. If the algorithm is performed 
in software, this metric can facilitate the data 
arrangement for the cache system of the CPU. 
After determining the memory configuration, 
the kind of memory to be used, such as SRAM, 
registers, and register files, to support the 
application must also be determined. Memory 
information must be known prior to 
software/hardware partitioning. 
Fig. 3 Algorithm/Architecture Co-exploration 
 6 
 
Since the datapath of the hardware modules 
are composed of the PEs, the designers can 
roughly estimate the gate-count of each module. 
We introduce how to perform hard-
ware/software partitioning by the proposed 
architectural exploration scheme in the follow-
ing subsection. 
2) Tradeoff between bandwidth and 
internal buffer based on various dataflow: 
Due to the multimedia processing needs 
amount of memory to store the intermediate 
data, the data store in the internal memory or 
external memory according to the data size. 
In a two-dimensional filter, for example, we 
can process a one-dimensional filter twice to 
complete the function of the two-dimensional 
filter. We must store the results of the 
row-dimension, and then fetch more data to 
process the column-dimension, as shown in Fig. 
7. For high resolution image processing, the 
intermediate data is usually too large to store in 
the internal memory. Therefore, we need 4N2 
times to fetch the external memory without the 
use of an internal memory. The internal memo-
ry is more expensive than the external memory, 
but has better good performance. Hence, there 
exists a tradeoff between reducing the cost and 
maintaining the speed of the system. Figure 8 
shows a line-based process, and we can use the 
size of the L-1 line buffer to complete the 
two-dimensional filter. Figure 8 uses the inter-
nal buffer to reduce the memory access by 2N2 
times.  
 
 
Energy is a big issue in the global environ-
ment. Power consumption is defined as the 
energy used per second. Therefore, the reduc-
tion of power consumption can save energy.  
In the SoC, the largest power consumption 
comes from the computational operations and 
data transactions over the bus. [17] reduces 
unnecessary on-chip and off-chip memory 
access to achieve power efficiency. Designers 
use embedded memory to reduce the required 
external memory bandwidth based on the da-
taflow models with various processing granu-
larities and histories of dataflow. The system 
architects are faced with a tradeoff between the 
internal memory size and bandwidth. The 
memory configuration of the SoC can be fur-
ther optimized by carefully considering the 
access speed and the memory capability. 
After determining the required bus and ex-
ternal memory bandwidth, the bus width can be 
calculated according to the clock speed. Note 
that the data width of the external memory is a 
very important cost which we cannot ignore 
because this factor affects the number of the 
I/O pins of the chip package and the APR re-
sults. 
3) Clock frequency: From the 
complexity metrics, we can determine the 
number of operations and how many cycles are 
required to execute the complete task. The total 
number of cycles per second can be estimated 
for real-time applications. This information will 
give us the appropriate required clock 
frequency. The pipeline depth and memory 
configuration will affect clock frequency if 
increasing the degree of parallelism can lower 
the clock speed or scale down the supply 
voltage for low power application. 
To easily control the complete system mod-
ule, we synchronize the module using the same 
clock domain. It is economical to implement 
the phase lock loop to adjust different clock 
speeds. One then needs to identify the hot 
module, which requires the maximal clock 
Fig. 6 Pipeline Finite Impulse Response Filter 
Fig. 7 Directed row-column processing 
Fig. 8 Line based row-column processing 
 8 
implementation cost weighting factors for 
memory. As mentioned in the previous subsec-
tion, designers can trade off between bandwidth 
and memory by adjusting nlocal_bus, ncentral_bus, 
nlocal_mem and nexternal_mem to obtain an optimal 
memory hierarchical configuration. 
4.4 Overall architectural complexity:  
, , ,
1
( )
N
architecture comp j tran j mem j
j
C C C C
=
= + +∑       (4) 
We collect the sum of total architecture com-
plexities presented by the equation(4). N is the 
total tasks of the algorithm. The subscript j 
standards for the jth task of the algorithm. 
For the specific application, we define the 
different cost weighting factors, α, β, and γ. 
The Lagrange optimization approach solves the 
constrained problem. Finally, the optimal pa-
rameters ci,j, ri,j, nlocal_bus,j, ncentral_bus,j, nlocal_mem,j, 
and nexternal_mem,j are derived, and the optimal 
architectural complexity of the algorithm is ob-
tained. The term α can be estimated from the 
area information for hardware or the software 
execution. The term  β can be estimated by 
physical information, while the term γ can be 
obtained from the price of the DRAM or em-
bedded memory. The solution helps us to find 
the optimal architectural design for the specific 
application. 
5.   Dataflow model 
The dataflow is the trajectory of data 
processing; it records the history of data. We 
can use the dataflow for algorithm/architecture 
co-exploration, since it provides the bridge that 
links the specific algorithm and the architecture, 
allowing the algorithm to be mapped to the ar-
chitecture. The architecture can be any form of 
multi-format platform. The dataflow can be ca-
tegorized as coarse grain or fine grain because 
of the concepts of level of abstraction and data 
granularity. We construct the dataflow from a 
high level of abstraction, similar to how archi-
tect depicts the blueprint of buildings from low 
levels of abstraction. This is identical to the 
top-down design 
Traditionally, the algorithm designer uses a 
programmable language to model the behavior 
of the algorithm. The programmers who correct 
the uniformity of the algorithm and the pro-
gram usually ignore practical implementation. 
Hence, high level synthesis, which transfers the 
behavior model to register transfer level mod-
eling (RTL), does not achieve good efficiency 
because it includes a wide gap between the al-
gorithm and architecture. To solve this problem, 
we use the high level of abstraction to depict 
coarse grain data processing, which features a 
high level dataflow. After constructing the high 
level dataflow, the designer verifies the high 
level dataflow model in a manner similar to the 
behavioral model. We can analyze the dataflow 
to refine intrinsic complexity metrics, such as 
number of operations and degree of parallelism. 
Using lifetime analysis, the dataflow can be 
used to estimate the upper boundary of the 
memory size. The fine grain dataflow is estab-
lished to evaluate the system clock speed and 
bandwidth. As such, the dataflow plays a cru-
cial role in the AAC methodology.  
Many models have recently described dataf-
lows, such as directed acyclic graph, Kahn 
processing networks [18], YAPI [19], dataflow 
Fig. 9 Generic SoC model 
 10 
specification and constraints are provided, the 
CAD tool can generate various graph forms to 
comply with the design constraints. The various 
graph forms reveal the important architectural 
information for implementation. In summary, 
the CAD tool can rapidly map algorithms to 
architectures using design constraints. We pro-
duced a dataflow that can help not only verify 
but also extract the algorithm intrinsic com-
plexity metrics and architectural information to 
map the multi-format platform. 
We expect this sub-project to develop into an 
AAC methodology for highly efficient elec-
tronic system levels to effectively analyze al-
gorithm performance and explore the costs of 
architecture. Our laboratory used the AAC me-
thodology to analyze multi-format architectures 
and co-operation with another sub-project to 
build the Transaction Level Modeling (TLM) 
and virtual software/hardware platforms. Fi-
nally, we refined the TLM model to verify 
FPGA and post-simulation for tape out, and 
developed the CAD tool to automatically per-
form the design space exploration for system 
designers. The AAC has a systematic metho-
dology to enhance the yield of tape out inte-
grated circuits and reduce the difficulty of 
complex system implementation. We com-
pleted all of the above proposed achievements 
and participated in the MPEG standard confe-
rence in the last three years. The proposed AAC 
methodology plays a significant role for elec-
trical system level design technology.  
六、 相關著作 
[1] Gwo Giun (Chris) Lee, Yen-Kuang Chen, Marco 
Mattavelli, and Euee S. Jang, “Algo-
rithm/Architecture Co-Exploration of Visual Com-
puting on Emergent Platforms: Overview and Future 
Prospects,” IEEE Trans. on Circuits and Systems for 
Video Technology, Vol.19, Iss. 11, pp. 1576-1587, 
Nov. 2009. 
[2] G. G. Lee, M. J. Wang, H. Y. Lin and R.L. Lai, “On 
the efficient algorithm/architecture co-exploration 
for complex video processing,” IEEE International 
Conference on Multimedia & Expo, ICME 2008, 
June 2008. 
[3] Gwo Giun Lee, Ming-Jiun Wang, Bo-Han Chen, 
Jiun-Fu Chen, Ping-Keng Jao, Ching-Jui Hsiao, 
Ling-Fei Wei, “Reconfigurable Architecture for 
Deinterlacer based on Algorithm/Architecture 
Co-Design.,” Journal of Signal Processing Systems, 
special issue on reconfigurable video coding, Jun. 
2009. 
[4] J. Gorin, M. Raulet, Y-L. Cheng, H-Y. Lin, N. Siret, 
K. Sugimoto and G.G. Lee, "An RVC Dataflow De-
scription of the AVC Constrained Baseline Profile 
Decoder," IEEE International Conference on Image 
Processing (ICIP2009).  
[5] Gwo Giun Lee, Chia-Cheng, Lo, Yuan-Ching, Chen, 
He-Yuan Lin, and Ming-Jiun Wang, “High 
Throughput Low-cost VLSI Architecture for 
AVC/H.264 CAVLC Decoding,” IET Image 
processing, Vol. 4, Iss. 2, pp. 81-91, Apr. 2010. 
[6] G. G. Lee, C. C. Lo, Y. C. Chen, S. F. Lei, H. Y. Lin 
and M. J. Wang, “Low Complexity and High 
Throughput VLSI Architecture for AVC/H.264 
CAVLC Decoding,” IEEE International Symposium 
on Circuits and Systems (ISCAS2009). 
[7] G. G. Lee, B. H. Chen, H. Y. Lin, M. J. Wang, R. L. 
Lai, Y. L. Cheng and J. W. Liang, “Algorithm and 
architecture design for wide Range ELA deinterlac-
er,” IEEE International Symposium on Circuits and 
Systems (ISCAS2009). 
七、 參考文獻 
[8] J. W. Janneck, D. Miller and D. B. Parlour, “Profil-
ing dataflow programs,” Proceeding of IEEE ICME 
2008, pp. 16065-1068, June 2008. 
[9] L. Cai, and D. Gajski, “Transaction level model-
ing: an overview,” Proceedings of the 1st 
IEEE/ACM/IFIP international conference on Hard-
ware/software codesign and system synthesis, pp. 
19-24, Oct. 2003. 
[10] T. Grotker, S. Liao, G. Martin, and S. Swan, “System 
Design with SystemC,” Kluwer Academic Publish-
ers, 2002. 
[11] AMBA Specification (Rev 2.0). ARM, Ltd. 
[12] Theo A. C. M. Claasen, “An industry perspective on 
current and future state of the art in system-on-chip 
(SoC) technology”, Proceedings of the IEEE, vol. 94, 
no. 6, pp. 1121-1137, Jun. 2006 
[13] G.G. Lee, E. S. Jang, M. Mattavelli, and C. J. Tsai, 
“Text of ISO/IEC FCD 23001-4 Codec Configura-
tion Representation,” ISO/IEC JTC1SC29/WG11, 
MPEG w9772, Archamps, France, April, 2008. 
[14] Y. S. Tung, G. G. Lee, E.S. Jang, S. Lee, K. Asai, Y. 
Yamada, and M. Mattavelli, “Text of ISO/IEC FCD 
23002-4 Video Tool Library,” ISO/IEC JTC1SC29/ 
WG11, MPEG w9774, Archamps, France, April, 
2008. 
[15] N. Zhang, “Algorithm/architecture co-design for 
wireless communications systems,” Ph.D. disserta-
tion, EECS, University of California, Berkeley, USA, 
July, 2001. 
[16] Michael Keating, Pierre Bricaud, “Reuse Metho-
dology Manual”, Kluwer Academic Publishers, 
2002. 
[17] Finchelstein, D.F.  Sze, V.  Chandrakasan, A.P., “” 
[18] Gilles KAHN, “The Semantics of a Simple 
Language for Parallel Programming”, Information 
Processing 74, North-Holland Publising, 1974. 
[19] E. A. de Kock, W. J. M. Smits, P. van der Wolf, J.-Y. 
Brunel, W. M. Kruijtzer, P. Lieverse, K. A. Vissers, 
and G. Essink, “YAPI: Application modeling for 
signal processing systems,” in Proc. Design Auto-
mationConf., Los Angeles, CA, 2000, pp. 402–405. 
[20] E.A. Lee and T.M. Parks, “Dataflow process net-
works,” Proceedings of the IEEE, vol. 83, pp. 
773–801, 1995.
 12 
(18) Circuits and Systems for Wearable Computing 
 
本屆 ISCAS會議的進行方式含有論文口頭報告（lecture session）與壁報
發表（poster session），與會者可依興趣與專長選擇適合的場次聽講及發問。
會議主要討論的議題有：(1) Circuits, (2) Multimedia, (3) Biomedical, (4) Ana-
log, (5) Nonlinear, (6) Life-Science, (7) Live, (8) Nano-electronics, (9) Digital, 
(10) Neural, (11) Computer-Aided, (12) Power, (13) VLSI, (14) Visual, (15) Sen-
sory。 
筆者在參加會議期間，發表論文口頭報告，其題目為“Reconfigurable 
Architecture Design of Motion Compensation for Multi-Standard Video Cod-
ing”，透過與會人士的討論，能夠了解目前各國的研究與發展趨勢，不僅獲
益良多，亦得到相當的啟發。 
二、與會心得 
IEEE電路與系統之國際研討會 (2010 IEEE International Symposium on 
Circuits and Systems, ISCAS )是國際上相當著名的研討會，參與會議之成員皆
具有相當高的水準，會議宗旨主要在電路與系統設計之發展與創新並了解在
相關領域之前瞻性研究，在參與此次會議的過程中，透過學術與技術之討
論，了解目前國際上多媒體技術與電路及系統設計的發展趨勢，對於從事數
位積體電路設計或相關領域的研究人員可以藉由此會議得知目前最熱門之
研究方向，並可與會議人士在討論的過程中得知更多經驗，對於日後的研究
發展有相當程度的幫助。此會議討論內容相當廣泛，筆者參與此次會議後，
獲得很多與本人有相關研究方向的資訊與靈感，並且擔任會議主持與發表論
文，讓各國了解目前台灣在積體電路與多媒體相關研究之發展與水準，希望
能在此會議中所得到的多媒體相關之先進技術引進國內，以幫助國內多媒體
相關產業與學術研究有更進一步的發展，在此，特別感謝國科會給予的支持
以及鼓勵。 
 
 14 
TABLE I. Using adders and shifters to implement tap values 
Tap value Operation 
20 16(<<4) + 4(<<2) 
-6 4(<<2) + 2(<<1) 
-5 4(<<2) + 1(<<0) 
3 2(<<1) + 1(<<0) 
 
 L1
L2
L3
L-1
L-2
L-3
+
+
+
+
+16
+4 (-)
+
4
interpolated 
sample
L2
L3
L4
L-2
L-3
L-4
+
+
+
+
+16
+4 (-)
+
4
interpolated 
sample
L1
L -1
+
2
+
+
(-)
2
8
= n times n
MPEG4 : 8- tap FIR filter 
 { 20(L4＋L -4 )－6(L3＋L-3 )＋3(L2＋L-2)－(L1＋L-1) }<<3 
H.264 : 6- tap FIR filter 
20(L3＋L -3 )－5(L2＋L-2 )＋(L1＋L-1)   
Figure 1. Basic interpolation operations of both H.264 and MPEG-4 
operations of both H.264 and MPEG-4, and identifies the commonal-
ity parts in the corresponding color. Next, MPEG-2 and MPEG-4 
support half-sample interpolation for both luma and chroma predic-
tions. The interpolation algorithm directly adopts the simple bilinear 
filter to generate the prediction values and can easily be combined to 
the filter architecture mentioned above. 
To utilize the maximum common operation and minimize the im-
plementation cost, a three-stage recursive interpolation [10] is applied 
to chroma prediction in H.264. The recursive bilinear calculation is 
performed in the four quadrants of the section, according to the frac-
tional sample location indicated by the motion vector, to interpolate 
the fractional sample. Each stage can generate four neighboring sam-
ples for the next stage. After three stages, the result of interpolated 
values can be obtained. Speaking globally, the foregoing operations 
only utilize adders and shifters to accomplish the MC interpolation 
and design a multi-standard reconfigurable processing element by 
combination of extracted commonality of different video standards.    
Bandwidth Reduction Strategy 
Huge bandwidth demand is essential issue for video motion 
compensation, especially supporting H.264 and B picture feature, 
because of the variable block size and six-tap fraction sample inter-
polations. In this section, two bandwidth reduction strategies are 
mainly presented to improve the external bandwidth requirement. 
First, we reuse the reference data previously fetched from external 
memory to reduce the access times according to different macroblock 
partition type [4]. Reusing the reference data of overlapped region is 
an essential bandwidth reduction strategy.  Second, the reference 
data can be fetched according to interpolation block classification. 
That is, the interpolation of different fractional-sample positions may 
require different reference block size. For example, some fractional 
sample only needs the horizontal reference data and does not require 
the vertical filtering during interpolation process. Therefore, only 
(M+5)xN reference data, not (M+5)x(N+5),  needs to be fetched 
from the external memory for interpolating one MxN block in H.264. 
Therefore, we can control the motion compensation to fetch a smaller 
and essential reference data and the number of memory access can be 
reduced.  
Design Space Exploration 
During design space exploration, the potential problems such as 
bandwidth bottleneck can be identified in the early stage of the design 
period. In this paper, we mainly evaluate the data granularity such as 
16x16, 8x8, and 4x4 block size based on algorithm commonality 
analysis, bandwidth reduction strategy, and the parallel processing of 
four-sample interpolation. Different data granularities will require the 
different input buffer size and bandwidth requirement. Besides, 
bandwidth requirement and the internal buffer size are also consi-
dered for supporting B picture mode. After the evaluation of the 
above issues, we employ 4x4 data granularity for data regular 
processing method of MC. The 4x4 data granularity can not only 
achieve the bandwidth reduction strategy, but also has a reasonable 
input buffer size. 
Based on the proposed commonality analysis, described in Sec-
tion A, and the adopted 4x4 data granularity, complexity analysis of 
algorithm can be implemented to not only clarify how many opera-
tions have to be performed but also provide the estimation numbers 
of processing elements. In the proposed MC method, only operations 
of additions and shifts are needed to employ. The number of addition 
operations is more critical than the one of shift operations in target 
design. We have calculated out the number of addition operations 
based on picture types (P or B picture) and color format of MPEG-2, 
MPEG-4 and H.264 to understand the algorithm complexity. By 
arranging data flow, we can further gain the accuracy of data order 
and functionality, and required cycles for different supported cases. 
The latency of pre-fetch the reference data of first 4x4-size block in 
MPEG-2, MPEG-4 and H.264 are 8, 11 and 12, respectively. Consi-
dering the B picture mode, the required cycle number of each stan-
dard is shown in Table II. The information of required cycles pro-
vides the essential information for architecture implementation and 
even evaluation of design clock rate and bandwidth. 
PROPOSED MC ACHITECTURE DESIGN AND IMPLEMENTATION 
Fig.2 shows the block diagram of the proposed architecture. The 
function unit, named parameter controller, receives the MB parameter 
information including motion vectors and offers the imperative con-
trol flow to related blocks based on these parameters. The function 
unit, named data communication, determines which position of in-
ternal memory the reference data need to be stored and also control 
the mechanism of reference data reuse. The internal memory unit, 
which consists of 896-byte memory, can provide enough space to 
store the reference data for interpolation. The data feeder arranges the 
required reference data and then feeds them into the interpolator. The 
interpolator function unit which is a critically reconfigurable archi-
tecture provides the interpolation function according to the corres-
ponding control signals. 
TABLE II.  Required cycles for processing B picture  
Standard Required Cycle Number (cycles/sec) 
MPEG-2 244800(MB/sec)*256(cycles/MB)+8 = 62,668,808 
MPEG-4 244800(MB/sec)*448(cycles/MB)+11 = 109,670,411 
H.264 244800(MB/sec)*384(cycles/MB)+12 = 94,003,212 
 
 
Data feeder 
Interpolator 
Data 
communication 
Output buffer 
Internal 
memory 
Parameter
controller 
Reference data 
MB Parameter 
Information 
Interpolation result  
Figure 2. Block diagram of the proposed MC architecture 
Major MC Function Units Description 
Based on 4x4 data granularity, the overall overhead of data 
alignment is in the data feeder. There are two main components in the 
 16 
 
+ + 
+ 
+ + 
+ 
<<1 
+ 
<<4 <<2 <<2 <<1 
+ 
(-) 
(-) 
L1 L-1 L2 L-2 L3 L-3 L4 L-4 
+ 
 
 
<<3 
+ 
PIPE LINE 
 
Figure 6. PE configuration for MPEG-4 luma interpolation 
IMPELEMENTAION RESULT AND COMPARISON 
The proposed architecture design has been implemented in Veri-
log HDL and synthesized to gate level which can operate at 108MHz 
using TSMC 0.18um technology library. To verify the function cor-
rectness during the whole top-down design methodology, we also 
develop the behavior C model to simulate top-level data flow of the 
proposed method. In addition, we trace the reference software of 
MPEG-2 [11], MPEG-4 [12] and H.264 [13] to generate the input test 
patterns and golden output values from them. The input test patterns 
is used to simulate the top-level data flow model and compare the 
results with the golden output values to ensure the data flow model is 
correct. Similarly, the verification flow also is accomplished using 
Verilog-XL simulator during both RTL and gate level design stages.  
Due to the extraction of maximum commonality, the proposed 
interpolator only uses the required operators of luma interpolation of 
MPEG4 from the viewpoint of hardware resource. The comparison of 
adder number for one pixel is listed in Table III and 53% adders are 
reduced. Besides, the comparison between our wok and previous 
works is shown in Table IV. In this table, the total area of proposed 
interpolator is larger than [8]. The main cause is that the B picture 
mode is supported in our work and more storage elements are needed.  
Finally, our work can not only support both P and B picture, but also 
support MC decoding of MPEG-2, MPEG-4, and H.264 using effi-
cient hardware resource. 
CONCLUSION 
In this paper, we propose a reconfigurable MC architecture for 
multi-standard video standards, MPEG-2, MPEG-4 and H.264, based  
TABLE III. Comparison of the number of adder 
 Required adder  total Reduction Ratio 
MPEG2 5 
28 53% MPEG4 13 H.264 10 
Proposed 13 13 
on the top-down design methodology. MC algorithm analysis is per-
formed among the three standards to extract the maximum commo-
nality of MC algorithm of targeted video standards. Next, we explore 
the design space and arrange regular data flow which can be applied 
to multiple standards. Based on the algorithm analysis and design 
space exploration, a reconfigurable PE that only involve shifters, 
adders and multiplexes can be accomplished. Basic and efficient 
bandwidth reduction strategies are introduced to reduce the memory 
access times. Finally, we have developed a reconfigurable motion 
compensator has significant reduction of area compared with sum-
ming-up of all three standards, independently.   
References 
[1] Iain E. G. Richardson, H.264 and MPEG-4 Video Compression: Video 
Coding for Next-generation Multimedia. John Wiley and Sons, 2003, 
ISBN 0470848375, 9780470848371 
[2] ISO/IEC 13818-2, Information Technology – Coding of moving 
pictures and associated audio, 1996. 
[3] ISO/IEC 14496-2, Information Technology – Coding of moving 
pictures and associated audio, 2001. 
[4] Yu Li, Yun He, “Bandwidth Optimized and High Performance 
Interpolation Architecture in Motion Compensation for H.264/AVC 
HDTV Decoder,” Journal of Signal Processing Systems, vol. 52, no. 2, 
2008, pp. 111-129, Aug. 
[5] S. Z. Wang, T. A. Lin, T. M. Liu, and C. Y. Lee, “A New Motion 
Compensation Design for H.264/AVC Decoder,” in Proc. of Int. 
Symposium on Circuits and Systems (ISCAS’05), 2005, pp. 4558–4561. 
[6] Chuan-Yung Tsai; Tung-Chien Chen; To-Wei Chen; Liang-Gee Chen, 
"Bandwidth optimized motion compensation hardware design for 
H.264/AVC HDTV decoder," Circuits and Systems, 2005. 48th 
Midwest Symposium on , vol., no., pp.1199-1202 Vol. 2, 7-10 Aug. 
2005. 
[7] Azevedo, A.; Zatt, B.; Agostini, L.; Bampi, S., "Motion Compensation 
Decoder Architecture for H.264/AVC Main Profile Targeting HDTV," 
Very Large Scale Integration, 2006 IFIP International Conference on , 
vol., no., pp.52-57, 16-18 Oct. 2006. 
[8] Junhao Zheng; Wen Gao; David Wu; Don Xie, "A novel VLSI 
architecture of motion compensation for multiple standards," Consumer 
Electronics, IEEE Transactions on , vol.54, no.2, pp.687-694, May 
2008. 
[9] Chih-Da Chien; Ho-Chun Chen; Lin-Chieh Huang; Jiun-In Guo, "A 
low-power motion compensation IP core design for MPEG-1/2/4 video 
decoding," Circuits and Systems, 2005. ISCAS 2005. IEEE 
International Symposium on , vol., no., pp. 4542-4545 Vol. 5, 23-26 
May 2005. 
[10] Kai Luo, Dong-xiao Li, Ming Zhang, “High Throughput Bandwidth 
Optimized    VLSI Design for Motion Compensation in AVS HDTV 
Decoder,” J Zhejiang Univ Sci A, 2008 9(6):822-832 
[11] MPEG Software Simulation Group “ MPEG-2 codec ” Version 1.1, 
June 1994. 
[12] ISO/IEC 14496 (MPEG-4) Video Reference Software Version 
Microsoft-FDAM1-2.3-001213, December 13, 2000. 
[13] H.264/AVC reference software 
JM12.1, http://iphome.hhi.de/suehring/tml/. 
TABLE IV. Comparison with previous works 
 Technology On-chip memory 
Interpolation hardware 
(gate count) 
Total gate 
count Resolution Frames/s 
Operation fre-
quency 
Picture 
type Supported standard 
[4] UMC 0.18um 2,048bytes 13K 31.8K 1920x1088 30 100MHz P H.264 
[5] UMC 0.18um N/A 20.6K 43K 1920x1088 30 100MHz P H.264 
[6] TSMC 0.18um 168 bytes 21.5K 31.4K 2048x1024 30 125MHz P H.264 
[7] TSMC 0.35um N/A N/A 46K 1920x1088 30 100MHz P,B H.264 
[8] 0.18um N/A 21K 56K 1920x1088 30 148.5MHz P MPEG-2, AVS, H.264 
[9] 0.18um 1,280 bytes 23.3K N/A 4CIF 30 54MHz P,B MPEG-1/2/4 
Proposed TSMC 0.18um 896 bytes 29.6K 52.4K 1920x1088 30 108MHz P,B MPEG-2/4, H.264 
 

其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
藉由參與國際知名之視訊標準之制訂以及提案，如 MEPG 標準制定會議和 AVS 標
準制定會議，有效提升台灣多媒體產業的技術層次及水平。子計畫於今年度已
在 MPEG 國際多媒體標準制訂會議中提出五個重要的技術貢獻案，厚植台灣學界
研究水準及業界技術層次，同時提高國內在多媒體標準制訂的能見度進而提升
台灣多媒體產業之國際影響力。 
 
 成果項目 量化 名稱或內容性質簡述 
科 
教 
處 
計 
畫 
加 
填 
項 
目 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
計畫成果推廣之參與（閱聽）人數 0  
 
