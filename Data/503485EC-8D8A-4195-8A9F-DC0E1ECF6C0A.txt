apply the developed robot for the auxiliary education 
for autistic children and provide evaluation for the 
robot design.  
Because the developed robot will posses capabilities 
of motion, wireless senor network, and control 
feedback with interaction with human behavior, it 
will improve the education function for autistic 
children. Our research team is going to complete the 
3-year project in the rescue robot development. The 
accumulated experience and techniques will be applied 
to this integrated project for social benefit.  
 
英文關鍵詞： Human Behavior, Weight Reduction , Safety 
Evaluation , HRI , Wireless Senor Network , Feedback 
 
 2 
影響，故轉至 YCbCr 色彩系統，針對目標區域選擇
YCbCr 臨界值，將符合臨界值得像素二值化，即使經
過二值化範圍的判斷，環境中可能會出現些微的雜
訊，因此必須將這些不必要的訊號濾除，第三步將以
侵蝕運算處理，以濾除環境中的雜訊；雖然透過侵蝕
運算的影像，可以濾除非必要的區域，但也侵蝕了主
要目標區域的範圍，故第四步將利用擴張運算，將目
標的區域大小恢復。當得到四個目標區域的紅色區
塊，必須將像素與像素之間之連通性標記出來，第五
步將使用連通標籤法，目的是將輸入之影像中的所有
物件，依照互相有連結的區域給予同一編號，常見的
為四鄰近與八鄰近，此部分運用八鄰近的方式將鄰近
像素相同之數值標示為同一編號，在貼完標籤後，將
影像所看到的最大面積分辨出來，並由式(2-1)、(2-2)
算出四個目標區域的重心 ),(~),( 4411 yxyx 。 
1
0
1 n
i
i
x x
n
−
=
= ∑                             (2-1) 
∑
−
=
=
1
0
1 n
i
iyn
y                            (2-2) 
得到四點的重心後，由於此研究針對手臂大幅度
動作做擷取，故上肢的四個紅色區域有一定的排序，
當標籤後的重心座標與實際上的區域不匹配，將導致
姿態判斷的錯誤，故此部分納入氣泡排序演算法
(bubble sort)，其運作原理是藉由逐次比較兩筆相鄰的
資料，依照排序的條件(由小至大或由大至小)交換位
置，直到全部資料依序排好為止。 
 
1.2. 手臂相對距離與角度 
 
 
圖 2-2 手臂紅色標記擷取對應座標 
得到四點正確排序之重心後，由圖 2-2 所示，對
應至座標系中，以肩膀座標為基準可利用式 2-3、2-4
得到兩手臂與水平面之角度，此部分將其視為手臂之
垂直角度。 






−
−
= −
02
021
0 tan xx
yy
α  (2-3) 






−
−
= −
13
131
1 tan xx
yy
α  (2-4) 
另外影像中的四點座標可利用式 2-5、2-6求得手
臂於影像中的相對長度。 
( ) ( )2022020 yyxxd −+−=   (2-5) 
( ) ( )2132131 yyxxd −+−=  (2-6) 
得到手臂在影像中的長度後，欲求得手臂之水
平角度，以圖 2-3 所示，首先對手臂之影像作初始
化，以得到初始手臂在影像中的長度，接著在手臂移
動時，得到新的手臂在影像中的長度，以此兩個長
度，便可以式 2-7得到手臂在水平移動上的角度。 






= −
LengthInitial
Length
_
cos 1θ  (2-7) 
 
圖 2-3 量測水平角度步驟 
因此，經由上述之步驟，可得知手臂的擺動皆是
以肩上為基準點，手臂姿態擷取的方式是將手臂資訊
分解成垂直與水平的角度，以作為上肢姿態判斷的依
據。 
 
圖 2-4 手臂姿態資訊分解 
 
1.3. 手臂垂直角度實驗分析 
實驗環境如圖 2-5 所示，將左邊的紅點設為基準
點，所形成的三種排列角度，分別為 45 o、0 o、與-45 
o做測試，並以影像處理每 10 Hz的取樣頻率，分別取
得 200筆三種情況的角度 
 
 4 
圖 3-2 卦限與三軸加速度值對應座標 
得到一連串的動作序列數值，可表示 X、Y、Z
三軸的特徵也可以得到動作狀態的順序，針對此順序
性的比對，且為了判斷的即時性，需要運算簡單且快
速的動態規劃演算法，本研究採用 D.S. Hirschberg 
所提出的最長共同子序列演算法 (Longest Common 
Subsequence; LCS) [19] ，來計算動作序列相似的程
度，可以滿足動態辨識的功能。 
LCS 是一種針對序列順序性的辨識演算法，常
應用在不同領域中做相似度的比對，像是生物學上做
測量序列相似度及語言訊號處理等等，其定義如式
3-1所示。 
( ) ( )
( ) ( )( )



=−
=+−
==
=
jyixifjY,1iXLCS,1-jY,iXLCSMax
jyixif11-jY,1iXLCS
0jor0iif0
jY,iXLCS  (3-1) 
欲求得兩序列 X1 ~ Xm與 Y1 ~ Yn之最長共同子
序列，需將X及Y序列轉變為二維陣列，再將兩兩元
素做比對以累積共同子序列的長度。以設定之序列
1234(m=4)與 13243(n=5)及 1324314(n=7)兩序列比對
的情形為例子說明，並經由式(3-1)可得知最長共同子
序列長度之數值分別為 3 與 4，利用此長度的數值，
可以方便成為下一階段的相似度比對。 
相似程度依前述之兩個範例說明，可得知最長共
同子序列分別的長度數值分別為 3 與 4，故 matching 
rate分別為 3/4=75%與 4/4=100%。因此，得到此動作
相似度的比率數值，便可依據不同的應用，自行設定
門檻值，達到動作辨識的功能。 
動作之運動方向由上一階段得到手臂運動趨勢的
正確率，但因三軸加速度計為與地面G值得到相對之
加速度值，故在同一水平下的運動無法正確的辨識，
故此部分納入前述所提出之影像處理技術，來輔助確
定上肢運動區域的範圍，以提升動態辨識的正確性。 
2.2. LCS演算法實驗分析 
此部分將利用動態規劃演算法來計算三軸加速度
計之一連串動作序列，並將此動作序列與設定之動作
序列做比對分析，以下將呈現動作在擺動速度過快與
速度匹配之情況。 
實驗環境為手臂張開上下重複擺動之動作，如圖
3-3 所示，於手臂上架設加速度計，將手臂張開做出
上下擺動的姿勢，分別記錄擺動速度較快與較慢的三
軸加速度值及相對應之一維狀態空間，所設定之擺動
序列為 11112222，擺動頻率約 1.25Hz。 
 
圖 3-3手臂張開上下擺動示意圖 
 擺動速度匹配之情況 
由圖 3-4(a)可知三軸在手臂擺動速度匹配時，三軸
各自的加速度值，並且對應至一維狀態空間，如圖
3-4(b)所示。 
 
 
 
(a) 三軸分別之加速度值 
 
(b) 對應至一維動作序列 
圖 3-4擺動較慢之情況(頻率約 1.25 Hz) 
 
 擺動速度較快之情況 
由圖 3-5(a)可知三軸在手臂擺動速度較快時，三軸
各自的加速度值，並且對應至一維狀態空間，如圖
3-5(b)所示。 
 
 
 
(a) 三軸分別之加速度值 
 
(b) 對應至一維動作序列 
圖 3-5擺動較快之情況(頻率約 2.5 Hz) 
 
由圖 3-4 與圖 3-5 分別在擺動速度較慢(約 1.25 
Hz)與速度較快(約 2.5 Hz)情況下之一維動作序列值，
整理擺動速度較快與速度匹配分別之 200筆數值，以
每 8筆依序與設定的序列(11112222)做 LCS比對，共
計比對 193筆，並得到序列比對之辨識率，茲整理如
表 3-1，由表可知在擺動速度較快(約 2.5 Hz)情況下，
序列比對辨識率在 75%以上只有 9 筆，而速度匹配
(約 1.25 Hz)情況下，實際擺動的序列比對辨識率有
113筆在75%以上，依此實驗數據可將100%設定為此
動作序列比對條件較嚴謹之門檻值，而 75%設定為此
動作序列比對條件較寬鬆之門檻值。 
 6 
以 ZigBee 星狀拓樸網路，處理低成本之非視覺式
三軸加速度感測器，並納入動態辨識演算法，將手臂
移動的運動方向與快慢，以 LCS 演算法辨識一連串
之動作序列，並根據實驗結果與自閉兒教學應用，設
定相似度門檻值為 75%；並以影像處理輔助運動區域
的正確性，彌補加速度計的不足，以完成動作追蹤的
目的。 
 
3. 回饋互動教學的建立與教學可行性評估： 
以上述之無線感測網路技術，建立起靜態互動教
學、伴隨互動教學與動態互動教學，並配合音效回饋
系統，以此迴路互動教學，協助自閉症孩童正確的復
健與提升之間的互動，並提升自發性的眼神注視、改
善固著專注力的遷移與提高社會性行為的模仿意願。 
 
參考文獻 
[1] Meltzoff, A. N. & Moore, M. K, (1994). “Imitation, 
memory, and the representation of persons.”  
Infant Behavior and Development, 17, 83-99.  
[2] Carpenter. M., Nagell, K., & Tomasello, M. (1998). 
“Social cognition, joint attention, and 
communicative competence from 9 to 15 months 
of age.” Monographs of the Society for Research in 
Child Development, 63, 1-142 
[3] Roeyers, H., Oodt, P. V., & Bothuyne, S. (1998). 
“Immediate imitation and joint attention in young 
children with autism.” Development and 
Psychopathology, 10, 441-450 
[4] Grynszpan, O., Martin, J.-C. ; Nadel, J.; “What 
influences human computer interaction in autism?”  
Development and Learning, 2007. ICDL 2007. 
IEEE 6th International Conference. 
[5] D. Feil-Seifer and M. J. Mataric, “B3IA: A control 
architecture for autonomous robot-assisted 
behavior intervention for children with Autism 
Spectrum Disorders”, Robot and Human 
Interactive Communication, pp.328-333, 2008 
[6] B. Robins, N. Otero, E. Ferrari, and 
K. Dautenhahn,  “Eliciting requirements for a 
robotic toy for children with autism - Results from 
user panels”, Robot and Human interactive 
Communication, pp.101-106, 2007 
[7] B. Robins, K. Dautenhahn, R. T. Boekhorst , and A. 
Billard, “ Robotic assistants in therapy and 
education of children with autism: can a small 
humanoid robot help encourage social interaction 
skills?”, Universal Access in the Information 
Society, pp.105-120, 2005 
[8] B. Robins, P. Dickerson, P. Stribling, and K. 
Dautenhahn, “Robots as embodied beings - 
Interactionally sensitive body movements in 
interactions among autistic children and a robot,” 
Proc. 14th IEEE International Workshop on Robot 
and Human Interactive Communication 
-ROMAN ’05, 2005. 
[9] B. Robins, K. Dautenhahn,  “The role of the 
experimenter in HRI research – A case study 
evaluation of children with autism interacting with 
a robotic toy”, Robot and Human Interactive 
Communication, pp.646-651, 2006 
[10] B. Robins, K. Dautenhahn, “Robot as assistive 
technology – Does appearance matter.” 
[11] H. 
Proc. 13th 
IEEE International Workshop on Robot and 
Human Interactive Communication -ROMAN ’09, 
2004. 
Kozima, C. Nakagawa, Y. Yasuda, “Interactive 
robots for communication-care: a case-study in 
autism therapy”, 
[12] H. Kozima, Y. Yasuda, C. Nakagawa , “Social 
interaction facilitated by a minimally-designed 
robot: Findings from longitudinal therapeutic 
practices for autistic children”, 
Robot and Human Interactive 
Communication, pp.341-346, 2005 
Robot and Human 
interactive Communication, pp.599-604, 2007 
[13] H. H. Lund, M. D. Pedersen, and R. Beck, 
“Modular robotic tiles experiments for children 
with autism”, Artificial Life and Robotics, pp. 
394-400, 2009 
[14] Sam Naghshineh, Golafsoun Ameri, Mazdak 
Zereshki & Dr. S. Krishnan, Dr. 
M.Abdoli-Eramaki “Human Motion capture using 
Tri-Axial accelerometers” 
[15] Davey T. W. Fong, Joe C. Y. Wong, Alan H. F. 
Lam, Raymond H.W. Lam and Wen J. Li “A 
Wireless Motion Sensing System Using ADXL 
MEMS Accelerometers for Sports Science 
Applications” Proceedings of the 5" World 
Congress on Intelligent Control and Automation, 
June 15-19. 2004, Hangzhou, P.R. China 
[16] Jihong Lee and Insoo Ha “Real-Time Motion 
Capture for a Human Body using Accelerometers” 
Robotica (2001) volume 19, pp. 601–610. Printed 
in the United Kingdom © 2001 Cambridge 
University Press 
[17] Dean M. Karantonis, Michael R. Narayanan, 
Merryn Mathie, Nigel H. Lovell, and Branko G. 
Celler, “Implementation of a Real-Time Human 
Movement Classifier Using a Triaxial 
Accelerometer for Ambulatory Monitoring” IEEE 
Transactions on information technology in 
biomedicine, vol.10, No.1, January 2006 
[18] Pedram Azad, Ales Ude, Tamim Asfour, Gordon 
Cheng, and Ruediger Dillmann “Image-Based 
Markerless 3d Human Motion Capture using 
Multiple Cues” Neuroscience (2006) 
[19] D.S. Hirschberg, “A Linear Space Algorithm for 
Computing Maximal Common Subsequence”, 
Communication of ACM, Vol.18, pp.341-343, 1975 
[20] Likert, Rensis, “A Technique for the Measurement 
of Attitudes, Archives of Psychology.” 1932, 140: 
pp. 1-55 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：徐保羅 計畫編號：99-2221-E-009-024- 
計畫名稱：發展先進機器人與人互動系統並應用在自閉症者輔助教學--總計畫：發展先進機器人與人
互動系統並應用在自閉症者輔助教學 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 0%  
研究報告/技術報告 1 1 100% 完成碩士論文、博士論文各一篇 
研討會論文 1 1 100% 
篇 
在 SIRCoc  2011 
發表會議論文一
篇 
論文著作 
專書 0 0 0%   
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 2 1 50% 2011 蔡政宏畢業 
博士生 1 1 100% 2011 賴建良畢業 
博士後研究員 0 0 0%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 1 100% 
人次 
 
期刊論文 0 1 0%  
研究報告/技術報告 0 0 0%  
研討會論文 0 0 0% 
篇 
 
論文著作 
專書 0 0 0% 章/本  
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 0 0 0%  
博士生 0 0 0%  
博士後研究員 0 0 0%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 0% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
會議論文  ’’Efficient Static and Dynamic Gesture Capture of the Interactive 
Robotic Education System’’ 發表在台中 SIRCon 2011 No., 25-27        
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
目前有許多針對自閉症孩童於遊戲中介入模仿行為的研究，正方興未艾，因為模仿能力對
於所有孩童都是與生俱來的能力，並為早期發展的關鍵。研究也指出模仿能力可能是發展
社會性互動與語言溝通的基礎，故模仿能力是一個可分辨自閉症孩童互動缺陷的指標，傳
統上發展出許多靜態圖卡、一對一教學直到現今發展了動畫、電腦教學與虛擬實境的方
式，來協助自閉症孩童的復健，皆各有其優缺點。 
    除了上述較為靜態的教學方式，機器人對自閉症孩子的復健研究，近年來也更被探
討。基本上，相關的研究報告均指出機器人能提升自閉症孩子的注意力，在互動上，也有
許多改進的成果。因此，近來有關與人形機器人互動的相關研究，正不斷發展；不過，在
目前所看到應用於自閉症探討的機器人，其運動能力一般皆不夠靈活；而在互動能力上，
亦欠缺有效的無線感測裝置，因而有許多改善的空間。 
    目前無線感測姿態擷取的應用，十分廣泛，包含視覺式之影像處理技術與非視覺式的
加速度計、陀螺儀、磁力計等等，但由於人體的自由度豐富，姿態辨識上可以有許多不同
的應用，一般非視覺式的感測器擷取多個動作資訊分析人體的動作，主要應用於生理資訊
的判斷等應用；也有許多以視覺式攝影機擷取人體特徵，如以影像辨識手勢遙控音樂的應
用，甚至是設計一套電腦動畫辨識自閉症孩童手掌的遊戲等應用，無論是視覺式或非視覺
式的感測器，應用於遊戲、機器人控制、復健或教學等，皆是十分多樣化的。 
