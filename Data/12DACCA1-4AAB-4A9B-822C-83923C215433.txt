 I 
目錄 
中文摘要...............................................................................................II 
英文摘要...............................................................................................III 
一、前言...............................................................................................1 
二、研究目的.......................................................................................3 
三、文獻探討.......................................................................................4 
四、研究方法.......................................................................................7 
五、結果與討論...................................................................................19 
六、參考文獻.......................................................................................37 
七、計畫成果與自評...........................................................................44 
 III 
Abstract 
Convolutional and Reed-Solomon codes have been recognized as very powerful error-control 
codes and widely used in many practical applications such as digital communication and storage 
systems. With their performance being very close to the Shannon limit, the emergence of turbo code 
and low-density parity-check code in the last decade opens a new research area and attracts much 
attention from researchers in data communications. From the error-control viewpoint, the 
improvement on the resulting bit-error rate (BER) comes from the application of soft-input 
soft-output (SISO) decoders together with the concept of iterative decoding. Although lots of related 
work existing in the literature, there still exist bottlenecks for effectively, or even successfully, 
implementing the SISO channel decoders, especially for high-performance applications, because of 
the emanating demands from human desires and new high-end products. Based on our past 
experiences on the design and implementation of hard-decision channel decoders as well as the 
sliding-window turbo decoders, this research is planned to make an advanced study on the 
algorithms and hardware realizations of state-of-the-art SISO channel decoders employing iterative 
decoding scheme. The goal is to derive more efficient hardware architectures for the design of 
targeted SISO channel decoders and their corresponding intellectual property (IP) design based on 
different system requirements. From practical and academic points of view, the results of this 
research plan will be very valuable and can be used as a basis for future investigation. 
According to the aim of this research plan, this three-year project has accomplished the 
following tasks. (1) Complete the comparative study of the existing algorithms and architectures of 
targeted SISO channel decoders for turbo, RS, and LDPC codes, especially for high-performance 
applications. (2) From system implementation point of view, we have combined the advantages of 
existing works and developed more efficient architectures for above channel decoders. We have also 
established the necessary simulation and verification environment to justify our development. (3) In 
compliance with the potential requirements of multi-rate and multi-standard applications, we have 
developed target channel decoders and their IPs with low-power feature. 
 
 
 
Keywords：Error-control codes, Turbo code, Reed-Solomon (RS) code, Low-density parity-check 
code (LDPC), Iterative decoding, Soft-input soft-output (SISO) decoder, VLSI. 
 2 
設計流程，在高效能方面的考量下，實現具低功率考量的軟性輸入輸出遞迴式解碼器之晶片設
計與矽智產模組（及模型）開發。因此本研究之預期成果不但兼具研究與商業之雙重價值，亦
可作為以後可能衍生之相關數位通訊系統研究之經驗累積。 
 4 
三、文獻探討 
1. 低密度同位元檢查碼 
低密度同位元檢查碼是由 Gallager 在 1962 年所發明之編碼方式[1]，雖然之後 Tanner 利
用了圖形的方式來詮釋此種編碼[2]，但在當時並沒有受到太大的注目，直到後來 MacKay 與 
Neal 兩位學者重新詮釋了低密度同位元檢查碼[3]，之後此種編碼方式才開始大放異彩。由於
低密度同位元檢查碼具有相當好的錯誤更正能力，因此廣泛地應用在目前的無線通訊標準中，
如 WLAN (IEEE 802.11n) [4]、WMAN (IEEE 802.16e) [5]、衛星通訊 (DVB-S2)[6] 等。為了使
低密度同位元檢查碼適合硬體實現，另有發展一種半循環 (Quasi-Cyclic) 的低密度同位元檢查
碼[7]被應用在大部分的硬體解碼器上[8-14]。 
低密度同位元檢查碼是一種線性區塊碼，目前有許多種解碼演算法支援此種編碼方式，其
中包含了 SPA (Sum-Product Algorithm) 演算法[15]與 MSA (Min-Sum Algorithm) 演算法
[16]。MSA 演算法是屬於 SPA 演算法之簡化版本，因此其效能上與 SPA 演算法有些差距；
為了提升整體的解碼效能，有許多其他改良後的解碼演算法[17-19]相繼發表。在低密度同位元
檢查碼的解碼器架構中，全平行架構[20][21]是具有相當高輸出率的一種方式，但其硬體複雜
度也較高。為了取得複雜度與輸出率之平衡點，有部分平行之架構[10-14][22][23] 之探討。由
於傳統的解碼方式之硬體使用率只有 50%，為提昇效率，[10][11]中也提出了運算單元重疊的
概念，讓整體的硬體使用率接近 100%，於[12]中亦提出了節點運算單元與變數運算單元兩者
複雜度之方法。近期 Layer 解碼架構[14][18][24][32]之討論亦受到相當多的關注，主要是因為
其所需要的疊代次數大約為傳統演算法的一半，因此整體的輸出率可以得到提升。除了上述所
描述之方法，低密度同位元解碼器亦有其他相關硬體論文之探討[24-37]。其中關於多碼率  
(Mult-rate) 架構[34-37]之設計亦相當受到各界的討論。在近期的低密度同位元檢查碼的文獻
中，除了傳統在 GF(2) 下的探討，目前亦有相當多篇著名的文獻在討論 Non-binary 之低密
度同位元檢查碼及其對應之硬體架構[38-40]。由於傳統的部分平行架構之解碼方式需要大量的
小容量記憶體區塊[10][11][13]，雖然平行度可以有效提升，但整體記憶體面積亦會增加。本計
畫即是針對此缺點加以改良，提出低複雜度之記憶體架構，它不僅能有效降低整體解碼器之面
積，在功率消耗上也有顯著的改善。 
 6 
性決定演算法 (soft-decision algorithm)。常見的硬性決定解碼演算法主要有 Berlekamp-Massey
（簡稱 BM algorithm）演算法[71-81]與 extended Euclidean（簡稱 eE algorithm）演算法 [82-90]。
對 (n, k) RS 碼而言，這兩種方式可保證最大錯誤更正能力為 (n－k)/2；且由於這兩種方法複
雜度較低，對應之硬體架構簡單且規則，故適用於實際的系統應用之中。另一硬性決定解碼法
為  List-Decoding 演算法  [91]，其解碼方式是將求解正確字碼的過程轉換至曲線配適  
(Curve-fitting) 的問題，其錯誤更正能力可超過 (n－k)/2。但早期 List-Decoding 演算法的僅適
用於碼率較低的碼且有計算複雜度極高，並不適合實際的應用。為解決低碼率的問題， 
Guruswami 與 Sudan 提出另一改良式演算法 [92]，並加入了權重式曲線配適 (Weighted curve 
fitting) 的觀念，使此法能適用於高碼率的碼。對通訊設計從業人員而言，如何提高改錯碼之
編碼增益 (coding gain) 一直為其研究之重要課題，而軟性決定解碼法正是近年來針對此一問
題所提出最有效之方法之一[93-107]。然而，RS 碼並不像 Convolutional codes 一樣，可以很
輕易地使用通道資訊，因此 RS 軟性解碼演算法除在 1966 年 Forney 提出  Generalized 
Minimum Distance decoding (GMD) 演算法[93]外，其研究發展並不如 Convolutional codes 迅
速。不過，近年來已有不少相關之文獻發表出來，如 Chase 演算法[94]、Fossorier 及 Lin 共
同 發 表 之  Order Statistics Decoding (OSD) 演 算 法 [95] ， Kotter 與  Vardy 基 於  
Guruswami-Sudan 演算法所提出之 Algebraic Soft-decision Decoding (ASD) 演算法[96]等。 
由於 KV-ASD 演算法兼具有低複雜度與高編碼增益的優點，因此本計畫主要著重於 
KV-ASD 演算法之探討與硬體架構之實現。同時，結合多項新的技術，設計出一高效能且低
複雜度之 RS 軟性解碼器。 
 8 
基於圖 1 的研究流程，以下我們詳述三年研究期間，針對三種錯誤更正編碼/解碼器在 IP 
設計時所採用之研究方法及其步驟。 
（一）本計畫採用之研究方法與原因： 
第一年： 
(I) 低密度同位元檢查碼演算法 
低密度同位元檢查碼 (LDPC code) 是一種接近薛農極限 (Shannon Limit) 的通道編碼，
亦將是未來通訊系統之數位通道編解碼器的熱門選擇之一。低密度同位元檢查碼的解碼演算
法主要是利用遞迴式的解碼概念，因而對電路的複雜度之要求相對會比較高，就目前的應用
評估，如何降低演算法的複雜度並且適合硬體架構設計，還有許多的研究空間。在低密度同
位元檢查碼演算法上值得討論的主題為資料相依性的多寡，會有此問題是由於演算法是建構
在 Tanner graph 上，所以 Tanner graph 性質的好壞會直接影響解碼結果，因此降低資料的
相依性可以提高整體解碼之效能。要降低資料相依性必須提高 Tanner graph 中 Girth 的大
小，若 Girth 太小所代表的是圖形之間小型 cycle 的比例很高，因此會造成整體演算法的效
能降低，此部分為本計畫探討的範疇。圖 2 為 Cycle-8 的例子，其 Tanner Graph 表示法如圖 3
所示。 




















=
101001001000
000110010100
010001100001
001000011010
010010100100
100100000011
H
 
圖 2: Example of the cycle-8 girth 
 
圖 3: 相對於圖 2 之 Tanner Graph 表示圖 
 10
S
y
m
b
o
ls
 
圖 4: Sliding window 之應用及示意圖 
不過面對現今及未來高速通訊的需求，以移動視窗的方法是無法符合其所需之高 throughput 
rate。因為移動視窗還是循序解碼輸出，但由於渦輪碼在解碼時已經將長度 N 之資料接收下來，
所以我們可將長度 N 之資料分成幾個區塊，將這些區塊採平行方式去運算，如此一來就可有
效的提高 throughput rate。移動視窗架構之平行演算法 [65] 的操作模式如下圖所示。 
0
W
2
W
3
W
4
W
sy
m
b
o
ls
 
圖 5: Parallel sliding window 之應用 
在平行演算法架構中，主要的研究重點之一是如何去決定每一個區塊的大小，跟移動視窗 L
的關係是如何，這將會影響到後續硬體架構的設計與實現。之後我們會將原本的演算法分解成
多組平行運算並完成 C model，來評估跟原本的演算法是否有差異。 
 12
除了上述解碼演算法之探討，我們還會建立起整體之模擬環境，此模擬環境有助於日後研
究的模擬與分析，如圖 6 所示為一以低密度同位元檢查碼為例之模擬環境。 
 
圖 6: LDPC 模擬環境 
第二年： 
(I) 低密度同位元檢查碼解碼器 
本計劃第二年在低密度同位元檢查碼部分，著重在 High-performance 解碼器架構的討論
與相關 behavior 模型的建立。根據之前在研究背景的描述，低密度同位元檢查碼解碼器可以
分成三種主要架構，且各有其優缺點。全平行架構雖然 throughput rate 比較高，但相對的運
算單元和記憶體之間的 interconnection 相當複雜，因此整體的電路相當大。而序列架構剛好
相反，其 throughput rate 相當低，因此之後我們所討論的解碼器架構都會建構在部分平行的
架構上，因為此架構可根據不同的應用，調整其平行度，而達到不同的效能。下面我們將分別
描述第二年度所討論之架構。 
(1) High-Performance 之低密度同位元檢查碼解碼器 
在傳統的 LDPC 解碼器中，其運算方式為 CNFU 和 VNFU 交錯排列運算，如 圖 7 所
示，代表 VNFU 要運算之前，CNFU 必須先運算完 VNFU 所需之資料，這樣 VNFU 才可
接續執行。但是此種運算方式會使整體的硬體使用效率 (HUE) 只有 50%，因此若能得到 
High-HUE 之 LDPC 解碼器，可以大量降低整體的運算時間。 
CNFU VNFU CNFU VNFU VNFU CNFU VNFU
 
圖 7: 傳統 LDPC 解碼程序 
 14
路進行研究和設計，最後並建構解碼器之相關 C model。 
基於目前的研究歸納，圖 9 所示為 Log-MAP 演算法之解碼器基本架構圖，其包括 LLR 
運算單元、向前/向後遞迴運算單元 (forward/backward processor)、分支轉變機率運算單元 
(branch metric processor) 及相對之記憶體。就各單元的硬體實現而言，forward processor (FP) 
與 backward processor (BP) 之基本電路是一樣的（動作的時序不同），而 LLR 運算單元及 
branch metric processor 的設計就目前的文獻所提出的方法都已足夠應付，但 (I) 記憶體的使
用量、安排與管理，(II) 如何降低解碼 latency，(III) 如何提高解碼速度；及(IV) forward/backward
解碼時序的規劃則是設計的重點，同時如要找出一可 IP 化且同時解決上述四個問題的架構更
是一大挑戰。 
Branch Metric
Memory
Branch Metric
Processor
Rk
Backward
Processor
Forward
Processor
Backward Metric
Memory
Forward Metric
Memory
LLR
Unit
Decoded
Bit
 
圖 9：渦輪碼解碼器之基本架構圖 
由於 FP 及 BP 的運算時序不同，因此必須將預解碼資料（Rk）儲存以便最後做 BP 的遞
迴運算，若以 Log-MAP 演算法來設計解碼器，則需要一 N×b×q 位元（其中 N 為資訊序列；
假設每一 symbol 有 b 個 branch metrics 且每個量化為 q bits）的記憶體儲存分支轉變機率，當
N 很大時，便需要很大的記憶體面積來儲存大量的資料，同時也造成解碼時的延遲 (latency or 
delay) 變大，所以 Log-MAP 演算法並不適合於實際即時系統的硬體實現。而另一類型之移
動視窗 Log-MAP 演算法 (SW-Log-MAP algorithm)，其特色乃是更改 Log-MAP 演算法使解碼
器在解碼過程中向後遞迴運算式 kβ 只需往回追溯 L 長度且 mLN )6~5(≥>> （一般 L 值為 5~6 
倍的記憶體深度(m)時即達到可接受之解碼效能）；當 L 越接近 N 時解碼效能越好，但卻需
要大量之記憶體面積；反之，若 L 越接近(5~6)m，雖較省硬體面積但解碼效能相對也較差。 
圖 10(a) 所示為文獻 [70] 所提出之節省記憶體面積與降低 Latency 的 Sliding-window 解
碼演算法之示意圖，此演算法最令人詬病的地方就是在 trace back L 長度後僅解碼出一筆資
 16
並行的方式做設計。最後，我們亦會建構解碼器相關之 C model 並完成驗證的工作。以下簡
述 KV-ASD 演算法對應之硬體架構的考量： 
(1) KV-ASD 之 High-Peformance 架構 
KV 解碼器包含以下三個單元：重數計算單元（Multiplicity Computation unit），補插單元
（Interpolation unit）和因式分解單元（Factorization unit）。為達高效能之硬體架構，我們就上
述三個功能單元分別討論： 
(A) Multiplicity Computation unit 
由於 KV 解碼器為一代數解碼器 (Algebraic decoder)，因此必須將接收到的通道可信度資
訊 (Channel reliability information) 轉換成代數形態 (Algebraic condition)，此代數形態將以重
數矩陣 (Multiplicity matrix)的方式存在，用以記錄置入點 (Interpolation points) 及其所對應之
重數 Multiplicity)。因此，須完成一可信度矩陣 (Reliability matrix) 轉換至一大小為 q×n 的重
數矩陣 (Multiplicity matrix) 的運算。同時，為了減少 Interpolation 的計算複雜度，通常會在 
Interpolation 之前加入一重編器 (Re-encoder) 的設計，不僅能轉換 k 個置入點之 Y 座標以利
於二元多項式 Q 的求得，更能減少記憶體之需求。相關設計可參考 [106]。 
(B) Interpolation unit 
此單元之主要是透過 Iterative 的方式計算 Q，其為解碼器中複雜度最高的，因此如何提
高 Interpolation 的效能與減少其硬體複雜度為一直是一個很重要的研究課題。[97] 提出一高
速的 Interpolation 架構，此架構主要區分為兩部分：Discrepancy Coefficient Computation (DCC) 
區塊與 Polynomial Update (PU) 區塊。經評估後發現解碼器之 Critical path 落在 DCC 上，而 
Critical path delay 幾乎由 MAC 所決定，因此好的 MAC 設計對整體效能之提昇具有很大的
助益。此外，Interpolation 架構中的 routing network 主要是用來調整 PUE 與 Coefficients 
RAM Banks 間係數存取的資料流，其複雜度會隨著 r 值的增加而提高，進而可能造成最後電
路意料之外的延遲路徑。此一問題，或許參考先前在 Hard-decision 方面的經驗來加以改善。
有關 Interpolation 的相關設計請參考 [99-105]。 
(C) Factorization unit 
此部分主要是在做因式分解的動作，其複雜度雖較 Interpolation unit 為低，但卻是佔了解
 18
 
圖 11: 所參考之 IP 設計流程 
 
 20
 
圖 13：16Kb 記憶體容量之各種組成方案面積比較圖 
(2). 列區塊記憶體合併法 
基於上述之概念，我們提出合併小記憶體區塊的可行方案。第一個方法為列區塊記憶體合
併法，如圖 14 所示。此方法主要是在合併多個小記憶體區塊以組成一大容量記憶體時，將每
個小容量之記憶體區塊一對一地對應到同位元檢查矩陣 (Parity check matrix) 中同一列區塊 
(Block row) 中的子矩陣。於本文中，我們稱此合併後之記憶體為一個記憶體群組 (Memory 
group)。 
 
圖 14：列區塊記憶體合併之架構 
若某一同位元檢查矩陣具有 J 個列區塊，則在採用列區塊記憶體合併方式之後，將產生 J
個記憶體群組。此外，透過此合併方式，每次存取記憶體時，皆可同時讀取多筆的資料。假設
 22






=
7105
421
baseH  
假設所探討之 H 為一維度為 26×39 之同位元檢查矩陣，則 Hbase 中的元素 (Entry) 所記載
之數值是維度為 13×13 之單位矩陣 (Identity matrix) 的位移數量。在圖 15 中除了包含記憶體
群組之外，每個記憶體群組皆額外搭配一組 Read-FIFO 與 Write-FIFO 來調整資料的時序。
於此架構下，記憶體群組的讀取方式是由某一組特定的位址開始讀取，之後則以遞增的方式來
存取記憶體群組。因此，雖然每次變數節點單元運算所需的資料皆位於不同位址，但利用此一
架構可先將已經從記憶體讀出，但尚未被使用的資料儲存於 Read-FIFO 中，待這些資料需使
用時，該資料會正好到達變數節點單元，此時便如預期之時序進行運算。如此一來，我們可以
有效地減少記憶體的存取次數，而且輸出量亦不會因記憶體區塊的合併而大幅降低。在此架構
中，由於前幾次的記憶體存取會讀到尚未準備好之資料，因此在變數節點單元的設計上，除了
原始之運算電路外，我們額外加入了旁通模式 (Bypass mode)。在旁通模式下，資料經過變數
節點單元後，並不會執行任何的運算，而這些未更新之資料會被再次寫回其原來的位址上，待
適當的時間點會被再次讀出，然後被變數節點單元運算。於此架構中除了加入 Read-FIFO 之
外，為了使經過變數節點單元運算後之資料能順利寫回原始讀出來之位置，我們也額外加入 
Write-FIFO 來完成此一任務。然而，雖然此架構可以使合併後之記憶體群組運作地更有效率，
但也會產生一些問題。這問題主要是因為列區塊記憶體合併法只能合併記憶體區塊，並無法有
效地控制 Read-FIFO 與 Write-FIFO 中延遲單元的數量，因此有可能造成更多硬體成本的浪
費。為此，我們提出記憶體區塊選擇演算法，來有系統且有效率地降低所需延遲單元之數量。 
(4). 記憶體區塊選擇演算法 
由於列區塊記憶體合併法之合併方式會受限於同位元檢查矩陣之結構，即不同列區塊所對
應之記憶體區塊並不能被放置於同一記憶體群組中。因此，若能有效排除此限制，則可獲得較
佳之記憶體合併結果。接下來，以下方之例子作為我們提出之記憶體區塊選擇演算法的說明。
假設我們選定之同位元檢查矩陣所對應之基本矩陣為： 
 24
不同的模式，其可支援的字碼長度可從 576 到 2304。本解碼器的主要設定如下： 
 記憶體區塊選擇演算法中的最長 FIFO 長度設為 L=4 
 使用的解碼演算法為 Min-Sum 演算法，且利用 8 個量化位元來表示傳遞之資訊 
 包含了 12 個檢查檢點單元 (CNU) 與 24 個變數節點單元 
根據上述之設定，我們所提出的解碼器之佈局繞線圖如圖 17 所示，記憶體的部分包含了 16
個記憶體群組，其中每個記憶體群組中的記憶體區塊個數分布從 1 個到 8 個。此外，經過我們
的分析，我們額外所付出的延遲單元個數為 248 個。 
 
圖 17：低密度同位元檢查碼解碼器之佈局繞線圖 
表一中呈現了我們所提出之低複雜度同位元檢查碼解碼器與現有文獻[20], [23], [14], [13], 
[35]之比較。雖然表一中的每個設計規格差異頗大，但我們仍能清楚地看出，我們的設計具有
最小的硬體複雜度。此外，與規格相近的設計[13]比較之後，我們所提出之架構能節省大約 33% 
的邏輯閘數目，這可歸功於我們所提出之記憶體區選擇演算法帶來的好處。 
在[13]的設計中，為了保持其硬體的平行度，使用了 100 個大小為 96×8 之記憶體區塊，
其中本質記憶體 (Intrinsic memory) 使用 24 個 Single-Port 的記憶體區塊，而非本質記憶體 
(Extrinsic memory) 則用 76 個 Two-Port 的記憶體區塊。相對的，在我們的設計中，由於引進
了記憶體合併概念，因此所需記憶體區塊數目可從原先的 100 個，減少為只需要 16 個不同大
小的 Two-Port 記憶體群組與 2 個相同大小的 Single-port 記憶體群組；如此一來，記憶體面積
可大量減少。從表二我們可以清楚地看出，單就記憶體部分，相較於[13]的設計可大幅減少約
44.59%的記憶體面積，這對於整體解碼器的貢獻度是相當高的。 
 26
圖 18 中繪出了在不同的參數 L (可允許之最長 FIFO 長度)下，所需要的 FIFO、非本質記
憶體及本質記憶體所需要的面積。由圖可看出所需要的 FIFO 面積會隨著 L 變大而呈線性成
長，而非本質記憶體則隨著 L 變大而減少。在本質記憶體部分，由於它並不會隨著 L 而改變
其合併結果，因此其面積大小與 L 無關。綜合上述之討論，我們可看出，大約在 L=3 或 L=4
左右可得到最省之面積。 
 
圖 18：所需之 FIFO 與記憶體群群組面積比較圖 
為求公平，我們透過下式所定義之 NPE 來評估單位功率的消耗下所能得到的輸出率。 
2
m13.0
Technology
nConsumptioPower
RateThroughputNPE 




×= µ  
根據上述所定義的 NPE，我們可以估算出所設計解碼器之 NPE 比起傳統的方法還要來得高，
因此本設計之低密度同位元解碼器不僅可大量降低所需之記憶體面積，功率消耗也比傳統的設
計來的低。 
 
 
 
 
 28
 
圖 20：反向演算法[68-69] 
(2). 改良式反向演算法 
改良式反向演算法主要訴求為在反向運算時不僅能夠完全排除記憶體單元的需求，且幾乎
不會影響到解碼效能。要達到此一目的，必須對狀態圖中各狀態運算結果做類別分析，當狀態
圖中各狀態資訊皆可由上個時間點的狀態資訊獲得時，可沿用反向演算法；反之則須依不同的
狀況套用如圖 21 中演算法回推上一時間點的狀態資訊。 
其重點在於，假定前一級的資訊皆為已知，若目前運算發生如圖 21 的類別時，就可由上
一級的資訊以及目前這一級已知的資訊來運算處理，進而得出無法藉由原本反向運算函式求出
的未知資訊。 
 
圖 21：改良式反向演算法 
 
( ) ( ) 




−−−+





+−−=
−
+−−
++
+ 1lnln,min 1,0,1,
4
10,
0
2
1,0,1,
4
10,
00
1
kkkkkk
ee kkkkkkk
γγγβγβ γγγβγββ
  
 30
 
圖 23：改良式反向演算法運算流程圖 
(5). 實驗結果與比較 
實驗的系統參數使用 LTE 通訊標準中的渦輪碼參數，以及 BPSK 調變 (Modulation)，移
動視窗長度為一般常用的五倍限制長度 (Constrain length)，遞回次數為八次，測試了 1000 組
框架 (Frame) 資料。圖 24 中虛線代表的為框架錯誤率 (Frame error rate)，實線代表的為位元
錯誤率 (Bit error rate)，在模擬圖中分別比較了下列三種演算法： 
 紅線：傳統演算法（無解碼效能誤差之對照組）  
 綠線：改良式反向運算演算法 
 藍線：改良式反向運算配合單一確認點 
其中藍線與紅線完全重合，表示改良式反向運算配合單一確認點即可達到近乎無解碼效能
損失的要求；同時，在硬體設計上可完全省去 α 或 β 記憶體單元，在單獨使用改良式反向運
算時亦可達到一定的解碼效能表現。 
 
 32
3. 里德索羅門碼 
(1). 代數解碼法 
對建構在有限場 GF(q) 的 (n,k) RS 碼而言，解碼器在接收到前級所傳送之一筆大小為 
q×n 的通道可信度資訊 (Channel reliability information) 矩陣 Π 之後，會透過重數計算單元將 
Π 轉換成非負整數的重數矩陣 (Multiplicity matrix) M，以記錄收到之置入點 (Interpolation 
points) 所對應的重數。接著，補插單元依 M 及置入點的資訊，藉由反覆疊代的方式求得二
元多項式 Q。最後，對 Q 進行因式分解，得到所有可能的解集合 L。整個解碼過程中，以補
插單元之設計最為複雜。假設 mi,j 為 M 中之項目元素 (Entry)，則代數演算法所需之疊代次
數為 Σ(mi,j2+mi,j)/2，其中 1≤i≤q 及 1≤j≤n。對常見的 RS 碼而言，總疊代次數可能多達數萬次，
如此高的計算複雜度實在難以用於現行的應用中，同時其潛在著大量的 buffer 需求。 
(2). 重編器架構 
為了有效降低補插單元於硬體設計上的複雜度，通常會採用重編碼及座標轉換技術
(re-encoding and coordinate transformation techniques)。假設 multiplicity assignment 單元在碼字
中的每個位置上產生二個對應的符號元；即分別以 ri,0 與 ri,1 表示接收碼 r 中第 i 個位置的兩個
符號元，其中 ri,0 所對應的重數較 ri,1 大。令 IH 為 r 中擁有最高重數的 k 個位置之索引所構成
之集合，而 IL 為其餘 n-k 個位置所成之集合。重編器的主要概念是將這 k 個屬於 IH位置之符
號元重新編碼得到一個新的字碼 u，同時產生一新的接收碼 r′ = r + u。我們可看出 r′ 與 r 具
有同樣的錯誤資訊(即有同樣的錯誤多項式)，因此 KV-ASD 亦可由 r′解碼取得所需的錯誤資
訊。以 r′ 取代 r 最大的好處是這 k 個屬於 IH 位置在 r′ 所對應的符號元皆為 0，故 IH 位置的
k 個座標點可先行計算，即 v(x)=∏i∈IH(x+αi)；對 interpolation unit 而言，僅需針對其餘屬於 IL
位置之 n-k 個非零的符號元進行處理。然而，在經過重新編碼後，用於 interpolation 步驟的初
始多項式卻變得冗長且複雜，造成額外的運算與硬體需求；為解決此一問題，座標轉換的技術
被採用以縮短初始多項式的長度。 
圖 25 為具有 re-encoder 設計之 RS 代數解碼器區塊圖。一般而言，由於 n-k 個具有最低重
 34
 
圖 26：Λ(x)計算電路架構 
由於接著所要計算的 Ω(x) 有 d-1 個係數，其硬體需求與計算 Λ(x) 的電路雷同，因此我們提
出了一有效的控制方案與硬體架構(圖 27)，能在 2d-2 iterations 後求得 Λ(x) 與 Ω(x)。 
Proposed Control Scheme 
Initialization: 
    Λ(x) = 1, Ω(x) = 0; 
Step.1:     /* Compute Λ(x) */ 
For q = 0 to d -2     
Enable registers of the Λ part, Disable registers of the Ω part; 
SEL_2 = 1, SEL_3 = 1, SEL_4 = 1; 
For i = 0 to f-1 
If i = 0 then SEL_1 = 0;            
Else SEL_1 = 1;  
Λ(q+1)hf+i = Λ(q)hf+i-1 ⋅αj + Λ(q)hf+i;  
End 
End 
Step.2:     /* Compute Ω (x) */ 
For q = 0 to d -2     
Disable registers of the Λ part, Enable registers of the Ω part; 
SEL_2 = 0, SEL_3 = 0; 
For i = 0 to f-1 
If i = 0 then SEL_1 = 0, SEL_4 = 1;            
Else SEL_1 = 1, SEL_4 = 0;  
Ω(q+1)hf+i = Λ(d-1)hf+i-1 ⋅sq + Ω(q)hf+i-1;  
End 
End 
Output: Λ(d-1)(x), Ω(d-1)(x) 
 
 36
AT = (# of Gates / Throughput rate) 
由下表可看出我們所設計的 re-encoder 具有較高的 throughput rate 及較小的 AT 複雜度。相較
於 [106]之設計，雖然本設計多出了約16％ 的面積複雜度，但由於各級管線的延遲時間(latency)
較短，不僅可提昇整體 throughput rate 約 4 倍，也更適用於實際的應用層面。 
表四：與相關文獻之實驗結果比較 
Re-Encoder [106] Proposed 
Constant FFMs 0 16 
FFMs 21 21 
FFAs 39 34 
DFFs 75 96 
Muxs 42 32 
256×8 ROM 2 1 
256×8 RAM 1 0 
Critical path delay Tmult+Txor2+2Tmux2 Tmult+Txor2+2Tmux2 
Latency/per stage (cycles) 1038 257 
Throughput rate (Mbps) 500 2000 
Area Complexity 8424 9770 
AT Complexity 33696 9770 
AT Improvement - 71%* 
*(33696-9770)/33696 = 0.71 
(6). 相關研究成果 
現今有許多的應用均具有單一系統包含多個 RS 碼的設計，以應付不同通道 (Channel) 
變化或資料傳輸速度的需求；常見的應用諸如 xDSL、WiMAX、Blu-ray Disc、DVD 及 CD 
等。由於現今的應用有單或多重速度/模式的硬性決定 RS 解碼器的需求，因此，本研究亦對
此提出相關的解決方案。針對單模式之解碼器，我們提出一具高效能且低複雜度的解碼器架
構，相較於其他己發表之文獻，能以較少硬體提供更高的輸出量[109]。此外，我們也提出一
具高效能的多重模式的 RS 解碼器設計，它不僅能操作在較高的工作頻率，更能同時更正錯
誤與拭去 (Errors-and-erasures) 的資訊，此特性足以應付各種不同應用的需求[108]。雖然軟決
定 RS 解碼法至今尚未有實際的系統應用出現，但展望未來，當新的應用出現之時，本計劃所
開發之研究成果必能有所幫助。
 38 
[16] M. P. C. Fossorier, M. Mihaljevic, and H. Imai, “Reduced complexity iterative decoding of low 
density parity check codes based on belief propagation,” IEEE Trans. Commun., vol. 47, no. 5, 
pp. 673–680, May 1999. 
[17] J. Chen, A. Dholakia, E. Eleftheriou, M. P. C. Fossorier, X. Y. Hu, “Reduced-complexity 
decoding of LDPC codes,” IEEE Trans. on Commum., vol. 53, no. 8, pp. 1288–1299, Aug. 
2005. 
[18] D. E. Hocevar, “A reduced complexity decoder architecture via layered decoding of LDPC 
codes,” in Proc. IEEE Workshop on Signal Processing Systems, Austin, TX, Oct. 2004, pp. 
107–112. 
[19] M. M. Mansour, “A turbo-decoding message-passing algorithm for sparse parity-check matrix 
codes,” IEEE Trans. Signal Process., vol. 54, no. 11, pp. 4376–4392, Nov. 2006. 
[20] A. J. Blanksby, C. J. Howland, “A 690-mW 1-Gb/s 1024-b, rate-1/2 low-density parity-check 
code decoder,” IEEE J. Solid-State Circuits, vol. 37, no. 3, pp. 404–412, Mar. 2002. 
[21] N. Onizawa, T. Hanyu, and V. C. Gaudet, “Design of high-throughput fully parallel LDPC 
decoders based on wire partitioning,” IEEE Trans. Very Large Scale Integr. (VLSI) Syst., vol. 18, 
no. 3, pp. 482–489, Mar. 2010. 
[22] M. M. Mansour, and N. R. Shanbhag, “High-throughput LDPC decoders,” IEEE Trans. Very 
Large Scale Integr. (VLSI) Syst., vol. 11, no. 6, pp. 976–996, Dec. 2003. 
[23] S. H. Kang, I. C. Park, “Loosely coupled memory-based decoding architecture for low density 
parity check codes,” IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 53, no. 5, pp. 1045–1056, 
May 2006. 
[24] Z. Cui, Z. Wang, and Y. Liu, “High-throughput layered LDPC decoding architecture,” IEEE 
Trans. Very Large Scale Integr. (VLSI) Syst., vol. 17, no. 4, pp. 582–587, Apr. 2009. 
[25] S. L. Howard, V. C. Gaudet, C. Schlegel, “Soft-bit decoding of regular low-density parity-check 
codes,” IEEE Trans. Circuits Syst. II, Exp. Briefs, vol. 52, no. 10, pp. 646–650, Oct. 2005. 
[26] H. Sankar, K. R. Narayanan, “Memory-efficient sum-product decoding of LDPC codes,” IEEE 
Trans. on Commum., vol. 52, no. 8, pp. 1225–1230, Aug. 2004. 
[27] T. Zhang, K. K. Parhi, “Joint (3,k)-regular LDPC code and decoder/encoder design,” IEEE 
Trans. Signal Process., vol. 52, no. 4, pp. 1065–1079, Apr. 2004. 
[28] L. Yang, H. Liu, C. J. R. Shi, “Code construction and FPGA implementation of a 
low-error-floor multi-rate low-density Parity-check code decoder,” IEEE Trans. Circuits Syst. I, 
Reg. Papers, vol. 53, no. 4, pp. 892–904, Apr. 2006. 
[29] F. Verdier, D. Declercq, “A low-cost parallel scalable FPGA architecture for regular and 
irregular LDPC decoding,” IEEE Trans. Commun., vol. 54, no. 7, pp. 1215–1223, 2006. 
[30] V. K. K. Srinivasan, C. K. Singh, and P. T. Balsara, “A generic scalable architecture for 
min-sum/offset-min-sum unit for irregular/regular LDPC decoder,” IEEE Trans. Very Large 
Scale Integr. (VLSI) Syst., vol. 18, no. 9, pp. 1372–1376, Sep. 2010. 
[31] J. Sha, Z. Wang, M. Gao, and L. Li, “Multi-Gb/s LDPC code design and implementation,” 
IEEE Trans. Very Large Scale Integr. (VLSI) Syst., vol. 17, no. 2, pp. 262–268, Feb. 2009. 
[32] J. Jin and C.-Y. Tsui, “An energy efficient layered decoding architecture for LDPC decoder,” 
 40 
[51] J. Hagenauer and P. Hoeher, “A Viterbi algorithm with soft-decision outputs and its 
applications,” in Proc. GLOBECOM, pp. 47.1.1-47.1.7, 1989. 
[52] O. Joeressen, M. Vaupel, and H. Meyr, “Soft-output Viterbi decoding: VLSI implementation 
issues,” in Proc. VTC, pp. 941-944, 1993. 
[53] J. Hagenauer and L. Papke, “Decoding turbo codes with the soft-output Viterbi algorithm 
(SOVA),” in Proc. ISIT, p. 164, 1994. 
[54] J. Hagenauer, “Source-controlled channel decoding,” IEEE Trans. Commun., vol. 43, pp. 
2449-2457, Sept. 1995. 
[55] L. Papke, P. Robertson, and E. Villebrun, “Improved decoding with the SOVA in a parallel 
concatenated (turbo-code) scheme,” in Proc. ICC, pp. 102-106, 1996. 
[56] A. Ghrayeb and W. E. Ryan, “Concatenated coding and iterative SOVA decoding with PR4 
signaling,” in Proc. ICC, pp. 597-601, 2000. 
[57] Z. He, P. Fortier, and S. Roy, “Highly-parallel decoding architectures for convolutional turbo 
codes,” IEEE Trans. VLSI Systems, vol. 14, no. 10, pp. 1147-1151, Oct. 2006. 
[58] A. Giulietti, L. van der Perre, and A. Strum, “Parallel turbo coding interleavers: Avoiding 
collisions in accesses to storage elements,” Electron. Lett., vol. 38, no. 5, pp. 232-234, Feb. 
2002 
[59] A. J. Viterbi, “An intuitive justification of the MAP decoder for convolutional codes,” IEEE J. 
Sel. Areas Commun., vol. 16, pp. 260-264, Feb. 1998. 
[60] Raghupathy and K. J. Liu, “VLSI implementation considerations for turbo decoding using a 
low latency Log-MAP,” in Proc. IEEE ICCE, pp.182-183, 1999. 
[61] C. Schurgers, F. Catthoor, and M. Engels, “Memory optimization of MAP turbo decoder 
algorithms,” IEEE Trans. VLSI systems, vol. 9, pp. 305-312, Apr. 2001. 
[62] G. Masera, G. Piccinini, M. R. Roch, and M. Zamboni, “VLSI architectures for turbo codes,” 
IEEE Trans. VLSI systems, vol. 7, pp. 369-378, Sept. 1999. 
[63] E. Yeo, P. Pakzad, B. Nikolic, and V. Anantharam, “VLSI architectures for iterative decoders in 
magnetic recording channel,” IEEE Trans. Magnetics, vol. 37, pp.748-755, Mar. 2001. 
[64] C.M. Wu, M.D. Shieh, C.H. Wu, Y.T. Hwang, and J.H. Chen, ”VLSI architectural design 
tradeoffs for sliding-window Log-MAP decoders,” IEEE Trans. VLSI Systems, vol. 13, no. 4, pp. 
439-447, Apr. 2005. 
[65] Z. Wang, Z. Chi, and K. K. Parhi, “Area-efficient High-speed decoding schemes for turbo 
decoders,” IEEE Trans. VLSI Systems, vol.10, no. 6, pp. 902-912, Dec. 2002. 
[66] E. Boutillon, W. J. Gross, and P. Glenn Gulak, “VSLI architecture for the MAP algorithm,” 
IEEE Trans. Communications, vol. 51, no. 2, pp. 175-185, Feb. 2003. 
[67] T. H. Tsai, C. H. Lin, and A. Y. Wu, “A Memory-reduced Log-MAP kernel for turbo decoder,” 
IEEE ISCAS, vol. 2, pp. 1032-1035, May 2005. 
[68] H.-M. Choi, J.-H. Kim, and I.-C. Park, “Low-power hybrid turbo decoding based on reverse 
calculation,” IEICE Trans. Fund. Electron. Comm. Comput. Sci., vol. E89-A, no. 3, pp. 
782–789, Mar. 2006. 
[69] D. S. Lee and I. C. Park, “Low-power log-MAP decoding based on reduced metric memory 
 42 
[87] J.C. Huang, C.M. Wu, M.D. Shieh and C.H. Wu, “An Area-efficient Versatile Reed-Solomon 
Decoder for ADSL,” Proc. IEEE International Symposium on Circuits and System, pp. 517-520, 
vol. 1, 1999. 
[88] H. M. Shao, T. K. Truong, L. J. Deutsch, J. H. Yuen, and I. S. Reed, “A VLSI Design of A 
Pipeline Reed-Solomon Decoder,” IEEE Transactions on Computers, vol. C-34, no. 5, pp. 
393-402, May 1985. 
[89] H. Lee, “Modified Euclidean Algorithm Block for High-Speed Reed-Solomon Decoder,” IEE 
Electronics Letters, vol.37, no. 14, pp. 903-904, July 2001. 
[90] H. Lee, “High-Speed VLSI Architecture for Parallel Reed-Solomon Decoder,” IEEE 
Transactions on Very Large Scale Integration (VLSI) Systems, vol. 11, no. 2, pp.288-294, April 
2003. 
[91] M. Sudan, “Decoding of Reed–Solomon codes beyond the error correction bound,” J. 
Complexity, vol. 12, pp. 180–193, 1997. 
[92] V. Guruswami and M. Sudan, “Improved decoding of Reed–Solomon and algebraic–geometric 
codes,” IEEE Trans. Inf. Theory, vol. 45, no. 6, pp. 1755–1764, Sep. 1999. 
[93] G. D. Forney Jr., “Generalized minimum distance decoding,” IEEE Trans. Inform. Theory, vol. 
IT-12, pp. 125–131, Apr. 1966. 
[94] D. Chase, “A class of algorithms for decoding block codes with channel measurement 
information,” IEEE Trans. Inform. Theory, vol. IT-I 8, pp. 170-182, Jan. 1972. 
[95] M. P. C. Fossorier and S. Lin, “Soft-Decision Decoding of Linear Block Codes Based on 
Ordered Statistics,” IEEE Trans. Inf. Theory, vol. 41, no. 5, Sep 1995 
[96] R. Koetter and A. Vardy, “Algebraic soft-decision decoding of Reed–Solomon codes,” IEEE 
Trans. Inf. Theory, vol. 49, no. 11, pp.2809–2825, Nov. 2003. 
[97] Z. Wang and J. Ma, “High-Speed Interpolation Architecture for Soft-Decision Decoding of 
Reed-Solomon Codes,” IEEE Transactions on VLSI systems, vol. 14, no. 9, Sep. 2006. 
[98] X. Zhang and K. K. Parhi, “Fast Factorization Architecture in Soft-Decision Reed-Solomon 
Decoding,” IEEE Transactions on VLSI systems, vol. 13, no. 4, April. 2005. 
[99] A. Ahmed, R. Koetter, and N. Shanbhag, “VLSI architectures for soft-decision decoding of 
Reed–Solomon codes,” in Proc. ICC, 2004, pp.2584–2590. 
[100] ——, “Reduced complexity interpolation for soft-decoding of Reed–Solomon codes,” in 
Proc. IEEE Int. Symp. Inf. Theory, 2004, p.385. 
[101] ——, “Systolic interpolation architectures for soft-decoding Reed–Solomon codes,” in Proc. 
IEEE Workshop Signal Process. Syst., 2003, pp. 81–86. 
[102] W. J. Gross, F. R. Kschischang, R.Koetter, and P. G. Gulak, “Towards a VLSI architecture for 
interpolation-based soft-decision Reed–Solomon decoders,” J. VLSI Signal Process., vol. 39, no. 
1–2, pp. 93–111, Jan.-Feb. 2005. 
[103] ——, “A VLSI architecture for interpolation in soft-decision list decoding of Reed–Solomon 
codes,” in Proc. IEEE Workshop Signal Process. Syst., 2002, pp. 39–44. 
[104] R. Koetter, J. Ma, A. Vardy, and A. Ahmed, “Efficient interpolation and factorization in 
algebraic soft-decision decoding of Reed–Solomon codes,” in Proc. IEEE Int. Symp. Inf. 
 44 
七、計畫成果自評 
本計畫所探討的範圍無論在目前的產品應用上或是學術的研究上，皆為熱門之技術。以
目前被廣泛討論的通訊標準 IEEE 802.16e 及 IEEE 802.11n 為例，兩系統之通道編碼已採用
低密度同位元檢查碼，而渦輪碼也被應用在 CDMA2000、WCDMA 及 IEEE 801.16 的標準
上。此外，相信不久的將來，軟性決定里德索羅門碼亦會被應用於數位通訊或磁碟儲存系統之
中。整體而言，目前之研究成果已完成原先預定目標的八成以上。計畫至目前為止之相關研究
成果歸納如下： 
論文及專利發表 
期刊 
[1] M.D. Shieh, T.P. Wang, and C.M. Wu, “Reducing Interconnect Complexity for Efficient Path 
Metric Memory Management in Viterbi Decoders,” IEICE Trans. Information and Systems, vol. 
E91-D, no. 9, pp. 2300-2311, Sep. 2008. 
[2] C. L. Wey, M. D. Shieh, and S. Y. Lin, “Algorithms for Finding the First Two Minimum Values 
and Their Hardware Implementation,” IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 55, no. 11, 
pp. 3430–3437, Dec. 2008. 
[3] M.D. Shieh, T.P. Wang, and D.W. Yang, “Low-Power Register-Exchange Survivor Memory 
Architectures for Viterbi Decoders,” IET Circuits, Devices & Systems, vol. 3, no. 2, pp. 83-90, 
Apr. 2009. 
[4] M.D. Shieh, Y.K. Lu, and S.M. Chung, “Efficient Reed-Solomon Decoder Design for 
Multi-Mode Applications,” Journal of Electrical Engineering, vol.16, no.6, pp.503-516. Dec. 
2009. 
[5] Y.K. Lu and M.D. Shieh, “High-Speed Low-Complexity Architecture for Reed-Solomon 
Decoders,” IEICE Trans. Inf & Syst. vol. E93.D, no. 7, pp. 1824-1831, July, 2010 . 
[6] M. D. Shieh, S. H. Fang, S. C. Tang, and D. W. Yang, “Low-Complexity Memory Access 
Architectures for Quasi-Cyclic LDPC Codes,” submitted to IEEE Trans. Very Large Scale 
Integr. (VLSI) Syst.. 
[7] M. D. Shieh, S. H. Fang, S. C. Tang, and D. W. Yang, “Design and Implementation of 
Overlapped Quasi-Cyclic LDPC Decoders with New Memory Arrangement Scheme,” in 
preparation for submission to IEEE Trans. Circuits Syst. II, Exp. Briefs. 
[8] Y.K. Lu and M.D. Shieh, “Design and Implementation of a Low-Complexity Reed-Solomon 
Decoder for Optical Communication Systems,” submitted to IEICE Trans. Inf & Syst.. 
 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本計畫與工研院資通所短期的合作計畫，計劃名稱為「平行 DVB-T channel 
decoder 之研發」。主要是協助開發 DVB 系統中所需之通道編解碼器，並有效運
行於 PAC DUO 工作平台。此合作案之內容與本計劃所探討之通道解碼器設計有
關，希望藉由本計畫之成果能縮短產業界系統開發之時程。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 ■申請中 □無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
期刊論文： 
國際：已發表 4篇，審查中 2篇，準備中 1篇 
國內：已發表：1篇 
 
會議論文： 
國際：3篇 
國內：1篇 
 
專利： 
美國專利：1件 
中華民國專利：1件 
 
合作案： 
本計畫與工研院資通所短期合作計畫，主要是協助開發 DVB 系統中所需之通道編解碼器。
