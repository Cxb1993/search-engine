 I
摘要 
近年來安全監控產業蓬勃發展，使一般監控設備都已朝數位化方式演進。但是這類設備儲存的檔
案通常極為冗長，常常包含一整天、一星期甚至數個月的內容。因此想在大量的檔案中，有效地進行
影像搜尋與瀏覽，就需要一些視覺化索引工具。我們先前的研究中，曾提出一個能有效地將靜態監控
影片內容濃縮的新技術，稱為擴增關鍵頁框(augmented keyframe)，是進行監控影片搜尋時，非常有效
的視覺化索引工具。本計畫基於先前的擴增關鍵頁框(augmented keyframe)研究架構，為更清楚表達擴
增關鍵頁框的內容資訊與移動軌跡，我們透過搭配使用三維幾何資訊及改進物體追蹤演算法來產生擴
增關鍵頁框。由相關資訊擷取之效率比較與使用者調查等實驗，可以證實這樣的關鍵頁框對影片的搜
尋工作非常有幫助。 
 
關鍵詞: 監控影片摘要、擴增關鍵頁框、影像三維幾何資訊、物體追蹤 
Abstract 
 The surveillance industry grows vigorously in recent years, and the monitoring equipments have been 
mostly digitalized. However, the recorded video files are usually very long, including contents for activities 
all day long or even several months. For retrieving and browsing the desired video file from the database 
efficiently, the user needs some visual indices. In our previous work, we proposed a new technique to 
efficiently condense the contents of a surveillance video clip captured by a static camera into a still picture 
(called “augmented keyframe”). The augmented keyframe can be an efficient visual index in searching of the 
surveillance video clips. This project is based on our previous work of the augmented keyframe and involves 
3D geometry information processing in addition to improving the accuracy of the object tracking algorithm to 
express the contents and trajectory information of the augmented keyframe more clearly. We show through 
the comparison and the user study in our experiments that the results are very helpful to the surveillance video 
search. 
 
Key words: Video Summarization, Augmented Keyframes, 3D Geometry Information in Image, Object 
Tracking 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 2
圖二.圖中顯示使用三維幾何資訊將取出的內容資訊合成到三度空間中的概念。我們可以藉由轉換不
同的視角，觀看三維空間中不同內容與移動資訊間的相互關係。例如圖中的視角a與b就分別呈現出不
同的投影結果：視角a接近相機所拍攝的角度，因此呈現出來的結果跟相機所拍攝出來的結果相似，
而視角b則是在相機鏡頭的上方，因此呈現由上往下觀看場景的內容資訊 
 
1.三維幾何資訊之擷取:取出場景三維幾何資訊之主要目的是希望可以透過圖二所描述的概念，將取出
的內容資訊合成到三度空間中。本計畫考慮到監控應用中，移動物體大部份都是在地板區域內移動，
因此我們將透過相機與地板間的關係，取得簡易三維幾何資訊以達成目的。研究過程透過下列三個步
驟完成三維幾何資訊的擷取工作: 
(1)取得相機內外在參數:首先透過自我校正(self calibration)[2]的相機校正方法取出相機的
內外在參數，在此我們參考Chen et al. [3]的方法(稱為parameterized cuboid structure (PCS)
方法)進行實作。此方法透過場景背景頁框(background frame)中指定的參考幾何形狀(如圖三(a))
之六個參考點(如圖三(b))，計算出相機內外在參數。 
(2)計算二維與三維地板的homograph轉換關係:接下來透過二維影像所決定的地板(如圖三(b)中
之點a、b、c，與d 所形成的地板區域)與三維空間中的地板(如圖三(a) 中之點A、B、C，與D 所
形成的地板區域)，找出一個homograph轉換關係。透過這個homograph轉換，可以找出較精準的二
維地板區域內之點座標所對應的三維座標。 
(3)計算二維與三維座標間的轉換:最後為了要計算出一些非地板區域的二維點座標所對應的三維
座標，我們設計了一個轉換演算法。即先利用二維地板與三維地板所計算出來的homograph轉換取
得對應的三維地板座標，再透過猜測一個最佳的高度值，取得整個三維座標資訊。 
 
(a) (b) 
圖三.(a)參考幾何形狀，(b)在背景頁框
(background frame)中點選指定的六個參考點 
 
2.監控影片內容與移動資訊擷取:此階段工作對應我們先前研究之內容擷取(content extraction)階
段。在此對輸入影片片段進行內容分析與擷取，以便取出有意義的移動物體內容資訊與其軌跡資訊。
在移動物體內容資訊擷取方法中，我們延續先前工作的方法，即透過對輸入影片片段進行背景訓練
(background modeling)，取得比較不被環境或雜訊干擾的背景影像，再利用訓練出來的背景影像，擷
取移動物體或是前景物體(foreground extraction)。此外為減低物體影像被陰影影響的情況，我們也
嘗試了一些影像陰影去除法(如Horprasert et al.[4])來消除影像之陰影部份。另外，關於移動物體
的軌跡資訊之擷取(object tracking)，我們也作了一些改進，以便獲取較精準的移動軌跡，我們改進
的方式為(詳細內容已投稿ICIP會議[5]): 
(1)首先透過所取出的移動物體影像之邊界框(bounding box)資訊，進行物體移動情況的判斷。在
此將物體的移動歸類成單一物體(single object)、物體遮蔽(occlusion)，與物體分離
(object-splitting)等三種最常見的移動情況。這三種移動情況的判斷方式顯示於圖四。 
 4
(4)內容與資訊的合成:內容與資訊的合成透過圖二所描述的概念來進行。合成過程中，所有要被
合成到三維空間的二維影像，都將其視為廣告牌(billboard)來合成，包含場景的背景影像、移動
物體的代表性影像，與臉部影像等。此外，在合成這些二維影像到三維空間時，我們先計算這些
二維影像的四個頂點所對應的三維座標，即透過第一階段的三維幾何資訊的轉換方法來進行。另
外要特別注意，合成代表性影像前要對二維影像進行homograph轉換，避免合成到三維空間再投影
後所造成的歪斜現象，如圖七所示。最後，在移動資訊合成的部份，為讓合成軌跡資訊看起來更
柔順，我們對整個軌跡平滑化 (smoothing)，而每一個三維標誌(3D icons)合成前，也要先計算
出對應的三維座標資訊。 
 
(a) (b) (c) 
圖五.在此顯示不同視角下之擴增關鍵頁框成果(a)正規視角(與相機同一視角)下之擴增關鍵頁框，(b) 
上視之擴增關鍵頁框，且只顯示三維軌跡(3D trajectories)資訊，(c) 上視之擴增關鍵頁框且只顯示
三維標誌(3D icons)資訊 
 
結果與討論 
圖五顯示本計畫之研究所產生的結果，使用的監控影片是由二樓往一樓拍攝而成。影片共有 1850
個頁框，影片中有七個移動物體(六個人及一輛轎車)。我們得到的擴增關鍵頁框內(圖五(a))也產生七
個代表性物件，且不同物件使用不同的顏色輪廓作為區別依據。每一個物件的上方還置入一個標號，
用來表示每一個移動物體出現的次序;此擴增關鍵頁框未呈現人臉影像，原因在於出現的人臉影像皆太
小，以至於無法偵測出來。圖五(b)是由計算所得資訊，調整相機視角產生的擴增關鍵頁框：在此視角
下，我們只顯示移動軌跡資訊，讓觀察的使用者可以清楚判斷影片內的移動物體間的移動情況，另外
圖五(c)和圖五(b)都是透過上視方式產生的擴增關鍵頁框，但是這邊顯示的是三維標誌(3D icons)。
三維標誌可用來觀察每一定義的單位時間內，移動物體的動作，如停止，左右移動等。每一個三維標
誌上，也可置放一些標號指明這些三維標誌出現的順序。此外，圖五(b)與(c)中不同的物體之移動軌
跡透過不同的顏色生成，以作為判斷不同移動物體的依據。 
 為證明我們所產生的擴增關鍵頁框有助於對監控影片的內容搜尋與檢索，首先與傳統方法產生的
關鍵頁框進行比較，如圖八所示。傳統方法產生的關鍵頁框乃是在固定時間間距，判斷在該時間點是
否有移動量的產生，抽取而得。與圖五的比較，可以發現我們的擴增關鍵頁框比較能表達出監控影片
的內容，且所產生的頁框數也較少。另外，我們也完成一個使用者測試 (user study)的實驗：在此實
驗中，有 24 個使用者參與。我們準備了三種搜尋工具，包含監控影片，傳統的關鍵頁框，及擴增關鍵
頁框等：請使用者分別使用這三種工具來找出 30 個指定的物件(譬如往某個方向走的人，某個人與某
個人交錯的位置等)。實驗中記錄每一個使用者用每一個工具所花費的時間。 24 個人分成六組，每一
組使用工具的順序相同。實驗結果顯示於圖九，可看出利用我們的擴增關鍵頁框進行影片內容搜尋時，
 6
    
    
    
圖八.透過在固定時間間距以及判斷取出時間點是否有移動量產生，所抽取出來的傳統
關鍵頁框 
 
0
100
200
300
400
500
600
700
800
Group using video Group using
traditional keyframe
Group using
augmented keyframe
(S
ec
on
ds
)
 
圖九.使用者測試實驗所記錄的時間平均與標準差之結果，記錄的單位為秒。 
 
參考文獻 
[1] G.C. Chao,Y.P. Tsai,and S.K. Jeng,“Augmented Keyframe,＂ J. Vis. Commun. Image R., vol. 21, no. 7, pp. 
682-692, May 2010.  
[2] Z.Zhang, “A flexible new technique for camera calibration,” IEEE Trans. Pattern Anal. Mach. Intell. Vol. 
22, no.11, pp. 1330-1334, 2000. 
[3] C.S. Chen, C.K. Yu, and Y.P. Hung, “New calibration-free approach for augmented reality based on 
parameterized cuboid structure,” in Proc. IEEE Int. Conf. Computer Vision, 1999, pp.30-37. 
[4] T. Horprasert, D. Harwood, and L. S. Davis , “A Statistical Approach for Real- time Robust Background 
Subtraction and Shadow Detection,” in Proc. ICCV. Frame-Rate workshop, 1999, pp.1-19. 
[5] G.C. Chao,S.K. Jeng,and S.S. Lee, “An improved occlusion handling for appearance-based 
tracking,”submitted to ICIP 2011. 
[6]A. Senior, “Tracking people with probabilistic appearance models,” in Proc. Int. Workshop Perf. Eval. of 
Tracking and Surveillance, 2002, pp. 48–55. 
[7] T. Koga, K. Iinuma, A. Hirano, Y. Iijima, and T. Ishiguro, “Motion compensated interframe coding for 
video conferencing,” in Proc. Nat. Telecommun. Conf., New Orleans, LA, Nov. 29–Dec. 3 1981, 
 1
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■  達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 ■申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他：（以 100 字為限） 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
本計畫研發之擴增關鍵頁框，學術成就主要在於改良了傳統監控影片之關鍵頁框。傳統關
鍵頁框結果只使用監控影片內的頁框(frame)當成關鍵頁框，而以這種形式呈現的關鍵頁
框，所包含的監控影片內容資訊經常不足：這些影格只能讓使用者知道影格當下出現的事
物，而無法讓使用者清楚了解整段影片發生的事情。我們提出的方法不僅解決傳統關鍵頁
框的問題，也開創了一個新的影片摘要研究領域。本計畫之研究成果，已發表於知名之 IEEE 
CSVT 期刊，相關研究內容也已申請美國及台灣專利。另外，為生成擴增關鍵頁框，我們提
出的流程架構與方法，濃縮與合成所抽取出來的影片內容。這些流程與方法皆屬新創，也
是首次被應用來生成擴增關鍵頁框。到目前為止，監控影片的搜尋仍然很沒有效率，並且
沒有一個最佳的搜尋方式出現，因此本研究所進行之擴增關鍵頁框研究，可相當加速監控
影片的搜尋工作。這樣的研究促使監控安全的技術更往前邁進一步，並可使社會保安工作
更進步。 
 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：鄭士康 計畫編號：99-2221-E-002-007- 
計畫名稱：運用 3D 資訊的監視影片內容摘要擷取與呈現 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 0%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 0% 
篇 
 
論文著作 
專書 0 0 0%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 0 0 0%  
博士生 1 1 100%  
博士後研究員 0 0 0%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 0% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 0%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 0% 章/本  
申請中件數 1 1 100%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 0 0 0%  
博士生 0 0 0%  
博士後研究員 0 0 0%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 0% 
人次 
 
 
