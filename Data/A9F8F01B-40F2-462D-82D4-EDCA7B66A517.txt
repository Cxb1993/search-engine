IThis is the end of a 3-year project. We have accomplished several results. All
of the results are published in leading international conferences or journals. We
feel that the results justify the scope and goal of this project. The results are
summarized as follows.
– Bo-Nian Chen, Bing-Jie Shen and Tsan-sheng Hsu∗, ”Chinese Dark
Chess,” International Computer Game Association (ICGA) Jour-
nal, volume 33, number 2, pages 93–106, 2010.
Chinese dark chess is a popular and easy-to-learn game in Asia. The charac-
teristc of possible revealing of unknown pieces makes it different from Chinese
chess or Western chess. Players with luck may win a game by chance. Thus,
there is a probabilistic behavior that a player has to consider. Computer Chi-
nese dark chess problems can be divided into three phases: 1) the opening
game, 2) the middle game, and 3) the endgame. Revealing pieces reasonably
and affectively is the main issue in the opening game. In the middle game,
the choice of revealing pieces or moving pieces becomes the critical issue.
Designing a good evaluation function is also important both in the middle
game and endgame. In an advantageous endgame, how to capture all op-
ponents pieces to win the game is also an interesting problem during the
endgame phase. Search-based methods, such as α-β pruning, are only good
enough in cases where no revealing actions is considered. However, programs
that reveal pieces reasonably and affectively have better playing strength in
our experiments. We propose strategies for considering the revealing actions
in this paper.
– Bo-Nian Chen, Pangfeng Liu, Shun-Chin Hsu and Tsan-sheng Hsu∗,
”Conflict Resolution of Chinese Chess Endgame Knowledge Base,”
Proceedings of the 12th Advances in Computer Games Conference,
(ACG), Springer-Verlag LNCS# 6048, pages 146–157, 2010.
Endgame heuristics are often incorperated as part of the evaluation func-
tion used in Chinese chess programs. In our program, Contemplation, we
have proposed an automatic strategy to construct a large set of endgame
heuristics. In this paper, we propose a conflict resolution strategy to elimi-
nate the conflicts among the constructed heuristic database, which is called
endgame knowledge base. In our experiment, the correctness of the obtained
constructed endgame knowledge base is high enough for practical usage.
– Meng-Tsung Tsai, Da-Wei Wang, Churn-Jung Liau and Tsan-sheng
Hsu∗, ”Heterogeneous Subset Sampling”, Proceedings of the 16th
International Computing and Combinatorics Conference (COCOON),
Springer-Verlag LNCS# 6196, pages 500–509, 2010.
In this paper, we consider the problem of heterogeneous subset sampling.
Each element in a domain set has a different probability of being included
in a sample, which is a subset of the domain set. Drawing a sample from
a domain set of size n takes O(n) time if a Naive algorithm is employed.
We propose a Hybrid algorithm that requires O(n) preprocessing time and
O(n) extra space. On average, it draws a sample in O(1+n
√
p∗) time, where
p∗ is min (pµ, 1− pµ) and pµ denotes the mean of inclusion probabilities. In
Chinese Dark Chess 1
Chinese Dark Chess
Bo-Nian Chen1, Bing-Jie Shen2, and Tsan-sheng Hsu3
Taipei, Taiwan
ABSTRACT
Chinese dark chess is a popular and easy-to-learn game in Asia. The characteristc of possible reveal-
ing of unknown pieces makes it different from Chinese chess or Western chess. Players with luck
may win a game by chance. Thus, there is a probabilistic behavior that a player has to consider.
Computer Chinese dark chess problems can be divided into three phases: 1) the opening game, 2)
the middle game, and 3) the endgame. Revealing pieces reasonably and affectively is the main issue
in the opening game. In the middle game, the choice of revealing pieces or moving pieces becomes
the critical issue. Designing a good evaluation function is also important both in the middle game
and endgame. In an advantageous endgame, how to capture all opponent’s pieces to win the game is
also an interesting problem during the endgame phase.
Search-based methods, such as αβ pruning, are only good enough in cases where no revealing actions
is considered. However, programs that reveal pieces reasonably and affectively have better playing
strength in our experiments. We propose strategies for considering the revealing actions in this paper.
Keywords: Chinese dark chess, dark chess, half chess, Banqi
1. INTRODUCTION
Chinese dark chess is a popular version of Banqi, a variation of Chinese chess that only uses half of the board,
also called dark chess, half chess or blind chess. 4 It is played in oriental countries where Chinese chess is played,
but with much more players. Most people playing Chinese chess play Chinese dark chess. A lot more people can
play Chinese dark chess while not able to play Chinese chess.
The pieces in Chinese dark chess are the same as those in Chinese chess: each player has sixteen pieces of one
color 5, including one king (K/k) 6, two guards (G/g), two ministers (M/m), two rooks (R/r), two knights (N/n),
two cannons (C/c), and five pawns (P/p). The board size consists of 4 × 8 squares, totally thirty two squares.
Unlike Chinese chess, pieces are placed within squares in Chinese dark chess. In the beginning of a game, all
pieces are randomly placed on the board with piece icons facing down so that piece types are unknown.
When playing a game, two players make actions alternately. There are two kinds of actions: 1) the flipping action
that reveals an unknown piece that is facing down, which is briefly called an unknown piece in this paper and 2)
the moving action that moves one revealed piece of his own color from a source to a destination or for the cannon,
it can jump over a piece. The unknown piece being flipped is called a revealed piece. From the above discussion,
we know the player who plays first must flip a piece.
1Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan.
email:f92025@csie.ntu.edu.tw.
2Department of Radiation Oncology, Far Eastern Memorial Hospital, Taipei, Taiwan. email:dale@iis.sinica.edu.tw.
3Corresponding author. Institute of Information Science, Academia Sinica, Taipei, Taiwan. email:tshsu@iis.sinica.edu.tw.
4The game, dark chess, is also a chess variant that players can only see their own pieces and the grids of their legal moves; half chess is
also a chess variant that uses half chess board; blind chess sometimes refers to blindfold chess, which is a training method that players do not
look at the board during playing.
5One side is Red. The other side is Black.
6We use upper-cased letters for the Red side and lower-cased letters for the Black side.
Chinese Dark Chess 3
1
2
3
4
5
6
7
8
a b c d
lz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lz
b2(G)-
1
2
3
4
5
6
7
8
a b c d
lz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz |g lz lzlz lz lz lz
b4(c)-
1
2
3
4
5
6
7
8
a b c d
lz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz |C lz lzlz lz lz lzlz |g lz lzlz lz lz lz
a2(N)-
1
2
3
4
5
6
7
8
a b c d
lz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz |C lz lzlz lz lz lz|n |g lz lzlz lz lz lz
b4-b2-
1
2
3
4
5
6
7
8
a b c d
lz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lzlz lz lz lz|n |C lz lzlz lz lz lz
a2-b2-
1
2
3
4
5
6
7
8
a b c d
lz lz lz lzlz lz lz lzlz lz lz lzlz lz lz lzlz lz lzlz lz lz lz|n lz lzlz lz lz lz
Figure 1: A sample opening game.
2. POSSIBLE RESEARCH PROBLEMS IN COMPUTER CHINESE DARK CHESS
As an incomplete information game, the Chinese dark chess problem is hard to be either weakly-solved or
strongly-solved. Unknown pieces make the result of a position undecidable. An exhaustive search algorithm
cannot precisely obtain the scores of positions with unknown pieces, but it can compute their approximated
value.
In this section, we will discuss the complexity of an exhaustive search in Chinese dark chess, and possible research
problems in the opening game, the middle game and the endgame.
2.1 Analysis of the Search Complexity
To start a game, we can only reveal a piece. In the opening game, there may be a few revealed pieces and
many unknown pieces in a position; some pieces are captured. When more pieces are revealed and captured, the
branching factor reduces. To analyze the branching factor, we use the following definitions.
Definition 1. The variable n is the piece number remaining on the position. We have n = nr + nf where nr is
the number of revealed pieces and nf is the number of unknown pieces.
Definition 2. The variable nt is the number of piece types that remains to be unknown. For example, we have
nt = 14 in the beginning of a game.
Definition 3. The estimated branching factor b = M(p) + R(p) where p is the current position. M(p) is the
number of nodes for computing moving actions, and R(p) is the number of nodes for computing flipping
Chinese Dark Chess 5
2.3 Issues in Piece Flipping
Three critical issues about flipping actions are: 1) when should a player flip pieces, 2) which place should a player
flip, and 3) how to analyze the positions after flipping a piece. Some possible heuristics for the three critical issues
are listed follows.
When should a player flip pieces? In the opening game, a player frequently flips pieces. It is generally consid-
ered appropriate to flip pieces when we cannot capture any piece and our pieces are not being captured.
However, the heuristic is not always correct. For example, when our piece is being threatened and unable
to move, flipping a piece may cause an exchange of pieces, or discover a new piece that protects the piece
being threatened.
Which piece should a player flip? When the opposite’s king is alive and our pawns are not yet revealed, we can
try to flip the unknown pieces adjacent to the opposite’s king. When at least one of our cannons are not
revealed, we can flip a piece that is behind the carriage in the same row or column of an opponent’s piece
to increase the chance of capturing pieces.
How to analyze the positions after flipping a piece? A flipping action results in nt possible variations. The
variable nt represents the number of unknown piece types. When nt = 1, the evaluation function of the
position after a flipping action is a precise value. Otherwise, we can only obtain an expected value out of nt
possible choices. When we compare two values in the search algorithm, a score that is an expected value
is less reliable. For example, we have two choices in a position with the scores of 10 and 20, respectively.
The score of the first choice is a precise value that is computed according to the best moves. The score
of the second choice is an expected value of three flipping actions. Assume the original scores of the
flipping actions are −20, 0, 80, respectively. If we only consider the score itself, we will select the value
20. However, there is a probability of 2/3 that the result will be worse than the choice of the value 10.
2.4 Issues in the Middle Game
The critical issue here in the middle game is how to design a good evaluation function. To decide which pieces
to remain on the board is an important issue in the middle game of Chinese dark chess. For example, the king,
though has the highest rank, is usually captured by pawns or cannons in early phase of a game if revealed.
Therefore, guards becomes as important as king. If both sides have neither king nor guards, ministers become
the pieces of the highest rank.
To design a suitable evaluation function, we may consider to represent piece values either by static or dynamic
strategy. Static piece value strategy uses a fixed table of the values of all pieces while dynamic piece value
strategy uses variant table. In Chinese dark chess, pawns are powerful pieces to attack the opposite’s king. The
material value of a pawn should be a high value when the opposite’s king is alive. After the king is captured,
pawns are more or less useless and can be ignored. By static piece value strategy, a pawn with a low value may be
easily captured. We can use dynamic strategy that gives pawns higher values when the opponent’s king is alive,
and gives them a low value otherwise.
Cannons are very powerful when carriages exist and the pieces that can threaten them are a distance away. A good
arrangement with cannons can even threaten pieces of high ranks such as king or guard. If a cannon is limited
in the surrounding of opposite’s pieces or unknown pieces, they can be easily captured. In a good evaluation
function, the score of a cannon is decided according to the situations above. Thus, we need to solve the following
two problems. The first is to consider the influence of other pieces on cannons. The second is to compute the
safety of a cannon.
It is easy to draw a game in the middle game by performing repeated moves. If a program tends to use repeated
moves to draw all the time, the games are very boring. A program that plays repeated moves in disadvantageous
positions is reasonable. Playing repeated moves in an advantageous position misses the chance of winning a
game. Hence, the judgement of advantage or disadvantage is a very difficult issue in the middle game.
Chinese Dark Chess 7
In endgames containing petty pieces, a player needs to use strategical method to win or draw a game. How to use
petty pieces reasonably is a problem to be studied.
3. IMPLEMENTING A CHINESE DARK CHESS PROGRAM
In this section, we will compare two basic search methods for Chinese dark chess. The first method is intuitively
a baseline method that do not handle flipping actions. The second method is an exhaustive search algorithm that
considers both moving actions and flipping actions. When searching a position with a flipping action, it expands
all unknown pieces with all types that are possible to appear. In our experiments, there is a great gap in playing
strength between the baseline program and the exhaustive search program. This emphasizes that reasonably
handles flipping actions is important in the game of Chinese dark chess.
3.1 Our Baseline Program
The baseline program shown in Algorithm 3.1.1 incorporates an nega-max search algorithm, a simple evaluation
function designed by static piece value strategy, and a flipping policy to decide whether we want to make a moving
action or a flipping action at the root. If a flipping action is selected, we randomly select an unknown piece to
reveal. When we visit a node with no moving action, we use the no-move cut strategy that calls the evaluation
function and returns the computed value.
3.1.1 Flipping Policy
The baseline program considers only moving actions. After the search algorithm returns a move with the best
value given a fixed depth or time limitation, we have two choices: 1) perform the best move that the search
algorithm suggested, and 2) perform a random flipping action. The flipping policy is a decision function to
identify when we should make flipping actions. We list three possible flipping policies below.
The first policy is move-first policy. When there is a moving action, we perform the search algorithm and play the
best move. Since a flipping action takes one ply, the move-first policy never wastes time flipping and just wait for
the opponent to flip all unknown pieces unless no legal move is found. However, when there is no effective move,
i.e., a move with a material gain, the program would rather making meaningless moves than trying to flip an
unknown piece. In addition, making meaningless moves sometimes leads to danger in the future. Furthermore, if
both players use this policy, their games seem to be draw all the time because they tend to make repeated moves.
To improve the move-first policy, we have the second policy, called comparing policy, which makes flipping
actions when no effective move exists. The strategy that determines when to flip pieces is a comparison algorithm.
The first idea is to compare the score of the best moving action and the average score of performing a flipping
action, which is performed by a null-move search. If the score of performing a flipping action is not worse than
the best moving action, we make a flipping action.
The comparison algorithm solves the problem of making meaningless moves. However, when a piece of the
opponent is to be captured for sure, the program usually does not capture it because the best scores computed
by an ordinary search and null-move search are both as good as obtaining that piece. If the opponent flips
surrounding pieces, the to-be-captured piece may have chances to escape. Furthermore, the revealed piece can
even threaten the potential attacking pieces.
Our third policy, take-advantage-or-flip policy uses the enhanced comparison algorithm that compares the imme-
diate evaluation score of the current position and the score of performing the best moving action. The immediate
evaluation score is the score of the position before making any move. If the score after performing a best moving
action is higher than the score of the original position, we choose the moving action. Otherwise, a null-move
search is used to determine whether to use the searched moving action or perform a flipping action. If the score
of the null-move search is higher than that of the previous best move, it means that the player gets higher value
when he does not move any piece. Thus, a flipping action is suggested. In this method, the program captures
unescapable pieces immediately. Thus, the behavior of a computer program is more like human players.
Chinese Dark Chess 9
Table 3: The result of BASIC v.s. ENHANCE.
First player Number of games Win Loss Draw
BASIC 100 9 34 57
ENHANCE 100 47 7 46
1
2
3
4
5
6
7
8
a b c d
|p|C
|G |G
|B
Figure 4: An example of a winning position.
3.3 Results and Discussions
Here we have done some experiments that contain 200 games to verify the playing strength of the two programs
discussed above. For fairness concern, the evaluation function of both programs are equal. Each player has a
time limit of 30 seconds for each play. The differences of the two programs are their search depth and their
strategies in handling flipping actions. Since initiative, the advantage of playing first, exists in many games, our
experiments also take initiative into account. The baseline program played first in 100 games, and the exhaustive
search program played first in the other 100 games.
The average branching factor among 1, 561 real game positions we test without flipping actions is 7.76. If we
also consider flipping actions, the average branching factor becomes 32.30.
The result of our experiments is shown in Table 3. The baseline program is named BASIC and the exhaustive
search program is named ENHANCE.
Although many games of them are draw, the winning rate of the exhaustive search program is much higher than
the baseline program. The result shows that the search depth and the strategy of handling flipping actions are
equally important.
In Chinese dark chess, a player having a great advantage sometimes needs to win the game with many moves
because he has to capture all pieces of the opponent. However, in a middle game position, it is not necessary to
search very deep to obtain a good move because the mobility of pieces except cannons in Chinese dark chess is
much less than pieces in Chinese chess or Western chess. In Section 4.2, we will discuss more about strategies
for setting the searching depth and handling flipping actions.
In this experiment, the ENHANCE program wins more when it plays first. The BASIC program does not have the
ability to handle flipping action. This also shows that reasonably flipping pieces is a critical skill in the opening
and middle game.
When a program is in a position that is considered to be a winning position, it usually needs deeper search to
obtain a correct move. For example, Figure 4 shows a winning position that the black side has a great advantage.
The only thing the black needs to do is to capture the red pawn. It takes at least fourteen plies for the program to
find such a winning strategy. We can increase the search depth or design a better evaluation function to solve the
problem.
Chinese Dark Chess 11
1
2
3
4
5
6
7
8
a b c d
|p lz |P lzlz |n |B lzlz |C lz lzlz lz lz lz|N |P |klz lz lz lzlz lz lz lzlz lz lz lz
Figure 6: An example of horizontal effect due to the no-move cut strategy.
definitions:
• RSp,q(p): the relative strength of p in comparing to q when p plays first.
• RSp,q(q): the relative strength of q in comparing to p when p plays first.
• winp,q(p): the number of games won by p when p plays first with q.
• winp,q(q): the number of games won by q when p plays first with q.
• drawp,q: the number of games drawn when p plays first with q.
RSp,q(p) = (2 ∗ winp,q(p) + drawp,q)/np,q
RSp,q(q) = (2 ∗ winp,q(q) + drawp,q)/np,q
The variable np,q represents the total number of games that p plays first with q.
RSp,q(p) +RSp,q(q) must be equal to 2.
Define advantage ratio of p in comparing to q:
AR(p, q) = RSp,q(p) +RSq,p(p)
This value is 2 when two programs p and q are roughly equal. This value is greater than 2 when p is better than
q. This value is smaller than 2 when q is better than p. AR(p, q) +AR(q, p) must be equal to 4.
The advanced result of our experiments is shown in Table 4. Any two of the programs have played 100 games
as the previous experiment in Section 3. The player p is ENHANCE program in odd rows. In even rows, p
represents refined programs.
VAR1 won the most game when ENHANCE program played first, but also lost the most game when it played
first. VAR3 steadily kept an advantage either playing first or not. Both VAR1 and VAR2 performed better when
ENHANCE program played first, but VAR3 performed better when playing first. According to their advantage
ratio values, VAR3 has a slight better performance than VAR1.
The initial-depth flipping strategy increases branching factor for the root node and may cause the searching depth
to be reduced. When a player is in advantage, a deeper search may help it to find a path to win the game. The
k-type expansion takes the advantage of considering flipping options and also improve the searching depth, but
the improvement is much less when comparing with initial-depth flipping strategy. Relatively speaking, random
piece order strategy performs better than fixed piece order strategy.
Chinese Dark Chess 13
8. APPENDICES
APPENDIX A: TWO SELECTED GAME RECORDS
1. ENHANCE v.s. VAR1
∗ 3 . d8 ( P ) d8−c8 4 . a6 ( p ) d7 (R)
∗ 5 . a5 ( p ) b8 ( P ) 6 . a4 ( r ) c8−d8
∗ 7 . b5 ( c ) b8−c8 8 . b7−b8 a8−b8
∗ 9 . b5−b8 c7 (G) 1 0 . b8−a8 c8−b8
∗ 1 1 . a5−b5 b8−b7 1 2 . a6−a5 c7−c8
∗ 1 3 . b4 ( P ) c8−b8 1 4 . c5 ( r ) b4−b5
∗ 1 5 . d3 (m) b8−a8 1 6 . c5−b5 c6 ( k )
∗ 1 7 . d5 (N) c4 (G) 1 8 . b2 (R) b7−c7
∗ 1 9 . c6−c5 c4−b4 2 0 . d6 ( g ) a8−b8
∗ 2 1 . d6−d7 c7−c6 2 2 . c5−d5 b4−b5
∗ 2 3 . a5−a6 b5−b4 2 4 . a4−a5 b8−c8
∗ 2 5 . b6 ( p ) c6−c5 2 6 . d5−d6 c8−b8
∗ 2 7 . d7−d8 b8−b7 2 8 . a3 ( c ) b7−b6
∗ 2 9 . a1 (M) a2 ( p ) 3 0 . a3−a1 b2−a2
∗ 3 1 . a5−b5 b6−b5 3 2 . a7 (C) a2−a1
∗ 3 3 . d8−c8 b5−b6 3 4 . a6−a5 c5−c6
∗ 3 5 . d6−d7 c6−c7 3 6 . d7−d6 a7−a6
∗ 3 7 . d6−d5 c7−c6 3 8 . d4 ( P ) d4−d5
∗ 3 9 . d3−d4 b6−b5 4 0 . c2 ( P ) c6−b6
∗ 4 1 . c3 ( n ) b4−c4 4 2 . d1 (K) c4−d4
∗ 4 3 . d2−c2 b5−a5 4 4 . b3 ( g ) d1−d2
∗ 4 5 . c3−c4 d4−c4 4 6 . c2−c3 d2−d3
∗ 4 7 . b3−b2 d3−c3 4 8 . b1 (N) b6−b7
∗ 4 9 . c1 (C) c4−b4 5 0 . c8−d8 c1−d1
∗ 5 1 . d8−c8 b1−c1 5 2 . c8−c7 a6−a7
∗ 5 3 . c7−c8 c3−c2 5 4 . c8−b8 c2−b2
∗ 5 5 . b8−a8 a5−a6 5 6 . a8−b8 a7−a8
∗ 5 7 . b8−a8 b7−a7 5 8 . a8−b8 a6−b6
∗ 5 9 . b8−a8 b6−b7 6 0 . a8−a7 b7−a7
∗ VAR1 wins
2. VAR3 v.s. ENHANCE
∗ 3 . a6 (M) d8 (m) 4 . c7 ( p ) a4 ( g )
∗ 5 . d6 ( P ) b5 ( r ) 6 . c5 (K) b6 (M)
∗ 7 . b6−b5 d8−c8 8 . a8−c8 c4 ( p )
∗ 9 . b8−a8 c4−c5 1 0 . b5−c5 b7 (R)
∗ 1 1 . b7−c7 d4 ( p ) 1 2 . c5−c4 a2 ( n )
∗ 1 3 . c4−d4 b2 (G) 1 4 . b2−a2 b1 ( p )
∗ 1 5 . a8−b8 b1−b2 1 6 . a2−b2 c1 ( g )
∗ 1 7 . b8−b7 a1 (N) 1 8 . a6−b6 b3 ( c )
∗ 1 9 . b6−a6 c3 ( P ) 2 0 . b7−b6 a7 ( k )
∗ 2 1 . b2−b3 c1−b1 2 2 . a1−a2 a7−a8
∗ 2 3 . b6−b7 c6 ( c ) 2 4 . c8−d8 d7 (R)
∗ 2 5 . c7−c8 c2 ( n ) 2 6 . d8−a8 a5 (G)
∗ 2 7 . a5−b5 a3 ( r ) 2 8 . a8−a4 a3−a4
∗ 2 9 . a6−a5 d1 ( p ) 3 0 . a5−a4 c2−c3
∗ 3 1 . b3−c3 b1−a1 3 2 . a2−b2 a1−b1
∗ 3 3 . c3−b3 d1−d2 3 4 . c8−c7 c6−b6
∗ 3 5 . b5−b6 b1−c1 3 6 . b3−c3 d2−d1
∗ 3 7 . b2−c2 c1−b1 3 8 . c3−b3 d1−c1
Conflict Resolution of Chinese Chess Endgame
Knowledge Base
Bo-Nian Chen1,?, Pangfang Liu2, Shun-Chin Hsu3, and Tsan-sheng Hsu4,?,??
1 Department of Computer Science and Information Engineering, National Taiwan
University, Taipei, Taiwan. r92025@csie.ntu.edu.tw
2 Department of Computer Science and Information Engineering, National Taiwan
University, Taipei, Taiwan. pangfeng@csie.ntu.edu.tw
3 Department of Information Management, Chang Jung Christian University,
Tainan, Taiwan. schsu@mail.cjcu.edu.tw
4 Institute of Information Science, Academia Sinica, Taipei, Taiwan.
tshsu@iis.sinica.edu.tw
Abstract. Endgame heuristics are often incorperated as part of the
evaluation function used in Chinese chess programs. In our program,
Contemplation, we have proposed an automatic strategy to construct a
large set of endgame heuristics. In this paper, we propose a conflict reso-
lution strategy to eliminate the conflicts among the constructed heuristic
database, which is called endgame knowledge base. In our experiment, the
correctness of the obtained constructed endgame knowledge base is high
enough for practical usage.
Keywords: Computer Chinese chess, Endgame Knowledge Base, Conflict Reduc-
tion
1 Introduction
A game of Chinese chess, like chess, can be divided into three phases: 1) opening
game, 2) middle game, and 3) endgame. Opening game is the first phase of a
game that almost all pieces are on the board. After about 20 plies, both two
players have moved their pieces to their important places and the game becomes
middle game. After exchanging some pieces, the game goes into endgame phase.
The most popular technique used to solve the opening game problem is con-
structing opening databases that stores all possible choices in previous games
[1]. In the middle game, people often use a nega-scout algorithm with a good
evaluation function and a nice move ordering scheme to obtain a good solution
[2]. There are also strategies in artificial intelligence that automatically generate
middle game evaluation functions [3]. In the endgame phase, the performance of
? Supported in part by National Science Council (Taiwan) Grants 97-2221-E-001-011-
MY3.
?? Corresponding author.
Conflict Resolution of Chinese Chess Endgame Knowledge Base 17
2.1 Using Lattice to Represent the Material Structure
There are seven types of pieces in Chinese chess: king (K), guard (G), minister
(M), rook (R), knight (N), cannon (C), and pawn (P). A material combination is
defined as the set of pieces in a position, e.g., KCMKRP is a material combination
that the red player has the king, a cannon and a minister; the black player
has the king, a rook and a pawn. A material combination is attached with a
score that describes its advantage without position information. Each material
combination has exactly an mirrored material combination such that the red
pieces and the black pieces are swapped. The material structure consists of a set
of material combinations. In our discussion, the material structure represents all
of the material combinations in our endgame knowledge base. Invariable nodes
are those modified or verified by our human expert and cannot be changed by
our conflict reduction algorithm.
The material combination structure can be viewed as a lattice. A lattice is a
partially ordered set(poset) that all non-empty subsets have a join and a meet
in mathematical order theory. A join is the least upper bound of an element or a
subset; a meet is the greatest lower bound of an element or a subset. All material
combinations in Chinese chess follow the piece additive rule that for a material
combination, adding pieces to a player cannot make him be disadvantageous if
we only consider material combination, not specific positions. The piece additive
rule also claims that removing a piece from a material combination cannot be
better than the original material combination. By applying piece additive rule,
the material structure can be transformed into a lattice which is a directed graph.
The node in the lattice represents a material combination. The edge connects
two material combinations that differ only one piece. We define x → y as two
adjacent nodes and the directed edge represents that the red player is at least as
advantageous in x as in y. In lattice, x→ y means that x and y are comparable
and the meet of x is y.
2.2 Construction Strategy of Material Structure
In the lattice, the least element is KK. We always expand the material structure
by adding either a red piece or a black piece. The number of possible piece types
on one side is 35 × 6 = 1, 458. Totally, there are 1, 4582 = 2, 125, 764 possible
material combinations in Chinese chess. An example of material structure is
shown in Fig. 1. A lattice can be divided into several levels. Each level contains
material combinations of the same piece number. In Chinese chess, there are at
most 32 pieces and at least 2 pieces, two kings, on a position. Hence, there are
totally 31 possible levels in our lattice.
It is not always correct to give a score to the material combinations on each
side. For example, KPPKGG and KPPKMM are generally red-win endgames
when pawns are not yet move to the palace of the opposite side in the starting
position of these endgame, but KPPKGM is generally a draw endgame. Thus, we
may conclude that KGM is better than KGG and KMM for defense. However,
KHPKGM and KHPKGG are generally red-win endgames but KHPKMM is a
Conflict Resolution of Chinese Chess Endgame Knowledge Base 19
combination has only one inconsistent edge, inconsistent percentage is 9.09%. In
this example, the first material combination is more likely to be incorrect and
should be modified first.
Fig. 2. Examples of two adjacent inconsistent nodes. The number in each node
is its score value. The edge with a cross means an inconsistent edge.
We need a standard endgame knowledge base that is considered as “correct”
for the conflict reduction algorithm. The algorithm discovers and modifies the
nodes in automatically-generated endgame knowledge base that are inconsistent
with some nodes in the standard endgame knowledge base.
3.1 Conflict Computation
If there is a conflict in a lattice, there must be some nodes having inconsistent
neighbors. Conflict computation procedure computes the number of inconsistent
neighbors of each nodes. When finishing the computation, information that we
actually want to know is the inconsitent number and information of the inconsis-
tency level. The level of inconsistency is relative to the inconsistent percentage
of the node. We define 10 levels of inconsistency, from level 0, level 1, ... , to level
9. Level 0 represents the inconsistent percentage in (0%−10%], level 1 represents
(10% − 20%], etc. Information of the number of nodes is in each inconsistency
level. It simplifies the process of reducing conflicts.
Our idea is a greedy method that always modifies a node of the highest
inconsistency level. We use inconsistent edge checking to find conflicts between
nodes. Inconsistent edge checking algorithm has two targets: 1) two neighbor
nodes, and 2) two mirrored material combinations. We implement the piece
additive rule which is defined in Section 2.1 for the first target. The second target,
a mirrored material combination pair in our lattice is virtually considered as the
same material combination. Inconsistent edge checking algorithm can ensure the
consistency of mirrored material combinations.
The algorithm of computing conflicts simply uses inconsistent edge checking
to summary the inconsistency neighbors for each node. Computing conflicts of
the whole lattice can be done in O(MN) time, where M is the maximum number
of the neighbors of a node, and N is the number of nodes.
3.2 Conflict Reduction Algorithm
The conflict reduction algorithm, shown in Algorithm 3.2 finds inconsistent nodes
in our lattice and modifies the score values of some nodes to reduce the number
of inconsistent nodes. It takes four steps to finish the work: 1) conflict compu-
tation, 2) candidate selection, 3) score value selection, and 4) modification. Our
algorithm repeats the four steps until no more candidate can be selected. The
Conflict Resolution of Chinese Chess Endgame Knowledge Base 21
return;
for each nn of n do
// compute possible values of nn that do not violate n
// variable count records the number of possible values
// variable score records which scores are possible values
(count, score) = ComputeRelativePossibleValue(nn, n);
// update if only one possible value
if(count = 1)
Modify(nn, score);
Diffusing(nn);
end if
end for
end procedure
Algorithm 4.1. Diffusing algorithm.
By performing diffusing algorithm, all nodes with only one possible value are
modified first and our algorithm reduces more conflicts.
4.2 Ranking and Scoring Strategies
We rank nodes in the lattice to indicate its degree of errors, called conflict rank.
Our algorithm picks one with the highest rank to update its value. In the basic
conflict reduction algorithm, we use inconsistent percentage as its conflict rank.
Here we define a better conflict rank:
V = Ni ×Nn
In the above formula, V represents conflict rank, Ni represents the number of
inconsistent neighbors, and Nn represents the number of neighbors. Instead of
dividing Nn, the new conflict rank multiplying Nn to emphasize the importance
of the number of neighbors.
In the step of score value selection, we use corrected score to measure the
whole level of inconsistency. Our conflict reduction algorithm always selects the
score value that minimizes the corrected score. In basic method, we use the
number of inconsistent nodes as the corrected score. Here we have developed a
new corrected score that favors small inconsistency levels as follows:
Vc =
9∑
i=0
2i × Ii
In the formula, the value Vc means corrected score, Ii represents the information
of inconsistency level i (see Section 3.1).
By using the new corrected scores, nodes with large inconsistent percentages
are usually reduced to smaller percentages. The new corrected score improves
the ability of identify better score values and thus decreases the probability of
fall into local minimum.
Conflict Resolution of Chinese Chess Endgame Knowledge Base 23
Table 1. Comparison of the reduction ability of the basic algorithm and the
refined algorithm. The error after BA and the error after RA columns show
the number of inconsistent nodes after performing the basic algorithm and the
refined algorithm, respectively.
DB size org error error after BA iterations error after RA iterations
END64 47621 14616 9786 6 970 3
END59 2722 1786 1330 3 166 2
END49 3938 1362 438 6 45 3
ENDALL 69595 16488 11108 6 585 4
By using all refinement techniques, we obtain the knowledge bases with much
less conflicts in less number of iterations. This reduces the work of the human
expert to verify and modify the endgame knowledge base.
In the second experiment, we show the correctness of our endgame knowledge
base after we performed random sampling verification. We have done three ran-
dom sampling experiments. In each experiment, we use an algorithm described in
Section 4.3 to generate different 695 nodes with parameters k = 4, p = 1%. After
the sampled nodes have been verified and modified, we performed our conflict
reduction algorithm with all refinement techniques on the ENDALL knowledge
base. We define the error distance as the difference between the score value of
the consistent endgame knowledge base and the score value verified by our hu-
man expert. Because the score values 4 and 5 represent very similar class of
advantage, the error distance between them is set to zero. In addition, the error
distance between any score value and 4 is consider equal to the error distance
between that score value and 5. We recorded the error distances of the modified
data and checked whether it is inverted. An inverted result is a result that is
wrong in the side who has advantage. For example, a node that the red side is
in advantage and is marked as black win is an inverted result. The result of this
experiment is shown in Table 2.
The probability of having error distance more than one is 2.20%. Note that
a node with a score value 4 or 5 cannot be inverted. Hence, inverted results
only happen when score values are less than 4 or more than 5. In other words,
inverted results happen when the distance is more than or equal to one. They
are also counted in the column of the distance is more than or equal to one. Al-
though the absolute correctness is 85.77%, which is acceptable, the correctness
with confidence is 97.70% ignoring one level difference. Evaluation of a material
combination as “win” or “win in most cases” is a subjective choice. Even hu-
man master or grandmaster may have subjective judgement in many practical
positions. Hence, we assume a difference of 1 level is tolerable.
In Table 3, we show the statistical comparison of the consistent endgame
knowledge bases after verification and their original versions. Since different
Conflict Resolution of Chinese Chess Endgame Knowledge Base 25
Table 3. The statistical comparison of the original endgame knowledge bases
and the final version of consistent endgame knowledge bases. IR means inverted
results. D represents error distance.
DB size ErrNum D ≥ 4 D = 3 D = 2 D = 1 D = 0 IR
END65 17038 1100 6 24 174 894 2 80
END60 422 48 2 6 8 32 0 8
END50 1499 222 4 16 34 168 0 10
END64 47621 20908 1056 2042 1952 15858 0 708
END59 2722 1734 594 390 142 606 2 290
END49 3938 1982 60 32 50 1840 0 50
ENDALL 69595 24486 1652 2392 2286 18154 2 1064
plation, and find it to steadily improve it strength against its previous version.
Its correctness is high enough for practical usage.
In the future, we will enhance our conflict reduction algorithm to be more
sensible of advantage. For example, KCCKCPGG and KCCKCGG differs only
by one pawn and they have score values 5 and 8, respectively. KCCKCRGG and
KCCKCGG differ by a rook and they also have score values 5 and 8. The degrees
of conflict-free expectation of the two above cases are different. In practical
usage, if the two cases are both inconsistent, in the latter case has a more severe
degree of conflict than the formal case. Another example is KRPKGGMM and
KRPKGGM who are assigned 0 and 9 respectivly in compared with the same
material combinations who are assigned 0 and 1, respectively. Although two cases
include a conflict, the first score values is more severe because the difference of
the score values is very obvious.
Combining the two representative examples, we can define a lattice with
weighted edges. The weight is defined as follows:
w = Dm(m1,m2)×Ds(Score(m1), Score(m2))
The variable w represents the weight which indicates the degree of conflicting.
Function Dm computes the difference between the two material combinations
m1, and m2; function Ds computes the difference between the two score values
of m1, and m2. The weight value follows the order: rook > cannon = knight >
pawn > guard = minister. The weight of guards and ministers should be ad-
justed dynamically: when the player has cannons, the weight values of guards
and ministers should be bigger than the ones without. Function score retrieves
the score value of a material combination. When a conflict occurs, the node with
a larger weight value needs to be taken care of first.
Knowledge Abstraction in Chinese Chess
Endgame Databases
Bo-Nian Chen1,?, Pangfeng Liu2, Shun-Chin Hsu3, and Tsan-sheng Hsu4,?,??
1 Department of Computer Science and Information Engineering, National Taiwan
University, Taipei, Taiwan. r92025@csie.ntu.edu.tw
2 Department of Computer Science and Information Engineering, National Taiwan
University, Taipei, Taiwan. pangfeng@csie.ntu.edu.tw
3 Department of Information Management, Chang Jung Christian University,
Tainan, Taiwan. schsu@mail.cjcu.edu.tw
4 Institute of Information Science, Academia Sinica, Taipei, Taiwan.
tshsu@iis.sinica.edu.tw
Abstract. Retrograde analysis is a well known approach to construct
endgame databases. However, the size of the endgame databases are too
large to be loaded into the main memory of a computer during tourna-
ments. In this paper, a novel knowledge abstraction strategy is proposed
to condense endgame databases. The goal is to obtain succinct knowledge
for practical endgames. A specialized goal-oriented search method is de-
scribed and applied on the important endgame KRKNMM. The method
of combining search algorithm with a small size of knowledge are used to
handle endgame positions in a limited depth but with a high correctness.
Keywords: Computer Chinese chess, Endgame Database, Knowledge Abstrac-
tion, Contemplation
1 Introduction
Chinese chess is a two-player zero sum game [1]. Many programs use opening
database for the opening game [2], NegaScout search algorithm with a domain-
dependent evaluation function for the middle game, and endgame databases for
the endgame. Although many Chinese chess programs have a master-level play-
ing strength, they sometimes do not perform well in the endgame. In 2002, R.
Wu, et al [3] proposed a memory-efficient retrograde algorithm to construct Chi-
nese chess endgame databases. Wu, et al [4] constructed large endgame databases
including KCPGGMMKGGMM in 2006. However, the databases are too large
to be loaded into memory. There are many even larger but practical endgames
needed to be handled. In 2008 and 2009, we proposed an automatic system to
? Supported in part by National Science Council (Taiwan) Grants 97-2221-E-001-011-
MY3.
?? Corresponding author.
Knowledge Abstraction in Chinese Chess Endgame Databases 29
complex but important endgame KRKNMM5 in Chinese chess as an example.
We perform a fast search on both drawing positions and hard winnable positions
with only a small size of memory. The forced positions are also suitable materials
for human players to learn the endgame.
The paper is organized as follows. We describe the concept of knowledge
in endgame databases in Section 2. Our method for abstracting knowledge is
introduced in Section 3. We discuss the results and some issues in Section 4. In
Section 5, we make our conclusions.
2 Knowledge in Endgame Databases
Human masters can handle large endgames by applying simple rules. These rules,
which are in human masters’ minds, are hard and time consuming to be written
out.
Here we illustrate the ideas about knowledge in endgames. An endgame is
generally considered as a set of positions with a set of pieces that differ by their
piece locations. Knowledge or rule is succinct description of a set of positions.
Our purpose is to find rules in the endgame KRKNMM so that these rules
can cover all positions in it.
2.1 The KRKNMM Endgame
Here we focus on a complex but important endgame KRKNMM. KRKNMM,
shown as an example in Figure 1, is an endgame that the red side, who has a
rook, wins in most cases, but the black side can achieve a draw in some positions.
This endgame is an important one in many Chinese chess endgame books [8, 9].
There is only one drawing configuration according to human experts, but there
are many winnable positions. It is not easy to win on winnable positions for
expert players.
KRKNMM is an essential endgame that is useful in real tournaments. The left
side of Figure 2 is an endgame played in the national individual title tournament
in mainland China 1999. The red side capture a black minister after 48 plies and
the black side gave up. The right side of Figure 2 is also a game played in the
national team title tournament in mainland China in 1999. The red side is in
advantage. To win this endgame, the red player needs to know two endgames: 1)
KRKNGG, which is an endgame that the red side wins in practically all cases,
and 2) KRKNMM, which has one drawing configuration and needs more moves
to win than KRKNGG. The red player transform this position into a position in
KRKNGG by piece exchanging in plies followed instead of KRKNMM because
the latter is more complex with a small chance of red drawing [10].
5 The pieces in Chinese chess are as follows: each player has sixteen pieces of one color,
including one king (K/k), two guards (G/g), two ministers (M/m), two rooks (R/r),
two knights (N/n), two cannons (C/c), and five pawns (P/p). The piece types of a
position is denoted as a string. KRKNMM is the positions where the red side has a
king and a rook, and the black side has a king, a knight and two ministers.
Knowledge Abstraction in Chinese Chess Endgame Databases 31
 
 
 
@
@
@
 
 
 
@
@
@
a b c d e f g h i
a b c d e f g h i
10
9
8
7
6
5
4
3
2
1
10
9
8
7
6
5
4
3
2
1
|K
|N
|B
|B|r
|k
|b |g |g
 
 
 
@
@
@
 
 
 
@
@
@
a b c d e f g h i
a b c d e f g h i
10
9
8
7
6
5
4
3
2
1
10
9
8
7
6
5
4
3
2
1
|K
|N
|G |G|B
|B
|r
|k
|P |p
|g |g|b |b
Fig. 2. The real endgames that use the knowledge of KRKNMM.
capturing the rook, the black with a knight can usually checkmate within 10
plies.
2.3 Simple Strategies for Reducing the Size of Endgame Databases
There are three simple strategies that can reduce the size of practical knowledge
in a endgame database:
1. Many endgame positions can be mapped to symmetric positions. If we do not
store symmetric positions, we can save about 1/2 of memory space. When we
want to obtain the result of a position, we have to query both the position
and its symmetric position. The reduced number of KRKNMM positions
becomes 13, 312, 530, which is about half of the size.
2. KRKNMM is considered as an advantageous endgame to the red side. There-
fore, we do not need to store red disadvantageous positions in the endgame
database. Similarly, a position in black player’s turn indicates that the red
side win positions do not need to be stored.
3. Winnable positions that can be solved by searching engines within a rea-
sonable time do not need to be stored. For example, general positions of
KRKMM can be solved within 11 plies within reasonable computing time.
It implies that in a KRKNMM endgame, the red side usually can capture a
knight or a minister within 11 plies. Thus, the positions that the red side can
win at less than or equal to 18 plies usually can be converged to a position
in KRKMM in 7 plies. As a result, we do not consider winnable positions
solvable within 18 plies in this paper.
When we eliminate the items from endgame databases, it causes the problem
of re-indexing the databases. However, our approach reduces the size of knowl-
edge into about 1/100 such that we can store the positions in the transposition
table.
Knowledge Abstraction in Chinese Chess Endgame Databases 33
3.1 The Scoring Scheme
There are three states in our goal-oriented search: 1) success, 2) failure, and 3)
unknown. The sucess state for the red side is to win the game, but for the black
side is to draw the game. The failure state is the complement of the success
state, ex., the red side fails when the game is a draw or loss.
We can simply map the success state, the unknown state, and the failure
state to 1, 0, and −1 in a general nega-max search, respectively. The unknown
state is a state better than the failure state, but worse than the success state.
When all other choices result in the failure states, the unknown state should be
the most desired choice.
For the purpose of drawing a game, any nodes with a success state are the
goals we need. It is not necessary to obtain the best score. However, for the
purpose of winning a game, we have to ensure that for any winnable position in
the set we are interested in, our algorithm can reach the goal. To achieve this,
the DTM value of the move reported by our algorithm must be less than the
DTM value of the query position. As a result, we define scores for each level of
intermediate goals in Table 2. The generalized definition of the scoring scheme
in goal-oriented search is as follows: a positive value for the success state, a
negative value for the fail state, and 0 for the unknown state. The range of the
score value is given as (−1000, 1000) in this paper.
For practical usage, we map the success state, the unknown state, and the
failure state to a positive integer, a zero, and a negative integer, respectively.
In Table 2, the positive scores mean the red side achieves the goal and negative
otherwise. A draw result, which is a failure state for the red side, is assigned with
a negative value. The checkmate score is 800. The difference of the checkmate
score between the scores of other winnable positions indicates the distance of an
intermediate goal to a final goal.
3.2 Goal-oriented Search Algorithm
Our goal-oriented search algorithm can be implemented by either an αβ pruning
algorithm or a NegaScout algorithm. In Algorithm 1, we implement it by a
NegaScout algorithm. In goal-oriented search, a quiescence search is critical to
avoid immediate losing or capturing moves. We only use the result evaluated by
the goal function in a quiescent position.
There are two different approaches between a goal-oriented search and a
generic αβ pruning search or NegaScout search. The first is that the evaluation
function of the algorithm is specially designed for a certain endgame. The second
is that we can perform interior node evaluation with a quiescence search.
We use the goal-oriented search for determining drawing positions. The re-
sult of abstracting drawing knowledge of the endgame KRKNMM is shown in
Section 4.2.
Knowledge Abstraction in Chinese Chess Endgame Databases 35
3.3 Position Induction Algorithm for Winnable Positions
By using the goal-oriented search algorithm alone, we cannot obtain satisfiable
results for winnable positions. Thus, we need to do additional knowledge abstrac-
tion. Our method is trying to find the set of critical positions, which is defined
as the positions with answers that are necessary for the goal-oriented search
algorithm to report the correct result of a position, denoted as CRP (x, p, d).
We want to find a minimal set of CRP so that the value of p% positions in
the endgame position set x can be determined with the goal-oriented search of
depth ≤ d. The value of d can be determined according to the searching speed. It
is hard to find the minimum CRP (x, p, d), however, a minimal set is good for our
purpose. If we have a large enough memory, we do not care whether CRP (x, p, d)
is minimal, but any candidate should be accessed quickly in CRP (x, p, d). To
access the positions in a transposition table matches the speed requirement.
The algorithm to construct CRP (x, p, d) is called position induction algo-
rithm, which is shown in Algorithm 2. it incorporate a goal-oriented search and
compare the result with the endgame database. If the search result is wrong, the
algorithm adds the query position into the set CRP (x, p, d). The stored positions
are considered as essential knowledge of the KRKNMM endgame. During search-
ing the set of query positions, the positions needed to be fed into CRP (x, p, d),
are stored in the transposition table. Thus, other positions may also use the
stored positions. More query positions uses the stored positions, the lower re-
duced size will be achieved.
Algorithm 2 Position induction algorithm
function PositionInduction(position set, depth limit)
for all position in position set do
r = GoalNegaScout(position, depth limit,−∞, ∞)
if CheckDatabase(r) = wrong or r = unknown then
StoreToTable(tr table, position, GetDatabaseResult(position))
for all position in tr table do
AddCRP(crp set, position, GetDatabaseResult(position))
return crp set
4 Experiments and Discussions
The KRKNMM endgame knowledge is used either when our program plays red
or black. When it plays red, we need knowledge about winnable positions; when
it plays black, we need knowledge about drawing positions. Hence, we design
two experiments for the two different purposes of approximated machines.
We have two experiments. The first experiment takes the set of black-first
drawing positions without symmetric positions as our test data, called TEST DRAW.
Knowledge Abstraction in Chinese Chess Endgame Databases 37
The number of the critical position of TEST WIN18 is 175, 741. The number
of incorrect positions is 15, 030, the correct percentage is 97.09%. The total
knowledge size is 190, 771 items, which is 36.94% of the original database size.
4.4 Discussions
For the TEST DRAW set, we can obtain the knowledge that is in about 1/100
of the original size. However, the complexities of winnable positions are much
higher such that we can only obtain a minimal knowledge set of about 1/3 size
of the TEST WIN18 set.
In our experiment for winnable positions, we only use depth limit = 2 to
construct the critical position set. Increasing the value of depth limit does not
produce noticeable improvement because we have no general knowledge about
the winnable positions at KRKNMM.
The original KRKNMM endgame database contains 24, 079, 140 positions.
We use knowledge abstraction strategy to select only 1, 217 drawing positions
and 190, 771 winnable positions, which is 0.79% of the original size. These posi-
tions are considered to be the critical knowledge for computers to conquer the
KRKNMM endgame. The knowledge is small enough to be stored in the trans-
position table. The positions that are not stored can either be solved by the
goal-oriented search or generic search engines.
5 Conclusions and Future Work
Chinese chess is a popular game in Asia. There are also many strong Chinse
chess programs that are at the level of human masters. Many programs cannot
be beaten in the opening game and the middle game. Hence, the playing strength
in endgame becomes very important for today’s programs.
There are many available endgame databases constructed by retrograde anal-
ysis. We need a large disk to store these endgame databases. However, there
are many positions in endgame databases that are unnecessary in the sense
that they can be easily solved by using information available elsewhere in the
database. Therefore, we propose a knowledge abstraction method that applies
a goal-oriented search to find critical positions. We do our experiments in a
complex but important Chinese chess endgame, KRKNMM. We perform our
goal-oriented search algorithm for drawing positions and the position induction
algorithm to find critical positions for winnable positions. The obtained critical
positions can also be an intelligent tutoring system that teaches human players
how to draw and win an endgame.
Our goal-oriented search and position induction algorithms can be used in
many endgames of Chinese chess, Western chess or other games to reduce the
size needed of endgame databases. For the endgames with simple rules, we can
handle it by only goal-oriented search; for complex endgames, we use both the
two algorithms to reduce the size of knowledge. The amount of reduction depends
on the structure of the original database.
Heterogeneous Subset Sampling?
Meng-Tsung Tsai??, Da-Wei Wang, Churn-Jung Liau, Tsan-sheng Hsu? ? ?
Institute of Information Science
Academia Sinica, Taipei 115, Taiwan
{mttsai,wdw,liaucj,tshsu}@iis.sinica.edu.tw
Abstract. In this paper, we consider the problem of heterogeneous sub-
set sampling. Each element in a domain set has a different probability of
being included in a sample, which is a subset of the domain set. Drawing
a sample from a domain set of size n takes O(n) time if a Naive algo-
rithm is employed. We propose a Hybrid algorithm that requires O(n)
preprocessing time and O(n) extra space. On average, it draws a sample
in O(1 + n
√
p∗) time, where p∗ is min (pµ, 1− pµ) and pµ denotes the
mean of inclusion probabilities. In the worst case, it takes O(n) time to
draw a sample. In addition to the theoretical analysis, we evaluate the
performance of the Hybrid algorithm via experiments and present an
application for particle-based simulations of the spread of a disease.
1 Introduction
Problem HSS. Heterogeneous subset sampling involves drawing several sam-
ples from a domain set of size n. Without loss of generality, let the domain set D
be {1, . . . , n} in which each element i is associated with an inclusion probability
pi. For each drawn sample, which is a subset of the domain set, the probability
of element i being included is equal to the given inclusion probability pi. As it is
necessary to draw several samples from the exemplar application in this paper,
and potential new applications, we need to devise an efficient method to achieve
the task. Complexity is analyzed under the computation model of random access
machine, which supports operations on floating-point numbers with a precision
of d digits. In addition, we assume it takes O(1) time to calculate lnx with a
precision of d digits and to generate a variate with a precision of d digits from
the standard uniform distribution U(0, 1).
The homogeneous case, in which all pi are identical, is almost equivalent to
generating variates from a binomial distribution. However, only a few works, such
as [14], have considered the heterogeneous case and they focus on the size of the
drawn sample rather than the elements included in it. Although the approach
calculates the size of the drawn sample, it does not provide an efficient reduction
? Extended from the technical report TR-IIS-10-002, IIS, Academia Sinica, Taiwan.
http://www.iis.sinica.edu.tw/page/library/TechReport/tr2010/tr10002.pdf
?? Supported in part by National Science Council (Taiwan) Grants NSC 97-2221-E-
001-011-MY3.
? ? ? Corresponding Author.
Heterogeneous Subset Sampling 41
Algorithm 1 details the steps of a Naive algorithm for the HSS problem.
To determine whether an element i should be included in a drawn sample, the
algorithm compares its inclusion probability pi with a variate generated from
U(0, 1). Because the size of the domain set D is n, the total cost is O(n), which
would be the lower bound of the HSS problem if it were necessary to make the
decisions one by one.
2.2 Sieve Algorithm
Algorithm 2: Sieve algorithm
input : a domain set D = {1, . . . , n} in which each element i is associated
with an inclusion probability pi
output : a drawn sample S
pM ← max(p1, . . . , pn)1
k ← B(n, pM )2
R← SWOR(k,D)3
S ← φ4
foreach i ∈ R do5
t← U(0, 1)6
if t < pi/pM then7
S ← S ∪ {i}8
return S9
Procedure SWOR(k,X)
built-in: an array E of size n, where E[i] = i for all 1 ≤ i ≤ n
input : an integer k, where k ≤ |X| ≤ n and a set X = {X1, . . . , X|X|}
output : R, a randomly selected subset of X, whose size is k
R← φ1
for i = 1 to k do2
t← U(0, 1)3
t← min(bt(n− i+ 1)c, n− i)4
exchange E[i+ t] with E[i]5
R← R ∪ {XE[i]}6
re-swap array E into the built-in state7
return R8
The rationale for the proposed Sieve algorithm, Algorithm 2, is that instead
of making a decision about each element in the domain set, we consider a smaller
subset selected by a designed mechanism. Then, we only make decisions about
the elements in the subset.
The designed mechanism is based on a simple idea. Specifically, for each
element i in the domain set, we decouple the decision about it being included in
Heterogeneous Subset Sampling 43
Proof.
Pr
( ⋂
i∈R
(EVi)
)
=
n∑
x=|R|
Pr((k ← B(n, pM )) = x) Pr(R ⊂ SWOR(k,D))
∏
i∈R
Pr(Bi)
=
n∑
x=|R|
(
n
x
)
pxM (1 − pM )n−x
(
n− |R|
x− |R|
)
(
n
x
) ∏
i∈R
Pr(EVi)
pM
=
∏
i∈R
Pr(EVi) uunionsq
Procedure SWOR(k,X) requires O(n) time to initialize the built-in array E
and O(n) space to accommodate it. Each invocation of Procedure SWOR(k,X)
executes a loop of k iterations (Lines 2-6). Then, the procedure re-swaps the
array E into the built-in state, where there are at most 2k differences between
the two status (Line 7). Therefore, the time complexity of each invocation of
Procedure SWOR(k,X) is O(k + 1).
The Sieve algorithm requires O(n) time to calculate pM (Line 1). This step is
ignored in subsequent invocations under the same problem setting. For each in-
vocation, a binomial variate k is generated (Line 2) and Procedure SWOR(k,D)
is invoked once (Line 3), after which a loop of k iterations is executed. Let
C(B(n, p)) denote the cost of generating a variate that follows a binomial distri-
bution B(n, p). Then, the following lemma can be derived.
Lemma 3. Solving the HSS problem with the Sieve algorithm requires O(n)
preprocessing time and O(n) extra space; and the time complexity of drawing
each sample is
O(C(B(n, pM )) + k + 1) . (1)
Several works focus on binomial random variate generation, e.g., [3] [4] [8]
[9] [12]. In [8], the authors report the results of comparing a number of algo-
rithms in experiments. Provided the generated variate is k, Algorithm BG [3]
needs O(k + 1) computation time for each sampling and Algorithm BALIAS
[8] is O(1) fast but requires O(n) preprocessing time and O(n) extra space. In
[8], they also conclude that the proposed Algorithm BTPE is the most effective
when µ is moderate or large, where µ is the product of the parameters n and
p in B(n, p). For cases where µ is small, Algorithm BINV [8] dominates. Since
there is no difference between the binomial variate generation algorithms in our
theoretical analysis whose complexity can be bounded by O(k + 1) and prepro-
cessing time can be bounded by O(n), we let C(B(n, p)) be O(k + 1) without
specifying which efficient binomial variate generator should be used. In [8], the
authors conclude that the combination of Algorithms BINV and BTPE is the
fastest experimentally. Hence, we adopt this combination to run our experiments,
which we discuss in Section 3. To be noticed, lnx operation is needed by several
binomial samplings [3] [8].
Heterogeneous Subset Sampling 45
Remark 3. When 1−pM < pM , it is easier to draw the complement of a sample.
In Algorithm 3, let pi = 1− pi for all i ∈ D and Line 5 be S = D− (sieve(X)∪
naive(Y )), by Lemma 4, the average time complexity to draw each sample is
O(1 + n
√
1− pµ) if Line 5 can be achieved in average O(k + 1)-time after O(n)
preprocessing time.
Procedure Complement(D,X) /*X ⊂ D*/
Initialization(D): Deletion(i): Recovery(X):
for i ∈ D ∪ {0} do next[prev[i]]← next[i] for i ∈ X do
prev[i]← i− 1 prev[next[i]]← prev[i] next[i− 1]← i
crnt[i]← i prev[i+ 1]← i
next[i]← i+ 1
As shown in Procedure Complement(D, X), the initialization requires O(n)
preprocessing time and the deletion of set X and recover to the initial state
take O(k + 1) time. Therefore, the assumption in Remark 3 holds. Combined
the results of Remarks 2 and 3, the Hybrid algorithm solves HSS problem in
average complexity O(1+n
√
p∗) where p∗ = min(pµ, 1−pµ). More details of the
used data structure can be found in Chapter 10.3 of Book [2]. For the ease to
compare, the complexities of the introduced algorithms are listed in Table 1.
Algorithm Preprocessing Time Time to Draw Each Sample Extra Space
Naive − avg: O(n) worst: O(n) −
Sieve O(n) avg: O(1 + npM ) worst: O(n) O(n)
Hybrid O(n) avg: O(1 + n
√
p∗) worst: O(n) O(n)
Table 1: Complexity comparison.
3 Experiment Results
In this section, we compare the performance of the Naive and Hybrid algorithms
via experiments. Then, we demonstrate how the Hybrid algorithm can improve
the performance of a practical application substantially. The implementation of
the combined BTPE and BINV algorithms [8] was downloaded from GSL1. All
experiments were run on a workstation with Intel Xeon 3.2GHz processors.
3.1 Experiments
We conducted a number of experiments to assess the speedup and relative error of
the Hybrid algorithm in solving the HSS problem. Let EN (n, pµ) and EH(n, pµ)
be an experiment that draws 100 samples with Naive and Hybrid algorithms
respectively, where |D| = n and ∑i∈D pi/n = pµ. In addition, let S(n, pµ)
denote the ratio of the running time of EN (n, pµ) to that of EH(n, pµ); note
that the preprocessing time is included. Let AX(n, pµ) be the average size of
the samples drawn in the experiment EX(n, pµ); and let R(n, pµ) denote the
1 GNU Scientific Library http://www.gnu.org/software/gsl/
Heterogeneous Subset Sampling 47
of factors, such as the nature of the disease, the intervention methods applied to
it, and the closeness of I and S. In other words, p varies between different (I, S)
pairs and also for the same pair in different time periods.
Following the approach in [6], we construct a simulation model based on
Taiwan’s census data and apply the Hybrid algorithm to it [15]. As shown in
Figure 2, the value of p is usually quite small in the simulation model of disease
transmission, as a person seldom has close contact with a large number of family
members or friends, compared to the number of casual contacts encountered
daily. Figure 2 also shows that setting
√
pµ as pthres is not appropriate. In
practice, to maximize the speedup, pthres can be adjusted dynamically based
on the distribution of inclusion probabilities. Figure 3 compares the simulated
results, the attack rates, and the differences between the computational cost of
the two algorithms. Based on the figure, we conclude that the Hybrid algorithm
can improve the performance of particle-based disease simulation substantially,
without changing the behavior of the model.
105
106
107
108
109
1010
1011
10-7 10-6 10-5 10-4 10-3 10-2 10-1 100
n
u
m
be
r o
f c
er
ta
in
 p
i
inclusion probability pi
pµ pµ
1/2
Fig. 2: Histogram of pi in the disease transmission model.
4 Concluding Remarks
In this paper, we propose an algorithm, called the Hybrid algorithm, to solve the
problem of heterogeneous subset sampling. We prove the correctness of the algo-
rithm and show that time complexity is O(1 + n
√
p∗). In addition, we evaluate
the performance of the algorithm via experiments and demonstrate its efficacy
by a practical application. The experiment results show that the speedup is sub-
stantial when pµ deviates from 1/2. Moreover, the exemplar application demon-
strates that the Hybrid algorithm can be used effectively to simulate particle-
based spread of a disease, without changing the behavior of the model. We
believe the proposed Hybrid algorithm can be applied to many other problems.
In this paper, we focus on dividing the domain set into two groups and solving
each of them with a proper algorithm. This method can be extended to improve
the performance further. In a future work, we will divide the domain set into
O(log n) groups, where the i-th group consists of the elements, whose inclusion
probabilities are in the interval [21−i, 2−i) for all 1 ≤ i ≤ logn, and the remain-
ing elements are contained in the last group. Solving each group with the Sieve
algorithm, the average complexity to draw each sample is O(log n + npµ). We
will also consider how to dynamically divide the domain set according to the
distribution of the inclusion probabilities.
本人計劃之出國經費，
已經用於出席詳見會議。
原核定清單項目中
國外出差或研習項目也利用
出席國際會議場合完成。
詳見出國開會報告。
 
	
 
REPORT FOR ATTENDING INTERNATIONAL CONFERENCES 
    
Name 
 
	 
Institute & Position 
	
	
  

      	 
Title of Meeting 
  
Chinese 
7th International Conference on Computer Games and 15th 
Computer Olympiad 
English 
    
Date of Conference 
2010/9/24 ~ 2010/10/2    
Location 
!" 
       
Source of Travel Funding  Applying for Funding Supported by: 
  
!
" Funded by Conference !#$ Self-funding
 

%&' Report 
Notes:  
The report should be typed on A4 paper in approximately 1000 words containing events of conference, reflections, 
comments or suggestions … etc. Please do not use attendee’s own paper(s) or document(s) collected from the 
conference as the main part of the report. 
	
( !"# A4$%&'!()
*+,(-) 
1../  
2.01  
3.23  
4.456
 
#$%&'  
6 6 789:;<=>?@A7th International Conference on Computer GamesBC89DEFGHIJ;(15th 
Computer Olympiad) KLM 2010N 9O 24P~10O 2PQPRS-TUV International Computer Game 
Assocation (ICGA)!WXYQZ[\ Shiinoki Cultural Complex, Ishikawa Prefecture-]^_`abc?d
_:^- 
6 6 efghi!^ oral presentationjQkhPlmkno section-p^Qabc
qrst!?duvwxHy<z{|}~-u+o~!+~y<z
!z1 +~1y<{|}!y<-presentation
{Q ¡¢g interesting!£¤¥¦§h¨©o¦ª!«¬­®¯`°^±²³´µ¶01!
Q³·l¸¹º»- 
Q¼Pe{!@ UCT½¾¿!ÀÁuÂÃSÄÅÆÇ±ÈY UCTÉÊËpª-£¤`Ì°
ÍÎu²¾¿!QÏÐÑHI-ÒÓÔ`1. °oÕÖ×Ø²ÙÚHÛ!£
KPÜHe#-2.  proof number search²ÝÞH¦ª- 
knPeXßàáâ¾¿¨ã<zäåæªç!Rèéêë1. ì@ßàáâíîÉÊ
Óï!£ð+ñÙºÉÊQò>lóô- 2. ßàáâÉÊ²õö Amazons÷øã<z-
ùú!Pû`@°^÷ø½ª!èëQ Yahtzee°^÷ø{üýþÉÊ- 
6 6 khPeX45HIª!èë1. Q°^÷øl@ëßàáâÉÊ-2. 	h^÷
ø Lattice
-3. Q Synchronized Domineeringu-6
 Computer Olympiad{89xHÇ+f` 5!4{f`h!	
]Âi
SÆ³]?ÍÂH Æ!"ê#$ö?ÍÂxH%Æ-ú`n&;'
(ÂHaQiKi DÆ-./ 10)*+¥!]ÂiSÆ,-./-6
6 6 ú!abcqrQ Computer Olympiad{ã01HAChinese dark chessB2;Ç!;f`3
!Q 5)*+{!]ÂLeave or LoseÆe#415/- 
 
($)* 
6 6 89xHe#QHÛ~½67!8899 :`°;0 CPU<=!¯íîÉÊô>?ÃSÄÅ
½×!ð+ñ@íîóA-]e#BÂiSÆCKQã<~`DHE2Fã<z¨{
<:y<QíîÉÊ!G<~H`IýÄ!JùKLMNo7e#'O!ÈÀ41ÐPQ- 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/30
國科會補助計畫
計畫名稱: 巨量資料的高效率演算法設計暨實做
計畫主持人: 徐讚昇
計畫編號: 97-2221-E-001-011-MY3 學門領域: 計算機理論與演算法
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
指導研發電腦象棋程式 TMSK 獲 2010 年第十五屆 Computer Olympiad Silver 
medal 
 指導研發電腦暗棋程式獲 2nd TAAI Cup Ｇold and Bronze medals 
 指導研發電腦暗棋程式獲 2010 年第十五屆 Computer Olympiad Bronze medal
 指導研發電腦象棋程式 TMSK 獲 2009 年第十四屆 Computer Olympiad Gold 
medal 
 
 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
