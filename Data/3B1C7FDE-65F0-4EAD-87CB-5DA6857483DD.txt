行政院國家科學委員會專題研究計畫成果報告 
全域性無線數位家庭多媒體網路管理 
計畫編號：NSC 94-2213-E-004-011 
執行期限：94年 8 月 1 日至 95年 7 月 31 日 
主持人：蔡子傑   國立政治大學 資訊科學系 
計畫參與人員：江啟宏、李政霖、林建圻、張碩瀚、王川
耘、劉姿吟 
 
此 成 果 報 告 為 五 篇 論 文 的 集 節 ： 
[1] Tzu-Chieh Tsai, Cheng-Lin Li, Tsung-Ming Lin, 
"Reducing Calibration Effort for WLAN Location 
and Tracking System using Segment Technique" in 
The IEEE International Workshop on Ad Hoc and 
Ubiquitous Computing (AHUC2006), Taichung, 
T a i w a n ,  J u n e  5 - 7 ,  2 0 0 6 . 
[2] Tzu-Chieh Tsai, Tzu-Yin Liu, "Bandwidth 
Routing Support for Wireless Multihop Networks", 
in IEE Mobility Conference 2005: The Second 
International Conference on Mobile Technology, 
Applications and Systems, Nov 15-17, 2005, 
G u a n g z h o u ,  C h i n a .  ( E I ) 
[3] Tsai Tzu-Chieh, Lin Chien-Chi, "Efficient 
Routing Path Selection Algorithm based on Pricing 
Mechanism in Ad Hoc Networks", in International 
Computer Symposium (ICS 2006), Taipei, Taiwan, 
D e c  0 4 - 0 6 ,  2 0 0 6 .  
[4] Chi-Hong Jiang, and Tzu-Chieh Tsai, "Token 
Bucket Based CAC and Packet Scheduling for 
IEEE 802 .16  Broadband Wire less  Access 
Networks", in IEEE Consumer Communications 
and Networking Conference 2006 (CCNC2006), 
Special Session on Multimedia and QoS in Wireless 
Networks, MP1-02-3, Jan 8-10, 2006, Las Vegas, 
U S A . 
[5]  Tzu-Chieh Tsai ,  Sol-Han Chang, “The 
Streaming Service Platform based on EATCP for 
Heterogeneous Wireless networks”, submitted to  
IEEE Wireless Communications & Networking 
Conference (WCNC 2007), Hong Kong, Mar 11-15, 
2 0 0 7 . 
首先我們先整理摘錄此五篇論文在本計畫中的關聯
度與重要成果，後附上完整論文內容供參考。其中
第五篇在審查中，基於智慧財產權，暫不附全文，
請見諒。 
 
一、Abstract 
 
近年來數位家庭與無線網路硬體技術的逐漸
發展，使得建置一個smart home environment 的願景
逐步呈現。這樣一個環境必須能夠感知個人情境，
隨時隨地能透過周邊的智慧型數位家電，擷取多媒
體個人資訊，並隨著行動過程，藉由週遭感知設
備，自主追蹤及定位相關個人或數位家電位置，而
能提供具一定服務品質的資訊遞送。 
 
我 們 假 設 家 中 有 一 個 Media & Network 
server來統一控管整個家的網路環境設備與系統。
使用UPnP(Universal Plug and Play)的概念，讓
所有的intelligent devices一旦啟動之後，便會
自動接合上整個智慧型家庭環境網路，並同時向
Media & Network server註冊。在資料傳輸的協定
上，在室內，我們使用IEEE 802.11無線區域網路
提供穩定的網路服務品質；在室外WLAN無法涵蓋的
區域，則是需要涵蓋範圍較大的802.16都會型區域
網路來加強WLAN涵蓋範圍不足的缺陷。 
 
    本研究的主要目的，是希望由網路的各種技術
為基礎，提供一個完整而具前瞻性的新數位家庭生
活環境，並透過中央的Media & Network server來
對整個家庭成員及設備作一整體性的管理，以期對
人類的生活作突破性的進步。 
 
    我們研究的主要關鍵技術將包括:（1）室內無
線定位暨追蹤預測技術，（2）WLAN 與 Mobile Ad 
hoc Networks 的具服務品質的通訊協定改良，
（3）即時性多媒體串流應用的遞送品質 
 
  
Figure 3.Comparison between (M1+M2) and RADAR 
 
 
 
2. "Bandwidth Routing Support for Wireless 
Multihop Networks" 
2.1 Abstract 
The idea of mobile computing service is to provide a 
ubiquitous information environment.  However, the 
present mobile ad hoc networks still can’t support real-
time transmission very effectively.  In other words, the 
capability of supporting QoS guarantee has become a 
very important issue.  IEEE 802.11 PCF adopts the 
polling scheme to provide time-bounded traffic 
services, which is not suitable in multi-hop networks.  
Moreover, due to mobility and traffic dynamics, the 
network resource management is more difficult.  Thus, 
QoS support in such an environment is a challenge.  
Specifically, path bandwidth calculation is the first key 
element.  All the bandwidth routing papers we referred 
to were using TDMA.  However, they are restricted in 
TDMA systems and somehow complicated in path 
bandwidth calculation.  We propose a simple path 
bandwidth calculation solution that can be used for any 
kinds of MAC protocols.  It is also easy to implement 
call admission control and to combine with bandwidth 
routing algorithms.  The simulation results illustrate 
that the statistical error rates of our path bandwidth 
calculation are within an acceptable range.  By path 
bandwidth calculation, bandwidth routing algorithm is 
also developed to achieve the objective of supporting 
QoS in wireless multihop networks effectively. 
 
2.2 Main Results 
We the maximal available remaining bandwidth 
between the estimation and real network traffic through 
the throughput information we obtained.  Fig. 4 depicts 
the comparison of CBR and VBR traffic. 
 
 
Fig. 4. Available Bandwidth Comparison 
 
Finally, we evaluate our bandwidth 
calculation in a more typical wireless multi-hop 
topology as shown in Fig. 5. 
 
Fig. 5. Integrated Scenario 
 
Fig. 6 is the simulation result that depicts the 
average achieved throughput ratio. The ATR decreases 
slightly while the background traffic loading increases. 
Overall, the average ATR are acceptable which are 
almost above 85%.  Although there exists statistical 
inaccuracy in our solution, our proposed estimate still 
get stable results even we ignore the IEEE 802.11 
MAC overhead. 
 
 
Fig. 6. Average Achieved Throughput Ratio 
 
Fig. 7 shows the normalized delay time of the 
simulation. The mean normalized delay time jumps 
with the increase of traffic load.  The VBR traffic delay 
time ascends more obviously than CBR traffic delay 
time when traffic load is high. This result might be 
caused by IEEE 802.11 overhead or our inaccuracy. 
0
1
2
3
4
5
6
7
8
9
10
0 20 40 60 80 100
mobile time (secs)
PD
R 
* 1
00
 / p
ay
me
nt
AOP-L AOP-P AODV
DSDV DSR
Figure. 10.  Efficiency 
The simulation results bring out some important 
characteristic differences between the routing protocols. 
The presence of high mobility implies frequent link 
failures and each routing protocol reacts differently 
during link failures. The different basic working 
mechanisms of these protocols lead to the differences 
in the performance. The results show that our routing 
protocols (AOP-L and AOP-P) outperform than other 
routing protocols. Although the packet delivery of 
AOP is almost the same with others, the end-to-end 
delay is lower and the efficiency is highest. 
 
4. "Token Bucket Based CAC and Packet Scheduling 
for IEEE 802.16 Broadband Wireless Access 
Networks" 
4.1 Abstract 
The IEEE 802.16 standard was designed for Wireless 
Metropolitan Area Network (WMAN). It supports QoS 
and has very high transmission rate. The key part of 
802.16 – packet scheduling, was undefined and is an 
open issue. We first proposed a token-bucket based 
uplink packet scheduling combined with call admission 
control (CAC) of 802.16. Then a model of 
characterizing traffic flows by token bucket is 
presented. The simulation results show that our CAC 
and uplink packet scheduling can promise the delay 
requirement of rtPS flows and our model can predict 
the delay and loss of a traffic flow precisely. 
 
4.2 Main Results 
We show the simulation results for CAC and uplink 
packet scheduling. 
 
Two methods of CAC and uplink packet scheduling 
are compared here. Method 2 was proposed in the 
literature and method 1 was proposed by us. The 
parameters of four classes are listed in Table 1. 
The begin time of each flow is Poisson distribution. 
All flows send data during each frame in full speed. 
Frame duration f is 1ms and simulation time is 150ms. 
Table 1. Simulation parameters 
Class Token rate(bps)
Bucket 
size(bits) 
Delay 
req.(ms) 
Packet 
size(bits)
UGS 192000 64 - 64 
rtPS 640000 15000 20 256 
nrtPS 2000000 15000 - 256 
BE 512000 8000 - 128 
0
10
20
30
40
50
100 200 400 800 1600
number of rtPS calls
av
g d
ela
y (
ms
)
method 1
method 2
Figure 11. Average delay v.s. number of rtPS calls 
 
From Figure 11 we can find that the average delay 
of rtPS used by our method is almost constant no 
matter how many rtPS calls exist.  
 
5. “The Streaming Service Platform based on EATCP 
for Heterogeneous Wireless networks” 
5.1 Abstract 
With the growth of broadband access networks, the 
demand of streaming service increased. In tradition, 
UDP is the only option for streaming service. UDP will 
suffer the various losses in heterogeneous wireless 
network. In our work, we develop an Error-Adaptive 
TCP for the purpose of streaming service in 
heterogeneous wireless network. EATCP-Assisted 
Module could collect the information of MAC layer 
such as wirelessRTT, and Link utilization. After the 
sender receive the information that from MAC layer 
and from itself, it can estimate the wiredBW and 
wirelessBW. Based on the estimation the sender 
adjusts the congestion window in a proper heuristic 
manner. EATCP could also adjust the congestion 
window based on the bandwidth demand of application. 
Under the help of simulator, we will prove the EATCP 
could have better performance under heterogeneous 
wireless networks. 
 
5.2 Main Results 
Fig.12 shows the total throughput. In this kind of 
Scenario, our total throughput is a little bit higher than 
Reducing Calibration Effort for WLAN Location and Tracking System using 
Segment Technique 
 
 
Tzu-Chieh Tsai, Cheng-Lin Li, Tsung-Ming Lin 
Department of Computer Science 
National Cheng Chi University 
Taipei, Taiwan 
{ttsai, g9303, s9109}@cs.nccu.edu.tw 
 
Abstract 
 
As mobile computing technology becomes more and 
more mature, people feel great interest on context-
aware applications and services. Referring to context, 
location-aware system is one of the most important 
components. This paper presents a precise indoor RF-
based (IEEE 802.11) locating system named Precise 
Indoor Locating System (PILS). In order to acquire 
high level of location estimation result, a large number 
of training samples should be collected in offline phase. 
As a result, the system becomes impractical and huge 
number of man-power is needed. In this paper, we aim 
to reduce the manual effort in constructing radio map 
and maintain high accuracy in our system. We propose 
models for data calibration, interpolating, location 
estimation, and tracking in PILS. Wireless Channel 
Propagation model is also in our concern. Large scale 
and small scale fading are involved in the wireless 
channel propagation.   
 
1. Introduction 
 
In wireless network research, context-aware 
applications and mobile computing are interested by 
investigators in recent years. To establish an intelligent 
environment with context-aware applications is 
significant for human life. A key feature of context-
aware applications and mobile computing is the 
location information. Via location information, a 
number of geographical and commercial applications 
are derived. For example, the museum guiding system 
does.   
It’s critical to develop a locating system indoors 
with high accuracy. Several studies have been 
conducted to offer some locating theorems. Many of 
above implement based on signal strength(SS) and 
access point(AP) information and supply a model for 
their location calculation. Although regarding signal 
strength is somehow sufficiently to obtain location of 
mobile terminal with low deviation, it’s more workable 
to consider with physical architecture property. Real 
world wireless channel can be decomposed into two 
parts: large-scale model and small-scale fading model. 
Large-scale model considers the path loss which 
represents the local mean of the channel gain and is 
therefore dependent on the distance between the 
transmitter and receiver. Small-scale fading is a 
characteristic of radio propagation resulting from the 
presence reflectors and scatters that cause multiple 
versions of the transmitted signal to arrive at the 
receiver, each distorted in amplitude, phase and angle 
of arrival. 
Most RF-based location systems are operated in two 
phases: offline calibration phase and online estimation 
phase. In offline calibration phase, location system 
calibrates a great deal of data on specific location and 
stores these data which is labeled with location 
information into database, which is called radio map. 
In online estimation phase, system calibrates some data 
in real time and substitutes them into radio map for 
estimating people’s location. The greater part of RF-
based location system described above demand large 
amount of calibration data. It’s manpower-wasted to 
calibrate a lot of data for each building. Reducing 
offline calibration effort and making estimation result 
acceptable are our goals in this paper. We expect to 
train data on one location in small room and to train 
less than three locations in bigger ones. 
We propose a methodology called Segment Process. 
Both offline and online phases refer to the concept of 
Segment Process. In offline phase we use Segment 
Process to gain more useful data in radio map, and in 
online we use it for making estimation result more 
accurate. Segment Process only consumes computer 
calculation frequency but needn’t more manual effort. 
The detail of Segment Process will introduce below. 
calibration into small pieces of time. Definitely 
Segment Process matches the claim of small-scale 
fading. Therefore, we adopt Rayleigh-like fading 
probability density function as our probability model.  
Let Probability Model be  
 
⎪⎭
⎪⎬⎫⎪⎩
⎪⎨⎧ ΜΜΜ= mij
2
2
ij
2
1
ij
2
)
)|,(
(,...,)
)|,(
(,)
)|,(
()|(
N
XSR
N
XSR
N
XSR
XSP jijijiji
                                                                                       
                                                                                    (1) 
where 
0S},
2
Sexp{S)X|,S( i
ij
2
2
i
ij
2
i
jij
2
i ≥Μ−×Μ=ΜR                                                                             
                                                                                    (2) 
 
3.3   Interpolation Model 
 
For reducing calibration number of locations, most 
of the data of grid points on the radio map are gained 
by interpolating. Large-scale fading represents the 
relationship between path loss and signal attenuation.  
Equation 3 and 4 are our interpolating models and we 
use them to calculate data for un-calibrated grid points 
on radio map. An illustration is shown in figure 2, 
location A and B have been calibrated and location C 
need to be calculated. When only location A is 
observable to location C, we use equation 3 to infer 
signal strength on location C, and when both location 
A and B are visible, we use equation 4. All the other 
un-calibrating grid points are computed with the same 
way. 
 
AiCi Sdd
dS ×+= )( log
 log
10
0                             
(3) 
 
BiAiCi Sdd
dS
dd
dS ×++×+= )( log
 log
)( log
 log
21
1
21
2     
(4)  
  
Once we calculate all the signal strengths of un-
calibrated grid points on radio map, we use Segment 
Process to divide data of each point into m parts. 
Meanwhile, system computes mean, second moment, 
variance value for each location and substitutes these 
values into probability model. All the details have been 
introduced above. After interpolating step, we establish 
a complete radio map for location system. 
 
Figure 2.Interpolation Model 
 
3.4   Location Deterministic Model 
3.4.1 Pre-operation  
 
In location deterministic model, location system 
estimates locations of mobile devices. We make use of 
Segment Process to improve the accuracy of estimation 
results. Assume system produces one estimation 
consequence every time period t. Now we separate t 
into m portions, and then calculate one brief result for 
each portion. Finally, we combine these m brief results 
for ultimate outcome. After pre-operation, we propose 
two location methodologies, which will introduce 
below. 
 
3.4.2 Weighted Triangulation Model 
 
After combining m brief results, system produces a 
sequence of P(Si | Xj), which form the radio map. The 
radio map is defined as following:  
 
 } )X,P(S ..., ),X,P(S  ),X,P(S {              
 )}P(X ,..., )P(X ),{P(X RM      
ja
i
1a2a
i
1a1a
i
1a
j21
=== ΠΠΠ=
=
                               
(5) 
Let k/m probability radio map(t=k*m, k=1,2,3…) be 
RMk/m. Then we multiply all RMk/m as following: 
∏
=
≤≤=
m
1
k/m tk1,
k
final RMRM                         
(6) 
Finally take the max P(Si|Xj) of RMfinal as the output 
result. 
Then we choose three locations XA, XB, XC, which 
own the max probability values, and use weighted 
triangulation to determine the outcoming location. 
Figure 3 illustrates weighted triangulation. Being 
normalized, PA equals to 0.5, PB equals to 0.3, PC 
4.2   Data Collection 
 
Since we deem that train data on too many locations 
on offline phase is impractical, we attempt to calibrate 
in few locations and interpolate all the other data on 
grid points by our model. In our experiment 
environment, we collected 1 point in small rooms, 2 
points in bigger ones, and 2 points in corridor. Totally, 
we selected 23 locations, 9.7% in whole environment 
locations. On the other hand, system calculates 90.3% 
locations. In our opinion, newly computer owns high 
performance and can sustain vast data calculation. 
Figure 
We collected 30 samples at each calibrating 
locations and expected an error of about 10~15 cm due 
to the inaccuracies when clicking the radio map. 
 
4.3   Experimental Result 
 
 
Figure 5.Performance at calibrated and interpolated 
locations with varying sampling data(M1) 
 
Define M1 as weighted triangulation model, M2 as 
time correlation-based model, and M3 as M1+M2. 
Figure 5 illustrates the effect of reducing the number 
of calibrated locations. And it also shows the factor of 
reducing the calibrated data on each point. The X axis 
represents number of training samples at one location, 
and the Y axis shows the accuracy whose probability 
of error distance is within 2 meters.  
For a fixed number of training samples, for example 
30 data, three measurements were held. The first 
experiment was taken at calibrated position, whose 
signal strength distributions were calculated directly 
from the sampled data. The second experiment was 
measured at interpolated positions, whose distributions 
were interpolated from the calibrated locations. The 
last one was taken at locations which are combined 
calibrated locations with interpolated ones. As we can 
see, experiments held at calibrated locations achieve 
best consequence. It proves that experiments with real 
data produce better result. Experiments taken at overall 
locations own second results and have worst outputs at 
interpolated locations.  
Figure 6 and 7 illustrate the same idea with figure 5, 
but they are different at that figure 5 operates with M1, 
and figure 6 and 7 operate with M2 and M3. We 
analysis these three figures together. In general, M3 
has the best performance, and M2 is worst. M1 is 
better than M2 and worse than M3. 
 
Figure 6.Performance at calibrated and interpolated 
locations with varying sampling data(M2) 
 
 
Figure 7.Performance at calibrated and interpolated 
locations with varying sampling data(M3) 
 
In figure 8 and figure 9, the calibrated point rate is 
9.7%, and data of other grid points are interpolated. 
We integrate all experiments data in these two figures. 
As we can see, Figure 8 shows the accuracy 
probability on each model and figure 9 illustrates the 
accuracy distribution. In figure 8, M3 owns the highest 
probability when error distance is within 2 meters, and 
it reaches about 73.40%. M1 performs better than M2 
within 2 meters of error distances and they all exceed 
60% on 2 meters. Figure 9 illustrates the distribution of 
all 1500 experiment samples. Within 2 meters of error 
distances, 1101 samples are eligible in M3, 935 
samples in M2, and 1013 in M1. The result shows high 
accuracy since the calibrated point rate is 9.7%. 
phase, the system constructs a radio map for the RF signal 
strength from a fixed number of APs. When estimating a 
user’s location, the system operates KNN or Triangulation 
with radio map to figure out the best fits of the collected 
signal strength information. [4] and [5] propose their own 
deterministic modes which differ from KNN and 
Triangulation. Cricket is another well-known in-door 
location system, but it is ultrasonic-based system. Cricket 
uses ultrasonic signal to infer distance and concept of AOA 
(Angle of Arrival) to judge a user’s position. 
Probabilistic models [6,7,10,12,13] form the second 
category. They are also called distribution-based techniques 
since they store the signal strength distributions from the 
APs as the information for the radio map. The Horus 
system[6,7] defines the possible causes of variations in the 
received signal strength vector and devising techniques to 
overcome them. Horus achieves a significant performance 
gain, both in terms of accuracy as well as computation cost. 
In [20], locations in the area are pre-clustered into groups so 
as to reduce the computational cost of searching the radio 
map. In [13], correlation among consecutive samples from 
the APs is introduced to enhance the system performance. 
The essence to all these techniques is the use of Bayesian 
inversion to return the location that maximizes the 
probability of the received signal strength vector. 
Other systems, [3,11], intend to reduce the calibration effort 
for economizing manpower. Our main notion is in the same 
way, and we purpose to achieve high level of accuracy with 
great deal of reducing manual effort. 
 
7. References 
 
[1] Paramvir Bahl and Venkata 
N.Padmanabhan, ”RADAR: An In-Building RF-based 
User Location and Tracking System”, in IEEE 
INFOCOM 2000, Mar 2000, pp. 775-784. 
[2] P. Bahl, A. Balachandran, and V. Padmanabhan , 
“Enhancements to the RADAR user location and 
tracking system” ,Technical report, Microsoft 
Research, February 2000. 
[3] J. Krumm and J. C. Platt, “Minimizing calibration 
effort for an indoor 802.11 device location 
measurement system”, Technical report, Microsoft 
Research, 2003. 
[4] Ming-Hui Jin, Eric Hsiao-Kuang Wu, Yu-Ting Wang, 
Chin-Hua Hsu, “802.11-based Positioning System for 
Context Aware Applications”, Globecom2003 
[5] Ming-Hui Jin, Eric Hsiao-Kuang Wu, Yu-Ting Wang, 
Chin-Hua Hsu, “An 802.11-based Positioning System 
for Indoor Applications”, ACTA Press Proceeding 
(422) Communication Systems and Applications - 
2004 
[6] Moustafa A. Youssef, Ashok Agrawala, A. Udaya 
Shankar, “WLAN Location Determination via 
Clustering and Probability Distributions”, in IEEE 
PerCom’03. 
[7] Moustafa Youssef and Ashok Agrawala, “The Horus 
WLAN Location Determination ference On Mobile 
Systems, Applications And Services Proceedings of 
the 3rd international conference on Mobile systems, 
applications, and services. 
[8] Asim Smailagic and David Kogan, “Locating Sensing 
and Privacy In a Context-Aware Computing 
Environment”, in IEEE Wireless Communications, no. 
5, Oct 2002, pp.10-17. 
[9] H. Hashemi, “The indoor radio propagation channel. 
In Proceedings of the IEEE”, volume 81, pages 943–
968, 1993. 
[10] T. Roos, P. Myllymaki, H. Tirri, P. Misikangas, and J. 
Sievanen, “A probabilistic approach to WLAN user 
location estimation”, International Journal of Wireless 
Information Networks, 9(3):155–164, July 2002. 
[11] Xiaoyong Chai and Qiang Yang, “Reducing the 
calibration Effort for Location Estimation Using 
Unlabeled Samples”, Proceedings of the 3rd IEEE Int’l 
Conf. on Pervasive Computing and Communications 
(PerCom 2005). 
[12] Ankur Agiwal, Parakram Khandpur, Huzur Saran, 
“LOCATOR - Location Estimation System For 
Wireless LANs”, WMASH’04, October 1, 2004, 
Philadelphia, Pennsylvania, USA. 
[13] Andreas Haeberlen, Eliot Flannery, Andrew M. Ladd, 
Algis Rudys, Dan S. Wallach, Lydia E. Kavraki, 
“Practical Robust Localization over Large-Scale 
802.11 Wireless Networks”, MobiCom’04, Sept. 26-
Oct. 1, 2004, Philadelphia, Pennsylvania, USA. 
comparing with its own, and forwards to neighbors 
with the calculation result. If the routing table has no 
more space to store the information or the result of 
bandwidth calculation is not better than the existing 
ones, then the received message will stop its traveling 
in this multi-hop packet radio network. This feature 
prevents the message from traveling in the multi-hop 
packet radio network endlessly and from wasting 
valuable bandwidth. 
Here the bandwidth information is embedded in the 
routing table. By exchanging the routing table, the end-
to-end bandwidth of the shortest hop-distance pair can 
be calculated [1]. The transmission time scale is 
organized in frames, each containing a fixed number of 
time slots. Time is divided into slots which are 
grouped into frames. 
Because only adjacent nodes can hear the 
reservation information, and the network is multi-hop, 
the free slots recorded at every node may be different. 
Here the link bandwidth is defined to be the set of the 
common free slots between two adjacent nodes. And 
the path bandwidth between source and destination 
nodes is the set of available slots on each links along 
the path. Fig. 1 depicts the bandwidth 
information/calculation overview. 
 
 
Fig. 1. Bandwidth Calculation Overview 
 
Fig. 2 illustrates an example for calculating the path 
bandwidth in more details. The number of data slots in 
the data frame is 10, and “–” means a reserved slot by 
the other connections. From this example, path_BW 
(0,1) = link_BW (0,1) = free_slot(0) ∩ free_slot(1) = 
{0,7,8}. path_BW(0,2) is calculated from path_BW(0,1) 
and link_BW(1,2), which is equal to {1,8}. Then 
path_BW(0,9) is recursively calculated from 
path_BW(0,8) and link_BW(8,9) which is equal to 
{2,5}.  As a result, maximum available bandwidth is 
two data slots per frame for each link along the entire 
path. After calculating the end-to-end bandwidth, the 
data slots need to be reserved from the destination 
(Node 9) hop-by-hop backward to the source (Node 0). 
And the reservation wouldn’t be released until the end 
of the session. In the end, Node 0 begins transmitting 
datagram on completing the reservation. 
 
 
Fig. 2. Path Bandwidth Calculation Example 
 
In general, to compute the available bandwidth for a 
path in a time-slotted network, one not only needs to 
know the available bandwidth on the links along the 
path, but also has to determine the scheduling of the 
free slots. To resolve slot scheduling at the same time 
as available bandwidth is searched on the entire path is 
equivalent to solving the SAT problem, which is 
known to be NP-complete [13]. 
In this paper, we utilize load statistics to estimate 
current network remaining bandwidth. Previous papers 
regarding bandwidth routing focused on TDMA to do 
bandwidth reservation. It is very complicated both in 
bandwidth calculation and in reservation. Our solution 
can estimate bandwidth easily and quickly not only in 
TDMA networks, but also in IEEE 802.11 networks. 
We propose a method of bandwidth calculation that is 
robust to node mobility and traffic dynamics with 
sacrifice of little statistical errors. 
 
II. THE PROPOSED CALL ADMISSION CONTROL SCHEME 
AND BANDWIDTH CALCULATION 
 
Because the wireless medium resource is scarce, so 
we want to calculate the present bandwidth and know 
about if there is enough bandwidth to allow a new flow 
to achieve the QoS guarantee. So bandwidth 
calculation is the most important part we want to stress 
in this paper. According to the information about the 
bandwidth, we can implement the call admission 
control scheme. Our objective is to investigate QoS in 
wireless multi-hop environment. The infrastructure is 
in Fig. 3 as follows.  We plan to add a CAC (Call 
Admission Control) control procedure into the 
framework above TCP/UDP layer. Before admitting a 
new flow entering the network, we have to check if the 
remaining bandwidth along the path is enough to 
handle the new request. So when a new application 
(AP) requests to enter the network (Procedure 1 in Fig. 
3), we have to do “bandwidth calculation” first. We 
 
Fig. 6. Induction of Two-Hop 
 
Assume A (B) is the mean common idle percentage 
between Node 1 & 2 (2 & 3). Assume C is the mean 
common idle percentage among all nodes (1, 2, 3).  
Then we have A=xy, B=yz, C=xyz.  Then we can use 
(A-C) + half of C percentage of bandwidth to transmit 
data between Node 1 & 2, and use (B-C) + half of C 
percentage to transmit data between Node 2 & 3. 
Therefore, the mean idle percentage of the 2-hop path 
bandwidth (Node1-Node2-Node3) 
is )]1(),1(min[
2
xyzzxyxyz −−+ . 
Variance A=xy(1-xy), B=zy(1-yz), C=xyz(1-xyz). 
The variance of idle percentage of the path Node1-
Node2-Node3 
is
)]1)(1(),1)(1(min[
2
)1( xyzyzxyzxyzxyzxyxyzxyz −−−−−−+−
 
Similar to single-hop, the two-hop available 
bandwidth analysis is as follows. If the transmitting 
pairs around the observers are not all the same to them, 
then the idle percentage of this two-hop link 
is )]1(),1(min[
2
xyzzxyxyz −−+  (lower bound). 
If Node 1 and Node 2 sense the same traffic flows 
around them, or Node 2 and Node 3 sense the same 
traffic flows, then the idle percentage of the link is 
min(x,y,z) (upper bound).  And we also have the in-
between case here. 
 
C. Multi Hop Path Bandwidth Calculation 
In the multi-hop case, the proposed solution is to 
extend the solution of the above two-hop bandwidth 
calculation. As in Fig. 7, i, j, k indicate the idle 
percentage of A to C, B to D, C to E (all two-hop 
distance) respectively. And the idle percentage of the 
whole path from A to E is min(i,j,k). 
 
Fig. 7. Induction of Multi-Hop 
 
D. Bandwidth Routing and Call Admission Control 
Policy 
There are many routing protocols for ad hoc mobile 
wireless networks.  Here we choose DSDV as our 
starting point since it is simple. We extend the DSDV 
routing protocol to further include the bandwidth 
information in the routing table. 
Our call admission control policy does not need to 
reserve any bandwidth at call set up time.  When a new 
flow requests to enter the network, it is admitted if the 
path bandwidth calculation has enough available 
bandwidth for the request.  We are assuming that the 
path bandwidth calculation is performed every time the 
routing information exchange.  The call admission 
control policy is performed only at the source node. 
 
III. SIMULATION RESULTS 
 
We use the SimReal Inc. NCTUns 1.0 network 
simulator [8] and simulate on IEEE 802.11b wireless 
unslotted system. We also take in account different 
interfering pairs to simulate several kinds of situation 
in single-hop, two-hop and multi-hop cases to evaluate 
our proposed bandwidth calculation scheme. We 
compare the error percentage between the estimated 
(our proposed formula) and real (according to log files) 
bandwidth percentage to see if the error percentage is 
acceptable. The below figures are the topologies we 
simulate, Node O1 (or O2, O3) are the observers which 
sense the channel activity (busy or idle).  Interfering 
pairs, Node IS transmits data flow to ID through 
UDP/CBR/VBR. 
 
A. Single Hop Path Bandwidth Evaluation 
Fig. 8 are several single-hop network topologies we 
simulate to evaluate our proposed bandwidth 
estimation. We change different external traffic load 
(IS to ID) during the simulation.  Node O1 and O2 are 
the observers, and don’t have data flow between them 
at this time being. 
Case 1-1 is the simplest case that O1 and O2 only 
observe one transmitting pair (IS to ID). O1 and O2 are 
both in the transmission ranges of IS and ID. We 
change different loading through IS to ID.  Both CBR 
and VBR traffic, we use the bandwidth information 
observed from O1 and O2 to calculate the bandwidth 
utilization percentage between them. We also calculate 
the real idle percentage from the log file, and compare 
with the estimated value. 
 
curve in Fig. 12 is a little more irregular. 
 
 
Fig. 13. Case 1-5 in Single Hop Topology 
 
Case 1-5 is the last case we simulate in single-hop 
topologies. In the case, O1 is affected by two external 
traffic flows IS1 to ID1 and IS2 to ID2, but O2 is only 
influenced by IS2 to ID2.  IS1 and ID1 are the hidden 
terminals to O2. So we derive from the previous 
inference that the idle percentage in this case is xy.  Fig. 
13 is the simulation result. 
 
B. Two Hop Path Bandwidth Evaluation 
 
 
2-1 
 
2-2 
 
2-3 
Fig. 14. Two-Hop Topologies 
 
Fig. 14 are the two-hop network topologies we 
simulate to evaluate our bandwidth calculation scheme. 
Here we still change different external traffic load (IS 
to ID) in each topology.  O1, O2 and O3 are the 
observers, and don’t’ have data flow between them at 
this time being. O1 to O3 are two hop distances, and we 
use these three different scenarios to compare the 
accuracy. 
Case 2-1 is the simplest case that O1, O2 and O3 all 
observe the same transmitting pair (IS to ID). O1, O2 
and O3 are all in the transmission ranges of  IS and ID, 
and the link O1 to O3 is two-hop distances. We change 
different loading through IS to ID. For both CBR and 
VBR traffic, we use the bandwidth information 
observed from O1, O2 and O3 to calculate the 
bandwidth utilization percentage between them. We 
also calculate the real idle percentage from the log file, 
and compare with the estimated value. 
Fig. 15 shows the comparison of the O1 to O3 path 
bandwidth between estimated idle percentage and the 
real idle percentage in the two-hop case 2-1. 
 
 
Fig. 15. Case 2-1 in Two Hop Topology 
 
Next, in Case 2-2, there are two interfering pairs that 
are totally independent to the two observers O1 and O3. 
That is, O1 is only affected by IS1 to ID1, and O3 is only 
influenced by IS2 to ID2.  IS1 and ID1 are the hidden 
terminals to O2. O3 here is out of the range of the two 
external traffic flows. The idle percentage between O1 
and O3 is the lower bound case, and Fig. 16 is the 
result. 
 
 
Fig. 16. Case 2-2 in Two Hop Topology 
 
Case 2-3 is more complicated than 2-2.  We add 
another interfering pair (IS3 to ID3).  That means, O1 
and O3 has one independent interfering pair, and also 
observe the same traffic flow IS3 to ID3.  The idle 
percentage of link O1 to O3 here is using the lower 
bound. 
Fig. 17 is the simulation result of case 2-3. We can 
 
Moreover, we also try to put real traffic in the 
observer pairs to verify if the bandwidth estimation is 
correct enough.  Here we add additionally different 
CBR and VBR traffic loading in the original 1-1 
scenario. We compare the maximal available 
remaining bandwidth between the estimation and real 
network traffic through the throughput information we 
obtained.  Fig. 21 indicates the available bandwidth 
comparison of both CBR and VBR traffic cases. 
Similarly, we also experiment different CBR and 
VBR traffic load (O1 to O3) in the original 2-1 scenario.  
Then we can compare the maximal available remaining 
bandwidth between the estimation and real network 
traffic through the throughput information we obtained.  
Fig. 22 depicts the comparison of CBR and VBR 
traffic. 
 
 
Fig. 22. Available Bandwidth Comparison 
 
Same thing here, we also add different CBR and 
VBR traffic load (O1 to O4) in the original 3-1 scenario. 
Then we can compare the maximal available remaining 
bandwidth between the estimation and real network 
traffic through the throughput information we obtained.  
Fig. 23 depicts the comparison of CBR and VBR 
traffic. 
 
 
Fig. 23. Available Bandwidth Comparison 
 
D. Integrated Scenario  
Finally, we evaluate our bandwidth calculation in a 
more typical wireless multi-hop topology as shown in 
Fig. 24. Here we fix three interfering pairs {F,G}, 
{C,D}, and {E,K} as background traffic and vary the 
total traffic loads. Then we choose several S/D 
(Source/Destination) pairs randomly which might be 
single-hop, two-hop or multi-hop in different time 
scales. We evaluate their efficiency for supporting QoS. 
We define ATR (Achieved Throughput Ratio) for S/D 
pairs as one of the efficiency metrics. 
)( andwidthEstimatedBdOfferedLoa
ThroughputATR ==
 
 (2) 
100% of ATR is the perfect situation, which means 
that we could efficiently use the available bandwidth 
as we estimated. Normalized one-hop average delay 
represents another efficiency metrics. Because S/D pair 
is randomly chosen, so we normalize the delay time to 
one-hop distance delay time and get the average. 
 
 
Fig. 24. Integrated Scenario 
 
Fig. 25 is the simulation result that depicts the 
average achieved throughput ratio. The ATR decreases 
slightly while the background traffic loading increases. 
Overall, the average ATR are acceptable which are 
almost above 85%.  Although there exists statistical 
inaccuracy in our solution, our proposed estimate still 
get stable results even we ignore the IEEE 802.11 
MAC overhead. 
 
 
Fig. 25. Average Achieved Throughput Ratio 
 
Fig. 26 shows the normalized delay time of the 
simulation. The mean normalized delay time jumps 
with the increase of traffic load.  The VBR traffic 
delay time ascends more obviously than CBR traffic 
Efficient Routing Path Selection Algorithm based on Pricing Mechanism in Ad 
Hoc Networks 
 
 
Tzu-Chieh Tsai, Chien-Chi Lin 
Computer Science Department, National Chengchi University 
ttsai@cs.nccu.edu.tw, g9316@cs.nccu.edu.tw
 
ABSTRACT 
In military and rescue applications of mobile ad hoc 
networks, all the nodes belong to the same authority； 
therefore, they are motivated to cooperate in order to 
support the basic functions of the network. However, 
the nodes are not willing to forward packets for the 
benefit of other nodes in civilian applications on mobile 
ad hoc networks. In this research, we adopt the “pay 
for service” model of cooperation, and propose a 
pricing mechanism combined with routing protocol. The 
scheme considers user’s benefits and interference effect 
in wireless network, and can distribute traffic load 
averagely to improve network performance. The 
simulation results show that our algorithm outperforms 
than other routing protocols. 
 
 
1: INTRODUCTIONS 
 
In MANET, sources communicate with far off 
destinations by using intermediate nodes as relays. 
User’s cooperation (each node to forward packets for 
other nodes) is usually assumed. However, it’s not a 
realistic assumption in a public MANET formed by a 
random group of strangers. Mobile users with a small 
computing device usually face limited resources, such 
as battery, CPU and bandwidth. The forwarder incurs 
the real cost of battery energy expenditure and the 
opportunity cost of possible delay for its own data. 
They are likely to behave selfishly and decide to reject 
all relay requests, and hence paralyze the whole 
network. 
Thus, the concept of introducing incentives for 
collaboration into the ad hoc networks is an important 
step. This leads us naturally to the use of pricing 
mechanisms which has long been an active research 
area in wire-line networks. 
The packet purse model [1] introduces the concept of 
a virtual currency called nuggets, which can be 
exchanged for data forwarding. The authors call the 
devices Terminodes because they act as network nodes 
and terminals at the same time. In this model, the 
originator of the packet must pay virtual currency to 
intermediate nodes for relaying data packets. The packet 
forwarding service charge is in the following way：
when sending the packet, the originator loads it with a 
number of nuggets sufficient to reach the destination. 
Each forwarding node acquires one or several nuggets 
from the packet and thus, increases the stock of its 
nuggets. It is assumed that each terminal has a tamper 
resistant security module, such as a special chip or a 
smart card, to manage cryptographic parameters and 
nuggets. This model provides a kind of business 
transaction and solves the problem of how to pay for 
packet forwarding service in MANET. 
In the packet purse model, it doesn’t specify how 
much to pay for packet forwarding service. For ease of 
presentation, it is assumed that each forwarding node be 
rewarded with exactly one nugget for the packet 
forwarding. However, a rough pricing method may 
result in many problems. If an intermediate node 
supports more than one routing path, its traffic load 
distribution becomes higher and the resource 
occupation of this node is heavy. It is easy to infer that 
traffic load of the node which is in the center of the 
MANET is always higher than those in the edge of the 
MANET. Those nodes which are in the edge of the 
MANET may be bankrupt easily because no traffic 
passes through them.  
Hence, we propose a new pricing mechanism to take 
more factors into account. Our algorithm proposes the 
function to transform resources into virtual currency. 
By using the mechanism, nodes are willing to relay 
packets for other nodes. In addition, we propose an ad 
hoc on-demand pricing routing protocol（AOP）based 
on pricing mechanism. It both improves the network 
performance and stimulates user cooperation by using 
AOP. 
The rest of the paper is organized as follows. 
Section 2 describes the pricing mechanism in detail. 
Section 3 considers user mobility and calculates the 
expected connection time of a routing path. In Section 4, 
we indicate how to choose efficient routing paths. 
Section 5 describes the AOP routing protocol. Finally, 
we make a simulation in Section 6 and conclude the 
paper in Section 7. 
 
2: PRICING MECHANISM 
 
In this section, we present how to make our pricing 
mechanism. It considers three issues ： bandwidth, 
congestion, and interference. In our pricing mechanism, 
each node should take account of congestion 
price . congestionP
We model the network using M/M/1 queuing 
theoretical formulation. In this system, node R can 
transfer µR bits / second at most. Node R has sold λR 
bits / second bandwidth to others. Hence the average 
response time TR for node R can be estimated as︰ 
RR
RT λµ −=
1
             (8) 
where µR is the wireless channel capacity；λR is the 
customer’s arrival rate. Obviously in order to have a 
stable system, the following condition has to hold︰ 
.1<
R
R
µ
λ
                (9) 
Hence, the marginal delay time equals 
( )2'
1
RR
RT λµ −=            (10) 
So the unit congestion cost is , where 
 is the delay penalty of every second. Consequently 
we can know the congestion price for node R︰ 
RRR GT ⋅⋅ λ'
RG
quantityGTP RRRRcongestion ⋅⋅⋅= λ'_  (11) 
 
2.4: PRICE FUNCTION 
 
So far, we transform the resources of each 
intermediate node into virtual currency according to the 
node’s resources. The total virtual currency that each 
intermediate can get is linear combination of bandwidth 
cost, inference cost, and congestion cost. That means 
RncongestiioRerferenceRbandwidthRlink PPPP ____ ++= int    (12) 
in which  is link price of node R. RlinkP _
This is the benefit to make intermediate nodes 
willing to relay data packets to the destination node. We 
call this benefit which a node gets “Link Price”. Link 
price of node R is denoted by Plink_R. We sum all the 
virtual currency which intermediate nodes can get. Then 
we can count the payment that source node should pay. 
The “Route Price” of a routing path is defined as 
follows︰ 
∑=
i
ilinkspath PP __            (13) 
where  isilinkP _  the price for each intermediate node i 
charges for relaying data packets；  is the 
source node s should pay to all the intermediate nodes 
for relaying its data packets. 
spathP _
 
3: USER MOBILITY 
 
In this section, we specifically investigate the impact 
of mobility on the average connection time of a routing 
path. It is assumed that the average connection time of a 
user is inverse proportion to his speed. In figure.2, user 
A’s average speed is . The probability of connection 
time between any users follows exponential distribution. 
We can know 
AV
AA
A V
11 ∝= κϕ             (14) 
where Aϕ  is the average connection time between A 
and any other user, Aκ  is the average disconnection 
number in unit time 
 
Figure. 2.  Expected Connection Time of Single Hop 
The probability density function of connection time 
of A is 
tV
AA
AeVtP ϖω −⋅=)(          (15) 
in which t is the connection time. So the expected 
connection time equals to 
AVω
1
 
The connection time of a routing path is greater than 
T on condition that whole connection time of 
intermediate links is greater than T. In figure.3, a 
routing path comprises n users and each user has 
average link time ti. The speed of each user is denoted 
by . That means iV
TVVV
npath
TVVV
path
TVVV
TVTVTV
nn
path
n
n
n
n
eVVVTtP
Hence
eTtP
Then
e
eee
TtPTtPTtP
TtP
)(
21
)(
)(
2211
21
21
21
21
)()(
1)(
)()()(
)()()(
)(
+⋅⋅⋅++−
+⋅⋅⋅++−
+⋅⋅⋅++−
−−−
⋅+⋅⋅⋅++==
−=<
=
⋅⋅⋅⋅=
>⋅⋅⋅>⋅>=
>
ω
ω
ω
ωωω
ω
 
The probability of connection time from source to 
destination still follows exponential distribution. We 
can know the expected connection time of a routing 
minimum hop. However, route price of path 4 is higher 
than that of path 6 although they have the same 
expected connection time. That means path 6 is more 
efficient than path 4. 
Finally we can list all efficient routing paths to let 
user choose the best one. For Example, risk lovers may 
choose routing path 1 because of its lowest route price. 
However path 1 may be broken easily. Risk averters 
possibly choose routing path 6. Although its route price 
is higher, the disconnection probability is lowest. 
Using our pricing mechanism, the network can 
balance loading averagely because people will choose 
one path from efficient routing paths. The heavy 
loading node like node F in Figure 5 has higher link 
price. Efficient routing paths may not pass through it. 
5: AD HOC ON DEMAND PRICING 
ROUTING PROTOCOL 
 
There are many routing protocols for mobile ad hoc 
networks. We choose to modify ad hoc on demand 
distance vector routing protocol. We combine pricing 
mechanism and AODV routing algorithm into a new 
one： ad hoc on demand pricing routing protocol
（AOP） . We extend the AODV to further include 
cumulative price and cumulative speed in the Broadcast 
ID Cache. They are separately the sum of node’s link 
price and speed. 
AOP builds routes using a route request / route reply 
query cycle. When a source node desires a route to a 
destination for which it does not already have a route, it 
broadcasts a route request (RREQ) packet across the 
network. Nodes receiving this packet update their 
information for the source node and set up backwards 
pointers to the source node in the route tables. In 
addition to the source node's IP address, current 
sequence number, and broadcast ID, the RREQ also 
contains the most recent sequence number for the 
destination of which the source node is aware. A node 
receiving the RREQ may send a route reply (RREP) if it 
is the destination. If this is the case, it unicasts a RREP 
back to the source. Otherwise, it rebroadcasts the RREQ. 
Nodes keep track of the RREQ's source IP address and 
broadcast ID. If they receive a RREQ which they have 
already processed, they check if this path is an efficient 
routing path. We take an example in Figure. 6. Node 3 
receives RREQ which has the same source node and 
sequence number. One＇s cumulative price is higher than 
the other but its expected connection time is less. So the 
second RREQ is not an efficient routing path and node 3 
just drops it. 
 
6: SIMULATION MODEL AND RESULTS 
ANALYSIS 
 
We show the simulation results in this section. We 
evaluate the AOP through simulations by using the 
Network Simulation Version 2 (NS-2)[9].  
 
6.1: SCENARIO DESCRIPTION 
 
The setdest tool in ns2 is used to generate the random 
topologies for the simulations. Mobility models were 
created for the simulations using 25 nodes, with pause 
times of 0, 20, 40, 60, 80, 100 seconds, maximum speed 
of 20m/s, topology boundary of 1000x1000 and 
simulation time of 100secs. For the simulations carried 
out, traffic models were generated for 25 nodes with cbr 
traffic sources. The packet size is 512 bytes, and the 
sending rate is 512 Kbps.  
Node 1
Node 2 Route Request Packet
Dest: Node 3
 Src : Node 1
TTL: 3
Cumulative Price: 20
Cumulative Speed: 5
Broadcast ID:  0
    ..
    ..
RREQ
RREQNode 3
Broadcast ID Cache
Src.Node    Seq #  Cum Price  Cum Speed
       1             0             15                 3
       1             0             20                 5
Node 4
Node 5
 
Figure. 6.  RREQ 
 
6.2: PERFORMANCE METRICS 
 
The performance of AOP is evaluated and compared 
against AODV, DSDV, and DSR for the network 
scenarios outlined above. To evaluate the performance, 
we use the following metrics： 
z Packet delivery fraction — The ratio of the data 
packets delivered to the destinations to those 
generated by the CBR sources. 
z Average end-to-end delay of data packets — This 
includes all possible delays caused by buffering 
during route discovery latency, queuing at the 
interface queue, retransmission delays at the 
MAC, and propagation and transfer times. 
z Efficiency — The ratio of the packet delivery 
fraction to the payment. This value is the metric 
of one unit price can transfer successfully how 
many packets. 
 
6.3: SIMULATION RESULTS 
 
In this section, we present the simulation results and 
analysis. AOP-L is the method which chooses the 
longest expected connection time from efficient routing 
paths. AOP-P is the method which chooses the lowest 
price from efficient routing paths. 
From figure 7 we can find that on-demand routing 
protocols delivery over 70% of the data packets 
[4] Crowcroft, J., Gibbens, R., Kelly, F., and Ostring, S., 
March 2003 " Modelling incentives for collaboration 
in Mobile Ad Hoc Networks", Proceedings of 
Modeling and Optimization in Mobile, Ad Hoc and 
Wireless Networks (WiOpt) 
[5] Zhong, S., Yang, R., Chen, J., March 2003, “Sprite : A 
Simple, Cheat- Proof, Credit-Based System for 
Mobile Ad-hoc Networks” Proceedings of INFOCOM 
2003 
[6] Kai Chen, Klara Nahrstedt, “iPass: an Incentive 
Compatible Auction Scheme to Enable Packet 
Forwarding Service in MANET”, in Proc. of 24th 
IEEE International Conference 
[7] Marti, S., Giuli, T.J., Lai, K., and Baker, M., 2000 
“Mitigating routing misbehaviour in mobile ad hoc 
networks” Proceedings of MOBICOM 2000 
[8] Y. Qiu and P. Marbach, “Bandwith Allocation in Ad-
Hoc Networks: A Price-Based Approach,” in Proc. of 
INFOCOM, 2003 
[9]   http://www.isi.edu/nsnam/ns/
SS BS
Traffic flows
Traffic Policing
Packet Queues
Schedulor
Call
Admission
Control
Uplink
Scheduling
Create
Connection
Accept
BW-Request
Grant BW
Send Data
 
Figure 1. Operation process of 802.16 
The 802.16 standard divides transmission time into 
super frames and each super frame can be divided into 
a downlink sub-frame and an uplink sub-frame. 
Downlink means the direction of transmission is from 
BS to SS, and the uplink means inversely. The 
downlink scheduling is simple because the only sender 
is BS. Hence we focused on uplink scheduling. 
After a BS accepts a new connection, it will poll 
this new connection and give it the opportunities of 
sending its BW requests. This connection should send 
its bandwidth request (BW request) to BS for receiving 
BW grants (e.g. time slots for transmitting data) from 
BS. In this paper, we use the architecture in [4]: a 
connection sends its queue length as BW request. 
These grants are the result of uplink packet scheduling 
at BS and will be included in uplink MAP (UL-MAP) 
field in the downlink sub-frame. The 802.16 frame 
structure is as Figure 2. 
Super
frame
Super
frame
Super
frame
˙˙˙
Downlink
sub-frame
Uplink
sub-frame
DL-
MAP
UL-
MAP
Data
BW request
Contention
SS 1
data
SS 2
data ˙˙˙
SS n
data  
Figure 2. 802.16 frame structure 
The BW request contention period is for the classes 
of lower priority, such as nrtPS and BE, to get 
opportunities of sending BW requests when system is 
too busy to poll all connections. 
 
3. Call admission control (CAC) 
 
In our scenario each connection is controlled by two 
token bucket parameters: token rate ri (bps) and bucket 
size bi (bits). When a traffic flow wants to establish a 
connection with BS, it sends these two parameters to 
BS and waits for response from BS. An extra 
parameter, delay requirement di, will be sent by rtPS 
flow. 
Before presenting our CAC model, we should 
analyze the bandwidth requirement of an rtPS flow. 
Assume f is the duration of a super frame and there is 
an rtPS flow with parameter ri, bi, and di. The di must 
be two times of f at least. Here we assume 4f ＞di≧3f. 
So we set its delay requirement to 3f.  
t t+f t+2f t+3f t+4f t+5f t+6f t+7f t+8f
bi
=3fdi =3fdi
r fi r fi r fi r fir fir fi
 
Figure 3. A burst of an rtPS connection from time t 
to t+6f 
If this connection has a burst from time t to t+6f, the 
maximum size should be sent during each frame is 
shown in Figure 3. The gray blocks means the 
maximum size should be sent during that frame. 
Because the delay requirement of this connection is 3f, 
data arrived during frame[t, t+f] must be sent out 
during frame[t+2f, t+3f] at least. We know that a 
connection with token bucket parameters ri and bi 
sends data of rit+bi bits at most during a time period t. 
Hence during a frame f this connection will send data 
of rif+bi bits at most. If the rate of generating data is 
over ri, bi is consumed. In the extreme case this 
connection may run out of bi during a certain frame. In 
Figure 3, bi is totally consumed during frame[t+2f, 
t+3f], this situation makes the maximum size should be 
sent out during frame[t+4f, t+5f] to be rif+bi bits. 
In Figure 3, the bi comes from the frame[t+2f, t+3f]. 
So only the frame[t+3f, t+4f] can share the bi bits of 
the frame[t+4f, t+5f]. Let mi=di mod f (mi is 3 in 
Figure 3), we can find there are m-1 frames can share 
the bi bits at most. Through analysis above we can 
easily find the maximum size during a frame is 
1-m
b+fr
i
i
i                                                             
(1) 
Let NrtPS be the number of rtPS connections, Cdemand 
be the maximum size (bits) required by all rtPS 
connections, we can know 
∑ ⎟⎠⎞⎜⎝⎛ +=
NrtPS
i i
i
idemand
m
bfrC                                     
(2) 
In order to avoid starvation of some classes, we set 
a threshold for each class. They are four parameters: 
tUGS, trtPS, tnrtPS, tBE, and tUGS+trtPS+tnrtPS+tBE≦Cuplink, 
where Cuplink is the total capacity of uplink. When the 
total capacity occupied by a class is over its threshold, 
analyze the queuing delay by making use of Markov 
Chain. State(t, p) means there are t tokens in the bucket 
and p packets in the queue. Assume the time interval 
between two states is 1/ri, that is the time of generating 
a token. Hence we can find the probability P of n 
packets that arrive during the time interval 1/ri is 
n!
eP(n)
-n αα ⋅=  , where 
i
i
r
λα =  
This Markov Chain is shown in Figure 5 and 6. 
b ,0i
P(0)+P(1)
b -1,0i b -2,0i
P(0)
P(2) P(2)
P(0)
P(3)
P(4)
P(5)
˙
˙
˙
˙˙˙
P(1) P(1)  
Figure 5. The beginning of the Markov 
Chain 
t-1,0 t,0 t+1,0
P(0)
P(2) P(2)
P(0)
˙˙˙
P(3)
P(4)
P(5)
˙
˙
˙
t-2,0
P(2)
P(0)
t+2,0
P(0)
P(2)
P(3)
P(4)
P(5)
˙˙˙
˙
˙
˙
P(1)P(1) P(1) P(1) P(1)  
Figure 6. The general case of the Markov Chain 
Assume state(t, p) is denoted by π(bi-t+p) and let 
∑∞
=
=
2i
P(i)M  
We can list equations as follows. 
(1)P(0)M(0) ππ ⋅=⋅                                              
(3) 
And for n≧1, we have ( )
∑
=
⋅+++⋅
=+⋅
1-n
0k
P(0)1)(nk)-1P(n(k)
MP(0)(n)
ππ
π
                
(4) 
Assume the Z-transform of Poisson and [π(0), π
(1), π (2)…] is Gp(z) and Gπ (z). Then apply Z-
transform to (4) and simplify it, we can get 
( ) ( )
( )
( ) (5)                                              (1)z(0)
z
P(0)
-(0)P(0)A(z)G
z
P(0)
-(z)G
z
P(1)z-P(0)-Gp(z)-(z)GP(0)M
ππ
ππ
ππ
+
⋅+=⋅
⋅⋅+
 
From (3) we know 
(0)
P(0)
M(1) ππ ⋅=                                                  
(6) 
M+P(0)+P(1) is equal to 1, so substitute π(1) in (5) 
for (6) and simplify it we get 
Gp(z)-z
1)-(z(0)P(0)(z)G ⋅⋅= ππ                                    
(7) 
We know 
1(z)Glim 1z =→ π                                                (8) 
Use (7) and (8) we can find 
α
λπ -
i
ii
er
-r(0) ⋅= , where i
i
r
λα =                        
(9)
). The average 
queuing delay d  can be expressed as 
(see
0bucket) in the token P(seed
⋅
 
To find [π(0), π(1), π(2)…], we should make 
use of (6) to findπ(1) first. After we knowπ(0) and 
π(1), we can utilize (4), π(0) and π(1)  to find π(2). 
Go on this process we can find anyπ(n
avg
M/D/1/
avg
dbucket) in the token no P
+⋅=
          
10
he mean delay of a M/D/1 queue 
and its value[8] is
( ) 
where dM/D/1 is t
 
)-(r2r
-2r
iii
ii
λ
λ , given ri ＞ λ i                             
(11
And 
(12
ge 
de
(1), …, π(bi+q-
1)]. The equations are listed below. 
) 
∑
=
=
1-b
0k
i
(k)-1bucket) in the token no P(see π  
) 
Substitute dM/D/1 and P(see no token in the bucket) 
in (10) for (11) and (12) we can calculate the avera
lay of this flow if we give it parameters ri and bi.  
Now we consider the case of finite queue with 
queue size q. This traffic flow has an extra parameter lq, 
which means its loss rate requirement. We still use 
Markov Chain to solve this case, but the number of 
states become limited, e.g. [π(0), π
( ) P(0)(1)P(0)-P(1)-1(0) ⋅=⋅ ππ                       
(13
For  bi+q-2≧n≧1,  
) 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
200
000
300
000
400
000
500
000
600
000
700
000
token rate (bps)
av
g l
os
s r
ate
Simulation
Math
 
Figure 9. Average loss rate v.s. token rate 
 
7. Conclusions and future work 
 
In this paper we proposed a QoS-supported uplink 
packet scheduling and CAC mechanisms. Bandwidth 
needed by real-time flows is correctly reserved and 
their delay requirements can be promised. We also 
proposed a model to convert Poisson traffic flow into 
token bucket-based connection. In the future, how to 
integrate CAC and uplink scheduling with token rate 
estimation model may be another issue we will concern. 
 
8. References 
 
[1] IEEE, “IEEE Standard for Local and metropolitan area 
networks Part 16: Air Interface for Fixed Broadband 
Wireless Access Systems”, IEEE standard, December 2001. 
[2] IEEE, “IEEE Standard for Local and metropolitan area 
networks Part 16: Air Interface for Fixed Broadband 
Wireless Access Systems”, IEEE standard, October 2004. 
[3] Carl Eklund, Roger B. Marks, Kenneth L. Stanwood and 
Stanley Wang, “IEEE standard 802.16: A technical overview 
of the wirelessMAN air interface for broadband wireless 
access”, IEEE Communications Magazine, vol. 40, no. 6, 
June 2002, pp. 98 – 107. 
[4] Kitti Wongthavarawat, and Aura Ganz, “Packet 
scheduling for  QoS support in IEEE 802.16 broadband 
wireless access systems”, International Journal of 
Communication Systems, vol. 16, issue 1, February 2003, pp. 
81-96. 
[5]  Dong-Hoon Cho, Jung-Hoon Song, Min-Su Kim, and 
Ki-Jun Han, “Performance Analysis of the IEEE 802.16 
Wireless Metropolitan Area Network”, IEEE Computer 
Society, DFMA’05, February 2005, pp. 130-137. 
[6] Puqi Perry Tang and Tsung-Yuan Charles Tai, “Network 
traffic characterization using token bucket model”, IEEE 
INFOCOM 1999 - The Conference on Computer 
Communications, no. 1, March 1999, pp. 51 – 62. 
[7] Tarkan Taralp, Michael Devetsikiotis, and Ioannis 
Lambadaris, “Traffic Characterization for QoS Provisioning 
in High-Speed Networks”, IEEE Computer Society, Thirty-
First Annual Hawaii International Conference on System 
Sciences-Volume 7, January 1998, pp. 485. 
[8] Kleinrock L., “Queueing Systems. Volume I: Theory”, 
John Wiley, New York, 1975. 
 
