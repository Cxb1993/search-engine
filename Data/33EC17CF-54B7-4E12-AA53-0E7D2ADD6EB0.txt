II
圖 目 錄
頁次
圖1 機器人正視及側視圖.............................................................. 0錯誤! 尚未定義書籤。
圖2 擺線路徑-1 .............................................................................. 0錯誤! 尚未定義書籤。
圖3 擺線路徑-2 ....................................................................................................................03
圖4 擺線路徑-3 ....................................................................................................................03
圖5 單一動作控制流程........................................................................................................03
圖6 人型機器人正視及側視圖............................................................................................04
圖7 方向感測器....................................................................................................................04
圖8 人型機器人行走步態示意圖........................................................................................05
圖9 人型機器人行走實際圖................................................................................................05
圖10 原始影像........................................................................................................................05
圖11 二值化影像....................................................................................................................05
圖12 關鍵點之相對位置........................................................................................................05
圖13 人型機器人模仿人類動作實際圖................................................................................05
圖14 自主機器人系統架構圖................................................................................................06
圖15 NIOS發展板 ................................................................................................................06
圖16 機器人自由度分配與座標軸定義................................................................................06
圖17 主導機器人....................................................................................................................07
圖18 從屬機器人....................................................................................................................07
圖19 從屬機器人紅外線感測器位置....................................................................................07
圖20 電源轉換電路板............................................................................................................07
圖21 電源Zigbee無線通訊模組傳輸模式.............................................................................08
圖22 主導機器人指揮握手示意圖........................................................................................08
圖23 從屬機器人色塊位置....................................................................................................09
圖24 從屬機器人旋轉修正關係圖........................................................................................09
圖25 接力搬運示意圖............................................................................................................10
圖26 合作搬運示意圖............................................................................................................10
2蹈的動作。它提到下半身的動作視為是一種任
務型動作，上半身的動作藉由反動力學求得上
半身各關節馬達的角度，在模仿的同時透過重
心補償方式保持其平穩。在文獻 [7] 中，作者
利用六個攝影機去偵測人身上38個標記進行辨
識並成功的讓機器人模仿人表演「太極」功夫。
在文獻 [8] 中提到機器人利用影像去擷取人身
上的自然特徵(膚色)，讓機器人模仿人類雙手的
動作。在文獻 [9] 中介紹可以和人跳華爾滋的
機器人。
更有一些研究是在討論機人類與雙足機器
人的互動，其機器人能夠對於人類施加的外力
有所反應，即時計算重心位置，再結合重力補
償與全身力矩的控制達到自我平衡 [10]，有的
則可以與人類做進一步的互動，包含握手或拿
取人類手中物體等 [11]，而結合手勢辨識對機
器人下達指令，更是與人類互動最直接的例子
[12]；此領域裡，偶有多機器人間互動的研究，
例如兩台機器人安置攝影機，在共同搬運過程
中利用影像相互確認彼此位置，最後將物體搬
運到定點 [13]，但全然依賴影像做控制而沒有
其他感測器，且無法使機器人 stand alone，確
實可惜。因此第三年計畫主要為設計人型機器
人獨立自主的系統，並完成獨立機器人間的互
動功能。
三. 研究方法
1.第一年：
在第一年計畫執行的期間，機器人整個系
統分為硬體架構設計以及控制策略設計，在硬
體架構設計上，採用了AI-601與AI-1001伺服馬
達作為主要的致動器，在髖部及踝部各擁有兩
個自由度，再加上膝蓋一個自由度，兩腳共使
用10顆馬達。在控制策略上，主要的目標為讓
機器人能達到流暢的前進、後退行走、左右轉
向、坐下、翹腿、站起、跪下等動作。如圖一
所示。
圖1 機器人正視及側視圖
1.1 雙足機器人控制策略
光是讓馬達動作是不足以實現行走的
目標，接著便是做路徑的規畫，在這方面有
不少相關的paper都提出不同的設計方法，以
一個常見的例子來說，就是採用擺線
（cycloid）的路徑[14]，如圖2中虛線所示。
但在實做上採用以下簡化方法。再看看圖3
的軌跡，現僅在轉折處取樣作為關鍵點，如
圖4中灰色點部分所示，另在起步處多取一
點，即圖中白色點部分，目的是為了補強離
地動作的順暢，因此以這五點作為關鍵資料
的設計，在未來的動作設計上，也只以最多
五點的狀態資料做軌跡的建立。
圖 2 擺線路徑
42.第二年：
在第二年計畫執行的期間，我們藉著第一
年對機器人雙足設計的經驗，研發出一台自行
設計的人型機器人。其動力上採用 AI 馬達，搭
配自行設計關節連接機構來加強機構的穩定
性。
2.1 人型機器人機構設計
機器人全身共使用 17 顆馬達，其自由度分
配是雙足十個自由度：包含了髖部二個自由
度，膝蓋一個自由度，腳踝二個自由度；雙手
六個自由度：包含了肩膀二個自由度，手肘一
個自由度；頭部一個自由度。將攝影機置於頭
部的馬達上並以此攝影機作為機器人的眼睛，
藉由馬達的轉動，使機器人具有上下搜尋的視
覺能力。圖 6 為人型機器人正視及側視圖。
圖6 人型機器人正視及側視圖
圖 7 方向感測器
爲了讓機器人可以知道跌倒了要自行爬
起，我們利用水銀開關自製方向感測器，藉以
得知機器人傾倒的面向，由於一個水銀開關具
有導通與否的狀態，而使用兩個水銀開關來
搭配則可以獲得四狀態的識別（即表示 2
bits），分別用來表示站立、面朝上、面朝下。
圖 7 為自行製作的方向感測器。
2.2 人型機器人步態開發
我們將以一個前進的步伐為例，並搭配
圖8與圖9的步態示意圖與步態實際圖，介紹
步態開發的方法與重心偏移的關係。
Step 1：初始狀態為雙腳站立，此時重心落
在二腳中間。
Step 2：重心偏移至左腳的腳底板內。
Step 3：右腳抬高並往前。
Step 4：右腳著地。
Step 5：重心偏移至兩腳中間。
Step 6：重心偏移至右腳的腳底板內。
Step 7：左腳抬高並往前。
Step 8：左腳著地。
步驟中的重點將詳細說明如下：
1. 上述八個步驟中，是以機器人的觀點，來
區分左(右)腳。
2. 圖8中黑色圓點代表身體重心，重心上的
箭頭代表即將偏移的方向；實線矩形代
表腳底板著地，虛線矩形代表腳底板離
地，矩形上的箭頭代表腳步移動方向。
3. 在Step 2中，利用腳踝和髖部左右擺動的
自由度，即可將身體重心偏移至左腳的
腳底板內。
4. 在Step 3中，因為此時身體重心已落在左
腳的腳底板內，故抬起右腳並往前，機
器人依然可穩定的站立。
5. 在Step 4中，將右腳著地，此時機器人為
雙腳支撐狀態。在Step 5中，再將身體重
心偏移到兩腳中間。
6. 用上述類似的概念，即可解釋Step 6到
Step 8的過程。最後，我們可以把上述八
個Step視為八個關鍵的狀態(state)，完成
此八個狀態，即是完成一個前進步伐。
63.第三年：
第三年計畫中將整個人型機器人的系統改
成 stand alone 的架構，以嵌入式系統 NIOS 作
為機器人控制的核心。使機器人能夠不依賴電
腦獨立的完成計畫前兩年所設計的動作。
3.1 獨立機器人之系統架構
整個機器人系統以 NIOS 嵌入式軟核心處理
器為主。NIOS 為整個機器人的中樞，負責分析
從感測器偵測的資料、控制馬達轉動的角度與
動作的決策。系統架構如圖 14 所示。其中以
NIOS 發展板為主軸，周邊連接了組成機器人的
AX-12 馬達、負責感測距離的紅外線感測器（IR
Sensor）、擔任機器人間溝通橋樑的無線傳輸模
組（Zigbee Module）以及儲存機器人動作的記
憶體（Flash Memory）。再配合演算法的撰寫，
此人型機器人便能自主的做出決策，藉由感測
器與無線資訊的傳輸依不同的環境條件完成指
定的動作。
圖 14 自主機器人系統架構圖
其中 NIOS 發展板控制晶片型號為
EP2C20F484C8，不但可自行撰寫 FPGA 程式運
行，也可以建立 NIOS CPU 來控制 FPGA 程式
所編寫之模組；其中可應用的 I/O 腳位相當多，
對於硬體的擴充非常方便。計畫利用發展板來
控制機器人的馬達轉動、無線傳輸以及接收
紅外線感測器訊號。此外發展板內建 8M
Bytes 快閃記憶體(Flash Memory)，可儲存機
器人的動作，並依照指令執行不同記憶體中
的動作。圖 15 為 NIOS 發展板之外觀圖。
圖 15 NIOS 發展板
圖 16 機器人自由度分配與座標軸定義
3.2 自主機器人之硬體機構
在第三年的計畫裡，我們設計了兩台獨
立自主的機器人。它們的差別為主導機器人
具備了 CCD 攝影機，因此主導機器人比從
屬機器人多了一個頭部的 pitch 軸自由度，
其餘的分配均相同；手部每隻三個自由度
(roll*2, pitch)，腳部每隻六個自由度，其中
83.4 無線傳輸系統
兩台獨立自主機器人與電腦三者之間資訊
的溝通由Zig-100無線通訊模組負責，此模組工
作於250kbs頻帶，且傳輸方式與AX-12馬達同樣
為非同步串列傳輸，並擁有三種傳輸模式可供
選擇。第一種為點對點模式(peer to peer)，如圖
21(a)所示；第二種為等待模式(waiting)，此時
各模組的目標ID(Dist. ID)可設成一樣，資料便
會依序傳到目標ID，如圖21(b)所示；第三種是
本計劃所採用的廣播模式(broad casting)，只要
其中一個模組發送訊號，所有模組都可以收
到，如圖21(c)所示，但並不是每一組訊號都是
該模組所需要的，所以必須預先定義封包內
容，讓各模組自行判定收到的訊號是否該予以
採用。
(a)
(b)
(c)
圖 21 Zigbee 無線通訊模組傳輸模式
(a) 點對點模式 (b)等待模式
(c)廣播模式
3.5 指揮握手演算法
利用指揮握手演算法，主導機器人可以
透過攝影機擷取到的影像做出決策判斷並
指揮從屬機器人定位至主導機器人正前
方，至於從屬機器人應該停止的位置點，則
交由其身上的紅外線感測器決定，圖22為主
導機器人指揮握手示意圖。
在此演算法中，從屬機器人胸前為藍色
色塊，雙手臂為紅色色塊，以不同顏色的色
塊做為主導機器人指揮從屬機器人定位的
判斷依據，如圖23所示。
(a) (b)
圖22 主導機器人指揮握手示意圖
(a)從屬機器人被動定位 (b)握手完成
10
動作是使用搬運物體上的藍色色塊重心
 C,ObjObjC, yx ,, 當作判斷從屬機器人左右修正的依
據，在本計劃中，所預設的環境條件是：搬運
的物體需大於從屬機器人身上之藍色色塊，使
主導機器人得以搬運物體作為指揮判斷依據。
當從屬機器人身上的紅外線感測器測得與
主導機器人的間距符合預設之足夠傳遞物體的
距離閥值( 135IRT )時，兩機器人便開始執行傳
遞物體之動作。雖然本小節的演算法是結合之
前所提出的兩項演算法，但其內部參數值及閥
值皆需微調，其執行結果才能更為準確，機器
人接力搬運過程如圖25所示。
(a) (b)
(c)
圖25 接力搬運示意圖 (a)從屬機器人搬運物體
(b)物體進行交接 (c)主導機器人搬運定位成功
3.7 合作搬運演算法
合作搬運演算法需由兩台機器人共同完
成，首先，由主導機器人自我定位至平台上的
物體面前，並運用「指揮握手演算法」，指引從
屬機器人正對物體另一端，待從屬機器人以預
設閥值 ( 255IRT )完成定位後，兩機器人同步
抬起平台上的物體，最後主導機器人運用「獨
力搬運演算法」搜尋目標球，並帶領從屬機器
人合力搬運物體至目標平台，但為了避免在執
行目標定位時，旋轉修正造成兩機器人互相拉
扯，所以在合作搬運時，將旋轉修正區域與
平移修正區域合併，並以平移修正動作取
代，讓動作修正區域降為三個，最後，當機
器 人 前 進 至 目 標 球 半 徑 值 大 於 閥 值
rT ( 21rT )後，即完成合作搬運的動作，如
圖 26 所示。
(a) (b)
(c) (d)
圖26 合作搬運示意圖 (a)初始狀態
(b)主導機定位至物體面前
(c)從屬機器人定位至物體面前
(d)共同搬運至目標平台
四、結果與討論
在第一年裡，我們自行製作了一台雙足
式機器人，並規劃各種動作路徑，完成機器
人的基本動作如：平衡、前進、後退左右轉
向、上下坡等行動控制。第二年裡我們完成
整體人型機器人的機構設計、製作，與馬達
自由度配置。憑藉第一年的經驗完成了人型
機器人的各種基本動作設計，並在機器人身
上加裝視覺回授，讓機器人具備模仿人類動
12
Conference on Robotics and Biomimetics,
Kunming, China, pp.619-624, 2006.
[13] Y. Inoue, T. Tohge, and H. Iba, “Cooperative 
transportation system for humanoid robots
using simulation-based learning,” Applied
Soft Computing Journal, vol.7, pp.115-125,
2007.
[14] Y. Kurematsu, S. Kitamura, and Y. Kondo,
“Trajectory Planning and Control of a Biped
Locomotive Robot-Simulation and
Experiment,” Robotics and Manufacturing,
Recent Trends in Research, Education and
Applications, M.Jamshidi(ed.), pp.65-72,
1988.
六、計畫成果自評
1. 完成了雙足機器人的機構與運動規畫，對於
雙足式機器人的動作控制有紮實的實作經驗
與原理上的了解。
2. 自製一台完整的人型機器人，自行設計機構
與挑選合適的馬達，加裝感測器於機器人身
上，使人型機器人更能適用於不同的環境。
其過程對於機器人的硬體機構與電路設計了
解甚深。
3. 將人型機器人運用於人類動作的模仿上，拓
展出更多人型機器人的應用，並發展出機器
人與人類互動的平台。
4. 完成控制演算法程式移轉至 NIOS，完成機
器人獨立自主的功能並測試互相配合的可能
性，完成軟、硬體的撰寫及製作。
5. 修改機器人機構，整合測試成功，具備行走
能力與環境反應能力，利用影像處理，使機
器人具有自我修正協調能力。
6. 參與之工作人員對於機器人整體的技術，會
有很好的實習訓練，對國內機器人技術也能
提供寶貴的經驗。
7. 製作的機器人參加第七屆、第八屆旺宏電子
金矽獎全國大賽，均獲得銅牌獎及最佳指
導教授獎。
行政院國家科學委員會 
補助學者參與國際學術學會會議報告 
                                            98 年 6 月 25 日 
報告人姓名  王文俊 服務機構  中央大學電機系 職稱   教授 
中文：第二十八屆北美模糊訊號處理學會年度研討會 會議正式名稱 
英文：The 28th North American Fuzzy Information Processing Society Annual 
Conference 
會 議 時 間       自 98 年 6 月 14 日至
98 年 6 月 17 日 
地點（國、州、城市） 美國俄亥俄州辛
辛那提 
 
一、參加會議經過 
本研討會是由北美模糊資訊處理學會 North American Fuzzy Information Processing 
Society 主辦，IEEE 協辦的一個中小型國際研討會，地點在美國俄亥俄州辛辛那堤大學內的一
個會議中心舉行，中心是在校內一個知名飯店內。因為辛辛那提不是一個大城市，要飛到那裡
真是很難機票很難訂，本人是先飛到底特律，再租車開到辛辛那提，車程約需要五小時，才抵
達該市。會議日期為 6/14~6/17 五天，參加者的人數約 250 人左右，而且大部份來自北美，少
部分來自亞洲。 
本會議總共有七個 Plenary Lectures，演講者都是國際知名教授，論文發表分為 20 個
sessions，每個 session 五篇文章，是個完全聚焦於 Fuzzy Systems 的研討會。我的主要專長就
是 Fuzzy Systems，所以參加此研討會很值得，會中發表的文章理論與應用兼具，幾天會議下
來，獲益匪淺。 
我的文章發表在第二天(6/15)早上第一場，Session 主持人為加拿大多倫多大學教授Nick J. 
Pizzi ，我發表論文的題目為 Fuzzy Based Seeded Region Growing for Image Segmentation，該
session 在場聽講人數約 20 人，大家都很認真聽，其他有三篇作 fuzzy clustering 的，有一篇來
自印度，其他一篇也是作 Pattern Classification，幾乎每篇文章發表後，討論都很熱烈。 
本次研討會是我參加過國際研討會中最有誠意的一次研討會，因為放在會場走廊的點心
隨時補充，每天中餐、晚餐大會都有提供，而且大部分就在飯店內用 Buffet，很貼心，而且
一起用餐很自然的就增加與會者的交流。不像以前有些國際研討會以賺錢為目的，只希望收取
參加者註冊費，會議中的服務及福利卻非常小氣。因為我是開車前往大會很貼心，給我們一天
一張停車卷，可以免費停車一次，省了不少錢。 
二、參加心得 
 參加此研討會，有以下幾點心得值得提出來： 
1. 大會很有誠意很貼心，有準備中晚餐，有提供停車位。提供的禮物也不錯，手提袋、
 1
