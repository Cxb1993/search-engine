i 
 
行政院國家科學委員會專題研究計畫成果報告 
前瞻異質多核心系統開發工具研發總計畫 
Advanced System Toolkits for Heterogenious Multi-core Processors 
計畫編號：NSC 98-2220-E-007-001- 
執行期限：98 年 8 月 1 日至 99 年 7 月 31 日 
計畫主持人：李政崑教授 國立清華大學資訊工程學系 
 
中文摘要 
本結案報告將對前瞻異質多核心系統開發工具研發三年計畫的執行情形提出說明與報
告。本計畫為前瞻性技術的整合型計畫，目標是提升國內處理器及相關軟體技術，總計畫
將提供子計畫共用平台，包括：目前先進的多核心系統實驗版，以及 ESL 虛擬環境整合。
利用 ESL 虛擬環境作為前瞻系統載具，然後將各子計畫的研究產出實現於虛擬平台上，並
驗證其可行性。整體計畫包含五個子計畫，並分別專注在：多核心編譯器環境、多核心網
路連結、無線應用、系統功率評估、及軟硬體共同設計。主要的平台是以 MPU、VLIW DSP、
Service Processor 處理器為核心元件整合而成的異質多核心系統架構。 
在這三年的計畫中，已針對 Streaming Remote Procedure Call(Streaming RPC)、An 
Adaptive Testing Tool for Embedded Multicore Software、ESL 多核心虛擬共通平台之偵錯開
發環境、Register File Spilling、Network-on-chip-centric System Exploration Platform、多核心
的多媒體應用 framework、Power modeling for PAC-DSP、Hardware/Software co-design for 
multimedia applications 等多個技術領域提出研究與討論。以上結果有多項成果已經被發表
在期刊及各大國際會議上。 
 
 
 
關鍵字： 
多核心系統、開發工具組、編譯器、編譯器最佳化、即時系統、內嵌式系統 
  
iii 
 
目錄 
 
中文摘要 ..................................................................................................... i 
英文摘要 .................................................................................................... ii 
目錄 ........................................................................................................... iii 
報告內容 ............................................................................................... - 1 - 
一、 前言 ................................................................................................... - 1 - 
二、 總計畫研究目的 ............................................................................... - 1 - 
三、 文獻探討 ........................................................................................... - 2 - 
四、 研究方法 ........................................................................................... - 4 - 
五、 結果與討論 ..................................................................................... - 11 - 
六、 參考文獻 ......................................................................................... - 12 - 
 
- 2 - 
 
三、 文獻探討 
(a) 異質多核心編譯器工具組 
目前在國外的異質多核心處理器應用正蓬勃發展，已成為未來的發展趨勢。其中以 IBM 
等三家公司發展的 Cell 環境最受矚目。而應用於 Cell 架構之上的編譯器，是由 IBM 所投
入研究的 XLC 編譯器，提供了 OpenMP 的支援，以及自動利用 SIMD(SingleInstruction 
Multiple Data)向量化程式的機制。由於 XLC 目前還在研究階段，目前還無法確定未來其是
否將商品化，但已有功能相當完整的版本開放提供 PS3 的設計人員下載使用。而在商品化
的編譯器方面，The Reservoir Lab 針對企業的嵌入式訊號處理系統及異質多核心系統提出
了 R-Stream 編譯器。除此之外，在開放式源碼(Open Source)領域中頗負盛名的 GCC 也在
最近加入了對 OpenMP 以及 SIMD 的支援。過去在分散式系統裡面，遠端程序呼叫是一成
熟且易於使用之程式設計技巧，例如 Java RMI 亦是遠端程序呼叫的一種形式。近年來隨著
多核心系統的廣泛，此類程式技巧亦被採用於撰寫多核心程式上如德州儀器之 DaVinci[1]
便使用了此技巧提供了多媒體程式撰寫之軟體架構。在此領域中，如何最佳化此溝通層
（Communication Layer）已有許多廣泛的討論。如 ARMI[2]以及 Manta[3]解決了許多 RMI
之缺點並對其做了功能上之擴充。近年來亦有人提支援資料串流之 RMI[4]。雖然遠端程序
呼叫之機制已是成熟之技巧，然而如何在此一程式撰寫模式支援遠端程式之串流資料交換
卻仍然是個挑戰的議題。 
(b) 多核心連結網路架構之研究與設計 
由於半導體的製程技術日新月異，目前已從逐漸邁向未來的製程生產（65nm 以下），
而晶片系統（system-on-chip, SoC）的設計理念在近幾年儼然已經成為一種新的趨勢。由於
製造出來的電晶體面積能夠越來越小，同時速度提升且消耗的功率減少，使得未來在單一
晶片內能夠容納數個、甚至數十個處理核心的設計，已經不再是遙不可及的夢想；甚至進
而將數個晶片連結在一起，便可大大擴充系統規模，有效提升運算效能。除此之外，隨著
多核心系統規模擴大，在系統中增加了處理核心、記憶體及輸入輸出裝置的數目，來提高
整體系統的效能和運算能力。不過受限於實體製程技術上的限制，連結網路的設計並非如
其他部分那樣地容易擴充，尤其它需要考慮到擴充之後連結網路的種種特性（如：面積、
功率消耗、頻寬、傳輸延遲、複雜度等），是否仍然符合應用的需求；假使連結網路無法提
供足夠的傳輸速度與頻寬供給元件間快速傳遞資料使用，那麼它將可能將會成為整個系統
的瓶頸所在。 
目前國內外無論在學術界或產業界都在積極研發多核心處理器架構：從最普遍的 Intel 
Core Duo 和 AMD Athlon X2 的雙核心處理器，到最新 Sony、IBM 與 Toshiba 合作的 Cell 
BE 及 Sun UltraSPARC T1 含有八個以上核心的處理器問世；工業技術研究院也在先前發
表國內首見異質雙核心架構平台 PAC，由一個微處理單元和數位訊號處理單元所構成，將
- 4 - 
 
去做功率消耗的取捨。目前已經有許多功率模型被發表在各種期刊論文上。而這些模型可
以大略被分為兩類，解析式(analytical)與實驗式(empirical)。 
而實驗式依據他們的特性，還可再被畫分為測量型與模擬型這兩類。一個關於這些模
型的不錯研究可以在[43]中找到。對於解析式模型來說，一個記憶體區塊的功率消耗主要是
依據其內部的電容轉換[45][46]而定。因為這個方法需要電路內部的詳細資料，所以有時候
被稱為白箱法。如果我們模擬的記憶體結構是屬於第三方的智慧財產，則要建立這種解析
式模型的話，智財權就會成為一個問題。[43]中所提出的測量型功率模型是建構在物理測量
上面。它首先藉由把要測量的靜態隨機存取記憶體結構實作在 FPGA 晶片上估測其功率，
然後再經過一些較準的步驟得到結果。相較其他方法來說，這種方法十分的快速，但是準
確率較低。對於模擬式的功率模型來說，一個記憶體結構所消耗的功率是藉由功率模擬
[40][41][47][52]所得到的。在[41]中，作者依據目標記憶體架構內每個小區塊的功能，使用
逐步線性迴歸為每個小區塊建立功率模型。而所需要模擬的記憶體結構包含所有各種記憶
體結構設定。因為有時需要模擬一些大型的記憶體結構，這就表示了模擬時間的可能會過
分的冗長。而在[52]中所提出的方法，進一步的加入了非線性迴歸的方式去改善其準確率。
由於這個方法把整個記憶體結構當成一個區塊，而且也不需要結構上的資訊，因此被視為
演化成了黑箱法。 
(e) Hardware/Software Codesign for Multimedia Applications on Multi-Core Platforms 
Scheduling and partitioning of tasks onto multiple processors with communication scheduling has 
been studied for embedded systems with multiple processors. Luo et al considers periodic and 
aperiodic tasks for power reduction but do not consider communication. Pop et al performs 
scheduling to meet timing constraints while taking into bus access, though it assumes TDMA 
over a shared bus. Hu et al targets a more general, heterogeneous network-on-chip (NoC) 
architecture consisting of n-by-n tiled, 2D mesh architecture, and it saves up to 44% power for 
multimedia applications. All of these problems are NP-hard. Liu et al formulated a problem that 
fits a pipelined architecture but with a shared bus rather than point-to-point connection. It has a 
polynomial-time optimal solution and actually fits the way we decompose the applications. 
 
四、 研究方法 
本計畫主要在於協助各子計畫的研究運作與成果分享，並且整合異質多核心處理器上
的系統開發工具組（內容涵蓋，編譯器工具、連結架構評估、應用軟體、系統功耗評估、
以及軟硬體共同開發工具等）。異質多核心處理器平台包含：MPU（微處理器），多顆 VLIW 
DSPs，以及 service processor 服務處理器。為了讓異質多核心處理器能夠搭配多種應用，
在整個 DSP 與 MPU 架構的設計上，DSP 的數目採用了可變動性架構，並且提供完整介
面能夠與 MPU 緊密搭配，減少彼此間溝通上的浪費。另外，針對資料的運算特性，及大
量計算的控制，額外提供了服務處理器的功能，能夠卸載 MPU 的運算量。 
- 6 - 
 
各個處理器上依序執行，所以可以達到高效能、低功耗的成果，但是要如何在這些異質核
心上管理任務的遷移以及資料的溝通就成為了一項重大的挑戰。在這項計畫中，我們提出
了”Multi-core Software APIs”(MSA)的programming model，用以解決遇到的問題；MSA是
一個由library所提供的框架，而這個框架則是建立在非同步遠端程序呼叫(remote procedure 
call, RPC)的機制上，所以MSA在嵌入式系統常見的分散式記憶體平台上提供了
function-offloading的programming model。 
 
圖表 2 Experiment Environment 
Remote procedure call(RPC)的programming model會把不同核心上的工作都當作是一個
遠端程序，並且允許每一個程序調用在其他核心上的程序，基於這個model，我們提出了
Multi-core Software API(MSA)，用以簡化在異質多核心平台上遇到的問題。此外，為了在
異質多核心的環境中分散並管理工作，MSA提供了程式開發者一系列的RPC APIs(圖表 3)，
而為了在不同的核心間管理資料的搬移，MSA也提供了message passing和data streaming兩種
module，讓使用者管理data和streaming data；除了上述關於程式功能的開發之外，我們也提
供了high-level library的設計，讓軟體開發者能夠更有效率的在不同的平台上開發程式。 
RPC Module 
msa_load_procset(char *I, CoreID c) Load executable image ―i‖ to ‖c‖ core 
msa_RPC_start(char *p, CoreID c) Start procedure ―p‖ on  ‖c‖ core 
Message Module 
msa_msg_send(MsgID m, void *p, MsgAttr *a) Send data from pointer ‖p‖ to message box ―m‖ 
with given attribute ―a‖ 
Msa_msg_recv(MsgID m, void *p) Receive data from message box ―m‖ to pointer 
―p‖ 
Stream Module 
msa_stream_send(StrID s, void *p, StrAttr *a) send data from pointer ‖p‖ to streaming 
channel ‖s‖ with given attribute ‖a‖ 
Msa_stream_recv(StrID s, void *p) Receive data from streaming channel ‖s‖ to 
pointer ‖p‖ 
圖表 3 Highlight of Multi-core Software API 
我們以 BP（Belief Propagation）來作為我們測詴的應用程式。我們將測詴的 BP 中所
使用的時間分成三大類：分別是 MPU Computation、Major Computation、以及 MSA Overhead。
Major Computation 為傳資料到 DSP 所花的時間，MSA Overhead 則是 MSA 函數跑的時間，
圖表 4 即為分別測詴 MPU 加不同數目的 DSP 的總共耗時。 
- 8 - 
 
使用者可以用正規表示法來描述待測系統可發生的行為或是針對待測系統的部分
服務來設計出相對應的正規表示法，pattern generator將根據使用者輸入的正規表示
法以及待測系統的行為(服務)發生機率的分佈資訊來建造出PFA。其中，待測系統
的行為(服務)發生機率可以取得自profiling資訊或是使用者自定的機率。pattern 
generator將利用PFA來自動產生出大量的測詴樣本，並將這些測詴樣本送給pattern 
merger做後續處理。 
B. Pattern merger 
pTest考慮到多核心程式的並行執行的現象，因此pattern merger的設計目的是交錯
pattern generator所產生的測詴樣本，交錯的測詴樣本用來探查多核心程式可能執行
的每一條路徑，多核心程式的各種執行路徑都需要探查，因為並行程式中不同的執
行順序可能會導致程式發生錯誤，如deadlock/livelock。 
C. Bug detector 
Bug detector 是一個全天候監視器，用來監視每一個測詴樣本的執行狀況。若在測
詴期間，程式執行發生不預期的錯誤，bug detector 將提供程式測詴過程的執行記
錄給使用者，幫助使用者重建測詴環境，以便於找出多核心程式中的錯誤。 
Probabilistic finite state automata 是設計 pTest 的核心基礎，PFA 的應用型式相當多，隱
藏式馬可夫模型（hidden Markov model，HMM）便是一個典型的 PFA，而 PFA 的定義如下: 
 A probabilistic finite-state automaton is a six tuple (Q, Σ, δ, q0, F, P), where:  
1) Q is a finite set of states; 
2) Σ is a finite alphabet; 
3) δ ⊆ Q × Σ × Q  is the state transition relation;  
4) q0 ∈ Q is the initial state; 
5) F ⊆ Q is the set of final states; 
6) P: δ → R+ is the transition probability function such that: 
 
 
pTest的研究結果已發表於2009 ACM/IEEE Design, Automation, and Test in Europe 
Conference & Exhibition（DATE'09）[6]。目前的實作設計可讓使用者利用pTest在嵌入式雙
核心系統上進行Dual-core RPC的程式測詴。 
3. ESL多核心虛擬共通平台之偵錯開發環境 
隨著產品不斷推陳出新，縮短time-to-market來搶佔市場是相當重要的關鍵，尤其是對
於嵌入式消費電子產品而言。為了達到這個目的，以及獲知成本與效能的最佳結果，我們
設計了一個異質多核心ESL虛擬平台，提供快速的異質多核心模擬環境，觀察系統內部行
為與收集相關數據，來評估是否達到效能及功能的要求。我們所建構的模擬平台是架構在



Qqa
QqwhereqaqP
',
,1)',,(
- 10 - 
 
User interface
Build model
Build settings file
Makefiles
Plug-in manifest
Makefile generator
CDT parser
Tool Integrater
CDT End-user
 
圖表 1 : Managed build system 概觀圖 
 
除錯器（debugger）在整合發展環境裡扮演相當重要的角色，它提供一個控制系統的
方式，讓使用者能夠依據需求來操控系統，進而從系統獲得所需要的資訊。舉例來說，使
用者能夠指定讓系統執行一個指令並且停止下來，接著使用者便能觀察目前系統的暫存器
（register）內容，甚至可以更動暫存器的內容。藉由除錯器所提供控制系統的方法，使用
能從得到的資訊判斷程式是否按照使用者的需求來執行，使執行結果錯誤的程式能夠有效
的縮小可能的錯誤範圍，提供使用者具體的方向來解決程式或系統的問題。 
以目前最廣為流傳的除錯器GNU debugger（GDB）為例，為了使除錯器的發展能保有
最大的可移植性，GDB將debugger劃分為兩部分：符號端（symbol side）及目標端（target side）。
在GDB中，目標向量（target Vector）負責的處理的部分界於上述兩者之間。其發展概念類
似於物件導向程式中的物件，利用相同對物件的操控方法，重覆利用相同的上層程式碼，
簡化開發時抽換底層機制的複雜度。一個目標向量包含有，與目標平台相同暫存器數量大
小的空間，負責傳輸暫存器的內容及儲存其內容；反組譯（disassemble）硬體機械碼，提
供解譯目標平台上應用程式內容的方法；除此之外，並負責控管中斷點（breakpoint）及監
視點（watchpoint）的數量與使用情形。利用這樣的架構劃分，使GDB能夠同時兼備有對多
重語言的支援與多重平台的支援，讓GDB在不同平台的移植上更便利。 
針對嵌入式系統（embedded system）上的除錯，為了讓GDB能夠被使用在嵌入式系統
的除錯，GDB提出了遠端串列傳輸協定（remote serial protocal，RSP），利用精簡化的單一
指令封包，控制接在本端機器上的遠端硬體。在遠端串列傳輸協定裡，所有的傳輸內容都
利用ASCII碼來做為傳輸格式。在協定的設計上，考慮了利用串列傳輸線傳輸封包時，資訊
誤傳的可能性。為了實現多處理器平台上的偵錯，將利用單獨的偵錯器來對應不同的處理
器，同時在每個不同的區塊之間，以不同的溝通介面連結，使系統達到整合的目的。 
實作內容，在整合 MPU Tool-Chain及 DSP Tool-Chain的部份，我們利用CDT plugin
上既有的延伸點（extension point）：org.eclipse.cdt.managedbuilder.core. buildDefinitions來
做延伸，將我們既有的tool-chain：MPU跟DSP整合在我們的IDE上，這部份主要透過修改 
XML檔來達成如圖表2所示。藉由一套定義好的tool chain格式，我們可以將各種tool chain
- 12 - 
 
份，對一個debug target我們必頇實作debug一整個的行為，如 thread、frame、variable、
breakpoint。 
 實作 IThread 的 interface：對應一個 debugging program 只會有一個 gdb thread，在
thread 這部份，我們必需實作整個 gdb thread 的操作，如：suspend、resume、
isSuspended、getStackFrames 等。 
 DSPStackFrame 及 MPUStackFrame 的部份，我們必需去 parse 跟 cache stack frame
所回應的 message，根據這些 message，我們可以知道目前的 line number, stack 的
位置，在 stackframe 這個部份，我們必頇實做 step into 和 step over 的功能。 
 IVariable：我們在這個部份包裝了 variable 的名稱，並從 debug target 那邊取得所
需的 value。 
 IValue：value 的值包含各種型態，如：string、int、double、char 等。在 value 的
部份，我們只需要將 value object 的值正確的呈現出來。 
 Breakpoint： breakpoint 的部份算是相當複雜的一塊 class，這邊必頇實作
linebreakpoint、addressbreakpoint，所幸 ECLIPSE 上面已經有一套優良的 abstract 
LineBreakpoint implementation. 我們這裡的 MPU 及 DSP 的 breakpoint 會是
LineBreakpoint 的一個 subclass. 
在整個多核心 debugger的設計上，我們有著各自獨立的 DSP Debugger Element 及 
MPU Debugger Element，這兩個獨立的debugger element將有著自己的variable view、memory 
view、disassemble view等，觀察到的debugging資訊並不互相影響，以及有著各自的command 
queue，發出的command如suspend、resume、step也不會互相產生影響，這讓我們可以同時
在IDE上操作兩個不同的debugger，順利的達成多核心debugging的功能。 
4. Register File Spilling 
暫存器分配過程的spill code，將會產生load/store方面的額外負擔。之前已有許多篇論
文探討減少spill code，但皆以統一暫存器架構（unified register file architecture）為其基本假
設。如今，由於分散式暫存器架構（distributed register file architecture）和多庫暫存器架構
（multi-bank register file architecture）的出現，對於減少spill code的技術製造了新的挑戰。
在這個研究裡，我們提出了新的最佳化技術，善用分散式特性以達到減少spill code的目的。
在之前的研究裡 [10] [11] [12] [13] [14]，記憶體（memory）為唯一的spilling destination；
而我們的方法，則將暫存器檔案（register file）亦視為一種spilling destination，利用其溝通
成本（communication cost）較記憶體低廉的特性，以達到減少spill code額外負擔與提高整
體效能的目的。Register file spilling將會針對待spilling的live range，分析哪個暫存器檔案或
者記憶體最為合適，合適與否是以溝通成本及暫存器壓力（register pressure）為評估基礎。
而在評估暫存器壓力（register pressure）的實作方式上，我們先在不同register file建立一個
global interference graph，不同於local interference graph，其以多個register file間的溝通做為
考量。而此global interference degree（GID）可以作為我們評估暫存器壓力的一個基礎，在
這個基礎之上，我們用GID/RA這個方法來提高我們預測暫存器壓力的準度，並且能夠作更
大膽的spill code。詳細的演算法如圖表所示。而評估完所有的暫存器的壓力後我們就能以
- 2 - 
 
 
圖表 12. Open64 compiler 加入 RFA 後的架構流程圖 
 
圖表 13. Register file spilling 在 DSPStone 的效能表現 
 
子計畫二：多核心連結網路架構之研究與設計 
在第一年的時間之中，本研究先致力於建立模擬器設計的相關知識，藉由建立簡單但
是完整的模擬器，我們可以得到建構模擬器時可能會遭遇到的困難，並且將這些經驗作為
之後研究的基石。為了方便驗證與考量模擬速度，本研究所設計的模擬器都是以 SystemC
語言所建立。研究首先探討單晶片網路最基本的元件：緩衝器(Buffer)。由於不論任何拓
樸的單晶片網路都會使用之，我們可以預期若緩衝器的效能可以被改善，則整體網路的效
能也將獲得改善。在確定緩衝器的設計之後，我們開始擴展、設計不同拓樸的單晶片網路，
由於多數的模擬器都是採用網狀拓樸(Mesh Topology)，缺乏設計空間的多樣性，在初期有
限的時間之中，我們先以環狀(Ring)、網狀(Mesh)以及圓環體狀(Torus)三種拓樸的設計為
主。在確認三種拓樸網路的設計是正確且可靠之後，我們能夠針對不同的參數作模擬，可
調整的參數包含了緩衝器的深度，虛擬通道的數目，以及採用均勻交通(Uniform Traffic)
或不均勻交通(Non-uniform Traffic)等。這些項目的模擬結果與設計模擬器的過程能有助
- 4 - 
 
的利用率最大，提供開發者一個充分利用異質多核心平台運算資源並具有方便移植性和程
式利用性的多媒體函式庫。 
● 異質多核心多媒體函式庫優化 
本計畫的構想是希望利用PAC DSP作為影片編解碼的處理，必頇從Android的
OpenCORE中找出Component從何處將需要編解碼的資料傳到底層去做編解碼處理，以及
如何將編解碼處理完成的資料回傳。  
在OpenCORE中，如圖14左邊所示，上層的Player AP會透過Engine去驅動下層各種Node
的連結，而OpenMAX component被實作在PVMF Node之下，透過OpenMAX component來
連結到真正的decoder，因此如果要將PAC版本的decoder整合進OpenCORE中就必頇修改
OpenMAX component及真正的decoder之間的Interface(紅色虛線圈起處)。 
 
<圖14 OpenCORE Player / Author Dataflow> 
 
Encoder的Dataflow也類似Decoder Dataflow，請看<圖14>的右邊。上層的Author AP會
透過Engine去驅動下層各種Node的連結，再透過OpenMAX component來連結encoder，因此
我們將會用類似的方法把PAC版本的encoder整合進OpenCORE。 
<圖15>為原始的OMX Component與H.264 AVC Decoder的解碼流程圖，因為Encoder也
是繼承同樣的Base Component，所以不再補充OMX Component與H.264 AVC Encoder原始編
碼流程圖和修改後編碼流程圖。  
當一個Android啟動時，scheduler會從priority Queue中找出一個active object，執行其名
為run的API。 
- 6 - 
 
 
<圖16 修改後的Component解碼流程> 
 
判斷Input Queue是否有可使用的buffer，若沒有則跳至判斷Output Queue是否有可
使用的buffer。 
1. 當Input Queue中有可使用的Inputbuffer，Dequeue Inputbuffer來使用。  
2. 將此需要解碼的Inputbuffer從ARM的memory ―SDRAM‖傳到DSP的memory ―DDR2‖，
讓DSP解碼。  
3. 歸還已經用完的Inputbuffer。判斷Output Queue是否有可使用的buffer，若沒有則跳
至判斷Input Queue是否有可使用的buffer。  
4. 當Output Queue中有可使用的Outputbuffer，Dequeue Outputbuffer來使用。  
5. 將已經解碼完成的Outputbuffer從DSP的memory ―DDR2‖ 傳到ARM的memory 
―SDRAM‖，讓ARM作螢幕輸出。  
6. 歸還已經用完的Outputbuffer。 若Input Queue沒有可使用的buffer，Output Queue也
沒有可使用的buffer，則Return。 
我們主要的目標，期望在 H.264 encode/decode 的過程之中，能夠充分地利用所有核心
的運算資源，讓其速度能夠明顯提升並維持影片的品質。 
 
子計畫四：適用於多核心數位訊號處理系統晶片之功率消耗評估軟體工具研發 
本子計畫提出了以下幾點： 
（1）我們的方法是一個完全【黑盒式】 (Black-Box) 的，不需要標準元件庫或 SRAM
的編譯器的內部電路結構資訊就可進行。 
（2）我們的方法減少了所需溫度點採樣的數量，而是透過少數（快速）SPICE 模擬的
結果，進行【分段指數模型法】找到一個符合所有溫度下的靜態功耗的公式。優點是
- 8 - 
 
A.基本思維 
在這項工作，我們的目標是在不同的配置參數（即 word depths，word-widths和
IOs）和不同溫度下，針對記憶體 macro建立漏電流模型。以 Artisan memory compiler
為例，其內共有 80835記憶體配置。不像標準元件庫，透過 SPICE模擬在每個配置參數
上建立功率模型是不可能的。我們需要一個方法，這個方法可以使用小的配置參數來推
估更大的配置參數的漏電流。我們發現，不同多工器寬度（即數個字元線對共享一個 IO
線）的 SRAM macro，往往有不同功率的消耗行為。因此，一個多工器導向模型更為合適。
這就如同我們發現很難用單一的公式去建立 SRAM macro 的漏電流模型，但是我們發現能
夠利用多工器特定寬度來細分成幾個公式。如此一來，只有幾個小的記憶體配置，需要
作為 training set，就可以準確地推斷所有其他 macro的漏電流。與前幾節技術（即考
慮到溫度的影響之溫度採樣與分段指數回歸）結合，就可以在任何溫度下的目標範圍內
提供準確的任何的 SRAM macro 漏電流。 
B. SRAM 編譯器的特性公式 
在本小節，我們詳細地討論了由 SRAM編譯器產生的 SRAM macro的多工器導向漏電
流模型。 
1）多工器導向功率模型 
如前所述，對於記憶體編譯器的所有配置利用單一功率公式模擬，未能有高度精確
的結果。因此，我們根據多工器寬度將所有的 SRAM 配置分割成幾部分的主要類別，每個
類別將有自己的功率公式。如此一來，功率公式將與模擬結果相當匹配。功率模型定義
如下： 
對於一特定多工器寬度 Mw： 
Power = C0 + C1W + C2B + C3W〃B （2） 
其中，C0，C1和 C2，C3是加權因子，W是 word 數，B是 bit數，WxB是記憶體矩陣
的大小。 
我們分析了使用多工器導向所推估的漏電流和實際透過 SPICE模擬在不同溫度和
training下漏電流之關係。在 25 ° C和 100 ° C 下功率數據和理想值相當符合。 
2）SRAM macro的分段指數模型 
到目前為止，我們在某些特定的溫度下，使用多工器導向功率模型推導出不同的 SRAM
的漏電流。但是，我們沒有能力預測某溫度下尚未產生自己的多工器導向模型的漏電流。
從某種意義上說，標準元件庫的漏電流模型是一維預測問題（只考慮溫度的影響），而
SRAM編譯器的模型是一個二維的預測問題，（考慮到 SRAM配置和溫度的影響）。因此，
我們需在 SRAM macro上運用到以前使用在標準元件庫的概念 分段指數模型。唯一不同
的是，我們如何產生在很寬的溫度範圍內的漏電流採樣值。 在這個二維預測方法中，我
們首先針對選定的溫度中，執行不同配置的的多工器導向的建立模型。然後，我們在那
些非採樣溫度上利用分段指數回歸填入每個 SRAM 配置的功率。 
C. 推導記憶體 macro 的漏電流 
SRAM編譯器的整個漏電流建模流程是更複雜一點。它分兩個階段 - 【離線階段】
和【在線階段】。如前所述，使用了兩種類型的公式，即：（1） 多工器導向模型（考慮
到配置的影響）和（2） 分段指數模型 （考慮溫度的影響）。建立多工器導向功率模型
是離線階段，而建立分段指數模型是一個在線階段，即根據指令動態地執行。 
在離線階段，我們首先執行 SPICE模擬所有樣本溫度下在 training set 中的 SRAM 
- 10 - 
 
independent frames as well. Vertical parallelism is exposed by annotation of application-specific 
knowledge. The implementation is relatively simple: in addition to the threads partitioned and 
mapped by horizontal decomposition, each core is also given the threads for several frames of 
independent data to process. When one thread is blocked by synchronization, the core context 
switches to another thread of an independent frame. This approach maximizes the locality of the code 
memory while keeping the cores nearly fully utilized. 
In the simulator implementation, we partition it into horizontal and vertical parallelism accordingto 
the function and node. We simulate the application code cycle by cycle, like the ATEMU, and use 
different thread to different node, like the Avrora, so that it is synchronization free. The thread for 
each node is not creating unrestricted. If the threads greatly outnumber the cores, the performance 
will decrease. For this reason, we use a thread pool to provide the threads need by the nodes to 
execution each cycle. This has another beneficent that avoids any one thread to be starvation. 
III. Virtualization 
To support our experiments, first build up a platform for actually running applications on a variety of 
multi-core architectures. Instead of building or buying a new architecture each time, we ported a 
virtualization layer onto a multi-core architecture. Virtualization is a software technique for making 
hardware appear as either multiple instances, hide resources such as multiple cores, or make available 
virtual hardware accelerators using multiple cores. This will provide a transparent abstraction layer 
above which a variety of architectures can be experimented. Our approach is to port an open-source 
system virtualization layer to our target multi-core platform. The available VMs as surveyed in the 
Related Work section assume symmetric multiprocessors (SMP), a multiprocessor computer 
architecture where two or more identical processors (or cores) are connected to a single shared main 
memory. 
System virtualization can be done in a manner entirely transparent to the guest OS (i.e., pure 
virtualization, as in QEMU, VirtualBox, VMWare), or in cooperation with the guest OS, (i.e., 
para-virtualization, as in Xen). Both techniques have several advantages and disadvantages. Primarily, 
pure virtualization can support unmodified OSs, but can suffer performance loss when the OS makes 
assumptions about the hardware that are invalid for virtualized resources. Pa-ra-virtualization 
eliminates these assumptions, but sometimes requires significant modifications to the guest OSs and 
the hardware/software interface. In addition, there are many cases where para-virtualization is 
inapplicable or unnecessary, such as when supporting legacy software. It is hard to predict which 
particular approach —pure or para —if not both, will survive, given the diverse application domain 
for virtualization. 
The extension we make is to make not only additional virtual instances of the cores but actually create 
the appearance of hardware accelerators from groups, or is-lands, of cores in addition to the 
general-purpose cores. The virtual machine thus needs the ability to take advantage of the parallelism 
available, and the accelerator functionality may be coded manually using domain-specific and 
architecture-specific knowledge so that it is fully optimized. The other code can then take advantage 
of the island as a blackbox.  However, one key question is how to divide the cores between those for 
the application execution and those that emulate hardware accelerators. Today's SMPs assume shared 
- 12 - 
 
模方法與軟體。 
5. 我們在無線感測網路之模擬器中，模擬每個週期的指令執行情況，減少同步化對於
執行效能之影響。並利用不同的執行緒來執行不同的無線感測網路模擬節點所發生
之事件，以利用多核心系統之效能，來增進無線感測網路之模擬器之效率及其模擬
之真實性。 
6. 我們並提出了針對 Streaming Remote Procedure Call(Streaming RPC)、An Adaptive 
Testing Tool for Embedded Multicore Software、ESL 多核心虛擬共通平台之偵錯開發
環境、Register File Spilling、Network-on-chip-centric System Exploration Platform、
多核心的多媒體應用 framework、Power modeling for PAC-DSP、Hardware/Software 
co-design for multimedia applications 等多個技術討論。 
7. 本計畫主要的研究成果論文受到了國際上的肯定，並陸續刊登在以下知名國際期刊
與研討會 2008 International Conference on Parallel Processing(ICPP 2008) [5]、2009 
ACM/IEEE Design, Automation, and Test in Europe Conference & Exhibition
（DATE'09）[6]、The 14th Workshop on Compilers for Parallel Computing（CPC 2009）
[20]、Computer Standards & Interfaces[76]、Computer Communications, Nov. 2008[77]、
Information Technology Journal[78][79]、IEEE Trans. on Consumer Electronics[80]、
IEEE Journal of Solid-State Circuits[81]、IEEE Trans. on Circuits and Systems II: 
Express Briefs,[82] 、 IEEE Journal of Solid-State Circuits[83] 、 IEEE Trans. on 
Computer-Aided Design of Integrated Circuits and Systems[84]、IEEE Symposium on 
Foundations and Practice of Data Mining (GrC2010)[86]、International Journal of 
Innovative Computing, Information and Control (IJICIC)[87]、Multimedia Tools and 
Applications (MTAP)[88] 、 Theoretical Computer Science[89] 、 Journal of Signal 
Processing Systems[90]、IEEE Consumer Communications & Networking Conference 
(CCNC2010)[91] 、Compilers for Parallel Computing (CPC2010)[92]。我們相信本研
究計畫的成果與經驗對於日後的研究可提供不少的助益。 
 
六、 參考文獻 
 
[1] Texas Instruments, Programming details of codec engine for DaVinci, Techonology 
whitepaper 
[2] Ra jeev R. Ra je, Joseph I. William, and Michael Boyles. An asynchronous remote method 
invocation （ARMI） mechanism for Java. Concurrency: Practice and Experience, 9 
(11):1207–1211, 1997. 
[3] Jason Maassen, Rob van Nieuwpoort, Ronald Veldema, Henri E. Bal, and Aske Plaat. An 
eﬃcient implementation of Java’s remote method invocation. In Proceedings of Principles 
Practice of Paral lel Programming, pages 173–182, 1999.  
[4] Chih-Chieh Yang, Chung-Kai Chen, Yu-Hao Chang, Kai-Hsin Chung, and Jenq-Kuen Lee. 
- 14 - 
 
Design Automation Conf. (DAC), pp.419-424, June 2003. 
[24] M. Oka and M. Suzuoki, ―Designing and Programming the Emotion Engine,‖IEEE Mirco, 
Vol. 19, No.6, November-December 1999, pp. 20-28. 
[25] D. Pham, et al., ―Overview of the Architecture, Circuit Design, and Physical State Circuits of 
a first generation Cell processor‖, IEEE Journal of Solid State Circuits Vol. 41, No.1, January 
2006,pp 179-196.  
[26] M.A. Horowitz et al., ―The Future of Wires,‖ Proc. IEEE,vol.89, no.4, pp. 490-504, Apr. 
2001.  
[27] D. Sylvester and K. Keutzer, ―Impact of Small Process Geometries on Microarchitectures in 
Systems on a Chip,‖ Proc. IEEE, vol.89, no. 4, pp.467-489, Apr.2001. 
[28] Kyeong Keol Ryu, Eung Shin, and Vincent J. Mooney, ‖A Comparison of Five Different 
Multi processor SoC Bus Architectures,‖ Digital Systems, Design, 2001. Proceedings. 
Euromicro Symposium on 4-6 Sept. 2001 pp.202-209 
[29] J. Plosila, T. Seceleanu, and P. Liljeberg, ―Implementation of a self-timed segmented bus,‖ 
Design & Test of Computers, IEEE Vol. 20, Issue 6,  Nov.-Dec. 2003 pp.44 – 50 
[30] J. Plosila, P. Liljeberg, J. Isoaho, ‖Pipelined on-chip bus architecture with distributed 
self-timed control,‖ Signals, Circuits and Systems, 2003. SCS 2003. International 
Symposium on Vol. 1, 10-11 July 2003 pp.257 – 260 
[31] L. Benini and G. De Micheli, Networks on chip – Technology and Tools. Morgan Kaufmann, 
2006. 
[32] L. De Coster,N. Dewulf, and C. T. Ho,"Efficient Multi-Packet Multicast Algorithms on 
Meshs with Wormhole and Dimension-Ordered Routing," Proc. 1995 Int'l Conf. Parallel 
processing, Vol.3 IEEE CS Press, Los Alamitics, Calif.  
[33] Michael D.Ciletti, Modeling, synthesis and rapid prototyping with the Verilog HDL. Prentice 
Hall, 1999. 
[34] W. J. Dally, ―Virtual-channel Flow Control,‖ IEEE Trans. On Parallel and Distributed 
systems, March, 1992. 
[35] W. J. Dally and C. L. Seitz, ―Deadlock-Free Message Routing in Multiprocessor 
Interconnection Networks,‖ IEEE Transaction on Computers, Vol. 36, No. 5, May 1987, 
pp.547-553 
[36] SystemC User’s Guide Version 2. 
[37] ―Artisan Standard Library SRAM Generator User Manual,‖ Artisan Components, 2004. 
[38] D. Brooks, V. Tiwari, and M. Martonosi, ―Wattch: A framework for architectural-level power 
analysis and optimizations,‖ Proc. of Int’l Symp. on Comput. Architecture, pp. 83-94, June 2000. 
[39] F. Catthoor, F. Franssen, S. Wuytack, L. Nachtergaele, and H. De Man, ―Global communication and 
memory optimizing transformations for low power signal processing system,‖ Proc. of Int’l 
Workshop on Low-Power Design, pp. 51-56, 1994. 
[40] M. Chinosi, R. Zafalon, and C. Guardiani, ―Automatic characterization and modeling of power 
consumption in static RAMs,‖ Low Power Electronics and Design, August 1998. 
[41] S.L. Courmeri and D.E. Thomas, Jr., ―Memory modeling for system synthesis,‖ IEEE Trans. VLSI 
Systems, vol. 8, pp. 327-334, June 2000. 
[42] D. Elleouet, N. Julien, D. Houzet, J.-G. Cousin, and E. Martin, ―Power consumption characterization 
and modeling of embedded memories in XILINX VIRTEX 400E FPGA,‖ Proc. of EUROMICRO 
System on Digital System Design, pp. 394-410, 2004. 
- 16 - 
 
[65] M.-J. Li, ―Extrapolation-Based Power Modeling for Memory Compilers Using 
MUX-Oriented Linear Regression,‖ M.S. thesis, National Tsing Hua University, Taiwan, Jul. 
2007. 
[66] T.-Y. Tai, ―Power Modes Classification for Dual-Power SRAM Based on MUX-Oriented 
Power Modeling with Leakage Issue,‖ M.S. thesis, National Tsing Hua University, Taiwan, 
Jan. 2009. 
[67] V. Tiwari, S. Malik, and A. Wolfe, ―Power Analysis of Embedded Software: A First Step 
Towards Software Power Minimization,‖ IEEE Trans. on VLSI Systems, pp. 437-445, Dec. 
1994. 
[68] J. Russell and M. Jacome, ―Software Power Estimation and Optimization for High 
Performance 32-bit Embedded Processors,‖ Proc. of Int’l Conf. on Computer Design, pp. 
328-333, Oct. 1998. 
[69] C. Chakrabarti and D. Gaitonde, ―Instruction Level Power Model of Microcontrollers,‖ Proc. 
of IEEE Int’l Symp. on Circuits and Systems, vol. 1, pp. 76-79, May 1999. 
[70] ―SystemC 2.2”, OSCI, 2004. http://www.systemc.org. 
[71] L. Séméria and A. Ghosh, ―Methodology for Hardware/Software Co-verification in C/C++,‖ 
Proc. of Asian-Pacific Design Automation Conf., pp.405-408, Jan. 2000. 
[72] L. Benini, D. Bertozzi, D. Bruni, N. Drago, F. Fummi, and M. Poncino, ―SystemC 
Cosimulation and Emulation of Multiprocessor SoC Designs,‖ Computer, vol. 36, no. 4, pp. 
53-59, Apr. 2003. 
[73] ―AMBA Specification (Rev. 2.0),‖ ARM, Inc., 1999. http://www.arm.com 
[74] CoWare, Inc., Nov. 2008. http://www.coware.com 
[75] ―PowerMixer Tutorial‖, TinnoTek,  Nov. 2008. http://www.tinnotek.com.tw 
[76] Han-Cheng Hsiang and Wei-Kuan Shih, "Improvement of the secure dynamic ID based 
remote user authentication scheme for multi-server environment", Accepted by Computer 
Standards & Interfaces, , Dec. 2008. (SCI, EI). 
[77] Han-Cheng Hsiang and Wei-Kuan Shih, "Weaknesses and Improvements of the 
Yoon-Ryu-Yoo Remote User Authentication Scheme Using Smart Cards", Accepted by 
Computer Communications, Nov. 2008. (SCI, EI). 
[78] Han-Cheng Hsiang and Wei-Kuan Shih, "A Secure Remote Mutual Authentication and Key 
Agreement without Smart Cards", Accepted by Information Technology Journal, Dec. 2008. 
(EI, INSPEC). 
[79] Han-Cheng Hsiang and Wei-Kuan Shih, "Efficient Remote Mutual Authentication and Key 
Agreement with perfect forward secrecy ", Accepted by Information Technology Journal, 
Nov. 2008. (EI, INSPEC). 
[80] S.-P. Cheng and S.-Y. Huang, "A Low-Power SRAM for Viterbi Decoder in Wireless 
Communication," IEEE Trans. on Consumer Electronics, Vol. 54, No. 2, pp. 290-295, (May 
2008) 
[81] Y.-C. Lai and S.-Y. Huang, "X-Calibration: A Robust Technique for Combating Excessive 
Bitline Leakage Current in Nanometer SRAM Designs", IEEE Journal of Solid-State 
Circuits, Vol. 43, No. 9, pp. 1964-1971, (Sept. 2008).  
[82] Y.-C. Lai and S.-Y. Huang, "A Resilient and Power Efficient Automatic-Power-Down Sense 
Amplifier for SRAM Design", IEEE Trans. on Circuits and Systems II: Express Briefs, Vol. 
55, No. 10, pp. 1031-1035, (Oct. 2008). 
[83] Y.-C. Lai and S.-Y. Huang, "Robust SRAM Design via BIST-Assisted Timing-Tracking 
(BATT)", IEEE Journal of Solid-State Circuits, Vol. 44, No. 2, pp. 642-649, (Feb. 2009). 
[84] C.-W. Tzeng, H.-C. Cheng, and S.-Y. Huang, "Layout-Based Defect-Driven Diagnosis for 
Intra-Cell Bridging Defects," IEEE Trans. on Computer-Aided Design of Integrated Circuits 
and Systems, Vol. 28, No. 5, pp. 764-769, (May 2009). 
[85] A Multi-Core Software API for Embedded MPSoC Environments, Jia-Jer Li, Shao-Chung 
Wang, Po-Chun Hsu, Po-Yu Chen, and Jenq Kuen Lee, Methods and Tools of Parallel 
Programming Multi-computers (MTPP 2010), Russia-Taiwan Symposium 
[86] Tsung Tai Yeh, Tseng-Yi Chen, Yen-Chiu Chen, Wei-Kuan Shih, "Efficient Parallel 
出席國際會議心得報告 
黃崇文 
清華大學資工系博士生 
1. 主要任務摘要： 
參加 Embedded and Ubiquitous Computing (EUC 2009)，本次會議舉行
於加拿大溫哥華，會議期間為 29-31 August 2009。會議主題包括：
嵌入式運算、嵌入式軟體、嵌入式架構、即時作業系統、可重組運算、
隨意運算與通訊，等。這些主題都是以嵌入式架構為基礎，然後沿著
嵌入式系統發展趨勢產生的研究與技術。本次參加會議與各界專家討
論嵌入式架構技術發展，包括：使用嵌入式軟體開發模型、多核心程
式技術、可變架構設計、等等。本次並參與技術研究發表，題目為
Support of Paged Register Files for Improving Context Switching on 
Embedded Processors，藉此向國際與會人員報告對於嵌入式處理器的
微架構技術。 
2. 與會心得： 
感受深刻的會議keynote有 Prof. Yau (Arizona State Univ.)講述在採用
SOA時需要面對的隱私權與安全性議題，Prof. Yau曾經來台參訪，當
時簡介SOA的技術，但這次更加深入提到安全議題。另外，Prof. Wang 
Yi 以Cache-Aware Scheduling and Analysis for Muticores來探討多核
心架構下，如何利用Cache分區的設計，讓多核心架構達到即時系統
的要求，而不會讓task互相影響彼此的執行。EUC會議首日以嵌入式
軟體硬體設計、中介軟體與P2P、無線通訊、嵌入式軟體及架構最佳
化，為主軸進行討論，我們的研究成果就在第一天的嵌入式架構最佳
化上報告。報告完我們設計的暫存器架構後，在場學者的回應相當踴
躍，其中不乏有些問題是在論文中沒有考慮到的情形。而這些意見在
當場有詳細討論，我們並把許多有幫助的意見帶回來跟研究團隊進行
分享。也因此這次透過參與EUC會議與國際學者的交流，得到很多豐
富的經驗分享。 
2 
 
VLIW)、Architecture optimizations (soft-vector and reconfigurable processors)、Architecture 
optimizations (streaming FFT on REDEFINE)、Parallelism (mapping stream programs, progressive 
register spilling, loop parallelism for ILP)。 
2 
 
（三）心得及建議事項 
ESWeek 不愧是國際級的研討盛事，其中車用電子部份，已開始有研究成果發表，顯見我們
往此領域發展的重要性。唯一美中不足的是，或許是因為議城相當緊湊的關係，往往有多篇
論文同時在不同的會議室進行宣讀，令人有分身乏術之感，這是較為可惜的地方。回顧這次
ESWeek 之行，對我在此領域的研究有相當大的助益。學校跟教育部應該多多編列經費鼓勵
老師及學生參加，甚至爭取於台灣主辦會議。除可進行國際學術交流，亦可促進國內研究人
員的國際觀，亦可提高台灣在此領域的能見度！ 
2 
 
group), Automatic polyhedral compilation for GPGPU (affine transformation for GPU)。 
Task scheduling and mapping：Automatic mapping of “stream programs” and “parallel loops” on 
multicore (minimizing synchronization and startup overhead)。 
Adaptive optimization：composition of performance-aware parallel components, offline library 
adaptation (minimize decision trees for FFTW)。 
Automatic parallelization：SIMD Vectorization for Larrabee and AVX ISAs (by the Spiral group)。 
Code generation：parallel copy motion, optimistic integrated instruction scheduling and register 
allocation (by TU Wien)。 
Memory hierarchy optimization：optimizing DDR-SDRAM communications at C-level (by Alain 
Darte from France), parametric tiling of affine loop nests (another affine transformation work)。 
2 Chi-Bang Kuan and Jenq Kuen Lee
1 Introduction
To conquer increasingly growing multimedia workload, SIMD computing is gen-
erally realized in most modern processors as multimedia extensions. Recently,
these multimedia extensions are able to manipulate multiple data in 128-bit or
512-bit vector registers. Similarly, VLIW DSP processors are often equipped
with subword instructions to accelerate subword data processing. Though their
vector widths are relatively short compared with those of general purpose pro-
cessors, usually 32-bit, they are sufficient for image and audio/video processing
in embedded systems. Besides subword instructions, functional units of VLIW
DSP processors can also be utilized to process multiple data streams in par-
allel. For a five-way issue VLIW DSP processor with two multiplication units,
it can issue five full-precision add or two multiply operations in one cycle. This
SIMD capability by parallel instruction issuing can be extended by increasing the
number of functional units. However, centralized register files hinder hardware
designers from adding functional units unlimitedly due to excessive wire con-
nection between register files and functional units. Therefore, many embedded
VLIW DSP processors adopt distributed register files to reduce wire connection
by clustering functional units and privatizing register files for clusters and even
for functional units. Though the distributed design contributes to scalability,
it sacrifices programmability and performance. In the distributed environment,
data accessing is a critical concern, where data sharing between functional units
may incur communication overhead from one to multiple cycles. It presents great
challenges for compilers to employ functional units for parallel data processing.
In this paper, we address the issue in supporting SIMD parallelism on VLIW
DSP processors with subword instructions and distributed register files. Cur-
rently, industrial practices have adopted intrinsic supports in C compilers of
conventional DSP processors, allowing developers to utilize hardware resources
to compete with the performance of hand-written assembly code. However, to
provide such a solution for VLIW DSP processors with distributed register files
is still an open issue. In this work, we support subword and cluster intrinsics
for programmers to elaborate SIMD computation in C programs. With subword
intrinsics, programmers are able to access DSP subword instructions to accel-
erate subword data processing without worrying register allocation, a difficult
task that troubles compilers and assembly programmers for a long time. In ad-
dition, cluster intrinsics are supported to allow programmers to manipulate data
streams in different clusters by forcing instructions to be issued at specified clus-
ters. Cluster intrinsics can be used to guide compilers to distribute computation
to clusters even when data are shared. This is significant to compilers because
they mostly fail to parallelize programs due to communication overhead from
data sharing. When combining subword processing and parallel instruction is-
suing in clusters, VLIW DSP processors actually provide considerable SIMD
computing power. For a five-way issue VLIW DSP processor, with subword and
cluster intrinsics programmers are able to accomplish four dual 16-bit add or
two dual 16-bit multiply operations in one or two cycles, which conceptually
constitute to a 128-bit vector-add or a 64-bit vector-multiply operation.
4 Chi-Bang Kuan and Jenq Kuen Lee
Memory
Interface
Scalar (B)
r0~r15 (R)
d0~d7 (D1) L
S
U
(M)
ac0
~
ac7
(AC1)
a0
~
a7
(A1)
A
L
U
(I)d8~d15 (D2)
d0~d7 (D3) L
S
U
(M)
ac0
~
ac7
(AC2)
a0
~
a7
(A2)
A
L
U
(I)d8~d15 (D4)
Fig. 1. Architectural Overview of PACDSP
logic units (ALU) and one scalar unit (Scalar). The load/store units are in
charge of memory accessing and inter-cluster communication; the arithmetic
logic units are capable of multiplication and saturation operations; the scalar
unit manages program control by issuing conditional branch instructions. The
distributed register design of PACDSP separates functional units into two ALU-
and-LSU pairs as two clusters. There are no shared register files for functional
units in different clusters. Data shared by functional units of different clusters
have to be transmitted between clusters through communication issued by LSU.
In each cluster, every functional unit has its own private register file, which is
A register files for LSU and AC register files for ALU. They are named A1 and
AC1 in cluster 1, while they are named A2 and AC2 in cluster 2. Data reside at
these private register files can not be accessed by other functional units even in
a same cluster. Data shared by functional units within a cluster have to reside at
global register files to be accessible to all of them. There are two global register
files in PACDSP, one for each cluster.
For reducing more wire connection, the global register files are divided into
four banks, which are D1 and D2 in cluster 1 and D3 and D4 in cluster 2.
Accesses to these banks are restricted, forbidding multiple functional units si-
multaneously reading and writing at a bank. Each bank only provides exclusive
read and exclusive write in one cycle. If more than one functional unit attempts
to read (or write) data from (or to) a bank, it will result in global bank con-
tention and cause fatal errors in instruction encoding. Two instruction bundles
in Figure 2.a are used to present how global bank contention happens, in which
instructions are decomposed into read and write operations, W representing a
write and R standing for a read. Both operations take operands from register
files that are accessible by functional units they belong to. Legal register files for
read and write operations in LSU at cluster 1 are A1, D1 and D2, while they are
AC1, D1 and D2 for operations in ALU. Asterisk marks in operands represent
any legal register file of read/write operations. In the first instruction bundle of
Figure 2.a, contention happens as two instructions collide with each other due
to two simultaneous writes to D1. In the second bundle, other two instructions
clash together as they concurrently read operands from D1. Both two instruction
bundles are invalid in PACDSP, and assembly programmers or compilers have
to interleave these instructions by scheduling different instructions or inserting
nop to avoid the contention.
6 Chi-Bang Kuan and Jenq Kuen Lee
full-word, half-word and quarter-word mode, whose data manipulating manners
are depicted in Figure 4.a. The full-word mode treats data in two 32-bit reg-
isters as two integrals, while half-word and quarter-word mode treats registers
as discrete parts by dividing a register into two 16-bit or four 8-bit elements.
Instructions in full-word mode are normal 32-bit operations. Instructions whose
names are suffixed with .d are in half-word mode. They process data in subword
pairs, operating high-part by high-part and low-part by low-part separately with-
out interferences between two subword operations. Half-word mode instructions
can be used to finish two 16-bit operations by one instruction. Instructions in
quarter-word mode have their names ended with .q, and are able to process four
8-bit data tuples independently. So, they are very suitable to accelerate image
processing since pixels are often stored in 8-bit formats.
Before being processed by subword instructions, subword data have to be
packed in registers as two 16-bit pairs or four 8-bit tuples. To pack subword
in registers, one can either load them from contiguous memory locations or
compact them through permutation instructions. To load packed subword data
from contiguous memory is simple. One can use a load word instruction to ac-
cess two 16-bit subword in memory if they reside at aligned addresses. If data
are scattered in memory or in unaligned locations, they have to be loaded into
registers separately and then to be packed together through permutation. To fa-
cilitate permuting subword, PACDSP support diverse instructions to rearrange
subword in registers, including swap to switch two half words in one register
(fig4.b), unpack to dismantle data in a register into two half words in two reg-
isters (fig4.c) and permh2 to fetch any two half words from two registers in
a specified order (fig4.d). Each of these instructions has different applications,
such as realigning data from discrete or unaligned memory locations and ex-
panding a scalar variable into a vector. Two practical uses of them are provided
in section 3.1 when intrinsics programming procedures are elaborated.
ALU
LSU
ALU
ALU
-
-
-
-
LSU
restricted
(d)dex, (d)bdt, (d)bdrcommunication
limw(u)cp, limhw(u)cp, limb(u)cpsaturation
and, andi, or, ori, xor, xori, not, insert, inserti, rol, ror, sll.(d), slli.(d), 
srl.(d), srli.(d), srl40, srli40, sra.(d), srai.(d), extract(u), extracti(u)
bit manipulation
fmul(uu/su/us).(d), mul.d, xfmul.(d), xmul.d, fmac(uu/su/us).(d), mac.d, 
msu.d, xfmac.(d), xmsu.d, dotp2, xdotp2
multiplication
add(u).(d/q), addi.(d), sub(u).(d/q), mergea, merges, neg, abs.(d/q), addc(u)arithmetic
slt(u)[.l/.h], sgt(u)[.l/.h], slti(u), sgti(u), seq, seq[.l/.h], seqi(u), 
(d)min(u).(d/q), (d)max(u).(d/q)
comparison
lmbd, sfra.(d), bf.(d), rnd, saa.qspecial
permh2, permh4, swap2, swap4, swap4e, pack4, unpack2(u), unpack4(u) permutation
(d)lw, (d)lnw, lh(u), lb(u), (d)sw, (d)snw, sh, sbload/store
instructionscategories
Fig. 3. PACDSP Instruction Listing
8 Chi-Bang Kuan and Jenq Kuen Lee
short H[N], X[N];
short *p_H, *p_X, *p_X2;
int f, y=0, d=7, delta=1, error;
/* state update and dot-product */
for(f = 1; f < N; f++)
y += *p_H-- * (*p_X-- = *p_X2--);
y += *p_H * (*p_X = x);
/* coefficient update */
error = (d - y) * delta;
for(f = 0; f < N; f++)
*p_H++ += error * *p_X++;
/* state update and dot-product */
for(f = 1; f < N; f++)
y += H[N-f] * (X[N-f] = X[N-f-1]);
y += H[0] * (X[0] = x);
/* coefficient update */
error = (d - y) * delta;
for (f = 0; f < N; f++)
H[f] += error * X[f];
1
2
3
4
5
6
7
8
9
10
11
12
13
14
(a) original lms with pointer accessing (b) lms with array references
Fig. 6. The LMS Filter in DSPstone
data streams are almost parallel and isomorphic so that they can be easily al-
located to clusters for parallel processing. In next paragraphs, a real program
which consists of SIMD workload is used to present how SIMD intrinsics can be
used to accelerate data processing on VLIW DSP processors.
3.1 SIMD Intrinsics Programming
In rest of this section, the Least Mean Squares (LMS) filter from DSPstone
benchmark is used as an example to illustrate the process of SIMD intrinsics
programming. Along the process, step-by-step explanation and program snip-
pets are provided to instruct programmers to write high-performance code on
clustered VLIW DSP processors. The implementation of LMS filter in DSPstone
is listed in Figure 6.a with all array data accessed via pointers. To facilitate read-
ing, we change the pointer accesses to array references as shown in Figure 6.b.
To keep explanation simple, the input number of the LMS filter, variable N in
the program, is assumed to be multiple of four so that we do not have to han-
dle remaindering iterations for loop unrolling. The programming process can be
summarized into three major steps that are enumerated in next paragraphs. Fol-
lowing the procedures, the program can be rewritten as shown in Figure 7, which
has same functionality as the original but has higher performance for utilizing
SIMD features.
Program analysis and rewriting plans The first step to rewrite a pro-
gram is to understand its algorithms and implementation. This helps to identify
parallel regions of programs or encourage programmers to change the imple-
mentation to parallel ones. After analyzing the original LMS implementation, it
can be observed there are two loops in the program, one for dot-product and
another for coefficient-update. The dot-product is implemented by multiplying
two input arrays and accumulating results into a variable, Sum. Unfortunately,
it is not parallel due to a dependence cycle on Sum. To parallelize the dot-
product, partial-sum techniques can be used by accumulating results in multiple
temporary variables to make accumulation on partial sums independent. The
changed implementation is shown in Figure 7, where accumulation of results is
implemented by creating eight 16-bit partial sums accommodated in four 32-bit
variables from sum1 to sum4.
10 Chi-Bang Kuan and Jenq Kuen Lee
0 1 2 3
1 2
r1 r2
rd
permh2 rd, r1, r2, 1, 2
(b)
X[N-f]X[N-f-1]X[N-f-2]…
X[N-f-1]X[N-f-2]…
X[N-f-3]
X[N-f-3] X[N-f]
vX[(N/2)-f]vX[(N/2)-f-1]
X[N]
X[N]’
0 1 2 3
0 0
r1 r2
rd
permh2 rd, r1, r2, 0, 0
(c)(a)
Fig. 8. Applications of Permutation Instructions
addresses. For example, in Figure 7 two integer pointers, vX and vH , are used to
access H and X array with 32-bit lw instructions rather than 16-bit lh instruc-
tions. This utilizes memory bandwidth and saves data accessing time. However,
pointers must be carefully used since accessing data from unaligned locations
may result in fatal errors or unexpected results. To ensure subword data are
on aligned addresses, some compiler utilities can be used to align arrays to a
specified boundary. For example, in Figure 7 variable attributes supported by
GCC and Open64 are used to align two input arrays to 4-byte boundaries by
adding attribute ((aligned(4))) in array declarations.
Though data can be aligned to specified boundaries, not all data reside at
aligned addresses. For example, the X array in dot-product is updated by as-
signing each element by its left neighbor in each iteration, ie. X[N-f]=X[N-f-1].
To update two array elements in parallel, we can load X[N-f-1] and X[N-f-2]
in pair and store them to memory locations of X[N-f] and X[N-f-1] as depicted
in Figure 8.a. However, accessing a 32-bit data from the location of X[N-f-2]
and X[N-f-1] is invalid for crossing 32-bit boundaries. To obtain the desired sub-
word pair, permutation instructions can be employed to pack them from data in
aligned addresses, vX[(N/2)-f-1] and vX[(N/2)-f]. The permutation is presented
in Figure 8.b, where two subword data scattered in registers are packed from
different parts in registers. Besides unaligned data accessing, permutation in-
structions can also be used to expand a scalar variable to a vector of subword
by specifying two zeros in last two operands as shown in Figure 8.c. This is used
in the LMS filter to expand an intermediate result, error, into a vector, v err,
at line 22 in Figure 7.
Using subword and cluster intrinsics Once subword data are packed, they
are ready to be processed by subword instructions via SIMD intrinsics. In the two
loops of LMS filter,mac.c instructions for half-word multiply-and-accumulate are
used to accomplish two 16-bit multiplication and accumulation in one instruc-
tion. The first loop uses mac.d to multiply array inputs and accumulate results
in partial sums, while the second loop employs mac.d to update two 16-bit coef-
ficients in H . After elaborating subword operations in subword intrinsics, we can
use cluster intrinsics to distribute computation to clusters. Before distributing
the workload in dot-product, we further unroll the loop thrice and create four
partial-sum pairs to increase parallelism in the loop body as shown in Figure 7.
After considering data sharing between computation, we would like to assign
two adjacent accumulations to one cluster, first two to cluster 1 and the other
two to cluster 2. Cluster intrinsics, builtin c1 mac d and builtin c1 permh2
and their counterparts for cluster 2, are used to allocate the unrolled loop to
12 Chi-Bang Kuan and Jenq Kuen Lee
// two R at D1
// two W at D1
ALU @ C1LSU @ C1
SW D1, A1;
ADD D1, D1, AC1;SW D1, A1; 
ADD D1, D1, AC1;LW D1, A1; 
LW D1, A1;
ALU @ C1LSU @ C1
SW D2, A1;
ADD D2, D2, AC1;SW D1, A1; 
ADD D1, D1, AC1;LW D2, A1; 
LW D1, A1;
(a) (b)
Fig. 9. Global Bank Contention due to Parallel Data Processing
Global bank contention For reducing more wire connection, the global reg-
ister files are divided into banks and restricted to provide exclusive read and
write per cycle. Due to this restriction, even if data are allocated in global reg-
ister banks, concurrently reading or writing data from/to a bank may result in
contention. Global bank contention occasionally happens in sequential programs
and could be avoided by scheduling different instructions or inserting nop. How-
ever, contention happens frequently in SIMD processing since operations on data
streams compete for global banks within clusters. An oversimplified example is
shown in Figure 9.a to illustrate how contention happens due to parallel data
processing. In the instruction bundles, two input data are loaded from mem-
ory to be updated by ALU and then stored back to memory, similar to the
coefficient-update in LMS filter. Since data are accessed by both LSU and ALU,
they have to reside at global banks. In this example, they are all allocated in
the bank D1. To obtain compact code, compilers will attempt to schedule the
two add instructions with load/store instructions, lw and sw. Unfortunately,
the scheduling result is invalid since contention happens at the second and third
instruction bundle for reading or writing a global bank at the same time.
One way to avoid contention is to assign data that may interference with
each other to different banks. For example, in Figure 9.b two data are allocated
in different global banks, one in D1 and the other in D2. Such bank assignment
technique was proposed in the paper [6], and is efficient to avoid contention for
sequential programs. However, contention in SIMD processing is so frequent and
crucial to performance that the solution is not applicable to produce adequate
results for SIMD programs. Therefore, an adaptive bank assignment scheme tai-
lored to SIMD needs is proposed to provide efficient code generation for clustered
SIMD programs.
4.1 Compiler Techniques to Enable SIMD Computation
To generate efficient code for clustered SIMD programs, data accessing problems
and global bank contention must be solved. In this paper, we provide restricted
compiler techniques to solve these problems for SIMD programs. They are spe-
cific to SIMD programs since in the solutions we presume that there are parallel
data stream operations in programs. The data stream operations are defined as
sets of similar and independent operations on different data sets, which can be
executed in parallel. Most data parallelism in programs can be modeled as data
stream operations. For example, in the LMS filter, the SIMD workload we dis-
tribute in the dot-product loop can be considered as four data stream operations
in each iteration, each of which corresponds to one mac.d and one permh2 in-
struction. Each iteration of the coefficient-update loop also consists of two data
14 Chi-Bang Kuan and Jenq Kuen Lee
5 Experiments
In this section, we describe implementation details and experimental results for
SIMD intrinsics programming and compiler supports. Our supporting framework
is implemented in an Open64 compiler which targets at PACDSP, a five-way issue
VLIW DSP processor designed by Industrial Technology Research Institute in
Taiwan. We extend the intrinsics supports of Open64 compilers to accommodate
subword and cluster features. To enable efficient code generation for clustered
SIMD programs, we modify the code generator of the Open64 compiler to al-
locate data to register banks or replicate them in multiple banks if necessary.
The register bank assignment and replication techniques are implemented be-
fore register allocation phase in Open64. For experiments, we rewrite DSPstone
benchmark and a set of H.264 kernels by using SIMD intrinsics and following the
procedures provided in Section 3.1. Data types used in DSPstone programs are
configured to 16-bit for employing DSP subword instructions. Data types used
in H.264 kernels are either 8-bit or 16-bit for intra-prediction, interpolation and
IQIT (inverse transform and inverse quantization) respectively.
The performance numbers are presented in Figure 10. There are three num-
bers for each DSPstone program, which are performance for original programs
compiled with the best compiler option (-O2), performance for programs rewrit-
ten by subword intrinsics, and performance for programs rewritten by both sub-
word and cluster intrinsics. All numbers are normalized by those of original
programs, the higher the better. Additional performance numbers of assembly
implementation are provided for H.264 kernels, which are reported by manually
tuned assembly library for high-performance H.264 decoder [10,11]. According to
the performance results, merely using subword intrinsics to rewrite programs can
DSPstone Performance
1.6 1.2 1.2 1.3
1.8
2.3
3.0
1.1 1.5
2.3
3.6
2.3
3.4
3.6
5.8
1.7 1.6
1.4
4.9
7.6
1.92.0
2.32.5
1.1
3.1
4.1
4.85.1
5.8
3.5
2.51.8
2.8
1.21.31.2
1.7
0.0
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
biq
ua
d_
N_
se
cti
on
s.c
biq
ua
d_
on
e_
se
cti
on
.c
co
mp
lex
_m
ult
ipl
y.c
co
mp
lex
_u
pd
ate
.c
co
nv
olu
tio
n.c
do
t_p
rod
uc
t.c fir.
c
fir2
dim
.c
lm
s.c
ma
t1x
3.c
ma
trix
1.c
ma
trix
2.c
n_
co
mp
lex
_u
pd
ate
s.c
n_
rea
l_u
pd
ate
s.c
rea
l_u
pd
ate
.c
ma
in1
02
4_
bit
_re
du
ct.
c
ma
in1
02
4_
inp
sc
a.c
ma
in1
6_
bit
_re
du
ct.
c
ma
in1
6_
inp
sc
a.c
O2 Subword Subword+Cluster
H.264 Kernel Performance
2.6 3.3 1.7 1.2
7.4
9.8 9.2 9.7
2.7 3.5 1.8
3.8 4.8 4.1
2.1 2.5
3.8
4.02.4 1.2 2.2
4.1
2.8
4.9
6.6 5.67.3
2.1
3.6 4.4
10.1
4.2
18.8
3.3
4.03.3
5.3
8.2
2.2
0.0
2.0
4.0
6.0
8.0
10.0
12.0
14.0
16.0
18.0
20.0
Int
ra_
Ch
rom
a_
8x
8_
m0
.c
Int
ra_
Ch
rom
a_
8x
8_
m1
.c
Int
ra_
Ch
rom
a_
8x
8_
m2
.c
Int
ra_
Ch
rom
a_
8x
8_
m3
.c
Int
ra_
Lu
ma
_1
6x
16
_m
0.c
Int
ra_
Lu
ma
_1
6x
16
_m
1.c
Int
ra_
Lu
ma
_1
6x
16
_m
2.c
Int
ra_
Lu
ma
_1
6x
16
_m
3.c
Int
er_
Ch
rom
a_
X_
Y_
NE
Q_
0.c
Int
er_
Lu
ma
_X
_1
_3
_Y
2.c
IQ
IT_
Ch
rom
a_
DC
_Q
P_
GT
_6
.c
IQ
IT_
DT
RF
P_
AC
_E
Q_
1.c
IQ
IT_
Lu
ma
_D
C_
QP
_G
T_
12
.c
O2 Subword Subword+Cluster Assembly
Fig. 10. Performance Results for DSPstone and H.264 Kernels
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
