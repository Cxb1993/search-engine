 1
行政院國家科學委員會專題研究計畫成果報告 
   適應於異質性網格計算環境上複合式資源排程技術   
之設計與研發 
Design, Analysis and Implementation of Composite Multiple 
Resource Scheduler for Heterogeneous Grid Computing 
 
計畫編號：NSC95-2221-E-216-011-MY2 
執行期限：95 年 8 月 1 日至 97 年 7 月 31 日 
主持人：許慶賢   中華大學資訊工程學系副教授 
 
計畫參與人員：中華大學資訊工程學系研究生 
陳世璋(博三)、李開文(研二)、陳泰龍(博二)、郁家豪(研二)  
 
一、中文摘要 
 
本報告是有關於在異質性網格環境上開
發複合式資源排程技術之設計，並且發展具有
平台透通性的分析工具。本計畫有三個主要的
研究課題：一、發展適應於叢集網格環境之主
從式工作排程技術。此項成果可以直接移植到
叢集網格的工作排程系統。二、發展複合式資
源排程的核心技術。針對異質的計算網格系統
與網格拓僕，開發最佳化的評估模組；並以實
際的 work load trace tape，分析系統的效能。
三、發展具有平台透通性的系統資源排程、調
整與學習工具。鑒於網格平台在大量計算與高
性能科學應用上漸漸普及，本計畫之研究成果
可以直接應用在發展高效能叢集式與網格計
算之實驗環境。 
 
關鍵詞：異質計算、網格計算、複合式排程、
資源排程、工作排程、主從式架構。 
 
Abstract 
 
This report presents the project to design 
analysis and implement a composite resource 
scheduler and a platform mutual analysis tool on 
heterogeneous grids.  There are three major 
subjects in this research:  first, we will develop 
master-slave task scheduling technologies which 
can be directly incorporated on cluster grid; 
second, we will develop the main technique of 
composite resource scheduler.  For 
heterogeneous grid and its topology, we will 
devise optimized performance analysis model 
and analyze system efficiency according to a set 
of real work load trace tape from SDSC; third, 
we will develop platform mutual resource 
scheduling and learning tool.  Whereas the grid 
computing becomes widespread for massive 
computing and high performance scientific 
applications, the achievements of this research 
will facilitate constructing high performance 
cluster and grid systems. 
 
Keywords: Heterogeneous Computing, Grid 
Computing, Composite Scheduling, Resource 
Scheduling, Task Scheduling, Master Slave. 
 
二、緣由與目的 
 
  格網計算的技術在近幾年被運用在整合
各種類型網路環境下的各種資源，其目標在於
讓使用者將來處理大量資料和龐大的計算時
能在最短的時間內獲得最有效率的執行成
果，所以格網運算技術簡單的說就是利用大規
模整合的電腦系統，搭配有效率的網路傳輸，
可依照使用者的需求，提供大量的資料處理功
能。在異質網路架構下，資源排程的技術是很
 3
不同的運算能力，所需的傳送時間為 T1 到
T2，T1_comm到 T4_comm即為 Master-Server 傳送一
個工作到各區域之處理器所需之單位時間。 
本計畫第一年所提出的資源排程演算法
為 Shortest Communication Ratio (SCR)，主要
分為三個部份。第一個部分先對需要參與計算
的節點處理器排程，如圖一中的 P1到 P4，排
序依序為處理器中擁有最快執行效能 P1 到最
慢 P4 處理器執行效能。 
Master Server
C1 : P1 C2 : P2 
C3 : P3 C4 : P4
 
圖二、異質性處理器與異質性網路頻寬示意圖 
 
第二部份使用參與運算的處理器之
(Ti_comm + Ti) 計算其最小公倍數的概念將計
算出每一個處理器在每一個基本排程週期
(Basic Scheduling Cycle)將接收多少數量的工
作以利於系統的排程。 
第三部份依照所計算出的基本排程週期
內每個處理器所佔的資料傳輸時間比例大小
來分配，讓資料傳輸時間比例小(換言之為資
料執行時間比例較長)的處理器優先接收工作
以利於提早執行，如此一來可以讓每個處理器
減少等待時間。 
本計畫在第二年提出了三個改良的 SCR
資 源 排 程 演 算 法 分 別 為 SCR-Best-fit 、
SCR-Worst-fit and Extended SCR (ESCR)，除了
先前的三個部份，第四部份分別利用 Best-fit、
Worst-fit 與二元逼進法(Binary approximation 
method)使每個處理器在有限的排程週期
(Scheduling Cycle)、或者在有限的工作結束時
間內(Deadline)增加最大的工作接收與處理數
量而不會造成資源的閒置與浪費。 
SCR 演 算 法 與 Greedy, FPF (Fast 
Processor First) 演算法 [5,6]最大的不同在於
Greedy 演算法為工作單一傳送至處理器做運
算，在系統執行期間會因為沒有考慮到工作整
批傳送的優點產生許多零碎的系統閒置時
間，而 FPF 演算法雖然考慮到工作整批傳送,
但忽略的異質性網路頻寬所造成的影響，導致
有效率的處理器雖然收到比較多工作，但相對
的也增加傳輸負載，如此一來其他的處理器必
需等待更長的時間才可以接收工作。所以 SCR
演算法減少的處理器等待時間與閒置時間，進
而提升整體輸出效能。 
舉例說明 SCR 排程演算法，如圖二之架
構，假設 T1_comm=5， T2_comm=2， T3_comm=1， 
T4_comm=3； T1=3，T2=6， T3=11， T4=13，
分述如下： 
第一步：在圖中，處理器依照單位工作執
行時間( Ti )排序。假設有 n 個節點，則對處理
器排序完後得到集合為<P1, P2, …, Pn>。 
第二步：由步驟一排序節點的結果中所需
之 Ti 與各節點之單位工作傳輸時間 Ti_comm 
計算其最小公倍數 LCM=(5+3, 2+6, 1+11, 
3+13)= 48，計算出處理器 P1到 P4在每一個基
本排程週期(BSC)接收(6, 6, 4, 3)個單位數量
的工作。 
第三步：依照所計算出的基本排程週期內
每個處理器所佔的資料傳輸時間比例大小來
分配，P3 資料傳輸時間比例小(換言之為資料
執行時間比例較長)優先接收工作以利於提早
執行，如此一來可以讓每個處理器減少等待時
間，執行順序依序為 P3, P4, P2 , P1。 
如圖三中所顯示，SCR 演算法讓資料傳
輸時間比例小的節點先接收工作，所以減少其
他節點的等待時間，而參與計算的節點皆有接
收工作並參與執行進而提升系統效能。 
在此範例中工作排程為有限的三個排程
週期(BSC)而工作結束時間(Deadline)為 183。
在 P1的最後一個排程週期結束之前，P2 ,P3, P4, 
 5
    為了讓整體系統效能更加提升與具有彈
性，我們設計了 Extended SCR (ESCR)的演算
法，在 SCR 排程中的閒置空間，利用二元逼
進法使每個處理器在系統所設定的排程週期
內與在有限的工作結束時間內增加最大的工
作處理數量。 
如圖七中所顯示，此範例中，ESCR 演算
法利用二元逼進法使每個處理器在第 j-1 到
j+1 的排程週期內指定完成 66 個工作。每個
運算節點逼近 Deadline = 199 時皆有接收工作
並參與執行進而提升系統效能。ESCR 可依照
使用者指定固定的工作數量或最後的截止時
間，最後一個週期的閒置時間為 12。 
 
 
 
 
圖七、ESCR 排程演算法模擬示意圖。 
 
如圖八中 ESCR 的二元逼進法，當指定固
定的工作數量時，系統會自動辨別工作完成時
間落在那一個週期，並且找出 Makespan 將可
確保最短的時間內完成指定的工作數量。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖八、ESCR 的二元逼進演算法 
    我們針對不同的處理器配置情形與格網
異質性網路環境和各個工作排程演算法進行
分析，發現排程演算法最佳化或與花費最少排
程時間與處理器的異質性有關聯。 
圖九的數據模擬為設定每個處理器取得
的計算能力為正負十，而網路頻寬差距為正負
四，系統執行週期設定為 1 到 5 的基本排程週
期，處理器的節點數量為五個節點的平均系統
效能輸出比較。 
 
圖九、不同基本排程週期下的 FPF，SCR_W，LCR，
SCR，SCR_B 排程步驟效能輸出數據比較 
 
圖十的數據模擬為設定每個處理器取得
的計算能力為正負十，而網路頻寬差距為正負
四，系統執行週期設定為 1 到 5 的基本排程週
期，處理器的節點數量為五個節點的處理器等
待時間比較。 
 
圖十、不同基本排程週期下的 FPF，SCR_W，LCR，
SCR，SCR_B 排程步驟處理器等待時間比較 
 
圖十一的數據模擬為設定每個處理器取
得的計算能力為正負十，而網路頻寬差距為正
負四，系統執行時間設定為 50 到 2000，處理
器的節點數量為五個節點的處理器系統效能
Algorithm_ESCR_Binary_Approcimation (Ti, Ti_comm, Qtask)
// Qtask is the amount of tasks to be processed 
01. While ( !( ESCRfinishTask (x) = Qtask) ) { 
02.    Left_t= )( 1−jSCRfinish BSCT ; 
03.    Right_t= )( 1+jSCRfinish BSCT ; 
04. x=1/2(Left_t+ Right_t); 
05. if ( ESCRfinishTask (x) > Qtask) 
06. x=1/2(x+ Right_t) 
07.       else if  ( ESCRfinishTask (x)< Qtask) 
08. x=1/2(Left_t+x)                   } 
09.   makespan = x; 
End_of_ESCR_Binary_Approcimation 
0.1
0.15
0.2
0.25
0.3
0.35
1 2 3 4 5 BSC
Th
rou
gh
pu
t
FPF SCR_W LCR
SCR SCR_B
0
50
100
150
200
250
1 2 3 4 5 BSC
To
tal
 pr
oc
ess
or
 id
le
FPF SCR_W
LCR SCR
SCR_B
 7
0
1
2
3
4
5
6
7
8
50 200 800 1600 6400
# of task
 A
ve
ra
ge
 m
ea
n 
er
ro
r
Greedy FPF SCR ESCR
 
圖十六、不同工作數量下的 Greedy、FPF，SCR，
ESCR 排程步驟平均錯誤數據比較 
 
在比較這些結果後，我們發現不管節點數
量多或少、網路異質性的高與低、工作數量多
寡，ESCR 仍然比其他演算法有更高的效能，
本計畫中提出 ESCR 排程演算法明顯地勝出其
他演算法許多，尤其在節點數量多的時候，
ESCR 演算法與其他演算法有更大的系統效能
輸出差距，並且有最少的系統等待時間。 
 
四、結論與討論 
 
下面我們歸納本計畫主要的成果: 
z 完成發展單一叢集網格系統之主從式工
作 排 程 、 並 且 實 作 應 用 在 HPHC 
(Heterogeneous Processor with 
Heterogeneous Communication) 架構下，
以實現在異質性叢及網格計算環境中高
效率的執行工作排班程式。 
z 完成 SCR-scheduler 之演算法實作 
我們完成 SCR 之演算法實作，可用來判
斷資料傳送與執行的最少排程步驟。針對
不同數量大小的工作與資料分配性的問
題，設計一套處理器優先序列的計算模
式、以及基本排程週期計算的公式，研究
效能評估機制對整體網路架構的必要性
及其在效能上影響。 
z 完成 SCR-Best-fit 與 SCR-Worst-fit 之演
算法實作 
完成 SCR-Best-fit 與 SCR-Worst-fit 之演
算法實作，用來增加資料傳送量。與 SCR 
比較以相同執行環境下，增加了利用
Best-fit 與  Worst-fit 兩種演算法評估週
期計算的最佳化，使排程系統善用整體網
路資源，比單純使用SCR-scheduler有更好
的效能。 
z 完成ESCR-scheduler 之演算法實作 
完成ESCR-scheduler 之演算法實作，用來
增加資料傳送與減少執行時間，以彌補
SCR-Best-fit 與  SCR-Worst-fit 之演算法
的不足之處。除了先前設計的處理器優先
序列的計算模式、更增加了利用二元逼近
演算法評估週期計算的最佳化，使排程系
統對整體網路資源有最高的使用率。 
z 完成Minimum-Deadline資料分配之排程
演算法實作 
針對最短時間排程步驟分析，所設計的排
程演算法可以找出最短的系統執行時間
(Makespan) 以確保在固定工作量的系統
運作下，處理器的運作時間與閒置時間比
其他演算法更短。 
z 完成Maximum-Job資料分配之排程演算
法實作 
針對最大工作量排程步驟分析，所設計的
排程演算法可以在指定的系統執行時間
(Makespan)內，確保在長系統運作時，處
理器可以做出最有效率的系統輸出，亦及
在時間內與其他演算法比較起來可以完
成最多的工作數量。 
z 完成動態網格拓僕模擬。 
針對不同叢集式計算網格架構、我們建立
一個可以動態評估外部通訊效能的模
式。這一個部分的工作包括，閘道計算、
網路基礎頻寬拓樸模擬、即時網路資訊擷
取、與權重計算方法。 
z 完成Greedy, FPF (Fast Processor First) 
algorithm [5,6], 以 及 LCR (Largest 
Communication Ratio) [1] 之實作。 
為了證實本計畫開發的排程演算法為有
效率的排程演算法，需實做其他排程演算
法以便進行實驗。 
 9
Zagorodnov, ”Adaptive Computing on the Grid 
Using AppLeS,” IEEE Trans. on parallel and 
distributed systems, Vol. 14, No. 4, pp.369-379, 
April 2003. 
[9] S. Bataineh, T.Y. Hsiung and T.G. Robertazzi, 
“Closed Form Solutions for Bus and Tree 
Networks of Processors Load Sharing a Divisible 
Job,” IEEE Trans. Computers, Vol. 43, No. 10, pp. 
1184-1196, Oct. 1994. 
[10] A.T. Chronopoulos and S. Jagannathan, “A 
Distributed Discrete-Time Neural Network 
Architecture for Pattern Allocation and Control,” 
Proc. IPDPS Workshop Bioinspired Solutions to 
Parallel Processing Problems, 2002. 
[11] Atakan Dogan, Fusun Ozguner, ”Matching and 
Scheduling Algorithms for Failure Probability of 
Applications in Heterogeneous Computing,” IEEE 
Trans. on parallel and distributed systems, Vol. 13, 
No. 3, pp. 308-323, March 2002. 
[12] Ching-Chin Han, Kang G. Shin, Jian Wu, ”A 
Fault-Tolerant Scheduling Algorithm for 
Real-Time Periodic Tasks with Possible Software 
Faults,” IEEE Trans. on computers, Vol. 52, No. 3, 
pp.362-372, March 2003. 
[13] Tarek Hagras, Jan Janecek, ”A High Performance, 
Low Complexity Algorithm for Compile-Time 
Task Scheduling in Heterogeneous Systems,” 
Proceedings of the 18th International Parallel and 
Distributed Processing Symposium (IPDPS’04). 
[14] Jennifer M. Schopf, “A General Architecture for 
Scheduling on the Grid,” 
TR-ANL/MCS-P1000-1002, special issue of JPDC 
on Grid Computing, April, 2002. 
[15] Rui Min and Muthucumaru Maheswaran, 
“Scheduling Co-Reservations with priorities in 
grid computing systems,” Proceedings of the 2nd 
IEEE/ACM International Symposium on Cluster 
Computing and the Grid (CCGRID’02), pp. 
250-251, May 2002. 
[16] Muhammad K. Dhodhi, Imtiaz Ahmad Anwar 
Yatama, Anwar Yatama and Ishfaq Ahmad, “An 
integrated technique for task matching and 
scheduling onto distributed heterogeneous 
computing systems,” Journal of Parallel and 
DistributedComputing, Vol. 62, No. 9, pp. 
1338–1361, 2002. 
[17] Ching-Hsien Hsu and Tai-Long Chen, “Grid 
Enabled Master Slave Task Scheduling for 
Heterogeneous Processor Paradigm,” Grid and 
Cooperative Computing - Lecture Notes in 
Computer Science, Vol. 3795, pp. 449-454, 
Springer-Verlag, Dec. 2005. (GCC’05) (SCI 
Expanded) 
[18] G. Aloisio, M. Cafaro, E. Blasi and I. Epicoco, 
“The Grid Resource Broker, a Ubiquitous Grid 
Computing Framework,” Journal of Scientific 
Programming, Vol. 10, No. 2, pp. 113-119, 2002. 
[19] W. E. Allcock, I. Foster, R. Madduri. “Reliable 
Data Transport: A Critical Service for the Grid.” 
Building Service Based Grids Workshop, Global 
Grid Forum, June 2004. 
[20] B. Allcock, J. Bester, J. Bresnahan, A. L. 
Chervenak, I. Foster, C. Kesselman, S. Meder, V. 
Nefedova, D. Quesnal, S. Tuecke. “Data 
Management and Transfer in High Performance 
Computational Grid Environments.” Parallel 
Computing Journal, Vol. 28 (5), May 2002. 
[21] O. Beaumont, A. Legrand and Y.Robert, “Optimal 
algorithms for scheduling divisible workloads on 
heterogeneous systems, “Proceedings of the 12th 
Heterogeneous Computing Workshop, IEEE 
Computer Press 2003. 
[22] J. Blythe, E. Deelman, Y. Gil, C. Kesselman, 
A.Agarwal, G. Mehta and K. Vahi, “The role of 
planning in grid computing,” Proceedings of 
ICAPS’03, 2003. 
[23] H. Casanova, “Simgrid: A Toolkit for the 
Simulation of Application Scheduling,” 
 11
 
 
行政院所屬各機關人員出國報告書提要                  
                                                 撰寫時間： 96 年  6 月  20  日   
姓 名 許慶賢 服 務 機 關 名 稱
 
中華大學
資工系 
連絡電話、 
電子信箱 
03-5186410 
chh@chu.edu.tw
出 生 日 期  62 年 2  月 23  日 職 稱 副教授 
出席國際會議 
名 稱 
2007 International Conference on Algorithms and Architecture for Parallel 
Processing, June 11 -14 2007. 
到 達 國 家 
及 地 點 
Hangzhou, China 出 國
期 間
自 96 年 06 月 11 日
迄 96 年 06 月 19 日
內 容 提 要 
這一次在杭州所舉行的國際學術研討會議共計四天。第一天下午本人抵達會
場辦理報到。第二天各主持一場 invited session 的論文發表。同時，自己也
在上午的場次發表了這依次被大會接受的論文。第一天也聽取了 Dr. 
Byeongho Kang 有關於 Web Information Management 精闢的演說。第二天許
多重要的研究成果分為六個平行的場次進行論文發表。本人選擇了
Architecture and Infrastructure、Grid computing、以及 P2P computing 相關場
次聽取報告。晚上本人亦參加酒會，並且與幾位國外學者及中國、香港教授
交換意見，合影留念。第三天本人在上午聽取了 Data and Information 
Management 相關研究，同時獲悉許多新興起的研究主題，並了解目前國外
大多數學者主要的研究方向，並且把握最後一天的機會與國外的教授認識，
希望能夠讓他們加深對台灣研究的印象。三天下來，本人聽了許多優秀的論
文發表。這些研究所涵蓋的主題包含有：網格系統技術、工作排程、網格計
算、網格資料庫以及無線網路等等熱門的研究課題。此次的國際學術研討會
議有許多知名學者的參與，讓每一位參加這個會議的人士都能夠得到國際上
最新的技術與資訊。是一次非常成功的學術研討會。參加本次的國際學術研
討會議，感受良多。讓本人見識到許多國際知名的研究學者以及專業人才，
得以與之交流。讓本人與其他教授面對面暢談所學領域的種種問題。看了眾
多研究成果以及聽了數篇專題演講，最後，本人認為，會議所安排的會場以
及邀請的講席等，都相當的不錯，覺得會議舉辦得很成功，值得我們學習。
出 席 人 所 屬 機 
關 審 核 意 見 
 
層 轉 機 關 
審 核 意 見 
 
研 考 會 
處 理 意 見 
 
 13
approach, information of applications, such as tasks execution time, message size of 
communications among tasks, and tasks dependences are known a priori at 
compile-time; tasks are assigned to processors accordingly in order to minimize the 
entire application completion time and satisfy the precedence of tasks.  Hybrid 
scheduling techniques are mix of dynamic and static methods, where some 
preprocessing is done statically to guide the dynamic scheduler [8]. 
A Direct Acyclic Graph (DAG) [2] is usually used for modeling parallel 
applications that consists a number of tasks.  The nodes of DAG correspond to tasks 
and the edges of which indicate the precedence constraints between tasks.  In 
addition, the weight of an edge represents communication cost between tasks.  Each 
node is given a computation cost to be performed on a processor and is represented by 
a computation costs matrix.  Figure 1 shows an example of the model of DAG 
scheduling.  In Figure 1(a), it is assumed that task nj is a successor (predecessor) of 
task ni if there exists an edge from ni to nj (from nj to ni) in the graph.  Upon task 
precedence constraint, only if the predecessor ni completes its execution and then its 
successor nj receives the messages from ni, the successor nj can start its execution.  
Figure 1(b) demonstrates different computation costs of task that performed on 
heterogeneous processors.  It is also assumed that tasks can be executed only on 
single processor with non-preemptable style.  A simple fully connected processor 
network with asymmetrical data transfer rate is shown in Figures 1(c) and 1(d). 
 
            
 P1 P2 P3 iw  
n1 14 19 9 14 
n2 13 19 18 16.7 
n3 11 17 15 14.3 
n4 13 8 18 13 
n5 12 13 10 11.7 
n6 12 19 13 14.7 
n7 7 16 11 11 
n8 5 11 14 10 
n9 18 12 20 16.7 
n10 17 20 11 16  
(a)                                   (b) 
                  
 (c)                                  (d) 
Figure 1: An example of DAG scheduling problem (a) Directed Acyclic Graph (DAG-1) (b) 
computation cost matrix (W) (c) processor topology (d) communication weight. 
 
The scheduling problem has been widely studied in heterogeneous systems where 
 15
∑== Pj jii Pww 1 ,                         (1) 
Example of the mean execution time can be referred to Figure 1(b).   
 
For communication part, a P × P matrix T is structured to represent different 
data transfer rate among processors (Figure 1(d) demonstrates the example).  The 
communication cost of transferring data from task ni (execute on processor px) to task 
nj (execute on processor py) is denoted by ci,j and can be calculated by the following 
equation, 
yxjimji tMsgVc ,,, ×+= ,                    (2) 
Where: 
Vm is the communication latency of processor Pm, 
Msgi,j is the size of message from task ni to task nj, 
tx,y is data transfer rate from processor px to processor py, 1≤ x, y ≤P. 
 
In static DAG scheduling problem, it was usually to consider processors’ 
latency together with its data transfer rate.  Therefore, equation (2) can be 
simplified as follows, 
yxjiji tMsgc ,,, ×= ,                     (3) 
Given an application represented by Directed Acyclic Graph (DAG), G = (V, E), 
where V = {nj: j = 1: v} is the set of nodes and v = |V|; E = {ei,j = <ni, nj>} is the set 
of communication edges and e =|E|.  In this model, each node indicates least 
indivisible task.  Namely, each node must be executed on a processor from the start 
to its completion.  Edge <ni, nj> denotes precedence of tasks ni and nj.  In other 
words, task ni is the immediate predecessor of task nj and task nj is the immediate 
successor of task ni.  Such precedence represents that task nj can be start for 
execution only upon the completion of task ni.  Meanwhile, task nj should receive 
essential message from ni for its execution.  Weight of edge <ni, nj > indicates the 
average communication cost between ni and nj. 
Node without any inward edge is called entry node, denoted by nentry; while node 
without any outward edge is called exit node, denoted by nexit.  In general, it is supposed 
that the application has only one entry node and one exit node.  If the actual application 
claims more than one entry (exit) node, we can insert a dummy entry (exit) node with 
zero-cost edge. 
 
3. Preliminaries 
This study concentrates on list scheduling approaches in DAG model.  List 
scheduling was usually distinguished into list phase and processor selection phase.  
Therefore, priori to discuss the main content, we first define some notations and 
terminologies used in both phases in this section. 
3.1 Parameters for List Phase 
Definition 1: Given a DAG scheduling system on G = (V, E), the Critical Score of task 
ni denoted by CS(ni) is an accumulative value that are computed recursively traverses 
along the graph upward, starting from the exit node.  CS(ni) is computed by the 
following equations,  
 17
task nj denoted by )( jnEFT , is formulated as follows,  
)},({)( kjPpj PnFTMinnEFT k∈
=                      (9) 
Definition 5: Based on the determination of )( jnEFT  in equation (9), if the earliest finish 
time of task nj is obtained upon task nj executed on processor pt, then the target processor of 
task nj is denoted by TP(nj), and TP(nj) = pt. 
 
4. The Generalized Critical-task Anticipation Scheduling Algorithm 
Our approach takes advantages of list scheduling in lower algorithmic complexity and 
superior scheduling performance and furthermore came up with a novel heuristic 
algorithm, the generalized critical task anticipation (GCA) scheduling algorithm to 
improve the schedule length as well as speedup of applications.  The proposed 
scheduling algorithm will be verified beneficial for the readers while we delineate a 
sequence of the algorithm and show some example scenarios in three phases, 
prioritizing phase, listing phase and processor selection phase.  
In prioritizing phase, the CS(ni) is known as the maximal summation of scores 
including the average computation cost and communication cost from task ni to the 
exit task.  Therefore, the magnitude of the task’s critical score is regarded as the 
decisive factor when determining the priority of a task.  In listing phase, an ordered 
list of tasks should be determined for the subsequent phase of processor selection. The 
proposed GCA scheduling technique arranges tasks into a list L, not only according to 
critical scores but also considers tasks’ importance.  
Several observations bring the idea of GCA scheduling method.  Because of 
processor heterogeneity, there exist variations in execution cost from processor to 
processor for same task.  In such circumstance, tasks with larger computational cost 
should be assigned higher priority.  This observation aids some critical tasks to be 
executed earlier and enhances probability of tasks reduce its finish time.  
Furthermore, each task has to receive the essential messages from its immediate 
predecessors.  In other words, a task will be in waiting state when it does not collect 
complete message yet.  For this reason, we emphasize the importance of the last 
arrival message such that the succeeding task can start its execution earlier.  
Therefore, it is imperative to give the predecessor who sends the last arrival message 
higher priority.  This can aid the succeeding task to get chance to advance the start 
time.  On the other hand, if a task ni is inserted into the front of a scheduling list, it 
occupies vantage position.  Namely, ni has higher probability to accelerate its 
execution and consequently the start time of suc(ni) can be advanced as well.   
In most list scheduling approaches, it was usually to demonstrate the algorithms 
in two phases, the list phase and the processor selection phase.  The list phase of 
proposed GCA scheduling algorithm consists of two steps, the CS (critical score) 
calculation step and task prioritization step. 
Let’s take examples for the demonstration of CS calculation, which is performed 
in level order and started from the deepest level, i.e., the level of exit task.  For 
example, according to equation (4), we have CS(n10)= 10w = 16.  For the upper 
level tasks, n7, n8 and n9, CS(n7) = ))(( 1010,77 nCScw ++  = 47.12, CS(n8) = 
))(( 1010,88 nCScw ++ =37.83, CS(n9) = ))(( 1010,99 nCScw ++ =49.23.  The other 
tasks can be calculated by the same methods.  Table 1 shows complete calculated 
 19
16.     /* if there are 2+ tasks with same CS(ni), task ni is randomly pushed into S. 
17. EndWhile 
End_GCA_List_Phase 
 
In processor-selection phase, tasks will be deployed from list L that obtained in 
listing phase to suitable processor in FIFO manner.  According to the ordered list L = 
{n1, n4, n2, n5, n9, n3, n7, n6, n8, n10}, we have the complete calculated EFTs of tasks in 
DAG-1 and the schedule results of GCA algorithm are listed in Table 2 and Figure 2(a), 
respectively.   
Table 2: Earliest Finish Time of tasks in DAG-1 using GCA algorithm 
 
Earliest Finish Time of tasks in GCA algorithm 
n1 n2 n 3 n 4 n 5 n 6 n 7 n 8 n 9 n 10 
9 27 42 19.7 32.7 47.6 53 65.7 54.7 84.7   
 
P1 P2 P3 P1 P2 P3 P1 P2 P3
1
10
20
30
40
50
60
70
80
90
100
110
1
24
5 6
9
8
3
7
10
1
34
2
5
6
9
7
8
10
(a) (b) (c)
24
5
9
3
7
6
8
10
 
Figure 2: Schedule results of three algorithms on DAG-1 (a) GCA (makespan = 84.7) (b) 
CA (makespan = 92.4) (c) HEFT (makespan = 108.2). 
 
In order to profile significance of the GCA scheduling technique, the schedule 
results of other algorithms, CA and HEFT are depicted in Figure 2(b) and 2(c), 
respectively. The GCA scheduling techniques incorporates the consideration of 
heterogeneous communication costs among processors in processor selection phase.  
Such enhancement facilitates the selection of best candidate of processors to execute 
specific tasks.   
 
5. Performance Evaluation 
5.1 Random Graph Generator 
We implemented a Random Graph Generator (RGG) to simulate application graphs 
with various characteristics.  RGG uses the following input parameters to produce 
diverse graphs. 
z Weight of graph (weight), which is a constant = {32, 128, 512, 1024}. 
 21
to the HEFT algorithm.  The improvement rate (IRGCA) is estimated by the following 
equation: 
IRGCA = ∑
∑∑ −
)(
)()(
CAorHEFTSpeedup
CAorHEFTSpeedupGCASpeedup         (13) 
 
 
Figure 3: PQS: GCA compared with CA (3 processors)   
 
 
Figure 4: PQS: GCA compared with CA (weight = 128) 
 
16 processors
2.00
3.50
5.00
6.50
8.00
20 40 60 80 100
# task
sp
ee
du
p
GCA
CA
HEFT
 
Figure 5: Speedup of GCA, CA and HEFT with different number of tasks (n). 
 
3.50
4.50
5.50
6.50
7.50
3 4 5 6 7 8
degree
sp
ee
du
p
GCA CA HEFT
 
 
Figure 6: Speedup of GCA, CA and HEFT with different out-degree of tasks (d) 
 23
system.  The GCA scheduling algorithm employs task prioritizing technique based on CA algorithm and introduces a 
new processor selection scheme by considering heterogeneous communication costs among processors.  GCA 
scheduling algorithm is a list scheduling approach with simple data structure and profitable for grid and scalable 
computing.  Experimental results show that GCA has superior performance compare to the well known HEFT 
scheduling heuristic algorithm and our previous proposed CA algorithm which did not incorporate the consideration of 
heterogeneous communication costs into processor selection phase.  Experimental results show that GCA is equal or 
superior to HEFT and CA scheduling algorithms in most cases and it enhances to fit more real grid system. 
Acknowledgements 
This paper is based upon work supported by National Science Council (NSC), Taiwan, under grants no. 
NSC95-2213-E-216-006. Any opinions, findings, and conclusions or recommendations expressed in this material are those of 
the authors and do not necessarily reflect the views of the NSC. 
References 
[1] R. Bajaj and D. P. Agrawal, “Improving Scheduling of Tasks in a Heterogeneous Environment,” IEEE Trans. on PDS, vol. 15, 
no. 2, pp. 107-118, 2004. 
[2] S. Behrooz, M. Wang, and G. Pathak, “Analysis and Evaluation of Heuristic Methods for Static Task Scheduling,” Jounal of 
Parallel and Distributed Computing, vol. 10, pp. 222-232, 1990. 
[3] M.R Gary and D.S. Johnson, “Computers and Interactability: A guide to the Theory of NP-Completeness”, W.H. Freeman and 
Co., 1979. 
[4] T. Hagras and J. Janecek,” A High Performance, Low Complexity Algorithm for Compile-Time Task Scheduling in 
Heterogeneous Systems,” Parallel Computing, vol. 31, Issue 7, pp. 653-670, 2005.  
[5] Ching-Hsieh Hsu and Ming-Yuan Weng, “An Improving Critical-Task Anticipation Scheduling Algorithm for Heterogeneous 
Computing Systems”, Proceedings of the Eleventh Asia-Pacific Computer Systems Architecture Conference, LNCS 4186, pp. 
97-110, 2006.  
[6] E. Ilavarasan P. Thambidurai and R. Mahilmannan, “Performance Effective Task Scheduling Algorithm for Heterogeneous 
Computing System,” IEEE Proceedings of IPDPS, pp. 28-38, 2005. 
[7] S. Ranaweera and D. P. Agrawal, “A Task Duplication Based Scheduling Algorithm for Heterogeneous Systems,” IEEE 
Proceedings of IPDPS, pp. 445-450, 2000. 
[8] Rizos Sakellariou and Henan Zhao, “A Hybrid Heuristic for DAG Scheduling on Heterogeneous Systems”, Proc. of the IEEE 
IPDPS Workshop 1, pp. 111b, 2004. 
[9] H. Topcuoglu, S. Hariri and W. Min-You, “Performance-Effective and Low-Complexity Task Scheduling for Heterogeneous 
Computing,” IEEE Transactions on PDS, vol.13, no. 3, pp. 260-274, 2002. 
 
 
 25
與的第三天全部的大會議程。晚宴，大會安排交通車到市郊一個花園餐廳舉行。最
後一天，本人亦參與了所有的場次，並且發表了這一次的論文。本人主要聽取 GRID
相關研究，同時獲悉許多新興起的研究主題，並了解目前國外大多數學者主要的研
究方向，並且把握最後一天的機會與國外的教授認識，希望能夠讓他們加深對台灣
研究的印象。四天下來，本人聽了許多優秀的論文發表。這些研究所涵蓋的主題包
含有：無線網路技術、網路安全、GRID、資料庫以及普及運算等等熱門的研究課題。
此次的國際學術研討會議有許多知名學者的參與，讓每一位參加這個會議的人士都
能夠得到國際上最新的技術與資訊。是一次非常成功的學術研討會。 
 
四、心得 
 
    參加本次的國際學術研討會議，感受良多。讓本人見識到許多國際知名的研究
學者以及專業人才，得以與之交流。讓本人與其他教授面對面暢談所學領域的種種
問題。看了眾多研究成果以及聽了數篇專題演講，最後，本人認為，會議所安排的
會場以及邀請的講席等，都相當的不錯，覺得會議舉辦得很成功，值得我們學習。 
 
五、建議與結語 
    出席國際會議，註冊費越來越貴(AINA-08 約兩萬元)，若會議在亞州舉行，補
助的經費免強足夠，但是若在歐美，經費往往不足。降低同學參與歐美的會議。 
大會安排的會場以及邀請的講席等，都相當的不錯，覺得會議舉辦得很成功，
值得我們學習。 
 
六、攜回資料  
 
     論文集光碟片 
 
七、出國行程表 
 
3/25 前往 Okinawa  下午研討會報到，參與 AINA-08 Workshop Progra, 
3/26 全日參與研討會 
3/27 全日參與研討會  
3/28 全日參與研討會、晚上飛機返回台灣 
 
 
 
 
 
 
 
 
 27
problems are NP-complete, which has also 
instigated many heuristic solutions [1, 6, 10, 14] 
to resolve. As mentioned in [23], a complete 
grid scheduling framework comprises 
application model, resource model, 
performance model, and scheduling policy. The 
scheduling policy can further decomposed into 
three phases, the resource discovery and 
selection phase, the job scheduling phase and 
the job monitoring and migration phase, where 
the second phase is the focus of this study.  
Although many research works have been 
devoted in scheduling grid applications on 
heterogeneous system, to deal with QOS 
scheduling in grid is quite complicated due to 
more constrain factors in job scheduling, such 
as the need of large storage, big size memory, 
specific I/O devices or real-time services, 
requested by the tasks to be completed. In this 
paper, we present two QoS based rescheduling 
schemes aim to improve the makespan of 
scheduling batch jobs in grid.  In addition, 
based on the QoS guided scheduling scheme, 
the proposed rescheduling technique can also 
reduce the amount of resource need without 
increasing the makespan of grid jobs.  The 
main contribution of this work are twofold, one 
can shorten the turnaround time of grid 
applications without increasing the need of grid 
resources; the other one can minimize the need 
of grid resources without increasing the 
turnaround time of grid applications, compared 
with the traditional QoS guided scheduling 
method. To evaluate the performance of the 
proposed techniques, we have implemented our 
rescheduling approaches along with the QoS 
Min-Min scheduling algorithm [9] and the 
non-QoS based Min-Min scheduling algorithm. 
The experimental results show that the 
proposed techniques are effective in 
heterogeneous systems under different 
circumstances. The improvement is also 
significant in economic grid model [3]. 
The rest of this paper is organized as 
follows. Section 2 briefly describes related 
research in grid computing and job scheduling.  
Section 3 clarifies our research model by 
illustrating the traditional Min-min model and 
the QoS guided Min-min model.  In Section 4, 
two optimization schemes for reducing the total 
execution time of an application and reducing 
resource need are presented, where two 
rescheduling approaches are illustrated in detail. 
We conduct performance evaluation and 
discuss experiment results in Section 5. Finally, 
concluding remarks and future work are given 
in Section 6. 
2. Related Work 
Grid scheduling can be classified into traditional grid 
scheduling and QoS guided scheduling or economic based 
grid scheduling.  The former emphasizes the 
performance of systems of applications, such as system 
throughput, jobs’ completion time or response time.  
Swany et al. provides an approach to improving 
throughput for grid applications with network logistics by 
building a tree of “best” paths through the graph and has 
running time of O(NlogN) for implementations that keep 
the edges sorted [15].  Such approach is referred as the 
Minimax Path (MMP) and employs a greedy, 
tree-building algorithm that produces optimal results [20].  
Besides data-parallel applications requiring high 
performance in grid systems, there is a Dynamic Service 
Architecture (DSA) based on static compositions and 
optimizations, but also allows for high performance and 
flexibility, by use of a lookahead scheduling mechanism 
[4]. To minimizing the processing time of extensive 
processing loads originating from various sources, the 
approaches divisible load model [5] and single level tree 
network with two root processors with divisible load are 
proposed [12]. In addition to the job matching algorithm, 
the resource selection algorithm is at the core of the job 
scheduling decision module and must have the ability to 
integrate multi-site computation power.  The CGRS 
algorithm based on the distributed computing grid model 
and the grid scheduling model integrates a new 
density-based internet clustering algorithm into the 
decoupled scheduling approach of the GrADS and 
decreases its time complexity [24].  The scheduling of 
parallel jobs in a heterogeneous multi-site environment, 
where each site has a homogeneous cluster of processors, 
but processors at different sites has different speeds, is 
presented in [18]. Scheduling strategy is not only in batch 
but also can be in real-time.  The SAREG approach 
paves the way to the design of security-aware real-time 
scheduling algorithms for Grid computing environments 
[21].  
For QoS guided grid scheduling, 
apparently, applications in grids need various 
resources to run its completion.  In  [17], an 
 29
all machines in Min-Min manner.  Figure 2 outlines the 
method of QoS guided scheduling model with the 
Min-Min scheme.   
Analysis: If there are m jobs to be scheduled in 
n machines, the time complexity of QoS guided 
scheduling algorithm is O(m2n).  
Figure 3 shows an example demonstrating 
the Min-Min and QoS Min-Min scheduling 
schemes.  The asterisk * means that 
tasks/machines with QoS demand/ability, and 
the X means that QoS tasks couldn’t be 
executed on that machine.  Obviously, the 
QoS guided scheduling algorithm gets the 
better performance than the Min-Min algorithm 
in term of makespan.  Nevertheless, the QoS 
guided model is not optimal in both makespan 
and resource cost. We will describe the 
rescheduling optimization in next section. 
 
Algorithm_QOS-Min-Min() 
{ 
for all tasks ti in meta-task Mv (in an arbitrary order) 
for all hosts mj (in a fixed arbitrary order) 
       CTij = etij + dtj 
end for 
end for 
do until all tasks with QoS request in Mv are mapped 
for each task with high QoS in Mv,  
find a host in the QoS qualified host set that obtains 
the earliest completion time 
end for 
find task tk with the minimum earliest completion time 
assign task tk to host ml that gives the earliest completion 
time 
delete task tk from Mv 
update dtl 
update CTil for all i 
end do 
do until all tasks with non-QoS request in Mv are mapped 
for each task in Mv 
find the earliest completion time and the 
corresponding host 
       end for 
find the task tk with the minimum earliest completion time 
assign task tk to host ml that gives the earliest completion 
time 
delete task tk from Mv 
update dtl 
    update CTil for all i 
end do 
} End_of_ QOS-Min-Min 
 
Figure 2. The QoS Guided Algorithm 
 
4. Rescheduling Optimization 
Grid scheduling works as the mapping of individual 
tasks to computer resources, with respecting service level 
agreements (SLAs) [2].  In order to achieve the 
optimized performance, how to mapping heterogeneous 
tasks to the best fit resource is an important factor.  The 
Min-Min algorithm and the QoS guided method aims at 
scheduling jobs to achieve better makespan.  However, 
there are still having rooms to make improvements.  In 
this section, we present two optimization schemes based 
on the QoS guided Min-Min approach.  
 
 *M1 M2 
T1 7 4 
T2 3 3 
T3 9 5 
*T4 5 X 
Machine 
Makespan 
A. The Min-Min algorithm B. The QOS guided scheduling algorithm  
M3 
7 
5 
7 
X 
T5 9 8 6 
*T6 5 X X 
Machine 
0 
M1 M2 
*T4 
*T6 
T1 
3 
8 
12 
M3 
T3 
T5 
Makespan 
T2 
0 
M1 M2 
T2
*T4
*T6
T13 
8 
13
M3 
T3
T5
 
Figure 3. Min-Min and QoS Guided Min-Min 
 
4.1 Makespan Optimization Rescheduling (MOR) 
The first one is Makespan Optimization Rescheduling 
(MOR), which focuses on improving the makespan to 
achieve better performance than the QoS guided 
scheduling algorithm. Assume the makespan achieved by 
the QoS guided approach in different machines are CT1, 
CT2, …, CTm, with CTk = max { CT1, CT2, …, CTm }, 
where m is the number of machines and 1 ≤ k ≤ m.  By 
subtracting CTk – CTi, where 1 ≤ i ≤ m and i ≠ k, we can 
have m-1 available time fragments.  According to the 
size of these available time fragments and the size of tasks 
in machine Mk, the MOR dispatches suitable tasks from 
machine Mk to any other machine that has available and 
large enough time fragments.  Such optimization is 
repeated until there is no task can be moved.   
 
 31
 
 M1 *M2 
T1 3 4 
T2 6 6 
*T3 X 7 
T4 4 6 
B. The Resource Optimization Rescheduling 
(ROR) Algorithm 
M3 
2 
3 
X 
2 
T5 5 7 2 
*T6 X 6 X 
Machine 
0 
M1 *M2 
*T6 
T1
4 
8 
13
M3 
*T3 
T5
T2
Makespan 
Machine 
T4
M1 
A. The QOS guided scheduling 
0 
*M2 
T4 
*T6 
T1 
4 
8 
13 
M3 
*T3 
T5 
T2 
Makespan 
 
Figure 6. Example of ROR 
 
The ROR is an optimization scheme which aims to 
minimize resource cost. If there are m tasks to be 
scheduled in n machines, the time complexity of ROR is 
also O(m2n).  Figure 7 depicts a high level description of 
the ROR optimization scheme. 
 
Algorithm_MOR() 
{ 
for m in all machines 
        find out the machine m with minimum count of jobs 
end for 
do until no job can be rescheduled 
for job i in the found machine with minimum count of jobs
            for all machine j 
according to the job’s QOS demand, find the 
adaptive machine j  
if (the execute time of job i in machine j + the 
CTj <= makespan CTmax) 
           rescheduling the job i to machine j   
           update the CTj  
           update the count of jobs in machine m and 
machine j  
       exit for 
end if 
            next for         
next for 
end do 
} End_of_ MOR 
 
Figure 7. The ROR Algorithm  
5. Performance Evaluation 
5.1 Parameters and Metrics 
 
To evaluate the performance of the proposed 
techniques, we have implemented the Min-Min 
scheduling algorithm and the QoS guided Min-Min 
scheme. The experiment model consists of heterogeneous 
machines and tasks.  Both of the Machines and tasks are 
classified into QoS type and non-QoS type.  Table 1 
summarizes six parameters and two comparison metrics 
used in the experiments.  The number of tasks is ranged 
from 200 to 600. The number of machines is ranged from 
50 to 130. The percentage of QoS machines and tasks are 
set between 15% and 75%.  Heterogeneity of tasks are 
defined as Ht (for non-QoS task) and HQ (for QoS task), 
which is used in generating random tasks.  For example, 
the execution time of a non-QoS task is randomly 
generated from the interval [10, Ht×102] and execution 
time of a QoS task is randomly generated from the 
interval [102, HQ×103] to reflect the real application world.  
All of the parameters used in the experiments are 
generated randomly with a uniform distribution.  The 
results demonstrated in this section are the average values 
of running 100 random test samples.  
 
Table 1: Parameters and Comparison Metrics 
 
Task number (NT) {200, 300, 400, 500, 600} 
Resource number (NR) {50, 70, 90, 110, 130} 
Percentage of QOS resources (QR %) {15%, 30%, 45%, 60%, 75%}
Percentage of QOS tasks (QT %) {15%, 30%, 45%, 60%, 75%}
Heterogeneity of non-QOS tasks (HT) {1, 3, 5, 7, 9} 
Heterogeneity of QOS tasks (HQ) {3, 5, 7, 9, 11} 
Makespan The completion time of a set of tasks 
Resource Used (RU) 
Number of machines used for 
executing a set of tasks  
 
5.2 Experimental Results of MOR 
 
Table 2 compares the performance of the MOR, Min-Min 
algorithm and the QoS guided Min-Min scheme in term 
of makespan.  There are six tests that are conducted with 
different parameters.  In each test, the configurations are 
outlined beside the table caption from (a) to (f).  Table (a) 
changes the number of tasks to analyze the performance 
results.  Increasing the number of tasks, improvement of 
MOR is limited. An average improvement ratio is from 
6% to 14%.  Table (b) changes the number of machines.  
It is obvious that the MOR has significant improvement in 
larger grid systems, i.e., large amount of machines.  The 
average improvement rate is 7% to 15%.  Table (c) 
discusses the influence of changing percentages of QoS 
machines.  Intuitionally, the MOR performs best with 
45% QoS machines.  However, this observation is not 
always true.  By analyzing the four best ones in (a) to (d), 
we observe that the four tests (a) NT=200 (NR=50, QR=30%, 
QT=20%) (b) NR=130 (NT=500, QR=30%, QT=20%) (c) 
 33
 
Similar to those of Table 2, Table (a) changes the 
number of tasks to verify the reduction of resource that 
needs to be achieved by the ROR technique.  We noticed 
that the ROR has significant improvement in minimizing 
grid resources.  Comparing with the QoS guided 
Min-Min scheduling algorithm, the ROR achieves 50% ~ 
60% improvements without increasing overall makespan 
of a chunk of grid tasks.  Table (b) changes the number 
of machines.  The ROR retains 50% improvement ratio.  
Table (c) adjusts percentages of QoS machine.  Because 
this test has 20% QoS tasks, the ROR performs best at 
15% QoS machines.  This observation implies that the 
ROR has significant improvement when QoS tasks and 
QoS machines are with the same percentage.  Table (d) 
sets 40% QoS machine and changes the percentages of 
QoS tasks.  Following the above analysis, the ROR 
technique achieves more than 50% improvements when 
QoS tasks are with 45%, 60% and 75%.  Tables (e) and 
(f) change the heterogeneity of tasks.  Similar to the 
results of section 5.2, the heterogeneity of tasks is not 
critical to the improvement rate of the ROR technique.  
Overall speaking, the ROR technique presents 50% 
improvements in minimizing total resource need compare 
with the QoS guided Min-Min scheduling algorithm. 
 
6. Conclusions 
In this paper we have presented two optimization 
schemes aiming to reduce the overall completion time 
(makespan) of a chunk of grid tasks and minimize the 
total resource cost.  The proposed techniques are based 
on the QoS guided Min-Min scheduling algorithm. The 
optimization achieved by this work is twofold; firstly, 
without increasing resource costs, the overall task 
execution time could be reduced by the MOR scheme 
with 7%~15% improvements. Second, without increasing 
task completion time, the overall resource cost could be 
reduced by the ROR scheme with 50% reduction on 
average, which is a significant improvement to the state of 
the art scheduling technique. The proposed MOR and 
ROR techniques have characteristics of low complexity, 
high effectiveness in large-scale grid systems with QoS 
services.  
 
References 
 
[1] A. Abraham, R. Buyya, and B. Nath, "Nature’s Heuristics for 
Scheduling Jobs on Computational Grids", Proc. 8th IEEE 
International Conference on Advanced Computing and 
Communications (ADCOM-2000), pp.45-52, 2000. 
[2] A. Andrieux, D. Berry, J. Garibaldi, S. Jarvis, J. MacLaren, D. 
Ouelhadj, D. Snelling, "Open Issues in Grid Scheduling", 
National e-Science Centre and the Inter-disciplinary Scheduling 
Network Technical Paper, UKeS-2004-03. 
[3] R. Buyya, D. Abramson, Jonathan Giddy, Heinz Stockinger, 
“Economic Models for Resource Management and Scheduling 
in Grid Computing”, Journal of Concurrency: Practice and 
Experience, vol. 14, pp. 13-15, 2002. 
[4] Jesper Andersson, Morgan Ericsson, Welf Löwe, and Wolf 
Zimmermann, "Lookahead Scheduling for Reconfigurable 
GRID Systems", 10th International Europar'04: Parallel 
Processing, vol. 3149, pp. 263-270, 2004. 
[5] D Yu, Th G Robertazzi, "Divisible Load Scheduling for Grid 
Computing", 15th IASTED Int’l. Conference on Parallel and 
Distributed Computing and Systems, Vol. 1, pp. 1-6, 2003 
[6] Fangpeng Dong and Selim G. Akl, "Scheduling Algorithms for 
Grid Computing: State of the Art and Open Problems", 
Technical Report No. 2006-504, 2006. 
[7] Ligang He, Stephen A. Jarvis, Daniel P. Spooner, Xinuo Chen, 
Graham R. Nudd, "Hybrid Performance-oriented Scheduling of 
Moldable Jobs with QoS Demands in Multiclusters and Grids", 
Grid and Cooperative Computing (GCC 2004), vol. 3251, pp. 
217–224, 2004.  
[8] Xiaoshan He, Xian-He Sun, Gregor Von Laszewski, "A QoS 
Guided Scheduling Algorithm for Grid Computing", Journal of 
Computer Science and Technology, vol.18, pp.442-451, 2003. 
[9] Jang-uk In, Paul Avery, Richard Cavanaugh, Sanjay Ranka, 
"Policy Based Scheduling for Simple Quality of Service in Grid 
Computing", IPDPS 2004, pp. 23, 2004. 
[10] J. Schopf. "Ten Actions when Superscheduling: A Grid 
Scheduling Architecture", Scheduling Architecture Workshop, 
7th Global Grid Forum, 2003. 
[11] Junsu Kim, Sung Ho Moon, and Dan Keun Sung, "Multi-QoS 
Scheduling Algorithm for Class Fairness in High Speed 
Downlink Packet Access", Proceedings of IEEE Personal, 
Indoor and Mobile Radio Communications Conference (PIMRC 
2005), vol. 3, pp. 1813-1817, 2005 
[12] M.A. Moges and T.G. Robertazzi, "Grid Scheduling Divisible 
Loads from Multiple Sources via Linear Programming", 16th 
IASTED International Conference on Parallel and Distributed 
Computing and Systems (PDCS), pp. 423-428, 2004. 
[13] M. Baker, R. Buyya and D. Laforenza, "Grids and Grid 
Technologies for Wide-area Distributed Computing", in Journal 
of Software-Practice & Experience, Vol. 32, No.15, pp. 
1437-1466, 2002. 
[14] Jennifer M. Schopf, "A General Architecture for Scheduling on 
the Grid", Technical Report ANL/MCS, pp. 1000-1002, 2002. 
[15] M. Swany, "Improving Throughput for Grid Applications with 
Network Logistics", Proc. IEEE/ACM Conference on High 
Performance Computing and Networking, 2004. 
[16] R. Moreno and A.B. Alonso, "Job Scheduling and Resource 
Management Techniques in Economic Grid Environments", 
LNCS 2970, pp. 25-32, 2004. 
[17] Shah Asaduzzaman and Muthucumaru Maheswaran, 
"Heuristics for Scheduling Virtual Machines for Improving QoS 
in Public Computing Utilities", Proc. 9th International 
Conference on Computer and Information Technology 
(ICCIT’06), 2006. 
[18] Gerald Sabin, Rajkumar Kettimuthu, Arun Rajan and P 
Sadayappan, "Scheduling of Parallel Jobs in a Heterogeneous 
Multi-Site Environment", in the Proc. of the 9th International 
Workshop on Job Scheduling Strategies for Parallel Processing, 
LNCS 2862, pp. 87-104 , June 2003. 
[19] Sriram Ramanujam, Mitchell D. Theys, "Adaptive Scheduling 
based on Quality of Service in Distributed Environments", 
PDPTA’05, pp. 671-677, 2005. 
[20] T. H. Cormen, C. L. Leiserson, and R. L. Rivest, "Introduction 
to Algorithms", First edition, MIT Press and McGraw-Hill, 
ISBN 0-262-03141-8, 1990. 
[21] Tao Xie and Xiao Qin, "Enhancing Security of Real-Time 
Applications on Grids through Dynamic Scheduling", Proc. the 
11th Workshop on Job Scheduling Strategies for Parallel 
