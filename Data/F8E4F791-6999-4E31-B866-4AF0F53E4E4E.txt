 2 
中文摘要 
 
近年來，隨著動作感測器的逐漸普及，以體感控制為基礎的遊戲與人機介面成為數位內容
相關領域中最受注目的新發展。然而，受限於平價儀器的準確度與感應器的數目，這類的介面
方式往往無法反應使用者快速與多變的動作，僅能以簡單動作指令來控制操作。 
本研究計畫，針對此問題，提出以分析比對感測器資料與大量擷取之人物動作資料庫，藉
由結合人物動作辨識與動作合成技術，能以少量的動作感測資料推估出使用者對應的動作變
化。本計畫在一年的時間完成，首先利用電腦學習與訓練的技術，分析出不同的動作指令。再
利用動作指令配合電腦動畫技術驅動角色動作。本計畫所發展的技術，能以普及的平價動作感
測器即時產生平順的人物動畫與體感動作控制，將可應用於擬真體感遊戲或是更進一步的體感
人機介面。 
 
關鍵詞：人物動作合成、動作辨識、動態捕捉技術、體感人機互動 
 
 
 
Abstract 
 
Recently, motion-sensing-based games and interfaces become the most attractive topics in related 
fields of digital contents. However, due to the accuracy and amount limitations of popularly used 
motion sensors, users can only perform simple and restricted motion commands with these kinds of 
interfaces. 
In this project, we propose analyzing and comparing motion sensing data with human motion capture 
database. We plan to combine motion recognition and synthesis techniques and estimate 
high-resolution character motion from sparse motion sensing data. We apply machine learning 
methods to analyze and recognize motion commands. These recognized commands are further 
utilized to drive virtual characters with animation techniques. With the proposed methods, more 
smooth, and high-resolution character animation and interactions can be realized. These techniques 
can be applied to motion-sensing games or advanced human computer interaction. 
 
Key words: character motion synthesis, character motion recognition, motion capture, 
motion-sensing-based human computer interaction 
 
 
 4 
 
圖一：動作辨識系統之流程圖 
使用者的動作資訊將以 Wiimote 中三軸加速度計的三維加速度值來表示，然後從這些資訊
中來分析並且辨識使用者所做的動作。首先讓使用者拿著 Wiimote 重複做要錄製的動作數次，
Wiimote 中的加速度計會透過藍芽傳輸三維加速度值給電腦接收端。在錄製動作的時候，我們
利用加速度量之門檻值判斷使用者是處於動作中抑或是靜止的狀態，以略去多餘的資料。 
多層感知類神經網路(Multi-Layer Perceptron Neural Network)為一種監督式(supervised)的
類神經網路模型，其層(layer)數在三個以上，可分辨非線性可分(non-linearly separable)的資料，
該技術被廣泛應用在語音辨識與影像辨識等領域。在本計畫中，我們將其應用在辨識動作上。
假設動作中一個樣本點的加速度資料為 a = (ax, ay, az) 動作資料庫中各動作資料分段後的資料
區段其三維加速度序列為(a1, a2, … , an)，相對應的動作名稱為 Action_name，則每個資料區段
皆對應到某個動作名稱 (a1, a2, …, an)→(Action_name) 
以 back propagation 的方式更新類神經網路中的權重向量(weight vector)，最後我們可以訓
練出最適當的權重向量。在實際要辨識動作時，新收到的加速度資料區段(a1’, a2’, … , an’)會被
放進訓練好的類神經網路中，可以得到相對應的(Action_name’)，即辨識出來的動作名稱。由
於輸入到類神經網路的加速度值總數量必頇是固定的，所以我們得先把每一筆動作資料之三維
加速度值進行分段(segmentation)。採用分段的方式為：取固定的樣本數為一個區段(一組 sample
資料有三個軸的加速度值)，並間格數個樣本點重疊取下一段，如此重複直到取到最後一個樣
本點。 
 
圖二、資料分段示意圖 
 
 6 
 
圖四、 辨識動作流程 
 
使用者拿 Wiimote 做動作，其當下的三維加速度資料值會被加到一個環狀佇列(circular 
queue)中，此環狀佇列的長度跟類神經網路輸入的 neurons 數一樣，以確保輸入到類神經網路
的資料數量每次都會相同。 
從類神經網路我們只能知道這個資料區段是對應到哪個動作名稱，但是我們不能知道他跟
這個動作的相似度是多少，尤其是當遇到使用者非法的情況，類神經網路還是會分配到一個相
對應的動作名給該動作。這個問題我們預期先利用 KNN(K-Nearest Neighbor)的方式來與現有
資料庫資料比對，並給相似度較高的動作區段較高的權重，把佇列中的加速度值放進訓練好的
類神經網路，我們會得到相對應的動作名稱，得到相對應的動作名稱之後，我們將此資料區段
跟此動作訓練出來的 cluster centers 做 KNN 的比較 
一個資料區段必會對應到一個動作名，故一個動作的多個資料區段可能會對應到多種動
作。我們為了要判斷這多個資料區段最有可能屬於哪一種動作，於是我們得幫每個可能的動作
評分，並以分數最高的動作作為辨認出來的結果。由於先前的動作分數影響整個辨識的結果較
小，所以應該給予較小的權重，而目前的資料區段影響較大，於是會給予 KNN 所得較大的權
重值。 
 
[以多項式函數回歸法與動作資料庫之指令辨識] 
我們從卡內基美隆大學(Carnegie Mellon University, CMU)提供的 BVH 數據庫來研究人體
動作開始，將各個關節點都視為一個紀錄點，各代入一次和二次的多項式，套用 Reduced Marker 
Set 概念從 31 個紀錄點中選出 5 個當作主要紀錄點，之後我們利用這些主要紀錄點的 Wiimote
資料來推臆測人物動作。 
 為了能符合 Wiimote with Motion Plus 的輸入，我們引用了 Homogeneous Coordinate 概念，
藉由原 BVH 提供的旋轉角度得到旋轉矩陣，取代位置資訊，同樣地再經過 MATLAB 進行多
項式回歸之最小平方法運算後，得到的參數即可以主要紀錄點的角速度為輸入，推估出人體動
作之動作指令。 
  如此一來，我們就可以使用 Wii Remote 加裝 Motion Plus 讓使用者可以將資訊輸入、訓練
多項式的參數矩陣，達到只在使用者身上裝 5 隻 Wii Remote 即可當主要紀錄點輸入並完成全
身動作模擬。 
  我們進行過兩種嘗試，首先，判斷多項式是否存在線性關係，我們先用簡單的一次項來做
 8 
    將 Step2 所得角速度資訊與 Step3 所計算出的多項式參數帶入多項式，計算出動作指令。 
Step5:再次以 Motion Plus 紀錄角速度並過濾不合理的輸入 
    對同一動作模型再次進行類似 Step2 的動作，不同的地方是將會計算感測到的角速度與之
前紀錄的角速度的差距，如果大於一指定的門檻值將會判定為無效的動作輸入，而有效的動作
輸入將會紀錄下來。 
Step6: Step5 所得資料再次代入多項式並將還原結果呈現 
    將 Step5 所紀錄的角速度資訊代入多項式找出動作指令，配合人物角色之動作連接技術，
即可還原出類似原始動作的動作模型，系統將會自動撥放該模型。 
 
[動作指令驅動角色動作] 
將 Wiimote 偵測的加速度與角速度資料辨識成對應的動作後，能藉由虛擬人物以互動式的
表現出來，也就是使虛擬人物的運動，能配合操作者做出相仿的動作，達到互動的效果，進而
能延伸到遊戲或其他層面的應用。 
至於在動作的合成技術方面，我們採用類似於 motion graph 的動畫合成技術。motion graph
可將不同動作片段中最相似的部分串接在一起，再藉由動作內插來達到更加平順的效果。只要
motion graph 能夠建立好，再搭配使用類神經網路辨認出的人物動作，作為 graph 中轉換動作
的條件，應該可以對資料庫內包含之動作產生平順擬真的動作對應效果。 
當使用者所要求的動作被系統的虛擬人物完成之後，可能會有兩種情況，第一種是使用者
暫無新的要求，第二種是使用者馬上想要接續新的動作。前者只需讓虛擬角色動作暫停，或是
慢慢將姿勢轉移到 motion graph 中的呆滯狀態即可。而後者需要動作與動作之間的轉移技術，
我們預計沿用之前計畫所研發的具彈性之動作轉移技術，先將姿勢空間進行分群之後，然後替
資料庫中的每個畫格找到所屬分群，並將畫格的時間連續關係拿來當作建立 edge 的資訊，最
後合成轉移動畫時只需尋找兩個目標畫格(前面動作的最後一個畫格、後面動作的第一個畫格)
的所屬分群，還有他們在 garph 中的最短路徑，然後挑選適合的那些 edge 來當中間轉移的動
畫片段，再利用混合的技術來串接各片段，最後便可產生平順自然的轉換效果。 
 
圖六：動作轉移範例 
 
結果與討論 
 
為了要評估類神經網路技術之辨識動作的正確率，我們以 Square、Circle、Roll、Z、 
 10 
 
圖九、動作資料分析、辨認與動作驅動 
 
 1
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期： 99 年 8 月 12 日 
一、參加會議經過 
IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 是電腦視覺與圖形辨識界最
主要的頂級國際會議之一。此會議除了有極為嚴格的論文評審，2010 年共有 1724 篇論文投稿，383 篇
(22.3%)被接受為海報論文，78 篇(4.5%)被接受為口頭報告論文。相較於電腦圖學界對於海報論文偏鼓
勵性質，其質量較不重視；在電腦視覺之重要會議如 ICCV、CVPR、ECCV 等，口頭報告論文外，海
報論文亦受到相當的重視。 
今年度的 CVPR 於 6/13~6/18 在美國加州舊金山市舉行，本年度為期五天的會議，其論文 double 
tracks 的方式交互進行。此會議的一大特色是除了主要會議外，亦包含多個專門主題子研討會。另外此
會議並包含小規模科技廠商的商品展覽。會議之議程包括： 
z 6/13 日－『Object Tracking and Classification beyond the Visible Spectrum』、『Workshop on Use of 
Context in Video Processing』、『Perceptual Organization in Computer Vision』、『Workshop on Embedded 
Computer Vision』、『Online Learning for Computer Vision』。 
z 6/14 日－『Workshop on Computer Vision for Computer Games』、『Workshop on Camera Networks』、
『Workshop on Socially Intelligent Surveillance and Monitoring』、『Workshop on Computer Vision 
計畫編號 NSC 98－2221－E－009－151－ 
計畫名稱 結合動作感測器之角色動作合成技術 
出國人員
姓名 林奕成 
服務機構
及職稱 國立交通大學資訊工程學系 
會議時間 99 年 6 月 13 日至 99 年 6 月 18 日 會議地點 美國 舊金山 
會議名稱 
(中文)第二十三屆電子電機工程學會電腦視覺與圖形辨識會議 
(英文)The 23th IEEE Conference on Computer Vision and Pattern 
Recognition (CVPR’10) 
 3
作合成技術，在前端動作感測器訊號或影像訊號需要精準快速的高維度資料辨識技術；此外，本實驗
室一直以來即發展臉部動作分析、由單一視角利用多特徵估計深度值等技術。這些部分正是電腦視覺
與辨識會議(CVPR)的研究重點。 
其中值得注意的：在 Shape-from-X 部分，Ecker and Jepson 提出『Polynomial Shape from Shading』
利用多項式計算 Shape-from-shading、Jacob 等人提出『Using Cloud Shadows to Infer Scene Structure and 
Camera Calibration』利用動態雲朵的陰影計算城市影像的深度資料。Biswas and Chellappa 則針對人臉
利用基底向量空間重建膚色與臉部曲面『Pose-Robust Albedo Estimation from a Single Image』。 
在人物或動作分析上，Pons-Moll 等人結合動作感應器與攝影機影像，利用最佳化的方式求得對應
資料中最符合之人物動作『Multisensor-Fusion for 3D Full-Body Human Motion Capture』，此部分與本計
畫目標類似，利用攝影機可以將可變空間受限，但須增加運動與拍攝之空間。Zhou 等人則提出
『Unsupervised Discovery of Facial Events』，利用人臉動作的重複規則作自動化分群，這概念類似於本
實驗室接續動作壓縮計畫中人物動作重複性擷取之技術。 
此外，此會議中討論到許多特製化的影像分群技術，如 Felzenszwalb and Veksler 提出的『Tiered 
Scene Labeling with Dynamic Programming』，Yang 等人提出的『Layered Object Detection for Multi-Class 
Segmentation』都是希望在 low-level data grouping 之後，利用部分已知假設來結合以往不易處理的影像
分割。 
 
三、考察參觀活動(無是項活動者略) 
略。 
四、建議 
近年來，在資訊界頂級會議的高度競爭使得會議的影響力與注目程度不亞於一流期刊。對於學界
而言，除了可掌握最新研究趨勢，其整個會議的呈現方式與討論均值得學習。 
對於類似的一流會議，以正式論文入選方式參加並不容易，除了鼓勵國內相關博士班研究生先從
Talk/Sketch/Short 等 paper 開始著手多參加，與國際一流學者交流，將可增廣見聞。在畢業與研究評估
上對於頂級論文應給予一定之肯定，以鼓舞國內學者往頂級會議與期刊的目標努力。 
 
五、攜回資料名稱及內容 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/11/24
國科會補助計畫
計畫名稱: 結合動作感測器之角色動作合成技術
計畫主持人: 林奕成
計畫編號: 98-2221-E-009-151- 學門領域: 計算機圖學
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本計畫之感測器驅動人物角色之技術，正進一步與遊戲業界合作，研發應用於
即時遊戲之互動控制介面。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
