2 
 
 
 
目錄 
 
報告內容…………………………………………………………………3 
參考文獻…………………………………………………………………11 
計畫成果自評……………………………………………………………12 
 
4 
 
translated to the output media (2D or 3D actors). Another technique [2] uses PCA to analyze the 
input video and decides the key-images automatically. It then uses radial basis functions (RBF) 
to interpolate among key-shapes for generating the result shape. Later, [3] can also be used to 
retarget deformation from 2D cartoons to 3D meshes through a sketch-based GUI. Deformation 
transfer [4] is a technique that retargets the deformation from one triangle mesh to the other. This 
technique is a skeleton-free retargeting approach, and it does not need to determine bone-skin 
weights in contrast to the skeleton-based approach. 
Mesh editing: As mentioned earlier, the most popular method to create animations is 
skeleton-based deformation; i.e., the mesh is driven by editing the skeleton. The skeleton-based 
method cannot deal with non-rigid models well.  In addition, it potentially suffers from 
“collapsing joint” and thus requires better solutions such as [5] [6] [7], and [8]. On the other 
hand, several non-skeleton-based methods [3,9,10,11, and12] are proposed to create shape 
deformation by manipulating some handles. In [9] the Poisson equation is used to solve mesh 
editing, and a mesh is modified implicitly through gradient field manipulation. In [10] Laplacian 
coordinates are used to encode geometric details of a 3D surface, and this differential property 
will be preserved as much as possible when it reconstructs the edited mesh. Later, to prevent the 
artifacts for large deformation, a volume-based technique called volumetric graph Laplacian 
(VGL) is proposed in [3]. Some researchers [11,12] are also concentrating on designing a more 
intuitive sketching interface for editing mesh models. 
2. SYSTEM OVERVIEW 
Figure 2 shows the system overview of exaggeration cloning. The inputs are a series of 2D 
cartoon (or sketch) key frames and a 3D model. By extracting the exaggeration parameters from 
a 2D actor, we can retarget these parameters to a 3D model to produce exaggerative effects 
similar to those of the 2D actor. First, we partition the 2D actor into several parts and 
parameterize its exaggeration effects using skeleton warping with an affine transformation. Then 
we partition the 3D model into the corresponding parts (or sub-meshes). For each sub-mesh we 
rotate it to a desired view to roughly match with the corresponding part of the 2D actor and then 
extract its contours. By retargeting the exaggeration parameters of the 2D actor’s corresponding 
part to the contours of a sub-mesh, we deform this sub-mesh to fit with the new contours to 
produce the similar exaggerative effects. Finally, we reconstruct the complete exaggerative 3D 
model from all the deformed sub-meshes. 
3. EXAGGERATION CLONING 
3.1 Exaggeration Parameterization 
The exaggeration effects of an actor in a cartoon can usually be attributed to a combination of 
two factors. One is the global exaggerative pose; the other is the local exaggerative shape 
deformation. In our system the global pose is described using a 2D skeleton; the local shape 
deformation is evaluated using a skeleton warping and a 2D affine transformation. 
First, users choose a part of the actor whose exaggerative effect they would like to clone. 
Through the GUI of our system, users can manually mark the contour (a sequence of points) and 
skeleton (a polyline) for the chosen part among all frames, as shown in Figure 3. For a cartoon 
6 
 
figure, 
1,id  is on bone 1,jb  of 1S . When retargeting 1,id  to 2S  to obtain 2,id′ , instead of using the 
normalized arc length as in [11], we record its relative position on 
1,jb  and locate 2,id′  to the 
same relative position on 
2,jb . Because of a meaningful deformation of an actor in a cartoon, it is 
usually a reasonable assumption that a contour’s (or skin’s) vertex should correspond to the 
identical bone of the skeleton in the animation. This effect is especially obvious in an 
exaggerative animation, since the lengths of all the bones could vary significantly and 
independently. Figure 4 shows the skeleton vertex retargeting using these two schemes. 
Evidently, our method is more reasonable (Figure 4(c)) because a contour vertex is mapped to 
the same bone among all frames. 
 
Next, we similarly use the interpolated rotational angle ( )1,icθ  and Equation (1) to retarget 
1,ic  to 2,ic′ . For details please refer to [11]. 
 
1,1,1,2,2, )())(()( iiiii TRT cdcdc −′=′ θ  (1) 
where T stands for translation and R for rotation. 
After all vertices of 
1C  have been retargeted to 2F , we have a new contour 2C ′ , which is 
expected to have a similar shape to that of
2C . To further fit 2C ′  with 2C , we evaluate an affine 
transformation M, which minimizes their difference using least square criterion. 
 ∑
=
−′
n
i
ii
1
2
2,2,2 ˆˆmin
2
ccM
M
 (2) 
where the hat symbol means the coordinate is shifted such that the contour’s centroid is 
located at the origin. 
In Figure 5 (a), 
1C  (the blue dot curve) is superimposed on 2F  to compare with 2C  (the red 
dot curve). Figure 5 (b) shows 
2C  and 2C ′′  (the green dot curve) superimposed on 2F , where 
222 CC ′=′′ M . We can see that after being skeleton warped and affine transformed, 1C  can be 
retargeted to 2C ′′ , whose shape can properly fit with 2C . This result convinces us that our 
exaggerative parameterization is effective and appropriate. 
8 
 
We can see that our exaggeration parameters retargeting can produce very good shapes for the 
leg in spite of leg bending or leg stretching. Comparing Figure 8 (c) and (d), we can find that the 
affine mapping in the local exaggeration parameter is important to producing the local 
exaggerative effects. Figure 9 shows the exaggeration parameters retargeting results for all the 
sub-meshes of a 3D model in 
1F  and 2F . 
3.3 Mesh Deformation and Reconstruction 
Now for each sub-mesh, it has a corresponding deformed 3D contour. We then treat these 
contour vertices as the handles and use [10] to smoothly deform the sub-mesh. Figure 10 shows 
the results of sub-mesh deformation. Figure 10 (a) is the original sub-mesh. Figure 10 (b) and (c) 
show the different views of the deformed sub-mesh in 
1F  and 2F , respectively. We can see that 
the boundary shape of the sub-mesh is not preserved well. This is because the sub-mesh may 
have some opened boundaries, and our constraints (those extracted contour vertices) are sparse 
near these boundaries. 
We solve this problem by first capping a boundary with a disk-like mesh, deforming the 
capped sub-mesh, and finally removing this cap mesh. The cap mesh is formed as follows. First, 
we use a unit circular disk as the initial mesh for the cap. Then we triangulate the internal region 
of this disk and scale it to roughly fit with the boundary. Finally, we use [10] again to deform the 
caps boundary to fit with the boundary of the sub-mesh. The results of deformation with cap are 
shown in Figure 10 (d) and (e). Comparing with Figure 10 (b) and (c), we can see that the 
boundary shape preservation in (d) and (e) is much better. 
  
  
Since all the sub-meshes are deformed individually, their corresponding boundaries need to 
be stitched together to form a complete mesh model. Instead of directly stitching or merging 
sub-meshes together, we merge all sub-meshes simultaneously and reconstruct the complete 
mesh model. We treat the deformation gradients 
jS s of all triangles between the original (or 
10 
 
 
 
Note that some of the processes discussed in Section 3 only need to be performed once, not 
for all the frames. These processes include exaggeration parameterization, mesh decomposition, 
contour extraction, and sub-mesh boundary capping. Moreover, in each of the processes of 
sub-mesh deformation and mesh reconstruction in Section 3.3, we need to solve a very large 
linear system with a sparse matrix. To speed up the process time for generating each frame, we 
perform the LLT decomposition for these two linear systems during preprocessing. Table 1 shows 
the numerical data of exaggeration cloning for the examples in Figure 11, and 12. Excluding the 
manual labor, the preprocessing is done in seconds. Also, on average, generating each frame only 
takes seconds. Therefore, our exaggeration cloning system can be executed interactively. 
5. CONCLUSION, LIMITATION, AND FUTURE WORK 
We present an exaggeration cloning system that clones the exaggerative effects from a 2D 
actor in sketches or cartoon key-frames to a 3D model. We propose a novel 2D exaggeration 
parameterization that encodes the global exaggerative pose and the local exaggerative shape. The 
results show the effectiveness of our system and its ability to generate manifold exaggerative 
animations. However, there are still some limitations. In cases where the local shape 
deformations are more complicated, the affine transformation of the exaggeration 
parameterization may not give a precise representation of the local exaggeration. Another 
limitation is that the motion trajectories of each 3D part should be restricted parallel to their 
motion plane. In the future we plan to extend our system to handle the more flexible motions. 
For example, the running man in the first row of Figure 15 may turn around while running. 
12 
 
[9] O. Sorkine, Y. Lipman, D. Cohen-Or, M. Alexa, C. Rössl, and H.-P. Seidel. Laplacian surface 
editing. Proceedings of the Eurographics/ACM SIGGRAPH Symposium on Geometry 
processing, 179-188, 2004. 
[10] A. Nealen, O. Sorkine, M. Alexa, and D. Cohen-Or. A Sketch-Based Interface for Detail- 
Preserving Mesh Editing. ACM Transactions on Graphics, 24(3):1142–1147, 2005. 
[11] Y. Kho and M. Garland. Sketching mesh deformations. Proceedings of the ACM Symposium 
on Interactive 3D Graphics, pp.147-154, April 2005. 
[12] R. W. Sumner, J. Popović, Deformation transfer for triangle meshes, ACM Transactions on 
Graphics (TOG), v.23 n.3, August 2004. 
[13] D. DeCarlo, A. Finkelstein, S. Rusinkiewicz, and A. Santella. Suggestive contours for 
conveying shape. ACM Transactions on Graphics, 22(3):848-855, 2003. 
 
計畫成果自評 
 
Related Journal Publication about this Project 
1. Ping-Hsien Lin, Hung-Kuo Chu and Tong-Yee Lee, “Smooth Shape Interpolation for 2D 
Polygons”, International Journal of Innovative Computing, Information and Control 
(IJICIC) pp. 2405-2417, vol. 4, no. 9, September 2008 
2. Tong-Yee Lee, Ping-Hsien Lin, Shao-Wei Yen1, Yu-Shuen, Wang, Zhi-Yuan Yao, Jin-Lung 
Lin, “Exaggeration Cloning From Example Sequence”, International Journal of Computer 
Sciences and Engineering Systems (IJCSES), vol. 3, no. 4: 2009. 
 
 
 
