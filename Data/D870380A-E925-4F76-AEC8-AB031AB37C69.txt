設計與建構一個具有多因子及自我學習能力排程演算法之高效能網
格計算環境 
游坤明 
中華大學資訊工程學系 
摘要 
隨著電腦科學的發展，資訊處理以及分析在各研究領域扮演了相當重要的角色。雖然根據
莫耳定律提到，電晶體的數目平均每兩年會成長一倍，但是計算量的需要卻成長的相對快
速。於是藉由系統匯流排，區域網路或網際網路連接多個計算資料是目前的主流，叢集及
網格系統便是典型的高效能計算平台。本計畫主要運用上述高效能計算平台對生物資訊及
資料探勘領域中兩個重要的問題設計平行演算法，分別為平行化合物推論以及平行頻繁項
目集探勘。化合物推論的問題目標為列舉出所有相同特徵的化合物，在計畫執行中，我們
在主從架構的叢集系統上設計並實作該平行演算法。並且採用兩階段的搜尋策略，主節點
可以先運用 bread-first search 產生適量的候選項目後，將候選項目分配給從屬節點後
使用 depth-first search 找到所有的解。頻繁項目集探勘的目標是在一個給定的交易資
料庫中找到所有符合給定支持度的高頻項目集。我們亦順利在叢集系統及網格系統設計平
行演算法，實驗結果觀察到所設計的方法在叢集系統減少計算所需時間，而在網格系統亦
可以平衡異質節點間的計算負載。計畫進行中所得到的研究成果已發表一篇國際期刊論文
於 Expert System with Application (SCI)，三篇國際研討會論文(兩篇為 EI)，以及一
篇國內研討會論文。 
 
Keywords: 分支與界定, 叢集運算, 網格運算, 化合物推論, 頻繁項目 
Abstract 
With the development of computer science, information processing and data analysis play an 
important role in various research areas. According to Moore’s law, describing a long-term trend 
of computing hardware, the number of transistors can be doubling approximately every two years. 
With the growth of the amount of data, the computing power also needed to grow up. Therefore, 
connect multiple computing units through system bus, interconnection network, or internet to 
produce high throughput computing power is currently the trend. Cluster system and grid system 
are the typical high performance computing platform. This project used cluster or grid system to 
solve two important problems in Bioinformatics and Data Mining named Chemical Compound 
Inference (CCI) problem and Frequent Pattern Mining (FPM) problem respectively. The goal of 
CCI is to enumerate all chemical compounds having the same characteristics; we developed our 
parallel algorithm on cluster system constructed of master/slave architecture. Proposed method 
used two stages searching strategy, in the first stage, bread-first search was used to generate set of 
candidate items on master node. Then each participated slave node use depth-first search to 
2 研究方法與成果 
本計畫已完成項目為：(1) 設計並實作化合物推論演算法於叢集系統中，(2) 設計並實
作頻繁項目集探勘演算法於叢集及網格系統。 
2.1 平行化合物推論 
對化合物推論問題 (Chemical Compound Inference Problem, CCI) 我們提出一 Parallel 
Branch-and-Bound Chemical Compound Inference with Path Frequency (PB-CIPF) 演算法。首
先我們先定義問題本身： 
Definition 1. Let G(V,E) be an undirected vertex-labeled connected graph and ∑ be a set of vertex 
labels. 
由於要解決的問題是化合物，因此可以合理假設圖上最大 degree 是一個常數值，鍵結
數是由原子所決定。圖 1 為一個 feature vector 的例子。f1(G) 代表的就是 G(V,E) 這個圖
的 path frequency. 
 
圖 1  Examples of feature vectors 
利用 path frequency 推論回化合物的問題稱為 Chemical Compound Inference (CCI)。定
義如下： 
Definition 2. Given a feature vector v of level K, output a graph G(V,E) satisfying vGfK =)( and 
∑ ∈ ≤Ewvw vlvalwvm},{: ))((}),({ for all Vv∈ . If there does not exist such G(V,E), 
output “no solution”. 
因為 CCI 問題已被證明為 NP-hard 的問題，於是我們採用平行處理的技術來降低計
算所需的時間。本計畫採用叢集系統做為平行程式執行的平台，叢集系統的主要特性為計
算節點的硬體規格相同，於是在負載平衡的設計上不需要考慮節點的異質特性。圖 2 描述
了我們的方法的概念，可以將圖 2 視為一分支與界定樹 (branch and bound tree)，PB-CIPF 
在執行期間分成 BFS 以及 DFS 兩個階段。由於叢集系統中，我們採用的是標準的主從架
構，在第一階段時，主節點 (master node) 採用 bread-first search (BFS) 的搜尋策略，當產
生了一定數量的候選項目後，再將這些項目採用區塊分配 (block distribution) 的策略分給
所有參與計算的節點。而後各節點便在本機端使用分支與界定演算法結合 depth-first search 
(DFS) 策略求解，直到沒有任何候選項目為止。 
 
 
在實驗的結果中，我們使用的叢集系統硬體規格為 AMD Athlon XP 2000+ 的處理器
以及 1GB 記憶的電腦，並且採用 C 以及 MPI 做為通訊函式庫作我們的程式。為了驗證
程式的正確性及效能，我們使用了 KEGG LIGAND Compound Database 中的化合物為做實
驗資料。效能評估以程式執行的 makespan 做為比較的依據，並且對 K=1 到 K=4 不同限
制條件分別在 1, 2, 4 個節點上執行。(見圖 5) 結果中可以觀到，我們提出的方法能夠在計
算節點增加時，降低計算所需要的時間。 
 
  
(a) (b) 
  
(c) (d) 
圖 5. Makespan of C00097, C11108, C11109, C15987 
2.2 平行頻繁項目集探勘 
探勘頻繁項目集是許多資料探勘研究的基礎，分類（Classification）、分群（Clustering）、
關聯式法則（Association rule）、時間序列（Time sequence）。以關聯式法則為例子，主要的
目標是關聯式法則是一個能從大量資料中去找出資料間彼此關聯性的技術。例如一家資訊
商品量販店從過去 3 個月的交易紀錄中找出顧客最常購買的商品關聯性，發現凡是購買了
噴墨印表機的顧客，都會在一個月內回到店內來購買墨水匣，因此店家便可以利用這樣的
發現去訂出促銷決策，提升其業績及利潤。 
然而隨著資訊系統被廣泛應用，資料庫的交易筆數增加非常快速，面對大量的資料，
只要做一個檢索的動作可能就需要非常多的時間，更遑論要去找出項目之間的相關性，當
探勘時間需要好幾個工作天甚至是一個禮拜之時，探勘得到的資料早已過時。因此，平行
運算技術是減少探勘所需時間的主要策略。 
我們已設計並實作平行頻繁項目集探勘演算法，並且於叢集系統及網格系統中執行並
驗證。首先，設計平行程式時，最重要的是需要資料計算時間的瓶頸的所在，所以我們實
作先前 Javed  [6] 所提出的 PFP-tree 演算法，並且將各階段計算所需時間列於表 1。表
050
100
150
200
250
300
350
2 4 6 8 10 12 14 16
Ti
m
e 
(S
ec
.)
Number of processors
Execution time (TPFP vs. PFP), threshold =0.0005
t10.i04.d200k.n100k 
(TPFP)
t10.i04.d200k.n100k 
(PFP)
t15.i04.d200k.n100k 
(TPFP)
t15.i04.d200k.n100k 
(PFP)
 
0
100
200
300
400
500
600
2 4 6 8 10 12 14 16
Ti
m
e 
(S
ec
.)
Number of processors
Execution time (TPFP vs. PFP), threshold = 0.0001
t10.i04.d200k.n100k 
(TPFP)
t10.i04.d200k.n100k 
(PFP)
t15.i04.d200k.n100k 
(TPFP)
t15.i04.d200k.n100k 
(PFP)
 
(a) (b) 
0
100
200
300
400
500
600
2 4 6 8 10 12 14 16
Ti
m
e 
(S
ec
.)
Number of processors
Execution time of various threshold, t15.i04.d200k.n100k
0.0001 (TPFP)
0.0001 (PFP)
0.0005 (TPFP)
0.0005 (PFP)
0.001 (TPFP)
0.001 (PFP)
 
 
(c)  
圖 6. Execution time of TPFP-tree 
相同的，表 3 為 BTP-tree 執行時的網格系統軟硬體規格，而圖 7 為 BTP-tree 在網
格系統上的執行時間。實驗結果中可以觀察到，即是在網格的異質環境下，我們提出的 
BTP-tree 依然能夠平衡不同節點間的負載，並且降低計算所需時間。 
 
表 3. Hardware and Software Specification of Multi-cluster Grid 
 Cluster 1 Cluster 2 Cluster 3 
 Hardware Specification 
Number of 
Nodes 
5 5 3 
CPU Pentium 4 3.2G AMD XP 2.0G Pentium 4 3.0G 
Memory 512 MB 1024 MB 1024 MB 
Network 100 Mbps interconnection network 
 Software Configuration 
OS and 
Compiler 
Linux 2.6 
Gcc/G++ 4.03 
Globus Toolkit 4.0 
Message 
Passing Library 
MPICH-G2 
MPICH2 1.0.5 
mpi4py 0.5 
 
Frequency," Proceedings of the 2009 IEEE International Conference on Granular Computing 
(GrC), pp. 733-738, 2009. (EI) (2009.08.17 - 2009.08.19; Lushan Mountain / Nanchang, 
China)  
3. Kun-Ming Yu, Yi-Yan Chang, Jiayi Zhou, Chun-Yuan Huang, Whei-meih Chang, Chun-Yuan 
Lin, Chuan Yi Tang, "Chemical Compounds with Path Frequency Using Multi Core 
Technology," Proceedings of the 4th International ICST Conference on Scalable Information 
Systems (INFOSCALE), 2009. (2009.06.10 - 2009.06.11, Hong Kong, China)  
4. Jiayi Zhou, Kun-Ming Yu, "Balanced Tidset-based Parallel FP-tree Algorithm for the 
Frequent Pattern Mining on Grid System," Proceedings of 4th International Conference on 
Semantics, Knowledge and Grid (SKG 2008), pp. 103-108, 2008. (2008.12.03 - 2008.12.05; 
Beijing, China)  
5. 游坤明, 張義諺, 周嘉奕, 林俊淵, 唐傳義, "Inferring a Chemical Compound from Path 
Frequency Using Multi-Core Technology," 2008 生物資訊科技與應用研討會 , 2008. 
(2008.11.07; Hsinchu, Taiwan)  
4 參考文獻 
[1] B. Buchanan, and E. Feigenbaum, DENDRAL and Meta-DENDRAL: Their Applications 
Dimension. Artificial Intelligence 11 (1978) 5-24. 
[2] K. Funatsu, and S. Sasaki, Recent advances in the automated structure elucidation system, 
chemics. utilization of two-dimensional nmr spectral information and development of 
peripheral functions for examination of candidates. J. Chem. Inf. Comput. Sci 36 (1996) 
190-204. 
[3] J. Faulon, C. Churchwell, and D. Visco Jr, The signature molecular descriptor. 2. Enumerating 
molecules from their extended valence sequences. J. Chem. Inf. Comput. Sci 43 (2003) 
721-734. 
[4] L. Hall, R. Dailey, and L. Kier, Design of molecules from quantitative structure-activity 
relationship models. 3. Role of higher order path counts: path 3. Journal of Chemical 
Information and Computer Sciences 33 (1993) 598-603. 
[5] M. Deshpande, M. Kuramochi, N. Wale, and G. Karypis, Frequent substructure-based 
approaches for classifying chemical compounds. IEEE Transactions on Knowledge and 
Data Engineering 17 (2005) 1036-1050. 
[6] A. Javed, and A. Khokhar, Frequent pattern mining on message passing multiprocessor 
systems. Distributed and Parallel Databases 16 (2004) 321-334. 
 
 
 
 一、 參加會議經過 
會議的開幕典禮由大會主席致簡單的歡迎詞，並由會議的委員會主席說明本屆的投
稿與錄取篇數及本屆會議的特色與會議重點後，隨即展開，本屆會議分別於第一天及第
二天的會議議程中各安排了五、六個場次之粒度計算與生物資料處理暨應用領域之最新
趨勢之專題報告 : (1). Intelligence and Language How Could Human Being Have 
Language?, (2). What is Granular Computing?: Highlights and Fallacies, (3). Security and 
Integrity in Outsourcing of Data Mining, (4). Cloud Computing, (5). Cloud Computing Panel 
(6). Challenges Techniques for Mining Real Clonical Data, (7). Granular Computing:Based 
on Fuzzy and Tolerance Relation, (8). Granular Computing: Toward inner logic in decision 
systems,  (9). Mechanism Approach to the Research of Atificial Intelligence, (10). 
Nonstructure Information Retrieval Tolerant Granular Space Model, 以及(11). Clustering 
Algorithms with Automatic Selection of Cluster Number，分別由 Setsuo Ohsuga、Tsau 
Young Lin、 David Wai-lok. Cheung、Dennis Quan、 Meng Ye、 Wesley W. Chu、Bo Zhang 
and Ling Zhang、 Lech Polkowski、Yixin Zhong、ZhongZhi Shi 以及 Michel Ng 作精彩
的專題報告。正式之論文報告分別於專題報告後進行，本人之論文『A Weighted 
Load-Balancing Parallel Apriori Algorithm for Association Rule Mining』被安排在第二天
的 –“Intelligent Data Analysis and Applications”之場次發表。 
二、 與會心得 
  GrC 2008 是一個在粒度計算(Granular computing)研究領域中具有指標性的最重
要國際會議，此次會議共有近四百篇的論文投稿，但僅錄取了一百七十餘篇優秀的粒度
計算資訊系統領域的論文，由會議的進行過程中可以看出主辦單位對會議的流程安排相
當用心，参與此次會議之篇學者可藉著此次會議，在粒度計算資訊系統與生物資訊運用
之各研究領域互相作深入的討論，而且可藉此機會認識在此領域中之權威研究學者，對
於此後從事此領域之研究有相當之助益。 
A Weighted Load-Balancing Parallel Apriori Algorithm  
for Association Rule Mining 
 
 
Kun-Ming Yu1, Jia-Ling Zhou2 
1Department of Computer Science and Information Engineering, Chung Hua University 
2Department of Information Management, Chung Hua University 
1yu@ chu.edu.tw, 2jlzhou@pdlab.csie.chu.edu.tw 
 
 
Abstract 
 
Because of the exponential growth in worldwide 
information, companies have to deal with an ever 
growing amount of digital information. One of the 
most important challenges for data mining is quickly 
and correctly finding the relationship between data. 
The Apriori algorithm is the most popular technique in 
association rules mining; however, when applying this 
method, a database has to be scanned many times and 
many candidate itemsets are generated. Parallel 
computing is an effective strategy for accelerating the 
mining process. In this paper, the Weighted 
Distributed Parallel Apriori algorithm (WDPA) is 
presented as a solution to this problem. In the 
proposed method, metadata are stored in TID forms, 
thus only a single scan to the database is needed. The 
TID counts are also taken into consideration, and 
therefore better load-balancing as well as reducing 
idle time for processors can be achieved. According to 
the experimental results, WDPA outperforms other 
algorithms while having lower minimum support. 
 
1. Introduction 
 
With the rapid development of information 
technology, companies have been working on 
digitizing all areas of business to improve efficiency 
and thus competitiveness.  However, the consequences 
of full-digitization are that tremendous amounts of 
data are generated. It is important to extract 
meaningful information from scattered data, and data 
mining techniques are developed for that purpose. 
There are many techniques being used for data mining, 
for example, Classification, Regression, Time Series, 
Clustering, Association Rules and Sequence. 
Association rule [1, 2] is one of the most useful 
techniques in data mining. Generally, it takes long to 
find the association rules between datasets when a 
database contains a large number of transactions. By 
applying parallel-distributed data mining techniques, 
the mining process can be effectively speeded up. 
With parallel-distributed data mining the calculation is 
done in a distributed environment [3, 7, 8, 9, 12], but 
most of the time, irregular and imbalanced 
computation loads are allocated between processors 
and thus the overall performance is degraded.  
In this paper the Weighted Distributed Parallel 
Apriori algorithm (WDPA) is presented as a solution 
for this problem. In the proposed method, a database 
has only to be scanned once because metadata are 
stored in TID tables. This approach also takes the TID 
count into consideration. Therefore, WDPA improves 
load-balancing as well as reduces idle time of 
processors. 
The experimental results in this study showed that 
the running time of WDPA was significantly faster 
than that of previous methods. In some cases, WDPA 
only used about 2% of the time used in previous 
methods. This can be achieved because WDPA 
successfully reduced the number of scan iterations to 
databases and was able to evenly distribute workloads 
among processors.  
The paper is organized as follows: In section 2, 
association rule and parallel distributed algorithms are 
explained. The WDPA algorithm is proposed in 
section 3. Section 4 gives the experimental results. 
Finally, the conclusion is given in section 5. 
 
2. Related Work 
 
Frequent pattern mining problem is defined as 
follows. Let DB = {T1, T2, …, Tk} be a database of 
transactions, where each transaction Te consists of  I, I 
= {i1, i2, …, im} be a set of all items. Assuming A, B 
are itemsets, A, B ⊆ I, A ∩ B=∅, A→B denotes there 
is an association rule between A and B. Each 
association rule has support and confidence to confirm 
the validity of the rule. Support denotes the occurrence 
rate of an itemset in a DB. Confidence denotes the 
Ii. Equation (4) represents the total weight value of k-
itemsets. 
∑ −
+=
−
×=
1)(
1
1
)()()(_
k
TIDTID
freqlen
ij
jii IlenIlenIWeightTidValue
 (3) 
∑ ∑−
=
−
+=
= −
×=
1)(
0
1)(
1
1 1
)()(
_
k k
TIDTID
freqlen
i
freqlen
ij
ji IlenIlen
WeightTidTotalValue
 (4) 
There are two methods of partitioning weighted 
TID, the Block_WeightTid(BWT) partitions and 
distributes TID by block, the Cyclic_WeightTid(CWT) 
partitions and distributes TID in cyclic. 
 
An example of the algorithms is given below: 
For step1 and step2, P1 (MP), P2 (SP) read and scan 
database, then build level-1 candidate itemsets. (Figure 
3) 
 
Figure 3. Scan database and creating TID forms 
 
Figure 4 shows that P1 collects itemsets that match 
given support into frequent 1-itemsets, then uses CWT 
to calculate and distribute the itemsets on P1. P1: {C, 
B}, P2: {A, F, L, M, O}. (Step 3 and Step 4) 
 
Figure 4. Distributing frequent 1-itemsets on P1 
 
Figure 5 describes P1 and P2 combining level-2 
candidate itemsets and calculating itemset counts 
according to the TID table. Figure 6 represents level-2 
candidate itemset counts on P1 and P2. (Take level-2 
candidate A and C for example, the intersection of A 
and C on TID, [1, 5], is the resulting set, AC) (Step 5 
and Step 6) 
 
 
Figure 5. Itemsets are calculated by counting the 
TID forms 
 
 
Figure 6. P1 and P2 level-2 candidate itemsets 
 
Select the itemsets that match the given support 
value, and save them as frequent 2-itemsets. Because 
the frequent 1-itemsets are larger, candidate itemsets 
that required combination computation will be larger, 
too. In this case, distributing the itemsets in Cyclic will 
produce better results. On the other hand, if there are 
frequent itemsets above level 1, candidate itemsets that 
required combination computation will be smaller, too. 
In this case, distributing the itemsets in Block will 
produce better results. 
P1 receives P2 itemsets, and repeats execution step 4 
to step 9 until there are no more frequent itemsets. 
Figure 7 illustrates the use of BWT to calculate and 
distribute the itemsets on P1. P1: {BC, AC}, P2: {AO, 
AP, CP}. (Step 3 and step 4) 
Figure 8 represents P1 combined level-3 candidate 
itemsets matching given support value into frequent 3-
itemset. 
 
 
Figure 9. Speedup of Four partition Methods of 
WDPA (T10I4D100KN100K, minsup: 0.2%) 
 
Figure 10. Each Processors Execution Time 
(T10I4D50KN100K, minsup: 0.2%) 
 
Figure 11 and 12 show the execution time and 
speedup under different given supports. Ye’s 
algorithm requires that a database being re-scanned for 
every itemset to be counted during the mining process, 
so when there is lower support, Ye’s algorithm takes 
longer to re-scan the database. On the other hand, 
using the TID table with precise distribution of 
itemsets, the WDPA scans the database once only. 
This greatly reduced the time spent on database 
scanning and balanced the computation workload 
among processors. Thus, there is an obvious 
performance advantage of the WDPA algorithm over 
Ye’s algorithm. 
Figures 13 and 14 give the execution time and 
speed up with different databases. With the increased 
size of the database, the length of the TID of itemsets 
in the table will increase. Therefore, when the size of 
the database increased, the execution took longer. 
Moreover, by parallel-distributing the processing, 
large databases can be more effectively mined and 
itemsets will be allocated to different processors to 
perform the calculation, this significantly speeding up 
the mining process. 
 
Figure 11. Execution Time (WDPA vs. Ye’s 
algorithm )(T10I4D100KN100K, minsup: 0.2%) 
 
Figure 12. Execution Time (WDPA vs. Ye’s 
algorithm )(T10I4D100KN100K, minsup: 0.3%) 
 
Figure 13. WDPA Execution Time, minsup: 0.15% 
 
Parallel TID-based frequent pattern mining algorithm on a PC Cluster
and grid computing system
Kun-Ming Yu a, Jiayi Zhou b,*
aDepartment of Computer Science and Information Engineering, Chung Hua University, 707, Section 2, WuFu Road, HsinChu 300, Taiwan, ROC
b Institute of Engineering and Science, Chung Hua University, 707, Section 2, WuFu Road, HsinChu 300, Taiwan, ROC
a r t i c l e i n f o
Keywords:
Frequent pattern mining
Association rules
Data mining
Grid computing
Cluster computing
a b s t r a c t
The mining of frequent patterns from transaction-oriented databases is an important subject. Frequent
patterns are fundamental in generating association rules, time series, etc. Most frequent pattern mining
algorithms can be classiﬁed into two categories: generate-and-test approach (Apriori-like) and pattern
growth approach (FP-tree). In recent years, many techniques have been proposed for frequent pattern
mining based on the FP-tree approach since it only needs two database scans. However, for pattern
growth methods, the execution time increases rapidly when the database size increases or when the
given support is small. Therefore, parallel-distributed computing is a good strategy for solving this prob-
lem. Some parallel algorithms have been proposed, but the execution time is still costly when the data-
base size is large. In this paper, two parallel mining algorithms are proposed; Tidset-based Parallel FP-
tree (TPFP-tree) and Balanced Tidset-based Parallel FP-tree (BTP-tree) for frequent pattern mining on PC
Clusters and multi-cluster grids. In order to exchange transactions efﬁciently, a transaction identiﬁcation
set (Tidset) was used to directly select transactions instead of scanning the database. Since a Grid system
is a heterogeneous computing environment, the proposed BTP-tree can balance the loading according to
the computing ability of the processors. BTP-tree, TPFP-tree and PFP-tree were implemented, and datasets
generated with an IBM Quest Synthetic Data Generator were used to verify the performance of TPFP-tree
and BTP-tree. The experimental results showed that the TPFP-tree needed less execution time on a PC
Cluster than the PFP-tree when the database increased. Moreover, the BTP-tree shortened the execution
time signiﬁcantly and had a better load balance capability than both the TPFP-tree and PFP-tree on a
multi-cluster grid.
 2009 Elsevier Ltd. All rights reserved.
1. Introduction
Extracting frequent patterns in a transaction-oriented database
is vital in the mining of association rules (Agrawal & Srikant, 1994;
Park, Chen, & Yu, 1995), time series, classiﬁcation (Gorodetsky,
Karasaeyv, & Samoilov, 2003), etc. The basic problem in frequent
pattern mining is ﬁnding the number of times for a given pattern
appears in a database. Most of the research in this area has either
used the generate-and-test (Apriori-like) or the pattern growth
approach (FP-growth) (Coenen, Leng, & Ahmed, 2004; Han, Pei,
Yin, & Mao, 2004).
For the Apriori-like approach (Lazcorreta, Botella, & Fernández-
Caballero, 2008; Park et al., 1995), the core idea is that if any length
of the k pattern is not frequent in the database, then the super-pat-
tern (length k + 1) cannot be frequent. However, this approach gen-
erates a large number of candidate datasets and repetitively scans
the database to verify whether it is frequent or not. For example,
250 (about 1015) candidate datasets may be needed to verify
whether a set is frequent or not in a database with 50 items.
Han et al. (2004) propose a novel data structure and method for
mining frequent patterns: the Frequent Pattern (FP) tree data
structure which only stores compressed, necessary information
for mining. Moreover, a mining algorithm – FP growth – based on
FP-tree was also developed. Unlike the Apriori algorithm, the
FP-tree only scans a database twice and the mining information
is obtained from the proposed data structure.
Based on the above, many methods derived from FP-tree have
been proposed (Hong, Lin, & Wu, 2008; Zhou & Yu, 2008). More-
over, these also proved that FP-tree-like algorithms performed
better than Apriori-like algorithm. However, even though FP-tree
performed better, the execution time still increased signiﬁcantly
when the database was large. A parallel and distribution technique
is a good strategy for overcoming this problem. Many parallel-
distributed methods have been proposed (Chen, Huang, Chen, &
Wu, 2005; Holt & Chung, 2004; Li, Zhu, & Ogihara, 2003; Lin, Lee,
Chen, & Yu, 2002; Pramudiono & Kitsuregawa, 2003; Tang & Turkia,
0957-4174/$ - see front matter  2009 Elsevier Ltd. All rights reserved.
doi:10.1016/j.eswa.2009.07.072
* Corresponding author. Tel.: +886 3 5186360; fax: +886 3 5186416.
E-mail addresses: yu@chu.edu.tw (K.-M. Yu), jyzhou@pdlab.csie.chu.edu.tw (J.
Zhou).
Expert Systems with Applications xxx (2009) xxx–xxx
Contents lists available at ScienceDirect
Expert Systems with Applications
journal homepage: www.elsevier .com/locate /eswa
ARTICLE IN PRESS
Please cite this article in press as: Yu, K.-M., & Zhou, J. Parallel TID-based frequent pattern mining algorithm on a PC Cluster and grid computing system.
Expert Systems with Applications (2009), doi:10.1016/j.eswa.2009.07.072
each other at most logp rounds. For example, processor pi commu-
nicates with processor p%prp
2þið Þ in round r where 0 6 i 6 p and1 6 r 6 logp. However, too many trees need to be exchanged if
the given threshold is small. Thus, for the worst case, more proces-
sors will lead to the execution time being longer, since too many
subtrees are needed to send, receive and insert back.
2.3. Grid computing system
Grid computing is a loosely coupled distributed system, it al-
lows for the sharing of processing powers, storage resources, and
services from different geographical locations. Unlike the conven-
tional high performance computing (e.g., Cluster computing)
which is connected by a high speed network, grid computing nodes
are connected by a variety of networks (e.g., gigabit network, inter-
net, etc.). Since a grid connects various computing systems with
different software and hardware speciﬁcations at different geo-
graphical locations, middleware plays an important role in inte-
grating these resources. Globus, Sun Grid Engine, gLite, etc. are
the best known grid middleware suppliers. Of these, Globus is
the most popular and is widely used as open source grid middle-
ware. There are many types of grid computing systems. Multi-clus-
ter is the most popular and widely used. In the multi-cluster grid,
resources are distributed across different networks on a multi-
cluster grid. Moreover, each cluster can be a grid site with a grid
head in each site. Jobs are dispatched to a grid head and the grid
head then dispatched the jobs to the computing node inside a clus-
ter according to its job scheduling algorithm. The administrator is-
sues a certiﬁcate to the grid head and permits it to manage
computing nodes inside the cluster. Moreover, when the cluster
size varies, it only requires the grid head to adjust the setting in-
stead of reconﬁguring the entire grid system.
Since the Grid system has sizeable computing and storage re-
sources. Some researchers have developed their data mining appli-
cation on a Grid system (Cannataro, Talia, & Trunﬁo, 2002; Ciglaric,
Pancur, Ster, & Dobnikar, 2005; Jiang & Yu, 2005). Cannataro et al.
(2002) propose a knowledge grid system and discuss its use in dis-
tributed data mining services. Their study focused on the underly-
ing framework and developed a distributing tool, based on JXTA
peer-to-peer technology. Ciglaric et al. (2005) implemented the
Apriori and the FP-tree algorithm in a grid environment. The results
indicated beneﬁts when using Apriori and FP-tree with a grid sys-
tem. However, the proposed algorithm did not consider the balanc-
ing issue, therefore the performance did not achieve the ideal
speedup when the number of processors increased.
3. Proposed parallel FP-tree algorithms
In this paper, parallel algorithms for frequent pattern mining on
Cluster and Grid systems are proposed. In spite of the results of
other research (Javed & Khokhar, 2004; Pramudiono & Kitsuregawa,
2003), there are still two important issues that need to be consid-
ered for a parallel algorithm to improve frequent pattern mining,
one is reducing the communication cost and the other is balancing
the computing node workload. In order to evaluate the execution
time of different computing stages in detail, the PFP-tree (Javed &
Khokhar, 2004) algorithm was implemented. Table 1 shows the
execution time for each stage of the PFP-tree. It can be observed
that the exchange stage dominated the others. Thus, the exchange
stage was analyzed in depth. First, the exchange stage examined
the candidate tree paths required for other processors, then ex-
changed the extracted paths with other processors and inserted
it back to the local FP-tree. Therefore, the performance deteriorated
with large databases or lower thresholds. Moreover, more proces-
sors also led to worse load balancing. Therefore, the performance
can be improved signiﬁcantly if the execution time of the exchange
stage can be reduced and the workload of the processors can be
balanced evenly.
The goal of our algorithm was to reduce the computation and
communication cost of the exchange stage. Since extracting the
candidate tree paths from an FP-tree data structure needs repeated
traversing of the entire tree and inserting the tree paths back to the
objective tree also requires repeated traversing of the trees, it be-
comes costly, leading to the FP-tree construction procedures being
postponed. After creating the Header Table, the necessary informa-
tion for parallel mining is exchanged in the transaction level of the
DB instead of in the tree paths of the FP-tree.
However, indexing the necessary transactions is costly when
the number of processors increases. For example, when there are
n processors, processor pi needs processing mineSeti. mineSeti is
items that block partitioned from header table for processor pi.
Therefore, processor p0 should scan its database |mineSet1| +
   + |mineSetn| times and then transfer to corresponding proces-
sors, to efﬁciently index the item in which transactions can speed
up the execution processes. For that reason, transaction id (TID)
was used to index the item. For a transactional database
DB = {T1, T2, . . . , Tn} and each transaction Ti # I, I = {i1, i2, . . . , im},
TID(j) = {k|ij \ Tk– u, k = 1, . . . , n}. After creating TID, transactions
can be selected directly while the information for mining frequent
patterns is exchanged.
3.1. Tidset-based parallel FP-tree (TPFP-tree) algorithm for cluster
computing
Since ﬁnding all frequent patterns from transactional databases
is a computation intensive problem, a parallel and distributed
strategy could reduces the execution time and improve the mining
performance. Therefore, the ﬁrst parallel FP-tree algorithm based
TID is developed for Cluster computing. Since a Cluster is homoge-
neous computing, the proposed algorithm distributes the workload
to each processor evenly without considering the difference be-
tween processors. The main object is to reduce the execution time
of mining information exchange and to shorten the index cost of
transaction extraction. There are ﬁve primary stages in the Tid-
set-based Parallel FP-tree (TPFP-tree) algorithm: (1) create Header
Table and Tidset, (2) distribute mining item set, (3) exchange trans-
actions, (4) FP-tree and (5) FP-growth.
Firstly, although creating the header table needs only one data-
base scan, when the database size is large, the execution time is
still costly. Therefore, the TPFP-tree uses block distribution to par-
tition the database and to distribute the divided database to corre-
sponding computing nodes. Moreover, in order to directly select a
transaction with corresponding item in subsequent procedures, a
local transaction identiﬁcation set (Tidset) is also created in this
stage. After processing stage 1, frequent 1-itemset was found with
a given threshold. Frequent 1-itemsets were also the mining items
of the TPFP-tree algorithm. Then the mining items were equally
distributed to the participating processors. Each processor was as-
signed np
j k
items to mine for n frequent 1-itemset and p processors.
In order to build the FP-tree structure and to mine the frequent
patterns with FP-growth on each processor independently, a pro-
cessor should comprise the transactions which contain the as-
signed mining items from other processors. In the transaction
exchanging stage, processor pi scans its partial database to gather
the transactions containing mining items required by other proces-
sors. However, it is costly since pi must scan its database p  1
times to gather all transactions. Hence, the Tidset is used to im-
prove the transaction selecting. Tidset is a map between items
and transaction, the transactions can be directly chosen from given
items with Tidset. Since the Tidset table can be concurrently created
with a frequent 1-itemset, the Tidset of each partial database is
K.-M. Yu, J. Zhou / Expert Systems with Applications xxx (2009) xxx–xxx 3
ARTICLE IN PRESS
Please cite this article in press as: Yu, K.-M., & Zhou, J. Parallel TID-based frequent pattern mining algorithm on a PC Cluster and grid computing system.
Expert Systems with Applications (2009), doi:10.1016/j.eswa.2009.07.072
mining items equally increases the execution time and causes
some computing nodes to be idle. In order to solve this problem,
the target mining items were partitioned according to the perfor-
mance index (PI). Since mining frequent patterns is a computation
TID Items
1 FC A M B P
2 F C AM B P
3 F C AM B H
4 F CA M B H G
TID Items
1 F C A G OH
2 F C A G OH
3 F C A M K L
4 F A M K L
TID Items
1 F C A G P KL
2 F G PD E
3 F C A M BH
4 F A M H G
TID Items
1 F C A G D E K
2 FC M B P
3 F C A M B H
4 F C M H
F C A M H G B P K L D E O
16 14 13 11 8 7 7 5 4 3 2 2 2
F C A M B P H G
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
4
F A G C M P H K L D E B
1
2
3
4
1
3
4
1
2
4
1
3
3
4
1
2
3
4
1 1 2 2 3
F A C G M O K H L
1
2
3
4
1
2
3
4
1
2
3
1
2
3
4
1
2
3
4
1
2
3
4
F C M A B H G D E K P
1
2
3
4
1
2
3
4
2
3
4
1
3
2
3
3
4
1 1 1 1 2
DB1(p1) DB2 (p2) DB3 (p3 BD) 4 (p4)
Tidset1 Tidset2 Tidset3 Tidset4
F C A M B P H G
4 4 4 4 4 2 2 1
F A G C M P H K L D E B
4 3 3 2 2 2 2 1 1 1 1 1
F A C G M O K H L
4 4 3 2 2 2 2 2 2
F C M A B H G D E K P
4 4 3 2 2 2 1 1 1 1 1
HT1 HT2 HT3 HT4
GHT
MS1 MS2 MS3 MS4
DB(p = 4, = 2)
(a)
(b)
(c)
(d)
Fig. 1. Example of DB partitioning into 4 processors with the given threshold n.
F C A
16 14 13
MS1
M H G
11 8 7
MS2
B P K
7 5 4
MS3
L D E O
3 2 2 2
MS4
TID Items
1 FC A M B P
2 F C AM B P
3 F C AM B H
4 F CA M B H G
Transactions to p2
TID Items
1 FC A M B P
2 F C AM B P
3 F C AM B H
4 F CA M B H G
Transactions to p3
TID Items
Transactions to p4
TID Items
1 F C A G OH
2 F C A G OH
3 F C A M K L
4 F A M K L
Transactions to p1
TID Items
3 F C A M K L
4 F A M K L
Transactions to p3
TID Items
3 F C A M K L
4 F A M K L
Transactions to p4
TID Items
1 F C A G P KL
2 F G PD E
3 F C A M BH
4 F A M H G
Transactions to p1
TID Items
3 F C A M BH
4 F A M H G
Transactions to p2
TID Items
1 F C A G P KL
2 F G PD E
Transactions to p4
TID Items
1 F C A G D E K
2 FC M B P
3 F C A M B H
4 F C M H
Transactions to p1
TID Items
1 F C A G D E K
2 FC M B P
3 F C A M B H
4 F C M H
Transactions to p2
TID Items
1 F C A G D E K
2 FC M B P
3 F C A M B H
Transactions to p3
(a)
(b)
Fig. 2. Example of the exchange stage of 4 processors.
K.-M. Yu, J. Zhou / Expert Systems with Applications xxx (2009) xxx–xxx 5
ARTICLE IN PRESS
Please cite this article in press as: Yu, K.-M., & Zhou, J. Parallel TID-based frequent pattern mining algorithm on a PC Cluster and grid computing system.
Expert Systems with Applications (2009), doi:10.1016/j.eswa.2009.07.072
shows that the algorithm saved on execution time compared to the
PFP-tree. Fig. 5 illustrates the execution time of various thresholds
showing that this algorithm reduced the execution time for differ-
ent given thresholds.
In order to further compare the TPFP- and PFP-tree,
SU2ðnÞ ¼ Execution time of 2 processorsExecution time of n processors was deﬁned. Table 4 shows the
comparisons of the two trees with a given threshold of 0.0005. It
can be seen that the ratio SU2 of the TPFP-tree was better than that
of the PFP-tree for all of the test cases. This means that the TPFP-
tree had better scalability than the PFP-tree with a different num-
ber of processors and different datasets. Moreover, it can be ob-
served that the speedup ratio SU2 improved with a larger
number of transactions.
0
100
200
300
400
500
600
2 4 6 8 10 12 14 16
Ti
m
e 
(S
ec
.)
Number of processors
Execution time (TPFP vs. PFP), threshold=0.0001
t10.i04.d200k.n100k 
(TPFP)
t10.i04.d200k.n100k 
(PFP)
t15.i04.d200k.n100k 
(TPFP)
t15.i04.d200k.n100k 
(PFP)
Fig. 4. Execution time (TPFP vs. PFP), threshold = 0.0001.
0
100
200
300
400
500
600
2 4 6 8 10 12 14 16
Ti
m
e 
(S
ec
.)
Number of processors
Execution time of various threshold, t15.i04.d200k.n100k
0.0001 (TPFP)
0.0001 (PFP)
0.0005 (TPFP)
0.0005 (PFP)
0.001 (TPFP)
0.001 (PFP)
Fig. 5. Execution time of various thresholds.
Table 4
Speed-up ratio (SU2) of TPFP and PFP.
Itemset Method Number of processors
2 4 6 8 10 12 14 16
t10.i04.d050k.n100k TPFP 1 1.67 2.53 3.04 3.88 4.07 4.62 4.62
PFP 1 1.53 2.12 2.7 3.3 3.59 3.95 4.16
t10.i04.d100k.n100k TPFP 1 1.87 2.7 3.47 4.31 5.11 6.33 6.79
PFP 1 1.53 2.12 2.7 3.3 3.59 3.95 4.16
t10.i04.d200k.n100k TPFP 1 1.94 2.94 3.87 4.89 6.23 7.3 8.41
PFP 1 1.62 2.2 2.95 3.61 4.21 5.25 5.61
t15.i04.d050k.n100k TPFP 1 1.6 2.29 2.98 3.55 4.12 4.66 5.39
PFP 1 1.47 2.02 2.52 3.1 3.59 4.14 4.73
t15.i04.d100k.n100k TPFP 1 1.72 2.48 3.22 4.19 4.82 5.83 6.66
PFP 1 1.47 2.02 2.59 3.37 4.08 4.8 5.43
t15.i04.d200k.n100k TPFP 1 1.93 2.81 3.76 4.9 5.98 7.11 8.24
PFP 1 1.5 2.14 2.83 3.59 4.44 5.29 6.35
t20.i04.d050k.n100k TPFP 1 1.57 2.12 2.65 3.22 3.71 4.28 4.86
PFP 1 1.38 1.87 2.32 2.88 3.23 3.79 4.43
t20.i04.d100k.n100k TPFP 1 1.59 2.22 2.78 3.41 3.97 4.74 5.25
PFP 1 1.41 1.9 2.44 2.92 3.57 4.13 4.62
t20.i04.d200k.n100k TPFP 1 1.62 2.27 2.96 3.67 4.42 5.14 5.91
PFP 1 1.4 1.93 2.5 3.06 3.69 4.46 5.02
Table 5
Hardware and software speciﬁcation of multi-cluster grid.
Cluster 1 Cluster 2 Cluster 3
Hardware speciﬁcation
Number of Nodes 5 5 3
CPU Pentium 4 3.2G AMD XP 2.0G Pentium 4 3.0G
Memory 512 MB 1024 MB 1024 MB
Network 100 Mbps interconnection network
Software conﬁguration
OS and compiler Linux 2.6
Gcc/G++ 4.03
Globus Toolkit 4.0
Message Passing Library MPICH-G2
MPICH2 1.0.5
mpi4py 0.5
0
10
20
30
40
50
60
70
80
90
3 6 9 13
Ti
m
e 
(S
ec
.)
Number of processors
Execution time (t20.i4.d050k.n100k, threshold=0.0003)
BTP
TPFP
PFP
Fig. 6. Execution time of different processors (d50k).
K.-M. Yu, J. Zhou / Expert Systems with Applications xxx (2009) xxx–xxx 7
ARTICLE IN PRESS
Please cite this article in press as: Yu, K.-M., & Zhou, J. Parallel TID-based frequent pattern mining algorithm on a PC Cluster and grid computing system.
Expert Systems with Applications (2009), doi:10.1016/j.eswa.2009.07.072
100k transactions, respectively. From the results of Fig. 6, it is clear
that BTP performed better than the TPFP and PFP regardless of how
many processors were assigned. Moreover, it can be seen that BTP
reduced about 20% and 58% on TPFP and PFP. Fig. 6 also shows that
BTP saved on execution time compared to TPFP and PFP.
Figs. 8 and 9 illustrate the execution time of various thresholds
with 50k and 100k transactions, respectively. This conﬁrmed that
BTP can efﬁciently reduce the execution related to TPFP and PFP.
Moreover, it can be seen that in a heterogeneous computing envi-
ronment (three types of CPU in this case) balancing the workload
can reduce the execution time.
Fig. 10 shows that BTP could balance the workload to save exe-
cution time. The experimental results showed BTP had better bal-
ancing capability and it could save about 25% and 66% on the
execution time needed with TPFP and PFP.
Table 6 shows the complete execution time for dataset
t10.i4.d050k.n100k, t10.i4.d100k.n100k, t20.i4.d050k.n100k, and
t20.i4.d100k.n100kwith threshold 0.0005, 0.0003, and 0.0001. Here
it can be seen that BTP-tree performed better than the TPFP-tree
and PFP-tree for all test cases. Moreover, the BTP-tree shortened
execution time with more processors with different thresholds
and datasets. Consequently, with a smaller threshold BTP per-
formed signiﬁcantly better than the others.
5. Conclusions
Mining frequent patterns from a transaction-oriented database
is important in data mining research. Many methods have been
proposed to solve this problem, and some of them have been
developed for a parallel-distributed computing system. However,
the execution time increases signiﬁcantly with an increase in data-
base size and a decrease in the given threshold. In this paper, two
parallel algorithms Tidset-based Parallel FP-tree (TPFP-tree) and
Balanced Tidset-based Parallel FP-tree (BTP-tree) were developed
to solve frequent pattern mining problems. TPFP-tree is based on
FP-tree data structure for a Cluster system, it exchanges necessary
information for mining before tree construction to improve the
performance. Moreover, it also uses a TID set to select transactions
directly instead of scanning the database repeatedly. Furthermore,
BTP-tree was proposed for solving mining problems on Grid sys-
tems. BTP-tree calculates the performance index (PI) of each com-
puting node, then dispatches mining items to a computing node
according to its PI. The experimental results show that TPFP-tree
performed better than PFP-tree on a Cluster system judged upon
a variety of computing nodes, database sizes or different given
thresholds. Additionally, the results also show that BTP-tree had
better load balancing ability and it performed better than TPFP-
and PFP-tree on a Grid system. Moreover, it also reduced both exe-
cution and idle time.
References
Agrawal, R., & Srikant, R. (1994). Fast algorithms for mining association rules in
large database. In Proceedings of the 20th international conference on very large
data base (pp. 487–499).
Almaden. Quest synthetic data generation code. <http://www.almaden.ibm.com/cs/
quest/syndata.html>.
Cannataro, M., Talia, D., & Trunﬁo, P. (2002). Distributed data mining on the grid.
Future Generation Computer Systems, 18(8), 1101–1112.
Chen, M.-C., Huang, C.-L., Chen, K.-Y., & Wu, H.-P. (2005). Aggregation of orders in
distribution centers using data mining. Expert System with Applications, 28(3),
453–460.
Ciglaric, M., Pancur, M., Ster, B., & Dobnikar, A. (2005). Data mining in grid
environment. Adaptive and Natural Computing Algorithm, 522–525.
Coenen, F., Leng, P., & Ahmed, S. (2004). Data structure for association rule mining:
T-trees and P-trees. IEEE Transactions on Knowledge and Data Engineering, 16(6),
774–778.
Foster, I., & Kesselman, C. (1998). The grid: blueprint for a new computing
infrastructure. Morgan Kaufmann.
Gorodetsky, V., Karasaeyv, O., & Samoilov, V. (2003). Multi-agent technology for
distributed data mining and classiﬁcation. In Proceedings of the IEEE/WIC
international conference on intelligent agent technology (pp. 438–441).
Han, J., Pei, J., Yin, Y., & Mao, R. (2004). Mining frequent patterns without candidate
generation: A frequent-pattern tree approach. Journal of Data Mining and
Knowledge Discovery, 8(1), 53–87.
Holt, J. D., & Chung, S. M. (2004). Parallel mining of association rules from text
databases on a cluster of workstations. In Proceedings of 18th international
symposium on parallel and distributed processing (pp. 86).
Hong, T.-P., Lin, C.-W., & Wu, Y.-L. (2008). Incrementally fast updated frequent
pattern trees next term. Expert System with Applications, 34(4), 2424–2435.
Javed, A., & Khokhar, A. (2004). Frequent pattern mining on message passing
multiprocessor systems. Distributed and Parallel Database, 16(3), 321–334.
Jiang, W.-S., & Yu, J.-H. (2005). Distributed data mining on the grid. In Proceedings of
the fourth international conference on machine learning and cybernetics (pp. 18–
21).
Lazcorreta, E., Botella, F., & Fernández-Caballero, A. (2008). Towards personalized
recommendation by two-step modiﬁed Apriori data mining algorithm. Expert
System with applications, 35(3), 1422–1429.
Li, T., Zhu, S., & Ogihara, M. (2003). A new distributed data mining model based on
similarity. In Symposium on applied computing (pp. 432–436).
Lin, C.-R., Lee, C.-H., Chen, M.-S., & Yu, P. S. (2002). Distributed data mining in a
chain store database of short transactions. In Conference on knowledge discovery
in data (pp. 576–581).
Lin, C.-W., Hong, T.-P., & Lu, W.-H. (2009). The Pre-FUFP algorithm for incremental
mining. Expert System with Applications, 36(5), 9498–9505.
Park, J. S., Chen, M.-S., Yu, P. S. (1995). An effective hash-based algorithm for mining
association rules. In Proceedings of the ACM SIGMOD (pp. 175–186).
Pramudiono, I., & Kitsuregawa, M. (2003). Shared nothing parallel execution of FP-
growth. DBSJ Letters, 2(1), 43–46.
Tang, P., & Turkia, M. P. (2006). Parallelizing frequent itemset mining with FP-Trees.
In Proceeding of the 21st international conference on computers and their
applications. (pp. 30–35).
Yan, X., Zhang, C., & Zhang, S. (2009). Genetic algorithm-based strategy for
identifying association rules without specifying actual minimum support.
Expert System with Applications, 36(2), 3066–3076.
Zhou, J., & Yu, K.-M. (2008). Tidset-based parallel FP-tree algorithm for the frequent
pattern mining problem on PC clusters. In Proceeding of 3rd international
conference on grid and pervasive computing (pp. 18–28).
K.-M. Yu, J. Zhou / Expert Systems with Applications xxx (2009) xxx–xxx 9
ARTICLE IN PRESS
Please cite this article in press as: Yu, K.-M., & Zhou, J. Parallel TID-based frequent pattern mining algorithm on a PC Cluster and grid computing system.
Expert Systems with Applications (2009), doi:10.1016/j.eswa.2009.07.072
 2
and engineering area, or in new application areas [13]. 
In this study, we want to reduce the computing time in 
inferring chemical compounds with path frequency. We 
developed a parallel computing method by modifying the 
algorithm published by Akutsu and Fukagawa[12]. The main 
concept is to assign independent tasks to different computing 
nodes expect for reducing computing time. 
The rest of this paper is organized as follows. Section II 
introduces the background about problem and definition. Next, 
we present our algorithm and description in section III. In 
section IV, we show the experiment results. Finally we 
conclude this paper in section VI. 
 
2. Related Work 
 
2.1 The BB-CIPF algorithm 
 
Terms of compound characteristics such as Frequency of 
labeled paths [8, 9] or frequency of small fragments [4, 5] are 
used by some researchers to classify compound. Extending 
from inferring a tree from walks [14] or graphic reconstruction 
problem [15], Kernel Principal Component Analysis and 
Regression [4] and stochastic search algorithms [5] are used to 
find pre-images. However, in previous cases, the obtained 
results and performance of these algorithms were not 
thoroughly verifies against more complex compound cases. 
 
Figure 1 shows that giving a target x to find φ(x) with kernel 
method and then inferring the compound. Inferring a chemical 
structure from a feature vector based on frequency of 
labeled-paths and small fragments, Branch-and-Bound 
Chemical compound Inference from Path Frequency 
(BB-CIPF) [12] is used to infer chemical compounds of 
tree-like structures. BB-CIPF algorithm extends from [10, 11]. 
BB-CIPF uses tree-like structures and infers chemical 
compound. Chemical compounds are assigned with a feature 
vector by the algorithm based on frequency of small fragments. 
Moderate size chemical compounds are inferred. 
 
Figure 1: Inferring a Chemical Structure from a Feature 
Vector 
The pre-image problem was defined as follows. Let  be
an alphabet and Kbe the set of strings with length K
over .Fora string tandagraphG,occ(t,G)denotes
thenumber ofoccurrencesofsubstringt inG.Then,the
feature vector fK (G) of level K for G is a
— K—-dimensional integer vector such that the
coordinateindexedbyt∈ Kisocc(t,G).Thatis,fK(G)
is defined by fK (G) = (occ(t, G))t∈ΣK. For example, 
consider a compound C2H4O2 (see figure2) over Σ = {C, O, H} 
and the K value is 1. Then, fK (G) = (2,2,4,2,2,3,2,0,1,3,1,0) 
because occ(C,G) = 2, occ(O,G) = 2, occ(H,G) = 4, occ(CC,G) 
= 2, occ(CO,G) = 2, and so on. If K is large, the number of 
dimensions of a feature vector will be large (exponential of K). 

C O H CO CH OC OO OH HC HO HH
2 2 4 2 3 2 0 1 3 1 0
Figure 2: An illustration of a multitree G and its feature 
vector 
 
Give a target compound Ttarget and Tcur is inferred to Ttarget. 
Tcur insert a node n becoming Tnext. ftarget is the feature vector of 
Ttarget and fnext is the feature vector of Tnext. After inserting a 
node compare Ttarget and Tnext. If the feature vector fnext of Tnext 
does not match with the feature vector ftarget of Ttarget, the Tnext 
will be discarded and Tnext will not continue to carry out the 
evolution of Tnext. Tcur may be re-inserted into another node for 
comparison with Ttarget. 
The concept of branch-and-bound chemical compound 
inference from path frequency algorithm is inferring tree-like 
structures of chemical compounds. Back tracking a full scheme 
of all of the possible pre-images, regardless of their difference 
in molecular structure, if they shared with the same feature 
vector to come close to the reality of the development of 
algorithms for drug design. 
The BB-CIPF algorithm will track back pre-images as the 
solution of partial results. For example, giving a target 
compound, if there are three objects having the same feature 
vector, then those are the partial results. 
Our method is based on BB-CIPF. We will find all possible 
compounds with same feature vector. To reduce the computing 
time, the method we proposed used MPI to solve the chemical 
compound inference problem.  
 
2.2 Message Passing Interface 
 
Message Passing Interface has already used in solving 
chemistry problems [16]. MPI (Message Passing Interface) is a 
specification for a standard library for message passing that was 
defined by the MPI Forum, a broadly based group of parallel 
computer vendors, library writers, and applications specialists. 
Multiple implementations of MPI have been developed [17]. 
The message-passing model of parallel computation has 
emerged as an expressive, efficient, and well-understood 
paradigm for parallel programming. Until recently, the syntax 
and precise semantics of each message-passing library 
implementation were different from the others, although many 
of the general semantics were similar. The proliferation of 
message-passing library designs from both vendors and users 
was appropriate for a while, but eventually it was seen that 
 4
 
Figure5: An example of BFS stage of PB-CIPF 
 
After the tasks were assigned by the master computing node, 
each slave computing node used Depth-First-Search (DFS) 
approach to insert an atom into a candidate compound. After 
inserted an atom, the candidate compound will be compared 
feature vector with target compound. If the feature vector of 
candidate compound and target compound has the same feature 
vector with parts of target compound structure, then the atom 
will be kept. If the candidate feature vector is different from 
target compound structure, then the atom will be dropped and 
continue to apply DFS approach to insert another atom into the 
candidate compound. If the candidate compounds have the 
same feature vector with the target structure, then it got a 
solution. Do the same thing until all nodes completed its 
candidate compounds. Figure 6 shows the idea of this stage. 
 
 
Figure 6: An example of DFS stage of PB-CIPF 
3.1 The procedure of PB-CIPF 
 
The pseudo code of PB-CIPF is shown below; the 
implemented code has more details and will be presented later. 
 
Procedure PB-CIPF(Ttempi, ftempi, Ttarget, ftarget) 
GET processors numbers:n 
Let first computing node = master computing node 
 
Master computing node: 
step 1: Produce candidate compounds. Run BFS (Ttarget). 
Store all candidate compounds computed in Tqueue 
which is a queue that stores all candidate 
compounds. 
 
 The procedure of BFS is shown below: 
 Procedure BFS (Ttarget): 
      for (a = all atoms exist in Ttarget ) do  
Let Ttemp be a temporary candidate compound  
Initial Ttemp  
Insert a as a new node into Ttemp 
Add Ttemp to Tqueue 
Process the next atom in Ttarget 
end 
step 2: Gather candidate compounds as tasks. Block tasks 
by computing nodes number.  
step 3: For each block of tasks will be assigned to slave 
computing node. 
 
 
Slave computing node: 
step 1: Receive tasks. 
step 2: Run DFS approach. 
The procedure of DFS is shown below:  
      Procedure DFS(Ttempi, ftempi, Ttarget, ftarget) 
if ftempi = ftarget  
then output a solution Ttempi; 
return true; 
else return false; 
for (a = all atoms exist in Ttarget )do 
if atom = H continue; 
(Hydrogen atoms will be added at the last 
stage) 
if {l(u)|u V(Ttemp) ∪ {a} atomset(fterget) 
(set means multiset here) 
then continue; 
for all w ∈ V(Ttemp) do 
Let Tnext be a tree got by connecting new 
leaf node u  
if w does not satisfy the valence constraint  
then continue; 
Compute fnext from Tnext and ftemp; 
if DFS(Tnext, fnext, Ttarget, ftarget)=true  
then return true; 
end 
end 
return false; 
step 3: Send result to a queue stored all matched result.  
step 4: If still needed to process go to step 2. Else end. 
 6
 
When the K = 1 and size of atoms is bigger than 19, the 
solution space is larger, so it needs more computing time to 
finish. We use several compounds with different size of atoms 
to verify the performance of our algorithm. To look over 
performance of our algorithm, we compute the speedup ratio of 
each testing case. The speedup ratio is defined as follows: 
If the computing time of single node is t0 and the computing 
time of 2 nodes is t1. Then the speedup ratio of 2 computing 
nodes will be t0 / t1. 
Figure12 and 13 show the speedup of our algorithm. 
Increasing the computing nodes to 4 nodes, we can find out that 
the average speedup ratio is about 1.9. According to our 
experiment, it verified that our proposed algorithm can reduce 
the computing time. 
 
 
Figure 12: Speedup ratio of 2 nodes 
 
 
Figure 13: Speedup ratio of 4 nodes 
5.  Conclusion 
 
In this paper, we proposed a parallel algorithm for the 
problem of chemical compound inference from path frequency. 
Our approach has two stages. First, a master node will build 
several candidate compounds using BFS approach. Then 
distribute the candidate compounds to participated computing 
nodes according to block distribution.  Then each computing 
node will infer the c’=φ (g) using a DFS approach. The BFS 
and DFS adopted branch-and-bound approach. The 
experimental results show that our algorithm can reduce the 
computing time. When using 4 nodes to compute, the average 
speedup is 1.820136 when K=1, 1.891199 when K=2, 1.954588 
when K=3 and 1.995495 when K=4.  
 
References 
[1] C. J. Harris, A. P. Stevens, ”Chemogenomics: structuring the drug 
discovery process to gene families”, Drug Discov Today11, 2006, 
880-888. 
[2] C. Cortes, V. Vapnik, “Support vector networks”. Machine Learning 20, 
2005, 273-297. 
[3] N. Cristianini, J. Shawe-Taylor, An Introduction to Support Vector 
Machines and Other Kernel-based Learning Methods, Cambridge Univ. 
Press, 2000. 
[4] E. Byvatov, U. Fechner, J. Sadowski, and G. Schneider, “Comparison of 
support vector machine and artificial neural network systems for 
drug/nondrug classification” Journal of Chemical Information and 
Computer Sciences 43, 2003, 1882–1889. 
[5] M. Deshpande, M. Kuramochi, N. Wale, and G. Karypis, ” Frequent 
substructure-based approaches for classifying chemical compounds”, 
IEEE Trans. Knowledge and Data Engineering17, 2005, 1036–1050. 
[6] A. Ben-Hur, W. Noble, "Kernel methods for predicting protein-protein 
interactions," Bioinformatics, vol. 21, 2005, 38-46. 
[7] C. J. C. Burges, "A Tutorial on Support Vector Machines for Pattern 
Recognition” Data Mining and Knowledge Discovery, vol. 2, 1998, 
121-167. 
[8] H. Kashima, K. Tsuda, and A. Inokuchi, ” Marginalized kernels between 
labeled graphs.” Machine Learning 20, 2005, 321–328. 
[9] P. Mahé, N. Ueda, T. Akutsu, J.-L. Perret, and J.-P. Vert, ” Graph kernels 
for molecular structure-activity relationship analysis with support vector 
machines”, Journal of Chemical Information and Modeling 45, 2005, 
939–951. 
[10] T. Akutsu, D. Fukagawa, “Inferring a graph from path frequency”, 
Combinatorial Pattern Matching 16, Volume 2527 of Lecture Notes in 
Computer Science, 2005, 371-392. 
[11] T. Akutsu, D. Fukagawa, “On inference of a chemical structure from path 
frequency”, BIOINFO, 2005. 
[12] T. Akutsu, D. Fukagawa,” Inferring a Chemical Structure from a Feature 
Vector Based on Frequency of Labeled Paths and Small Fragments”, 
Asia-Pacific bioinformatics conference 5th, 2007, 165-174. 
[13] D. B. Skillicorn, D. Talia, ” Models and Languages for Parallel 
Computation”, ACM Computing Surveys Vol. 30 No. 2, 1998, 123-169. 
[14] O. Maruyama, S. Miyano, “Inferring a tree from walks” Theoretical 
Computer Science 161, 1996, 289–300. 
[15] J. Lauri, R. Scapellato, Topics in Graph Automorphisms and 
Reconstruction, Cambridge Univ. Press, 2003. 
[16] J. J. Vincent, K. M. M. Jr, “A highly portable parallel implementation of 
AMBER4 using the message passing interface standard”, Journal of 
Computational Chemistry Volume 16 Issue 11, 1995, 1420-1427. 
[17] W. Gropp, E. Lusk, N. Doss, and A. Skjellum , “A high-performance, 
portable implementation of the MPI message passing interface standard” , 
Parallel Computing 22, 1996, 789-828. 
[18] G. H. Bakimathr, A. Zien, and K. Tsuda, “Learning to find graph 
pre-images “, The 26th DAGM Symposium, Volume 3175 of Lecture 
Notes in Computer Science, 2004, 253-261. 
dimensional feature space. Recently, it has also been applied to the classification of 
chemical compounds [4, 5, 6, 7]. In these approaches, chemical compounds are 
mapped to feature vectors and then SVMs [9, 10] are employed to learn the rules for 
classifying these feature vectors. Several mapping methods for feature vectors have 
been proposed; among them, the mapping of feature vectors based on the frequency of 
labeled paths [6, 7] or the frequency of small fragments in chemical compounds [4, 5] 
are widely used. 
In kernel methods, an object in the input space can be mapped into a point (or 
feature vector) in a space called feature space. Through a suitable function ∅, a given 
point y in the feature space can be mapped back into an object in the input space. 
Such object is called pre-image. The problem exists when mapping a given y in 
feature space back into an object in the input space such that y=∅(x) is satisfied, as x 
may not exist. 
In [1], a feature vector g is a multiple set of strings of labels with length at most K 
which represents path frequency. Given a feature vector g, they considered the 
problem of finding a vertex-labeled graph G that attains a one-to-one correspondence 
between g and the set of sequences of labels along all paths of length at most K in G. 
In previous works [1, 2], a graph can be inferred from the numbers of occurrences 
of vertex-labeled paths. In [1], they showed that this problem can be solved in 
polynomial time of the size of an output graph if graphs are trees of bounded degree 
and the lengths of given paths are bounded, by a constant, whereas this problem is 
strongly NP-hard even for planar graphs of bounded degree. 
In this study, we have taken into account the situation when chemical compounds 
become increasingly complex, the computation time required to infer pre-images from 
the feature vectors of these compounds increase at a much faster rate. We resort to 
parallel computing, in which the computation tasks are assigned to multiple cores 
appropriately to reduce the overall computation time. We extend the algorithms in [3], 
and therefore the modified algorithms can support multi-core processing technology. 
The rest of this paper is organized as follows. Section 2 introduces the background 
about problem and definition. Next we describe our proposed algorithms in section 3. 
In section 4, we show the experimental result. Finally we conclude this paper in 
section 5. 
2   Related Work 
For classification of the characteristics of chemical compounds to work, chemical 
compounds are often mapped into feature vectors. Several methods for converting 
chemical compounds into feature vectors have been proposed. Among them, methods 
such as frequency of labeled paths [6, 7] or frequency of small fragments [4, 5] are 
popular. Recently, the pre-image methods have been proposed. In [4], pre-images 
were found in a general setting by using Kernel Principal Component Analysis and 
regression. In [8], stochastic search algorithm is used to find pre-images for graphs. 
However, these pre-image methods are not derived from a computational viewpoint. 
In this paper, we extend the inference algorithm [3] to obtaining all possible 
compounds that are mapped back from the same feature vector but differ in their 
molecular structures. We used the Branch-and-Bound concept to derive the trees or 
tree-like structures of chemical compounds. Our algorithm is committed to obtain all 
possible compounds that can be inferred from the same feature vector but differ in 
their molecular structures. We develop our algorithm based upon the algorithm in [3] 
so that the computation process will not terminate on the first obtained solution, but 
will continue to search for all possible solutions. However, in order to output more 
chemical compounds, it also means that the algorithm will consume more 
computation time. Therefore, we also propose adopting the multi-core computing 
technology to reduce the computation time in our proposed algorithm. We hope that 
by providing more thorough and practical solutions to the inference problem, we can 
improve on the development of drug design. 
3   Multi-Core Chemical Compound Inference from Path 
Frequency (MC-CIPF) 
In the previous section, we have described that when a compound structure is more 
complex, it will require more computation time for inference of its solutions. That is 
to say, if the feature vector v in feature space has been mapped from a compound c 
thought a function ∅, and we want to find c’ where c’= ∅(v). If a compound is more 
complex in structure, its feature vector in feature space is also more complex, and it 
will require substantially more computation time to map back to c’ from v. Therefore, 
in this paper, we divide computation tasks into several smaller tasks and distribute 
these tasks appropriately among several processing cores for computation. We 
propose the Multi-Core Chemical Compound Inference from Path Frequency (MC-
CIPF) to obtain all possible compounds. 
 
Fig. 1. Each job is initiated based on the atoms that existed in the target compound. 
kept; otherwise, the inserted atom will be dropped, and the algorithm continues on 
applying DFS to insert the next atom in queue into the candidate compound. If the 
resulted structure of the candidate compounds is in line with the target structure, it is 
output as one of the solution. The algorithm iterates until all cores have completed all 
candidate compounds in their queues. 
Procedure BFS (Ttarge) 
  Let Tqueue be a queue that stores all candidate compounds; 
  for all a ∈ all atoms exist in Ttarget do 
    Let Ttemp be a temporary compound 
    Ttemp ← ∅ ; 
    Insert a into Ttemp; 
    if Ttemp ∈ Ttarget then 
      Add Ttemp to Tqueue; 
    else 
      continue (examine the next atom in Ttarget); 
    end 
  end 
  while Tqueue is not empty do 
    for each core compute a compound from Tqueue per time do 
      Compute feature vector ftempi from Ttempi in Tqueue; 
      if MC-CIPF(Ttempi, ftempi, Ttarget, ftarget)=false then 
        output “no solution”; 
      end 
    end 
Procedure MC-CIPF(Ttempi, ftempi, Ttarget, ftarget) 
  if ftempi = ftarget then output Ttempi; 
    popup Ttempi from Ttemp; 
    return true; 
  else  
    return false; 
  for all a ∈ all atoms exist in Ttarget do 
    L ← ∅ ; 
    if { L(u)|u ∈ V(Ttemp)} ∪ {a} ⊈ atomset(ftarget) then 
      continue; 
    for all w ∈ V(Ttemp) do 
      Let Tnext be a tree gotten by connecting new leaf u with 
label a to w by bond b; 
      if w does not satisfy the valence constraint then 
        continue; 
      Compute fnext from Tnext and ftemp; 
      if MC-CIPF(Tnext, fnext, Ttarget, ftarget)=true then 
        return true; 
      end 
    end 
  return false; 
In the experiment, we randomly chosen 5 chemical compounds (C00097, C00497, 
C11109, C14601, and C15987; the number of atoms of compound size with hydrogen 
are 14, 15, 16, 15 and 19, respectively) from KEGG LIGAND Database and 
examined them with K = 1, 2, 3, 4, where K is the length of sequence label of feature 
vectors in MC-CIPF. Larger K means more constraints for target compound, which 
leads to less variation for its molecular structure. Fig. 3(a)-(e) are the computing time 
for each chemical compound. In each case, we have found that the computing time 
was reduced as the number of cores was increased. For example, in Fig. 3(c), when K 
was equal to 4, the computing time was reduced from 11.9337 second with 1 core to 
5.542821 second with 4 cores.  
 
 
Fig. 3(c). Computing time of C11109. 
 
Table 1. Computing time of MC-CIPF for various chemical compounds. 
Instances Cores detail CPU time (sec.) 
   K=1 K=2 K=3 K=4 
C00097 1 Core  4.27 0.96 1.49 3.71 
2 Cores Core 1 2.99 0.26 1.17 2.81 
 Core 2 3.00 0.72 1.17 2.81 
 Max 3.00 0.72 1.17 2.81 
4 Cores Core 1 2.91 0.20 0.72 1.56 
  Core 2 2.67 0.36 0.46 0.98 
  Core 3 0.77 0.35 0.50 0.97 
  Core 4 2.91 0.51 0.72 1.56 
  Max 2.91 0.51 0.72 1.56 
C00497 1 Core  75.44 31.95 47.23 131.42 
 2 Cores Core 1 28.82 8.78 31.26 35.33 
  Core 2 54.10 25.12 31.27 88.09 
  Max 54.10 25.12 31.27 88.09 
 4 Cores Core 1 13.76 3.93 24.43 11.05 
  Core 2 31.23 7.77 12.25 28.88 
  Core 3 12.47 7.88 12.26 30.69 
  Core 4 56.14 21.67 24.43 64.10 
  Max 56.14 21.67 24.43 64.10 
C11109 1 Core  6.88 5.42 5.63 11.93 
 2 Cores Core 1 5.47 3.59 3.55 6.73 
  Core 2 5.48 3.59 3.56 6.73 
  Max 5.48 3.59 3.561 6.73 
 4 Cores Core 1 5.13 3.18 2.90 5.53 
  Core 2 1.83 2.06 1.91 3.53 
  Core 3 2.48 2.05 1.18 1.93 
  Core 4 5.13 3.18 2.90 5.54 
  Max 5.13 3.18 2.90 5.54 
C14601 1 Core  0.72 0.57 1.02 2.02 
 2 Cores Core 1 0.62 0.40 0.51 0.83 
  Core 2 0.62 0.40 0.55 1.16 
  Total 0.62 0.40 0.55 1.16 
 4 Cores Core 1 0.54 0.27 0.40 0.37 
  Core 2 0.13 0.23 0.38 0.55 
  Core 3 0.21 0.25 0.40 0.68 
 Fig. 4(b). Speedup ratio of C00497. 
 
 
Fig. 4(c). Speedup ratio of C11109. 
 
time, with the best speedup ratio close to 3 folds while using 4 cores in the 
experiment. Therefore, our proposed algorithm can infer chemical compounds from 
path frequency effectively and reduce computation time by employing the multi-core 
technology. 
References 
1. Tatsuya, A., Daiji, F.: Inferring a graph from path frequency, In Proc. 16th Symp. 
Combinatorial Pattern Matching. Lecture Notes in Computer Science, Springer. 2527, 371--
392 (2005) 
2. Tatsuya, A., Daiji, F.: On inference of a chemical structure from path frequency. Proc. 2005 
International Joint Conference of InCoB, AASBi, and KSBI, pp. 96--100 (2005). 
3. Tatsuya, A., Daiji, F.: Inferring a Chemical Structure from a Feature Vector Based on 
Frequency of Labeled Paths and Small Fragments. APBC, pp. 165--174 (2007) 
4. Byvatov, E., Fechner, U., Sadowski, J., Schneider, G.: Comparison of support vector 
machine and artiﬁcial neural network systems for drug/nondrug classiﬁcation. Journal of 
Chemical Information and Computer Sciences. 43, 1882--1889 (2003) 
5. Deshpande, M., Kuramochi, M., Wale, N., Karypis, G.: Frequent substructure-based 
approaches for classifying chemical compounds. IEEE Trans. Knowledge and Data 
Engineering. 17, 1036--1050 (2005) 
6. Kashima, H., Tsuda, K., Inokuchi, A.: Marginalized kernels between labeled graphs. In 
Proc. 20th Int. Conf. Machine Learning, pp. 321--328 (2003) 
7. Mahé, P., Ueda, N., Tatsuya, A., Perret, J-L., Vert, J-P.: Graph kernels for molecular 
structure-activity relationship analysis with support vector machines. Journal of Chemical 
Information and Modeling. 45, 939--951 (2005) 
8. Bakir, G.H., Zien, A., Tsuda, K.: Learning to find graph pre-images. In Proc. The 26th 
DAGM Symposium. Lecture Notes in Computer Science, Springer. 3175, 253--261 (2004) 
9. Cortes, C., Vapnik, V.: Support vector networks. Machine Learning. 20, 273--297 (1995) 
10. Cristianini, N., Shawe-Taylor, J.: An Introduction to Support Vector Machines and Other 
Kernel-based Learning Methods. Cambridge Univ. Press (2000) 
11. Almasi, G.S. and A. Gottlieb. Highly Parallel Computing. Benjamin-Cummings publishers, 
Redwood City, CA. (1989) 
12. Maruyama, O., Miyano, S.: Inferring a tree from walks. Theoretical Computer Science. 161, 
289--300 (1996) 
13. Lauri, J., Scapellato, R.: Topics in Graph Automorphisms and Reconstruction. Cambridge 
Univ. Press (2003) 
 一、 參加會議經過 
會議的開幕典禮由大會主席致簡單的歡迎詞，並由會議的委員會主席說明本屆的投
稿與錄取篇數及本屆會議的特色與會議重點後，隨即展開，本屆會議分別於第一天及第
二天的會議議程中各安排了五、六個場次之粒度計算與生物資料處理暨應用領域之最新
趨勢之專題報告 : (1). Intelligence and Language How Could Human Being Have 
Language?, (2). What is Granular Computing?: Highlights and Fallacies, (3). Security and 
Integrity in Outsourcing of Data Mining, (4). Cloud Computing, (5). Cloud Computing Panel 
(6). Challenges Techniques for Mining Real Clonical Data, (7). Granular Computing:Based 
on Fuzzy and Tolerance Relation, (8). Granular Computing: Toward inner logic in decision 
systems,  (9). Mechanism Approach to the Research of Atificial Intelligence, (10). 
Nonstructure Information Retrieval Tolerant Granular Space Model, 以及(11). Clustering 
Algorithms with Automatic Selection of Cluster Number，分別由 Setsuo Ohsuga、Tsau 
Young Lin、 David Wai-lok. Cheung、Dennis Quan、 Meng Ye、 Wesley W. Chu、Bo Zhang 
and Ling Zhang、 Lech Polkowski、Yixin Zhong、ZhongZhi Shi 以及 Michel Ng 作精彩
的專題報告。正式之論文報告分別於專題報告後進行，本人之論文『A Weighted 
Load-Balancing Parallel Apriori Algorithm for Association Rule Mining』被安排在第二天
的 –“Intelligent Data Analysis and Applications”之場次發表。 
二、 與會心得 
  GrC 2008 是一個在粒度計算(Granular computing)研究領域中具有指標性的最重
要國際會議，此次會議共有近四百篇的論文投稿，但僅錄取了一百七十餘篇優秀的粒度
計算資訊系統領域的論文，由會議的進行過程中可以看出主辦單位對會議的流程安排相
當用心，参與此次會議之篇學者可藉著此次會議，在粒度計算資訊系統與生物資訊運用
之各研究領域互相作深入的討論，而且可藉此機會認識在此領域中之權威研究學者，對
於此後從事此領域之研究有相當之助益。 
A Weighted Load-Balancing Parallel Apriori Algorithm  
for Association Rule Mining 
 
 
Kun-Ming Yu1, Jia-Ling Zhou2 
1Department of Computer Science and Information Engineering, Chung Hua University 
2Department of Information Management, Chung Hua University 
1yu@ chu.edu.tw, 2jlzhou@pdlab.csie.chu.edu.tw 
 
 
Abstract 
 
Because of the exponential growth in worldwide 
information, companies have to deal with an ever 
growing amount of digital information. One of the 
most important challenges for data mining is quickly 
and correctly finding the relationship between data. 
The Apriori algorithm is the most popular technique in 
association rules mining; however, when applying this 
method, a database has to be scanned many times and 
many candidate itemsets are generated. Parallel 
computing is an effective strategy for accelerating the 
mining process. In this paper, the Weighted 
Distributed Parallel Apriori algorithm (WDPA) is 
presented as a solution to this problem. In the 
proposed method, metadata are stored in TID forms, 
thus only a single scan to the database is needed. The 
TID counts are also taken into consideration, and 
therefore better load-balancing as well as reducing 
idle time for processors can be achieved. According to 
the experimental results, WDPA outperforms other 
algorithms while having lower minimum support. 
 
1. Introduction 
 
With the rapid development of information 
technology, companies have been working on 
digitizing all areas of business to improve efficiency 
and thus competitiveness.  However, the consequences 
of full-digitization are that tremendous amounts of 
data are generated. It is important to extract 
meaningful information from scattered data, and data 
mining techniques are developed for that purpose. 
There are many techniques being used for data mining, 
for example, Classification, Regression, Time Series, 
Clustering, Association Rules and Sequence. 
Association rule [1, 2] is one of the most useful 
techniques in data mining. Generally, it takes long to 
find the association rules between datasets when a 
database contains a large number of transactions. By 
applying parallel-distributed data mining techniques, 
the mining process can be effectively speeded up. 
With parallel-distributed data mining the calculation is 
done in a distributed environment [3, 7, 8, 9, 12], but 
most of the time, irregular and imbalanced 
computation loads are allocated between processors 
and thus the overall performance is degraded.  
In this paper the Weighted Distributed Parallel 
Apriori algorithm (WDPA) is presented as a solution 
for this problem. In the proposed method, a database 
has only to be scanned once because metadata are 
stored in TID tables. This approach also takes the TID 
count into consideration. Therefore, WDPA improves 
load-balancing as well as reduces idle time of 
processors. 
The experimental results in this study showed that 
the running time of WDPA was significantly faster 
than that of previous methods. In some cases, WDPA 
only used about 2% of the time used in previous 
methods. This can be achieved because WDPA 
successfully reduced the number of scan iterations to 
databases and was able to evenly distribute workloads 
among processors.  
The paper is organized as follows: In section 2, 
association rule and parallel distributed algorithms are 
explained. The WDPA algorithm is proposed in 
section 3. Section 4 gives the experimental results. 
Finally, the conclusion is given in section 5. 
 
2. Related Work 
 
Frequent pattern mining problem is defined as 
follows. Let DB = {T1, T2, …, Tk} be a database of 
transactions, where each transaction Te consists of  I, I 
= {i1, i2, …, im} be a set of all items. Assuming A, B 
are itemsets, A, B ⊆ I, A ∩ B=∅, A→B denotes there 
is an association rule between A and B. Each 
association rule has support and confidence to confirm 
the validity of the rule. Support denotes the occurrence 
rate of an itemset in a DB. Confidence denotes the 
Ii. Equation (4) represents the total weight value of k-
itemsets. 
∑ −
+=
−
×=
1)(
1
1
)()()(_
k
TIDTID
freqlen
ij
jii IlenIlenIWeightTidValue
 (3) 
∑ ∑−
=
−
+=
= −
×=
1)(
0
1)(
1
1 1
)()(
_
k k
TIDTID
freqlen
i
freqlen
ij
ji IlenIlen
WeightTidTotalValue
 (4) 
There are two methods of partitioning weighted 
TID, the Block_WeightTid(BWT) partitions and 
distributes TID by block, the Cyclic_WeightTid(CWT) 
partitions and distributes TID in cyclic. 
 
An example of the algorithms is given below: 
For step1 and step2, P1 (MP), P2 (SP) read and scan 
database, then build level-1 candidate itemsets. (Figure 
3) 
 
Figure 3. Scan database and creating TID forms 
 
Figure 4 shows that P1 collects itemsets that match 
given support into frequent 1-itemsets, then uses CWT 
to calculate and distribute the itemsets on P1. P1: {C, 
B}, P2: {A, F, L, M, O}. (Step 3 and Step 4) 
 
Figure 4. Distributing frequent 1-itemsets on P1 
 
Figure 5 describes P1 and P2 combining level-2 
candidate itemsets and calculating itemset counts 
according to the TID table. Figure 6 represents level-2 
candidate itemset counts on P1 and P2. (Take level-2 
candidate A and C for example, the intersection of A 
and C on TID, [1, 5], is the resulting set, AC) (Step 5 
and Step 6) 
 
 
Figure 5. Itemsets are calculated by counting the 
TID forms 
 
 
Figure 6. P1 and P2 level-2 candidate itemsets 
 
Select the itemsets that match the given support 
value, and save them as frequent 2-itemsets. Because 
the frequent 1-itemsets are larger, candidate itemsets 
that required combination computation will be larger, 
too. In this case, distributing the itemsets in Cyclic will 
produce better results. On the other hand, if there are 
frequent itemsets above level 1, candidate itemsets that 
required combination computation will be smaller, too. 
In this case, distributing the itemsets in Block will 
produce better results. 
P1 receives P2 itemsets, and repeats execution step 4 
to step 9 until there are no more frequent itemsets. 
Figure 7 illustrates the use of BWT to calculate and 
distribute the itemsets on P1. P1: {BC, AC}, P2: {AO, 
AP, CP}. (Step 3 and step 4) 
Figure 8 represents P1 combined level-3 candidate 
itemsets matching given support value into frequent 3-
itemset. 
 
 
Figure 9. Speedup of Four partition Methods of 
WDPA (T10I4D100KN100K, minsup: 0.2%) 
 
Figure 10. Each Processors Execution Time 
(T10I4D50KN100K, minsup: 0.2%) 
 
Figure 11 and 12 show the execution time and 
speedup under different given supports. Ye’s 
algorithm requires that a database being re-scanned for 
every itemset to be counted during the mining process, 
so when there is lower support, Ye’s algorithm takes 
longer to re-scan the database. On the other hand, 
using the TID table with precise distribution of 
itemsets, the WDPA scans the database once only. 
This greatly reduced the time spent on database 
scanning and balanced the computation workload 
among processors. Thus, there is an obvious 
performance advantage of the WDPA algorithm over 
Ye’s algorithm. 
Figures 13 and 14 give the execution time and 
speed up with different databases. With the increased 
size of the database, the length of the TID of itemsets 
in the table will increase. Therefore, when the size of 
the database increased, the execution took longer. 
Moreover, by parallel-distributing the processing, 
large databases can be more effectively mined and 
itemsets will be allocated to different processors to 
perform the calculation, this significantly speeding up 
the mining process. 
 
Figure 11. Execution Time (WDPA vs. Ye’s 
algorithm )(T10I4D100KN100K, minsup: 0.2%) 
 
Figure 12. Execution Time (WDPA vs. Ye’s 
algorithm )(T10I4D100KN100K, minsup: 0.3%) 
 
Figure 13. WDPA Execution Time, minsup: 0.15% 
 
