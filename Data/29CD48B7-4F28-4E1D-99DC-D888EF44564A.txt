 2
行政院國家科學委員會專題研究計畫成果報告 
FARMA 模型辨証與模糊模型控制器設計 
Fuzzy Auto-Regressive Moving Average (FARMA) Modeling and 
the Fuzzy Model Based Controller Design 
計畫編號：NSC 96-2221-E-036-033-MY2 
執行期限：96 年 08 月 01 日至 98 年 07 月 31 日 
主持人：龔宗鈞  大同大學電機系所 
(e-mail:cckung@ttu.edu.tw) 
計畫參與人員：研究生 蘇瑞堯 張碩傑 聶怡芬  大同大學電研所 
 
一、中文摘要 
本計畫提出「FARMA 模型辨証與模
糊模型控制器設計」之方法。第一年的
研究成果已完成適用於 FARMA 模型的
群集驗證準則以幫助 FCRM分類演算法
選擇出最精簡的群集數目，並對此群集
驗證準則進行極限分析(limit analysis)，
以研究該群集驗證準則之可靠度。第二
年的研究成果，吾人應用群集驗證準則
決定 FARMA 模型的模糊規則庫(fuzzy 
rule base)數目，並計算出 FARMA 模型
的前件部參數與後件部參數。更進一步
提出系統化的步驟說明，以辨証出受控
系統的 FARMA 模型。為使模型盡可能
地仿製原本的受控系統，吾人擬提出參
數修正方法以達成模型誤差小的目標。
最後吾人根據受控系統之 FARMA 模型
設計一模糊模型控制器以克服最小近似
誤差所導致的不穩定因素，達成控制目
標。 
關鍵詞：FCRM 分類演算法，FARMA 模
型，群集驗證準則，模糊模型控制器 
Abstract 
In this project, the “fuzzy 
auto-regressive moving average (FARMA) 
modeling algorithm and the fuzzy model 
based controller design” is proposed. In the 
first year, we proposed a new cluster 
validity criterion suitable for the fuzzy 
c-regression model (FCRM) clustering 
algorithm for choosing the optimal number 
of clusters for FARMA model, and took the 
limit analysis on it to study its behavior as 
the weighting exponent +→1m  and 
∞→m . In the second year, we focused our 
attention on the FARMA modeling 
algorithm and the design of fuzzy model 
based controller (FMBC). We proposed a 
FMBC design scheme for the nonlinear 
plant based on the obtained FARMA model. 
It is seen that the proposed FMBC can 
overcome the instability due to the minimum 
approximation error. 
Keywords: FCRM clustering algorithm; 
Fuzzy auto-regressive moving average 
(FARMA) model; cluster validity criterion; 
fuzzy model based controller (FMBC)  
 
二、緣由與目的 
1. T-S [1]形式之 FARMA 模型[9,10]相較
於其他的模糊模型，T-S 模糊模型具有以
下優點：(a)以 T-S 模糊模型描述一個非線
性系統所需要的規則(rule)數目往往較其
他形式的模糊模型所需的規則數目少。這
是由於它的後件部相對地較具有數學意
義，因此可以有效地減少模糊規則的數
目。 (b)T-S 模糊模型具有片段線性
(piece-wise linear)的結構使得模糊控制與
傳統線性控制之間有了共通之特性，因此
許多線性系統的分析工具與理論便能夠用
來描述與分析 T-S 模糊模型並基於此模型
設計控制器。因此吾人選用 T-S 型式之
FARMA 模型作為描述未知受控系統的數
學模型。 
2. 近來有很多學者提出模糊分群演算法
(fuzzy clustering algorithm)[2-5]理論以處
理複雜系統辨証上的問題。其中，Fuzzy 
c-means 演 算 法 (Fuzzy C-Means 
Algorithm：FCM Algorithm)[6-10] 是以
「點的觀點」(point-wise)產生 c 組「超球
 4
 
N
y
f
N
h
c
i
hi
T
h
m
ih
com
∑∑
= =
−
−
≡ 1 1
2
1
)(
 
θxμ
 (7) 
綜合以上，適用於 FCRM 分群演算法的
新的群集驗證準則即可定義為 
 
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+><
−
=
≡
≠
= =
−
−
∑∑
1
1 1
2
1
1
,
1min
)(
 
k
N
y
f
fV
ji
ji
N
h
c
i
hi
T
h
m
ih
sep
com
FCRM
uu
θxμ  (8) 
2. Bezdek’s partition coefficient PCV [13]的
極限特性: 
PCV 定義如下： 
 
N
V
c
i
N
h
ih
PC
∑∑
= =≡ 1 1
2)(μ
 (9) 
當 +→1m 及 ∞→m 時， PCV 特性分別如下 
 1)},({lim1 =+→ SUVPCm  (10) 
 cSUVPCm 1)},({lim =∞→  (11) 
所以當 +→1m ， PCV 恆為 1 則失去區分能
力。 
而當 ∞→m 時，最小值的 c即為最佳群集
數。 
3. 新的群集驗證準則 FCRMV 的極限特性: 
(a) 當 +→1m 時， 
 ( )
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+
=
⎪⎭
⎪⎬⎫⎪⎩
⎪⎨⎧=
Θ
≠
−
−
→
→
+
+
1
11
1
1
1
1
,
1min
;,,, 
lim
)};,({lim
k
N
SUJ
f
f
SUV
ji
ji
c
sep
com
m
FCRMm
uu
θθ K  (12) 
其中 
 
( )
∑ ∑
= ∈ ⎟
⎟
⎠
⎞
⎜⎜⎝
⎛ −=
c
i Sy
hi
T
h
c
ihh
y
SUJ
1 ),(
2
11 ;,,,
x
θx
θθ K
 
(b) 當 ∞→m 時， FCRMV 的分子項為 
 
0lim1
}){(lim1 
)(1lim
}{lim
1
2
1
2
1 1
2
1
=⎭⎬
⎫
⎩⎨
⎧⋅⎟⎠
⎞⎜⎝
⎛ −=
⋅⋅⎟⎠
⎞⎜⎝
⎛ −=
⎭⎬
⎫
⎩⎨
⎧ −=
∞→=
∞→=
= =∞→
−∞→
∑
∑
∑∑
mm
N
h
h
T
h
m
ihm
N
h
h
T
h
N
h
c
i
hi
T
h
m
ihm
comm
c
cy
N
cy
N
y
N
f
θx
θx
θx
μ
μ
 
  (13) 
而對於 FCRMV 的分母項可得 
 
11
1
1
1
1
0
1
,
1min 
,
1minlim
}{lim
kk
k
k
f
ji
ji
jim
sepm
=+=
+=
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+=
≠
≠∞→
−∞→
uu
uu
 (14) 
其中u 為 θ的單位法向量。 
最後， FCRMV ，當 ∞→m 時 
 
.0
k1
0 lim
)};,({lim
11
1 ==⎪⎭
⎪⎬⎫⎪⎩
⎪⎨⎧=
Θ
−
−
∞→
∞→
sep
com
m
NEWm
f
f
SUF
 (15) 
所以，當m 值過大時， FCRMV 之可靠度將
無法預測。 
4. 提出 FARMA 模型參數修正方法： 
定義 FARMA 模型的輸出 1ˆ +hy 與非線
性系統的輸出 1+hy 之間的誤差為: 
 ∑
=
+++++ −=−=
c
i
i
h
i
hhhh yyyye
1
11111 ˆ~ φ  (16) 
吾人定義代價函數(cost function)為: 
 6
 Tlkekek )]2(,),1([)1( +−+=+ Le  
 
 .]0001[ 
,
0
0
0
1
        ,
1000
0100
0010
0000
L
M
L
L
MOMM
L
L
=
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
=
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
=
C
BA
 
為達控制目標，吾人訂立下列 ∞H 追蹤性
能： 
 η≤
≠ 2
2
02
Sup
w
e
w
, (29) 
其中， 
 
21
0
2
2
)( ⎟⎟⎠
⎞
⎜⎜⎝
⎛= ∑
=
fk
k
kee , 
 
21
0
2
2
)( ⎟⎟⎠
⎞
⎜⎜⎝
⎛= ∑
=
fk
k
kww , 
而 2⋅ 為 ],0[2 fkl 及 0>η 定為規定衰減程
度(prescribed attenuation level)。 
Theorem: The FMBC that stabilize the 
nonlinear system with ∞H  tracking 
performance can be obtained by solving the 
following LMIs: 
0>Q ,  (30a) 
0
00
0
00
)(0
2
>
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢
⎣
⎡
+
+
IC
QBBMAQ
B
CBMAQQ
T
TT
η
, 
 (30b) 
where QLM T= . 
Proof: Suppose there exists a quadratic 
function )()())(( kkkV T Peee = , where 
0>P , and 0>η  such that, for all k , 
 0)()())(( 222 ≤−+ kwkekV ηΔ e , (31) 
where 
 ))(())1(())(( kVkVkV eee −+=Δ . 
We have 
0))()())(((
0
222 ≤−+∑
=
fk
k
kwkekV ηΔ e . (32) 
Assume that 0)0( =e . We obtain 
0))()(())1((
0
222 ≤−++ ∑
=
fk
k
f kwkekV ηe .(33) 
Since 0))1(( ≥+fkV e , this implies  
 η≤
2
2
w
e
.  
Hence 
 η≤
≠ 2
2
02
Sup
w
e
w
 
if (31) holds. We derive the LMI conditions 
from (31): 
 
0
)(
)(
][
)(
0
0
])()([
)()())((
2
222
≥
⎥⎦
⎤⎢⎣
⎡
⎟⎟⎠
⎞+⎥⎦
⎤⎢⎣
⎡ +−
⎜⎜⎝
⎛
⎥⎦
⎤⎢⎣
⎡ −=
+−Δ−
kw
k
kwk
kwkekV
T
T
TT
T
T
e
BBLAP
B
BLA
CCP
e
e
η
η
 
  (34) 
From the Schur complement [24], we obtain 
the following LMI condition: 
00
)(0
0][][
0
0
1
2
2
≥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
+
+−
⇔
≥++−
⎥⎦
⎤⎢⎣
⎡ −
−PBBLA
B
BLACCP
BBLAPBBLA
CCP
T
T
TTT
TTT
T
η
η
  
  (35) 
Furthermore, inequality (35) is equivalent to 
 
0
00
0
00
)(0
0]00[]00[
0
)(0
1
2
1
2
≥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+
+
⇔
≥−
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
+
+
−
−
IC
PBBLA
B
CBLAP
CIC
PBBLA
B
BLAP
T
T
TTT
T
T
T
TT
η
η
 (36) 
 8
∑
∑
=
=
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
−+−
−+
=
−
c
i
ii
c
i
iii
T
ii
i
b
kyakya
kky
ku
AkyAky
R
1
1
1
21
21
])1()([
)()1(
)( THEN
 is )1( and  is )( IF
  : FMBC
φ
φ
eL
 (40) 
where T]0.0074    -0.1881[=L  is the 
feedback gain vector obtained from 
Theorem  with 05.0=η . 
Tkekek )]1()([)( −=e . The antecedent and 
consequent parameters are the same as Table 
1 and Table 2, respectively. Define the mean 
squared error (MSE) between the plant 
output )(ky  and the reference signal )(ky  
by 
 ( )∑
=
−=
N
k
kyky
N 1
2)()(1MSE  (41) 
Here we set 200=N  and use two kinds of 
signals to validate the performance of the 
FMBC. 
 
Case 1: Consider a sinusoidal reference 
signal 
)25/2sin(3241)1( k..ky π+=+ , so 
that the desired output will be 
within the operating range. The 
initial condition is 
]0,0[)]1(),([ =−kyky . The MSE 
is 0.0227. Fig. 3(a)-(c) illustrate 
the control input, output response, 
and error, respectively. 
Case 2: Consider a periodic triangular 
reference signal in the range [ ]7.3,9.0− . The initial condition is 
]0,0[)]1(),([ =−kyky . The MSE 
is 0.0044. Fig. 4(a)-(c) illustrate 
the control input, output response, 
and error, respectively. 
五、計畫成果自評 
1. 研究內容與原計畫相符程度： 
95% 以上。 
2. 達成預期目標情況： 
理論推導、模式建立與人才之培育。 
3. 研究成果的學術或應用價值： 
本計畫之相關研究成果 
[a] C. C. Kung and J. Y. Su, “A Study of Cluster 
Validity Criteria for the Fuzzy c-Regression 
Models Clustering Algorithm” Proc. of 2007 
IEEE International Conference on Systems, 
Man, and Cybernetics (IEEE SMC 2007), pp. 
853-858, Oct. 2007. 
[b] C. C. Kung and J. Y. Su, “A New Cluster 
Validity Criterion for Fuzzy C-Regression 
Models Clustering and Its Application to Fuzzy 
Model Identification” Proc. of 2008 
International Federation of Automatic Control 
World Congress (IFAC WC 2008) , pp. 
7445-7450, July 2008. 
4. 主要之發現與綜合評估： 
本計畫提出「FARMA 模型辨証
與模糊模型控制器設計」之方法。吾
人提出一個適用於 FARMA 模型的群
集驗證準則 FCRMV 以幫助 FCRM 分類
演算法選擇出最精簡的群集數目。此
外吾人對此群集驗證準則進行極限分
析(limit analysis)，以研究該群集驗證
準則之可靠度，並瞭解加權指數m 的
選取範圍。再根據群集驗證準則決定
FARMA模型的模糊規則庫(fuzzy rule 
base)數目，並計算出 FARMA 模型的
前件部參數與後件部參數。提出系統
化的步驟說明，以辨証出受控系統的
FARMA 模型。且利用梯度下降法 
( gradient descent method )，提出
FARMA 模型參數修正方法以達成模
型誤差小的目標。最後，依據建立的
FARMA 模型，設計 FMBC。並設計
一補償機構以避免最小近似誤差
（minimum approximation error）所導
致的不穩定因素，完成控制目標。 
 10
Fig. 1. (a) Training input signal )(ku  in Example 1. 
(b) Plot of FCRMV  vs. c in Example 1. 
Fig. 2. Simulation results of Example 1: (a) Outputs of the 
identification model (dashed line) and the plant (solid 
line). (b) Errors between the outputs of FARMA model 
and the plant for )25/2sin()( kku π=  with 400=N . 
(MSE=0.0016) 
 
 
Fig. 3 Simulation results of Example 2 Case 1: (a) FMBC control 
signal. (b) Output of the plant (solid line) and the desired 
signal (dashed line). (c) Errors between the output of the 
plant and the reference signal (MSE=0.0227). 
 
Fig. 4 Simulation results of Example 2 Case 2: (a) FMBC control 
signal. (b) Output of the plant (solid line) and the reference 
signal (dashed line). (c) Errors between the output of the 
plant and the reference signal (MSE=0.0044). 
Table 1 List of antecedent parameters in Example 1 and 
Example 2. 
 i = 1 i = 2 i = 3 i = 4 i = 5
i
1α 1.2807 0.1528 -1.8071 1.7033 1.9907
i
1β 1.0130 1.1755 1.0917 0.7129 0.6593
i
2α 1.9206 0.8256 -0.4791 1.2688 -0.0324
i
2β 0.8662 0.4220 2.3622 0.6505 1.2827
Table 2 List of consequent parameters in Example 1 
and Example 2. 
 i = 1 i = 2 i = 3 i = 4 i = 5
ia1 0.7151 1.1301 -0.1956 0.8990 -0.1161
ia2 -0.0191 0.3857 -0.2243 0.2959 1.0315
ib1 0.9490 0.9426 0.9741 0.9100 0.9871
 
 
 
 
Set the weighting exponent 1>m . Specify the form 
of cluster representatives ),( iify θx= . Define ihd  as 
(2) so that 0≥ihd  for all i  and h . Pick a termination 
threshold 0>ε  and an initial partition )0(U . 
Set iteration index 0=r . 
Step 2) Calculate the c model parameters iθ  at each iteration 
that globally minimizes the objective function (3) 
Step 3) Update )1()( +→ rr UU  with )( iihd θ  as follows: 
 
⎪⎪
⎪⎪
⎩
⎪⎪
⎪⎪
⎨
⎧
∉∅≠
∈∅≠
∅=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎟⎟⎠
⎞
⎜⎜⎝
⎛
=
−
=
−
+
∑
hh
hh
h
h
c
j
m
jjh
iih
r
ih
IiI
IiI
n
I
d
d
,for 0
,for 1
for 
)(
)(
1
1
1
2
)1(
θ
θ
μ  (4) 
where }0)(,1|{ =≤≤= iihh dciiI θ  and hn  is the 
number of elements in hI . 
Step 4) Check for termination in some convenient induced 
matrix norms:  
If ε≤− + )1()( rr UU ,   stop;  
otherwise, set 1+= rr  and return to Step 2. 
A common form of the cluster representatives in the FCRM 
clustering algorithm is the linear regression functions of the 
input variables:  
 
n
i
n
i
i
T
ii
xaxa
fy
++=
==
L11
),( θxθx
 (5) 
where nTnxx ℜ∈= ],,[ 1 Lx  is the input variable vector and 
nTi
n
i
i aa ℜ∈= ],,[ 1 Lθ  is the parameter vector needed to be 
determined. The measure of error is defined as 
 
.
),()(
hi
T
h
hihiiih
y
yfd
−=
−=
θx
θxθ
 (6) 
The regression function parameters iθ  that globally 
minimize the objective function in (3) can be obtained by 
using the weighted least square (WLS) algorithm [10]:  
 ΥWΧΧWΧθ i
T
eei
T
ei
1][ −=  (7) 
where  
 ,, 2
1
2
1
N
N
nN
T
N
T
T
e
y
y
y
ℜ∈
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=ℜ∈
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
= × MM Y
x
x
x
Χ  (8) 
 NN
iN
i
i
i
×ℜ∈
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=
μ
μ
μ
L
MOMM
L
L
00
00
00
2
1
W . (9) 
Another specific form of the cluster representatives in the 
FCRM clustering algorithm is the affine linear regression 
functions with a constant term:  
 
i
n
i
n
i
i
T
ii
bxaxa
fy
011
]1,[),(
+++=
== ++
L
θxθx
 (10) 
where 101 ],,,[
++ ℜ∈= nTiinii baa Lθ  is the parameter vector 
needed to be determined. The measure of error is defined as 
 
.]1,[
),()(
hi
T
hihiiih
y
yfd
−=
−=
+
++
θx
θxθ
 (11) 
The parameters +iθ  that globally minimize the objective 
function in (3) are obtained by WLS algorithm [10], too: 
 ΥWΧΧWΧθ i
T
aai
T
ai
1][ −+ =  (12) 
where  
 ,,
1,
1,
1,
2
1
)1(2
1
N
N
nN
T
N
T
T
a
y
y
y
ℜ∈
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=ℜ∈
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
= +× MM Y
x
x
x
Χ  (13) 
 NN
iN
i
i
i
×ℜ∈
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=
μ
μ
μ
L
MOMM
L
L
00
00
00
2
1
W . (14) 
B. Cluster Validity Criteria for FCRM 
In practice, the number of clusters is usually decided with 
the aid of a reliable index called the cluster validity criterion. 
There are many cluster validity criteria proposed for fuzzy 
clustering algorithms [7]-[9], [11]-[15], but only a few of 
them are applicable to the FCRM clustering algorithm:  
1) The Bezdek’s parttion coefficient [11]: Let fcMU ∈  and 
),,,( 21 cθθθ L=Θ  be the vector of c regression models 
parameters that describe the functional clusters. The 
Bezdek’s parttion coefficient [11] is defined as follows: 
 ∑∑
= =
=Θ N
h
c
i
ihPC N
SUV
1 1
2)(1);,( μ  (15) 
which is very intuitive and very simple for calculation. The 
optimal number c is chosen at which PCV  is closest to one. It 
is noticed that PCV  is independent of the cluster prototypes 
[16]. Although PCV doesn’t aim at the FCRM clustering 
algorithm, it is still applicable to the FCRM clustering 
algorithm. We use it as a comparison to the following two 
cluster validity criteria.  
2) NEWF  for FCRM with linear regression functions [7]: In 
[7], we adopt the concept of the compactness-to-separation 
ratio in [12] to propose a new cluster validity criterion for the 
FCRM clustering algorithm with linear regression functions: 
 
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+
−
=≡Θ
≠
= =
∑∑
k
N
y
f
f
SUF
ji
ji
N
h
c
i
hi
T
h
m
ih
sep
com
NEW
uu
θx
,
1min
)(
 );,( 1 1
2μ
 (16) 
 
 
 
 
{ }
,1,][
}lim{]}lim{[
][lim}{lim
1
1
1
1
1
11
cii
T
ai
T
i
i
m
T
aai
m
T
a
i
T
aai
T
a
m
i
m
<≤=
=
=
−
→
−
→
−
→
+
→
++
++
ΥΧΧΧ
ΥWΧΧWΧ
ΥWΧΧWΧθ
 (28) 
where )1(]1,[ +×ℜ∈= nNThi ixX  and iNhi y ℜ∈= ][Y  are 
matrices composed by ihh Sy ∈),(x  respectively. The 
obtained parameters represent the hard partition affine linear 
functions for input-output data in each cluster. 
 
{ }
+−
∞→
−
∞→
−
∞→
+
∞→
==
=
=
θΥΧΧΧ
ΥWΧΧWΧ
ΥWΧΧWΧθ
T
aa
T
a
im
T
aaim
T
a
i
T
aai
T
amim
c
c 1
1
1
][
}lim{]}lim{[
][lim}{lim
 (29) 
where +θ  is the parameter of the grand mean affine linear 
function for all input-output data pairs in S . 
B. Limiting Properties of the Validity Criteria for FCRM 
From (23) and (26), we now take limits of the validity 
criteria as m approaches one from above or infinity.  
1) The limiting properties of PCV : For the partition 
coefficient PCV , we have following results: 
Partition Coefficient, +→ 1m  and ∞→m : 
 1)};,({lim
1
=Θ+→ SUVPCm ; (30) 
 cSUVPCm 1)};,({lim =Θ∞→ ; (31) 
It is noticed that PCV  is independent of the parameter vectors 
Θ , so its dependency of m seems transparent [9]. For values 
of +→ 1m , PCV  loses its ability to discriminate between 
various values of c because (30) takes the same value on all 
crisp U ’s for every c. When ∞→m , we will select the 
minimum of c as the optimum number. At the extreme case, 
when the clustering algorithm starts from two clusters, c≤2 , 
PCV  will maximize at 1/2 (whereas 2=c ) for ∞→m . 
2) The limiting properties of NEWF : For the cluster validity 
criterion NEWF , we have following results as 
+→ 1m :  
 ( )
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+
=
⎪⎭
⎪⎬⎫⎪⎩
⎪⎨⎧=Θ
≠
→→ ++
k
N
SUJ
f
fSUF
ji
ji
c
sep
com
mNEWm
uu
θθ
,
1min
;,,, 
lim)};,({lim
11
11
K  (32) 
where 
 ( ) ∑ ∑
= ∈ ⎟⎟⎠
⎞⎜⎜⎝
⎛ −= c
i Sy
hi
T
hc
ihh
ySUJ
1 ),(
2
11 ;,,,
x
θxθθ K  (33) 
denotes the classical within-group sum of squared error 
objective function for hard c-partition. 
Since the denominator in (32) varies with Θ  alone, it is 
very possible that this index will validate ),( ΘU  pairs for 
different c than only ),(1 ΘUJ does. 
As ∞→m , the numerator of NEWF  becomes: 
 
0lim1
}){(lim1 
)(1lim}{lim
1
2
1
2
1 1
2
=⎭⎬
⎫
⎩⎨
⎧⋅⎟⎠
⎞⎜⎝
⎛ −=
⋅⋅⎟⎠
⎞⎜⎝
⎛ −=
⎭⎬
⎫
⎩⎨
⎧ −=
∞→=
∞→=
= =∞→∞→
∑
∑
∑∑
mm
N
h
h
T
h
m
ihm
N
h
h
T
h
N
h
c
i
hi
T
h
m
ihmcomm
c
cy
N
cy
N
y
N
f
θx
θx
θx
μ
μ
 (34) 
For the denominator of NEWF , however, we have 
 
kk
k
k
f
ji
ji
jimsepm
1
0
1
,
1min 
,
1minlim}{lim
=+=
+=
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+=
≠
≠∞→∞→
uu
uu
 (35) 
where u  is the unit normal vector of θ . Consequently, the 
limit of NEWF  as ∞→m  is 
 
.0
k1
0 
lim)};,({lim
==
⎪⎭
⎪⎬⎫⎪⎩
⎪⎨⎧=Θ ∞→∞→
sep
com
mNEWm f
f
SUF
 (36) 
So the index NEWF  can not validate the partition for ∞→m . 
3) The limiting properties of +NEWF : Similar to the results in 
(32)-(36), the limit analysis of +NEWF  is arranged as follows:  
 ( )
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+
=
⎪⎭
⎪⎬⎫⎪⎩
⎪⎨⎧=Θ
≠
++
+
+
→
++
→ ++
k
N
SUJ
f
fSUF
ji
ji
c
sep
com
m
NEW
m
uu
θθ
,
1min
;,,,
 
lim)};,({lim
11
11
K  (37) 
where 
 ( ) ∑ ∑
= ∈
++++ ⎟⎟⎠
⎞⎜⎜⎝
⎛ −= c
i Sy
hi
T
hc
ihh
ySUJ
1 ),(
2
11 ]1[;,,,
x
θxθθ K  (38) 
Next, 
 
.0
kk
0 
lim)};,({lim
12
==
⎪⎭
⎪⎬⎫⎪⎩
⎪⎨⎧=Θ +
+
∞→
++
∞→
sep
com
mNEWm f
f
SUF
 (39) 
The index +NEWF  may validate the FCRM clustering result for 
+→ 1m  but also loses its ability to validate the partition for 
∞→m .  
IV. NUMERICAL EXAMPLES ON CLUSTER VALIDITY 
The numerical data are extremely simple; however, they 
give clear illustration of the above deductions. The same 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
-5 0 5
-20
-15
-10
-5
0
5
10
15
x1
y
Mixed Data
   (a)  
 
2 3 4 5 6 7 8
0
0.2
0.4
0.6
0.8
1
Number of clusters, c
C
lu
st
er
 in
de
x 
 V
P
C
VPC index plot
VPC, m=1.1
VPC, m=2.0
VPC, m=7.0
   (b)  
 
2 3 4 5 6 7 8
0
0.5
1
1.5
2
2.5
3
3.5
Number of clusters, c
C
lu
st
er
 in
de
x 
 F
+ N
E
W
F+NEW index plot
F+NEW, m=1.1
F+NEW, m=2.0
F+NEW x10, m=7.0
   (c) 
Fig. 2.  (a) Input-output data in Example 2. (b) The plots 
of PCV  vs. c with different values of m. It is noticed that 
PCV  works only with m =2.0 for FCRM clustering 
algorithm. (c) The plots of +NEWF  vs. c with different 
values of m. It indicates the correct number of clusters, 
c=4, for both m=1.1 and m=2.0. When m=7.0 (a 
relatively large value), +NEWF  indicates c=3 as the 
appropriate number of clusters for a relatively “fuzzier” 
partition. 
-5 0 5
-15
-10
-5
0
5
10
15
20
x1
y
Mixed Data
   (a)  
 
2 3 4 5 6 7 8
0
0.2
0.4
0.6
0.8
1
Number of clusters, c
C
lu
st
er
 in
de
x 
 V
P
C
VPC index plot
VPC, m=1.1
VPC, m=2.0
VPC, m=7.0
   (b)  
 
2 3 4 5 6 7 8
0
0.5
1
1.5
2
2.5
3
Number of clusters, c
C
lu
st
er
 in
de
x 
 F
N
E
W
FNEW index plot
FNEW, m=1.1
FNEW, m=2.0
FNEW x10, m=7.0
   (c)  
Fig. 1.  (a) Input-output data in Example 1. (b) The plots 
of PCV  vs. c with different values of m. It is noticed that 
PCV  works only with m =2.0 for FCRM clustering 
algorithm. (c) The plots of NEWF  vs. c with different 
values of m. It indicates the correct number of clusters, 
c=4, for both m=1.1 and m=2.0. When m=7.0 (a 
relatively large value), NEWF  indicates c=3 as the 
appropriate number of clusters for a relatively “fuzzier” 
partition. 
2.1 Review of Cluster Analysis  
Let },,1),{()},(,),,{( 11 NhyyyS hhNN LL === xxx  be a 
set of N  input-output data to be clustered, each independent 
input vector nn
T
nhhh xx ℜ⊂×××∈= XXXx LL 211 ],,[  has a 
corresponding dependent output ℜ⊂∈ Yhy , where 
1X , 2X ,…, nX  are the domains of the input variables and Y  
denotes the domain of the output. The FCRM clustering 
algorithm assumes that the given input-output data are drawn 
from c  different affine linear regression models: 
 
,,,1,]1[
),(
02211
ci
xxx
fy
i
T
h
ihninhihi
ih
i
h
L
L
==
++++=
=
θx
θx
θθθθ  (1) 
where 1021 ],,,[
+ℜ∈= nTiiniii θθθθ Lθ , 0iθ  is a constant that 
represents the bias or offset term. The parameter vectors iθ  
are needed to be determined. Label vectors assigned to each 
data pair can be arrayed as a )( Nc×  fuzzy c-partition matrix, 
][ ihU μ= , in which ihμ  is regarded as the membership of 
each input-output data pair ),( hh yx  belonging to the ith fuzzy 
cluster. All ihμ  are constrained labels (Ruspini, 1970): 
 
.,,1,0
,,1,1
,,10
1
1
ciN
Nh
hi
N
h
ih
c
i
ih
ih
L
L
=<<
==
∀≤≤
∑
∑
=
=
μ
μ
μ
 (2) 
The distance (measure of fitness) from every sampled 
),( hh yx  to the ith affine linear regression model with 
parameter iθ  are defined as follows 
 .]1[),()( hi
T
hhih
i
iih yyfd −=−= θxθxθ  (3) 
The objective function in FCRM clustering algorithm is then 
defined as follows: 
 ( ) ∑∑
= =
=
N
h
c
i
iih
m
ihcm dUJ
1 1
2
1 )()(,,, θθθ μK  (4) 
where ),1( ∞∈m  is the weighting exponent. Minimization of 
the objective function (4) yields a fuzzy c-partition of the data, 
together with estimates for the c parameter vectors 
simultaneously. 
The FCRM clustering algorithm is executed in the following 
steps (see Hathaway and Bezdek, 1993): 
Step 1 Assign the number of the clusters c . Set the 
weighting exponent 1>m . Pick a termination 
threshold 0>ε  and an initial partition 
][ )0()0( ihU μ= . Set iteration index .0=r  
Step 2 At each thr  iteration, calculate c parameter 
vectors iθ  that minimize the objective function 
(4) by using the weighted least square (WLS) 
algorithm (e.g. Ljung and Soderstrom, 1983) to 
),( hh yx , Nh ,,1 L= . 
Step 3 Update )(rU  to )1( +rU  as follows: 
 
⎪⎪
⎪⎪
⎩
⎪⎪
⎪⎪
⎨
⎧
∉∅≠
∈∅≠
∅=⎟⎟⎠
⎞
⎜⎜⎝
⎛
=
∑
=
−
+
hh
hh
h
h
c
j
m
jjh
iih
r
ih
IiI
IiI
n
I
d
d
,for 0
,for 1
for 
)(
)(1
1
1
2
)1(
θ
θ
μ  (5) 
where }0)(,1|{ =≤≤= iihh dciiI θ  and hn  
is the number of elements in hI . 
Step 4 Check for termination in convenient induced 
matrix norms: 
If ε≤− + )1()( rr UU ,  stop;  
otherwise, set 1+= rr  and return to Step 2. 
2.2 Design of New Cluster Validity Criterion  
For fuzzy c-means (FCM) clustering algorithm (e.g. Hoppner 
et al., 1999), one commonly used cluster validity criterion 
called the Xie-Beni index (see Xie and Beni, 1991) is 
designed on the concept of compactness-to-separation ratio. 
The numerator of Xie-Beni index is a compactness validity 
function that fits the objective function of the FCM and 
reflects the compactness of clusters. The denominator is a 
separation validity function that measures the separation 
status of clusters. The smaller the separation validity function 
value is, the more probability there will be redundant cluster 
representative in the existed representatives. We adopt the 
compactness-to-separation ratio concept and propose a new 
cluster validity criterion for FCRM with affine linear 
functional cluster representatives. 
1) The Compactness Validity Function: Define the fuzzy 
covariance matrix of the ith cluster as follows: 
 
,1,1
;)())(()(
11
Nhci
N
h
m
ih
N
h
T
ihih
m
ihi
≤≤≤≤
−−= ∑∑
==
μμ vzvzF
 (6) 
where 11 ],,,[],[
+ℜ∈== nThnhhThThh yxxy Lxz  is the 
observation consisting of the hth sampled input-output data. 
iv  is the centers of the ith cluster calculated by 
 Nhci
N
h
m
ih
N
h
h
m
ihi ≤≤≤≤= ∑∑
==
1,1;)()(
11
μμ zv  (7) 
Defined the flatness index as the ratio between the smallest 
and the largest eigenvalue of iF  (see Babuska and 
Verbruggen, 1995): 
 maxmin −−= iiit λλ  (8) 
where min−iλ  is the smallest eigenvalue of iF  and max−iλ  is the 
largest one, respectively. The flatness index has low values 
for clusters which are large and flat. For the entire partition, 
the average flatness index is measured by (see Babuska, 1998): 
17th IFAC World Congress (IFAC'08)
Seoul, Korea, July 6-11, 2008
7446
 ,)()(
1
∑
=
=
c
i
iii ww xxφ  (18) 
 .)()()()(
1
11 ∏
=
=××=
n
q
q
i
qn
i
n
ii xAxAxAw Lx  (19)  
The procedure of our T-S fuzzy model identification 
algorithm is outlined in the following steps:  
T-S fuzzy model identification algorithm 
Step 1 Get experimental input-output data ( )hh y,x , 
Nh ,,1 L= , from the unknown system. Choose 
the initial number of clusters MINcc = . 
Step 2 Apply the FCRM clustering algorithm to partition 
the product space of the given input-output data 
into c linear functional clusters. 
Step 3 Set 1+= cc  and repeat Step 2 to Step 3 until 
MAXcc = , the termination number of clusters. 
Step 4 Cluster validation: Use the proposed new cluster 
validity criterion NEWF  in (14) to determine the 
appropriate number of needed clusters  
Step 5 Construct the prototypes of fuzzy rules: the 
parameter estimations of iqα  and iqβ  can be 
roughly obtained from the fuzzy partitions matrix 
U by the axis-orthogonal projection method (see 
e.g. Babuska, 1998): 
 ∑∑
==
=
N
h
ih
N
h
qhih
i
q x
11
μμα  (20) 
 ∑∑
==
−=
N
h
ih
N
h
i
qqhih
i
q x
11
2)( μαμβ . (21) 
The parameters Tiiniii ],,,[ 021 θθθθ L=θ can 
inherit from the affine linear functional cluster 
representatives in FCRM. 
Step 6 Fine-tuning of the parameters: define a cost 
function 221 ))(ˆ)(( kykyJ −= . By the gradient 
descent method (e.g. Wang, 1994, 1997), the 
antecedent and consequent parameters in the T-S 
fuzzy model can be finely tuned to minimize J  by 
the following equations: 
 )()()1( kkk iqiqiq ααα Δ+=+  (22) 
 )()()1( kkk iqiqiq βββ Δ+=+  (23) 
 )()()1( khk iqiqiq θθθ Δ+=+  (24) 
 )()()1( 000 kkk iii θθθ Δ+=+  (25) 
where )(kiqαΔ , )(kiqβΔ , and )(kiqθΔ  denote the 
adjustments at each learning step k  as follows (we 
drop the argument k  for brevity):  
 ⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−−=Δ 21 )ˆ)(ˆ(2 i
q
i
qqiii
q
x
yyyy β
αφηα  (26) 
 
2
22 )ˆ)(ˆ(2 ⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−−=Δ
i
q
i
qqiii
q
x
yyyy β
αφηβ  (27) 
 q
ii
q xyy φηθ )ˆ(3 −=Δ  (28) 
 ii yy φηθ )ˆ(30 −=Δ . (29) 
Where 1η , 2η , and 3η are positive real-valued 
constants denoting the step-size. 
The deduction of the above fine-tuning laws (22)-(29) are 
introduced in Wang (1994, 1997). Pick two termination 
thresholds 0>αβε  and 0>aε , we can apply the fine-tuning 
laws (22)-(23) recursively until the termination conditions, { } αβεβα <ΔΔ
==
i
q
i
q
nq
ci
,max
,1
,1
L
L
 and { } aiq
nq
ci
εθ <Δ
== LL,0,1
max , are satisfied. 
4. SIMULATIONS  
4.1 Example 1: Mixed data classification 
To validate the new cluster validity criterion NEWF , we 
consider the following example and compare the result with 
Bezdek’s partition coefficient PCv : 
 Nv
N
h
c
i
ihPC ∑∑
= =
=
1 1
2)(μ  (30) 
The appropriate number c is chosen when largest PCv  appears. 
Given a mix of four linear equations with exogenous white 
Gaussian random noise )4,3,2,1( =iiε  having zero mean and 
variance 0.25: 
 
432144
332133
232122
132111
1053]1[
,321]1[
,14432]1[
,4432]1[
εε
εε
εε
εε
++++−=+=
+−++−=+=
+++−=+=
+−+−=+=
+
+
+
+
xxxy
xxxy
xxxy
xxxy
T
T
T
T
θx
θx
θx
θx
 (31) 
we randomly generate 800 training input vector x  with each 
element uniformly distributed in the range [-5,5] and then 
apply each 200 of them to the four linear equations 
correspondingly. By the FCRM algorithm, we obtain cluster 
representatives and partition matrix U  for different c . we set 
001.01 =k  and 001.02 =k  in (14) and consider the following 
two cases: 
Case 1: 2=m . The plot of cluster index vs. cluster number is 
depicted in Fig. 1. We see that both the Bezdek’s partition 
coefficient and the new cluster index indicate the correct 
answer 4=c . The affine linear regression models obtained 
by the FCRM algorithm are listed below: 
17th IFAC World Congress (IFAC'08)
Seoul, Korea, July 6-11, 2008
7448
Table 2, respectively. Define the mean square error as 
( ) NkykyN
k
∑
=
−=
1
2)(ˆ)(MSE . The comparative results in the 
literatures are listed in Table III. We see that the proposed 
identification method is capable of obtaining competent 
results using fewer rules than other approaches reported in the 
literatures. 
5. CONCLUSIONS 
In this paper, a new cluster validity criterion NEWF  designed 
for the FCRM clustering algorithm with affine linear 
functional cluster representatives is proposed. A modification 
of Kim’s fuzzy modelling approach (Kim et al., 1997) is 
proposed as well to construct a T-S fuzzy model with compact 
number of rules.A The simulation results illustrate that NEWF  
is applied for a wider range of m and the T-S fuzzy model 
obtained by the proposed fuzzy model identification algorithm 
is able to well approximate the discrete-time nonlinear plant 
with satisfactory results. 
ACKNOWLEDGMENTS 
This work was supported by the National Science Council of 
Taiwan, Republic of China, under grant 96-2221-E-036-033-
MY2. 
REFERENCES 
Babuska, R. and H. Verbruggen (1995). New approach to 
constructing fuzzy relational models from data. In: 
Proceedings of 3rd European congress on Intelligent 
Techniques and soft Computing EUFIT’95, Aachen, 
Germany, 583-587. 
Babuska, R. (1998). Fuzzy Modeling for Control. Boston: 
Kluwer Academic Publishers. 
Bezdek, J. C. (1974). Cluster validity with fuzzy set. Journal 
of  Cybernetic, 3, 58-72. 
Bezdek, J. C. (1981). Pattern Recognition with Fuzzy 
Objective Function Algorithms. New York: Plenum. 
Chuang, C. C., S. F. Su and S. S. Chen (2001). Robust TSK 
fuzzy modeling for function approximation with outliers. 
IEEE Transactions on Fuzzy Systems, 9, 810-821. 
Friedberg, S. H., A. J. Insel and L. E. Spence (1989). Linear 
Algebra. NJ: Prentice-Hall. 
Hathaway, R. J. and J. C. Bezdek (1993). Switching 
regression models and fuzzy clustering. IEEE 
Transactions on Fuzzy Systems, 1, 195-204. 
Hoppner, F., F. Klawonn, R. Kruse, and T. Runkler (1999). 
Fuzzy cluster analysis, methods for classification, data 
analysis and image recognition. John Wiley & Sons. 
Kim, E., M. Park, S. Ji, and M. Park (1997) A new approach 
to fuzzy modeling. IEEE Transactions on Fuzzy Systems, 
5, 328-337. 
Ljung, L. and T. Soderstrom (1983). Theory and practice of 
recursive identification. MIT Press. 
Pal, N.R. and J.C. Bezdek (1995). On cluster validity for the 
fuzzy c-means model. IEEE Transactions on Fuzzy 
Systems, 3, 370-379. 
Ruspini, E. (1970). Numerical method for fuzzy clustering. 
Information Science, 2, 319-350. 
Setnes, M. and H. Roubos (2000). GA-fuzzy modeling and 
classification: complexity and performance. IEEE 
Transactions on Fuzzy Systems, 8, 509-522. 
Takagi, T. and M. Sugeno (1985). Fuzzy identification of 
systems and its applications to modeling and control. 
IEEE Transactions on Systems, Man and Cybernetics, 15, 
116-132. 
Wang, L. X. (1994). Adaptive Fuzzy Systems and Control: 
Design and Stability Analysis. Prentice-Hall. 
Wang, L. X. (1997). A Course in Fuzzy Systems and Control. 
New York: Prentice-Hall. 
Wang, L. and J. Yen (1999) Extracting fuzzy rules for system 
modeling using a hybrid of genetic algorithms and 
Kalman filter. Fuzzy Sets and Systems , 101, 353-362. 
Xie, X. L. and G.A. Beni (1991). Validity measure for fuzzy 
clustering. IEEE Transactions on Pattern Analysis and 
Machine Intelligence, 3, 841-846. 
 
 
 
 
 
Fig. 3. The plot of NEWF  vs. cluster number c in Example 2. 
Table 2 List of consequent parameters in Example 2 
 i1θ  i2θ  i0θ  
1=i  0.4603 0.1938 0.1926 
2=i  -0.0953 0.2673 0.0900 
3=i  -0.0087 -0.0638 -0.0082 
Table 1 List of antecedent parameters in Example 2 
 i1α  i1β  i2α  i2β  
1=i  -0.9175 0.4732 -0.8998 0.3259 
2=i  1.4970 0.7024 0.2014 0.5541 
3=i  0.3879 0.3337 0.2867 0.7132 
Table 3 Comparative results of Example 2 
Ref. No. of rules No. of sets Consequent MSE 
Setnes & 
Roubos 
7 
5 
4 
14 Triangular 
8 Triangular 
4 Triangular 
Singleton 
Affine Linear 
Affine Linear 
3.0e-3
7.5e-4
1.2e-3
Wang & Yen 28 40 Gauss Singleton 3.3e-4
The proposed 
method 
3 6 Gauss Affine Linear 5.2e-4
17th IFAC World Congress (IFAC'08)
Seoul, Korea, July 6-11, 2008
7450
