 1
一、中文摘要 ............................................................................................................................ 2 
Abstract ...................................................................................................................................... 2 
二、計畫緣由與目的 ................................................................................................................ 2 
三、結果與討論 ........................................................................................................................ 4 
整合 WiMAX 與 WiFi 網路作為情緒管理服務運算系統之通訊骨幹系統 ................. 4 
1.  整合型  WiMAX/WiFi  架構 .............................................................................. 5 
2.  頻寬分配與管理 ........................................................................................ 7 
3.  效能評估 .................................................................................................. 10 
4.  結論 .......................................................................................................... 11 
研究 WiMAX 服務品質保證(QoS)與省電節能機制以支援情緒管理服務應用 ........ 12 
5.  IPSS 架構介紹 ......................................................................................... 13 
2.  系統分析 .......................................................................................................... 15 
3.  模擬與分析 .............................................................................................. 18 
4.  結論 .......................................................................................................... 21 
支援無縫移動式網路服務以提供整合性情緒管理服務 .............................................. 21 
1.  IEEE 802.16j Transparent Relaying 網路架構 .............................. 21 
2.  系統架構與問題形成 ...................................................................................... 22 
3.  中繼資源排程演算法 (RRS) .................................................................. 24 
4.  模擬結果與效能分析 .............................................................................. 26 
5.  結論 .......................................................................................................... 28 
四、計畫成果自評 .................................................................................................................. 28 
參考文獻 .................................................................................................................................. 29 
附錄 (研究成果) ..................................................................................................................... 31 
 3
讓自己的思想停留在此安詳輕鬆的環境一
段稍長的時間，直到自己的心情平靜放鬆
為止。另外如音樂療法則是透過具有解放
患者情緒之音樂旋律，以渲泄患者之情
緒，以達到壓抑情緒之解放，使得情緒得
以放鬆。還有心理諮詢又稱為"談話治療
"，為另一種被視為治療憂鬱症或精神病非
常有效的方法。它是指透過心理諮詢專家
面談患者所面臨之狀況。一個深受患者信
賴的心理治療師，其談話及聲音對患者心
情的改善，在緊急狀況時具有非常有效的
穩定作用。因此若能透過現代高科技的協
助，在患者發病時能隨時給予適當的治
療，應該可避免病情的惡化並且大幅減少
不幸的事情發生。 
前述的場景應用的要求以現代的科技
而言事實上可以達成的，只要情緒障礙者
配戴一無線行動裝置具備情緒管理工具的
應用程式，其便可在需要情緒輔導時，透
過此行動裝置連接到無線網路，以存取情
緒管理工具所需之多媒體影音資料，隨時
隨地受治療，而不受時間與地點的限制。
因此以網路傳輸的角度而言，由於上述這
些情緒管理的工具或療法，皆為即時或非
即時的多媒體應用，因此如果要讓這些情
緒管理的工具或療法能有效發揮其作用，
則必須確保這些即時或非即時的多媒體資
料傳輸能順暢，換言之就是保障資料傳輸
品質。因此，為了可以保障資料傳輸的品
質且為了不限制使用者的移動自由性，因
此目前最常使用的無線網路WiFi網路就是
一個可以當做此情緒管理系統資料傳輸的
媒介。然而，雖然 WiFi 可以提供無線網路
傳輸的環境，但是由於 WiFi 傳輸速度上的
限制以及可涵蓋範圍的限制下，WiFi 網路
只能提供短距離且傳輸的資料量不大的情
況之下，為了可以提供情緒管理系統更良
好的資料傳輸環境，目前正在發展的
WiMAX 無線網路技術就非常適合作為情
緒管理服務系統的資料傳網路。這是由於
WiMAX 無線網路涵蓋的範圍可以遠至數
十公里，因此使用者可以隨心所欲的移動
不必被限制在某些活動範圍，並且對於情
緒管理服務系統而言，WiMAX 仍可隨時連
接上網際網路，使之可以在網路上隨時隨
地的存取資料與服務。除此之外，由於
WiMAX 網路通訊協定在設計之初便考量
到資料傳輸品質保障的重要，因此在其通
訊協定內特別設計保障資料傳輸品質的機
制，因此對於情緒管理服務應用所需傳輸
之即時或非即時的多媒體影音資料，能確
保其應用運作之流暢性，避免因為多媒體
影音資料傳輸不順暢，造成使用者情緒上
感受到不耐煩與挫折，影響到情緒管理服
務的效果，更甚者可能會觸發其負面情緒
惡化成躁鬱或憂鬱，反而造成整體情緒管
理服務系統失效。 
目前無線網路技術的應用在生活上已
經愈來愈普遍，除了現今正廣為推廣的
WiMAX 外，許多的區域網路也開始提供透
過 WiFi 技術存取網路的服務。由於 WiFi
可提供小型區域網路的無線存取服務或作
為有線區域網路的延伸，因此在很多大都
會區已經地廣泛鋪設 WiFi 無線網路，如台
北市已建置涵蓋全市的 WiFi 無線網路，所
以若能將 WiMAX 與現行已架設之 WiFi
網路整合，提供網路的存取服務，預期將
可降低初期情緒管理服務運算系統架設的
成本與推廣之阻力。 
WiMAX 是泛指符合 IEEE 802.16 無線
通訊標準的無線通訊設備，WiFi 則是泛指
符合 IEEE 802.11 無線通訊標準的無線通
訊設備。WiFi 可以提供高速的無線區域網
路傳輸服務，WiMAX 則可提供遠距離的寬
頻無線網路存取服務。由於 WiMAX 使用
連接導向 (Connection-oriented) 存取方式
進行資料傳輸，而 WiFi 是採用競爭
(Contention-based) 的方式來存取傳輸通
道，這種方法實際上無法給予 WiFi 區域網
路即時性和正確性的頻寬分配，因此當網
路的傳輸量提高時，資料發生遺失的機率
將大幅增加，因而若直接應用於傳輸豐富
影音多媒體時，將會有無法提供服務品質
保證的疑慮。因此，在整合 WiMAX 與 WiFi
無線網路技術時，如何適切的整合兩者的
服務品質保證的機制，將是整合首先需要
解決的一項問題。 
有鑑於WiMAX較WiFi有較佳的傳輸
服務品質保證機制，本計畫中將研究如何
將 WiMAX 的傳輸服務品質技術延伸至
WiFi 網路上。為了達到此目的，本計劃初
期預計在WiFi基地台的部分開發一個可將
 5
 
 
中，最受關注的應用乃 WiMAX/WiFi 整合
系統。此應用可使 WiFi 熱點藉由 WiMAX 
作為後置式 (backhaul) 網路進而存取網際
網路服務。如此一來，不僅能減少昂貴的
乙太網路建置成本，同時也利用熱點的行
動性，進一步實現在智慧型運輸系統
(Intelligent Transport System，簡稱 ITS) 之
應用。一般來說，對於建構 WiMAX/WiFi 
整合系統最重要的議題是如何設計一套有
效 的 媒 介 存 取 控 制  (Media Access 
Control，簡稱 MAC) 協定，以減少在
WiMAX 與 WiFi 之間技術上的差異性 
[1]。近年來，許多研究學者就此議題上提
出相關的服務品質 (Quality of Service) 保
證之策略 [2][3]。舉例來說，文獻 [2]中，
作者提出一套整合 802.16/802.11e 架構，
將這兩種網路技術的服務品質類別互相對
應，以達成一致性。同樣地，在文獻 [3]
中亦提出在 802.16 與 802.11e 整合架構中
的服務品質控制協定，此協定提供 WiMAX 
與 WiFi 整合網路的串流服務之服務品質
保證。然而文獻 [2] 並未考慮頻寬分配、
排程以及允許控制  (Admission Control) 
等控制需求。而對於文獻 [3] 所提出的服
務品質控制協定，則必須對 802.16 及
802.11e 的原始協定大幅修改，因此會增加
整合時額外的負擔。 
因此，本計畫在無線寬頻存取網路上
提出了具有統一連接導向架構之整合型
WiMAX/WiFi 無線網路系統。此系統中包
含一個新穎的  WiMAX/WiFi 無線存取
(W2-AP) 裝置與 WiFi 節點，以管理
WiMAX/WiFi 的介面。另外，在 WiFi 節
點中嵌入了 802.16 用戶平台 (Subscriber 
Station，簡稱 SS) 的 MAC 協定以取代原
有 802.11 MAC 協定之功能。整體而言，
W2-AP 裝置和所設計的MAC 協定可以支
援以連結為導向的傳輸以及不同服務類別
的串流。同時，本論文亦提出名為兩階層
式的頻寬配置機制 (Two-tier Hierarchical 
Bandwidth Allocation ，簡稱 THBA)，以分
配 WiMAX/WiFi 之網路頻寬。此機制可使
無線區域存取網路與無線都會存取網路的
存取方式達成一致性。因此，可提供此整
合型網路一致性的服務品質以及頻寬管
理。 
 
1. 整合型 WiMAX/WiFi 架構 
 
本 章 首 先 將 透 過 所 提 出 的 
整 合 型 WiMAX/WiFi 網路架構圖進行
討論，如圖一 (a) 所示之單點對多點
(Point-to-Multipoint，簡稱 PMP)網路拓樸。
此 拓 樸 中 ， 單 一 的 WiMAX 基地台
(WiMAX Base Station，簡稱 BS) 運作於具
有執照許可的特定頻譜上，並且與多個 SS
及 W2-AP 裝置相連。因此本網路架構中，
WiMAX 系統可透過連結數個 W2-AP 裝
置提供後置式網路服務以存取網際網路。
如圖一(a)所示，每個 WiFi 熱點皆透過
W2-AP 裝置與 BS 連結。其中，BS 和 SS 
所建立的連線是專門提供某個具有
WiMAX 介面卡的使用者使用。而在 BS 
與 W2-AP 裝置所建立的連線則是由與
W2-AP 裝置連結之 WiFi 節點所共享，使
得 WiMAX 系統亦可透過 W2-AP 裝置提
供 WiFi 使用者享受網際網路服務。接下來
將介紹所提出 WiMAX/WiFi 整合型網路
之 MAC 協定層模組，其架構圖如圖一(b)
所示。首先將介紹兩個主要的功能模組， 
分別為 MultiMAC 與 SoftMAC，細節如
下： 
 7
 
人化熱點存取之需求，每個使用者僅須配
備經韌體更新後之 WiFi 網路介面卡 (即
本文所提出的 WiFi 節點架構) 與附近的
W2-AP 裝置連結，藉由大樓內的有線後置
式網路存取網路服務。當離開大樓時，他
們可以攜帶 W2-AP 裝置以便透過戶外的
WiMAX 服務存取網際網路。此種個人化
熱點服務使得上述情境在近期內利用所提
出的架構得以實現，使得使用者可藉此架
構在戶內或是戶外皆可享受網路服務。 
 
2. 頻寬分配與管理 
 
本章將介紹一套新穎的 THBA 頻寬
分 配 機 制 及 傳 輸 框 架 結 構  (Frame 
Structure)以符合先前介紹之網路架構的需
求。基於在 WiFi 與乙太網路之間資料傳輸
之技術背景，本論文僅針對 WiFi 與
WiMAX 系統間的封包傳遞與頻寬分配方
法進行說明。在此假設 WiFi 與 WiMAX 
所使用的頻道不同，並忽略頻道干擾問題。 
 
THBA 機制 
 
由於 WiMAX 網路系統是以連結為
導向的寬頻存取技術，每個服務串流皆對
應到一個獨立的連線識別 (Connection 
Identification，簡稱 CID) [6][7]，當此串流
提出頻寬請求以及建立連結時，將依循連
結為導向的機制以提供不同服務類別的需
求。為了滿足使用者的服務需求，BS 會將
多個 SS 請求的頻寬進行排程，接著依據
服務類別分配給每個 SS，而 SS 將分配到
的頻寬進一步排程，最後配置給 SS 中所 
有服務的連線。然而，WiFi 技術並不能支
援此類型頻寬分配機制。例如 802.11e 標
準 [8]所定義之增強型分散式協調存取方
法(Enhanced Distributed Channel Access，簡
稱 EDCA)，主要針對具備碰撞避免之載波
感測多重存取  (Carrier Sense Multiple 
Access with Collision Avoidance ，簡稱
CSMA/CA) 機制定義不同的優先權類別
存取頻道的機會。使用 EDCA 存取機制可
以使不同類別 (Access Category, 簡稱 AC) 
的資料以不同的競爭條件  ( 即不同
Arbitration Inter-Frame Spaces 、
Contention-Windows 大小) 進行傳送，以
保證具有較高優先權的串流不受其他較低
優先權的串流影響其服務品質。 
由此可知 WiMAX 與 WiFi 為兩種截
然不同網路存取技術，尤其在頻寬分配方
式以及服務品質保證機制上大相逕庭。而
WiMAX 乃基於分時多工的存取機制，比
WiFi 系統有更佳的頻道使用率。另外，其
連結為導向的頻寬配置機制具有服務品質
可預測之特性，較 CSMA/CA 頻寬競爭機
制更為穩定。因此，WiMAX 技術可提供
比 802.11 技術更好的串流服務品質。經由
上述比較得知，為了讓 WiFi 熱點能提供與
WiMAX 系統相似之連結為導向存取協
定，則必須在 WiFi 網路介面卡及存取點裝
置的 MAC 協定層中，增加此功能模組(即
先前所提之架構)。如此一來，新增後的
WiFi 節點與存取點可配合 WiMAX 系統
提供以連結為導向之頻寬存取機制， 以達
成 WiMAX/WiFi 整合型網路中服務品質
及頻寬管理的一致性。 
接下來將說明如何把 THBA 頻寬分
配機制導入 WiMAX/WiFi 整合型網路
中。如圖二所示，當兩個 WiFi 節點 (Node 
#3 與#4) 送出頻寬請求 (即 CIDs #A1 與
#A2) 到 W2-AP 裝置時，W2-AP 裝置隨即
擷取並匯集這些頻寬請求，統一向 BS 送
出 (CIDs #B3)。在此須特別說明的是，當
W2-AP 裝置匯集這些頻寬請求時，會根據
請求之服務類別進行分類處理。換句話
說，W2-AP 裝置會匯集相同服務類別之請
求，進而向 BS 提出頻寬使用申請。一旦
BS 接收到匯集後的頻寬請求，會透過排程
機制分配頻寬，並以訊息告知 W2-AP 裝置
頻寬分配結果，如圖二所示，BS 將頻寬分
配給 W2-AP #2。而當 W2-AP 收到頻寬分
配訊息時，會對其所服務的 WiFi 節點依 
 9
 
階層 B 架構如圖二所示，以 BS 的觀
點，在階層 B 所運作的 W2-AP #1 與
W2-AP #2 視為在 WiMAX 網路中一般的
SS。BS 在每個框架開始時，會廣播
DL-MAP 與 UL-MAP 訊息給 W2-AP #1 
與 W2-AP #2，並且分別對其定義允許 DL 
與 UL 的傳輸長度。其中，一個在 DL-MAP 
中的 DL 同意 (DL grant) 訊息會在 DL 子
框架 K 的起始位置，透過 BS 發出的突發
封包通知 W2-AP 裝置 (或 SS) 。而一個在
UL-MAP 的 UL 同意 (UL grant) 訊息會
指明框架K 中的UL 子框架可傳輸的間隔
時間，UL 同意訊息依據先前框架 (即框架
K-1) 所發出的頻寬請求予以發送。在框架
K 的 DL 子框架中，當 W2-AP #1 與#2 收
到由 BS 發出的第一個 DL Burst 訊息，便
根據此訊息所通知的分配時間接收來自
BS 的封包。在框架 K 的 UL 子框架中，
每個 W2-AP 裝置以分時多工的方式轉送
從 WiFi 節點所傳送的資料到 BS。 
 
階層 A 的框架運作 
 
對於階層  A 的框架運作模式，以
W2-AP 裝置的觀點， WiFi 節點就像
WiMAX 網路中的 SS。而 W2-AP 裝置對
於 WiFi 節點而言亦類似 WiMAX 網路中
的 BS。如同先前描述階層 B 的協定運作
模式，每個 W2-AP 裝置以週期性的廣播框
架給予在所連結的 WiFi 節點。當 W2-AP
裝置收到由BS 在框架K 發出的UL-MAP 
時，此 MAP 定義該 W2-AP 裝置所同意的
頻寬請求訊息 (即在框架 K-1 所請求的頻
寬)。此時，每個 W2-AP 裝置會採取 THBA
機制，進一步決定其連接的每個 WiFi 節點
應分配多少頻寬。因此，W2-AP 裝置藉由
WiMAX 介面卡收到 UL-MAP，隨即重新
分配所得的頻寬，接著利用 WiFi 介面卡將
重新分配後的頻寬以控制訊息告知其連接
的每個 WiFi 節點，使得 WiFi 節點可利用
所分配的頻寬上傳資料。 
接下來將針對階層 A 框架結構詳加
探討，圖三中 SFG (Second-hop Frame 
Gap，簡稱 SFG) 所呈現的是一個位於框架
K 與框架 K’之間的間隔時間。一般而言，
SFG 考慮以下幾點進行計算: 
 BS 於框架 K 時廣播訊息至 W2-AP 
所 花 費 的 時 間  ( 即 Transmission 
delay)。 
 傳播延遲。 
 W2-AP 對DL-MAP 與UL-MAP 的計
算時間。 
由於先前假設忽略傳播延遲與計算時間延 
遲。因此，圖三中的 SFG 僅包含 BS 於框
架 K 時廣播控制訊息至 SS 所耗費的時
間。而設計 SFG 的目的乃透過延遲框架 K’
的時間，提供 W2-AP 裝置有足夠的反應時
間處理 BS 所廣播的 DL-MAP 與 UL-MAP 
控制訊息，並且依此訊息計算各個 WiFi 節
點可獲得頻寬的配置，進而在框架 K’時對
各個 WiFi 節點進行頻寬分配。 
另外在圖三亦顯示階層 A 與階層 B 
的 BW-REQ 間隔同為 TBS 長度。假設在框
架 K’的 BW-REQ 區間結束時間與框架 K 
的 DL 子框架結束時間一致。因此，框架
K’的 DL 子框架長度為： 
SubFrameLen k BSDL T SFG T         (1) 
其中 kT 為 DL 子框架 K 的長度。而對於框 
架 K’的 UL 子框架長度部分，為了達成在 
WiMAX 與 WiFi 網路中框架長度的一致
性，框架 K’的 UL 長度必須增加 BST SFG 。 
因此，在 UL 子框架 K’的 BW-REQ 區間
結束時，位於框架 K 的 BW-REQ 區間會
緊接著開始。因此 W2-AP 裝置與 WiFi 節
點利用 BW-REQ 區間上傳頻寬請求，這樣
接續不斷 (back-to-back) 的頻寬請求可確
保W2-AP 裝置預先接收匯集從 WiFi 節點
所需的頻寬請求，進而從容地利用框架 K 
的 BW-REQ 區間上傳匯集後的頻寬請求。 
對於在 DL 子框架 K’時，W2-AP 裝
置使用排程機制決定不同的 WiFi 節點可
接收多少封包資料單元。在此須特別考慮
這些 MAC 封包資料單元是從 BS 在 DL 
子框架 K-1 時傳給 W2-AP 裝置，W2-AP 
裝置會接收並且立即轉送給 WiFi 節點，若
欲傳送的資料無法在目前的框架 K’-1 傳
至 WiFi 節點，則會延後至框架 K’再傳
送。在 UL 子框架 K’中間隔 BS T 後，
W2-AP 裝置會安排各個 WiFi 節點傳送
Burst 訊息上傳至 BS。對於 W2-AP 裝置所
同意給予 WiFi 節點上傳頻寬的總和，會等
同於 BS 所分配至 W2-AP 裝置的頻寬總
 11
 
 
裝置只當作WiFi與WiMAX之間的橋
接器以轉換期傳輸封包。另外頻寬分
配如同 Independent 的機制，只依據 
W2-AP 佇列長度向 BS 提出其頻寬請
求。 
 
數據結果 
 
圖四表示其端點對端點延遲變化量分
別對不同的網路流量 (圖四(a)) 以及網路
中不同 VoIP 的連線數 (圖四(b)) 進行評
估(註:每個 WLAN 內部設置有五個 WiFi 
節點)。經由觀察此圖後發現，當網路流量
增加時，所有頻寬分配機制的端點對端點
延遲也逐漸增加。但是，本計畫所提出的
THBA 機制產生比其他機制較低的端點對
端點延遲，這是由於統一連結為導向的頻
寬配置方式所致。統一連結為導向的頻寬
配置方式，W2-AP 能在當下框架聚集 WiFi 
節點頻寬請求以立即送至 WiMAX BS，並
且可在下一框架中得到 BS 的同意將 WiFi 
節點的資料封包立即送往基地台。換句話
說，從 WiFi 節點佇列中的封包送至 BS 所
耗費的時間只需一個框架間隔。此模擬分
析驗證了 THBA 在不同服務類別的串流
可以有效使用頻寬以傳輸資料。另外，亦
可滿足其 VoIP 服務所需的服務保證，不會
因網路負載量與 VoIP 連線數增加，造成
對其所保證的延遲時間有劇烈增加的現
象。 
圖五表示網路當 WiFi 節點數量不同
對其端點對端點延遲變化量之影響。此實
驗，將 WiFi 節點由 5 個增至為 35 個以觀
察其延遲變化情形。經觀察此圖後可得
知，在較低的網路流量 (WiFi 節點低於 10 
個) 時，由於此情況下，所有 WiFi 節點的 
 
上傳佇列幾乎是空的。 
因此，各個機制的延遲時間曲線以緩慢的
方式漸漸升高。無論如何，在較高網路流
量時 (WiFi 節點高於 10 個)，各個機制當
中的不同網路服務型態都會劇烈升高。尤
其是 WiFi-EDCA 機制，此機制運作時所
呈現的延遲時間遠高於 THBA 機制與
Independent 機制。這個結果是由於隨著
WiFi 節點增加，相同網路類別的串流服務
也因此增加，因而產生劇烈的競爭造成延
遲時間較高於其它機制。另外，可以很清
楚觀察到在本論文所提出的 THBA 機制
得到的延遲時間都優於 Independent 機
制。顯然地，此現象可再次驗證 THBA 機
制中，當 WiFi 節點依據其佇列長度向
W2-AP 裝置提出請求後，W2-AP 裝置可在
匯集後立即轉送此頻寬請求至 BS，並且可
在下個框架時得到 BS 頻寬同意，以將
WiFi 節點資料立即送達 BS。因此，在
THBA 的各個服務類別串流延遲時間亦相
對的減少。 
 
4. 結論 
 
本計畫提出一套統一連結導向整合型
架構以結合 WiMAX 與 WiFi 網路系統。 
 13
 
圖二、在 1T 前一個週期的起始點排程下一個 1T 週期內 1G 的排程 
 
源在通訊上。因此，如何在電池供應的有
限能源下有效的延長 WiMAX 行動裝置的
運作時間將是 WiMAX 是否能成功的關鍵
因素之一。 
因此，本計畫於此年度針對 WiMAX
網路提出一個應用於 IEEE 802.16 網路之
整合性節能排程演算法 (Integrated Power 
Saving Scheduling Algorithm for IEEE 
802.16 PMP Networks，簡稱 IPSS)。再者，
為了證明本計畫所提出的 IPSS演算法的效
能，在本年度亦同時提出一個針對 IEEE 
802.16e 網路整合性節能排程演算法之分
析。 
 
5. IPSS架構介紹 
 
 
IPSS 使用雙層 (two-level) 的排程策
略，對 MSS 進行一般模式與睡眠模式的控
制，如圖六所示，演算法的排程週期可分
為排程週期 (scheduling cycle) 與子排程
週期 (sub-cycle) 兩種，其中設定排程週期
為子排程週期的 β 倍 (β 為整數)，子排程
週期的時間長度則為訊框長度 (frame) 的
α 倍(α 為整數)。 
在進行排程時，IPSS 將 MSSs 依據連
線性質區分為兩群組，一種為具有需要即
時性的服務 (如 UGS、rtPS) 之 MSSs 將納
入第一群組 G1，另一種則為僅需要非即時
性的服務 (如 nrtPS) 之 MSSs 則納入第二
群組 G2。納入群組後的 MSSs 將根據加入
BS 的順序給予加入的 MSSs 從 0 開始遞增
的成員編號。為了方便敘述以 1T 和 2T 分別代
表子排程週期與排程週期的時間長度，
IPSS 將依照下列兩步驟進行排程。 
步驟一: 根據最小頻寬的需求，計算 1T 和 2T
之週期時間長度，以及在單一子排程週期
中，G1 和 G2 的通道各自使用時間 1GL 與
2GL 。 
步驟二: 透過比例分配之方法計算群組中
各 MSS 所應預留的頻寬資源，以及各 MSS
的起始覺醒時間。令 fT 表示一個 802.16 的
訊框時間長度，子排程週期的長度 1T 計算如
下: 
1 , arg max( , delay constraint),f fT T i T i N       
(1) 
接著計算排程週期的長度 2T 如下: 
2 1,T T N            (2) 
在公式 (1) 及公式 (2) 中，子排程的長度
為根據第一群組MSS的QoS參數 (定義為
延遲限制(delay constraint)) 決定，其中排
程週期的長度可藉由與子排程週期的倍數
β 來調整。從整個排程週期的角度觀察，
IPSS 會在每個子排程週期 ( 1T ) 內針對第
一群組內的各個 MSSs 進行排程一次，並
在 β 倍子排程週期後 ( 2T 公式(2)) 才對第
二群組的 MSSs 進行排班，運作情形如圖
七所示，第一群組的 MSSs 可在前一個子
排程週期的起始點便得知下一次子排程週
期內的覺醒時間點及覺醒時間長度。由公
式 (1) 取得 1T 的時間長度後，IPSS 接著計
算在第一群組中各MSS在子排程週期內分
配到的存取時間長度： 
1
min
1 1
1 2
min
1 1 1
(1, , )
(1, , )
j
ji
N
j k
G N
i j k
R j k
L
R j k

 

  
 


       (3) 
其中， min (1, , )R j k  代表第 i 個群組內第 j 個
MSS 中第 k 條連線的最小頻寬，Ω(j)表示
在 MSS j 中的連線總數，又 iN 表示第 i 群 
 15
組可用頻寬區段的次數，若有出現越過第
一群組可用頻寬區段的情形，則第二群組
的成員便須延後覺醒的時刻至下一個子排
程週期內第二群組的可用頻寬區段 ( 2GL )
內: 
1
1
0
1 1 2
02
(2, )
( ) (2, ) %
k
k
II II i
k G G
iG
b i
U x t L T b i L
L




        
 
 
(10) 
其中，
1
2
0
(2, ) /
k
G
i
b i L


 ，為計算出可能跨越的
子排程週期數目，
1
2
0
(2, ) %
k
G
i
b i L


    ，則為計
算出在第二群組可用頻寬區間( 2GL )中的
覺醒時刻。簡單來說，IPSS 會根據各 MSSs
的最小頻寬需求分配出該MSS的可用頻寬
並計算出該 MSS 應在何時醒來進行傳輸；
利用此兩項資訊，BS 將在前一次的排程週
期 (或子排程週期) 起始時替 MSSs 保留
頻寬，並透過 MOB-SLP-RSP 訊息告知
MSS 下次進入睡眠模式的時間，以及離開
睡眠模式的時間 (定義為醒來的時間)。 
 
2. 系統分析 
 
在介紹系統分析前，必須先討論針對
此系統我們所關心的部份。此系統採用
PSC III 的睡眠類型在 MSSs 覺醒時告知睡
眠週期的長度，透過 BS 的分配將頻寬適當
的分配給底下的 MSSs 進入睡眠的時間和
視窗大小。因此，如何找出最佳的排程週
期以及不影響 QoS 的情況下控制網路負載
量，成為本計畫中主要關心的方向，以下
將針對此兩部份分別進行討論。 
 
節能效果及延遲時間找出最佳β值 
 
從架構的角度觀察對第二群組的
MSSs 而言，β 值的增加可對越長的週期進
行排程進而累積較多的資訊才進行傳輸，
但此種情形卻使資料延遲的時間增長，因
此在找出最佳 β 值時，勢必將這兩項因素
同時考慮在內。最佳 β 值的選取有以下之
三步驟：第一步驟為估計出在不同的 β 下
節能效果，第二步驟為估計平均延遲長
度，最後第三步驟則為根據可加性效用函
數 (additive utility function) 依網路的情況
設定各自的權重值以找出最佳 β 值之解。 
再者，為方便分析，我們做了以下的
假設：將 MSS 分為兩類，其中有 1N 個 MSSs
屬於第一群組且使用 1GL 的時段；有 2N 個
MSSs 屬於第二群組且使用 2GL 的時段。此
外假設同一群組的 MSSs 擁有相同的連線
類型，但各條連線間各自獨立不互相影響。 
 
睡眠比例(ε) 
 
一般而言，當 MSS 處於睡眠狀態的時
間越長，其節能的效果越佳。為了評估節
能的效果，我們定義ε為進入睡眠模式的
時間與整段排程週期之比例，稱之為睡眠
比例，此比例用來表現節能效果的好壞，
比例值越高節能效果越佳。 
首先，針對第一群組的 MSSs 進行睡
眠比例的計算。由於，屬於第一群組的
MSSs 必須在每個子排程週期醒來進行傳
輸，因此在整個排程週期裡屬於第一群組
的 MSSs 必須醒來β次，並在指定的覺醒
期間公式 (5) 進行資料的傳輸其餘皆維持
在睡眠模式。由於 IPSS 採用的是以訊框 
(frame) 為基本排程時間單位，因此 MSS
只有在整段訊框內皆不需醒來時才切換至
睡眠模式，因此第一群組 MSSs 的睡眠比
例算式如下： 
1
2
(1, )
f
f
G
b i T
T
T
 

          
       (11) 
其中， (1, )
f
b i
T
    
為在第一群組內的第 i個MSS
分配到在子排程週期 ( 1T ) 內醒來進行傳
輸的訊框數目。 
因此，第二群組 MSSs 的睡眠比例也
採用上述的相同觀念，透過第二群組 MSSs
的排程週期內醒來的訊框數目與排程週期
之比例做為節能比例，如下： 
2
2
(2. )
f
f
G
b i T
T
T
 

          
        (12) 
其中， (2, )
f
b i
T
    
為在第二群組內的第 i 個
MSS 分配到在排程週期 ( 2T ) 內醒來進行
傳輸的訊框數目。  
 17
 
圖九、模擬的網路拓墣 
表 2、即時性封包產生的模式 
Service Type UGS rtPS 
Packet Size 160 bytes 120 ~ 200 bytes 
(Uniform) 
Inter-arrival Time 20 ms 20 ms (On-Off mode) 
Avg. Data Rate 64 kbps 64 kbps 
表 3、非即時性封包產生的模式 
Service Type nrtPS 
Packet Size 500 ~ 1500 bytes (Uniform) 
Inter-arrival Time  40 ms (Exp.) 
Avg. Data Rate 200 kbps 
表 4、模擬劇本 
Scenario G1＇ connections G2＇ connections 
1 UGS nrtPS 
2 UGS+rtPS nrtPS 
3 UGS+nrtPS nrtPS 
4 UGS+rtPS+nrtPS nrtPS 
 
MAP  overhead、IEs (Information Elements)
以及 SLP (Sleeping response)，如圖八 (此
處假設α=4,β=2) 所示，每個 frame 分為
個時槽。 
為了清楚表達三項主要控制訊息的頻
寬消耗情形，以下將先針對使用 IPSS 節能
時，控制訊息的行為介紹。在每個訊框起
始時 BS 會針對在該訊框內必須醒來的進
行傳輸的 MSS 發送 MAP 訊息，其內容包
含避免碰撞、作為 UL 和 DL 中間分隔的時
區以及 MAP 訊息傳輸所花費的時間，假設
MAP 訊息在每個訊框中占用個時槽，因
此，對於整段排程週期長度而言，將花費
  個時槽進行 MAP 的通知。 
除了在訊框一開始進行通知的 MAP
訊息外，BS 還需針對在該訊框中必須進行
傳輸的傳輸的 MSS 進行個別的 IE 通知，
因此若有 個 MSS 必須被告知進行傳輸，
則 BS 必須佔用 個 IEs 的傳送訊息時間，
由於每個 IE 的長度為 5 bytes (40 bits)，且
根據傳輸速度的標準 IE傳送訊息的傳輸速
度屬於控制訊息之傳輸速度 (每單位時槽
可傳輸 48 bits)，因此每傳送一個 IE 訊息恰
佔用該訊框中的一個時槽時間。在本研究
中，假設每個 MSS 皆可以在分配的訊框中
完成傳輸，且每個 MSS 皆至少被服務一
次。若考慮在整段排程週期的長度，由於
第一群組 1G 的 MSS 在每個子排程週期皆
收到一次 IEs 的訊息，因此將接收到  次的
IEs 訊息，而第二群組 2G 的 MSS 則僅接收
 19
 
圖十、不同的  睡眠比例的模擬與分
析 
802.16 的網路 中，設置一個 BS 作為網路
的主控者，另外在周圍 500 公尺的範圍內
隨機散佈 MSS，BS 與 MSS 之間的存取方
式遵循 IEEE 802.16 通訊協定。 
本模擬採用 OFDMA 的物理層，相關
設定參考表一。在模擬中各連線的設定參
考表二和表三。即時性的連線以 UGS 和
rtPS 的連線為代表，非即時性的以 nrtPS 為
代表，並使用 Poisson pattern 來模擬資料傳
輸的不規則性。表四為不同模擬劇本的設
定。 
 
模擬的結果與討論 
 
睡眠比例(ε) 
 
由圖十證明式子  (11) 和 (12) 可以
驗證睡眠比例 (ε) 的正確性。如圖十所
示，當  值設定為 4~8 之後可以明顯的看
見睡眠比例趨近於 0.925，當  值再往上設
定可以明顯看見並沒有更明顯的改善，由
此可知睡眠比例雖然會隨著  值上升而增
加，但是睡眠比例會在某定值後逐漸收斂。 
圖十一是根據網路上不同的負載的情況進
行模擬。圖十一(a)~(d)可以發現網路負載
增加時節能效果會受到些微影響，並且受
影響的組合又會與連線類型相關。如圖十
(a)受到網路負載的影響較大，因為在劇本
一(scenario 1) 的連線組合在第一群組的連
線中僅有 UGS 的連線，其中 UGS 的連線
又與網路上控制訊息的封包大小差異不
大，因此隨著 MSS 的數目增加網路上控制
訊息佔用頻寬的情形也就更明顯的影響網
路效能，因此整體節能效果將下降地明顯。 
 
Additive utility function  
 
 
(a) 
 
(b) 
 
(c) 
 
(d) 
圖十一、(a) Scenario 1(b) Scenario 2 (c) 
Scenario 3 (d) Scenario 4 
接下來，進行尋找最佳 β 值的模擬，
根據公式 (18) 中計算出滿意度的量值，如
圖十二顯示出不同的權重值 (W) 在模擬
與分析的表現，(其中，此處連線設定為表
4 的劇本一 (Scenario 1)，各群組的 MSSs
數目為 20，同圖十之設定)。從圖十二得
知，不同的權重值將對滿意度有不同程度
 21
限制進入此 BS 服務中的 MSSs 數目，藉以
同時達成最佳的節能效果且保證連線品質
不受節能排程之影響。 
 
4. 結論 
 
在無線網路中，具有移動性的 MSS 大
多使用電池作為運作電力的來源，因此如
何減少能源的消耗以延長MSS的運作時間
便成為一項重要的課題。在 IEEE 802.16e
標準中，針對節能議題制定了一系列的標
準。除了平常運行的狀態外，為了減少通
訊能源的消耗，MSS 可在沒有資料需要進
行傳送/接收時，進入所謂的睡眠模式以減
少能源的消耗。  
此外在標準裡還制定了節能類別
(Power-Saving Class)，然而標準裡所制定的
節能類別並未將排程的情形加入考量，因
此若在多種不同類型的連線排程同時出現
時，MSS 將因無法有效率的進入睡眠模式
而使節能效果大幅下降。因此，為了更有
效率的使用頻寬並增加節能效果，本篇論
文將針對一種以MSS為基礎並將整體排程
加入考量來進行睡眠模式的整合性節能排
程演算法進行數學。 
 
支援無縫移動式網路服務以提供整合性情
緒管理服務 
 
在此學年度，本計畫會針對目前最為
矚目的 IEEE 802.16j 網路提出一個針對資 
 
圖十五、IEEE 802.16j 穿透式中繼
（transparent relaying）的訊 
框結構 
 
源分配之有效率的排程演算法。 
 
1. IEEE 802.16j Transparent Relayin
g 網路架構 
 
IEEE 802.16j 標準定義「穿透式中繼
（ transparent relaying）」的傳輸模式來提
升網路容量（increase capacity）。此模式
下的資源排程由基地台所負責，屬於集中
式的排程方式，並且限定於最多兩點跳躍
（two-hop）的中繼網路架構。圖十五為
IEEE 802.16j 的 transparent relaying 的訊
框結構 
（ frame structure ） 。一個訊框切割成兩
個子訊框（subframe），分別是用於傳送下
行資料的下行子訊框（downlink subframe）
與用於傳送上行資料的上行子訊框（uplink 
subframe）。為了支援中繼的功能，下行子
訊框分為以下兩個區塊： 
 下行存取區（downlink access zone）: 
BS 使用此區傳送資料給它所直接服務的
D-MS 與 RS，包括訊框控制標頭（Frame 
Control Header）、下行地圖（DL-MAP）
與上行地圖（UL-MAP）訊息。 
 穿透區（transparent zone）: 
RS 使用此區將所收到的資料傳送給所服
務的 MS (簡稱 R-MS)。此外，標準中亦提
供「選擇性的傳輸」。在此傳輸模式下，
BS 可使用此區傳送資料給 D-MS，或與
RS 做一個合作性（cooperative）的傳輸
[20-22]。 
上行子訊框亦分為以下兩個區塊： 
 上行存取區（uplink access zone）: MS 
使用此區傳送資料給所連結的 BS 或
是 RS。 
 中繼區（relay zone）:RS 使用此區將
所收到來自R-MS 的資料上傳給BS。 
雖然在 IEEE 802.16j 的網路中，RS 一般
是使用解碼與前送（Decode-and-Forward）
的方式傳輸，然而，在穿透式中繼模式當
中 亦 可 以 使 用 解 調 變 與 前 送
（Demodulate-and-Forward）的傳輸方式進
行傳送。利用此種方式可以讓網路封包
（packet）在一個訊框時間之內自 BS 傳送
至 R-MS，並且仍然可以濾掉雜訊以增進
路容量。 
 
 23
 
圖十六、RSS 演算法 
 
 最大化產量（Maximum Throughput，
簡稱 Max.） 
m,nU ( )
m m
n n            (2) 
其中，
m m m
n n nC S   。 mnS 為 MS m 在子
通道所分配到的槽之個數。而
m
nC 是其平均
槽傳輸速率，根據 [5]，可由下列公式獲得： 
log(1 )m mAMC AMCn P n
S
N M
C B SNR
N
 
   (3) 
其中， AMCN 為 AMC 槽的子載波個
數， AMCM 為 AMC 槽之 OFDMA 符元個
數。 PB 為子載波之頻寬。 SN 為一個訊框之
OFDMA 符元個數。
m
nSNR 為 MS m 在子通
道之訊雜比。對於最大化產量利益函式，
產量是唯一的考量，具有較高產量的 MS 
將有較高的利益值。 
 比例公平（Proportional Fairness，簡稱
PF） 
, ( )
m
m n
m n n mU T C
            (4) 
其中， mC 為至前一個訊框為止，排程
給 MS 的平均傳輸速率（bits/slot），以下
列公式更新： 
1 1( ) 1 ( 1) ( )m m mC p C p C p
tw tw
           (5) 
( )mC p 為在訊框 p之 mC 值。tw 為視窗
大小（window size）。 ( )
mC p 為 MS m 在訊
框 p 被排程所達到的傳輸速率（bits/slot）。
公式 (1) 為本研究排程上之目標，但在
IEEE 802.16j 的資源排程上仍然有以下的
限制 
條件： 
1. 本研究不考慮空間重複利用（spatial 
reuse），且為了避免干擾上的問題，
訊框中的每個槽只能夠至多排程給一
個 RS 或一個 MS 使用，因此須滿足
下列要求： 
( , ) ( , ) 1 ,
m r
n t n t
m M r R
x x n N t
 
     
  (6) 
2. 根據中繼網路的傳輸限制， IEEE 
802.16j 將 下 行 子 訊 框 切 割 成
downlink access zone 與 transparent 
zone 兩個區塊提供分段傳輸使用。在
downlink access zone 用於將資料從
BS 傳送至 RS，因此，RS-MS 鏈結不
可在此區塊排程，必須滿足下列公式
之要求： 
( , )
1
0
T
m
n t
t n N r R m M
x


   
 
      (7) 
3. 接續 2，在 transparent zone 中不可排
程 BS-RS 鏈結，必須滿足下列限制： 
( , )
1
0
T
r
n t
t T n N r R
x
   
 
        (8) 
4. 本研究考慮 RS 使用解調變與前送的
方式進行傳輸，因此對於一個 RS 來
說，在一個訊框內所接收的資料量必
須等於所傳送的資料量，所以須滿足
下列公式之限制： 
( , ) ( , )
1 1 r
T T
r r m m
n n t n n t
t n N t T n N m M
C x C x r R

     
     
 
(9) 
 25
不同之傳輸速率
m
nC 與
m
m
r
naC ），R-MS m 將
會利用 βm.n 的時間在第 1 點跳躍鏈結的
傳輸，並將剩下的時間使用在第 2 點跳躍
鏈結，來達到兩條鏈結能夠傳輸相同的資
料量（滿足限制公式(9)），因此必須滿足
下列式子： 
, ,( )mm
r m
na m n n m nC T C T T          (11) 
其中βm.n 即為R-MS m 使用在第1 點
跳躍鏈結所占之全部時間的時間比例，也
代表所期望的 zone boundary 位置，經過整
理可獲得下列式子 
, /( )mm
rm m
m n n n naC C C          (12) 
因此，R-MS m 在一個下行子訊框時
間 T 的實際產量為 ,
m
m
rm
n m n naT C   ， mn 將產
量帶入利益函式即可獲得 R-MS 之實際利
益增進值，並在 line 8 選取具最高利益增
進值之 R-MS，記作 k。 
雖然  R-MS 有自己期望的 zone 
boundary 位置（即 βk.n），但子訊框已有
決定的 zone boundary 位置。演算法在 line 
9-16 即是滿足子訊框的 zone boundary 傳
輸限制下，排程給所選出的 R-MS 最大的
資料量。而最大的資料量取決於兩個即將
排程的子通道中（ mna  與 n），所能夠排
程的資料量較小的子通道。因此，若子通
道 mna 所能夠排程的資料量較小（ line 
9-12），便將子通道 nam 上的所有槽（即
sa）都排程給 R-MS 的第 1 點跳躍鏈結使
用，並在子通道排程相同資料量所需的槽
之個數（即 st）給第 2 點跳躍鏈結使用；
同樣的，若子通道 n 所能夠排程的資料量
較小（line 14-16），便將子通道 n 上的所
有槽（即 st）都排程給 R-MS 的第 2 點跳
躍鏈結使用，並在子通道 mna 排程相同資料
量所需的槽之個數（即 sa）給第 1 點跳躍
鏈結使用。RRS 演算法在 line 17 計算出對
排程的 R-MS 可造成之實際產量
k
n 。 
然而，RRS 演算法為了有效利用頻
寬，考慮了 R-MS 在 BS 佇列內的資料量
qk ，若佇列內的資料量小於目前給予的傳
輸量
k
n ，便在 line18-20 對分配的槽個數
（sa 與 st ）進行修正，至多給予 qk 的傳
輸量。演算法在 line 21 進行實際的排程。
由於將一個 transparent zone 之子通道排程
完，才能對 transparent zone 的下一個子通
道進行排程，因此，在排程完一個
transparent zone 的子通道時，可能因為下
列二個原因，使得在 downlink access zone
中對第 1 點跳躍鏈結的排程會有多個碎裂
區塊： 
 Line 9-13：當使用完在 downlink access 
zone 的一條子通道中可用的槽，但
transaprent zone 子通道仍有可用的
槽，便會再次對 transparent zone 的子
通道排程，也會再次的在 downlink 
access zone 中選一個區塊的槽來提供
第 1 點跳躍鏈結使用。 
 Line 18-20：BS 內的佇列資料量小於
給與的傳輸量，由於 transaprent zone 
之子通道因為 R-MS 資料量不足以使
用 完 可 用 的 槽 ，  便 會 再 次 對
transparent zone 的子通道排程，也會
再次的在 downlink access zone 中選
一個區塊的槽來提供第 1 點跳躍鏈結
使用。 
為了在接下來的排程中與 D-MS 比較
利益增進值（utility gain），演算法必須記
錄在一個 transparent zone 的子通道排程
中，這些 R-MS 總共所使用的資源與排程
所獲得 
的 利 益 增 進 值 ， 因 此 將 這 些 在
downlink access zone 中所使用的槽（所有
區塊）記錄下來。在 line 22 將 R-MS 在目
前排程的子通道 n，將其用於第 1 點跳躍
鏈結所使用的子通道 kna 紀錄在 nREC 中，所
使用的槽個數記錄在 k
na
nSA 中，並在 line23 
累加此子通道 n 排程給R-MS 所造成之利
益增進值 Un（utility gain）。 
 步驟二：將剩餘之槽對 D-MS 進
行排程（line26-31）: 
RRS 演算法將在之後的步驟比較
R-MS 與 D-MS 兩個群組的利益增進值
（utility gain），將會把槽排程給較高利益
增進值的群組。而為了避免 D-MS 群組有
可用的槽不使用，卻去搶奪 R-MS 已排程
之槽，演算法在 line 26-31 於比較之前將
目前尚未被排程的槽排程給 D-MS。在 line 
26 對目前仍有可用槽的子通道 n 進行排
程。針對一條子通道 n，在 line 27 的 while 
 27
 
圖十八、在隨機分布拓樸之 Throughput vs. 
Load 
 
圖十九、在隨機分布拓樸之 Fairness index 
vs. Load 
 
模擬環境與參數設定 
 
本研究使用 Qualnet 4.5 為模擬工具，
環境參數設定如表七，考慮一個 cell 內的
排程，cell 之半徑為 1500 公尺。BS 與
RS 的佈置如圖十七(a)，BS 位於 cell 的中
間，將 cell 分成 6 個等分的 sector，每個
sector 為 60 度，將 6 個 RS 佈置在等分
線上的 1/2 半徑位置。BS 發射功率為
43dBm，RS 
發射功率為 35dBm。BS-RS 鏈結不考
慮任何的 shadowingfading，BS-MS 鏈結與
RS-MS 鏈結使用標準差為 6 之 log-normal 
shadowing fading model。BS-RS 鏈結使用
k=10 之 Rician fading model，其它鏈結因
為是NLOS 的傳輸，則使用Rayleigh fading 
model。 
模 擬 的 環 境 考 慮 兩 種 拓 樸
（topology），分別是隨機分布（random 
distribution ） ， 與 邊 緣 分 布 （ edge 
distribution）。 
圖十七(b)是將一個 cell 將半徑等分成
4 等分所形成的區域，隨機將所有 MS 散
布在整個 cell 之內；邊緣分布是將 70%的
MS 隨機散布在區域 4，剩下的 30%隨機散
布在剩餘的區域。 
 
模擬結果與效能分析 
 
圖二十、在邊緣分布拓樸之 Throughput vs. 
Load 
 
 
圖二十一、在邊緣分布拓樸之 Fairness 
index vs. Load 
 
如圖十八所示，當負載（load）逐漸增
加時，網路之產量的變化。大約在負載為 7 
Mbps 時，最大產量（Max.）開始有較高
的產量，原因在於最大產量之利益值著重
於系統產量，所以當到達滿載時，最大產
量之產量會高於比例公平(PF)利益值演算
法。但是，如圖十九所示，比例公平(PF) 利
益值演算法卻具有較好的公平性於服務使
用者。以上可證明 RRS 演算法可利用不同
的利益值達成系統所需的目的。 
圖二十與圖二十一使用邊緣散布拓
樸，此拓樸是假設大部分行動用戶端位於
cell 的邊緣或是處於一些遮蔽區域(即行動
用戶端對 BS 訊號較弱的區域)，來驗證利
用 RS 所能達到的增益。圖二十與圖二十
一中，相較於圖十八與圖十九在效能上都
有明顯的衰弱。原因是在於大部分的行動
用戶端都位於 cell 的邊緣，使得這些用戶
端連接 BS 的訊號低落而選擇 RS 進行傳
輸，雖然 RS 可提供顯著的幫助，但是需
要較耗費資源進行兩段式跳躍傳輸，以及
相較於隨機分布的環境，邊緣散布拓樸中
較少數之用戶端可直接透過 BS 進行一點
跳躍傳輸，造成系統效能低落。但是，其
所達到的系統效能相較於圖十八與圖十
九，並無相差甚多，這是由於 RS 的協助
以提升用戶端之訊號品質，同時再次驗證
 29
參考文獻 
[1] IEEE Std 802.16-2004, “IEEE Standard 
forLocal and Metropolitan Area 
Networks –Part 16: Air Interface for 
Fixed Broadband Wireless Access 
Systems”, Oct. 2004. 
[2] M. Settembre, M. Puleri, S. Garritano, P. 
Testa, R. Albanese, M. Mancini and V. 
Lo Curto, “Performance analysis of an 
efficient packet-based IEEE 802.16 
MAC supporting adaptive modulation 
and coding,” 2006 International 
Symposium on Computer Networks, 
June 16-18, 2006.  
[3] Haidar Safa, Hassan Artail, Marcel 
Karam, Rawan Soudah, Samar Khayat, 
“New Scheduling Architecture for IEEE 
802.16 Wireless Metropolitan Area 
Network,” IEEE/ACS International 
Conference on Computer Systems and 
Applications, 2007 (AICCSA '07), May 
13-16, 2007.  
[4] Nararat Ruangchaijatupon and Yusheng 
JI, “Adaptive Scheduling with Fairness 
in IEEE 802.16e Networks,” The 3rd 
International Conference on Wireless 
Communications, Networking and 
Mobile Computing (WiCOM 2007), Sep. 
2007.  
[5] Fen Hou, Pin-Han Ho, Xuemin Shen 
and An-Yi Chen, “A Novel QoS 
Scheduling Scheme in IEEE 802.16 
Networks,” IEEE Wireless 
Communications and Networking 
Conference 2007 (WCNC 2007), March 
11-15, 2007.  
[6] C. Eklund, et al, “IEEE Standard 802.16: 
A Technical Overview of the Wireless 
MAN Air Interface for Broadband 
Wireless Access”, IEEE Commun. Mag., 
vol. 40, no.6, pp. 98-107, June 2002. 
[7] A. Ghosh, D.R. Wolter, J.G. Andrews, 
and R. Chen, “Broadband Wireless 
Access with WiMax/802.16: Current 
Performance Benchmarks and Future 
Potential”, IEEE Commun. Mag., vol. 
43, no. 2, pp. 129-136, Feb. 2005. 
[8] IEEE draft for Wireless Medium Access 
Control (MAC) and Physical Layer 
(PHY) specifications, “Medium Access 
Control (MAC) Enhancements for 
Quality of Service (QoS)”, IEEE Std. 
802.11e/D11.0, Oct. 2004. 
[9] Kamal Gakhar, Annie Gravey and Alain 
Leroy, “IROISE: A New QoS 
Architecture for IEEE 802.16 and IEEE 
802.11e Interworking”, in Proc. of IEEE 
International Conference on Broadband 
Networks, pp. 607-612, Oct. 2005. 
[10] Rajagopal Iyengar, Prakash lyer, Biplab 
Sikdar, “Delay Analysis of 802.16 
based Last Mile Wireless Networks”, in 
Proc. of IEEE GLOBECOM, vol. 6, pp. 
5, Dec. 2005 
[11] Qiang Ni, Alexey Vinel, Yang Xiao, 
Andrey Turlikov, Tao Jiang, 
“Investigation of Bandwidth Request 
Mechanisms under Point-to-Multipoint 
Mode of WiMAX Networks”, IEEE 
Commun. Mag., vol. 45, no 5, pp. 
132-138, May 2007. 
[12] Qualnet Simulator Home. 
http://www.scalable-networks.com/ 
[13] G.J.M. Smit, P.J.M.H., A Survey of 
Energy Saving Techniques for Mobile 
Computers. 1997, Moby Dick Technical 
Report. 
[14] A. Ghosh, D.-R.W., J.-G. Andrews, and 
R. Chen, , "Broadband Wireless Access 
with WiMax/802.16: current 
performance benchmarks and future 
potential," IEEE Communications 
Magazine, vol. 43, no. 2, pp. 129-136, 
Feb., 2005. 
[15] B. Li, Y.Q., C.P. Low, and C.-L. Gwee,, 
"A Survey on Mobile WiMAX," IEEE 
Communication Magazine, vol. 45, no. 
12, pp. 70-75, Dec., 2007. 
[16] C. So-In, R.J., and A.-K. Tamimi, 
"Scheduling in IEEE 802.16e Mobile 
WiMAX Networks: Key Issue and a 
Survey," IEEE Journal on Selected 
Areas in Communications, vol. 27, no.2, 
pp. 156-171, Feb., 2009. 
[17] Y. Xiao, "Energy Saving Mechanism in 
the IEEE 802.16e wireless MAN," IEEE 
Communications Letters, vol. 9, no.7, 
pp. 595-597, July, 2005. 
[18] QualNet Simulation Home, 
http://www.scalable-networks.com/. 
[19] MATLAB Home, 
http://www.mathworks.com/products/ma
 31
附錄 (研究成果) 
國際期刊論文 
1. Hui-Tang Lin; Chia-Lin Lai; Wang-Rong 
Chang; Sheng-Jhe Hong, “Design and 
Analysis of a WDM EPON for 
Supporting Private Networking and 
Differentiated Services,IEEE/OSA 
Journal of Optical Communications and 
Networking,”Vol. 2, Issue 5, pp. 266-282, 
2010 (SCI) 
國際會議 
1. Hui-Tang Lin; Chia-Lin Lai; Wang-Rong 
Chang; Chin-Lien Lui, “FIPACT: A 
Frame-Orented Dynamic Bandwidth 
Allocation Scheme for Triple-play 
Services over EPONs,” IEEE 
International Conference on Computer 
Communications and Networks (ICCCN), 
2011 
2. Hui-Tang Lin; Ying-You- Lin, “A Game 
Theoretic Framework for Resource 
Allocation in IEEE 802.16j Transparent 
Relay Networks,” International 
Conference on Game Theory for 
Networks (GameNets), 2011 
3. Hui-Tang Lin; Ying-You Lin; 
Wang-Rong Chang; Song-Ming Chen, 
“A Game-Theoretic Framework for 
Intra-ONU Scheduling in Integrated 
EPON/WiMAX Networks,” IEEE Global 
Communications Conference 
(GLOBECOM), 2009 
4. Hui-Tang Lin; Zhong-Huan Ho; 
Hung-Chen Cheng, Wang-Rong Chang, 
“SPON: A Sotted Long-Reach PON 
Architecture for Supporting 
Internetworking Capability,” IEEE 
International Conference for Military 
Communication (MILCOM), 2009 
5. Hui-Tang Lin; Chia-Lin Lai; Wang-Rong 
Chang; Sheng-Jhe Hong, “An Analytical 
Framework for a WDM EPON with 
Differentiated Services,” IEEE 
Internation Conference on 
Communication and Networking in 
China (ChinaCom), 2009 (Best Paper 
Award) 
6. Hui-Tang Lin; Ying-You Lin; 
Wang-Rong Chang; Rung-Shiang Cheng, 
“An Integrated WiMAX/WiFi 
Architecture with QoS Consistency over 
Broadband Wireless Networks,” IEEE 
Consumer Communication and 
Networking Conference (CCNC), 2009 
7. Hui-Tang Lin; Rung-Shiang Cheng; 
Li-Jun Guo; Yuen-Fu Chiu, “Integrated 
Power-Saveing Scheduling for IEEE 
802.16e Networks,” Iternational 
Computer Symposium (ICS), 2008 (Best 
Paper Award) 
 
國內會議 
1. 林輝堂 ;林英佑 ;孫仲銳 , “針對 IEEE 
802.16j 穿透式中繼網路中有效資源排
程,” The Sixth Workshop on Wireless Ad 
Hoc and Sensor Networks, 2010 
2. Hui-Tang Lin; Ming-Che Chen; 
Wang-Rong Chang; Chi-Wei Lin,” A 
Path-Aggregation-Tree Multicast Routing 
Protocol in Wireless Sensor Networks,” 
National Computer Symposium (NCS), 
2009 
3. 林輝堂 ;程榮祥 ;邱元甫 ;應用於 IEEE 
802.16 網路之整合性節能排程演算法, 
Wireless Ad Hoc and Sensor Networks 
Conference (WASN'08), Tainan, Taiwan, 
Sep. 4-5, 2008 
lem, the authors in [13] presented a ring-based EPON
and a dynamic bandwidth allocation (DBA) scheme to
enable a fully distributed intercommunication capa-
bility among all the ONUs in the EPON. However, the
proposed scheme not only required the original control
protocol to be significantly reworked, but also failed to
satisfy the requirement for backward compatibility
with the IEEE 802.3ah multipoint control protocol
(MPCP) [1].
The current study presents what we believe to be a
novel WDM EPON system based on an arrayed-
waveguide-grating (AWG) module [14–16] to support
the requirements of high-speed access networks and
to provide private networking capability. The pro-
posed WDM EPON architecture has a full-duplex tree
topology, in which a dual-fiber is employed to facilitate
simultaneous transmissions in the downstream and
upstream directions, respectively. Significantly, the
cyclic AWG not only enables the ONUs to access the
upstream bandwidth, but also allows them to commu-
nicate directly with one another. As a result, the pro-
posed architecture provides an efficient solution for
end users seeking a private networking capability.
The AWG permits each wavelength in the network to
be spatially reused and therefore yields a considerable
improvement in the bandwidth utilization. A DBA
scheme and a quality-of-service (QoS) provisioning
mechanism are proposed to arbitrate the access of the
individual ONU to the available upstream wave-
lengths. Furthermore, an analytical framework is de-
rived for evaluating the packet queuing delay and the
mean queue length in the WDM EPON network. The
validity of the analytical framework is verified by
comparing the results with those obtained from simu-
lations.
The remainder of this paper is organized as follows.
Section II introduces the proposed AWG-based WDM
EPON network, while Section III describes the major
components of the proposed media access control
(MAC) protocol, namely, the WDMMPCP protocol, the
DBA algorithm, and the buffer scheduling scheme.
Section IV introduces the proposed QoS provisioning
mechanism. Section V derives an analytical frame-
work to analyze the packet queuing delay and the
mean queue length within the WDM EPON system.
Section VI compares the analytical and simulation re-
sults and investigates the performance of the pro-
posed WDM EPON protocols under a variety of net-
work loads and traffic patterns. Finally, Section VII
presents some brief concluding remarks.
II. AWG-BASED WDM EPON ARCHITECTURE
This section commences by providing an overview of
the WDM EPON architecture proposed previously by
the current authors in [10].
A. Proposed WDM EPON System
The WDM EPON proposed in this study is based on
the bidirectional tree topology shown in Fig. 1. The
overall network consists of an optical line terminal
(OLT), an AWG module, and N ONUs. The OLT is con-
nected to the AWG module through a dual fiber and
resides in a central office (CO), where it connects the
access network to a metropolitan area network (MAN)
or a wide area network (WAN). Each ONU in the net-
work uses an upstream fiber for transmission pur-
poses and a downstream fiber for reception. Basically,
an AWG module with degree of D has D input ports
and output ports. All wavelengths of each input port
are routed cyclically to all the D output ports simulta-
neously without causing channel collision. Due to the
length constrains, please refer to [15,16] for the de-
tailed description of the AWG basic properties.
The AWG module enables the OLT to broadcast its
data to all of the ONUs in the downstream direction.
In contrast to traditional EPON architectures, ONUs
in the WDM EPON system presented in this study
can not only send data to the OLT, but can also com-
municate directly with one another through the AWG
module. Therefore, the traffic generated by each ONU
can be classified as either private or public. In the
former case, the packets are destined for other ONUs
attached to the same access network and are served
by allowing the ONUs to communicate with one an-
other directly, i.e., through the AWG module rather
than through the central OLT. However, in the case of
public traffic, the data packets are destined for remote
end users attached to a different access network and
are therefore routed through a MAN (or a WAN) via
the OLT.
Using the AWG module to enable direct ONU–ONU
communications has a number of advantages. First,
the burden on the border router is substantially re-
duced since it only needs to forward public traffic to a
MAN (or a WAN). Second, the need for an additional
Ethernet bridge at the OLT can be avoided if the data
frames are redirected by a layer-two bridge rather
than a layer-three router and thus the OLT architec-
ture is simplified. Third, the bandwidth waste and the
end-to-end delay increase of private traffic forwarding
for the meaningless loopback in question is signifi-
cantly avoided compared with the case of a conven-
tional EPON.
Fig. 1. (Color online) AWG-based WDM EPON.
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 267
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
nicate with an ONU in another PG, it must first de-
termine the particular wavelength that exits the AWG
and passes to the splitter associated with that PG. For
example, consider the case where ONU 0 in Fig. 2
wishes to send private data to an ONU in PG 1. To
achieve this, it must send the data on wavelength 1
to ensure that the transmitted data exits the AWG
through output port O1 and therefore passes to split-
ter S1, which is connected to PG 1.
To enable the OLT to broadcast data frames and
control messages to all the ONUs in the downstream
direction, it is connected to splitter S2, which spreads
all the wavelengths to the two combiners C0 and C1
attached to the AWG input ports. Similarly, combiner
C2, which combines all the incoming wavelengths
from the two splitters S0 and S1 attached to the AWG
output ports, enables each ONU to send upstream
traffic on 0 or 1 to the OLT. To avoid the downstream
signals sent from the OLT on wavelengths 2 and 3
looping back to the OLT, an optical filter is installed at
the output port of combiner C2, which allows only up-
stream traffic from the ONUs to enter the upstream
trunk fiber connected to the OLT.
III. WDM EPON PROTOCOL DESIGN
This section commences by introducing the pro-
posed WDM-MPCP (extended from the original MPCP
standardized by IEEE 802.3ah [1]). The WDMDBAal-
gorithm is then introduced. Finally, the proposed pri-
vate queue scheduling scheme is described.
A. MPCP Extended for WDM EPON
To ensure the compliance of the signaling protocol
used in the proposed WDM EPON scheme with the
specifications in IEEE 802.3ah, this study extends the
conventional MPCP to a WDM-MPCP in order to fa-
cilitate the proposed DBA algorithm and private
queue scheduling scheme.
In the normal MPCP operation mode, the OLT
transmits a GATE message to a particular ONU. A
GATE message typically contains a grant start time, a
grant length, and a 4 byte timestamp. However, in the
proposed WDM EPON scheme, the OLT is required to
assign a specific data wavelength for the upstream
transmission of private and public traffic from a given
ONU, and thus two additional information fields must
be added to the reserved fields of the conventional
GATE MPCP data unit (MPCPDU), i.e.,
• Grant Traffic Type 1 bit: This bit is set to 0 (or
1) to indicate that the corresponding ONU is
granted permission to transmit public (or pri-
vate) traffic.
• Grant Wavelength 1 byte: This 8 bit wave-
length identifier is used to indicate the assigned
wavelength of the transmission grant.
Once the ONU receives the GATE message, it up-
dates its local clock to the time indicated by the time-
stamp specified by the OLT in order to achieve global
synchronization with the OLT. At the grant start time,
the ONU starts to transmit its backlogged data and
continues transmission until the transmission win-
dow expires.
To ensure backward compatibility, WDM-MPCP is
specifically designed to enable non-WDM ONUs [i.e.,
ONUs in conventional time-division-multiplexing
(TDM) single-channel EPONs] [4] to coexist alongside
WDM ONUs within the WDM EPON. To achieve this,
the traffic generated from non-WDM ONUs and the
traffic generated from WDM ONUs destined to non-
WDM ONUs are both classified as public traffic. In
this way, the transmissions to and from non-WDM
ONUs can be processed using the public traffic rules
defined in WDM-MPCP and WDM interleaved polling
with adaptive cycle time (IPACT), as described below.
B. Dynamic Bandwidth Allocation
In conventional EPONs, the well-known IPACT al-
gorithm [17] is one of many possible candidate DBA
algorithms proposed to allocate upstream bandwidth
for ONUs by enabling the OLT to poll the ONUs indi-
vidually and to issue transmission grants to each
ONU in a round-robin (RR) fashion. However, IPACT
cannot support private traffic transmissions among
ONUs that share multiple data wavelengths. There-
fore, the current study presents a new DBA algorithm,
designated as WDM-IPACT, to schedule the transmis-
sions of private and public traffic on different up-
stream wavelengths.
In WDM-IPACT, an ONU is prevented from imme-
diately sending the REPORT message as soon as the
ONU transmits private data for up to the granted
window size. In other words, the REPORT message is
only permitted to piggyback by the transmission win-
dow of public traffic from an ONU. Consequently, the
bandwidth demand within the REPORT message gen-
erated by an ONU reflects the instantaneous queue
lengths of both the public and the private traffic at
that ONU.
As shown in Fig. 3, in WDM-IPACT, each polling
cycle consists of a public subcycle and a private sub-
cycle. In the public subcycle, the OLT allocates the
public bandwidth by sending GATE messages to all of
the ONUs within the network. As stated above, the
REPORT (RPT) messages sent by the ONUs in this
subcycle include a consolidated bandwidth request for
both the public and the private traffic in the queues at
the ONU. The polling behavior of this subcycle is simi-
lar to that of traditional EPON schemes. That is, in
the event that an ONU empties its public buffer, it re-
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 269
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
length 1 at a certain time index, T, by sending a
GATE message at time T−1/2 RTT0. Once ONU 0
receives this GATE message, it immediately com-
mences transmission and continues to transmit until
the assigned transmission window expires. Further-
more, from Eq. (1), the OLT also knows that the last
bit of the transmission from ONU 0 will arrive at the
attached combiner C0 (i.e., the AWG module) at an in-
terval of PROPB
0+WTT after the transmission com-
mences, where WTT is the window transmission time.
Thus, the OLT can prevent the data channel collision
problem simply by scheduling the first bit of ONU 1’s
granted transmission on wavelength 1 in such a way
that it reaches combiner C0 no sooner than time T
+PROPB
0+WTT.
The left part of Fig. 3 illustrates a transmission sce-
nario during the private subcycle of a WDM EPON
network with the system structure shown in Fig. 2.
Note that an assumption is made here that at the be-
ginning of the private subcycle of polling cycle P, the
OLT knows (via the REPORT messages received in
the public subcycle of polling cycle P−1) that ONUs 0,
1, 2, and 3 have made bandwidth requests for private
queues 0, 1, 0, and 1, respectively. Due to the spatial-
reuse feature of the 22 AWG, the OLT grants the
private traffic transmissions of ONUs 0 and 3 (ONUs
1 and 2) on data wavelength 01 to enable the
ONUs to transmit their private data simultaneously
to PGs 0 and 1 (PGs 1 and 0), respectively. As a result,
the available wavelengths within the network are
spatially reused when transmitting the private traffic
of the various ONUs connected to different combiners.
Note that private data collisions would occur at the
OLT in this scenario since the transmissions of ONUs
0 and 3 (ONUs 1 and 2) are overlapped in time on
data wavelength 01 and are routed to the OLT
through the combiner, C2. However, since the pro-
posed WDM EPON permits the ONUs to exchange
private traffic directly among themselves through the
AWG, the issue of private traffic collisions at the OLT
is not essential to be concerned with. On the other
hand, the private data might arrive at the OLT with-
out collision. The OLT must drop all the received pri-
vate data in this subcycle; otherwise, these data
frames would be forwarded to the attached router or
the Ethernet bridge. Consequently, these data frames
would come back to the OLT and then be sent to their
destination ONUs, causing duplicate private data re-
ceptions at ONUs.
2) Polling Policy in Public Subcycle: In the public sub-
cycle, the polling policy employs an efficient band-
width allocation approach, designated as the first
available-wavelength prioritized algorithm (FAPA), to
schedule the upstream transmissions of each ONU on
the first of the various wavelengths in the upstream
fiber to become available [3,5]. (Note that when more
than one wavelength can be used to route a granted
transmission in the private subcycle, FAPA is also
used by the OLT to schedule the earliest idle wave-
length to the ONU seeking a transmission
opportunity.)
The right part of Fig. 3 illustrates the polling policy
executed during the public subcycle in polling cycle P.
As shown, through the use of an interleaved polling
strategy and the FAPA, the public subcycle is estab-
lished before the private subcycle terminates by per-
mitting the OLT to send a GATE message to grant a
3840 byte public transmission from ONU 0 at a time
equivalent to the guard time interval after the preced-
ing 1500 byte private transmission from ONU 3. It
can also be seen that after the 3840 byte public trans-
mission is granted permission to transmit, the
640 byte, 2560 byte, and 1280 byte public data trans-
missions from ONUs 1, 2, and 3, respectively, are
scheduled on the earliest idle data wavelength, 1,
with a timing such that each transmission is sepa-
rated from the preceding transmission by a guard
time interval.
Since an on-demand polling policy is enforced in the
private subcycle, if all the REPORT messages re-
ceived by the OLT in the public subcycle of polling
cycle P indicate a 0 byte private bandwidth require-
ment, polling cycle P+1 involves only a public sub-
cycle. As a consequence, the polling overhead incurred
by the private traffic within each polling cycle is elimi-
nated.
3) Maximum Transmission Window Assignment: To
prevent the upstream channel from being monopo-
lized by a single ONU with a high volume of transmis-
sion data, WDM-IPACT adopts a limited service
scheme [17], in which the size of the transmission
window granted by the OLT to each ONU in a polling
cycle is limited to a maximum value of WMAX (bits).
Since the network traffic includes both public traffic
and private traffic, WMAX comprises two components:
the maximum public window size WMAX_PUB granted
in the public subcycle and the maximum private win-
dow size WMAX_PRI granted in the private subcycle,
i.e., WMAX=WMAX_PUB+WMAX_PRI. As discussed above,
in the WDM-IPACT algorithm, the REPORT mes-
sages issued by the ONUs in the public subcycles re-
quest bandwidth for both the public traffic and the
private traffic. Therefore, the OLT can determine ap-
propriate values ofWMAX_PUB andWMAX_PRI for a given
ONU on a dynamic basis by observing the ratio of
public traffic to private traffic at that particular ONU.
Consequently, the values of WMAX_PUB and WMAX_PRI
assigned to each ONU in the public and private sub-
cycles, respectively, are given by
WMAX_PUB =
PUB

WMAX, 2
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 271
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
queue is scheduled for transmission if, and only if, all
of the queues with a higher priority are empty. How-
ever, this approach may starve low-priority traffic of
the network resources and may therefore cause high
packet losses. In [23], the authors simulated the prob-
lem of providing differentiated services to EF, AF, and
BE traffic, respectively, for the case in which a strict
priority scheduling policy was enforced at the ONUs.
The results revealed the presence of a so-called light-
load penalty phenomenon, i.e., the queuing delay ex-
perienced by traffic with a lower priority increased as
the network load decreased. The authors proposed two
mechanisms for resolving this problem, namely, a two-
stage buffer method and a constant-bit-rate credit
scheme.
Although the two-stage buffer and constant-bit-rate
credit mechanisms provide an effective means of sup-
porting differentiated services in TDM EPONs, they
cannot satisfy the QoS requirements of the private
and public traffic carried in the proposed WDM
EPON. To resolve this problem, the present study ex-
tends the two-stage buffer concept presented in
[22,23] and implements a two-stage buffering module
within each ONU in the network.
A. Stage-I Buffering Space
As shown in Fig. 4, in Stage-I, each ONU is
equipped with a buffering space containing three
separate priority queues, i.e., one queue for each of
the three different classes of traffic. Upon receipt at
the ONU, the packets transmitted from the end users
are classified by checking the type of service (ToS)
field in the IP packets encapsulated in the Ethernet
frames and are then buffered in the appropriate pri-
ority queue. If a high-priority packet arrives at the
ONU, but the corresponding buffer is full, the packet
simply displaces a lower-priority packet. Conversely, if
a low-priority packet arrives at the ONU and the
buffer is full, the arriving packet is dropped [22]. As a
result, low-priority traffic may experience excessive
delays, increased packet losses, and even resource
starvation. This issue can be addressed by implement-
ing the traffic policing scheme at each ONU [19] in or-
der to monitor each type of traffic for conformity with
the corresponding maximum arrival rate, as specified
in accordance with user-defined criteria.
B. Stage-II Buffering Space
To support differentiated QoS for public and private
traffic, in Stage-II, each ONU maintains buffering
spaces of one public queue and D =2 private queues
and each buffering space is shared by three separate
traffic priorities that correspond to EF, AF, and BE
traffic classes. As a result, the second-stage buffering
spaces of one public queue and two private queues all
comprise three priority subqueues, i.e., EF, AF, and
BE subqueues (see Fig. 4). Packets within each prior-
ity queue in Stage-I are delivered via a dedicated
packet scheduler and are then buffered into the corre-
sponding priority subqueue at the target buffering
space in Stage-II depending on the MAC address ob-
served by the MAC address check module. Since in
each ONU, each buffering space at Stage-II consists of
three priority subqueues, each ONU in every public
subcycle reports the total three priority subqueue oc-
cupancies of the public queue and the selected private
queue (i.e., the total public queue length and the total
selected private queue length) when sending REPORT
messages. Hence, in each public (or private) subcycle,
data packets are extracted from all of the priority sub-
queues in the buffering space of the public queue (or
in the buffering space of the scheduled private queue)
and are then transmitted to the OLT (or ONUs). The
buffering spaces vacated by these packets are then oc-
cupied by data packets sent from Stage-I in accor-
dance with the service rate, CC AF,BF,BE,
given by the packet scheduler to each Stage-I priority
queue.
V. ANALYTICAL FRAMEWORK
Although the literature contains various analytical
models for analyzing the performance of TDM EPONs
[24–26], these models all consider the case of a single-
channel EPON environment. By contrast, this section
presents an analytical framework for analyzing the
performance of the dual-fiber WDM EPON shown in
Fig. 1, in which the upstream bandwidth is allocated
using the WDM-IPACT algorithm (described in Sub-
section III.B) and the various QoS requirements of the
different traffic classes are satisfied using the two-
stage buffering approach (introduced in Section IV).
The analysis presented in this section considers the
WDM EPON to consist of a single OLT, N ONUs, M
available wavelengths used by the ONUs in the up-
stream fiber, and an AWG module based on an AWG
with degree D. In performing the analysis, an as-
sumption is made that the packets from the end usersFig. 4. (Color online) Two-stage queue at an ONU D=2.
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 273
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
ing cycle time is not static, but varies dynamically in
accordance with changes in the instantaneous net-
work load.
As shown in Fig. 4, packets in the Stage-I priority
queues are advanced to the Stage-II public/private
queues in accordance with the service rates assigned
by the packet scheduler to each of the three traffic
classes. In the scheduling strategy, each priority
queue is assigned a service share value fC. To distrib-
ute the allocated bandwidth fairly among the different
traffic classes, the service share of each traffic class is
assigned in accordance with the corresponding traffic
load, i.e.,
C =
C

C, 12
where dC is the traffic load of traffic class C C
 AF,EF,BE, d is the total ONU traffic load (i.e.,
=CC), and C is a weighting factor assigned to traf-
fic class C based on its priority CC=1. To ensure a
fair service to each of the different traffic classes, the
service rate provided to each class is determined in ac-
cordance with its service share, fC, i.e.,
C =
C

C
C
MIN. 13
(Note that various schemes for assigning an appropri-
ate priority weight to each traffic class, such as
bandwidth-based algorithm, jitter-based algorithm,
etc., have been studied extensively in [27]. As long as
the weights are determined, they can be readily
plugged in the proposed model for performance analy-
sis. Therefore, the current study does not prescribe a
specific priority weight assignment approach.)
In the present analysis, it is assumed that new
packets arrive at the ONUs in accordance with a Pois-
son process with a rate dC and have an exponential
service time distribution with a mean 1/C. The ana-
lytical model developed in this study focuses princi-
pally on the average packet delay at the ONUs rather
than the level of packet losses throughout the net-
work, and thus the priority buffers are assumed to be
of an infinite size. As a result, the three priority
queues in the Stage-I buffering space are all modeled
as M /M /1 queues. In developing an analytical model
for the queuing delay at the Stage-I queues, it is as-
sumed that (1) the Stage-I buffer contains only
monoserver stations that operate under a first in first
out (FIFO) discipline, (2) the service time is exponen-
tially distributed with a mean 1/C, and (3) the end
user packets arrive at the ONUs in accordance with a
Poisson process with a rate dC. Under these assump-
tions, the Stage-I queues can be modeled as a mono-
class open queuing network, i.e., a Jackson’s network.
As a result, the state probability can be expressed as
follows:
PnEF,nAF,nBE =C PCnC, 14
where pCnC is the marginal probability associated
with the priority queue of traffic class C.
As stated above, the present analysis focuses spe-
cifically on modeling the average packet delay at the
ONUs. Let EDC denote the average packet delay as-
sociated with class C traffic. To formulate an analyti-
cal expression for EDC, it is first necessary to deter-
Fig. 5. (Color online) Calculation of maximum polling cycle time, TMAX, for heavily loaded WDM EPON with N=4 ONUs, M=2 upstream
data wavelengths, and AWG degree D=2.
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 275
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
TP
=	
N
SGATE
R
+ N − 1TGUARD +
1
2
RTT +
SREPORT
R
,
if P = 1,
AROUTE
SGATE
R
+ AROUTE − 1TGUARD +RTT
+
GPRIPRITP − 1
R
+ GPRI − 1TGUARD
+
GPUBPUBTP − 1
R
+GPUBTGUARD + TCOMPU,
if P 2

 .
22
If the total window size assigned to an ONU is in-
sufficient for that ONU’s needs, i.e., the achievable
transmission rate is less than the packet arrival rate
at the ONU, the duration of the following cycle in-
creases accordingly. As a result, the polling cycle time,
TCYCLE, can be estimated by continuously calculating
the polling cycle times of successive cycles [i.e., calcu-
lating T(2), T(3),…, and so forth] and approximates to
TP if the transmission rate is equal or approximate
to the arrival rate, i.e.,
WP =WP
PRI +WP
PUB PRI + PUBTP. 23
Assuming that the condition given in Eq. (23) holds,
the estimated polling cycle time [i.e., TCYCLE=TP]
can be used to calculate the packet delay in the
Stage-II queue using the method described below.
In analyzing the packet delay at the public queue
(comprising three priority subqueues) in Stage-II of
each ONU, it is important to recall that a packet ar-
riving at the Stage-II buffering space of the public
queue is not transmitted in the first transmission win-
dow granted to that ONU (counted from its arrival),
but is buffered in the public queue. In practice, before
transmitting packets, the ONU must first send a RE-
PORT message to the OLT requesting bandwidth for
the packets that were buffered in all priority sub-
queues of its public queue during the previous TCYCLE.
Having done so, the ONU must then wait for the cor-
responding GATE to arrive. Since the packets arrive
at the Stage-II buffers in accordance with a Poisson
distribution, a packet arrives at each of three priority
subqueues on average halfway through each polling
cycle. Hence on average, the time for which a packet is
buffered in each priority subqueue of the public queue
is equal to one and a half times the polling cycle time.
In other words, the mean packet delay in the Stage-II
public queue is equal to that of each priority subqueue
and therefore can be approximated as follows:
EDPUB = TCYCLE +
1
2
TCYCLE =
3
2
TCYCLE. 24
Regarding the private packet delay, the transmissions
from the private queues are managed using the two-
phase RR scheme described in Subsection III.C, and
thus each private queue is selected for transmission
once every D polling cycles. Given the Poisson distri-
bution of the packet arrivals at the Stage-II buffers, a
private packet arrives at any arbitrary priority sub-
queue of the selected private queue on average half-
way through the D polling cycles. Since an ONU has
to wait until the next public subcycle to send a RE-
PORT indicating the backlogged private packets that
arrived during the previous D polling cycles, and must
then wait further to receive the corresponding GATE
in the next private subcycle, the average mean queu-
ing delay of private traffic at Stage-II comprises the
computation time, the private subcycle time,
TCYCLE_PRI, and half of the time required to execute
the D polling cycles. As a result, the mean packet de-
lay at each Stage-II private queue can be approxi-
mated as
EDPRI = TCOMPU + TCYCLE_PRI +
D
2
TCYCLE. 25
From Eq. (7), the private subcycle time can be easily
obtained as
TCYCLE_PRI = AROUTE
SGATE
R
+ AROUTE − 1TGUARD
+RTT +
GPRIWP
PRI
R
+ GPRI − 1TGUARD,
26
where WP
PRI=PRITP−1. Substituting Eq. (26) into
Eq. (25), the mean packet delay of each Stage-II pri-
vate queue can be formulated in the following normal-
ized form:
EDPRI = TCOMPU + AROUTE
SGATE
R
+ AROUTE
− 1TGUARD +RTT +
GPRIWP
PRI
R
+ GPRI
− 1TGUARD +
D
2
TCYCLE. 27
VI. COMPARISON RESULTS AND PERFORMANCE
EVALUATION
This section commences by verifying the analytical
model presented in the previous section by comparing
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 277
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
stability limit at a network offered load of 1.64 Gbps,
whereas the AF and EF traffic remain in a stable con-
dition. Figure 7(b) presents the variation of the mean
queue lengths of the public and private traffic in
Stage-II as the network offered load is progressively
increased. Since, in performing the simulations, the
public traffic was assumed to account for 70% of the
total network traffic load, it is observed that the pub-
lic queue has a longer mean queue length than any of
the D private queues under all values of the network
load.
It can be seen that in all figures shown in this sub-
section, a good agreement exists between the analyti-
cal results and the simulation results.
B. Numerical Results of WDM-IPACT Algorithm and
Two-Phase RR Scheduling Protocol
For simplicity, in investigating the effectiveness of
the WDM-IPACT and two-phase RR schemes, this
subsection considers the network to carry only BE
traffic. In the following simulations, each ONU con-
sists of one public queue and D private queues and no
two-stage buffering approach is employed. For the
traffic model considered here, an extensive study
shows that most network traffic [i.e., http, ftp, vari-
able bit rate (VBR), video applications, and so forth]
are characterized by self-similarity and long-range de-
pendence (LRD) [28]. Hence, this model is used in the
present analysis to generate highly bursty BE traffic
with a packet size uniformly distributed in the range
of 64–1518 bytes.
Figure 8 shows the variation in the mean queuing
delay of the proposed WDM EPON scheme and a con-
ventional WDM EPON system (e.g. [5,6,9],) under
various network traffic loads. Note that in the conven-
tional WDM EPON, all of the packets (i.e., both public
and private) are processed through the OLT, whereas
in the proposed WDM EPON, the private packets are
routed directly through the AWG. In performing the
simulation, the network traffic is assumed to be
evenly split between public traffic and private traffic.
Due to the wavelength spatial-reuse feature of the
AWG, the network capacity is greater than 4 Gbps in
the WDM EPON system with four upstream data
wavelengths. Therefore, the results clearly show that
queue overflows (due to the use of finite size queues)
occur at much higher traffic loads in the proposed
WDM EPONs than in the conventional WDM EPON.
Furthermore, when comparing the results obtained
using AWGs with different degrees, it is observed that
the WDM EPON with a 44 AWG can accommodate
around 5 Gbps of network traffic before queue over-
flows occur, whereas that with a 22 AWG can sup-
port a network traffic load of 4.4 Gbps. The perfor-
mance improvement obtained by increasing the
degree of the AWG arises since a higher degree in-
creases the number of times that each data wave-
length can be reused, and therefore improves the
bandwidth utilization.
Fig. 7. (Color online) Mean queue length of WDM EPON with a
44 AWG. (a) Stage-I queues, (b) stage-II queues.
Fig. 8. (Color online) Mean queuing delay for various network traf-
fic loads.
Fig. 9. (Color online) Mean queuing delays of RR and RND
schemes for various private traffic to public traffic ratios.
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 279
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
VII. CONCLUSIONS
This study has proposed a novel WDM EPON archi-
tecture to facilitate Ethernet transmissions in high-
speed access networks. In the proposed network, a cy-
clic AWG device is employed to interconnect the ONUs
and the OLT. The AWG enables the WDM EPON ar-
chitecture to support both direct ONU–ONU commu-
nications and upstream access to the OLT. A WDM-
IPACT bandwidth allocation algorithm and a RR
private queue scheduling scheme have been developed
to arbitrate between private and public transmissions
and to achieve a full wavelength spatial-reuse capabil-
ity over the WDM layer. Furthermore, a two-stage
buffering approach has been presented to support the
different QoS requirements of different traffic classes.
The simulation results have demonstrated that the
wavelength spatial-reuse capability of the proposed
WDM EPON architecture yields a significant im-
provement in the bandwidth utilization of the access
network and therefore reduces the queuing delay at
the ONUs.
An analytical framework comprising an M /M /1
queue model and a recursive formulation for the poll-
ing cycle time has been developed to derive the mean
packet delay and mean queue length at each buffering
stage of the ONU. It has been shown that the results
obtained via computer simulations are in close agree-
ment with those obtained using this analytical frame-
work. To the best of the current authors’ knowledge,
this study represents the first reported attempt to
analyze the performance of WDM EPONs with QoS
support and private networking capability. Therefore,
the analytical framework presented in this paper pro-
vides a convenient means of establishing suitable per-
formance evaluation guidelines for any application us-
ing an EPON-based access network with a two-stage
buffer QoS provisioning mechanism.
ACKNOWLEDGMENT
This work was supported by the National Science
Council of Taiwan under grant NSC 97-2221-E-006-
175-MY3.
REFERENCES
[1] IEEE 802.3ah, Ethernet in the First Mile Task Force. Avail-
able: http:// www.ieee802.org/3/efm/index.htm.
[2] G. Kramer and G. Pesavento, “Ethernet passive optical net-
work (EPON): building a next-generation optical access net-
work,” IEEE Commun. Mag., vol. 40, no. 2, pp. 66–73, Feb.
2002.
[3] K. H. Kwong, D. Harle, and I. Andonovic, “Dynamic bandwidth
allocation algorithm for differentiated services over WDM
EPONs,” in Proc. IEEE ICCS, Sept. 2004, pp. 116–200.
[4] M. P. McGarry, M. Reisslein, and M. Maier, “WDM Ethernet
passive optical networks,” IEEE Commun. Mag., vol. 44, no. 2,
pp. 15–22, Feb. 2006.
[5] W. R. Chang, H. T. Lin, S. J. Hong, and C.-L. Lai, “A novel
WDM EPON architecture with wavelength spatial reuse in
high-speed access networks,” in Proc. of IEEE ICON, Nov.
2007, pp. 155–160.
[6] M. Maier, M. Herzog, and M. Reisslein, “Topics in Optical
Communications—STARGATE: the next evolutionary step to-
ward unleashing the potential of WDM EPONs,” IEEE Com-
mun. Mag., vol. 45, no. 5, pp. 50–56, May 2007.
[7] A. Rafiq, S. M. H. Zaidi, and M. Ramzan, “Comparative analy-
sis of scheduling frameworks for efficient wavelength utiliza-
tion in WDM EPONs,” in Proc. of ICEE, Apr. 2007, pp. 1–6.
[8] M. Maier, “WDM EPON: future applications and services,” in
Proc. of AccessNets, Aug. 2007, pp. 1–8.
[9] M. P. McGarry, M. Reisslein, C. J. Colbourn, M. Maier, F. Aur-
zada, and M. Scheutzow, “Just-in-time scheduling for multi-
channel EPONs,” J. Lightwave Technol., vol. 26, no. 10, pp.
1204–1216, May 2008.
[10] H. T. Lin, W.-R. Chang, C.-L. Lai, and S.-J. Hong, “Supporting
private networking with wavelength spatial-reuse over WDM
EPONs,” in Proc. of IEEE GLOBECOM, Nov. 2008, pp. 1–6.
[11] C.-J. Chae, S.-T. Lee G.-Y. Kim, and H. Park, “A PON system
suitable for internetworking optical network units using a fi-
ber Bragg grating on the feeder fiber,” IEEE Photon. Technol.
Lett., vol. 11, no. 12, pp. 1686–1688, Dec. 1999.
[12] E. Wong and C.-J. Chae, “CSMA/CD-based EPON with optical
internetworking capability among users,” IEEE Photon. Tech-
nol. Lett., vol. 16, no. 9, pp. 2195–2197, Sept. 2004.
[13] A. S. M. D. Hossain, R. Dorsinville, M. Ali, A. Shami, and C.
Assi, “Supporting private networking capability in EPON,” in
Proc. of IEEE ICC, vol. 6, June 2006, pp. 2655–2660.
[14] H. Takahashi, K. Oda, H. Toba, and Y. Inoue, “Transmissions
characteristic of arrayed waveguide NN wavelength multi-
plexer,” J. Lightwave Technol., vol. 13, no. 3, pp. 447–455, Mar.
1995.
[15] M. Maier, M. Reisslein, and A. Wolisz, “A hybrid MAC protocol
for a metro WDM network using multiple free spectral ranges
of an arrayed-waveguide grating,” Comput. Netw., vol. 41, no.
4, pp. 407–433, Mar. 2003.
[16] M. Maier, M. Scheutzow, and M. Reisslein, “The arrayed-
waveguide grating-based single-hop WDM network: an archi-
tecture for efficient multicasting,” IEEE J. Sel. Areas Com-
mun., vol. 21, no. 9, pp. 1414–1432, Nov. 2003.
[17] G. Kramer, B. Mukherjee, and G. Pesavento, “IPACT: a dy-
namic protocol for an Ethernet PON (EPON),” IEEE Commun.
Mag., vol. 40, no. 2, pp. 74–80, Feb. 2002.
[18] J. Zheng and H. T. Mouftah, “Media access control for Ethernet
passive optical networks: an overview,” IEEE Commun. Mag.,
vol. 43, no. 2, pp. 145–150, Feb. 2005.
[19] H. Shimonishi, I. Maki, T. Murase, and M. Murata, “Dynamic
fair bandwidth allocation for Diffserv classes,” in Proc. IEEE.
ICC, 2002, pp. 2348–2352.
[20] S. Blake, D. Black, M. Carlson, E. Davies, Z. Wang, and W.
Weiss, “An architecture for differentiated services,” IETF, RCF
2475, Tech. Rep., Dec. 1998.
[21] M. P. McGarry, M. Maier, and M. Reisslein, “Ethernet PONs: a
survey of dynamic bandwidth allocation (DBA) algorithm,”
IEEE Commun. Mag., vol. 42, no. 8, pp. S8–S15, Aug. 2004.
[22] C. M. Assi, Y. Ye, S. Dixit, and M. A. Ali, “Dynamic bandwidth
allocation for quality-of-service over Ethernet PONs,” IEEE J.
Sel. Areas Commun., vol. 21, no. 9, pp. 1467–1477, Nov. 2003.
[23] G. Kramer, B. Mukherjee, S. Dixit, Y. Ye, and R. Hirth, “Sup-
porting differentiated classes of service in EPON-based access
network,” J. Opt. Netw., vol. 1, no. 8, pp. 280–298, 2002.
[24] C. G. Park, H. S. Jung, D. H. Han, and Y. Lee, “Performance
analysis of DBA scheme with interleaved polling algorithm in
an Ethernet PON,” in Proc. of IEEE ISCC, June 2004, pp. 792–
797.
Lin et al. VOL. 2, NO. 5 /MAY 2010/J. OPT. COMMUN. NETW. 281
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented.
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:36:33 UTC from IEEE Xplore.  Restrictions apply. 
FIPACT: A Frame-Oriented Dynamic Bandwidth 
Allocation Scheme for Triple-Play 
Services over EPONs 
Hui-Tang Lin1,2, Chia-Lin Lai1, Wang-Rong Chang3, and Chin-Lien Liu1 
1 Institute of Computer and Communication Engineering, National Cheng Kung University, Taiwan (R.O.C.) 
2 Department of Electrical Engineering, National Cheng Kung University, Taiwan (R.O.C.) 
3 ICT-Enabled Healthcare Program, Industrial Technology Research Institute-South, Taiwan (R.O.C.)  
E-mails: 1{htlin, q3897105}@mail.ncku.edu.tw;annliu@nsda.ee.ncku.edu.tw;3Allen_Chang@itri.org.tw; 
 
Abstract–Ethernet Passive Optical Networks (EPONs) are not 
only cost-effective, but also provide high throughput, high 
bandwidth utilization, and low transmission latency. As a result, 
EPONs are a viable solution for overcoming the bandwidth 
bottleneck problem in local access networks. This study develops a 
novel Dynamic Bandwidth Allocation (DBA) scheme, designated as 
Frame-oriented Interleaved Polling with Adaptive Cycle Time 
(FIPACT), to provide a differentiated Quality-of-Service (QoS) 
capability in EPONs. FIPACT adopts a framed approach, in which 
the upstream network bandwidth is partitioned into successive 
frames. Within each frame, each Optical Network Unit (ONU) is 
guaranteed the network resources necessary to transmit a specific 
quota of Voice over Internet Protocol (VoIP), video, and Internet 
access traffic, respectively. Since FIPACT permits these three types 
of traffic stream to share the available bandwidth efficiently whilst 
still satisfying their respective QoS requirements, it provides an 
effective means of achieving differentiated triple-play services in 
EPONs. The simulation results demonstrate the effectiveness and 
efficiency of the proposed approach. 
 
Keywords- EPON; dynamic bandwidth allocation; triple-play 
services; QoS 
 
I. INTRODUCTION 
Ethernet Passive Optical Networks (EPONs) [1] have 
emerged as one of the most promising broadband access 
technologies for resolving the last-mile problem, and have 
attracted significant attention due to their inherent simplicity, 
longevity, low operational cost, and enormous bandwidth. 
EPONs contain only passive optical components in the signal 
path between the source and the destination and comprise one 
Optical Line Terminal (OLT) and multiple Optical Network 
Units (ONUs). Given the wide deployment of Ethernet ports 
nowadays and the huge volume of Ethernet-originated end-user 
traffic, the EPON standard is a natural candidate for 
next-generation access networks. Currently, network vendors 
and telecom operators view differentiated triple-play services 
and broadband access networks as necessary ingredients for 
offering residential customers Voice over Internet Protocol 
(VoIP), video, and high-speed Internet traffic services [2]. Since 
EPON is an inexpensive technology and is anticipated to be a 
suitable communication infrastructure between the central 
offices of the service provider and the customer sites, it is 
essential to provide a viable solution for network vendors 
seeking to fulfill QoS requirements for each of the triple-play 
services in an EPON system. 
To date, a wide range of Dynamic Bandwidth Allocation 
(DBA) schemes have been proposed for achieving 
differentiated services for broadband voice, video and data 
access applications over EPONs. Many existing QoS 
provisioning mechanisms intended for deployment at the 
individual ONUs in an EPON are implemented using a 
strict-priority-based scheduling strategy [3-5], in which the 
ingress traffic is classified into three different priorities, namely 
Expedited Forwarding (EF), Assured Forwarding (AF), or Best 
Effort (BE). In accordance with this strategy, the servicing of 
higher priority traffic is guaranteed by ensuring that a lower 
priority queue is scheduled for transmission if, and only if, all 
of the queues with a higher priority are empty. In [6], a dynamic 
scheduling algorithm, called the HG(SPS) (Hybrid Granting 
with Strict Priority Scheduler), was proposed to support 
guaranteed QoS for different types of applications over EPONs. 
In HG(SPS), the delay-variation sensitive transmissions (i.e., 
EF traffic) are served in an independent EF sub-cycle within 
each polling cycle, and thus the performance of the EF traffic is 
considerably improved. Furthermore, the authors in [7] 
proposed an Admission-Control DBA (AC-DBA) scheme 
which adopts a fixed polling cycle time approach to support 
guaranteed bandwidth and to ensure a bounded delay for 
real-time traffic.  
Although the schemes presented above provide an effective 
means of enhancing the QoS performance in EPONs with 
differentiated services, they are not readily applicable to EPONs 
hosting triple-play services since they can not simultaneously 
satisfy the differing QoS requirements of VoIP, video, and 
Internet access (i.e., BE traffic) applications, respectively. 
Accordingly, this study develops a novel DBA scheme to 
integrate triple-play services for an EPON system. The 
proposed scheme, designated as Frame-oriented Interleaved 
Polling with Adaptive Cycle Time (FIPACT), is based upon the 
concept of the IPACT protocol [8] which assigns the available 
network resources by polling the ONUs’ bandwidth demands in 
an interleaved manner. FIPACT employs a framed approach, in 
which the time domain of the upstream wavelength is 
subdivided into contiguous frames containing a Real-Time (RT) 
subframe followed by a BE subframe. Each ONU is guaranteed 
the network resources required to transmit a specific quota of 
VoIP and video traffic within each RT subframe. Furthermore, 
978-1-4577-0638-7 /11/$26.00 ©2011 IEEE
 
 
Fig. 1. FIPACT operation in an EPON system with two ONUs. (a) DBA frame structure. (b) Polling Policy in BE Subframe. (c) Polling Policy in RT 
Subframe. 
 
permission is in the initial BE polling cycle or not. 
z Unlike IPACT, the polling behavior of the VoIP and video 
polling cycles in FIPACT is based on a “grant-on-demand” 
approach. In other words, if an ONU presents a bandwidth 
demand of zero bytes for its VoIP (or video) queue in the 
REPORT message transmitted in the initial BE polling 
cycle of the BE subframe, the OLT skips this particular 
ONU to release its VoIP (or video) connection when 
polling the ONUs in the VoIP (or video) cycle of the 
subsequent RT subframe. In other words, the OLT polls 
only those ONUs which have backlogged VoIP (or video) 
packets waiting for transmission.  
As discussed above, each BE subframe contains a number 
of contiguous BE polling cycles. Since the period of each BE 
polling cycle varies in accordance with the amount of BE data 
granted for transmission, the number of BE polling cycles in 
each BE subframe depends on the BE traffic load. Furthermore, 
due to the constant duration of the DBA frames, an “insufficient 
void” issue occurs if the OLT receives the total BE bandwidth 
demand, Rtol_BE, exceeds the remaining available bandwidth, 
Brem_avail, in the BE subframe. In such a situation, the OLT uses 
a proportional bandwidth allocation mechanism to grant ONU n 
a BE transmission window, nBEW , with a size determined by the 
amount of bandwidth requested by ONU n, nBER , relative to the 
total bandwidth requested by all the ONUs, i.e., 
 .
_
_
BEtol
n
BE
availrem
n
BE R
RBW ×=             (1) 
Polling Policy in RT Subframe 
The RT subframe consists of one VoIP and one video 
polling cycles dedicated to ONUs for establishing their 
admitted VoIP and video connections, respectively (Note that to 
enable the ONUs to perform real-time stream admission locally, 
an admission control scheme should be provided at the ONU 
side [13]. However, due to length constraints, the issue of 
realizing such a control scheme is not addressed in the present 
study.) The implementation of DBA in the VoIP and video 
polling cycles is described in the following paragraphs. 
1) DBA in VoIP Polling Cycle. VoIP traffic is non-bursty and 
can be characterized by its mean data rate, μV. As a result, it is 
quite predictable. However, VoIP traffic has stringent delay and 
jitter requirements. To establish voice call connections, the OLT 
polls the ONUs individually and issues transmission grants for 
VoIP traffic in every VoIP polling cycle. The average delay and 
jitter of each VoIP stream is therefore guaranteed to be bounded 
due to the fixed duration of the DBA frames. Thus, for a VoIP 
call, the admission decision is straightforward, i.e., if the mean 
data rate can be supported, then the flow is admitted by the 
ONU; else it is rejected. Once an ONU n has admitted a VoIP 
Stream s, it estimates the quantum value of the bandwidth 
requirement of this stream in every RT subframe as follows: 
.. frameV
sn
V TR ×= μ               (2) 
The OLT is informed of this bandwidth demand via the 
REPORT sent from ONU n in the initial BE polling cycle of 
every BE subframe. The OLT then grants the VoIP transmission 
in the VoIP polling cycle of the following RT subframe. 
Figure 1(c) illustrates the VoIP transmission scenario for 
DBA Frame j with a fixed frame duration of Tframe = 8 ms. An 
assumption in made here that ONU 0 (ONU 1) issues a 
REPORT message requesting 64 Bytes to establish a 64-Kbps 
VoIP connection in the initial BE polling cycle of BE Subframe 
j – 1. In the current VoIP polling cycle of RT subframe j, the 
OLT grants ONU 0 (ONU 1) a 64-Byte transmission window to 
transmit its VoIP data. As a result, ONU 0 (ONU 1) can 
establish its VoIP voice call since the duration of each DBA 
frame is fixed, i.e., set to 8 ms, and is equal to the time spent by 
1500001
1000001
1500001
2000001
2500001
3000001
5 5.5 6 6.5 7 7.5 8 8.5 9 9.5 10 10.5 11
Nu
mb
er 
of 
Sa
mp
les
Jitter (ms)
FIPACT
AC-DBA
HG(SPS)
  
(a) 
1
1000001
2000001
3000001
4000001
5000001
6000001
5 5.5 6 6.5 7 7.5 8 8.5 9 9.5 10 10.5 11
Nu
mb
er 
of 
Sa
mp
les
Jitter (ms)
FIPACT
AC-DBA
HG(SPS)
   
(b) 
 
Fig. 2. Jitter performance of the VoIP traffic under FIPACT, AC-DBA, and 
HG(SPS) protocols. (a) Network offered load ρ = 0.5 Gbps. (a) Network 
offered load ρ = 1 Gbps. 
 
subframes was set to 2 ms. To ensure a fair comparison between 
the FIPACT, AC-DBA, and HG(SPS) allocation schemes, the 
fixed polling cycle time in the AC-DBA protocol and the 
maximum polling cycle time in the HG(SPS) protocol were 
both set to 8 ms. For the traffic model considered here, an 
extensive study shows that most network traffic flows (e.g., http, 
ftp, Variable Bit Rate (VBR), video applications, and so forth) 
are characterized by self-similarity and Long-Range 
Dependence (LRD) [14]. Hence, this model is used in the 
present study to generate highly bursty video and BE traffic 
with a packet size uniformly distributed in the range 64 ~ 1,518 
Bytes. Meanwhile, the VoIP traffic was modeled using a 
Poisson distribution with a constant packet size of 64 Bytes. 
Each VoIP stream was generated at a mean rate of 64 Kbps, 
while each video stream was generated at an average bit rate of 
4.85 Mbps. Finally, the VoIP, video and BE traffic loads were 
set to 20%, 40% and 40% of the network offered load, ρ, 
respectively. All of the simulations were run for 30 seconds.  
Figures 2(a) and 2(b) show the jitter performance of the VoIP 
traffic when using the FIPACT, AC-DBA, and HG(SPS) 
protocols given network offered loads of ρ = 0.5 Gbps and 1 
Gbps, respectively. In every case, the jitter is computed as the 
difference in the packet delay of two consecutive VoIP packets 
transmitted from the same ONU. The Probability Density 
Function (PDF) shows that the VoIP traffic delay sequence 
presents a centralization with all data points condensed on 8 ms 
for FIPACT protocol, one dispersion with enough number of 
data points in a curve from 6.6 ms (or from 7.9 ms) to 9.1 ms 
(or to 8.1 ms) for AC-DBA protocol, and one dispersion with 
enough number of data points in a curve from 6 ms (or from 7.5 
ms) to 10 ms (or to 8.3 ms) for HG(SPS) protocol. The reason 
behind the difference between centralization and dispersion 
delay sequence is that since the bandwidth request of every 
VoIP stream can be serviced in the VoIP polling cycle of each 
DBA frame, the FIPACT scheme has no possibility to obtain 
jitter delay time lower or higher than 8 ms, irrespective of the 
 
0
2
4
6
0 1 2 3 4 5 6 7 8 9 10A
cc
um
m
ul
at
iv
e 
T
h
ro
ug
hp
ut
 
(M
bi
ts
)
one-second time unit
FIPACT Avg.(4.85Mbits)
  
(a) 
0
2
4
6
0 1 2 3 4 5 6 7 8 9 10
Ac
cu
m
m
ul
at
iv
e 
Th
ro
ug
hp
ut
 
(M
bi
ts
)
one-second time unit
AC-DBA Avg.(4.85Mbits)
  
(b) 
0
2
4
6
0 1 2 3 4 5 6 7 8 9 10
A
cc
um
m
ul
at
iv
e 
T
h
ro
ug
hp
ut
 
(M
bi
ts
)
one-second time unit
HG(SPS) Avg.(4.85Mbits)
  
(c) 
 
Fig. 3. Accumulative throughput of an admitted video stream. (a) FIPACT. 
(b) AC-DBA. (c) HG(SPS). 
 
network offered load. This result reflects the fact that the fixed 
frame duration approach used in FIPACT leads to a constant 
departure rate amongst the backlogged VoIP packets, and 
therefore bounds the jitter delay time by the DBA frame 
duration to guarantee the generation of a VoIP packet with size 
64 Bytes every 8 ms.  
Figures 3 (a)~(c) present the accumulative throughput of an 
admitted video stream transmitted by ONU 0 under the FIPACT, 
AC-DBA and HG(SPS) schemes, respectively. The 
accumulative throughput is defined here as the amount of 
admitted video data transmitted by ONU 0 at every entry point 
during one-second time unit. It is observed that in each 
one-second time unit, the accumulative throughput of the 
proposed FIPACT and AC-DBA schemes increases 
progressively to approximately 4.85 Mbps. This result confirms 
that both FIPACT and AC-DBA schemes provide a guaranteed 
bandwidth of 4.85 Mbits in every one-second time unit, and 
hence satisfy the QoS requirements of the video traffic. 
Furthermore, in HG(SPS) scheme, since the strict priority-based 
scheduling is enforced in the AF/BE sub-cycle to serve buffered 
video traffic first, it may have some performance shortcomings, 
such as better-than-needed performance for video priority queue 
or starvation of BE queue. Hence, as shown in Fig. 3, HG(SPS) 
exhibits a fluctuant performance of accumulative throughput in 
each one-second time unit compared to that obtained from 
either FIPACT or AC-DBA. 
Figure 4 shows the variation in the BE queuing delay with 
the network offered load when using the FIPACT, AC-DBA, 
and HG(SPS) bandwidth allocation protocols, respectively. It  
  
Abstract—This paper focuses on downlink resource allocation in 
IEEE 802.16j transparent relay networks. A game theoretical 
formulation is derived where a resource allocation problem is 
represented as a two-stage bargaining game. Based on game 
formulation and solutions, the proposed approach not only provides 
improved performance but also supports fairness among the 
inter-class and intra-class users according to their heterogeneities 
in terms of the rate requirement, channel conditions, and link types. 
The simulation results confirm that the proposed scheme achieves a 
tradeoff between effective data rate and proportional fairness while 
also outperforming the static scheme and guaranteeing the rate 
requirements. 
Index Terms- OFDMA, 802.16j networks, game theory, resource 
allocation, transparent relay. 
I. INTRODUCTION 
Next generation (i.e.,4G) broadband wireless access networks 
are designed to provide high data rate to support fixed and mobile 
users having different quality of service (QoS) requirements.  
The system based on IEEE 802.16e standards is among leading 
candidates for 4G wireless networks. In such networks, a single 
base station covers a cellular area with radius of one mile. 
However, its initial field trials have limited coverage and poor 
service for indoor as well as cell boundary users.  To address 
drawbacks, the IEEE 802.16j standard [1] has been developed to 
extend 802.16e to achieve coverage extension and capacity 
enhancement with full backward compatibility to 802.16e 
Mobile Stations (MSs).  
The IEEE 802.16j standard [1] specifies that a relay station 
which supports multi-hop relay operations can operate in two 
different modes: transparent and non-transparent modes. In the 
transparent relay mode, a transparent RS is not allowed to 
transmit control messages such as preamble, FCH, UL/DL-MAP 
and DCD/UCD. Instead, the BS directly sends control messages 
to MSs. Hence, the scheduling for both uplink and downlink 
transmission are performed at the BS centrally. In doing this, the 
control overhead is reduced and the end-to-end throughput is 
improved. However, the transparent mode only supports when all 
MSs are within the coverage range of the BS.  In contrast, a 
non-transparent RS is designed to support MSs which are out of  
 
 
                                 (a)                                                            (b) 
Fig. 1. IEEE 802.16j transparent relay networks: (a)topology and (b) frame 
structure. 
 
the BS coverage range by transmitting/receiving control 
messages as well as data packets to/from those MSs. In the 
non-transparent mode, the transmission scheduling can be done 
either in a centralized or a distributed way. For both operating 
modes, resource allocation is one of the most important issues 
concerns the system throughput. Therefore, this study focuses on 
the resource allocation issue of 802.16j transparent relay systems 
and leaves the problem of non-transparent relays as the future 
work.  
Figure 1 shows the topology and the frame structure of an 
802.16j transparent relay network. In Fig. 1(a), the one-hop links 
between the multi-hop relay base station (MR-BS) and the 
transparent relay stations (T-RSs) are referred to as relay links, 
while the links between the T-RSs and the relay mobile stations 
(R-MSs) are referred to as access links. The links between the 
MR-BS and the directed mobile stations (D-MSs) are direct links. 
As shown in Fig. 1(b), the 802.16j transparent relay frame is 
comprised of the downlink and uplink subframes. Each downlink 
subframe is further partitioned into access and transparent zones. 
The  MR-BS uses the access zone to transmit packets to D-MSs 
and T-RSs. The packets received in the access zone by a T-RS 
are subsequently relayed to R-MSs in the transparent zone.  
Although the resource allocation problem of relay networks 
has been extensively investigated in [2-4], their solutions are 
under a fixed zone partitioning structure which ignores the 
A Game-Theoretic Framework for Resource Allocation in 
IEEE 802.16j Transparent Relay Networks 
Hui-Tang Lin1,2, Ying-You Lin1 
1Institute of Computer and Communication Engineering, National Cheng Kung University, Taiwan (R.O.C.) 
2Department of Electrical Engineering, National Cheng Kung University, Taiwan (R.O.C.) 
E-mails: 1{htlin, q3897107}@mail.ncku.edu.tw;  
 Egalitarian Bargaining Solution (EBS) [16] is used to obtain the 
bargaining solution. The EBS is defined as follows. 
Definition 2 (Egalitarian Bargaining Solution (EBS)): The 
total number of allocated resource slots for class k is N*k . Thus, 
N*k,i is the EBS for a service flow i in the intra-class bargaining 
game if and only if the numbers of allocated resource slots 
received by any two players p and v satisfy 
 
* *
, , , ,( ) ( ),  ,  ,  k p k P k v k v kN N p v p v     ,    (2) 
 
where * *,1
kI
k i ki
N N 
 
and , (.)k i is the utility function  of service 
flow i in class k. 
 
B. UTILITY FORMULATION FOR TWO-STAGE BARGAINING  
When conducting a bargaining process in two stages, a critical 
problem is that of modeling the player utility functions in each 
stage in such a way as to reflect the corresponding bargaining 
solutions. In the proposed DZP scheme, the aim is to provide an 
effective throughput-fairness allocation for all service flows 
under varying network dynamics. Thus, it is reasonable to take a 
bottom-up approach to model the utility functions in the 
two-stage bargaining game by first deriving the bargaining 
power of each service flow within a class and then deriving the 
overall bargaining power of the class.  
1) Intra-class Bargaining Utility Formulation: Let Rk={rk,1,s, 
rk,2,s, …, rk,I,s} for all s{D-MS, R-MS} be the set of per slot 
transmission rates for the service flows in class k. To obtain EBS 
for the different service flows within the class, the utility function 
(i.e., the payoff) for service flow i in the current frame is assumed 
to be its amount of data which can be sent in this frame, i.e.,  
 
, , , , , , ,( ) ,  k i k i s k i s k i s kN r N i    ,                        (3) 
 
where Nk,i,s is the number of resource slots allocated to the service 
flow i. If flow i is destined for a D-MS, the per slot transmission 
rate rk,i,D is easily obtained from the feedback received at the 
MR-BS from the D-MS. However, if flow i is destined for an 
R-MS (denoted as R-MS i), the per slot transmission rate is given 
by combining the transmission rate on the relay and access links, 
i.e., 
 
1 1
, , , , _ , , _1 / (( ) ( ) )k i R k i B R k i R Mr r r
    ,               (4) 
 
where rk,i,B_R is the per slot transmission rate from the MR-BS to 
the T-RS associated with R-MS i, and rk,i,R_M is the per slot 
transmission rate from T-RS to R-MS i. This utility formulation 
applied in Eq. (2) guarantees EBS fairness amongst the different 
service flows within a class. 
2) Inter-class Bargaining Utility Formulation: In formulating 
the utility function of each class in the inter-class bargaining 
stage of the game, the transmission rate of a class is defined as 
follows. 
Definition 3 (Class Transmission Rate (CTR)): rCTR,k is the 
class transmission rate for class k and is equal to the summation 
of the amount of data sent in this frame of all service flows within 
the class divided by the total number of resource slots θk 
allocated to the class, i.e.,  
 
  , , ,,
1
( )
 
KI k i k i s
CTR k
i k
N
r

  ,                            (5) 
 
where  , , , , ,
1
( ) / ( )
KI
k k i k i s k i s
i
N r 

 . 
 
Since the EBS of the intra-class bargaining game guarantees 
that each flow within class k has the same payoff, the class 
transmission rate is obtained as follows: 
 
 
 , , ,
,
( )
 k i k i s kCTR k
k
N I
r



  
 
, , ,
, , , , , , ,1 1
( )
=
( )/( ) 1 / ( )k k
k i k i s k k
I I
k i k i s k i s k i si i
N I I
N r r

 
   .       (6) 
Therefore, to measure the achievable utility of a particular 
class in each frame, the following logarithmic utility function is 
introduced:  
 
min, , ,1 1
( ) log( )k k
I I
k k CTR k k i k ii i
u N r N c      ,         (7) 
 
where ηmin,k,i and ck,i are the minimum guaranteed amount of data 
and the control message overhead (i.e., Preamble and DL/UL 
MAP) should be sent per frame for service flow i in class k in the 
current frame, respectively. Note that ηmin,k,i can be derived from 
its minimum reserved traffic rate. 
 
C. ZONE PARTITION 
Once the inter-class bargaining stage has determined the 
allocated resources N*k for each class k, the number of 
transmission slots N*k,i,s required for service flow i associated 
with class k can be determined by Eq. (2) and Eq. (3) as follows: 
  * 1 1, , , , , ,1/ kIk i s k k i s k i siN N r r      ,                         (8)  
 
where  ' * , , ,1 /kIk k k i k i siN N c r  . If flow i is destined to an R-MS, 
N*k,i,R is further divided into N*k,i,R,az and N*k,i,R,tz, i.e., the number 
of resource slots required for R-MS i downlink transmission in 
the access zone and the transparent zone, respectively. N*k,i,R-,az 
and N*k,i,R,tz are expressed as 
  * *, , , , , , _ , , _ , , _/k i,R az k i s k i R M k i B R k i R MN N r r r                (9) 
and 
 * *, , , , , , , _ , , _/k i,R tz k i R az k i B R k i R MN N r r    .                  (10) 
 0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
90% 80% 70% 60% 50% 40% 30% 20% 10%
Ja
in
's 
Fa
ir
ne
ss
Ratio of R-MSs to total MSs
C1(DZP)
C2(DZP)
C1(SP 1:1)
C2(SP 1:1)
 
Fig.  4. Jain’s Fairness for various R-MSs to total MSs ratios. 
 
higher priority to get requested bandwidth before bandwidth 
being distributed to the MSs of C2.  The average throughput of 
the proposed DZP is superior to that of the SP scheme when the 
ratio of R-MSs is greater than 30%. The reason is that the 
proposed DZP scheme is able to adaptively select a suitable zone 
boundary between the access zone and the transparent zone.  
Figure 4 illustrates the variation of the class fairness with 
respect to the ratio of R-MSs to total MSs. It shows that both C1 
and C2 in the proposed DZP have almost perfect fairness among 
all service flows in the class while the SP approach is not fair for 
the C2 service flows. This is a result of the EBS of the second 
stage game formulation in the proposed DZP. 
 
IV. CONCLUSION 
A dynamic zone partitioning game has been presented for 
solving the resource allocation problem in IEEE 802.16j 
transparent relay networks under varying network dynamics. The 
proposed scheme is able to adaptively adjust the boundary 
between the access zone and the transparent zone in the downlink 
subframe. It provides a tradeoff between fairness and throughput 
while meeting rate guarantees to all the service flows within the 
system irrespective of whether they are direct or relay MSs. The 
simulation results have confirmed that the proposed 
game-theoretic-based resource allocation scheme ensures 
efficient and fair bandwidth distribution amongst the different 
service flows within the IEEE 802.16j transparent relay network. 
 
ACKNOWLEDGEMENTS 
The authors would like to thank the National Science 
Council, Taiwan, R.O.C., for supporting this research under 
grant NSC 97-2221-E-006 -175 -MY3.  
 
REFERENCES 
[1]  IEEE Std 802.16j/D7: “Air Interface for Fixed and Mobile Broadband 
Wireless Access Systems, Multihop Relay Specification”. 
[2]  C. Bae and D. Cho, “Fairness-Aware Adaptive Resource Allocation Scheme 
in Multihop OFDMA Systems,” IEEE Communication Letters, vol. 11, no. 
2, pp. 134-136, Feb. 2007. 
[3]  Mohamed Salem, Abdulkareem Adinoyi, Halim Yanikomeroglu, David 
Falconer, and Young-Doo Kim, “A Fair Radio Resource Allocation Scheme 
for Unbiquitous High-data-rate Coverage in OFDMA-based Cellular Relay 
Networks,” in proceedings of IEEE Global Communications Conference 
(GLOBECOM), Honolulu, Hawaii, USA, Dec. 2009. 
[4]  Lin Xiao and Laruie Cuthbert “Load Based Relay Selection Algorithm for 
Fairness in Relay Based OFDMA Cellular Systems,” in proceedings of 
IEEE Wireless Communications and Networking Conference (WCNC), 
April 2009. 
[5]  Iam Kin Chan and Wanjiun Liao, “Adaptive Bandwidth Allocation for TCP 
Traffic in IEEE 802.16j Wireless Networks with Transparent Relay 
Stations,” in proceedings of IEEE Personal, Indoor and Mobile Radio 
Communications (PIMRC), Sept. 2008. 
[6]  Liping Wang, Yusheng Ji and Fuqiang Liu, “A Semi-distributed Resource 
Allocation Scheme for OFDMA Relay-Enhanced Downlink Systems,” in 
proceedings of IEEE Global Communications Conference (GLOBECOM) 
Workshops, Nov. 2008.  
[7]  Kaneko, M., Popovski, P. and Hayashi, K., ”Throughput-Guaranteed 
Resource Allocation Algorithms for Relay-Aided Cellular OFDMA 
System,” IEEE Transactions on Vehicular Technology, vol. 58, no. 4, MAY 
2009. 
[8]  Najah AbuAli, Mohammad Hayajneh, and Hossam Hassanein, 
“Congestion-Based Pricing Resource Management in Broadband Wireless 
Networks,” IEEE Transactions on Wireless Communications, vol. 9, no. 8, 
Aug. 2010.  
[9]  Dusit Niyato and Ekram Hossain, “A Microeconomic Model for 
Hierarchical Bandwidth Sharing in Dynamic Spectrum Access Networks,” 
IEEE Transactions on Computers, vol. 59, no. 7, July 2010.  
[10]  Dusit Niyato and Ekram Hossain, “Competitive Pricing in Heterogeneous 
Wireless Access Networks: Issues and Approaches,” IEEE Network, 
Nov./Dec. 2008. 
[11]  M. Rubaiyat Kibria and Abbas Jamalipour, ”Game Theoretic Outage 
Compensation in Next Generation Mobile Networks,” IEEE Transactions 
on Wireless Communications, vol. 8, no. 5, MAY 2009. 
[12]  Juncheng Jia and Qian Zhang, “Competitions and Dynamics of Duopoly 
Wireless Service Providers in Dynamic Spectrum Market,” in proceedings 
of ACM International Symposium on Mobile Ad Hoc Networking and 
Computing, May 26–30, 2008. 
[13]  Xi-Ren Cao, Hong-Xia Shen, Rodolfo Milito, and Patrica Wirth, “Internet 
Pricing With a Game Theoretical Approach: Concepts and Examples,” 
IEEE/ACM Transactions on Networking, vol. 10, no. 2, April 2002.  
[14]  Siew-Lee Hew and Langford B. White, “Cooperative Resource Allocation 
Games in Shared Networks: Symmetric and Asymmetric Fair Bargaining 
Models,” IEEE Transactions on Wireless Communications, vol. 7, no. 11, 
Nov. 2008. 
[15]  Juan E. Suris, Luiz A. DaSilva, Zhu Han, Allen B. MacKenzie, and 
Ramakant S. Komali, “Asymptotic Optimality for Distributed Spectrum 
Sharing using Bargaining Solutions,” IEEE Transactions on Wireless 
Communications, vol. 8, no. 10, Oct. 2009.  
[16]  H. J. M. Peters, Axiomatic Bargaining Game Theory. Kluwer Academic 
Publishers, 1992. 
[17]  Qualnet Simulator Home. http://www.scalable-networks.com/. 
[18]  Kitti W. and Aura G., “Packet scheduling for QoS support in IEEE 802.16 
broadband wireless access systems,” International Journal of 
Communication System, vol. 16, no.1, pp. 81-96, 2003. 
[19]  R. Jain, D. Chiu, and W. Hawe. A quantitative measure of fairness and 
discrimination for resource allocation in shared computer systems. DEC 
Research Report TR-301, Sep 1984. 
 
 
                             (a)                                                          (b) 
Fig. 1. Integrated EPON/WiMAX system. (a) Integrated EPON/WiMAX networks architecture. (b) Queue management scheme. 
 
individual ONUs in order to ensure a fair sharing of the 
available bandwidth within the trunk fiber. 
In modeling the integrated EPON/WiMAX network shown in 
Fig. 1, it is assumed that each ONU is placed at the curb by the 
network operator to perform a FTTC infrastructure solution for 
an autonomous access environment such as a community area, a 
university campus, a large-scale corporation distributed over 
several adjacent buildings, and so forth. Furthermore, each 
ONU serves both Ethernet end-users and a WiMAX BS located 
within the autonomous access area. In other words, the EPON 
system provides a broadband backhaul access service to the 
WiMAX BSs deployed within the dispersed FTTC 
infrastructures. 
Hybrid networks comprising both EPON and WiMAX 
technologies have a number of significant practical advantages 
[3]. First, the use of an EPON network to interconnect WiMAX 
BS cells and Ethernet customers simplifies the network design 
and yields a substantial reduction in the operational cost. 
Second, in a traditional EPON network, the maximum feasible 
network coverage is limited by the high costs incurred in 
deploying a fiber directly to the home (e.g., Fiber-to-the-Home, 
FTTH) or to the curb (e.g., FTTC). However, wireless systems 
have a low deployment cost, and thus integrated 
EPON/WiMAX networks not only reduce the network 
deployment cost, but also provide a scalable wireless solution 
for broadband network access. Third, unlike wired 
communication networks, wireless techniques facilitate the 
implementation of mobile user applications, and thus integrated 
EPON/WiMAX schemes not only provide network services to 
indoor end-users, but also enable outdoor end-users to access 
the network wirelessly, thereby creating an “anytime” and 
“anywhere” computing capacity within the autonomous access 
area. 
 
B. Queue Management Scheme 
In order to support the QoS transmissions of network traffic 
originating from the heterogeneous networks (i.e., Ethernet and 
WiMAX) within the autonomous access area, this section 
proposes a priority-based queuing scheme for handling the 
different classes of Ethernet and WiMAX traffic received at the 
ONU. 
As in a conventional EPON, the Ethernet traffic from the 
end-users in the EPON/WiMAX network is classified directly 
in accordance with the Ethernet packet classifier (CE) into three 
different priorities, namely Expedited Forwarding (EF), 
Assured Forwarding (AF), or Best Effort (BE) [8] (see Fig.1(b)). 
Typically, EF services support delay sensitive applications such 
as Voice over IP (VoIP), which require a bounded end-to-end 
delay and must satisfy prescribed jitter specifications. 
Meanwhile, the AF traffic class is intended for applications 
which are not delay sensitive, but require certain bandwidth 
guarantees. Finally, BE services support applications which are 
neither delay sensitive nor require a minimum guaranteed 
bandwidth or a specified robustness toward jitter. As shown in 
Fig. 1(b), to satisfy the QoS requirements of these three traffic 
types, each ONU is equipped with an Ethernet buffering space 
(SE) containing three separate priority queues, i.e., one queue 
for each type of traffic. 
On the other hand, WiMAX is a connection-oriented 
transmission system in which each service flow is dedicated to 
one of five different service priorities, namely Unsolicited 
Grant Service (UGS), extended real-time Polling Service 
(ertPS), real-time Polling Service (rtPS), non-real-time Polling 
Service (nrtPS), and Best Effort (BE) [2]. To enable the use of a 
common priority queue structure for the EPON and WiMAX 
traffic at each ONU and to achieve QoS consistency between 
the EPON and WiMAX traffic, the WiMAX packet classifier 
(CW) within each ONU is assumed to have a QoS mapping 
mechanism to map the UGS and ertPS traffic into EF priority 
traffic, the rtPS traffic into AF priority traffic, and the nrtPS and 
BE traffic into BE priority traffic, respectively. As a result, each 
ONU contains two buffering spaces, each containing three 
priority queues, namely SE for the Ethernet user traffic and SW 
for the WiMAX BS traffic (see Fig. 1(b)). Note that since the 
aim of this paper is to derive a game-theoretic framework to 
accomplish intra-ONU scheduling, the problem of developing 
this QoS mapping mechanism is not explicitly addressed. 
However, in practice, the mapping function can be implemented 
using any of the QoS mapping mechanisms proposed in the 
literature [3][9]. 
 
III. PROPOSED INTRA-ONU SCHEDULING STRATEGY 
Most of existing QoS provisioning mechanisms intended for 
deployment at the individual ONUs within a conventional 
EPON are generally implemented using a Strict Priority (SP) 
scheduling strategy (defined in P802.1D, clause 7.7.4) [10]. In 
such strategies, a lower priority queue is scheduled for 
transmission if, and only if, all of the queues with a higher 
priority are empty. However, SP-based QoS provisioning 
mechanisms are intended specifically for homogeneous access 
network environments (i.e., Ethernet traffic only). As a result, 
they can not satisfy both the QoS requirements of the Ethernet 
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.
978-1-4244-4148-8/09/$25.00 ©2009
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:42:52 UTC from IEEE Xplore.  Restrictions apply. 
individual priority queues within them. Hence, each ONU 
requires a bandwidth partitioning scheme which ensures that the 
different priority queues within the two buffering spaces receive 
a fair share of the calculated bandwidth, ][ jONUB , whilst 
continuing to satisfy their QoS commitments. Accordingly, as 
described in the following section, the game-theoretic 
framework proposed in this study employs a bargaining game 
approach to make bandwidth partition decisions in accordance 
with a sigmoid utility function. 
Bargaining Game Formulation 
Most bargaining theory can be traced back to the seminal 
study presented by Nash [16]. Generally speaking, an N-person 
bargaining problem describes a scenario in which N players 
attempt to reach agreement on trading a limited amount of 
resource. These N individuals have a choice to bargain with 
each other so that all of them can gain the highest benefits as a 
result of playing the game in cooperation. 
1) Case I: Bargaining Game for SE. This section 
considers the bandwidth partition problem for SE with three 
players P = {EF, AF, BE}, an allocated bandwidth, ][ ESONUB , 
(obtained from the bankruptcy game described in Section III-A) 
and a nonnegative number ][k
ES
R representing the bandwidth 
demand of player k (k∈{EF, AF, BE} ) in SE. Since the BE 
priority queue holds traffic for which no bandwidth or latency 
requirements are imposed, player BE bargains only for the 
unexhausted bandwidth. As a result, the solution for player BE 
(i.e., the amount of bandwidth allocated to the BE priority 
queue) can be obtained simply as follows: 
)( ][][][][ AF
ES
EF
ES
ES
ONU
BE
ES
BBBB +−= ,        (8) 
where ][ EFSEB and
][ AF
ES
B denote the bandwidths allocated to 
players (i.e., priority queues) EF and AF, respectively. 
In order to determine the bandwidth allocations 
][ EF
SE
B and ][ AF
ES
B , an assumption is made that the performance 
factor of player l (l∈P-{BE}) is equivalent to the ratio of the 
allocated bandwidth to the required bandwidth in each polling 
cycle, i.e., 
.][
][
l
S
l
S
l
E
E
R
B
=σ                    (9) 
To define the payoff (i.e., the QoS level) received by the 
individual players in the game, a sigmoid utility function is 
used to quantitatively estimate the relative satisfaction of the 
EF and AF priority queues on the performance factors lσ , and 
therefore this function is defined as follows: 
,
))(exp(1
1)(
ll
lU βσασ −×−+=           
(10) 
where α  indicates the steepness (i.e., the sensitivity of the 
performance factor) and βl represents the service priority 
parameters of player l. Hence, the payoff for player l is 
represented by U(σl) with the condition: 
,1)(0 ≤≤ lU σ                 (11) 
where U (σl)∈D and D is the bargaining domain, i.e. the 
feasible set of all possible payoffs. In order to prevent player l 
from disputing any QoS differentiation decision (i.e., any 
possible payoff result), a disagreement point of Umin(σl)= 0 is 
imposed such that any uncooperative player is punished by 
losing the opportunity to compete for bandwidth in the current 
polling cycle. Thus, the bargaining game problem and solution 
can be defined as (D, Umin(σl)) and F(D, Umin(σl)) ∈ D, 
respectively. 
In general, the Pareto optimal solution of a game defines an 
agreement such that one player cannot increase his or her utility 
without decreasing the utilities of the other players. One of the 
most common approaches for obtaining a fair bargaining 
solution is to apply the four axioms proposed by Nash [15], 
namely: 
z A1: Pareto Optimality. This axiom ensures that the 
bargaining solution is located on the Pareto boundary. An 
assumption is made that (D, Umin(σl)) is a bargaining 
problem and U, U’∈D. If U (σl) > U’(σl), then the solution 
F(D, Umin(σl)) ≠ U’ (σl). 
z A2: Symmetry. In this rule, the two players EF and AF 
receive the same payoff (i.e., U(σEF) = U(σAF)) if they have 
the same utilities. Such a criterion implies that if the 
conditions Umin(σEF) = Umin(σAF) and (U(σEF), 
U(σAF)) ∈ D ⇔ (U(σAF), U(σEF)) ∈ D hold, then F(D, 
Umin(σEF)) = F(D, Umin(σAF)). 
z A3: Invariance with respect to affine transformation. 
This axiom ensures that if U*(σl) is the solution to (D, 
Umin(σl)) and y is any positive affine transformation, the 
solution to (y(D), y(Umin(σl))) is y(U*(σl)). 
z A4: Independence of Irrelevant Alternatives. This 
criterion implies that if (D, Umin(σl)) and (D’, Umin(σl)) are 
bargaining problems with D ⊆ D’ and F(D’, Umin(σl))∈D, 
then F(D, Umin(σl)) = F(D’, Umin(σl)). 
 
The main drawback of criterion A4 is that each player pays no 
heed to the amount of resource (i.e., the available bandwidth in 
the current example) given up by the other players. In other 
words, each player is entirely selfish in pursuing his or her own 
benefit at the expense of the other players. Accordingly, Raiffa 
[17] suggested replacing A4 by the following axiom: 
z A5: Monotonicity. If D ⊆ D’, U1(D’) = U1(D), and U2(D’) 
≥ U2(D), then F2(D’, Umin(σl)) ≥ F2(D, Umin(σl)). 
Cao [18] explained that the bargaining solutions obtained 
by satisfying axioms A1 ~ A4 (Nash) or A1 ~ A3 and A5 (Raiffa) 
represent different solution points on the Pareto boundary. In 
other words, both solutions reflect the concern of each player 
for the amount of resource which he or she receives, but reflect 
a greater (Raiffa) or lesser (Nash) concern in the amount of 
resource given up by the others. Assuming that the relative 
tradeoff between these two concerns is indicated by a weighting 
factor γ, the preference functions of players EF and AF can be 
expressed as 
and  )),(1()()()( min AFEFEFEF UUUv σγσσγ −+−=
  
 (12) 
   )),(1()()()( min EFAFAFAF UUUv σγσσγ −+−=   (13) 
where γ = 0 and γ =1 correspond to the Nash solution and the 
Raiffa solution, respectively. In accordance with the players’ 
preference functions, the bargaining solutions of players EF and 
AF can be obtained as 
)},()(max{arg))(()),(( ** γγγσγσ AFEFAFEF vvUU ×= (14) 
where U*(σEF(γ)) and U*(σAF(γ)) indicate the bandwidths 
allocated to the EF and AF priority queues (i.e., 
][ EF
SE
B and ][ AF
ES
B ), respectively. Note that the solution of Eq. 
(14) can be obtained by performing a local search method. 
2) Case II: Bargaining Game for SW. As in the SE 
bargaining game, the SW bargaining game also has parameters 
of P = {EF, AF, BE}, an allocated bandwidth, ][ WSONUB , and a  
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.
978-1-4244-4148-8/09/$25.00 ©2009
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:42:52 UTC from IEEE Xplore.  Restrictions apply. 
0.1
1
10
100
1000
10000
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Network Offered Load (Gbps)
M
ea
n 
Q
ue
ui
ng
 D
el
ay
 (m
s) Nash, E_EF Raiffa, E_EF Nash, E_AF Raiffa, E_AF
Nahs, W_AF Raiffa, W_AF
Nash, W_BE Raiffa, W_BE 
 
Fig. 4. Mean queuing delay versus various network offered loads under 
Nash and Raiffa bargaining manners. 
 
WiMAX traffic. For Ethernet (or WiMAX) traffic, the loads of 
different traffic priorities stored in the corresponding EF, AF 
and BE priority queues were specified as 20%, 40%, and 40% 
of the Ethernet (or WiMAX) traffic load, respectively. As 
shown in Fig. 3(a), the results show that the impact of the 
proposed game-theoretic-based scheme appears on both EF and 
AF traffic queues within SE. Therefore, compared to the SP 
scheme, EF and AF traffic exhibit fair results under different 
service priority parameters, βl. It is observed that all schemes 
obtain an identical delay performance associated with BE traffic 
class. The reason for this phenomenon is that similar to SP 
scheme, the player BE in the proposed scheme is permitted to 
only use the unexhausted bandwidth, thereby exhibiting the 
same BE queuing delay as that of using SP scheme.  
In Fig. 3(b), since the SW bargaining game has better delay 
performance for BE priority queue than SP scheme, the 
proposed scheme can provide QoS guarantee for nrtPS traffic 
originated from WiMAX cell. It is also apparent that fairness 
issue between AF and BE priority queues can be satisfied in the 
proposed intra-ONU scheduling scheme. This result again 
confirms that using bargaining game can achieve a fair 
bandwidth allocation because it provides a sigmoid utility 
function to quantitatively estimate the QoS satisfaction of the 
AF and BE priority queues in accordance with their assigned 
service priority parameters, βl. Compared with the curves of EF 
priority queue, it is apparent that all the delay performance at 
EF priority queue are identical. This result is to be expected 
since in the proposed game-theoretic-based scheme, player EF 
is allowed to acquire all of its required bandwidth in the 
bandwidth bargaining process; therefore, the time required for 
the buffered EF packets to leave an ONU is equivalent to the SP 
scheme, in which EF packets with the highest priority are firstly 
scheduled for transmissions. 
Finally, Fig. 4 presents the variation in the mean queuing 
delay of priority queues within SE and SW, respectively, under 
Nash and Raiffa bargaining manners. Note that in the 
simulations, the amount of network traffic distributed to 
heterogeneous Ethernet and WiMAX traffic was specified as in 
Fig. 3. It is apparent that the delay curves of different traffic 
priorities in using Raiffa bargaining solution are closer to each 
other than that of employing Nash bargaining manner. This 
result confirms the ability of Raiffa bargaining solution to 
minimize the variation of allocated bandwidth amongst the 
players [20]. 
V. CONCLUSIONS 
This study has presented a game-theoretic framework for 
implementing an intra-ONU scheduling scheme within each 
ONU of an integrated EPON/WiMAX network. In the proposed 
framework, a bankruptcy game is formulated to distribute the 
bandwidth granted from the OLT between the SE and SW buffer 
regions of the ONU, respectively. Having received the results of 
the bankruptcy game, two branches of bargaining games are 
performed to further partition the bandwidth allocated to each 
buffering space to the different priority queues within them in 
accordance with the QoS requirements specified by the Ethernet 
end-users and the WiMAX cell, respectively. The simulation 
results have confirmed that the proposed game-theoretic-based 
intra-ONU scheme ensures a fair bandwidth distribution 
amongst the different service classes within the integrated 
EPON/WiMAX network. 
 
ACKNOWLEDGEMENT 
The authors would like to thank the National Science Council, 
Taiwan, R.O.C., for supporting this research under grant NSC 
97-2221-E-006 -175 -MY3. 
REFERENCES 
[1]  G. Kramer and G. Pesavento, "Ethernet Passive Optical Network (EPON): 
Building a Next-Generation Optical Access Network," IEEE Commun. 
Mag., pp. 66-73, Feb. 2002. 
[2]  IEEE Standard 802.16 Working Group, IEEE 802.16e-2005 Standard for 
Local and Metropolitan Area Networks: Air interface for fixed broadband 
wireless access systems-amendment for physical and medium access 
control layers for combined fixed and mobile operation in licensed bands. 
Dec. 2005. 
[3]  Gangxiang Shen, Rodney S. Tucker, and Chang-joon Chae, "Fixed and 
Mobile Convergence Architectures for Broadband Access: Integration of 
EPON and WiMAX", IEEE Commun. Mag., Aug. 2007. 
[4]  S. Sarkar, S. Dixit, and B. Mukherjee, "Hybrid Wireless-Optical 
Broadband Access Network (WOBAN): A Review of Relevant 
Challenges," IEEE/OSA Journal of Lightwave Technology, vol. 25, no. 11, 
pp. 3329-3340, Nov. 2007. 
[5]  S. Sarkar, H. Yen, S. Dixit, and B. Mukherjee, "Hybrid Wireless-Optical 
Broadband Access Network (WOBAN): Network Planning and Setup," 
IEEE JSAC, vol. 26, issue 6, pp. 12-21, Aug. 2008.  
[6]  S. Sarkar, H. Yen, S. Dixit, and B. Mukherjee, "A Novel Delay-Aware 
Routing Algorithm (DARA) for a Hybrid Wireless-Optical Broadband 
Access Network (WOBAN)," IEEE Network, vol. 22, no. 3, May 2008. 
[7]  G. Kramer, B. Mukherjee, and G. Pesavento, "IPACT: A Dynamic 
Protocol for an Ethernet PON (EPON)", IEEE Commun. Mag., vol. 40, 
issue 2, pp.74-80, Feb. 2002. 
[8]  S. Blake, D. Black, M. Carlson, E. Davies, Z. Wang, and W. Weiss, An 
Architecture for Differentiated Services, IETF, RFC 2475, Dec. 1998. 
[9]  Kun Yang, Shumao Ou, Ken Guild, and Hsiao-Hwa Chen, "Convergence 
of Ethernet PON and IEEE 802.16 Broadband Access Networks and its 
QoS-Aware Dynamic Bandwidth Allocation Scheme," IEEE JSAC, vol. 
27, issue 2, Feb. 2009.  
[10]  MAC Bridges, ANSI/IEEE Std. 802.1D, 1998. [Online]. Available: 
http://standards.ieee.org/getieee802/download/802.1D-1998.pdf.  
[11]  B. O'Neill, "A problem of rights arbitration from the Talmud," 
Mathematical Social Sciences 2, pp. 345-371, 1982.  
[12]  R. B. Myerson, Game Theory: Analysis of Conflict. Cambridge, MA: 
Harvard University Press, 1991.  
[13]  Dusit Niyato and Ekram Hossain, "A Cooperative Game Framework for 
Bandwidth Allocation in 4G Heterogeneous Wireless Networks," IEEE 
ICC, vol. 9, pp. 4357-4362, June 2006.  
[14]  L. S. Shapley, "A Value for n-person Games," in R.D. Luce and A.W. 
Tucker (eds.), Annals of Math. Studies, Princeton University Press, vol. 2, 
pp. 307-317, 1953.  
[15]  S.P. Ketchpel, "Coalition Formation among Autonomous Agents," Proc. 
of MAAMAW, 1993.  
[16]  J. Nash, "The bargaining problem," Econometrica, vol. 19, 1950.  
[17]  H. Raiffa, Contributions to the Theory of Game II. Princeton University 
Press, 1953, ch. Arbitration schemes for generalized two-person games.  
[18]  X. Cao, "Preference functions and bargaining solutions," Proc. CDC-21, 
Orlando, FL, Dec. 1982. 
[19]  W. Willinger et al., “A bibliographical guide to self-similar traffic and 
performance modeling for modern high-speed networks,” in Stochastic 
Networks. Oxford, U.K.: Oxford Univ. Press, pp. 339-366, 1996. 
[20]  B. Shrestha, D. Niyato, Z. Han, and E. Hossain, "Wireless access in 
vehicular environments using BitTorrent and bargaining," IEEE 
GLOBECOM, 30 Nov.-4 Dec. 2008. 
 
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.
978-1-4244-4148-8/09/$25.00 ©2009
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:42:52 UTC from IEEE Xplore.  Restrictions apply. 
 
 
Fig. 1. Schematic illustration of AWG-based SPON network. 
 
II. DESCRIPTION OF SPON ARCHITECTURE 
 
A. Proposed SPON System 
Figure 1 illustrates the architecture of the proposed SPON 
system. As shown, the SPON comprises four major elements, 
namely the core exchange, the local exchange, the distribution 
section, and multiple customer ONUs. The core exchange and 
the local exchange are separated by a distance of approximately 
90 km, which is representative of the typical geographic 
distribution in a metro area, and are connected via a dual 
backhaul fiber. Note that all of the connections in the SPON are 
accomplished using standard Single-Mode Fiber (SMF). The 
local exchange is connected to the distribution section by a 
second dual fiber, designated as the feeder fiber, with a length 
of 5 km. Finally, the distribution section is connected to each 
customer ONU by a third dual fiber, referred to as the add/drop 
fiber, with the same length as the feeder fiber. As a result, the 
SPON spans a total distance of around 100 km. 
 
Core Exchange 
The core exchange plays the role of an OLT (or a CO) in 
connecting the SPON network to a Wide Area Network (WAN). 
Thus, it is assumed that the core exchange is powered and 
possesses an O/E/O conversion capability in order to handle the 
packets received from and input to the backhaul fiber, 
respectively. Furthermore, to compensate for the chromatic 
dispersion effect, Dispersion Compensating Fibers (DCFs) are 
installed in the core exchange in both the upstream and the 
downstream directions, respectively. (Note that a detailed 
description of the use of DCFs in LR-PON systems is presented 
in [3].) In order to simplify the equipment requirements at the 
ONU end, the upstream wavelengths are amplified by an OA 
component in the core exchange and are then separated by an 
optical de-multiplexer before being received by the 
corresponding fixed-tuned receivers. Similarly, the downstream 
wavelengths are multiplexed using an optical multiplexer 
before being injected into the backhaul fiber. 
 
Local Exchange 
As shown in Fig. 1, the local exchange is equipped with an 
AWG module which enables the OLT to broadcast its data to all 
the ONUs in the downstream direction simultaneously. In 
contrast to traditional LR-PON architectures such as those 
presented in [2-5], the present SPON supports an 
internetworking capability within the network, i.e., the ONUs 
can communicate directly with one another without the need to 
route their transmissions through the OLT. In general, the 
traffic generated by the ONUs can be classified as either 
“inner” or “public”. In the former case, the packets are destined 
for other ONUs attached to the same LR-PON and are routed 
through the AWG in the local exchange, while in the latter case, 
the data packets are destined for remote end users attached to a 
different LR-PON or a different access network and are routed 
through a WAN via the OLT. 
Using the AWG module to accomplish direct ONU-ONU 
communications has a number of advantages. First, the burden 
on the border router is substantially reduced since its role is 
limited simply to that of forwarding public traffic to an 
appropriate WAN. Second, the need of an additional Ethernet 
bridge at the OLT can be avoided if the forwarding is 
performed by a layer-two bridge, instead of a layer-three router, 
to redirect data frames. Finally, the bandwidth wastage and 
end-to-end delays increase of inner traffic forwarding for the 
meaningless loopback in question is significantly avoided 
compared to the case of conventional LR-PONs. 
 
Distribution Section 
The distribution section of each local PON accomplishes a 
256-way split using a cascaded arrangement of two 1 x 16 
splitters (or combiners). The SPON architecture proposed in 
this study is intended to integrate a total of M = 4 local PONs, 
i.e., the SPON serves a total of N = M x 256 = 1024 customer 
ONUs. As a result, the cost of the shared equipment is 
distributed over a large number of customers, and thus the 
per-customer cost is substantially reduced. This enables 
expensive items of equipment such as OAs, DCFs, and so on, 
to be implemented in the shared section of the network without 
significantly increasing the overall cost to the end-user. 
Furthermore, the statistical multiplexing provided by increasing 
the number of ONUs to 1024 has the benefit of improving the 
bandwidth utilization since the network capacity can be shared 
dynamically amongst all the active ONUs even every ONU 
should not be active at all times [2]. An assumption is made 
that each ONU has a unique ID. Without loss of generality, 
ONU n (n ∈  {0, 1, …, N-1}) and its associated local PON m 
(m ∈  {0, 1, …, M-1}) are related via the simple relationship 
m = n mod M. Thus, ONUs 256, 257, 258 and 259, for example, 
are assigned to local PONs 0, 1, 2 and 3, respectively. 
 
Customer ONU 
Each ONU comprises two major functionalities, namely data 
transmission and data reception. In general, the ONU 
transmitter is a cost-critical component, and it is therefore 
desirable to minimize its complexity in order to reduce the 
overall cost. Accordingly, in the SPON architecture proposed in 
this study, it is assumed that each ONU employs a Fabry-Perot  
As shown in Fig. 2(b), the local exchange in the illustrative 
SPON structure is based on a 2 x 2 cyclic AWG. The AWG 
module is connected to the OLT via a 1 x 2 splitter (S2) and a 
combiner (C2) in the downstream and upstream directions, 
respectively. Meanwhile, the 1 x 3 splitters S0 and S1 distribute 
the incoming wavelengths to the two PON (ONU) groups 
within the network and to a single 2 x 1 combiner, C2. 
Similarly, two 3 x 1 combiners, C0 and C1, integrate the 
incoming wavelengths received from the PON (ONU) groups 
and splitter S2, respectively. The local exchange therefore 
comprises two 3 x 1 optical combiners (i.e., C0 and C1) 
attached to the AWG input ports and two 1 x 3 optical splitters  
(i.e., S0 and S1) connected to the AWG output ports. Note that 
as shown in splitter S0 in Fig. 2(b), the 1 x 3 splitters (or 3 x 1 
combiners) are implemented by cascading two 1 x 2 splitters 
(or 2 x 1 combiners). In addition, the optical signals launched 
into the input ports of the AWG and emitted from the output 
ports are amplified using dedicated OA devices. 
In developing the SPON architecture, it is assumed that all of 
the PONs (ONUs) attached to the same splitter/combiner form 
a single Internetworking Group (IG). As shown in Fig. 2(b), 
based on the degree of the considered AWG device (i.e., D = 2), 
the PONs are therefore partitioned into two IGs, with each IG 
containing two PONs. To support the simultaneous 
transmission of public and inner traffic, each ONU maintains 
dedicated transmission queues for the two traffic types, namely 
a single “public queue” and D separate “inner queues” (one 
queue per destination IG.). 
In contrast to the directional properties of the optical passive 
components within the SPON architecture (e.g., the optical 
splitters and combiners), the cyclic AWG is a wavelength 
routing device. In other words, when transmitting inner traffic, 
the individual data frames on a fiber can be routed to different 
splitters (i.e., to different IGs) by sending them on different 
wavelengths. Once the data frames arrive at the appropriate 
splitter, the inner packets are delivered to the corresponding 
PONs and extracted by the ONUs specified in the respective 
MAC addresses. Importantly, the AWG permits different data 
frames to be transmitted simultaneously on the same data 
wavelength provided that they are launched into different input 
ports. In other words, the AWG makes possible a wavelength 
spatial-reuse capability within the SPON, and therefore 
maximizes the use of the available bandwidth in the upstream 
directions. When an ONU wishes to communicate with a node 
in another IG, it need only determine the particular wavelength 
which exits the AWG and passes to the splitter associated with 
this IG. For example, in Fig. 2(b), if ONU 0 located within IG 0 
wishes to send inner data to ONU 3 attached to IG 1, it sends 
the data on wavelength λ1 such that it exits the AWG through 
output port O1 and is therefore passed to splitter S1. 
To enable the OLT to broadcast data frames and control 
messages to all the ONUs in the downstream direction 
irrespective of the IG to which they belong, it is connected to a 
1 x 2 splitter (S2) which spreads all the wavelengths to the two 
combiners attached to the AWG input ports, i.e., C0 and C1. 
Similarly, a 2 x 1 combiner (C2) is used to combine the 
incoming wavelengths received from the two splitters attached 
to the AWG output ports, i.e., S0 and S1, such that all of the 
ONUs can send upstream traffic on wavelengths λ0 and λ1 to 
the OLT. Note that to avoid the downstream signals sent from 
the OLT on wavelengths λ2 and λ3 from looping back to the 
OLT, an optical filter is installed at the output port of combiner 
C2 which allows only upstream traffic from the ONUs to enter  
OLT
G
λ4
λ0
λ1
Tx
Rx
Rx
T1 - τ
ONU 0's Msg
ONU 1's Msg
ONU 2's Msg
ONU 3's Msg
ONUs 2 
and 3
G G
T1
…
…
…
Guard Time
A Slot Time
 
 
Fig. 3. Slotted mode operation of SPON from perspective of OLT. 
 
the upstream backhaul fiber connected to the OLT. 
 
III. SPON MAC PROTOCOL DESIGN 
 
As in a traditional PON, the data transmissions in a 
conventional LR-PON all take place between a single OLT and 
multiple ONUs. Since the downstream transmissions are 
broadcasted by the OLT and are received by their intended 
destination ONUs, it has fewer challenges for network 
operation. However, to prevent transmission collisions in the 
upstream backhaul fiber, the OLT requires some form of 
scheduling mechanism to arbitrate the access of the individual 
ONUs over the DWDM layer. In conventional PONs, this is 
generally achieved using a Dynamic Bandwidth Allocation 
(DBA) algorithm such as IPACT [12] based on a polling-cycle 
approach [13]. However, while such protocols work well in 
conventional PONs, they are less suitable for LR-PONs due to 
the following reason. Since a LR-PON has a huge number of 
ONUs and the end user may be increased by a very significant 
amount, the DBA algorithms for scheduling the upstream 
transmissions in traditional PONs may not be efficient for 
LR-PONs [14]. Therefore, the design of efficient DBA 
algorithms for scheduling the upstream transmissions in 
long-reach access networks is recognized as being one of the 
biggest problems in realizing LR-PON networks. In an attempt 
to address this problem, this study proposes a simple Slotted 
MAC protocol, designated as SMAC, to distribute the upstream 
bandwidth in continuous time slots and to schedule the 
upstream transmissions amongst the ONUs in such a way as to 
avoid collisions. 
 
A. Slotted Organization 
In developing the SMAC protocol, a simplifying assumption 
is made that all of the ONUs are situated at the same distance 
from the OLT. Furthermore, it is assumed that the OLT is able 
to estimate the Round-Trip Time (RTT) between itself and the 
ONUs using some form of measurement procedure. Using this 
RTT information, the OLT, after executing the proposed 
scheduling mechanisms (described later in Section B), issues a 
GRANT (G) control message to the individual ONUs 
informing them of the time at which they should transmit their 
packets and the wavelengths which they should use via the 
dedicated control wavelength. 
Figure 3 presents a simple schematic illustration showing the 
slotted-mode operation of the proposed SMAC protocol. In this 
example, if the transmissions of ONU 2 and ONU 3 are to 
arrive at the OLT on wavelengths λ0 and λ1, respectively, at 
time T1, the OLT must send a G message granting ONUs 2 and 
3 access to the upstream bandwidth at time T1 – τ, where τ 
includes both the RTT and the control message processing time. 
As in the slotted system proposed for passive-star optical 
networks in [15], the OLT in the SPON scheme presented in  
time slots to the ONUs in accordance with the R messages 
received in BR slot F – 1. In other words, before scheduling 
frame F starts, the OLT is already aware of both the inner-slot 
and the public-slot reservation requests of all the ONUs in the 
network. In the SMAC protocol, the OLT employs an 
“on-demand” slot allocation approach. In other words, if an 
ONU presents no slot reservation requests for its inner or 
public data during the appropriate mini-slot in BR slot F – 1, 
the OLT skips this particular ONU when allocating time slots in 
the inner (public) sub-frame in frame F. 
The left part of Fig. 4(a) shows the scheduling policy during 
the inner sub-frame of frame F. Note that the problem of 
receiver collisions is prevented since each ONU is equipped 
with an array of fixed-tuned receivers. Furthermore, since the 
inner sub-frame is dedicated to the transmission of inner data 
only, the wavelength spatial-reuse feature of the 2 x 2 AWG 
can be fully exploited. For example, assume that at the 
beginning of the inner sub-frame, the OLT knows via the R 
messages received in the BR slot of the preceding frame that 
ONUs 0, 1, 2 and 3 have made inner-slot reservation requests 
for inner queues 0, 1, 0 and 1, respectively. Due to the 
spatial-reuse feature of the 2 x 2 AWG, the OLT grants the 
inner traffic transmissions of ONU 0 and ONU 3 (ONU 1 and 
ONU 2) in the first inner-slot on data wavelength λ0 (λ1) such 
that these ONUs can transmit their inner data to IGs 0 and 1 
(IGs 1 and 0), respectively, and their transmissions are 
overlapped within the first inner-slot. In other words, the first 
inner-slot on data wavelength λ0 (λ1) is spatially reused two 
times in transmitting the inner traffic of ONUs 0 and 3 (ONUs 
1 and 2) to two different combiners C0 and C1  
simultaneously. Note that inner data collisions would occur at 
the OLT in this situation since the transmissions of ONUs 0 and 
3 (ONUs 1 and 2) are overlapped in the first inner-slot on data 
wavelength λ0 (λ1) and are routed to the OLT through the 
combiner, C2. However, since the proposed network permits 
ONUs to exchange inner traffic directly between one another 
through the AWG, the risk of inner traffic collisions at the OLT 
is not essential to concern for take care. On the other hand, the 
inner data might arrive at OLT without collision. The OLT must 
drop all the received inner data in this sub-frame; otherwise, 
these data frames would be forwarded to the attached router. 
Consequently, these data frames would come back to OLT and 
then be sent to their destination ONUs, causing duplicate inner 
data receptions at ONUs. 
The right part of Fig. 4(a) illustrates the scheduling policy 
during the public sub-frame in frame F. The public sub-frame 
is established after all the inner-slot reservation requests have 
been granted. In contrast to the inner sub-frame, the upstream 
resource in the SPON architecture is shared by all the ONUs in 
sending their public traffic to the OLT, and thus each 
public-slot is permitted to grant just one public data 
transmission. Once the OLT has scheduled all the bandwidth 
requests received from the ONUs, it issues an ADV message to 
enable each ONU to make inner-slot and public-slot reservation 
requests for the following frame. 
 
C. Proposed Inner Queue Scheduling 
In general, the inner queue scheduling mechanism is 
responsible for interposing the transmissions of the different 
inner queues at each ONU. This section extends the two-phase 
Round-Robin (RR) scheme previously proposed by the current 
authors [9] to create a simple RR mechanism for scheduling the 
traffic buffered in the inner queues of each ONU in the SPON 
architecture. The aim of the RR scheduling mechanism is to 
ensure that each inner queue receives a fair access to the 
network resources and to achieve a spatial-reuse of the 
inner-slots (i.e., each inner-slot is spatially reused D (= 2) times 
in every inner sub-frame). As described in the following, the 
RR scheduling mechanism comprises two phases, namely the 
ONU setup phase and the RR steady-state phase. 
 
ONU Setup Phase 
The ONU setup phase takes place during the initialization of 
the SPON network. The goal of this phase is to initially 
schedule (assign) one inner queue for each ONU in the first BR 
slot of the first scheduling frame (counted from when the 
network first becomes active) in order to achieve a 
spatial-reuse of the inner-slots in the subsequent inner 
sub-frame. 
In the following discussions, the connection between input 
port x (Ix) and output port y (Oy) of the AWG on wavelength λw 
is defined as an “AWG routing path”, where x, y ∈  {0, 1, …, 
D - 1}. Since in an AWG with degree D, each wavelength can 
be spatially reused D times, the total number of AWG routing 
paths is given by: 
 
DWAROUTE ×= .            (1) 
 
Therefore, to ensure that one inner-slot on each upstream data 
wavelength is spatially reused D times, the inner transmission 
grants must be evenly distributed amongst all the AWG routing 
paths, i.e., the number of inner transmission grants carried by 
each AWG routing path should be equal to: 
 
ROUTEA
NG = .                (2) 
 
To achieve a fair distribution of the inner transmission grants 
amongst all the available AWG routing paths, the scheduled 
inner queue IDs of all the ONUs located within a local PON m 
are hashed to a number in the interval [0, D - 1] in accordance 
with the following function: 
 
h(m) = m mod D.                (3) 
 
Consider the simple case shown in Fig. 2(b), in which the 
SPON network has four ONUs (N = 4), a 2 x 2 AWG (D = 2), 
and two data wavelengths in the upstream fiber (W = 2). In 
accordance with Eq. (2), each wavelength can be spatially 
reused by letting each AWG routing path route exactly one 
inner transmission grant in each inner sub-frame. Applying the 
hash function given in Eq. (3), in the first BR slot, ONUs 0, 1, 
2 and 3 schedule their inner queues 0, 1, 0 and 1, respectively, 
when making an initial reservation of the inner-slots. This inner 
queue scheduling strategy enables the OLT to distribute a 
single granted transmission to each of the four different AWG 
routing paths within the same slot time. In other words, each 
inner-slot is spatially reused two times per wavelength in the 
inner sub-frame of the second scheduling frame. 
 
RR Steady State Phase 
The RR steady-state phase takes place in all the subsequent 
scheduling frames. Starting from the inner queue scheduled in 
the ONU setup phase, each ONU selects an appropriate queue 
from amongst all its inner queues in accordance with a RR 
method. This approach ensures that all the available inner slots 
are spatially reused in every inner sub-frame (assuming that all  
V. CONCLUSIONS AND FUTURE WORKS 
 
This study has proposed a novel LR-PON architecture, 
designated as Slotted-PON (SPON), to enable the integration of 
multiple access networks and a single metro backhaul network. 
The SPON scheme has a fix-slotted operational mode, and thus 
both the implementation cost and the complexity of the MAC 
protocol design are substantially reduced. In the proposed 
architecture, a cyclic AWG is employed to inter-connect the 
ONUs within different local PONs and the OLT. The AWG 
device enables the SPON architecture to support both an 
internetworking capability (i.e., ONU-ONU (PON-PON) 
communications) and upstream access to the OLT. This study 
has also developed a Slotted MAC (SMAC) protocol and an 
inner queue scheduling mechanism to arbitrate between inner 
and public transmissions and to achieve wavelength 
spatial-reuse on a slot-by-slot basis. The simulation results have 
shown that the spatial-reuse capability yields a notable 
improvement in the bandwidth utilization and therefore reduces 
the average queuing delay at the ONUs.  
Future studies will use OptSim [11] simulator to evaluate the 
efficiency (i.e., BER performance) of the upstream and 
downstream operations and will examine the use of the 
proposed architecture in supporting differentiated services and 
multicast transmissions. 
 
ACKNOWLEDGEMENT 
 
The authors would like to thank the National Science 
Council, Taiwan, R.O.C., for supporting this research under 
grant NSC 97-2221-E-006-175-MY3. 
 
REFERENCES 
[1]  Sang-Mook Lee et al., “Demonstration of a Long-Reach DWDM-PON 
for Consolidation of Metro and Access Networks”, IEEE/OSA J. 
Lightwave Technol., vol. 25, no. 1, pp. 271-276, Jan. 2007. 
[2]  D. P. Shea et al., “A 10-Gb/s 1024-Way-Split 100-km Long-Reach 
Optical-Access Network”, IEEE/OSA J. Lightwave Technol., vol. 25, no. 
3, pp. 685-693, Mar. 2007. 
[3]  G.. Talli et al., “Hybrid DWDM-TDM Long-Reach PON for 
Next-Generation Optical Access”, IEEE/OSA J. Lightwave Technol., vol. 
24, no. 7, pp. 2827-2834, July 2006. 
[4]  I. Van de Voorde et al., “The SuperPON Demonstrator: An Exploration of 
Possible Evolution Paths for Optical Access Networks”, IEEE Commun. 
Mag., vol. 38, pp. 74-82, Feb. 2000. 
[5]  R. P. Davey et al., “DWDM Reach Extension of a GPON to 135 km”, 
Proc. of OFC/NFOEC, vol. 6, pp. 6-11, Mar. 2005. 
[6]  C.-J. Chae et al., “A PON System Suitable for Internetworking Optical 
Network Units Using a Fiber Bragg Grating on the Feeder Fiber,” IEEE 
Photon. Technol. Lett., vol. 11, pp. 1686–1688, Dec. 1999. 
[7]  E. Wong et al., “CSMA/CD-based EPON with Optical Internetworking 
Capability among Users,” IEEE Photon. Technol. Lett. vol. 16, pp. 
2195–2197, Sept. 2004. 
[8]  ASM Delowar Hossain et al., “Supporting Private Networking Capability 
in EPON,” in Proc. of IEEE ICC, vol. 6, pp. 2655–2660, June 2006. 
[9]  Hui-Tang Lin et al., “Supporting Private Networking with Wavelength 
Spatial-Reuse over WDM EPONs”, Proc. of IEEE GLOBECOM'08, pp. 
1-6, Nov. 2008. 
[10]  M. Maier et al., “A Hybrid MAC Protocol for a Metro WDM Network 
using Multiple Free Spectral Ranges of an Arrayed-Waveguide Grating,” 
Comput. Network, vol. 41, no. 4, pp. 407-433, Mar. 2003. 
[11]  OptSim Network Simulator, http://www.rsoftdesign.com/ 
[12]  G. Kramer et al., “IPACT: A Dynamic Protocol for an Ethernet PON 
(EPON),” IEEE commun. Mag., pp. 74-80, Feb. 2002. 
[13]  G. Kramer et al., “Ethernet PON (ePON): Design and Analysis of an 
Optical Access Network,” photonic network Communication, vol. 3, no. 3, 
pp. 307-319, July. 2001. 
[14]  Huan Song et al., “Multi-Thread Polling: A Dynamic Bandwidth 
Distribution Scheme in Long-Reach PON,” IEEE J. Select. Areas on 
Commun., vol. 27, pp. 134-142, Feb. 2009. 
[15]  E. Modiaon et al., “Design and Analysis of an Asynchronous WDM Local 
Area Network Using a Master/Salver Scheduler,” Proc. IEEE INFOCOM, 
vol.2, pp. 900-907, Mar. 1999. 
[16]  W. Willinger et al., “A bibliographical guide to self-similar traffic and 
performance modeling for modern high-speed networks,” in Stochastic 
Networks. Oxford, U.K.: Oxford Univ. Press, pp. 339-366, 1996. 
 
Fig. 2. Polling cycle of offline scheduling algorithm in a WDM EPON system.
upgraded incrementally as needed, i.e., adding new fixed-tuned 
or tunable transceivers incrementally. In the WDM EPON 
proposed in [5], an offline scheduling was employed by the 
OLT to allocate the upstream bandwidth amongst the ONUs in 
a round-robin fashion once the OLT has received current 
REPORT messages from all the ONUs. Using this scheme, the 
OLT schedules the upstream transmission of an ONU on the 
earliest available wavelength amongst all the wavelengths 
shared by the ONUs in the upstream fiber. 
Fig. 2 illustrates the offline scheduling of a WDM EPON 
with N = 4 ONUs and M = 2 upstream wavelengths. Without 
loss of generality, the polling cycle time is defined here as the 
elapsed time between the final bits of two successive REPORT 
messages transmitted from the last polled ONU (i.e., ONU 3 in 
the example shown in Fig. 2) in two consecutive rounds. As 
shown, all of the granted transmissions are scheduled on the 
earliest available wavelength, and are timed by the OLT such 
that they are separated from the preceding transmission on the 
same wavelength by a specified guard time interval. A 
computation time is introduced between successive scheduling 
polling cycles in order to make its scheduling decisions based 
upon a global knowledge of the current bandwidth 
requirements. Note that this computation time inevitably incurs 
a small channel utilization cost since the upstream channel is 
not utilized for the interval between the moment at which the 
transmission of the last polled ONU in the previous cycle 
completes and that at which the transmission of the first polled 
ONU in the next cycle starts. 
B. Two-Stage Buffering Approach 
In accordance with the Diffserv framework developed by the 
Internet Engineering Task Force (IETF) [9] the network traffic 
can be classified into three different priorities, namely 
Expedited Forwarding (EF), Assured Forwarding (AF), or Best 
Effort (BE). EF services support delay sensitive applications 
such as Voice over IP (VoIP) which require a bounded 
end-to-end delay and must satisfy prescribed jitter 
specifications. Meanwhile, the AF traffic class is intended for 
applications which are not delay sensitive but require certain 
bandwidth guarantees. Finally, BE services support 
applications which are neither delay sensitive nor require a 
minimum guaranteed bandwidth or a specified robustness 
toward jitter. 
Currently, most QoS provisioning mechanisms intended for 
deployment at the ONUs in a TDM EPON are implemented 
using a strict priority scheduling strategy. However, this 
approach may starve low priority traffic of the network 
resources and may therefore cause high packet losses [10]. In 
order to support the QoS requirements of the three traffic types 
without causing unfairness and the “light-load penalty” 
problems for the lowest priority traffic, a two-stage buffering 
approach can be maintained at each ONU [6][10]. As shown in 
Fig. 3, in Stage-I, each ONU is equipped with a buffering space 
containing three separate priority queues, i.e., one queue for 
each of the three different types of traffic. Upon receipt at the 
ONU, the packets transmitted from the end users are classified 
by checking the Type of Service (ToS) field in the IP packets 
encapsulated in the Ethernet frames and are then buffered in the 
appropriate priority queue. If a high priority packet arrives at 
the ONU, but the corresponding buffer is full, the packet 
simply displaces a lower priority packet within the appropriate 
queue. Conversely, if a low priority packet arrives at the ONU 
and the buffer is full, the arriving packet is dropped. As a result, 
low priority traffic may experience excessive delays, increased 
packet losses, and even resource starvation if a suitable traffic 
policing mechanism is not implemented at the ONU. In the 
current study, this issue is addressed by implementing the 
traffic policing scheme presented in [11] at each ONU in order 
to monitor each type of traffic for conformity with the 
corresponding maximum arrival rate, as specified in 
accordance with user-defined criteria. 
7RWDO
2FFXSDQF\
2I218
4XHXH
Fig. 3. Two-stage queue at an ONU.
In Stage-II, the buffering space of the ONU output queue is 
shared by three separate traffic priorities that are corresponding 
to EF, AF, and BE traffic classes. As a result, the second stage 
buffer of the ONU queue comprises three ONU sub-queues, i.e., 
EF, AF, and BE ONU sub-queues (see Fig. 3). Since in each 
ONU, the ONU queue at Stage-II buffer consists of three ONU 
sub-queues, each ONU in every polling cycle reports the queue 
occupancies of the three ONU sub-queues (i.e., the total ONU 
queue length) when sending REPORT messages. Hence, in 
each polling cycle, data packets are extracted from all of the 
Stage-II ONU sub-queues and are then transmitted to the OLT. 
The space vacated by these packets in the Stage-II queues is 
then occupied by data packets sent from the Stage-I in 
accordance with the service rate, ȝC, given by the packet 
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:48:57 UTC from IEEE Xplore.  Restrictions apply. 
this particular type, i.e., E[PC], where PC is a random variable 
associated with the number of packets buffered at the priority 
queue dedicated to traffic class C. In evaluating E[PC], it is 
assumed that the system stability factor, ȡC, is equal to įC/ȝC
and the system stability condition is defined as: 
.1<Cρ                    (6) 
Note that all the parameters presented in the current analysis 
are computed at equilibrium with regard to this queuing 
network stability condition. Since each priority queue in the 
Stage-I buffer is treated as an M/M/1 queue, the expected 
number of packets buffered in each queue at any moment in 
time can be estimated as follows: 
.
1
]E[
CC
C
C
C
CP δμ
δ
ρ
ρ
−
=
−
=           (7) 
The average queuing delay of traffic class C can then be 
computed by applying Little’s formula (i.e., L = įWT, where L
is the queue length and WT is the packet waiting time), i.e., 
.1]E[]E[
CCC
C
C
PD δμδ −==
          (8) 
C. Analysis of Stage-II Queues 
This sub-section commences by constructing a recursive 
model to obtain approximate estimates of the polling cycle time, 
TCYCLE, for a limited service under an ONU traffic load, į. The 
estimated results are then used to compute the queuing delay at 
the Stage-II buffer in the ONU. In estimating the polling cycle 
time in the limited service discipline, the model explicitly 
recognizes the fact that successive polling cycle times influence 
one another [10]. 
As stated earlier, an assumption is made that new packets 
arrive at the priority queues in the Stage-I buffer in accordance 
with a Poisson process with a rate įC. To model each M/M/1
priority queue under equilibrium conditions, the average packet 
departure rate must be equal to the average packet arrival rate. 
As a result, the packet departure rate from the Stage-I priority 
queues (equivalent to the packet arrival rate at the Stage-II 
queues) also conforms to a Poisson process with a rateδ . 
It is assumed that the OLT polls the ONUs with the same 
polling sequence in every polling cycle. Note that in the 
following analysis, the cycle time is computed from the 
perspective of the last polled ONU (i.e., ONU 3 in the current 
example of Fig. 2). In the offline scheduling, the ONUs are 
unable to transmit a REPORT until they have received a GATE 
message because they can only request bandwidth when polled 
by the OLT. The time period of the first polling cycle in the 
network, i.e., polling cycle 1, thus comprises a half of the RTT 
between the OLT and an ONU, the time required to transmit the 
N = 4 GATEs, the time required to transmit the REPORT from 
the last polled ONU (i.e., ONU 3), and the guard time intervals 
separating the N = 4 GATE messages. The total duration of 
polling cycle 1 is therefore given by: 
,
2
1)1(1 R
SRTTTN
R
SNT REPORTGUARDGATE +⋅+⋅−+⋅= (9) 
where SREPORT is the size of the REPORT message. The average 
granted window size for each ONU in polling cycle 2 (i.e., W2) 
is equivalent to the amount of traffic accumulated during T1
(i.e., A1), and can be estimated as: 
.112 TAW ⋅== δ             (10) 
In the successive polling cycles, the time period of polling 
cycle P (P ≥ 2) can be easily obtained (from Eq. (1)) as: 
,)1(
)1(
COMPUGUARD
P
GUARD
GATE
P
TRTTTG
R
WGTM
R
SMT
++⋅−+
⋅
+⋅−+
⋅
=     (11) 
where 
.11 −− ⋅== PPP TAW δ           (12) 
As a result, the following recursive model for calculating the 
polling cycle time of cycle P (i.e., T(P)) can be established: 
.
2,)1(
)1()1(
1,
2
1)1(
)(
°°
°°
°°
¿
°°
°°
°°
¾
½
°°
°°
°°
¯
°°
°°
°°
®
­
≥++⋅−
+
−⋅⋅
+⋅−+
⋅
=
+⋅+⋅−+⋅
=
PifTRTTTG
R
PTGTM
R
SM
Pif
R
S
RTTTN
R
SN
PT
COMPUGUARD
GUARD
GATE
REPORT
GUARD
GATE
δ
(13) 
The durations of successive cycles increase progressively if the 
total window size assigned to each ONU is insufficient for that 
ONU’s needs, i.e., the achievable transmission rate is less than 
the packet arrival rate at the ONU. As a result, the polling cycle 
time, TCYCLE, can be estimated by continuously calculating the 
polling cycle times of successive cycles (i.e., calculating T(2), 
T(3), …,and so forth) and is approximately equal to T(P) if the 
transmission rate is equal or approximate to the arrival rate, 
i.e., 
).()( PTPW ⋅≅ δ              (14) 
Assuming that the condition given in Eq. (14) holds, the 
estimated polling cycle time (i.e., TCYCLE = T(P)) can be used to 
calculate the queuing delay in the Stage-II queue using the 
method described below. 
In analyzing the queuing delay of Stage-II at each ONU, it is 
important to recall that a packet arriving at the Stage-II buffer 
is not transmitted in the first transmission window granted to 
the ONU (counted from its arrival), but is buffered in the ONU 
sub-queues. In practice, before transmitting the packet, the 
ONU must first send a REPORT message to the OLT 
requesting bandwidth for the buffered packets which were 
buffered in all ONU sub-queues during the previous TCYCLE.
Having done so, the ONU must then wait for the corresponding 
GATE to arrive. Since the packets arrive at the Stage-II buffer 
in accordance with a uniform Poisson distribution, a packet 
arrives at each of three ONU sub-queues on average halfway 
through each polling cycle. Hence on average, the time for 
which a packet is buffered in each Stage-II ONU sub-queue is 
equal to one and a half times of the polling cycle time. In other 
words, the mean queuing delay in the Stage-II ONU queue is 
equal to that of each ONU sub-queue and therefore can be 
approximated as follows: 
.
2
3
2
1]E[ 2 CYCLECYCLECYCLES TTTD ⋅=⋅+=      (15) 
IV. COMPARISON OF ANALYTICAL AND SIMULATION RESULTS
This section verifies the analytical framework presented in 
the previous section by comparing the analytical results 
obtained for the mean queuing delay and mean queue length 
under various network conditions with the results obtained 
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:48:57 UTC from IEEE Xplore.  Restrictions apply. 
(
(
(
(
       
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XH
/H
QJ
WK
E\
WHV
 ()ǔ $QDO()ǔ 6LPX
()ǔ $QDO
()ǔ 6LPX
(
(
(
(
       
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XH
/H
QJ
WK
E\
WHV
 $)ǔ $QDO$)ǔ 6LPX
$)ǔ $QDO
$)ǔ 6LPX
                  (a)                               (b) 
(
(
(
(
(
(
(
       
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XH
/H
QJ
WK
E\
WHV

%(ǔ $QDO
%(ǔ 6LPX
%(ǔ $QDO
%(ǔ 6LPX
      (c) 
Fig. 7. Mean queue length of three traffic classes for two different priority 
weight assignments. (a) EF traffic. (b) AF traffic. (c) BE traffic.
assignments considered in Fig. 6. For the EF (see Fig. 7(a)), it 
can be seen that the mean queue length increases slightly as the 
ratio of the EF priority weight is decreased. This result is 
reasonable since decreasing the relative volume of EF weight 
within the network causes on average more EF packets to be 
temporarily buffered at the EF priority queue, and thus the 
queue length of the EF traffic inevitably increases. For the AF 
and BE traffic (see Figs. 7(b) and 7(c)), it is observed that the 
mean queue length decreases as the weight of the AF or BE 
traffic increases. Furthermore, comparing the two BE traffic 
profiles in Fig. 7(c), it can be seen that the BE traffic reaches its 
saturation limit of 10 Mbytes more rapidly when it accounts for 
a lower priority weight. These findings indicate that a lower 
volume of BE priority weight results in a lower BE bandwidth 
utilization since the packet scheduler assigns the traffic a 
relatively lower service rate. Overall, the results presented in 
Figs. 6 and 7 imply that the EF traffic always obtains the 
optimum QoS support from the packet scheduler and is 
therefore guaranteed to achieve a good delay performance. 
It can bee seen that in all figures shown in this section, a 
good agreement exists between the analytical results and the 
simulation results, and thus the validity of the analytical 
framework is confirmed.  
V. CONCLUSIONS
This article has analyzed the performance of the offline 
scheduling scheme in a WDM EPON in which a two-stage 
buffer is used to support the differentiated QoS requirements of 
various traffic classes. An analytical framework comprising an 
M/M/1 queuing model and a recursive formulation for the 
polling cycle time has been developed to estimate the mean 
queuing delay and mean queue length at each buffering stage of 
the ONU. It has been shown that the numerical results obtained 
using this analytical framework in close agreement with those 
obtained via computer simulations. Therefore, the analytical 
framework presented in this paper provide a convenient means 
of establishing suitable performance evaluation guidelines for 
any application using an EPON-based access network with 
offline scheduling and two-stage buffer QoS provisioning 
mechanism. 
ACKNOWLEDGEMENT
The authors would like to thank the National Science 
Council, Taiwan, R.O.C., for supporting this research under 
grant NSC 97-2221-E-006-175-MY3. 
REFERENCES
[1] IEEE 802.3ah, Ethernet in the First Mile Task Force, http:// 
www.ieee802.org/3/efm/index.htm 
[2] G. Kramer et al., “Ethernet Passive Optical Network (EPON): Building a 
Next-Generation Optical Access Network,” IEEE commun. Mag., pp. 
66-73, Feb. 2002. 
[3] K. H. Kwong et al., “Dynamic Bandwidth Allocation Algorithm for 
Differentiated Services over WDM EPONs,” Proc. IEEE ICCS, pp. 
116–200, Sept. 2004. 
[4] Maier, M., “WDM EPON: Future Applications and Services”, Proc. of 
AccessNets, pp. 1-8, Aug. 2007. 
[5] McGarry M.P. et al., “WDM Ethernet passive optical networks,” IEEE 
commun. Mag., vol. 44, pp. 15-22, Feb. 2006. 
[6] Chul Geun Park et al., “Performance Analysis of DBA Scheme with 
Interleaved Polling Algorithm in an Ethernet PON,” in Proc. of IEEE 
ISCC, vol. 2, pp. 792-797, June 2004. 
[7] S. Bhatia et al., “Analysis of the gated IPACT scheme for EPONs,” in
Proc. of IEEE ICC, vol. 6, pp. 2693–2698, June 2006. 
[8] Bart Lannoo et al., “Analytical Model for the IPACT Dynamic 
Bandwidth Allocation Algorithm for EPONs,” J. Opt. Networking, vol.6, 
no. 6 pp. 677–688, June 2007. 
[9] S. Blake et al., “An Architecture for Differentiated Services,” IETF, RCF 
2475, Tech. Rep., Dec. 1998. 
[10] G. Kramer et al., “Supporting Differentiated Classes of Service in 
EPON-based Access Network,” J. Opt. Networking, pp. 280–298, 2002. 
[11] H. Shimonishi et al., “Dynamic Fair Bandwidth Allocation for Diffserv 
Classes,” in Proc. IEEE ICC, vol. 4, pp. 2348–2352, Apr. 2002. 
[12] J. Zeng et al., “Media Access Control for Ethernet Passive Optical 
Networks: An Overview,” IEEE Commun. Meg., vol. 43, no. 2, pp. 
145-150, Feb. 2005. 
[13] J. Xie, et al., “A Dynamic Bandwidth Allocation Scheme for 
Differentiated Services in EPONs,” IEEE commun. Mag., vol. 42, pp. 
32-39, Aug. 2004. 
[14] Mong-Fong Homg, et al., “An adaptive approach to weighted fair queue 
with QoS enhanced on IP network,” in Proc. of IEEE TENCON, vol. 41, 
pp. 181-186, 2001. 
[15] Blanca Camnero et al., “Traffic Scheduling Solutions with QoS Support 
for an Input-Buffered MultiMedia Router,” IEEE Trans. on Parallel and 
Distribution Systems, vol. 16, no. 11, pp. 1009-1021, Nov. 2005. 
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:48:57 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. Integrated WiMAX/WiFi Network architecture.
and a SS is dedicated to a single user. However, the connection 
between the BS and each W
2
-AP is shared amongst all the 
nodes within the WLAN served by the W
2
-AP. As a result, the 
WiMAX network provides a backhaul service connecting 
multiple dispersed WiFi hotspots to the Internet. 
B. Proposed MAC Layer Module 
Figure 2 illustrates the MAC layer module developed in this 
study to support the integrated operations of the WiMAX/WiFi 
network. As described in the following, the MAC layer module 
is realized using two adaptive MAC frameworks, namely 
MultiMAC and SoftMAC. 
zMultiMAC: As in [8], the MultiMAC framework acts as a 
mediating MAC layer between the physical (PHY) device 
and the network layer, and performs a dynamic switching 
between different MAC protocols. Therefore, individual 
MAC variants can be used by MultiMAC for decoding their 
respective incoming frames and encoding outgoing frames 
with the MAC best suited to the current network conditions. 
When a frame arrives, the appropriate MAC layer “claims”
the frame and then decodes it. As discussed in [8], claiming 
a frame can be achieved in a variety of ways, e.g., by 
marking identifiers of the existing frame, adding a byte to 
the header of the frame for identification purposes, and so 
on. 
z SoftMAC: The SoftMAC framework is a convergence 
sub-layer located beneath the WiMAX frame layer. The 
objective of SoftMAC is to encapsulate a WiMAX Packet 
Data Unit (PDU) into a single WiFi PDU over 802.11a 
OFDM PHY or to decapsulate a single WiFi PDU into its 
WiMAX PDU. (Note that the technique of embedding an 
802.16 PDU over 802.11a has been investigated and 
validated in [9] and is therefore not discussed here.)
As shown in Fig. 2(a), the MAC protocol module proposed in 
this study comprises three major elements; namely the W
2
-AP 
device, the WiFi node, and the WiMAX BS. 
MAC Module in W
2
-AP Device
The W
2
-AP element comprises MultiMAC, the proposed 
convergence 802.16 MAC, and 802.16 OFDM PHY embedded 
within a conventional 802.11 AP device.  
In the upstream service flow, when MultiMAC receives a 
packet from the 802.11a PHY device, it decides which MAC 
(i.e., 802.11 MAC or the convergence 802.16 MAC) is best 
suited to claiming the packet by examining the current 
connection state of the network. If the network is currently 
connecting a WiFi node to the WiMAX network, MultiMAC 
switches the received packets to the convergence 802.16 MAC. 
As shown in Fig. 2(b), the uplink (UL) traffic is classified as 
either UL data packets or Bandwidth Requests (BW-REQs) of 
WiFi nodes via a specific Separator module. The received UL 
data packets are forwarded by the Separator module, through 
the Common Part Sub-layer (CPS) and the Convergence 
Sub-layer (CS) of Layer 2 BS-MAC, and then to the UL 
Aggregator/Classifier of the proposed Layer 2.5 MAC. For the 
BW-REQs, which are typically processed by the 802.16 MAC 
in a conventional 802.16 system, instead, they are forwarded to 
the UL Aggregator/Classifier and the UL Scheduler for further 
processing. The UL Aggregator/Classifier performs the 
following two functions in the upstream service flow:  
z Packet Classification: Similar to the packet classification 
in the conventional 802.16 SS-MAC, the packet 
classification function is to temporarily buffer the UL data 
packets based on their corresponding priority. Since each 
W
2
-AP acts as a relay node between a WiFi and a WiMAX 
network, all these backlogged packets are directly 
forwarded to CPS plane of 802.16 SS-MAC, and are 
relayed to the WiMAX BS during the granted time interval 
defined in the UL-MAP from the WiMAX BS. 
z BW-REQ Aggregation: This function is to aggregate all 
bandwidth demands at the same QoS level from WiFi nodes 
into a single bandwidth request. Subsequently, these 
aggregated bandwidth demands at various QoS levels (the 
gray arrow in Fig. 2(b)) are forwarded to the UL BW 
Request Generator in the CPS plane which then transmits 
these aggregated BW-REQs to the WiMAX BS via the 
802.16 PHY. 
In the downstream service flow, if WLAN hotspots currently 
use WiMAX as their backhaul services, the downlink (DL) 
traffic is separated by a Separator module into DL data packets 
and the DL/UL-MAP. As shown in Fig. 2(c), the DL data 
packets and the original the DL/UL-MAP are forwarded to the 
DL Traffic Processor of CPS plane in 802.16 SS-MAC and the 
Layer 2.5 MAC (the UL Aggregator/Classifier and the UL 
Scheduler). Upon receiving the UL-MAP, the UL 
Aggregator/Classifier can determine when to forward the 
buffered data packets from WiFi nodes in the upstream service 
flow. When the UL Scheduler receives the UL-MAP, it then 
finely reallocates the UL granted bandwidth to the WiFi nodes 
has sent the BW-REQs. The UL and DL bandwidth information 
is passed down to the DL/UL-MAP Generator (the gray arrow 
in Fig. 2(c)) to construct the corresponding DL/UL-MAP, 
which subsequently broadcasts to its associated WiFi nodes. 
The DL data packets from WiMAX BS are temporarily 
buffered at the corresponding priority queues in the CPS plane 
in 802.16 BS-MAC. They are relayed to their corresponding 
WiFi nodes following the schedule defined in the DL-MAP 
within the DL subframe. 
Through its use of MultiMAC and SoftMAC embedded in 
the proposed convergence 802.16 MAC, the W
2
-AP acts either 
as a bridge in translating frames between a WiFi and an 
Ethernet interface or as a relay node in transferring frames 
between a WiFi and a WiMAX network. Moreover, since the 
W
2
-AP incorporates a convergence 802.16 MAC comprising 
both SS and BS functions, it can also serve as a WiMAX 
sub-BS capable of sending BW-REQs (from the WiFi nodes) to 
the BS and allocating the granted bandwidth (from the BS) to 
the WiFi nodes. From the preceding discussions, it is clear that 
by upgrading existing 802.11 AP devices, the resulting W
2
-AP 
devices provide the means for WiFi users to connect to the 
Internet via a wired Ethernet infrastructure or a wireless 
broadband access mechanism (see Fig. 1).
2
Authorized licensed use limited to: National Cheng Kung University. Downloaded on April 15, 2009 at 11:19 from IEEE Xplore.  Restrictions apply.
Fig. 3. Two-hierarchy bandwidth allocation scheme.
A. Two-Level Hierarchical Bandwidth Allocation (THBA) 
WiMAX is a connection-oriented transmission technique in 
which each service flow is allocated a unique Connection ID 
(CID) [2][3], and BW-REQs and QoS support are processed in 
a connection-oriented manner. In satisfying the users’ 
bandwidth demands, the WiMAX BS allocates an aggregated 
bandwidth to each SS, and the SS then allocates this bandwidth 
to its various service connections. However, existing WiFi 
technology does not support this type of bandwidth allocation. 
As the mandatory access mechanism in 802.11e [10], 
Enhanced Distributed Channel Access (EDCA) defines the 
prioritized Carrier Sense Multiple Access with Collision 
Avoidance (CSMA/CA) mechanism. Differentiated services 
can be provided by introducing different Arbitration 
Inter-Frame Spaces (AIFSs) and Contention Windows (CWs) 
for different Access Categories (ACs) as well as different 
virtual collisions for priority queues in the same station. In 
802.11e, each WiFi station maintains up to four priority queues, 
with each queue corresponding to one AC.  
Obviously, the overall operational principles of WiMAX and 
WiFi are quite different, particularly as regards their bandwidth 
access and QoS provisioning mechanisms. WiMAX systems 
generally utilize bandwidth more finely than WiFi systems. 
Furthermore, connection-oriented bandwidth allocation 
approaches tend to provide a more predictable QoS than 
CSMA/CA-based bandwidth contention schemes. Therefore, it 
is reasonable to expect 802.16 technologies to provide a better 
QoS than their 802.11e counterparts. Since WiFi and WiMAX 
use different operational protocols in their bandwidth access 
mechanisms, it is necessary to embed additional functionality 
into the MAC layer of the WiFi NIC card and AP device 
(described in Section II) to enable WiFi hotspots to support 
connection-oriented services in the same way as in WiMAX 
systems. By implementing this modification,, a common 
bandwidth access mechanism can be deployed throughout the 
entire WiMAX/WiFi network. 
The current study develops a Two-level Hierarchical 
Bandwidth Allocation (THBA) scheme to request and grant 
bandwidth within the proposed integrated network. The 
following discussions consider the illustrative example shown 
in Fig. 3. As shown, two WiFi nodes (Nodes #3 and #4) send 
BW-REQs (CIDs #A1 and #A2) to the W
2
-AP. The W
2
-AP 
intercepts and aggregates these requests via the UL 
Aggregator/Classifier module (described in Section II-B), and 
then sends the aggregated BW-REQs (Request CID #B3) to the 
BS. It is recalled that when aggregating the BW-REQs from the 
WiFi nodes within a WLAN, the BW aggregation function 
performs the aggregation process in accordance with the QoS 
requirements of the individual requests. In other words, the 
W
2
-AP attempts to aggregate bandwidth demands having the 
same level of QoS. Once the BS receives the aggregated 
request, it grants an aggregated bandwidth (Grant for W
2
-AP 
#2) to the W
2
-AP, which then finely reallocates this bandwidth 
to the two WiFi nodes (Grants for Nodes #3 and #4) through its 
UL Scheduler. In other words, the protocol operation comprises 
two levels, namely Level A between the WiFi nodes and the 
W
2
-AP and Level B between the W
2
-AP and the BS. The BS is 
unaware of the detailed bandwidth requirements of the WiFi 
nodes in Level A since this information is summarized by the 
W
2
-AP prior to its transmission to the BS. Note that the CIDs 
assigned by the W
2
-AP and the BS are independent of one 
another and can therefore exist simultaneously in the two 
different levels of the bandwidth allocation hierarchy without 
affecting the operation of the system. 
The two-level bandwidth allocation approach described 
above enables the WiMAX and WiFi systems within the 
integrated network to be controlled via a single protocol based 
on the IEEE 802.16 standard used by the WiMAX system. 
Thus, the proposed bandwidth allocation scheme has two major 
advantages. First, the MAC protocols laid down in the WiFi 
and WiMAX standards require only slight modification, and 
therefore the time and expense incurred in implementing the 
integrated network are reduced. Second, the WLAN can 
support a fine level of QoS as in WiMAX without the need for 
any form of QoS mapping mechanism (e.g., in [6]). Therefore, 
the implementation complexity of the integrated network is 
reduced, and both QoS continuity and bandwidth management 
consistency can be obtained throughout the network. 
B. MAC Frame Structure 
Figure 4 illustrates the MAC frame structure to realize the 
THBA scheme for the illustrative example shown in Fig. 3. 
Note that to simplify the following discussions, the propagation 
and the W
2
-AP processing delay are deliberately neglected. 
Each frame broadcast by the BS or the two W
2
-AP devices 
consists of a DL subframe and an UL subframe, respectively. 
The length of both subframes is dynamically determined in 
accordance with the varying traffic load received from the 
upper layer. The DL subframes start with the periodic broadcast 
of various items of control information, including the DL 
preamble, the frame control header (not shown in Fig. 4), and 
the first DL burst (i.e., DL Burst #1). As shown, the first DL 
burst includes both the DL-MAP and the UL-MAP to define 
the access time interval to the DL and UL channels, 
respectively. The UL subframe commence with a BW-REQ 
interval and then comprise a series of UL bursts. The BW-REQ 
interval in Level B (or in Level A) is reserved for the BS (or for 
a W
2
-AP) to poll the W
2
-AP devices (or the WiFi nodes). The 
BS (or W
2
-AP) defines the duration carried by the UL-MAP 
during which a given W
2
-AP (or a given WiFi node) is 
permitted to issue the BW-REQ to the BS (or the W
2
-AP). 
Based on such contention-free polling approach [11][12], the 
BS (or W
2
-AP) allocates burst transmissions of the UL 
subframe to different W
2
-APs (or to different WiFi nodes). 
The W
2
-APs (or WiFi nodes) use the periodic DL preamble 
issued by the BS (or by a W
2
-AP) for synchronization purposes 
and assume the current frame duration to be equivalent to the 
time interval between the broadcast of two consecutive DL 
preambles. Note that the frame duration has a value in the 
range of 2.5~20 ms, and is fixed during normal operation.   
4
Authorized licensed use limited to: National Cheng Kung University. Downloaded on April 15, 2009 at 11:19 from IEEE Xplore.  Restrictions apply.
020
40
60
80
100
120
140
160
180
200
1.28 2.56 3.84 5.12 6.4 7.68 8.96 10.24
Network Offered Loads (Mbps)
M
ea
n
 E
n
d
-t
o
-E
n
d
 D
el
ay
  
(m
s)
VoIP (THBA)
Video (THBA)
Web (THBA)
VoIP (Indep.)
Video (Indep.)
Web (Indep.)
VoIP (EDCA)
Video (EDCA)
Web (EDCA)
0
20
40
60
80
100
120
140
160
180
200
10 20 30 40 50 60 70
Number of VoIP Connections
M
e
an
 E
n
d
-t
o
-E
n
d
 D
e
la
y
 (
m
s)
VoIP (THBA)
Video (THBA)
Web (THBA)
VoIP (Indep.)
Video (Indep.)
Web (Indep.)
VoIP (EDCA)
Video (EDCA)
Web (EDCA)
(a)                                                  (b)
Fig. 5. Mean end-to-end delay of various traffic classes for: (a) various network offered loads, and (b) the number of VoIP 
connections within the network.
(i.e., two WiFi hotspots). The IEEE 802.16 protocol was 
implemented using the WirelessMAN-OFDM air interface in 
TDD mode. The total bandwidth of the BS was assumed to be 
64 Mbps. The transmission frame size was specified as 10 ms 
in every case, and the ratio of the DL subframe duration to the 
UL subframe duration was set to 50:50. The SSs and WiFi 
nodes were assumed to generate three different types of traffic, 
each with a different priority, namely (i) VoIP (UGS) with a 64 
kbps Constant Bit Rate (CBR) and stringent delay requirements, 
(ii) Video (rtPS) with a 128 kbps CBR, and (iii) Web (BE) 
modeled for simplicity with a 64 kbps CBR. The packet 
intervals of VoIP, Video, and Web were assumed to be 20 ms, 
10 ms, and 12.5 ms, respectively. For the WLAN segment of 
the integrated network, an assumption was made that the 
upstream channel rate was 12 Mbps and the cell radius was 50 
meters. The key evaluation metric is the mean uplink 
end-to-end traffic delay. The end-to-end delay is defined here 
as the elapsed time between the arrival of a data packet at the 
WiFi node and the instant at which this packet was received by 
the BS receiver. The simulation runs achieve a confidence 
interval of 5% for a 95% confidence level. Note that since the 
confidence intervals of all numerical results are very small, 
these confidence intervals are not plotted along with the 
simulation results shown in this section. 
The following discussions compare the performance results 
obtained for three specific bandwidth allocation protocols in 
the WiMAX/WiFi system, namely: 
z THBA scheme: In this case, the proposed two-level 
hierarchical scheme is employed. In other words, each 
W
2
-AP aggregates all the bandwidth demands with the same 
QoS level received from its WiFi nodes and then requests 
the BS to allocate the total amount of bandwidth required. 
Having received this aggregated bandwidth from the BS in 
the UL-MAP of a particular Frame K, the W
2
-AP 
establishes the corresponding Frame K’ to perform a fine 
allocation of the bandwidth amongst its WiFi nodes in 
accordance with their original BW-REQs. As a result, each 
W
2
-AP has a guaranteed ability to relay all of the WiMAX 
PDUs transmitted by its WiFi nodes to the BS during its 
granted time interval in UL Subframe K.
z Independent bandwidth allocation control (Independent): 
The bandwidth allocation approach in this case is based on 
the integrated system described above. However, in the 
WLAN and WMAN segments, the BW-REQ and allocation 
procedures are performed independently using their 
respective IEEE 802.16 protocols without tightly coupling 
the two segments in terms of time. In other words, in a 
WLAN segment, the W
2
-AP directly allocates its own 
bandwidth to its WiFi nodes based on their bandwidth 
requirements and buffers the packets sent from the WiFi 
nodes. Meanwhile, in the WMAN segment, the W
2
-AP 
sends BW-REQs to the BS in accordance with the length of 
its queues and transmits the buffered packets from the WiFi 
segment to the BS during the granted time interval within 
the UL frame. 
zWiMAX with EDCA control (EDCA): Under this procedure, 
the WiFi nodes now are equipped with IEEE 802.11e NIC 
card to employ a priority-based EDCA bandwidth 
contention protocol for accessing the channel. The 
simulation parameters of EDCA are shown in Table I. In 
addition, in each W
2
-AP device, the convergence MAC 
(shown in Fig. 1) comprising SoftMAC and 802.16 
BS-MAC now is replaced with 802.11e MAC as well as no 
Multi-MAC functionality is required. Therefore, each 
W
2
-AP device in this case only acts as a bridge in 
translating frames between the WiFi and WiMAX networks. 
Like the Independent scheme, the W
2
-APs transmit 
BW-REQs to the BS in accordance with the length of their 
local queues. 
Note that even though 802.11e also defines an alternative 
protocol, designated as HCCA (HCF Control Channel Access), 
which is an enhanced version of PCF (Point Coordination 
Function), most of commodity WLAN interface products do 
not support the operation of HCCA or PCF. Therefore, the 
performance comparison between the proposed THBA 
scheme and HCCA is excluded in the simulation. 
TABLE I. SIMULATION PARAMETERS FOR EDCA.
Voice Video Best Effort 
Transport 
Protocol 
UDP (CBR) UDP (CBR) UDP (CBR) 
AC VO VI BE 
CWmin 3 7 15 
CWmax 7 15 1023 
AIFSN 2 2 3 
B. Numerical Results 
Figure 5 shows the variation in the end-to-end delay for 
various network offered loads (Fig. 5(a)) and the number of 
VoIP connections within the network (Fig. 5(b)), respectively.  
6
Authorized licensed use limited to: National Cheng Kung University. Downloaded on April 15, 2009 at 11:19 from IEEE Xplore.  Restrictions apply.
Integrated Power-Saving Scheduling for IEEE 802.16e Networks  
aHui-Tang Lin, bRung-Shiang Cheng, cLi-Jun Guo, dYuen-Fu Chiu 
aDepartment of Electrical Engineering, National Cheng Kung University, Taiwan, 
b, c, dDepartment of Electrical Engineering and Institute of Computer Communication 
Engineering, National Cheng Kung University, Taiwan 
ahtlin@mail.ncku.edu.tw 
{bchengrs, clgguo, dyuen_fu_chiu}@nsda.ee.ncku.edu.tw 
 
 
Abstract - The mobility of IEEE 802.16e 
introduces an important issue for battery-powered 
mobile station to extend the operational lifetime. 
Although the sleep-mode operation in power 
management helps to increase the life of mobile 
station by saving energy consumed, since the 
sleep-mode operation is not fully integrated with 
the scheduling mechanism, the energy-saving 
efficiency is not utilized due to the reciprocal effect 
between the connections. In order to effectively use 
the channel bandwidth and provide energy 
efficiency for wireless mobile station, this research 
developed a scheduling method, in attempt to 
provide energy saving based on the premise of 
different service delayed restrictions. 
 
Keywords: IEEE 802.16e, PSC, Sleep-mode, 
Power-saving.  
 
 
1. Introduction 
  In recent years, IEEE 802.16 has been 
standardized for WiMAX technique to provide a 
solution for the next generation broadband 
wireless access networks. The original IEEE 
802.16 standard only supported fixed broadband 
wireless access. The emerging IEEE 802.16e 
standard has enhanced the original standard with 
mobility so that the mobile subscriber station 
(MSS) can be movable during service. However, 
although this protocol can provide better 
throughput and transmission distance than the 
traditional WiFi access, the mobile device would 
consume more power for communication. 
Consequently, power management has become an 
important issue for the mobile device. Furthermore, 
due to the promising mobility capability, energy 
saving is a significant issue in IEEE 802.16e. 
 In IEEE 802.16e, in order to extend the 
operating time of mobile device, an MSS is 
permitted to repeatedly switch from normal mode 
(i.e., wake-mode) to sleep-mode whenever it is not 
communicating with a base station (BS). Hence, 
the MSS can temporarily close the radio frequency 
component and enter the sleep-mode when the data 
transmission is not carried out. However, if a large 
number of connections are established between 
MSS and BS, the MSS operation state would be 
affected by the interaction among the power saving 
mechanisms of those connections. The operation 
state of a MSS can be switched to sleep-mode only 
when all the connections in the MSS expect to 
enter the sleep-mode. Comparing with the single 
connection MSS, multi-connection is less likely to 
be switched to a sleep-mode. The reason is that 
operation among power saving-classes and their 
schedule mechanisms has no cooperative 
relationship. Therefore, the effect of power-saving 
mechanism operation is not obvious. 
 Many studies have evaluated the power-saving 
in IEEE 802.16 communication systems. [2] [5] 
investigated the protocol and control mechanism. 
[1] proposed a novel model to investigate the 
energy consumption of IEEE 802.16e by 
considering the message delivery from BS to MSS. 
[3] analyzed the energy consumption by 
considering both the incoming frames and 
outgoing frames since the instants of terminating 
sleep-mode by incoming or outgoing traffics are 
different. These studies only considered the 
power-saving class (PSC) Type I and Type II [6] 
sleep-mode, and the analytical models were 
evaluated for average energy consumption and the 
average response delay of awakening MAC SDUs. 
Although many studies have evaluated the 
performance of sleep-mode, none conducted 
performance analysis on PSC type III nor proposes 
the schedule scheme for PSC type III. 
   This study introduced an integrated power 
saving schedule scheme, called IPSS. 
Distinguished from previous studies, IPSS is a 
novel MSS-based schedule scheme. Furthermore, 
to efficiently manage energy consumption in IEEE 
802.16e, the sleep interval and wake interval of 
MSS are directly specified by the base station. 
This study modeled the sleep-mode operation of 
are in group 2 (G2). T1, T2 are the time lengths of 
sub-scheduling cycle and scheduling cycle, 
respectively. IPSS scheduler conducts scheduling 
following the steps below:  
 
Step1: compute the time period for the next T1 at 
the starting of the previous sub-scheduling cycle, 
and the time period for the next T2 at the starting of 
the previous scheduling cycle, then the channel 
usage time, LG1, LG2, allocated to G1,G2 in a 
sub-scheduling cycle.  
Step2: Compute the bandwidth assigned to each 
MSS, and assign the wake-up time of MSS. 
 
The sub-scheduling cycle period, is given by: 
NiTi
mTmT
f
i
f
∈≤⋅=
⋅=
  ),constraintdelay  (max  arg     
  ,1   (1) 
and the scheduling cycle period, is given by: 
NnTnT ∈⋅=   ,12           (2) 
 
   With T1 as a basic cycle, IPSS would schedule 
the MSS of G1 after each T1 cycle, then schedule 
the MSS of G2 after n TL1 cycle. After obtaining the 
time period of T1  cycle, the scheduler would 
compute the access time of station of G1 in 
sub-scheduling cycle. Then, base on the minimal 
reserved data rate, the length of T1 cycle is 
proportionally assigned to stations of G1 and G2: 
∑
∑
×= ,G2flow in G1
i
i
min
flow in G1
i
i
min
1G1
R
R
TL           (3) 
Where, Rimin is the minimal reserved data rate for 
the service flow i.  
Then the time length in T1 cycle for G2, is 
calculated by: 
G11G2 -LTL =              (4) 
   After passing each T2 cycle, the IPSS would 
allocate the LG2 time period left in n T1 to stations 
of G2.  
   After computing the allocation areas of the 
scheduling cycle, sub-scheduling cycle, and 
bandwidth, IPSS then computes the time point wi 
for waking-up of MSS in each cycle, and the time 
interval bi for accessing the channel. IPSS would 
notify the MSS of the time and length of the next 
access after each wake-up of MSS, as shown in 
Figures 2 and 3.  
For the reserved bandwidth, as shown in 
Figure 2, IPSS first calculates the MSS of G1, the 
allocated length of access time in T1 is based on 
the proportion of the minimal reserved data rate. 
For example, MSS i has number of flow j, and 
then MSS i can reserve to access time of bG1i:  
∑
∑
×= flow in G1
j
j
S iflow in MS
j
j
i
G1
R
R
Lb
min
min
1G         (5) 
T1T1
T2 T2
T1 T1
LG1
wG10
bG10 bG11
wG1i
bG1i...
LG1
time
...
Figure 2. The scheduling of G1 in the next 
T1 cycle at the starting point of the 
previous T1 cycle 
 
Figure 3. The scheduling of G2 in the next 
T2 cycle at the starting point of the 
previous T2 cycle 
   
   The following equation is used to compute the 
relative time for MSS to start accessing the 
channel, wherein the relative time is the expected 
wake-up time of MSS with each T2 as the starting 
point, using the length based on T2 cycle. For 
example, MSS 0, which is the first MSS of group 1, 
can be transmitted after T1 period. And MSS i, 
which is the ith MSS of group 1, can be transmitted 
after T1 cycle plus the total time of MSSs reserved 
time in group 1 before MSS i coming.  
1Tw
G1 =0             (6) 
∑−
=
−− +=+=
1
0
i
m
m
G1
11i
G1
1i
G1
i
G1 bTbww (7) 
   The allocation of stations of G2 is similar to 
that of G1, as shown in Figure 3. First, the 
accessing time length allocated to stations in G2 
within the T2 cycle is computed, then Eq. (8) is 
used to differentiate the time allocated to each 
station. 
∑
∑
×∗= flow in G2
i
i
S kflow in MS
i
i
Gk
G
R
R
Lnb
min
min
2
2 )(         (8) 
Then, Eqs. (9) and (10) are used to compute the 
relative time for MSS to start accessing the 
channel. For example, MSS 0, which is the first 
total wake-up time for evaluating the effectiveness 
of sleep, the equation is written as below:  
( ) 2
f
f
G2
f
f
G1
total TNM
NT
T
Ln
NnmMnT
T
L
Mm
×+
××
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
⎥⎥
⎥
⎥
⎤
⎢⎢
⎢
⎢
⎡ ××
×+×××
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
⎥⎥
⎥
⎥
⎤
⎢⎢
⎢
⎢
⎡ ×
=
1
-
1
-
ε (17) 
 
Lastly, according to Eqs. (1), (2), (12) and (13), Eq. 
(17) can be rewritten as follows:  
NM
N
NM
M
nrtrttotal +×++×= εεε    (18) 
The following uses analytical equation to evaluate 
the effective of power-saving by IPSS. Simulation 
experiment was conducted to validate the accuracy 
of the results. 
 
5. Numerical Results 
   This section presents the effect of Integrated 
Power Saving Schedule. In this study, the 
parameters were M = 50, N = 50, with mean of 
Poisson λ=25. Figure.4 shows the analysis of 
sleeping ratio with group 1, the influence of delay 
constraint is more obvious than the number of n 
because the MSS of group 1 needs to wake up at 
each T1 cycle. Therefore, the MSS of group 1 is 
not influenced by different numbers of n. Figure 5 
shows the analysis of sleeping ratio with group 2. 
As seen, the sleeping ratio increases as the delay 
constraint and the number of n increase. This is 
because the MSS of group 2 can aggregate more 
packets to transmit wake-up time at once. Figure 6 
shows the analysis of sleeping ratio with group 1 
and group 2. The sleeping ratio is better when the 
number of n and the delay constraint grow. 
 
 
Figure 4. Analysis of sleeping ratio with 
group 1 
 
 
Figure 5. Analysis of sleeping ratio with 
group 2 
 
 
Figure 6. Analysis of sleeping ratio with 
group 1 and group 2 
 
   Figure 7 shows the ratio of power-saving with 
analysis and simulation. In this case, Tf and T1 are 
set to 5 ms and 20 ms, respectively (i.e., m = 4) 
and other parameters are the same as above. In 
order to satisfy QoS requirement, the MSS in 
group1 needs to wake up in each T1 cycle, whereas 
that in group 2 only needs to wake up once in each 
T2 cycle. The MSS of group 1 needs to wake up at 
least a Tf time in a T1 cycle, so the sleeping ratio is 
about to 3/4. Figure 7 shows that the analysis 
model matches with the simulation results, and the 
sleeping ratio increases with n. However, the 
performance of power-saving mechanism can 
longer reach a better performance when the value 
of n increases to a certain degree. According to the 
initially evaluated result, the value of n is 
recommended to be set between 3 and 8. 
針對IEEE 802.16j穿透式中繼網路中有效資源排程 
林輝堂 1,2 林英佑 2 孫仲銳 2   
1 國立成功大學電機工程學系 
2 國立成功大學電腦與通信工程研究所  
E-mails: 1,2{htlin, q3897107, q3697117}@mail.ncku.edu.tw; 
 
中文摘要 
 
IEEE 802.16j 標準定義一套中繼式網路傳輸機制以提
升傳統 IEEE 802.16e 點對多點式網路中的系統效能與網路
覆蓋率。此傳輸機制主要分為兩種傳輸模式，穿透式中繼模
式與非穿透式中繼模式。其中，穿透式中繼模式主要用於改
善行動用戶端與基地台之間訊號品質不良之問題，以提升網
路效能;而非穿透式中繼模式則擴展基地台網路服務範圍於
原本基地台因遮蔽物或是行動用戶端超出基地台之服務範
圍而無法提供訊號覆蓋之區域。由於提升網路效能為目前資
源排程熱門問題之一，因此，本論文著重研究資源排程問題
於 IEEE 802.16j穿透式中繼傳輸模式並且提出一套有效且低
時間複雜度的啟發式（heuristic）中繼資源排程（Relay 
Resource Scheduling，RRS）演算法。此 RRS 演算法主要考
量多使用者分集（multiuser diversity）之特性以及支援「選
擇性傳輸」之排程，進而提升頻寬的利用度與網路效能。本
論文利用 Qualnet 模擬軟體建構 IEEE 802.16j 中繼式網路平
台以提供真實中繼式網路模擬分析。藉由複雜度分析以及實
驗模擬的結果，可驗證本論文所提出之演算法具有低複雜度
且可達成不同之利益值(Utility)之目的。 
關鍵詞：無線寬頻存取網路，WiMAX，全球互通微波存取，
啟發式。 
 
1. 緣由與目的 
隨著網際網路的蓬勃發展，以及全球消費形態的改
變，在網路上所發展出的行動應用也越來越廣泛。為了因應
許多不同的行動應用需求，在 2005 年，IEEE 802.16 任務群
制訂一套支援「行動式」傳輸的 IEEE 802.16e-2005[1]標準。
然而，即使 IEEE 802.16e 標準提供行動用戶端高傳輸速率的
無線寬頻服務，卻仍然面臨到一些困境。例如，若行動用戶
端移動至一個受遮蔽的地點（shadow hole），便可能造成與
基地台之間的訊號微弱，服務可靠度降低;再者，在某些人
群易於聚集的小範圍區域，此區域緊鄰基地台的服務範圍
（基地台服務範圍之外），但收不到基地台的訊號，行動用
戶端若從緊鄰的服務範圍內移動至此區域便會失去與基地
台的連線，無法使用服務。上述問題或許可藉由設置更多的
基地台來獲得解決，卻會大幅的增加營運所需的成本。因
此，IEEE 802.16 任務群在 2009 年公布了 IEEE 802.16j 標準
[10]，提供一套以架設成本較低的中繼站（Relay Station，簡
稱 RS）方式來解決上述問題。 
IEEE 802.16j 標 準 [2] 基 於 正 交 分 頻 多 工 存 取
(Orthogonal Frequency-Division Multiple Access)實體層架構
分別定義了兩套傳輸模式，即「穿透式中繼（transparent 
relaying）」與「非穿透式中繼（non-transparent relaying）」
模式。其中，穿透式中繼模式藉由建置穿透式中繼站來增加
行動用戶端傳輸效率，以改善行動用戶端與基地台之間訊號
品質不良之問題;而非穿透式中繼模式藉由佈建非穿透式中
繼站以延伸基地台網路服務範圍，此延伸之服務範圍可彌補
原本基地台因遮蔽物或是行動用戶端超出基地台之服務範
圍而無法提供訊號服務之缺點。本論文著重於設計一套資源
排程演算法提升系統效能於 IEEE 802.16j穿透式中繼網路架
構。對於中繼網路資源排程的相關研究，許多研究考量不同
特性提出相對應之資源排程機制，如研究[3]，作者研究多重
跳躍中繼網路於分時多工的網路架構進行排程，但是作者並
沒有考慮多使用者分集於不同子通道所產生的差異值。在研
究[4]當中，一套網路流量適應排程被提出用來執行如何依據
網路流量進行排程。但是，作者亦沒有考慮多使用者分集的
問題於他們的問題敘述當中。同時，許多相關研究[5][6]都
基於一個不真實的假設，即考慮無限的資料量 (infinite 
backlogged)進行資源排程。另外，IEEE 802.16j 標準提供一
種選擇性傳輸模式於下行鏈結，此模式允許直接連結基地台
之行動站台(簡稱 D-MS）有更彈性的排程方式。 
針對這樣的議題，本研究將在 IEEE 802.16j 穿透式中
繼網路中提出一套低時間複雜度的啟發式（heuristic）中繼
資源排程(Relay Resource Scheduling，簡稱 RRS)演算法，以
易於實作在即時性（real time）的 WiMAX 中繼網路當中。
RRS 演算法考慮選擇性傳輸模式與多使用者分集於下行方
向並且利用利益值(utility)的方式以提供不同目的進行資源
排程。此利益值包括了最大化產量（Maximum Throughput）
與比例性公平(Proportional Fairness)兩種目標，在最大產量
利益值當中，資源排程將考慮具有最大傳輸效率之行動用戶
端優先分配資源。而對於比例性公平利益值，將針對行動用
戶端的連結傳輸效率以及使用者之間的公平性，做為系統產
量與公平性之間的權衡(tradeoff)。並且，將針對所提出的
RRS 演算法進行時間複雜度分析。最後，本論文修改 Qualnet 
WiMAX 模組[7]以建置 IEEE 802.16j 穿透式中繼網路，使
得此演算法可模擬於真實的 IEEE 802.16j 網路環境。藉由複
雜度分析以及實驗模擬結果，可驗證出 RRS 演算法具有低
時間複雜度的特性，可運作在具有延遲限制之 IEEE 802.16j
穿透式中繼網路。並且，在考慮不同目的之利用度，可達成
所預期之系統效能。 
本篇論文之架構如下。第二章敘述 IEEE 802.16j 穿透
式中繼網路的架構，第三章介紹本篇論文所考慮知系統架構
與問題形成，第四章為所提出之啟發式 RRS 演算法，第五
章為 RRS 演算法的時間複雜度分析，第六章為電腦模擬分
析結果的呈現，最後，第七章是本篇論文的結論。 
 
2. IEEE 802.16j Transparent Relaying 網路架構 
IEEE 802.16j 標準定義「穿透式中繼（ transparent 
relaying）」的傳輸模式來提升網路容量（increase capacity）。
此模式下的資源排程由基地台所負責，屬於集中式的排程方
式，並且限定於最多兩點跳躍（two-hop）的中繼網路架構。
圖一為 IEEE 802.16j 的 transparent relaying 的訊框結構
（ frame structure ） 。 一 個 訊 框 切 割 成 兩 個 子 訊 框
 最大化產量（Maximum Throughput，簡稱 Max.）   mnmnn,mU                (2) 
其中， mn
m
n
m
n SC  。 mnS 為 MS m 在子通道 所分配
到的槽之個數。而 mnC 是其平均槽傳輸速率，根據[5]，
可由下列公式獲得： 
 mnp
s
AMCAMCm
n SNRlogBN
MNC  12              (3) 
其中，NAMC 為 AMC 槽的子載波個數，MAMC 為 AMC
槽之 OFDMA 符元個數。Bp為子載波之頻寬。Ns為一
個訊框之 OFDMA 符元個數。 m
nSNR 為 MS m 在子通道 
之訊雜比。 
對於最大化產量利益函式，產量是唯一的考量，
具有較高產量的 MS 將有較高的利益值。 
 
 比例公平（Proportional Fairness，簡稱 PF） 
  mmnmnn,m CTU                    (4) 
其中， mC 為至前一個訊框為止，排程給 MS 的平均傳
輸速率（bits/slot），以下列公式更新： 
     pC
tw
pC
tw
pC mmm 

  1111            (5)
 
 pC m 為在訊框 p 之 mC 值。tw 為視窗大小（window 
size）。  pC m 為 MS m 在訊框 p 被排程所達到的傳輸
速率（bits/slot）。 
 
公式(1)為本論文排程上之目標，但在 IEEE 802.16j 的
資源排程上仍然有以下的限制條件： 
1. 本論文不考慮空間重複利用（spatial reuse），且為了
避免干擾上的問題，訊框中的每個槽只能夠至多排程給一
個 RS 或一個 MS 使用，因此須滿足下列要求： 
    TN
RM
 

tnxx
r
r
t,n
m
m
t,n  ,      1      (6) 
2. 根據中繼網路的傳輸限制，IEEE 802.16j 將下行子訊框
切割成 downlink access zone 與 transparent zone 兩個區塊提
供分段傳輸使用。在 downlink access zone 用於將資料從 BS
傳送至 RS，因此，RS-MS 鏈結不可在此區塊排程，必須
滿足下列公式之要求： 
 
  0
1
  
   
T
t n r m
m
t,n
r
x

N R M
                 (7) 
3. 接續 2，在 transparent zone 中不可排程 BS-RS 鏈結，
必須滿足下列限制： 
  0
1
 
  
T
Tt n r
r
t,nx
 N R
                  (8) 
4. 本論文考慮 RS 使用解調變與前送的方式進行傳輸，因
此對於一個 RS 來說，在一個訊框內所接收的資料量必須
等於所傳送的資料量，所以須滿足下列公式之限制： 
    R
N M
   
   
rxCxC
T
Tt n m
m
t,n
m
n
r
n,t
βT
t Nn
r
n
r
      
11 
           (9) 
5. 一個槽 （slot ）在排程中被分配與否，可由下列式子
表示 (0 代表未被分配，1 代表被分配)：  
   10,x t,n                          (10) 
 
目 標 公 式 (1) 與 限 制 條件 (6-10) 的整 數 規 劃（ integer 
programming）問題是一個 NP-hard 問題[6]，最佳解無法在
短時間內獲得，而在 IEEE 802.16j 以訊框結構的網路中，資
源排程必須於一個訊框時間內完成。因此一個低時間複雜度
的演算法是必要的。本論文針對此問題提出了啟發式演算
法：中繼資源排程演算法（Relay Resource Scheduling，簡稱
RRS）。 
 
4. 中繼資源排程演算法(RRS) 
RRS 演算法根據一個輸入的 zone boundary 位置 β 
（downlink access zone 占下行子訊框之時間比例），將下行
子訊框以固定比例切割成 downlink access zone與 transparent 
zone，而 zone boundary 就位在第 βT 個時槽的位置。RRS 演
算法將利用多使用者分集（multiuser diversity）來提升頻寬
利用度，且支援 IEEE 802.16j 所定義的選擇性傳輸（即 D-MS
可在 transparent zone 排程）以提升排程的效能。RRS 演算法: 
 
 
 
前仍有可用槽的子通道 n 進行排程。針對一條子通道 n，在
line 27 的 while 迴圈內排程，此迴圈控制著此步驟是否結
束，若子訊框已沒有可用的槽，則進入下一個步驟；若 BS
內已沒有 D-MS 資料，演算法將結束。在 while 迴圈的排程
中，演算法為了獲得更高的利益值（即公式(1)），利用多使
用者分集（multiuser diversity）在 line 28 將子通道排程給具
有最高利益增進值的 D-MS，記作 d，並且考慮 BS 內的資料
量，決定所要分配的槽之個數 。 
 
3. 步驟三：對 R-MS 排程之子通道進行排序（line32）: 
RRS 演算法將於下個步驟進行 D-MS 與 R-MS 兩個群
組的比較與取代，為了優先取代掉利益增進值較低的排程，
以獲得較佳的子訊框利益值（即公式(1)），在 line 32 先對
R-MS 排程之子通道根據利益增進值 由低至高進行排序，建
立序列
orderN 。 
4. 步驟四：將 D-MS 群組排程取代較低效益的 R-MS 群
組排程（line 33-47）: 
為了獲得更高的排程利益值（即公式(1)），若排程給 D-MS
群組具有較高的利益增進值，則將取代步驟一中 R-MS 群組
之排程。在 line 33-47 的 while 迴圈中，開始對 R-MS 的排
程進行取代，在 line 34 選擇一個對於 R-MS 群組排程之利
益增進值最低的子通道 開始對 D-MS 進行排程。在演算法
的 line 35-38 即是在第 2 點跳躍鏈結區對 D-MS 進行排程，
在 line39-44 即是在第 1 點跳躍鏈結區對 D-MS 進行排程，
若 D-MS 排程的利益增進值大於 R-MS 群組之排程，便在
line45 進行取代。此步驟過程中若滿足下列其中一個條件，
演算法將結束： 
 已經比較過所有 R-MS 的排程。 
 BS 內已無 D-MS 的資料。 
 
5. 時間複雜度分析 
1. 步驟一：對 R-MS 進行排程（line2-25） 
在 line 2 的 for 迴圈對每個子通道進行排程，則時間複雜度
為 O(N)。針對 line2 所選即將在 transparent zone 排程的子通
道 n，進入 line 3 的 while 迴圈內進行排程，此 while 迴圈每
執行一次便會選取一個最佳的 R-MS 排程在 transparent zone
的子通道 n，而迴圈的終止條件為排程完在 transparent zone
子通道 n 的所有可用槽，因此針對一個 line 2 所選的子通道
n，while 迴圈執行的次數取決於在 transparent zone 的子通道
n 上排程的 R-MS 次數。而整個演算法 while 迴圈執行的次
數即為整個子訊框排程的 R-MS 次數，此次數與是否考慮佇
列的資料量有關（line 18-20），這裡分為兩個部分來分析，
首先是先不考慮佇列內資料量的問題，若某個 R-MS 在某個
子通道具有最高之利益增進值，則直接將子通道直接排程給
此 R-MS（即刪除演算法 line 18-20）；第二個部分即是考慮
佇列內資料量的問題，若佇列內的資料量小於可排程的傳輸
量則至多排程佇列內的資料量，此部分則會因為某個 R-MS
佇列為空而再次選擇其它的 R-MS 進行排程，因此增加了排
程 R-MS 的次數。針對上述二個部分進行分析: 
 若不考慮佇列內資料量問題，則在一條子訊框的
R-MS 全部排程的次數（總共 while 迴圈執行的次
數），記作 K。而平均一條子通道排程的 R-MS
次數（平均一條子通道 while 迴圈執行的次數）
為K 次（K =K/N）。其中K  < 2，說明如下： 
K 值增加的原因可分為兩部分： 
– 對於每個 line 2 所選擇的子通道在
transparent zone 一開始都必須選擇一個最
佳的 R-MS 進行排程，因此 K 值在此原因
下最多增加 N。  
– 當使用完在 downlink access zone 的一個子
通道中可用的槽，但 transparent zone 子通
道仍有可用的槽，便會再次對 transparent 
zone 的子通道排程，再次排程一次 R-MS，
此原因 K 值最多增加 N-1 次。 
因此，K < (2N-1)，則K < 2。 
 考慮佇列內資料量所增加排程 R-MS 的次數（總
共 while 迴圈增加的執行次數），記作 Q1。而平
均一條子通道所增加排程的次數（平均一條子通
道 while 迴圈增加執行的次數）為
1Q 次（ 1Q = 
Q1/N）。當所選的 R-MS 佇列內資料量不夠時，
就至多排程佇列內資料量的資源，並會再次選擇
其它佇列內有資料的 R-MS 繼續排程剩下的資
源，因此在整個訊框中因為佇列資料量為空而必
須再次選擇其它 R-MS 次數最多為 MR - 1 次，則
Q1  MR - 1，其中 MR為 R-MS 之個數。則 1Q  ( MR 
- 1)/N。 
因此，平均一條子通道排程的 R-MS 次數小於 1Q +2，
而 line 3 之 while 迴圈平均一條子通道執行的次數亦就小於
1Q +2 次，則 line 3 之 while 迴圈所造成的時間複雜度為
O( 1Q +2)。 
在 line 4-8 找出最佳的 R-MS，時間複雜度為 O(MR)。
在 line 5 中，每個 R-MS m 從
1mr
NRS 選擇對自己中繼鏈結
最有利的子通道為 O(1)。在 line 12 要對所有 RS 刪除
downlink access zone 中沒有可用資源的子通道。對於一個
RS r 從 rNRS 刪除一條子通道使用特定的資料結構只需花
O(1)。 
總結此步驟之時間複雜度：在 line 2 為 O(N)，在 line 3
為 O( 1Q +2)，在 line 4 與 line 7 為 O(MR)，在 line 5 為 O(1)，
刪除 rNRS 內的子通道為 O(NR)。因此，在 line 2-25 之時
間複雜度為 O(( 1Q +2) NMR+NR)。 
2. 步驟二：將剩餘之槽對 D-MS 進行排程（line 26-31） 
在 line26 將具有剩餘槽的子通道對 D-MS 排程，時間複雜度
為 O(N)。在 line 27 的 while 迴圈執行次數等於排程的 D-MS
次數，每條具有可用槽的子通道都至少排程一次。然而，在
line 28 考慮了佇列內資料量的影響，可能增加排程次數，最
多在一個訊框增加 MD - 1 次（MD為 D-MS 個數），記作 Q2。
而令 2Q 為平均一條子通道所增加的排程次數，則       
2Q = ( MD – 1)/N。則 line 26-31 之時間複雜度為 O(( 2Q +1) 
NMD)。 
3. 步驟三：對 R-MS 排程之子通道進行排序（line 32） 
line 32 對所有子通道排序的時間複雜度為 O(NlogN)。 
4. 步驟四：將 D-MS 群組排程取代較低效益的 R-MS 群
組排程（line 33-47） 
在 line 33 對 orderN 集合內的子通道進行對 D-MS 的排程，
orderN 最多具有 N 個元素，因此時間複雜度為 O(N)。在 line 
35-38 為對在 line 34 所選之子通道 n 的第 2 點跳躍鏈結區所
占之區塊對 D-MS 進行排程，此為單一區塊。而在 line 39-44
為對在 line 34 所選之子通道 n 的第 1 點跳躍鏈結區所占之
區塊對 D-MS 進行排程，此部分的區塊數可能超過一個，而
 
圖六:在邊緣分布拓樸之 Throughput vs. Load 
 
圖七:在邊緣分布拓樸之 Fairness index vs. Load 
7.結論 
本論文針對 IEEE 802.16j 穿透式中繼網路架構提出一
套有效的 RRS 資源排程演算法。RRS 能夠考慮不同的利益
值(Utility)的選擇適應不同的系統目的。藉由考慮多使用者
分集以及選擇性傳輸，可使得此演算法具有良好的效能。並
且藉由複雜度分析，可驗證所提出之 RRS 演算法具有低時
間複雜度的特性，適合於即時性的 WiMAX 網路中使用。若
考慮真實佇列的情況，則 RRS 演算法的時間複雜度為
O((M/N+3)  LN);若使用無限佇列長度的假設情況下，則 RRS
演算法的時間複雜度為 O(LN)。由實驗模擬結果可知，無論
是在隨機或是邊緣散佈的拓樸中，RRS 皆能維持較佳的網路
效能。並且達到所定義之不同利益值的目的。當最大系統效
能利益值使用時，可使得其系統效能高過於比例性公平利益
值之系統效能。相對地，比例性公平利益值可達到較佳的使
用者公平性。 
 
致謝 
 作者感謝行政院國家科學委員會補助此論文的研究發
表，國科會計畫編號為 NSC 97-2221-E-006-175 -MY3。 
 
參考文獻 
[1] IEEE 802.16e-2005 standard, “Local and Metropolitan 
Area Networks, Part 16: Air Interface for Fixed Broadband 
Wireless Access Systems: Amendment for Physical and 
Medium Access Control Layers for Combined Fixed and 
Mobile Operation in Licensed Bands,” Feb. 2006. 
[2] IEEE 802.16j-2009 standard, “Local and Metropolitan Area 
Networks, Part16: Air Interface for Broadband Wireless 
Access Systems: Amendment for Multiple Relay 
Specification,” Jul. 2009. 
[3] M. Charafeddine, O. Oymant, and S. Sandhu. System-level 
performance of cellular multihop relaying with multiuser 
scheduling. 41st Annual Conference on Information 
Sciences and Systems, March 2007.  
[4] O. Jo and D. Cho. Traffic adaptive uplink scheduling 
scheme for relay station in ieee 802.16 based multi-hop 
system. IEEE VTC (Fall), September 2007. 
[5] Alessandro Biagioni, Romano Fantacci, Dania Marabissi, 
and Daniele Tarchi, “Adaptive Subcarrier Allocation 
Schemes for Wireless OFDMA Systems in WiMAX 
Networks,” IEEE Journal on Selected Areas in 
Communications (JSAC), Vol. 27, No. 2, pp. 217-225, Feb. 
2009. 
[6] Supratim Deb, Vivek Mhatre, and Venkatesh Ramaiyan, 
“WiMAX Relay Networks: Opportunistic Scheduling to 
Exploit Multiuser Diversity and Frequency Selectivity,” 
14th ACM international conference on Mobile computing 
and networking (MobiCom), pp. 163-174, Sept 2008. 
[7] Qualnet: http://www.scalable-networks.com/ 
 
    
     (a)                  (b) 
 
Fig. 1. (a) Illustrative example of WSN topology. 
(b) Corresponding UR table for Node 0. 
 
The remainder of this paper is organized as fol-
lows. Section II reviews the related studies within 
the literature and briefly highlights the issues aris-
ing when implementing multicast routing schemes. 
Section III introduces the proposed multicast rout-
ing protocol. Section IV presents the simulation 
results. Finally, Section V draws some brief con-
clusions. 
II. RELATED WORK 
   
  In WSNs, many geographic-based multicast 
routing protocols (e.g., Minimum Incremental 
Power (MIP) algorithm [4], Localized En-
ergy-efficient Multicast Algorithm (LEMA) [5], 
Geographic Multicast Routing (GMR) protocol [6], 
and so on) have been previously proposed to realize 
multicast transmissions in WSNs. Although these 
protocols perform multicast transmission abilities 
for WSNs with many-to-many communication 
paradigm, the costs incurred in implementing these 
protocols were somewhat high since the sensor 
nodes were required to exchange and maintain a 
significant amount of additional information (i.e., a 
subset of the total network topology information [4] 
or the locations of all the neighboring nodes [5][6]). 
In an attempt to resolve these problems in geo-
graphic-based multicast schemes, the authors in 
[7][8] proposed an efficient and loca-
tion-unawareness multicast protocol, designated as 
Branch Aggregation Multicast (BAM), which used 
a Unicast Routing (UR) table to construct an en-
ergy-efficient multicast tree, thereby avoiding the 
requirement to exchange and store additional in-
formation at each sensor. 
  The following subsections describe the basic 
principles of the BAM protocol and then discuss 
the major issues arising when adopting this proto-
col to achieve multicast routing. 
 
A.   Description of BAM 
 
  In describing the BAM protocol, the following 
discussions consider a simple network topology 
comprising six sensor nodes (i.e., Nodes 0-5) and 
five sinks (i.e., Sinks A, B, C, D and E), as shown 
in Fig. 1(a). It is further assumed that Node 0 is the 
current source sensor. Whenever Node 0 wishes to 
transmit data to the sinks in the network, it con-
structs a UR table using the unicast DD routing 
protocol [2]. As shown in Fig. 1(b), the UR table 
has four fields, namely “Source Attribute”, 
“Neighbor Address”, “Sink Address”, and “Cost”. 
The “Cost” field indicates the number of hops from 
Node 0 to each of the destination sinks when rout-
ing the data through the specified nearest 
neighboring node. When the UR table has been es-
tablished, Node 0 executes the BAM algorithm to 
search for all the possible multicast routing paths 
between it and the sinks. For simplicity, in describ-
ing the detailed steps of the BAM scheme, the fol-
lowing discussions partition the BAM operational 
procedure into two sequential phases, namely the 
Best Routing (BR) table construction phase, and 
the Multicast Routing (MR) path selection phase. 
 
Phase I: BR Table Construction Phase 
 
  The aim of this phase of the BAM algorithm is to 
construct a BR table based upon the routing infor-
mation within the UR table. Here, the term “best 
path” is defined as the routing path with the mini-
mum hop-count between Node 0 and the desig-
nated sink. The best paths to the various sinks are 
selected from amongst the possible routes specified 
in the UR table. For example, in the case shown in 
Fig. 1, Node 0 selects entries #1, #2, #5, #8, #9, 
#10 and #11 as the best paths and uses these entries 
to populate the BR table, as shown in Fig. 2(a). 
 
Phase II: MR Path Selection Phase 
 
The purpose of this phase is to establish a MR 
table. Note that in the BR table, the more 
frequently a particular neighbor appears, the greater  
                                                                             
   
(a) (b) 
 
Fig. 3. (a) BAM multicast tree corresponding to 
MR Table in Fig. 2(d). (b) Alternative multicast 
tree for network topology shown in Fig. 1(a). 
 
represent the multicast cost of the transmissions 
from the nodes in Level i of a multicast tree to their 
children located in Level i+1. Thus, the total mul-
ticast cost (i.e., the number of hop-counts) of the 
multicast tree shown in Fig. 3(a), can be obtained 
by summing the costs of all levels (i.e., , , 
and ) and is equivalent to + +  = 1 + 3 + 
1 = 5.  
0
1C 12C
2
3C
0
1C 12C
2
3C
  Although the BAM protocol is capable of pro-
viding a multicast routing capability, there is no 
guarantee that the multicast tree which it discovers 
is the most efficient in terms of minimizing the to-
tal communication cost. For instance, Fig. 3(b) 
presents a more energy-efficient multicast tree for 
the network topology shown in Fig. 1(a). In this 
case, the multicast tree is established by aggregat-
ing the routing paths at Nodes 1and 5, respectively, 
and the corresponding multicast cost is equivalent 
to + +  = 1 + 2 + 1 = 4. The multicast cost 
of this multicast tree is clearly lower than that of 
the tree derived using the BAM algorithm (see Fig. 
3(a)). As a result, it is shown that the multicast so-
lution provided by BAM may not be an en-
ergy-efficient one. 
0
1C 12C
2
3C
III. DESCRIPTION OF PAT MULTICAST ROUTING 
PROTOCOL 
 
In order to minimize the multicast cost of WSN 
applications based on a many-to-many communica-
tion paradigm, this study proposes an effective 
multicast protocol, designated as Path-Aggrega-
tion-Tree multicast routing (PAT). The basic prin-
ciple of the PAT protocol is to evaluate and com-
pare the multicast costs of all the potential multi- 
 
 
Fig. 4. BNR table of SO. 
 
 
 
cast trees which provide routing paths from the 
neighbors of the source sensor to the destination 
sinks such that the path with the minimum cost can 
be chosen for routing purposes. In the proposed 
protocol, this is achieved by using a Multicast Cost 
Estimation scheme, designated as MCE. Note that 
in describing the MCE scheme, the following dis-
cussions consider the network topology and UR 
table shown in Figs. 1(a) and 1(b), respectively. 
 
A. Multicast Cost Estimation (MCE) Scheme 
 
Similar to BAM, the MCE scheme makes use of 
the UR table constructed by the DD routing proto-
col to perform estimation of the cost for each po-
tential multicast tree. Whenever a source node 
wishes to forward its sensed data to the sinks, it 
consults its UR table to derive two node sets, 
namely SM and SS, where SM is the set of all 
neighboring nodes and SS is the set of all sinks in 
the UR table. 
In the UR table, the occurrence of a neighbor set 
having a small number of members, but providing 
routing paths to all the sinks in SS indicates that a 
greater number of routing paths can be aggregated 
to this neighbor set. Therefore, the term “best 
neighbor-set” is introduced here to describe the 
subset of SM which comprises the minimum num-
ber of neighbors, N, providing routing paths to all 
the sinks. Note that N lies in the range MN ≤≤1 , 
where M is the total number of nodes in SM. As a 
result, another parameter, SO, is further defined as a 
set in which the members BB(x) comprise the best 
neighbor-sets, where . In the ex-
ample shown in Fig. 1, Node 0 inspects the UR ta-
ble and establishes the following parameters:   
)C(1 M, Nx ≤≤
                                                                             
 
 
Figure 5(a) illustrates the routing paths from 
Nodes 1 and 5 to all the destination sinks in SS ob-
tained by applying the DMR algorithm to the best 
neighbor-set B(1). Since all of the routing paths 
from Nodes 1 and 5 to the destination sinks are 
disjointed, this DMR multicast tree can be regarded 
as a “worst case” routing scenario in the sense that 
the multicast transmission from Node 0 to all the 
destination sinks in the network yields the maxi-
mum multicast cost, i.e., DMRB(1) = + + = 5.  01C 12C 23C
 
MCE for IMR Scenario 
 
  Node 0 evaluates the multicast cost of the IMR 
scenario by establishing an IMR multicast tree for 
BB(1) using the IMR Multicast-tree Construction 
(IMC) algorithm described in the following: 
 
z Node 0 views itself as the root and adds Nodes 
1 and 5 as its children. Thus, the distance be-
tween Node 0 and each of its neighbors in 
Level 1 is equal to 1 hop-count. 
z Inspecting the BNR table, Node 0 finds that 
the communication cost associated with Sink A 
when forwarding through Node 1 is equal to 2 
hop-counts. Therefore, Node 0 adds Sink A to 
Level 2 of the multicast tree as the child of 
Node 1. Furthermore, the BNR table shows 
that forwarding data to Sinks B and C through 
Node 1 incurs a cost of 3 hop-counts in both 
cases. Therefore, in accordance with the defi-
nition given above for the IMR scenario, Node 
0 adds Sinks B and C to Level 3 of the multi-
cast tree as the children of Sink A. In this way, 
the routing paths from Node 0 to B and C are 
aggregated at Sink A, which receives data 
from Node 1. 
z From the BNR table, Node 0 determines that 
the communication cost associated with Sinks 
D and E when forwarding data through Node 5 
is equal to 2 hop-counts in both cases. There-
fore, Node 0 adds Sinks D and E to Level 2 of 
the multicast tree as the children of Node 5. 
 
  The pseudo-code of the IMC algorithm presented 
above is shown in Algorithm 2. 
 
 
 
 
Figure 5(b) illustrates the routing paths from 
Nodes 1 and 5 to all the destination sinks in SS ob-
tained by applying the IMC algorithm to the best 
neighbor-set B(1). Since in this multicast tree, the 
routing paths from Node 0 to Sinks B and C are 
aggregated at Sink A and these paths are over-
lapped with the routing path from Node 0 to Sink A, 
the IMR multicast tree can be regarded as the “best 
case” scenario, and the corresponding multicast 
cost can be computed as follows: IMRB(1)= 
+ + = 1 + 2 + 1 = 4. Having computed the 
multicast costs of the DMR and IMR multicast 
trees for best neighbor-set B
0
1C 12C
2
3C
(1), PAT computes the 
                                                                             
020
40
60
80
100
120
140
2 3 4 5 6 7 8 9 10
Number of Intended Sinks per Packet (α)
To
ta
l E
ne
rg
y 
C
on
su
m
pt
io
n
(Jo
ul
e)
DD (β=200)
BAM (β=200)
PAT (β=200)
DD (β=100)
BAM (β=100)
PAT (β=100)
 
 
Fig. 6. Variation of total energy consumption 
with number of intended destination sinks per 
generated packet. 
 
ignored, i.e., the wireless channels were assumed to 
be loss free. In the simulations, the effectiveness of 
the PAT protocol was evaluated by comparing its 
performance with that of the DD and BAM routing 
protocols, respectively. The corresponding results 
are presented in Figs. 6-8, in which it is assumed 
that the source sensor node generates a total of 100 
packets. Note that to realize a many-to-many com-
munication paradigm, the generated packets are 
assumed to have multiple intended destination 
sinks. 
 
TABLE I: SENSOR NODE PARAMETERS 
Explanation Value  
Voltage 3 (Volt) 
The current draws for radio transmission 5.21 (mA) 
The current draws for radio reception 7.03 (mA) 
The current draws of CPU idle mode 3.2 (mA) 
The current draws of CPU sleep mode 110 (μA) 
The radio range of each sensor 5 (m) 
 
Figure 6 compares the variation of the total en-
ergy consumption within the network with the 
number of intended destination sinks (α) per gener-
ated packet under the PAT, BAM and DD routing 
schemes, respectively. Note that the figure presents 
results for both 100 and 200 sensor nodes, respec-
tively (i.e., β = 100 and β =200). It is observed that 
irrespective of the protocol applied, the total energy 
consumption reduces as the number of sensor 
nodes increases. This is to be expected since the 
higher node density associated with a greater num 
ber of sensor nodes enables all three routing 
protocols to identify a larger number of routing paths  
0
200
400
600
800
1000
1200
1400
1600
1800
2 3 4 5 6 7 8 9 10
Number of Intended Sinks per Packet (α)
N
um
be
r o
f F
or
w
ar
de
d
Pa
ck
et
s
DD (β=200) BAM (β=200)
PAT (β=200) DD (β=100)
BAM (β=100) PAT (β=100)
 
 
Fig. 7. Variation of number of forwarded pack-
ets with number of intended destination sinks 
per generated packet. 
 
with relatively fewer hop-counts, and thus the en-
ergy consumption is reduced. In addition, it is 
noted that for each protocol, the total energy con-
sumption increases as the number of sinks per 
packet increases. Amongst the three protocols, the 
DD scheme incurs the greatest energy cost due to 
its use of a unicast-based transmission approach for 
forwarding the sensed data. Comparing the per-
formance of the PAT and BAM schemes, it is evi-
dent that PAT consistently achieves a lower energy 
consumption than BAM irrespective of the number 
of sensors deployed or the number of sinks per 
packet. The performance improvement obtained 
from the PAT protocol stems from the fact that on 
average PAT enables more routing paths to be ag-
gregated at immediate sensor nodes than BAM. As 
a consequence, more of the individual routing paths 
between the source node and the destination sinks 
are overlapped and therefore “covered” by the 
same multicast transmission. 
Figure 7 compares the variation in the number of 
forwarded packets with the number of intended 
sinks per packet under the three routing schemes. 
Since the DD protocol is incapable of transmitting 
a single packet to multiple sinks located on differ-
ent branch paths, it inevitably results in the greatest 
number of forwarded packets at the intermediate 
nodes. Furthermore, it is observed that the PAT 
protocol results in fewer forwarded packets than 
BAM since it is specifically designed to establish a 
more energy-efficient multicast tree, and therefore 
reduces the number of forward hops required to 
reach the destination sinks. 
                                                                             
ACKNOWLEDGEMENT 
 
  The authors would like to thank the National 
Science Council, Taiwan, R.O.C., for supporting 
this research under grant NSC 97-2221-E-006-175 
-MY3. 
REFERENCE 
[1]  W. R. Heinzelman et al., “Adaptive Protocols 
for Information Dissemination in Wireless 
Sensor Networks,” in Proc. ACM MobiCom, 
pp.174-185, Aug. 1999. 
[2]  C. Intanagonwiwat et al., “Directed Diffusion 
for Wireless Sensor Networking,” IEEE/ACM 
Transaction on Network, vol. 11, no. 1, pp. 
2-16, Feb. 2003. 
[3]  P. Ciciriello et al., “Efficient Routing from 
Multiple Sources to Multiple Sinks in Wireless 
Sensor Networks,” in Proc. European Work-
shop on Wireless Sensor Networks, Jan. 2007. 
[4]  J. E. Wieselthier et al., “Energy-Efficient 
Broadcast and Multicast Trees in Wireless 
Networks,” Mobile Networks and Applications, 
vol. 7, issue 6, pp.481-492, Dec. 2002. 
[5]  J. A. Sanchez et al., "LEMA: Localized En-
ergy-Efficient Multicast Algorithm based on 
Geographic Routing," in Proc. IEEE LCN, 
pp.3-12, Nov. 2006. 
[6]  J. A. Sanchez et al., “Bandwidth-Efficient 
Geographic Multicast Routing Protocol for 
Wireless Sensor Networks,” IEEE Sensor 
Journal, vol. 7, no.5, pp.627-636, May 2007. 
[7]  A. Okura et al., “BAM: Branch Aggregation 
Multicast for Wireless Sensor Networks,” in 
Proc. IEEE MASS, Nov. 2005. 
[8]  A. Okura et al., “Branch Aggregation Multicast 
(BAM): An Energy Efficient and Highly 
Compatible Multicast Protocol for Wireless 
Sensor Networks,” IEICE Transaction on In-
formation and Systems, vol. e89-d, no. 5, pp. 
1633-1643, May 2006. 
[9]  L. Ji et al., “Differential Destination Multi-
cast-A MANET Multicast Routing Protocol for 
Small Group,” in Proc. IEEE INFOCOM, vol. 
2, pp. 1192-1202, Apr. 2001. 
[10]  Network Simulator Version 2 (ns2) Home. 
http://www.isi.edu/nsnam/ns/ 
[11]  IEEE 802.15.4 Standard Home. 
http://www.ieee802.org/15/ 
[12]  V. Shnayder et al., “Simulating the Power 
Consumption of Large-Scale Sensor Network 
Applications,” in Proc. ACM SenSys, pp. 
188-200, Nov. 2004. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                                                             
應用於IEEE 802.16網路之整合性節能排程演算法 
 
 
Hui-Tang Lin 
Department of Electrical 
Engineering and Institute of 
Computer Communication 
Engineering, National Cheng 
Kung University, Taiwan 
htlin@mail.ncku.edu.tw 
Rung-Shiang Cheng 
Department of Electrical 
Engineering, National Cheng 
Kung University, Taiwan 
chengrs@nsda.ee.ncku.edu.tw 
Yuen-Fu Chiu 
Institute of Computer and 
Communication Engineering, 
National Cheng Kung 
University, Taiwan 
yuen_fu_chiu@nsda.ee.ncku.
edu.tw 
 
 
中文摘要 
 在無線網路中，無線通訊裝置的電源管理一直是
一個相當重要的議題，為了減少無線通訊裝置的能源
消耗，因此IEEE 802.16工作小組在IEEE 802.16e這個
標準中，定義了電源管理的方法。為了有效的使用無
線通訊裝置的能源以延長無線通訊裝置的運作時
間，本文進一步提出一個整合封包排程與睡眠模式控
制的排程演算法，稱為IPSS(Integrated Power Saving 
Schedule)，期望能在滿足QoS的前提下，進行睡眠模
式與排程單元的控制，以延長WiMAX行動通訊裝置的
運作時間。 
 
 
1. 簡介 
 
 近年來，由於無線通信技術的進步與各種網路資
訊服務的普及，寬頻網路的存取技術也從傳統以電纜
或光纖為主的有線網路延伸至寬頻無線網路，預期透
過寬頻無線網路的普及，行動通訊將可提供更加多元
且高品質的服務；然而在移動式的存取環境中，行動
設備將消耗可觀的能源在無線通訊上，因此如何減少
能源的消耗、延長行動通訊設備的使用時間，也成為
一項需要考慮的重要的議題。 
 WiMAX網路是遵循IEEE 802.16[1]通訊協定運作
的 無 線 寬 頻 存 取 技 術 ， WiMAX 支 援 PMP 
(Point-to-Multi Point)和Mesh兩種網路環境。PMP網路
的運作模式跟傳統的寬頻無線存取網路的網路拓樸
方式類似，由base station(BS)直接對所涵蓋範圍內的
所有subscriber station(SS)做資料傳輸。至於在Mesh的
模式中，資料傳輸可直接透過鄰近的SS將資料送往
BS，換言之，SS之間可以用multi-hop的方式傳輸資料。 
 雖然WiMAX可提供較WiFi更高的資料傳輸速率
與傳輸距離，但行動通訊設備在通訊上也勢必消耗更
多的能源，因此，對行動通訊設備而言，電源管理的
問題就顯得更加地重要。為了延長行動通訊設備的使
用時間， IEEE 802.16e允許MSS(Mobile Subscriber 
Station)可以在不需要進行資料傳輸時，暫時將射頻元
件關閉並進入睡眠模式，以減少能源消耗。同時，根
據連線的服務品質需求，在IEEE 802.16e中也制定了
三種類型(Type)的睡眠模式控制機制，稱為PSC(Power 
Saving Class)，每條連線需選擇對應的節能類別以及
相關的參數。若MSS與BS間建立多條連線，實際上的
睡眠模式將依照所有對應的節能類別進行運作。 
 近年來，已經有許多關於IEEE 802.16電源管理的
研究被提出，在[2] [3]中，針對單一MSS與Type I PSC
的睡眠模式運作提出包含上下載的分析模型，在[4] [5]
中，針對能源消耗與傳送時間的延遲(delay)進行Type 
I PSC的分析與評估。在[6]中，進一步探索在滿足預
期的節能效果與時間延遲的需要之後，該如何作出取
捨設定PSC參數。由於過去的研究大都只有針對單一
的802.16連線進行分析評估，在[7] [9] [10]中，提出以
MSS的節能為主要考量，但能滿足頻寛與延遲限制的
排程方法。 
 儘管過去已經有關於IEEE 802.16能源管理的研
究被提出，但是先前的研究大多是建立在比較簡單的
假設上，例如只有考慮特定的應用服務，或者僅針對
下載或上傳進行探討，而不適用於存在各類型連線服
務且同時有許多MSS進行傳輸的情況。為此在本文提
出稱為IPSS的整合性排程方法，結合排程單元與PSC
控制單元，利用兩階層式排程的方式，在保證連線服
務品質的前提之下，同時提昇MSS的能源使用效能。 
 本文的組織架構如下：章節2說明IEEE 802.16的
節能機制和相關研究，章節3介紹本文提出之節能排
程機制，章節4使用模擬的方式來驗證本文所提之改
進方法，章節5是本研究的結論。 
 
2. IEEE 802.16的節能機制 
 
    為了達到省電的目的，IEEE 802.16e定義了節能
類別(PSC，Power-Saving Class)來實作電源管理的方
法。 在IEEE 802.16e中，MSS的電源管理運作可分為
兩個狀態：啟動狀態(Active)與關閉狀態(Inactive)。在
啟動狀態時，MSS的節能類別可提供睡眠模式(Sleep 
mode)運作的控制，反之在關閉狀態時，則不提供睡
眠模式的控制。MSS可以自行選定欲使用的節能類
別，但是在進入睡眠模式前，MSS必須和BS協調欲使
Unit)傳送給MSS的順序；在上傳(Uplink)部分，則由
上傳排程器(UL scheduler)根據QoS參數與MSS的頻寬
要求，分配上傳的頻寬。需要注意的是，上傳的排程
可分為兩個部份，一部份在BS進行，另一部份則是在
MSS進行。首先，BS的上傳排程器會根據各個MSS發
出的頻寬請求(Bandwidth request)決定他們在每個訊
框裡所能使用的頻寬資源多寡並以UL_MAP訊息告
知MSS；之後，MSS再依照先前發出的頻寬請求訊息
及所收到的UL_MAP訊息來決定要如何使用這些被
分配到的頻寬資源。 
    如圖3所示，依據原先IEEE 802.16e標準的規範，
睡眠模式運作是由BS的PSC控制器統一管理，藉由發
送MOB-SLP-RSP訊息以控制各個MSS的睡眠視窗與
聆聽視窗時間；另一方面，MSS的PSC管理器會根據
所收到的MOB-SLP-RSP訊息通知RF控制器進行睡眠
模式的運作。 
    為了增進睡眠模式運作的效率，並且保證提供的
連線服務品質，本文提出一個整合排程單元與節能類
別控制單元的架構，如圖3所示，我們在BS的下載/上
傳排程器與PSC控制器之間加入一個整合性的省電排
程模組，稱為IPSS；IPSS除了控制PSC控制器，驅使
MSS根據IPSS排程結果進行睡眠模式的運作之外，也
藉由控制下載/上傳排程器，使MSS在啟用睡眠模式的
同時，也能滿足連線的服務品質。 
 
 
圖3．IPSS structure in MAC系統架構圖 
 
 
圖4．兩階層式排程策略的例子 
 
3.2 以MSS為基礎的兩階層式排程策略 
 
 IPSS使用兩階層式的排程策略，對MSS進行正常
運作模式與睡眠模式的控制。如圖4所示，演算法的
排程週期可分為排程週期(Scheduling cycle)與排程次
週期(Sub-cycle)兩種，其中排程週期是排程次週期的β
倍長(β為整數)，排程次週期的排程時間長度則為訊框
的α倍長(α為整數)。 
 在進行排程時，IPSS會將MSS區分為兩種群組，
需要即時性的服務的MSS會被納入第一群組(G1)，而
僅需要非即時性的服務的MSS則會被納入第二群組 
(G2)，被納入群組後，將給予加入的MSS從0開始遞增
的成員編號。令T1, T2分別代表排程次週期與排程週期
的時間長度，IPSS排程器會依下列兩個步驟進行排班: 
步驟一: 計算排程次週期與排程週期的時間長度，
以及在一個排程次週期中，G1和G2的通道
使用時間LG1與LG2。 
步驟二:   計算群組中MSS被預留的頻寬資源，以及 
          MSS的覺醒時間。 
    令Tf表示一個802.16訊框的時間長度，排程次週
期的時間長度T1計算如下: 
NiTiTT f
i
f    ),constraintdelay (max  arg   ,1    (1) 
然後，計算排程週期的時間長度T2如下: 
NTT     ,12                  (2) 
    在Eq.(1)和Eq.(2)中，排程次週期的時間長度是根
據第一群組MSS的QoS參數(即延遲限制)決定的，而排
程週期的時間長度可以藉由設定β值的大小來調整。 
    在一個排程週期時間內，IPSS每間隔一個排程次
週期時間(即T1)就會對第一群組的MSS進行排程，經
過β個T1週期後(即T2, 根據Eq.(2)) 接著才對第二群組
的MSS進行排班。在取得T1週期的時間間隔後，接著
排程器會計算第一群組MSS在排程次週期中的存取
時間： 
 Group2 and Group1 inflow minGroup1 inflow min11 /
i
i
i
i
G RRTL
        (3) 
其中Rimin是保留給第i個服務資料流的最小頻寬。 
    在每個排程次週期中，剩下能給第二群組的存取
時間可經由下列方式取得： 
112 GG LTL                  (4) 
每間隔一個排程週期時間，IPSS會將這些分散在β個
排程次週期中的頻寬資源(即LG2)，重新分配給第二群
組的MSS使用。相似地，每間隔一個排程次週期時
間，IPSS將LG1的頻寬資源重新分配給第一群組的
MSS。 
由於β值的設定會影響節能的效果，特別對於第
二群組的MSS會產生較大的影響，令awake-ratio，ε，
表示在一個排程週期內，MSS醒著的時間比率，令Nexf
表示在一個排程週期中MSS除了被排程的訊框以外
平均額外醒著的訊框數。根據Eqs.(1) (2)，ε可以用如
下的式子表示： 
 

 exf
f
fexf N
T
TN 1
)(
)1(             (5) 
從上述式子可以粗略地看出β值與ε之間呈反比關係，
換句話說，β值愈大的話, ε相對的會比較小(代表MSS
進入睡眠模式的比例就會增加)，根據初步評估的結
果，β值的設定建議範圍在3到8間。 
    在上述步驟中，IPSS先以群組為單位，計算出每
個群組的排程週期與預先保留的頻寬資源。接下來，
IPSS針對每個MSS計算可預先分配到的頻寬資源(為
方便表示，以下都以時間為單位)，以及可以開始使用
頻寬資源的相對時間(Uk，也就是MSS的覺醒時間)。
對第一群組中的第k個MSS中的而言，其可分配通道頻
寬資源為： 
 
圖5．PMP網路拓撲 
 
表2．系統相關參數 
Parameter Value
PHY OFDMA
Duplexing Mode TDD 
Bandwidth 10 MHz
Number of sub-carriers(FFT size) 1024 
Number of sub-channels 30 
Frame duration 5 ms 
PS per frame 24 
 
    表3為Application traffic generator的參數設定。在
模擬進行時，即時性(Real-Time)連線以UGS為主，並
以CBR的方式產生欲傳輸的資料，而非即時性(Non 
Real-Time)連線以則是以NRT-VR為代表，針對這類型
的連線，我們使用Poisson traffic model來模擬資料出
現時間，若沒有特別說明，睡眠模式的運作都是以表
4做為預設參數。 
 
表3．封包產生的傳輸模式 
 Real-Time Non Real-Time 
Service Type UGS NRT-VR 
Packet Size 160 bytes 500~1500 bytes (Uniform Distribution) 
Inter-arrival 
Time 20 ms 
40 ms 
(Exp. Distribution) 
Avg. Data 
Rate 64 kbps 200 kbps 
 
表4．節能類別相關參數的設定 
 Type I Type II
Initial Sleep Window 8 3 
Final Sleep Window 128 N/A 
Listening Window 1 1 
 
4.2 模擬結果 
 
    由於從BS至MSS的排程管理較為單純，因此實驗
一開始先討論在下載進行排程管理對省電的省電機
制之影響。在此實驗中，網路上的MSS會有一半使用
UGS與BS的下載建立即時性連線，另一半則使用
NRT-VR建立非即時性連線，服務品質的參數如表5
所示。在實驗中我們增加MSS的個數來調整網路的負
載情況，藉以表現出負載量增加對於Type I PSC節能
效果的影響；並且將對於節能類別並沒有任何管理的
演算法(without mgnt)以及MMPS演算法作為比較的對
象。在以上兩種執行睡眠模式的演算法上，我們使用
WFQ排程演算法來配合進行傳輸封包的選擇。 
 
表5．QoS參數設定 
QoS parameters Real-Time Non Real-Time
Minimum Reserved 
Data Rate 64 kbps 200 kbps 
Delay Constraint 80 ms N/A 
 
    圖6呈現出三種演算法提供的平均睡眠比率(MSS
的睡眠時間與運作時間之比值)，在這個網路中，各有
一半的MSS使用Type I PSC運行睡眠模式。模擬結果
顯示沒有進行能源管理的方法與MMPS方法的節能效
果隨著負載的增加下降，IPSS則明顯能使MSS穩定地
維持睡眠模式的運作。IPSS優於MMPS的主要理由在
於IPSS將IEEE 802.16的服務類別進一步地區分為兩
個排程類別，並進行睡眠模式的管理，藉此減少網路
負載的影響、提升整體的節能效果。 
 
 
圖6．三種睡眠策略的睡眠比率比較 
 
    為了瞭解排程方法對即時性連線(即UGS)服務品
質的影響，下面進一步觀察封包在網路上的平均等待
傳輸時間。如圖7所示，MMPS與IPSS演算法會有比較
長的延遲時間，原因是以延遲限制做為提供服務的週
期，因此使得延遲時間稍為增加；相對的，在沒有進
行電源管理的連線等待傳送的延遲時間較短，原因是
以連線封包產生的週期作為提供服務的週期，因此模
擬結果顯示延遲時間相對較短(在網路負載較低的情
況下大約維持在10 ms)。 
    雖然模擬結果顯示IPSS演算法會使得封包的延
遲時間增加，比較圖6和圖7結果可以發現，IPSS可以
滿足連線的服務品質要求，而且能提昇MSS的能源使
用效能。除此之外，在MSS的個數超過92個之後(根據
量測只剩下2.9%的平均可用頻寬)，MMPS和沒有電源
管理之方法的延遲時間會隨著網路負載增加而變
長，同時節能的效果也跟著變差，但IPSS仍然維持在
穩定的狀態，原因是IPSS驗算法能動態的分配下載與
上傳的頻寬，因此較能有效地利用每個訊框中的可用
頻寬。 
 
 
圖11．針對第一群組平均的睡眠比率 
 
 
圖12．針對第二群組平均的睡眠比率 
 
5. 結論 
 
    在WiMAX無線行動寬頻存取網路上，由於遠距
離大量資料傳輸容易消耗許多能源在無線通訊上，因
此如何有效地利用行動設備有限的電力是一個重要
的問題。本文針對改善IEEE 802.16e通訊協定的睡眠
模式運作，提出一個整合排程與睡眠模式控制的演算
法，此方法解決了多個節能類別同時運作時導致節能
效果不彰的問題，亦同時減少了行動站台為了等待存
取網路頻寬而造成的能源浪費。本文提出之方法將行
動站台分為兩類，提供不同的睡眠模式節能效果，模
擬結果證明，本文所提之方法可以在保證連線的服務
品質之下，提供IEEE 802.16行動站台更好的節能效
果。 
 
6. 參考文獻 
 
[1] IEEE Std. 802.16e/D9-2005, IEEE Standard for Local 
and Metropolitan Area networks – Part 16: Air Interface 
for Fixed Broadband Wireless Access Systems – 
Amendment for Physical and Medium Access Control 
Layers for Combined Fixed and Mobile Operation in 
Licensed Bands, June 2005.  
[2]  Y. Xiao, “Energy saving management in the IEEE 
802.16e wireless MAN,” IEEE Communications Letters, 
July 2005, vol.9, no.7, pp.595-597. 
[3]  Y. Zhang, and M. Fujise, “Energy management in the 
IEEE 802.16e MAC,” IEEE Communications Letters, 
April 2006, vol.10, no.4, pp.311-313. 
[4]  K. Han, and S. Choi, “Performance analysis of sleep 
mode operation in IEEE 802.16e mobile broadband 
wireless access system,” in Proc. VTC 2006-Spring, 
May 2006, vol.3, pp.1141-1145. 
[5] M.G. Kim, J. Choi, and M. Kang, “Performance 
evaluation of the sleep mode operation in the IEEE 
802.16e MAC,” in Proc. ICACT'07, Feb. 2007, vol.10,  
pp.602-605. 
[6] M.G. Kim, J. Choi, and M. Kang, “Trade-off guidelines 
for power management mechanism in the IEEE 802.16e 
MAC,” Computer Communication, June 2008, vol.31, 
no.10, pp.1857-2642. 
[7] Y.L. Chen, and S.L. Tsao, “Energy-efficient Sleep-mode 
Operations for Broadband Wireless Access Systems,” in 
Proc. VTC 2006-Fall, Sep. 2006, pp.1-5. 
[8] Y. Ge, and G.S. Kuo, “An Efficient Sleep Mode 
Management Scheme in IEEE 802.16e Networks,” in 
Proc. ICC'07, June 2007, pp.5957-5962. 
[9] J. Shi, G. Fang, Y. Sun, J. Zhou, Z. Li, and E. 
Dutkiewicz, “Improving Mobile Station Energy 
Efficiency in IEEE 802.16e WMAN by Burst 
Scheduling,” in Proc. GLOBECOM'06, Nov. 2006, 
pp.1-5. 
[10] S.C. Huang, R.H. Jan, and C. Chen, “Energy Efficient 
Scheduling with QoS Guarantee for IEEE 802.16e 
Broadband Wireless Access Networks,” in Proc. 
IWCMC'07, Aug. 2007. 
[11]  B. Li, Y. Qin, C.P. Low, and C.L. Gwee, “A Survey on 
Mobile WiMAX,” IEEE Communications Magazine, 
Dec. 2007, vol.45, no.12, pp.70-75.  
[12] ITU-T Recommendation G.114 “One-way transmission 
time” 
[13] H. Oouch, T. Takenaga, H. Sugawara, and M. Masugi, 
“Study on Appropriate Voice Data Length of IP Packets 
for VoIP Network Adjustment,” in Proc. 
GLOBECOM'02, Nov. 2002, vol.2, pp.1618-1622. 
[14] E. Fortunato, M. Marchese, M. Mongelli, and A. 
Raviola, “QoS guarantee in telecommunication networks: 
technologies and solutions,” International Journal of 
Communication Systems, Sep. 2004, vol.17, no.10, 
pp.935-962. 
[15] D. Wu, “QoS provisioning in wireless networks,” 
Wireless Communications and Mobile Computing, Nov. 
2005, vol.5, no.8, pp.957-969. 
[16] D. Wu, and R. Negi, “Power control and 
scheduling for guaranteeing quality of service in 
cellular networks,” Wireless Communications and 
Mobile Computing, Sep. 2006, vol.8, no.1, 
pp.75-92. 
[17] V.P. Kafle, S. Pack, Y. Choi, E. Kamioka, and S. 
Yamada, “IIPP: Integrated IP paging protocol with a 
power save mechanism,” Wireless Communications and 
Mobile Computing, July 2006, vol.7, no.5, pp.553-568. 
[18] QualNet Simulator, http://www.scalable-networks.com/ 
 
 2
Inaltekin, Mung Chiang and H. Vincent Poor 
 Multi-Portfolio optimization: A unified framework based on variational inequality, Yang 
Yang, Francisco Rubio, Gesualdo Scutari, Daniel P. Palomar  
Sessions C1: Stochastic and Dynamic Games Session Chair: Galina Schwartz 
 Every stochastic game with perfect information admits a canonical form, Endre Boros, 
Khaled Elbassioni, Vladimir Gurvich and Kazuhisa Makino 
 Analyzing the Dynamics of Evolutionary Prisoner's Dilemma on Structured Networks, 
Ahmet Yasin Yazicioglu, Xiaoli Ma and Yucel Altunbasak • Spatio-temporal control for 
Dynamic Routing Games, Manjesh Kumar Hanawal, Eitan Altman, Rachid El-Azouzi 
and Balakrishna Prabhu  
 Designing Incentive Schemes Based on Intervention: The Case of Imperfect Monitoring, 
J. Park and M. van der Schaar 
4 月17 日: 
大會第二天一早，我參與了 Plenary 2，在這Plenary 2 中，大會邀請了知名的學者Prof. 
Sergiu Hart 分享其如何利用game theory 進行分析策略選擇產生之動態行為研究之心
得。 
Sunday, 17 April 2011, 11:15am-12:15pm 
Title: Game Dynamics and Equilibria 
Prof. Sergiu Hart 
Hebrew University of Jerusalem, Israel 
Abstract: 
An overview of a body of work on dynamical systems in multi-player environments. On the 
one hand, the natural informational restriction that each participant does not know the payoff 
functions of the other participants -- "uncoupledness" -- severely limits the possibilities to 
converge to Nash equilibria. On the other hand, there are simple adaptive heuristics -- such as 
"regret matching" -- that lead in the long run to correlated equilibria, a concept that embodies 
full rationality. Connections to behavioral economics, neurobiological studies, and 
engineering, are also mentioned. 
接下來，我更是參與了許多 Technical session 聆聽各方學者所發表之論文，藉此更可充
實自己的學識以及掌握目前自己所專注之研究領域動向。 
參與的session 有: 
Sessions D2: Game-Theoretic Network Models Session Chair: John Musacchio Incentivizing 
Upload Capacity in P2P-VoD Systems: A Game Theoretic Analysis, 
Weijie Wu, John C. S. Lui, Richard T. B. Ma 
 Service Routing in Multi-ISP Peer-to-Peer Content Distribution: Local or Remote 
Srinivas Shakkottai 
 Bargaining and peering between network content and coverage providers, Dah Ming 
Chiu, Jianwei Huang, Sam Feng 
Sessions E1: Cooperative Games in Networks Session Chair: Rajgopal Kannan Coalition 
Stability under QoS Based-Market Segmentation, Helene Le Cadre, Johanne Cohen, Loubna 
Echabbi and Dominique Barth 
 On the Shapley-like Payoff Mechanisms in Peer-Assisted Services 
with Multiple Content Providers, Jeong-woo Cho and Yung Yi 
 Economic Viability of Femtocell Service Provision, Lingjie Duan, Jianwei Huang and 
Biying Shou 
4 月18 日: 
第三天一早輪到我進行Oral presentation，在報告後，有許多學者向我請問一些研究上的
問題，使我獲益良多。此session 上還有其他知名的學者也被邀請前來發表paper。其中，
最讓我印象深刻的有Hierarchical Coalition Formation Game of Relay Transmission in IEEE 
802.16m, Dusit Niyato, Xiangyun Zhou, Are Hj?rungnes, Ping Wang and Yifan Li 雖然 Zhu 
 4
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                              日期：年月日 
                               
一、參加會議經過 
8 月 25 日早上，由高雄小港機場出發，搭乘華信航空抵達香港再轉機搭乘海南
航空抵達咸陽機場，並搭乘接駁車於晚上 9 點 30 左右抵達下榻飯店。26 日早上前
往 ChinaCom 會議位西安市區的索費特會場報到，領取名牌、會議資料等，並於參
予開幕式以及當日下午的論文報告。27日早上 9:00再度前往會議會場，參加 keynote
演講，並根據會議資料，選取相關領域的報告會議參與。當日晚上，參與 banquet
並上台領取獎項且與大會主席以及其他領獎人照相。8 月 28 日早上在參與其他相關
演講及論文報告。 
二、與會心得 
 本人發表之論文題目為”An Analytical Framework for a WDM EPON with 
Differentiated Services”，有幸為大會 accepted 且獲選為本領域的 Best Paper 
Award，因此此次出席此國際學術會議的主要目的為報告本篇獲獎論文內容，分享
研究成果，並與國內外相關研究領域的學者意見交流。 
此次參與會議會第一次參與國際會議，也是第一次前往大陸。為了要讓出國報告
順利，於前一天早上搭機前往大陸，並先熟悉大會會場以及下榻的飯店位置等。也
因而順利完成此次出國報告行程。再這次會議中，結識了不少國內外學者、教授與
同學，大家於 ChinaCom 會議中共同分享彼此的研究成果，因此此次出國會議報告
讓我獲益良多。 
三、考察參觀活動(無是項活動者略) 
計畫編
號 
NSC 97-2221-E-006 -175 -MY3 
計畫名
稱 
植基於醫療看護需求之情緒管理與促進服務運算系統-支援
情緒管理服務之無線網路整合系統 
出國人
員姓名 賴家齡 
服務機
構及職
稱 
國立成功大學電通所博士生 
會議時
間 
98年 8月 26日 
～ 98 年 8 月
28 日 
會議地
點 
中國陝西省西安市 
會議名
稱 
(中文)2009 中國通訊與網路國際研討會 
(英文) 2009 International Conference on Communications and 
Networking in China (ChinaCom) 
發表論
文題目 
(中文)一個針對分波多功乙太被動式光纖網路的分析框架 
(英文)An Analytical Framework for a WDM EPON with 
Differentiated Servcies 
 6
行政院國家科學委員會補助國內專家學者出席國際學術會
議報告 
100 年 8 月 22 日 
報告人
姓名 
賴家齡 服務機構 
及職稱 
 
國立成功大學電通與通信研究所博士
班學生 
時間 
會議 
地點 
100.07.31-100.08.04 
美國夏威夷州茂宜島 
本會核定補助文
號  
會議 
名稱 
 (中文) 第 20 屆國際電腦通訊與網路研討會  
 (英文) The 20th International Conference on Computer Communications and 
Networks (ICCCN) 
發表 
論文 
題目 
(中文)於乙太被動式光纖網路下支援三合一整合型服務且以框架為導向的
頻寬動態分配演算法 
(英文)FIPACT: A Frame-Oriented Bandwidth Allocation Scheme for Triple-Play 
Services over EPONs 
報告內容應包括下列各項： 
一、參加會議經過 
ICCCN 是一個由 IEEE Communications Society 和其他相關業界和學術團體  (如
Qualcomm 和 NSF 等 ) 贊助，列名於 IEEE major conference 的會議之一，學術影響力甚
遠，截至目前為止，已經舉行了 19 屆，是一個享譽國際的著名的學術會議。每一屆的
會議都有來自世界各地國家的教授學者投稿，發表對於目前在網際網路 (Internet) 上一
些創新的想法，以及新興的網路議題等。此外，ICCCN 會議為了維護論文內容的品質，
每年都會聘請國際著名學者審稿，嚴謹的把關會議論文的內容品質，並且盡力促進各個
國家學者間的技術上交流，例如專門的 Workshop 會議或 technical program 會議等 ，使
各國的專家學者都可以在舉行會議的期間互相分享及討論創新網路技術，因此是一個值
得學者專家投稿並且參加的會議之一。 
而這一次 ICCCN 會議為了慶祝第 20 屆的會議，更是在夏威夷茂宜島擴大舉辦這一次的
會議。從 7 月 31 日到 8 月 4 號，為期五天的會議，其中共有 6 場 high-quality 的 tutorials
開放給所有的參與會議的學者外，更有4場keynote演講以及3場Plenary Panel Discussion
演講，再加上同時平行進行的多場 oral presentations 以及 work shops 等，涵括了目前最
新的通信和網路技術的主題，更是提供了給與會者最多及最豐富的知識饗宴。 
以下敘述為有參與到的會議日期及內容描述： 
8 月 1 日： 
8:30 – 10:15 Keynote I 
John M. Cioffi (ASSIA, Inc. USA) 
“Dynamic Spectrum Management” 
串音干擾 (crosstalk)一直都是 Digital subscriber line (DSL)系統在性能上最主要的限制因
附件三
 
 8
WDM 網路架構上。主要提出如何去計算一個 WDM 網路上所花費的網路成本，以及相
對應的 Reliability 的考量。 
“Wavelength Retuning in Optical Waveband Switching Networks” 
本篇演講者主要是講述如何使用現存可以用的波長個數，再配合 Switch 元件的應用達到
wavelength retuning 的利用。 
“Dynamic Non-Continuous Advance Reservation over Wavelength Routed Networks” 
本篇演講者主要提出一個 non-continuous 的資料傳輸方式，即將資料分割使之可以在不
同的 lightpath 上傳輸，並且探討這樣的傳輸方式對於 receiver 的 overhead，以及 delay 
performance 的影響。模擬的部分主要分成兩種方法的傳輸的比較，分別是 packet-time
和 packet-wavelength 的方法比較。 
8 月 3 日 
由於參加本次會議的目的，是去做論文的 oral presentation，而我 present 的時間是在會
議的第四天。由於 conference paper presentation 主要是排在第四天和第五天，因此 8 月 3
日這一天，有非常多的會議發表者出席。再者，由於我的專長領域是在光纖網路的部分，
因此此天會議的行程只有針對 Presentation 的 technical program 為主。我所參與的
technical program 為  Optical Networking Solutions for Emerging Applications 這個
symposium，並且為此 session 的第三位論文發表者。 
在此 Optical session 中，所有的論文發表者都是以提出新型的 WDM 網路架構翰其光纖
網路中的節能減碳為主題，對於通訊協定的探討上，只有我這一篇是針對通訊網路頻寬
分配。因此，在發表完我的論文之後，被在場的人所提出的問題皆是跟所使用的網路硬
體或是佇列頻寬如何切割，不過也由於是這樣，更加深我對於網路研究的興趣，我從此
得知做網路並不能只有著重於軟體或演算法的部分，對於所提出的方法是否能實際在網
路上實現或應用也是一個需要考慮的地方。於會議結束後，我與此 session 的 chair 
Zuquing Zhu 有稍微的討論一下我的論文不足的地方，以及需要改進的問題等。 
二、考察參觀活動 
三、建議 
由於之前參加的會議都是屬於 IEEE Computer Society的領域，對於這一次可以參加 IEEE 
Communication Society 的所舉辦的國際會議，實在是一個難得的經驗。由於 Computer
和 Communication 所在乎的領域並沒有很類似，一個比較屬於通訊協定的制定，另外一
個比較屬於 Physical 元件與實際網路架構的設計，因此，從此會議得到許多硬體技術的
觀念。 
但是由於此次會議舉辦的地方，距離台灣好遠，光機票來回加上註冊的錢可能就會等於
所有補助的錢，對於一個在學的博士般而言，負擔很大。因此，如果能有機票+註冊費+
住宿費上實報實銷的制度，這樣對於要出國參加會議的研究生，可能可以減輕一點經濟
上的負擔。 
四、攜回資料名稱及內容 
大會論文集 CD。 
五、其他 
 
 802.16j specifications. Applying these solutions under a heavy 
network load will result in poor system utilization due to their 
inability to adapt to varying network dynamics (e.g., varying 
traffic load to D-MSs and R-MSs, various MS channel 
conditions, and differing minimum reserved rates of service 
flows). Several resource allocation schemes based on dynamic 
zone partitioning (DZP) have also been proposed for relay 
networks [5-7]. However, the scheme proposed in [5] does not 
take into account the various minimum reserved traffic rates 
(MRTR) of different service flows in the network. Those 
presented in [6-7] are distributed approaches, and are unsuitable 
for centrally-oriented networks such as 802.16j transparent relay 
networks.  
Recently, game theory has been widely used for resource 
management weighing different network constraints such as 
power, QoS requirements, channel conditions, etc. In particular, 
many studies have focused on using a non-cooperative game 
approach to model the bandwidth allocation problem in wireless 
networks. In [8], a game-theoretic based scheduler for bandwidth 
provisioning in 4G BWA technologies is presented. This 
approach simultaneously controls network congestion and 
fairness while providing differentiated QoS guarantees. In [9], 
the hierarchical bandwidth sharing problem in dynamic spectrum 
access is formulated as an interrelated market model from a 
microeconomics perspective. A similar approach has been used 
in [10]-[12] with varying definitions of the utility function and 
different network constraints. However, it is well known that 
Nash equilibrium is Pareto inefficient and the pricing 
mechanisms proposed only provide some Pareto improvements 
[13].  
In recently years, there has been an increasing trend to use the 
axiomatic bargaining theory of cooperative game theory to 
examine resource allocation problems [13-15]. Axiomatic 
bargaining theory provides a good analytical framework to 
derive a unique desirable operation point that is fair and Pareto 
optimal. Accordingly, this study presents a DZP resource 
allocation scheme based on a two-stage bargaining game for 
accomplishing downlink transmission under varying network 
dynamics in a 802.16j transparent relay network. The game 
formulation is based on a bottom-up model where player utility 
functions in each stage reflect the corresponding bargaining 
solutions. According to game formulation and solutions, a 
tradeoff between effective data rate and proportional fairness for 
relay systems is provided. Simulation results show the resulting 
resource allocation is both fair and efficient among inter-class 
and intra-class users. To the best of the authors’ knowledge, the 
proposed scheme represents the first attempt to present a game 
formulation for the DZP problem in 802.16j transparent relay 
systems. 
II. DYNAMIC ZONE PARTITIONING GAME 
In developing the DZP resource allocation scheme, this study 
assumes the 802.16j transparent relay network utilizes partial 
usage of sub-carriers (PUSC) mode in orthogonal frequency 
division multiple access (OFDMA) systems and operates under 
heavy traffic load environment. It is further assumed that the 
downlink subframe contains N resource slots, comprising Naz 
access zone resource slots and Ntz transparent zone resource slots. 
Finally, an assumption is made that the system consists of K 
service classes, indexed by the set Ω={1,2,…,K}. For each class 
kΩ, the corresponding service flows are denoted by the set 
Φk={1,2,…, Ik}.  
 
A. TWO-STAGE BARGAINING GAME  
The proposed DZP resource allocation scheme  is based on a 
two-stage bargaining game. In the first stage, resource allocation 
between different service classes is modeled as an inter-class 
bargaining game, in which each player represents a particular 
service class, i.e., a class of service flows with the same 
minimum reserved rate. The strategy for a player k, where all 
kΩ, is the number of resource slots allocated for transmission 
in a downlink subframe. The payoff for service class k is 
evaluated using a utility parameter uk, defined as a function of the 
corresponding class-level performance.  
To ensure an efficient and fair distribution of the resource slots 
amongst all the service classes, the solution of the bargaining 
game is obtained using  Nash Bargaining Solution (NBS). The 
NBS is defined as follows:  
Definition 1 Nash Bargaining Solution (NBS): Let C = 
{kΩ|  uU, uk > udis,k } be the set of players(i.e., classes) 
which can achieve a utility strictly greater than the disagreement 
utility udis,k. Under the five general axioms [15], Nash showed that 
the unique NBS (i.e.,  (u*,udis,k)) is that which maximizes the 
Nash Product, i.e., 
 
*
, ,
1
( ) arg max ( ( ) )
dis
K
dis k k k dis k
u u k
u ,u u N u
 
   ,         (1) 
 
where 
1
,
K
kk
N N 
 
uk(.) is the utility function for class k, and Nk 
is the total number of resource slots allocated to class k.  
Once each class has obtained its solution (i.e., N*k) by 
performing a local search method, the second stage of the 
bargaining game is performed to distribute the resource slots 
allocated to each class amongst all service flows within the class. 
In other words, the second stage of the bargaining game is an 
intra-class bargaining problem. For a service class k, each of the 
service flows within the class represents a player in the game.  
The strategy of each player i (where iΦk) is the number of 
allocated resource slots received for its downlink transmission. 
Importantly, in obtaining the solution to the game, each player 
must receive an equal payoff in every frame since each service 
flow has the same minimum reserved rate. To achieve this goal, 
 0
2
4
6
8
10
12
14
90% 80% 70% 60% 50% 40% 30% 20% 10%
Sy
st
em
 T
hr
ou
gh
pu
t (
M
bp
s)
Ratio of R-MSs to total MSs
SP(1:1)
DZP
       
0
50
100
150
200
250
300
350
400
90% 80% 70% 60% 50% 40% 30% 20% 10%
A
ve
ra
ge
 T
hr
ou
gh
pu
t (
kb
ps
)
Ratio of R-MSs to total MSs
C1(DZP)
C2(DZP)
C1(SP 1:1)
C2(SP 1:1)
 
Fig.  2. System throughput for various R-MSs to total MSs ratios.            Fig. 3. Average Throughput for various R-MSs to total MSs ratios 
 
As a result, in each downlink sub-frame, the exact number of 
resource slots required for data transmission in the access zone 
and transparent zone are given respectively by 
 
  * * *, , , , , , , ,1 1 + /kK Iaz k i D k i R az k i k i sk iN N N c r   
     
  (11) 
 
and 
 
 * * , ,1 1kK Itz k i,R tzk iN N    .                                  (12) 
 
Once N*az and N*tz have been derived, the partitioning of the 
downlink sub-frame into the access zone and the relay zone is 
easily achieved.  
III. SIMULATION RESULTS AND ANALYSIS 
The performance of the proposed DZP scheme was evaluated 
using an 802.16j transparent relay simulation model constructed 
using QualNet Simulator 4.5 [17]. The simulation model 
included a single cell comprising a MR-BS, six T-RSs and 40 
randomly-distributed MSs. The simulations assumed 20 MHz 
bandwidth, an OFDMA frame size of 20 ms, and the 
downlink-to-uplink ratio was specified as 2:1. Two different 
service classes were simulated, namely class 1 (C1) and class 2 
(C2). Each MS has a service flow which has an equal probability 
of being in either C1 or C2. The packet arrival at MR-BS was 
modeled as a Poisson process. The traffic rates for  C1 and C2 
service flows were specified as 375 kbps and 256 kbps, 
respectively. Finally, the minimum reserved traffic rates for C1 
and C2 were respectively set at 256 and 128 kbps. The 
performance of the proposed bargaining game-based DZP 
scheme was compared with Strict Priority (SP) scheme [18]. 
Note that SP scheme is regarded as a static scheme which has a 
fixed boundary between the access zone and the transparent zone 
with a ratio of 1:1.  
In addition, to measure the user fairness within a class, the 
fairness metric uses the traditional Jain’s Fairness Index (FI) 
[19]. 
 21
2
1
FI
( )
N
ii
N
ii
Thr
N Thr


                                        (13) 
 where Thri is the average throughput of service flow i in a class 
and 0 FI 1. 
.
 
Figure 2 shows the variation of the system throughput with 
respect to the ratio of R-MSs to total MSs. It can be seen that the 
system throughput of the SP scheme decreases with the ratio of 
R-MSs to total MSs. In contrast to the SP scheme, the system 
throughput of the proposed DZP scheme increases with 
increasing ratio of R-MSs to total MSs. The results show the 
proposed DZP scheme improves the capacity of the SP approach 
by up to 33% on average. This is because when the ratio of 
R-MSs to all MSs increases, the R-MSs need more resource slots 
to transmit data packets. By employing the proposed DZP 
scheme, the boundary between the access zone and the 
transparent zone can be adaptively adjusted to improve resource 
utilization according to the traffic rate requirements of MSs with 
different link types.  
Figure 3 plots the C1 and C2 average throughputs of the 
proposed DZP scheme compared with those of SP with varying 
ratio of R-MSs. It can be observed that the C2 average 
throughput of the SP scheme is lower than its minimum reserved 
traffic rates due to the essence of the SP scheme. Since the 
proposed DZP scheme employs the NBS solutions at the first 
stage bargaining game, the average throughput of each class in 
DZP always meets the minimum reserved traffic rate required by 
each class despite the fact that the service flows are receiving 
lower allocations than the scenarios with a lower ratio of R-MSs. 
The SP scheme favors the MSs of C1, where C1 always has  
An Analytical Framework for a WDM EPON 
with Differentiated Services 
Hui-Tang Lin1, Chia-Lin Lai1, Wang-Rong Chang2, and Sheng-Jhe Hong1
1Institute of Computer and Communication Engineering, National Cheng Kung University, Taiwan (R.O.C.) 
2ICT-Enabled Healthcare Program, Industrial Technology Research Institute, Taiwan (R.O.C.) 
E-mails: 1{htlin, q3897105, q3695428}@mail.ncku.edu.tw; 2Allen_Chang@itri.org.tw; 
Abstract—Recently, various analytical models have been 
proposed to analyze the performance of traditional EPONs. 
However, these analytical models are not readily applicable to 
analyze the performance of WDM EPON systems since they are 
aimed specifically at a single-channel EPON environment. 
Accordingly, this paper constructs an analytical framework 
comprising an M/M/1 queuing model and a recursive formulation 
to analyze the performance of the offline scheduling polling policy 
in a multi-channel WDM EPON network with differentiated 
services. The analytical results derived using this model for the 
mean queuing delay and mean queue length are found to be in 
good agreement with those obtained from computer simulations. 
Index Terms—WDM EPON; Differentiated Services; M/M/1 
queuing model; Analytical Framework; 
I. INTRODUCTION
EPON technology [1][2] provides a promising means of 
simplifying network operations and of increasing the available 
bandwidth in a cost-effective manner. However, as the number 
of end users continues to rise and the use of data-intensive 
network applications becomes ever more widespread, 
traditional EPON architectures are increasingly unable to cope 
with the huge volumes of network traffic carried by typical 
access networks. Therefore, an urgent requirement exists to 
upgrade the capabilities of EPONs such that they can 
accommodate the huge volume of traffic demands anticipated 
in the future. One of the most promising solutions for doing so 
is Wavelength Division Multiplexing (WDM) EPON 
architectures [3-5], which adopt WDM techniques to enhance 
the transmission capacity of EPON access networks and avoid 
linearly increasing polling cycle times as the number of 
attached Optical Network Units (ONUs) scale up. 
Fig. 1 illustrates an example of a WDM EPON network with 
two upstream and two downstream wavelengths. In such a 
system, an assumption is made that each wavelength is 
operating at a line rate of 1 Gbps, and therefore a total capacity 
of 2 Gbps is available in both transmission directions. In the 
downstream, the OLT is permitted to utilize any of the two 
downstream wavelengths for packet transmissions. The 
downstream signal is then fanned out to each ONU by the 
optical splitter. In the upstream direction, the OLT schedules 
the transmissions of ONUs and receives data from ONUs on 
any upstream wavelength. The optical combiner integrates all 
of the incoming wavelengths from the ONUs to a shared 
section of trunk fiber. Similar to conventional EPON schemes, 
in order to avoid data collisions or overlapped transmissions 
from different ONUs in the upstream transmissions, a WDM 
Dynamic Bandwidth Allocation (DBA) protocol is essentially 
required to arbitrate the transmissions among ONUs within the 
network. 
)LEHU
)LE
HU
Fig. 1. WDM EPON system.
Recently, the literature contains various analytical models for 
analyzing the performance of TDM EPONs [6-8]. However, 
these models all consider the case of a single-channel EPON 
environment. Accordingly, this study presents an analytical 
framework for analyzing the performance of a WDM EPON, in 
which the upstream bandwidth is allocated using the offline 
scheduling algorithm and a two-stage buffering approach is 
adopted to support the various QoS requirements of different 
traffic classes. Utilizing an M/M/1 queuing model and a 
recursive formulation, the analytical framework is designed to 
evaluate the mean queuing delay and mean queue length within 
the WDM EPON system. The validity of the analytical 
framework is verified by comparing the results with those 
obtained from numerical simulations. To the best of the current 
authors’ knowledge, this study represents the first reported 
attempt to analyze the performance of the mean queuing delay 
and mean queue length specifically for multi-channel EPON 
networks with differentiated services. 
The remainder of this paper is organized as follows. In 
Section II, more details are given about WDM DBA protocol 
and QoS provisioning mechanism employed in the WDM 
EPON network. Section III introduces the proposed analytical 
framework. Section IV compares the analytical and simulation 
results, and finally, Section V draws some brief conclusions. 
II. OFFLINE SCHEDULING AND TWO-STAGE BUFFERING 
APPROACH
This section commences by reviewing the basic concepts of 
the offline polling policy and then provides a detailed 
description of two-stage buffer QoS provisioning mechanism. 
A. Offline Scheduling Polling Policy 
McGarry et al. [5] examined the feasibility of cost-effective 
WDM structures for the OLT and ONU in a WDM EPON. In 
their proposal, the OLT is fitted with an array of fixed-tuned 
transceivers, with each transceiver dedicated to one particular 
wavelength. Furthermore, ONUs should also be able to be 
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:48:57 UTC from IEEE Xplore.  Restrictions apply. 
scheduler to each priority queue. 
III. ANALYTICAL FRAMEWORK
In the current analysis, it is assumed that the packets from 
the end users arrive each ONU in accordance with a Poisson 
distribution with a rate į (bits/s) and have a constant size (bits). 
Furthermore, it is assumed that the network traffic is evenly 
distributed over all the ONUs and the ONUs are all situated at 
the same distance from the OLT. 
A. Analysis of Maximum Polling Cycle Time, TMAX
As a limited service in traditional EPON systems [12], a 
maximum transmission window, WMAX, is assigned by the 
offline scheduling to each ONU in a polling cycle to prevent 
the upstream channel from being monopolized by a single 
ONU with a high data volume. For simplicity, the following 
discussions consider Fig. 2 as an example to describe the 
maximum polling cycle time calculation for the case of a 
WDM EPON with N = 4 ONUs and M = 2 upstream 
wavelengths.  
Since the OLT simply schedules the granted transmissions to 
the upstream wavelength which it estimates will become idle 
earliest, under heavy traffic load conditions, each wavelength 
in Fig. 2 is only permitted to deliver G = 2 grants of size WMAX
on average, where G = (N / M). Starting from the beginning of 
each polling cycle, the OLT issues M = 2 consecutive GATE 
messages to grant the ONUs’ transmissions on upstream 
wavelengths Ȝ0 and Ȝ1, respectively. The two GATE messages 
are separated by a guard time interval, TGUARD. As a result, the 
maximum polling cycle time, TMAX, is equivalent to the sum of 
the transmission time of the two consecutive GATEs, the guard 
time between the two GATEs, the transmission time of the two 
WMAX frames on the last scheduled wavelength in a cycle, the 
guard time between these two granted transmissions, the RTT, 
and the computation time, TCOMPU. TMAX can therefore be 
expressed in the following normalized form: 
,)1(
)1(
COMPUGUARD
MAX
GUARD
GATE
MAX
TRTTTG
R
WGTM
R
SMT
++⋅−+
⋅
+⋅−+
⋅
=    (1) 
where SGATE is the size of the GATE message, R is the line rate 
of each wavelength, and RTT is the round trip time between the 
OLT and each of the ONUs within the network. 
B. Analysis of Stage-I Queues 
Obviously, each ONU has the guaranteed ability to send a 
minimum of WMAX (bits) in TMAX (seconds). The minimum 
guaranteed bandwidth of each ONU is given by: 
.
MAX
MAX
MIN T
W
=Λ                 (2) 
However, the bandwidth available to an ONU is only limited to 
this guaranteed bandwidth if all the other ONUs in the system 
are currently using all of their available guaranteed bandwidths. 
If at least one ONU does not consume all its guaranteed 
bandwidth, it is assigned a shorter transmission window, thus 
reducing the overall polling cycle time. Therefore, a greater 
amount of bandwidth is made available to the other ONUs in 
the network. In other words, the polling cycle time is not static, 
but varies dynamically in accordance with changes in the 
instantaneous network load. 
As shown in Fig. 3, packets in the Stage-I priority queues are 
advanced to the Stage-II ONU sub-queues in accordance with 
the service rates assigned by the packet scheduler to each of the 
three priority queues. In the scheduling strategy, each priority 
queue in Stage-I is assigned a service share value ĳC. To 
provide differentiated services for different types of traffic 
while considering the dynamics their traffic loads, the service 
share of each traffic class is assigned in accordance with the 
corresponding the traffic load and the priority weight [13][14], 
i.e., 
,C
C
C σδ
δϕ ⋅=                   (3) 
where įC is the traffic load of traffic class C (C∈{AF, EF, 
BE}), į is the total network traffic load (i.e., ¦= C Cδδ ), 
and ıC is a priority weight assigned to traffic class C
(¦ =C C 1σ ). To ensure a fair service to each of the different 
traffic classes, the service rate provided to each class is 
determined in accordance with its service share, ĳC, i.e., 
.MIN
C C
C
C Λ⋅=¦ ϕ
ϕμ               (4) 
(Note that various schemes for assigning an appropriate priority 
weight to each traffic class, such as bandwidth-based algorithm, 
jitter-based algorithm, etc., have been studied extensively in 
[15]. As long as the weights are determined, they can be readily 
plugged in the proposed model for performance analysis. 
Therefore, the issue of how to assign priority weights is out of 
the scope of this paper.) 
In the present analysis, it is assumed that new packets arrive 
at the ONUs in accordance with a Poisson process with a rate 
įC and have an exponential service time distribution with a 
mean 1/ȝC. The analytical model developed in this study 
focuses principally on the average queuing delay at the ONUs 
rather than the level of packet losses throughout the network, 
and thus the priority buffers are assumed to be of an infinite 
size. As a result, the three priority queues in the Stage-I 
buffering space are all modeled as M/M/1 queues. In 
developing an analytical model for the queuing delay at the 
Stage-I queues, it is assumed that: (1) the Stage-I buffer 
contains only mono-server stations which operate under a FIFO 
discipline; (2) the service time is exponentially distributed with 
a mean 1/ȝC; and (3) the end user packets arrive at the ONUs in 
accordance with a Poisson process with a rate įC. Under these 
assumptions, the Stage-I queues can be modeled as a 
mono-class open queuing network; i.e., a Jackson’s network. 
As a result, the state probability can be expressed as follows: 
,)(),,( ∏= C CCBEAFEF nPnnnP          (5) 
where pC(nC) is the marginal probability associated with the 
priority queue of traffic class C. The Markov chain associated 
with each of the three priority queues in the Stage-I buffer is 
illustrated in Fig. 4. 
Fig. 4. Markov chain of each priority queue in M/M/1 queuing model.
As stated above, the present analysis focuses specifically on 
modeling the average queuing delay at the ONUs. Let E[DC] 
denote the average queuing delay associated with class C traffic. 
In order to formulate an analytical expression for E[DC], it is 
first necessary to determine the expected number of packets of 
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:48:57 UTC from IEEE Xplore.  Restrictions apply. 





      
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XL
QJ
'
HOD
\
V
()$QDO
$)$QDO
%($QDO
218$QDO
()6LPX
$)6LPX
%(6LPX
2186LPX
(
(
(
(
(
(
(
      
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XH
/H
QJ
WK
E\
WHV

()$QDO
$)$QDO
%($QDO
218$QDO
()6LPX
$)6LPX
%(6LPX
2186LPX
               (a)                             (b) 
Fig. 5. Performance results of Stage-I and Stage-II queues. (a) Mean 
queuing delay. (b) Mean queue length.
from a series of computer simulations. In performing the 
numerical calculations and simulations, the network parameters 
were assigned as shown in Table I. 
TABLE I. SIMULATION AND ANALYTICAL PARAMETERS FOR WDM EPON. 
Symbol Explanation Value 
N Number of ONUs 64 
M Number of upstream wavelengths 2 
R Bandwidth capacity 1 Gbps 
RTT Round-trip delay 200 ȝs 
TCOMPU Computation time 35 ȝs 
TGUARD Guard time 1.5 ȝs 
SGATE  Size of GATE message 512 bits 
SREPORT Size of REPORT message 512 bits 
WMAX Maximum transmission window 120,000 bits
In performing the comparative trials, the Ethernet frame size 
was specified as a constant 1500 bytes, and the capacity of each 
queue in each ONU was assumed to be 10 Mbytes. 
Furthermore, the traffic of each ONU was modeled in 
accordance with a Poisson process at a rate of į. Finally, the EF, 
AF and BE traffic loads were specified as 20%, 30% and 50% 
of the network offered load, respectively. The performance of 
the WDM EPON was evaluated in terms of the mean queuing 
delay and the mean queue length. The mean queuing delay was 
defined as the elapsed time between the arrival of a data packet 
at the ONU and the moment at which the packet was extracted 
from the queue. Note that since the ONU queue comprising 
three ONU sub-queues is serviced once every polling cycle, in 
the offline scheduling scheme the mean queue length of the 
ONU queue in Stage-II was defined as the average amount of 
traffic accumulated in all ONU sub-queues during each cycle. 
Figures 5(a) and 5(b) illustrate the mean queuing delay and 
mean queue length of the Stage-I and Stage-II buffers as the 
network offered load is increased. Note that the priority 
weights, ı, of the EF, AF and BE traffic loads were specified as 
0.6, 0.3 and 0.1, respectively. Furthermore, the maximum 
network offered load was deliberately restricted to a value of 
0.7 Gbps in order to ensure the stability of the BE queue in the 
Stage-I buffer. In Fig. 5(a), the results show that for an offered 
load of 0.7 Gbps, the average delay in the BE queue increases 
to almost 0.1 s, which indicates that the arrival rate of the BE 
traffic has reached its service rate (i.e., ȡBE ≅ 1). Fig. 5(b) 
plots the mean queue length in each of the four queues. 
Comparing the three traffic classes, it can be seen that the BE  



       
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XL
QJ
'
HOD
\
V
()ǔ $QDO
()ǔ 6LPX
()ǔ $QDO
()ǔ 6LPX



       
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XL
QJ
'
HOD
\
V
$)ǔ $QDO
$)ǔ 6LPX
$)ǔ $QDO
$)ǔ 6LPX
                   (a)                             (b) 





       
1HWZRUN2IIHUHG/RDG
*ESV
0
HD
Q4
XH
XL
QJ
'
HOD
\
V
%(ǔ $QDO
%(ǔ 6LPX
%(ǔ $QDO
%(ǔ 6LPX
        (c) 
Fig. 6. Mean queuing delay of three traffic classes for two different priority 
weight assignments. (a) EF traffic. (b) AF traffic. (c) BE traffic. 
traffic has the longest queue length followed by the AF and the 
EF traffic streams, respectively. The results also confirm that 
the BE traffic reaches its stability limit at a network offered 
load of 0.7 Gbps, whereas the AF and EF traffic remain in a 
stable state. 
Figures 6(a)~(c) show the mean queuing delays of the EF, 
AF and BE traffic under two different priority weight 
assignments. In the first assignment, the priority weights of the 
EF, AF and BE traffic loads were specified as the same as that 
in Fig 5, while in the second assignment, the priority weights 
were set to 0.5, 0.35 and 0.15, respectively. For the EF traffic, it 
can be seen that the mean queuing delay increases when the 
priority weight of the EF traffic is decreased from 0.6 to 0.5 
(see Fig. 6(a)). Intuitively, this finding is reasonable since a 
smaller volume of EF priority weight causes the packet 
scheduler to assign a smaller service rate to the EF traffic class, 
and thus the average queuing time is increased. For the AF 
traffic (see Fig. 6(b)), the queuing delay decreases slightly as 
the weight of the AF traffic is increased from 0.3 to 0.35. This 
result is to be expected since under this condition, the service 
rate assigned to the AF priority queue is increased, and thus a 
small decrement in the AF queuing delay is incurred. Finally, it 
can be seen that the BE traffic reaches its stability limit at a 
higher value of the total offered network load when it’s priority 
weight is set to 0.15 rather than 0.1 (see Fig. 6(c)). This result 
confirms that the service rate provided to the BE priority queue 
increases as the weight of the BE traffic is increased from 0.1 
to 0.15, and thus the delay of the BE traffic is decreased. 
Figures 7(a)~(c) show the mean queue lengths of the EF, AF 
and BE traffic classes under the two priority weight  
Authorized licensed use limited to: National Cheng Kung University. Downloaded on June 02,2010 at 14:48:57 UTC from IEEE Xplore.  Restrictions apply. 
FIPACT: A Frame-Oriented Dynamic Bandwidth 
Allocation Scheme for Triple-Play 
Services over EPONs 
Hui-Tang Lin1,2, Chia-Lin Lai1, Wang-Rong Chang3, and Chin-Lien Liu1 
1 Institute of Computer and Communication Engineering, National Cheng Kung University, Taiwan (R.O.C.) 
2 Department of Electrical Engineering, National Cheng Kung University, Taiwan (R.O.C.) 
3 ICT-Enabled Healthcare Program, Industrial Technology Research Institute-South, Taiwan (R.O.C.)  
E-mails: 1{htlin, q3897105}@mail.ncku.edu.tw;annliu@nsda.ee.ncku.edu.tw;3Allen_Chang@itri.org.tw; 
 
Abstract–Ethernet Passive Optical Networks (EPONs) are not 
only cost-effective, but also provide high throughput, high 
bandwidth utilization, and low transmission latency. As a result, 
EPONs are a viable solution for overcoming the bandwidth 
bottleneck problem in local access networks. This study develops a 
novel Dynamic Bandwidth Allocation (DBA) scheme, designated as 
Frame-oriented Interleaved Polling with Adaptive Cycle Time 
(FIPACT), to provide a differentiated Quality-of-Service (QoS) 
capability in EPONs. FIPACT adopts a framed approach, in which 
the upstream network bandwidth is partitioned into successive 
frames. Within each frame, each Optical Network Unit (ONU) is 
guaranteed the network resources necessary to transmit a specific 
quota of Voice over Internet Protocol (VoIP), video, and Internet 
access traffic, respectively. Since FIPACT permits these three types 
of traffic stream to share the available bandwidth efficiently whilst 
still satisfying their respective QoS requirements, it provides an 
effective means of achieving differentiated triple-play services in 
EPONs. The simulation results demonstrate the effectiveness and 
efficiency of the proposed approach. 
 
Keywords- EPON; dynamic bandwidth allocation; triple-play 
services; QoS 
 
I. INTRODUCTION 
Ethernet Passive Optical Networks (EPONs) [1] have 
emerged as one of the most promising broadband access 
technologies for resolving the last-mile problem, and have 
attracted significant attention due to their inherent simplicity, 
longevity, low operational cost, and enormous bandwidth. 
EPONs contain only passive optical components in the signal 
path between the source and the destination and comprise one 
Optical Line Terminal (OLT) and multiple Optical Network 
Units (ONUs). Given the wide deployment of Ethernet ports 
nowadays and the huge volume of Ethernet-originated end-user 
traffic, the EPON standard is a natural candidate for 
next-generation access networks. Currently, network vendors 
and telecom operators view differentiated triple-play services 
and broadband access networks as necessary ingredients for 
offering residential customers Voice over Internet Protocol 
(VoIP), video, and high-speed Internet traffic services [2]. Since 
EPON is an inexpensive technology and is anticipated to be a 
suitable communication infrastructure between the central 
offices of the service provider and the customer sites, it is 
essential to provide a viable solution for network vendors 
seeking to fulfill QoS requirements for each of the triple-play 
services in an EPON system. 
To date, a wide range of Dynamic Bandwidth Allocation 
(DBA) schemes have been proposed for achieving 
differentiated services for broadband voice, video and data 
access applications over EPONs. Many existing QoS 
provisioning mechanisms intended for deployment at the 
individual ONUs in an EPON are implemented using a 
strict-priority-based scheduling strategy [3-5], in which the 
ingress traffic is classified into three different priorities, namely 
Expedited Forwarding (EF), Assured Forwarding (AF), or Best 
Effort (BE). In accordance with this strategy, the servicing of 
higher priority traffic is guaranteed by ensuring that a lower 
priority queue is scheduled for transmission if, and only if, all 
of the queues with a higher priority are empty. In [6], a dynamic 
scheduling algorithm, called the HG(SPS) (Hybrid Granting 
with Strict Priority Scheduler), was proposed to support 
guaranteed QoS for different types of applications over EPONs. 
In HG(SPS), the delay-variation sensitive transmissions (i.e., 
EF traffic) are served in an independent EF sub-cycle within 
each polling cycle, and thus the performance of the EF traffic is 
considerably improved. Furthermore, the authors in [7] 
proposed an Admission-Control DBA (AC-DBA) scheme 
which adopts a fixed polling cycle time approach to support 
guaranteed bandwidth and to ensure a bounded delay for 
real-time traffic.  
Although the schemes presented above provide an effective 
means of enhancing the QoS performance in EPONs with 
differentiated services, they are not readily applicable to EPONs 
hosting triple-play services since they can not simultaneously 
satisfy the differing QoS requirements of VoIP, video, and 
Internet access (i.e., BE traffic) applications, respectively. 
Accordingly, this study develops a novel DBA scheme to 
integrate triple-play services for an EPON system. The 
proposed scheme, designated as Frame-oriented Interleaved 
Polling with Adaptive Cycle Time (FIPACT), is based upon the 
concept of the IPACT protocol [8] which assigns the available 
network resources by polling the ONUs’ bandwidth demands in 
an interleaved manner. FIPACT employs a framed approach, in 
which the time domain of the upstream wavelength is 
subdivided into contiguous frames containing a Real-Time (RT) 
subframe followed by a BE subframe. Each ONU is guaranteed 
the network resources required to transmit a specific quota of 
VoIP and video traffic within each RT subframe. Furthermore, 
978-1-4577-0638-7 /11/$26.00 ©2011 IEEE
 
 
Fig. 1. FIPACT operation in an EPON system with two ONUs. (a) DBA frame structure. (b) Polling Policy in BE Subframe. (c) Polling Policy in RT 
Subframe. 
 
permission is in the initial BE polling cycle or not. 
z Unlike IPACT, the polling behavior of the VoIP and video 
polling cycles in FIPACT is based on a “grant-on-demand” 
approach. In other words, if an ONU presents a bandwidth 
demand of zero bytes for its VoIP (or video) queue in the 
REPORT message transmitted in the initial BE polling 
cycle of the BE subframe, the OLT skips this particular 
ONU to release its VoIP (or video) connection when 
polling the ONUs in the VoIP (or video) cycle of the 
subsequent RT subframe. In other words, the OLT polls 
only those ONUs which have backlogged VoIP (or video) 
packets waiting for transmission.  
As discussed above, each BE subframe contains a number 
of contiguous BE polling cycles. Since the period of each BE 
polling cycle varies in accordance with the amount of BE data 
granted for transmission, the number of BE polling cycles in 
each BE subframe depends on the BE traffic load. Furthermore, 
due to the constant duration of the DBA frames, an “insufficient 
void” issue occurs if the OLT receives the total BE bandwidth 
demand, Rtol_BE, exceeds the remaining available bandwidth, 
Brem_avail, in the BE subframe. In such a situation, the OLT uses 
a proportional bandwidth allocation mechanism to grant ONU n 
a BE transmission window, nBEW , with a size determined by the 
amount of bandwidth requested by ONU n, nBER , relative to the 
total bandwidth requested by all the ONUs, i.e., 
 .
_
_
BEtol
n
BE
availrem
n
BE R
RBW ×=             (1) 
Polling Policy in RT Subframe 
The RT subframe consists of one VoIP and one video 
polling cycles dedicated to ONUs for establishing their 
admitted VoIP and video connections, respectively (Note that to 
enable the ONUs to perform real-time stream admission locally, 
an admission control scheme should be provided at the ONU 
side [13]. However, due to length constraints, the issue of 
realizing such a control scheme is not addressed in the present 
study.) The implementation of DBA in the VoIP and video 
polling cycles is described in the following paragraphs. 
1) DBA in VoIP Polling Cycle. VoIP traffic is non-bursty and 
can be characterized by its mean data rate, μV. As a result, it is 
quite predictable. However, VoIP traffic has stringent delay and 
jitter requirements. To establish voice call connections, the OLT 
polls the ONUs individually and issues transmission grants for 
VoIP traffic in every VoIP polling cycle. The average delay and 
jitter of each VoIP stream is therefore guaranteed to be bounded 
due to the fixed duration of the DBA frames. Thus, for a VoIP 
call, the admission decision is straightforward, i.e., if the mean 
data rate can be supported, then the flow is admitted by the 
ONU; else it is rejected. Once an ONU n has admitted a VoIP 
Stream s, it estimates the quantum value of the bandwidth 
requirement of this stream in every RT subframe as follows: 
.. frameV
sn
V TR ×= μ               (2) 
The OLT is informed of this bandwidth demand via the 
REPORT sent from ONU n in the initial BE polling cycle of 
every BE subframe. The OLT then grants the VoIP transmission 
in the VoIP polling cycle of the following RT subframe. 
Figure 1(c) illustrates the VoIP transmission scenario for 
DBA Frame j with a fixed frame duration of Tframe = 8 ms. An 
assumption in made here that ONU 0 (ONU 1) issues a 
REPORT message requesting 64 Bytes to establish a 64-Kbps 
VoIP connection in the initial BE polling cycle of BE Subframe 
j – 1. In the current VoIP polling cycle of RT subframe j, the 
OLT grants ONU 0 (ONU 1) a 64-Byte transmission window to 
transmit its VoIP data. As a result, ONU 0 (ONU 1) can 
establish its VoIP voice call since the duration of each DBA 
frame is fixed, i.e., set to 8 ms, and is equal to the time spent by 
1500001
1000001
1500001
2000001
2500001
3000001
5 5.5 6 6.5 7 7.5 8 8.5 9 9.5 10 10.5 11
Nu
mb
er 
of 
Sa
mp
les
Jitter (ms)
FIPACT
AC-DBA
HG(SPS)
  
(a) 
1
1000001
2000001
3000001
4000001
5000001
6000001
5 5.5 6 6.5 7 7.5 8 8.5 9 9.5 10 10.5 11
Nu
mb
er 
of 
Sa
mp
les
Jitter (ms)
FIPACT
AC-DBA
HG(SPS)
   
(b) 
 
Fig. 2. Jitter performance of the VoIP traffic under FIPACT, AC-DBA, and 
HG(SPS) protocols. (a) Network offered load ρ = 0.5 Gbps. (a) Network 
offered load ρ = 1 Gbps. 
 
subframes was set to 2 ms. To ensure a fair comparison between 
the FIPACT, AC-DBA, and HG(SPS) allocation schemes, the 
fixed polling cycle time in the AC-DBA protocol and the 
maximum polling cycle time in the HG(SPS) protocol were 
both set to 8 ms. For the traffic model considered here, an 
extensive study shows that most network traffic flows (e.g., http, 
ftp, Variable Bit Rate (VBR), video applications, and so forth) 
are characterized by self-similarity and Long-Range 
Dependence (LRD) [14]. Hence, this model is used in the 
present study to generate highly bursty video and BE traffic 
with a packet size uniformly distributed in the range 64 ~ 1,518 
Bytes. Meanwhile, the VoIP traffic was modeled using a 
Poisson distribution with a constant packet size of 64 Bytes. 
Each VoIP stream was generated at a mean rate of 64 Kbps, 
while each video stream was generated at an average bit rate of 
4.85 Mbps. Finally, the VoIP, video and BE traffic loads were 
set to 20%, 40% and 40% of the network offered load, ρ, 
respectively. All of the simulations were run for 30 seconds.  
Figures 2(a) and 2(b) show the jitter performance of the VoIP 
traffic when using the FIPACT, AC-DBA, and HG(SPS) 
protocols given network offered loads of ρ = 0.5 Gbps and 1 
Gbps, respectively. In every case, the jitter is computed as the 
difference in the packet delay of two consecutive VoIP packets 
transmitted from the same ONU. The Probability Density 
Function (PDF) shows that the VoIP traffic delay sequence 
presents a centralization with all data points condensed on 8 ms 
for FIPACT protocol, one dispersion with enough number of 
data points in a curve from 6.6 ms (or from 7.9 ms) to 9.1 ms 
(or to 8.1 ms) for AC-DBA protocol, and one dispersion with 
enough number of data points in a curve from 6 ms (or from 7.5 
ms) to 10 ms (or to 8.3 ms) for HG(SPS) protocol. The reason 
behind the difference between centralization and dispersion 
delay sequence is that since the bandwidth request of every 
VoIP stream can be serviced in the VoIP polling cycle of each 
DBA frame, the FIPACT scheme has no possibility to obtain 
jitter delay time lower or higher than 8 ms, irrespective of the 
 
0
2
4
6
0 1 2 3 4 5 6 7 8 9 10A
cc
um
m
ul
at
iv
e 
T
h
ro
ug
hp
ut
 
(M
bi
ts
)
one-second time unit
FIPACT Avg.(4.85Mbits)
  
(a) 
0
2
4
6
0 1 2 3 4 5 6 7 8 9 10
Ac
cu
m
m
ul
at
iv
e 
Th
ro
ug
hp
ut
 
(M
bi
ts
)
one-second time unit
AC-DBA Avg.(4.85Mbits)
  
(b) 
0
2
4
6
0 1 2 3 4 5 6 7 8 9 10
A
cc
um
m
ul
at
iv
e 
T
h
ro
ug
hp
ut
 
(M
bi
ts
)
one-second time unit
HG(SPS) Avg.(4.85Mbits)
  
(c) 
 
Fig. 3. Accumulative throughput of an admitted video stream. (a) FIPACT. 
(b) AC-DBA. (c) HG(SPS). 
 
network offered load. This result reflects the fact that the fixed 
frame duration approach used in FIPACT leads to a constant 
departure rate amongst the backlogged VoIP packets, and 
therefore bounds the jitter delay time by the DBA frame 
duration to guarantee the generation of a VoIP packet with size 
64 Bytes every 8 ms.  
Figures 3 (a)~(c) present the accumulative throughput of an 
admitted video stream transmitted by ONU 0 under the FIPACT, 
AC-DBA and HG(SPS) schemes, respectively. The 
accumulative throughput is defined here as the amount of 
admitted video data transmitted by ONU 0 at every entry point 
during one-second time unit. It is observed that in each 
one-second time unit, the accumulative throughput of the 
proposed FIPACT and AC-DBA schemes increases 
progressively to approximately 4.85 Mbps. This result confirms 
that both FIPACT and AC-DBA schemes provide a guaranteed 
bandwidth of 4.85 Mbits in every one-second time unit, and 
hence satisfy the QoS requirements of the video traffic. 
Furthermore, in HG(SPS) scheme, since the strict priority-based 
scheduling is enforced in the AF/BE sub-cycle to serve buffered 
video traffic first, it may have some performance shortcomings, 
such as better-than-needed performance for video priority queue 
or starvation of BE queue. Hence, as shown in Fig. 3, HG(SPS) 
exhibits a fluctuant performance of accumulative throughput in 
each one-second time unit compared to that obtained from 
either FIPACT or AC-DBA. 
Figure 4 shows the variation in the BE queuing delay with 
the network offered load when using the FIPACT, AC-DBA, 
and HG(SPS) bandwidth allocation protocols, respectively. It  
 
 
February 24, 2011 
  
 
Dear Prof. Hui-Tang Lin: 
 
It is my pleasure welcoming you to attend the International Conference on Game Theory in 
Networks (GameNets), 2011 to be held at the Crowne Plaza Century Park Hotel in Shanghai, 
China on April 16-18, 2011 by confirming receipt of your paid registration fee as a presenting 
author of  ""A Game-Theoretic Framework for Resource Allocation in IEEE 802.16j Transparent 
Relay Networks". Your presence is most important to the success of the technical program agenda 
of this ICST event.  
 
 
Thank you again for your active contribution to the event and I am looking forward to meeting 
you personally at GameNets 2011. Should you be interested in reviewing the logistical, academic 
or other details of the event, please visit http://www.gamenets.org. 
 
 
Should you have questions or need further information, please feel free to contact me at 
theory.wang@gmail.com. 
 
 
Sincerely, 
 
 
________________________________ 
Xinbing Wang 
GameNets 2011 – Local Chair  
Associate Professor,   
Institute of Wireless Communication and Technology, 
Dept of Electronic Engineering 
Shanghai Jiao Tong University, China 
http://iwct.sjtu.edu.cn/Personal/xwang8/ 
 
 
Address: 
Room 307                                                    Minhang District 
NO.5 SEIEE Building                                        Shanghai, P,R,China 

國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/30
國科會補助計畫
計畫名稱: 支援情緒管理服務之無線網路整合系統
計畫主持人: 林輝堂
計畫編號: 97-2221-E-006-175-MY3 學門領域: 圖形辨識
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
