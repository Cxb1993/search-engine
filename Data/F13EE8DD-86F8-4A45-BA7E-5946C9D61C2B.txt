 II
計畫中文摘要 
     在植入式生醫晶片的發展中，常需要一個智慧型辨識系統來整合大量感測器訊號，控制植入式無
線裝置只傳輸新的或異常的訊號，以達到省電的目的，其中，腦機介面等相關研究，更進一步希望能
即時辨識植入式神經微電極陣列的電生理訊號，以即時控制腦傷的機電輔具。因應此需求，本計畫主
要目的在於探討是否能基於擴散網路的理論，實現一隨機晶片系統，以應用於辨識高維度且隨時間變
化的生醫訊號。此晶片系統將以雜訊產生特有的隨機動態行為，且可利用調變此隨機行為來概括時變
訊號中的變異，或是系統自身的雜訊與運算誤差，進而保持穩健的辨識能力。本計劃的原創性在於，
第一，嘗試利用雜訊在積體電路中產生可調控的隨機動態行為，以有效學習時變訊號的機率分布並保
持電路的穩健性，第二，應用類比電路本身即時反應的特性，設計可同時平行解多個隨機微分方程式
的晶片系統，以處理高維度、高雜訊的時變訊號，第三，驗證運用雜訊做運算的可能性，對未來要以
雜訊大的奈米元件作電路設計時，提供一新的思考方向。本計劃最終將設計一運算元個數可擴充且參
數可程式化的擴散網路晶片系統，以測試其辨識高維時變生醫訊號的能力。 
 
關鍵字 : 隨機晶片系統, 隨機動態, 擴散網路, 生醫訊號處理, 雜訊, 智慧型系統 
 IV
目錄 
 
計畫中文摘要 
計畫英文摘要 
1. 前言…………………………………………………………………………………………………………1 
2. 研究目的…………………………………………………………………………………………………….1 
3. 文獻探討…………………………………………………………………………………………………….1 
4. 研究方法…………………………………………………………………………………………………….2 
5. 結果與討論………………………………………………………………………………………………….2 
5-1. 適於辨識高維時變生醫訊號的架構設計…………………………………………………………….2 
5-2. 適於硬體實現的辨識方法 …………………………………………………………………………...4 
5-3 硬體實現的參數調變範圍與解析度…………………………………………………………………..5 
5-4. 硬體中非理想特性的考量…………………………………………………………………………….7 
5-5. 擴散網路運算元電路設計…………………………………………………………………………….8 
5-6. 指數型運算元電路設計…………………………………………………………………………….…9 
5-7. 硬體實現擴散網路參數調變演算法可行性探討……………………………………………….…..10 
5-8. 擴散網路晶片系統測試與新版設計………………………………………………………………..12 
5-9. 模組化擴散網路晶片系統…………………………………………………………………………...14 
5-10. 指數型擴散網路晶片系統………………………………………………………………………….16 
5-11 雜訊可調電晶體設計………………………………………………………………………………..18 
參考文獻………………………………………………………………………………………………………20 
執行本計畫相關之著作....................................................................................................................................22 
 2
4. 研究方法 
根據以上的討論與本人初步研究的成果，擴散網路有潛力應用於辨識高維時變生醫訊
號，且可實現成積體電路。本計畫第一年的目標為「發展適於辨識高維時變生醫訊號且適於
硬體實現的擴散網路架構設計」，第一年的研究方法重點在於以模擬測試擴散網路在學習辨識
生醫訊號的特性，決定適合辨識生醫訊號的架構，進而依此架構歸納擴散網路所需的參數調
變範圍，設計參數在硬體與數值模擬間的對應關係。除此之外，亦須模擬評估硬體實現時的
非理想效應是否限制擴散網路的運算能力。 
第二年的重點在於「設計擴散網路的雛型晶片」，主要研究方法為基於 CRBM 晶片系統
的電路模組，設計擴散網路運算元電路，另外，更以指數型運算元設計運算元電路，以增加
擴散網路晶片的隨機動態範圍，對於電路的不匹配與非線性等不理想效應可能影響擴散網路
晶片系統的運作，我們更進一步探討將擴散網路參數調變法實現成積體電路的可行性。 
第三年的研究重點在於「實現適於辨識高維時變生醫訊號的擴散網路晶片系統」，主要重
點在於設計運算元模組化、參數可程式的晶片系統，並實現調變晶片參數的測試平台。此三
年的研究成果與討論詳述於下節。 
 
5. 結果與討論 
擴散網路是由可見神經元與隱藏神經元組成。圖 5.1 為單一擴散網路神經元的架構圖
與模型區塊圖，每一各圓代表ㄧ個運算元，其隨機動態以下列擴散方程式描述 
  


  

n
i
ijjjjj
j
j wtxtxdt
tdx
tx
1
))(()(
)(
),(   
，而經過 Sigmoid function 的 Sj 會回傳給各個運算元當作輸入，如此持續疊代，直到最後
一個時間點 T 的取樣結束。運算元分為可見與隱藏運算元兩種，學習的目標是使可見神經
元的動態變化與訓練資料的時變訊號有一樣的隨機分布，而隱藏神經元則是用來輔助學習
訓練資料的隨機動態(Stochastic dynamics)分布。 
 
                               
圖 5.1 單一擴散網路神經元的模型區塊圖 
 
第一年:「發展適於辨識高維時變生醫訊號且適於硬體實現的擴散網路架構設計」 
5-1. 適於辨識高維時變生醫訊號的架構設計 
本研究主要在測試單一擴散網路是否可同時學習多種不同的資料，以減少所需網路的個數，
以下分別以非對秤的分支曲線與不同振幅、相位的正弦波測試。 
5-1-1 非對稱分支曲線學習 
    我們先以含一個可見神經元，三個隱藏神經元的擴散網路同時學習兩種分支曲線，如圖
5.2.(1)所示，當網路雜訊參數很小時將造成學習失敗，擴散網路無法在可見神經元同時重建
兩筆曲線。然而，提高雜訊變異量，則可學習成功，如圖 5.2.(2)所示。因此，擴散網路主要
是靠雜訊變異去同時學習兩筆以上的訓練資料。為驗證此推論，我們進一步強制可見運算元
xi
xj
wijwji
wjj
wii
 4
200 400 600
−5
0
5
(a)
tr
ai
ni
ng
 d
at
a
6sin(4fo)
2sin(4fo)
200 400 600
−5
0
5
(b)
V
[n
]
200 400 600
−1
0
1
2
(c)
H
1[
n]
200 400 600
−1
−0.5
0
0.5
(d)
H
2[
n]
200 400 600
0
0.5
1
1.5
2
(e)
H
3[
n]
0 20 40 60 80
0
2
4
6
x 10
6
(f)
su
m
 o
f l
og
 p
(x
o,
hl
)
sum of log p(6sin4fo,hl)
sum of log p(2sin2fo,hl)
n n 
n n 
n training data  
120 240 360 480 600 720
−5
0
5
(a)
tr
ai
ni
ng
 d
at
a
5sin0.5fo
5cos0.5fo
120 240 360 480 600 720
−5
0
5
(b)
V
[n
]
120 240 360 480 600 720
−0.5
0
0.5
1
(c)
H
1[
n]
120 240 360 480 600 720
−4
−2
0
2
4
(d)
H
2[
n]
120 240 360 480 600 720
−2
−1
0
1
2
(e)
H
3[
n]
0 20 40 60 80
0
5
10
x 10
4
(f)
su
m
 o
f l
og
 p
(x
o,
hl
)
sum of log p(5sin0.5fo,hl)
sum of log p(5cos0.5fo,hl)
n n 
n n 
n training cycle  
                 (1)                                      (2) 
圖 5.4 (1) 學習不同振幅正弦波的學習結果； (a)兩種訓練資料； (b) 學習結果可見神經元 V[n]； (c)(d)(e)代表
對應 V[n]的隱藏層隨機序列 H1[n]、 H2[n]、 H3[n]； (f)兩種學習指標隨訓練過程的變化圖。圖 5.3.(2) 學習不
同相位弦波的學習結果； (a)兩種訓練資料； (b)學習結果可見神經元 V[n]； (c)(d)(e)對應 V[n]的隱藏層隨機序
列 H1[n]、 H2[n]、 H3[n]； (f)兩種學習指標隨訓練過程的變化圖。 
 
    综上所述，我們發現當使用擴散網路同時學習多筆信號，會使得網路參數綜合了每一筆
信號的特色而不利重建；又發現對於同時學習多筆比較困難的信號，擴散網路無法同時學習
成功，既使是讓隱藏神經元有不同的增益，或是讓擴散網路有侷限性的連結，仍無有效改善。
因此，以擴散網路辨識生醫訊號，我們將採用一個擴散網路只學一類信號的方式，訓練好的
網路只判斷待辨識訊號是否屬於該類訊號。 
5-2. 適於硬體實現的辨識方法 
    目前本實驗室發展出針對擴散網路的辨識方法有如下兩種：(1)末端值辨識法 (2)可能性
辨識法。末端值辨識法是找出一組辨識訊號的擴散網路參數，接著強制可見神經元(Visible 
neuron)為我們待辨識訊號，再利用找到的擴散網路參數來重建隱藏層路徑，最後用隱藏層路
徑末端值來判斷這個待變識訊號是不是我們一開始所學習的辨識訊號。此法的優點是硬體實
現較為簡單。因此我們使用下列三個測試範例，探討利用末端值辨識法之擴散網路，對一維
及二維生醫訊號辨識之可行性。 
5-2-1. 希臘字母二維序列之辨識  
    選擇希臘字母β和ρ做為訊號辨識的第一個測試範例。選擇β和ρ是因為兩者在筆劃上
有相當接近的初始值和末端值，如圖 5.5.(a)和(b)所示，其中β和ρ的主要差異在於β有雙峰
值而卻ρ沒有，故我們預期擴散網路可以將這個小差異在重建隱藏層時轉換成明顯的差異，
並且可藉由其重建出的隱藏層末端值來判斷是β或ρ。藉由觀察圖 5.5.(a)和圖 5.5.(b)可看出
β和ρ的每個對應隱藏運算元的隨機動態之末端值均不同，並且皆可以用「零」做為辨識界
線。 
5-2-2. 螺旋曲線二維序列之辨識 
    螺旋信號呈現出高度非線性，且不容易將信號轉換到其他的座標處理，因此我們將圖
5.5.(c)和(d)列為擴散網路的第二個測試範例。假設圖 5.5.(c)和圖 5.5.(d)最上方分別為螺旋 S1
和螺旋 S2，我們可以利用 S1 學習出來的參數 1S 來辨識 S1 和 S2 二個螺旋，利用末端值辨識法
來辨識出此雙螺旋。如圖 5.5.(c)和(d)所示，可看出 S1 螺旋和 S2 螺旋的 h3[n]和 h5[n]末端值不
同，故而依然可利用「末端值大於零或小於零」當作辨識界線。 
 6
表一 
 Matlab Circuit or Spice Unit 
Ix -30~30 -0.657uA~0.657uA Iunit = 0.0219uA 
Vx -3~3 0.9v~2.1v Vunit = 0.2V 
Low 
R 
0.25~4 
0.25~4 
2.283M ~36.528M  Runit = 9.132M  
t 0.05 5us Tuint = 100us 
ai 0.5~10   
Wij -30~30 -5uA~5uA Wunit = 0.1667uA 
Sij -1~1 -2uA~2uA Sijunit = 2uA 
Inoise -1.342~1.342 -29.1nA~29.1nA  
C 1 10.95pF Cunit = 10.95pF 
我們先讓此電路重建正弦波，正弦波的頻率是在 250 個點內重建 8 個週期的正弦波，如圖
5.7.(a)，將這些參數紀錄下來放到電路中重建，會重建出圖 5.7.(b)。可以看出在有加入雜訊的
情況下，它也能成功重建出正弦波，不過有幾個地方需要討論。在圖 5.7.(b)中一開始的值偏
大，這是 Spice 計算上的問題，若把時間繼續拉長它就會像後面四個波一樣穩定持續下去。
在圖 5.7.(a)中有八個正弦波，而在圖 5.7.(b)中卻只有 5.5 個，不一樣的原因在於電容，依照
mapping 每個神經元會有一個電容存在，若再加上其他雜散電容會使的總電容變大，電容便
大會使的時間常數變大，使的在一樣時間內產生的正弦波變少。 
再來學習圖 5.8.(a)的波形，我們稱它為 bifurcation，學習正波形的意義在於證明 diffusion 
network 能在同一時間內因為不同雜訊的關係重建不同波形的可能性，一樣將這些學到的參數
放到 Spice 重建，在圖 5.8.(b)中可看到 Spice 成功重建四條路徑。 
   
(a)         (b) 
圖 5.7. (a)利用 Matlab 學習時，欲被學習的正弦波；(b)Spice 重建出的波形。 
   
(a)         (b) 
圖 5.8. (a)利用 Matlab 學習時，欲被學習的 bifurcation；(b)Spice 重建出的波形。 
 8
第二年:「設計擴散網路的雛型晶片」 
5-5. 擴散網路運算元電路設計 
在第一年歸納出擴散網路運算元的參數範圍與硬體實現對應關係後(參 2008 年期中報
告)，圖 5-11 所示為擴散網路運算元的主要架構。我們需要乘法器、可變電阻、電容、雜訊
產生器和 sigmoid 電路。但是在真正設計電路時，不僅僅只有以上的電路，仍需要考量電路
的輸入電阻、輸出電阻、電壓操作範圍及寄生電容等等的因素，所以還需要電流傳送器電路
來輔助。 
 
圖 5-11: 擴散網路運算元電路架構 
  
    圖 5-12 所示為乘法器、Sigmoid、可變電阻電路圖及其模擬結果，四象限乘法器主要參
考文獻[13]設計電流式乘法器，圖中的橫軸是權重電流，Iy 是 sigmoid 電路提供一個定電流來
和權重電流相乘，可以看到曲線分布是線性的，而且可操作在四個象限。Sigmoid 電路則參考
文獻[14]，利用電晶體操作在次臨界區來實現非線性函數，可以藉由輸入不同的偏壓電流(Itune)
來調整 sigmoid 的斜率。而可變電阻則參考文獻[15]，使電路中 VX與 VY間的電阻等於 2R，
R 利用電晶體設計，調變電晶體的偏壓則可調變 R，此電路主要的優點為易於產生大於幾 M
的電阻。將這些電路與雜訊產生器等連結及構成擴散網路的運算元電路。 
     
 10
我們便可以上述的方程式直接轉為實體電路（如圖 5-13）。在整理的過程中，為了解決單位一
致性的問題，還需要在方程式兩邊同乘一些常數，這是很重要的關鍵。 
使用 log-domain 電路的優點在於以下兩點 
（a）參數可以在一個較大範圍內調整而不會降低所欲模擬行為的精確度。 
（b）狀態（數值）能夠操作在較大的範圍，而不會使硬體電路的行為達到飽和。 
由於儲存於電容的資料（電壓值）容易受到電晶體漏電流的影響，儲存的資料因而發生極小
的改變，但是因為電壓與電流為指數關係，所以縱使電壓只有極小的改變也會使其對應的電
流有極大的變化，進而對系統的行為造成極大的誤差，而無法得到我們所需的結果。因此，
在設計 log-domain 電路時，必須要設法降低電晶體的漏電流對儲存資料的影響，以防止硬體
電路做出偏離預期的行為。 
 
dt
tdBC ii
i
offset
R
X
i
s
R
I
 iij sw
 
圖 5-13 指數型運算元電路設計架構 
5-7. 硬體實現擴散網路參數調變演算法可行性探討 
擴散網路演算法中，最主要是得到能將期望值最大化的擴散網路參數，而學習理論部份
最重要的是 Movellan 應用蒙地卡羅期望值最大化(Monte Carlo Expectation Maximization)來得
到代表待學習訊號的擴散網路參數： 
1. 先對學習訊號取期望值(Expectation) 
2. 將期望值最大化(Maximization) 期望值越大，則擴散網路參數越能代表所學習之訊
號，而期望值的公式為： 
          


   TT dttxdxtxxL 0 2202 |),(|21),(1exp)(   
其中    


  

n
i
ijjjjj
j
j wtxtxdt
tdx
tx
1
))(()(
)(
),(   
雖然擴散網路參數有六種參數，但在數學模擬軟體（matlab）模擬，發現可用學習兩種擴散
網路參數電阻（ρ）和權重(w)即可將待學習訊號學習成功，之後的演算法就針對這兩種參數
做學習和修改。 
5-7-1 修改且簡化擴散網路演算法 
    Movellan 在 2002 年提出的「擴散網路」演算法，由於演算法中的算式對於實現在積體電
路來說會太過於複雜，造成相當大的難度。所以首先必須對「擴散網路」演算法進行修改。
利用最佳化方法修改「擴散網路」演算法，而最佳化方法所需要的資訊有兩種：1.搜尋方向
 12
          
              (d)                                 (e) 
圖 5-16: (a)為學習正弦波的結果；(b)為四個權重參數，兩兩ㄧ組，對於期望值繪出之全區域
三維曲面；(c)為(b)圖之等高線圖，每個參數的初始點均是零，Λ為期望值最大的位置，紅藍
相間曲線為每次疊代點移動的路徑；(d)為兩個電導參數對於對於期望值繪出之全區域三維曲
面；(e)為(d)圖之等高線圖，每個參數的初始點均是零，Λ為期望值最大的位置，紅藍相間曲
線為每次疊代點移動的路徑。 
 
5-7-3 擴散網路數學模擬之參數的範圍限制和準確度 
    設定參數的範圍限制是為了和電路之間做橋樑，因為擴散網路參數會利用電路上的電壓
或電流表示，必須要知道參數的範圍限制，利用這些範圍找到合適電路，如此才能有效的對
應到合宜之電壓或電流範圍，防止電路在操作上，有跑出操作區域或飽和的情形發生，會造
成電路運算不準確。再來本研究想用類比電路實現此演算法，但類比電路做運算一定會有誤
差，所以在設計之前，要先在數學模擬上尋找擴散網路參數所能接受的準確度，換句話說，
也就是了解運算過程中可以接受的誤差範圍；而在模擬過程發現，不同的學習訊號會有不同
的擴散網路參數的範圍限制和準確度，這是因為學習訊號之困難度不同所造成的情況，越複
雜的學習訊號需要越高的準確度，表 1(a)、(b)、(c)分別代表學習正弦波、正常心跳、希臘字
母ρ，由表 2 即可看出，所需的準確度隨著學習訊號困難度上升，由 5 bits 上升至 9bits。即
使如此，跟傳統類神經網路比起來，擴散類神經網路所需的準確度是更低即可達到學習成功。 
  
              (a)                              (b) 
表 2 (a)為學習正弦波，擴散網路參數所需之上下限和準確度(b)為學習希臘字母ρ，擴散
網路參數所需之上下限和準確度。 
 
第三年:「實現適於辨識高維時變生醫訊號的擴散網路晶片系統」 
5-8. 擴散網路晶片系統測試與新版設計 
5-8-1 前版擴散網路晶片測試結果與硬體之主要非理想效應成因討論 
構成擴散網路中神經元的電路有：權重電流源、電流乘法器、電流傳送器、電壓電流轉
換器、sigmoid電路、補償電路、可調變電阻、電壓緩衝器、雜訊產生器、電容。再前版晶片
量測中，電流傳送器、電壓緩衝器壓、補償電路是可以正常工作的。而權重電流源、電流乘
 14
current。 
 
5-8-2 新版擴散網路晶片之子電路圖、模擬結果、晶片佈局 
在 5-8-1 提到上一版晶片由於乘法器和可變電阻不適用的原因，因此我們設計新的電路取代
這兩個子電路。 
 
 
圖 5-19(a)為乘法器的電路架構圖。    圖 5-19(b)為在 five corner 模擬的結果 
 
 
圖 5-20(a)為可變電阻的電路架構     圖 5-20(b)為可變電阻在 five corner 模擬的結果 
 
 
圖 5-21 重建希臘案母μ的結果       圖 5-22 四顆神經元的晶片佈局圖 
 
5-9. 模組化擴散網路晶片系統 
5-9-1 模組化架構設計 
在歸納出擴散網路運算元的主要架構後（參 2009 年報告），我們進一步想探討的是如何
將數個擴散網路晶片併為一個擴散網路晶片系統。如果只有先前所歸納出的擴散網路運算元
的主要架構是無法將數個擴散網路晶片組成一個擴散網路晶片系統，所以我們提出一個解決
方案，如表 3。這個解決方案可分為晶片內與晶片間兩方面來解釋，先從晶片內來說，就是
 16
12
11
16
15
IBIAS IBIAS
V+V‐
33
34
31
32
25
26
27
28
18
17
14
13
21
22
19
20
1 2 3 4
29
30
35
36
2423
40
39
38
37
44
43
46
45
42
41
48
47
 
圖 5-25 乘法器電路及其模擬結果 
0d
0c
0i
0j
0g
0h0a
0f
0e
0b
V+
V+
V‐
V‐7
6
9
8
13
12
11
10
Vtune
3a 4 3b
5
1a
2a
1b
2b
18
19
14
15
20
21
24
25
33
32
31
30
V+
  
圖 5-26 可變電阻電路及其模擬結果 
0d
0c
0i
0j
0g
0h0a
0f
0e
0b
V+
V+
V‐
V‐7
6
9
8
13
12
11
10
Vtune
3a 4 3b
5
1a
2a
1b
2b
16
17
18
19
14
15
20
21
24
25
22
23
33
32
27
26
29
28
31
30
VO1 VO2
1.5 1.5
46
47
44
45
40
41
42
43
VO134VO2 35
37
36
51
50
49
48
39
38
IOUT
 
圖 5-27 可調變 Sigmoid 運算電路及其模擬結果 
  
圖 5-28 Soma 圖 5-29 Synapse 圖 5-30 Full chip 
5-10. 指數型擴散網路晶片系統 
5-10-1 指數型電路架構設計 
首先，先將運算元的狀態 xj 轉換至指數領域產生對應的變數 Vxj 
 
 
 
經由轉換後，原先的微分方程可改寫如下 
 
 18
      
  圖 5-32 重建 Sine Wave (10 trials)   圖 5-33 擴散網路重建 ECG 訊號 (10 trials) 
   
圖 5-34 擴散網路重建 Bifurcation(8 trials)   圖 5-35 擴散網路重建希臘字母ρ (10 trials) 
 
圖 5-36 含有兩個運算元之擴散網路晶片佈局及系統規格 
5-11 雜訊可調電晶體設計 
已經發現電晶體雜訊在許多應用上是有用的，例如用於資料加密[17-18]、生物啟發運算
的擾動學習[19]、概率化模型等，也已經有使用具增強雜訊功能的電晶體的演算法架構被提
出來[20]。現有的方法包括使用氮化矽介電層以增加界面陷阱(interface trap)[17]，以及縮小電
晶體的尺寸使其具有單一氧化物陷阱(single oxide trap)[18]。然而這些方法只是將雜訊增強到
可用的程度，未能控制精確的雜訊準位。以下提出二種雜訊可調電晶體，二者皆以 TSMC 0.18
μm CMOS 邏輯製程製作，並呈現它們的量測結果。 
 
 5-11-1 八角型雙閘極電晶體(ODGFET)設計與測試結果 
在圖 5-37 所示的八角型 FET 結構中，增加額外的閘極在 Shallow Trench Isolation (STI)
上。此 FET 有兩個閘極，在通道上方的閘極是主閘極，如同一般的 FET 閘極用來控制通道電
流，在 STI 上方的 STI 閘極用來吸引通道載子沿著 STI 邊緣流動以引發雜訊。在此 ODGFET
中，主動區是一個八角形的環，圍繞八角形的 STI 閘極。 
當施加電壓 VG 到主閘極時，在其下方的通道感應出反轉電荷，在此狀態下，此當作一
般的 FET 使用，其低頻雜訊很小。當施加電壓 VX 到 STI 閘極時，在 STI 邊緣感應出反轉電
荷，通道載子沿著 STI 邊緣流動而產生雜訊。與閘極介電層不同，STI 邊緣處的 STI-矽界面
 20
汲極周圍會產生空乏區。當通道載子流經富含缺陷的 RPO 表面時，會被其表面陷阱所補捉與
釋放，進而引發大量的低頻擾動。在汲極側空乏區內，由汲極產生的橫向空乏電場的強度，
並不亞於來自閘極的垂直電場強度。故而促成載子的傳輸路徑遠離 RPO 的介面陷阱，載子與
RPO 陷阱交互作用的機率將微乎其微，雜訊因而降低。此即為「陷阱屏蔽原理」。當汲極電
壓 VD 較大時，汲極空乏區亦將擴大，被屏蔽的 RPO 介面陷阱也會增多，這代表能補捉載子
的 RPO 陷阱將變少，因而低頻雜訊將被降低，此即 DSFET 的雜訊可為 VD 所調變的原理。 
為了研究此一 offset 設計的效果，一個對照用的 NMOSFET(offset=0μm)也一起於相同的
CMOS 製程中製作，其有效通道長度及寬度皆與 DSFET(Offset=0.5μm)相同。使用雜訊分析
儀 BTA 9812B 量測此二電晶體的雜訊頻譜(SID)，然後對 ID2 作正規化。如圖 5-40 所示，汲
極電壓 VD 對 offset=0μm 的 NMOSFET 的雜訊準位幾乎沒有調變性。反觀 DSFET 具有相對
大的雜訊準位，並且其汲極電壓 VD 能夠調變雜訊的準位超過百倍。當 VD 越低，雜訊準位
越高，明確驗證了上述的陷阱屏蔽原理。當 VD 達到 1.4V，DSFET(offset=0.5μm)的雜訊準
位變得幾乎和 NMOSFET (offset=0μm)一樣低，意味著 RPO 表面的陷阱完全被汲極空乏區所
屏蔽。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
參考文獻 
[1] Movellan, J. R., Mineiro, P., and Williams, R. J., "A Monte-Carlo EM Approach for Partially Observable Diffusion 
Processes: Theory and Applications to Neural Networks," Neural Computation, vol. 14, no. 7, pp. 1507-1544, 2002. 
[2] Specht, D. F., "Probabilistic Neural Networks," Neural Networks, vol. 3 pp. 109-118, 1990. 
[3] Jou, I. C., Liu, R. Y., and Wu, C. Y. CMOS Implementation of Neural Networks for Speech Recognition. 
513-518.12-5-1994. 1994 IEEE Asia-Pacific Conference on Circuits and Systems.  
[4] Aibe, N., Yasunaga, M., Yoshihara, I., and Kim, J. H. A Probabilistic Neural Network Hardware System Using 
aLearning-parameter Parallel Architecture. 3, 2270-2275. 5-12-2002. Proceedings of the 2002 International Joint 
Conference on Neural Networks. 
[5] Hsu, D., Bridges, S., Figueroa, M., and Diorio, C. Adaptive Quantization and Density Estimation in Silicon. 15. 
2003. Advances in Neural Information Processing Systems (NIPS02). 2002. 
[6] Genov, R. and Cauwenberghs, G. Stochastic Mixed-Signal VLSI Architecture for High-dimensional Kernel 
Machines. 14, 1099-1105. 2002. Advances in Neural Information Processing Systems. 
[7] Genov, R. and Cauwenberghs, G., "Kerneltron: support vector machine in silicon," IEEE Transactions on Neural 
N-imp
Active Region
RPOPoly Contact
Offset
S D
G
Trapping
De-Trapping
100 101 102 103 104 105
10-15
10-13
10-11
10-9
10-7
10-5
VD= 0.4, 0.7, 1.4 V
1.4 V
0.7 V
0.4 V
VD
1/f1.5 Curve
1/f Curve
 
 
S I
D
/I D
2  (
H
z-
1 )
Frequency (Hz)
 Offset= 0.5 m
 Offset= 0 m
           VS= VB= GND
                  VG= 0.1V
圖5-39. DSFET的平面佈局與剖面圖。 圖5-40. DSFET (Offset= 0.5μm)及NMOSFET 
(offset= 0μm)的雜訊調適性的比較。 
 22
執行本計畫相關之著作 
Journal 
1. Lu, C.C, Chen, P.L., Huang, C.D. and Chen, H.* “An Embedded, Analogue Nonvolatile Memory with a 
Feedback-Controlled Programming Circuit On-chip”, vol.46 , no.12, p.822-823, the Electronics Letters, 2010. (IF = 
1.14  Rank : 108/229) 
2. Lu, C.C. and Chen, H.* “A Scalable and Programmable Probabilistic Generative Model in VLSI”, IEEE Trans. on 
Neural Networks, 2010, Under revision (IF = 3.726, Rank : 4/94) 
3. Chiu, T.J., Gong, J., King, Y.C., Lu, C.C., and Chen, H.* “An Octagonal, Dual-gate Transistor with Enhanced and 
Adaptable Low-frequency Noise” the IEEE Electron Device Letters, In Press (IF = 3.049, Rank : 23/229) 
4. Chiu, T.J., King, Y.C., Gong, J., Tsai, Y.H., and Chen, H.* “A Drain-shifted Transistor with Enhanced and Adaptable 
Low-frequency Noise” the IEEE Electron Device Letters, Under review (IF = 3.049, Rank : 23/229) 
Conference 
1. Lu, C.C. , Li, C.C., and Chen, H.* “How Robust is a Probabilistic Neural VLSI System against Environmental Noise”, 
The 3rd Inter. Workshop on Artificial Neural Networks for Pattern Recognition, 2008, p 44-53 (EI) 
2. Hsu, Y.S., Chiu, T.J., Chen, H.*, “Real-time Recognition of Continuous-time Biomedical Signals Using the 
Diffusion Network”, IEEE Inter. Joint Conf. on Neural Networks,2008, p2628-2633 (EI) 
3. Lu, C.C. and Chen, H.* “A Scalable and Programmable Probabilistic Neural VLSI for Intelligent Sensing in 
Implantable Biomedical Devices” the 12th Inter. Conf. on Cognitive and Neural Systems, 2008. 
4. Lu, C.C. and Chen, H.*, “ Minimising Contrastive Divergence with Dynamic Current Mirrors”, the Inter. Conf. on 
Artificial Neural Networks, 2009. (EI) 
5. Lu, C.C. and Chen, H.*, “Current-mode Computation with Noise in a Scalable and Programmable Probabilistic 
Neural VLSI System”, the Inter. Conf. on Artificial Neural Networks, 2009. (EI) 
6. Chien, C.H., Lu, C.C., and Chen, H.* “Mapping the Diffusion Network into a Stochastic System in Very Large Scale 
Integration”,  IEEE Inter. Joint Conf. on Neural Networks, 2010 (EI) 
7. Wu, Y.D., Lin, S.C., and Chen, H.* “A Log-Domain Implementation of the Diffusion Network in Very Large Scale 
Integration”, Neural Information Processing Systems, 2010 (The most prestigious conference for the neural network 
society) 
 
Patent 
1. Huang, C.D., Lu, C.C., Chen, H. “Nonvolitile Analogue Memory”, Taiwan, R.O.C. and the U.S. patents 
(26576-US-PA). 
2. Chiu, T.J., Gong, J., Chen, H. “Multi-gate Field-effect Transistors with Enhanced and Adaptable Low-frequency 
Noise”, Taiwan, R.O.C. and the U.S. patents, under review. 
3. Chiu, T.J., King, Y.C., Chen, H. “Drain-shifted Field-effect Transistors with Enhanced and Adaptable 
Low-frequency Noise”, Taiwan, R.O.C. and the U.S. patents, under review 
 
 
 
報告內容應包括下列各項： 
一、參加會議經過 
此次會議在香港的國際會議暨展覽中心舉行，此次會議由以往的 IJCNN，CEC 與 FUZZ-IEEE
三個合併舉行，因此包含的領域更廣，共有 2500 多個學者來自 70 多個國家參與。而會議進
行的六天(6 月 1 日-6 月 6 日)，共有 15 個邀請的演講，每天有 19 分項主題同時進行，本人
主要選擇神經資訊(Neuroinformatics)、與腦機界面(Brain Computer Interface)等與研究
相關議題，參與聆聽論文發表與討論，其中亦於 6月 5日上午發表自己的成果，與其他學者
交換意見。而由於本人於 6月 7日即將前往法國研究訪問，且限於航空公司規定，此次僅參
加會議兩天(6 月 4 日-6 月 5 日)，但仍收穫良多。 
 
二、與會心得 
  此會議為 IEEE 的類神經網路學會年度舉辦的最主要學術會議，早期主要著重與
類神經網路、人工智慧、機械學習等演算法的發展與應用，而近年因應生醫工程研
究的蓬勃發展，會議的研討主題有生物資訊、神經資訊、仿生演算法等與本人研究
相關之領域。所以很適合發表此次的研究結果—以擴散網路即時處理高維度的時變
生醫訊號，語彙的學者對擴散網路利用隨機性保持對生醫訊號中雜訊與偏移的容忍
度，相當印象深刻，不過也指出，擴散網路目前仍侷限於學習單種資料，是未來我
們可以試圖改善的方向。此外，從參與研討會的過程，本人也學習了許多新的神經
系統模型建立的方法，以及腦機界面訊號處理的技巧，前者對於未來發展新的仿神
經演算法有幫助，而後者則可與擴散網路相比，比較不同演算法處理神經訊號如 EEG
的能力與侷限，進而探討更進一步修改擴散網路架構的可能性。最後，值得ㄧ提的
是本屆會議頒發獎給 Prof. Kohonen，此獎項創立於 1990 年，主要表揚在仿生演算
法及人工智慧的卓越研究，此次表揚 Prof. Kohonen 首創的 Self-Organising-Map
等類神經網路對整個領域的卓越貢獻與影響，已有超過 8000 多篇文獻從事相關研
究。此獎項的頒予，鼓勵所有學者用心投入對社會有影響力的研究，而不是只ㄧ昧
發表文獻。 
三、考察參觀活動(無是項活動者省略) 
無 
四、建議 
無 
 
五、攜回資料名稱及內容 
會議論文集紙本一份 
會議論文集光碟ㄧ片 
會議論文集 DVD 一片 
 
六、其他 
 
 
xi
xj
wijwji
wjj
wii
s1
w1i
w2i
Iin
I
noise
wji
s2
sj
xi
si
iR iC
(a)
(b)
Fig. 1. (a)The diagram of a Diffusion Network with one visible (white-
coloured) and three hidden(grey-coloured) units. (b)The stochastic unit of
the Diffusion Network in terms of electrical equivalent circuits.
for modelling high-order correlations among different di-
mensions of the sequences. The latter is normally identified
through a trial process. As the Monte-Carlo EM algorithm
maximises the likelihood of regenerating the modelled se-
quences, the trained Diffusion Network can classify whether
an unknown sequence xTo belongs to the training dataset
by calculating the likelihood of regenerating the sequence
according to Eq.(4).
Consider a single run of a Diffusion Network with n
visible and m hidden units in the time interval [0, T ]. Given
xi(0) = 0 for all units, the dynamics of all units are sampled
according to Eq.(1) and Eq.(2)1. Let λ denote the set of all
parameters wij , Ci, Ri, xo : [0, T ] → Rn an n-dimensional
sequence representing the dynamics of visible units sampled
during [0, T ], and xh : [0, T ] → Rm an m-dimensional
sequence representing the sampled dynamics of hidden units.
The log-likelihood for the Diffusion Network with parameter
λ to generate the joint dynamics (xo, xh) is given as [3]
log pλ(xo, xh) =
1
σ2
n∑
i=1
∫ T
0
µi(t)dxi(t)− 12σ2
∫ T
0
µi(t)2dt
(3)
To calculate the probability of generating a specific path
xTo , the marginal probability pλ(xTo ) can be estimated by
clamping the dynamics of visible units to be xTo [3], sampling
the corresponding dynamics of hidden units for l times, and
1Discrete-time approximation to the stochastic differential equations was
adopted in the numerical simulation in a computer
marginalising over hidden samples as
log pˆλ(xTo ) =
∑
l
log pλ(xo, xlh) (4)
where xlh represent the l-th Monte-Carlo sampled hidden
dynamics. The estimated marginal likelihood in Eq.(4) is
useful not only for sequence classification, but also for the
indication of whether the EM algorithm has optimised the
parameters, which is important for knowing when to stop a
training process.
III. HARDWARE AMENABILITY OF THE DIFFUSION
NETWORK
Hardware implementation of the Diffusion Network is
important for running continuous-valued, continuous-time
stochastic dynamics of multiple units in parallel and in real-
time. Exploiting the diffusion process inherent in analogue
circuits, Fig.1b shows the translation of the stochastic differ-
ential equation in Eq.(1) into an equivalent-circuit model for
the stochastic unit. The diagram indicates that the Diffusion
Network can be implemented simply by integrating analogue
multipliers, capacitors, resistors, noise generators, and sig-
moid circuits. Furthermore, [4] has proved that the Diffusion
Network is simply different from the Continuous Restricted
Boltzmann Machine(CRBM) by the inclusion of parameters
Ri and Ci. As the CRBM has been demonstrated in Very-
Large-Sale-Integration (VLSI) implementation[6], the anal-
ogy between the Diffusion Network and the CRBM indicates
that the Diffusion Network can be realised in VLSI simply
by adding one resistor and one capacitor into the CRBM
system in VLSI, whose stochastic units contain all the com-
ponents expect for Ri and Ci in Fig.1. Therefore, the VLSI
implementation of the Diffusion Network is undoubtedly
feasible and potentially useful as a intelligent system for
many implantable devices.
From another point of view, an analogy also exists between
the Diffusion Network and the Cellular Neural Network
[8], [9], a deterministic recurrent network with localised
connections. The Diffusion Network differs from the Cellular
Neural Network mainly by the inclusion of the Browian
motion. The successful development of cellular neural net-
work in both applications and VLSI implementation [10],
[11], [12] suggests not only the hardware amenability of the
Diffusion Network but also the rich computational power of
the Diffusion Network in VLSI.
IV. REAL-TIME RECOGNITION BASED ON THE
DETERMINISTIC DYNAMICS OF HIDDEN UNITS
Although calculating the log-likelihood of an unknown
sequence is one mathematically-plausible way of classifica-
tion, the VLSI implementation of Eq.(4) requires complicated
circuits and discourages real-time classification. As the dy-
namics of hidden units must depend on and correlate to those
of visible units owing to full connection among units, we
investigate the possibility of classifying data according to the
deterministic dynamics of hidden units when the dynamics
of visible neurons are clamped to sequences to be classified.
−2 −1 0 1 2
−2
−1
0
1
2
−2 −1 0 1 2
−2
−1
0
1
2
3
y
(a) (b)
Fig. 4. The two-dimensional spiral curves to be classified (b)The 20 regen-
erated visible sequences(solid lines) sampled from the Diffusion Network
trained on one of the spiral curve(dashed line).
−2 −1 0 1 2
−2
0
2
0 100 200 300 400 480
−5
0
5
n
h
1
[n
]
0 100 200 300 400 480
−10
0
10
n
h
2
[n
]
0 100 200 300 400 480
−5
0
5
n
h
3
[n
]
0 100 200 300 400 480
−5
0
5
n
h
4
[n
]
0 100 200 300 400 480
−5
0
5
n
h
5
[n
]
−2 −1 0 1 2
−2
0
2
0 100 200 300 400 480
−5
0
5
n
h
1
[n
]
0 100 200 300 400 480
−10
0
10
n
h
2
[n
]
0 100 200 300 400 480
−5
0
5
n
h
3
[n
]
0 100 200 300 400 480
−5
0
5
n
h
4
[n
]
0 100 200 300 400 480
−5
0
5
n
h
5
[n
]
detection threshold 
detection threshold 
detection threshold 
detection threshold 
(a) (b)
Fig. 5. The dynamics of hidden units of the DN trained on the first spiral
curve when visible units are clamped to (a)the first (b)the second spiral
curves
V. TOLERANCE AGAINST NOISE AND OFFSET
Biomedical signals are normally noisy and drifting. It is
thus important to probe the tolerance of the proposed classi-
fication method against noise and offsets. The classification
of spiral curves in Fig.4a is one of the most difficult artificial
tasks in pattern classification[13], as the classification relies
on capturing the correlation between the two dimensions of
the spiral series, and then drawing a third nonlinear spiral
curve to separate the two curves. To examine the Diffusion
Network’s tolerance against noise and offsets, the Diffusion
Network was trained to model one of the spiral series,
and then used to classify “distorted” spiral series obtained
−2 0 2 4
−2
0
2
4
(a) v1[n]
v
2
[n
]
−2 0 2 4
−2
0
2
4
(b) v1[n]
v
2
[n
]
Fig. 6. The distorted spiral curves obtained by adding offsets and noise to
the two types of spiral curves in Fig.4a.
TABLE I
THE ACCURACY IN CLASSIFYING TWO TYPES OF SPIRAL CURVES
DISTORTED BY VARIOUS LEVELS OF OFFSETS AND NOISE
δx = δy σx = σy
0.2 0.4 0.6 0.8 1.0
0.4 100% 100% 100% 100% 100%
0.5 100% 100% 100% 100% 100%
0.6 100% 100% 100% 100% 100%
0.7 100% 100% 100% 100% 99%
0.8 100% 100% 97% 97% 94%
0.9 78% 71% 77% 74% 79%
1.0 51% 53% 62% 63% 67%
according to Eq.(6).
Let xS1 and xS2 : [0, 480] → R2 represent the spiral
series ending at (0,3) and (0,-3) in Fig.4, respectively. A
Diffusion Network with two visible and five hidden neurons
was trained to model xS1 with σ = 0.2, Ri = 1, and ai = 1.
After 80 training epochs, the Diffusion Network regenerated
its visible dynamics as shown in Fig.4b, indicating that the
spiral series has been modelled satisfactorily. With visible
units of the trained Diffusion Network clamped to xS1 and
to xS2, the deterministic dynamics of hidden units are shown
in Fig.5. As shown in Fig.5, the two different spiral curves
can be easily distinguished by comparing the final values of
the hidden dynamics xH3 or xH5 to the thresholds indicated
by the dashed lines.
Let xSix(t) and xSiy(t) represent the coordinate of
either xS1 or xS2 at time t. To probe the tolerance
against noise and offsets, the trained Diffusion Network
was employed to classify a set of “distorted” spiral curves
xT = (xTx, xTy) : [0, 480]→ R2 generated according to
xTx(t) = xSix(t) + δx + σx ·N(0, 1) (6)
xTy(t) = xSiy(t) + δy + σy ·N(0, 1) (7)
where δx and δy denote the offsets added to the x and
y dimensions, respectively, N(0, 1) denotes a zero-mean
Gaussian noise with unit variance, and σx and σy scale the
noise variance. Fig.6 illustrates two types of distorted spiral
curves with δx = δy = 1 and σx = σy = 1. The distorted
spiral curves xT were classified according to the final value
abnormal ECGs can be easily detected by comparing xH3[81]
to the threshold indicated as the dashed line in Fig.8. If
xH3[81] > 0, the trace is classified as normal ECGs, and
if xH3[81] < 0 the trace is classified as abnormal ECGs.
Based on the classification method, only two abnormal ECGs
are misclassified, as shown by Fig.8h. The accuracy is thus
proved to be 99.8% (calculated as 1006/1008). The slight
inaccuracy mainly come from the fact that the S segment of
several abnormal ECGs do not have significantly lower value
than that of normal ECG, as shown in Fig.7d.
VII. CONCLUSION
This paper investigates the feasibility of applying the
Diffusion Network, a stochastic recurrent network, to the
recognition of continuous-time, continuous-valued biomed-
ical signals. A new classification method is also proposed
to facilitate real-time recognition especially for hardware
implementation. Simulation results demonstrate that the Dif-
fusion Network can classify both artificial and heartbeat data
reliably with considerable tolerance against noise and offsets,
demonstrating the advantage of using stochasticity to gener-
alise variability in data. As the dynamics of the Diffusion
Network are governed by stochastic differential equations
which are shown hardware-amenable, it is important to look
into the VLSI implementation of the Diffusion Network,
making the Diffusion Network useful for real biomedical
applications.
VIII. ACKNOWLEDGEMENT
The authors would like to thanks to the National Science
Council in Taiwan for funding this research (Grant code :
NSC 96-2221-E-007 -167 -MY3).
REFERENCES
[1] M. Lebedev and M. Nicolelis, “Brain-machine interfaces: past, present
and future,” TRENDS in Neuroscience, vol. 29, no. 9, pp. 536–546,
2006.
[2] J. R. Movellan, “A learning theorem for networks at detailed stochastic
equilibrium,” Neural Computation, vol. 10, no. 5, pp. 1157–1178,
1998.
[3] J. R. Movellan, P. Mineiro, and R. J. Williams, “A Monte-Carlo
EM approach for partially observable diffusion processes: Theory and
applications to neural networks,” Neural Computation, vol. 14, no. 7,
pp. 1507–1544, 2002.
[4] H. Chen and A. F. Murray, “A continuous restricted boltzmann
machine with an implementable training algorithm,” IEE Proceedings
of Vision, Image and Signal Processing, vol. 150, no. 3, pp. 153–158,
2003.
[5] D. Specht, “Probabilistic neural networks,” Neural Networks, vol. 3,
no. *, pp. 109–118, 1990.
[6] H. Chen and A. F. Murray, “Continuous-valued probabilistic behaviour
in a vlsi generative model,” IEEE Transactions on Neural Networks,
vol. 17, no. 3, pp. 755–770, 2006.
[7] E. Wong and B. Hajek, Stochastic Process in Engineering Systems,
2nd ed. Springer-Verlag New York Inc., 1971.
[8] L. Chua and T. Roska, “The cnn paradigm,” IEEE Transactions
on Circuits and Systems-I: Foundamental Theory and Applications,
vol. 40, no. 3, pp. 147–156, 1993.
[9] L. Chua and L. Yang, “Cellular neural networks: Theory,” IEEE
Transactions on Circuits and Systems, vol. 35, no. 10, pp. 1257–1272,
1988.
[10] L. Chou and L. Yang, “Cellular neural networks: Applications,” IEEE
Transactions on Circuits and Systems, vol. 35, no. 10, pp. 1273–1290,
1988.
[11] T. Roska and L. Chua, “The cnn universal machine: An analogic array
computer,” IEEE Transactions on Circuits and Systems Ii-Analog and
Digital Signal Processing, vol. 40, no. 3, pp. 163–173, 1993.
[12] L. Chua, T. Roska, T. Kozek, and A. Zarandy, “Cnn universal chips
crank up the computing power,” IEEE Circuits and Devices Magazine,
vol. 12, no. 4, pp. 18–28, 1996.
[13] S. Singh, “Quantifying structural time varying changes in helical data,”
Technical Reort, *.
[14] P. Gomis, K. Suarez, G. Passariello, I. Mendoza, P. Caminal, and
P. Lander, “Abnormal intra-qrs signals and late potentials in the high-
resolution ecg associated with chagasic myocarditis,” IEEE Computers
in Cardiology, vol. 8, no. 11, pp. 633–636, 1996.
報告內容應包括下列各項： 
一、參加會議經過 
此次會議在巴黎的 Pierre & Marrie Curie University 舉行，共有 100 多個學者來自十幾
個國家參與，主題為探討類神經網路於圖型辨識的應用與演算法的發展，所以整個會議經過
所有與會人士都在同ㄧ個會議室討論，Poster Session 亦是單獨進行，不與任何口頭報告衝
突，以讓與會學者與發表論文的人可以充分交流與討論。會議的 Invited Speaker 為 Prof. 
Patrick Gallinari，演講的題目為 Predicting Structured Outputs – A Reinforcement 
Learning Approach。主要探討 Reinforcement Learning 應用於建模資料結構的優缺點。本
人全程參與聆聽論文發表與討論，並在第ㄧ天 7月 2日下午發表自己的成果，與其他學者交
換意見。 
 
二、與會心得 
  此會議專注探討類神經網路於樣形辨識的應用，大部分的論文發表著重在類神經網路在
特定應用上，例如 DNA 結構分析，影像分割等的表現，並討論不同的演算法的優缺點，對
解決特定的應用問題相當有幫助。但是，整體來說，比較缺乏新演算法的發表，在解釋或
比較結果的過程，也比較偏質化的解釋，缺乏嚴謹的數學描述，所以對學習新的演算法與
深入了解演算法的特性有限。本人於會議中發表機率型晶片系統對環境雜訊的穩健性探
討，主要成果為驗證晶片中的機率行為，有助於晶片的運算較不受外界雜訊的干擾，仍能
正確建模資料，或是辨識資料，雖然與會學者不多人從事積體電路設計，但很多學者對機
率型演算法能實現成晶片系統，以及機率行為於實際硬體上的應用非常感興趣，並對此研
究成果相當肯定。此外，在會議的餐會中，ㄧ位來自埃及的 IBM 的經理，Dr. Hisham 
EI-Shishiny 對台灣清華大學的學術表現非常讚賞，以上海交大的學校排名為依據，並希望
邀請本人或系上同仁參加明年他在開主辦的多核心處理器之國際研討會。 
 
三、考察參觀活動(無是項活動者省略) 
本人於 7月 4日下午趕回 Bordeaux,France 與美國 Georgia Tech., Dept of Electrical and 
Commputer Science 的 Prof. Stephen P. DeWeerth 會面，他主要來法國進行交流訪問，而
研究重點為發展神經與電子電路的介面，本人代表清大在 IMS Lab, Bordeaux University
的訪問教授與其交流，除了介紹清大相關神經工程的研究外，所以我們討論了建立複合式神
經-機電系統的可行性與挑戰，Prof. DeWeerth 對我們能有許多生物實驗的平台(如螯蝦神經
系統)非可以驗證新研發的神經機電介面非常讚許，也對腦科學中心的果蠅研究很感興趣，
表示我們與生科系同仁有良好的溝通與合作關係，並與本人討論未來交流及可能合作的機
會。 
 
四、建議 
無 
 
五、攜回資料名稱及內容 
會議論文集紙本一份 
 
六、其他 
 
 
h1 h2 h3 h4
v1 v2v0
h0
W(1)
Fig. 1. The architecture of a CRBM model with two visible and four hidden neurons. v0 and h0
represent biasing unit with invariant outputs v0 = h0 = 1.
2 The CRBM Model
The CRBM model consists of one visible and one hidden layers of continuous-valued,
stochastic neurons with inter-layer connections, as shown in Fig.1. Circle vi represents
visible neurons while circle h j represents hidden neurons. The number of visible neu-
rons corresponds to the dimensions of modeled data, while that of hidden neurons is
chosen according to data complexity. Let si denotes the state of neuron vi or h j, and wi j
represents the bi-directional connection between vi and h j. The stochastic behaviour of
a neuron si is described by [5]
si = ϕi (ai · (Σ jwi j · s j + Ni (σ ,0))) (1)
where Ni (σ ,0) represents a zero-mean Gaussian noise with variance σ2, and ϕi (·) a
sigmoid function with asymptotes at ±1 and slope controlled by ai. As a generative
model, the CRBM learns to ”regenerate” training data distributions in its visible neu-
rons. Testing data can then be categorised according to the responses of hidden neu-
rons [5]. The training algorithm implemented in the CRBM system is defined by the
following equation [6]
△λ = ηλ · (
〈
si · s j
〉
4−
〈
sˆi · sˆ j
〉
4) (2)
where λ represent parameters wi j or ai, ηλ the updating rate, sˆi and sˆ j the one-step
Gibbs-sampled states. 〈·〉4 stands for taking the expectation over four training data. For
parameter ai, the training algorithm is the same with Eq.(2) but simply replace s j and
sˆ j by si and sˆi, respectively.
The modelled distribution of a trained CRBM is obtained by initializing visible neu-
rons with random values, and then Gibbs sampling hidden and visible neurons alterna-
tively for multiple steps. The N-th step samples of visible neurons are called the N-step
reconstruction, and it approximates the modelled distribution when N is large. The sim-
ilarity between N-step reconstruction and training data indicates how well training data
is modelled.
stochastic behaviour in VLSI [5]. Fig.2 shows the modular diagram of the CRBM sys-
tems excluding its learning circuits. The CRBM neurons mainly comprise of multipliers
to calculate the products (wi j · s j) in Eq.(1), and sigmoid circuits with {ai} controlling
the slope of ϕi. On the other hand, multi-channel, uncorrelated noise {ni} are injected
into the neurons to make the outputs, {vi} and {hi}, probabilistic. Parameters {wi j}
and {ai} are stored as voltages across capacitors, and are adaptable by on-chip learning
circuits. The learning circuits can also refresh {wi j} and {ai} to specific values after
training. Table 1 summarises the mapping for all parameters between software simula-
tion and VLSI implementation, which has been proved useful for simulating the effects
of non-ideal training offsets on the performance of the CRBM system [5]
In an implantable device containing digital-signal-processing circuits, multi-purpose
sensors, and wireless transceivers, a VLSI system unavoidably suffers from various en-
vironmental noise including substrate noise, sensory noise, and electromagnetic inter-
ferences. As these interferences mainly affect the precision of voltage signals in VLSI,
voltage-represented si, wi j, and ai in the CRBM system are expected to experience se-
rious effects, while the influence on current-mode learning circuits are assumed to be
negligible. Therefore, the influence of environmental noise on the CRBM system was
simulated by replacing si, wi j , and ai in Eq.(1) and Eq.(2) by the following equations
w′ = w+ nw
a′ = a + na (3)
s′ = s+ ns
where ns, nw, and na represent zero-mean, uncorrelated noise with either Gaussian or
Uniform distributions.
3.2 Modelling Artificial Data in the Presence of Environmental Noise
To illustrate the characteristics of the CRBM, as well as to identify a quantitative index
for how well the CRBM models a dataset, the CRBM with two visible and four hid-
den neurons was first trained to model the artificial data in Fig.3(a) in the absence of
environmental noise. The training data contains one elliptic and one circular clusters of
1000 Gaussian-distributed data points. With σ = 0.2, ηw = 0.02, ηa = 0.2, and after
15,000 training epochs, the CRBM regenerated the 20-step reconstruction of 1000 data
points as shown in Fig.3(b), indicating that the CRBM has modelled data. While visual
comparison between Fig.3(a) and (b) can hardly tell how well the data is modelled, the
following index is employed to measure the similarity quantitatively.
Let PT (v) and PM(v) represent the probability distribution of training data and that
modelled by the CRBM, respectively. The Kulback-Leibler (KL) Divergence defined as
Eq.(4) [7] measures the difference between PT (v) and PM(v).
G = ΣvPT (v)log
PT (v)
PM(v)
(4)
where v denotes the subset of visible space, and G equals zero when PT (v) = PM(v).
As explicit equations for describing the modelled distribution, PM(v), are normally
that the tolerance against Gaussian-distributed noise is much better than that against
uniformly-distributed noise. This is attributed to the fact that the training data and the
noise incorporated in the CRBM neurons are Gaussian-distributed. From another point
of view, if the distribution of environmental noise is known, training the CRBM sys-
tem with noise inputs {ni} modified to have the known distribution can enhance the
tolerance against a specific type of noise.
Table 2. The maximum gaussian- and uniformly-distributed noise tolerable by the CRBM system
during modelling artificial data.
Gaussian-distributed noise Uniformly-distributed noise
nw [-0.27V, 0.27V] [-0.18V, 0.18V]
na [-0.16V, 0.16V] [-0.08V, 0.08V]
ns [-0.18V, 0.18V] [-0.06V, 0.06V]
nw,na,ns [-0.13V, 0.13V] [-0.04V, 0.04V]
−1 −0.5 0 0.5 1
−1
−0.5
0
0.5
1
overlapped
abnormal heartbeat 
Fig. 4. The projection of 500 ECG training data to its first two principle components. The projec-
tion of the five abnormal ECGs in the dataset are denoted by black crosses.
3.3 Modelling Biomedical Data in the Presence of Environmental Noise
The tolerable environmental noise for modelling high-dimensional, real-world data was
examined in the context of recognising electrocardiograms (ECG), extracted from the
MIT-BIH database as in [6]. The training dataset contains 500 heartbeats with only 5
abnormal heartbeats. The testing dataset contains 1700 heartbeats with 27 abnormal
heartbeats. Each heartbeat is sampled as a 65-dimemsional datum, and Fig.4 shows the
projection of the training dataset onto its first two principle components. Although the
dimension reduction makes the quantitative index G remain applicable, pilot simula-
tion showed that modelling training data satisfactorily does not guarantee the detection
of abnormal heartbeats with 100% accuracy. This is because the distributions of nor-
mal and abnormal heartbeats overlap with each other, as shown in Fig.4. Therefore,
detecting abnormal heartbeats with 100% accuracy was used as a stricter criterion for
identifying the tolerable noise during modelling ECG data.
Fig.5(a)(b) shows heartbeat signals reconstructed by a CRBM system trained with-
out noise. Fig.5(c) shows the response of hidden neuron h2 to 1700 testing data {d},
calculated according to Eq.(5). The abnormal heartbeats can be detected with 100%
accuracy by setting any threshold between minV and maxQ.
h2 = ϕ2(a2 · (w(2) ·d)) (5)
With uniformly-distributed noise ranging between -0.01V and 0.01V, the trained CRBM
system was able to reconstruct both normal and abnormal ECG signal satisfactorily, as
shown in Fig.5(d)(e). Comparison between Fig.5(a)(b) and Fig.5(d)(e) indicates that the
influence of environmental noise injection introduce extra fluctuations in the waveform.
Table 3 summarises the maximum environmental noise the CRBM can tolerate to
model and to detect abnormal ECGs with 100% accuracy. The tolerable noise levels in
Table 3 are mostly smaller than those in Table 2 because the ECG data require more
sophisticated modelling. On the contrary, parameter {wi j} has comparable tolerance
in both modelling tasks because the presence of nw simply distorts the weight vectors
and results in fluctuated reconstructions like those in Fig.5(d)(e), while these effects do
not impede the CRBM from modelling the distinguishable features between abnormal
and normal ECGs. This also explains the relatively smaller tolerance against ns, i.e. the
noise in {si}, as ns does distort the features of ECGs, making it difficult to identify any
distinguishable feature between normal and abnormal ECGs.
4 Noise-enhanced Robustness in the CRBM System
By reducing the standard deviation of the noise injected into CRBM neurons to σ = 0.1
in Eq.(1), the maximum environmental noise the CRBM can tolerate to model the arti-
ficial data in Fig.3(a) is summarised in Table 4. Comparison between Table 2 and Table
4 indicates that reducing σ = 0.1 helps to enhance the robustness against environmental
noise, as part of environmental noise is incorporated to compensate for the reduction
of the“internal noise” ni, which is essential for inducing stochasticity for modelling the
variability of training data. Therefore, as shown by Table 4, the robustness against en-
vironment noise, especially for uniformly-distributed noise, is improved significantly.
The worst tolerable level is still greater than 110mV, corresponding to a signal-to-noise
ratio less than 20 for a CRBM system. The advantage of incorporating noise-induced
stochasticity in VLSI is clearly demonstrated.
Furthermore, it is interesting to investigate whether the internal noise ni could be
completely replaced by environmental noise to induce stochasticity for computation.
By substituting s j +ns for s j and setting Ni(σ ,0) = 0 in Eq.(1), the term ∑wi j ·(s j +ns)
becomes a random variable n′i with mean value ∑wi j · s j and a variance given as
var(n′i) = Σ jw2i j · var(ns) (6)
and incorporated during training, or by reducing the internal noise of the CRBM system.
It is also demonstrated that environmental noise can be used to induce the stochasticity
essential for the CRBM system to model data optimally. In other words, the robust-
ness of the CRBM system can be optimised by training the CRBM to model data with
stochasticity induced by environmental noise the CRBM system is exposed to. All these
concepts will be further examined by hardware testing with the CRBM system.
References
1. B. T. Tong, E. A. Johannessen, W. Lei, A. Astaras, M. Ahmadian, A. F. Murray, J. M. Cooper,
S. P. Beaumont, B. W. Flynn, and D. R. S. Cumming: Toward a miniature wireless integrated
multisensor microsystem for industrial and biomedical applications. Sensors Journal, IEEE,
vol. 2, no. 6 (2002) 628–635
2. E. A. Johannessen, W. Lei, C. Li, B. T. Tong, M. Ahmadian, A. Astaras, S. W. J. Reid, P.
S. Yam, A. F. Murray, B. W. A. Flynn, S. P. A. Beaumont, D. R. S. Cumming, and J. M. A.
Cooper: Implementation of multichannel sensors for remote biomedical measurements in a
microsystems format. IEEE Transactions on Biomedical Engineering, vol. 51, no. 3 (2004)
525–535
3. S. Mingui, M. Mickle, L. Wei, L. Qiang, and R. J. Sclabassi, ”Data communication between
brain implants and computer: IEEE Transactions on Neural Systems and Rehabilitation Engi-
neering, vol. 11, no. 2 (2003) 189-192
4. M. A. L. Nicolelis: Actions from thoughts. Nature, vol. 409 (2001) 403–407
5. C. Hsin, P. C. D. Fleury, and A. F. Murray: Continuous-valued probabilistic behavior in a VLSI
generative model. IEEE Transactions on Neural Networks, vol. 17, no. 3 (2006) 755–770
6. H. Chen and A. F. Murray: Continuous restricted Boltzmann machine with an implementable
training algorithm. IEE Proceedings-Vision Image and Signal Processing, vol. 150, no. 3
(2003) 153–158
7. Hinton, G. E. and Sejnowski, T. J.: Learning and Relearning in Boltzmann Machine. Parallel
Distributed Processing: Explorations in the Microstructure of Cognition Cambridge, Mas-
sachusetts: MIT (1986) 283–317
8. N. H. Hamid, A. F. Murray, D. Laurenson, S. Roy, and C. Binjie: Probabilistic computing with
future deep sub-micrometer devices: a modelling approach. IEEE International Symposium on
Circuits and Systems (2005) 2510-2513
合作的機會。 
    在本次會議中，學生學到了許多新的研究方法以及了解目前在本研究領域中所
遇到的主要困難。例如在 Prof. Giacomo Indiveri 的演講中，介紹他們在瑞士的團隊，
利用 MOSFET 操作在 Subthreshold Region 中的電壓電流的指數關係，設計一個仿
真的神經元，並利用 AER 的神經溝通介面，探討大腦內的神經網路，並實現成硬
體，做出仿生積體電路，而透過與會的神經科學家、計算機科學家，硬體科學家的
的互動過程中得到不少的啟發。 
    本次的會議讓學生獲益良多，並且也為學生的研究找到新的應用，且學習到目
前在這方面研究領域中的發展現況以及遇到的問題，讓學生在日後的研究能夠更創
新以及針對問題想出解決方式，在此謝謝指導教授陳新博士的指導以及鼓勵和國科
會在研究經費以及出國經費的補助。 
 
三、 建議 
    今年舉辦的 ICANN 是第十九屆，台灣學者參與的人數相對少，但此會議實為
歐洲頂尖類神經網路會議，所邀請來的演講者都是國際級的資深學者，有些演講者
在之前的研討會中就已見過，且所報告的題目都是該領域目前的發展近況及所面臨
的問題，台灣學者可以多參與這樣的會議。 
四、 攜回資料名稱及內容 
1. International Conference on Artificial Neural Networks 摘要集。 
2. 此次會議的 Proceeding 光碟，內容包含此次會議所有的 paper。 
 
五、 其他 
明年的會議將於希臘舉行，有興趣的學者可以上網查看。以下為其網址 
Web: http://delab.csd.auth.gr/icann2010/index.html 
發表論文 
全    文 
如附件 
受補助之學生請於回國後將此表填妥 mail 至 scchung@mx.nthu.edu.tw 信箱 
2   The CRBM Model 
The CRBM consists of one visible and one hidden layers of stochastic neurons 
with inter-layer connections only [7]. The number of visible neurons corresponds to 
the dimension of data, while that of hidden neurons is chosen according to data 
complexity [7]. Let wij represent the bi-directional connection between neurons si and 
sj. The stochastic state of a neuron si is defined by [7] 
⎟⎟⎠
⎞
⎜⎜⎝
⎛
⎟⎟⎠
⎞
⎜⎜⎝
⎛ +⋅⋅= ∑
j
ijijii Nswas ),0( σϕ                           (1) 
where Ni(σ,0) represents a Gaussian noise with zero mean and variance σ2, and φ(⋅) a 
sigmoid function (e.g. tanh(⋅) ) with asymptotes at ±1. Parameter ai controls the slope 
of the sigmoid function and thus the variance of si, such that the neuron is either near-
deterministic (small ai), or continuous-stochastic (moderate ai), or binary-stochastic 
(large ai). Let λ represent the parameter {wij} or {ai}. Parameters in a CRBM 
microsystem are trained by the simplified MCD algorithm [3] ( )
44
ˆˆ jiji sssssign ⋅−⋅⋅= ληλ∆                               (2) 
where ŝi and ŝj denotes the one-step Gibbs-sampled states [7], ηλ the updating rate, and 
<⋅>4 taking the expectation over four training data. The difference between <si⋅sj>4 
and <ŝi⋅ŝj>4 corresponds to the contrastive divergence between training and modelled 
distributions [6] and has to be minimised. For training {ai}, sj and ŝj in Eq.(2) are 
replaced by si and ŝ i, respectively. 
3   Maximum Offsets Tolerable by the CRBM 
The CRBM has been realised as a VLSI microsystem containing six neurons with 
on-chip training circuits [3]. However, hardware nonidealities in training circuits 
prevents the CRBM system from modelling data optimally, and it was shown that the 
overall effect of hardware nonidealities can be modelled as the “biased” training 
algorithm 
)ˆˆ( 44 Tjiji sssssign ∆ηλ∆ λ +>⋅<−>⋅<⋅=           (3) 
where ∆T represents the offset that limits the minimum contrastive divergence 
achievable by on-chip training circuits. Although the offset varies from one circuit to 
another, it is assumed to be identical in simulation for simplicity. Based on the 
software-hardware mapping derived in [3], the following subsections simulate the 
behaviour of a CRBM microsystem with Eq.(3), and identify the maximum offsets 
(∆T) the system can tolerate. The value of tolerable offsets will be given in terms of 
percentage, normalized with respect to the maximum value of |< si ⋅ sj >4 | = 1. (i.e. ∆T  
=1% refers to ∆T =0.01 in Eq.(3)). 
 
where v denotes the subset of visible states, and G equals zero when PT(v) = PM(v). 
As not all distributions can be described by explicit equations, PT(v) and PM(v) were 
statistically-estimated by dividing the two-dimensional space into 10x10 square grids, 
counting the number of data points in each grid, and normalising the counts with 
respect to the total number of data points. Fig.1(c)(d) shows the statistical density of 
20-step reconstructions generated by the CRBM after 20000 and 30000 training 
epochs, respectively. The G values calculated according to Eq.(4) are shown at the 
bottom-left corner of each subfigure, indicating that the KL-divergence is a reliable 
index for measuring quantitatively the similarity between training and modelled 
distributions. Similar results are obtained for other data like doughnut-shaped 
distribution. As the training updates of most parameters become negligible after G < 
0.8, it is chosen as the criterion for identifying the tolerable offsets for the CRBM. 
When all parameters ({wij}, {avi}, and {ahi}) experience offsets, the maximum offsets 
the CRBM can tolerate to model artificial data was identified to be 1% (Table I). 
3.2   Modelling Real Heartbeat Data with Offsets 
The tolerable offset for modelling high-dimensional, real-world data was 
examined in the context of recognising electrocardiograms (ECG), extracted from the 
MIT-BIH database as in [9-10]. The training dataset contains 500 heartbeats with only 
5 abnormal heartbeats. The testing dataset contains 1700 heartbeats with 27 abnormal 
heartbeats. Each ECG trace was sampled as a 65-dimensional datum, and Fig.2(a) 
−1 −0.5 0 0.5 1
−1
−0.5
0
0.5
1
 1 65−1
−0.5
0
0.5
1
Normal
Recon.
 1 65−1
−0.5
0
0.5
1
Abnormal
Recon.
 
(a)                    (b)                   (c) 
200 400 600 800 1000 1200 1400 1600
−1
−0.5
0
0.5
1
maxV 
minV 
minQ 
maxQ 
Vth=0.51 
Vth=0.19
 
(d) 
Fig.2. (a)The projection of 500 ECG training data to its first two principle 
components. The projection of the five abnormal ECGs are denoted by black 
crosses. (b)(c)(d)Results of training the CRBM to model ECG data with ∆T=0.2% 
for all parameters. (b)The normal and (c)the abnormal ECGs in training dataset 
(grey) and the reconstruction by the trained CRBM (dashed). (d) Responses of 
hidden neuron h3 to 1700 testing data. maxV, minV, maxQ, and minQ correspond 
to the maximum and minimum responses to abnormal heartbeats, and maximum 
and minimum responses to normal heartbeats, respectively. 
Overlapped 
abnormal heartbeat 
  
 
    
(a)                             (b) 
Fig.5. Measured Vo = VREF-Iout⋅Hf for four-datum training with Iin = 0.25 µA (a) 
without offset (b)with offset. The digital signals from top to bottom correspond to 
SIN, SD1, SG1, SD2, SG2, and SOUT of accumulator A and those of accumulator B in 
Fig.3. 
    
(a)                              (b) 
Fig.4. Measured Vo = VREF-Iout⋅Hf for single-datum training with Iin = 1µA. (a) 
without offset (b)with offset. The digital signals from top to bottom correspond to 
SIN, SD1, SG1, SD2, SG2, and SOUT in Fig.3. 
 
Accumulator A
Accumulator B VREF
Iin
Iout
 
VREF
CIN
CF
 
Fig.3. The proposed DCM training circuit consisting of (a)a multiplier and the 
DCM accumulator calculating (si⋅sj– ŝi⋅ŝj), or (b)the DCM accumulator 
calculating <si⋅sj>4–<ŝi⋅ŝj>4, and, (c)the charge amplifier. 
SOUT=”ON” SOUT=”ON” 
Vo(CH2) 
Vo(CH2) 
SOUT=”ON” SOUT=”ON” 
∆Vo
Vo(CH2) 
Vo(CH2) 
∆Vo
multiplier proposed in [3]. As for the latter, complementary transistors can be used as 
switches to compensate for charge-injection errors. However, the simulation normally 
underestimates the charge-injection errors. The DCM accumulators in Fig.3(a) and (b), 
excluding the multiplier, were thus fabricated with the TSMC 0.35um 2P4M CMOS 
process to investigate the precision achievable by the proposed training circuits. 
For the single-datum training algorithm, Iin was designed to range from 1µA to 
3µA, corresponding to si⋅sj =–1 and ŝi⋅ŝj =1, respectively. To minimise the 
dependence of charge injection on Iin, the charge-injection error is minimised at 
Iin=2µA. For four-data training algorithm, Iin was designed to range from 0.25µA to 
0.75µA, such that the accumulation of four data still ranges from 1µA to 3µA, 
allowing the minimisation of charge-injection error to remain at Iin = 2µA. 
5   Measurement Results 
With Iin generated from a Source Meter (Keithley 2602), the output of the DCM 
accumulators were connected to a current-voltage(I-V) converter, which emulated 
VREF in Fig.3 and converted Iout into a voltage of Vo= VREF – Hf ⋅Iout with Hf = 1650 
(V/A). The voltage change ∆Vo = Vo–VREF = -Hf ⋅Iout at the instant of closing SOUT was 
then measured. With digital-control clocks generated by a Field-Programmable-Gate-
Array (FPGA) chip, the DCM accumulators were set easily to calculate (si⋅sj–ŝi⋅ŝj)  
or <si⋅sj>4–<ŝi⋅ŝj>4. 
For calculating (si⋅sj–ŝi⋅ŝj), the measured Vo in response to a constant Iin of 1 µA, 
i.e. si⋅sj = ŝi⋅ŝj = -1, is shown in Fig.4. Although ∆Vo ideally equaled zero, ∆Vo 
measured from the same circuit either approximated zero or varied from one trial to 
another. Similar results were observed when calculating < si⋅sj >4–< ŝi⋅ŝj >4, as shown 
in Fig.5. Normalising ∆Vo with respect to 1.65 V (the ∆Vo for Iout  = 1µA representing 
|si⋅sj|=1) gives the offset errors in terms of percentage. Fig.6 shows the statistical 
distribution of the offsets measured from 1000 trials of calculating (si⋅sj–ŝi⋅ŝj). 
Interestingly, the offsets exhibit a uniform distribution instead of staying constant, and 
the variance is greater than the mean value. 
The offsets in the DCM accumulators were caused by charge-injection errors, 
leakage currents of C1 and C2, and clock jitters generated by the FPGA chip. To 
investigate the contribution of leakage currents, two types of digital clocks were used 
to buffer Iin to Iout by storing Iin in the NMOS DCM, transferring it to the PMOS DCM, 
and subsequently outputing the current. One clock differs from the other mainly by 
shortening the period of opening SG1 and SG2. Shortening the period improved the 
mean errors from -8.09% to -6.38%, while the standard deviations of the two cases 
are comparable (~3.45%). Therefore, leakage currents mainly affect the mean errors, 
while clock jitters have dominant effects on the variance. Accumulating four Iin 
caused mean errors to increase by more than four times, while the standard deviations 
remained about the same. Charge injection thus also affected mainly the mean errors. 
Table II summarises the performance of the DCM accumulator in calculating 
(si⋅sj–ŝi⋅ŝj) with different Iin. The mean errors became significantly smaller than 6.38%, 
indicating that charge-injection and leakage-current errors in the NMOS and PMOS 
DCMs cancelled with each other largely through the subtraction operation. Complete 
This feature agrees with the finding that randomness releases the precision required 
for training a multi-layer-perceptron [17-18]. The CRBM is able to correct training 
errors whenever the random offset is small, and thus to discourage the saturation of 
parameter values. Therefore, it is important to know when to stop training once the 
data distribution is modelled, so as to prevent ∆T from dominating to causes all 
parameters to saturate. Fortunately, the G value could be used as a reliable indicator 
for when to stop. 
6   Conclusions 
The feasibility of minimising contrastive divergence on-chip with DCMs has 
been carefully investigated by both behavioural simulation of the CRBM microsystem 
and the VLSI implementation of DCM accumulators. The simulation indicates that 
the CRBM can tolerate a maximum offset of only 0.3% to model real biomedical 
(ECG) data satisfactorily, and that the tolerance can be slightly-improved by real-
valued adaptation. On the other hand, measurement results of DCM accumulators 
indicate that the accumulation errors in DCMs can be largely cancelled by the 
subtraction operation essential for the contrastive-divergence training. As the mean 
offsets in Table II are all smaller than 0.5%, i.e. the tolerable offset for four-data, real-
valued trainning in Table IV, using four DCM accumulators (Fig.3(a)) to calculate 
<si⋅sj>4–<ŝi⋅ŝj>4 would allow us to avoid the accumulation error in Table III while 
achieving satisfactory precision. This suggestion will be further confirmed with the 
VLSI implementation of the full training circuit. 
Acknowledge 
 The authors would like to acknowledge the TSMC and CIC for fabrication of 
the chip, and the National Science Council (NSC) in Taiwan for funding this project 
(Grant code : NSC 95-2221-E-007-115). 
References 
1. Schwartz, A. B., "Cortical Neural Prothetics," Annual Review Neuroscience, pp. 487-507, Mar.2004. 
2. Lebedev, M. A. and Nicolelis, M. A. L., "Brain-machine interfaces: past, present and future," TRENDS 
in Neuroscience 29 [9], 536-546. 2006. 
3. Chen, H., Fleury, P., and Murray, A. F., "Continuous-Valued Probabilistic Behaviour in a VLSI 
Generative Model," IEEE Transactions on Neural Networks, vol. 17, no. 3, pp. 755-770, 2006. 
4. Genov, R. and Cauwenberghs, G., "Kerneltron: support vector machine in silicon," IEEE Transactions 
on Neural Networks, vol. 14, no. 8, pp. 1426-1433, 2003. 
5. Hsu, D., Bridges, S., Figueroa, M., and Diorio, C., "Adaptive Quantization and Density Estimation in 
Silicon," 15. 2003. Advances in Neural Information Processing Systems (NIPS02). 2002. 
6. Hinton, G. E., "Training Products of Experts by Minimizing Contrastive Divergence," Neural 
Computation, vol. 14, no. 8, pp. 1771-1800, Aug.2002. 
Current-mode Computation with Noise in a Scalable 
and Programmable Probabilistic Neural VLSI System 
C.C. Lu and H. Chen 
 
The Dept. of Electrical Engineering, 
The National Tsing Hua University, Hsin-Chu, Taiwan 30013 
Abstract. This paper presents the VLSI implementation of a scalable and 
programmable Continuous Restricted Blotzmann Machine (CRBM), a 
probabilistic model proved useful for recognising biomedical data. Each single-
chip system contains 10 stochastic neurons and 25 adaptable connections. The 
scalability allows the network size to be expanded by interconnecting multiple 
chips, and the programmability allows all parameters to be set and refreshed to 
optimum values. In addition, current-mode computation is employed to increase 
dynamic ranges of signals, and a noise generator is included to induce 
continous-valued stochasticity on chip. The circuit design and corresponding 
measurement results are described and discussed. 
Keywords: Probabilistic VLSI, noise, scalable and programmable systems, 
probabilistic model 
1   Introduction 
Probabilistic models use stochasticity to generalise the natural variability of data, 
and have been shown promising for reasoning biomedical data or for solving weakly-
constrained problems such as pattern recognition. Realising probabilistic models in 
the Very-Large-Scale-Integration (VLSI) is thus attractive for the application like 
intelligent sensor fusion in implantable devices [1][2]. However, only a few 
probabilistic models are amenable to VLSI implementation [3][4], and most of which 
relies greatly on precise computation of Bayesian rules or vector products, which 
becomes infeasible as transistor noise and hardware non-ideality grow. 
The CRBM is a probabilistic model which has been shown capable of classifying 
biomedical data reliably [5] and has been realised as a probabilistic VLSI system [6], 
potential for being an intelligent embedded system in implantable devices. With a 
fixed number (six) of neurons, however, the prototype system is limited to model two-
dimensional data, while biomedical signals in real-world applications are normally 
high-dimensional and complex. Therefore, modular design is employed in the VLSI 
implementation presented here, allowing the network size to be expanded by 
connecting multiple chips. All parameters of the system are stored in dynamic 
analogue memory which can be not only refreshed at optimum values reliably but also 
trained by chip-in-a-loop configuration. The full system has been designed and 
fabricated with the TSMC 0.35µm CMOS technology. Following a brief introduction 
 3   System Architecture 
Fig.2 shows the architecture of the scalable and programmable CRBM system 
[8], containing neuron modules (vi and hj), synapse modules (wij), a noise generator, 
and digital control circuits. The refreshing unit is designed to be realised by a 
microcontroller off-chip. Each synapse module contains two multipliers to calculate 
wijhj and wijvi as current inputs for neurons vi and hj, respectively. Each neuron vi (hj) 
then sums up the currents on the same row (column) at the terminal I (Fig.2(c)), and 
passes the total current through sigmoid function to generate an output voltage at 
terminal O. In addition, each neuron includes a noise input to makes its output 
probabilistic. 
The modular design enables the CRBM system to expand its network size easily 
by interconnecting multiple chips. For example, an MxN chip array forms a CRBM 
system with 5M visible and 5N hidden neurons. Synapse modules in the same row 
(column) transmit output currents to the left- (bottom-) most neurons in the row 
(column). Each neuron module vi (hj) then transmits voltage output back to synapse 
modules in the same row (column). The control signal N in each neuron (Fig.2(c)) 
determines whether the neuron is enabled. When N=1, current inputs at terminal I are 
passed through sigmoid circuit to generate the neuron’s output at terminal O. When 
N=0, the current inputs at terminal I are simply directed to terminal X, and the neuron 
output is buffered from terminal S into terminal O. A current normaliser is included to 
avoid the saturation of sigmoid circuit. 
 
 
Fig.2. The architecture of a scalable and programmable CRBM system and its 
functional units. 
  
 
Fig.5. (a)A multiplexing architecture for programming parameters in the CRBM 
system. (b)Clock signals for programming (c)Local updating circuit. 
 
Fig.4. The sub-circuits in the stochastic neuron. (a)Current conveyor with N:1 
normaliser (b)Floating resistor (c)Sigmoid circuit. 
mode, update directions are multiplexed and registered into the parameter array in a 
similar manner, except for that the update directions are calculated from the MCD 
algorithm. 
5 Measurement Results 
Fig.6(a) shows the measured output current of one multiplier in the synapse w40. 
With the output O of the neuron V4 sweeping from 1V to 2V, the output currents at 
IH, in response to different levels of w40, were measured. Obviously, the multiplier 
allowed the parameter w40 to have a rail-to-rail dynamic range and exhibited 
satisfactory linearity. Furthermore, the arithmetical zeros located at 1.5V precisely, 
agreeing with the mapping in Table.1. 
Fig.6(b) shows the measured characteristics of the sigmoid circuit in the neuron 
H0. With the current at the input I (called IH0) sweeping from -3µA to 3µA, the 
voltage at the output O (called H0) was measured. Different curves correspond to 
different levels of the voltage AH0, which controls the slope of the sigmoid function. 
As ϕ(1)=0.462 and the unit values of IH0 and H0 are 1µA and 0.5V, respectively, the 
adaptable range of AH0 corresponds to an adaptable range of [0.5, 2.5] for the 
parameter ai, covering the required range ([0.5, 5]) set in Table.1. 
Fig.7(a) shows the noise voltage (the top trace) measured at one channel of the 
noise generator. The signal fell in [1, 2](V), corresponding to a numerical range of [-1, 
1] in software simulation. As the noise signal was sent into the neuron H0 with 
w40=3V and AH0=1.9V, the measured neuron output, in response to all connected 
synapses having their VO sweeping between 1V and 2V, are shown in Fig.7(b). The 
neuron output (the upper trace) swept the sigmoidal curve periodically with VO (the 
lower trace), and the noise input perturbed the curve significantly. The continuous-
valued stochastic behaviour of the neuron in accordance with Eq.(1) was clearly 
demonstrated 
Fig.8(a) further shows the measured characteristic of the updating circuit in 
refreshing mode. With VP=2.46V, VN=0.57V, and a pulse width of 320ns for VPLS, 
an updating step of only 12mV was easily achieved for both incremental 
(INC/DEC=0) and decremental (INC/DEC=1) updates. The updating step could be 
further decreased by simply reducing the pulse width of VPLS, while the background 
noise of the oscilloscope and the switching noise made the updating step hardly 
visible. The programmability of parameter arrays was further tested by initialising a 
parameter to 2.25V and then adapting it towards 1.5V. Fig.8(b) shows the measured 
parameter voltage (the second trace from top) and corresponding digital control 
signals. The parameter value adapted from 2.25V to 1.5V within 336µsec. As soon as 
the target value was achieved, the directional signal (INC/DEC) started to alternate 
between 1 and 0, refreshing the parameter at 1.5 reliably. 
 
6   Conclusion 
The VLSI circuits realising a scalable and programmable CRBM system have 
been designed, fabricated and tested. The preliminary measurement results 
demonstrate satisfactory functionality of the synapse module, the neuron module, and 
their programmable parameters. By interconnecting multiple chips, the capability of 
the system to model high-dimensional biomedical data, as well as the feasibility of 
using noise-induced stochastic behaviour to enhance the robustness of analogue 
computation will be further examined and discussed. 
Acknowledge 
The authors would like to acknowledge the TSMC and the National Chip 
Implementation Center for fabricating the chip, and the National Science Council 
(NSC) in Taiwan for funding this project (Grant code : NSC 95-2221-E-007 -115).  
References 
1. T.B. Tang, E. A. Johannessen, W. Lei, A. Astaras, M. Ahmadian, A. F. Murray, J. M. 
Cooper, S. P. Beaumont, B. W. Flynn, and D. R. S. Cumming, "Toward a miniature wireless 
integrated multisensor microsystem for industrial and biomedical applications," Sensors 
Journal, IEEE, vol. 2, no. 6, pp. 628-635, 2002. 
2. Erik. A. Johannessen, Lei Wang, Cathy Wyse, David R. S. Cumming, and Jon M. A. Cooper, 
"Biocompatibility of a Lab-on-a-Pill Sensor in Artificial Gastrointestinal Environments," 
Biomedical Engineering, IEEE Transactions on, vol. 53, no. 11, pp. 2333-2340, 2006. 
3. Genov, R. and Cauwenberghs, G., "Kerneltron: support vector machine in silicon," IEEE 
Transactions on Neural Networks, vol. 14, no. 8, pp. 1426-1433, 2003. 
4. Hsu, D., Bridges, S., Figueroa, M., and Diorio, C., "Adaptive Quantization and Density 
Estimation in Silicon," in Advances in Neural Information Processing Systems (NIPS*2002), 
Cambridge, MA: MIT Press, pp. 1083-1090, 2002. 
5. H. Chen and A. F. Murray, "Continuous restricted Boltzmann machine with an 
implementable training algorithm," Iee Proceedings-Vision Image and Signal Processing, 
vol. 150, no. 3, pp. 153-158, 2003. 
6. H. Chen, P. C. D. Fleury, and A. F. Murray, "Continuous-valued probabilistic behavior in a 
VLSI generative model," Neural Networks, IEEE Transactions on, vol. 17, no. 3, pp. 755-
770, 2006. 
7. Chen, H., Fleury, P., and Murray, A.F., "Minimizing Contrastive Divergence in Noisy, 
Mixed-mode VLSI Neurons, " in Advances in Neural Information Processing Systems 
(NIPS*2003), Camgridge, MA: MIT Press, 2004. 
8. Lu, C. C., Hong, C. Y., and Chen, H., "A Scalable and Programmable Architecture for the 
Continuous Restricted Boltzmann Machine in VLSI," 2007. IEEE International Symposium 
on Circuits and Systems. 
9. Cauwenberghs, G., "An Analog VLSI Recurrent Neural Network Learning a Continuous-
Time Trajectory," IEEE Transactions on Neural Networks, vol. 7, no. 2, pp. 346-361, 
Mar.2003. 
國科會計畫補助國內專家學者出席國際學術會議報告 
                                                             年    月    日 
報告人姓名 
 
陳  新 
 
服務機構 
及職稱 
 
清大電子所   助理教授 
 
計畫名稱 
適於辨識高維時變生醫訊號之
隨機晶片系統研發 
 
會議時間 2010.07.18~2010.07.23 
會議地點 Barcelona, Spain 
會議名稱 
 (中文) IEEE 2010 年智慧演算法世界年會 
 (英文) IEEE Word Congress on Computational Intelligence 2010 
發表論文 
題目 
 (中文) 將擴散網路實現成一積體電路隨機系統 
 (英文) Mapping the Diffusion Network into a Stochastic System in Very 
Large Scale Integration 
 
(a)
(b)
xi
xj
w ijw ji
w jj
wii
s1
w1i
w2i
I in
I
noise
w ji
s2
s j
x i
si
C iR iV REF
CC II
in out
r
Fig. 1. (a)The diagram of a DN with one visible (white-coloured) and
three hidden(grey-coloured) units. (b)The circuit architecture of a stochastic
unit in the DN.
at visible neurons and the dynamics of training data then
indicate how well the data are modelled.
III. MAPPING THE DIFFUSION NETWORK INTO VLSI
A. Circuit architecture
The stochastic unit of the DN can be translated into
the equivalent-circuit model in Fig.1b The resistor and the
capacitor correspond to Ri and Ci in (2), respectively, and the
voltage at node xi represent the state of the stochastic unit.
The multipliers calculate wij · sj and output a total current
Iin proportional to
∑
j wijsj(t). Iin and the noise current
Inoise are then summed up and buffered to Ri and Ci by
the class II current conveyor [9], producing the stochastic
dynamics at xi according to (1). Finally, passing xi through
the sigmoid circuit gives si for the inputs of all stochastic
units.
B. Adapting wij and Ri only
The simulation in [2] shows that adapting wij and Ci
is sufficient for modelling various types of data. However,
a variable resistor is easier to implement in VLSI than a
variable capacitor. Fig.1b indicates that Ci and Ri cooperate
to determine the “time constant” of the stochastic dynamics
of each unit. The feasibility of modelling different data by
adapting wij and Ri only is thus investigated.
Following [2], Ci = 1 and ∆t = 0.05 were used for
discrete-time iteration of (1) in Matlab, and the DN was
trained to model different types of data with their dynamic
ranges normalised into [−2, 2]. A DN with one visible and
0 20 40 60 80 100 120 140 160 180 200
−3
−2
−1
0
1
2
3
v
1
time
Fig. 2. The four bifurcating training data (black dashed lines) and 50
sequences (grey curves) regenerated by the DN after 100 training epochs.
ai = 3 and σ = 0.1 for all units. The numerical values of the horizontal
axis correspond to the indexes of discrete-time samples, and the same
representation is employed in Fig.3-Fig.5
0 20 40 60 80
−2
−1
0
1
2
time
v
1
Fig. 3. 10 normal heartbeats (black curves) and 50 sequences (gray curves)
regenerated by the DN after 100 training epochs. ai = 2 and σ = 0.1 for
all units.
0 0.5 1 1.5
0
0.5
1
1.5
2
v1
v
2
−2 −1 0 1 2
−2
−1
0
1
2
v1
v
2
Fig. 4. (a)The spiral curve and (b) the handwritten ρ (black dashed lines)
for training the DN. The gray curves in each subplot are 50 sequences
regenerated by the DN after 120 training epochs. ai = 0.8 and σ = 0.01
for modelling (a), while ai = 0.5 and σ = 0.04 for modelling (b).
0 50 100 150 200 250
−2
0
2
v
1
0 50 100 150 200 250
−2
0
2
v
1
(a)time
time
(b)
Fig. 5. The sinusoidal waves (black dashed lines) with frequency (a)f0
and (b)10f0. The gray curves in each subplot are 50 sequences regenerated
by the DN after 100 training epochs. ai = 1 and σ = 0.05 for all units.
Moreover, the mappings of Ci and Ri depend on the unit
values of xi, Iin, and ∆t. According to (2), Ri = 1 and
xi = 1 result in xi/Ri = 1, corresponding to a unit current of
Iunit = 660nA/30 = 22nA at node xi in Fig.1b. As the unit
voltage for xi is Vunit = 0.6V/3 = 0.2 (Table.I), the unit
value of Ri simply equals Runit = Vunit/Iunit ≈ 9.1MΩ.
Multiplying the unit resistance with the numerical ranges
of Ri gives its dynamic range required in VLSI. Similarly,
the unit value of Ci is calculated as Iunit ·∆tunit/Vunit =
11pF , with tunit = 5µs/0.05 = 100µs. Multiplying the
unit capacitance with numerical ranges of Ci then gives its
dynamic ranges in VLSI.
For σ, the noise term in (1) introduces a change of
dxi = σ · z ·
√
dt in discrete-time simulation (z represents an
unit Gaussian). The noise current required to cause the same
amount of dxi is given as
in =
Ci · dxi
dt
=
Ci · σ · z
√
dt
(3)
Substituting the maximum of z = 3, dt = 0.05 and Ci =
1 then gives the numerical relationship between in and σ.
Multiplying in with Iunit then gives the mapping of σ.
IV. VLSI DESIGN OF THE STOCHASTIC UNIT
The current-mode, four-quadrant multiplier proposed in
[10] is employed to calculate wij · sj . Fig.6a shows the
multiplier basing on the current squarers formed by M1-M10.
I2, I3, and I4 are proportional to the square of (Ix+Iy), Ix,
and Iy , respectively [10]. The current mirrors M11-M20 then
calculate I1+I2−I3−I4, resulting in Iout = Ix ·Iy/4Ib1. The
relationship holds as long as |Ix + Iy | < 4Ib1. Fig.6b shows
the simulation result, indicating that the dynamic ranges
defined in Table.I are met with negligible nonlinearity.
As shown in Fig.7a, the active resistor proposed in [11]
is adopted to implement Ri. Let R represent the resis-
tance between ground and V1 or V2. The resistance is
tunable through Itune. Transistors Mn1-Mn8 and Mp1-Mp8
form four cascode current mirrors, resulting in an effective
resistance of 2R between the nodes Vx and Vy . Fig.7b
shows the simulated relationship between Itune and 1/Ri,
demonstrating the required dynamic range is achieved. For
the sigmoid function, the voltage xi is first converted by the
voltage-to-current(VI) converter in Fig.8a, and then delivered
to the inputs of the current-mode sigmoid circuit in Fig.8b
[12]. The VI conversion is simply achieved by operating
M1 in triode region, and the operating mode is set by Vc
which defines the drain voltage of M1. The converted current
is then replicated by current mirrors and subtracted from
a reference current to produce differential input currents
(Ix+andIx−) for the sigmoid circuit. Let Itune = kIB and
Ix+−Ix− = xWIB with W = (Ix++Ix−)−1 in the sigmoid
circuit. Transistors Ms1-Ms4 operate in the subthreshold
region, forming a translinear loop that produces a differential
current I2 − I1 = xW2kIB . Transistors Ms12-M21 and
M25-M26 further form translinear loops by operating in the
Mp5
VDD
Mn5
Mn1
Mn6
Mn2
Mp1
Itune
Mp6
Mp2
Mp7
Mp3
Mp8
Mp4
Mn7
Mn3
Mn8
Mn4
Vx Vy
Iin Iout
M1 M2
Vb1
Vb2M3
V1 V2
(a)
0 1 2 3 4
0.5
1.0
1.5
2.0
 
 
1
/
R
i
Itune ( A)
(b)
Fig. 7. (a)The tunable active resistor (b)The simulated relationship between
1/Ri and Itune.
subthreshold region, resulting in
Is+ − Is− =IB · f(x)
=IB ·
xWk
(xWk)2 + 2
√
(xWk)2 + 4 (4)
where f(x) approximates tanh(ai · xi) in (2) and k cor-
responds to ai, adapting the slope of f(x). Fig.9a shows
the simulated input-output relationship of the sigmoid circuit
connected with the V-I converter. The relationship between
Itune and ai is further derived and shown in Fig.9b. Finally,
the noise generator is implemented by the analogue random
vector generator basing on cellular automata [13].
V. THE DIFFUSION NETWORK IN VLSI
The designed VLSI stochastic units are interconnected to
form a DN system and simulated with HSPICE. To facilitate
the comparison between VLSI and Matlab simulation, the
same noise sequence is employed in both simulations during
the generation of specific stochastic dynamics. With one vis-
ible and one hidden neurons, the DN system can regenerate
the bifurcating dynamics as shown by the black curves in
Fig.10a, agreeing with the Matlab simulation (grey curves)
Fig. 11. The VLSI system of the Diffusion Network. The chip area is
3.5× 3.5mm2 .
satisfactorily. With two visible and five hidden neurons,
the DN system can be further programmed to generate the
hand-written ρ, as shown by Fig.10c. The promising results
demonstrate the satisfactory mapping of the DN model into
VLSI circuits. A chip containing a DN of seven neurons is
thus fabricated with the TSMC 0.35 µm CMOS technology.
The measurement results will be presented in the conference.
VI. CONCLUSION
With extensive simulation, the dynamic ranges of the
parameters of the DN have been identified and mapped into
VLSI. This underpins the realisation of the DN with analogue
VLSI circuits. A DN system in VLSI has thus been designed
and fabricated. The circuit simulation demonstrates that the
DN model has been mapped into a stochastic VLSI system
satisfactorily. Based on the DN theory, the VLSI system
with noise-induced stochasticity will be able to adapt its
stochastic dynamics towards modelling various continuous-
time, continuous-valued data. This capability makes it a
potential solution for recognising high-dimensional, time-
varying biomedical signals in implantable microsystems.
Therefore, the DN system’s ability to model and to classify
biomedical data such as electrocardiograms or neural activity
will be tested and reported in the future. To enhance the
flexibility in real biomedical applications, a size-scalable DN
system with easily-programmable parameters will also be
developed.
APPENDIX : THE MONTE-CARLO EM ALGORITHM
To train a DN with n visible and m hidden units, the
dynamics of visible units are forced to follow the desired
sequences (training data), while the corresponding dynamics
of hidden units are sampled, in accordance with (1) and (2),
for l times. Let xli(t) : [0, T ] → R denote the l-th sampled
dynamics of the unit i. A weighting factor proportional to
the likelihood of the l-th Monte-Carlo sample is calculated
according to
pi(l) = exp{
1
σ
2
n∑
i=1
∫ T
0
µi(t)dxi(t)
−
1
2σ2
n∑
i=1
∫ T
0
µi(t)
2
dt} (5)
To obtain the maximum-likelihood estimate of the connection
matrix wˆ = {wij}, the aˆ and bˆ matrixes are first computed
for each Monte-Carlo sample according to
aij(l) =
∫ T
0
ϕ(xli(t))ϕ(x
l
j(t))dt, (6)
bij(l) =Cj
∫ T
0
ϕ(xli(t))dx
l
j(t)
+
1
Rj
∫ T
0
ϕ(xli(t))x
l
j(t)dt, (7)
where ϕ(·) represents the sigmoid function. The connection
matrix is then estimated as wˆ = a¯−1b¯ with a¯ and b¯ given
in (8) and (9), respectively.
a¯ =
∑m
l=1 pi(l)
ˆ
a(l)∑m
l=1 pi(l)
, (8)
b¯ =
∑m
l=1 pi(l)
ˆ
b(l)∑m
l=1 pi(l)
, (9)
On the other hand, the maximum likelihood estimates for Ci
and Ri are calculated for each Monte-Carlo sample according
to (10) and (11), respectively.
Cˆi =
Ci
∫ T
0
µ
l
i(t)
2
dt∫ T
0
µ
l
i(t)dx
l
i(t)
(10)
Rˆi =
∫ T
0
x
l
i(t)
2
dt∫ T
0
∑n
j=1 ϕ(x
l
j(t))wijx
l
i(t)dt− Ci
∫ T
0
x
l
i(t)dx
l
i(t)(11)
The opinions of the l estimates for Ri and Ci are also
weighted by pi(l) to obtain their optimum estimates.
ACKNOWLEDGMENTS
The authors would like to devote their greatest thanks
to the National Science Council in Taiwan for funding this
project (NSC 96-2221-E-007-167-MY3).
REFERENCES
[1] J. R. Movellan, “A learning theorem for networks at detailed stochastic
equilibrium,” Neural Computation, vol. 10, no. 5, pp. 1157–1178,
1998.
[2] J. R. Movellan, P. Mineiro, and R. J. Williams, “A Monte-Carlo
EM approach for partially observable diffusion processes: Theory and
applications to neural networks,” Neural Computation, vol. 14, no. 7,
pp. 1507–1544, 2002.
[3] H. Chen and A. F. Murray, “A continuous restricted boltzmann
machine with an implementable training algorithm,” IEE Proceedings
of Vision, Image and Signal Processing, vol. 150, no. 3, pp. 153–158,
2003.
[4] D. Specht, “Probabilistic neural networks,” Neural Networks, vol. 3,
no. *, pp. 109–118, 1990.
國科會補助計畫衍生研發成果推廣資料表
日期:2010/11/25
國科會補助計畫
計畫名稱: 適於辨識高維時變生醫訊號之隨機晶片系統研發
計畫主持人: 陳新
計畫編號: 96-2221-E-007-167-MY3 學門領域: 積體電路及系統設計 
研發成果名稱
(中文) 具增強的、可調適的低頻雜訊之多閘極場效電晶體
(英文) Multi-gate Field-effect Transistors with Enhanced and Adaptable Low-frequency Noise
成果歸屬機構
國立清華大學 發明人
(創作人)
陳新,邱當榮,龔正
技術說明
(中文) 當半導體技術朝向縮小電晶體尺寸，導致電晶體雜訊大幅增加，因而劣化積體電
路的準確性及可靠性，於是有許多技巧提出以抑制電晶體雜訊。但是相反地，也
已經發現電晶體雜訊在許多應用上是有用的，例如用於資料加密、生物啟發運算
的擾動學習、推測演算法、概率化模型等，也已經有使用具增強雜訊功能的電晶
體的演算法架構被提出來。以硬體實現這些應用通常需要多通道無關聯性的雜訊。
現有的方法包括使用氮化矽介電層以增加界面陷阱及縮小電晶體的尺寸使其具有
單一氧化物陷阱。然而這些方法只是將雜訊增強到可用的程度，未能控制精確的
雜訊準位。 
 
本發明係關於一種場效電晶體(FET)，特別是有關一種具增強的、可調適的低頻
雜訊之場效電晶體。 
本發明的目的之一，在於提出一種具增強的低頻雜訊之FET。 
本發明的目的之一，在於提出一種具可調適的低頻雜訊之FET。 
本發明的目的之一，在於提出一種相容於標準CMOS邏輯製程之具增強的低頻雜訊
之FET。 
一種根據本發明的FET，在STI上有額外的閘極以增強及調適STI-矽界面引發的低
頻雜訊。 
藉由改變該STI閘極的電壓，該FET可調適的低頻雜訊超過萬倍。
(英文) As the low-frequency noise of a transistor grows non-negligible in advanced 
technologies, the possibility of using noise for computation is becoming an alternative, 
receiving more and more attention. The ability to control the noise level would further 
enrich the flexibility of the circuit design. Therefore, this patent presents a dual-gate, 
field-effect transistor in an octagonal shape. By changing the voltage of an extra gate 
above the shallow trench isolation, the transistor is able to adapt its low-frequency noise 
over several decades and in a power-efficient manner. The octagonal geometry further 
makes sufficient a voltage range from 0V to 5V for the noise adaptation. Moreover, the 
transistor is fabricated with the standard CMOS logic process without additional masks. 
All the features underpin the development of large-scale noisy computation in integrated 
circuits.
產業別 電機及電子機械器材業
技術/產品應用範圍 通訊系統資料加密、生物啟發運算的擾動學習、推測演算法、概率化模型等
技術移轉可行性及
預期效益
可技轉先進製程的元件設計與積體電路設計公司，將提供一種有效的電晶體雜訊控制與
運用技術。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
申請中件數 2 0 100% 
1.Multi-gate 
Field-effect 
Transistors with 
Enhanced and 
Adaptable 
Low-frequency 
Noise 
2.Drain-shifted 
Field-effect 
Transistors with 
Enhanced and 
Adaptable 
Low-frequency 
Noise 
專利 
已獲得件數 1 0 100% 
件 
Nonvolitile 
Analogue Memory, 
26576-US-PA-1 
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1.於 2009 年 5 月 20-21 日主辦仿神經系統與神經復健輔具國際研討會
(http://neuron.ee.nthu.edu.tw/)，並擔任其中一位講員發表隨機晶片研發成
果 
2.於 2008年 6-10 月訪問法國波爾多大學，以雜訊造成隨機行為之技術，應用
在仿神經晶片系統，驗證以晶片系統模擬生物神經細胞行為的可行性與優點，
成果發表於 IEEE Trans. on Neural Networks 
3.於 2008.01-2010.10 執行台法幽蘭計畫，將隨機晶片系統應用於腦機介面的
神經訊號辨識，成果已投稿 IEEE Trans. on Neural Networks，並準備提台法
合作計畫，研發智慧型腦機界面。 
4/於 2010 年 11 月 10-12 日主辦仿生系統與復健輔具國際研討會
(http://biopro2010.ee.nthu.edu.tw/)， 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
