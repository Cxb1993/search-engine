 1 
具物體追蹤、鏡頭變焦與影像重點擷取功能之智慧型人車監
控系統研究 
Intelligent visual surveillance system of vehicles and people by 
integrating object tracking, zooming, and image region capture 
計畫編號：NSC 95-2221-E-155 -028 
執行期限：95年 8月 1日 至 96年 7月 31日 
主持人：李建誠    元智大學通訊工程學系 
 
中文摘要 
本計畫之目的在於提出一種利用具有可控制攝影機的監控系統來擷取人的臉部特
寫。在現今已知的監控系統中，大部份都是拍攝固定區域，而且只單純追蹤影像中人物的
軌跡或者是抓取影像中的人臉；但是當人物距離攝影機較遠的時候，就無法獲得更仔細的
資訊。本計畫利用離散小波轉換來去除雜訊及增進計算效能，並以背景相減及邏輯 AND
運算的方式來取得移動區域，接著使用膚色偵測來過濾出人體區域。藉由人體區域可以計
算出移動向量，然後再根據移動向量的方向來預測人物下一步會到達的位置，並且依據移
動向量的大小來設定攝影機的旋轉速度，以達到控制攝影機來拍攝臉部特寫的目的。 
 
關鍵詞: 可控制攝影機、監控系統、小波轉換、背景模型 
 
Abstract 
A surveillance system with controllable video camera is presented to obtain the close-up of 
the human face. The discrete wavelet transform is used to reduce the effect of the noise of the 
video camera and improve the computational efficiency. Then the moving regions are detected by 
the background subtraction and the logic AND operation. Hence the regions including the 
human body are derived from the moving regions by detecting the skin color, and those are used 
to calculate the motion vectors. Then the direction of the motion vector is used to control the 
panning and the tilting directions of the video camera and its norm is adopted to set the speed 
parameters of the panning and the tilting of the video camera. In this way, we can obtain the 
close-up of the human face by the zooming of the video camera.   
 
Keywords: surveillance, background model, wavelet, PTZ camera. 
 
一. 前言與目的 
近年來，監控攝影機廣泛地裝設於各大街小巷、大樓及重要公共設施中，其不僅是人員
進出管制的一項重要工具，也是嚇阻犯罪的重要利器之一。然而，傳統視訊監控系統必須
仰賴人力，在控制中心以緊盯螢幕的方式進行視訊監控，主要提供拍攝及錄影功能，攝影
 3 
界影像微小變化的干擾，例如：光影所造成的變化。 
從攝影機所獲得的來源影像是屬於 RGB 色彩空間 (RGB color space)。由於
RGB 色彩空間具有三個成份，因此為了減少在主要程序時所需要處理影像的資料
量，我們希望將 R、G及 B三個成份轉化成一個成份。而在轉換之後，雖然僅剩下
一個成份，但此一個成份卻有足夠資訊來做後續程序的處理。在此，我們將 RGB
色彩空間分別轉換成 YUV色彩空間 (YUV color space)。 
 
去除雜訊 
當來源影像轉為 YUV 色彩空間之後，為了避免雜訊對後續處理造成干擾，因
此需要對 Y 成份進行去除雜訊的步驟。為了簡化後續計算的考量，我們選擇了離
散小波轉換[7]。離散小波轉換的主要目的是在於分解影像，而且分解出來的影像
可以提供一個跟原來影像相似但尺寸較小的影像。藉由經過二次離散小波轉換所得
到的低頻部份除了用來除去影響影像之攝影機及外界的雜訊之外，還可以用來減少
後續處理所需花費的時間以增進系統的效能。 
 
偵測移動區域 
背景相減 (background subtraction) [8]方法主要是應用在分割出前景的部
份；會被經常使用在即時監控系統裡的原因，就是在於它不需要花費太多的計算時
間。因此，在本計畫中，背景相減方法被應用於如何找出移動區域 (moving region)。
背景影像的建立是利用系統剛開始，沒有任何人在畫面中的時候，所取得的畫面做
為系統初始的背景影像；接著利用接下來的畫面來做背景更新，背景更新方法我們
採用 Two level background maintenance algorithm的方法。 
整個偵測移動區域的流程如圖二所示。首先，先找出空間差異影像 (spatial 
difference image) 及時間差異影像 (time difference image) 以便消除目前畫面中靜
止物體的區域。所謂空間差異影像 SD 指的是目前影像 (current image) 與背景影像 
(background image) 的差值 (difference) 經過二值化 (Binary threshold) 之後的結
果，其數學式表示如下： 
 


 >−
=
.,0
),(),(,1
),(
otherwise
ThyxCyxBif
yxSD
D  ,    (1) 
其中 B(x, y) 是背景影像中在 x, y 位置的像素值，C(x, y) 是目前影像中在 x, y 位置
的像素值，以及 ThD是二值化時的臨界值 (binary threshold value)。取得此張影像的
目的是希望可以獲得在影像中可能是移動物體的完整獨立區域。利用背景相減法所
求得的差異值所形成的區域，也有可能是物體在畫面中只靜止了一小段時間，但是
在原來的背景中並沒有出現，因而被分割出來成為可能移動物體的區域。因此，當
獲得空間差異影像 SD 之後，將影像中的各個獨立的區域都給予一個編號，以方便
我們接下來為了要獲得確定的完整移動區域時，所需討論的依據。 
 
 5 
在影像 R 中，所獲得的區域雖然是具有移動性質的區域，但都只是部份區域
或是零散的區域。為了能夠獲得確切的完整區域，因此需要與先前所獲得的空間差
異影像 SD 相結合。如圖三所示，如果影像 SD 中的某一個區域，其在影像 R 中的
同一範圍內，如果存在著移動的區域，則在影像 SD中的該區域會被辨識為移動區
域。為了避免所找出來的區域是由於畫面中部份區域的光影變化所引起的，因此設
定了一個區域大小的臨界值 ThA；如果影像 SD 的該區域在影像 R 中同一範圍內的
區域大小總和大於一個臨界值 ThA時，則在影像 SD 中的該區域才會被辨識為移動
區域，否則將會把此區域去除掉，並且將此區域的編號消除。 
 
 
圖三、獲得完整移動區域示意圖 
 
另外，如圖四所示，當存在著兩個以上的區域時，由於之前在取得影像 SD
的時候已經先將所獲得的各個區域標上編號，因此這時候只要根據先前的編號，就
可以個別地去討論各個區域範圍內所取得的區域大小，來決定是否留下該區域，並
且取消非移動區域的編號。當影像 SD 中所有的區域都檢查過了後，接著將所有的
區域重新進行編號，以統計出在影像 SD 中移動區域的個數。 
 
 
圖四、兩個移動區域以上的判斷方式 
 
偵測膚色區域 
偵測人體區域之目的在於找出具有人體正面的區域。獲得人體區域的方法就
是去找尋具有膚色的區域，而為了減少計算上的負擔，僅在移動區域內執行搜尋的
動作。偵測膚色的方法有兩種；一種是在一般強度的日光照射下，另一種則是在強
 7 
x
y
 
圖六、攝影機的八個方向 
 
 
圖七、移動向量大小與速度參數對應圖 
 
追蹤及拍攝特寫 
將人體區域置中之後，繼續追蹤人體區域直到拍攝的動作完成。這時，移動
向量 (mvt) 則是使用相鄰兩張影像的人體區域中心所計算出來的。計算 motion 
vector的方法是類似於 mpeg4中，在處理 motion compensation時找尋 motion vector
的方法，如圖八中所示。在圖八中，我們在目標畫面 (target frame) 中的人體區域
部份，在重心的位置選擇了一個 macroblock，接著在參考畫面 (reference frame) 中
的搜尋視窗內找尋差異值最小的 matched macroblock。在圖九中，利用 macroblock
與 matched macroblock 的重心位置，可以算得移動向量 mvt，獲得移動向量 mvt之
後，利用移動向量 mvc 計算θ及 norm 的方式來獲得控制攝影機時所需的方向及速
度參數。利用獲得的方向及速度，我們可以讓攝影機提前到移動人物的下一個位置
去執行鏡頭拉近以拍攝特寫。 
 
 9 
四、計畫成果自評 
目前我們已完成此計畫中規劃的人臉追蹤、鏡頭移動、變焦、與自動人臉畫面擷取，
並著手設計改善正確率與偵測系統對於人臉側面的辨識能力。本研究結果也整理成論文發
表在於 CVGIP 會議中[11]。 
 
參考文獻 
[1] T. Yang, S. Z. Li, Q. Pan, and J. Li, “Real-time multiple objects tracking with occlusion 
handling in dynamic scenes,” in Proc. IEEE Computer Society Conf. Computer Vision and 
Pattern Recognition, 20-25 June 2005, pp. 970-975. 
[2] D. Comaniciu, V. Ramesh, and P. Meer, “Real-time tracking of non-rigid objects using mean 
shift,” in Proc. IEEE Computer Society Conf. Computer Vision and Pattern Recognition. 
2000, pp. 142-149. 
[3] J. S. C. Yuk, K. K. Y. Wong, R. H. Y. Chung, F. Y. L. Chin, and K. P. Chow, “Real-time 
multiple head shape detection and tracking system with decentralized trackers,” in Proc. 
Sixth Int. Conf. Intelligent Systems Design and Applications, Oct. 2006, pp. 384-389. 
[4] J. Zhou and J. Hoang, “Real time robust human detection and tracking system,” in Proc. 
IEEE Computer Society Conf. Computer Vision and Pattern Recognition, 20-26 June 2005, 
pp. 149-149. 
[5] Y. Wei, and W. Badawy, “A novel zoom invariant video object tracking algorithm 
(ZIVOTA),” IEEE CCECE 2003. Canadian Conference on Electrical and Computer 
Engineering, 4-7 May 2003, pp. 1191 – 1194. 
[6] S. Ribarić, G. Adrinek, and S. Šegvić, “Real-time active visual tracking system,” in Proc. 
12th IEEE MELECON, Dubrovnik, Croatia, 12-15 May 2004, pp. 231 – 234. 
[7] F. H. Cheng, and Y. L. Chen, “Real time multiple objects tracking and identification based 
on discrete wavelet transform,” Pattern Recognition, vol. 39, issue 6, pp. 1126-1139, 2006. 
[8] N. Amamoto and A. Fujii, “Detecting obstructions and tracking moving objects by image 
processing technique,” Electronics and Comm. in Japan, Part 3, vol. 82, no. 11, pp. 28-37, 
1999. 
[9] J. Kovač, P. Peter, and F. Solina, “Human skin colour clustering for face detection,” 
EUROCON 2003. Computer as a Tool, 22-24 Sept. 2003, pp. 144-148. 
[10] H. Yoon, D. Kim, S. Chi, and Y. Cho, “A robust human head detection method for human 
tracking,” IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct. 2006, 
pp. 4558-4563. 
[11] Chien-Cheng Lee and Shan-Ho Yang, ”A human-face surveillance system with close-up 
pictures capturing,” in Proceeding of 2007 Computer Vision, Graphics and Image 
Processing Conference (CVGIP 2007), Miaoli, Taiwan, Aug. 19-21, 2007, pp.328-332. 
 
