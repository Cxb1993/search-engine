 2
行政院國家科學委員會專題研究計畫成果報告 
隱藏約束型關聯規則集之有效率維護之研究 
A Study of Efficient Maintenance of Hiding Constrained Association Rule Sets 
計畫編號：NSC  97－2221－E －390－021－ 
執行期間：97 年 8 月 1 日至 98 年 7 月 31 日 
計畫主持人： 王學亮教授  執行機構：高雄大學資管系 
E-mail: slwang@nuk.edu.tw 
 
 
Abstract 
 
The goal of this project is to develop a set 
of hiding techniques of constrained 
association rule sets when the database is 
updated.  As such, we proposed two 
algorithms, namely SIU for the 
maintenance of sanitizing informative 
association rules and MSCR for the 
maintenance of sanitizing collaborative 
recommendation association rules. 
Various characteristics of the proposed 
algorithms are analyzed.  Numerical 
experiments and running time analyses 
show that the proposed approach out 
performs the direct sanitization approach 
on original and added data sets, with 
similar side effects.  The proposed work 
has been published in both SCI indexed 
journal and international conference. 
 
Keywords: data mining, privacy 
preserving, constrained association rules, 
incremental hiding 
 
摘要 
 
本研究計畫之目的在於，針對資料庫資
料微量增加時，發展出一套有效率之隱
藏約束型(constrained)關聯規則集之
技術，以便及時的維護資料及知識之隱
私性並提昇資訊之安全性。研究結果顯
示，針對集中式資料庫，當各式資料分
別微量增加時，我們提出兩個有效率的
演算法分別隱藏翔實關聯規則集
(informative association rule set)
及協作推薦關聯規則集(collaborative 
recommendation association rule 
set)。數值實驗顯示，我們的演算法比
原有之直接隱藏演算法速度更快，且具
類似之副作用。我們的研究結果已發表
於 SCI 國際期刊及研討會。 
 
關鍵詞：資料探勘、隱私保護、約束型
關聯規則、漸增式之隱藏 
 
Introduction 
In the past decade, data mining has 
developed into an important technology 
of identifying patterns and trends from 
large quantities of data.  Successful 
applications of data mining have been 
demonstrated in marketing, business, 
medical analysis, product control, 
engineering design and scientific 
exploration, among others.  While all of 
these applications of data mining can 
benefit commercial, social and human 
activities, there is also a negative side to 
this technology: the threat to data privacy.  
For example, through data mining, one is 
able to infer sensitive information, 
including personal information, or even 
patterns from non-sensitive information or 
unclassified data. 
 
 4
utilizing the information from the old 
sanitization process, are quite desirable. 
 
In this work, we propose using pattern 
inversion tree to store the added data set 
in one database scan.  It is then sanitized 
and merged to the original sanitized 
database.  Numerical experiments show 
that the proposed approach out performs 
the direct sanitization on original and 
added data sets, with similar side effects. 
 
Problem Statement 
Informative Association Rule Sets 
 The problem of mining association rules 
was introduced in [2]. Let 
}   ,,  , { 21 miiiI   be a set of literals, 
called items.  Given a set of transactions 
D, where each transaction T  in D is a 
set of items such that ,IT   an 
association rule is an expression YX   
where ,IX   ,IY   and .YX   
The X and Y  are called respectively the 
body (left hand side) and head (right hand 
side) of the rule.  An example of such a 
rule is that 90% of customers buy 
hamburgers also buy Coke.  The 90% 
here is called the confidence of the rule, 
which means that 90% of transaction that 
contains X  (hamburgers) also contains Y 
(Coke).  The confidence is calculated as 
|||| XYX  , where |X| is the number of 
transactions containing X and |XY| is the 
number of transactions containing both X 
and Y.  The support of the rule is the 
percentage of transactions that contain 
both X and Y, which is calculated as 
NYX ||  , where N is the number of 
transactions in D.  In other words, the 
confidence of a rule measures the degree 
of the correlation between itemsets, while 
the support of a rule measures the 
significance of the correlation between 
itemsets.  The problem of mining 
association rules is to find all rules that 
are greater than the user-specified 
minimum support and minimum 
confidence. 
 
 As an example, for a given database in 
Table 1, a minimum support of 33% and a 
minimum confidence of 70%, nine 
association rules can be found as follows: 
B=>A (66%, 100%), C=>A (66%, 100%), 
B=>C (50%, 75%), C=>B (50%, 75%), 
AB=>C (50%, 75%), AC=>B (50%, 75%), 
BC=>A(50%, 100%), C=>AB(50%, 75%), 
B=>AC(50%, 75%), where the 
percentages inside the parentheses are 
supports and confidences respectively. 
Table 1: Database D 
TID Items 
T1 ABC 
T2 ABC 
T3 ABC 
T4 AB 
T5 A 
T6 AC 
 
However, mining association rules 
usually generates a large number of rules, 
most of which are unnecessary for the 
purpose of prediction.  For example, 
given predicting itemset P = {C} for 
prediction, the rule set that contains only 
two rules C=>A (66%, 100%), C=>B 
(50%, 75%), will generate the same 
predicted itemset Q = {A, B} as the nine 
association rules found from Table 1.  
Therefore, an informative association rule 
set [16] can be informally defined as the 
smallest association rule set that makes 
the same prediction as the entire 
association rule set by confidence 
priority.  
 
Formally, given an association rule set 
R and a predicting itemset P, we say that 
the prediction for P from R is a sequence 
 6
following rule containing item C on the 
left hand side will be hidden: C=>A (44%, 
66%).  However, two new rules are 
generated A=>B (77%, 71%) and AC=>B 
(33%, 75%).  There is no hiding failure 
and no lost rule. 
Proposed algorithm 
 In order to hide an association rule, 
X=>Y, we can either decrease its supports, 
( NX || or NYX ||  ), to be smaller 
than pre-specified minimum support or its 
confidence ( |||| XYX  ) to be smaller 
than pre-specified minimum confidence.  
To decrease the confidence of a rule, two 
strategies can be considered.  The first 
strategy is to increase the support count of 
X, i.e., the left hand side of the rule, but 
not support count of X  Y.  The second 
strategy is to decrease the support count 
of the itemset X  Y.  For the second 
strategy, there are in fact two options.  
One option is to lower he support count of 
the itemset X  Y so that it is smaller than 
pre-defined minimum support count.   
The other option is to lower the support 
count of the itemset X  Y so that 
|||| XYX   is smaller than pre-defined 
minimum confidence.  In addition, in the 
transactions containing both X and Y, if 
we decrease the support of Y only, the 
right hand side of the rule, it would 
reduce the confidence faster than reducing 
the support of X.  In fact, we can 
pre-calculate the number of transactions 
required to hide the rule.  If there are not 
enough transactions exist, then the rule 
cannot be hidden.  To decrease support 
count of an item, we will remove one item 
at a time in a selected transaction by 
changing from 1 to 0.  To increase the 
support count of an item, we will add one 
item by changing from 0 to 1.  We will 
adopt the second strategy of decreasing 
the support count of the itemset X  Y, i.e., 
sanitize the transactions that contain the 
itemset X  Y. 
 
 In order to hide informative association 
rules, we will consider hiding association 
rules with 2 items, x=>z, where x is a 
predicting item and z is a single large 
one-item.  In theory, informative rules 
may have more specific rules that contain 
more items, e.g., xY => z, where Y is a 
large itemset.   However, for such rule 
to exist, its confidence must be greater 
than the confidence of x=>z, i.e., 
conf(xY=>z) > conf(x=>z) or |xYz| > 
conf(x=>z) * |xY|.  For higher 
confidence rules, such as conf(x=>z) = 1, 
there will be no more specific rules.  In 
addition, once the more general rule is 
hidden, the more specific rule might be 
hidden as well. 
 
 To reduce the number of database 
scanning in generating large or frequent 
itemsets in association rule mining, a 
one-scan of database method was 
proposed in [14].  The basic idea is to 
construct a tree structure, called Pattern 
tree (P-tree) and a frequency list which 
contains the frequency counts of each 
item in one database scan.  The pattern 
tree is then restructured to a compact 
Frequent-Pattern tree (FP-tree) proposed 
by [13], which can store more information 
in less space.  A FP-tree based pattern 
growth method (FP-growth) is used to 
find all the large tiemsets from the 
FP-tree. 
 
 In [28], we proposed a Pattern-Inversion 
tree (PI-tree) based on the pattern tree to 
sanitize informative association rules with 
one database scan.  A PI-tree is similar 
to a P-tree except the following.  Each 
node in a PI-tree contains three fields: 
item name (or item number), number of 
transactions containing the items on the 
path from the root to current node, and list 
 8
7: Output sanitized database 'D ; 
EXAMPLE 
 Using the same example database D and 
sanitized database D’ with minimum 
support of 33% and minimum confidence 
of 70% in Table 2, when the data set   
shown in Table 3 is added, the result of 
running proposed SIU algorithm is as 
follows.  
 
 In step one, the pattern inversion tree 
PI  for 
  has two branches, root – 
A:3 – C:2:[T7, T8], root – A:3 – B:1:[T9].  
In step two, the sorted frequency list L  
= <(A:3), (C:2), (B:1)> is built.  In step 
3, to hide C=>A (66%, 100%), transaction 
T7 is sanitized from AC to C.  The 
sanitized 'PI  tree has three branches, 
root – A:2 – C:1:[T8], root – A:2 – 
B:1:[T9], and root – C:1:[T7].   In step 4, 
the updated frequency list for D+ is L’ = 
<(A:6), (C:6), (B:4)>.  In step 5, the 
merged PI’ tree has 3 branches, root – 
A:6:[T5] – B:4:[T4,T9] - C:2:[T2, T3], 
root – A:6:[T5] – C:1:[T8], and root – 
C:3:[T1, T6, T7].  In step 6, the 
restructured PI’ tree according to L’ 
remains unchanged.  The sanitized 
database D’ hides C=>A (33%, 50%).  
There are no new rules generated, no 
hiding failure and one lost rule BC=>A 
(22%, 100%). 
Numerical experiments 
In order to better understand the 
characteristics of the proposed SIU 
algorithm numerically, we perform a 
series of experiments to measure various 
effects and compare with the direct 
sanitization DSC algorithm proposed in 
[28].  The following effects are 
considered: time effects, side effects, 
database effects and item ordering effects.  
For time effects, we measure the running 
time required to hide one and two 
predicting items, i.e., one and two 
informative association rule sets 
respectively.  For side effects, we 
measure the hiding failure, new rules 
generated and lost rules.  The hiding 
failure side effect measures the number of 
informative association rules that cannot 
be hidden.  The new rule side effect 
measures the number of new rules 
appeared in the transformed database but 
is not in the original database.  The lost 
rule side effect measures the number of 
rules that are in the original database but 
not in the transformed database.  The 
database effects measure the percentage 
of altered transactions in the database.  
The item order effects examine the 
previous effects when the order of 
predicting item is changed. 
 
The experiments are performed on a PC 
with AMD 1.99 GHz processor and 1 GB 
RAM running on Windows XP operating 
system.  The data sets used are generated 
from IBM synthetic data generator.  The 
sizes of the data sets range from 5K to 
25K transactions with average transaction 
length, |ATL| = 5, and total number of 
items, |I| = 50.  For each data set, various 
sets of association rules are generated 
under various minimum supports and 
minimum confidences.  The minimum 
support range is from 3% to 10%.  The 
minimum confidence range is from 20% 
to 40%.  Total number of association 
rules is from 6 to 178.  The number of 
hidden rules ranges from 3 to 16, which in 
percentage over total association rules is 
from 9% to 66%.  The number of 
predicting items considered here is one 
and two items. 
 
Figure 2 shows the processing times 
required to maintain the sanitized 
informative association rules under 
multiple updates for proposed SIU 
 10
Side Effects DSC
0%
1%
2%
3%
4%
5%
6%
7%
5K 10K 15K 20K
Data Size
P
er
ce
nt
ag
e
Hiding Failure
Lost Rules
New Rules
 
Figure 4 Side Effects for DSC 
Database Effects
0%
2%
4%
6%
8%
10%
10K 15K 20K 25K
Data Size
Pe
rc
en
ta
ge
DSC
SIU
 
Figure 5 Database Effects for SIU and 
DSC 
 
References 
[1] D. Agrawal and C. C. Aggarwal, “On the 
design and quantification of privacy 
preserving data mining algorithms”, In 
Proceedings of the 20th Symposium on 
Principles of Database Systems, Santa 
Barbara, California, USA, May 2001. 
[2] R. Agrawal, T. Imielinski, and A. Swami, 
“Mining Association Rules between Sets of 
Items in Large Databases”, In Proceedings 
of ACM SIGMOD International Conference 
on Management of Data, Washington DC, 
May 1993. 
[3] R. Agrawal and R. Srikant, ”Privacy 
preserving data mining”, In ACM SIGMOD 
Conference on Management of Data, pages 
439–450, Dallas, Texas, May 2000. 
[4] Ljiljana Brankovic and Vladimir 
Estivill-Castro, “Privacy Issues in 
Knowledge Discovery and Data Mining”, 
Australian Institute of Computer Ethics 
Conference, July, 1999, Lilydale.  
[5] C. Clifton and D. Marks, “Security and 
Privacy Implications of Data Mining”, in 
SIGMOD Workshop on Research Issues on 
Data Mining and knowledge Discovery, 
1996. 
[6] C. Clifton, “Protecting Against Data Mining 
Through Samples”, in Proceedings of the 
Thirteenth Annual IFIP WG 11.3 Working 
Conference on Database Security, 1999. 
[7] C. Clifton, “Using Sample Size to Limit 
Exposure to Data Mining”, Journal of 
Computer Security, 8(4), 2000. 
[8] Chris Clifton, Murant Kantarcioglu, 
Xiaodong Lin and Michael Y. Zhu, “ Tools 
for Privacy Preserving Distributed Data 
Mining”, SIGKDD Explorations, 4(2), 1-7, 
Dec. 2002. 
[9] E. Dasseni, V. Verykios, A. Elmagarmid and 
E. Bertino, “Hiding Association Rules by 
Using Confidence and Support” in 
Proceedings of 4th Information Hiding 
Workshop, 369-383, Pittsburgh, PA, 2001.  
[10] A. Evfimievski, R. Srikant, R. Agrawal, and 
J. Gehrke, “Privacy preserving mining of 
association rules”, In Proc. Of the 8th ACM 
SIGKDD Int’l Conference on Knowledge 
Discovery and Data Mining, Edmonton, 
Canada, July 2002. 
[11] Alexandre Evfimievski, “Randomization in 
Privacy Preserving Data Mining”, SIGKDD 
Explorations, 4(2), Issue 2, 43-48, Dec. 
2002. 
[12] Alexandre Evfimievski, Johannes Gehrke 
and Ramakrishnan Srikant, “Limiting 
Privacy Breaches in Privacy Preserving Data 
Mining”, PODS 2003, June 9-12, 2003, San 
Diego, CA. 
[13] H. Huang, X. Wu, and R. Relue, 
“Association Analysis with One Scan of 
Databases”, Proceedings of IEEE 
International Conference on Data Mining,  
Maebashi City, Japan, December, 2002, 
629-632. 
[14] J. Han, J. Pei, and Y. Yin, “Mining Frequent 
Patterns without Candidate Generation”, 
Proceedings of ACM International 
Conference on Management of Data 
(SIGMOD), 2002, 1-12. 
[15] M. Kantarcioglu and C. Clifton, 
“Privacy-preserving distributed mining of 
association rules on horizontally partitioned 
data”, In ACM SIGMOD Workshop on 
Research Issues on Data Mining and 
Knowledge Discovery, June 2002. 
[16] Jiuyong Li, Hong Shen and Rodney Topor, 
“Mining the Smallest Association Rule Set 
for Predictions”, Proceedings of the 2001 
 1
出席國際學術會議心得報告 
 
計畫編號 NSC 97-2221-E-390-021- 
計畫名稱 隱藏約束型關聯規則集之有效率維護之研究 
出國人員姓名 
服務機關及職稱
王學亮 
國立高雄大學資訊管理系教授 
會議時間地點 2008年12月11 - 13日 
Embassy Suites Hotel, San Diego, California, USA 
會議名稱 第七屆國際機器學習與應用研討會 
(The 7th International Conference on Machine Learning 
& Applications) 
發表論文題目 Efficient Hiding of Collaborative Recommendation 
Association Rules with Updates 
 
 
 
 3
Proceeding of the 7th International Conference on Machine Learning & Applications（紙本論文集，
無光碟）. 
 
 
(四)附件 
 
發表論文全文 
 
 5
of hiding collaborative recommendation association 
rules. 
One possible approach to the maintenance problem is to 
re-run the hiding algorithms on the whole updated 
database. However, this approach has some obvious 
disadvantage. All the computation done initially at 
sanitizing the original database is wasted and has to be 
computed again from scratch. Therefore, more efficient 
algorithms for hiding collaborative recommendation 
association rules, utilizing the information from the old 
sanitization process, are quite desirable. 
In this work, we propose using pattern inversion tree to 
store the added data set in one database scan. It is then 
sanitized and merged to the original sanitized database. 
Numerical experiments and running time analyses show 
that the proposed approach out performs the direct 
sanitization on original and added data sets, with similar 
side effects. 
The rest of the paper is organized as follows. Section 2 
presents the statement of the problem and the notation 
used in the paper. Section 3 presents the proposed 
algorithm for the maintenance of sanitizing 
collaborative recommendation association rule sets that 
contain the specified predicting items. Section 4 shows 
an example for the proposed algorithm. Section 5 shows 
the experimental results of the performance and various 
side effects of the proposed algorithm compared with 
direct sanitization approach. Concluding remarks and 
future works are described in section 6. 
 
2. Problem Statement 
 
The problem of mining association rules was introduced 
in [2]. Let },,,{ 21 miiiI   be a set of literals, 
called items. Given a set of transactions D, where each 
transaction T in D is a set of items such that IT  , an 
association rule is an expression YX   where 
IX  , IY  , and YX .  The X and Y 
here are called respectively the body (left hand side) and 
head (right hand side) of the rule.  The confidence is 
calculated as
XYX 
, where 
X
 is the 
number of transactions containing X and 
YX 
 is 
the number of transactions containing both X and Y. The 
support of the rule is the percentage of transactions that 
contain both X and Y, which is calculated as 
NYX 
, where N is the number of transactions in 
D. In other words, the confidence of a rule measures the 
degree of the correlation between itemsets, while the 
support of a rule measures the significance of the 
correlation between itemsets. The problem of mining 
association rules is to find all rules that are greater than 
the user-specified minimum support and minimum 
confidence. 
As an example, for a given database in Table 1, a 
minimum support of 33% and a minimum confidence of 
70%, nine association rules can be found as follows: 
B=>A (66%, 100%) C=>A (66%, 100%), B=>C (50%, 
75%), C=>B (50%, 75%), AB=>C (50%, 75%), AC=>B 
(50%, 75%), BC=>A(50%, 100%), C=>AB(50%, 75%), 
B=>AC(50%, 75%), where the percentages inside the 
parentheses are supports and confidences respectively. 
 
     Table 1: Database D before and after sanitization 
TID D D’ 
T1 ABC AB 
T2 ABC ABC 
T3 ABC ABC  
T4 AB AB 
T5 A A 
T6 AC AC 
However, mining association rules usually generates a 
large number of rules, most of which are unnecessary 
for the purpose of collaborative recommendation. For 
example, to recommend a target item {C} to a customer, 
the collaborative recommendation association rule set 
that contains only two rules, B=>C (50%, 60%), AB=>C 
(50%, 60%), will generate the same recommendations as 
the entire nine association rules found from Table 1. 
This means that if the new customer has shown interests 
in purchasing item {B} or items {AB}, then the 
collaborative recommender will recommend the new 
customer to purchase target item {C}. Therefore, a 
collaborative recommendation association rule set can 
be informally defined as the smallest association rule set 
that makes the same recommendation as the entire 
association rule set by confidence priority. 
Formally, given an association rule set R and a 
predicting itemset P, we say that the collaborative 
recommendation for P from R is a sequence of items Q. 
Using the rules in R in descending order of confidence 
generates the sequence of Q. For each rule r that 
matches P (i.e., for each rule whose antecedent is a 
subset of P), each consequent of r is added to Q. After 
adding a consequence to Q, all rules whose 
consequences are in Q are removed from R. 
The objective of data mining is to extract hidden or 
potentially unknown and interesting rules or patterns 
from databases. However, the objective of privacy 
 7
Pattern tree (P-tree) and a frequency list which contains 
the frequency counts of each item in one database scan. 
The pattern tree is then restructured to a compact 
Frequent-Pattern tree (FP-tree) proposed by [7], which 
is an extended prefix-tree structure for storing 
compressed, crucial information about frequent patterns 
in less space. A FP-tree based pattern growth method 
(FP-growth) is used to find all the large itemsets from 
the FP-tree. 
In [18], we proposed a Pattern-Inversion tree (PI-tree) 
based on the pattern tree to sanitize collaborative 
recommendation association rules with one database 
scan. A PI-tree is similar to a P-tree except the following. 
Each node in a PI-tree contains three fields: item name 
(or item number), number of transactions containing the 
items on the path from the root to current node, and list 
of transaction ID that contains all the items on the path 
from the root to current node. For example, the PI-tree 
for the six transactions in Table 1 is shown in Figure 1. 
The frequency list is L = < (A:6), (B:4), (C:4)>. 
 
Figure 1 Pattern Inversion Tree for Database in Table 1 
To sanitize the collaborative recommendation 
association rules of updated database D+, there are two 
possible approaches as mentioned in section 2. One 
approach is that we can re-run any hiding algorithm on 
the updated database D+ directly. The second approach 
is to process the newly added data set 
  
incrementally and combined it with the sanitized result 
of original database D’. For the second approach, a 
collaborative recommendation association rule in D 
does not have to be a collaborative recommendation 
association rule in 
  or D+, and vice versa. However, 
if all collaborative recommendation association rules in 
D and in 
  are sanitized, then all collaborative 
recommendation association rules are sanitized in the 
updated database D+. We will adopt this strategy to 
sanitize the collaborative recommendation association 
rules in his work. 
Based on the strategies described above, we propose a 
data-mining algorithm called MSCR for the 
maintenance of sanitizing collaborative recommendation 
association rules. The basic steps of the algorithm are 
described as follow. 
Algorithm MSCR 
Input: (1) a sanitized database D (or pattern inversion 
tree 'PI , and frequency list 'L  ) 
(2) min_support  
(3) min_confidence  
(4) a set of hidden items Y 
(5) added data set 
  
Output: a sanitized database 'D  , D+ = D +   , 
where rules containing items of Y on RHS will be 
hidden 
1. Build the Pattern Inversion Tree PI  for   
according to 
'L  and new items in   
2. Sort frequency list L  for   in descending 
order 
3. Sanitize all collaborative recommendation 
association rules of the form: U: yx   in   
according to L  , to obtain 
'
PI  and 
'
L  
4. Build frequency list 'L  for 'D , by adding 
'
L  to 'L  
5. Merge PI-trees 
'
PI  and 'PI  to obtain 'PI  
6. Restructure 
'PI  according to 'L  
7. Output sanitized database 'D  
 
4. Example 
 
Using the same example database D and sanitized 
database D  with minimum support of 33% and 
minimum confidence of 70% in Table 2, when the data 
 9
Database Effects
0%
2%
4%
6%
8%
10%
10k 15K 20K 25K
Data Size
Pe
rc
en
ta
ge
DCBS
MSCR
 
Figure 3 Database Effects for MSCR and DCBS 
Multiple Updates Side Effects
0%
2%
4%
6%
8%
10K 15K 20K 25K
Data Size
Pe
rc
en
ta
ge New Rules
Lost Rules
Hiding Failure
 
Figure 4 Side Effects for MSCR 
DCBS Side Effects
0%
2%
4%
6%
8%
10K 15K 20K 25K
Data Size
Pe
rc
en
ta
ge New Rules
Lost Rules
Hiding Failure
 
Figure 5 Side Effects for DCBS 
 
6. Conclusion 
 
In this work, we have studied the database privacy 
problems caused by data mining technology and 
proposed an efficient data-mining algorithm MSCR to 
maintain sanitized collaborative recommendation 
association rule sets. The proposed algorithm 
incrementally sanitized the added data set and merged 
with the previously sanitized database with one database 
scanning using pattern-inversion trees. Example 
illustrating the proposed algorithm is given. Numerical 
experiments are performed to show the time effects, 
database effects, and side effects of the algorithm and 
compared with direct database sanitization algorithm. In 
addition, running time analysis of the proposed 
algorithm is presented. It can be seen that the proposed 
MSCR algorithm out performs the direct sanitization 
algorithm DCBS in processing time with similar side 
effects. In the future, we will consider the problem of 
efficient maintenance of privacy for other types of rules 
and patterns when databases are updated. In addition, 
the issue of how side effects affect the level of privacy 
will be studied. 
 
7. References 
 
[1] D. Agrawal and C. C. Aggarwal, “On the design 
and quantification of privacy preserving data mining 
algorithms”, In Proceedings of the 20th Symposium on 
Principles of Database Systems, Santa Barbara, 
California, USA, May 2001. 
[2] R. Agrawal, T. Imielinski, and A. Swami, “Mining 
Association Rules between Sets of Items in Large 
Databases”, In Proceedings of ACM SIGMOD 
International 
[3] Conference on Management of Data, Washington 
DC, May 1993. 
[4] R. Agrawal and R. Srikant, ”Privacy preserving 
data mining”, In ACM SIGMOD Conference on 
Management of Data, pages 439–450, Dallas, Texas, 
May 2000. 
[5] L. Brankovic and V. Estivill-Castro, “Privacy 
Issues in Knowledge Discovery and Data Mining”, 
Australian Institute of Computer Ethics Conference, July, 
1999, Lilydale. 
[6] C. Clifton, M. Kantarcioglu, X.D. Lin and M. Y. 
Zhu, “Tools for Privacy Preserving Distributed Data 
Mining”, SIGKDD Explorations, 4(2), 1-7, Dec. 2002. 
[7] A. Evfimievski, J. Gehrke and R. Srikant, 
“Limiting Privacy Breaches in Privacy Preserving Data 
Mining”, PODS 2003, June 9-12, 2003, San Diego, CA. 
[8] J. Han, J. Pei, and Y. Yin, “Mining Frequent 
Patterns without Candidate Generation”, Proceedings of 
ACM International Conference on Management of Data 
(SIGMOD), 2002, 1-12. 
[9] H. Huang, X. Wu, and R. Relue, “Association 
Analysis with One Scan of Databases”, Proceedings of 
IEEE International Conference on Data Mining, 
Maebashi City, Japan, December, 2002, 629-632. 
[10] M. Kantarcioglu and C. Clifton, 
“Privacy-preserving distributed mining of association 
rules on horizontally partitioned data”, In ACM 
SIGMOD Workshop on Research Issues on Data Mining 
and Knowledge Discovery, June 2002. 
[11] S. Oliveira, O. Zaiane, “Privacy Preserving 
Frequent Itemset Mining”, Proceedings of IEEE 
International Conference on Data Mining, November 
2002, 43-54. 
[12] S. Oliveira, O. Zaiane, “An Efficient On-Scan 
Sanitization for Improving the Balance Between Privacy 
and Knowledge Discovery”, Technical Report TR 03-15, 
Department of Computing Science, University of 
Alberta, Canada, June 2003. 
