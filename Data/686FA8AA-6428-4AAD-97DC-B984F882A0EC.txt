energy and meet the multiple QoS of users in the 
cloud computing environment. According to the 
distribution of available resources, the accuracy of 
the predictor and the workload of executing tasks, 
the virtual machine monitor can determine for 
migrating tasks properly, and reallocate to the 
virtual machine with enough resource. By predicting 
the usage of resources, the system status of the 
virtual host can effectively be controlled, thus, the 
bandwidth requirement of the computation can be 
reduced.  
To satisfy the users＇ QoS requirements, minimize the 
makespan and the cost of workflows, and increase the 
success rate of workflow, we consider the key 
features of cloud and the characteristics of workflow 
applications with factors which affect the total 
makespan and cost of workflow greatly. A multiple QoS 
constrained scheduling algorithm will be developed 
for satisfying the multiple QoS requirements of 
users.  
For improving the proposed system, the accuracy of 
the resource allocation scheme and the system 
performance will be analyzed. The reliability and 
user friendly of the proposed computing environment 
will be concerned during the system implementation. 
This project is expected to provide a better solution 
for the efficient resources usage, to reduce the 
energy consumption of the virtual machine in the 
cloud computing environment, and to meet the multiple 
QoS requirements of users. 
英文關鍵詞： Cloud Computing、Virtual Machine、Extension Theory、
Quality of Service 
 
 I 
摘要 
有別於過去的分散式運算、網格運算和平行運算，雲端運算似乎可說是 IT技術不斷發展下的產物。
使用者只需要關注於服務而不必考慮關於相關的基礎設施。過去有不少文獻探討關於虛擬機器與網格
運算，而隨著雲端運算的發展，如何改善雲端環境中的資源使用效率與平衡虛擬主機的工作負載，發
展一套合適的解決方案將是相當重要的議題。 
本計畫擬依可拓理論設計適性化節能機制與滿足多重服務品質排程，可使雲端環境下的虛擬主機
工作負載平衡，降低能源消耗，並且可滿足使用者的多重服務品質需求。適性化節能機制根據可用資
源分布、預測器之準確率以及待處理之任務之工作量，適性化進行工作轉移，並調整該工作至合適資
源的虛擬主機，改善以往靜態負載平衡工作分配不均之問題；接著，為了減少伺服器的能耗問題，利
用動態電壓調整（Dynamic Voltage Scaling, DVS），藉由適當地降低電壓減少能耗。為了減少雲端環境
下工作流的完工時間和成本及提高工作流調整的成功率，滿足多重服務品質排程可根據雲端服務主要
功能的特點和工作流應用程序，考慮影響整體工作流程的完工時間和成本，進而滿足用戶的多重服務
品質需求。 
效能評估方面將探討資源配置調整之準確性以及程式執行之效能，並於計畫中實現環境的可靠性
及使用性。本計畫期望能在支援雲端計算之虛擬主機環境中，提升電腦資源的利用且降低能源消耗，
並滿足用戶使用需求的整體性解決方案。 
 
關鍵詞：雲端運算、虛擬主機、可拓理論、服務品質 
 
 1 
一、前言 
繼Web 2.0後，雲端運算（Cloud Computing）已被視為 IT產業下一波的新浪潮，伴隨著雲端的發
展，雲端運算所蘊藏的龐大商機，迫使 Google、Microsoft、IBM、Yahoo、Amazon、Oracle、HP、Dell、
Sun等科技大廠與網路服務商紛紛加入，期盼能取得先機，搶食這塊擁有無限商機的大餅。有關雲端
運算的蓬勃發展，最重要的莫過於虛擬化（Virtualization）技術，在近年逐漸受到各界重視，企業廠商
也看到了此技術未來的發展性以及其許多優點，有些企業廠商漸漸的將虛擬化技術導入企業內部的運
作之中，以期望發揮虛擬化技術的特性，以達到整合資源、節省成本、簡化管理的優點。 
本計畫將針對目前雲端計算環境下適應性資源調整與節能機制，進行研究與實作，改善過去相關
研究的缺點，並考量能源消耗與使用者服務品質等議題，建立一套支援雲端環境之適應性節能機制與
滿足多重服務品質排程。 
 
二、研究目的 
依目前市場伺服器的運算能力使用率來看，約有 80%的運算能力常是閒置未用的；而由伺服器所
集中組成的資料中心，其運算力的平均利用率更是僅在 20%至 30%之間。以傳統的伺服器而言，即便
在閒置的狀態下，功耗也約有峰值的 60%，空閒設備的電力消耗，加上資料中心冷卻設備的耗能，資
料中心會增加 50%至 100%的能源消耗。 
有效地利用處理器運算能力，減少各種軟、硬體資源的浪費，一直以來也都是分散式運算的重要
議題，如何解決此問題，進行伺服器虛擬化改造，將資料中心的伺服器由原先各種規格轉變為相對統
一制式標準（即按照資料中心的需求客製化不同類型的伺服器），能有效降低資料中心的能耗，提高利
用率。本計畫將依據預測器提供之硬體資源使用率適當分配至各個合適的虛擬主機上來進行處理（包
含多台主機的硬體資源），達到高效能的計算效果。 
以往網格運算的工作流管理系統，其開發重點在於方便地組成和在分散式資源執行工作流程應
用。許多研究還提出了以優化一個目標的工作流調整，如減少執行時間或預算的限制。然而，需要更
多的目標時必須考慮到雲端調整工作流與用戶對於 QoS需求。大部分排程演算法著重在單一的服務品
質（QoS）的參數，如執行時間或成本。但是，如果考慮一個以上的 QoS參數（如執行成本和時間），
這個問題將變得具有挑戰性。 
此外，針對雲端運算資源使用預測機制，將更能減少網路頻寬、額外記憶體使用的浪費，以減輕
各別計算環境硬體資源之負擔，並增加雲端運算技術的可擴性；最後，研究執行時間、網路頻寬、記
憶體使用率、CPU 負載等參數，對虛擬主機環境運行效能之影響，為評估本計畫環境之可行性與必要
性的重要指標。 
 
三、文獻探討 
在本計畫中，我們將設計一虛擬化技術在動態運算資源配置方面機制以及負載平衡架構，並與其
他文獻所提出之方法進行分析和比較，相信我們提出的虛擬雲端計算環境上之適應性資源調整配置以
及負載平衡機制，在各方面均會有較其他文獻有更佳的表現。 
本計畫主要採用之技術與理論以下將分為五個部份來說明，為雲端計算、虛擬技術、排程演算法、
可拓理論與動態電壓頻率調整。 
1. 雲端運算 
 3 
2. 虛擬化（Virtualization） 
虛擬化技術之所以在這幾年受到重視，不外乎有以下幾點優點，使得許多公司企業逐漸願意接受 
這一項新的技術。 
（1）使資源規劃更加完善： 
（2）節省成本： 
（3）增加資訊安全的保障： 
虛擬化概念最早使用的就是 IBM大型電腦上 VM/CMS（Virtual Machine/Conversational Monitor 
System）Time-Sharing產品，該產品使用互動式運算的單使用者作業系統。透過此種方式，CMS編寫
起來較為簡單，如同只有單一用戶在執行一樣；VM作業系統則在幕後提供多工以及資源管理服務及
虛擬機器監視器（Virtual Machine Monitor, VMM）體作為電腦硬體層上面的一層軟體抽象層，將電腦
硬體虛擬分割成一個或多個虛擬機器，提供多個用戶對大型電腦(或是電腦叢集)的同時、交互訪問。 
虛擬機器可以在電腦平台和終端用戶之間建立一種環境，而終端用戶則是在這個軟體所建立的環
境來操作各種的服務，在電腦科學中虛擬機器是指可以如同真實機器一樣執行程式的電腦軟體實作。
Linux 類別的作業系統上，Xen與 KVM是最常被使用的虛擬機器： 
 Xen 
Xen於 2002 年劍橋大學計算機實驗室所研發的成果，透過半虛擬化（Para Virtualization）的技術
對底層硬體的控制效率接近實機操作、包括中斷控制（IRQ）等，因此獲得高效能的表現。在 x86的電
腦上 Xen也有極佳的表現。與傳統透過軟體模擬方式實現硬體的虛擬化技術不同，Xen可以從硬體方
面直接的模擬出虛擬機器，也是影響效能表現較好的原因之一。 
Xen的架構是分成多個層級（Layer）來執行，它將 Linux的核心修改過後，再使用該修改後的核
心開機，而開機後先載入 Xen的監督器，稱之為 Hypervisor，並且啟動第一個在上頭的作業系統，我
們稱為 Domain-0。 
 
 
圖 2 Xen虛擬化示意圖 
 
 KVM 
KVM是一個開放原始碼的虛擬平台，提供 x86 Linux作業系統中的全虛擬化的虛擬環境，一個運
行在作業系統上的管理程序（Hypervisor），透過 Linux核心開發方法把 Linux核心本身當作一個管理
程序並整合管理程序功能，這種方法的優點是，增加虛擬化效能，即使沒有特別的硬體也能夠達到半
虛擬的效能；Linux核心在這種模式下，每個虛擬機器都被視為一個普通的 Linux程序（Process），會
以標準 Linux排程（Schedule）進行運作。一個普通的 Linux程序有兩種模式執行：核心模式和用戶模
式。用戶模式是一個應用程式預設的模式，當應用程序需要從核心作某些動作時會進入核心模式，KVM
增加了第三種模式，來賓模式（Guest Mode），來賓模式是運行在虛擬機器上，擁有自己的核心和使用
 5 
然而若使用 LLF對工作進行排程，其以 di減去當前 Ti剩餘所需的執行時間（稱為 Laxity）來決定優先
權，排程結果如圖 2(b)表示，各工作皆能在其時限內完成，EDF在多處理器上已經不屬於最佳排程法。 
另外，雖然 LLF在多處理器平台上仍屬最佳排程法，但卻會造成頻繁的內文切換（Content Switch），
視內文切換的時間，有可能所有工作都將無法在時限內完成。比起 EDF 只造成 T1一個工作超過時限
的結果還來得糟。除此之外，T2和 T3在兩個處理器之間的置換花費也需納入考量。針對即時工作，目
前的排程演算法將以 LLF 為主，並以權重（Weight）為依據來分配調整各工作的優先權，以減少內文
切換。同時利用多核心架構共享 L2快取記憶的特性，用適當的順序分配處理器資源來 L2快取的命中
率，減少工作在處理器間置換所需要的花費。 
 
4. 可拓理論 
可拓理論為中國大陸 蔡文教授於 1983年所提出。其中物元分析提出了解決矛盾問題的思考框
架，經由物元的構造和物元的變換來反應事物的「質」和「量」間的相關變換關係。該理論研究如何
將數學問題形式化，問題之間的關係和問題的轉化，解決問題的物元方程式、蘊含方程式、關連不等
式和轉換橋的構造，從而建立一套解決矛盾問題的工具。 
何為矛盾問題，舉例來說，“曹沖秤象”即是標準的例子。要用小秤子去秤大象是不可能的事，但
利用相同重量的石頭與大象做比較後，只要秤出石頭的重量便可達到秤大象之目的，在可拓理論中被
稱為一個相同特徵的物元轉換。可拓理論將古典數學由原本的二位值邏輯延伸成連續多值（Continuous 
Multi Value），並且將關聯函數表示成事物特質，將一個元素屬於某一事物特性之程度由-∞~∞中之實數
來表達，此實數可稱為此元素對於事物特性所屬集合之關聯度。若將關聯度正規化後得到之數值為 1
時，則代表此元素完全符合該事物特性，而若將關聯度正規化後得到之數值為-1時，代表此元素不屬
於此事物特性，假使正規化後關聯度介於〈-1, 1〉之間，則表示元素屬於或是不屬於事物特性之強弱
程度。 
我們將生活中的人、事、物統稱為事物，事物具有各式各樣的特徵，而一個事物關於某一個特徵
會有相對應的量值，事物的名稱、特徵及特徵相對應的量值是描述事物的三項基本要素。我們將事物
的名稱定義為 N，而是物相對於特徵 C的量值為 V，以此定義用來描述事物的基本元素，稱為物元。
事物、特徵、量值稱為物元三要素，我們將物元以數學式表示成公式（1）。 
 
R = ( N , C , V )                  （1） 
 
並根據物元特徵與質量關係 V = C(N)，可將公式（1）表示成： 
 
V = ( N , C , C(N))                  （2） 
 
物元理論中，其物元亦可為多維物元，多維物元設事物有 n個特徵分別為 C1 ,C2 ,C3,…Cn，其對應
的量值分別為 V1, V2, V3 ,…Vn，則物元的表示式為： 
 
                  （3） 
 
 7 
 
圖 5 本計畫支援雲端計算之虛擬主機環境 
 
1. 工作轉移機制模組的開發與預測系統 
本計畫支援雲端計算之虛擬主機環境，雖然利用所提出之排程演算法可提昇 CPU之使用率，
但是在不同工作及各個虛擬主機間如何有效地分配與互動，是亟需克服的一個問題。然而，以使
用者端來看，可將所需服務下之所有軟硬體元件視為單一的中介軟體所提供之服務，實際如何發
揮 VMM其下所管理的所有硬體元件資源的最佳配置的優勢，將所有將運行的工作予以最佳化的
配置，過去亦曾有關於網格環境之動態排程方面的議題。為此，第一年計畫中我們將設計一適應
性排程機制用來提升本計畫所設計之雲端計算環境的效能。 
 
2. 開發適應性排程演算法模組 
本計畫之適應性資源調整機制使用兩個佇列來管理任務：等待佇列（Waiting Queue），與執行
佇列（Execution Queue）。等待佇列管理還沒分發到處理器的任務。排程程式把每項任務分發給各
個計算節點，這任務便從等待佇列移出然後移入執行佇列。每一個任務在執行佇列有固定的權重
且不重複。執行佇列使用指標來指出在佇列內的任務。透過目前指標、下個指標及最後指標，可
以對佇列進行插入、刪除等動作。圖 6為適應性排程演算法的狀態圖。 
適應性排程演算法狀態說明： 
（1）狀態 1（S1）：等待任務的到達，此為初始狀態。 
（2）狀態 2（S2）：分派任務給閒置的處理器。最初，在狀態 2內有些任務進入等待佇列，
此時執行佇列沒有任務。每一個處理器會分到一個任務。 
（3）狀態 3（S3）：執行在執行佇列內任務的複本。當等待佇列是空的，狀態便從 2移到 3。
此狀態會分派任務的複本給閒置的處理器以提升完成任務的速度。當新任務到達等待佇列，
排程將前進至狀態 4。 
（4）狀態 4（S4）：處理器重新分配。考慮的條件如下 
I. 如新任務數量大於或等於執行複本的處理器的數量，排程狀態將回到狀態 2。 
II. 如新任務數量小於執行複本的處理器的數量，排程狀態將回到狀態 3。 
 9 
圖 7 改良式 DVS演算法之運作流程 
 
為了改善動態電壓排程法，本計畫提出了一個利用可拓工程為基礎的新演算法來改善它。可
拓工程方法的理論在 1983 年由蔡文所提出，其主要目的在於透過一種分類法則來解決矛盾問
題。我們將該方法應用於動態電壓排程法中，即是在即時系統中的每一個工作項目的狀態視為一
種矛盾問題，透過可拓工程方法來分類，將其分別分成超過時限、能在時限完成、超過時限但可
透過回饋機制完成三種種類。我們將每一個工作分別針對不同電壓找出其可拓關係值，找出的可
拓關係值可以依照不同的數值範圍作為分類之依據，假設在電壓 V之下的可拓關係值為 K(V)： 
（1）K(V) < 臨界值，代表這過工作在電壓 V執行時，將會超過時間限制。 
（2）0 > K(V) >臨界值，代表這個工作在電壓 V執行時將會超過時間限制，但是可以透過回
饋機制處理，使其可以在時間限制內完成。 
（3）K(V) ≧ 0，代表這個工作在電壓 V執行時候，將可以在時間限制內完成。 
（4）K(V) = 0，這個點我們稱作為零點。每一個工作只有在兩個狀況下產生的可拓關係值會
是零點。第一個狀況是用最高電壓全速執行的時候。第二個狀況是這個工作剛好在時間限制
內完成，也就是說 Slack Time為 0，代表利用電壓 V（此電壓非最高電壓）執行這個工作時，
將會是能量消耗最小的時候。 
利用可拓工程方法來改善動態電壓演算法，有以下優點： 
（1）可以利用簡單的計算公式，較少的計算量來計算出每一個工作應該在何種電壓下面執行。 
（2）由於每一個工作產生出來的結果是無法預測的，因此動態電壓演算法教難以去當作動態
演算法執行，目前大部分研究提出的演算法皆是靜態演算法為主體。透過我們的演算法可以
將動態電壓演算法轉換為動態演算法，實做活用性質大幅上升。 
（3）保有原來動態電壓演算法之節省能量特性。 
 
五、結果與討論 
5.1實驗結果與分析 
本計畫實驗主機為搭載四核心 Intel® Core™2 Quad CPU的高階個人電腦，CPU每一個核心運作時
脈為 2.83 GHz，內建 8 Gb DDR3記憶體，搭配 500 Gb SATAII 硬碟，電源供應器瓦數為 250W。實驗
軟體採用 CloudSim模擬雲端環境，CloudSim是由澳大利亞的墨爾本大學（University of Melbourne）
以 Java 所撰寫的模擬雲端環境平台。實驗主機的作業系統為 Microsoft Windows 7 Enterprise。由於
CloudSim支援 Java，因此本計畫採用 Eclipse為本計畫的開發軟體。Eclipse IDE是集合了撰寫、編譯、
除錯和部署 Java程式的程式開發工具，軟體本身是以 Java撰寫且能夠多種程式語言的軟體開發。 
本計畫所提出的機制係在 CloudSim 中模擬大型雲端資料中心，主要分為三個部分：CPU 使用率
的監測、DVS調整、即時遷移。當系統啟動之後，將監控每一個主機上的 CPU使用率，並將此使用率
作為判斷的依據，並依照判斷出的結果執行不同的節能方式。在電壓調整方面，實測了一個 250W 的
電源供應器所得出來的數值，以此作為調整設定的參考。 
在 CloudSim中係以MIPS做為主機、VM之能力以及工作量的單位。各個工作量會分給不同主機
上的 VM，VM MIPS為 VM所要求的MIPS量，HOST MIPS則為主機所能供給的MIPS量，公式 4用
以計算 Vcpu的使用率，公式 5計算的結果則用來計算 CPU的平均使用率。 
 
Vcpui = 
VM
MIPSi / 
HOST
MIPSi                (4) 
 11 
 
表 2 VM數量與遷移次數的實驗結果 
 實驗一：VM數量與遷移或次數 
VM數量 0 50 100 150 200 250 
遷移 0 31 76 109 136 155 
合併 0 13 28 41 52 64 
 
 
圖 9 VM數量與遷移次數折線圖 
 
圖 9為 VM數量與遷移合併次數的關係圖，隨著 VM的設立越多，遷移或合併的次數也隨之提高，
而在工作量不斷給予的情況下，其遷移次數與合併次數大約是成 1比 2的狀態。而以省電效益方面來
看，越多台 VM放在同一主機上的省電效益越大，但之所以不讓太多台 VM放在同一主機上的原因是
當有 VM需要遷移或合併時會額外耗損功率，同一主機上越多 VM將會增加此次數，反而會因此降低
效能。 
表 3 工作數量與遷移次數的實驗結果 
 實驗二：工作數量與遷移次數 
工作數量 0 100 200 300 400 500 
遷移 0 31 65 97 124 147 
合併 0 13 34 56 78 99 
 
 13 
表 5 能源消耗比較的實驗結果 
 實驗四：能源消耗比較 
VM數量 0 50 100 150 200 250 
使用前(kwh) 0 5.042 9.874 13.654 17.413 20.972 
使用後(kwh) 0 3.248 6.394 9.371 12.157 14.733 
 
 
圖 12 能源消耗比較折線圖 
 
表 5與圖 12為 VM數量與能源消耗使用節能機制前後的結果，上方是未原始未經過本計畫的設
計，下方為調整過後的結果，經過觀察，使用了資源調整機制後的結果大約能讓原本未經過設計的配
置方式省下 24 %至 33%的電量。 
 
5.2 結論 
以傳統的主機與虛擬機器的資源配給方式來看，要能更有效的提升資源使用率，必定得將資源依
照情況進行調整，因此本計畫中提出了一個基於雲端運算環境底下的動態節能機制用來降低能源的消
耗，我們架構了一個讓資源能夠靈活運用的方式，其中 DVS的調整以主機端的 CPU平均使用率做為
調整的依據，固定時間即計算各虛擬機器的資源使用率，以隨時捕捉 CPU平均使用率的變化，並在負
載過重的時候運用即時遷移保證一定的服務品質以提供更有效的資源利用方式，而工作量過低的時候
則選擇合併讓多餘的伺服器關閉，且不會讓使用者查覺到伺服器端的變化。 
實驗結果顯示，在此環境中有經過動態資源調整的與沒有經過調整的能源消耗相比有明顯改善，
使用前後大概可省下 24 %至 33%的電量。 
 
參考文獻 
[1] D. A. Bader, V. Kanade, and K. Madduri, "SWARM: A Parallel Programming Framework for Multicore 
Processors," Parallel and Distributed Processing Symposium, 2007 (IPDPS 2007), pp. 1-8, IEEE 
International, 2007. 
[2] R. Buyya, "High Performance Cluster Computing: Programming and Applications", Vol. 2, Prentice Hall 
PTR, NJ, 1999. 
[3] H. Casanova, A. Legrand, D. Zagorodnov, and F. Berman, "Heuristics for Scheduling Parameter Sweep 
 15 
Japan, Oct. 2 - Oct. 4, 2006. 
[20] X. Li, Y. Li, T. Liu, J. Qiu and F. Wang, "The Method and Tool of Cost Analysis for Cloud Computing," 
International Conference on Cloud Computing, 2009 (CLOUD '09), pp. 93-100, 2009. 
[21] Y. N. Shen, R. C. Zhao and J.M. Pang, "Automatic Code Generation of Data Decomposition", 
INFOSCALE '06,May 29-June 1, 2006. 
[22] S. Wu, W. Zhu, W. Jiang and H. Jin, "VMGrid: A Virtual Machine supported grid middleware," 
International Conference on Granular Computing, 2008 (GrC 2008), pp. 676-679, 2008. 
[23] L. J. Zhang and Q. Zhou, "CCOA: Cloud Computing Open Architecture," International Conference on 
Web Services, 2009 (ICWS 2009), pp. 607-616, 2009. 
[24] G. Zheng, O. S. Lawlor and L. V. Kale, "Multiple Flows of Control in Migratable Parallel Programs,” 
ICPPW, 14-18 Aug. 2006. 
[25] T. Ishihara and H. Yasuura. “Voltage Scheduling Problem for Dynamically Variable Voltage Processors,” 
International Symposium on Low Power Electronics and Design, pp. 197-202, August 1998. 
[26] F. Yao, A. Demers and S. Shenker. A Scheduling Model for Reduced CPU Energy. IEEE Annual 
Foundations of Computer Science, pp. 374 -382, 1995. 
[27] W. Tian, S. Su, and G. Lu, "A Framework for Implementing and Managing Platform as a Service in a 
Virtual Cloud Computing Lab," 2th International Workshop on Education Technology and Computer 
Science 2010, pp.273-276, March 2010. 
[28] R. Rojas-Cessa, E. Oki, and H. J. Chao, "CIXOB-k: Combined In-put-Crosspoint-Output Buffered 
Switch," IEEE Global Conference on Telecommunications 2001, vol. 4, pp. 2654-2660, November 2001. 
[29] R. Rojas-Cessa, E. Oki, and H. J. Chao, "CIXB-1: Combined Input-One-Cell-Crosspoint Buffered 
Switch," IEEE Workshop on High Performance Switching and Routing 2001, pp. 324-329, May 2001. 
[30] Z. Dong and R. Rojas-Cessa, "Shared-Memory Combined Input-Crosspoint Buffered Packet Switch for 
Differentiated Services," IEEE Global Conference on Telecommunications 2006, November 2006. 
[31] L. D. Sun, G. Chang, C. Wang, Y. Xiong, and X. Wang, "Efficient Nash Equilibrium Based Cloud 
Resource Allocation by Using a Continuous Double Auction," International Conference on Computer 
Design and Applications 2010, pp.94-99, June 2010. 
[32] Rodrigo N. Calheiros, Rajiv Ranjan, Anton Beloglazov, Cesar A. F. De Rose, and Rajkumar Buyya, 
CloudSim: A Toolkit for Modeling and Simulation of Cloud Computing Environments and Evaluation of 
Resource Provisioning Algorithms, Software: Practice and Experience, Volume 41, Number 1, Pages: 
23-50, ISSN: 0038-0644, Wiley Press, New York, USA, January 2011. 
 
     筆者被安排在 5 月 30 日下午發表論文，論文題目為 “Dynamic resource 
management for energy saving in the cloud computing environment”，此外另有一  
篇論文“A Modified DRR-Based Non-real-time Service Scheduling Scheme in 
Wireless Metropolitan Networks”，由共同作者博士生莊漢聲同學發表。 
二、 與會心得   
    此次研討會計有 79 篇論文發表，由於研討會幾乎涵蓋資訊科學與產業應用
上各研究領域，有來自各個國家的眾多學者參與，其中大部分來自我國、大陸
及韓國，筆者主要從事平行與分散式計算、雲端計算以及嵌入式系統方面之研
究，除參與研究相關場次之研討外，亦參與其他領域之研討，在會場與多位學
者認識，相互切磋獲益良多，咸認雲端計算為資訊科技之下一次大變革。此外，
研究生莊漢聲同學為第一次出國參加國際研討會，除利用此機會展示其本身之
研究成果外，亦可擴大其視野，了解外界之研究狀況，以充實、改進其本身之
研究內容。 
 
三、攜回資料名稱及內容 
    參加本次會議一共攜回下列資料： 
1. 2012 International Conference on Information Science and Industrial Applications 
(ISI 2012) / The 1st International Conference on Software Technology ( Soft Tech 
2012) Conference Program 一冊。 
2. 2012 International Conference on Information Science and Industrial Applications 
(ISI 2012) Conference proceeding 光碟一片。 
 
 
Dynamic resource management for energy saving in the cloud computing 
environment 
Liang-Teh Lee, Kang-Yuan Liu, and Hui-Yang Huang 
Department of Computer Science and Engineering, Tatung University, Taiwan 
ltlee@ttu.edu.tw, d9306005@ms.ttu.edu.tw, isaacyuyu@gmail.com 
Abstract. Cloud computing has become the new generation of IT industry in recent year, and cloud computing 
services will be an important role to meet various requirements of the people in their daily lives. In cloud 
computing, virtualization is an important issue. This paper presents a method of dynamic voltage scaling for 
dynamic adjustment of resources by inspecting CPU utilization. The voltage of the idle or light loaded computer 
can be reduced and heavy loaded works can be migrated to those machines with lighter loading for achieving the 
purpose of energy saving. The experimental results show that by applying the proposed mechanism, at the user 
unaware situation, energy consumption can be saved significantly. 
Keywords: Cloud computing, virtual machine, dynamic voltage scaling 
 
1. Introduction 
 
With more and more suppliers began offering cloud computing services, these services are 
convenient to users but consuming a lot of energy. Thus, how to save the energy of the data center 
without affecting both the economic efficiency and system performance is an important issue. 
Virtualization technology can simulate a variety of different platforms and manage the resources 
of the system. By applying the virtualization technology, in accordance with the requirements of the 
users to configure a virtual machine, both the computing environment and resource management 
problems can be solved. 
In cloud computing environment, the amount of workload will affect the loading of the physical 
machine of cloud server. If in accordance with the appropriate voltage regulation would be effective 
in improving energy efficiency and reduce the overhead. This paper proposes a mechanism to adjust 
the system voltage based on the CPU utilization, and migrating tasks in a heavy loaded machine to 
idle machines. 
 
2. Related work 
 
2.1 Virtualization Technology 
 
Due to the isolation and migration functions can provide users with a secure, flexible and effective 
way, the virtual machine (VM) technology has substantial growth. Virtualization technology [1][2] 
can be classified into two categories, full virtualization and para-virtualization. The advantage of 
full virtualization is that regardless of any hardware environment it can maintain consistent 
compatibility, but will cause a greater loading of the physical machine. While the advantage of 
message exchange in data center and users can develop their own algorithms to be processed in 
CloudSim. 
2.4 Virtual machine migration 
 
Virtual machine migration technique allows a virtual machine running on a physical machine to be 
migrated to another physical machine. Migration can be classified into offline migration and 
real-time migration. The difference is whether or not to stop the execution of the task to be migrated. 
For offline migration, the current user's state must be suspended or shut down before the migration 
can be performed, and users will not be able to take any action. For real-time migration, in contrast, 
it is not necessary to shut down the original virtual machine and the task can be migrated at the user 
unaware situation. The advantages of the real-time migration include load balancing, power 
efficiency, and convenient maintenance [6]. 
Migration of memory is one of the most important issues in real-time migration [7]. Virtual 
migration consists of the following steps: pre-migration, reservation, iterative pre-copy, stop and 
copy, as well as the commitment activation. Where pre-copy is the existing virtual machine 
migration technology. For real time migration, by applying the pre-copy technique, all memory 
pages are migrated before VM migration, once the Writable Work Sequence (WWS) is small 
enough or the predefined iteration numbers reached, the virtual machine will start to be migrated, 
CPU status and memory pages are transferred to the destination machine. Although pre-copy can 
compromise the system downtime and total migration time, it cannot guarantee to transfer data 
continuously if the number of work queue limit is reached, especially when the virtual machine is 
running read-intensive operations. 
 
3. Dynamic virtual resource management for energy saving  
 
The resource utilization improvement and energy saving are important issues in the cloud 
computing environment. In addition, the strategy to satisfy the quality of service requirements of 
users and the task scheduling in the multitasking environment should also be considered. 
According to a report by Symantec in 2009, about 97 % of the respondents pointed out that the 
company has been discussed the Green IT issues, while 45% have been importing the green energy 
plan. According to the utilization of server resources in the current market, about 80% of them are 
idle. In general, even in the idle state, 60% of the power is consumed by the cloud servers. The 
power consumption coupled with cooling equipment, energy consumption will result in 50-100% of 
the waste of energy. 
 
3.1 System overview 
 
This paper proposed a mechanism by applying CloudSim to simulate a large scale cloud data center 
for energy saving. The system consists of three parts: the CPU utilization monitoring, DVFS 
adjustment, and real-time migration. CPU utilization on each host is monitored in the system. 
Table 1. Power consumption of CPU usage 
Time (sec) Min power consumption (kwh) Max. power consumption (kwh) 
5 0.66 0.67 
10 0.63 0.64 
15 0.62 0.63 
20 0.63 0.66 
25 0.64 0.67 
 
Table 2. Power consumption vs. CPU performance 
POWER (W) CPU (MIPS) 
250 247 
225 228 
200 207 
175 182 
 
In the experiment, real-time migration can be performed for migrating the VM to other idle (or light 
workload) host, or merging VMs by migrating other VM to the light workload host. In the system, a 
host cannot support full utilization of 3 VMs at the same time.  
 
4. Experimental results and analysis 
 
In the experiment, the computer is using Intel® Core™2 Quad Q9500 CPU, running at 2.83GHz, 
4GB DDR3 memory, and 500GB SATAII hard drive. Experimental platform is the CloudSim 
software with Windows 7 operating system. Both host and VM are single-core architecture.  
 
A large scale cloud computing environment is simulated in the experiment. The number of tasks 
is 400, the resources required for each tasks are from 5 to 250 MIPS which are generated randomly. 
The voltage adjustment is determined every 15 seconds. Total run time is measured at the time all 
works completed. The experiment is performed 10 times for calculating the average value and total 
power consumptions. 
The relationship between the number of acting VMs and the number of migration and merging is 
illustrated in Figure 1. Increasing the number of acting VMs will result in increasing the number of 
migration and merging. In terms of power efficiency, the more VMs can be placed on the same host, 
the greater the power efficiency can be obtained. However, too many VMs on the same host will 
increase the number of migration and degrade the system performance. 
 
 
 
Fig. 1. Number of acting VMs vs. migration and merging numbers 
From: sersc@sersc.org [mailto:sersc@sersc.org]  
Sent: Wednesday, May 02, 2012 4:33 AM 
To: ltlee@ttu.edu.tw 
Cc: sersc@sersc.org 
Subject: ISI 2012 Status of paper 90 
 
Dear  Han-Sheng Chuang, Liang-Teh Lee and Chen-Feng Wu 
 
We are happy to inform you that your paper entitled "A Modified DRR-Based Non-real-time 
Service Scheduling Scheme in Wireless Metropolitan Networks", submitted to ISI 2012, has been 
accepted. 
** Please Check First ** 
Below, you will find attached the reports of the reviewers. 
Please consider the reviewers' comments carefully when preparing the final version of your paper. 
Please check next schedule very carefully. 
Please note that any delay may prevent the inclusion of your paper in the 
proceedings and journals. 
1. Conference Proceedings published by SERSC 
 - Your paper will be included in conference proceedings by using LNCS paper format within 6 
pages.  (After closing conference, we will send proceedings to EI and SCOPUS for review) 
- Please download the paper format from 
 MS-word format: http://www.sersc.org/CCIS-LNCS-word-PaperFormat.zip 
 LaTeX format: http://www.sersc.org/LNCS_LaTeX_Format.txt 
- Prepare max 6 pages proceedings papers, and send it to 
proceedings@sersc.org by May 10, 2012. 
- This means copyright of your paper is moved to SERSC automatially. 
- Conference proceedings will be distributed at the conference site. 
2. Registration 
- Please visit Registration page: 
 http://www.sersc.org/ISI2012/reg.php or 
http://www.sersc.org/SoftTech2012/reg.php 
- Register your paper by May 10, 2012. 
 
The ISI 2012 site also provides all necessary information for conference registration and hotel 
accommodation. 
Best regards, 
ISI 2012 PC chairs 
2   Related Work 
2.1   QoS Service in WiMAX 
WiMAX speciﬁes ﬁve types of service classes: Unsolicited Grant Service (UGS), real-time Polling Service (rtPS), 
extended real-time Polling Service (ertPS), non-real-time Polling Service (nrtPS), and Best Effort (BE). The allocations 
of UGS are ﬁxed, while the allocations of ertPS and rtPS are dynamic. The nrtPS is designed for non-real-time service 
that requires variable size bursts periodically and BE is adopted for the service which does not concern itself with 
throughput or delay guarantees. 
2.2   RR-Based Scheduling 
The RR scheduler is a simple and normal algorithm which distributes the equal resource without priority, but it does not 
guarantee any QoS requirements. There had been some enhanced RR-based schedulers proposed, such as the weighted 
round-robin (WRR) [4] and the deﬁcit round-robin (DRR) [5]. For WRR scheduler, each SS is assigned a weight as its 
priority. The scheduler allocates the bandwidth according to the static weight. DRR scheduler sets a ﬁxed quantum and 
a deﬁcit counter to each ﬂow, and it allows provision of different quanta for each SS. A higher quantum can be assigned 
to higher priority SSs. 
2.3   Call Admission Control 
The method of Minimum Reserved Traffic Rate (MR) is currently most adopted. Because each service has its own MR 
except BE and it can be assumed as rmin(i, j) that represents the MR of the jth connection for the ith class of service flow, 
the CAC can be designed easily and summarized by Eq. 1. 
 
 
(1) 
 
Where, Ca and Ctotal represent the available capacity of current system and the total capacity of whole system, 
respectively. Once a new connection intends to add to the system, the newer Ca in Eq. 1 will be recalculated and 
checked if it is greater than 0 or not. 
3   Proposed Scheduling Scheme 
3.1   Signal-Aware Call Admission Control 
IEEE 802.16e specifies a Fast Feedback region that can be assigned in the uplink sub-frame, and it provides several 
uplink control channels to send messages to rapid exchange cross-layer information [6]. One of those is CQICH 
(Channel Quality Information Channel), replied the Signal to Noise Ratio (SNR) by SSs. A cross-layer CAC, which 
In MDRR, a queue in a group can be defined as a Priority Queue (PQ). The PQ always will be served in each round 
and does not consider the order. In this paper, we will temporarily assign the queue with the shortest length as the PQ. 
This means that it will release the occupied resources quickly. 
4   Simulation Results and Discussion 
The simulations are conducted to evaluate the performance of the proposed scheduling algorithm and CAC according to 
the throughput of non-real-time service (nrtPS) for downlink traffic. The simulations were implemented in NS-2 with 
the following parameters as shown in table 1. The simulation adopts the operation mode of Point-to-Multi-Point (PMP) 
and composes of one BS and five SSs based on IEEE 802.16e. To simplify the simulation, the SSs only request of nrtPS 
service. In the scenario, SSs request a new connection requirement every 10 seconds. The simulation had lasted for 60 
seconds and repeated 10 times to obtain average value. 
 
Table 1. Simulation Parameters. 
Parameter Value 
SS distance from BS: SS1, SS2, SS3, SS4, SS5 100 m, 200m, 400m, 600m, 800m 
Source model 
Maximum sustained traffic rate 
Minimum reserved traffic Rate 
Constant bit rate (CBR) 
100 ~ 200 Kbps 
50 ~ 100 Kbps 
Maximum latency: nrtPS 1 sec (ITU-T Class 4) 
BS transmitted power 
Operating frequency band 
Total Bandwidth 
Log-normal shadowing standard deviation 
40 dBm 
3.5 GHz 
6 Mbps 
9 dB 
 
Fig. 1 illustrates that the throughput of the SA and CMDRR is larger than the MR and RR, and it will significant for 
more connections case. Because the RR scheduling does not adjust the resources assigned after the MR admitted even if 
there are available resources not to be assigned in system. It causes that the resource utilization and the throughput 
decrease. In more connections case, the decrease becomes more apparent. 
 
 
Fig. 1. System Average Throughput. 
 
In Fig. 2, the result proves that the CMDRR meets the original intent of our design: The connection with better SNR 
can transmits more data. According to the propagation loss of wireless communication, the distance is an important 
factor to affect the radio wave transmission. In the simulation, SSs have different distance between BS, and the SNR 
Fixed Broadband Wireless Access Systems,” IEEE Standard 802.16-2004, Oct. 2004. 
[3] IEEE Computer Society, “Air interface for fixed broadband wireless access systems amendment for physical and 
medium access control layers for combined fixed and mobile operation in licensed bands,” IEEE Standard 
802.16e, Dec. 2005. 
[4] M. Katevenis, S. Sidiropoulos, and C. Courcoubetis, “Weighted round-robin cell multiplexing in a 
general-purpose ATM switch chip,” IEEE J. Sel. Areas Commun., Vol. 9, No. 8, pp. 1265–1279, 1991. 
[5] M. Shreedhar and G. Varghese, “Efﬁcient fair queuing using deﬁcit round robin,” IEEE Trans. Netw., Vol., 4, No. 
3, pp. 375–385, 1996. 
[6] S. A. Xergias, N. Passas, and L. Merakos, “Flexible Resource Allocation in IEEE 802.16 Wireless Metropolitan 
Area Networks,” Proc. of the IEEE Local and Metropolitan Area Network (LANMAN’05), pp. 1-6, Sept. 18-21, 
2005. 
[7] Cisco Feature Navigator, 
http://tools.cisco.com/ITDIT/CFN/Dispatch?act=featdesc&task=display&featureId=1080 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：李良德 計畫編號：100-2221-E-036-028- 
計畫名稱：支援雲端運算環境之可拓適性化節能機制與滿足多重服務品質排程 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
