  共 6 頁 第 2頁
 
  
（A） （B） （C） 
圖一、（A）原始資料，（B）主成份分析的投影，（C）等量特徵映射（局部定義為 k=12
個鄰居點所成的區域）。 
 
三、文獻探討與研究方法 
I. 等量特徵映射（Isomap） 
在一般在空間上，我們猜想資料集的分佈在一個流形 (manifold)上。當資料呈現在高維空間上時，
我們無法直接觀察到這個流形，所以我們需要透過維度降低的技術，將高維空間上的資料點映射到較
低維度空間中，使我們能觀察到這個流形，並利用這個觀察來進行各種的應用。而最能表現這個流形
的維度，被稱為本質維度 (intrinsic dimensionality)。由於資料在高維度空間中不一定呈現線性結構，
因此若直接使用如 PCA (Principal Component Analysis) 等全域技術進行降維，結果將無法符合我們的
需求。 
等量特徵映射為利用非線性的方式對特徵集進行維度降低的技術。它的目的在同時保有局部 
(local) 與全域 (global) 的不相似 (dissimilar) 性質下，透過MDS (MultiDimensional Scaling) [5] 將資
料集投影到較低的維度空間中。於新維度空間中，各資料點間有著如同原維度空間中的不相似性質，
以及適當地呈現資料集的本質。等量特徵映射的處理過程主要分為三個部分。第一部份為局部結構的
建立；第二部份為全域資訊的建立，利用第一部分所產出結果，透過局部子結構間的連通(connect) 性
質，便可計算任兩資料點間的最短路徑；最後一部份為低維度空間的映射。 
 
−6 −4 −2 0 2 4 6 8 10
−6
−4
−2
0
2
4
6
 −10 −9 −8 −7 −6 −5
0
5
10
15
20
25
30
35
40
45
 −10 −9 −8 −7 −6 −5
0
10
20
30
40
50
60
70
 
（A） （B） （C） 
圖二、（A）位於二維空間上的資料分布，共有兩種類型，紅色十字形的點集以及藍色圓形的點
集，（B）主成份分析第一主成份（最大特徵值所對應的特徵向量）的投影，（C）SIR第一方向
的分布。 
 
  共 6 頁 第 4頁
 
入類別值y的資訊，成功的得到正確的投影方向。由圖二（C）我們可以觀察到兩點集各有不同的分布，
也就是說 SIR成功把兩點集分開來。由此實驗我們可以發現加入了類別值y的考量，提供了監督式降
維方法更有效的投影方向。雖然 SIR加入類別值的考量促使我們更能找到正確表現資料的投影方向，
然而 SIR是屬於線性的做法，因此當資料具有非線性分布的性質時，SIR就無法完美的找出解釋此資
料的方向。以下我們延續圖二（A）的實驗資料，將一筆新的資料加入，其分布情形如圖三（A）所
示。由圖三（B）結果所示，我們發現藍色圓圈以及黑色菱形的投影結果有很多部分重疊在一起，此
現象可以說明單純求解線性投影方向，並不能有效處理此類型資料。我們必需考慮區域性結構和非線
性的資料特性。 
 
四、實驗結果與討論 
本計畫實驗的目的在比較線性監督式降維、非監督流形降維和非線性監督式降維等諸類方法。初
步來說，由圖四（B）我們發現雖然 SIR有加入類別值的考量，然而只針對線性方向是無法克服非線
性流形型態的資料。而如圖四（C）等量特徵映射雖然沒有加入類別值的考慮，可是針對資料性質去
處理，可以提供一組較為合理的結果。當然非線性作法也面臨一些問題，如 outlier的影響，往往會破
壞使用非線性降維所重新建構的參數空間結構。如果我們可以加入類別值的考量，嘗試去降低 outlier
影響，使我們可以得到一個更為合理的資料結構。以下針對各種方法的比較，說明其優劣及適合的應
用範圍。 
−10 −5 0 5 10 15
20
40
−15
−10
−5
0
5
10
15
−15 −10 −5 0 5 10
−30
−25
−20
−15
−10
−5
0
5
10
15
 −60 −40 −20 0 20 40 60
−20
−15
−10
−5
0
5
10
15
20
 
（A） （B） （C） 
圖四、（A）原始資料分布於三維空間，（B）使用 SIR映射到二維的結果，（C）使用等
量特徵映射到二維的結果。 
−3 −2 −1 0 1 2 3
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
 
−4 −3 −2 −1 0 1 2 3 4 5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
 
（A） （B） 
圖五、（A）使用等量特徵映射將資料映射到二維的結果，（B）使用加入類別資訊的等
量特徵映射到二維的結果。 
  共 6 頁 第 6頁
 
的建出一個不錯的結構1。整體來說，加入類別點之後這些分類或分群的效果可以提升。 
 
−0.3 −0.2 −0.1 0 0.1 0.2 0.3 0.4 0.5 0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
 
 
Mac
Electronics
Religion
 
−3 −2 −1 0 1 2 3
−4
−3
−2
−1
0
1
2
3
 
 
Mac
Electronics
Religion
 
（A） （B） 
圖七、（A）多元尺度法映射至二維的結果，（B）等量特徵映射至二維的結果。 
 
   
（A） （B） （C） 
（A）為使用等量特徵映射對資料做降維後投影到二維的結果，我們把 kNN的 k取為 4。（B）則是使
用 SIR來做降維後投影到二維的結果（取 5%的點來找降維的矩陣）。在（C）我們則是利用Gaussian kernel 
來當作 KSIR的 kernel並把結果投影到二維，其中 Gaussian kernel中的參數γ 設為 0.00001。 
 
III. 實驗三： 
在這個實驗中，我們取用 Pendigit的 dataset中的前 1500筆資料(共 7494個)來實作等量特徵映射、
SIR、KIR三個方法。結果我們可以發現用等量特徵映射跟 KSIR的效果明顯比沒有核化的 SIR來
的好。基本的 SIR雖然各類別有分開但是卻不夠聚集，類別與類別的邊界都有混在一起的情形。
等量特徵映射跟 KSIR的結果雖然都有達到群聚的效果。且受到投影維度的選擇而比較不好比
較。但在演算的過程，等量特徵映射在計算一開始就需要計算兩兩之間的距離，這需要花費大量
的時間及記憶體。而 KSIR只需計算每個切片 ( slice ) 的平均點的兩兩之間的距離。所以在這方
面 KSIR明顯優於等量特徵映射。 
 
                                                 
1 “Mac”和“electronics”相對重疊的部分比較高，它們本身也是有些重疊性的概念。 
  共 6 頁 第 8頁
 
Neural Computation, 10: pp. 1299—1319, 1998. 
[19] B. Schoelköpf, C. Burges and A. Smola. “Kernel principal component analysis”, Advances in Kernel 
Methods - Support Vector Learning, pp. 327—352. MIT Press, Cambridge, 1999. 
[20] V. de Silva and J. B. Tenenbaum. “Global versus local methods in nonlinear dimensionality reduction”, 
Neural Information Processing Systems 15 (NIPS'2002), pp. 705—712, 2003. 
[21] J. B. Tenenbaum, V. de Silva and J. C. Langford. “A global geometric framework for nonlinear 
dimensionality reduction”, Science, 290(22): pp. 2319—2323, 2000. 
[22] UC Irvine Machine Learning Repository, Twenty newsgroups data set 
http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups 
[23] V. Vapnik. The Nature of Statistical Learning Theory, Springer Verlag, New York, 1995. 
[24] V. Vapnik. Statistical Learning Theory, John Wiley and Sons, New York, 1998. 
 
find novel attacks. As another feature of our system, our system can deal with the 
frequent changes of network environment. The framework gives the judgment of 
attacks adaptively. An ensemble of classifiers is adopted for the purpose. Accordingly, 
we propose a system mainly consisting of two components: one is for alarm filtering 
to reduce the number of false alarms and duplicated alarms; and one is the 
ensemble-based adaptive learner which is capable of adapting to environment 
changes through automatic tuning given the expertise feedback. Two datasets are 
evaluated. 
 
此次會議的 session 議題包含“Engineering of IDTs for KMS”, “Intelligent Data 
Processing Techniques for Decision Making”, “Decision Making in a Dynamic 
Environment”, “Decision and Health, Intelligent Systems: Foundations and 
Applications”, “Non-Classical Logics for Intelligent Decision Technologies”, 
“Knowledge - Based Interface Systems”, “IDT Based Anomaly Detection”, 
“Intelligent Data Analysis”, “Knowledge-Based Software Engineering and Medical 
Decision Support Systems”, “Rough Sets and Decision Making, Decision Making in a 
Changing Financial and Social Environment”等幾項。本人參加比較多及比較有趣
的項目為“Intelligent Data Processing Techniques for Decision Making”, “Decision 
Making in a Dynamic Environment”, “IDT Based Anomaly Detection”, “Intelligent 
Data Analysis”等幾項。其中“IDT Based Anomaly Detection”也是我們此次發表論
文的時段。 
此外，在此次會議中認識諸位國際學者，如 Kyoto University 的 Toyoaki 
Nishida 和 Waseda University 的 Junzo Watada。另外此會議本身的舉辦經驗也值得
探討以作為日後台灣舉辦相關研討會等的依據。 
 
參考資料 
[1] H.-S. Lin, H.-K. Pao, C.-H. Mao, H.-M. Lee, T. Chen, Y.-J. Lee “Adaptive 
Alarm Filtering by Causal Correlation Consideration in Intrusion Detection”, 
First KES International Symposium on Intelligent Decision Technologies, IDT 
2009. 
 
2  
Keywords: Intrusion detection, alarm filtering, false alarm, adaptive learning, en-
semble. 
1. Introduction   
  Over the last couple of decades, the intrusion methods are getting sophisticated 
and diversified.  Variety of rootkits and exploit codes are easily obtained for the 
hackers to attack the systems.  Therefore, individual data can be illegally read or 
overwritten by intruders.  Many different Intrusion Detection Systems (IDSs) have 
been provided to detect those malicious attacks.  However, one of the weakest 
points with those IDSs is the problem of massive false alarms (or false positives).  
As revealed in several reports, IDS usually generates nearly 99% of false alarms in 
the detection [1, 5].  On the other hand, various alarms, which could be issued by 
naïve decision rules may come from the same unique attack.  For instance, several 
minor alarms may suggest a multi-step attack.  A clever detection system should 
be able to single out the reason for further automatic or non-automatic analysis.  
Overall, false alarms or duplicated alarms can waste significant time from human 
analyzers.  Without considering those issues, an IDS can be virtually useless.  The 
problem is more serious when no enough human analyzers can be assigned for 
further analysis of the generated alarms.  E.g., a personal IDS will not afford such 
overhead.  In this work, we propose an alarm filtering (AF) framework which can 
significantly reduce these two kinds of alarms: false alarms and duplicated alarms.  
The framework considers causal correlation between alarms and alarms will then 
be issued with high accuracy and no redundancy.  As another important feature, to 
apply our system to real network, we would like to make the final decision of 
alarm classification adaptively to different periods and to different environment.  
An ensemble of classifiers called ensemble-based adaptive learner (EAL) will be 
adopted to adjust the prediction precision and sensitivity for the system according 
to network conditions.  The feedback from alarm analysts will be used to tune the 
setting periodically. 
To reduce the false alarms and duplicated alarms, our AF system considers 
causal correlation between several alarms when they are either temporally corre-
lated or associated with a single attack.  Alarm correlation [12, 13] has been used 
in discovering the intentions or root cause of the attackers [3] and how they 
achieve their goals [8], i.e. the attack methods.  Based on our observations, single 
minor alarm in small scale may be confusing, but minor alarms collected as a 
whole may indicate a serious attack. When lacking of considerations in large 
scale, some alarms may be mislabeled, so called the false alarm problem.  On the 
other hand, multi-step attacks often trigger a bunch of alarms in a sensitive system 
to downgrade the performance of the system, so called the duplicated alarm prob-
lem.  To deal with these two problems, one has to consider causal correlated 
alarms instead of a single alarm.  Note that reduction of false alarms may lower 
the detection sensitivity (also known as recall).  A trusted system must still be sen-
4  
even different sites.  Using the proposed ensemble-based adaptive learner (called 
EAL) is eligible to give robust performance on prediction as time goes by or for 
different network environment.  It is understood that the network data are large-
scale stream data, and usually highly unbalanced between attacks and normal data.  
Besides, most attacks happen in a continuous fashion in a very short period of 
time.  To deal with those concerns, our EAL is proposed based on entropy compu-
tation, also inspired by AdaBoost [10].  Also, some aging effect is added to the 
system.  By our approach, the rare attacks are not to be overlooked and can con-
tribute some to our system.  Other than adapting to time, we can also make our 
system adaptive to different commercial organizations.  We will take the risk of 
assets as the input for further system improvement.  Overall, we aim at designing a 
system which can be applied to real environment. 
2. Feature Extraction, Alarm Filtering and Adaptation 
    In this section, we discuss our proposed system in full details, as illustrated in 
Fig. 1.  Different from most IDSs, we focus on the reduction of false alarms and 
duplicated alarms after IDSs issue alarms.  To deal with real network data, we also 
consider an adaptive system where the attack call may depend on the time infor-
mation.  Our system can take alarms from several sources, e.g., distributed IDSs, 
as the input.  Basically, the system can be separated into three parts: Feature Ex-
traction Unit, Alarm Filtering Unit, and Ensemble-based Adaptive Learning Unit. 
We proceed to give details for those different units 
2.1 Feature Extraction 
Many factors combined together to decide which alarm comes from a true at-
tack.  They include causal correlated alarms, unusual changes of frequency in 
alarm issuing, and asset information, etc.  That is, the feature extraction set is be-
yond the common attributes of intrusion alarms, such as packet size, signature 
names, IP addresses, port numbers and so on.  We need to know that, in some 
cases, the IP address may limit the generalization ability of the model [3].  Op-
posed to that, the properties of hosts are more strongly relevant to attacks.  There-
fore, an IP address is replaced by its corresponding asset information.  Below, we 
illustrate those features one by one. 
Causal Alarm Features.  Our idea is to correlate the alarm in the previous step 
and the alarm at this moment as causal correlation features.  As we can imagine, 
the features will help us to detect a multi-step attack.  More than that, the features 
also provide more information on recognizing alarms which may be from novel at-
tacks.  For instance, if an alarm never happened in historical data, it is still possi-
ble to be classified correctly according to the conditional probability of the alarm 
after observing the pre-step alarms. To be more specific, those features consist of 
6  
data.  Moreover, sample re-weighting, like AdaBoost, and complementary learn-
ing from previous wrongly predicted examples, strongly enhance the robustness of 
our system.  The function is listed as follows: 
z Z 1
( ) arg max ( , , ) ( , )
m
final k k k
k
h x a v h x zϕ λ τ
∈ =
= ⋅ ⋅∑                                                (2) 
Where hfinal(。) is the finial hypothesis of committee decision with m member 
classifiers, hk( 。 ) represents the hypothesis of the k-th day, 
(1 ( ( ))) log((1 ) / )k k k kv entropy P d ε ε= + ⋅ −  is the corresponding voting weight de-
cided by its error rate ε, and the entropy defined by, 
( ) ln( ) (1 ) ln(1 )entropy P P P P P= − − − − ,  indicating the information of the k-th 
training data point for the distribution. The ( )kP d  is the portion of true alarms in 
a training set.  Finally, in order to being adaptive to changes, the Memory Decline 
Ratio (MDR) listed as follows will be used: 
exp(- ( - ))( , , )
1 exp(- ( - ))
k
k k
k
aa
a
λ τϕ λ τ λ τ= +
 ,                                                                    (3) 
which is inspired by aging-forgetting mechanism and modified by sigmoid func-
tion. It is employed to tune the voting weight through the time in each individual 
classifier. The forgetting slope λ, is set for how fast to drop out a useless classifier 
with tolerating time τ.  Setting the pair of parameters will be discussed in experi-
ment and, actually, depends on the degree of concept drift or change in each data-
set. 
3. Experiments 
We have built a prototype system to demonstrate the proposed approach that is 
able to filter the alarms of both kinds, the false alarms and the duplicated alarms.  
Below, we discuss different measurement on the system of alarms filtering such as 
False Positive (FP), which analysts have to pay extra effort with, and True Nega-
tive (TN), which means that filtered alarms are indeed not correlated to attacks.  
Of course, filtering out the true alarms associated to attacks is more serious than 
anything else, e.g. achieving high TP rate.  Moreover, the ability to identify novel 
alarms is also taken into account.  There are two experiments designed for demon-
stration. One is to evaluate that the proposed feature set including the causal corre-
lation features is able to enhance the performance of intrusion detection.  The sec-
ond experiment is to compare with different learning schemes to support that our 
approach is able to filter out false or duplicated alarms and effectively adapt to 
network change especially when novel alarms happen. 
Novel alarms make operators tune the setting of IDSs from time to time.  The 
novel alarms also make pre-trained model useless after a while.  Hence, we espe-
cially discuss the ability of our framework to identify novel alarms, meaning that 
our AF is able to give the correct predicted class on an unseen alarm under an ac-
ceptable level of false positive rate.  By means of Receiver Operating Characteris-
tic (ROC) curve, the False Positive (FP) rate referring to cost and the True Posi-
8  
Table 2  Performance Test with Different Feature Combinations.  The performance comparison is 
TP rate (detection rate) vs. FP rate (cost).  The detection rate of novel alarms is specifically dem-
onstrated for revealing the ability to detect novel alarms with different feature combinations.  Ba-
sic feature set is the original attributes generating from Snort IDS but excluding source and desti-
nation IP addresses. 
Cost All Alarms Novel Alarms Dataset Feature Combination FP rate TP rate TP rate 
Correctly 
Filtered 
Basic 18.83% 82.45% 85.76% 89.8% 
DARPA 
Causal 5.26% 95.08% 87.36% 97.34% 
Basic 37.19% 64.01% 87.58% 98.73% A-SOC 
Causal 28.03% 62.36% 88.68% 98.84% 
 
Note: Our experiment takes all alarms as the input.  Correctly Filtered Alarms represent the re-
labeled false alarms that are indeed not associated to attacks and can be filtered out appropriately.  
variance frequency has the best performance, higher detection rate and lower FP 
rate, especially on detecting novel alarms.  Moreover, adopting the causal correla-
tion features to classify SOC dataset causes that the false positive rate is greatly 
reduced about 10%.  The reason is that the SOC dataset gathered in 2007 has more 
sophisticated multi-step attacks than DARPA 1999.  Therefore, the causal correla-
tion feature set has greater enhancement on SOC dataset than on DARPA 1999. 
Cost and Detection Rate.  To evaluate our approach on the tradeoff of cost and 
detection rate, our proposed EAL are compared with two other generic schemes in 
the second experiment.  The first controlled scheme is that the decision model 
only keeps the last classifier in alarm ensemble classifiers for prediction. The sec-
ond one is to keep all previous trained classifiers and combine them with the same 
weight in alarm ensemble classifiers for prediction.  The comparison of ROC 
curve is shown in Fig. 2, which demonstrates that our approach receives the larg-
est area-under-curve (AUC) values in both of the DARPA and A-SOC datasets.  
The ROC curve provides analysts the view of how much the cost has to pay if the 
model can identify alarms including novel alarms, as shown in Fig 2(a) and 2(b).  
The cost implicitly means that analysts have to spend their time to pick out the 
false alarms.  Obviously, the high cost is unpractical when the system is operated 
on real environment.  All comparison results are illustrated in Table 3.  Our pro-
posed EAL also performs very well on correctly filtering alarms without sacrific-
ing much to deal with novel or rare true alarms.  In traditional methods on false 
alarm reduction, assessing risk through an asset table or setting a correlation rule 
to recognize true alarms is possible to ignore novel alarms.  Therefore, they can 
only aware of known attack and lack of ability to defense from a new threat.  
However, in our experiment, it actually shows the ability to find out novel alarms. 
Aggregation Duplicated Alarm.  There are 55,473 individual alarms in 
DARPA dataset grouped into 11,197 groups, including only two impure groups, 
which include true and false alarms in the same group.  The reduced amount sig-
nificantly relieves about 75% of overall alarms.  On the other hand, the 308,063 
