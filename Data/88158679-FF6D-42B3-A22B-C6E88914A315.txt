Auto-generation of Relevant Concepts for Organizing Web Images 
 
中文摘要 
基於網路上影像資訊成長迅速，本研究的目標是發展適合瀏覽搜尋結果的網路影像檢索技
術，我們利用網路影像檢索系統所蒐集的使用者查詢記錄，自動產生查詢關鍵詞的相關概
念，以期在語意上可自動組織搜尋結果。部份結果已發表於相關研究領域。 
 
Abstract 
With rapid growth of digital images on the Web, automatic retrieval of Web images is significant, but very 
challenging for developing more effective search technologies to benefit image browsing. This project is 
intended to investigate efficient techniques helpful for the organization of search-result images based on 
search engines’ query logs. The techniques try to generate the relevant concepts of a given image query 
using the query logs. Partial research results have been published in some related fields. 
 
Keywords: Web-image retrieval, relevant concepts generation, image browsing 
 
1. Introduction 
The increasing demand for high-performance Web image search engines is being driven by the rapid 
growth in the number of Web users and in the availability of image collections on the Web. The 
techniques used by most search engines to perform keyword-based search over Web images are similar to 
those used in textual information retrieval. The images whose textual information — including filenames, 
captions, HTML <ALT> tags, and surrounding texts — match the queries are ranked and returned back to 
users. However, keyword-based image search has not proved to be successful in every case, especially 
when users’ queries are short. To illustrate, we take the query “building” as an example: Google Images 
retrieved about three millions of images. Suppose we focus on only top–1% of images, however, more 
than 30,000 images are regarded as highly relevant and such numerous result images are impossible for 
users to go through. The returned images are not well organized in a conceptually meaningful way; as a 
result, users may find it difficult to understand the structure of the concepts related to the query. 
 
To assist users either efficiently finding desired images from retrieved result or effectively refining the 
query, this project presents a new approach for them to find the images they want in a conceptually simple 
way that organizes retrieved images on the basis of auto-generated relevant concepts. We define the terms 
concept and relevant concept as follows. For each query, it represents a concept users want to find, even 
for unique queries (specific person, place, or objects) because each retrieved image represents part of the 
form, property, class, etc., of the query so that all of them form a concept of the corresponding query. And 
a relevant concept is the subset of the concept that describes the form of a query (e.g., “building 
wallpaper” and “cartoon building”), the property of it (e.g., “tall building” and “modern building”), the 
class of it (e.g., “office building” and “school building”), and so on.  
 
To contrast with traditional image search results, the result of querying “building” is shown in Figure 1a. 
As we can see, the purpose of the proposed approach is to generate relevant concepts, such as “office 
building,” “tall building,” “school building,” and “modern building,” for the given query “building.” The 
(Barnard et al., 2001; Mukherjea et al., 1999) took into account both of the textual and visual information 
for clustering images into topics. These works exploit various characteristics of Web images to cluster 
visually-similar or semantically-relevant images. They require, however, much effort in image processing, 
link analysis and textual feature extraction, which is not the case in our approach. In this project, we focus 
mainly on clustering retrieved images using users’ queries obtained from search engine logs. 
 
3. The Proposed Approach 
Figure 2 shows the overview of the concept of the proposed approach. Here we briefly explain the 
function of each stage (functional block). First, in the Relevant Concept Generation stage, a large numbers 
of concepts are found/derived from a concept pool and are treated as relevant concept candidates, where 
the concept pool might be built from query logs, search-result snippets, Web image annotations, etc., and 
can be seen as the knowledge base. Next, a Ranking/Filtering process is applied so that each candidate is 
assigned a score, called interestingness, to estimate the degree of users’ interest and to prune candidates 
irrelevant to q. Finally, we have the sorted relevant concepts, R(q), of a given concept q after the 
Ranking/Filtering stage so that we can proceed Relevant Image Rendering process that performs image 
search q by showing its relevant images with concepts in R(q). We then elaborate the stages. 
 
Figure 2: The overview of the proposed approach. 
 
Relevant Concept Generation 
Since the problem we deal is finding relevant concepts, the input query q can be seen as the input concept 
by nature. We use the term query and concept alternatively. The proposed approach of relevant concept 
generation task is illustrated in Figure 3. First of all, we can see that there are three “concept pools” in the 
figure. They are identical and the copies are just for illustration use. The concept pool is a unified data 
structure consisting of a large numbers of concepts extracted mainly from query logs. Since these concepts 
are originated from users’ queries, it is reasonable to say that they are more meaningful to users than 
ordinary term sequences are. Relevant concept candidates are obtained with two different strategies: by 
elaboration and by inheritance, described, respectively, later. The result is the union of both strategies. 
 
Relevant Concept Ranking and Filtering 
The major challenge of the ranking task is how to quantify the interestingness of a candidate. We assume 
that the popularity, namely, the number of occurrences of a candidate in the concept pool, reflects users’ 
interests. For an unseen candidate, we propose a measure called potential popularity. Consider the case 
where a candidate is generated by inherited pattern. In a concept-class, there may be more than one 
concepts derive that pattern; such concepts are called voters. For example, suppose “cute dog” and “cute 
cat” are in the same concept class, then both are voters of the pattern “cute_.” Given an input concept q 
 We list the average scores for each query-focused question and performance-related question in Figure 4, 
where –NE stands for named-entities queries, –Common stands for common queries, and –All stands for 
The results show that, in all three questions, the scores of “GI-All” are lower than those of “LI-All;” 
however, the difference in Q2 is not as great as that in the question Q1 and Q3. This is probably because 1) 
it is easier for the users to understand the structure of the search-results from a categorized view and thus 
easier to refine their queries, 2) it takes less effort for users to refine their queries according to the text 
descriptions rather than image content, and 3) the text descriptions of images returned by LI, primarily 
from query logs, contain less noise than the surrounding texts returned by GI. In the first 4 rows, the 
performance of both LI and GI on named-entities are lower than that on common queries. We also find 
that the difference between the scores of “GI-NE” and those of “GI-Common” is not obvious, while 
“LI-Common” outperforms “LI-NE” significantly. An interpretation for this phenomenon is that 
categorized search-results of a common query may greatly improve browsing experience because the 
images of a common query, such as “flower” or “cake”, contain a great number of diverse relevant 
concepts from which users can easily distinguish. Concerning the response time, GI gets a score of 4.7, 
while LI gets only 3.35 in G1. Besides, GI is considered to be easier to use (4.3 in G4) and to have its 
search results arranged in a visually–comfortable way (3.57 in G6.) On the contrary, LI is more suitable 
for browsing task than GI is (4.09 in G2) and organizes the search-results based on their semantics (4.04 in 
G5.) 
 
(a) Query-focused questions.                       (b) Performance-related questions. 
Figure 4: The user study results. 
 
5. Conclusions 
Organizing search results of images on the Web in a conceptual meaningful way both facilitates browsing 
efficiency of users and assists users sharpen their need. In this paper, we have proposed a new direction 
toward image search as well as an approach that organizes retrieved images with auto-generated relevant 
concepts (Chen et al., 2007; Cheng et al., 2007). The preprimary user study demonstrates the feasibility 
and the effectiveness of the approach in improving Web image search. 
 
 可供推廣之研發成果資料表 
□ 可申請專利  ■ 可技術移轉                                   日期：2008 年 10 月 31 日 
國科會補助計畫 
計畫名稱：以自動產生相關概念為基礎之網路影像檢索技術 
計畫主持人：鄭卜壬 
計畫編號：96-2221-E-002-225-      學門領域：WEB 技術
技術/創作名稱 
網路影像之自動分群技術 
發明人/創作人 簡立峰、鄭卜壬 
技術說明 
中文： 
本技術主要利用網路影像檢索系統所蒐集的使用者查詢記錄(query 
log)，自動產生查詢關鍵詞的相關概念，以期在語意上可自動組織
網路影像搜尋結果，例如：關鍵詞「項鍊」的相關概念可能包含「鑽
石項鍊」及「水晶項鍊」，所產生的相關概念一方面可幫助使用者
瀏覽相關主題的影像，縮小檢索範圍，另一方面亦可建議使用者如
何進一步查詢。 
英文： 
This technology is intended to be helpful for the organization of
search-result images based on search engines’ query logs. The
technique tries to generate the relevant concepts of a given image query 
using the query logs. For example, suppose we are given the query 
“necklace.” Its relevant concepts might include “diamond necklace” 
and “crystal necklace.” The generated relevant concepts could be used 
to refine the original query and classify the retrieved images 
effectively. The achieved results with the research are expected can 
improve search technologies in image search-result browsing. 
可利用之產業 
及 
可開發之產品 
網路影像檢索系統 
數位典藏系統 
技術特點 
過去相關技術需要大量人力事先建立所有影像的主題分類架構，或
是利用影像特徵動態分群視覺上相似的影像；人工的分類方式準確
度高，但增加維護成本，以視覺內容分群的方式，雖可自動化完成，
但在語意分類上卻無法滿足使用者的要求。 
本技術從使用者查詢記錄自動產生出的查詢詞相關概念，不但較接
近使用者的查詢習慣，更貼近使用者在影像上的語意分類法則。 

SIGIR 2008 Conference Report 
by林怡君 
 
今年的 SIGIR是在新加坡舉辦，首先，會場是在很高級的飯店裡舉辦，
一踏進會場就看到許多新加坡大學的學生們在門口招待，與會的人也非常
多，看得出來的確是場很盛大、讓人重視的研討會，讓我不自覺的再次佩
服明峰學長的厲害。 
 
研討會的前四天是 paper session，最後一天則是 workshop。首先請到
了許多重量級的大老們來演講，從他們的言談裏明顯的感覺出他們的豐富
學識涵養，透過他們的介紹，讓我們迅速進入 Information Retrieval 的各領
域，包括了 web mining、content-based retrieval等，這時不免也慶幸自己
大多數的術語都聽得懂，這兩年的研究也不算白做了。不過聽報告之餘，
也讓我深覺自己的英語能力實在太爛了，很多時候都是鴨子聽雷，看來，
我絕對有必要要好好加強英語能力了!  
 
聽完了這幾天的研討會，讓我有印象的有以下的報告。首先，這還是
我第一次聽明峰學長用英文報告自己的論文，感覺跟以前聽的又不太同了，
主題是 A Study of Learning a Merge Model for Multilingual Information 
Retrieval，主要是探討Multilingual & Crosslingual Retrieval，雖然與學長屬
於不同研究室，但是聽到學長的報告一直讓我想起自己的研究論文，雖然
是不同層面的應用，但是本質應當是相同的，差別是我的論文是針對每個
查詢詞做分析應用，但是學長的論文則是將其 feature應用在跨語言的搜尋
模型，這也讓我深覺研究的有趣，只是換了一層包裝就能呈現出不同的面
貌，無怪乎有那麼多人沉醉在研究上了。可是，如何將其包裝成大家都喜
歡的樣貌也是一大學問吧! 聽完了學長的演講，讓我有很大的衝擊，真不
知道我是不是也有那站在台上的一天呢? 現在想到覺得很害怕又恐懼…。 
接下來，在 web search的 session中，聽到了有趣的應用，將現今的 retrieval 
model應用在部落格上，最近幾年部落格很火紅，如果真的像此篇論文所
說，將部落格的查詢做得更好，想必絕對是很棒的應用，或許也因為這樣
有趣的創意讓此篇論文獲得迴響，這也說明了在研究中，創意不可缺，這
是很重要的! 看完了這些論文發覺，在 IR上，實用果然還是最重要的，即
使是理論為基礎，大家也要眼見為憑才算是真的，所以，在這些論文裡都
看得出來作者的用心苦心，那些實驗量都是非常大的，只有理論跟實際相
配合，如此才能在此研討會大放異采吧! 這也讓我看出我現在的能力實在
太不足了，與他們的距離大概要用鴻溝來計量吧。 
  
 最後一天的是 workshop，workshop相較於先前，有趣多了，可能是因
