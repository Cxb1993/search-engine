行政院國家科學委員會專題研究計畫成果報告 
 
以特徵為基礎之三維材質合成 
A Study on Feature-Based 3D Texture Synthesis 
 
計畫編號：NSC 100-2221-E-239-034- 
執行期限：100 年 08 月 01 日至 100 年 08 月 31 日 
 
中英文摘要 
我們提出一個利用權重彩色和灰階共現機
率來做三維材質合成的方法。我們首先利用
彩色和灰階共現機率這兩種方法來擷取輸
入貼圖中的特徵。其中彩色的部分使用表面
向量值取代傳統只用色彩值作為特徵向
量，而灰階共現機率可隨輸入貼圖的特性來
選擇不同的統計量作為特徵向量。再預先計
算輸入圖片中的特徵所組成的相似集和三
維候選點來做三維材質合成。接著利用三維
金字塔合成方法來完成三維材質的合成。 
 
關鍵詞：計算機圖學; 材質; 三維材質; 材質
合成; 材質分析 
 
We introduce a 3D texture synthesis 
method using weighted color and grey level 
co-occurrence probabilities. We use color and 
grey level co-occurrence probabilities to 
extract the features. Appearance vectors are 
used to replace RGB color values. And 
various statistics are used according to the 
characteristic of the input 2D texture. We will 
achieve 3D texture synthesis by using a 
pre-computed similarity set and 3D-candidate 
set. Then we can synthesize desired 3D 
textures by applying the 3D pyramid synthesis 
method.  
 
Keywords：Computer Graphics; Texture; 3D 
Texture; Texture Synthesis; Texture Analysis 
 
一、 前言與研究目的 
以目前來講，在 2D 上許多材質合成的
效果都不錯。然而，要產生 3D 材質仍然有
很大的改善空間。對於 3D 表面貼圖，現在
有許多不同種類的技術例如：材質貼圖，程
序化貼圖以及影像式貼圖。 
對於 3D 表面貼圖來說，材質貼圖是最
簡單的方法，但是結果的品質並不好。因為
有可能受到像變形、裂痕以及多餘的裂縫等
等問題。程序化貼圖可以解決變形跟裂痕方
面的問題。然而，它仍然有一些缺點。程序
化貼圖的模型只能限制在某些類型的材
質，例如：大理石。除此之外，使用者可能
得花時間去了解以及控制它的參數。實驗的
結果往往是由設計者決定的。影像式貼圖可
以合成更多種類的材質，但是它沒辦法處理
較大型的結構化材質，例如：磚塊。當曲線
過大時，它仍然會有變形以及裂痕的問題。
除此之外，影像式貼圖具有不可再度使用
性，也就是說，當一個材質產生出來給一個
表面上使用過後，就不能再被其他表面所使
用。如果使用三維材質的話，便可解決以上
兩種問題。根據 Peachey 和 Perlin 於 1885
年所提出的方法，三維材質就像三維空間中
的有色區塊，用來表示真實世界中的物質。
藉由使用三維材質的方式，使用者不用去找
出需被貼圖的物體表面之參數。除此之外，
三維材質也提供內部體積的材質資訊。 
先前的方法適用於各種各樣的材質。然
而，品質問題仍然存在。進一步改進往往需
要更可靠的材質特徵提取。在本計畫中，我
們提出了全新的以特徵為基礎三維材質合
成演算法。我們進行以隨機性材質特徵為基
礎之三維材質合成研究，利用色彩分析的方
法，得到色彩特徵向量。此外，我們利用灰
階分析的方法—灰階共現矩陣以及權重灰
階共現矩陣進行分析，取得統計特徵向量。
最後，我們金字塔三維合成法，使用鄰近點
比對法讓結果更貼近範例。 
 
二、 文獻探討 
現在要來介紹一些不同的實體材質合
成法。Jagnow et al. 於2004年針對實體材質
提出了立體量測法。這個方法使用了傳統的
立體量測的技巧，從二維的影像中合成出三
維的實體材質。他們先對球狀的粒子合成出
實體材質，進而發展到可以針對任意形狀的
粒子合成。方法中需要用到橫切面的影像來
記錄二維切面中不同大小的圓的分布情
形，並且建立起二維切面中圓分布密度和三
維粒子分布密度的對應關係。使用者可以利
用此粒子分布密度，藉由一次增加一顆粒子
一般量化的數量介於 16~64 之間得出來的
成效較明顯，若超過 64 則會過大，我們
選定中間的值，假設 G=32 作為量化石的
參數設定。 
 3
測試影像量化完成後，接下來設定
(i，j，d，a)參數，兩像素間的距離 d=1，
角度 a=0°，以此將灰階共現矩陣計算出
來。我們根據量化數 G=4，產生一個 G×
G 的新矩陣，並以列為基準點像素值 i，
行座標則為鄰近點像素值 j，以此方式將
原矩陣的像素組灰階值出現之次數記錄
到新的矩陣當中。像素組灰階值出現的次
數紀錄完成後，接著透過公式將條件聯合
機率 G 1
, =0
P
C
P
−= ∑
ij
ij
ij
i j
計算出來，公式中分子部
分的 Pij 是代表矩陣中基準點的灰階像素
值 i，與相鄰點的灰階像素值 j 共同產生的
次數。分母的部分則為矩陣中 i 與 j 所產
生的總組合次數。 
 
 統計特徵計算 
經過一連串運算取得灰階共現矩陣
後，通常都會根據不同使用需求，選擇適當
的統計測量方式來求取統計特徵。由於各種
統計特徵所具備的特性都不相同，統計特徵
的優劣會有著相互影響的問題，因此雖然結
合多種統計特徵所得出的特徵向量所擷取
出的資訊較多，但各個統計特徵的優劣也存
在著相互影響的問題。有鑑於此，我們試著
將各個統計方式分開進行測試，進而選取在
分析上有較佳效果的特徵值。各種統計特徵
方法所代表的意義說明如下： 
(1) 能量(Energy，Ene) 
或稱為角二次矩或是一致性，主要是用
來衡量材質中的一致性或均勻性，當影像材
質越均勻或一致時，灰階共現矩陣中的值就
會集中在少數幾個元素上，則 ASM 的值便
越大。 
=0 =0
Ene C=∑∑N N ij
i j
 
(2) 差異度(Dissimilarity，Diss) 
差異度是用來度量影像中灰階值的不
相似程度。此統計參數對影像的線條、色調
有較高的敏感度，可表現灰階值於空間中的
排列情況。 
=0 =0
Diss C= −∑∑N N ij
i j
i j  
(3) 同質度(Homogeneity，Homo) 
或稱反差矩此項參數在計算 Cij 矩陣中
元素聚集在主對角線附近程度，通常影像的
對比越弱，獲得的反差矩則越大。 
( )2=0 =0
1Homo C
1
= + −∑∑
N N
ij
i j i j
 
(4) 熵(Entropy, Ent) 
此項指標之特性與能量的性質相反，其
乃是用來度量材質的複雜程度或 Cij 矩陣中
元素排列的混亂程度。當影像中的圖樣越是
隨機時，則材質複雜，其 Cij 矩陣中各元素
越相等，其值就越大。從概念上來說，熵跟
能量是一種反向的高相關統計量。 
=0 =0
Ent C log C= −∑∑N N ij ij
i j
 
(5) 對比度(Contrast，Con) 
對比度是反應影像中的對比強烈度，並
顯示出 Cij 矩陣中中的元素於對角線的集中
狀態。 
( )2
=0 =0
Con C= −∑∑N N ij
i j
i j  
(6) 平均值(Mean，M) 
即移動視窗中影像灰階值之平均值。其
中 N 為視窗大小， 為影像灰階值。 ijS
0 0M = == ×
∑∑N N ij
i j
S
N N  
(7) 標準差(Standard Deviation，SD) 
即移動視窗中影像灰階值之標準差。其
中 N 為視窗大小， 為影像灰階值。 ijS
( )2
0 0SD
1
= =
−
= × −
∑∑N N ij ij
i j
S S
N N  
 
 金字塔三維合成法 
1985. 
[PCOS09] Pietroni, N., Cignoni, P., Otaduy, M., and 
Scopigno, R., “A survey on solid texture 
synthesis”, IEEE Computer Graphics and 
Applications, pp. 1-1, 2009. 
 5
[QY07] Qin, X., and Yang, Y. H., “Aura 3D textures”, 
IEEE Transactions on Visualization and Computer 
Graphics 2007, vol. 13, no. 2, pp.379-389, 2007. 
[ST99] Soh LK, Tsatsoulis C, “Texture analysis of 
SAR sea ice imagery using gray level 
co-occurrence matrices”, IEEE Trans. Geosci. 
Remote Sens., 37:780-794. 
[TOII08] Takayama, K., Okade, M., Ijirl, T., and 
Igarashi, T., “Lapped solid textures: filling a 
model with anisotropic textures”, ACM 
SIGGRAPH 2008, vol. 27, no. 3, 2008. 
[TA03] Taponecco, F., Alexa, M., “Vector field 
visualization using Markov random field texture 
synthesis”, Proceedings of Eurographics / IEEE 
TCVG Symposium on Visualization, 195–202, 
2003. 
[WZYG10] Wang, L., Zhou, K., Yu, Y., Guo, B., 
“Vector solid textures,” ACM Transactions on 
Graphics (SIGGRAPH 2010) 
[YHBZ01] Ying, L., Hertzmann, A., Biermann, H., and 
Zorin, D., “Texture and shape synthesis on 
surfaces”, Eurographics Workshop on Rendering 
2001, vol. 12, pp. 301-312, 2001. 
[ZG03] Zelinka, S., and Garland, M., “Interactive 
texture synthesis on surfaces using jump maps”, 
Eurographics Workshop on Rendering 2003, vol. 
14, pp. 90-96, 2003. 
[ZZV*03] Zhang J., Zhou K., Velho L., Guo B., and 
Shum H., “Synthesis of progressively-variant 
texture on arbitrary surfaces,” ACM Transactions 
on Graphics (TOG), vol. 22, iss. 3, 2003. 
 
 
(圖一) 
 
 
 
 
University and Adjunct Professor, COEP   
 
而技術場次(Technical Session)包括八個場次如下： 
z ICSCA 2012 Session 1 
共 5 篇論文 
z ICSCA 2012 Session 2 
共 5 篇論文 
z ICSCA 2012 Session 3 
共 5 篇論文 
z ICSCA 2012 Session 4 
共 5 篇論文 
z ICSCA 2012 Session 5 
共 5 篇論文 
z ICSCA 2012 Session 6 
共 5 篇論文 
z ICSCA 2012 Session 7 
共 5 篇論文 
z ICSCA 2012 Session 8 
共 7 篇論文 
 
    
 
會議地點 
 
二、與會心得 
此趟參加 ICSCA 2012 國際會議使我受益良多，讓我看到各國學者軟體與計算機應用研究的熱情，
 2
The 2012 International Conference on Software and Computer Applications (ICSCA 2012) 
- 1 - 
Notification of Acceptance of the ICSCA 2012 
June 9-10, 2012, Singapore 
http://www.icsca.org  
      
 
Dear Huei-Yung Lin, Chin-Chen Chang and Chia-Hao Hsieh, 
Paper ID :  S037 
Paper Title : Cooperative Resizing Technique for Stereo Image Pairs 
 
Congratulations! The review processes for The 2012 International Conference on Software and 
Computer Applications (ICSCA 2012) has been completed. The conference received submissions 
from nearly 15 different countries and regions, which were reviewed by international experts, and 
about 100 papers have been selected for presentation and publication. Based on the 
recommendations of the reviewers and the Technical Program Committees, we are pleased to 
inform you that your paper identified above has been accepted for publication and oral presentation. 
You are cordially invited to present the paper orally at ICSCA 2012 to be held during June 9-10, 
2012 in Singapore. 
 
All papers for the ICSCA 2012 will be published in the IPCSIT (ISSN: 2010-460X) as one volume, 
and will be included in the Engineering & Technology Digital Library, and indexed by EBSCO, 
CNKI (中国知网), WorldCat, Google Scholar, and sent to be reviewed by Ei Compendex and ISI 
Proceedings. Selected papers will be recommended to be published in the Journals. 
 (Important) So in order to register the conference and have your paper included in 
the proceeding successfully, you must finish following SIX steps. 
1. Revise your paper according to the Review Comments in the attachment carefully. 
2. Format your paper according to the Template carefully.  
http://www.icsca.org/IPCSIT.template.doc (DOC Format)   
3. Download and complete the Registration Form. 
http://www.icsca.org/reg.doc  
4. Finish the payment of Registration fee. (The detailed information can be found in the 
Registration form)  
http://www.icsca.org/reg.doc 
5. Finish the IACSIT Copyright Form 
http://www.icsca.org/Copyright.doc  
Cooperative Resizing Technique for Stereo Image Pairs 
Huei-Yung Lin 1, Chin-Chen Chang 2 +  and Chia-Hao Hsieh 1 
1 Department of Electrical Engineering 
National Chung Cheng University, Minhsiung, Chiayi 621, Taiwan 
2 Department of Computer Science and Information Engineering 
National United University, Miaoli 360, Taiwan 
 
Abstract. In this paper, a cooperative stereo image resizing technique is presented. The proposed approach 
first extracts three feature maps: disparity map, gradient map and saliency map. After that, the proposed 
approach constructs an importance map which combines the three feature maps by the weighted sum. Finally, 
the proposed approach constructs the target image using the seam carving method based on the importance 
map. The experimental results show that the proposed approach performs well in terms of the resized quality. 
Keywords: Image resizing, Image retargeting, Stereo image, Feature map, Seam carving  
1. Introduction 
Non-standard screen aspect ratios will be applied more extensively because of cellular phones, portable 
multimedia players and so on. In such cases, different image sizes are required to adapt to the display devices. 
Scaling and cropping are two standard methods for resizing images. Scaling resizes the image uniformly 
over an entire image. However, when the display screen is too small, the image loses some of its detail in 
adjusting to the limitations of the display screen. Cropping resizes the image by discarding boundary regions 
and preserving important regions. This method provides a close up of a particular image section, but prevents 
users from viewing the rest of the image. 
Recently, several retargeting techniques [1, 5, 6, 7] for resizing image based on image contents has been 
proposed. These methods require a certain understanding of image content and do not adjust the size of the 
image as a whole. Retargeting preserves important regions and discards less important regions, to achieve a 
target image size. Since the creation of stereo images for a 3D display from the 2D images is important, 
developing techniques for stereo image retargeting is essential. 
In this paper, a stereo image resizing technique is proposed. The proposed approach first extracts three 
feature maps: disparity map, gradient map and saliency map. After that, the proposed approach constructs an 
importance map which combines the three feature maps by the weighted sum. Based on the importance map, 
the important regions are preserved and less important regions are discarded. Finally, the proposed approach 
constructs the target image using the seam carving method [1] based on the importance map. The 
experimental results show that the proposed approach resizes stereo image pairs effectively. 
 
2. Related Works 
Avidan and Shamir [1] proposed a method for adjusting image size based on image content. They 
                                                          
+  Corresponding author. Tel.: + 886-37-381893; fax: +886-37-354326. 
   E-mail address: ccchang@nuu.edu.tw. 
 
96
       2012 International Conference on Software and Computer Applications (ICSCA 2012) 
IPCSIT vol. 41 (2012) © (2012) IACSIT Press, Singapore
The Sobel calculation on original image I results in the gradient map. Considering the direction of 
image resizing, the proposed approach offers weight individually to the Sobel horizontal and vertical 
directions as  
22
)1(
y
Iw
x
IwE hhgradient ∂
∂
⋅−+
∂
∂
⋅= , 
where hw  is the weight for the Sobel horizontal direction. 
When the image reduces or extends horizontally, the increase of weight of Sobel horizontal direction 
can reduce the energy dispersal caused by the vertical gradient.  
3.1.3 Saliency Map 
Visual saliency is an important factor for human visual system. Therefore, the proposed approach 
extracts a saliency map from the source image. The computer vision [2, 9] tries to imitate the possible visual 
perception of the human eye, from object detection, object classification to object recognition. 
The most-studied feature of natural images is the invariant of extension and reduction, which is also 
called 1/f law [11, 12]. After adding several images together and proceeding the fast Fourier transform, the 
amplitude A(f) of the averaged Fourier spectrum are observed as 
ffAE /1)}({ ∝ . 
Based on the residual image in frequency space [3, 4, 13], Hou and Zhang [4] proposed a log spectrum 
representation to find out the relation of polylines and visual features in log spaces. The method can rapidly 
detect conspicuous objects without extra references. Given an image I , the intensity and the phase spectrum 
of the image can be obtained by transferring the image to Fourier space as  
])[()( IFfA ℜ= , and ])[()( IFfP ℑ= , 
where F denote the Fourier Transform. )( fL  is the intensity information obtained after the reduction of the 
original image to one of rr sizesize ×  by Fourier transform as follows: 
))(log()( fAfL = . 
Therefore, the spectral residual )( fR  can be obtained by 
)()()()( fLfhfLfR n ∗−= , 
where )( fhn is an n × n matrix defined by 
⎟⎟
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜⎜
⎜
⎝
⎛
==
111
111
111
1)( 2
…
#%##
…
…
n
fhn , 
and )()( fLfhn ∗ is the averaged spectrum approximated by convoluting the input image. 
Using inverse Fourier transform, the saliency map in spatial domain can be constructed as  
21 ))]()([exp(*)( fPfRFxgEsaliency +=
− , 
where 1−F denote the inverse Fourier transform and )(xg is a Gaussian filter smoothing the saliency map. 
 
3.2 Image resizing 
The proposed approach applied the method proposed by Avidan and Shamir [1] for image retargeting. Let I 
be an n × m image and the vertical seam is defined as  
{ } { } 1)1()( , s.t. ,)),(( 11 ≤−−∀== == ixixiiixss ninixix , 
where x is a mapping x : [1, …, n] → [1, …, m]. 
A vertical seam is an 8-connected line. Every row only contains a single pixel. Carving the seam 
interactively is considered an advantage because it can prevent horizontal displacement during the deleting 
process. Horizontal displacement appears if the number of deleted pixels in each row is different, resulting in 
98
video retargeting using the seam carving. 
6. Acknowledgements 
The support of this work in part by the National Science Council of Taiwan, R.O.C. under Grant NSC-
96-2221-E-194-016-MY2 is gratefully acknowledged. 
7. References 
[1] S. Avidan and A. Shamir, “Seam carving for content-aware image resizing,” ACM Transactions on Graphics, 
article no. 10, 2007. 
[2] D. Gao and N. Vasconcelos, “Integrated learning of saliency, complex features, and object detectors from cluttered 
scenes,” IEEE Computer Society Conference on Computer Vision and Pattern Recognition, vol. 2, pp. 282-287, 
2005. 
[3] C. Guo, Q. Ma, and L. Zhang, “Spatio-temporal saliency detection using phase spectrum of quaternion fourier 
transform,” Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2008.  
[4] X. Hou and L. Zhang, “Saliency detection: A spectral residual approach,” Proceedings of IEEE Conference on 
Computer Vision and Pattern Recognition, pp. 1-8, 2007.  
[5] D. S. Hwang and S. Y. Chien, “Content-aware image resizing using perceptual seam carving with human attention 
model,” 2008 IEEE International Conference on Multimedia and Expo, pp. 1029-1032, 2008. 
[6] J. H. Kim, J. S. Kim, and C. S. Kim, “Image and video retargeting using adaptive scaling function,” Proceedings 
of 17th European Signal Processing Conference (EUSIPCO 2009), 2009. 
[7] J. S. Kim, J. H. Kim, and C. S. Kim, “Adaptive image and video retargeting technique based on Fourier analysis,” 
Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1730-1737, 2009.  
[8] K. Konolige, “Small vision systems: Hardware and implementation,” Proceedings of Eighth International 
Symposium on robotics Research, vol.8, pp.111-116, 1997.  
[9] T. Liu, Z. Yuan, J. Sun, J. Wang, N. Zheng, X. Tang, and H. Shum, “Learning to detect a salient object,” IEEE 
Transactions on Pattern Analysis and Machine Intelligence, 2010. 
[10] M. Rubinstein, A. Shamir, and S. Avidan, “Improved seam carving for video retargeting,” ACM Transactions on 
Graphics, pp.1-9, 2008.  
[11] D. Ruderman, “The statistics of natural images,” Network: Computation in Neural Systems, vol. 5, no. 4, pp. 517-
548, 1994. 
[12] A. Srivastava, A. Lee, E. Simoncelli, and S. Zhu, “On advances in statistical modeling of natural images,” Journal 
of Mathematical Imaging and Vision, vol. 18, no. 1, pp. 17-33, 2003. 
[13] A. vander Schaaf and J. VanHateren, “Modelling the power spectra of natural images: statistics and information,” 
Vision Research, vol. 36, pp. 2759-2770, 1996.  
[14] L. Wang, H. Jin, R. Yang, and M. Gong, “Stereoscopic inpainting: Joint color and depth completion from stereo 
images,” Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2008. 
100
100 年度專題研究計畫研究成果彙整表 
計畫主持人：張勤振 計畫編號：100-2221-E-239-034- 
計畫名稱：以特徵為基礎之三維材質合成 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
