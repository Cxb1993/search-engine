一、前言 
影像探勘主要是藉助資料探勘的技術，試圖作用在影像上，以期達到影像的比對與分類的
目的；進一步可以發覺隱含在影像中的獨特資訊，或是某些特定的樣式(pattern)但未明顯存在
於影像資料庫中。透過前置處理、特徵擷取與轉換，並且進行特徵的探勘與解讀，將可以從選
取的影像中挖掘出一些知識，影像探勘的整體流程如圖 1 所示。 
 
Image 
Database
Image 
DatabasePreprocessingPreprocessingTransformation &feature extraction
Transformation &
feature extraction
MiningMining Interpretation &
evaluation
Interpretation &
evaluation
Knowledge
 
 
 
 
圖 1 影像探勘的基本流程 
影像探勘雖是從資料探勘的角度切入，然而，實際上兩者問題的本質大不相同[HLZ02]。最主
要的原因在於一般資料所存在的關聯式資料庫與影像資料庫之間有下述三項差異點： 
1. 絕對數值與相對數值：在關聯式資料庫中的數值資料，是有其語意意涵的。但是，在影像資
料庫中，數值資料若沒有影像內容的輔助，該項數值便無法彰顯其真正意義。 
2. 在空間資訊的呈現：在進行影像內容的解讀過程中，空間資訊的關聯程度相較於一般關聯式
資料庫更為重要。 
3. 唯一性與多樣性的解讀：針對相同的影像內容樣式，在不同的使用者眼中，其實會有不一樣
的解讀結果。然而，這種情形卻鮮少發生在關聯式資料庫中的資料。所以，勢必需要重新開
發新的探勘方法才能解決。 
二、研究目的 
隨這數位時代的來臨，越來越多的文物古蹟紛紛數位化。這些相當龐大的數位化資料，尤
其是數位影像，所建構而成的數位圖書館或是數位典藏品，已經提供給了使用者一種合理的檢
索管道。然而檢索出來的影像之間，是否有其特殊的關係？例如：西洋美術史上的印象派繪畫、
或是中國古山水的國畫等，如果我們可以利用資料探勘的技術，協助使用者瞭解到其所檢索出
來的影像，有哪些是出自於同一位藝術家？有哪些是屬於同一畫風？有哪些是同屬某一類技
巧？甚至可以進一步推估，某些畫作是師徒之間的傳承？如此，更可以將檢索得到的影像，從
其萃取出相當程度的知識。 
本研究計畫我們嘗試將檢索而得到的影像資料進行自動分類與探勘。透過分類的動作，可
將大量看似彼此無任何關連的影像資料，進行整理、歸檔；如此可便利使用者快速地找尋到影
像之間彼此存在的關係。透過改進資料探勘的相關技術，可以達到建構一個「個人化的影像知
識建構系統」。我們提出一套應用影像的低階特徵(low-level descriptor/feature)，結合關聯式分類
技術(associative classification technique)進行相關影像資料的探勘。我們所開發的系統，與現有
的影像分類研究有以下的差別： 
1. 目前所蒐集到關於影像資料分類的文獻中，多數偏向於醫學影像或多頻譜的遙測衛星影像。
我們的方法可應用在一般的彩色影像，也包括前述的特定影像。 
 2
Blobworld [CBGM02]是一套由加州大學柏克萊分校所開發的影像分割系統。這個系統先透過影像
的前處理將圖片分割成小區域，每個分割出來的區域稱做 blob 並對應到影像裡的物體或物體的一部
份。接著在其檢索系統的部份共分為三個步驟，第一個步驟是系統會提供一組範例影像，一張是原始
影像，一張是該原始影像經影像前處理後切割出的區塊，讓使用者從切割出的區塊裡挑選想要的部份，
確定之後進入第二個步驟。在第二個步驟裡，系統則是提供了五個權重值，分別為色彩、紋理、位置、
形狀、以及大小進行調整第一步驟挑選到的區塊重要程度，另外還提供兩個選項來設定被選區塊以及
背景區塊的重要程度。最後在第三個步驟裡，系統將依據第二個步驟之條件檢索出符合條件的圖片供
使用者選擇。由於此系統所使用的方法，亦被多數學者採納並予以應用；在我們所使用的方法上，亦
採取其使用到的影像分割技術；也就是由 Carson et al. [CBGM02]所提出的以最大期望值法為基準的影
像分割技術進行影像的切割 
 以區塊為基準的特徵擷取 
將影像劃分為一些均勻的區塊後，便可以透過以下的方法進行相關特徵的擷取，以利後續的影像
分類之用。 
(A) 色彩直方圖 
目前已有許多研究學者，以分析一張影像的顏色分布狀況，當成是該張影像的一項特徵，其中又以
色彩直方圖(color histogram)為最常被使用的特徵之一。要產生色彩直方圖之前，必須先將影像對應到
一個合適的色彩空間，接著對該影像進行色彩量化(quantization)，然後計算每一種色彩量化值出現的次
數，而這樣的過程即可產生一個色彩直方圖。假設I是一張大小為W × H 的影像，Iq(x, y)代表影像裡(x, y) 
位置的像素之色彩量化值，ki為第i個色彩量化值的代號的話，那麼色彩直方圖hc裡的各個項目被定義成
如Eq.(1)： 
,..., ,1  ,)),,((][
1
0
1
0
NikyxIih
W
x
H
y
i
q
c == ∑ ∑
−
=
−
=
δ  (1) 
其中δ(·,·)為Kronecker delta函數，其定義為當兩個參數相等時，函數值為 1；否則，為 0。我們使用RGB
色彩空間，並將每個頻譜進行量化。也就是，我們將R, G, B的顏色分佈 0-255，分別等分為K等分(bin)，
如此可形成一K × K × K = K3 bins。所以，對於某個影像區域R，其色彩直方圖hc可定義為： 
1,-,0,  , 3Ki
N
nhc ii K==  (2) 
其中，ni為顏色類別i的像素個數，而N表示在區域R中的像素個數總和。因此，若考慮某兩張影像A與B，
其所屬區域Ri與Rj的差異程度，可以式子(3)表示之： 
  ,||),(
1
0
)(
,
)(
,
)(
3
∑−
=
−= K
i
B
mj
A
miji
R
hc hchcBAdist  (3) 
此處的 與 分別代表著區域R)(,Amihc )( ,Bmjhc i與Rj的正規化色彩直方圖。 
(B) 局部二元模型 
局部二元模型(local binary pattern, LBP)是一種紋理資訊統計方法，對於紋理的敘述能力相當強。LBP
運算子藉由比較影像中每一個像素與其鄰域像素的差異取得一個以二進位數值為表示的結果，如果像
素值大於中心像素值，就紀錄為 1，如果小於中心像素值，就紀錄為 0。再將所得紀錄值乘以相對應的
權重，並將其加總，就可得到 LBP 值(如圖 3 所示)。 
 4
如下： 
i
Redgepixel
i N
ER i
∑
∈∀=
1
. (10) 
因此，若考慮某兩張影像S與T，其所屬區域Ri與Rj的邊際比率差異程度，可定義成 
)()()( ),( Tj
S
iji
R
er ERERTSdist −=  
 影像探勘模組 
假設我們探勘的對象是屬於美術品或是畫作方面的影像，影像中顏色的搭配使用(例如：黃色與藍
色一起使用的現象)將是主宰整個影像意義的依據。因此在探勘此種類型或相關的影像的過程中，我們
應採用關聯式規則的技術較為適切。從前面的觀念引伸出，我們可以將一幅繪畫影像視為一筆的交易，
而這幅繪畫影像所萃取出來的低階影像特徵，以其所用色彩為例，就是這個交易的項目組，一種顏色，
就是一個項目。而 support 是指 itemset 出現的百分比。此外使用者需指定最小支持度(minimum support)，
而關聯式關則會找出 support 超過最小支持度的樣式，稱為經常性樣式(frequent pattern)。例如某四張彩
色影像，當最小支持度設為 50%時，經由探勘出來的經常性樣式為〈白、紅〉與〈綠、藍〉，其 support 皆
為 2；這表示在這些影像中將同時出現白與紅兩種顏色，此外有 50%的影像同時出現綠與藍兩種顏色。
此外，相鄰關係的探勘過程也和主要色彩相似，此時每一個項目就是一組相鄰關係，例如<黃、橘>，
找出來的經常性項目集則代表著影像間常出現的相鄰關係組合，例如〈紅、靛 黃、橘〉。 
在某些文獻上顯示[ADMR01, AZC02, KW06, TNM03]，利用關聯式分類法則可以成功地協助影像
資料的探勘。我們採用了 Liu et al. [LHM98]提出的 associative classification 方法，該法是一種結合
association rule 與 classification 的分類方法，分類的依據是利用各類別間所探勘出來的 associative rules。
利用資料探勘技術所挖掘出來的規則，可以代表該分類資料的共同特性；例如，有 X，Y 兩類不同的彩
色影像，如果在 X 類的影像中顯示藍與紅兩種顏色經常一起出現，而在 Y 類畫中綠與黃兩種顏色經常
一起出現，那麼分類器就可以將關聯式規則的表示方式，描述下列兩條分類規則︰〈藍、紅〉→〈X〉，〈綠、
黃〉→〈Y〉。因此，只要新的影像中，使用的顏色也是藍與紅兩種顏色一起出現，那麼該張影像就會被分
到 X 類，同理，若是黃與綠色經常搭配使用，則該影像可被劃歸到 Y 類。此方法是一種結合分類規則
探勘(classification rule mining)以及關聯式規則探勘(association rule mining)的技術。前者主要是從資料
庫中發覺一規則集，並藉此建構一正確的分類器。至於後者，則是發覺資料庫中所有的規則，這些規
則需滿足最小支持度與最小信賴值的條件。他們提出的演算法稱之為 CBA (classification based on 
association)，其包含了兩個部分，分別是：規則產生器(rule generator, CBA-RG)，主要觀念源生自 Apriori
探勘演算法[AS94]，利用該演算法找尋合適的關聯式規則，以及分類器建構(classifier builder, CBA-CB)。 
Algorithm 1 CBA-RG 
F1 = {large 1-ruleitems}; 
CAR1 = genRules(F1); 
prCAR1 = pruneRules(CAR1); 
for (k = 2; Fk-1 ≠ ∅; k++) do 
Ck = candidateGen(Fk-1); 
for each data case d ∈ D do 
Cd = ruleSubset(Ck, d); 
for each candidate c ∈ Cd do 
c.condsupCount++; 
if d.class = c.class then c.rulesupCount++ 
end 
 6
 8
第二個步驟，建構所使用的分類器。 
表 2  合併完成的經常項目集合 
項目集 信賴度 支持度 類別
紅色、綠色、藍色 100% 4 X 
紅色、黃色、藍色 100% 4 Y 
綠色、藍色 100% 4 X 
黃色、藍色 100% 4 Y 
藍色 60% 6 X 
黃色 60% 6 Y 
紅色、藍色 60% 6 X 
紅色 55% 10 X 
綠色 50% 4 X 
紅色、黃色 50% 4 Y 
紅色、綠色 50% 4 X 
依據表 2 的順序，將每條規則加進分類器中，並記錄準確率；所謂的準確率是指該影像被分到正確的
那一類的比例。除了記錄規則以外，分類器還隨時記錄一個預設的類別，是剩下未分類的影像中數量
最多的類別。仿照前述 CBA-CB 的方法，整個分類器的建構方法如下所示： 
Algorithm 3 Training Classifier Generation  
sort rules by confidence and support; 
for each rule r do 
for each image object p in DB do 
if r satisfies p then mark p to be classified  
if every p be classified correctly by r then 
remove all marked p from DB 
insert r at the end of Classifier; 
choose majority category of image in DB as  
default_class(r) 
compute the total number of errors of Classifier; 
end 
end 
Remove rules after the first rule r' with the lowest total error in 
Classifier; 
Insert the default_class(r') to the end of Classifier, and return 
Classifier 
五、結果與討論(含結論與建議) 
我們使用了 SIMPLIcity project [WLW01]中使用的影像資料庫進行實驗。實驗結果大體上可得到類
似表 1 與表 2 的結果；不過，我們發現了該法比較不適用於影像顏色過於複雜的情形；換言之，該法
適用於影像顏色較為簡潔的狀況。因此，若要真正將此技術應用於數位典藏之上，仍需要進一步的改
良相關的方法。 
從實驗的結果可知，要提供相關的影像關聯服務，影像探勘是非常重要的工作，而其自動化的影
像分類絕對是主要考量。以影像的低階特徵，搭配關聯式分類技術，能夠將檢索而得的影像資料，快
速且正確的分類並提供給使用者瀏覽。 
本計畫對於學術研究、國家發展及其他應用方面的貢獻如下： 
 10
[TNM03] J. Tesic, S. Newsam, and B. S. Manjunath, "Mining image datasets using perceptual association 
rules," Proceedings of SIAM International Conference on Data Mining, 6th Workshop on Mining Scientific 
and Engineering Datasets, pp.71-77, 2003. 
[WLW01] J. Z.Wang, J. Li, and G.Wiederhold, “SIMPLIcity: Semantic sensitive integrated matching for 
picture libraries,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 23, no. 9, pp. 947–963, Sep. 2001. 
[YLGJ07] Y. Yang, H. Lin, Z. Guo, and J. Jiang, "A data mining approach for heavy rainfall forecasting 
based on satellite image sequence analysis," Computers & Geosciences, vol.33, pp.20-30, 2007. 
 2
Karunya University, Prof. R.Venkatesan, (3) The Chinese University of Hong Kong, IEEE 
Fellow, Prof. Jun Wang。 
在會議舉行的前一天，本人即從高雄出發經桃園轉機到印尼山峇里島，並在會議當
天前往 Dynasty Resort 參加會議。參與成員主要來自世界國，台灣參與的研究學者則
不在少數。會議中討論相當踴躍，休息時間更是彼此寒軒問候和交換名片，華人之間
一方面也藉著難得的機會，互相詢問與指教各國先進的研究趨勢與成果，探索進一步
的研究突破與新知，或尋求跨國與跨校共同研究的可能性；另一方面，討論國內、外
高等教育的發展和學生素質，及如何培養學生具有新奇與嚴謹的研究氣息，藉此了解
國內、外學術界的實際情況差異，適度分享研究心智與接受建議。 
本人於本次研討會投稿一篇論文，名稱分別為「一種適應型態的彩色影像檢索技術
(An Adaptive Approach for Color Image Retrieval」，被安排在 4/3 下午的 Oral Session 進
行報告。本次發表的論文，主要是我們在彩色影像檢索主題上的研究成果，內容分別
是利用互動式遺傳演算法，配合彩色影像中的特徵描述子(例如：RGB 色彩空間的色
彩平均值與標準差，灰階共生矩陣求得的熵函數與 MPEG-7 所定義的影像邊際直方圖
用以代表影像中的紋理特徵，以及利用離散小波轉換設計一二元位置圖)來改善以內容
為基準(content-based image retrieval)之方法的效能；我們也與其他非適應型態的方法
進行比較，實驗結果顯示出我們所採用的方法有不錯的表現。本議題受到許多學者的
關注，並且獲得許多意見，使得後續的研究有更多的參考。 
二、與會心得 
ICIII 是一個偏重實務的會議，所涵蓋的議題範圍相當廣泛，也有許多跨領域的合
作研究成果發表。此次 ICIII 研討會與 ICCCD 及 FDIT 合併舉行，因此，在許多方面
資訊都是共享。從其所收錄的論文觀察，此次會議場次可概略分為三大方向，分別為
通用之智慧型技術、智慧型系統的應用、及相關應用技術。 
1. 通用之智慧型計算技術：此部份探討目前常使用之智慧型計算技術之一些議題，包
括了模糊理論與神經網路、支撐向量機、機器學習、專家系統、案例推論、群體智
慧、遺傳演算法、蟻群演算法、與混合式最佳化演算法等，均是目前相當熱門之主
題。其中有多篇文章均是採用前述之方法，進行某事件之決策支援或預測某事件之
未來情況。此題目一直是資料處理、資訊擷取與知識整合中非常熱門的一個研究方
向。為了解決某些問題的特殊性質，有些文章除了探討暨有技術的優劣外，更將相
關技術進行深入的變化，以符合不同的需求。 
2. 智慧型系統之應用：此部份較強調智慧型系統的實際應用，包括了交通控制、錯誤
診斷、工業控制、醫藥系統、影像處理、機器視覺、財務及市場分析預測、語音處
 4
4. 機器學習應用在工業製造、居家照護、生活起居已經是一種相當成熟的技術，其應
用廣泛。但在跨領域技術的整合，還需要廣徵各方智慧。國內研究應可以朝此方向
發展。 
四、攜回資料名稱及內容 
1. ICCCD 2011 Conference Proceedings 光碟片乙片與紙本論文集乙本。 
2. ICCCD 2011 Conference Program(會議議程表)乙本。 
introduced. The proposed approach is also described in the 
same section. In Section III, some experimental results are 
shown. Finally, conclusions are drawn in Section IV. 
II. THE PROPOSED APPROACH 
A. Color Information 
One of the key issues in CBIR is the choice of 
appropriate image descriptors and corresponding similarity 
measures. Retrieving images by color information is the 
most direct way among various image descriptors. Here we 
considered the most common used RGB color space, and 
employed the mean value and the standard deviation of the 
pixel colors as the color features of an image. The mean 
value (μ) and the standard deviation (σ) of the pixel Pi in a 
color image are determined as follows: 
∑
=
=
M
i
iPM 1
1μ , and (1) 
2
1
)(
1
1 ∑
=
−−=
M
i
iPM
μσ , (2) 
where μ = [μR μG μB] and σ = [σR σG σB], each component of μ and σ indicates the RGB information, respectively, and the 
M is the size of the image. 
B. Texture Information 
Texture is an important image feature that has been used 
for characterization of images. If we can choose an 
appropriate texture descriptor, the performance of the CBIR 
must be improved. In this paper, the entropy (E) is used to 
capture texture information in an image and is defined as 
follows. 
∑∑−=
i j
ijij CCE log , (3) 
where Cij is the gray level co-occurrence matrix [6]. The Cij 
is obtained by first specifying a displacement vector and then 
counting all pairs of pixels separated by the displacement 
and having gray levels i and j. 
In addition to entropy, spatial distribution of edges in an 
image is another useful texture descriptor for similarity 
search and retrieval. The edge histogram descriptor (EHD) in 
MPEG-7 represents local edge distribution in an image. The 
extraction of this descriptor involves division of image into 
16 nonoverlapping blocks of equal size. Then, edge 
information is calculated for each block in five edge 
categories: vertical, horizontal, diagonal (45° and 135°), and 
nondirectional edges. It is expressed as a five-bin histogram, 
one for each image block. The descriptor is scale invariant, 
and supports both rotation-sensitive and rotation-invariant 
matching [9]. 
In the last decade, wavelets have been shown to be useful 
in the image retrieval based-on texture in literature, possibly 
due to their finite duration which provides both the 
frequency and spatial locality. Here, we also considered the 
discrete wavelet transform (DWT) to introduce a texture 
descriptor. The wavelet series expansion of the function f(x) 
relative to wavelet ψ(x) and scaling φ(x) functions can be 
given by 
∑ ∑∑∞
=
+=
k jj k
kjkjkjkj dxcxf
0
,,,0,0 )()( ψφ  (4) 
where j0 is an arbitrary starting scale and the cj0,k and dj,k are 
real-valued "approximation" and "detail" expansion 
coefficients. The one-level Haar wavelet transform is used to 
extract features from an image for facilitating an effective 
search. The obtained wavelet coefficients are used to 
construct a binary bitmap. To create a binary bitmap for an 
image (M × M) via wavelet transformation, the mean of 
wavelet coefficients (μw) for each sub-band is created first. 
The image is then divided into small non-overlapping blocks. 
The binary bitmap for each image block (n × n) is computed 
as 
⎩⎨
⎧ ≥=
otherwise   ,0
  if   ,1
),( wblock
Avg
jibm
μ  (5) 
where 0 ≤ i, j ≤ (M/n), and Avgblock indicates the mean value 
of the considered block. 
C. Image Retrieval based on IGA 
The ultimate goal of the image similarity model used in 
CBIR research is to perform image matching, and identify 
the database images most similar to the user's query image 
[10]. Therefore, in order to find more images which satisfy 
the user's expectations, we view it as an optimization 
problem and employ the GA-based technique to solve it. 
Genetic algorithms (GAs) [4] are robust computational 
and stochastic search procedures modeled on the mechanics 
of natural genetic systems. GAs are well known for their 
ability by efficiently exploiting the historical information to 
improve search performance. When GAs use a human to 
provide fitness, rather than a programmed function to 
compute fitness, they are called interactive GAs (IGAs). This 
property allows a system to be developed according to 
human intuition or emotion. When we apply the IGA to 
develop a color image retrieval system, we must consider the 
following components: (1) a genetic representation of 
solutions to the problem, (2) one way to create the initial 
population of solutions, (3) an evaluation function that rates 
all candidate solutions according to their "fitness", (4) 
genetic operators that alter genetic composition of children 
during reproduction. 
• Solution representation: In the proposed approach, 
the chromosome is made up of color features as well 
as texture features. 
• Initial population: The IGA requires a population of 
potential solutions to be initialized at the beginning 
of the GA process. In our approach, we use the query 
results of an example image as initial candidate 
images. The advantage is that heuristic initialization 
may improve the search performance. 
V2-138
2011 International Conference on Computer and Communication Devices (ICCCD 2011) 
by the user's ranking concept. Through repeated rounds of 
content generation and fitness assignment by the user, IGA  
 
Figure 4.  Retrieval results after the 10th generation of IGA. 
 
Figure 5.  Retrieval results after the 15th generation of IGA. 
TABLE I.  CATEGORY RETRIEVAL ACCURARY (%) FROM THE 
PROPOSED APPROACH 
Category 1st gen. 2nd gen. 3rd gen. 4th gen. 5th gen.
Texture 85 91 93 95 97 
Forest 63 72 75 82 86 
Skeleton 86 90 94 99 100 
Horses 95 96 96 97 99 
Mountains 63 71 77 86 89 
People 76 84 89 92 95 
Category 6th gen. 7th gen. 8th gen. 9th gen. 10th gen.
Texture 97 97 98 98 99 
Forest 90 91 92 93 95 
Skeleton 100 100 100 100 100 
Horses 99 99 99 100 100 
Mountains 95 97 97 99 100 
People 95 96 98 99 100 
TABLE II.  CATEGORY RETRIEVAL ACCURACY (%) FROM THE SGA 
Category Texture Forest Skeleton 
 92 68 77 
Category Horses Mountains People 
 67 45 53 
enables unique content to evolve that suits the user's 
preferences. In some cases such content cannot be 
discovered or created in any other automated methodologies. 
IV. CONCLUSTION 
In this paper, an adaptive approach for general color 
image retrieval was presented. The color distributions, the 
mean value and the standard deviation, are used as color 
information of an image. Additionally, appropriate texture 
descriptors also help to characterize the properties of images. 
In particular, we use the IGA to tune human judgment results 
on similarity of images. Experimental results have shown the 
good performance of the proposed approach. Many 
possibilities both to extend the proposed approach and to 
validate the method in different scenarios and against other 
similar methods have been left as further work. 
ACKNOWLEDGMENT 
This work is supported by the National Science Council, 
Taiwan, under grants NSC 98-2221-E-390-027 and NSC 99-
2221-E-390-035. 
REFERENCES 
[1] S. Antani, R. Kasturi, and R. Jain, "A survey of the use of pattern 
recognition methods for abstraction, indexing and retrieval," Pattern 
Recognition, vol. 35, no. 4, pp. 945–965, 2002. 
[2] C. A. Z. Barcelos, M. J. R. Ferreira, and M. L. Rodrigues, "Retrieval 
of textured images through the use of quantization and modal 
analysis," Pattern Recognition, vol. 40, no. 4, pp. 1195–1206, 2007. 
[3] K. Deb, Multi-Objective Optimizatoin using Evolutionary Algorithms, 
John Wiley & Sons, Ltd., 2001. 
[4] D. E. Goldberg, Genetic Algorithms in Search, Optimization, and 
Machine Learning, Reading, MA: Addison-Wesley, 1989. 
[5] J. Han, K. N. Ngan, M. Li, and H.-J. Zhang, "A memory learning 
framework for effective image retrieval," IEEE Trans. Image 
Processing, vol. 14, no. 4, pp. 511–524, 2005. 
[6] R. M. Haralick and L. G. Shapiro, Computer and Robot Vision: 
Volume I. Reading, Massachusetts: Addison-Wesley, 1992. 
[7] A. Khotanzad and O. J. Hernandez, "Color image retrieval using 
multispectral random field texture model and color content features," 
Pattern Recognition, vol. 36, no. 8, pp. 1679–1694, 2003. 
[8] Y. Liu, D. Zhang, G. Lu, W.-Y. Ma, "A survey of content-based 
image retrieval with high-level semantics," Pattern Recognition, 
vol.40, no. 1, pp. 262–282, 2007. 
[9] T. Sikora, "The MPEG-7 viusal standard for content description – An 
overview," IEEE Trans. Circuits and Systems for Video Technology, 
vol. 11, no. 6, pp. 696–702, 2001. 
[10] Z. Stejic, Y. Takama, and K. Hirota, "Relevance feedback-based 
image retrieval interface incorporting region and feature saliency 
patterns as visualizable image similarity criteria," IEEE Trans. 
Industrial Electronics, vol. 50, no. 5, pp. 839–852, 2003. 
[11] H. Takagi, "Interactive evolutionary computation: Fusion of the 
capacities of EC optimization and human evaluaiton," Proc. IEEE, 
vol. 89, no. 9, pp. 1275–1296, 2001. 
[12] L. V. Tran and R. Lenz, "Compact colour descriptors for colour-based 
image retrieval," Signal Processing, vol. 85, no. 2, pp. 233–246, 2005. 
[13] R. C. Veitkamp and M. Tanase, "Content-based image retrieval 
systems: a survey," Technical report:UU-CS-2000-34, University of 
Utrecht, 2000. 
[14] E. de Ves, J. Domingo, G. Ayala, and P. Zuccarello, "A novel 
Bayesian framework for relevance feedback in image content-based 
retrieval systems," Pattern Recognition, vol. 39, no. 9, pp. 1622–1632, 
2006. 
[15] X. S. Zhou and T. S. Huang, "Relevance feedback in content-based 
image retrieval: some recent advances," Information Science, vol. 48, 
no. 1-4, pp. 129–137, 2002. 
V2-140
2011 International Conference on Computer and Communication Devices (ICCCD 2011) 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/15
國科會補助計畫
計畫名稱: 以使用者為導向的影像檢索、探勘與註解之研究(II)(III)
計畫主持人: 賴智錦
計畫編號: 99-2221-E-390-035- 學門領域: 人工智慧
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
