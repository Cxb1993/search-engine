 2 
成果報告： 
 呂全斌, 莊明輝, 李瑞彬, 劉偉羿, 2011,"照護機器人視覺定位與引導方法之研
究", 2011 南台灣健康照護暨健康產業國際學術研討會, pp. 244-251. 
2011南台灣健康照護暨健康產業國際學術研討會                                                                                                         屏東，中華民國100年9月 
International Conference on Health Care and Health Industry                                                                                           Ping Tung, September 2011 
 
 
前言 
經過行政院經建會的調查[1]，2008 年國人超過
65 歲的人口比例為 10.4%，預估在 2019 年時，將
會超過 14.7%，之後快速上升，台灣已經邁入高齡
化的社會。然而，高齡化的社會伴隨而來的是人口
快速老化、疾病型態的慢性化與身心障礙老衰人口
的增加，國人對健康照護的需求日益增加，而國內
培養的護理相關人才畢業後大都投入醫療單位，經
過幾年辛苦的臨床工作，部分護理人員即轉任其他
職場，繼續從事護理工作的人員也會隨著其他因素
(如工作福利與待遇的不佳)逐年減少，我國護理人
力不足的現象早已經出現多年，更遑論能夠投入老
人照護工作；除此之外，根據行政院衛生署的分析
調查，60 歲以上的高齡者，平均的醫療支出是其他
年齡層的 4.5 倍，有鑑於此，為了減少健保的負擔
與提供國人足夠的需求，行政院衛生署已經在進行
一連串的遠距照護相關計畫 ( 行政院衛生署 , 
2008[2])，期望藉由資訊科技的導入，使得照護服
務便利化、科技化與自動化，並且降低照護人力的
需求。目前國內逐漸形成的老人照護的產業，目前
正積極發展各式各樣的遠距醫療與照護相關產品，
如血壓、血糖、心跳、體溫遠距管理與醫療照護通
訊等生理資訊管理平台；此外在輔助獨立生活感測
器[3]則有智慧型藥盒、遠距視訊攝影機、跌倒偵測
器、離床偵測器、PIR 動作偵測器、個人隨身壓扣
發報器等等；還有尚在發展的多功能照護機器人。
其中以為緊急應變機制功能為主的輔助獨立生活感
測器最為重要，一旦有狀況發生，受護者則可以透
過這些感測器傳送訊息至通報平台，通知鄰近社福
機構或醫療單位到家處理；然而，穿戴式感測器存
在著一些常見的問題，如容易受到其他電子器材的
影響而產生電磁干擾現象，而導致感測器資料流失
(ITIS 智網-產業評析, 2008)[4]，以及感測器因受護
者穿戴方式不正確而掉落、電池沒電、忘記佩帶或
故障等等，一旦有跌倒或者是急性病症情況發生，
照護者就無法獲知受護者的狀況，因此照護者必頇
透過遠距視訊攝影機，來隨時注意受護者是否有狀
況發生；然而，現行的遠距照護系統所使用的攝影
機大多為安裝在固定位置上的攝影機，由於攝影機
無法移動，只要受護者離開攝影機的視野範圍，遠
距照護者則無法取得受護者在家中的的影像，為了
慎重起見照護者只能通知鄰近社福機構或醫療單位
到府探視與處理，這類的情況經常發生，也是現今
遠距照護工作面臨的一項難題。尚在發展的多功能
照護機器人(Care Robot)則可以協助解決這樣的問
題，照護機器人可以裝設許多感測器，如超音波、
紅外線、攝影機與溫度等等感測器，由於照護機器
人具有行動能力，因此可以移動到室內中的任何一
個位置，協助遠距照護者解決上述的問題；然而，
照護機器人必頇由照護者以遠操控的方式進行移動
控制，在操控的過程中必頇讓照護機器人避開路徑
中的障礙物(傢俱)，並且找尋適當的路徑讓機器人
順利的移動到目標地。為了讓具行動能力的機器人
更智慧化，因此機器人自主性行動的研究開始有了
許多的探討，這些研究的最終目標是操控者只要給
予目標地的指令，機器人則就能夠自主性的找尋最
佳路徑與避開障礙物移動至目標地。而這一點對照
護機器人相當重要，如此一來才能真正用於居家照
護的工作上；我們在此研究中進行機器人自主性行
動方法上的探討，並且以影像資訊為主進行機器人
定位與路徑規劃方法的研究。 
 
文獻探討 
資訊技術在醫療與照護的相關研究在近幾年也
受到相當的重視，在相關學術文獻的探討如下：
Brender 於 1998[5]提出資訊技術應用在醫療照護上
的作法與建議；Schelkens(1999) [6]、Caldelli(2006) 
[7] 與 Singh(2007)[8]將影像處理技術應用在遠距醫
療與照護上，而這些文獻主要是著重在醫療資訊收
集與辨識方法的探討。在照護機器人方面的研究則
有，Song 等人(2007~2009)[9~12]所發展的家用機器
人與保全機器人，主要的研究是著重在機器人於保
全或家用的特定功能上，如老人跌倒偵測、機器人
臉部控制、機器人追蹤控制、機器人情緒識別、保
全警示、行走輔助等；行動式機器人(Mobile Robot)
定位的相關研究也在許多的文獻中提出，如 Wang 
(2009) [13]、Cho(2009) [14]、Kim(2007) [15]與 Han 
(2007) [16]等人的研究，這些研究著重在使用各類
型的感測器(如 Ultrasonic、RFID、Infrared Rays 與
GPS)來進行機器人的定位，在這些研究的方法上，
主要是透過座標的轉換將地圖上感興趣的資訊轉換
至機器人自身的座標上，進而控制機器人移動到目
的地。定位可以提供機器人具有自主能力的一種重
要的基礎，所以定位的研究是一項重要的議題，自
主性的移動能力對照護機器人尤其顯得相當重要，
這是因為居家環境中會有許多家俱與複雜裝潢，這
些將會嚴重考驗照護機器人的移動能力。相較於其
他類型的感測器而言，光感應式的攝影機具有幾項
不可獲缺的特性，如攝影機可以取得大範圍的環境
資訊與可以使用直覺式的技巧來進行定位控制(就如
同人一樣)。使用視覺影像為基礎(Vision-based)的定
位方法有兩種：其一是以機器人裝置上的攝影機視
訊為視野，透過室內擺設物品的影像特徵來建立數
據地圖(Metric Maps)、拓樸地圖(Topological Maps)
或認知地圖(Cognitive Maps)。數據地圖[17~19]的方
法是使用幾何特徵來描述環境，並且儲存環境中所
有的細節，並且設定單張影像參考畫面(Reference 
245
2011南台灣健康照護暨健康產業國際學術研討會                                                                                                         屏東，中華民國100年9月 
International Conference on Health Care and Health Industry                                                                                           Ping Tung, September 2011 
 
 
影像結構初始化分析進行初步估測環境影像中
的結構，這些結構將做進一步處理並作為 CNN 的
細胞；由於影像資訊對電腦而言僅是光感應變化下
的資料，影像擷取下來後必頇針對具有相同結構的
像素以群組方式定義與識別，我們假設機器人初始
位置為可移動區域(如地板)，並以機器人相鄰的區
域影像作為樣本，透過 Bayes 分類器配合顏色的特
徵進行識別分類，將影像區域分為可移動區域與未
知區域兩類，並將未知區域設定為障礙物。在定位
方法部分，機器人從預設起始點開始移動，過程中
將會經過許多中途點，直到最後目的地，我們透過
影像來計算機器人從起始到中途點的方向，透過電
子羅盤來獲取機器人實際的移動方位，工作站透過
無線通訊來指引機器人往中途點方向移動。在影像
資訊分析上，我們使用移動物體偵測方法來取得機
器人在影像中的位置，定位出機器人的位置。由於
室內環境的光線明暗度不均一，相同的物質在影像
中呈現出的色彩也會有所不同，這一點對地板影像
識別會有相當程度的影響，但有一項規則是可觀察
到的，就是地板影像亮度會逐漸變亮或逐漸變暗，
因此當機器人移動中途點時，我們再次擷取鄰近的
地板影像並做為識別樣本，使用 Bayes 分類器下一
階段的可移動區域，並與初始階段的可移動區域合
併，採循序估測方式進行；當機器人完整的走過所
有路徑一次之後，我們即可取得精確且完整的影像
結構地圖，而機器人之後的移動則只要使用該影像
地圖來進行路徑規劃與移動即可，直到環境部分場
景被改變，該重複上述的作法並更新該部分的地圖
資訊。獲取影像結構地圖後，我們使用網格型類神
經網路來進行路徑規劃，每次規劃皆以可移動區域
與目的地方向作為目標，過程中假設未知區域為障
礙物；移動過程中若聲波感測器回傳可移動區域為
障礙物，則該機器人停止移動，並重新進行可疑區
域識別與路徑規劃。 
機器人定位、影像結構地圖循序估測建置、
CNN 路徑規劃步驟重複進行直到機器人移動到目的
地；返回原地則以先前紀錄路徑移動至初始點。以
下則是上述步驟流程中所使用的方法： 
1. 影像結構初始化分析 
影像結構地圖建立步驟如圖二所示，在進行機
器人定位之前，我們以影像結構初始化步驟來估測
環境影像中的結構，為了要取得整個環境的影像，
我們使用 PTZ 快速球型攝影機，以 15 度為間隔轉
動進行影像擷取，若取像環境為走道則設定 180 度
為攝影機旋轉角度，取像環境為家中客廳，則可設
定為 360 度，以擷取足夠的環境資訊為原則；接著
使用相關性比對運算方式來計算出每張影像重疊之
處，並以重疊之處做為接合點，獲得環境影像後，
進行影像邊緣檢測，由於邊緣線可以展現物體之間
在初始化步驟並不讀取聲波感測器回饋訊號，直到
機器人移動時才分析回饋訊號，若聲波感測器讀取 
 
的差異，因此利用物件於影像中的邊緣線作為切割
線；之後我們使用 Lifeng 等人[31]在 2009 年提出的
非遞迴式的快速標記法來進行區域標記；以機器人
起始位置的影像區域作為樣本，透過 Bayes 分類器
進行分類，將影像區域分為可移動區域與未知區
域。 
 
距離小於設定距離，我們則認定前方區域是為障礙
物，並停止移動機器人，標記前方影像區域為障礙
物，同時擷取機器人所在鄰近影像做為新樣本，以
循序估測方式再次進行區域分類識別，分類的區域
則不包含先前已移動影像區域。每次所估測出的結
果為影像結構地圖 )(IM  ( 為估測次數)，當 值越
大， 也會越精確。接下來，我們使用相關性比對方
法來分析影像連接之處，方法如下所述： 
1. 相關性比對 [29] 
相關匹配的原理是利用兩張影像函數進行乘積
運算(如 f . )，這樣的乘積運算可以是交叉相關或
自相關，所乘積出來的值越高表示兩實數函數的相
關性越高，基於此相關性定義，我們可從多個實數
函數的相關性乘積值進一步進行比對的分析，這樣
的比對分析亦稱為匹配。匹配的作法中， f 為包含
物體或區域的一個影像，若我們想要分析 f 的資訊
中是否有我們感興趣的特定物體或區域資訊，我們
假設特定物體或區域資訊為 ， 影像也稱為樣版
247
2011南台灣健康照護暨健康產業國際學術研討會                                                                                                         屏東，中華民國100年9月 
International Conference on Health Care and Health Industry                                                                                           Ping Tung, September 2011 
 
 
轉換Gaussian模糊化處理Sobel濾波邊緣檢測影
像二值化處理中值濾波細線化處理。 
I. 色彩模式轉換： 
首先將24-bit彩色影像轉換至8-bit的灰階影像可
降低演算的複雜度，轉換公式可由下式來獲得
(Gonzalez, et al., 2002) (其中 R 、G 、 B 分別為彩色
影像中三成份的灰階值，而 f 為轉換為8 Bits影像
的灰階值)。 
BGRf 114.0587.0299.0     (8) 
II. Gaussian模糊化處理： 
接著，為了讓邊緣資訊的效果提昇，必頇降低
影像雜點資訊，才能保留物件清楚的邊緣線，所以
透過Gaussian濾波模糊化處理(
G
f )來降低影像雜點
的干擾，二維的Gaussian函數如下(Gonzalez, et al., 
2002)： 

22 yx
G
eff


      (9) 
其中 x 與 y 為影像水平軸與垂直軸座標符號， 為
標準差，符號 為旋積運算(Convolution Operation)
處理。 
III. Sobel濾波邊緣檢測： 
邊緣檢測演算法有幾種方式可以實現，如
Roberts梯度運算子、Prewitt運算子、Sobel運算子、
Laplacian運算子等等，這些方法都可以獲得影像邊
緣資訊，而效果會隨著不同的應用而有所不同，在
此我們選擇能抑制雜訊特性的Sobel運算子來尋找影
像中的邊緣。Sobel運算子可由以下梯度公式
G
f 來
獲得(Gonzalez, et al., 2002) 
  5.0 22)(
yxGG
DDmagf  f ,
 
T 
T 











y
f
x
f
DD GG
yxG
f , 
   
321987
22 ssssssD
x
  , 
   
741963
22 ssssssD
y
 .              (10) 
取得影像的邊緣資訊
G
f 後，接著進行二值化處
理，將邊緣強度較高的部份擷取出來做為區塊邊
界，讓影像內部多個能代表特殊屬性的區域分割出
來。 
IV. 影像二值化處理： 
二值化的處理重要關鍵在於灰階閥值，於此我
們使用 Otsu 學者所提出(Otsu, 1978)的統計式閥值決
定法，此方法的概念為假設有一最佳閥值， 可
將影像中的像素分為兩區(
1
 與
2
 )，其的決定必
頇滿足兩個條件其中一即可。 
條件一：使得
1
 與
2
 之間的變異數最大。 
條件二：使得
1
 與
2
 內在的變異數總和最小。 









G
G
fif
fif
    ,    0
     ,255
                (11) 
此方法詳細說明可參考Otsu學者於1978的文
獻，定義符號  為二值化後的影像。 
V. 中值濾波： 
使用中值濾波是為了要去除二值化後，邊緣影
像上的一些小雜點，本研究使用Yang 與Toh所提出
的適應性模糊多層中值濾波器 (Adaptive Fuzzy 
Multilevel Median Filter/AFMMF)來去除影像中的雜
訊 ， 此 方 法 是 結 合 模 糊 關 聯 記 憶 法 (Fuzzy 
Associative Memory)，所提出的修正式的多層中值
濾波器，該濾波器克服了傳統多層中值濾波器(A 
Multilevel Median Filter/MLMF)的一些缺點，此方
法於保留影像內容物的邊緣資訊能有更好的效果。 
VI. 細線化處理： 
透過細線化處理將邊緣線的寬度最小化為一個
像素的寬度，如此一來，這樣的格線就可以作為網
格的邊界，接著再透過切割與標記處理，每個區域
網格之間也有相對應的交互關係，這樣一來我們就
可以使用網格型類神經網路於具網格型態的影像結
構地圖上。細線化的定義是假設有兩個於集合 A 與
B，A 被一個結構元素 B 細線化，可表示成使用
A  B，我們可以使用一個結構元素序列來定義細
線化 (Gonzalez, et al., 2002)： 
 nBBBABA  ...))(...(}{ 21              (12) 
4. 影像切割與影像區域標記 
取得細線化後的邊緣線作為影像區域切割的基
準，定義邊緣線為1，其餘部分為0，在邊緣線之間
經常存在著少許的縫隙，為了讓邊緣線更完整，我
們使用型態處理方法 (Morphology)中的膨脹運算 
(Gonzalez, et al., 2002)來進行填補的動作。膨脹的定
義為假設有兩個於影像函數 2Z 中像素的集合A與
B，使用B對A來進行膨脹處理，是為 z 所有位移
(Displacement)的集合，這些位移可以使得 Bˆ 和A之
間至少有一個元素的重疊，將處理結果標記為
BA ，公式的定義如下： 
 AABBA  ])ˆ[(|  
z
z  .            (13) 
每個點 Bz ，這些點對 A 來進行平移，並將全部
的平移結果取聯集(OR)處理。我們以邊緣線為切割
線  ，其餘部分則為切割後的影像區域  1
~
， 

~
影像區域標記處理，是使用 Lifeng 等人所提出的
非遞迴式(Non-recursive)的快速標記法來進行區域標
記，他們的方法是一種 Two-scan標記演算法，演算
效率比傳統遞迴式標記法、Multi-scan 標記演算
法、Hybrid 標記演算與 Tracing-type 標記演算來的
更快速，非常適合使用在影像結構地圖即時定位
249
2011南台灣健康照護暨健康產業國際學術研討會                                                                                                         屏東，中華民國100年9月 
International Conference on Health Care and Health Industry                                                                                           Ping Tung, September 2011 
 
 
Classification in Medical Image Compression for 
Teleradiology. Computers in Biology and 
Medicine, 37(6): 811-819. 
[9] 宋 開 泰 , (2008). Rola 家 用 型 機 器 人 , 
http://isci.cn.nctu.edu.tw/index.html. 
[10] Chia-How Lin, Su-Hen Yang, Hong-Tze Chen and 
Kai-Tai Song, (2008). Mobile Robot Intruder 
Detection Based on a Zigbee Sensor Network, in 
Proc. of 2008 IEEE International Conference on 
Systems, Man and Cybernetics (SMC 2008), 
Singapore, Oct. 12-15: 2786-2791. 
[11] Fu-Sheng Huang and Kai-Tai Song, (2008). Vision 
SLAM Using Omni-Directional Visual Scan 
Matching, in Proc. of IEEE/RSJ International 
Conference on Intelligent Robots and Systems 
(IEEE/RSJ IROS 2008), Nice, France, Sep. 22-
26:1588-1593. 
[12] Meng-Ju Han, Jing-Huai Hsu, Kai-Tai Song and 
Fuh-Yu Chang, (2007). A New Information Fusion 
Method for SVM-Based Robotic Audio-Visual 
Emotion Recognition , in Proc. of IEEE 
International Conference on Systems, Man and 
Cybernetics, Montreal, Canada, pp. 2656-2661. 
[13] M. L. Wang, Y. C. Chung, and H. Y. Lin, (2009). 
A Self-Localization Technique for Mobile Robots 
using Image-Based Ground Plane Detection, 
Proceedings of the 2009 International Conference 
on Service and Interactive Robotics  
[14] S.-K. Cho, T. Yang, M.-G. Choi; J.-M. Lee, 
(2009). Localization of a High-Speed Mobile 
Robot Using Global Features, ICARA 2009. 4th 
International Conference on Autonomous Robots 
and Agents, pp.  138-142. 
[15] S.-H. Kim, C.-W. Roh, S.-C. Kang, M.-Y. Park, 
(2007). Outdoor Navigation of a Mobile Robot 
Using Differential GPS and Curb Detection, 2007 
IEEE International Conference on Robotics and 
Automation, pp. 3414-3419. 
[16] S. S. Han, D. K. Kim, J. M. Lee, (2007). A New 
Tag Arrangement Pattern for a Differential Driving 
Mobile Robot Based on RFID System, ICCAS '07- 
International Conference on Control, Automation 
and Systems, pp 1228-1233. 
[17] I.J. Cox, J.J. Leonard, (1994). Modeling a 
Dynamic Environment Using a Bayesian Multiple 
Hypothesis Approach, Artificial Intelligence 66 
(1) : 311–344. 
[18] A. Elfes, (1989). Occupancy Grids: A Probabilistic 
Framework for Robot Perception and Navigation, 
Ph.D. Dissertation, Department of Electrical and 
Computer Engineering, Carnegie Mellon 
University. 
[19] F. Lu, E. Millos, (1997). Robot Pose Estimation in 
Unknown Environment by Matching 2D Range 
Scans, Journal of Intelligent and Robotics Systems 
18 (3):249–275. 
[20] H. Choset, K. Nagatani, (2001). Topological 
Simultaneous Localization and Mapping (SLAM): 
Toward Exact Localization Without Explicit 
Localization, IEEE Transactions on Robotics and 
Automation 17 (2): 125–137. 
[21] D. Kortenkamp, T. Weymonth, (1994). 
Topological Mapping for Mobile Robots Using a 
Combination of Sonar and Vision Sensing, in: 
Proceedings of the 12th National Conference on 
Artificial Intelligence, pp. 979–984. 
[22] H. Frezza-Buet, F. Alexandre, (2002). From a 
Biological to a Computational Model for the 
Autonomous Behavior of an Animation, 
Information Sciences 144 (1–4): 1–43. 
[23] M.E. Jefferies, W.-K. Yeap (Eds.), Robotics and 
Cognitive Approaches to Spatial Mapping, 
Springer Tracts in Advanced Robotics, vol. 38, 
Springer, 2008. 
[24] B. Kuipers, The cognitive map: could it have been 
any other way?, in: H.L. Pick, L.P. Acredolo 
(Eds.), Spatial Orientation: Theory Research and 
Application, Plenium Press, New York, 1983. 
[25] M. P. Paulraj, R.B. Ahmad, C.R. Hema, F. 
Hashim, S. Yusoff, (2008). Active Stereo Vision 
Based System for Estimation of Mobile Robot 
Orientation Using Affine Moment Invariants, 
ICED 2008 International Conference on Electronic 
Design, pp 1-7. 
[26] I. Gavrilut, A. Gacsadi, C. Grava, V. m. Tiponut, , 
(2006). Vision Based Algorithm for Path Planning 
of a Mobile Robot by Using Cellular Neural 
Networks, Automation, Quality and Testing, 
Robotics, 2006 IEEE International Conference on 
Vol. 2, 25-28:306-311. 
[27] I. Gavrilut, V. Tiponut, A. Gacsadi, (2006). Path 
Planning of Mobile Robots by Using Cellular 
Neural Networks,Cellular Neural Networks and 
Their Applications, 2006. CNNA '06. 10th 
International Workshop on, 28-30:1 - 6 
[28] L. O. Chua, and L. Yang, (1988). Cellular Neural 
Networks: Theory and Application, IEEE Trans. 
On Circuits and Systems, (CAS), Vol. 35:1257-
1290. 
[29] Gonzalez, Rafael C., Woods, Richard E. 2002. 
Digital Image Processing. Second Edition, 
Prentice-Hall. 
[30] Chiu, Shih-Hsuan, Lu, Chuan-Pin, Wen, Che-Yen, 
(2006). A Motion Detection Based Framework for 
Improving Image Quality of CCTV Security 
Systems. Journal of Forensic Sciences, 51(5): 
1115-1119. 
[31] B. Siemiatkowska, A. Dubrawski, (1998). Cellular 
Neural Networks for Navigation of a Mobile 
Robot, Springer-Verlag Berlin Heidelberg, pp. 
147-154. 
 
251
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/26
國科會補助計畫
計畫名稱: 使用影像結構地圖與網格型類神經網路於照護機器人視覺定位與引導之研究
計畫主持人: 呂全斌
計畫編號: 99-2221-E-276-005- 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
