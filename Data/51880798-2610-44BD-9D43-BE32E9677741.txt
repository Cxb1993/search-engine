 2
充放電的過程中，會產生一個非常有名的非線性現
象，也就是所謂的遲滯(hysteresis)現象，這對控制而言
是一個有趣又挑戰的課題。因此近幾年來，在壓電致
動系統相關的研究部份也非常受到重視，許多前饋式
或迴授式的控制方法都被熱烈地討論與研究。以前饋
控制(feedforward control)的角度來看，例如在文獻[30]
中使用相位領先的補償方法來克服遲滯非線性。另外
更常被用的策略是嘗試建構遲滯的數學模式，以便設
計反遲滯控制器來作為補償機構，例如 generalized 
Preisach model [31], generalized Maxwell model [32], 或
polynomial approximation model [33]等等。從迴授控制
(feedback control)的角度來看，例如文獻[31]的 PID 控
制器，文獻[34]的可變結構控制器，文獻[35]的模糊控
制器，或文獻[36]的 ∞H 控制器等等，均是壓電致動系
統控制器設計常見的方法。另外，最近也有論文開始
研究反覆學習控制（ILC）在壓電致動系統的理論分析
與應用[37-38]，只是反覆學習控制必須架構在一些迴
授控制上，控制器的架構仍然有點複雜。另外在[39-40]
中，我們也利用 PI 迴授控制與前饋相位補償器
(feedforward phase compensator)的結構，配合系統鑑別
的技術，引入反覆學習的細調補償，成功地將壓電致
動系統追蹤誤差降至合理的範圍，與其他的研究報告
相比較，控制性能有一定的提升。 
然而，不論是我們的過去成果，或是其他相關的
研究文獻，控制器不僅大都非常複雜，且相對的控制
性能仍有改善的空間。事實上，以學習控制的觀點而
言，此一控制策略標榜的一個重點是控制法則非常簡
單，在實做上非常容易，更重要的是控制器的設計不
需依賴詳細的受控廠數學模式。因此對於壓電致動器
系統做重複性追蹤控制的應用應該有很好的發揮空
間。可惜的是目前在壓電致動器學習控制的研究成
果，都無法顯現學習控制的這一個優勢，必須在其他
適當的前饋或迴授補償器的幫助下，學習控制才發揮
其性能。事實上計畫主持人的研究團隊在先期的研究
過程中，就曾經嘗試利用最基本的反覆學習控制法則
進行實驗，亦即利用下列的 D 型反覆學習控制法則： 
( ) ( ) ( )111 +⋅+= −− neLnunu iii  
其中 )(nui 與 )(1 nui− 分別代表在第 i 次與 1−i 次控制學
習的壓電致動器輸入電壓，n 代表第 n 個取樣時間，
)1(1 +− nei 代表在第 1−i 次學習第 1+n 個取樣時間的學
習誤差，L 則代表學習增益。然而實驗結果顯示這個最
常用的基本反覆學習控制器並無法讓學習誤差收斂，
實驗過程中可以看到壓電致動器位移迴授訊號有時候
正常顯示，但接下來的幾次學習便開始不穩定振盪，
有時候則實驗一開始即呈現發散的不穩定現象。這可
能是壓電致動系統本身的特性無法滿足反覆學習控制
法則收斂的條件，或是實驗過程一些訊號雜訊、干擾
的影響，因此我們猜想目前採用學習控制的研究論文
必須再添加其他前饋或迴授補償器，可能就是這個原
因之一吧？當然，實做與純理論分析永遠還有一段距
離，再完美的理論於實際應用中不見得可以直接引
用。然而對於反覆學習控制的簡易實做優秀特質，卻
又是令人難忘與不捨。因此本計畫的重要研究動機與
背景就是希望在無模式(model free)的狀況下，甚至在無
傳統迴授控制的狀況下，仍能達成反覆學習控制的目
標，且儘可能保持反覆控制學習法則的簡易性，並進
一步改善學習性能。在這個動機與目標下，本計畫提
出一個改良的反覆學習控制法則，稱之為狀態補償反
覆學習控制器 (state compensated iterative learning 
controller)。這個新的狀態補償反覆學習控制器將保有
反覆學習控制法則的簡易性，不必前饋或迴授控制器
的幫忙，針對本實驗的壓電致動器系統將有極佳的控
制性能。這個改良的基本物理觀念是來自於以下的想
法，我們知道壓電致動系統利用充電與放電的特性達
到壓電片伸張與收縮的位置精密控制目的，但是在反
覆來回的充放電過程並不一定會保持其動態特性不改
變，這在反覆學習的領域中，我們稱之為系統是
iteration-varying。對於反覆學習的控制而言，系統動態
若存在 iteration -varying 的特性，目前傳統使用的反覆
學習控制法則將可能無法滿足收斂條件，導致系統學
習產生發散行為。因此，狀態補償的觀念就由此而來，
我們相信透過狀態補償的效應，將可彌補實際壓電致
動器系統的遲滯與 iteration-varying 動態行為。另外，
本計畫也探討訊號濾波處理技術，讓狀態補償反覆學
習控制器能發揮其優勢。這個想法也來自於我們實驗
過程中發現偶而出現學習控制在一開始有良好的收斂
情形，但是學習次數過多，學習誤差進入某一個較小
的範圍內時，迴授訊號的雜訊有開始累積的現象，也
就是系統開始想要學習雜訊而非參考訊號。因此，本
計畫的第二個重點將深入研究不同的濾波技術，例如
零相位的FIR (Finite Impulse Response)濾波和小波轉換
(Wavelet Transform)濾波，以及非零相位的 B-撓線網路
(B-Spline Network)濾波等，希望結合狀態補償反覆學習
控制法則和數位訊號處理技術，對於壓電致動器進行
精密的追蹤定位控制。 
三、研究方法與理論成果 
本計畫實驗平台為德國 Piezomechanics 公司所生
產的壓電致動器實驗系統，如圖一所示： 
 
圖一：壓電致動器實驗系統 
在這個實驗硬體平台中，包含壓電致動器（圖一前方
所示）和功率放大器（圖一後方所示）。壓電致動器之
移動距離為 mμ 8− 到 mμ 40 ，輸入電壓為 -30V 到
+150V，致動器推動一個內有彈簧預壓之機台載具。壓
 4
( ) )()()()(
4
1
)(
)(~)( 200
2
00
2 zHzHzHzHz
zX
zXzH ss
dd
αα
+==  
其中 d 為完全重建訊號之相位延遲，和小波的種類和
階數有關。對於 l 層的小波轉換零相位濾波，我們可以
推導其轉移函數為 
( ) ( )( )
( )( )1
1
2
0
2
00
2
0
2
00
12
)...()(
)...()(
2
1
)(
)(~)(
−
− ∗=
=
−
l
ll
zHzHzH
zHzHzHz
zX
zXzH
sssl
ααα
 
B- 撓 線 網 路 濾 波 器 起 源 於 LFFC (learning 
feed-forward control)，LFFC 可以稱為另類的反覆學習
控制。LFFC 之控制器，區分為回授控制器(簡稱 FBC)
和前饋控制器(簡稱 FFC)，LFFC 的控制命令值是 FBC
命令值與 FFC 命令值的總和。FBC 是作即時誤差的回
授控制，傳統的 PID 即是一種 FBC。FFC 為一種反覆
學習控制器，基本上，本次學習週期 FFC 的命令值等
於學習增益乘以上一次 FBC 的命令值，再加上一次
FFC 的命令值。有一些 LFFC 的研究，其 FFC 採用類
神經網路，希望透過學習來調整類神經的權重，使得
受控體的輸出能趨近目標軌跡。較簡單的這類 FFC，
有的採用單層的 B-撓線網路(簡稱 BSN)，例如 BSN 的
輸入變數是時間，BSN 為 N 條等時距分布的三角形 B-
撓線，每條三角形 B-撓線代表時間變數所對應的三角
形歸屬值函數、歸屬值為 0 到 1，則 BSN 輸出為 
∑
−
=
N
k
i
kk
i
ff wttu
1
)()( μ  
其中 )(nuiff 代表 BSN 於第 i 次學習、時間 t 的命令值，
i
kw 代表 BSN 於第 i 次學習時、第 k 條 B-撓線的權重，
)(nkμ 代表時間 t 對應到第 k 條 B-撓線的歸屬值。每次
學習，是根據上一次受控體的誤差，亦即上一次的 FBC
的命令值，來調整權重。按照類神經之梯度下降法，
我們可以導出如下之權重調整法則 
∑
∑
=
=
−
− += T
t
k
T
t
i
fbk
i
k
i
k
t
tut
ww
0
0
1
1
)(
)()(
μ
μγ
 
其中γ 代表學習速率， )(1 tuifb− 代表 FBC 於第 1−i 次學
習、時間 t 的命令值， [ ]Tt ,0∈ 亦即每次學習的時間長
度是T 。因此，BSN 型 FFC 的控制法則為 ( ))()()( 11 tuftutu ifbiffiff −− += γ  
其中 ( ))(1 tuf ifb− 代表如下的 BSN 濾波函數 
( ) ∑ ∑
∑
=
=
=
−
− ≡
N
k
T
k
T
i
fbk
k
i
fb
u
ttuf
1
0
0
1
1
)(
)()(
)()(
τ
τ
τμ
ττμ
μ  
由此即可以推導從輸入 ( )tuifb1− 到輸出 ( ))(1 tuf ifb− 的 BSN
濾波器 Z 轉移函數 ( )zH 。 
•控制器收斂頻寬之分析： 
以上稍加介紹各種濾波器的基本原理是因為不同
的濾波器有其不同的轉移函數，因而會對於本計畫的
反覆學習控制器造成不同的收斂頻寬。以零相位 FIR
濾波器的設計為例，對於加入濾波功能的狀態補償反
覆學習控制器（請見方程式(1)），其收斂條件可以將濾
波器之轉移函數 )( fH （ )( fH 是將 ( )zH 套用 fjez π2=
所得之傅立葉轉換）代入控制器法則中，經過一些推
導之後可得， 
( )
( )
( ) ( )
( )fGG
fGfG
fE
fE
pfb
pff
i
i
+
−=
− 1
1
1
 
其中 
KG fb = ， 
( ) ( )∑−
=
⎟⎠
⎞⎜⎝
⎛ −−+−=
1
0
2
2
12cos
N
n
fj
ff fn
NnhLeKfG ππ  
( )fGp 代表壓電致動器的模式。因此，學習誤差的收斂
條件為 
( ) ( )
( ) ffGG
fGfG
fR
pfb
pff ∀<+
−= ,1
1
1
)(  
 
然而對於實際的壓電致動系統而言，上述收斂條件不
一定能適用於所有的工作頻率，因此，我們定義收斂
頻寬 bf 為 ( ) 1=bfR ，亦即 ( ) bfffR <∀< ,1  
為了使誤差收斂，低通濾波器 ( )fH 的截止頻率(cutoff 
frequency) cf 應當位於收斂頻寬 bf 之內，亦即 bc ff < 。
我們可以在收斂頻寬 bf 之內，選定一個截止頻率 cf ，
對於擬學習之輸出誤差進行低通濾波，濾得 cf 以下之
訊號成分做為反覆學習之用，並濾除 cf 以上之雜訊成
分，如此輸出誤差應當會隨著反覆學習而收斂。因此
截止頻率的選定，應先探討輸出誤差的頻譜分布，了
解輸出誤差的訊號成分和雜訊成分之區隔。 
•學習誤差之頻譜分析： 
基本上，學習誤差是一個非固定(non-stationary)訊
號。要分析非固定訊號的頻率內容，較常見的方式有
STFT (Short Time Fourier Transform)，WT (Wavelet 
Transform)，和 WVD (Wigner-Ville Distribution)。一般
而言，STFT 使用固定寬度之窗框(window)，低頻成分
解析度不如高頻成分解析度，WT 使用變動寬度之窗
框，高低頻成分解析度較一致，而 WVD 並非使用窗框
直 接 解 析 訊 號 ， 乃 是 透 過 訊 號 的 自 相 關
(auto-corrrelation)函數，對於訊號的能量作頻譜解析，
其解析度較 STFT 和 WT 為佳。不過 WVD 有一個問
題，那就是解析出來的頻譜或許會有鬼影(cross-term 
 6
0 200 400
0
0.1
0.2
0.3
0.4
Time index
In
st
an
t. 
fre
qu
en
cy
(cy
cle
/sa
mp
le)
 (b)
0 200 400
−5
0
5
Time index
Tr
ac
ki
ng
 e
rr
or
  (%
 st
ro
ke
)
 (a)
0 0.2 0.4
0
0.5
1
Frequency (cycle/sample)
ED
S
(x1
.40
e−
00
3J
/H
z)
 (c)
100 200 300 400
0
0.1
0.2
0.3
0.4
Time index
Fr
eq
ue
nc
y
(cy
cle
/sa
mp
le)
W
VD
 (J
/H
z/s
ec
)
 (d)
2
4
6
x 10−3
 
圖四： (a) 學習誤差量測訊號  (b) instantaneous 
frequency 的分析 (c) energy density spectrum 的分析 (d) 
smoothed pseudo Wigner-Ville Distribution. 
由圖四的(c)圖可以看出兩個明顯的能量密度頻譜，因
此，估計低頻部份為主要控制訊號，高頻部份則應為
雜訊，所以合理的推測應設計濾波器的截止頻率約為
1.0=cf 。另外，設並 FIR 濾波器長度為 35=N ，則
實驗所使用的 FIR 濾波器頻率響應圖如圖五所示： 
0 0.1 0.2 0.3 0.4 0.5−0.5
0
0.5
1
1.5
Frequency  (cycle/sample)
H
’(ω
)
 (a)
0 0.1 0.2 0.3 0.4 0.5−100
−50
0
50
Frequency  (cycle/sample)
|H
’(ω
)|  
(dB
)
 (b)
 
圖五：FIR 濾波器長度 35=N ，截止頻率 1.0=cf 的
頻率響應圖 
採用此一 FIR 濾波器至本計畫預計使用的狀態補償反
覆學習控制器，針對壓電致動器系統執行學習控制的
成果，顯示在圖六中，其中橫軸代表學習次數，縱軸
為學習誤差的 RMS 值，由實驗結果可以得知，本計畫
採用的方法與步驟是可行的，基本觀念與方向也是正
確的，不僅保有控制法則的良好實現性，比起現有文
獻所採用的控制結構都要簡易許多，對於壓電致動器
系統將可提供一個很好的參考設計方法。 
0 10 20 30 40 50 60 70 80 90 1000.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
2.25
2.50
Iteration index
R
M
S 
tra
ck
in
g 
er
ro
r  
(%
 st
ro
ke
)
0
80
160
240
320
400
480
560
640
720
800
R
M
S 
tra
ck
in
g 
er
ro
r  
(n
an
om
ete
r)
 
圖五：學習誤差的 RMS 值與學習次數的關係 
六、結論與討論： 
    本計畫提出一個利用即時學習誤差作為控制力修
正的的取樣時間反覆學習控制器，應用在重複控制的
受控問題上。本控制器引用當次學習控制的即時誤差
作為學習機構的設計訊號，並利用遺忘因子以克服初
始狀態誤差的強健性問題。本計畫證明整個學習系統
的穩定度、收斂性與強健性，並提出學習增益的設計
原則以及學習增益和學習性能的關係。本計畫另外從
事兩種不同的硬體實驗來實現學習控制法則。第一個
實驗目標是利用數位訊號處理器(DSP)的控制技術來
實做控制法則，以 C 語言作為設計的軟體工具。第二
個實驗目標則是以 PFGA 等可程式邏輯晶片來實現控
制法則，以硬體描述語言(VHDL)來完成其主要的運算
元電路，除了核心電路的設計之外，並探討電路架構、
電路面積與執行速度間的相對關係，藉此提供反覆學
習控制的另一個應用層面。 
七、計畫成果自評： 
   本計畫研究成果符合原計畫書之目標，在反覆學習
控制器的改良上得到一個重要的突破結果，並且依據
計畫書的規劃探討三種濾波器的設計，以應用在反覆
學習控制的實做上。目前所得的研究成果已有發表在
下列的期刊論文中： 
1. C.-J. Chien, F.-S. Lee and J.-C. Wang, “Enhanced iterative 
learning control for a piezoelectric actuator system using 
wavelet transform filtering,” Journal of Sound and 
Vibration, (SCI,EI), Volume 299, Issue 3, pp. 605-620, 
2007. 
2. F.-S. Lee, C.-J. Chien, and J.-C. Wang, “Trajectory tracking 
of piezoelectric actuators using state compensated iterative 
learning control,” Journal of Intelligent Material Systems 
and Structures, (SCI,EI), Vol. 18, No. 6, pp. 555-567, 2007. 
參考文獻 
[1] S. Arimoto, S. Kawamura and F. Miyazaki, “Bettering operation of 
robots by learning,” Journal of Robot. Syst., vol. 1, no. 2, pp. 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          96 年 10 月 10 日 
報告人姓名 
 
簡 江 儒 
 
服務機構
及職稱 
華梵大學電子系 
教授 
會議時間 
會議地點 
2007 年 10 月 1 日至 3 日 
新加坡 
本會核定
補助文號
 
 
會議 
名稱 
 (中文) 2007 年 IEEE 系統與控制多種會議 
 (英文) IEEE Multi-conference on Systems and Control, 2007 
發表 
論文 
題目 
 (中文) 機械臂的單參數適應反覆學習控制器 
 (英文) A One-Parameter Structure for Adaptive Iterative Learning Control of 
Robot Manipulators 
報告內容應包括下列各項： 
 
一、參加會議經過 
報告人於 2007 年 10 月 1 日至 10 月 3 日至新加坡參加 2007 年 IEEE 系統與控制多
種會議(IEEE Multi-conference on Systems and Control, 2007)，發表一篇邀請全篇論文，
並擔任該邀請論文場次的共同主持人。2007 年 IEEE 系統與控制多種會議於 2007 年 10
月 1 日至 10 月 3 日在新加坡的 Suntec 國際會議中心舉行，報告人與國立台灣大學電機
系連豐力教授同行，於 9 月 30 日清晨 7：40 搭乘長榮航空由中正機場出發，直接飛抵
新加坡樟宜國際機場，飛抵新加坡已經是中午 12 點多了。隨即再搭乘旅館接送巴士至
開會的旅館。新加坡是一個國際知名的大城市，有花園城市的美稱，街道整齊清潔，綠
樹遍處，的確名不虛傳。不過接近赤道的地理位置讓新加坡終年炎熱，我們到的這幾天
正是天氣溫度較為偏高的幾天，的確較為辛苦。第一天安定之後，就和南洋理工大學電
機系余明裕教授取得聯絡，余教授於下午兩點半至旅館接我們，帶領本人與連教授參觀
國立新加坡大學和南洋理工大學。雖然今天的參觀活動以硬體的建築以及校園為主，但
仍然對於新加坡這兩所排名世界大學百大之內的有名大學，留下一個很深的印象。晚上
回大會會場參加歡迎晚宴，認識一些其他國家來的教授學者。 
第二天正式參加本次會議，除了聆聽多場專題演講外，也選擇部分與研究專長相關
的論文發表會場聽取其他學者的論文報告。第一天本人並接受加拿大 Lakehead 
University 的 Prof. Tayebi 請託，幫忙他報告他們的論文。該論文的場次為反覆學習控制
的邀請場次(invited session)，正是本人研究的主要領域，因此借此機會參與討論，不啻
為一舉兩得的事情。第一天會議結束，本人受邀參加大會舉辦的 VIP 邀宴，前往新加
坡著名的聖陶沙風景區參加晚宴，並欣賞十五分鐘的表演。第二天則為本人論文的發
表，本論文亦為邀請論文，是本人與前述新加坡南洋理工大學余教授共同主持的邀請場
次。本場次論文發表非常順利，在場學者也給各論文許多精闢的見解與建議，是一個非
 
A One-Parameter Structure for Adaptive Iterative Learning Control of
Robot Manipulators
Chiang-Ju Chien and Abdelhamid Tayebi
Abstract— In this paper, a new one-parameter structure is
presented for the design of adaptive iterative learning controller
for repetitive control of robot manipulators. Only one control
parameter is needed for compensation of the unknown plant
information so that the size of memory for storage of previous
control information can be greatly reduced. In addition to the
new control structure, an adaptive algorithm combining time-
domain and iteration-domain adaptation is also proposed. The
combined adaptive law can relax the requirement of certain
unknown upper bound usually used in current existing adaptive
iterative learning control schemes. The technical analysis shows
that the boundedness of all the internal signals and convergence
of the learning error are guaranteed without using projection
mechanism in adaptive laws. Finally, a simulation result is
provided to illustrate the effectiveness of the learning controller.
Key words : Iterative learning control; adaptive control;
robot manipulator;
I. INTRODUCTION
Classical PD and PID linear controllers are widely used in
robotics applications due to their implementation simplicity.
In the early works [1], [2], [3], most of the controllers were
designed to asymptotically stabilize the joint positions of
rigid robot manipulators at a given set-point. Owing to the
physical property that the robot parameters enter linearly in
the Lagrange equation, adaptive control strategies [4], [5]
have been derived for trajectory tracking instead of set-point
regulation.
Taking advantage of the fact that robot manipulators are
generally used in repetitive tasks, several iterative learning
control (ILC) schemes have been proposed for robot manip-
ulators in the past two decades. The main objective of ILC
approach is to enhance the tracking accuracy from operation
to operation for systems executing repetitive tasks. Initially,
ILC algorithms for robot manipulators were developed based
on the contraction mapping theory and required a certain a
priori knowledge of robot dynamics [6], [8], [7], [14], [9].
In the past decade, another type of ILC algorithms, namely
adaptive iterative learning control (AILC), has been widely
studied in the literature. Substantial efforts, in the area of
This work is supported by the National Science Council, R.O.C., under
Grant NSC95-2221-E-211-008
Chiang-Ju Chien is with the Department of Electronic Engineer-
ing, Huafan University, Shihding, Taipei County, 223, Taiwan. e-mail:
cjc@huafan.hfu.edu.tw
Abdelhamid Tayebi is with the Department of Electrical Engineering,
Lakehead University, 995 Oliver Road, Thunder bay, Ont., Canada. e-mail:
Abdelhamid.Tayebi@lakeheadu.ca
AILC design for robot manipulators, have been deployed
during the last decade (see, for instance, [10], [11], [12], [13],
[15]). The main feature of AILC is to iteratively estimate the
uncertain parameters, which are in turn used to generate the
current control input. Because of the iteration based control
problem, the adaptive learning laws for the estimation of the
unknown parameters are mostly designed in the iteration-
domain. In general, projection or deadzone mechanisms are
necessary to construct the iteration-domain based adaptive
laws in order to guarantee the tracking error convergence as
well as the boundedness of all internal signals. In [13] both
time-domain and iteration-domain adaptations were used. A
time-domain adaptive law estimates the robot parameters so
that the upper bounds on these parameters are not necessary.
However, the iteration-domain learning law which learns the
desired input and disturbances still needs the upper bound
and the projection mechanism. Recently, in [15], three AILC
schemes have been proposed for the tracking problem of
rigid robot manipulators without any a priori knowledge of
the robot dynamics.
In [15], a two-parameter control structure was proposed
for the design of adaptive iterative learning controller. One of
the main features of [15] is that only two control parameters
are needed for adaptation so that the size of memory for the
storage of previous control information can be reduced, espe-
cially when compared with the related works. In this paper,
a new one parameter structure is presented for the design of
learning controller to further reduce the number of control
parameters to be one. Furthermore, a new adaptive law
using mixed time-domain and iteration-domain adaptation is
developed in this paper to relax the requirement of projection
mechanism. It will become a pure time-domain learning
law or iteration-domain learning law if a weighting gain is
suitably chosen. In other words, the proposed adaptive law is
a general formulation and extension for the existing results
[10]-[15]. We show that the finiteness of control parameters
and control input can be guaranteed for all the time interval
during each iteration without using parameter projection.
This implies that the upper bounds on the desired unknown
control parameters are not necessary. Another interesting
feature of this adaptive law is that the weighting gain can
be set to be zero such that only time-domain adaptation is
executed. In this case, the memory for storing the control
information in the previous trial can be even omitted. A
rigorous proof via the technique of Lyapunov-like analysis
is given to guarantee the stability and convergence of the
closed-loop learning system. It is shown that all adjustable
parameters as well as internal signals are bounded in time
22nd IEEE International Symposium on Intelligent Control
Part of IEEE Multi-conference on Systems and Control
Singapore, 1-3 October 2007
TuA07.3
1-4244-0441-X/07/$20.00 ©2007 IEEE. 327
= ‖sk‖
(
(θ1 + θ2) + (θ2 + θ3)‖ ˙˜qk‖+ θ4‖q˜k‖
+ θ4‖ ˙˜qk‖‖q˜k‖
)
− s⊤k τk
≤ ‖sk‖θ
(
1 + ‖ ˙˜qk‖+ ‖q˜k‖+ ‖ ˙˜qk‖‖q˜k‖
)
− s⊤k τk
= ‖sk‖η( ˙˜qk, q˜k)θ − s
⊤
k τk (3)
where η( ˙˜qk, q˜k) = (1 + ‖ ˙˜qk‖ + ‖q˜k‖ + ‖ ˙˜qk‖‖q˜k‖), θ =
max{θ1+θ2, θ2+θ3, θ4}. Under this condition, let the control
torque be designed as
τk(t) = Ksk(t) + sgn(sk)η( ˙˜qk, q˜k)θˆk(t) (4)
where K ∈ Rn×n is a symmetric positive definite matrix,
sgn(sk) = [sgn(s1k), · · · , sgn(snk)]
⊤
. θˆk(t) ∈ R is an on-
line adaptive control parameter used to compensate for the
unknown plant parameter θ. It is updated by the following
adaptive law which combines time-domain and iteration
domain adaptation :
(1 − γ)
˙ˆ
θk(t) = −γθˆk(t) + γθˆk−1(t)
+ β‖sk(t)‖η( ˙˜qk, q˜k) (5)
where 0 < γ < 1, β > 0 are defined as the weighting
gain and learning gain, respectively. The initial value of the
parameter is set to be θ̂k(0) = θ̂k−1(T ) ∀k ∈ Z+, and the
initial parameter profile for k = 0 is chosen as θ̂0(t) =
θini, ∀t ∈ [0, T ] where θini is a constant parameter. In
general, the adaptive law (5) will become a pure time-domain
adaptive law if γ = 0, or a pure iteration-domain adaptive
law if γ = 1. In addition to the convergence of q˜k(t) and
˙˜qk(t) to zero when k tends to infinity, we will also guarantee
the boundedness of all the internal signals, especially the
boundedness of the parameter θ̂k(t) and control torque τk(t).
IV. STABILITY AND CONVERGENCE ANALYSIS
To study the stability and convergence of the proposed
one parameter structure adaptive iterative learning controller
for robot manipulators, we use the concept of Lpe[0, T ] in
the subsequent discussions to denote the set of Lebesgue
measurable (or piecewise continuous) real valued (vector)
functions with Lpe norm [15]
‖x(t)‖pe =

(∫ T
0
‖x(t)‖pdt
) 1
p
if p ∈ [1,∞)
sup
0≤t≤T
‖x(t)‖ if p =∞
We say that x(t) ∈ Lpe[0, T ] when ‖x(t)‖pe exists (i.e.,
when ‖x(t)‖pe is finite).
At first, we will derive the boundedness of s1(t), q˜1(t),
˙˜q1(t), θ̂1(t), τ1(t) at the first iteration in a way different
from that for sk(t), q˜k(t), ˙˜qk(t), θ̂k(t), τk(t) with k ≥ 2.
Proposition 1 : Consider the robot manipulator system
(1) with properties (P1-P3) under the control torque (4)
and parameter adaptive law (5). If assumptions (A1-A2)
are satisfied, then we have s1(t), q˜1(t), ˙˜q1(t), θ̂1(t), τ1(t)
∈ L∞e[0, T ].
Proof. Let us consider the following Lyapunov-like positive
definite function :
Vk(t) =
1
2
s⊤k (t)M(qk)sk(t) +
1− γ
2β
θ˜ 2k (t) (6)
where θ˜k(t) = θ̂k(t)− θ is the parameteric estimation error.
Its derivative with respective to time t along (1) can be
computed by using (3) and (4) as follows:
V˙k =
d
dt
1
2
s⊤k M(qk)sk +
1− γ
β
θ˜k
˙˜
θk
≤ ‖sk‖η( ˙˜qk, q˜k)θ − s
⊤
k τk +
1− γ
β
θ˜k
˙˜
θk
= −s⊤k Ksk − ‖sk‖η( ˙˜qk, q˜k)θ˜k +
1− γ
β
θ˜k
˙˜
θk
(7)
Using the adaptive law (5) and the fact that −γ θ̂k+γθ̂k−1 =
−γθ˜k + γθ˜k−1, inequality (7) leads to
V˙k ≤ −s
⊤
k Ksk − ‖sk‖η( ˙˜qk, q˜k)θ˜k
+
1
β
θ˜k
(
−γθ˜k + γθ˜k−1 + β‖sk‖η( ˙˜qk, q˜k)
)
= −s⊤k Ksk −
γ
β
θ˜ 2k +
γ
β
θ˜kθ˜k−1
= −s⊤k Ksk +
γ
4β
θ˜ 2k−1 −
γ
β
(
θ˜k −
1
2
θ˜k−1
)2
≤
γ
4β
θ˜ 2k−1 (8)
Now, consider the first iteration of k = 1. Since θ̂0(t) in the
adaptive law (5) is chosen as a constant θini ∀t ∈ [0, T ], we
have θ˜0(t) = θ̂0(t)−θ = θini−θ ≡ θ0 and θ˜1(0) = θ̂1(0)−
θ = θ̂0(T )− θ = θini − θ ≡ θ0. This implies that the initial
condition of V1(0) = 12s
⊤
1 (0)M(q1)s1(0) +
1−γ
2β θ˜
2
1 (0) =
1−γ
2β θ
2
0 is bounded due to assumption (A2). The Lyapunov-
like function (6) at the first iteration will now satisfy
V˙1(t) ≤
γ
4β
θ˜ 20 (t) =
γ
4β
θ
2
0 (9)
which readily concludes that V1(t), s1(t), q˜1(t), ˙˜q1(t), θ˜1(t)
∈ L∞e[0, T ] and hence, τ1(t) ∈ L∞e[0, T ]. Q.E.D.
Based on the results given in Proposition 1, we next prove
the boundedness of sk(T ), q˜k(T ), ˙˜qk(T ), θ̂k(T ) at the end
of each iteration and the convergence of s⊤k sk in the sense
of L1e norm.
Proposition 2 : Consider the problem set-up in Proposition
1. The proposed adaptive iterative learning system ensures
that sk(T ), ˙˜qk(T ), q˜k(T ), θ˜k(T ),
∫ T
0
θ˜ 2k dt, and
∫ T
0
s⊤k skdt
are bounded ∀k ∈ Z+ and
lim
k→∞
sk(T ) = lim
k→∞
∫ T
0
s⊤k Kskdt = 0.
Proof. Define a positive definite functional Wk(T ) as
Wk(T ) =
∫ T
0
γ
β
θ˜ 2k dt+
1− γ
2β
θ˜ 2k (T ) (10)
TuA07.3
329
0, ∀t ∈ [0, T ] according to the definition of sk(t). This
completes the proof. Q.E.D.
Remark : In this paper, we present a general adaptive
learning algorithm combining time-domain and iteration-
domain adaptation for adaptive iterative learning control of
robot manipulators. In the main theorem, we show that ˙˜qk(t)
and q˜k(t) converge to zero for all t ∈ [0, T ] as the iteration
number k → ∞ with all the internal signals belonging to
L∞e[0, T ]. For the extreme case of γ = 1, the adaptive law
(5) becomes a pure iteration-domain adaptive law similar as
that in [15] as follows :
θ̂k(t) = θ̂k−1(t) + β‖sk(t)‖η( ˙˜qk, q˜k) (21)
with θ̂0(t) being some specified initial vector. The main
advantage of (21) is that it can be applied to systems with
time-varying parameters and the learning convergence speed
is in general faster than the case of γ ∈ [0, 1). But, without
a projection mechanism, only L2 boundedness of control
parameters is guaranteed. On the other hand, another extreme
case of γ = 0 results in a pure time-domain adaptive law
˙̂
θk(t) = β‖sk(t)‖η( ˙˜qk, q˜k) (22)
where θ̂k(0) = θ̂k−1(T ), ∀k ∈ Z+ and θ̂1(0) = θini for
some specified constant vector θini. The technical results
shown in our theorem are still valid for the case of γ = 0.
In fact, Eq. (22) is similar to the adaptive law presented in
[17]. The main feature of (22) is that the previous parameter
profile during the time interval [0, T ] is no longer needed.
However, the convergence speed of the learning error is
in general slow, especially when compared with the cases
of γ 	= 0. This can be easily seen from (14), where larger
values of γ contribute to generate a more negative term in
the right hand side. By increasing γ will result in Wk much
smaller than Wk−1 indicating higher convergence rates.
V. SIMULATION RESULTS
To demonstrate the effectiveness of the proposed adaptive
learning controller, we consider a two degrees-of-freedom
planar manipulator with revolute joints described by (1). The
matrix M = [mij ]2×2 is given by m11 = m1ℓ2c1 +m2(ℓ21 +
ℓ2c2 + 2ℓ1ℓc2 cos q2) + I1 + I2, m12 = m21 = m2(ℓ
2
c2 +
ℓ1ℓc2 cos q2) + I2, and m22 = m2ℓ2c2 + I2. The matrix C =
[cij ]2×2 is given by c11 = hq˙2, c12 = hq˙1 + hq˙2, c21 =
−hq˙1, and c22 = 0 where h = −m2ℓ1ℓc2 sin q2. The vector
G = [G1, G2]
⊤ is given by G1 = (m1ℓc1 +m2ℓ1)g cos q1 +
m2ℓc2g cos(q1 + q2) and G2 = m2ℓc2g cos(q1 + q2). The
robot parameters shown above are given by m1 = m2 =
1Kg, ℓ1 = ℓ2 = 0.5m, ℓc1 = ℓc2 = 0.25m, I1 = I2 =
0.1Kg.m2, g = 9.81m/s2. The disturbances are assumed to
be d1 = d2 = rand(k) sin(t) where rand(k) is a random
function taking its value between 0 and 1. The formulation
of the disturbances implies that they are time-varying and
varying from iteration to iteration. The desired trajectories
for q1 and q2 are chosen as q1,d(t) = sin(2πt) and q2,d(t) =
cos(2πt) over the time interval is [0, 1] second.
At first, we investigate the convergence of the sup-norm for
the joint position tracking errors versus the iteration number
k. The control gain K is set to be K = 20I2×2 where I2×2
is a 2 × 2 identity matrix and the learning gain is set to
be β = 20, respectively. Figure 1 (a) shows the evolutions
of supt∈[0,1] q˜1,k(t) and supt∈[0,1] q˜2,k(t) versus the iteration
number k when γ = 0.5. After 20th trials, the sup-norm of
position error is less then 0.0093 radian for joint one and
less than 0.004 radian for joint two.
In order to study the effect of the parameter γ, we
choose the sup-norm of the position error at joint one
for comparisons. Figure 1 (b), illustrates the evolution of
supt∈[0,1] q˜1,k(t) versus the iteration number k with γ =
0, 0.5 and 1, respectively. In other words, the pure time-
domain, combined domain and pure iteration-domain adap-
tive laws are applied for simulation. No matter what the
value of γ is, the error convergence is guaranteed once
0 ≤ γ ≤ 1. However, the convergence speed is faster if
γ is larger. Finally, the trajectories of the control parameter
and control torque at the 20th trial are shown in Figure 2
and Figure 3, respectively, to show the boundedness of the
internal signals.
0 2 4 6 8 10 12 14 16 18 20
0
0.05
0.1
0.15
0.2
0.25
(a)
0 2 4 6 8 10 12 14 16 18 20
0
0.05
0.1
0.15
0.2
0.25
(b)
Figure 1 :
(a) supt∈[0,1] q˜k(t) (radian) versus trial number k;
· · · for link 1, ◦◦◦ for link 2, γ = 0.5.
(b) supt∈[0,1] q˜1,k(t) (radian) versus trial number k;
· · · for γ = 0, ∗ ∗ ∗ for γ = 0.5, ◦◦◦ γ = 1.
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
35.4
35.5
35.6
35.7
35.8
Figure 2 : θˆ20(t) versus t.
TuA07.3
331
