these two ways to find the best matching method. We 
are going to use the CMU PIE database to examine the 
proposed method. We saved execution time and obtained 
excellent recognition rates. 
英文關鍵詞： Color image, image matching, face recognition, 
illumination condition, normalized gradients, 
recognition rate 
 
  
先前已有許多基於 Hausdorff 距離函數
的影像比對法[1-5]. Gualtieri et al. [1]提出兩
種基於古典 Hausdorff 距離而有效率的影像
比對法。You et al. [2]應用 Hausdorff距離於
有興趣的比較點取代邊界圖上的點為比較
影像的點。作者應用在二元影像中時，先以
距 離 轉 換 (distance transform) 再 計 算
Hausdorff 距離. 如果以 Hausdorff 距離的定
義直接計算最小距離是很耗時的。若先將參
考的形狀做距離轉換(DT)將會顯著的加速
計算程序。距離轉換(DT)將一個二元影像的
內容轉成一個新的影像其值為與最近的非
零像素的距離。這個新的影像所含的距離值
為與原始影像的邊緣最小距離。計算時以歐
基里德距離是很費時，所以以 chamfer 距離
取代。 Chamfer 轉換為一個循序的處理過
程此為一個疊代的方法與距離轉換類似。
Gesu和 Starovoitov [3]定義幾個影像距離函
數，包括以 Hausdorff 距離為基礎，以區域
距離為基礎，以全域特徵為基礎，以及以對
稱為基礎的演算法在 JACOB 相片資料庫裡
比對影像。 Ghafoor et al. [4]提議一個距離
變換比對(chamfer)的延伸而成為一個強韌
的影像比對法。Perlibakas [5] 比較 14段距
離測量,例如 Lp， 均方錯誤(MSE) ，….，
等等，加上主元件分析，以(PCA)為基礎的
臉部識別， 並且提出一個修正後以誤差和
(SSE)為基礎的對臉部識別的距離函數。  
很多研究者提出修改後的 Hausdorff 距
離用在不同目的的相似度量中 [6-11]。 
Hausdorff 距離的最獨特的好處是它不需要
在兩個物件或者兩張影像之間的對應點即
可計算得到。Huttenlocher et al. [6] 應用具方
向性的 Hausdorff 距離來發展出依據距離做
影像調整的有效率演算法。Dubuisson和 Jain 
[7] 發展出幾種修飾的 Hausdorff距離(MHD)
用來比較灰階影像的邊界圖。Paumard [8]提
出一個應用在二元影像的審查 Hausdorff 距
離(CHD)。Takacs [9]引進鄰域函數和相關懲
罰來擴展 MHD 的運用在臉部識別。另外
Sim , et al. [11]把M-估計和最小整理平方估
計與 Hausdorff 距離結合起來達到強韌的影
像比對。 
那些基於幾何為基礎的影像比對法被
認定比縱使沒有亮度變化的以亮度為基礎
的方法更為強韌。一些先前的使用 Hausdorff
距離已經被用於物件識別上[12-17]. Yi 和
Camps [12]發表一個以線段為基礎的辨識演
算法在以模型為基礎的辨識上，藉由一四維
Hausdorff距離與線斷特徵的比對。Gao and 
Leung [13]運用人臉的邊界圖上的主要點來
合併架構和空間訊息以萃取可代表臉部的
線段集合，然後藉由 Hausdorff 距離來計算
臉部比對的相似性度量。其比對結果被稱為
線段 Hausdorff距離(LHD)。Guo et al. [14]
提出一個新的修飾的 Hausdorff 距離，其所
使用比重函數來自臉部的空間資訊。而且，
Lin et al. [15] 提出修改的 Hausdorff距離以
eigenface特徵來決定的空間比重。比重函數
基於 eigenface 提供重要的臉部特徵的比
重，例如眼睛，嘴和表面輪廓。Zhu et al. [16] 
利用一個改進的 Gabor 過濾器來計算邊界
圖，並且在一個環形 Gabor特徵空間裡使用
一個具權重的修飾後的 Hausdorff 距離
(WMHD)。 Kwon et al. [17] 提出利用一個
強韌的階層 Hausdorff 距離，在一多層金字
塔結構裡比較邊界圖。 
在不同亮度變化的臉部識別被認定為
在臉部識別中的一個重要並且具有挑戰性
的問題 [18-21]。雖然前面提到的基於幾何
的方法對於平滑的亮度變化更具強韌性，這
種方法倚賴於在不同的條件時擷取臉部影
像其萃取邊界或幾何特徵的可靠性。相當多
的努力已經用在於基於亮度的影像比對陣
營中。Georghiades et al. [18] 藉由引進一個
亮度圓錐在不同亮度的條件下比對臉部影
像時提出一個新的演算法，其擷取同一個人
在不同姿勢與不同亮度和方向上的數張影
  

 


 ),( ),( ),(max
)),((1),(
),(
ji Wlk
clkI
jiTI
TIE
jiT
 (2) 
其中絕對中心位置是在在被變換的位置
後的 T(i,j), 並且 c 是一個正常數，被用來剔
除零梯度變化導致的無窮大的量。Γ 表示比
較的像點總數的集合。確定萃取的輪廓位置
包含最大的相對梯度大小。邊緣偵測被使用
為輪廓萃取的方式。選擇候選邊緣地點是以
在一個位置區域的局部最大值的梯度大小
沿它的梯度方向選取。因而，輪廓位置應該
是與最大相對梯度的位置一致。 
在上述相似性度量, 我們只考慮影像梯
度的大小而忽略向量梯度的方向。為了影像
比對更加強健，我們將向量梯度的方向一致
性加到影像相似性度量。影像相似性度量被
修改如下 

 



 ),( 1),(
1
0
),(
0
01 ),(max
)),((
),(max
),(1);,(
),(),(
ji WlkWlk
clkI
jiTI
clkI
jiIITIE
jiTji
 (3) 
其中 I0 是用來比對的臉部影像或叫樣板
臉部影像，而 I1 是包含整個臉部要搜尋的
影像。符號‧是內積。因為正規化後的內積
的絕對值是在 0和 1之間，所以正規化的相
似性度量一定是在 0和 1之間。這樣使得更
增加搜尋臉部影像與樣板臉部影像的相似
性度量的可靠性，而具有更大的價值。 
如何消除由於陰影或強度飽緩和問題，
我們在各自的相似性度量上的點分配權重
以消除非常明亮或非常黑暗的強度值。修改
過的相似性度量成為 
 






ji
ji
WlkWlk
jiTI
jiTI
clkI
jiTI
clkI
jiI
ITIE jiTji
,
,
1
1
1
),(
1
0
),(
0
01 ))),(((
))),(((
),(max
)),((
),(max
),(
);,( ),(),( 
  (4) 
其中強度權重函數被給予為 








255)
255
*
2
cos(
1
0)
2
sin(
)(
IIwhere
I
II
IIIwhere
IIwhere
I
I
I
Ub
Ub
Ub
UbLb
Lb
Lb


  (5) 
ILb 和 IUb 意味權重作用的最大下界和
最小上界面。這個加權函數的說明在圖 1。
像點接近明暗度值離零或 255的灰階值，在
相似性度量中我們分配較小的權重。在公式
(4)的分母的正規化因子，是變換的位置後的
所有權重總和。使用正規化因子的用途為修
改相似性度量正規化後的度量落在[0,1] 。 
在我們的臉部比對的演算法中，我們為
每個在臉部資料庫的臉部影像樣板，藉由邊
緣偵測以某一個量為過濾值來萃取臉部輪
廓。另外，我們也計算正規化梯度為臉部影
像樣板資料庫。然後, 我們輸入臉部影像 I1 
與各個樣板臉部影像 I0比較，解決以下最佳
化的問題：注意這個最佳化問題可以用
Levenberg-Marquardt 算法解決[16] 可利用
一些幾何轉換參量為初始的猜測。在實踐
上，我們先運用一種臉部偵測算法發現臉部
的近似位置和大小在輸入的影像，如此提供
幾何轉換參量的一個最初的猜測。然後 , 
Levenberg-Marquardt 算法被運用最佳化相
似性度量作用在所有樣板臉部影像。具有最
佳化相似性度量的樣板臉部是最接近輸入
臉部。所以，這是最接近的臉部辨識結果。
換句話說，臉部辨識可能被公式化作為以下
最佳化問題: 
);,(maxmaxarg )(01
k
TFk
ITIE
  (6) 
其中是 )(0kI 是第 k個臉部樣板影像，F 表示
在資料庫所有臉部樣板影像。 
  
3. 實驗結果 
我們利用卡內基美隆大學(CMU)的姿
勢、亮度和表情(Pose, Illumination, and 
Expression,  PIE) 人臉資料庫。其中共有 68
人的 41,368 張臉部影像。其中包含 13種不
同姿勢，43種不同亮度和 4種表情。我們只
選擇如圖 3的 4種亮度臉部影像。 
 
  
 
 
(a) 無特別光源 (b)左側光源 (c)正面光源 (d)右側光源 
圖 3 各種不同光源的影像 
以左側光源、正面光源與右側光源為參考臉
部，無特別光源為實驗臉部。取 68人的各 4
張為實驗影像。參考我們之前使用的的參數
[20]，實驗參數如下：平均濾波器模板大小
為 3x3，梯度正規化的區域視窗為 5x5，光
照強度權重函式其下限為 60，上限為 230。
正規化常數 c為 5。我們可以化簡 RGB彩
色影像為灰階影像，可以減少 2/3的計算時
間，其辨識率與分別使用一個彩色影像的
RGB三張加上三個不同亮度的影像，共需要
比對 9張。即每張臉的 R頻道比對所有資料
庫的三種不同光源的 R頻道，其他 2種頻道
亦同。我們測試了比對結果，其辨識率為下
表所示。 
表 1：各種比對方法的辨識率 
 
4. 結論與建議 
我們提出一個有效的臉部比對演算法
來克服由於不同光線情況下的問題。我們以
一張彩色影像的 Y 頻道代表 RGB 三張影
像，這樣可以大約減少為 1/3 的比對時間。
為了正確地比對，在臉部輪廓的位置，我們
使用相對梯度變化的特性。在這個研究當中
提出了一個基於在累積梯度變化內積的相
似方法。此外，包含在相似方法中的適當強
度權重減輕了陰影及強烈飽和度的問題。基
於這個新的相似方法，我們將臉部比對如同
相當於一致的最佳化問題的臉部辨識問
題，公式化地表示出。由於相似方法只有在
臉部輪廓位置被計算，其計算的值與整個臉
部影像比對方法相對的低很多。在我們的實
驗中，在不同光線情境下，我們對 CMU PIE
臉部資料庫，應用提議的臉部比對演算法。
我們會考慮用其他影像資料與 AR臉部資料
庫來做實驗，以說明我們的演算法是辨識率
極高的演算法。 
致謝 
本論文由國科會補助 
(NSC 100-2221-E-364 -001 -) 
參考文獻： 
[1] J.A. Gualtieri, J. Le Moigne, and C.V. 
Packer, “Distance between images,” 
Frontiers of Massively Parallel 
Computation, 1992., Fourth 
Symposium on the, pp.:216 – 223, 
19-21 Oct. 1992 
[2] J. You, E. Pissaloux, J.-L. Hellec, and P. 
Bonnin, “A guided image matching 
approach using Hausdorff distance 
with interesting points detection,” 
Image Processing, 1994. Proceedings. 
ICIP-94., IEEE International 
Conference, Volume: 1, pp. 968 - 972 
vol.1, 13-16 Nov. 1994 
  
March, 2004,  
[17] O.-K. Kwon, D.-G. Sim, and R.-H. 
Park, “Robust Hausdorff distance 
matching algorithms using pyramidal 
structures,” Pattern Recognition, 
Volume: 34, Issue: 10, pp. 2005-2013, 
October, 2001 
[18] A. S. Georghiades, D. J. Kriegman, and 
P. N. Belhumeur, “From Few to Many: 
Illumination Cone Models for Face 
Recognition under Variable Lighting 
and Pose,” IEEE Trans. Pattern 
Analysis Mach. Intel., Vol. 23, No. 6, 
pp. 643-660 June 2001 
[19] W.-Y. Zhao and R. Chellappa, 
“Illumination-insensitive face 
recognition using symmetric 
shape-from-shading,” Proc. IEEE Conf. 
Computer Vision Pattern Recognition, 
pp. 286-293, 2000. 
[20] C.-H. T. Yang, S.-H., Lai, and L.-W. 
Chang, “Robust Face Image Matching 
under Illumination Variations” 
EURASIP Journal on Applied Signal 
Processing, Vol. 2004, No. 16, 
November 2004 
[21] S. Shan, W. Gao, and D. Zhao, 
“Illumination normalization for robust 
face recognition against varying 
lighting conditions,” Proc. IEEE 
International Workshop on Analysis 
and Modeling of Faces and Gestures, 
pp. 157 – 164, 2003. 
[22] P. N. Belhumeur, J. P. Hespanha, and D. 
J. Kriegman, “Eigenfaces vs. 
Fisherfaces: recognition using class 
specific linear projection,” IEEE Trans. 
Pattern Analysis Mach. Intel., Vol. 19, 
No. 7, pp. 711-720, 1997. 
[23] Chengzhang Wang; Baocai Yin; 
Xiaoming Bai; Yanfeng Sun; “Color 
face recognition based on 2DPCA”, 
Pattern Recognition, 2008. ICPR 2008. 
19th International Conference on 8-11 
Dec. 2008 Page(s):1 – 4 
[24] Jae Young Choi; Yong Man Ro; 
Plataniotis, K.N.; “Color Face 
Recognition for Degraded Face 
Images” Systems, Man, and 
Cybernetics, Part B: Cybernetics, IEEE 
Transactions on Volume 39, Issue 5, 
Oct. 2009 Page(s):1217 – 1230 
[25] Wijaya, I.G.P.S.; Uchimura, K.; 
Zhencheng Hu; “Pose Invariant Color 
Face Recognition Based on Frequency 
Analysis and DLDA with Weight Score 
Classification”, Computer Science and 
Information Engineering, 2009 WRI 
World Congress on Volume 6, March 
31 2009-April 2 2009 Page(s):90 – 94 
[26] Liu Fanjun; Cao Binggang; Wang 
Junping; Zhou Kai; “Color Image 
Similarity Measurement and Its 
Application in Matching”, Intelligent 
Computation Technology and 
Automation, 2009. ICICTA '09. Second 
International Conference on Volume 1, 
10-11 Oct. 2009 Page(s):566 – 568 
[27] Hashem, H.F.; “High performance pose 
of human face recognition for different 
color channels”, Radio Science 
Conference, 2009. NRSC 2009. 
National 17-19 March 2009 
Page(s):1 – 5 
[28] Berbar, M.A.; Kelash, H.M.; Kandeel, 
A.A.; “Faces and Facial Features 
Detection in Color Images”, Geometric 
Modeling and Imaging--New Trends, 
 1
 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                  日期：2011 年 09 月 20 日 
一、參加會議經過 
啟程：2011/09/15 早上 
返國：2011/09/19下午 
報告時間：2011/09/17 下午1:00-2:30 
報告方式：口頭報告 
二、與會心得 
1. 這個報告論文，以影像處理方法應用在影像資訊隱藏上。  
2. 口頭報告的敘述和詢問者的問題都是要很精準表達和了解。 
3. 和相同領域的學者互相交流，親自體會其他人對這些相同或類似的問題的看法或
解決之道。 
4. 和台灣去的老師與同學交換不同問題的心得。  
5. 聆聽一些有興趣的議題，幫助了解更多相關的領域。  
6. 宜昌是大陸二線城市，除三峽工程耗大之外還不是很發達。 
三、發表論文全文或摘要：如附件，文章被 EI 收錄 
四、建議：很具多樣性的會議，但大陸參與者多為學生，水準不高。 
五、攜回資料名稱及內容： 
計畫編號 NSC100－2221－E－364－001－ 
計畫名稱 在不同亮度下基於色彩差異與 YIQ 中 Y 頻道梯度變化的彩色影像比對法 
出國人員
姓名 楊權輝 
服務機構
及職稱 
玄奘大學資訊管理學 
系助理教授 
會議時間 
2011 年 9 月 16 日 
至 
2011 年 9 月 18 日 
會議地點 宜昌，中國大陸 
YiChang , China 
會議名稱 
第二屆國際電子與控制工程研討會 
The 2nd International Conference on Electrical and Control Engineering 
(ICECE2011) 
發表題目 
基於 Shamir與離散Haar小波轉換的可回復秘密影像分享 
Reversible Secret Image Sharing Based on Shamir’s Scheme with Discrete 
Haar Wavelet Transform 
附件五 
Reversible Secret Image Sharing Based on Shamir’s 
Scheme with Discrete Haar Wavelet Transform 
 
Chyuan-Huei Thomas Yang* 
Department of Information Management 
Hsuan Chuang University 
Hsinchu, Taiwan 
chyang@hcu.edu.tw 
Yuan-Hui Huang, Jhih-Hao Syue 
Department of Information Management 
Hsuan Chuang University 
Hsinchu, Taiwan 
md0984018@umail.hcu.edu.tw, md0994011@umail.hcu.edu.tw 
 
 
Abstract—We proposed a fast secret image sharing based on 
Haar wavelet transform and Shamir’s method. Many researchers 
develop secret image sharing method with Shamir’s algorithm in 
one whole image. We employ discrete Haar wavelet transform to 
reduce the secret image to its quarter size firstly, i.e. the 1-level 
LL subband. Then only apply the modified Shamir’s algorithm 
to this LL subband to generate the shadow images. Lagrange 
method exploits the enough numbers of the shadow images in the 
retrieval step. Due to the Shamir’s and Lagrange algorithms 
consume a lot of time during the processing of the secret image 
sharing. Our method only processes a quarter size of image that 
can decrease computation time, and still achieve to recover the 
secret image reversible. The experiment results demonstrate our 
method is fast and retrieve secret image lossless. 
Keywords- Haar wavelet transform;image sharing; lossless; 
Shamir’s scheme.  
I.  INTRODUCTION  
Digital media resources spread widely and fast during these 
few years. The technique to protect copyright and authorized 
material becomes more and more important. The object of 
secret image sharing is an essential method to protect digital 
images. Basically secret image sharing methods generate 
several shadow images from one secret image then share to 
participants [11]. After that the secret image can be retrieved 
with enough shared shadow images to recover the original 
secret image. Many authors have modified or extended the 
original Shamir’s method for the secret image sharing. Some 
authors proposed their methods create with Shamir’s method 
[1~3, 6, 10, 12, 14, 16], or without Shamir’s method [5, 13]. 
We also briefly discuss the wavelet transform that we have 
used [4, 7~9]. 
Firstly we are going to describe the secret image sharing 
method with Shamir’s method. Basically, it takes parts of 
information form a secret image to generate n shadow images 
then distribute to people whom assigned to be owned. The t 
owners may recover the original secret image, where t ≤ n. It is 
called (t, n) threshold scheme for secret image sharing. Thien 
and Lin [12] proposed a method (t, n) threshold scheme. Each 
shadow image is smaller than the secret image in their method. 
It gives the benefit to process the shadow images when stores, 
transmits, or processes image hiding. They also gave a 
reversible version to overcome the losses of 251~255 
grayscales when applied Shamir’s algorithm. Since their 
method is simple and lossless, our method will adopt their 
method after applying the Haar wavelet transform. A novel 
secret image sharing method based on Shamir’s (t, n) threshold 
scheme was proposed by Lin and Tsai [10], but they have three 
weaknesses, dishonest participant for image authentication, 
deteriorating quality of stego-image, and irreversible secret 
image scheme for secret image. After few years they proposed 
an improvement method to overcome these weaknesses. Wu et 
al. [15] proposed a new scheme which not only maintains all 
advantages in Lin-Tsai’s schemes, but also overcame this 
problem and design a lossless image sharing scheme both for 
secret images and for stego-images. Chang et al. [2] first 
transform the secret pixels into the m-ary notational system. 
The information data used to reconstruct original pixels from 
camouflaged pixels are computed. The information data and 
transformed secret data are shared using the (t, n) threshold 
sharing scheme. Thus they can retrieve the lossless secret 
image and reverse the original image from stego-image. 
Alexandrova et al. [1] they combined two-variable one way 
functions and Shamir's secret sharing. Each participant only 
needs to hold one secret share to share the secret image. They 
claimed the size of each image share is much smaller than the 
size of the image shares in other conventional methods. Chen 
et al. [3] extended the Shamir’s method and two layer 
structures to present a novel hybrid method for reducing the 
distortion of the reconstructed image and for grouping 
participants with different weights in a secret image sharing. 
Eslami and Ahmadabadi [6] proposed an embedding algorithm 
so that the block size is determined dynamically due to the size 
of hidden data and hence all the capacity of cover images is 
used for data hiding. They also proposed an authentication-
chaining method which reaches 15/16 as its tamper-detection 
ability while using only two authentication bits. Wu et al. [15] 
applied the quantization procedure to pre-process the secret 
image. The quantization procedure quantizes the secret image 
and embeds the generated S-E (smooth and edge) table. The 
secret sharing procedure generated shadow images that 
appeared noisy. The hiding shadow procedure hided each 
shadow image in an ordinary host image. Wang and Shyu [14] 
proposed a scalable secret image sharing scheme, for sharing 
an image among n participants such that the clarity of the 
reconstructed image scales with proportion with the number of 
the participants. They defined three modes, namely the multi-
secret, priority, and progressive modes, for sharing in their 
scheme. The scalability and flexibility of the proposed schemes 
*Corresponding author: Prof. Chyuan-Huei Thomas Yang 
E-mail: chyang@hcu.edu.tw  
 
The sharing steps are  
1. Convert the 2-D secret image into the 1-D array by 
raster scan, then use pseudo-random generator 
(PRNG) to shuffle the pixels of the 1-D array, and 
use a location map to record the positions of those 
grayscales are 251~255, and replace them by 250 ~ 
246. 
2. Sequentially take t not-shared-yet pixels of the 
permuted image (1-D array).  
3. Use the t pixels in Step 2 and Eqs. (2.3) then generate 
n pixels q(x1), q(x2), …, and q(xn) for the n shadow 
images. 
4. Repeat Steps 2 and 3 until all pixels of the permuted 
image are processed. 
 
The retrieval steps are 
1. Collect the shadow images and the identification 
numbers (xi) of t or larger than t participants. 
2. Convert each of those 2-D shadow images into 1-D 
arrays by raster scan, and calculate the original secret 
by the following Lagrange interpolation to get the 
original secret image q(q(x1), q(x2), …, and q(xn)),  
(2.4)     ) (mod)(
1,11
P
xx
xx
yxq
t
bj ijib
iji
t
b
ibi ∏∑
≠== −
−
=
 
where xi is the identification number and yib is the 
current pixel’s grayscale of the shadow image which xi 
owns. 
3. Collect q(xi) then use the location map to change those 
grayscales 250 ~ 246 back to 251~255, and use pseudo-
random generator (PRNG) to shuffle back to original 
order. 
4. Convert the 1-D array into the 2-D original secret 
image. 
 
C. Proposed method 
Our proposed method applies discrete Haar wavelet 
transform to secret image to get the LL subband firstly. It 
becomes to its quarter size of the original secret image. Then 
we employ the modified (t, n) threshold Shamir’s scheme 
which is discussed in the sharing part of above subsection B to 
the LL subband to generate the shadow images. We exploit 
Lagrange method with enough numbers of the shadow images 
to obtain the original secret image that was described in the 
retrieval part in above subsection B.  
Sharing Steps: 
Step1: Apply the discrete Haar image transform to get the 
LL subband with the carried or truncated location 
map.  
Step2: Convert the LL subband into 1-D array. 
Step3: Use PRNG to shuffle above 1-D array and use a 
location map to record the positions of those 
grayscales are 251~255, and replace them by 250 ~ 
246. 
Step4: Sequentially take t not-shared-yet pixels of the 
permuted image (1-D array) and apply Eqs. (2.3) 
then generate n pixels q(x1), q(x2), …, and q(xn) for 
the n shadow images. 
Step5: Repeat above Steps 4 until all pixels of the 
permuted image are exhausted. 
Step6: Convert the above 1-D array into 2-D shadow 
images 
Step7: Distribute the shadow images with the location 
maps to the participants. 
Retrieval steps: 
Step1: Collect the shadow images and the identification 
numbers (xi) of t or larger than t participants. 
Step2: Convert each of those 2-D shadow images into 1-D 
arrays by raster scan, and calculate the original 
secret by the following Lagrange interpolation to 
get the original secret image q(xi),  
(2.4)     ) (mod)(
1,11
P
xx
xx
yxq
t
bj ijib
iji
t
b
ibi ∏∑
≠== −
−
=
 
where xi is the identification number and yib is the 
current pixel’s grayscale of the shadow image which xi 
owns. 
Step3: Collect q(xi) then use the location map to change 
those grayscales 250 ~ 246 back to 251~255, and 
use pseudo-random generator (PRNG) to shuffle 
back to original order. 
Step4: Convert the 1-D array into the 2-D image. 
Step5: Use inverse discrete Haar wavelet transform and the 
carried or truncated location map to obtain the 
original secret image.  
III. EXPERIMENT RESULTS 
Due to our goal is to get a fast secret image sharing method 
and still achieve to recover the secret image reversible. We 
examine several frequently used images such as Lena, Baboon, 
Airplane and Peppers, shown in Figure 1 to do experiment. 
Theoretically we only process a quarter size of secret image 
that can decrease computation time, but the additional Haar 
transform which classical Shamir’s schemes do not apply will 
increase our method’s execution time. Figure 2 shows an 
example by using Lena to present the (2, 4) threshold 
condition. The computer facilities are Pentium(R) Dual-Core 
CPU E5300 @ 2.60GHz and with 2.60 GHz, 3.50 GB RAM. 
We implemented our experiment by MATLAB 6.5. The 
improvement is around average 2.1 times faster than the 
traditional Shamir’s scheme. Table 1 demonstrated the 
experiment results. The rate in the table means the time 
consumed of Shamir’s scheme over the time consumed our 
propose method. 
 1
 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                  日期：2012 年 08 月 30 日 
一、參加會議經過 
啟程：2012/08/23 早上 
返國：2012/08/29下午 
報告時間：2012/08/27 下午1:00-2:30 
報告方式：口頭報告 
二、與會心得 
1. 這個報告論文，以影像處理方法應用在影像資訊隱藏上。  
2. 口頭報告的敘述和詢問者的問題都是要很精準表達和了解。 
3. 和做相同領域的學者互相交流，體會其他人對這些相同或類似的問題的看法。 
4. 和台灣去的老師與同學交換不同問題的心得。  
5. 聆聽一些有興趣的議題，幫助了解更多相關的領域。  
6. 北九州是日本的小城市，順道去參觀大阪和神戶。 
三、發表論文全文或摘要：如附件  
四、建議：很具多樣性的會議，參與學者很具水準 
五、攜回資料名稱及內容： 
計畫編號 NSC100－2221－E－364－001－ 
計畫名稱 在不同亮度下基於色彩差異與 YIQ 中 Y 頻道梯度變化的彩色影像比對法 
出國人員
姓名 楊權輝 
服務機構
及職稱 
玄奘大學資訊管理學 
系助理教授 
會議時間 
2012 年 8 月 25 日 
至 
2012 年 8 月 28 日 
會議地點 北九州，日本 
Kitakyushu, Japan 
會議名稱 
第六屆國際基因與演化式演算法研討會 
The Sixth International Conference on Genetic and 
Evolutionary Computing 
發表題目 
以K-means與相似對將彩色調色盤分群的資訊隱藏法 
An Information Hiding Method Based on Grouping Color Palette Indices by 
K-means Clustering and Similar Pairs 
附件五 
An Information Hiding Method Based on Grouping Color Palette Indices  
by K-means Clustering and Similar Pairs 
Chyuan-Huei Thomas Yang 
Department of Information Management,  
Hsuan Chuang University,  
Hsinchu, Taiwan 
e-mail:chyang@hcu.edu.twline name@xyz.com 
Yu-Wei Hsu, Che-Lun Chung 
Department of Information Management,  
Hsuan Chuang University,  
Hsinchu, Taiwan  
e-mail:md0994001@umail.hcu.edu.tw, 
md1004017@umail.hcu.edu.tw
 
 
Abstract— We propose a data hiding method with color image 
palette. Many previous authors often embed data into the 
index table of the color palette or into the color palette directly. 
Those data hiding methods will change the color palette into a 
difference one. It is impossible to reconstruct the original color 
palette. We follow previous method to apply the K-means 
clustering to split the color image palette into several groups 
first. If a palette group has k numbers indices, the data can be 
embedded  log2k  bits into the pixel that its palette index falls 
in this group. The current embedding pixel will be replaced by 
the same group of pixel in the order of embedding data value 
which are corresponding each palette index. Next step, we 
collect those k 2  log2k  in each groups to use the Euclidean 
distance to cluster two groups with similar group that have 
similar index pairs. We embed one bit in each pixel that 
belongs these two groups. The extraction method firstly groups 
of the color palette index of stego-image by k-means clustering 
and similar pairs like embedding steps. If the palette index of 
the pixel belong to groups that produced by K-means 
clustering, then finds what order in its group. That order is the 
embedded value. If the palette index of the pixel belong to 
groups that yielded by similar pairs, then it belongs to first 
group is embedded 0, else is 1. The information can be 
extracted completely until all embedded pixels are retrieved or 
retrieved to the last bit of host image. From the experimental 
results, the method has the more embedding capacity then it 
only uses k-means clustering in the same image. 
Keywords- information hiding,color palette, watermarking, 
K-means clustering 
I.  INTRODUCTION 
During these few years data hiding and watermarking 
are two popular research areas.  They united image and 
signal processing with cryptography, visual perceptions, and 
data communication. Although they have alike processes, 
the main purposes of these two topics are very dissimilar. 
The watermarking techniques basically focus on robustness 
and data hiding or so called steganography concentrate on 
the capacity. They are all persistently preserved the 
imperceptible of the intermediate multimedia, or so called 
cover multimedia, or host multimedia. The intermediate 
multimedia includes image, audio, or video data. The hiding 
data can be any kind of data that may be converted into 
binary format. Some authors are not only interesting in 
extracting the secret data but also preserving the host after 
extraction. The host image can be recovered after extraction 
is called reversible data hiding or watermarking. In 
steganography or watermarking, the noise-like data can be 
embedded into multimedia to keep it from illegal used and 
modified, to authenticate its original content, or to avoid 
tampering with its value and to keep away from 
exaggerating its content. Basically the data hiding methods 
are reversible and irreversible. The reversible data hiding 
method deliberates the host image can be retrieved 
completely after extracting the secret data from it, or called 
lossless data hiding. Hidden data is called payload or secret 
data, hidden into host data, such as pixels in image. To 
verify the data hiding method is good or not, it depends on 
either reversible data hiding or irreversible data hiding is 
embedded capacity and quality degradation. Capacity and 
imperceptible are two factors conflict with each other. Of 
course, both reversible and irreversible data hiding method 
should extract secret data entirely, and should also achieve 
high capacity and low distortion. The secret data is possible 
in binary, gray scales, or color format. Usually data hiding 
techniques have been researched in two ways that embedded 
the secret data into the spatial domain or the frequency 
domain. 
In this paper we study the data hiding in color images. 
We survey the previous data hiding works in color images 
using the color image palettes [1, 2, 4, 7-9, 14, 15, 18-21]. 
Also we discuss the K-means clustering or the other 
clustering method [3, 5, 6, 10-13, 16, 17] that we are going 
to apply. There are two kinds of methods in data hiding in 
color images. One is the color palette indices of host image 
will be changed [2, 7-9, 14, 19] another will be not [1, 4, 15, 
18, 20, 21]. Dogan et al. [2] propose a watermarking method 
based on Singular Value Decomposition used in the 
frequency domain. Liu et al. [7] they used Arnold transform 
and color-blend operation in discrete cosine transform 
domains. RGB components of the color image are 
scrambled by Arnold transform then exchanged and mixed 
randomly under the control of a matrix defined by random 
angle. DCT is employed for changing the pixel values of 
color image. Niu et al. [8] invented a method based on the 
support vector regression (SVR) and nonsubsampled 
partition the observations with the Voronoi diagram that 
produced by the means. Assume  
t : the iteration step,  
Si(t) : the i set in t iteration steps, i=1, …,k.  
Pj : the observation, j=1, …, n. 
||‧|| : Euclidean distance 
 
t=1; 
while ( t ≦ stop criterion or the observations do not change 
in each set any more)  
  for j=1 to n 
  for i=1 to k 
   calculating ||xj-mi(t)|| 
  end 
end 
if ||xj-mi*(t)|| is the min(||xj-mi(t)||)  
where i* =1, …, or k 
assign the xj to i* cluster 
Calculating the new mean to update the new centroid 
of the observations in each cluster by  
for i=1 to k 
)(
)1( )(
t
i
Sx
j
t
i S
x
t
ijm

                                               (2.1) 
end 
t=t+1; 
end while 
 
B.  Similar pair method 
If we have n observations (palette indices) in a set 
called G, and want to divide into two sets which the most 
dissimilar element will be matched with. In this method, the 
similar pair concept is used to divide the palette indices into 
two groups. We use the Euclidean distance to find the 
closest pairs in these n (n ≥ 2) observations (palette indices). 
Each one of the indices in the palette will be matched with 
another color satisfying the distance (Eq. 2.2) of each other 
is the smallest. 
dሺݔ, ݕሻ ൌ ሺݔଵ െ ݕଵሻଶ ൅ ሺݔଶ െ ݕଶሻଶ ൅ ሺݔଷ െ ݕଷሻଶ           (2.2) 
where x, y are indices of the color palette. After the finding 
the closest pairs of process, let an element of each pair into 
group G1, and another to group G2, respectively. The 
observations (palette indices) are grouped into two groups 
G1 and G2. For each index cxi in G1 is corresponding to an 
index cyi in G2 such that cyi is the most similar to cxi, where 
G1  G2  G and cxi G1 and cyi G2 and 1  i  n/2. 
Since it is possible that is not even elements in G so that one 
element is not grouped. The palette is as shown in Figure 1. 
 
 
G  G1 G2 
C1  Cx1 Cy1 
C2  Cx2 Cy2 
    
    
cn  cxn/2 cyn/2 
Figure 1: the similar pairs of n observations (palette indices) 
 
C. Grouping Palette Indices by K-means Clustering and 
Similar pair methods 
 
Preprocessing Procedure 
1. To get the palette index from a color image I. Assume 
the size of the palette Pn3, i.e. we have n vectors with 3 
dimensions, which are R, G, and B. 
2. We calculate frequencies of the palette index of this 
color image as the descending order. If we want to 
divide into k sets, we firstly assign the first k indices of 
the descending order as an initial set of k means. 
3. Apply K-means to find the k centroids and the palette 
index vectors in each cluster. 
4. We have k clusters with the descending order of palette 
index vectors which are a part of whole palette index. 
5. the indices mk-2lg mk to a set Dg. Then use similar pairs 
to set up two similar sets Dg1 and Dg2 as the subsection 
2.2.  
Next we are going to use above k clusters with the 
descending order of palette index vectors PVk to embed the 
secret data in this color image. The embedding algorithm is 
described as follows. 
 
Embedding Algorithm 
S: the secret data 
I: host image(color) 
Pn3 : color palette vectors of I 
PVk : the descending order of palette index vectors in k 
cluster that grouping by K-means  
 
Step 1: Convert the secret data S into a bit-stream, then by 
pseudo-random number generator (PRNG), noted 
S’. 
Step 2: While (not end of S’) 
We use raster scan from top left to bottom right.  
Form the first pixel in host image I,  
   If the palette index of current pixel i belongs to 
k cluster and the sub-palette PVk in k 
cluster has m vectors,  
then 
     Pick the current lg m bit in S’, convert it 
into  
decimal number d.  
Replace the current palette index of pixel by 
the  
order d of the sub-palette in k cluster. 
          end While 
Table 1: PSNRs with k = 8 clusters in k-means, and k-means 
with similar pairs for the four famous images.  
 lena baboon peppers airplane
k-means 32.7723 31.9254 32.2526 33.0325
k-means 
with 
similar 
pairs 
31.0483 30.0823 31.8845 32.5927
 
Table 2: the capacities with k = 8 clusters in k-means, and k-
means with similar pairs for the four famous images. 
 lena baboon peppers airplane 
k-means 182,344   192,345 171,195 188,227 
k-means 
with 
similar 
pairs 
190,542 201,263 186,731 197,226 
IV. CONCLUSIONS 
We propose a data hiding method in color image with its 
image palette. We apply the K-means clustering to divide 
the color image palette into several groups first. Then use 
the similar pairs to embed more secret data. Our method 
uses the order of the sub-palette indices to embedding secret 
in K-means clustering and similar pairs. The extraction is 
easily obtain from the order of the cluster that current index 
belongs to which group. We recorded the first k of the 
highest frequencies of the color palette indices for private 
keys to avoid the order changed after embedding. The 
results show we have good embedding capacity and the 
image quality. The future works are to find how many 
clusters should be divided and to search the best initial 
centroids in order to get the best PSNR.  
ACKNOWLEDGMENT 
This paper is supported by NSC 99-2221-E-364-001- 
REFERENCES 
[1] Chin-Chen Chang, Thai Son Nguyen and Chia-Chen Lin, “A 
Reversible Data Hiding Scheme for VQ Indices Using Locally 
Adaptive Coding,” Journal of Visual Communication and Image 
Representation, Volume 22, Issue 7, pp.664-672, Oct. 2011. 
[2] Sengul Dogan, Turker Tuncer, Engin Avci and Arif Gulten, “A robust 
color image watermarking with Singular Value Decomposition 
method,” Advances in Engineering Software, Volume 42, Issue 6, pp. 
336-346, June 2011. 
[3] Jan Feyereisl and Uwe Aickelin, “Privileged information for data 
clustering,” Information Sciences, In Press, 
 Corrected  Proof, Available online 22, April. 2011.  
[4] Liu Hongmei, Zhang Zhefeng, Huang Jiwu, Huang Xialing and Shi, 
Y.Q., “A High Capacity Distortion-free Data Hiding Algorithm for 
Paiette Image,” Circuits and Systems, 2003. ISCAS '03, pp.II-916 - 
II-919, June 2003. 
[5] Ing-Sheen Hsieh and Kuo-Chin Fan, “An adaptive clustering 
algorithm for color quantization,” Pattern Recognition 
Letters, Volume 21, Issue 4, pp.337-346, April 2000. 
[6] Linlin Liu, Lifang Zhou and Shenggang Xie, “A Novel Supervised 
Multi-model Modeling Method Based on k-means 
Clustering,”  Control and Decision Conference (CCDC), 2010 
Chinese, pp. 684-689, May 2010. 
[7] Zhengjun Liu, Lie Xu, Ting Liu, Hang Chen, Pengfei Li, Chuang Lin 
and Shutian Liu, “Color image encryption by using Arnold transform 
and color-blend operation in discrete cosine transform domains,” 
Optics Communications, Volume 284, Issue 1, 1 ,pp.123-128, Janu. 
2011. 
[8] Pan-Pan Niu, Xiang-Yang Wang, Yi-Ping Yang and Ming-Yu Lu, “A 
novel color image watermarking scheme in nonsampled contourlet-
domain,” Expert Systems with Applications, Volume 38, Issue 
3,pp.2081-2098, March 2011. 
[9] Hideki Noda, and Michiharu Niimi, “Local MAP estimation for 
quality improvement of compressed color images,” Pattern 
Recognition, Volume 44, Issue 4, pp.788-793, 2011 April. 
[10] Jinjian Qing, Xuefang Liang, Rongfang Bie, and Xiaozhi Gao “A 
New Clustering Algorithm Based on Artificial Immune Network and 
K-means Method,” Natural Computation (ICNC), 2010 Sixth 
International , pp. 2826-2830, Aug. 2010. 
[11] Xiaoping Qin and Shijue Zheng, “A new method for initialising the 
K-means clustering algorithm,” Knowledge Acquisition and 
Modeling, 2009. KAM '09. Second International Symposium 
on ,pp.41-44, Dec. 2009. 
[12] Rasouli, A.  Bin Maarof, M.A. and Shamsi, M. , “A New Clustering 
Method Based on Weighted Kernel K-Means for Non-linear Data,” 
International Conference of Soft Computing and Pattern Recognition, 
2009. SOCPAR '09., pp.19-24, Dec. 2009 . 
[13] Yan Song, Anan Liu, Lin Pang, Shouxun Lin, Yongdong Zhang and 
Sheng Tang, “A Novel Image Text Extraction Method Based on K-
means Clustering,” Seventh IEEE/ACIS International Conference on  
Computer and Information Science, 2008. ICIS 08, pp.185-190, May 
2008 . 
[14] Yen-Shing Tsai and Piyu Tsai, “Adaptive data hiding for vector 
quantization images based on overlapping codeword clustering,” 
Information Sciences, Volume 181, Issue 15, 1, pp. 3188–3198, Aug. 
2011. 
[15] Chih-Hsuan Tzeng, Zhi-Fang Yang, Wen-Hsiang Tsai, “Adaptive 
Data Hiding in Palette Images by ColorOrdering and Mapping With 
Security Protection,” Communications, IEEE Transactions,pp.791-
800, May 2004 . 
[16] Junli Wang and Zhenyu Liu, “An Analysis of Regional Product by 
Three Strata of Industry Based on K-means Method,” 2011 
International Conference on  Business Management and Electronic 
Information (BMEI) ,pp.361-364. May 2011. 
[17] Liang Wang, Christopher Leckie, Ramamohanarao Kotagiri and 
James Bezdek, “Approximate pairwise clustering for large data sets 
via sampling plus extension,” Pattern Recognition, Volume 44, Issue 
2, pp.222-235, Feb. 2011. 
[18] Hsien-Chu Wu, Hui-Chuan Lin and Chin-Chen Chang, “Reversible 
Palette Image Steganography Based on De-clustering and Predictive 
Coding,” The 9th International Conference on Computer Science and 
Informatics (JCCSI), pp.705-708. Oct. 2006. 
[19] Mei-Yi Wu, Yu-Kun Ho and Jia-Hong Lee, “An iterative method of 
palette-based image steganography,” Pattern Recognition 
Letters, Volume 25, Issue 3, pp.301-309, Feb 2004. 
[20] Chyuan-Huei Thomas Yang and Wen-Feng Wu,  “Data Hiding 
Method in Color Image Based on Grouping Palette Index by Particle 
Swarm Optimization with K-means Clustering,” The 2011 World 
Congress in Computer Science Computer Engineering and Applied 
Computing, July. 2011. 
[21] Chung-Min Yu, Kuo-Chen Wu and Chung-Ming Wang, “A 
distortion-free data hiding scheme for high dynamic range images,” 
Displays, Volume 32, Issue 5, pp.225-236, Dec. 2011 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：楊權輝 計畫編號：100-2221-E-364-001- 
計畫名稱：在不同亮度下基於色彩差異與 YIQ 中 Y 頻道梯度變化的彩色影像比對法 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 已發表在 2012 玄
奘大學主辦之全
國資訊管理前瞻
技術研討會 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 5 100% 
五位碩士班學生
參與計畫 其中 2
位已完成碩士學
位 
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
在電腦視覺與影像處理中影像辨識是一直都是重要的問題。而影像辨識又以影像比對為最
複雜的步驟。本計畫為研究在不同的亮度情況下的彩色影像的辨識，以色彩變化與轉換成
YIQ 中梯度變化為依據的高辨識率影像比對方法。本計畫利用色彩轉換成灰階後，根據對
應的二個臉部圖像的臉部位置累積其一致性的正規化梯度變化；利用一個人的同一表情、
同一位置的三個不同方向的照明情況作為其測度比較參考的依據。其中一種參考的方式為
局部比較臉部輪廓和重要部分的位置上每個點將參考三個不同的梯度變化中取其最大的
正規化的絕對值量，再累積其度量；另一種方式為全域比較臉部輪廓和重要部分的位置上
將分別參考三個不同亮度情況計算其正規化的梯度變化累積量取其最大。也將會利用一個
明暗度加權的函數來修正陰影和明暗度飽和所產生的影響。我們先比較上述單獨考慮局部
或全域的參考方式，也同時會混和局部和全域的累積度量來尋找最佳方法。我們將用 CMU 
PIE 與 AR 資料庫來測試此演算法。 
在學術成就、技術創新中，本計畫提供在亮度不同環境下，一個創新的對彩色影像臉部比
對演算法， 與利用梯度變化的強固而辨識率極高的比對度量。可以參考多個已知資訊，
也就是越多的參考臉部樣板空間，越能增加辨識率。 
在經過 911 事件後，門禁或是過濾篩選人員進出的安全性的偵測是越來越重要。人臉辨識
是一個困難度極高的問題，一直都在發展研究。目前監視系統都採用以彩色影像方式建
檔。一套對彩色影像完整而辨識率極高的人臉辨識系統是很需要的，而更需要找到強固而
高辨識率的臉部比對演算法來支持這個人臉辨識系統。我們可以發展這個辨識演算法用在
