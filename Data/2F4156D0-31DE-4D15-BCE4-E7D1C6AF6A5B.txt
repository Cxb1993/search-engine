codes 即將發表在 IEEE Trans. on Computers 部分成果，
(2) Mode Decision using Inter-view Dependencies and 
Depth Information for Multiview Video Coding，以及(3) 
Automatic Fast Forwarding for Surveillance Video 
using Saliency Detection。 
 
中文關鍵詞： H.264/AVC、LT-編碼、Rate-distortion 傳輸、Multiview 
video coding, Mode decision. 
英 文 摘 要 ： In this project, we focus on source coding (video 
sequences), channel coding (LT codes), Rate-
distortion optimization, video-event-detection 
applications, and some sort of integration. Several 
research results were published in the prestigious 
journals and conferences, such as IEEE Trans. on 
Computers, IEEE Trans. on Parallel and Distributed 
Systems, and ICPR. Besides, one paten was granted in 
this year.  
Previous researches have shown that UEP rateless 
codes can provide a low-complexity solution for 
downloading scalable information. However, the 
randomized generator of rateless codes leads to 
uncertainty of decoding probability and decoding 
priority of input data, and thus it is not suitable 
for streaming applications. a novel UEP method is 
presented for streaming media. The proposed method, 
which consists of a hierarchical coding graph as well 
as low-complexity encoding and decoding operations, 
preserves the advantage of the UEP rateless codes and 
characterizes the decoding probability and decoding 
priority by formulae. The proposed hierarchical 
coding graph guarantees high-priority input data are 
recovered before low-priority ones, so important 
information can be recovered with low-latency, low-
computation, and high-probability.  
Multiview Video Coding (MVC) performs both disparity 
and motion estimation to exploit inter-view 
correlations along with the rate distortion 
optimization to achieve superior coding efficiency； 
however the encoder load dramatically increases as 
well. To reduce the stunning computational 
complexity, many research works focus on fast motion 
1 
 
行政院國家科學委員會補助專題研究計畫  成 果 報 告   □期中進度報告 
 
視訊編碼與傳輸進階技術：延展性、最佳化與事件分析（3/3） 
 
 
計畫類別： 個別型計畫  □ 整合型計畫 
計畫編號：NSC  99－2221－E－007－077－MY3 
執行期間： 99 年 8 月 1 日至 100  年 10 月 31 日 
 
計畫主持人：王家祥 
共同主持人： 
計畫參與人員： 徐廷倢、徐君潔、薛光利、黃昌傑、黃兆武 
 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，▓一年□二年後可公開查詢 
          
執行單位：國立清華大學資訊工程學系 
 
中   華   民   國  100 年   12 月    20 日
II 
 
英文摘要 
In this project, we focus on source coding (video sequences), channel coding (LT codes), 
Rate-distortion optimization, video-event-detection applications, and some sort of integration. 
Several research results were published in the prestigious journals and conferences, such as IEEE 
Trans. on Computers, IEEE Trans. on Parallel and Distributed Systems, and ICPR. Besides, one 
paten was granted in this year.  
Previous researches have shown that UEP rateless codes can provide a low-complexity 
solution for downloading scalable information. However, the randomized generator of rateless 
codes leads to uncertainty of decoding probability and decoding priority of input data, and thus it 
is not suitable for streaming applications. a novel UEP method is presented for streaming media. 
The proposed method, which consists of a hierarchical coding graph as well as low-complexity 
encoding and decoding operations, preserves the advantage of the UEP rateless codes and 
characterizes the decoding probability and decoding priority by formulae. The proposed 
hierarchical coding graph guarantees high-priority input data are recovered before low-priority 
ones, so important information can be recovered with low-latency, low-computation, and 
high-probability.  
Multiview Video Coding (MVC) performs both disparity and motion estimation to exploit 
inter-view correlations along with the rate distortion optimization to achieve superior coding 
efficiency; however the encoder load dramatically increases as well. To reduce the stunning 
computational complexity, many research works focus on fast motion estimation, fast disparity 
estimation and/or fast mode decision, but are not fully utilized the information supplied by 
inter-view referencing frames. In this report, a fast mode decision algorithm using both inter-view 
dependencies and depth information is proposed. In the era of information explosion, especially 
the data rich but information poor epoch, how can we effectively secure useful information with 
limited time becomes a fundamental issue. Considering we are browsing a tedious video content, 
many skip and/or fast forward operations have to be done to filter out the worthlessness. Usually, 
the chosen video playback speed is adapted to the sort of video clip and user preference as well. 
Our goal is to play surveillance videos in an efficient, convenient and smooth way.  
Because of the page limitation, three condensed results are given in this report. They are: (1) 
Unequal Error Protection for Streaming Media Based on Rateless Code, (2) Mode Decision using 
Inter-view Dependencies and Depth Information for Multiview Video Coding, and (3) Automatic 
Fast Forwarding for Surveillance Video using Saliency Detection。 
Key words: H.264/AVC, LT-codes, Rate-distortion optimization, Multiview video coding, Mode 
decision. 
2 
 
第二部分，我們利用運動向量補償的結果去決定是否需要計算視差向量補償。第三部分，
我們分別減少運動向量補償和視差向量補償的搜尋範圍。最後，如果此多視角影片含有深
度資訊，我們會利用此深度資訊去進一步的縮小視差向量補償的搜尋範圍和過濾掉不適合
的 Macroblocks。 
三. Automatic Fast Forwarding for Surveillance Video using Saliency Detection 
在這個網路發達的年代，各式各樣的資訊充斥在我們的日常生活中，如何在有限的時間內
獲取最大的資訊成為一個我們所關注的課題。在平日我們觀看冗長的影片時，針對不同的
影片類型，我們常常會使用跳段或是加快播放速度的方式快速瀏覽過整個影片內容，並且
在快轉影片時，依照使用者的時間考量或是影片的內容來改變快轉的速度。我們將主題放
在如何能有效率地播放監視系統影片，在影片壓縮的過程中擷取必要的資訊，產生一組影
片播放速度的建議參數，標示出影片需要慢速播放或是快速前進的地方，因此影片在播放
時就可參照這組參數來達到自動改變快轉速率的目的。 
為了要決定不同時間點的快轉速率，我們利用特徵圖資訊(Saliency)模擬人類視覺注目
度，標示出不同時間點時影片的對視覺產生的資訊量而產生出一條注意力曲線，接著將注
目度對應到快轉速率的改變值。最後我們提出一個新方法來量測影片快轉後重要的資訊是
否有被保留。經由實驗我們可以得知，自動快轉的方式可以在符合使用者需求並且不遺漏
影片重要資訊的要求下大量節省觀看時間。 
研究方法 
一. Unequal Error Protection for Streaming Media Based on Rateless Codes 
1.1. The Design and Analysis of the Proposed LT-based UEP Code 
We found that the decoding probability and decoding priority correlate closely with the degrees 
of encoding blocks [1]. To stress the important input blocks, the edge distribution used in the 
proposed UEP codes does not follow the Soliton distribution. We remove encoding blocks with 
degree more than three to avoid unpredictable decoding delay in the decoding process. For 
remaining blocks, the ratio of degree-one encoding blocks is increased to improve the decoding 
probability and assure the decoding priority of important input blocks. Let the number of the most 
important input nodes be a = 2q for q  some positive integer, and let n = 3a – 8a/3b – 2/3, where 
b = 2m for some positive integer m  k+1. Define 








3for 0
3for 3)24(
2for )42(
1for /
)(
i
ibnba
ibnaab
ina
i  (1) 
(i) is the proportion of degree-i encoding blocks. Then input blocks are hierarchical protected by 
degree-one, degree-two, and degree-three encoding blocks. The hierarchical structure guarantees 
that input blocks at different layers can have different probability and priority to be recovered. 
Moreover, the coding graph is constructed as a connected graph so that the recovery of every 
input block can help to recover other input blocks. Instead of randomly generating encoding 
4 
 
Equation (4) implies the range of m is 2  m  q+1, which indicates the range of b is 4  b  2q+1 
= 2a. Therefore, the range of inversed coding rate (inversed coding rate = 1 + overhead) R = 
N(i)/ K(i) is  
12
23
15
27



a
aR
a
a  (6) 
In the proposed finite-length UEP codes, the inversed coding rate is confined by (6), and the 
coding overhead can be easily deduced also from (6). 
Encoding blocks consists of degree-one, degree-two, and degree-three blocks. The number 
of degree-one encoding blocks equals the number of the most important blocks. Besides, the 
number of degree-two and degree-three encoding blocks is decided by parameter m. e(i) in (7) 
describes the number of degree-i encoding blocks by q and m. q is determined by the number of 
the most important input blocks. m is used to decide the ratio between degree-two encoding 
blocks and degree-three encoding blocks. As long as k and m are decided, the coding graph can 
be randomly generated. 



















3
3
222
2222
12
)(
21
2
21
0
i
i
i
ie
mqmq
j
jmq
mqq
m
j
jq
q
 (7)
 
An input block in the coding graph can be recovered from different decoding sets. According 
to the ways to recover an input block, we define three types of input blocks. Note that an input 
block may be categorized as more than one types since there are multiple decoding sets to recover 
it. 
Type Ai input blocks: An input block at layer i recovered through one of two encoding blocks 
at layer i. 
Type Bi input blocks: An input block at layer i recovered through one encoding block at layer 
i+1 or one of two encoding blocks at layer i. 
Type Ci input blocks: An input block at layer i recovered through an encoding block at layer 
i+1 or an encoding block at layer i. 
The proposed hierarchical coding graph has a significant feature: an input block can be 
recovered from either “bottom-up” or “top-down” direction. Here “bottom-up” means an input 
block is recovered from its lower layers, and “top-down” means an input block is recovered from 
its upper layers. Based on this feature, we define two types of encoding blocks. The first one is i 
encoding blocks at layer i, which are used to recover Ai, Bi, or Ci input blocks (i.e., bottom-up 
recovery). The second one is i encoding blocks at layer i, used to recover Ai-1, Bi-1, or Ci-1 input 
blocks (i.e., top-down recovery). Figure 1.1 shows examples of all types of blocks. 
6 
 
unstable network conditions in streaming circumstances. 
 
1.2. Hierarchical Rateless Codes 
Given k and m, the number of input blocks and encoding blocks can be determined from (4) and 
(5). Because the structure of the proposed coding graph is fixed, the size of the coding graph 
might not exactly match user requirements. In this condition, we can use pre-codes, such as 
LDPC applied in Raptor codes. In the above case, two error correction blocks can be generated 
and treated as the input blocks as well. Another advantage of pre-codes is the adjustment of the 
amount of coding overhead. Let a coding graph can accommodate K(i) input blocks at layer i, and 
the source data have K’(i) input blocks at layer i. The inversed coding rate of pre-codes plus 
proposed UEP codes is 

 




 
2/)1(
1
2/)1(
1
2/)1(
1 )(
)('
)( mq
i
mq
i
mq
i iN
iK
iN  (9) 
The right term of (9) is the extreme case, which happens when there is only one input block. 
Taking (6) into account, the range of R becomes 
nR
a
a 

15
27
 (10)
 
In (10), n is the number of encoding blocks in the coding graph. Instead the proposed algorithm 
in TABLE 1-1, we can extend the size of coding graph to unlimited large, so there is no upper 
bound for R. Therefore, using pre-codes and a larger coding graph can achieve nearly arbitrary 
coding rates. However, for on-the-fly coding, the size of coding graph cannot be determined first. 
In this situation, a better way to realize the arbitrary coding rate is to carry out the proposed 
algorithm in TABLE 1-1 multiple times. The details are described as follows: 
1. Generating a hierarchical coding graph. 
2. Randomly determining a degree number i according to (4). 
3. Sending a degree-i encoding block that has not been sent before to the client. 
4. If all input blocks have been sent to the client, going to step 1. Otherwise, going to step 2. 
Because input blocks are randomly selected to be encoded, every generated coding graph 
8 
 
probability of other blocks with different priorities. This also decreases the performance of 
UEPLT codes. Moreover, in the proposed codes, the gap of decoding probability between 
high-priority data and low probability data is obvious at low receiving rate, and it converges at 
high receiving rate. This means bad transmitting circumstances benefit high-priority data more, 
and good transmitting circumstances benefit low-priority data more. This feature totally meets 
user requirements because people tend to see important information (or basic quality) under bad 
network circumstances and see less important information (or advanced quality) only when there 
is enough bandwidth. However, the curves of UEPLT codes display the opposite trend. 
 
Figure 1.3. Decoding probability at different packet receiving rate. 
The rateless version of the proposed UEP codes is applied in the next simulation and 
compared with pre-coding UEPLT codes proposed in [3]. In the simulation, 767 input blocks with 
256 high-priority input blocks are encoded. Following the assumption in [3], high-priority input 
blocks are first pre-encoded at coding rate = 1/2. Then input blocks as well as pre-coding blocks 
are used to generate proposed UEP codes and pre-coding UEPLT codes. In the proposed UEP 
codes, we put high-priority data and pre-coding data in the first layer of the hierarchical coding 
graph. In Figure 1-4, the black curves represent the proposed UEP rateless codes. It can be seen 
that all high-priority data can be recovered when 767 encoding packets are generated (received 
ratio = 1). After that, the pre-coding blocks can be also recovered through high-priority input 
blocks. Therefore, the decoding probability of low-priority input blocks rapidly increases after the 
complete recovery of high-priority and pre-coding data due to the feature that lower layers can 
help with recovery of high layers in the hierarchical coding graph. Consequently, it can be 
guaranteed that all high-priority data are recovered and low-priority data have good decoding 
probability after the received ratio equaling one. In the left part of the received ratio equaling one, 
pre-codes cause performance degradation, but they only affect the decoding probability of 
low-priority data. This is because the hierarchical coding graph provides sufficient protection for 
high-priority data. Considering pre-coding UEPLT codes, pre-codes are useless until enough 
pre-coding and high-priority packets are received, so the performance of high-priority data is the 
same as low-priority data at low overhead. This causes that the overall performance is even worse 
than standard LT codes.  Besides, there are two constraints in pre-coding UEPLT codes. First, 
the size of low-priority data is assumed to be much smaller than high-priority data. Second, the 
decoding probability is significantly influenced by the input size due to the instinct of LT codes. 
For example, if 1000 input blocks with 300 high-priority input blocks are used in the simulation, 
10 
 
 
2.1. The Method 
The overall flow chart of our proposed method is depicted in the following figure. The first phase 
is GDV-based candidate modes selection which is motivated by observations. Then, in order to 
further accelerate the mode decision procedure, we proposed a threshold-based early termination 
strategy to end up the mode decision process in advance. Apart from accelerating the mode 
decision procedure, we also want to improve the computations of ME and DE. Thus, we proposed 
a criterion to judge if performing DE is necessary in the third phase and shrink the search ranges 
of both ME and DE in the fourth phase. Furthermore, in the fifth phase, if the depth maps are 
available, we improve our method by using the depth info. The details of each phase please refer 
to [4]. 
 
 
 
 
 
2.2. Experimental Results and Discussions 
In our experiments, the proposed method is carried out on a Pentium(R) Dual-Core CPU E6500 
2.93GHz processor and 4.0 GB memory equipped PC, developed on JMVM 7.0 reference 
software. The proposed is tested on four 640x480 format sequences and two 1024x768 format 
sequences. In our experiments, we encode 100 frames for each sequence and the proposed 
method only applies on non-anchor frames. 
See Table 2.2, the proposed method can speed up ranging from 76% to 86% of the total 
encoding time with -0.56% to 1.47% bitrate increasing and -0.02dB to -0.13dB PSNR dropping. 
In a sequence with different QP value or with different kind of sequences, the compression 
12 
 
40 -0.02 -0.45% -76.48% 
AVG. -0.03 -0.18% -78.62% 
AVG. 
24 -0.04 0.56% -78.94%  
28 -0.05 0.65% -80.13% 
32 -0.04 0.23% -79.36% 
36 -0.03 -0.01% -78.95% 
40 -0.04 -0.03% -78.82% 
Table 2-3 demonstrates the experimental results with phases 1-4 and phases 1-5. Since video 
sequences, breakdancers and ballet, having depth information, we list the results of these two 
sequences only. Note that the time saving of phases 1-5 is better than phases 1-4 ranging from 3% 
to 4% with various QP values. 
Table 2-3. The comparison between phases 1-4 and phases 1-5. 
Sequence QP 
Phases 1~4 Phases 1~5 
D-PSNR(dB) 
D-Bitrate 
(%) 
D-Time (%) D-PSNR(dB)
D-Bitrate 
(%) 
D-Time (%)
breakdancers 24 -0.05 0.26% -77.89% -0.06 0.93% -81.15% 
breakdancers 28 -0.05 0.41% -78.49% -0.07 0.83% -81.49% 
breakdancers 32 -0.05 0.15% -77.88% -0.07 0.33% -81.28% 
breakdancers 36 -0.05 0.34% -77.29% -0.07 -0.01% -81.14% 
breakdancers 40 -0.04 0.31% -75.63% -0.05 0.26% -78.45% 
AVG. -0.05 0.29% -77.44% -0.06 0.47% -80.70% 
ballet 24 -0.03 0.45% -80.25% -0.04 0.96% -83.36% 
ballet 28 -0.03 0.06% -79.70% -0.05 0.22% -82.49% 
ballet 32 -0.03 -0.42% -78.90% -0.05 -0.45% -81.73% 
ballet 36 -0.03 -0.56% -77.79% -0.04 -0.75% -80.46% 
ballet 40 -0.02 -0.45% -76.48% -0.02 -0.54% -79.02% 
AVG. -0.03 -0.18% -78.62% -0.04 -0.11% -81.41% 
The figure below demonstrates the percentages of time saving for each phase. The best time 
saving phase is obviously the candidate mode selection ranging 62% to 70%. And the saving of 
the search range prediction is noticeable, ranging 4% to 8%. Moreover, if with depth information, 
the time saving of the search range prediction can have 3% to 4% improvement. 
 
 
 
 
 
14 
 
used the result to build the summery. Höferlin et al. [7] identified visual complexity as the 
temporal information density. Temporal information is formulated as symmetric information gain 
between an estimated noise distribution and the video data using the concept of information 
theory. The results showed that entropy is correlated with the magnitude of changes, but 
independent of noise. 
Peker and Divakaran [8] dedicated on finding out how fast a video can be played with 
human perceptual limits. The highest speed to play a video with acceptable comprehension is a 
complicated function. To model this function, a lot of parameters need to be concerned, including 
the scene complexity, semantic elements in the scene, familiarity of those elements, and the 
processing capacity of the visual system, and so on. Instead of actually modeling this complex 
function, a visual complexity measure based on early vision models was proposed. Our result 
indicated that the perceived quality of fast-forwarded video is determined by the temporal 
bandwidth, which obtained by a function of the spatial texture complexity and the motion activity 
of each DCT block in the original video. 
Recent developments in image and video coding have heightened the need for perceptual 
video coding [9-10]. Modeling human visual attention can improve coding efficiency, 
compression rate and perceptual quality while encoding the video content. Many attempts on 
development of computational models of attention have been proposed. 
Recent developments in image and video coding have heightened the need for perceptual 
video coding [9-10]. Modeling human visual attention can improve coding efficiency, 
compression rate and perceptual quality while encoding the video content. Many attempts on 
development of computational models of attention have been proposed. 
3.1. The Algorithm 
To achieve our goal, the importance of each frame is conducted and the video playback speed is 
dynamically adjusted thereby. The system framework is shown in Figure 3-1. 
 
Figure 3-1 The framework. 
Almost all the video content today is recorded on a digital video recorder and is encoded to 
save the storage space. During the encoding process, we can take advantage of the coding process 
16 
 
0 20 40 60 80 100 120
0
1000
2000
3000
4000
5000
6000
7000
 
Figure 3-3 Attention curve (IndoorGTTest2). 
When finding the key frames, two things have to be noticed. First, the distance between two 
frames should not be too close, because people are not willing to change the playback speed too 
frequently. Then, a lower bound of the attention value is set to filter out local minima. 
The summarized extraction steps are stated below: 
(a) The attention curve is smoothed by the median filter. 
(b) Conducting the derivative of the attention curve and find zero crossing points, which 
means the position of crests on the attention curve. 
(c) Excluding the exceptions of points whose position are too close or values are too low. 
The remaining points are the position of key frames. 
3.2. Experimental Results and Discussions 
To show the efficiency and effectiveness of our algorithm, both subjective and objective quality 
assessment are conducted. Three aspects are considered for the evaluation. 
(a) Effectiveness for event detection 
(b) Efficiency of time 
(c) Comprehensibility for user 
To meet the effectiveness requirement, we use the ground truth of surveillance video for 
evaluation. However, it is not appropriate for evaluating efficiency for fast forwarded video. As a 
result, we proposed a new mechanism called saliency hit rate to measure the efficiency of time. 
The comprehensibility for use should be examined by subjective evaluation. 
Three video sequences are selected as our test sequences, which representing three different 
conditions of surveillance video. In the first sequence (IndoorGTTest2) several people walking 
through the room. The second sequence is the highway sequence, in which a car is driving on a 
highway and some traffic signs are passing while driving. The third sequence is obtained from 
PET2001 dataset [12]. The video content is about outdoor people and vehicle tracking. In these 
sequences, the condition of the indoor, outdoor, and vehicle recorded video type are concerned. 
We compared our adaptive fast forward result with the effect of normal fix-rated fast 
forward method with the same average frame rate. The rate of the compared sequence is obtained 
18 
 
IndoorGTTest2 
 
F 6.00x 99.10% 
A 6.23x 99.47% 
Highway F 4.00x 98.36% 
A 4.41x 98.45% 
Pets2001 F 7.00x 97.98% 
A 6.93x 98.39% 
We also conducted a user study to compare our proposed adaptive fast forward approach 
with the fix-rate fast forward method as well. The volunteers are composed of 20 male and 
female students in computer science department. Each user is asked to watch two fast forwarded 
video clips of each sequence and answered some questions. 
The results of our user study are arranged in Table 3-4. The results of this study indicate that 
the video qualities of both videos are perceptible for users but our proposed automatic fast 
forwarded video content is more informative. It is interesting to note that in the highway case, 
although the adaptively forwarded video is more informative than the fixed one, users considered 
the quality is depressed and some users prefer to watch it in fix-rate mode. Generally speaking, 
we believe that adaptive fast forward can help user browsing the surveillance videos and more 
users prefer to adaptively fast forward the surveillance video. 
Table 3-4 User study. 
Sequence Quality 
(F) 
Quality 
(A) 
Informative 
rate (F) 
Informative 
rate (A) 
Preference 
for A 
IndoorGTTest2 3.20 3.60 2.65 3.60 95% 
Highway 3.80 3.55 2.50 3.75 70% 
PetsD1 3.55 3.60 3.20 3.95 80% 
3.3. Experimental Results and Discussions 
We proposed an automatic fast forward mechanism which is applicable for surveillance videos 
and other unedited video types like vehicle recorded videos. Our proposed algorithm is practical 
for implementation. The motion information is extracted from the video encoding process to 
build the attention model, and a set of fast forward parameters are assigned for the video content 
according to the attention curve. With the parameters, the playback speed is able to be adjusted 
automatically when users browsing the video content.  
In most of the video players, fast forward is accomplished by skipping frames. Considering 
the coding structure of video content, the video playback rates are categorized into five layers and 
represented by a fast forward parameter. Each GOP is assigned a fixed parameter representing the 
20 
 
參考文獻 
[1] Yang, Kai-Chao and Wang, Jia-Shung, “Unequal Error Protection for Streaming Media Based on Rateless 
Codes,” accepted and to appear in IEEE Trans. on Computers, April, 2011. 
[2] T. Schierl, K. Gänger, C. Hellge, and T. Wiegand, “SVC-based multisource streaming for robust video 
transmission in mobile ad hoc networks,” IEEE Wireless Communication, 2006, pp. 96-103. 
[3] U.C. Kozat and S.A. Ramprashad, “Unequal error protection rateless codes for scalable information delivery in 
mobile networks,” in Proc. of IEEE International Conference on Computer Communications (INFOCOM 2007), 
2007, pp. 2316-2320. 
[4] Chun-Chieh Hsu, “Mode Decision using Inter-view Dependencies and Depth Information for Multiview Video 
Coding,” Master Thesis, National Tsing Hua University, 2011. 
[5] X. Li, D. Zhao, X. Ji, Q. Wang, and W. Gao, "A fast inter frame prediction algorithm for multi-view video 
coding," IEEE International Conference on Image Processing (ICIP), vol.3, pp.III-417-III-420, 16-19 
September 2007. 
[6] L. Shi, M. R. Lyu, and I. King, "Video summarization by spatial-temporal graph optimization," Proceedings of 
International Symposium on Circuits and Systems, pp. 197-200, 2004. 
[7] B. Höferlin, M. Höferlin, D. Weiskopf, and G. Heidemann, "Information-based adaptive fast-forward for visual 
surveillance," Multimedia Tools and Applications, 2010. 
[8] K. A. Peker and A. Divakaran, "Adaptive fast playback-based video skimming using a compressed-domain 
visual complexity measure," IEEE International Conference on Multimedia and Expo, pp. 2055-2058, 2004. 
[9] Z. Chen, W. Lin, and K. N. Ngan, "Perceptual video coding: Challenges and approaches," IEEE International 
Conference on Multimedia and Expo (ICME), pp. 784-789, 2010. 
[10] C. Guo and L. Zhang, "A novel multiresolution spatiotemporal saliency detection model and its applications in 
image and video compression," IEEE Transactions on Image Processing, vol. 19, pp. 185-198, 2010. 
[11] Kuang-Li Hsueh, “Automatic Fast Forwarding for Surveillance Video using Saliency Detection,” Master Thesis, 
National Tsing Hua University, 2011. 
[12] PETS2001 Datasets. http://www.cvg.cs.rdg.ac.uk/PETS2001/pets2001-dataset.html. 
[13] M. Luby, “LT codes,” in Proc. of the 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002, 
pp. 271-282. 
[14] I.S. Reed and G. Solomon, “Polynomial codes over certain finite fields,” SIAM  Journal on Applied 
Mathematics, 1960, pp. 300-304. 
[15] A. Shokrollahi, “Raptor codes,” in Proc. of International Symposium on Information Theory (ISIT 2004), 2004, 
pp. 37. 
[16] 3GPP TS 26.346 V6.1.0, Technical Specification Group Services and System Aspects; Multimedia 
Broadcast/Multicast Service; Protocols and Codecs, June 2005. 
22 
 
[34] W. Zhu, X. Tian, F. Zhou, and Y. Chen, "Fast inter mode decision based on textural segmentation and 
correlations for multiview video coding," IEEE Transactions on Consumer Electronics, vol.56, no.3, 
pp.1696-1704, August 2010. 
[35] D.-H. Han and Y.-L. Lee, "Fast mode decision using global disparity vector for multiview video coding," 
International Conference on Future Generation Communication and Networking Symposia (FGCNS), vol.3, 
pp.209-213, 13-15 December 2008. 
[36] W. Zhu, W. Jiang, and Y. Chen, "A fast inter mode decision for multiview video coding," International 
Conference on Information Engineering and Computer Science (ICIECS), pp.1-4, 19-20 December 2009. 
[37] M. Ai and J. Wang, "A fast mode decision algorithm for multiview video coding," International Congress 
on Image and Signal Processing (CISP), vol.7, pp.3252-3257, 16-18 October 2010. 
[38] Y.-H. Lin and J.-L. Wu, “A depth information based fast mode decision algorithm for color plus depth-map 3D 
videos,” IEEE Transactions on Broadcasting, vol.57, no.2, pp.542-550, June 2011. 
 
366 J.-W. Huang et al. 
We also propose a cache-and-share mechanism to improve the availability of the videos. 
Once a client obtains a video, this video will be stored and shared to others by means of 
a peer-to-peer file sharing technique, e.g., structured P2P (Pastry[2], Chord[3], CAN[4], 
CoopNet[5]), unstructured P2P (Gnutella[6], Napster[7], KaZaA[8]), or P2P streaming 
(CoolStreaming[9], PPLive[12], UUSee[13], SopCast[14]). These works are good for 
file sharing or video streaming; however, directly implementing them to support virtual 
channel service is not appropriate. The reasons will be stated later. 
To support each user a dedicated virtual channel, we summarize the general 
viewing behaviors of users to four modes as follows: 
A. Live mode 
In this mode, users always watch the live program (for instance, live basketball 
game). In Fig. 1, we let the four users all watch a live video program A. When a user is 
coming, she/he always watches the latest frame of the live program. 
B. Review mode 
The review mode is based on the live mode. When a user is watching a live 
program, she/he could want to review some scenes, for example, splendid scenes or the 
scenes she/he just missed. Consider the example in Fig. 2. Let the live program A have 
a splendid scene at time 3. Therefore, some users, such as the user 1 and user 2 in this 
example, are probably to watch the scene A3 again. 
C. Serial-play mode 
In this mode, a user always watches an entire TV program from the head to the tail 
sequentially. Consider the example in Fig. 3. When a user requests the program A, 
she/he always stays in this channel until the entire program has end. 
D. Interest-based mode 
In this mode, a user can randomly access the TV programs according to her/his 
interest. Consider the example in Fig. 4. As the figure illustrates, the request sequences 
are irregular and are difficult to model. 
Based on the above, we can summarize these general modes to two types: 1) 
sequential access; 2) random access. Undoubtedly, a perfect TV broadcasting platform 
should consider two goals as below:  
User 1 A1 A2 A3 A4 A5 A6 A7 ……. An
A2 A3 A4 A5 A6 A7 ……. An
A3 A4 A5 A6 A7 ……. An
A4 A5 A6 A7 ……. An
User 2
User 3
User 4
Time          1      2      3      4      5      6      7       …….        n 
 
Fig. 1. The behavior of live viewing 
368 J.-W. Huang et al. 
that the proposed platform partitions each video program into many small segments, 
such as [10][11][15][16] do. Then, a virtual channel can be constructed by retrieving 
these video segments and composing them into a long video playout sequence.  
The rest of this paper is organized as follows. Section 2 introduces the concept of 
the proposed virtual channel platform and formulates its problem on query overhead. 
Section 3 then presents a virtual stream mechanism for reducing the query overhead. 
Section 4 presents some simulation results to evaluate the performance of the platform. 
Finally, the conclusion and future works are given in Section 5. 
2   A Framework of Virtual Channel 
2.1   Overview of the Proposed Platform 
The primary components of the proposed platform can be summarized as follows: 
A. The video source provider 
With the rapid advances on network communication technologies, a client which 
can access the Internet and has some videos to share can also operate as a video source 
provider. Unfortunately, the storage and the reliability would be limited. To eliminate 
these restrictions in our platform, a backup service, which contains a large storage and 
has high reliability, to store the videos supported from the video source providers is 
essential. The details of the backup service will be introduced later. 
B. The client 
In the proposed virtual channel platform, each client could generate a request 
sequence including a series of video segments according to her/his demanded. To 
satisfy the demands of each client at anytime, we must increase the availability of each 
video program. Therefore, we not only introduce a backup service to store these videos 
but also adopt a cache-and-share mechanism to each client. 
C. The backup service/the lookup service  
In this paper, we introduce a backup service and a lookup service to increase the 
availabilities of the videos which are summarized as follows: 
The backup service 
In this paper, we adopt a backup service to store the video programs from the video 
source providers. The main functionalities of the backup service are 1) partitioning 
each video program into many small video segments; 2) storing these video segments 
in the buffers; 3) sharing these video segments to the clients. However, the storage of 
the backup service could still be exhausted. Therefore, we also adopt a LRU algorithm 
to replace the video segments which are not accessed for a long time. 
The lookup service 
In the current peer-to-peer file/video sharing platforms, each file/video is usually 
identified by a unique hash key. Thus, we introduce a lookup service to keep the 
mapping of the hash keys to the corresponding video segments. 
370 J.-W. Huang et al. 
B. Locating the sender peers 
When a client gets the hash key of a video segment, it still has to retrieve the video 
segment from one or more sender peers. The process to locate the sender peers can be 
implemented in either a centralized model or a peer-to-peer model. 
(1) Centralized model 
In the centralized model, the strategy is for each segment to publish the information 
of its contributed sender peers. However, this model would result in a performance 
bottleneck on the server of a large scale service. 
(2) Peer-to-peer model 
In a structured P2P system, a video source provider usually publishes the essential 
information to specific peers where requesters can easily discovered by means of a 
DHT (Distributed Hash Table) mechanism. However, maintaining such a DHT over a 
large scale P2P network will require considerable management overhead, and any 
update on peer status and system information will also cause an update on the content 
of the DHT. In the proposed virtual channel platform, a client can dynamically join or 
leave the system, and the cached video segments in its buffer could also update 
frequently. Thus, the structured P2P is not appropriate for our platform. Based on the 
above, we develop the delivery architecture of the proposed virtual channel platform 
based on the concept of unstructured P2P, just as CoolStreaming [9] does. 
C. Retrieving the video segments  
After locating the possible sender peers, the client then must retrieve the desired 
video segments from these sender peers. Fig. 6 shows an illustrative example of the 
delivery architecture in the proposed virtual channel platform. (It is important to 
remember that a sender peer could be the local buffer, another client, or the backup 
server.) As Fig. 6 illustrates, the client c1 has gathered the hash keys {A, B, C, D} of its 
desired video segments. c1 also understands that it can get the segments corresponding 
to {A, C, D} from S1 and the segments corresponding to {B, D} from S2. 
2.3   The Details of the Proposed Delivery Architecture 
In this subsection, we will discuss the details of a client to retrieve the desired video 
segments as follows: 
(1) hash key conversion 
After receiving the request sequence from a client, the directory server transforms 
the request sequence into a series of hash keys for P2P sharing. 
(2) query and delivery 
After receiving the responded hash keys, the user attempts to obtain the 
corresponding video segments according to these hash keys. First, the client checks if 
the video segments are already cached in its local buffer. If the segments are not 
cached in the local buffer, the client floods a query message to find at most w sender 
peers among all other peers and wait for responses. Let the number of available sender 
peers be x. Then, the delivery process would be either of the following cases: 
372 J.-W. Huang et al. 
We use this match measure MM to check if the request subsequence v’ is matched in 
the request sequence qi. If v’ is found in qi, then we have MM(qi, v’) = 1. Otherwise, we 
have MM(qi, v’) = 0. The match ratio of the request subsequence v’ is then defined as 
follows: 
n
vqMM
vMR
n
i
i∑
=
=
1
)',(
)'(                               (2) 
The above match ratio MR function for v’ is equivalent to the probability that a request 
sequence contains v’. Then, if the match ratio of v’ is larger than or equal to a threshold 
δ, i.e., δvMR ≥ )'( , the request subsequence v’ is referred to as a popular 
subsequence and is treated as a beneficial virtual stream in this paper. 
3.3   A Naïve Approach 
A. Virtual stream generation  
A naïve approach is to list all possible subsequences, check their match ratio MR, 
and select the highest ones as the beneficial virtual streams. However, this naïve 
approach requires too much memory space and computation overhead. 
For example, we assume that the system have 10,000 video segments, whose 
lengths are all five minutes long. Let the system have 10,000 clients, and let each client 
request 60 video segments (i.e., 5 hours). Therefore, the number of possible request 
subsequences in worse case will be 10,00060 = 10240, because a video segment could be 
requested many times by a client. To find the most popular subsequences, we must 
derive all the possible subsequences in advance, and then check the match ratio MR of 
each one. Since a beneficial virtual stream will be at least two segments long, the 
amount of possible subsequences will be  
,10000
60
2
∑
=i
i
 
which is an incredible large number. Based on the above, we can make two essential 
assumptions for virtual stream generation: 1) the number of subsequences to be 
checked must also be restricted, and 2) the length of each subsequence must be 
restricted.  
B. Virtual stream scheduling 
To reduce the query overhead, the directory server should reschedule the request 
sequences and try to replace with the beneficial virtual streams. The scheduling 
approach can be further divided into two steps: 1) sequentially scan all request 
sequences to check if any beneficial virtual stream is matched; 2) replace the matched 
subsequences with the corresponding beneficial virtual streams. However, this naïve 
scheduling approach has some problems: 1) too large memory space and computation 
overhead. 2) the match probability is low. 
374 J.-W. Huang et al. 
possible subsequences will be {A, B}, {A, B, C}, {B, C}, and {A, C}. Finally, the 
directory server evaluated the estimated performance gains E(G) based on the equation 
(4) and selects the subsequences with the largest F gains as the beneficial virtual 
streams, and then it will associate each of them an unique hash key. 
B. Virtual stream scheduling 
In this subsection, we will introduce the proposed approach for virtual stream 
scheduling with a rearranging strategy. Note that while rearranging a request sequence, 
each demanded video segment Ri can not be scheduled to a time slot before its 
generating time t(Ri), i.e., can not cause a “time violation”. However, this procedure 
could take a lot of computation overhead. To reduce the computation complexity, we 
let the directory server sort the interest-based request sequences to a nondecreasing 
order on the segment generating time t(Ri).  
4   Simulation Results 
In this section, we propose two platforms based on the Gnutella P2P overlay network 
to compare their system performance over various physical network topologies, as 
illustrated in Table 1.  
We let each client have 10 neighbors, and let the TTL of each query message be 5 
hops for limiting the query range of a request. Besides, we assume that all video 
programs are originally from several TV broadcasting channels. Let the lengths of all 
videos be one hour, and let each video be divided into 12 five-minute video segments 
(M = 12). The execution time of each simulation is 24 hours. In each scheduling 
interval which is one hour long, the directory server will generate at most 10 beneficial 
virtual streams, and each virtual stream could have at most five segments. We use the 
term “normalized load” to evaluate the system performance of both platforms: 
platform baseline in thecost  system
platform enhanced in thecost  systemload normalized =  
Serial
Live
Idle
Review Random
 
Fig. 7. The finite state machine to model the user viewing behavior 
376 J.-W. Huang et al. 
0.5
0.6
0.7
0.8
0.9
1
0 20000 40000 60000 80000 100000
num of user
n
o
rm
a
liz
e
d 
lo
a
d
num = 5
num = 10
num = 15
num = 20
num = 25
 
(a) 
0.5
0.6
0.7
0.8
0.9
1
0 20000 40000 60000 80000 100000
num of user
n
o
rm
a
liz
ed
 
lo
a
d
num = 5
num = 10
num = 15
num = 20
num = 25
 
(b) 
Fig. 9. The impact of the number of generated beneficial virtual streams F: (a) for random-
major, (b) for serial-major 
Requesting a video segment 
After the viewing state and the demanded channel have been determined, we have to 
combine the finite state machine with the channel table to model the user viewing 
behaviors. 
4.2   Performance Evaluation 
A. Impact of the request patterns  
Now we evaluate the system performance of the baseline platform and the 
enhanced platform under different request patterns: 1) live-major: with high ratio of 
378 J.-W. Huang et al. 
5. Padmanabhan, V.N., Wang, H.J., Chou, P.A., Sripanidkulchai, K.: Distributing streaming 
media content using cooperative networking. In: Proc. ACM NOSSDAV (May 2002) 
6. Gnutella, http://www.gnutella.com/  
7. Napster, http://www.napster.com  
8. KaZaA, http://www.kazaa.com  
9. Zhang, X., Liu, J.C., Li, B., Peter Yum, T.-S.: CoolStreaming/DONet: A data-driven 
overlay network for efficient live media streaming. In: Proc. IEEE INFOCOM (March 
2005) 
10. Viswanathan, S., Imielinski, T.: Metropolitan area video-on-demand service using 
pyramid broadcasting. Multimedia Systems 3, 197–208 (1996) 
11. Hua, K.A., Sheu, S.: Skyscraper broadcasting: a new broadcasting scheme for 
metropolitan video-on-demand systems. In: Proc. ACM SIGCOMM 1997 (1997) 
12. PPLive, http://www.pplive.com/ 
13. UUSee, http://www.uusee.com/ 
14. SopCast, http://www.sopcast.com/ 
15. Chi, H., Zhang, Q., Jia, J., (Sherman) Shen, X.: Efficient Search and Scheduling in P2P-
based Media-on-Demand Streaming Service. IEEE Journal on Selected Areas in 
Communications 25(1) (January 2007) 
16. Cheng, X., Liu, J.: NetTube: Exploring Social Networks for Peer-to-Peer Short Video 
Sharing. In: Proc. IEEE INFOCOM 2009, Rio de Janeiro, Brazil (April 19-25, 2009) 
97 年度專題研究計畫研究成果彙整表 
計畫主持人：王家祥 計畫編號：97-2221-E-007-077-MY3 
計畫名稱：視訊編碼與傳輸進階技術：延展性、最佳化與事件分析 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 1 1 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
