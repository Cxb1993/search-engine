連續時間區間值線性規劃問題
1 Abstract
The concept of continuous-time linear programming problem with interval-valued objective and
constraint functions is studied in this project. We introduce the concepts of scalar product of
closed intervals and integral of interval-valued function to interpret the meaning of interval-valued
objective and constraint functions of primal and dual problems. We create the weak and strong
duality theorems for this kind of continuous-time linear programming problem. The computational
procedure is also provided to obtain the approximate nondominated solutions.
Keywords: Closed intervals; Scalar product; Weak duality theorem; Strong duality theorem;
Optimality condition.
2 Introduction and Purpose
The methodology for solving optimization problems has widely applied to many research fields. If
the coefficients of optimization problems are taken as real numbers, they are categorized as the de-
terministic optimization problems. However, the coefficients can be taken as uncertain quantities. If
the coefficients of optimization problem are assumed as random variables with known distributions,
they are categorized as the stochastic optimization problems. The books written by Birge & Lou-
veaux [4], Kall [6], Pre´kopa [12], Stancu-Minasian [16] and Vajda [20] give the main stream of this
topic, and also give many useful techniques for solving the stochastic optimization problems. On the
other hand, if the coefficients are taken as closed intervals, they will be categorized as interval-valued
optimization problems.
As we have known in the stochastic optimization problems, the coefficients are assumed as random
variables with known distributions in most of cases. However, the specifications of the distributions
are very subjective. For example, many researchers invoke the Gaussian (normal) distributions
with different parameters in the stochastic optimization problems. These specifications may not
perfectly match the real problems. Therefore, interval-valued optimization problems may provide
an alternative choice for considering the uncertainty into the optimization problems. That is to
say, the coefficients in the interval-valued optimization problems are assumed as closed intervals.
Although the specifications of closed intervals may still be judged as subjective viewpoint, we might
argue that the bounds of uncertain data (i.e., determining the closed intervals to bound the possible
observed data) are easier to be handled than specifying the Gaussian distributions in stochastic
optimization problems.
The inexact linear programming problem was proposed by Soyster [13, 14, 15] and Thuente [17],
where the closed intervals are also used to describe the uncertainty. Falk [5] also provided some
properties on this problem. However, Pomerol [11] pointed out some drawbacks of Soyster’s results
and also provided some mild conditions to improve Soyster’s results.
The concept of continuous-time linear programming problem was first introduced by Bellman
[3, Chapters VI and VII] for considering the bottleneck problem, and then it was also rigorously
investigated by Tyndall [18, 19]. The continuous-time linear programming problem is the extension
1
and
(D2) min
∫ T
0
〈y(t), c(t)〉 dt
subject to y(t) ·B(t) ≥ a(t) +
∫ T
t
y(s) · C(t, s)ds for 0 ≤ t ≤ T
y : [0, T ]→ Rm is a nonnegative and bounded measurable function,
where
B(t) ≥ 0 is an n×m matrix and continuous on [0, T ]
c(t) is an n-vector and continuous on [0, T ]
a(t) is an m-vector and continuous on [0, T ]
C(t, s) is an n×m matrix and continuous on [0, T ]× [0, T ]
The continuous optimal control problem is a kind of continuous-time programming problem that
is formulated as follows:
min
∫ T
0
f(x(t),u(t))dt
subject to x˙(t) = φ(x(t),u(t)) for 0 ≤ t ≤ T
x(t) ∈ X for 0 ≤ t ≤ T
u(t) ∈ U for 0 ≤ t ≤ T
ψ(y,u) ∈ D,
where x is a state vector with initial state vector x(0) = x0 and u is a control vector governed by
the differential equation x˙(t) = φ(x(t),u(t)) for 0 ≤ t ≤ T .
Now, in order to complete the inspiration, we also adopt the example from Bellman [3]. We
consider the auto and steel industries. The quantities needed in the formulation are
r1(t)=auto stockpile at time t, x1(t)=rate of production of autos
r2(t)=auto capacity at time t, x2(t)=rate of increase of auto capacity
r3(t)=steel stockplie at time t, x3(t)=rate of production of steel
r4(t)=steel capacity at time t, x4(t)=rate of increase of steel capacity
The measures of stockpile and capacity are chosen so that one unit of capacity, either auto or steel,
is required for the production of one unit of stockpile in unit time. We assume that b1 units of steel
are required to make one unit of autos, b2 units of steel are required to increase auto capacity by
one unit, and b4 units of steel are required to increase steel capacity by one unit. However, we shall
assume that no steel is required to produce additional steel. Then the model is governed by the
following system of differential equations
dr1/dt = x1(t), r1(0) = c1
dr2/dt = x2(t), r2(0) = c2
dr3/dt = x3(t)− b1x1(t)− b2x2(t)− b4x4(t), r3(0) = c3
dr4/dt = x4(t), r4(0) = c4
where the xi and ri are subject to the following constraints
x1(t) ≤ r2(t)
x3(t) ≤ r4(t)
r3(t) ≥ 0
xi(t) ≥ 0 for i = 1, 2, 3, 4.
3
Therefore, we see that A	B = A⊕ (−B) = [aL − bU , aU − bL]. We also see that
kA = {ka : a ∈ A} =
{
[kaL, kaU ] if k ≥ 0
[kaU , kaL] if k < 0,
where k is a real number. Let A = [aL, aU ]. We also adopt the notation AL = aL and AU = aU .
Then we have
(A⊕B)L = AL +BL = aL + bL and (A⊕B)U = AU +BU = aU + bU (3)
and
(A⊗B)L = min{aLbL, aLbU , aUbL, aUbU} and (A⊗B)U = max{aLbL, aLbU , aUbL, aUbU}. (4)
For more details on the topic of interval analysis, we refer to Moore [9, 10] and Alefeld and Herzberger
[1]. In the sequel, we are going to present the scalar (inner) product of closed intervals.
Let A = [aL, aU ] be a closed interval. If aL ≥ 0 then A is called a nonnegative closed interval.
If aU ≤ 0 then A is called a nonpositive closed interval. If aL > 0 then A is called a positive closed
interval. If aU < 0 then A is called a negative closed interval. If aL ≤ 0 and aU ≥ 0 then we let
A+ = [0, aU ] and A− = [aL, 0]. We call A+ the positive part of A and A− the negative part of A.
It is obvious that A+ is a nonnegative closed interval and A− is a nonpositive closed interval and
A = A+ ⊕A−. If A is nonnegative then A− = [0, 0], and if A is nonpositive then A+ = [0, 0].
Let A ∈ In ≡ I × · · · × I, i.e., A = (A1, · · · , An), where Ai = [aLi , aUi ] ∈ I, i = 1, · · · , n, are
closed intervals in R. We also denote A+ = (A+1 , · · · , A+n ) and A− = (A−1 , · · · , A−n ). The (vector)
addition of A = (A1, · · · , An) and B = (B1, · · · , Bn) is defined by
A⊕B = (A1 ⊕B1, · · · , An ⊕Bn).
Then we see that
A = A+ ⊕A−.
We also use the notations AL = (aL1 , · · · , aLn) ∈ Rn and AU = (aU1 , · · · , aUn ) ∈ Rn.
Definition 3.1 The scalar product of A and B in In is defined by
〈〈A,B〉〉 = (A1 ⊗B1)⊕ · · · ⊕ (An ⊗Bn).
It is easy to see that the scalar product 〈〈A,B〉〉 is also a closed interval. Therefore, using Eq.
(3), we have
〈〈A,B〉〉L = (A1 ⊗B1)L + · · ·+ (An ⊗Bn)L
and
〈〈A,B〉〉U = (A1 ⊗B1)U + · · ·+ (An ⊗Bn)U .
Also, using Eq. (4), we can obtain the more detailed formulas for 〈〈A,B〉〉L and 〈〈A,B〉〉U . We omit
the detailed description here.
We say that A is nonnegative (resp. nonpositive) if each Ai is nonnegative (resp. nonpositive)
for i = 1, · · · , n. The following result is not hard to prove.
Proposition 3.1 Let A and B be in In. If A is nonnegative or nonpositive, then
〈〈A,B〉〉 = 〈〈A,B+〉〉 ⊕ 〈〈A,B−〉〉.
Let a ∈ R. Then a can be regarded as a closed interval Ia = [a, a]. For a = (a1, · · · , an) ∈
Rn, the vector a can also be regarded as an element Ia in In by setting Ia = (Ia1 , · · · , Ian) =
([a1, a1], · · · , [an, an]). Let us write 〈·, ·〉 to denote the usual inner (scalar) product in Rn. Using
Proposition 3.1, we also have the following useful results that will be used for the further discussions.
5
For B ∈ Im, the product B⊗A ∈ In can be similarly defined.
Let A and B be two closed intervals. We write
A  B if and only if AL ≥ BL and AU ≥ BU . (5)
We also write A  B if and only if B  A.
Now we are in a position to formulate the continuous-time linear programming problem with
interval-valued objective and constraint functions. Let A(t) and C(t) be two interval-valued vector
functions from [0, T ] into In and Im, respectively, such that each component of them is end-point-
bounded and end-point-measurable, and let B and C be two m × n interval-valued matrices. We
recall that
Ix(t) = (Ix1(t), · · · , Ixn(t)) = ([x1(t), x1(t)] , · · · , [xn(t), xn(t)]) .
Let X be the set of all nonnegative and bounded measurable functions x : [0, T ]→ Rn satisfying
B ⊗ Ix(t)  C(t)⊕
∫ t
0
C ⊗ Ix(s)ds for 0 ≤ t ≤ T, (6)
and let Y be the set of all nonnegative and bounded measurable functions y : [0, T ]→ Rm satisfying
Iy(t) ⊗ B  A(t)⊕
∫ T
t
Iy(s) ⊗ Cds for 0 ≤ t ≤ T, (7)
where ∫ t
0
C ⊗ Ix(s)ds and
∫ T
t
Iy(s) ⊗ Cds
are integrals of interval-valued function as discussed in the previous section by considering each
component of C ⊗ Ix(s) and Iy(s) ⊗ C.
Given A(t), C(t), B and C, the interval-valued primal problem is given by
(IVP1) max
∫ T
0
〈〈Ix(t),A(t)〉〉dt
subject to B ⊗ Ix(t)  C(t)⊕
∫ t
0
C ⊗ Ix(s)ds for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
and the interval-valued dual problem is given by
(IVD1) min
∫ T
0
〈〈Iy(t),C(t)〉〉dt
subject to Iy(t) ⊗ B  A(t)⊕
∫ T
t
Iy(s) ⊗ Cds for 0 ≤ t ≤ T
y : [0, T ]→ Rm is a nonnegative and bounded measurable function
We see that the interval-valued coefficient matrices B and C in problems (IVP1) and (IVD1) are
assumed to be time-independent. We can also extend to consider the time-dependent interval-valued
coefficient matrices B(t) and C(t, s) for 0 ≤ t, s ≤ T . Therefore, the primal and dual pair problems
are given below:
(IVP2) max
∫ T
0
〈〈Ix(t),A(t)〉〉dt
subject to B(t)⊗ Ix(t)  C(t)⊕
∫ t
0
C(t, s)⊗ Ix(s)ds for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
7
4 Results and Discussions
We shall separately discuss the results for the time-independent interval-valued coefficient matrices
and time-dependent interval-valued coefficient matrices.
4.1 Time-Independent Interval-Valued Coefficient Matrices
Let B, C, A(t) and C(t) for 0 ≤ t ≤ T be given in problem (IVP1). Recall that A  B if and only if
AL ≤ BL and AU ≤ BU . Therefore, for the objective and constraint functions in problem (IVP1),
we can consider its lower-level and upper-level continuous-time linear programming problems that
are given below
(IVP1L) max
(∫ T
0
〈〈Ix(t),A(t)〉〉dt
)L
subject to
(B ⊗ Ix(t))L ≤ (C(t)⊕ ∫ t
0
C ⊗ Ix(s)ds
)L
for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
and
(IVP1U ) max
(∫ T
0
〈〈Ix(t),A(t)〉〉dt
)U
subject to
(B ⊗ Ix(t))U ≤ (C(t)⊕ ∫ t
0
C ⊗ Ix(s)ds
)U
for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
Now, from Proposition 3.2, the objective functions in problems (IVP1L) and (IVP1U ) are, respec-
tively, given by(∫ T
0
〈〈Ix(t),A(t)〉〉dt
)L
=
∫ T
0
〈〈Ix(t),A(t)〉〉Ldt =
∫ T
0
〈
x(t),AL(t)
〉
dt (9)
and (∫ T
0
〈〈Ix(t),A(t)〉〉dt
)U
=
∫ T
0
〈〈Ix(t),A(t)〉〉Udt =
∫ T
0
〈
x(t),AU (t)
〉
dt. (10)
From Proposition 3.2, we have
(A⊗ Ix)L =
(〈〈A1·, Ix〉〉L, · · · , 〈〈Am·, Ix〉〉L)
=
(〈
AL1·,x
〉
, · · · , 〈ALm·,x〉) = AL · x.
Similarly, we also have (A⊗ Ix)U = AU · x. Therefore, we obtain that
(B ⊗ Ix(t))L ≤ (C(t)⊕ ∫ t
0
C ⊗ Ix(s)ds
)L
is equivalent to
BL · x(t) ≤ CL(t) +
∫ t
0
CL · x(s)ds (11)
9
and
(CLP1U ) max wL ·
∫ T
0
〈
x(t),AL(t)
〉
dt+ wU ·
∫ T
0
〈
x(t),AU (t)
〉
dt
subject to BU · x(t) ≤ CU (t) +
∫ t
0
CU · x(s)ds for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
We also have the following interesting result.
Proposition 4.2 For any fixed wL, wU > 0, suppose that x∗(t) ∈ X = XL ∩ XU is an optimal
solution of problem (CLP1L) or (CLP1U ). Then x∗(t) is a nondominated solution of problem (IVP1).
For any fixed wL, wU > 0, if we consider the following problem
(CLP1) max wL ·
∫ T
0
〈
x(t),AL(t)
〉
dt+ wU ·
∫ T
0
〈
x(t),AU (t)
〉
dt
subject to BL · x(t) ≤ CL(t) +
∫ t
0
CL · x(s)ds for 0 ≤ t ≤ T
BU · x(t) ≤ CU (t) +
∫ t
0
CU · x(s)ds for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
then we can similarly obtain the following result.
Proposition 4.3 If x∗(t) is an optimal solution of problem (CLP1), then x∗(t) is a nondominated
solution of problem (IVP1).
We can similarly define the problems (CLD1L), (CLD1U ) and (CLD1). Therefore, we also have
the following results.
Theorem 4.1 (Weak Duality Theorem) For the primal-dual pair problems (IVP1) and (IVD1), if
x(t) ∈ X and y(t) ∈ Y, then ∫ T
0
〈〈Ix(t),A(t)〉〉dt 
∫ T
0
〈〈Iy(t),C(t)〉〉dt.
Theorem 4.2 (Optimality Condition) For the primal-dual pair problems (IVP1) and (IVD1), if
there exist functions x∗(t) ∈ X and y∗(t) ∈ Y such that∫ T
0
〈〈Ix∗(t),A(t)〉〉dt =
∫ T
0
〈〈Iy∗(t),C(t)〉〉dt (15)
then x∗(t) is an optimal solution of primal problem and y∗(t) is an optimal solution of dual problem.
Theorem 4.3 (Optimality Condition) For the primal-dual pair problems (IVP1) and (IVD1), if
there exist a unique x∗(t) ∈ X and a unique y∗(t) ∈ Y such that∫ T
0
〈
x∗(t),AL(t)
〉
dt =
∫ T
0
〈
y∗(t),CL(t)
〉
dt
or ∫ T
0
〈
x∗(t),AU (t)
〉
dt =
∫ T
0
〈
y∗(t),CU (t)
〉
dt,
then x∗(t) is a strongly nondominated solution of primal problem and y∗(t) is a strongly nondomi-
nated solution of dual problem.
11
4.2 Time-Dependent Interval-Valued Coefficient Matrices
Let B(t), C(t, s), A(t) and C(t) for 0 ≤ t ≤ T be given in problem (IVP2). We can consider its
lower-level and upper-level continuous-time linear programming problems that are given below
(IVP2L) max
(∫ T
0
〈〈Ix(t),A(t)〉〉dt
)L
subject to
(B(t)⊗ Ix(t))L ≤ (C(t)⊕ ∫ t
0
C(t, s)⊗ Ix(s)ds
)L
for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
and
(IVP2U ) max
(∫ T
0
〈〈Ix(t),A(t)〉〉dt
)U
subject to
(B(t)⊗ Ix(t))U ≤ (C(t)⊕ ∫ t
0
C(t, s)⊗ Ix(s)ds
)U
for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
We denote by X̂L the set of all nonnegative and bounded measurable functions x(t) satisfying the
following inequality
BL(t) · x(t) ≤ CL(t) +
∫ t
0
CL(t, s) · x(s)ds,
and denote by X̂U as the set of all nonnegative and bounded measurable functions x(t) satisfying
the following inequality
BU (t) · x(t) ≤ CU (t) +
∫ t
0
CU (t, s) · x(s)ds.
Then problems (IVP2L) and (IVP2U ) can be rewritten as
(IVP2L) max
{∫ T
0
〈
x(t),AL(t)
〉
dt : x(t) ∈ X̂L
}
and
(IVP2U ) max
{∫ T
0
〈
x(t),AU (t)
〉
dt : x(t) ∈ X̂U
}
Similarly, we denote by ŶL the set of all nonnegative and bounded measurable functions y(t) satis-
fying the following inequality
y(t) · BL(t) ≥ AL(t) +
∫ T
t
y(s) · CL(t, s)ds,
and denote by ŶU the set of all nonnegative and bounded measurable functions y(t) satisfying the
following inequality
y(t) · BU (t) ≥ AU (t) +
∫ T
t
y(s) · CU (t, s)ds.
Then, according to problem (IVD2), we have the lower-level and upper-level continuous-time linear
programming problems that are given by
(IVD2L) min
{∫ T
0
〈
y(t),CL(t)
〉
dt : y(t) ∈ ŶL
}
13
where the integrals in the constraints are also approximated by∫ tk
0
CL · x(s)ds ≈
k∑
s=1
CL · x(ts) for k = 1, · · · ,K.
Therefore, we see that xi(tk) are the decision variables for i = 1, · · · , n and k = 1, · · · ,K, where
x(tk) = (x1(tk), · · · , xn(tk)). Now, we rename xi(tk) as xik. Then x(tk) = xk = (x1k, · · · , xnk) and
problem (IVP1L(K)) can be rewritten as follows:
(LP-IVP1L(K)) max
K∑
k=1
〈
xk,A
L(tk)
〉
subject to BL · xk ≤ CL(tk) +
k∑
s=1
CL · xs for k = 1, · · · ,K
xk ≥ 0 for k = 1, · · · ,K.
We see that this problem is a conventional linear programming problem. Therefore, the simplex
method can be used to obtain the optimal solution x∗k for k = 1, · · · ,K.
The optimal solution x∗(t) of problem (IVP1L) can be approximated by a function x¯L(t) =
(x¯L1 (t), · · · , x¯Ln(t)) that is obtained by fitting the points (tk,x∗k) for k = 1, · · · ,K. More precisely, the
ith component x∗i (t) of the optimal solution x
∗(t) can be approximated by a function x¯Li (t) that is
obtained by fitting the points (tk, x
∗
ik) for k = 1, · · · ,K. Of course, many existing numerical methods
in the literature for fitting functions can be used to obtain x¯L(t). For example, the polynomial
interpolations, least-squares approximations or B-splines as presented in Johnson and Riess [7] are
very useful for this purpose.
Similarly, the discrete problem corresponding to problem (IVP1U ) is given below:
(LP-IVP1U (K)) max
K∑
k=1
〈
xk,A
U (tk)
〉
subject to BU · xk ≤ CU (tk) +
k∑
s=1
CU · xs for k = 1, · · · ,K
xk ≥ 0 for k = 1, · · · ,K.
Using the interpolation technique as described above, we can also obtain the approximate optimal
solution x¯U (t) of x∗(t) of problem (IVP1U ).
By definition of optimal solution, if x¯L(t) = x¯U (t), then this function can be regarded as the
approximated optimal solution of problem (IVP1). However, it is rarely happened. Therefore, we
need to propose another viewpoint to validate the approximated optimal solution. Although we
cannot expect x¯L(tk) = x¯
U (tk) for k = 1, · · · ,K, if the values x¯L(tk) and x¯U (tk) are close enough
for each k = 1, · · · ,K, then we can imagine that the approximate optimal solution is possible to
be obtained based on the values x¯L(tk) = x¯
U (tk) for k = 1, · · · ,K. Therefore, we can measure the
following mean square error
1
K
·
K∑
k=1
[
x¯L(tk)− x¯U (tk)
]2
.
If the decision-maker can tolerate this error, then the approximate optimal solution of problem
(IVP1) will be obtained according to the following procedure: Since x¯L(t) = (x¯L1 (t), · · · , x¯Ln(t)) and
x¯U (t) = (x¯U1 (t), · · · , x¯Un (t)), we calculate the following average
x¯ik =
1
2
· [x¯Li (tk) + x¯Ui (tk)] .
15
BU · xk ≤ CU (tk) +
k∑
s=1
CU · xs for k = 1, · · · ,K
xk ≥ 0 for k = 1, · · · ,K.
The discrete problems (LP-CLP1L(K)) and (LP-CLP1L(K)) can also be similarly obtained. We
omit the detailed expressions here.
In the sequel, we shall introduce some other solution concepts. For any two closed intervals A
and B, we write A L B if and only if AL ≤ BL, and A U B if and only if AU ≤ BU . We also
see that A  B if and only if A L B and A U B. We say that x∗(t) is an L-optimal solution of
problem (IVP1) if∫ T
0
〈〈Ix(t),A(t)〉〉dt L
∫ T
0
〈〈Ix∗(t),A(t)〉〉dt, i.e.,
∫ T
0
〈x(t),AL(t)〉dt ≤
∫ T
0
〈x∗(t),AL(t)〉dt
for all x(t) ∈ X. We can similarly define the U -optimal solution of problem (IVP1).
Now we consider the following problem:
(L-IVP1) max
∫ T
0
〈〈Ix(t),A(t)〉〉dt
subject to B ⊗ Ix(t) L C(t)⊕
∫ t
0
C ⊗ Ix(s)ds for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
where the constraints use the ordering L. Then we say that x∗(t) is an LL-optimal solution of
problem (IVP1) if x∗(t) is an L-optimal solution of problem (L-IVP1), and that x∗(t) is a UL-
optimal solution of problem (IVP1) if x∗(t) is a U -optimal solution of problem (L-IVP1). More
precisely, we see that x∗(t) is an LL-optimal solution of problem (IVP1) if∫ T
0
〈
x(t),AL(t)
〉
dt ≤
∫ T
0
〈
x∗(t),AL(t)
〉
dt
for all x(t) ∈ XL, and that x∗(t) is a UL-optimal solution of problem (IVP1) if∫ T
0
〈
x(t),AU (t)
〉
dt ≤
∫ T
0
〈
x∗(t),AU (t)
〉
dt
for all x(t) ∈ XL.
We can also consider the following problem:
(U -IVP1) max
∫ T
0
〈〈Ix(t),A(t)〉〉dt
subject to B ⊗ Ix(t) U C(t)⊕
∫ t
0
C ⊗ Ix(s)ds for 0 ≤ t ≤ T
x : [0, T ]→ Rn is a nonnegative and bounded measurable function
Then we can similarly define the concepts of LU -optimal and UU -optimal solutions of problem
(IVP1).
Now the computational procedure for solving problem (IVP1) is given below.
• Step 1. Call Subroutine A. If the approximate optimal solution of problem (IVP1) can be
obtained, then stop; otherwise, go to Step 2.
17
subject to x1(t) ≤ CU2 +
∫ t
0
x2(s)ds
x3(t) ≤ CU4 +
∫ t
0
x4(s)ds
0 ≤ CU3 +
∫ t
0
[
x3(s)−BL1 x1(s)−BL2 x2(s)−BL4 x4(s)
]
ds
xi(t) ≥ 0 for i = 1, 2, 3, 4.
Also, the corresponding discrete problems (approximated problems) are given by
(LP-IVPL(K)) max
K∑
k=1
x1k
subject to x1k ≤ CL2 +
k∑
s=1
x2s for k = 1, · · · ,K
x3k ≤ CL4 +
k∑
s=1
x4s for k = 1, · · · ,K
0 ≤ CL3 +
k∑
s=1
x3s −BU1
k∑
s=1
x1s −BU2
k∑
s=1
x2s −BU4
k∑
s=1
x4s
for k = 1, · · · ,K
xik ≥ 0 for i = 1, 2, 3, 4 and k = 1, · · · ,K.
and
(LP-IVPU (K)) max
K∑
k=1
x1k
subject to x1k ≤ CU2 +
k∑
s=1
x2s for k = 1, · · · ,K
x3k ≤ CU4 +
k∑
s=1
x4s for k = 1, · · · ,K
0 ≤ CU3 +
k∑
s=1
x3s −BL1
k∑
s=1
x1s −BL2
k∑
s=1
x2s −BL4
k∑
s=1
x4s
for k = 1, · · · ,K
xik ≥ 0 for i = 1, 2, 3, 4 and k = 1, · · · ,K.
Similarly, the discrete problems (LP-IVPLU (K)) and (LP-IVPUL(K)) can also be obtained. In order
to obtain the nondominated solution, we consider the following problem
(CLP) max CL1 + C
U
1 + 2
∫ T
0
x1(t)dt ≡
∫ T
0
x1(t)dt
subject to x1(t) ≤ CL2 +
∫ t
0
x2(s)ds
x3(t) ≤ CL4 +
∫ t
0
x4(s)ds
x1(t) ≤ CU2 +
∫ t
0
x2(s)ds
19
[12] A. Pre´kopa, Stochastic Programming, Kluwer Academic Publishers, Boston, 1995.
[13] A.L. Soyster, Convex Programming with Set-Inclusive Constraints and Applications to Inexact
Linear Programming, Operations Research 21 (1973) 1154-1157.
[14] A.L. Soyster, A Duality Theory for Convex Programming with Set-Inclusive Constraints, Op-
erations Research 22 (1974) 892-898; Erratum, 1279-1280.
[15] A.L. Soyster, Inexact Linear Programming with Generalized Resource Sets, European Journal
of Operational Research 3 (1979) 316-321.
[16] I.M. Stancu-Minasian, Stochastic Programming with Multiple Objective Functions, D. Reidel
Publishing Company, 1984.
[17] D.J. Thuente, Duality Theory for Generalized Linear Programs with Computational Methods,
Operations Research 28 (1980) 1005-1011.
[18] W.F. Tyndall, A duality theorem for a class of continuous-time linear programming problems,
J. Soc. Indust. Appl. Math. 13 (1965) 644-666.
[19] W.F. Tyndall, An Extended Duality Theorem for continuous-time linear programming Prob-
lems, SIAM J. Appl. Math. 15 (1967) 1294-1298.
[20] S. Vajda, Probabilistic Programming, Academic Press, 1972.
21
100年度專題研究計畫研究成果彙整表 
計畫主持人：吳憲忠 計畫編號：100-2221-E-017-005-MY2 
計畫名稱：連續時間區間值線性規劃問題 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
The continuous-time linear programming problem with interval-valued objective and 
constraint functions is investigated in this research project. One of the 
contribution is to introduce the notion of scalar product of closed intervals. 
After the fundamental properties have been established, the notion of integral 
of interval-valued function can be defined based on the concept of integral of 
set-valued function, which is another contribution of this research project. Under 
these settings, we can formulate the continuous-time linear programming problem 
with interval-valued objective and constraint functions, which can be regarded 
as the extension of conventional continuous-time linear programming problem. This 
is the main contribution of this research project for modeling the uncertainty 
of this probpem. Since the set of all closed intervals cannot be a totally ordered 
set, the concept of nondominated solution are defined. 
The main purpose is to derive the optimality conditions and duality theorems for 
continuous-time 
interval-valued linear programming problem. Two different kinds of 
continuous-time interval-valued linear programming problems, i.e., the 
time-independent interval-valued coefficients and time-dependent interval-valued 
coefficients, are studied. Finally,the numerical method is also developed to 
