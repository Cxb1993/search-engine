  
摘   要 
為因應國內人口老化問題對醫療資源運用所帶來的衝擊，本整
合型研究計畫過去三年主要致力於設計一護理型機器人系統，提供
居家照護對象日常看護、生理資訊監測及影像輔助監控…等服務，
藉以彌補目前照護制度之不足並提昇國人接受居家照護之意願，進
而降低醫療資源的浪費。本計畫由三個子計畫構成，包含：(1)居家
型護理機器人之研製，(2)智慧型即時診斷系統晶片平台設計，(3)
智慧型家用機器人輔助系統之設計與研究。其中，子計畫一建置之
護理機器人可提供多樣化行為代理服務，其利用距離感測器判斷障
礙物狀態並以階層式模糊邏輯推論合適之運動策略，而後根據影像
辨識資訊驅動多軸機械臂執行夾取並遞交目標物之任務。子計畫二
利用短時傅立葉轉換及支持向量機自動分析心音訊號，並以適應性
特徵擷取及改進支持向量機檢測心電圖內心律不整訊號；此外，為
提昇護理機器人之視覺處理及辨識能力，其亦完成高動態範圍影像
處理及不均勻光源下人臉辨識技術之開發。子計畫三建立之智慧型
影像輔助監控系統可針對居家照護對象日常活動進行長時間監
控，其經由對受觀測目標之運動特徵分析，對於可能之異常行為或
危急事件(如：摔倒、跌落…等)進行即時偵測並發佈警報，藉以降
低患者自主健康管理之風險。 
關鍵詞—居家護理機器人、自主移動式機器人、心音心電圖分析、
高動態範圍影像、人臉辨識、智慧型影像監控、跌倒偵測。 
 
Abstract 
This integrated project aims at designing a household nursing robot 
system (HNRS) for providing the elderly or disabled with various 
services, such as simple nursing care, supervision of vital sign and 
video-assisted activity recognition. The HNRS project consists of three 
subprojects, including 1) Design of a Home-Care Mobile Robot 
(HCMR); 2) The SoC Platform Design for Intelligent Real-Time Diag-
nosis System (IRTDS); and 3) Design of an Intelligent Household 
Robotic Assistant System (IHRAS). The main achievements of each 
subproject are briefly described as follows. The HCMR project has 
constructed a nursing robot with the capability of autonomous naviga-
tion as well as daily assistance, which adopts laser rangers and camer-
as—for detecting obstacles and searching targets respectively—in 
cooperation with hierarchical fuzzy logic controllers to drive the mo-
bile platform and manipulator so as to carry out the task of transferring 
objects. The IRTDS project develops a real-time diagnosis system and 
robot vision system for the nursing robot based on a system-on-a-chip 
(SoC) platform. Using SoC with embedded software technologies, the 
systems integrate versatile hardware and software modules into a small 
device such that the practicability of the systems can be promoted. The 
IHRAS project has completed a home-care-oriented intelligent vid-
eo-assisted surveillance (IVAS) system. Through persistently monitor-
ing patient activity areas in the domestic environment, the IVAS system 
can automatically analyze human postures and movement in real time. 
This functionality makes the nursing robot system not only be able to 
detect life-threatening fall events, but also to autonomously inform 
nursing personnel or family members if necessary. 
Keywords — Household nursing robot, autonomous mobile robot, 
phonocardiograph and electrocardiograph analysis, high dynamic range 
image, face recognition, intelligent video surveillance, fall detection.  
 
一、前  言 
隨著出生率的降低，目前世界各先進或已開發國家
幾乎均面臨人口老化在社會或經濟層面所帶來的問題
與衝擊。根據內政部之人口統計資料顯示，我國於
2007 年底老年人口(65 歲以上)約為 230 萬人，占全國
總人口 10%，其相較於 2006 年底約增加 0.26 個百分
點，人口已超過聯合國世界衛生組織所定義之老年人
口比率為 7%之高齡化社會標準；除此之外，據同時
期資料顯示 2007 年身心障礙者亦已達 100 多萬人。面
對如此高比例可能有長期照護需求之潛在族群，如何
提供妥善照顧並降低政府之醫療與社福負擔長久以來
一直是各領域研究或相關從業人員努力的目標。 
針對此議題之迫切性，本整合型計畫預計以三年研
發時程，發展一居家護理機器人系統，以提供老年人
或行動不便者各項日常所需服務，如：基礎之護理與
照顧、生理訊號監測及行動輔助…等，使其可獨立生
活而毋須長期依賴療養院、護理之家或其他醫療機構
之照護。此不僅可滿足其對於生活之獨立性與自主性
之需求，更可有效降低醫療資源的浪費，並為個人或
政府節省龐大之醫療開支。本計畫由三個子計畫所構
成，包含：(1)居家型護理機器人之研製，(2)智慧型即
時診斷系統晶片平台設計，(3)智慧型家用機器人輔助
系統之設計與研究。其中，子計畫一旨在設計一居家
型護理機器人之硬體機構與相關軟體介面開發，以提
供居家環境成員護理服務之硬體平台；子計畫二負責
居家輔助診斷系統平台建置，其利用系統晶片與嵌入
式軟體技術開發智慧型即時診斷系統以及機器人視覺
系統，以便將多種軟硬體設計整合於單一晶片中，裨
使居家照護系統相關元件更趨小型化；子計畫三主要
任務為開發適用於居家環境之影像輔助監控系統，其
以影像訊號處理與電腦視覺理論為基礎，自動萃取並
分析受照護對象之影像特徵，藉以估測其目前狀態並
監控是否發生緊急事件。 
根據上述研究目標，各子計畫過去三年來已陸續完
成相關系統模組之功能開發與研究工作。這些成果除
了包括基礎技術之發展外，更包含相當程度之理論或
實務方式之創新。子計畫一建置之護理機器人可提供
多樣化行為代理服務，其利用距離感測器判斷障礙物
狀態並以階層式模糊邏輯推論合適之運動策略，而後
根據影像辨識資訊驅動多軸機械臂執行夾取並遞交目
標物之任務。子計畫二利用短時傅立葉轉換及支持向
量機自動分析心音訊號，並以適應性特徵擷取及改進
支持向量機檢測心電圖內心律不整訊號；此外，為提
昇護理機器人之視覺處理及辨識能力，其亦完成高動
態範圍影像處理及不均勻光源下人臉辨識技術之開
發。子計畫三建立之智慧型影像輔助監控系統可針對
居家照護對象日常活動進行長時間監控，其經由對受
觀測目標之運動特徵分析，對於可能之異常行為或危
急事件(如：摔倒、跌落…等)進行即時偵測並發佈警
報，藉以降低患者自主健康管理之風險。 
本成果報告之目的在概述各子計畫三年來於居家
型護理機器人系統設計領域之研發成果，其內容主要
涵蓋居家型護理機器人系統建置所需之理論推導、設
計方法以及相關之模擬與實驗結果，而本報告之架構
係以各子計畫為單位，採用分節討論方式呈現各自之
研究方法與研究成果。 
 
 
 3
 
C. 雷射測距儀 
本子計畫使用的雷射測距儀是由HOKUYO公司製
造，型號為 URG-04LX。URG-04LX 實體如圖 1.4 所
示。URG-04LX 掃描弧度為 240 度，且最大半徑為 400
公分，每個掃描點相距 0.36 度。 
 
圖 1.4 雷射測距儀 
本子計畫使用兩個雷射測距儀，分別掃描上及下
層，當移動機器人靠近目標物時，上層之雷射測距儀
掃描前方 60 度、90 度、120 度的距離，以調整移動機
器人和目標物夾取距離。下層之雷射測距儀掃描前方
0~180 度之障礙物距離，每隔 30 度取一個最小值。 
 
D. 五軸機器手臂 
本子計畫所使用的 5+1 軸機器手臂，手臂長度約
50 公分如圖 1.5，機器手臂共使用 10 個 AX-12 AI 伺
服馬達控制。 
 
圖 1.5 五軸機器手臂[1] 
手臂控制系統架構如圖 1.6 所示，一開始電腦經
由手臂控制器下命令，手臂控制器再操控機器手臂上
伺服馬達以完成命令。 
 
圖 1.6 手臂控制系統架構 
     
E. 視覺系統 
視覺系統之攝影機架設在頭部利用四顆伺服馬達
來控制方向如圖 1.7 所示。 
 
圖 1.7 移動機器人頭部機構[2] 
機器人開始搜索目標物時，將攝影機所擷取到的影
像先進行二值化，二值化後的影像進行Roberts快速邊
緣偵測如圖1.8所示，再進行形狀判斷，若不為所指定
之形狀，就繼續搜索目標物，直至搜索到目標物。若
為所指定之形狀開始朝此目標物前進。前進將僅利用
影像追蹤判斷目前目標物位於機器人之方位，可使機
器人朝此方向前進。 
 
(a) 原圖 
 
(b) 二值化 
 
(c) 邊緣偵測 
圖 1.8 二值化和邊緣偵測 
 
E. 電源系統 
機器人電源系統大致可分為五大部分如圖 1.9 所
 5
而動態靜態障礙物模糊邏輯系統，輸入為 X11 前後筆
資料的差，即 Xd=X11(k+1)-X11(k)，其歸屬函數如圖
1.13 所示，其規則為：  
IF Xd IS s THEN Ө=Q1 , 
IF Xd IS M THEN Ө=Q2, 
IF Xd IS b THEN Ө=Q3 
 
圖1.13 輸入Xd歸屬函數 
 
B. 沿牆面之模糊邏輯系統 
沿牆面之模糊邏輯系統為第二級的模糊系統，輸入
X2 、X3為下層雷射測儀度 120~180 度及 0~60 度最短
距離， X2其歸屬函數如圖 1.14 所示，其規則為： 
IF X2 IS FAR THEN Ө=Q1, 
IF X2 IS MED THEN Ө=Q2, 
IF X2 IS NEAR THEN Ө=Q3 
輸出為機器人行走偏移角度。偏右行走定義為正，偏
左行走定義為負。  
0
cm
Near Med Far
856035
1
 
圖 1.14 輸入 X2歸屬函數 
 
C. 抓取目標物之模糊邏輯系統 
當機器人確定無任何障礙物時，機器人開始原地旋
轉，經由攝影機尋找紅色目標物，找到目標物後往目
標物方向行進。其模糊邏輯系統輸入為紅色目標物所
在的橫向像素點，由左到右 0~176，其輸入歸屬函數
如圖 1.15 所示，其規則為： 
IF X6 IS L THEN Ө=Q1, 
IF X6 IS M THEN Ө=Q2, 
IF X6 IS R THEN Ө=Q3 
其輸出為機器人行走偏移角度。偏右行走定義為正，
偏左行走定義為負。  
0
Pixel
L M R
15011075  
圖 1.15 輸入 X2歸屬函數 
當機器人距離目標物 20 公分處，機器人便執行抓
取行為，抓取行為其模糊系統輸入為攝影機的影像，
其模糊邏輯系統輸入為紅色目標物所在的縱向像素
點，由上到下分成 0~144，其輸入歸屬函數如圖 1.16
所示，其規則為： 
IF X6 IS UP THEN HIGH, 
IF X6 IS DOWN THEN LOW. 
輸出為決定機器人手臂往上層夾取或往下層夾
取，上層夾取約高度約 103 公分，下層夾取約高度約
80 公分。 
 
圖 1.16 輸入 X6歸屬函數 
 
1.3 實驗結果 
移動機器人靜態、動態避障實驗平面圖如圖 1.17
所示，一開始機器人右側靠牆，目標物置於機器人前
方，兩者間放置紙箱當做靜態障礙物，當機器人靜態
避障後，動態障礙物將出現於目標物和機器人之間。
錄影機一開始拍攝於攝影機 1 的位置，當機器人開始
抓取目標物時，拍攝位置移動到攝影機 2，實驗中執
行動作行為流程如圖 1.18 所示，其各個動作行為模糊
邏輯系統定義如 2.2 中所描述。靜態、動態避障實驗
詳細結果如圖 1.19 所示。 
 
圖 1.17 移動機器人靜/動態避障實驗平面 
 
 7
 
(i)動態避障行為：機器人原地旋轉，躲避動態障礙 
 
(j) 沿目標動作行為：動態避障執行完畢，原地旋轉找尋目
標物 
 
(k) 沿目標動作行為：找到目標物，往目標物前進 
 
 (l) 抓取動作行為： 執行抓取動作行為，判斷目標物上層
或下層。 
 
(m) 抓取動作行為：舉起機器手臂準備夾取。 
 
(n) 抓取動作行為：機器手臂準備夾取目標物。 
 
(o) 沿目標動作行為：舉起目標物，原地旋轉尋找第二個目
標物 
 
(p) 沿目標動作行為：找到第二目標物，機器人往目標物前
進。 
 
(q) 沿目標動作行為： 將第一個目標物交給第二個目標物。 
 
 
(r)收取機器手臂，完成動作  
圖 1.19 第二個移動機器人靜態、動態避障實驗結果 
 
 
 9
子計畫二：智慧型即時診斷系統 
晶片平台設計 
隨著高齡化社會的來臨，需要長期居家照護的人口
越來越多，預期全世界將面臨居家照護人力的嚴重不
足問題，特別是老年人口與慢性疾病患者，常因為行
動不方便或是路程遙遠等原因，造成就醫的困難度，
必須仰賴看護人員長時間的照顧，因此需要發展居家
護理機器人解決看護人力不足的問題。藉由系統晶片
與嵌入式軟體來實現輕薄短小的可攜式照護系統晶片
平台與機器人整合以完成居家護理機器人的設計。 
理想的專業護理機器人必須具備安全保護、生理監
測及照護等功能，故本研發團隊在為期三年的時間
內，針對居家照護系統中較為不足的機器人視覺及生
理訊號監測的部份，開發出包括以區域對比估測及攝
影色調重現的高動態範圍影像處理、應用區域對比增
強於不均勻光源下之人臉辨識、利用短時傅立葉轉換
及支持向量機對心音訊號做自動分析及以適應性特徵
擷取及改進支持向量機檢測心電圖心律不整等四大系
統，使居家照護系統能夠具備更完善的功能。 
 
2.1 以區域對比估測及攝影色調重現的高動態範
圍影像處理 
 
A. 系統架構 
我們所提出的高動態範圍 (high dynamic range, 
HDR)影像處理流程，就如圖 2.1 所示。該演算法架構
是為了改善在高動態範圍場景下的可見性，而重新調
整影像的強度值。 
假設輸入的影像是由消費型的數位相機 (digital 
still camera, DSC) 拍攝而得，因此，影像資料應該被
存成標準的 RGB(sRGB)色彩空間並經過伽瑪校正
(gamma correction)，故輸入影像要做反伽瑪校正
(inverse gamma correction)轉換成線性 sRGB 色彩空
間，使得在之後的高動態範圍處理流程可以維持住顏
色的正確性。 
Photographic
tone reproduction
Local contrast
map evaluation
Bilateral filter
RGB to Yxy
Yxy to RGB RGBnormalization
Initial scaling
Tone
mapping Gamma
R
G
B
x   y
YL
YA
R
G
B
YS
Local contrast
extraction
Histogram
equalizationSimilar filter
R G B
R G B
x   y
YBY
Inverse
gamma Y
R
G
B
YHYG
Input image
Output image
Y adjustment
Y
YT
 
圖 2.1 高動態範圍影像處理流程 
第二步驟，為了代表亮度(Y)和彩度(xy)將影像轉換
成 CIEXYZ 色彩空間。接下來的過程是重新調整 Y 成
分以提高視覺品質的兩種方法：局部對比映射圖評估
(local contrast map evaluation)以及攝影色調重現
(photographic tone reproduction)。 
用區域對比映射圖代表一張影像可以大大減低動
態範圍，因為像素對比值是以中心像素與其相鄰像素
的相對強度比率為基礎所偵測到的。由於自然界低通
的特性，一般相對比率遠小於整體影像原來的動態範
圍。不過使用像素梯度來代表影像對隨機雜訊而言是
相當敏感的，因此，在估測每一像素的區域對比值之
前，影像的亮度值要通過強健的雜訊濾波器。如此一
來，影像紋理就變得顯而易見，尤其是在暗處的像素。
為了使影像內的紋理更加顯著，透過統計直方圖等化
(histogram equalization)的過程讓對比值範圍進一步延
伸。經由上述步驟，雖然整體對比提高了，但如果原
始影像是由典型的數位相機拍攝得到，那麼輸出的影
像可能仍然會有許多雜訊。我們提出一個相似濾波器
(similar filter)使對比映射圖平滑化，該濾波器檢查相
鄰像素的顏色跟中央像素相似才做亮度值的平均。這
種平滑化後對比映射圖可以減低不想要的人造影像，
如光環或相反的對比值。 
繼區域對比圖評估之後，像素的亮度值被原始亮度
和平滑化後對比值的幾何平均數所取代。影像的對比
得到了加強後，新的亮度圖保持更好的可見性，然後
色調重現重新調整像素亮度值以進一步增強影像。 
色調重現流程經由利用時間考驗的攝影實踐技術
被設計產生，它由初始調整(initial scaling)、色調映射
(tone mapping)、色彩空間轉換(color space conversion)
及數據正規化(data normalization)等階段所組成。在初
始調整階段，輸出的色調範圍是首先被正規化，使得
影像亮度對數值的平均大約為 18%的灰階色調(18% 
gray tone)。色調映射過程非線性地調整亮度值，使得
亮度在明亮區域衰減，以減少整個動態範圍，同時提
高了較暗區域的相對亮度。透過傳遞原始彩度值(xy)
到最後影像合成階段，讓顏色恆定可以保留下來。在
高動態範圍影像中所採用的策略是用較低曝光的方式
拍攝影像以減少過度曝光像素的數量，並採用綜合色
調重現方法恢復像素的亮度以及顏色。原始影像在曝
光不足和過度曝光的區域看起來顏色黯淡，藉著整合
已縮放過亮度值的像素資訊及原始彩度值，讓得到的
影像色彩看起來可以更加鮮豔，這是因為大多數像素
曝光調整成更好的設定。 
 
B. 以影像處理為基礎應用於視訊處理 
一般而言，視訊處理流程是使用 YCbCr 或 YUV
的格式，因此，輸入及輸出訊號的色彩空間不再是高
動態範圍影像處理流程內所標示的 RGB，而是修改為
YCbCr。 
視訊處理流程，中間會經過離散餘弦轉換(discrete 
cosine transform, DCT)、量化(quantization)、可變長度
編碼(variable length coding, VLC)等步驟，一直都是
YCbCr 的串流格式，所以，用 YCbCr 取代原來的 RGB，
這樣一來色彩空間轉換的步驟就可以省略。 
另外，高動態範圍視訊處理流程亦省略伽瑪校正
(gamma correction)及反伽瑪校正(inverse gamma cor-
 11
圖 2.4 戶外原始測試影像 
圖 2.5 室內測試影像(攝影色調重現) 
圖 2.6 室內測試影像(適應性 retinex 濾波) 
圖 2.7 室內測試影像(感光色調重現) 
圖 2.8 室內測試影像(提出的方法) 
圖 2.9 戶外測試影像(攝影色調重現) 
圖 2.10 戶外測試影像(適應性 retinex 濾波) 
圖 2.11 戶外測試影像(感光色調重現) 
 13
(b)戶外 
圖 2.15 調整後的亮度圖 
(a)直方圖等化後的對比圖 
(b)直方圖等化和相似濾波器平滑化的對比圖 
圖 2.16 局部區域對比圖(室內) 
(a)直方圖等化後的對比圖 
b)直方圖等化和相似濾波器平滑化的對比圖 
圖 2.17 局部區域對比圖(戶外) 
 
2.2 應用區域對比增強於不均勻光源下之人臉辨
識 
A. 系統架構 
整個人臉辨識系統的處理流程如圖 2.18 所示，當
人臉資料輸入之後，將分為三大部份作處理。首先利
用區域對比增強（local contrast enhancement）的方式，
來處理每張影像被拍攝的光線不均勻的問題，而經過
此處理後，可將影像的細節保存下來並將這些可能影
響辨識結果的變因做某個程度的去除，之後再利用離
散餘弦轉換擷取特徵，以進行下一步的辨識。 
在辨識處理的程序中，通常要經過前置處理的步
驟，並產生很多相關的數據，但是如何快速的處理這
些數據完成判斷，此時就需要進行數據的分類；如果
要確認所定的判斷規則或者是所擷取的特徵條件，是
否合乎研究所預期的處理結果，一般的做法會先擁有
一群用以建立系統的樣本，這些樣本通常稱為訓練樣
本(training sample)，訓練樣本進入系統後，會改以各
種型態的特徵表現出來，然後根據這些樣本建立某種
 15
表 2 特徵選取數量的統計表 
8 67 69
10 11 8
12 10 6
14 5 3
16 1 2
18 4 6
20 3 3
22 1 3
24 0 3
26 0 1
28 1 0
30 1 1
32 1 0
Total Number of
Hyperplanes 105 105
The Average Number
of Feature values 10.438 10.857
The Number of Feature
values
The Number of Hyperplanes
W ithout LCE W ith LCE
 
 
表 3 支持向量的統計表 
1 0 0
2 0 0
3 0 0
4 15 11
5 43 30
6 47 64
7 0 0
8 0 0
9 0 0
10 0 0
11 0 0
Total Number of
Hyperplanes 105 105
The Average Number
of Support Vecotrs 5.304 5.504
The Number of
Support Vectors Without LCE With LCE
 
 
表 4 人臉辨識的結果 
Without LCE With LCE Without LCE With LCE
8 10 3 88.89 96.67
10 11 4 87.78 95.56
12 10 4 88.89 95.56
14 10 3 88.89 96.67
16 8 2 91.11 97.78
18 8 3 91.11 96.67
20 10 1 88.89 98.89
22 10 2 88.89 97.78
24 9 1 90 98.89
26 9 1 90 98.89
28 9 1 90 98.89
30 7 1 92.22 98.89
32 7 0 92.22 100
Adaptive Feature
Selection 3 0 96.67 100
The Number of
Feature values
Number of the Misrecognized
Images Recognition Rate (%)
 
 
表 4 為每個人選出五張(共 75 張)來訓練，其餘的
90 張影像來測試所得到的結果，下表 5 為 Adaptive 
Feature Selection 的統計圖，由此表可看出大部份的
Feature Number 小於 10，而平均值為 8.5，因此可以分
析出大部份的 Feature Number 都沒有很大，表示我們
選用的 Feature 都不會很大。表 6 為 Adaptive Feature 
Selection 的支持向量統計圖，由此表可看出大部份的
SV Number 小於 4，而平均值為 3.18，因此可以分析
出大部份的 SV Number 都沒有很大，表示大部份的
hyper-plane 可以容易分類。未經區域對比增強的影
像，其辨識率為 96.67%。而經過區對比增強之後的影
像，其辨識率為 100%。由此可知，經過我們建議的
方法之後，其辨識率大大的提升，並且有效的解決光
源變化的問題。 
表 5 特徵選取數量的統計表 
8 88 97
10 2 3
12 2 1
14 2 1
16 1 0
18 1 0
20 0 3
22 2 0
24 3 0
26 0 0
28 2 0
30 2 0
32 0 0
Total Number of
Hyperplanes 105 105
The Average Number
of Feature values 9.92 8.5
The Number of Feature
values
The Number of Hyperplanes
Without LCE With LCE
 
 
表 6 支持向量的統計表 
1 0 0
2 33 66
3 2 6
4 9 4
5 19 12
6 24 13
7 12 2
8 4 2
9 1 0
10 1 0
11 0 0
Total Number of
Hyperplanes 105 105
The Average Number
of Support Vecotrs 4.59 3.18
With LCEThe Number ofSupport Vectors Without LCE
 
 
表 7 人臉的辨識結果 
8 289 91.55
10 234 93.16
12 182 94.68
14 166 95.15
16 167 95.12
18 153 95.53
20 131 96.17
22 133 96.11
24 114 96.67
26 94 97.25
28 82 97.6
30 85 97.51
32 75 97.8
Adaptive Feature
Selection 51 98.51
The Number of
Feature values
Recognition
Rate (%)
Number of the
Misrecognized
Images
 
 
(c) Yale_B 實驗結果 
根據人臉辨識演算法經由 Adaptive Feature 
Selection 的 SVM 辨識系統的處理，針對 Yale_B 
Database 的人臉資料庫做統計分析，此人臉資料庫的
樣本數有十個人，每個人有九種姿勢，每個姿勢有四
個 subset，分別在不同角度的光源下做變化，所以每
人有四百零五張，總共有四千五十張。 
首先我們將人臉資料庫經過區域對比增強，並選擇
 17
2.3 以短時傅立葉轉換及支持向量機對心音訊號
做自動分析及適應性特徵擷取 
A. 系統架構 
 
圖 2.24 心音辨識系統處理流程 
整個辨識系統的處理流程(如圖 2.24 所示)，我們使
用德州心臟學會的心音當資料來源，當心音訊號輸入
之後，將資料分為三大流程處理：切割處理、特徵擷
取及分類器。切割處理：這個步驟主要是對心音圖的
訊號去做心臟週期的切割，其切割的流程首先將心音
圖資料降取樣數，再來是利用直方圖統計方法對心音
圖做時域訊號的凸顯，可以分別凸顯出找心音週期長
度及找心音切割初值位置的訊號，之後將凸顯後的心
音訊號做自相關函數可預測心臟週期長度，有了心音
週期長度及心音切割初值位置，我們就可以切割出心
臟週期，再對切割出來的心跳做重疊修正及置中修
正。特徵擷取：對於特徵擷取最主要目的就是要找尋
能幫助診斷心臟病症的特徵，我們先將資料做正規
化，再分別使用短時傅立葉轉換(STFT)及二維離散餘
弦轉換(2D-DCT)，這兩種方法對心臟週期去做特徵擷
取，主要是因為短時傅立葉轉換會同時考慮到時域及
頻域的特性，而二維離散餘弦轉換會對高相關性的信
號內容集中在少數低頻係數上，最後將特徵擷取結果
交由分類器去做辨識。分類器：在分類器部份，分為
訓練樣本和測試樣本兩部份，首先在訓練樣本時，針
對 17 種特徵維度作辨識，並且依其辨識結果判斷最佳
的特徵向量，在這訓練過程中，會針對每兩類之間統
計出每個特徵值在對於辨識的權重，也就是對於兩類
之間的最能區分的特徵。而測試樣本的部份是使用支
持向量機(support vector machines)為辨識的核心，由於
支援向量機是每兩類之間相互做比較，因此必須能比
較出兩類之間差異的特徵，利用能夠所取的特徵值來
做為決定病症。 
 
B. 心音辨識 
心音的預測係由支持向量機判別，其決策函數為 
 
 
圖2.25 心音辨識的流程 
 
1
( ) [ ( ) ]
[ ( ) ( ) ]
n
i i i
i
f x sgn w x b
sgn y x x b
f
a f f
=
= ⋅ +
= ⋅ +å  
判斷 ( )f x 之正負值就可得知分類結果，整個心音辨識
的流程如圖2.25。我們使用的辨識系統輸入為未知的
特徵向量，每個未知的特徵向量根據當初訓練分類的
hyper-plane使用的特徵維度取得對應此維度的特徵
值。 
例如輸入的未知特徵向量要分辨第一與第二類
時，就取第一與第二類的hyper-plane辨認當初訓練出
的hyper-plane當輸入的特徵值，然後這些值經過之前
的訓練模型與支持向量的運算後，最後系統輸出為第
一類或第二類。接著我們使用一個投票機制來做為系
統第二級的辨認。例如：系統在經過第一類與第二類
的分類後會決定出分類結果，比較第一與第二類系統
覺得此未知向量應該是第一類則系統就會投給第一類
一票，將第一類的票數加一票。同理比較第一與第三
類後將系統輸出的那個類別的票數加一票，最後則經
過946個hyper-plane的比較後，第一到第四十四類中都
會累積一些SVM比較這946個hyper-plane後所投出的
票。在第一到四十四類中，累計票數最高的那個就是
系統最後輸出的辨認結果。 
 
C. 心音辨識結果 
針對德州心臟學會 20類的病症及 44種子類做統計
分析，本研究之心跳樣本個數經人為的方式去計算約
有 1031 下心跳週期，經過心音切割演算法可以順利的
切割出 980 下心跳週期，其切割心跳的成功率為
95.05%。利用 STFT 及 2D-DCT 擷取出的特徵經由
SVM 去做辨識，其中我們把 500 個心跳去做訓練樣
本，480 個心跳去做測試樣本去做辨識，其結果如表
10，最後經由 Adaptive Feature Selection 的辨識率為
94.79%，如表 11 特微選取數量的統計表，Feature 
Number 大部份在 32 以下平均值為 6.49，因此可以分
析出大部份的 Feature Number 都沒有很大，表示我們
選用的 Feature 都沒有很大，而表 12 為 Adaptive 
Feature Selection 的支持向量統計表，由此表可看出大
部份的 SV Number 小於 6，而平均值為 3.18 因此可以
分析出大部份的 SV Number 都沒有很大，表示大部份
的 Hyper-plane 可以容易分離，由此可知，心音經由我
們提出的自動分析系統分析之後，可以達到不錯的辨
識效果。 
 19
Sound1 
17 Third Heart Sound2 44 22 22 0 100
18 Tumor Plop 21 11 10 0 100
19 Wide Split S2 12 6 6 0 100
20 
Aortic Re-
gurgitation 
Case1 
31 16 15 0 100
21 
Aortic Re-
gurgitation 
Case2 
20 10 10 0 100
22 
Aortic Re-
gurgitation 
Case3 
18 9 9 0 100
23 
Aortic Re-
gurgitation 
Case4 
17 9 8 0 100
24 
Aortic Ste-
nosis 
Case1a 
16 8 8 0 100
25 
Aortic Ste-
nosis 
Case1b 
17 9 8 3 62.5
26 
Aortic Ste-
nosis 
Case2a 
25 13 12 0 100
27 
Aortic Ste-
nosis 
Case2b 
14 7 7 0 100
28 
Aortic Ste-
nosis 
Case2c 
10 5 5 0 100
29 
Aortic Ste-
nosis 
Case3a 
32 16 16 0 100
30 
Aortic Ste-
nosis 
Case3b 
34 17 17 0 100
31 
Mitral Re-
gurgitation 
Case1a 
10 5 5 0 100
32 
Mitral Re-
gurgitation 
Case1b 
19 10 9 0 100
33 
Mitral Re-
gurgitation 
Case1c 
9 5 4 0 100
34 
Mitral Re-
gurgitation 
Case1d 
17 9 8 0 100
35 
Mitral Re-
gurgitation 
Case2 
36 18 18 0 100
36 
Mitral Re-
gurgitation 
Case3 
16 8 8 1 87.5
37 Mitral Ste-nosis Case1 18 9 9 0 100
38 Mitral Ste-nosis Case2 13 7 6 0 100
39 Mitral Ste-nosis Case3 7 4 3 0 100
40 
Pulmonary 
Stenosis 
Case1 
20 10 10 4 60 
41 
Pulmonary 
Stenosis 
Case2 
26 13 13 0 100
42 
Tricuspid 
Regurgita-
tion 
25 13 12 0 100
43 VSD Case1 30 15 15 0 100
44 VSD Case2 54 27 27 0 100
To-
tal/Average 980 500 480 25 94.79
 
2.4 以適應性特徵擷取及改進支持向量機檢測心
電圖心律不整 
A. 系統架構 
完整的心電訊號辨識系統包含三個部份，訊號前處
理、學習階段、辨識驗證。心電圖的辨識系統首先在
第一階段進行單一心電圖訊號切割、心電圖訊分群、
特徵值擷取，接著第二階段為學習訓練，最後第三階
段則完成分類網路決策。心律不整辨識系統的處理流
程如圖2.26所示，未知的心電圖訊號通過輸入端之
後，會將心電圖訊號分為四大區塊處理。心電圖辨識
系統中，具有高量的R波是第一個偵測的重點；由於
各類病症的心電圖中QRS波是差異最為明顯的部位，
所以區域的搜尋上相對容易偵測出來。在切割完病症
資料後，由於資料十分龐大，因此需要對病症資料做
分群的動作，並且利用小波分解和分析波形來抽取各
個病症的特徵值，最後經由分類網路判斷出病症種類。 
 
B. 心搏偵測 
心電圖訊號量測的過程中，會因為人、事、物及時
間的不同而有所差異。例如胸前誘導量測時，黏貼於
胸腔的量測電極會受到呼吸的起伏的影響，因為胸腔
阻抗的改變，心電圖會呈現上下起伏的漂移情況；亦
或由於身體狀況的不穩定，心跳的週期與強度也會有
所差異。基於上述原因，偵測心電圖的QRS波形位置
時，必須使心電圖基於同一單位的基準上。主要流程
如圖2.27所示。 
QRS波的位置是每個心跳週期中最為重要的部
份，因為QRS波具有較高的能量，所以心電圖訊號分
割的過程中必須將QRS波的位置置於每一個週期的中
心點。一般來說，每一段正常心跳週期中的P波至T波
經過時間大約介於0.5到0.8秒間。典型的心律不整心電
圖資料庫每秒鐘取樣率為360個樣本數，如MIT-BIH心
電圖資料庫。由於大多數的重要特點是集中於 
PQRST波，因此心電圖識別系統每一段心跳需要至少
192個樣本數，耗費時間大約為0.52秒，故MIT-BIH心
電圖訊號的長度可覆蓋整個 PQRST波的範圍。 
 
圖2.26 心電圖辨識系統流程圖 
 21
果觀察出，辨識系統都能有效的將大多數的特徵維度
降至最低，平均維度以每一類取1/2作為學習樣本時為
最小，平均為69.31個(表17)，支持向量的平均各數為
26.82個(表19)。 
表 17 實驗結果 
Type of Dis-
ease 
Total of 
Beat 
the 
Learning 
Beats 
the Testing 
Beats 
the error 
Beats Rate (%)
N 71673 35837 35836 795 97.78 
L 7868 3934 3934 29 99.26 
R 7058 3529 3529 19 99.46 
a 120 60 60 5 91.67 
V 6452 3226 3226 68 97.89 
F 762 381 381 22 94.23 
J 78 39 39 2 94.87 
A 2384 1192 1192 67 94.38 
E 100 50 50 2 96.0 
J 220 110 110 8 92.73 
/ 3504 1752 1752 4 99.77 
F 222 111 111 4 96.40 
Total 100441 50221 50220 1025 97.96 
 
表 18 特徵選取量的統計表 
#Features #Hyperplanes #Features #Hyperplanes #Features #Hyperplanes #Features #Hyperplanes
4 272 124 6 244 2 364 0 
8 80 128 10 248 2 368 0 
12 42 132 7 252 5 372 3 
16 28 136 1 256 0 376 2 
20 28 140 6 260 2 380 0 
24 24 144 4 264 0 384 1 
28 19 148 6 268 1 388 0 
32 18 152 5 272 1 392 0 
36 17 156 3 276 2 396 1 
40 11 160 5 280 2 400 1 
44 10 164 3 284 0 404 1 
48 6 168 4 288 1 408 0 
52 8 172 7 292 4 412 3 
56 9 176 0 296 1 416 1 
60 8 180 3 300 2 420 0 
64 7 184 6 304 1 424 1 
68 11 188 3 308 0 428 1 
72 5 192 4 312 2 432 2 
76 6 196 3 316 2 436 1 
80 7 200 1 320 1 440 3 
84 4 204 0 324 2 444 1 
88 8 208 3 328 3 Numbet Of 
hyper-
planes 
861 92 10 212 6 332 1 
96 12 216 4 336 0 
100 3 220 2 340 1 
Average of 
Feature 69.31104 3 224 3 344 1 
108 7 228 4 348 2 
112 4 232 3 352 2 
 116 2 236 4 356 1 
120 6 240 3 360 1 
 
表 19 項目 IV 中支持向量的統計表 
Feature Hyperplanes Feature Hyperplanes Feature Hyperplanes Feature Hyperplanes 
2 85 36 1 75 2 180 1 
3 91 37 2 76 1 181 1 
4 81 38 4 77 2 187 1 
5 55 39 3 78 1 194 1 
6 47 40 2 80 1 196 1 
7 37 41 3 81 3 207 1 
8 31 42 2 82 1 208 1 
9 20 43 1 84 2 213 1 
10 32 44 2 88 1 220 1 
11 20 45 2 92 1 228 1 
12 13 46 2 97 1 234 1 
13 14 47 4 100 2 235 1 
14 11 48 3 101 1 238 1 
15 18 49 1 105 2 239 1 
16 13 50 2 106 1 240 1 
17 15 52 1 108 2 261 1 
18 15 54 1 109 1 269 1 
19 12 55 1 111 2 272 1 
20 8 56 1 118 2 287 1 
21 12 58 2 119 1 315 1 
22 6 59 3 120 1 340 1 
23 13 60 1 122 2 385 1 
24 11 63 1 124 1 442 1 
25 16 64 2 125 1 451 1 
26 5 65 3 127 1 Numbet Of 
hyper-
planes 
861 27 2 66 2 134 2 
28 3 67 2 137 1 
29 7 68 2 138 1 Numbet Of 
Support 
Vector 
26.8230 5 69 1 142 1 
31 2 70 3 147 1 
32 9 71 4 148 1 
 33 2 72 2 150 1 34 6 73 1 163 1 
35 5 74 1 165 1 
0
50
100
150
200
250
300
0 50 100 150 200 250 300 350 400 450
The dimension of feature vectors
Th
e 
nu
m
be
r o
f h
yp
er
pl
an
ce
s
(a)使用的特徵向量統計圖 
0
10
20
30
40
50
60
70
80
90
100
0 50 100 150 200 250 300 350 400 450
The number of support vectors
Th
e 
nu
m
be
r o
f h
yp
er
pl
an
es
(b)使用的支持向量統計圖 
0
50
100
150
200
250
300
350
1 51 101 151 201 251 301 351 401
The indices of the features
Th
e 
nu
m
be
r o
f h
yp
er
pl
an
es
(c)使用的特徵維度表示圖 
圖2.30 特徵向量統計圖 
 
2.5 結  論 
本子計畫主要目標是改善現有居家照護機器人對
於機器人影像系統及即時心音與心電圖診斷系統的缺
點，開發出更適用於家中患有心臟相關的慢性疾病，
以提供良好的醫療照護環境。 
 23
子計畫三：智慧型家用機器人輔助系統 
之設計與研究 
本計畫之研究目的為發展一影像輔助式居家環境
跌倒事件自動偵測系統。本系統主要係由兩大部份構
成：首先，一植基於新型色彩空間之改良式碼書背景
模型(Improved Codebook Background Model, ICBM)搭
配陰影抑制策略，用以偵測複雜且變動式背景中之目
標物；其次，利用ICBM產生之前景畫面計算目標物
前景團塊之運動與外型特徵參數，接著運用一系列辨
識策略判斷目標物目前之運動狀態是否正常，並藉此
偵測受測者是否正遭遇跌倒事件。本計畫採用低價且
容易取得之網路攝影機實現系統功能，實驗結果證實
本系統的確可有效區分一般日常活動與跌倒動作間之
差異，即時偵測跌倒事件之發生並適時發佈危險警報。 
以下各節分別就每一單元之運作原理及其涉及之
理論與技術基礎做一簡單說明，最後並以實際之跌倒
事件情境模擬實驗驗證本系統之可靠性。 
 
3.1 改良式碼書背景模型 (ICBM) 
使用背景相減法擷取移動物影像為目前最廣泛使
用的技術，傳統上其假設每一背景像素之色彩模型為
單模分佈(unimodal distribution)，利用目前像素與背景
像素值之差值大小判斷移動物像素所在位置，此法目
前已被證實在理想條件下可成功將靜態背景與動態前
景分割。然而，居家環境內常存在許多複雜且非靜態
之背景元素，例如：隨風不規則飄動的窗簾、盆栽植
物枝葉的晃動或是往復擺動的電扇…等，使得一般單
模高斯分佈無法有效描述此類變動式背景。為克服上
述缺點，本計畫採用碼書(codebook)技術建構居家環
境影像之背景模型[18]。碼書式背景模型(codebook 
background model, CBM)相較於傳統之混合式高斯模
型(mixture of Gaussians, MOG)而言[19]，其可在有限
之記憶體資源下有效描述快速變化之背景特徵，並對
受觀測場景進行長時間建模以提供精簡且分層式之背
景模型資訊。 
 
圖3.1 跌倒偵測系統之整體架構 
傳統之CBM係將場景之背景模型建立於一般RGB
色彩空間，其令畫面中每一像素擁有各自之碼書，且
每一碼書係由為數不等之碼詞(codeword)所組成，碼
詞之數目取決於其所屬像素位置之背景複雜度而定，
通常背景類型愈多樣化之像素需要愈多碼詞來完整描
述其模型。CBM以亮度邊界(brightness bounds)及色彩
偏移(color distortion)判斷目前像素是否顯示背景成
份，此將使碼書內的每一碼詞所描述之像素值群聚
(cluster)均呈現圓柱型(cylindrical)分佈，且造成各圓柱
體之軸心均通過RGB座標之原點。若吾人可由一像素
之碼書中檢索出任一碼詞其群聚圓柱體包含此像素
值，則此像素目前呈現的是背景部份，反之則為前景
(即運動目標物)部份。 
傳統之CBM利用色彩偏移量測將像素值與碼詞兩
者之亮度資訊納入比對依據，藉以降低兩者因亮度差
所造成之誤判，並避免如正規化RGB像素值等方法可
能造成之數值不穩定問題；此外，CBM並以加大碼詞
圓柱體之亮度上下界方式避免系統將背景亮部或前景
陰影誤分類為前景之一部份。CBM目前雖已被成功應
用於許多需自動化影像監控之場合中[20-24]，然而經
實驗證實，此法對前景投射於背景上之陰影抑制效果
有限，其一般而言僅對半影(penumbra)有較佳之抑制
能力，而對本影(umbra)部份則常無法有效去除。 
對此，文獻[25]提出將碼書式背景模型建立於HSV
色彩空間，並以圓錐-圓柱混合式(hybrid cone-cylinder 
codebook, HC3)背景模型改良傳統之CBM，藉以同時
克服背景上之陰影、亮部以及亮度變化對於前景分割
所造成的困難。HC3利用HSV色彩空間較接近人類視
覺感知並可較直觀且有效區分陰影[26]之特性建構
CBM，其利用圓錐-圓柱混合式群聚取代舊有的圓柱
模型，使CBM能更有效地抑制背景陰影與亮部
(highlight)。然而，由於HC3採用HSV色彩空間建構碼
書，此使其存在下述缺點：當吾人進行RGB對HSV轉
換時，所得之飽和度(saturation)S 值大小係代表在某
一亮度值時可得之最大飽和度百分比；換言之，HSV
座標內之值將與亮度值之大小相關，且當亮度值降低
時，因飽和度範圍變小將可能使得S 值呈現劇烈變化
[27-29]，此現象可由圖3.2所示之一暗紅色像素於HSV
空間之樣本分佈情形看出。圖中之RGB空間中的對角
線代表無色軸(achromatic axis)，而HSV空間之圓柱體
代表像素值之分佈邊界；為方便比較，吾人將所有座
標值正規化至 [0,1]區間。左上圖顯示該暗紅色像素值
因受到攝影系統內部雜訊之影響而產生輕微擾動，使
其群聚呈現小範圍分佈；右上圖為其RGB座標值之時
間響應圖。右下圖為HSV轉換結果，可看出該像素之S
值呈現劇烈變動，此造成其於HSV空間中之群聚呈大
範圍散佈(見左下圖)。由於此一缺陷，使得HC3在建
立碼書式背景時往往需要較多碼詞才可充份描述低亮
度背景之群聚型態，此不僅造成系統於背景建模時之
記憶體浪費，更可能拖慢碼書索引速度並降低目標物
偵測模組效能。 
 25
xp rd
ld
rs
ls
r
bs
ls
v
l
as
l
as
 
圖3.5 碼詞及其圓柱型群聚模型 
 
2 2
rd = -x p   且  ld = -v p  
其中 ⋅ 表示 2 normL - 。接著，若下列兩決策條件
皆符合的話，則表示 x位於碼詞 v之圓柱內 
r rd bs<   且  
   if 0 
   if 0 
l L l l
l U l l
d a s d
d a s d
ìï < ³ïíï < <ïïî
 
其中 , , 1U La a b > ；調整 La 與 Ua 可初步抑制陰影或亮
部之影響。 
為使ICBM能隨環境光源變化動態調整圓柱體之涵
蓋範圍，以便系統能勝任長時間監控之任務，本計畫
使用下列適應性調整策略修正碼書參數：假設樣本 x
已被判定落於碼詞 v之內，則 
1 1(1 )h h¬ + -v x v                   
2 2(1 )r r rs h d h s¬ + -                 
3 3(1 )l l ls h d h s¬ + -                 
其中 1 2 3, , 0h h h > 為學習率，其值愈大表示碼詞參數調
整速度愈快，但可能造成過度調整而降低ICBM之前
景偵測能力。一般而言，在碼詞建立之初吾人常指定
, 0r ls s > 以避免因產生過多初始碼詞而造成記憶體
資源浪費的缺點。 
此外，為避免ICBM將畫面中暫時性前景或雜訊所
生成之碼詞誤加入碼書，系統對每一碼詞配置一組存
取記錄 3( , , )F Lt t l Î  ，藉以評估各碼詞可靠性並做為
其個別保留與否之依據；其中 Ft 與 Lt 則分別為碼詞最
初及最近被匹配之時間標記(timestamp)，而l則表示
碼詞未被使用的最大時間長度，此三者作用方式以及
碼詞建立及刪除程序皆與傳統CBM演算法相同[18]。 
 
C. 目標物之陰影消除 
為加強系統對目標物投射於背景上之本影(umbra)
之抑制能力，在ICBM完成前景偵測後，系統導入一
組適用於IHLS空間之陰影消除策略以進一步減輕陰
影對前景分割所帶來的負面效應[27,28]。此策略之制
定主要係根據如圖3.4所呈現之像素值分布特性：當前
景陰影投射於背景時，對應該背景之像素亮度L將顯
著下降且飽和度S 稍為提昇，但色調H 方面則無明顯
變化。據此，吾人採用下列之陰影抑制策略：令經過
ICBM初步切割後之前景像素為 
c
oSh
oh
oS
S
Ht
St
St
Ht
oc
 
圖3.6 色彩平面上之陰影消除決策區域 
 
[ , , ] [ , ] [ , ]o o xo yo o o o o oL C C L L S= ºx c h  
且令該像素所對應之碼書內任一碼詞為 
1 2[ , , ] [ , ]LL C C m=v c  
當下列三條件完全符合時 
   and   o oL L L L Lg< - <  
0 SS S t- <   且  o HSh t- <c  
系統將 ox 視為碼詞 v所描述之背景受陰影投射後之
觀測值，故此時 ox 將被改分類為背景像素。圖3.6所示
之陰影區域即為上述規則於IHLS色彩(H-S)平面上所
形成之決策區域，當原前景像素值落於此類區域時，
則系統將此像素視為背景像素。 
 
3.2 跌倒事件偵測 
本計畫主要參考並改良文獻[31]所提之方法，採用
下列步驟偵測跌倒事件：1)以運動歷史圖 (motion 
history image, MHI)量化目標物主體之運動特性；2)以
影像矩量(moment)計算目標物團塊之近似楕圓；3)分
析目標物之MHI量化值及楕圓參數之變化幅度，據此
偵測並確認跌倒事件。以下概述各步驟之實現方法。 
 
A. 運動量化 (Motion Quantizer) 
由於跌倒經常伴隨著大幅度快速運動，此特性恰可
由運動歷史圖MHI之量化結果進行初步估測。首先令
目前畫面 ( , , )I x y t 與先前畫面 ( , , )I x y t t-D 之影像差
異(frame-difference image)二值化圖為 
 1    if  ( , , ) ( , , )
( , , )
 0    otherwise         
I x y t I x y t t Th
D x y t
ìï - -D >ï= íïïïî
 
一般令時間差 1tD = ，其值愈大通常將可由 ( , , )D x y t
看出愈明顯之動作差異；Th為一閥值(threshold)，其
值設定之優劣將直接影響 ( , , )D x y t 是否可如實反應二
影像間之差異，本計畫利用先前所提之適應性閥值快
速遞迴算法計算Th值。接著定義MHI為 
{ }
                              if   ( , , ) 1
( , , )
max 0, ( , , 1) 1   otherwise
T D x y t
H x y t
H x y t
ìï =ï= íï - -ïïî
其中T 表示MHI記錄運動變化之持續時間，由於跌倒
之動作多在1秒內完成，本計畫令 0.2T = 秒；在MHI
中，時間上愈近發生的動作其亮度愈高。假設團塊
(blob) ( )B t 為受測者目前所在之前景像素所成集合，
 27
常活動；對於跌倒事件(#1102畫面)，系統則可將其正
確無誤地判別為不正常活動並加以標記(如圖中之黃
色警示)；而後待目標物跌落並靜止5秒後(#1131畫
面)，系統亦可成功確認跌倒事件發生並發佈緊急通報
(如圖中之紅色警示)。此外，當受測者自地板爬起後，
系統則可有效偵測並解除警報(如#1465畫面所示)。 
此外值得注意的是，當受測者進入及離開畫面時
(如畫面#350之前以及#1550之後)，由於目標團塊之外
型發生大幅度變化，此連帶常造成 Rs 或 qs 有波動過
大的情形發生；所幸，由於運動量化參數 MHIC 之導
入，使得此兩種極端情形不致被誤判為異常狀態。 
本實驗所使用之畫面解析度為 320 240´ ，在此條
件下系統平均處理速度皆可達30fps以上，故足以滿足
即時監控之需求。 
 
3.5 結論與成果自評 
本計畫之研究目的為提出一適合居家環境使用之
跌倒偵測系統。在毋須進行攝影機校正程序之前提
下，實驗結果證實本系統可有效區分一般日常活動與
跌倒動作間之差異，即時偵測跌倒事件之發生並適時
發佈危險警報。由於本系統以一般常見之網路攝影機
搭配具有適應性及強健性之背景建模與運動分析技術
實現影像監控功能，故其擁有價格低廉、易於建置以
及適合即時且長時間自動監控應用…等優點；因此，
本計畫研究成果已達成既定之研究目標。 
 
 
圖3.7 具USB介面之網路攝影機
 
200 400 600 800 1000 1200 1400 1600
0
50
100
150
200
250
m
aj
or
 a
 &
 m
in
or
 b
-50
0
50
100
150
200

200 400 600 800 1000 1200 1400 1600
0
0.5
1
1.5
C
M
H
I &
  R
# frame
0
20
40
60
 
 
圖3.8 目標物外觀及運動參數隨時間之演變 
 
 
 
   
 29
knowledge base for a mobile robot,” Int. J. Approx. Reason., vol. 
17, no. 4, pp. 447–469, 1997. 
[8] V. Matellan, C. Fernandez, and J. Molina, “Genetic learning for 
fuzzy reactive controllers,” J. Robot. Auton. Syst., vol. 25, pp. 
33–41, 1998. 
[9] H. Kawata, W. Santosh, T. Mori, A. Ohya and S. Yuta, "Develop-
ment of ultra-small lightweight optical range sensor system", 
IEEE/RSJ International Conference on Intelligent Robots and Sys-
tems (IROS2005), pp.3277-3282 , August 2005. 
[10] Safiotti, A, “Fuzzy logic in autonomous robotics: Behavior coor-
dination,” in Proc.6th IEEE Int. Conf. Fuzzy Systems, Barcelona, 
Spain, , pp.573–578, 1997. 
[11] E. Tunstel, T. Lippincott, and M. Jamshidi, “Behavior hierarchy for     
autonomous mobile robots: Fuzzy behavior modulation and evolu-
tion,”      Int.J. Intell. Automat. Soft Comput., vol. 3, no. 1, pp. 
37–49, 1997. 
[12] R. Bellman, Adaptive Control Processes, Princeton University 
Press, Princeton, 1966. 
[13] G. V. S. Raju, J. Zhou, and R. A. Kisner, “Hierarchical fuzzy con-
trol,”Int. J. Contr., vol. 54, no. 5, pp. 1201–1216, 1991. 
[14] L. X. Wang, “Universal approximation by hierarchical fuzzy sys-
tems,” Fuzzy Sets and Systems, vol. 93, no. 2, pp. 223-230, 1998. 
[15] H. Kawata, W. Santosh, T. Mori, A. Ohya and S. Yuta, "Develop-
ment of ultra-small lightweight optical range sensor system", 
IEEE/RSJ International Conference on Intelligent Robots and Sys-
tems (IROS2005), pp.3277-3282 , August 2005. 
[16] Safiotti, A, “Fuzzy logic in autonomous robotics: Behavior coor-
dination,” in Proc.6th IEEE Int. Conf. Fuzzy Systems, Barcelona, 
Spain, , pp.573–578, 1997. 
[17] E. Tunstel, T. Lippincott, and M. Jamshidi, “Behavior hierarchy for     
autonomous mobile robots: Fuzzy behavior modulation and evolu-
tion,”      Int.J. Intell. Automat. Soft Comput., vol. 3, no. 1, pp. 
37–49, 1997. 
[18] K. Kim , T. H. Chalidabhongse, D. Harwood, and L. Davis, “Re-
al-time foreground-background segmentation using codebook 
model,” Real-Time Imaging, vol. 11, pp. 172-185, 2005. 
[19] C. Stauffer and W.E.L Grimson, “Adaptive background mixture 
models for real-time tracking,” in Proc. Computer Vision and Pat-
tern Recognition Conf., 1999. 
[20] W. Zhang, F. Chen, W. Xu, and E. Zhang, “Real-time video intel-
ligent surveillance system,” in Proc. IEEE Int’l Conf. on Multime-
dia and Expo, pp. 1021-1024, Jul. 2006. 
[21] S. W. Joo and R. Chellappa, “A multiple-hypothesis approach for 
multiobject visual tracking,” IEEE Trans. On Image Processing, 
vol. 16, pp. 2894-2854, 2007. 
[22] A. Ilyas, M. Scuturici, and S. Miguet, “Real-time foreground- 
background segmentation using a modified codebook model,” in 
Proc. IEE Int’l Conf. on Advanced Video and Signal Based Sur-
veillance, pp. 454-459, Sep. 2009. 
[23] S. Park and M. M. Trivedi, “Understanding human interactions 
with track and body synergies (TBS) captured from multiple 
views,” Computer Vision and Image Understanding, vol. 111, pp. 
2-20, 2008. 
[24] Y. Miao, S. M. Naqvi, and J. Chambers, “Fall detection in the 
elderly by head tracking,” in Proc. IEEE Workshop on Statistical 
Signal Processing, pp. 357-360, 2009. 
[25] A. Ylisaukko-oja, E. Vildjiounaite, and J. Mäntyjärvi, “Five-point 
acceleration sensing wireless body area network-design and prac-
tical experiences,” in Proc. ISWC’04 Symp., pp. 184-185, 2004. 
[26] R. Cucchiara, C. Grana, M. Piccardi, A. Prati, and S. Sirotti, “Im-
proving shadow suppression in moving object detection with HSV 
color information,” in Proc. IEEE Int’l Conf. Intelligent Transpor-
tation Systems, pp. 334-339, Aug. 2001. 
[27] A. Hanbury, “A 3D-Polar coordinate colour representation well 
adapted to image analysis” Scandinavian Conf. on Image Analysis, 
pp. 804-811, 2003. 
[28] M. Kampel, H. Wildenauer, P. Blauensteiner, and A. Hanbury, 
“Improved motion segmetation based on shadow detection,” Elec-
tronic Letters on Computer Vision and Image Analy., vo. 6, pp. 
1-12, 2007. 
[29] A. Hanbury, “Constructing cylindrical coordinate colour spaces,” 
Pattern Recognition Letters, vol. 29, pp. 494-500, 2008. 
[30] K. V. Mardia, Statistics of Directional Data, Academic Press, Lon-
don UK, 1972. 
[31] C. Rougier, J. Meunier, A. St-Arnaud, and J. Rousseau, “Fall de-
tection from human shape and motion history using video surveil-
lance,” in Proc. IEEE Int’l Conf. Advanced Information Network-
ing and Appl., pp. 875-880, 2007. 
 
96年度專題研究計畫研究成果彙整表 
計畫主持人：洪欽銘 計畫編號：96-2221-E-003-011-MY3 
計畫名稱：居家型護理機器人系統設計--總計畫：居家型護理機器人系統設計 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 4 4 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 1 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
