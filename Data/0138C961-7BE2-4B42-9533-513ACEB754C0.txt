 L*
a*
centroid
b*
 
Figure 1. MRCR sphere in a uniform color space 
proposed by Eastman Kodak Company uses 
features based on red-eye defects to 
automatically detect only a pair of red-eyes in 
each image [1].  In [2], the face must be 
successfully detected before the red-eye 
detection where the information of color, 
intensity and dimension is utilized.  In [3], a 
learning-based face detector is also adopted for 
the detection of red-eye defects.  In these 
approaches, the face detection itself is another 
challenging problem to be solved [5].  In [4], a 
heuristic algorithm is used to detect candidate 
red-eye regions, and then an eye classifier is 
utilized to confirm whether the candidate 
region is a red-eye. 
 
 
Figure 2. The set of representative red-eye colors 
A fully automatic red-eye detection and 
correction algorithm is therefore needed, such 
a method can be combined with a red-eye 
reduction algorithm to automatically reduce 
this artifact. Furthermore, it is highly expected 
that this automatic algorithm can be realized as 
a piece of hardware and planted in digital 
cameras. Recently, a number of researches on 
automatic red-eye detection and correction 
have been conducted.   
Our algorithm is based on CIE Lab Color 
Space. We create a novel color filter that is 
developed to locate regions of major colors 
including red-eye color and skin tone. The 
geometric relationship between the dimension 
of the human pupil and binocular distance is 
employed to eliminate false positives at large. 
 
2. RED-EYE DETECTION 
From the statistical analysis of large data 
sets we can gets the red-eye and skin color 
distributions in CIE Lab color space. To 
determine the thresholds for each component 
(a and b), skin regions and red-eye regions 
need to be manually extracted from a set of 
training images. Images acquired by different 
sources: digital cameras, web etc. 
For each pixel in the picture, if the Lab 
value of the pixel satisfies the following 
condition, it will be marked as red-eye color 
pixels. 
⎪⎩
⎪⎨
⎧ >
50~25- : b
  80~20 : a
       30  L
                           (1) 
Because all following procedures will be 
processed based on this step, these constraint 
are loose in order to fit most cased of 
photographs and guarantee most pixels in a 
red-eye will be preserve. 
Otherwise, if the Lab value of the pixel 
satisfies the following condition, it will be 
marked as skin color pixels. 
⎪⎩
⎪⎨
⎧ >
  25~5- : b
  20~5- : a
       30  L
                           (2) 
Skin color is reference information, it can be 
help us eliminate false positives candidates. 
 
2.1. Major Red-Eye Color Region 
The set of representative red-eye colors 
obtained by k-means clustering, R. Using these 
centroids, we can defined major red-eye color 
regions (MRCR) by major red-eye color 
difference (MRCD) in uniform color space. 
We can calculate the red-eye centorids from 
the large data sets of our collected. In this 
paper, we set the number of centroids is 32 
(Figure 2).  If the length of color difference 
between centroid and test pixel is smaller than 
major red-eye color difference (MRCD), the 
test pixel should preserves. 
 
R1 > 4Dw                        
          (5) 
R2 < 10Dw                      
               
In fact, the red-eye candidate is detected, it 
smaller than original red-eye size.  In 
previous process including color filtering 
and noise reduction, a part of red-eye pixels 
will be lost.  Then binocular geometric 
constraint is bigger than previous section. 
2. Test if the dimension of the high-probable 
red-eye’s pupil ratio satisfies pupil ratio 
constraint.  The dimension of pupil ratio 
constraint as 
0.75  D≦ w2 / Dw1  1.3≦                    (6) 
0.75  D≦ h2 / Dh1  1.3≦                          
We can find a pair of red-eye candidate that 
if all conditions are satisfied. 
 
2.4. Eliminate False Positive Candidates 
In this part, we test the candidate red-eye 
region is surrounded by pixels of skin tones in 
a larger area.  In figure 7 the surrounding 
pixels in a search area depend on candidate’s 
width and height, the region with 1.5Dh*3Dw 
pixels are checked for each region.  If there are 
enough non-skin pixels marked in Section 2. 
In search area, then the candidate will be 
removed.  The criterion of skin color pixel is 
 
Dw
Skin Color 
Search 
Area
Dw
Skin Color 
Search 
Area
1.5Dh
1.5Dh
3Dw
red-eye 
candidate
 
Figure 7. Binocular geometric constraint 
       
 
…
2 4 6 8 … N
…
2
4
6
8
10
N
…
      (a)              (b) 
Figure 9 The inspection of red-eye with shape of 
convex hull. 
 
Dw
Dh
Dw
Dw
Dh
Dh
Search area
       
 
Dw
Dh
Dw
Dw
Dh
Dh
Search area
  (a)         (b) 
Figure 8. Example of recover red-eye color pixels
(a) before (b) after 
 
8.0/ >rk SS (7) 
here Sk is the quantity of skin color pixels 
in search area.  Sr is the total pixels in search 
area. 
 
2.5. Recover Red-Eye Color Pixels 
In the previous steps, a lots of false positive 
red-eye candidates are removed.  The red-eye 
color pixels are loosed by previous process 
including rough red-eye color filtering, precise 
red-eye color filtering (MRCR) and 
morphological processing.  The recover red-
eye color pixel is needed.  In this step, each 
candidate region is extended, we can find 
losing red-eye pixels in search area.. 
In this step, each candidate bounding box is 
extended, we enlarge the bounding box by 3 
times, one pixel by one pixel, to form precise 
red-eye region.  The red color pixels, which 
are selected by rough color filtering and have 
similar red color, will be extended as a part of 
the red-eye candidate. 
 
2.6. Elimination of False Positive 
Candidates by Convexity Test 
To further increase the accuracy, the shape 
of each red-eye candidate is inspected if it is a 
convex hull (Fig. 9). 
The shape of red-eye candidate is 
considered as convex hull, if following 
condition is satisfied: 
 (8) 
where LN denotes the number of non red-eye 
pixels between the first and the last pixel of 
red-eye in each even row (or even column).  LT 
3.0/ <TN LL
