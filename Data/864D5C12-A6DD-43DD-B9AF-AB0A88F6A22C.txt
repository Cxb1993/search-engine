 2
摘要 
傳統的遠距醫療監測作法是將聲音或影像傳回
監測站，再由監視人員做判斷，這不但會影響病人
的隱私權，也會增加醫療人員的負擔。而現代社會
交通事故、公安事故等意外頻傳，加上老年人口比
例增加，使得醫療人員工作量越來越大，社會上對
醫療看護的需求也越來越急迫。 
目前已被應用在許多領域的無線感測網路，對
聲音的感測應用還不是很普遍，因此本計畫提出的
作法是以無線感測網路為傳播管道，將感測器收集
到的聲音，利用音訊處理技術做聲音特徵值的擷
取，並在感測器端先行比對，再將結果傳回伺服器
端進一步確認，並記錄結果與通知醫療人員做處
理，藉此避免侵犯病患的隱私，同時達到降低護理
人員工作量的目的。 
關鍵字：遠距醫療監測、無線感測網路、聲音特徵
擷取、聲音比對 
Abstract 
Medical telemonitoring in the past is that the 
audio and the video are sent to end monitoring station, 
then nursing staff diagnoses it. It will infringe upon 
patients’ private rights, and increase nursing staff’s 
workload. As traffic accidents, public security 
accidents and population of old people increase, 
amount of work of nursing staff is heavier. 
Wireless sensor network (WSN) is already 
applied to many fields, but it’s not common that WSN 
is applied to sound detection. In this project we 
propose that based on WSN, sound is detected, 
extracted features and identified in the side of sensor, 
then result of comparison is sent to end server for 
advanced identification. Finally it records the results 
and notifies nursing staff. 
Keywords：Medical telemonitoring, Wireless sensor 
network, Audio features extraction, Audio comparison 
1. 前言 
無線感測網路 [1](Wireless Sensor Network, 
WSN) 是指由數個至數千個的感測器 (Sensor) 以隨
機分佈的方式搭配可移動式基地台 (Base Station) 
所組成的網路系統所構成的網路系統[18][28]，由
於科技發展日新月異，電子產品的體積也越來越
小，而且又需要考量如何降低產品成本，因此低成
本、有著用了即丟的便利性之無線感測網路就成為
目前熱門的研究項目。 
感測器與基地台之間和感測器彼此之間的通訊
方式是採用無線通訊方式[23][38]。由於其能自行
建置一個無線網路環境，能方便地將需觀測的資料
收集回伺服器端來加以分析運用，如此大幅降低了
人工收集資料或建置大型固定式網路的成本。 
目前已開發的感測器種類相當多，能支援感測
溫濕度、聲音、影像等環境資料，無線感測器網路
已漸漸從一開始的軍事應用，朝向其他領域做多元
化的發展，從監測應用到軍事用途都有[38]：例如
偵測某種特定生物的存在與否、感測人員出入活動
的保全偵測、危險橋樑的監測控管等[1][22]。 
在無線感測網路的應用研究中，對於溫濕度之
收集及回報已有廣泛的討論，但對音訊的處理則尚
未有深入的探討，傳統的作法僅將感測到的資料傳
送至伺服器處理。但由於無線傳輸所耗費的電力往
往是感測器內部運算電力耗損的千倍以上[11]，如
此把大量的音訊資料傳送至伺服器端將會很快耗盡
感測器的電池電力[10][23]。較理想的作法是利用
感測器的運算能力，先在感測器端做音訊資料的分
析，並判斷資料是否需回傳；另外感測器的記憶體
大小與運算能力不強大，傳統的音訊處理 (如聲音
辨識) 技術無法直接移植到感測器中，因此本研究
必須對感測器的音訊處理能力及相關的應用作進一
步的研究與探討。 
一般醫療照護需要醫療人員在病患身旁或不遠
處進行照顧，對醫院人力調度支援上需花費相當高
的成本[21]；另外一種醫療照護作法是使用攝影機
 4
空分佈情況而繪製成的等高線圖，來取代簡單的門
檻值，在某個時間點的感測器讀數與先前設立的參
數相符時，即表示事件發生[6][24]。在感測器上使
用感測資料庫系統，於收集到感測資料時先行在感
測器上進行判斷，萃取出有用的資訊後才將資訊傳
遞給其他感測器或基地台，也是一個節省電力的方
法[25][26]，如 TinyDB[27]與 TAG系統[28]。 
2.2音訊辨識技術 
聲音訊號 (Audio Signals) 指的是人所能聽到的
各種聲音的訊號[14]，以電腦技術處理聲音訊號，
就叫做音訊處理 (Audio Signals Processing)。聲音
在空氣中傳播，經過了麥克風之類的收集轉換器，
會轉變成電的訊號，再經過類比轉數位轉換器，就
會變成數位的表達方式，這時才能將數位訊號拿來
作進一步的分析處理。目前音訊處理的應用技術有
語音編碼、語音合成、語音辨認[8][35]等，另外在
語言教學、去除噪音、比對聲紋[7]、門禁保全系
統[36]，也都是目前音訊處理的應用領域。 
一般聲音有幾個物理上的特性：音量 
(Volume)、音高 (Pitch)、與音色(Timbre)[14]。音量
代表的是聲音的強度，也叫做能量 (Energy)，通常
音量越大，訊號振幅也越大；音高是訊號振動的頻
率，音高較低，聲帶的振動也越緩慢，而此頻率指
的是基本頻率 (Fundamental Frequency)，也就是基
本週期 (Fundamental Period) 的倒數[5]，通常在分
辨聲音特徵時，主要是看聲音的音高有無不同；音
色是聲音的特質，主要受到發聲器官、共鳴器不同
的影響。 
聲音訊號是一種隨時間變化 (Time Varying) 的
訊號，波形的變化非常快速，但如果將訊號以短時
間來觀察，可以發現聲音的變化是很穩定的，因此
在處理聲音訊號前通常會先將聲音切割成一個個小
單位，以便找出訊號的週期或規律變化[37]。若音
框切割的太大，無法看出音訊隨時間變化的特性；
反之，若音框太小，也無法得到音訊的特性，通常
音框要能包含幾個音訊的基本週期。 
聲音分類的工作可分成兩部分，先對觀測到的
聲音訊號進行特徵擷取，再將擷取出來的特徵向量
傳給分類器進行分類[2][30]。在分類語音樣本的技
術中，最常使用的是高斯混合模型  (Gaussian 
Mixture Models, GMM)[27]、隱藏馬可夫模型 
(Hidden Markov Models, HMM)[25]，及 K近鄰 (K-
Nearest Neighbor, KNN) 演算法[9]。 
擷取音訊特徵通常有下列步驟[13]：將音訊切
成一個個音框；求取音框的特徵，如過零率
[29][31]、音高[34]、線性預估編碼 (Linear Predict 
Coding, LPC)[26]、梅爾倒頻譜係數 (Mel-Frequency 
Cepstral Coefficients, MFCC)[12][19]、自相關函數
(Autocorrelation Function, ACF)[5]等；根據特徵
值，進行端點偵測 (Endpoint Detection)[35]，並保
留特徵資訊，以便進行分析。 
過零率 (Zero Crossing Rate, ZCR) 的定義是每
個音框中，訊號通過零點的次數，其具有下列特性
[29][31]：雜訊及氣音的過零率比有聲音大；常用
在端點偵測，尤其是用在預估氣音的開始點和結束
點；可用來預估訊號的基頻。若將聲音用聲譜圖來
表示，運用聲音特性作為分離聲音之依據，如基
頻、起始時間 (onset time/offset time) 等，將相同音
源的頻率找出，就可分析出有何種聲音及聲音音高
[4]。 
自相關函數 (ACF)[5]可用來區分規律音與非規
律音，因為規律音的 ACF 能量值會比非規律音
高。計算方式為將音框每次向右平移一小段時間單
位，再與原本音框的重疊部分做內積，重複 n次後
會得到 n個內積值。 
但由於重疊的波形越來越短，因此 ACF 的曲
線會呈遞減狀態，為了避免此種情況，可以求取正
規化的 ACF，或只對音框的前半部進行平移。正
規化即是將重疊部份的內積再除以重疊的點數，但
這會造成計算量變大，且曲線容易呈現不穩定的情
況；而只對音框的前半部進行平移，雖然得到的曲
 6
 
圖5  使用moteview的觀測結果
至於在 imote2上的資料傳輸主要是採用IEEE 
802.15.4 的規格，頻帶為2.4GHz，以 Multi-hop 的
方式傳送資料回伺服器，若感測節點與伺服器端的
根節點的距離超過可傳輸距離，感測節點會自動尋
找另一個節點當作轉傳的收發站，用接力的方式，
來達成不同節點的通訊目標，如圖6。 
圖 6  感測器傳遞資料的路線示意圖 
同樣地在 PDA 等行動通訊裝置上，也會安裝
聲音偵測軟體，紀錄觀測聲響是否發生變化，圖 7
顯示的即為在桌上電腦執行的 PDA 模擬器，在觀
測到周遭聲響有變化時，畫面會顯示出大於 128的
數值 (無聲時為 128)。 
在無線通訊方面確立的過程，同時也進行聲音
訊號辨識的研究，如第二小節所示。 
3.2聲音處理演算法 
聲音的儲存格式有 mp3、wav、mid 等，在本
研究中以 wav檔作為主要的研究聲音來源，wav檔
以 PCM 的編碼格式儲存聲音，用固定的取樣頻
率，在每個取樣點以固定位元數表示聲音的波型變
化，能保存較正確的聽覺感受。 
 
圖 7  PDA模擬器偵測到聲響 
雖然一整段聲音不容易分辨其聲音特徵，但若
將聲音切割成數個小單位的音框 (Frame)，再透過
目前已應用在聲音處理技術的演算法，即可判斷出
該聲音的特徵值。本研究中可依情況自訂要切割的
音框長度與彼此間的重疊大小，在去除掉 wav 檔
的檔頭 (Header) 後，讀入 wav 檔內的實際聲音資
料。接下來將切割後的音框乘上漢明窗，強調音框
中間的聲音並減少音框邊緣的不連續。然後計算出
每個音框的特徵值，如音量、過零率 (ZCR)等。用
來計算音框內音量 )(nEx 與過零率 )(nZ x 的公式如
下： 
∑= 210 )(log*10)( nxnEx ，
∑ −−= )]1(sgn[)](sgn[211)( nxnxNnZ x ； 
 8
究計畫在伺服器端會建立一個病徵資料庫，以提供
醫療照護人員查詢使用，如圖8，使醫生診斷時有
充分的資料，以提高醫療及照護品質。 
 
圖8  伺服器端查詢介面 
4. 實驗與討論 
在本研究計畫裡，採用了一般音訊處理的技
術，如切割音框、乘上漢明窗、快速傅立葉轉換
等，並擷取出音訊特徵，如過零率、音量、音量差
異總和函數，如圖9所示，最後再使用高斯混合模
型、最大可能性估算法來比對接收到的聲音是否為
咳嗽聲。 
 
圖9  音訊特徵擷取介面 
而本研究中也加入了新的判別依據：一般來
說，在發生嚴重咳嗽聲時，患者往往會連續發出
「咳」的聲音數次，如「咳咳～咳咳咳咳～咳咳咳
～」，而人交談間的對話語句則通常不會一直重複
某個詞，因此利用這樣的差異性，在系統中增加了
這種差異的辨識演算，如果發現同一種或類似的聲
音特徵，連續重複出現了五六次，則可能是嚴重的
咳嗽聲，改進了原本只是單純使用音訊特徵來比對
的正確性。在最後的驗證階段裡，針對辨識正確程
度加以驗證，最後實驗結果以Recall-Precision曲線表
示之，如圖10所示。而本研究也針對感測器在面對
接收到的聲音的處理方式不同：完整地將聲音傳回
與 (Unprocessed)，及先處理過後再將聲音傳回
(Processed)，分別記錄其感測器電池耗電量的不
同，如圖11所示。 
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100
%
Recall
Pr
ec
isi
on
 
圖10  平均Recall-Precision曲線圖 
0.00%
20.00%
40.00%
60.00%
80.00%
100.00%
120.00%
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
Time (week)
Po
we
r Processed
Unprocessed
 
圖11  兩種方案的耗電程度 
在實際的應用裡，我們將這整個系統建置在行
動通訊裝置裡，利用行動裝置裡內的處理器加以運
算，先將接收到的聲音予以存檔，再將存檔讀出，
使用系統擷取特徵等參數，最後比對是否為所要觀
察的病患咳嗽聲。 
 
 10
[16] Madden, S., Franklin, M.J., Hellerstein, J.M., & 
Hong, W., “TAG: a Tiny A Ggregation Service 
for Ad-Hoc Sensor Networks,” In OSDI, 2002. 
[17] Madden, S., Franklin, M.J., Hellerstein, J.M., & 
Hong, W., “The design of an acquisational 
query processor for sensor networks,” In 
SIGMOD, 2003. 
[18] Mainwaring, A., Polastre, J., Szewczyk, R., Culler, 
D., & Anderson, J. (2002). Wireless Sensor 
Networks for Habitat Monitoring. Proceedings of 
the 1st ACM International Workshop on Wireless 
Sensor Networks and Applications. 
[19] Mammone, R. J., Zhang, X., & Ramachandran, R. 
P. (1996). Robust speaker recognition:A feature-
based approach. IEEE Signal Processing 
Magazine, 3(5), 58-71. 
[20] Manjhi, A., Nath, S., & Gibbons, P.B., 
“Aggregation Query over Sensor Network Stream 
-- Tributaries and Deltas: Efficient and Robust 
Aggregation in Sensor Network Streams,” 
SIGMOD, 2005. 
[21] Mea, V.D. (2001). Agents acting and moving in 
healthcare scenario-a paradigm for telemedical 
collaboration. IEEE Trans. Inf. Technol. Biomed. 
5(1), 10-13. 
[22] Nath, S., Gibbons, P.B., Seshan, S., & Anderson, 
Z., “Synopsis diffusion for robust aggregation in 
sensor networks,” In SenSys, 2004. 
[23] Pottie, G. J. (1998). Wireless sensor networks. 
IEEE Information Theory Workshop, 139-140. 
[24] Pottie, G., & Kaiser, W. (2000). Wireless 
integrated network sensors. Communications of 
the ACM, 43(5), 51-58. 
[25] Rabiner, L. R. (1989). A Tutorial on Hidden 
Markov Models and Selected Applications in 
Speech Recognition. IEEE Transactions on ASSP, 
77(2), 257-286. 
[26] Rabiner, L. R., & Juang, B. H. (1993). 
Fundamental of speech recognition. Prentice Hall 
International, New York. 
[27] Reynolds, D. A., & Rose, R. C. (1995). Robust 
text-independent speaker identification using 
Gaussian mixture models. IEEE Transactions on 
Speech and Audio Processing, 3(1), 72-83. 
[28] Ruiz, L. B., Nogueira, J. M., & Loureiro, A. 
(2003). MANNA:A Management Architecture for 
Wireless Sensor Networks. IEEE Communication 
Magazine, 41(2), 116-125. 
[29] Scheirer, E., and Slaney, M. (1997). Construction 
and evaluation of a robust multifeature 
speech/music discriminator. ICASSP, IEEE 
International Conference on Acoustics, Speech 
and Signal Processing, 2, 1331-1334. 
[30] Soong, F. K., Rosenberg, A. E., Rabiner, L. R., & 
Juang, B. H. (1985). A vector quantization 
approach to speaker recognition. Proceeding of 
IEEE ICASSP, 387-390. 
[31] Tzanetakis, G., and Cook. P. (2002). Musical 
genre classification of audio signals. IEEE 
Transactions on Speech and Audio Processing, 
10(5), 293-302. 
[32] Wang, A., & Chandrakasan, A. (2002). Energy-
Efficient DSPs for Wireless Sensor Networks. 
IEEE Signal Processing Magazine, 19(4), 68-78. 
[33] Wang, X., and Qi, H. (2002). Acoustic target 
classification using distributed sensor arrays. 
IEEE International Conference on Acoustics 
Speech and Signal Processing, 4, 4186. 
[34] Wrigley, S. N., Brown, G. J., Wan, V., & Renals, 
S. (2005). Speech and crosstalk detection in 
multichannel audio. IEEE Transactions on Speech 
and Audio Processing, 13(1), 84-91. 
[35] Wu, B. F., & Wang, K. C. (2005). A Robust 
Endpoint Detection Algorithm Based on the 
Adaptive Band-Partitioning Spectral Entropy in 
Adverse Environments. IEEE Transactions on 
Speech and Audio Processing. 13(5), 762-775. 
[36] Wu, C. H., & Chen, J. H. (1997). Speech 
activated telephony email reader (SATER) based 
on speaker verification and text-to-speech 
