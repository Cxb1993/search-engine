previous works lacks of considering a critical 
problem, called ’the density divergence problem’, 
which refers to the phenomenon that the region 
densities vary in different subspace cardinalities. 
Without considering this problem, previous works 
utilized a density threshold to discover the dense 
regions in all subspace, which incurs the serious 
loss of clustering accuracy in different subspace 
cardinalities. Therefore, in this project, we 
investigated the crux of this issue and proposed an 
efficient algorithm DENCOS to solve the problem. 
DENCOS adopts a divide-and-conquer scheme to 
efficiently discover clusters satisfying different 
density thresholds in different subspace 
cardinalities. As validated by our extensive 
experiments on various data sets, DENCOS can discover 
the clusters in all subspaces with high quality, and 
the efficiency of DENCOS outperforms previous works. 
Moreover, we first study an important but unsolved 
dilemma in the literature of subspace clustering, 
which is referred to as ’information overlapping-
data coverage’ challenge. We propose an innovative 
algorithm, called ’NOnRedundant Subspace Cluster 
mining’ (NORSC), to efficiently discover a succinct 
collection of subspace clusters while also 
maintaining the required degree of data coverage. 
NORSC not only avoids generating the redundant 
clusters with most of the contained data covered by 
higher dimensional clusters to resolve the 
information overlapping problem but also limits the 
information loss to cope with the data coverage 
problem. As shown by out experimental results, NORSC 
is very effective in identifying a concise and small 
set of subspace clusters, while incurring time 
complexity in orders of magnitude better than that of 
previous works. 
英文關鍵詞： Data Mining, High-dimensional Data, Data Clustering, 
Subspace Clustering 
 
行政院國家科學委員會專題研究計畫成果報告 
高維度與空間資料之叢集資料探勘 
Advanced Clustering for High-Dimensional and Spatial Data with 
Concept Drifting 
計畫編號：NSC 97-2221-E-002-172-MY3 
執行期間：97 年 8 月 1 日至 100 年 7 月 31 日 
主持人：陳銘憲教授 國立臺灣大學電機工程學系暨研究所 
摘要 
近年來，隨著網際網路的蓬勃發展，資訊流通頻繁，使得累積的資料量大幅增加。在資料
探勘領域中，叢集技術可以有效地將大量的資料分群，使得使用者可以快速地從分群資料
中獲取所需的知識。隨著行動裝置設備普及，資料來源顯得多元化，使得資料庫中高維度
資料之比例日益增加。但在高維度資料中，並非每個維度對於每筆資料皆有意義。許多無
意義的資料欄位，將讓資料無法在所有維度形成的空間中群聚，使得傳統之叢集分析技術
在高維度資料中不易進行有效地資料分群。因此，在執行本計畫中，我們探討了高維度資
料叢集之研究議題，並發展新的叢集技術。子空間叢集為目前極具挑戰性的研究議題，主
要是著重發掘子空間之叢集。大部份先前的研究是屬於以密度為主(density-based)的方法。
然而，先前之研究在辨識密集區域缺法考慮一個極重要的問題，即密度分歧問題(density 
divergence problem)。在沒有考慮這個問題情況下，先前的研究會導致叢集正確性嚴重地下
降。為了克服這個問題，我們提出一個演算法，稱為 DENCOS(DENsity Conscious Subspace 
clustering)，是採用分治法(divide-and-conquer)的方式在不同的子空間下有效地發現有意義
的叢集。我們所設計得 DENCOS 演算法可以在所有的子空間中發現具有高品質的叢集，且
與目前學界所提出的方法相比擁有較好的效率。然而在所有子空間執行叢集演算法容易導
致不同群集資料重複之問題。在本計畫中，我們亦設計一個演算法，稱為
NORSC(NOnRedundant Subspace Cluster mining) ，用來解決高維度空間之叢集方法之資訊
重複(Information Overlapping)問題並確保可以減少資訊流失(Information Loss)。我們的實驗
結果顯示 NORSC 可以有效地找出子空間之叢集，並可增進叢集演算法之執行效率。 
 
關鍵詞：資料探勘、高維度資料、叢集演算法、子空間叢集演算法 
英文摘要(Abstract) 
With the ubiquitousness of Internet technologies, the amount of data created and exchanged 
grows rapidly. In data mining, clustering techniques can effectively partition the data into 
multiple groups such that users can find the required knowledge with no delay. As the increasing 
似。由於在高維度下缺乏距離鑑別度，要發掘有意義且分開之叢集便成為一項重大的挑戰。 
  為了克服資料探勘所面臨之維度災難問題，常見的方法就是利用特徵轉換和特徵選擇[17]
之技術來減少資料維度。特徵轉換技術，例如主成分分析(principal component analysis)和奇
異值分解(singular value decomposition)，是透過結合原來資料之特性而以較少維度來總結資
料。然而轉換過的特徵或維度不再具有直覺意義，造成要解釋或分析所得到之叢集變得相
當困難[18]。另一方面，特徵選擇方法[19][20]，試著從原來資料特性中選擇最相關之特性
來減少資料的維度，採用這種方式將只選擇一個特定子空間來發掘叢集。然而在許多真實
資料中叢集可能隱含在各種子空間中，特徵選擇方法將會遺失在不同子空間下資料叢集的
資訊[18]。因此，子空間叢集(subspace clustering) ，其目的在發掘原先的資料空間下所有子
空間所隱含之叢集，近來受到很多研究學者注視。如何在龐大的子空間進行有效且快速的
叢集分析是一個極重要的課題。 
  子空間叢集的技術會發掘大量的叢集，然而大部份的叢集都具有類似的叢集行為。過去
的研究[21][22][23][24]利用 grid-based 的方式來辨識子空間內的密集區域。在這種情況下，
單調(monotonic)的特性會使得這個方式產生多餘的叢集結果。因為一個密集的區域，其投
射到較低維度子空間的區域也會被視為密集，將回報太多重疊資訊給使用者，造成使用者
必須花費額外的時間來過濾叢集結果。我們認為一個扼要且容易被了解的報告比起包含一
堆叢集的報告更符合使用者的需求。因此，如果找出非多餘的子空間叢集也是另一個極為
重要的課題。 
貳、 研究目的 
  對於高維度之資料，由於資料欄位數量增加，造成資料特性更趨複雜。因此，設計一個
適當更有效率的資料叢集分析技術便十分重要，亦具備相當之挑戰性[13][15][16]。其主要
原因在於高維度的資料中，並非所有維度均對於每筆資料皆有意義。許多無意義的資料欄
位，將使得資料無法在所有維度所形成的空間中群聚，此情況造成傳統叢集分析技術無法
在高維度資料中，進行有效之資訊分群。因此，在本計畫中，我們發展一個新型態的子空
間資料叢集技術來對高維度資料進行分析，對於每個子空間設計了不同的門檻值，且提出
一個新的資料結構來記錄每個子空間內資料的分佈情況，並有效地從資料中挖掘出有意義
的子空間叢集。此外，我們也設計一個演算法來發掘非多餘的子空間叢集，可快速且有效
地發掘有意義之子空間叢集，期望能提供使用者更有意義之資訊。 
參、 文獻探討 
  我們可以根據是否使用格子結構將先前的研究分為兩大類。演算法 CLIQUE[21]和其後繼
演算法 ENCLUS[22]、MAFIA[23]即為子空間叢集之第一類方法，且皆為以格子為主之演算
法。在 CLIQUE 中，會先將資料空間切割成一樣大小的單元(格子)。接著 ，將相鄰密集單
元(即單元之密度超過一門檻值)聚集成為子空間叢集。然而對所有之子空間採用單一絕對之
單元密度來發掘密集單元，使得 CLIQUE 很難得高品質之子空間叢集。因為在不同的子空
間中單元密度會隨著變化，所以在所有子空間採用單一絕對單元密度門檻值會使得密集單
元辨識面臨 precision 和 recall 之取捨。 
  此外，演算法 ENCLUS[22]延伸 CLIQUE 並且透過子空間熵(subspace entropy)來選擇有興
趣之子空間來發現叢集，以增加叢集過程的速度。然而在 ENCLUS 採用了跟 CLIQUE 一樣
的叢集模組來發掘叢集，因此 ENCLUS 無可避免地將面臨密度分歧之問題。另一個 CLIQUE
Procedure GenerateInherentDenseUnits:
Input: a DFP-tree node: n,  Output: the inherent dense units 
3
4
5
2
for each child node nc of node n
1 Calculate the cardinality k(n) for node n such that 
if ( k(n) > kmax ) return;
Call the procedure GenerateOneNodeDenseUnit(n, k(n)); //Generate dense units for n
                
Procedure GenerateOneNodeDenseUnit:
1 Let      be the 1-dimensional unit carried by ni
2 //Generate dense units of cardinalities in [k(ni), kmax]
3
4
        }else{
5
in
u
6
        if ( k(nj) < k(ni) ) {        
        Call the procedure GenerateInherentDenseUnits(nc);
1)()( .  nknk countn 
Input: a DFP-tree node ni, the cardinality k(ni),   Output: the dense units related to node ni
                 for each k with 
maxkk)k(ni 
                      Output the k-dimensional dense units generated by concatenating     
in
u
1k
n j
I
                 for each k with 
                      Output the k-dimensional dense units generated by concatenating      
max1 kk)k(ni 
in
u
1k
n j
I
                 Output the k(ni)-dimensional dense units by first generating            ,
1)( i
j
nk
nIinu
1)( i
j
nk
nI
        }
for each prefix node nj of ni{
7
8
10
}
                       with each (k-1)-dimensional dense unit in        ; 
                        with each (k-1)-dimensional dense unit in        ;  
                 and then concatenating       with the units in           ; 
11
12
9
 
Procedure GenerateAcquiredDenseUnits:
Input: DFP-tree: Tree,  Output: dense units
3
4
5
2
1 for each entry h in the header table of Tree {
                 
6
7
8
10
11
12
13
14
15
        Let uh be the 1-dimensional unit carried by entry h
        Let cardList be the buffer to store the subspace cardinalities with surplus counts not
        Let cardS and cardL be the smallest and largest cardinalities in cardList
        //Setup cardList, cardS , cardL
        cardS=kmax; cardL=2;
        for each subspace cardinality k from 2 to kmax {
                 if(                 ){
                          insert k into cardList
                          if ( k < cardS) cardS=k;
                          if ( k > cardL) cardL=k;
                 }
        }
k
k
uh
SC 
        if (cardList =    )
                 continue; //go to next header entry
16
17
18
19
        Setup            by following the node links of uh;S
h
card
uP
        Construct the DFP-tree                on
        Call procedure MineDenseUnits(                                                              )
}
S
h
card
uP
S
h
card
uTree
h
card
uL
card
uh uPcardcardListTreeu
S
h
S
h
,,,,,
Procedure MineDenseUnits:
Input: (BaseUnits: B, DFP-tree: Tree, cardList, cardL, PathSet: PSet, Units: u) Output: dense units
3
4
5
2
1 for each entry    in the header table of Tree {
6
7
8
9
10
11
12
13
14
15
        Let      be the 1-dimensional unit carried by entry 
        Let I denote the unit by joining      with B (i.e.,                    ),  and let |I| be the cardinality of I
        if ( |I| is not in cardList ){
                 if ( |I|==cardL )
                          Return;
                 Extract   ‘s conditional pattern base from Tree by following  ‘s node links
                 Construct a DFP-tree,            , on  ‘s conditional pattern base, where the 1-d units 
                 MineDenseUnits(                                                       ); //Recursive mining
        } else {
                 Set the count value of I, denoted as count(I), to be the unit count stored in entry
                 if (                       )
                           Output I as a dense unit;
                 if ( |I|==cardL )
                           Return;
16
17
18
19                  //Do path removal
hˆ
huˆ hˆ
huˆ BuI h  ˆ
huˆ huˆ
hu
Treeˆ huˆ
Lcard

uPSetcardcardListTreeI Luh ,,,,, ˆ
hˆ
||)( IIcount 
                 Extract   ‘s conditional pattern base from Tree by following  ‘s node links
huˆ huˆ
                 if (   ‘s conditional pattern base is empty )huˆ
                           Return;
20
21
22
23
24
25
26
27
28
29
                 Let cardnext denote the next cardinality to discover dense units, which is the smallest
                 Let PathList be the buffer for storing paths to be removed from ‘s conditional pattern basehuˆ
                 Identify the paths in PSet, whose count values are smaller than      but are larger than or 
||I
nextcard

                 Let      be the unit by removing the unit u from I;
uI
                 Delete the paths in PathList, which do not contain     ; //path exclusion

uI
                 for each path p in PathList{
                            //Path reorganization, to re-organize the path p to the form it appears in  ‘shuˆ
                            Delete the nodes in p which are positioned below      in the header table of Treehuˆ
                            if ( p is not empty ){
30
31
32
33
34
35
36
37
                                      Sort the nodes in p according to the unit order in the header table of Tree
                                      Remove p from  ‘s conditional pattern base; //perform path removalhuˆ
                            }
                 }
                 Construct a DFP-tree,            , on  ‘s conditional pattern base, where 1-d. units with
hu
Treeˆ huˆ
Lcard

                 if (           is not empty )
hu
Treeˆ
                            MineDenseUnits(                                                      ); //Recursive mininguPSetcardcardListTreeI Luh ,,,,, ˆ
        }
}
        satisfying thresholds
                 with total counts below          are removed
9
                 cardinality larger than |I| in cardList
                 equal to           , and insert them into PathList
                            // conditional pattern base
                 total counts below         are removed
 
圖一發掘固有之密集單元程序                    圖二發掘習得之密集單元程序 
100%
99.44 %
90.28%
100%
90.28%
100%
Dim. 5
100%
26.28 %
78.16%
100%
89.17%
100%
Dim. 5
Dim. of subspace cluster
Recall
Precision
Recall
Precision
Recall
Precision
97.82%100%100%
8.17%99.86 %97.96%
SUBCLU(4)
26.08%100%100%
100%100%100%
CLIQUE(4)
50.73%89.43%100%
100%100%100%
DENCOS
Dim. 6Dim. 5Dim. 4
    
0
0 . 5
1
1 . 5
2
2 . 5
3
C L I Q U E
    ＝0.4
CLIQUE
   ＝0.15
D
R
 
g
a
in
k = 1 k = 2 k = 3
k = 4 k = 5
( a )     C o m p a r e d  w i t h  C L I Q U E  
o n  A d u l t  d a t a s e t
( b )    C o m p a r e d  w i t h  C L I Q U E  
o n  T h y r o i d  D i s e a s e  d a t a s e t
( c )     C o m p a r e d  w i t h  S U B C L U  
o n  A d u l t  d a t a s e t
( d )     C o m p a r e d  w i t h  S U B C L U  
o n  T h y r o i d  D i s e a s e  d a t a s e t
τ
0
0 . 5
1
1 . 5
2
2 . 5
3
S U B C L U
m = 1 0 0 0 0 ,      = 5
S U B C L U
m = 7 0 0 0 ,      = 5
D
R
 
g
a
in
k = 1 k = 2
k = 3 k = 4
0
1
2
3
4
5
6
C L I Q U E
    ＝0.4
CLIQUE
    ＝0.15
D
R
 
g
a
in
k = 1 k = 2 k = 3
k = 4 k = 5 k = 6
0
1
2
3
4
5
6
7
8
S U B C L U
m = 2 5 0 0 ,      = 3
S U B C L U
m = 5 0 0 ,      = 3
D
R
 
g
a
in
k = 1 k = 2 k = 3
k = 4 k = 5 k = 6
τ τ τ
ε ε ε ε
 
圖三 DENCOS 與 CLIQUE、SUBCLU 在合成資料上正確性的比較   圖四 DENCOS 與 CLIQUE、SUBCLU 在真實資料上正確性的比較 
0
10000
20000
30000
40000
0 10 20 30 40 50
Dataset Size (*1000)
E
x
e
c
u
ti
o
n
 T
im
e
 (
s
e
c
)
CLIQUE
DENCOS
0
500
1000
1500
2000
2500
0 10 20 30 40 50
Dataset Size (*1000)
E
x
e
c
u
ti
o
n
 T
im
e
 (
s
e
c
)
CLIQUE
DENCOS
(f) DS05
(b) DS04(a) DS03
(c) DS05
(d) DS03 (e) DS04
0
10000
20000
30000
40000
0 10 20 30 40 50 60 70 80 90
Dataset Size (*1000)
E
x
e
c
u
ti
o
n
 T
im
e
 (
s
e
c
)
CLIQUE
DENCOS
0
10000
20000
30000
40000
4 6 8 10 12 14 16
Dataset Size (*1000)
E
x
e
c
u
ti
o
n
 T
im
e
 (
s
e
c
)
SUBCLU
DENCOS
0
1200
2400
3600
4800
6000
7200
2 4 6 8 10
Dataset Size (*1000)
E
x
e
c
u
ti
o
n
 T
im
e
 (
s
e
c
)
SUBCLU
DENCOS
0
3000
6000
9000
12000
15000
5 6 7 8 9 10
Dataset Size (*1000)
E
x
e
c
u
ti
o
n
 T
im
e
 (
s
e
c
) SUBCLU
DENCOS
 
圖五 DENCOS 與 CLIQUE、SUBCLU 在合成資料上執行效率的比較 
     
圖九延伸最大密集單元發現程序             圖十一非多餘子空間叢集發現之程序 
 
我們執行了一系列的實驗來驗證 NORSC 的效能。在圖十二我們探討了傳統 grid-based 子
空間叢集之資料覆蓋問題，由實驗結果可以看到傳統 grid-based 之方法會面臨嚴重之資訊
遺失。例如在 Covertype 的資料庫，最大的覆蓋遺失率高達 45.12%，這表示被刪除叢集內
有很高比例之資料點並沒有被較高維度之叢集所覆蓋。圖十三為 NORSC 正確性之實驗結
果，其圖中之叢集率是指 NORSC 所發現之叢集數與 CLIQUE 所發現之叢集數的比例。由
圖十三我們可以發現當多餘門檻值設為 0.95 時 NORSC 可以在降低資訊遺失之情況下發掘
出小且簡潔的叢集組。在圖十四與圖十五中我們比較了 NORSC 與 CLIQUE 的執行時間。
圖十四比較 NORSC 與 CLIQUE 在不同密度門檻值的擴充性，從圖中可以證實 NORSC 在
執行時間上比 CLIQUE 好。在較大的密度門檻值下，因為較少的密集單元需要被辦別所以
NORSC 擁有較短的執行時間。圖十五顯示 NORSC 與 CLIQUE 在不同多餘門檻值的擴充
性。從圖中我們發現 NORSC 在所有情況下都具有較佳的效能，且 NORSC 的執行時間不會
受到多餘門檻值的影響。 
7.84
7.27
18
17.64
7.27
26
5.43
1.58
1.66
11.74
3.17
6.67
3.77
4.01
1.58
7.41
4.01
1.58
29.9340.7845.12
24.0214.3714.26
Data Set
CLR≥10%CLR≥10%CLR≥10% CLR≥5%
# of Cluster (%)
CLR≥5%
# of Cluster (%)
CLR≥5%
# of Cluster (%) Max.
CLR (%)
Max.
CLR (%)
Max.
CLR(%)
τ =0.1τ =0.05τ =0.01
13.9110.11 13.98
Covertype
Adult
Yeast
 
                     圖十二資料覆蓋問題之圖示 
(a) Yeast (b) Adult (c) Covertype









0
10
20
30
40
50
60
70
80
90
100
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Redundancy Threshold α
C
lu
s
te
r 
R
a
ti
o
 (
%
.)      = 0.1
     = 0.05
     = 0.01
0
10
20
30
40
50
60
70
80
90
100
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Redundancy Threshold α
C
lu
s
te
r 
R
a
ti
o
 (
%
.)      = 0.1
     = 0.05
     = 0.01
0
10
20
30
40
50
60
70
80
90
100
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Redundancy Threshold α
C
lu
s
te
r 
R
a
ti
o
 (
%
.)     = 0.1
    = 0.05
    = 0.01
 
                               圖十三多餘門檻值對叢集率的影響 
[5]  S. Guha, R. Rastogi, and K. Shim, “CURE: an efficient clustering algorithm for large 
databases,”  in Proceedings of the 1998 ACM SIGMOD international conference on 
Management of data, New York, NY, USA, 1998, pp. 73–84. 
[6]  R. Srikant and R. Agrawal, “Mining Sequential Patterns: Generalizations and Performance 
Improvements,” in Proceedings of the 5th International Conference on Extending Database 
Technology: Advances in Database Technology, London, UK, 1996, pp. 3–17. 
[7]  A. K. Jain and R. C. Dubes, Algorithms for clustering data. Upper Saddle River, NJ, USA: 
Prentice-Hall, Inc., 1988. 
[8]  A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a review,” ACM Comput. 
Surv., vol. 31, no. 3, pp. 264–323, Sep. 1999. 
[9]  R. T. Ng and J. Han, “CLARANS: A Method for Clustering Objects for Spatial Data 
Mining,” IEEE Trans. on Knowl. and Data Eng., vol. 14, no. 5, pp. 1003–1016, Sep. 
2002. 
[10]  J. F. Camapum and M. H. Fisher, “Segmentation using spatial-feature clustering from 
image sequences,” in 1998 International Conference on Image Processing, 1998. ICIP 98. 
Proceedings, 1998, pp. 799-803 vol.3. 
[11]  M. Charikar, C. Chekuri, T. Feder, and R. Motwani, “ Incremental clustering and 
dynamic information retrieval,” in Proceedings of the twenty-ninth annual ACM symposium 
on Theory of computing, New York, NY, USA, 1997, pp. 626–635. 
[12]  G. Kontaxis, F. Delaglio, and A. Bax, “Molecular fragment replacement approach to 
protein structure determination by chemical shift and dipolar homology database mining,” 
Methods in Enzymology, vol. 394, pp. 42-78, 2005. 
[13]  C. C. Aggarwal, A. Hinneburg, and D. A. Keim, “On the Surprising Behavior of 
Distance Metrics in High Dimensional Space,” in Database Theory — ICDT 2001, vol. 
1973, J. Bussche and V. Vianu, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 
420-434. 
[14]  C. C. Aggarwal and P. S. Yu, “The IGrid index: reversing the dimensionality curse for 
similarity indexing in high dimensional space,” in Proceedings of the sixth ACM SIGKDD 
international conference on Knowledge discovery and data mining, New York, NY, USA, 
2000, pp. 119–129. 
[15]  K. S. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft, “When Is ”Nearest 
Neighbor”  Meaningful?,”  in Proceedings of the 7th International Conference on 
Database Theory, London, UK, 1999, pp. 217–235. 
[16]  A. Hinneburg, C. C. Aggarwal, and D. A. Keim, “What Is the Nearest Neighbor in High 
Dimensional Spaces?,” in Proceedings of the 26th International Conference on Very Large 
Data Bases, San Francisco, CA, USA, 2000, pp. 506–515. 
[17]  L. Parsons, E. Haque, and H. Liu, “Subspace clustering for high dimensional data: a 
review,” SIGKDD Explor. Newsl., vol. 6, no. 1, pp. 90–105, Jun. 2004. 
[18]  K. Kailing, H.-P. Kriegel, and P. Kröger, “Density-connected subspace clustering for 
high-dimensional data,” IN: PROC. SDM. (2004, p. 246--257, 2004. 
[19]  A. L. Blum and P. Langley, “Selection of relevant features and examples in machine 
learning,” Artif. Intell., vol. 97, no. 1-2, pp. 245–271, Dec. 1997. 
[20]  H. Liu and H. Motoda, Feature Selection for Knowledge Discovery and Data Mining. 
 
 
 
 
 
國科會國外研討會心得報告  
 
計畫名稱：國立台灣大學博士班研究生申請教育部補助出
席國際會議經費 
 
撰寫人： 許家睿  
 
服務單位名稱：國立台灣大學應用力學研究所  
 
出國地點：新加坡(Singapore)  
 
出國日期：2006/06/24~2006/06/29  
會，而且開會時間也太接近開學，加上在東歐開會，地理位置偏遠，種種因素造成
美國學者此次會義的參與意願不足。 
此行最大的收穫為獲得先進國家在傳輸現象相關研究上最新的發展趨勢，對於
今後研究計畫的執行與未來研究方向的規劃將有莫大的助益，本次會議由於主題眾
多，因此分為四天舉行，這在一般國際會議中是較為少見的，因為通常的會議時間
多為三天，但是也因為大會將時間拉長，使得同時之間只有三個不同主題的研究在
進行報告，對於想多方面了解各國在不同領域研究現況的我，反而是一項有利的安
排，雖然還是有一些想了解的主題，還是會因為時間的重疊而無法參與，幸而可就
大會所整理的論文集而加以了解。以下就本次會議中一些精彩的演講做一些心得摘
要： 
二、會議參與心得內容  
1.邀請演講(plenary lecture)部份  
本次大會在前三天的早上均有安排邀請演講，講題與講員分別如下:  
(1) June 26th“ 
“PLENARY SPEAKER INDUCING A COMPLEX BIO-SYSTEM TOWARD A 
DESIRED DESTINY ”, Professor Chih-Ming Ho, UCLA, USA  
(2) June 27th  
“ACOUSTIC MANIPULATON AND SEPARATION OF MICROPATICLES 
AND CELLS”, Professor Thomas Laurell , Lund University, USA  
(3) June 28th  
“SCIENTIFIC ANALYSIS AND ENGINEERING UTILIZATION OF BIO 
MOLECULES IN MEMS”, Professor H. Fujita, University of Tokyo , Japan 
由本次大會所安排的三場邀請演講的內容看來，可以看出現在國際間的研究趨
勢，大多集中在生物科技、奈微米技術與微小尺度下的力學機制，這也是我們國家
現在努力發展的方向，而何志銘博士所率領的研究團隊更在近幾年內於國際的研究
中享有聲譽，現階段的奈微米技術開發層面，除了單一功能的微元件開發外，另一
得：此研究主要是討論一個3D的微光學系統，這項系統主要是為了改善微機電中可
調變雷射之光學耦合效率，其中的一些可調變元件則利用微機電製程製作，實際的
效率也與傳統的設計進行比較。  
(3)Ultra-Sensitive Cantilevers: Linking Micro with Nano for Molecular Detection, 
(Xinxin Lee, et al., Chinese Academy of Science, China)心得：此研究主要是利用為機
械式懸臂樑作為感測元件，在動態與靜態的環境下進行感應，主要是感測生物分子
單層鍵結時候的訊號變化，動態則是記錄其振動頻率的偏移。  
(4)Electrowetting-based Droplet Mixing Efficiency Enhanced by Generating 
Vortexes inside Droplet, (Heng-Cang Hu, et al., Instrument Technology Research Center, 
Taiwan) 心得：此研究是應用液珠在電極中因為電場的影響，使其表面的親疏水性
發生變化，因此表面的接觸角也跟著改變，利用此一特性，將之應用於微混合中，
可以快速有效的達到混合結果。  
(5)Powerless Nano/MicroFluidic System Driven by Surface Tension, (Fan-Gang 
Tseng, National Tsing Hua University, Taiwan) 心得：本研究主要利用表面張力的差
異，使得液體不需要外加動力的情況下，便可達到推送的效果，因此表面張力的應
用將是奈微米流體推送的動力。  
(6)Characterization of Polydimethylsilozane (PDMS) Membrane for Pneumatic 
Pumping Applications, (H.L. Yin et al., National Tsing Hua University, Taiwan) 心得：
本研究主要主要討論的是利用PDMS所製作的微幫浦及其製作過程，並討論利用此
材質時之相關特性。  
(7)Zwta-Potential Effect on Electro-Hydro-Dynamic (EHD) Flows, (Jiun-Min Wang 
et al., Tamkang University, Taiwan) 心得：本研究主要主要討論電滲透現象於幫浦
時，不同的壁面材質下之行為，實驗中發現在非傳導性之必面上，Zwta-Potentia效
應是不能被忽略的。 
 
3.海報張貼過程與心得：  
本次所投稿之論文雖然沒有以口頭形式發表，但應會議邀請以海報的形式呈現
三、結論 
在此特別感謝國科會與台灣大學博士生參加國際會議提供經費上的補助，使得
我能順利參加新加坡舉辦的APOCT2006國際研討會。APCOT年會是近來在亞洲相
當著名的年會，參與年會除了可以增進學生對於相關領域研究趨勢的了解之外，更
可以與外國的專家學者溝通，同時也可增加台灣在世界上的能見度與地位，對於我
國當前所面臨的外交困境也算是盡個人的一份心力。  
由於本次會議內容對於國內發展奈微米的重點科技有相當的幫助，下屆的年會
也將在成功大學舉行，因此在未來兩年內，國內發展的奈微米及生醫微系統的技術
將有機會做更多的呈現，可見我國現今的方向也符合世界潮流。  
在本次會議中，除了應力所的教授外，也遇到其他台、清、交、成、淡江與國
內工研院及精密儀器中心等單位的人士，也在會議期間做些交流，對於國內別的學
校目前的研究內容也有了初步的了解，相信在回國後，可以就研究的需求，就近互
相切磋。  
整體而言，參與本次國際會議對我而言是個重要的經驗，不僅讓我有了更寬廣
的國際觀，也有了更深的研究體認，想要在國際會議中獲得掌聲、贏得尊敬，只有
秉持精益求精的精神，不斷的自我要求，這是我在國內研討會所難以感受的。 
 
四、攜回資料與名稱與內容 
 
本次會議中所攜回之資料如下: 
1. 會議之手冊與論文摘要集。 
2. 會議光碟一片。 
3. 一些與會議人士討論的資料及當地參展科技廠商的資訊。
國科會補助計畫衍生研發成果推廣資料表
日期:2012/01/30
國科會補助計畫
計畫名稱: 高維度與空間資料之叢集資料探勘
計畫主持人: 陳銘憲
計畫編號: 97-2221-E-002-172-MY3 學門領域: 資料庫系統及資料工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
