I 
 
目錄 
中文摘要 .............................................................................................................. II 
英文摘要 ............................................................................................................ III 
一、前言 ............................................................................................................... 1 
二、研究目的 ........................................................................................................ 1 
三、文獻探討 ........................................................................................................ 2 
四、研究方法 ........................................................................................................ 3 
五、結果與討論 ................................................................................................... 21 
六、參考文獻 ...................................................................................................... 25 
 
 
 
  
III 
 
English Abstract  
The main purpose of this project is to provide a smart environment to improve 
human-machine interaction, integrate different service devices, and provide multi-modal 
customized services to satisfy the needs of users. The goal of this project captures the 
intention of the user to be used by service robots and provides an infrastructure for multiple 
robots and devices in a smart environment to be integrated. A service-oriented architecture 
and intelligent agents will be used for processing different data to improve the extensibility 
of a robot system through a simple interface to blend in different systems easily. For the first 
year, definition to environment knowledge was studied and plan generation system was 
completed. The main topic of the second year is to involve the study of context-aware 
systems and related issues into our integrated project. The third year focuses on the research 
in case-based reasoning (CBR), system integration, and verification through a Petri-Net 
model. This research combines a rule-based system and ontology to conquer disadvantages 
we have found, and we have developed a prototype system using ontology and a rule base 
to deal with conflicts between multiple services. In addition, we use CBR as the reasoning 
method to determine what behaviors a user is involved. The CBR mechanism not only 
reuses previous cases, but also stores new cases for future reference. Furthermore, personal 
ontology is constructed to represent user’s preferences, and the system will use this 
information to choose the suitable service for the user. The verification stage can verify 
structure correctness property such as safeness, reachability, and liveness; it is completed by 
Petri Net model with coverability tree, incidence matrix and state equation, and transitive 
matrix. 
 
Keywords: intelligent agents, human-machine interaction, service-oriented architecture, user 
intention, context-aware information, ontology, intelligent agents, rule-based reasoning, 
case-based reasoning, Petri-Net model, personal ontology 
 
 
  
2 
 
 
三、 文獻探討 
本子計畫的研究重點在於介面的建立，介面的研究可分為智慧型人機介面與機器
人與智慧型環境的整合介面。本研究將採取使用者意念導向的互動以及語言控制的技
術，環境的架構將採用服務導向架構(SOA)為主。如何使用自然語言一直是系統開發
者極大的挑戰[1]，為了更能接近使用者需要，我們將使用有限的語言(controlled 
language)及加入背景知識[2]，使用在機器人的人機介面[3]。為了使用者與機器人或機
器人間的合作與協調，智慧型代理人的協助是一項重要的研究[4]，同時如何將不同的
機器人，或既有的產品納入合作環境中，亦是極有挑戰的研究[5,6]。SOA 為提供服務
的架構，不僅是資訊產業的技術，此架構已開始在不同的領域發展[7]，我們相信在服
務機器人中也能扮演重要的角色。相關的研究中 Ubiquitous Robotic Companion (URC)
的團隊研究使用 SOA 為架構，並在此架構建立智慧型環境，他們的技術包含架構、協
定語言、在智慧行人機介面方面[8-10]。 
情境感知(Context-aware)其最常被引用的定義如下:「任何可以被用來描述狀態的
資訊稱之，這些狀態包含使用者和應用程式之間互動的人類、環境、物件、時間、活
動、喜好」[11]，本研究的情境感知也將引用此定義。在此定義下，對於計算機擁有
情境感知的特性時，計算機對於人類的掌握將會更精確、更具有彈性，因此情境感知
的應用相當廣泛，諸如:智慧型空間、博物館自動導覽等。 
情境感知系統並非單純掌握當下的資訊以及具有處理這些資訊地能力則可稱之，
文獻[12]曾提到情境感知系統必須能夠符合智慧型空間的應用，舉例來說:假設情境感
知系統應用於智慧型空間僅能夠掌握人類某特定動作或狀態並做出反應，但這將只是
「Wait-Sense-Respond System」，意即系統僅是針對狀況做出預設的反應，系統本身缺
乏彈性以及選擇合適服務的能力；因此情境感知系統必須要能夠針對人類行為進行理
解，並且必須建立完整的知識庫，這樣系統提供的服務或者資訊才能夠真正適合人類
情境，也才能稱得上是真正的「智慧型系統」。 
近年來由於嵌入式系統的發展以及網路的廣泛使用使得情境感知系統更顯重要，
因為在硬體上的發展使得軟體有更多的發展空間，許多研究都能夠支持這樣的論點，
例如:Oxygen Project[13]，此計劃希望計算機所提供的服務能夠像是「呼吸的空氣般」，
情境感知系統與嵌入式系統的結合可以促使計算機達到此目的；另外，Oxygen Project
子計畫 AIRE[14]也利用嵌入式系統與情境感知系統結合建立智慧型空間；Gaia[15]發
展智慧型空間的中介軟體也屬於在情境感知系統的範疇之中，此外發展推理不確定情
境的方法以適用於智慧型空間[16]也屬於一種情境感知系統的實現。 
現今對於情境感知的文獻整理以 Baldauf 等人 [17]和 Hong 等人 [18]所整理的資
料最為齊全且這兩篇發表於西元 2006 年與西元 2008 年對於資料更新具有較好的參考
價值，這兩篇文獻不僅探討數量極為豐富，兩位作者所提出的架構(Framework)對於情
境感知系統研究者更具意義，這些架構使情境感知相關研究者在此領域進行文獻探討
時可以進行更集中式的探討。 
 
4 
 
在使用階層式工作網路規劃前， 我們得先自行規劃好領域定義，則接收問題描述
後，才有能力拆解此問題所描述的服務，並配合已知的領域服務組合出流程模型。而
本研究應用的領域設定在居家生活中，當有訪客來訪時，應用家中現有的服務設備，
以進行服務組合，提供給使用者，便是本系統領域定義，當我們將領域定義規劃完成
後，便可以對問題描述進行拆解，以下將說明本研究應用於家庭服務組合系統中的拆
解方法。 
在訪客來訪的領域定義中，因為「訪客來訪」的目標狀態太過於抽象，所以須將
這個目標狀態做拆解，在本研究中，首先使用人、事、時、地、物的概念進行「訪客
來訪」的拆解，如表 1。其中「人」為得知訪客身分，「事」為取得訪客來訪目的，「時」
是取得訪客來訪時間，「地」是來訪的場地安排，「物」則是提供家中的設備。 
 
表 1. 客廳的服務設備 
概念 內容敘述 
人 得知訪客身分 
事 取得訪客來訪目的 
時 取得訪客來訪時間 
地 來訪的場地安排 
物 提供家中設備 
 
然而，若是我們不清楚訪客的來訪目的時，則「地」和「物」的狀態就不能拆解，
例如：當訪客來臨時，若是我們不知道訪客來訪的目的，則不清楚要提供哪一類的設
備和安排哪一類的場地給訪客。因此在本研究提出的拆解法中，「地」和「物」屬於在
「事」的狀態底下，也就是來訪的場地安排和提供家中設備的狀態，須先根據「訪客
來訪的目的」才可進行拆解，如圖 1。 
 「訪客來訪」的狀態拆解完後，產生出「得知訪客身分」、「取得訪客來訪目的」、
「取得訪客來訪時間」、「來訪的場地安排」、「提供家中設備」五個狀態，但是對於使
用家電資訊設備以進行服務組合來說，這樣拆解出來的狀態還是太過於抽象，因此，
本研究繼續將「取得訪客來訪目的」進行拆解。由於訪客的來訪，有一定的需求，例
如：為了聚餐或是為了看球賽而來拜訪，因此根據這些需求，我們可將來訪的目的分
解成「食」、「衣」、「住」、「行」、「育」、「樂」六個概念，而這六個概念下，有其隸屬
的狀態，例如：聚餐就是屬於「食」的概念，聊天或看電視就屬於「樂」的概念(如圖
2)，透過這樣的分類，我們可以將訪客來訪的目的做拆解，方便了解需提供哪一類的
家中設備和場地安排。 
根據圖 1，我們得知當訪客來訪的目的被確定後，就可進行「來訪場地安排」和
「提供家中設備」的拆解，因此以下先說明「提供家中設備」的拆解法。在本研究中，
「物」這個概念是屬於「提供家中設備」的狀態。然而家庭中的家電資訊設備種類太
多，因此針對這些種類，我們在本研究中，使用「食」、「衣」、「住」、「行」、「育」、「樂」
六個概念，將家中的資訊設備做為分類，以便當使用者可透過這六大概念，對設備做
分類，當要新增設備時，也可透過這六大概念來做新增。 
6 
 
清楚地將每一個家電資訊設備做功能上的配對，例如：空氣清靜機可提供改善空氣品
質的功能，冷氣機可提供改善場地濕度和溫度的功能，而吸塵器可提供清潔地板和家
具的功能，如圖 3 所示。  
我們得知若是家中的設備繁多，則規劃器規劃出的服務組合就會有很多個，因此
為了解決這樣的問題產生，本研究提出了記錄訪客喜好及使用者喜好的方法，來篩選
服務組合，並且計算服務組合滿足使用者需求的程度，以下是本研究中針對服務組合
篩選的流程，如圖 4。 
 
圖 3 家電設備對於場地安排提供的服務 
根據此篩選流程，規劃器組合完後的服務組合，便會根據訪客的喜好來做篩選。
目前所考慮到的使用者喜好只限定於『時間』以及『耗電量』，時間所表示的是所排出
來的行程，需要多少時間讓所有的服務完成，而耗電量表示所有行程完成後，所參與
的家電總共消耗多少電。時間與耗電量都屬於使用這在成本的喜好。 
 
圖 4 服務組合篩選流程 
  
8 
 
從新定義規則。 
 條件的信任度:使用者對於條件可能擁有程度上的分別，但:規則式推理系統的條
件只要條件符合即可觸發。 
 不易表達複雜的知識:規則只能表示片段知識，不易表達較為複雜的知識 
以上六項為單純使用規則式推理實作情境感知系統可能會遇到的瓶頸。 
本研究的前端推論用於對人類行為做一推論，L. V.  Mises[19]提到人類行為是有目
的性的。且因為人類所有的決策都是以排序方式為基礎的，因此人類不可以同時進行
超過一項行為，所以行為是由許多行為組合而成且為某特定目的而存在。根據此論證，
本研究將加入「人類行為本體論」用以判斷人類的行為，許多的研究都有使用到類似
的作法，例如[20][21]及建立本體論表示出所有狀況的知識，然後使用模糊比對找出現
在可能的狀況為何。 
本研究採用本體論當作處理前端推論的主要方法並加入一些本研究提出的演算法，
這將達成「處理情境資訊的能力」的評估標準。這裡的本體論推論使用人、事、時、
地、物為主軸建構，「人」在這裡指參與的使用者，這裡推論的行為是指使用者行為故
考慮使用者行為才具有意義；「事」指的是使用者的行為，也是前端推論想推論的結果；
「時」指的是事情發生的時間，時間可能會影響事情的發生故考慮之；「地」指的是行
為發生的環境，某特定行為只會發生在特定的環境，所以環境納入考慮;「物」指的是
正在被使用的物品，這項因素是決定行為的關鍵線索，透過物品的使用決定可能在發
生的行為。透過「人」、「時」、「地」、「物」推論「事」，這裡的「事」指的是行為，因
為這裡所建構的是人類行為判斷本體論，所以「人」這項參數永遠是人，故不考慮之。
所以「時」「地」「物」為每一個行為所必須具備有的判斷因子（圖 6）。 
行為
時間 地點 物品
關係 行為 地點 時間
圖形說明
物品
 
圖 6.行為判斷因子 
 
函數 relate(i)用來計算時間、地點、物品各別與行為相關的程度，這個函數的概念
來自於 Christos 等人所提出的 Similarity 函數[21]，該作者將不同的「情況(Situation)」
使用本體論建構，當某情況發生時會根據演算法進行比對相似度，也就是 Similarity 函
數的值，這個結果可以幫助系統辨識使用者所處於的情況為何。行為發生的程度使用
符號「Degree」表示，「Degree」代表某行為透過函數 Relate(i)計算時間、地點、物品
行為相關程度的加總，公式如下: 
10 
 
 飯後收拾 Degree=[(1+1+1+0.83+0.83)/(1+1+1+1+1)]*100%=93.2% 
 判斷行為優先權:吃飯=飯後收拾>準備食物=準備餐具=清潔餐具=擦桌子 
 程度比較:吃飯(96.6%)>飯後收拾(93.2%) 
 系統判斷現在行為:吃飯 
此外，本研究採用案例式推理來推論使用者的行為，也有許多學者在情境感知系
統中採用案例式推理來推論使用者的行為，以下為本研究採用案例式推理的主要原
因。 
1. 增進解決問題的能力：在智慧型環境中使用者的行為往往是多變化的，系統設計者無法
預先建構出完整的規則，而案例式推理系統有學習的機制，能將新的案例新增到案例庫
中，隨著系統的運作，而擴充了案例庫提升了解決問題的能力。 
2. 知識的獲得成本：以知識為基礎的系統是依賴規則，而規則的獲得過程較費力也較不可
靠，因為並不能保證規則能充分的表達專家的知識，而案例式推理無須將經驗轉變成規
則即可推論，所以獲得知識的成本相對來得低。 
3. 知識的維護：案例式推理系統只需要處理實際上會發生的問題，而不是所有可能會發生
的問題，所以使用者只需要加入缺少的種子案例(Seed case)，不需要專家的介入來預先
制訂所有的規則。 
4. 使用者的接受程度：規則式推理為基礎的系統所制定的規則大多是由領域專家和程式設
計者所制定的，使用者未必能理解和接受這些規則，而案例式推理系統是基於先前實際
上發生的案例來表達給使用者，因此較符合使用者的思維。 
本研究基於上述之優點，採用案例式推理為情境感知系統中的推論引擎，本研究中
以「Person」、「Activity」、「Environment」、「Object」為主軸來建構案例，「Person」在
這裡所指的是使用者，系統所要推論的為使用者的行為，故要考慮到使用者才有意義；
「Activity」指的是使用者的行為，也是前端推論中所想要得到的結果；「Environment」
所指的是使用者周遭的環境，其包含了時間「Time」、地點「Location」、物理資訊
「Physical Information」等三種概念資訊，而使用者的行為可能會發生在特定的時間及
地點，也有可能與周遭的物理資訊有關，所以將環境中的三個概念納入考慮；「Object」
指的是使用者在使用的用具或物品，這項因素也是決定使用者行為的關鍵線索，透過
物品的使用可使系統能更精準的推論出使用者的行為。 
    本研究採用本體論來建構案例，如圖 7 所示，灰色的橢圓為案例的問題描述，長
方形為案例的解。而案例結構的設計則採用階層式架構，以便於資料的維護與降低搜
索時間，對於重複出現的案例則保留一筆，並記錄其出現次數，做為使用者的參考依
據。 
12 
 
算是採用 PaL 和 Shiu 學者[23]所提出的，此公式可計算兩個定性屬性之間的相似度，
而使用此演算法主要的原因是計算方式簡單，能簡單的計算出屬性之間的相似度，較
為直覺也較多人所使用，公式如下： 
simX，Y = 
   
 = 
相同特徵數量
總特徵的數量   (2) 
simX，Y：屬性 X 與屬性 Y 的相似度。 
Common：兩個案例中，具有相同特徵數量之總和。 
Different：兩個案例中，不同特徵量之總和。 
在案例庫中存有一個 T 的案例；使用者為 Daniel，位置位於廚房，時間是中午，
所使用的物品包括：餐桌、餐具，而物理資訊分別為：溫度高、亮度適中、濕度適中、
音量適中，此案例 T 如圖 8 所示。 
 
圖 8 案例庫中 T 案例 
 
假設今日有一位 Daniel 的使用者位置位於廚房，時間是中午，正在使用的物品包
括：爐子、冰箱、餐桌，而環境資訊為：溫度高、亮度適中、濕度適中、音量吵雜，
其與 T 案例的相似度計算如表 3.2 所示，此表計算了每個屬性的相似度，最後將個個
屬性的相似度乘以權重值加總起來，即可算出兩個案例之間的相似度；在「Physical 
Information」此屬性中，包含了四種物理資訊，所表達的資訊類型也都不相同，因此
本研究將這四種資訊分別去做相似度計算，最後加總起來取平均。在屬性權重值的部
分本研究給予每個屬性相同的權重，若給予每個屬性適當的權重值，可使案例索引更
加精準，此數值可由專家擬定，這項工作也視為未來需要加強的地方。 
案例使用主要是從擷取到的相似案例中找出最適合的案例解；本研究的應用領域
為智慧家庭，案例所推論出的解為使用者的行為，在此步驟本研究會從擷取到的案例
中計算出使用者最有可能發生的行為，步驟如下： 
14 
 
Personal Ontology 時，我們用概念代表使用者對於某個領域的偏好。例如：「Price」
這個詞彙在購物領域中通常是指物品的價格，而價格的概念可以用來當作使用者購買
物品的一個考慮因素。詞彙也可能跨於不同的領域，對於不同的領域詞彙可能代表了
不同的意義，就如同一字多義，這類想法就類似 Wordnet 中一個 Word 可能含了許多
Sense。例如：「Java」這個詞彙可能代表的是一種咖啡、電腦程式語言或島嶼。 
 詞彙所表達的意義可能不只一種，我們要如何得知某一個詞彙所表達的含意為何？
這時我們就需要更多與此概念相關的資訊來幫助我們了解此概念的意義。例如：「Price：
500 NTD」，此時便能很容易的了解 Price 這個詞彙的意義為價錢；當看到「Product name：
Price」，此時便能得知 Price 所代表的含意為一項產品。 
 此外，即使是同一個領域下的詞彙，他所表達的概念也會根據使用者的不同而有
程度上的差異。例如：「expensive book」，甲與乙都知道這是在描述昂貴的書籍，對
甲來說 500 元可能已經很貴了，但對乙來說要超過 1000 元才屬於昂貴的書籍。 
 根據以上描述，每一個領域都會包含許多的概念，而概念本身又需要由其他更多
的概念來組成。從領域(Domain)與使用者(User)的觀點可將這些概念區分為六種類型。
先從領域的觀點來看，區分如下： 
1. 領域獨立概念(Domain Independent Concept, DIC)：存在一領域集合(Domain Set)，
概念在集合內會被應用於不同的領域，但所表達的含意皆是相同的。例如：有一
設購物域集合存在兩個子領域，分別為咖啡與機票，此時「price」這個詞彙在兩
個領域中皆代表價錢的概念，所以為領域獨立概念。 
2. 領域相關概念(Domain Dependent Concept, DDC)：存在一領域集合，概念在集合
內會被應用到不同的領域，但所表達的含意是不相同的，類似一字多義，此時概
念需要更多的資訊來輔助它，在不同的領域下會有不同的屬性用來描述此概念，
因此便可得知此概念所表達的含意為何。例如：有一購物域集合存在兩個子領域，
分別為咖啡與機票，此時「java」這個詞彙在兩個領域中分別代表咖啡種類與島
嶼的概念，概念會因為領域的不同而有不同的含意，是為領域相關概念。 
3. 領域特定概念(Domain Specific Concept, DSC)：存在一領域集合，概念只會出現在
某個特定領域，為此概念的特別限定用法，詞彙只會有唯一含意。例如：有一購
物領域存在三個子集合，分別為咖啡、機票與書，此時「ISBN」只會在書的領域
被用到，它所代表的概念是國際標準圖書編號。 
4. 使用者獨立概念(User Independent Concept, UIC)：在同一領域集合下，使用 
者對於某概念都有共通的標準，而每個人也都遵循此標準。例如：氣象局用 
大雨及豪大雨的概念來描述雨勢的大小，而氣象局也明確定義出大於 50 公厘小於
130 公厘雨量被稱之為大雨，這是一個標準的準則，此概念不會因人而異，是為
使用者獨立概念。 
5. 使用者相關概念(User Dependent Concept, UDC)：一些較模糊的概念，此概念會因
為使用者的自身條件而有程度上的差異。例如：「expensive book」，貴的標準會
因人而異，因為使用者所處的環境不同，自身的條件也不同，因此對於概念的看
法產生了程度上的差異，此為使用者相關概念。 
16 
 
 
圖 10 needInterpretation relation 
 
本研究的 Personal Ontology 應用的領域為智慧屋中的家庭服務，系統會依據使用
者的地點找尋可提供服務的設備，使用者則可對於設備做些偏好設定，而這些資訊則
將會儲存在 Personal Ontology 中，以幫助系統做服務的選擇。例如：系統偵測到使用
者在飯廳中吃飯，而飯廳中有音響、電燈和冷氣機等裝置，其所能提供的服務包含了
溫度服務、燈光服務、音樂服務…等等，從領域的觀點來看溫度、風速和音樂類別是
屬於 DSC，從使用者觀點來看溫度高低和風速大小是屬於 UDC，因為需要更多的使
用者資訊才能夠解釋，例如：適合的溫度會因人而異；上述如圖 11 所示。 
 
圖 11 家庭服務領域 Personal Ontology 
     
延續上述的例子，再取得使用者對於服務的偏好及權重值，我們可以產生出如下
18 
 
 
圖 13 服務驗證方法架構圖 
 
在驗證程序一開始，Plan Generator 會呼叫 Correctness Verificator 啟動本系統，以
對描述網路服務組合的 OWL-S 文件進行驗證，接著 Correctness Verificator 會呼叫
OWL-S to PNML Translator 執行服務組合的塑模，OWL-S to PNML Translator 會先後呼
叫 OWL-S Parser、XSLT Engine 與 PNML Parser，執行 OWL-S 文件的修改、OWL-S
文件轉 PNML 文件與 PNML 文件的修改，產生記錄 places、transitions 與 arcs 的陣列
並回傳給 Correctness Verificator，之後 Correctness Verificator 會依序呼叫 Safeness 
Verificator、Reachability Verificator 與 Liveness Verificator，將塑模產生的陣列當成輸入
參數，進行安全性、可到達性與活性的驗證，並產生個別屬性的驗證結果文件，最後
Correctness Verificator 呼叫 Verification Result Integrator 整合這些文件以產生一份正確
性驗證結果文件，透過這份文件，可讓 Plan Generator 決定是否呼叫 Plan Executor 執
行服務組合，或是重新定義服務組合的規格。底下我們詳述各個元件的功能與所扮演
的角色： 
Plan Generator 以網路服務組合的三個階段(規劃、定義與實作)而言，Plan Generator
具有定義組合規格的功能，對於規劃階段產生的服務，會透過相關規劃方法(如 HTN 
Planning)進行服務組合，產生一份描述網路服務組合的 OWL-S 文件，以滿足使用者
的需求，除此之外 Plan Generator 還具有判別服務組合是否通過正確性驗證的功能，
透過讀取本系統產生的驗證結果，決定是否需要重組服務，對於未通過驗證的服務組
合，會重新定義其組合規格並呼叫本系統再度進行驗證，對於通過驗證的服務組合則
是呼叫 Plan Executor 執行實作。 
Correctness Verificator 本系統可分為塑模與驗證兩個部分，Correctness Verificator
被視為系統的中央控制單元，除了呼叫 OWL-S to PNML Translator，塑模以 OWL-S 文
件描述的網路服務組合之外，還會將塑模產生的文件經由 Reachability Verificator、
Liveness Verificator、Safeness Verificator 與 Verification Result Integrator 進行正確性的
驗證與驗證結果的整合。 
20 
 
 
圖 15 已拆解的 OWL-S 程式片段 
3. 對於缺少 fromProcess 與 theVar 的資料流，加入<fromProcess resource="null"/>
與<theVar resource="null"/>兩個程式區段，並修改 toParam 的 resource 值(字
尾加入_null)。 
 
XSLT Engine 使用 XSLT 處理器 Xalan-Java，將 OWL-S Parser 拆解產生的各個
OWL-S樣版文件，搭配Composition Pattern XSLT Templates中的XSLT組合結構範本，
執行 OWL-S 文件轉 PNML 文件的動作。 
Composition Pattern XSLT Templates 由 Sequence.xsl、Split.xsl、Split-Join.xsl 與
Any-Order.xsl 四個 XSLT 範本文件組成，XSLT Engine 會呼叫 Composition Pattern XSLT 
Templates，將 Sequence、If-Then-Else、Choice、Repeat-Until 與 Repeat-While 樣版與
Sequnece.xsl 範本搭配，Split 樣版與 Split.xsl 範本搭配，Split-Join 樣版與 Split-Join.xsl
範本搭配，Any-Order 樣版與 Any-Order.xsl 範本搭配，產生這些結構的 PNML 樣版文
件。 
PNML Parser 根據原始 OWL-S 文件描述的結構順序，將轉換產生的 PNML 樣版
文件進行組合，並依據下列規則，對文件中的 Petri Net 元件進行修改或刪除的動作，
以產生一份能完整表達網路服務組合的 PNML文件，在 PNML文件修改完成後，PNML 
Parser 會透過陣列分別儲存 places、transitions 與 arcs，接著將陣列以參數的形式傳遞
給 Correctness Verificator，以進行後續驗證的動作。PNML 文件修改規則： 
1. 依照樣版種類與順序修改元件 id 的值 
如<place id=”O1”>改為<place id=”O1_If1”>，代表這個 place 是屬於 OWL-S
文件的第一個 If-Then-Else 樣版。 
2. 刪除多餘的 transition、place 與 arc 
檢查 transition 與 place 的 name 值，若為 null，刪除這個元件以及與其相連的
arc，若含有_null，將_null 去除並刪除 target 值為這個元件的 arc。 
3. 針對各個樣版刪除重複元件與修正 arc 
22 
 
 
圖 16.情境感知系統架構 
 
以下簡述系統內各個元件的功能: 
 Behavior Reason Component:此元件用來推理人類行為，系統會先向行為本體論要
求一個人類行為的背景知識，之後透過感應器觸發該元件裡的本體論實體，並透
過演算法加以計算，並得到與該元件內容行為的相似程度，藉此系統了解人類目
前的情況，此元件會將目前的情況傳送給「Environment Ontology」。 
 Behavior Ontology:行為本體論，此元件是紀錄人類行為的本體論，內容包含與人
類行為相關的時間、地點、物品與子行為，透過這些相關的線索可以進行人類行
為的推理與判斷。 
 Environment Monitor:此元件用來監控目前環境的狀態，包含人類的行為、物品的
使用、時間…等等相關的資訊，但此元件會記錄「Behavior Ontology」所推理的結
果，因為人類正在發生的行為屬於一種環境狀態。此元件所包含的資訊會傳送給
規則式推理的事實庫，以及元件「Confidence Modify Component」。 
 Environment Ontology:環境的本體論，內容記錄著環境物件彼此之間的關係、以
及物件本身的屬性，舉例來說:藥物此項物件可以透過環境本體論看出藥物是被人
類所使用、藥物本身的適當使用時間、藥物適用疾病、保存期限…等等相關的資
訊，此元件與「Behavior Ontology」最大的不同在於此元件紀錄的資訊屬於靜態資
訊，且其資訊不必經過推理即可獲得 
 Confidence Modify Component:信賴值修正元件，在此系統裡使用者對於每一個規
則都有信賴程度，但這些信賴程度可能在不同的情況下會有所改變，例如:「吃飯
則播放音樂」這個規則會在「看電視」的情況下信賴值會降低。此元件是由「Rule」
24 
 
 
圖 17 驗證方法循序圖 
 
 
圖 18 Document Translator 內部循序圖 
 
流程一開始，Plan Generator 先將 OWL-S 文件傳送至 Correctness Verificator 以啟
動驗證系統，接著 Correctness Verificator 會將 OWL-S 文件交由 Document Translator
進行轉換，轉換的流程如圖 18 所示：首先 OWL-S to PNML Translator 會將 OWL-S 文
件傳送至 OWL-S Parser 進行拆解與修改，接著 OWL-S to PNML Translator 將 OWL-S 
Parser 產生的 OWL-S 格式結構樣版交由 XSLT Engine，搭配對應的 XSLT 範本文件轉
換為 PNML 格式的結構樣版，最後 OWL-S to PNML Translator 將這些樣版交由 PNML 
Parser 進行合併與修改，產生儲存 place、transition 與 arc 的陣列並回傳給 Correctness 
Verificator，完成了塑模的程序。 
在塑模結束後，這些陣列被當成輸入參數傳給 Structure Verificator，依序執行安全
性驗證、可到達性驗證與活性驗證，驗證產生的結果文件會被 Correctness Verificator
交由 Verification Result Integrator 進行整合，以產生一份正確性驗證結果文件，並將文
件回傳給 Plan Generator 完成了驗證的程序。 
26 
 
Context-Awareness, ACM Press, New York, 1999. 
[12] A. Kulkarni, “A Reactive Behavioral System for the Intelligent Room,” Master’s thesis, 
Massachusetts Institute of Technology, Cambridge, MA, 2002. 
[13] M. Dertouzos, “The Oxygen Project,” Scientific American, August 1999,  pp.252–263. 
[14] Howard Shrobe, “Agent-based Intelligent Reactive Environments,” MIT Computer 
Science and Artificial Intelligence Laboratory, 2000. 
[15] M. Roman, “A Middleware Infrastructure Active Spaces,” IEEE Pervasive Computing, 
2002, pp.74–83. 
[16] A. Ranganathan, J. Al-Muhtadi and R. H. campbell. “Reasoning about Uncertain 
Contexts in Pervasive Computing Environments,” IEEE Pervasive Computing, Apr. 
2004, pp.62-70. 
[17] M. Baldauf and S. Dustdar, “A survey on context aware systems,” Tech. Rep. 
TUV-1841-2004-24, Technical University Vienna, 2004. 
[18] Jong-yi Hong, Eui-ho Suh and Sung-Jin Kim, “Context-aware systems: A literature 
review and classification,” Expert Systems with Applications, 2008. 
[19] L. V. Mises, Chinese translation by T. P. Hsia, revised by H. L. Wu, “Human Action,” 
Taipei, Taiwan: Yuan Liu Publishing, 2 Volumes, 1999, pp. 1-506. 
[20] C.B. Anagnostopoulos, Y. Ntarladimas, and S. Hadjiefthymiades, “Situation Computing: 
An innovative architecture with imprecise reasoning,” The Journal of Systems and 
Software 80, 2007.  
[21] C. B. Anagnostopoulos, Y. Ntarladimas, and S. Hadjiefthymiades, “Reasoning about 
Situation Similarity,” 3rd international IEEE Conference Intelligent Systems, September 
2006. 
[22] J. Kolodner, Case-Based Reasoning, Morgan Kaufmann, 1993. 
[23] T. Strang, and C. Linnhoff-Popien, “A Context ModelingSurvey,” First International 
Workshop on Advanced Context Modelling, Reasoning and Management, UbiComp, 
2004. 
  
 28
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■ 達成目標 
□ 未達成目標（請說明，以 100 字為限）  
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
本計畫研究並發展一具有彈性、可攜性、耐用性、自主性的智慧型平台，提供多重智慧
型代理人架構的實現以及多裝置的整合。其技術含一結合 Rule-base 及 CBR 的控制方式、 
多重代理人導向軟體工程的應用、以 Petri-Net 模型描述的服務組合驗證等。將來應用價
值在於數位家庭的技術提昇，讓目前的數位家庭轉為智慧型家庭環境，使居家服務機器
人更容易結合環境，並降低使用者學習新科技的困難度。藉由此計畫補助完成發表三篇
SCI 索引之專業期刊以及 18 篇國內外研討會論文。 
 
 
 
 
 
本人與已畢業學生合著的論文屬於10月11日（星期一）Intelligent Decision and Learning場
次，並有口頭報告的機會。其他的時間，在Session中或場內與不同國家的學者交流。今年大
會可惜沒有安排研究單位的參訪，可是在伊斯坦堡這古城，有安排民族藝術分享，大會
banquet則在歐亞分界的海峽，以乘船的方式，在船上舉行。 
  
（三） 心得
 
今年最大的收穫，應該是所安排的特別演講。特別是第一位Prof. Werbos所講智慧層級，
剛好附合本人目前的國科會計畫，因此收穫良多。對本人在設計智慧型機器人的研究方面，
有許多的幫助。
 
 
（四） 攜回資料名稱及內容
 
論文集光碟
 
techniques are used for building the behavior definitions. The 
execution subsystem is to carry out the behavior sequence 
produced by the reasoning subsystem. Such high-level 
behaviors are the collection of basic actions of the EDP that 
was originally built into the system.  
The reasoning subsystem takes the input from the user in 
two forms, voice and gesture. The input is treated as a 
command to the EDP, in which a set of commands are defined 
initially. The approach we take is to let the user build his own 
commands and gestures to communicate with the EPD based 
on the predefined actions. The perception module is based on 
the previous results from other projects. At the moment, we 
reuse those existing techniques developed to support the voice 
and gesture input.  
 
 
Figure 2.  System concept. 
The commands are processed in the reasoning subsystem 
where those commands are transformed to the goals for the 
EPD to follow. The EPD has the basic actions already defined, 
including ‘down,’ ‘sit,’ ‘stand,’ ‘walk,’ and ‘run’ shown in 
Fg.2. Thus, the main work of the reasoning subsystem is to use 
such basic actions to construct more complicated behaviors to 
meet the goals associated with the commands. For such 
process, we use planning techniques to process the 
decomposition of goals into subgoals and to find the 
relationships associated to the basic actions. 
The execution subsystem is responsible for sending the 
behavior sequences of actions to the external system (Virtual 
Reality Display, VRD) which shows the behaviors of the EPD 
in animation. The interface between the execution subsystem 
and the VRD is defined with animation components to 
represent the basic actions. However, simply reflecting the 
actions to corresponding animation modules may cause the 
EPD do some strange behaviors, such as lying down while 
running. Thus, a certain constraints must be set in the 
execution subsystem to control the rational behavior sequences 
to be sent to the VRD. We have used a state diagram approach 
to define the rational action relationship, which is reported in 
Section IV. The VRD is another previous venture with other 
research institute and is not the scope of this paper. 
III. PLANNING AND LEARNING 
A. Planning Technique 
AI planning is used for deriving a high-level behavior 
based on the existing basic actions. At the same time, the goal 
of the user command is considered in constructing such 
behaviors while each behavior consists of a sequence of 
actions. Each EPD is equipped with the basic actions as 
mentioned in the previous section. The goal of our research is 
to use such basic actions to construct more complicated 
behaviors. One of the features of the EPD is to involve the user 
in helping the EPD to own some behaviors or tricks that are 
not originally defined. 
We use the HTN Planning technique [3] in our research 
since we view the commands as the goals to achieve, and the 
concept of the hierarchical task network matches our 
definitions of the behaviors. At the same time, we consider 
Markov Decision Process (MDP) for reducing the effort in the 
processing of initial settings for task and constraint definition. 
This will be combined with HTN planning as described later. 
An MDP is a tuple (S’, D, A, {Psa(․)},γ,R), where S is the 
state, D the initial state, A the action, {Psa(․)}a transition 
probability for deciding what action a to perform under a state 
S, γ the discounting factor, and R the feedback function for 
giving constraints to the actions to take. 
SHOP2 [3] is what we use for HTP planning, and we 
modified the algorithm from SHOP2 to integrate an MDP as 
our approach. The main purpose is to determine the behavior 
sequences as tasks while satisfying constraints. The parameters, 
S is the current state, M the initial plan, and L the constraints. 
The algorithm is shown below. 
procedure SHOP2(S,M,L) 
if M is empty then return NIL endif 
choose a task t in M 
set r to be a task in a reduced partial order set of tasks 
 
if r = FAIL then return FAIL endif 
choose an operator instance o 
 
S’ = the state produced from S by applying o to r 
L’ = the protection list produced from L by applying o to r 
M’ = the partially ordered set of tasks produced from M 
// the model in MDP ),)},({,,,( RPADS sa γ•  is used in 
M’ 
M’ = (S’, D, A, {Psa(․)},γintention,R)  
 
∂(w,u,m) = ((U – {u}) ∪ subtasks(m’), C’ ∪ constr(m’)) 
{u} = set of subtasks  
 
// constr(m’) is the constraints 
// the original P = SHOP2(S’,M’,L’) is then set to  
P = SHOP2(r(s0, ActionSeqi), w – {u}, o, m) 
 
// action condition is then set as 
U{s’ results∈ (s,a) | a ∈  actioncondition(s)}  
 
return cons(o,P)  
 // return the constraint o set for solving the problem P 
end SHOP2 
 
 
atomic task. The premises will be placed as the task in the 
TABLE I. 
 
 
 
Figure 4.  State diagram for behaviors. 
 
TABLE I.  MDP DEFINED BY (S,A) OF THE STATE-ACTION PAIR TABLE 
 
∑ state is a State-Action Sequence Condition model, P is 
planning to solve the problem , P = (O, M, S0, G). The Q table 
is decided by what sequence generated by planning  and by 
the reinforcement method for an improved Sequence 
Condition model. User selection will force planning results to 
give rewards or penalty. The relationship between the 
planning process and others are depicted in Fig.5. 
 
 
 
 
 
 
Figure 5.  HTN Compainy Q-Learning  process. 
Our HTN method has a 4-tuple form, m=(O,M,S0,G)  in 
which the elements are described as follows. 
 m: the definition of a method in HTN planning 
generated. 
 O: a set of  operators  
 M: a set of m, where every m ∈ M is totally 
ordered . 
Each row of the state-action set shows that a continuous 
action sequence. The planner is required to follow the 
methods of solving the problem (P) and the operation and 
limitations and will plan out the sequence of all possible row 
of actions into the behavior of M multi-dimensional array list 
in the Fig. 6. The upper half of the figure shows that there 
may be n plans generated, and each plan is described as a 
collection of q. The corresponding representation in a matrix 
is shown in the lower part. 
In the figure, n
m
a
sq indicates that a q vaule is based on 
decision-making under conditions of continuous Sm to obtain 
an action. Therefore, our MDP-Based Planning is defined as 
follows: Conditional forward segment of the MDP planning 
algorithm is to respond to an optimized solution. If it is 
established, Plan is an instance of Controlled-Plan and the 
Bptable for space control function by rewards and penalty R is 
determined, where M = (Sequ, ActionSequ, Bptable, Pr, 
Intention, R) and a MDP and P = (O, M, S0, G) is considered. 
We can reduce the MDP as well as to define the field of 
planning shown in Fig. 7. 
 
 
Figure 6.  Q-Table in the space diagram of  HTN  
 
   state-
action 
Primitive task 
sequences 
Primitive task 
sequences 
Primitive task 
sequences 
1 down { down , u1 , 
sit } 
{ down , u1 , 
down}  
2 sit { sit , u1 , stand } { sit , u1 , down } { sit , u1 , sit } 
3 stand { stand , u1 , 
walk } { stand , u1 , sit } 
{ stand , u1 , 
stand } 
4 walk { walk , u1 , 
run } { walk , u1 , sit } 
{ walk , u1 , 
walk } 
5 run { run , u1 , 
walk } { run , u1 , run }  
       SMC 2010 
do-setup( S11,d,k,loc,p, epd )   // to set up for moving toys 
task :    setup(S, epd ) 
subtask :  
U1 = bite ( k,loc,S, d, p )  
U2  = load( k, loc , S , epd ) 
constr :  U1 < U2 , before({U1}, on(S , d) , before({U1}, 
attached( p ,loc )), before({U1}, in(S , p)), belong( k ,loc), 
before({U1}, at ( epd , loc )) 
 
unload(S11, d , k , loc , p , epd); // to complete moving toys 
task :    finish(S, epd ) 
subtask :  
U1=unload( k,loc, S , epd ) 
U1= put( k,loc, d , p ) 
constr :  U1 < U2 , before({U1}, attached( p ,loc)), before({U1}, 
loaded(epd ,S)), before({U1}, top(d, p)), 
before({U1},belong( k ,loc), before({U1}, at ( epd , loc )) 
TABLE II.  STEATE SEQUENCES 
 
D. Experiments 
The learning technique is used for training the EDP to 
perform certain behaviors associated to user commands. The 
MDP training process is used for the EDP to perform basic 
actions. We use a grid in which each cell represents an 
allowable action for the EDP to take a subsequent action. The 
training process involves the rewards, and the result of the 
process will be used in Q-table and later to HTN planning. 
After the training, a set of probability values are associated 
to action sequences. These values are then used in the HTN 
planning to generate a sequence of actions that will be a plan to 
carry out the high-level behaviors. The learning and planning 
process is built into our prototype system which lets us evaluate 
the feasibility and the effectiveness of our approach. 
As mentioned before, our design goal for the EPD is to let 
the owner of the EPD have the freedom to teach the EPD a new 
trick. For this reason, we incorporate a learning mechanism 
which is able to record the use’s commands and execute some 
behaviors. Our subsystem is integrated with the voice-gesture 
input and animation output mentioned earlier. The training 
process mentioned above is to prepare the EPD to set up basic 
behavior for initial use as the product is delivered to the new 
user.  
For training behavior sequences, we have two subjects who 
used voice and gesture to interact with the EPD for training 
behavior sequences, down-sit, sit-stand, stand-walk, and talk-
run. The rewards are set as 1 and discounting factor is set as 0.4. 
Each behavior sequence was repeated for 600 times. Among 
2400 test sets, there were 2194 correct behaviors, making a 
correct rate of 91.5%. 
TABLE III.  EXPERIMENT RESULTS 
 
V. CONCLUSIONS 
This research focuses on the behavior definition and control 
of an EDP. The main contribution presented in this paper is a 
flexible behavior execution model which consists of learning 
and planning. Using the MDP technique with Q-learning 
improved the initial setup of the learning model; whereas 
ontology was used to analyze and design the basic behaviors. 
The learning model is also used in the interaction with the user, 
so that the user has a chance to train the EDP for a new 
behavior. This creates an owner-pet relationship equipped with 
the idea of training a pet. 
ACKNOWLEDGMENT 
The authors thank the colleagues at the Institute for 
Information Industry for providing the audio and gesture input 
and the animation output. 
REFERENCES 
[1] Rodeney A. Brooks. A robust layered control system for a mobile robot, 
IEEE of Robotics and Automation, vol.2, no.1,1986, pp.14-23. 
[2] Max Risler Formal behavior Specification of Multi-Robot Systems 
Using Hierarchical State Machines in XABSL, AAMAS08: Workshop on 
Formal models and methods for multi-robot 2008 
[3] Dana Nau, “SHOP2: An HTN Planning System,” Journal of Artificial 
Intelligence Research , vol.20, 2003, pp. 379-404 
[4] Andrew Y. Ng, Michael Jordan., “PEGUASUS: A policy search method 
for large MDPs and POMDPs,” Proceedings of the Sixteenth Conference 
on Uncertainty in Artificial Intelligence, , 2000 
[5] M. Kearns, Y. Mansour, and A. Y. Ng. Approximate planning in large 
POMDPs via reusable trajectories,” Proceedings of The annual 
Conference on Neural Information Processing System (NIPS 12), 1999. 
[6]  C.J.C.H. Watkins, and P.Dayan,“Technical note: Q leraning,” Maching 
Learning, vol.8,no.3,pp. 279-292, 1992. 
[7] A.G. Tsirukis, G.V. Reklaitis, and M.F. Tenorio, “Nonlinear 
optimization using generalized hopfield networks,” Neural Comput. 
vol.1, no.4, 1989, pp.511-521.  
 
 
 
Behavior 
 
Observation 
down-sit sit-stand stand-
walk 
walk-run 
No. of 
Training 
600 600 600 600 
No. of 
Correct 
552 527 561 554 
No. of 
Incorrect 
48 73 39 46 
Correct 
percentage 
92.0% 87.8% 93.5% 92.2% 
 
no. behavior no. behavior no behavior 
Sseq
-010 
down-sit Sseq
-130 
sit-down Sseq
-240 
wiggle 
Sseq
-020 
sit-stand Sseq
-140 
stand-sit Sseq
-250 
eat 
Sseq
-030 
stand-
walk 
Sseq
-150 
walk-
stand 
Sseq
-270 
bite 
97 年度專題研究計畫研究成果彙整表 
計畫主持人：劉立頌 計畫編號：97-2221-E-194-048-MY3 
計畫名稱：智慧半人型與人共生服務機器人之研製--子計畫六：智慧型人機互動系統設計 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 2 0 100%  
研究報告/技術報告 3 3 100%  
研討會論文 5 3 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 7 3 100% 
博士班學生的補
助轉移碩士生使
用 
博士生 0 1 100% 
博士生因家庭因
素，休學後申請退
學 
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 3 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 13 6 100% 
篇 
多數國際研討會
來台辦理 
論文著作 
專書 1 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
