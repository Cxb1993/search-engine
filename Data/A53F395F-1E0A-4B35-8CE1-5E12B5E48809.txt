2若欲促成這幾年來漸獲重視的格網計
算(grid computing)[6,7,9,10]從實驗性的研
究平台邁向能自給自足營運的成熟平台，
加入市場導向的觀念將是一個必須要走的
方向，本計畫以市場導向的角度來思考計
算格網(computational grid)平台上所需的
資源配置與工作排程方法，並對這些方法
之於整體計算格網平台及個別使用者與工
作將造成的影響做進一步的分析與探討。
由於過去幾年來的蓬勃發展，建構格網
計算平台所需的技術與相關軟體已有長足
的進步也大致完備[8,10]。目前世界上已有
許多滿足不同應用需求的實驗性格網平台
陸續被建立起來[11]，其中在兩岸三地，近
一兩年來也有幾個主要的實驗性格網平台
計畫在分別進行中，包括本人有幸參與其
中的台灣 Unigrid [1]、香港的 Hong Kong
Grid [2]、以及中國大陸的 ChinaGrid [3]等
等。
本人之前的研究成果[12]亦證實了計算
格網平台的確可以有效達成格網內不同單
位間的計算能量互援與工作負載分擔效
益。雖然眼前看來格網計算正蓬勃發展當
中，但仔細一分析可以發現，目前絕大部
分的格網計算平台都是由政府部門所出資
贊助的實驗性研究平台，距離格網計算的
落實與普及應用還有一段距離[13]，為了不
使格網計算的發展在日後政府公部門不再
投入大筆經費後成為了另一個泡沫，一些
有識之士已開始呼籲讓格網計算平台往自
給自足營運方向發展的重要性[4]，一些以
促成這個發展方向為目標的相關技術研究
也陸續出現[5]，但多數著重在如何提供競
價計算資源環境的建立或是探討怎樣的定
價機制對資源提供者或使用者最有利，至
於本計畫則以市場導向的角度切入資源配
置與工作排程方法的研究，在ㄧ個市場導
向的環境裡，使用者滿意度及整體系統資
源的使用效率將是首要的考量，因此本計
畫選定 average waiting time 及 average
waiting ratio 作為改進計算格網平台上
工作排程與資源配置方法的衡量標準。
三、研究方法、結果與討論
由於計算格網平台上 job scheduling 及
processor allocation 方法的決定牽涉到許多
複雜的因素，因此本研究採用 simulation
的方式來探討各種不同因素的影響與交互
作用，並嘗試找出最合適的方法。本年度
計畫針對跨叢集平行計算的 processor
allocation 方法以及 Non-FCFS 型態之 job
scheduling 方法做了初步研究。
在 Non-FCFS 之 job scheduling 方面，所
研究分析的方法包括:
 Conservative backfilling。此方法允許
工作之執行打破 FCFS 的順序，以善
用系統資源，提升使用效率並同時縮
短部份工作的等待時間。不過，晚來
的工作要能比先到的工作還早開始執
行，必須滿足一個前提，那就是晚來
工作的提前執行不能夠因此耽誤到任
何一個比它先到之工作的預定完成時
間，因此在挑選哪一個工作可以提前
執行時必須經過精密複雜的計算。這
個排程方法的一個主要優點是，任何
工作在被交付執行時便可得到系統所
給予的一個最晚開始執行時間保證，
再晚開始執行，都不會晚過那個時
間。但這個優點並不是沒有任何代價
的，每個工作在被交付執行時會被要
求提供一個該工作最長所需執行時間
的預估值，一旦實際執行時該工作使
用的時間若達到該預估上限值，即使
還未完成，也將被強制結束。對於某
些工作或使用者而言，預估一個工作
的所需執行時間並不是件容易的事，
因此這項要求會帶來一些困擾。
接下來的三種方法都不需要使用者提
供工作執行所需的時間上限。雖然因此不
具備提供使用者最晚開始執行時間資訊的
優點，但卻對進ㄧ步提升系統資源使用效
率有所助益。
 First available。這個方法在每次從
waiting queue 中挑選下一個執行的工
作時，由 waiting queue 的第一個工作
開始依序檢查，直到遇到第一個可以
在目前的資源數目下執行的工作為
4工作的 waiting time 除以 runtime，而 load
factor 代表系統中等待執行工作的擁擠程
度，在模擬分析的過程中以工作的平均執
行時間作為調整系統擁擠程度的工具。由
表三跟表四的結果可知 smallest first 的表
現優於其他方法。
表三: 各個job scheduling方法的average waiting time(秒)
FCFS First Available Smallest First Largest First Backfilling
Load
Factor=1.0
102.71 49.17 47.40 51.86 50.73
1.5 335.20 142.49 134.14 150.79 157.63
2.0 956.25 370.18 343.39 417.00 396.85
2.5 2815.84 938.98 833.67 1075.84 1082.79
3.0 8328.50 2280.82 1909.66 3059.78 2863.94
4.0 350945.34 51191.40 49653.18 95794.07 65481.10
表四: 各個job scheduling方法的average waiting ratio
FCFS First
Available
Smallest First Largest First Backfilling
Load
Factor=1.0
0.77 0.17 0.15 0.21 0.16
1.5 1.89 0.51 0.40 0.53 0.53
2.0 4.08 0.86 0.79 1.15 0.85
2.5 10.38 1.68 1.29 2.03 1.75
3.0 26.92 3.15 2.19 5.27 3.22
4.0 840.93 62.63 21.99 153.65 50.72
在 跨 叢 集 平 行 計 算 的 processor
allocation 方法的部份，研究的目的在於雖
然允許跨叢集的平行計算，但透過適當的
processor allocation 方法安排，自然地減少
跨叢集平行計算所必須發生的機率，因為
跨叢集平行計算由於廣域網路的速度及頻
寬比不上單一叢集內部的高速網路，往往
需要比在單一叢集內執行時花上更多的時
間，也因此佔用系統資源更久的時間，降
低了系統資源的使用效率。解決這個問題
牽 涉 到 兩 個 不 同 情 況 下 的 processor
allocation 安排，首先是若一個工作同時有
數個叢集能提供足夠資源讓其執行時，該
選擇到哪一個上去執行? 表面上看來這似
乎只是單一叢集內部的平行計算跟跨叢集
無關，但透過適當的選擇單一叢集，可以
影響到後來跨叢集平行工作發生的機率。
第二個情況是，若有一個工作需要跨叢集
的資源進行平行計算，該從計算格網中挑
哪幾個叢集出來供他使用呢? 同樣地，不
同的挑選結果將導致將來不同的跨叢集平
行計算發生機率。
在第一種情況下的 processor allocation
方法，我們研究了底下數種:
 First-fit。要為某一個工作挑選執行叢
集時，從計算格網系統內儲存所有叢
集資訊的資料結構中的第一個叢集開
始依序檢查，一遇到第一個擁有足夠
資源的叢集，便將該工作交付給它執
行。
 Best-fit。在所有滿足該工作所需計算
資源的叢集當中，挑選所擁有資源與
該工作所需資源間差距最小者。背後
的邏輯在於萬一扣除該工作所使用的
資源之外所剩下的資源已不夠其他的
工作之用，那所浪費的計算資源也可
盡量維持在較少的狀態。
 Worst-fit。在所有滿足該工作所需計算
資源的叢集當中，挑選所擁有資源與
該工作所需資源間差距最大者。背後
的假設在於讓剩下的資源不要太少，
盡可能仍有機會供其它工作使用。
 Median-fit。在所有滿足該工作所需計
6Slowdown
ratio
Best Fit with Fixed
Order
Best Fit with Smaller
First
Best Fit with Larger
First
1 0.37 0.37 0.37
2 0.47 0.47 0.47
4 0.51 0.51 0.51
5 0.75 1.61 0.53
表 九 將 我 們 所 研 究 建 議 採 用 之
processor allocation 方法與原始之沒有做任
何特殊安排的 processor allocation 作法作
效能上的分析比較。結果可以發現不論是
以 average waiting time或是 average waiting
ratio 來看，我們所建議的方法都達到了相
當大幅度的效能提升，而且當叢集內外部
網路速度及頻寬的差異愈大時，改進的效
果愈顯著。以 average waiting ratio 而言，
在 slowdown ratio 等於 5 時，效能的提升甚
至超過了 20 倍。
表九: Processor alloctaion 方法效能改進成果
Slowdown
ratio
Average waiting time (sec.) Average waiting ratio
Single-pool
centralized
queue
The integrated
approach
Single-pool
centralized
queue
The
integrated
approach
5 200.71 28.54 1.88 0.08
4 117.57 23.68 0.90 0.07
2 61.71 23.30 0.47 0.07
no slowdown 50.36 22.18 0.37 0.06
四、計畫成果自評
本年度計畫執行順利，產生不少有意義
的研究成果，並已將部份研究成果撰寫成學
術 論 文 投 稿 至 學 術 研 討 會 議
[14,15,16,17]。
五、參考文獻
[1] Taiwan Unigrid Project,
http://unigrid.nchc.org.tw
[2] Hong Kong Grid Initiative,
http://www.hkgrid.org
[3] 中 國 教 育 科 研 網 格 (China Grid),
http://www.chinagrid.edu.cn
[4] Ni, L. M., “Can Grid Computing Survive 
without a Business Model?”, Keynote 
Speech, The First Workshop on Grid
Technologies and Applications, Hsinchu,
Taiwan, December 7-8, 2004.
[5] Rajkumar Buyya’s Internet Home!, http://
http://www.buyya.com/
[6] Foster, I., The GRID: Blueprint for a New
Computing Infrastructure, Morgan
Kaufmann Publishers, Inc., San Francisco,
California, USA, 1999.
[7]Foster, I. and Gannon, D., “The Open Grid
Services Architecture Platform”, 
draft-ggf-ogsa-platform-2, Global Grid
Forum.
[8] http://www.globus.org
[9] Tuecke, S., Czajkowski, K., Foster, I., Frey,
J., Graham, S., Kesselman, C., Maquire,
T., Sandholm, T., Snelling, D., Vanderbilt,
P., “Open Grid Services Infrastructure 
Version 1.0”, 
draft-ggf-ogsi-gridservice-29, Global
Grid Forum.
