參數的計算複雜度將會比 LPC 來的高 [15-16]，本計畫
使用主持人所研發的無複數形式之 Ferrari 公式來快速求
解 LSP 參數 [17]。 
此外，許多研究學者提出利用小波轉換 (Wavelet 
Transform)來研究語者識別以及語音辨識的問題  [18-
20]，自從 Morlet 在 1984 年首次提出小波轉換在信號處
理上的潛力以來，有關小波轉換的研究一直持續不斷，
與傳統的傅立葉轉相比較，小波轉換具有極佳的時域-
頻域解析特性，而該特性極為適合應用在不具有統計性
質的語音信號處理上。使用小波轉換的語者辨識演算法
可歸納如下：先將輸入的聲音訊號分割為數個音框，之
後利用小波轉換把每個音框的聲音訊號分解為子波段訊
號，子波段訊號經由能量計算、特徵值擷取、統計偵測
後再與資料庫的語者資訊共同判斷輸入的音框屬於哪個
語者。另一方面，由於語者分類與語音分割也是屬於分
類問題的一種，因此已有部分論文提出使用支撐向量機
(Support Vector Machine, SVM)於語者分類與語音分割應
用方面的研究 [21-26]，自從 Vapnik [27]在 1980 年代提
出 SVM 之後，針對 SVM 的研究便逐漸熱絡起來。
SVM 使用一個已知的核函數(Kernel Function)配合訓練
樣本參數推算出一個超平面(Hyperplane)，在語者分類
與語音分割的應用上，語音樣本參數可選用 LPC 參
數、LSP 參數、音高週期、低高頻能量等等；此超平面
便可用來區分兩類不同的資訊，在本計畫中，超平面即
可用來區分兩種不同語者的聲音；如果進一步搭配
Multi-case SVM [26, 28]，便可執行多語者分類。目前
SVM 已被證實比傳統的分類技術，例如 RBF Neural 
Networks、Nearest Neighbor (NN), Nearest Center (NC)以
及 The k-NN Classifier 等來得有效。從文獻 [18-26]的實
驗數據顯示，語者分類準確度可藉由使用小波轉換或是
SVM 加以提升。 
基於前述文獻的分析探討，本計畫提出一個利用無
複數快速求解線頻譜對演算法結合支撐向量機與小波轉
換於多語者對話環境中的語者分類與語音分割之研究，
其基本步驟是使用小波轉換擷取多語者對話環境中的語
音特徵資料，包括音高週期 [29]、高低頻能量，音訊亮
度、頻帶寬等等，並使用無複數形式快速演算法來求取
LSP 參數，接著使用支稱向量機針對前述多語者對話環
境中的語音特徵資料與 LSP 參數進行訓練與分類，最後
訓練完成的 SVM-MSC (Multi-Speaker Classification)機制
便可做出多語者對話環境中的語者分類與語音分割判
斷。本計畫運用 Matlab 程式完成了線頻譜對結合小波轉
換與支稱向量機在多語者對話環境中的語者分類與語音
分割之研究，並將計畫執行成果應用於多語者的對話環
境中。實驗結果顯示，本計畫完成的語者分類與語音分
割程式在八人的對話環境中，其分割與分類的正確率分
別高達 98.65%與 96.55%。 
II. 特徵參數擷取說明 
首先每個輸入的語音聲音訊號將被切割成 256 取樣
點長度(32 ms)、前後 50%重疊的音框，每個訓練音框先
通過 AMR 標準的聲音活動偵測 [33]，判斷是否為語音
段，若該音框屬於語音段則執行後續的特徵值擷取運
算，否則跳至下一個音框，重新偵測是否為語音段。判
定屬於語音段的音框會進行預強調(Pre-emphasizing)處
理，預強調處理演算法如下所示： 
1
' 96.0 −×−← nnn sss , 255,,1L=n ,                            (1) 
其中 ns 為音框 s 第 n-th 個取樣值，同時令 0'0 ss = 。之
後，經過預強調處理過的音框將再透過漢明視窗
(Hamming Window)濾波，其定義如下： 
ii
h
i hss *
'← , 255,,0L=i ,                                           (2) 
其中 )255/ 2cos(46.054.0 ihi π×−= 。最後再從每個經過
漢明視窗濾波過音框求取特徵值。本計畫預計採用的特
徵值包括次頻帶功率(Subband Power, Pj)、音高頻率(Pitch 
Frequency, fp )、音訊亮度 (Brightness, ωc)、音訊頻寬
(Bandwidth, B) 、頻率倒頻譜係數 (Frequency Cepstral 
Coefficient, FCC)以及線頻譜對(LSP)等六種特徵值。根據
文獻[25]顯示，利用前五種特徵值訓練所得的 SVM 分類
機制，在 16 種類別音訊的分類工作中，僅有 3%的錯誤
率，而最一項 LSP 參數，則可用來提高語者間的鑑別
性，增加語者分類的正確性。 
在這六種特徵值中，次頻帶功率以及音高頻率是經由
小波轉換求取，而音訊亮度、音訊頻寬以及頻率倒頻譜
係數是經由快速傅立葉轉換求取。最後，線頻譜對參數
則是透過無複數快速求解演算法取得。本計畫使用 3 階
小波轉換，其中 )(~ nh 及 )(~ ng 分別為分析低通及高通濾波
器，令{ } Z3 )( ∈nna 為輸入信號，則其輸出將為： 
∑ +−=
n
ii naknhka )()2(
~)( 1 ,                                         (3) 
∑ +−=
n
ii nakngkd )()2(~)( 1                                           (4) 
其中 )(kai 及 )(kdi 分別稱為對 )(3 na 進行小波轉換分析的
近似(Approximation)係數及細節(Detail)係數，考量運算量
及 分 頻 解 析 度 後 ， 本 計 畫 的 小 波 轉 換 預 計 採 用
Daubechies 8-Tap 的正交濾波器。 
 
(1) 次頻帶功率(Subband Power, Pj): 有三組不同頻帶寬
的次頻帶功率將被用於SVM-MSC計算，分別為
[0~1000Hz]、[1000~2000Hz]以及[2000~4000Hz]等三
組次頻帶，這三組次頻帶信號正好對等於小波轉換近
似係數與細節係數： )(0 ka 、 )(0 kd 以及 )(1 kd 。次頻
帶功率可由(3)計算求出，其中 )(kz j 代表第 j 階的小
波轉換近似係數與細節係數。 
∑=
k
jj kzP )(
2                                                          (5) 
(2) 音高頻率(Pitch Frequency, fp ): 本計畫所使用的音高
頻率搜尋演算法可分成四步驟達成，第一步驟為使用
小波轉換求取輸入語音信號的近似信號及細節信號，
第二步驟是利用第一步驟所獲得的近似信號來計算該
輸入語音信號的空間域相關函數；第三步驟則是在前
一步驟所求得空間域相關函數中擷取音高週期特徵
)22(cos
)53(2cos)4(4cos
)5(8cos16cos32)(
'
1
'
3
'
5
'
2
'
4
2'
1
'
3
3
'
2
4'
1
5
0
ppp
pppp
ppRP
+−+
+−+−+
−++=
ω
ωω
ωωω
          (24) 
)22(cos
)53(2cos)4(4cos
)5(8cos16cos32)(
'
1
'
3
'
5
'
2
'
4
2'
1
'
3
3
'
2
4'
1
5
0
qqq
qqqq
qqRQ
+−+
+−+−+
−++=
ω
ωω
ωωω
     (25) 
由於(24)、(25)需要大量的三角函數之計算，所以可
將上述的兩個頻率函數利用代數的方式將其改寫成
(26)、(27)，其中 )cos(ω=x ，x 的範圍為 ]1,1[ +− 。 
)22(
)53(2)4(4
)5(81632)(
'
1
'
3
'
5
'
2
'
4
2'
1
'
3
3'
2
4'
1
5
10
ppp
xppxpp
xpxpxxP
+−+
+−+−+
−++=
                 (26) 
)22(
)53(2)4(4
)5(81632)(
'
1
'
3
'
5
'
2
'
4
2'
1
'
3
3'
2
4'
1
5
10
qqq
xqqxqq
xqxqxxQ
+−+
+−+−+
−++=
                 (27) 
P10(x)及 Q10(x)兩組多項式之根將分別以 Pxi及 Qxi來
表示，而 LSP 的頻率可將其寫成ω2i-1=arccos(Pxi)及
ω2i=arccos(Qxi)，其中 i=1,…,p/2，LSP 之頻率順序如下
所示： 
 0 1 πωω <<<< PL , P 為偶數                        (28) 
3.2 無複數形式快速求解 LSP 演算法 
3.2.1 對 P10(x)多項式降階 
計算 P10(x)多項式之根，首先將此多項式做降階，
降階方法是採用一階導數，該動作主要是將 5 階多項式
轉為 4 階多項式，轉換後可使用改良型之 Ferrari 公式求
出 5 階多項式之極值，而降階後之 4 階多項式如下： 
)53(0125.0)4(05.0
)5(15.04.0)(
'
2
'
4
'
1
'
3
2'
2
3'
1
4'
10
+−+−
+−++=
ppxpp
xpxpxxP           (29) 
3.2.2 改良型 Ferrari 公式 
Ferrari 公式 [31]可直接求解一元四次方程式：
0234 =++++ dcxbxax x ，因此，可直接使用此公式求
解降階後的 4 階多項式 P ′10(x)，其實數根即 P10(x)之極
值。Ferrari 公式的定義如下： 
)]}
4
2([
2
{
2
1
1 S
PQRSqrtSaFx +−+−−=        (30) 
)]}
4
2([
2
{
2
1
2 S
PQRSqrtSaFx +−−−−=        (31) 
)]}
4
2([
2
{
2
1
3 S
PQRSqrtSaFx −−−+−=        (32) 
)]}
4
2([
2
{
2
1
4 S
PQRSqrtSaFx −−++−=      (33) 
其中 
dacbM 1232 +−= ， cabaP 843 −+−= ，
bddacabcbN 72272792 222 −++−= ， 
234 NMT +−= ，
( ) ⎟⎠
⎞⎜⎝
⎛ += 313
1
0 )(3/)2( TSqrtNMQ ，
( ) )23/()( 31311 ⋅+= TSqrtNQ ， 
10 QQQ += ， 3
2
4
2 baR −= ， )( QRSqrtS +=  
在 LSP 求解過中，其根大小之不等式為 
1234 xxxx FFFF <<<                                          (34) 
LSP 多項式之根必為實數根，被降階後的 P ′10(x)也
具有實數根，而利用 Ferrari 公式在運算過程所產生的複
數最後會被消除，但複數的存在使得計算量變大，為了
減少複數運算，可以將 Ferrari 公式中的複數移除。移除
的方法是將根號中所產生的負數值直接取絕對值以避免
複數的運算，又因 LSP 多項式的係數很小，所以在運算
過程根號中的值也很小，取絕對值後所產生的誤差也不
大，經過實驗運算後所得到的經驗值誤差範圍絕大部分
都小於 0.04。因此，Ferrari 公式改良後就不需要再進行
複數運算，而修改後的 Ferrari 公式如下： 
)]}([
2
{
2
1 '
2
''
1 USqrtS
aFx +−−=                            (35) 
)]}([
2
{
2
1 '
2
''
2 USqrtS
aFx −−−=                           (36) 
)]}([
2
{
2
1 '
1
''
3 USqrtS
aFx −+−=                           (37) 
)]}([
2
{
2
1 '
1
''
4 USqrtS
aFx ++−=                          (38) 
其中 
)4( 23' NMAbsT +−= ，
( ) ⎟⎟⎠
⎞⎜⎜⎝
⎛ += 3
1
'3
1
'
0 )(3/)2( TSqrtNMQ ，
( ) )23/()( 3131''1 ⋅+= TSqrtNQ ， '1'0' QQQ += ，
))(( '' QRAbsSqrtS += ， 
)
4
2( '
''
1 S
PQRAbsU −−= ，
)
4
2( '
''
2 S
PQRAbsU +−=  
在 LSP 求解過中，其根大小之不等式為: 
'
1
'
2
'
3
'
4 xxxx FFFF <<<                                             (39) 
3.2.3 P10(x)初始值之定義 
初始值定義是將改良型之 Ferrari 公式所求解出的極
值，再經由初始值之定義公式運算後可獲得一組較佳之
初始值給後續的 Newton 搜尋法使用，因 LSP 多項式根
之範圍為[-1,+1]，所以可將公式定義成(40)~(42)。其中
Init_Px1、Init_Px2、Init_Px3、Init_Px4、Init_Px5為 P10(x)之
初始值。 
2/)1(1_ '11 −−= xx FAbsPInit                              (40) 
.3,,1for ,                       
2/)(_ '' )1(
'
)1()1(
L=
−+= +++
i
FFAbsFPInit xiixixix       (41) 
況下，如圖 3 所示，在 X 空間中給定的非線性區分的樣
本可在 F 空間中線性分離。 
1+
1+
1+
1+
1+1+
1−
1−
1−
1−
1−
)1(−φ
)1(−φ
)1(−φ
)1(−φ
)1(−φ
)1(+φ )1(+φ
)1(+φ
)1(+φ
)1(+φ
)1(+φ
φ
X F
 
圖 3. 簡化分類工作的特徵映射示意圖 
 
目前已有很多求取可執行前述線性分割的超平面
(Hyperplanes)演算法被提出，典型的超平面可定義為
RRbw n ×∈),( ，其包含了所有滿足 0, =+>< bxw 條件的
變數 x ，因此，求取超平面的問題可歸納如下： 
⎪⎩
⎪⎨
⎧
≥+>< 1),(subject to 2
1minimize 2
bxwy
w
ii
                           (50) 
此問題可用 Lagrange 函數來求解，而(50)則進一步改
寫為 
∑∑∑
= ==
><−=
l
i
l
j
jijiji
l
i
i xxyyL
1 11
,
2
1)( αααα          (51) 
其中 iα  為具有 0
1
=∑
=
l
i
ii yα 以及 Ci ≤≤ α0 兩項限制的
Lagrange 乘法器(Multiplier)。假設某 *iα 可將(51)最大化，
則 對 於 任 何 k 使 得 Ck << *0 α ， (50) 的 解 即 為
i
l
i
ii xyw ∑
=
=
1
*α ， ∑
=
><−=
l
i
kiiik xxyyb
1
* ,α ，並可求得超平
面函數 ∑
=
+><=+>=<
l
i
iii bxxybxwxH
1
* ,,)( α ，而其決
定函數 ))(()( xHsignxf = 就可用來執行最佳分離。 
 
margin
hyperplane
iξ
γ
)(xH
 
圖 4. 使用 Soft-Margin SVM 克服少數樣本無法
分類的問題 
與標準 SVM 相比，Soft-Margin SVM 多加入了一組
Slack 變 數 0≥iξ ， 其 定 義 為
)),(,0max( bxwy iii +><−= γξ ，來解決無法完全達成非
線性分離的問題。如圖 4 所示，Slack 變數可量測出哪些
訓練集合的 Margin 值大於γ ，並將該分類失敗的訓練集
合進行統計。因此，使用 Soft-Margin SVM 可容許部份的
分類失敗，避免最佳分離超平面無法解出的情況。 
一般常用來作為非線性特徵對應的核函數有三種，
分別為：(1) 指數放射基底函數(Exponential Radial Basis 
Function, ERBF)，其定義為 )2/||exp(),( 2σxxxxK −−= ，
(2) 高 斯 函 數 (Gaussian Function) ， 其 定 義 為 
)2/||exp(),( 22 σxxxxK −−= ，其中參數σ 為高斯函數的
寬度，(3) 多項式函數(Polynomial Function)，其定義為
dxxxxK )1,(),( +><= ，其中參數 d 為多項式的階數。從
文獻[25, 26]中顯示，指數放射基底函數與高斯函數在分
類上具有較佳的效果，因此本計畫將比較使用指數放射
基底函數與高斯函數，測試何種核函數較適用於多語者
對話環境中的語者分類與語音分割判定。 
 
4.3 Multi-case SVM 
標準的 SVM 機制僅能執行 2 個類別之分類動作，換
句話說，標準 SVM 會將輸入的資料劃分成 Plus-class (+1)
類與 Minus-class (−1)類。因此，除了二人對話環境之
外，其餘的多人對話環境均需採用 Multi-case SVM 來執
行語者分類。目前常用的 Multi-case SVM 演算法有以下
四種 [25]： 
(1) One-against-one (1 對 1 演算法): 將輸入的資料與訓
練過的類別依序兩兩配對分類。 
(2) One-against-all (1 對全演算法): 先將輸入的資料歸類
為某一類，並將其他所有的資料視為另一類，接著開
始進行分類運算；前一程序分類完畢後，更換輸入資
料的類別，重複前述分類程序，找出分類誤差最小的
類別設定。 
(3) Top-down binary tree (由上而下之二元樹演算法): 將
所有訓練過的類別劃分成兩大群 A、B，輸入的資料
先與 A、B 群進行比對；若被判定屬於 A 群，則再將
A 群細分成兩群，重新比對；重複前述的程序，直到
最後分割的群內只有一個類別存在。 
(4) Bottom-up binary tree (由下而上之二元樹演算法): 與
Top-down binary tree 演算法相反，輸入的資料先和所
有訓練過的類別兩兩比對，排除誤差最大的類別，保
留其他類別；接著，輸入的資料再和保留下來的類別
兩兩比對，排除誤差最大的類別，保留其他類別；重
複前述的程序，直到最後只剩下一個類別被保留。 
從文獻[25]的分析中可得知，Bottom-up binary tree 所
需的運算複雜度最低，且從[25]的實驗結果得知，其在音
訊分類上的成效不比其他三種演算法差，因此本計劃將
採用 Bottom-up binary tree 演算法來達成 Multi-case 
SVM。 
最後將多語者對話環境中的語音訊號與與背景音訊
特徵向量送入 Soft-Margin Multi-case SVM 訓練，其訓練
所得的最佳超平面函數 H(x)便可用於多語者分類判斷。 
98.65%與 96.55%，未來將進一步應用本計畫所得的技術
在多媒體語音資料檢索方面的研究。 
 
參考文獻 
[1] 台 灣 網 路 資 訊 中 心 網 頁 資 料
http://www.twnic.net.tw/download/200307/0607.doc 
[2] 經 濟 部 商 業 司  iService 網 站 
http://www.find.org.tw/iservice/news_disp.aspx?news_id=4
102 
[3] Yahoo 科 技 新 聞 網 站 
http://tw.news.yahoo.com/article/url/d/a/061222/19/8c7h.ht
ml 
[4] S. Z. Li, ”Content-based audio classification and retrieval 
using the nearest feature line method,” IEEE Trans. Speech 
Audio Process., vol. 8, no. 5, pp. 619–625, 2000. 
[5] Jitendra Ajmera, Iain McCowan, and Hervé Bourlard, 
“Speech/music segmentation using entropy and dynamism 
features in a HMM classification framework,” Speech 
Communication, vol. 40, Issue 3, pp. 351–363, 2003. 
[6] Yi-Jian Wu, Hisashi Kawai, Jinfu Ni, and Ren-Hua Wang, 
“Discriminative training and explicit duration modeling for 
HMM-based automatic segmentation,” Speech 
Communication, Volume 47, Issue 4, pp. 397–410, 2005. 
[7] P. Clarkson and P. J. Moreno, “On the use of support vector 
machines for phonetic classification,” In Proc. IEEE Int. 
Conf. Acoustics, Speech, Signal Process., vol. 2, pp. 585–
588, 1999. 
[8] G. Guo and S. Z. Li, “Content-based audio classification and 
retrieval by support vector machines,” IEEE Trans. Neural 
Networks, vol. 14, no. 1, pp. 209–215, 2003. 
[9] T. Zhang and C.-C. Jay Kuo, “Audio content analysis for 
online audiovisual data segmentation and classification,” 
IEEE Trans. Speech Audio Process., vol. 9, no. 4, pp. 441–
457. 2001 
[10] Lie Lu, Hong-Jiang Zhang, and Hao Jiang, ”Content 
Analysis for Audio Classification and Segmentation,” IEEE 
Trans. Speech Audio Process., vol. 10, no. 7, pp. 504-516, 
Oct. 2002. 
[11] F. Itakura, ”Line spectrum representation of linear predictive 
coefficients of speech signals,” J. Acoust. Soc. Am., 57, 
535(A), Apr. 1975. 
[12] Wai C. Chu, Speech Coding Algorithms, John Wile & Sons, 
2003. 
[13] F. K. Soong and B. H. Juang, “Line spectrum pair (LSP) and 
speech data compression,” in Proc. ICASSP-84, pp. 1.10.1–
1.10.4, Mar.1984. 
[14] G. S. Kang and L. J. Fransen, “Low bit rate speech encoders 
based online spectrum frequencies (LSF’s),” Naval Res. 
Lab., Washington, DC, Rep. 8857, Nov. 1984. 
[15] P. Kabal and R. P. Ramachandran, “Computation of line 
spectral frequencies using Chebyshev polynomials,” IEEE 
Trans. Acoust., Speech, Signal Processing, Vol. ASSP-34, 
pp. 1419–1426, Dec 1986. 
[16] Wu Chung-Hsien and Chen Jau-Hung, “A Novel Two-Level 
Method for the Computation of the LSP Frequencies Using a 
Decimation-in-Degree Algorithm,” IEEE Trans. Acoust., 
Speech, Signal Processing, VOL. 5, NO. 2, pp 106-115, 
Mar.1997. 
[17] Shi-Huang Chen, Jiun-Ching Ruan, Jie-Siang Chen, Hsin-Te 
Wu, and T. K. Truong, “The Computation Of Line Spectrum 
Pair Using Modified Complex-Free Ferrari Formula,” 
ISPACS 2005, Dec. 13-16, 2005. 
[18] C.-T. Hsieh, E. Lai, and Y.-C. Wang, “Robust speech 
features based on wavelet transform with application to 
speaker identification,” IEE Proceedings- Vision, Image and 
Signal Processing, vol. 149, Issue 2, pp 108 – 114, 2002. 
[19] F. Phan,; E. Micheli-Tzanakou, S. Sideman, ”Speaker 
identification using neural networks and wavelets,” IEEE 
Engineering in Medicine and Biology Magazine, vol. 19, pp 
92-101, 2000. 
[20] Sungwook Chang; Y. Kwon, Sung-I Yang, ”Speech feature 
extracted from adaptive wavelet for speech recognition,” 
Electronics Letters, Vol. 34, pp 2211 – 2213, 1998. 
[21] H. Fenglei and W. Bingxi, ”Text-independent speaker 
recognition using support vector machine,” In Proc. Int. 
Conf. Info-Tech Info-Net, vol. 3, pp. 402–407, 2001. 
[22] P. Ding, Z. Chen, Y. Liu, and B. Xu, ”Asymmetrical support 
vector machines and applications in speech processing,” In 
Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process., 
vol. 1, pp. I-73–I-76, 2002. 
[23] A. Ganapathiraju, J. E. Hamaker, and J. 
Picone, ”Applications of support vector machines to speech 
recognition,” IEEE Trans. Signal Process., vol. 52, no. 8, pp. 
2348–2355, 2004. 
[24] W. M. Campbell, J.P. Campbell, D.A. Reynolds, E. Singer, 
and P.A Torres-Carrasquillo,” Support vector machines for 
speaker and language recognition,” Computer Speech & 
Language, vol. 20, Issues 2-3, pp. 210–229, 2006. 
[25] Chien-Chang Lin, Shi-Huang Chen, T. K. Truong, and 
Yukon Chang, “Audio Classification and Categorization 
Based on Wavelets and Support Vector Machine,” IEEE 
Transactions on Speech and Audio Processing, Vol. 13, No. 
5, pp. 644-651, Sept. 2005. 
[26] T. K. Truong, Chien-Chang Lin, and Shi-Huang Chen, 
“Segmentation of Specific Speech Signals from Multi-
dialogic Environment Using SVM and Wavelet,” Accepted 
to publish in Pattern Recognition Letters, 2007 
[27] V. N. Vapnik, Statistical Learning Theory. New York: 
Wiley, 1998. 
[28] F. Schwenker, “Hierarchical support vector machines for 
multi-class pattern recognition,” in Proc. IEEE Fourth Int. 
Conf. Knowledge-Based Intelligent Eng. Syst. Allied 
Technologies, vol. 2, pp. 561–565, 2000. 
[29] Shi-Huang Chen, Jhing-Fa Wang, “Noise-robust pitch 
detection method using wavelet transform with aliasing 
compensation,” IEE Proc. - Vision, Image and Signal 
Processing, Vol. 149, No. 6, pp. 327-334, Dec. 2002. 
[30] N. Sugamura and N. Farvardin, “Quantizer design in LSP 
speech analysis- synthesis,” IEEE Select. Areas Commun., 
vol. 6, pp. 432–440, 1988. 
[31] See http://mathworld.wolfram.com/QuarticEquation.html 
[32] Aurora 2 Database, 2000. (Online) 
<http://www.elda.org/article52.html> (accessed 12:07:06) 
[33] ETSI EN 301 708 V7.1.1, 1999. Voice Activity Detector 
(VAD) for Adaptive Multi-Rate. 
[34] G. Schwarz, “Estimating the dimension of a model,” The 
Annals of Statistics, vol. 6, pp. 461-464, 1978. 
 
 
 
 
 
 
 
 
 
 
  
出席國際學術會議心得報告 
計畫編號 NSC 96-2221-E-366 -011 - 
計畫名稱 利用無複數快速求解線頻譜對演算法結合支撐向量機與小波轉
換於多語者對話環境中的語者分類與語音分割之研究 
出國人員姓名 
服務機關及職稱 
陳璽煌 
樹德科技大學 資工系 助理教授 
會議時間地點 96年9月5日~ 96年9月7日，日本(Japan)熊本(Kumamoto) 
會議名稱 The Second International Conference on Innovative Computing, 
Information and Control (ICICIC 2007) 
發表論文題目 A Support Vector Machine Based Voice Activity Detection 
Algorithm for AMR-WB Speech Codec System 
 
一、參加會議經過： 
第2屆國際創新計算、資訊與控制研討會(The Second International Conference on 
Innovative Computing, Information and Control, ICICIC 2007)從2007年9月5日到9月7
日在日本熊本的熊本市國際會議中心(Kumamoto City International Center)舉行，
ICICIC會議是由IEEE、九州東海大學(Kyushu Tokai University)以及高雄應用科技
大學合辦，今年是第二屆舉辦，本屆ICICIC 2007收到來自全球各地研究專家學者
所投稿的1000餘篇論文，最後獲選列入議程的論文共有624篇，論文接受率約為
60%，算是水準不錯的研討會。個人投稿論文的題目為：A Support Vector Machine 
Based Voice Activity Detection Algorithm for AMR-WB Speech Codec System，論文編
號為C08-04, ICICIC-2007-IS10-004，發表的場次屬於Novel Approaches to Pervasive 
Applications分項，排在9月7日早上第一場第三位講者。該場次有五位講者，每位
講者可有15分鐘的時間來發表論文，時間稍嫌緊湊，因此僅能把論文研究成果大
約地介紹給與會人員。報告完畢後，主席僅提問一個問題，個人當場回覆後便回
座休息。Session結束之後，個人還觀摩了其他場次的論文發表，與廠商產品簡介，
作為教學及未來研究方向的參考。 
 
二、與會心得： 
個人從本次研討會中獲得不少Speech Classification、Speech Recognition, 
Digital Watermarking等相關主題的最新研究成果，並且與來自日本的研究學者面對
面交換學術意見，這些資料可作為日後研究方向的改進參考。本次會議主辦地點
是在熊本市國際會議中心，距離熊本城十分近，幾乎所有的與會人員都有順道參
觀熊本城，熊本城原本就是一個著名的景點，整座城區維護得極為完善，地上看
不到什麼垃圾，草皮也無踐踏後的光禿景象，綠意盎然，景致十分優美，漫步其
中的感覺相當不錯。本次會議在晚宴上有頒發大會論文獎的活動，個人的論文被
獲選為大會優良論文獎，沒想到個人的小小研究成果竟能獲得眾評審先進的青
