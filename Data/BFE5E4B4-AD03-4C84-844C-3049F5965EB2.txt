1. 前言 
本研究預計為期三年，工作目標為發展快速測站間光達點雲場景特徵偵測及自動匹配、影
像快速相對方位計算及進行光達點雲與影像之物像對應及品質評估，第一年度(即本研究報告
範圍)著重於現地場景光達資料之點雲特徵萃取與特徵匹配，藉由研擬之演算法於各掃描點雲
資料中獲取基本幾何元件，如點、直線與平面等特徵，並遂行特徵匹配建構特徵對應，使得後
續點雲資料套合、三維圖資整合或建構三維物件模型等應用之自動化作業程度，得以提升。本
報告詳述研擬之特徵萃取策略以及相應特徵匹配所創建之RSTG演算法，探討應用於一般場景
及災變場景之處理成效，並呈現具體工作事項及成果及後續發展可行方向。 
2. 研究目的 
光達系統依據不同載具可區分為地面、車載與空載三種平台，而不同系統平台具有不同的
場景適用時機。地面與車載光達之掃描型態可提供不同地面視角資訊，而移動性強的車載與空
載光達則可有效率進行大規模場景量測，但對於場景規模較小、交通運輸不便或道路已阻斷而
僅能徒步到達之區域，地面光達則具有較高的機動性與適用性。有鑑於此，考量對於一般場景
及災變區資料收集之通用性，本計畫所建構之演算策略已考量不同光達類型資料特性且適用於
各式光達系統，藉以提升實務作業之實用與適用性。本年度研究工作著重於光達資料之點雲特
徵萃取與特徵匹配，藉由研擬之演算法於各掃描點雲資料中獲取基本幾何元件如點、直線與平
面等特徵，並針對各萃取之特徵進行自動化匹配，建構特徵對應，提升後續點雲資料套合應用
亦或三維圖資成果整合建構三維物件模型之自動化作業程度。本報告詳述研擬之特徵萃取策略
以及相應特徵匹配所建構之RSTG演算法，並探討應用於一般場景及災變場景之處理成效。 
3. 光達點雲相關文獻 
3.1 特徵萃取相關研究 
光達掃描為非接觸式量測技術，因其具備較佳之自動化潛力，故隨著電腦設備運算效能提
升，諸多學者提出各式自動化演算法。光達掃描可在短時間內獲取大量的點雲資料，然也帶來
大量資料處理之困擾。雖然，離散的點雲藉由人腦視覺判斷亦可提供近似的視覺化空間概念，
但對於後續資料處理、災救規劃及復原重建等應用仍需從中擷取具有幾何意義或具代表性的場
景空間物件，而由場景中萃取出具幾何表徵之物件的程序稱特徵萃取。特徵萃取程序往往是處
理點雲資料之前端步驟，概觀相關之研究文獻，若僅基於光達點雲資料而無外加資訊條件下的
特徵萃取方式，現行研究中可概略區分為以下四種主要演算概念(Boyer and Sarkar, 1999): 區域
成長、參數空間、張量分析及影像處理等，各方法之概念將分述如下。 
(a).基於區域成長概念: 藉由各點與相鄰點為之位向關係或幾何關係進行判斷，若符合設
上可較有變通彈性以增加執行效率。 
3.2 特徵匹配相關研究 
三維特徵匹配往往為自動化點雲資料處理的關鍵程序，如何針對不同測站所萃取之幾何特
徵，自動且快速地建立特徵對應作為後續建構套合轉換或空間資料整合應用，亦為重要的研究
課題。Kilian et al. (1996)將離散點雲內插成網格高程影像，並使用影像特徵式匹配技術進行配
對，Vosselman and Maas (2001)則將點雲資料內插成不規則三角網並以共軛平面之距離進行平
差匹配；Burman (2000)將空載點雲內插成規則網格後，針對點位高程資料與反射強度值，以
Sobel 濾波器尋找坡度變化較大的點位當特徵點進行高程和強度值的匹配;；Akca and Gruen 
(2007)以廣義平差進行多表面平差匹配；Jaw and Chuang (2008)以空間幾何約制及最小二乘平
差指標進行三維直線特徵匹配。然而，現行演算法的之執行效率與自動化程度，以及對於災區
場景之適用性仍有待改進與評估。有鑑於此，本計畫提出快速三維幾何特徵匹配演算法，利用
多重幾何特徵(點、直線、平面)遂行三維幾何關係校正，篩選及確認最佳的共軛特徵對應，稱
為 RSTG 匹配法，其特徵匹配成果之正確性實乃根基於匹配過程中合理的轉換參數推求，因此
匹配的輸出不僅給予共軛特徵的對應，也建構起包含這些特徵的資料與資料間的三維空間轉換
關係。 
4. 研究方法 
本研究基於點、直線與平面三種空間幾何元件，針對特徵式點雲處理的主要兩個程序(特
徵萃取、匹配)分別提出多重特徵偵測元及 RSTG 匹配法，藉由不同特徵整合之效益因應一般
及災變區場景三維空間資訊收集任務。點雲特徵萃取須以明確、高品質且可靠的幾何特徵為目
標，平面特徵具有顯著的幾何辨別性與簡單的數學解析式，此部分之相關研究多針對平面特徵
為處理對象，然而，無論以何種光達平台進行點雲收集，平面特徵的分布幾何不免相對單調，
不易具體勾勒場景幾何以及獲得穩固且均勻的萃取成果。本研究建構的多重特徵偵測元藉由影
像處理與群聚分析方法，搭配由粗到細的執行策略，可有效率地基於原始點雲品質獲取精確的
直線、平面以及點特徵。接續之 RSTG 匹配法更可由萃取成果中獲取共軛特徵，並同時估計測
站間的近似轉換關係。 
本工作內容之幾何特徵參數表示方式包含點、直線及平面特徵參數，以點位三軸坐標
( ௜ܺ , ௜ܻ , ܼ௜ሻ 表 示 點 特 徵 ； 兩 直 線 端 點 坐 標 ( ࣦ൛ ௜ܺ,ଵ, ௜ܻ,ଵ, ܼ௜,ଵ, ௜ܺ,ଶ, ௜ܻ,ଶ, ܼ௜,ଶൟ ) 、 四 參 數 式
(ࣦሼ݀௜, ݁௜, 1, ݌௜, ݍ௜, 0ሽ)以及六參數式(ࣦሼݐ௜, ݑ௜, ݒ௜, ܺ଴௜, ଴ܻ௜, ܼ଴௜ሽ)表示三維直線特徵；而以三參數式
(࣪ሼߠ௜, ߮௜, ߩ௜ሽ或 ࣪ሼܽ௜, ܾ௜, ܿ௜ሽ)表示平面特徵。以上參數符號意義可詳參式(4.1)至(4.4)。 
4.1 多重特徵偵測元 
考量光達系統的取樣掃描特性，實際場景中的點特徵位置未必能忠實呈現於點雲資料中，
因此，若直接進行點特徵之萃取，其成果並不可靠。圖 4.1 為本研究基於一般及災變區場景提
    
   (a) 離散點雲      (b) 距離影像直線偵測     (c) 點雲切割      (d) 直線交會或擬合 
圖 4. 3 直線特徵萃取示意圖 
൥
௜ܺ
௜ܻܼ௜
൩ ൌ ൥
ܺ଴௜
଴ܻ௜ܼ଴௜
൩ ൅ ݇௜ ൥
ݐ௜ݑ௜ݒ௜
൩ ൌ ቈ
݌௜ݍ௜0
቉ ൅ ݖ௜ ൥
݀௜݁௜1
൩                                              (4.1) 
൜ܽଵܺ ൅ ܾଵܻ ൅ ܿଵܼ െ 1 ൌ 0ܽଶܺ ൅ ܾଶܻ ൅ ܿଶܼ െ 1 ൌ 0                                                       (4.2) 
其中，ሺܺ଴௜,  ଴ܻ௜, ܼ଴௜ሻ與ሾݐ௜ ݑ௜ ݒ௜ሿ்分別第݅條直線之參考點與方向向量；ሺ݌௜, ݍ௜, 0ሻ表示直線
特徵在X-Y平面上之穿刺點，而ሾ݀௜ ݁௜ 1ሿ்為對應之方向向量；݇௜、ݖ௜為常數。 
4.1.2 平面特徵萃取 
圖 4.4 呈現平面特徵萃取之處理程序，為確保特徵萃取之執行效率，研究中採用由粗到細
的執行策略。首先，將離散點雲內插成較原始解析度為粗的網格資料(如圖 4.5b)，並計算各子
網格的平面法向量(如圖 4.5c)，再藉由群聚分析方法找出各子網格的主要法向量方向並作為三
維平面霍夫轉換的參數近似值(如圖 4.5d)，如此可顯著降低霍夫轉換的計算量，大幅改善霍夫
轉換演算效率低之缺點。最後，針對霍夫轉換找出的平面點群進行平面擬合完成平面特徵萃取
作業。研究中所用之平面參數式分別如式(4.3)與式(4.4)所示。 
 
點雲資料 以較大之點兼具內插為網格資料
計算
各網格之法向量
法向量參數
群聚分析
三維平面霍夫轉換 平面擬合 三維平面特徵
 
圖 4. 4 平面特徵萃取流程 
知的尺度參數則可決定交會之點特徵點位。另外，以三個相鄰平面交會點特徵之目標函數如式
(4.7)所示，點特徵則可由式(4,8)導出。 
ቐ
݊ଵሬሬሬሬԦ · ܲݐ௜௡௧௘௥௦௘௖௧௘ௗ ൅ ݀ଵ ൌ 0, |݊ଵሬሬሬሬԦ| ൌ 1 
݊ଶሬሬሬሬԦ · ܲݐ௜௡௧௘௥௦௘௖௧௘ௗ ൅ ݀ଶ ൌ 0, |݊ଶሬሬሬሬԦ| ൌ 1
݊ଷሬሬሬሬԦ · ܲݐ௜௡௧௘௥௦௘௖௧௘ௗ ൅ ݀ଷ ൌ 0, |݊ଷሬሬሬሬԦ| ൌ 1
                                               (4.7) 
ܲݐ௜௡௧௘௥௦௘௖௧௘ௗ ൌ ିௗభሺ௡మሬሬሬሬሬԦൈ௡యሬሬሬሬሬԦሻିௗమሺ௡యሬሬሬሬሬԦൈ௡భሬሬሬሬሬԦሻିௗయሺ௡భሬሬሬሬሬԦൈ௡మሬሬሬሬሬԦሻ௡భሬሬሬሬሬԦ·ሺ௡మሬሬሬሬሬԦൈ௡యሬሬሬሬሬԦሻ                                         (4.8) 
4.2 RSTG 匹配法 
本研究提出之 RSTG 特徵匹配法可勝任多重幾何特徵之共軛對應搜尋並同時獲取匹配資
料間的近似坐標轉換關係。RSTG 分別代表旋轉(Rotation)校正、尺度(Scale)估計、平移
(Translation)校正與幾何(Geometry)檢查四個搜尋策略，可有效處理點、直線、平面特徵或群聚
離散點資料。在滿足最小觀測條件下各種特徵資料型態可聯合或單獨進行匹配運算，其成果對
於後續套合轉換除可提供共軛觀測量，亦可解決非線性估計之參數起始值給定問題。此外，有
鑑於幾何特徵收集途徑與品質之差異性，RSTG 匹配程序中亦考量各特徵觀測量之隨機性。圖
4.7 呈現 RSTG 匹配架構，各程序之概念與相應數學模式將簡要說明於後。流程中以兩筆資料
為處理對象，然其概念可擴展至多筆資料兩兩間之匹配作業。 
 
圖 4. 7RSTG 匹配架構 
旋轉矩陣ܴ的估計方法乃藉由常規化後的向量即可組成相似幾何矩陣ܴீ(Han, 2010)如式
(4.10)所示，其中 ሺܲଵሻ與 ሺܲଶሻ兩矩陣分別用以表示兩特徵資料之品質， ܥሺଵሻ與 ܥሺଶሻ矩陣則由各幾
何特徵資料之常規化向量堆疊而成，如式(4.11)。則針對相似幾何矩陣ܴீ施以奇異值分解後可
計算得旋轉矩陣。 
ܴீ ൌ ܥሺଶሻ் ሺܲଶሻ் ሺܲଵሻܥሺଵሻሺܥሺଵሻ் ሺܲଵሻ் ሺܲଵሻܥሺଵሻሻିଵ ൌ ܷߑ்ܸ                                    (4.10) 
ܥሺଵሻ ൌ
ۏێ
ێێ
ۍݒሺଵሻଵ்
ݒሺଵሻଶ்
ڭ
ݒሺଵሻ௡் ے
ۑۑ
ۑې , ܥሺଶሻ ൌ
ۏێ
ێێ
ۍݒሺଶሻଵ்
ݒሺଶሻଶ்
ڭ
ݒሺଶሻ௡் ے
ۑۑ
ۑې ሺ݊ ൒ 3ሻ                                            (4.11) 
ܴ ൌ ்ܷܸ                                                                     (4.12) 
其中，ܷ與்ܸ分別為兩正交矩陣，ߑ為對角矩陣。 
然而在估算旋轉矩陣前，尚需確定兩筆待匹配特徵資料間的共軛對應。 
4.2.1.1 初始匹配搜尋與轉換參數估計 
此階段之目的為搜尋初始共軛對應特徵，以進行旋轉矩陣、尺度與平移參數估計，因此僅
需搜尋足夠且幾何分布均勻的匹配成果即可，不需將所有資料逐一進行匹配，以降低計算負荷。
此程序首先依據特徵觀測量精度品質進行先後排序，再以排列組合建構可能配對參考表，使品
質較好的觀測量先行匹配，藉由反覆計算的程序待達到預設搜尋之配對數目或已無共軛特徵可
配對，則完成初始匹配。利用式(4.10)至式(4.12)所估計之旋轉矩陣是否可通過後續旋轉矩陣正
交性及一致性檢查，逐一過濾配對結果。 
4.2.2 尺度估計 
此階段程序之目的為估計兩筆待匹配資料間的尺度差異，使得 RSTG 匹配程序亦可適用於
處理特徵觀測量資料尺度不一致時的應用。而兩筆資料間的尺度差異可藉由一段空間距離在兩
筆資料間的差異比例進行估計，如式(4.13)所示。特徵間的空間距離對應則可分別利用初始匹
配成果估算獲得，如圖 4.9 所示。 
ܵ ൌ ሺ∑ ௜ܲ௡௜ୀଵ ሻିଵ ∑ ௜ܲ௡௜ୀଵ ௗ௜௦௧ሺమሻ೔ௗ௜௦௧ሺభሻ೔                                                    (4.13) 
其中，ܵ為尺度參數； ሺܲଵሻ與 ሺܲଶሻ兩矩陣分別用以表示兩距離觀測量之權重；݀݅ݏtሺଵሻ௜與݀݅ݏݐሺଶሻ௜則
分別表示在資料一與資料二中的相同距離。 
 
模式(Jaw and Chuang, 2010)將剩餘未匹配之特徵轉換至相同坐標基準上，如此不同特徵資料間
的尺度、旋轉與平移差異皆已消除，則共軛特徵在空間位置與角度上應具有一致性。因此，幾
何檢查程序乃針對特徵間的空間距離、角度以及與初始匹配特徵間的相對關係進行判斷。若差
異皆小於設定之門檻則是為共軛對應特徵，如此則可完成兩筆特徵資料間的匹配程序。 
5. 實驗成果與討論 
為檢視本研究提出之多重特徵偵測元與 RSTG 特徵匹配法之可行性與成效，實驗中分兩部
分進行測試驗證，並針對該演算法應用於一般場景及災變區域進行討論分析。 
5.1 特徵萃取測試 
本研究以兩組實際資料進行測試驗證，藉以呈現多重特徵偵測元應用於實際光達點雲資料
處理之效益。第一組測試資料為臺灣大學校史館之地面光達點雲資料。該筆資料是以 Trimble 
(Mensi) GS200地面光達系統進行收集，儀器製造商所宣稱定位精度在25公尺下約為2.5公厘。
第二組測試資料為成功大學校區之空載光達點雲資料，是以 Riegl LMS-Q680i 進行收集，量測
精度在 250 公尺下約為 20 公厘，兩筆點雲資料之相關資訊如表 5.1 所示。 
表 5. 1 點雲相關資訊 
光達系統 地面光達系統 空載光達系統 
點數 5,907,407 268,335 
平均掃描距離(公尺) 16.285 800 
點密度(點數/平方公尺) 14,360 4 
平均點間距(公尺) 0.001 0.500 
5.1.1 測試一 
第一組實驗資料場景如圖 5.1a 所示。藉由圖 4.1 之多重特徵偵測元之處理程序，共萃取出
32 條直線特徵與 8 個平面特徵，而表 5.2 呈現萃取特徵之量化品質評估指標。其中，
ሺߪௗതതത, ߪ௘തതത, ߪ௣തതത, ߪ௤തതതሻ、ሺߪ௔തതത, ߪ௕തതത, ߪ௖ഥ ሻ與ሺߪ௑തതത, ߪ௒തതത, ߪ௓തതതሻ分別代表直線、平面與點特徵參數之平均精度。視覺
化之萃取成果與程序中各階段成果分別呈現於如圖 5.1。其中，圖 5.1d 中的紅色直線為直線特
徵萃取成果，不同顏色區域表示不同平面萃取成果。 
表 5. 2 特徵成果品質指標 
 測試一 測試二 
直線特徵個數 32 49 
ߪௗതതത 0.0009 0.0116 
ߪ௘തതത 0.0008 0.0085 
ߪ௣തതത 0.003 公尺 0.038 公尺
ߪ௤തതത 0.003 公尺 0.029 公尺
平面特徵個數 8 40 
ߪ௔തതത 0.0070 0.0131 
ߪ௕തതത 0.0029 0.0102 
ߪ௖ഥ  0.0026 0.0191 
點特徵個數 s 0 13 
ߪ௑തതത N/A 0.133 公尺
ߪ௒തതത N/A 0.210 公尺
ߪ௓തതത N/A 0.111 公尺
5.1.2 測試二 
第二組實驗資料場景如圖 5.2a 所示。針對空載光達點雲資料共萃取出 49 條直線特徵、40
個平面特徵與 13 個點特徵，其特徵量化品質評估指標亦標註於表 5.2 中。視覺化成果呈現於
圖 5.2。 
  
                (a) 點雲資料                  (b) 距離影像邊緣偵測成果 
佳的狀況下之匹配成效。 
5.2.1 測試一 
圖 5.3 實驗區域之兩筆點雲資料重疊區域約 30%，因此多數所萃取出來之特徵應無正確的
共軛對應，藉由此實驗場景可驗證出 RSTG 匹配法對於匹配粗差之抵抗性(Robustness)。圖 5.4
呈現以多特徵偵測元萃取之 91 個幾何特徵成果，其中，紅色直線代表直線特徵，不同色彩之
點群代表萃取之不同平面特徵，而藍色菱形代表交會之點特徵。各類型特徵資訊如表 5.3所示。 
  
     (a) 點雲資料一                      (b) 點雲資料二 
圖 5. 3 測試一實驗場景 
  
     (a) 點雲資料一                      (b) 點雲資料二 
圖 5. 4 特徵萃取成果 
表 5. 3 取之特徵資訊 
 
 
點特徵 直線特徵 平面特徵 合計 
點雲資料一 6 29 17 52 
點雲資料二 4 22 13 39 
合計 10 51 30 91 
 
圖 5.5顯示萃取特徵之匹配成果，其中匹配之平面特徵以相同顏色呈現。以人工視覺檢查，
RSTG 在此次測試中可正確匹配所有共軛特徵，足以驗證其正確性與可行性。 
表 3. 1 特徵匹配成果 
觀測量隨機中誤差(公尺) േ0.01 േ0.03 േ0.05 േ0.1 
平均匹配率 (%) 98.83 96.10 92.5 85.90 
平均第一類錯誤率 (%) 1.16 3.90 7.50 14.10 
平均第二類錯誤率 (%) 0 0 0 0 
 
 
 
       (a) േ0.01 公尺隨機誤差               (b) േ0.03 公尺隨機誤差 
 
        (c) േ0.05 公尺隨機誤差              (d) േ0.1 公尺隨機誤差 
圖 5. 7 匹配統計成果 
5.2.3 討論與分析 
本研究提出的 RSTG 特徵匹配法應用於一般場景與災變場景之匹配成效，分別由測試一與
測試二成果獲得初步驗證。無論是針對含粗差之匹配抗拒性或對於災變場景複雜的幾何特徵分
布，RSTG 法皆可獲得良好的匹配成果。 
Geodetic Science and Surveying, The Ohio State University, Columbus, OH, USA. 
Lin, S.H., and J.J. Jaw, 2004. Structuralization of Lidar Point Cloud, Proceedings of 25th Asian 
Conference on Remote Sensing, Volume I, Chiang Mai, Thailand, pp. 102-107. 
Morgan, M., and A. Habib, 2002. Interpolation of LIDAR Data and Automatic Building Extraction, 
ACSM-ASPRS 2002 Annual Conference Proceedings, pp. 19-26. 
Pratt, V., 1987. Direct least-squares fitting of algebraic surfaces, Computer Graphics Proceeding 
SIGGRAPH ’87, 21(4):145–152. 
Rabbania, T., F.A. van den Heuvelb, and G. Vosselman, 2006. Segmentation of Point Clouds using 
Smoothness Constraint, ISPRS Commission V Symposium Image Engineering and Vision 
Metrology, pp.248-253. 
Roggero, M., 2002. Object segmentation with region growing and principal component analysis, 
Proceeding of the Photogrammetric Computer Vision, ISPRS Commission III, Symposium, 
pp.289-294, Graz, Austria. 
Schuster, H.F., 2004. “Segmentation of lidar data using the tensor voting framework”, in XXth ISPRS 
Congress: Geo-Imagery Bridging Continents, Commission III, volume 35, part B3. 
Tang, C.K., G. Medioni, and M.S. Lee, 2001. N-dimensional tensor voting and application to 
epipolar geometry estimation, IEEE Transac-tions on Pattern Analysis andMachine Intelligence, 
23(8), 829–844. 
Taubin, G., 1990. Estimation of planar curves, surfaces and nonplanar space curves defined by 
implicit equations, with applications to edge and range image segmentation. Technical Report 
LEMS-66, Division of Engineering, Brown University. 
Vosselman, G., and S. Dijkman, 2001. 3D building model reconstruction from point clouds and 
ground plans, International Archives of Photogrammetry, Remote Sensing and Spatial 
Information Sciences, 34(3):37-43. 
Vosselman, G., and H.G. Maas, 2001. Adjustment and Filtering of Raw Laser Altimetry Data. 
OEEPE Workshop on Airborne Laser scanning and Interferometric SAR for Detailed Digital 
Elevation Models, Stockholm, pp. 62-73. 
 
 
 
 
2 
 
   研討會 CD-ROM 論文集一份。 
四、所發表(口頭報告)文章詳如附件 
matching approach named RSTG to retrieve corresponding 
counterparts from unsorted multiple 3-D features, where 
different types of features can be integrated and employed 
simultaneously; Moreover, the RSTG can synchronously 
estimate the transformation parameters relating two data frames 
while establishing the correspondence. Notably, uncertainty of 
features be matched is taken into account with a weighting 
arrangement throughout the process, which is rarely considered 
in current matching methods. In addition, point-to-point 
correspondence is needless retrieving the translation parameters 
as the line-based similarity transformation model (Jaw and 
Chang, 2008) is employed. The methodology of the RSTG is 
given as follows.  
 
2 RSTG APPROACH 
The RSTG approach is strategically formulated towards finding 
out 3-D matching solution with high efficiency and leading to 
accomplishing the 3-D similarity transformation with four 
major processes, namely “Rotation alignment”; “Scale 
estimation”; “Translation alignment” and “Geometric check.” 
Starting from the rotation alignment step, RSTG produces a 
queue of possible associations for a set of features in both 
query and reference frame data. The decision whether the set of 
features is matched or not would be made by a judging function 
taking account into both similarity and relative geometry of 
features. This operation proceeds iteratively until the desired 
number of matches is achieved or there is no more matches 
found. That is to say, only some of qualified matches, called 
‘initial matches,’ are required in this phase as long as the 
matched mates are satisfactory for estimating scale and 
translation parameters in the subsequent procedures. Instead of 
exploring whole data, the strategy would significantly reduce 
the computational time. The remaining correspondence will be 
retrieved in the final phase.  
 
2.1 Rotation alignment 
The purpose of rotation alignment is to find out the initial 
matches, while constructing the rotation matrix between two 
data frames as illustrated in Fig. 1.  
 
 
Fig. 1. the workflow of rotation alignment 
 
At the beginning of the procedure, multiple features are first 
converted into the form of normalized vectors (NVs). This 
allows different types of features which may be collected 
through dissimilar methods with distinct scale can work 
together. Utilizing the form of NVs makes the RSTG approach 
a scale invariant algorithm. Additionally, the relevant scale 
would be reconstructed in the scale estimation step. The NVs of 
different features can be derived in both query and reference 
frames by: 
 
ۖە
۔
ۖۓݒሺଵሻ௜ ൌ ∆௉௧
ሬሬሬሬሬሬሬԦሺభሻ೔ೕ
ฮ∆௉௧ሬሬሬሬሬሬሬԦሺభሻ೔ೕฮ ݋ݎ
஽௩ሬሬሬሬሬԦሺభሻ೔
ฮ஽௩ሬሬሬሬሬԦሺభሻ೔ฮ ݋ݎ
ே௩ሬሬሬሬሬԦሺభሻ೔
ฮே௩ሬሬሬሬሬԦሺభሻ೔ฮ ݋ݎ
ఒ௩ሬሬሬሬԦሺభሻ೔
ቛఒ௩ሬሬሬሬԦሺభሻ೔ቛ
ݒሺଶሻ௜ ൌ ∆௉௧
ሬሬሬሬሬሬሬԦሺమሻ೔ೕ
ฮ∆௉௧ሬሬሬሬሬሬሬԦሺమሻ೔ೕฮ ݋ݎ
஽௩ሬሬሬሬሬԦሺమሻ೔
ฮ஽௩ሬሬሬሬሬԦሺమሻ೔ฮ ݋ݎ
ே௩ሬሬሬሬሬԦሺమሻ೔
ฮே௩ሬሬሬሬሬԦሺమሻ೔ฮ ݋ݎ
ఒ௩ሬሬሬሬԦሺమሻ೔
ቛఒ௩ሬሬሬሬԦሺమሻ೔ቛ
, ݅ ് ݆    (1) 
 
where ݒሺଵሻ௜  and ݒሺଶሻ௜  are the ݅௧௛  normalized vector in the 
query and reference frames, respectively; ∆ܲݐሬሬሬሬሬሬሬԦሺଵሻ௜௝  is the 
difference vector derived by the ݅௧௛  and ݆௧௛  points in the 
query; ܦݒሬሬሬሬሬԦሺଵሻ௜ , ܰݒሬሬሬሬሬԦሺଵሻ௜  and ߣݒሬሬሬሬԦሺଵሻ௜  individually stand for the 
݅௧௛ direction vector of a line, the ݅௧௛ normal vector of a plane 
and the ݅௧௛ eigenvector vector of a cluster of points in the 
query frame, whereas ܦݒሬሬሬሬሬԦሺଶሻ௜ , ܰݒሬሬሬሬሬԦሺଵሻ௜  and ߣݒሬሬሬሬԦሺଶሻ௜  represent 
their counterparts in the reference frame, respectively. 
Therefore, the relative geometric matrix ܴீ  can be established 
by Eq. (2), where ሺܲଵሻ and ሺܲଶሻ represent the weight matrices 
of features in query and reference frames, respectively; 	ܥሺଵሻ 
and 	ܥሺଶሻ matrices, as shown in Eq. (3), consist of stacking 
NVs acquired from multiple features with respect to each data 
frame. The normalized row vectors ݒሺଵሻ௡்  and ݒሺଶሻ௡்  can 
arbitrarily be acquired by points, lines, planes or clustered 
points with Eq. (1), and the ݊  in both ܥሺଵሻ  and ܥሺଶሻ  is 
defined in advance as long as it embraces at least three 
independent NVs forming the relative geometric matrix. 
Consequently, the rotation matrix is derived by using the SVD 
on the relative geometric matrix: 
ܴீ ൌ ܥሺଶሻ் ሺܲଶሻ் ሺܲଵሻܥሺଵሻሺܥሺଵሻ் ሺܲଵሻ் ሺܲଵሻܥሺଵሻሻିଵ ൌ ܷߑ்ܸ        (2) 
ܥሺଵሻ ൌ
ۏێ
ێێ
ۍݒሺଵሻଵ்
ݒሺଵሻଶ்
⋮
ݒሺଵሻ௡் ے
ۑۑ
ۑې , ܥሺଶሻ ൌ
ۏێ
ێێ
ۍݒሺଶሻଵ்
ݒሺଶሻଶ்
⋮
ݒሺଶሻ௡் ے
ۑۑ
ۑې ሺ݊ ൒ 3ሻ                 (3) 
	ܴ ൌ ்ܷܸ                                         (4) 
where ܴ is a rotation matrix; ܷ and ்ܸ are two orthogonal 
matrices, and ߑ is a diagonal matrix. However, to estimate a 
rotation matrix, the correspondences between features in the 
query and reference frames has to be investigated in advance. 
The way to find initial matches is described as follows. 
 
2.1.1 Matches Mining via Rotation Estimation: Assume 
that there are ݉ଵ and ݉ଶ NVs in each query and reference 
frame, and the row number of matrices ܥሺଵሻ and ܥሺଶሻ is given 
as ݊. The process starts from generating a short list for all 
possible connections between the NVs in each frame by using 
the permutation to pick ݊  NVs from ݉ଵ  and ݉ଶ 
individually, and then implementing the combination for the set 
of NVs. During the iterative calculation, the order and the 
ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume I-3, 2012 
XXII ISPRS Congress, 25 August – 01 September 2012, Melbourne, Australia
124
the relative connections of conjugate features in the query and 
reference data would be comparatively similar with each other. 
Finally, these three constraints make certain erroneous matches 
disappear from the final matching result, and features in the 
query data are all explored for correspondents. Notably, the 
thresholds involved are all determined by the error propagation 
based on the uncertainty of features. In addition, a feature may 
have multiple corresponding mates as long as they all pass 
through the constraints. 
 
3 EXPERIMENTAL ASSESSMENTS 
For a practical matching algorithm, the effectiveness and 
efficiency are the most significant issues that should be verified. 
Therefore, the RSTG approach was inspected with both a 
statistical assessment and a real case to prove the feasibility and 
the effectiveness. The explicit setting of each examination is 
introduced as follows. 
 
3.1 Statistical Assessment 
All experiments in this assessment were performed by multiple 
3-D features. We investigated the performance and efficiency 
which related to the distribution and uncertainty of features 
between two data frames. The experiments were carried out 
repeatedly for 100 times to derive a statistic result. There 
comprised 40 points, 30 lines and 30 planes, 100 features 
totally, generated randomly for every calculation. That is, the 
distribution of features changes every time. Besides, random 
errors, ranging from 0.01m to 0.1m, were also added to 
simulate the uncertainty of features. As shown in Table 1, the 
type 1 error is defined as the wrong decision that rejects a true 
match, whereas the type 2 error indicates the error that fails to 
reject a false match. The statistical results reveal that the RSTG 
reached an average successful matching rate of 98.83% while 
the feature were added with േ 0.01m random errors; an 
average successful matching rate of 85.9% while the features 
were added with േ0.1m random errors. It is worth to point out 
that the percentage of statistical type 2 error, which has critical 
influences on the matching reliability, was kept 0% throughout 
all tests. The operations took an average time of 67.87 seconds 
to accomplish the matching based on Intel i5 CPU 2.53GHz in 
Matlab. Yet, the efficiency would highly depend on 
programming skills and language, facilities, and so on. It still 
has space for further optimization. The statistical illustrations 
are shown in Fig. 2, where the blue square line indicates the 
݅௧௛ successful matching rate; the red dotted line is the average 
successful matching rate; the green star line represents the type 
1 error, and the cyan star line denotes the type 2 error. 
 
Table 1. the matching performance.  
Std. of features (m) േ0.01  േ0.03  േ0.05 േ0.1
Avg. matching rate (%) 98.83 96.10 92.5 85.90
Avg. type 1 error (%) 1.16 3.90 7.50 14.10
Avg. type 2 error (%) 0 0 0 0 
Avg. operation time (sec) 72.2 70.4 67.5 61.4
 
 
(a) േ0.01m random errors   (b) േ0.03m random errors 
 
(c) േ0.05m random errors   (d) േ0.1m random errors 
Fig. 2. the statistic results. 
 
3.2 The Real Case 
Due to visibility constraints from a single terrestrial laser 
scanner, scenes are normally performed by combining multiple 
overlapping scans into a single data set. It depends on the 
correspondents in different scan to establish the transformation.  
Assuming that the features in each scan had been acquired 
already, the RSTG approach assisted in finding out the 
corresponding features in an automatic fashion. There were five 
successive scans, marked “S-1”, “S-2”, “S-3”, “S-4” and “S-5”, 
collected by Trimble (Mensi) GS200 describing the front door 
of National Taiwan University in Taiwan. The nominal 
positional accuracy of 4 shots as reported by Trimble (2005) 
was up to 2.5mm at 25m range. The extracted features totally 
contained 21 points, 46 lines and 22 planes as illustrated in Fig. 
8 with white colour, and the relevant uncertainty was derived 
based on error propagation from the origin accuracy of point 
clouds. 
 
 
(a) S-1           (b) S-2            (c) S-3 
 
(d) S-4           (e) S-5 
Fig. 3. the point clouds and extracted features. 
 
Although the LiDAR point clouds were scanned sequentially, 
we assumed that we didn’t have the information so feature 
matching between scans were performed randomly. Once a 
data set has matched, it would not be involved again in 
ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume I-3, 2012 
XXII ISPRS Congress, 25 August – 01 September 2012, Melbourne, Australia
126
point clouds, in: Optical 3D Measurement Techniques VI, 
volume 1, Zurich, Switzerland, pp. 330–337. 
 
Ankerst, M., Kastenmuller, G., Kriegel, H. P., and Seidl, T., 
1999. 3D shape histograms for similarity search and 
classification in spatial databases. In Proc. SSD. 
 
Belongie, S., Malik, J., and Puzicha, J., 2001. Matching shapes, 
ICCV. 
 
Besl, P.J., and McKay, N.D., 1992. A method for registration 
of 3D shape, IEEE Trans. Pattern Analysis and Machine 
Intelligence, 14(2), 239-256. 
 
Chen, Y., and Medioni, G., 1992. Object modelling by 
registration of multiple range images, Image and Vision 
Computing, 10(3), 145-155. 
 
Chen, D. Y., Ouhyoung, M., Tian, X. P., and Shen, Y. T., 2003. 
On visual similarity based 3D model retrieval, Computer 
Graphics Forum, pp. 223.232. 
 
Chua, C., and Jarvis, R., 1996. Point signatures: A new 
representation for 3D object recognition, International Journal 
of Computer Vision 25(1), 63-85. 
 
Dold, C. and Brenner, C., 2006. Registration of terrestrial laser 
scanning data using planar patches and image data, in: The 
International Archives of the Photogrammetry, Remote Sensing 
and Spatial Information Sciences, volume 36, pp. 78–83. 
 
Franaszek, M., Cheok, G.S., and Witzgall, C., 2009. Fast 
automatic registration of range images from 3D imaging 
systems using sphere targets, Automation in Construction 18, 
265–274. 
 
Gal, R., and Cohen-or, D., 2006. Salient geometric features for 
partial shape matching and similarity, ACM Transaction on 
Graphics. 
 
Gelfand, N., Mitra, N. J., Guibas, L. J., and Pottmann, H., 2005. 
Robust global registration, Eurographics Symposium on 
Geometry Processing , pp. 197–206. 
 
Gruen, A., and Akca, D., 2005. Least squares 3-D surface and 
curve matching, ISPRS Journal of Photogrammetry and 
Remote Sensing, 59(3), 151-174. 
 
Habib, A., Mwafag, G., Michel, M., and Al-Ruzouq, R., 2005. 
Photogrammetric and LiDAR data registration using linear 
features, Photogrammetric Engineering & Remote Sensing, 
71(6), 699–707. 
 
Heczko, M., Keim, D., Saupe, D., and Vranic, D., 2002. 
Methods for similarity search on 3D databases, 
Datenbank-Spektrum, 2, pp. 54-63. 
 
Huang, J., and Menq, C. H., 2001. Automatic data 
segmentation for geometric feature extraction from 
unorganized 3-D coordinate points, IEEE Transactions on 
Robotics and Automation (17): 268–278. 
 
Jaw, J.J., and Chuang, T.Y., 2008. Registration of LIDAR point 
clouds by means of 3D line features, JCIE Journal of the 
Chinese Institute of Engineers, 31(6), 1031-1045. 
 
Jaw, J.J., and Chuang, T.Y., 2010. On the effectiveness of 
feature-based LIDAR point cloud registration, 
Photogrammetric Computer Vision and Image Analysis, ISPRS 
Comm. III Symposium, 38(3B), pp. 60-65. 
 
Kim, C., Lee, J., Cho, M., and C. Kim, 2011. Fully automated 
registration of 3D CAD models with point cloud from 
construction sites, in: Proceedings of the International 
Symposium on Automation and Robotics in Construction 
(ISARC), vol. 2,pp. 311–316. 
 
Li, X., and Guskov, I., 2005. Multi-scale features for 
approximate alignment of point-based surfaces, Symposium on 
Geometry Processing. 
 
Rabbani, T., Dijkman, S., Heuvel, F., and Vosselman , G., 2007. 
An integrated approach for modelling and global registration of 
point clouds, ISPRS journal of Photogrammetry and Remote 
Sensing, 61, 355-370. 
 
Trimble, 2005. GS200 Declaration of conformity, 
http://www.accupoint.com/uploads/ebay/Untitled.PDF. 
 
Xu, Z., and Li, Z., 2000. Least Median of Squares Matching for 
Automated Detection of Surface Deformations, Int’l Archives 
of Photogrammetry and Remote Sensing, vol. 33, no. B3/2, pp. 
1000-1007. 
 
Zhang, Z., 1994. Iterative point matching for registration of 
freeform curves and surfaces, International Journal of 
Computer Vision, 13(2), 119-152. 
ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume I-3, 2012 
XXII ISPRS Congress, 25 August – 01 September 2012, Melbourne, Australia
128
100年度專題研究計畫研究成果彙整表 
計畫主持人：趙鍵哲 計畫編號：100-2221-E-002-216- 
計畫名稱：光達點雲與影像之物像對應及品質評估 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 0% 撰寫中 
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 2 0% 撰寫中 
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
