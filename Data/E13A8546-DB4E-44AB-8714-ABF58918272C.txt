skin-color model, face tracking and eye tracking, our 
system can work well for face tracking and 
recognition in various illumination and face angle 
conditions. Furthermore, to speed up the search of 
videos with a requested target in a large variety of 
video contents, this work uses a new method to merge 
the neighboring frames of interest into a video clip 
instead of using the conventional shot detection 
method.  
 
The proposed method can effectively extract faces and 
their eyes in images； in addition, it also can 
greatly expedite the process of video sequences. 
Because the extracted feature vector of faces is 
highly discriminative, only a simple classifier, such 
as Euclidean distance or nearest feature line 
classifier, is required to achieve a high correct 
recognition rate. Moreover, the proposed method can 
be operated in a real-time environment since we 
abandon the use of shot detection method that is very 
computationally intensive. 
英文關鍵詞： face tracking, eye tracking, face recognition, skin-
like color background 
 
中文摘要 
近年來由於科技的進步，使得多媒體設備的使用變得更為普遍，也使得視訊內容的保
存變得更為容易，但同時也產生許多冗餘的訊視垃圾，讓視訊內容的搜尋變得更為困難。
由於這個緣故，本研究提出一基於人的視訊檢索系統，嘗試解決此一惱人問題。 
藉由改善影像中人臉與人眼追蹤技術，本研究提出一強健性膚色模型以輔助類膚色複
雜環境下之人臉追蹤。同時，為確保膚色模型所提取人臉之準確性，本研究另外提出一人
眼追蹤方法以再次確認候選人臉就是真正的人臉。透過上述膚色模型、人臉追蹤與人眼追
蹤等三大關鍵技術，本研究確實可於各種不同環境（光線、角度）下進行人臉追蹤與識別。
再者，為求能在大量視訊內中進行快速的搜尋與處理，本研究放棄現行的分鏡偵測技術，
改由使用自行提出的鄰近影像區段合併方法，將所有感興趣的視訊區段進行合併。 
本研究所提方法能有效地提取出人臉與人眼特徵，同時也能加快視訊影像處理的速
度。由於提取的人臉特徵向量具有高度鑑別性，在分類方面，僅需利用簡單的分類器，例
如歐氏距離或最近特徵線分類器(nearest feature line classifier)，即可達到相當高的正確辨識
率(correct recognition rate)。同時，由於放棄運算密集的分鏡偵測技術，使得本研究所提方
法可運行於即時系統(real-time system)中。 
關鍵詞：人臉追蹤、人眼追蹤、人臉識別、類膚色背景 
英文摘要 
 In recent years, the advance in science technology makes the use of multimedia devices 
more popular and the storage of video contents easier, but it also produces many redundant video 
garbage, which causes the search of video contents of interest more difficult. To solve this 
annoying problem, a human-based video retrieval system is presented. 
 By improving the tracking technique of human faces and their eyes in images, we propose a 
robust skin-color model to assist the face tracking against a skin-color-like complex background. 
To validate the face candidates detected by the skin-color model to be the true ones, an eye 
tracking method is presented. By using the three proposed methods of skin-color model, face 
tracking and eye tracking, our system can work well for face tracking and recognition in various 
illumination and face angle conditions. Furthermore, to speed up the search of videos with a 
requested target in a large variety of video contents, this work uses a new method to merge the 
neighboring frames of interest into a video clip instead of using the conventional shot detection 
method.  
 The proposed method can effectively extract faces and their eyes in images; in addition, it 
also can greatly expedite the process of video sequences. Because the extracted feature vector of 
faces is highly discriminative, only a simple classifier, such as Euclidean distance or nearest 
feature line classifier, is required to achieve a high correct recognition rate. Moreover, the 
proposed method can be operated in a real-time environment since we abandon the use of shot 
detection method that is very computationally intensive. 
 
Keywords: face tracking, eye tracking, face recognition, skin-like color background 
 
   
上，常用的方法有：(1)基於背景信息追蹤：Bala等人[3]利用視訊中前後景分析，並結合彩
色資訊對整體人臉進行追蹤；同時採用區塊匹配，對人的雙眼進行快速追蹤；(2)基於運動
信息追蹤：Liu等人[4]首先利用運動資訊提取運動區域，並運用人臉的膚色與輪廓，進行人
臉目標的篩選，進而取得候選目標，最後利用貝氏網路(Bayesian network)對候選目標進行
確認，該方法可以用來追蹤部分遮擋的人臉。Black與Yacoob[5]則是應用光流場演算法計算
人臉運動，該方法用簡單直觀的參數模型來描述人臉的運動，估計出的參數還可以用來作
進一步的人臉表情識別，但這種方法只適合於中等大小的人臉運動，對大幅度的人臉運動
有一定的局限性；(3)基於彩色信息追蹤：Sobottka等人[6]採用HSV色彩空間進行膚色分割，
並利用臉部特徵的對稱性定位人臉，然後利用Snake演算法對整體人臉進行主動輪廓跟蹤。
同樣的方法，Hunke等人[7]則是結合了色彩與運動資訊，實現了視頻中即時的人臉追蹤。 
以基礎理論說來，人臉辨識分成兩個部份，即特徵擷取(feature extraction)與分類階段
(classification)。在特徵擷取階段，即是指利用子空間轉換技術，將高維度的原影像空間投
影至較低維度之影像空間，這種技術常見的有：主分量分析法(principle component analysis; 
PCA)，又稱特徵臉法、線性鑑別分析法(linear discriminant analysis; LDA)，又稱費雪臉法
(Fisher’s face method) [8]，與獨立分量分析法(independent component analysis; ICA) [9]。至
於分類階段，常用的分類器有：歐氏距離分類器(Euclidean distance classifier)，最近特徵線
分類器(nearest feature line classifier)、類神經分類器(neural network classifier)與支持向量機
(support vector machine; SVM)等。 
在以人為主的檢索系統中，Satoh等人[10]開發了一套視訊檢索系統，名稱為Name-It，
主要用在新聞視訊(news video)中特定人物的搜索。本套系統主要依賴字幕中特定關鍵詞(這
裡是人名)的擷取，再配合人臉影像的抽取，以偵測出特定人物(例如Clinton)出現在新聞中
的所有視訊片段(video shots)。這個研究與我們所提計畫最大的不同點，在於我們研究的視
訊影片中，並不見得會有字幕可以運用，而且在大部分家庭所攝錄的影片中，可能有很大
一部分都是沒有字幕的，在這種情形下，Name-It根本無法運作，因此我們所提的這個子計
畫是以人臉識別的角度切入進行研究。 
 
(四) 研究方法 
 
本研究主要致力於開發一強健性的人臉追蹤方法，此一方法分為類膚色複雜環境下之
人臉追蹤與眼睛定位等兩大部分，透過此一方法可以有效地在複雜背景下提取人臉，緊接
著，我們使用主分量分析法來降低所提取人臉的影像維度，並使用最近特徵線分類器作為
辨識的分類器。 
在檢索系統的建構與使用上，本研究採用網路上可搜尋取得的各式照片作為訓練樣本
對分類器進行訓練。完成訓練後的分類器可對使用者所輸入的影片進行人臉識別，該分類
器針對影片中每個影像框(frame)內進行運算，並記錄所有影片中出現感興趣對象之影像
框，最後將所有鄰近的影像框合併為一影像區段供使用者使用，其詳細流程如圖一所示： 
  
首先，我們認為一段影像序列通常會將主要人物置於畫面中央，於是本研究採用Sobel
邊緣檢測的方式提取影像邊緣，接著使用填滿運算元(fill operation)將畫面中央的邊緣區域
一一填滿，並將該填滿區域視為感興趣區域，並在該區域內對原彩色影像進行膚色分析。
取得膚色分析後之二值化影像，並對該影像進行型態學運算與直方圖統計，緊接著從直方
圖的左右兩側往中間搜尋最鄰近的山谷點(見圖三中的V1與V2)，利用這兩個點可以有效地
提取出人臉準確的位置並去除類膚色背景。經去除背景後的膚色區塊被視為人臉候選區
塊，針對各候選人臉區塊進行人臉幾何匹配(常見為橢圓形模板匹配)與熵值計算，以剔除不
符合規範(criteria)的候選區塊，最後所留下的區塊即為人臉。 
 
圖三、利用水平投影直方圖去除類膚色背景：(a)原始候選人臉區塊；(b)去除類膚色背景
後之候選人臉區塊；(c)利用直方圖山谷法去除類膚色背景 
 
傳統的膚色模型由於受限於光線因素，經常只能使用在特定的場合下，而使得其推廣
性大大的降低。本研究為去除光線因素對膚色模型的影響，採用HSL色彩空間轉換之方法，
將一色彩空間轉換至HSL空間，藉以分離出光線與色彩通道，並將轉換後會影響到RGB色
彩空間的S與L空間調整至該空間最飽和的狀態（即S=1、L=0.5），調整後再將該影像轉換
回RGB色彩空間，結果發現原始彩色影像僅存在於G通道，如圖四所示。進一步，為了定
義新的膚色模型範圍，本研究配合文獻[11]所提出的膚色模型，再從人臉資料庫中擷取出約
十萬點膚色來進行分析，分析後求得之膚色範圍為R=255、G介於25~201之間與B=0，其分
析統計值如圖五所示。 
 
 圖四、膚色模型統計方法 
   
候選區塊分別計算其質心與重心所在位置，並依質心與重心相距之歐幾里得距離作為人眼
判別的依據，其相關流程如圖七所示。 
 
 
 圖七、人眼篩選方法 
 
4.3 分類器訓練與鄰近影像合併 
 
本研究經由上述兩個方法可以準確地決定出人臉與人眼所在位置，由於本方法並不是
依照人臉幾何來尋找雙眼，因此可以容許人臉有小角度之旋轉，如此一來，不同角度人臉
所形成的樣本空間將使得PCA特徵空間更為完整，因此本研究僅使用簡單的最近特徵線分
類器即可達到高準確度的分類效果。對於鄰近影像合併成單一視訊區段(video clip)，其概念
為：對任一搜尋標的物而言，其必定出現在連續相鄰的影像框中，就算當中有若干張影像
框因為某些原因無法偵測到它的存在，我們依然可將之納入具該搜尋標的物之視訊區段內。 
 
(五) 結果與討論 
 
為驗證本研究所提膚色模型、類膚色背景下人臉追蹤方法，與眼睛定位方法為有效率
且具推廣性(generalization)，我們進行一序列各種不同環境下之試驗。圖八為本研究所提膚
色模型與其它方法之比較，由圖中可看出本研究所提膚色模型可以有效地提取出各種不同
人種之膚色區塊，同時所提膚色模型對於嘴唇、眼睛、鼻孔等五官特徵擁有更好的分割效
果。圖九是本研究所提類膚色背景下人臉追蹤方法之結果，由該圖可發現，本研究所提方
法可以準確的在類膚色背景下搜尋出人臉所在的位置；除此之外，本方法也可以準確的分
離出與臉部相連接的人體膚色區塊，例如手部與人臉相連接等。 
   
圖十與圖十一分別展示本研究所提人臉與人眼追蹤方法可適用於多種不同的人臉角
度。圖十二與圖十三顯示本研究除了適用於不同的人臉角度外，同時也適用於各種不同的
光線環境。圖十四為整合本研究所提方法所發展出的一套人臉檢索系統，由圖中可知所提
方法能在各種不同的人臉角度下，進行人臉特徵提取與識別，其中圖十四中的左圖為本研
究自行拍攝之測試短片，右圖為人臉訓練資料。在訓練完成後，本系統可識別出測試短片
中所出現的人物，並標示其姓名；而圖十五則列出欲檢索標的在該測試短片中出現的影像
框編號。 
 
 圖十二、昏暗光線下人臉追蹤之結果 
 
 圖十三、各種光源下人眼追蹤之結果 
 
 
 圖十四、各種不同角度下人臉訓練影像與人臉識別結果 
   
   
on Feature Analysis and Edge Detection against Skin Color-like Backgrounds,” Pro. of the 
4th International Conference on Genetic and Evolutionary Computing (ICGEC2010), IEEE 
Computer Society Press, Shenzhen, China, Dec. 13-15, 2010, pp. 687-690. 
2. Deng-Yuan Huang, Ta-Wei Lin, Wu-Chih Hu, and Mu-Song Chen, “Eye detection based 
on skin color analysis with different poses under varying illumination environment,” IEEE 
Proceedings of the 5th International Conference on Genetic and Evolutionary Computing 
(ICGEC2011), IEEE Computer Society Press, Kinmen, Taiwan, Aug. 29-Sep. 1, 2011, pp. 
252-255. 
 
表 Y04 
機場，再轉乘接駁車到達哈工大研究生院附近之旅館-深圳維也納酒店(大學城店)。論文發表
時間排在 12 月 13 日到 12 月 15 日舉行，主辦單位在議程的安排，會場設備的佈置，和交通
等各方面的安排都相當盡心盡力，因此會議的進行仍然很順利圓滿，充份達到了資訊交流和
增廣見聞的目的。大會除了論文發表的議程之外，也費心安排了廠商參展等活動，以便與會
人士能進一步了解相關領域研究之應用。 
 
 大會在 12 月 14 日晚上舉行晚宴餐會，並頒發 ICGEC2010 最佳論文獎，本人與澎湖科大
胡武誌教授發表的論文「Automatic video object segmentation with opacity estimate」有幸獲得
大會最佳論文獎，也是對我們研究的一種肯定。透過晚宴的進行，本人和與會人士進行學術
研究心得交換，大家並交換名片，以便日後保持聯繫。 
 
二、與會心得 
 
 本次會議計有 210 多篇論文發表，主題的涵蓋範圍非常廣泛，可謂充份探討計算機科學
中基因(genetic)、演化(evolutionary)與智慧(intelligence)計算相關研究的各種理論和應用層面。
在本次大會中，本人與澎湖科大胡武誌教授共同主持一個議程「Intelligent video processing」，
本議程計有 8 篇論文發表，本人在此次大會發表的論文題目為「類膚色背景下基於特徵分析
與邊緣偵測之人臉偵測 (Face detection based on feature analysis and edge detection against skin 
color-like backgrounds)」。因為筆者目前的研究較投注於視訊與影像處理等領域上，故筆者大
多參與大會中與視訊與影像處理有關的主要場次，以及在智慧型計算相關之應用上。綜觀有
關視訊與影像處理、智慧型計算的主題及重點，可以歸納如下： 
a. 粒子群最佳化(Particle swarm optimization) 
b. 基因、演化與智慧計算(Genetic, evolutionary and intelligent computation) 
c. 語言處理、分類與資料採礦(Language processing, classification and data mining) 
d. 視訊與影像處理(Video and image processing) 
e. 智慧服務(Intelligence service) 
 
此次參加 ICGEC2010 會議，認識了許多世界各地同樣為 Intelligent computing 等領域的研
究人員。本次與會的學者遍佈相當廣泛，在亞洲方面包括有日本、台灣、印度、中國、馬來
西亞與伊朗等，其它尚包含來自英國與澳大利亞等國的學者等。在會議期間，當然也有接觸
Face detection based on feature analysis and edge detection against skin color-like 
backgrounds 
 
Deng-Yuan Huang, Ta-Wei Lin, Chun-Ying Ho 
Department of Electrical Engineering 
Dayeh University 
Changhua, Taiwan 
kevin@mail.dyu.edu.tw 
Wu-Chih Hu 
Dep. of Computer Science and Information Engineering 
National Penghu University of Science and Technology 
Penghu, Taiwan 
wchu@npu.edu.tw 
 
 
Abstract—In this paper, we propose a method of face detection 
based on feature analysis and edge detection against skin color-
like backgrounds. The proposed method consists of three 
phases including image preprocessing, skin color segmentation, 
and determination of face candidates. First, the objects in 
foreground are separated by image preprocessing. Second, the 
non-skin color objects are rejected by the method of skin color 
segmentation. Finally, both the elimination of skin color-like 
blobs in backgrounds and face detection are performed by the 
method of determination of face candidates. Experimental 
results show that the proposed method can effectively detect 
most of faces in skin color-like backgrounds. In addition, 
detection of face images with pose and expression variations or 
against dark backgrounds are also carried out. 
Keywords-face detection; skin-color segmentation; edge detection 
I. INTRODUCTION 
Recently, face detection has greatly attracted much 
attention of numerous researchers due to its wide variety of 
applications such as face recognition, human-computer 
interface (HCI), video surveillance, access control, and 
content-based image retrieval (CBIR). In real-world 
applications of face detection, speed and detection rate are 
two critical issues about which people most concern. During 
the past decade there has been a proliferation of literature on 
effective methodologies to improve the performance of 
detection rate. However, the speed of face detection is still a 
problem that seriously hinders it from being widely used in 
real-world applications. This problem is not completely 
solved until the algorithm of face detection based on 
AdaBoost and Haar-like features was proposed by Viola and 
Jones [1]. Moreover, face detection is often preceded by the 
extraction of skin-tone colors [2], since it is one of the most 
important cues of face features due to its invariance of face 
scales, poses, and facial expressions. However, color-based 
approaches are quite difficult to detect skin-tone color in the 
presence of skin color-like backgrounds. Therefore, we 
propose a novel method to robustly segment face clusters 
against skin color-like backgrounds. 
In general, face detection based on skin-tone colors is 
significantly affected by illumination variations and complex 
backgrounds. To overcome such difficulties, Huang et al. [3] 
proposed an adaptive switching method to choose an optimal 
one from nine combinations of skin color models by a well-
defined quality measure. The separated skin-tone clusters 
were further validated by the AdaBoost method with Haar-
like features to determine whether human faces exist in those 
clusters or not. They used this method to track a sequence of 
images with the scenarios of dim-light, side-light, and back-
light settings. The performance of their method achieves an 
average tracking time of about 145.4 ms/frame and a 
detection rate of 94.4%. 
At the same time, Hu et al. [4] proposed a three-stage 
scheme to detect faces of pedestrians for intersection 
monitoring. Their method was mainly based on skin color as 
well as face features. Several testing results show the 
superiority of their proposed method especially in skin color-
like backgrounds or varying illumination environments. 
Real-time performance is well achieved by their system 
since detection time is only 15.9 ms for each frame. 
However, many parameters used in their model are needed to 
be tuned for robustly detecting possible face candidates. 
Moreover, their method cannot operate well when the 
clusters of human skin colors are overlapped with those in 
skin color-like backgrounds. 
In this paper, a robust method is proposed to solve the 
difficulties of segmenting face clusters from skin color-like 
backgrounds, especially in which face clusters are connected 
with those in skin color-like backgrounds. The remainder of 
this paper is organized as follows. In Section 2, the proposed 
method including three subsystems of image preprocessing, 
skin color segmentation, and face detection is described. 
Section 3 presents the result of face detection in skin color-
like backgrounds. Conclusion and future work are given in 
Section 4. 
 
Figure 1.  Flow diagram of the proposed method for face detection. 
2010 Fourth International Conference on Genetic and Evolutionary Computing
978-0-7695-4281-2/10 $26.00 © 2010 IEEE
DOI 10.1109/ICGEC.2010.175
687
 
Figure 2.  Detailed flow diagram of determination of face candidates. 
The skin color clusters may include face parts with neck 
that is redundant in our case, or consists of other skin color 
regions without faces such as arm, hand, or leg that should 
be removed. As for the former, we proposed the following 
method to eliminate the neck part. As shown in Fig. 3(a), the 
skin color region drawn with a red rectangle box is 
determined using the 8-conneced component labeling 
method. The histogram of skin color pixels for the red 
rectangle box shown in Fig. 3(a) was then statistically 
completed (see Fig. 3(c)). Since the profile of human faces 
can be assumed to be approximately elliptical, the histogram 
appears to be a single mode of Gaussian distribution. Hence, 
the maximum value of histogram should exist in the 
centerline of faces, and the minimum values of histogram 
can be determined as the last valleys from both sides to the 
centerline whose values are less than 0.375Vmax (see Fig. 
3(c)). These three values are indicated by red dash lines 
shown in Fig. 3(c). Based on the two locations of x1 and x2 
corresponding to the minimum values of V1 and V2, 
respectively, where x2>x1, the width of face region, say Wf 
(=x2-x1), can be determined. Since the aspect ratio of faces 
(=height/width) is assumed to be 4/3, the height of face 
region, say Hf, can be calculated as 4/3*Wf. However, if the 
calculated Hf is larger than the height of original rectangle 
box, this rectangle box is not changed. By this method, the 
neck part of faces can be successfully eliminated, and the 
resulting face region is shown in Fig. 3(b). 
As mentioned earlier, the skin color clusters that may not 
contain any faces should be eliminated. Since the aspect ratio 
of faces of 4/3 is assumed, it indicates that if the width of 
skin color clusters is larger than its height, the skin color 
clusters that may be an arm, a hand or a leg should be 
rejected. However, the clusters of containing face candidate, 
say Wr, can be fitted to an ellipse, say We, shown in Fig. 4. 
Furthermore, if (Se+Sp+Sa)/3<ρ, the skin color clusters are 
rejected, where Se, Sp, and Sa represent the sensitivity (true 
positive rate=TP/(TP+FN)), the specificity (true negative 
rate= TN/(TN+FP)), and the spatial accuracy (=1-
(FP+FN)/(TP+FN)), respectively. These values are estimated 
from the elliptical regions We, where TP, TN, FP and FN 
represent the total number of true positive, true negative, 
false positive and false negative pixels, respectively. The 
value of ρ is a threshold set to 0.7. 
 
Figure 3.  Results of determination of face candidates, (a) Original 
rectangle box of face candidates, (b) Modified rectangle box of face 
candidates, (c) Histogram of skin color pixels in rectangle box in (a). 
The face candidates accepted by elliptical fitting may 
contain no faces, and these face candidates should be further 
removed. In general, face regions usually has higher entropy 
than those of other skin regions such as arms or hands. The 
entropy S is a histogram feature that is defined as -
Σp(g)ln[p(g)], g=0,1,…,255, and p(g)=N(g)/M, where N(g) 
is the number of pixels at gray level g, and M is the total 
number of pixels in the image. In this work, S≥6.6 is a 
criterion for accepting skin color clusters as face regions. 
 
Figure 4.  The face template used for elliptical fitting. 
III. EXPERIMENTAL RESULTS AND DISCUSSION 
To extract object clusters in foregrounds and eliminate most 
of skin color-like pixels in backgrounds, the proposed image 
preprocessing method was carried out. As shown in Fig. 5, 
the results of skin color segmentation obtained by the 
proposed method (Figs. 5(b) and (e)) and Garcia et al. [5] 
(Figs. 5(c) and (f)) show that the proposed method has less 
fraction of skin color-like pixels in backgrounds due to the  
use of image preprocessing. Note that only the method of 
skin color segmentation was used in [5]. Furthermore, more 
results of face detection against skin color-like backgrounds 
are shown in Fig. 6. This result was also compared with 
those of Huang et al. [3] and Hu et al. [4]. As shown in this 
figure, many skin color-like clusters were detected by [3] 
since their method primarily focused on the issues of varying 
illumination. Moreover, when the overlapped area between 
faces and skin color-like clusters was larger, missing or false 
detection of faces (see column 3 in Fig. 6) appeared in [4]; 
however, when the overlapped area was relatively small, 
689
國科會補助計畫衍生研發成果推廣資料表
日期:2011/11/28
國科會補助計畫
計畫名稱: 植基於人及其行為動作之視訊檢索系統
計畫主持人: 黃登淵
計畫編號: 99-2221-E-212-022- 學門領域: 圖形辨識
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
