2 
 
4 
 
Research on the Development of a Hierarchical Network-on-Chip 
System Platform Synthesizer 
 
Abstract 
In this project, a comprehensive realization of a hierarchical Network-on-Chip (NoC) 
architectural synthesis and analysis tool will be developed.  In particular, the following 
specific tasks will be pursued: (1) NoC topology design; (2) NoC formal verification; (3) 
NoC router design; (4) Performance simulator design; and (5) NoC fault-tolerant design. 
 This research project has many distinct features. (1) This is a unique hierarchical 
approach towards developing NoC architectures emphasizing modularity which enables 
optimization of several performance objectives over multiple layers of NoC architecture.  (2) 
This research emphasizes the strategy, policy, and realization of system adaptation at all 
levels.  We will investigate the power, area, bandwidth issues in NoC modules; study CAD 
and verification issues in the composition module, placement engine, and overall flow of the 
NoC synthesis tool. (3) This research is a inter-disciplinary study combining physical, data 
link, networking and transport, and application into one integrated comprehensive flow which 
can be used for hierarchical NoC architecture development. 
In the first year of the project, we completed the architecture design of a Bi-directional 
channel NoC (BiNoC). This architecture design has been designed by Prof. Sao-Jie Chen and 
his PhD student (Ying-Cherng Lan) during their visits in University of Wisconsin, Madison, 
around August 2008 to April 2009. Also, this work has accepted the best paper award from 
the 3rd ACM/IEEE International Symposium on Networks-on-Chip, held on May 10-13 2009, 
at San Diego. In the second year of the project, we completed the formal verification of our 
BiNoC architecture. This verification work has been designed by Prof. Sao-Jie Chen and his 
PhD student (Yean-Ru Chen) during their visits in University of Wisconsin, Madison, around 
July-August 2009 and Jan-May 2010. Also, this work has been presented at The First 
International Conference on Green Circuits and Systems, held on June 2010, at Shanghai. In 
the third year of the project, we completed the fault-tolerant design of our BiNoC architecture. 
This fault-tolerant BiNoC has been designed by Prof. Sao-Jie Chen and his PhD student 
(Wen-Chung Tsai) during their visits in University of Wisconsin, Madison, around 
July-September 2010. Also, this work has been presented at ACM/IEEE Design Automation 
Conference, held on June 2011, at San Diego. 
 
Keywords:  Network-on-Chip, NoC router, NoC topology, formal verification, fault 
tolerance design. 
6 
 
  
 
PART I 
8 
 
channel arbitration. Finally, the granted packet will traverse through a crossbar to the next router, and the 
process repeats until the packet arrives at its destination.  
 
MUX
 
Figure 1. Typical NoC architecture in mesh topology. 
 
In a city-block tiled NoC architecture, neighboring routers are connected via a pair of communication 
channels. One channel will support out-going traffic and the other channel will support in-coming traffic.  
Under various traffic conditions, it is often observed that the out-going channel may be flooded with out-going 
traffic while the incoming channel remains idle. In many metropolitan areas, during rush hours, the travel 
directions of some highway lanes are reversed temporarily to relieve congestions of the opposing traffic 
direction.  
In this work, we explore similar idea as a mechanism to relieve intermittent traffic congestion in the NoC 
communication backbone, and hence enhance overall performance. Specifically, we propose a key innovation to 
replace the pair of unidirectional channels between routers by a pair of bidirectional channels that can be 
dynamically self-reconfigured to facilitate flits traffic in either out-going or incoming direction. This added 
flexibility promises better bandwidth utilization, lower packet delivery latency, and higher packet consumption 
rate at each on-chip router. 
To facilitate this bidirectional traffic, we devise a novel inter-router traffic control algorithm to allow 
neighboring routers to coordinate the specific directions of the pair of channels between them for each data 
packet. A novel router architecture that supports bidirectional channels with dynamic self-reconfiguration 
capability is also proposed. It is observed that the hardware overhead for bidirectional channels is negligible. 
Finally, a cycle-accurate behavioral simulator for NoC is developed to validate the potential performance gain 
of this proposed new approach. This simulator is capable of simulating cycle-true traffic behaviors of a 
moderate size NoC over different traffic patterns. Very encouraging simulation results have been observed.  
10 
 
South, and West) such that propagating a flit through one hop requires one clock cycle.  Each router is also 
equipped with input buffers to each of its five connections.  Packets are broken into head, body, and tail flits 
and sent via wormhole routing with smaller buffer sizes to save area.  The routing algorithms that we use for 
reference and comparison are minimal routing algorithms, thereby ensuring freedom from livelock.  We also 
implement the dimension-ordered XY routing restrictions to guarantee that no deadlock occurs. 
 
A.3.2. Problem Formulation 
In a conventional NoC architecture, each pair of neighboring routers uses two unidirectional channels in 
opposite direction to propagate data on the network as shown in Figure 2.(a).  To enable the most bandwidth 
utilization, data channels between each pair of routers should be able to transmit data in any direction at each 
run cycle.  That is, four kinds of channel direction combinations should be allowed for data transmission as 
shown in Figure 2(b).  However, current unidirectional NoC architectures, when facing applications that have 
different traffic patterns, cannot achieve the high bandwidth utilization objective. 
 
 
(a)                                             (b) 
Figure 2. Channel directions in: (a) a conventional NoC and (b) our proposed BiNoC. 
 
To discuss our motivation more specifically, Figure 3 shows how the bandwidth utilization of a typical 
conventional NoC under uniform, regional and transpose traffics (please refer to Section A.5 for detailed 
description of the simulation setup and characteristics of traffic patterns).  Here we define the bandwidth 
utilization as: 
Bandwidth_utilization = , 
where execution_time represents the total time needed to execute the whole pattern, and trans_channels is the 
number of data channel being used for each time cycle while total_channels is the total channel numbers in an 
NoC architecture.  We observe that the bandwidth utilization in a conventional NoC architecture running with 
these three synthetic traffic patterns are all very low.  Therefore, we can speculate that many channels are idle 
during each processing cycle because of the fixed direction of channel restriction. 
 
12 
 
as shown in Figure 5(a) to make sure that only one direction is valid on each bidirectional channel at one time.  
More specifically, the finite state machine in the channel control block dynamically reconfigures the direction of 
each channel.  As illustrated in Figure 5(b), the direction setup scheme for a bidirectional channel is formed by 
a handshake protocol implemented in the two individual finite state machines located at the two neighboring 
routers in this channel.  Due to the inter-router communication delay, the control signal for direction setup 
should take two additional cycles to traverse from one router to the other.  For example, the input_req signal in 
Router 2 uses the same output_req signal from Router 1 but having a two cycles of delay. 
The state machine in our design is quite simple and area efficient.  It contains three main states, which are 
idle, free and waiting as shown in Figure 5(a).  At the initialization time of the whole system, the two 
bidirectional channels for each neighboring router pair will be set as each having a different direction at first.  
For each bidirectional channel, the initial states of the pair of finite state machines in this channel will be 
respectively set to idle and free to make sure that only one direction is valid for data transmission at this moment.  
For example, if the direction of bidirectional channel in Figure 5(b) is set from Router 1 to Router 2, then the 
finite state machines will stay at free and idle states respectively.   
 
 
Figure 5. (a) Finite state machine for inter-router control and (b) control scheme of a bidirectional channel setup 
between two routers. 
 
14 
 
channels can be requested in each output direction.  In other words, this router is able to transmit at most two 
packets to the same direction simultaneously which decreases the probability of contentions.   
The channel control block has two major functions.  One is to dynamically configure the channel direction 
between neighboring routers.  Since the bidirectional channel is shared by a pair of neighboring routers, every 
transition of the output authority is achieved by a channel control protocol between these two routers.  The 
control protocol, implemented as a finite state machine was described in the previous section.  The input_req 
and output_req signals are used to communicate with the two neighboring routers during their configuration. 
 
in-out select
input buffer routing module
North Channel A
in-out select
input buffer routing module
East Channel A
in-out select
input buffer routing module
South Channel A
in-out select
input buffer routing module
West Channel A
in-out select
input buffer routing module
PE Channel A
arbiter
Channel Control Moduleinput_req
output_req
in-out select
input bufferrouting module
North Channel B
in-out select
input bufferrouting module
East Channel B
in-out select
input bufferrouting module
South Channel B
in-out select
input bufferrouting module
West Channel B
in-out select
input bufferrouting module
PE Channel B
 
Figure 6. Dynamically self-reconfigurable bidirectional channel NoC architecture. 
 
The other responsibility is that whether the channel request (channel_req) for the corresponding channel is 
blocked or not will depend on the current status of channel direction.  If the channel is able to be used, the 
arb_req will be sent to the arbiter to process the channel allocation. 
The most important point of this architecture is that we can replace all the unidirectional channels in a 
conventional NoC with our bidirectional channels.  That will increase the channel utilization flexibility without 
requiring additional transmission bandwidth compared to the conventional NoC platform. 
 
16 
 
Three types of traffic patterns were run: uniform, transpose, and regional.  In a uniform traffic, a node 
receives a packet from any other node with equal probability based on the injection rate.  In a transpose traffic, 
a node at (i,j) always sends packets to a single node at (j,i).  In a regional traffic, 90% of the packets are sent to 
the destination within 3 hops away.  That is more realistic since each node does not often send packets to other 
nodes in a longer distance. 
Figures 7(a), 7(b), and 7(c) show that our BiNoC owns a lower latency than the Typical-NoC in these three 
traffic patterns even if compared with Typical-NoC-double.  In Figure 7(a), we can find that Reduced-BiNoC 
performs the worst in the uniform traffic case.  This is because the uniform pattern sends packets randomly, 
which will cause the bidirectional channel switch frequently.  In the transpose traffic case, such regular traffic 
patterns with XY routing applied will make at least one of the two hardwired directional channels connecting 
neighboring routers unable to be used.  Therefore, the latency results of a Typical-NoC is the same as a 
Reduced-BiNoC which has only one bidirectional channel between two neighboring routers as illustrated in 
Figure 7(b).  In the regional pattern case, BiNoC still outperform the other three architectures even at low 
injection rate, as show in Figure 7(c).  That is because more packets can be transmitted via the two 
bidirectional channels, which breaks the bottleneck caused by the hardwired-direction channel. 
 
0
50
100
150
200
250
300
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
la
te
nc
y (
cy
cl
e)
injection rate (flit/node/cycle)
Typical‐NoC
Typical‐NoC‐double
BiNoC
Reduced‐BiNoC
 
0
50
100
150
200
250
300
0 0.05 0.1 0.15 0.2 0.25 0.3
la
te
nc
y (
cy
cl
e)
injection rate (flit/node/cycle)
Typical‐NoC
Typical‐NoC‐double
BiNoC
Reduced‐BiNoC
 
0
50
100
150
200
250
300
0 0.1 0.2 0.3 0.4 0.5 0.6
la
te
nc
y (
cy
cl
e)
injection rate (flit/node/cycle)
Typical‐NoC
Typical‐NoC‐double
BiNoC
Reduced‐BiNoC
 
Figure 7. Latency versus injection rate results obtained by running (a) uniform, (b) transpose, and (c) regional traffics. 
 
18 
 
0
20000
40000
60000
80000
100000
120000
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
sw
itc
hi
ng
 tim
es
injection rate (flit/node/cycle)
BiNoC‐uni
BiNoC‐trans
BiNoC‐regional
0
20000
40000
60000
80000
100000
120000
0 0.1 0.2 0.3 0.4 0.5 0.6
sw
itc
hi
ng
 tim
es
injection rate (flit/node/cycle)
Reduced‐BiNoC‐uni
Reduced‐BiNoC‐trans
Reduced‐BiNoC‐regional
 
(a)                                     (b) 
Figure 9. Total number of configuration times on (a) BiNoC and (b) reduced-BiNoC running synthetic patterns. 
 
A.5.3. Experiments with Real Application 
According to the experimental results above, the channel configuring times have important impact on 
transmission latency.  However, in real cases, data transmission is much regular than synthetic patterns.  
Therefore, we use E3S benchmarks from the Embedded Microprocessor Benchmark Consortium (EEMBC) [14] 
to demonstrate the improvements of our BiNoC architecture compared to the typical NoC in this section.  The 
three tests used are auto-indust, consumer, and telecom which were run on a 55, 44, and 66 NoC 
architectures, respectively. 
First we input task graphs given in the E3S benchmarks and performed task mapping to map each task in the 
graph to a tile on NoC.  Task mapping will put tasks with heavy communication closer to optimize 
communication cost.  Then the resulting process graph was converted to a packetized traffic flow which was 
fed into our NoC simulator.  Here we adopt the common simulated annealing (SA) algorithm as our task 
mapping algorithm.  The cost function of SA for mapping is the data flow between tasks: 
 
_ij
ij i j i j
w task graph
w x x y y
 
     
The term wij represents the total communication volume between taski and taskj while (xi, yi) and (xj, yj) 
represent the positions of PEs which are assigned with  and , respectively. 
As shown in Figures 10(a), 10(b), and 10(c), BiNoC consistently provides the lowest average packet latencies 
among the three benchmark applications.  This is because its self-reconfigurable bidirectional channel has 
more flexibility for data transmission.  In real traffic, we observe more clearly that the Reduced-BiNoC has 
almost the same latencies with respect to the Typical-NoC because of the regularity characteristic in real traffics. 
In other words, many channels in the Typical-NoC cannot be used for transmission due to its fixed unidirection.  
Also, the simulation results also show that the buffer size increase from a Typical-NoC to a Typical-NoC-double 
cannot help much on the performance under regular pattern while using the same task mapping algorithm.  
20 
 
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
1
Typical‐NoC
Typical‐NoC‐double
BiNoC
Reduced‐BiNoC
 
Figure 11. Area comparison of different NoC architectures. 
 
A.6. Conclusion 
In this work, we proposed a novel NoC backbone architecture BiNoC which features dynamically 
self-reconfigurable bidirectional channels. An algorithm that supports real-time traffic-direction arbitration in 
the bidirectional channels is presented.  Experimental results using both synthetic traffic patterns and E3S 
benchmarks verified that the proposed BiNoC architecture can significantly reduce the packet delivery latency 
at all levels of packet injection rates.  Compared to the conventional NoC, the bandwidth utilization of our 
BiNoC also exhibits higher efficiency.  The content of this report has just received the best paper award from 
the 3rd ACM/IEEE International Symposium on Networks-on-Chip, held on May 10-13 at San Diego [15]. 
 
References 
[1] A. Jantsch and H. Tenhunen (Eds.), Networks on Chip, Kluwer Academic Publishers, 2003. 
[2] S. Kumar, et al., “A Network on Chip Architecture and Design Methodology,” in Proceedings of ISVLSI, 
pp. 105-112, Apr. 2002. 
[3] W. J. Dally and B. Towles, “Route Packets, Not Wires: On-Chip Interconnection Networks,” in 
Proceedings of DAC, pages 684-689, 2001. 
[4] L. Benini and G. De Micheli, “Networks on Chips: a New SoC paradigm,” IEEE Computer, 35(1):70-78, 
Jan 2002. 
[5] D. Bertozzi, et al., “NoC Synthesis Flow for Customized Domain Specific Multiprocessor 
Systems-on-chip,” IEEE Transactions on Parallel and Distributed Systems, vol. 16, no. 2, pp. 113-129, 
Feb. 2005. 
[6] T. Bjerregaard and S. Mahadevan, “A Survey of Research and Practices of Network-on-Chip,” ACM 
Computer Survey, vol. 38, no. 1, pp. 1-51, Mar. 2006. 
[7] U. Orgas, J. Hu, and R. Marculescu, “Key Research Problems in NoC Design: A Holistic Perspective,” in 
Proceedings of CODES+ISSS, pages 69-74, Sept 2005. 
[8] R. Marculescu, et al., “Outstanding Research Problems in NoC Design: System, Microarchitecture, and 
Circuit Perspectives,” IEEE Transactions on CAD, vol. 28, no. 1, pp. 3-21, Jan. 2009. 
[9] H. G. Lee, et al., “On-Chip Communication Architecture Exploration: A Quantitative Evaluation of 
Point-to-Point, Bus and Network-on-Chip Approaches,” ACM Transactions on DAES, vol. 12, no. 3, pp. 
1-20, Aug. 2007. 
[10] J. Lillis and C. Cheng, “Timing Optimization for Multisource Nets: Characterization and Optimal Repeater 
Insertion,” IEEE Transactions on CAD, vol. 18, no. 3, pp. 322-331, Mar. 1999. 
22 
 
24 
 
qualitative arguments to justify that these properties are likely to hold in typical operations. What we need is a 
formal verification approach to systematically, and rigorously prove that a given router architecture and the 
corresponding routing algorithm satisfy the desired properties. 
 
In this work, we not only propose several formal modeling guidelines for the above four properties of an 
NoC architecture, but also verify these properties using model checking [9], one of the most popular formal 
verification techniques. As an example to illustrate NoC modeling and property verification, we applied our 
work on a specific NoC, namely, the bidirectional channel network-on-chip (BiNoC) [1]. Besides being a 
conventional mesh-based NoC design with XY-based wormhole routing, BiNoC also allows dynamically 
configuring the direction of a channel. 
 
Our contributions are three-folds: 
(1) to provide guidelines for constructing formal models of an NoC design, 
(2) to analyze the minimal formal models essential for verifying a given property, and 
(3) to propose a methodology for verifying NoC properties. 
 
Our work on NoC verification has been implemented in a model checker called State Graph Manipulators 
(SGM) [2]. 
The rest of this article is organized as follows. Section B.2 reviews the state-of-the-art techniques for NoC 
verification. Section B.3 defines several required terminologies. In Section B.4, we describe the proposed 
modeling method and use BiNoC as an example to illustrate property verification and traffic congestion analysis. 
Finally, we give a conclusion and future work in Section B.5. 
 
B.2. Related Work 
The techniques for NoC verification can be classified into simulation, formal verification, and 
mathematical proof, out of which simulation is the most popular and widely-used. Several NoC simulators, such 
as Noxim [3] and XMulator [4], have been designed to evaluate performance on throughput and latency. 
Various interconnection topologies, router switch designs, arbitration algorithms, routing algorithms, and traffic 
patterns have been modeled and simulated. 
 
Simulation is limited by the length of time that a system is simulated, which means that exhaustive 
checking of all system behaviors is near to impossible and time-consuming for a complex NoC-based SoC. 
However, some functional properties, such as mutual exclusion, deadlock-freedom, and starvation-freedom, 
require exhaustive exploration; thus simulation cannot be used to complete such verifications. 
 
To solve these problems, a conventional method is to use mathematical proof. For example, Jones et al. [6] 
26 
 
 
Definition3: System State Graph 
Given a system S with n components modeled by ETA Ai =(Mi, m0i, Ci, Di, χi, Ti,τi, ρi), 1 ≤ i ≤ n, the system 
model is defined as a system state graph represented by A1 ×···×An = AS = (M, m0, C, D, χ, T, τ , ρ). M = M1 
×M2 ×...×Mn is a finite set of system modes. m0 = m01.m02.....m0n א M is the initial system mode. C = ∪iCi is 
the union of all sets of clock variables in the system. D = ∪iDi is the union of all sets of discrete variables in 
the system. χ: M → B(∪iCi, ∪iDi), χ(m) = רi χi(mi), where m = m1 · m2 · ··· · mn א M. T ك M ×M is a set of 
system transitions, where ׌i, 1 ≤ i ≤ n, t א Ti such that t = t’א T. τ (t’)= τi(t) for a transition t’ = t. ρ: T → 2∪i Ci∪
(∪i Di×N) gives the assignments on a system transition such that ρ(t’)= ρi(t) for a transition t’= t. Two concurrent 
transitions are represented by interleaving them in the product automata, resulting in possibly two different 
paths (computations). 
 
The system properties can be specified in temporal logics. We choose the Computation Tree Logic as the 
property’s logical formalism, which is defined as follows.  
 
Definition4: Computation Tree Logic 
A Computation Tree Logic (CTL) formula has the following syntax: φ ::= η | EXφ’|EGφ’| Eφ’Uφ”|¬φ’| φ’שφ”, 
where η is a mode predicate, φ’ and φ” are CTL formulas. EXφ’ means there is a next state of the current state, 
where φ’ is true. EGφ’ means there is a computation from the current state, along which φ’ is always true. 
Eφ’Uφ” means there exists a computation from the current state, along which φ’ is true until φ” becomes true. 
Other short hands like ר, →, EF, AF, AG, AX, and AU are all defined in terms of five operators ¬, ש, EX, EG 
and EU as follows. 
 φר φ” ≣ ¬(¬φ ש φ”) 
 φ → φ” ≣ ¬φ ש φ” 
 EFφ = E(True U φ) 
 AFφ = ¬EG(¬φ) 
 AGφ = ¬EF(¬φ) 
 AXφ = ¬EX(¬φ) 
 Aφ’Uφ”≣¬E(¬φ”U(¬φ’ר¬φ”)) ר¬EG¬φ” 
 
B.4. Formal Model and Verification of NoC 
To verify the crucial functional properties of an NoC design as described in Introduction, we need to 
construct models that can be used to verify the properties. Some required information must be included, but they 
must also be minimal in the sense that no unnecessary information is modeled. We provide guidelines for 
modeling NoC and use our previously-proposed BiNoC [1] for illustration. In this work, we model the router 
designs of an NoC in ETA. These ETA models will be composed into a system state graph which will be input 
28 
 
modeling, the routing table must also be modeled. 
 
B.4.2. Model Checking BiNoC 
 
BiNoC Design: Through detailed analysis on the BiNoC design [1], the authors concluded that the proposed 
BiNoC can achieve the same performance (latency or bandwidth utilization) as a typical NoC does, but BiNoC 
uses less buffer size than a typical NoC. In other words, to achieve the same performance, BiNoC will save 
more buffer area and power than a typical NoC. Let us use this less power-consuming NoC, called BiNoC [1], 
to illustrate our proposed method. Refer to the BiNoC design in [1], Figure 1 shows that an inter-router 
transmission channel control scheme is implemented in a finite state machine for each channel. This control is 
used to make sure that only one direction is valid on each bidirectional channel at one time. More specifically, 
the finite state machine in the channel control block dynamically reconfigures the direction of each channel.  
 
Figure 1. Finite State Machine for Inter-Router Control. 
 
As illustrated in [1], the direction setup scheme for a bidirectional channel is formed by a handshake 
protocol implemented in the two individual finite state machines located at a pair of neighboring routers in this 
channel. Due to the inter-router communication delay, the control signal for direction setup should take two 
additional cycles to traverse from one router to the other. For example, the inputreq signal in Router 2 uses the 
same outputreq signal from Router 1 but having a two-cycle delay.  
 
Formal Models and Model Check of BiNoC: Here, we will provide the ETA models of BiNoC to verify whether 
the composed system state graph satisfies the given properties. As described in Introduction, there are four 
properties that we need to verify as follows. 
(1) Verification of Mutual Exclusion Property. As mentioned above, BiNoC allows two neighboring routers 
to configure the directions of the two links (channels) shared between them. For each channel, a pair of 
FSM controllers, one in each of the two routers, tries to gain access to the shared channel. Since the two 
controllers work together to control the communication direction, we need to guarantee that at a time only 
one of the controllers can gain access and configure the direction of a channel (mutual exclusion). Figure 
30 
 
Specifically, as illustrated in Figure 3, we also require a packet generator, a channel request 
generator, and a $2$-clock-delay pipeline. A packet generator for uniform traffic pattern is shown in 
Figure 3(a). Each source PE can be associated with a packet generator. Other traffic patterns such as local, 
1-transpose, and 2-transpose can all be modeled. Figure 3(b) shows how a channel request is enabled, as 
long as, one or more packets are in the input buffer. The channel request signal CL is used for triggering 
the FSM in Figure 2. Since there is a two-cycle delay for data transfer from one router to a neighboring 
router using a shared channel, Figure 3(c) shows a pipelined signal propagation model, which uses two 
registers to propagate an output signal into an input signal. The verification result shows that the mutual 
exclusion property is guaranteed. 
 
(2) Verification of Starvation Freedom Property. Besides checking mutual exclusion of channel access, we 
further verify if this BiNoC design is starvation free with the same models. The starvation free property is 
specified in CTL as: φ: AG((C_R =1) → AF(mode(FSMR)= Free_R)), which means that a router can 
access a shared channel eventually, as long as it sends a request. Unfortunately, this property is not 
satisfied, because this version of the BiNoC design is not fair. It is well-known that CTL cannot be used to 
express fairness. Instead, we verified the property: φ ’: AG(mode(FSML)= Free_L)) → 
(!EG(mode(FSML)= Free_L))), which is also unsatisfied. This means that once an FSM controller enters 
the Free state, then it could be in the Free state forever, thus fairness is not guaranteed. Moreover, from 
the verification result of mutual exclusion property, we can see that if one FSM controller can stay in the 
Free state forever, that is, the shared channel will be occupied forever, then its neighboring router will be 
deprived access to the shared channel indefinitely. This is an unfair design, thus the starvation free 
property is violated.  
(3) Discussions on the Verification Results of Mutual Exclusion and Starvation Freedom Properties. Mutual 
exclusion and starvation freedom were checked using the SGM model checker on a machine with a 3.00 
GHz Intel Pentium4 CPU and 4 GB RAM. SGM was extended such that the ETA models could invoke 
function calls. Totally, there are 1, 675 system modes and 25, 238 system transitions. The memory usage 
and the total execution time are 4.77 MB and 1.49 sec., respectively. The BiNoC design satisfies the 
mutual exclusion property but violates the starvation freedom property. From the counterexample of the 
verification result of the starvation freedom property, we can modify each router design to avoid staying 
in the Free state indefinitely either by setting an upper bound on the time allowed in the Free state or by 
implementing a preemptive priority mechanism to yield access to the shared channel to the neighboring 
router.  
(4) Verification of Deadlock Freedom Property. As far as verifying the deadlock property and estimating the 
network congestion are concerned, we need more complete and complex models for BiNoC such as those 
related to routing, switching, and arbitration. Three out of the six required components are illustrated in 
Figure 4. The new packet generator in Figure 4(a) generates the source and destination for each packet. 
32 
 
 
(a) Packet Generator with More Information. 
 
Init_B0_0_NW=0W_0_N=0
R_0_N=0
Write_0_N
(W=1 & In_0_N=0)
W_0_N:=W_0_N
W:=0
(W=1 & In_0_N=1  & W_0_N=0 &B0_N_1=0),
B0_N_1:=P_N_0,
W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5),
W:=0
|| (W=1 & In_0_N=1  & W_0_N=1 &B0_N_2=0),
B0_N_2:=P_N_0,
W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5),
W:=0
|| (W=1 & In_0_N=1  & W_0_N=2 &B0_N_3=0),
B0_N_3:=P_N_0,
W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5),
W:=0
|| (W=1 & In_0_N=1  & W_0_N=3 &B0_N_4=0),
B0_N_4:=P_N_0,
W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5),
W:=0
(W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_1, Outreq_0_N:=1,
B0_N_1:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5), Full_0_N:=0,
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_2, Outreq_0_N:=1,
B0_N_2:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5), Full_0_N:=0,
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_3, Outreq_0_N:=1,
B0_N_3:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5), Full_0_N:=0,
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_4, Outreq_0_N:=1,
B0_N_4:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5), Full_0_N:=0,
W:=0
(W=1 & W_0_N=R_0_N & B0_N=4)
Full_0_N:=1
W:=0
cg_time:=0
Read_0_N
Full_0_N
(W=1 & In_0_N=0)
W_0_N:=W_0_N
W:=0
(W=1 & In_0_N=1  & W_0_N=0 
&B0_N_1=0)
B0_N_1:=P_N_0
W_0_N:=W_0_N+1(mod 4)
B0_N:=B0_N+1(mod 5)
W:=0
|| (W=1 & In_0_N=1  & W_0_N=1 
&B0_N_2=0)
B0_N_2:=P_N_0
W_0_N:=W_0_N+1(mod 4)
B0_N:=B0_N+1(mod 5)
W:=0
|| (W=1 & In_0_N=1  & W_0_N=2 
&B0_N_3=0)
B0_N_3:=P_N_0
W_0_N:=W_0_N+1(mod 4)
B0_N:=B0_N+1(mod 5)
W:=0
|| (W=1 & In_0_N=1  & W_0_N=3 
&B0_N_4=0)
B0_N_4:=P_N_0
W_0_N:=W_0_N+1(mod 4)
B0_N:=B0_N+1(mod 5)
W:=0
(W=1 & In_0_N=0), W_0_N:=W_0_N,
W:=0
|| (W=1 & In_0_N=1  & W_0_N=0 &B0_N_1=0),
B0_N_1:=P_N_0, W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5), W:=0
|| (W=1 & In_0_N=1  & W_0_N=1 &B0_N_2=0),
B0_N_2:=P_N_0, W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5), W:=0
|| (W=1 & In_0_N=1  & W_0_N=2 &B0_N_3=0),
B0_N_3:=P_N_0, W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5), W:=0
|| (W=1 & In_0_N=1  & W_0_N=3 &B0_N_4=0),
B0_N_4:=P_N_0, W_0_N:=W_0_N+1(mod 4),
B0_N:=B0_N+1(mod 5), W:=0
(W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_1, Outreq_0_N:=1,
B0_N_1:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5),
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_2, Outreq_0_N:=1,
B0_N_2:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5),
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_3, Outreq_0_N:=1,
B0_N_3:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5),
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0),
Out_0_N := B0_N_4, Outreq_0_N:=1,
B0_N_4:=0, R_0_N:=R_0_N+1(mod 4),
B0_N:=B0_N-1(mod 5),
W:=0
(W=1 & Next_port_0=4 & R_0_N=0), Out_0_N := B0_N_1
Outreq_0_N:=1, B0_N_1:=0
R_0_N:=R_0_N+1(mod 4), B0_N:=B0_N-1(mod 5)
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0), Out_0_N := B0_N_2
Outreq_0_N:=1, B0_N_2:=0
R_0_N:=R_0_N+1(mod 4), B0_N:=B0_N-1(mod 5)
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0), Out_0_N := B0_N_3
Outreq_0_N:=1, B0_N_3:=0
R_0_N:=R_0_N+1(mod 4), B0_N:=B0_N-1(mod 5)
W:=0
|| (W=1 & Next_port_0=4 & R_0_N=0), Out_0_N := B0_N_4
Outreq_0_N:=1, B0_N_4:=0
R_0_N:=R_0_N+1(mod 4), B0_N:=B0_N-1(mod 5)
W:=0
(W=1 & W_0_N=R_0_N & B0_N=0)
W:=0
(W=1 & W_0_N=R_0_N & B0_N=4)
Full_0_N:=1
W:=0  
(b) Detailed Buffer Model with Arbitration. 
34 
 
using Interconnect IPs, Proceedings of the 2003 international workshop on System-level interconnect 
prediction ACM, 2003. 
[6]  M. Jones and G. Gopalakrishnan, Verifying Transaction Ordering Properties in Unbounded Bus Networks 
through Combined Deductive/Algorithmic Methods, Proceedings of the Third International Conference on 
Formal Methods in Computer-Aided Design Springer-Verlag, 2000. 
[7] X. Lin, P. K. McKinley and L. M. Ni, Deadlock-Free Multicast Wormhole Routing in 2-D Mesh 
Multicomputers, IEEE Transactions on Parallel and Distributed Systems IEEE Computer Society, 1994. 
[8] W. J. Dally and C. L. Seitz, Deadlock-Free Message Routing in Multiprocessor Interconnection Networks, 
IEEE Transactions on Computers IEEE Computer Society, 1987. 
[9] E. M. Clarke, O. Grumberg and D. A. Peled, Model Checking, Book MIT Press, 1999. 
[10] D. BORRIONE, A. HELMY and L. PIERRE, ACL2-based Verification of the Communications in the 
Hermes Network on Chip, Proceedings of the International Workshop on Symbolic Methods and 
Applications to Circuit Design , 2006. 
[11] D. Borrione, A. Helmy, L. Pierre, and J. Schmaltz, A Formal Approach to the Verification of Networks on 
Chip, EURASIP Journal on Embedded Systems Hindawi Publishing Corporation, 2009. 
[12] G. Salaun, W. Serwe, Y. Thonnart and P. Vivet, Formal Verification of CHP Specifications with CADP 
Illustration on an Asynchronous Network-on-Chip, International Symposium on Asynchronous Circuits 
and Systems IEEE Computer Society, 2007. 
36 
 
channels are used in our proposed BiNoC architecture as illustrated in Figure 1. 
 
(a)                                   (b) 
Figure 1.  Channel Directions in a Typical NoC and Proposed BiNoC. 
C.2. BiNoC Router Architecture 
In the following sections, we will introduce two flow-control mechanisms including wormhole and 
virtual-channel flow-control for BiNoC architectures.  The implementation details will be described and 
breakdown into function blocks for easier understanding. 
C.2.1. BiNoC Router with Wormhole Flow-Control 
To realize a dynamically self-reconfigurable bidirectional channel NoC architecture, we initially modify 
the input/output port configuration and router control unit designs based on the conventional router using 
wormhole flow-control.  In order to dynamically adjust the direction of each bidirectional channel at run time, 
we add a Channel Control module to arbitrate the authority of the channel direction as illustrated in Figure 2.   
 
Figure 2.  Proposed BiNoC Router with Wormhole Flow-Control. 
38 
 
 
Figure 3.  Proposed BiNoC Router with Virtual-Channel Flow-Control. 
As shown in Figure 3, our virtual-channel flow-control based BiNoC is implemented with a 4-stage 
pipeline architecture to enhance the clock rate and throughput as a conventional router design does.  To fit in 
with our BiNoC architecture, the proposed channel control models as described in the following sections will be 
also implemented to arbitrate the inter-router bidirectional channel authority.  Note that all the input/output 
ports in a router are registered to provide clean signals from router to router in our design, as an NoC hardware 
implementation may require long wires. 
C.2.3. Reconfigurable Input/Output Ports 
As shown in Figure 3, one of the input/output ports is designated as a high-priority (HP) port, and the other 
is designated as a low-priority (LP) port.  Each of the two bidirectional channels between a pair of routers will 
determine its own transmission direction based on a distributed channel-direction control protocol.  When both 
channels have the same transmission direction, two data packets could be sent concurrently, which effectively 
double the channel bandwidth. 
Figure 4 shows the detailed schematic of the in-out ports implementation in BiNoC.  As long as the 
inout_select signals are assigned properly, no conflict and no unpredictable situation will occur. Instead of using 
dedicated input port and output port, within BiNoC, each port can be either an input port or an output port 
controlled by the inout_select signals generated from the Channel Control module. 
40 
 
T-NoC_WH(32) represents a typical unidirectional NoC architecture with wormhole flow-control which 
occupies one 32-flit buffer queues in each direction.  Moreover, T-NoC_4VC(32)_4L, which is equipped with 
four unidirectional links between adjacent router pairs, is implemented to evaluate the effect of doubling 
inter-router communication bandwidth. 
Table 1.  NoC Architectures used in our Experiments. 
 
C.3.1. Comparison between BiNoC and Conventional NoC 
Figure 6 illustrates the latency versus injection rate results obtained by running XY routing under 6(a) 
uniform, 6(c) regional, and 6(e) transpose traffics, and running Odd-Even routing under 6(b) uniform, 6(d) 
regional, and 6(f) transpose traffics.  We can find that our proposed BiNoC_4VC(32) owns a lower latency 
than the T-NoC_4VC(32) under both XY and Odd-Even routing algorithms in these three traffic patterns even if 
compared with T-NoC_4VC(64) which has a double buffer size.  Comparing results in uniform traffic with 
regional traffic, we can find that both T-NoC and BiNoC architectures perform better in terms of latency versus 
injection rate under the regional traffic case, since the uniform pattern sends packets randomly and results in 
more traffic contention.  However, in the regional traffic case, more packets transmitted to the destination near 
around reduce the traffic contention on a network, which lowers the direction switching frequency of a 
bidirectional channel in a BiNoC and gathers more latency improvement than a T-NoC. 
In the transpose traffic case, such regular traffic patterns will make many hardwired unidirectional 
channels connecting neighboring routers unable to be used.  Therefore, the latency results of a T-NoC are 
restricted by its bandwidth utilization capability as illustrated in Figures 6(e) and 6(f).  Enlarging the buffer 
size of a T-NoC_4VC(32) to a T-NoC_4VC(64) cannot improve the latency results even using adaptive routing 
algorithm such as Odd-Even.  However, for the BiNoC architecture, more packets can be transmitted via the 
two bidirectional channels, which will break the bottleneck caused by unidirectional channels, and achieve 
better latency result than a T-NoC. 
As to the comparison between a BiNoC_4VC(32) with two bidirectional links and a T-NoC_4VC(32)_4L 
with four unidirectional links, T-NoC_4VC(32)_4L performs better than BiNoC_4VC(32) in uniform and 
42 
 
and 7(e) transpose traffics, and running Odd-Even routing under 7(b) uniform, 7(d) regional, and 7(f) transpose 
traffics.   
We can find that the effects of wormhole flow-control and virtual-channel flow-control toward our BiNoC 
architecture in terms of latency result versus various flit injection rates under the same buffer depth.  As 
illustrated in Figures 7(a), 7(b), 7(c) and 7(d), BiNoC_2VC(32) with virtual-channels performs much better than 
BiNoC_WH(32) running under wormhole flow-control using an equal total input buffer size of 32 (the two 
input buffers, each having a size of 16, can be implemented as two independent FIFOs for BiNoC_WH or two 
virtual-channels for BiNoC_2VC) in each direction.  This is because the virtual-channel diminishes the 
blocking probability caused by wormhole flow-control.  However, BiNoC_WH(32) performs better than other 
virtual-channel flow-control architectures in transpose traffic with XY routing applied as illustrated in Figure 
7(e), because virtual-channel flow-control and adaptive routing raise the physical channel utilization probability 
in trade of using a more complex arbitration technique and one more stage of router pipeline, which is not 
necessary for regular traffic such as transpose when packets can always flow smoothly. 
0
100
200
300
400
500
600
0 0.2 0.4 0.6
la
te
nc
y (n
or
m
al
iz
ed
 cy
cl
e)
flit injection rate (flit/node/cycle)
BiNoC_WH(32)
BiNoC_2VC(32)
BiNoC_3VC(48)
BiNoC_4VC(64)
BiNoC_4VC(32)
0
100
200
300
400
500
600
0 0.2 0.4 0.6
la
te
nc
y (n
or
m
al
iz
ed
 cy
cl
e)
flit injection rate (flit/node/cycle)
BiNoC_WH(32)
BiNoC_2VC(32)
BiNoC_3VC(48)
BiNoC_4VC(64)
BiNoC_4VC(32)
 
(a)                                    (b) 
0
100
200
300
400
500
600
0 0.2 0.4 0.6
la
te
nc
y (n
or
m
al
iz
ed
 cy
cl
e)
flit injection rate (flit/node/cycle)
BiNoC_WH(32)
BiNoC_2VC(32)
BiNoC_3VC(48)
BiNoC_4VC(64)
BiNoC_4VC(32)
0
100
200
300
400
500
600
0 0.2 0.4 0.6
la
te
nc
y (n
or
m
al
iz
ed
 cy
cl
e)
flit injection rate (flit/node/cycle)
BiNoC_WH(32)
BiNoC_2VC(32)
BiNoC_3VC(48)
BiNoC_4VC(64)
BiNoC_4VC(32)
 
    (c)                                    (d) 
44 
 
0
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
0 20 40 60 80 100 120 140
la
te
nc
y (n
or
m
al
iz
ed
 cy
cl
e)
depth of each buffer (flit)
T‐NoC_2VC
BiNoC_WH
BiNoC_2VC
0
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
0 20 40 60 80 100 120 140
la
te
nc
y (n
or
m
al
iz
ed
 cy
cl
e)
depth of each buffer (flit)
T‐NoC_4VC
T‐NoC_4VC_4L
BiNoC_4VC
 
        (a)                                   (b) 
Figure 8.  Latency versus Buffer Size Analysis. 
The latency diagrams are separated according to the number of total buffer queues in each direction of the 
router architectures for fair comparison.  Figure 8(a) shows the results of simulation on T-NoC_2VC, 
BiNoC_WH, and BiNoC_2VC, which contain two buffer queues in each direction, under different queue depths 
at a flit injection rate of 0.512.  We can observe that as buffer size decreases, the latencies of BiNoC_2VC are 
not increased dramatically as the other two architectures do.  In other words, our proposed virtual-channel 
flow-control based BiNoC architecture can achieve better buffer utilization efficiency thus also increase the 
physical channel utilization. 
Another quite valuable phenomenon appeared in these simulation results is that NoC performance cannot 
keep improving while the buffer size is increased.  For instance, increasing the depth of each queue from 8 to 
32 flits can achieve a great deal of performance improvement in a T-NoC_2VC, while there is a slight latency 
reduction if the queue size increases from 32 to 128 flits.  However, we find that our BiNoC, if limited with 
fewer buffer area cost, can still achieve a better performance than a typical NoC does.  Furthermore, 
virtual-channel flow-control performs better than wormhole flow-control on our BiNoC architecture while the 
buffer size is small.  The latency comparison of T-NoC_4VC and BiNoC_4VC at a flit injection rate of 0.704 
also exhibits significant performance superiority in the BiNoC router with dynamic reconfigurable bidirectional 
channels as illustrated in Figure 8(b).   
C.4. QoS Support for BiNoC 
A QoS-aware BiNoC architecture is proposed in [6] to support guarantee-service (GS) traffic while 
reducing packet delivery latency.  With the dynamically self-reconfigured bidirectional communication 
channels incorporated in BiNoC, our proposed QoS-aware technique can promise more flexibility for various 
traffic flow patterns.  Specifically, a novel inter-router communication protocol is proposed to prioritizes 
bandwidth arbitration in favor of high-priority GS traffic flows.  Multiple virtual-channels with prioritized 
routing policy are also implemented to facilitate data transmission with QoS considerations.  Combining these 
architectural innovations, the QoS-aware BiNoC architecture can promise reduced latency of packet delivery 
and more efficient channel resource utilizations. 
46 
 
C.4.2. QoS Design for BiNoC Router 
A flexible virtual-channel management mechanism is applied to enhance the authority of the GS packets in 
BiNoC.  In each direction of the router, a four-entry prioritized virtual-channel module is implemented.  Two 
of the virtual-channels are specifically designed for GS packets but the other two virtual-channels can be 
utilized by both GS and BE packets, thus we can reduce the blocking probability of GS packets in the VA stage.  
The intra-router arbitration is applied to the prioritized virtual-channels at the SA stage according to the QoS 
requirements of traffic flows.  
To maximum the advantages of dynamic self-reconfigurable bidirectional channels in BiNoC and provide 
a superior performance guarantee for the GS packets, an inter-router arbitration technique is proposed and 
integrated into the channel-direction control protocol to extend the scope of the channel arbitration from a local 
router to adjacent routers.  In this scheme, the GS packets will be assigned a higher priority in adjusting the 
channel direction such that we can further improve the communication performance of GS traffic. 
Figure 10 shows the proposed connection-less QoS scheme in our router model. In order to keep up with 
the double bandwidth obtainable in each output direction, the number of intra-router channel arbiters is also 
doubled to pick two requests in each input direction.  In this design, at most two GS packets requesting for the 
same output direction can be delivered simultaneously by configuring both bidirectional channels to the target 
direction without any blocking.  Then the contentions among GS packets from different queues can be greatly 
reduced.  
 
Figure 10.  Proposed QoS Scheme in a BiNoC Router. 
In this QoS-aware BiNoC architecture, we make the GS packets to be given a precedence over BE packets 
not only in the intra-router arbitration among other BE packets in the local router, but also in the inter-router 
arbitration which tackles the channel direction with the adjacent routers.  The detailed inter-router arbitration 
48 
 
BiNoC_QoS_OE also adopts the proposed prioritized deadlock-free routing which routes the GS packets and 
BE packets respectively with adaptive Odd-Even and deterministic OE-fixed algorithms.  All of the NoC 
architectures above are implemented in a four-stage pipelined router design based on virtual-channel 
flow-control, with four virtual-channels in length of 8 flits in each direction. 
C.4.3.1. Comparison between BiNoC_QoS and BiNoC_4VC 
Figure 12 illustrates comparisons of BiNoC_4VC Architecture with BiNoC_QoS architecture by latency 
versus flit injection rate.  Results are obtained by running 12(a) uniform, 12(b) transpose, and 12(c) hotspot 
traffics, in which GS traffic occupies 20% of the total traffic.  We can find that the latency results between 
BiNoC_4VC which only provides BE service, and BiNoC_QoS which permits the GS packets a higher priority 
to utilize the network resources.  Since the prioritized intra-router and inter-router arbitration schemes favor the 
GS traffic on resource allocation, there is a significant amount of latency reduction in the GS packets while the 
BE packets get a worse performance.  We can observe that the total average latency of BiNoC_4VC lies 
between the latency results of the prioritized GS and BE traffics.  Note that the available virtual-channels and 
buffer space for BE packets may be occupied by GS packets under the QoS mechanism applied.  The network 
capacity for the BE packets is reduced such that the packet injection saturation point lessens.  While the GS 
packets not only retain the authority for all the network resources but also have the precedence to use the 
channel bandwidth, the latency curves of GS packets are not increased drastically as the BE packets do, thus 
lengthen the packet injection saturation points. 
0
50
100
150
200
250
300
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
la
te
nc
y (c
yc
le
)
flit injection rate (flit/node/cycle)
BiNoC_4VC
BiNoC_QoS(GS)
BiNoC_QoS(BE)
 
(a) 
0
50
100
150
200
250
300
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
la
te
nc
y (c
yc
le
)
flit injection rate (flit/node/cycle)
BiNoC_4VC
BiNoC_QoS(GS)
BiNoC_QoS(BE)
 
(b) 
50 
 
the communication efficiency of the GS packets is further improved.  Comparing to NoC_QoS, the latency 
promotion is apparent under transpose traffic and hotspot traffic where the performance gap between GS traffic 
and BE traffic is enlarged in BiNoC_QoS as shown in Figures 13(b) and 13(c). 
0
50
100
150
200
250
300
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
la
te
nc
y (c
yc
le
)
flit injection rate (flit/node/cycle)
NoC_QoS(GS)
NoC_QoS(BE)
BiNoC_QoS(GS)
BiNoC_QoS(BE)
 
(a) 
0
50
100
150
200
250
300
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
la
te
n
cy
 (cy
cl
e
)
flit injection rate (flit/node/cycle)
NoC_QoS(GS)
NoC_QoS(BE)
BiNoC_QoS(GS)
BiNoC_QoS(BE)
 
(b) 
0
50
100
150
200
250
300
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
la
te
nc
y (c
yc
le
)
flit injection rate (flit/node/cycle)
NoC_QoS(GS)
NoC_QoS(BE)
BiNoC_QoS(GS)
BiNoC_QoS(BE)
 
(c) 
Figure 13. Comparison of NoC_QoS with BiNoC_QoS. 
C.4.3.3. Analysis of Prioritized Routing 
To illustrate the benefit of our prioritized routing restriction for traffic flows with different QoS 
requirements, Figure 14 show the comparison of BiNoC_QoS architecture with BiNoC_QoS_OE architecture 
by latency versus injection rate.  Results are obtained by running 14(a) uniform, 14(b) transpose, and 14(c) 
hotspot traffics in which GS traffic occupies 20% of the total traffic. 
52 
 
C.4.4.4. Comparison between GS and BE Traffics 
Figures 15(a) and 15(b) illustrate the latency results of GS packets and BE packets respectively between 
NoC_QoS and BiNoC_QoS under various ratios of GS traffic to the total traffic.  Results are obtained by 
running hotspot traffic.  The GS ratio is varied from 10% to 50% of the total traffic in our experiments, because 
only a small portion of the total network traffic is expected to be QoS guaranteed in realistic cases.  Under a 
fixed flit injection rate, we can observe that as the ratio of GS traffic increases, the latency of GS packets steps 
up as a result of the confliction between the GS traffics.  However, the GS latency of BiNoC_QoS is not 
increased drastically as NoC_QoS does especially when the ratio grows higher than 30%.  This is attributed to 
the flexibility of the bidirectional channels and the proposed inter-router arbitration scheme that greatly enhance 
the communication performance of the GS packets.  As to the latency results of BE traffic, they also get worse 
as the GS ratio grows, since more network resource utilization priority is given to the GS traffic.  We also plot 
the latency comparisons between BiNoC_QoS and BiNoC_QoS_OE for GS and BE traffic flows as shown in 
Figures 16(a) and 16(b).  
 
(a) 
 
(b) 
Figure 15.  Comparisons between NoC_QoS and BiNoC_QoS. 
54 
 
C.5.1. Design Concept of Virtual Channel Sharing 
As shown in Figure 17, each output direction in a router has one set of output virtual-channels can be 
allocated, which located in its corresponding input direction in the adjacent routers. One of two prerequisites for 
a packet travels to the next node through one output port is to acquire an output virtual-channel from the 
virtual-channel set associated with this output port. Once the virtual-channels associated with this output 
direction are all reserved, the remaining packets which want to pass through this output port must wait for any 
output virtual-channel to be released.  
 
Output 
East
Output 
North
Output 
West
Output 
South
 
Figure 17. Output Port Associated with a Virtual-Virtual Set. 
 
Figure 18. Two Virtual-Channel Sets Available for Each Output Direction. 
In the proposed router architecture as shown in Figure 18, each output direction has two output 
virtual-channel sets can be accessed. One is Main-Virtual-Channel (MVC) set. This set is consisted of 
virtual-channels which located in the corresponding input direction in the adjacent router, like the conventional 
router architecture. And another set is Neighbor-Virtual-Channel (NVC) set. This set is consisted of half number 
56 
 
 
Figure 19.  Original Resource Dependences in Routers. 
 
(a)                       (b) 
Figure 20.  Possible Routing Path in Shared Virtual-channel based BiNoC. 
traffic
 
Figure 21.  Modified Resource Dependences in BiNoC. 
58 
 
 
   (a) (b) 
Figure 23. Example on NVC Allocation Constraint-2 Violation. 
With these NVC allocation constraints, we can ensure that the virtual-channel sharing based NoC/BiNoC 
design is deadlock-free with any conventional routing algorithms. Figure 24 shows the flow control of 
VCS-based router architecture, when a head flit arrives to the router, the first step is to decide the routing 
direction of this packet by routing computation. And the second step is to acquire an output virtual-channel. 
Packets will prefer to select a MVC rather than a NVC if at least one MVC is available. If MVCs in the MVC 
set are all reserved but at least one NVC in the NVC set can be acquire, the NVC allocation constraints will first 
be applied to check the buffer dependency between the current occupied input virtual-channel and all available 
output virtual-channel in the NVC set and remove the NVCs which may cause deadlock problems from the list 
of available NVCs. And then the packet tries to acquire a NVC from remaining NVCs. After virtual-channel 
allocation, packets will try to acquire the bandwidth of physical channels (Switch Allocation) and travel to the 
next routers. 
60 
 
v : 1
arbiter 1
v : 1
arbiter vp
VA stage1
(v x p) : 1
arbiter 1
(v x p) : 1
arbiter vp
VA stage2
request
grant
Arbitration 
Result 
Storage
Arbitration
Result 
Storage
rsv
North
Status
Local
Status
VC Management
Allocator ARSs
VC Management
 
Figure 25. Virtual-Channel Allocation on Original BiNoC Router Architecture. 
In the proposed VCA architecture as shown in Figure 26, to support the MVC and NVC allocation, there 
are two VCM units and twice the number of ARS units built in the proposed VCA unit. During the MVC 
allocation, both the MVC Management and Arbitration Storages for MVC (ARS-MVC) are used to manage 
MVCs’ status and record the arbitration results of MVCs. During the NVC allocation, both NVC Management 
and Arbitration Result Storages for NVC (ARS-NVC) are used to manage NVCs’ status and record the 
arbitration results of NVCs. On the other hand, intuitively, to allocate twice the number of output 
virtual-channels for an output port, it is necessary to considerably increase the size and the number of arbiters in 
an allocator. The area overhead of the proposed allocator should not be underestimated. To avoid the large 
amount of area increase in our proposed VCA unit, a folding technology is used to implement an inexpensive 
allocator. Since MVCs and NVCs in an output direction will not be allocated simultaneously, in the proposed 
VCA unit, the allocator which can allocate 2n virtual-channels (MVCs + NVCs) for each output direction will 
be folded to a smaller allocator which can allocate n virtual-channels for each output direction, and we 
time-multiplex the operations of the MVC allocation and the NVC allocation to this single allocator unit by 
MUXs and DEMUXs.  
62 
 
Arbitratio
n Result
Storage
(NVC)
Router 3 Router 4
Requests from 
the routing 
computation
VC0
VC1
VC2
VC3
VC0
VC1
VC2
VC3
VC0
VC1
VC2
VC3
VC
0
VC
1
VC
2
VC
3
Arbitratio
n Result
Storage
(MVC)
01
Router 2
Requests from 
the routing 
computation
Arbitration 
Result
Storage
(NVC)
Arbitration 
Result
Storage
(MVC)
rbitratio
n esult
torage
( )
Arbitratio
n Result
Storage
(NVC)
Arbitration 
Result 
Stora  
(NV )
rbitratio
n esult
torage
( )
Arbitratio
n Result
Storage
(MVC)
Arbitration 
Result 
Stora  
(MV )
rbitration 
esult
torage
( )
Arbitration 
Result
Storage
(NVC)
Arbitration  
Result 
Stora  
(NV )
rbitration 
esult
torage
( )
Arbitration 
Result
Storage
(MVC)
Arbitration 
Result 
Stora  
(MV )
01 01 01
Allocator for 
South Edge
1
0
1
0
1
0
1
0
Allocator 
for East 
Edge
NVC Reservation 
Checker
NVC Reservation 
Checker
 
Figure 27. Inter-Router Virtual-Channel Status Synchronization Scheme. 
The inter-router control scheme for the virtual-channels status synchronization is illustrated in Figure 28(b). 
Assume the virtual-channel associates with the ARS units as shown in Figure 28(b) is the VC3 located at the 
north edge of Router4 as shown in Figure 27. The FSM unit built in Router3 controls the flow of the NVC 
reservation checking process according to the input signal in_nvc_req and the output signal out_nvc_req. The 
state mechanism implemented for virtual-channel status synchronization is simple and inexpensive. It contains 
three main states: STANDBY, WAIT, and RSV as shown in Figure 28(a).  
 
(a) 
64 
 
different number of virtual-channels such as BiNoC_VCS1(2VC) and BiNoC_VCS1(4VC). In order to remove 
the effect of channel length on the router performance, routers listed in Table 3 are with equal virtual-channel 
length. Each router has two In/out ports at each input direction, and a 10×10 crossbar switch used to switch 
packets from input ports to output ports. 
Table 3. BiNoC Architectures used in our Experiments for Simulation-1. 
 
Table 4 lists the other five BiNoC-based router architectures used for comparison purpose in Simulation-2. 
Three of the five router architectures are also the original BiNoC router architectures with a conventional 
virtual-channel management, dividedly configured with different numbers of virtual-channels such as 
BiNoC2(2VC), BiNoC2(4VC), and BiNoC2(8VC). And the other two router architectures are the proposed 
BiNoC_VCS router architectures, such as BiNoC_VCS2(2VC) and BiNoC_VCS2(4VC). The difference with 
the router architectures for Simulation-1 is that the buffer size at each input port in the router architectures as 
listed in Table 4 is equivalent. And the length of a virtual-channel in a router is according to the number of 
virtual-channels in the router. Each router also has two Inout ports at each input direction, and a 10×10 crossbar 
switch used to switch packets from input ports to output ports. 
Table 4. BiNoC Architectures used in our Experiments for Simulation-2. 
 
C.5.4.1. Simulation-1 for BiNoC platforms with Odd-Even Routing Algorithm 
Figure 29 and Figure 30 show the performance comparison, respectively about the transmission delay 
versus flit injection rates and the average throughput versus flit injection rates, on our proposed BiNoC_VCS 
66 
 
Regional Traffic Condition (Odd-Even routing algorithm)
flit injection rate (flit/node/cycle)
0.0 0.2 0.4 0.6 0.8
la
te
nc
y 
(c
yc
le
)
0
100
200
300
400
500
600
BiNoC1 (2VCs, 8Bufs) 
BiNoC1 (4VCs, 8Bufs)
BiNoC1 (8VCs, 8Bufs)
BiNoC_VCS1 (2VCs, 8Bufs)
BiNoC_VCS1 (4VCs, 8Bufs)
 
(a) 
Uniform Traffic Condition (Odd-Even routing algorithm)
flit injection rate (flit/node/cycle)
0.0 0.1 0.2 0.3 0.4 0.5 0.6
la
te
nc
y 
(c
yc
le
)
0
100
200
300
400
500
600
BiNoC1 (2VCs, 8Bufs) 
BiNoC1 (4VCs, 8Bufs)
BiNoC1 (8VCs, 8Bufs)
BiNoC_VCS1 (2VCs, 8Bufs)
BiNoC_VCS1 (4VCs, 8Bufs)
 
 (b) 
Hotspot Traffic Condition (Odd-Even routing algorithm)
flit injection rate (flit/node/cycle)
0.0 0.1 0.2 0.3 0.4
la
te
nc
y 
(c
yc
le
)
0
100
200
300
400
500
600
BiNoC1 (2VCs, 8Bufs) 
BiNoC1 (4VCs, 8Bufs)
BiNoC1 (8VCs, 8Bufs)
BiNoC_VCS1 (2VCs, 8Bufs)
BiNoC_VCS1 (4VCs, 8Bufs)
 
(c) 
Figure 29. Latency versus Injection Rate Results 
68 
 
C.5.4.2. Simulation-2 for BiNoC platforms with Odd-Even Routing Algorithm 
Figure 31 and Figure 32 show the performance comparisons in Simulation-2, respectively about the 
transmission delay versus flit injection rates and the average throughput versus flit injection rates, on our 
proposed router architecture and the original BiNoC router architecture, both using Odd-Even routing based 
routers, and running under regional, uniform, and hotspot traffic conditions. Like the previous simulation result 
as shown in Simulation-1, in regional traffic, since the transmission distance for a packet is short and a routing 
path in regional traffic is always regular, the performance growth for our proposed mechanism is slight small. In 
uniform traffic, our proposed mechanism makes up for the performance degradation caused by the 
load-imbalance problem in Odd-Even routing algorithm. As shown in Figure 31(b), the saturation point of 
BiNoC_VCS2(2VC) or BiNoC_VCS2(4VC), has been substantially postponed. In Figure 32(b), we can observe 
that BiNoC_VCS2(2VC) has approximately 7.2% throughput improvement compares with BiNoC2(2VC), and 
BiNoC_VCS2(4VC) has approximately 10.07% throughput improvement compares with BiNoC2(4VC). The 
simulation results of our proposed architectures with the Odd-Even routing algorithm in hotspot traffic 
according to the specifications for Simulation-2 are shown in Figure 31(c) and Figure 32(c). From the 
perspective of transmission delay, our proposed architectures still has significant performance superiority when 
working under the non-uniform traffic condition. As shown in   Figure 32(c), BiNoC_VCS2(2VC) has 9.22% 
throughput improvement compares with BiNoC2(2VC). For BiNoC_VCS2(4VC), even through 
BiNoC_VCS2(4VC) has nearly maximum network throughput compares with BiNoC2(4VC), the average 
network throughput of BiNoC_VCS2(4VC) is still higher than BiNoC2(4VC). 
70 
 
Regional Traffic Condition (Odd-Even routing algorithm)
flit injection rate (flit/node/cycle)
0.0 0.2 0.4 0.6 0.8
th
ro
ug
hp
ut
 (f
lit
/n
od
e/
cy
cl
e)
0.0
0.2
0.4
0.6
0.8
BiNoC2 (2VCs, 32Bufs) 
BiNoC2 (4VCs, 16Bufs)
BiNoC2 (8VCs, 8Bufs)
BiNoC2_VCS (2VCs, 32Bufs)
BiNoC2_VCS (4VCs, 16Bufs)
 
(a) 
Uniform Traffic Condition (Odd-Even routing algorithm)
flit injection rate (flit/node/cycle)
0.0 0.2 0.4 0.6 0.8
th
ro
ug
hp
ut
 (f
lit
/n
od
e/
cy
cl
e)
0.0
0.1
0.2
0.3
0.4
0.5
BiNoC2 (2VCs, 32Bufs) 
BiNoC2 (4VCs, 16Bufs)
BiNoC2 (8VCs, 8Bufs)
BiNoC_VCS2 (2VCs, 32Bufs)
BiNoC_VCS2 (4VCs, 16Bufs)
 
 (b) 
Hotspot Traffic Condition (Odd-Even routing algorithm)
flit injection rate (flit/node/cycle)
0.0 0.2 0.4 0.6 0.8
th
ro
ug
hp
ut
 (f
lit
/n
od
e/
cy
cl
e)
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
BiNoC2 (2VCs, 32Bufs) 
BiNoC2 (4VCs, 16Bufs)
BiNoC2 (8VCs, 8Bufs)
BiNoC_VCS2 (2VCs, 32Bufs)
BiNoC_VCS2 (4VCs, 16Bufs)
 
(c) 
Figure 32. Throughput versus Injection Rate Results. 
72 
 
section.  
In this project, we proposed a Bidirectional Fault-Tolerant NoC (BFT-NoC) scheme to well control the two 
problems mentioned above by utilizing bidirectional channel. As shown in Figure 33(c), although the TX-Channel is 
faulty, the intact RX-Channel can be changed in bidirectional operations to provide both TX and RX 
communications. BFT-NoC can provide fault-tolerance except that we have a pair of faulty channels as shown in 
Figure 34(a). Therefore, we analyzed the probability that there is a certain number of faulty channels in an 8×8 mesh 
network and at least one pair of faulty channels located between two neighboring routers. Figure 34(b) shows that 
even when the number of faulty channels is increased to seven, the probability is less than 10%. In other words, our 
BFT-NoC can provide above 90% reliability in an 8×8 mesh network where there even exist seven faulty channels. 
Furthermore, BFT-NoC can achieve almost 100% reliability after coupling with another detour-based scheme.  
0
10
20
30
40
50
0 1 2 3 4 5 6 7
P
ro
b
ab
il
it
y (
%
)
Number of faulty channel(s)
 
  Figure 34. (a) Example of a pair of faulty channels and (b) probabilities of existing at least 
one pair of faulty channels in an 8×8 mesh among different numbers of faulty channels. 
C.6.2. Bidirectional Fault-Tolerance NoC Router Architeccture 
Referring to Figure 35, in a Bidirectional Fault-Tolerant NoC (BFT-NoC), two bidirectional channels are 
equipped between neighboring routers. An additional channel controller is required to dynamically select the data 
flow direction in the bidirectional channels whenever any faulty channel is detected or the faulty channel is 
recovered. We focus on studies about the capability and feasibility in applying bidirectional channel for NoC 
fault-tolerant communications. Hence, during the normal operations (i.e., no faulty channel) of our experiments, one 
of the pair of bidirectional channels is used for the TX-Channel (TX-Ch) and the other is served for the RX-Channel 
(RX-Ch). When one of the two channels is faulty, the other channel is changed to operate bidirectionally; that is, the 
intact channel can share for both TX and RX data flows. Compared with the other fault-tolerant schemes as 
mentioned above, our proposed mechanism can dynamically react to the fault conditions and be independent of the 
74 
 
UNI-directional NoC (UNI-NoC) fails in case of any faulty channel, the failure rate can be represented as:  
Ch
n
ChNoCUNI FRnFRFR  2)1(1 2  
With bidirectional channels, if there is a pair of such channels between each pair of routers, then the NoC 
traffic will not be severely disrupted unless both channels fail. Therefore, the failure rate of BFT-NoC may be 
estimated as: 
NoCUNI
Ch
Ch
n
ChNoCBFT FR
FRFRnFRFR   2)1(1
22
 
Since FRCh << 1, one has FRBFT-NoC << FRUNI-NoC. Clearly, with bidirectional channels, the failure rate of 
BFT-NoC is significantly reduced.  
0
10
20
30
40
50
60
70
80
90
100
0 1 2 3 4 5 6 7
Re
lia
bi
lit
y (
%
)
Number of faulty channel(s)
Method‐1 + BFT‐NoC
BFT‐NoC 
Method‐1 
          
90
91
92
93
94
95
96
97
98
99
100
0 1 2 3 4 5 6 7
Re
lia
bi
lit
y (
%
)
Number of faulty channel(s)
Method‐2 + BFT‐NoC
BFT‐NoC 
Method‐2
 
(a)                                          (b) 
Figure 37. (a) Reliabilities of Method-1, BFT-NoC, and Method-1+BFT-NoC, and (b) reliabilities 
of Method-2, BFT-NoC, and Method-2+BFT-NoC. 
Once faulty channels exist in an NoC, fault-tolerant schemes can be used to provide a certain reliability to 
probably maintain the functional correctness for a system operations. Here, we evaluate the reliabilities of our 
proposed BFT-NoC and the other two schemes as proposed in [8] and [9], which are respectively called as Method-1 
and Method-2 in later sections. Each of the reliability data shown in Figure 37 is caculated with an 8×8 mesh 
network. Since BFT-NoC cannot tolerate the faulty case where channels between neighboring nodes are both faulty, 
BFT-NoC can provide a 90.80% reliability even if seven faulty channels exist in the network. Referring to Figure 
37(a), Method-1 provides a poor reliability when the number of faulty channels is bigger than 1. The reason is that 
Method-1 sets a constraint that all faults must be related to one router. That is, if there are two faulty channels 
connected to four routers, deadlocks could happen in the use of Method-1. As shown in Figure 37(b), Method-2 
supports a good reliability (> 98%) in case of seven faults. However, Method-2 needs to reconfigure the global 
routing tables; thus, Method-2 is difficult to dynamically handle transient faults. Last and most importantly, 
BFT-NoC can be combined with Method-1 or Method-2 as a hybrid scheme of Method-1+BFT-NoC or 
Method-2+BFT-NoC, which respectively improve the reliabilities to 99.58% and 99.94% as shown in Figures 37(a) 
76 
 
0
50
100
150
200
250
300
0.0055 0.0067 0.0079 0.0091 0.0103 0.0115
A
vg
. pa
ck
et
 lat
en
cy
 (cy
cl
e)
Max. packet injection rate (packets/cycle/node)
XY ‐ Hotspot Latency
zero-fault
1-fault
3-fault
7-fault
20-fault
      
0.54
0.61
0.68
0.75
0.82
0.89
0.96
1.03
0.0055 0.0067 0.0079 0.0091 0.0103 0.0115
A
vg
. th
ro
ug
hp
ut
 (p
ac
ke
ts
/c
yc
le
/n
od
e)
Max. packet injection rate (packets/cycle/node)
XY ‐ Hotspot Throughput
zero-fault
1-fault
3-fault
7-fault
20-fault
× 10‐2
 
(b) 
0
100
200
300
400
500
0.008 0.011 0.014 0.017 0.02 0.023
A
vg
. pa
ck
et
 lat
en
cy
 (cy
cl
e)
Max. packet injection rate (packets/cycle/node)
OE ‐ Uniform Latency
zero-fault
1-fault
3-fault
7-fault
20-fault
      
0.8
1
1.2
1.4
1.6
1.8
2
2.2
0.008 0.011 0.014 0.017 0.02 0.023
A
vg
. th
ro
ug
hp
ut
 (pa
ck
et
s/
cy
cl
e/
no
de
)
Max. packet injection rate (packets/cycle/node)
OE ‐ Uniform Throughput
zero-fault
1-fault
3-fault
7-fault
20-fault
× 10‐2
 
(c) 
0
100
200
300
400
500
0.01 0.0107 0.0114 0.0121 0.0128 0.0135
A
vg
. pa
ck
et
 lat
en
cy
 (cy
cl
e)
Max. packet injection rate (packets/cycle/node)
OE ‐ Hotspot Latency
zero-fault
1-fault
3-faults
7-faults
20-faults
      
0.99
1.02
1.05
1.08
1.11
1.14
1.17
1.2
0.01 0.0107 0.0114 0.0121 0.0128 0.0135
A
vg
. th
ro
ug
hp
ut
 (pa
ck
et
s/
cy
cl
e/
no
de
)
Max. packet injection rate (packets/cycle/node)
OE ‐ Hotspot Throughput
zero-fault
1-fault
3-faults
7-faults
20-faults
× 10‐2
 
(d) 
  Figure 38. Performance variations in latency (left) and throughput (right) with XY under (a) uniform and 
(b) hotspot  traffics, and OE under (c) uniform and (d) hotspot traffics. 
 
C.7. Conclusion 
In this report, we introduced a novel BiNoC backbone architecture using dynamic self-reconfigurable 
bidirectional channels to improve bandwidth utilization with effective implementation cost.  A new, distributed 
channel-direction control protocol that supports real-time traffic-direction arbitration while avoiding deadlock and 
starvation has been presented. 
Based on this BiNoC backbone architecture, we implemented a QoS-aware BiNoC architecture which can 
arbitrate the inter-router channel direction based on real-time traffic condition.  Specifically, an inter-router 
channel-direction arbitration scheme which assigns a higher priority for the critical GS traffic to traverse the network 
was presented.  Moreover, a flexible virtual-channel management mechanism and a novel prioritized routing policy 
78 
 
Publication List on NoC from our Group: 
[1] Y. C. Lan, H. A. Lin, S. H. Lo, Y. H. Hu and S. J. Chen, “A Bidirectional NoC (BiNoC) Architecture with 
Dynamic Self-Reconfigurable Channel,” IEEE Trans. on Computer-Aided Design, Vol. 30, No. 3, pp. 427-440, 
March 2011. 
[2] Y. C. Lan, M. Chen, A. Su, Y. H. Hu, and S. J. Chen, “Flow Maximization for NoC Routing Algorithms,” IEEE 
Computer Society Annul Symposium on VLSI, Montpellier, France, Apr. 2008, pp. 335-340. 
[3] Y. C. Lan, M. C. Chen, A. P. Su, Y. H. Hu, and S. J. Chen, “Fluidity Concept for NoC: A Congestion Avoidance 
and Relief Routing Scheme,” IEEE International SOC Conference (SOCC), Newport Beach, California, USA, 
September 2008, pp. 65-70. 
[4] Y. C. Lan, M. C. Chen, W. D. Chen, and S. J. Chen, “Performance-Energy Tradeoffs in Reliable NoCs,” 
International Symposium on Quality Electronic Design (ISQED), San Jose, California, USA, Mar. 2009, pp. 
141-146. 
[5] Y. C. Lan, S. H. Lo, Y. C. Lin, Y. H. Hu and S. J. Chen, “BiNoC: A Bidirectional NoC Architecture with 
Dynamic Self-Reconfigurable Channel,” The 3rd ACM/IEEE International Symposium on Networks-on-Chip 
(NOCS), San Diego, California, USA, May 2009, pp. 266-275 (Best Paper Award). 
[6] S. H. Lo, Y. C. Lan, H. H. Yeh, W. C. Tsai, Y. H. Hu, and S. J. Chen, “'QoS Aware BiNoC Architecture,” The 
24th IEEE International Parallel & Distributed Processing Symposium (IPDPS), Atlanta, Georgia, USA, April 
2010, pp. 1-10. 
[7] Y. R. Chen, W. T. Su, P. A. Hsiung, Y. C. Lan, Y. H. Hu, and S. J. Chen, “Formal Modeling and Verification for 
Network-on-chip,” The First International Conference on Green Circuits and Systems (ICGCS), Shanghai, 
China, June 2010, paper D2-PM1-R71. 
[8] W. C. Tsai, Y. C. Lan, S. J. Chen, and Y. H. Hu, “DyML: Dynamic Multi-Level Flow Control for Networks on 
Chip,” The 23rd IEEE International SOC Conference (SOCC), Las Vegas, Nevada, USA, September 2010, pp. 
429-434. 
[9] W. C. Tsai, K. C. Chu, S. J. Chen, and Y. H. Hu, “TM-FAR: Turn-Model Based Fully Adaptive Routing for 
Networks on Chip,” The 18th IEEE/IFIP International Conference on VLSI and System-on-Chip (VLSI-SoC), 
Madrid, Spain, September 2010, pp. 19-24. 
[10] Wen-Chung Tsai, Deng-Yuan Zheng, Sao-Jie Chen, and Yu-Hen Hu, “A Fault-Tolerant NoC Scheme Using 
Bidirectional Channel,” Design Automation Conference, San Diego, California, pp. 918-923, June 2011. 
80 
 
 
 ii
 
ABSTRACT 
 
Network-on-Chip (NoC) is a promising on-chip communication infrastructure 
and is commonly considered as an aggressive long-term approach for on-chip 
communications in Multi-Processor System-on-Chip (MPSoC) and Chip 
Multi-Processor (CMP). An NoC Router (NoCR) that includes a network interface 
design and a 4-port router is proposed in this Report. The NoCR design functions 
have been proven on an Altera FPGA development board with a NIOS2 CPU attached 
to the network interface. The flexible NoCR architecture enables fluidity-aware 
transport management, highly adaptive network routing, and bidirectional 
fault-tolerant data-link connection for on-chip communications. These functions 
respectively correspond to the Transport Layer, Network Layer, and Data-Link Layer, 
as defined in the ISO reference model.  
Tested with both synthetic traffic patterns as well as industry benchmark traffic 
patterns, significant performance enhancement and higher reliability have been 
observed when NoCR is compared to some state-of-the-art methods. Moreover, the 
implementation overheads analyzed by Synopsys Design Compiler in UMC 90nm 
technology are small in terms of chip area, power consumption, and logic latency. As 
a result, NoCR is an ideal on-chip interconnection solution for emerging many-core 
systems. 
 
Keywords: Network-on-Chip, Congestion Control, Flow Control, Routing Algorithm, 
Fault-Tolerance, Bidirectional Channel. 
  
 iv
 
2.3 Methodology and Implementation of the Proposed Dynamic Scheme ....... 22 
2.3.1 Congestion Avoidance and Congestion Relief ................................. 22 
2.3.2 Buffer Fluidity Concept ................................................................... 23 
2.3.3 In-transit Packets Concept ............................................................... 24 
2.3.4 Buffer Flow Monitor ........................................................................ 25 
2.3.5 Dynamic Buffer-Level Congestion Control ..................................... 27 
2.3.6 Dynamic Multi-Level Flow Control ................................................ 28 
2.3.7 Dynamic Traffic Control .................................................................. 30 
2.4 Experimental Results ................................................................................... 31 
2.4.1 Cycle Accurate Evaluation and its Settings ..................................... 31 
2.4.2 Experiments with Synthetic Traffics ................................................ 32 
2.4.3 Experiments with Real Traffic ......................................................... 37 
2.4.4 Implementation Overhead ................................................................ 40 
2.5 Remarks ....................................................................................................... 41 
CHAPTER 3 HIGHLY ADAPTIVE NETWORK ROUTING ......................... 43 
3.1 NoC Routing Basics .................................................................................... 43 
3.1.1 Characterization of NoC Routing .................................................... 43 
3.1.2 Deadlock and Livelock Issues ......................................................... 44 
3.1.3 Deadlock-Free Routing Schemes in NoCs ...................................... 45 
3.2 Turn Model Based Routing Basics .............................................................. 47 
3.2.1 The Odd-Even Turn Model .............................................................. 48 
3.2.2 The Odd-Even Turn-Model Based Routing Algorithm, ROUTE .... 49 
3.2.3 Odd-Even Based Routing Algorithms ............................................. 50 
3.2.4 Motivations of our Proposed Turn Model Based Routing Schemes 50 
3.3 Proposed Turn-Model Based Fully Adaptive Routing ................................ 50 
3.3.1 Turn Prohibitions Release ................................................................ 51 
3.3.2 Path Prohibitions Release ................................................................ 52 
3.3.3 Deadlock Free and Livelock Free .................................................... 55 
 vi
3.5.6 Packet Length Determination .......................................................... 87 
3.5.7 Buffer Size Allocation ...................................................................... 88 
3.5.8 Experimental Results ....................................................................... 89 
 3.5.8.1 Uniform Traffic Simulation Result ...................................... 89 
 3.5.8.2 Transpose Traffic Simulation Result .................................... 91 
 3.5.8.3 Hotspot Traffic Simulation Result ....................................... 92 
 3.5.8.4 Real Traffic Simulation Result ............................................. 93 
 3.5.8.5 Fault-Tolerance Simulation Result ...................................... 94 
 3.5.8.6 Implementation Overhead .................................................... 96 
3.5.9 Remarks ........................................................................................... 96 
CHAPTER 4 FAULT-TOLERANT DATA-LINK CONNECTION ................. 99 
4.1 Problem and Motivation .............................................................................. 99 
4.2 Fault-Tolerance Basics .............................................................................. 100 
4.2.1 Fault Types in NoCs ....................................................................... 100 
4.2.2 Fault-Tolerance in NoCs ................................................................ 101 
4.2.3 Bidirectional Channel in NoCs ...................................................... 101 
4.2.4 Problems of Existing Fault-Tolerant Schemes ............................... 102 
4.2.5 Methodology of our Proposed Scheme .......................................... 103 
4.3 Proposed Bi-directional Fault-Tolerant NoC Architecture ........................ 103 
4.3.1 Bidirectional Channel .................................................................... 104 
4.3.2 Bidirectional Router Architecture .................................................. 104 
4.3.3 Channel Direction Change Handshaking ....................................... 105 
4.3.4 Fault-Tolerance Control Procedure ................................................ 106 
4.3.5 In-router Deadlock and its Solution ............................................... 108 
4.3.6 Failure Rate Enhancement ............................................................. 109 
4.3.7 Reliability Enhancement ................................................................ 110 
4.4 Experimental Results ................................................................................. 111 
4.4.1 Experiments with Synthetic Traffics .............................................. 111 
4.4.2 Experiments with Real Traffics ..................................................... 113 
 viii 
 x 
Fig. 2-16. Task Mapping Results ................................................................................ 38 
Fig. 2-17. Performance Variations under (a) Consumer, (b) Auto-indust, and (c) 
Telecom Traffics ..................................................................................................... 39 
Fig. 2-18. Comparisons in Average Latency among Router Schemes under Real 
Traffics. ................................................................................................................... 40 
Fig. 2-19. Router Incorporated with the DyTC Module ............................................. 40 
Fig. 3-1. Local Congestion Scenarios in (a) Minimal Routing and (b) 
Non-Minimal Routing; and Faulty Link Cases in (c) Minimal Routing and (d) 
Non-Minimal routing ............................................................................................. 44 
Fig. 3-2. (a) Deadlock Condition and (b) Eight Turn Types in a Two-Dimensional 
Mesh .................................................................................................................... 45 
Fig. 3-3. Taxonomy of NoC Deadlock Avoidance Routing Schemes ...................... 46 
Fig. 3-4. Four Transmission Examples Following the Odd-Even Turn Model ........ 48 
Fig. 3-5. (a) Minimal Routing Criterion 2 and (b) Minimal Routing Criterion 3 .... 49 
Fig. 3-6. Examples of EN and ES Turn Prohibitions Imposed by Odd-Even Are 
Active in (a); but Released in (b), (c), and (d) by Using EVCT. ............................ 52 
Fig. 3-7. (a) Violated Turn Criterion Case and (b) Circular Waiting Path ................ 53 
Fig. 3-8. Enhanced Deadlock-Buffer (EDB) Architecture ....................................... 54 
Fig. 3-9. (a) EDB Parks the Dirty Packet in the Input Buffer of Port 0, and (b) the 
Packet Can Be Relayed to the Destination without Creating an NW Turn ............ 55 
Fig. 3-10. Routing Examples of (a) a Normal Case and (b) a Faulty Case of 
ROUTE ................................................................................................................... 57 
Fig. 3-11. Routing Examples of Packets Getting through the Prohibited Turn by (a) 
EVCT and (b) EDB under a Faulty Case of TM-FAR ........................................... 58 
Fig. 3-12. Performance under (a) Uniform, (b) Transpose, and (c) Hotspot Traffics . 59 
Fig. 3-13. (a) Available Direction Sets (ADS) and (b) NMinR Criterion 1 ................ 64 
Fig. 3-14. NMinR (a) Criterion 2-1, (b) Criterion 2-2, (c) Criterion 3-1, and (d) 
Criterion 3-2 ........................................................................................................... 66 
Fig. 3-15. NMinR (a) Criterion 4-1, (b) Criterion 4-2, and (c) Criterion 4-3 ............. 67 
Fig. 3-16. Performance Variations of (a) Uniform and (b) Hotspot Traffics .............. 73 
Fig. 3-17. Performance Variations of (a) Regional-Burst Traffic and (b) Faulty 
Link Case ................................................................................................................ 75 
Fig. 3-18. Performance Variations of (a) Transpose and (b) Telecom Traffics .......... 77 
Fig. 3-19. Performance Enhancement by 1024-bit Buffers over 512-bit Buffers ...... 78 
  
 xii
Fig. B-4. Non-Minimal Routing Algorithm Based on Negative-First .................... 129 
Fig. C-1. Validation by Self Loop Back Test .......................................................... 132 
 
 
 xiv
 
 2 
 
The Network-on-Chip (NoC) paradigm has emerged as a long-term, on-chip 
communication solution for Multi-Processor System on Chip (MPSoC) [2] and Chip 
Multi-Processor (CMP) [6] micro-architectures. NoC features an intelligent packet 
switching network system (see Fig. 1-2) that can deal well with the design issues of 
communication performance, power consumption, signal integrity, and system 
scalability in the next-generation SoCs.  
 
 
Fig. 1-1. SoC Architecture with Multi-Layer Bus. 
 4 
 
Within the NoCR design, an input buffer (or FIFO) is equipped to each input 
port connecting to a neighboring router as shown in Fig. 1-4(a). Moreover, the 
network interface unit includes both input and output FIFOs to process (pack and 
unpack) packets and throttle data flows between the processor and the network system 
as shown in Fig. 1-4(b).  
 
Sl
av
e
FI
FO
 
Ct
l.
M
as
ter
Re
gs
.
 
Fig. 1-3. NoC Router Architecture. 
 6 
Destination Offset is to support Direct Memory Access (DMA) between nodes. The 
CRC (Cyclic Redundancy Check) field is used for packet error detection. Moreover, 
the Control Code field can enable an intelligent network system. For example, bits in 
the Control Code can be used to distinguish packet types (uni-cast, multi-cast, or 
broadcast), record the packet sequence number (for error packet retransmissions), 
support Quality of Service (QoS), and so on. The NoCR design covers the 
specifications of interfacing signal, packet format, and configurable register set. 
Please refer to APPENDIX A for details.  
 
 
1.2.2 Applied NoC Topology  
Through programming the configurable routing table, NoCR can support routing 
packets in any kind of network topology under the premise that at most four 
neighboring routers are connected by the 4-port router as illustrated in Fig. 1-7. 
 
31             16 15     00 
Destination Address Control Code 
Source Address Data Length 
Destination Offset Extended Control Code 
Data (0 - 65535 flits) 
 
 
CRC (1 flit) 
 
Fig. 1-6. Packet Format. 
 8 
network congestions [8]. One of the most crucial issues for the contention resolution 
is, under a premise of a deadlock- and livelock-free routing algorithm, to enhance the 
utilization efficiency of available network resources in order to come up with a better 
communication performance. 
Contentions can be alleviated by both congestion control and flow control as the 
description in [8]: “Congestion control keeps the router network free of traffic jams; 
while flow control ensures that no transmission master overwhelms any of its 
counterpart slaves”. These two kinds of traffic control schemes are extensively used 
in NoCs. For congestion control, adaptive routing schemes [9], [10] can be used to 
forward packets around the contentions. In NoCs, most congestion control schemes 
depend on some form of buffer fill-level to select profitable routing paths such as [11], 
[12], [13], [14], [15], and [16]. For flow control in NoCs, link-layer (node-to-node) 
flow control schemes such as STALL/GO [17] and ACK/NACK [18] use a signal to 
ensure that the buffers are not overfilled between neighboring nodes. 
Transmission-layer (end-to-end) flow control schemes tackle congestions by 
exchanging buffer fill messages, namely credits, between the transmission pairs. 
However, credit traffic will consume a substantial amount of the bandwidth [8]. 
Accordingly, most NoCs such as [19] and [20] only apply the link-layer flow control 
to result in a chain of queued flits, then the transmission flow control can be 
automatically obtained by the chain of queued flits between transmission ends [8]; but, 
in the mean time, the network has been congested. To achieve a better tradeoff of flow 
control methods between link and transmission layers, some hybrid-layer schemes 
[21], [22], [23], [24] were proposed. As a whole, all the above-mentioned traffic 
control schemes refer to the static buffer-fill information to make decisions for flit and 
packet movements. 
To compensate the dynamic buffer operation information missed in previous 
traffic control schemes that solely refer to the static buffer fill-level information; we 
will propose a buffer fluidity-level applied to both congestion control and flow control. 
In the fluidity concept, traffic flows can be viewed as strings of flits stalled or fluid in 
 10
unpredictable period from a deadlock being detected to the deadlock being released 
[28]; deadlock-recovery techniques are relatively uncommon in NoCs [29].  
On the other hand, the switching technique determines how flits and packets are 
transported and stored between neighboring routers. Compared to other switching 
schemes (i.e., virtual-cut-through [30] and store-and-forward), wormhole [31] is the 
most common switching technique for NoCs because of its relatively small packet 
transmission latency and minimal buffer requirement. However, wormhole is prone to 
suffer from deadlocks [8]; the reason is that using wormhole switching, in a chain of 
blocked packets, head flits of those packets are probably queued inside buffers, 
blocked by tail flits of the other packet in the same buffers. However, with 
virtual-cut-through or store-and-forward, head flits are always queued in the front of 
buffers, the chained blocking scenario of the wormhole switching can be broken 
whenever there is any head flit escaping from the hold-and-wait dependency relation 
through other alternative routing paths. Therefore, wormhole switching might not be 
suitable for highly adaptive routing scheme such as deflection routing [26], [32]. We 
will discuss this issue in detail in Chapter 3. 
1.3.3 Data-Link Layer 
The main purpose of data-link layer protocols is to increase the reliability of the 
link up to a minimum required level, under the assumption that the physical layer by 
itself is not sufficiently reliable [8]. With continued shrinkage of semiconductor 
process feature sizes, on-chip interconnecting wires become increasingly vulnerable 
to failures caused by permanent physical damages (e.g., electronic migration and 
dielectric breakdown) and transient malfunctions (e.g., soft error and timing fault). 
Existing NoC fault-tolerant schemes [33], [34], [35], [36], [37] have been 
focused on efficient detour strategies for rerouting blocked packets. Although the 
faults exist in the physical layer of communication channels; however, these 
fault-tolerant schemes rely on changing routing paths on the network layer. Therefore, 
detour rerouting is a costly solution. Since this detour-based mechanisms must deal 
 12
1.5 Report Organization 
In Chapter 2, we will introduce a novel fluidity-aware transport management 
mechanism for both congestion and flow controls. In Chapter 3, we will analyze the 
causes of inefficiency in existing routing scheme and then propose our solutions. Then, 
a data-link layer fault-tolerant scheme will be given in Chapter 4. Finally, conclusion 
will be drawn in Chapter 5. 
 
 14
2.1.1 Congestion Control in NoCs  
Adaptive routing algorithms can be decomposed into two functions: routing and 
selection [39]. The routing function (e.g., Turn model [9] and Odd-Even [10]) 
supplies a set of admissible output paths. An output selected from this set is made by 
the selection function such as [15] based on the status of output paths. Accordingly, 
adaptive routing algorithms are able to use alternative paths instead of waiting for 
busy channels. 
In NoCs, most selection functions are based on monitoring the buffer fill-level in 
its neighboring nodes, such as the Proximity Congestion Awareness (PCA) technique 
[11], Contention-look-ahead on-chip routing scheme [12], Dynamic Adaptive 
Deterministic (DyAD) switching [13], Low Latency Router supporting adaptivity [14], 
and Neighbors-on-Path (NoP) selection [15], all of which allow each router to 
monitor the buffers of its nearest or two-hop neighboring routers in order to detect 
potential congestion earlier. Different from the common selection functions that focus 
on output selection, Contention-Aware Input Selection (CAIS) [16] was proposed as 
PE PE PE PE
PE PE PE PE
PEPEPEPE
 
Fig. 2-1. Congestion Tree Caused by Contentions. 
 16
(1) Partial-Software Implementation: In common computer network 
implementations, the data-link and physical layers are fixed by hardware 
(e.g., Ethernet) and the transport and network layers are software 
implemented (e.g., TCP/IP); therefore, congestion and flow controls 
usually require software efforts and pass control messages between 
communication pairs. As a result, additional computation and 
communication overheads cannot be avoided. However, in contrast to the 
macroscopic networks, the on-chip micro-networks (i.e., NoCs) are always 
equipped with a large number of micro-processors working in parallel, and 
require communication latency in nanoseconds. In general, hardware 
implementations for routine procedures (e.g., routing) are commonly used 
in NoCs to offload extra computation overheads of processors. In our 
opinion, the additional overheads of congestion and flow control schemes 
partially implemented in software should be carefully taken care of. 
(2) Hardware Implementation with Sideband Control: As control signals 
used in on-chip bus [4], it is feasible to add sideband control signals among 
routers in an NoC to provide design flexibilities in congestion and flow 
control schemes. However, the following two major impacts were always 
overlooked in related studies. The first is the wiring issue: Adding one extra 
control signal to each unidirectional link of a five-port router in an 88 
mesh requires a total of 576 long wires to be used as interconnections 
among all routers. Moreover, the timing and area of metal wires are getting 
much more critical and costly than silicon gates in a chip, and this trend 
will continue with the shrinking process technology. The second is the 
reusability impact: In functionality, adding a new control signal to the 
router interface probably causes incompatible problems with the legacy 
design (i.e., processing element). Physically, the new control wires crossing 
the whole chip needs a new layout where more timing closure efforts are 
required. 
 18
unavailable (sl), or a stall of waiting in the queue (sw) where the flit is not at the front 
of a buffer. Flit stalls can be represented as: 
wlb ssss                          (2.2) 
 
 
Stalls of sb and sl can be reduced by adaptive routing coupling with congestion 
control. It is notable that sw is artificially created by buffer size and seems to be 
unavoidable before. In this chapter, we will demonstrate that sw can be reduced by our 
proposed traffic control scheme in the following sections. 
By monitoring the buffer status, the collected statistical information can be used 
to represent the network performance from a standpoint of buffer utilization. In 
minimal routing, latencies caused by transferring a packet in the network architecture 
include basic transport hops (h) and additional stall periods (s). The total number of h 
and s represents the cycle time that buffers are in use, and the percentage of h of this 
total number reflects the efficiency of buffer operations: 
,
( )
b
efficiency
b
h
B
h s




 B
B
                      (2.3) 
  
 
Fig. 2-3. Components of Latency. 
 20
without sacrificing throughput performance in most traffic types and loads. 
2.2.3 Throughput Analysis  
To compute the greatest data transport rate among every communication pairs 
without violating any capacity constraints, the maximum throughput of an NoC can 
be analogous to the maximum-flow problem with multiple sources and sinks in graph 
algorithms.  
Given a flow network graph G = (V, E), each edge (u, v) ∈ E and vertices u, v 
∈ V. A cut c(S, T) of flows f(S, T) in a network G is a partition of V into S and T (V = 
S + T) such that s ∈ S and t ∈ T. A minimum cut of a flow network is a cut whose 
capacity is minimum over all cuts of the network. The max-flow min-cut theorem tells 
that a flow f(s, t) is maximum if and only if its residual network contains no 
augmenting path (i.e., c(s, t) is minimal). The throughput of a flow network G can be 
represented as: 
),(),(),(),()( TSctsctsfTSfGt
Ss TtSs Tt
 
  
           (2.6) 
Accordingly, the maximal throughput of a flow network G equals the minimum cut: 
),(),()( TScMinTSfMaxGtMax                   (2.7) 
It is well known that, an adaptive routing algorithm (e.g., Odd-Even) can 
increase the maximal throughput more than a static routing algorithm (e.g., XY). The 
reason is that since the additional routing paths are provided by the adaptive routing 
ability, the minimum cut of the flow network G with Odd-Even (GOE) is probably 
greater than the minimum cut of the flow network G with XY (GXY) as: 
)(),(),()( XYXYOEOE GtMaxTScMinTScMinGtMax         (2.8) 
Besides, in an NoC, the rate of traffic flows is probably a kind of distribution 
(e.g., Poisson). Accordingly, by enlarging the size of buffers to spread the burst traffic 
evenly, then the channel utilization can be increased, and the throughput performance 
can be enhanced as well. 
 22
2.3 Methodology and Implementation of the Proposed Dynamic Scheme 
In this section, we will introduce the methodology foundations and 
implementation details of our proposed Dynamic Traffic Control scheme. 
2.3.1 Congestion Avoidance and Congestion Relief 
Congestion Avoidance (CA) [11], [12], [13], [14], [15] is a common congestion 
control method that depends on downstream nodes to report its buffer status to the 
upstream nodes. Accordingly, in adaptive routing, a node can select to output packets 
to a neighboring node that is expected to be in less congestion compared with other 
alternative selections as shown in the scenario of Fig. 2-5(a). In contrast to avoiding 
congestions by selecting a profitable output port, Congestion Relief (CR) [16] is 
another congestion control scheme used for the input port selection. In [16], the 
author provided a contention-aware input port selection algorithm for a node to 
receive the packets in the upstream node which is expected to contain more traffic 
 
Fig. 2-4. Latency Analyses in Cases of (a) a Single Path with a Buffer Size of Twelve
(b) a Single Path with a Buffer Size of Sixteen, and (c) Two Alternative Paths 
with a Buffer Size of Sixteen. 
 24
status, while our proposed buffer fluidity-level tries to predict the buffer’s next-state 
status. That is, a buffer in a fluid state is expected to be continuously fluid, because a 
buffer always keeps in the same state for a period of time. For example, in Fig. 2-5(c), 
rather than selecting a routing path to the neighboring node with less buffer filled, the 
upstream node outputs its packets to another node that is in a fluid state. If the 
prediction is correct, then a better performance will be achieved. In our experiments, 
the prediction would be more precise if referring to more historical operation data 
rather than the current buffer state status. Based on the buffer fluidity concept, a 
Dynamic Multi-Level (DyML) flow monitor is proposed for flow control and 
congestion control in the following sections. 
2.3.3 In-transit Packets Concept  
Shin and Daniel proposed a hybrid switching scheme [24], which dynamically 
adopts wormhole or virtual-cut-through switching [30] to get a better performance 
balance between latency and throughput. According to [24], in a light traffic-load 
network, wormhole switching performs better than virtual-cut-through in throughput 
performance. On the contrary, in a heavy traffic-load network, the latency can be 
reduced by virtual-cut-through since it causes less in-transit packets than wormhole 
does. The scenarios are shown in Figs. 2-5(d) and 2-5(e). In other words, wormhole 
performs node-to-node flow control on the flit level; virtual-cut-through does this on 
the packet level. Accordingly, these two switching methods deliver diverse latency 
performances between light and heavy traffic loads. Besides, the authors of [23] 
proposed a layered switching which implements wormhole switching on top of 
virtual-cut-through. It realizes flow control on a new group that comprises of a 
number of flits. Instead of queuing packets in units of one flit, buffers are allocated 
group by group, causing less packet transits in the network as well as [24] does. 
  
 26
output is fluid). Different timeout conditions of STO and FTO determine the 
sensitivity levels of the buffer flow monitor.  
 
 
For example, a smaller timeout value causes more state transitions due to STO 
or FTO being valid frequently. Therefore, the timeout values should be configurable 
to fit different flow conditions in different traffic control types and input buffer 
locations. As a whole, the state in Fig. 2-6(a) trends moving to the unfluid state (L5) 
when the buffer cannot forward any flit to next nodes. On the contrary, the state in Fig. 
2-6(a) probably keeps in the fluid state (L1) when the FIFO buffer push and pop 
operate alternately. In short, by constantly calculating the density of operations in the 
buffer, the buffer fluidity concept can be realized to represent not only a real-time 
traffic condition but also a precise traffic prediction. Additionally, Fig. 2-6(b) presents 
another common buffer fill state machine. In the following sections, both levels of 
Table 2-1. Buffer Fluidity-Level. 
 
Level Definition 
L0 Empty (buffer fill = 0) 
L1 Fluid 
L2 Middle fluid 
L3 Less fluid 
L4 Near unfluid 
L5 Unfluid 
 
 
Table 2-2. Buffer Fill-Level. 
 
Level Definition 
L0 Under 1/4 full (filled buffer  0/4 buffer size) 
L1 At least 1/4 full (filled buffer  1/4 buffer size) 
L2 At least 2/4 full (filled buffer  2/4 buffer size) 
L3 At least 3/4 full (filled buffer  3/4 buffer size) 
L4 Near full (filled buffer  buffer size - 2) 
L5 Full (filled buffer = buffer size) 
 
 28
2.3.6 Dynamic Multi-Level Flow Control  
Dynamic Multi-Level Flow Control (DyML-FC) regulates packets or flits 
injecting into the network after routing paths had been selected by the adopted 
congestion control scheme. DyML-FC uses the in-transit packets concept to enhance 
latency performance when the network is under heavy traffic loads [24], and also 
considers that wormhole is the most popular and solely implemented switching 
technique in many NoCs. Instead of mixing wormhole and virtual-cut-through 
switchings in a router [23], [24], we give the wormhole router an additional flow 
control ability to suppress injecting packets or flits into the network when the flow 
monitor reflects that the traffic flow is unfluid, rather than buffer full. Therefore, in a 
congested network, the length of macro-pipeline of flits can be reduced; in 
consequence, the congestion backpressure is rapidly propagated by a shorter 
macro-pipeline of flits. This scenario is illustrated as a congestion tree with less filled 
flits in Fig. 2-8. Additionally, to prevent the throughput performance loss under light 
and middle traffic loads, DyML-FC must operate in a smarter way. 
 
end
else
if
else
if
begin
level original  the//keeping
L3)  toL4 shifting (e.g., level max.  the to//shifting
 L3) ~L0for  bits 2 using (e.g.,limit  level max.  theexceeding//when 
L1)  toL0 shifting (e.g., levelhigher  a  to//shifting
state unfluid  the toclose is levelfluidity uffer  //when the
level original  the//keeping
state fluid  the toclose is levelfluidity buffer  //when the
 BFilL;  BLevel      
    L3  BFilL  //L0  
 L3;  BLevel      
 L3)(BFilL   
 1;BFilL  BFilL      
   b L5  BFluL  //L3  
 BFilL;  BFilL      
  L2)  BFluL (L0   
 indication StatusBuffer  // BStatus :Output    
Level Fill //Buffer BFilL :Input    
LevelFluidity  //Buffer BFluL :Input    
BLevel)BFilL, (BFluL, CC-DyBL :Algorithm








 
Fig. 2-7. Algorithm DyBL-CC for Congestion Control. 
 30
2.3.7 Dynamic Traffic Control  
Here, an integrated scheme, the Dynamic Traffic Control (DyTC), is presented. 
DyTC is an incorporation of the buffer flow monitor in Fig. 2-6, the Dynamic 
Multi-Level Flow Control (DyML-FC) in Fig. 2-9, and the Dynamic Buffer-Level 
Congestion Control (DyBL-CC) in Fig. 2-7. DyTC is implemented as a stand-alone 
hardware module as shown in Fig. 2-10(a). The distinct features and advantages of 
DyTC will be discussed in the next section. 
 
end
else
if else
if else
if else
if else
ifelse
if
begin
GO) (i.e., indication STALL //inactive
condition //GO
state unfluid ain  and full 1/4under  is //buf.
state unfluidnear  ain  and full 1/4least at  is //buf.
state fluid less ain  and full 2/4least at  is //buf.
state fluid middle ain  and full 3/4least at  is //buf.
state fluid ain  and fullnear  is //buf.
STALL/GO of conrol flowlegacy  //the
 caret don' is levelfluidity buffer   thusfull, is//buffer 
 ;DeAsserted  STALL      
   
Asserted;  STALL      
 L5)BFluL&L0  (BFilL   
Asserted;  STALL      
 L4)BFluL&L1  (BFilL   
Asserted;  STALL      
 L3)BFluL&L2  (BFilL   
Asserted;  STALL      
 )2LBFluL&L3  (BFilL   
Asserted;  STALL      
 )1LBFluL&L4  (BFilL    
 Asserted;  STALL      
  L5)  (BFilL   
 indication STALL //Buffer STALL :Output    
Level Fill //Buffer BFilL :Input    
LevelFluidity  //Buffer BFluL :Input    
STALL)BFilL, (BFluL, FC-DyML :Algorithm













 
Fig. 2-9. Algorithm DyML-FC for Flow Control. 
 32
timeout value of STO was set to a quarter or a quadruple number of the buffer size 
depending on the buffer connected to a neighboring node or a processing element; and 
in DyML-FC, the timeout value of STO was set to a quadruple or a quarter number of 
the buffer size depending on the buffer connected to a neighboring node or a 
processing element. Accordingly, two flow monitors were used for DyBL-CC and 
DyML-FC independently. Besides, the other timeout value of FTO was assigned to 
one in all of our experiments. Furthermore, key network performance metrics, such as 
packet latency, network throughput, buffer efficiency, and buffer usage, were recorded 
for further analyses. 
2.4.2 Experiments with Synthetic Traffics  
In CMP NoCs, traffic conditions are irregular and unpredictable. Accordingly, 
we tried to analyze the traffic control effects for such traffic scenarios. Three common 
traffic patterns, namely uniform, hotspot, and transpose used in Odd-Even [10], were 
considered in our experiments. In uniform traffic, a node transmits a packet to any 
other node with equal probability. In hotspot traffic, uniform traffic is applied, but 
10% of packets change their destination to one of the following four selected nodes 
[(7, 2), (7, 3), (7, 4), (7, 5)] with equal probability. In transpose traffic, a node at (i, j) 
always sends packets to a node at (j, i). Especially, the size of packets was randomly 
distributed between 4 and 32 flits to conform that the packet size should be adjustable 
for real communication needs. To use a practical buffer size considering both cost and 
performance, we assigned each input-port buffer in 1024 bits as in [48] to 
accommodate a feasible number of multiple packets of burst traffic [49]; besides, a 
packet may be queued in different nodes due to wormhole switching. Furthermore, all 
performance metrics are averaged over 60,000 packets after a warm-up session of 
30,000 arrival packets at each of the forty packet injection rates. 
Uniform Traffic: The uniform traffic is a common pattern used in most NoC 
studies. As shown in Fig. 2-11, we observed that the XY-Baseline performs the best 
compared to other algorithms. Identical results are shown in [10]. The reason is that 
 34
Odd-Even supports a certain degree of routing freedom for packets to route around 
busy traffic blocks through other available routing paths. Compared with OE-Baseline, 
OE-DyTC on average improved 20.87% in latency, 2.03% in throughput, 1.67% in 
buffer efficiency, and 2.44% in buffer usage. 
 
 
Transpose Traffic: The transpose traffic pattern is a kind of specific operations 
similar to the Matrix-Transpose pattern. The communication graph can be visualized 
as a number of concentric squares on which the source and destination pairs lie 
between northwest and southeast areas of the mesh. In such a communication scenario, 
half of all uni-directional links are unused for XY routing; consequently leads to the 
extra low buffer usage as shown in Fig. 2-13(d). On the contrary, Odd-Even can 
Fig. 2-12. Performance Variations under Hotspot Traffic. 
 36
performance phenomena among different traffic control schemes as follows: (1) 
XY-Baseline behaves diversely among different traffic types due to its non-adaptive 
routing property. (2) In congestion controls, CC performs better than CA, and CA is 
better than CR. (3) Adaptive routing selections in DyBL can achieve more 
performance gains than in BFilL. (4) Except for XY-Baseline under uniform traffic, 
DyTC performs the best among all traffic types. (5) In Fig. 2-15, the buffer usage of 
Hotspot is higher than Uniform but the buffer efficiency of Hotspot is smaller than 
Uniform, the reason is Hotspot causes more waiting packets due to traffic jams than 
uniform. (6) XY-Baseline has an ultra low buffer usage in transpose traffic due to the 
imbalanced link utilization. And (7) Basically, buffer usage and efficiency are in direct 
proportion; however, it is notable that DyTC has the lowest buffer usage but has the 
highest buffer efficiency among all traffic control schemes based on Odd-Even. 
 
 
Fig. 2-14. Performance Comparisons of Latency and Throughput. 
 38
   jiji
graphtaskW
ji yyxxw
ji


                    (2.9) 
 
 
Simulation results showed that there is no distinct throughput performance 
difference among traffic control schemes in Fig. 2-17 (right). The reason is that most 
communications of well-mapped tasks in the mesh just took one hop between 
neighbor nodes. According to the throughput analysis in Section 3.3, traffic control 
schemes caused little effect in throughput for such local and regular traffic flows. 
Nevertheless, we found that the OE-DyML-FC has a significant latency performance 
enhancement. The reason was discussed in details in Section 2.2.2. Compared with 
OE-Baseline, OE-DyML-FC respectively improved latency performance 3.39%, 
17.85%, and 15.18% in consumer, auto-indust, and telecom real traffics as shown in 
Fig. 2-18. 
 
Fig. 2-16. Task Mapping Results. 
 40
2.4.4 Implementation Overhead  
As shown in Fig. 2-10(a), DyTC is a design module using inexpensive control 
logics (i.e., without memory and channel resources). Referring to Fig. 2-10(b), five 
DyTC modules are required for a five-port router in a common mesh network. Our 
router was designed in Verilog HDL (Hardware Description Language), synthesized 
by Synopsys Design Compiler, and power analyses were calculated by Synopsys 
Power Compiler in UMC 90nm technology under typical operation conditions. 
Referring to Table 2-3, the area and power overheads for supporting DyTC in the 
designed router are small in 2.09% and 2.66%, respectively. Especially, as shown in 
Fig. 2-19, we used only an “OR” gate and a “MUX” to integrate the DyTC module’s 
registered outputs into the primary router. In such a way, DyTC makes minor timing 
impact to the original design as depicted in Table 2-3. 
 
 
 
Fig. 2-18. Comparisons in Average Latency among Router Schemes under Real 
Traffics. 
 
Fig. 2-19. Router Incorporated with the DyTC Module. 
 42
 
 
 44
Any routing scheme can have its pros and cons. For example, in minimal path 
routing, the path length is equal to the two-dimensional city block (mesh) distance 
between the source and the destination. The constraint of using only minimal paths 
has the advantages in guaranteeing livelock free and minimal hops for a packet 
traversal, which simplifies the design of a deadlock-free routing algorithm. However, 
the minimal routing limitation may lead to performance degradation and function loss 
in certain conditions. As shown in Fig. 3-1(a), the minimal routing path may carry a 
heavy traffic load, causing an excessive delay (latency) for any flits which must 
traverse its links. By contrast, non-minimal routing paths offer alternative light-traffic 
routes which provide additional link bandwidth and therefore reduce the overall 
latency by avoiding contention as illustrated in Fig. 3-1(b). Furthermore, as shown in 
Figs. 3-1(c) and 3-1(d), non-minimal routing provides a significantly improved 
fault-tolerance performance. However, a non-minimal routing scheme probably 
requires more implementation overheads (e.g., cost and performance) compared with 
the minimal one. Therefore, it would be of interest to design a flexible routing sheme 
to meet most of the on-chip interconnecton criteria. 
 
3.1.2 Deadlock and Livelock Issues 
In any routing algorithm, it is essential to avoid both deadlock and livelock. 
Deadlock is an anomalous network state in which a circular hold-and-wait 
dependency relation is formed among the network resources; causing the routing of 
 
Fig. 3-1. Local Congestion Scenarios in (a) Minimal Routing and (b) Non-Minimal 
Routing; and Faulty Link Cases in (c) Minimal Routing and (d) Non-Minimal 
routing. 
 46
minimal routing algorithm, ROUTE, has been extensively applied in NoCs (e.g., 
DyAD [13], NoP [15], Schafer et al. [55], Lin et al. [56], and Wu [57]). In general, the 
turn-model based routing algorithms have a lower implementation complexity and a 
more flexible routing performance than those deadlock-free approaches, such as 
Virtual Channel (VC) based methods [58], [59], deflection routing algorithms [26], 
[32], and deadlock recovery approaches [60], [61]. 
 
 
However, traditional turn-model based routing schemes are either Non-Adaptive 
Routing (NAR) such as XY [25] or Partially Adaptive Routing (PAR) such as 
Odd-Even [10], which can only use a subset of minimal paths in their classes. In Fully 
Adaptive Routing (FAR), packets can be routed using all the shortest paths. Routing 
algorithms usually use VCs to achieve the goal of FAR. However, using extra VCs 
leads to power and performance penalties in switching packets [10], [62]. For high 
performance on-chip communications, it is desirable to have a routing algorithm that 
is fully adaptive, performance-efficient, and deadlock-free. To achieve this goal, a 
Turn-Model based Fully-Adaptive-Routing (TM-FAR) scheme is proposed in this 
chapter. Moreover, the turn models can be extended to a non-minimal routing 
algorithm which still guarantees both deadlock-free and livelock-free conditions. 
Three novel Non-Minimal Routing (NMinR) algorithms upon this premise are 
proposed based on the Odd-Even, West-First and Negative-First turn models and 
designated as NMinR-OE, NMinR-WF, and NMinR-NF, respectively.   
 
Fig. 3-3. Taxonomy of NoC Deadlock Avoidance Routing Schemes. 
 48
3.2.1 Odd-Even Turn Model  
This section reviews the turn rules in the Odd-Even turn model [10] and 
describes the routing criteria applied in ROUTE, the corresponding minimal routing 
algorithm. The Odd-Even turn model is governed by the following turn rules: 
(1) Turn Rule 1: No packet is allowed to make an EN turn at any router 
located in an even column, or an NW turn at any router located in an odd 
column. 
(2) Turn Rule 2: No packet is allowed to make an ES turn at any router 
located in an even column, or an SW turn at any router located in an odd 
column. 
(3) Turn Rule 3: (Derived from Theorem 1 of [10]). No packet is allowed to 
make a 180-degree turn at any router. 
Referring to the above rules, any packet is not allowed to take an EN or ES turn 
at any node located in an even column, and it is not allowed to take an NW or SW 
turn at any node located in an odd column. Deadlock freedom can be proved, because 
the rightmost column segment always is short of an essential turn to form a circular 
waiting path. We demonstrate the principle in Fig. 3-4. 
 
 
 
Fig. 3-4. Four Transmission Examples Following the Odd-Even Turn Model. 
 50
3.2.3 Odd-Even Based Routing Algorithms  
Numerous NoC routing algorithms (e.g., DyAD [13] and NoP [15]) utilize the 
Odd-Even turn model to prevent deadlock. However, these algorithms are all limited 
to the use of minimal routing paths. The non-minimal routing potential of the 
Odd-Even turn model has received only partial benefit as stated in the literature. In 
the Odd-Even based routing algorithms proposed in [55], [56], and [57], deadlock free 
is guaranteed by using a set of pre-defined non-minimal routing paths to route around 
faulty nodes or rectangular blocks in the network. However, the use of these 
non-minimal routing paths is still subject to a Partially Adaptive Routing (PAR). That 
is, for each source-destination pair, the path selection is still limited to a subset of 
paths with the shortest length among all possible minimal and non-minimal routing 
paths. Moreover, the traffic loads in a congested minimal path cannot be redistributed 
to alternative minimal or non-minimal paths to enhance the network performance. 
Thus far, the fully adaptive and non-minimal routing capabilities of the Odd-Even 
turn model do not have a complete presentation. 
3.2.4 Motivations of our Proposed Turn Model Based Routing Schemes  
Turn models (i.e., XY and Odd-Even) are the most prevalent methodologies 
adopted for deadlock-free packet routing in NoCs. However, the developed researches 
such as the path-selection strategy for adaptive routing [15] and the fault-tolerant 
routing [57] are highly constrained in the inherent turn prohibitions and the 
minimal-path routing limitations. Nevertheless, these prohibitions and limitations of 
turn models can be relieved as presented in Sections 3.3 and 3.4, respectively. 
3.3 Proposed Turn-Model Based Fully Adaptive Routing 
To relieve the Partially Adaptive Routing (PAR) limitation of the traditional 
turn-model based routing, a novel Turn-Model based Fully-Adaptive-Routing 
(TM-FAR) algorithm is proposed. TM-FAR retains the deadlock-free property of 
traditional turn-model based routing algorithms (e.g., XY, Odd-Even), while 
alleviating restrictions on turn and path selections. Just like the current 
 52
3.3.2 Path Prohibitions Release 
Since the turn prohibitions can be removed by EVCT, we start to consider the 
possibility of removing the constraints in turn criteria as described above. 
Unfortunately, deadlocks could exist if we apply EVCT without regarding the turn 
criteria. A scenario is shown in Fig. 3-7. Following all the turn rules and criteria in 
Odd-Even, EVCT could validate additional turns from the inherent illegal turns of 
Odd-Even. That is, these additional turns are under certain circumstances, not 
deadlock-free guaranteed. Fig. 3-7(b) shows that when an Odd-Even prohibited turn 
becomes the only available path for a packet to reach its destination, a deadlock could 
be incurred. 
 
 
Fig. 3-6. Examples of EN and ES Turn Prohibitions Imposed by Odd-Even Are 
Active in (a); but Released in (b), (c), and (d) by Using EVCT. 
 54
 
(1) Buffer Size Requirement: The size of EDB (i.e., the input buffer of Port 0) 
is required to be not less than the size of the maximal packet that permits 
violating a turn criterion. 
(2) Dirty Packet Label: When a packet violates a turn criterion, the router 
labels it dirty using one bit in the packet header. This bit notices the router 
that the receiving packet needs to use a prohibited turn to reach its 
destination. The dirty label can be removed after the packet passes a 
prohibited turn. 
(3) Mutual Exclusion: The EDB accepts a dirty packet when its empty space 
is equal to or greater than the dirty packet. Input ports of the router need to 
obtain a mutual exclusive access grant to EDB before they allow a dirty 
packet to be entered into its input buffer. In other words, at any one time, 
there is only one dirty packet existent in the router. 
(4) Parking Regulation: When a router receives a dirty packet, and it cannot 
forward the packet to the next node because there is no available valid path; 
immediately, the router shall park this dirty packet to EDB to prevent 
blocking other normal packets from entering the input buffer. The parked 
dirty packet leaves EDB to a next node whenever a path is available. 
Port 4
Port 0
Port 1
Port 2
Port 3
A newly added path for EDB
 
Fig. 3-8. Enhanced Deadlock-Buffer (EDB) Architecture. 
 56
speedily pass a prohibited turn validated by EVCT, thus EDB can just be used to 
buffer the dirty packet that cannot be instantly relayed to a neighbor node and reduce 
the probability of activating EDB.  
TM-FAR-OE is a routing algorithm integrating both EVCT and EDB with 
Odd-Even. First, TM-FAR-OE is livelock free due to its minimal routing property. 
Second, TM-FAR-OE guarantees deadlock freedom because the five operation rules 
of EDB guarantee that a motionless dirty packet can always be buffered in a deadlock 
buffer. 
Theorem: The TM-FAR based routing algorithm that follows the rules adopted 
in turn model is deadlock-free as long as the 180-degree turns are prohibited in a 
mesh network and all dirty packets in input buffers are in a moving state. 
Proof: We prove the theorem by contradiction. Assume that there exists a set of 
packets p1, p2, . . . , pn, that are deadlocked. Thus, the associated waiting path 
forms a circular path. Since the 180-degree turns are prohibited, the circular path 
must include four different, either clockwise or counterclockwise 90-degree 
turns. In accordance with the adopted turn model, one of these four turns is 
prohibited with normal packets; therefore, the prohibited turn must be formed by 
a dirty packet being blocked in an input buffer. Thus, contradiction arises, and 
we prove the theorem. 
3.3.4 Fault Tolerance Advantage 
As a Partially Adaptive-Routing (PAR) algorithm, ROUTE [10] probably 
provides only one of the available minimal paths between a source and destination 
pair in a mesh network due to the turn and path prohibitions of Odd-Even. This 
limitation could cause problem under a possible faulty case as shown in Fig. 3-10.  
 
 58
3.3.5 Performance Evaluation  
Comprehensive simulations were run in Register Transfer Level using Cadence 
NC-Verilog. Performance metrics were carried out on an (8×8) mesh network. Each 
link bandwidth is set to one flit per cycle. Packets are generated and received by a 
NIOS2 host model attached to Port 0 of each router. In different evaluations, the sizes 
of buffers were configured in 16 and 32 flits, respectively; the size of packets was 
randomly distributed between 4 and 16 flits in all simulations. In uniform traffic, a 
node transmits a packet to any other node with equal probability. In transpose traffic, 
a node at (i, j) always sends packets to a node at (j, i). In hotspot traffic, uniform 
traffic is applied, but 20% of packets change their destination to one of the following 
four selected nodes [(7, 2), (7, 3), (7, 4), (7, 5)] with equal probability. For each traffic 
load value, the results of packet latency and throughput are averaged over 60,000 
packets after the unstable warm-up session of 30,000 arrival packets. 
 
 
 
Fig. 3-11. Routing Examples of Packets Getting through the Prohibited Turn by (a) 
EVCT and (b) EDB under a Faulty Case of TM-FAR. 
 60
Uniform Traffic: Fig. 3-12(a) shows the results obtained under uniform traffic. 
We observed that the XY algorithm performs the best. Identical results were shown in 
[10]. Since the non-adaptive XY embodies global and long-term information for the 
uniform traffic pattern, it happens to spread traffic much more evenly across paths of 
a mesh. However, except for XY, TM-FAR-OE achieves the highest saturation point 
in throughput and performs better than ROUTE in both delay and throughput. 
Compared with ROUTE by averaging the data of Uniform in Tables 3-2(a) and 3-2(b), 
TM-FAR-OE improved 33.11% in delay and 7.21% in throughput. 
Transpose Traffic: The transpose traffic pattern is a kind of specific operations 
identical to the Matrix-Transpose used in [9]. Fig. 3-12(b) shows that, before the 
saturation point in throughput and under an identical packet injection rate, 
TM-FAR-OE and ROUTE provide similar performance in throughput; however, 
TM-FAR-OE greatly overcomes ROUTE in the packet delay. Compared with ROUTE 
by averaging the data of Transpose in Tables 3-2(a) and 3-2(b), TM-FAR-OE 
improved 25.17% in delay and 1.01% in throughput. 
Hotspot Traffic: Hotspot is a more realistic traffic scenario [10]. Hotspot traffic 
causes early saturation for all routing schemes due to uneven traffic loads in the 
network. In contrast to ROUTE that provides partial adaptivity due to the turn and 
path prohibitions, TM-FAR-OE supports full adaptivity for packets to route around 
local traffic jams. Fig. 3-12(c) shows that ROUTE and TM-FAR-OE have similar 
peak throughput value. Besides that, TM-FAR-OE outperforms ROUTE in both 
performance metrics. Compared with ROUTE by averaging the data of Hotspot in 
Tables 3-2(a) and 3-2(b), TM-FAR-OE improved 31.95% in delay and 5.39% in 
throughput. 
 
 62
 
3.3.6 Remarks  
We presented a Turn-Model based Fully-Adaptive-Routing scheme, TM-FAR, 
that guarantees deadlock and livelock freedom. In our proposed routing algorithm, 
TM-FAR-OE, the turn rules and criteria of Odd-Even are no longer being used to 
prohibit available turns and limit path selections in an NoC router. Instead, we 
transformed these intrinsic restrictions of turn model into the operation conditions 
which guide the router to operate in a Virtual-Cut-Through mode or use of 
Deadlock-Buffers. Compared with state-of-the-art routing algorithm, TM-FAR-OE 
achieved an averaged delay reduction of 30.08% and throughput rate increase of 
4.54%. 
3.4 Proposed Turn-Model Based, Non-Minimal Routing 
Current turn-model based NoC routing algorithms are constrained to the use of 
minimal routing paths in preventing deadlock or livelock. However, in this study it is 
shown that any deadlock-free, turn-model based minimal routing algorithm can be 
extended to a non-minimal routing algorithm which still guarantees both deadlock 
free and livelock free conditions. Three novel non-minimal NoC routing algorithms 
upon this premise are proposed based on the Odd-Even, West-First, and 
Negative-First turn models, respectively. It is shown that these three algorithms are 
not only deadlock free and livelock free, but also can explore non-minimal routing 
Table 3-3. Performance Comparisons among Different Traffics and Buffer Sizes. 
 
 64
(1) Available_Dimension_Set_Priority_0 (ADS-P0): Those which contain 
the same routing direction as a minimal routing path. 
(2) Available_Dimension_Set_Priority_1 (ADS-P1): Those which contain a 
routing direction with a minimal 90 degree phase difference to the direction 
of a minimal routing path. 
(3) Available_Dimension_Set_Priority_2 (ADS-P2): Those which contain a 
routing direction with a minimal 180 degree phase difference to the 
direction of a minimal routing path. 
As shown in Fig. 3-13(a), when selecting a direction within a Priority_0 ADS, 
the packets are forwarded along a minimal path. By contrast, when a direction within 
a Priority_1 or Priority_2 ADS is selected, the packets are forwarded along a 
non-minimal path. 
 
3.4.3 Non-Minimal Routing Algorithm Based on Odd-Even Turn Model  
This sub-section presents the proposed non-minimal routing algorithm based on 
the Odd-Even turn model (designated as NMinR-OE). To lift the minimal routing 
limitation (MinR Criterion 1) in ROUTE based on the Odd-Even turn model 
(designated henceforth as ROUTE-OE), a new set of Non-Minimal Routing (NMinR) 
Criteria is proposed for both minimal and non-minimal routing paths. (Note that all 
the minimal routing paths of ROUTE-OE are included among those in NMinR-OE.) 
X
X
 
Fig. 3-13. (a) Available Direction Sets (ADS) and (b) NMinR Criterion 1. 
 66
 
(4) NMinR Criterion 3-1: If the destination of a packet is to the south of its 
source, the packet is prohibited from moving east. 
The motivation for this criterion is similar to that for NMinR Criterion 2-1 (see 
Fig. 3-14(c)). 
(5) NMinR Criterion 3-2: If the destination of a packet is to the south of its 
source, the packet is prohibited from moving north at any intermediate 
router residing in an odd column or in the west-most even column (i.e., col. 
0). 
The motivation for this criterion is similar to that for NMinR Criterion 2-2 (see 
Fig. 3-14(d)). 
(6) NMinR Criterion 4-1: If the destination of a packet is to the east of its 
source and is located in the next even column, the packet is prohibited from 
moving north or south at any router residing in an odd column. (see Fig. 
3-15(a)). 
Since in the Odd-Even turn model, NW, SW, and 180-degree turns are not 
allowed at any routers in the odd columns, if the packet is to be routed in the north or 
south direction next, the packet can only take a NE or SE turn, respectively. 
Furthermore, since an ES or EN turn is not permitted in the next even column, the 
packet can only move continuously in the east direction. That is, for the reason 
described above for NMinR Criterion 1, the packet cannot reverse its direction of 
 
Fig. 3-14. NMinR (a) Criterion 2-1, (b) Criterion 2-2, (c) Criterion 3-1, and (d) 
Criterion 3-2. 
 68
and Negative-First models designated as NMinR-WF and NMinR-NF, respectively. 
First, in the West-First model, all turns to the west (NW, SW) are prohibited 
following an initial turn in the west direction, and thus for a packet to travel west, it 
must start from the west direction. Therefore, the proposed NMinR-WF routing 
algorithm has a non-adaptive routing property when the destination of a packet is 
located on its west side. However, if the destination is located on the east side, full 
routing adaptivity is achieved. Second, the Negative-First model prohibits the use of 
the northeast turns (NW, ES) of possible clockwise or counter-clockwise circular 
paths to prevent deadlock. In other words, a packet can go through the other turns on a 
mis-routing path to the southwest of its destination, as described in the NMinR-NF 
routing algorithm proposed in this study. For details, the complete NMinR-WF and 
NMinR-NF routing algorithms can be accessed in APPENDIX B of this report 
3.4.5 Deadlock Free, Livelock Free, and Minimal Routes Compatibility 
In this section, it is shown that any deadlock-free, turn-model based minimal 
routing algorithm can be extended to a non-minimal routing algorithm which 
guarantees both deadlock free and livelock free conditions in closed mesh networks. 
(Note that the non-minimal routing algorithm retains all the minimal routing paths of 
the original algorithm.) Utilizing the same format as that used for the Odd-Even 
model in [10], the proofs are given as follows: 
Definition 1: A non-minimal routing algorithm is a routing algorithm in which 
the path selections are not limited to the minimal routes between each source 
and destination pair. 
Definition 2: A closed network is a network in which the topology, size and turn 
prohibition positions are static during normal operations. 
Theorem 1: A non-minimal routing algorithm which follows all the rules of the 
adopted turn model is deadlock free in closed mesh networks provided that 
180-degree turns are prohibited. 
 
 70
accordance with Theorem 1, the circular path includes an illegal (prohibited) 
turn. Accordingly, there is an illegal (prohibited) turn within the path (a, b, c). 
However, the path (a, b, c) is valid in the minimal routing algorithm. That means 
the possible turn in router B is legal (un-prohibited) or not existent. Thus, a 
contradiction arises. Hence, the theorem is proved. 
3.4.6 Experimental Results 
In this section, the performance and implementation cost of the proposed 
Non-Minimal Routing (NMinR) algorithms are compared with those of the primitive 
Minimal Routing (MinR) schemes. 
3.4.6.1 Path Selection and Switch Arbitration  
Assume that a direction-aware path selection mechanism classifies the available 
output directions at each router in the priority sequence ADS-P0, ADS-P1, and 
ADS-P2 (referring to Section 3.4.2). When a header flit arrives at the router, the router 
retrieves the destination address, reads the routing table, and then checks the buffer 
status in all the neighboring routers. In making a routing decision, the router selects a 
direction within the highest priority ADS (ADS-P0) unless the buffer of the router in 
the preferential direction is full, in which case a direction within the ADS with the 
second highest priority (ADS-P1) is selected. If buffer full conditions are found for all 
three ADSs, the router waits until any neighboring router becomes available. In 
addition, if a header flit can be routed in two directions with an equal priority, the 
router transfers the header along the y dimension first (i.e., as in ROUTE [10]). 
Finally, a simple round-robin policy is used in the router cross-bar arbitrations to 
prevent packet starvation. 
3.4.6.2 Simulation Setting  
Performance metrics in a series of simulations were conducted on an 8×8 mesh 
network. In performing the simulations, the bandwidth of each link was specified as 
one flit (32 bits) per cycle. Accordingly, four cycles were required to switch the 
 72
increases and leads to a corresponding increase in the consumption of the available 
channel resources. However, in most real-world applications, networks are prevented 
from operating at traffic loads greater than the saturation point, and thus this 
performance drawback of NMinR-OE is of little practical concern. 
Figure 3-16(a) shows that NMinR-WF and NMinR-NF yield no particular 
improvement in the routing performance under uniform traffic conditions. In 
accordance with the non-minimal routing properties described in Section 3.4.4, in a 
mesh network, NMinR-WF generally mis-routes packets to the west, while 
NMinR-NF always mis-routes packets to the southwest. As a result, traffic jams are 
incurred in the west and southwest areas of the network, respectively, leading to a 
reduction in the global network performance. This uneven distribution of the 
mis-routing packets is reflected in the packet mis-routing rates shown in the lower 
panel of Fig. 3-16(a). Overall, the results presented in Fig. 3-16(a) show that at packet 
injection rates resulting in an excessive mis-routing, a significant performance 
degradation occurs (i.e., the throughput reduces and the latency increases). From 
inspection, the maximal throughput of NMinR-OE was approximately 6.78% higher 
than that of ROUTE-OE, while the average latency was around 11.38% lower at 
traffic loads equal and lower than that associated with the maximal throughput. 
 
 74
network. Since NMinR-WF first mis-routes packets to the west when detecting 
congestion, it eases this traffic jam and therefore improves the global network 
performance. From inspection, NMinR-WF outperformed MinR-WF by around 
10.10% in terms of the maximal throughput and 24.28% in terms of the average 
latency at traffic loads equal to and lower than that associated with the maximal 
throughput. It is seen in Fig. 3-16(b) that NMinR-OE also performs well in 
distributing the traffic load under hotspot traffic conditions. For example, the maximal 
throughput of NMinR-OE was approximately 6.65% higher than that of ROUTE-OE, 
while the average latency was around 22.98% lower at traffic loads equal to and lower 
than that associated with the maximal throughput. 
3.4.6.5 Regional-Burst Traffic Simulation Results  
In the regional-burst traffic simulations, five 2×2 sub-meshes [(1, 1), (1, 2), (2, 
1), (2, 2)], [(1, 4), (1, 5), (2, 4), (2, 5)], [(3, 3), (3, 4), (4, 3), (4, 4)], [(5, 1), (5, 2), (6, 
1), (6, 2)], and [(5, 4), (5, 5), (6, 4), (6, 5)] were assumed to operate in a burst fashion. 
That is, the nodes within these sub-meshes transmitted packets at a constant rate (i.e., 
regardless of the packet injection rate) to the other nodes in the same sub-mesh with 
equal probability, and nodes beyond these sub-meshes transmitted packets to each 
other with an equal probability at a rate equal to the specified packet injection rate. In 
performing the simulations, a control bit designated as Mis-routing Disable (MD) was 
set in the header flits issued by the nodes in the sub-meshes to inform the routers to 
route the corresponding packets only through minimal routing paths in order to 
prevent undue mis-routes (Note that this optional mis-routing capability is not 
supported by a deflection routing algorithm). As shown in Fig. 3-17(a), NMinR-OE 
yields the best network performance among the considered schemes. Overall, 
NMinR-OE improved the maximal throughput and average latency at traffic loads 
equal to and lower than the maximal throughput point by around 5.32% and 10.02%, 
respectively, compared to ROUTE-OE. 
 
 76
3.4.6.7 Transpose Traffic Simulation Results 
In executing Matrix-Transpose operations in a mesh network [9], [10], it is 
assumed that node (i, j) sends packets only to node (j, i). As shown in Fig. 3-18(a), in 
such a scenario, the entire proposed non-minimal routing algorithms yield a poorer 
network performance than their minimal routing counterparts. In a mesh network with 
transpose traffics, the communication graph can be visualized as a number of 
concentric squares on which the source and destination pairs lie, and a heavy-traffic 
band is formed in the southwest to northeast direction. Within this heavy-traffic band, 
there are no light-traffic paths which can be exploited by the non-minimal routing 
algorithms. As a result, mis-routing packets is not only infeasible, but also seriously 
congests the network (Note that a similar experimental result was also reported for the 
non-minimal routing scheme in DISHA [60]). Nevertheless, since the non-minimal 
routing algorithms proposed in this study are fully backward compatible with the 
routing operations of their primitive counterparts, the NoC-based communication 
system can accordingly be aware and simply be triggered to disable the use of 
non-minimal routing paths for such specific applications (e.g., transpose traffic) and 
to use the minimal routing paths identified by the original algorithm in their place. 
Besides, comparing the two panels in Fig. 3-18(a), it is seen that the throughput 
performances of the minimal and non-minimal routing algorithms are insensitive to 
the buffer size due to the extremely regular data flows of the transpose traffic. 
 
 78
however, the 512-bit performance of ROUTE-OE was reduced by around 10.98%. 
3.4.6.9 Buffer Size Effect  
To evaluate the effect of the buffer size on the performance of the proposed 
algorithms, all of the simulations conducted in this study were performed using both 
1024-bit buffers and 512-bit buffers. The performance gain obtained using the larger 
buffer size was quantified as: 
buffersbitinthroughputMax
buffersbitinthroughputMaxbuffersbitinthroughputMaxGain
512.
512.1024.    (3.1) 
The results presented in Fig. 3-19 show that the average performance gain 
provided by the larger buffer size for all of the MinR and NMinR routing algorithms 
was equal to 16.73%. In addition, it is shown that large buffers resulted in a greater 
performance gain for random traffic flows (e.g., 28.44% in uniform traffic) than for 
regular traffic flows (e.g., 4.87% in transpose traffic). 
 
3.4.6.10 Implementation Overhead  
In the present study, the router design was synthesized using Synopsys Design 
Compiler and power analyses were performed using Synopsys Power Compiler in 
UMC 90nm technology under typical operating conditions. The results presented in 
 
Fig. 3-19. Performance Enhancement by 1024-bit Buffers over 512-bit Buffers. 
 80
Moore’s Law. 
Of the three non-minimal routing algorithms proposed in this study, the one 
based on the Odd-Even turn model (NMinR-OE) yields the best network performance 
(i.e., the greatest maximal throughput and the lowest average latency) in most 
experimental results. In contrast to the conventional turn-model based minimal 
routing algorithms, the operational flexibility provided by NMinR-OE results in not 
only better routing performance, but also improves fault tolerance. Furthermore, the 
non-minimal routing schemes proposed in this study are backwards compatible with 
their primitive minimal routing counterparts, and the mis-routing path selection is 
optional for each packet in each router. 
3.5 Proposed High Performance Deflection Routing 
In contrast to the turn-model based routing schemes, deflection routing is an 
inherently topology-unaware and non-minimal routing scheme. These two distinct 
features form the base of a seamless and efficient fault-tolerant mechanism that the 
turn-model based routing algorithms have difficulty to achieve. However, traditional 
deflection routing schemes are performance inefficient. Since in a congested network, 
the packets are likely to be mis-routed away from their destinations and that leads to 
more congestion. In our opinion, the full routing adaptivity of deflection routing 
cannot be overlooked. If a deflection routing algorithm can utilize the routing 
adaptivity while minimizing the inefficiency in flow control, then its communication 
performance can be improved significantly. Moreover, the deflection routing property 
could be a great benefit for NoCs in which faults exist. Therefore, a novel NoC 
Deflection Routing algorithm with Virtual-Cut-Through switching (DR-VCT), that 
integrates ring buffers operating in a ping-pong fashion, is proposed. DR-VCT 
completely solved the root causes of inefficient performance of the state-of-the-art 
packet-switched deflection routing algorithms and its delivered performance is 
comparable to the prevalent Odd-Even turn-model based routing algorithm. 
 
 82
FLIT-BLESS or in the inefficient packet switching of WORM-BLESS. For these 
insufficiencies, we propose our methodology and demonstrate that the deflection 
routing can be implemented as a practical routing algorithm for NoCs in the following 
sections. 
3.5.2 Wormhole Switching and Virtual-Cut-Through Switching 
Wormhole switching [31] forwards each flit of a packet when there is available 
buffer space to accommodate that flit in the receiving router. Accordingly, a packet 
may be queued in different buffers of routers as illustrated in the upper panel of Fig. 
3-20(a). Currently, wormhole switching is the most prevalent packet switching 
technique for NoCs because of its optimal packet transmission latency and the 
minimal buffer requirement. However, in BLESS, wormhole switching performs 
worse than expected as discussed in the above section. 
 
 
Virtual-cut-through switching forwards the first flit of a packet as soon as the 
buffer space for the entire packet is available in the receiving router. In consequence, 
 
Fig. 3-20. Cases of (a) Wormhole Switching and (b) Virtual-Cut-Through Switching. 
 84
furthermore, DR-VCT can support a variable packet length which is equal to or less 
than the buffer size. 
 
3.5.4 Ping-Pong Buffer and its Operation  
The major operation constraint of virtual-cut-through switching is that flits of a 
packet can move to the next router only when the buffer space in the receiving router 
is available to accommodate the entire packet. As shown in Figs. 3-22(a) and 3-22(b), 
where the link utilization is less than 50% since the head packet is blocked even if 
there is only one flit of the preceding packet left in the receiving buffer. To enhance 
 
Fig. 3-21. Deadlock-Free Mechanism of DR-VCT. 
 86
3.5.5 Output Port Prioritization and Livelock Freedom  
In each router, an adaptive routing algorithm must determine the output port 
through which a packet will be forwarded. According to different output port 
directions to the packet destination, five output port selection priorities are defined for 
a two-dimensional mesh network as shown in Fig. 3-23. In DR-VCT, an output port 
toward the packet destination will be selected unless it has been allocated to another 
packet, then other output ports in the second priority will be checked. Finally, if all 
output ports are occupied, then the packet is queued in the input buffer until any one 
of the output ports is available. As mentioned in Section 3.5.3, at least one output port 
will be released to the input buffer before it overflows. Besides, when there are 
several output ports with the same priority to be chosen. To prevent using a random 
number generation with complex logics and for a fair comparison, as the routing 
algorithm implemented in Odd-Even [10], DR-VCT chooses the output port along y 
dimension prior to the output port along x dimension, then selects output ports in the 
same x or y dimension depending on the current router being in the odd or even 
column to spread traffic flow evenly. The detailed algorithm is shown in Fig. 3-23. 
 
 88
the original datagram. 
In NoCs, the adopted packet length can be as small as one flit (32 bits) in 
FLIT-BLESS routing as proposed in [32], as large as 100Wc (6400 bits; a Wc equals 
64 bits) as used in [66], or a moderate size of 512 bits as assumed in [48]. In 
architecture view, it is possible to support an unlimited packet length. However, as 
described in [67]: “It is not desirable to choose the packet size to be of extreme length, 
even if the channel and message throughputs increased with the offered load, because 
in a given time duration this leads to use of only a small number of packets resulting 
in large delays”. In a CMP with caches, the major data transfers are in units of a cache 
line size. To prevent fetching a cache line in several fragments of packets, the 
maximum packet length setting should not be less than the cache line size adopted in 
a CMP NoC. 
3.5.7 Buffer Size Allocation  
It is well known that network performance can be enhanced by enlarging the 
size of buffers to regulate traffic flows and increase the link utilization. To accomplish 
a better tradeoff between cost and performance, an ideal minimal buffer size is 
required to accommodate the burst traffic at a maximum peak data rate. Actually, for a 
general-purpose platform, it is difficult to predict real network conditions in the chip 
design phase. Thus, Hu et al. [49] analyzed XY and Odd-Even routing algorithms 
under uniform, hotspot, and realistic application traffics. The experimental results 
showed that the network performance can be greatly enhanced by enlarging each 
buffer size from two to multiple times of a packet length. 
In NoCs, Michelogiannakis et al. [48] allocated 1024 bits for each endpoint 
buffer (for two virtual channels where each virtual channel equals 8×64 bits). The 
1024-bit buffer equals the double of a 512-bit packet length adopted in the same paper. 
A real NoC, the TeraFLOPS Processor [64] uses two logical lanes in each input buffer 
of a router; each lane has a 16-flit queue and each flit contains 32 data bits. 
TeraFLOPS Processor also features a 1024-bit buffer, which is the double of the cache 
 90
[10]. Except for XY, only DR-VCT.512b performed much worse than OE-WH.512b. 
However, DR-VCT.1024b behaved slightly better than OE-WH.1024b, about 5.00% 
in maximal throughput and 33.11% in average latency before the maximal throughput. 
The lower panel of Fig. 3-24 shows that the packet deflection rate (i.e., the percentage 
of packets routed along non-minimal routes) increased rapidly after the packet 
injection rate of the maximal throughput, and led to a higher latency and a lower 
throughput performance. However, in most real-world applications, networks are 
prevented from operating at traffic loads more than the throughput saturation point. 
Thus, this performance drawback of DR-VCT is of little practical concern. 
 
 92
heavy-traffic band forms in the southwest-to-northeast direction. In a network with 
heavy traffic loads, deflection routing packets can congest the network. Anjan and 
Pinkston reported similar experimental results for the non-minimal routing scheme 
DISHA [60]. Nevertheless, under light-traffic loads (i.e., the maximal packet injection 
rates equal to and lower than 0.013, as shown in Fig. 3-25(b)), DR-VCT can exploit 
more routing paths. Thus, DR-VCT provided better performance metrics in both 
latency and throughput under these conditions. 
 
3.5.8.3 Hotspot Traffic Simulation Results 
The hotspot traffic simulations applied uniform traffic conditions, but for 20% 
of the packets, the destination was restricted to one of four selected nodes [(7, 2), (7, 
3), (7, 4), (7, 5)] with equal probability. Figs. 3-26(a) and 3-26(b) show that XY-WH 
routing achieved relatively poor performance in coping with traffic jams caused by 
 
Fig. 3-25. Performance Variations under Transpose Traffic Conditions with (a) 
512-bit and (b) 1024-bit Buffer Configurations. 
 94
series of 100 simulations using the “telecom” traffic pattern and a 6×6 mesh network. 
Besides, “telecom” traffic included 30 tasks (nodes), which is the largest task number 
application of E3S. Fig. 3-27(a) shows that DR-VCT.512b and OE-WH.512b 
achieved similar performance. Furthermore, Fig. 3-27(b) shows that DR-VCT.1024b 
performed better than OE-WH.1024b, at about 11.10% higher in maximal throughput 
and 10.13% lower in average latency before the maximal throughput. 
 
3.5.8.5 Fault-Tolerance Simulation Results 
Freedom from deadlock is achieved by turn-prohibitions in a turn model [9]. As 
a result, turn-model based algorithms can only use a subset of all physically existent 
routing paths, and this limitation creates challenges for fault-tolerant routing 
algorithms based on turn models. For example, Zhen et al. [34] and Fick et al. [35] 
required reconfiguring routing tables to fit different faults in the network. Turn-model 
 
Fig. 3-27. Performance Variations under Telecom Traffic Conditions with (a) 512-bit 
and (b) 1024-bit Buffer Configurations. 
 96
3.5.8.6 Implementation Overhead  
The proposed router was designed using Verilog Hardware Description 
Language (HDL) and synthesized by Synopsys Design Compiler. Power analyses 
were calculated by Synopsys Power Compiler in UMC 90nm technology under 
typical operation conditions. Input buffers were implemented by flip-flop arrays, 
which can be further optimized using the custom SRAM-based buffers in [48]. Table 
3-5 shows that the area and power overheads for implementing DR-VCT in a router 
with a double buffer-size (1024 bits per buffer) were 1.77% and 0.58%, respectively. 
Even when implementing DR-VCT with a single buffer-size configuration (512 bits 
per buffer), the area and power overheads were still as small as 3.57% and 1.27%, 
respectively. Moreover, since the additional controls for deflection routing and 
virtual-cut-through switching are executed in parallel with the primary router design, 
they add no extra delay in the critical path of this implementation. 
 
 
3.5.9 Remarks  
In this study, first, we introduced a virtual-cut-through switching method to 
enhance the packet routing adaptivity and solve the packet truncation problem in the 
current deflection routing algorithm. Second, we applied a ping-pong ring buffer to 
increase the inefficient link utilization in traditional virtual-cut-through switching 
implementations. By doing so, our proposed Deflection Routing algorithm with 
Virtual-Cut-Through Switching (DR-VCT) demonstrated that it out-performs the 
Table 3-5. Implementation Overhead Analyses. 
 
BUFFER SIZE 1024-BIT INPUT UFFER 512-BIT INPUT BUFFER 
ITEM \ 
ALGORITHM 
PRIMARY DR-VCT OVER 
HEAD 
PRIMARY DR-VCT OVER 
HEAD 
Area 442411.00 450253.00 1.77% 335493.00 347470.00 3.57% 
Power (mW) 80.89 81.36 0.58% 56.45 57.17 1.27% 
Timing (ns) 1.25 1.25 0.00% 1.25 1.25 0.00% 
 98
 
 100
routing algorithms, the detour-based scheme is continually open to discussion. 
Recently, while bidirectional channels have been used to enhance the NoC 
communication performance [63], [69], and [70] there has been no study that applied 
bidirectional channels in the fault-tolerant NoC research. In this chapter, we propose a 
novel scheme, named Bi-directional Fault-Tolerant NoC (BFT-NoC), which utilizes 
the bidirectional channel to deal with the fault-tolerance issues in the NoC data-link 
layer. 
4.2 Fault-Tolerance Basics 
With continued shrinkage of semiconductor process feature sizes, on-chip 
operating frequency and transistor density will continue to grow while the supply 
voltages will continue to decrease. In [2], it is commented that “Electrical noise due 
to crosstalk, electromagnetic interference, and radiation-induced charge injection will 
likely produce data errors, also called upsets. Thus, transmitting digital values on 
wires will be inherently unreliable and nondeterministic”. Therefore, NoCs need to be 
designed with specific fault-tolerant schemes to counterbalance the negative impact of 
the increasing failure rate of on-chip interconnects. 
4.2.1 Fault Types in NoCs 
Along with the continued scaling in process technologies, the on-chip 
communication is not guaranteed error-freedom in future NoCs. The main challenge 
is represented by the increased prominence of noise sources such as power supply 
noise, crosstalk noise, inter-symbol interference, electromagnetic interference, thermal 
noise, and noise induced by alpha particles [8]. Consequently, failures probably exist 
in a chip and can be static or dynamic. Referring to the definition in [8], static failures 
are present in the network when the system is powered on and dynamic failures 
appear at random during the operation of the system. These two types of failures are 
respectively caused by permanent faults and transient faults. Alternatively, transient 
faults generally occur in the field and it has been showed that 80% of system failures 
are associated with transient faults [8]. For these reasons, fault-tolerant schemes are 
 102
flexibility as well as the advantages and limitations regarding a bi-directional 
fault-tolerant NoC which will be discussed in details in the following sections. 
4.2.4 Problems of Existing Fault-Tolerant Schemes 
In conventional NoCs, a router uses a TX-Channel and a RX-Channel to 
communicate with its neighboring router as shown in Fig. 4-1(a). When the 
TX-Channel is faulty as illustrated in Fig. 4-1(b), it will lead to a fatal error if 
transmitting packets from router R1 to router R2 in a non-fault-tolerant system. Even 
applying existing fault-tolerant schemes which can detour packets through the other 
possible routing paths; there are still two major problems to be taken into 
consideration as follows: 
(1) Problem 1: The alternative path does not exist (e.g., in an irregular 
topology network such as the SPIN in [2]). 
(2) Problem 2: The alternative path possibly leads to a deadlock (e.g., 
violating the turn rules of the adopted turn model [10]). 
 
 
To the best of our knowledge, no NoC fault-tolerant scheme can handle Problem 
1 before our proposal. For Problem 2, to avoid deadlocks in the fault-tolerant 
operation mode, schemes based on a modified existing routing algorithm such as [34] 
always have inferior routing adaptivity and lower reliability. Besides, some studies 
rely on re-configuring the global routing tables such that the system can restart after 
completing the re-configuration [35]. However, this kind of off-line schemes cannot 
dynamically handle faults as mentioned in the previous section. 
 
Fig. 4-1. Channel Transmission Directions and Connection Statuses of (a) non-faulty 
NoC, and a faulty channel in (b) conventional NoC and (c) the BFT-NoC. 
 104
4.3.1 Bidirectional Channel  
In an NoC, faults in connections between routers could be permanent faults 
caused by electronic migration and dielectric breakdown or transient faults such as 
soft error and timing fault [8]. In these cases, a fault detection mechanism is required 
in an unreliable on-chip communication environment and the approach involves 
communications between a sender and a receiver. For example, Cyclic Redundancy 
Code (CRC) is a common channel error detection code as introduced in [8]. Since the 
CRC designs in both the channel encoder and the channel decoder are identical, it is 
feasible to implement a bidirectional channel with almost the same hardware cost of a 
unidirectional channel as shown in Fig. 4-3. 
 
4.3.2 Bidirectional Router Architecture  
Referring to Fig. 4-4, in a Bi-directional Fault-Tolerant NoC (BFT-NoC), two 
bidirectional channels are equipped between neighboring routers. An additional 
channel controller is required to dynamically select the data flow direction in the 
bidirectional channels whenever any faulty channel is detected or the faulty channel is 
recovered. In this chapter, we focus on studies about the capability and feasibility in 
applying the bidirectional channel for NoC fault-tolerant communications. Hence, in 
normal operations (i.e., no faulty channel case) in our experiments, one of the 
bidirectional channel pair is used for the TX-Channel (TX-Ch) and the other is 
reserved for the RX-Channel (RX-Ch). When one of the two channels is faulty, the 
other channel can be changed to operate bi-directional; that is, the intact channel can 
be shared by both the TX and RX data flows. Compared with the other fault-tolerant 
 
Fig. 4-3. Bidirectional Channel Example. 
 106
(1) tx_req: output, asserted when requesting to use the channel for TX. 
(2) tx_gnt: input, asserted when the TX request is granted. 
(3) rx_req: input, asserted when being requested to use the channel for RX. 
(4) rx_gnt: output, asserted when the RX request is granted. 
 
 
It is noticeable that each of these four control signals has a corresponding 
definition in its counterpart router. Referring to Fig. 4-5, the tx_req in Router 1 
corresponds to the rx_req in Router 2; and the tx_gnt in Router 1 corresponds to the 
rx_gnt in Router 2. Besides, some other control signals are used for the channel 
controller within a router. For example, ch_req is asserted when the bidirectional 
channel is requested to be used for transmitting packets. An asserted tx_ch_fault 
means that the TX-Channel is faulty, and the asserted tx_ch_fault could be de-asserted 
after the TX-Channel is recovered from a transient fault; similarly, rx_ch_fault 
indicates the fault status of the RX-Channel. The signal of buf_full is used to prevent 
in-router deadlocks which will be discussed later. Last, sel_signals are the selections 
of multiplexers and tri-state buffers as shown in Fig. 4-4. 
4.3.4 Fault-Tolerance Control Procedure  
The Finite State Machine (FSM) of the channel controller as depicted in Fig. 4-6 
comprises five main states: 
 
Fig. 4-5. Intra-Router and Inter-Router Control Signals. 
 108
after receiving the transmission grant, tx_gnt (i.e., the rx_gnt at the counterpart router); 
then the FSM can directly transfer to the TX state since the counterpart router has 
completed its data transmission. In case of detecting a pair of faulty channels, the 
FSM will transfer to the Paired-Fault state in order to inform a detour-based scheme 
such as in [34] and [35] to handle this faulty case. Especially, if the error is transient 
and whenever the faulty channel is recovered, the FSM will retrieve a TX, RX or 
Normal state. 
4.3.5 In-router Deadlock and its Solution  
In our implementations, we adopted XY [25] and Odd-Even [10] as the 
deadlock free routing algorithms. Although deadlock freedom can be guaranteed 
among routers in a mesh network, a new in-router deadlock phenomenon could exist 
in our proposed BFT-NoC with wormhole switching. As shown in Fig. 4-7(a), there 
are two faulty channels respectively located in the west and east sides of the router, 
where both FSMs of the channel controllers are in the RX state and waiting for each 
other to transfer to the TX state to free up the buffer spaces for accommodating the 
remaining flits of the incoming packets. Unfortunately, the mutually waiting condition 
will continue forever and form a deadlock in the router. To relieve this in-router 
deadlock condition, we select to preempt the FSM from the RX state to the TX state 
while the channel controller receives both a channel request (ch_req) and a buffer full 
condition (buf_full) as illustrated in Fig. 4-7(b). Consequently, the buffer will be 
flushed and then the FSM can return to the RX state to continue receiving the residual 
flits. 
 
 110
Since FRCh << 1, one has FRBFT-NoC << FRUNI-NoC. Clearly, with bidirectional 
channels, the failure rate of a BFT-NoC is significantly reduced. 
4.3.7 Reliability Enhancement  
Once faulty channels exist in an NoC, fault-tolerant schemes can be used to 
provide a certain reliability to probably maintain the functional correctness for a 
system operation. Here, we evaluate the reliabilities of our proposed BFT-NoC and 
the other two schemes, proposed in [34] and [35] and respectively called as Method-1 
and Method-2 in later sections. Each of the reliability data as shown in Fig. 4-8 was 
caculated with an 8×8 mesh. Though BFT-NoC cannot tolerate the case where 
channels between neighboring nodes are both faulty, but BFT-NoC can provide a 
90.80% reliability even if seven faulty channels exist in the network. Referring to Fig. 
4-8(a), Method-1 provided a poor reliability when the number of faulty channels is 
bigger than 1. The reason is that Method-1 set a constraint that all faults must be 
related to one router. That is, if there are two faulty channels connected to four routers, 
deadlocks could happen when using Method-1. As shown in Fig. 4-8(b), Method-2 
supported a good reliability (> 98%) in case of seven faults. However, Method-2 
needed to re-configure the global routing tables; thus, Method-2 is difficult to 
dynamically handle transient faults. Last and most importantly, BFT-NoC can be 
combined with Method-1 or Method-2 as a hybrid scheme of Method-1+BFT-NoC or 
Method-2+BFT-NoC, which respectively improved the reliabilities to 99.58% and 
99.94% as shown in Figs. 4-8(a) and 4-8(b). 
 
 112
simulations with randomly selected faulty-channel locations. As shown in Figs. 4-9 
and 4-10, first, the latency increased and the throughput decreased along with the 
increased number of faulty channels in all simulations. Next, the performance 
downgrading was moderate. For example, compared with the simulations with 
zero-fault, the decreases of the maximal throughput in the simulations with the 7-fault 
were small with 20.83%, 4.33%, 12.82%, and 0.37% in XY-Uniform, XY-Hotspot, 
OE-Uniform, and OE-Hotspot, respectively. Lastly, BFT-NoC performed better with 
Odd-Even than with XY, the reason is that the adaptive routing algorithm of 
Odd-Even can reduce the chance of packets going through the bidirectional channels 
where TX and RX data flows share with a channel bandwidth. 
 
 
 
 
Fig. 4-9. Performance Variations with XY Routing Algorithm under (a) Uniform and 
(b) Hotspot Traffics. 
 114
(i.e., 5%-fault), the bandwidth sharing for both TX and RX rarely happen in contrast 
to the sharing in synthetic traffics. 
 
4.4.3 Implementation Overhead  
Our router was designed in Verilog, synthesized by Synopsys Design Compiler, 
and power analyses were calculated by Synopsys Power Compiler in UMC 90nm 
technology. Referring to Table 1, the area and power overheads for implementing a 
BFT-NoC router were small in 4.07% and 1.86%, respectively. Moreover, BFT-NoC 
made no timing impact since the additional controls for bidirectional channels can 
execute in parallel with the primary UNI-NoC design. 
 
 
 
 
Fig. 4-11. Performance Comparisons under Real Traffics. 
Table 4-1. Implementation Overhead Analyses. 
 
Item \ Scheme UNI-NoC BFT-NoC Overhead 
Router Area 407762.00 424396.00 4.07% 
Router Power 79.57mW 81.05mW 1.86% 
Router Timing 1.23ns 1.23ns* 0.00% 
Note*: The 0.29ns latency of the additional control is not located in the critical path of the designed 
router. 
 116
 118
 
 120
TC: Type Code (of CFG) 
  00: CFG Write Request 
  01: CFG Write Response 
  10: CFG Read Request 
  11: CFG Read Response 
PC: Priority Code 
000: Low priority 
111: High priority 
EC: Error Control 
EC[0]: 0, Ack is required; 1, Ack is not required 
EC[1]: 0, Retry is permitted; 1, Retry is not permitted 
SN: Sequence Number 
 
A.2 Interface Signals 
The interface signal definitions are given as follows. 
A.2.1 Host Interface  
 
Name IO Width Description 
HS_ADD O 16 Read/Write Address 
HS_WE O 1 Write Enable 
HS_WD O 32 Write Data 
HS_RD I 32 Read Data 
A.2.2 Buffer Interface  
 
Name IO Width Description 
HF_PUSH I 1 Push Signal 
HF_DI I 33 Data In 
HF_POP I 1 Pop Signal 
HF_DO O 33 Data Out 
HF_FULL O 1 FIFO Full Signal 
HF_EMPT O 1 FIFO Empty Signal 
 
 
 
 
 122
A.4 Control Registers and Routing Table 
 
A.4.1 Definitions of Registers 
 
Name Address Description 
Node Address 0x0000,  
[00:15] 
Node Address (for uni-cast) 
Channel Number 0x0000,  
[16:23] 
Channel Number (for multicast and broadcast) 
Routing Mode 0x0000,  
[24:22] 
000: No Turn Limitation Mode 
001: Odd-Even Mode 
011: West-First Mode 
101: North-Least Mode 
111: Negative-First Mode 
TABDA03-00 0x0001 Routing Table on Destination Addresses 03-00 
TABDA07-04 0x0002 Routing Table on Destination Addresses 07-04 
TABDA11-08 0x0003 Routing Table on Destination Addresses 11-08 
TABDA99-12 0x0004- 
0x0019 
Routing Table on Destination Addresses 99-12 
THPRI4-1 0x001A Threshold of the Priority Ports 4-1 
Reserved 0x001B - 
0xFFFE  
Reserved for future uses 
Testing 0xFFFF For Testing 
 
Programming:  
The registers can be programmed directly by the local host or via a 
configuration packet. The address is specified in destination offset 
field of the configuration packet. 
 
 
 
 31     24 23    16 15 08 07    00 
00 Routing Mode Channel Number Node Address 
01 TABDA03 TABDA02 TABDA01 TABDA00 
02 TABDA07 TABDA06 TABDA05 TABDA04 
03 TABDA11 TABDA10 TABDA09 TABDA08 
~ ~ ~ ~ ~ 
1a Reserved THPRI3 THPRI2 THPRI1 THPRI0 
~ Reserved
 124
 
 126
B.1 Non-Minimal Routing Algorithm Based on Odd-Even Turn Model 
 
  
 
 
Fig. B-1. Non-Minimal Routing Algorithm Based on Odd-Even (1/2). 
 128
B.2 Non-Minimal Routing Algorithm Based on West-First Turn Model 
 
  
 
 
Fig. B-3. Non-Minimal Routing Algorithm Based on West-First. 
 130
 
 132
FPGA Performance Report: 
Quartus II Version: 7.2 Build 175 11/20/2007 SP 1 SJ Full Version 
Device Family: Stratix II, EP2S90F1020C5 
Logic Utilization: 14 % 
Combinational ALUTs: 7,026 / 72,768 (10 %)  
Dedicated logic registers: 7,402 / 72,768 (10 %)  
Total block memory bits: 290,688 / 4,520,448 (6 %)  
Max. Operation Frequency: 76.38 MHz 
C.2 RTL Simulation Environment 
The simulations in an RTL-implemented 88 NoC really took time. We used 
some methods to speed up the simulations. 
(1) Simulations were run on Cadence NC-Verilog, which is a compiled-code 
and event-trigger simulator. The simulation speed is much faster than 
Verilog-XL (another interpreter simulator). 
(2) We disabled displaying any information during execution. The results are 
only reported in a text file at the end of simulations. 
(3) We used scripts to distribute executing independent simulations to free 
work-stations in our laboratory. Our Graduate Institute supports us 
 
Fig. C-1. Validation by Self Loop Back Test. 
 134
 
 
 136
[11] E. Nilsson, M. Millberg, J. Oberg, and A. Jantsch, “Load distribution with the 
Proximity Congestion Awareness in a Network on Chip,” in Proc. of the Design, 
Automation and Test in Europe Conference and Exhibition, pp. 1126-1127, 
March 2003. 
[12] T.T. Ye, L. Benini, and G.D. Micheli, “Packetization and Routing Analysis of 
On-Chip Multiprocessor Networks,” Journal of Systems Architecture, Vol. 50, 
No. 2-3, pp. 81-104, February 2004. 
[13] J. Hu and R. Marculescu, “DyAD - Smart Routing for Networks-on-Chip,” in 
Proc. of the 41st ACM/IEEE Design Automation Conference, pp. 260-263, June 
2004. 
[14] J. Kim, D. Park, T. Theocharides, N. Vijaykrishnan, and C. R. Das, “A Low 
Latency Router Supporting Adaptivity for On-Chip Interconnects,” in Proc. of 
the 42nd ACM/IEEE Design Automation Conference, pp. 559-564, June 2005. 
[15] G. Ascia, V. Catania, M. Palesi, D. Patti, “Implementation and Analysis of a 
New Selection Strategy for Adaptive Routing in Networks-on-Chip,” IEEE 
Trans. Computers, Vol. 57, No. 6, pp. 809-820, June 2008. 
[16] D. Wu, B.M. Al-Hashimi, and M.T. Schmitz, “Improving Routing Efficiency for 
Network-on-Chip Through Contention-Aware Input Selection,” in Proc. of the 
11st Asia and South Pacific Design Automation Conference, pp. 36-41, January 
2006. 
[17] A. Pullini, F. Angiolini, D. Bertozzi, and L. Benini, “Fault Tolerance Overhead 
in Network-on-Chip Flow Control Schemes,” in Proc. of the 18th Symposium 
on Integrated Circuits and Systems Design, pp. 224-229, September 2005. 
[18] D. Bertozzi and L. Benini, “Xpipes: A Network-on-Chip Architecture for 
Gigascale Systems-on-Chip,” IEEE Circuits and Systems Magazine, Vol. 4, No. 
2, pp. 18-31, October 2004. 
[19] K. Goossens, J. Dielissen, and A. Radulescu, “Æthereal Network on Chip: 
Concepts, Architectures, and Implementations,” IEEE Design and Test of 
Computers, Vol. 22, No. 5, pp. 21-31, September-October 2005.  
 
 
 138
[31] W.J. Dally and C.L. Seitz, “The Torus Routing Chip,” Journal of Distributed 
Computing, Vol. 1, No.4 , pp. 187-196, January 1986. 
[32] T. Moscibroda and O. Mutlu, “A Case for Bufferless Routing in On-Chip 
Networks,” in Proc. of the 36th International Conference on Computer 
Architecture, pp. 196-207, January 2009. 
[33] T. Schonwald, J. Zimmermann, O. Bringmann, and W. Rosenstiel, “Fully 
Adaptive Fault-Tolerant Routing Algorithm for Network-on-Chip Architectures,” 
in Proc. of the 10th Euromicro Conference on Digital System Design 
Architectures, Methods and Tools, pp. 527-534, August 2007. 
[34] Z. Zhen, A. Greiner, and S. Taktak, “A Reconfigurable Routing Algorithm for a 
Fault-tolerant 2D-Mesh Network-on-Chip,” in Proc. of the 45th ACM/IEEE 
Design Automation Conference, pp. 441-446, June 2008. 
[35] D. Fick, A. DeOrio, G. Chen, V. Bertacco, D. Sylvester, and D. Blaauw, “A 
Highly Resilient Routing Algorithm for Fault-Tolerant NoCs,” in Proc. of the 
Design, Automation and Test in Europe Conference and Exhibition, pp. 21-26, 
April 2009. 
[36] M. Valinataj, S. Mohammadi, J. Plosila, and P. Liljeberg, “A Fault-Tolerant and 
Congestion-Aware Routing Algorithm for Networks-on-Chip,” in Proc. of the 
13rd IEEE International Symposium on Design and Diagnostics of Electronic 
Circuits and Systems, pp. 139-144, April 2010. 
[37] A. Kohler, G. Schley, and M. Radetzki, “Fault Tolerant Network on Chip 
Switching With Graceful Performance Degradation,” IEEE Trans. 
Computer-Aided Design of Integrated Circuits and Systems, Vol. 29, No. 6, pp. 
883-896, June 2010. 
[38] Y. Qian, Z. Lu, and W. Dou, “Analysis of Worst-Case Delay Bounds for 
Best-Effort Communication in Wormhole Networks on Chip,” in Proc. of the 
3rd ACM/IEEE International Symposium on Networks-on-Chip, pp. 44-53, May 
2009. 
[39] J. Duato, S. Yalamanchili, and L. Ni, Interconnection Networks: An Engineering 
Approach, Morgan Kaufmann Publishers Inc., 2002. 
[40] T. Bjerregaard and S. Mahadevan, “A Survey of Research and Practices of 
Network-on-Chip,” ACM Computing Surveys, Vol. 38, No. 1, pp. 1-51, June 
 140
[51] T.C. Chen and Y.W. Chang, “B*-tree Floorplanner (Windows),” 
http://eda.ee.ntu.edu.tw/research.htm. 
[52] P.P. Pande, C. Grecu, M. Jones, A. Ivanov, and R. Saleh, “Performance 
Evaluation and Design Trade-Offs for Network-on-Chip Interconnect 
Architectures,” IEEE Trans. Computers, Vol. 54, No. 8, pp. 1025-1040, August 
2005. 
[53] S. Konstantinidou and L. Snyder, “The Chaos Router,” IEEE Trans. Computers, 
Vol. 43, No. 12, pp. 1386-1397, December 1994. 
[54] J.T. Brassil and R.L. Cruz, “Bounds on Maximum Delay in Networks with 
Deflection Routing,” IEEE Trans. Parallel and Distributed Systems, Vol. 6, No. 
7, pp. 724-732, July 1995. 
[55] M.K.F. Schafer, T. Hollstein, H. Zimmer, and M. Glesner, “Deadlock-Free 
Routing and Component Placement for Irregular Mesh-based 
Networks-on-Chip,” in Proc. of the IEEE/ACM International Conference on 
Computer-Aided Design, pp. 238-245, November 2005. 
[56] S.Y. Lin, C.H. Huang, C.H. Chao, K.H. Huang, and A.Y. Wu, “Traffic-Balanced 
Routing Algorithm for Irregular Mesh-Based On-Chip Networks,” IEEE Trans. 
Computers, Vol. 57, No. 9, pp. 1156-1168, September 2008. 
[57] J. Wu, “A Fault-Tolerant and Deadlock-Free Routing Protocol in 2D Meshes 
Based on Odd-Even Turn Model,” IEEE Trans. Computers, Vol. 52, No. 9, pp. 
1154-1169, September 2003. 
[58] L. Schwiebert and D.N. Jayasimha, “Optimal Fully Adaptive Wormhole 
Routing for Meshes,” in Proc. of the ACM/IEEE Conference on Supercomputing, 
pp. 782-791, November 1993. 
[59] W.J. Dally and C.L. Seitz, “Deadlock-Free Message Routing in Multiprocessor 
Interconnection Networks,” IEEE Trans. Computers, Vol. C-36, No. 5, pp. 
547-553, May 1987. 
[60] K. V. Anjan and T. M. Pinkston, “An Efficient, Fully Adaptive Deadlock 
Recovery Scheme: DISHA,” in Proc. of the 22nd Annual International 
Symposium on Computer Architecture, pp. 201-210, June 1995. 
 
  
行政院國家科學委員會補助研究計畫出國研究心得報告 
                                                                                                  100  年  8  月 25日 
報告人姓名  陳少傑  服務機構
及職稱 
國立台灣大學教授 
          時間 
 
          地點 
自 99年 7 月  2日至   
      99年 9 月 12日 
UW, Madison 
本會核定
補助文號
   
  NSC‐97‐2221‐E002‐241‐MY3 
 
計畫 
名稱 
(中文)  階層式網路晶片系統平台合成器之研製 (3/3) 
(英文)  Research  on  the  Development  of  a  Hierarchical  Network‐on‐Chip 
System Platform Synthesizer (3/3) 
 
   
 
 
  
  
Report of EITC 2010 
by Sao-Jie Chen,  December 7th, 2010 
 
The 10th Emerging Information & Technology Conference, EITC 2010, was 
successfully held on August 14-15, at the James H. Clark Center of Stanford 
University. After the opening speech was delivered by Dean Lin-Shan Lee of 
National Taiwan University, the four parallel technical sessions began (Fig. 1).   
 
Fig.1. Dean Lin-Shan d Lee delivering opening speech. 
 
In this year of EITC, with the help of Prof. Liang-Gee Chen, we have invited 25 
distinguished speakers for the SoC/C4I workshop, among which 14 are from USA, 9 
from Taiwan, and 2 from Japan. Among them, 12 speakers are from industry and 13 
speakers from academics, which form a very strong program for the workshop. The 
details of invited speakers and their presentation topics are described as follows.  
For the keynote speech, we have succeeded to invite Prof. Chin-Long Wey, the 
Director of National Chip-Implementation Center (CIC) to deliver a presentation on 
“Chip Design and Implementation Service in Taiwan” (Fig. 2).  
  
from National Tsing-Hua University, “Low-Power Analog Front-End Circuits for 
HealthCare System and Telemetry Devices” by Prof. Shuenn-Yuh Lee from National 
Chung-Cheng University, “Low-Power Analog Front-end Circuits for ECG 
Acquisition Systems” by Prof. Tsung-Heng Tsai from National Chung-Cheng 
University, and “Design and Implementation of an XML Parsing Engine” by Prof. 
Sheng-De Wang from National Taiwan University. 
 
Fig. 3. Prof. Liang-Gee Chen hosting a Medical SoC session. 
For the Wireless System and Communication SoC tracks, we have invited six 
speakers (four from USA, one from Japan, and one from Taiwan). The four speakers 
from USA are Professor Yung-Hsiang Lu from Purdue University who delivers a talk 
on “Mobile and Cloud Computing Opportunities and Challenges”. Dr. James Larsen 
from the iWICS, Inc. presented “Beyond 3G™, Unlimited Capacity”, Dr. Zye-Kong 
Cheng from iCHIPdesign, presented “A Multimedia Routing Algorithm in Multipath 
Environment”, and Professor Yu-Hen Hu from UW Madison presented “Recent 
Progress in Design Methodologies for Software Defined Radio”. The one speaker 
from Japan, Professor Kazuya Masu of Tokyo Institute of Technology presented a 
topic on “Physical design challenge to cognitive radio/software defined radio” and the 
one professor from Taiwan, Professor Chen-Yi Lee from National Chiao-Tung 
University presented “Recent Progress in Communications SoC’s”. 
  
UW-Madison Study Report 
蔡文宗 撰寫 
學生蔡文宗於民國99年 06月 28日至民國99年 08月 31日期間前往美國威
斯康辛大學麥迪遜分校進行研究訪問，其間包含 08 月 14 日至 08 月 15 日於伊利
諾大學香檳分校兩天之參訪行程。關於 Network-on-Chip 之研究，停留美國期
間曾四次與威斯康辛大學麥迪遜分校副系主任胡玉衡老師進行四次當面討論，並
多次書信往返，獲益良多，對於研究工作的進行甚有幫助。期間完成論文題目『A 
Novel Fluidity-Aware NoC Traffic Control』(包含研究實驗與論文撰寫)，之
後並同胡老師完成論文題目『Non-Minimal, Turn-Model Based NoC Routing』
之 Abstract、 Introduction 與 Background 三個章節的論文撰寫和實驗設計。
關於此兩篇論文之簡介如下： 
A Novel Fluidity-Aware NoC Traffic Control: 
In this paper, a Dynamic Traffic Control (DyTC) scheme, that integrated 
Networks-on-Chip (NoC) congestion control and flow control with a novel fluidity 
concept, is proposed. Buffer fluidity is used to measure the likelihood that flits in a 
buffer could be forwarded toward its neighboring switches. Flits with a higher level of 
fluidity would move toward its destination faster and free-up scarce buffer resources 
sooner. Thus, they should be handled with a higher priority than stalled flits. In doing 
so, latency can be reduced and traffic throughput can be increased. A buffer flow 
monitor is developed to estimate the buffer fluidity level. Both the congestion control 
algorithm and flow control algorithm have then to adapt their policies according to the 
currently estimated buffer fluidity level. Tested with both synthetic traffic patterns as 
well as industry benchmark traffic patterns, significant performance enhancement has 
been observed when DyTC is compared to traffic control algorithms that solely refer 
to the conventional buffer fill level information. 
 
出席國際會議心得報告 
撰寫人:陳少傑 
 
I.  SOCC 2010 
本人於9月26日(週日)一早到桃園機場搭乘達美航空 DL276班機前往美國，因該班
機延誤將近半天，經交涉後得以改搭聯合航空UA838前往東京成田機場，順利銜接下
午03:30之DL284班機飛達加州Los Angelos機場後，再轉DL4903班機抵達Las Vegas。隨
即租車開往大會旅館安頓妥當。 
第二天（9月27日，週一）上午即到大會會場報到，取得名牌、研討會議程簡介一冊、
及會議論文集CD等資料。上午參加Keynote and Plenary Presentations: 由University of 
California Berkeley之Alberto Sangiovanni Vincentelli主講“SoC Design as an Example of 
Component-Based Design of Distributed Systems”、Synopsys之Michael Keating主講“Third 
Revolution: The Search for Scalable Code-Based Design”、及IBM之Sandra Woodward主講
“A Wire-Speed Processor System-on-a-Chip (SOC): Technical Overview and Challenges for 
a Large Complex SOC used in Next-Generation Systems”。中午與Invited speakers用餐後參
加下午1:00PM-2:40PM之Session MA3: SoC Power Optimization Techniques，及主持
2:55PM-3:45PM之Embedded Tutorial由IBM之Thomas Buechner主講“A Holistic View on 
Low Power Design”及5:00PM-6:00PM由Synopsys 之Kaijian Shi主講“Low-power SOC 
implementation: What you need to know”。晚上參加Organization Committee Meeting討論
明年由台灣主辦SoCC 2011事宜。 
第三天（9月28日，週二）上午參加8:00AM-9:40AM之Session TB1: System Level 
Design Methodologies 及 9:55AM-12:00noon 之 Session TB2: System Level Design 
Methodologies。中午參加之Luncheon Speaker為由NanoArk Corp.之P.R. Mukund主講
“From Film to Silicon: The Migration of Document Archiving Technology” 接著由本人介
紹明年SoCC 2011之地點:台北市圓山大飯店。下午參加1:30PM-04:15PM之Session TB3: 
Reconfigurable Systems，然後參加Poster Session及Reception Dinner。 
第四天（9月29日，週三）上午參加Plenary Session:由Covington & Burling LLP之Jo 
Dale Carothers主講“What You Need to Know About Patent Litigation”。然後主持
8:50AM-10:05AM之Embedded Tutorial由Eindhoven University of Technology之Lech 
Jóźwiak主講“Quality-driven SoC Architecture Synthesis for Embedded Applications”、接著
主持10:20AM-12:00 noon Session WA2之“Network on Chip 1”及報告我們的文章“DyML: 
Dynamic Multi-Level Flow Control for Networks on Chip”。下午參加1:00PM-2:40PM 
Session WA3之“Network on Chip 2”至此大會結束。隨即前往Las Vegas機場搭乘16:35之
DL2640班機前往Salt Lake City再轉20:05之DL3480班機於23:52抵達Austin。 
DyML: Dynamic Multi-Level Flow Control for Networks on Chip 
 
Wen-Chung Tsai1, Ying-Cherng Lan1, Sao-Jie Chen1, 2, Yu-Hen Hu3 
 
1Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan, ROC 
{d95943036, f94943068}@ntu.edu.tw, csj@cc.ee.ntu.edu.tw 
2Graduate Institute of Electrical Engineering, National Taiwan University, Taipei, Taiwan, ROC 
3Department of Electrical and Computer Engineering, University of Wisconsin, Madison 
Madison, WI53706, USA, hu@engr.wisc.edu  
 
 
ABSTRACT 
A novel hybrid Dynamic Multi-Level (DyML) 
flow control scheme for Networks-on-Chip is 
proposed. DyML uses a buffer fluidity flow monitor 
for real-time monitoring the incoming traffic volume. 
Instead of buffering as many flits as a router can 
afford, DyML dynamically adjusts the proper 
number of buffering flits. Accordingly, DyML causes 
less in-transit packets in the network, thus improves 
packet latency and mitigates traffic congestion. 
Experiments indicated that DyML averagely 
improves the latency performance of a state-of-the-
art routing algorithm (Odd-Even) by 25.43% in 
synthetic traffics and by 0.90% in real traffics. 
 
I. INTRODUCTION 
Networks-on-Chip (NoC) is a promising on-chip 
communication infrastructure [1]. Key performance 
metrics of an NoC include low packet delivery 
latency and high throughput rate. These metrics are 
critically impacted by the underlying flow control 
mechanism [2]. A flow control scheme regulates the 
data transmission rates from a sender to a receiver 
in a network. The goal is to maximize the rate of 
data transmission without overwhelming the 
receiver’s data buffer. In an NoC fabric, both local 
link layer (node-to-node) and global transmission 
layer (end-to-end) flow control objectives must be 
considered jointly so as to meet the communication 
requirements while maximizing a network’s 
resources utilization efficiency [2]. Moreover, real 
hardware overheads as well as power consumption 
are critical in an NoC chip design. 
On one hand, link layer NoC flow control 
schemes, such as STALL/GO [3] and ACK/NACK [4] 
mechanisms use local information to regulate the flit 
transmission rate between wormhole routers. As 
such, the packet injection rate at the sending end of 
a transmission flow often cannot be timely regulated 
to adapt to the congestion condition at a down-
stream link along its routing path. On the other 
hand, transmission layer flow control schemes in 
NoCs, such as credit-based and window-based 
algorithms [5,6], do regulate the packet injection 
rate right at the transmission source. However, the 
end-to-end flow control schemes go with significant 
communication and processing overheads that 
could require extra hardware resources and impact 
the primary system performance. 
To balance the needs of link and transmission 
layer flow controls, a novel Dynamic Multi-Level 
flow control mechanism, named DyML, is proposed 
in this paper. DyML uses a quantity called “buffer 
fluidity level” [7] to monitor the link layer flow 
volume. When heavier link layer traffic is detected, 
DyML dynamically regulates the buffering of in-
transit packets [8] in wormhole routers to prevent 
overcrowding network resources, thereby balances 
the performance requirements of packet delivery 
latency and overall network throughput. 
Furthermore, DyML performs well in both light and 
heavy traffic conditions and is practical to be 
integrated in most NoC platforms with a low cost. 
 
II. BACKGROUND 
Transmissions may experience contentions 
along its routing paths which results in a congestion 
tree [9] as illustrated in Fig. 1. In a network, 
contentions can be alleviated by both congestion 
and flow controls. Congestion control keeps the 
network free of traffic jams; while flow control 
ensures that no transmission master overwhelms 
any of its counterpart slaves. For congestion control, 
adaptive routing schemes [10] can be used to 
forward packets around the contentions. In NoCs, 
most congestion control schemes are based on 
monitoring the buffer conditions in its neighboring 
nodes. For example, Hu and Marculescu presented 
429978-1-4244-6683-2/10/$26.00 ©2010  IEEE      
[7] showed that using the buffer fluidity level can 
reflect more realistic traffic conditions. 
 
A.  Implementation Details 
Applying In-Transit Packets and Buffer Fluidity 
Concepts in DyML: Using the in-transit packets 
concept to enhance latency performance when the 
network is under heavy traffic loads [8], and also 
considering that wormhole is the most popular and 
solely implemented switching technique in many 
NoCs, we borrowed the buffer fluidity concept in [7] 
to realize a flow monitor to reflect the real-time 
traffic conditions. Instead of mixing virtual-cut-
through and wormhole switching in a router [8], we 
gave the wormhole router an additional flow control 
ability to suppress injecting packets or flits into the 
network when the flow monitor reflects that the 
traffic is busy as illustrated in Fig. 2. Additionally, to 
prevent the throughput performance loss under light 
and middle traffic loads, DyML must operate in a 
smarter way as introduced in next section. 
Dynamic and Multi-Level Properties of DyML: In 
this paper, a six-state (L0 to L5) flow monitor as 
shown in Fig. 3 is used to demonstrate the dynamic 
and multi-level flow control concept. Definitions of 
the Buffer Fluidity Levels (BFluL) and Buffer Fill 
Levels (BFilL) are respectively defined in Table 1 
and Table 2. In Fig. 3, the default state is L0, which 
is valid when the buffer is empty. L1 to L5 represent 
5 buffer fluidity levels from fluent to un-fluent. The 
state transfer event, NPTO (Non-Pop Time-Out), 
indicates there is no pop operation in the buffer 
during a pre-defined period. The other state transfer 
event, PTO (Pop Time-Out), indicates that there is 
a certain pre-defined number of pop operations 
occurred in the current state. Consequently, the 
state in Fig. 3 trends moving to the un-fluent state 
(L5) when the buffer cannot forward any flit to next 
nodes. On the contrary, the state in Fig. 3 probably 
keeps in the fluent state (L1) where push and pop 
operate alternately. In short, by constantly 
calculating the density of push and pop operations, 
the buffer fluidity concept can be realized to 
represent the real-time traffic conditions. 
Table 1:  Buffer Fluidity Levels 
Level Buffer Fluidity Levels
L0 Empty (buffer fill = 0) 
L1 Fluent 
L2 Middle fluent 
L3 Less fluent 
L4 Near un-fluent 
L5 Un-fluent 
Table 2: Buffer Fill Levels 
Level Buffer Fill Levels
L0 Full (buffer fill = buffer size) 
L1 Near full (buffer fill = buffer size - 1) 
L2 At least 1/2 filled (buffer fill >= buffer size / 2) 
L3 At least 1/4 filled (buffer fill >= buffer size / 4) 
L4 At least 1/8 filled (buffer fill >= buffer size / 8) 
 
Enhanced STALL/GO Flow Control using DyML: 
Fig. 4 discloses the conditions where the STALL 
signal is asserted or de-asserted by the DyML 
mechanism. In the conventional STALL/GO flow 
control, STALL is asserted only when buffer is full to 
prevent loss of packets. Moreover, DyML 
dynamically asserts STALL according to the real 
Figure 3: Buffer fluidity state machine. 
: Source : Destination
A slow slave  
PE PE PE PE
PE PE PE PE
PEPEPEPE
X
X
X
X X
XX
X X X
X
X
Reduces in-transit packets
Figure 2: Congestion tree using DyML. 
431
a buffer in 32 flits can accommodate at least two 
packets [15]. All packet latency and throughput 
results are averaged over 60,000 packets after an 
warm-up session of 30,000 arrived packets. 
Uniform Traffic: In Fig. 6(a), we observed that 
the XY performs the best. Identical results are 
shown in [10]. The reason is that under uniform 
traffic, XY happens to spread traffic much evenly 
across the paths in a mesh. However, except for XY, 
OE-DyML achieves a higher throughput saturation 
point and performs better than OE in both 
performance metrics. Referring to Table 3, OE-
DyML on average improves OE 25.12% in latency 
and 2.45% in throughput. 
Hotspot Traffic: In contrast to uniform traffic, Fig. 
6(b) shows that XY is inferior in performance under 
hotspot traffic. Hotspot is a more realistic traffic 
scenario [10]. Instead of waiting in front of traffic 
jams caused by hotspot nodes, adaptive routing 
algorithms such as OE support a certain degree of 
routing freedom for packets to route around traffic 
busy blocks through other available routing paths. 
Referring to Table 3, OE-DyML on average 
improves OE 28.14% in latency and 1.09% in 
throughput. 
Transpose Traffic: The transpose traffic pattern 
is a kind of specific operations similar to the Matrix-
Transpose [10]. In experiments, OE-DyML is little 
inferior to OE in throughput; however, OE-DyML 
greatly overcomes OE in packet latency. Referring 
to Table 3, OE-DyML on average improves OE 
23.03% in latency and -0.55% in throughput. 
 
C.  Experiments with Real Traffics 
We used E3S benchmarks from the Embedded 
Microprocessor Benchmark Consortium (EEMBC) 
[16] to realize the performance variations under real 
traffics. First, each task in the task graph was 
mapped into a node in the mesh to optimize the 
total communication cost. Next, each of the three 
adopted patterns: consumer, auto-indust, and 
telecom, was repeated 100 times and run on a 4×4, 
5×5, and 6×6 mesh respectively.  
Two simulation results are shown in Fig. 6(c) 
and 6(d), which display that there is no distinct 
throughput performance difference among routing 
Figure 6: Variations in (top) latency and (bottom) throughput under (a) Uniform, (b) Hotspot, (c) Consumer, and (d) Auto-indust traffics.
Table 3: Performance enhabcements by DyML upon the routing algorithm based on Odd-Even. 
ʳ  Synthetic Traffics Real Traffics 
Performance Average Latency* Average Throughput* Average Latency* Average Throughput* 
Algorithm Unif. Trans. Hots. Unif. Trans. Hots. Cons. Auto. Tele. Cons. Auto. Tele. 
OE 190.625  276.113  383.425  0.01326 0.01222 0.01062 74.075 112.838 71.088  0.00459  0.00664 0.00505 
OE-DyML 142.738  212.538  275.538  0.01359 0.01215 0.01074 73.188 112.088 70.500  0.00459  0.00664 0.00505 
OE-DyML** 74.88% 76.97% 71.86% 102.45% 99.45% 101.09% 98.80% 99.34% 99.17% 100.00% 100.00% 100.00%
Note*: The perfromance data are averaged in all experimental results where buffers are respectively configured in 16 flits and 32 flits. 
Note**: The data of OE-DyML are normalized by OE (100%). 
 
433
Agenda for Prof. Sao-Jie Chen 
National Taiwan University 
September 30, 2010 
 
 
 
9:45am   Arrive at ARL 
   Loc: Bldg. 904 Lobby (Sani to escort up) 
 
10:00-10:45am  Meet with Ram Rajamony 
   Manager Novel Systems Architecture 
   Loc: Ram’s office 
 
10:45-11:30am  Meet with Peter Hofstee 
   Research Staff Member 
   Loc: Peter’s office 
 
11:30am-1:00pm LUNCH with Sani Nassif  
   Manager Tools and Technology  
   Loc: Offsite 
 
1:00-1:45pm  Meet with Chuck Alpert 
   Manager Design Productivity 
   Loc: Chuck’s office 
 
1:45-2:00pm  Set up time 
 
2:00-3:00pm  Seminar by Prof. Sao-Jie Chen 
   Title: "Anticipated QoS Control in a Bidirectional NoC" 
   Loc: ARL Classroom 
 
3:00-3:30  Q & A 
   Loc: ARL Classroom 
 
3:30-4:15pm  Meet with Jian Li 
   Novel Systems Architecture 
   Loc: Jian’s office 
 
4:15-5:00pm  Meet with Gi-Joon Nam 
   Design Productivity 
   Loc: Gi-Joon’s office 
 
5:30-7:30pm  Dinner with Kevin Nowka, and others (Sani Nassif, Peter Hofstee, 
Chuck Alpert) 
   Director Austin Research Lab 
   Loc: TBD 
II.  ICCAD 2010 
 
本人於 11 月 7 日(週日) 晚搭乘中華航空 CI 004 的 23:20 班機於 18:20 許抵達 San 
Francisco。旋即租車開往 San Jose 機場附近之旅館安頓妥當以便參加三天之
International Conference on CAD (ICCAD)。 
11 月 8 日(週一)上午即到 ICCAD 大會會場所在之 Double Tree 旅館報到，取得名
牌、研討會議程簡介一冊、及會議論文集 CD 等資料。上午參加 Opening Session and 
Keynote Address，由 UC San Diego 之 James C. Bouwer 主講 Multi-Scale Microscopy of 
the Nervous System: The Challenge of Imaging and Organizing Data Across Spatial 
Scales Spanning。接著參加 Tutorial 1: Designing for Uncertainty: Addressing Process 
Variations and Aging Issues in Digital Systems。下午參加 Tutorial 2: Reliability Analysis 
and Optimization at System-Level: A Straddle Between Complexity and Accuracy，及
Tutorial 3: Analog Challenges in Nanometer CMOS and Digitalization of Analog 
Functionality。晚上參加了 ACM/SIGDA Member Meeting 聆聽由 Scott Kirkpatrick 之
演講。 
第三天（11 月 9 日，週二）參加上午的 Tutorial 4: System-Level Design  An Industrial 
Perspective。中午參加 Lunch Presentation 由 Lanza TechVentures 之 Lucio Lanza 主講
Semiconductor and EDA Industr  A New Business Model。下午參加 Session 6C: 3-D-ICs 
and Detection of Faults and Hardware Trojans 及 Session 7B: Parallel Methods for Power 
Grid and Interconnect Analysis。晚上參加了 Reception Banquet。 
第四天（11 月 10 日，週三）參加上午的 Tutorial 7: Digital Microfluidic Biochips: A 
Vision for Functional Diversity and More than Moore 及 下 午 的 Tutorial 8: 
Manufacturing, CAD and Thermal-Aware Architectures for 3-D MPSoCs。至此會議結
束。 
11 月 11 日(週四) 8 月 16 日 (週一) 中午車開往 San Jose 機場搭乘美國航空
AA1052 的 14:00 班機經 Chicago 轉美國航空 AA5028 的 21:45 班機於 22:30 許抵達
Madison。翌日本人即到 UW Madison 的 ECE Department，和胡玉衡教授討論合作研
究事宜。 
11 月 15 日(週一) 本人於 Madison 搭乘美國航空 AA3313 的 14:20 班機經 Dallas
轉 AA1421 的 19:20 班機於 21:05 許抵達加州 San Francisco。然後搭乘 11 月 16 日(週
二)中華航空 CI 003 的 00:05 班機於 11 月 17 日 06:00 許返抵台北。 
  
  
  
 
 
 
 
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are  
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, to republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee. 
DAC'11, June 5-10, 2011, San Diego, California, USA  
Copyright © 2011 ACM 978-1-4503-0636-2/11/06...$10.00 
 
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
A Fault-Tolerant NoC Scheme Using Bidirectional Channel 
Wen-Chung Tsai1, Deng-Yuan Zheng1, Sao-Jie Chen1, 2, and Yu-Hen Hu3  
1Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan, ROC  
2Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan, ROC 
3Department of Electrical and Computer Engineering, University of Wisconsin, Madison, WI, USA 
{d95943036, r98943094}@ntu.edu.tw, csj@cc.ee.ntu.edu.tw, hu@engr.wisc.edu 
 
 
 
 
ABSTRACT 
A novel Bidirectional Fault-Tolerant NoC (BFT-NoC) 
architecture capable of mitigating both static and dynamic channel 
failures is proposed. In a traditional NoC platform, a faulty data 
channel will force blocked packets to make costly detours, 
resulting in significant performance hits. In this work, novel fault-
tolerance measures for a bidirectional NoC platform are proposed. 
The dynamically reconfigurable bidirectional channels of the 
BFT-NoC offer great flexibility to contain data-link permanent or 
transient faults while incurring negligible performance loss. 
Potential performance advantages in terms of failure rate 
reduction and reliability enhancement of the BFT-NoC 
architecture are carefully analyzed. Extensive experimental results 
clearly validate the fault-tolerance performance of BFT-NoC at 
both synthetic and real world network traffic patterns.   
Categories and Subject Descriptors 
C.1.2 [Processor Architectures]: Multiple Data Stream 
Architectures (Multiprocessors) – Interconnection architectures 
(e.g., common bus, multiport memory, crossbar switch). 
General Terms 
Algorithms, Design, Reliability. 
Keywords 
NoC, Fault-Tolerance, Bidirectional Channel. 
1. INTRODUCTION 
Networks-on-Chip (NoC) [1] has become an increasingly 
popular on-chip interconnection solution for many-core Systems-
on-Chip platforms. With a fabric of mesh-connected routers, an 
NoC promises enhanced scalability and reliability for on-chip data 
communication. In particular, leveraging redundant routers and 
channels between senders and receivers, it is often touted that an 
NoC is inherently fault tolerant.  
On chip data communication over an NoC fabric may be 
gravely disrupted due to transient malfunctions or permanent 
physical damages to interconnection devices. Existing NoC fault-
tolerant schemes [2], [3], [4], [5] have focused on efficient detour 
strategies for rerouting blocked packets. However, detour 
rerouting is a costly solution. To avoid potential deadlock 
situation caused by detour routing, existing strategies either settle 
for a more restricted set of path selection heuristics, or require off-
line reconfiguration of routing tables. The former may yield 
inferior routes that further aggravate the overall performance; 
while the latter may incur significant overheads to store new 
routing tables, and is inefficient to deal with transient faults.  
Recently, NoCs equipped with bidirectional channels, such as 
the Bidirectional NoC (BiNoC) [6], and the bandwidth-adaptive 
network [7], have been proposed. Bidirectional channel supports 
run-time reconfigurations of data transmission directions to adapt 
to varying traffic demands. This kind of flexibility promises great 
performance advantages which have been clearly demonstrated 
under normal operating conditions. However, the potential 
impacts of utilizing bidirectional channel to fault-tolerant NoC 
operations have not been thoroughly studied. 
In this work, a novel fault-tolerant NoC scheme using 
bidirectional channel, called as Bidirectional Fault-Tolerant NoC 
(BFT-NoC), is proposed. This mechanism is devised to mitigate 
potential performance hits due to faulty channels through dynamic 
sharing of other surviving channels. As such, unless channels 
between neighboring routers all fail, costly data rerouting can be 
avoided. Accordingly, we provide a thorough analysis showing 
that the proposed BFT-NoC achieves better fault-tolerance 
capabilities in terms of lower failure rate and higher reliability. 
Moreover, extensive experiments exhibit graceful performance 
degradation of the BFT-NoC at increasing number of faulty 
channels.   
In Section 2, current NoC fault-tolerant schemes and potential 
applications with bidirectional channels are reviewed. Section 3 
discusses issues with existing fault-tolerant NoCs. In Section 4, 
we introduce our router architecture and fault-tolerance 
mechanism. Then mathematical analyses and experimental results 
are given respectively in Sections 5 and 6. Finally, a conclusion is 
drawn in Section 7. 
2. RELATED WORKS 
2.1 Fault-Tolerance in NoCs 
With continued shrinkage of semiconductor process feature 
sizes, on-chip interconnecting wires become increasingly 
vulnerable to failures caused by permanent and transient faults 
[8]. The mesh-connected NoC architecture has been touted to be 
fault tolerant due to the availability of redundant alternate routes. 
 
918
51.2
4. BIDIRECTIONAL FAULT-TOLERANT 
NOC SCHEME 
4.1 Bidirectional Channel 
In an NoC, faults in connections between routers could be 
permanent faults caused by electronic migration and dielectric 
breakdown or transient faults such as soft error and timing fault 
[8]. In these cases, a fault detection mechanism is required in an 
unreliable on-chip communication environment and the approach 
involves communications between a sender and a receiver. For 
example, Cyclic Redundancy Code (CRC) is a common channel 
error detection code as introduced in [8]. Since the CRC logics in 
the channel encoder and the channel decoder are identical, it is 
feasible to implement a bidirectional channel with the similar 
hardware cost of a unidirectional channel as shown in Figure 3. 
 
 
 
Figure 3. Bidirectional channel example. 
4.2 Router Architecture 
 
FSM
Channel Controller
Input Buffer MU
X
Ch
an
ne
l-S
ele
ct
Arbiter
FSM
Channel Controller
Input Buffer
MUX
Arbiter
Channel-Select
 
 
Figure 4. Router architecture and inter-router connections 
including control signals and bidirectional channels. 
 
Referring to Figure 4, in a Bidirectional Fault-Tolerant NoC 
(BFT-NoC), two bidirectional channels are equipped between 
neighboring routers. An additional channel controller is required 
to dynamically select the data flow direction in the bidirectional 
channels whenever any faulty channel is detected or the faulty 
channel is recovered. In this paper, we focus on studies about the 
capability and feasibility in applying bidirectional channel for 
NoC fault-tolerant communications. Hence, during the normal 
operations (i.e., no faulty channel) of our experiments, one of the 
pair of bidirectional channels is used for the TX-Channel (TX-Ch) 
and the other is served for the RX-Channel (RX-Ch). When one of 
the two channels is faulty, the other channel is changed to operate 
bidirectionally; that is, the intact channel can share for both TX 
and RX data flows. Compared with the other fault-tolerant 
schemes as mentioned above, our proposed mechanism can 
dynamically react to the fault conditions and be independent of 
the adopted routing algorithm. Once both channels between 
neighboring routers are faulty, our designed channel controller 
reflects this condition and then can cooperate with other scheme 
such as [4] and [5] to seek alternative routing paths. However, 
since the failure rate in an on-chip environment is much small as 
shown in Table 4.1 of [8]. Accordingly, and referring to Figure 
2(b), BFT-NoC can individually provide a high reliability when 
the number of faults is generally a small value. In next section, we 
will introduce the details of our BFT-NoC mechanism. 
4.3 Fault-Tolerance Measures 
4.3.1 Channel Direction Change Handshaking 
To share a channel (ch.) bandwidth between two neighboring 
routers, a handshaking protocol is required to avoid conflicts 
caused by transmitting data from both sides at the same time. 
From the viewpoint of a router, four control signals as shown in 
Figure 5 are required and the definitions are:    
tx_req: output, asserted when requesting to use the ch. for TX. 
tx_gnt: input, asserted when the TX request is granted. 
rx_req: input, asserted when being requested to use the ch. for RX. 
rx_gnt: output, asserted when the RX request is granted. 
 
 
 
Figure 5. Intra-router and inter-router control signals. 
 
It is noticeable that each of these four control signals has a 
corresponding definition in its counterpart router. Referring to 
Figure 5, the tx_req in Router 1 corresponds to the rx_req in 
Router 2; and the tx_gnt in Router 1 corresponds to the rx_gnt in 
Router 2. Besides, some other control signals are used for the 
channel controller within a router. For example, ch_req is asserted 
when the bidirectional channel is requested to be used for 
transmitting packets. An asserted tx_ch_fault means that the TX-
Channel is faulty, and the asserted tx_ch_fault could be de-
asserted after the TX-Channel is recovered from a transient fault; 
similarly, rx_ch_fault indicates the fault status of the RX-Channel. 
The signal of buf_full is used to prevent in-router deadlocks 
which will be discussed later. Last, sel_signals are the selections 
of multiplexers and tri-state buffers as shown in Figure 4. 
4.3.2 Fault-Tolerance Control Procedure 
The Finite State Machine (FSM) of the channel controller 
depicted in Figure 6 comprises five main states: 
1. Normal: In the absence of faulty channel. 
2. TX: The intact channel is available for transmitting data out. 
3. RX: The intact channel is ready for receiving data in. 
4. Wait: An intermediate state from the TX state to the RX state. 
5. Paired-Fault: Both channels are faulty. 
920
51.2
a poor reliability when the number of faulty channels is bigger 
than 1. The reason is that Method-1 sets a constraint that all faults 
must be related to one router. That is, if there are two faulty 
channels connected to four routers, deadlocks could happen in the 
use of Method-1. As shown in Figure 8(b), Method-2 supports a 
good reliability (> 98%) in case of seven faults. However, 
Method-2 needs to reconfigure the global routing tables; thus, 
Method-2 is difficult to dynamically handle transient faults. Last 
and most importantly, BFT-NoC can be combined with Method-1 
or Method-2 as a hybrid scheme of Method-1+BFT-NoC or 
Method-2+BFT-NoC, which respectively improve the reliabilities 
to 99.58% and 99.94% as shown in Figures 8(a) and 8(b). 
 
0
10
20
30
40
50
60
70
80
90
100
0 1 2 3 4 5 6 7
Re
lia
bi
lit
y 
(%
)
Number of faulty channel(s)
Method-1 + BFT-NoC
BFT-NoC 
Method-1 
90
91
92
93
94
95
96
97
98
99
100
0 1 2 3 4 5 6 7
Re
lia
bi
lit
y 
(%
)
Number of faulty channel(s)
Method-2 + BFT-NoC
BFT-NoC 
Method-2
 
(a)                                                    (b) 
 
Figure 8. (a) Reliabilities of Method-1, BFT-NoC, and 
Method-1+BFT-NoC, and (b) reliabilities of Method-2, BFT-
NoC, and Method-2+BFT-NoC. 
6. EXPERIMENTAL RESULTS 
To evaluate the performance impact among various traffic types 
upon different numbers of faulty channels in the BFT-NoC, 
comprehensive simulations were run in Register Transfer Level 
(RTL) using Cadence NC-Verilog. Each channel’s bandwidth is 
set to one flit (32 bits) per cycle. Four cycles are required for 
switching a header flit to an output port in a pipelining fashion. 
We assigned to each input port’s buffer 1024 bits as in [11] and 
applied the wormhole switching technique.  
6.1 Experiments with Synthetic Traffics 
Synthetic traffic performance analyses in terms of latency and 
throughput were carried out on an 8×8 mesh network. The sizes of 
packets were randomly distributed between 4 to 16 flits. In each 
run of the simulations, all performance metrics are averaged over 
30,000 packets after a warm-up session of 10,000 arrived packets. 
Two common traffic patterns, namely uniform and hotspot were 
considered in our experiments. In uniform traffic, a node transmits 
a packet to any other node with equal probability. In hotspot 
traffic, uniform traffic is applied, but 20% of packets change their 
destinations to one of the following four selected nodes [(7, 2), (7, 
3), (7, 4), (7, 5)] with equal probability. Five different faulty-
channel numbers including 0, 1, 3, 7, and 20 were performed to 
realize the performance impacts. Each data of the performance 
metrics is an average value of 100 simulations with randomly 
selected faulty-channel locations. As shown in Figure 9, first, the 
latency increases and the throughput decreases along with the 
increased number of faulty channels in all simulations. Next, the 
performance downgrading is moderate. For example, compared 
with the simulations with zero-fault, the decrease of the maximal 
throughput in the simulations with the 7-fault are small with 
20.83%, 4.33%, 12.82%, and 0.37% in XY-Uniform, XY-Hotspot, 
OE-Uniform, and OE-Hotspot respectively. Lastly, BFT-NoC 
performs better with Odd-Even than with XY, the reason is that 
the adaptive routing algorithm of Odd-Even can reduce the chance 
of packets going through the bidirectional channel where TX and 
RX data flows share with a channel’s bandwidth. Besides, the 
adaptive routing algorithm of Odd-Even is also useful to spread 
traffic loads in hotspot traffic than in uniform traffic. 
 
0
50
100
150
200
250
300
0.008 0.011 0.014 0.017 0.02 0.023 0.026
A
vg
. p
ac
ke
t l
at
en
cy
 (c
yc
le
)
Max. packet injection rate (packets/cycle/node)
XY - Uniform Latency
zero-fault
1-fault
3-fault
7-fault
20-fault
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
0.008 0.011 0.014 0.017 0.02 0.023 0.026
A
vg
. t
hr
ou
gh
pu
t (
pa
ck
et
s/
cy
cl
e/
no
de
)
Max. packet injection rate (packets/cycle/node)
XY - Uniform Throughput
zero-fault
1-fault
3-fault
7-fault
20-fault
× 10-2
 
(a) 
0
50
100
150
200
250
300
0.0055 0.0067 0.0079 0.0091 0.0103 0.0115
A
vg
. p
ac
ke
t l
at
en
cy
 (c
yc
le
)
Max. packet injection rate (packets/cycle/node)
XY - Hotspot Latency
zero-fault
1-fault
3-fault
7-fault
20-fault
0.54
0.61
0.68
0.75
0.82
0.89
0.96
1.03
0.0055 0.0067 0.0079 0.0091 0.0103 0.0115
A
vg
. t
hr
ou
gh
pu
t (
pa
ck
et
s/
cy
cl
e/
no
de
)
Max. packet injection rate (packets/cycle/node)
XY - Hotspot Throughput
zero-fault
1-fault
3-fault
7-fault
20-fault
× 10-2
 
(b) 
0
100
200
300
400
500
0.008 0.011 0.014 0.017 0.02 0.023
A
vg
. p
ac
ke
t l
at
en
cy
 (c
yc
le
)
Max. packet injection rate (packets/cycle/node)
OE - Uniform Latency
zero-fault
1-fault
3-fault
7-fault
20-fault
0.8
1
1.2
1.4
1.6
1.8
2
2.2
0.008 0.011 0.014 0.017 0.02 0.023
A
vg
. t
hr
ou
gh
pu
t (
p
ac
ke
ts
/c
yc
le
/n
od
e)
Max. packet injection rate (packets/cycle/node)
OE - Uniform Throughput
zero-fault
1-fault
3-fault
7-fault
20-fault
× 10-2
 
(c) 
0
100
200
300
400
500
0.01 0.0107 0.0114 0.0121 0.0128 0.0135
A
vg
. p
ac
ke
t l
at
en
cy
 (c
yc
le
)
Max. packet injection rate (packets/cycle/node)
OE - Hotspot Latency
zero-fault
1-fault
3-faults
7-faults
20-faults
0.99
1.02
1.05
1.08
1.11
1.14
1.17
1.2
0.01 0.0107 0.0114 0.0121 0.0128 0.0135
A
vg
. t
hr
ou
gh
pu
t (
p
ac
ke
ts
/c
yc
le
/n
od
e)
Max. packet injection rate (packets/cycle/node)
OE - Hotspot Throughput
zero-fault
1-fault
3-faults
7-faults
20-faults
× 10-2
 
(d) 
 
Figure 9. Performance variations in latency (left) and 
throughput (right) with XY under (a) uniform and (b) hotspot  
traffics, and OE under (c) uniform and (d) hotspot traffics. 
6.2 Experiments with Real Traffics 
In addition to evaluate BFT-NoC performance with synthetic 
traffics, we used E3S benchmarks [12] to demonstrate the 
922
51.2
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/31
國科會補助計畫
計畫名稱: 階層式網路晶片系統平台合成器之研製
計畫主持人: 陳少傑
計畫編號: 97-2221-E-002-241-MY3 學門領域: 積體電路及系統設計
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本研究成果所提出之雙向通道網絡晶片（Bidirectional NoC, BiNoC）架構可
提高晶片上資料傳輸的效能，是計畫主持人和其博士生(籃英誠 Ying-Cherng 
Lan)經研究分析後共同提出，受學術界肯定先在2009年5月之The 3rd ACM/IEEE 
International Symposium on Networks on  Chip (NOCS)中發表並獲最佳論文
獎。隨即獲大會推薦撰寫成期刊論文發表於 2011 年 3 月之 IEEE Trans. on 
Computer-Aided Design 中。國際間網路晶片(Network-on-Chip, NoC)的研究
競爭相當激烈，本團隊另一研究成果「A Fault-Tolerant NoC Scheme Using 
Bidirectional Channel」已發表於 2011 年 Design Automation Conference 
(DAC)。DAC 是 EDA (Electronic Design Automation)研究領域中的頂尖會議，
此論文獲得所有評審委員推薦發表非常難得。本團隊之研究成果能分別發表於
電子設計自動化領域的頂尖會議及重量級期刊中，對提升我國在此研究領域的
國際地位，具有重要的貢獻。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
