共  頁  第 2 頁 
 
文獻探討 
關聯性資料不僅是網頁搜尋、整合的核心技術，更是許多其他研究領域，例如：自然語
言分析 (Embley et al. 1998, Bernstein et al. 2005, Pazienza et al. 2005, Sáenz and Vaquero 
2005)、Question Answering (Harabagju et al. 2000, Mann 2002, Ravichandran and Hovy 2002)、
Machine Translation (Hovy 1998, Mahesh and Nirenburg 1996, Okumura and Hovy 1994)中的核
心關鍵，在這些領域中，了解字詞中間的關聯以及概念中的關聯是非常重要的，而大部分的
研究都會利用 Ontology 來作為關聯性資料的格式，Ontology (Klein et al. 2002, Klein and Fensel 
2001, Heflin and Hendler 2000, Smith and Christopher 2001, Benjamins et al. 1999, Gruber 2003) 
能夠讓使用者及系統對於某個概念、專業領域有著通盤了解，使得使用者與系統之間能夠溝
通順利。 
因此有研究希望能針對 Ontology 的繁複建置步驟，利用系統自動化的產生 Ontology，以
減少人力投注、加速 Ontology 的建置。建置 Ontology 需要幾個不同的步驟，從初期的挑選領
域、挑選資料來源；以及接下來自動辨識出領域重要詞彙及辨識關係 (Alani et al. 2003a)；到
後期的自動產生分類、以及最後進行演化的步驟。每一項步驟都有其困難與挑戰，因此目前
自動化的研究，多半都專注於某個步驟的自動化過程，少有能夠全程自動化的。 
目前甚少有研究能夠達到完全自動化建置 Ontology，即使有也是在少數的固定領域上，
例如：Fuzzy Ontology (Widyantoro and Yen 2001)，這個研究能自動化的對於資料建立概念叢
集 (Cluster)，找出關鍵字，再為這些關鍵字建立關聯，但此研究所利用的資料皆是來自於 IEEE 
transaction 的資料，有著相似的資料格式；另一方面，它所使用的關係較為特別，是直接使
用數字來表達相關程度，而非自然語言的方式來表達。也有研究針對智慧財產文件來建立圖
示概念的 Ontology (Yan and Soo 2008)，也能做到擷取資料、關係的自動化。但所使用的資料
是結構明顯的資料。 
以上研究大都是著重在特定領域，選定固定領域，其實皆是在同個領域知識中自動發展
Ontology 的意思。可看出過往很多自動化建置 Ontology 的研究，都是由固定領域知識開始發
展。而在固定領域中，其實有著固定常用詞彙與關係形式，稱為領域知識。這些領域知識到
了別的領域當中可能無法適用。因此雖然在這些研究中，所提出的方法都能達到不錯的效果，
卻無法彈性到運用到各領域當中。 
至於在在不固定領域知識的問題上，我們並沒有找到任何的研究能做完整的自動建置，
只有看到一些研究能協助比較不同的 Ontology (Wiesman et al. 2001, , Gal et al. 2004, Gal et al. 
2005)，申請人過去與學生所研發的技術 (Hsu et al. 2006)，也是屬於這一個大項。 
從上述的文獻探討可得知，要全然自動化建立 Ontology 是一大挑戰，在本計畫中，我們
將嘗試著從不固定 Format、不明確領域開始，然後利用詞彙簡短的使用者檢索詞彙做的語料
來源，嘗試自動建立起概念之間的上下位、分類關係、自動建立起之間的關係，這將是一個
極大的挑戰，不過根據申請人與學生過去的研究成果來看，這樣的研究計畫卻是實際可行的。 
98-2221-E-007-096- Final Report11/4
共  頁  第 4 頁 
 
參考文獻 
• (Alani et al. 2003) Harith Alani, Sanghee Kim, David E. Millard, Mark J. Weal, Paul H. Lewis, Wendy 
Hall, and Nigel R. Shadbolt. Automatic Extraction of Knowledge from Web Documents. 2nd 
International Semantic Web Conference - Workshop on Human Language Technology for the Semantic 
Web abd Web Services, 2003. 
• (Alani et al. 2003a) Harith Alani, Sanghee Kim, David E. Millard, Mark J. Weal, Weal Hall, Paul H. 
Lewis and Newis Shadbolt. Web based Knowledge Extraction and Consolidation for Automatic 
Ontology Instantiation. 2nd
 
International Conference Knowledge Capture (K-Cap'03), Workshop on 
Knowledge Markup and Se-mantic Annotation, 2003. 
• (Agrawal et al. 2008) Rakesh Agrawal, Anastasia Ailamaki, Philip A. Bernstein, Eric A. Brewer, 
Michael J. Carey, Surajit Chaudhuri, AnHai Doan, Daniela Florescu, Michael J. Franklin, Hector 
Garcia‐Molina, Johannes Gehrke, Le Gruenwald, Laura M. Haas, Alon Y. Halevy, Joseph M. 
Hellerstein, Yannis E. Ioannidis, Hank F. Korth, Donald Kossmann, Samuel Madden, Roger Magoulas, 
Beng Chin Ooi, Tim O’Reilly, Raghu Ramakrishnan, Sunita Sarawagi, Michael Stonebraker, Alexander 
S. Szalay, Gerhard Weikum, The Claremont Report on Database Research, 
http://db.cs.berkeley.edu/claremont/claremontreport08.pdf , 2008. 
• (Bernstein et al. 2005) Abraham Bernstein, Esther Kaufmann, Christoph Buerki, and Mark Klein. How 
Similar Is It? Towards Personalized Similarity Measures in Ontologies. Wirtschaftsinformatik, pp. 
1347-1366, 2005. 
• (Buscaldi et al. 2005)Davide Buscaldi, Paolo Rosso, Emilio Sanchis Arnal. A wordnet-based query 
expansion method for geographical information retrieval. Working Notes for the Cross-Language 
Evaluation Forum (CLEF) Workshop, 2005. 
• (Chandrasekaran et al. 1999) B. Chandrasekaran, John R. Josephson, and V. Richard Benjamin. What 
are ontologies, and why do we need them?. IEEE Intelligent Systems, 14(1), pp. 20-26, 1999.  
• (Dean et al. 2003) Mike Dean, Guus Schreiber, Sean Bechhofer, Frank van Harmelen, James Hendler, 
Ian Horrocks, Deborah L. McGuinness, Peter F. Patel-Schneider, and Lynn Andrea Stein. OWL Web 
Ontology Language Reference. W3CWorking Draft, 2003.  
• (Dou et al. 2003) Dejing Dou, Drew McDermott, and Peishen Qi. Ontology Translation on the Semantic 
Web. Conference on Ontologies, Databases and Applications of Semantics, 2003. 
• (Embley et al. 1998) David W. Embley, Douglas M. Campbell, Randy D. Smith, and Stephen W. Liddle. 
Ontology-Based Extraction and Structuring of Information from Data-Rich Unstructured Documents. 
Conference on Information and Knowledge Management CIKM'98 Proceedings, pp.52-59, 1998. 
• (Ehrig and Staab 2004) Marc Ehrig and Steffen Staab. Efficiency of ontology mapping approaches. 
International Workshop on Semantic Intelligent Middleware for the Web and the Grid at ECAI 04, 
2004. 
 
98-2221-E-007-096- Final Report11/4
共  頁  第 6 頁 
 
• (Jiang et al. 2009) Yunliang Jiang, Hui-Ting Yang, Kevin Chen-Chuan Chang, Yi-Shin Chen, AIDE: 
Ad-hoc Intents Detection Engine over Query Logs, Submitted to SIGMOD 2009 
• (Jiang et al. 2009a) Yunliang Jiang, Hui-Ting Yang, Kevin Chen-Chuan Chang, Yi-Shin Chen, Query 
Intent Detection: Searching Query Log Online, Submitted to WWW 2009 
• (Kalfoglou and Schorlemmer 2003) Yannis Kalfoglou and Marco Schorlemmer. Ontology mapping: 
The state of the art. The Knowledge Engineering Review, (1), pp. 1–31, 2003. 
• (Kietz et al. 2000) Joerg-Uwe Kietz, Alexander Maedche, and Raphael Volz. A method for 
semi-automatic Ontology acquisition from a corporate intranet. Proc. of Workshop Ontologies and Text, 
co-located with (EKAW’2000), 2000. 
• (Kim 2002) Henry Kim. Predicting How Ontologies for the Semantic Web Will Evolve. Communications 
of the Association for Computing Machinery (ACM), 45(2), pp. 48–54, 2002. 
• (Klein and Fensel 2001) Michel Klein and Dieter Fensel. Ontology versioning on the semantic web. 
Proceeding of International Semantic Web Working Symposium (SWWS), 2001. 
• (Klein et al. 2002) Michel Klein, Dieter Fensel, Atanas Kiryakov, and Damyan Ognyanov. Ontology 
versioning and change detection on the web. Proceeding of 13th International Conference on 
Knowledge Engineering and Management, 2002. 
• (Lee et al. 2007) Chang-Shing Lee, Yuan-Fang Kao, Yau-Hwang Kuo, and Mei-Hui Wang. Automated 
Ontology construction for unstructured text documents. Data & Knowledge Engineering, 60(3), pp. 
547-566, 2007. 
• (Liu et al. 2009) Po-Ching Liu, Kevin Chen-Chuan Chang, Yi-Shin Chen. Are We Searching for the 
Same Thing? A Large-Scale Analysis of Search Engine Logs. Submitted to SIGIR 2009 
• (Maedche and Staab 2001) Alexander Maedche and Steffen Staab. Ontology learning for the semantic 
web. IEEE Intelligent Systems, 16 (2), pp. 72–79, 2001. 
• (Maedche and Staab 2002) Alexander Maedche and Steffen Staab. Measuring similarity between 
ontologies. Proceedings of the European Conference on Knowledge Acquisition and Management 
(EKAW), 2002. 
• (Maedche et al. 2003) Alexander Maedche, Boris Motik, Ljiljana Stojanovic, Rudi Studer, and Raphael 
Volz. Ontologies for Enterprise Knowledge Management. IEEE Intelligent Systems, 18(2), pp. 26-33, 
2003. 
• (Mahesh and Nirenburg 1996) Kavi Mahesh and Sergei Nirenburg. Meaning Representation for 
Knowledge Sharing in Practical Machine Translation. Proceedings of the FLAIRS-96 track on 
Information Interchange, Florida AI Research Symposium, 1996. 
• (Mann 2002) Gideon S. Mann. Fine-Grained Proper Noun Ontologies for Question Answering. 
SemaNet'02: Building and Using Semantic Networks, 2002. 
• (Mcllraith et al. 2001) Sheila A. McIlraith, Tran Cao Son, and Honglei Zeng. Semantic Web Services. 
IEEE Intelligent Systems 16(2), pp. 46-53, 2001. 
98-2221-E-007-096- Final Report11/4
共  頁  第 8 頁 
 
• (Smith and Christopher 2001) Barry Smith and Christopher Welty. Ontology: Toward a New Synthesis.  
Proceedings of the international conference on Formal Ontology in Information Systems, 2001. 
• (Staab et al. 2001) Steffen Staab, Hans-Peter Schnurr, Rudi Studer, and York Sure. Knowledge 
Processes and Ontologies. IEEE Intelligent Systems, 16 (1), pp. 26-34, 2001. 
• (Stojanovic et al. 2002) Nenad Stojanovic, Ljiljana Stojanovic, and Siegfried Handschuh. Evolution in 
the Ontology-based knowledge management systems. European Conference on Information Systems 
(ECIS), 2002. 
• (Sure et al. 2002) York Sure, Michael Erdmann, Juergen Angele, Steffen Staab, Rudi Studer, and Dirk 
Wenke. OntoEdit: collaborative Ontology development for the semantic web. Proceedings of the First 
International Semantic Web, 2002. 
• (Lee et al. 2001) Tim Berners-Lee, James Henlder and Ora Lassila. The Semantic Web. Scientific 
American, 2001.  
• (Voorhees 1994) Ellen M. Voorhees. Query Expansion using Lexical-Semantic Relations. Proceedings 
of the 17th Annual ACM-SIGIR Conference, pp. 61-69, 1994. 
• (Wang and Ali 2005) James Z. Wang and Farha Ali. An efficient ontology comparison tool for semantic 
web applications. The 2005 IEEE / WIC /ACM International Conference onWeb Intelligence (WI’05), 
pp. 372–378, 2005. 
• (Wang et al. 2005) James Z.Wang, Farha Ali, and Rashmy Appaneravanda. A web service for efficient 
ontology comparison. Proceedings of the IEEE International Conference on Web Services (ICWS05), 
pp. 843–844, 2005. 
• (Widyantoro and Yen 2001)Dwi H. Widyantoro and John Yen. A fuzzy Ontology-based abstract search 
engine and its user studies. Proceedings of the 10th IEEE International Conference on Fuzzy Systems, 
2001. 
• (Wiesman et al. 2001) Floris Wiesman, Nico Roos, and Paul Vogt. Automatic Ontology mapping for 
agent communication. Proceedings of BNAIC '01, pp. 291- 298, 2001. 
• (Yan and Soo 2008) Shih-Yao Yan and Von-Wun Soo. Comparing the Conceptual Graphs Extracted 
from Patent Claims. Sensor Networks, Ubiquitous and Trustworthy Computing, 2008. SUTC '08. IEEE 
International Conference, pp. 394-399, 2008. 
• (Yoshinaga et al. 1999) Kazuyuki Yoshinaga, Takao Terano, and Ning Zhong. Multi-lingual intelligent 
information retriever with automated Ontology generator. Proceedings of the Third International 
Conference on Knowledge-Based Intelligent Information Engineering Systems, pp. 62–65, 1999. 
• (Zhou et al. 2002) Lina Zhou, Queen E. Booker, and Dongsong Zhang. ROD – toward rapid Ontology 
development for underdeveloped domains. Proceedings of the 35th Annual Hawaii International 
Conference on System Sciences, 2002. 
98-2221-E-007-096- Final Report11/4
II. FRAMEWORK
 
 
	


	














ﬀﬁﬂ


ﬃ

ﬀ
 
ﬀ
 
!
ﬁ

ﬀ"
#
ﬀ

"$
%
!

 
ﬀ
ﬃ

ﬀ
&
'
(
)
*
)+, -
./
0102
3.
21
* 4
)'2
/
5
(
6
7
89:;
<=
>? @>A:
B
C
=
9:DE
#FF

ﬀ
G
H
IJ
HK L
MM
N
O
P
Q

$
R




ﬀﬀ

ﬀ
R
ﬂ
S
"
 
TU
	
V
O
W
Fig. 1. Framework
HOMME1 employs four different types of web data, search
logs, web directory data, WorNet, and social bookmarks, to
map the concepts. The architecture is illustrated in Figure 1.
In the demonstration system, the search logs are obtained from
MSN Search with 15 million queries and the associated list of
clicked URLs sampled over one month; the directory data are
manually labeled categories assigned to websites and extracted
from the Open Directory Project (ODP) [5]; a complete list
of nouns is crawled from WordNet [6] for support; and, the
social bookmarks are a list of top manually assigned tags to
each URL from Delicious.com [7].
During the offline process, these four data sources are
integrated and mapped together by the Resource Integrator.
The integrator first filters non-English characters, punctuations,
and white spaces. Subsequently, the categories and tags are
automatically obtained through a custom built crawler and
mapped onto the click logs. Finally, this module maps each
clicked URL to its ODP category, ODP title, and related
Delicious tags to assemble a huge consolidated dataset, which
is the input data for the follow-up processes.
Both Term Extractor and Term Mapper utilize the previ-
ously consolidated data matrix as input to collect the related
data. For each given keyword k, The Term Extractor looks
through the whole matrix for the other terms whose related
details contain k and generates the corresponding term list as
the output. The Term Mapper then employs the output list
to build a Query-Tag Matrix (or features matrix). First, terms
will be classified according to the categories in ODP. Second,
the matrix will be built by counting the frequency of the tags
(features) assigned to each query.
Once the term list and Query-Tag Matrix are ready, two im-
portant modules Relationship Finder and Concept Clustering,
which are described later, are activated.
1Homme means the human being in French, and we use this name for our
system which contains human intelligence.
A. Relationship Finder
The Relationship Finder seeks to find important semantic
relationships between terms, such as “ Southwest is-A air-
line company” or “ae has-Meaning American eagle and has-
Website www.ae.com”. Because of the variety of relationships
between the terms, different Relationship Finders are designed.
Each finder is dedicated to a specific type of relationship. In
HOMME, seven kinds of relationship finders, i.e., Is-A, Has-
Subclass, Has-Data-About, Has-Meaning, Is-Equal-To, Has-
Website, and Specialization/Generalization, are introduced.
Figure 2 describes the detailed data used in these relationship
finders.
 


 


	
 	







	
 

ﬀ
ﬁ


ﬂ
ﬃ 
ﬂ 
ﬃ
!

ﬁ

"



ﬂ
ﬂﬁ

"



ﬂ
#$%
&
'(
)
%*
) +,
-
,
.
/

01
	
2
3ﬂ


4
3




56



578
3

9:;

<9

/


5=
ﬂ

ﬂ


5>

8


57


5?
3
8
!ﬁ

Fig. 2. Relationship Finder
• Is-A Relationship Finder: This finder focuses on ana-
lyzing the patterns of the queries and assigned titles of
the clicked URL by ODP. This finder extracts all the
nouns and the corresponding noun modifiers from the
queries and assigned titles based on the noun lists of
WordNet. If the modifier and the noun appear together
frequently or the noun has the related domain name, the
finder constructs one “is-A” relationship between the pair
of nouns together and the noun modifier alone.
• Has-Subclass Relationship Finder: This finder empha-
sizes on examining the match between the query and the
ODP category assigned to the clicked URL. Once the
match frequently exists, one “has-subclass” relationship
is then established (e.g. “travel” is super class of “travel
agents”).
• Has-Data-About Relationship Finder: This finder
finds the match between the queries and the
resource path of the clicked URLs. Once there
is a match, the finder constructs one “has-data-
about” relationship between the domain name and
the submitted queries. For instance, from the URL
http://www.mtv.com/music/artist/bowlingforsoupartist.htm
clicked after querying “bowling for soup”, we can
determine that “mtv” has data about “bowling for soup”.
Fig. 4. Categories for query “Cinco de mayo”
Fig. 5. Mind Map for the query “Toyota”
user can find more queries related to recipes, holidays, food,
etc. For the same query, when clicking the Society category
he can find related queries such as “how is cinco de mayo
celebrated in mexico”. Going deeper under Society, queries
about history, social studies, or even the war around 1950 can
be found by the user.
In our second scenario, the user types “toyota” as the search
keyword. The Ontology Builder immediately provides the
mind map for “toyota” (as illustrated at Figure 5). From the
map, the user can learn that Toyota not only sells normal cars
but forklifts as well. The official company that sells forklifts is
called “Toyota material Handling U.S.A. Inc.”, whose official
website is www.toyotaforklift.com. Another official website of
Toyota is www.toyota.com which contains information about
“Solara”, “Yaris”, “Prius”etc. (which are the car brands from
Toyota). Furthermore, the user can also find that Toyota offers
financial services promising to close the gap between the user’s
transportation needs and her cash flow. She can also find
several kinds of services provided online.
If the user wants to check data related to Toyota across
Fig. 6. Categories for query “Toyota”
different categories, she can employ the Concept Finder to
explore the concept spaces as shown in Figure 6. She can also
find out that Toyota is involved in sports. There is a “Houston
Toyota Center”, which is an indoor arena located in Texas.
Apparently, this arena is sponsored by Toyota. Different sports
games can also be found in that particular cluster, such as “Pac
10 Conference” and “Indiana Rivals”.
As shown in this demo, HOMME provides the user with
a graphical tool able to facilitate the search experience and
enrich him or her with previously unknown knowledge. Even
with a very small dataset, HOMME was able to provide in-
tuitive and relevant information. Moreover, HOMME demon-
strates the feasibility of future research on Web Information
Integration by taking advantage of the Ontological knowledge
provided by the Ontology Builder.
REFERENCES
[1] R. A. Baeza-Yates, C. A. Hurtado, and M. Mendoza, “Query
recommendation using query logs in search engines.” in EDBT
Workshops, ser. Lecture Notes in Computer Science, W. Lindner,
M. Mesiti, C. Trker, Y. Tzitzikas, and A. Vakali, Eds., vol. 3268.
Springer, 2004, pp. 588–596. [Online]. Available: http://dblp.uni-
trier.de/db/conf/edbtw/edbtw2004.html
[2] R. Baeza-Yates and A. Tiberi, “Extracting semantic relations from
query logs,” in KDD ’07: Proceedings of the 13th ACM SIGKDD
international conference on Knowledge discovery and data mining.
New York, NY, USA: ACM, 2007, pp. 76–85. [Online]. Available:
http://dx.doi.org/10.1145/1281192.1281204
[3] S. Sekine and H. Suzuki, “Acquiring ontological knowledge from query
logs.” in WWW, C. L. Williamson, M. E. Zurko, P. F. Patel-Schneider,
and P. J. Shenoy, Eds. ACM, 2007, pp. 1223–1224. [Online]. Available:
http://dblp.uni-trier.de/db/conf/www/www2007.html
[4] (2010) Google wonder wheel. [Online]. Available:
http://www.googlewonderwheel.com/
[5] (2010) Open directory project. [Online]. Available: http://www.dmoz.org
[6] G. A. Miller, “Wordnet: A lexical database for english,” Communications
of the ACM, vol. 38, pp. 39–41, 1995.
[7] (2010) Del.icio.us. [Online]. Available: http://delicious.com/
to as crowd wisdom since it collects session data from all
users. In this work, we propose a Pattern Recognition Query
(PRQs) method, which aims to integrate both sets of wis-
dom to achieve a query suggestion method. First, we for-
mally define session and search log as follows:
Definition 2.1. : A user session s of user u is a set of
records {〈 ipu, q1, t1, 〉,〈 ipu, q2, t2, 〉,...,〈 ipu, qn, tn, 〉},
where ti+1 - ti ¡ Θ ∀ i = 1 to n-1. ipiu, qi, ti, andΘ are IP
address of the machine which submits the query, the submit-
ted query, the timestamp when the query is submitted, and
a defined threshold value, respectively.
To address the queries in the session, we further denote
the set of consecutive queries submitted in this session as
Qs, i.e., Qs = {q1, q2, ..., qn}.
Definition 2.2. : A search log L consists of the session data
s of all search engine users, i.e., L={s1,s2,...,sn}.
Given the search log L and the session of the current
user, our goal is to generate a set of refined queries as sug-
gestions to accelerate the user’s search process to retrieve
desired information. The proposed system can be divided
into two categories: offline and online processing, as illus-
trated in Figure 1.
&RRFFXUUHQFH
4XHU\([WUDFWLRQ
6HDUFK/RJ
,QVHUWLRQ
([WUDFWLRQ
&RRFFXUUHQFH
4XHU\,QGH[
,QVHUWLRQ
,QGH[
2IIOLQH
2QOLQH
LQSXWVHVVLRQ
$JJUHJDWH
FDQGLGDWHV	UHSUHVHQWDWLYHV
)HWFKFDQGLGDWHV
IURPHDFKLQGH[
RXWSXWVXJJHVWLRQV
6HVVLRQ5HS
6HOHFWLRQ 6XJJHVWLRQ
*HQHUDWLRQ
,QWHQW
&ODVVLILFDWLRQ
Figure 1. System framework
In offline processing, search log data is given as input.
Offline processing aims to integrate clues to user intent and
the search pattern from the session by two parallel pro-
cesses: insertion extraction and co-occurrence query ex-
traction. The details of offline processing are described in
Section 3.
In online processing, the session of the current user
is given as input. Online processing first performs two
preprocesses- intent classification and session represen-
tative selection- to extract essential information. The
“concepts” , which can be phrases or terms contained in
the query, that best describe user intent will be exploited to
fetch candidate suggestions from the indexes built offline.
Finally, suggestion generation aggregates better candidates
and representatives as final suggestions. The details of on-
line processing is described in Section 4.
3 Offline Processing
Search logs contain past search patterns. By utilizing
these search patterns, other users with similar search intents
get needed information faster. We intend to apply crowd
wisdom in two ways: specialization and association.
Specialization. As we mentioned before, users may
consecutively reformulate their queries to find information
more closely related to their search intents. Although previ-
ous studies have investigated various reformulation patterns
in query sessions [8], we only focus on one reformulation
pattern: specialization, i.e., users specify the meaning of the
query by inserting more keywords [8]. The goal of inser-
tion extraction is to extract and reuse the insertion pattern
as candidate suggestions.
Association. Queries that frequently co-occur in the
same query session may be conceptually related. For ex-
ample, the queries “harry potter” and “joanne kathleen
rowling” can be viewed as candidate suggestions for each
other. These query pairs are extracted by the process co-
occurrence query extraction.
The insertion extraction process scans all sessions in the
search log and identifies all concepts having the added key-
words (i.e., the insertion concepts) in the follow-up queries.
For each concept C having the insertions, we build the in-
sertion index to pre-store each insertion of C as well as the
corresponding frequency of this insertion to C. The inser-
tions are then ranked according to the frequency.
The co-occurrence query extraction process is to ex-
tract useful query pairs that led to click-through behav-
iors and that also frequently appeared in the same ses-
sion. In other words, these useful query pairs (termed co-
occurrence queries afterward) can assist users to retrieve
target pages easily.
To analyze the importance of co-occurrence queries,
we first built a co-occurrence query index to collect co-
occurrence click queries for each query q i. The importance
of each co-occurrence query qj to qi is evaluated according
to Equation 1. The concept of this equation is similar to
TF-IDF that is, the importance is proportionally increased
to the frequency of the query in the session but decreased
by the frequency of the query in the search log.
26
keyword. Queries that better describe user intent can
lead to more click-through since the information re-
trieved is more related and arouses user interest.
We compute the score of each keyword k ∈ Qs based on
the following equation:
s(k) = α · fk
max fk
+ β · ok
max ok
+ γ · c.fk
max c.fk
(2)
Each feature value is normalized by dividing the maxi-
mum one in the session. α, β, and γ are weighting parame-
ters of each feature, which can be adjusted according to the
application, where α+ β + γ = 1. For fear that incomplete
concepts could lead to incorrect suggestions, we further in-
spected whether selected keywords can be combined. Given
the consecutive queries Qs and selected keywordsKs of the
session s, the process outputs the set of representative con-
cepts Cs.
The process starts by combining keywords into phrases.
Each keyword is combined with other keywords, and we
examine whether any query in Qs contains the combina-
tion. The combination that appeared in Qs will be added to
the set Combinee. After all combinations are examined, we
remove the keyword that totally depends on combinations
in Combinee (i.e. the keyword is contained in the combi-
nations every time it appears). After dependent keywords
are removed, combinations in Combinee and the remaining
keywords form the candidate concepts.
Similarly, we check whether the combinations in Com-
binee can be further combined, and we remove dependent
combinations iteratively until no combination of concepts
exists in the session. Finally, dependent concepts are re-
moved, and the remaining concepts are representative con-
cepts. These concepts will be given scores based their fre-
quency, order, and click frequency using the same rules as
keyword selection.
After the session is classified and the representative con-
cepts are selected, we retrieve candidate suggestions from
indexes built offline. For each concept C ∈ Cs, we re-
trieve the insertions applied from the insertion index as
well as their co-occurrence queries drawn from the co-
occurrence query index. The concepts apply insertions and
co-occurrence queries form the set of candidate suggestions
CSs. The system processes Cs and CSs are used to gener-
ate final suggestions at the next stage.
4.3 Suggestion Generation
In this process, we associate the current user with past
users who had similar search intents by searching for: (1)
insertions connected with representative concepts from the
insertion index, and (2) queries that co-occurred with the
representative concepts from the co-occurrence query in-
dex. The concepts, adding insertions and co-occurrence
query data, are candidate suggestions.
To determine which representative concept and candi-
dates should be included in the final suggestions, we pro-
pose a scoring mechanism to determine their importance.
First, we assign a parameter K to determine the number of
suggestions that should be presented to the user. We then
determine the relative proportion of (1) representative con-
cepts and candidates, and (2) candidates generated by dif-
ferent measures in the final suggestions based on the classi-
fied type. With K and the predefined proportion, the num-
ber of representative concepts and candidates generated by
different aspects in the final suggestions is decided.
To generate the top-K suggestions, we score each repre-
sentative concept C ∈ Cs and candidate suggestion cs ∈
CSs to decide which one is more important. Since rep-
resentative concepts were already scored in the previous
stage, we score the candidates at this stage based on two
aspects:
Trigger score(Ts). Each candidate is “triggered” by cer-
tain information embedded in the session. The “trigger”
may be the representative concepts. Ts indicates how im-
portant the candidate cs is to its trigger tcs. The trigger
score of each cs is computed by Equation 3. Note that the
weight of cs is normalized by dividing the maximum weight
among all candidates retrieved by tcs.
Ts(cs) = wcs/maxwtcs (3)
Context score(ConS). Since the approach is context-
aware, we consider the relevance between the candidates
and all representative concepts. The relevance is measured
by whether the candidate co-occurred with the representa-
tive concepts in past sessions. The relevance between cs
and Ci is measured by Equation 4, where cs ∈ CS and
Ci ∈ C.
Rel(cs, Ci) =
{
TIcs
maxTIlCi
if cs ∈ lCi
0 otherwise
(4)
The context score of each candidate cs is measured by
Equation 5, where Rel(cs, Ci) represents average relevance
score among all lists that contain cs, and olcs represents
number of lists that cs appears.
Rel(cs, Ci) =
1
olcs
×
∑
Rel(cs, Ci), ∀cs ∈ lCi
Cons(cs) = 0.5× olcs
max olcsi
+ 0.5×Rel(cs, Ci) (5)
28
gated the precision and recall ratio under different settings
of the parameter K . K was set to 10, 20, 50, and all (i.e, all
candidate suggestions will be returned to the current user).
The precision and recall of PRQs dramatically exceeded
those of other approaches under all settings. We can observe
that the approach with higher coverage reached a better per-
formance. The above comparisons demonstrate that PRQs
outperforms existing query suggestion approaches in differ-
ent ways. We compared some differences between PRQs
and the comparison baselines to figure out potential reasons
for this increased performance.
TSM generates candidate suggestions according to the
current user query. Relevance with the search context is
considered when ranking these candidates. This mechanism
may work for sessions with focus intent since all queries in
the session are explicitly related. For sessions with general
or changing intents, however, the performance of TSM may
decrease due to the neglect of search context when selecting
candidates.
CACB addresses the order of consecutive queries. It
transforms session data into concept sequences from search
logs in order to generate suggestions for the current user
session. When transforming consecutive queries into a con-
cept sequence, the queries are mapped to the concept sepa-
rately. Therefore, users with similar search intents who sub-
mit queries in different orders may be considered to have
different search intents that cannot be associated. Cao et
al. implemented CACB with a much larger-scale query log.
If the source query log is very large, the mined concept
sequences may be sufficient to handle the above problem.
Otherwise, the requirement that users with similar search
intents must submit queries in a similar order may be too
strict and lead to a decrease in performance.
This points out that we could apply search context in a
more flexible manner. Instead of considering consecutive
queries separately, we could view users’ search contexts
from a more integrated perspective. This is also the motiva-
tion for summarizing user sessions with representative con-
cepts, one feature of PRQs. Another potential reason is that
PRQs utilizes search context more than other approaches
do. This helps when we need more clues in order to pro-
vide suggestions. The advantage of the above mechanisms
is reflected by the high coverage of PRQs.
6 CONCLUSION AND FUTURE WORK
In this paper, we presented a novel query suggestion
approach - PRQs(Pattern Recognition Query suggestion),
which exploit search context and query logs to help users
search for required information more efficiently. PRQs is
“context-aware” in that it integrates the whole search con-
text in a two-fold manner: consecutive queries and refor-
mulation patterns. Moreover, we summarize user search
context by selecting the representative concepts that best
describe user intents, and we provide customized sugges-
tions according to users’ search patterns. The experimental
results show that PRQs outperforms previous context-aware
query suggestion methods.
References
[1] R. A. Baeza-Yates, C. A. Hurtado, and M. Mendoza.
Query recommendation using query logs in search en-
gines. In EDBT Workshops, pages 588–596, 2004.
[2] D. Beeferman and A. Berger. Agglomerative clustering
of a search engine query log. In KDD ’00: Proceedings
of the 6th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 407–416,
New York, NY, USA, 2000. ACM.
[3] H. Cao, D. Jiang, J. Pei, Q. He, Z. Liao, E. Chen, and
H. Li. Context-aware query suggestion by mining click-
through and session data. In KDD ’08: Proceeding
of the 14th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 875–883,
New York, NY, USA, 2008. ACM.
[4] J. Dean and S. Ghemawat. Mapreduce: Simplified data
processing on large clusters. In OSDI ’04: Proceedings
of the 6th Symposium on Operating Systems Design and
Implementation, pages 137–150, 2004.
[5] B. M. Fonseca, P. Golgher, B. Poˆssas, B. Ribeiro-Neto,
and N. Ziviani. Concept-based interactive query expan-
sion. In Proceedings of the 14th ACM international
conference on Information and knowledge manage-
ment, pages 696–703, New York, USA, 2005. ACM.
[6] C.-K. Huang, L.-F. Chien, and Y.-J. Oyang. Relevant
term suggestion in interactive web search based on con-
textual information in query session logs. Journal of the
American Society for Information Science and Technol-
ogy, 54(7):638–649, 2003.
[7] R. Jones, B. Rey, O. Madani, and W. Greiner. Generat-
ing query substitutions. In WWW ’06: Proceedings of
the 15th international conference on World Wide Web,
pages 387–396, New York, NY, USA, 2006. ACM.
[8] S. Y. Rieh and H. I. Xie. Analysis of multiple query re-
formulations on the web: The interactive information
retrieval context. Inf. Process. Manage., 42(3):751–
768, 2006.
[9] Z. Zhang and O. Nasraoui. Mining search engine query
logs for query recommendation. In WWW ’06: Pro-
ceedings of the 15th international conference on World
Wide Web, pages 1039–1040, New York, NY, USA,
2006. ACM.
30
此圖是大會第一天的Keynote speech中其中一半的人數，因為會場太大了無法同時拍到
所有的人，這兩天我們聽了很多場Sessions，其中一個最震撼的是 
Title: Towards The Web of Concepts: Extracting Concepts from Large Datasets 
Presenters: 
Aditya Parameswaran, Stanford University, United States of America 
Hector Garcia-Molina, Stanford University, United States of America 
Anand Rajaraman, Kosmix Corporation, United States of America 
 
 
Hector Garcia-Molina是美國目前最紅的Database Researcher,因為他旗下的學生就是在
唸書期間創立Google然後到現在一直都領導趨勢，所以Hector和學生們的paper發表在
VLDB一級期刊並不足為奇，讓我們震撼的是因為該篇paper的內容我們實驗室在兩年
前就完成並嘗試投遞到幾個一級期刊，都被回絶，原因都說沒有創新，技巧不足為奇，
所以這兩年本研究室又研發好幾個不同的技術，所以我們這次就特別來學習為什麼同
樣的內容被Hector包裝後可以進入VLDB 
 
9/15下午有一場Panel是在講解Cloud Computing, 
Title: Cloud Databases: What's New?  
Participants:  
Daniel Abadi (Yale Univ.),  
Michael Carey (Univ. of California, Irvine),  
Surajit Chaudhuri (Microsoft Research),  
Hector Garcia-Molina (Stanford Univ.),  
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
