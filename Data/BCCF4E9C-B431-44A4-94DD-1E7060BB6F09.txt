 2 
Abstract 
This project proposed a three-year 
research plan on context aware services 
enabling spontaneous speech recognition for 
care application and education. This 
research plan is composed of word fragment 
detection, accented speech recognition and 
multi-language speech recognition.  
In the first, we focus on developing the 
approach for the speech recognition of word 
fragment in spontaneous speech. The word 
lattice based conditional random fields, 
combined with acoustic and language 
features, are employed to detect the word 
fragments and recognize corresponding 
speech. the acoustic features of the word 
consists of syllable, sub-syllable and state 
information. The language features are 
formed with the building blocks: words, 
chunks and sentences. The optimal path 
within word lattice that is modeled as 
conditional random fields is the result of 
speech recognition. 
Accented speech recognition is the 
main research topic of the second year. The 
speech adaptive technologies such GBT 
trees are applied to recognize the accented 
speech recently. However, to deal with the 
accented speech with large pronunciation 
variance is difficult. It is hard to achieve the 
performance to fit the desired result by 
adaptive for application by the adaptive 
technologies. We proposed an investment in 
accented speech recognition based on 
personal acoustic inventory, lexicon and 
language model. The response of dialogue 
system can provide confirmation about the 
acoustic results with lower confidence to 
ensure the accented patterns. By updating 
the personal acoustic inventory, lexicon and 
language model, the accented speech 
recognition obtained the performance using 
incremental strategies by the 
transformation-cased error-driven learning 
(TBL) for care application and education.  
Finally, we plan to develop a 
multi-language speech recognition that is 
able to recognize the Mandarin, English and 
Taiwanese. The International Phonetic 
Alphabet (IPA) is used as the standard 
representation of phoneme set defined in 
Mandarin, English and Taiwanese. 
Considering the co-articulation, contextual 
tri-phone models in hyperspace analog to 
language (HAL) are applied to analyze the 
acoustic likelihood. Combined with 
tree-copy search based on the 
multi-language lexicon, the Hidden Markov 
Model (HMM) based speech recognition 
engine is built for multiple languages. 
This project developed the service 
enabling speech recognition technologies for 
care. Co-operation with speaker 
identification and dialogue system, the 
models to deal with disfluency, accented 
pronunciation variance and multi-language 
recognition in spontaneous speech has been 
invested during three years. By the 
realization of this research project, the 
improvement of spontaneous speech 
recognition was obtained. 
 
 4 
段(Word fragment)來討論研究現況。在口語
辨識技術方面，國外的部份相關的研究在
國外方面，ISCI and SRI International 利用
語言模型以及韻律模型偵測不流暢語流
[5]、結合基於詞和詞性的語言模型解決 
重複(Repetition) [6]和使用隱藏事件語言模
型直接對不流暢語流進行統計式分析以及
利用不流暢語流語言模型(DF-gram)來預
測是否出現不流暢現象[7]以及使用最大熵
模型以及隱藏馬可夫模型修正不流暢語流
[8]。John Bear 應用不同知識來源來針對不
流暢語流進行偵測及修正 [9] 、 Anand 
Venkataraman 使用人工訂定之規則來判斷
不流暢語流[10]、Matthias Honal 利用噪音
頻道(Noisy Channel)的觀念，運用不同特徵
訓練出統計模型並以線性組合來修正之
[11]。Charniak and Johnson 建立ㄧ基於詞
性特徵之分類器來預測可被刪除區域
[12]。Nakatani and Hirschberg 利用聲學、
音韻學以及語言特徵建立ㄧ決策樹模型來
偵測重複[13]。Snover 等人以及 Joungbum 
等人利用轉換學習 (Transformation-Based 
Learning)偵測不流暢語流[14][15]。Furui 
致力於口語化語音辨識之研究[16]。而國內
部分，中研院曾淑娟博士及鄭秋豫博士投
入相當之人力進行口述語言語料之收集、
分析[17-19]。而交大電信系也針對口語之
語音辨認進行研究[20]。台灣大學則對於口
語中的語句中斷點利用統計的方法進行偵
測[17,11]，而成大方面先前則對所謂鼻音
化現象填充詞語及遲滯現象進行研究，目
前則著手對於 Edit Disfluency 進行分析，
已有部分成果目前正預計投入大量人力進
行深入的研究[22-24]。本計畫研究發生於
口術語言中之部份詞語(Sub-word)或詞語
片段(Word fragment)現象。 
關於詞語片段(Word Fragment)，Bear 等人
以及[25] Nakatani 和 Hirschberg [26] 發
現大約 60-74% 的不流暢語流(disfluencies)
會包含詞語片段(Word fragment)現象，所以
可以有效偵測詞語片段(Word fragment)便
可以有效提供不流暢語流處理的成效，更
可以提供口語的語音辨識結果有效的改
善。最近關於詞語片段的研究，在美國史
丹佛大學的 Dan Jurafsky 所領導的團隊，
利用支持向量機(SVM)和決策樹(Decision 
Tree)作比較，結合了聲韻特徵 (Prosodic 
Featear)、聲音品質(Voice qulity)以及詞典
特徵(Lexicon feature)來偵測電話對話中國
語的詞語片段(Word fragment)現象[27]。台
灣大學的陳信希教授早在 1996 年，便注意
到口述語言處理在語音的應用上十分重
要，並且著手分析 Repair 的聲學特性與部
分 詞 (subword) 在 repair 上 之 特 性
[28][29]。而李琳山教授在關於中斷點的偵
測 的 研 究 上 也 論 及 詞 語 片 段 (Word 
fragment)與不流暢語流之相關性極高[30]。 
腔 調 化 語 音 辨 認 (Accented Speech 
Recognition) 關於腔調(Accent)的問題，在
語音辨認中已經是一個存在已久之現象。
在過去可視為語者調適之主題之ㄧ，然而
由於具腔調之語音辨識由於跟標準樣本之
距離頗大且變異性亦不同，有部分已經不
是單純利用傳統語者/語音調適所能夠解
決，尤其針對因母語影響之語音發音而
言，本計畫考慮 Context aware 之應用，配
合總計劃中關於對話系統，建立一可具體
應用於長期照護之具腔調之語音辨認技
術。 
關於腔調化語音的相關研究在最近國內外
也是一個重點，最著名的專案莫過於美國
卡 內 基 美 濃 大 學 的 Let’s Go 專 案
 6 
(phone)[49]或音節(syllable)[50]來處理因腔
調影響而導致聲學模型錯誤的問題，也是
這方面研究的重點。史丹佛大學觀察四種
不同腔調的語音語料庫，利用 Genre 
Variation 針對腔調化語音的音高週期作預
測[51][52]。同樣地，希臘的 Nikos Fakotakis 
博士也利用貝式學習(Bayesian Learning)理
論來偵測音高的變化[53]。美國科羅拉多大
學的口述語言研究中心 (The Center for 
Spoken Language Research) 利 用 Voice 
Onset time 來針對部分的子音作偵測，並
利用 Tear Energy Operator(TEO)來偵測具
有腔調化的英語[54]。也曾利用 Trajectory 
Models 來對於各種的腔調化的英語作分
類[55]，並在 2003 針對西班牙母語語者之
腔調化英語語音辨識提出一些研究的心得
[56] 。 北 京 的 NOKIA 研 究 中 心 與
TOSHIBA 研究中心分別在腔調化語音辨
認上成立專案小組，進行手機通訊上與行
動式車上語音介面的研發，足見此一技 
術對於口語化語音辨識乃是一個不可忽
略，極具產業價值的基礎研究[57][58]。長
庚大學呂仁園等人則分析國語與台語之發
音變異，提供同時可以辨認國、台語之雙
語語音辨識器發展重要的參考[59]。成大電
機系王駿發教授與資訊系的吳宗憲教授則
就台灣地區語者在英文發音上的變異進行
分析研究。 
多語語音辨認技術(Multi-Language Speech 
Recognition) 由於台灣地區國際化的程度
越來越高，且在台灣地區既有的多種語
言，使得多語辨識技術在台灣日益顯得重
要。尤其在長期照護中有許多銀髮族的語
者，慣用的多為其習慣母語。如何能將多
語環境中不得不面對的語音辨認問題作一
適切的處理，遂成為本計劃研究的一個極
重要的特點。本計畫於第三年進行多語辨
認模型之研究，以總計劃成功大學吳宗憲
教授所領導的語音辨認小組，目前已經就
國語與英語建立一雙語辨識系統之雛形架
構，並配合佘永吉博士所主持之子計畫所
蒐集之台語語料，以建立可辨認中、英、、
台等多語之語音辨認。在過去幾年間，多
語自動語音辨識作法上可以歸納成三大
類。第一類作法：為在前端處理先利用一
個語言辨認 (language identification, LID)
方法[60][61]，判斷輸入語音訊號屬於哪種
語言，再分別透過單一語言的自動語音辨
識器進行轉譯。對於多語語音辨識演算
法，前端語言辨認的成效決定了多語語音
辨識的好壞，有效的語言辨認方法將使得
多語語音辨識的正確率達到和個別單一語
言的獨立語音辨識相當之效果。因此，利
用先前的語言辨認方法，缺點在於辨識效
果會受到 LID 表現影響。 
第二類作法：利用個別單一語言的語音辨
識器分別產生辨識結果，再經由後端處理
選擇最大似然的方法(Maximum Likelihood, 
ML)，決定最佳的多語辨識序列。作法上
類似對語音辨識序列做驗證(Verification)
之處理 [62]；多語語音辨識的表現取決於
後端最佳序列選擇之效果。利用選擇最大
似然的方法缺點在於，多語辨識的效果會
受到 ML 方法的限制，且辨識的多語句型
需要另外考慮，切割出語句內不同語言的
段落。 
第三類作法：藉由定義多語語音辨識單元
集[63]，合併個別單一語言之音素模型，來
進行多語語音辨識。本計劃基於此方法，
探討如何定義出有效的多語語音辨識單元
模型。在多語音素模型之建立可以歸納為
三種方式。首先，我們可以直接合併個別
 8 
Conditional Random Fields)來描述。 
而關於文字階段的處理，也就是語言處理
的構面，則可以以語言特性及其相依性
(Features and dependences of language)則可
以透過詞階層(Word level)取其相關性，憑
藉其相關性可以引入語言處理的構面，以
不定長度特徵之隨件隨機域來協助偵測並
辨認”不完全詞”（Word Fragment）。在語
者識別技術上的整合，可以將語者的 ID 以
及應用的情境有所限制，藉以提升語音辨
認之效能，使語音辨認能夠真正落實與實
際生活中。本計畫於第一年之研究進程以
詞(word)為基礎，利用建隨機域有效整合語
音聲學與語言學上之特徵。 
條 件 隨 機 域 唯 一 無 像 圖 論 模 型
(undirectioned graphical model)，其中 X 為
一被觀測並標示的隨機變數，而 Y 為相對
應之隨機變數。所有 Y 的組成成分 Yi 被
標示的有限狀態的區間都被假設為 y。而條 
件隨機域 CRF 則建構出一個條件機率模型
P(Y | X )在給定一個具有觀測(Observations)
與標示(Labels)的特徵集(Feature set)，並且
為一全域(Global)觀測之條件機率模型並
且可用於整合異質的特徵。Lafferty 在 2001 
年提出的線性基本模型[70]，如下式所表
示： 
(1) 
其中 y|e與 y|v 分別表示與邊 e 跟節點 v 相
關的組成 y，  kf  與  kg  分別代表點的轉
移特徵 (Transition features) 與觀測特徵
(Observation features)。當然了，以圖論的
觀念點的轉移特徵也意味著邊的觀測特
徵，只是在本計劃所提之模型轉移除了兩
相鄰點外也包含聯通成分中的間接相連通
的兩點。Z (x)為一正規化因子也是一個分
割函數(Partition function)，其標準是可以寫
成下式： 
 
(2) 
而語音辨認的結果通常是在聲學模型輸出
後的詞絡中的一條路徑，要解決語音辨認
尤其是具有部份詞與之語音辨認結果則必
須改寫原本線型的條件隨機域，因為在辨
認的過程中假設以音節個數為狀態數，並
以音節絡產生相對應的詞，再以詞搭配音
節訊息則可以將本計畫你實現之觀念表現
下圖： 
 
圖二、以詞絡為基礎之調件隨機域 
 
其中若語音辨認出來之結果，最大音節個
數為 N 的情況下，初始狀態為 T0 而終止狀
態為 TN+1。在聲學模型所產生的最大音節
個數為 N 的情況下，分別以一個狀態來表
示一個音節，所以可能音節序列則被包含
於狀態 T1 到 TN 。第一個第 p 個狀態中的
第 i 個可能音節則可以表示為 yp,i，考慮到
可能有部分詞的插入，則在每一個中間狀
態如圖中 Tp 到 p Tp+q-1 中加入空節點
(NULL)如 yp,0，藉以先跳過(skip)該音節，
待信心度(confidence)較高之音節確定後，
再行判斷。而根據這些音節狀態，往上建
 10 
結構，此處邊可以有三類分別是父子邊 
E 
pc、子父邊 Ecp 與兄弟邊 Ess。而點的部份
可以以 V 表示之。則可以將式子(1)改寫為
以下式子(8) 
 
(8) 
在給定訓練資料的情況下，則其對數概似
度(log-likelihood)可以描述如下： 
       (9) 
其中 p (x, y)為訓練過程中由資料計算所得
的實際機率分布(Empirical distribution)，Θ 
≡  {λ1,λ2 ,...;μ1 ,μ2 ,...}。引用梯度函數
(Gradient function)。梯度向量中的每一個元
素的乃是由對數概似度對每一個參數做偏
微分。 
    (10) 
其中  ,p x yE 乃是相對於實際資料分布的期望
值，可以由資料的結果計算而得，而
   | , kp y xE f 表示條件式機率模型所估得之期
望值。對於每一個觀測特徵函數 fk 以及轉
移特徵函數 gk 分別表示為式子(11)與式子
(12)。 
 
(11) 
 
(12) 
運用 Forward-Backward 的估算方式，則
Forward 向量  i x 可以定義如下： 
      (13) 
並以此為初始條件，依以下式子(14)遞迴地
計算每一個  i x 如下： 
             (14) 
同理，Backward 向量  i x 可以定義如以
下式子(15)與式子(16)。 
     (15) 
            (16) 
接下來，便可以計算在給定觀測值 x 時，
狀態序列中第 i 個狀態 Ti 的條件機率為： 
          (17) 
所以在某個狀態轉移的 y|e的條件機率便可
以寫成： 
 
(18) 
其中  1, |i ip T T x 可以以下面式子(19)表示
之。 
 
(19) 
3.2.2 以 GTB 決策樹為本之腔調化語音音
長模型 
本計畫的系統架構圖，如圖一所示，主要
可分成訓練模型和語音辨識兩部分。 
 
 12 
值，如下式(23)所示： 
  
2
1
arg min ,
N
m iim
a i
a y h x a

   (23) 
其中 imy 是梯度值表示成式(24)。 
  
 
   1
,
i m
i i
im
i
F x F x
y F x
y
F x

 
   
  
 (24) 
代入由損失函數 Ψ（y, F（x））可得到式
(25)。 
 1i m iimy y F x     (25) 
當第m棵迴歸樹所使用參數αm後可得到葉
節點 Lm，所以迴歸樹可以表示成式(26)。 
    1
1
, 1
Lm
Lm
lm lmlml
l
h x R y x R


           (26) 
Rlm 是表示第 m 棵迴歸樹中第 l 個葉節點所
分離的區域。l（‧）是布林函數，假如條
件是成立的就輸出為 1。
lm
y 是一個常數，
定義成在分屬在第 m 棵迴歸樹中第 l 個葉
節點的訓練資料之平均值。由於在迴歸樹
中
lm
y 是常數，所以權重值 βm可以直接利用
線性收尋的損失函式評估出來。因此我們
可以得到一個新的累加函式如下式(27)： 
     1
1
1
Lm
m m lm lm
l
F x F x v x R

    (27) 
利用上述的方法，將 21 個聲母與 37 個韻
母透過 GTB 演算法共訓練出 58 組迴歸樹
群，並把全部的迴歸樹群整合起來成為音
長模型，讓辨識結果中音素經過音長模型
處理後，根據音素的前後文關係和音素特
徵，可以得到最適合音長高斯分佈，並根
據經驗法則來找出插入錯誤和刪除錯誤的
分佈區域。如果音長時間是分佈插入錯誤
區域內，此時會去計算前一個音素跟後一
個音素之高斯分佈位置，並選擇一個較適
合音長時間合併，之後在用新的音節去做
再辨識，可以減少插入錯誤的情況；如果
是分佈在刪除錯誤區域，把音節切割成兩
部分，去做再辨識，將根據所得到的結果
作判斷是否合理，不合理的話就保持之前
的辨識結果。 
在建立分類與回歸樹之前，將 Baseform 跟
Surface form 做匹配是重要的步驟。 匹配
通 常 是 用 動 態 規 劃 （ Dynamic 
Programming）來處理，以編輯距離（Edit 
Distance ） 來 當 作 成 本 函 數 （ Cost 
Function），取最小成本（Cost）之路徑做
為Baseform跟Surface form之間對應關係。 
但是一般以次音節為單位的動態規劃配置
（Dynamic Programming Alignment）中的
編輯距離是不足以當作成本函數，可能會
導致錯誤對應關係。以―國立嘉義大學‖為
例子，如下表一所示，其中 Baseform 代表
正確發音，Surface form 代表辨識結果。  
 
表一、 Baseform 與 Surface form 
Baseform ㄍㄨㄛ  ㄌㄧ  ㄐㄧㄚ  ㄧ  ㄉㄚ  ㄒㄩㄝ 
Suface form ㄍㄨㄛ    ㄩ      ㄗㄚ    ㄧ  ㄉㄚ  ㄒㄩㄝ 
以子音節為單位做一對一匹配，則
Baseform 與 Surface form 可能的對應關係
如表二所示。雖然這兩組對應關係的成本
相同，但第二組對應關係中的ㄌ→ㄩ和ㄧ
→ㄗ都是很明顯的錯誤對應關係，所以第
二組對應關係是錯的。 
 
表二、 對應關係表 
Baseform 
Surface form 
ㄍ ㄨㄛ ㄌ ㄧ ㄐ ㄧㄚ ㄧ ㄉ ㄚ ㄒ ㄩㄝ 
ㄍ ㄨㄛ      ㄩ ㄗ   ㄚ   ㄧ ㄉ ㄚ ㄒ ㄩㄝ 
Baseform 
Surface form 
ㄍ ㄨㄛ ㄌ ㄧ ㄐ ㄧㄚ ㄧ ㄉ ㄚ ㄒ ㄩㄝ 
ㄍ ㄨㄛ ㄩ ㄗ        ㄚ   ㄧ ㄉ ㄚ ㄒ ㄩㄝ 
因此我們是用音素特徵距離（Phone Feature 
Distance）來解決這個問題。首先根據音素
 14 
 
圖五、原聲母混淆矩陣 
 
圖六、音素特徵距離之聲母混淆矩陣 
 
分類與迴歸樹是一種二分法決策樹
（decision tree），經常被使用在多樣性的樣
式辨認（pattern recognition）上，利用分離
節點的問題將資料分屬到葉節點上，能提
供一種簡單方式來說明和預測該資料群的
特性。 
這裡我們建立分類與迴歸樹是用來預測
Surface form 中音素可能的發音變異，透過
yes\no 的問題將每一個音素分屬到 CART
的葉節點，其中問題集主要是有關音素之
發音特徵及附近音素之種類。建立分類與
迴歸樹的流程如圖七所示，首先利用動態
規劃匹配來找出 Baseform 與 Surface from
之間對應關係，將得對應關係透過問題集
來得到相對應的答案，並利用這些答案來
建立 CART。這裡將聲母跟韻母各建立一
棵 CART 來當作發音模組，並用來處理發
音變異，一共建立 56 棵 CART。 
  當建立完 CART 之後，將 Surface from
每一個次音節去執行個別之 CART，會根
據與上下文子音節關係，得到發音變異後
補子音素，如下圖八所示。在圖五中是用
『嘉義大學』的辨識結果『ㄗㄚ ㄧ ㄉㄚ 
ㄒㄩㄝ』為例子，其中子音節“ㄗ”中，
在執行過 CART 之後，可以得到“ㄓ”、
“ㄗ”跟“ㄐ”的後補音素，也就是說這
個子音節“ㄗ”有可能是由“ㄓ”跟 
“ㄐ”發音錯誤所造成。依照得到每個子
音節的後補音素，我們可以建立後補音素
網絡（Lattice）圖，如圖九所示。 
 
Phone Alignment
 Word:    嘉義   ㄔㄚ ㄧ
 Phone:  ㄐ       ㄔ
 Phone:  ㄧㄚ   ㄚ
 Phone:  ㄧ       ㄧ
 Word:    大學    ㄉㄚ ㄒㄧㄝ
 Phone:  ㄉ       ㄉ
 Phone:  ㄚ       ㄚ
 Phone:  ㄒ       ㄒ
 Phone:  ㄩㄝ   ㄧㄝ
Context questions 
Classification and 
regression tree 
buliding
Nasal?
Aspirated?
Y N
N
NN
Y
Y Y
R_lateral?
R_round?
A CART
 
圖七、CART 建立流程圖 
 16 
 
圖十一、HAL三連音之觀察視窗加權 
 
概念上，圖十一的列向量(raw vector)表
示音素與左邊文脈資訊的關聯；另外，圖
十一的行向量(column vector)則表示音素
與右邊文脈資訊的關連。因此每一個音素
將 由 兩 個 向 量 維 度 呈 現 ： 
 
 (29) 
考慮音素發聲受到相鄰音素的影響，以三
連音素 hl,k 為中心之空間相似度可以利用
與右邊文脈相關之向量 vl及與左邊文脈相
關之向量 vk之描述；wNl和 wNk分別表示利用
觀測視窗於 HAL 空間內統計之音素相關權
重，l和 k分別表示行與列之索引。 
在 HAL 空間中，權重之計算需考慮正規化
(normalization)因素，本論文利用在資訊
檢 索 中 相 當 重 要 之 參 數 tf(term 
frequency) 以及 idf (inverse document 
frequency) ，重新估計每個向量維度之權
重，表示如下： 
                  (30) 
其中，wi指在向量 vl或向量 vk中第 i 個維
度之權重；Ci指在所有向量中，第 i 個維
度之權重不為零的向量個數；N為向量總個
數或辨識單元個數。 
 
經過前述分析，三連音素可以在聲學空間
和語言超空間中，用向量的方式表示在空
間中的相似程度。本論文分析聲學相似度
矩陣  ,k l N NA a  和語言超空間相似度矩
陣  ,k l N NH h  ，同時考慮聲學相似度和前
後文脈發音的特性，基於前後文脈相關之
三連音素模型，合併相似之發音找出最為
精簡有效的多語音素模型定義。作法上，
參考資料融合的方法，本論文利用加法融
合的技術(sum rule)，結合兩相似度矩陣
和 H，將聲學相似度和前後文脈的音素特徵
作整合，表示如下： 
 
(31) 
其中，α是一個權重因子，負責融合聲學
相似度和前後文脈的關聯。針對相似度矩
陣 A 和 H，論文中對其數值正規劃，將聲學
和語言超空間相似度矩陣的分數結合，稱
知識融合相似度矩陣  ,k l N NS s  為一個對
稱矩陣，行 l 與列 k 均表示某一音素與其
他音素相似度之向量。為了建立有效精簡
的三連音素模型於多語語音辨識之應用，
本 論 文 利 用 向 量 量 化 (vector 
quantization, VQ)的方法，從資料分析的
角度(data-driven)，將原本三連音素自動
地依據音素相似度分析，合併多語音素定
義。向量量化為是一種非監督式的群集分
析方法，可以將分散的資料群集成有意義
的類別。三連音素在相似度矩陣分析後，
可用向量方式表示其空間座標，論文引用
在矩陣中，兩向量夾角的計算方法，因此
兩音素的相似度計算為，計算如下： 
(32) 
 18 
 
3.3.3 HAL 多語辨識實驗 
本論文使用的多語語音辨識訓練語料，台
灣腔英文(English Across Taiwan, EAT)語料
庫，其中包含英文長句,英文短句,英文單詞
及中英夾雜句等[17]。從 2004 年 5 月開始
收集，至 2005 年 1 月初步完成收集，由師
大、交大、清大、成大和台大等五所學校
參與語料之錄製收集，經工研院電通所彙
整。分別由英語系及非英語系學生錄製。
麥克風語料錄製 16KHz 取樣頻率 16bits 的
取樣點音檔，電話語料錄製 8KHz 取樣頻
率 16bits 的取樣點音檔，其中電話語料又
可細分為固定式電話(PSTN)語料及行動電
話 (GSM )語料，電話語料部份是透過
Dialogic 電話語音介面卡，錄得的 8KHz，
8Bits，Mulaw 格式的取樣點,經程式轉成
8KHz，16bits，pcm 格式的取樣點；麥克
風語料是由個人電腦及麥克風，直接從個
人電腦的音效卡錄製 16KHz，16bits 的聲
音訊號。最後將所有取樣點以 wav 格式音
檔儲存。本論文研究採用麥克風語料部
分。就單音素與三連音模型之多語辨識結
果分別表示如下表九與十所示： 
表九、單音素模型之多語辨識音素正確率 
 
表十、三連音模型之多語辨識音素正確率 
 
由實驗結果可知，合併前的三連音素模型
(Triphone sets)的多語辨識效果可達 68.07%
的正確率。利用聲學相似度矩陣群集音素
定義(ACL phone sets) ，在多語辨識效果上
可達 63.12%的正確率，而利用語言超空間
相似度矩陣群集音素定義 (HAL phone 
sets) ，在中英文多語辨識效果上可達
64.23%的正確率。進一步利用資料融合方
法於聲學及語言超空間相似度矩陣群集分
析之音素定義(FUN phone sets) ，在多語辨
識效果可以提升至 66.07%的正確率。整體
而言，採用三連音素的辨識效果比單音素
(IPA 或 MIX)定義好。又從語言分析(HAL)
效果會較聲學分析(ACL)效果來得顯著，且
利用資料融合方法結合聲學相似度及前後
文脈分析，對於多語語音辨識可以有明顯
的提升。 
3.4 結論與建議 
本計畫以居家照護與學習環境之語音相關
研究議題進行研究，以三年之研究期程分
別以條件隨機域偵測自發性口語中關於部
分詞語現象。因條件隨機域可以有效整合
異質特徵所以在本研究上可以有效整合音
韻與語言知相關特徵，是以在部分詞語之
偵測上得到可接受之結果。第二年針對腔
調化語音辨識，本計畫提出了利用音節時
間來訓練出高斯混合音長模型和分類與迴
歸樹來降低發音變異所造成的插入錯誤、
刪除錯誤與替代錯誤，從實驗結果中，我
們可以觀察到高斯混合音長模型可以減少
約 20%的插入錯誤，在分類與迴歸樹的方
面，可以大量的減少替代錯誤，並可以少
量的減少插入錯誤與刪除錯誤。關於多語
辨識乃應用聲學相似度及前後文脈分析於
多語語音辨識之有效音素定義，以 EAT 中
英文雙語語料為例。基於 IPA 標準定義之
多語單音素集，本研究考慮以發音前後文
相依三連音素模型。以此定義，我們分別
以聲學相似度及前後文脈分析，音素間相
 20 
spontaneous speech. ” Journal of the 
Acoustical Society of America, pages 
1603--1616, 1994. 
[14] Snover, M., B. Dorr, and R. Schwartz. 
―A lexically-driven algorithm for disfluency 
detection. ” In Proceedings of Human 
Language Technology Conference / North 
American Chapter of the Association for 
Computational Linguistics Annual Meeting, 
2004. 
[15] Kim, J., S. E. Schwarm, and M. 
Ostendorf,” Detecting structural metadata 
with decision trees and transformation-based 
learning. ”  Proceedings of HLT/NAACL 
2004, (2004), 137–144. 
[16] Furui, S., K. Maekawa, H. Isahara, T. 
Shinozaki and T. Ohdaira ―Toward the 
realization of spontaneous speech 
recognition – Introduction of a Japanese 
priority program and preliminary 
results –―, Proc. ICSLP2000, Beijing. 
[17] Che-Kuang Lin, Shu-Chuan Tseng, 
Lin-Shan Lee. 2005. Important and New 
Features with Analysis for Disfluency 
Interruption Point (IP) Detection in 
Spontaneous Mandarin Speech. In 
Proceedings of the ISCA Workshop on 
Disfluency in Spontaneous Speech. 
Aix-en-Provence. 
[18] Peng, Shu-hui, Chan, Marjorie K. M., 
Tseng, Chiu-yu, Huang, Tsan, Lee, Ok-joo 
and Beckman, Mary (2005). ―Towards a 
Pan-Mandarin System for Prosodic 
Transcription,” in Prosodic Typology : The 
Phonology of Intonation and Phrasing, edited 
by Jun, Sun-ah, Oxford University Press, 
230-270. 
[19] 曾淑娟、劉怡芬.現代漢語口語對話語
料庫標註系統說明, 中文詞知識庫小組.民
國九十一年一月. 
[20] 羅應順, ―自發性中文語音基本辨認系
統之建立”國立交通大學電信工程研究所
碩士論文 
[21] Che-Kuang Lin, Lin-Shan Lee 
― Improved Spontaneous Mandarin Speech 
Recognition by Disfluency Interruption Point 
(IP) Detection Using Prosodic Features― in 
Porc. of Interspeech 2005. 
[22] Chung-Hsien Wu and Chia-Hsin Hsieh, 
―Multiple Change-Point Audio Segmentation 
and Classification Using an MDL-based 
Gaussian Model,” IEEE Trans. Speech and 
Audio Processing, 2005. (SCI, EI) (NSC 
92-2213-E-006-003) 
[23] Chi-Jiun Shia, Yu-Hsien Chiu and 
Chung-Hsien Wu, ―Language boundary 
detection and identification of 
mixed-language speech based on MAP 
estimation, ”  in Proceedings of 
ICASSP2004, Montreal, Canada, 2004. 
[24] Chung-Hsien Wu and Gwo-Lang Yan, 
―Speech Act Modeling and Verification of 
Spontaneous Speech with Disfluency in a 
Spoken Dialogue System,”  IEEE Trans. 
Speech and Audio Processing, Vol.13, May 
2005. (SCI, EI) (NSC 91-2213-E-006-036) 
[25] Bear, J., Dowding, J. & Shriberg, E.E. 
―Integrating multiple knowledge sources for 
detection and correction of repairs in 
human-computer dialog.‖ Proc. ACL, 1992. 
pp. 56-63. 
[26] C. Nakatani and J. Hirschberg. ―A 
 22 
Design,”Speech Communication, 29(2-4), 
1999, pp. 99-114. 
[41] Liu, Y., and P. Fung, ―Modeling partial 
pronuncia-tion variations for spontaneous 
Mandarin speech recog-nition, ” 
International Journal of Computer Speech 
and Language, 17, 2003, pp.357-379. 
[42] P. Fung, and Y. Liu, ―Spontaneous 
Mandarin Speech Prouncition Modeling” 
in Advenced Chinese Spoken Language 
Processing, Charpter 10, 2006. pp. 227-242. 
[43] Cremelie, N., and J.-P. Martens, ―In 
search of pronunciation rules, ”  In 
Proceedings of the European Speech 
Communication Association (ESCA) 
Workshop on Modeling Pronunciation 
Variation for Acoustic Speech Recognition, 
1998, Rolduc, Kerkrade, pp.103-108. 
[44] Kessens, J.M., H. Strik, and C. 
Cucchiarini, ―Modeling pronunciation 
variation for ASR: Comparing criteria for 
rule selection, ”  In Proceedings of the 
Workshop on Pronunciation Modeling and 
Lexicon Adaptation, 2002, Estes Park, USA, 
pp. 18-23. 
[45] Yuan Jia1, Ziyu Xiong, Aijun Li, 
―Phonetic and Phonological Analysis of 
Focal Accents of Disyllabic Words in 
Standard Chinese ”  in Proceedings of 
ISCSLP 2006, VOL. 1, pp. 55-66. 
[46] Timothy J. Hazen, I. Lee Hetherington, 
Han Shu, and Karen Livescu, ”
Pronouciation Modeling using a Finite-State 
Transducer Repersentation. ”  In the 
Proceedings of PMLA 2002, 
[47] H. Shu and I. L. Hetherington, ―EM 
Training of Finite-State Transducers and its 
Application to Pronunciation Modeling,” 
Proc. ICSLP, Denver, CO, September 2002. 
[48] I. L. Hetherington, ―An efficient 
implementation of phonological rules using 
finite-state transducers, ”  Proc. 
EUROSPEECH, Aalborg, Denmark, 
September 2001. 
[49] S. Greenberg. ―Speaking in shorthand - 
A syllable-centric perspective for 
understanding pronunciation variation, ” 
Speech Communication, vol. 29, pp. 159-176, 
November 1999. 
[50] M. Riley, et al, ―Stochastic 
pronunciation modelling from handlabelled 
phonetic corpora,”Speech Communication, 
vol. 29, pp. 209–224, November 1999. 
[51] Yuan, Jiahong, Jason M. Brenier, and 
Dan Jurafsky. ” Pitch Accent Prediction: 
Effects of Genre and Speaker. ”  In 
Proceedings of EUROSPEECH-05. 
[52] D. Jurafsky, et al, ―What kind of 
pronunciation variation is hard for triphones 
to model?”, Proc. ICASSP, Salt Lake City, 
UT, May 2001. 
[53] Panagiotis Zervas, Nikos Fakotakis, 
George K. Kokkinakis: Pitch Accent 
Prediction from ToBI Annotated Corpora 
Based on Bayesian Learning. TSD 2004: 
545-552 
[54] S. Das, J.H.L. Hansen, "Detection of 
Voice Onset Time (VOT) for Unvoiced Stops 
(/p/, /t/, /k/) Using the Teager Energy 
Operator (TEO) for Automatic Detection of 
Accented English", IEEE NORSIG-2004: 
Nordic Signal Processing Symposium, pp. 
 24 
distance. in Proc. ICSLP, pp. 2005-2008. 
[68] Jacob Goldberger and Hagai Aronowitz, 
2005. A Distance Measure Between GMMs 
Based on the Unsented Transform and its 
Application to Speaker Recognition. in Proc. 
of EUROSPEECH 2005,pp. 1985-1988, 
Lisbon, Portugal. 
[69] 吳宗憲 "口述對話系統中語意分析與
不流暢語音模型化之研究技術報告" 國家
科學委員 
會,2006. 
[70] J. Lafferty, A. McCallum, and F. Pereira, 
"Conditional Random Fields: Probabilistic 
Models for Segmenting and Labeling 
Sequence Data," in Proceedings of ICML-01, 
2001, pp.282-289. 
 
 
 
 
 
 
 
6術與產業銜接之經驗交流。會議後的第一天本人旋即搭乘早班飛機經香港返回台灣
完成此次學術交流活動。
二、與會心得
此次參加會議之心得主要有感於語音與語言研究攸關文化之傳承，在此次會議中雖
然對於華語文之研究比例較往年會議為多，然而繁體中文或台灣地區之語言分析略
嫌不足，在今年於暨南大學舉辦之計算語言學會會議中成功大學的盧文祥教授特別
高聲疾呼希望結合國內相關研究的學者，打破藩籬共同有好的論文產出實為其來有
自。如何能讓台灣在語音與語言之研究在國際上發光發熱，這實在是一個重要的課
題。
三、考察參觀活動(無是項活動者略)
無。
四、建議
希望國科會經費對於學術活動的支持能持續，學術研究是長期耕耘的事業，或許短
期內很難有立竿見影之效，然而卻是長久累積可收豐碩成果的。在此次會議中有許
多國外學者對於中文語音與語言相關研究十分感興趣，但總有繁體與簡體何者為主
流之疑惑，本人深覺繁簡共存的事實也正說明了語言演化之多樣性。唯政府應大力
推廣使得繁體中文在國際能有一席之地。
五、攜回資料名稱及內容
論文集光碟乙份。
六、其他
無。
96年度專題研究計畫研究成果彙整表 
計畫主持人：葉瑞峰 計畫編號：96-2221-E-415-010-MY3 
計畫名稱：情境感知語音及語言處理在照護及教育訓練環境之應用--情境感知之口語辨識技術之研究
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 5 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
