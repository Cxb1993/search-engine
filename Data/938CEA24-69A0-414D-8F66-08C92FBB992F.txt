such as transportation planning, urban and regional planning, traffic assignment, and 
even pedestrian simulation (Bernstein, 1996, 1997, 2001; Chang, 1994, 1999, 2004, 
2005; Jou, 2001,2002; Gao 2002; Lee 2001). The O-D matrix provides a planner with 
the basic information for planning a transportation system (Nanda, 1993). Traditional 
ways of acquire actual O-D information can be obtained by an extensive traffic survey, 
including license plate recognizing, automatic vehicle identification, and so on; this is 
not only a cumbersome process but also very costly. Real-time O-D information, 
which plays an important role in Intelligent Transportation System (ITS), is not 
possible to obtain by the traditional method. With real-time O-D information, 
numerous high-value ITS applications e.g., just-in-time delivery, time shortest path 
emergency vehicle routing and congestion avoidance would be feasible. Due to this 
reason, researchers have been seeking estimation methods to derive valuable O-D 
flow information from less expensive traffic data, mainly link traffic counts of 
surveillance systems. The existing studies on this subject can be roughly divided into 
two categories: 1) Assignment-Based Methods and 2) Non-Assignment-Based 
Methods (Chang, 1995).  
 The concept of assignment-based methods is mainly extended from static O-D 
estimation method. These methods based on the assumption of reliable descriptive 
model for network flow assignment. The dynamic models developed by this approach 
The remainder of this paper is organized as follows, the dynamic origin-destination 
estimation (DODE) by state space model is introduced in section 2, the parallel 
implementation of DODE is addressed in section 3, and the conclusion is outlined in 
the last section. 
 
2. Dynamic Origin-Destination Estimation 
State space model is introduced to estimate O-D flow from link traffic counts. 
The standard state space model is coupled with two parts: transition equations and 
observation equations. First, the state equation which assumed that the O-D flows at 
time t can be related to the O-D flows at time t-1 by the following autoregressive 
form, 
ntuFxx ttt ,...,3,2,1,1 =+= −     (1) 
where tx  is the state vector which is unobservable, F is a random transition matrix, 
( )Σ,0~ pt Nu  is independently and identically distributed noise term, where pN  
denotes the p-dimensional normal distribution, Σ  is the corresponding covariance 
matrix. x the state variable, is defined to be the path flow belonging to an O-D pair.  
 Next, the observation equation, 
ntvHxy ttt ,...3,2,1, =+=      (2) 
where ty  is the 1×q  observation vector which means there are q detectors on the 
 1 | 1 | 1|t t t t t tVar x y V FV F− − − ′= = + Σ⎡ ⎤⎣ ⎦     (4) 
where | 1t tµ −  denotes the expect value of tx  and | 1t tV −  denotes the variance of tx  
when 1ty −  is observed. By the above information, the forecast observation would be 
normal distribution with parameters 
 1 | 1ˆ|t t t t tE y y y Hµ− −= =⎡ ⎤⎣ ⎦       (5) 
 1 1|t t t tVar y y M HV H− − ′= = + ϒ⎡ ⎤⎣ ⎦      (6) 
The above equation (3)-(6) holds for any t. 
 As the new observation ty  become available, the parameter vector would be 
updated according to Baye’s rule, 
 ( ) ( ) ( )1| | |t t t t t tp x y p y x p x y −∝  
by using Baye’s rule and standard Bayesian theory, the posterior will be normal 
distribution with parameters 
 ( )1| | 1 | 1 | 1t t t t t t t t t tV H M y Hµ µ µ−− − −′= + −     (7) 
 1| | 1 | 1 | 1t t t t t t t t tV V V H M HV−− − −′= −      (8) 
The algorithm of Kalman Filter is illustrated as follows, 
Algorithm Kalman Filter 
 
Input: 0µ , 0V , :ty observation sequence=  
Output: Filtered µ  and V 
 Begin 
  FOR each time step of the observation sequence 
   Generate prediction of the new observation by 
    1ˆt ty H F µ −= ⋅ ⋅  
( ) ( ) ( )
( ) ( ) ( ) ( )
( ) 1 ( ) 1
( ) 1 ( ) 1 1 1
,
? ?
ij i j n i n i n j n j
n i n i n j n j i i n n j j
S F F X X F X X F
X X F X X F F F X X F F
− −
− − − −
′′ ′ ′ ′ ′ ′ ′ ′= − −
′ ′′ ′ ′ ′ ′ ′ ′ ′ ′ ′ ′= − − + − −
 
where ( ) 11 1 1 ( )iˆ n n n n iF X X X X−− − −′ ′ ′=  is the least square estimate of iF ′ , and ( )n iX  is 
the i-th column vector of nX . Consequently, 
( ) ( ) ( )1 1?i i n n j jS F A F F X X F F− −′′ ′ ′ ′ ′ ′= + − −  
where A is a p p×  matrix, { }ijA a=  with 
( ) ( )( ) 1 ( ) 1?ij n i n i n j n ja X X F X X F− −′′ ′ ′ ′ ′ ′= − −  
That means, A is proportional to the sample covariance matrix. From the general 
result in the Gaussian model, the posterior distribution of F ′  is then 
 
( ) ( )
( ) ( )
2
2
1 1
| ,
?
n
n
i i n n j j
p F X S F F
A F F X X F F
−
−
− −
′ ′ ′∝ −∞ < < ∞
′′ ′ ′ ′ ′= + − −
  (9) 
The distribution in equation (9) is a matrix-variate generalization of the t-distribution. 
The following sampler for generating F ′  and X is then proposed. 
Sampling Scheme Generate from the conditional distributions 
 a. ( )1 1| , , ~ ,t t tx F x N Fx− −Σ Σ  
 b. ( ) ( )1 2 22 1 1 1 1| , ~ , , p nn p n n n nF X k n p p A X X A FX X F− −− − − − −′ ′ ′ ′⎡ ⎤Σ +⎣ ⎦  
The above sampling scheme would be the key component of the Gibbs sampler. 
The Gibbs sampler is a Markovian updating scheme that proceeds as follows. 
Given an arbitrary starting set of values )0()0(3
)0(
2
)0(
1 ,...,,, kZZZZ , and then draw 
[ ])0()0(3)0(21)1(1 ,...,~ kZZZZZ , [ ])0()0(3)0(122 ,...,~ kZZZZZ , and so on. Each variable is 
variable forms the center part of the algorithm. In the process of generate state 
variables, Kalman filtering mechanism is added. While a simple monitoring of the 
chain (x(g)) can only expose strong non-stationarities, it is more relevant to consider 
the cumulated sums, since they need to stabilize for convergence to be achieved 
(Robert 1998).  The solution algorithm with the time-complexity of ( )2O n  is shown 
as follows, 
 
Algorithm Gibbs Sampler 
 
Input: :H path observation incidence matrix= − , :ty observation sequence=  
Output: Xˆ , Fˆ  
 Begin 
  Initialize 
   (0) : pF I= , : pIΣ = , : PIϒ =  
   { }storeX = ∅ , { }storeF = ∅  
  SET GibbsCount (g) to 0 
  WHILE not Converge 
Generate ( )( ) ~ ,gx N Vµ  
Append ( )gx  to storeX  
   CALL Kalman Filter with µ , V , and observation sequence 
   Generate )( gF ′  by 
    { })()( gijg aA = , ( ) ( ))()( 1)( )()()( 1)( )()( ˆˆ gjgngjngigngingij FXXFXXa ′′−′′′′−′= −−  
    Generate ( )pnXXWishartw gngn −′−− ,~ )( 1)( 1  
    Generate ( )pzzzzZ ′′′′= ,...,,, 321 , ( ))(,0~ gpiidk ANz  
    COMPUTE ZwF g
1
2
1
)(
−
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛ ′
⎟⎟⎠
⎞
⎜⎜⎝
⎛=′  
different random seed, each computing part will lead to a different solution chain. The 
chain in each computing part will then be gathered to check the convergence. In this 
situation, communication between computing nodes is minimum, and computing 
power can be easily increased without communication bandwidth limitation. Figure 1 
describes the parallel architecture; a similar architecture had been proposed by Li (Li, 
2002). In the pre-processor section, parameters used in our algorithm are initialized, 
so does the necessary input data. When assign jobs, these input data are sent to 
computing nodes in the cluster through TCP/IP base intranet with Message Passing 
Interface (MPI) Library. The computational procedure for the parallel process consists 
of: 
Step 1. Load input data and parameters. Initialize MPI environment. 
Step 2. Count the computing nodes exits in the cluster environment. Decide 
the count of samples should be generated by each computing nodes. 
Send data to each computing nodes. 
Step 3. Each computing nodes generate its own Xˆ  and Fˆ ′  by given input 
data for given times. And then send the result to server. 
Step 4. After all the data been sent to server, the server check the convergence 
by each Xˆ  and Fˆ ′ . If converge, the server estimate the global Xˆ  
and Fˆ ′  by averaging Xˆ  and Fˆ ′  of each computing node. 
4. Conclusions 
 This paper introduced a dynamic origin-destination estimation method by state 
space model. With Gibbs Sampler and Kalman filter, the algorithm loosens the 
assumption of known transition matrix that exists in other studies. To satisfy the 
real-time computation requirement of this algorithm, a parallel implementation on a 
PC-based Linux cluster is conducted. The parallel implementation shows a good 
result of nearly 80% of computing power remains for each CPU under a 32 CPUs 
cluster environment. That leads to the conclusion: real-time estimation of O-D 
matrices can be achieved by increasing a reasonable amount of CPUs. 
 
Acknowledgement 
This research was supported in part by the Ministry of Education of Taiwan, ROC 
under Grants EX-91-E-FA06-4-4 and in part by the National Science Council of 
Taiwan, ROC under Grants NSC-94-2218-E-009-015 respectively. 
Authors 
Yow-Jen Jou, Institute of Statistics, National Chiao-Tung University, Taiwan, 
yjjou@stat.nctu.edu.tw 
David Bernstein, College of Integrated Science and Technology, James Madison 
University, bernstdh@jmu.edu 
[7] David Bernstein, T.L. Friesz and R. Stough, “Variational Inequalities, Dynamical 
Systems and Control Theoretic Models for Predicting Time-Varying Urban 
Network Flows”, Transportation Science, Vol.30, pp.14-31, 1996. 
[8] Gang-Len Chang, Xianding Tao, “Advanced computing architecture for 
large-scale network O-D estimation”, Proceedings of the 6th 1995 Vehicle 
Navigation and Information System Conference, pp.317-327, 1995. 
[9] Gnag-Len Chang, J. Wu, “Recursive estimation of time-varying 
origin-destination flows from traffic counts in freeway corridors”, Transportation 
Research 28B, pp.141-160, 1994. 
[10] Gnag-Len Chang, X.D. Tao, “An integrated model for estimating time-varying 
network origin-destination distributions”, Transportation Research, Vol. 33A 
pp.381-399, 1999. 
[11] H. El-Rewini, T. G. Lewis, “Distributed & Paralle Computing.”, Manning, 
Greenwich, NY, 1998. 
[12] Iljoon Chang, Gang-Len Chang, ”Calibration of Intercity Trip Time Value with a 
Network Assignment Model: A Case Study for the Korean NW-SE Corridor”, 
Journal of Transportation and Statistics, Vol. 5, 2002. 
[13] Jodie Y. S. Lee, William H. K. Lam, and S. C. Wong, “Pedestrian Simulation 
Model for Hong Kong Underground Stations”, Proceeding of the IEEE 
Message-Passing Interface.”, MIT Press, Cambridge, MA, 1999. 
[21] Yow-Jen Jou, Ming-Chorng Hwang and Jia-Ming Yang, “A Traffic Simulation 
Interacted Approach for the Estimation of Dynamic Origin-Destination Matrix”, 
IEEE International Conference on Networking, Sensing and Control, Vol. 2, 
2004. 
[22] Y. Li, S.M. Sze and T.-S. Chao, “A Practical Implementation of Parallel 
Dynamic Load Balancing for Adaptive Computing in VLSI Device Simulation”, 
Engineering with Computers, Vol. 18, pp. 124-137, 2002. 
[23] Y.J. Jou, M.C. Hwang, Y.H. Wang, and C.H. Chang, “Estimation of Dynamic 
Origin-Destination by Gaussian State Space Model with Unknown Transition 
Matrix,” 2003 IEEE International Conference on Systems, Man & Cybernetics, 
5-8 Oct. 2003, Washington, D.C., USA. 
[24] Yow-Jen Jou, Ming-Chorng Hwang, “Rapid Transit System Origin-Destination 
Matrix Estimation”, 2002 World Metro Symposium & Exhibition, Taipei, April 
2002. 
[25] Yow-Jen Jou, “Rapid Transit System O/D Pattern Calculation with Statistical 
Gibbs Sampling and Kalman Techniques”, Conference on Computational Physics 
2001, 5-8 September, 2001, Germany. 
 
Figure 1. The flow chart of parallel algorithm 
Pre-processor (Server) 
Assign Jobs to Computing Nodes (Server) 
Computing 
Node Local 
Job 
Client Local 
Xˆ & Fˆ ′  
Send Local 
Xˆ & Fˆ ′  to 
server 
Computing 
Node Local 
Job 
Client Local 
Xˆ & Fˆ ′  
Send Local 
Xˆ & Fˆ ′  to 
server 
Computing 
Node Local 
Job
Client Local 
Xˆ & Fˆ ′  
Send Local 
Xˆ & Fˆ ′  to 
server
…
C
om
puting N
ode 1 
Post-processor (Server) 
C
om
puting N
ode 2 
C
om
puting N
ode n 
