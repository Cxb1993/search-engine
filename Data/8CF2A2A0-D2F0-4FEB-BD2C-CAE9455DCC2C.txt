多輸入多輸出有限脈衝系統的盲判別與對等化
中文摘要
本報告針對多出入多輸出頻率選擇衰減之無線通信系統提出了三種通道盲蔽判別
的方法。判別的方法是利用所估測出來的接收信號協方差矩陣, 先計算出通道乘積矩陣,
再對此通道乘積矩陣取特徵分解, 即可求出通道脈衝響應矩陣。 所提出的方法都是利用
對傳送信號作不同的編碼方式所引發的循環穩態特性來求解問題。我們分別考慮了以下
三種不同的編碼方式: (1) 週期性編碼, (2) 週期性編碼加補零, (3) 補零。 對前兩種判
別方法, 我們也設計了最佳的週期性編碼器。 我們的方法在正規均方差的表現上可與子
空間的方法相比, 但只需要較少的計算量, 同時判別條件也較為寬鬆, 另外我們的方法
還可適用於發射器數目較接收器數目多或者少的情況。數值模擬的結果顯示我們所提出
的方法對通道階數過估的情況具有相當的強健性。
關鍵詞: 多出入多輸出通道, 盲蔽判別, 週期性編碼, 有限脈衝響應, 補零, 單載波補
零傳輸系統, 正交分頻多工系統。
i
Contents
1 Introduction 1
1.1 Research Objective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Literature Survey . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.3 Organization of the Report . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
2 Identification of General MIMO Channels 4
2.1 System Model and Formulation . . . . . . . . . . . . . . . . . . . . . . . . 4
2.2 Blind Channel Identification . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.2.1 The Identification Method . . . . . . . . . . . . . . . . . . . . . . . 6
2.2.2 Channel Order Overestimation . . . . . . . . . . . . . . . . . . . . 9
2.2.3 More Transmitters Than Receivers . . . . . . . . . . . . . . . . . . 10
2.3 Optimal Design of the Precoding Sequence . . . . . . . . . . . . . . . . . . 10
2.3.1 Optimality Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2.3.2 On Selection of m . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.4 Identification Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2.5 Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3 Identification of MIMO Single Carrier Zero Padding Channels 22
3.1 System Model and Formulation . . . . . . . . . . . . . . . . . . . . . . . . 22
3.2 Blind Channel Identification . . . . . . . . . . . . . . . . . . . . . . . . . . 24
3.2.1 The Identification Method . . . . . . . . . . . . . . . . . . . . . . . 24
3.2.2 Optimal Design of the Precoding Sequence . . . . . . . . . . . . . . 27
3.2.3 Computation of G−10 . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2.4 Identification Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 30
3.3 Channel Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.4 Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
4 A Simplified Identification Algorithm for MIMO Zero Padding Channels 38
4.1 System Model and Formulation . . . . . . . . . . . . . . . . . . . . . . . . 38
4.2 Blind Channel Identification . . . . . . . . . . . . . . . . . . . . . . . . . . 39
4.2.1 The Identification Method . . . . . . . . . . . . . . . . . . . . . . . 39
iii
Chapter 1
Introduction
1.1 Research Objective
Multiple-input multiple-output (MIMO) communication systems employing multiple
transmit and receive antennas have received much attention due to the potential improve-
ment in data transmission rate and link reliability they can offer. However, to exploit
the potential advantage of MIMO systems, accurate channel state information is required.
Channel can be identified or estimated using training signal which requires additional band-
width. As a means to eschewing the need of training signal and the associated bandwidth
requirement, blind identification of MIMO channels has been the focus of much research.
Many blind identification algorithms have been proposed in recent years (see [1, 2] for a
detailed review).
Existing algorithms for blind identification of MIMO finite impulse response (FIR)
channels can be classified into second-order statistics methods [8]-[12],[20]-[22], higher-
order statistics methods [3]-[5], and deterministic methods [6, 7]. Among these three types
of methods, blind identification based on second-order statistics has been widely studied
because it requires fewer data samples than the high-order statistics approach and it avoids
poor estimation accuracy under low SNR, a common shortcoming of deterministic methods.
Existing second-order statistics methods for MIMO systems, e.g., the subspace methods
[8, 9], [26], [28]-[29], the linear prediction methods [10]-[12], and the matrix outer product
decomposition methods [20]-[22], either impose restrictive assumptions on the channel to
be identified or require large amount of computations, that may not be realistic in practical
applications.
The goal of this research is to develop blind identification algorithms for MIMO channels,
1
1.3 Organization of the Report
The report is organized as follows. In Chapter 2, we propose a blind identification
method for general MIMO FIR channels based on periodic precoding. We also discuss the
optimal design of the precoding sequence which takes into account the effect of additive
channel noise and numerical error. We also propose a blind identification method for
MIMO FIR channels in SC-ZP block transmission systems based on periodic precoding
and discuss the optimal design of the precoding sequence in Chapter 3. In Chapter 4, we
first propose a blind identification for SC-ZP block transmission systems without periodic
precoding. Extension of this method to ZP-OFDM systems is given subsequently. Chapter
5 concludes this report and discusses the related future research.
We define the following operations that will be used in the derivation of the main result.
First, for anym×mmatrixA = [ak,l]0≤k,l≤m−1, define Γj(A) = [a0,j a1,j+1 · · · am−1−j,m−1]T
for 0 ≤ j ≤ m− 1, i.e., Γj(A) is the vector formed from the jth super-diagonal of A. Sec-
ond, for any Jn× Jn matrix B = [Bk,l]0≤k,l≤n−1, where Bk,l is a block matrix of dimension
J × J , define Υj(B) = [BT0,j BT1,j+1 · · · BTn−1−j,n−1]T for 0 ≤ j ≤ n− 1, i.e., Υj(B) is the
matrix formed from the jth block super-diagonal of B.
3
-
⊗? -s1(n) p(n) u1(n)
...
...
-
⊗? -sK(n) p(n)uK(n)
MIMO FIR
Channel
-
⊕? -t1(n)w1(n)x1(n)
...
...
-
⊕? -tJ(n)wJ(n)xJ(n)
Figure 2.1. An MIMO channel model
where p(n + P ) = p(n), ∀ n. The discrete time model describing the relation between the
transmitted signal uk(n) and the received signal xj(n) has the form of an MIMO FIR filter
with additive noise:
xj(n) =
K∑
k=1
Ljk∑
l=0
hjk(l)uk(n− l) + wj(n), j = 1, 2, · · · , J, (2.2)
where hjk(0), hjk(1), · · · , hjk(Ljk), are the impulse responses of the channel between the
kth transmitter and the jth receiver, and wj(n) is the channel noise seen at the input of
the jth receiver. The equations (2.1) and (2.2) can be written more compactly as
u(n) = p(n)s(n), x(n) =
L∑
l=0
H(l)u(n− l) +w(n), (2.3)
where u(n), s(n) ∈ CK , and x(n), w(n) ∈ CJ are vector signals formed by stacking the
respective scalar signals together, e.g., x(n) = [x1(n) x2(n) · · · xJ(n)]T . The jkth element
of H(l) ∈ CJ×K is hjk(l), and L = maxj,k{Ljk} is the order of the MIMO channel. Thus
H(L) 6= 0J×K .
Group the sequence of x(n) as x¯(n) = [x(Pn)T ,x(Pn + 1)T , · · · ,x(Pn + P − 1)T ]T ∈
CKP , and let w¯(n), u¯(n), s¯(n) be similarly defined, we have
x¯(n) = H0u¯(n) +H1u¯(n− 1) + w¯(n), (2.4)
where H0 is an JP ×KP block lower-triangular Toeplitz matrix with [H(0)T H(1)T · · ·
H(L)T 0TJ×K · · · 0TJ×K ]T ∈ CJP×K as its first block column (i.e., the first K columns),
and H1 is an JP ×KP block upper-triangular Toeplitz matrix with [0J×K · · · 0J×K H(L)
H(L − 1) · · · H(1)] ∈ CJ×KP as its first block row (i.e., the first J rows). Since p(n)
is periodic, u¯(n) = Gs¯(n) for all n, where G = diag[p(0)IK , p(1)IK , · · · , p(P − 1)IK ] ∈
RKP×KP is a diagonal matrix, (2.4) can be written as
x¯(n) = H0Gs¯(n) +H1Gs¯(n− 1) + w¯(n), (2.5)
We assume that the receivers are synchronized with the transmitters. In addition, the
following assumptions are made throughout this chapter.
5
written as
H0G
2H∗0 =
∑L
k=0 J
k ⊗H(k) (G2p ⊗ IMt)∑Ll=0 (Jl ⊗H(l))∗
=
∑L
k=0
∑L
l=0
(
Jk ⊗H(k)) (G2p ⊗ IMt) ((JT )l ⊗H(l)∗)
=
∑L
k=0
∑L
l=0
(
JkG2p(J
T )l
)⊗ (H(k)H(l)∗) , (2.7)
where we have used the identies (A⊗B)∗ = A∗⊗B∗ and (A⊗B)(C⊗D) = (AC)⊗ (BD)
[35, p.190]. Similarly, H1G
2H∗1 can be written as
H1G
2H∗1 =
L∑
k=0
L∑
l=0
(
(JT )P−kG2pJ
P−l)⊗ (H(k)H(l)∗) . (2.8)
The following proposition shows that the matrices JkG2p(J
T )l and (JT )P−kG2pJ
P−l have
special structures that allow decomposition of (2.6) into a group of decoupled equations.
Roughly speaking, the jth block super-diagonal part of (2.6) involves only the unknown
“channel product matrices”,H(k)H(k+j)∗, k = 0, 1, · · · , L−j. For example, the equations
corresponding to the diagonal blocks (j = 0) involve only H(k)H(k)∗, k = 0, 1, · · · , L. In
the proposed identification algorithm, these “channel product matrices” are computed first
by solving linear equations, and then the channel impulse response matrices H(k) are
computed via eigenvalue-eigenvector decomposition.
Proposition 2.1 : Let 0 ≤ k, l ≤ L be two non-negative integers. Then
(a) For l = k+ j, where 0 ≤ j ≤ L− k, both JkG2p(JT )l and (JT )P−kG2pJP−l are upper
triangular matrices with only the respective jth upper diagonals nonzero, and
Γj
(
JkG2p(J
T )l
)
= [0 · · · 0︸ ︷︷ ︸
k entries
p(0)2 p(1)2 · · · p(P − 1− k − j)2︸ ︷︷ ︸
P−k−j entries
]T , (2.9)
Γj
(
(JT )P−kG2pJ
P−l) = [p(P − k)2 p(P − k + 1)2 · · · p(P − 1)2︸ ︷︷ ︸
k entries
0 · · · 0︸ ︷︷ ︸
P−k−j entries
]T . (2.10)
(b) For l < k, both Γj
(
JkG2p(J
T )l
)
and Γj
(
(JT )P−kG2pJ
P−l) are lower triangular with
zero diagonal matrices.
Proof : See [16].
It follows from (2.9) and (2.10) that
Γj
(
JkG2p(J
T )l
)
+ Γj
(
(JT )P−kG2pJ
P−l)
=

[p(P − k)2 · · · p(P − 1)2︸ ︷︷ ︸
k entries
p(0)2 · · · p(P − 1− k − j)2︸ ︷︷ ︸
P−k−j entries
]T if j = l − k ≥ 0
0(P−j)×1 if j 6= l − k
.
(2.11)
7
sequence, we can make each Mj full column rank. Then the solution Fj can be obtained
as
Fj = (M
T
j Mj)
−1MTj Υj (Rx¯) . (2.18)
If Fj, 0 ≤ j ≤ L, are computed from (2.18), then we have the channel product matrices
H(k)H(l)∗ for 0 ≤ k ≤ l ≤ L. We now consider the computation required to determine
the channel impulse response matrix H from Fj.
Let Q be the Hermitian matrix defined by Υj(Q) = Fj for j = 0, 1, · · · , L, and let the
channel impulse response matrix H = [H(0)T H(1)T · · · H(L)T ]T . Clearly we have
Q = HH∗. (2.19)
Since rank(H) = K by assumption (A3), Q has rank K. Since Q is Hermitian and positive
semidefinite, Q has K positive eigenvalues, say, λ1, · · · , λK . We can expand Q as
Q =
K∑
j=1
(
√
λjdj)(
√
λjdj)
∗, (2.20)
where dj is a unit norm eigenvector of Q associated with λj > 0. We can thus choose the
channel impulse response matrix to be
Ĥ = [
√
λ1d1
√
λ2d2 · · ·
√
λKdK ] ∈ CJ(L+1)×K . (2.21)
We note H can only be identified up to a unitary matrix ambiguity U ∈ CK×K [20, 21],
i.e., Ĥ = HU, since ĤĤ∗ = HH∗ = Q. The ambiguity matrix U is intrinsic to methods
for blind identification of multiple input systems using only second-order statistics [20, 21].
2.2.2 Channel Order Overestimation
So far we have assumed that the channel order L is known. If only an upper bound
Lˆ ≥ L is available with P > Lˆ+ 1, then following the same process given in Section 2.2.1,
the corresponding J(Lˆ+ 1)× J(Lˆ+ 1) matrix Q can be similarly constructed as in (2.19).
The last (Lˆ−L) block columns (i.e., (Lˆ−L)J columns) of Q are zero, so are its last (Lˆ−L)
block rows. Hence again, Q is of rank K and has K positive eigenvalues with the associated
eigenvectors all of the form dˆ = [dT 0 · · · 0]T ∈ CJ(Lˆ+1) where d ∈ CJ(L+1). Thus, we can
determine the channel impulse response matrix, up to a unitary matrix ambiguity, from
the K eigenvectors associated with the K positive eigenvalues of Q. In the noise free case,
we can, in theory, also determine the actual channel order.
9
except for the j = 0 group, which becomes
Υ0 (Rx¯) = Υ0
(
H0G
2H∗0 +H1G
2H∗1
)
+ σ2wΥ0 (IJ ⊗ IP ) =M0F0 +Y, (2.23)
where Y = σ2w[IJ IJ · · · IJ ]T ∈ RJP×J . Thus from (2.18), Fˆ0, the least squares approxi-
mation of F0, can be written by
Fˆ0 = (M
T
0M0)
−1MT0 (M0F0 +Y)︸ ︷︷ ︸
Υ0(Rx¯(0))
= F0 + (M
T
0M0)
−1MT0Y = F0 + Z, (2.24)
which is F0 plus a perturbation term due to noise. The perturbation term Z is the least
squares solution of the equationM0Z = Y. We note that if every column ofY is orthogonal
to every column of M0, then Z = 0, which implies Fˆ0 = F0. But that is impossible since
the entries of M0 are positive and those of Y are nonnegative. Therefore, we seek to
appropriately choose the precoding sequence p(n) such that every column of Y is as close
to being orthogonal to that ofM0 as possible. To this end, we first define qki and yi shown
below as the columns of M0 and Y, respectively:
M0 =
[
q01 q02 · · · q0J︸ ︷︷ ︸
M0(:,1:J)
q11 q12 · · · q1J︸ ︷︷ ︸
M0(:,J+1:2J)
· · · qL1 qL2 · · · qLJ︸ ︷︷ ︸
M0(:,LJ+1:(L+1)J)
]
, (2.25)
Y = σ2w[IJ IJ · · · IJ ]T = [y1 y2 · · · yJ ]. (2.26)
Then, due to the special structure of the block matrix M0 and Y, it is easy to check that
qki is orthogonal to yj, i.e., q
T
kiyj = 0 for j 6= i, e.g.,
qT01y2 = [p(0)
2 0 · · · 0︸ ︷︷ ︸
J entries
· · · p(P − 1)2 0 · · · 0︸ ︷︷ ︸
J entries
][0 σ2w 0 · · · 0︸ ︷︷ ︸
J entries
· · · 0 σ2w 0 · · · 0︸ ︷︷ ︸
J entries
]T = 0,
and each qTkiyi assumes the same value, σ
2
w
∑P−1
n=0 p(n)
2, for k = 0, 1, · · · , L, i = 1, 2, · · · , J ,
e.g.,
qT01y1 = [p(0)
2 0 · · · 0︸ ︷︷ ︸
J entries
· · · p(P − 1)2 0 · · · 0︸ ︷︷ ︸
J entries
][σ2w 0 · · · 0︸ ︷︷ ︸
J entries
· · · σ2w 0 · · · 0︸ ︷︷ ︸
J entries
]T = σ2w
P−1∑
n=0
p(n)2.
Thus we only need to consider the relation between columns of q01 and y1 (the case of
k = 0 and i = 1). Define the correlation coefficient
γ =
qT01y1
‖q01‖2‖y1‖2 . (2.27)
Since γ is nonnegative and by Cauchy-Schwarz inequality, 0 ≤ γ ≤ 1. In order to make the
perturbation term Z small, we choose q01 so that the correlation coefficient γ is as small
11
Proposition 2.2 : At least one Mj, 0 ≤ j ≤ L, is not full column rank if and only if
P − L+ 1 ≤ m ≤ P − 2.
Proof : See Appendix A.
Hence if we choose, either 0 ≤ m ≤ P − L or m = P − 1, then each Mj is full column
rank and the channel is identifiable. The following result shows that we can classify the
remaining choices into 2 groups that are relevant to the optimal choice of m.
Proposition 2.3 :
(a) Each of the (P − L) choices, m = 0, m = 1, · · · , m = P − L− 1, results in the same µ
denoted by µ1.
(b) The two choices m = P − L and m = P − 1 result in the same µ denoted by µ2. Also
µ2 ≥ µ1.
Proof : See Appendix A.
From Proposition 2.3, we know if µ2 > µ1, then we choose case (a); if µ2 = µ1, we
proceed to compare the second largest condition numbers of the set of matrices {MTj Mj}Lj=0
for these two cases and choose the case whose value is smaller. If they are again equal,
the same procedure can be done by comparing the third largest condition numbers and so
on. Moreover, for 0 ≤ m ≤ P − L − 1 (case (a)), since the condition numbers of MTj Mj
are the same for each fixed j, j = 0, 1, · · · , L, (see Appendix A), we can use m = 0 to
represent case (a). Similarly, m = P − 1 can be used to represent case (b). Hence the
optimal selection of m reduces to one of two cases: m = 0 or m = P − 1. In other words,
the optimal precoding sequence has a peak either at the beginning or at the end.
2.4 Identification Algorithm
So far, we have proposed a method for blind identification of FIR MIMO channels using
periodic precoding sequence. It is shown that, by properly choosing the precoding sequence,
the MIMO FIR transfer functions, with K inputs and J outputs, can be identified up to
a unitary matrix ambiguity. The proposed algorithm requires solving linear equations and
computing the nonzero eigenvalues and eigenvectors of a Hermitian positive semidefinite
matrix. Since the cyclostationarity is induced at the transmitter, the identifiability condi-
tion imposed on the channel is minimum: it only requires that channel impulse response
matrix H is full column rank. The channel transfer matrix is not required to be irreducible
or column reduced. The channel can have more receivers or more transmitters. The per-
formance of the algorithm depends on the precoding sequence which is optimally designed
to reduce the effect of noise and error in estimating the covariance matrix of the received
data.
13
(2.30) for P = 4 and τ = 0.5878 with the two possible peak positions: m = 0 and m = 3.
By computation, the corresponding µ for the three cases are 40.0, 4.66 and 22.1, respec-
tively. Thus m = 0 is the optimal selection. Figure 2.2 shows that for SNR=10 dB, there
are about 5∼7 dB and 5∼9 dB difference in NRMSE between the optimal one and two
others.
In experiment 2, we use the precoding sequences that satisfy (2.30) with m = 0, but
with different τ to test the effect of τ on the identification performance. Figure 2.3 shows
that for each sequence, when the number of samples (for each transmitter) is fixed at
1000, the NRMSE decreases as SNR increases and is roughly constant for SNR ≥ 20 dB. A
possible explanation is that for sufficiently large SNR, the NRMSE is contributed mainly by
numerical error rather than by channel noise. Figure 2.3 also shows that the identification
performs better for smaller τ , which is consistent with the conclusion at the end of Section
2.3.1.
2) Simulation 2 – channel order overestimation
In this simulation, we use the following channel model
H(z) =
[
0.4851 0.3200
−0.3676 0.2182
]
︸ ︷︷ ︸
H(0)
+
[
−0.4851 0.9387
0.8823 0.8729
]
︸ ︷︷ ︸
H(1)
z−1 +
[
0.7276 −0.1280
0.2941 −0.4364
]
︸ ︷︷ ︸
H(2)
z−2
(2.34)
given in [19]. For each upper bound Lˆ, 0 ≤ (Lˆ − L) ≤ 6, we choose P = Lˆ + 2, SNR=10
dB, and 1000 samples (for each transmitter) for simulation. The precoding sequences are
chosen as (2.30) with m = 0 and τ = 0.2, 0.4, 0.6, and 0.8. Figure 2.4 shows the NRMSE
increases with increasing channel order overestimation. We see the proposed method is
quite robust to channel order overestimation when τ is small. For example, with τ = 0.4,
when (Lˆ − L) increases from 0 to 3, the NRMSE increases from -25.5dB to -21dB, which
is still a low value.
3) Simulation 3 – a 3-input 2-output channel
In this simulation, we use the 3-input 2-output model
H(z) =
[
1.6 0.88 0.66
0.8 0.44 0.33
]
︸ ︷︷ ︸
H(0)
+
[
−0.44 0.35 0.14
−0.14 0.37 0.23
]
︸ ︷︷ ︸
H(1)
z−1 +
[
0.13 0.01 0.08
0.26 0.02 0.16
]
︸ ︷︷ ︸
H(2)
z−2
(2.35)
to illustrate the performance of the proposed method for channel with more transmitters
than receivers. Note that H is full column rank, but the channel is not irreducible [21]
15
variable with unit variance. We compare the proposed method with a generalized space
time block codes (GSTBC)[23] based method. Both methods require periodic precoding
sequences. For the proposed method, the precoding sequence is chosen as {1.500 0.767
0.767 0.767}; whereas the entries in the precoding sequence for the GSTBC method is
chosen as random entries with modulus 1 for each random channel simulation [23]. The
performance of the proposed method is also compared with a linear prediction (LP)[2,
chap. 6] based method, and an outer product decomposition algorithm (OPDA)[20]. Both
methods do not require a periodic precoder. MMSE equalizers are used for the proposed
method, LP method, and OPDA method. For the GSTBC method, we use the customized
equalizer proposed in [23]. Figure 2.8(a) shows that when the number of samples is 1200
(for each transmitter), the identification performance of the proposed method is better
than those of the other three methods excepting the GSTBC method for SNR ≥ 13 dB.
However, Figure 2.8(b) shows the equalization performance of the proposed method is only
better than those of the LP and OPDA methods and worse than the GSTBC method.
The inconsistency of the channel estimation and equalization performance of the proposed
method and the GSTBC method for SNR ≤ 13 dB may be due to the different precoding
sequences and equalizers used. Figure 2.9 shows that when the number of samples is 200
(for each transmitter), the identification and equalization performance of the proposed
method is better than that of the GSTBC method for SNR ≤ 15 dB. Figure 2.9 shows that
when the number of samples is small, the proposed method has better performance than
the GSTBC method under low SNR.
17
0 1 2 3 4 5 6
−30
−28
−26
−24
−22
−20
−18
−16
−14
−12
−10
overestimated channel order
ch
an
ne
l N
R
M
SE
(dB
)
τ=0.2
τ=0.4
τ=0.6
τ=0.8
Figure 2.4. Channel NRMSE versus (Lˆ− L)
100 200 300 400 500 600 700 800 900 1000
−22
−21
−20
−19
−18
−17
−16
−15
−14
−13
−12
number of samples
ch
an
ne
l N
R
M
SE
(dB
)
m=0
m=3
Figure 2.5. 3-input 2-output model: channel NRMSE versus number of samples
19
0 5 10 15 20
−35
−30
−25
−20
−15
−10
−5
0
5
SNR
ch
an
ne
l N
R
M
SE
(dB
)
 
 
proposed method
GSTBC method
OPDA method
LP method
(a) Channel NRMSE versus output SNR
0 5 10 15 20
10−6
10−5
10−4
10−3
10−2
10−1
100
SNR(dB)
sy
m
bo
l e
rro
r r
at
e
 
 
proposed method
GSTBC method
OPDA method
LP method
(b) Symbol error rate versus output SNR
Figure 2.8. Comparison of NRMSE and symbol error rate, number of input samples =
1200
0 2 4 6 8 10 12 14 16 18 20
−22
−20
−18
−16
−14
−12
−10
−8
−6
−4
−2
SNR
ch
an
ne
l N
R
M
SE
(dB
)
proposed method
GSTBC method
(a) Channel NRMSE versus output SNR
0 2 4 6 8 10 12 14 16 18 20
10−5
10−4
10−3
10−2
10−1
100
SNR(dB)
sy
m
bo
l e
rro
r r
at
e
proposed method
GSTBC method
(b) Symbol error rate versus output SNR
Figure 2.9. Comparison of NRMSE and symbol error rate, number of input samples = 200
21
-⊗? - S/P ===⇒ ZP ====⇒ P/S -v1(n)
p(n)
s1(n) s¯1(i) u¯1(i) u1(n)
1 :M N : 1
...
...
...
...
...
-⊗? - S/P ===⇒ ZP ====⇒ P/S -vK(n)
p(n)
sK(n) s¯K(i) u¯K(i) uK(n)
1 :M N : 1
MIMO
FIR
Channel
-⊕? -t1(n)
w1(n)
x1(n)
...
...
-⊕? -tJ(n)
wJ(n)
xJ(n)
Figure 3.1. An MIMO SC-ZP block transmission baseband model with periodic precoding
Then s¯k(i) is passed through a zero padding prefilter F1 = [IM 0
T
P×M ]
T ∈ R(M+P )×M whose
output is
u¯k(i) = F1s¯k(i) = [ s¯k(i)
T︸ ︷︷ ︸
M entries
0 · · · 0︸ ︷︷ ︸
P entries
]T = [uk(iN) · · ·uk(iN +M − 1)︸ ︷︷ ︸
M entries
0 · · · 0︸ ︷︷ ︸
P entries
]T , (3.2)
where N = M + P . Finally, u¯k(i) is converted to uk(n) via a parallel-to-serial block and
transmitted through the MIMO FIR channel. At the receiver, the jth received signal is
xj(n) = tj(n) + wj(n), where tj(n) is the signal component at the output and wj(n) is the
channel noise seen at the jth receiver. If we define x(n) = [x1(n) x2(n) · · · xJ(n)]T ∈ CJ ,
then x(n) can be written as
x(n) =
L∑
l=0
H(l)u(n− l) +w(n) = t(n) +w(n), (3.3)
where u(n) ∈ CK , w(n) ∈ CJ , and t(n) ∈ CJ are similarly defined as x(n), and H(l) ∈
CJ×K is the channel coefficient matrix whose jkth element hjk(l), l = 0, 1, · · · , Ljk, is the
impulse response from the kth transmitter to the jth receiver, and L = maxj,k{Ljk} is the
order of the MIMO channel. We assume that H(L) 6= 0J×K . Group the sequence of x(n)
as x¯(i) = [x(iN)T x(iN + 1)T · · ·x(iN + N − 1)T ]T ∈ CJN , and define u¯(i) ∈ CKN and
w¯(i) ∈ CJN similarly as x¯(i), we have
x¯(i) = H0u¯(i) +H1u¯(i− 1) + w¯(i), (3.4)
where H0 is a JN×KN block lower-triangular Toeplitz matrix with the first block column
being [H(0)T H(1)T · · ·H(L)T 0TJ×K · · ·0TJ×K ]T ∈ CJN×K , and H1 is a JN × KN block
upper-triangular Toeplitz matrix with the first block row being [0J×K · · ·0J×K H(L) H(L−
1) · · ·H(1)] ∈ CJ×KN . We assume that the receivers are synchronized with the transmit-
ters. In addition, the following assumptions are made throughout this chapter.
23
x¯(i)︷ ︸︸ ︷
x(iN)
...
x(iN + L)
...
x(iN +M − 1)
...
x(iN +N − 1)

=
H0︷ ︸︸ ︷
H(0)
...
. . .
H(L) · · · H(0)
. . .
...
. . .
H(L) · · · H(0)
. . .
...
. . .
H(L) · · · H(0)

u¯(i)︷ ︸︸ ︷
u(iN)
...
u(iN + L)
...
u(iN +M − 1)
0
˙˙˙
0

= Hes¯(i),
(3.5)
where He is the sub-matrix formed from the first M block columns of H0 and s¯(i) =
[u(iN)T u(iN + 1)T · · · u(iN +M − 1)T ]T is the first M block entries of u¯(i). Because
u(iN) = [u1(iN) u2(iN) · · · uK(iN)]T (see the line below (3.3)) and uk(iN) = sk(iM)
for k = 1, 2, · · · , K (see (3.2)), u(iN) = [s1(iM) s2(iM) · · · sK(iM)]T , s(iM). Simi-
larly, u(iN + m) = s(iM + m) for m = 1, 2, · · · ,M − 1. Hence s¯(i) = [s(iM)T s(iM +
1)T · · · s(iM +M − 1)T ]T .
Let xf (i) = [x(iN)
T x(iN + 1)T · · · x(iN + L)T ]T be the first J(L+ 1) rows of x¯(i).
Then
xf (i) = Hfsf (i), (3.6)
where Hf ∈ CJ(L+1)×K(L+1) is the sub-matrix formed from the first (L+ 1) block columns
and block rows of He, and sf (i) = [s(iM)
T s(iM + 1)T · · · s(iM + L)T ]T . Also we know
for k = 1, 2, · · · , K, sk(iM) = p(iM)vk(iM) = p(0)vk(iM) from (3.1) and assumption
(B2). Hence s(iM) = [p(0)v1(iM) p(0)v2(iM) · · · p(0)vK(iM)]T = p(0)v(iM), where
v(iM) = [v1(iM) v2(iM) · · · vK(iM)]T . Similarly, s(iM + n) = p(n)v(iM + n) for
n = 1, 2, · · · , L. Therefore (3.6) can be written as
xf (i)︷ ︸︸ ︷
x(iN)
x(iN + 1)
...
x(iN + L)
 =
Hp︷ ︸︸ ︷
p(0)H(0)
p(0)H(1) p(1)H(0)
...
...
. . .
p(0)H(L) p(1)H(L− 1) · · · p(L)H(0)

vf (i)︷ ︸︸ ︷
v(iM)
v(iM + 1)
...
v(iM + L)
 . (3.7)
Define S ∈ RJ(L+1)×J(L+1) as the matrix whose first block sub-diagonal entries are all IJ
(i.e., S(J +1 : J(L+1), 1 : JL) = IJL), and all remaining entries are zero. Rewrite (3.7) as
xf (i) = [p(0)H p(1)SH · · · p(L)SLH]vf (i) = Hpvf (i). (3.8)
25
3.2.2 Optimal Design of the Precoding Sequence
When the noise is present, the covariance matrix Rf contains the contribution of noise.
Thus (3.9) becomes
Rf = E[xf (i)xf (i)
∗] = HpH∗p + σ
2
wIF , (3.14)
where F = J(L+ 1). In this case, (3.11) becomes
vec(Rf ) = G · vec(HH∗) + σ2wvec(IF ). (3.15)
From (3.13), the approximate solution of vec(HH∗) is
̂vec(HH∗) = G−1vec(Rf ). (3.16)
It follows from (3.16) and (3.15) that
̂vec(HH∗) = vec(HH∗) + σ2wG−1 · vec(IF )︸ ︷︷ ︸
z
= vec(HH∗) + σ2wz. (3.17)
The vector z = [z1 z2 · · · zF 2 ]T in (3.17) is the solution of Gz = vec(IF ). Since the matrix
G is completely determined by the precoding sequence p(n), we seek to choose p(n) so that
‖z‖22 is minimized. To this end, we need to analyze the relations between z and p(n). By
expanding the matrix equation Gz = vec(IF ), we find that

p(0)2zi = 1 i = 1 + k(F + 1), k = 0, 1, · · · , J − 1∑1
n=0 p(n)
2zi+(1−n)J(F+1) = 1 i = 1 + k(F + 1), k = 0, 1, · · · , J − 1∑2
n=0 p(n)
2zi+(2−n)J(F+1) = 1 i = 1 + k(F + 1), k = 0, 1, · · · , J − 1
...
...
...∑L
n=0 p(n)
2zi+(L−n)J(F+1) = 1 i = 1 + k(F + 1), k = 0, 1, · · · , J − 1
(3.18)
and zj = 0 for all other indices j. We write (3.18) as the following matrix equation.
g0 0 · · · 0
g1 g0 · · · 0
...
...
. . .
...
gL gL−1 · · · g0

︸ ︷︷ ︸
Gs

m0
m1
...
mL

︸ ︷︷ ︸
m
=

1
1
...
1

︸ ︷︷ ︸
y
(3.19)
where Gs is a lower-triangular Toeplitz matrix, gn = p(n)
2 for n = 0, 1, · · · , L, and mj =
zi+jJ(F+1) for j = 0, 1, · · · , L, i = 1+k(F+1), k = 0, 1, · · · , J−1. HenceGz = vec(IF ), the
relations between z and p(n), is reduced to (3.19), and minimization of ‖z‖22 is equivalent
to minimization of ‖m‖22, which is a nonlinear function of g0, g1, · · · , gL. Then the problem
27
RL+1 as its first column, and{
g¯0 =
1
g0
g¯l = − 1g0
∑l
i=1 g¯l−igi, i = 1, 2, · · · , l − 1, for l = 1, 2, · · · , L .
(3.25)
Then
‖m‖22 = g¯20 + (g¯0 + g¯1)2 + · · ·+ (g¯0 + g¯1 + · · ·+ g¯L)2. (3.26)
For the optimal solution in (3.22), the corresponding g¯n in (3.25) can be expressed as
follows: {
g¯0 =
1
L+1−Lτ > 0
g¯i = − τ(L+1−Lτ)2 (1− τL+1−Lτ )i−1 < 0, i = 1, 2, · · · , L .
(3.27)
The following proposition shows that ‖m‖22 is a continuous and strictly increasing function
of τ on (0, 1). In other words, for 0 < τ < 1, ‖m‖22 decreases as τ decreases, and thus as
τ decreases, the noise effect in the estimation of the covariance matrix Rf is reduced and
hence identification performance improves.
Proposition 3.1: With g¯n given in (3.27), ‖m‖22 =
1−(1− τ
L+1−Lτ )
2(L+1)
2(L+1−Lτ)τ−τ2 and
d
dτ
‖m‖22 > 0 for
0 < τ < 1.
Proof : See Appendix D.
3.2.3 Computation of G−10
With the precoding sequence p(n) chosen as (3.24), the matrix G in (3.12) becomes
G0 =

aIJF 0 · · · 0
bŜ aIJF · · · 0
...
...
. . .
...
bŜL bŜL−1 · · · aIJF
 , (3.28)
where a = L+1−Lτ , and b = τ . The inverse ofG0 can be obtained by forward substitutions
as
G−10 =

k0IJF 0 · · · 0
k1Ŝ k0IJF · · · 0
...
...
. . .
...
kLŜ
L kL−1ŜL−1 · · · k0IJF
 , (3.29)
where k0 =
1
a
and ki = − ba2 (1 − ba)i−1 for i = 1, 2, · · · , L. The solution ̂vec(HH∗) =
G−10 vec(Rf ) in (3.16) is thus quite easy to compute once the optimal precoding sequence
is given.
29
decreases. Hence using a small τ brings good channel estimation and improves the accuracy
of Ge, which is expected to improves the equalization performance. However, using a small
τ would make the diagonal gain p(k)−1 = 1√
τ
in P−1, k = 1, 2, · · · , L, becomes large, which
results in large noise amplification at the receiver and hence is more likely to cause decision
error. Therefore using a small τ would amplify the noise and the equalization performance
deteriorates as τ decreases.
In summary, although decreasing τ improves the accuracy of Ge, it would cause an
increased amplification of noise, and vice versa. Hence there is a trade-off on the selection
of τ when channel equalization is performed. In the work of [15, 16, 27], this trade-off is
also observed. We will give a simulation example to demonstrate this trade-off in the next
section.
3.4 Simulation Results
In this section, we use several examples to demonstrate the performance of the proposed
method. The channel NRMSE, SNR, and the number of Monte Carlo runs are the same as
those given in Section 2.5. The source symbols are i.i.d. QPSK signals. The channel noise
is zero mean, temporally and spatially white Gaussian.
1) Simulation 1 – optimal selection of precoding sequences
In this simulation, we use the model (2.33) to demonstrate the performance of the
proposed method. The length of symbol blocks is M = 27, which is zero padded to
blocks of length M + P = 30. It means P = 3(= L + 1) and transmission efficiency is
90%. In experiment 1, we use 5 precoding sequences which all satisfy (3.20) and (3.21) to
illustrate the effect of the precoding sequences on the identification performance. The first
sequence S0 are chosen based on (3.24) for τ = 0.6, i.e., S0 is chosen as {
√
1.8
√
0.6
√
0.6}.
The sequences S1, S2, SA, and SB are chosen as {
√
0.6
√
1.8
√
0.6}, {√0.6√0.6√1.8},
{√0.6√1.0√1.4}, and {1 1 1} (i.e., no precoding), respectively. Figure 3.2 shows that for
SNR=10 dB, the NRMSE decreases as the number of symbol blocks increases for every
precoding sequence. As expected, the optimal precoding sequence S0 yields the smallest
NRMSE.
In experiment 2, we use the precoding sequences that satisfy (3.24), but with different
τ to test the effect of τ on the identification performance. Figure 3.3 shows that when the
number of symbol blocks = 100, the NRMSE decreases as SNR increases and is roughly
constant for SNR ≥ 20 dB for different τ . Figures 3.3 also shows that the identification
performs better for smaller τ .
31
example, it seems a τ between 0.7 and 0.8 is a good choice for BER performance.
5) Simulation 5 – comparison with the subspace method
In this simulation, we again generate 300 2-input 2-output channels based on IEEE
802.11a standard. We use the precoding sequences that satisfy (3.24) with τ = 0.8. We
use Gray-coded QPSK and 16-QAM input symbols for simulation. We compare the iden-
tification and MMSE equalization performances of the proposed method with those of the
subspace method [26] for MIMO SC-ZP systems.
Figure 3.9(a) shows that when the number of symbol blocks is 200, the identification
performance of the proposed method is better than that of the subspace method except
SNR > 16 dB. The proposed method yields almost the same identification performance for
QPSK and 16-QAM input symbols. Figure 3.9(b) shows that the equalization performance
of the proposed method is better than that of the subspace method except SNR > 16
dB. Figure 3.9 shows that the identification and equalization performance of the proposed
method is better than those of the subspace method for low to medium SNR. The subspace
method gives smaller BER than the proposed method for SNR> 16 dB.
33
0 1 2 3 4 5 6
−30
−25
−20
−15
−10
−5
Overestimated Channel Order
Ch
an
ne
l N
RM
SE
(dB
)
 
 
τ=0.2
τ=0.4
τ=0.6
τ=0.8
τ=1.0
Figure 3.4. Channel NRMSE versus (Lˆ− L)
20 40 60 80 100 120 140 160 180 200
−22
−20
−18
−16
−14
−12
−10
−8
−6
−4
Number of symbol blocks
Ch
an
ne
l N
RM
SE
(dB
)
 
 
sequence S0
sequence S1
sequence S2
Figure 3.5. Channel NRMSE versus number of symbol blocks
35
0 5 10 15 20
10−3
10−2
10−1
100
SNR
Bi
t e
rro
r r
at
e
150 random channels with L=7, number of symbol blocks = 250
 
 
τ=0.1
τ=0.3
τ=0.5
τ=0.7
τ=0.8
(a)
0 5 10 15 20
10−3
10−2
10−1
100
SNR
Bi
t e
rro
r r
at
e
150 random channels with L=7, number of symbol blocks = 250
 
 
τ=0.7
τ=0.8
τ=0.9
τ=0.93
τ=0.96
τ=0.99
(b)
Figure 3.8. BER versus output SNR
0 5 10 15 20
−20
−18
−16
−14
−12
−10
−8
−6
−4
−2
SNR
Ch
an
ne
l N
RM
SE
(dB
)
300 random channels with L=7, number of symbol blocks = 200
 
 
QPSK, proposed method
16 QAM, proposed method
QPSK, subspace method
16 QAM, subspace method
(a) Channel NRMSE versus output SNR
0 5 10 15 20
10−5
10−4
10−3
10−2
10−1
100
SNR
Bi
t e
rro
r r
at
e
300 random channels with L=7, number of symbol blocks = 200
 
 
QPSK, proposed method
16 QAM, proposed method
QPSK, subspace method
16 QAM, subspace method
(b) Bit error rate versus output SNR
Figure 3.9. Comparison with the subspace method
37
- S/P ===⇒ ZP ====⇒ P/S -s1(n) s¯1(i) u¯1(i) u1(n)
1 :M N : 1
...
...
...
...
- S/P ===⇒ ZP ====⇒ P/S -sK(n) s¯K(i) u¯K(i) uK(n)
1 :M N : 1
MIMO
FIR
Channel
-⊕? -t1(n)
w1(n)
x1(n)
...
...
-⊕? -tJ(n)
wJ(n)
xJ(n)
Figure 4.1. An MIMO single carrier with zero padding block transmission baseband model
(C1) The source signal s(n) = [s1(n) s2(n) · · · sK(n)]T ∈ CK is a zero mean white
sequence with E[s(m)s(n)∗] = δ(m−n)IK ∈ RK×K , where δ(·) is the Kronecker delta
function. The noise is zero mean, wide-sense stationary, and may be temporally and
spatially colored with E[w(m)w(m + d)∗] = Kw(d) ∈ CJ×J . In addition, the source
signal is uncorrelated with the noise w(n), i.e., E[s(m)w(n)∗] = 0K×J , ∀m,n.
(C2) An upper bound Lˆ of the channel order L is known, P = Lˆ+ 1, and M > P .
(C3) The channel impulse response matrix H = [H(0)T H(1)T · · ·H(L)T ]T is full column
rank, i.e., rank(H)=K.
In the next section, we propose an algorithm for blind identification of the MIMO
channel impulse response matrix H using second-order statistics of the received data.
4.2 Blind Channel Identification
In this section, we derive the proposed method under assumptions (C1), (C2), and
(C3). Application of the proposed method to MIMO ZP-OFDM systems is given in Section
4.3.
4.2.1 The Identification Method
We first derive the proposed method for the case where the channel order L is known
with P = L + 1, and there are more receivers, i.e., J ≥ K. The cases of channel order
39
way, we obtain the following matrices.
E0 = [H(0)H(0)
∗ +Kw(0) H(1)H(1)∗ H(2)H(2)∗ · · · H(L)H(L)∗]
E1 = [H(0)H(1)
∗ +Kw(1) H(1)H(2)∗ H(2)H(3)∗ · · · H(L− 1)H(L)∗]
E2 = [H(0)H(2)
∗ +Kw(2) H(1)H(3)∗ H(2)H(4)∗ · · · H(L− 2)H(L)∗]
...
...
...
EL−1 = [H(0)H(L− 1)∗ +Kw(L− 1) H(1)H(L)∗]
EL = [H(0)H(L)
∗ +Kw(L)]
(4.6)
From (4.6), we can obtain the channel product matrices H(m)H(n)∗ for m,n = 1, 2, · · · , L.
If we can further obtain H(0)H(j)∗ for j = 0, 1, · · · , L, then we can get a Hermitian matrix
Q = HH∗ formed by these channel product matrices. Similarly, under the assumption
(C3), we can obtain the channel impulse response matrix, up to a unitary matrix ambiguity,
by choosing the K largest eigenvalues and the associated eigenvectors of Q, like the way
given at the end of Section 2.2.1
Now, to obtain H(0)H(j)∗ for j = 0, 1, · · · , L, we need to eliminate the noise covariance
matrix imposing on H(0)H(j)∗+Kw(j). We will take advantage of the special structure of
the last P block entries of x¯(i), i.e., xl = [x(iN +M)
T · · · x(iN +N − 1)T ]T to eliminate
Kw(j) for j = 0, 1, · · · , L.
From (4.2), we know xl(i) can be written as
xl(i)︷ ︸︸ ︷
x(iN +M)
x(iN +M + 1)
...
x(iN +N − 1)
 =
Hl︷ ︸︸ ︷
0 · · ·0 H(L) · · · H(1)H(0)
H(L) · · · H(1)H(0)
. . . . . . . . .
0︸ ︷︷ ︸
M blocks
H(L) · · ·H(1)H(0)︸ ︷︷ ︸
P (=L+1) blocks

u¯(i)︷ ︸︸ ︷
u(iN)
...
u(iN +M − 1)
0
˙˙˙
0

+wl(i),
(4.7)
where wl(i) is similarly defined as xl(i). Because the last P block rows in u¯(i) are zero and
P = L+ 1, xl(i) can be written as
xl(i) = Hr[u(iN)
T · · · u(iN +M − 1)T ]T +wl(i) = Hrur(i) +wl(i), (4.8)
where Hr, the first M block columns of Hl, is a JP ×KM block Toeplitz matrix with the
first block row being [0J×K · · ·0J×K︸ ︷︷ ︸
(M−L) blocks
H(L) H(L−1) · · · H(1)] and the first block column
being zero, as seen from (4.7). Let Rl = E[x(iN +M)x
∗
l (i)]. Then from (4.7) and (4.8),
41
4.2.2 Identification Algorithm
So far, we have proposed a blind identification method for MIMO zero padding block
transmission systems based on eigen-decomposition approach. With zero-padding, the re-
lation between the covariance matrix of the received data and the channel product matrices
becomes highly structured. The structure makes it easy to estimate the channel product
matrices and the noise covariance matrices. Eigen-decomposition of a Hermitian matrix
formed by the channel product matrices yields the channel impulse response up to a uni-
tary matrix ambiguity. The channel noise may be temporally and spatially colored. We
summarize the proposed method as the following algorithm.
Algorithm :
1) Collect the received data as x¯(i), pick up the first (L+ 1) block entries of x¯(i) as xf (i)
and the last P block entries of x¯(i) as xl(i).
2) Estimate the matrices Rf and Rl via the following time average
Rˆf =
1
S
S∑
i=1
xf (i)xf (i)
∗, (4.11)
Rˆl =
1
S
S∑
i=1
x(iN +M)xl(i)
∗, (4.12)
where S is the number of data block, and x(iN +M) is the (M +1)th block entry of x¯(i).
3) Form Υj(Rˆf ) as in (4.5) and then obtain H(m)H(n)
∗ for m,n = 1, 2, · · · , L.
4) Form (4.10) from Υj(Rˆf ), j = 0, 1, · · · , L, and form (4.9) from Rˆl. Then obtain
H(0)H(j)∗ for j = 0, 1, · · · , L by subtracting (4.9) from (4.10).
5) Form the matrix Q = HH∗ using the channel product matrices, and obtain the channel
impulse response matrix H by computing the K largest eigenvalues and the associated
eigenvectors of Q.
4.2.3 Extension to MIMO Zero-Padding OFDM Systems
The proposed method can be extended to the MIMO ZP-OFDM systems. In this case,
at the transmitter, each s¯k(i) is multiplied by the IFFT matrix F
∗ before entering the zero
padding block, F1 [26]. Here F ∈ CM×M is an FFT matix. Thus we know the input to F1
is F∗s¯k(i) for OFDM case. Since F is a unitary matix [?], s¯k(i) and F∗s¯k(i) are both zero
mean and have the same second-order statistics. Hence
E[F∗s¯k(m)] = 0, E[(F∗s¯k(m))(F∗s¯k(n))∗] = δ(m− n)IM .
43
Figure 4.2(a) shows the NRMSE decreases as the number of symbol blocks increases. Figure
4.2(b) shows that the noise NRMSE also decreases as the number of symbol blocks increases,
where the noise NRMSE is similarly defined as in (2.32) except H is replaced by K =
[Kw(0)
T Kw(1)
T Kw(2)
T ]T and Ĥ(i) is replaced by K̂(i) = [K̂
(i)
w (0)T K̂
(i)
w (1)T K̂
(i)
w (2)T ]T .
2) Simulation 2 – random channels case
In this simulation, we generate 100 2-input 2-output random channels with order L = 2
to demonstrate the performance of the proposed method. Each element in the channel
impulse response matrix is complex Gaussian distribution with zero mean and unit variance.
We use M = 18 and P = 2(= L) (transmission efficiency is 90%). Figure 4.3 shows for
different number of symbol blocks, the NRMSE decreases as SNR increases and is roughly
constant for SNR ≥ 20 dB.
3) Simulation 3 – a 3-input 2-output channel
In this simulation, we use the 3-input 2-output model (2.35) to illustrate the perfor-
mance of the proposed method for channel with more inputs than outputs. We use M = 18
and P = 2. Figure 4.4 shows for different number of symbol blocks, the NRMSE decreases
as SNR increases and is roughly constant for SNR ≥ 20 dB.
4) Simulation 4 – channel order overestimation
In this simulation, we use the channel model (2.34) to demonstrate the performance of
the proposed method by comparing with the subspace method [26], which is also for MIMO
zero padding block transmission systems. For each upper bound Lˆ, 0 ≤ (Lˆ − L) ≤ 6,
we choose P = Lˆ and M = 9P for simulation such that the transmission efficiency is
maintained at 90%. Figure 4.5 shows when the number of symbol blocks is fixed at 500,
the NRMSE increases with increasing channel order overestimation for different SNR. When
SNR=0 and 5 dB, the proposed method performs better than the subspace method. When
SNR=10 dB, the subspace method performs better than the proposed method. Figures 4.5
shows that the proposed method is more robust to channel order overestimation than the
subspace method when SNR is low.
5) Simulation 5 – channel estimation and equalization of a 2-input 2-output ZP-OFDM
system
In this simulation, we use a ZP-OFDM system with the same channel model (2.34), and
M = 18, P = 2. We compare the performance of the proposed method with that of the
subspace method [26]. Figure 4.6(a) shows when SNR = 0 and 5 dB, the performance of
45
0 5 10 15 20 25 30 35 40
−24
−22
−20
−18
−16
−14
−12
−10
−8
−6
SNR
Ch
an
ne
l N
RM
SE
(dB
)
 
 
100 blocks
200 blocks
300 blocks
400 blocks
500 blocks
Figure 4.3. Channel NRMSE versus output SNR
0 5 10 15 20 25 30 35 40
−18
−17
−16
−15
−14
−13
−12
−11
SNR(dB)
Ch
an
ne
l N
RM
SE
(dB
)
100 symbol blocks
300 symbol blocks
500 symbol blocks
Figure 4.4. Channel NRMSE versus output SNR
47
0 5 10 15 20 25
10−4
10−3
10−2
10−1
100
SNR
Sy
m
bo
l e
rro
r r
at
e
subspace method
proposed method
(a) 25 symbol blocks for identification
0 5 10 15 20 25
10−5
10−4
10−3
10−2
10−1
100
SNR
Sy
m
bo
l e
rro
r r
at
e
subspace method
proposed method
(b) 50 symbol blocks for identification
0 5 10 15 20 25
10−5
10−4
10−3
10−2
10−1
100
SNR
Sy
m
bo
l e
rro
r r
at
e
subspace method
proposed method
(c) 250 symbol blocks for identification
0 5 10 15 20 25
10−5
10−4
10−3
10−2
10−1
100
SNR
Sy
m
bo
l e
rro
r r
at
e
subspace method
proposed method
(d) 500 symbol blocks for identification
Figure 4.7. An OFDM system: symbol error rate versus output SNR
0 5 10 15 20 25
10−5
10−4
10−3
10−2
10−1
100
SNR
Sy
m
bo
l E
rro
r R
at
e
proposed method
subspace method
Figure 4.8. An OFDM system: symbol error rate versus output SNR
49
Appendix
A Proof of Proposition 4.1 and 4.2
Preliminary :
For each j, let Nj ∈ R(N−j)×(L−j+1) be similarly defined as (2.17), except that IMr
is replaced by 1. It can be easily check that there exists permutation matrices Plj ∈
RMr(N−j)×Mr(N−j) andPrj ∈ RMr(L−j+1)×Mr(L−j+1) such thatPljMjPrj = diag[Nj,Nj, · · · ,Nj] =
Dj ∈ RMr(N−j)×Mr(L−j+1) is a block diagonal matrix with each block of dimension (N−j)×
(L− j + 1). Since PljT = Plj−1 and PrjT = Prj−1 [34, p.110], we have Mj = PljTDjPrjT .
Hence Mj is full column rank if and only if Nj is full column rank for j = 0, 1, · · · , L.
Also,MTj Mj = (PrjD
T
j Plj)(Plj
TDjPrj
T ) = PrjD
T
j DjPrj
T = Prjdiag[N
T
j Nj, · · · ,NTj Nj]PrjT .
Let λ(A) denote the spectrum of A [34, p.310], that is, the set of eigenvalues of A. Then
λ(MTj Mj) = λ(N
T
j Nj).
Proof of Proposition 2.2 :
If at N − L + 1 ≤ m ≤ N − 2, it can be checked that Nj, j = 2, 3, · · · , L− 1 is not of
full column rank since it has two columns both equal to [τ τ · · · τ ]T which implies that at
least one Mj is rank deficient and vice versa.
Proof of Proposition 2.3 :
From the Preliminary, since λ(MTj Mj) = λ(N
T
j Nj), the condition number of M
T
j Mj
is identical to that of NTj Nj, i.e., κ(M
T
j Mj) = κ(N
T
j Nj). Thus we need only compute the
condition number of NTj Nj.
Case (a): For m = 0,m = 1, · · · , and m = N − L− 1, we know
NTj Nj = a · IL−j+1 + (2b+ cj) · [1 · · · 1]T [1 · · · 1], (A.1)
where a = N2(1− τ)2, b = Nτ(1− τ), cj = (N − j)τ 2. Hence the maximum and minimum
51
B The Eigenvalues of NTjNj for m = N − L
Proof :
Let Aj = N
T
j Nj defined in (A.2), then Aj is positive definite since Nj is full column
rank. It can be checked that the eigenvectors corresponding to (L−j−1) multiple eigenvalue
a are: [1,−1, 0, 0, · · · , 0]T , [1, 1,−2, 0, · · · , 0]T , · · · , [1, 1, · · · , 1,−(L − j − 1), 0]T . The
remaining eigenvectors are [1, 1, · · · , 1, x]T ∈ RL−j+1. Hence
Aj

1
...
1
x
 =

a+ (L− j)(2b+ cj) + (b+ cj)x
...
a+ (L− j)(2b+ cj) + (b+ cj)x
(L− j)(b+ cj) + cjx
 = λj

1
...
1
x
 , (B.1)
which implies the following two equations
a+ (L− j)(2b+ cj) + (b+ cj)x = λj, (B.2)
(L− j)(b+ cj) + cjx = λjx. (B.3)
Substitute (B.2) into (B.3), we can get an second order equation of x. Solving this equation
can lead to two solutions of x. Bring these two x into (B.2) and we can obtain the two
eigenvalues βj, αj. In addition, βj ≥ a because of (B.4)
βj =
1
2
{(L− j)(2b+ cj) + (a+ cj) +
√
[(L− j)(2b+ cj) + a− cj]2 + 4(L− j)(b+ cj)2}
≥ 1
2
{(L− j)(2b+ cj) + (a+ cj) +
√
[(L− j)(2b+ cj) + a− cj]2}
= 1
2
{[(L− j)(2b+ cj) + (a+ cj) + [(L− j)(2b+ cj) + a− cj]}
= a+ (L− j)(2b+ cj)
≥ a
(B.4)
and αj ≤ a because of the interlacing property [34, p.396].
53
D A Proof of Proposition 3.1
Let a = L + 1 − Lτ and b = τ , then according to (3.27), g¯0 = 1a > 0 and g¯i =
− b
a2
(1− b
a
)i−1 < 0 for i = 1, 2, · · · , L, and
g¯0 + g¯1 + g¯2 + · · ·+ g¯l = 1a − ba2 − ba2 (1− ba)− · · · − ba2 (1− ba)l−1
= 1
a
− b
a2
· 1·[1−(1− ba )l]
1−(1− b
a
)
= 1
a
− 1
a
[1− (1− b
a
)l]
= 1
a
(1− b
a
)l
Hence
‖m‖22 = g¯20 + (g¯0 + g¯1)2 + · · ·+ (g¯0 + g¯1 + · · ·+ g¯L)2
= [ 1
a
]2 + [ 1
a
(1− b
a
)]2 + · · ·+ [ 1
a
(1− b
a
)L]2
= 1
a2
[1 + (1− b
a
)2 + · · ·+ (1− b
a
)2L]
= 1
a2
· 1·[1−(1− ba )2(L+1)]
1−(1− b
a
)2
=
1−(1− b
a
)2(L+1)
a2·[1−1− b2
a2
+ 2b
a
]
=
1−(1− b
a
)2(L+1)
2ab−b2
=
1−(1− τ
L+1−Lτ )
2(L+1)
2(L+1−Lτ)τ−τ2
and
d
dτ
‖m‖22 =
[2(L+1−Lτ)τ−τ2]·[−2(L+1)(1− τ
L+1−Lτ )
2L+1]·[− d
dτ
( τ
L+1−Lτ )]
[2(L+1−Lτ)τ−τ2]2 −
[1−(1− τ
L+1−Lτ )
2(L+1)]·(−4Lτ−2τ)
[2(L+1−Lτ)τ−τ2]2
=
[(1−τ)τ(2L+1)+τ ]·[2(L+1)(1− τ
L+1−Lτ )
2L+1]·[ L+1
(L+1−Lτ)2 ]
[2(L+1−Lτ)τ−τ2]2 +
[1−(1− τ
L+1−Lτ )
2(L+1)]·(4Lτ+2τ)
[2(L+1−Lτ)τ−τ2]2
Because 0 < 1− τ < 1 and 0 < (1− τ
L+1−Lτ ) < 1 for 0 < τ < 1,
d
dτ
‖m‖22 > 0 for 0 < τ < 1.
55
[10] A. Gorokhov and P. Loubation, “Blind identification of MIMO-FIR systems: a gener-
alized linear prediction approach”, Signal Processing , vol. 73, pp. 105-124, 1999.
[11] J. K. Tugnait, “On linear predictors for MIMO channels and related blind identification
and equalization”, IEEE Signal Processing Letters , vol. 5, no. 11, pp. 289-291, Nov.
1998.
[12] J. K. Tugnait and B. Huang “Multistep linear predictors-based blind identification and
equalization of multiple-input multiple-output channels”, IEEE Trans. Signal Process-
ing , vol. 48, no. 1, pp. 26-38, Jan 2000.
[13] A. Scaglione, G. B. Giannakis, and S. Barbarossa, “Redundant filter bank precoders
and equalizers Part I: Unification and optimal designs.”, IEEE Trans. Signal Process-
ing , vol. 47, no. 7, pp. 1988-2006, July 1999.
[14] A. Scaglione, G. B. Giannakis, and S. Barbarossa, “Redundant filter bank precoders
and equalizers Part II: Blind channel estimation, synchronization, and direct equaliza-
tion”, IEEE Trans. Signal Processing , vol. 47, no. 7, pp. 2007-2022, July 1999.
[15] A. Chevreuil, E. Serpedin, P. Loubaton and G. B. Giannakis, “Blind channel identifi-
cation and equalization using periodic modulation precoders: performanve analysis”,
IEEE Trans. Signal Processing , vol. 48, no. 6, pp. 1570-1586, June 2000.
[16] C. A. Lin and J. W. Wu, “Blind identification with periodic modulation: A time-
domain approach”, IEEE Trans. Signal Processing , vol. 50, no. 11 pp. 2875-2888,
Nov. 2002.
[17] A. Chevreuil and P. Loubaton, “MIMO blind second-order equalization method and
conjugate cyclostationarity”, IEEE Trans. Signal Processing , vol. 47, no. 2, pp. 572-
578, Feb. 1999.
[18] H. Bo¨lcskei, R. W. Heath, Jr., and A. J. Paulraj, “Blind channel estimation in spatial
multiplexing systems using nonredundant antenna precoding”, Proc. of the 33rd An-
nual IEEE Asilomar Conf. on Signals, Systems, and Computers , vol. 2, pp. 1127-1132,
Oct. 1999.
[19] H. Bo¨lcskei, R. W. Heath, Jr., and A. J. Paulraj, “Blind channel identification and
equalization in OFDM-based multiantenna systems”, IEEE Trans. Signal Processing ,
vol. 50, no. 1, pp. 96-109, Jan. 2002.
[20] Z. Ding, “Matrix outer-product decomposition method for blind multiple channel iden-
tification”, IEEE Trans. Signal Processing , vol. 45, no. 12, pp. 3053-3061, Dec. 1997.
57
[33] M. W. Hirsch and S. Smale, Differential Equations, Dynamical Systems, and Linear
Algebra, Academic Press, 1974.
[34] G. H. Golub and C. F. Van Loan, Matrix Computions, 3rd edition, The Johns Hopkins
University Press, 1996.
[35] F. Zhang, Matrix Theory: Basic Results and Techniques, Springer-Verlag , 1999.
[36] B. O’Hara and A. Petrick, The IEEE 802.11 Handbook: A Designer’s Companion, 2nd
edition, 2nd edition, IEEE Press, 2005.
[37] P. Lancaster and M. Tismenetsky, The Theory of Matrices With Applications, Aca-
demic Press, 1984.
[38] D. G. Luenberger, Linear and Nonlinear Programming, 2nd edition, Kluwer Academic
Publishers, 2003.
59
