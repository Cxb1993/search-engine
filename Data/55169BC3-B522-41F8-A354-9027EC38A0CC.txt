machine vision. 
英文關鍵詞： Reflectance edge, Illumination edge, Error function, 
Edge detector 
 
approach that is used in the least-square-error-based reflectance edge detectors, the 
illumination edges can be determined by fitting the profiles of the illumination ratios 
with the proposed blurred illumination edge models. Verified by practical 
experiments, the proposed detecting technique is feasible with high accuracy.  
 
3. 研究方法 
All the illumination edge detectors have been discussed operate according to the 
grayscale intensity changes in the images. In this section, a new term, called the 
illumination ratio, is introduced. Then, a mathematical model using the illumination 
ratio to detect blurred illumination edges are proposed. Because images are 
illuminated by vertically- striped light patterns and the pixels in an image are 
processed one row at a time, the edge detection process could be simplified as a 
one-dimensional problem without losing its generality. The direction of the pixel 
processing is assumed to be performed from left to right throughout the remaining of 
this paper.  
3.1 Illumination ratio 
The illumination ratio at the center of a pixel ),( vu , noted as ),( vuR , is a function 
defined as 
),(~),(
),(~),(),(
00
0
vugvug
vugvugvuR
−
−
=           (1) 
where ),(0 vug , ),(~0 vug , and ),( vug  denote the grayscale intensities of the pixel 
),( vu  on the images, which are captured under the illuminations of the full uniform 
light, the ambient light, and any one of the light patterns respectively. Intuitively, 
0.1),(5.0 ≤≤ vuR  indicates that the pixel is ‘lit’ mostly by a bright light pattern, and 
5.0),(0 <≤ vuR  indicates the pixel is ‘shadowed’ mostly by a dark light pattern. 
3.2 Models for blurred illumination edges  
Similar to the model for an ideal reflectance edge without blurring effect, the profile 
of illumination ratio versus pixel position for an ideal illumination edge can be 
modeled as a step function. However, if taking the influences of blurring factors into 
account, such ideal modeling would become impractical. Therefore, in this research, a 
Gaussian-function-based diffusion process is used to describe the blurring influences 
on the illumination edges. Since the convolution of a step function with a Gaussian 
function would generate an error function, the impulse response function of the 
blurred illumination edge with respect to the pixel position can be derived as follow:  
R
ERL RxxerfRRxR +





+




 −⋅
−
= 1
22
)(
σ
            
that can precisely identify illumination edges in images. Although the 
frame-differencing method using complementary patterns is generally acknowledged 
to be the most accurate illumination edge detector, the proposed technique could 
perform better than it in both speed and accuracy. The frame-differencing method 
gains its accuracy because of using complementary patterns, which unavoidably 
prolong the scanning time; whereas the proposed method uses only the compulsory 
light patterns. Skipping the complementary patterns makes the proposed method save 
about a half of the total measuring time. In addition, the frame-differencing method 
using complementary patterns failed to identify the illumination edges in dark areas. 
The proposed method determines illumination edges by fitting the profile of 
illumination ratio with the proposed blurred illumination edge models. Verified by a 
series of experimental results, the proposed method could successfully detect the 
illumination edges in either bright or dark areas. 
II、 參考文獻 
[1] The 4th International Conference on 3D Systems and Applications (3DSA 2012), 
Cheng WEN, Chih-Hung HUANG and Kuang-Chiung CHANG, “Accelerating 
Acquisition Speed of Structured Light 3D Scanning Systems” 
[2] The Third International Conference on Swarm Intelligence(ICSI 2012), 
Ming-Feng Yeh, Cheng Wen and Min-Shyang Leu, “Grey-based Particle Swarm 
Optimization Algorithm” 
[3] Journal of Lung-Hwa University of Science and Technology, Cheng Wen, 
Chih-Hung Huang and Kuang-Chiung Chang, “Accelerating Acquisition Speed of 
3D Scanners”, no.6, 2012 
 
 
III、 計畫成果自評 
本計畫研究提出一種基於照射率的模糊照射邊緣偵測模型，依此理論基礎開
發的實務技術可提供結構光三維掃描器使用。 
本計畫的相關研究論文發表於二篇國際研討會以及一篇學刊。計畫研究成果
符合預期。 
 
100 年度專題研究計畫研究成果彙整表 
計畫主持人：溫成 計畫編號：100-2221-E-262-029- 
計畫名稱：模糊照射邊緣的建模與偵測技術 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 12 12 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
(1)研討會論文：The 4th International Conference on 3D Systems and Applications 
(3DSA 2012),’’Acquisition Speed of Structured Light 3D Scanning Systems’’  
(2)期刊論文：Journal of Lunghwa University of Science and Technology,’’
Accelerating Acquisition Speed of 3D Scanners’’ 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
理論上，邊緣可分為反射邊緣和照射邊緣。反射邊緣是由物體表面原有的顏色變化造成，
一般邊緣偵測技術討論的對象即為反射邊緣。此外，當有圖案的光線(例如結構光)，照在
物體表面時，物體表面的顏色變化所形成的邊緣，便包含部分的原有反射邊緣，與部分由
光線陰影造成的照射邊緣。 
照射邊緣偵測技術對於主動式的機器視覺檢測而言非常重要，這可以由機器視覺設備廠商
推出多種結構光投射器看出。然而，目前絕大多數的技術皆是將照射邊緣視為反射邊緣同
類，在利用傳統的反射邊緣偵測程序之後，再將其中的照射邊緣檢出。實際上，此一照射
邊緣檢出的工作，並不簡單。此外，部分技術以互補式結構光投射來偵測照射邊緣，可以
達到照射邊緣偵測的目的，但是存有偵測時間過長的缺點。 
本研究所提出的方法可用來偵測圖像中的照射邊緣。不同於傳統的照射邊緣偵測技術，主
要基於灰階值強度。本研究提出圖像上之每個畫素的照射率定義，並依此照射率定義，利
用誤差方程式建立一個照射邊緣之數學理論模型。而後，利用曲線匹配技術即可以準確的
偵測照射邊緣。 
實務上，常使用一組參考的結構光圖形來達成增加二值化程序演算的強健性。然而，這些
額外增加使用的參考結構光圖形會降低結構光三維掃描器的擷取速度。因此，在開發二進
