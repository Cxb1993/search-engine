2報告內容:
I. INTRODUCTION
Since the ever increasing dependency on the Internet, there has been a rapid evolution in the Internet applications. It provides a
broad range of multimedia services, such as IP telephony, video conferencing, collaborative research, and distance based virtual
reality/visualization. To meet real time property, Quality of Service (QoS) management for networked multimedia applications
over IP is thus a significant and demanding challenge. During the past several years, numerous mechanism s have been proposed for
providing QoS networks. The ultimate goal of these QoS mechanisms is to provide differentiated services to the applications at the
edges of the network. These mechanisms usually rely on two procedures [1], as shown in Fig. 1. First, traffic arriving at edge routers
is separated into distinct forwarding classes, e.g., indicated by the differentiated services codepoint (DSCP field) in the DiffServ
model [2], via the process of packet classification. Packets from each flow are then directed to a corresponding queue. Then, the
queue- scheduling algorithm determines the rate at which packet from each queue is forwarded that the resources are allotted to each
queue and to the corresponding flows.
Fig. 1. The Enabling Procedures for QoS Mechanism.
Currently, end-to-end service guarantees for specific aggregated flows are achieved through RSVP, MPLS or similar reservation
protocols by routing these flows along specific traffic engineered paths. The directed routing is based on the source and destination
addresses of packets [3–5]. The two- dimensional packet classification determines the next hop and the allocated resource for each
packet based on its source and destination addresses. Hence, packet classification is a key component of the QoS mechanisms that
determines to which forwarding class a packet belongs. For example, the current discussions about differentiated services within the
IETF assume that the edge routers of a core network are capable to classify the packets of different users [6]. Furthermore, two-
dimensional packet classification is also useful for multicast forwarding which requires lookups based on both the source address and
multicast group [7], [8].
Packet classification entails searching a table of rules which binds a packet to a flow or set of flows and returning the forwarding
class for the least-cost rule which matches the packet. A rule consists of a set of fields, which in turn correspond to another set of
fields in the packet header. The most common fields include the IP source address (SA, 32 bits), the destination address (DA, 32 bits),
the protocol type (8 bits), port numbers (16 bits) of source/destination applications and protocol flags in the packet header. Each
field can be any variable length prefix bit string, range, explicit value or wildcard. A d-dimensional rule F is thus defined as F
= (f1, f2, . . . , fd). A packet P is said to match a particular rule F if for all i, the ith field of the header satisfies fi. Each rule has
an associated action, which is usually assigned a cost to define its priority among the actions of matched rules. The matched rule
with the least-cost action will be enacted to process the arriving packets. In sum, the complexity of packet classification builds on
the search for the least-cost, matching rule.
While packet classification has been extensively employed in the Internet for security, the properties of rules for security and
service differentiation are quite different. Currently, the largest rule sets in firewalls contain a few thousand rules [9–11]; however,
dynamic resource reservation protocols could cause rule sets to swell into the tens of thousands. For example, let’s consider a
backbone router with 100K prefixes. If each destination prefix is coupled with even a few source prefixes (e.g. for resource
reservation between content providers and customers), it is not hard to imagine the need for several hundred thousand rules. Thus the
problem of finding the best matching rule for more than 100K rules at Gigabit speeds is an important challenge [12].
In the last few years, the problem of packet classification has been studied extensively. Most of these algorithms are de- signed
for applications on firewalls. Since these rule sets used for security and firewalls are fairly small [9], the performance of these
algorithms cannot be guaranteed with a reasonable storage as the number of rules increases. Thus, they might not be suitable for
differentiated services. To successfully deploy the Internet differentiated services, we are interested in solutions that can scale to
several hundreds thousands rules. In addition, the algorithms should be able to achieve fast updating since the rules specified for
differentiated services might change frequently. Furthermore, we concern only worst- case performance of the algorithms since the
header processing delay should be avoided in order to provide service assurances.
4Even a linear search of the tuple space represents a considerable improvement over a linear search of the rules since the
number of tuples is typically much smaller than the number of rules.
The rectangle search, a tuple-based algorithm, was proposed to improve the performance of the tuple lookup [10]. The
lower bound has been demonstrated to be O(2W −1) given aO(W × W) rectangular tuple space, where W is the number
of distinct prefix lengths. The primary aim is to eliminate a set of tuples during each probing, as depicted in Fig. 2.
Tuples above T are eliminated if the probe of tuple T returns “Match”. Otherwise, tuples to the right of tuple Tare
discarded. Markers and a pre-computation mechanism are required to reach this goal. Assuming that the number of rules
is N, a rectangle search requires NW memory space. In our experiments, the number of the generated markers are about
twelve times of the original rules. In [22], Wang et al. presented an algorithm to improve the required storage and the
lookup speed of the rectangle search. Based on the observation that the performance of the rectangle search ties to the
number of tuples, this scheme adopts a dynamic programming scheme to calculate the optimal set of tuples and
reorganizes the rules by using rule expansion. However, the cost of pre-computation would increase exponentially as the
classifier expands and makes the scheme unsuitable for large rule sets.
Fig. 2. Rectangle Search Algorithm.
Another heuristic, tuple pruning search, performs lookups on individual fields to eliminate tuples that cannot match the
query. For each dimension, the referred information is collected in the pruning table. Accordingly, the lookup procedure
starts by searching the pruning tables. The set of referred tuples for each prefix are recorded and the tuples corresponding
to the intersection will be probed. Since no extra entry is required besides the pruning table, it features low update cost.
We use an example to explain the lookup procedure. The two rules F1 (10*, 110*) and F2 (1010*, 110010*) are located in
T2,3 and T4,6, respectively. For the incoming packets with addresses (101000,110010), the matched prefixes of source
address include 10* and 1010* which are referred in T2,3 and T4,6, respectively. For the destination address, the matched
prefixes are 110* and 110010* which are also referred in T2,3 and T4,6. Hence the intersected tuples T2,3 and T4,6 will be
probed, as shown in Fig. 3. The authors claimed that the intersected rules are very rare in the industrial firewall database,
hence it might perform well in the practical environment [10]. However, its worst case performance O(W 2) is identical to
that of the linear search.
Fig. 3. Tuple Pruning Search Algorithm.
III. ENHANCED TUPLE PRUNING
Since the action of the least-cost matching rule is used to process the arriving packet. The tuple pruning search can be improved
6where Existing(LPrefix(SPi ), LPrefix(DPi )) is the number of existing rules whose source address prefix 2 LPrefix(SPi )
and destination address prefix 2 LPrefix(DPi ).
One of the major concerns about this approach is the number of the additional i-markers which ties to the different lengths of
referred prefixes in each dimension. Apparently, the number of the i-markers ties to the existence of rules with longer prefixes.
Therefore, each rule can result in at most W 2 i- markers with shorter prefixes. Nevertheless, the observation from the real-world
routing tables and rule sets indicate that the number of different sub-prefix lengths is few. First, we use the routing tables
downloaded from [24], [25] to show the number of different sub-prefix lengths for each route prefix without counting the default
route. For most route prefixes, there are usually less than three sub-prefixes in the routing table and six in the worst case, as shown in
Fig. 6. Thus at most48 (72−1) extra rules will be generated for each inserted rule. However, the occurrence of the worst-case
situation should be relatively low since only 5% of route prefixes have more than three and two sub-prefixes in the NLANR and the
rest routing tables, respectively. In [12], the authors also reported that the phenomenon remains for the industrial classifiers. In
our experiments, we further demonstrate that the extra cost is reasonable with respect to the improvement in performance.
Tuple Construction Algorithm
FOR each rule Fi = (SPi,DPi) BEGIN
Calculate LPrefix(SPi ) and LPrefix(DPi ).
FOR each (sp, dp) pair where sp 2 LPrefix(SPi ) and dp 2 LPrefix(DPi ) BEGIN
Check whether the rule (sp, dp) exists in the tuple Tlsp,ldp .
If yes, compare its cost with cost(Fi) and overwrite with the lower-cost action.
Otherwise, put an i-marker (sp, dp) with the action of Fi into the tuple Tlsp,ldp .
END
END
Fig. 5. Tuple Construction Algorithm
8Fig. 8. An Example of Rule Insertion.
The procedure of rule deletion is similar to that of rule insertion. For each deleted rule, the related i-markers should be dropped.
The i-markers in T1,3 , T2,2 , T2,6 and T4,3 will be removed for the deletion of F1 , as shown in Fig. 9. Furthermore, the tuples
covered by the deleted rule will also be examined for the correctness of the least-cost action. The nearest rule which covers F2
should be checked for possible revision. This is because if the examined tuples with i-markers or rules with cost higher than F5, the
action of F5 should replace those entries to ensure that the lowest cost action will be taken. Otherwise, their actions will remain
unchangeable. The number of the deleted i-markers are 2W−1 and the examined tuples are W2 in the worst case. For the ease
of updating, each entry in the tuple should have two action fields: one is the least-cost action related to the rule and
another is its original action.
Fig. 9. An Example of Rule Deletion.
Implementation: The tuple pruning search can be implemented with software or hardware. With software
implementation, the total lookup time is (lookup(SA) + lookup(DA)) plus one hash access time. The lookup performance
can be further improved through hardware implementation. By exploiting hardware parallelism, the total lookup time of
the pruning tables is reduced to max(lookup(SA), lookup(DA)). We can also perform pruning and hashing
simultaneously by adopting pipeline design and accomplish one packet classification within maximum(pruning(SA),
pruning( DA), one hash access to the tuple). Assume the worstcase pruning time is 20ns with 10ns SRAM [26] and one
hash access time (without collision) is 20ns (one 20ns DRAM access time), the proposed scheme can achieve 50 MPPS.
IV. PERFORMANCE EVALUATION
To evaluate the performance of the proposed TPP scheme, we use the synthetical rule sets with 5K to 1M entries. Since our
algorithm is designed for supporting QoS of multimedia applications, we generate the rule sets from the routing table in NLANR
[24]. There are 102,309 prefixes in the sample routing table. We use two different sampling schemes to generate the (SA,DA) rules:
the first one is to choose the prefixes uniformly [10] and the other is to concentrate 80% rules in 20% address space to show
locality [27]. Note that the rules with wildcard are not considered in the simulation because they will be inserted into the
pruning table and will not affect the tuples. The rule length distribution of the 100K-rule set with 80% locality is shown in the
right part of Fig. 13 which is similar to the figure represented by uniformly chosen rules. Most rules correspond to the tuples near
(24,24). The color shades represent the density of rules: the darker the shade, the greater number of rules.
10
The resulted rule lengths distribution from Fig. 13 is shown in Fig. 14. It can be noticed that the number of required tuples is
increased and the colors of most of the blocks are darker than as compared with Fig. 13. Furthermore, the number of colored blocks
is increased because the i-markers might be inserted to the tuples, which do not contain any rule originally.
Fig. 11. The Rule Lengths Distribution of Database with i-markers. (Left:Random, Right:80% locality)
B. Comparison with the Rectangle Search Schemes
In this section, the TPP scheme is compared to the rectangle search schemes presented in [10], [22]. Since the
existing rectangle search schemes require extensive pre-computation, we only compare their performance based on
classifiers with at most 100K rules. First, we present the comparison between the TPP scheme and the rectangle search.
As shown in Table IV, the TPP scheme might result in more tuples than the rectangle search, but the required storage and
the lookup speed are greatly superior than the rectangle search. This is due to the fact that the i-markers are inserted into
the tuples based on the referred prefixes, the markers used in the rectangle search are inserted into every left-hand tuple.
Hence the i-makers can result in an efficient data structure and search algorithm, as demonstrated in Table IV.
Next, we compare the TPP scheme with the tuple-reduction scheme [22]. As listed in Table V, the tuple reduction
scheme outperforms the rectangle search in both speed and storage. Nevertheless, the TPP scheme provides better
performance than the tuple reduction scheme due to the efficiency of the i-markers.
C. Comparison with Other Existing Schemes
It is difficult to compare the practical performance of the existing schemes because there is no public available
benchmark tools for packet classification yet. Currently, most schemes use randomly generated rule set to examine the
performance while few schemes use real-world firewall databases. In addition, most schemes are designed for five-
dimensional packet classification except for the tuple-based schemes, Grid of Tries and the proposed scheme. Therefore,
12
可供推廣之研發成果資料表
□ 可申請專利 ■ 可技術移轉 日期：95 年 8月 1 日
國科會補助計畫
計畫名稱：可擴充式封包分類器之研究
計畫主持人： 張弘毅 博士
計畫編號：NSC94－2213－E－327－017－
學門領域：計算機系統結構
技術/創作名稱 可擴充式封包分類器
發明人/創作人 王丕中、詹家泰、李春良、張弘毅
技術說明
中文：現今 IP 網路正迅速向具有 QoS 功能的網路基礎設施演
進。隨著差異服務功能興起，對封包分類技術的需要也日益增
加。然而當差異服務種類能增加時，區分服務的規則的數量也會
隨之顯著增加；事實已經證明當潛在區分服務規則很多，遇到最
糟狀況時，封包分類的效能將大幅下降。在本研究中，我們設計
了一個優於現存封包分類技術的演算法，我們稱這個改良於
tuple pruning search 演算法為 Tuple Pruning Plus (TPP)。
我們的主要想法是簡化查找程序並且避免不必要的 tuple
probing，這個想法主要是透過維護最少成本的規則和額外的資訊
標記來達成。隨著在資訊標記上新增的規則，我們的方法在做每
一次封包分類的時候，只需要僅僅一次的 tuple access。在實驗
中，TTP 在有一百萬的分類規則時，可以用 70MB 的動態記憶體來
達到每秒五千萬次封包分類，性能改善可達五十倍。我們也提出
更進一步降低記憶體需求的探索演算法，這個演算法大約降低了
約 20 MB 記憶體需求。這些結果顯示 TPP 在高速封包分類應用的
有效性。
