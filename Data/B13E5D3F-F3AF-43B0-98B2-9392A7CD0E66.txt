行政院國家科學委員會專題研究計畫成果報告(完整版) 
核磁共振影像之融合、切割與檢索自動化 
Fusion, Segmentation and Automatic Indexing for MRI 
計 畫 編 號：NSC 96-2628-E-005-084-MY3 
執 行 期 限：96 年 8 月 1 日至 99 年 7 月 31 日 
主 持 人：黃博惠  教授／國立中興大學資訊科學與工程學系 
計畫參與人員：李政雄、蕭宗志、陳正宜 
 
一、中文摘要 
本研究計劃就醫學影像之融合、切割、與
影像資料庫檢索自動化等技術，做深入的探
討，並提出有效的解決方案以建構成一個實際
有用的整合系統。在醫學影像中，利用磁振造
影(Magnetic Resonance Imaging, MRI)來引導
腦部腫瘤切除手術已成為不可或缺的重要工
具，本計劃所處理的醫學影像，即是以 MR
影像為標的。影像融合(image fusion)率先應用
於遙測影像，對不同效果之取像提供整合成一
張清晰影像的技術，最近更將此技術應用於醫
學影像。影像切割 (image segmentation)在影
像處理與分析的研究領域中，一直是受到相當
重視的主題，近年來由於數位醫學影像的蓬勃
發展，影像切割更應用到醫學影像，幫助醫師
對病情做診斷。以影像內容為搜尋基礎之影像
資 料 庫 擷 取 系 統 (Content-Based Image 
Retrieval, CBIR)，近二十年來更是熱門的研究
主題，而影像檢索自動化 (automatic image 
indexing)則是影像資料庫效能表現之關鍵技
術。最近十年來，該技術已陸續被應用到醫學
影像，以搜尋相似病例輔助醫師看診、遠距醫
療(telediagnosis)、及作為醫學院相關教學之
用。本計劃分三年執行，第一年完成一個具有
高效能的影像融合系統，將 T1、T2 影像融合
成最富資訊之影像。第二年著重在 MR 腦部腫
瘤影像自動切割技術，以第一年的成果為基
礎，配合第二年的切割技術結果，期能將腦部
正常與異常組織做精確描述。第三年則建構一
個具有自動檢索功能的 3D腦部腫瘤影像資料
庫系統，利用第二年完成的切面 MR 影像切割
結果，重建腦瘤 3D 形狀，並從中擷取相關特
徵，作為 MR 影像在資料庫系統中的索引之
用。由於本研究計劃具有前瞻性，相信對醫學
影像之研究與實際應用將有重大之貢獻。 
關鍵詞：核磁共振影像、影像融合、影像切割、
影像資料庫、自動檢索。 
二、英文摘要 
This research project concentrates on 
techniques including image fusion, image 
segmentation, and content-based image retrieval 
(CBIR) for brain tumor magnetic resonance 
(MR) images. In medical imaging, magnetic 
resonance imaging in conjunction with 
computerized stereo-tactic systems has become 
an indispensable tool for guiding brain tumor 
resections. The medical images to be dealt with 
in this project are MR images. Image fusion was 
initially applied to the remote sensing field by 
combining images with different resolutions and 
spectral wavelengths to form a unique image 
1 
部腫瘤區域，現階段仍是一個深具挑戰性的研
究主題[8]-[11]，因為腦部腫瘤可能以任意的
大小、形狀及亮度出現在影像中的任何位置
[12][13]，有時一些腦部腫瘤可能與其附近的
腦部組織結構互相干擾而產生變形，形成水
腫，以致於改變腫瘤周圍組織的亮度，造成腫
瘤區域不易判讀。 
建構一個有效率的影像檢索系統，首先必
須定義明確的影像特徵空間。近年文獻
[14]-[16]以立體區域的觀念做為醫療影像檢
索的依據，所採用的特徵包括腦瘤體積、重心
位置，並指出如果可增加形狀與灰階強度資訊
可以提升檢索的正確性。從醫學診斷觀點來
看，腫瘤形狀所反應出來的惡性程度比腫瘤形
狀本身更具重要性[17]-[19]，因此腦瘤形狀所
反應之惡性程度亦是檢索重要資訊。本計劃第
三年以建置一個三維腦部腫瘤影像檢索系統
為主要目的，醫師可透過此系統來查詢資料庫
中相似病例的腦部影像。經過系統的查詢比對
與特徵分析所得到的資訊，可做為醫師診斷時
的參考，進而協助醫師對於病人的病情與療法
有更進一步的掌控。 
依據統計，大型醫院每年產生的醫學影
像，數量都非常龐大。因此要從龐大的資料中
取得相似病灶影像，是件相當耗時的事。而且
醫師在診斷治療上，通常都是憑藉著專業知識
以及臨床的經驗來判讀病患的病況，對於一些
罕見病例以及從醫療影像上不易判讀的病
症，若能透過醫療影像資料庫的輔助，將歷年
病患的資料全部蒐集起來，經過類似病灶的查
詢比對與分析，利用醫療影像資料庫的搜尋結
果作為幫助醫師診斷的參考依據，則可協助醫
師對於病人的病情與療法能有更進一步的掌
控及療程規劃。 
四、研究內容與成果 
在第一年的醫學影像融合方面，其方法及
成果簡述如下： 
1. 腦部核磁共振之 T1 與 T2 影像輸入：使
用者將欲融合的 T1 與 T2 影像輸入本系
統中。 
2. T1 與 T2 影像邊界偵測：由於腦部核磁共
振影像在 T1 與 T2 中可突顯出不同的腦
部結構，且每個腦部結構在不同影像中也
有不同之對比程度，如圖二(a)、(b)所示，
故本階段先利用邊界偵測演算法對 T1 與
T2 影像進行邊界偵測，將不同腦部結構
之邊界完整地偵測出來，提供後續融合步
驟之運用。 
3. 具有鑑別力邊界集合之取得：在上述區域
邊界偵測步驟中，T1 與 T2 影像所得到的
邊界並不相同，為了得到一致的區域邊
界，我們將第二步驟所取得之 T1 與 T2
區域邊界影像進行下列運算，以獲得一具
有鑑別力的邊界集合。 
k
d
N
kd
SS
1=∪=  且  
i
EP
N
i
k
EP IIS
k
d 1=∩−=
其中 N 為來源影像個數， 表示來源影
像 Ii 使用邊界偵測後所得到的邊界集
合。 
i
EPI
4. T1 與 T2 影像中相對應像素強度值計
算：參照具有鑑別力邊界集合，計算 T1
與 T2 影像中具有鑑別力的邊界像素所在
位置之區域強度值，最後以目前考慮像素
之座標(x, y)為中心，加總視窗 SZ內所有
邊界像素之區域能量值作為目前考慮像
素之全域能量強度值 ),( yxM iz ，其計算公 
式如下： 
∑=
∩∈∀ dzS Syxvu
i
w
i
z vuEyxM
),(),(
),(),(  
∑=
∈∀
−
),(
1|)),((|),(
vuDd
w
i
w
w
dvuDvuE  
}),()','(,0)],()','([|{),( 2 vuSvudvufvufdvuD ww ∈∀≠=−=  
其中 f(u, v)為邊界像素(u, v)之灰階值，而
SZ(x, y)為一大小為 Z 之考慮視窗，其中心
點落於考慮像素(x, y)上，Sw(u, v)為一個
大小為 w 之小視窗，其中心點落於像素
位置(u, v)上。 
5. 根據能量強度值選擇目前考慮像素應保
留之來源影像灰階值：第四步驟計算出
T1 與 T2 影像中相對應像素之全域能量
強度值 ),(1 yxM z 與 ),(2 yxM z ，系統選擇其中能
量強度值較大者，並將其相對應之來源影
像灰階值保留於融合影像中。 
6. 輸出融合結果之最後影像：當輸入影像中
所有像素皆已執行步驟四與步驟五之運
算後，即可獲得一融合影像，並將其輸出
3 
Jaccard Similarity：
21
21
21 )( SS
SS
,SSJ ∪
∩= ， 
其中 S1 為專業醫師手動切割出的腦瘤
區域，S2 為本演算法所切割區域。S1 和
S2 交集部份為正確的切割區域，Jaccard 
Similarity 為 0 與 1 之間的小數，切割若
是完全正確，其值為 1，隨著交集的區域
逐漸減少，其值由 1 遞減，若是完全沒有
交集，則其值為 0。 
κ-index: 
21
21
21
2
)(
SS
SS
,SS +
∩×=κ ， 
其中 S1 為專業醫師手動圈選的腦瘤區
域，S2 為本系統所切割出之腫瘤區域。
S1和S2交集部份為本系統切割出正確的
腫瘤區域，κ-index 為 0 至 1 之間的小數，
切割若是完全正確，其值為 1，隨著交集
的區域逐漸減少，此值由 1 遞減，若完全
沒有交集，則其值為 0。 
 
在實驗結果中，我們使用四組不同的腦部
核磁共振影像 CASE A 至 CASE D，進行
Jaccard similarity與κ-index二種衡量方法的切
割效能評估，結果如表一所示。另外，在圖四
至圖七中，(a)為對應表一的四組不同的原始
MR 影像， (b)為系統自動切割後所得到的腫
瘤區域結果。 
 
(表一)、腫瘤切割方法效能評估結果 
影像編號 Jaccard κ index 
CASE-A 0.870 0.930 
CASE-B 0.814 0.897 
CASE-C 0.771 0.871 
CASE-D 0.895 0.945 
平均 0.837 0.911 
 
 
(a) 
 
(b) 
(圖四)、系統自動化切割對 CASE-A 的結
果。(a)原始 MR 影像；   (b)自動化腫瘤切
割後之結果 
 
(a) 
 
(b)  
(圖五)、系統自動化切割對 CASE-B 的結
果。(a)原始 MR 影像；   (b)自動化腫瘤切
割後之結果 
 
 
(a) 
 
(b)  
(圖六)、系統自動化切割對 CASE-C 的結
果。(a)原始 MR 影像；   (b)自動化腫瘤切
割後之結果 
 
 
(a) 
 
(b)  
(圖七)、系統自動化切割對 CASE-D 的結
果。(a)原始 MR 影像；   (b)自動化腫瘤切
割後之結果 
 
在第三年的 MRI 影像檢索自動化，其方
法及成果簡述如下：  
1. 三維腦部腫瘤影像特徵萃取 
由於腦瘤相對於腦部組織結構中所分佈的
位置，將會影響人體各類的感官功能(包括
痛覺、觸覺、語言及記憶等功能)，因此，
本研究所採用的腦瘤影像特徵包括：腦瘤
體積、腦瘤重心與大腦頂骨中心之距離(即
腦瘤相對位置)、腦瘤重心與大腦頂骨中心
之角度(即腦瘤相對角度)、腦瘤形狀之惡
性程度等，茲分別描述如下： 
(1) 腦瘤體積：使用影像切割所得到之腦
瘤形狀像素堆疊成離散式的三維體
積，將腦瘤體素的總個數乘以單位體
素之體積，即可得到該腦瘤之估計值
體積。腦瘤體積的估算方式如下： 
5 
統完成的使用者介面如 (圖八 )所示，圖中
Query 區域可提供原查詢影像的切面圖，圖中
右邊的影像序列是依相似度由高至低的順序
列出資料庫中相似影像的縮小圖與腦瘤資
訊，該縮小圖會以該病人包含腦瘤之切面為顯
示影像，使用者點選縮小圖可將該組影像放大
顯示於 Retrieval 區域並可觀看其三維視覺化
透視圖，在放大顯示的影像中，可利用介面的
scroll bar 下上移動來查看該組影像的前後切
面影像以輔助判讀，而三維視覺化透視圖則可
依照使用者所需的視角隨意調整角度，讓使用
者可以清楚地了解腦瘤與腦組織的三維空間
關係，每張影像都會附上該病人的腦瘤特徵資
訊，並在點選之後可查閱該病人的個人資料與
相關的診斷及療程醫治資訊，快速且有效地提
供醫師做為診斷及醫療規劃上重要的參考依
據。 
五、結論 
在影像融合方面，本計劃研發一腦部影像
融合系統，此一系統先對所有來源影像找出共
同具有鑑別力的邊界，配合新的像素能量強度
計算方法來融合所要保留的腦部結構，將腦部
核磁共振影像 T1 與 T2 中所擁有的腦部結
構，如白質、灰質、腦脊髓液與腫瘤等，均能
整合於同一張影像中。 
在腫瘤影像切割方面，我們以 FPCM 的
方法來偵測與切割腫瘤在影像中的區域，準確
地切割出異常組織區域，並將此區域套入融合
後之影像當中，作為腫瘤影像資料庫檢索之特
徵，以類似病例提供醫療診斷相關資料來輔助
醫師，使其能更準確地判斷並規劃出更適當的
療程。 
本計畫已完成一腦部 MR 影像融合系
統，此系統能將 T1 與 T2 所各自擁有的腦組
織結構及腫瘤區域呈現於一張影像中，幫助醫
生對於腦部腫瘤有更精確的診斷與處理，並且
可以大大的節省資訊儲存所需的空間。在腦瘤
切割系統的建置中，我們針對注入顯影劑後
T1 影像中之腦瘤病變區域，自動將其偵測出
來與並與其他背景準確切割，對可疑的病變區
域進一步細分其紋理特徵資訊，作為影像資料
庫檢索系統所使用之特徵。最後，我們運用以
影像內容為基礎的資料庫檢索方法，建置一個
腦部腫瘤醫學影像資料庫，提供相似病例搜尋
機制，作為醫師在診斷及治療規劃上的重要參
考依據。 
六、 參考文獻 
[1] Weibei Dou, Su Ruan, Yanping Chen, 
Daniel Bloyet, Jean-Marc Constans, “A 
framework of fuzzy information fusion for 
the segmentation of brain tumor tissues on 
MR images,” Image and Vision 
Computing,1-8, 2006. 
[2] G. Pajares, Jesus Manuel de la Cruz, “A 
wavelet-based images fusion tutorial,” 
Pattern Recognition, Vol. 37, pp. 1855-1872, 
2004. 
[3] G. Piella, , “A general framework for 
multiresolution image fusion: from pixels to 
regions,” Information Fusion, Vol. 4, pp. 
259-280, 2003. 
[4] Shruti Garg, K. Ushah Kiran, Ram Mohan, 
U S Tiwary, “Multilevel medical image 
fusion using segmented image by level set 
evolution with region competition,” 
proceedings of the 2005 IEEE Engineering 
in Medicine and Biology 27th Annual 
Conference,2005. 
[5] Maria Gonzalez-Audicana, Jose Luis Saleta, 
Raquel Garcia Catalan, and Rafael Garcia, 
“fusion of multispectral and panchromatic 
images using improved HIS and PCA 
mergers based on wavelet decomposition,” 
IEEE transaction on Geoscience and 
Remote sensing, 42(6), 2004. 
[6] H. Li, B.S. Manjunath, S.K. Mitra, 
“Multisensor image fusion using the wavelet 
transform,” Graphical Models Image 
Process, 57(3), 235-245, 1995. 
[7] V. Petrovic, C. Xydeas, “Multiresolution 
image fusion using cross band selection,” 
Proc. SPIE, (39),319-326, 1999. 
[8] L.M. Fletcher-Heath, L.O. Hall, D.B. Goldgof, 
F.R. Murtagh, “Automatic Segmentation of 
Non-enhancing Brain Tumors in Magnetic 
Resonance Images,” Artificial Intelligence in 
Medicine, vol. 21, pp. 43-63, 2001. 
[9] M. Prastawa, E. Bullitt, S. Ho, G. Gerig, “A 
7 
(表二)、三維腫瘤影像之特徵萃取分析表 
資料庫 體積 距離 角度 惡性程度 
Data1 45247 141.12 82.31 0.15 
Data2 6058 31.15 0.63 0.23 
Data3 15684 43.84 324.13 0.18 
Data4 24118 56.75 198.04 0.18 
Data5 22064 47 22.97 0.22 
 
 (表三)、以 Data5 查詢三維腦瘤影像檢索之相似度比對分析表 
特徵 
(加權值) 
體積 
(0.4) 
距離 
(0.3) 
角度 
(0.3) 
惡性程度 
(0) 
正規化分數 Rank
Data1 0.164 0.042 0.201 0 0.407 4 
Data2 0.236 0.258 0.264 0 0.758 2 
Data3 0.336 0.291 0.201 0 0.828 1 
Data4 0.38 0.273 0.009 0 0.662 3 
 
 
(圖八)、三維腦瘤影像檢索之系統介面圖 
 
9 
報告內容應包括下列各項： 
一、參加會議經過 
學生於 2009 年 10 月 10 日中午一點搭乘統聯客運前往桃園中正機場，並準時搭乘長榮航空
於台灣時間 10 月 10 日下午 6 點 10 分飛往美國洛杉磯之班機。到達洛杉磯機場後轉搭美國聯合
航空於當地時間 6 點 59 分飛往德州聖安東尼奧之班機，並於當地時間凌晨一點左右到達會議舉
行地點 Hyatt Regency Riverwalk 旅館。 
學生所發表的論文被歸類在大會中的 Medical Informatics 領域中，發表時間為第二天(10 月
12 日)下午 15：30～16：50 的場次報告，論文發表時間為每人十五分鐘 (包含：問題討論)。會議
期間學生除了發表自己的論文外，更到其他與自己研究相關的場次，從中瞭解並學習各國學者現
階段的研究成果與方向，以作為學生日後的研究參考。學生於美國時間 10 月 14 日搭乘美國聯合
航空於德州聖安東尼奧飛往洛杉磯機場的班機，並於洛杉磯機場轉搭長榮航空，於台灣時間 10
月 16 日上午 6 點 15 分抵達台灣，完成了此次出國會議行程。 
 
二、與會心得 
這次的國際會議雖然不是自己第一次出國用英文發表自己的研究著作，但向來英文能力與口
語表達不太擅長的自己，難免會有些許的緊張與不安。還好在出國前有指導教授－黃博惠老師的
指導與協助，陪同學生反覆練習與修正會議報告的內容，才讓學生安心不少。由於指導教授事前
細心指導的緣故，在會議的報告過程中，學生能用較流暢的英文呈現自己的研究主題，而對於來
自不同國家之與會者所提出的問題，亦能盡可能地給予答覆，讓學生能順利地完成報告之任務。
而在這次會議中，學生也看到許多國外的學者，不論在外語的能力、報告台風的穩健度及研究內
容的紮實性，都是自己學習的榜樣。 
    會議的最後一天，與學弟利用空檔時間，在當地進行了一次徒步旅行，參觀了附近的著名景
點，與當地人民有不少的接觸與對話，深刻體會了美國所謂的種族大熔爐，真的是獲益匪淺。學
生相信此行程的經驗，可以幫助學生往後在面對來自世界各地的研究人員時，可以更有自信地與
他們進行交流，增進了學生國際參與能力。 
 
三、考察參觀活動(無是項活動者省略) 
 
四、建議 
承蒙國科會對於學生這次國際會議的相關經費補助，僅此致謝。由於美國的生活費較台灣高
出許多，對於一些台灣學生而言，會議期間的生活支出是一件相當沉重負擔，建議應該提高補助
金額，讓其他有心參加會議的學生，能無後顧之憂。 
 
978-1-4244-2794-9/09/$25.00 ©2009 IEEE             SMC 2009 
Support Vector Classification for Pathological Prostate 
Images Based on Texture Features of Multi-Categories 
P. W. Huang, Cheng-Hsiung Lee 
Department of Computer Science and Engineering 
National Chung Hsing University 
Taichung 40227, Taiwan 
powhei.huang@msa.hinet.net 
Phen-Lan Lin 
Department of Computer Science and  
Information Management, Providence University 
Shalu, Taichung 433, Taiwan 
lan@pu.edu.tw
Abstract—This paper presents an automated system for grad-
ing pathological images of prostatic carcinoma based on a set of 
texture features extracted by multi-categories of methods includ-
ing multi-wavelets, Gabor-filters, GLCM, and fractal dimensions. 
We apply 5-fold cross-validation procedure to a set of 205 patho-
logical prostate images for training and testing. Experimental 
results show that the fractal dimension (FD) feature set can 
achieve 92.7% of CCR without feature selection and 94.1% of 
CCR with feature selection by using support vector machine clas-
sifier. If features of multi-categories are considered and opti-
mized, the CCR can be promoted to 95.6%. The CCR drops to 
92.7% if FD-based features are removed from the combined fea-
ture set. Such a result suggests that features of FD category have 
significant contributions and should be included for considera-
tion if features are selected from multi-categories.  
Keywords—Fractal dimension, Gleason grading, prostatic 
carcinoma, prostate image, SVM 
I. INTRODUCTION
Over the last few years, prostate carcinoma becomes the 
most common cancer in men. In the US, prostate cancer is the 
most frequently diagnosed cancer and ranks second among 
cancer deaths [1]. Biopsy of the prostate, usually stained by 
Hematoxylin and Eosin (H&E) technique, is a key step for 
confirming the diagnosis of malignancy and guiding treatment 
[2]. By viewing the microscopic images of biopsy specimens, 
pathologists can determine the histological grades. The Glea-
son grading system [3] is the most widespread method for his-
tological grading of prostate carcinoma.  
Although pathologists can determine the histological 
grades by viewing the microscopic images of biopsy speci-
mens, the process of human visual grading is time-consuming 
and very subjective due to inter- and intra-observer variations. 
Therefore, how to develop a more objective computer-aided 
technique for automatically and correctly grading prostatic 
carcinoma is the goal of this research study. 
A classic Gleason grading diagram containing the five ba-
sic tissue patterns associated with the five tumor grades is 
shown in Fig. 1. As reported in [4], the use of texture analysis 
for prostatic lesions is very essential to the identification of 
tissue composition in prostatic neoplasia. Figure 2 shows four 
pathological images of prostatic carcinoma from well differen-
tiated (grade 2) to very poorly differentiated (grade 5) in our  
Figure 1. The Gleason grading diagram.
image set. From Fig. 1 and Fig. 2, we can also see that the 
texture of prostate tissue plays an important role in Gleason 
grading for prostate cancer. 
There are several well-known techniques for texture analy-
sis such as extracting texture features from Gray-Level Co-
occurrence Matrix (GLCM), Gabor filters, and multiwavelet 
transforms. The concept of fractal dimension (FD) is applied 
in this paper for analyzing the texture of prostate tissue. In 
physical phenomena, the growth of cancer shows the features 
of fractal. The fractal theory can provide clinically useful in-
formation for discriminating pathological tissue from healthy 
tissue [5].  
The FD-based features can be extracted through differen-
tial box-counting (DBC) method [6] and entropy-based fractal 
dimension estimation (EBFDE) method to analyze pathologi-
cal images of prostatic carcinoma. We combine the FD-based 
features with those extracted from multiwavelets, Gabor fil-
ters, and GLCM to form a set of 144 texture features of multi-
categories for classification.  
To evaluate the effectiveness of classification results based 
on these features, we use k-fold cross-validation procedure [7] 
to a set of 205 pathological prostate images and tested against 
these samples using Support Vector Machine (SVM) classifier 
to estimate the correct classification rates (CCR). For selecting 
an optimal set of features, we apply the Sequential Floating 
Forward Selection (SFFS) feature selection method [8].  
Our system performs very well on classifying pathological 
prostate images in terms of CCR. Experimental results show 
that the fractal dimension (FD) feature set can achieve 92.7% 
of CCR without feature selection and 94.1% of CCR with fea-
ture selection by support vector machine classifier. If  
Proceedings of the 2009 IEEE International Conference on Systems, Man, and Cybernetics
San Antonio, TX, USA - October 2009
978-1-4244-2794-9/09/$25.00 ©2009 IEEE
912
          
space such that (x, y) represents a two-dimensional position and 
the third coordinate (z) represents the gray level of an image at 
position (x, y). The (x, y)-space is divided into grids of size 
ss× . Thus, there will be a column of boxes of size hss ×× on 
each grid, where ¬ ¼ ¬ ¼sMhG // = and G is the total number of 
gray levels in an image. Let the maximum and minimum gray 
levels of an image in the ),( ji th grid fall in box number k and l,
respectively. The contribution of rN in the ),( ji th grid is ex-
pressed as 
1),( +−= lkjinr .                                (2)  
The contribution from all grids is 
¦=
ji
rr jinN
,
),( .                                (3) 
rN is counted for different scale ratio r. Then, the fractal 
dimension D can be estimated from the slope of line approx-
imated by least-squares linear fitting for log(Nr) versus 
log(1/r) in (1).  
The DBC method only captures the information about in-
tensity difference which is necessary but not sufficient enough 
to differentiate all patterns of different Gleason grades. The 
entropy-based fractal dimension estimation (EBFDE) method 
can further capture the information about randomness of pixels. 
The EBFDE method is described as follows. First, a 2-D image 
is partitioned into several grids of size ss × . Then, we compute 
the entropy for the ),( ji th grid using the following equation: 
¦−= −= 10 2 )(log),(
G
k kkr ppjie .                      (4) 
In this equation, index k is taken over all grayscales in the  
(i, j)th grid of an image, kP is the probability of gray-level k occur-
ring in the (i, j)th grid of an image, and G is the total number of 
gray levels. The contribution from the (i, j)th grid is er(i, j)2. So 
the total contribution from all grids is 
¦=
ji
rr jieE
,
2),( .                                 (5) 
Again, by applying (1), the fractal dimension D of an im-
age can be estimated using least-squares linear fitting for 
log(Er) versus log(1/r).
We assume that various self-similarity properties in a pros-
tatic carcinoma (PCa) image may be reflected in different indi-
vidual ranges of scales. Remember that the scaled down ratio is 
r=s/M, where s2 is the grid size and M2 is the image size. Since 
M=384 for prostate images, we choose s=2, 4, 8, 16, 32, 64, 
and 128 to include all feasible grid sizes, from 2×2 (the smal-
lest one) to 128×128 (one ninth of the whole image). There-
fore, the range of scales (r) is {1/192, 1/96, 1/48, 1/24, 1/12, 
1/6, 1/3}, which is subsequently divided into three sub-ranges: 
the sub-range of small scales {1/192, 1/96, 1/48}, the sub-range 
of medium scales {1/48, 1/24, 1/12}, and the sub-range of large 
scales {1/12, 1/6, 1/3}. Here, we allow a small portion of over-
lapping between two neighboring sub-ranges because there is 
no clear cut between two sub-ranges reflecting different self-
similarity properties. We choose three scales in each sub-range 
because this is the minimum requirement for using the tech-
nique of least square linear fit. Since we do not exclude the 
possibility that the same self-similarity property is reflected in 
all scales, we also use all of the seven scales to estimate the 
fractal dimension of an image. As a result, four fractal dimen-
sion texture features are obtained by DBC method and another 
four fractal dimension texture features are obtained by the 
EBFDE method. Then, we can combine these eight features to 
form a feature set denoted by fD+fE. We call this type of fea-
tures as the FD-category. Details of extracting FD-based fea-
tures from prostate images can be found in [13]. Finally, we 
combine the FD-based features with those extracted from mul-
tiwavelets, Gabor filters, and GLCM to form a set containing 
144 texture features of multi-categories for classification.  
III. CLASSIFICATION AND FEATURE SELECTION
Compared with traditional classification methods which 
minimize the empirical training error, the goal of Support Vec-
tor Machine (SVM) is to minimize the upper bound of the 
generalization error by finding the largest margin between the 
separating hyperplane and the data. The theory of non-linear 
SVM is briefly described as follows.  
Consider a training set of N samples in binary clas-
sification. Each sample is denoted by a tuple ),( ii yx ,
where Tidiii xxx ),...,,( 21=x corresponds to the feature vector for 
the ith sample ),...,2,1( Ni =  in d-dimensional space 
and }1,1{−∈iy denotes its two-class label.  
Any point x on the hyperplane must satisfy the decision 
boundary 0=+⋅ bxw , where parameter w is normal to the 
hyperplane. In practicality, a non-linear SVM is more widely 
used for the general case due to its non-linear mechanism that 
can effectively classify data which are non-separable by a li-
near SVM. A non-linear SVM can be formulated by the fol-
lowing optimization problem: 
¦+
=
N
i
ib
C
1
2
,, 2
1min ξξ ww
Subject to Niby iiii ,...,2,1,0,1))(( =≥−≥+Φ⋅ ξξxw ,      (6) 
where notation ⋅ represents the norm of a vector. In the 
above objective function, a training data ix is mapped to a 
higher dimensional space by a kernel function Φ , and penalty 
C is a user-specified parameter.  
By minimizing (1/2) 2w , we can get the maximum mar-
gin between the separating hyperplane and the data. To reduce 
the number of training errors in linearly non-separable case, 
the penalty term ¦ =Ni iC 1ξ consists of a number of positive-
valued slack variables iξ which can be used to construct a 
soft margin hyperplane. In this study, we use the one-against-
914
          
TABLE I.                                                                                                            
COMPARISONS OF THREE FEATURE SETS IN TERMS OF CCR USING SVM 
CLASSIFIER EVALUATED 5-FOLD CROSS-VALIDATION PROCEDURE
Feature Sets 
Without                
feature selection
With 
feature selection 
# of Fea-
tures  CCR (%) 
# of Fea-
tures  CCR (%) 
Multi-category-1 144 92.2 10 95.6 
Multi-category-2 136 92.2 8 92.7 
fD + fE 8 92.7 5 94.1 
REFERENCES
[1] American Cancer Society, Cancer Facts & Figures 2007. Atlanta, GA: 
American Cancer Society, 2007. 
[2] Y. Zhu, S. Williams, and R. Zwiggelaar, “Computer technology in 
detection and staging of prostate carcinoma: A review,” Medical Image 
Analysis, vol. 10, pp. 178-199, 2006. 
[3] D. F. Gleason, “The veteran’s administration cooperative urologic 
research group: Histologic grading and clinical staging of prostatic 
carcinoma,” in Urologic Pathology: The Prostate, M. Tannenbaum Ed. 
Lea and Febiger, Philadephia, PA, pp. 171-198, 1977. 
[4] K. Jafari-Khouzani and H. Soltanian-Zadeh, “Multiwavelet grading of 
pathological images of prostate,” IEEE Transactions on Biomedical 
Engineering, vol. 50, no. 6, pp. 697-704, June 2003. 
[5] J. W. Baish and R. K. Jain, “Fractals and cancer,” Cancer Research, vol. 
60, pp. 3683-3688, July 2000. 
[6] N. Sarkar and B. B. Chaudhuri, “An efficient differential box-counting 
approach to compute fractal dimension of image,” IEEE Transactions on 
Systems, Man and Cybernetics, vol. 24, no. 1, pp. 115-120, Jan 1994. 
[7] K. Fukunaga, Introduction to Statistical Pattern Recognition, 2nd ed. 
Academic, New York, 1990. 
[8] J. Novovicova, P. Pudil, and J. Kittler, “Floating search methods in 
feature selection,” Pattern Recognition 28, pp. 1389-1398, 1995. 
[9] L.-X. Shen, H. H. Tan, and J. Y. Tham, “Symmetric-antisymmetric 
orthonormal multiwavelets and related scalar wavelets,” Appl. 
Computational Harmonic Anal. (ACHA), vol. 8, no. 3, pp. 258–279, 
May 2000. 
[10] A. K. Jain and F. Farrokhnia, “Unsupervised texture segmentation using 
Gabor filters,” Pattern Recognition, vol. 24, no. 12, pp. 1167-1186, 
1991. 
[11] O. Pichler, A. Teuner and B. J. Hosticha, “A comparison of texture 
feature extraction using adaptive Gabor filtering, pyramidal and tree 
structured wavelet transforms,” Pattern Recognition, vol. 29, no. 5, pp. 
733-742, 1996. 
[12] B. B. Chaudhuri and N. Sarkar, “Texture segmentation using fractal 
dimension,” IEEE Transactions on Pattern Analysis and Machine 
Intelligence, vol. 17, no. 1, January 1995. 
[13] P. W. Huang and Cheng-Hsiung Lee, “Automatic classification for 
pathological prostate images based on fractal analysis,” to appear in 
IEEE Transactions on Medical Imaging, 2009. 
[14] T.F. Wu, C.J. Lin, and R.C. Weng, “Probability estimates for multi-class 
classification by pairwise coupling,” J Mach Learn Res., vol. 5, pp. 975–
1005, 2004. 
[15] C.-C. Chang and C.-J. Lin, LIBSVM: a library for support vector 
machines, 2001. Software available at http://www.csie.ntu.edu.tw/
~cjlin/libsvm.
[16] W.-Li Lee, Y.-Chang Chen, and K.-Sheng Hsieh, “Ultrasonic liver 
tissues classification by fractal feature vector based on M-band wavelet 
transform,” IEEE Transactions on Medical Imaging, vol. 22, no. 3, pp. 
382-392, March 2003. 
916
96年度專題研究計畫研究成果彙整表 
計畫主持人：黃博惠 計畫編號：96-2628-E-005-084-MY3 
計畫名稱：核磁共振影像之融合、切割與檢索自動化 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 3 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 7 7 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 3 3 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
