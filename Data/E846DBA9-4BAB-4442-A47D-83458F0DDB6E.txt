 1
一、 前言及研究目的 
網路搜尋引擎提供了有效率的資料搜尋功能，然而通常回傳的資料量仍很龐大，使
用者不容易了解查詢結果的概要，需要耗費許多時間瀏覽來篩選內容。此外，搜尋引擎
通常以整份文件為搜尋及回傳單位，使用者需要自行找出與所需資訊相關的文字片段。
若能對搜尋引擎找出的文件資料，擷取出與查詢相關的句子，並經過組織整理後摘要呈
現，將可讓使用者更有效率取得所需資訊。本研究計劃的目標是研發出結合資訊檢索、
自然語言處理、以及資料探勘方法，根據使用者所給定專有詞彙，從文件集中有效擷取
出包含該專有詞彙相關資訊的重要句子或段落，並依句子或段落涵蓋資訊的不同面向進
行自動組織整理的相關技術，以提供使用者從文件集中有效率取得查詢詞相關概念敘述
的摘要結果。本計畫探討的研究子題如下：1)單一專有詞彙相關句擷取方法，2)單一專
有詞彙相關句組織分群技術，3)單一專有詞彙相關句分類方法，4) 兩個專有詞彙關聯句
擷取方法，及 5)兩個專有詞彙比較句摘要方法。 
 
二、 研究方法及結果 
2.1單一專有詞彙相關句[1] 
2.1.1 研究動機 
   專有詞彙的了解對於知識學習有很大的幫助，以往問答系統的研究多採用句型比對
方法對特定名詞尋找定義解釋，此種作法將會受限於句子中必須出現該目標關鍵字，且
句子必須符合某種定義句型的寫法，其他不符合語法之重要內容將被忽略。使用者提出
這類專有詞彙之定義問題詢問，通常會希望從不同方面了解此專有詞彙，例如用途、方
法、和其他詞彙的關係等有幫助於了解該專有詞彙之相關資訊，而這些句子內容不容易
存在固定句型語法，因此必須考慮其他方法來擷取專有詞彙定義之答案句。 
2.1.2 研究方法及結果 
一) 選取候選答案句 
我們使用 IndexSearcher 來對指定索引檔進行檢索，輸入指定查詢關鍵字 Q 後，系
統以 Lucene提供之 Sort 方法對索引文件依照相關度進行評分排序，並將排序結果存放
至 Hits 物件，我們便可以由 Hits 物件中取得相關文件之排名、分數、文件編號、儲存
路徑等資訊。Lucene預設的相關度計算方法如以下算式 1： 
         RelScore(Q, d) = ∑
∈
×
Qt
tidfdttf )(),(      ………  (1) 
 其中 Q為給定之查詢關鍵字，d為索引中所對應的一個索引單位文件，t表示 Q中
的一個字。tf(t, d)為 t在 d中的字詞出現頻率(term frequency)，表示 t在文件 d中所出現
的次數。idf(t)為 t的文件頻率反比值(inverse document frequency)，以包含有 t的文件數
除以文件庫中所有文件數取倒數。 
由於與查詢關鍵字相關的答案句未必一定包含該關鍵字，與出現該關鍵字的前後句
子，或是同一頁內容中，都很可能涵蓋相關概念的解釋，因此我們分別使用以頁、以句
子、以句子及其鄰近句為單位等三種不同方式進行檢索，取出候選答案句。 
 二) 字詞權重評估方法 
 為了對抽取出的候選答案句進行評分排序，挑選出內容屬於定義解釋該專有詞彙的
句子作為答案。我們藉由查詢外部知識來源中解釋該查詢詞彙之相關文件集合，從中找
尋與查詢詞彙具有強烈相關性，特別經常出現於定義解釋該專有詞彙關鍵字之重要字
詞，並依照重要度賦予其權重。 
 本研究提出 JSD字詞權重模型(JS-Divergence term weighting model)，透過比對字彙
在檢索外部知識來源所回傳之專有詞彙相關文件集合與一般文件集合的機率分布差異
 3
答案句。Pattern作為實驗比較基準方法，以答案句之句型是否符合定義句型為基準進行
排序。Lucene作為另一個實驗比較基準方法，以 Lucene檢索系統預設之 TF-IDF值對句
子進行檢索排序。本實驗的結果如表 1所示。 
實驗結果顯示本論文研究方法所擷取之答案句品質都優於 Lucene，這是由於句子通
常最多由數十個字詞所組成，Lucene以句子為單位依 TF-IDF值進行檢索便等同於只擷
取內容有包含查詢關鍵字的句子，無法評斷整個句子的其他字詞是否與查詢關鍵字的定
義解釋有所關聯，因而容易找出包含關鍵字且句子短，但內容卻無實質定義解釋的句
子。另外，實驗結果也發現以 Page、Sentence 及 Sentence+-2 分別擷取候選答案句對不
同關鍵字的最終結果造成些微差異。Sentence+-2是一個折衷的方法，不同於 Page將整
個頁面的句子都納入候選答案句，而是將 Sentence擷取之句子及其前後鄰近兩個句子納
入候選答案句，當這些鄰近句正好是單以 Sentence 所無法找出的相關答案句，採用
Sentence+-2 之答案句選取效果果就比其他兩者還好。Pattern 方法取上述三種方法擷取
而出的答案句聯集，將結果重新以句子是否符合定義式句型為基準進行排序，反而讓實
驗結果更差。這是由於許多人工評分高的答案句並不一定符合特定定義式句型，反之也
有許多符合定義式句型的答案句人工評分分數較低，表示其內容對於了解該專有詞彙的
定義解釋幫助不大，因此造成排序結果表現較差。 
 實驗結果顯示以三種索引方式擷取答案候選句所得之答案句品質平均效果差異不
大，皆比 Pattern及 Lucene表現好上許多，這個實驗結果驗證了我們的研究方法的確能
夠有效擷取出正確的答案句。使用者亦可以自行設定所希望擷取的電子書來源，能夠針
對領域的不同而彈性更換答案擷取來源及外部知識來源。 
 
2.2單一專有詞彙相關句組織分群技術[2] 
2.2.1 研究動機 
以單一專有詞彙相關句所述方法處理後，系統便已取出答案句排序清單，並擷取出
前 25 個答案句。然而這些答案句涵蓋的概念可能相似或相異，比如同為定義解釋
"clustering"之答案句，可能有些內容在解釋各式分群演算法，有些內容在解釋分群之用
途，有些內容在解釋如何實驗驗證比較分群結果。因此，除了找出答案句之外，我們希
望能夠再進一步將答案結果進行自動整理，讓答案句能夠依照概念主題進行分群，讓使
用者能夠更快速掌握重點資訊。 
2.2.2 研究方法 
進行資料分群以前，我們必須要先提供各筆資料之間的距離或相似度計算方法。以
往文件分群多以文件為單位進行相似度計算及分群，一筆文件中包含較多字詞。但我們
要對句子進行分群，大部分的句子最多包含數十個字彙，若單以字詞比對來計算句子的
相似度，語意及概念類似的句子若採用不同用字遣詞將會判斷為不相似，無法達到有效
的句子分群。 
 為解決上述問題，我們使用維基百科作為外部知識來源來計算兩字詞 ti 與 tj 的
WikiDice(ti, tj)值來表示其語意關聯度。由該定義，以兩字詞分別向維基百科進行查詢，
由查詢某一字詞之相關文件中，計算另一字詞之出現頻率。當兩字詞互相於對方之相關
文件中頻繁出現，就代表兩字詞關聯性越高，所得WikiDice語意關聯度也會越高。 
我們定義單一字詞 t對應至一個句子 s之相似度為WSSim(t,s)，其計算方式如下： 
WSSim(t,s) = }|),(max{ stttWikiDice ii ∈   ………  (4) 
兩句子之相似度則由兩句子中各字詞與另一句子的 WSSim 相似度計算平均值如下：  
 5
而其他有許多應屬同一群卻因為相似度限制未達門檻值而被視為雜訊的句子會造成
Concentration值低落。因此， DBSCAN能夠有效對彼此很相似的句子進行正確分群，
但是應該要有其他的方法來對被視為雜訊的句子再進行分群。 
Agglomerative Hierarchical Clustering 演算法的實驗結果與 DBSCAN相近，Purity值
多次都達到最高值 1，但略低於 DBSCAN，Concentration值普遍表現低於其他方法，但
略高於 DBSCAN。這是由於 Agglomerative Hierarchical Clustering會優先將相似度最高
的句子合併為一個群，能夠被分為一群的句子彼此相似度較高，因此 Purity值相當高。
而其他相似度較低的句子則無法被併入其他群中，形成孤立群，無法進行正確分群，因
此 Concentration值低落。若再繼續進行分群，則可能將所有聚落都合併為一群，而失去
分群意義。相對於 DBSCAN 演算法，由於 Agglomerative Hierarchical Clustering不需設
定相似度門檻值，原於 DBSCAN 中相似度未達門檻值的句子仍能被合併至最相似的群
中，能夠將較多的句子進行分群，被視為雜訊的句子數量較 DBSCAN 少，但同時也有
比較高的機會將句子錯誤分群，因此 Purity 值略低於 DBSCAN，而 Concentration 值則
略高於 DBSCAN。 
 總結以上實驗結果，Bisecting K-means 及 K-means 演算法能夠在 Concentration 及
Purity 中取得一個較為平衡的結果，適合用於多數一般情況。而 DBSCAN 及
Agglomerative Hierarchical Clustering 則是能夠達到更好的 Purity 值，但是會導致
Concentration值表現較差，適合用於需要考量分群結果之高純淨程度的情況。 
 
2.3單一專有詞彙相關句分類方法[3] 
2.3.1 研究動機 
此部份的研究目標是將第一部份研究找出之專有詞彙相關句，依據解釋專有詞彙時
經常使用之分類項目，將解釋句分類整理成具有主題性架構的解釋頁面，方便學習者依
照主題的不同，對該專有詞彙之各面向概念有所了解，以增進學習者對專有詞彙的瞭解。 
2.3.2 研究方法 
本研究採用三種解釋專有詞彙時經常使用之分類項目：概述(Overview)、詳細描述
(Detail Description)以及用途(Usage)，查詢專有詞彙找出的相關解釋句將依此三項分類項
目做為分類基準，三項分類項目之定義如下： 
1. 概述: 概述句為專有詞彙的概括性簡述，此類句子大多出現在維基百科解釋頁首句。 
2. 詳細描述: 詳細描述為專有詞彙的特性說明，此類句子用來進一步說明專有詞彙本身
或其構成元件的特性，描述其具有能力及特徵，能提供專有詞彙本身或其構成元件
的知識性敘述。 
3. 用途:用途句為描述專有詞彙可被應用之範圍，亦即可被用在某個領域或常被用來做
某種用途。 
在蒐集三項分類項目的解釋句後，我們將各句子進行句型樣式擷取，並統計樣式中
出現的詞彙頻率，儲存在句型樣式資料庫中作為分類特徵，處理過程如下所述。 
1) 句型樣式擷取: 本工作的目標是從句子取出一般化之句型樣式，包含三個步驟：首先
對訓練資料進行詞性標注；接下來選擇特殊字詞取代成詞性標注的符號；最後以專有詞
彙為基準點，取出句子中出現查詢專有詞彙位置之前後K 個字詞或標注符號成為一個句
型樣式。 
2) 統計樣式詞彙出現頻率: 我們以句子中出現查詢專有詞彙之位置取出前後 n 個字形
成一個詞彙樣式，共有2n個位置，我們統計每個位置出現不同字詞或標注符號的次數，
也就是單一詞彙在每個位置的出現頻率，並統計每個相鄰位置出現詞彙組合的次數。 
本研究分別採用貝式分類器以及支持向量機分類器對解釋句進行分類。 
一) 以語言模型為基礎的貝式分類模型 
 7
2.4兩個專有詞彙關聯句擷取方法[4] 
2.4.1 研究動機 
使用者即使有一個很好的資訊檢索工具，若是想了解兩個專有詞彙有何關聯時，一
次只能輸入一個專有詞彙查詢出相關句，需要自行整理後才能夠瞭解兩個詞彙彼此的關
聯性或其具有相同相異的概念比較。因此本研究的目的是針對特定專業領域的電子書為
文件集，根據讀者輸入的兩個專有辭彙作為查詢詞彙，先對查詢詞彙間的關係進行自動
分類，再依據分類結果進行可描述這兩個專有詞彙關聯性的句子擷取，或是進行下一部
分研究所探討的專有詞彙比較句摘要。 
2.4.2 研究方法 
我們首先將查詢詞彙關係分為兩大類語意關係：”包含”關係和”非包含”關係。第一
部分探討如何對於輸入的兩個查詢詞彙關係進行自動語意關係分類，第二部分則探討如
何根據詞彙關係的不同，找出具”包含”關係的兩個查詢詞彙之詞彙關聯句，或是找出” 
具非包含”關係的兩個查詢詞彙之詞彙比較句組。 
一) 查詢詞彙關係自動分類方法 
由使用者給定的兩個查詢詞彙Q1及Q2，我們利用網路搜尋引擎個別搜尋Q1及Q2，由
其回傳結果的網頁摘要，相互統計在其中一個查詢詞彙網頁摘要中出現的另一個查詢詞
彙的分布情況當作分類特徵值。 
首先我們計算在Q1或Q2網頁摘要中同時出現兩個字的機率作為第一個分類特徵
值，如以下算式9，此算式所得之值可代表Q1和Q2的語意關聯程度。 
CoOccur(Q1, Q2) = (|snippet(Q2| Q1)| + |snippet(Q1| Q2)|) / (|snippet(Q2)| + |snippet(Q1)|) ... (9) 
其中snippet(Qi)表示以Qi為關鍵字查詢出的前k篇網頁摘要所成的集合，以下稱為i的網頁
摘要集。|snippet(Qj| Qi)| 表示Qi網頁摘要集內出現Qj的網頁摘要篇數。 
另外我們考慮分類特徵值考慮關聯規則1→2的信賴度值(confidence)，如算式10。 
Conf(Q1→Q2)= |snippet(Q2| Q1)|/ |snippet(Q1)|  ....... (10) 
由於Q1和Q2順序不同會造成Q1→2信賴度值的不同，我們利用算式11挑選出Q1→Q2及
Q2→Q1兩者信賴度值較高的規則之信賴度值，再利用算式12挑選信賴度值較低的規則之信
賴度值，做為兩個分類特徵。此外，我們計算Q1→Q2及Q2→Q1兩者信賴度值的差距，也就
是將兩個信賴度值相減，如算式13所示，分別做為一個分類特徵。 
(Q1, Q2)={C(Q1→Q2), C(Q2→Q1)} ……… (11) 
(Q1, Q2)={C(Q1→Q2), C(Q2→Q1)} ……… (12) 
_(Q1, Q2)=(Q1, Q2) −(Q1, Q2) ……. (13) 
最後一個分類特徵則是考慮在Q1網頁摘要集內沒有出現Q2的篇數以及Q2網頁摘要集內沒有
出現Q1的篇數，將篇數較少的放在分母，篇數較多的放在分子計算比值，如算式14所示。
此外為了避免零值的情況，我們採用了Laplace smoothing的方式。 
t_i_ (1,2)= δ
δ
+¬¬
+¬¬
|})|(||,)|({|
|})|(||,)|({|
2112
2112
QQsnippetQQsnippetMin
QQsnippetQQsnippetMax
 ……. (14) 
利用蒐集的訓練字組，我們根據函式"# 、、、_、
t_i_ 的特徵值形成特徵向量，並給定訓練字組已知的分類關係，輸入 SVM 分類
模型建立詞彙關係分類模型。當使用者輸入兩個查詢詞彙後，系統便會依照上述處理步驟，
蒐集個別網頁摘要集，擷取出分類特徵，利用詞彙關係分類模型對於輸入的兩個查詢詞彙
關係進行自動分類。 
二)關聯句挑選方法 
當查詢詞彙關係被分類成包含關係後，我們採用語句檢索系統擷取出同時包含兩個查
詢詞彙的句子 sen(1,2)，接下來是必須從中自動選出關聯句，幫助使用者瞭解兩個查詢詞
彙的關聯。處理過程包括敘述句型樣式擷取、建立關聯句比對規則模型及關聯句選取方法。 
為了對關聯句的句型樣式進行學習，我們對於同時包含兩個查詢詞彙的句子，經過詞
性標記方法處理後取出句子中一般化的句型樣式。為了避免過多不同的詞性符號導致不容
 9
(1) Noun+：單一名詞，或是多個名詞組成的複合名詞。 
(2) Adj (Vbg | Noun)+：形容詞後接著一個或多個名詞或是動名詞。 
(3) Det(Vbg | Noun)+：定冠詞後接著一個或多個名詞或是動名詞，由此規則找出之概
念詞會去掉定冠詞。 
一個句子s中符合上述規則的字詞皆會被擷取出，稱為 s 的概念詞集，以sen_Concept(s)
表示。 
我們對 sen(Q1)中每個句子的概念詞集進行聯集，得到 Q1 所有概念詞集
_(1)；以同樣的方法，得到 Q2所有概念詞集_(Q2)。兩個共同
概念詞集取交集後，再去掉 Q1及 Q2兩個查詢詞彙，剩下的字詞所成的及合稱為兩個查詢
詞彙的共同候選概念詞集 candidate_C(Q1, Q2)。 
接下來我們會對共同候選概念詞集進行三個階段的篩選處理：1) 在整個資料來源中，
包含有候選概念詞 Ci的句數小於門檻值者，我們認為是語意不明顯的字詞，而予以刪除。
2)我們認為一個共同概念詞 Ci與兩個查詢詞彙 Q1及 Q2出現要有正相關性，因此去除與任
一查詢詞彙的MI值小於等於零的候選概念詞。3) 計算出*# +,)(Q1, Q2, Ci)= -(1,) 
∗-(2,)。若是重複率 overlap(C1, C2)大於等於一個指定值α(在此將α設為 0.8)，我們將刪
除 queryRel(Q1, Q2, Ci)值較小的概念詞 Ci。剩下的共同候選概念詞集我們稱為高度相關的共
同概念詞集 highSemantic_C(Q1,Q2)。 
找出 highSemantic_C(Q1,Q2)後，我們對各個共同概念詞選出關聯句組。對於一個共同
概念詞 C，我們由 sen(Q1,C)和 sen(Q2,C)中各挑出一句 s1 及 s2 建立關聯句組(s1,s2)，並進
行以下評估計算。 
(1)評估句子和共同概念詞相關程度 
對於sen(Qj,C)中的每一個句子s (j=1 or 2)，我們取出句子概念詞集sen_Concept(s)中每一個概
念詞，計算共同概念詞C和句中各個概念詞Ci的Dice(C,Ci)後取幾何平均數得到con_rel(C)。 
(2)句子和句子間關聯度評估方法 
接下來我們將sen(Q1, C)中每一個句子s1，和sen(Q2, C)中每一個句子s2進行句組配對。計算
句子s1中每個概念詞和句子s2中每個概念詞Cj兩兩配對，計算概念詞配對Ci和Cj 間的Dice
值後，取各配對Dice值的幾何平均數得到senpair_rel(s1, s2)。 
最後我們將上述兩個算式_,)(,')及' _,)('1,'2)以ω及1−ω進行比重加
總，其中0<ω<1，算出repDegree(C, s1, s2) ，選出 / (,'1,'2)高的句組做為專有詞
彙比較代表句。 
(二) 產生擴展段落 
 我們另採用動態的方式，產生查詢詞 Qi在共同概念詞 C 下的比較代表句 s 之擴展段
落。首先評估 s 其立即上下句的語意關聯度，若語意關聯度大於設定的門檻值，再繼續評
估其他上文的句子或其他下文的句子之是否可加入擴展段落。令θ1表示s 的立即上句
PreSen(s)與 s 之語意計算出的語意關聯度，且 expPreSenList(s) 為已被選出作為 s 之上文
擴展段落之句子所成的集合。則我們限制 expPreSenList(s)與 PreSen(s)的平均語意關聯度必
須大於θ1×0.95，以確保擴展段落中句子的語意相關性。擴展下句的產生方法亦採取相同的
做法進行。 
2.5.3 實驗評估 
此部分實驗的目的是評估本系統挑選出的比較代表句組，是否能夠幫助使用者了解查
詢字組間在不同概念上相同或相異處。本實驗找了三位對於演算法領域熟悉的研究生作為
受試者，對40組查詢詞彙回傳之比較代表句組評定為”有幫助”或是”無幫助”。 ”有幫
助”計1分，”無幫助”則計0分。 
本研究對每組查詢詞組分別採用兩種方法選出top 5的比較代表句組，方法如下： 
1) Method 1：由highSemantic_C(Q1,Q2)中各概念詞的*# +,)(1,2,)值，取前5名高的
概念詞建立對應的比較代表句組。 
2) Method 2：由各概念詞下的句子'1和其他句子'2形成的各句組計算repDegree(,'1,'2)
出席國際學術會議心得報告 
計畫編號  100-2221-E-003-024- 
計畫名稱   專有詞彙相關句搜尋及摘要技術之研究 
出國人員姓名 
服務機關及職稱 
  柯佳伶  
  臺灣師範大學資訊工程系 副教授 
會議時間地點   Valencia, Spain, May 16-19, 2012. 
會議名稱 
 The IEEE Sixth International Conference on Research Challenges in 
 Information Science (RCIS 2012) 
發表論文題目 
A Multi-level Hierarchical Index Structure for Supporting Efficient 
Similarity Search on Tag Sets 
 
一、參加會議經過 
RCIS 研討會是由 IEEE 歐洲地區分會贊助舉辦的年度國際學術研討會，研究會涵蓋主題
以資料庫、資訊及網際網路系統、智慧代理人、知識管理、資料探勘、ontology 等技術及應
用為主，今年是第六屆，由瓦倫西亞大學主辦，於 5月 16日至 19 日，在西班牙瓦倫西亞 Beatriz 
Rey Don Jaime旅館舉行。 
RCIS 會議的規模不會很龐大，是屬於小而美的國際研討會，該會議總共只接受了 40 篇  
papers及 9篇 poster papers，因此同時間最多只有兩個 sessions 同時進行，使得參與會議的人
員較為集中，也較能引發熱烈的討論。在 5月 16日到 5月 19 日三天的議程中，共安排了 12
場論文發表 sessions、三場 keynote speech、以及五場 tutorial 課程。我的論文被安排於 5 月 16
日，會議第一天開幕式及 keynote speech 後上午第二個 session 中的第三位發表。我此次被接
受及發表的論文: A Multi-level Hierarchical Index  Structure for Supporting Efficient Similarity 
Search on Tag Sets。近來社群網站已成為網際網路中一種重要的服務，它提供使用者很方便分
享他們的資料及資訊。為了提供社交標籤系統中標籤集合有效率的查詢，在此論文中我們提
出一個多層的階層式索引結構，可用來增進標籤集合相似查詢的處理效率。我們根據一個先
前提出對交易資料庫進行相似查詢處理的方法，將標籤集合漸進加入形成聚落，並運用兩層
的邊界過濾篩選技巧，減少必須一一比對檢查所有標籤集合的計算成本。我們還提供可對所
建立的索引結構刪除及更新標籤集合的處理方法，以因應資料標籤集可能的動態變化。在我
們提出的方法中，一個聚落還可形成更小的子聚落，成為多層的階層式聚落，而葉節點聚落
中包含相同標籤數目的標籤集合再形成 batches。我們使用三個參數，控制此索引結構中每一
層次聚落中標籤集合間的相似程度。此外，我們的方法中限定同一聚落中的標籤集要至少具
有一個共同標籤，以避免將一些標籤個數少且彼此毫無關聯的標籤集合儲存在同一聚落中。
此外，我們對標籤集合定義了一個新版的 hamming distance 計算函式，將兩個標籤集合中各
標籤相互間的語意相關程度列入集合相似度計算的考慮，使其用在標籤集合的相似搜尋更有
效。實驗結果顯示我們提出的 MHIB方法比先前提出的方法，在搜尋空間有更好的篩選效果。 
    瓦倫西亞是西班牙第三大城，除了有一個小巧的古城區，最特別的是它在城市舊河床上
新開發建設的藝術科學城，有好幾棟設計前衛創新的建築，歌劇院、天文館、科學館、海洋
公園等，結合建築、天空、與水反射所形成的藝術感與美感，令人印象深刻。將一個城市塑
造自己的文化特色，不但提升居民的生活品質，也讓外人對這個城市有正向觀感。近來西班
牙爆發債務危機，在瓦倫西亞街頭也看到了零星民眾抗議遊行，警察武裝警戒的情景。歐債
危機在這兩年一直牽動著全球金融及經濟，希望台灣有充分的因應措施，以減少歐債對台灣
社會民生的衝擊。 
 
2 
 
----------------------- REVIEW 1 --------------------- 
PAPER: 5 
TITLE: A Multi-level Hierarchical Index Structure for Supporting Efficient Similarity Search on Tag Sets 
AUTHORS: Jia-Ling Koh, Nonhlanhla Shongwe and Chung-Wen Cho 
 
This paper provides an efficient similarity search of tag set in a social tagging system and it proposes a 
multi-level hierarchical index structure to group similar tag sets. There are presented the algorithms of 
similarity searches of tag sets and algorithms of deletion and updating of tag sets. It is defined a modified 
Hamming distance function on tag sets. There is studied a systematic performance study to verify the 
effectiveness and the efficiency of proposed strategies. 
 
 
----------------------- REVIEW 2 --------------------- 
PAPER: 5 
TITLE: A Multi-level Hierarchical Index Structure for Supporting Efficient Similarity Search on Tag Sets 
AUTHORS: Jia-Ling Koh, Nonhlanhla Shongwe and Chung-Wen Cho 
 
This paper proposes a structure for an index that can group similar tags together in  tagging datasets. It 
also proposes a modified hamming distance function to determine similarity of tag datasets using this 
hierarchical index. The authors have reported on  a performance evaluation using tags collected from 
Flickr (a  photo website with tags).  
It would be good to show a comparison with best of the breed semantic similarity algorithms.  
The paper is well written and appears to be well motivated. The index structure and the similarity function 
are interesting. 
 
 
----------------------- REVIEW 3 --------------------- 
PAPER: 5 
TITLE: A Multi-level Hierarchical Index Structure for Supporting Efficient Similarity Search on Tag Sets 
AUTHORS: Jia-Ling Koh, Nonhlanhla Shongwe and Chung-Wen Cho 
 
The paper "A Multi-level Hierarchical Index Structure for Supporting Efficient Similarity Search on Tag Sets" 
presents an index structure for answering similarity queries on tag sets, as well as the "modified hamming 
distance" distance measurement function for tag sets.  
 
The paper is well written and motivated, and explains clearly how both index structure and measurement 
function work. The proposed index structure also seems to perform quite well, however, the structure 
seems to be a rather minor improvement of the techniques presented in [6]. If this is not the case, it would 
be beneficial if the authors further elaborate on their additional contribution. 
 
In contrast, the modified hamming distance approach seems to be quite ad-hoc, and assumes that 
"semantic relatedness" of tags directly follows from occurrence correlation. While this assumption 
probably holds some truth, further evaluation of the semantic performance are definitely required (i.e. 
does this assumption indeed capture semantic relatedness, or is it off the mark more often than not). Here, 
comparisons with other "semantic similarities" or at least some case studies should be presented. 
 
Also, the charts presented in the evaluation section should be improved as they look rather unprofessional. 
The resolution is low, font sizes randomly vary, and many axes lack proper labels. 
 
 A Multi-level Hierarchical Index Structure for 
Supporting Efficient Similarity Search on Tag Sets 
Jia-Ling Koh and Nonhlanhla Shongwe 
Department of Computer Science and  
Information Engineering  
National Taiwan Normal University  
Taipei, Taiwan 
jlkoh@csie.ntnu.edu.tw 
Chung-Wen Cho 
Cloud Computing Center for Mobile Applications Industrial 
Technology Research Institute  
Hsinchu, Taiwan 
chungwen.cho@gmail.com 
 
 
Abstract—Social communication websites has been an 
emerging type of a Web service that helps users to share their 
resources. For providing efficient similarity search of tag set in 
a social tagging system, we propose a multi-level hierarchical 
index structure to group similar tag sets. Not only the 
algorithms of similarity searches of tag sets, but also the 
algorithms of deletion and updating of tag sets by using the 
constructed index structure are provided. Furthermore, we 
define a modified hamming distance function on tag sets, 
which consider the semantically relatedness when comparing 
the members for evaluating the similarity of two tag sets. This 
function is more applicable to evaluate the similarity search of 
two tag sets. A systematic performance study is performed to 
verify the effectiveness and the efficiency of the proposed 
strategies. The experiment results show that the proposed 
MHIB approach further improves the pruning effect of the 
previous work which constructs a two-level index structure. 
Especially, the MHIB approach is well scalable with respect to 
the three parameters when using either the hamming distance 
or the modified hamming distance for similarity measure. 
Although the insertion operation of the MHIB approach 
requires higher cost than the naïve method, with the assistant 
of the constructed inverted list of clusters, it performs faster 
than the previous work. Besides, the cost of performing 
deletion operation by using the MHIB approach is much less 
than the other two approaches and so is the update operation. 
Keywords: Social tagging;index structure;similarity search. 
I. INTRODUCTION  
Social tagging has became widely popular in various 
applications, such as photo-sharing sites (e.g Flickr), video-
sharing sites (e.g. YouTube), and social bookmarking sites 
(e.g. CiteULike and Delicious). Social tagging systems 
enable users to freely annotate web resources of interest with 
tags for describing the content or semantics of the resources.  
Besides, a resource can be tagged by more than one tag. It is 
also possible that a tag is used to label different resources. 
These tags can be used to search the web resources by users 
conveniently.  
In general, if two web resources are assigned the similar 
sets of tags, we believe that they should be semantics-related. 
Instead of comparing the content of web resources, the 
similarity measure of tag sets provides a good way of finding 
similar resources, which is an essential operation required to 
support resource recommendation. However, the amount of 
various tag sets in a social tagging system is usually huge. 
Accordingly, providing efficient similarity search on tag sets 
is a critical problem in a social tagging system.  
Given a set of tags as a query, a distance measure 
function, and a query threshold, the goal of a similarity 
search is to find all web resources whose tag sets have 
distances with the query less than the given query threshold. 
To efficiently find the semantics related web resources with 
a given tag set, there is a need for constructing an index 
structure of web resources according to their tag sets. The 
goal of the index structure is well organizing the web 
resources to provide efficient similarity searches of tag sets.  
A transaction in a supermarket database indicates the set 
of items purchased by a customer. For a given transaction of 
a customer, the similar transactions of other users found from 
the transaction database can be selected as recommend items 
that the customer may be interested. Similarity search in a 
transaction database thus becomes one of the important 
techniques for data analysis in data mining [1]. Let the set of 
tags given to a web resource correspond to a transaction, the 
indexing method for supporting similarity search on a 
transaction database is thus applicable for providing 
similarity search of tag sets on a social tagging system. 
A method called the two level bounding mechanisms was 
proposed in [6], which is a novel indexing method to support 
similarity search in a dynamically updated transaction 
database. The incoming transactions are incrementally 
grouped into clusters. Each cluster is characterized by two 
features: the outer border and the inner border, where the 
outer border and inner border is the union and the 
intersection of all the transactions in the cluster respectively. 
The cardinality of the set difference between the two borders 
is used to evaluate the similarity among the transactions in a 
cluster. In each cluster, the transactions are further grouped 
into sub-clusters called batches. All the transactions are thus 
organized as a two-level index structure where the distance 
between each pair of transactions in a cluster is bounded by a 
given cluster threshold. To the best of our knowledge, the 
two level bounding mechanisms are better than most of the 
other approaches in dealing with the similarity search 
problem on transaction databases. However, this approach 
has some drawbacks for improvement. First, there is no 
limitation on the inner border of a cluster. Consequently, it is 
possible that a set of small and disjoint transactions are 
grouped into a cluster when the cardinality of their union is 
The similarity function measures the degree of similarity 
between two objects, which returns a similarity value in [0, 
1]. A higher similarity value of objects indicates that they are 
more similar to each other.  
There are a number of similarity functions that can be 
used to evaluate the similarity between two objects 
consisting of sets of feature tokens, such as Jaccard similarity, 
cosine similarity, and overlap similarity [17]. Jaccard 
similarity is commonly used to evaluate the similarity of 
categorical data. Given two sets of tokens S1 and S2, the 
jaccard similarity between S1 and S2 is defined as 
Jacc_sim(S1 ,S2) = (|S1⋂S2| / |S1⋃S2|). Jaccard similarity 
was used in [17] to perform duplicate detection of web 
documents. In [2], the author studied the asymmetric version 
of Jaccard similarity to provide indexing strategy for Jaccard 
containment similarity function. In [3] , both the hamming 
distance and Jaccard similarity function were used to identify 
all pairs of sets that are highly similar for performing a set-
similarity join. On the other hand, from a sparse set of 
vectors, the cosine similarity is used in [4] to find all pairs of 
vectors whose similarity score is above a given threshold. 
Also consider the various similarity functions of sets, instead 
of giving a query threshold, [16] considered the problem of 
finding the top-k pairs of records ranked by their similarities.  
C. Index Structures for Similarity Search of Objects 
For providing efficient similarity search of objects 
consisting of sets of tokens, it is necessary to design an index 
structure used for effectively pruning the search space when 
processing a query. The concept of signature has been 
widely used in the studies of index strategies for market 
basket data or sets and categorical data, such as [1], [4], [9], 
[11], [13]. The index strategies using signatures are mainly 
classified into signature table approaches and signature tree 
approaches. 
The signature table approach [1] first partitions all the 
items in the transaction database into K groups of frequently 
correlated items. Then a bit vector with K bits is used to 
represent a transaction, where each bit is associated with one 
of the K groups of items called vertical signatures. If a 
transaction contains a sufficient number of the items in a 
group, the corresponding bit of its signature is set to 1. 
Otherwise, the bit is set to 0. Accordingly, the transactions 
are hashed into a signature table consisting of 2k entries 
according to their signatures. By comparing the signatures of 
the query and each signature table entry, the estimated lower 
bound of the distance between the query and the transactions 
hashed into the entry is used to prune the search space for 
finding similar transactions. Therefore, this approach 
performs efficiently for nearest neighbor search queries. 
Instead of grouping correlated items globally to form vertical 
signatures, [8] considered the problem that different subsets 
of the data may have different data distribution and proposed 
the localized signature table for blocks consisting of highly 
related transactions. However, the performance of the SG-
table approach is sensitive to various parameters which have 
to be tuned in advance. Besides, the highly correlative sets of 
items, which determine the vertical signatures of the 
signature table, may change from time to time. Accordingly, 
the SG-table approach is not suitable for a dynamic database.  
The signature tree was proposed in [9], which is a 
dynamic balanced tree similar to an R-tree for maintaining 
the signature vectors. For a leaf node entry in the signature 
tree, it contains the signatures of transactions within a disk 
page and their transaction ids. Each internal node contains a 
number of entries and each entry contains a signature and a 
pointer linking to a child node, where the signature is the 
logical OR of all the signatures in the child node. A signature 
representation method and algorithms were proposed in [11] 
to guarantee getting the complete results for similarity 
searching in transaction databases. Although the R-tree based 
approach provide the flexibility of index updates, this 
approach has several disadvantages. First, for the internal 
nodes at a higher level, more transactions contained in their 
sub-trees results in most bits in their signatures are 1. 
Consequently, it is not distinguishable whether the 
transactions stored in the descendants of the node are similar 
to the query. Besides, the time complexity of processing 
node splitting in the tree structure is high.  
    For providing efficient similarity search in a transaction 
database which is frequently updated, [6] proposed an index 
structure where the similar transactions are grouped into 
clusters and the transactions in a cluster are divided into 
disjoint groups called batches. When processing a similarity 
search for a given query, the lower bound and upper bound 
on distance between the query and the transactions assigned 
within a cluster can be estimated according to the recorded 
information. Consequently, if the estimated distance lower 
bound is larger than the query threshold or the upper bound 
is less than the query threshold, it implies that all 
transactions in the cluster can be pruned or all transactions 
are similar to the query without actually computing their 
distances to the query. The strategy is also applicable for the 
batch level.  The experiment results show that this approach 
performs more efficiently than the SG-Tree approach [9] on 
the execution times of similarity search and index updating. 
D. Two-level Bounding Mechanism  
One goal of our work is to further improve the indexing 
strategy previously proposed by [6], which is provided for 
supporting similarity search in transaction databases. 
Therefore, we briefly introduce the method in this section. 
Let I = {i1, i2, …, im} denote the set of items in a specific 
application domain. Let TDB denote a database of 
transactions, where each transaction Ti in TDB is a non-
empty subset of I. In [6] the transactions in TDB are 
incrementally grouped into clusters. Each cluster C in the 
index structure is characterized by two features, the outer 
border of C and the inner border of C, denoted as C.Co and 
C.Ci, respectively. The C.Co stores the union of all the 
transactions in cluster C and C.Ci stores the intersection of 
all the transactions in cluster C. Thus, C.Ci is a subset and 
C.Co is a superset of each transaction in the cluster C, 
respectively. The difference of a transactions Ti with respect 
to another transaction Tj is denoted as diff(Ti, Tj), which is 
defined to be |Ti - Tj|. Furthermore, the hamming distance is 
III. A MULTI-LEVEL HIERARCHICAL INDEX STRUCTURE 
WITH BOUNDING MECHANISM   
We propose a multi-level hierarchical index structure 
which supports the similarity search of sets. Here, we assume 
that the main application scenario is for indexing the tag sets 
in a social tagging system. Similar to the index structure 
proposed in [6], the tag sets are grouped into clusters. 
However, a cluster can have sub-clusters. The tag sets in a 
leaf-cluster are further grouped into batches.  
A constructing algorithm of the multi-level hierarchical 
index structure is provided for inserting the tag sets of the 
objects in a database into the index structure. Once a query is 
given, we apply the two level bounding mechanisms to 
search the index structure and return the objects having 
similar tag sets with the query efficiently. In addition, in 
order to support dynamic updates of the database, we also 
propose the necessary algorithms for maintaining the index 
structure, which includes deletion of existing tag sets, 
insertion of new tag sets, and updating of existing tag sets. 
The details of the proposed index structure and processing 
algorithms are introduced in the following subsections. 
A. Terms Definition  
Let WDB denote a database of web resources, where each 
object Oi in WDB has a set of annotated tags, denoted as 
Oi.tagset. The proposed multi-level hierarchical index 
structure organizes the sets of tags for all the objects in WDB 
into a forest-like structure, where each tree corresponds to a 
cluster. Let C denote a cluster in the index structure, which is 
characterized by two features: the outer border of C and the 
inner border of C, denoted as C.Co and C.Ci, respectively. 
The C.Co stores the union of all the transactions in cluster C 
and C.Ci stores the intersection of all the transactions in 
cluster C.  
The similarities of the tag sets stored within a cluster C is 
controlled by limiting the maximum distance between its 
outer border(C.Co) and inner border(C.Ci). Here, the 
distance between two tag sets Ti and Tj are evaluated by 
computing dist(Ti, Tj). 
We define two different thresholds to control the 
similarity of the tag sets within the clusters at different levels.  
1) maxd_root: It is used to limit the maximum distance 
between the outer and inner borders of a cluster C at the root 
level in the index structure.  
2) maxd_leaf: It is used to limit the maximum distance 
between the outer and inner borders of a cluster C at the leaf 
level in the index structure.  
In the cluster at the leaf level, the tag sets are further 
grouped into batches. Let B denote a batch in the index 
structure, which is also characterized by two features: the 
outer border of B and the inner border of B, denoted as B.Bo 
and B.Bi, respectively. The B.Bo stores the union of all the 
transactions in cluster B and B.Bi stores the intersection of all 
the transactions in cluster B. Therefore, we defined the third 
threshold value maxd_batch to the maximum distance 
between the outer and inner borders of a batch B. 
B. Index Structure Construction 
In this section, we will explain how the index structure is 
constructed for the given tag sets of the dataset WDB.  
1) Index Construction . 
    Initially, the index structure is empty. The process of 
index construction is to insert the tag set Oi.tagset into the 
index structure for each object Oi in WDB one by one. 
Let Ti denote Oi.tagset. When inserting a tag set Ti into 
the index structure, first, we have to check if the tag set 
already exists in the index structure. The checking is 
performed by the searching strategy introduced later. If the 
tag set Ti is found from the index structure, it means that 
there exists another object in WDB annotated with the same 
set of tags. Therefore, the address of the object Oi is added 
into the object list of the tag set in the index structure. If the 
tag set Ti is not in the index structure, it is necessary to find a 
cluster or create cluster for inserting Ti into.  
For a cluster C at the root level (first level) of the index 
structure, Ti is allowed to be inserted into C if C.Ci∩Ti≠ φ 
and dist(new_Co, new_Ci) ≤ maxd_root, where new_Co = 
(C.Co∪Ti) and new_Ci = (C.Ci∩Ti). In other words, the 
distance between the new outer border and inner border of C 
after inserting Ti still satisfies the maxd_root constraint. 
Besides, because the inner border of each cluster is required 
to be non-empty, it prevents a set of small and disjoint 
transactions being grouped into a cluster. 
If there were a number of clusters at the root level the tag 
set Ti can be inserted into, we will choose the cluster Cbest 
which has the smallest difference between the new two 
borders after inserting Ti. Ti is inserted into cluster Cbest and 
the borders of Cbest are updated as Cbest.Co = (Cbest.Co∪Ti) 
and Cbest.Ci = (Cbest.Ci∩Ti). If the cluster Cbest has sub-
clusters, the similar processing is performed recursively to 
find a sub-cluster of Cbest for inserting Ti until Ti is inserted 
into a cluster at the leaf level.  
Let Cleaf denote the cluster at the leaf level that Ti is 
inserted into. According to the cardinality of Ti, Ti is inserted 
into the corresponding batch under Cleaf. If the batch does not 
exist, a batch B is created to store Ti, whose difference-value 
pair is set to be (dist(Cleaf.Co, Ti ), dist(Ti , Cleaf.Co)). Besides, 
both the borders of Cleaf and B are updated as follows: 
Cleaf.Co = (Cleaf.Co∪Ti) and Cleaf.Ci = (Cleaf.Ci∩Ti); 
B.Bo = (B.Bo∪Ti) and B.Bi = (B.Bi∩Ti). 
The two borders and the difference-value pairs of the other 
batches under this cluster are also updated accordingly. 
After inserting Ti into Cleaf, the cluster Cleaf is checked if 
diff(Cleaf.Co, Cleaf.Ci) is greater than maxd_leaf. If the 
insertion of Ti into Cleaf  making Cleaf violates the maxd_leaf 
constraint, the splitting algorithm described in the next 
subsection is performed.  
If there is no cluster at the root level which Ti can be 
inserted into, a new cluster C’ is created. Ti is inserted into 
cluster C’ and the borders of C’ are C’.Co= Ti and C’.Ci = Ti. 
Besides, a batch B’ under the cluster C is created for storing 
clusters at the root level. Therefore, the inverted list is also 
applicable for speeding up the searching of tag set when the 
query threshold δ is zero. The detailed processing methods of 
searching and deletion operations are described as the 
following subsections.  
4) Similarity Search Operation  
Given a query Tq which consists of an non-empty set of 
tags and a specified query threshold (δ), the searching 
algorithm is used to find the objects in WDB where the 
distances between their tag sets and Tq are less than or equal 
to δ. When the given search threshold (δ) is small, it means 
that the user is interested in the objects with highly similar 
tag sets to the query. If the search threshold (δ) is set to 0, 
only the objects have the same set of tags will be returned. 
For each cluster C at the root level, we calculate 1st-
LB(Tq, C) according to equation(1). If the value of 1st-LB 
(Tq, C) is greater than δ, it implies that all the tag sets within 
C have distance with Tq greater than δ. Thus, all the tag sets 
within C can be pruned without needing further checking. 
Otherwise, the 1st-UB(Tq, C)) is calculated according to 
equation(2). If the value of 1st-UB(Tq, C)) is less than or 
equal to δ, it is indicated that all the tag sets within C have 
distance with Tq not greater than δ. Accordingly, all the 
objects with the tag sets in the cluster C are returned as 
answers. 
If neither one of the checking on the two bounds satisfies, 
we have to check the clusters at the next level under C. If C 
is not a cluster at the leaf level, the same bounding 
mechanism checking is performed recursively on each sub-
cluster of C. The same processing repeats until a cluster Cleaf 
at the leaf level is reached, which consists of batches. On the 
batch level, the checking on the 2nd-LB(Tq, Cleaf, B)) is used 
to check whether all the tag sets in a batch B can be pruned 
from the search space; else the checking on the 2nd-UB(Tq, 
Cleaf,, B) is performed to decide whether all the tag sets in the 
batch are part of the answers. If the checking on the 2nd-
UB(Tq, Cleaf, B) also fails, the distance between Tq and each 
tag set T in the batch B is calculated. If the value of dist(Tq, T) 
is not greater than δ, the tag set T is returned as a query result.   
In the case when the query threshold is set to 0, it means 
that the user requires the objects have the same set of tags as 
Tq. The clusters that are needed to be checked are only the 
clusters whose inner border contains any tag in Tq. Therefore, 
for each tag t in Tq, the list of cluster ids for tag t in the 
inverted list is retrieved to find a set of candidate clusters for 
searching. This strategy significantly enhances the pruning 
efficiency of searching space when performing the exact 
match search. 
5)  Deletion Operation 
When an object Od in WDB is deleted, the deletion 
operation on its tag set Td needs to be performed. First, a 
search for Td with query threshold 0 is performed. We have 
to check whether only one object in WDB has the tag set Td. 
If there is more than one object in the object list of tag set Td, 
we only need to remove the object Od from the object list of 
Td and do not need to delete Td from the index structure. 
Otherwise, the tag set Td is removed from the index structure 
and the borders of the batch and all the clusters that Td 
belongs to should be updated accordingly. 
6) Update Operation 
In a tag database, sometimes users want to modify the tag 
set of an object such as add a tag or remove a tag from the 
tag set. It can be performed by deleting the existing tag set 
and inserting the new tag set after modification.  
IV. MODIFIED HAMMING DISTANCE  
A. Definition of Modified Hamming Distance 
According to the hamming distance defined previously, 
two semantic-related concepts represented by two different 
tags will be considered different concepts. It will reduce the 
effectiveness of similarity search of tag sets in the social 
tagging system. Therefore, we define a new distance 
measure called the modified hamming distance in this 
section, which is an extension of the hamming distance 
measure. When computing the cardinality of the intersection 
between two tag sets, we consider not only the number of 
same tags in the two tag sets but also the degrees of semantic 
relatedness of the unmatched tags in both tag sets.  
 According to the definition of hamming distance 
between two tag sets Ti and Tj given in the subsection of 
terms definition, we can derive the following result: 
dist(Ti, Tj) = diff(Ti, Tj) + diff(Tj, Ti) 
                  = (|Ti|-|Ti∩Tj|)+(|Tj|-|Ti∩Tj|) 
                  = |Ti|+|Tj|-2|Ti ∩ Tj| 
In other words, the hamming distance between two tag sets 
Ti and Tj is mainly determined by the cardinality of both Ti 
and Tj and the cardinality of their intersection.  
We define the modified hamming distance function to be: 
 mdist(Ti, Tj) =|Ti|+|Tj|-2(|Ti∩Tj|+SR(T,Tq) ………..…(5), 
where SR((T,Tq)) computes the degree of semantic 
relatedness  among the un-matched tags in T and Tq .  
    We use the correlation measure between two tags ta and tb 
to represent their degree semantic relatedness as follows: 
If correlation(ta, tb)>0 
  related-degree(ta, tb) = correlation(ta, tb); 
Otherwise, related-degree(ta, tb) = 0. 
Let k denote the value of min(|T-Tq|, |Tq-T|). The SR(T,Tq) is 
defined to be the maximum value of the sum of the related-
degrees of k disjoint pairs between (T-Tq) and (Tq-T). 
To prevent from enumerating all possible k disjoint pairs 
between (T-Tq) and (Tq-T), we use a greedy approach to 
approximately estimate the value of SR(T,Tq) as follows. Let 
T1 denote (T-Tq) and T2 denote (Tq-T). First, for ta in T1 and tb 
in T2, the pair (ta, tb) with the maximum related-degree(ta, tb) 
is selected. Then ta and tb are removed from T1 and T2, 
maxd_root is 50, maxd_leaf is 30, and the maxd_batch is 10. 
For the TIB approach, the maxd_root is set to 50. We 
randomly selected 100 tag sets from the dataset as test 
queries, where the average cardinality of the query tag sets is 
10.5. For each experiment, the average execution time is 
obtained by performing the 100 different queries. 
In the following, using the two difference distance 
measures: the hamming distance and the modified hamming 
distance, we observe the performance of similarity search, 
deletion and update operations respectively for the three 
approaches. 
A. Perfomed by Using Hamming Distance 
1) Execustion Time of  Performing Similarity Search 
a) Varying the query threshold (δ)  
Fig.3(a) shows the execution time of performing 
similarity search for the three approaches by varying the 
query threshold δ from 0 to 20. The MHIB approach 
performs better efficiency for similarity searching than the 
other two approaches especially for the small δ setting. The 
reason is that we require the tag sets within a cluster must 
have at least one common tag. Therefore, the tag sets stored 
in a cluster got by the MHIB approach are more similar than 
the one got by the TIB approach. Besides, the MHIB 
approach is a forest like-structure, even we couldn’t prune a 
cluster at the root level from the search space, it still has 
chance to prune the clusters at the next level from the search 
space. Accordingly, the pruning effect of the MHIB is better 
than the one of the TIB approach. If the pruning strategy 
according to the estimated distance bounds does not work 
well, the distance between each tag set and the query has to 
be calculated. It makes the TIB approach spend the 
additional cost for checking the distance bounds of clusters 
and batched but degrades to the naïve method. That is why 
the TIB approach performs worse than the naïve method in 
this case. Because both the average cardinality of a query 
and a tag set is about 10, it is reasonable to set the value of δ 
less than or equal to 10. In the case when δ is set to be 10, 
the returned tag sets are having about 50% overlap with the 
query on their tags. 
b) Varying the maxd_root   
In this experiment, the setting of maxd_root is varied 
from 10 to 50 to observe the execution time of similarity 
search with δ is 0 and 10, which implies the exactly match 
and a lower similarity requirement of a query, respectively. 
The results of the two different setting of δ are shown in 
Figure 3(b) and 15(c), respectively.  
When δ = 0, as the result shown in Figure 3(b), the 
MHIB approach performs much more efficiently than the 
other two methods. It indicates that the inverted list of the 
clusters at the root level provides very good effect for 
reducing the search space of clusters for the MHIB approach. 
Figure 3(c), shows the execution times of the three 
approaches when δ = 10. When the maxd_root threshold is 
set to a larger value, it means that the tag sets assigned in the 
same cluster are less similar to each other than the ones in a 
cluster constructed with a smaller maxd_root. Consequently, 
fewer clusters will be formed by both the MHIB and the TIB 
approaches with a larger value of maxd_root. That is why the 
execution times of both both the MHIB and the TIB 
approaches decrease as the value of maxd_root increases. 
When the value of the maxd_root threshold is as large as 50, 
the pruning strategy of the TIB approach becomes less 
effective because too many dissimilar tag sets are assign to a 
cluster. That is why the execution time of the TIB approach 
with maxd_root=50 is more than the one with 
maxd_root=40. However, for the MHIB approach, more 
than one level of clusters will be constructed when the 
cluster at the root level violates the maxd_leaf constraint. 
Therefore, the MHIB approach still has good pruning effect 
with maxd_root=50. 
c)  Varying the cardinality of the query tag set     
In this experiment, the cardinality of the query tag set, 
called query length in the following, is varied from 4 to 20. 
The execution times of similarity search by using the three 
approaches with δ is 0 and 10 are shown in Figure 3(d) and 
15(e), respectively. 
Without surprising, the execution times of all the three 
approaches increase as the query length increases when δ = 0. 
The reason is that the larger the query length, the more time 
needed to perform matching of the members in the tag sets. 
When δ = 10, most clusters in the index structure could not 
be pruned from the search space when the query length is 
less that the query threshold (i.e. 4 and 8 in this case). 
However, the execution times of both the MHIB and the TIB 
approach decrease as the query length increases from 8 to 12. 
The reason is that the pruning effect of the bounding 
mechanisms starts to work well when the query length is 
greater than δ. After that, the execution times of the two 
approaches keep increasing slightly as the query length 
increases. 
2) Execustion Time of  Updating the Index Structure 
We also compare the execution times of the three 
approaches when performing deletion or updating operations 
on the index structure.   
As the result shown in Figure 3(f), the MHIB approach 
performs much more efficiently than the other methods when 
performing the deletion operation. The reason is that the 
inverted list is used to select the clusters that might contain 
the tag set to be deleted, which effectively reduces the 
number of clusters need to be checked. The naïve method 
performed poorly because it has to check all the tag sets one 
by one. 
The MHIB approach has to find the best cluster among 
the clusters for inserting a new tag set. Therefore, it requires 
more time to perform an insertion operation. However, the 
MHIB approach performs a deletion operation much faster 
than the other two approaches. Consequently, as shown in 
Figure 3(g), the MHIB approach also has the best 
performance on the execution time of update operation.  
 
B. Perfomed by Using Modified Hamming Distance 
The modified hamming distance mainly influence the 
performance of similarity search because it requires higher 
cost for computing the distance between a tag set and the 
query tag set than the hamming distance. Accordingly, the 
execution time of performing a similarity search is 
significantly influenced by the pruning effectiveness of the 
proposed index structure. In this part of experiments, we 
evaluate the execution times of the MHIB and the TIB 
approaches for performing similarity search operations by 
varying the setting of query threshold δ, maxd_root, and 
query length, respectively. 
a) Varying the query threshold δ   
Figure 3(h) shows the execution times of the two 
approaches by varying the query threshold δ. When the value 
of δ increases, more tag sets satisfy the query. It clauses the 
number of clusters which can be pruned from the search 
space decreases. That is why the execution time of both 
approaches increases as δ increases, which is consistent with 
the results shown in Figure 3(a). However, the modified 
hamming distance between a tag set and a query tag set is 
smaller than the hamming distance between them. 
Accordingly, for the same query threshold setting, using the 
modified hamming distance to perform similarity measures 
on tag sets gets more tag sets as the answers than using the 
hamming distance. Besides, the cost of computing a 
modified hamming distance between two tag sets is higher 
than the one of computing their modified hamming distance.  
Consequently, the increasing rate of the execution time for 
the TIB approach shown in Figure 3(h) is faster than the one 
shown in Figure 3(a). However, for the MHIB approach, the 
effect on the execution time is less significant by varying the 
query threshold. It indicates that the MHIB approach is well 
scalable with respect to δ.  
b) Varying the maxd_root  
The execution times of the two approaches by varying 
the maxd_root are shown in Figure 3(i), where the query 
threshold δ is set to 4. When the value of the maxd_root 
increases from 10 to 30, the execution times of both methods 
increase linearly. During this setting range, the constructed 
index structure of the MHIB approach only has one level of 
clusters, which is similar to the TIB approach. However, the 
similarity of a cluster formed by the MHIB approach is 
higher than the one formed by the TIB approach. For this 
reason, the MHIB approach performed similarity searches 
more efficiently than the TIB approach. When the maxd_root 
increases from 30 to 50, more than one level of clusters is 
constructed by the MHIB approach, which performs better 
pruning effect than the one level of clusters. That is why the 
execution time of the MHIB approach decreases from 30 to 
40 and the increasing rate starting from  maxd_root = 40 is 
less than the one when maxd_root  is less than 30.  
 
 
 
 
0
5
10
15
20
25
30
20 40 60 80 100
A
v
g.
 
ex
ec
u
tio
n
 
tim
e 
(se
c.
)
Number of Items
MHIB
TIB
Naïve
(g) 
0
20
40
60
80
100
120
140
0 2 4 6 8 10 12 14 16 18 20
A
gv
.
 
ex
ec
u
tio
n
 
tim
e 
(se
c.
)
Threshold Value (δ)
MHIB
TIB
(h) 
0
2
4
6
8
10
12
10 20 30 40 50
A
v
g.
 
ex
ec
u
tio
n
 
tim
e 
(se
c.
)
Root threshold (maxd_root)
MHIB
TIB
 
(i) 
0
5
10
15
20
25
30
4 8 12 16 20
A
v
g.
 
ex
ec
u
tio
n
 
tim
e 
(se
c.
)
Root threshold (maxd_root)
MHIB
TIB
 
(j) 
Figure 3. (cont.) 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/08/31
國科會補助計畫
計畫名稱: 專有詞彙相關句搜尋及摘要技術之研究
計畫主持人: 柯佳伶
計畫編號: 100-2221-E-003-024- 學門領域: WEB 技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
