                        
f
i
i
fwhfreq
whk σ
−= ),(),(            公式(3) 
接著計算目標詞 h  及其特徵 iw  之共同出現次數，與在語料庫總次數之比例，也就是搭
配次數含量 ),( iwhgain  及其平均搭配次數含量  ),( iwhgain  ，並將特徵 iw  在出現語料
庫中之總次數定義為 )( iwc  ： 
           
)(
),(
),(
i
i
i wc
whfreqwhgain =  ;  
d
whgain
whgain ii 2
),(
),( =         公式(4) 
所有與目標詞 h  搭配之特徵 iw  之總平均搭配次數含量 g  和標準差 gσ  定義為： 
     ∑
=
=
n
i
iwhgainn
g
1
),(1  ;  ∑
=
−=
n
i
ig gwhgainn 1
2)),((1σ     公式(5) 
將特徵 iw  之總平均搭配次數含量標準化，定義為： 
                        
g
i
i
gwhgain
whg σ
−= ),(),(                     公式(6) 
在萃取模式中，透過 ),( iwhk  ，訂定門檻值 0K  ，其過濾條件為 0),( Kwhk i ≥  ，過
濾掉與目標詞共同發生次數過低的周邊特徵。同時也訂定門檻值  0G  ，篩選總平均搭配
次數含量 ),( iwhg  ，其過濾條件為 0),( Gwhg i ≥  ，過濾與目標詞在語料庫中緊密程度較
低的特徵。搭配程度萃取模式之過濾條件可整理為： 
                
⎪⎪⎩
⎪⎪⎨
⎧
≥−=
≥−=
0
0
),(
),(
),(
),(
:
1
G
gwhgain
whg
K
fwhfreq
whk
C
g
i
i
f
i
i
phrase
σ
σ
              公式(7) 
 
第二階段的萃取模式主要是透過統計特徵在視窗範圍內，不同位置的出現次數。計算與目
標詞之變異程度，過濾相對而言變異程度較小，也就是較不固定出現在特定位置之特徵。 
首先定義特徵  iw  在目標詞  d±  視窗範圍內，各個位置的出現次數之變異數 
),( iwhu   ： 
                 
d
whfreqmwhp
whu
d
dm
ii
i 2
)),(),,((
),(
2∑
−=
−
=               公式(8) 
考慮到平均出現次數可能會有差異很大的情形，為了方便觀察變異數及其分布情形，
套用無單位變異係數進行計算變異數，將其定義為 ),( iwhcv  ： 
                        
),(
),(
),(
i
i
i whfreq
whu
whcv =                        公式(9) 
在萃取模式中，訂定門檻值 0CV  ，過濾條件為 0),( CVwhcv i ≥  ，篩選不固定出現在
目標詞周邊或出現位置過於分散之特徵，也就是整體而言較無文法架構之特徵。次數變異
留(VC) 11 31 35.5 15.5 
求(VC) 78 78 100.0 39.0 
結(VC) 50 51 98.0 25.5 
平均   91.2 37.8 
整體來說，透過字典資源設定搭配詞詞義，所能比對上之搭配詞有限，導致進行詞義
辨識工作時，所能比對上之待標示句子過少，造成應用率偏低之情形。本研究使用名詞作
為目標詞的主要詞類，除此之外，為了觀察研究方法對不同詞類的目標詞的實驗結果，也
分別擷取了動詞及形容詞詞類的目標詞進行實驗。整理不同詞類之實驗結果如表 2，名詞
及形容詞的正確率及應用率最高分別為 89.4%、100%及 37.3%、52%，而動詞的正確率及
應用率最高為 86.9%及 26.7%。整體來說，名詞及形容詞的詞義辨識結果較佳，但動詞也可
以得到一個不錯的詞義辨識結果，顯示本計畫提出之研究方法可適用於不同詞類。觀察實
驗結果應用率最高可達到 37.8%，正確率最高可達到 91.2%，算是一個不錯的結果。 
表 2 不同詞類在詞義辨識上之實驗結果 
詞性 正確率(%) 應用率(%) 
名詞 89.4 37.3 
形容詞 100 52.0 
動詞 86.9 26.7 
 
參考文獻 
Breidt E., 1993, Extraction of V-N-Collocations from Text Corpora: A feasibility Study for 
German,In Proceedings of the First Workshop on Very Large Corpora, pp. 74-83, USA. 
Chen H.-H., Y.-C. Yu, and C.-L. Li, 2004, Collocation Extraction Using Web Statistics, In 
Proceedings of 4th International Conference on Language, Resources and Evaluation, pp. 
1851-1854, Portugal. 
Gitaski et al., 2000, English Collocation and Their Place in the EFL Classroom, pp. 121-126. 
Goldman J.-P. and Wehrli E., 2001, FipsCo: A Syntax-Based System for Terminology Extraction, 
In Grammar and Natural Language Processing Conference, Montreal. 
Jian J.-Y., Y.-C. Chang and J. S. Chang, 2004b, TANGO: Bilingual Collocational Concordancer, 
In Proceedings of the ACL-2004 on Interactive poster and demonstration sessions, pp. 
166-169, Spain. 
Li W., Q. Lu and W. Li, 2005, Integrating Collocation Features in Chinese Word Sense 
Disambiguation, In Proceedings of the Fourth SIGHAN Workshop on Chinese Language 
Processing, pp. 87-94, Korea. 
Lu Q., Y. Li and R. F. Xu, 2003, Improving Xtract for Chinese Collocation Extraction, In IEEE 
2003 International Conference on Natural Language Processing and Knowledge Engineering, 
pp. 333-338, China. 
Mitra, M., C. Buckley, A. Singhal, C. Cardie, 1997, An analysis of statistical and syntactic 
phrases, In Proceedings of RIAO-97, 5th International Conference, pp. 200-214. 
Orliac B. and M. Dillinger, 2003, Collocation extraction for machine translation, In Proceedings 
of Machine Translation Summit IX, pp. 292-298. 
Seretan V., L. Nerima, and E. Wehrli., 2003, Extraction of Multi-Word Collocations Using 
Syntactic Bigram Composition, In Proceedings of the Fourth International Conference on 
Recent Advances in NLP (RANLP-2003), pp. 424–431, Bulgaria. 
Sinclair J., 1991, Corpus, Concordance, Collocation, Oxford University Press. 
Smadja F., 1993, Retrieving Collocation from Text: Xtract, Computational Linguistics, Vol. 19, 
No. 1, pp. 143-177. 
Sue-Jin Ker, Chu-Ren Huang, Jia-Fei Hong, Shi-Yin Liu, Hui-Ling Jian, I-Li Su and Shu-Kai 
Hsieh, 2008, Design and Prototype of a Large-scale and Fully Sense-tagged Corpus, In 
Proceedings of 3rd International Conference on Large-scale Knowledge Resources, March 3–5, 
Japan. 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 97-2221-E-031 -003 
計畫名稱 中文搭配詞集製作技術之研究 
出國人員姓名 
服務機關及職稱 柯淑津 （東吳大學 資訊管理學系 副教授） 
會議時間地點  98  年 7  月 27 ～ 30 日， 山東，魯東大學 
會議名稱 第十屆漢語詞彙語義學研討會（CLSW2009） 
發表論文題目 Corpus-driven Linguistic Approaches to Sense Prediction 
 
一、 參加會議經過 
第十屆漢語詞彙語義學研討會，從 7 月 27 日至 30 日於山東魯東大學舉辦。
申請人在 28 日下午的會議中報告入選論文，論文名稱為「Corpus-driven 
Linguistic Approaches to Sense Prediction」。論文描述透過語料庫中找尋未分析過
詞彙的代表句子，分別利用自動統計技術，與經由假設實驗進行問卷分析方
式進行詞義辨析工作。兩種不同作法所得結果可互為驗證，以正確率作為效
果之判斷，呈現高度一致性。 
 
二、 與會心得 
幾天的會議中所宣讀的論文範圍極為廣泛，包括資源探勘、語料庫的建構、自
然語言處理等多層面，無法一一詳述。來自大陸各地、新加坡、香港以及台灣
等多個地區從事自然語言相關研究之學者匯集一堂，共同討論相關研究，對彼
此都有很大的幫助。 
 
semantic features, and predicting the correct senses for lexically ambiguous words in word sense 
prediction. 
 
2  Previous studies 
 If a word has more than two senses at the same time, then it is usually called a lexically 
ambiguous word. We need to divide its correct senses and assign its appropriate senses to the 
different contexts. However, “lexical ambiguity” is presented in several different related 
researches to present and refer the same target.  
 What is “lexical ambiguity”? Lexical ambiguity indicates vague, unclear, and indefinite 
senses; that is to say, lexically ambiguous words can refer to more than two senses at the same 
time. Lexical ambiguity is a linguistic term for a word’s capacity to carry two or more distinct 
meanings, for example, bank. In some modern linguistic and literary theories, it is argued that all 
signs are polysemous, and the term has been extended to larger units, including entire literary 
works. In WordNet, the definition of a lexically ambiguous word is the ambiguity of an individual 
word or phrase that can be used (in different contexts) to express two or more different meanings. 
WordNet researchers also regard polysemy and lexical ambiguity as synonym. 
 In the case of the previously mentioned related lexical ambiguity or polysemy studies, I 
categorize them into three different sections. Several studies may concentrate on corpus and 
computational perspective, some studies focus on psycholinguistic studies, while others emphasize 
neurolinguistic studies. I will divide these lexical ambiguity studies into three different categories, 
list some previous studies of these three categories, and explain and point out their significance. 
Three categories of lexical ambiguity study are shown following, in Table 1: 
Table 1: Three categories for lexical ambiguity study 
Category Previous Related Studies Significant Points 
Corpus and 
Computational 
Veronis and Ide (1990) 
Philip and Yarowsky (2000) 
Alberto et al. (2003) 
Ganesh and Prithviraj (2004) 
Ker and Chen (2004) 
Moldovan and Novischi (2004) 
Chen et al. (2005) 
Zhang et al. (2005) 
Martinez et al. (2006) 
Xue et al. (2006) 
Peng et al. (2007) 
1. Uses the corpus-based approach 
2. An adaptive system 
3. Divides the sense of lexically 
ambiguous word 
4. Finds the possibility of the senses 
of a word 
Psycholinguistic Ahrens (1998, 2001, 2006) 
Lin and Ahrens (2000) 
1. Experimentally-based 
2. Determines literal bias meanings 
or metaphorical bias meanings 
3. Context influences lexical access 
4. Conceptual domains and the 
linguistic context 
Neurolinguistic Gunter et al. (2003) 
Li and Li (2004) 
Elston-Guttler and Friederici 
(2006) 
Mason and Just (2007) 
Zempleni et al. (2007) 
1. Takes lexically ambiguous words 
to examine comprehensions of 
different senses 
2. Processes ambiguous words that 
can occur both as nouns and as 
verbs 
3. Examines lexical ambiguity 
comprehension in order to 
noun of the first noun phrase after the target verb; and (3) the head noun after the first punctuation 
mark of the target verb. They are shown following, in Table 2 through Table 4. 
Table 2: The noun after the target verb 
Connected Sentence Relative Collocation 
民众 除了 多 食用 蔬菜 , 多 吃{VC} 
鱼{Na} 也 有益 健康 。 
鱼{Na} 
 
Table 3: The head noun of the first noun phrase after the target verb 
Connected Sentence Relative Collocation 
当地 的 贡丸 店 ，为 保证 质量 ，每天
特别 搜购 温体 猪肉 , 也就是 吃{VC} 
残羹{Na} 剩菜{Na} 长大 的 黑 毛猪 ；须
以 土法 屠宰 
剩菜{Na} 
 
Table 4: The head noun after the first punctuation mark of the target verb 
Connected Sentence Relative Collocation 
台南县 芒果 产量 占 台湾省 总产量 三 
分 之 二 , 希望 民众 能 多 吃{VC} 
对 健康 有益 的 芒果{Na} 。 
芒果{Na} 
 
 Among all large databases of Taiwan’s Central News Agency, we collected 22,906 sentences 
for our target verb chi1 “eat” and examined these collocations. Among these 22,906 sentences, we 
collected their appropriate collocations and ranked them by their frequencies. It’s very important 
that we obtain 4032 types from these 22,906 sentences. 
 For experimental evaluation, different collocations will affect the interpretations of the target 
verb, such as chi1 “eat”. If we can demonstrate that there are several clusters of the related 
collocations for chi1 “eat” by the experimental evaluation, we can certainly predict several 
different senses for the target verb.  
 In order to test the related collocations for the target word of lexical ambiguity or polysemy, 
we will run a multiple-choice task experiment to demonstrate which target word (chi1 “eat”) in the 
different sentences belongs to the same sense cluster in this study. For that reason, we will utilize 
the multiple-choice task and obtain some experimental data from the related collocations for chi1 
“eat” of the corpus-based analysis. 
 In this multiple-choice task, we will let my participants choose one word/one item that is 
different from three other words/items. This multiple-choice task is a test without context. In other 
words, in this multiple-choice task, whether some conceptual words belong to the same sense 
cluster helps me prepare some materials in my sense prediction study. 
 
5  Analysis 
5.1  Corpus-based analysis 
 There are two important steps for the sense prediction experiment in this study: (1) collect 
appropriate collocations and rank them by their frequencies; and (2) group some similar 
collections into the same cluster. Among these 22,906 sentences, we collected their appropriate 
collocations and ranked them by their frequencies. It’s very important that we obtain 4032 types 
from these 22,906 sentences. These partial collocation words of higher frequency of these 
sentences are shown following, in Table 5. 
 
 
 
苦头 99 
亏 97 
 
 Similar features are often synonymous compounds that share a common morpheme. For 
instance, [饭 (fan4 “rice”), 米饭 (mi3 fan4 “rice”)] and [案 (an4 “case”), 案件 (an4 jian4 
“case”)], respectively, share a common morpheme [饭 (fan4 “rice”)] and [案 (an4 “case”)]. Fujii 
and Croft (1993) also pointed out a similar thesaurus effect of Chinese characters in Japanese 
Information Retrieval. In the cluster step, there are two sub-steps here: (1) character similarity 
comparison between words; and (2) group similarity comparison between words. Two formulas 
for these sub-steps are presented as the following: 
Formula 1: Character similarity comparison between words 
 
 
 
 By using this formula, we will obtain some collocations and regard 药 (yao4 “medicine”), 
减肥药 (jian3 fei2 yao4 “reducing weight medicine”), and 中药 (zhong1 yao4 “traditional 
Chinese medicine”) as the same cluster. 
Formula 2: Group similarity comparison between words 
 
 
 
 In Formula 2, we take one undefined word (x) to compare with each word (y) of one certain 
cluster (Y), calculate their average similarities, gain the maximum, and then this undefined word 
(x) will belong to this certain cluster (Y). After comparing some cluster similarities’ comparisons 
between them, we can put 败绩 (bai4 ji1 “defeat”) and 败仗 (bai4 zhang4 “defeat”) in the same 
cluster. 
 From these two different experimental steps, we reduce 4032 types from these 22,906 
sentences to 348 clusters. Among 348 clusters, we further categorize the results into two 
sub-groups, the physical sense group and the metaphorical sense group, such as shown in both 
Table 6 and Table 7. 
Table 6: Physical senses clusters 
「Yao4 Wu4 
“medicine”」Cluster 
E.g.1：一名女子吃减肥药吃到被判刑，想减肥的民众要
特别注意服用的减肥药成分。 
「Fan4  
“boiled rice”」Cluster 
E.g.1：捐十万元者，可以跟柯林顿吃两顿饭，再和高尔
吃两顿饭。 
「Can1 “meal”」
Cluster 
Eg1：到了晚间，总统则与参访团员同样吃飞机餐，菜
色为石斑鱼与竹叶饭。 
「Rou4 “meat”」
Cluster 
E.g.1：人权组织今天指出，北韩难民为了活命，吃鼠肉、
假结婚，什么手段都使用了。 
 
 
||||
||2),(
yx
yxyxdice +
∩=
||
),(
),(
Y
yxdice
Yxsim Yy
∑ ∈=
Obviously, 餐刀 (can1 dao1 “knife”) is a different conceptual word. We will let our participants 
choose one word/one item that is different from three other words/items. In other words, the 
concept of this selected word/item is obviously different from the concept of the other three 
words/items. This multiple-choice task is a test without context. 
 Twenty undergraduate students from National Taiwan University participated in this 
production test (mean age = 20.9 years; SD = 1.2 years; range = 19 to 23 years). There were ten 
males and ten females, all native Mandarin Chinese speakers and all right-handed, with no 
linguistic background knowledge. 
 All of our participants are asked to choose the most appropriate answer for each question, 
such as the following instruction 1 and Table 9: 
Instruction 1: Instruction in the multiple-choice task 
问卷一共有 60 题，里面都是中文的句子。填写问卷时，你要做的就是，先读完每个
句子中的四个词组的概念。请你在看过词组之后，根据你的语感，决定每题里的概念与概
念之间，哪一个概念与其它三个概念不同，然后圈选作答。请你一定要在这四个词组之间
圈选一个你觉得最适当的答案。举例如下： 
 
 
1 请问下列哪一个概念与其它三个概念不同？ 
a) 炒菜锅； b) 电饭锅； c) 罗锅； d) 闷烧锅 
 
2 请问下列哪一个概念与其它三个概念不同？ 
a) 洗碗精； b) 糖精； c) 洗衣精； d) 洗发精 
 
 
Table 9: Multiple-choice task for sense prediction study 
(1) 请问下列哪一个概念与其它三个概念不同？ 
a) 喷饭；b) 午饭；c) 团圆饭；d) 中饭 
 
(2) 请问下列哪一个概念与其它三个概念不同？ 
a) 晚餐；b) 佐餐；c) 餐点；d) 自助餐 
 
(3) 请问下列哪一个概念与其它三个概念不同？ 
a) 皮肉；b) 鸡肉；c) 甲鱼肉；d) 鱼肉 
 
(4) 请问下列哪一个概念与其它三个概念不同？ 
a) 药品；b) 农药；c) 乌药；d) 止痛药 
 
 Following this multiple-choice task, which includes sixty questions for our sense prediction 
study, we distinguished these sixty questions of the questionnaire into a YES group and a NO 
group for each participant. Regarding all candidates in the YES group, we selected them from the 
yao4 “medicine” cluster, the fan4 “boiled rice” cluster, the can1 “meal” cluster, and the rou4 
“meat” cluster; all candidates had the same morpheme in each cluster, for example, an1mi2 yao4 
“sleeping pill”, xie4 yao4 “laxative”, and cheng2 yao4 “patent medicine”. Regarding all 
candidates in the NO group, we chose for them to have the same morpheme in each cluster based 
on the new dictionary of Ministry of Education, R.O.C; for example, ye2 rou4 “coconut (meat)” in 
the rou4 “meat” cluster. 
 While we distinguished and analyzed the YES group and the NO group by each participant, 
this multiple-choice task also demonstrated other related analysis by each item. They are shown in 
Table 10 and Table 11: 
[9] Ganesh, Ramakrishnan, B. P. Prithviraj, A. Deepa, Pushpak Bhattacharyya, and Soumen Chakrabarti. “Soft 
Word Sense Disambiguation.” 2004. GWC 2004, Proceedings, pp. 291–298. 
[10] Goddard, Cliff. 2002. “The search for the shared semantic core of all languages”. In C. Goddard and A. 
Wierzbicka (eds). Meaning and Universal Grammar -Theory and Empirical Findings. Volume I. 
Amsterdam: John Benjamins. pp. 5-40. 
[11] Gunter, Thomas C., Susanne Wagner, and Angela D. Friederici (2003). “Working Memory and Lexical 
Ambiguity Resolution as Revealed by ERPs: A Difficult Case for Activation Theories.” Journal of 
Cognitive Neuroscience. 15:5, pp. 643–657. 
[12] Huang, Chu-Ren, Elanna I. J. Tseng, Dylan B. S. Tsai, and Brian Murphy. 2003. “Cross-lingual Portability 
of Semantic Relations: Bootstrapping Chinese WordNet with English WordNet Relations.” Language and 
Linguistics. 4.3: 509–532. 
[13] Ker, Sue-Jin and Jen-Nan Chen. 2004. “Adaptive Word Sense Tagging on Chinese Corpus.” PACLIC 18, 
Dec. 8–10, 2004, Waseda University, Tokyo, pp. 267–273. 
[14] Li, Ping, Zhen Jin, and Li Hai Tan (2004). “Neural Representations of Nouns and Verbs in Chinese: An 
fMRI Study. Neuroimage, 21: 1533–1541. 
[15] Lin, Charles and Kathleen Ahrens. 2000. “Calculating the Number of Senses: Implications for Ambiguity 
Advantage Effect During Lexical Access.” In H. Y Tai and Chang Y. L. (eds.) Proceedings of the Seventh 
International Symposium on Chinese Languages and Linguistics. Chai-yi: National Chung-Cheng 
University, pp. 141–155. 
[16] Martinez, David, Eneko Agirre, and Xinglong Wang. 2006. “Word Relatives in Context for Word Sense 
Disambiguation.” Proceedings of the 2006 Australasian Language Technology Workshop (ALTW2006), pp. 
42–50. 
[17] Mason, Robert A. and Marcel Adam Just. 2007. “Lexical ambiguity in sentence comprehension.” Brain 
Research, 1146: 115–27. 
[18] Moldovan, Dan, Adrian Novischi. 2004. Word sense disambiguation of WordNet glosses. Computer Speech 
and language, 18: 301-317. 
[19] Peng, Jin, Xu Sun, Yunfang Wu, and Shiwen Yu. 2007. “Word Clustering for Collocation-Based Word 
Sense Disambiguation.” The Eighth International Conference on Intelligent Text Processing & 
Computational Linguistics (CICLing 2007), LNCS 4394, pp. 267–274. 
[20] Philip, Resnik and David Yarowsky. 2000. “Distinguishing Systems and Distinguishing Senses: New 
Evaluation Methods for Word Sense Disambiguation.” Natural Language Engineering 5 (3): 113–33. 
Printed in the United Kingdom. Cambridge University Press. 
[21] Ravin, Yael and Claudia Leacock. 2000. Polysemy: Theoretical and Computational Approaches. 
Computational Linguistics. 28.1: 90-95. 
[22] Stevenson, Mark. 2003. “Word sense disambiguation: the case for combinations of knowledge sources.” 
Stanford, California: Center for the Study of Language and Information. 
[23] The New dictionary of Ministry of Education, R.O.C. 1994. http://140.111.34.46/newDict/dict/index.html 
[24] Veronis, Jean and Nancy M. Ide. 1990. “Word sense disambiguation with very large neural networks 
extracted from machine readable dictionaries,” Proceedings of the 13th Conference on Computational 
Linguistics, pp. 389–94, August 20–25, 1990, Helsinki, Finland. 
[25] Xue, Nianwen Jinying Chen, and Martha Palmer. 2006. “Aligning Features with Sense Distinction 
Dimensions.” Proceedings of the COLING/ACL Main Conference Poster Sessions, pp. 921–928. Sydney, 
July 2006. 
[26] Zempleni, Monika-Zita, Remco Renken, John C.J. Hoeks, Johannes M. Hoogduin, and Laurie A. Stowe. 
2007. “Semantic ambiguity processing in sentence context: Evidence from event-related fMRI.” 
Neuroimage, 34: 1270–79. 
[27] Zhang, Yuntao, Ling Gong, and Yongcheng Wang. 2005. “Chinese Word Sense Disambiguation Using 
HowNet.” L. Wang, K. Chen, and Y.S. Ong (Eds.): ICNC 2005, LNCS 3610, pp. 925–32. 
 1
詞義預測研究: 以語料庫驅動的研究方法 
 
洪嘉馡 1、柯淑津 2、黃居仁 3,4、安可思 1,5、李冠勳 2 
1 臺灣大學語言學研究所研究所，臺灣 
2 東吳大學資訊管理學系，臺灣 
3 中央研究院語言學研究所，臺灣 
4 香港理工大學人文學院，香港 
5 香港浸會大學語言中心，香港 
E-mail: jiafei@gate.sinica.edu.tw; ksj@cis.scu.edu.tw;  
churenhuang@gmail.com; kathleenahrens@yahoo.com; franker.lee@msa.hinet.net 
摘  要：在本研究裏，我們將要探究中文辭彙歧義的所有可能詞義，主要是為了
處理一些還沒有分析辭彙的詞義預測研究，以及提出更多適合辭彙歧義的解決研
究方法。我們打算運用語料庫驅動的語言探究方法在本研究中。我們將關注這些
詞義的個別詞義特徵以預測一些還沒分析辭彙的詞義，而我們所使用的語料庫和
工具有：中文十億字語料庫 (Chinese Gigaword Corpus)和知網 (HowNet)。使用
這些語料庫，我們將可以藉由語意特徵與概念分群來確認我們在本研究中的目標
詞的共現辭彙分群。而這些研究過程也將可證明語料庫為主的研究方法的明顯
性。 
關鍵字：辭彙歧義、詞義預測、語料庫方法、共現搭配、概念分群 
 
Corpus-driven Approaches to Sense Prediction 
 
Jia-Fei Hong1, Sue-Jin Ker 2, Chu-Ren Huang3,4, Kathleen Ahrens1,5, Guan-Xun Li2 
1 Graduate Institute of Linguistics, National Taiwan University, Taiwan 
2 Department of Computer Science and Information Management, Soochow 
University, Taiwan 
3 Institute of Linguistics, Academia Sinica, Taiwan 
4 Faculty of Humanities, The Hong Kong Polytechnic University, Hong Kong 
5 Language Centre, Hong Kong Baptist University, Hong Kong 
E-mail: jiafei@gate.sinica.edu.tw; ksj@cis.scu.edu.tw 
churenhuang@gmail.com; kathleenahrens@yahoo.com; franker.lee@msa.hinet.net 
Abstract: In this study, we would like to explore all possible senses of lexical 
ambiguity in Mandarin Chinese in order to deal with the undefined sense prediction 
study and to bring about more appropriate lexical ambiguity resolutions. We propose to 
use corpus-driven linguistic approaches for a sense prediction study. We will 
concentrate on individual semantic features to predict the senses of non-defined words 
by using corpora and tools, such as Chinese Gigaword Corpus and HowNet. Using 
these corpora, we will determine the collocation clusters of my target word through 
semantic features and concepts. This requirement will demonstrate the visibility of the 
corpus-based approaches. 
Keywords: Lexical ambiguity, sense prediction, corpus-based approach, collocation, 
 3
 
3  假設與研究問題 
 本文中有兩個假設。首先，辭彙歧義是一些辭彙的語言現象，他們同時擁有多
樣的意義或詞義。所以，在中文辭彙網路系統裏 (Chinese Wordnet (CWN), Huang 
等人， 2003)，我們可以藉由這些辭彙的詞義來決定他們的語意關係。第二，共現
搭配的現象呈現辭彙結合的情形，不同的結合分佈與趨勢可作為詞義分群的證據。
事實上，當辭彙共現搭配特徵、句法特徵、語意特徵和詞類標記等，在中文原始文
檔上，必須先準備好的。 
 基於以上總總因素與假設，本研究提出兩個主要研究議題：(1)、我們如何預測
辭彙歧義的詞義並表現出不同的詞義在不同的語境或領域？(2)、我們如何使用語料
庫當作資料來支援我們的詞義預測研究？我們將透過中文辭彙網路、十億詞語料庫 
(Gigaword Corpus)和知網，以探討辭彙歧義的辭彙語意、辭彙特徵和辭彙共現搭配
特徵來檢測這些研究議題。 
 
4  重要特徵收集 
 在本研究當中，我們將探討的研究方法，是從概念出發的分群方法。我們使用
具豐富語料的中文十億詞語料庫第二版 (Lexical Data Consortium, 2005)做為我們
的實驗語料庫。另外，我們也使用知網將特徵辭彙轉換成概念，利用概念間相似度
進而計算出辭彙間相似度。 
 特徵辭彙擷取階段，我們選取特徵辭彙做為句子的特徵，以特徵來代表句子，
透過對特徵辭彙分群，完成對句子分群。在分群演算法中，概念分群演算法是將特
徵辭彙進一步擷取出概念群，將概念視為特徵辭彙的代表，透過對特徵概念進行分
群，達到對句子分群的工作。 
 為了收集大量資料以進行我們的詞義預測研究，我們選定十億詞語料庫中的臺
灣中央社新聞的內容(繁體中文的語料庫)，十億詞語料庫的內容 (從 1991 年到 2004
年)，包含有十四億的中文字，其中，有八億字是來自於臺灣中央社新聞的內容，有
五億字是來自於中國新華社新聞的內容，和將近 3000 萬自來自於新加坡早報的內
容。 
 在本文中，我們將選取歧義特性的動詞做為目標辭彙，然後再收集其相關共現
搭配組合辭彙。我們以三種不同的方式來收集：(1)、動詞後緊鄰的名詞；(2)、動詞
後的名片語的主要名詞；(3)、動詞後的第一個標點符號前的名詞。這段區間裏文字
中受詞(名詞)往往可以做為判斷目標辭彙詞義的重要依據。在收集到的例子中，我
們可以歸納幾類如下： 
表 1: 動詞後緊鄰的名詞 
相關聯句子 相關共現搭配辭彙 
民眾除了多食用蔬菜，多吃魚也有益健康。 魚{Na} 
 
表 2: 動詞後的名片語的主要名詞 
相關聯句子 相關共現搭配辭彙 
 5
與|clu2|分別表示 clu1與 clu2 中成員的個數。 
 每個概念都自成一個群組，計算群組間的兩兩相似度，並將擁有最大相似
度的那兩個群組合並成為新群組，反復歸併直到群組達到設定的群組數。概念
分群演算法，如圖 2 所示： 
圖 2：概念分群演算法 
步驟 1：針對目標動詞 w，選取語料庫中所有含 w 的句子，所有的句子都各自
成為初始的群組 clu1,clu2…clun，組成集合 S 
步驟 2：設定分群組數 
步驟 3：計算 S 中所有群組的兩兩相似度 
 
 
 
 
其中，兩特徵辭彙的相似度計算如： 
 
 
步驟 4：將群組相似度最大的那一對群組合並成新群組 
步驟 5：反復步驟 3，4 直到設定群組數 
 
6  分析與討論 
 本研究使用中央社的資料，然後，我們利用知網來做為擷取義原的資料來
源，輔助分群的進行。實驗以「吃」為目標動詞，找出含有這些目標辭彙的例
句，執行分群演算法之後可以將例句進行分群。 
 從中文辭彙網路系統的資料來看，與「吃」同詞類的動詞，如：「拉」共有
20 個詞義，在中央研究院平衡語料庫中 (Sinica Corpus)，共出現 315 筆資料，
平均，每一個詞義會出現大約 16 筆資料。藉此，推測目標動詞「吃」在語料庫
中出現 2638 筆資料，若以此比例來看，「吃」可能會有 160 幾個詞義，我們暫
且對於所要分的群組數，我們設定在 160 群，以對於「吃」來進行詞形分群與
概念分群。 
 特徵擷取階段，我們從中央社的資料裏，找到 22,906 筆含有「吃」的例句，
可以找到重要的搭配特徵辭彙，並擷取出 2,915 種特徵辭彙，我們將詞頻小於、
等於 2 的特徵辭彙過濾之後，得到 932 種重要特徵辭彙。 
 在詞形分群方面，我們對 932 種重要特徵辭彙做為詞句分群的依據，根據
我們對於目標詞「吃」所要分的設定群組，可以成功地將 20,458 筆的例句分到
這些群組裏面，其分群結果，舉例如表 6。 
表 6：詞形分群群組 
群組 句子 特徵辭彙 分析結果 
「藥」群 1 孕婦最怕吃中藥。 
2 中藥界也在瞭解薯蕷的生理效
1 中藥 
2 山藥 
1 正確 
2 錯誤 
||||
)),(_(
),(
21
21
21
11 22
cluclu
ccdefdice
cluclusim cluc cluc ×=
∑ ∑
∈ ∈
||||
||2),(_
nm
nmnmdefdice +
∩=
 7
人工驗證結果，其平均正確率為 89.81%，這 10 個群組的結果，大致如表 9 所
示： 
表 9：以概念分群的隨機 10 組分析結果及準確率 
 群組 總句數
 1 2 3 4 5 6 7 8 9 10  
各組句子
數 
5 4 22 5 6 3 54 3094 24 13 3230 
正確句子
數 
0 3 0 0 4 1 29 2864 0 0 2901 
正確率           89.81%
 
 從詞形分群與概念分群的方法來做詞義預測的研究，由上得知，詞形分群
演算的正確率是 77.26%、概念分群演算法的正確率是 89.81%，兩者比較，我們
很清楚地知道，對於詞義預測的研究，加上了概念的分析元素，是可以達到較
高的準確度。 
 
7  結論與未來發展 
 對於詞義預測的研究，本文主要采以概念分群兩種演算法來進行。在詞形
分群演算法中，雖然有效將特徵辭彙詞形相近的句子分到同一群，對於句子的
重要特徵辭彙在還沒有任何的定義時，仍可對於那些句子分群。至於在概念分
群演算法中，就能有效將句子的特徵詞形看起來不相近，但概念相近的句子分
到同一群，這是基於義原距離的概念分群演算法，則更進一步提升群組的品質，
更接近人類直觀的想法。 
 未來我們將進一步整合從詞形分群與概念分群為出發點的分群演算法，我
們也將提供更好的特徵擷取方式，期望能擷取出對目標動詞而言，更具代表性
的特徵辭彙，盡可能協助人工詞義預測與降低人工詞義標記工作量的進行。 
 
參  考  文  獻 
[1] Dai, Liu-Ling, Bin Liu, Yuning Xia and Shi-Kun Wu. 2008 “Measuring 
Semantic Similarity between Words Using HowNet”, International Conference 
on Computer Science and Information Technology, pp.601-605. 
[2] Dice, Lee R. 1945. Measures of the Amount of Ecologic Association Between 
Species. Journal of Ecology, 26: 297-302. 
[3] Dong, Zhen-Dong, Dong, Qiang. 2000. HowNet Knowledge Database, http:// 
www.keenage.com. 
[4] Huang, Chu-Ren, Elanna I. J. Tseng, Dylan B. S. Tsai, and Brian Murphy. 2003. 
“Cross-lingual Portability of Semantic Relations: Bootstrapping Chinese 
WordNet with English WordNet Relations.” Languages and Linguistics. 4.3: 
509–532. 
[5] Jiang, Jay J. and David W. Conrath. 1997. “Semantic Similarity Based on 
