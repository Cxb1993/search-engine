 2
1. Introduction 
As an alternative to traditional input devices, researchers are exploring the 
possibility of adopting hand gestures in applications to computer games, 
interactive computer graphics, hand tracking and television control (Al-Jarrah 
& Halawani, 2001). Hand gestures are mainly used to communicate and to 
express ideas. Detecting, tracking and identifying hand movements and 
interpreting gestic acts are currently the capabilities required of pervasive 
computing and wearable devices in applications such as smart environments 
and perceptual user interfaces (Pentland, 2000).  
Both glove-based and opto-electronic motion capture systems have been 
employed to obtain the spatial-temporal information of finger kinematics 
(Braido & Zhang, 2004). Accuracy in quantifying the “true” underlying 
rigid-body kinematics has been obtained by using a surfaced-based 
opto-electronic measuring system (Zhang & Braido, 2003). This study proposes 
a 3D HGRS for recognition of 20 static hand gestures in Taiwan Sing languages 
(TSL). As a primary component of many sign languages and in particular TSL, 
hand gestures and finger-spelling language are the fundamental methods of 
communication between people who suffer from hearing impediments. Sign 
language is an accumulation of gestures, postures and facial expressions 
corresponding to letters and words in natural languages. An excellent review of 
automatic analysis of hand gestures in signing can be found in Ong and 
Ranganath (2005). This work adopted an eight-camera 3D opto-electronic 
VICON system to capture the spatial-temporal data of 6 miniature reflective 
markers strategically placed on the dorsal surface landmarks of the hand. The 
Neural Network algorithm was employed to classify hand gestures.  
2. System design 
The HGRS illustrated in Fig. 1 is composed of four components, namely 3D 
hand kinematics, feature extract, size normalization and gesture recognition.  
Insert Figure 1 about here 
2.1 Experimental protocol   
Ten university students (males and females, mean age 27.5 years old, mean 
stature 172.0 cm, mean weight 70.7 kg) were recruited in the study. The subjects 
performed the 20 hand gestures with their right hands. Figure 2 shows the 
selected TSL. All movements were performed beginning with gesture “0” and 
ending with the assigned gesture. The gestures were assigned in a random 
order to eliminate any possible sequence effect. Each assigned gesture was 
repeated for 15 times. The participants were permitted to practice and rest 
between every trial until they felt ready to proceed with the movement that 
would be accurately recorded.  
Insert Figure 2 about here 
 4
in a very specific description of the training set. This causes the system to 
respond badly for any data that does not fit to that specific description, thus 
decreasing  the system’s generalization capability. A system with low 
generalization capabilities is not of interest. The aim of this study is to develop 
a system that is trained using training set and can perform well with the testing 
set. This is achieved by carefully setting the number of neurons in hidden layers. 
Table 1 shows that the recognition rates of the test set and training set were 
highest when the two hidden layers each had 250 neurons. 
Insert Table 1 about here 
5. Conclusion 
This study develops a hand recognition system for recognition subset of the 
Taiwan sign language. The proposed system is robust against change in 
position, direction, size and gestures, and is invariant for background color and 
occlusion, rotation, scaling and translation of hand. The feature extraction work 
was accomplished by VICON. After processing, the features were normalized 
for unaffecting by hand size. These features were then fed to the neural network. 
Experimental results demonstrated that the proposed system could recognize 
hand gestures correctly at a rate of 96.58% in all data, and 94.65% in test data. 
The system could be further developed for application in human-computer 
communication or control mechanism. 
References 
Al-Jarrah, O. & Halawani, A. (2001). Recognition of gestures in Arabic sign 
language using neuro-fuzzy system. Artificial Intelligence, 133, 117-138. 
Braido, P., & Zhang, X. (2004). Quantitative analysis of finger motion 
coordination in hand manipulative and gestic acts. Human Movement Science, 
22, 661-678.  
Ong, S. C. W. & Ranganath, S. (2005). Automatic sign language analysis: A 
survey of the future belong lexical meaning. IEEE Transactions on Pattern 
Analysis and Machine Intelligence, 27, 6, 873-891. 
Sengur, A., & Guldemir, H. (2003). Performance comparison of automatic 
analogy modulation classifiers. Third international advanced technologies 
symposium. Ankara, Turkey.  
Zhang, X., Lee, S. W., & Braido, P. (2003), Determining finger segmental centers 
of rotation in flexion-extension based on surface marker measurement. 
Journal of Biomechanics, 36, 1097-1102. 
 6
 
 
 
Fig. 2. The selected 20 hand gestures in TSL. 
 
 
 
 
 
 
 
 
守
