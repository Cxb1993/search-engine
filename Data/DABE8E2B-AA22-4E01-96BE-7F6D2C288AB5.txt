with analog circuits. However, the sequence is a very 
long training time. There are two drawbacks to be 
tackled over. First, in the adjustment of a gene that 
may be represented as an integer or a floating-point 
number, two adjustment methods are needed. It takes 
times to finish such a type-checking for every gene. 
Secondly, when computing the fitness of a chromosome 
that representing an analog circuit, all inputs are 
also analog signals which need to be digitalized. 
Checking all digitalized inputs and their 
corresponding outputs takes a considerable computing 
time. However, these may need advanced researches 
英文關鍵詞： Evolvable hardware, evolutionary computation, 
adaptive hardware, artificial intelligence, genetic 
programming, genetic algorithms, analog hardware 
design 
 
 II
 
中文摘要 
進化式硬體 (evolvable hardware，EHW)是希望透過演化式計算 (evolutionary 
computation)、可重規劃式晶片(reconfigurable chip) 與機器學習(machine learning)的
整合，讓硬體線路可以依照環境要求，在有限的計算資源中，自主的規劃出可用的、
具適應性的硬體系統，使系統有效的運作。本計畫為三階段計畫的第三階段。計畫
前二階段分別獲得國科會專題研究計畫(97-2221-E-390-020-, 2008/08/01-2009/10/31)
與 (98-2221-E-390-026-, 2009/08/01-2010/10/31)的經費支援。本年度計畫重點於類比
式 EHW 的計算，並將之與第一二階段完成的數位 EHW 連接在一起。當實數形式可
以順利與 EA 整合，類比式 EHW 才有實現的可能性。計畫中 EHW 染色體的整數與
實數的混合編碼，融入多階層式 EA，分離類比 EHW 架構計算與實數值的演化，使
之能順利的應用在類比式 EHW 計算上。本計畫以圖形化連接點的概念進行類比
EHW 架構的推演，再以整數類比演化的技術進行元件值的推演。計畫實驗結果顯示， 
EHW 演化混合整數與實數的編碼方式，對於類比線路設計有實際成效；但因為混合
編碼中整數與實數在演化時調整突變的方式不同，檢查差異時增加訓練時間；並外，
類比線路的 fitness 測試需大範圍的進行區間測試，染色體的 fitness 計算十分費時，
造成訓練時間費時。 
關鍵詞： 進化式硬體、演化式計算、自主式硬體、人工智慧、基因演算法、基因程
式規劃、類比線路、硬體設計 
 
 1
一、 前言 
進化式硬體 (evolvable hardware ， EHW) 是希望透過演化式計算 (evolutionary 
computation)、可重規劃式晶片(reconfigurable chip) 與機器學習(machine learning)的整
合，讓硬體線路可以依照環境要求，在有限的計算資源中，自主的規劃出可用的、具
適應性的硬體系統，使系統有效的運作。如果 EHW 應用在自主性硬體，如智慧型機
器人、無人駕駛探測車、嵌入式系統等，更需要進一步考慮計算即時性、電力消耗與
有限制的記憶體容量等限制。針對上述 EHW 的核心問題，本研究擬定三階段的計畫。
第一階段已獲得國科會專題研究計畫(97-2221-E-390-020-, 2008/08/01--2009/10/31)一
年的經費支援。第二階段也已獲得國科會專題研究計畫 (98-2221-E-390-026-, 
2009/08/01--2010/10/31)的經費支援，該計畫著重降低染色體長度，提升 EHW 計算的
scalability。本年度計畫的重點是類比式 EHW 的計算，並嘗試將之與第一二階段完成
的數位 EHW 連接在一起。 
二、 研究目的 
本年度計畫將重點於類比式 EHW 的計算，並嘗試將之與第一二階段完成的數位
EHW 連接在一起。計畫任務區分與關係如下圖： 
以染色體切割與最佳化技術
提升EHW效率
染色體切割
與sSCkt分析s kt
各種EHW
編碼形式
整數與實數編碼在EHW上
的研究
高效能的演化式硬體設計之研究
NSC 97-2221-E-390-020 本年度NSC 98-2221-E-390-026-
類比EHW的特徵
分析與限制訂定
多模式適應
函數定義
類比線路
實數編碼
的研究
EA方法的改
善
類比與數位EHW
相關EA技術
發展
合併EHW與
最佳化技術
穩定狀態
的測量函
數
限制資源環境下的EHW
計算方法與實現
限制資源
環境FPGA
分析
FP
變動限制條件之
EA方法
染色體與適應函
數在限制環境下
的調整
FPGA-based
EHW 實現與分析
- ase
 
 
當實數形式可以順利與EA整合，類比式EHW才有實現的可能性。本計畫中進行EHW
染色體的整數與實數的混合編碼，融入多階層式 EA，分離類比 EHW 架構計算與實
數值的演化，使之能順利的應用在類比式 EHW 計算上。本階段計畫以圖形化連接點
的概念，以 EA 進行類比 EHW 架構的設計，再以整數類比演化的技術進行元件值的
推演。以建立數位與類比 EHW 的設計，提升 EHW 的實用性。 
 3
V P
R C
V C V L
7 1 0 k 3 1 6 k
5 V
1
1 M
7 5 k
1 M 7 5 0 k
1M
12
5k
5 0 k75
0k
25
0k
1 k
5V
A
B
1
32
 
1,2,3 的線路均有不同空間位置，但具完全相同的功能。這意味著二維空間編碼不適
用。但是，類比電路的連接構造仍是一種 graph，第一年計畫中提出的對偶式樹狀結
構可能可以加以擴充，來進行類比電路的 EHW。 
數位電路沒有阻抗的問題，不同位置的邏輯雜均可輸入相同電壓電流。不會發生
元件過載的情形。但在類比電路，每一條線路在不同位置時，可能有不同的電壓電流
條件。而這些數據都是實數而非整數。這些都造成類比實數編碼 EHW 的困難。本研
究提出的方法是以元件為圖形的基本單位，進行圖形的連接(connections)。分成染色
體編碼、演化計算方式、適應函數訂定等三部分進行說明： 
1. 染色體編碼： 
我們將類比式 EHW 中元件的連接設計只能以稱為 via 虛擬的「連接點」或輸出入、
接地線相連在一起。例如下圖陰影區域。 
Vin C1
R1 R2
C2
0V
Vout
R3
+ Vcc
  
依據元件型態，每個元件有 1—n 個輸出入與 via 相連接。例如電晶體有三個輸出入與
via 連接，電容電阻等有兩個輸出入與 via 連接。我們將元件下面的形式描述 
via-1 via-2 via-3 type-code value
為三接觸點的元件， 
 5
需檢驗輸出的電壓、電流、頻率等是否符合。一般事先將連續訊號進行數位取樣
(digitizing)，再計算各分項累計誤差。所以，針對一 EHW 染色體，我們將適應函數
制訂為 
)()()(  
j
iijji cgcefcf  

 超過在正常工作範圍
維持在正常工作範圍
j
j
jj e
e
ef
0
1
)(  
g(ci) 為指定輸出的正確率，為一依時間取樣的正確率的百分比。 
 
dt i
ii
i dtcO
dtcOdtcocg 2||
),(
),(),(||
2
1)(  
其中，o(ci,dt)為實際輸出值、O(ci,dt)為預期輸出值。因為類比式 EHW 同時考慮線路
架構與元件數值，二者都會經過演化運算元而交互影響，二者會彼此干擾其收斂情
形。我們使用兩階段的 EA： 
 第一階段：線路架構。本階段的目的是先以 EA 求出一穩定雛形架構
(prototyping)。該架構可以在是當輸入下，表現出類似所期望的輸出結果。每
一元件的有預設數值，其值為該元件在問題中的可用平均值，並固定該值，先
以 EA 求出一穩定架構，並合乎 f(ci)的一定範圍的值[min:max]。其中，min, max
為使用者設定。所求得的雛形可能會有下面的誤差結果。故可以視為好的 EHW
架構。可以輸出至第二階段進行元件參數調整。 
 第二階段：元件參數調整。依照第一階段求出的 EHW 架構針對各元件數值的
EA 調整。前二階段無法呈現滿意結果，依序重複第一、二階段工作。 
本方法進行步驟： 
步驟一： 依問題規格隨意決定 n 個 via 與 m 個元件 
步驟二： 隨機產生數條 m 個元件與 via 相連的染色體 
步驟三： 進行限制性的演化運算元 Crossover、Mutation 等動作進行 via 位置、元件型
態、元件值進行調整。 
步驟四： 檢查各元件的工作範圍與計算適應函數 
步驟五： 重複步驟三至五 k 次，若達到預期要求則停止運算。否則進行下一步驟。 
步驟六： 調整 via 元件的個數 nn+a, mm+b，並重複步驟二至六，直到達到預期要
求或超過計算時間。 
 7
（B）訊號源 B 
圖 2：訓練效率--fitness 
表格 1：訓練適應值與訓練時間 
Noise 0.00 0.01 0.02 0.05 
Fitness (source A) 100 98.7173 96.4345 96.2197 
Training time (min) 350 712 915 >1200 
Fitness (source B) 100 97.5660 95.1898 94.8740 
Training time (min) 380 640 865 >1200 
 
圖 3--圖 4 顯示本研究方法與中值過濾的比較在不同雜訊比下的表現。 
0.00
5.00
10.00
15.00
20.00
25.00
30.00
35.00
40.00
5% 10% 20% 40% 50% 70%
Median filter (5x5) Median filter (7x7) Ours (5x5)
Ours (7x7) Ours+Mask (3x3) Ours+Mask2
PSNR
 
圖 3：本研究方法與中值過濾的比較（使用不同雜訊比）--訊號源 A 
0.00
5.00
10.00
15.00
20.00
25.00
30.00
35.00
40.00
5% 10% 20% 40% 50% 70%
Median filter (5x5) Median filter (7x7) Ours (5x5)
Ours (7x7) Ours+Mask (3x3) Ours+Mask2
 
 9
1. Chih-Hung Wu*, Ya-Wei Ho, Li-Wun Chen, You-Dong Huang, Discovering 
approximate expressions of GPS geometric dilution of precision using genetic 
programming, Advances in Engineering Software 45 (2012), pp. 332-340 (SCIE, 
online available) 
2. Chih-Hung Wu*, Chih-Chin Lai, Yu-Chieh Lo, An empirical study on mining 
sequential patterns in a grid computing environment, Expert Systems with 
Applications, Available online, 1 December 2011, ISSN 0957-4174, 
10.1016/j.eswa.2011.11.095. 
3. Chih-Hung Wu*, Wei-Han Su, and Ya-Wei Ho, "A Study on GPS GDOP 
Approximation Using Support-Vector Machines," IEEE Transactions on 
Instrumentation & Measurement, 60(1), pp 137 – 145, 2011 (SCIE) 
計畫中獲補助出席國際學術會議及論文發表如下（報告另附）： 
1. Chih-Hung Wu, I-Sheng Lin, Ming-Liang Wei, "Discovery of Regression Models for 
Coordinates Transformation Using Genetic Programming for a Vision-based Security 
Robot", The 12th International Symposium on Advanced Intelligent Systems (ISIS 
2011), September 28 -- October 1, 2011, Suwon-City, Korea. 
2. Chih-Hung Wu, I-Sheng Lin, Ming-Liang Wei, "Fuzzy Control of Target Approaching 
and Object-Grabbing for a Four-Wheeled Vision-based Security Robot", The 12th 
International Symposium on Advanced Intelligent Systems (ISIS 2011), September 28 
-- October 1, 2011, Suwon-City, Korea. 
 
活動與觀光區域的購物區信步可至。從此也可以看當地政府對國際化的重視與心力的
投入，值得台灣學習。 
參與成員除了地主國，國外學者有新加坡、澳洲、加拿大、中國、日本等。會議
中討論相當踴躍，休息時間更是彼此寒喧問候和交換名片，華人之間一方面也藉著難
得的機會，互相詢問與指教各國先進的研究趨勢與成果，探索進一步的研究突破與新
知，或尋求跨國與跨校共同研究的可能性；另一方面，討論國內、外高等教育的發展
和學生素質，及如何培養學生具有新奇與嚴僅的研究氣息，藉此了解國內、外學術界
的實際情況差異，適度分享研究心智與接受建議。 
本人於本次研討會所投稿之論文名稱為「Fuzzy Control of Target Approaching and 
Object-Grabbing for a Four-Wheeled Vision-based Security Robot」, 「Discovery of 
Regression Models for Coordinates Transformation Using Genetic Programming for a 
Vision-based Security Robot」，為近期研究成果與目前計畫中所使用的部分技術。此兩
篇論文被安排在 09/30 下午(Session：Intelligent Robotics II 與 Session： Vision and 
Sensors)。第一篇論文「Fuzzy Control of Target Approaching and Object-Grabbing for a 
Four-Wheeled Vision-based Security Robot」以 Fuzzy Control為基礎，應用於機器人影
像辨識與追蹤目標的分析，並與傳統迴授控制比較。第二篇論文「Discovery of 
Regression Models for Coordinates Transformation Using Genetic Programming for a 
Vision-based Security Robot」提出透過演化式學習找到機器人影像回歸的策略，結合
自主控制與環場地圖偵測的應用。報告結束後，本議題受到許多學者的討論，顯示本
議題在目前的重要性，並且獲得許多意見，報告完後的休息時間，發問的學者也給予
了寶貴的建議，使得後續的研究有更多的參考。 
 
二、 與會心得 
ISIS已經舉行超過 12屆，逐漸形成國際重要會議，所涵蓋的議題範圍相當廣泛，
也有許多跨領域的合作研究成果發表。此次會議場次可概略分為三大方向，分別為通
用之人工智慧，智慧型系統應用，資料處理技術、及相關技術，分述如下。 
1. 機器學習技術：此部份探討目前常使用之機器學習技術之一些議題，包括了
模糊理論與神經網路、機器學習、專家系統、案例推論、遺傳演算法和智慧型代理人
的結合等，均是目前相當熱門之主題。其中資料挖掘主要是從大型資料庫中整理分析
資料，以求出高階總結性之規則作為決策依據。此題目為目前資料庫及知識庫的整合
中非常熱門的一個研究方向，廣義而言，甚至可將機器學習領域納入。此次會議發表
的文章均是將傳統資料挖掘技術再做更深入的變化，以符合不同的需求。而在機器學
習部份，則包含加強式學習、模糊學習、神經網路式學習及資料群聚等文章。 
2. 機器學習之應用：此部份較強調模糊系統的實際應用，包括了交通控制、錯
內學者的投稿和參與，增加國內外學者互相切磋交流的機會，甚至彼此合作，這
是相當可喜的現象，除了鼓勵國內學者投稿國外重要會議，也希望國內專家學者
能持續獲得補助出國參加國際研討會。 
5. 會議場所常有國際知名大學，如果能進行正式拜訪，相信會對國際交流與研究合
作產生更多機會。雖然不容易取得正式管道。建議國科會可以建立聯絡窗口，或
代為聯繫。建議國科會可嘗試與國際知名大學院校，建立互動式的研究交流管道，
例如：以交換研究助理或研究生的方式，讓相關研究人員取得更多的學習機會，
體驗國際間的研究氣息。 
 
五、 攜回資料名稱及內容 
1. ISIS 2011 Conference Proceedings光碟片乙片。 
2. ISIS 2011 Conference Technical Program（會議議程表、論文摘要集）乙本 
3. 相關研討會訊息。 
 
會議實況 
 
 
Dear Author,
We are happy to inform you that your below abstract, submitted to the 12th International Symposium on 
Advanced Intelligent Systems, has been accepted for presentation at the symposium, and publication in the 
proceedings.
Abstract No.: 114
Abstract Title: Discovery of Regression Models for Coordinates Transformation Using Genetic 
Programming for a Vision-based Security Robot
Camera Ready Paper Submission: August 15, 2011
An instruction for camera ready paper is provided on the ISIS 2011 Website, 
http://www.isis2011.org/instruction.html. 
Author Registration: August 15, 2011
At least one author of accepted paper must make a Regular Registration no later than August 15, 2011 for 
presentation and publication in the proceedings. 
One regular registration will cover the publication of only one accepted papers.
Please check the related policy on http://www.isis2011.org/registration.html. 
Technical program with your presentation date and time will be posted on the website later.
We look forward to seeing in Suwon, Korea. 
Our Best Regards,
ISIS2011 Secretariat
頁 1 / 1
2012/1/31cid:20120131211430.EF6D.4266ACDD@nuk.edu.tw
ARTGA X
m
Y
m
(a) V-Frame and RTGA
(xr,yr)
Target 1
90°
180°
270°
0°
Xr
d
Target 2
Target 3
Yr
(b) The R-Frame
Fig. 2. The robot’s coordinate systems
M
1
M
2
(a) The gripper
M
0 M3
(b) The arm
Fig. 3. The actuation of the grabber
DmΘm-cylindrical coordinate system. In DmΘm, the
angle between Ym and the vector from A to the target
is θm, −90 ≤ θm ≤ +90, where θm ≥ 0 if xm ≥ 0 and
θm < 0 if xm < 0. The distance from RTGA to a target
is measured as dm, 0 ≤ dm ≤ 306, in DmΘm.
• R-Frame is a coordinate system originated on the center
of the robot’s body and has two axes: Xr and Yr, as
shown in Fig. 2(b). A unit in R-Frame is one center meter
(cm). A point (xr, yr) in XrYr is ranged on −200 ≤
xr, yr ≤ +200. Similar to V-Frame, the coordinate of
a target in R-Frame also has a dual DrΘr-cylindrical
form. They can also be transformed to each other by
standard transformation formulas.
In this paper, inputs to the fuzzy controller are the coordinates
in V-Frame. R-Frame is for approaching other targets.
The main actuators of the robot include a 5-DOF robot
arm/grabber for grabbing objects and four wheels for moving
the robot. The grabber has a gripper organized by two moving
flats at one end and a fixed base attached to the front-side
of the robot, as shown in Fig. 3. Five servos actuate the
grabber with a total of 5 DOF. The CCD camera is installed
behind the grabber’s base and its vision scope goes through
the two supports of the upper arm. The grabber performs
three actions: arm extend-forward (M0), gripper open/close
(M1/M2), and arm pull-back (M3). The robot needs to move
the body to make the target’s center to become inside RTGA.
Once the target is in RTGA, the robot arm performs actions
M1, M0, M2, M3, and M1 sequentially to pick up and put
the target into the container. The actions of the grabber are
depicted in Fig. 3.
The mobility of the robot is driven by four wheels, two
on the left-side (LF, LB) and two on the right-side (RF, RB).
Each wheel is connected with a 30:1 gear head motor and can
rotate forward or backward. If the robot needs to turn in-situ,
the wheels at one side rotate forward and the ones at another
side rotate backward. Let w denote a wheel, w=LF, LB, RB,
RB. The motors drive w with the following parameters.
1) Speed Argument (SA). SA(w) is an integer, 1000 ≤
SA(w) ≤ 1900, representing the input signal requiring
the motor to perform a certain angular speed. The
Near Far
40 200 dm
1
)(
m
dµ
0
(a) dm
Middle
5 20 45 60 80
Small Large
m
θ
)(
m
θµ
0
1
(b) θm
1100 1200 1300 14500
BF R
1600 1700
BS FS FF
SA
1
)( SAµ
1800
(c) SA(w)
Fig. 4. Fuzzy membership functions
motor stops when SA(w)=1450, forward rotates when
1450 < SA(w) ≤ 1900, and backward rotates when
1000 ≤ SA(w) < 1450. When SA(w) is 1900 or
1000, w rotates in full speed forward or backward,
respectively. The rotation speed is not constant and not
always linear. It depends on the weight of the robot and
the ground friction the wheels encountered.
2) Speed Changing-rate Argument (SCA). SCA(w) de-
notes the change rate of angular speed per second,
650 ≤ SCA(w) ≤ 1000. SCA is a parameter dom-
inating the change rate of SA. With a smaller SCA,
SA changes slowly, and vice versa.
Notice that the above equations of SA and SCA are measured
in an ideal situation where friction and inertia can be ignored.
When the robot is operated in real world, the robot’s move-
ment may not be exactly controlled by such ideal parameters.
III. THE METHODS – FUZZY OBJECT GRABBING (FOG)
The design of fuzzy methods for robot control needs to
consider the characteristics of robot’s hardware [5], [6], [7].
When the robot has decided to pick up a target and the target
is visible in the CCD scope, a track to the target is planned.
This track is to move the robot until the target is located
inside RTGA. Suppose a target is identified by (xm, ym) in
V-Frame, then the dual form (dm, θm) is calculated. The robot
needs to turn its body to eliminate θm and to move forward
to eliminate dm. These two actions need to actuate the four
wheels (LF, LB, RF, RB). Based on the characteristics of this
problem, this study develops fuzzy rules to control the robot
for picking up a target. This procedure is called fuzzy object-
grabbing (FOG). By the fuzzy control theory, the following
terms are defined.
1) Fuzzy variables: Inputs: distance (dm) and angle (θm);
output: SA(w), where w= LF, LB, RF, RB.
2) Fuzzy terms: Terms associated with dm: Near and
Far; terms associated with θm: Small, Middle, Large;
terms associated with SA(w): Backward-Fast (BF),
Backward-Slow (BS), Rest (R), Forward-Slow (FS),
Forward-Fast (FF).
3) Fuzzy membership functions: Membership functions
are defined in a continuous manner, as shown in Fig. 4.
Consider the number of fuzzy variables and terms associated
with LF, LB, RF, and RB, the number of input-output combi-
nations of control rules is 512. However, not all input-output
TABLE I
PERFORMANCE COMPARISON OF FOG AND FEEDBACK CONTROL
FOG Feedback (γ=60)
Time SR(%) AD Time SR(%) AD
A1 2.82 80.77 28.66 3.85 86.25 22.40
A2 2.21 92.31 41.79 3.03 94.25 31.11
A3 1.67 88.46 52.90 3.12 91.52 29.33
A4 2.54 96.15 37.85 3.78 89.23 23.61
B1 4.50 100.0 22.21 5.86 92.15 15.73
B2 3.47 92.31 26.61 5.23 93.23 17.83
B3 3.37 96.15 28.56 5.36 93.12 17.37
B4 3.78 100.0 26.43 5.89 89.25 15.15
where γ is the control gain. Initially, θ(t = 0)=θm. The above
rules applied on LF/LB and RF/RB for turning right or left.
Then the robot evaluates and eliminates the distance dm (with
new θ ≈ 0) by moving forward the robot. The control rules
associated with LF, LB, RF, RB for distance approaching
is SA(w) = 1600 + β × dm. In the experiments, α=2.0834
and β=0.76 are derived from a number of tests that feedback
control gives stable results.
The experiment is to evaluate the effectiveness of FOG for
picking up targets. Eight targets are placed on 8 positions, as
shown in Fig.6(c). Each target is tested for five times and the
experimental results are averaged. The experimental results
are presented in Table I and Figure 7. The results show that
when targets located on the margin of CCD vision, e.g., A1,
A4, B1, B4, FOG spent more time for target-approaching.
This is because that these targets were easily to be out of
CCD’s sight when the robot did a right or left turn. Besides,
these targets have larger θm and FOG took more inference
iterations to derive adequate SA(R) and SA(L). Conversely,
picking up targets located on the center of CCD vision, e.g.,
A2, A3, B2, B3, FOG can perform better. Regarding SR and
AD, average SR for picking up A1–A4 is less than that for
B1–B4, but average AD for A1–A4 is better than that for
B1–B4. This may be because that the dm’s of B1–B4 is
longer than those of A1–A4, so that the tracks planned for
approaching to B1–B4 are smoother than those for A1–A4 so
that the robot has a better SR in B1–B4. However, picking up
B1–B4 surely takes longer time; and AD in A1–A4 is better
than that in B1–B4.
As in most control methods, the control gain γ needs to
be adjusted. In this experiment, γ=40, 50, 60. It was found
that feedback control had longer settle time. Sometimes, the
system became instable and even breakdown when γ ≤ 50.
Conversely, FOG always performed stably. The feedback
control method spent more time in picking up all target
objects than FOG did. For the same reasons, SR for picking
up A1–A4 is less than that for B1–B4, but average AD for
A1–A4 is better than that for B1–B4. Clearly, FOG is effective
in tracking and picking up targets.
V. CONCLUSION
This paper presents the design and implementation of
fuzzy control methods for target-approaching and object-
grabbing that have been installed on a 4-wheeled vision-
based security robot. To overcome the physical inaccuracy
existing in the environments, a fuzzy controller, FOG, is
developed. The experimental results show that the proposed
methods outperforms feedback control and are adaptive to
various ground frictions. The proposed methods can be fur-
ther improved by adjusting related parameters, such as the
membership functions, and control parameters.
ACKNOWLEDGMENT
This work was supported by the National Science Council,
Taiwan, under grants NSC 99-2221-E-390-031.
REFERENCES
[1] R. Siegwart and I. R. Nourbakhsh, Introduction to Autonomous Mobile
Robots. Stringer, Cambridge, Massachusetts 02142: The MIT Press,
2004.
[2] A. Oreba¨ck and H. I. Christensen, “Evaluation of architectures for mobile
robotics,” Autonomous Robots, vol. 14, no. 1, pp. 33–50, January 2003.
[3] B. Li and C. Zhang, “Adaptive fuzzy control for mobile robot obstacle
avoidance based on virtual line path tracking,” in Proceedings of the
IEEE International Conference on Robotics and Biomimetics, 2006, pp.
1454–1458.
[4] K. K. Jung, K. H. Hyun, J. W. Kim, S. B. Chung, and K. H. Eom, “Mov-
ing target tracking of mobile robot using 1-d image projection method,”
in International Conference on Control, Automation and Systems, 2007,
pp. 994–997.
[5] M. Abdellatif, “A vision-based navigation control system for a mobile
service robot,” in Proceedings of the 2007 SICE Annual Conference,
sept. 2007, pp. 1517 –1522.
[6] P.-J. Lee, C.-H. Yen, C.-L. Chan, M.-S. Lee, and R.-C. Wang, “Imple-
mentation of a fuzzy control based intelligent robot fish,” International
Journal of Fuzzy Systems, vol. 11, no. 4, pp. 287–297, December 2009.
[7] C.-T. Cheng, H.-C. Chen, Y.-Y. Hu, and C.-C. Wong, “Fuzzy balancing
control of a small-size humanoid robot based on accelerometer,” Interna-
tional Journal of Fuzzy Systems, vol. 11, no. 3, pp. 146–153, September
2009.
0
30
60
90
120
150
180
0 20 40 60 80 100time(sec.)
d m (pixels) γ=40 γ=50 γ=60 FOG
(a) Distance approaching
-90
-60
-30
0
30
60
90
0 20 40 60 80 100time (sec.)
γ=40 γ=50 γ=60 FOGm
θ
(b) Angle approaching
Fig. 7. Experimental results on FOG
CCD camera
Box
34°
7°
39cm 200cm
17 cm
19 cm
11 cm
22 cm
PC
Fig. 1. The main structure of the robot
d
m
Target
+37°
A
(a) RTGA and the V-Frame System
(X,Y)
Target 1
90°
180°
270°
0°
X
d
Target 2
Target 3
Y
(b) The R-Frame
Fig. 2. The robot’s coordinate systems
the robot has to remember the positions of all targets. The
robot scans the environment and records their positions in
R-Frame with the aids of wheel sensors. When the robot is
picking up a visible target, the target’s location is identified
by XmYm in V-Frame. The location in DmΘm in V-Frame is
then calculated and used as inputs to the controllers. Hence,
the coordinates of targets need to be transformed between
V-Frame and R-Frame.
According to the robot’s structure (Fig. 1), the transfor-
mation of coordinates between these two coordinate systems
takes level-wise operations, such as projection, flattening,
and shifting. Fig. 3 depicts the transformation steps between
V-Frame and R-Frame. Transformations between coordinate
systems usually involve complex, non-linear, algebraic formu-
las. If necessary, the transformation process performs level-
wise conversions, starting from the source coordinates to
the target coordinates. Unfortunately, positioning accuracy is
degraded as the rounding errors are accumulated during the
transformation process. The more steps for transformations,
the more inaccuracies. Besides, from the aspect of computa-
tional costs, the more steps for transformations usually take
longer computing time and result in more power consumption;
which is a serious problem in mobile applications. This study
tries to eliminate the levels needed for the transformation of
coordinates and to produce a condensed process for target
positioning.
Robot’s CCD
V-Frame
d
R-Frame
φ
mθ
my
Fig. 3. From V-Frame (pixel) to R-Frame (cm)
II. PROBLEM FORMULATION BY GENE EXPRESSION
PROGRAMMING
Conceptually, the level-wise transformation process can be
viewed as the composition of all transformation functions.
Thus, there seemingly exists a set of transformation equations
between the visual signals received from CCD and the target
coordinates in R-Frame. This intuitively forms a problem of
regression. If formulas that perform fewer levels of transfor-
mation can be derived, the inaccuracies and computational
costs may be reduced.
Methods like linear regression, polynomial regression,
etc. [4], [5], [6] are widely used for regression. However,
their accuracy and performance vary in different applications.
For complicated or non-linear problems, these methods have
limited performance. Evolutionary-based methods are emerg-
ing methods for complex regressive problems and usually
gain satisfactory results under the control of sophisticated
parameters. Some studies on evolutionary-based regression
have been presented, such as [7], [8], [9], [10]. This paper
employs Gene Expression Programming (GEP) [11] for find-
ing simpler formulas for direct transformation of coordinates
from V-Frame to R-Frame.
GEP is a version of genetic programming (GP) [12]. GEP
describes problems in the same kind of diagram representation
of GP, but the entities produced by GEP are the expression
of a genome. The use of expression trees brings efficiency
to GEP because of easier operations of mutation, crossover,
and re-production on linear structure. For example, the al-
gebraic expression, (a × b + c) × √c ÷ d, is expressed as
a linear gene: ×+÷×cSdabcaddecbabdaa, where symbols
a, b, . . . , e are terminals (input variables or constant numbers)
and +,−,×,÷, S(sqrt) are operators/functions. The gene
expression is of length 21, with the first 10 elements the head
and the remaining 11 ones the tail. The head contains symbols
that represent both functions and terminals, whereas the tail
contains only terminals. Therefore two different alphabets
occur at different regions within a gene. For each problem,
the length of the head h is chosen, whereas the length of the
tail t is a function of h and the number of arguments of the
function with the most arguments n, and is evaluated by t =
h×(n−1)+1. With this linear expression, the computational
complexity of search for specific gene elements in crossover
and mutation can be reduced from O(n) to O(1). For solving
complex problems, GEP is efficient. For more details on GEP,
please refer to [11].
The regression problem in this study can be described as
follows. Suppose that DV is a set of positions in V-Frame
and
I = {(xi, R(xi))|0 ≤ i ≤ n,xi ∈ DV },
is a set of training data where R(xi) the corresponding
coordinate of xi in R-Frame. The purpose of regression is
to find a function R′(xi) so that R(xi) ∼= R′(xi) for all
xi ∈ DV . The error, εi, between R(xi) and R′(xi) is defined
as the least square error in the form of
εi = ||R(xi)−R′(xi)||2, ∀xi ∈ DV .
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
MSE RMSE MAE
cm from XrYr
from DrΘr
from YrΘr
(a) Derived Xr
0.0
3.0
6.0
9.0
12.0
15.0
MSE RMSE MAE
cm from XrYr
from DrΘr
from XrDr
from XrΘr
(b) Derived Yr
0
4
8
12
16
MSE RMSE MAE
cm
from XrYr
from DrΘr
from YrΘr
from XrΘr
(c) Derived Dr
0.0
0.4
0.8
1.2
1.6
2.0
MSE RMSE MAE
from XrYr
from DrΘr
from XrDr
 
(d) Derived Θr
Fig. 4. Comparisons on derived positions from regression models
such phenomena.
IV. CONCLUSION
In this paper, GEP is used for regression for the trans-
formation of target coordinates in vision-based robot appli-
cations. With such regression models, the target coordinates
can be calculated by simpler formulas with less processing
time. The method is integrated with the robot’s vision system
and is verified in real environments. The experimental results
show that the proposed method is able to produce simple
and precise transformation formulas and improves the robot’s
performance.
ACKNOWLEDGMENT
This work was supported by the National Science Council,
Taiwan, under grants NSC 99-2221-E-390-031.
REFERENCES
[1] Y. Zhou and M. Er, “An evolutionary approach toward dynamic self-
generated fuzzy inference systems,” IEEE Transactions on Systems,
Man, and Cybernetics, Part B: Cybernetics, vol. 38, no. 4, pp. 963
–969, aug. 2008.
[2] C.-C. Tsai, C.-C. Chen, C.-K. Chan, and Y. Y. Li, “Behavior-based
navigation using heuristic fuzzy kohonen clustering network for mobile
service robots,” International Journal of Fuzzy Systems, vol. 12, no. 1,
pp. 25–32, March 2010.
[3] R. Siegwart and I. R. Nourbakhsh, Introduction to Autonomous Mobile
Robots. Stringer, Cambridge, Massachusetts 02142: The MIT Press,
2004.
[4] J.-T. Chien and C.-H. Huang, “Aggregate a posteriori linear regression
adaptation,” IEEE Transactions on Speech and Audio Processing,
vol. 14, no. 3, pp. 797–807, 2006.
[5] L. Lindbom, M. Sternad, and A. Ahle´n, “Tracking of time-varying
mobile radio channels –Part I: The wiener LMS algorithm,” IEEE
Transactions on Communications, vol. 49, no. 12, pp. 2207–2217, 2001.
[6] X. Xiao, Y. Li, and R. Mukkamala, “A model order selection criterion
with applications to cardio-respiratory-renal systems,” IEEE Transac-
tions on Biomedical Engineering, vol. 52, no. 3, pp. 445–453, 2005.
[7] C. Zhou, W. Xiao, T. M. Tirpak, and P. C. Nelson, “Evolving accurate
and compact classification rules with gene expression programming,”
IEEE Transactions on Evolutionary Computation, vol. 7, no. 6, pp.
519–531, 2003.
[8] E. E. Korkmaz and G. U¨c¸oluk, “A controlled genetic programming
approach for the deceptive domain,” IEEE Transactions on Systems,
Man, and Cybernetics, PartB, vol. 34, no. 4, pp. 1730–1742, 2004.
[9] S. Gustafson, E. K. Burke, and N. Krasnogor, “On improving genetic
programming for symbolic regression,” in Proceedings of the 2005
IEEE Congress on Evolutionary Computation, vol. 1, 2-5 Sep 2005,
pp. 912–919.
[10] E. O. Costa and A. Pozo, “A (µ + λ)–GP algorithm and its use
for regression problems,” in Proceedings of 18th IEEE International
Conference on Tools with Artificial Intelligence, Nov. 2006, pp. 10–17.
[11] C. Ferreira, “Gene expression programming: A new adaptive algorithm
for solving problems,” Complex Systems, vol. 13, no. 2, pp. 87–129,
2001.
[12] J. R. Koza, Genetic Programming: On the Programming of Computers
by Means of Natural Selection. The MIT Press, 1992.
99 年度專題研究計畫研究成果彙整表 
計畫主持人：吳志宏 計畫編號：99-2221-E-390-031- 
計畫名稱：混合整數與實數編碼與模型演化機制在類比線路設計上的研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 100%  
研究報告/技術報告 1 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
