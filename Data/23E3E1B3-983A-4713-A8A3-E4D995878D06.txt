 1
□成果報告 行政院國家科學委員會補助專題研究計畫
■期中進度報告 
 
用於互動式三維多視角顯示器之智慧型互動式綠能多核心圖形處理單元技術-子計畫
二：應用於互動式之多視角顯示系統的三維自然模擬(2/3) 
 
計畫類別：□個別型計畫 ■整合型計畫 
計畫編號：NSC 100－2200－E－110－003 
執行期間：100 年8 月1 日至101 年10 月31 日 
 
計畫主持人：李宗南 
共同主持人： 
計畫參與人員：張簡大敬 陳翔竣 楊智翔 謝文婕 張庭愿 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告■完整報告 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列 
   管計畫及下列情形者外，得立即公開查詢 
   ■涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
 
執行單位：國立中山大學資訊工程系 
中 華 民 國 101 年 7 月 26 日 
 3
係，但遺憾的是目前只能單純透過 3D立體眼鏡來與觸控式螢幕來進行互動。有鑑於此，
在本計劃中我們提出一個可直接對虛擬空間中作ㄧ互動之技術，以增進人類對自然視覺
的追求。 
此外，近年來基於物理的流體模擬已成為計算機動畫領域中的一個研究熱點，且台
灣本身是屬於海島型氣候，颱風與土石流等天然災害不少，若能提供一個有關治水防災
的自然模擬系統，將能協助緊急避難、逃生及應變，以提升防災救災之效能。故如何基
於一個 3D立體顯示與虛擬實境之技術，透過一可互動式的情境操作以提供人類來針對
自然現象做ㄧ模擬(如火災、海嘯、土石流與颱風等)，是未來一個研究的新趨勢。對此，
在本計畫中我們提出一個互動式之多視角顯示的 3D 自然模擬應用，依據自行開發之
OpenGL ES 2.X API為基礎，與搭配一個平行 Programming API，來提供 3D graphics 
multi-view GPU 所需之 3D 模擬資料。將 3D 自然模擬實現於在我們專屬之硬體
(SYS-3DG multi-core)，並與其它硬體子計劃整合來提升硬體之處理速度，使得能真實
有效地滿足與呈現人們對真實感、實用性及靈活性上等需求。 
II、文獻探討 
對於研究計畫之背景及相關研究，在本計劃中第二年主要圍繞在『自然動態特效模
擬設計』與『3D立體技術與互動』之上，說明如下：  
 2.1. 自然動態特效模擬設計 
近年來，對於流體相關的內容上的處理，在國內外的研究上，有日漸增加的趨勢。
然而目前計算機動畫所關注，仍是人眼所可感知之現象，因此先今主要研究皆集中在低
速流之議題上，如煙霧、自由運動界面、流固耦合與火焰燃燒等。而低速流給人的觀感
不僅只觀賞性強之外，還給人一個足夠的附應時間的特性。此外，由於台灣近年來颱風
與土石流災情頻傳，災害範圍程度也較過去擴大及增加，因此若能提供一個基於物理的
流體模擬系統應用已是未來研究熱點。目前許多專家學者已開始著手相關研究，如由礫
石、泥砂及水組成的高濃度混合物，因受重力作用所產生之流動現象，即土石流(debris 
flow)。然而此等模擬皆需要大量運算，對於即時互動而言相當不易，因此必須藉著模
擬演算法之改良，與透過多核心之處理運算，以符合即時互動與效率上之需求。在此計
畫中，以下我們將會針對『自由運動界面與流固耦合』、『火焰燃燒』與『土石流』上分
別作ㄧ描述。 
 5
表的為流體體積比函數，且其優點為滿足體積守恆，並透過結合CIP(Cubic 
interpolated propagation)方法求解VOF方程以進一步提升精確。或者是採用混合
Level set和VOF方式亦通稱為(CLSVOF:combined level set and volume of fluid )以綜
合兩者的長處[36]。Level set與VOF的缺點是無法處理界面處的密度、黏性和壓強
的不連續性，以至無法表現表面張力的作用，為了克服該缺點，須引入其他源項。 
對於Particle level set而言，在基於體的建模轉到基於表面的建模之下[39]，會
在表面內外一個很窄的區域會分佈若干粒子，利用這些粒子來偵測界面處的不精確
度，並透過粒子局部的Level set函數 pφ 來加以校正，從而保持界面上原有的尖銳特
徵。一般而言通常是透過將速度往外推廣至空氣中，從而以正確處理該界面處上速
度，以獲得更精確的視覺效果。對於Particle level set而論，兼具Level set的易用性
與VOF靈活性[40]。 
Ghost fluid法則是一個可避免界面處的平滑處理，該方法利用函數將含有這兩
種流體的流場，分成各具一種流體的兩個流場，藉此來改善。設定界面內的流體為
流體 )0(2 ≤φ ，界面外的流體為流體 )0(1 >φ 。對於一個只含有流體2的流場(稱之為
流場2)，界面內的點為真實點，其具有真實的物理量；而界面外的點為流體2的虛
擬點，其物理量為界面內真實點物理量。採用level set來追蹤氣體回應區的移動隱
式曲面，為了解決兩種不同的氣體計算過程出現的界面法向速度不連續的問題
[41]，引入幽靈(Ghost)速度值，利用切線速度的連續性來得出正常值。對於界面壓
強的不連續，則採用Ghost fluid法來處理，成功地解決有關接觸面間斷的模擬問題，
該方法本身不僅沒有數值耗散的問題，且又易於消除非物理上的震蕩，對於具有不
同狀態方程的流體接觸面兩端能夠輕易地處理。目前對於基於拉格朗日方法的流體
表面演算法[42]，需先確定流體表面的粒子，然後根據這些粒子的構造出等值曲
面，在對其多邊形化。文獻[43]是基於網格，構造粒子系統下的Level set方程來重
建出自由表面。 
對於流固耦合問題，簡言之即是如何考慮流體與固體間的相互作用，如水中漂
浮物、帆船、防波堤和風中飛揚的旗幟等。目前由於很多文獻只著重於處理單向作
用，如固體對流體的作用，即固體運動是已知的，利用固體運動來改變流體的運動
狀態，且固體本身運動並不受流體之影響；或者流體對固體的作用，即固體在流體
 7
關研究中，也不乏有採用粒子系統作為實作自然現象模擬的文獻，如文獻[49]即為
針對模擬複雜的流體表面移動，另外文獻[50]也採用粒子系統針對水花濺起的現象
作一探討。此外基於一火焰粒子之變動資訊，並搭配後端優化處理，以產生如真實
影片般之快速燃燒傳導動畫[51] 
粒子系統對於傳統描述物體表面導向的方法有兩點好處：一、只需計算單一點
的座標，故計算複雜度小於計算多邊形的方式；二、因計算步驟為程序式，故易於
控制內部參數且可調整 Level of detail來因應視野的變化，相對於傳統方式，粒子
具有『生命』的特性，可充分表現時間演進對於物體之影響。此外，除了透過 NS
方程來計算 3D網格之外[52]與一個無條件穩定的解答型式來模擬火燄[53]，還能夠
以其作為基底，發展出一個具有額外黏滯性的模擬，以補償在每個時間步驟間過度
發散之現象。此外之後更提出透過前述之架構並利用等位函數法(Level set)來追蹤
火焰反應區域，以模擬出網格火焰效果，但此方法無法表現火焰強烈對流之細節，
所以需透過三階曲線方程式對 Level set演進作修飾以產生有趣的皺摺表面[54]。但
如此的作法衍生出另外的缺點為網格解析度決定了該模擬結果的精細度，因此要產
生圖像般精細的大規模效果，其成本將會是極度昂貴的。此外，亦有提出一個藉由
結合追蹤粒子和解 NS方程的網格之混和模擬方式，以製作相關動畫，如砂礫的動
畫[55]。文獻[56]發展一個可避免視野限制之大規模燃燒現象，而文獻[57]則建立在
一個以可壓縮流作為高速燃燒過程的模擬模式。但由於上述方法，並沒有一種能夠
完全模擬火焰實際燃燒過程的模式，因此在本計畫中，我們主要圍繞探討在如何利
用一段實際影像序列，並搭配影像處理的萃取特徵能力，以實作出一個能夠自動提
供使用者開發火焰動畫之相關參數的系統。 
 2.1.3. 土石流 
土石流屬於非牛頓流體，物理特性非常複雜。其中泥流的流速通常較快，破壞
程度較小，但是傳遞距離也較長，災害的主要型態為淹沒農地與民宅。目前在泥流
中，觀察到間歇性的湧浪，若在土石流流動過程中，發生滾波等不穩定現象，對防
治設施、監測設備的位置、形狀、設計強度均有不同的規劃設計，如土石流警戒系
統[58]。 
透過賓漢流體沿緩坡流動且利用 Karman’s 動量積分法(Karman’s momentum 
 9
System)』、『虛擬魚系統(Fish Simulation System)』來分別描述。 
2.2.1. 影像學習系統(Visual Learning System) 
為了讓一個互動魚缸系統具有趨近真實性的互動機制，首先我們先透過影像學習的
機制來分析影片中相關資訊，如魚的移動路徑、魚的形狀等。因此我們先將輸入的影像
做分割(Segmentation)以得到物體外型、貼圖與特徵等資訊，接著可將此些資訊與資料
庫中的模型做一比對(Model Matching)，並擷取物體的動作 (Motion Extraction)，以求得
的動作路徑來提供給學習機制，以下將會對『影像做分割(Segmentation)』、『模型比對
(Model Matching)』與『動作擷取(Motion Extraction)』分別說明： 
 影像分割(Segmentation) 
擷取影像資訊一般常見分割方法，可分成時間(Temporal)與空間(Spatial)兩類
理，Zhu等人在時間方面利用 FDM (Frame Difference Mask) [66]的方式來產生一個
遮罩，藉此遮罩將影像中之移動的物體作一分離，並將未移動的背景透過遮罩來加
以濾除，只留下移動變化之人物部分。而在空間方面 Zhu 等人則透過將影像分成
多個區塊，每個區塊擁有個別的臨界值，將區塊內的值與臨界值相比，來取得影像
的邊界資訊，並先將區塊大小內的所有值相加，再除以一常數，藉此求得每一區塊
不同的臨界值，再利用臨界值與周圍的像素相比以得到邊界資訊。最後將時間域及
空間域分別求得的資訊整合起來，來將影片中移動的物體分割出來。Zhang等人，
一樣是利用時間及空間的資訊來對影片做處理，並採用 FDM值來做運算[66][67]，
計算前後相鄰影像的相減值，接著計算 FDM值設以 0和 1來做為遮罩。此外由於
利用時間與空間域來做分割的方法，實際上很容易因為雜訊的干擾而產生誤差，分
割出來的效果也較不理想，所以 Messaoud 等人[68]提出一個不同的方法，利用
ACM(Active Contour Model)結合 UKF (Unscented Kalman filter)來對影片物體做分
割及追蹤的動作。ACM 可分為以邊界為基礎(Edge-based models)和以區域為基礎
(Region-based models)兩種方式，而常見的以邊界為基礎的模型有 GAC(Geodesic 
Active Contour)，但 GAC只能針對初始化時設定的輪廓來做計算，意即 GAC只能
找出部分區域的完整輪廓，若一開始不包含在初始設定中的物體，則無法偵測。另
外以區域為基礎的模型，如 C-V(Chan-Vese) Model，則可找出全部區域範圍內的所
有物件輪廓。為了有效地求出物體的輪廓，文獻[68]透過 SBGFRLS (Selective binary 
 11
2.2.2. 虛擬魚系統(Fish Simulation System) 
為了對於一個 3D立體即時互動，如魚缸內水中生態與互動等，為了提供使用者更
逼真的虛擬實境體驗，在建置魚缸內生態環境的過程中，常會將重點放在如何設計逼真
的擬真魚，對於實作上可分成外型設計、游動方式、人工智慧或變形方面來探討。外型
設計主要著重在建構網格之上(Mesh)，透過控制網格上骨架來移動或旋轉骨架以造成網
格的變形，藉此模擬生物的活動行為[75]。此外由於魚在生理構造的獨特性，使得魚的
游動方式完全依賴脊椎來擺動，而脊椎擺動曲線近似於數學三角函數曲線，故可透過分
類歸納的方式來模擬[76]。人工智慧方面則依據現實世界中，魚所表現出之獵食、群聚
性或空間感知等特性，將這些特性數值化後用於控制魚在何時基於何種狀態而應採取的
合理游動軌跡。文獻[77]探討魚的一個視野機制，使能感知外在環境並做一 AI 判斷，
進而做出反應。文獻[78]則提出魚與外在環境的互動反應，如地面或魚缸邊界等障礙
物，此外亦可表現出魚的群聚現像。此外文獻[79]提出一個透過外型曲線的變形來模擬
幼魚至成魚階段。 
III、研究方法 
本計劃為了達到一個 3D立體顯示與虛擬實境之技術應用，透過一個可互動式的情
境操作以提供自然現象模擬。首先利用 ARM versatile platform做為基礎硬體開發環境，
與搭配自行開發之 OpenGL ES 2.X API，且透過一個Windowing system與一個 Operating 
system(Linux)和一個專屬之 3D 多視角(Multi-view) SOC 驅動來協助軟硬體間的協調，
以開發多種 3D自然流體特效。並且藉由 OpenGL ES 2.X之 shading language來呈現並
成像出一個 3D自然流體特效，並利用一個平行 Programming API與一個 Shader compiler
來協助自然特效之平行運算與開發，以供 3D graphics multi-view GPU所需之 3D模擬資
料。當硬體完成之後，在將 3D 自然流體特效實際執行在我們所自行開發之硬體
(SYS-3DG multi-core)上，以呈現出 Multi-view 之硬體加速效能。此外透過一個圖形效
能評估工具與 3D自然景觀開發模組，來協助開發者進行自然模擬特效之開發，並整合
所有系統功能，即包含軟體、驅動系統與硬體等，來協助完成整個系統即時偵測，整體
軟硬體架構如圖一。 
 
 13
對嵌入式系統所量身制定。其本身為一個應用於嵌入式系統中一跨平台的 2D與 3D的
圖形 API，故可應用於可攜式裝置(Handheld devices)、現代設備與運輸工具等系統中。
此外，由於 OpenGL ES本身是屬於 OpenGL[81]的一個子集並加入一些擴展的功能，因
此能使得原本在一般個人電腦上所開發的遊戲及應用軟體，可以很容易的移植到嵌入式
系統之中。為了提升效果在 2005年訂定了 OpenGL ES 2.0架構，其提供了一個 Shading 
language的功能(Vertex 與 Fragment shader)，其主要差異在於，OpenGL ES 2.0它可來
增強一些如流體模擬效果與製作精細的水面特效和自然之水波動畫帶來非常大的幫
助，以下我們將圍繞在軟體系統之『自然動態特效模擬』與『3D 立體技術與互動』來
進一步說明。 
3.1. 自然動態特效模擬 
在所有的自然模擬中，水對我們而言是相當重要的。在日常生活中，隨時隨地都可
看到，也正因它在生活中扮演著重要角色，因此我們欲先模擬海水變化，接著探討水與
固體間關係，接著再分別模擬出火焰與土石流現象。因此在本節中我們將著重在海水變
化之流體方程來敘述，詳細的自然動態特效之實作將於第四章時再作一詳述：  
 3.1.1.流體方程 
    Navier stokes(NS)方程是流體力學中描述粘性牛頓流體的方程。先前研究，由於科
學家看到理論流體與工程實際相差太遠，故試圖給尤拉理想流體運動方程加上摩擦力
項。如納維(Navier)、柯西(Cauchy)、泊松(Poisson)、聖維南(St.Venant)和斯托克斯(Stokes) 
分別以自己不同的方式對歐拉方程作了修正，其中 Stokes首次採用動力粘性係數 µ。目
前此些粘性流體的基本方程即稱稱為 NS 方程。如果要模擬的流體密度的變化很小甚至
可忽略不計的話，則稱此流體為不可壓縮流體，因為海水的密度變化很小，因此在這裡
我們所採用的是不可壓縮流體的 NS方程式。 
    NS 方程包含物體力 gF 、壓力 pF 及黏力 vF 三種力。在海水模擬中，物體力只有一
項即重力( GFg ρ= )，其中 ρ為密度，G為重力(9.81m/s2)；壓力是從水內部向法向量方
向到水的表面，定義為負的 ( pF ⋅−∇= )；至於黏力是根據牛頓流體的定義
( VFv
2∇= µ )，其中 VL/1 ρµ = 、ρ為密度、V 為速度而 L為維度。接著將這三種力代入
牛頓第二運動定律( mAF = )，式子如下：  
 15
置，擷取手部的三維座標(x、y與z)，接著利用內部的depth map資訊來與 3D 立體畫
面做結合。此外為了讓使用者有真實魚缸的感覺，我們提出一影像學習的機制，讓
魚缸內的魚有更趨近於真實的動作。對於從Kinect而言，其機身上具有三顆鏡頭，
中間的鏡頭為RGB攝影機，左右兩邊的鏡頭分別是紅外線發射器和紅外線CMOS 攝
影機所構成的3D深度感應器。Kinect透過一個名為Light Coding 的技術來準確偵測
深度資訊，其理論為利用左邊紅外線發射器先對測量空間進行編碼，當紅外線照射
到物體時會形成隨機的反射斑點，亦稱之散斑。此外由於空間所形成的散斑通常不
會相同，所以將這些散斑進行編碼，接著利用右邊的紅外線感應器讀取編碼的光線
後，再進行運算解碼以產生一張3D 深度的圖像。 
 
圖三、Kinect 外觀圖 
IV 、研發結果與討論 
第二年的研發結果主要圍繞在『自然動態特效模擬設計』與『3D立體技術與互動』
來探討，分別說明如下： 
 4.1. 自然動態特效模擬設計 
在第二年的計畫中，對於自然動態特效模擬主要是圍繞在『海洋模擬』、『火焰燃燒』
與『土石流』上，分別作ㄧ描述。 
4.1.1 海洋模擬 
對於海洋模擬部份，我們提出了一種基於切片之流固耦合方法來進行海洋模擬，其
包含了流體模擬、固體模擬及交互作用三大部分。在流體模擬方面，首先利用納維-斯
托克斯方程式作為物理方程以進行二維切片的海洋模擬，過程中加入固體模擬之物件，
其主要由 mesh 建構之三維固體物件(如海底地形或船隻等)，接著選取出關鍵切片，並
藉由內差求得關鍵切片之參數，過程中並記錄每個切片中之固體所在位置，之後利用納
 17
Start
Generate
grid
Setup initial 
parameter
Load solid
mesh object
Select key
slice
Solve NS
equation
Calculate the 
fluid momentum 
change to solid
Setting solid 
velocity to fluid
Update the 
position of solid
Continue
simulation?
End
Yes
No
Update VOF
Surface 
reconstruct
Expansion to 3D Render
 
圖五、海洋模擬之系統流程 
 
¾ 流體模擬：對此部份而言，重點在於其水波的波動變化，因此我們使用了 NS方程
式來計算出流體的變化，透過 VOF 來解決自由液面的問題，經由線性內插結合噪
音函數得到差值，最後透過重構等值面來畫出水面，以模擬出真實效果，以下將分
別作一詳細介紹。在海水碎浪模擬中，根據目的不同，可大概分為『速度』和『真
實度』兩種類型討論。追求速度目的大多採用高度場方法，它可以獲得快速結果，
基本上可以達到即時模擬，但其模擬結果並不是真的物理變化所求得，而且由於模
擬方法的限制，使得真實度上無法得到碎波的模擬結果；而另依種以真實度為目的
的模擬，由於採取的模擬過程中，帶入大量的物理公式，去獲得真實準確的結果，
因此有較高的真實度，且可以模擬出碎波情形，但由於運算量的龐大，也使得速度
變慢，往往一張畫面需要數十秒，設置數分鐘，這昂貴的代價使得應用上有了很大
的限制，在此，我們分別對這兩種模式實作應用。 
高度場方法透過捨棄 3D的完整模擬，而採用二維的模擬環境來節省運算量；
在一海水平面中透過一高度函數，將平面上的頂點代入該函式後，即可獲得該平面
高度，藉此架構出一 3D 的模擬海水環境，Gerstner 波是一種相關的方法之ㄧ，它
的水波有波峰尖銳，波谷圓滑的特徵，而且它不比普通的正餘弦波動方程複雜，但
更卻像水波。我們實現它以網格之模式如圖六(a)，並且加入打光及應用凹凸貼圖
 19
V V
Fluid
 
圖七、No-slip boundary condition 
 
在交互作用之後，固體會因受到力作用而產生移動及旋轉，圖八表示物體所受
的力總和為 54321 FFFFFF ++++= ，根據牛頓第二運動定律及運動學方程
( atvv += 0 )，來改變速度及移動位置。此外，施加於固體上的力也會造成固體旋
轉的行為，如圖八中 Ri為各力到質心的垂直距離，其淨力矩為 ( )∑ ×=
i
iF iRτ ，而
τ=
dt
dL ，且 ωIL = (其中 L為角動量、I為轉動慣量與 ω為角動量)，所以可得到淨
力矩( aI ×=τ )為，其中轉動慣量乘上角加速度 a。為了能夠讓流體跟固體間的互
動更加真實，我們將固體與液體交界處之網格做更細的細化，根據物件與固體接觸
面來使用不同的大小網格，如圖九。在將網格細化後，更能在網格中有效的描繪出
固體外型。 
F1
F2
F3
F4
F5
centroid
R1
 
圖八、Force and moment 
 
 21
體與固體。在挑選關鍵切片時，若只選擇到全液體時(如 S1及 S9)，則會在進行內
插時將兩個切片中之情況判斷為全液體，故須根據固體所在位置，來選擇關鍵切片
(如 S2及 S8切片)，此外亦須挑選到 S5及 S6才兩切面才可模擬出轉角的情況。 
 
X
Z
S1
S2
S3
S4
S5
S6
S7
S8
S9
 
圖十一、Key slice select 
使用二維切片來進行海洋模擬時，因無法得知物體詳細輪廓，所以過程中需利
用挑中切片之鄰近切片來進行物體形狀判斷，以 S2為例，須多挑選 S1及 S3兩個切
片並根據固體所在位置判斷出物體外型，並利用流固耦合計算出水的流動方向。此
外當固體複雜度較高時，需選擇過多的切片，因而增加運算時間，所以在進行關鍵
切片選擇時，我們先根據物體複雜度，亦即 mesh 個數的多寡，來選擇切片之間的
間距，如當物體複雜度較高時，則需要較小的間距來有效表達該物體之特性。 
海洋之中，除了遠洋的部分其主要由水所構成，其中海底的地形提供邊界條
件，而在近灘的部分，由於固體接觸到空氣、水跟固體之間的交互作用，因影響到
自由液面的變化，進而產生浪花，故在進行關鍵切片必須根據海岸線走向來選擇與
之垂直的切片來進行運算處理，才能經由二維切片運算以突顯出海水沖擊沙灘時所
造成的效果。至於交互作用之做法，主要是藉由能量的傳遞來造成各種變化，當流
體碰撞到固體時，除了造成流體改變移動方向外，也會將能量傳給固體，造成固體
狀態改變。反之，固體也會因受到水的阻力，造成速度或方向的改變，進而造成能
量變化，且減少的能量則會傳至給流體。以下將分成流體對固體及固體對流體兩個
部分來探討。 
 23
表二、三維海洋模擬與二維切片海洋模擬的時間比較 
Grid size 100*100*100 
3D simulation Computation 
time(fps) 0.288933 
Grid size 100*100*100(5 slice) 
100*100*100 
(10 slice) 
100*100*100
(15 slice) 2D slice 
simulation Computation 
time(fps) 3.619503 2.721762 2.256938 
第二部分則為二維切片海洋模擬與加上流固耦合之比較，圖十二(b)可看出因
無法與邊界相互作用故海洋與附近相鄰地形有些怪異，因此無法模擬物體漂泊於海
面上之情況，所以對於二維切片中我們加入了流固耦合之效果。圖十三為加入流固
耦合之後的結果，從圖中可得知流體撞到固體能夠有效的產生交互作用。 
(a) (b) 
圖十三、加入流固耦合的結果：(a)第 15個 frame的結果與(b)第 60個 frame的結果 
第三部分為二維切片加流固耦合之海洋模擬，鑒於上述之二維切片模擬在結合
流固耦合時會造成流體表面不順暢之缺點，所以我們挑選出切片之後，加入第三個
維度上的速度，使得流體可在第三個維度上流動，並且透過切片法來減少運算時
間。圖十三為目前提出之模擬結果，其場景為海浪打向岸邊，藉由關鍵切片挑選，
如 15個切片；與圖十二(a)相比，可以看出海浪會受到地形作用影響。而圖十五為
沒經過 Doo-Sabin 細化曲面之結果，三角片與圖十四的結果相比變得較明顯。 
 25
 
圖十七、計算時間的比較 
4.1.2. 火焰燃燒 
對於火焰模擬部分，在此計畫中我們提出一個利用實際火焰影像萃取出的影像特徵
資訊來增強火焰模擬 rendering 效果的方法，系統架構圖如圖十八。本架構主要由兩大
階段和一組中介資料所組合而成：第一個階段為前處理(Preprocessing)步驟，主要用途
在於將影像中火焰之輪廓取出，並搭配我們的演算步驟將特徵點以及影像動態記錄下
來，由於其處理時間較長，因此以 offline 方式進行；而中介檔即為前述步驟所取得之
資料以及原始影像檔之集合，稱為 fire profile；最後的階段為顯示(Rendering)步驟，即
為利用 fire profile加上一個火焰統計學習器(Fire statistics learner)，可讓有限的影像資源
得以有效的持續使用並提供讓使用者輸入外部力量，再透過加入兩個由我們開發之管理
模組改進的粒子系統將學習器所提供之資料以 online方式繪出以產生火焰動畫。以下將
會針對『前處理(Preprocessing)』、『火焰統計學習器(Fire statistics learner)』與『顯示
(Rendering) 』三部分來敘述，說明如下。 
 27
Feature
Extraction
Motion
Extraction
Source 
Image 
sequence
Feature
Points
Motion
Vector Fire
Profile
Threshold
Edge Detection
Contour
Image
 
圖十九、前處理流程圖 
  
(a) (b) (c) 
圖二十、輪廓萃取 
表三為 fire profile資料結構表，包含特徵點及動態向量兩部分。其中特徵點又可分
為底部區域和火焰頂點兩部分，底部區域由六個特徵點組成，分別為左右上下四極點與
兩個位於左右點和底點間二分之ㄧ位置的補充點。特徵點可用來形塑火焰外觀，動態向
量可用以計算粒子之平均速度。六個火焰特徵點的分布如圖二十一，令 I為火焰輪廓點
之集合代稱，左右兩點即為低於一 threshold 之下之最寬的火焰端點，而底部端點為此
左右兩點間之最低點，最高點 top(I)為影像中最高之輪廓點。另兩個底部之補充點各為
左、底點間之輪廓上中點和右、底點間之輪廓上中點。 
 
表三、Fire profile之資料結構 
 29
Image 
Sequence
Framet Framet+1
 
圖二十二、找尋動態向量之示意圖 
¾ 火焰統計學習器(Fire Statistics Learner)：學習器架構圖如圖二十三，當我們已有
fire profile資料之後，接著我們希望將有限數量的影像檔中，案取出火焰特徵來有
效利用，以產生擬真且無限之火焰動畫。本學習器由兩大部分構成，第一部分為一
個 fire status state machine，其作用在於將一個以手動整理的傾斜狀態資料檔案根據
使用者輸入之外力選擇出對應的火焰特徵點，並更改火焰的狀態再輸入給後續的粒
子系統；第二部份是將原始的影像資料中火焰部分選出，並將其長寬正規化並平均
各區塊內的 RGB通道值，以提供粒子系統作為修改粒子顏色的參考查詢表。 
Fire
Profile
SFCCT
(Spatial Fire Color 
Correlation Table )
Leaning 
State Data
Fire Status 
State Machine
Feature
Points
Source
Images
Manually Classify 
the Feature Data
Averaged the 
Color Value
Shape
Color
Switching the 
leaning state
Feature Point
Data
External Force
Fe a t u re  St a t is t ic  Le a rn e r
Send to 
particle 
system
Referenced 
by particle 
system
 
圖二十三、特徵統計學習器之架構圖 
 31
X
Y
0
0.2
0.4
0.6
0.8
1
x
x
B
x
G
R
 
圖二十五、影像中火焰部分作色塊內之色值統計 
 
表四、Spatial Fire Color Correlation Table(SFCCT) 
218.49
242.77
253.93
252.89
254.28
253.52
none
none
none
none
none
none
none
none
none
0.8 – 1.0
209.14
241.68
254.57
251.85
253.99
254.13
249.7
254.28
254.13
233.98
247.41
252.83
221.06
242.87
253.75
0.6 – 0.8
193.3203.82194.43
235.66238.60240.84
253.84237.55237.55
254.27246.65246.65
254.46254.43253.470.8
|
1.0
254.74254.46254.50.6
|
0.8
0.4 – 0.60.2 – 0.40.0 – 0.2
0.4
|
0.6
0.2
|
0.4
0.0
|
0.2
254.06253.53
227.09231.02
245.01247.38
254.38254.57
253.25248.46
254.43253.17
254.72
237.18
Ratio of Fire Width
234.33
254.59254.61254.84
230.43
245.36
254.3254.5
none
none
254.36254.72none
R
atio of Fire H
eight
 
 
 
 33
 
圖二十七、粒子位置與對應之顏色 
 
 圖二十八為粒子移動之示意圖，粒子由建立好的底部區域出發，而其建立方式可由
以下式子來求得， 
( ) ( ) ( )( ),SeCubicSplin ,xInnery ,xEmitter =  
( ) ( ) ( ) ( ),IRightxILeft 1, 0,  ,
2
xexp
2
1 xInner xx2
2
<<==⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−= µσσ
µ
πσ  
其中 ( )yxEmitter  , 代表粒子在二維區域上之分布方式， ( )xInner 為粒子在水平方向上的
分布函式。一般而言，若一個物體以類物理方式移動，在電腦圖學領域中我們常會採用
曲線方式來將一個物體從一個端點移動到另一個端點，但在影像中我們難以決定外部的
參考點，所以只能單純地 fitting可見的線，故在此計畫中我們採用 Cubic spline來改善。 
Top(I)
Left(I)
Right(I)
Bottom(I)  
圖二十八、粒子移動之示意圖 
 
由於我們影像的來源是由未同步化的影像來形塑火焰的效果，因此如何確定唯一的
 35
圖三十(a)表示我們 3D火焰重構的結果，其由兩台照相機機所攝之 2D影像如圖三
十(b)與(c)所重構。圖三十一為利用 fire status狀態機器所產生的一序列之燭火動態模擬
結果。由圖三十二可知，我們模擬之結果如較於 Bridault-Louchez等人提出之方法，在
火燄外型上更能近似於真實的火焰影像。 
  
(a) (b) (c) 
圖三十、火焰模擬與真實影像之結果(a)Proposed method、(b)Captured by FUJI F-30照相
機與(c)Captured by RICOH GR Digital III照相機 
 
 
圖三十一、The snapshots for demonstrating the transition of candle leaning state 
 
  
(a) (b) (c) 
圖三十二、模擬結果之比較: (a)實際影像、(b) Bridault-Louchez[86]與(c) Proposed method 
 
 
 
 37
面坡度(河床坡度加上水流梯度)並以擴散波方程式 fx ox
hS S
x
∂= − ∂  來 計 算 流
速，如二階牛頓迭代法中的一次估計。速度被用來決定完全動力波方程式的根，
而摩擦坡降 Sfx公式如下 
2 2
2 4/38
y x td x
fx
m m
K V n VS
h h h
τ η
γ γ= + +              (3) 
其中 yτ 代表降伏應力， mγ 為混合流體的比重，流阻參數K與黏滯性η， tdn 則為
Manning’s equation中的流阻 n值。在完全動力波動量方程式，局部加速度項是
由上一時間步驟給定之速度微分而成，對流加速度項則是上一時間步驟通過網格
的流速所微分而求得，舉例來說，如圖三十四所示，網格 5東邊方向的局部加速
度項 1 xV
g t
∂
∂ 可轉換為
1
6 6 5( ) /( * )
t tV V g t−∆ − ∆ ，其中 6tV 為網格 5在 t時間東邊方向的
速度， 16tV − 為前一時間東邊方向的速度，∆t是以秒為單位的時間，g為重力加速
度。另一個相似的對流加速度項 x xV V
g x
∂
∂ 可以被產生，如方程(4) 
 1 1 16 6 4 5( ) /( * )
t t tV V V g x− − −×∆ − ∆                                      (4) 
其中 16tV − 為網格 5 東邊方向的速度，而 14tV − 為西邊方向的速度，其中速度乘上時
間和局部流動區域可求得跨越網格邊界的流量，在八個方向的流量皆求出後，依
網格進或出的水流流量改變(八個方向的流量總和)乘以時間以決定網格含水的
變化量。含水變化量除以網格面積以取得該時間流深的增減。除了流深是跨區域
通道的函式，通道佈線整合在本質上相同，且共用流量通常只有一條順流跟一條
逆流通道網格。 
 39
之角，因此將每個網格與周遭八個網格相加後平均，經過此些步驟後所得之三維圖
形如圖三十五(b)，與未平滑前相比，可明顯看出更加平滑。 
(a) (b) 
圖三十五、三維圖形之範例：(a)平滑前與(b)平滑後 
¾ 流固交互作用：本計劃在模擬過程中加入植物或岩石等要素，因此須以雙向流固耦
合處理之，其結果與一般土石流模擬文獻相較之下將更為真實。對於網格若判斷是
屬於流固體交界時，會透過 two-way coupling方法來有效處理固體與流體間之雙向
耦合部份。雙向流固耦合中固體對流體(Solid to Fluid)會造成阻擋，使流體轉向，
並且固體移動後會排開水；流體對固體(Fluid to Solid)會依據動量守恆使固體形成
速度，且此速度會受到流體阻力而減少，而造成位移。FLO-2D 模型是以 2D 方式
呈現，但因較不真實故在此論文中我們利用高度和水深特徵來加強並以三維方式顯
示以接近真實環境。其中因 FLO-2D 本身未考慮土石流在流動過程中，其受沖擊
的岩石與樹木之作用，因此我們透過流固耦合方法來對於所有流固交接(該網格為
固體且周遭八網格中有一網格為流體)網格作一處理，以呈現較真實的效果。 
當網格屬於流固交界網格時，可由速度與流體體積計算出固體於此流固交界網
格所受之動量影響，及流體碰撞固體後之反彈情況，以求出下一時間步驟固體之作
用(如流體流動方向)。在此計劃中，我們依固體位置來標示出固體網格，接著計算
出流體速度後，檢視固體網格所受到來自八個方向之速度，若速度方向為流向固體
網格時，則計算流體對固體所造成之動量；若流出固體網格則不考慮。對於流固交
 41
VSolid
 
圖三十七、固體遭受流體阻力 
 
¾ 固體模擬：固體因流體造成移動與旋轉，其速度將會因摩擦力(Friction)而減少，當
固體處於流體之間，尚未越過流體邊界而接觸地表時，此時因摩擦力較小而不考
慮，若越過流體邊界而接觸地表時，則考慮摩擦力之影響使固體速度因摩擦力而減
少。當固體與其他固體接觸時，我們稱為碰撞(Bump)，碰撞發生時頇重新調整固
體位置，使其不會重疊，並且將兩碰撞之固體依動量守恆重新給予一新速度。固體
會依據所有的動量合，以求得固體速度。求得合速後再計算得知移動情況，如圖三
十八表示一個固體，其質心位於M 點與受到不同之力 Fn，將所有力相加後，求得
合力為 F。 
M
F1
F2
F3
F4
F5
F6
F7
F8
F9F10
F11
F
 
圖三十八、固體受力示意圖 
 
對於摩擦力部分，固體與地表之接觸面含有流體時，其摩擦力很小，故可忽略不
計。但若無流體影響，固體接觸未含流體之網格時因直接與地表接觸，故摩擦力較大，
如圖三十九(a)所示，需考慮摩擦力之影響。摩擦力 Ff 與地表之正向力 Fn 和摩擦係
 43
一般流固耦合皆以 NSE 作為其流體演算法，其他土石流模擬皆未考慮流固耦合之
狀況，總結來說，我們可將本論文分成兩方面觀點來探討，從土石流模擬觀點來看，表
五顯示了本研究之方法與各土石流 model 之比較，相較於 FLO-2D 等二維土石流模擬
model，本研究多考慮了流固間交互作用、固體碰撞與三維視覺模擬，而相較於 DAN3D
等三維土石流模擬 model，本研究仍多考慮了流固間交互作用、固體碰撞。從流固耦合
觀點來看，表六比較了本計劃與其他流固耦合研究，本計劃使用了適用於土石流模擬之
FLO-2D model，較其他流固耦合研究多考慮了流阻與降伏應力等更適合土石流模擬之
影響。 
對土石流模擬的模擬結果，目前我們使用的地形為高雄市壽山附近地區，其網格數
為 600×600，且每一網格實際代表 1×1立方公尺，目前模擬之固體物件為 51個。模擬
環境為 Intel Pentium D CPU 2.8GHz、NVIDIA GeForce 9600 GT顯示卡及 1.5G RAM，
作業系統為Windows XP，3D繪圖 API為 OpenGL。首先我們先透過壽山地形數據產生
出一三維之地形，接著雨量數據，其中雨量數據為每單位時間之降雨量，接著選定山坡
一角作為視線貣點，並加入房屋與樹木物件，最後顯示畫面如圖四十所示。 
 
圖四十、初始模擬狀態 
當得到地形與雨量數據後，利用 FLO-2D來進行模擬運算，所有網格以完全動力
波方程來與相鄰八個網格進行運算，以求得八個方向之速度，最後將速度乘以時間與
兩網格間截面積來得各別的流量變化，其中截面積為網格邊長乘以平均水深。將網格
視為一正八邊形，設定正八邊形邊長為網格之邊長，加總八個方向之流量變化後，可
 45
發射器先對測量空間進行編碼，當紅外線照射到物體時會形成隨機的反射斑點，稱之為
散斑，由於空間中不同深度所形成的散斑會不相同，所以將這些散斑進行編碼，再利用
紅外線感應器讀取編碼的光線後，交由晶片進行運算解碼，進而產生一張具有3D深度
的圖像，如圖四十二所示。 
 
圖四十二、Kinect 3D偵測 示意圖(圖片來源: PrimeSense) 
在得到深度圖後，我們使用 OpenNI 和 NITE 所提供的手部追蹤(Hand tracking)功
能，進一步的獲得手的中心點，如圖四十三，OpenNI 和 NITE 可以針對特定的手勢動
作進行偵測並傳回手部中心點的三維座標，目前可支援的手勢有四種：揮手(Wave)、點
(Click)、舉手(Raise hand)及移動手(Move hand)，使用者做出特定手勢後，即可得到其深
度距離，用以跟魚缸中的魚作互動偵測。 
 
圖四十三、手部偵測及中心點座標 
 
 47
 
圖四十五、手掌深度值分割 
得到手掌分割圖後，我們利用 OpenCV所提供的函式先找到手掌輪廓，如圖四十六 
(a)中紅線部分並逼近輪廓值得到簡化的輪廓點圖四十六(b)，得到輪廓點後我們利用這
些點資訊找出其凸多邊形，如圖四十六(c)中白線部分，接著將輪廓與凸多邊形做比較
找出手指點和凹陷處的點，如圖四十六(d)中黃色和綠色的點，最後我們以各點間的角
度做判斷，得到我們要的手指點，如圖四十六(e)。 
  
(a) (b) (c) 
  
(d) (e) 
圖四十六、手指偵測結果圖：(a)輪廓、(b)輪廓簡化、(c)凸多邊形、(d)手指及凹陷點與
(e)手指點 
 做完手指偵測可知道使用者伸出的手指數目，因此我們可藉由判斷手指數目來達到
互動的機制，目前只單純判斷手指是處於張開或是握緊的狀態，張開的話即有五個點，
握緊即為零點，藉此我們可以透過碰撞偵測來判斷使用者是否有抓魚的動作產生。碰撞
偵測的目的，是要判斷使用者是否有與魚互動的情形發生，其判斷方法目前是利用使用
 49
精細的水面特效與水波動畫帶來非常大的幫助，故這亦是OpenGL ES1.0與2.0之間的差
異所在。 
 
5.3. 自然模擬中的運算與CPU和GPU結合上的障礙 
    自然模擬需求解Navier-Stokes方程，但此方程為一偏微分方程，需透過有限差分法
來幫助我們離散此方程式，若要達成此目標需要對流體力學有基礎的了解，且需將此些
數學公式代入至GPU中來協助運算，以往CPU在解此些式子時，需採用陣列來表示網格
並對應至模擬中的座標，但在GPU中則需透過貼圖來儲存此些資訊，因此在計算上易發
生錯誤。此外，因我們希望可透過GPU來求取流場中之速度，然後透過CPU來重構出水
面，但此流程與成像的流程有很大的差異，因此在實現上易發生錯誤。 
 
5.4. 軟硬體間的差距與軟硬體整合的障礙 
在一個軟硬體整合計畫中，除了軟硬體間測量數據的準確性與實質性問題的差異之
外，且由於開發平台的不同，在除錯偵錯上可能未能如PC平台上之方便且簡易，且最
大的障礙是當遇到一個系統錯誤或顯示結果錯誤時，不知是在何處發生問題，故常成為
一系統整合計畫之中的一個負荷所在，以下我們將對『軟體系統(Software)』、『驅動系
統(Driver)』與『硬體系統(Hardware)』分別描述。 
 軟體系統：在軟體設計上，其所可能發生的問題常常不外乎幾類，一、本身軟
體設計架構的錯誤。二，驅動系統在配置空間時所造成缺失，如材質所需的空
間大小等。三、驅動系統是否造成軟體無止境的沉睡，未在特定的時間喚醒軟
體或API。四、某些函數初始化時的錯誤，造成某種特殊狀況下導致系統發生
錯誤。 
 驅動系統：在軟體與硬體的溝通上，常藉由一中間者來協調，即驅動系統。其
常發生的錯誤常因軟體函數所欲I傳遞的值或位址給硬體時，可能因驅動系統
上的缺失，使得配給的位址或空間不足等，或者是軟體系統不正確的呼叫，而
 51
VI、計畫成果自評 
開發過程中我們發現，如何在一個低效能且具硬體限制之嵌入式系統中，開發3D
應用程式，已是一個重要議題。目前嵌入式系統中有關3D動畫應用程式之OpenGL ES
開發平台常有兩個缺點。一、並無提供繪圖管線效能檢測；二、常因系統或特殊硬體需
求限制，造成開發困難與效能不彰。因此如何實現一個具有跨平台之繪圖管線效能檢測
且不需特殊硬體環境的OpenGL ES仿真器，來提供開發者可對3D應用程式之效能做出分
析，並依不同嵌入式系統的限制實現3D應用程式，亦是另ㄧ需考量的重點與價值。 
此外在嵌入式系統中，電源管理和功耗控制，始終也是一個重要的任務，ㄧ般而言
通常都會有各自不同的軟硬體策略，來輔助電源管理和功耗控制，常見的有低功耗模式
或動態頻率或電壓切換等。因此如何實現一個適當的電源管理計畫，也是一個重要價
值。故在本節中我們將針對『計畫目標與目前成果』、『主要發現或相關價值』與『學術
研究成果』三項分別做ㄧ敘述。 
6.1. 計畫目標與目前成果  
目前我們根據原計劃內容，第二年的研發目標主要為『自然動態特效模擬設計』與
『3D立體技術與互動』。對於自然動態特效模擬設計部分，我們已實現海洋、火焰與
土石流模擬。對於3D立體技術方面，目前已完成手部偵測部份，接下來將會做初步驗
證及測試整合軟硬體系統。茲第二年原計畫書所需實現項目及各季工作項目與目前結果
如表七所列。 
表七、第二年度進度表 
第一年度 預期目標 目前成果 
第一季 ¾ 動態特效模擬模組(火焰) 
¾ 動態特效模擬模組(土石流) 
¾ 完成火焰特效模擬 
¾ 初步建構土石流特效模組 
第二季 ¾ 動態特效模擬模組(土石流) ¾ 完成土石流特效模組 
第三季 ¾ 3D立體技術(位置偵測) 
¾ 驗證及測試整合軟硬體系統 
¾ 完成手部位置追蹤 
¾ 初步的軟體系統測試 
第四季 ¾ 軟硬體系統整合測試 ¾ 初步軟硬體系統整合測試 
 53
參考文獻 
[1] http://www.iart3d.com/TC/Products_TC/3D%20Glasses/3D%20Glasses_TC.htm 
[2] 柯志函, 無穿戴即時三維指向偵測暨指向手勢辨識系統設計與開發, 碩士論文, 國
立台灣科技大學工業管理所, 2009. 
[3] 許宏賓, 利用多攝影機合成新視點影像之方法研究, 碩士論文, 銘傳大學資訊傳播
工程學系, 2005. 
[4] E. G. Rieffel, A. Girgensohn, D. Kimber, T. Chen, and Q. Liu, “Geometric tools for 
multicamera surveillance systems,” ACM/IEEE international conference on distributed 
smart cameras (ICDSC '07), pp.132-139, 2007. 
[5] 許峰雄, 使用高斯混何模型於移動物件偵測, 碩士論文, 國立台灣科技大學電機工
程系, 2007. 
[6] 蘇耘德, 視訊資料中移動物體軌跡之萃取, 碩士論文, 國立中央大學土木工程學系, 
2006. 
[7] W. Long, and Y.H. Yang, “Stationary background generation: an alternative to the 
difference of two images,” Pattern recognition, 1990. 
[8] A.H.S. Lai and N.H.C. Yung, “A fast and accurate scoreboard algorithm for estimating 
stationary backgrounds in an image sequence,” Proceedings of the 1998 IEEE 
international symposium on circuits and systems, vol. 4, pp. 241-244, 1998. 
[9] J. Krumm, S. Harris, B. Meyers, B. Brumitt, M. Hale, and S. Shafer, “Multi-camera 
multi-person tracking for easyliving,” Proceedings of the third IEEE international 
workshop on visual surveillance, pp. 3-10, 2000. 
[10] S. Khan, and M. Shah, “Consistent labeling of tracked objects in multiple cameras with 
overlapping fields of view,” IEEE trans. on PAMI, 2003. 
[11] 王希俊,劉文心,陳怡惠 紅外線數位浮水印結合擴增實境之創新影像顯示應用, 
Journal of technology, vol. 24, no. 3, pp. 213-219, 2009. 
[12] 楊谷洋,周高平, 虛擬實境飛行模擬系統之力感分析與操控, 碩士論文,國立交通大
學電機與控制工程系所, 2009. 
[13] R. S. Kalawsky, “The science of Virtual Reality and virtual environments,” 1st edition, 
Addison-wesley longman publishing co., inc., 1993. 
[14] 曹文凱, 使用影像資料在虛擬環境中繪製真實場景的方法, 碩士論文, 國立台灣大
學資訊工程系, 1996. 
 55
proceedings of second 3D digital imaging and modeling conference, pp. 34-43, 1999. 
[29] J. A. Beraldin, M. Picard, S. F. El-Hakim, G. Godin, V. Valzano, and A. Bandiera, 
“Combining 3D technologies for cultural heritage interpretation and entertainment,” 
Proceedings of SPIE-IS&T electronic imaging, vol. 5665, no. 374, pp. 108-118, 2005. 
[30] F. Remondino, A. Guarnieri and A.Vettore, “3D modelling of close-range objects: 
photogrammetry or laser scanning?” Proceedings of SPIE-IS&T Electronic Imaging, 
vol.5665, no. 374, pp. 216-225, 2005. 
[31] D. Owens, D. Luebke, N. Govindaraju, M. Harris, J.  Krüger, A. E. Lefohn, T. J. 
Purcell, “A survey of general-purpose computation on graphics hardware,” In graphics 
forum, vol. 26, 2007. 
[32] NVIDIA, “CUDA,” http://developer.nvidia.com/object/cuda.html 
[33] T. Purcell, C. Donner, M. Cammarano, H. W. Jensen, and P. Hanrahan, “Photon 
Mapping on Programmable Graphics Hardware,” Graphics hardware, 2003. 
[34] A. Lamorlette, and N. Foster, “Structural modeling of flames for a production 
environment[J],” ACM trans. on graphics, vol. 21, no. 3, pp. 729-735, 2002. 
[35] T. Takahashi, H. Fuji, A. Kunimatsu, K. Hiwada, T. Saito, K. Tanaka, and H. Ueki, ” 
Realistic animation of fluid with splash and foam[J],” Computer graphics forum, vol. 22, 
no. 3, pp. 391-400, 2003. 
[36] V. Mihalef, D. Metaxas, and M. Sussman, ”Animation and control of breaking 
waves[A],” Proceedings of the 2004 ACM SIGGRAPH symposium on computer 
animation, pp. 315-324, 2004. 
[37] N. Foster, and D. Metaxas, “Realistic animation of liquids[J],” Graphical models and 
image processing, vol. 58, no.5, pp. 471-483, 1996. 
[38] N. Foster, and R. Fedkiw, “Practical animation of liquids[A],” Proceedings of 
SIGGRAPH[C], pp. 15-22, 2001. 
[39] D. Enright, S. Marschner, and R. Fedkiw, “Animation and rendering of complex water 
surfaces[J],” ACM tran. on graphics, vol. 21, no. 3, pp. 736-744, 2002. 
[40] D. Nguyen, D. Enright, and R. Fedkiw, “Simulation and animation of fire and other 
natural phenomena in the visual effects industry[A],” Western states section, 
Combustion institute, UCLA, 2003. 
[41] D. Q. Nguyen, R. Fedkiw, and H. W. Jensen, “Physically based modeling and animation 
of Fire[J],” ACM trans. on graphics, vol. 21, no. 3, pp. 721-728, 2002. 
[42] M. Müller, D. Charypar, and M. Gross, “Particle-based fluid simulation for interactive 
applications[A],” Proceedings of the 2003 ACM SIGGRAPH/ symposium on xomputer 
 57
non-newtonian fluid mech., vol. 84, pp. 65-81, 1999. 
[61] J. J. Lee, and C. C. Mei, “Stationary waves on an inclined sheet of viscous fluid at high 
reynolds and moderate weber numbers,” Journal of fluid mechanics, vol. 307, pp. 
191-229, 1996. 
[62] N. J. Balmforth, and S. Mandre, ”Dynamics of roll waves,” Journal of fluid mechanics, 
vol. 514, pp. 1-33, 2004. 
[63] C. Batty, F. Bertails, and R. Bridson, “A fast variational framework for accurate 
solid-fluid coupling,” ACM transactions on graphics, vol. 26, no. 3, Article 100:1-8, 
2007. 
[64] T. Takahashi, H. Ueki, A. Kunimatsu, and H. Fujii, “The simulation of fluid-rigid body 
interaction,” ACM SIGGRAPH, pp. 266-266, 2002. 
[65] O. Génevaux, A. Habibi, and J.-M. Dischler, “Simulating fluid-solid interaction,” 
Graphics interface, pp. 31-38, 2003. 
[66] S. Zhu, X. Xia, Q. Zhang, and K. Belloulata, “A novel spatio-temporal video object 
segmentation algorithm,” IEEE International Conference on Industrial Technology, 
pp.1-5, 2008. 
[67] Y. Zhang, D. Wang, and Y. Hou, “An effective algorithm of automatic video object 
segmentation based on temporal-spatial information,” International Conference on 
Computer Science and Education, pp.1755-1759, 2010. 
[68] Z. Messaoudi, A. Ouldali, and M. Oussalah, “Tracking objects in video sequence using 
active contour models and unscented kalman filter,” International Workshop on 
Systems, Signal Processing and their Applications (WOSSPA), pp.135-138, 2011. 
[69] A. Ion, N. M. Artner, G. Peyré, W. G. Kropatsch, and L. D. Cohen, “Matching 2d and 
3d articulated shapes using the eccentricity transform,” Journal of Computer Vision 
and Image Understanding, vol. 115, no. 6, pp.817-834, 2011 
[70] W. Matusik, C. Buehler, R. Raskar, S. J. Gortler, and L. McMillan, “Image-based 
visual hulls,” Annual Conference on Computer Graphics and Interactive Techniques 
(SIGGRAPH), pp.369-374, 2000. 
[71] O. Au, C. Tai, H. Chu, D. Cohen-Or, and T. Lee, “Skeleton extraction by mesh 
contraction,“ ACM Transactions on Graphics (TOG), vol. 27, no. 3, pp.44-53, 2008. 
[72] G. Wen, Z. Wang, S. Xia, and C. Li, “Articulated skeleton fitting,” IEEE International 
Conference on Computer-Aided Design and Computer Graphics, pp.395-400, 2007. 
[73] J. Gall, C. Stoll, E. de Aguiar, C. Theobalt, B. Rosenhahn, and H. Seidel, “Motion 
capture using joint skeleton tracking and surface estimation,” IEEE Conference on 
Computer Vision and Pattern Recognition, pp.1746-1753, 2009. 
[74] K. Zhang, L. Zhang, H. Song, and W. Zhou, “Active contours with selective local or 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/07/27
國科會補助計畫
計畫名稱: 子計畫二：應用於互動式之多視角顯示系統的三維自然模擬(2/3)
計畫主持人: 李宗南
計畫編號: 100-2220-E-110-001- 學門領域: 晶片科技計畫--整合型學術研究
計畫
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
軟體創作競賽 
  榮獲「建國百年開放軟體創作競賽」互動多媒體組金牌獎 
  榮獲「建國百年開放軟體創作競賽」互動多媒體組銅牌獎 
  榮獲 100年開放軟體比賽金牌銅牌 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
