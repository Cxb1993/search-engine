1 
行政院國家科學委員會專題研究計畫成果報告 
應用內建數位類神經網路之智慧型機器人行為學習 
Behavior Learning of Intelligent Robotic Systems Using Build-in Digital Neural Network 
計 畫 編 號：NSC 95-2218-E-009-024 
執 行 期 限：95 年 2 月 1 日至 96 年 8 月 31 日 
主 持 人：宋開泰教授   國立交通大學電機與控制工程學系 
計畫參與人員：蔡奇鎰、林嘉豪、韓孟儒  國立交通大學電機與控制工程學系 
 
一、中文摘要 
在此國際合作研究計畫中，交通大學
團隊與比利時魯汶大學團隊共同發展出一
個自走式機器人之視覺狀態估測器，用以
讓機器人視覺追蹤系統在視覺處理過程中
可有效地估測出目標物在影像平面中之狀
態。此設計的優點在於此估測器可在沒有
追蹤目標物的三維空間移動速度資訊條件
下，有效地估測出追蹤目標物在影像平面
中的移動速度。此項優點有助於在影像空
間中設計一個機器人之視覺追蹤控制器。
同時，為了增加此估測器對隨機觀測雜訊
的強健性，我們使用迴響狀態網路(Echo 
state network)技術發展出一個以類神經網
路為基礎之自我調整演算法。經由結合卡
曼濾波器(Kalman filter)演算法與迴響狀態
網路為基礎之自我調整式演算法，可有效
設計出一個強健型視覺狀態估測器。多項
電腦模擬測試及實際在機器人上實驗均被
實現，成功驗證此項設計的效能。 
關鍵詞：視覺追蹤控制、視覺狀態估
測、影像平面速度估測、自走式機器人 
Abstract 
This report presents the results of the 
joint research cooperation between NCTU 
team and the PMA team, K U Leuven on a 
visual state estimator for a robotic visual 
tracking system to estimate the system state 
during visual tracking process. The 
advantage of this design is that it can 
estimate the motion velocity of the target in 
image plane without the knowledge of 
target’s 3D velocity information. This 
advantage is helpful to the visual tracking 
control design. In order to increase the 
robustness against the random observation 
noise, a neural network based self-tuning 
algorithm is proposed using echo state 
network (ESN) technique. The visual state 
estimator is designed by combining a 
Kalman filter with the ESN-based self-tuning 
algorithm. Several realizations are described 
and assessed by computer simulation and 
experimental results. 
Keywords: Visual tracking control, visual 
state estimation, image velocity 
estimation, mobile robots. 
二、緣由與目的 
Visual tracking control task of a mobile 
robot encompasses several key factors such as 
motion control of a mobile robot, target 
detection, depth estimation, position and 
velocity estimations, etc. Researches on visual 
tracking control of mobile robots to track a 
target of interesting has been an active area of 
robotic research in recent years [1-3]. 
However, a mobile robot usually needs to 
track a dynamic moving target in practical 
applications. Therefore, a visual state 
estimator to estimate the motion of a dynamic 
moving target can greatly help the design of 
visual tracking control system. 
This cooperative research addressed the 
problem in two aspects. First we focus on the 
position and velocity estimation of a dynamic 
motion target in the image plane. In the 
estimation applications, it is well known that 
the Kalman filter is one of the best linear 
estimators for a linear plant model with 
Gaussian white noise [5]. However, if the 
noise statistics are unknown, a difficult 
problem of the Kalman filter is to determine 
two suitable covariance matrices for 
computing the Kalman gain matrix [6]. 
3 
was proposed in our previous work [10]. 
Figure 2 shows the definition of observed 
system states in image plane used for the 
visual interaction model. In Fig. 2, xi and yi 
are, respectively, the horizontal and vertical 
position of the centroid of target in image 
plane; dx is the width of target in image plane. 
The visual interaction model between robot 
and target in image coordinate frame can than 
be modeled as a dual-Jacobian equation [11] 
called target image Jacobian and robot image 
Jacobian and transfers the mobile robot 
control velocity u into robot image velocity. 
The visual estimation problem is then defined 
as to find the state estimate *nX  that 
minimizes the weighted least square criterion: 
( ) ( )
( ) ( )
* 1
1
arg min[
]
T
n n n nX
T
n est n n est
X X X X X
Z X Z X
−
−
= − −
+ − −
P
H R H
 (1) 
where Testnestn APAP 1−=  is the covariance 
matrix of propagation model at time step n, 
and Rn is the covariance matrix of observation 
model at time step n. 
 
3.2 Self-Tuning Kalman Filter Using Echo 
State Network  
Define that (Xn,Pn) are the propagation state 
and the corresponding covariance matrix at 
time step n; (X*n-1,P*n-1) are the optimal 
estimate and the corresponding covariance 
matrix at time step n-1; 
TTt
i
T
in nXnXX ]])[(])[([ δδδ =  represents 
Gaussian propagation uncertainty with zero 
mean and covariance matrix Qn at time step n; 
and nZδ  represents Gaussian observation 
uncertainty with zero mean and covariance 
matrix Rn at time step n. Then, when the 
linear propagation model and linear 
observation model both have Gaussian 
propagation and observation uncertainties, a 
Kalman filter will provide the local minimum 
solution of performance criterion (1). 
According to [5], the filter performance of 
Kalman filter is determined by the covariance 
matrices Qn and Rn. Thus, a difficult problem 
in Kalman filter applications is how to 
determine the values of matrices Qn and Rn 
for computing the Kalman gain matrix Kn. 
Typically, this problem usually is left up to 
engineering intuition by a trial-and-error 
method. However, the observation uncertainty 
usually varies with the conditions of target 
motion (such as orientation and rotation of a 
tracked human face) and working 
environment (such as light variation and 
occlusion), and the corresponding covariance 
matrix Rn are time-varying for different 
operating conditions. In order to deal with this 
problem, the neural network techniques are 
helpful to filter the observation noise and 
estimate the noise variance without any noise 
model [6]. Therefore, this advantage 
motivates us to combine a neural network 
based self-tuning algorithm with Kalman filter 
to filter the observation noise and provide a 
suitable observation covariance matrix Rn in 
varying environmental conditions.  
Fig. 3 shows the block diagram of the 
proposed ESN-based self-tuning Kalman filter, 
in which nZˆ  denotes the measurement with 
observation noise, and (Zn, ∆Rn) are the 
filtered measurement and the estimated noise 
covariance matrix. The covariance matrix of 
the observation signal is then updated such 
that 
nn RRR Δ+= 0 ,          (2) 
where R0 is an initial covariance matrix to 
avoid the covariance matrix becoming zeros. 
An ESN is described by an input matrix 
Win, a connection matrix W and a readout 
linear discriminate Wout , as shown in Fig. 4. 
A. Activation Function 
 The ESN is activated on a step-by-step 
basis. At each time step, the state vector 
 
Fig. 3 Proposed neural network based self-tuning 
Kalman filter. 
 
Fig. 2. Definition of the observed system state in 
image plane. 
5 
color. Fig. 6 shows the overall architecture of 
the system. All the image patches are 
matched between frames, according to the 
predicted centroid, and the similarity of HSI 
histograms. If any of the patches can be 
tracked within 30 frames, it is registered as 
an object.  A registered object will be 
deleted if it cannot be matched within 30 
frames.  The focus point is placed in the 
middle of the image initially, but can be 
moved by large motion, bright color, or any 
given point by mouse. It helps the system to 
focus on the most interesting object on the 
image plane. Fig. 7 show an example of how 
the system segments the human face , focus 
on it and matches it in two frames. 
3.4 Simulation and Experimental Results 
A. Simulation Setup 
 In order to evaluate the performance of 
the proposed visual state estimator, a 
simulation environment is setup using 
MATLAB. Fig. 8 shows the architecture of 
the simulation setup. In Fig. 8, Xn denotes the 
reference signal needed to be estimated by a 
visual state estimator. The input of the visual 
state estimator is the observation signal nZˆ  
with random noise. The intensity of the noise 
is time-varying and dependent on a random 
condition. This kind of random noise is 
usually happened during practical visual 
tracking process of the mobile robot, since 
the intensity of the observation uncertainty 
usually is position-dependent and 
light-dependent. 
 In the following, a visual state estimator 
is utilized to filter the random noise and 
provide the optimal estimation. The 
performance of the visual state estimator is 
then validated by mean-squared-error (MSE) 
criterion between the ideal signal Xn and the 
estimated signal Xn*. Table I shows the 
parameters used in the simulations. Note that 
we use a threshold 75.0=ρ  when 
generating the training data for the ESNs. 
Moreover, the parameters used to create the  
ESNs (found empirically) are nr=90 neurons 
(for all three ESNs) and m=0.5, 0.6 and 0.8 
for xi, yi and dx respectively. 
B. Simulation Results 
 There are three visual state estimator 
used to compare the performance: Kalman 
filter (KF), self-tuning Kalman filter using 
linear regression (STKF-LR) [10], and the 
proposed self-tuning Kalman filter using 
ESN (STKF-ESN). Table II shows the 
average results of MSE measurements as the 
threshold value 1=ρ  and 0=ρ  in the 
simulations (out of 40 simulations for each 
ρ ). In Table II, the bold font denotes the 
smallest value of the MSE measurement 
across each row. From Table II, we observe 
that the estimation results of KF and 
STKF-LR are very sensitive to the intensity 
of the observation noise. As the threshold 
value ρ  increased from 0 to 1, the average 
MSE measurements are also increased 
apparently. Moreover, when the threshold 
value 1=ρ  (the observation signal always 
has the largest noise intensity), the proposed 
STKF-ESN provides the best estimation 
Fig. 8. The architecture of the simulation setup 
Image 
sequences
Edge
HSI Color space
Difference between  
frames 
image patches 
Mean-shift Clustering
Focus point Selection
Tracking
Image patches 
matching
Object 
registration/deletion  
Fig. 6 System architecture of the color-based object 
segmentation system 
Target1
Target2
Target3
Target4
Target5
Target6
Target7
Target8
Target9
Target10 Target11
Target12
Target13
Target14 Target15
15Clusters:6bw0.15
100 200 300 400 500 600
50
100
150
200
 
Fig. 7 A sample result of object segmentation and 
matching  
7 
estimator is proposed based on ESN-based 
self-tuning Kalman filter technique. This 
design can be applied into several visual 
tracking applications, such as visual tracking 
control, visual surveillance, and visual 
navigation, etc., to estimate the position and 
the velocity of the target in the image plane. 
In the simulations, it shows that this design 
provides high robustness against the 
observation uncertainty with time-varying 
intensity. This advantage is very useful in 
practical applications, since the observation 
uncertainty usually varies with the conditions 
of target motion and working environment. 
Computer simulation results validate the 
robustness and performance of proposed 
estimation method by comparing with 
conventional Kalman filter and linear 
regression based self-tuning Kalman filter. 
Moreover, experimental results also verify 
the tracking performance of the proposed 
visual tracking system in practical 
environment under light-varying condition. 
四、參考文獻 
[1]  G. L. Mariottini, G. Oriolo, and D. Prattichizzo, 
“Image-based visual servoing for nonholonomic 
mobile robots using epipolar geometry,” IEEE 
Trans. on Robotics, Vol. 23, No. 1, pp. 87-100, 
2007. 
[2]  J. Chen, W. E. Dixon, D. M. Dawson and M. 
McIntyre, “Homography-based visual servo 
tracking control of a wheeled mobile robot,” 
IEEE Trans. on Robotics, Vol. 22, No. 2, pp. 
407-416, 2006. 
[3]  T. Nierobisch, W. Fischer, and F. Hoffmann, 
“Large view visual servoing of a mobile robot 
with a pan-tilt camera,” in Proc. IEEE/RSJ Int. 
Conf. on Intel. Rob. and Sys., Beijing, China, pp. 
3307-3312, 2006. 
[4]  L.-Q. Xu and D. C. Hogg, “Neural networks in 
human motion tracking – An experimental 
study,” Journal of Image and Vision Computing, 
Vol. 15, No. 8, pp. 607-615, 1997. 
[5]  J. D. Schutter, J. D. Geeter, T. Lefebvre and H. 
Bruyninckx, “Kalman filters: a tutorial,” Journal 
A, Vol. 40, No. 4, pp. 52-59, 1999. 
[6]  O. V. Korniyenko, M. S. Sharawi and D. N. Aloi, 
“Neural network based approach for tuning 
Kalman filter,” in Proc. IEEE Int. Conf. on 
Electro/Information Technology, Lincoln, 
Nebraska, pp. 1-5, 2005. 
[7]  S.-S. Xiong and Z.-Y. Zhou, “Neural filtering of 
colored noise based on Kalman filter structure,” 
IEEE Trans. on Instrumentation and 
Measurement, Vol. 52, No. 3, pp. 742-747, 
2003. 
[8]  H. Jaeger, “The “echo state” approach to 
analysing and training recurrent neural 
networks,” German National Research Center for 
Information Technology, Tech. Rep., 2001. 
[9]  D. Comaniciu and P. Meer, “Mean shift: A 
robust approach toward feature space analysis” 
IEEE Trans. on Pattern Analysis and Machine 
Intelligence , Vol. 24, No. 5, pp. 603-619, 2002. 
[10]  C.-Y. Tsai and K.-T. Song, “Face tracking 
interaction control of a nonholonomic mobile 
robot,” in Proc. IEEE/RSJ Int. Conf. on Intel. 
Rob. and Sys., Beijing, China, pp. 3319-3324, 
2006. 
[11]  C.-Y. Tsai, K.-T. Song, X. Dutoit, H. Van 
Brussel and M. Nuttin, “Robust mobile robot 
visual tracking control system using self-tuning 
Kalman filter,” in Proc. IEEE Int. Sym. on Comp. 
Intel. in Rob. and Auto., Jacksonville, Florida, pp 
161-166, 2007. 
   
(a1)    (a2) 
  
(a3)   (a4) 
   
 
(b1)    (b2) 
  
(b3)    (b4) 
Fig.10. Experimental results of visual tracking. 
 1
國科會雙邊國際合作計畫出國報告 
國立交通大學電機與控制工程學系       宋開泰教授  2007/3/5   
 
一、 目的 
2007 年 2 月 18~26 日赴比利時魯汶大學(K U Leuven, Belgium)
進行國際合作專題計畫學術研討會 ，並拜會國科會駐歐盟科技代表
處，規劃未來合作事宜。 
 
二、過程 
    筆 者 執 行 國 科 會 雙 邊 國 際 合 作 專 題 研 究 計 畫
(NSC-95-2218-E-009-024)，主旨在交通大學電控系智慧型系統控制整
合(ISCI)實驗室與比利時魯汶大學機械系 Prof. Hendrik Van Brussel 
及 Prof. Manix Nuttin 研究團隊合作進行智慧型機器人行為學習相關
之研究。目前已選派交通大學博士班研究生蔡奇謚赴魯汶大會進行合
作研究(2006/10/20~2007/4/20)，計畫進展順利。為討論研究進度並規
劃未來研究重點，筆者於 2007/2/18~26 赴比利時魯汶大學進行短期研
究。同時亦藉此機會拜會國科會派駐歐盟科技組許榮富博士，感謝其
支持與協助此國合計畫。 
筆者是在 2 月 18 日深夜搭乘華航班機由桃園機場出發，於當地
時間 19 日上午六點半抵達德國法蘭克福(Frankfurt)，隨即轉機於當天
 3
約定與 Prof. Nuttin 及 Prof. Van Brussel 於 2/23 星期五下午進行第二
場討論會。 2/23 下午 4:30 之討論會地點就在 Prof. Van Brussel 之辦
公室，參加人員除 Prof. Van Brussel, Prof. Nuttin 及筆者外，尚有湯孝
威博士及黃甦。 筆者先簡介交大 ISCI 實驗室最近的研究進展及交大
團隊成員與最近成果，接著主要討論未來此合作計畫之進行與研究重
點，Prof. Van Brussel 及 Prof. Nuttin 皆對蔡奇謚目前之研究十分感興
趣，並希望能在未來兩個月內有更具體的成果產出，以謀求雙方團隊
最佳成果，同時 Prof. Van Brussel 也希望能先瞭解交大團隊下一位要
選派至 PMA 博士生之研究情形。 
     筆者於 2/23 上午赴比京布魯塞爾拜會台灣駐歐盟科技組許榮富
組長及文化組卓鳴鳳組長，此行也參觀了台灣駐比京代表處，新辦公
大樓之位置及辦公室環境皆十分理想，也了解到科技組工作範圍廣
泛，對促進我國與歐盟國家的科技合作交流貢獻卓著。     
 
三、心得與建議: 
(1).   交通大學 ISCI 研究團隊與魯汶大學 Prof. Van Brussel 及
Prof. Nuttin 之研究團隊有許多相共同之研究興趣與研究
主題，透過此國合專題研究，可激發出雙方更多創意與研
究成果，十分有意義。交大博班學生能在此計畫之支持
下，順利前往比利時魯汶大學進行短期研究，無論對其博
 5
國科會雙邊國際合作計畫出國報告 
國立交通大學電機與控制工程學系       蔡奇謚  2007/11/7   
 
一、 目的 
2007 年 10 月 20 日至 2007 年 4 月 20 日赴比利時魯汶大學(K U 
Leuven, Belgium)進行國際合作研究計畫，研究主題為結合本實驗室
開發的視覺追蹤技術以及魯汶大學 PMA 團隊所開發的類神經網路
技術。 
 
二、過程 
筆 者 執 行 國 科 會 雙 邊 國 際 合 作 專 題 研 究 計 畫
(NSC-95-2218-E-009-024)，主旨在交通大學電控系智慧型系統控制整
合(ISCI)實驗室與比利時魯汶大學機械系 Prof. Hendrik Van Brussel 
及 Prof. Manix Nuttin 研究團隊合作進行智慧型機器人視覺追蹤行為
學習相關之研究。主要的研究合作夥伴為魯汶大學機械系博士班研究
生 Xavier Dutoit ，其博士論文主題為迴響狀態網路 (Echo-State 
Networks)之研究。經討論後，我們決定的研究方向為利用迴響狀態
網路之特性來提升機器人視覺追蹤行為之性能。 
研究的方法主要是利用迴響狀態網路設計一個具有消除隨機雜
訊的強健型觀測器(Observer)，然後再將其輸出結果輸入給一個能克
 7
學術研究環境與創新能力更是學校進步的主要動力。在這間世界最古
老之ㄧ的大學裡，可以明顯感受到學生們與教授們不斷求進步與創新
的積極態度。他們不斷的以創新的理念，將科技技術與日常生活相結
合，開發出有利於提升人民生活便利的新技術。以本合作計畫來說，
在這裡的計畫背景為協助醫療設備廠商開發出新一代的智慧型電動
輪椅，主要是輔助行動不便的殘障人士可直接用腦波訊號來操控輪
椅。這不但是個偉大的理想，也很實際。另一方面，校際之間的合作
研究也很盛行，例如根特大學與魯汶大學之間就常有合作計劃在進
行。根特大學的工程學系是相當有名的，其實作能力具有相當高的專
業水準。在智慧型電動輪椅開發的計畫案中，根特大學就扮演了開發
新型感測器與腦波訊號讀取器的重要角色。 
 在研究風氣方面，魯汶大學的研究生是非常注重互相討論的。在
開始執行之前，通常都需要跟自己的研究夥伴討論許多次，直到討論
出有原創性的議題後，才開始執行。這一點是跟國內的研究風氣最大
不同的地方。國內的研究環境很少會提倡同儕之間的討論，但在魯汶
大學中，同儕之間的討論是很頻繁的。藉由每個人專業的觀點，可以
很快的找出目前的想法或設計有哪些不足或瑕疵，以利於持續改進。
這點我想是國內各大學研究所值得學習的地方。 
 經過這次出國短期研究的經驗，不僅讓我親身體會到國外開放健
 9
國科會雙邊國際合作計畫出國報告 
國立交通大學電機與控制工程學系       林嘉豪  2007/11/8   
 
二、 目的 
2007 年 6 月 20 日至 2007 年 8 月 20 日赴比利時魯汶大學(K U 
Leuven, Belgium)進行國際合作研究計畫，研究主題為結合本實驗室
開發的視覺追蹤技術以及魯汶大學 PMA 團隊所開發的類神經網路
技術。 
二、過程 
    筆 者 執 行 國 科 會 雙 邊 國 際 合 作 專 題 研 究 計 畫
(NSC-95-2218-E-009-024)，主旨在交通大學電控系智慧型系統控制整
合(ISCI)實驗室與比利時魯汶大學機械系 Prof. Hendrik Van Brussel 
及 Prof. Manix Nuttin 研究團隊合作進行智慧型機器人行為學習相關
之研究。 
筆者是在 6 月 20 日晚上 7 點 30 搭乘荷航班機由桃園機場出發，
於當地時間 21 日上午 5 點 45 抵達荷蘭阿姆斯特丹(Amsterdam)，隨
即轉機於當天上午 7 點 45 抵達比利時布魯塞爾(Brussels) 。國科會許
組長特請魯汶大學博士後研究湯孝威博士接機，並直接前往魯汶大學
機械系拜會 Prof. Van Brussel。稍後並分別與 Prof. Nuttin 以及魯汶大
學博班黃甦會面。 
