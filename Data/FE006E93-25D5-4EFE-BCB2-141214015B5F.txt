 2
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價值（簡要敘
述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適合在學術期刊發表或申請
專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
達成目標 
說明： 
本計畫針對非線性非仿射系統已完成擬定項目 
1. 第一年：單一輸入單一輸出之智慧型控制器設計。 
2. 第二年：多輸入多輸出系統之基於輸出型小波類神經網路之控制器設計 
3. 第三年：具非仿射特性之非線性機械設計與實現。 
    
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：已發表未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 無 
技轉：□已技轉 □洽談中 無 
其他：（以 100 字為限） 
本計畫值形成果已有 1 篇期刊論文（第一年成果）接受刊登，第二年成果於研討會發表，
期刊論文撰寫中。 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價值（簡要敘述
成果所代表之意義、價值、影響或進一步發展之可能性）（以 500 字為限） 
   本計畫之成行目的為設計一雙軸機械手臂與實現（非線性多輸入多輸出非仿射系統），
並已完成基於數位信號處理器（DSP）之智慧型控制器設計，對目前機械人研製之發展有
其應用價值。未來擬解決系統手臂旋轉角速度狀態具雜訊之控制器之設計。 
 
 
 
 
 
 
 4
緻論文摘要集、論文全文光碟片與發表論文之論文冊。為期 3 天的議程中，因投稿者眾多，
大會必須事前篩選優秀論文並規劃在幾天完成發表，可發現議程緊湊，且每一場次似乎幾
乎座無虛席，由此可見與會者都相當重視此次的會議。今年度有三十個國家與數百篇論文
發表。 
17-18 日穿插多場專題演講(Keynote Speeches, Invited Talks, Tutorials)，個人 17 日聆聽
介紹；論文發表亦在 17 日上午開始，主要為 Int. Conf. on Artificial Intelligent and Applications 
(ICAIA 2010)，個人之研究在 18 日上午 9:30～10:45 與 11:15~13:00 發表。參與學生在國內
均經過充分的準備與驗收，在大會中從容的將成果介紹給與會學者，可增廣視野與國際觀，
也讓他們清楚瞭解目前相同研究領域的進展，更讓他們見到其他國外學者（或學生）的態
度，相信對他們是一個不同的經驗。大會在 18 日晚間舉行大會晚宴，個人因行程安排未能
參與，一行四人搭乘晚間 7:15 長榮航空 BR872 班機離開香港。 
此次會議在論文審查階段，三篇論文均獲得審查委員推薦參與論文競賽、推薦至期刊
論文發表，大會亦將於大會結束後一個內月公告獲獎論文；個人去年亦獲肯定，推薦發表
於期刊 Int. J. of Engineer Letters。 
 
二、與會心得 
此次帶領學生參與國際會議，認識國外學生與研究學者，個人認為對研究生收穫頗大，
也感謝學校能給予補助，讓學生順利成行。 
個人主要的研究領域在模糊邏輯、模糊控制、類神經網路與非線性控制的應用，藉由
參與這次的與會，讓個人有機會瞭解到目前國際學者之研究方向，藉由參與不同主題的討
論，並參考別人的研究成果與應用範圍，對於其他領域也有更進一步的認識與體會，甚至
計畫於近來嘗試著從事這方面的研究。 
 
三、建議 
國內之重要學者應積極爭取主辦，藉由學術上的交流，提高大家對台灣與台灣學術界的
認識，並讓更多學者有機會參與盛會。 
 
四、攜回資料名稱及內容 
光碟片、會議摘要冊、未來會議徵文 
 
 
 
 
 
 6
Abstract:  The purpose of this project is to develop an intelligent control approach for 
nonlinear a class of uncertain multiple-input-multiple-output (MIMO) nonlinear non-affine system. 
The intelligent control approach is used to solve the problems of the industrial mechanisms which 
face problems, including MIMO system, complexity system dynamic characteristic. The intelligent 
controller has the properties of adaptation, robustness, available to hardware implement. In the first 
year of this project, we have designed an intelligent adaptive backstepping approach. This approach 
can guarantee the stability of the system, and use fuzzy neural network to overcome the problems 
including external disturbances, system parameter variation, highly nonlinear characteristic of 
model. According to Lyapuov stability theory, we will find the on-line update law of controller.  
The purpose of this project is to develop an intelligent control approach for a class of nonlinear 
uncertain multiple-input-multiple-output (MIMO) non-affine system. In the first year project results, 
using backstepping technique, we have proposed a recurrent-fuzzy- neural-network-based 
intelligent control scheme for the single-input-single-output nonlinear nonaffine system. Details 
please find the previous project report. 
Herein, we extend the previous results to the multi-input-multi-output systems and proposed 
method to treat the drawback of the backstepping approach, explosion of complexity problem, and 
reduce the computation effort. Based on the backstepping approach and output recurrent wavelet 
neural network (ORWNN), we propose an approach that guarantees the stability of the system, and 
use the ORWNN to overcome the problems including external disturbances, system parameter 
variation, highly nonlinear characteristic of model. Nota that, we utilize dynamic surface control 
(DSC) technique to solve the drawback of backstepping method called the “explosion of 
complexity”. According to Lyapuov stability theory, we will find the on-line update law of 
controller. Simulation results of nonlinear non-affine (double pendulum robot) are shown to 
demonstrate the effectiveness and performance of the proposed approach. Finally, the nonlinear 
MIMO non-affine system- two linked manipulator robot system is established and the 
corresponding intelligent controller is implemented by the digital signal processing chip.  
 
Keywords: multiple-input-multiple-output, nonlinear non-affine, wavelet neural network, 
backstepping, adaptive control   
 
 8
non-affine systems. However, many dynamic models of practical systems are nonlinear non-affine 
systems, and they are less common over the last decade. In general, non-affine system is not easy to 
control due to the fact that the control input appears in different form and no general approaches 
were proposed. Therefore, it is difficult to develop an adaptive control scheme for MIMO nonlinear 
uncertain non-affine systems.  
In this project, the backstepping technique is used to design adaptive controller for a class of 
MIMO nonlinear uncertain non-affine systems. The backstepping technique provides a systematic 
framework and recursive design methodology for nonlinear systems [21, 24, 29, 39, 45, 55]. The 
design procedure treats the state variables as virtual control inputs; than, the virtual controllers are 
designed step by step. Finally, the actual control input can be obtained. It illustrates the stability by 
Lyapunov stability theorem. However, the major constraint is that the system functions must be 
exactly known. If the internal uncertainty and external disturbance exist, then they may result in an 
unstable system. Therefore, we propose an output-recurrent wavelet neural network (ORWNN) 
system to approximate the unknown functions to solve this problem. Previous literatures developed 
fuzzy systems and neural networks to approximate the unknown functions [20-24, 26, 41, 55]. 
Many researchers have shown that using wavelet basis achieve superior performance in network 
size and learning ability [26, 34, 46, 48]. Therefore, wavelet functions are combined with the fuzzy 
neural network to construct the wavelet based neural network (WNN). In order to meet our 
requirement, the output feedback scheme is used to develop an output recurrent wavelet neural 
network (ORWNN) [43-44].  
Recently, newly neural network (NN) based backstepping control schemes were proposed for 
nonlinear affine uncertain systems [21, 24, 29, 55]. According to the idea of literatures [23, 28, 42], 
the non-affine form system can be transferred into strict-feedback-like form system, in which each 
subsystem can be viewed as an affine-like system. Thus, there exists stabilizing controller for this 
type of transforming system by implicit function theorem [42, 56]. Literature [23] proposed fuzzy 
neural network (FNN) based adaptive backstepping control approach to deal with a class of 
single-input-single-output (SISO) nonlinear non-affine system by the concept of [23, 28, 42]. We 
extend this approach to MIMO nonlinear non-affine system in non-triangular form. According to 
the results of [23, 28, 42], the MIMO nonlinear, non-affine, and non-triangular can be transferred 
into a like MIMO strict-feedback-like system; therefore, it can simplify the complexity of controller 
design, e.g., non-affine double-pendulum system [53]. Besides, these ideas can also cope with 
MIMO affine form systems, e.g., the inverted double pendulums on carts system [55]. Literature 
[54] proposed a NN-based controller to deal with the state-feedback linearizable system, and two 
NNs to be used to approximate two unknown functions, i.e., gain matrix function and uncertain 
functions in system dynamic. In this project, we proposed an adaptive backstepping control scheme 
ORWNNsABC  for a class of MIMO nonlinear uncertain non-affine systems. ORWNNsABC  only uses 
one NN for MIMO affine system control which simplifies the controller design. Therefore, our 
approach has ability to deal with not only affine-form but also non-affine system.    
Besides, most backstepping techniques have the problem of “explosion of complexity” [45, 47, 
49, 52]. It is caused by repeated differentiations of virtual controllers. Literature [49] indicated the 
 10
subsystems .  ,  ,  , 21 m∑∑∑ K  mTmuuu ℜ∈= ]  ,  , ,[ 21 Ku  is the control input vector and 1,iy , 
 ,  ,  ,2  ,1for  mi K=  denote the system output of subsystems ,  ,  ,  , 21 m∑∑∑ K  respectively. 
For the single-input-single-output system (for the first year results), the following nth-order 
nonlinear single-input-single-output (SISO) nonaffine system  
( )
( )
( )
1
232122
12111
 , ,
   
 , , ,
 , ,
xy
duxFx
dxxxFx
dxxFx
nnnn
=
=
=
=
&
L
&
&
                                    
where [ ]Tii xxxx  , , , 21 K= iℜ∈ , i=1, 2, …, n denote the system state vectors, u∈ℜ and y∈ℜ are 
the input and output, respectively. Fi(ּ), i=1, 2, …, n are the nonlinear smooth functions; di(ּ), i=1, 
2, …, n are the bounded external disturbances. Herein, system state variables are assumed to be 
measurable. The control objective is to design the control input u such that the output y follows a 
desired bounded trajectory yd. The following assumptions are made for the controllability of system 
(1). 
We rewrite system (1) as the following vector form: 
,
     ,   
     ,1  ,   ,1for    , , 
1
1
xy
)du,,x(Fx
)dx,x(Fx
=
=
−== +
nnnn
iiiii ni
&
K&
         (2) 
where ,  ,  ,1   ,]  ,   ,,[ ,,2,1 nixxx
mT
imiii KK =ℜ∈=x  are the vector of denoting the states of system 
(1),   ,   ), , ,( ), , ,([ , ,21,2,2,2,11,1,1,11 Kiiiiiiiiiiii dxxFdxxF +++ =)dx,x(F  ,)] , ,( ,1,,, mTimimimim dxxF ℜ∈+  
 ,1  ,   ,1 −= ni K are smooth vector function, mTmuuu ℜ∈= ]  ,  ,,[ 21 Ku  is the control input, 
mT
myyy ℜ∈= ]  ,  ,,[ 1,1,21,1 Ky  is the system output, ,  ,   ,2,1 ,]  ,   ,,[ ,,2,1 niddd Timiii KK ==d  
denotes the external bounded disturbance satisfying ii ρ≤d , in which ⋅  is the Euclidean norm 
and 0>iρ . Herein, system states are assumed to be measurable and the origin is the equilibrium 
point. Throughout this study, the following assumptions are needed to ensure the controllability of 
the system (1).  
Assumption 1: The inequalities  ,0),(
1 ,
1 , , , >∂
∂
+
+
ji
jijiji
x
xxF  hold ,iix ℜ∈∀  
.1   ,   ,1 ,1  ,   ,2,1 −=−= njmi KK  
 12
keyu d += )(nflc                 (7) 
where ][ 1kkk Ln= , substituting (5) and (7) into (4) and yields  
011 =+++ − nnn keke L                 (8) 
which implies that 0)(lim =∞>− tt e . This can be done by choosing proper k so that all roots of the 
polynomial that 0)1(1 =+⋅+ − nnn ksks L  are located in the open left-half plane. Thus, if ),( uxH  
is perfectly canceled by rnnu , i.e., rnnuuxH =),( , and 0=rcu , the closed-loop system is stable.  
As the discussion above, a RNN controller should be employed to approximate ),( uxH . The 
inputs to the RNN are x and u rcrnnflc uuuu +−=( ). Apparently, the output of the RNN rnnu  is 
directly fed into RNN to produce the control input u . According to the implicit function theorem 
[23, 37], there exists a set nx ℜ⊂Ω  and unique *rnnu  which is a function of x  and 
rcflc uuu +=α , such that ),(* αuxu rnn  satisfies for all nx R×Ω∈),( αux . Figure 1 illustrates that 
we should use RNN to approximate the uncertain function )( ux,H  and overcome this recursive 
problem. 
 
x
u RNNΣ+
-
)),(( uxHu ≅rnn
rcflc uuu +=α
 
Figure 1: Diagram of recurrent neural network. 
 
As mentioned above, system (2) can be rewritten as follows  
,
,
        ,1  ,   ,1for    ,,
1
11
xy
u)du,,x(Hx
x)dx,x(Hx
=
+=
−=+= ++
nnnn
iiiiii ni
&
K&
          (9) 
where [ ] [ ]u)du,,x(F)du,,x(HxdxxFd,xH −=−=−= ++ nnnnnniiiiiiii ni   ;1  ,   ,2 ,1  ,) ,  ,()( 11 K . Then system 
(2) is translated into a like strict-feedback form. Besides, each subsystem can be viewed as 
affine-like system based on the virtual control concept. In the rest of  this project, we use the iH  
to replace )(⋅iH  for convenience. For a nonlinear uncertain system, nii  ,  ,1 , L=H  are not 
exactly known. Hence, we utilize NNs to solve this unknown factor which has the excellent 
approximated ability. According to what has been discussed above, we proposed an output-recurrent 
 14
( )
( )
( )∑
∑
=
==== R
j
j
R
j
jj
T
p
kO
kOw
kOy
1
)3(
1
)3(
)4( ψw                   (12) 
where w=[w1 w2, …, wR]T is the weighting vector; [ ]Rψψψψ  ..., , 21= , jψ = ( ) ( )∑R
j
jj kOkO
)3()3(  
represents the normalized value. Obviously, the RFNN is a special TSK-type FNN system, therefore, 
it is suitable for on-line estimator [6, 8]. That is, for any given real function pnih ℜ→ℜ: , there 
exists optimal vector *iw , the function hi can be described by the output of the RFNN with a 
reconstruction error iε  as 
i
T
ii
T
i
T
iiii hhh εε +=+−=−= ψwψwψw ~ˆˆ~ *             (13) 
ii δε ≤                                         (14) 
where 0>iδ  is an unknown finite constant. 
Our objective is to design a control scheme for system (1) under unknown system functions 
such that the output y follows a desired trajectory yd. FNNs are used to estimate the unknown 
functions as above discussion, and then the FNN based adaptive backstepping control scheme can 
be designed. 
 
3.2  Output Recurrent Wavelet Neural Network (ORWNN) 
In recent years the applications of NNs in the identification and control of the dynamic systems 
have received considerable attention [32, 41]. The most useful property of NNs is the ability of 
uniformly approximation. Additionally, the concept of incorporating fuzzy logic into a neural 
network has grown into a popular research topic, called fuzzy neural network (FNN) or neural fuzzy 
system (NFs) [32-34, 37-38]. In contract to the pure neural network or fuzzy system, the FNN 
combines the capability of fuzzy reasoning in handling uncertain information with the capability of 
artificial neural networks in learning from processes [32]. However, the major drawback of FNNs is 
their application domain is limited to static problems due to their inherent feedforward network 
structure. Therefore, the recurrent fuzzy neural network (RFNN) which naturally involves dynamic 
elements in the form of feedback connection used as internal memories has been studied [37-38].  
Currently, several researches have shown that wavelet basis neural network achieves superior 
performance in network size and learning ability [26, 34, 48, 52]. 
In this project, to achieve highly approximated accuracy and speed up the convergence, the 
FNN is modified as a novel wavelet-based NN. Herein, we combine the advantages of FNN with 
wavelet functions to propose a four-layer output recurrent wavelet neural network (ORWNN). The 
schematic diagram is depicted in Fig. 3, in which 1−z  denotes a unit time delay. This ORWNN is 
composed of an input layer, a wavelet layer, a hidden layer, an output layer, and a recurrent layer.  
 16
Each node in this layer performs a wavelet function. A family of wavelets is constructed by 
translations and dilations performed on a single fixed function, as known the mother wavelet. There 
are many types of wavelet functions that can be used in the basis functions [7, 15, 29, 33]. In this 
thesis, the Gaussian wavelet function )
2
exp()cos()(
2zzz −= ωμ  is adopted as the activation 
function, where ω  is the selected frequency. Hence, 
],)(
2
1exp[)cos()( 2
ik
ikri
ik
ikri
ik
ikri
ik
mxmxmx
σσωσμ
−−⋅−⋅=−  bmk   ,  ,2,1 L=    (16) 
where ikm  and ikσ  are the translations and dilation in the kth term of the ith input rix  to the 
node of the mother wavelet layer, respectively. Each node in this layer has two adjustable 
parameters ikm  and ikσ . bm  is the total number of the wavelets with respect to the input nodes. 
 
Layer 3: Hidden layer 2 
In this layer, each node calculates the product of all input signals, i.e.,    
∏
=
== b
m
i
bikkkk mk
1
  ...,  ,1  ,),,,( μψ rr θσmx            (17) 
where b
b
mT
mkkk mmm ℜ∈= ]  ,   ,  ,   ,[ 21 KKm , bb mTmkkk ℜ∈= ]  ,   ,  ,   ,[ 21 σσσ KKσ . It can be 
expressed in a vector notation as  
bmT
mbrr mx ℜ∈= ]  ,  , ,[),,,( 21 ψψψθσ Lψ         (18) 
where b
b
mmT
m
T
k
TT mmmm ×ℜ∈= ]  ,  ,  ,  , [ 21 LLm  and bb mmTmTkTT ×ℜ∈= ]  ,  ,  ,  , [ 21 σσσσ LLσ . 
 
Layer 4: Output layer 
Each node calculates the linear combination of input variables. Therefore, the pth output is 
o
m
k
kkpr
T
pp mpwwmxwy
b
 ,  ,2,1  ,),,,(
1
L=== ∑
=
ψσψ          (19) 
where kpw  denotes the connecting activated weight value of the pth output associated with the kth 
layer. In vector representation,  
ψwy TTmp oyyy == ] ,  , ,  ,[ 1 LL           (20) 
where  
0
0
1
1
1111
1 ]  ,  ,[
mm
mmpmm
kmkpk
mp
mp
b
obbb
o
o
www
www
www
www ×ℜ∈
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
==
LL
MOMOM
LL
MOMOM
LL
LLw .          (21) 
 18
)(zj
lA
μ .  Since the triangular function is easier to calculate than other functions. It reduces the 
computation and is easy to implement in hardware. The triangular membership function can be 
expressed as 
    
otherwise ,    0    
 ,
 ,
)(
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
≤≤−
−
≤≤−
−
= czb
bc
zc
bza
ab
az
zj
lA
μ                              (22) 
Figure 2.2 shows the triangular membership function, where a , b , and c  denote the positions of 
three vertices satisfying cba ≤≤ .  
 The second part of DFLS is the fuzzy rule base consists of a collection of the fuzzy IF-THEN 
rules. The ith fuzzy IF-THEN rule is described by 
:iR If z1 is jA1 and K   and zl is 
j
lA , then y is y
i          (23) 
where jA1 , 
jA2 , …, 
j
lA are fuzzy variables and Y∈iy  is a fuzzy singleton. l is the dimension of 
inputs. j is the number of the fuzzy sets. 
 In the fuzzy inference engine, fuzzy logic principles are used to combine fuzzy IF-THEN rules 
from the fuzzy rule base into a mapping from fuzzy input sets in nXXX 321 ××× L  to fuzzy 
output sets in Y . We choose t-norm product to compute the firing strength as 
 ∏
=
=
l
k
kj
j
li k
A
1
)(μξ , lji  , ,2 ,1 K=                        (24) 
where kj  denotes the rule node correspond membership function nodes. 
 Defuzzification produces a crisp output for the fuzzy logic system from the fuzzy sets that 
appear at the output of the fuzzy inference engine in Fig. 2.1. There have many defuzzifier methods, 
such as centroid defuzzifier, center-of-sum defuzzifier, center-of-sets defuzzifier, etc. In this thesis, 
we use the following method to defuzzify 
ξΘΘHy Th zz == )|(ˆ)(                               (25) 
where ni×ℜ∈Θ  is the adjustable parameter vector and )(zhy  is the output of DFLS. 
 Herein, we consider the state variables 2x  is unmeasured, thus, we use 2xˆ  substitute for 2x . 
According the above discussion and property of universal approximation, the function ),( uxH  can 
be described by the DFLS as 
    )ˆ,(ˆ),(),( ˆ~ 2121 u,xxΘuxεu,xxΘHHH ξξ TT −+=−= ∗    (26) 
nℜ∈≤ εuxε ),(                                  (27) 
 20
niekes iIiii  , ,1 , K=+= ∫                        (33) 
where 0>Iik , i=1, …, n are integral gain values. The FNN estimated outputs are denoted ihˆ , 
i=1, …, n, especially nhˆ  is the output of RFNN. Then the following theorem is obtained.  
 
dx1
+ -
FNN 1
u
11 c
RFNN
Plant nx
nhˆ1ˆh
dx2 ndx1e ne
1su snu
nx2x
+ -+ - + -
+ + y
+
1s
+ - +
ns
+
∫ nIn ek
1111 ekysk Id −+− & nc1
∫ 11 ekI
( )
2
1
1
2
1
2
1
ρ
ρ s+− ( )222 1n nn
s
ρ
ρ +−
n
nnn
nInndnn
s
esc
ekxsk
11      −−−
−+− &
 
Figure 5: The FNN based adaptive backstepping control scheme. 
 
Theorem 1: Consider the nonlinear uncertain system (32) satisfying Assumptions 1 and 2. 
According to (24), the corresponding virtual controllers and the control input are designed as 
( )111111
1
2
ˆ1
sIdd uekhyskc
x +−−+−= &                          (34) 
( ) 1,,2 ,ˆ
1 11
1  n- iuekhxs
escsk
c
x siiIiiid
i
iii
ii
i
di …=⎟⎟⎠
⎞
⎜⎜⎝
⎛ +−−+−−= −−+ &     (35) 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ +−−+−−= −− snnInnnd
n
nnn
nn
n
uekhx
s
escsk
c
u ˆ1 11 &              (36) 
( )  n isu
i
ii
si ,,1 ,2
1
2
2
…=+−= ρ
ρ                              (37) 
where siu , i=1, …, n represent the robust controllers, iρ , i=1, …, n are design constants; and the 
following update laws of FNNs are chosen 
( ) 1,,1 ,ˆ 1  n- ixs iiiii …=Γ= +ψw&                    (38) 
( )nnnnn xs ψw Γ=&ˆ                               (39) 
where  n ii ,,1 , …=Γ  are the parameter adaptive rates. Then, the asymptotically convergence of 
 22
ε)θ,σ,m,(xψwεHH rr +=+= ******    T         (42) 
where mℜ∈ε  denotes an approximation error vector and ∗w and *ψ  are the optimal parameter 
matrix and vector of w  and ψ , respectively. The optimal parameter ∗w , *m , *σ , and ∗rθ  are 
defined as  
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧ −=
Ω∈Ω∈Ω∈Ω∈
HHw ˆsupminarg
ˆˆˆˆ
ˆ,ˆ,ˆˆ
*
rrzm
w mw θθσ
          (43) 
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧ −=
Ω∈Ω∈Ω∈Ω∈
HHm ˆsupminarg
ˆˆˆˆ
ˆ,ˆ,ˆˆ
*
rrzw
m wm θθσ
          (44) 
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧ −=
Ω∈Ω∈Ω∈Ω∈
HHσ ˆsupminarg
ˆˆˆˆ
ˆ,ˆ,ˆˆ
*
rrmw
mw θσ θσ
          (45) 
⎭⎬
⎫
⎩⎨
⎧ −=
Ω∈Ω∈Ω∈Ω∈
HHθ*r ˆsupminarg
ˆˆˆˆ ˆ,ˆ,ˆ zmwrr mw σθ θ
          (46) 
where σˆˆˆ   ,  , ΩΩΩ mw , and rθˆΩ  are the compact sets of suitable bounds on ,ˆ  ,ˆ  ,ˆ σmw  and 
,ˆ rθ respectively. They are defined as { } { }mw mmww ˆˆˆˆ ˆˆ  ,ˆˆ MM mw ≤=Ω≤=Ω  
{ } { }
rr
MM θθσσ ˆˆˆˆ ˆˆ  ,ˆˆ ≤=Ω≤=Ω rr θθσσ , where wM ˆ , mM ˆ , σˆM , and rM θˆ  are positive constants 
that are specified by the designer. 
From (15), the ORWNN’s output can be described as  
 ).,ˆ,ˆ,ˆ(ˆˆˆˆˆ n
TT xθσmψwψwH r==           (47) 
The estimated error H~  satisfies  
 
εψwψw
εψwψwψwψw
ψwεψw
HHH
++=
+−+−=
−+=
−=
∗
∗∗∗∗
∗∗
ˆ~~     
ˆˆˆˆ     
ˆˆ     
ˆ~
TT
TTTT
TT
         (48) 
where www ˆ~ −= ∗  and ψψψ ˆ~ −= ∗ . The linearization technique is employed to have the 
following Taylor expansion of ψ~ :  
 24
( ) ( )( ) ( ) ( )( )
.  ...,  ,1  ,        
~~~ˆˆˆˆˆ~~ )()(
nii
iT
i
iT
i
iT
mi
T
i
iT
i
iT
i
iT
mii
T
ii r
=+
+++−−−=
D
θψσψmψwθψσψmψψwH rr θσθσ   (52) 
Then the following theorem is obtained.  
 
d1x
)1( −nx
)1( −ns u
)1( −nz
dn )1( −x
Actual 
Control
Nonlinear
Plant 
-
+
+
-
2x
2s
2z
1k
1s d2xVirtual
Control 1
ORWNN 1
1Hˆ
Filter 1
(41)
2Hˆ
Virtual
Control 2
ORWNN 2 
+
-
2k
d3x
Filter n-1
(65)
Virtual
Control n-1
ORWNN n-1 
1
ˆ −nH
1−nk
Filter n
(85)
ORWNN n
nHˆ
nknx
+
-
ndx
ns
nz
y
dt
d
d1x&
1x
nx
nx
2x
1−nx
2τ nτ
1−nτ
 
Figure 6: ORWNNs based improved adaptive backstepping control scheme (IABCORWNNs). 
 
Theorem 2: Consider the MIMO nonlinear uncertain non-affine system (2) which satisfies 
Assumptions 1, 2, and 3. The virtual controllers and the actual control input are designed as  
11112 Hˆxsx −+−= dd k & ,               (53) 
,1  ,  ,2  ,ˆ)1( −=−+−=+ nik iiiidi L& Hzsx               (54) 
nnnnk Hzsu ˆ−+−= & ,                  (55) 
where .  ,  ,2 ,1  ,0 niki L=>  The corresponding parameters adaptive laws of ORWNNs are chosen 
as 
( ) ( ) ( )( )  ,ˆ2ˆˆˆˆˆ iTiiT iiTiiTmiiwii r wsθψσψmψψw r λγ θσ −−−−=&       (56) 
( ) , ˆ2ˆˆ )(iiimimii mswψm λγ −=&               (57) 
( )  ,ˆ2ˆˆ )(iiiiii σswψσ λγ σσ −=&            (58) 
, n, iiiiii
i
rr
…=−= 1  ,ˆ2ˆˆ )()( rr θswψθ λγ θθ& ,            (59) 
where niimw riii   ,  ,1  , ,  ,  , L=θσ γγγγ , are positive adaptive parameter rates and λ  is a finite 
 26
⎥⎥
⎥⎥
⎥⎥
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎢⎢
⎢⎢
⎢
⎣
⎡
−
−
−
−
==
∫ ∫
∫ ∫
∫ ∫
∫ ∫
∫
t t
r
t t
r
t t
t t
t
TT
I
dd
dd
dd
dd
d
0 0
2
0 0
1
0 0
22
0 0
11
0
ˆ
ˆ
ˆ
ττ
ττ
ττ
ττ
τ
xx
xx
xx
xx
ΞΞ
&
                        (63) 
and 
dt
d
dt
d
dt
d u
u
u,xxx
x
u,xxx
x
u,xxu,xx ∂
∂+∂
∂+∂
∂= )ˆ,(ˆ
ˆ
)ˆ,()ˆ,()ˆ,( 212
2
211
1
21
21
ξξξξ&  (64) 
where 
dt
d 1x  can be replaced 1xˆ& . Therefore, 1xˆ&  and dt
d 2xˆ  can be obtained as above. Then x~  and 
eX  are uniformly ultimately bounded (UUB), 
∞→
=
t
t 0)(lim Ξ                                                          (65) 
 
5. Simulation Results, Comparisons, and Experimental Equipment 
In this section, the simulation examples are divided into two parts. Part A shows the results of 
MIMO nonlinear non-affine systems including three order non-affine system in non-triangular form, 
and non-affine double-pendulums system. Simulation results of MIMO nonlinear affine system 
including the inverted double-pendulums on carts systems are introduced in Part B. These 
illustration examples show the performance of our proposed approaches can solve the tracking 
control of MIMO affine and non-affine systems. 
Example 1: Single-input-single-output System 
Consider the nonlinear system [16]: 
( )
( )[ ]
1
1212
2
2
111
cos2
1.015.0
xy
duxxxx
xxxx
=
+++=
++=
&
&
                    (66) 
where d is the bounded external disturbance. The initial condition is ( ) [ ]Tx 0 ,102 =  and the tracking 
trajectory is yd=sin(t). According to our approach h1=[0.5x1+(1+0.1 21x )x2-c1x2], 
h2=[x1x2+2u+cos(x1)u+d-c2u]. The following two cases are considered in this simulation. 
Case 1: External disturbance free, i.e., d=0. 
Case 2: The external disturbance d which is a square wave with the amplitude ± 2 and the period 
4π  (sec). 
The design parameters of our approach are 321 == kk ; 121 == cc ; 121 == ρρ ; 
 28
0 5 10 15 20 25 30
-1
-0.5
0
0.5
1
time(sec)
sy
st
em
 o
ut
pu
t
Case 2 of Example 4.1
0 5 10 15 20 25 30
-0.5
0
0.5
1
time(sec)
tra
ck
in
g 
er
ro
r
0 1 2 3 4 5 6 7 8 9 10
-50
0
50
time(sec)
co
nt
ro
l f
or
ce
ABC
FNN2
ABC
FNN3
literature [16]
desired trajectory
ABC
FNN2
ABC
FNN3
literature [16]
desired trajectory
ABC
FNN2
ABC
FNN3
literature [16]
 
(b) 
Figure 8: Simulation results, (a) case 1; (b) case 2. 
 
Table 2: Comparison results of our approach and literature [16]. 
Our approach 
 Literature [16] 
ABCFNN-2 ABCFNN-3 
Networks No. 4 2 
Adjustable 
Parameters No.
52 48 
MSE of case 1 0.013965 0.002952 0.003986 
MSE of case 2 0.015997 0.003054 0.004289 
 
Figure 3 and Table 2 show the results of the tracking control problem. From Fig. 3, we can 
observe that both our approaches (ABCFNN-2 and ABCFNN-3) have better performance (tracking 
error and convergence speed) than [16], even the external disturbance exists. In addition, Table 2 
shows the comparison of network structure and tracking error. There are fewer adjustable 
parameters and lower MSE of our approaches. 
 
Example 2: MIMO Nonlinear Non-affine System 
Example 1: Three-order non-affine system in non-triangular form  
The major drawback of backstepping technique is the problem of “explosion of complexity” 
which grows the controller complexity drastically as the order n of the system increases especially 
in the presence of control effort. Hence, we use a three-order MIMO nonlinear system to illustrate 
this fact. Consider the nonlinear system in vector form as follows:    
 30
0 2 4 6 8 10 12 14 16 18 20
-1
0
1
2
t(sec)
x 1
1
0 2 4 6 8 10 12 14 16 18 20
-1
-0.5
0
0.5
1
1.5
t(sec)
x 2
1
Ref erence signal(x
1d
)
IABC
ORWNNs
-1
ABC
ORWNNs
-1
Reef ence signal(x
2d
)
IABC
ORWNNs
-1
ABC
ORWNNs
-1
 
Figure 9: State trajectories of Example 2 - Case 1 (dashed line: reference signal; solid line: 
1-IABCORWNNs ; dash-dotted line: 1-ABCORWNNs ). 
0 2 4 6 8 10 12 14 16 18 20
-5
0
5
x 10
4
u 1
0 2 4 6 8 10 12 14 16 18 20
-5000
0
5000
u 2
0 2 4 6 8 10 12 14 16 18 20
-1
0
1
T
ra
ck
in
g 
er
ro
r
0 2 4 6 8 10 12 14 16 18 20
-1
0
1
t(sec)
T
ra
ck
in
g 
er
ro
r
IABC
ORWNNs
-1
ABC
ORWNNs
-1
(x
11
-x
1d
)IABC
ORWNNs
-1
(x
11
-x
1d
)ABC
ORWNNs
-1
(x
21
-x
2d
)IABC
ORWNNs
-1
(x
21
-x
2d
)ABC
ORWNNs
-1
IABC
ORWNNs
-1
(x
11
-x
1d
)ABC
ORWNNs
-1
 
Figure 10: Control forces and tracking errors of Example 2 - Case 1 (solid line: 1-IABCORWNNs ; 
dashed line: 1-ABCORWNNs ). 
 32
Table 4: Comparison results of MSE and maximum control force of 1-IABCORWNNs  and 
1-ABCORWNNs . 
          Methods  1-IABCORWNNs  1-ABCORWNNs  
Case 1 (0.3262, 0.3380) (0.3121, 0.3175) MSE of sate 
)  ,( 2111 xx  Case 2 (0.3285, 0.3387) (0.3124, 0.3188) 
Case 1 ( 3101.385× , 3102.44× ) ( 410895.2 × , 410969.4 × )Maximum control 
force  )  ,( 21 uu  Case 2 ( 310054.1 × , 31041.2 × ) ( 410595.2 × , 410951.4 × )
 
Figures 9 and 10 show the comparison of state trajectories and the corresponding control 
efforts, and tracking error ( dxx 111 − ) and ( dxx 221 − ) of Case 1, (dashed line: dd xx 21  , ; solid line: 
1-IABCORWNNs ; dash-dotted line: 1-ABCORWNNs ). From Fig. 9, we can see that 1-IABCORWNNs  
carries out control performance well with characteristics of stability, convergence, robustness, and 
adaptation even when external disturbance exists. Figure 10 shows the state trajectories of Case 2. 
Table 4 shows that 1-IABCORWNNs  has better control performance in maximum control force and 
MSE value. It verifies the efficiency of DSC technique of 1-IABCORWNNs .  
 
 
 
Figure 13: Diagram of double pendulums system [53]. 
 
Example 3: Tracking Control of a Non-affine Double-Pendulums System 
Considering the two-link robot manipulators, the two rods rotate in the vertical plane and two 
connecting joint are derived by torque control. The dynamic equations of the system can be 
rewritten as [10]: 
 34
 
Figure 14: The developed Two-linked manipulator system.  
 
Experimental Equipment and Controller Design 
The non-affine system is two-link robot manipulators as shown in Fig. 14. The hardware 
contains two robot arms and two AC server motors. The first and the second robot arm’s length are 
390mm and 340mm. The motors we chose 3000rpm 100W 0.32N-m and 3000rpm 400W 1.274N-m. 
The gear ratio of the two-link robot manipulators are 1:30. The motor driver we chose TECO JSD 
9300 series. 
Figure 15 shows the structure of control experiment. At first, we program our control method 
by CCS in the personal computer. Then, we load the control algorithm to the DSP control card. The 
DSP control card contains two parts. The first part is encoder interface. We use it to receive the 
states of non-affine system. Another is the control signal interface. The control signal contains the 
PWM signal and the sign signal. The PWM signal can be control the position that we need. The 
sign signal can be control the motor clockwise or anti-clockwise. Herein, the control signal output 
from the DSP control card is 3.3V, but the motor driver requires the 5V signal. Therefore, we use 
the IC (LVC4245A) to upgrade 3.3V to 5V. Then, we can use the control signal to control motor and 
to make the system achieve our control objective. 
Motor 
Driver
Non-affine
System 
DSP
Control Card
 36
Table 5: Network structure and initialization of 1-IABCORWNNs  and 1-ABCORWNNs . 
 ORWNN 1 ORWNN 2 
Network structure [2-8-4-2] [4-16-8-2] 
         ijw  0           0 
         ijm  [-2.7, -0.9, 0.9, 2.7] [-2.475, -0.825, 0.825, 2.475]
ijσ  1.0 1.1 
         
ijr
θ  0            0 
 
0 1 2 3 4 5 6 7 8 9 10
-1
-0.5
0
0.5
1
t(sec)
θ 1(
ra
d)
x1
0 1 2 3 4 5 6 7 8 9 10
-1
0
1
2
t(sec)
θ 2(
ra
d)
x3
Ref erence signal(x
3d
)
IABC
ORWNNs
-1
ABC
ORWNNs
-1
Ref erence signal(x
1d
)
IABC
ORWNNs
-1
ABC
ORWNNs
-1
 
Figure 16: Simulation results of Example 2 - State trajectories (dashed line: reference signal 
dd xx 31 , ; solid line: 1-IABCORWNNs ; dash-dotted line: 1-ABCORWNNs ). 
 38
of parameter adaptive laws for reducing the effect of initialization and improving the control 
performance. The simulation results have been presented to illustrate the effectiveness and 
performance of ABCFNN. In the second year, this project has successfully presented ORWNNsIABC  
for a class of MIMO nonlinear uncertain non-affine systems in non-triangular form. The proposed 
ORWNN-based backstepping controller is composed of a DSC technique to solve the drawback of 
“explosion of complexity”. Based on Lyapuov stability approach, the adaptive laws of online tuning 
parameters are obtained and the stability of the control system is guaranteed. Moreover, numerical 
simulation cases including non-affine system in non-triangular form and nonlinear affine systems 
have been presented to illustrate the effectiveness and well performances of approach we proposed 
in this project. Finally, the nonlinear MIMO non-affine system- two-linked manipulator system has 
been developed and the corresponding adaptive fuzzy controller implemented in DSP chip is 
proposed.  
 
REFERENCES 
[1] H. K. Khalil, Nonlinear Systems, 3rd Edition, Prentice Hall, NJ, 2000. 
[2] K. Hornic, M. Stinchcombe, and H. White, “Multilayer feedforward networks are universal 
approximators,” Neural Networks, Vol. 2, pp. 359–366, 1989. 
[3] B. Kosko, “Fuzzy systems as universal approximators,” IEEE Trans. on Computer, Vol. 43, 
No. 11, pp. 1329-1333, 1994. 
[4] M. Brown and C. J. Harris, Neurofuzzy Adaptive Modeling and Control, Prentice-Hall, NJ, 
1994. 
[5] Y. C. Chen and C. C. Teng, “A model reference control structure using a fuzzy neural 
network,” Fuzzy Sets and Syst., Vol. 73, pp. 291-312, 1995. 
[6] C. T. Lin and C. S. G. Lee, Neural Fuzzy Systems: A Neuro-Fuzzy Synergism to Intelligent 
Systems, Prentice-Hall, NJ, 1996. 
[7] C. H. Lee and C. C. Teng, “Fine tuning of membership functions for fuzzy neural systems,” 
Asian Journal of Control, Vol. 3, No. 3, pp. 216-225, 2001. 
[8] C. H. Lee and C. C. Teng, “Identification and control of dynamic systems using recurrent 
fuzzy neural networks,” IEEE Trans. on Fuzzy Systems, Vol. 8, No. 4, pp. 349-366, 2000. 
[9] C. H. Lee, “Stabilization of Nonlinear Nonminimum Phase Systems: An Adaptive Parallel 
Approach,” IEEE Trans. on Systems, Man, Cybernetics- Part: B, Vol. 34, No. 2, pp. 1075-1088, 
2004 
[10]  H. Han, C. Y. Su, and Y. Stepanenko, “Adaptive control of a class of nonlinear systems with 
nonlinearly parameterized fuzzy approximators,” IEEE Trans. on Fuzzy Systems, Vol. 9, No. 2, 
pp. 315-323, 2001. 
[11]  F. J. Lin, R. J. Wai, and C. C. Lee, “Fuzzy neural network position controller for Ultrasonic 
motor drive using push-pull DC-DC converter,” IEE Proc. Control Theory Appl., Vol. 146, No. 
1, pp. 99-107, 1999. 
[12] J. H. Park, S. H. Huh, S. H. Kim, S. J. Seo, and G. T. Park, “Direct adaptive controller for 
nonaffine nonlinear systems using self-structuring neural networks,” IEEE Trans. on Neural 
 40
fuzzy-neural approach,” IMACS Multiconference on Computational Engineering in Systems 
Applications, Vol. 1, pp. 519-523, 2006. 
[29] H. K. Khalil, Nonlinear Systems, rd3  Edition, Prentice-Hall, NJ, 2000. 
[30] M. Krstic, I. Kanllakopulos, and P. Kokotovic, Nonlinear and Adaptive Control Design, New 
York: Wiley, 1995. 
[31] Y. Li, S. Qiang, X. Zhuang, and O. Kaynak, “Robust and adaptive backstepping control for 
nonlinear systems using RBF neural networks,” IEEE Trans. on Neural Networks, Vol. 15, No. 
3, pp. 693-701, 2004. 
[32] C. H. Lee and C. C. Teng, “Identification and control of dynamic systems using recurrent 
fuzzy neural networks,” IEEE Trans. on Fuzzy Systems, Vol. 8, No. 4, pp. 349-366, 2000. 
[33] C. H. Lee and C. C. Teng, “Fine tuning of membership functions for fuzzy neural systems,” 
Asian Journal of Control, Vol. 3, No. 3, pp. 216-225, 2001. 
[34] C. J. Lin and C. C. Chin, “A wavelet-based neural-fuzzy system and its applications,” in Proc. 
IEEE Int. Joint Conf. Neural Networks, pp. 1921-1926, 2003. 
[35] C. M. Lin, L. Y. Chen, and C. H. Chen, “RCMAC hybrid control for MIMO uncertain 
nonlinear systems using sliding-mode technology,” IEEE Trans. on Neural Networks, Vol. 18, 
No. 3, pp. 708-720, 2007. 
[36] C. M. Lin and Y. J. Mon, “Decoupling control by hierarchical fuzzy sliding-mode controller,” 
IEEE Trans. on Fuzzy Systems, Vol. 13, No. 4, pp. 593-598, 2005. 
[37] C. T. Lin and C. S. G. Lee, Neural Fuzzy Systems: A Neuro-Fuzzy Synergism to Intelligent 
Systems, Prentice-Hall, NJ, 1996. 
[38] F. J. Lin and C. H. Lin, “On-line gain-tuning IP controller using RFNN,” IEEE Trans. on 
Aerospace and Electronic Systems, Vol. 37, No. 2, pp. 655-670, 2001. 
[39] Y. J. Liu and W. Wang, “Adaptive fuzzy control for a class of uncertain nonaffne nonlinear 
system,” Information Sciences, Vol. 177, Issue 18, pp. 3901-3917, 2007. 
[40] S. Labiod and T. M.Guerra, “Adaptive fuzzy control of a class of SISO nonaffine nonlinear 
systems,” Fuzzy Sets and Systems, Vol. 158, No. 10, pp. 1126-1137, 2006. 
[41] K. S. Narendra and K. Parthasarathy, “Identification and control of dynamical systems using 
neural networks,” IEEE Trans. on Neural Networks, Vol. 1, No. 1, pp. 4-27, 1990. 
[42] J. K. Park, S. H. Huh, and S. H. Kim, “Direct adaptive controller for nonaffine nonlinear 
systems using self-structuring neural networks,” IEEE Trans. on Neural Networks, Vol. 16, No. 
2, pp. 414-422, 2005. 
[43] Y. F. Peng and C. M. Lin, “Intelligent hybrid control for uncertain nonlinear systems using a 
recurrent cerebellar model articulation controller,” IEE Proc. Control Theory Appl., Vol. 151, 
pp. 589-600, 2004. 
[44] Y. F. Peng, M. H. Lin, and C. M. Chong, “Design of output recurrent CMAC backstepping 
control system for tracking periodic trajectories,” IEEE International Joint Conference on 
Neural Networks, pp. 3108-3113, 2006. 
[45] H. J. Shieh and C. H. Hsu, “An integrator-backstepping-based dynamic surface control method 
for a two-axis piezoelectric micropositioning stage,” IEEE Trans.  on Control Systems 
 42
x C. H. Lee and Y. C. Lin, “Robust Adaptive Control for Nonlinear Uncertain Systems 
Using Type-2 Fuzzy Neural Network System,” Mathematical Problems in Engineering, 
2011. (SCI) doi:10.1155/2011/604391 IF: 0.689, RF: 44/87 in Engineering, 
Multidisciplinary, 
 C. H. Lee and F. Y. Chang, “Interval Type-2 Recurrent Fuzzy Neural System for 
Nonlinear Systems Control Using Stable Simultaneous Perturbation Stochastic 
Approximation Algorithm,” Mathematical Problems in Engineering, special issue for 
“Nonlinear Systems: Asymptotic Methods, Stability, Chaos, Control, and Optimization,” 
2011. (SCI) IF: 0.689, RF: 44/87 in Engineering, Multidisciplinary  
doi:10.1155/2011/102436 
 C. H. Lee and L. J. Kau, “Enhancing the Predictive Coding Efficiency with Control 
Technologies for Lossless Compression of Images,” Accepted to appear in IET Image 
Processing. (SCI/EI) IF: 0.862, RF: 137/247 in Engineering, Electrical & Electronic 
 C. H. Lee and Y. H. Lee, “Nonlinear System Identification Using Takagi-Sugeno-Kang 
Type Interval-valued Fuzzy Systems via Stable Learning Mechanism,” IAENG 
International Journal of Computer Science, Vol. 38, Issue 3, pp. 249-259, 2011. (Good 
Paper collection of IMECS for special issue of IMECS 2011) 
 C. H. Lee and Y. C. Lee, “Nonlinear Fuzzy Neural Controller Design via EM-based 
Hybrid Algorithm,” Accepted to appear in special issue “System Control 
Using Bio-Inspired Learning Algorithms” of the International Journal of Computational 
Intelligence in Control (IJCIC). 
 C. H. Lee and B. R. Chung, “Adaptive Backstepping Controller Design for Nonlinear 
Uncertain Systems Using Fuzzy Neural Systems,” Accepted to appear in International 
Journal of Systems Science, 2010. (SCI/EI) IF: 0.948, RF: 29/60 in Automation & Control 
Systems  
 C. H. Lee and S. K. Chang, “Experimental Implementation of Nonlinear TORA System 
and Robust Adaptive Backstepping Controller Design,” Accepted to appear in Neural 
Computing and Applications, Dec. 2010. (SCI) IF: 0.563, RF: 91/108 in Computer 
Science, Artificial Intelligence 
 C. H. Lee, F. K. Chang, and Y. C Lee, “An Improved Electromagnetism-like Algorithm 
for Recurrent Neural Fuzzy Controller Design,” International Journal of Fuzzy Systems, 
Vol. 12, no. 4, pp. 289-299, 2010. IF: 1.362, RF: 22/60 in Automation & Control Systems; 
 44
Paper No.: ICAIA_94 
Paper Title: Nonlinear Systems Design by a Novel Fuzzy Neural System via 
Hybridization of EM and PSO Algorithms 
4.   The winner of the Best Paper Award- Certificate of Merit for The 2010 IAENG 
International Conference on Artificial Intelligence and Applications 
   Paper No.: ICAIA_80 
Paper Title: Species-based Hybrid of Electromagnetism-like Mechanism and 
Back-propagation Algorithms for An Interval Type-2 Fuzzy System Design 
5. 獲得元智大學 97 學年研究傑出獎 
6. 獲得 2009 年中華民國自動控制學會青年自動控制工程獎 
7. 中華民國模糊學會碩士論文獎第二名 
 
緻論文摘要集、論文全文光碟片與發表論文之論文冊。為期 3 天的議程中，因投稿者眾多，
大會必須事前篩選優秀論文並規劃在幾天完成發表，可發現議程緊湊，且每一場次似乎幾
乎座無虛席，由此可見與會者都相當重視此次的會議。今年度有三十個國家與數百篇論文
發表。 
17-18 日穿插多場專題演講(Keynote Speeches, Invited Talks, Tutorials)，個人 17 日聆聽
介紹；論文發表亦在 17 日上午開始，主要為 Int. Conf. on Artificial Intelligent and Applications 
(ICAIA 2010)，個人之研究在 18 日上午 9:30～10:45 與 11:15~13:00 發表。參與學生在國內
均經過充分的準備與驗收，在大會中從容的將成果介紹給與會學者，可增廣視野與國際觀，
也讓他們清楚瞭解目前相同研究領域的進展，更讓他們見到其他國外學者（或學生）的態
度，相信對他們是一個不同的經驗。大會在 18 日晚間舉行大會晚宴，個人因行程安排未能
參與，一行四人搭乘晚間 7:15 長榮航空 BR872 班機離開香港。 
此次會議在論文審查階段，三篇論文均獲得審查委員推薦參與論文競賽、推薦至期刊
論文發表，大會亦將於大會結束後一個內月公告獲獎論文；個人去年亦獲肯定，推薦發表
於期刊 Int. J. of Engineer Letters。 
 
二、與會心得 
此次帶領學生參與國際會議，認識國外學生與研究學者，個人認為對研究生收穫頗大，
也感謝學校能給予補助，讓學生順利成行。 
個人主要的研究領域在模糊邏輯、模糊控制、類神經網路與非線性控制的應用，藉由
參與這次的與會，讓個人有機會瞭解到目前國際學者之研究方向，藉由參與不同主題的討
論，並參考別人的研究成果與應用範圍，對於其他領域也有更進一步的認識與體會，甚至
計畫於近來嘗試著從事這方面的研究。 
 
三、建議 
國內之重要學者應積極爭取主辦，藉由學術上的交流，提高大家對台灣與台灣學術界的
認識，並讓更多學者有機會參與盛會。 
 
四、攜回資料名稱及內容 
光碟片、會議摘要冊、未來會議徵文 
 
 
 Layer 2: Membership layer
Layer 5: TSK layer
Layer 1: Input layer
Layer 3: Rule layer
Layer 4: Left-most & 
Right-most layer
Layer 6: Output layer
1x nxix
11
~F jF1
~
MF1
~
1
~
iF ijF
~
iMF
~
1
~
nF njF
~
nMF
~
∏ ∏ ∏
Σ
Σ Σ Σ Σ Σ Σ
][ 11
ll ωω  ][ 11 rr ωω  
][ lj
l
j ωω  
][ lM
l
M ωω  
][ rj
r
j ωω  
][ rM
r
M ωω  
] [ MM ff] [ 11 ff ] [ jj ff
Σ Σ
 lT1  
l
jT  lMT  
rT1  rjT  
r
MT
yˆ
 
Figure 1: Diagram of the proposed TIVNFS-A with M rules. 
 
 
Figure 2: Constructed asymmetric interval valued fuzzy set (IVFS) [18]. 
 
II. TAKAGI-SUGENO-KANG-TYPE INTERVAL-VALUED 
NEURAL FUZZY SYSTEMS  
In this paper, we propose a TSK-type interval-valued 
neural fuzzy system with asymmetric fuzzy membership 
functions (TIVNFS-A), which is a modification of type-2 
fuzzy neural networks (or interval-valued neural fuzzy 
systems). We adopted interval-valued asymmetric MFs and 
the TSK-type consequent part to develop the TIVNFS-A. A 
TIVNFS-A with M fuzzy rules is implemented as the 
six-layer network shown in Fig. 1. We first introduce the 
network structure of TIVNFS-A. In general, given the system 
input data xi, , ,,2 ,1 ni L=  and the TIVNFS-A’s output yˆ , 
the jth fuzzy rule can be expressed as: 
Rule j: IF x1 is jF1
~  and … and xn is njF
~ , THEN  
Yj=Cj0+Cj1x1+Cj2x2+…+ Cjnxn         (1) 
where j=1, 2, …, M; Cj0 and Cji are the consequent fuzzy sets, 
Yj is the output of the jth rule (a linear combination operation), 
and ijF
~  is the antecedent fuzzy set. The fuzzy MFs of the 
antecedent part ijF
~  are the asymmetric interval-valued fuzzy 
sets (IVFSs) that are shown in Fig. 2, which are different 
from typical Gaussian MFs. Several approaches indicate that 
using asymmetric MFs can improve approximation accuracy 
[3, 12, 18, 20-22, 27]. The asymmetric IVFSs are generated 
from four Gaussian functions, as shown in Fig. 2. The 
construction of asymmetric IVFSs is introduced in Appendix 
A. Subsequently, the fuzzy sets of the consequent part Cj0 and 
Cji are designed to be convex, normal type-1 fuzzy subsets. 
The signal propagation and the operation functions of the 
nodes are indicated in each layer. In the following description, 
)(k
iO  denotes the ith output of a node in the kth layer. 
 
Layer 1 (Input Layer): For the ith node of layer 1, the net 
input and the net output are written as 
ii xO =)1(                                               (2) 
where i=1, 2, …, n, xi represents the ith input to the ith node 
of layer 1. The nodes in this layer only transmit input values 
to the next layer directly. 
 
Layer 2 (Membership Layer): In this layer, each node 
performs an asymmetric IVFS ijF
~  (as shown in Fig. 2), 
where the subscript “ij” indicates the jth term of the ith input,  
j=1, …, M. We use superscripts l and r to denote the left and 
right curves of the Gaussian membership function. The 
parameters of the lower and upper MFs are denoted by _ and 
−, respectively. Therefore, the output of layer two is   
T
iFiF
T
ijijiFij
OOOOOO
ijijij
])()([][)( )1(~)1(~)2(
)2()1(
~
)2( μμμ ===  (3) 
where  
⎪⎪⎩
⎪⎪⎨
⎧
≤
<<
≤
=
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−
xme
mxm
mxe
x
r
mx
rl
l
mx
F
r
r
l
l
for   ,
for                 ,1 
for   ,
)(
2
2
2
1
2
1
~
σ
σ
μ
 
  
and   
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
≤⋅
<<
≤⋅
=
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−
xme
mxm
mxe
x
r
mx
rl
l
mx
F
r
r
l
l
for   ,
for                ,     
for   ,
)(
2
2
2
1
2
1
~
σ
σ
γ
γ
γ
μ .  
IAENG International Journal of Computer Science, 38:3, IJCS_38_3_09
(Advance online publication: 24 August 2011)
 
______________________________________________________________________________________ 
 layer, ωW  is the consequent weighting vector, W  is the 
parameters of lower AFMFs, W  is upper AFMFs’ 
parameters, and γ  is the maximum value of lower AFMFs, 
i.e., 
[ ]
[ ]
[ ]
[ ] .
, 
,
,
Trlrl
Trlrl
Trlrl
T
mm
mm
sc
σσ
σσ
ωωωωω
=
=
=
=
W
W
W
C
                  (13) 
Considering the gradient term W∂∂ )(kE , we have 
WWW ∂
∂−=∂
∂⋅∂
∂⋅∂
∂=∂
∂ )(ˆ)()(ˆ
)(ˆ
)(
)(
)()( kykeky
ky
ke
ke
kEkE         (14) 
thus  
.)()()()1(
)6(
W
WW ∂
∂⋅⋅+=+ kOkekk η                  (15) 
The remaining work involves finding the corresponding 
partial derivative with respect to each parameter. For the BP 
algorithm, the remaining works are the derivations of 
gradient for parameters ωγ WWW  , , , , and C. According to 
(11)-(15), we can obtain the update rule of each parameter. 
 
-The Derivation of update law for C  
The update law of the TIVNFS-A’s parameters C  is 
j
jj c
kykekckc ∂
∂⋅+=+ )(ˆ)()()1( η                         (16) 
j
jj s
kykeksks ∂
∂⋅+=+ )(ˆ)()()1( η                         (17) 
where the partial derivative with respect to jic  and jis  are 
   
2
1)(ˆ
1
)4(
)4(
1
)4(
)4(
0 ⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+=∂
∂
∑∑
==
M
j
jr
jr
M
j
jl
jl
j O
O
O
O
c
ky                            (18) 
   
2
1ˆ
1
)4(
)4(
1
)4(
)4(
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+⋅⋅=∂
∂
∑∑
==
M
j
jr
jr
M
j
jl
jl
i
ji O
O
O
O
x
c
y                         (19) 
   
2
1ˆ
1
)4(
)4(
1
)4(
)4(
0 ⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+−=∂
∂
∑∑
==
M
j
jr
jr
M
j
jl
jl
j O
O
O
O
s
y                            (20) 
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+−⋅⋅=∂
∂
∑∑
==
M
j
jr
jr
M
j
jl
jl
i
ji O
O
O
O
x
s
y
1
)4(
)4(
1
)4(
)4(
 
2
1ˆ .                     (21) 
 
-The Derivation of update law for ωW  
The update law of the TIVNFS-A’s parameters ωW  is 
 )(
ˆ
)()()1(
j
jj
kykekk ωηωω ∂
∂⋅+=+                       (22) 
 )(
ˆ
)()()1(
j
jj
kykekk ωηωω ∂
∂⋅+=+                        (23) 
where the partial derivative with respect to jω  and jω  are 
  
2
1)(ˆ )4()3(
1
)4(
)5(
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+
−⋅−=∂
∂
∑
=
l
j
l
j
jlj
M
j
jl
l
l
j
l
j
OO
O
OTky
ωωω                       (24) 
  
2
1)(ˆ )4()3(
1
)4(
)5(
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+
−⋅−=∂
∂
∑
=
r
j
r
j
jrj
M
j
jr
r
r
j
r
j
OO
O
OTky
ωωω                       (25) 
  
2
1)(ˆ )4()3(
1
)4(
)5(
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+
−⋅−=∂
∂
∑
=
l
j
l
j
jlj
M
j
jl
l
l
j
l
j
OO
O
OTky
ωωω                       (26) 
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+
−⋅−=∂
∂
∑
=
r
j
r
j
jrj
M
j
jr
r
r
j
r
j
OO
O
OTky
ωωω
)4()3(
1
)4(
)5(
2
1)(ˆ .                        (27) 
 
-The Derivation of update law for W  
The update law of the TIVNFS-A’s parameters W  is 
 )(
ˆ
)()()1(
ij
ijij m
kykekmkm ∂
∂⋅+=+ η                     (28) 
 )(
ˆ
)()()1(
ij
ijij
kykekk σησσ ∂
∂⋅+=+                     (29) 
where the partial derivative with respect to ijm  and ijσ  are 
W
W
∂
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −∂
⋅
⎥⎥
⎥⎥
⎦
⎤
+
⋅⋅−+
⎢⎢
⎢⎢
⎣
⎡
+
⋅⋅−−=∂
∂
∑
∑
=
=
2
)3(
1
)4(
)5(
)3(
1
)4(
)5(
4
1)(ˆ
σ
ωω
ω
ωω
ωγ
mx
O
O
OT
O
O
OTky
r
j
r
j
j
r
j
M
j
jr
r
r
j
l
j
l
j
j
l
j
M
j
jl
l
l
j
           (30) 
where ( )
( )2
2
2
l
ij
l
iji
l
ij
l
iji
l
ij
mxmx
m σσ
−−=⎟⎟⎠
⎞
⎜⎜⎝
⎛ −
∂
∂                               (31) 
( )
( )2
2
2
r
ij
r
iji
r
ij
r
iji
r
ij
mxmx
m σσ
−−=⎟⎟⎠
⎞
⎜⎜⎝
⎛ −
∂
∂                               (32) 
( )
( )3
22
2
l
ij
l
iji
l
ij
l
iji
l
ij
mxmx
σσσ
−−=⎟⎟⎠
⎞
⎜⎜⎝
⎛ −
∂
∂                              (33) 
( )( )3
22
2
r
ij
r
iji
r
ij
r
iji
r
ij
mxmx
σσσ
−−=⎟⎟⎠
⎞
⎜⎜⎝
⎛ −
∂
∂ .                           (34) 
 
-The Derivation of update law for W  
The update law of the TIVNFS-A’s parameters W  is 
 )(
ˆ
)()()1(
ij
ijij m
kykekmkm ∂
∂⋅+=+ η                       (35) 
IAENG International Journal of Computer Science, 38:3, IJCS_38_3_09
(Advance online publication: 24 August 2011)
 
______________________________________________________________________________________ 
 yˆ
 
Figure 3: Series-parallel model with the TIVNFS-A for nonlinear systems identification. 
 
2
1
)4(
)4(
1
)4(
)4(2
 
2
1)(ˆ1
−
==
−
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+⋅=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂= ∑∑ M
j
jr
jr
M
j
jl
jli
ji
c
O
O
O
Ox
Dc
ky
Dji
η   (55) 
2
1
)4(
)4(
1
)4(
)4(2
0
 
2
11)(ˆ1
0
−
==
−
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+−=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂= ∑∑ M
j
jr
jr
M
j
jl
jl
j
s
O
O
O
O
Ds
ky
Dj
η  (56) 
. 
2
1)(ˆ1
2
1
)4(
)4(
1
)4(
)4(2
−
==
−
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+⋅=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂= ∑∑ M
j
jr
jr
M
j
jl
jli
ji
s
O
O
O
Ox
Ds
ky
Dji
η  
(57) 
 
-Optimal learning of W  
.
4
1)(ˆ1
2
2)3(
1
)4(
)5(
)3(
1
)4(
)5(2
−
=
=
−
⎥⎥
⎥⎥
⎦
⎤
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −
∂
∂⋅
⎟⎟
⎟⎟
⎠
⎞
+
⋅⋅−+
⎢⎢
⎢⎢
⎣
⎡
⎜⎜
⎜⎜
⎝
⎛
+
⋅⋅−−=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂=
∑
∑
σωω
ω
ωω
ωγη
mxO
O
OT
O
O
OTky
D
r
j
r
j
j
r
j
M
j
jr
r
r
j
l
j
l
j
j
l
j
M
j
jl
l
l
j
W
WW
        (58) 
 
- Optimal learning of W  
.
4
1)(ˆ1
2
2)3(
1
)4(
)5(
)3(
1
)4(
)5(2
−
=
=
−
⎥⎥
⎥⎥
⎦
⎤
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −
∂
∂⋅
⎟⎟
⎟⎟
⎠
⎞
+
⋅⋅−+
⎢⎢
⎢⎢
⎣
⎡
⎜⎜
⎜⎜
⎝
⎛
+
⋅⋅−−=⎟⎠
⎞⎜⎝
⎛
∂
∂=
∑
∑
σωω
ω
ωω
ωγη
mxO
O
OT
O
O
OTky
D
r
j
r
j
j
r
j
M
j
jr
r
r
j
l
j
l
j
j
l
j
M
j
jl
l
l
j
W
WW
        (59) 
 
-Optimal learning of ωW  
2
)4()3(
1
)4(
)5(
2
2
11)(ˆ1
−
=
−
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+
−⋅−=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂= ∑ ljlj
jlj
M
j
jl
l
l
j
l
j
OO
O
OT
D
ky
D
l
j ωωωηω (60
) 
2
)4()3(
1
)4(
)5(
2
2
11)(ˆ1
−
=
−
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+
−⋅−=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂= ∑ rjrj
jrj
M
j
jr
r
r
j
r
j
OO
O
OT
D
ky
D
r
j ωωωηω (61
) 
2
)4()3(
1
)4(
)5(2
2
11)(ˆ1
−
=
−
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+
−⋅−=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂= ∑ ljlj
jlj
M
j
jl
l
l
j
l
j
OO
O
OT
D
ky
D
l
j ωωωηω (62) 
.
2
11)(ˆ1
2
)4()3(
1
)4(
)5(2
−
=
−
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
+
−⋅−=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂= ∑ rjrj
jrj
M
j
jr
r
r
j
r
j
OO
O
OT
D
ky
D
r
j ωωωηω (63) 
 
- Optimal learning of γ  
.
2
11)(ˆ1
2
)3(
1
)4(
)5(
1
)4(
)5(
2
−
=
=
−
⎥⎥
⎥⎥
⎦
⎤
⋅
⎟⎟
⎟⎟
⎠
⎞
+⋅
−+
⎢⎢
⎢⎢
⎣
⎡
⎜⎜
⎜⎜
⎝
⎛
+⋅
−=⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂=
∑
∑
ij
j
r
j
r
j
r
j
M
j
jr
r
r
j
l
j
l
j
l
j
M
j
jl
l
l
j
ij
O
O
OT
O
OT
D
ky
Dij
γωω
ω
ωω
ω
γηγ
 (64) 
 
IV. SIMULATION RESULTS 
In this section, two illustrated examples of nonlinear 
system identification are introduced to show the 
performance and effectiveness of TIVNFS-A. All 
simulations were done by MATLAB in Intel(R) CORE 2 
QUAD computer with clock rate of 2.4GHz and 3GB of 
main memory. 
 
Example 1: Nonlinear system identification 
Consider the following nonlinear system [15] ( ))1(),(),2(),1(),()1( −−−=+ kukukykykyfky pppp  (65) 
where 
( ) .
1
)1(,,,, 2
3
2
2
435321
54321 xx
xxxxxxxxxxxf ++
+−=                   
IAENG International Journal of Computer Science, 38:3, IJCS_38_3_09
(Advance online publication: 24 August 2011)
 
______________________________________________________________________________________ 
 TABLE I 
THE COMPARISON RESULTS IN 10 TIMES OF DIFFERENT LEARNING RATE 
 BP algorithm with optimal learning rate 
BP algorithm with fixed 
learning rate 
Best 0.001671 0.001696 
Average 0.002377 0.003203 
Worst 0.003458 0.006690 
Times(sec) 21.904 15.808 
 
Illustration Comparison of TIVNFS-A system-  
In this comparison, we discuss the performance of 
TIVNFS-A and RFNN. Figure 8 shows the result of the 
values of RMSE after training with TIVNFS-A and RFNN. 
The performance of TIVNFS-A is better than RFNN’s in 
comparison of RMSE. In addition, the convergent speed of 
TIVNFS-A is also faster than ones of RFNN. TABLE II 
shows the best average and worst RMSE of TIVNFS-A and 
RFNN after training. According to the results, the 
performance of identification by TIVNFS-A is better than 
by RFNN. We solve the nonlinear system identification by 
TIVNFS-A successfully and the simulation result the better 
performance. 
 
0 10 20 30 40 50
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
epoch
R
M
S
E
 
 
TIVNFS-A
RFNN
 
Figure 8: The values of RMSE of  TIVNFS-A and RFNN. 
 
TABLE II 
 THE COMPARISON RESULTS IN 10 TIMES OF DIFFERENT NEURAL 
NETWORKS 
 TIVNFS-A RFNN 
Best 0.001696 0.002169 
Average 0.003203 0.010345 
Worst 0.006690 0.017337 
imes(sec) 15.808 1.050 
 
 
Figure 9: Continuous Stirred Tank Reactor. 
 
TABLE III 
 THE PARAMETER OF CSTR PLANT 
Parameter Description Value 
Ca0 The concentration of inlet feed 1  (mol·l-1) 
T0 The temperature of inlet feed 350  (K) 
Tc0 The temperature of inlet coolant 350  (K) 
v The volume in the reactor tank 100  (l) 
k0 Reaction rate constant 7.2×1010  (min-1) 
E/R Energy of activation 9.95×103  (K) 
ΔH Heat of reaction -2×105  (cal·mol-1) 
Cp, Cpc Specific heats 1  (cal·g-1·K-1) 
ρ, ρc Liquid densities 1×103  (g·l-1) 
ha Heat transfer coefficient 7×105  (cal·min-1·K-1) 
 
Example 2: Identification of nonlinear CSTR system  
In Example 1, we have shown that the TIVNFS-A has 
capability of nonlinear system identification and it has better 
performance than RFNN’s results. In this example, we will 
use the TIVNFS-A to identify an actual system in chemistry 
and show the TIVNFS-A system. The Continuous Stirred 
Tank Reactor (CSTR) system was chosen as an example 
problem by application of identification. Figure 9 shows the 
illustration of CSTR system that is common chemical 
system. The process describes the reactions two reactants 
which are react and generate a compound in the tank. The 
plant of CSTR system is described by [29] 
( ) )(00 )()()()( tRT
E
aaaa etCktCCv
tqtC
−−−=&                 (70) 
( )
( ))(1)(         
)()()()(
0
)(
2
)(
10
3
tTTetqk
etCktTT
v
tqtT
c
tq
k
c
tRT
E
a
c −⎟⎟⎠
⎞
⎜⎜⎝
⎛ −+
−−=
−
−&
                     (71) 
where k1, k2, and k3 are thermodynamic and chemical as  
pC
Hkk ρ
0
1
Δ−= , 
vC
C
k
p
pcc
ρ
ρ=2  and 
pcc
a
C
hk ρ=3 . 
Ca(t) and T(t) are the concentration and temperature of 
produce in the tank. q(t) and qc(t) are the flow rate of inlet 
feed and inlet coolant. Other parameters of above equations 
are fixed and have been described and determined in 
TABLE III. 
For system identification, the flow rate of inlet feed and 
inlet coolant q(t) and qc(t) as the inputs of TIVNFS-A. The 
concentration and temperature of produce Ca(t) and T(t) as 
the outputs of TIVNFS-A. Figure 10 shows the 
series-parallel scheme for CSTR system identification. In 
order to make more real simulation, we added the white 
noise in the inputs data.  Since the inputs of the TIVNFS-A, 
q(t) and qc(t) contain the white noise, therefore we use a 
simple filter before TIVNFS-A system. Figures 11 and 12 
show the inputs and the desire outputs data for the CSTR 
system identification, respectively. Note that the 
non-smooth phenomenon of input and output signals exists 
since the white noises are added in the input signals.  
 
 
 
 
 
IAENG International Journal of Computer Science, 38:3, IJCS_38_3_09
(Advance online publication: 24 August 2011)
 
______________________________________________________________________________________ 
 0 500 1000 1500 2000 2500 3000
0.05
0.1
0.15
(a)
Time(k)
T
IV
N
F
S
-A
's
 o
ut
pu
t (
C
a)
0 500 1000 1500 2000 2500 3000
430
435
440
445
450
(b)
Time(k)
T
IV
N
F
S
-A
's
 o
ut
pu
t (
T
)
 
Figure 13: Identification results of CSTR system, (a) Concentration, Ca(t); 
(b)  Temperature, T(t). 
0 5 10 15 20 25 30
0
20
40
60
80
100
120
140
Epoch
R
M
S
E
 
Figure 14: Results of RMSE value. 
 
TABLE IV 
THE RESULTS OF CSTR IDENTIFICATION USING TIVNFS-A IN 10 
INDEPENDENT RUNS. 
 TIVNFS-A 
Best 0.42827  
Average 0.62242  
Worst 0.77573  
Times(sec) 15.808 
 
REFERENCES 
[1] H. Bustince, “Indicator of Inclusion Grade for Interval-valued Fuzzy 
Sets. Application to Approximate Reasoning based on Interval-valued 
Fuzzy Sets,” Int. J. of Approximate Reasoning, Vol. 23, No. 3, pp. 
137-209, 2000. 
[2] H. Bustince and P Burillo, “Vague Sets are Intuitionistic Fuzzy Sets,” 
Fuzzy Sets andSystems, Vol. 79, pp. 403-405, 1996. 
[3] J. F. Baldwin and S. B. Karake, “Asymmetric Triangular Fuzzy Sets 
for Classification Models,” Lecture Notes in Artificial Intelligence, 
Vol. 2773, pp. 364-370, 2003. 
[4] M. Biglarbegian, W. W. Melek, and J. M. Mendel, “On the Stability of 
Interval Type-2 TSK Fuzzy Logic Control Systems,” IEEE Trans. on 
Systems, Man, and Cybernetics, Part B, Vol. 10, No. 1, in press, 2010. 
[5] Y. C. Chen and C. C. Teng, “A Model Reference Control Structure 
Using a Fuzzy Neural Network,” Fuzzy Sets and Systems, Vol. 73, 
No.3, pp. 291-312, 1995. 
[6] J. R. Castro, O. Castillo, P. Melin, and A. R. Díaz, “A Hybrid Learning 
Algorithm for A Class of Interval Type-2 Fuzzy Neural Networks,” 
Information Sciences, Vol. 179, No. 13, pp. 2175-2193, 2009. 
[7] W. A. Farag, V. H. Quintana, and L. T. Germano, “A Genetic-based 
Neuro-fuzzy Approach for Modeling and Control of Dynamical 
Systems,” IEEE Trans. on Neural Networks, Vol. 9, No. 5, pp. 
756-767, 1998. 
[8] V. G. Gudise and G. K. Venayagamoorthy, “Comparison of Particle 
Swarm Optimization and Backpropagation as Training Algorithm for 
Neural Networks,” IEEE Swarm Intelligence Symp., pp. 110-117, 
April, 2003. 
[9] S. Horikawa, T. Furuhashi, and Y. Uchikawa, “On Fuzzy Modeling 
Using Fuzzy Neural Networks with the Back-propagation 
Algorithm,” IEEE Trans. on Neural Networks, Vol. 3, No. 5, pp. 
801-806, 1992. 
[10] D. H. Kim, “Parameter Tuning of Fuzzy Neural Networks by Immune 
Algorithm,” IEEE Int. Conf. on Fuzzy Systems, Vol. 1, pp. 408-413, 
May, 2002. 
[11] M. S. Kim, C. H. Kim, and J. J. Lee, “Evolutionary Optimization of 
Fuzzy Models with Asymmetric RBF Membership Functions Using 
Simplified Fitness Sharing,” Lecture Notes in Artificial Intelligence, 
Vol. 2715, pp. 628-635, 2003. 
[12] N. N. Karnik, J. Mendel, and Q. Liang, “Type-2 Fuzzy Logic 
Systems,” IEEE Trans. on Fuzzy Systems, Vol. 7, No. 6, pp. 643-658, 
1999. 
[13] C. H. Lee, “Stabilization of Nonlinear Nonminimum Phase Systems: 
An Adaptive Parallel Approach Using Recurrent Fuzzy Neural 
Network,” IEEE Trans. on Systems, Man, Cybernetics- Part: B, Vol. 
34, No. 2, pp. 1075-1088, 2004. 
[14] C. H. Lee and M. H. Chiu, “Adaptive Nonlinear Control Using 
TSK-type Recurrent Fuzzy Neural Network System,” Lecture Notes 
in Computer Science, Vol. 4491, pp. 38-44, 2007. 
[15] C. H. Lee and C. C. Teng, “Identification and Control of Dynamic 
Systems Using Recurrent Fuzzy Neural Networks,” IEEE Trans. on 
Fuzzy Systems, Vol. 8, No. 4, pp. 349-366, 2000. 
[16] C. H. Lee and Y. C. Lin, “An Adaptive Type-2 Fuzzy Neural 
Controller for Nonlinear Uncertain Systems,” Control and Intelligent 
systems, Vol. 12, No. 1, pp. 41-50, 2005. 
[17] C. H. Lee and C. C. Teng, “Fine Tuning of Membership Functions for 
Fuzzy Neural Systems,” Asian Journal of Control, Vol. 3, No. 3, pp. 
216-225, 2001. 
[18] C. H. Lee and H. Y. Pan, “Performance Enhancement for Neural 
Fuzzy Systems Using Asymmetric Membership Functions,” Fuzzy 
Sets and Systems, Vol. 160, No. 7, pp. 949-971, 2009.  
[19] Y. H. Lee and C. H. Lee, “Stable Learning Mechanism for Novel 
Takagi-Sugeno-Kang Type Interval-valued Fuzzy Systems,” Lecture 
Notes in Engineering and Computer Science: Proceedings of The 
International MultiConference of Engineers and Computer Scientists 
2011, IMECS 2011, 16-18 March, 2011, Hong Kong, pp. 1-6.  
[20] C. Li, K. H. Cheng, and J. D. Lee, “Hybrid Learning Neuro-fuzzy 
Approach for Complex Modeling Using Asymmetric Fuzzy Sets,” 
Proc. of the 17th IEEE International Conf. on Tools with Artificial 
Intelligence, pp. 397-401, 2005. 
[21] C. J. Lin and W. H. Ho, “An Asymmetric-similarity-measure-based 
Neural Fuzzy Inference System,” Fuzzy Sets and Systems, Vol. 152, 
pp. 535-551, 2005. 
[22] C. T. Lin and C. S. G. Lee, Neural Fuzzy Systems, Prentice Hall: 
Englewood Cliff, 1996. 
[23] P. Z. Lin and T. T. Lee, “Robust Self-organizing Fuzzy-neural Control 
Using Asymmetric Gaussian Membership Functions,” Int. J. of Fuzzy 
Systems, Vol. 9, No. 2, pp. 77-86, 2007. 
[24] G. Ligntbody and G. W. Irwin, “Nonlinear Control Structures Based 
on Embedded Neural System Models,” IEEE Transactions on Neural 
Networks, Vol. 8, pp. 553-567, 1997. 
[25] J. M. Mendel, Uncertain Rule-Based Fuzzy Logic Systems: 
Introduction and New Directions, Upper Saddle River, Prentice-Hall, 
NJ, 2001. 
[26] T. Ozen and J. M. Garibaldi, “Effect of Type-2 Fuzzy Membership 
Function Shape on Modeling Variation in Human Decision Making,” 
IEEE Int. Conf. on Fuzzy Systems, Vol. 2, pp. 971-976, 2004.  
[27] M. N. H. Siddique and M. O. Tokhi, “Training Neural Networks: 
Backpropagation vs. Genetic Algorithms,” Proc. of Int. J. Conf. on 
Neural Networks, Vol. 4, pp. 2673-2678, 2001. 
[28] K. Salahshoor, A. S. Kamalabady, “On-line Multivariable 
Identification by Adaptive RBF Neural Networks Based on UKF 
Learning Algorithm,” Chinese Control and Decision Conference, 
pp.4754-4759, 2008. 
[29] L. S. Saoud and A. Khellaf, “Nonlinear Dynamic Systems 
Identification Based on Dynamic Wavelet Neural Units,” Neural 
Computing and Applications, Vol. 19, pp. 997-1002, 2010. 
IAENG International Journal of Computer Science, 38:3, IJCS_38_3_09
(Advance online publication: 24 August 2011)
 
______________________________________________________________________________________ 
   
Abstract—In this paper, we propose a novel Takagi-Sugeno- 
Kang type interval-valued neural fuzzy system with asymmetric 
fuzzy membership functions (called TIVNFS-A). In addition, 
the corresponding type reduction procedure is integrated in the 
adaptive network layers to reduce the amount of computation 
in the system. Based on the Lyapunov stability theorem, the 
TIVNFS-A system is trained by the back-propagation (BP) 
algorithm having an optimal learning rate (adaptive learning 
rate) to guarantee the stability and faster convergence. Finally, 
the TIVNFS-A with the optimal BP algorithm is applied in 
nonlinear system identification to demonstrate the effectiveness 
and performance. 
 
Index Terms—interval-valued fuzzy system, Lyapunov 
stability theorem, asymmetric membership function, TSK type, 
nonlinear system  
 
I. INTRODUCTION 
n recent years, fuzzy neural networks (FNNs) are used 
successfully in many applications [5, 7-9, 10, 13-21, 25, 
27-28], such as classifications, prediction, nonlinear system 
and control. FNNs are combined the advantages of fuzzy 
system and neural network. Recently, interval type-2 fuzzy 
logic systems (T2FLSs) have got lots of attention in many 
applications due to their ability to model uncertainties. 
Besides, many literatures have shown that an interval T2FLS 
is the same as an interval-valued fuzzy logic system (IVFLS) 
[1-2, 23, 26]. IVFLSs are more complex than type-1 fuzzy 
logic systems (T1FLSs). IVFLSs have better performance 
than T1FLSs on the applications of function approximation, 
system modeling and control. Combining the advantages of 
IVFLSs and neural network, interval-valued fuzzy neural 
network (IVFNN) systems are presented to handle the system 
uncertainty [6, 16, 18].  
By designing the fuzzy partition and rule engine, 
symmetric and fixed membership functions (MFs), like 
Gaussian or triangular, are usually used to simplify the design 
procedure. Accordingly, a large number of rules should be 
used to accomplish the explicit approximation accuracy [5, 
15, 17]. In order to solve these problems, the asymmetric 
fuzzy MFs (AFMFs) have been adopted [3, 11,  17-20, 24]. 
These results demonstrated that using AFMFs can improve 
 
This work was supported in part by the National Science Council, 
Taiwan, R.O.C., under contracts NSC-97-2221-E-155-033-MY3. 
Ching-Hung Lee is with Department of Electrical Engineering, Yuan-Ze 
University, Chung-li, Taoyuan 320, Taiwan. (phone: +886-3-4638800, ext: 
7119; fax: +886-3-4639355, e-mail: chlee@saturn.yzu.edu.tw). 
the modeling capability. The asymmetric fuzzy MFs provide 
the ability of high flexibility and more accurate [18]. In 
addition, the Takagi-Sugeno-Kang (TSK) type FLSs have the 
universal approximation capability [4]. By the combination 
of these above advantages, the TSK-type interval-valued 
neural fuzzy system with asymmetric membership functions 
(TIVNFS-A) is proposed in this paper. In addition, the 
corresponding type reduction procedure is integrated in the 
adaptive network layers to reduce the amount of computation 
in the system. Therefore, the Karnik-Mendel type-reduction 
procedure is removed. 
For training and designing the neural fuzzy systems, the 
back-propagation algorithm is widely used and a powerful 
training technique [5, 8, 25]. For each training cycle, all 
parameters of neural fuzzy system are adjusted to reduce the 
error between the desired and actual output. Herein, based on 
the Lyapunov stability theorem, the TIVNFS-A system is 
trained by the back-propagation (BP) algorithm having an 
optimal learning rate (adaptive learning rate) to guarantee the 
stability and faster convergence. 
The rest of this paper is as follows. Section II introduces 
the construction of AFMFs and TIVNFSF-A. The back- 
propagation algorithm with the optimal learning rate is 
introduced in Section III. Section IV shows the simulation 
results of nonlinear system identification using TIVNFS-A 
with optimal BP algorithm. Finally, the conclusion is given.  
 
II. TAKAGI-SUGENO-KANG-TYPE INTERVAL-VALUED NEURAL FUZZY 
SYSTEMS  
 In this paper, we propose a TSK-type interval-valued 
neural fuzzy system with asymmetric membership functions 
(TIVNFS-A), which is a modification of type-2 fuzzy neural 
networks (or interval-valued neural fuzzy systems). We 
adopted interval-valued asymmetric MFs and the TSK-type 
consequent part to develop the TIVNFS-A. We first 
introduce the network structure of TIVNFS-A. In general, 
given the system input data xi, , ,,2 ,1 ni L=  and the 
TIVNFS-A’s output yˆ , the jth fuzzy rule can be expressed 
as: 
Rule j: IF x1 is jF1
~  and … and xn is njF
~ , THEN  
Yj=Cj0+Cj1x1+Cj2x2+…+ Cjnxn,         (1) 
where j=1, 2, …, M; Cj0 and Cji are the consequent fuzzy sets, 
Yj is the output of the jth rule (a linear combination operation), 
and ijF
~  is the antecedent fuzzy set. The fuzzy MFs of the 
antecedent part ijF
~  are the asymmetric interval-valued fuzzy 
Stable Learning Mechanism for Novel 
Takagi-Sugeno-Kang Type Interval-valued 
Fuzzy Systems 
Yi-Han Lee    and   Ching-Hung Lee, Member IAENG 
I 
 right-most points. Without operating the iterative procedure 
of KM algorithm described in [12] for finding coefficients R  
and L . Therefore, the TIVNFS-A can reduce the 
computational complexity successfully. 
III. LEARNING OF TIVNFS-A SYSTEMS 
In this paper, we adjust the parameter of TIVNFS-A by the 
back-propagation (BP) algorithm to enhance performance [5, 
8, 15, 25]. The back-propagation algorithm is based on the 
gradient descent method to fine the optimal solution of each 
parameter. 
A. Back-propagation Algorithm 
For clarification, we consider the signal-output system and 
define the error cost function  
2)(
2
1)( kekE = ,                              (11) 
where ),()()(ˆ)()( )6( kOkykykyke dd −=−= that )(ˆ ky  and 
)(kyd  are the TIVNFS-A’s output and desired output for 
discrete time k, respectively. Using the gradient descent 
method, the parameters updated law of the parameters is 
,)()()1( ⎟⎠
⎞⎜⎝
⎛
∂
∂−+=+
W
WW kEkk η                 (12) 
where η  is the learning rate. [ ]TCWWWW  , , , , ωγ=  are the 
adjustable parameters, where C  is the parameters of TSK 
layer, ωW  is the consequent weights, W  is the parameters 
of lower MFs, W  is upper MFs parameters, and γ  is the 
column vectors, i.e., 
[ ]
[ ]
[ ]
[ ] .
, 
,
,
Trlrl
Trlrl
Trlrl
T
mm
mm
sc
σσ
σσ
ωωωωω
=
=
=
=
W
W
W
C
                  (13) 
Considering W∂∂ )(kE , we have 
,)(
ˆ
)()(
ˆ
)(ˆ
)(
)(
)()(
WWW ∂
∂−=∂
∂
∂
∂
∂
∂=∂
∂ kykeky
ky
ke
ke
kEkE         (14) 
thus,  
,)()()(
)(ˆ)()()1(
)6(
W
W
W
WW
∂
∂⋅⋅+=
∂
∂⋅⋅+=+
kOkek
kykekk
η
η
                 (15) 
where ).(ˆ)()( kykyke d −=  The remaining work involves 
finding the corresponding partial derivative with respect to 
each parameter. For the BP algorithm, the remaining works 
are the derivations of gradient for parameters ωγ WWW  , , , , 
and C. The derivations are omitted due to the writing space. 
Similar details can be found in literature [18]. 
 
B. Optimal Learning Rate 
The learning rate plays an important role in BP algorithm. 
A small value of learning rate leads the speed of convergence 
will be slower. The large value of learning rate leads the 
speed of convergence is faster but it might produce local 
minimum. Hence, the selection of the learning rate is 
importantly but it is not easy to choosing suitably. Thus, we 
use the Lyapunove function to find the optimal learning rate 
[5, 15, 29]. At first, we defined the positive Lyapunov 
candidate 
)(
2
1)()( 2 kekEkV == .                          (16) 
In general, )()()1( kekeke Δ=−+ . Thus, we have 
[ ]
( )[ ]
[ ], )()(2)(
2
1
)()(2)(
2
1
))()1(())()1((
2
1
)()1()(
2 kekeke
kekeke
kekekeke
kVkVkV
Δ⋅+Δ=
Δ+⋅Δ=
++⋅−+=
−+=Δ
        (17) 
where WW Δ∂∂≈Δ )()( eke ,thus, according to the 
parameter update rule of BP algorithm, )( WW ∂∂−=Δ Eη . 
And we can obtain  
⎟⎠
⎞⎜⎝
⎛
∂
∂⋅⋅−=⎟⎠
⎞⎜⎝
⎛
∂
∂−∂
∂≈Δ
WWW
ykeEeke
ˆ
)()( ηη .           (18) 
Thus, 
. 
ˆ
2
ˆ
2
1
ˆˆ
2
2
1)(
22
2
4
22
2
2
⎥⎥⎦
⎤
⎢⎢⎣
⎡ ⎟⎠
⎞⎜⎝
⎛
∂
∂⋅−⎟⎠
⎞⎜⎝
⎛
∂
∂⋅⋅−=
⎥⎥⎦
⎤
⎢⎢⎣
⎡ ⎟⎠
⎞⎜⎝
⎛
∂
∂⋅⋅+⎟⎠
⎞⎜⎝
⎛
∂
∂⋅⋅−=Δ
WW
WW
yye
yeyekV
ηη
ηη
    (19) 
Next, according to the Lyapunov stability theory, we should 
choose a proper value of η  such that 0)( ≤Δ kV . Therefore, 
we can obtain the stability condition for learning rate 
2
ˆ
0
2
<⎟⎠
⎞⎜⎝
⎛
∂
∂<
W
yη .                          (20)  
Define  
2ˆ ⎟⎠
⎞⎜⎝
⎛
∂
∂⋅=
W
yηλ  and rewrite (19) as 
( ) .02)()( ≤+−⋅⋅=Δ λλkVkV                   (21) 
Then we have ( ) 02)()()1( ≤+−⋅⋅=−+ λλkVkVkV      (22) 
and  ( ) .021)()1( 2 ≤+−⋅=+ λλkVkV                (23) 
Thus, the optimal learning rate η  can be obtained 
2
* ˆ
−
⎟⎠
⎞⎜⎝
⎛
∂
∂=
W
yη                            (24) 
such that λ=1. Note that W∈ℜD, where D is the dimension of 
the problem. Therefore, the choice of optimal learning rate 
guaranteed the faster convergence is 
2
* ˆ1
−
⎟⎠
⎞⎜⎝
⎛
∂
∂=
W
y
D
η .                            (25) 
The optimal learning of TIVNFS-A’s parameters are as 
follows. 
 
 
 
 
 ⎪⎪
⎪⎪
⎩
⎪⎪
⎪⎪
⎨
⎧
<≤
+
+
<≤−
<≤
<<
=
.1000507
)
10
sin(6.0      
)
32
sin(1.0)
25
sin(3.0
,7500050.1
,5005020.1
,2500)
25
sin(
)(
k
k
kk
k
k
kk
ku
π
ππ
π
(40) 
The following RMSE is adopted to be the performance index 
2/12 )/)((: ∑
k
NkeRMSE  ,                     (41) 
where N is the number of training pattern. 
The parameters of TIVNFS-A are  , , ,, ,, llrrll mmmm σσ  
scrr  , , , , , , ωωγσσ  that are chosen randomly between [-1, 
1]. The numbers of the TIVNFS-A’s rule is set to be 2, then 
the structure of TIVNFS-A is 2-4-2-4-2-1, and the numbers 
of parameter of TIVNFS-A is 56. 
Figures 4 and 5 show the results of nonlinear system 
identification after 50 epochs training and testing, 
respectively (solid line: actual output; dashed line: 
TIVNFS-A’s output). The convergence of RMSE is shown in 
Fig. 6.  
 
 
Fig. 4. Training results of nonlinear system identification. 
 
 
Fig. 5. Testing results of nonlinear system identification. 
 
Fig. 6. The values of RMSE after training. 
 
Illustration Comparison of the Optimal Learning Rate: 
Figure 7 and TABLE I show the comparison results between 
the TIVNFS-A system using the optimal learning rate *η  and 
fixed learning rate η.  Obviously, we obtain the performance 
of BP algorithm with optimal learning rate is better than 
without optimal learning rate. The average RMSE of BP 
algorithm with *η  was 0.002377 and The average RMSE of  
BP algorithm with optimal learning rate was 0.003203. Thus, 
the performance is more stable with optimal learning from 
the best and the worst value of RMSE. 
 
 
Fig. 7. The values of RMSE of  BP algorithm with optimal learning rate and 
without optimal learning rate. 
 
TABLE I 
THE COMPARISON RESULTS IN 10 TIMES OF DIFFERENT LEARNING RATE 
 BP algorithm with optimal learning rate 
BP algorithm with fixed 
learning rate 
Best 0.001671 0.001696 
Average 0.002377 0.003203 
Worst 0.003458 0.006690 
Times(sec) 21.904 15.808 
 
Illustration Comparison of TIVNFS-A system: In this 
comparison, we discuss the performance of TIVNFS-A and 
RFNN. Figure 8 shows the result of the values of RMSE after 
training with TIVNFS-A and RFNN. The RMSE of 
TIVNFS-A is better than RFNN at last epoch. In addition, the 
convergent speed of TIVNFS-A is also faster than using 
RFNN. TABLE II shows the best average and worst RMSE 
of TIVNFS-A and RFNN after training. According to the 
results, the performance of identification by TIVNFS-A is 
  
 
  
Abstract—In this paper, we propose a novel SPSA-based 
on-line adaptive decoupled control scheme by using PID neural 
network for a class of nonlinear systems. In addition, the update 
laws of parameters with adaptive optimal learning rate are 
proposed based on the Lyapunov stability theorem, this 
guarantees the stability of closed-loop system. In addition, the 
affect of the frictional force model and uncertainty are 
discussed and analyzes. The proposed approach is applied in the 
translational oscillations with a rotational actuator (TORA) 
system. In experimental results, the proposed control is realized 
by DSP to demonstrate the performance and the efficiency. 
Index Terms—adaptive control, PID neural network, 
simultaneous perturbation stochastic approximation, real-time 
control. 
I.   INTRODUCTION 
ECENTLY, intelligent control systems using fuzzy 
logic system and neural networks are widely applied 
for particular systems [2, 11-12, 14, 17]. The neural networks 
are used to approximate the complicated mathematical 
function of nonlinear systems when the physical 
mathematical model is not exactly known. For the training of 
neural networks, there are many optimization problems 
which only the measurement of the objective function is 
available. To develop the neural-network-based controller, 
the corresponding adaptive laws should be derived by the 
measurement of objective function. Many approaches were 
introduced to train the neural networks [5, 9, 11-12, 14-15, 
17-18]. However, the usually used methods are gradient 
descent method and Lyapunov approach. However, it is 
difficult to obtain the system’s gradient information exactly. 
Therefore, the simultaneous perturbation stochastic 
approximation (SPSA) is proposed to solve these problems 
[23, 27-29]. By using SPSA, we can only measure the 
objective function to solve the optimization problem for 
providing the adaptive laws of neural networks.  
In this paper, we propose a novel SPSA-based on-line 
adaptive decoupled control scheme by using PID neural 
network for a class of nonlinear systems. The sliding-mode 
 
This work was supported in part by the National Science Council, 
Taiwan, R.O.C., under contracts NSC-97-2221-E-155-033-MY3. 
Ching-Hung Lee is with Department of Electrical Engineering, Yuan-Ze 
University, Chung-li, Taoyuan 320, Taiwan. (phone: +886-3-4638800, ext: 
7119; fax: +886-3-4639355, e-mail: chlee@saturn.yzu.edu.tw).  
control (SMC) has been suggested as an approach for the 
control of systems with nonlinearities, uncertain dynamics 
and bounded input disturbances [1-2, 7-10, 21, 22, 24]. The 
SMC-based decoupled architecture is adopted for 
simplifying the computational complexity. The weights of 
the PID NN are updated according to the results of SPSA 
algorithm for the purpose of controlling the system states to 
stay in sliding surface. By using the SPSA update laws, we 
can adjust the PID neural network’s parameters to achieve 
the stability of closed-loop system. The proposed approach is 
applied in the translational oscillations with a rotational 
actuator (TORA) system. In experimental results, the 
proposed control is realized by DSP to demonstrate the 
performance and the efficiency. 
This paper is organized as follows. Section II introduces 
the problem formulations and PID neural networks. The 
proposed on-line adaptive decoupled control scheme is 
introduced in Section III. Experimental results of TORA 
system are shown in Section IV. Finally, the conclusion is 
given.  
 
II. PRELIMINARIES 
A. Problem Formulation 
Consider the following nonlinear coupled system 
  
( ) ( ) ,1111
1312
1211
dugfx
xx
xx
n +⋅+=
=
=
XX&
M
&
&
 
( ) ( ) ,2222
2322
2221
dugfx
xx
xx
n +⋅+=
=
=
XX&
M
&
&
   
    2211 , xyxy ==                                                              (1) 
where nTnnTTT xxxxxx 21212121
1
11111121 ] ...  ... [][ ℜ∈== −− &&XXX is 
system state variable and ℜ∈21 , yy  are system output. ( ) ( ) ,, ℜ∈XX ii gf i=1,2, which satisfy ( ) 0, ≠Xig  ,0≠∀X  
.0≥t  u is the control input, and d1(t), d2(t), are external 
bounded disturbances, i.e., |d1(t)|≤D1, |d2(t)|≤D2.  
Control objective: In this paper, an adaptive decoupled 
PID neural network controller is proposed to treat the 
tracking control problem of system (1), that is the proposed 
controller generates proper control signal such that the 
system output y1 and y2 follows the continuous bounded 
desired trajectories yr1 and yr2, respectively. Note that the 
desired trajectories yr1, yr2∈Cn-1, i.e., the (n-1)th order 
derivative exist. Thus, we define 
Adaptive Neural Network Controller Design 
for a Class of Nonlinear Systems Using SPSA 
Algorithm 
Ching-Hung Lee, Member, IAENG, Tsung-Min Yu, and Jen-Chieh Chien 
R 
  
 
the PID neural network based decoupled adaptive control 
scheme using  SPSA algorithm. The inputs of PID neural 
network are s1 and the output is the control signal for 
nonlinear system.  
Our control goal is to minimize the following cost 
function: 
)(
2
1)( 21 kskE = .                          (9) 
By the gradient-descent method, the update laws of ith 
PIDNN’s parameters are 
⎥⎥
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎢
⎣
⎡
∂
∂
∂
∂
∂
∂
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
−
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
+
+
+
D
I
p
D
I
P
D
I
p
D
I
p
k
kE
k
kE
k
kE
ka
ka
ka
kk
kk
kk
kk
kk
kk
)(
)(
)(
)(00
0)(0
00)(
)(
)(
)(
)1(
)1(
)1(
 (10) 
where aP(k), aI(k), aD(k) are adaptive time varying learning 
step length. Herein, we use the SPSA algorithm to 
approximate the gradients of 
pk
kE
∂
∂ )( ,
Ik
kE
∂
∂ )( ,
Dk
kE
∂
∂ )( , thus 
⎥⎥
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎢
⎣
⎡
Δ⋅
−
Δ⋅
−
Δ⋅
−
=
⎥⎥
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎢
⎣
⎡
Δ⋅
+−+
Δ⋅
+−+
Δ⋅
+−+
≈
⎥⎥
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎢
⎣
⎡
∂
∂
∂
∂
∂
∂
Δ
Δ
Δ
Δ
Δ
Δ
Δ
Δ
Δ
Δ
Δ
Δ
)()(
))(())((
)()(
))(())((
)()(
))(())((
)()(
)1()1(
)()(
)1()1(
)()(
)1()1(
)(
)(
)(
kkc
kEkE
kkc
kEkE
kkc
kEkE
kkc
kEkE
kkc
kEkE
kkc
kEkE
k
kE
k
kE
k
kE
D
I
p
D
I
p
D
I
p
WW
WW
WW
                                                                                          (11) 
where TDIp kkkkkkk ])(  )(   )([)( =W , )([)( kkk p=ΔW  
)()()( kkkkc IpΔ⋅+ Δ )()(   )()( kckkkkc DI ΔΔ +Δ⋅+ T])(kDΔ⋅  
, ℜ∈Δ )(kc  is perturbation that between 0 and 1. )(kPΔ , 
)(kIΔ , )(kDΔ  are perturbation ones whose elements are 
either 1 or -1 in random. 
From equations (10) and (11), the update laws of kp(k), 
kI(k), kD(k) are represented as 
)()(
)()()(
)()(
)()()(                 
))](([)()()()1(
11
11
kkc
kskkc
kkc
kskkc
kgkskakkkk
p
D
p
I
PPP
Δ⋅
Δ⋅+⎢⎢⎣
⎡
Δ⋅
⋅Δ⋅⋅
⋅⋅−=+
Δ
Δ
Δ
Δ
X
  
)()(
)]2()1(2)[()( 11
kkc
kskskkc
p
D
Δ⋅
−+−−Δ⋅+
Δ
Δ         
⎥⎦
⎤
Δ⋅
−−Δ⋅+
Δ
Δ
)()(
)]1()()[()( 11
kkc
kskskkc
P
P                    (12)  
)()(
)()()(
)()(
)()()(                 
))](([)()()()1(
11
11
kkc
kskkc
kkc
kskkc
kgkskakkkk
I
D
I
I
III
Δ⋅
Δ⋅+⎢⎣
⎡
Δ⋅
⋅Δ⋅⋅
⋅⋅−=+
Δ
Δ
Δ
Δ
X
  
)()(
)]2()1(2)[()( 11
kkc
kskskkc
I
D
Δ⋅
−+−−Δ⋅+
Δ
Δ         
⎥⎦
⎤
Δ⋅
−−Δ⋅+
Δ
Δ
)()(
)]1()()[()( 11
kkc
kskskkc
I
P                    (13)  
)()(
)()()(
)()(
)()()(                 
))](([)()()()1(
11
11
kkc
kskkc
kkc
kskkc
kgkskakkkk
D
D
D
I
DDD
Δ⋅
Δ⋅+⎢⎣
⎡
Δ⋅
⋅Δ⋅⋅
⋅⋅−=+
Δ
Δ
Δ
Δ
X
  
)()(
)]2()1(2)[()( 11
kkc
kskskkc
D
D
Δ⋅
−+−−Δ⋅+
Δ
Δ         
⎥⎦
⎤
Δ⋅
−−Δ⋅+
Δ
Δ
)()(
)]1()()[()( 11
kkc
kskskkc
D
P .                   (14)  
B. Stability analysis 
Herein, we develop the convergence theorem for selecting 
appropriate learning step length a(k). The choice of learning 
step length is very important for convergence. If a small 
value is given for the learning step length, the convergence of 
the closed-loop system is guaranteed. However, the 
convergent speed may be very slow. On the other hand, if a 
large value is given, the system may be unstable. Hence, we 
employ the Lyapunov stability analysis approach to have the 
condition for convergence and find the optimal learning step 
length. We have the following theorem for control scheme. 
Theorem 1. Let aP(k), aI(k), aD(k) be adaptive learning 
step length for PID neural network tuning parameters. 
Consider the nonlinear control problem (shown in Fig. 3), the 
asymptotic convergence of the closed-loop system is 
guarantee if the learning step length is chosen satisfying  
2)(
2)(0
kg
ka << , for all k           (15) 
where  
)(
))(())()()(())(( 11
kc
kWskkckWskWg −Δ+=  
 [ ]Tp k)(  ...  (k)  (k) 11211 −−− ΔΔΔ⋅  
is the gradient estimation using SPSA approach. In addition, 
the faster convergence can be obtained by using the 
following optimal time-varying learning step length 
 ( ) ( ) )])()1-(-)(3[
1 ,1min()(
2
111 kgksks
kaP X
=  
( ) )])()(3[
1 ,1min( )(
2
11 kgks
kaI X
=                                  (16)  
( ) ( ) )])()2-()1-(2-)(3[
1 ,1min( )(
2
1111 kgksksks
kaD X+=  
Proof: The proof is omitted due to the writing space.  
 
 
Fig. 4. TORA system. 
  
 
 
Figure 6 shows the simulation results when the system 
having frictional force. We can observe that the proposed 
approach has the better performance in convergence. The 
corresponding control effort is shown in Fig. 7. Figure 7(b) 
shows the control effort between 0~1 sec. It is also found that 
the proposed approach has more reasonable control effort 
than other literature [6, 16]. Figure 8 shows the simulation 
results of our approach using difference fixed learning step 
length and adaptive step length (16). Also, we find that the 
proposed adaptive learning step length performs well by 
using SPSA.  
 
0 1 2 3 4 5 6 7 8 9 10
-0.15
-0.1
-0.05
0
0.05
0.1
0.15
time(sec)
θ
System Response
 
 
0 1 2 3 4 5 6 7 8 9 10
-0.01
-0.005
0
0.005
0.01
time(sec)
x c
System Response
 
 
desired output
adaptive PID-BP
DNNSMC
Our approach
adaptive PID-BP
DNNSMC
Our approach
 
Fig. 9. Comparison results of oscillation control (dotted: PID-BP [16]; 
dashed: DNN SMC [6]; solid: our approach). 
0 1 2 3 4 5 6 7 8 9 10
-10
-5
0
5
time(sec)
u
Control Effort
 
 
0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2
-10
-5
0
5
10
time(sec)
u
Control Effort
 
 adaptive PID-BP
DNNSMC
Our approach
adaptive PID-BP
DNNSMC
Our approach
 
Fig. 10. Comparison results in control effort of oscillation control (dotted: 
PID-BP [16]; dashed: DNN SMC [6]; solid: our approach). 
 
Case2: Oscillation Control Illustration (system having 
frictional force) 
In addition, we use the following illustrated examples, 
oscillation control problem, to show that the controller can 
reduce the influence of uncertainty. These are used to 
demonstrate the effectiveness and ability of the proposed 
control scheme. The initial conditions of the following 
oscillation control are selected as ( ) 00 =Cx [m], 
( ) 00 =Cx& [m/s], 0(0) =θ [deg] and ( ) 00 =θ& [deg/s], and the 
desired trajectory is derived from the oscillation frequency, 
i.e., ).1510sin(0050 t.xcd = . The Oscillation control case is 
considered.  
As above, Fig. 9 shows the simulation results when the 
system having frictional force. We can observe that the 
proposed approach has the better performance in 
convergence. The corresponding control effort is shown in 
Fig. 10, Fig. 10(b) is control effort between 0 to 1 sec. It is 
also found that the proposed approach has more reasonable 
control effort than other literature [6, 16]. Figure 11 shows 
the simulation results of our approach using difference fixed 
learning step length and adaptive step length (16). Also, we 
find that the proposed adaptive learning step length performs 
well by using  SPSA. 
 
0 1 2 3 4 5 6 7 8 9 10
-0.5
0
0.5
time(sec)
θ
 
 
0 1 2 3 4 5 6 7 8 9 10
-0.02
0
0.02
0.04
time(sec)
x c
 
 
desired output
η=1.2
η=0.01
Our approach
0 1 2 3 4 5 6 7 8 9 10
-10
0
10
time(sec)
u
 
 
desired
η=1.2
η=0.01
Our approach
η=1.2
η=0.01
Our approach
 
Fig. 11. Comparison results of oscillation control case using difference 
learning step lengths (dashed: fixed value 1.2; dotted: fixed value: 0.01; solid: 
our approach in equation (16)). 
 
 
Fig. 12. DSP-based control platform for the TORA system. 
Experimental Results of TORA System using DSP-based 
Control Scheme 
The experimental equipment block diagram of the 
DSP-based control system f or the TORA system are 
depicted in Fig. 12.  Figure 13 shows the experimental result 
of stability problem. The proposed approach has good 
performance (converge to zero in small stabilizing time) in 
experimental equipment. Figure 14 shows the state 
trajectories of our approach with fixed learning step length 
and adaptive step length (16). This result illustrates the 
effectiveness and ability of the adaptive learning step length.  
 
0 0.5 1 1.5 2 2.5 3
-0.1
0
0.1
time(sec)
x c
0 0.5 1 1.5 2 2.5 3
-50
0
50
time(sec)
u
0 0.5 1 1.5 2 2.5 3
-0.2
0
0.2
time(sec)
θ
 
Fig. 13. Experimental result of our approach.  
   
Abstract— This paper presents a novel differential evolution 
algorithm (called CCDE) using self-adaptive scaling factors, 
chemotaxis by BP technique, and cooperative strategy to 
enhance the performance of traditional DE algorithm. The 
CCDE consists of modified mutation strategy which is 
implemented from each individual and includes the momentum 
of each individual, the self-adaptive scaling factor strategy 
which adopts the fuzzy logic system to improve  convergence 
speed, the chemotaxis by BP technique, and optimal learning 
rate which enhances the local search ability and convergence. 
The cooperative strategy could generate extra vectors to search 
the solution. Finally, the CCDE algorithm is demonstrated by a 
comparative study on function optimization. 
 
Index Terms—Optimization, Differential evolution, 
Chemotaxis, Cooperative Strategy, back-propagation  
 
I. INTRODUCTION 
N the past decades, many investigators have proposed 
many effective approaches to solve the optimization 
problem, such as genetic algorithm, electromagnetism-like 
algorithm, particle swarm optimization, etc [2, 4-5, 8, 14]. 
Evolutionary algorithms (EAs) have received attention for 
their potential as global optimization techniques [3, 10, 13]. 
As a method of solving optimization problems, a powerful 
stochastic global optimization differential evolution (DE) 
algorithm was proposed [15-16]. DE utilizes mutation and 
recombination operations as searching mechanisms and 
selection operators to determine the most promising regions 
of the search space. It creates new candidate solutions by 
combining the parent individual and several other individuals 
by randomly choosing from the same population. A 
candidate replaces the parent only if it has a better fitness 
value. This is a rather greedy selection scheme that often 
outperforms traditional EAs [3, 10]. 
Although the DE algorithm benefits from the 
aforementioned advantages, the DE convergence velocity is 
slow for high dimensional optimization problems. In addition, 
DE is sensitive to algorithm parameters, such as low 
precision, and it cannot easily determine the global optimal 
solution if these parameters are not properly met. Therefore, 
 
This work was supported in part by the National Science Council, 
Taiwan, R.O.C., under contracts NSC-97-2221-E-155-033-MY3. 
Ching-Hung Lee is with Department of Electrical Engineering, Yuan-Ze 
University, Chung-li, Taoyuan 320, Taiwan. (phone: +886-3-4638800, ext: 
7119; fax: +886-3-4639355, e-mail: chlee@saturn.yzu.edu.tw). 
the selection of the scaling factor F, and CR is very important 
and difficult. In our experience, the larger value of F can 
converge quickly, but usually at a local minimum. Inversely, 
small value of F converges slowly. In literature [19], F was 
selected by experienced human operators.  
In order to improve the performance of DE algorithm, this 
paper proposes a DE algorithm (called CCDE algorithm) 
with novel strategies, includes the modified mutation strategy, 
the self-adaptive scaling factor using fuzzy logic system, 
chemotaxis by BP technique with adaptive learning rates, and 
the simple cooperative strategy. The modified mutation 
strategy consists of a mutation strategy of traditional DE, the 
best information, and the momentum term. In addition, the 
momentum term provides the past information, which 
advances the ability of searching the optimal solution. The 
adaptive scaling factor F is established by fuzzy logic 
systems. The generation number and change of fitness value 
are used to generate changes in F using a fuzzy approach. 
Subsequently, the chemotaxis by BP technique supplies the 
algorithm with the searching ability in the neighborhood. In 
addition, the concept of the chemotaxis is derived from the 
bacterial foraging algorithm [6, 17]. In the neutral medium, if 
the bacterium swims up a nutrient gradient, its behavior seeks 
increasingly favorable environments. We adopt the 
chemotaxis concept for our CCDE algorithm. Many 
literatures [1, 11-12] indicate that the cooperative strategy 
lead to a significant improvement in performance.  
This paper is organized as follows. Section II introduces 
the proposed novel hybrid differential evolution algorithm 
CCDE. The experimental results of function optimization are 
introduced in Section III. Finally, the conclusion is given.  
 
II. A NOVEL HYBRID DIFFERENTIAL EVOLUTION 
ALGORITHM- CCDE 
This section introduces the proposed novel hybrid 
differential evolution algorithm CCDE. Figure 1 shows the 
flowchart of the CCDE algorithm. The CCDE algorithm is 
proposed by using (a) the modified mutation strategy which 
is implemented from each individual and includes the 
momentum of each individual; (b) the chemotaxis by BP 
technique with the optimal learning rates to search the better 
situation in the neighborhood; (c) the simple cooperative 
strategy to generation extra vectors for searching the solution; 
and (d) self-adaptive scaling factors to improve the 
performance. The CCDE algorithm would improve the 
precision, and enhance the convergence speed. Firstly, the 
optimization problem is formula as   
A Novel Hybrid Differential Evolution 
Algorithm: A Comparative Study on Function 
Optimization 
Ching-Hung Lee, Member, IAENG, Pei-Yuan Chung, and Hao-Han Chang 
I 
 The scaling factors F1, F2, and F3 are also adjusted by 
fuzzy logic systems, the inputs of the fuzzy system are 
changes of fitness value, Δe, and generation number, g, and 
the corresponding outputs are 321  and  , βββ . The adjustment 
is shown as follows: 
.3 ,2 ,1    , =×= iFF iii β                 (2)                
The 3×3 fuzzy rules table are described in Table I. The 
corresponding membership functions for inputs Δe, 
generation, and output 321  and , , βββ  are shown in Fig. 2. (a), 
2(b), and 2(c), respectively. The consequence 321  and , , βββ  
is deduced from Δe and generation by taking the max-min 
composition. The center of area (COA) method is used as the 
defuzzification strategy. Figure 3 shows the corresponding 
surface of 321  and , , βββ . The fuzzy system is constructed 
by the following IF-THEN rules 
IF eΔ  is Zero and generation is Small,  
THEN 321  and , , βββ  are Increasing. 
IF eΔ  is Small and generation is Small,  
THEN 321  and , , βββ  are Increasing. 
IF eΔ  is Big and generation is Small,  
THEN 321  and , , βββ  are Fixing. 
IF eΔ  is Zero and generation is Medium,  
THEN 321  and , , βββ  are Increasing. 
IF eΔ  is Small and generation is Medium,  
THEN 321  and , , βββ  are Fixing. 
IF eΔ  is Big and generation is Medium,  
THEN 321  and , , βββ  are Decreasing. 
IF eΔ  is Zero and generation is Big,  
THEN 321  and , , βββ  are Fixing. 
IF eΔ  is Small and generation is Big,  
THEN 321  and , , βββ  are Decreasing. 
IF eΔ  is Big and generation is Big,  
THEN 321  and , , βββ  are Decreasing. 
 
B. Chemotaxis By Back-propagation Technique 
The idea of the chemotaxis by BP technique is deduced 
from bacterial foraging algorithm [6, 17]. Bacterial foraging 
algorithm is inspired by the pattern exhibited by bacterial 
foraging behaviors. Bacteria have the tendency to gather in 
the nutrient-rich areas by an activity called “chemotaxis”. If a 
bacterium finds a favorable environment, it searches a better 
situation until it cannot find any more. We adopt this concept 
and BP technique to search the optimal solution in the 
neighborhood.  
The update law of trial vector )1( +′ gvp  is represented as  
,
)1(
))1((
)()1(                  
)1()1()1(
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+∂
+∂−++=
+Δ++=+′
gv
gvE
ggv
gvgvgv
pd
p
dpd
pdpdpd
η     (3) 
where Dd ,...,2,1=  and )(gdη  is the learning rate. After we 
get the trial vector )1( +′ gvp , the fitness value of the trial 
vector ))1(( +′ gvf p  is compared with the fitness value of the 
parent vector ))(( gf pΘ . If the trial vector )1( +′ gvp  is better 
than the parent vector )(gpΘ , the trial vector )1( +′ gvp  is 
going to get into the chemotaxis procedure. Otherwise, the 
trial vector )1( +′ gvp  becomes the parent vector )(gpΘ , and 
skip the chemotaxis procedure. The update is expressed as 
follows: 
⎪⎩
⎪⎨
⎧
Θ
Θ<+′+′=+′
otherwise.         )(
))(())1(( if       )1(
)1(
g
gfgvfgv
gv
p
ppp
p  (4) 
We implement the back-propagation algorithm to get the 
chemotaxis vector )1( +′′ gvp , which is denoted as 
,
)1(
))1((
)()1(                  
)1()1()1(
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+′∂
+′∂−++′=
+′Δ++′=+′′
gv
gvE
ggv
gvgvgv
pd
p
dpd
pdpdpd
η    (5) 
where Dd ,...,2,1= . After we get the chemotaxis vector 
)1( +′′ gvp , the fitness value of the chemotaxis vector 
))1(( +′′ gvf p  is compared with the fitness value of the trial 
vector ))1('( +gvf p . If the chemotaxis vector )1( +′′ gvp  is 
better than the trial vector )1( +′ gvp , the chemotaxis vector 
)1( +′′ gvp  replaces the trial vector )1( +′ gvp . Repeat the 
chemotaxis procedure until the chemotaxis vector )1( +′′ gvp  
is not better than the trial vector )1( +′ gvp . The update is 
expressed as follows: 
⎪⎩
⎪⎨⎧ +′
+′<+′′+′′=+′
otherwise.  )1(
))1(())1(( if   )1(
)1(
gv
gvfgvfgv
gv
p
ppp
p (6) 
Moreover, the learning rates play an important role in the 
chemotaxis by BP technique. If the proper learning rates are 
chosen, the convergence is guaranteed. According to the 
literature [7], we can obtained the optimal learning rate from 
the Lyapunov stability analysis is  
            ( ) ( )( )
( )
2
* 11
⎟⎟⎠
⎞
⎜⎜⎝
⎛
′∂
′∂
=+
gv
gvE
D
g
pd
p
η                   (7) 
where D is the dimension. 
 
C. The Simple Cooperative Strategy  
Although competition among individual vectors usually 
improves their performance, much greater improvements can 
be obtained through cooperation. Many researchers apply the 
cooperative approach to improve their algorithm. Various 
cooperative approaches have been proposed and analyzed.  
A typical example is the cooperative co-evolutionary 
genetic algorithm which is proposed [12]. The cooperative 
strategy is that the solution vector is split into its constituent 
components and assigned to multiple populations [1]. In this 
configuration, each population is then optimized a single 
component of the solution vector (i.e. a one-dimensional 
optimization problem). We adopt the spirit of cooperative 
strategy into CCDE algorithm. 
The simple cooperative strategy in CCDE algorithm is to 
generate extra individuals by the populations. On the other 
hand, the solution vector is split into populations areas. Now, 
we obtain Ps copies of the solution vector. The Ps jth in jth 
copy are replaced with the Ps jth in the parent )(gpΘ  
 B. Illustration Discussions  
To illustrate the performance and effectiveness of CCDE, 
several comparative experiments are shown to demonstrate 
the ability and advantages of the adopted modified strategies, 
e.g., chemotaxis by BP technique, self-adapting scaling 
factor, cooperative strategy, BP’s optimal learning. In order 
to make the comparison on fair, the populations for all 
algorithm comparsion variants were initialized using same 
random seeds, population size is 50, maximum number of 
generation is 20, F1=0.5, F2=0.5, F3=0.5 and CR=0.5,the 
average results of 30 independent runs in Table III. Some 
observations are found from Table III. From each column 
values of Table III (optimization results of twenty functions), 
we can observe that the CCDE’s results have better accuracy 
compared with the results using CCDE without using 
chemotaxis by BP technique, self-adapting scaling factor, 
cooperative strategy, and BP’s optimal learning, respectively. 
Thus, we could conclude that the chemotaxis by BP 
technique, self-adapting scaling factor, cooperative strategy, 
and BP’s optimal learning can improve the ability of 
optimization searching.   
 
IV. CONCLUSION 
The CCDE algorithm adopts the modified mutation 
strategy to increase the diversity. The modified mutation 
strategy also provides a correct direction to the optimal 
solution by the momentum term and the best individual 
which is updated instantly. The self-adaptive scaling factor 
strategy improvement could increase the precision and 
convergence velocity. The chemotaxis by BP technique 
supplies the capability of searching in the neighborhood. In 
addition, we use the optimal learning rates to improve the 
ability of convergence. The simple cooperative strategy 
provides the capability of searching optimal solution by 
replacing the parameters of one population of the trial vector 
with the parameters of the same population of the parent 
vector. Therefore, CCDE algorithm has the ability of global 
optimization, advantages of faster convergent speed and 
higher precision. Experimental results of function 
optimization are shown to demonstrate the effectiveness of 
the proposed CCDE.  
REFERENCES 
 
[1] F. Bergh and A. P. Engelbrecht, “A Cooperative Approach to Particle 
Swarm Optimization,” IEEE Trans. on Evolutionary Computation, Vol. 
8, No. 3, pp. 225-239, June, 2004. 
[2] M. Clerc and J. Kenney, “The Particle Swarm-explosion, Staility, and 
Convergence in A Multidimensional Complex Space,” IEEE Trans. on 
Evolutionary Computation, Vol. 6, No. 1, pp. 58-73, 2002. 
[3] W. A. Farag, V. H. Quintana, and L. T. Germano, “A Genetic-based 
Neuro-fuzzy Approach for Modeling and Control of Dynamical 
Systems,” IEEE Trans. on Neural Networks, Vol. 9, No. 5, pp. 756-767, 
1998. 
[4] D. E. Goldberg, Genetic Algorithms in Search, Optimization and 
Machine Learning, Addison-Wesley, Reading, 1989. 
[5] V. G. Gudise and G. K. Venayagamoorthy, “Comparison of Particle 
Swarm Optimization and Backpropagation as Training Algorithm for 
Neural Network,” IEEE Swarm Intelligence Symp., pp. 110-117, April, 
2003. 
[6] C. F. Juang, “A Hybrid of Genetic Algorithm and Particle Swarm 
Optimization for Recurrent Network Design,” IEEE Trans. on Systems, 
Man, Cybernetics- Part: B, Vol. 34, No. 2, pp. 997-1006, 2004. 
[7] D. H. Kim, A. Abraham, and J. H. Cho, “A Hybrid Genetic Algorithm 
and Bacterial Foraging Approach for Global Optimization,” 
Information Sciences, Vol. 177, No. 18, pp. 3918-3937, 15 Sep, 2007. 
[8] C. H. Lee and M. H. Chiu, “Adaptive Nonlinear Control Using 
TSK-type Recurrent Fuzzy Neural Network System,” Lecture Notes in 
Computer Science, Vol. 4491, pp. 38-44, 2007. 
[9] C. H. Lee and F. K. Chang, “Recurrent Fuzzy Neural Controller Design 
for Nonlinear Systems Using Electromagnetism-like Algorithm,” Far 
East Journal of Experimental and Theoretical Artificial Intelligence, 
Vol. 1, No. 1, pp. 5-22, 2008. 
[10] C. Y. Lee and X. Yao, “Evolutionary programming using mutations 
based on the Lévy probability distribution,” IEEE Trans. Evol. 
Comput., Vol. 8, No. 1, pp. 1–13, 2004. 
[11] K. E. Parsopoulos, “Cooperative Micro-Differential Evolution for 
High-dimensional Problems,” Genetic and Evolutionary Computation 
Conference 2009 (GECCO 2009), pp. 531-538, Montreal, Canada, 
2009.  
[12] M. A. Potter and K. De Jong, “A Cooperative Coevolutionary 
Approach to Function Optimization,” In Proceedings from the Third 
Parallel Problem Solving from Nature, Vol. 2, pp. 249-257, 1994.  
[13] R. Sarker, M. Mohammadian, and X. Yao, Evolution Optimization, 
Kluwer Academic Pub., 2002.  
[14] M. Srinivas and L. M. Patnaik, “Adaptive Probabilities of Crossover 
and Mutation in Genetic Algorithms,” IEEE Trans. on Systems, Man 
and Cybernetics, Vol. 24, No. 4, pp. 656-667, 1994.  
[15] M. Srinivas and L. M. Patnaik, “Adaptive Probabilities of Crossover 
and Mutation in Genetic Algorithms,” IEEE Trans. on Systems, Man 
and Cybernetics, Vol. 24, No. 4, pp. 656-667, 1994.  
[16] R. Storn, K. Price, and J. Lampinen, Differential Evolution: A Practical 
Approach to Global Optimization, Springer-Verlag, Berlin, 2005.  
[17] W. J. Tang, Q. H. Wu, and J. R. Saunders, “Bacterial Foraging 
Algorithm for Dynamic Environments,” 2006 IEEE Congress on 
Evolutionary Computation, (CEC 2006), pp. 1324-1330, Canada, 
2006. 
[18] X. Yao, Y. Liu, and G. Lin, “Evolutionary programming made faster,” 
IEEE Trans. Evol. Comput., vol. 3, no. 2, p. 82, Jul. 1999. 
[19] X. Zhang, W. Chen, C. Dai, and A. Guo, “Self-adaptive Differential 
Evolution Algorithm for Reactive Power Optimization,” 2008 IEEE Int. 
Con. on Natural Computation (ICNC 2008), pp. 560-564, 2008.  
[20] D. Xu, S. Li, and F. Qian, “An Improved Differential Evolution 
Algorithm and Its Application in Reaction Kinetic Parameters 
Estimation,” 2007 International Conference on Intelligent Systems and 
Knowledge Engineering (ISKE 2007), Oct. 2007.  
 
TABLE II 
BENCHMARK FUNCTION 
Test function D Search Range f min 
( ) 2
11 ∑ == Di ixxf  2 [-100, 100] D 0 
( ) ∏∑ == += Di iDi i xxxf 112  5 [-10, 10] D 0 
( ) ( )∑ ∑= == Di ij jxxf 1 1 23  2 [-100, 100] D 0 
( ) Dixxf i ≤≤= 1,max4  5 [-100, 100] D 0 
( ) ( ) ( )[ ]∑ −= + −+−= 11 22215 1100Di iii xxxxf  2 [-30, 30] D 0 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/25
國科會補助計畫
計畫名稱: 多輸入多輸出非線性非仿射系統之智慧型控制器設計與實現
計畫主持人: 李慶鴻
計畫編號: 97-2221-E-155-033-MY3 學門領域: 智慧型控制
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1. 協助辦理 2011 FUZZ IEEE (台北君悅飯店)，擔任 Local Arrangement 
Co-chair 
2. 帶領碩士生擔任 2011 FUZZ IEEE (台北君悅飯店)服務工作人員 
3. 獲得中華民國模糊學會碩士論文競賽第二名 
4. 計畫執行期間(2008/08/01~2011/10/31)獲得  
   (i) 中華民國自動控制學會第七屆「青年自動控制工程獎」(2009/11) 
   (ii) 元智大學 98 學年「輔導暨服務傑出獎」(2010/12) 
(iii)元智大學 97 學年「研究傑出獎」(2009/12) 
5. Certificate of Merit for The 2010 IAENG Int. Conf. on Artificial 
Intelligent and Applications (2010/04)- paper Title: Species-based 
Hybrid of Electromagnetism-like Mechanism and Back-propagation 
Algorithms for An Interval Type-2 Fuzzy System Design； Paper Title: 
Nonlinear Systems Design by a Novel Fuzzy Neural Systems via 
Hybridization of EM and PSO Algorithms （國外獲獎） 
6. 執行與台達電子產學合作案「應用類神經網路建構物件分類系統」 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
