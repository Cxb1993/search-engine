I 
目錄 
 
摘要............................................................................................................................... II 
一、前言 ......................................................................................................................1 
二、研究目的 ..............................................................................................................1 
三、文獻探討 ..............................................................................................................1 
四、研究方法 ..............................................................................................................3 
五、結果與討論 ..........................................................................................................4 
六、參考文獻 ..............................................................................................................8 
附錄 (已發表之論文，含國際期刊論文兩篇、國際會議論文六篇) ...................10 
[Journal Papers] 
1. W.-G. Teng, Y.-H. Chian, P.-L. Chang, and H. Wang, “Bridging the Semantic Gap in Online 
Image Retrieval,” Accepted by Applied Mathematics & Information Sciences, September 
2011. 
2. W.-G. Teng and P.-L. Chang, “Identifying Regions of Interest in Medical Images Using 
Self-Organizing Maps,” Journal of Medical Systems, 2011. (In Press, Published online: 5 
July 2011, DOI: 10.1007/s10916-011-9752-8) 
[Conference Papers] 
1. C.-T. Yang, W.-S. Chang, F.-N. Cheng, and W.-G. Teng, “Assessing Media Relevance via 
Eye Tracking,” Proceedings of the International Conference on ASONAM (MSN-2011 
Workshop), pages 722-726, July 25-27, 2011.  
2. Y.-S. Chian and W.-G. Teng, “Discovering Visual-Concepts of Online Images from 
Associational Image Patches,” Proceedings of the 15th IEEE Symposium on Consumer 
Electronics (Poster), pages 218-221, June 14-17, 2011. 
3. W.-H. Wen and W.-G. Teng, “Incorporating Localized Information with Browsing History 
for On-Demand Search,” Proceedings of the 15th IEEE Symposium on Consumer 
Electronics (Poster), pages 14-17, June 14-17, 2011. 
4. Y.-J. Wu and W.-G. Teng, “An Enhanced Recommendation Scheme for Online Grocery 
Shopping,” Proceedings of the 15th IEEE Symposium on Consumer Electronics, pages 
410-415, June 14-17, 2011. 
5. K.-F. Lin and W.-G. Teng, “An Incremental SVD-based Scheme for Large-scale 
Recommendation Systems,” Proceedings of the Second IITA International Joint Conference 
on Artificial Intelligence, pages 61-64, December 25-26, 2010. 
6. P.-L. Chang and W.-G. Teng, “Exploiting a Growing Self-Organizing Map for Adaptive and 
Efficient Color Quantization,” Proceedings of the 2009 IEEE Pacific-Rim Conference on 
Multimedia (LNCS 5879), pages 1219-1229, December 15-18, 2009. 
 
1 
一、前言 
隨著消費電子和行動運算技術的進
步，數位相機及手機等隨身設備的使用率亦
逐年增長；此外，社群網路的盛行也使得透
過網際網路與朋友溝通變得更加容易，這些
事實都明顯地改變了使用者的使用習慣。舉
例來說，人們可以隨時隨地利用數位相機或
手機拍照，並可以立即上傳這些照片至自己
的網路相簿或部落空間與朋友們分享。因
此，造成網路上湧現並聚集了大量的影像資
料，網際網路無疑地成為了一個包含各種影
像資料的最大空間。但卻仍未有非常理想的
影像檢索機制。因此，如何擷取影像中的明
顯特徵並找尋圖片之間的關連性，以及尋求
有效率的搜尋方法，就成了一個值得探討的
議題。 
影像檢索目前仍是許多學者持續討論
卻尚待解決的研究問題，如何以使用者提供
的資訊 (諸如：幾個關鍵詞、一張範例影像) 
來找到符合條件的影像，牽涉到影像處理、
資料庫系統、資訊檢索等諸多領域的研究課
題。在本研究計畫為期兩年的執行時期中，
我們的研究重點即為研讀基於影像內容之影
像檢索以及其相關技術，並在相關子課題中
設計並研發具應用價值之方法。 
 
二、研究目的 
通訊網路技術的進步與行動裝置的廣
泛使用，不僅可以讓使用者可以即時獲取所
需的資訊，而且還縮短了人與人之間的距
離。如今人們可以在拍照後立即輕鬆地在網
際網路上共享他們的照片。隨著線上影像的
與日俱增，發現影像中之視覺概念是一個具
有挑戰性的問題。 
本研究主要探討如何使電腦可以理解
任意一張影像並明白影像中所包含的視覺概
念。為了解決這個問題，大部分前人研究試
圖將不同的影像分類至預先定義好的許多類
別中 [8][12][18][37]；然而因線上影像的快
速成長，影像的類別將無法完全預先設定，
所以我們利用影像中類似的影像區域而不是
分類模型 (classification model) 來解決這個
問題；更明確地而言，我們將不會把影像檢
索問題視為一個分類的問題 (亦即試圖把不
同的影像區分至預先定義的某個類別中)，我
們建議在這項工作開始尋找類似的形象區
塊。具體來說，我們採用關聯式規則這項技
術建立影像之間的關係，從線上影像中發掘
相同的視覺概念，並找出具有相同視覺概念
之影像。 
 
三、文獻探討 
隨著資訊技術的進步，大量資料被廣泛
分享於網際網路上，而造成了 “資訊超載” 
的問題。而針對文字資料的檢索  (text 
retrieval) 技術現已相當成熟了，多數使用者
每天均會使用的網頁搜尋引擎  ( 諸如
google、Yahoo! Search、Bing 等)，可在幾秒
內完成搜尋動作並傳回相關的檢索結果，是
對於文字檢索此一課題最顯著的和成功的解
決方案。 
影像檢索的目的是從影像資料庫中瀏
覽、搜尋和檢索數位影像 [7]。最常見的方
法是利用文字資訊，如檔名、關鍵字或語意
相關的片段文字來尋找影像資料 [23]。這個
方法在基於文字檢索的成功基礎上，有相當
高的效率，可以在短時間內回傳與搜尋關鍵
字相符的影像和文字資訊。 
然而當利用關鍵字來尋找影像資料
時，需預先將所有影像加上相對應的文字註
記，因此發展一有效且自動的方法以為影像
註記相對應之文字資訊，成為了當前熱門的
研究課題；此外，另一方面的研究方向是僅
根據影像本身的內容特徵，而不使用額外的
文字資訊來進行檢索。相關技術發展至今已
有相當多的討論與研究成果，在本計劃中我
3 
然而 Web 2.0 社群性標籤服務的成功，證明
使用者願意手動為資料提供語意註記也就是
所謂的標籤 (tag)，因為這樣一來，可以讓分
享的資料更容易被大眾取得 [2]。類似文字
檢索時所用到的關鍵字詞，標籤可為一影像
資源提供簡要的文字描述。 
分眾分類 (folksonomy) 指由使用者自
發性地為資源以任意關鍵字定義非階層式標
籤，也就是群眾可以自由地將資源對應到某
個標籤分類；是 Web 2.0 應用協同式標籤系
統的核心資料結構。最近，社群標籤服務如
Del.icio.us、CiteULike，和 Flickr 提供使用者
對網際網路中資源進行註記和檢索，包括網
頁、圖片、音訊、影片、網誌、網址、地點、
甚至人物等，即是分眾分類的應用。 
以 Flickr 相片分享系統而言，照片伴隨
著各種文字資訊，如標籤、意見、使用者評
論和上傳日期等，Flickr 影像搜尋系統利用
這些文字資訊來搜尋影像資料並針對搜尋結
果做排名。比如說，照片被瀏覽次數表示其
受歡迎的程度，照片的上傳日期和拍攝日期
是則新舊程度的指標，而將照片加入使用者
追蹤清單可能是最直接表明使用者對該照片
是感興趣的。並且針對使用者、標籤和相片
本身，分析它們之間的三元關係 [16] 進行
分類聚合可控制分類，方便檢索分眾分類所
涵蓋的照片，讓使用者可以在這些標籤服務
中利用標籤輕易地組織、共享和檢索可取得
的照片。 
標籤的主要目的是為了使影像更容易
被公眾取得 [2] ，雖然社群性標籤系統允許
使用者自由地為影像建立文字標籤資訊，卻
使得標籤資料往往是雜亂、模糊、不完整和
主觀的 [10][15][17]。研究指出，使用者提供
的許多標籤中與影像有相關性的只有約 
50% [12]，這些因素都有可能會嚴重降低檢
索性能。 
標籤資料有著一詞多義和同義詞的語
意問題。首先，由於每個人的背景知識和身
分背景不同 [15]，而使用者可以使用自己的
慣用語來標籤影像，不同的使用者可能會用
不同的詞語標籤類似的影像，如對大海影像
場景，使用者可能會註記  “sea” 抑或 
“ocean” 同義的不同標籤，而不會輸入所有
的相同意義的標籤，因此造成大量的影像可
能無法有效地檢索。其次，文字本身的模糊
性也是一個問題。使用者可以使用一般的標
籤來代表不同的事物，舉例來說，“apple” 這
個標籤可以指一種水果，也可以是指蘋果電
腦公司。一般而言，若使用者沒有想到甚至
不知道標籤的其他意義時，很難意識到標籤
的歧義的存在，而使許多無關的影像出現在
搜尋結果中。因此，許多研究致力於尋找標
籤的語意關係，如調查使用者如何標籤照片
和在 Flickr 標籤中包含的資訊 [15]，以改善
社 群 標 籤 檢 索 系 統 的 準 確 率
[15][17][30][35]。 
社群性標籤資料中常常有影像無關的
標籤出現在標籤列表中，且使用者通常不會
為影像中出現的所有物件建立標籤，這造成
了語意的損失 [35]；在影像檢索中基於相關
性排名是很重要的，標籤排名除了用在基於
標籤的影像搜索，也可以被用在標籤推薦和
群組推薦。然而在目前基於標籤的影像檢索
服務中，與影像相關的標籤通常以隨機方式
排列，而無法依標籤影像的相關性排名，使
得標籤列表不包含任何重要性或相關性資
訊，這限制了這些標籤在搜尋和其他應用的
有效性。 
此外，如何基於標籤資料進行影像的推
薦，是一個新興的研究課題。社群性標籤不
僅方便使用者尋找和組織線上影像，還可提
供推薦系統有意義的語意資料。傳統推薦系
統著重於使用者評分資料；而隨著社群標籤
資料越來越普遍，利用標籤進行影像推薦需
要在成千上百甚至數以百萬計的影像中推薦
5 
的物件以其屬性加以描述，並藉以判斷此物
件的類別。在物件分類上，採用監督式學習
的方式可建立出一個有識別力的分類器 
(classifier)，以做為影像中形狀特徵的物件識
別工具 [12]；前人研究中發現 SVM (support 
vector machine) 和 k-NN (k-nearest neighbors)
這兩種典型用於分類的技術在妥善地加以結
合後，便可用以解決當一張影像中含有許多
不同物件時，同一影像被分配至不同類別之
於多重類別 (multiclass) 的問題 [38]。 
然而，物件的識別分類有一個重要的限
制：所有的概念或場景必須事先指定。而當
物件識別與分類結合了語意影像標籤的技術
後，便可為一張影像提供豐富的說明，主要
概念即為利用場景 (scene) 的不同而進行影
像分類和物件識別的工作。 
 
5.2 多樣化搜尋結果 (Diversity in Search) 
基於影像內容的影像檢索系統利用低
階特徵相似度的計算可尋找到和搜尋條件相
當相似的影像，但卻無法檢索到某些特定主
題，並針對這個主題增進影像檢索結果的視
覺多樣性，捕捉不同方面檢索結果 [14]。比
如是尋找特定的地標建築 “台北 101” 的影
像，並且多樣化地呈現像是遠眺煙火場景以
及由上俯視等等不同的結果。 
對人們而言“讀取”影像資料，也就是
在極短時間內了解影像中所表達的場景是個
輕易的任務。人類可以直觀地發現某些影像
中具有相同的視覺概念，例如臉、物體、或
場景；即使是從未見過的影像都能一目了
然。然而對於電腦而言，要達成相同的目標
是相當困難的。具體來說，要發現一個影像
的資訊類似於計算機視覺 “場景偵測”。也就
是“教電腦它看到了怎樣的情景”。 
視覺概念可能指得是一種低階的影像
特徵 (如圖二左上的藍色)，也可以是視覺上
可見的物體 (如圖二右上的窗戶和左下的啤
酒)，甚或包含有複雜內容的抽象概念 (如圖
二右下之聖誕節影像)。 
 
 
圖二、不同視覺概念之範例影像 
 
5.3 發 現 視 覺 概 念  (Discovering 
Visual-Concept) 
在視覺上，人類看到一張影像時，會對
整體先做觀察及瞭解，然後再區別影像中各
個不同的物件，以本身的知識理解並賦予物
件意義。而電腦程式在解析一張影像時，往
往需經過影像切割的步驟以得到所需的物
件，並依此物件對應到所屬的分類，最後再
做影像標註，當然在這過程仍有許多尚待解
決的問題。 
而我們的目標類似於場景偵測 (scene 
detection)，是從線上影像集合中發現視覺概
念。我們首先識別相似的影像區塊，而不是
使用影像分類試圖將影像分配到預定義的不
同類別中。因影像分類需預先定義所有的類
別，並不適用於持續增長的影像系統，例如，
網際網路中的新物體或場景。 
同一張影像中出現許多相關的物件
7 
在本研究計畫的執行期間內，我們已在
國際學術研討會及期刊中發表了我們的研究
成果，計有期刊論文兩篇 [25][26] 和國際會
議論文六篇 [5][6][19][33][34][36]。除了在理
論方面有以上斬獲，我們也利用理論發展的
同時，實作影像檢索系統原型以證明可應用
於現實中。而對於參與本計畫的研究人員在
計畫執行期間，對技術的研究得到頗豐的成
果，亦有相關議題的學位論文 [39][40]。本
研究團隊深信，若繼續在未來各項研究議題
持續深入探討，必定能有更豐富的產出。 
 
六、參考文獻 
[1] R. Agrawal, T. Imielinski, and A. Swami, “Mining 
Association Rules between Sets of Items in Large 
Databases,” the 1993 ACM SIGMOD 
International Conference on Management of Data, 
pages 207-216, May 1993. 
[2] M. Ames and M. Naaman, “Why We Tag: 
Motivations for Annotation in Mobile and Online 
Media,” Proceeding of the SIGCHI Conference on 
Human Factors in Computing System, pages 
971-980, April 2007. 
[3] D. M. Blei and M. I. Jordan, “Modeling Annotated 
Data,” Proceedings of the 26th Annual 
International ACM SIGIR Conference on Research 
and Development in Information Retrieval, pages 
127-134, July 2003. 
[4] S. Boll, P. Sandhaus, A. Scherp, and U. 
Westermann, “Semantics, Content, and Structure 
of Many for the Creation of Personal Photo 
Albums,” Proceedings of the 15th International 
Conference on Multimedia, pages 641-650, 
September 2007. 
[5] P.-L. Chang and W.-G. Teng, “Exploiting a 
Growing Self-Organizing Map for Adaptive and 
Efficient Color Quantization,” Proceedings of the 
2009 IEEE Pacific-Rim Conference on Multimedia 
(LNCS 5879), pages 1219-1229, December 15-18, 
2009. 
[6] Y.-S. Chian and W.-G. Teng, “Discovering 
Visual-Concepts of Online Images from 
Associational Image Patches,” Proceedings of the 
15th IEEE Symposium on Consumer Electronics 
(Poster), pages 218-221, June 14-17, 2011. 
[7] R. Datta, D. Joshi, J. Li, and J. Z. Wang, “Image 
Retrieval: Ideas, Influences, and Trends of the 
New Age,” ACM Computing Surveys, 40(2): 1-60, 
April 2008. 
[8] J. Deng, A. C. Berg, K. Li, and L. Fei-Fei, “What 
Does Classifying More Than 10,000 Image 
Categories Tell Us?,” Proceedings of the 11th 
European conference on Computer vision, pages 
71-84, September 2010. 
[9] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth,
“ Describing Objects by Their Attributes,” 
Proceedings of the IEEE International Conference 
on Computer Vision and Pattern Recognition 
(CVPR), pages 1778-1785, June 2009. 
[10] S. A. Golder and B. A. Huberman, “Usage 
Patterns of Collaborative Tagging Systems,” 
Journal of Information Science, 32(2): 198- 208, 
April 2006. 
[11] C. v. G. Jan, “Visual Word Ambiguity,” IEEE 
Transactions on Pattern Analysis and Machine 
Intelligence, 32(7): 1271-1283, July 2010. 
[12] L. S. Kennedy, S. F. Chang, and I. V. Kozintsev, 
“To Search or To Label? Predicting the 
Performance of Search-Based Automatic Image 
Classifiers,” Proceeding of the 8th ACM 
International Workshop on Multimedia 
Information Retrieval, pages 249–258, October 
2006. 
[13] S. Lazebnik, C. Schmid, and J. Ponce, “Beyond 
Bags of Features: Spatial Pyramid Matching for 
Recognizing Natural Scene Categories,” 2006 
9 
in Large Database Recognition Problems," 
Proceedings of 2009 IEEE 12th International 
Conference on Computer Vision Workshops (ICCV 
Workshops), pages 2109-2116, September 2009. 
[29] K. van de Sande, T. Gevers, and C. Snoek, 
“Evaluation of Color Descriptors for Object and 
Scene Recognition, ” Proceedings of IEEE 
Conference on Computer Vision and Pattern 
Recognition, pages 1-8, June 2008. 
[30] B. Sigurbjörnsson and R. Van Zwol, “Flickr Tag 
Recommendation Based on Collective 
Knowledge,” Proceeding of ACM International 
World Wide Web Conference, pages 327-336, April 
2008. 
[31] N. Vasconcelos, “From Pixels to Semantic Spaces: 
Advances in Content-Based Image Retrieval,” 
IEEE Computer, 40(7): 20-26, July 2007. 
[32] R. C. Veltkamp and M. Tanase, “Content-Based 
Image Retrieval Systems: A Survey,” Technical 
Report UU-CS-2000-34, October 2000. 
[33] W.-H. Wen and W.-G. Teng, “Incorporating 
Localized Information with Browsing History for 
On-Demand Search,” Proceedings of the 15th 
IEEE Symposium on Consumer Electronics 
(Poster), pages 14-17, June 14-17, 2011. 
[34] Y.-J. Wu and W.-G. Teng, “An Enhanced 
Recommendation Scheme for Online Grocery 
Shopping,” Proceedings of the 15th IEEE 
Symposium on Consumer Electronics, pages 
410-415, June 14-17, 2011. 
[35] L. Wu, L. Yang, N. Yu, and X. S. Hua,  “Learning 
to Tag,” Proceedings of the 18th International 
Conference on World Wide Web, pages 361–370, 
April 2009. 
[36] C.-T. Yang, W.-S. Chang, F.-N. Cheng, and W.-G. 
Teng, “Assessing Media Relevance via Eye 
Tracking,” Proceedings of the 2011 International 
Conference on Advances in Social Networks 
Analysis and Mining (MSN-2011 Workshop), 
pages 722-726, Kaohsiung, Taiwan, July 25-27, 
2011. 
[37] H. Zhang and J. Malik, “Learning a 
Discriminative Classifier Using Shape Context 
Distances,” Proceedings of the IEEE Computer 
Society Conference on Computer Vision and 
Pattern Recognition (CVPR), pages 242-247, June 
2003. 
[38] H. Zhang, A. C. Berg, M. Maire, and J. Malik, 
“SVM-KNN: Discriminative Nearest Neighbor 
Classification for Visual Category Recognition,” 
Proceedings of the IEEE Computer Society 
International Conference on Computer Vision and 
Pattern Recognition (CVPR), pages 2126-2136, 
June 2006. 
[39] 陳昱呈，“設計與實作一以多重有興趣區塊查
詢之地標影像檢索系統”，國立成功大學工程
科學系碩士論文，民國九十九年七月 
[40] 錢雅馨，“以關聯式規則發掘線上影像之視覺
概念”，國立成功大學工程科學系碩士論文，
民國一百年七月。 
 
54 
Wei-Guang Teng et al 
To completely describe an image, a global image descriptor such as color histograms 
is not adequate, since it only provides a global statistics and ignores the local distinct 
features and structure of an image. On the other hand, using a local descriptor like SIFT, 
which preserves the invariance of photometric and various geometric transformations 
across images, to describe only local information, the global characteristic will be lost as 
well. The combination of using global and local image descriptors to represent an image 
is thus a promising strategy in CBIR [1]. 
Once images are pre-processed to be represented by descriptors and saved in a 
database, the next step is to evaluate the similarity between them and a new queried 
image. Current CBIR systems typically measure the similarity of different images by a 
voting scheme or by comparing histograms over a set of quantized vector descriptors. 
Such a similarity measure, however, omits the co-occurrence of a set of discriminative 
features which is particularly important for the recognition of objects and textures, and it 
brings failure in distinguishing between images having varying numbers of similar 
features [2]. 
The lack of the completeness of representing an image by using insufficient variety of 
low-level descriptors together with losing the high-level information, i.e., the frequency 
of features co-occurrence, cause a so-called semantic gap problem between human 
visual-concept and the retrieval images. To bridge the gap, we devise a CBIR system 
using the combination of various features and propose to incorporate a well-known data 
mining technique, association rules, into this system to analyze the co-occurrence of these 
features. 
This objective is also similar to that of a scene detection task in capturing the "gist" of 
an image. In a typical process, training examples are provided to help the recognition of 
objects or the overall scene contained in a new image. Recognition results are then 
presented by classifying images into pre-defined scene categories. This process may work 
well in a static dataset but fails to learn new objects or scenes in a continuously growing 
image archive, e.g., the Internet. Alternatively, we propose to start with identifying the 
relationship between two image patches (or regions) from two different images. This 
helps to consolidate the basis of discovering identical visual-concepts from online 
images. 
The main contribution of this paper is to introduce the concept of associating image 
patches formed by a bag of visual words model (BoW). Note that visual words are not 
real words, but rather summarized descriptors to describe image details, i.e., a corner, 
texture, or point [3]. Furthermore, the association rules [4] are adopted to identify evident 
relationships of image patches that can help to constitute a specific visual-concept, e.g., 
the Santa, reindeers and stockings imply a Christmas scene.  
The rest of this paper is organized as follows. Preliminaries and related works are 
generally reviewed in Section 2. Techniques of visual words and association rule mining 
used in our scheme to discover visual-concepts from online images are explored in 
Section 3. Empirical studies to show the feasibility of our proposed scheme are conducted 
in Section 4. Finally, this paper concludes with Section 5. 
2  Preliminaries 
In most of current CBIR systems, images are represented by general features, e.g., 
56 
Wei-Guang Teng et al 
Section 3.3. 
3.1.  Associating relevant image patches 
It is straightforward for users to comprehend the meanings of a word and associate 
this word with other relevant ones. The patterns “star”, “day”, “Apollo”, and “Java”, for 
example, can imply the word “sun”, because the sun is a fixed star, we have day time 
when the sun shows in the sky, Apollo is identified with the sun in Greek Mythology, and 
Java is a kind of programming language developed by Sun Microsystems.  
 
Figure 1.  The Easter scene can be implied by associational image patches 
That is to say, this word association game is the connection and production of other 
words to a given word based on the noun phrase word association. In view of this, we 
propose to introduce the technique of association rule mining. In general, association rule 
mining is a widely-used approach for discovering significant regularities between items, 
i.e., frequent itemsets, in large scale customer transaction data recorded by usually a large 
retailing company [4]. Let I be a set of items, and T be a set of transactions, lists all items 
bought by a customer. Each transaction in T contains a subset of the items in I. A rule is 
defined as an implication of the form: 
YX  , where IYX , and YX  
For example, a set in supermarket databases of items is I = {milk, bread, butter}. An 
rule for the supermarket could be {bread, milk}→{butter} meaning that if bread and milk 
is bought, customers also buy butter. Similarly, many relevant objects are simultaneously 
contained in an image. Instead of recognizing independent objects, we tend to discover 
the latent meaning by associating these visual objects. As shown in Fig. 1, the co-
occurrence of bunnies, eggs, chicks and lilies can imply the Easter scene. 
In this work, visual-words, i.e., significant image patches, are taken as items whereas 
an image is regarded as a transaction when association rule mining is applied. For our 
purpose of identifying similar concepts or scenes from numerous images, association rule 
mining helps to discover frequently co-occurring visual words so as to ease the problem 
of scene detection. Unlike the approaches developed in prior works [3][14], visual-
concepts are not required to be pre-defined in a constraint number of categories in our 
scheme. 
3.2.  Quantizing image features to visual vocabulary 
In CBIR systems using voting similarity measures, a considerable number of 
descriptors are extracted from images to be saved individually in local databases. When 
querying is executed, the CBIR systems contrast each image in database with query 
image by calculate their similarity of these descriptors. In other words, many similar or 
even duplicate descriptors are stored in the database. With the sizes of image databases 
58 
Wei-Guang Teng et al 
quantized from features, and the discovered frequent itemsets are stored. 
 Conceptual Groups: Images containing similar visual-concepts are grouped 
together. This facilitates the execution of an image retrieval task. 
Visual 
Words
Frequent 
Itemsets
ImagesInternet
Feature 
Quantization
Feature 
Extraction
Association 
Rule Mining
ExplorerDatabase
Conceptual
Groups
 
Figure 3.  Proposed scheme for discovering visual-concepts of online images 
4  Empirical Studies and Discussions 
Our experimental process is depicted in Fig. 4. The upper part of Fig. 4 shows the 
training process that all images are carefully processed through necessary steps. 
Specifically, feature vectors are firstly extracted from an image. Then, visual words are 
formed after the feature quantization step. Frequent itemsets can thus be discovered by 
utilizing the technique of association rule mining. Finally, images containing several 
identical itemsets are considered similar, i.e., within the same conceptual group.  
Feature 
Vectors
Internet Visual 
Words
Frequent 
ItemsetsImages
Query Image
Results
User
Feature
Extraction
Feature
Quantization
Association
Rule Mining
Feature 
Vectors
Visual 
Words
Feature
Extraction
Feature
Quantization
Itemsets
Matched
 
Figure 4.  Our experimental process and an illustrative example 
An example scenario of utilizing our proposed scheme for image retrieval is also 
shown in the lower part of Fig. 4. Once a user takes and uploads a photo with his or her 
smart phone, digital camera or even tablets, similar processing steps can be done to 
identify corresponding visual words of this image. With a proper matching mechanism, 
images containing similar visual-concepts can be retrieved even if these images are not so 
similar in terms of low-level features. To further illustrate the scenario as shown in the 
lower part of Fig. 4, one can easily understand that the corresponding visual-concept is 
the Christmas. Several image patches with strong associations, e.g., Christmas stockings, 
candy canes, and gingerbread man, are found in the images belonging to the same 
conceptual group. 
60 
Wei-Guang Teng et al 
Query Image Retrieval Results
(c)
(b)
(a)
 
Figure 6.  Results of querying with (a) a Halloween image; (b) a lantern image; and (c) a 
Chinese New Year image using the proposed CBIR scheme 
Additionally, we use the MIRFLICKR dataset [16] which addresses the topic of 
visual-concept detection to evaluate our proposed scheme. This dataset is a popular large-
scale benchmark that consists of 25,000 images from real world users, i.e., Flickr users. 
Based on the annotations provided by Flickr users, the ImageCLEF organization 
manually categorize the images in the MIRLFICKR dataset to a number of conceptual 
categories, e.g., animals, people, sky, night, indoor and so on. 
To evaluate the feasibility of our proposed scheme, each of the images in this 
MIRFLICKR dataset are taken as the input and the MAP (mean average precision) of 
retrieval results are recorded for all conceptual categories. As shown in Fig. 7, our 
scheme generally improves the MAP values as compared to a generic retrieval scheme. 
Furthermore, our scheme our approach reaches a more than 15% improvement in the 
conceptual categories of river, bird, food, car, and sea. 
62 
Wei-Guang Teng et al 
5 Conclusions 
As more and more people get used to sharing their photos on the Internet, the problem 
of image retrieval has attracted increasing research interests. In this work, we have 
proposed to discover visual-concepts embedded within numerous images. Instead of 
adopting the typical process of scene detection to categorize images into different pre-
defined classes, we have devised a scheme to start with identifying similar image patches. 
Specifically, we have introduced the concept of visual words and the technique of mining 
association rules to construct evident relationships among image patches so as to discover 
identical visual-concepts from online images. 
Acknowledgements 
The authors are supported in part by the National Science Council, Project No. 
NSC98-2221-E-006-164-MY2, Taiwan, R.O.C. 
References 
[1] P. Liu, K. Jia, Z. Wang, and Z. Lv, A New and Effective Image Retrieval Method Based on 
Combined Features, Proceedings of the 4th International Conference on Image and 
Graphics, (2007) August 22-24; Chengdu, China 
[2] K. Grauman and T. Darrell, Efficient Image Matching with Distributions of Local Invariant 
Features, Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision 
and Pattern Recognition, (2005) June 20-25; San Diego, CA, USA 
[3] C. G. M. Snoek and A. W. M. Smeulders, Visual-Concept Search Solved?, IEEE Computer 6, 
43 (2010) 
[4] R. Agrawal, T. Imielinski, and A. Swami, Mining Association Rules Between Sets of Items in 
Large Databases, Proceedings of the 1993 ACM SIGMOD International Conference on 
Management of Data, (1993) May 26-28; Washington, D.C, USA 
[5] M. Agrawal, K. Konolige, and M. Blas, CenSurE: Center Surround Extremas for Realtime 
Feature Detection and Matching, Proceedings of the 10th European Conference on Computer 
Vision, (2008) October 12-18; Marseille, France 
[6] D. G. Lowe, Distinctive Image Features from Scale-Invariant Keypoints, International 
Journal of Computer Vision 2, 60 (2004) 
[7] N. Vasconcelos, From Pixels to Semantic Spaces: Advances in Content-Based Image 
Retrieval, IEEE Computer 7, 40 (2007) 
[8] V. N. Gudivada, and V. V. Raghavan, Content-Based Image Retrieval Systems, IEEE 
Computer 9, 28 (1995) 
[9] R. Veltkamp and M. Tanase, Content-Based Image Retrieval Systems: A Survey, Technical 
Report UU-CS- 2000-34, October (2000). 
[10] 10. S. Lazebnik, C. Schmid, and J. Ponce, Beyond Bags of Features: Spatial Pyramid 
Matching for Recognizing Natural Scene Categories, Proceedings of the 2006 IEEE 
Computer Society Conference on Computer Vision and Pattern Recognition, (2006) June 17-
22; New York, NY, USA 
[11] D. Nister and H. Stewenius, Scalable Recognition with a Vocabulary Tree, Proceedings of the 
2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 
(2006) June 17-22; New York, NY, USA 
[12] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman, Object Retrieval with Large 
Vocabularies and Fast Spatial Matching. Proceedings of the 2007 IEEE Computer Society 
Conference on Computer Vision and Pattern Recognition, (2007) June 18-23; Minneapolis, 
Minnesota, USA 
[13] J. Sivic and A. Zisserman, Video Google: A Text Retrieval Approach to Object Matching in 
Videos, Proceedings of the 9th IEEE International Conference on Computer Vision, (2003) 
October 13-16; Nice, France 
ORIGINAL PAPER
Identifying Regions of Interest in Medical Images
Using Self-Organizing Maps
Wei-Guang Teng & Ping-Lin Chang
Received: 2 March 2011 /Accepted: 16 June 2011
# Springer Science+Business Media, LLC 2011
Abstract Advances in data acquisition, processing and
visualization techniques have had a tremendous impact on
medical imaging in recent years. However, the interpreta-
tion of medical images is still almost always performed by
radiologists. Developments in artificial intelligence and
image processing have shown the increasingly great
potential of computer-aided diagnosis (CAD). Nevertheless,
it has remained challenging to develop a general approach
to process various commonly used types of medical images
(e.g., X-ray, MRI, and ultrasound images). To facilitate
diagnosis, we recommend the use of image segmentation to
discover regions of interest (ROI) using self-organizing
maps (SOM). We devise a two-stage SOM approach that
can be used to precisely identify the dominant colors of a
medical image and then segment it into several small
regions. In addition, by appropriately conducting the
recursive merging steps to merge smaller regions into larger
ones, radiologists can usually identify one or more ROIs
within a medical image.
Keywords Computer-aided diagnosis . Image
segmentation . Region of interest . Self-organizing map
Abbreviations
BMU Best Matching Unit
CAD Computer-Aided Diagnosis
CBIR Content-Based Image Retrieval
ROI Region of Interest
SOM Self-Organizing Map
Introduction
With the remarkable advances that have occurred in
computer technologies in recent years, the number of
applications that utilize digital image processing techniques
has greatly increased. For clinical use, images are now
almost always collected and stored digitally. Common
medical images include ultrasound images, images pro-
duced by magnetic resonance imaging (MRI), X-ray
images, and images produced by computed tomography
(CT) and digital mammography [1, 2]. With the aid of data
acquisition, processing and visualization techniques, med-
ical imaging can easily facilitate diagnosis.
However, radiologists must still interpret the details of
medical images. Suspicious regions of an image, as
indicated by abnormal colors or shapes, must be manually
identified by radiologists for further clinical examination.
Nevertheless, with the development of computer-aided
diagnosis (CAD), methods of interpretation have begun to
improve; radiologists can use computerized medical images
for input in making diagnostic decisions [3]. In addition,
analogous to the role of CAD algorithms in medical
imaging to complement the opinion of a radiologist, CAD
algorithms may also be used to complement the opinion of
the pathologist for disease detection, diagnosis, and
prognosis prediction [4]. Furthermore, content-based image
retrieval (CBIR) techniques are becoming valuable to
W.-G. Teng
Department of Engineering Science,
National Cheng Kung University,
Tainan, Taiwan
W.-G. Teng (*)
No.1, University Road,
Tainan 701, Taiwan
e-mail: wgteng@mail.ncku.edu.tw
P.-L. Chang
Department of Computing, Imperial College London,
London, UK
P.-L. Chang
e-mail: p.chang10@imperial.ac.uk
J Med Syst
DOI 10.1007/s10916-011-9752-8
Author's personal copy
Utilizing SOMs for image segmentation
Self-organizing maps (SOMs) are commonly used for
dimensionality reduction [14]. In a typical SOM, n-
dimensional input vectors can be mapped to a few neurons
of one or two dimensions. When the aim is to segment
color images, a typical option is to use all color components
of each pixel as input vectors. This process reveals the
corresponding two-layer structure of the SOM, which will
contain input vectors and output neurons, as shown in
Fig. 1. Without loss of generality, the RGB color model is
used in Fig. 1. Other color models, including Lab, Luv,
HSV and YCbCr, can also be utilized in a similar way.
During the iterative learning process, the output neurons
usually converge on the dominant colors of the original
image. The goal of color reduction can thus be achieved by
discarding insignificant colors.
The weight vectors associated with the neurons in the
output layer are denoted by Wi ¼ ½wi1;wi2;wi3T ; their
initial values are randomly determined, where 0  i 
M  N (i.e., M × N is the size of the output layer). Note
that the SOM procedure works iteratively to form an
unsupervised learning process. In each iteration, the most
similar neuron or the best matching unit (BMU) can be
designated as an input vector. In addition, a training process
begins in which neighboring units of the BMU are
identified according to an exponential decay function at
time t as follows.
sðtÞ ¼ s0 exp  th
 
ð1Þ
where η is a time constant and σ0 is the initial value of the
neighboring length. Furthermore, as can be represented by a
Gaussian function δ(t), the effect of learning gradually
decreases in magnitude from the BMU to the edge of the
neighborhood. On the other hand, the learning rate L(t) also
decreases over time as the learning process converges.
Consequently, every neuron within the neighborhood of
BMU has its weight vector adjusted according to the
following equation.
Wi t þ 1ð Þ ¼ WiðtÞ þ diðtÞLðtÞ V ðtÞ WiðtÞð Þ ð2Þ
if i BMUk k  sðtÞ where diðtÞ ¼ exp  iBMUk k
2
2s2ðtÞ
 
and
LðtÞ ¼ L0 exp  th
 
:
Note that V(t) denotes the input vector, i BMUk k
stands for the distance between the neuron i and the BMU,
and L0 is the initial learning rate.
The learning process converges after a number of
iterations, and the output neurons can be regarded as
representatives of all input vectors. In image segmentation,
this typical use of the SOM procedure can help to reduce a
wide range of colors to a few representative ones and to
identify corresponding segments. Nevertheless, there are
usually many noise pixels embedded in medical images,
and radical over-segmentation may result if the noise is
mistakenly selected to form output neurons. Consequently,
the direct use of the SOM technique for color segmentation
may not work well in all cases, especially those with
inherent noise.
Exploiting the self-organizing map for medical image
segmentation
To effectively segment medical images so as to identify
ROIs for further diagnosis, we propose an extensive
approach based on the SOM technique. The utilized two-
stage procedure is presented in “Two-stage SOM structure”.
Furthermore, additional steps that can be used to enhance the
feasibility of our approach are explored in “Featured steps of
our approach”.
Fig. 1 Two-layer structure of
the self-organizing map for
image segmentation
J Med Syst
Author's personal copy
ing ROIs in medical images. In this paper, we propose a
recursive merging method of in which smaller segments are
gradually merged into larger segments based on both the
local and the global information in the image. The most
similar segments can be merged with the aid of local
information. In additional, during each merging step, the
global information on the average segment size in pixels
can be utilized to determine where merging is necessary.
Figure 3 demonstrates this step conducted with an MRI
medical image. In practice, additional stop criteria for the
merging process can be introduced in accordance with the
preferences of radiologists.
Fig. 4 Testing medical images and corresponding segmentation
results using different color models: a. a brain MRI image with color
enhancement; b. a body X-ray image with color enhancement; c. a
breast ultrasound image with a cyst; d. a brain MRI image with
abnormal meninges; e. a breast X-ray image; f. a leg X-ray image with
an abnormal tribal bone
J Med Syst
Author's personal copy
21] is utilized, which considers the number and the
homogeneity of segments.
QðIÞ ¼ 1
10000 N Mð Þ
ﬃﬃﬃﬃﬃﬃ
NR
p

XR
i¼1
e2i
1þ logAi þ
NR Aið Þ
Ai
 2" #
ð3Þ
where I is the segmented image, N×M is the image size, NR
is the number of regions in the segmented image, Ai is the
area of the i-th region, e2i is the sum of the squared color
error in the i-th region, and NR(Ai) represents the number of
regions with an area equal to Ai. Note that the Q value
increases with the color error value. Also, the Q value
decreases based on NR Aið ÞAi when the segmentation results
contain too many regions (i.e., when over-segmentation
occurs). Consequently, a better segmentation technique
yields a smaller Q value when the same image is used.
On the other hand, it is meaningless to compare the Q
values with the segmentation results of different input
images. Q can be used as an objective measurement to
establish a benchmark for comparison purposes and either
adjust the segmentation approach further or evaluate the
quality of various approaches.
Feasibility of our approach
We utilize both the algorithm active contour and our
approach to segment the six testing images. The
corresponding results, which can be used to evaluate the
effectiveness of both approaches, are shown in Fig. 5. It is
clear that our approach yields better segmentation results.
In general, the active contour algorithm does not work well
with blurred regions and disjunctive objects (e.g., Fig. 5b
and e). On the other hand, all results as shown in Fig. 5
indicate that our approach can be used to properly identify
image segments. In addition, proper ROIs are identified by
using our approach. Specifically, in Fig. 5(a) through (f),
the ROIs of our testing images are the cerebrum and
cerebellum, the liver, the cyst, the abnormal meninges, the
lung lobes and the abnormal tribal bone, respectively. Note
that the effectiveness of image segmentation plays a crucial
role here; in our approach, each ROI is generated by
merging the corresponding segments.
To further indicate the usefulness of our approach, we
have tabulated the corresponding execution times, which
are reported in Table 1. Note that our approach is more
efficient than the competing approach in most cases.
Consequently, we can conclude that our approach is both
effective and efficient, helping us to process several types
of medical images.
Objective measurement of our approach
Here, we present the advantages of utilizing the proposed
two-stage SOM procedure according to quantitative studies.
For this purpose, we can compare the image segmentation
results achieved by utilizing the one-stage SOM [10, 22]
and revised two-stage SOM procedures. Without loss of
generality, the map size is 6×6 neurons for the one-stage SOM
procedure and 3×3 neurons for the two-stage SOM proce-
dure. All the images were tested five times; the corresponding
statistics are listed in Tables 2 and 3. Obviously, the
segmentation results achieved by using our revised two-
stage SOM approach are superior in terms of quality and
steadiness.
Last but not least, the usefulness of the proposed step
of eliminating the isolated pixels is evaluated here. As
previously mentioned, this step helps to improve seg-
mentation quality by removing noise that may limit the
use of local information in the second-stage SOM
process. All of the images were tested five times. The
average Q values of the test results with and without
using this step are reported in Table 4. It is clear that
eliminating isolated pixels creates better segmentation
results.
Table 2 Average Q values achieved when utilizing the one-stage and
two-stage SOM techniques for image segmentation
Image ID (a) (b) (c) (d) (e) (f)
One-Stage SOM 50.71 2721.43 2562.36 156.50 33.56 326.60
Two-Stage SOM 26.60 1571.68 34.36 10.40 19.48 61.86
Table 3 Standard deviations of the Q values achieved by using the
one-stage and two-stage SOM techniques for image segmentation
Image ID (a) (b) (c) (d) (e) (f)
One-Stage SOM 26.18 431.33 830.55 62.12 14.00 32.54
Two-Stage SOM 6.20 226.12 11.89 2.34 1.74 11.32
Table 4 Average Q values achieved by using our approach with and
without eliminating isolated pixels during the image segmentation
process
Image ID (a) (b) (c) (d) (e) (f)
Without the
Eliminating step
65.16 2814.84 2186.09 77.84 42.41 1413.24
With the
Eliminating
Step
26.60 1571.68 34.36 10.40 19.48 61.86
J Med Syst
Author's personal copy
Assessing Media Relevance via Eye Tracking 
Cheng-Ta Yang, Wen-Sheng Chang, Fan-Ning Cheng 
Department of Psychology and 
Institute of Cognitive Science 
National Cheng Kung University 
Tainan, Taiwan 
Wei-Guang Teng 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 
wgteng@mail.ncku.edu.tw
Abstract—To ease the problem of data overloading, it is crucial to 
understand the user behavior when s/he interacts with online 
contents, or more specifically, a web page containing several 
entries for further exploration. We devise to estimate the 
relevance of an entry to the user goal by observing eye 
movements as implicit feedback. Specifically, this study proposes 
a framework that assumes eye movement measures can be used 
to infer a user’s cognition. A rating task was conducted in which 
subjects were required to judge whether an image was relevant to 
a word. Results showed that the total fixation duration and the 
fixation count can be used to discriminate between the relevant 
and irrelevant conditions; in contrast, the first fixation duration 
cannot. In addition, the subjective rating and relevancy 
manipulation interacted on the total fixation duration. 
Converging evidence verifies the assumption we have proposed. 
Keywords-eye movement; social media; relevance feedback 
I. INTRODUCTION
As information and communication technologies are advancing, 
it is prevalent to use handheld devices such as mobile phones 
and tablets, in addition of conventional desktop computers. 
People can now easily surf the web, search for desirable 
information, and communicate with others almost anytime and 
anywhere. Thus, desirable information can usually be obtained 
within seconds. On the other hand, the use of web-based and 
mobile technologies to interactively create and exchange user-
generated contents motivates the popularity of the social media
[11]. In contrast to industrial or traditional media (e.g., 
newspapers, television, and film,) social media enable anyone 
to publish and share the thought, idea, and information online. 
Consequently, data overloading has become a crucial problem 
for online users as the data amount gathered on the Internet 
increases at an incredible rapid speed. 
When browsing a web page containing much unfamiliar 
information, one may have to spend significant efforts 
digesting all the contents. Then, s/he may read further material 
on another page by following the hyperlinks on the current 
page. More than a few such cycles are usually required until 
the user obtains satisfactory knowledge. An illustrative 
example is that a user can spend hours searching and reading 
relevant articles when planning a backpacking trip. Some 
previously unknown sites and facts can then gradually become 
familiar to him or her. In prior works, several possible 
improvements are suggested to provide visual cues [21] such as 
thumbnails [12][23] to facilitate the browsing process. The 
basic idea behind these approaches is that it is easier and 
quicker for users to understand a concept by glancing over 
pictures rather than reading textual contents. Moreover, recent 
developments of web search techniques also facilitate the 
browsing process undoubtedly. 
Nevertheless, a search engine usually delivers results which 
are syntactically similar but not semantically similar to the user 
query. Among a huge amount of search results, some entries 
are relevant to the user goals, but some are not. Consequently, 
it is usually a time-consuming process to generally browse all 
result pages. Additionally, note that users may iteratively 
change their direction of the query after gaining new 
knowledge from retrieved articles and clarifying their own 
thoughts. Thus, the modeling of user behavior patterns during 
the searching and browsing process has attracted significant 
research interests. Specifically, several issues of human-
machine interaction are addressed in prior works to improve 
the efficiency of web search applications [20][24]. 
In this work, our goal is to understand user cognition by 
observing eye moving patterns. Specifically, how user eyes 
move when browsing a web page which contains several 
thumbnails for different entries is tracked and analyzed. 
Example applications include glancing news articles, exploring 
comments on one's blog, and doing shopping online as 
depicted in Figure 1. Intuitively, one would pay more attention, 
i.e., with deep processing, on the image that s/he seeks for 
among many others. Otherwise, s/he would just pass through 
an irrelevant image with shallow processing. Also note that the 
search processes would not be terminated until enough 
information is acquired or all images are exhausted. In other 
words, different search patterns, i.e., eye movements patterns, 
are conducted according to the relevance degree as judged by 
the user. According to the literature of eye tracking [2][22], a 
variety of eye movement measures are considered in this work 
to infer the relevance degree of an image, e.g., total fixation 
duration, fixation count, first fixation duration, and saccade 
distance.
The rest of this paper is organized as follows. Preliminaries 
and related works are reviewed in Section II. Our approach on 
utilizing eye movements as an implicit feedback is illustrated in 
Section III. Empirical studies and general discussion are 
presented in Section IV and Section V, respectively. This paper 
concludes with Section VI. 
2011 International Conference on Advances in Social Networks Analysis and Mining
978-0-7695-4375-8/11 $26.00 © 2011 IEEE
DOI 10.1109/ASONAM.2011.122
722
a 19” LCD display with a vertical refresh rate of 75 Hz and the 
resolution of the monitor is 1024 x 768 pixels.  
Design and stimuli. Subjects were required to rate the 
relevancy of each word-image pair. The words and images 
were classified into four categories, including animal, building, 
natural scene, and transportation, all downloaded from Flicker 
(an online photo sharing application). Each category contains 
twenty images. An image was paired with three words 
uploaded by the anonymous users describing the image. For 
example, a koala (image) is paired with three words, such as 
gray, sleepy, and lazy. Each image was 800 (horizontal) x 600 
(vertical) pixels. Each word contained 2 - 4 Chinese characters 
and each character was 40 (horizontal) x 40 (vertical) pt.
Each trial was composed of an image and a word in a 
display (See Figure 2 for an illustration of the arrangement of 
the image and word). One within variable (relevancy of a 
word-image pair) was manipulated. In the relevant condition 
(see Figure 2(a)), the words and images were paired as those 
uploaded by the anonymous users. In the irrelevant condition 
(see Figure 2(b)), the image was chosen from one category, 
and the word was randomly selected from the word pool of 
another category. There were a total of 480 trials. Half were 
relevant pairs and the other half were irrelevant pairs. 
(b)
(a)
Figure 2. An illustration of the arrangement of the word and image used in 
the experiment. (a) Relevant condition: the koala (image) is relevant to “gray” 
(word), and (b) irrelevant condition: the hippopotamus (image) is irrelevant to 
“transportation” (word). The eye movement data of a subject were shown in 
the figures with red circles representing the fixation points and red lines 
representing the scan path. 
Procedure. Subjects performed the rating task in a dark 
room at a viewing distance of 60 cm (see Figure 3 for the setup 
of the experiment). They were asked to press the keyboard to 
rate the relevancy of each word-image pair using a 6-point 
Likert type scale, with 1 representing the most irrelevant pair 
and 6 representing the most relevant pair. Throughout the 
experiment, the speed was not emphasized. It took about 30 
minutes for a subject to complete the experiment. 
tobii X60
60 cm
30Ʊ
Figure 3. The subject was required to sit down in front of the monitor at a 
viewing distance of 60 cm. The Tobii X60 eye tracker was placed in front of 
the monitor and the angle of elevation was set as 30°. 
Dependent variables. We collected the rating score and 
response time for each trial. The rating score reflects one’s 
subjective opinion regarding the relevancy of a word-image 
pair. The response time was recorded from the stimulus onset 
until a response is made.  Response time indicates how long it 
takes for a subject to make a response in a trial.  
In addition to recording behavioral responses, we recorded 
subjects’ eye movements. In a typical eye-tracking experiment, 
eye movement switches between a relative still state (fixation) 
and a fast moving state (saccade). Visual information of an 
object or a region is encoded and accumulated only when a 
subject fixates on that object or region. During saccadic eye 
movements, no information can be encoded and accumulated. 
Therefore, to understand how many times and how long a 
subject spent on an object or a region can reveal to what extent  
s/he is interested in the object or region. In this experiment 
(see Figure 2 for an example of the scan path), three indexes 
were considered. (1) The first fixation duration: the duration of 
the fixation on where a subject first looks. (2) The fixation 
count until response: the number of fixations counted from 
stimulus onset to subject response in a given trial. (3) The total 
fixation duration (also termed the gaze duration): the sum of 
the duration of all fixations in a given trial. 
IV. RESULTS AND DISCUSSION
There were a total of 2893 and 2910 valid observations in 
the relevant and irrelevant conditions, respectively. Figure 4 
plots the frequency distribution as a function of the subjective 
rating score in the relevant (blue bar) and irrelevant (red bar) 
conditions. These results verified the manipulation of 
relevancy. The word-image pairs uploaded by the anonymous 
users were judged more relevantly compared to those 
724
irrelevant (rating score = 3 and 4), the total fixation duration 
was generally longer than the other conditions. It is likely that 
information is too ambiguous for a decision, that more total 
fixation durations were required. 
When the irrelevant pair was shown, subjects generally 
responded very fast regardless of their subjective feeling about 
the relevancy of an image (Figure 5(c)). Consequently, 
observing short total fixation duration of judging the irrelevant 
pairs the most irrelevant is reasonable. Subjects made an 
irrelevant decision after they glanced at the image without any 
further processing. However, it is unclear why the total 
fixation duration while judging irrelevant pairs the most 
relevant was so short. We speculated that the short total 
fixation duration was observed due to the extraneous variable, 
such as the fast error in the relevancy judgment. The number 
of responses in that condition was rare (0.03% of data points). 
The error in decision is usually observed under time pressure 
or in an uncertain context, resulting in fast error reaction time. 
(a)
(b)
Figure 6. The empirical distribution functions of the total fixation duration 
as a function of the subjective rating score [rating score = 1 and 2 (red), 3 and 
4 (green), and 5 and 6 (blue)] in (a) the relevant condition and (b) the 
irrelevant condition. 
V. GENERAL DISCUSSION
In this study, we examined whether eye movement 
measures can reveal the relevancy of a word-image pairs. 
Subjects were required to rate the degree to which an image 
was relevant to a word. When they performed the rating task, 
we recorded their eye movements as well as their behavioral 
responses.
The answer is “yes”. The current results showed that the 
total fixation duration (gaze duration) and the fixation count 
can be used to distinguish the relevant condition from the 
irrelevant condition. These measures can indicate the user’s 
cognition about the relevancy of an image. When a relevant 
pair was shown, subjects generally spent more time with 
longer total fixation duration and more fixations on processing 
the image than when subjects viewed an irrelevant pair. There 
were no such differences in the first fixation duration between 
the two conditions. These implied that the differences in the 
user behavior were observed due to the iterative search 
processes.
These results supported our hypothesis which states that 
after a brief scan, subjects spend more time and fixations on 
the image relevant to the word with deep processing. If the 
image was irrelevant to the word, subjects would make an 
irrelevant decision with shallow processing. Therefore, it is 
plausible for us to incorporate the gaze data into online 
analysis and feedback to the search engine. The search engine 
can refine the search results based on the relevancy analysis. 
After few iterative processes, the search engine can return a 
result that matches the thought in a user’s mind. This 
framework does not require a user to generally browse all the 
result pages, leading to an efficient browsing process.  
A previous study has also incorporated eye movement 
measures as data input to a new technique for image retrieval 
[14]. They proposed that eye movement measures can help a 
data base select an image that subjects are interested n and 
extract the image properties for image retrieval. In their study, 
subjects were required to search for a pre-defined target image 
among thousands of photos. The subjects’ eye movements 
were recorded and analyzed online. When the sum of fixation 
duration on a photo exceeds a cut-off criterion, the display will 
retrieve a photo that shares visual properties from the database 
with that one. After a successive viewing, the pre-defined 
target image will be retrieved. Using this technology, it took 
less time in retrieving the pre-defined target image compared 
to the technique that randomly retrieves a photo from the 
database. However, in their study, the relevance between 
images was primarily defined by similarity derived from low-
level visual properties. In addition, their subjects were required 
to search for a pre-defined target in every trial. In real world 
situations, a user does not necessarily have a specific target in 
mind, and the relevance between images is usually semantic-
based instead of feature-based. Unlike the previous study [26], 
this study demonstrated the possibility that eye movement 
measures can reveal the semantic relevancy between a word 
and an image. Thus, we considered that the eye movement 
measures can be applied into a context that requires a 
semantic-based informational search.  
The current findings can be applied to extract the semantic 
relevancy in many domains. Let’s look at the trip-planning 
scenario. A user searches for traffic information about a city by 
surfing the web. It is annoying that a lot of irrelevant 
information is accompanied by the relevant information. 
Applying our framework, the search engine can filter out the 
irrelevant information and make the results converged into the 
most relevant ones. In addition, this framework can also be 
used in social networking. When a user browses through 
726
DISCOVERING VISUAL-CONCEPTS OF ONLINE IMAGES FROM 
ASSOCIATIONAL IMAGE PATCHES 
Ya-Shin Chian and Wei-Guang Teng 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 
wgteng@mail.ncku.edu.tw 
 
ABSTRACT 
With the advance of networking technologies, the 
widespread use of handheld devices not only enables 
instant access of required information but also shortens the 
distance among acquaintances. Nowadays one can easily 
share their photos on the Internet right after the photos are 
taken. With an increasing amount of images, a challenging 
problem for computer algorithms is to discover the visual-
concept embedded within an image. Instead of modeling 
this problem as a classification process which attempts to 
categorize images into different pre-defined classes, we 
propose in this work to start with identifying similar image 
patches. Specifically, we adopt the technique of mining 
association rules to construct evident relationships among 
image patches so as to discover identical visual-concepts 
from online images. 
1. INTRODUCTION 
As the technology of consumer electronics and mobile 
computing advances, the usage of handheld devices is of 
increasing growth in recent years. Moreover, establishing 
social relationships and communicating with friends on 
the Internet also becomes much easier. These facts 
significantly change user habits in several aspects. One 
illustrative example is that many people take photos 
whenever they want and wherever they want with their 
digital cameras or mobile phones. Then, these photos can 
be uploaded immediately to share among friends in their 
web albums or blog spaces. Consequently, the Internet 
undoubtedly forms the largest archive containing a variety 
of image data. 
It is usually a trivial task for human beings to "read" 
images or more specifically to understand the scene 
embedded in an image within seconds. On the contrary, it 
is quite difficult for computer algorithms to reach the same 
capability. A crucial issue behind this is the so-called 
semantic gap [10]. Specifically, there is usually weak or 
no correspondence between low-level image features, e.g., 
colors, shapes and textures, extracted by computer 
algorithms and high-level conceptual interpretations 
perceived by human users. To bridge this gap, many 
researchers have been working to propose several different 
approaches. It is thus easily understood that without a 
proper scheme, manually handling a large number of 
online images is obviously a labor-intensive and error-
prone task. 
In this work, we aim at discovering visual-concepts from a 
collection of online images. This objective is similar to 
that of a scene detection task in capturing the "gist" of an 
image. In a typical process, training examples are provided 
to help the recognition of objects or the overall scene 
contained in a new image. Also, recognition results are 
presented by classifying images into pre-defined scene 
categories. This process may work well in a static dataset 
but fails to learn new objects or scenes in a continuously 
growing image archive, e.g., the Internet. Alternatively, 
we propose to start with identifying the relationship 
between two image patches (or regions) from two different 
images. This help to consolidate the basis of discovering 
identical visual-concepts from online images, especially 
when a collection of the images are shared among 
community members, e.g., friends, relatives or colleagues. 
To estimate the similarity of two image patches with a 
comparison technique is a fundamental and core issue to 
many computer vision problems. In view of this, we 
propose to introduce the concept of visual words in this 
work. Note that visual words are not real words, but rather 
summarize local patches of the image to describe some 
details, i.e., a corner, texture, or point [10]. Furthermore, 
the well-known data mining technique of association rules 
[2] is adopted to identify evident relationships of image 
patches that can help to constitute a specific visual-
concept, e.g., the Santa, reindeers and stockings imply a 
Christmas scene. 
The rest of this paper is organized as follows. 
Preliminaries and related works are generally reviewed in 
Section 2. Techniques of visual words and association rule 
mining used in our scheme to discover visual-concepts 
from online images are explored in Section 3. Empirical 
studies to show the feasibility of our proposed scheme are 
conducted in Section 4. Finally, this paper concludes with 
Section 5. 
2011 IEEE 15th International Symposium on Consumer Electronics
978-1-61284-842-6/11/$26.00 ©2011 IEEE 218
association rule mining to identify co-occurrences of 
visual words in a collection of images. Note that if some 
visual words frequently co-occur in more than a few 
images, these visual words together may indicate a 
specific scene. 
Visual 
Words
Frequent 
Itemsets
ImagesInternet
Feature 
Quantization
Feature 
Extraction
Association 
Rule Mining
ExplorerDatabase
Conceptual
Groups
 
Figure 2. Proposed scheme for discovering visual-
concepts of online images. 
To concrete the above concept, we propose a scheme 
whose flow is as shown in Figure 2. Specifically, our 
scheme can be divided into several parts to be illustrated 
as follows. 
• Online Images: Images collected from web albums 
or blog spaces are taken as inputs of the proposed 
scheme. One can easily notice that these images 
are very likely to share common visual-concepts 
as they are shared among acquaintances of 
common interests. 
• Explorer: Several processing steps are conducted 
in this part. First, features are extracted from each 
input image. Then, these features are quantized 
into visual words. Finally, the technique of mining 
association rules is applied. 
• Database: In the database, images collected from 
the Internet, visual words quantized from features, 
and the discovered frequent itemsets are stored. 
• Conceptual Groups: Images containing similar 
visual-concepts are grouped together. This 
facilitates the execution of an image retrieval task. 
 
4. EMPIRICAL STUDIES AND 
DISCUSSIONS 
In our preliminary experiments, we firstly collect a set of 
100 photos representing four different festival scenes, i.e., 
St. Patrick Day, Easter, Halloween, and Christmas. Some 
example images of this dataset are shown in Figure 3. This 
image dataset is then used in our experimental process for 
evaluation purposes. 
 
Figure 3. Example images of the festival dataset. 
Our experimental process is depicted in Figure 4. The 
upper part of Figure 4 shows the training process that all 
images are carefully processed through necessary steps. 
Specifically, feature vectors are firstly extracted from an 
image. Then, visual words are formed after the feature 
quantization step. Frequent itemsets can thus be 
discovered by utilizing the technique of association rule 
mining. Finally, several conceptual groups can be obtained. 
With the festival image dataset, about 20,000 features and 
500 visual words are generated. Moreover, more than 
450,000 frequent itemsets are obtained when the minimum 
support, i.e., co-occurrence frequency, is set to be 10%. 
Also, the maximum length of discovered frequent itemsets 
is 5. In other words, there are usually up to five visual 
words co-occurring in images of a similar scene. Based on 
these results, two example conceptual groups, i.e, the 
Christmas scene and the Easter scene, discovered by our 
approach are shown in Figure 5(a) and Figure 5(b), 
respectively. 
An example scenario of utilizing our proposed scheme for 
image retrieval is also shown in the lower part of Figure 4. 
Once a user takes and uploads a photo with his or her 
smart phone, digital camera or even tablets, similar 
processing steps can be done to identify corresponding 
visual words of this image. With a proper matching 
mechanism, images containing similar visual-concepts can 
be retrieved even if these images are not so similar in 
terms of low-level features. To further illustrate the 
scenario as shown in the lower part of Figure 4, one can 
easily understand that the corresponding visual-concept is 
the Christmas. Several image patches with strong 
associations, e.g., Christmas stockings, candy canes, and 
gingerbread man, are found in the images belonging to the 
same conceptual group. By further devising a more 
interactive interface, human users may not only perform 
retrieval tasks but also help to annotate corresponding 
images. 
220
INCORPORATING LOCALIZED INFORMATION WITH BROWSING HISTORY 
FOR ON-DEMAND SEARCH 
Wei-Hsun Wen, To-Yeh Huang and Wei-Guang Teng 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 
wgteng@mail.ncku.edu.tw 
 
ABSTRACT 
Nowadays more and more people access the Internet with their 
accompanying mobile devices. Performing web search 
activities anytime and anywhere thus becomes common. As 
compared to the ones sitting in front of their PCs, mobile users 
often search for something which is closely relevant to his or 
her current context, e.g., location and time, or of specific 
requirements. We define this kind of web searches as the on-
demand search in this work. In view of the possible 
difficulties encountered in practice, we propose to introduce 
both browsing history and localized information when 
handling on-demand searches of a mobile user. Consequently, 
user demands can be better understood so that more 
personalized results can be integrated, delivered and visualized. 
On the other hand, features of social interaction are also 
addressed. For example, nearby friends could be informed and 
invited to join activities of common interests. Better user 
experience can thus be achieved among members of a mobile 
community. 
1  INTRODUCTION 
As the Internet grows rapidly nowadays, better access to 
information and wireless communication technology reforms 
our daily life impressively. As reported by Google, the traffic 
of mobile searches grows five times from 2008 to 2010 [6]. It 
is now prevalent to access the Internet without time and place 
limitations. Other than mobile phones, some other handheld 
devices such as PDAs and Tablet PCs also provide Internet 
capabilities. Thus, connecting to the Internet to communicate 
with friends and to look for desired information at anytime and 
anywhere becomes a commodity. 
According to previous studies, however, people have less 
inclination conducting web searches and browsing details on a 
handheld device due to its dimensional limitations [10][9]. 
Part of the reasons is that search engines are originally 
designed for users on desktop computers [4]. With the 
widespread of mobile surfing, how to improve the feasibility 
for mobile users to conduct web searches becomes a crucial 
issue. In addition, more and more service providers and 
researchers have spent significant efforts customizing web 
applications for mobile users. 
On the other hand, web searches can be further categorized 
according to different user goals [1]. Specifically, the process 
of navigational and transactional searches are rather simple 
since the search targets can be clearly formulated as definite 
keywords. Nevertheless, when looking for unfamiliar 
information so as to understand or learn some more 
knowledge, the search process tends to be very complicated. 
For example, one can easily understand that to plan a 
backpacking trip by searching and browsing web pages is not 
a trivial task. To extend this idea, we define the “on-demand 
search” in this work as the web searches under special 
circumstances, e.g., location and time, or of specific 
requirements from the mobile user. For example, users may 
demand the information of nearby restaurants, 
accommodations, transportation, or recreation areas. 
A motivating example is illustrated as follows. After a white-
collar worker has his dinner near the office after work, he 
plans to find a place to enjoy a few hours of his leisure time. 
Nevertheless, he is a coffee addict and wants to taste the “Kopi 
Luwak” (a special kind of coffee) today. In addition, he also 
needs the Internet access since he has been planning a trip in 
the coming holidays for a long while. One may easily 
understand that all these thoughts may not be satisfied 
simultaneously when he finally enter the keyword “coffee 
shop” to start a web search on his smart phone. A typical 
scenario is that this user has to quickly read all the entries of 
the search results and probably needs some more web searches 
to obtain a satisfactory answer. How this mobile search can be 
accomplished more efficiently and effectively then becomes 
the main issue to be addressed in this work. 
As described in the above example and other similar cases, 
often the searcher himself does not know what the search 
target is. Specifically, how the query terms can be precisely 
specified without filtering out desirable results is another 
challenge. As a result, more efforts are required, such as to 
browse through each website, to filter out unnecessary 
information, to memorize the best answer until now, etc. We 
thus propose in this work to utilize both the browsing history 
and localized information to facilitate on-demand searches 
conducted by mobile users. Namely, personal preferences, life 
patterns, and recent activities can be estimated once the  
browsing history of a user is obtained. On the other hand, 
localized information which is consistent with current 
circumstances of the mobile user does help. In other words, 
even a simple query may result in huge amount of search 
results, all user criteria as derived above can be used to 
identify a proper subset of desirable results. 
In this work, we focus on how to improve the feasibility of on-
demand searches for mobile users. Moreover, the features of 
2011 IEEE 15th International Symposium on Consumer Electronics
978-1-61284-842-6/11/$26.00 ©2011 IEEE 14
Browsing 
History
POS Tagging
Filtering for 
Nouns
Document
Document
Document
TD-IDF
Calculation Term
List
Terms and Weights
 
Figure 2. Process of generating a term list from the 
browsing history. 
Specifically, the TF-IDF technique which is widely adopted in 
information retrieval can be formulated as Equation (1). 
idf
N
ijtfijW log×=                                   (1) 
where Wij is the weight of term i in document j, tfij is the 
occurrence frequency of term i in document j, N is the number 
of documents in the corpus, and dfi is the number of 
documents where term i occurs at least once. 
The term list provides terms and corresponding weights that 
can be used to calculate the degree of preference for each entry. 
By analysing title and snippet of an entry, we can calculate the 
summation of weights of the terms that exist in the term list. 
The score represents the degree of relevance of the current 
entry to the browsing history of the user. Thus, with this 
relevance evaluation and localized information, we can re-rank 
the original search results for a user to better satisfy his or her 
needs.  
We present the adjusted search results of the following order. 
First, entries that conform to user’s localized information are 
presented in higher ranks as compared to those in other 
location. Moreover, for both two section of location-matched 
and location-unmatched, sort the entries form high weight to 
low. In general, the first entry of re-ranked results that 
recommended to the user will be in the location of user’s 
position. Also this entry will best fit the user’s appetite, since 
it is the most relevant search result to the user’s browsing 
history. 
On the other hand, since it is a growing trend of implementing 
social interaction features for mobile searches, we would like 
to enhance user experiences through social factors. When a 
user performs web search, our scheme shows nearby friends of 
the user in the result pages. Note that the information of 
friends may be obtained from online social network services 
such as Facebook, Myspace, or Twitter. Due to the nature of 
mobile devices, users could utilize our scheme to find 
something interesting, and then discover nearby friends.  
This concept could be best used at sharing information of 
recreation and necessaries with friends in social network, such 
as delicacies, clothes, accommodation, and transportation. 
Afterwards, users could invite friends joining for further 
gathering. For example, a user performs mobile search for 
restaurants. Firstly, our scheme could recommend nearby 
restaurants that suit his or her appetite. Subsequently, our 
scheme displays the nearby friends of his or her social network. 
The user could than invite these friends to join him or her. It is 
believed that this feature could influence user experience 
positively. 
4  A SCHEME FOR ON-DEMAND SEARCH 
To extract the information from browsing history and 
localized information, we propose a scheme as shown in 
Figure 3. Note that the social interaction factors are also 
included in this scheme. Specifically, the proposed scheme is 
divided into five components, i.e., interactive interface, 
database, social data collector, browsing history miner, and 
localized information extractor. Details of these components 
are illustrated as follows. 
Interactive Interface
QueryFeedback
Raw DataAnalyzed Results
O
nline Social N
etw
o
rk
 Se
rvice
s
User Identity
Information of 
Nearby Friends
Browsing History Miner Localized Information Extractor
Analyze User Cognition to 
Construct Framework
Provide Environmental 
Information
Database
Social Data
Collector
 
Figure 3. Proposed scheme for on-demand search. 
 Interactive Interface: Users could input queries and 
acquire search results from the interface like traditional 
search engines. The nearby friends’ information is also 
presented on the result pages. Besides, we provide 
interactive functions and visualize the search results 
presented here. 
 Database: Database records the raw data of browsing 
history and the contents of each browsed web pages for 
further processing. The location information is also 
stored for further usage. 
 Social Data Collector: Social data collector helps to 
retrieve the information of nearby friends. This can be 
done by utilizing the application program interface (API) 
provided by current online social network services. 
 Browsing History Miner: This component collects all 
browsed pages of a user and generates a term lists as 
mentioned in previous sections. Thus, original search 
results can be re-ranked to emphasize entries that the 
user may be interested in. 
 Localized Information Extractor: This component 
helps to extract the localized information so as to filter 
out search results which are irrelevant to the user context. 
It is also used to discriminate nearby friends of a user. 
16
AN ENHANCED RECOMMENDATION SCHEME FOR ONLINE GROCERY 
SHOPPING 
Yi-Jing Wu and Wei-Guang Teng 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 
wgteng@mail.ncku.edu.tw 
 
ABSTRACT 
Online grocery shopping becomes more and more popular 
in recent years. To facilitate the purchase process, many 
online stores provide a shopping recommendation system 
for their consumers. So far, the generic recommendation 
systems mainly consider preferences of a consumer based 
on his/her purchase histories. Nevertheless, it is noted that 
there is nothing to do with the right timing to purchase a 
product from the view point of product replenishment or 
economic purchasing. Hence, we develop a new 
recommendation scheme especially for online grocery 
shopping by incorporating two additional considerations, 
i.e., product replenishment and product promotion. We 
believe that such a new scheme should be able to provide 
a better recommendation list which fit consumer desires, 
needs, and budget considerations and finally boost 
transactions. 
1. INTRODUCTION 
Grocery shopping is undoubtedly one of the most frequent 
and necessary works of every family. However, as the life 
pace becomes faster and faster, people are less likely to 
spend time and energy on doing it. Fortunately, thanks to 
the vigorous development of e-commerce, people are now 
able to fulfill this work through online shopping. 
Moreover, people can use not only computers but also 
various types of handheld devices, e.g., PDAs, smart 
phones and tablets, to surf websites so as to do their 
shopping easily as information technology advances 
recently. As a result, shopping groceries online becomes 
more and more popular. Under such circumstance, how to 
make online purchasing quick and efficient becomes a 
vital issue in e-commence. 
In view of this, most online stores provide a shopping 
recommendation system for the consumers to facilitate 
online shopping. The core of such systems is a 
personalized recommendation algorithm. This algorithm 
models consumer shopping behaviors and recommend 
items to the consumers while doing on-line purchasing. 
Since there is no explicit product rating available for 
grocery shopping, the system has to estimate consumers’ 
preferences from their purchased histories. One of the 
major techniques used to develop a recommendation 
algorithm is collaborative filtering (CF). Nevertheless, the 
problem of sparsity due to too few user ratings may make 
the formation of neighborhood inaccurate and thereby 
results in poor recommendations. 
In this work, a methodology based on random walk and 
bipartite networks [9] is utilized and adapted to alleviate 
the problem of sparsity. To the best of our knowledge, 
conventional models cannot be directly applied in our 
target application of grocery shopping. Some other factors 
should also be considered. For instance, most products in 
grocery stores are daily necessities which are consumable 
and are purchased periodically. Therefore, product 
replenishment must also be considered in addition to user 
preferences. Besides, in real life, product price strongly 
affects consumers' purchase willingness, especially for 
budget consumers. Therefore, product promotion plays a 
very important role for decision-making. In other words, 
one may easily understand that a recommendation system 
without considering product promotion is not practical for 
the application of grocery shopping. 
Regarding the issues mentioned above, we develop a 
novel grocery shopping recommendation scheme by 
incorporating two additional considerations, i.e., product 
replenishment and product promotion, with the generic 
recommendation system which considers about product 
similarities and individual interest only. In addition, to 
enhance the estimation of a consumer’s individual interest 
in this work, we divide consumer online purchasing 
behaviors into three steps of “viewing the product 
informationĭ” “adding product to shopping basket” and 
“purchasing productį” Such a new scheme should be able 
to provide a more appropriate recommendation list which 
fit consumer desires, needs, and budget considerations. 
The rest of this paper is organized as follows. 
Preliminaries and related works are reviewed in Section 2. 
Our proposed methods and scheme used to estimate 
consumers’ preference are introduced in Section 3. The 
prototyping of our proposed recommendation system for 
on-line grocery shopping is explored in Section 4. Finally, 
this paper concludes with Section 5. 
2011 IEEE 15th International Symposium on Consumer Electronics
978-1-61284-842-6/11/$26.00 ©2011 IEEE 410
Thus, by introducing the random walk approach, how 
much a specific consumer likes a product can be generally 
estimated. 
Secondly, most daily necessities are consumable and are 
targets of grocery shopping. Therefore, consumers may 
buy the same product repeatedly. This is regarded as 
“product replenishment.” Note that consumable products 
normally are with a constant consumption rate. People 
then have to purchase them periodically. When something 
is going to be exhausted, the purchasing intent of a 
consumer becomes firm. In this work, we thus propose a 
statistical model to estimate this factor of product 
replenishment. 
Finally, a most common strategy to increase the sales of a 
product is promotion. People always like to do their 
purchases at a reduced price. Therefore, to consider the 
effect of product promotion in the recommendation system 
is necessary. Specifically, we model the degree of product 
promotion as well as the customer sensitivity of money 
saving to estimate the willingness for a consumer to buy a 
specific product. 
3.2 Estimation of Consumer Preferences 
As mentioned in previous sections, product similarities 
can be calculated based on the weights of all edges in a 
bipartite network. Suppose a matrix of product similarities 
P is obtained, the random walk approach is then utilized. 
Equation (1) is iterated to obtain the ranking scores for all 
the products based on the current items in the consumer’s 
basket [9]. 
 basketbasketbasket URPR ⋅−+⋅⋅= d)(d 1          (1) 
In Equation (1), Rbasket is the basket-based ranking score 
vector used for ranking all the products, and the i-th entry 
of the initial vector Ubasket = 1/m, if the i-th product is in 
the basket and 0 otherwise, d ⊂ (0, 1) is a damping factor, 
and m is the number of products in the current basket. 
Since the ranking score vector Rbasket coming out from 
iterations of Equation (1) is based on the products in the 
basket, therefore, two consumers with the same content in 
their baskets have same items-list to be recommended. 
This situation is unreasonable from the view point of 
consumer personalization. In order to provide personalized 
recommendations to a consumer, the vector of individual 
interest is assigned with different weights as compared to 
Rbasket. Namely, the individual interest vector I of a 
specific consumer is calculated by Equation (2). 
  ( ) ( )( )
( )
( )
( )
( )








⋅
+
⋅
+
⋅
=

  , 
, 
  , 
, 
  , 
, 
3
1, 
kp
ikp
kb
ikb
kv
ikv
ik
cN
pcN
cN
pcN
cN
pcN
pcI (2) 
To formulate Equation (2), the on-line purchasing process 
of consumer k is divided into three stages of “viewing the 
product information,” “adding product to shopping 
basket” and “purchasing product” [4]. Nv is the number of 
consumer k to viewing the product i. Nb is the number of 
consumer k to adding the product i to shopping basket. Np 
is the number of consumer k to purchase the product i. 
Therefore, I(ck , pi) is the interest vector of consumer k 
with product i. In conclusion, consumer preference CP1 is 
obtained by summing up Rbasket ranking scores vector and 
individual interest vector I. 
The probability density distribution for a consumer to 
replenish a consumable product as function of the time 
interval t between two consecutive purchases to the same 
category of products can be a gamma distribution [2][14]. 
The probability density function of a gamma distribution 
can be formulated as Equation (3). 
 ( ) ( ) 0,
1,; 1 ≥
Γ
==
−− xextXf x βα
α αββα     (3) 
In Equation (3),  is the shape parameter and  is the scale 
parameter. In this study, we calculate the averaged 
purchase time interval of a particular product, parameters 
of  and  based on consumer’s purchased histories. Then 
we input these values to the developed model of gamma 
distribution to do computation and get the probability of 
purchase to the same product in this visit. Here, the 
probability of purchase is the consumer preference CP2. 
This probability is based on the condition that this 
particular product has not been purchased for t days so far. 
In practice, a consumer may purchase different amount of 
a product at each purchase. Therefore, it is very important 
to consider the average purchase amount and the average 
purchase interval. 
Note that product price as well as money saving strongly 
affect the purchase willingness of a consumer. But these 
factors are not considered in conventional shopping 
recommendation systems. With the absence of these 
factors, the shopping recommendation system could not 
provide precise recommendations to the consumers, 
especially to the budget consumers. Hence, in this work, 
we model the effect of these two factors, price and money 
saving, to be the third part of consumer preference CP3. 
The willingness of purchasing a product on promotion is 
relevant with the discount rate (D) of a product and the 
consumer’s sensitivity (S) of money saving. As some 
products are often on sale and some others are seldom 
discounted, both the actual money saving and the average 
price should be taken into consideration when calculating 
the discount rate (D) of a product. For example, a product 
with an original price of $100, but it is quite often to be 
sold with a discount rate of 10%. Moreover, the average 
412
4. PROTOTYPING OF PROPOSED 
RECOMMENDATION SCHEME 
A prototype of the proposed scheme is introduced in 
Section 4.1. In addition, a case study is provided in 
Section 4.2. 
4.1 Prototyping of an On-line Grocery 
Recommendation System 
In this work, we develop a prototype of the proposed 
scheme to facilitate the empirical studies. Note that 
product information are obtained from real online stores. 
Consumers can thus browse the up-to-date information of 
all real products. The user interface is as shown in Figure 
3. A consumer can search for interested product or select a 
product category to begin his/her browsing and online 
purchasing. A significant difference of our scheme from 
generic online stores is that our website considers not only 
the individual interest, but also the product replenishment 
as well as money saving for customers.  
Total Amount 
Shopping 
Product Page 
Store Name & Corresponding Information 
Personal 
Recommendation 
List
Search 
Engine
Product
Categories
Popular 
Products
My Basket
Consumer
Center
 
Figure 3. The user interface of proposed on-line 
grocery recommendation system. 
When the consumer starts a shopping session, the 
shopping basket is empty. Consumer preferences CP1 have 
no value. Therefore, our scheme sums CP2 and CP3 up 
together to get the overall preference ranks and then 
selects top five products to make recommendation. 
Subsequently, the consumer put the milk into shopping 
basket. The proposed scheme computes CP1 based on the 
current basket and the purchase histories. Thus it can be 
seen that milk and toast are most frequently purchased 
together. However, the consumer purchased milk even two 
days before. The system compute the rank of CP2 for toast 
is low. Besides, the rank of CP3 for toast is also low. 
Consequently, toast is not recommended. This example is 
further illustrated in Figure 4. 
Rank CP1 CP2 CP3
1 Toast Yogurt Bread
2 Cereal Cereal Soap
3 Yogurt Rice Cheese
4   Bread Cheese Jam
5 Jam Toilet paper Yogurt
6 Cheese Bread Rice
7 Coke Jam Toilet paper
8 Soap Toast Cereal
9 Toilet paper Coke Toast
10 Rice Soap Coke
Rank CPf
1 Yogurt
1 Bread
3 Cereal
4   Cheese
5 Jam
Current Basket
Recommendation
List
 
Figure 4. An example for providing recommendation list 
by combining three consumer preferences 
4.2 A Case Study 
A common event in our daily life is taken as an example to 
illustrate the feasibility of our scheme. A consumer, Mrs. 
Lin, is a busy housewife and used to purchase daily 
necessities from online stores. Assume that Mrs. Lin visits 
a conventional online grocery store on 2011-04-25 that is 
flooded with product information and promotion plans. 
Also, only popular products or products which are most 
frequently purchased by her are recommended. Suppose 
all these recommended products are as listed in Table 1. 
There is a potential problem in this case. We can observe 
from Table 1 that she just bought milk and toilet paper 
three days ago. Therefore, there is low probability that 
Mrs. Lin runs out of these two products and needs to 
purchase them again at this time. In other words, to 
recommend milk and toilet paper to Mrs. Lin for 
purchasing at this time is inappropriate. Besides, this store 
may already launch promotional plans for some products 
at this moment.  But there is no way to notify Mrs. Lin. 
Once our scheme is introduced in this scenario, the 
problem as mentioned above can be eased. Specifically, 
the consumer preference CP1 is firstly estimated according 
to the purchasing logs of all consumers. Thus, products 
with the highest values of CP1 are listed. Suppose that 
these products are identical to the ones as shown in Table 
1. Then, further calculation based on the factors of product 
replenishment (CP2) and product promotion (CP3) are 
performed. After all these products are ranked according 
to the value of CP1, CP2 and CP3, respectively, the overall 
ranking score can be obtained by summing up these three 
individual rankings. Finally, as shown in the last two 
columns of Table 1, coke and cereal are the top two 
products to be recommended. On the other hand, milk and 
toilet paper are the top two products which are unlikely to 
be purchased among these six products. 
414
An Incremental SVD-based Scheme for Large-scale 
Recommendation Systems 
 
Kun-Fa Lin and Wei-Guang Teng 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 
wgteng@mail.ncku.edu.tw 
 
 Abstract - Online shopping is becoming a common activity 
for more and more people in their daily lives. In an online store, 
numerous types of items are provided for users that results in 
large amounts of transaction and rating data. Recommendation 
systems analyze these past transaction patterns or rating data to 
provide personalized recommendations for users. Among several 
alternatives, matrix factorization algorithms such as singular 
value decomposition (SVD) can potentially be used for generating 
predictions in a more precise way. However, conventional SVD-
based approaches suffer one serious limitation that recomputing 
the SVD of rating matrix is computationally very expensive. To 
adapt to the huge amount and rapid change of both user and 
item information in an online e-commerce environment, we thus 
aim at developing an incremental SVD scheme for generating up-
to-date user-item rating predictions when streams of new rating 
data come in. Through our incremental scheme, the user-item 
rating matrix is directly updated by making use the existing 
result of SVD. Empirical studies show that our approach is 
efficient to be utilized in practical applications. 
 
 Index Terms – Incremental update, large-scale data, 
recommendation system. 
 
I.  INTRODUCTION 
 Nowadays, people can easily purchase various types of 
items at online stores. Nevertheless, in order to meet the 
special tastes and needs of consumers, electronic retailers 
provide a numerous selection of items, whereas consumers are 
usually inundated with possible choices. Moreover, people 
always encounter the problem of information overloading on 
the Internet since thousands of new advertising messages are 
posted every day. Consequently, the development of 
recommendation systems has attracted a surge of research 
interests in recent years. Specifically, a recommendation 
system may analyze previous rating data, transactions, user 
behavior, or opinions from users to provide personalized 
recommendations that match a user’s preference. In our 
recommendation applications, it generates rating predictions 
mainly based on analyzing the rating data. 
 Many recommendation systems are based on the 
collaborative filtering (CF) technique, which relies on 
analyzing previous item ratings provided by all the users. 
Prior studies indicate that latent factor models such as singular 
value decomposition (SVD) technique can be applied to 
reduce the data dimensionality and to capture significant latent 
relationships between users and items. Generally speaking, a 
SVD-based recommendation system extracts the features of 
both users and items from past rating patterns and then 
captures latent user-item relationships to obtain the rating 
predictions. Through the SVD process, the reduced feature 
space is less noisy than the original one since the less 
important, smaller singular values are ignored [4]. 
Furthermore, the users who have similar tastes can be mapped 
into the space spanned by the same feature vectors [10]. 
 There are two steps in conventional SVD-based 
recommendation systems. The off-line step computes the SVD 
of user-item rating matrix to extract the features, and then the 
actual user-item rating prediction is generated in the on-line 
step. However, the online e-commerce environment is always 
dynamic since a huge volume of new users and items are 
constantly added and large-scale rating data are frequently 
updated. It causes the tremendous growth of user-item rating 
matrix and suffers one serious limitation since recomputing 
the SVD of a large-scale rating matrix in the off-line step is 
computationally very expensive. Thus, in this work, we 
propose an incremental scheme that directly updates the SVD 
of rating matrix without through off-line step when new rating 
data come in. Specifically, our incremental process attempts to 
pursue a goal of fast execution speed by only considering the 
influence of changed data when some portion of data changes. 
 The rest of the paper is organized as follows. The SVD-
based process and its challenges in recommendation systems 
are reviewed in Section II. An incremental SVD-based scheme 
is developed in Section III. Experimental results are presented 
in Section IV. Finally, this paper concludes with Section V.  
II.  PRELIMINARIES 
 General recommendation techniques and how SVD can 
potentially be adopted are studied in Section II.A. Moreover, 
challenges resulting from large-scale rating data and rapid 
growth of users and items are reviewed in Section II.B. 
A. Utilizing Singular Value Decomposition in 
Recommendation Systems 
 Recommendation techniques can be broadly classified 
into three different strategies. The content-based approach 
characterizes both user and item by their profiles, e.g., user 
demographic information and item popularity [6]. The CF 
technique predicts user preference by analyzing previous 
transactions [7]. The hybrid approach combines these two 
techniques to improve the performance by avoiding certain 
2010 International Conference on Circuit and Signal Processing 
978-1-4244-6782-2/10/$26.00 ©2010 IEEE 
 
61
[ ] M
R
M
R
USV
JV
KRV
0S
I0
0U ~TT
T =⎥⎦
⎤⎢⎣
⎡=⎥⎦
⎤⎢⎣
⎡=⎥⎦
⎤⎢⎣
⎡⎥⎦
⎤⎢⎣
⎡ . 
On the left-hand side of above identity, it is noted that the left 
and right matrices in the product are orthogonal as required in 
an SVD form. Thus, we focus on the middle matrix to make it 
diagonalized as 
T
mmmT VSUKRV
0S =⎥⎦
⎤⎢⎣
⎡ . 
Let  
[ ] mupdatedmupdatedmupdated ;; VJVVSSUI0
0U
U ==⎥⎦
⎤⎢⎣
⎡= . 
Then the updated SVD of user-item rating matrix is 
T
updatedupdatedupdated
~ VSUM = . 
Note that this update procedure takes ))(( 2 mknmO ++  time 
[2]. 
 Case 2: Updating with a New Item: Let matrix 1×mC  be 
the additional column which contains the rating data of a new 
item. To make use of U, S, and V as computed previously, we 
consider the following rating matrix M~  which is obtained by 
appending a column to the original matrix M, i.e., 
[ ]CMM =~ . 
where sparsity removal and normalization have been 
conducted on C first. Similarly, we project the new item onto 
the orthogonal complement of the latent feature space of users 
to get an orthogonal basis J and a projection K. To update the 
SVD, we diagonalize the middle matrix of the left-hand side 
of the following identity so that the updated user-item rating 
matrix can be obtained in the same way as in Case 1. 
[ ] [ ] [ ] MCMCUSV
I0
0V
K0
CUS
JU ~T
TT
===⎥⎦
⎤⎢⎣
⎡⎥⎦
⎤⎢⎣
⎡ . 
 Case 3: Updating Entries in the Original Rating Matrix: 
Let matrices X and Y form the change in rating values. 
Instead of recomputing the SVD of user-item rating matrix 
which contains the new rating data, we make use of U, S, and 
V in the computing the SVD of 
T~ XYMM += . 
The QR decomposition of the component of X that is 
orthogonal to the subspace spanned by U is ( ) PAXUUI =⋅− T , 
where P is an orthogonal basis and A is the projection of X 
onto the subspace orthogonal to U. Similarly, we have the QR 
decomposition of the component of Y that is orthogonal to the 
subspace spanned by V as ( ) QBYVVI =⋅− T , 
where Q is an orthogonal basis and B is the projection of Y 
onto the subspace orthogonal to V. This step can be viewed as 
a projection of the change in rating values onto the orthogonal 
complement of latent feature space of both users and items. 
Consider the following identity 
[ ] [ ] MXYUSVQV
B
YV
A
XU
00
0S
PU ~TTT
TT
=+=⎟⎟⎠
⎞
⎜⎜⎝
⎛
⎥⎦
⎤⎢⎣
⎡⎥⎦
⎤⎢⎣
⎡+⎥⎦
⎤⎢⎣
⎡ . 
Similar to the way to update the SVD in Case 1, the middle 
term on the left-hand side must be diagonalized as 
T
mmm
TT
VSU
B
YV
A
XU
00
0S =⎟⎟⎠
⎞
⎜⎜⎝
⎛
⎥⎦
⎤⎢⎣
⎡⎥⎦
⎤⎢⎣
⎡+⎥⎦
⎤⎢⎣
⎡ . 
Let [ ] mupdated UPUU = ; mupdated SS = ; [ ] mupdated VQVV = . 
Then, the updated SVD of user-item rating matrix is 
T
updatedupdatedupdated
~ VSUM = . 
Note that this update procedure takes ))(( 2knmO +  time [3]. 
 Once three SVD component matrices of user-item rating 
matrix are updated, the rating predictions can be generated by 
capturing latent relationships between factor vectors of users 
and items, which is modeled as the cosine similarities (inner 
products) of pseudo-users TSU  and pseudo-items TVS  
[11]. Thus, the rating predictions P can be presented as 
))(( T
T
u VSSUaP += ,                        (2) 
where ua  is the rating average of users which is used to 
normalize the rating matrix. 
IV.  EMPIRICAL STUDIES 
 To evaluate the performance of our approach, an 
incremental experiment is conducted. Details of the 
experimental procedures are presented in Section IV.A, and 
the experimental results are provided in Section IV.B. 
A. Experimental Procedures 
 Our testbed is based on the well-known Netflix dataset, 
which consists of more than 100 million ratings from over 480 
thousand anonymous users and their ratings on more than 17 
thousand movies, each movie being rated on a scale from 1 to 
5 stars. In our experiments, we choose data whose rating dates 
range from 2001/3/1 to 2001/3/31 and then divide the data 
into an initial and an incremental portion. The rating dates of 
the initial portion range from 2001/3/1 to 2001/3/15 (contains 
72,526 ratings) and those of the incremental portion range 
from 2001/3/16 to 2001/3/31 (contains 57,051 ratings). 
Ratings of the initial portion are converted into a user-movie 
rating matrix M that has 3,965 rows (users) and 3,484 
columns (movies), which is used to build an initial SVD 
model. We then conduct a pretest to determine an appropriate 
number of dimensions k=150 to be used for subsequent 
experiments. 
 We investigate the execution time of performing the 
conventional SVD method, folding-in technique, and our 
incremental method when ratings of incremental portion are 
added in. In addition, we randomly take 10% of the ratings in 
the incremental portion as the test data and apply MAE (mean 
absolute error) to evaluate the prediction accuracy. 
B. Experimental Results 
 To evaluate the feasibility of our incremental SVD 
methods, we record the average execution time and compare it 
with that of using either the conventional SVD method or the 
folding-in model. As mentioned earlier, the folding-in 
63
P. Muneesawang et al. (Eds.): PCM 2009, LNCS 5879, pp. 1219–1229, 2009. 
© Springer-Verlag Berlin Heidelberg 2009 
Exploiting a Growing Self-organizing Map for Adaptive 
and Efficient Color Quantization 
Ping-Lin Chang and Wei-Guang Teng 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 
wgteng@mail.ncku.edu.tw 
Abstract. Studies on color quantization have indicated that its applications 
range from the relaxation of displaying hardware constraints in early years to a 
modern usage of facilitating content-based image retrieval tasks. Among many 
alternatives, approaches based on neural network models are generally accepted 
to be very effective in color quantization. However, the inefficiency prevents 
their usefulness from practical usage. In view of this, we thus propose to incor-
porate a growing quadtree structure to the self-organizing map (GQSOM) tech-
nique in this work. Specifically, the strategy of inheriting from parent neurons 
hierarchically facilitates a much more efficient and flexible learning process. 
Both theoretical and empirical studies show that our approach is adaptive in de-
termining an appropriate number of quantized colors. Moreover, the efficiency 
is significantly improved without compromise of the effectiveness. 
Keywords: Color quantization, quadtree, self-organizing map. 
1   Introduction 
Color quantization is a task to reduce the number of colors in an image while keeping 
this image as visually similar to the original one as possible. Such a process is signifi-
cant in early years since personal computers at that time can usually display at most 
256 different colors. For recent applications, color quantization is also a crucial pre-
processing step in several image processing tasks, e.g., image compression and image 
segmentation [2]. Moreover, color quantization can facilitate the indexing process for 
the emerging field of content-based image retrieval (CBIR) by identifying a number 
of representative colors in an image [14]. 
Note that the number of colors to retain during the color quantization process is 
usually required to be predetermined in previous approaches. Nevertheless, it can be 
easily understood that the appropriate number of quantized colors varies with differ-
ent image contents. Also, the effectiveness of a color quantization approach can be 
reflected from the quantization error of resulting images in addition to subjective 
evaluations on the quantization quality. Consequently, we propose to devise an  
flexible approach in this paper so that color images can be quantized according to a 
satisfactory quality level. 
 Exploiting a Growing SOM for Adaptive and Efficient Color Quantization 1221 
self-organizing map (SOM) [9] is an unsupervised and competitive learning neural 
network which provides a way of projecting high dimensional data to a lower dimen-
sional space while preserving the similarities among these data. Also, the data dimen-
sionality can be significantly reduced. Thus, this approach is broadly used for data 
clustering and complex data visualization. The typical structure of SOM is shown in 
Fig. 1. Each data element in the input layer is iteratively fed into the two-dimensional 
SOM to search for its best-matching-unit (BMU) on the output layer. Note that an 
input data element is a n-dimensional vector, i.e., x1, x2, …, and xn where n is an arbi-
trary nonnegative integer, and all output neurons are n-dimensional vectors as well. 
This learning process converges as the neuron values on the output layer are gradually 
adjusted according to some learning functions. Consequently, the final output layer 
acts as a map to reflect the clustered result of the original data. For the task of color 
quantization, SOM-based approaches have shown to be with higher quality than  
several conventional algorithms [4]. However, technical difficulties are noted  
in the original model, including the inflexibility in the number of output neurons, 
sensitivity to parameter values, and a long training process. Consequently, a number 
of improving techniques are addressed in recent studies. 
The inflexible structure of a fixed neuron number in the output layer has been re-
designed recently [1][8]. Through a dynamically growing mechanism, the number 
of neurons can be adjusted correspondingly. However, as the search strategy for the 
BMU remains the same as the one used in the typical SOM, the other drawbacks are 
still unsolved. On the other hand, some other efforts have been spent on reducing 
the sensitivity in parameter setting whereas achieving better quantization results 
[2][13]. Finally, note that the strategy for searching the BMU is the primary bottle-
neck to further improve the efficiency of the whole process. In the typical SOM, the 
search takes O(N) where N is the number of neurons in the output layer. A progres-
sive algorithm which utilizes the tree structure reduces this search complexity to 
O(logsN) where s is the number of children per node in the tree structure [10]. Nev-
ertheless, to the best of our knowledge, none of prior works try to benefit neural 
network model by coupling with all these improving techniques on the color quanti-
zation task. 
Output Layer
Input Layer
N
M
BMU
x1 x2 x3 xn1 2 3 n
 
Fig. 1. A typical SOM structured with the two-dimensional output layer 
 Exploiting a Growing SOM for Adaptive and Efficient Color Quantization 1223 
This feature is especially critical in the very beginning since the number of neurons is 
limited in early layers. In our point of view, performing neighborhood learning may 
result in a significant error of final quantization results since the corresponding impact 
is accumulated through layers of the growing quadtree. 
Deciding a proper stop criterion to terminate the growing process is another crucial 
issue. For simplicity, GQSOM can stop growing the quadtree at some layer once the 
quantization quality is acceptable. Nevertheless, the drawback is that the number of 
output neurons must be the power of four since we have a complete quadtree. To 
relieve this difficulty, we scrutinize the growing process to make it sophisticated 
enough so that the number of output neurons can be made arbitrary. In other  
words, once the user specifies a desired number of quantized colors, our approach 
GQSOM can stop growing the quadtree when the number of output neurons reaches 
the specified value even if the quadtree is incomplete at that time. 
3.2   Color Quantization with GQSOM 
Two stages are required to utilize our approach GQSOM for color quantization, in-
cluding the network training and codebook mapping stages. For the first stage, it is 
assumed that the maximum number of quantized colors is specified as N. Also,  
the collection of all pixels in the original image using a certain three-channel color 
space is denoted by Ω. The input vectors are denoted as Xi = [x1i, x2i, x3i]T ,∀i∈Ω, 
and the weight of a corresponding neuron is Wj = [w1j, w2j, w3j]T, ∀j∈[Xi, c]. At first, 
the quadtree structure used in our approach GQSOM contains only a root neuron 
which is initialized the weight by a random vector, i.e., the number of layers l=0. 
Obviously, [Xi, c] contains only the root neuron, ∀i∈Ω. The following three steps 
are then iteratively conducted to complete the whole quantization process. 
Step 1) An input vector Xi is randomly selected to train the neurons to reduce the 
impact of spatial dependencies among pixels in the original image. Moreover, the 
WBMU of Xi is selected from the candidate set of [Xi, c] according to Eq. (1). 
[ ] , , minarg cXjWXWX ijiBMUi ∈∀−=−
 
(1)
where ||․|| denotes the Euclidean distance. This BMU or the winning neuron then 
learns from Xi, i.e., to become more similar to Xi, using Eq. (2) which is the proposed 
learning function with the frequency-sensitive feature. 
( ) ( ) ( )
1
1
1
1
+
×+
+
×=+
BMU
i
BMU
BMU
BMUBMU T
tX
T
T
tWtW
 
(2)
where t is the number of iteration, and TBMU is the winning times of this neuron. On 
the other hand, the maturity degree of this BMU is evaluated using Eq. (3). 
BMU
1
1N
ε<
+
 
(3)
where ε is a small number depending on the scales of adopted color spaces. For ex-
ample, it is suggested to have ε smaller than 1 for RGB colors (i.e., 0 to 255) and have 
it smaller than 0.01 for Lab colors (i.e., 0.00 to 1.00). Intuitively, while the left part of 
 Exploiting a Growing SOM for Adaptive and Efficient Color Quantization 1225 
4   Empirical Studies 
The experimental environment is firstly introduced in Section 4.1. Experiments based 
on several different approaches for color quantization are conducted in Section 4.2. 
Moreover, we examine our approach GQSOM with a large dataset in Section 4.3. 
4.1   Experimental Environment 
For comparison purposes, the proposed GQSOM approach and several other tech-
niques, including the typical SOM, median-cut, and an octree-based adaptive spatial 
subdivision algorithm [7], are all tested on a personal computer equipped with an Intel 
Pentium 4 3.4GHz processor and 2.5GBytes memory. All experimental programs are 
implemented in Java. To evaluate the similarity of reconstructed images, the peak 
signal-to-noise ratio (PSNR) is used as an objective metric [5]. Specifically, the 
PSNR is calculated as shown in Eq. (4). 
23 255PSNR=10 log
MSE
⎛ ⎞×
× ⎜ ⎟⎝ ⎠
 
(4)
In addition, the MSE (i.e., mean squared error) is 
( )2
1
1MSE=
=
−∑N i i
i
X Y
N
 
(5)
where N is the number of total pixels whereas Xi and Yi are the vectors of the i-th pixel 
in the original and reconstructed images, respectively. It is commonly accepted that 
the higher PSNR value, the subtler quantized image is rendered. Without loss of gen-
erality, all images and their corresponding objective criteria in terms of the PSNR are 
manipulated in the RGB color space if not mentioned explicitly. 
4.2   Performance of Visual Similarity 
To evaluate the performance of our approach GQSOM, a synthetic image of the  
homogenous color wheel is firstly tested to simulate a critical situation for color quan-
tization. As shown in Fig. 4(a), this color wheel originally consists of 152,241 colors. 
By applying different techniques for color quantization, the resulting images all  
contains nearly 4,096 colors as shown in Fig. 4(b) ~ 4(f). 
In addition to the usage of PSNR as an objective indicator, the similarity evaluation 
of a reconstructed image can be directly conducted with some subjective judgment. It 
is thus observed from Fig. 4(e) and Fig. 5(a) that our approach GQSOM is with the 
best quantization quality in this case. To verify the possible performance degradation 
of explicitly incorporating neighborhood learning (NL) in GQSOM, an unsatisfactory 
result can be observed from Fig. 4(f), although the corresponding palette in Fig. 4(h) 
is globally topology preservative. The corresponding PSNR curve in Fig. 5(a) also 
reflects that the early quantization error which would induce successive failure. On 
the other hand, the typical SOM presents an underutilization of neurons as observed 
from its PSNR curve in Fig. 5(a), and its inefficiency as shown in Fig. 5(b). 
 Exploiting a Growing SOM for Adaptive and Efficient Color Quantization 1227 
(b)
(a)
 
Fig. 5. Performance of various approaches for quantizing a color wheel image: (a) the quantiza-
tion quality in PSNR; and (b) the execution time 
As shown in Fig. 5(b), median-cut is generally the fastest approach. However, the 
quantization result is not well whether in subjective or objective criterion. In Fig. 4(c), 
the quantized color wheel is apparently dissimilar to the original one even though a 
large number of 4,096 quantized colors is utilized. Also, its PSNR performance in 
Fig. 5(a) is generally the worst. On the contrary, the octree-based algorithm is gener-
ally with a good quality, whereas its execution time increases dramatically. It is also 
noted that the quantized image as shown in Fig. 4(d) is with some apparent circle 
effect due to the algorithmic property of octree.  
 Exploiting a Growing SOM for Adaptive and Efficient Color Quantization 1229 
5   Conclusions 
As color quantization is with great significance in several applications, we have fo-
cused on developing a feasible approach in this work. In view of the inefficiency of 
neural network models, we have incorporated a growing quadtree structure to the self-
organizing map in our approach GQSOM. Empirical studies have shown that the 
execution time required for GQSOM is significantly reduced to a comparable level of 
other efficient approaches. Moreover, the quantized images generated by GQSOM are 
generally with the best quality among several other alternatives. 
 
Acknowledgments. The work was supported in part by the National Science Council 
of Taiwan, R.O.C., under Contracts NSC98-2221-E-006-164-MY2. 
References 
1. Atsalakis, A., Papamarkos, N.: Color Reduction and Estimation of the Number of Domi-
nant Colors by Using a Self-Growing and Self-Organized Neural Gas. Engineering Appli-
cations of Artificial Intelligence 19(7), 769–786 (2006) 
2. Chang, C.-H., Xu, P., Xiao, R., Srikanthan, T.: New Adaptive Color Quantization Method 
Based on Self-Organizing Maps. IEEE Transactions on Neural Networks 16(1), 237–249 
(2005) 
3. Chang, Y.-C., Lee, D.-J.: Color Image Quantization Using Color Variation Measure. In: 
Proceedings of the IEEE Symposium on Computational Intelligence in Image and Signal 
Processing, April 2007, pp. 127–132 (2007) 
4. Dekker, A.: Kohonen Neural Networks for Optimal Colour Quantization. Network: Com-
putation in Neural Systems 5(3), 351–367 (1994) 
5. Gonzalez, R.C., Woods, R.E.: Digital Image Processing, 2nd edn. Pearson Prentice Hall 
(2007) 
6. Heckbert, P.: Color Image Quantization for Frame Buffer Display. ACM SIGGRAPH 
Computer Graphics 16(3), 297–307 (1982) 
7. Imagemagick, http://www.imagemagick.org/ 
8. Kirk, J.S., Chang, D.-J., Zurada, J.M.: A Self-Organizing Map with Dynamic Architecture 
for Efficient Color Quantization. In: Proceedings of the International Joint Conference on 
Neural Networks, July 2001, pp. 2128–2132 (2001) 
9. Kohonen, T.: The Self-Organizing Map. Proceedings of the IEEE 78(9), 1464–1480 
(1990) 
10. Koikkalainnen, P.: Progress with the Tree-Structured Self-Organizing Map. In: Proceed-
ings of the 11th European Conference on Artificial Intelligence, August 1994, pp. 211–215 
(1994) 
11. Martin, D., Fowlkes, C., Tal, D., Malik, J.: A Database of Human Segmented Natural Im-
ages and Its Application to Evaluating Segmentation Algorithms and Measuring Ecologi-
cal Statistics. In: Proceedings of the 8th IEEE International Conference on Computer Vi-
sion, July 2001, pp. 416–423 (2001) 
12. Papamarkos, N., Atsalakis, A.E., Strouthopoulos, C.P.: Adaptive Color Reduction. IEEE 
Transactions on Systems, Man, and Cybernetics 32(1), 44–56 (2002) 
13. Wang, C.-H., Lee, C.-N., Hsieh, C.-H.: Sample-Size Adaptive Self-Organization Map for 
Color Images Quantization. Pattern Recognition Letters 28(13), 1616–1629 (2007) 
14. Wong, K.-M., Po, L.-M., Cheung, K.-W.: A Compact and Efficient Color Descriptor for 
Image Retrieval. In: Proceedings of the 2007 IEEE International Conference on Multime-
dia and Expo., July 2007, pp. 611–614 (2007) 
 二、與會心得 
本屆會議舉行的地點 – 中國上海市是一座極具現代化而又不失中國傳統特色的文化都市，停留
在此的與會期間可以發現開拓不同的視野，可令人更具包容不同文化的國際觀。在這段期間與世界各
地學者的討論過程中，再次體認到語言表達能力的重要性，對國內的教師或研究生而言，校內的討論
環境相對來說還是較為封閉，且在英文此一國際語言的應用上往往不若歐美國家，甚至新加坡、印度
與香港等亞洲國家或地區；而在另一方面，中國當地無論是在學術界和產業界近年來也以非常快速的
步調發展中，在許多硬體建設 (如交通、建築物) 等方面令人有耳目一新的感覺，但民眾普遍的人文素
養似乎還有進步空間，這也是我們在學術發展之同時應時時警惕並教育學生基本素養的重要責任。 
 
三、考察參觀活動(無是項活動者略) 
略。 
 
四、建議 
成大在工程領域的發展非常傑出，但理工背景的學生多少容易忽略交流與表達的重要性，然而在
近年來國科會與頂尖大學計畫的支持下，國際化的程度已有顯著的攀升，往後若能以更多方式實質地
鼓勵研究生進行學術發表或交流，並日積月累地訓練與培養書寫與口說的表達能力，應是提昇學生素
質與國際化程度的一大要務，並可更加提昇學生對研究的熱忱。 
 
五、攜回資料名稱及內容 
論文集光碟一份。 
 
六、其他 
Conclusions and future work: 5 
Readability, quality of the English: 4 
Quality of the figures: 4 
Quality of format: 4 
Overall Paper Recommendation (1-7, 1 strong reject, 1 strong accept) accepted as regular paper: 6 
 
Please modify it according to JCAI 2010 Format strictly. Otherwise, we will not publish your paper 
in the proceedings. If you are not a native speaker (not familiar with in English environment), please 
check your sentences and/or English one more time to improve the quality of the final camera-ready 
paper. 
 
87:An Incremental SVD-based Scheme for Large-scale Recommendation Systems 
 
 
----- 
No virus found in this message. 
Checked by AVG - www.avg.com 
Version: 10.0.1170 / Virus Database: 426/3281 - Release Date: 11/26/10
第 2 頁 (共 2 頁)
2011/10/31
limitations of either approaches [1]. Among these approaches, 
CF is the most successful one and being adopted by more than 
a few commercial systems. In this field, neighborhood models 
and latent factor models are the two primary methods. Unlike 
neighborhood models which analyze similarities between 
users or items, latent factor models directly profile both users 
and items [8] that are often based on matrix factorization 
algorithms such as SVD [6]. 
 
TABLE I  
AN EXAMPLE OF USER-ITEM RATING MATRIX 
 Avatar Toy Story 3 Transformers 
Alan 5 3 4 
Bill NULL 4 4 
Joe 4 2 NULL 
Martin 3 NULL 1 
 
 An example 4 × 3 rating matrix for recommending 
movies is presented in Table 1, where movies are rated on a 
scale from 1 to 5 stars and a NULL means that the user has 
not rated the corresponding movie. With such a rating matrix, 
SVD can be applied to extract factor vectors of both users and 
items. Then, the predicted ratings of unknown elements of 
rating matrix can be obtained by capturing latent user-item 
relationships [11]. 
 Specifically, given an m × n matrix M with rank r, the 
singular value decomposition of M is defined as 
TUSVM = ,                                  (1) 
where U and V are two orthogonal matrices of size m × r and 
n × r respectively, and S is called the singular matrix of size r 
× r with singular values of matrix M as its diagonal entries. 
All the entries of matrix S are nonnegative and arranged in 
decreasing order of their magnitude. To produce the low-rank 
approximation of M, only k (< r) largest singular values of S 
are retained. Accordingly, the size of reduced U, S, and V are 
m × k, k × k, and n × k, respectively. 
B. Challenges of a SVD-based Recommendation System 
 The flow of conventional SVD-based recommendation 
techniques can be separated into two steps. The off-line step 
produces a set of uncorrelated factor vectors and each user 
and item is represented by its corresponding factor vectors, 
which may help users who rated similar items (but not exactly 
the same items) to be mapped into the latent factor space [10]. 
Afterwards, the actual user-item rating prediction is generated 
in the on-line step. This flow works well if the rating data are 
static and if new users and items are not frequently added. 
 However, recommendation systems used in a commercial 
environment is always a changing environment where the 
rating data are frequently updated with new users and items 
constantly being added. As a result, the size of user-item 
rating matrix grows significantly as time advances. It poses a 
very challenging problem since recomputing the SVD of a 
large-scale rating matrix in off-line is a time-consuming 
process. Specifically, the SVD process usually requires a run 
time of )( 322 mnmmnΟ ++  for an m × n matrix [5] which 
significantly grows with the size of a user-item rating matrix. 
III.  EXPLOITING AN INCREMENTAL SVD-BASED 
SCHEME FOR RECOMMENDATION SYSTEMS 
 SVD is usually adopted in the latent semantic indexing 
(LSI) technique for textual information retrieval (IR) so as to 
overcome the problems of synonymy and polysemy [4]. In a 
rapidly changing environment such as the web, there are also 
similar challenges that document collections are often updated 
with new documents and terms constantly being added [12]. 
These challenges nicely map into the problem encountered by 
large-scale recommendation systems. Accordingly, some 
updating algorithms such as SVD folding-in technique [3] and 
SVD-updating algorithm [2][9][12] are proposed in prior 
works to address different aspects of such challenges. 
 In recommendation systems, folding-in technique is used 
to incrementally build upon a suitably sized model that SVD 
is pre-computed and provide larger SVD models [10]. 
However, the folding-in model does not address the problem 
that the new rating data are not included in the additional row 
(or column) of user-item rating matrix, but conversely, in the 
original rating matrix. Unfortunately, this is the most common 
case for new rating data in practice, i.e., ratings of current 
items are provided by current users. In this case, the existing 
result of SVD can no longer be utilized to incrementally 
compute the larger model by merely adopting the folding-in 
technique.  
 Specifically, we consider in this work the incremental 
scheme that rating predictions can be immediately updated 
whenever new rating data arrive. Specifically, we begin with 
an existing rank-k SVD of m × n user-item rating matrix M as 
in equation (1), 
TUSVM = , 
where sparsity removal and normalization have been 
conducted on M first. In a sense, U and V can be viewed as 
latent features of users and items, respectively. When each of 
new user-item rating data comes in, we conclude that there are 
three updating cases of the rating matrix M as specified 
below. 
 Case 1: Updating with a New User: Let matrix n×1R  be 
the additional row which contains the new rating data of new 
user. To make use of U, S, and V as computed previously, we 
consider the following rating matrix M~  which is obtained by 
appending a row to the original matrix M, i.e., 
⎥⎦
⎤⎢⎣
⎡=
R
M
M~ , 
where sparsity removal and normalization have been 
conducted on R first. The QR decomposition of the 
component of TR  orthogonal to the subspace spanned by V is 
then ( ) JKRVVI =⋅− TT , 
where J is an orthogonal basis and K is the projection of TR  
onto the subspace orthogonal to V. This process can be 
viewed as a projection that new user is projected onto the 
orthogonal complement of the latent feature space of items. 
We then consider the following identity 
62
technique cannot handle the case of updating entries in the 
original rating matrix, i.e., Case 3. Hence, the new coming 
ratings in such a case are simply ignored when running the 
folding-in model. 
 From Figure 1, one can easily note that our incremental 
method significantly outperforms the conventional SVD 
method. It is worthy to be mentioned that the average 
execution time of our method is bounded when new coming 
ratings are added in the original rating matrix. Consequently, 
the latest rating predictions can be immediately generated and 
provided for users. However, although the execution time of 
folding-in model is the lowest, it leads to poor prediction 
accuracy due to the non-orthogonality of the latent feature 
space. In addition, it may not be feasible in real applications 
since more than 90% of new coming ratings cannot be 
handled as reported in our experiments. 
0
10
20
30
40
50
60
70
80
0 10000 20000 30000 40000 50000 60000
Av
er
ag
e 
Ex
ec
ut
io
n 
Ti
m
e 
(S
ec
.)
Number of Coming Ratings
Conventional SVD Method
Our Approach
Folding-in Model
 
Fig. 1 Average execution time of three methods on the Netflix dataset. 
 
 Figure 2 compares the prediction quality among the 
conventional SVD method, folding-in model, and our 
incremental method. The MAE values are reported for every 
1,000 test ratings to evaluate the prediction accuracy. We 
observe from Figure 2 that the prediction quality of our 
incremental SVD scheme is comparable to the original SVD 
method. Moreover, the quality of predictions is only slightly 
influenced by the incremental process. 
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
0 1000 2000 3000 4000 5000 6000
M
A
E
Number of Test Ratings
Folding-in Model
Our Approach
Conventional SVD Method
 
Fig. 2 Prediction quality of three methods on the Netflix dataset. 
 
 In fact, improving prediction accuracy in the incremental 
scheme is not the only purpose of this work. Our goals also 
include to provide up-to-date recommendations immediately 
by directly updating the SVD and to reach a balance of 
efficiency and prediction accuracy. For real applications of 
online e-commerce environment, recommendation systems 
adopting our approach can perform the incremental SVD 
scheme in peak hours and reset to the initial SVD model in 
off-peak hours to ensure highly scalable performance. 
V.  CONCLUSIONS 
 In large-scale SVD-based recommendation systems, the 
huge volume of rating data and the tremendous growth of 
users and items pose a very challenging problem since 
recomputing the matrix factorization of a large rating matrix is 
a time-consuming process. In this work, we have exploited an 
incremental SVD-based scheme for generating up-to-date 
user-item rating predictions when new rating data come in. 
Through the scheme, the user-item rating matrix has been 
directly updated by making use the existing result of SVD. 
Moreover, we have conducted empirical studies to verify that 
our approach is feasible in practical applications. 
ACKNOWLEDGMENT 
 The authors are supported in part by the National Science 
Council, Project No. NSC98-2221-E-006-164-MY2, Taiwan, 
R.O.C. 
REFERENCES 
[1] G. Adomavicius and A. Tuzhilin, “Toward the next generation of 
recommender systems: a survey of the state-of-the-art and possible 
extensions,” IEEE Transactions on Knowledge and Data Engineering, 
vol. 17, no. 6, pp. 734-749, 2005. 
[2] M. E. Brand, “Incremental singular value decomposition of uncertain data 
with missing values,” Proceedings of the European Conference on 
Computer Vision, 2002, pp. 707-720. 
[3] M. W. Berry, S. T. Dumais, and G. W. O’Brien, “Using linear algebra for 
intelligent information retrieval,” SIAM Review, vol. 37, no. 4, pp. 573-
595, 1995. 
[4] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. 
Harshman, “Indexing by latent semantic analysis,” Journal of the 
American Society for Information Science, vol. 41, no. 6, pp. 391-407, 
1990. 
[5] G. Golub and C. Van Loan, “Matrix computations,” Johns Hopkins 
University Press, 1996. 
[6] Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization techniques for 
recommender systems,” IEEE Computer, vol. 42, no. 8, pp. 30-37, 2009. 
[7] Y. Koren, “Factor in the neighbors: scalable and accurate collaborative 
filtering,” Transactions on Knowledge Discovery from Data, 2009. 
[8] Y. Koren, “Factorization meets the neighborhood: a multifaceted 
collaborative filtering model,” Proceedings of International ACM 
SIGKDD Conference on Knowledge Discovery and Data Mining, 2008, 
pp. 426-434. 
[9] P. Stange, “On the efficient update of the singular value decomposition,” 
Proceedings of International Association on Applied Mathematics and 
Mechanics, 2008, pp. 10827-10828. 
[10] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, “Incremental singular 
value decomposition algorithms for highly scalable recommender 
systems,” Proceedings of the International Conference on Computer and 
Information Science, 2002, pp. 27-28. 
[11] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, “Application of 
dimensionality reduction in recommender system -- a case study,” ACM 
WebKDD Workshop, 2000. 
[12] H. Zha and H. D. Simon, “On updating problems in latent semantic 
indexing,” SIAM Journal on Scientific Computing, vol. 21, no. 2, pp. 782-
791, 1999. 
64
 二、與會心得 
本屆會議舉行的地點 – 新加坡是個融合多元民族文化與現代建設的國際大都市，停留在此的與
會期間可以發現開拓不同的視野可令人更具包容不同文化的國際觀；而在論文發表方面，由於資訊領
域的技術演進非常快速，所以積極地參與國際會議之重要性應不亞於期刊論文的發表；對國內的教師
或研究生而言，校內的討論環境相對來說還是較為封閉，且在英文此一國際語言的應用上往往不若歐
美國家，甚至新加坡、印度與香港等亞洲國家或地區。 
 
三、考察參觀活動(無是項活動者略) 
略。 
 
四、建議 
在近年來國科會與頂尖大學計畫的支持下，國際化的程度已有攀升的趨勢，且成大在工程領域的
發展非常傑出，但除了學術發展之外，與產業界的實務面互相結合應也是研究型大學的重要任務；而
本次研討會的專題演講全由產業界的專家擔綱，演說主題實際且明確，立意良好。未來若能多在國內
舉行這樣的國際研討會，並同時安排產業界和學術界的專家學者進行交流或演講，達到產學平衡，相
信更能讓同學們有更深一層的收獲，並可更加提昇學生對研究的熱忱。 
 
五、攜回資料名稱及內容 
論文集光碟一份、近期相關領域之徵稿啟事 (call for papers) 若干份。 
 
六、其他 
 
--------------------------------------- 
 
 
Reviewer 2 
 
Summary:  
        This manuscript can contribute a good conference paper after further modifications, e.g., by adding 
more experimental results. 
 
Specific Feedback to the Track Chair and Program Chair(s):  
      This paper develops a new recommendation scheme for online grocery shopping by considering the 
product replenishment and product promotion information, the system architecture is given. Hope some 
experimental results can be given in the full paper. 
 
 
--------------------------------------- 
 
 
============== END OF REVIEWS =============== 
 
 
 
----- 
No virus found in this message. 
Checked by AVG - www.avg.com 
Version: 10.0.1204 / Virus Database: 1498/3535 - Release Date: 03/28/11 
第 2 頁 (共 2 頁)
2011/10/31
2. PRELIMINARIES 
Common recommendation techniques are explored in 
Section 2.1. Moreover, previous works on supporting 
consumers in their grocery shopping process are reviewed 
in Section 2.2. 
2.1 Common Recommendation Techniques 
Recently, the development of recommendation systems 
has attracted significant research interests, especially in 
the field of e-commerce. In recommendation systems, user 
preferences are estimated so as to provide a recommended 
items-list for the users. Specifically, the recommendations 
can be made based on either user purchase logs or 
inferences from other users having similar preferences. 
Examples applications include recommending books, CDs, 
and gifts at Amazon.com [10].  
Item-based CF [5][11] is one of the most popular 
techniques in recommendation systems and has shown 
better performance in comparison with user-based CF 
[8][12]. Item-based CF performs the similarity calculation 
in item space so as to reduce the dimensionality of large-
scale datasets [7]. This is because the number of 
consumers is typically much larger than that of items in 
many practical applications. However, the problem of 
sparsity still remains in item-based CF. In order to solve 
this problem, many previous techniques focus on looking 
for more implicit indicators [6] of consumer preferences, 
such as the purchasing behavior [1]. 
Currently, many recommendation techniques are based on 
user ratings which are explicitly specified by the users to 
represent the degree of their preferences. The ratings are 
usually represented on a discrete numerical scale ranging 
from the lowest (most disliked) to the highest (most 
favored) value. However, for our target application of 
grocery shopping, it is quite difficult to get user ratings 
since the items are relatively cheaper and more common. 
Therefore, previous recommendation techniques based on 
user ratings cannot be directly applied in this work. 
2.2 Recommendation Techniques for Grocery 
Shopping 
Some previous works utilize association rules and 
clustering analysis to solve the problem that there is no 
explicit ratings in grocery shopping. Namely, association 
rules are used to whether some products are likely to be 
purchased together [4]. Thus, associated products can be 
recommended when the corresponding product is to be 
purchased. On the other hand, clustering analysis is to 
group consumers with similar purchasing histories since 
they may have the same preferences. Therefore, favorite 
products can be recommended to other members of the 
same group [3]. 
Some other prior works model purchasing histories as a 
bipartite network [9]. As shown in Figure 1, there are two 
types of nodes, i.e., consumers and products, in such a 
bipartite network Edges only lie between nodes of 
different types. Moreover, the strength of an edge E(Ci, Pj) 
in this network may be used to represent the times of 
consumer Ci buying product Pj. 
C1Consumers
Products P1 P2 P3 P4
C2 C3
…
…
E(1,1) E(3,4)
 
Figure 1. A bipartite network showing the consumer-
product relationships. 
The relevance or similarity between two nodes of the same 
type, i.e., two products or two consumers, can be 
calculated using a random walk approach [13]. This works 
even if two products have never been purchased together 
[9], thus alleviating the problem of sparsity. In view of this, 
the corresponding techniques are adapted in this work to 
estimate product similarities and individual interests. 
3. PROPOSED SCHEME FOR ONLINE 
GROCERY SHOPPING 
General concepts of our proposed approach are introduced 
in Section 3.1. Corresponding technical details are 
illustrated in Section 3.2. Moreover, the overall 
recommendation scheme for online grocery shopping is 
presented in Section 3.3. 
3.1 General Concepts of the Proposed Approach 
For grocery shopping, consumer preferences could be 
formed by combining three aspects, i.e., individual interest, 
product replenishment, and product promotion. Once the 
preferences can be precisely estimated, a corresponding 
recommendation technique is of high potential to be 
utilized in practical applications. 
Firstly, a bipartite network is constructed based on 
purchasing histories of all users to estimate the individual 
interest. Note that consumers are likely to accept product 
recommendations that are similar to what they have 
bought before. Also, it is observed that one is willing to 
accept recommendations from consumers of similar tastes. 
411
price of this product during a whole year is $95. For this 
case, if the price of this product is $90 now, then its 
discount rate is (100-90) / 95 = 10.5%. On the other hand, 
products which are seldom discounted could be of higher 
priority in the recommended item-list. 
Besides, different consumers may be with different 
sensitivities to the matter of money saving. Intuitively, the 
sensitivity to a $40 saving could be taken as high to a 
consumer with a weekly consumption of $200, but low to 
a consumer with a weekly consumption of $2000. 
Therefore, Sensitivity (S) can be set as the value of money 
saving divided by consumer’s averaged weekly 
consumption. Consumer preference CP3 is calculated by 
summing up above two psychological effects together 
with different weight assigned to these two effects. 
Normally, before the consumer selects a product and put it 
into the shopping basket, he/she may consider the 
preferences of this product as well as the necessity of 
replenishment and degree of promotion. To effectively 
simulate this thinking process, we select certain numbers 
of products based on the ranks of the first consumer 
preference CP1. Then, we re-arrange these products’ 
sequence based on consumer preferences CP1, CP2, and 
CP3, and assign a new ranking value to each selected 
product (rank-a, rank-b, rank-c). After that, we sum up 
three ranking values (rank-a, rank-b, rank-c) of each 
product together to get the final ranking values to generate 
the final recommendation list. 
3.3 Our Recommendation Scheme 
As shown in Figure 2, the proposed scheme can be divided 
into four parts, including information manager, database, 
analyzer, and recommender. The functionalities of each 
part is illustrated as follows. 
(1) Information manager: This part is to build consumer 
profiles such as gender, age, occupation, etc. On the 
other hand, when the consumer logs in to purchase 
products, the information manager begins to record the 
consumer behavior logs including the browsing time 
and clicks. 
(2) Database: This part is to store all on-line purchasing 
behavior and purchase histories of a consumer. Also, 
promotion plans of all the products are stored. 
(3) Analyzer: This part is to analyze database contents for 
obtaining product similarities, individual interests, 
replenishment time intervals, promotion degree so as to 
estimate consumer preferences. We use these 
consumer preferences to comprehensively evaluate the 
needs of a consumer. 
(4) Recommender: This part is to produce a 
recommendation list for a specific consumer according 
to the analysis result. The recommendation list shows 
the products which are most likely to be purchased. In 
general, this list includes not only replenishment goods 
but also products on promotion. 
 
Web Server
Consumer
Consumer 
Purchase  
Behavior &
History
Database
Promotion 
Plan
Consumer Log In
Recording On-line 
Purchasing 
Behavior
Analyzer
Product Similarities
Replenishment 
Time Intervals
Individual Interests
Promotion Degrees
Recommender
Producing 
Recommendation 
List
Information manager
 
Figure 2. Proposed recommendation scheme for on-line grocery shopping.
413
Table 1. The information of Mrs. Lin’s most frequently purchased products 
Product 
Name 
Last 
Purchase 
Date 
Mean 
Time 
Interval 
(day) 
Original 
Price    
(NTD) 
Current 
Price 
(NTD) 
Average 
Price 
(NTD) 
Rank 
of 
CP1 
Rank 
of 
CP2 
Rank 
of 
CP3 
Score
Rank 
of 
CPf 
Milk 2011-04-22 7 60 60 55 1 4 6 11 3 
Toilet paper 2011-04-22 20 120 115 108 2 6 5 13 6 
Diaper 2011-04-17 25 220 180 210 3 5 4 12 4 
Coke 2011-04-17 5 57 40 55 4 1 1 6 1 
Cereal 2011-04-12 15 90 65 85 5 2 2 9 2 
Rice 2011-04-08 30 130 100 117 6 3 3 12 4 
           
5. CONCLUSIONS 
In this work, we have proposed to develop a 
recommendation technique for online grocery shopping. 
Specifically, three different factors, i.e., individual 
interests, product replenishment, and product promotion, 
have been considered in the proposed scheme. In addition, 
on-line purchasing behavior has been separated into three 
stages, i.e., “viewing the product information,” “adding 
product to shopping basket” and “purchasing product.” 
Therefore, a more appropriate recommendation list can be 
generated to fit consumer desires, needs, and budget 
considerations. 
6. ACKNOWLEDGMENT 
The authors are supported in part by the National Science 
Council, Taiwan, R.O.C. (NSC98-2221-E-006-164-MY2) 
7. REFERENCES 
[1] S. Ahmed, P. Ko, J.-W. Kim, Y.-K. Kim, and S. Kang, “An 
Enhanced Recommendation Technique for Personalized E-
Commerce Portal,” Proceedings of the Second International 
Symposium on Intelligent Information Technology 
Application, pages 196-200, December 2008. 
[2] G. M. Allenby, R. Leone, and L. Jen, “A Dynamic Model of 
Purchase Timing with Application to Direct Marketing,” 
Journal of the American Statistical Association, pages 365-
374, June 1999. 
[3] Y. B. Cho, Y. H. Cho, and S. H. Kim “Mining Changes in 
Customer Buying Behavior for Collaborative 
Recommendations,” Expert Systems with Applications, 
28(2):359-369, February 2005. 
[4] Y. H. Cho and J. K. Kim, “Application of Web Usage 
Mining and Product Taxonomy to Collaborative 
Recommendations in E-commerce,” Expert Systems with 
Applications, 26(2):233–246, February 2004. 
[5] M. Deshpande and G. Karypis, “Item-based Top-N 
Recommendation Algorithms,” ACM Transactions of 
Information System, 22(1):143–177, January 2004. 
[6] S. Gadanho and N. Lhuillier, “Addressing Uncertainty in 
Implicit Preferences,” Proceedings of the 2007 ACM 
Conference on Recommender Systems, pages 97-104, 
November 2007. 
[7] C.-N. Hsu, H.-H. Chung, and H.-S. Huang, “Mining Skewed 
and Sparse Transaction data for personalized shopping 
recommendation,” Machine Learning, 57(1-2):35-59, 
October 2004. 
[8] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. 
Gordon, and J. Riedl, “Grouplens: Applying Collaborative 
Filtering to Usenet News,” Communications of the ACM, 
40(3):77–87, March 1997. 
[9] M. Li, B. M. Dias, I. Jarman, W. El-Deredy, and P. J. 
Lisboa, “Grocery Shopping Recommendations Based on 
Basket-Sensitive Random Walk,” Proceedings of the 15th 
ACM SIGKDD International Conference on Knowledge 
Discovery and Data Mining, pages 1215-1224, July 2009. 
[10] G. Linden, B. Smith, and J. York, “Amazon.com 
Recommendations: Item-to-Item Collaborative Filtering,” 
IEEE Internet Computing, 7(1):76-80, February 2003. 
[11] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl, “Item-based 
Collaborative Filtering Recommendation Algorithms,” 
Proceedings of the 10th International Conference on World 
Wide Web, pages 285–295, May 2001. 
[12] U. Shardanand and P. Maes, “Social Information Filtering: 
Algorithms for Automating Word of Mouth,” Proceedings 
of the SIGCHI Conference on Human Factors in Computing 
Systems, pages 210–217, May 1995. 
[13] J. Sun, H. Qu, D. Chakrabarti, and C. Faloutsos, “Relevance 
Search and Anomaly Detection in Bipartite Graphs,” 
SIGKDD Explorations Newsletter, 7(2):48-55, December 
2005. 
[14] R. Venkatesan and V. Kumar, “A Customer Lifetime Value 
Framework for Customer Selection and Resource Allocation 
Strategy,” Journal of Marketing, 68(4):106-125, October 
2004.  
415
--------------------------------------- 
 
 
Reviewer 2 
 
Summary:  
         
 
Specific Feedback to the Track Chair and Program Chair(s):  
       
 
 
--------------------------------------- 
 
 
Reviewer 3 
 
Summary:  
        Paper proposes a scheme for on-demand search based on browsing history and localized information 
to improve the effectiveness of performing web searches on mobile devices. 
 
Specific Feedback to the Track Chair and Program Chair(s):  
      The paper should contain implementation results to demonstrate the workability of the proposed idea.
 
 
--------------------------------------- 
 
 
============== END OF REVIEWS =============== 
 
 
 
----- 
No virus found in this message. 
Checked by AVG - www.avg.com 
Version: 10.0.1204 / Virus Database: 1498/3537 - Release Date: 03/29/11 
第 2 頁 (共 2 頁)
2011/10/31
social interaction are also considered in the proposed scheme, 
e.g., nearby friends can be informed and invited to join the 
user for a chat in the previous example. Corresponding 
functionalities can be devised by maintaining logs of 
registered mobile users or acquiring social information from 
online social network services.  
The rest of this paper is organized as follows. Relevant 
studies and improving approaches for mobile searches are 
discussed in Section 2. Our proposed approach which 
considers both browsing history and localized information is 
explored in Section 3. Prototyping of the proposed scheme and 
its usage are presented in Section 4. This paper concludes with 
Section 5. 
2  PRELIMINARIES 
As indicated by previous studies, web searches can be further 
classified into three categories according to different user 
goals. Unlike navigational and transactional searches, 
informational search is much more complicated. More than a 
few search sessions can be required to accomplish an 
informational search task since the user is usually unfamiliar 
with his or her target and requires to learn some more 
information. 
An example of informational user goals is illustrated in the 
following scenario. When a backpacker who travels to Austria 
is looking for some snacks in the afternoon, he may use his 
smart phone to perform web searches to find out what to eat. 
Obviously, as a tourist, food from global chain restaurants, e.g., 
the McDonald's, would not a better choice than the local 
specialty “pretzel.” However, this user may not know what his 
search target is at first. Thus, several iterative search sessions 
can be required for this user to find a good answer. In this case, 
the behavior patterns could form an “exploratory search” [11]. 
1
2
3
4
0
5
? Query
Documents
Thought  
Figure 1. An evolving search path as described in the 
berrypicking model (adapted from [1]). 
Specifically, an informational model of berrypicking [1] is 
adopted to describe this searching behavior [2]. As shown in 
Figure 1, the whole searching process is not merely a single 
movement for the user to reach the best results. The path of 
the searcher is usually a curve instead of a straight line. In 
general, searchers may iteratively change their direction after 
gaining new knowledge from retrieved documents and 
clarifying their own thoughts. 
On the other hand, mobile searches differ remarkably from 
web searches on desktop computers mainly due to the 
limitations of a handheld device. First, the screen size of a 
handheld device is smaller that reading on it can be laborious 
for users. Second, the input capabilities are much more 
inconvenient. Obviously, traditional mobile phones with a 12-
key keypad are not friendly enough for users to specify their 
queries. Although recent devices are equipped with a 
QWERTY keypad and/or a stylus input, the input capabilities 
are still inferior to those of desktop computers. 
Previous efforts on improving mobile searches focus on 
solving the problem brought by a limited-size screen. 
Alternative text segments are utilized to present search results 
as substitutes of original snippets. Specifically, key phrases are 
extracted from the corresponding result page so as to provide 
users succinct search results [8]. A similar technique called 
result-gisting [5] replaces result snippets with a much shorter 
text segment made up of terms from previous query logs. 
Users can then realize the key points of current search results. 
In recent years, many researchers have devoted to implement 
social interaction factors into mobile searches. Question not 
Answer [7] provides access to previous queries submitted by 
other users at or near the searcher’s current location. 
SocialSearchBrowser [3] allows peers of one’s social network 
to provide their experiences to the current query. A mobile user 
could thus see the previous queries of his or her friends and 
interact with them. 
3  REALIZING USER CONGITION IN ON-
DEMAND SEARCH 
It is believed that user intent could be tracked and projected 
from the browsing history. Thus, irrelevant entries contained 
in the search results of following search sessions can be 
filtered. On the other hand, the location information of a 
specific mobile user could be estimated from the 
accompanying global positioning system (GPS) embedded 
within the handheld devices or the signal strength of nearby 
base stations. Hence, nearby information can be delivered 
when a user conducts the on-demand search. As a result, both 
browsing history and localized information should be further 
investigated to customize search results for a mobile user. 
Firstly, we propose to extract a term list from the browsing 
history of a user. The term list contains representative 
keywords that may indicate personal preferences, life patterns, 
and recent activities. The process of constructing such a term 
list is shown in Figure 2. First, nouns are extracted from 
browsed pages through the POS (part-of-speech) tagging 
technique. Next, the TF-IDF (term frequency-inverse 
document frequency) calculation is performed to generate the 
term list by regarding each browsed page as a document. 
15
Visualizing search results is a good way to improve user 
experience, especially on mobile devices, since people always 
get tired of reading large amount of words on mobile devices. 
From this point of view, we adopt a map-based interface to 
visualize search results. This interface displays the search 
results on the screen. With the assistance of this interface, 
users could trace the search results easily. 
Advantages of the proposed scheme can be summarized as 
follows. Firstly, our scheme utilizes browsing history to 
construct a term list for each user, which is used to represent 
user preferences. By incorporating localized information with 
browsing history, the proposed scheme could recommend the 
results which is nearby and best fits the user’s appetite. 
Second, social interaction features are implemented in the 
prototyping of our scheme. By collecting the social 
information from online social network services, information 
of nearby friends can be presented to the user. 
As shown in Figure 4, a map-based interface displays search 
results to users. The search results are re-ranked through our 
mechanism. When a user searches for restaurant, since that the 
terms “coffee” and “Internet” is identified from his or her 
browsing history, the search results containing these terms are 
then recommended to the user. Moreover, the current location 
is also considered to filter out unlikely entries. Thus, he or she 
can easily find the desirable information. Finally, nearby 
friends is discovered and presented to the user. He or she 
could then invite friends to join following activities together. 
 
 
Figure 4. Prototyping of proposed scheme that is with 
a map-based Interface to show customized search 
results and information of nearby friends. 
5  CONCLUSIONS 
In this work, we have firstly defined “on-demand search” and 
provided some examples to illustrate corresponding concepts. 
Since people who perform web searches on mobile devices 
often have less time and patience to read and filter the 
information, precise search results are crucial. In order to 
provide a better user experience, we have incorporated 
localized information with browsing history to generate more 
desirable search results. Also, we have proposed to implement 
social interacting features in our scheme. By connecting to 
online social network services, information of nearby friends 
can be retrieved. In addition, we have also proposed to provide 
visualized search results. Better user experience can thus be 
achieved among members of a mobile community. 
6  ACKNOWLEDGMENT 
The authors are supported in part by the National Science Council, 
Taiwan, R.O.C. (NSC98-2221-E-006-164-MY2) 
7  REFERENCES 
[1] M. Bates, “The Design of Browsing and Berrypicking 
Techniques for the Online Search Interface,” Online Information 
Review, 13(5):407-424, October 1989. 
[2] W.-L. Chen and W.-G. Teng, “Exploiting Browsing History for 
Exploratory Search,” Proceedings of the 13th International 
Conference on Human-Computer Interaction (LNCS 5617), 
pages 355-364, July 2009. 
[3] K. Church, J. Neumann, M. Cherubini, and N. Oliver, 
“SocialSearchBrowser: A Novel Mobile Search and Information 
Discovery Tool,” Proceedings of the 15th International 
Conference on Intelligent User Interfaces, pages 101-110, 
February 2010. 
[4] K. Church and B. Smyth, “Understanding the Intent Behind 
Mobile Information Needs,” Proceedings of the 14th 
International Conference on Intelligent User Interfaces, pages 
247-256, February 2009. 
[5] K. Church, B. Smyth, and M. T. Keane, “Evaluating Interfaces 
for Intelligent Mobile Search,” Proceedings of the 2006 
International Cross-disciplinary Workshop on Web Accessibility 
(W4A): Building the Mobile Web: Rediscovering Accessibility?, 
pages 69-78, May 2006. 
[6] N. Gohring, “Google Betting Big on Mobile, Executive Says,” 
http://www.pcworld.com/article/191560/google_betting_big_on
_mobile_executive_says.html, May 2010. 
[7] M. Jones, G. Buchanan, R. Harper, and P.-L. Xech, “Questions 
Not Answers: A Novel Mobile Search Technique,” Proceedings 
of the SIGCHI Conference on Human Factors in Computing 
Systems, pages 155-158, April 2007. 
[8] S. Jones, M. Jones, and S. Deo, “Using Keyphrases as Search 
Result Surrogates on Small Screen Devices,” Personal 
Ubiquitous Computing, 8(1): 55-68, February 2004. 
[9] M. Kamvar and S. Baluja, “The Role of Context in Query Input: 
Using Contextual Signals to Complete Queries on Mobile 
Devices,” Proceedings of the 9th International Conference on 
Human Computer Interaction with Mobile Devices and Services, 
pages 405-412, September 2007. 
[10] M. Kamvar and S. Baluja, “A Large Scale Study of Wireless 
Search Behavior: Google Mobile Search,” Proceedings of the 
SIGCHI conference on Human Factors in Computing Systems, 
pages 701-709, April 2006. 
[11] G. Marchionini, “Exploratory Search: From Finding To 
Understanding,” Communications of the ACM - Supporting 
Exploratory Search, 49(4):41-46, April 2006. 
17
--------------------------------------- 
 
 
Reviewer 2 
 
Summary:  
         
 
Specific Feedback to the Track Chair and Program Chair(s):  
      The solid description about the proposed framework is required. 
 
 
--------------------------------------- 
 
 
============== END OF REVIEWS =============== 
 
 
 
----- 
No virus found in this message. 
Checked by AVG - www.avg.com 
Version: 10.0.1204 / Virus Database: 1498/3537 - Release Date: 03/29/11 
第 2 頁 (共 2 頁)
2011/10/31
2. PRELIMINARIES 
In most of current CBIR systems, images are represented 
by general features, e.g., color, shape, and texture 
descriptors, and locally measured features [1], e.g., SIFT, 
and SURF descriptors. Specifically, local descriptors are 
invariant to cancel out accidental circumstances of the 
recording caused by differences in lighting, viewpoint or 
scale [6]. Note that features extracted from images are 
usually indexed beforehand to improve the efficiency of 
following retrieval processes [13]. 
A typical image retrieval process starts as the user 
provides a query image, i.e., QBVE (query by visual 
example) [12]. Specifically, retrieval is performed by 
comparing the features of the query image against those of 
images in the database using a feature matching algorithm. 
In general, a distance measure is used to calculate the 
similarity of two images in terms of various feature 
dimensions such as color, texture, shape, and others. 
Therefore, based on the similarities and relevance 
feedback returned from users, ranked images are presented 
with a visualized user interface [3][13]. 
As there are billions of images available on the Internet, 
conventional approaches which store respective 
descriptors for each image are no longer appropriate. To 
solve this problem, image descriptors are quantized into 
the “visual words” [4][7][8][9]. This concept is extended 
from the technique of text retrieval. Specifically, 
significant words can be used to identify similar 
documents, whereas significant visual words can be used 
to identify similar images. The storage requirements for 
features and the execution time required for evaluating 
image similarities can thus be significantly reduced as 
visual words are representatives of all the features. 
Some prior works propose to classify images into pre-
defined semantic concepts based on the visual words 
contained in those images [5][10]. Specifically, a 
probability model can be utilized to assign a probability to 
each of the concept categories. Note that these concept 
categories may correspond to visual obviously attributes, 
meaningful objects, and descriptions to scenes [11]. In the 
task of image retrieval, images can thus be ranked 
according to the probabilities of concept presence, i.e., 
how likely an image is to represent the specified concept. 
In fact, the recognition and learning of object categories 
can be classified into several main approaches including 
parts and structure models, discriminative methods, and 
combined recognition and segmentation [5][11]. Provided 
a proper training process, the task of scene detection is 
able to be achieved with these techniques. Nevertheless, a 
significant limitation is that all concepts or scenes have to 
be specified in advance. 
3. DISCOVERING THE ASSOCIATION 
AMONG IMAGES 
The way relevant visual-words are associated to form a 
visual-concept is explored in Section 3.1. Moreover, the 
proposed scheme is devised in Section 3.2. 
3.1. Associating Relevant Image Patches 
It is easy for people to comprehend the meanings of a 
word and associate this word with other relevant ones. For 
example, the patterns “star”, “day”, “Apollo”, and “Java” 
can imply the word “sun”, because the sun is a fixed star, 
we have day time when the sun shows in the sky, Apollo 
is identified with the sun in Greek Mythology, and Java is 
a kind of programming language developed by Sun 
Microsystems. That is to say, this word association game 
is the connection and production of other words to a given 
word based on the noun phrase word association. 
Similarly, many relevant objects are simultaneously 
contained in an image. Although object recognition is not 
a main target in this work, we use visual objects for 
illustrating purposes in the following example. As shown 
in Figure 1, one may easily understand that the co-
occurrence of bunnies, eggs, chicks and lilies implies the 
Easter scene. 
 
Figure 1. The Easter scene can be implied with 
associational image patches. 
In view of this, we propose to introduce the technique of 
association rule mining. In general, association rule 
mining is a widely-used approach for discovering 
significant regularities between items, i.e., frequent 
itemsets, in large scale customer transaction data recorded 
by usually a large retailing company [2]. In this work, 
visual-words, i.e., significant image patches, are taken as 
items whereas an image is regarded as a transaction when 
association rule mining is applied. For our purpose of 
identifying similar concepts or scenes from numerous 
images, association rule mining helps to discover 
frequently co-occurring visual words so as to ease the 
problem of scene detection. Unlike the approaches 
developed in prior works, visual concepts to be learned are 
not required to be pre-defined as a limited number 
categories in our approach. 
3.2. Proposed Scheme 
For our purpose of discovering visual-concepts from 
online images, we extend the idea of frequent patterns in 
219
Feature 
Vectors
Internet Visual 
Words
Frequent 
Itemsets
Conceptual 
GroupsImages
Query ResultsUser
Feature
Extraction
Feature
Quantization
Association
Rule Mining
Feature 
Vectors
Visual 
Words
Feature
Extraction
Feature
Quantization
  
Figure 4. Our experimental process and an illustrative example. 
(a) (b)  
Figure 5. Example results of discovered conceptual groups: (a) the Christmas scene; and (b) the Easter scene. 
5. CONCLUSIONS 
As more and more people get used to sharing their photos 
on the Internet, the problem of image retrieval has 
attracted increasing research interests. In this work, we 
have proposed to discover visual-concepts embedded 
within numerous images. Instead of adopting the typical 
process of scene detection to categorize images into 
different pre-defined classes, we have devised a scheme to 
start with identifying similar image patches. Specifically, 
we have introduced the concept of visual words and the 
technique of mining association rules to construct evident 
relationships among image patches so as to discover 
identical visual-concepts from online images. 
6. ACKNOWLEDGMENT 
The authors are supported in part by the National Science 
Council, Taiwan, R.O.C. (NSC98-2221-E-006-164-MY2) 
7. REFERENCES 
[1] M. Agrawal, K. Konolige, and M. Blas, “CenSurE: Center 
Surround Extremas for Realtime Feature Detection and 
Matching,” Proceedings of the 10th European Conference 
on Computer Vision, pages 102-115, October, 2008. 
[2] R. Agrawal, T. Imielinski, and A. Swami, “Mining 
Association Rules Between Sets of Items in Large 
Databases”, Proceedings of the 1993 ACM SIGMOD 
International Conference on Management of Data, pages 
207-216, May 1993. 
[3] V. N. Gudivada, and V. V. Raghavan, “Content-Based 
Image Retrieval Systems,” IEEE Computer, 28(9): 18-22, 
September 1995. 
[4] S. Lazebnik, C. Schmid, and J. Ponce, "Beyond Bags of 
Features: Spatial Pyramid Matching for Recognizing 
Natural Scene Categories," Proceedings of 2006 IEEE 
Computer Society Conference on Computer Vision and 
Pattern Recognition, 2(14):2169-2178, June 2006. 
[5] L.-J. Li, R. Socher, and F.-F. Li, “Towards Total Scene 
Understanding: Classification, Annotation and 
Segmentation in an Automatic Framework,” Proceedings of 
the 2009 IEEE Conference on  Computer Vision and 
Pattern Recognition, pages 2036-2043, June 2009. 
[6] D. G. Lowe, “Distinctive Image Features from Scale-
Invariant Keypoints,” International Journal of Computer 
Vision, 60(2):91-110, November 2004. 
[7] D. Nister and H. Stewenius, “Scalable Recognition with a 
Vocabulary Tree,” Proceedings of the 2006 IEEE 
Conference on  Computer Vision and Pattern Recognition, 
pages 2161 - 2168, June 2006. 
[8] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman, 
“Object Retrieval with Large Vocabularies and Fast Spatial 
Matching,” Proceedings of the 2007 IEEE Conference on 
Computer Vision and Pattern Recognition, pages 1-8, 2007. 
[9] J. Sivic and A. Zisserman, “Video Google: A Text Retrieval 
Approach to Object Matching in Videos,” Proceedings of 
the Ninth IEEE International Conference on Computer 
Vision, vol. 2, page 1470, October 2003. 
[10] C. G. M. Snoek and A. W. M. Smeulders, "Visual-Concept 
Search Solved?" Computer, 43(6):76-78, June 2010. 
[11] A. Torralba, R. Fergus, and W. T. Freeman, “80 Million 
Tiny Images: A Large Data Set for Nonparametric Object 
and Scene Recognition,” IEEE Transactions on Pattern 
Analysis and Machine Intelligence, 30(11):1958-1970, 
November 2008. 
[12] N. Vasconcelos, “From Pixels to Semantic Spaces: 
Advances in Content-Based Image Retrieval,” IEEE 
Computer, 40(7): 20-26, July 2007. 
[13] R. Veltkamp and M. Tanase, "Content-Based Image 
Retrieval Systems: A Survey," Technical Report UU-CS-
2000-34, October 2000. 
221
98 年度專題研究計畫研究成果彙整表 
計畫主持人：鄧維光 計畫編號：98-2221-E-006-164-MY2 
計畫名稱：結合自動標註與內容特徵之網路影像檢索技術 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 6 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 6 6 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
在本研究計畫的執行期間內，我們已在國際期刊和學術研討會中發表了我們的研究成果，
計有國際期刊論文兩篇和會議論文六篇，茲詳列如下： 
[Journal Papers] 
1. W.-G. Teng, Y.-H. Chian, P.-L. Chang, and H. Wang, ’’Bridging the Semantic 
Gap in Online Image Retrieval,’’ Accepted by Applied Mathematics &amp；
Information Sciences, September 2011. 
2. W.-G. Teng and P.-L. Chang, ’’Identifying Regions of Interest in Medical 
Images Using Self-Organizing Maps,’’ Journal of Medical Systems, 2011. (In 
Press, Published online: 5 July 2011, DOI: 10.1007/s10916-011-9752-8) 
 
[Conference Papers] 
1. C.-T. Yang, W.-S. Chang, F.-N. Cheng, and W.-G. Teng, ’’Assessing Media 
Relevance via Eye Tracking,’’ Proceedings of ASONAM-2011 (MSN-2011 Workshop), 
pages 722-726, July 2011.  
2. Y.-S. Chian and W.-G. Teng, ’’Discovering Visual-Concepts of Online Images 
from Associational Image Patches,’’ Proceedings of the 15th IEEE Symposium on 
Consumer Electronics (Poster), pages 218-221, June 2011. 
3. W.-H. Wen and W.-G. Teng, ’’Incorporating Localized Information with Browsing 
