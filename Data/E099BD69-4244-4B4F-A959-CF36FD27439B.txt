 1
目錄 
中文摘要 .......................................................................................................................................... 2 
Abstract ............................................................................................................................................ 3 
一、  前言 .................................................................................................................................. 4 
二、  研究目的 .......................................................................................................................... 4 
三、  文獻探討 .......................................................................................................................... 5 
四、  研究方法 .......................................................................................................................... 5 
五、  結果與討論 ...................................................................................................................... 7 
六、  計畫成果自評 .................................................................................................................. 8 
參考文獻 .......................................................................................................................................... 9 
 3
 
Abstract 
Grid computing is emerging as a promising platform for integrating and coordinating 
distributed heterogeneous resources. Job scheduling and resource allocation are concerned in the 
performance management in a Grid environment. Centralized scheduling is the simplest and most 
introduced architecture for dealing with the workload in a Grid. However, as a Grid grows in size 
the centralized scheduler usually becomes a performance bottleneck. On the other hand, a 
distributed scheduling architecture can be adopted instead to resolve the performance bottleneck 
while confronting another challenge in lack of global information for optimizing scheduling 
decisions. In the proposed Pisces: A P2P Meta-Grid System, a hierarchical Grid architecture is 
established through Peer-to-Peer technology. The intra-Grid resources are managed by a 
centralized scheduling architecture while a distributed scheduling model is adopted for the 
inter-Grid system.  
Under the hierarchical Grid architecture, in the three-year proposal this subproject aims to 
develop a fair and effective workload management system for the Pisces, which includes a 
workflow management subsystem, job scheduling facilities, as well as a resource filter. Users can 
submit a workflow consisting of a set of serial and parallel jobs with predefined dependencies 
and other relationships between them. The workflow management system controls the progress of 
the submitted workflow and ensures that the jobs in the workflow are executed following the 
described dependency rules. It depends on the underlying job scheduling and resource filtering 
facilities to choose appropriate resources according to the jobs’ requirements and allocate the jobs 
on them for execution. A Grid is inherently a heterogeneous environment. Therefore, in this 
subproject we are going to develop job scheduling and resource allocation methods taking the 
heterogeneity into consideration. Support for multi-site parallel execution as well as adaptive 
processor allocation for moldable jobs are also important issues in the developments of effective 
job scheduling methods. 
Keywords: Grid computing, job scheduling, resource allocation, workflow management 
 5
個格網系統只有一個 global scheduler，架構比較簡單，各個不同單位的所有工作都集
中交付(submit)到這個 global scheduler 手中，由其統籌負責所有工作的安排及資源的分
配，好處是因為綜觀全局，因此能做較佳的安排，缺點是 single point of failure 的潛在
問題而且當格網規模逐漸變大時這個 global scheduler 容易成為整體效能的瓶頸之所
在。相反地，在分散式工作排程架構中，格網內的每個單位各自擁有自己的 local 
scheduler，各個單位的工作被交付到各自的 local scheduler 處，原則上會被安排在本地
的計算資源上執行，但若當地的系統負載過重則 local scheduler 會透過負載分擔機制的
安排將部分工作移轉給其他單位的 scheduler 去安排執行。這樣的架構除了可以避免集
中式架構下的 single point of failure 及潛在瓶頸的問題之外，如果各個單位想要維持自
己獨特的工作排程或優先權政策的話也比較可行，但架構上相形複雜而且因為沒有任
何一個 scheduler 擁有整體格網系統資源及負載的全貌，有時不易做出最佳的安排。 
本子計畫旨在開發格網系統上之運算資源管理系統，將可提供使用者工作流程的
設定、管理與進度監控等功能，同時透過資源篩選機制挑選符合需求的運算資源，並
設計高效率的工作排程演算法以適當地安排可滿足需求的資源執行適合的運算工作內
容，藉此加快工作完成的時間，提高系統工作的產能，並達到負載平衡的目的。此外，
針對格網系統分散式及動態性的特點將特別研發點對點的工作分配機制，以使得整體
系統的資源安排及工作分配更具效率與彈性，如此將可以更有效地結合更多分散各地
的計算資源來共同完成使用者所提交的工作。 
二、 文獻探討 
由於格網的應用日漸受到重視，全球已有許多國家建置格網系統[1-3]，然而，尚
未開發達到跨越不同格網系統執行工作的格網系統。為了建置分散式的點對點計算格
網，本整合型計劃採用 Super-Peer model 架構[4]連結不同的格網系統。 
在近年來不管是工程、科學、或是商業領域的應用系統都日趨龐大複雜，往往已
經不是一個單一的循序或是平行程式所能處理的了，常常需要一群不同的程式透過特
定的執行順序及合作模式來共同達成任務，也就是形成了一個工作流程(workflow)，因
此出現了不少探討 workflow computing 的研究工作[5,6]，包括在格網平台上的應用
[8]。不過大抵上來講，目前還是以在商業上的應用推動得比較積極。 
在 Workflow Management 部分國際上目前主要的標準發展組織為 WfMC 
(Workflow Management Coalition) [9]，其所定義之 Workflow Reference Model 將是本子
計畫主要的參考對象。而在 Grid computing 的 job scheduling 及 resource management 等
infrastructure 方面 Globus Alliance [7]仍是主要的參考對象，另外，Condor [10]在
workload management 及 resource discovery 等方面亦有可借鏡之處。在本子計畫進行 job 
scheduling 相關議題的 simulation 研究時，Parallel Workloads Archive [11]上的公開
workload traces 資料將是用來模擬產生格網平台上工作負載資料的一個主要來源。 
三、 研究方法 
本子計畫的工作重點是針對格網系統提交的工作進行排程、管理與進度監控，透
過資源篩選機制挑選符合需求的運算資源，並設計工作排程的演算法，分配可滿足需
求的資源執行適合的運算工作內容，共包含三個主要項目：Workflow Management、Job 
Scheduling、Resource Filter。 
 7
示，在同質性的計算格網環境中，best-fit是最好的方式，也就是
選擇一個free processors數目跟工作需求最接近的叢集作為執行
的環境。而在異質性的計算格網環境中，由於best-fit及
fastest-one這兩種方式各有所長所短，所以我們發展出了一個
adaptive allocation的方式，以整合兩個方法的優點。在
multi-site的resource selection方法部分，我們在同質性及異質
性的計算格網環境中分別採用了larger-first及faster-first這兩
個方法以達到最佳的系統效能。 
 
III. 第三年 
本年度的重點在於整合第一年及第二年成果，進一步強固系統的完整性，然
後建立完整的運算資源管理系統。主要工作內容如下： 
z 開發完成各個子系統內之相關軟體模組 
包括Workflow Engine、Job Scheduler、Resource Filter。其
中Workflow Engine負責將使用者交付的工作流程在遵循其執行順
序及資料相依關係的規範下拆解成一個個待執行的工作，Job 
Scheduler接著依各工作的特性安排出最終的最佳執行順序，最後由
Resource Filter依序為每個待執行的工作配置最符合其需求的計
算資源。 
z 整合與測試 
包含兩個部分，第一個部分是進行運算資源管理系統內各子系
統間之整合與測試，並開發及整合三個子系統間會發生交互影響的
功能部分，例如當 Job Scheduler 想依據目前系統資源現況來調整工
作執行順序，以求系統效能最佳化時，必須與 Workflow Engine 溝
通，以確保不會因此違反工作流程定義中的工作執行順序，或是反
而因此延長了工作流程執行的 makespan 或 critical path 所需時間。
第二個部分則進行運算資源管理系統與其它子計畫系統間之整合與
測試，以確保在整體 Pisces: P2P Meta-Grid System 的架構下能正確
運作。 
 
四、 結果與討論 
歸納本子計畫三年來的研發成果主要包括兩個部分，首先是開發出一套可實
際運作之格網計算資源管理系統，包括三個主要部分: Workflow Engine、Job 
Scheduler 及 Resource Filter，分別負責工作流程的執行、平行工作的排程及計
算資源的配置等工作。此一計算資源管理系統可支援格網環境中科學及工程高速
計算應用領域常見的 SPMD 及 DAG 型態之平行批次計算工作。研發成果中的第二個
部分主要牽涉到發展高效率之平行工作排程及資源配置方法，因為在格網計算環
境中，不管是 high performance computing 或是 high throughput computing 的
應用，要提升系統的整體效能主要必須透過採用適當的工作排程及資源配置方法
來達成。在執行此計劃的三年中，我們先後研發出了數個新的工作排程與資源配
 9
參考文獻 
[1] ChinaGrid. [Online] http://www.chinagrid.edu.cn/ 
[2] CRO Grid. [Online] http://www.cro-grid.hr/ 
[3] The Gridbus Project. [Online] http://www.gridbus.org/ 
[4] Yang, B. and Garcia-Molina, H., “Designing a Super-Peer Network,” Proceedings of the 
International Conference on Data Engineering, pp. 49-60, March 2003. 
[5] Bussler, C., “Enterprise-Wide Workflow Management”, IEEE Concurrency, July-September 
1999. 
[6] Bae, J., Bae, H., Kang, S. H., Kim, Y., “Automatic Control of Workflow Processes Using 
ECA Rules”, IEEE Transactions on Knowledge and Data Engineering, Vol. 16, No. 8, 
August 2004. 
[7] Globus Alliance. [Online] http://www.globus.org/ 
[8] Gil, Y., Deelman, E., Blythe, J., Kesselman, C., Tangmunarunkit, H., “Artificial Intelligence 
and Grids: Workflow Planning and Beyond”, IEEE Intelligent Systems, January/February 
2004. 
[9] The Workflow Management Coalition. [Online] http://www.wfmc.org 
[10] Condor Project Homepage. [Online] http://www.cs.wisc.edu/condor/ 
[11] Parallel Workloads Archive. [Online] http://www.cs.huji.ac.il/labs/parallel/workload/ 
[12] Foster, I., The GRID: Blueprint for a New Computing Infrastructure, Morgan Kaufmann 
Publishers, Inc., San Francisco, California, USA, 1999. 
[13] Foster, I. and Gannon, D., “The Open Grid Services Architecture Platform”, 
draft-ggf-ogsa-platform-2, Global Grid Forum. 
[14] Tuecke, S., Czajkowski, K., Foster, I., Frey, J., Graham, S., Kesselman, C., Maquire, T., 
Sandholm, T., Snelling, D., Vanderbilt, P., “Open Grid Services Infrastructure Version 1.0”, 
draft-ggf-ogsi-gridservice-29, Global Grid Forum. 
[15] http://www.ogf.org/ 
[16] Taiwan UniGrid, http://www.unigrid.org.tw 
[17] Hong Kong Grid Initiative, http://www.hkgrid.org 
[18] ShangHai Grid, http://www.ssc.net.cn 
[19] 黃國展、陳俊佑、陳怡超、張西亞，”計算格網中工作負載分擔效益之研究”, 第三屆離
島資訊技術與應用研討會，民國92年06月27日，澎湖馬公。 
[20] Kuo-Chan Huang, Po-Chi Shih, Yeh-Ching Chung, “Adaptive Processor Allocation for 
Moldable Jobs in Computational Grid”, International Journal of Grid and High 
Performance Computing, Vol. 1, Issue 1, January-March 2009, pp. 10-21. 
[21] Po-Chi Shih, Kuo-Chan Huang, Yeh-Ching Chung, “Improving Grid Performance Through 
Processor Allocation Considering Both Speed Heterogeneity and Resource Fragmentation”, 
to appear in Journal of Supercomputing. 
[22] Kuo-Chan Huang, Po-Chi Shih, and Yeh-Ching Chung, “Effective Resource Allocation and 
Job Scheduling Mechanisms for Load Sharing in a Computational Grid”, Handbook of 
Research on Grid Technologies and Utility Computing: Concepts for Managing Large-Scale 
Applications, Edited by Emmanuel Udoh and Frank Zhigang Wang, Information Science 
Reference, May 31, 2009, pp. 31-40, ISBN: 978-1605661841. 
[23] Kuo-Chan Huang, Po-Chi Shih, and Yeh-Ching Chung, “QoS-based Job Scheduling and 
Resource Management Strategies for Grid Computing”, Quantitative Quality of Service for 
Grid Computing: Applications for Heterogeneity, Large-Scale Distribution and Dynamic 
Environments, Edited by Lizhe Wang, Jinjun Chen, and Wei Jie, Information Science 
Reference, May 5, 2009, pp. 110-127, ISBN: 978-1605663708. 
[24] Kuo-Chan Huang, Po-Chi Shih, and Yeh-Ching Chung, “Using Moldability to Improve 
Scheduling Performance of Parallel Jobs on Computational Grid”, Proceedings of the Third 
International Conference on Grid and Pervasive Computing, GPC 2008, May 25-28, 2008, 
Kunming, China. 
[25] Kuo-Chan Huang, Hsi-Ya Chang, Kuan-Chou Lai, “An Integrated Job Scheduling and 
1 
 
 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 96-2221-E-142 -006 -MY3  
計畫名稱 雙魚座: 點對點格網系統/PISCES: A P2P META-GRID SYSTEM－子計畫二: 雙魚座之運算資源管理系統 (3/3) 
出國人員姓名 
服務機關及職稱 
黃國展/國立臺中教育大學資訊科學學系/助理教授 
會議時間地點 August 9~12, 2009；中國大陸成都市 
會議名稱 The 2009 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA09) 
發表論文題目 Adaptive Processor Allocation with Estimated Job Execution Time in Heterogeneous Computing Grid 
 
一、參加會議經過 
 
本年度的 ISPA 2009 會議地點在中國大陸成都市的西藏飯店舉行。大會於 8 月 9 日上午
8:30 就開始開放報到，下午兩點開始安排有議程，而正式的開幕典禮則安排在 10 日早上 9
點舉行，正式的議程一直延續到 11 日下午，內容包括邀請演講及論文發表等議程。12 日大
會安排了成都市的參訪行程。 
  
大會開幕當天(8/10)早上總共安排了兩場 Keynote Speech，第一場 Keynote Speech 的講者
是來自美國 Florida Atlantic University 的 Jie Wu 教授，講題是 A Utility-based Routing Scheme 
and Its Applications，第二場Keynote Speech的講者是來自美國University of Southern California
的 Viktor K. Prasanna 教授，他的講題是 High Performance Routers using FPGAs。本來
大會另外還安排了第三場的 Keynote Speech，主講者是中國大陸國防科技大學的 Xuejun Yang
教授，講題是 Heterogeneous Parallel Architecture, Compilation and Programming，不
過後來因為 Xuejun Yang 教授臨時有事不克出席，所以取消。 
 
本次會議內容豐富, 由於 Parallel and Distributed Processing 涵蓋內容廣泛, 參與會議人數
眾多, 論文發表場次共計 21 場, 有些場次於同一時段在不同會議室同時舉行，每個場次約有
6 篇論文報告，每篇論文約有 20 餘分鐘的報告時間。本次大會各場次主要可分為底下幾個主
題大類: 
 
3 
 
 
Adaptive Processor Allocation with Estimated Job Execution Time in 
Heterogeneous Computing Grid 
 
 
Kuo-Chan Huang         Kuan-Po Lai 
Comp. and Info. Sci. Dept. 
National Taichung University 
Taichung, Taiwan 
e-mail: kchuang@mail.ntcu.edu.tw; gkken77@gmail.com 
Hsi-Ya Chang 
National Center for High-Performance Computing 
National Applied Research Laboratories 
Hsinchu, Taiwan 
e-mail: jerry@nchc.org.tw 
 
 
Abstract—Many parallel computer systems installed in 
computing centers worldwide, which adopts backfilling based 
job scheduling policies, require that users should provide 
estimated job execution time when submitting a job to the 
system. This paper presents an approach, taking advantage of 
the estimated job execution time, to effectively allocating 
processors to jobs submitted to a heterogeneous computing 
grid. The proposed adaptive processor allocation approach 
was evaluated with simulation studies under various workload 
and processor speed conditions. The results indicate that the 
adaptive processor allocation approach can effectively 
improve the overall system performance, in terms of jobs’ 
average turnaround time, from two to four times under 
different conditions, compared to currently used methods.  
 
Keywords—processor allocation, computing grid 
 
I. INTRODUCTION 
Both job scheduling [15,16] and processor allocation 
[2,8] received a lot of research attention on earlier 
hypercube-based parallel systems. On a hypercube 
computer, allocating a job to different sub-cubes, although 
having little or no impact on that single job’s performance, 
might lead to diverse overall system performance. This is 
because different allocation decisions lead to different 
configurations of leftover processors and, in turn, the 
probability of successful allocation of subsequent jobs.  
Later, when switch-based parallel computers and 
cluster-based computing systems being widely used, job 
scheduling became a more important issue than processor 
allocation. Allocations of different portions of processors 
on such systems usually have negligible performance 
difference. This stemmed from the fact that on such 
systems allocation can be made with any number of 
processors, in contrast to the power-of-two restriction on 
earlier hypercube computers, and each processor has equal 
capability of communicating to all other processors. Many 
research efforts [6, 7] have been spent on the job 
scheduling issue on such switch-based parallel computers 
or cluster-based computing systems. Backfilling based job 
scheduling [10,13,14] is among such efforts.  
However, as grid [1,3] becomes a popular computing 
platform for both research purpose and production run. The 
premise is no longer sustainable that communication 
performances between any two processors are equal. A 
computing grid usually consists of several parallel or 
cluster computers located at different sites. 
Communications between processors within the same site 
are usually achieved through high-speed networking 
devices, while messages passed across different sites have 
to go through a much slower wide-area network or Internet. 
A job allocated to a pool of processors within the same site 
can usually run faster than if it is assigned to processors 
across different sites. Therefore, processor allocation 
becomes a crucial issue, again, on grid computing 
platforms.   
In general, processor allocation deals with the first job 
in the waiting queue. When the parallel job at the first place 
of the waiting queue cannot fit into any single site in a 
heterogeneous computing grid, the system may have 
several choices. It can simply keep the job waiting until a 
single site having enough free processors becomes 
available or it may allow the job to run across several sites 
[5]. For a moldable job [7] the system can even run it with a 
less number of processors than originally specified. This 
paper presents an adaptive processor allocation approach to 
the issue. It tries to dynamically make the best allocation 
decision among several allocation choices.  
An adaptive processor allocation method based on the 
estimated job execution time was proposed in [12] for a 
homogeneous grid environment. The adaptive processor 
allocation approach proposed in this paper takes advantage 
of the estimated job execution time to effectively allocating 
processors to jobs submitted to a heterogeneous computing 
grid. The proposed adaptive processor allocation approach 
will be evaluated with simulation studies under various 
workload and system configurations, using. workloads 
derived from publicly available trace data [11].  
II. COMPUTING GRID MODEL AND 
EXPERIMENTAL SETTING 
In this section, the computing grid model is introduced 
on which the evaluations of the proposed approach are 
based. In the model, there are several independent 
computing sites with their own local workload and 
management system. The computing grid integrates the 
sites and shares their incoming jobs. Each participating site 
2 
 
 
Queue 5 177 42262 462.46 50 4 
Total 56490     
 
 
 
Table 2. Configuration of the computational grid 
 total site 1 site 2 site 3 site 4 site 5 
Number of processors 442 8 128 128 128 50 
 
 
 
However, none of the above three approaches can 
consistently deliver the best performance under different 
workloads or system configurations, as illustrated in Tables 
3 to 6. Tables 3 and 4 show the performance evaluations on 
two lightly loaded systems with different processor speed 
configurations. On the other hand, Tables 5 and 6 show the 
performance results of two heavily loaded systems. The 
multi-pool configuration outperforms others in Tables 3 
and 5, while the moldable processor allocation policy 
performs the best in Tables 4 and 6. The multi-site parallel 
execution policy delivers comparable performance to the 
other two policies in Tables 3, 4, and 5. However, it 
produces extremely poor performance under the 
configuration of Table 6.  
The moldable processor allocation policy always results 
in the shortest average queue length since it tries to run the 
submitted jobs as soon as possible by scaling their 
parallelisms down.  
 
Table 3. Performance under speed vector (1,5,4,5,2) and load vector 
(1,1,1,1,1) 
 Average turnaround time 
(sec.) 
Average queue 
length 
Multi-pool 1102 0.06 
Multi-site 
(slowdown=1.5) 
1103 0.05 
Multi-site 
(slowdown=2.0) 
1103 0.05 
Multi-site 
(slowdown=2.5) 
1104 0.05 
Multi-site 
(slowdown=3.0) 
1105 0.05 
Moldable 1109 0.03 
 
Table 4. Performance under speed vector (4,1,2,1,5) and load vector 
(1,1,1,1,1) 
 Average turnaround time 
(sec.) 
Average queue 
length 
Multi-pool 1576 0.16 
Multi-site 
(slowdown=1.5) 
1560 0.13 
Multi-site 
(slowdown=2.0) 
1565 0.13 
Multi-site 
(slowdown=2.5) 
1571 0.13 
Multi-site 
(slowdown=3.0) 
1576 0.13 
Moldable 1547 0.08 
 
 
Table 5. Performance under speed vector (1,5,4,5,2) and load vector 
(5,5,5,5,5) 
 Average turnaround time 
(sec.) 
Average queue 
length 
Multi-pool 5708 0.44 
Multi-site 
(slowdown=1.5) 
5748 0.40 
Multi-site 
(slowdown=2.0) 
5827 0.44 
Multi-site 
(slowdown=2.5) 
5895 0.45 
Multi-site 
(slowdown=3.0) 
6088 0.50 
Moldable 5799 0.18 
 
Table 6. Performance under speed vector (4,1,2,1,5) and load vector 
(5,5,5,5,5) 
 Average turnaround time 
(sec.) 
Average queue 
length 
Multi-pool 33432 19.58 
Multi-site 
(slowdown=1.5) 
1419841 594 
Multi-site 
(slowdown=2.0) 
3705479 1369 
Multi-site 
(slowdown=2.5) 
10036993 5731 
Multi-site 
(slowdown=3.0) 
14508657 7307 
Moldable 13525 0.63 
IV. ADAPTIVE PROCESSOR ALLOCATION 
This section proposes an adaptive processor allocation 
approach which tries to dynamically make the best 
allocation decision for each job. Taking advantage of the 
estimated job execution time, the system can decide to keep 
a job waiting in queue for faster resources or select the best 
allocation approach among the three policies described in 
the previous section. This adaptive approach aims to deliver 
consistently better system performance than the three 
current practices under different workload and system 
configurations. The approach is described as follows. 
 
 
Variables:  
T0, T1, T2, T3: execution times required for different processor allocation policies;  
3 
 
 
immediate  
Execution on site S3; 
    } 
5 
 
 
that the proposed approach outperforms the three current practices even when the estimation error is as large as 90%. 
Therefore, the proposed approach is robust under job runtime estimation error.  
V. CONCLUSIONS 
This paper investigates the processor allocation issue in heterogeneous computing grid environments. An adaptive 
processor allocation approach is proposed, which takes advantage of the estimated job execution time commonly 
required by many parallel systems in computing centers worldwide. The proposed approach can dynamically make the 
best allocation decision among several allocation choices.  
The adaptive processor allocation approach was evaluated through a series of simulation analysis using workloads 
derived from publicly available trace data, compared with the three current practices. The simulation results indicate 
that the proposed approach can consistently outperform the three current practices under different workload and system 
configurations. The adaptive approach effectively improves the overall system performance, in terms of jobs’ average 
turnaround time, from two to four times under different conditions.  
ACKNOWLEDGMENT 
The work of this paper is partially supported by the National Science Council in Taiwan under NSC 96-2221-E-432 
-003 -MY3. 
 
REFERENCES 
[1] C. Ernemann, V. Hamscher, R. Yahyapour, “Benefits of Global Grid Computing for Job Scheduling,” Proceedings of the Fifth 
IEEE/ACM International Workshop on Grid Computing(GRID’04), pp. 374-379, November 2004. 
[2] L. M. Ni, S. W. Turner, B. H. C. Cheng, "Contention-Free 2D-Mesh Cluster Allocation in Hypercubes," IEEE Transactions on 
Computers, vol. 44, no. 8, pp. 1051-1055, Aug. 1995. 
[3] I. Foster, C. Kesselman, The Grid: Blueprint for a New Computing Infrastructure, Morgan Kaufmann Publishers, Inc., 1999. 
[4] C. Ernemann, V. Hamscher, R. Yahyapour, and A. Streit, “Enhanced Algorithms for Multi-Site Scheduling”, Proceedings of 3rd 
International Workshop Grid 2002, in conjunction with Supercomputing 2002, pp. 219-231, Baltimore, MD, USA, November 
2002. 
[5] K. C. Huang, and H. Y. Chang, “An Integrated Processor Allocation and Job Scheduling Approach to Workload Management on 
Computing Grid”, Proceedings of the 2006 International Conference on Parallel and Distributed Processing Techniques and 
Applications (PDPTA'06), pp. 703-709, Las Vegas, USA, June 26-29, 2006. 
[6] D. G. Feitelson, and L. Rudolph, “Parallel Job Scheduling: Issues and Approaches”, Proceedings of IPPS’95 Workshop: Job 
Scheduling Strategies for Parallel Processing, pp. 1-18, 1995. 
[7] D. G. Feitelson, L. Rudolph, U. Schwiegelshohn, K. C. Sevcik, and P. Wong, “Theory and Practice in Parallel Job Scheduling”, 
Job Scheduling Strategies for Parallel Processing, pp. 1-34, Springer-Verlag, 1997. 
[8] D. D. Sharma, D. K. Pradhan, "Processor Allocation in Hypercube Multicomputers: Fast and Efficient Strategies for Cubic and 
Noncubic Allocation," IEEE Transactions on Parallel and Distributed Systems, vol. 6, no. 10, pp. 1108-1122, Oct. 1995. 
[9] K. C. Huang, P. C. Shih, and Y. C. Chung, “Towards Feasible and Effective Load Sharing in a Heterogeneous Computational 
Grid”, Second International Conference on Grid and Pervasive Computing, GPC 2007, Lecture Notes in Computer Science, 
Editors: Christophe Cerin and Kuan-Ching Li, vol. 4459, pp. 229-240, Springer, Paris, France, May 2-4, 2007. 
[10] A. W. Mu’alem, D. G. Feitelson, “Utilization, Predictability, Workloads, and User Runtime Estimate in Scheduling the IBM 
SP2 with Backfilling”, IEEE Transactions on Parallel and Distributed Systems, Vol. 12, Iss. 6, pp. 529-543, 2001. 
[11] Parallel Workloads Archive, http://www.cs.huji.ac.il/labs/parallel/workload/ 
[12] K. C. Huang, K. P. Lai, K. C. Lai, “Development of a Stable Scheduling and Allocation Approach under Different Workloads in 
Computing Grid”, Proceedings of the 5th Workshop on Grid Technologies and Applications, December 12-13, 2008, National 
University of Tainan, Tainan, Taiwan. 
[13] D. Lifka, “The ANL/IBM SP Scheduling System,” Proc. Int'l Parallel and Distributed Processing Symp. Workshop Job 
Scheduling Strategies for Parallel Processing vol. 949, pp. 295-303, Apr. 1995. 
[14] J. Skovira, W. Chan, H. Zhou, and D. Lifka, “The EASY-LoadLeveler API Project,” Job Scheduling Strategies for Parallel 
Processing, D.G. Feitelson and L. Rudolph, eds., pp. 41–47, 1996. 
[15] O. H. Kwon, K. Y. Chwa, "An Algorithm for Scheduling Jobs in Hypercube Systems," IEEE Transactions on Parallel and 
Distributed Systems, vol. 9, no. 9, pp. 856-860, Sept. 1998. 
[16] O. H. Kwon, J. Kim, S. J. Hong, S. G. Lee, "Real-Time Job Scheduling in Hypercube Systems," Proceedings of 1997 
International Conference on Parallel Processing (ICPP '97), pp.166, 1997. 
 
 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
