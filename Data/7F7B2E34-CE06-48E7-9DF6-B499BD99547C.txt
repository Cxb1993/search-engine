 一、研究計畫中英文摘要 
 
關鍵詞：可擴展標記語言數位簽章、數位浮水印、網站公告系統。 
 
電腦使用與網際網路近幾年蓬勃的發展，對於社會大眾的生活習慣有
了直接的影響。在網路的公開與無遠弗屆的特性下，社會大眾經常透過網
站公告系統得知重要訊息。然現今之公告系統尚有諸多安全的疑慮，如公
告者傳送公告訊息時無法確認訊息傳送中的安全性;公告系統無法驗證傳
送端的身分;使用者瀏覽訊息時無法確認其內容及連結之完整性;以及如果
公告連結內容與原公告不一致，網站公告系統無法辨識此修改是否在授權
允許下。 
目前對於文件內容的安全，一般都是以數位簽章方式以確認公告者的
身份與資料的完整性。然公告性質的文件，其具有內容經常變動的特性；
如果對整份文件簽章，則任何修改將造成原始簽章無效。 
本計劃研製一個 ”資訊可信賴”的公告網站架構，結合數位浮水印與
XML 數位簽章的技術，以達到資訊可信賴的目的。於此架構下，檔案的接
受者或公告瀏覽者只需確認該公告之編輯者（或修改者）為原作者，雖該
公告內容與原公告不同，但仍可接受為有效文件。本架構透過 XML 數位
簽章具有可針對 XML 文件中做部分簽章，並能對不同型態的來源如字元
編碼資料（e.g. HTML）、位元編碼資料（e.g.  JPG）或 XML 文件進行簽
署的特性，因此對一份曾經多人多次修改的 XML 文件提供了相對的彈性，
修改者只對本身負責的部分簽章，其餘部分保有讓其他人修改的彈性。另
外，在連結文件之安全性上，使用者須以文件之摘要(digest)及本身之私密
金鑰(private key)所產生之浮水印嵌入文件當中；當文件取出時可利用該文
件之摘要與該使用者之公開金鑰取出浮水印。若能順利解出浮水印即可代
表該文件之所有權與安全性；倘若無法解出則代表其所有權或是文件內容
已遭竄改。 
  
 
 
 
                                                 I
                                                  III
二、目錄 
 
研究內容 
１、 前言                                               1 
２、 目的                                               3 
３、 文獻探討                                           3 
４、 研究方法                                             
4.1 研發一個以文件數位浮水印(Document Digital Watermark)與
數位簽章（Digital Signature）技術為基礎的文件驗證機制的
理論架構                                              
4.1.1 研發一個以數位浮水印對文件作者身份確認之模式      7 
4.1.2 影像浮水印產生與嵌入機制                         10 
4.1.3 以秘密分享為基礎之文件浮水印                     40 
4.2 研製一個”資訊可信賴”的公告網站架構 
   4.2.1. 現行網際網路之網站公告型態之研究                52 
4.2.2 現有相關網路傳輸安全性技術之研究                55 
4.2.3 安全的多點傳送公告模型                          59 
4.3 網站內容安全機制研製                               64 
 
５、 參考文獻                                           69 
６、 成果自評與討論                                     75 
6.1 研究成果                                        74 
6.2. 討論                                               75 
 
 
 
 
 
 
 
而現今網際網路上系統交換資料的格式逐漸地以 XML（eXtensible 
Markup Language）為主流，W3C（World Wide Web Consortium） 於 2000
年十月 提出 Extensible Markup Language (XML) 1.0 (Second Edition) [53] 
後，XML 的特性使它在交易傳輸上功能強大(如語義豐富、結構化資料、
文字基礎、 和網路可讀取性質)。W3C 考量 Internet 及 XML 兩者之優
勢於 2002 年二月提出 XML-Signature Syntax and Processing [61]。  
 
XML 數位簽章最重要的特性是提供可針對 XML 文件中的部分做簽
章，而不須對整份文件簽章。此特性對一份曾經多人多次修改的 XML 文
件提供了相對的彈性，修改者只對本身負責的部分簽章，其餘部分保有讓
其他人修改的彈性。如果對整份文件簽章，則任何修改將造成原始簽章無
效。XML 數位簽章能對不同型態的來源進行簽署如字元編碼資料（e.g. 
HTML）、位元編碼資料（e.g.  JPG）或 XML 文件。簽章的驗證需要存取
原先被簽署之資料或物件。這些參照（reference）可以是以下四種： 
z Be referenced by a URI within the XML signature. 
z Reside within the same resource as the XML signature (the 
signature is a sibling). 
z Be embedded within the XML signature (the signature is the 
parent) 
z Have its XML signature embedded within itself (the signature is the 
child) 
 
另一方面，數位浮水印可將一些智慧財產權的訊息，例如原作者、擁
有者、出版處、連絡公司地址等等隱藏在數位媒體產品上。數位指紋則可
將每一個商品給一個不同的商品編號，以便日後若有非法使用的控訴，可
將由一些仲裁機制，將非法拷貝者或傳播者找出。資料隱藏系統並不是去
限制或控制拿取媒體物的信號，而是可將一些智慧財產權的訊息加入，以
做為以後原版商品的辨識與非法拷貝和傳播的証據。與一般密碼系統比
較，密碼系統將密文解開後原版信號將毫無保障；而資料隱藏技術可加入
一些資料，正可彌補密碼系統對解開密文無法保障的遺憾。 
 
由於 XML 數位簽章與數位浮水印可彌補 SSL 在網際網路傳輸中安全
 2
z 影像型態的浮水印機制 
 Robust Watermark for Ownership Protection: [6-20] 
 Fragile and Semi-Fragile Watermark for Authentication [21-46] 
 
B. 文件規格 
 
z 1999 年六月 Microsoft 修訂 RTF 規格 [47]. 
z 2003 年 8 月修定 pdf 檔新規格 [48]. 
z 為 OpenOffice 對 1.1 版提供的規格書與 API 手冊 [49]. 
z W3C 公佈 XML 標準 [50]. 
 
C. 動態憑證管理中心相關應用及研究：     
 
z IETF RFC 2510 Internet X.509 [51] 
z 提出以 XML 數位簽章及網路服務達成階段導向及多方參與式
的驗證協定模式 [52]. 
 
D. XML 數位簽章相關研究及應用 
 
z W3C 公佈對 XML 數位簽章（XML Signatures）的標準語法及相
關處理程序 [53]. 
z 提出 STMS（The Secure Transaction Management System），提出
一個在分散式架構下利用 XML 數位簽章來達成資料驗證的機
制 [54]. 
z 提出 CES（Content Extraction Signatures），一個採用 XML 數位
簽章並加入相關機制使得簽章內容可被部分取出而不影響其簽
章值的機制 
[55]. 
z W3C 公佈網路服務（Web Services）相關標準 [56]. 
z W3C 公佈 Simple Object Access Protocol (SOAP)1.1 標準  [57]. 
z 提出一個 SKIPLIST 觀念以驗證分段式摘要 [58]. 
z 提出一個以 XML 標記的時間戳記格式，並採用 XML 數位簽章
 4
z 在應用系統實際運作下 Observer Pattern 的參與者(此指物件)不
應只是主動的觀察，而應該是主動的通知。 [70] 
z 維護軟體安全須”確保弱點安全”對最被易攻擊之處加以防範並
設有補救機制。 [71] 
 
 6
 
 
                        圖-7. 文件簽章機制 
 
 
 原始文件： 欲被加入浮水印與簽章的文件，以 rtf 文件形態中作測
試。 
 使用者 Secret Key：為使用者提供的一組私密金鑰作為對文件所產
生的摘要作簽章。 
 標記（Mark）：標記的原始功能是用來鑑定版權所有。此研究將其
引用在文件來源的確認 當標記經過浮水印產生技術將其隱藏至被
保護的資料中。若能取出有效標記來便能證明文件的來源。 
 文件型態判斷：判斷文件型態並參考”文件簽章政策”中的定義，以
決定針對該種類文件如何簽章。 
 文件簽章政策：記錄每種文件的處理原則與方式 
 文件簽章：利用文件本身內容值產生摘要，並對摘要值以
Secret/Private key 簽章。 
 浮水印製作：以使用者的 Secret/Private key 以產生浮水印（待研
究）。 
 8
文件
A. 
浮水印的嵌入 
我們分析目前市面上幾種常見的文件格式：*.doc(Microsoft 
Word)、*.sxw(Open office Writer)與*.rtf(Rich Text Format)後發現，各
種文件格式內部結構一般可大略分為內容、格式與物件三類。內容泛
指文件中的文字部分。格式(style and format)功能在於標示畫面呈現的
方式，如字型的種類、大小、位置或是表格的格式等。物件指文件中
於特定位置嵌入一些其他檔案，如影像、圖片、聲音或是其他檔案。 
若是使用格式藏入資訊，由於各種文字編輯器在檔案架構上的設
計差異造成在格式上的不同，以致於各種檔案型態無法取得一個可以
在格式上共用的結果。而內容的部分就是直接展現的部分，因此內容
部分的任何加註將直接顯現在編輯器打開的文件上。而在物件方面，
各種複雜的文件格式皆以定義”特殊物件”[23-27]將其包裝，而其特點
在於物件嵌入在檔案中仍然保有原始的形態或是格式。因此使用物件
的方式將可以確保物件寫入檔案或是自檔案取出仍保有原來內容。 
 基於以上的分析，我們採用影像浮水印以圖形物件的方式嵌入文件型
態檔案。 
 
 
4.1.2 影像浮水印產生與嵌入機制 
灰階影像浮水印機制 
方法一:階層式浮水印機制 [73,77,86] 
    此方法是使用一個跟原圖相同大小的方式，但是資訊卻非常的小，所以
嵌入之後的影像並不會影響原來的影像。主要目的是希望嵌入的浮水印不是
只能做認證和偵錯，還可以讓它具備回復原影像的能力。所以我們使用原影
像的特徵當作浮水印，這樣一來，浮水印就可以有數位影像驗證、偵錯和回
復的能力，具備了多重的功能。 
浮水印嵌入 
      假設全部影像都為 N x N 像素的大小和是256的灰階值。 先將影像分成 
4 x 4像素區塊，然後藉由 Ttorus Automorphism 方法 [46] 去找出嵌入特徵
的位置。 
區塊中浮水印的產生與嵌入 
 10
 V 是 前 4 個像素的平均值 
將化成二元字串 
取出 V 的 6-bit MSB 
區塊 A 的 v、p
1 3 9 11 
2 4 10 12 
區塊 B 
1 3 9 11 
2 4 10 12 
5 7 13 15 
6 8 14 16 
r 
5 7 13 15 
6 8 14 16 
區塊 A 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖 3.1. 區塊中浮水印的產生與嵌入 
影像的驗証過程 
     影像也是和浮水印嵌入過程相同，先分成 4 x 4 像素的區塊。對於每
一個區塊，我們計算區塊的平均像素 (aveg_B’) ,並且從 aveg_B’清除兩位元
LSB’s。然後我們再執行三階層的偵測處理。在階層 1 的偵測，一個區塊中
檢查每 2 x 2 的子區塊。在階層 2 的偵測，視一個 4 x 4 區塊為一個單位去
檢查；最後，階層 3 的偵測，我們檢查每一個區塊藉由它的 3 x 3 的鄰近區
塊。 
 
階層式竄改偵測 
a.第一層偵測 
對每一個 B’的 2 x 2 子區塊，依照下列規則偵測。分別將儲存的 v、p 取
出。計算每一個 2 x 2 子區塊的平均像素值，再清除 2 位元的 LSB，表示為
aveg_B’s。計算出 aveg_B’s,的 1 總個數，表示 N’s.。假如 N’s 是奇數的話，
就設定子區塊的 p’為 1；否則就為 0。比較 p’ 和 p，假如他們不相同，標
示這個子區塊為錯誤的。假如 aveg_B’s >= aveg_B’，就設代數關係 v’ =1；
 12
  
Level-1, -2 
  
 (e) (f) 
 
 
Level-1, -2, -3 
  
 (g) (h) 
       (a) The watermarked Beach. (b) The tampered Beach. (c)(e)(g) The 
detected erroneous regions. (d)(f)(h) The recovered Beaches. 
 14
block 所代表的 128-bit 的特徵值 
Block 浮水印的產生： 
我們使用在通訊方面的 CRC 技術來處理我們各個 block 所產生的特徵
值，CRC-r 的技術利用除法的定理來使得餘數相同，在這裡 r 可以視情況不
同做不同的選擇，如：8、16、24、32、、、等，這些數值的不同代表的是
系統的安全性，與還原影像品質之間的取捨。為了每個 block 產生一組
128bits 的 watermark，我們用 0 取代 128 最後的 r 個 bit，如此讓這組 block
的特徵還能保待為 128 bit，而此時對應的方程式為 xrM(x)，M(x)為原來
128-bit 的方程式。接下來，我們必須選擇一個 r 次方的 generator-G(x)方程
式，用此方程式去除以 xrM(x)，注意到多項式必須使用模組 2 除法。最後，
我們將 xrM(x)減去餘數，這時所產生的 128-bit 就是代表我們要嵌入的浮水
印了。我們要注意到 G(x)必須保待隱密，也就是只有加密者、解密者才知
道，因此如果有人惡意的修改，馬上就會顯現出來了，所以 r 愈大則系統愈
安全；然而我們為了保存住 r 就必須犧牲了一些資訊，還原的影像相對的也
會變的比較差。我們在後面也會討論到這一方面的取捨。 
 
浮水印的嵌入： 
通常一張被竄改過的影像，其被修改的部位通常都是連續的位置，而且
被修改的地方所佔原圖的比例也不會太，所以連續兩個隨機相關的 block 同
時被修改的機率也就相對的很低，因此我們採用隨機的分配 block 嵌入的位
置。關於嵌入浮水印之對應 block 的位置，在這兒我們使用 torus 的轉換，
去隨機分配 block A(Xi, Yi)的的對應嵌入位置 block B(Xi+1, Yi+1)，此公式表式
如下： 
)(mod
1
11
1
1
N
Y
X
kkY
X
i
i
i
i
⎟⎟⎠
⎞
⎜⎜⎝
⎛
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+=⎟⎟⎠
⎞
⎜⎜⎝
⎛
+
+
 
注意其所分配的 block 是不會重複的，在公式中(Xi, Yi)是一個二維空間中的
座標，其中，變數 i 是 torus 公式中的依序數，N 則是影像的大小，而 k 則
是一個隱密的整數。一但某個 block A 被分配到 block B，則我們就將 A 產
生的浮水印嵌入 B 中，嵌入的順序是從左到右、從上到下。如下圖 3.3 所示： 
 
 16
Test  image Divide into8×8 blocks
Extract 2 LSB's
from each pixel
within the
block
Divisible by
G(x)
Block is
invalid
Compute
block's
feature
Compare with the
watermark
embedded in the
designated block
Block is
valid
NO
Not Match
Yes
 Match
Figure 3 Image Authentication process圖 3.4. 浮水印認證過程圖 
 
 18
方法三 利用區塊特徵群集達成多功能數位影像之驗證及回復 [80,84] 
浮水印嵌入 
我們將所要藏入浮水印的影像分割成 N x N 個區塊(block)，計算每個區塊
的像素平均值和標準差。一般來說，區塊愈小，對竄改偵測的效果愈好，並
且在影像回復品質上也效佳；但是，小區塊所需的計算時間較大區塊為長，
因此在衡量偵測的效果和影像的回復品質上，我們必須選擇適當的區塊大
小。為了方便說明，我們在往後的演算法敍述上將以不同符號來標記。首先，
我們令 B(i,j)為位於區塊 B 的(i,j)位置的像素值，WB(i,j)為位於區塊 B 的(i,j)
位置的浮水印值(以二進位表示)，i=1,2,……n.。MB 和 δB 分別為區塊 B 的
像素平均值和標準差。 
 
a.區塊中浮水印的產生方式 
每一個區塊的浮水印是由區塊中的每一個像素值產生的各別浮水印所組
成的，區塊中的像素根據他們的像素值 B(i,j)和整體區塊的平均值上下一個
標準差(MB +－δB)之間的關係分成四個區間，在區塊中的每一個像素所產生
的浮水印如下列 Eq. (1)所示： 
⎪⎪⎩
⎪⎪⎨
⎧
−≤
≤<−
+≤<
+>
=
BB
BBB
BBB
BB
B
MjiBif
MjiBMif
MjiBMif
MjiBif
jiW
δ
δ
δ
δ
),(00
),(10
),(11
),(01
),(  
 
b.區塊浮水印的嵌入位置和方式 
為了有效的對區塊的竄改做偵測和回復，每一個區塊 B 的浮水印將被
嵌入於和它本身區塊的平均值相近的另一個區塊中。接下來我們將說明如
何選擇和區塊 B 相關聯的另一個區塊 A 和如何將區塊 B 所產生的浮水印嵌
入區塊 A 中。 
 
選擇相關聯區塊的演算法 
      首先我們將影像中所分割出來的所有區塊分派到 255/R 個群組中，其
中 R 代表著每一群組所含蓋的區塊平均值範圍，1≦R≦255，若區塊 B 的
 20
 (1,1
) 
130 133133133
134 134133138
136 133136137
136 133136137
4 x 4 pixels 
Block B1,1 
M1,1=135 
δ1,1=2 
 
 
 
 
W1,1(i,j)  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖 3.5 從位於 (1,1) 位置的區塊 B 中取出浮水印 WB，並將浮水印嵌入位於 (15,62) 位
置的相關聯區塊 A 中的過程。 
 
Watermark W1,1 
00 10 10 10 
10 10 10 01 
11 10 11 11 
11 10 11 11 
144 
150 
143 
143 
146 142134 
146 138129 
138 131123 
134 119115 
146 145143135
149 145137129
143 137130120
140 132118112
The pixels of B15,62 
before embedded 
Embeding 
Adjust 2 LSB
The pixels of B15,62 after 
embedded 
S
B1,1(1,1)、B1,1(1,2)、B1,1(1,4)、B1,1(2,1)、B1,1(2,2)、 
B1,1(2,4) 
B1,1(3,1) 
B1,1 (4,4) 
B1,1(1,3)、B1,1(2,3)、B1,1(3,2)、B1,1(3,3)、B1,1(3,4)、 
B1,1(4,1)、B1,1(4,2)、B1,1(4,3) 
11 
01 
10 
00 
M1 1+δ1, ,1=137 
M1,1=135 
M1 1-δ1 1=133 , ,
 22
1. 從嵌入浮水印所記錄的對應位置中找出區塊 B 的相關聯區塊 A 的確定
位置，並計算區塊 A 的像素平均值 MA。 
2. 驗証 MA 所位於的群組 G 是否為我們所要找的群組，其中 ⎥⎦
⎥⎢⎣
⎢= R
MG A
'
, R  
為在嵌入浮水印的過程中所選擇的群組大小範圍。 
3. 計算區塊 B 的像素平均值 MB。 
4. 調整區塊 B 的平均值從 MB-6 到 MB+6，表示為 M’B，檢查 M’B 是否落
在群組 G 內。調整平均值的主要原因是：由於我們嵌入浮水印在每一
個像素的最後二個 bits，所以區塊整體的平均值可能會不同於嵌入浮水
印且還沒被竄改之前。  
5. 若調整過程中的任一個 GR
M B =⎥⎦
⎥⎢⎣
⎢ ' ，則認定 B 為正確的。 
6. 為了增加偵測的準確性，我們由所記錄的對應關係中找出區塊 A 的相   
關聯區塊 C，來作為區塊 B 的相關聯區塊，重復步驟 1-5，直到區塊 B
被連續五次認定為正確區塊為止。 
7. 若所有的 M’B 均沒有落在群組 G 中，我們將無法認定區塊 B 或 A 為正  
確無誤的。假設區塊 A 為不正確的，我們將利用所記錄的對應關係中
找出區塊 A 的相關聯區塊 C 來作為區塊 B 的相關聯區塊。 
8. 若區塊 B 被連續五次認定為正確區塊，則我們標示區塊 B 為合格
(valid)，並且完成區塊 B 的驗証工作。 
9. 若在一連串的偵測步驟後，區塊 B 的相關聯區塊指向它自己本身或所
有可從相對應關係找出的區塊都被找完，尚未找到連續五個正確的認
定時，我們將以投票的方式來找出在這群找出的區塊中占區塊數最多
的 G 值來認定 M’B 是否有落在此範圍內，因此我們將所有找出區塊，
計算其區塊的平均值，然後分成不同的群組，若 M’B 落在區塊數最多
的群組中，則認定區塊 B 為合法的，否則為遭竄改的。 
 
(2) 數位影像回復技術 
在完成影像的驗証之後，所有的區塊即被標示為合法的或遭竄改的。影
像的回復工作亦是以區塊的概念來完成，只有被標示為遭竄改的區塊必須被
回復。由於每一個區塊中的像素值和其區塊平均值+－ 一個標準差的相對
 24
實驗結果 
            
 (a)經新增攻擊後的浮水印影像“Whale”(b)偵測出被竄改的區域 (c)回復後的影
像 PSNR=39.84dB 
 
                
       (a)                        (b)                  (c) 
 (a)經移除後的浮水印影像“Bear” (b)偵測出被竄改的區域 (c)回復後的影像
PSNR=40.44dB 
 
B.二元影像浮水印機制 
方法一 適用於一般大小影像 [72,75,87] 
 
a. Block Data- hiding Algorithm 
This is an improved version of Tseng et al’s method in [5].  
For each block Bi, 1<= i <=nB, perform the following. 
1.  If cedgei >T, mark the block embeddable. Otherwise, continue to next 
block Bi+1. 
2. Count the object pixel of Bi and denote it cobji. 
3. Determine its hiding capacity ci by  
ci = rj if Glj <= cobji <= Guj. 
4. Prepare the weight matrix Wi for this block, where Wi(k, l)= 1,2,…, 
2rj-1, 1<= k <=m, 1<= l <=n. For simplicity without having to save 
this matrix, a repeated sequence of 1 to 2rj-1 is used.  
5. Compute the weighted sum of the block, denoted wvi, using  
wvi=∑ Wi(k, l)*Bi(k, l) mod μi,              
 26
 
d. Data Extraction Algorithm 
    For each block Bi, perform the following. 
1. Determine if it has hidden data by checking cedgei > T and Glj <= 
cobji <=Guj, for any 1<=j<=NG.  
2. Go to next block if step 1 fails. 
3. Obtain its hiding rate ci= rj. 
4. Prepare Wi(k, l)= 1,2,…, 2rj-1, 1<= k <=m, 1<= l <=n. 
5. Obtain the hidden information Ii=b1…bci=∑Wi(k, l)*Bi(k, l) mod μI, 
1<= k <=m, 1<= l <=n. 
     
Experimental results and Comparisons 
We conduct three experiments to demonstrate that our proposed method 
can indeed perform better than both methods of Tseng et al. and Wu&Lin. 
The first two show that our method produces data-embedded images with 
embedding or from Tseng et al.’s method. The third one less visual artifacts 
than those produced from random shows that our method can produce 
images with smaller DRD values than Wu&Lin’s method can when hiding 
a same small amount of information and can hide 50% more information 
by trading off as little as 7% DRD value.  
Exp1. We repeat the same experiment as in [4] that hid a bit string of 
length around 40 randomly into a binary text-image of 198x109, as shown 
in Fig. 1(a). Fig. 1(b) depicts the embedded image, the DRD value, and the 
number of flipping pixels (NFP) using our method with ruggedness 
threshold =10 and group rates of {1, 2, 3, 2, 1}. Figs. 1(c)-(d) depict two 
randomly embedded images. The results clearly show that our method can 
produce images with the least visual artifacts and the smallest DRD 
measure when flipping about the same number of pixels. 
Exp2. We hide 1200 bits in total to images “Doramon” and “Onepiece”, 
as shown in Figs. 2 (a) and (b), and hide 600 bits to image “Freelady”, as 
shown in Fig. 2(c), using our method and Tseng et al’s method, 
respectively. All three images are of size 128 × 128 pixels. The parameters 
used for both methods are listed in Table 2. Figs. 2(d)-(f) and (g)-(i) are the 
data-embedded images with DRD values using both methods, respectively. 
Observing Figs. 2, it is clear that all the embedded images produced by our 
method have much less visual artifacts than those produced by Tseng et 
al.’s method. The 30-50% difference in DRD values provides with strong 
quantitative evidence as well. 
Exp3. We conduct this experiment to compare visual quality and hiding 
capacity using both our method and Wu&Lin’s method. We hide 49, 98, 
and 147 bits of information into the image shown in Fig. 3(a), respectively, 
using both methods. Figs. 3(b)-(d) depict the results of our method using a 
key (T=12, GR= {2,3,4,3,2}), (T=10, GR= {2,3,4,3,2}) and (T=6, GR= {2, 
2, 4, 2, 2}), respectively. Figs. 3(e)-(f) are the result of Wu&Lin’s method. 
Note that the result of Wu&Lin-147 is missing because their algorithm 
cannot hide 147-bit information within a simple image like this. The 
results demonstrate that for hiding a same amount of data, our method can 
produce images with smaller DRD values because it only flips nearly 1/2 
of pixels, as shown in the data of NFP in Figs. 3 (b), (e) and (c), (f). And, 
 28
Tseng’s 
method 
   
DRD 0.2821 0.3861 0.3503 
 (g) (h) (i) 
Fig. 2. (a)-(c): Original images, (d)-(f) embedded images using our method, 
(g)-(i) embedded images using Tseng et al’s method.  
 
Original 
image 
Ours-49 Ours-98 Ours-14
7 
Wu&L
in-49 
Wu&Li
n-98 
  
DRD 0.0688 0.1539 0.2560 0.1051 0.2417 
NFP 12 28 47 23 46 
T 12 10 6 0 0 
(a) (b) (c ) (d) (e) (f) 
Fig. 3. (a) Original image, (b)-(d) results of our method hiding 49-, 98-, 147-bit 
information, (e)-(f) results of Wu&Lin’s method hiding 49-, 98-bit information. 
 
方法二: 適用於小面積影像[82] 
浮水印嵌入 
uniform/non-uniform section 
由於本文所提出的方法要將資訊隱藏於小面積(約 25w x 12h 像素)的
字母影像檔中，在影像內容有限的情況下，為能藏入更多資訊 我們將區塊
(block)再切割為兩個儲存單位。如圖 8 所示，我們可將一個 區塊內之 9
個像素給予 0~8 的編號。然後定義像素{0, 1, 2, 3}與{4, 5, 6, 7}像素為二個
區段(section)，如圖 9(a)。 
33×
0
1
2
7
8
3
6
5
4
 
圖 8 33× 區塊排序定義 
 
若是 section 中像素值均為相同，則視為 uniform section，否則即視為
non-uniform section，如圖 9(b)。 
 30
 區段選擇演算法 
1. 由左而右，由上而下的順序取出圖形中所有 non-uniform section 依
序置於序列(queue)中(圖 10)。 
 
0 1 2 3 4 5 6 7 8
Queue
.....
 
圖 10 non-uniform section 排序 
 
2. 以 [ ]0seq 做為佇列中第一個嵌入資料的 section 與佇列起點之間的
距離。 
3. 以前一個放置資料的 section 為起點，以 [ ]iseq 為距離決定下一個放
置資料的 section。 
e.g.,如下圖 11 中， [ ]0seq =4 即代表 non-uniform section 的 queue 中
距離 4 的 non-uniform section 是將要被放入資料。 
 
 seq = {4,0,1,3,2,1,4,3,2,4,0,1,1,2,3,4,0,1,2,3,4,0} 
Queue
0 1 2 3 4 5 6 7 8 .....
4 0 1
 
圖 11 區段選擇 
 
 
 32
S0 S1 S2 S3 S4 S5 S6 S7 S8
Queue (non-uniform section)
.....
P0 P1 P2 P3 P4 P5 P6 P7 P8
Queue (pixel)
.....
section 0 section 1
P0 P1 P2 P3 P4 P5 P6 P7 P8
Queue (pixel)
.....
shift = 2
if (shift =2)
exp. seq[0] = section 0
修改第0, 1pixel 
0 1 2 3 4 5 6 7 8
Queue (pixel)
.....
section 1section 0shift = 2
S'0 S'1 S'2 S'3 S'4 S'5 S'6 S'7 S'8
nonuniform section Queue (shifted pixel)
.....
if(section != uniform section)
 
圖 12 區段切割調整 
 
 
 
 
 34
0 
0, 1 1, 1 
0
 
0
 
0
 
1, 0 1, 1 
0
 
0
 
0
 
1, 1 1, 0 
0
 
0
 
表 9 non-uniform section 加入資訊變化 
 
至於如何選擇 non-uniform section 中適合的像素作加黑點或減黑點的
動作，需以以下兩個條件作考量.. 
1.  必須與 non-uniform section 中原有的點形成連續線段；而減點不
可破壞原線段的連續狀態。 
2.  以區塊的中心點為基準，我們認為人類在視覺上(HVS)對水平或
是垂直的線段的敏感度較高(圖 13(b))，而對有斜度的線段在感覺
上較不敏銳(圖 13(a))[38]。因此在選擇區段內像素作加減點動作時
以角落(section[0], section[2])的像素為優先選擇，其次才是水平或
是垂直的像素(section[1], section[3])。  
 
 
0
 
         (a)斜角像素                   (b)水平或垂直像素 
圖 13 像素位置於視覺上的觀感 
 
 以圖 14 為例，區塊左方之 non-uniform section(圖 14(a))需以加入黑點使數
值為 0 的像素為奇數，在此例中可以選擇 section[0]或是 section[3]的像素。為
了滿足上述條件 2 的需求因此選擇 section[0]作為改變像素的標的(圖 14(b))。 
 
 36
delPoint 演算法 
1. 像素值為 0 之個數為 2 時; 
I. 第一次出現之像素值為 0 之像素值改為 1。 
2. 像素值為 0 之個數為 3 時; 
I. 像素值為 1 出現於 section[1]或 section[3]則減點於 section[0]。 
II. 像素值為 1 出現於 section[0]或 section[2]則減點於 section[3]。 
 
 
浮水印嵌入流程 
  浮水印嵌入過程與演算法如圖 15 所示.. 
 
  浮水印嵌入流程演算法 
1. 自二元字母影像中取出 non-uniform 放入 queue 中。 
2. 依使用者所定義之 shift 進行 pixel-shift 區塊切割調整。 
3. 依奇偶定義對 section 所代表的值作 pixel update 的動作。 
4. 還原影像。 
 
取出non-
uniform
section
non-
uniform
section
位移量
(shift)
update
section's pixel
還原圖形
pixel shift
區段切割調整
 
圖 15 浮水印嵌入流程 
 38
取出non-
uniform
section
if (shift = 0)
Pixel Shift
false
Get
Binary Data
位移量
(shift)
質數
(p)
seq-
key
seq
true
還原
Shadow與x
取出non-
uniform
section
 
圖 17 浮水印影像驗證流程 
 
 
 
4.1.3 以秘密分享為基礎之文件浮水印 [89] 
浮水印資訊設計 
二元影像中可以置放的資訊較少，所以放入資訊的長度受到嚴格的限制。 
為了確保用以建構(t, n)秘密分享之多項式的安全性，質數(p)必須大於主秘
密(Secret)且質數與多項式係數( 11,, −≤≤∈ niZaa pii )由亂數產生。由於主秘密
本身為使用者自訂的字串(String)，因此質數的長度將會導致分享之次秘密
(Shadow)長度大於二元(binary)字母影像所能承受的範圍(字母影像尺寸約 25(w) 
× 12(h) pixel)。以下的範例可以說明次秘密的長度遠超過二元字母影像可以承
受的範圍。本節中使用的各種代號於表 6 彙總說明。 
 
次秘密長度範例 
1. 使用者輸入”pu.csim”作為 DCM。。. 
 40
表 6 使用代號說明 
 
檢討多項式的結構與次秘密的產生後，我們使用赫夫曼編碼(Huffman 
Encoding)對 DCM 加以壓縮。利用赫夫曼編碼可消除資訊冗餘部份的特性，將
可有效減少 DCM 的長度。另一方面，DCM 的長度決定多項式中質數的長度
，因此壓縮 DCM 將可有效的減少次秘密的資料長度。 )sec( retp〉
由於在還原主秘密時需同時給予公開代號(x)與次秘密，因此欲隱藏的資訊
中包含公開代號(x)與次秘密(s)。因此我們以”次秘密代號”( cpxsp = )以公開代
號( x )串聯次秘密(s)表示將加入字母影像之浮水印資訊。 
 
以下”次秘密產生範例”說明次秘密的產生過程與次秘密內容。 
 次秘密產生範例 
1. 使用者輸入”pu.csim”作為 DCM，經壓縮後主秘密長度成為 3 byte。. 
2. 取得大於之主秘密之質數 
p = 11144737。 
3. 假設使用者設定之門檻值(t)為 3，則須以亂數產生 3 個係數(範圍於
[1, p-1])以應用於多項式( )(xf )中。 
假設  則以亂數取得 ~ 如下.. paxaxaxf mod)( 3221 ++= 1a 3a
1a = 2070752e6373696d 
2a = 662ede 
3a = 73cfd8 
4. 依上述多項式產生次秘密(s)。 
0s = 10000111011110110111100 
1s = 11100111010111001010001 
2s = 10110010111000111101111 
5. 以上述次秘密與公開代號(x,底線部份)結合後產生之次秘密代號
( sxsp = )即為將藏入二元影像之訊息。例如..  
0sp = 00000010000111011110110111100 
1sp = 00000111100111010111001010001 
2sp = 00001010110010111000111101111 
 
 42
原始檔案： 
 
圖 25 未嵌入浮水印前原始文件 
 
 44
檢查完整全文中文件版權標記 
 
圖 27 自完整全文中取出文件標記 
 
 實驗結果可以從文件中取得已嵌入之 81 個帶有浮水印資訊的影像，並還原
使用者個人之版權標記。 
 46
部分浮水印被惡意移除後之文件 
 本實驗乃模擬攻擊者欲將部分版權標記抹去的行為，在秘密分享的架構下
只要有超越門檻值(t)之浮水印被正確取出即可回覆版權訊息。以下文件中(圖
29)將第 8 行中的兩個浮水印刪除，系統在取得 79 個浮水印後依然可恢復版權
標記(圖 30)。 
 
 
圖 29 部分浮水印遭移除後之文件 
 
 
 48
部分文件被複製至其他文件 
 本實驗乃模擬已加入浮水印文件其部分內容被複製至其他文件(rtf 型態)。
只要被複製內容中包含超過 t 個浮水印內容即可恢復文件版權標記。圖 31 與圖
32 顯示在被拷貝 2 個浮水印(複製來源文件其定義 t=2)時依然可以正確取出版
權資訊(圖 31, 32)。 而在浮水印存在<t 的情況下，將無法正確取出版權訊息(圖
33,34)。 
 
 
圖 31 被部分複製之版權文件 
 
 
圖 32 從部分複製之版權文件中取出文件標記 
 
 
 50
4.2 研製一個”資訊可信賴”的公告網站架構 [78,79,83] 
 
4.2.1 現行網際網路之網站公告型態之研究 
 
本研究先前對現行網站公告運作機制做一研究，覺察到現行網站公告系
統，就公告過程、連結處理、及瀏覽過程方面有不同的做法與方式，但這些
方式都有其安全上的缺失，亦缺乏彈性，茲先臚列下： 
 
(1)公告過程 
  現行網站在管理公告登入時，大都是以輸入帳號（username）及密碼
（password）為之，如果登入成功（如圖-10.），則接下的動作都被系統所允
許，新增、修改、刪除資訊，此類驗證方式有以下問題： 
    
z 使用者帳號及密碼遭竊取。 
z 網路上有心人士以嘗試密碼方式進行攻擊 。 
    
一旦被竊入成功，公告系統則處於不設防狀態，公告內容則可能非
系統所預期。 
 
 
圖-10. 
 
 
 52
(3)瀏覽過程 
當一般瀏覽者在點選網路公告系統之訊息時，網站公告系統除顯示公
告本文外，如有附件或連結時亦會一併顯示供瀏覽點選（如圖-12.），但網
站公告系統並未對公告內與連結及附件之內容再確認，如果有安全上的疏失
則容易發生以下問題： 
 
z 公告內容、附件及連結遭竄改。 
z 連結內容大多為超連結（hyperlink），連結內容已變更。 
z 附件內容被經合法的修改或遭竄改。 
 
前述之一的狀況發生時，可能出現的情形有，與前一狀況相同，網站公
告系統所張貼出來的公告與原張貼的公告不符，連結的網址雖不變，但其內
容如已更改則會導致瀏覽者點選該連結時出現不知所云之狀況，另一種狀況
可能發生在附件（附件為專題小組分類表，其在當日公告但在隔日則已更
改），會使點選瀏覽者有無所適從，不知該相信哪一日所點選之公告附件。 
 
 
 
圖-12. 
 
     現行網站公告系統，就公告過程、連結處理、及瀏覽過程方面雖有不
同的做法與方式，但這些方式確有其安全上的缺失，亦缺乏彈性，實應導入
安全性之機制以補強之。 
 54
XML 數位簽章（XML Signatures）的組成元件  （如圖-15.） 
 
 
圖-15. 
 
B. 研究製作 XML 數位簽章的方法 
製作 XML 數位簽章（XML Signatures），可依據以下之步驟： 
(1). 決定要簽署的來源： 
以下是透過 URI（Uniform Resource Identifier）： 
z "http://www.abccompany.com/index.html" would reference an 
HTML page on the Web  
z "http://www.abccompany.com/logo.gif" would reference a GIF 
image on the Web  
z "http://www.abccompany.com/xml/po.xml" would reference an 
XML file on the Web  
z "http://www.abccompany.com/xml/po.xml#sender1" would 
reference a specific element in an XML file on the Web  
(2). 計算每個來源的摘要（digest）： 
在 XML 中，來源的參照是以 <Reference> 的 tag 描述，而摘
要值則是以<DigestValue>中存放： 
<ReferenceURI="http://www.abccompany.com/news/2000/03_27_00.htm"> 
<DigestMethodAlgorithm="http://www.w3.org/2000/09/xmldsig#sha1"/> 
<DigestValue>j6lwx3rvEPO0vKtMup4NbeVu8nk= 
 56
<X509Certificate>MIID5jCCA0+gA...lVN</X509Certificate>   
</X509Data> 
</KeyInfo> 
 
(6).完整的簽章元素以<SignedInfo>打包所有的簽章元素： 
 
<?xml version="1.0" encoding="UTF-8"?> 
<Signature xmlns="http://www.w3.org/2000/09/xmldsig#"> 
<SignedInfo Id="foobar"> 
<CanonicalizationMethodAlgorithm="http://www.w3.org/TR/2001/REC-xml-c14n-200103
15"/> 
<SignatureMethod Algorithm="http://www.w3.org/2000/09/ xmldsig#dsa-sha1" />  
<ReferenceURI="http://www.abccompany.com/news/2000/03_27_00.htm"> 
<DigestMethodAlgorithm="http://www.w3.org/2000/09/xmldsig#sha1" > 
<DigestValue>j6lwx3rvEPO0vKtMup4NbeVu8nk=</DigestValue>  
</Reference> 
<Reference URI="http://www.w3.org/TR/2000/WD-xmldsig-core- 
20000228/signature-example."> 
<DigestMethod Algorithm="http://www.w3.org/2000/09/ 
xmldsig#sha1"/> 
<DigestValue>UrXLDLBIta6skoV5/A8Q38GEw44=</DigestValue>  
</Reference> 
</SignedInfo> 
<SignatureValue>MC0E~LE=</SignatureValue> 
<KeyInfo> 
<X509Data> 
<X509SubjectName>CN=Ed Simon,O=XMLSec Inc.,ST=OTTAWA,C=CA 
</X509SubjectName> 
<X509Certificate>MIID5jCCA0+gA...lVN</X509Certificate> 
</X509Data> 
</KeyInfo> 
</Signature> 
 
C.研究驗證 XML 數位簽章（XML Signatures）的程序： 
1. 先將<SignedInfo>元素的內容以相同演算法計算出摘要， 
2. 再將<SignatureValue> 元素內容以發送者的公開金鑰解密之 
3. 比較前二者如相同則此簽章為有效。 
4. 如前一步驟成功，則再計算每一個來源元素的摘要再與
 58
者的授權限制、將使用者輸入之公告資訊製成 XML 數位簽章、傳送訊息簽
章至相對應網站訊息接收系統並將公告結果傳回公告者；訊息接收系統接收
公告的 XML 數位簽章、驗證簽章之有效性、將公告訊息存入資料庫並回傳
結果給公告系統。 
授權閘道（Authorization Gateway）： 
負責儲存、維護授權政策（Authorization Policy）。 
XML 數位簽章： 
簽章內容為公告之相關訊息，並透過 SOAP 傳送給相對應之網站訊息接收
模組。 
 
圖 2：系統之整體架構 
(2) 系統特性 
(a) 以 XML 數位簽章提供可依需求的（On-Demand）連結確認機制 
如圖 3 所示，本系統在 XML 數位簽章的<OBJECT>標籤中，加入一判別屬
性<Guarantee>。公告者依其需求選擇是否要在其他使用者瀏覽訊息時，由公告
系統進行連結內容之確認；而公告系統藉由判斷<Guarantee>屬性，來決定此則
訊息在被瀏覽時是否要進行連結內容之確認。此一機制，讓公告者有更加彈性
的選擇。
 60
生流程以接續公告動作。 
 
圖 4：公告過程中 CA 處理流程 
step5：向授權閘道查詢使用者之授權限制，並傳回相關授權情形（此例假設使
用者有權在 A、B 網站進行公告動作）。 
step6-7：輸入公告訊息及產生訊息簽章。 
step8：依授權將公告訊息簽章傳送至對應網站的公告接收網路服務中。 
step9：接收端先對此一 XML 數位簽章進行驗證。 
step10：如驗證成功則將公告訊息從 XML 數位簽章中抽取出來。 
step11-12：將公告訊息及相關資訊（連結的摘要值）儲存於資料庫中，並 
將公告結果傳回給原公告系統，且將多點傳送公告結果回傳給使用者。 
 62
4.3 網站內容安全機制研製 
研究方法 
A. 網站安全架構研製 
i. 定義需求 
攻擊修改網頁的型態一般可分以下幾型態： 
 塗鴉：其並不破壞網頁，而是將原來的網頁加工以傳達訊息。使用者可以
清楚的辨識出此為不正確的內容。 
 破壞：攻擊者直接使該網頁無法正常開啟。 
 偽造：攻擊者將原網頁中的部分內容修改，傳遞錯誤訊息。使用者無法以
外觀辨識出此訊息之錯誤。 
由於網站中的資料種類繁多，有網頁(html, htm)、圖檔(jpeg, gif, bmp…)、聲音、
影像、文件等；在不知攻擊者確切的目標下我們也須對網站下的各種檔案作內容
的判斷。另一方面網站擁有者可能會不定時的更新內容，因此所提出之安全架構
須能快速反應網站內容的合法修改。 
 
ii. 網站安全架構[69-71] 
a. MVC 模式的網站安全架構 
(1). MVC 模式研究 
     Model-View-Controller(以下簡稱 MVC)是一種相當著名，且廣泛被採用的
設計樣式，其歷史最早可追溯到 Smalltalk(一種物件導向程式語言，由 Alan Kay
所發明)語言的 Smalltalk-80 版本[69]。在 Smalltalk-80 中，使用者介面(UI)其背
後主要的概念就是 MVC。雖然 MVC 與傳統的應用程式設計，在觀念上與方法
上都相當不同，但這並不意味學習 MVC 很困難。事實上，MVC 很簡單而且十
分有用。  
簡單地說，MVC 的基本概念就是將使用者輸入、資料本身、以及資料的呈現
三者分離，各司其職。以下是 Model、View 與 Controller 
的一般定義：  
 
Model： 管理應用領域(Application Domain)的資料、執行資料的處理或轉
換、回應請求資料的要求(通常來自 View) 以及回應變更資料的要求(通常來自
Controller)。Model 對 View 與 Controller 一無所知，它們透過特定的介面(Interface)
與彼此溝通(圖-25.)。  
View： 負責顯示 Model 中的資料，也就是將資料做視覺化的呈現。同樣地，
View 透過特定的介面與 Model 溝通。  
Controller： 提供改變 Model 中資料的機制。Controller 解譯使用者所發出的
鍵盤或滑鼠事件，以便告知 Model 資料已改變的事實。Controller 也是透過特定
的介面與 Model 溝通。  
 
 64
管理者。 
 
 
圖-25. MVC 數位摘要檢核 
 
b. 監聽者模式之網站安全架構[72-74] 
(1). 監聽者模式研究 
監聽者模式乃是利用網站架構外的一種機制，對檔案定時予以檢核的架
構，其理論基礎較 MVC 簡單，且由於獨立於網站運作機制外所以與使用者
的互動無關。 
               
(2). 監聽者模式之網站安全架構 
計畫之監聽者架構是由 Scheduler 依設定時間發動。摘要比對即根據檔案結
構對其中所有檔案與 Digest Repository 中儲存之摘要值比對，以決定該檔案
有效與否。且由於本架構是獨立於 Application Sever 之外，因此可以在事前
 66
 
5、參考文獻： 
     
[1]. William Stallings, Cryptography and Network Security, Principles and Practice, 
2nd edition, Prentice Hall, 1999. 
[2]. Young-Won Kim, Kyung-Ae Moon, and Il-Seok Oh, “A Text Watermarking 
Algorithm based on Word Classification and Inter-Word Space Statistics,”  
[3]. Shimotsuruma, Yamato-shi, Kanagawa-ken, “A feature calibration method for 
watermarking of document images,” Tomio AMANO IBM Research, Tokyo 
Research Laboratory,1623-14, 
[4]. Ding Huang and Hong Yan,” Interword Distance Changes Represented by Sine 
Waves for Watermarking Text Images,” IEEE Transactions on Circuits and 
Systems for Video Technology, Vol. 11, No.12, 2001. 
[5]. J. Brassil, S. Low, N. Maxemchuk and L. O’Gorman, “Electronic Marking and 
Identification Techniques to Discourage Document Copying “, AT&T Bell 
Lab. , Murray Hill , 1994 
[6]. Phen-Lan Lin and James G. Dunham, “Secure Rotation- and 
Translation-Resilient Image Watermarking Based on Magic-Eye Template 
Detector,” Proceeding of The 2002 International Conference on Imaging 
Science, Systems, and Technology (CISST’02), Las Vegas, June 2002. 
[7]. Phen-Lan Lin, (Submitted) ”Affine-Resilient Image Watermarking in Two-Tier 
Hybrid Domain” 
[8]. Phen-Lan Lin, “An Oblivious Collusion-Secure and Shift-Invariant Image 
Watermarking Scheme, “Journal of Engineering, National Chung Hsing 
University, Vol. 13, No.1, pp. 33-40, 2002. 
[9]. Phen-Lan Lin, “Digital Watermarking Models for Resolving Rightful 
Ownership and Authenticating Legitimate Customer,” Journal of Systems and 
Software, vol. 55, no. 3, pp. 261-271, 2001.  
[10]. Phen-Lan Lin, “Oblivious Digital Watermarking Scheme with Blob-Oriented 
and   Modular-Arithmetic-Based Spatial-Domain Mechanism,” the Journal 
of Visual Communication and Image Representation, vol. 12, pp. 1-16, 2001. 
[11]. Phen-Lan Lin, “Robust transparent image watermarking system with spatial 
mechanisms,” The Journal of Systems and Software. Feb. 2000, vol.50 2, 
107-116. 
[12]. Chun-Shien Lu and Hong-Yuan Mark Liao, “Multipurpose Watermarking for 
Image Authentication and Protection”, IEEE Transactions on Image 
Processing, vol.10, no. 10, Oct. 2001, pp. 1579-1592.G.I. Friedman, “The 
trustworthy digital camera: restoring credibility to the phorographic image,” in 
 68
[28]. P. W. Wong, “A public key watermark for image verification and 
authentication,” in Proc. IEEE Int. Conf. Image Processing, Santa Barbara, CA, 
Oct. 1997, pp. 680-683. 
[29]. M.M. Yeung and F. Mintizer, “An invisible watermarking technique for image 
verification,” in Proc. IEEE ICIP, vol. I, Santa Barbara, CA, Oct. 1997, 
pp.680-683 
[30]. R.L. Lagendijk, G.C. Langelaar, and I. Setyawan, “Watermarking digital 
images and video data,” IEEE Signal Processing Mag., vol. 17, pp. 20-46, Sept. 
2000. 
[31]. Hartung and M. Kutter, “Multimedia Watermarking techniques,” Proc. IEEE, 
vol. 87, pp. 1079-1107, July 1999. 
[32]. M.D. Swanson, M. Kobayashi, and A.H. Tewfik, “Multimedia data embedding 
and watermarking technologies,” Proc. IEEE, vol. 86, pp. 1064-1087, June 
1988. 
[33]. I.J. Cox and M.I. Miller, “A review watermarking and the importance of 
perceptual modeling,” Proc. IEEE, vol. 3016, Feb. 1999. 
[34]. Christophe De Vleeschouwer, Jean-Francois Delaigle, and Benoit Macq, 
“Invisibility and Application Functionalities in Perceptual Watermarking—An 
Overview”, Proceedings of the IEEE, vol. 90, no. 1, Jan. 2002, pp. 64-77. 
[35]. C.W. Wu, D. Coppersmith, F.C. Mintizer, C.P. Tresser, and M.M. Mueng, 
“Fragile imperceptible digital watermark and privacy control,” Proc. SPIE, 
Security and Watermarking of Multimedia Contents, vol. 3657, Jan 1999. 
[36]. Mehmet Utku Celik, Gaurav Sharma, Eli Saber, and Ahmet Murat Tekalp, 
“Hierarchical Watermarking for Secure Image Authentication With 
Localization”, IEEE Transactions on Image Processing, vol.11, no. 4, Jun. 
2002, pp. 585-594. 
[37]. Kundur and D. Hatzinakos, “Digital watermarking for telltale tamper proofing 
and authentication,” Proc. IEEE, vol. 87, pp. 1167-1180, Jul. 1999. 
[38]. J. Eggers and B. Girod, “Blind watermarking applied to image authentication,” 
in Proc. IEEE ICASSP, Salt Lake City, UT, May 2001. 
[39]. S. Bhattacharjee and M. Kutter, “Compression tolerant image authentication, 
“ in Proc. IEEE Int. Conf. Image Processing, Chicago, IL, Oct. 1998. 
[40]. M. Holliman and N. Memon, “Counterfeiting attacks on oblivious block-wise 
independent invisible watermarking schemes,” IEEE Transactions on Image 
Processing, vol. 9, pp. 412-441, Mar. 2000. 
[41]. P.W. Wong and N. Memon, “Secret and public key authentication schemes that 
resist vector quantization attack,” Proc. SPIE, vol. 3971, no. 75, Jan 2002. 
[42]. J. Fridrich, “Security of fragile authentication watermarks with localization,” 
 70
Nielsen, S. Thatte, and D.Winer. Simple Object Access Protocol (SOAP) 1.1, 
W3C Note, May. 2000. http://www.w3.org/TR/2000/NOTE-SOAP-20000508/.  
[58]. MICHAEL T. GOODRICH, and ROBERTO TAMASSIA, "Efficient 
Authenticated Dictionaries with Skip Lists and Commutative Hashing",  
[59]. Karel Wouters, Bart Preneel, Ana Isabel Gonz´ alez-Tablas, and Arturo 
Ribagorda, "Towards an XML Format for Time-Stamps", ACM Workshop on 
XML Security, Nov. 22, 2002, Fairfax VA, USA 
[60]. R. L. Rivest, A. Shamir, and L. Adleman, “ A method for obtaining digital 
signatures and public-key cryptosystems, Communications of the ACM, 
21(2):120–126, 1978. 
[61]. Shamir, “How to Share a Secret ”, Communication of the ACM Vol.22, 
pp.612-612, 1979. 
[62]. G.R. Blakley, “Safeguarding Cryptographic Keys”, in Proc. NCC, Vol. 48, 
pp.313-317, AFIPS Press, Montvale, N.J. 1979 
[63]. HE, J., and DAWSON, E., “Multistage secret sharing based on one-way 
function”, Electronics letters, Vol. 30, No. 19, 1994, pp.1591-1592 
[64]. Imgemarsson and G. J. Simmons, “A Protocol to Set Up Shared Secret 
Schemas without Assistance of a Mutually Trusted Party”, In Advances in 
Cryptology and in Proc. of Eurocrypt ’90, pp.226-282 Springer Verlag, Berlin, 
1990 
[65]. H. Koga, “A general for formula of the (t, n) – threshold visual secret sharing 
schema” 
[66]. P.D’ Arco and D. R.Stinson, “On unconditionally secure robust distribution 
centers”, Advances in Cryptology, Proceedings of ASIACRYPT 2002, Lecture 
Notes in Computer Science, Vol. 2501, pp. 346-363, Springer-Verlag, 2002. 
[67]. Ted Husted, Cedric Dumoulin, George Franciscus and David Winterfeldt, 
“Struts in Action”, Manning Publications Company November 2002 
[68]. “Web services architecture using MVC style”, 
http://www-106.ibm.com/developerworks/webservices/library/ws-mvc/ 
[69]. Alan Shalloway and James R. Trott, “Design Pattern: Elements of Reusable 
Object-Oriented Software”, Addison-Wesley Pub Co; 1st edition (January 15, 
1995) 
[70]. 結城浩, “Design Pattern 於 Java 語言上的實習運用”, 博碩文化 2002. 
[71]. JohnViega and Gary McGraw, “Building Secure Software”, Addison-Wesley 
Pub Co; 1st edition (September 24, 2001) 
[72]. Phen-Lan Lin, Po-Whei Huang, “Block-Complexity Based information Hiding 
Scheme for Binary Images”, WSEAS Trans. Signal Processing, Vol. 2, No.5, 
pp.718-725, May, 2006. (EI) 
 72
 74
[86]. 謝仲凱,“應用於影像驗證及回復的階層式浮水印機制,” 碩士論文,中興大
學資訊科學系 
[87]. 黃俊霖,“二元影像區塊變量資訊隱藏機制之研究,” 碩士論文, 靜宜大學資
訊管理系 
 
 
6. 研究成果自評與討論 
6.1 研究成果 
本研究之研發成果尚佳,在學術上已有論文發表5篇並有2篇撰寫中,在實作上有
系統開發 3 個, 在訓練培養學生方面則有6篇相關碩士論文. 分列如下 
A. 論文發表 
[1]. Phen-Lan Lin, Po-Whei Huang, “Block-Complexity Based information Hiding 
Scheme for Binary Images”, WSEAS Trans. Signal Processing, Vol. 2, No.5, 
pp.718-725, May, 2006. (EI) 
[2]. Phen-Lan Lin, Chung-Kai Hsieh, Po-Whei Huang,” Hierarchical Digital 
Watermarking Method for Image Tamper Detection and Recovery”, Pattern 
Recognition, Vol. 38/12, pp. 2519-2529, 2005. (SCI) 
[3]. Lin J.L., Huang J. L., and Lin P.L., “Spatial-Domain Image Authentication 
Mechanism based on Fourier Transform”, Communications of the CCISA, Vol. 
10, No. 1, PP. 64-73, 2004. 
[4]. Phen-Lan Lin, Po-Whei Huang, “Data Hiding Scheme for Binary Images 
with Content-based Hiding Rate,” in Proceeding WSEAS. Signal and 
Image Processing, Istanbul, Turkey, May 27-29, 2006. 
[5]. Phen-Lan Lin, Po-Whei Huang, and An-Wei Pong, “A Fragile Watermarking 
Scheme for Image Authentication with Localization and Recovery”, IEEE 
MSE 2004, Dec. 12-15, Florida, USA 
 
B.實作系統建置 
(1) 一個可驗證 .rtf格式文件所有權之系統 
(2) 一個多點傳送的安全公告網站系統 
(3) 一個可驗證網頁整體性之系統 
 
C. 碩士論文 
[1]. 張庭榕,“以秘密分享為基礎之文件浮水印機制”,碩士論文,靜宜大學資訊管
理系 
[2]. 涂治中,“安全的多點傳送網站公告系統模型”碩士論文,靜宜大學資訊管理
系 
[3]. 翁利同,“利用區塊特徵群集達成多功能數位影像之驗證及回復”,碩士論文,
                            
 
 2 
encryption further strengthens the security. That all 
security parameters are user dependent and can be 
computed at both ends individually based on 
Diffie-Hellman key exchange method not only makes 
the scheme robust against collage attack but truly 
oblivious, as well. The experiments demonstrate that 
our scheme can detect and localize any tampering of 
size 8x8 pixels and can recover a 40% damaged image 
to an intelligible one with 24dB. As for incidentally 
manipulated images, our scheme can invalidate all the 
blocks but will not further degrade the images. 
 Comparing with the scheme of Celik et al. [14], 
ours has better tamper localization accuracy while 
trading off 2-3 dB of the watermarked image for 
recovery. 
  The rest of the paper is organized as follows. In 
section 2, the CRC is briefly described. Our proposed 
scheme is presented in section 3 and 4, respectively. 
The experimental results are described and illustrated in 
section 5. And, the conclusive remark is in section 6. 
 
II. CYCLIC REDUNDANCY CHECK  
  The cyclic redundancy check (CRC, also known as 
the polynomial code) is based upon treating bit strings 
as representations of polynomials with coefficients of 0 
and 1 only. A k-bit string is regarded as the coefficient 
list for a polynomial with k terms, ranging from Xk-1 to 
X0. Such a polynomial is said to be of degree k-1. The 
high-order bit is the coefficient of Xk-1; the next bit is 
the coefficient of Xk-2, and so on. For example, a  bit 
string 110001 has six bits and thus represents  a six-term 
polynomial X5+X4+1 with coefficients 1,1,0,0,0,1. 
The polynomial arithmetic is performed in modulo 2, 
according to the rules of algebraic field theory. Both 
addition and subtraction are identical to EXCLUSIVE 
OR. Long division is carried out the same way as it is in 
binary except that the subtraction is done in modulo 2. 
When the CRC method is employed, the encoder/sender 
and the decoder/receiver must agree upon a generator 
polynomial, G(x), in advance. Both the high- and low- 
order bits of the generator must be 1. To compute the 
checksum for some message with m bits, corresponding 
to the polynomial M(x), the message must be longer 
than the generator polynomial. The idea is to append a 
checksum to the end of the message in such a way that 
the polynomial represented by the message with the 
checksum is divisible by G(x). When the decoder gets 
the message with the CRC checksum, it tries dividing it 
by G(x). If there is a remainder, there has been an error 
with it [18].  
 
III. THE PROPOSED AUTHENTICATION 
METHOD 
Unlike using a small logo or a random binary bit 
stream as the watermark for image authentication, we 
propose a block-wise content-based watermarking for 
tamper detection, localization, and restoration. The size 
of each block is 8x8 pixels and the image is assumed to 
be 8N x 8N, 1<=N<=256.  
In the following, we describe our proposed 
authentication method from the phases of watermark 
generation, watermark embedding, and image 
authentication. 
3.1 Watermark Generation 
First, we divide the original image into 
non-overlapping blocks of 8×8 pixels, as shown in Fig. 
1(a). The watermark of each block is an encrypted form 
of the block signature.   
A. Block Signature Generation   
Including the block indices in the block signature has 
been proposed for block-wise independent 
authentication schemes as a countermeasure to VQ 
attack, “yet it is possible to launch an attack given a 
large enough database of watermarked images” [14]. 
On the other hand, the product rule of probability in 
Statistics implies that the probability of two blocks that 
are randomly spread in the image being tampered 
simultaneously is about the probability of one block 
being tampered squared.  
In order to be more robust against VQ attack and 
have a higher tamper detection rate, we design the 
block signature including its own location indices (x, y) 
and the content-feature of another block. For easier 
description, we name this other block the embedded 
block hereafter.  
Embedded Block Determination 
For each block with location indices (x, y), we apply 
the 2-D Torus automorphism [20] as shown in Eq. (1) to 
determine the indices (x’,  y’) of the embedded block.  
(1)           mod
1
11
'
'
N
y
x
kky
x
÷÷
ø
ö
çç
è
æ
´÷÷
ø
ö
çç
è
æ
+
=÷÷
ø
ö
çç
è
æ
 
where (x, y), (x’, y’)Î [ 0, N-1 ] ×  [ 0, N-1 ], N is the 
number of blocks in each dimension, and k Î [ 0, N-1 ] 
is a security parameter. 
Block Feature Extraction  
The block feature includes a 96-bit intensity feature 
and its 16-bit hash value.  
We calculate the average intensity of each 2×2 
sub-block, as shown in Fig. 1(b), with the six 
high-order bits of each pixel within it and concatenate 
all these average intensities within the block from 
left-to-right, top-to-bottom to form the intensity-feature 
of one block. For 8-bit gray-scale images, this intensity 
feature of one block contains exactly 96 bits (= 6 bits 
/sub-block * (4*4) sub-blocks). 
We then apply MD5 to the 96-bit intensity feature to 
obtain a 128-bit hash value. Divide these 128 bits into 
eight sections of 16 bits each and XOR these  8-bit 
streams bit by bit to get the 16-bit hash value. 
 4 
Fig.2, and concatenate these bits to form a 128-bit 
watermark of the block. We then decrypt the watermark 
by applying CBC-3DES with keys K1, K2 and IV to 
reveal the 128-bit block signature-authenticator, where 
K1, K2, and IV can be generated at the receiving end 
under the public-key infrastructure and will be 
discussed later in this paper. This authenticator is again 
put back to the two LSB’s of each pixel orderly within 
the block for stage-2 verification and error recovery.   
Signature-Authenticator Validation:  
For each 128-bit block authenticator, we perform 
the CRC check by dividing it with G(x). If there is a 
remainder, the block is tampered somewhat and is 
marked invalid.  
B. Stage-2 Verification: Block Feature Validation 
For those blocks passing stage-1 verification, we 
are sure that the two LSB’s of each pixel within them 
have not been tampered. To ensure that these blocks 
have not been VQ attacked or maliciously attacked their 
six high-order bits only, we perform the stage-2 
verification. For easier description, we denote the block 
under verification block_A.  
We verify the six high-order bits of each pixel in 
the 2x2 sub-block within b lock_A. Different from the 
block-wise independent verification in stage-1, this 
stage concerns with an additional block, denoted 
block_B, of which the signature contains the feature of 
block_A. The validation procedure is as follows.  
1. Compute the location of block_B using Eq. (1) with 
the secret key K. 
2. Mark block_A valid and complete this verification if 
block_B is invalid.  
3. Calculate the feature of each 2x2 sub-block within 
block_A as described in section 3.1.1 and denote it 
Vai, i=1… 16. 
4. Obtain Va =Va1 ||… ||Va16. 
5. Extract the 16-bit hash value Vb from the block 
signature starting at bit 112. 
6. Mark block_A invalid if Va ¹ Vb and complete this 
verification.  
7. Extract the 6-bit feature value of each sub-block, 
denoted Vbi, i=1… 16, from the block signature, 
starting at bit 16. 
8. Compare Vai with Vbi. Mark block_A valid if Vai =Vbi, 
i=1… 16; otherwise, mark it invalid and complete this 
verification. 
Note that we apply the principle of “not guilty until 
proved” in step2, since we have no way of telling 
whether block_A is tampered or not when block_B is 
invalid  
Note also that stage-1 validation serves two 
purposes: a) quickly locating blocks that are under 
general modifications except VQ attack and maliciously 
tampering the six high-order bits only; b) providing 
stage-2 verification with the correct feature value, for 
without it, we cannot determine whether block_A or 
block_B is tampered when the test condition in stage-2 
does not match.  
3.4 Cropping Detection            
Since stage-1 block signature-authenticator validation 
is block-wise independent, we can apply the 
“sliding-window” search pointed out in [14] to regain 
the synchronization with the block-boundaries. The 
detection procedure is as follow.  
1. Start at the top-left corner with a sliding-window of   
one pixel to the right then continue next row till one 
valid block authenticator is found.  
2. Extract the first 16 bits from the authenticator as the 
block indices (m1, n1) and thus, we have regained the 
synchronization with the top-left block boundary. 
3. Do both step 1 and 2 from the right-bottom corner 
with reverse sliding direction to regain the 
right-bottom corner block boundaries (m2, n2). 
3.5 Security Parameters Generation 
   There are in total five security parameters used in 
our proposed scheme. They are: a) the CRC generator 
polynomial G(x) of degree r for signature-authenticator 
validation, b) two keys K1 and K2 of length 56 each for 
3DES encryption and IV of 64 bits for CBC, and c) the 
secret K used in Torus automorphism for embedded 
block selection. Both the sender and the receiver must 
possess these security parameters in order to perform 
image watermarking and authentication. To save the 
bandwidth and the hassle for transmitting these 
parameters either through secure channel or through 
virtual private channel, we propose generating these 
keys under the public-key infrastructure by using 
Diffie-Hellman key exchange method. 
Denote (Xa, Ya) and (Xb, Yb) as the (private, public) 
key pairs of the sender and the receiver, respectively, p 
as a large prime, and g as p’s primitive root. The 
generation scenario is as follows. 
1. Determine the length L of p = (8-2 + (56-2)*2 + (64 
-2)+log2N) ×  2, where 8-2 is that both the MSB and 
the LSB of G(x) must be 1, -2 from both 56 and 64 is 
to force both the MSB and the LSB of K1, K2, and IV 
to be 1, and ×2 is for reducing the possibility of 
generating a common key with its length too short.   
2. By Diffie-Hellman key exchange method, both 
parties can compute the common key Ks= Yb
Xa mod 
p=Ya
Xb.mod p, where Ya= g
Xa mod p and Yb= g
Xb mod 
p, Xa, Xb <p and is randomly chosen by the sender and 
the receiver, respectively. 
3. Obtain the five security parameters from the 
computed Ks by extracting the bits from MSB toward 
LSB, and we have 
G(x)= x7 +Ks(0)x
6 +Ks(1)x
5+… +Ks(5)x+1, 
K1=1 Ks(6)Ks(7) … Ks(59)1, 
K2=1 Ks(60)Ks(61) … Ks(113)1, 
IV=1Ks(114)Ks(115) … Ks(175)1 
K =1Ks(176)Ks(177) … Ks(176+ log2N -2) 
 
IV. THE PROPOSED IMAGE RECOVERY 
METHOD 
 After the image gone through the authentication 
process, all the blocks are marked either valid or 
invalid. The system then tries to recover those invalid 
blocks. The two-stage recovery process is as follows. 
Stage-1: Recover each invalid block with its feature 
embedded in the designated block if the designated 
 6 
thus, they will not be further degraded even though they 
are correctly detected as changed. 
The above results demonstrate (a) that our 
authentication scheme is indeed fragile and thus can 
detect and localize any malicious or incidental 
modification of size 8x8 and above, (b) that our 
restoration scheme can recover the maliciously 
tampered image to a very clear one with PSNR better 
than 34 dB as long as the tampered region is not more 
than 20%, and will not further degrade the incidentally 
manipulated images.  
 
 5.2 Recovery from Cropping Attack  
In this experiment, we test the recovery capability 
from cropping attack. We simulate the attacks by either 
blacking out or whiting out a portion of the test image 
at-various locations as shown in Figs. 5 (a)-(c). Table 1 
lists the percentage of blocks not recovered in phase-I 
restoration relative to the percentage of blocks cropped. 
The results indicate that less than 7.5% of the tampered 
blocks have not been recovered in phase-I if less than 
30% of the blocks are cropped. The ratio increases to 
20% if the percentage of blocks cropped increases to 
50. The two-stage recovered images are shown in Figs. 
6 (a)-(c). The PSNR’s of all recovered images are listed 
in Table 2.  
 
Observing both Table 2 and Fig. 6, we find that our 
(a) (c) (b) 
Fig.6. The recovered Lena’s from the cropped 
images shown in Fig. 5. 
 Fig.7. The PSNR of the recovered Lena with 
various CRC-r codes 
36.11 
34.34 
32.65 
31.45 
16.14 15.67 
12.24 
10 
20 
30 
40 
8 16 24 32 48 64 96 CRC-r 
Table1. The percentage of blocks not recovered in 
phase-I restoration relative to the percentage of 
blocks cropped 
Cropped (%) 5 10 15 20 30 40 50 70 
Not recovered 
(%) 
0 2 2.2 4.8 7.5 14 20 39 
Table 2. The PSNR of the recovered image IR relative 
to the size of the cropped region 
Cropped size Cropped % Location PSNR (dB) 
6x256 2.34 top 48.97 
40x40 2.4 center 39.96 
70x75 8.01 corner 42.32 
80x80 9.7 center 36.24 
256x64 25. left 31.60 
85x256 34.0 top 27.37 
164x164 40.1 center 23.97 
200x200 61.0 center 19.47 
 
Fig.5. Lena’s with various cropping sizes: (a) 
256x64, (b) 85x256, (c) 200x200. 
(a) (b) (c) 
 8 
invisible watermarking schemes,” Image 
Processing, IEEE Transactions on, Volume: 9 
Issue: 3, March 2000. 
[9] P.S.L.M Barreto, H. Y. Kim,  and V.  Rijmen, 
“Toward secure public -key blockwise fragile 
authentication watermarking,” Vision, Image and 
Signal Processing , IEE Proceedings, Volume: 149 
Issue: 2, April 2002. 
[10]. J. Fridrich, ``Security of Fragile Authentication 
Watermarks with Localization,'' Proc. SPIE: 
Security and Watermarking of Multimedia 
Contents, Vol. 4675, pp. 691-700, 2002. 
[11] D. Kundur and D. Hatzinakos, “Digital 
watermarking for telltale tamper proofing and 
authentication,” Proceedings of the IEEE , Volume: 
87 Issue: 7, July 1999. 
[12] R. Radhakrisnan and N. Memon, ``On the Security 
of the SARI Image Authentication System,'' Proc. 
IEEE Int. Conf. on Image Proc., Vol. III, pp. 
971-974, 2001. 
 [13] Ching-Yung Lin and Shih-Fu Chang, “A robust 
image authentication method distinguishing JPEG 
compression from malicious manipulation,” 
Circuits and Systems for Video Technology, IEEE 
Transactions on, Volume: 11 Issue: 2, Feb 2001. 
[14] M. Utku Celik, G. Sharma, E. Saber, and A. Murat 
Tekalp, “Hierarchical watermarking for secure 
image authentication with localization,” Image 
Processing, IEEE Transactions on, Volume: 11 
Issue: 6, June 2002 
[15] R. Chandramouli, R. and N. D. Memon, “On 
sequential watermark detection,” Signal 
Processing, IEEE Transactions on Volume: 51 
Issue: 4, April 2003.  
[16] C. C. Chang, K. F.  Hwang, and M. S. Hwang, 
”Robust authentication scheme for protecting 
copyrights of images and graphics,” Vision, Image 
and Signal Processing, IEE Proceedings-, Volume: 
149 Issue: 1, Feb. 2002. 
[17] T. Kasami, Shu Lin, and W. Peterson, ”Polynomial 
codes ,” Information Theory, IEEE Transactions on, 
Volume: 14 Issue: 6, Nov 1968. 
[18] Andrew S. Tanebaum, “Computer Networks, 
Fourth Edition,” The Netherlands Pearson 
Education International, 2003. 
[19] C. Honsinger, “Data embedding using phase 
dispersion,” Secure Images and Image 
Authentication, IEE Seminar on, 10 April 2000. 
[20] G. Voyatzis  and I. Pitas, “Applications of toral 
automorphisms in image watermarking,” Image 
Processing, 1996, Proceedings, International 
Conference on, Volume: 1, 16-19 Sept. 1996. 
 
2520 P.L. Lin et al. / Pattern Recognition 38 (2005) 2519–2529
while permitting content-preserving processing such as cod-
ing and scanning [2,10]. In Ref. [20], the above categories
(1) and (2) are combined as fragile watermarking, whereas
category (3) is named as semi-fragile watermarking. Some
examples of these schemes are presented in Refs. [21–24].
In this paper, we adopt the deﬁnitions of fragile and semi-
fragile watermarking presented in Ref. [20].
Wong [12] proposed a public-key fragile watermark-
ing scheme that embeds a digital signature of each block
within the image into the least signiﬁcant bits of the same
block. However, Holliman and Memon [25] soon presented
a vector quantization (VQ) counterfeiting attack that can
construct a counterfeit image from a VQ codebook gen-
erated from a set of watermarked images. To solve the
problem of VQ counterfeiting attack, several enhanced
algorithms were proposed [7,25,27]. Nonetheless, they
either fail to effectively address the problem or sacriﬁce
tamper localization accuracy of the original methods [20].
Celik et al. then presented an algorithm based on Wong’s
scheme and demonstrated that their algorithm can thwart
the VQ codebook attack while sustaining the localization
property [20].
In this paper, we present an efﬁcient and effective dig-
ital watermarking method for image tamper detection and
recovery. Our method is efﬁcient as it only uses simple op-
erations such as parity check and comparison between av-
erage intensities. It is effective because the scheme inspects
the image hierarchically with the inspection view increases
along with the hierarchy so that the accuracy of tamper lo-
calization can be ensured. That is, if a tampered block is not
detected in level-1 inspection, it will be detected in level-
2 or level-3 inspection with a probability of nearly 1. Our
method is also very storage effective, as it only requires a se-
cret key and a public chaotic mixing algorithm to recover the
tampered areas. The experimental results demonstrate that
the precision of tamper detection and localization is close to
100% after level-2 inspection and the tamper recovery rate
is better than 93% for a less than half tampered image. As
compared with the method in Ref. [20], our method is not
only as simple and as effective in tamper detection and lo-
calization, it also provides with the capability of tamper re-
covery by trading off the quality of the watermarked images
about 5 dB.
The remainder of this paper is organized as follows. In
Section 2, we brieﬂy describe VQ counterfeiting attacks and
Torus automorphism. Our proposed watermarking scheme is
presented in Section 3. In Sections 4 and 5, we demonstrate
the experimental results and analyze the performance of
our scheme. Finally, the concluding remarks are given in
Section 6.
2. Backgrounds
In this section, we brieﬂy describe both vector quantiza-
tion (VQ) counterfeiting attacks and Torus automorphism.
2.1. VQ counterfeiting attacks
Holliman and Memon [25] presented a counterfeiting at-
tack on block-wise independent watermarking schemes. In
such an attack, the attacker is able to create a counterfeit im-
age by using a collage of watermarked blocks selected from
a large database. Because block-wise independent schemes
validate the watermark of each individual block and the wa-
termark of each block comprises only the information of the
block itself, the counterfeit image generated from the VQ
codebook can easily pass the authentication test of block-
wise independent schemes.
2.2. Torus automorphism
Torus automorphism is a kind of dynamic system. Brieﬂy
speaking, a dynamic system is a system whose states change
with time t. When t is discrete, a dynamic system can be
presented as an iteration of a function f, i.e., St+1 = f (St ),
t ∈ Z = {0, 1, 2, . . .}, St , St+1 are the states at time t and
t + 1, respectively. A two-dimensional Torus automorphism
can be considered as a permutation function or a spatial
transformation of a plane region. This transformation can be
performed using a 2 × 2 matrix A with constant elements.
More speciﬁcally, a state St+1 or a point (xi+1, yi+1) can be
transformed from another state St or another point (xi , yi)
by
A=
(
a1 a2
a3 a4
)
,
(
xi+1
yi+1
)
= A×
(
xi
yi
)
modN , (1)
where ai ∈ Z, |A| (the determinant of A) =1, and A has
eigenvalues 1,2 ∈ R − {−1, 0, 1}, R is the set of rational
numbers. The detailed characteristics of A are described in
Refs. [26,28]. A set of successive points {S0, S1, S2, . . .},
generated by Eq. (1), composes an orbit ϑ of the system and
the initial point S0=(x0, y0) classiﬁes ϑ into two categories.
When x0 and/or y0 are irrational, ϑ is inﬁnite. When both
x0 and y0 are rational, ϑ is chaotic and periodic at every R
times, i.e., SR = S0. R is called the “recurrence time”.
Voyatzis and Pitas [26] presented a one-parameter, two-
dimensional, discrete Torus automorphism, shown in Eq.
(2), for creating a unique and random mapping of the pixels
within an image:
A=
(
1 1
k k + 1
)
,
(
xi+1
yi+1
)
= A×
(
xi
yi
)
modN , (2)
where (xi , yi) ∈ [0, N−1]×[0, N−1] and k ∈ [0, N−1].
The recurrence time R depends upon the parameters k, N,
and the initial point (x0, y0). In most cases, R is equal to
N − 1 or N + 1, when N is prime [26,28].
3. The proposed scheme
Our proposed scheme can perform both tamper detec-
tion and recovery for tampered images. While tamper detec-
2522 P.L. Lin et al. / Pattern Recognition 38 (2005) 2519–2529
(a) Block A and one of its sub-block
 (b) Block B and one of its sub-block 
1 3 9 11
2 4 10 12 
5 7 13 15 
6 8 14 16 
a1 a2 a3 a4 a5 a6 a7 a8
1 3 9 11
2 4 10 12
5 7 13 15
6 8 14 16
avg_As 
= (I1+I2+I3+I4)/4 
r (c) The six MSBs of avg_As
v ` p of B
Fig. 1. Watermark generation procedure for the sub-block comprising pixels 1,2,3,4: (a) Block A and one of its sub-block; (b) block B and
one of its sub-block; (c) the six MSBs of avg_A.
       bit 1 2 3 4 5 6 7 8
pixel 1 
pixel 2 
pixel 3 
pixel 4 
v r
p r
r r
r r
Original image data Embedding data
Fig. 2. The 8-bit Watermark (v, p, r) embedded in pixels 1,2,3,4.
where num is the total number of 1s in the six MSBs of
avg_Bs .
4. From the mapping sequence generated in the preparation
step, obtain block A whose recovery information will be
stored in block B.
5. Compute the average intensity of each corresponding
sub-block As within A, as shown in Fig. 1(a), and denote
it avg_As .
6. Obtain the recovery intensity r of As by truncating the
two LSBs in avg_As , as shown in Fig. 1(c).
7. Embed the 3-tuple-watermark (v, p, r), eight bits in all,
onto the two LSBs of each pixel within Bs , as shown in
Fig. 2.
The watermark generation procedure for the sub-block
comprising pixels 1, 2, 3, and 4 is illustrated in Fig. 1. How
the 8-bit (v, p, r) are embedded in these four pixels is shown
in Fig. 2.
3.2. Block-based hierarchical tamper detection
The test image is ﬁrst divided into non-overlapping blocks
of 4 × 4 pixels, as in the watermark embedding process.
For each block, denoted as B ′, we ﬁrst set the two LSBs of
each pixel in B ′ to zero and compute its average intensity,
denoted as avg_B ′. We then perform 3-level hierarchical
detection. In level-1 detection, we check each 2 × 2 sub-
block within one block. In level-2 detection, we treat a 4×4
block as one unit. Finally, we check the block by extending
the inspection view to its 3×3 block-neighborhood in level-3
detection. Level-4 detection is for VQ-attack resiliency only.
The procedure of our hierarchical tamper detection scheme
is described in the following.
3.2.1. Hierarchical tamper detection algorithm
Level-1 detection. For each sub-block B ′s of 2× 2 pixels
within block B ′, perform the following steps:
1. Extract v and p from B ′s .
2. Set the two LSBs of each pixel within each B ′s to zero
and compute the average intensity for each sub-block B ′s ,
denoted as avg_B ′s .
3. Count the total number of 1s in avg_B ′s and denote it N ′s .
4. Set the parity-check bit p′ of B ′s to 1 if N ′s is odd;
otherwise, set it to 0.
5. Compare p′ with p. If they are not equal, mark B ′s erro-
neous and complete the detection for B ′s .
6. Set the algebraic relation v′ = 1 if avg_B ′s >= avg_B ′;
otherwise, set v′ = 0.
7. Compare v′ with v. If they are not equal, mark B ′s er-
roneous and complete the detection for B ′s ; otherwise,
mark it valid.
Level-2 detection. For each block of size 4 × 4 pixels,
mark this block erroneous if any of its sub-block is marked
erroneous; otherwise, mark it valid.
2524 P.L. Lin et al. / Pattern Recognition 38 (2005) 2519–2529
Fig. 5. (a) The watermarked Car; (b) tampered Car; (c,e) detected
erroneous region; (d,f) recovered Car.
Fig. 6. (a) The watermarked Fingerprint; (b) tampered Fingerprint;
(c,e) detected erroneous regions; (d,f) recovered Fingerprints.
Fig. 6(b). Comparing Figs. 6(a) with (b), we can hardly dif-
ferentiate one from the other. Using our method, we can
detect the modiﬁcations, as shown in Figs. 6(c) and (e) with
only level-1 detection, or both level-1 and -2 detections, re-
spectively. The size of the smallest modiﬁcation is about
Fig. 7. The watermarked Beach; (b) tampered Beach; (c,e,g) de-
tected erroneous regions; (d,f,h) recovered Beaches.
8× 8 pixels. Figs. 6(d) and (f) show the recovered Finger-
prints, respectively.
(d) The watermarked Beach, as shown in Fig. 7(a), has
been inserted with a deer, as shown in Fig. 7(b). The modiﬁ-
cation is so natural that one can hardly suspect any changes
that had been made to this picture. Using our method, we
can detect the modiﬁcation, as shown in Figs. 7(c), (e), and
(g) with only level-1, both level-1 and -2, or all three lev-
els of detection, respectively. The size of the modiﬁcation
is about 68 × 68 pixels. Figs. 7(d), (f), and (h) show the
recovered Beaches, respectively.
4.2. Performance of tamper detection on 100% tampered
images
We test the tamper detection capability for large tam-
pered area with image Lena, as shown in Fig. 8(a). All
blocks in image Lena are 100% altered by the four following
methods.
M1: Covering the whole image with leaf patterns, as de-
picted in Fig. 8(b).
2526 P.L. Lin et al. / Pattern Recognition 38 (2005) 2519–2529
0
50
100
150
200
250
300
350
400
450
500
550
600
650
700
16% 26% 30% 37% 39% 41% 48% 51% 54% 57% 60% 63% 70%
The numberof altered blocks/ the number of total blocks
Th
e 
n
u
m
be
r o
f b
lo
ck
s w
ith
ou
t r
es
to
ri
ng
 
(to
tal
 bl
oc
ks
=4
09
6) 
Fig. 10. The number of un-recovered blocks for single-tampered-chunk.
0
50
100
150
200
250
20% 24% 28% 30% 33% 36% 39% 41% 45% 48% 50%
The number of altered blocks / the number of total blocks
Th
e 
n
u
m
be
r o
f b
lo
ck
s w
ith
ou
t r
es
to
ri
ng
 (t
ota
l b
lo
ck
s=
40
96
)
Fig. 11. The number of un-recovered blocks for spread-tampered-blocks.
5. Performance analyses
In this section, we analyze the performance of our method
from aspects of the ﬁdelity of watermarked images, the qual-
ity of recovered images, as well as the tamper detection rate.
5.1. Image quality analysis
We use PSNR deﬁned in Eq. (6) as the indicator of
the quality of both watermarked images and recovered
images.
PSNR= 10× log10
2552
MSE
dB, (6)
where MSE = (1/m × n)∑i<ni=0∑j<mj=0 (c′ij − cij )2, m, n
are the width and the length of the image, respectively,
and c, c′ are the pixel intensities of the two images under
comparison.
(a) PSNR of the watermarked image. Since only two LSBs
of each pixel are used for embedding the watermark, the
2528 P.L. Lin et al. / Pattern Recognition 38 (2005) 2519–2529
future research includes improvements on both security and
watermark-payload reduction while maintaining the capa-
bility of both tamper detection and recovery.
References
[1] G.I. Friedman, The trustworthy digital camera: restoring
credibility to the photographic image, in: Proceedings of the
IEEE International Conference on Image Processing, vol. II,
Chicago, IL, USA, October 1998, pp. 409–413.
[2] J. Dittmann, A. Steinmetz, R. Steinmetz, Content-based
digital signature for motion pictures authentication and
content-fragile watermarking, in: Proceedings of the IEEE
International Conference on Multimedia Computing Systems,
1999, pp. 209–213.
[3] C.Y. Lin, S.F. Chang, A robust image authentication method
surviving JPEG lossy compression, Proc. SPIE 3312 (1998)
296–307.
[4] C.S. Lu, H.Y.M. Liao, C.J. Sze, Structural digital signature for
image authentication: an incidental distortion resistant scheme,
in: Proceedings of the Multimedia Security Workshop 8th
ACM International Conference on Multimedia, Los Angeles,
CA, 2000, pp. 115–118.
[5] W. Stallings, Network Security Essentials: Application and
Standards, Prentice-Hall, Upper Saddle River, NJ, 2000.
[6] J. Fridrich, Image watermarking for tamper detection, in:
Proceedings of the IEEE International Conference on Image
Processing, vol. II, Chicago, IL, USA, October 1998, pp.
404–408.
[7] J. Fridrich, M. Goljan, A.C. Baldoza, New fragile
authentication watermark for images, in: Proceedings of
the IEEE International Conference on Image Processing,
Vancouver, BC, Canada, September 2000, pp. 10–13.
[8] D. Kundur, D. Hatzinakos, Toward a telltale watermarking
technique for tamper-prooﬁng, in: Proceedings of the IEEE
International Conference on Image Processing, vol. 2, 1998,
pp. 409–413.
[9] E. Lin, E.J. Delp, A review of fragile image watermarks, in:
Proceedings of the ACM Multimedia and Security Workshop,
Orlando, FL, November 1999, pp. 35–40.
[10] M.P. Queluz, Content-based integrity protection of digital
image, Proceedings of the SPIE, Security and Watermarking
of Multimedia Contents II, vol. 3971, Bellingham, WA, 2000,
pp. 85–93.
[11] M. Schneider, S.F. Chang, A robust content based digital
signature for image authentication, in: Proceedings of the
IEEE International Conference on Image Processing, vol. III,
Lausanne, Switzerland, September 1996, pp. 227–230.
[12] P.W. Wong, A public key watermark for image veriﬁcation
and authentication, in: Proceedings of the IEEE International
Conference on Image Processing, Chicago, IL, October 1998,
pp. 455–459.
[13] M.M. Yeung, F. Mintizer, An invisible watermarking
technique for image veriﬁcation, in: Proceedings of the IEEE
International Conference on Image Processing, vol. I, Santa
Barbara, CA, October 1997, pp. 680–683.
[14] R.L. Lagendijk, G.C. Langelaar, I. Setyawan, Watermarking
digital images and video data, IEEE Signal Process. Mag. 17
(2000) 20–46.
[15] F. Hartung, M. Kutter, Multimedia watermarking techniques,
Proc. IEEE 87 (1999) 1079–1107.
[16] M.D. Swanson, M. Kobayashi, A.H. Tewﬁk, Multimedia data
embedding and watermarking technologies, Proc. IEEE 86
(1988) 1064–1087.
[17] I.J. Cox, M.I. Miller, A.L. Mckellips, Watermarking as
communications with side information, Proc. IEEE 87 (1999)
1127–1147.
[18] C.De. Vleeschouwer, J.F. Delaigle, B. Macq, Invisibility and
application functionalities in perceptual watermarking—an
overview, Proc. IEEE 90 (1) (2002) 64–77.
[19] C.W. Wu, D. Coppersmith, F.C. Mintizer, C.P. Tresser, M.M.
Mueng, Fragile imperceptible digital watermark and privacy
control, Proceedings of the SPIE, Security and Watermarking
of Multimedia Contents, vol. 3657, January 1999, pp.79–84.
[20] M.U. Celik, G. Sharma, E. Saber, A.M. Tekalp,
Hierarchical watermarking for secure image authentication
with localization, IEEE Trans. Image Process. 11 (6) (2002)
585–594.
[21] D. Kundur, D. Hatzinakos, Digital watermarking for telltale
tamper prooﬁng and authentication, Proc. IEEE 87 (1999)
1167–1180.
[22] J. Eggers, B. Girod, Blind watermarking applied to image
authentication, in: Proceedings of the IEEE ICASSP, Salt Lake
City, UT, May 2001, pp. 1977–1980.
[23] S. Bhattacharjee, M. Kutter, Compression tolerant image
authentication, in: Proceedings of the IEEE International
Conference on Image Processing, Chicago, IL, October 1998,
pp. 435–439.
[24] C.S. Lu, H.Y. Liao, Multipurpose watermarking for image
authentication and protection, IEEE Trans. Image Process. 10
(2001) 1579–1592.
[25] M. Holliman, N. Memon, Counterfeiting attacks on oblivious
block-wise independent invisible watermarking schemes,
IEEE Trans. Image Process. 9 (2000) 432–441.
[26] G. Voyatzis, l. Pitas, Chaotic mixing of digital images
and applications to watermarking, in: Proceedings of the
European Conference on Multimedia Applications Services
and Techniques (ECMAST’96), 1996, pp. 687–689.
[27] P.W. Wong, N. Memon, Secret and public key authentication
schemes that resist vector quantization attack, Proc. SPIE 3971
(75) (2002) 417–427.
[28] G. Voyatzis, I. Pitas, Applications of toral automorphisms
in image watermarking, in: Proceedings of the International
Conference on Image Processing, vol. II, 1996, pp. 237–240.
About the Author—PHEN LAN LIN received the B.S. degree in Engineering Science from National Cheng-Kung University, Taiwan in
1973, the M.S. degree in Mathematics from Texas Tech University, Texas in 1978, and both the M.S. and Ph.D. degrees in Electrical
Engineering from Southern Methodist University, Dallas, Texas in 1992 and 1994, respectively.
  
 
 
 
 
A Data-Hiding Scheme for Binary Images 
with Content-Based Hiding Rates  
 
PHEN-LAN LIN1, PO-WHEI HUANG2
1Department of Computer Science and Information Engineering  
Providence University 
 Shalu, Taichung, TAIWAN 
lan@pu.edu.tw 
2Department of Computer Science 
National Chung Hsing University 
 Taichung, TAIWAN 
 
Abstract: A block-based information hiding scheme that hides more information into more complex blocks 
for binary images is presented. The block complexity is measured by entropy and DCT spectrum and a set 
of secret keys that categorizes block complexity prevents correct decoding from unauthorized users. The 
embedded bits are selected based on a CPT coding algorithm and a WL flippability score so that good 
balance between imperceptibility and hiding capacity can be achieved. Compared to other schemes, the 
distortion measure DRD of our scheme grows slower with hidden amount than that of either CPT or its 
enhance version CPT1. Such DRD advantage becomes very significant when compared to scheme WL. 
 
Key-Words: Data hiding, Binary image, Image complexity, Entropy, Spectrum, Stego-image 
 
1   Introduction 
Information hiding embeds secret information into 
a media in such a way that degradation made to the 
cover- or the stego-media is kept imperceptible 
and only the authorize
information correctly.
visual imperceptibilit
concerns when desig
scheme.  
Many data-hidin
hide each bit of inform
relationship of obje
non-uniform block [1
bit per 0.5 pixel chan
more bits are hidden
changed. And, the 
stego-image could pos
approach, named CPT
⎣(log2(mn +1)⎦ bits 
block of m × n pixe
pixels is presented. In
relationship of a give
modulo arithmetic to 
to encode/decode the
                        
  This research is support
Council of ROC under G
NSC-94-2213-E-126-00
scheme is later revised to trade one-bit hiding 
capacity per block for reducing visual artifacts by 
enforcing the embedded pixel adjacent to the pixel 
that has a value equals to the hidden bit [5]. 
Several algorithms are also proposed for reducing 
 
Proceedings of the 5th WSEAS International Conference on Signal Processing, Istanbul, Turkey, May 27-29, 2006 (pp40-45)d user can extract the secret 
 Hence, embedding capacity, 
y, and security are major 
ning an information-hiding 
g schemes for binary images 
ation by enforcing odd-even 
ct pixel count within a 
-3]. Such schemes hide one 
ge on an average. Thus, the 
, the more pixels will be 
more visual artifacts the 
sibly have. In [4], a different 
 scheme, that can hide up to 
of information within each 
ls by flipping at most two 
stead of enforcing odd-even 
n block, the scheme applies 
a weighted sum of the block 
 hidden information. CPT 
                         
ed by National Science 
rant 
4 
visual artifacts of hiding effect. In [3], WL score, 
which is computed according to the change in 
connectivity and smoothness of the pixel after 
bit-flipping, is presented. 
Most block-based schemes hide a fixed 
number of bits into each non-uniform block in 
which not all pixels have same color. Although 
these schemes make hidden information easier to 
be decoded at extraction without rate information, 
they are not as secure as those having hiding rate 
varied from block to block. Obviously, it is easy to 
implement schemes with non-fixed hiding rate by 
randomly generating the rates using a secret key. 
However, the potential of causing severe visual 
artifacts to stego-images using random rates exists, 
because some non-uniform but rather smooth 
blocks may be assigned to hide the most bits. 
Although CPT method needs only flip at most two 
pixels within one block even hiding its maximum 
capacity of bits; however, the chance of finding an 
embedding-pixel that will not cause visual artifacts 
after flipping is very limited when hiding near 
maximum capacity of information into rather 1
 
 
2.4 Entropy 
The entropy of a binary image, denoted H, is the 
measure of the average information in bits in that 
image. It can be calculated by  
))1log()1(log( ppppH −−+−=        (6)                                             
where p is the probability of the occurrence of 
object or background pixel   
      
 
3  Our proposed scheme-MIMC 
The goal of our scheme, More Information in 
More Complex blocks (MIMC), is to achieve a 
good balance between hiding capacity and visual 
imperceptibility with moderate security. In follows, 
we describe our scheme MIMC in detail. 
 
 
3.1 General description of scheme MIMC 
Theoretically, the complexity of each block can be 
measured by its entropy or spectrum distribution. 
Entropy measured by Eq. (6) can provide some 
insight of block complexity, though it cannot 
differentiate two different looking blocks having 
same entropy. In fact, Eq. (6) reveals information 
about the occurrence frequency of object pixels in 
a binary image, as there are only two types of 
pixels in binary images. Since confining 
object-pixel count within a preset range during 
pixel manipulation for embedding is more 
deterministic than confining entropy, we use 
object-pixel count as the substitute measure of 
block entropy and use it as the first basis for 
complexity measurement. To differentiate two 
different looking blocks with same entropy, we 
introduce a second complexity measure-spectra 
category, which is defined as the frequency 
sub-band in that spectra energy is most 
concentrated. Fig.2 is one example of three 
frequency sub-bands PL, PM, PH, where PL= [1, 14], 
PM= [15, 41], PH= [42, 63]. 
For easier implementation, we divide entropy 
into several categories and further divide blocks 
within each entropy category into three spectra 
categories. Two blocks with same object-pixel 
count belong to the same entropy category and two 
blocks with their spectra energies concentrated in 
the same sub-band will be in the same spectra 
category.  
 
 
 
DC 1 5 6 14 15 27 28 
PL: Low Freq. Region 16 26 29 42 
3 8 12 17 25 30 41 43 
9 11 PM: Medium Freq. Region 44 53 
10 19 23 32 39 45 52 54 
20 22 33 38 PH: High Freq. Region
21 34 37 47 50 56 59 61 
35 36 48 49 57 58 62 63 
Fig. 2 Frequency sub-bands: PL, PM, PH, where 
PL=[1,14], PM=[15,41], PH=[42,63] 
 
 
3.2 MIMC Procedure: 
1. Divide the host image into blocks of m × n. 
2. Check each block if it is embeddable.  
3. Divide all embeddable blocks into NH entropy 
categories with bounds [HLi, HUi] for each 
category i, 1<=i<= NH. 
4. Determine hiding rate of blocks within each 
entropy category CHi. 
5. Determine complexity (CH, CS) of each 
embeddable block B. 
6. For each embeddable block, (a) Obtain its 
hiding rate based on its (CH, CS), (b) Embed 
the hidden information.  
 
Steps 2-5 and 6.b of the above procedure are 
further described in Algorithms 1-4 and 
Algorithm_CPTM, which is our improved version 
of CPT scheme, respectively. 
 
Algorithm_1: Check if block Bi is embeddable  
1. Count its entropy Hi, the object-pixel count. 
2. Mark Bi as embeddable if Hi > threshold TH. 
 
Algorithm_2: Divide all embeddable blocks into 
NH entropy categories with bounds [HLi, HUi] for 
each category i, 1<=i<= NH. 
1. Set the number of total entropy categories    
NH, 0<NH <= ⎣(log2 (m × n +1)⎦ 
2. Randomly divide (Hmin, Hmax) into NH 
categories with each category bounded by [HLi, 
HUi], 1<=1<= NH. 
 
For example, if TH =10 and NH=5, {[HL, HU]} = 
{[10, 17], [19, 26], [28, 35], [37, 44], [46, 55]}. 
Note that we leave one pixel between bounds of 
each category so that we can force the embeddable 
block to not-embedding in case of no pixel with 
WL-score >0 can be found. 
 3
Proceedings of the 5th WSEAS International Conference on Signal Processing, Istanbul, Turkey, May 27-29, 2006 (pp40-45)
secret key set used is listed in Table 1. Figs. 4(a)-(d) 
depict the stego-images with 1000 hidden bits and 
their respective DRD. Figs. 4(e)-(h) are the 
stego-images with DRD=0.4 and their respective 
hidden amount. 
Observing Fig.4, we find that all 
stego-images maintain rather good visual quality. 
The DRDs with 1000 hidden bits for “English” 
and “Baboon” are around 1/3 of those for “Laugh” 
and “Mickey”. For a DRD of 0.4, the hiding 
capacity of the former two images is about three 
times as much as that of the later twos. Since both 
images “English” and “Baboon” are visually more 
complex than the other two images, it is logical 
that both images have more blocks that can hide 
more bits without much degrading the quality of 
the host. 
 
 
4.2 Comparison with CPT 
We conduct this experiment to find out how the 
image-quality constraints and variable block rate 
of scheme MIMC affect image imperceptibility 
when compared to scheme CPT and its enhanced 
version CPT1. For better comparison, scheme 
MIMC is tested three times with its complexity 
measurement based on: (a) spectra-grouping only, 
(b) spectra- and entropy-grouping, and (c) none, 
respectively. Such three tests are named MIMC-1, 
MIMC-2, and MIMC-3 in follows. We repeatedly 
hide same amount of data into each image, as 
shown in Fig.3, and compute the DRD of each 
stego-image. The grouping bounds and rates used 
in MIMC-1 and MIMC-2 are listed in Table 2 and 
in Table 1, respectively, while the rate for MIMC-3 
is 5.  
 The results, as shown in Fig. 5, demonstrate that 
our scheme, using either only spectra grouping as 
in MIMC-1, both spectra- and entropy-grouping as 
in MIMC-2, or no grouping but only fixed rate as 
in MIMC-3, produces stego-images with smaller 
DRD than both CPT and CPT1 do when hiding 
same amount of data in all four images. 
 
4.3 Comparison with WL scheme 
We first use scheme MIMC with block size of 8x8 
to hide 49, 98, and 147 bits of information into the 
image shown in Fig. 6 (a). We then hide 49 and 98 
bits of same information into the same image using 
scheme WL with same block size. The results, as 
shown in Figs. 6 (b)-(f), demonstrate that for 
hiding same amount of data, MIMC produced 
images with smaller DRD values because it only 
flips less than 1/2 as many pixels than scheme WL 
does. Furthermore, our scheme can produce 
stego-images with 50% more hidden bits and 
smaller DRD. 
 
 
4.4 Security check 
Four tests of using completely or partially right 
key for data extraction are conducted and the 
results are shown in Fig. 7.  
Observing the extracted information, it is 
clear that one cannot extract the correct hidden 
information without using the exact secret keys. 
Any single incorrect parameter resulted in wrong 
extracted data from the current processed block 
and the blocks followed. If we apply encryption to 
the hidden information before it was hidden, the 
probability that any attacker can extract the correct 
hidden information becomes very slim.   
 
 
5  Conclusions 
 We presented a block-based information hiding 
scheme-MIMC for binary images that can achieve 
good balance between hiding capacity and visual 
imperceptibility while maintaining moderate 
security. Unlike most block-based schemes that 
hide fixed number of bits per block, our scheme 
hides more bits into more complex blocks with 
their complexity measured by entropy and  
spectra-energy concentration. A set of secret keys 
that categorizes block complexity prevents correct 
decoding from unauthorized users. We 
demonstrated that scheme MIMC can hide good 
amount of information into various types of 
images while maintaining imperceptibility and 
extract correct hidden information only when 
using the exact key set. Compared to other 
schemes, the distortion measure DRD of 
stego-images by our scheme grows slower than 
that by either CPT or CPT1. Such DRD advantage 
becomes very significant when compared to 
scheme WL.  
   
 
  
(a)English (b) Baboon (c)Laugh (d)Micky
Fig.3. Four host images 
 
 
 5
Proceedings of the 5th WSEAS International Conference on Signal Processing, Istanbul, Turkey, May 27-29, 2006 (pp40-45)
 
植基於富利葉轉換之空間域影像驗證數位浮水印機制 
 
林居利1  黃俊霖2  林芬蘭3 
1靜宜大學資訊管理研究所 g9011514@pu.edu.tw 
2靜宜大學資訊管理研究所 g9234002@pu.edu.tw 
3靜宜大學資訊管理系所 
 
摘要 
數位浮水印應用於影像保護的技術是一種被廣泛使用的方式，本文提出一植基於富利葉轉
換與數位量化技術經由空間域嵌入之數位浮水印影像確認機制。 
此機制是以頻率域的方法將數位影像經由富利葉轉換處理，再經量化的方式將其頻譜轉換
成為黑白數位浮水印以縮減浮水印資料量，並將其以時域的方式藏入影像中。利用富利葉頻譜
對稱性的性質，可進行快速浮水印之象限位元值比對，找出影像被篡改的部份，而且無需額外
存取驗證影像。實驗結果顯示，本文所提出的方法可以有效的找出影像被切割、模糊、銳化、 修
改、以及置換的部份，足證其在影像驗證之可行性。 
 
關鍵字：富利葉轉換、數位浮水印、頻率域、影像驗證 
 
 
1 前言 
現今數位化的時代裡，許多資料皆走向數位化的方式儲存，加上網際網路的蓬勃發展，使
得大量的數位化資料流傳，加上現今政府機關及民間團體資料皆朝向數位化的方式進行資料交
換及處理，而在處理相關資料中如遇到數位影像部份，針對資料中的影像篡改所造成資料的錯
誤與偽造，影響甚大，因此影像的驗證就扮演相當重要的角色。 
目前使用數位浮水印技術操作的領域不同分為時域(spatial domain)及頻率域(frequency 
domain)兩種。時域是將數位浮水印資料直接藏入影像像素值中，一般的方式是將數位浮水印藏
入影像的LSB(least significant bit)中，由於數位浮水印的像素值加入影像的LSB像素值中，使得
加總後影像像素值改變不大，因此肉眼無法看出太大的變化；但對於影像資料經過壓縮後，利
用時域的方式就無法利用此一方式進行數位浮水印的隱藏。 
而頻率域是將影像資料轉換成頻率域的方式，利用肉眼對影像高頻變化部份不敏銳的現
象，保留低頻部份的資料，如此可以抵抗影像資料壓縮，常用的方法有離散餘弦轉換(Discrete 
Cosine Transformation, DCT) 、 富 利 葉 轉 換 (Fourier transformation) 、 小 波 轉 換 (Wavelet 
transformation)。 
影像驗證的目的在於偵測影像內容是否有變化，其應用於數位浮水印技術中具有下列幾項
特性[5]： 
1.1 不可視(invisible)：影像經過數位浮水印資訊的隱藏，人類肉眼不易查覺出與原始影
像之間的變化。 
 1
S = {I(i,j)|0≤i<M, 0≤j<M }，S(i,j)∈{0,1,2…255}      ﹙3.1﹚ 
W = {w(i,j)|0≤i<N, 0≤j<N }，w(i,j)∈{0,1,2,…255}      ﹙3.2﹚ 
其中，S 代表原始影像，W 代表數位浮水印，i 代表影像的列，j 代表影像的行；因此，
原始影像的大小為M× M，數位浮水印的大小為N× N  ，N<= M.. 
 
 
圖3.1數位浮水印藏入流程圖 
數位浮水印藏入的過程，共分成下列三步驟： 
步驟(1) 
a. 將原始影像S(i,j)以富利葉轉換法轉換成富利葉頻譜F(i,j) (如圖3.1左上)。 
b. 將F(i,j)取Log,  取其總平均值為二元化之門檻值。 
c. 將Log(F(i,j))依門檻值以二分法轉換成二元影像  W = {w(i,j)|0≤i<N, 0≤j<N }，
w(i,j)∈{0,1}。 
步驟(2) 
a. 將原始影像切割四個象限並個別取其富利葉頻譜，如圖3.1右上所示，各個象限可再切
割以得到整體偵測篡改位置的精準度。 
 3
 
圖3.2數位浮水印取回及影像偵測流程圖 
 
4實驗結果分析 
本研究所選用的實驗平台為Pentium-4 2.0GHz、512MB RAM、作業系統為Windows 2000 
Advanced Server、程式撰寫工具為Matlab R13。此外，本研究中亦分別採用Adobe Photoshop 7.0C 
與Photo Impact 8.0C 兩套影像處理軟體，作為實驗的輔助工具，在實驗的結果方面，本研究提
 5
 (a) 原圖 (b)篡改之浮水印影像 (c)偵測的篡改點 
   
   
   
圖4.1影像切割偵測實驗與結果 
 
(a) 原圖 (b) 篡改浮水印之影像 (c)偵測的篡改點 
   
   
   
圖4.2影像部分模糊化偵測實驗與結果 
 
 7
 (a) 原圖 (b) 篡改之浮水印影像 (c)偵測的篡改點 
   
   
   
圖4.5影像前6bit置換偵測實驗與結果 
 
5結論及未來努力方向 
本研究利用頻率域的方法及使用富利葉轉換後之頻譜對稱性的特性來找出篡改點，與一
般使用時域計算像素值及頻率域需要存圖的方式相比，可謂是另一種思考方向也是一個值得
嘗試的新方法。雖然目前的方法尚無法做到抗壓縮，也未考量到安全性但這也是將來我們能
夠繼續努力以及思考的方向，但就使用數位浮水印應用於影像偵測的機制上，是一個值得大
家去探討及思考的方向。 
 
6參考文獻 
1. Steve Walton, "Image authentication for a slippery new age," Dr. Dobb’s Journal (1995)  
2. Sushil Bhattacharjee and Martin Kutter, "Compression Tolerant Image Authentication," 
International Conference on Image Processing, pp. 435–439. (1998) 
3. Jiri Fridrich, "A Hybrid Watermark for Tamper Detection in Digital Images," ISSPA 99’, 
Brisbane, Australia. (1999) 
4. N. Chotikakamthorn and W. Sangiamkun, " Digital Watermarking Technique for Image 
Authentication by Neighbouring Block Similarity Measure, " Proceedings of IEEE Region 10 
International Conference on Electrical and Electronic Technology, Vol.2, pp.743-747. (2001) 
5. 陳同孝，「應用灰階浮水印及離散餘弦轉換設計之新型數位浮水印系統」，2000年科技
與管理學術研討會論文集，pp.403-410，民國八十九年. 
6. 蔡中偉，「數位影像驗證法」，碩士論文，朝陽科技大學資訊管理研究所，台中，民國
 9
 1
出席國內外學術會議報告 
93 年 12  月 29  日 
報告人姓名 
林芬蘭 服務單位及職稱 靜宜大學資訊工程系教授兼
計算機及通訊中心主任 
會議時間 自 93   年 12 月  13 日至 93   年 12   月 15    日 
地點（國.州.城市） Miami, Florida, USA 
中文：2004 IEEE 國際多媒體軟體工程研討會  
會 議 名 稱 英文：IEEE International Symposium on Multimedia Software 
EngineeringIMSE2004 
中文：一個可偵測篡改部位並將之回復之影像驗證數位浮水印機制
發表論文題目 英文：A Fragile Watermarking Scheme for Image Authentication with 
Localization and Recovery  
內容應： 
一.參加會議經過 
 此研討會於Florida International University (FIU), Miami 舉行,約有100多位分別來自
北美與歐亞的專家學者與會.除了在 Session 4A(MSE (7): Multimedia Security Including Digital 
Watermark and Encryption)發表自己的論文,也聽取兩場大會邀請演講:1,Unifying the User 
Experience, by Dr. Harald Braun, Carrier Networks Division, Siemens Information and Communication 
Networks, Inc; 2, Using Multiple Viewpoints to Improve Retrieval Effectiveness in Content-based Image 
Retrieval, by Dr. James C. French, National Science Foundation, 並且參加”The Convergence of Fixed 
and Mobile Communications: Applications, Challenges and Opportunities” panel discussion.  
二.與會心得 
1. 與 Prof. Ming Ouhyoung (Taiwan University), Prof. Su-Ching Chen (FIU), the 
program chair, Dir. Yi. Deng (FIU), Prof. Yuhua Luo (Univ. de les Illes Balears) 等多
位學者交換研究心得並討論接下來的研究重點. 
2. 參觀 School of Computer Science, FIU 的 Network Data Center, PC classrooms, 與 
research labs.,對其網路,教室,以及研究室的專業管理印象深刻並吸取經驗以作
學校計中管理之參考. 
3. Prof. Chen 提及歡迎推薦臺灣研究生前往修讀碩博士 
三．考察參觀活動（無此項活動者省略） 
四.建議 
1. FIU 借舉辦知名研討會來推展學校知名度,應可借鏡 
2. School of CS, FIU 讓老師選擇是研究或教學類別.以此做評鑑依據,也可參考 
五.攜帶資料名稱及內容 
  Proceeding, Multimedia Software Engineering, 2004.  
 
 3
I.
                                                
Abstract—A fragile, block-wise, and content-based watermarking for image authentication and recovery is 
presented. In this scheme, the watermark of each block is an encrypted form of its signature, which includes the 
block location, a content-feature of another block, and a CRC checksum. While the CRC checksum is to 
authenticating the signature, the mixture of the location indices of one block with the feature of a randomly 
selected block complicates the VQ attack. The encryption further strengthens the security. That all security 
parameters are user dependent and can be computed at both ends individually based on Diffie-Hellman key 
exchange method makes the scheme not only robust against collage attack but also truly oblivious. The 
experiments demonstrate that our scheme can detect and localize any tampering of size 8x8 pixels and above and 
can recover a 40% damaged image to an intelligible one with 24dB. As for incidentally manipulated images, our 
scheme can invalidate all the blocks but will not further degrade the images. 
 Comparing with the scheme of Celik et al. [14], ours has better tamper localization accuracy while trading 
off 2-3 dB of the PSNR of watermarked images for recovery.  
Keywords: Image Authentication, Image Recovery, Tamper Detection, Fragile Watermark. 
 
 INTRODUCTION 
Digital watermark has become more important in recent years. As a result of the wide availability of both the 
Internet and some powerful image-processing software, it’s often difficult to determine whether an image is 
authentic or not.  
Watermark technique provides us with solutions for this problem. For example, we can apply fragile 
watermark, such as in [1], to detect modifications to those images that are sensitive to any changes. Or, we can 
apply content-based fragile watermark, such as in [2-4], to detect only the malicious destructions to the images 
while tolerating the necessary manipulations such as compression. . 
Many watermarking schemes for image authentication have been proposed [5-16]. Yeung and Mintzer [5] 
proposed a binary watermarking scheme that can detect and localize changes to watermarked images. Memon 
and Wong [7] established a scheme in which an image is divided into blocks and each block contains the hash 
value calculated from the MSB’s of the pixels forming that block. Honsinger [19] also proposed an image 
authentication method that can invert the tampered region if it is tampered designedly. However, Holliman and 
Memon [8] and Baretto et al. [9] later pointed out respectively that these block-wise independent watermarking 
algorithms are vulnerable to the so-called VQ attack or transplantation attack, because it’s possible to swap 
blocks within one image and among different images without being detected. Baretto et al. [9], then, proposed a 
hash block chaining method to break up the block independence. Fridrich [10] also proposed that the 
authentication watermark should XOR the hash value of the block with more block information, such as block 
position, image index, camera ID, etc., in order to be robust against the transplantation attack. Radhakrisnan 
and Memon [12] showed that SARI [13], which is based on an invariant property between two blocks, is also 
vulnerable to collage attack and suggested further complicating the block relationship by incrementing it among 
three or more blocks. Celik et al. [14] proposed a method in which the watermark is calculated in a multilevel 
hierarchy such that both the accuracy of tamper localization and the VQ attack resiliency could be achieved.  
In this paper, we propose a new fragile, block-wise, and content-based watermarking for image authentication 
and recovery. The watermark of each block is an encrypted form of its signature, which includes the block 
location, a content-feature of another block, and a Cyclic Redundancy Check (CRC) checksum [18]. While the 
CRC checksum is to authenticating the signature, the mixture of the location indices of one block with the 
feature of a randomly selected block complicates the VQ attack. The encryption further strengthens the security. 
That all security parameters are user dependent and can be computed at both ends individually based on 
Diffie-Hellman key exchange method not only makes the scheme robust against collage attack but truly 
oblivious, as well. The experiments demonstrate that our scheme can detect and localize any tampering of size 
8x8 pixels and can recover a 40% damaged image to an intelligible one with 24dB. As for incidentally 
manipulated images, our scheme can invalidate all the blocks but will not further degrade the images. 
 Comparing with the scheme of Celik et al. [14], ours has better tamper localization accuracy while trading 
off 2-3 dB of the watermarked image for recovery. 
  The rest of the paper is organized as follows. In section 2, the CRC is briefly described. Our proposed scheme 
is presented in section 3 and 4, respectively. The experimental results are described and illustrated in section 5. 
And, the conclusive remark is in section 6. 
 
II. CYCLIC REDUNDANCY CHECK  
  The cyclic redundancy check (CRC, also known as the polynomial code) is based upon treating bit strings as 
representations of polynomials with coefficients of 0 and 1 only. A k-bit string is regarded as the coefficient list 
for a polynomial with k terms, ranging from Xk-1 to X0. Such a polynomial is said to be of degree k-1. The 
high-order bit is the coefficient of Xk-1; the next bit is the coefficient of Xk-2, and so on. For example, a bit string 
110001 has six bits and thus represents a six-term polynomial X5+X4+1 with coefficients 1,1,0,0,0,1. 
 
. This research is supported by National Science Council of ROC under Grant NSC-92-2213-E-126-009 
 
 
 
Block Signature Formation 
Attach the block indices (x, y), 1<= x, y<= 256, to the front of the 112-bit block feature of the embedded block 
to form a 128-bit block signature, as shown in Fig. 1(c).  
B. Block Signature-Authenticator Generation 
Adapting the concept of using CRC technique for error detection in network communication, we want to 
generate a block signature-authenticator from the extracted 128-bit block signature and its CRC-r checksum, 
where r can be 8, 16, 24, or 32, depending on the system’s requirement for security and the quality of the 
recovered image. The signature-authenticator is generated as follows.  
1. Replace the r least significant bits of the 128-bit signature with r “0”s, so that the bit string still contains 128 
bits and corresponds to the polynomial xrM(x) in CRC-r code generation.  
2. Choose one polynomial G(x) of degree r and divide the bit string corresponding to G(x) into the bit string 
corresponding to xrM(x) using modulo-2 division.  
3. Subtract the remainder from the bit string corresponding to xrM(x) using modulo-2 subtraction. The result is 
the 128-bit signature-authenticator for that block.  
Note that G(x) must be kept as a secret parameter accessible only to both the sender and the receiver so that 
the malicious attacker can not easily tamper the image without being detected.  
C. Block Watermark Generation 
The larger degree of polynomial G(x) we choose for generating the authenticator, the more secure the 
system will be. However, the larger r means more feature information loss that will cause the system to give in 
the quality of the recovered image. In order to reconstruct a higher quality image while maintaining the security, 
we keep r as low as 8 and strengthen the security by encrypting each 128-bit signature-authenticator using 
CBC-3DES with two keys K1, K2 and an initialization vector IV to generate the respective 128-bit block 
watermark. 
3.2 Watermark embedding 
    The 128-bit watermark is embedded into the two low order bit planes of the block orderly from left-to-right 
and top-to-bottom, as shown in Fig.2.  
3.3. Image Authentication 
The image can be validated with only the knowledge of the G(x) used for CRC-r code generation, the secret 
key K of Torus automorphism used for selecting the watermark embedded block, the two keys K1,K2  for 3DES, 
the initialization vector IV for CBC, and the size of the image. No other information is required for this process.  
For a full-size test image, we first divide it into blocks of 8x8 pixels. We then perform the following 
2-stages verification. If the size of the test image is smaller than that of the original, due to loss of 
synchronization or cropping, for example, the system will first pad the test image to the full size with either 
white- or black-pixels. The issue of detecting which corner or side has been cropped will be discussed later on.  
A. Stage-1 Verification: Block 
Signature-Authenticator Validation 
In stage-1 verification, we extract and validate the signature-authenticator for each block within the entire 
image.  
{0,1,2,3,4,5,6,7} 
{8, . . . . . . . ,15} 
{16,. . . . . . .,23} 
{……………...} 
{56,. . . . . . .,63} 
 5
8 
8 
(a)Bxy 
Fig. 2. Embedding the 128-bit watermark onto the 
two LSB’s of pixel 0,1,…,63 within Bxy. 
(b) 
Pxl 2: 
Original image data Embedde
0 1 2 3 4 5 6 7 bit 
W0 W1
W4 W5
W6 W7
W2 W3
W126 W127
Pxl 1: 
Pxl 3: 
Pxl 0: 
Pxl 63: 
 7
“sliding-window” search pointed out in [14] to regain the synchronization with the block-boundaries. The 
detection procedure is as follow.  
1. Start at the top-left corner with a sliding-window of   one pixel to the right then continue next row till one 
valid block authenticator is found.  
2. Extract the first 16 bits from the authenticator as the block indices (m1, n1) and thus, we have regained the 
synchronization with the top-left block boundary. 
3. Do both step 1 and 2 from the right-bottom corner with reverse sliding direction to regain the right-bottom 
corner block boundaries (m2, n2). 
3.5 Security Parameters Generation 
   There are in total five security parameters used in our proposed scheme. They are: a) the CRC generator 
polynomial G(x) of degree r for signature-authenticator validation, b) two keys K1 and K2 of length 56 each for 
3DES encryption and IV of 64 bits for CBC, and c) the secret K used in Torus automorphism for embedded block 
selection. Both the sender and the receiver must possess these security parameters in order to perform image 
watermarking and authentication. To save the bandwidth and the hassle for transmitting these parameters either 
through secure channel or through virtual private channel, we propose generating these keys under the 
public-key infrastructure by using Diffie-Hellman key exchange method. 
Denote (Xa, Ya) and (Xb, Yb) as the (private, public) key pairs of the sender and the receiver, respectively, p as a 
large prime, and g as p’s primitive root. The generation scenario is as follows. 
1. Determine the length L of p = (8-2 + (56-2)*2 + (64 -2)+log2N) × 2, where 8-2 is that both the MSB and the 
LSB of G(x) must be 1, -2 from both 56 and 64 is to force both the MSB and the LSB of K1, K2, and IV to be 
1, and ×2 is for reducing the possibility of generating a common key with its length too short.   
2. By Diffie-Hellman key exchange method, both parties can compute the common key Ks= YbXa mod p=YaXb.mod 
p, where Ya= gXa mod p and Yb= gXb mod p, Xa, Xb <p and is randomly chosen by the sender and the receiver, 
respectively. 
3. Obtain the five security parameters from the computed Ks by extracting the bits from MSB toward LSB, and 
we have 
G(x)= x7+Ks(0)x6+Ks(1)x5+…+Ks(5)x+1, 
K1=1 Ks(6)Ks(7) …Ks(59)1, 
K2=1 Ks(60)Ks(61) …Ks(113)1, 
IV=1Ks(114)Ks(115) …Ks(175)1 
K =1Ks(176)Ks(177) …Ks(176+ log2N -2) 
 
IV. THE PROPOSED IMAGE RECOVERY METHOD 
 After the image gone through the authentication process, all the blocks are marked either valid or invalid. 
The system then tries to recover those invalid blocks. The two-stage recovery process is as follows. 
Stage-1: Recover each invalid block with its feature embedded in the designated block if the designated block 
is valid; otherwise, skip this stage. Again, we denote the block being recovered block_A and the designated 
block block_B. The recovery process is as follows. 
1. Compute the location of block_B by applying Torus automorphism with the secret key K. 
2. Extract the two LSB’s from each pixel within the corresponding 2×2 sub-block in block_B orderly and 
concatenate them to form the block signature.  
3. Obtain the 7-bit average pixel-value of each sub-block, denoted Vb, starting from bit 16 of the block signature, 
since bits 0-15 are the block indices. 
4. Pad 0 to bit 8 of Vb and fill each pixel in the 2×2 sub-block within block_A with Vb and mark block_A valid. 
Stage-2: Recover the remaining invalid blocks with the average intensity of their 3×3 neighboring block 
values.  
Note that Step-4 in stage-1 recovery can be performed right after Step-6 in stage-1 block verification. 
 
V. RESULTS AND COMPARISONS 
We conduct three experiments for this paper. The first one is to test both the tamper localization accuracy 
and the recovery capability when CRC-8-coded watermark is used. In the second experiment, we test the 
recovery capability from cropping attack. And, in the third experiment, we investigate the trade-off between the 
security parameter “r” and the quality of the recovered image. The three experiments and their respective results 
are described and depicted in the following. 
5.1 Capability of Tamper Detection and Recovery 
We use grayscale images “Home” and “Car” as our test images. All are of size 256×256. Since only the 
two LSB’s of each pixel are used for watermarking, both watermarked images are visually indistinguishable 
from their respective original. Both tests of malicious tampering and incidental manipulations are conducted in 
this experiment.  
Malicious Tampering:  
Both the door number “11” in the watermarked “Home” and the license number “7880” in the 
watermarked Car have been modified, and the face of “Elvis” has been black out, as shown in Figs. 3(a)-(c). The 
size of the modifications are about 4×10,10×20, 10x25, and 120x120, respectively. Figs. 3(g)-(i) show the 
recovered images, where the recovered “Home” has PSNR of 46 dB with respect to the watermarked “Home”, 
 
 5.2 Recovery from Cropping Attack  
In this experiment, we test the recovery capability from cropping attack. We simulate the attacks by either 
blacking out or whiting out a portion of the test image at-various locations as shown in Figs. 5 (a)-(c). Table 1 
lists the percentage of blocks not recovered in phase-I restoration relative to the percentage of blocks cropped. 
The results indicate that less than 7.5% of the tampered blocks have not been recovered in phase-I if less than 
30% of the blocks are cropped. The ratio increases to 20% if the percentage of blocks cropped increases to 50. 
The two-stage recovered images are shown in Figs. 6 (a)-(c). The PSNR’s of all recovered images are listed in 
Table 2.  
Fig.5. Lena’s with various cropping sizes: (a) 
256x64, (b) 85x256, (c) 200x200. 
(a) (b) (c) 
(a) (b) (c) 
Fig.6. The recovered Lena’s from the cropped 
images shown in Fig. 5. 
 9
 11
In the third experiment, we investigate the trade-off between security parameter “r” and the quality of the 
recovered image by using CRC-8, -16, -24, -32, -48, -64, and -96 codes, respectively. We black out Lena’s face 
of size 80x80. The PSNR of the recovered Lena against the degree r of CRC-r code is illustrated in Fig. 7. As 
expected, the PSNR of the recovered Lena using CRC-8 code has the highest PSNR of 36.11, followed by the 
PSNR of 34.34 using CRC-16 code, then PSNR of 32.65 using CRC-24 code, and PSNR of 31.45 using CRC-32 
code. The PSNR drops significantly when r is 48 and above, because we must trade “r” bits of the block feature 
for the CRC checksum. Thus, the bigger “r” we choose, the more block information loss. However, the larger “r” 
means tighter security, for the malicious attacker must guess from 2(r-2) combinations for a correct G(x).  
(Note: Both the coefficients of the highest and the lowest order of G(x) of degree r must be 1.) 
5.4 Comparison with the Celik’s scheme 
Celik et al. presented a fragile watermarking for secure image authentication with localization” in [14]. Since 
our proposed scheme is also a fragile image authentication with localization and recovery, we compare the two 
from the localization accuracy, cropping detection, VQ attack resiliency, and image quality degradation. 
Localization Accuracy: 
Our scheme is block-based with the block size 8x8, thus, the tamper localization accuracy is 8x8; whereas 
Celik et al.’s scheme can achieve an accuracy of 10x10 due to payload limitation [14]. 
Image Quality Degradation: 
Our scheme uses two LSB’s of each pixel to embed the watermark, whereas the scheme of Celik et al. only 
uses one LSB of each pixel to embed the watermark. Thus, the image quality watermarked by our scheme is 
degraded about 2-3 dB more than that of Celik et al. 
Cropping –Attack Detection: 
Our scheme can detect cropping by sliding-window search to regain the synchronization with the block 
boundaries, whereas the scheme of Celik et al. can detect the presence of cropping by a hierarchical search. 
VQ-Attack Resiliency:  
 In our scheme, the watermark of each block is an encrypted form of its signature, which includes the block 
location, a content-feature of another block, and a CRC checksum. While the CRC checksum authenticates the 
signature, the mixture of the location indices of one block with the feature of a randomly selected block breaks 
up the block independency. The encryption and the user-dependent security parameters further make the scheme 
robust against collage attack, as well. Celik’s scheme generates multilevel hierarchical block watermarks for 
breaking up the block independency. Thus, both schemes can achieve VQ-attack resiliency.   
 
VI. CONCLUSIONS 
  In this paper, we presented a new block-based fragile watermarking scheme for image authentication and 
recovery. We generated the block watermark by encrypting the combination of the block location, the 
content-feature of a randomly selected block, and a CRC checksum to break up the block independency and 
complicate the VQ attack. We also proposed using user-dependent security parameters for further complicating 
the collage attack. The experiments demonstrate that our scheme can detect and localize any tampering of size 
8x8 pixels and can recover a 40% damaged image to an intelligible one with 24dB. As for incidentally 
manipulated images, our scheme can invalidate all the blocks but will not further degrade the images. 
 Comparing with the scheme of Celik et al. [14], ours has better tamper localization accuracy while trading off 
1-2 dB of the watermarked image for recovery.  
 
REFERENCES 
[1] Hongtao Lu, Ruiming Shen and Fu-Lai Chung, “Fragile watermarking scheme for image authentication,” 
Electronics Letters, Volume: 39 Issue: 12, 12 Jun 2003. 
[2] J. Dittmann, A. Steinmetz, and R. Steinmetz, “Content-based digital signature for motion pictures 
authentication and content-fragile watermarking,” Multimedia Computing and Systems, 1999, IEEE 
International Conference on, Volume: 2, 7-11 June 1999. 
[3] Chai Wah Wu, “On the design of content-based multimedia authentication systems,” Multimedia, IEEE 
Transactions on, Volume: 4 Issue: 3, Sept. 2002. 
[4] Chun-Shien Lu and H. Y. M. Liao, “Structural digital signature for image authentication: an incidental 
distortion resistant scheme,” Multimedia, IEEE Transactions on, Volume: 5 Issue: 2, June 2003. 
[5] M. M. Yeung and F. Mintzer, “An invisible watermarking technique for image verification,” Image 
Processing, 1997 Proceedings., International Conference on , 26-29 Oct. 1997 
[6] Chun-Shien Lu; and H. Y. M Liao, “Multipurpose watermarking for image authentication and protection,” 
Image Processing, IEEE Transactions on, Volume: 10 Issue: 10, Oct. 2001. 
[7] Ping Wah Wong and N. Memon, “Secret and public key image-watermarking schemes for image 
authentication and ownership verification,” Image Processing, IEEE Transactions on, Volume: 10 Issue: 10, 
Oct. 2001. 
[8] M. Holliman and N. Memon, “Counterfeiting attacks on oblivious block-wise independent invisible 
watermarking schemes,” Image Processing, IEEE Transactions on, Volume: 9 Issue: 3, March 2000. 
[9] P.S.L.M Barreto, H. Y. Kim, and V. Rijmen, “Toward secure public-key blockwise fragile authentication 
watermarking,” Vision, Image and Signal Processing, IEE Proceedings, Volume: 149 Issue: 2, April 2002. 
[10]. J. Fridrich, ``Security of Fragile Authentication Watermarks with Localization,'' Proc. SPIE: Security and 
 13
出席國內外學術會議報告 
95 年 6  月 9  日 
報告人姓名 
林芬蘭 服務單位及職稱 靜宜大學資訊工程系教授兼計
算機及通訊中心主任 
會議時間 自 95   年 5 月  26 日至 95   年 5  月 30   日 
地點（國.州.城市） Istanbul, Turkey 
中文：第五屆訊號處理國際研討會 
會 議 名 稱 
英文：5th WEAS International Conference on Signal Processing  
中文：藏量植基於內涵之二元影像資訊隱藏機制 
發表論文題目 
英文：A Data Hiding Scheme for Binary Images with Content-Based Hiding Rates 
報告內容應包括下列各項： 
一.參加會議經過 
 此研討會於 Istanbul, Turkey 舉行,約有 200 多位分別來自北美與歐亞的專家學者與會.
除了在 session: Intelligent Techniques for Signal and Image Processing 發表自己的論文,也聽取
兩場大會邀請演講: “Next Generation Optical Networks -SDH and Protocols” by Professor 
Stamatios Kartalopoulos at The University of Oklahoma, USA, and “Hebbian Learning and 
Negative Feedback Neural Networks” by Professor Colin Fyfe, The University of Paisley, 
Scotland 並且參加另一個 Conference “Telecommunication and Informatics” 的”Internet, 
Multimedia Applications, E-Learning”  以及”Security and Privacy” 兩場次聽取 10 多篇論文
二.與會心得 
4. 與 多位來自各國(含台灣與大陸)的教授交換研究心得並討論接下來的研究重點. 
5. 參觀 Istanbul University 校園及 Network Data Center, PC classrooms, 與 research 
labs.,對其網路,教室,以及研究室的專業管理印象深刻並吸取經驗以作學校計中管理
之參考. 
三．考察參觀活動（無此項活動者省略） 
四.建議 
3. WSEAS 大部份成員是歐洲及歐亞地區之學者 近期也積極在中國大陸舉辦研討會 
台灣應可積極參加這個研究組織 進而拓展學術交流至歐亞區塊 
五.攜帶資料名稱及內容 
  1. One CD contains 3 proceedings: WEAS Proceeding on Math, Tele-Info, and SIP, Istanbul, 2006. 
    2. WSEAS Transactions on Signal Processing.  
六.其他 
                                           
hiding rates based on block’s entropy and DCT 
spectrum. DCT spectrum clearly signifies 
frequency variations within a block; however, one- 
or two-pixel changes due to data embedding could 
affect the spectrum enough for a wrong estimation 
of hiding rate at data extraction. Entropy measured 
by frequencies of object-pixel occurrence can also 
provide some insight of block complexity, though 
it cannot differentiate the case of two different 
looking blocks having same object-pixel counts. 
Thus, using both complexity measures together to 
assign the hiding rate of each block allows the 
scheme hide more information into more complex 
blocks. In addition, our scheme adopts CPT 
algorithm for encoding/decoding hidden 
information in each block once the hiding rate is 
determined and adopts WL score for selecting an 
embedding pixel. As a result, both imperceptibility 
and good hiding capacity can be achieved. Our 
scheme achieves security by using secret 
parameters to set the complexity category. The 
unauthorized users cannot correctly decode the 
hiding information with only the information of 
entropy or DCT spectrum that can be obtained 
directly from the stego-images.  
The rest of this paper is organized as follows. 
In Section 2, we brief the algorithms and measures 
adopted by this proposed scheme. In Section 3, we 
present our proposed scheme in detail. The 
experiments and results, as wells as comparisons 
to the adopted schemes are presented in Section 4. 
Finally, the concluding remarks are in Section 5. 
 
2  Backgrounds 
 
2.1 Data Hiding Scheme CPT 
 Tseng, Chen, and Pan (CPT) proposed an 
algorithm that can hide as many as ⎣(log2(mn +1)⎦ 
bits of information into a block of size m × n [4]. 
In their scheme, a host image F is divided into 
blocks of size m × n. A weight matrix W with its 
element w ∈{1, 2, …, 2r-1}, 1<= r <= ⎣(log2(mn 
+1)⎦ and appears at least once in W and a 
randomly selected binary matrix of size m × n are 
served as secret keys for data extraction. To embed 
information b1 b2…br into a block Fi, the scheme 
modifies Fi into Fi’ by flipping at most two bits in 
Fi such that SUM[(Fi’ ⊕ K) ⊗ W] ≡ b1 b2…br (mod 
2r). The hidden data b1 b2…br can then be extracted 
easily by applying SUM[(Fi’ ⊕ K) ⊗ W] (mod 2r).  
 
 
2.2 WL Score  
Wu and Liu [3] proposed an algorithm for 
computing flippability scores of pixels in 
nondithered binary images measured by the 
change in connectivity and smoothness after pixel 
flipping. Fig.1 lists the scores for 72 possible 3 ×3 
patterns calculated based on the algorithm. 
Patterns not shown are either the rotated or the 
inverted form The detail description of this 
algorithm can be found in [3]. 
 
Score
=0 
 
0.01  
0.125
0.25  
0.375  
0.625  
Fig. 1 WL scores for 72 possible 3 ×3 patterns 
 
2.3 Distance Reciprocal Distortion 
Measurement (DRD) 
Lu et al. [6] presented an objective distortion 
measure, named DRD, for binary document 
images based on the reciprocal of distance. They 
demonstrated that such measure matched well to 
subjective evaluation by human perception. The 
DRD can be calculated by the following equations. 
 
NUBN
DRD
DRD
s
k k∑ == 1                    (1) 
∑ ×=
ji
Nmkk jiWjiDDRD
,
)],(),([        (2) 
|]),[(),(|),( kkk yxgjiBjiD −=          (3) 
∑∑ === mj mmi
m
Nm
jiW
jiWjiW
11
),(
),(),(         (4)  
⎪⎩
⎪⎨
⎧
−+−
==
= otherwise,
)()(
1
   and  for  ,0
),(
22
CC
CC
m
jjii
jjii
jiW
 (5) 
where DRDk is the distortion measure for flipped 
pixel g(x, y)k in block , (WNm(i, j))/ Wm(i, j), 1<=i, 
j <=m, is the (normalized) weight for pixel (i, j) 
within an m x m template, respectively, Bk(ic, jc)= 
g(x, y)k, and NUBN is the number of non-uniform 
(neither all white nor all black) blocks of size >= m 
x m in original image f(x, y). 
kB
 
 
2.4 Entropy 
The entropy of a binary image, denoted H, is the 
measure of the average information in bits in that 
image. It can be calculated by  
 15
where i= -(m-1),…,0,…, (m-1), j<=|i|.  
Flip-1searches for and flips one particular pixel p 
within the block that satisfies the following 
conditions after flipping p: (a), wv’i=∑ Wi(k, 
l)*V’i(k, l) mod μi = Ii , (b) HLj <= Hi < = HUj , (c) 
CS’=CS, and (d) p has the highest WL score >0 . 
The algorithm is detailed as follows.  
 
For example, the hiding rates for {[10, 17], [19, 
26], [28, 35], [37, 44], [46, 55]} could be [2,3,4], 
[3,4,5], [4,5,6], [3,4,5], [2,3,4]. Note that the 
maximum entropy computed by Eq. (6) occurs at 
p=1/2. That is, blocks belong to the entropy 
category that contains approximately same number 
of object pixels and background pixels are 
supposed to be more complex than blocks in other 
entropy categories. Thus, we assign the maximum 
hiding rate for blocks in these entropy categories.    
 
Algorithm Flip_1: 
 
Algorithm_4: Determine (CH, CS) of block Bi 
1. Assign Bi to entropy category CHk if HLk <= Hi 
<= HUk  
2. Compute its DCT spectrum Si(u, v)= Ci2(u, v).  
3. Compute its total energy Ei=  ∑
vu
i vuS
,
)],([
4. Compute its energy in all three frequency 
sub-bands, denoted EiL, EiM, EiH,, by  
Eij = , j=L, M, H, where Pj = {Zi| 
DCT coefficients, jl<=i<=ju}, j=L, M, H, is 
frequency sub-band j, as shown in Fig. 2. 
∑
∈Pjvu
i vuS
),(
)],([
5. Assign Bi to spectra category CSj, j=L,M, H, if 
Eij >=TS × Ei,.  
 
For example, if block Bi has Hi=11, Ei=100.3, EiL 
=30, EiM =51, EiH =20, and TS=0.5, then 
complexity (CH, CS)i = (1, M). 
 
Algorithm_CPTM: Hiding information Ii=b1…bri 
into block Bi 
1. Prepare the weight matrix Wi for this block by 
assigning a repeated sequence of 1 to 2ri-1 to 
Wi(k, l), 1<= k <=m, 1<= l <=n. Note that we did 
not assign number 1 to 2ri-1 randomly as scheme 
CPT did, because we hide various number of bits 
in each block. If we used Wi as a secret key, then 
we would need to store more than one weight 
matrix. 
2. Compute the weighted sum of the block wvi, 
using wvi=∑ Wi(k, l)*Vi(k, l) mod μi,            
where Vi(k, l) is the value of pixel p at location (k, l) 
within block Bi, and μi=2 ri. 
3. If hiding information Ii=b1…bri= wvi, no pixel 
should be flipped. 
4. If Ii ≠ wvi, compute Δ= Ii − wvi, if Ii >= wvi or 
Δ= Ii − wvi + μi, if Ii < wvi.              
5. Start Flip-1.  
6. If Flip-1 does not succeed, start Flip-2.  
7. If Flip-2 fails, mark block as not embedding 
and stop.  
1. Find all pixels P={p|(Vi(k, l)=0, Wi(k,l)=Δ) or  
(Vi (k, l)=1, Wi (k, l)=μi −Δ) if HLj < Hi < HUj, 
(Vi(k, l)=0, Wi(k, l)=Δ) if Hi = H Lj, (Vi(k, l)=1, 
Wi(k, l)= μi−Δ) if Hi = HUj, for all 1<=k<=m, 
1<=l<=n}, where Hi is the number of pixels with 
Vi(k, l)=1. 
2. If P=∅, Flip-1 fails. 
3. For all p ∈P, keep only those satisfy CS’=CS 
and name the new set P’.  
4. For each p ∈P’, obtain the WL score s from   
the lookup table shown in Fig.2. 
5. Flip pj that has the highest WL score>0, i.e, pj 
>=pk, 1<=k, j<= |P’| (the size of P’), j≠k. 
 
Algorithm_Flip 2: 
1. Find all pixels P that after flipping (p1, p2),   
wv’i=∑ Wi(k, l)*V’i(k, l) mod μi = Ii.  
2. If P=∅, return Flip-2 fail and stop 
3. For all p ∈P, keep only those satisfy HLj <= 
H’i < = HUj , and CS’=CS, and name it P’. 
4. For each p ∈P’, obtain the WL score s from the 
lookup table shown in Fig.2. 
5. Flip pixels pl and pj that have the highest two 
WL scores >0. That is, pl, pj∈P’, pl, pj >=pk,1<=k, 
l, j<= |P’| (the size of P’), l≠j≠k.  
 
 
4  Experiments and results 
 
4.1 Effect of image complexity 
 In this experiment, we test how image complexity 
affects both visual imperceptibility and hidden 
capacity. Four binary images of size 256 x256: 
“English”, “Baboon”, “Laugh”, and “Mickey”, as 
shown in Figs. 3(a)-(d), are used as host images. 
All images are hidden in 500 bits each the first 
time, then with 500-bit increment till their 
respective maximum capacity is reached. The 
secret key set used is listed in Table 1. Figs. 4(a)-(d) 
depict the stego-images with 1000 hidden bits and 
their respective DRD. Figs. 4(e)-(h) are the 
stego-images with DRD=0.4 and their respective 
hidden amount. 
Observing Fig.4, we find that all 
 17
Fig. 4.Effect of host images Ts ○ ○ ○ × 
  
 
 
(a) (b) 
 
    (c) (d) 
Fig.7. Extracted information for various key sets 
 
Table 2 Block rate for various categories 
(○: Correct, ×: Incorrect). 
 
 SG only HG only H+S Fixed
Entropy
L L/M/H L/M/Hcategory
L/M/H rate  
/M/H 
rate rate 
5-9 
1
4/5/6
1-49 
51-59 
4/5/6
4/5/6
3/3/3 
5/5/5 
3/3/3 
3/4/5 
4/5/6 
3/4/5 
4/4/4
4/4/4
4/4/4
 
eferences 
 T. S. Chen, and M.W. Cheng, “A new 
[2] ata 
[3]  hiding in binary 
[4]  
[5] Pan, “Secure and 
[6] 
ing 
 
Fig.5. Comparison of DRD among MIMC (H+S, 
-○-), MIMC (S only, ---), MIMC (fixed, –●), 
CPT1 ( -x-), CPT (-+-).  
R
[1] J. Chen,
data hiding method in binary image,” in Proc. 
Fifth Int. Sym. Multimedia Software 
Engineering, 2003, Dec. 2003, pp. 88 – 93. 
T. H. Liu and L.W. Chang, “An adaptive d
 
 
MIMC 
-49 
MIMC 
-98 
MIMC Wu- 
-147 49 
Wu-
98 
DRD 0.063 0.115 0.159 0.1050.241
NFP 11 18 26 23 46
(a) (b) (c) (d) (e) (f)
hiding technique for binary images, ”, in Proc. 
17th Int. Conf. Pattern Recognition, vol. 4, 
Aug. 2004, pp. 831 – 833.  
M. Wu and B. Liu, “Data
image for authentication and annotation,” 
IEEE Trans. Multimedia, vol. 6, no.4, Aug. 
2004, pp. 528-538. 
Y. C. Tseng, Y. Y. Chen, and H. K. Pan, “A
Fig.6 Comparison with scheme WL 
 secure data hiding scheme for binary images,” 
IEEE Trans. Communications, vol. 50, no.8, 
Aug. 2002, pp.1227-1231. 
Y. C. Tseng and H. K. 
 
 
Table 1 Secret key set for experiments 4.1, 4.3 
Entropy 
category 
Block rate
(L/M/H) 
Spectra 
category 
 TS 
5-9, 51-59 
11-19, 41-49
21-39 
2/3/4/ 
3/4/5 
4/5/6 
PL: 1- 9; 
PM:10-21 
PH: 22-63 
50%
Invisible Data Hiding in 2-Color Images”, in 
Proc. IEEE INFOCOM, 2001, pp.887-896. 
H. Lu, A.C. Kot, and Y.Q. Shi, “Distance 
reciprocal distortion measure for binary 
document images,” IEEE Signal Process
Letters, vol.11, no.2, Feb. 2004, pp. 228-231.  
HC ○ × ○ ○ 
SC ○ ○ × ○ 
 19
 21
User Management within a Collaborative Community＂ Norway 以及 ＂An Ontological 
Multi-Agent System for Web Services＂ Taiwan 這二篇值得參考 
  
 
   
 
Sequential Floating Forward Selection method for 
each decision node of the hierarchical classifier so 
that biopsy images can be classified effectively. 
Experimental results showed that 94.5% of accuracy 
can be achieved for a set of 604 biopsy images with 
another 200 images as the training set. 
 
 
2 Image Acquisitions and Segmentation 
In this study, every image was obtained by the 
same processing and acquisition method. Tissue was 
embedded in paraffin cubes after chemical 
processing and then cut into very thin sections. These 
sections were placed on glass slides and stained with 
colored dyes such as Hematoxylin and Eosin. The 
images were acquired by a set of equipments 
including a high-quality optical microscope, a high 
resolution CCD camera, and an image acquisition 
computer system. Each image was taken through a 
microscope with magnifying factor of 400. There 
were 804 biopsy images with resolution 4080 by 
3072 captured by the above procedure. These images 
were analyzed by an experienced pathologist and 
classified into five grades (0 to 4) in advance for later 
comparison. 
According to the six types of characteristics for 
identifying HCC tumor, the major features used for 
grading are mainly related to cell nuclei; therefore, it 
is essential to segment nuclei from the images 
correctly. A HCC biopsy image may contain many 
undesirable elements such as erythrocyte, leukocyte, 
and impurities as shown in Fig. 1. In our system, we 
used a dual morphological reconstruction method to 
eliminate irrelevances without changing the shapes 
of nuclei in biopsy images. 
Morphological reconstruction [7][8] starts with 
eroding the original image, and then applies a series 
of conditional dilations to the marker image using the 
original image as the conditional image. 
Morphological reconstruction is more effective than 
the conventional opening and closing algorithms for 
removing small blemishes without affecting the 
shapes of interested objects. The process of 
morphological reconstruction for a HCC image is 
shown in Fig. 2, where Fig. 2(a) is the original RGB 
color image, Fig. 2(b) is the grayscale image in the 
red plane, Fig. 2(c) is obtained by eroding Fig. 2(b) 
with a disk shape structure element, Fig. 2(d) is the 
result from morphological reconstruction using 2(b) 
and 2(c) as mask and marker images, respectively. 
Then a second morphological reconstruction 
procedure (a dilation followed by a series of erosions) 
is applied by using Fig. 2(d) as the mask image and 
Fig. 2(e) as the marker image. The final result is 
shown in Fig. 2(f), where the shapes of nuclei are 
well preserved and other irrelative objects are 
removed.  
Thresholding methods [9] are usually used for 
image segmentation. Since the intensities within 
nuclei and in the background are not uniform as 
shown in Fig. 3(a), we utilized watershed transform 
[10] to obtain the edges of nuclei and the snake 
method [11][12] to smooth those edges. The intuitive 
idea of watershed transform is to regard a grayscale 
image as a topographic relief, which is flooded with 
water starting at the surface global minima. The 
water level would increase to fill up lower elevation 
points first. When water coming from different 
basins would meet, dams called watershed ridge lines 
are built. An example of watershed transform for 
nuclei is presented in Fig. 3. Figure 3(b) is the 
gradient image by performing Sobel operator on Fig. 
3(a). The result obtained from watershed 
segmentation is shown in Fig. 3(c). To refine the 
contours of nuclei, a snake method [11][12][13] was 
applied and the final result of segmentation for a 
biopsy image is shown in Fig. 4. 
 
 
 
 
 
 
 
 
 
 
 
 
 23
(a)
Fig. 2. An example of dual morphological reconstruction. 
(b) 
(c) (d) 
(f) (e) 
Fig. 1. A HCC biopsy image. 
1 11 1
1 1
tan tanj j w j j wj
j j w j j w
y y y y
d
x x x x
− −− −
− −
− −= −− −
− −
− −
 
  
Then we define contour irregularity as  
1
1
0
n
j j
j
d d
−
−
=
−∑         (6) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Type-3 (Hyperchromatism): 
  Hyperchromatism represents excessive 
pigmentation in hemoglobin content of erythrocytes. 
It is an important characteristic appearing in a 
malignant tumor. For the case of higher grade HCC, 
chromatin abnormality will increase the staining 
capacity by staining colored dyes especially in cell 
nuclei. By taking the advantage of reflecting the 
amount of chromatin within nuclei, we can obtain the 
following two features: 
y Average intensity (F7): The intensity of nuclei in 
higher grade HCC appears darker than that of 
normal nuclei. Thus, the average intensity reflects 
the degree of dyeing for nuclear staining and can 
be easily extracted from gray-level nuclei. 
y B/D spot ratio (F8): Within a malignant tumor, 
increasing chromatin will cause more holes to 
occur. The holes are reflected by the ratio of 
bright and dark spots in nucleus. The bright and 
dark spots can be found by using top-hat and 
bottom-hat transforms [19], respectively. 
 
Type-4 (Nuclear Size): 
y Area (F9): HCC with higher grade implies a 
higher probability of larger nuclei. Therefore, 
nuclear size is also used as a criterion for HCC 
grading and can be obtained by simply counting 
the number of pixels in nucleus. 
 
Type-5 (Anisonucleosis): 
In cases of HCC with high grades, the variance 
among the areas of nuclei is noticeable. Thus, the 
following two features can be derived from size 
distribution of nuclei for identifying HCC with high 
grades. 
y Standard deviation of nuclear size (F10): This 
feature is calculated by the squared root of the 
average squared deviation from the mean nuclear 
size. 
y Difference of extreme nuclear sizes (F11): 
Sometimes in grade-4 HCC images, there are 
only a few nuclei having large area differences. 
So the standard deviation of nuclear size can not 
represent anisonucleosis effectively. In this case, 
we use the difference between the maximal and 
minimal areas of nuclei as anisonucleosis. 
P4
S1
S2 S3
S4
P1
P2
P4
P3
S2
S1
S4
S3
P1
P2
P3
 
Type-6 (Nuclear Texture): 
Gray Level Co-occurrence matrices (GLCM) have 
been shown to be useful in texture analysis 
[20][21][22]. For nuclear texture analysis, the 
following three features are derived from a GLCM 
Nd with neighboring pixels separated by a distance d 
in directionθ . In our implementation, we chose d=1 
and θ =0o, 45o, 90o, 135o. 
(b) 
 
y Uniformity Energy (F12): 
2[ , ]
d
i j
N i j∑∑       (7) 
 
y Contrast (F13):   
2( ) [ ,d
i j
i j N i j− ]∑∑      (8) 
 
y Homogeneity (F14): 
[ , ]
1
d
i j
N i j
i j+ −∑∑       (9) 
 
 
4 Classification 
This study investigated the performance of two 
classifiers. One is to directly use SVM once to 
classify biopsy images into five grades by using all 
fourteen features. The other is to construct a 
hierarchical classifier so that each decision node has 
an optimal feature subset automatically selected by 
Support Vector Machine [23][24] and Sequential 
Floating Forward Selection method [25][26]. 
Support Vector Machine is a popular classification 
and regression technique [23]. The basic idea of 
SVM is to transform data into a higher dimensional 
space and find the optimal hyperplane with maximal 
separation margin between classes. In this study, the 
implementation of SVM used for experiments is 
LIBSVM [24]. 
 
Fig. 5. Two examples of area irregularity. (a) A round 
nucleus. (b) An irregular nucleus. 
(a) 
 25
Table 2. Performance results of our hierarchical classifier. 
Classification results using our method Grades Visual Grading G0 
 
 
G1 G2 G3 G4 Accuracy
G0 58 58 0 0 0 0 100. % 
G1 
 
 
26 0 26 0 0 0 100. % 
G2 75 0 0 72 2 1 96.0 % 
G3 220 0 1 0 201 18 91.4 % 
G4 225 0 0 6 5 
 
 
 
214 95.0 % 
Total 604 58 27 78 208 233 94.5 % 
 
 
 
 27
