2 
摘要 
隨著 3D 形狀模組化、數位化、以及視覺化等技術快速發展，導致了一個 3D 模型爆炸的
時代，在網路上或是特定領域的資料庫中到處都充斥著可以利用的 3D 模型。因此如何建立
一個有效的 3D 模型搜尋系統，讓使用者可以利用此一系統快速地找到在大型 3D 模型資料
庫中符合使用者個人期待的相同或相似 3D 模型是本計畫的首要目標。因此在本計畫中提出
一個全新以形狀為基礎的 3D 模型特徵擷取演算法，六立面圖特徵（elevation descriptor）擷
取法。 
 
一. 報告內容 
 
1. 前言 
因為 3D 模型在數位圖書館中的數量逐漸暴增，我們是很迫切需要一個搜尋系統去幫助人
們找到他們所要的 3D 資料。因此在本計畫中提出一個全新的 3D 模型檢索系統的特徵方法，
以六立面圖特徵（elevation descriptor）擷取法。它的關鍵就在於如何以 3D 模型本身的內容
（content）搜尋出符合使用者需求的 3D 模型。 
 
2. 研究目的與研究方法 
我們提出了六立面圖特徵（elevation descriptor），主要概念為收集 3D 模型在六個不同的
視角下的立面形狀分布，這六個立面圖分別為：正立面圖、背立面圖、右側立面圖、左側立
面圖、俯視圖與底視圖。首先，將這多邊形模型分割成 2R×2R×2R 的網格（Voxel grid），如
圖一(b)。在這網格 (m, n, h)中如果有 3D 模型中多邊形的面存在則 1=mnhVoxel ，反之
0=mnhVoxel 。這方法可以過濾物體的外型的雜訊，也可充分表現該物體的外型。為了能夠正
規化此系統，移動 3D 模型的質量中心到（R, R, R）的位置，然後縮放 3D 模型(注意！並非
縮放網格）讓非零網格到達中心的平均距離必須為 R/2 ，如圖二(b)。在本計劃中此 R 將設
定為 32。以這方法來對整個 3D 模型做取樣(sampling)的動作。 
接下來擷取這網格的六個立面圖，分別為：正立面圖、背立面圖、右側立面圖、左側立
面圖、俯視圖與底視圖的高度分部的資訊，並顯示這些立面圖為灰階。我們將以灰階值代表
模型在該立面圖的高度分布，其中越靠近觀察者的灰階值越高，反之則越低。其中正立面圖
二維灰階影像 1F  中的每個像素的灰階值定義為 
})63max{(1 mnhmn Voxelhf −= ， 
4 
∑
=
= 6
1k
k
k
rk
r
G
gx , 
其中 6 , ... ,2 ,1=k ， 32 , ... ,2 ,1=r 。 
 
 
 
圖三 3D 吉普車_1 模型的原圖及其六立面圖，正立面圖(K=1)、背立面圖(K=4)、 
    右側立面圖(K=3)、左側立面圖(K=6)、俯視圖(K=2)與底視圖(K=5)。 
 
 
圖四 立面圖上不同半徑的同心圓示意圖。 
 
再來就是本計畫中所提出六立面圖特徵向量的比對方法。為了比較兩個模型的相似程
度，必須計算兩個模型的六立面圖特徵向量的差異值，基於六立面圖特徵向量是擷取 3D 模
型的六個角度視角的關係，在計算兩模型的差異值不能僅僅只計算兩個向量的差值，則必須
考慮每一個面與其他的面的差異值。如圖五，理論上，模型 q 與模型 s 的比對將有 720 種（6
階層）種排列組合，因此計算模型 q 與模型 s 的六立面圖特徵向量差異值必須取其中一種使
得差異值為最小的排列方式。 
為了減少計算量，我們將模型六個面彼此的關係也考慮進去，減少兩模型六個面比對時
的排列組合。基於一個概念，模型的面必須跟其背對的面相對應，以圖七，的模型 q 為例子，
模型 q 的面 1 必須與模型 q 的面 4 相對應、模型 q 的面 2 必須與模型 q 的面 5 相對應、模型
q 的面 3 必須與模型 q 的面 6 相對應。因此在計算模型 q 與模型 s 的差異值時，模型 q 的面
1 與模型 s 的面 1 計算差值的話，則模型 q 的面 4 就必須與模型 s 的面 4 計算差值；如果模
型 q 的面 2 與模型 s 的面 6 計算差值的話，則模型 q 的面 5 與模型 s 的面 3 計算差值。若加
K=2 
K=1=1 K=3 K=4 K=6
K=5 
6 
T
Nrecall =  與 
K
Nprecision =  
其中 N 是檢索結果中與搜尋目標有相關的個數，T 是全部與搜尋目標相關的個數，K 是所有
被檢索出的 3D 模型個數。 
實驗所採用的資料庫是「普林斯頓形狀基準資料庫（Princeton Shape Benchmark）」[2, 3]，
此資料庫是提供給對 3D 模型檢索研究有需求的使用者免費使用，大部分的 3D 模型特徵擷
取[4-11]都有用此資料庫來做檢索研究。此資料庫含有 1814 個 3D 模型，包含 161 個不同的
類別，如圖七。 
 
表一 六個面比對時的 48 種排列組合。 
 
使用的特徵向量有以下五種：六立面圖特徵（ED）擷取法改良式 D2（AD2）[12]、球型
諧波（SH）[13]、MPEG-7 的 3D 形狀頻譜描述（SSD）[5]、3D 幾何形狀分佈的 D2[ 6 ]。首
先的實驗是五種特徵向量之間對不同類別的 3D 模型之正確率的比較，我們挑選普林斯頓形
狀基準資料庫中的一些類別來做檢索，挑選的類別都是包含 15 個模型以上的類別，有
barren、biplane、city、commercial、dining_chair、enterprise_like、face、fighter_jet、handgun、
head、helicopter、human、human_arms_out、military_tank、potted_plant、rectangular、sedan、
shelves、ship、sword、two_story_home 與 vase 以上幾個類別，如圖七。將以上類別的每個
k 1 2 3 4 5 6 k 1 2 3 4 5 6 k 1 2 3 4 5 6
1p (k) 1 2 3 4 5 6 17p (k) 2 1 3 5 4 6 33p (k) 3 2 1 6 5 4
2p (k) 1 3 2 4 6 5 18p (k) 2 3 1 5 6 4 34p (k) 3 1 2 6 4 5
3p (k) 1 5 3 4 2 6 19p (k) 2 4 3 5 1 6 35p (k) 3 5 1 6 2 4
4p (k) 1 3 5 4 6 2 20p (k) 2 3 4 5 6 1 36p (k) 3 1 5 6 4 2
5p (k) 1 2 6 4 5 3 21p (k) 2 1 6 5 4 3 37p (k) 3 2 4 6 5 1
6p (k) 1 6 2 4 3 5 22p (k) 2 6 1 5 3 4 38p (k) 3 4 2 6 1 5
7p (k) 1 5 6 4 2 3 23p (k) 2 4 6 5 1 3 39p (k) 3 5 4 6 2 1
8p (k) 1 6 5 4 3 2 24p (k) 2 6 4 5 3 1 40p (k) 3 4 5 6 1 2
9p (k) 4 2 3 1 5 6 25p (k) 5 1 3 2 4 6 41p (k) 6 2 1 3 5 4
10p (k) 4 3 2 1 6 5 26p (k) 5 3 1 2 6 4 42p (k) 6 1 2 3 4 5
11p (k) 4 5 3 1 2 6 27p (k) 5 4 3 2 1 6 43p (k) 6 5 1 3 2 4
12p (k) 4 3 5 1 6 2 28p (k) 5 3 4 2 6 1 44p (k) 6 1 5 3 4 2
13p (k) 4 2 6 1 5 3 29p (k) 5 1 6 2 4 3 45p (k) 6 2 4 3 5 1
14p (k) 4 6 2 1 3 5 30p (k) 5 6 1 2 3 4 46p (k) 6 4 2 3 1 5
15p (k) 4 5 6 1 2 3 31p (k) 5 4 6 2 1 3 47p (k) 6 5 4 3 2 1
16p (k) 4 6 5 1 3 2 32p (k) 5 6 4 2 3 1 48p (k) 6 4 5 3 1 2
8 
 
圖七 普林斯頓形狀基準資料庫中的一些類別。 
 
 
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
ba
rre
n
bip
lan
e
cit
y
co
mm
erc
ial
din
ing
_c
ha
ir
en
ter
pr
ise
_li
ke fac
e
fig
hte
r_
jet
ha
nd
gu
n
he
ad
he
lic
op
ter
hu
ma
n
hu
ma
n_
arm
s_
ou
t
mi
lita
ry
_ta
nk
po
tte
d_
pla
nt
rec
tan
gu
lar
sed
an
sh
elv
es
sh
ip
sw
or
d
tw
o_
sto
ry
_h
om
e
va
se
Classes
Re
ca
ll
ED AD2 SH SSD D2
 
圖八 不同類別的模型之正確率的實驗結果。 
表二 不同特徵向量之間正確率的比較。 
 Recall 
六立面圖特徵（ED） 0.337000  
改良式 D2（AD2） 0.2576262804 
球型諧波（SH） 0.2451209359 
MPEG-7 的 3D 形狀頻譜描述符（SSD） 0.2010285473 
3D 幾何形狀分佈的 D2 0.1745288704 
10 
Processing (ICIP 2003), vol. 3, pp. 757-760, September 2003. 
[12] J. T. Wang and J. L. Shih, “Shape-based 3D model retrieval system,”NSC 
92-2213-E-216-023-, 2004. 
[13] T. Funkhouser, P. Min, M. Kazhdan, J. Chen, A. Halderman, D. Dobkin, and D. Jacobs “A 
Search Engine for 3D Models” in Proc. of ACM Transactions on Graphics, Vol. 22(1), pp. 
83-105, January 2003. 
 
三. 計畫成果自評 
我們把六立面圖特徵（elevation descriptor）擷取法運用到 3D 模型檢索的領域，並且提升
了 3D 模型檢索上的正確性。此六立面圖特徵（elevation descriptor）擷取法，在 3D 模型檢
索系統方面有一定的研究價值。未來我們計畫要加大 3D 模型資料庫，且我們深信某些特別
類別的 3D 模型，用某些特徵會有較好的效果，所以未來還可以加入其他檢索效果也不錯的
特徵擷取方法，讓其檢索結果更佳。 
尤其在最近幾年 3D 模型設計主要因為軟、硬體技術上的進步，導致 3D 模型設計上的簡
單，使得 3D 模型被廣泛應用，也因此我們認為“3D 模型檢索系統＂在學術界及業界裡有相
當的研究價值，目前我們已發表五篇與 3D 模型檢索系統相關的論文，包括三篇期刊論文及
一篇研討會論文。相關論文如下 ： 
期刊論文 (Journal Papers) ： 
[1] 王建棠 石昭玲, “具有相關性回饋演算法之智慧型 3D 模型搜尋引擎,＂ Chung Hua 
Journal of Science and Engineering, Vol. 2, No. 1. pp. 53-61 , March 2004. 
[2] Jau-Ling Shih, Chang-Hsing Lee, and Jian Tang Wang, “3D Object Retrieval System Based 
on Grid D2,” Electronics Letters Vol. 41 No. 4 2005 pp23-24. (SCI) 
[3] J. L. Shih, C. H. Lee, and J. T. Wang, “A New 3D Model Retrieval Approach Based on the 
Elevation Descriptor,” accepted by Pattern Recognition. (SCI) (見附件三) 
研討會論文 (Conference Papers) ： 
[1] Jian Tang Wang and Jau-Ling Shih, “Shape-Based 3D Model Retrieval System based on 
Elevation Descriptor,” Proceeding of The CVGIP, August 2004. 
12 
 
 
A NEW 3D MODEL RETRIEVAL APPROACH BASED ON THE ELEVATION 
DESCRIPTOR 
 
Jau-Ling Shih*, Chang-Hsing Lee, and Jian Tang Wang  
Department of Computer Science and Information Engineering, 
Chung Hua University, Hsinchu, Taiwan, R.O.C 
 
Abstract 
The advances in 3D data acquisition techniques, graphics hardware, and 3D data modeling and 
visualizing techniques have led to the proliferation of 3D models. This has made the searching for 
specific 3D models a vital issue. Techniques for effective and efficient content-based retrieval of 
3D models have therefore become an essential research topic. In this paper, a novel feature, called 
elevation descriptor, is proposed for 3D model retrieval. The elevation descriptor is invariant to 
translation and scaling of 3D models and it is robust for rotation. First, six elevations are obtained 
to describe the altitude information of a 3D model from six different views. Each elevation is 
represented by a gray-level image which is decomposed into several concentric circles. The 
elevation descriptor is obtained by taking the difference between the altitude sums of two 
successive concentric circles. An efficient similarity matching method is used to find the best 
match for an input model. Experimental results show that the proposed method is superior to other 
descriptors, including spherical harmonics, the MPEG-7 3D shape spectrum descriptor, and D2. 
Keywords: 3D model retrieval, Elevation descriptor 
附件三
14 
2. Related Work 
In this section, some related work for 3D model retrieval is described. The 3D model retrieval 
methods are classified into three categories: low-level feature based methods, high-level structure 
based methods, and view based methods. 
 
2.1 Low-Level Feature Based Methods 
In 3D model retrieval systems, low-level feature descriptors are usually extracted to describe 
the geometric properties [2, 3], spatial properties [4-9], and shape distributions [10-16] of 3D 
models. The similarity between two 3D models can be measured by comparing their features. 
Zhang and Chen [2] proposed methods to efficiently calculate features such as area, volume, 
moments, and Fourier transform coefficients from mesh representation of 3D models. Paquet et al. 
[3] employed moments to describe symmetries of 3D objects, cord-based descriptors to represent 
shape information in fine details, and wavelet transform descriptors to describe the density 
distribution through a volume. 
Vranic et al. [4] performed Fourier transform on the sphere with spherical harmonics to get the 
feature vectors. This method requires pose normalization to be rotation invariant. A modified 
rotation invariant shape descriptor based on the spherical harmonics without pose normalization 
has been proposed by Funkhouser et al. [5, 6]. First, a 3D model is decomposed into a collection of 
spherical functions by intersecting the model with concentric spheres of different radii. Each 
spherical function is decomposed into a set of harmonics of different frequencies. The sum of 
norms of each frequency component at each radius forms the shape descriptor. The reason for the 
descriptor being rotation invariant is that rotating a spherical function does not change the energies 
in each frequency component. Novotni and Klein [7] used 3D Zernike moments for 3D shape 
retrieval. It is naturally an extension of spherical harmonics based descriptors. The 3D Zernike 
moments is a 2D histogram indexed by radius and frequency. The benefits of the 3D Zernike 
moments are that they are rotation invariant and less sensitive to geometric and topological 
16 
located. The shape spectrum descriptor (SSD) [16] is adopted in the MPEG-7 standard for 3D 
model retrieval. SSD represents the histogram of  curvatures of all points on the 3D surface. The 
advantages of SSD are that it can match two 3D models without first aligning the 3D objects, and 
that it is robust to the tessellation of the 3D polygonal model. 
 
2.2 High-Level Structure Based Methods 
The low-level feature based methods discussed above only take the geometric or topological 
properties of 3D models into consideration. On the other hand, high-level structure based methods 
describe the relationship between model components.  Hilaga et al. [17] used multi-resolution 
Reeb graphs (MRG) to describe the skeleton structure of a 3D model. Mathematically, the Reeb 
graph is defined as the quotient space of a shape and a quotient function. The Reeb graph used by 
Hilaga et al. is based on a quotient function defined by an integral geodesic distance. Bespalov et al. 
[18] applied the Reeb graph for description of solid models. One major advantage of using the 
Reeb graph to measure the distance between two 3D models is that it is robust to 3D shape 
deformation. However, computation of the Reeb graph is time consuming and very sensitive to the 
fine components of 3D models. 
 
2.3 View Based Methods 
The main idea of view based methods is to represent a 3D model using a number of binary 
images. Therefore, a set of 2D features can be used to index similar 3D models. Each binary image 
is obtained from the boundary contour of the 3D model from different views. Several methods 
provide a 2D query interface to facilitate view based retrieval of 3D models [5, 19]. Super and Lu 
[20] exploited 2D silhouette contours for 3D object recognition. Curvature and contour scale space 
are extracted to represent each silhouette. Chen et al. [21] introduced the lightfield descriptor to 
represent 3D models. The lightfield descriptor is computed from ten silhouettes. Each silhouette is 
represented by a 2D binary image. Zernike moments and Fourier descriptors are used to describe 
18 
set to be 32, which provides adequate resolution for discriminating objects and the fine-detail noise 
in complex components of a 3D model can be filtered out.  
Next, six elevations are extracted to indicate the altitude information of 2D projections from 
six different views: front, top, right, rear, bottom, and left. Each elevation is represented by a gray 
level image in which the gray values denote the altitude information. Let the front, top, right, rear, 
bottom, and left elevations be notated successively as Ek, .6 , ... ,2 1, =k The gray value of each 
pixel on these elevations is defined as 
64, ,1for  },641 ) , ,()65{() ,(1 ≤≤≤≤−= nmhhnmVoxelhnmf max
64, ,1for  },641 ) , ,()65{() ,(2 ≤≤≤≤−= hmnhnmVoxelnhmf max
64, ,1for  },641 ) , ,({ ) ,(3 ≤≤≤≤= hnmhnmmVoxelhnf max
64, ,1for  },641 ) , ,({) ,(4 ≤≤≤≤= nmhhnmhVoxelnmf max
64, ,1for  },641 ) , ,({) ,(5 ≤≤≤≤= hmnhnmnVoxelhmf max
64. ,1for  },641 ) , ,()65{() ,(6 ≤≤≤≤−= hnmhnmVoxelmhnf max  
Fig. 2 shows the six elevations of three example 3D models. From these figures, we can see 
that the two 3D jeep models exhibit similar elevations, whereas the jeep and ship models differ. 
 
3.2 Feature Extraction 
To extract the elevation descriptor from these six elevations, each elevation is decomposed 
into L concentric circles around the center point (see Fig. 3). The region within the j-th concentric 
circle is denoted as jC : 
{ }jLcLrcrC j <−+−= 22 )()(  ) ,( ,  
for .32 , ... ,2 ,1=j For the k-th elevation, the sum of gray values of all pixels located within the j-th 
circle, ,C j is defined as 
∑
∈
=
jCcr
kk crfjg
 ),(
),()( , 
where .32 , ... ,2 ,1=j  Let ,0)0( =kg the difference between the sums of gray values within two 
successive concentric circles is then derived: 
20 
efficient similarity computation is provided to find the best match for a given query model. 
The matching operations can be greatly reduced if the relative positions of the elevations are 
taken into account. In practice, the front elevation E1 and the rear elevation E4 locate on opposite 
sides. Similarly, the right elevation E3 and the left elevation E6 as well as the top elevation E2 and 
the bottom elevation E5 also locate on opposite sides. Let the six elevations of the query model q 
and the matching model s be respectively defined as qkE and ,
s
kE for .6 , ... ,2 ,1=k The six 
elevations of a query model q can be divided into three pairs: ), ,( 41
qq EE ), ,( 52
qq EE and ). ,( 63
qq EE  
Similarly, the six elevations of a matching model s can be divided into three 
pairs: ), ,( 41
ss EE ), ,( 52
ss EE and ). ,( 63
ss EE To calculate the difference between q and s, 
if q1E matches ,
s
iE
q
4E must match [ ]s i 1  6 mod 2)( ++E according to the topological relationship 
between q1E and .4
qE Similarity, if q2E matches ,
s
iE
q
5E must match [ ] ,1  6 mod 2)(s i ++E and 
if q3E matches ,
s
iE
q
6E must match [ ] .1  6 mod 2)(s i ++E In summary, the number of elevation matching 
operations that need to be performed is ,482  !3 3 =×  instead of 720 matching operations. Table 1 
lists these 48 matching operations. In this table, for i-th permutation ,ip
q
kE will match 
( ),s kpiE .61 ≤≤ k  
Let TTTT ]), ,) ,)[ 621 (x(x(xx K= and TTTT ]), ,) ,)[ 621 (y(y(yy K= denote the elevation 
descriptors of q and s, respectively. For the matching operation corresponding to the i-th 
permutation pi, 48, 1 ≤≤ i the distance between x and y is defined as: 
∑∑∑
= ==
−=−=
6
1
32
1
)(
6
1
1)(,
)()(
k r
kpk
k
kpk
i
sq ryrxDis iiyx , 
where )(kpi denotes the k-th value for the i-th permutation, 6 1 ≤≤ k . The distance between the 
query model q and the matching model s is defined as 
. ,48  1,
i
sqisq
DisDis  min≤≤=  
22 
can see that even though the model is deformed, the similarity value is still large enough.  
In the previous section, it is shown that the elevation descriptor of a rotated 3D model is similar 
to the original if the rotation degree is small. In our simulation results, the elevation descriptor is 
also robust if a 3D model is rotated by a large degree. Table 2 shows the distance between a rotated 
query model and all seed models in Database 1. The query model q is a dragon, the seed model of 
class 3 on Database 1 (see Fig. 7). The query dragon model is rotated about the m-axis and n-axis 
by different degrees mθ and :nθ ,20° ,40° ,60 ° and .80 ° We can see that even though the dragon 
model is rotated by various degrees, the one with the smallest distance is still the original dragon 
model. That is, the proposed elevation descriptor is robust to rotations.  
In our experiments, each model in Database 1 is presented as a query. Table 3 shows the 
average recall values for all query models using the proposed elevation descriptor (ED), spherical 
harmonics (SH), 3D shape spectrum descriptor (SSD), and D2. From Table 3, we can see that the 
elevation descriptor outperforms other descriptors. The detailed comparison of the average recall 
value for each class is shown in Fig. 9. The elevation descriptor has the best performance for most 
classes.  To see what kind of deformations will dramatically affect the retrieval result, a detailed 
performance comparison for each kind of deformation is shown in Fig. 10. From this figure, we 
can see that the elevation descriptor always get the best performance. 
 
4.2 Experiment on Database 2  
The second database, Database 2, is derived from the Princeton Shape Benchmark database [22] 
which contains 1814 models (161 classes) and is used for evaluating shape based retrieval and 
analysis algorithms. Note that in this database each class contains a different number of models. 
The 22 classes that have the largest number of models are selected as queries. Each of them 
contains at least 15 models. These 22 classes are shown in Fig. 11. 
The performance is also measured by recall and precision. Since the number of models in each 
class is different, the recall value and the precision value for the j-th query model within the i-th 
24 
the proposed ED outperforms other descriptors including spherical harmonics (SH), the MPEG-7 
3D shape spectrum descriptor (SSD), and D2.  
 
Acknowledgments 
This research was supported in part by the National Science Council, Taiwan under Contract 
NSC 94-2213-E-216-018 and Chung Hua University, Taiwan under Contract CHU-94-TR-002. 
References 
[1] J.W.H. Tangelder, R.C. Veltkamp, A survey of content based 3D shape retrieval methods, 
Proceedings of the Shape Modeling Applications, 2004, pp. 145-156. 
[2] C. Zhang, T. Chen, Efficient feature extraction for 2D/3D objects in mesh representation, 
Proceedings of IEEE International Conference on Image Processing (ICIP), Thessaloniki, 
Greece, 2001, pp. 935-938. 
[3] E. Paquet, A. Murching, T. Naveen, A. Tabatabai, M. Rioux, Description of shape 
information for 2-D and 3-D objects, Signal Processing: Image Communication 16 (2000) 
103–122. 
[4] D.V. Vranic, D. Saupe, J. RICHTER, Tools for 3D-object retrieval: Karhunen-Loeve 
transform and spherical harmonics, Proceedings of the IEEE Workshop on Multimedia 
Signal Processing, 2001, pp. 293-298. 
[5] T. Funkhouser, P. Min, M. Kazhdan, J. Chen, A. Halderman, D. Dobkin, D. Jacobs, A search 
engine for 3D models, ACM Trans. Graphics 22 (1) (2003) 83-105. 
[6] M. Kazhdan, T. Funkhouser, S. Rusinkiewicz, Rotation invariant spherical harmonic 
representation of 3D shape descriptors, Symposium on Geometry Processing, 2003. 
[7] M. Novotni, R. Klein, Shape retrieval using 3D Zernike descriptors, Computer-Aided Design 
36 (2004) 1047-1062. 
[8] M. Yu, I. Atmosukarto, W.K. Leow, Z. Huang, R. Xu, 3D model retrieval with 
morphing-based geometric and topological feature maps, Proceedings of Computer Vision 
26 
Pattern Recognition 36 (2003) 69-78. 
[21] D.Y. Chen, X.P. Tian, Y.T. Shen, M. Ouhyoung, On visual similarity based 3D model 
retrieval, Computer Graphics Forum 22 (3) (2003) 223-232. 
[22] P. Shilane, P. Min, M. Kazhdan, T. Funkhouser, The Princeton shape benchmark, Proceedings 
of the Shape Modeling Applications, 2004, pp. 167-178. 
Table 1  48 permutations for elevation matching between a query model and a matching model. 
 
k 1 2 3 4 5 6 k 1 2 3 4 5 6 k 1 2 3 4 5 6
1p (k) 1 2 3 4 5 6 17p (k) 2 1 3 5 4 6 33p (k) 3 2 1 6 5 4
2p (k) 1 3 2 4 6 5 18p (k) 2 3 1 5 6 4 34p (k) 3 1 2 6 4 5
3p (k) 1 5 3 4 2 6 19p (k) 2 4 3 5 1 6 35p (k) 3 5 1 6 2 4
4p (k) 1 3 5 4 6 2 20p (k) 2 3 4 5 6 1 36p (k) 3 1 5 6 4 2
5p (k) 1 2 6 4 5 3 21p (k) 2 1 6 5 4 3 37p (k) 3 2 4 6 5 1
6p (k) 1 6 2 4 3 5 22p (k) 2 6 1 5 3 4 38p (k) 3 4 2 6 1 5
7p (k) 1 5 6 4 2 3 23p (k) 2 4 6 5 1 3 39p (k) 3 5 4 6 2 1
8p (k) 1 6 5 4 3 2 24p (k) 2 6 4 5 3 1 40p (k) 3 4 5 6 1 2
9p (k) 4 2 3 1 5 6 25p (k) 5 1 3 2 4 6 41p (k) 6 2 1 3 5 4
10p (k) 4 3 2 1 6 5 26p (k) 5 3 1 2 6 4 42p (k) 6 1 2 3 4 5
11p (k) 4 5 3 1 2 6 27p (k) 5 4 3 2 1 6 43p (k) 6 5 1 3 2 4
12p (k) 4 3 5 1 6 2 28p (k) 5 3 4 2 6 1 44p (k) 6 1 5 3 4 2
13p (k) 4 2 6 1 5 3 29p (k) 5 1 6 2 4 3 45p (k) 6 2 4 3 5 1
14p (k) 4 6 2 1 3 5 30p (k) 5 6 1 2 3 4 46p (k) 6 4 2 3 1 5
15p (k) 4 5 6 1 2 3 31p (k) 5 4 6 2 1 3 47p (k) 6 5 4 3 2 1
16p (k) 4 6 5 1 3 2 32p (k) 5 6 4 2 3 1 48p (k) 6 4 5 3 1 2
28 
 
Table 4 Overall performance of the proposed ED method and other methods on Database 2. 
 Re (K = iT ) Re (K = 2 iT ) Re (K = 3 iT ) Re (K = 4 iT ) 
ED 0.3370 0.4364 0.4945 0.5371 
SH 0.2451 0.3159 0.3607 0.3931 
SSD 0.2010 0.2395 0.2705 0.2977 
D2 0.1745 0.2216 0.2596 0.2902 
 
Table 5 Comparison of average query time of the proposed ED method and other methods in 
Database 2. 
 query time(sec) 
ED 3.148 
SH 2.946 
SSD 1.656 
D2 1.661 
 
 
 
 
            
 
            
  
             
 
Fig. 1  Original and decomposed 3D jeep model. (a) The 3D jeep model circumscribed by a 
bounding box. (b) The bounding box of the 3D jeep model is decomposed into a 
LLL 222 ×× voxel grid. (c) The normalized 3D jeep model. 
(c) (a) (b) 
n 
h h 
n 
m m 
h 
n 
m 
30 
 
 
Fig. 3 Top elevation of the 3D jeep model shown in Fig. 2(a) segmented by several concentric 
circles. 
 
  0
0.005
0.01
0.015
0.02
  
  
(a) 
    0
0.005
0.01
0.015
0.02
 
 
(b) 
    0
0.005
0.01
0.015
0.02
 
 
(c) 
Fig. 4   Elevation descriptors for the three models shown in Fig. 2. The vertical axis 
represents xk(j). The horizontal axis represents j ( 321 ≤≤ j ) for each k = 1, 2,…, 6 successively. (a) 
The elevation descriptors for the jeep model shown in Fig. 2(a). (b) The elevation descriptors for 
another jeep model shown in Fig. 2(b). (c) The elevation descriptors for the ship model shown in 
Fig. 2(c). 
k = 1 k = 2 k = 3 k = 4 k = 5 k = 6 
xk(j) 
j j j j j j 
k = 1 k = 2 k = 3 k = 4 k = 5 k = 6 
xk(j) 
j j j j j j 
k = 1 k = 2 k = 3 k = 4 k = 5 k = 6 
xk(j) 
j j j j j j 
32 
 
 
 
 
(a) 
 
 
 
(b) 
Fig. 7 Database 1. (a) 20 seed models. (b) 15 deformed models for the cat class. 
 
34 
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
Classes
Re
ED D2 SSD SH
 
Fig. 9 Comparison of the average recall (Re) for each class on Database 1(K = 15). 
 
0.75
0.8
0.85
0.9
0.95
1
Original Geometric Scaling Rotation Various
resolution
Re
ED D2 SSD SH
 
Fig. 10 Recall (Re) for various deformations in Database 1 (K = 15).
