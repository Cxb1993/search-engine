可供推廣之研發成果資料表 
□ 可申請專利  X 可技術移轉                              日期：97年 1月 6日 
國科會補助計畫 
計畫名稱：在多角度下的自動人臉偵測及角度估計藉著視覺系統下
統計學原理 
計畫主持人： 連震杰 
計畫編號：NSC 95－2221－E－006－284－ 
學門領域：EB 資訊學門二 
技術/創作名稱 在多角度下的自動人臉偵測及角度估計藉著視覺系統下統計學原理 
發明人/創作人 連震杰 
技術說明 
中文： 
我們將發展一套針對不同角度,採用統計方式的系統, 應用於不只
是做多角度的人臉偵測, 還可以做角度的估計. 其中, 人臉偵測
器是採用全域的特徵到區域的特徵,以及角度的估計是從粗略的角
度到精細角度的估計. 因為輸入的測試影像中, 大部份的區域為
非人臉的部分, 因此, 我們發展一套串接式的非人臉移除器以達
到快速消除85%以上非人臉的部份, 並可以降低系統整體的計算時
間. 因為不同角度的人臉在空間的變異性高,只用單一的辨識器來
發展多角度的人臉估計以及角度估計是會不準確的, 所以, 我們
改採用階層式的架構, 針對輸入的人臉或非人臉樣式(pattern), 
先將其分類到7 個粗略的角度聚類(cluster)的一種, 再將其用其
相對應的人臉偵測器及精細角度估計器做測試. 相對於傳統考慮
整個2D 的人臉影像做處理, 我們採用四種或五種有意義的區域臉
部特徵(或subregion)做為人臉偵測器的開發. 提出的這種方式, 
可以擁有較好的容忍度,包括不同的臉部表情, 較大的人臉角度變
化, 以及部分的遮蔽(occlusion). 每個區域的特徵將投影至相對
應 的 eigenspace 以 及 剩 餘 的 獨 立 成 份 空 間 (residual 
independent basis space). 我們採用獨立成份分析法(ICA)來建
構剩餘的獨立成份空間以節省運算的時間.接下來, 用likelihood 
的評估方式, 結合了投影權重向量(projection weight vector)
以及各別區域特徵在獨立成份空間的係數向量(coefficient 
vector) 來建立不同角度(7 種)人臉模型(model). 最後, 引進向
量量化(VQ)的方式來加速事後機率的運算速度(posterior 
probability). 
 
附件二 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
在多角度下的自動人臉偵測及角度估計藉著視覺系統下統計學原理 
An Automatically View-Based Statistic Approach for Multi-View Face               
Detection and Pose Estimation 
          
   計畫編號：NSC 95－2221－E－006－284－ 
執行期間：2006 年 08 月 01 日至 2007 年 12 月 31 日 
 計畫主持人： 連震杰 國立成功大學資訊工程系所 (jjlien@csie.ncku.edu.tw) 
  計畫參與人員: 凃瀞涏 博士班研究生助理, 方志偉 博士班研究生助理 
                曾建中 博士班研究生助理, 王基鎮 博士班研究生助理 
                陳洳瑾 博士班研究生助理, 王德勳 博士班研究生助理 
                邱文鴻 博士班研究生助理, 吳進義 博士班研究生助理 
 
中文摘要 
我們將發展一套針對不同角度,採用
統計方式的系統, 應用於不只是做多角度
的人臉偵測, 還可以做角度的估計. 其中, 
人臉偵測器是採用全域的特徵到區域的特
徵,以及角度的估計是從粗略的角度到精細
角度的估計. 因為輸入的測試影像中, 大
部份的區域為非人臉的部分, 因此, 我們
發展一套串接式的非人臉移除器以達到快
速消除85%以上非人臉的部份, 並可以降低
系統整體的計算時間. 因為不同角度的人
臉在空間的變異性高,只用單一的辨識器來
發展多角度的人臉估計以及角度估計是會
不準確的, 所以, 我們改採用階層式的架構, 
針對輸入的人臉或非人臉樣式(pattern), 先
將其分類到 7 個粗略的角度聚類(cluster)的
一種, 再將其用其相對應的人臉偵測器及
精細角度估計器做測試. 相對於傳統考慮
整個 2D 的人臉影像做處理, 我們採用四種
或五種有意義的區域臉部特徵(或 subregion)
做為人臉偵測器的開發. 提出的這種方式, 
可以擁有較好的容忍度,包括不同的臉部表
情, 較大的人臉角度變化, 以及部分的遮蔽
(occlusion). 每個區域的特徵將投影至相對
應的 eigenspace 以及剩餘的獨立成份空間
(residual independent basis space). 我們採用
獨立成份分析法(ICA)來建構剩餘的獨立成
份空間以節省運算的時間 . 接下來 , 用
likelihood 的評估方式, 結合了投影權重向
量(projection weight vector)以及各別區域特
徵在獨立成份空間的係數向量(coefficient 
vector) 來建立不同角度 (7 種 )人臉模型
(model). 最後, 引進向量量化(VQ)的方式
來加速事後機率的運算速度 (posterior 
probability). 
 
關鍵字: 人臉偵測，角度估計，主成份分
析，獨立成份分析，串接式非人臉移除器，
人機互動。 
 
Abstract 
  We will develop a view-based statistical 
system for not only detecting multi-view faces 
by using the global-to-local feature-based 
approach but also estimating the 
corresponding poses by using the 
coarse-to-fine approach. Because most regions 
of the input facial image exist non-face 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
boosting cascade. Bu et al. [22] proposed Real 
Adaboost to improve the boosting algorithm 
and detect multi-view faces. These works 
construct facial detectors for different views 
and improve the detection speed significantly. 
However, each view model is constructed 
independently and the estimated pose for each 
candidate is the combination of each 
view-detector result. These works apply each 
view detector to the testing image for 
detecting different views of faces. It is 
unreasonable to combine the result of each 
view detector because each detector is trained 
without considering their relationships during 
the learning process. Therefore, we use a pose 
estimator before applying each view classifier. 
For the pose estimator, the correlation of all 
different views of facial data is considered. 
Other works [9], [17], [21] focused on pose 
estimation without the function of face 
detection. 
 
2. Multi-view face detection system 
 
To solve above existing problems, we develop 
an appearance-based multi-face detection 
system, which consists of two subsystems to 
implement pose estimation subsystem. This 
subsystem directly analyzes input window 
containing image intensities using Principle 
Component Analysis (PCA) and applies 
clustering method to learn the intrinsic 
property of data. The output of this subsystem 
is the estimated pan-rotation angle of any 
input window. The other is the face/nonface 
classifiers. The entire detection system is 
shown in Figure 1. A pyramid of the testing 
image are downsampled from the original 
image by using scaling factor of 1.2. Each 
20x20-pixel window of each level of the 
pyramid goes through several processing steps 
[15]: First, the window is preprocessed by 
illumination correction and histogram 
equalization [15], [18]. Second, it passes to 
the facial pose estimation subsystem. Then it 
passes to a corresponding face/ nonface 
classifiers regarding to the rotation angle 
returned by the pose estimation subsystem. 
Finally a merging procedure is applied by 
combining all facial candidates from all 
pyramid layers to remove redundant 
candidates. 
 
3. The models construction 
For the facial pose estimation subsystem, the 
pose estimation models are constructed, 
including both coarse model and fine models. 
For face/ nonface classifiers which dealing 
with different view face, face and nonface 
models are constructed. 
 
3.1 Facial pose estimation subsystem 
In this process, two types of models are 
constructed. One is the coarse model; and the 
other is fine model. To construct both facial 
pose estimation models, not only PCA-based 
approach [11] but also the clustering method 
are used to investigate the distribution of  
Figure 2. (a) Feature points are manually labeled on 
the face for geometric normalization. (b) The facial 
template size of corresponding normalized image is 
20x20 pixels. 
(a) 
(b) 
＋30° 
－30° 
＋60° 
－60° 
＋90° 
－90° 
0° 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
  
group. To have accurate pose estimation result, 
we develop a new clustering approach to 
classify all training data.  
We separate all face data into K coarse 
clusters. To achieve optimal classification 
accuracy, we select K =7 experimentally. 
K-means clustering is then applied. Each 
datum is represented by the ith projected 
weight vector
 iω , and the initial centers of K 
coarse clusters are the means of 
°±°±°± 90,60,30 and °0  pose groups. From [10], 
the Mahalanobis distance )( TId becomes: 
 
 
 
 
[ ]
∑
=
=
−
−−
=
=
=∑=
Vi
i
i
T
TT
T
W
IUWUIIIId
1
i
2
1
11
          
          
~~~~)(
λ
ω
ωω
 
where III −=~ , IU~=ω , W and U are the 
eigenvalue matrix and its corresponding 
eigenvector matrix. Thus, the distance 
),( tkk Md ω  between the i
th input datum 
iω and 
the kth cluster center 
kM  is measured by  
 







 −
= ∑
=
=
Vj
j
j
jkji
ikk
M
Md
1
2
,,
)(),( λ
ω
ω      (4)          
where 
kM  is the cluster center vector in the 
cluster k. And the coarse models are 
represented by  
∑
⊂
=
=
n
kclusteri
i
ik
n
M
 
1
1
ω          (5)            
where n is the total data number of cluster k. 
After partitioning all data into K coarse 
clusters, there are K  coarse pose models, 
which correspond to the above K  coarse 
clusters. Table 1 list the range of the rotation 
angle for each coarse pose model. From Table 
1 we can find that each coarse model contains 
data within several different rotation angles. 
Figure 3. The graph shows the weight trajectories in the 
first three-dimensional pose eigenspace of 6 persons, 
who rotate their heads from left profile to right profile. 
pc1,pc2, pc3 are the first three eigenvectors. 
pc: principle component. 
Figure 4. The first three-dimensional pose eigenspace. 
Each point represents the projection weight iω  on 
the first three eigenvetors. Each color represents the 
specific rotation angle. The symbol “*” represents the 
cluster center. 
(3) 
Table 1. The range of the rotation angles from all 
training data for each coarse pose model. 
Pose Cluster Major Angle Range of Rotation Angles 
1 °− 90  ]65~90[ °−°−=Θ  
2 °− 60  ]50~75[ °−°−=Θ  
3 °− 30  ]25~45[ °−°−=Θ  
4 °0  ]15~25[ °+°−=Θ  
5 °+ 30  ]35~15[ °+°+=Θ  
6 °+ 60  ]70~40[ °+°+=Θ  
7 °+ 90  ]90~65[ °+°+=Θ  
 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
  
 
1 1
'
( ')( ') / 2 1/ 2
1
1
exp[ ( ]
2( | )
(2 )
M
T T
M M H
M HM H
i
i
y y B B
P x
pi λ
− −
+
+
=
− Λ + Λ
Ω =
∏
  (15)       
 
 
4. THE TESTING PROCESS 
 
The testing image window (20x20 pixels) of 
each pyramid is preprocessed by illumination 
correction and histogram equalization [15], 
[18]. Then it goes through several processing 
steps, including the pose estimation. Then it 
passes to the facial detection networks to 
decide whether the pattern is similar to a face. 
In the facial pose estimation subsystem, the 
testing pattern is projected into the pose 
eigenspace, and the projected weight is ωt. 
Then find the nearest coarse model k by Eq. 
(4). The rotation angle is estimated using 
),(minarg tklll HdL ω=          (16) 
[ ] 2/1
1
2)(),( ∑ =
=
−=
Vi
i
k
litit
k
ll HHd ωω        (17)             
where L  is the angle that fine model l 
represented.   
In Figure 5, we assume that a coarse model 
with major angle °+ 60 , which contains three 
fine models °+°+ 60,55  and °+ 65 , is constructed 
in training process. The testing window has a 
minimum distance ),(min tkMd ω  from that coarse 
model, and r is larger than threshold t. Then 
the distances between the testing window and 
these three fine models are computed 
individually by Eq. (16). If it is closest to the 
fine model of °+ 65 , the estimated rotation 
angle of the pattern is °+ 65 .   
Then the testing window passes to the 
specific face/ nonface classifier to check 
whether a face exists according to the 
estimated angle. Eq. (18) is used to determine 
whether a face exists. If the ratio is larger than 
defined threshold λ , the testing window 
contains a face. 
 
 
)( | ) (
( | ) ( )
f n
n f
P Y p
P Y p
λ
Ω Ω>
=
<Ω Ω
        (18)       
where fΩ and nΩ  represent face and nonface 
class respectively, ( | )fP Y Ω and ( | )nP Y Ω  is 
defined in Eq. (15) but models differ. 
After all testing windows in different 
pyramid levels are processed as mentioned 
above, we propose a merge procedure to 
reduce false detections. The procedure is as 
following. Facial candidates are combined in 
each individual pyramid layer in step 1 and 
step 2. The picked candidates are combined 
across all layers in steps 3 to 5. Figure 6 
shows the merge procedure. 
Step1)For each candidate in each layer, the 
number of overlaps is counted. Overlap 
occurs when the distance between the 
center of the current candidate and the 
center of all other candidates in the 
same layer is less than the pre-defined 
threshold (4 pixels in our system).  
Figure 5. One coarse model consists of three fine 
models. Red symbol “x” represents the mean of the 
coarse model.  Each fine model represents the 
specific angle. Green symbol “o” is the mean of each 
fine model. 
One fine model 
+55
∘ 
+65∘ 
+60∘ 
One coarse 
model 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
 Table 4. Lists the compare results using different 
architectures 
 
 
Table 3 lists the accurate rate of the pose 
estimation subsystem applied to data sets with 
different numbers V of eigenvectors. For 
saving computational time and not losing 
important information, we choose first V (30)  
eigenvectors to construct the pose eigenspace, 
which contains 74% variances. 
5.2 Performance of Face/ nonface 
Classifiers 
 
Table 4 lists the accurate rate of each view 
classifier with different designs. Compared 
with Architecture A, using statistic approach 
has better result than “learning” method 
because Arechitecture A has the convergence 
problem in the profile-view classifiers. The  
 
 
reason is that few features contain in profile 
faces; the neurons are confused with non-face  
patterns in the situation lack of information. 
 
5.3 Performance of Multi-View Face 
Detection System 
 
The entire system includes pose estimation 
subsystem, non-face rejecter, and the face 
detection network subsystem. When the 
window exists a face and the estimated angle 
error is limited within °±10 , this window is 
viewed as a correct detection. Table 5 shows 
the detection rate and the number of false 
alarms of Testing Set 3. We analyze the 
detection rate for each view. If the rotation 
angles of the faces are °± 60 or °± 30 , the areas 
Component-based 
architecture 
Architecture A  
Face Nonface Face Nonface 
-90∘ 95.94% 96.55% 85.10% 92.18% 
-60∘ 99.43% 95.18% 87.20% 93.21% 
-30∘ 99.64% 94.92% 93.00% 95.12% 
0∘ 99.76% 96.31% 94.20% 95.86% 
+30∘ 99.43% 96.81% 92.20% 93.75% 
+60∘ 98.47% 97.81% 88.50% 92.06% 
+90∘ 98.31% 95.46% 87.20% 90.76% 
-90 +90 
+90 -90 
Figure 7. (a) Error distributions for Training Set 
1. (b) Error distribution for Testing Set 1. 
Figure8. Error distributions for Training Set 3. 
(Pose error = the manual angle – the estimated angle)  
Pose detector Detection 
rate 
False alarms 
-90∘Left-profile view 90.1% 23 
-60∘ 85.2% 38 
-30∘ 93.0% 53 
0∘  Frontal view 94.2% 47 
+30∘ 92.2% 54 
+60∘ 83.5% 45 
+90  Right-profile view 87.2% 22 
 
Table 5. Detection results of Testing Set 3. 
 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 9. Testing results. Rotation angle of each candidate is marked on the upper left corner. (a), (b) 
Testing Set 3  (c) Testing Set 4. (d) Some detect errors of Testing Set 4.  
(b) 
 
(c) 
 
(d) 
 
(a) 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
 PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
吳進義出國報告 
 
一、 參加會議經過 
   大會的第一天(11/19)只有排一場晚場演講，是由 British 大學的
教授 David Lowe 所做的演講，其演講在探討如何用生物視覺的概念
做 recognizing object categorization。 
會議的第二天(11/20)，大會安排了許多的論文發表，包含了
Shape & Texture、Fitting、Face & Gesture、Tracking、Human Pose 
Estimation、Matching 等重要的主題。早上在見識完許多來自世界
各地頂尖專家的發表，下午去聽了 Face & Gesture 這個 section 的
一些 talk，之後便到另一個場地聽有關 Tracking 的 talk。發表會
過後便是 poster 會議的開始，在稍微與各作者討論完他們的作品後
我們前往 Katsushi Ikeuchi 教授的兩個實驗室參觀，其中的一個實
驗室做的是機器人活動研究，如會跳舞或畫畫的機器人，可惜的是並
沒有現場的 demo，只有圖片的簡報。另外的一個實驗室做的是 3D 重
建的技術，他們展示了受邀至柬埔寨的吳哥窟所做的大佛 3D 雷射重
建結果以及使用的技術展示，看過這兩個實驗室以後深深地了解什麼
叫做國外先進的實驗室，跟在台灣所看到的實驗室真的是好太多了，
不僅是在技術上的領先，他們設備上的資源更是在台灣所無法想像
的。 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
二、 與會心得 
這是第一次去參加國際性的會議，在會場要用英文跟大家交談並
且用英文解釋自己的東西，這些都另我非常的興奮也非常的緊張，這
些都是在國內不會有的經驗。而且可以跟世界上在相同領域的頂尖人
士互相討論也是很令人興奮的一件事情。看到在場的人，用著流利與
不流利的英文互相討論著，想要釐清自己心中的疑問，讓我也感受到
什麼叫做認真的態度。此外，會場中也不乏中國、香港或韓國的學者，
讓我覺得說台灣真的需要努力才不會被別人拋得太遠。 
三、 建    議 
這個會議的內容相當不錯，但是註冊的費用卻稍嫌偏高，而會場
也較為偏僻，使外地人不容易找到會場。另外，會議中 oral 的數目
明顯的比 poster 的數目少很多，但是 poster 往往容易發生找不到作
者為你解說你有興趣的東西這種情形。 
四、 攜回資料名稱及內容 
1.研討會全文碟。 
2.研討會贈品(日式包袱巾)。 
3.研討會節目行程表一本。 
 
 
 
 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
開始，在與發表論文的作者們討論完他們的研究方法，過程與實驗結
果後，我們就前往 Katsushi Ikeuchi 教授的實驗室參觀，並見識到
他們卓越的機器人活動研究，如會跳舞或畫畫的機器人，可惜的是並
沒有現場的 demo，只有圖片的簡報。此外，我還參觀了 Ikeuchi 教
授的實驗室受邀至柬埔寨的吳哥窟所做的大佛 3D 雷射重建技術。之
後 下 午 我 挑 了 face & gesture 這 個 section 聽 其 他 作 者
presentation，晚餐過後在 special section 的 round talk，會議
邀請了五家廠商，分別是 Toshiba，Hitachi，Fujitsu，Mitsubishi，
NEC 演講他們對於 computer vision 在日本研究上過去，現在，未來
與推行上的一些看法。 
會議第三天(11/21)，上午主要是 poster 的發表，我也逐一的跟
各個作者討論他們的作品，發現到他們重視到的不只是演算法的好
壞，就連效率，速度等因素也考慮的相當仔細。下午第一個 section 
(human detection)第一篇報告作者就是我了，我的論文題目是 
AdaBoost Learning for Human Detection Based on Histograms of 
Oriented Gradients，主要是利用踢度角度的統計圖當作特徵資料再
利用 AdaBoost 學習出最具有鑑別力的特徵來偵測人體位置。報告過
程非常順利，之後也在此 section 聽了很多相關於我研究領域的論
文，發現其實此一研究領域尚有繼續研究下去的價值。之後我另外去
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
獎，不過我的這篇論文有此機會可以競選最佳學生論文獎也是一種對
自我的肯定，總之參加這次會議讓我獲益良多。 
 
三、 建    議 
會議的口頭報告篇數太少，大部分都是 post，在 demo section 
裡面實際展示研究成果的並不多，會議的報名費過高且會議過程太緊
湊，有種讓人消化不了的情況，但是這會議還是讓我學到很多與產生
很多研究的新想法。 
 
四、 攜回資料名稱及內容 
1.研討會全文碟。 
2.研討會贈品(日式包袱巾)。 
3.研討會節目行程表一本。 
 
 
 
 
 
 
 
 
 
 
 
 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
paper 相當多，大家都以華語交談討論著，留下彼此的聯絡方式。
最後一天的下午，在與一群來自中國優秀學者討論著自己研究的
方向與該有的心態及技巧後，會議便在輕鬆、啟發性的交談中結
束。 
 
二、 與會心得 
感謝教育部、學校和指導教授的協助及經費上的支持，得以
讓學生參加此次的國際會議。這是第一次參加國際性的會議，藉
由此次研討會，學生從中了解到未來電腦視覺的研究方向以及商
業應用上的發展，著實獲益良多。不同領域的觀摩與學習，又能
認識國際一些研究學者，獲得寶貴的意見交流，領略自己的不足
之處。此外，藉由參加此類國際學術研討會，學生更能體驗充實
外語能力之重要與迫切性。會場中也不乏中國、香港或韓國的學
者，讓我覺得說台灣真的需要努力才不會被別人拋得太遠。 
 
 
三、 建    議 
建議教育部以及校方能多獎勵，補助國內碩博士生參加國際
會議，並多舉辦國際間的學術交流或產學合作。並希望校方能多
開設相關英文論文寫作，英文論文報告等重要課程，提升學生的
英文口頭報告能力及國際觀，並拉近國內碩博士生與國際學術研
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
曾建中出國報告 
 
一、 參加會議經過 
會議的第一天(11/19)只有排一場晚場演講，是由 British 大學
的教授 David Lowe 所做的演講，其演講在探討如何用生物視覺
的概念做 recognizing object categorization。 
會議的第二天(11/20)，大會安排了許多的論文發表，包含了
Shape & Texture、Fitting、Face & Gesture、Tracking、Human 
Pose Estimation、Matching 等重要的主題。由於並沒有和我
做一樣領域的發表，所以我挑選了一些比較感興趣的領域，如 
Tracking、Human Pose Estimation 這兩個 section。早上在見
識完許多來自世界各地頂尖專家的發表，下午第一個 section 
(Face & Gesture) 的第一位 便是我報告，我的報告題目是
Synthesis of Exaggerative Caricature with Inter and Intra 
Correlation，主要是在探討畫家如何根據與平均人臉及該誇張
物周圍的五官來畫誇張卡通圖並實現這項理論，報告的過程相
當順利，報告後也跟在場的專家們交換了畫家對於誇張的一些
定義及看法，之後便到另一個場地聽有關 Tracking 的 paper
發表。發表會過後便是 poster 會議的開始，在稍微與各作者
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
時間提升五、六倍之多。在簡短的午餐後，我選擇了 Image & 
Video Processing 這個 section 來聆聽，由於是會議的最後一
天，大家把握著最後的機會討問，所以氣氛也明顯的熱絡了起
來，有趣的是今年中國人所提的 paper 相當多，大家都以華語
交談討論著，在會議裡會有種在自家舉辦的錯覺。最後一天的
下午，在與一群來自中國優秀學者討論著自己研究的方向與該
有的心態及技巧後，會議便在輕鬆、啟發性的交談結束了。 
二、 與會心得 
由於這次是我第一次參加國際型的會議，並且要用英文口頭報告
自己所做的東西給其他專家學者，心裡的緊張自然不在話下。但從此
經驗中，我也學到了如何準備一場英文演講。此外，看到其他國家的
學者用著不太流利的英語對談，也要釐清自己心中的疑問，讓我也感
受到他們對於學術的用心與認真的態度，這也是我該努力的方向。此
次會議可發現到一個現象，與會的人士很多都是中國或香港的大學學
者，會場的討論聲中也充斥著中文，表示對岸的電腦視覺技術進步的
非常快速，這也是要我好好努力、不落人後的啟發。 
本次的會議讓我學習到很多做研究的想法，各種報告的技巧，重
要的是在與各方專家討論的過程中可以學習到不同的創新的思維和
新知的吸收。 
PDF Created with deskPDF PDF Writer - Trial :: http://www.docudesk.com
