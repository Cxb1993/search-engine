can be decomposed into semantic subspaces according 
to the likelihood within the subspaces are maximum. 
Each subspace composing of the factors in a factor 
graph corresponds to a semantic topic； a probability 
provides a measure to assess it. We present efficient 
approximate algorithms to perform inference on 
generate a HMM-like factor graph based on a trained 
model and graphically decompose into inseparable 
components to represent semantic topics. We report 
results from experiments in the task of document 
categorization/clustering comparing with several 
document clustering methods, including probabilistic 
models. 
英文關鍵詞： Conditional Random Fields, Topological Geometry, 
Graph Decompositions, cliques 
 
 2 
可供推廣之研發成果資料表 
■ 可申請專利  ■ 可技術移轉                                      日期： 年 月 日 
國科會補助計畫 
計畫名稱：利用擴散理論、語義網絡與時序分析為基礎之機器學習
法建立人類活動與環境變遷間之分析模擬模型 (3/3) 
計畫主持人：蔣以仁 
計畫編號：NSC 99－2221－E－038－012 學門領域：資訊二 
技術/創作名稱 即時動態文件資訊分群 
發明人/創作人 蔣以仁 
技術說明 
中文：我們的研究成果中，關鍵特徵的擷取能更正確且具獨特性，是建立因語
義而結合，探討動態性隨時而變之 Ontology 規律最重要的起始歨驟，提出新的
模型，利用機器學習結合諸如辭典之專家知識以建立屬特殊領域數位內容為目
標之關鍵資訊萃取方法，藉由 Conditional Random Field 模式，成為
Knowledge-Based Probabilistic Extracting 法則，以形成各特殊領域從專業文件中
萃取重要之詞彙；為求能確實掌握其中文義涵意，以作為後續同質分類分群，
建立推論 Ontology，協助對趨勢進行預測。 
英文：This research has taken scientific dataset and related articles as subject, 
especially the ecology domain, implementing “automatic feature extraction” and 
“scoring” model for automatically constructing the taxonomical and decision 
supporting ontology.  Through a topological point of view, we address a novel 
model, latent topology (LT), a discriminative probabilistic model for illustrating the 
homogeneous groups in the high-dimensional, heterogeneous and discrete data. LT 
introduces a mixture topological space of topics, documents and the features in the 
documents to model latent semantics in the context of text. Each semantic topic is 
modeled as a locally finite mixture over an underlying structure of features. 
Probabilities explicitly measure the local structure and provide an intrinsic value of a 
document to belong to a topic. 
可利用之產業 
及 
可開發之產品 
1. 圖書及檔案資訊：進行知識地圖建構，以協助檔案管理機構、
及圖資系統公司，作相似議題與內容的分類歸納。 
2. 科技性或其他各類文獻：已提供建立北醫醫學檢索網站
(visualmedline.tmu.edu.tw)實證資料檢索，協助醫護人員正確找
到所需的資料。 
技術特點 
1. 機器學習法進行詞彙選取，可使適應於各專業領域，並隨資料
累積，而使系統之準確性更加提升。 
2. 能結合特定領域專家知識，進行加權，萃取符合這領域之關鍵
詞彙。 
3. 協助能達到語義上之詞彙歸納與分群分類。 
4. 可不斷增加新詞彙的累積。 
推廣及運用的價值 
改善一般資料檢索方式，使能更準確掌握語意上的意義與實質內容
特性。可運用於資料檢索、群聚分析等服務。可與資訊檢索作有效
整合。 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。 
 4 
provides a measure to assess it. We present 
efficient approximate algorithms to perform 
inference on generate a HMM-like factor 
graph based on a trained model and 
graphically decompose into inseparable 
components to represent semantic topics. We 
report results from experiments in the task of 
document categorization/clustering 
comparing with several document clustering 
methods, including probabilistic models. 
 
Keywords: Conditional Random Fields, 
Topological Geometry, Graph 
Decompositions, cliques 
 
二、Introduction and Background 
 
As the rapid growth of huge repositories 
including data, texts, medias, and so forth, on 
the World Wide Wed (WWW) have become 
available to public, search engines and some 
other tools are attempted to aid users in 
gathering relevant contents from the Web 
based on users' requests from the 
human-machine interaction. Often 
inconsistent, uninteresting and disorganized 
search results are returned. Polysemy, 
synonymy, homonyms, phrases and term 
dependency as well as spam bring the 
limitations of search technology (Henzinger, 
2007; Joshi and Jiang, 2001). More feasible 
searched results by categories, subjects, and 
contents are major requisites for the design of 
search engines that can be achieved by 
evolving a sophisticated mechanism. Without 
actual denoting the topic in a context, the 
information expressed in a Web page may 
cause this problem. 
In order to more naturally fruitful to 
facilitate and enhance information access 
with humans, fundamental models to deal 
with ambiguity, elusiveness, or 
impreciseness of user requests, latent 
generative models, the Aspect Model (Minka 
and Lafferty, 2002) and the Latent Dirichlet 
Allocation Model (Blei et al., 2003) have 
been proposed in the last decades. Since the 
tf-idf scheme (Salton and McGill, 1983), a 
measure of each basic element, term or word, 
occurred in a document collection, was 
addressed to reveal the significances of 
elements in the collection of documents, the 
information researches achieved a significant 
progress. Each document is formed to be a 
vector of the tf-idf measures in which each 
measure belongs to a corresponded term. The 
document collection is then presented as a 
document-by-term matrix. This matrix is 
needed to present an enormous, but always 
sparse, feature space, since each document 
does not contain all the terms in the 
document collection. That makes several 
topics exist according to the different 
composite of terms co-occurred in the 
document collection. The success of the basic 
tasks of classifications/clustering, 
abstractions, topic detections, similarity and 
ranking, and so on, are based on whether we 
can effectively uncover the topics in a 
document collection. 
Latent semantic indexing (LSI) 
(Deerwester et al., 1990) attempts to map 
documents as well as terms to representative 
categories for automatic indexing and 
information retrieval. The huge dimension of 
appealing terms could be reduced by using 
LSI. LSI uses the singular value 
decomposition method to identify the linear 
subspace composed of the eigenvectors from 
a document-by-term matrix to capture most 
of variance in a text collection. This 
approach can make a significant compression 
of a large collection. Deerwester et al. 
(Deerwester et al., 1990) argue that the 
derived feature terms of LSI, a linear 
combination of the original tf-idf features, 
are able to capture some aspect of basic 
linguistic notions, such as synonymous and 
polysemous words. 
Lack of giving a generative probabilistic 
model of text corpora, Hofmann (Hofmann, 
1995) addressed an Aspect Model, 
probabilistic LSI model (PLSI), to overcome 
the problem of LSI by enhancing it with a 
statistical foundation and a generative data 
model. PLSI uses a multinomial mixture 
model to define terms that are formed by 
\topics" in a document.  Each term is 
generated from a single topic, and different 
terms in a document may be generated from 
different topics. No generative probabilistic 
property has given to documents, which 
limits the scalability of PLSI model. Blei et 
al. (Blei et al., 2003) improve that to make 
 6 
space X = (X, τ) and the topic space C 
satisfies the algebra property and both are 
able to equip with distinguished -algebras, 
so called Borel spaces. Following 
Kuratowski theorem on Borel spaces, a 
morphism f: X  C is a Borel measurable 
mapping defined on two Borel spaces. This 
property of -algebra also defines an axiom 
of choice to generate the bases in B. 
  On the other hand, the document space 
and topic space can produce a product 
topology such that Π = X × C, which is 
countable and finite.  The product topology 
Π is the Cartesian product of X and C, that is 
defined to be the coarsest topology, i.e., the 
topology with the fewest topics.  These two 
topological spaces can be extracted 
individually by a projection.  A discrete 
metric d defined on the product topology Π is 
given as 
1. d(x, y) = 1 if x = y, 
2. d(x, y) = 0 if x≠y; 
for any x, y in Π. For each x in Π, x=(w0, 
w1, …, wN-1, zk) where wi , 0 ≤ i ≤ N - 1 is a 
feature in F(X) and zk denotes a topic in C, 
and a discrete metric d is a metric defined on 
N+1-dimensional space Π.  In order to 
define a discrete metric d for a topological 
space Π, it is essential to use the base set B = 
{b1, b2, b3, … } of X at least because a base 
element bi = {wi1, wi2, …} in B, |bi| ≤ N in B 
is enough to identify a semantic topic zk  in 
C. No bases in any two distinguishable topics 
are the same, otherwise, one topic is said to 
be finer than the others or indistinguishable. 
The product topology Π equipped with a 
discrete metric is called completely 
metrizable that makes the product topology 
Π organize a separable, completely 
metrizable topological space, i.e., a Polish 
space.  Let Γ = Ub in B b in F(X) which is the 
largest set containing all the features of base 
elements in B satisfy the property of 
-algebra.  The order-pair (Π, Γ × C) 
therefore organizes a measurable space also 
called -field. The latent semantics is 
illustrated in the entangling structure of (Π, Γ
× C).  Accordingly, a Borel measure 
mapping between two Borel spaces is 
defined in this paper for modeling semantics 
in text corpora. The Borel  -algebra Γ×C of 
the metrizable space Π equals the smallest 
family Borel set of subsets of X ×C that 
contains all categorized open set and that is 
closed under countable intersections and 
countable unions. Figure. 1 illustrates such 
phenomenon. The base B is enough to infer 
all semantic topics associated with 
probabilistic measures. For example, 
{“neural”, “network”} can imply the 
semantics in the fields of biology or 
computer science that it is dependent on how 
many documents contain {“neural”, 
“network”} are in biological or computer 
science areas. 
 
 
3.1 Approximate Algorithms 
 
The high dimensional data can form a 
latent semantic model based on the features 
and the internal structures discovered from 
the data. The semantic topics are hidden in 
the model. In order to discover latent 
semantics within a data, the sophisticated 
algorithm is required that can be divided into 
three ad hoc parts: first, to extract the 
features and to construct an undirected and 
connected factor graph based on Markov 
models, i.e., a Markov-based simplicial 
complex, from a document set X; second, to 
decompose the skeleton from the 
Markov-based simplicial complex using 
graph decomposition method with a 
simplex-size to generate topologically 
distinguishable simplexes bound with a 
simplex-size; third, to cluster the data based 
on the generated simplexes. 
CRFs have a different nature by comparing 
with HMMs. CRFs are discriminative model, 
while at the training stage, to maximize the 
conditional probability of observation and 
 8 
 
In order to discover latent semantics in 
high dimensional data effectively and 
efficiently, a probabilistic topology method, 
Latent Topology, naturally transfer the data 
into a probabilistic semantic space. Several 
latent semantic patterns reveal connected 
components within the space built from data. 
According to highly correlated terms of each 
layered skeleton, the data can be iteratively 
partitioned into several meaningful topics. 
Each topic corresponds to a simplex 
composed of features extracted from a 
collection of documents. 
For example, consider to cluster the results 
returned from Pubmed search engine. A 
query term “APC”(adenomatous polyposis 
coli) had been used to retrieve article 
abstracts from Pubmed. However, the return 
results consist of not only articles about 
“adenomatous polyposis coli” but also others 
such as “antigen-presenting cells (APC)”, 
“anaphasepromoting complex (APC)”, 
“activated protein C (APC)” and “Barrett’s 
esophagus” that is related to “argon plasma 
coagulation (APC).”  It is not easy to fulfill 
researchers to retrieve articles without 
reading the abstracts. Henzinger (Henzinger, 
2007) reviewed the current state of search 
engine and pointed out the weakness of 
search engine. Beall (Science online, 16, Aug 
2007) thought deterministic search engines 
could provide a good solution on the 
homonym problem by creating unique labels 
for concepts with the same name, as in 
“Jaguar (Animal)” and “Jaguar 
(Automobile).” However, nobody has the 
ability to scale it to the web. Clustering 
methods can properly provide a guide to the 
researchers if the methods can demonstrate 
the semantics in those articles. 
To identify and discriminate the correct 
topics in a collection of documents, the 
combinations of features and their 
co-occurring relationships are the clue and 
the probabilities display how signi_cance 
they will be. All features in documents 
compose a topologically probabilistic space, 
more speci_cally, a simplical complex 
associated with probabilistic measures to 
denote the underlying structure. The complex 
can be geographically decomposed into 
inseparable components at various levels (in 
various levels of skeletons) that each 
component properly corresponds to topics in 
a collection of documents. Of course, the 
topics that a component induced are either 
topologically distinguishable or perfectly 
including in other induced topics. 
A HMM-like factor graph is the way to 
represent such a topologically probabilistic 
space properly. A trained Markov model will 
guide us to perform inference on any 
document collection to extract the features 
and create their associated links, i.e., 
relations. Graph decomposition algorithms 
are therefore able to decompose the factor 
graph into individual but maybe overlapped 
simplexes that map to semantics. 
 
五、參考文獻 
 
1. M. Henzinger. Search technologies for the 
internet. Science, 317(5837):468-471, 2007. 
2. A. Joshi and Z. Jiang. Retriever: Improving 
web search engine results using clustering. In 
A. Gangopadhyay, editor, Managing 
Business with Electronic Commerce: Issues 
and Trends, chapter 4. World Scientific, 
2001. 
3. J. Lafferty, A. McCallum, F. Pereira: Conditional 
Random Fields: Probabilistic Models for 
Segmenting and Labeling Sequence Data. In 
Proceesings of 18
th
 International Conference on 
Machine Learning (ICML 2001) 2001:282-289. 
4. D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent 
dirichlet allocation. Journal of Machine Learning 
Research, 3:993{1022, 2003 D. M. Blei, A. Y. Ng, 
and M. I. Jordan. Latent dirichlet allocation. 
Journal of Machine Learning Research, 
3:993-1022, 2003. 
5. S. Lawrence and C. L. Giles. Searching the World 
Wide Web. Science, 280(5360):98-100, 1998. 
6. S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. 
Landauer, and R. Harshman. Indexing by latent 
semantic analysis. Journal of the American 
Society for Information Science, 41(6):391-407, 
1990. 
7. T. Hofmann. Probabilistic latent semantic 
indexing. In Proceedings of the Twenty-Second 
Annual International SIGIR Conference, pages 
35-44, 1995.  
 10 
 
such as examinations.  In my section, two presenters were absent; therefore, four 
researchers including me presented our experiences on our work.  Except one work 
is on comparing the effects of two coding algorithms over Nakagmi fading channels; 
the others are related to using and developing a data mining algorithm for massive 
data.  At the third day, all presentations were stopped for the educational tours and 
were started in the forth day.  We went to Villa d’Este, a famous Italy garden.  
Following the principle on beautiful geometry and symmetry, the designer create a 
manifest ordering that melt nature and technology. 
 
I did not join the last day conference and was back to Taipei. 
 
 
 
This conference is not similar to any conferences in which I have taken part.  It is 
full of the discussion of human cultures, which emphases the integration of humanity 
and technology.  In Rome, it is a really good place for us to understand it.  Many 
great architectures, buildings, statuses, technologies, as well as arts, polities, etc., are 
starting from Rome.  Such fascinate environments induce the conference’s objectives 
on multi-disciplines.  
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：蔣以仁 計畫編號：99-2221-E-038-012- 
計畫名稱：利用擴散理論、語義網絡與時序分析為基礎之機器學習法建立人類活動與環境變遷間之分
析模擬模型 (3/3) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 1 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 0 100%  
博士生 2 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 1 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
