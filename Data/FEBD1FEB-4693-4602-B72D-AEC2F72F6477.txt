太陽能矽晶片微隱裂自動光學檢測系統開發 
Development of Automatic Optical Inspection System for Discovering 
Invisible Micro Crack of Silicon Solar Wafer 
 
 
中文摘要 
    檢測多晶矽太陽能晶片中的不可見微裂紋並不是一
件容易的事，這是因為其所特有的異方向性紋理背景。
此困難可從兩方面來說明。首先取像設備必需看的到隱
藏於晶片內部的微裂紋。其次，軟體程式必需將微裂紋
從影像中抽取出來。本研究首先建立一套能夠攫取到微
裂紋影像的近紅外線取像系統解決了第一個問題。接著
我們以區域成長法為基礎，發展出有能力從攫取所得影
像中抽取出微裂紋的瑕疵偵測演算法。實驗結果顯示，
本研究所提出之微裂紋檢測系統除了可以有效偵測出微
裂紋外，也可以用來檢查矽晶片是否有玷污、針孔、異
物、及裂痕等瑕疵。系統之整體精確度為 99.85%，所提
供之優點包括傑出的裂紋偵測敏感度、察覺隱裂的能
力、以及低成本。 
關鍵詞：微裂紋、瑕疵偵測、區域成長、太陽能晶片、
近紅外線取像。 
 
Abstract 
    To discover invisible micro cracks from a multi-crystalline 
silicon solar wafer image is not an easy task because of its 
heterogeneously textured background. The difficulty is twofold. 
First, invisible micro cracks must be visualized to imaging 
devices. Second, an image processing sequences capable of 
extracting micro cracks from cracked images must be developed. 
To solve the problems, a near infrared imaging system was first 
set up to capture images of invisible micro cracks. After being 
able to see invisible micro cracks, a region-growing-based flaw 
detection algorithm was developed to extract micro cracks from 
the captured images. The experimental results showed that the 
proposed micro cracks inspection system is effective in 
detecting micro cracks. Besides, it is also applicable to inspect 
silicon solar wafers for stain, pinhole, inclusion, and macro 
crack. The overall accuracy of the defect detection system is 
99.85%. The advantages afforded by the system including 
excellent crack detection sensitivity, ability to detect hidden 
subsurface micro cracks, and low cost. 
Keywords: Micro Crack, Flaw Detection, Region Growing, 
Solar Wafer, NIR Imaging. 
 
1. 前言 
    對矽晶片而言，無論是可見微裂紋（微顯裂）或不
可見微裂紋（微隱裂），如果未能及時被發現，極有可能
在後續製程中因受力而成長成巨觀裂紋（即一般的裂
痕），甚至破片。根據統計，矽晶片在製程中的破片率大
約是 2%，而矽晶片在太陽能電池的成本結構中佔了近
66%。可見，未能儘早將具有微裂紋的矽晶片偵測出來，
所導致的成本損失是相當驚人的。此外，即使具微裂紋
的矽晶片並未導致破片並順利製成電池，則該電池的光
電轉換效率也會降低，甚至影響整片太陽能面板的效率。 
 
圖 1、具微裂紋之多晶矽太陽能晶片影像：圖中的兩個微
裂紋實際上是隱藏於晶片內部的不可見微裂紋，然而在
本研究建立的 NIR 設備取像下，不可見微裂紋變可見了。 
 
值得一提的是，目前大約 86%的太陽能光電是由結
晶矽太陽能電池所產生的，因此檢測多晶矽太陽能晶片
是否具有微裂紋的重要性是不言可喻的。再者，除微裂
痕外仍有許多類型的瑕疵需要被檢出。例如電池中的異
物可能導致電池的短路，因此雜質的檢出也很重要。   
    根據裂紋的大小，裂紋可歸類為巨觀裂紋或微觀裂
紋，寬度小於 30 µm 的裂紋通常稱為微裂紋。此外，根
據裂紋出現的位置，裂紋又可分成可見裂紋或不可見裂
紋，出現在表面者一般稱為可見裂紋，隱藏於內部者即
稱為不可見裂紋（或稱為隱裂）。雖然隱裂存在於矽晶片
內部，但並非無法被察覺，事實上紅外線取像技術已普
遍用來檢測內部瑕疵[1-2]。圖 1 所示為利用近紅外線取
像技術所取得之多晶矽太陽能晶片之微裂紋影像。造成
微裂紋的因素是多方面的，當晶片受到外力作用時，在
晶片內部很容易造成裂紋，同時厚度愈薄的晶片愈容易
產生裂紋，甚至會導致破片[3]。雷射切割過程當中很容
易在晶片內部引發裂紋[4]。許多深層之裂紋是在矽晶錠
切片（ingot cutting）時所產生的[5]。 
 
2. 文獻探討 
    偵測裂紋的方法相當多，將聲、光、熱、射線（X-
射線、Gamma-射線）等導入待測物並觀察其反應都可以
偵測裂紋是否存在。最常見的裂紋檢測方法包括染料檢
測法、渦電流檢測法[6]、聲學檢測法[7-8]、超音波檢測
法[9]、輻射熱像圖(RHT)檢測法[10-11]、掃描聲波顯微鏡
(SAM)檢測法[12-13]、光致螢光(PL)檢測法[14-15]、電致
發光(EL)檢測法[16-17]及共振超音波振動(RUV)檢測法
[18-19]. 將深色染料塗抹在矽晶片上，透過觀察可很容易
得知是否有裂紋，可惜染料檢測法是破壞性檢測法。渦
 圖 3、第二取像系統。 
 
 
圖 4、第三取像系統。 
 
圖 5、使用第一及第三取像系統所攫取之影像： (a) 及 (b) 
為第一取像系統所取得之正面及背面影像；(c) 為第三取
像系統所取得之影像。 
 
 
圖 6、使用第二及第三取像系統攫取所得之影像：(a)與(b) 
分別代表使用第二取像系統所取得之正面及背面影像；(c)
與(d)為使用第三取像系統所取得之正面及背面影像。 
 
圖 5 所示為使用取像系統一與三攫取所得之影像。
從圖中可以清楚地看出，使用取像系統一取像，無論是
正面影像(圖 5(a))或背面影像(圖 5(b))，都無法看到內部
的微裂紋。有鑑於可見光無法穿透晶片內部，本研究於
是改採近紅外線取像系統。圖 6(a)與 6(b)是使用取像系統
二取得之正反面影像，也是無法看到隱藏於內部的微裂
紋。值得一提的是，圖中顏色較深的不規則圖案，是人
本研究使用 Prewitt 梯度運算子對不連續之數位影像進行
邊界點強化的處理。Prewitt 用以強化水平及垂直方向邊
界點的迴旋積遮罩如下所示。 










−
−
−
=
101
101
101
xP









 −−−
=
111
000
111
yP
 
4.3.2. 區域成長 
區域成長是由種子像素點（seed pixel）開始，檢查
其四個近鄰或八個近鄰，將與種子像素具有相似性質的
近鄰加入目前種子像素所屬的區域中。是否相似可以用
灰階、色彩、紋理、或其組合來評估。成長過程一般是
以迭代的方式重複進行，直到沒有新的像素點加入為
止。當一個區域的成長停止後，再挑選下一個種子像素
並重複上述之成長過程，直到所有的種子像素都已完成
成長為止。最後再利用區域合併演算法，將鄰近之相似
區域合併成為一個較大的區域。區域成長演算法的種類
相當多，並沒有那一個演算法絕對比另一個演算法來得
好。事實上，應該選擇那一種演算法與應用領域的影像
特性息息相關的。 
 如圖 8(b)所示，經過梯度運算後微裂紋的邊界比其他
周圍晶格的邊界來的亮，因此我們將灰階值大於平均灰
階值µgrad，且差值超過 Ts 的像素點當作是種子像素，其中
µgrad 為梯度運算後之結果影像的平均灰階值；Ts 稱為種子
門檻（seed threshold）。在成長的過程當中，與種子像素
相鄰，而且與µreg 的灰階差的絕對值小於 Tm 者，則將該
近鄰加入種子像素所屬的區域，其中µreg 代表種子像素所
屬區域目前的灰階平均值；Tm 稱為合併門檻值（merge 
threshold）。本研究所使用之 Ts 及 Tm 分別設定 在 70 及
3。值得一提的是，雖然上述兩個門檻值是經過測試後所
得到的，但是在光源沒有顯著改變的情形下，此二數值
是不需改變的。梯度影像（圖 8(b)）經區域成長後所得到
的結果影像如圖 8(c)所示。 
 
4.3.3. 形狀處理 
    膨脹(⊕)及侵蝕(ϴ)是形態處理的兩個基本運算，至於
斷開(ο)及閉合(•)則是由膨脹及侵蝕所衍生出來的運算，
其中斷開是先侵蝕一次再膨脹一次的運算，至於閉合則
是先膨脹一次再侵蝕一次的運算。當 A 影像先被結構元
素 B 侵蝕，所得到的結果再被結構元素 B 膨脹，此操作
即稱為斷開，因此斷開也可以表示成(AϴB)⊕B。當 A 影
像先被結構元素 B 膨脹，所得到的結果再被結構元素 B
侵蝕，此操作即稱為閉合，因此閉合也可以表示成
(A⊕B)ϴB。斷開的主要作用包括消除小島、打斷窄橋及
平滑物體輪廓。閉合同樣具有平滑物體輪廓的功用，此
外還能填補小洞及小缺口。形態處理可以根據四近鄰或
八近鄰的原則進行。針對可能的瑕疵本研究先施以四近
鄰膨脹，之後再施以八近鄰侵蝕。上述之非標準閉合運
算，具有將物體與物體之間的小縫隙填補起來的效果。
膨脹及侵蝕分別所使用之結構元素 B1 及 B2 如下所示： 
 
 
4.3.4 物件分析 
    尺寸濾波前，有必要先進行物件標號與物件分析，
以得知影像中每一個物件的尺寸。物件標號的目的是要
知道影像中有多少個俗稱為 blob 的物件，並賦予每一個
物件一個唯一的標號（label）。一個物件可以看成是由一
群相連通的像素點所構成，至於像素與像素間是否相連
通，通常是根據四近鄰或八近鄰的連通準則來認定。物
件標號常用的方法是連通元件標號（connected-component 
labeling）[39-40]。完成標號後屬於同一物件的像素點會
獲得相同的標號。物件分析即是利用這些標號資訊獲得
尺寸、形心、方向、矩量、離心率及 L-S 因子等特徵。 
 
4.3.5 尺寸濾波 
    為了降低假警報的機率，本研究採用尺寸濾波（size 
filtering）影像技術，忽略面積太小或太大的物件，或者
直接將其移除掉。一般說來，面積太小的物件是雜訊所
造成。本研究是以設定面積下限值的方式，找到面積小
於此下限值的物件，並將其組成像素之灰階值直接以背
景像素的灰階值取代（相當於移除掉）。本研究所設定之
面積下限值為 36 個像素（大約是一個半徑 50µm 小圓點
的面積）。圖 8(d)所示為微裂紋檢測最終得到的結果影
像，從圖中可以發現部份小雜訊已經被移除了。 
 
 
圖 9、微裂紋檢測結果。 
 圖 13、由上而下分別代表玷污、針孔、裂痕、及異物之
檢測結果，左圖為原始瑕疵影像；右圖為以紅色點標示
檢出瑕疵之結果影像。 
 
6. 結論與建議 
    
在太陽能矽晶片進入電池製程前，逐片檢查以確保
沒有微裂紋是重要的。本研究在多晶矽太陽能晶片微裂
紋檢測設備的自主發展上向前邁進了一步。雖然本研究
自行設計組裝之半球型近紅外線光源，其成本不到新台
幣5000元，卻可以讓看不見的微裂紋在近紅外線攝影機
的取像下變可見。為了滿足線上即時檢測的要求，本研
究發展出一套簡單的微裂紋檢測法，可以有效的將微裂
紋從攫取所得之影像中抽取出來。整體而言，本研究是
成功的，雖然仍有許多值得進一步改進的地方。
 
本研究目前所發展之雛型機能夠找出寬度 13.4 µm
以上的微裂紋，就檢測解析度而言是足夠的，但是每片
長達 1.5 分鐘的檢測時間，則是令人無法接受的。幸好，
透過更換高解析度攝影機的方式，即可解決檢測速度慢
的致命缺點。舉例來說，採用 Sensovation 公司出品的
coolSamBa HR-830 NIR 攝影機，在 8.3 百萬像素的高解
析度下，只要取像一次就可完成六吋矽晶片的檢測。值
得注意的是，本文所提出之檢測系統仍在發展中，目前
檢測軟體只能判斷矽晶片是否有瑕疵，並無法分辨瑕疵
的類別。因此，本研究接下來的工作就是利用真圓度、
離心率、灰階平均值等特徵對偵測所得之瑕疵進行分類。 
 
參考文獻 
[1] J.R. Hodor, H.J.J. Decker and J. Barney, “Infrared 
Technology Comes to State-of-the-art Solar Array 
Production,” in Infrared technology XIII; Proceedings of 
the Meeting, San Diego, CA, Aug. 18-20, pp. 22-29, 1987. 
[2] Y.C. Chiou and W.C. Li, “Flaw Detection of Cylindrical 
Surfaces in PU-packing by Using Machine Vision 
Technique,” Measurement, vol. 42, no. 7, pp. 989-1000, 
2009. 
[3] G. Coletti, C.J.J. Tool and L. J. Geerligs, “Mechanical 
Strength of Silicon Wafers and Its Modeling,” in 15th 
Workshop on Crystalline Silicon Solar Cells and Modules: 
Materials and Processes, Colorado, USA, Aug. 7-10, pp. 
117-120, 2005. 
[4] Y. Hayafuji, T. Yanada, Y. Aoki, “Laser Damage 
Gettering and Its Application to Lifetime Improvement in 
Silicon,” J. Electrochem. SOC 128, no. 9, pp. 1975-80, 
1981. 
[5] Y.K. Park, M.C. Wagener, N. Stoddard, M. Bennett and 
G.A. Rozgonyi, “Correlation Between Wafer Fracture and 
Saw Damage Introduced During Cast Silicon Cutting,” in 
15th Workshop on Crystalline Silicon Solar Cells and 
Modules: Materials and Processes, Colorado, USA, Aug. 
7-10, 2005, pp. 178-181. 
[6] G. Zenzinger, J. Bamberg, W. Satzger and V. Carl, 
“Thermographic Crack Detection by Eddy Current 
Excitation,” Nondestructive Testing and Evaluation, vol. 
22, no. 2-3, pp. 101-111, 2007. 
[7] C. Hilmersson, D.P. Hess, W. Dallas and S. Ostapenko, 
“Crack Detection in Single-crystalline Silicon Wafers 
Using Impact Testing,” Applied Acoustic, vol. 69, no. 8, 
pp. 755-760, 2007. 
[8] K. Yagi, H. Kanishi, Y. Kawagoe, “Substrate Crack 
Inspection Method, Substrate Crack Inspection Apparatus, 
and Solar Battery Module Manufacturing Method,” US 
Patent, 7,191,656 B2, Mar. 20, 2007. 
[9] K. Reber, M. Beller, “Ultrasonic In-line Inspection Tools 
to Inspect Older Pipelines for Cracks in Girth and 
Long-seam Welds,” Pigging Products and Services 
Association, 2003 
[10] M. Pilla, F. Galmiche and X. Maldague, 
“Thermographic Inspection of Cracked Solar Cells,” in 
Proceedings of SPIE, vol. 4710, pp. 699-703, 2002. 
[11] J.W. Devitt, E. bantel, J.M. Sparks and J.S. Kania, 
“Apparatus and Method for Detecting Fatigue Cracks 
Using Infrared Thermography,” US Patent, 5,111,048, 
May 5, 1992. 
[12] D. Knauss, T. Zhai, G.A.D. Briggs, and J.W. Martin, 
!"#$%&'()*+,$-.%'/01$2'3*4567
7777777777777777777777777777777777777777777777777777777778997:7; <7=9 >7
56?@A7
7
BCD7
EFGH7
IJK7
LMN'OPQ7
RS7
TU7
*4VW7
100/7/26 –100/7/28 
Hangzhou, China 
X*YZ7
+,[\7
7
*47
AK7
 (L[) 2011 :]^_`abc3$2de* 
 (f[) 2011 International Conference on Multimedia Technology (ICMT 2011)  
gh7
i[7
jk7
 (L[) lmnopqrstuvwx 
 (f[) Projection of Shape Features for 3D Model Retrieval 
yz! {|*4}~7
    ]^_`abc3$2de*`abc3dL$2*4:x
i[ 250`:sWorkshops ICMT 2011! 3S&DC 
2011zWCEUP 2011 I IWPM 2011:N*i[gh
NICMT 2011  ¡¢£¤N*¥1 Prof. Aly A. Farag ¦§¨©ª«¬­®¯!
]y Keynote SpeechX_*4°*44±L²³´µ¶r`abz·¸q¹c
3z`abOº»dd¼½r¾¿Àr.j56: (1). Computer 
Vision in Virtual Reality”z(2). 3D visualization and its Applicationsz(3). Advances on Topological 
Registration Approaches with Applicationsz(4). Navigating large image databasesz(5). Facial 
Shape, Texture and Reflectance from a Single Viewz (6). 6:Quantum Nanophysics and 
Nanoengineering of Low-Dimensional Devices and Circuits ÁI (7). Relativistic Danger for 
Spacecraft from Fast Satellites of the Solar-System Planets¤ Prof. Demetri Terzopoulos 
(University of California, USA) zProf. Jie Yang(Shanghai Jiaotong University, China)zProf.Aly 
A. Farag(University of Louisville,USA)zDr.Gerald Schaefer(Loughborough University,U.K.)z
Prof. Edwin Hancock(University of York,U.K.)zProf.Vijay K. Arora(Wilkes University,USA)ÁI 
Prof. Alexander P. Yefremov (Peoples’ Friendship Univ. of Russia, Russia)ÂÃÄ.j56 
  
     The 2nd International Conference on Multimedia Technology 
(ICMT2011)
IEEE㄀Ѡሞ໮ၦԧᡔᴃ೑䰙Ӯ䆂
Acceptance Notification 
May. 30th, 2011
Dear Author, 
Congratulations! It is our great pleasure to inform you that your paper 
Paper ID:IC14376 
Author(s):Lee Chang-Hsing,Shih Jau-Ling,Yu Kun-Ming, 
Title:Projection of Shape Features for 3D Model Retrieval 
has been accepted for presentation at The 2nd International Conference on 
Multimedia Technology, ICMT2011. 
Please complete all registration procedures before Jun. 5th, 2011 by the 
registration information attached. Otherwise your paper will be excluded in the 
proceedings and can not be submitted to EI Compendex. 
Thank you for submitting paper(s) to ICMT 2011 and we hope you can attend 
the conference. We also appreciate that you can contribute your excellent work 
to future ICMT conferences. 
For more information, please visit the conference website:  
www.icmtconf.org 
Best regards, 
ICMT 2011 Organizing Committee 
www.icmtconf.org    2011ᑈ 5᳜ 30᮹  Hangzhou , China     ICMT Organizing Committee 
IEEE Catalog Number: CFP1153K-CDR   ISBN: 978-1-61284-773-3 
IEEE Catalog Number: CFP1153K-PRT   ISBN: 978-1-61284-772-6 
experimental results to show the effectiveness of the proposed 
features. Finally, conclusions are given in Section 4. 
II. PROPOSED 3D MODEL RETRIEVAL SYSTEM 
First, each 3D model is decomposed into a number of 
voxels. Second, the principal planes method [12] will be used 
for pose alignment of each 3D model. Third, different features 
describing variant shape characteristics of each decomposed 
voxel will be projected onto six viewing planes. Finally, the 
MPEG-7 ART will be applied to each projection plane to 
extract the feature values of each 3D model. 
A. 3D Model Normalization and Alignment 
Given a 3D model, its pose is first aligned by the principal 
planes method [12]. The smallest bounding cube that 
circumscribes the 3D model is then decomposed into a voxel 
grid of size 100×100×100. A voxel located at coordinates (x, y, 
z) will be defined as an opaque voxel, notated as Voxel(x, y, z) 
= 1, if there is a mesh located within this voxel; otherwise, the 
voxel is defined as a transparent voxel, notated as Voxel(x, y, z) 
= 0. To be robust for translation and scaling, the 3D model is 
transformed such that the model’s mass center becomes (0, 0, 
0) and the average distance from all non-zero voxels to the 
mass center is 25. 
Once the pose of a 3D model is aligned, the angle value, 
radial distance, and elevation (depth) value of each opaque 
voxel will be projected onto six projection planes from which 
the feature value will be extracted to represent each 3D model. 
These six projection planes denote the six different views of 
the 3D model. The angle value describes the angle between the 
normal vector n of the mesh and the ray connecting the mass 
center of the 3D model and the center point of the mesh (see 
Fig. 1). The radial distance denotes the distance from the 
opaque voxel to the mass center of the 3D model (see Fig. 2). 
The elevation value describes the distance from the opaque 
voxel to the projection plane (see Fig. 2). These values can 
capture different shape characteristics (the orientation and 
location) of each opaque voxel. Each projection plane is 
represented by a gray level image in which the gray value 
denotes the angle value, radial distance, or elevation value. 
B. Angle Value Projection 
The angle value tries to capture the orientation of the 
model’s surface. For each voxel located at (x, y, z), let r denote 
the vector connecting the mass center of the 3D model and the 
center point of the surface mesh. The angle between the vector 
r and the normal vector n of the mesh serves as one of the 
characteristics of the surface mesh (see Fig. 1). The cosine of 
the angle between r and n will be treated as the projected angle 
value of the voxel located at (x, y, z): 
 ( ) 255 
|||| ||||
,, ×=
rn
rn
T
zyxθ  (1)  α  + β  = χ. (1) (1) 
Let the six angle projection planes be notated as A
kI , k = 1, 
2, …, 6. Then, the gray value, indicating the projected angle 
value, of each pixel on these projected images is defined as 
follows: 
 50 50-  )),,(,,() ,( max1 ≤≤= yx,yxzyxyx
A θI  (2) 
 50 50-  ),),,(,() ,( max2 ≤≤= zx,zzxyxzx
A θI  (3) 
 50 50-  ),,),,(() ,( max3 ≤≤= zy,zyzyxzy
A θI  (4) 
 50 50-  )),,(,,() ,( min4 ≤≤= yx,yxzyxyx
A θI  (5) 
 50 50-  ),),,(,() ,( min5 ≤≤= zx,zzxyxzx
A θI  (6) 
 50 50-  ),,),,(() ,( min6 ≤≤= zy,zyzyxzy
A θI  (7) 
where 
 )),,((max),(
500
max zyxzVyxz
z≤≤
=  (8) 
 )),,((max),(
500
max zyxyVzxy
y≤≤
=  (9) 
 )),,((max),(
500
max zyxxVzyx
x≤≤
=  (10) 
 )),,((min),(
050
min zyxzVyxz
z≤≤−
=  (11) 
 )),,((min),(
050
min zyxyVlzxy
y≤≤−
=
 (12) 
 )),,((min),(
050
min zyxxVzyx
x≤≤−
=  (13) 
 
Fig. 1 The angle between the normal vector n of the surface mesh and the 
vector r that connects the mass center of the 3D model and the center point of 
the surface mesh. 
C. Radial Distance Projection 
The radial distance tries to capture the location of the 
model’s surface. For each voxel located at (x, y, z), the radial 
distance is measured as its distance from the mass center of 
the 3D model. The radial distance is defined as follows (see 
Fig. 2): 
 ( ) 222,, zyxzyxRD ++=  (14) 
Let the six radial distance projection planes be notated as R
kI , 
k = 1, 2, …, 6. Then, the gray value, indicating the projected 
radial distance, of each pixel on these projected images is 
defined as follows:  
 50,05 )),,,(),,((max),(
500
1 ≤≤−= ≤≤ yxzyxVzyxRDyx z
R
I  (15) 
 50,05 )),,,(),,((max),(
500
2 ≤≤−= ≤≤ zxzyxVzyxRDzx y
R
I  (16) 
 50,05 )),,,(),,((max),(
500
3 ≤≤−= ≤≤ zyzyxVzyxRDzy x
R
I  (17) 
 50,05 )),,,(),,((max),(
050
4 ≤≤−= ≤≤− yxzyxVzyxRDyx z
R
I  (18) 
 50,05 )),,,(),,((max),(
050
5 ≤≤−= ≤≤− zxzyxVzyxRDzx y
R
I  (19) 
 50,05 )),,,(),,((max),(
050
6 ≤≤−= ≤≤− zyzyxVzyxRDzy x
R
I  (20) 
D. Elevation Projection 
The elevation value tries to capture the altitude (depth) 
information of the model’s surface to each viewing (or 
projection) plane. For each voxel located at (x, y, z), the 
635
compares the retrieval results of the proposed approaches with 
other state-of-the-art descriptors in terms of DCG score. In 
this table, ART-A, ART-R, and ART-E denote the approaches 
that use the ART feature vectors extracted from the projection 
planes of the angle value, radial distance, and elevation value, 
respectively. In addition, the combination of these three 
feature vectors is notated ART-ARE. It can be seen that each 
of the proposed approaches outperform the other descriptors in 
terms of DCG score. 
TABLE I.  COMPARISON OF THE PROPOSED APPROACHES WITH OTHER 
DESCRIPTORS IN TERMS OF THE DCG SCORE (%). NOTE THAT THE 
APPROACHES MARKED WITH * ARE IMPLEMENTED BY AKGUL ET AL. AND 
ORIGINALLY APPEARED IN [18]. 
Approach DCG 
SH [3] 58.35 
SSD [5] 48.07 
GD2 [7] 60.91 
LF [9] 64.30 
ED[10] 67.04 
RISH [11]* 58.40 
PPD [12] 65.86 
CRSF [13] 66.80 
DBF [18] 65.90 
DSR+DBF [18] 70.20 
AED [19] 70.29 
DED[20] 66.92 
CED[20] 68.04 
EGI [21] 43.80 
SH-GEDT [22] 58.40 
DBI [23]* 66.30 
DSR [23]* 66.50 
SIL [23]* 59.70 
SWD [24]* 65.40 
3DHT [25]* 57.70 
CAH [26]* 43.30 
REXT [27]* 60.10 
Proposed ART-A 69.98 
Proposed ART-R 71.60 
Proposed ART-E 71.90 
Proposed ART-ARE 73.53 
IV. CONCLUSIONS 
In this paper, a new feature descriptor which combines the 
projected shape features, including the angle value, radial 
distance, and elevation value of each surface mesh, is proposed 
for 3D model retrieval. For each of the characteristic values, 
six projection planes represented as gray-level images will be 
generated. MPEG-7 angular radial transform (ART) is then 
used to compute the feature vector from each projection plane. 
Experiments conducted on Princeton Shape Benchmark (PSB) 
database have shown that the proposed approaches outperform 
other state-of-the-art descriptors in terms of DCG score. 
REFERENCES 
[1] J. W. Tangelder and R. C. Veltkamp, “A survey of content based 3D 
shape retrieval methods,” Multimedia Tools and Applications, vol. 39, 
pp. 441-471, 2008. 
[2] D. V. Vranic, D. Saupe, and J. Richter, “Tools for 3D-object retrieval: 
Karhunen-Loeve transform and spherical harmonics,” in Proc. IEEE 
Workshop Multimedia Signal Processing, 2001, pp. 293-298. 
[3] T. Funkhouser, P. Min, M. Kazhdan, J. Chen, A. Halderman, D. Dobkin, 
and D. Jacobs, “A search engine for 3D models,” ACM Trans. Graphics, 
vol. 22, no. 1, pp. 83-105, 2003. 
[4] R. Osada, T. Funkhouser, B. Chazelle, and D. Dobkin, “Shape 
distributions,” ACM Trans. Graphics, vol. 21, no. 4, pp. 807-832, Oct. 
2002. 
[5] S. Manjunath, P. Salembier, and T. Sikora, Introduction to MPEG-7 
Multimedia Content Descriptor Interface. John Wiley & Sons, 2002. 
[6] M. Ankerst, G. Kastenmüller, H. P. Kriegel, and T. Seidl, “3D shape 
histograms for similarity search and classification in spatial databases,” 
in Proc. 6th Int. Symp. Advances in Spatial Databases, 1999, pp. 207-
226.  
[7] J. L. Shih, C. H. Lee, and J. T. Wang, “3D object retrieval system based 
on grid D2,” Electronic Letters, vol. 41, no. 4, pp. 23-24, Feb. 2005. 
[8] B. J. Super and H. Lu, “Evaluation of a hypothesizer for silhouette-based 
3-D object recognition,” Pattern Recognition, vol. 36, no. 1, pp. 69-78, 
Jan. 2003. 
[9] D. Y. Chen, X. P. Tian, Y. T. Shen, and M. Ouhyoung, “On visual 
similarity based 3D model retrieval,” Computer Graphics Forum, vol. 
22, no. 3, pp. 223-232, Sep. 2003. 
[10] J. L. Shih, C. H. Lee, and J. T. Wang, “A new 3D model retrieval 
approach based on the elevation descriptor,” Pattern Recognition, vol. 
40, no. 1, pp. 283-295, Jan. 2007. 
[11] C. T. Kuo and S. C. Cheng, “3D model retrieval using principal plane 
analysis and dynamic programming,” Pattern Recognition, vol. 40, no. 
2, pp. 742-755, Feb. 2007. 
[12] J. L. Shih and W. C. Wang, “A 3D model retrieval approach based on 
the principal plane descriptor,” in Proc. 2nd Int. Conf. Innovative 
Computing, Information Control (ICICIC’07), 2007. 
[13] P. Papadakis, I. Pratikakis, S. Perantonis, and T. Theoharis, “Efficient 
3D shape matching and retrieval using a concrete radicalized spherical 
projection representation,” Pattern Recognition, vol. 40, no. 9, pp. 2437-
2452, Sep. 2007. 
[14] D. V. Vranic and D. Saupe, “3D model retrieval,” in Proc. Spring Conf. 
Computer Graphics and its Applications (SCCG2000), pp. 89-93, 2000. 
[15] J. L. Shih, C. H. Lee and C. H Chuang, “A 3D model retrieval system 
based on the drivative radial distance,” in Proc. 22th IPPR Conf. 
Computer Vision, Graphics and Image Processing (CVGIP’2009), 2009. 
[16] MPEG Video Group, “MPEG-7 Visual part of experimentation Model 
Version 9.0“, 2001. 
[17] P. Shilane, P. Min, M. Kazhdan, and T. Funkhouser, “The Princeton 
shape benchmark,” in Proc. Shape Modeling, 2004, pp. 167-178. 
[18] C. B. Akgul, B. Sankur, Y. Yemez, and F. Schmitt, “3D model retrieval 
using probability density-based shape descriptors,” IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol. 31, no. 6, pp. 1117-1133, June 
2009. 
[19] J. L. Shih and H. Y. Chen, “A 3D model retrieval approach using the 
interior and exterior 3D shape information,” Multimedia Tools 
Applications, vol. 43, no. 1, pp. 45-62, May 2009. 
[20] J. L. Shih, T. Y Huang, and Y. C. Wang, “A 3D model retrieval system 
using the derivative elevation and 3D-ART”, in Proc. IEEE Asia-Pacific 
Services Computing Conference (APSCC’2008), pp. 739-744, 2008.  
[21] B. K. P. Horn, “Extended Gaussian images,” Proceedings of the IEEE, 
vol. 72, no. 12, pp. 1671-1686, Dec. 1984. 
[22] M. Kazhdan, T. Funkhouser, and S. Rusinkiewicz, “Rotation invariant 
spherical harmonic representation of 3D shape descriptors,” in Proc. 
Eurographics/ACM SIGGRAPH Symp. Geometry processing, 2003, pp. 
156-164. 
[23] D. V. Vranic, “3D model retrieval,” Ph.D. Dissertation, University of 
Leipzig, Department of Computer Science, 2004. 
[24] H. Laga, H. Takahashi, and M. Nakajima, “Spherical wavelet descriptors 
for content-based 3D model retrieval,” in Proc. IEEE Int. Conf. Shape 
Modeling and Applications, 2006. 
[25] T. Zaharia and F. J. Preteux, “Shape-based retrieval of 3D mesh 
models,” in Proc. IEEE Int.Conf. Multimedia and Expo, vol. 1, pp. 437-
440, 2002. 
[26] E. Paquet and M. Rioux, “Nefertiti: A query by content software for 
three-dimensional models databases Management,” in Proc. Int. Conf. 
Recent Advances in 3D Digital Imaging and Modeling, pp. 345-352, 
1997. 
[27] D. V. Vranic, “An improvement of rotation invariant 3D shape 
descriptor based on functions on concentric spheres,” in Proc. IEEE Int. 
Conf. Image Processing, pp. 757-760, Sep. 2003.  
 
 
637
99 年度專題研究計畫研究成果彙整表 
計畫主持人：邱奕契 計畫編號：99-2221-E-216-036- 
計畫名稱：太陽能矽晶片微隱裂自動光學檢測系統開發 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備註（質化說明：
如數個計畫共同
成果、成果列為
該期刊之封面故
事...等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
多晶矽太陽能晶片
之微隱裂檢測 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100% 
Micro Crack 
Detection of 
Multi-Crystalline 
Silicon Solar 
Wafer Using 
Machine Vision 
Techniques 
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
檢測多晶矽太陽能晶片中的不可見微裂紋並不是一件容易的事，這是因為其所特有的異方
向性紋理背景。此困難可從兩方面來說明。首先取像設備必需看的到隱藏於晶片內部的微
裂紋。其次，軟體程式必需將微裂紋從影像中抽取出來。本研究首先建立一套能夠攫取到
微裂紋影像的近紅外線取像系統解決了第一個問題。接著我們以區域成長法為基礎，發展
出有能力從攫取所得影像中抽取出微裂紋的瑕疵偵測演算法。實驗結果顯示，本研究所提
出之微裂紋檢測系統除了可以有效偵測出微裂紋外，也可以用來檢查矽晶片是否有玷污、
針孔、異物、及裂痕等瑕疵。系統之整體精確度為 99.85%，所提供之優點包括傑出的裂紋
偵測敏感度、察覺隱裂的能力、以及低成本。 
    本研究建立一套有效的 NIR 取像設備，可以順利攫取可見光取像系統所看不到的微隱
裂，並成功整合軟體程式與移動平台完成 AOI 雛型機。系統之硬體設備包括 NIR 取像設備
及 XY 平台兩大部份。NIR 取像設備是由攝影機、鏡頭、自製半球型 NIR LED 照明、及影像
攫取卡所組成。XY 平台的 X-軸是用來移動承载太陽能晶片的檢測平台；Y-軸是設計來同
步移動攝影機及照明設備。本研究以全自動檢測的方式針對四片具微裂紋之六吋多晶矽太
陽能晶片進行檢測。檢測結果除了 3 張微裂紋影像沒有被偵測出來外，其餘 30 張瑕疵影
像都成功地被檢查出來，更重要的是並沒有 false alarm 的情形發生。從 99.85%的高精確
度來看，本檢測系統確實有效。本系統主要是用來檢查微裂紋，然結果顯示本系統也能檢
測出包括玷污、針孔、異物及裂痕等經常出現之瑕疵。本研究之成果已發表於國際 SCI 期
刊 Sensor Review (Yih-Chih Chiou, Jian-Zong Liu and Yu-Teng Liang, ’Micro Crack 
