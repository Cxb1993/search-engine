 2
動物體的依據[5]。有時會利用重複的線段逼近(recursive line-fitting)與一維的搜尋方式，在
連續的視訊影像中，擷取出移動物體之方向特性[6]。為了要避免環境雜訊導致移動物偵測
不準確，也可以收集各種可能跡象，來將視訊影像中可能的移動物體外型抽取出[7]。至於
背景若變動頻繁，可利用 Kalman 過濾方法(Kalman filter)[8]，來估算移動資訊(motion 
information)。有時可利用移動物體的外型、質地、顏色、邊緣與方向等特性，來建立有效
的模式(active model)，用以追蹤移動物體[9, 10]。 
B. 人類動作分析(human motion analysis)：專注在偵測移動人類週期性的動作，看看是
否符合人類的步伐(gait analysis) [11-13]，並記錄各時段人體的姿勢。大自然的物體可大概
分成剛體(rigid)與非剛體(non-rigid)兩大類，而非剛體根據變形程度(deformation degree)又可
分成三種：由關節相連的區塊組成(articulated)、如橡膠般有彈性(elastic)、有流動特性的
(fluid)。人類是屬於非剛性的第一種，可利用感知結構(perceptual organization)，例如時間連
貫性(temporal coherence)、空間親近性(spatial proximity)來分析與切割動作[14]。也可利用時
空的外型輪廓分析(spatial-temporal silhouette)方式，來辨認移動物體的步伐[15]。 
C. 行為理解(behavior understanding)：解析長時間對該移動物體的行為觀察，以容易瞭
解的解釋方式，來描述其獨自行為[16]或與他人的互動行為[17]。也可以根據應用，定義出
一些基本動作(primitives)，利用視訊中移動物體基本動作間的關係，配合機率性句法的分
析(probabilistic stochastic parsing)，可對該移動物體的行為做辨認[18]。 
多數的視訊監視技術，都是著重在上述三類領域的研究上。第一類研究領域屬於監視
應用的前處理，錄影畫面中的移動物體必須先被偵測出，進而做類別分辨，若是屬於移動
之人員，則需視需要進行後續的處理（也就是後兩類的動作分析與行為理解研究領域）。以
目前第一類研究領域的相關成果看來，絕大多數處理在單一空間，或者變化不大的兩空間
進出人員之偵測與追蹤，對環境變化大、或者亮度變化迥異的相鄰空間均未考慮，因此，
實用性會受到限制。而第二類的動作分析領域，多數的研究均以判別簡單的週期性動作（如
走路、跑步、站立、蹲下等）為主；第三類的行為理解領域，則是假設連續畫面中動作判
定已完成，來進行後續的行為理解。這些欲理解的行為也是事先定義好，來判定是否有需
協助、需防範或需警示的行為發生。事實上，所需分析的動作應該是要從欲理解的行為來
定義，而且可疑行為或者危險行為應該要讓監控人或者照護人來定義，以提升視訊監控系
統的實用性。 
在此次研究，我們採用多台 PTZ 攝影機來做視訊監控。然而，當 PTZ 攝影機的拍攝位
置或方向改變時，必須重新校正其外部參數。因此，如何快速且有效率地校正多台攝影機
的相對位置和方向，是一個很重要的議題。目前為止，有許多校正單一攝影機內部參數和
外部參數的方法[19]，也有一些針對校正多台攝影機而發展的技術[20]，但是複雜的校正程
序並不適合用在監控環境中重複地校正攝影機。因此，我們將利用簡易的影像資訊，開發
出有效率的多台 PTZ 攝影機校正方法，以適用於一般監控環境。 
 
丁、 研究方法 
本研究著重在室內環境的多移動物體追蹤，環境背景相對較穩定，因此採用背景相減
法，來偵測每張畫面影像中的前景物體。另外，視訊監控環境不應該只有單一人員在狹窄
的空間中移動，更可能的是多重人員在廣大空間，或是多個鄰近房間中移動。此種監控環
境除了需要使用多攝影機之外，還要處理移動人員追蹤時常見的幾個問題。首先是追蹤多
重移動人員時，常會發生遮蔽現象，也就是畫面中的移動人員重疊，導致於無法清楚判定
偵測法(connected component detection)，找出前景物體元件位置，並將分散但相近之元件合
併成同一物體，如圖 1(d)所示。 
(二). 攝影機色彩校正 
不同攝影機在不同環境下所拍攝之畫面，其顏色與亮度會有所不同。利用不同攝影機
畫面所偵測的前景物體，需透過特徵值的一致化，才能進行移動物體的持續追蹤。由於座
標之校正可在安裝攝影機之初便進行校正，而拍攝環境之亮度，會隨著時間、燈光有明顯
不同。本研究採用亮度均等化方式，將不同攝影機所拍之畫面做影像亮度的調整。 
針對每張畫面影像，我們先統計所有像素顏色的分佈。假設 Hmax 和 Hmin 表示分佈圖
中最大及最小之像素顏色值。對於原畫面中特定位置的顏色值 ，利用公式(4)的計算，
求出均等化後該位置的像素顏色值
),( yxI
),( yxI ′ 。 
)/(255)),((),( minmaxmin HHHyxIyxI −×−=′                                        (4) 
均等化後的像素顏色值變動範圍會從[Hmin, Hmax]改變為[0, 255]間，強化了整張畫面影像的
對比。圖2(a)及(b)顯示一張亮度偏暗的畫面影像及其像素色彩之分佈；經過亮度均等化後
的結果影像及相對之像素色彩分佈如圖2(c)及(d)所示。 
(a) (b) (c) (d) 
圖 2. 畫面影像及像素顏色分佈圖 (a)(b)亮度均等化前；(c)(d)亮度均等化後 
 
利用亮度均等化，主要用來調整單張影像的明亮對比，使影像內容的明暗更為明顯。
然而，本研究以多攝影機拍攝保全空間，並追縱在不同區域間移動的物體。因此，還要將
同時間不同攝影機之畫面影像做亮度一致化。由於兩攝影機所拍攝之背景環境有所不同，
亮度均等化雖可個別強化對比，但是對比強化後的兩張影像，其明亮程度還是有所不同，
也會影響後續進行物體接續追蹤。為利用特定且相同的亮度校正基準，本研究利用一張純
灰色之校正紙張，放置在各攝影機所在之環境中，分別拍攝包含該校正紙之畫面後，分別
擷取各畫面之校正紙區域，來進行亮度之差異校正。 
假設兩台不同攝影機之畫面影像，經過亮度均等化後，擷取出校正紙區域，並計算出的
平均亮度值分別以 CamAµ 與 CamBµ 表示。可選擇攝影機A之畫面為基準，則攝影機B所拍畫
面，除了自行做亮度均等化，尚須對各像素點的顏色 做等量之亮度調整（如公式(5)
所示），成為與攝影機A之畫面相近之顏色
CamBClr
CamBrCl ′ 。 
⎟⎠
⎞⎜⎝
⎛×=′
CamB
CamA
CamBCamB ClrrCl µµ                                                (5) 
圖3(a)與(c)分別為兩攝影機在環境明暗不同時所拍攝之畫面影像；圖3(b)為攝影機A畫面經
過亮度均等化之結果，而圖3(d)攝影機B畫面經過亮度均等化後，再與圖3(b)做亮度一致化
之結果。 
 4
位置擷取出後，將所有背景相減法所得之差異點做垂直投影，並設定門檻值，找出上
半身軀體部分之左右邊界（圖 4(b)），配合原先擷取之垂直邊界，可決定上半身驅幹之
範圍。假設分別以Hu、Hd、Wl與Wr代表其上下左右之邊界（圖 4(c)），該區域影像的色
彩特徵包括了顏色平均值與變異數，其計算方式分別如公式(7)與公式(8)所示。其中，
I為目前畫面影像，而DiffImg為利用背景相減法所得之差異圖。 
∑∑
∑∑ ×r uW H yxDiffImgyxI ),(
=
r
l
u
d
l d
W
W
H
H
W H
iBClrMean
yxDiffImg
OF
),(
),(
)(                                (7) 
∑∑
∑∑ −×
=
r
l
u
d
r
l
u
d
W
W
H
H
W
W
H
H
iBClrMean
iBClrVar
yxDiffImg
OFyxDiffImgyxI
OF
),(
))(),(),((
)(
2
                          (8) 
而下半身顏色的計算方式如同上半身，只是因為下半身主要是雙腳，如果是移動
中的
特徵 
精確度，本研究同時利用前景物體在連續畫面中的移動特性，加入比
對用
在 與 時間點，某物體 i所在位置為 pos 與 pos ，且兩時間點的時間差異為
則此時間內該物體之速率特徵計算方法如公式(9)，即是將位移距離除以時間間隔。 
人類物體，並不容易從下半身中找到較穩定的部位。因此，我們擷取所有位在物
體下半部的差異點，來進行顏色特徵的擷取。假設下半身區域之邊界位置為H’u、H’d、
W’l與W’r，該區域影像的色彩特徵的計算方式如同公式(7)與公式(8)。除了顏色平均值，
本研究同時計算區域內的顏色變異數，主要是要辨別穿著同一顏色之多重移動人員。
若其顏色雖相近，但可利用顏色變異性，來分辨純色衣物與含有其他顏色花紋衣物之
不同。 
(3). 速率
為提升比對
之特徵。首先，移動中的物體，通常在連續兩張畫面中，移動的速率會平穩，不
會剎那間有急遽的變化。因此，移動速率可當作多物體追蹤時的比對特徵之一。假設
t t+1 O )(t OF )(1t OF +
t∆ ，
i i
t
OFOF
OF
i
tt +1
posipos
iv ∆
−= )()()(                                           (9) 
(4). 方向特徵 
方向不定，但在短時間間隔內，移動方向通常變化不大。當然也可能
突然
雖說移動時
轉換方向，但輔以其他的穩定及移動特徵，還是可以彌補此方向特徵的不足之處。
由於本研究在追蹤過程中需判定是否需做攝影機畫面之切換，因此物體之移動方向輔
以目前位置，可較精確地判定該物體是否將離開某攝影機之拍攝範圍。假設在t與t+1
時間點，某物體Oi所在位置之X-Y座標分別為( )( it OXPos , )( it OYPos )與( )(1 it OXPos + , 
)(1 it OYPos + )，則此時間內該物體之移動方向特徵 )。 計算方法如公式(10
⎟⎟⎠
⎞
⎜⎜⎝
⎛
−
−=
+
+−
)()(
)()(
tan)(
1
11
itit
itit
idir OXPosOXPos
OYPosOYPosOF                               (10) 
(四). 物體追蹤 
為進行移動物體的追蹤，我們定義兩個不同的物體稱謂：前景物體(foreground objects)
 6
時間時，只偵測到一個前景物體，且其特徵與原先兩個追蹤標的物不相似，即被本系統判
定為遮蔽發生(如圖6(b))，馬上切換至攝影機B所拍攝之畫面影像(如圖6(d))，該畫面中可偵
測兩個前景物體，並可完整對應到追蹤標的物。 
Frmt Frmt+1 Frmt Frmt+1
攝影機 A 攝影機 B 
圖 6. 同空間多人發生遮蔽時切換畫面持續追蹤 
(a) (b) (c) (d) 
 
多攝影機尤其適用於多空間的接續追蹤，事先針對各攝影機所拍畫面定義出入口位
置，當移動人員從空間A透過出入口移動至空間B時，本系統即可自動切換畫面，持續進行
 8
追蹤
在 時 間 t 時 之 中 心 座 標
XPo
(Lexit, T
當下一個畫面 間t
時) OXPos OYPos )位置處，可算出此時之移動方向特徵
OF θ 來表示。若滿足 1min θθθ << + 條件，則可判定此物體O 正往
出入口位置移動。 
出入口範圍之相對關係，來判定該人員是否位於出入口。假設某前景物體Oi的邊界座標分
別為
。不同攝影機的畫面切換，最主要的問題是如何決定何時該切換。當可疑人員穿越不
同空間時，畫面切換的時間應該是在人員接近出入口時。因此，本研究利用物體之移動方
向，判定該物體是否正往出入口接近，再利用目前位置，判定是否已位在出入口區域。一
旦前景物體已移動至出入口位置，則進行攝影機畫面之切換。 
假設目前攝影機拍攝畫面所定義之出入口區域之上下左右邊界為Texit, Bexit, Lexit與Rexit。
畫 面 中 的 前 景 物 體 Oi ， 其 位 置 特 徵 Fpos(Oi) 中 ， 記 錄
( )( it Os , )( it OYPos )。因此，我們可以利用物體之中心座標，與出入口區域之四個邊緣點座
標 exit B)、(Lexit, exit)、(Rexit, Texit)與(Rexit, Bexit)計算角度，分別以 tLT 、 tLB、 tRT 與 tRB表
示，並以 tmaxθ 與 tminθ 表示四個角度中最大與最小之值。如圖 7 所示， (時 +1
1 it+ 1 it+
idir Oi i max
θ θ θ θ
，該前景物體移動至( )( , )(
)( ，以角度符號 1+t ttOt i
圖 7. 判斷前景物體是否往出入口移動 
(Lexit, Texit) 
(Lexit, Bexit) (Rexit, Bexit)
(Rexit, Texit)
1+t
iO
t
iO
1+t
Oi
θ tminθ tmaxθ
 
本研究以物體區域之底部中心點，當作是該人員之腳部位置參考點。以此腳部位置與
),( 與 ),( ，則該物體的腳部位置訂為
ii OO TL ii OO BR ( )iii OOO BRL ),(5.0 +× 。當前景物體的
 10
之面積為 Areaovlap 。本實驗中必須精確率 (precision rate)
sys
ovlap
Area
Area 與召回率 (recall 
rate)
manArea
均 ，才會被視為正確。最後，針對正確偵 物體，經過與追
追蹤效果之實驗結果如表 1
視訊類別 前景物體數
ovlapArea 大於 85% 測的前景
蹤標的物比對後，利用人工觀看來評估系統對每個移動物體之追蹤效果。前景物體偵測與
與表 2 所示。 
表 1. 前景物體偵測校果 
 正確偵測數 正確率 
I 3531 3377 95.6% 
II 3962 96.1% 3806 
III 3664 3185 86.9% 
表  
視訊類別 偵測成功物體數 正確追蹤數 
2. 移動物體追蹤校果
正確率 
I 3377 3115 92.2% 
II 3806 92.5% 3522 
III 3185 2813 88.3% 
在評估畫面切換時機部分，假設以人工觀看時，判定在第 i 張畫面時發生遮蔽或離開
出入口，而利用本系統判定在第 k 時需切換畫 追蹤。 3≤− ik張畫面 面持續 若 ，則系統對此
情況之畫面切換時機判定視為正確，否則為錯誤，實驗結果如表
率 
3 所示。 
表 3. 畫面切換判定效果 
視訊類別 畫面應切換次數 正確切換次數 正確
I 34 31 91.2% 
II 95.7% 23 22 
III 16 14 87.5% 
總括來說，本研究適時地利用多攝影機的畫面切換，來進行多重物體之移動追蹤。不
管是針對畫面切換時機、前景物體偵測與追蹤效果，平均起來有 91.8% 與 90.8%的
正確率。 
本研究為了明確偵測並追蹤空間內的多重移動物體，利用多重攝影機在不同位置、不
同角度拍攝保全空間，可自動切換最清楚的拍攝畫面，以進行移動物體之持續追蹤。主要
分成三個部份，第一部份是在相同空間內，多移動物體有互相遮蔽的情形發生時，可利用
不同
、92.9%
五、結論 
攝影機的切換，取得最好的監控畫面以做追蹤；第二部份是被追蹤物在不同的相鄰空
間移動時，能夠接續追蹤；第三部份則是當被追蹤物在兩亮度差異明顯空間移動時，得以
順利持續追蹤。 
本系統利用背景相減法，將畫面影像與事先學習之背景模型做相減，以得到差異圖，
 12
[16]. W. E. L. Grimson (2000) Learning patterns of activity using real-time 
[17]. ection of 
[18]. on of visual activities and interactions by 
[19]. Anal., 
 
 
本研究計畫原本希望執行三年之持續研究，經審查後僅核可一年，我們還是利用有限
的時間與經費，由主持人與數位參與之研究生合作開發相關技術，茲將原計畫書之第一年
4 所示；與本研究計畫相關之成果發表，條列於表 5。 
[15]. Wang, L., T. N. Tan; H. H. Ning and W. M. Hu (2003) Silhouette analysis-based gait 
recognition for human identification. IEEE T. Pattern Anal., 25(12), 1505-1518. 
Stauffer, C. and 
tracking. IEEE T. Pattern Anal., 22(8), 747-757. 
Haritaoglu, I., R. Cutler, D. Harwood and L. S. Davis (2001) Backpack: det
people carrying objects using silhouettes. Comput. Vis. Image Und., 81(3), 385-397. 
Ivanov, Y. A. and A. F. Bobick (2000) Recogniti
stochastic parsing. IEEE T. Pattern Anal., 22(8), 852-872. 
Zhang, Z. (2004) Camera calibration with one-dimensional objects. IEEE T. Pattern 
26(7), 892-899. 
四、 計畫成果自評 
成果預估與實際達成狀況，如表
表 4. 計畫執行情形表 
計畫書中預計
完成工作項目 實際執行內容 達成率 學術或應用價值 
建立多攝影
機的座標校
正及色彩校
 利用亮度均等
機所拍畫面做強化 
 利用灰色校正紙進行多攝影機
 ，並未自行
70% 
 利用簡易校正色紙進
行不同攝影機之色彩
校正，對於亮度相異但
正模組 
化方法，將各攝影
畫面色彩之一致化 
假設座標校正已完成
開發 
穩定之拍攝環境，有實
務之應用價值。 
利用背景相
減方法，建構
前景物體偵
 擷取多張不
以相連元件偵測法找出並將
100%
 
背景
模型訓練，並用以進行
測模組 
以一段訓練用視訊，
必特別挑選的畫面，訓練背景模
型 
 以背景相減法進行前景像素之
偵測，並利用 opening 消除雜訊
後，
破碎元件合併成前景物體 
利用不特別挑選之多
張畫面影像，進行
前景物體之偵測。既實
用且效果佳，有其應用
價值。 
利用多攝影
機所拍畫面
影像，自動選
擇分辨率較
佳的畫面 
 抽取前景物體穩定及移動特
徵，進行多物體之追蹤 
處理各種追蹤狀況，包括新物體
進入、追蹤物離開、多物體重疊
多物體重疊或追蹤目標移至出
入口時，能自動切換畫面 
100%
 多攝影機應用在大範
圍保全空間，或者相鄰
空間，常因監控標的發 
 
生重疊或者離開拍攝
範圍，可自動判定並切
換畫面，有其應用價
值。 
大空間多攝
影機畫面的 動切 100%
  在大空間之多重移動物體，一旦
發生重疊狀況，畫面會自
多攝影機應用在大範
圍保全空間，可自動判
 14
供推廣之研發成果資料表 
□ 可申請專利  ■ 可技術移轉                                      日期：95 年 10 月 25 日 
國科會補助計畫 
計畫名稱：以多攝影機在變化環境下進行多重移動人員之偵測、追
蹤與行為分析 
計畫主持人：大葉大學 資訊管理學系 曾逸鴻 助理教授 
計畫編號：NSC 96-2221-E-212 -036 -     學門領域：圖形辨識 
可
技術/創作名稱 明暗變化夜間環境下之多重移動人員追蹤 
發明人/創作人 曾逸鴻、林畇鈺、劉威志 
中文： 
視覺是最重要的感知系統，人類也最相信視覺所提供的訊息。
為建構以電腦視覺技術為基礎之智慧型環境，本技術著重在多重室
內空間的安全監控。為了明確偵測並追蹤空間內的多移動物體，可
利用多重攝影機在不同位置、不同角度拍攝同一保全空間，即時做
到同步監控追蹤，並自動切換清楚的拍攝畫面，記錄各物體的移動
狀況。本技術主要分成三個部份，第一部份是在相同空間內，多移
動物體有互相遮蔽的情形發生時，可利用不同攝影機的切換，取得
最好的監控畫面以做追蹤；第二部份是被追蹤物在不同的相鄰空間
移動時，能夠接續追蹤；第三部份則是當被追蹤物在兩亮度差異明
顯空間移動時，得以順利持續追蹤。 
技術說明 英文： Of all the sense organs, the images obtained by the eyes are the 
most reliable and substantial for humans. Computer-vision techniques
play a key role in the construction of a vision-based intelligent 
environment. To precisely detect and track multiple moving objects, 
this research first captures the same secure space by adopting multiple
cameras in different locations and angles. Then, moving statuses are 
recorded by switching video camera to synchronously monitoring 
doubtful objects. This technique is composed of three main parts. 
Firstly, video cameras are switched to continually track moving objects 
when an occlusion of multiple objects occurs. Secondary, a target 
moving object in different neighboring spaces can be continually
tracked. Thirdly, even two neighboring spaces with different brightness 
the target object can also be successfully tracked uninterruptedly.  
可利用之產業 
及 
可開發之產品 
可利用之產業：數位監控相關產業 
可開發之商品：無人化保全系統、居家入侵監控系統、… 
