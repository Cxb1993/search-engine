 1 
 
中文摘要 
 
隨著固態硬碟的快速發展，傳統的硬碟裝置在很多的應用上已經被固
態硬碟所取代。因為固態硬碟是由 NAND 型快閃記憶體所組成，固
態硬碟對大量的寫入也會造成系統效能的影響。大量的資料寫入會造
成資源回收機制的經常啟動去回收快閃記憶體內的可用空間，這是由
於快閃記憶體的寫入特性所造成的。在這個計畫裡，我們要提出一個
針對固態硬碟所設計的消除重複資料存取架構，這個架構的目的是要
消除重複資料所造成的空間浪費，根據我們實驗的結果，這個架構可
以有效率的減少重複資料所造成的寫入，同時，這個架構所造成的效
能影響也相當合理。 
關鍵字：固態硬碟、快閃記憶體、消除重複資料 
 
A Data De-duplication Access Framework
for Solid State Drives
Chin-Hsien Wu and Hau-Shan Wu
Department of Electronic Engineering
National Taiwan University of Science and Technology, Taipei, Taiwan
chwu@mail.ntust.edu.tw and m9702116@mail.ntust.edu.tw
Abstract—With the rapid development of SSDs (Solid State
Drives), traditional hard drives in many applications have been
replaced by SSDs. Since SSDs consist of NAND flash memory,
the main challenge to SSDs is that NAND flash memory is highly
sensitive to write requests. A lot of write requests will cause
garbage collection to reclaim free space due to the ”out-place
update” characteristic of flash memory. In the project, we will
propose a data de-duplication access framework for SSDs. The
objective is to eliminate duplicate data as much as possible and
reduce space consumption. According to the experimental results,
the proposed framework can efficiently identify duplicate data
and decrease a lot of data written, and at the same time, the
overhead is also reasonable.
I. INTRODUCTION
At present, most applications such as consumer electronics
and embedded systems have adopted NAND flash memory
as their main storage media. NAND flash memory has char-
acteristics such as non-volatile, shock-resistant, and power-
economic. Since the capacity of NAND flash-memory chips
grows rapidly, SSDs (Solid State Drives) have been popular
and are composed of NAND flash memory. For example, OCZ
Storage has released huge-capacity NAND flash-based SSDs
(e.g., 1TB SSD or above) in the markets [1]. Until now, some
desktops, notebooks, embedded systems, and servers have also
adopted SSDs devices. We will refer to NAND flash memory
as flash memory hereafter.
The management of flash memory as a storage system is
significantly different from those based on main memory and
disks. The unit of an erase operation is a block and the unit
of a read/write operation is a page. Since flash memory has
the characteristic of out-place update, the corresponding block
should be erased before one residing page will be updated.
When a lot of data are written or updated to flash memory,
a lot of pages might be invalidated and should be erased.
Therefore, free space on flash memory could become low after
a number of writes, and activities (i.e., garbage collection)
in the recycling of available space on flash memory must
be done from time to time. However, garbage collection is
considered as overheads in flash-memory management (caused
by live data copying). Traditional hard disk drives have been
gradually replaced by SSDs on personal computers, embedded
systems, and even server systems. Since SSDs consist of flash
memory, these systems might cause a lot of write requests and
will lead to performance degradation and reliable problems for
SSDs. If the duplicate data can be found out before writing,
a lot of write requests to SSDs can be decreased and system
performance will be improved. This motivates this research.
In the project, we will propose a data de-duplication access
framework for SSDs. The objective is to decrease a lot of write
requests by eliminating duplicate data as much as possible.
The rest of this thesis is organized as follows: Section II
is the related work for various data de-duplication algorithms.
Section III is the proposed data de-duplication access frame-
work. Section IV shows the experimental results. Section V is
the conclusion.
II. RELATED WORK
A. Duplicate Data
To find duplicate data effectively, we conduct a series of
experiments to observe the characteristics of duplicate data.
According to the experimental results, duplicate data have two
characteristics: application-based locality and file-name local-
ity. Application-based locality means that a lot of duplicate
data exist in the same directory because a large proportion
of duplicate data are generated by the same application. File-
name locality means that a lot of duplicate data tend to have
the same or similar file name (e.g., a file could be copied to
other directory with the same or similar file name).
There are two kinds of duplicate data in the storage systems
[3]. One is called near-duplicate data and another one is called
full-duplicate data. Whenever a part of a file is modified, a
large part of existing data may be unmodified and will be re-
written since upper applications (e.g., Word, Vi and Emacs)
could not identify the unmodified data. As a result, when a file
is updated, the unmodified data is called near-duplicate data.
On the other hand, when a file is replicated, a new file that
has the same content will be created. The content of the new
file will be called full-duplicate data. In a file system, near-
duplicate data and full-duplicate data always exist and waste
storage space. For improving the performance of SSDs, the
duplicate data should be identified and not written such that
the activities of garbage collection in SSDs will be decreased
and the lifetime of SSDS can be increased.
B. Data De-Duplication Algorithm
The objective of the data de-duplication algorithm is to
identify the duplicate data as much as possible. The algorithm
usually cuts data stream into fixed or variable size chunks.
Each chunk will have an identifier by a fingerprint hash
3
located. In this example, FileD(0,4096) → FileD log(0,2048)
→ FileD(4097,6144) represents that the latest version data of
FileD.tmp at offset 4097 to 6145 is located in the FileD log
at offset 0 to 2048.
B. Eliminate Full-duplicate Data
According to the application-based locality, a large portion
of duplicate data might be generated by the same application.
According to the file-name locality, those files that have the
similar file name might have a large portion of duplicate data.
Therefore, it is very efficient to eliminate duplicate data based
on the localities. We will use an example to explain how
to eliminate duplicate data by the file-name locality. Assume
that FileD will be created and written. In the meta table, an
entry should be generated for FileD. Its file name, name key,
and file-based fingerprint should be created accordingly. The
main process is to find out those files whose name keys are
similar with FileD and then compare with those files by their
file-based fingerprints. If one file (e.g., FileA) has the same
fingerprint with FileD, it means that FileD will not be written
to SSDs and the physical location of the entry in the meta
table for FileD should keep the information about FileA.
C. Eliminate Near-duplicate Data
In this section, the de-duplication algorithm for near-
duplicate data will be described. Section III-C1 presents the
chunk fingerprint table that we use to reduce checking time of
fingerprinting. Section III-C2 discusses the log file accessing
scheme that we use to solve the data shifting problem. Since
invalid data could occur in the log file, a merge operation will
reclaim the invalid data in Section III-C4.
1) Chunk Fingerprint Table: If a file has been updated
recently, it might be updated soon. In order to quickly identify
near-duplicate data, related fingerprints for the file should
be recorded. This is because the fingerprint can help the
identification of the near-duplicate data. The chunk fingerprint
table will maintain a file’s fingerprint when the file is updated.
Each entry in the chunk fingerprint table will contain a file
name and a 160-bit (SHA-1) fingerprint for each chunk of the
file.
2) Log File: A log file is used to solve the data shifting
problem under the static chunking. As shown in Fig. 2.(2),
a file may be modified due to data insertion. When the file
is closed, the space from the modified area to the last chunk
might be written to SSDs. However, if the modified area can
be located, as shown in Fig. 2.(3), only the modified area is
written to the log file and the corresponding physical location
in the meta table should add the new mapping. As shown in
Fig. 2.(4), it can locates where the valid area is in the original
file and where the modified area is in the log file. The physical
location format has been described in Section III-A. Since
only the modified area is written, unnecessary (redundant) data
written can be avoided. In the following subsection, we will
present how to efficiently identify the modified area when a
file is updated.
Fig. 2. Log file: an example of data insertion.
3) Identification of Near-Duplicate Data: In the section,
we will propose an identification of near-duplicate data under
fixed-sized chunks. Assume that FileD is the old version file
and FileD’ is the new version file after FileD is updated.
Fig. 3. Identification of near-duplicate data
Assume that the modified area consists of two parts such as
Fig. 3, the identification will execute forward order checking
and backward order checking. Forward order checking means
that each chunk in FileD is compared with each chunk in
FileD’ by their fingerprints in a forward sequential order from
the beginning. Backward order checking has the similar mean-
ing except it is executed in a backward sequential order from
the ending. Since FileD and FileD’ might have different file
length, forward order checking and backward order checking
can locate different starting offsets and ending offsets for those
different parts in the modified area. Note that forward order
checking and backward order checking will still execute until
all modified areas are found out.
After the modified area is identified and written, the
corresponding physical location is also updated. As shown
in Fig. 4, since the modified area consists of two parts,
FileD log(0,2048) and FileD log(2049,4097) denote new data
mapping and will be added in the corresponding physical
location.
5
Fig. 7. Average Latency
of duplicate data such that the average throughput was not
good. However, when the random write size was increased
(e.g., > 2048 bytes), the average throughput will be better
than that without the access framework. This was because a
large amount of duplicate data can be identified for the large
write size. As a result, the access framework can benefit those
applications than tend to have a large amount of data written.
B. Latency
The experiment measured the average latency. The average
latency means that how long a write request can be finished
and also represents an overhead for the access framework. The
result is shown in Fig. 7. The x-axis represents the random
write size for each repetition and the y-axis represent the
average latency. As described in the previous section, high
throughput also reflected short latency. This was because the
large write size can provide a better opportunity to identify
a large amount of duplicate data such that short latency can
be achieved. Overall, a file system with the access framework
can have short latency.
V. CONCLUSION
In the project, we propose a data de-duplication access
framework for SSDs. The framework can eliminate duplicate
data as much as possible such that the system performance can
be improved and the lifetime of SSDs can be increased. There
are four parts: (1) Meta table (2) Eliminate full-duplicate data
(3) Eliminate near-duplicate data, and (4) Reference count,
in the access framework. All required meta data for the data
de-duplication algorithm are stored in the meta table. Full-
duplicate and near-duplicate data can be identified efficiently
by the application-based locality and the file-name locality. In
particular, the concept of reference count is used to maintain
the sharing relationship in case the process of deleting files
is incorrect. According to the experimental results, the access
framework is efficient to eliminate duplicate data such that the
average throughput and latency can be improved significantly.
At the same time, the overhead caused by the fingerprint
checking is also reasonable.
Future research should involve further examination of the
characteristics of duplicate data, especially when different
applications are executed. With a more considered approach
incorporating application designs and access patterns, a real
prototype will be designed and manufactured. The real proto-
type can provide a fast and efficient SSDs.
REFERENCES
[1] Copyright Gizmag, ”Colossus: OCZ’s 1TB solid state drive expected in
stores this month” , Paul Ridden, http://www.gizmag.com/ocz-colossus-
1tb-ssd/12399/, accessed May. 20. 2010.
[2] Microsoft, ”Single Instance Storage in Microsoft Windows Storage
Server 2003 R2”, Technical White Paper, Published May 2006.
[3] Andre Brinkmann, ”Data Deduplication”, Theoretical Aspects of Storage
Systems, Autumn 2009.
[4] Deepak R. Bobbarjung and Suresh Jagannathan and Cezary Dubnicki,
”Improving Duplicate Elimination in Storage Systems”, ACM Transac-
tions on Storage, vol.2, issue.4, pp.424-448, 2006.
[5] Kubiatowicz, J. et al, ”Oceanstore: An Architecture for Global Store Per-
sistent Storage”, In Proceedings of the Ninth International Conference
on Architectural Support for Programming Languages and Operating
Systems, 2000.
[6] Copyright Estorian,Inc., ”Technical and installation information on
io profile”, Estorian, http://www.estorian.com/io profile.php , accessed
May.25.2010.
7
出國心得報告 
 
本人利用這次國科會的補助出席了兩個會議，分別是 IEEE 
International Conference on Embedded and Real-Time Computing Systems 
and Applications (RTCSA 2010)跟 IEEE International Symposium on 
Consumer Electronics (ISCE 2011)，RTCSA 2010是在中國澳門舉行，時
間是8/23~8/25，RTCSA是一個著名的國際會議，主要討論的議題為即時
系統與嵌入式系統相關的議題；ISCE 2011是在新加坡舉行，時間是
6/14~6/17，ISCA是一個著名的國際會議，主要討論的議題為消費性電
子產品相關的研究。參加RTCSA 2010的目的是要去擔任session chair, 
本人所主持的場次為2010/8/25的最後一場，從下午3:45到5:45，該session
的議題為Architecture and Practice II，藉由擔任session chair的工作，能提
升國際參與度與社交能力。參加ISCE 2011主要是去發表論文，報告的
場次為6/16下午1:45到3點，本篇論文是由本人所指導的博士生(黃凱聖)
所報告，他也是該篇論文的作者之一，本人並從旁協助指導發表國際論
文等注意事項。從RTCSA 2010及 ISCE 2011可以看出在Embedded 
Software及Ubiquitous Computing的重要性，也了解到目前最新的研究發
展跟結果，未來在雲端運算勢必會整合嵌入式系統及消費性電子產品等
相關議題，在會議期間，也與各國學者跟臺灣去的學者專家互相討論跟
切磋。 
最後期望未來能繼續獲得國科會的補助而有機會參與國際會議，也
感謝國科會的協助跟幫忙。 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：吳晉賢 計畫編號：99-2221-E-011-062- 
計畫名稱：針對大容量固態硬碟的前瞻性研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 5 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 1 1 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
