these approaches have only demonstrated the 
applicability to objects with simple and distinctive 
shapes, and therefore, cannot be applied to more 
complex shapes like shapes in a MPEG-7 data set.  
The most common approaches for overcoming 
skeleton instability are based on skeleton pruning. 
Pruning can either be performed implicitly as a 
post processing step or integrated in the step of 
skeletonization computation. In general, the 
skeletonization algorithms can broadly be classified 
into four types: (1) the first type is thinning 
algorithms, such as those with shape thinning and 
the wave front/grassfire transform. These 
algorithms iteratively remove border points, or 
move to the inner parts of an object in determining 
an object’s skeleton; (2) the second type is the 
category of discrete domain algorithms based on 
the Voronoi diagram. These methods search the 
locus of centers of the maximal disks contained in 
the polygons with vertices sampled from the 
boundary; (3) the third type of algorithms is to 
detect ridges in a distance map of boundary points. 
Approaches based on distance maps usually ensure 
accurate localization but does not guarantee that the 
skeleton can connect completely; (4) the fourth 
type of algorithms is based on mathematical 
morphology. Usually, these methods can localize 
the accurate skeleton, but may not guarantee the 
connectivity of the skeleton.   
In this paper, we proposed a method to 
integrate the contour-based approaches with 
skeleton-based approaches for object representation. 
The contour-based and skeleton-based approaches 
are based on the proposed two consecutive 
primitive edges method and the discrete curve 
evolution method respectively. To overcome 
skeleton instability based on skeleton pruning, the 
proposed skeleton pruning approaches can prune 
the redundant skeleton branches based on the 
contour estimation and pre-selection of the implicit 
skeleton branches. The remainder of this paper is 
organized as follows. Section 2 describes the 
proposed skeleton growing with contour 
information. Section 3 presents the proposed 
contour representation based on two consecutive 
primitive edges method. Section 4 presents the 
similarity measurement of object representation. 
Some experimental tests that illustrate the 
effectiveness of the proposed object retrieval are 
shown in Section 5. Finally, conclusions are drawn 
in Section 6. 
2.  Skeleton Growing with Contour 
Information  
2.1. The Proposed Contour Sampling Method using 
Discrete Curve Evolution 
GHT [4] was initially proposed to represent a 
planar set D with arbitrary boundary using a 
so-called R-table [4]. As an example shown in Fig. 
1, the boundary of the planar set D can be 
described by geometric relationship between the 
centroid XR of D and the boundary point X’s. 
According to the R-table in GHT to represent the 
boundary in question can be constructed as:  
).,(),...,,(),,(
),,(),...,,(),,(
),,(),...,,(),,(
),,(),...,,(),,(
332211
3
3
3
3
2
3
2
3
1
3
1
33
1
2
1
2
2
2
2
2
1
2
1
22
1
1
1
1
2
1
2
1
1
1
1
11
n
k
n
kkkkkk
nn
nn
nn
rrr
rrr
rrr
rrr
αααφ
αααφ
αααφ
αααφ
M
    (1) 
where iφ  is the common slope for the tangent line 
passing through the boundary points njx ji ,...,1, = . 
However, the information of R-table in GHT 
cannot link information of boundary into the planar 
set D in an image, and it is also difficult to express 
which boundary is a significant visual part.  
    The characters of significant visual part in a 
contour have be proposed in literature [5]. We can 
summarize the observation into four rules:  
(1) These visual parts are defined to be “convex” or 
on this reason, the consecutive primitive edge is 
proposed to describe the boundary of D. The 
concept of consecutive primitive edge iφ  is as 
follows: 
niee iii ,...,1|,| 1 =−= −φ          (3) 
where ei and ei-1 denote the consecutive primitive 
edges respectively. The detected of iφ  can be 
mapped to 7 types of visual parts, as shown in 
Fig.2. According to the key property of discrete 
curve evolution, a relevance measure k is given by   
                
)1()(
)1()()1,(
1),( ++
++
+ = jeje
jejejeje
jj eek ll
llβ
      (4)  
where ej and ej+1 is a pair of consecutive primitive 
edges, ),( 1+jj eeβ  is the turn angle at the common 
vertex of primitive edge ej and ej+1, and l  is the 
length function normalized with respect to total 
length of the polygonal curve. The main property 
of this relevance measure is that the higher the 
value of k(ej, ej+1) the larger the contribution to the 
shape of the curve of arc 1+∪ jj ee . Based on 
satisfying the rule (1-3) mentioned above, the 
turning point of visual part may appear as a (red) 
circle in Fig. 2 using the relevance measure k.  
The next problem is to find the significant 
visual part which hides in the boundary of an object. 
Mapping the consecutive primitive edge to a visual 
part is to encode an object with visual parts block 
by block along the boundary pixels. Hence, two 
given object blocks from along the edge pixel can 
be encoded and indicate which visual part is 
mapped, and the front of visual part ej+1 and the 
rear of visual part ej in Eq. (3) are overlapping. 
Without loss of generality, the histogram of 
consecutive primitive edge is used to describe the 
boundary of objects in this paper. Let 
7,...,1, =iCPEi  denote the type of consecutive 
primitive edges and Ni is the number of CPEi in Fig. 
2. The boundary of object BO will be described by 
             ∑
≤≤
=
71 k
kNBO           (5) 
For the CPE, the local significance of a boundary 
point is usually only considered and the global 
information of shape in an object is discarded. 
Assume that the arrangement of Nk in descending 
order ( )... 7321 NNNN ≤≤≤≤  associates the 
same ordering to the CPEis  
       
721 ,..., CPECPECPE ≤≤≤            (6) 
A ratio is decided to reserve how much of the 
visual parts can represent the object as the 
significant visual parts and the remainder will be 
ignored. The ratio ρ is defined by  
         ∑
≤≤
∑
≤≤≤
71
1
j
jN
pi
iN
ρ              (7) 
where p (p<7) denotes preceding sequences in eq. 
(7). It is important to determine a good stop 
criterion of the ratio selected. However, the ratio 
ρ  selected usually appears in a variety of 
application-dependent cases. According to the 
experimental result, It can preserve the perceptual 
appearance sufficiently for object recognition when 
the ratio ρ  is assigned as 0.1.  
A skeleton similarity measure is useful for 
object-based retrieval in image databases should be 
according to our perception. This basic property 
leads to the following requirements: 
(1) A skeleton similarity measure shall permit 
recognition of perceptually similar objects that 
are not mathematically identical. 
(2) It shall preserve significant visual parts of 
objects. 
(3) It shall not depend on scale, orientation, or 
position of objects. 
(4) A skeleton similarity measure is universal, in 
the sense that it allows us to identify or distinguish 
objects of arbitrary skeleton, i.e. no restrictions on 
 
Fig. 5. 4 skeleton point s is grown using the turning 
point ai. 
Letθ  denote an included angle between the line 
ax+by+c=0 and dx+ey+f =0.  That is  
21 θθθ −=                (12) 
According to the tangent function, it can be found 
as 
22
22
21
21
21
tantan1
tantan
tantan1
tantan
)tan(tan
θθ
θθ
θθ
θθ
θθθ
−
+=
+
−=
−=
               (13) 
Let 2tan
θ=x , it will be computed as  
)(
)(2)(
2tan aebd
aebdbeadx −
−++−== θ           (14) 
According to the 21
θφθθ += , it is simple to prove  
2
tan1tan1
2
tan1tan
21 )tan(tan θθ
θθθφ θθ +
−=−=       (15) 
The straight line L1 is found which connected the 
turning point and skeleton point as  
)(tan)( 11 xxyy −=− φθ              (16) 
The straight line L1 should intersect another line L2 
in the object. Let the L2 define as  
          gx+hy+i=0      (17) 
Combining the equations (16) and (17), it is 
assumed that the homogeneous system has a 
nontrivial solution. The nontrivial solution of 
system should be found by performing of 
Guass-Jordan reduction procedure on the 
augmented matrix [M|0]. The result is  
⎥⎦
⎤⎢⎣
⎡
0
0
|
|
1
0
0
1
2
1
k
k
               (18) 
where ki,i=1,2 are the ratios of x and y. Based on 
the reduction results, the values of x2 and y2  has 
the intersect point between straight line L1 and L2, 
and can be computed as 
                             
),(),(
2
2
2
11
2
2
2
2
1
1
1
22
kk
k
kk
kyx
++++
= .     (19)        
The skeleton point should be found as 
       ),( 2
21
2
21 yyxxs ++=              (20) 
Based on the skeleton point sets ,ks mnk +=  is 
found from the boundary points set ℜ  of the 
object. The skeleton arc comes into being 
according to the following algorithm.   
Algorithm 1: Proposed the skeleton arc of object 
comes into being. 
Input: Two boundary point sets {Ti} and 
mjniPT ji ,...,1,,...,1)},{}{{ ==∪=ℜ  
Output: A skeleton arc of the object comes into 
being.  
Method:  
1. Let S denote the collection of all the skeleton 
point sets sk, and empty initially. 
2. Let E denote the completed skeleton arc of an 
object and empty initially. 
3. while )( NULL≠ℜ  
 Find a skeleton point using a boundary point in 
ℜ  by the equation (20). 
 Insert the skeleton point into S and delete the 
skeleton point fromℜ . 
4. Select a skeleton point from S to E. 
5. While )( NULLS ≠  
 5.1. Find a skeleton point p from S, and its 
minimum distance is ).(min qpd , where q is a  
pj are ith feature and the corresponding number of 
TCPE in Fig. 6, respectively. The total number of 
TCPE in an object can be computed as  
                              
.
16
1
,∑=
=
i
jipζ              (23) 
Let }16,...,1},,{{ == kpxX ki and 
}16,...,1},{{ , == kqyY kj be the feature vectors of 
TCPE. Then the distance between X and Y based on 
the concept of QBIC [6] can be computed as  
              
ji
i j
ji
j
j
i i
TCPD qpaqpyxD ∑=
∑
=
∑
=
∑
=
−+= 16
1
16
1
,
16
1
216
1
22 2),(    (24) 
where aij is the perceptual coefficient between 
feature values pk and qk. The role of each TCPE in 
any object is different from the sense of human 
vision. The fewer numbers of TCPE is more 
important than many numbers of TCPE in an object.  
Thus, the perceptual coefficient aij can be defined 
as   
                             
∑
=
∑
=
+
+
= 16
1
16
1
11
11
,
||
||
i j jqip
jqip
jia              (25) 
where the values pi and qj are assumed as non-zero, 
otherwise the corresponding value of ip/1  or 
jq/1  is assigned as zero. 
 The feature vector of skeleton arcs can 
further be represented as 
},...,1},,,{{ 1 niss iii == + θβ shown as Fig.6, where 
si and si+1 are the consecutive of skeleton arcs and 
iθ  denotes the included angle between the 
consecutive skeleton arcs si and si+1. A weight of 
skeleton arcs in an object can be found as 
                              
∑
=
= n
i
sa
i
sa WW
1
             (26) 
and the saiW  is defined as  
       
1++
=
ii
isa
i ss
W
θ
               (27) 
Let },...,1},,,{{ 1 nissX
a
i
a
i
a
i == + θ and 
),...,1},,,{{ 1 mjssY
b
j
b
j
b
j == + θ be the feature 
vectors of skeleton arcs. Then the distance between 
X and Y is computed as 
       
|| saY
sa
X
sa WWD −=             (28) 
: Boundary of object
:Pruning point decision
:Skeleton arcs
:Skeleton Branch
e1
e2
b1 b2
b3
b4
b5 b6
s1
s2
s3
s4
s5
s6
s7e3
e4
e5
e6
 
Fig. 6. An example of representing an object by the 
boundary of object, skeleton arcs, and a skeleton 
branch. 
 
The feature vector of a skeleton branch can 
further be represented as 
},...,1,,...,1,},,,{{ nkmjibee kjii ===φ shown as 
Fig. 6, where bk denotes the skeleton branch, and ei 
and ej are the boundary edges of object, which is 
connecting to the skeleton branch bk. A weight of a 
skeleton branch in an object can be found as 
       
∑
=
= n
i
sb
i
sb WW
1
           (29) 
and the sbiW is defined as  
accuracy measured by recall and precision is 
computed as following. Recall measures the ability 
of the system to retrieval all the images that are 
relevant and defined as  
relevancesall
retrievedcorrectlylevancescall ReRe =  
. 
Precision measures the ability of the system to 
retrieve only images that are relevant and can be 
computed by 
                    
retrievedall
retrievedcorrectlyrelevancesecision =Pr . 
Recall and precision require a ground truth to 
assess the relevance of images for a set of 
significant queries. 
The performance of the proposed image retrieval 
method is evaluated in terms of retrieval accuracy. 
The average precision and recall curves are plotted 
in Figs. 7(a) and 7(b), respectively. It can be seen 
that the proposed method achieves good results in 
terms of retrieval accuracy compared with Torsello 
and Hancock’s method [7]. 
   
10 20 30 40 50 60 70 80 90 100
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Number of retrievals
Pr
ec
is
io
n
 
 
Proposed method using skeleton and contour features
Proposed method using  contour features
Proposed method using  skeleton features
Torsello and Hancock's  Method
 
(a) 
 
 
 
 
 
0 20 40 60 80 100
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Number of retrievals
R
ec
al
l
 
 Proposed method using skeleton and contour features
Proposed method using  contour features
Proposed method using  skeleton features
Torsello and Hancock Method
 
                 (b) 
Fig.7. Average precision and recall versus number 
of retrieved image: (a) Precision; (b) Recall. 
 
5. Conclusion 
   In this paper we have presented the recognition 
of shape-matching for object retrieval in image 
databases using skeleton and contour by discrete 
curve evaluation and two consecutive primitive 
edges. Object segmentation and recognition is the 
primary step of computer vision to achieve image 
retrieval of high-level image analysis. 
Contour-based and skeleton-based representations 
are important for object recognition in different 
areas. In this paper, we proposed a novel method to 
integrate the contour-based approaches with 
skeleton-based approaches for object representation. 
The contour-based and skeleton-based 
representations are based on the proposed 
two-consecutive primitive edges method and 
discrete curve evolution method respectively. The 
experimental results demonstrate that the proposed 
method is superior to Torsello and Hancock’s 
method in terms of retrieval accuracy.       
References 
1. W. H. Tsai. And S. S. Yu, 1985, “Attributed 
string matching with merging for shape 
  
 
  
Abstract—This paper presents a semantic space segmentation 
method for content-based image retrieval using the SVM 
decision boundary and principal axis analysis. Each object in an 
image has its activity scope, which conforms to semantic concept 
invariance. To find the maximum and fair activity scope for 
every object in an image that is best to discriminate the hidden 
semantic differences. A special property of SVM is known as 
maximum margin classifier, which simultaneously minimizes the 
empirical classification error and maximize the geometric 
margin. In this paper, the hidden semantic concepts based on the 
low-level features of region (object) will be found using the 
Expectation-Maximization (EM) technique. The activity scope 
of each object and support vector will be decided by the SVM 
decision boundary and principal axis analysis which is used to 
construct a hyper-plane projection line with minimum inertia. 
Furthermore, a similarity measure, by integrating the high-level 
semantic distance and low-level features, is used to retrieve 
images. The proposed semantic learning scheme provides a way 
to bridge the gap between the high-level semantic concept and 
low-level features for content-based image retrieval. 
Experimental results show that the performance of the proposed 
method is excellent when compared with that of other methods. 
 
Index Terms—SVM decision boundary; Content-based image 
retrieval; Principal axis analysis; Semantic learning.  
 
I. INTRODUCTION 
As the Internet advances, the demands for storing 
multimedia information (such as text, image, audio, and video) 
have increased. With such databases comes the need for a 
richer set of search facilities that include keywords, sounds, 
examples, shape, color, texture, spatial structure and motion. 
Traditionally, textual features such as filenames, captions and 
keywords have been used to annotate and retrieve images. As 
they are applied to a large database, the use of keywords 
becomes not only cumbersome but also inadequate to 
represent image content. Many content-based image retrieval 
systems have been proposed in the literature [1-2]. Accessing 
images based on their content is widely used as indexing 
features for image retrieval. Most of the past research was 
devoted to the development of an efficient image retrieval 
system based on the low-level feature. However, the semantic 
properties of the underlying data are not correctly captured in 
general. Deriving high-level semantic concepts from 
 
Tian-Luu Wu  is with the Electronic Engineering, National Kinmen 
Institute of Technology, Taiwan, R.O.C. (corresponding author to provide 
phone: +886-82-313559; fax: +886-82-313304; e-mail:wtlu@kmit.edu.tw). 
 
low-level visual features is typically based on one of two 
approaches as: (1) learning from interactive user relevant 
feedback and (2) learning from templates without run-time 
user interaction. In the relevance feedback approach [3], one 
may formulate learning of user perception as an optimization 
problem to estimate parameters of the distance metric to 
minimize the sum of distances of relevant examples from the 
query in the low-level feature space based on user feedback. 
However, since the set of semantically similar objects might 
be classified into several clusters in the low-level feature 
space, querying an object in one cluster would not be able to 
retrieve semantically similar objects in other clusters by 
estimating parameters of the distance metric.  
Learning from templates, on the other hand, attempt to 
discover hidden semantics of images based on similarity of 
low-level visual features [4]. Most image recognition 
methods focus on certain semantic concepts whose features 
have high discriminability for particular user-defined classes. 
One problem with the learning from templates approach is 
that the templates were being generated semi-automatically in 
general. The process to generate meaningful templates for a 
very large image database is essential but overlooked.  
Two thing are important to address the problem of image 
interpretation to generate semantic templates which conform 
to the viewpoint of human vision: (1) some objects in an 
image are semantically relevant with respect to a query image, 
the other non-relevant objects can reduce the accuracy of the 
captured hidden semantic concepts based on the low-level 
features of a region; (2) besides color, shape and texture, 
spatial distribution is useful for semantic learning and 
semantic classification. In this paper, we focus on the problem 
of semantic space segmentation to improve the performance 
of content-based image retrieval using support vector 
machine (SVM) decision boundary and principal axis 
analysis. In our approach, the query and all the images in 
database are segmented into multiple disjoint regions, each of 
them are represented by three types of low-level features (i.e. 
color, texture, and texture). First, we proposed a region-based 
retrieval method to discover hidden semantic regions using 
the Expectation-Maximization (EM) technique, which are 
called objects in this paper. The activity scope of hidden 
semantic objects will be found using the support vector 
machine and the support vector will be decided by the 
proposed principal axis analysis. Furthermore, a similarity 
measure, by integrating the high-level semantic distance and 
low-level features (color, shape, and texture), is used to 
Semantic Space Segmentation for 
Content-Based Image Retrieval using 
 SVM Decision Boundary and  
Principal Axis Analysis 
Tian-Luu Wu  
  
 
],,,...,,,,,,[ 332313654321 +++= m
iR
m
iR
m
iRiRiRiRiRiRiRi
R PPPPPPPPPP        (1) 
where 
),(),(),( 332211 QQPIIPYYP iR
iR
iR
iR
iR
iR
−=−=−= ααα  
),(),(),( 1,361,251,14 jRiRiRjRiRiRjRiRiR
QQPIIPYYP −=−=−= ααα  
),(),(),( 2,392,282,17 jRiRiRjRiRiRjRiRiR
QQPIIPYYP −=−=−= ααα  
M  
),(),(),(
,
333,223
,
113 mjRiRmiR
mjRiRmiRmj
RiRmiR
QQPIIPYYP −=−=−= +++ ααα  
and 
,21,αα and 3α are the weighting factors of color and set 
to be 0.4, 0.3, and 0.3, respectively in this study. ,, IY  and 
Q  denote the mean color of whole regions in an image.  
The research for the importance of primitives in an image is 
belonging to Gaussian distribution domain [9]. Every region 
is given a weighting to reveal the dominance of a region using 
the primitive value of color, which is called weighting of 
dominant region and defined as follows: 
                        
vS
iRVP
i eRW
−
−= 1                            (2) 
where sv denotes the covariance of primitive value of color in 
an image, and iRVP is a  primitive value of region Ri from (1), 
which is defined by 
                              .
331
∑
+≤≤
=
mk
K
iRi
R PVP                       (3) 
The RWi indicates the weighting of dominant region Ri, which 
is obtained using the primitive difference from the region Ri 
and its neighboring regions. An image is segmented into n’s 
non-overlapping regions, that is niRi ,...,1, = . The 
arrangement of RWs in ascending order 
( nRWIRWIRWI ≥≥≥ L21 ), associates the same ordering 
to the region Ris  
                 nRRRR ≥≥≥≥ L321                        (4) 
where R1 is called the most dominant region and Rn is the least 
dominant region. A ratio is decided to reserve how much of 
the regions can capture the semantics of an image and the 
remainder will be ignored. The radio ρ is defined by 
                          
∑
≤≤
∑
≤≤
=
nj
jRW
pi
iRW
1
1ρ                                   (5) 
where n denotes the number of regions and p (p<n) denotes 
preceding sequences in eq. (4).  
 
B. Finding Support Vectors using Principal Axis Analysis 
SVM performs the semantic space segmentation for two 
objects by determining the separating hyper-plane with 
maximum distance to the closest points training set. These 
support vectors are decided by the principal axis analysis in 
this paper, which is used to construct a hyper-plane projection 
line with minimum inertia. The projection scores, which are 
obtained by projecting the vectors in two objects on the line, 
are used as the approximations for filtering. Given a central 
vector x of an object, we project a set of vectors in the other 
object and a support vector can be found based on the 
projection score of x. The algorithm of principal axis analysis 
has been proved to achieve good results in terms of retrieval 
accuracy [10]. 
To find the decision function of SVM, the principal axis 
must be determined. The principal axis can be conveniently 
represented in terms of moments. In the case of 2-dimensional 
feature space S2, the principal axis L can be represented as 
βα coscos
yx
=                                     (6) 
Where α  and β are the angles between the principal axis L 
and the x and y, respectively. αCos  and βcos  are the two 
direction numbers of L and satisfy the following relationship: 
                        1coscos 22 =+ βα                            (7) 
Let )cos,(cos βα=zr be a vector aligned with L. The 
distance from a color vector c
r
to L is given by  
                           ||||
||)(||
z
cczd r
rr
−×
=                                       (8) 
where c is the centroid of the feature space and is defined as: 
                          ),(),(
1
1
1
1 ∑
=
∑
=
=
N
i
iN
N
i
iN yxyx                        (9) 
where xi and yi are the two-stimulus position values of the ith 
vector. For processing convenience, we subtract the centroid 
from all the feature vectors in order to translate the origin of 
the feature space to the centroid.   
To find the direction number of the 2-dimensional principal 
axis L, use the origin at the centroid. Then the moment of 
inertia of the point in s2 about the line L is 
∑
∈
−=
2
,
2 ])coscos[(),(
syx
yxI αββα                   (10) 
Differentiate this with respect to αcos  and βcos , and 
equating to zero gives 
            
0coscos
0coscos
0,211
1,12,0
=+−
=−
βα
βα
mm
mm
                        (11) 
Equation (11) is a homogeneous system, which has a trivial 
solution .0coscos == βα  However, this solution does not 
satisfy the equation (7) and hence the nontrivial solution of 
system should be found by performing of Guass-Jordan 
reduction procedure [11] on the augmented matrix [M|0]. The 
result is 






0|10
0|01
2
1
k
k
 
where 2,1, =ik i  are the ratios of αcos and βcos . Based on 
the reduction results, the values of αcos and βcos  can be 
computed as 
               ),()cos,(cos
2
2
2
11
2
2
2
2
11
1
kk
k
kk
k
++++
=βα .          (12) 
Once the principal axis L is obtained, we can project each 
position vector onto L to compute the projection score of 
vector by the following equation: 
                      βα coscos yxPc +=r                          (13) 
Consider two objects in an image, which consists of two 
large numbers of vectors and represented as A={a1,a2,…,am} 
and B={b1,b2,…,bn}, respectively. The centroid of objects A 
and B are found as  
  
 
system, three features are used independently. Users are 
required to set the weighting of each features type in order to 
retrieve semantically relevant images. Unfortunately, the 
low-level features and the high-level semantic concepts do not 
have an intuitive relationship. This limits the retrieval 
accuracy of QBIC-like systems. In this paper, we proposed a 
method to integrate the low-level features and semantic-level 
features. Given a query image with the object vector 
),...,,( )()(2
)(
1
q
n
qq
q OOOI = and an object vector  
),...,,( )()(2)(1 kmkkk OOOI =  belonging to database image, two 
kinds of semantic-level features are used as high-level 
semantic features. They are the dominant values RW of object 
defined as eq. (2) and its activity scope S of the dominant 
object belonging to its image. Without loss of generality, we 
assume the number of objects of a database image is larger 
than that of a query image, i.e. n<m. In order to calculate the 
value of similarity between two images Iq and Ik, two distances 
of matching )(Smd  and un-matching )(Sud on the basis of 
semantic-level are computed by  
∑
=
−+−=
n
i
k
j
q
iij
k
j
q
iij
S
m SSuRWRWwd
1
)()()()()( ||)||||||(    (19) 
                ∑
−=
−
Π=
m
mnj jnm
S
ud 1)(                             (20) 
where wij and uij denote weighting factors of the dominant 
value of an object and the activity scope of an object and set 
to be 0.6 and 0.4 respectively. The activity scope Si of an 
object and the penalty Π of un-match object is given as  
                        
ageanofSize
iObjectofScopeActivity
iS Im1−=              (21)                      
||ImIm|| kIkIj ageofBackgroundageofObject −=Π      (22) 
where the KIageofbackground Im is the neighbor and 
omitted with the KIj ageofobject Im . Note that the 
values of )(Smd  and )(Sud  should be normalized by maximum 
values of )(Smd and )(Sud , respectively, before advancing to 
define similarity measure between the two images Iq and Ik. 
This normalization process will result in the normalized 
values of )(Smd and )(Sud  are confined within the (0, 1) interval. 
Let )(~ Smd and )(
~ S
ud denote the normalized )(Smd and )(Sud , 
respectively. The measurement of similarity )(Sd  between 
two images Iq and Ik on the basis of high-level of semantic 
distance is defined as 
                       )~~(1 )(2)(1)( SuSmS dwdwd +−=                  (23) 
where w1 and w2 represent the weighting of )(~ Smd  and )(
~ S
ud  
respectively, and w1+w2=1.  
The low-level feature can be calculate using the weighted 
Euclidean distance as 
  |||||||||||| 321 TkTqSkSqCkCq IIIIIId −+−+−=Γ λλλ
r
        (24) 
where Γd  denote the low-level features distance and 1λ , 2λ , 
and 3λ  are the weighting factors of the low-level features 
color, shape, and texture, and set 0.4, 0.3, and 0.3, 
respectively. The value of d is also normalized by the 
maximum value of d , and defines as  
             Γ
Γ
−=
max
)( 1
d
dLd                        (25) 
The overall distance between the two models is a weighting 
sum of the semantic distance and the low-level feature 
distance 
                       
)()()()( LLSSoverall ddd ρρ +=            (26) 
where )(Sρ and )(Lρ are the semantic weighting and the 
low-level feature weighting, respectively, and )(Sρ + )(Lρ =1. 
V. EXPERIMENT RESULTS 
In order to evaluate the performance of the proposed 
approach, a series of experiments were conducted on an Intel 
PENTIUM-IV 2.5GHz PC. The Zhang and Chen’s method 
[14], R. Zhang and Z. Zhang [8], and QBIC method [13] are 
also simulated by computer software for the purpose of 
performance comparison. A real data set consisting of 16887 
natural images were used for the test database. The image 
database has images of 8956 scenes, 1189 persons, 1303 
animals, 1584 plants, 1856 traffic tools, 389 buildings, 270 
sports, 565 pictures, 476 arts, and 299 others. Each image in 
the real database is first tailored to the size of 256×256 for 
testing the retrieval approach. Ten percent of the images from 
the different category of image database are randomly chosen 
to decide the ratio of dominant region in eq. (5). Table 1 
shows the ratio of capturing the semantic of an image with 
different category of images using the proposed method. 
According to simulation results, the proposed method 
provides a dramatic result when the ratio of reserving regions 
was assigned to be larger than 0.85.  
It is difficult to derive a formal method in evaluating the 
retrieval accuracy of the tested database system. Traditional 
metrics for evaluating performance are recall and precision. 
They are a function of both correct matches and relevance of a 
database image to a query. The retrieval accuracy measured 
by precision and recall is computed as follows. Recall 
measures the ability of the system to retrieve all images that 
are relevant and defined as: 
.Re
relevancesall
retrievedcorrectlyrelevances
call =  
Precision measures the ability of the system to retrieve only 
images that are relevant and can be computed by: 
.Pr
retrievedall
retrievedcorrectlyrelevances
ecision =  
Recall and precision required a ground truth to assess the 
relevance of images for a set of significant queries.  
The average precision and recall curves are plotted in Figs. 2 
and 3, respectively. It can be seen that the proposed method 
achieves good results in terms of retrieval accuracy compared 
with Zhang and Chen’s method [14], R. Zhang and Z. Zhang’s 
method [8], and QBIC method [13]. The performance of the 
proposed method provides a good way to evaluate the fitness 
of a semantic description used to retrieve the semantic content 
of the image.  
 
VI. CONCLUSIONS 
In this paper, we have presented a new method of semantic 
space segmentation for content-based image retrieval using 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
