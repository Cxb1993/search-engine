 I
行政院國家科學委員會專題研究計畫期中報告 
多人臉部偵測與自動化讀唇系統之研究 
Multi-face detection and automatic lip-reading system 
 
計畫編號：96-2221-E-214-054-MY2 
                  計畫主持人： 蘇義明 
      共同主持人： 謝朝和 
                 執行單位： 義守大學 電子工程系 
 
中文摘要 
 本研究計畫之目的為實現一套自動化讀唇(lip-reading)雛形系統，有助於在沒有語音
資料的輔助之下可以得知說話者所要表達的意思。目前對於視覺語音的辨認，通常都以語
音辨認為主，再以視覺影像為輔，以便在高雜訊的環境下，增加語音辨認的效率，然而在
實際的生活環境之下，可能發生只有視覺影像資料而沒有語音資料，例如：街道監控錄影
系統或長距離監控攝影系統，因此建立一套自動讀唇系統，可提供在無影音資料下，能夠
輔助觀看者了解說話者的義涵和內容。  
 綜合上述的描述，為了建立一套自動化讀唇雛型系統，並初步針對數字和人名進行唇
語辨認，其處理的步驟，從多人臉部偵測開始，尋找可提供唇語辨認的來源，並完成嘴唇
定位，假若無法找到適當嘴唇範圍，則進行臉部追蹤，反之若能定位嘴唇範圍，再進行嘴
唇特徵擷取，並持續作嘴唇追蹤，取得更多唇形變化，以便完成唇語事件的辨認。 
關鍵字：多人臉部偵測，讀唇 
Abstract 
 The main goal of this proposal is to implement the prototype system of the lip-reading in 
order to understand the content of the speakers without speech information in the real world. The 
system is to allow people who interpret visual speech content on the videos. For understanding 
the content of the speakers, we usually use the techniques of the speech recognition. Furthermore, 
the lip-reading is mostly used improve the performance of the speech recognition under the 
high-noise environment. However, there is only visual information in some situations, but no 
speech information. For examples, a video record system for the street monitor only has visual 
information without speech information.  
 Therefore, we will develop an automatic lip reading system in order to understand the 
content of the speakers. According to the mentioned description, we propose the prototype system 
of the lip-reading. We initially use numbers and names to test the proposed system. In the system, 
the multiple faces are firstly detected in order to find the resource of the visual speech 
information. Then, the lips are further located. If the lip localization process is successful, the lip 
features are extracted for the lip classification. 
Keywords：multi-face detection，lip-reading 
 1
 
一、研究動機 
 隨著數位科技時代的來臨，在電腦視覺的相關研究中，對人體動作和表情有更深入的
探討，尤其在人臉的處理已經有相當多的研究成果，從單一的靜態影像處理，包含臉部偵
測和表情辨認等，到連續影像(sequential images)或視訊資料(visual video)處理包含臉部追蹤
(tracking)和讀話(speech-reading)，並藉由電腦來摸擬和分析，人類外在的表象和語言，以使
機器人更人性化，因此如何描述視覺語言是未來研究的主題之ㄧ，並使得人類能有效地從
視覺資料得到更多資訊。再者，建立一套自動讀唇系統可提供或揣摩在無可靠語音資料下
如遠端對話或具有高度雜音的環境，能夠輔助說話者的意涵和內容。 
 
二、背景 
 近年來，對於臉部特徵的數位化處理和自動讀唇系統，在國外的研究，有日漸增加的
趨勢，尤其在英國 Surrey 大學,視覺語言訊號處理中心[1]將於 2007 年開始執行為期三年的
研究計劃探討語言無關的讀唇(Language Independent Lip Reading )[2],以建立精確和可靠的
臉部和唇形追蹤系統，可運用在犯罪影片中，可得知唇語所提供的語音資料,以進行犯罪事
件的查證。另外 Intel 公司也曾在 2003 年宣布完成一套聽覺視覺語言辨認系統[3]教導電腦
以讀唇改善語言辨認的精確度，擷取視訊資料作臉部偵測，嘴唇追蹤，視覺特徵擷取和分
類。再者一些研究論文包含臉部偵測[4,5]、臉部追蹤[6,7]、嘴唇定位追蹤[8-10]、嘴唇分類
[11]和有關讀唇系統[12,13]。目前，在國內的研究對於自動讀唇系統並無顯著發展，但相關
領域如臉部偵測[14,15] 、臉部追蹤[16]和辨認[17,18]以及表情辨認[19,20]皆有初步進展。  
 目前對於自動讀唇系統，其使用的方法可包含一些處理步驟-臉部偵測，嘴唇定位，嘴
唇追蹤，唇形特徵擷取和分類。在作唇語辨識之前，首要步驟即是對影像做人臉的偵測，
其中臉部偵測方法[21]可分為二大類。 
 第一類處理方法先以臉部整體的特徵為考量，舉例以臉部膚色、形狀、大小、移動和
空間轉換為特徵再進行分類。此類的方法可適用在較無限制環境但計算量通常較大。 
 第二類處理方法先以偵測臉部局部器官為考量，舉例先以邊緣或彩色偵測眉毛、眼、
嘴等器官在定出臉部的位置。此類的方法通常假設臉部在影像圖片即清楚又大。再者，其
使用分類方法包含以知識為基底[22]，以樣版比對為基底[23]，以學習為基底[24]等方法。
其方法詳細描述如下。  
1.以知識為基底的方法:此類方法通常用規則(rules)來描述人臉器官之間關係，以便偵測
人臉區域。此類方法很難進一步偵測出不同姿勢的人臉，因為很難一一列舉出所有的
可能規則。  
2.以樣版比對為基底的方法:此類方法用一些事先定義好代表人臉的模版或人臉各個器
官的模版與輸入影像作比對。無法容忍變化度較高的輸入人臉影像。  
 3
 
 
 
 
 
 
 
 
 
圖二多人人臉偵測的流程 
 
 
 
 
 
 
 
圖三 多人臉部偵測的結果 
 
3.1.1 膚色偵測 
 首先將影像的色彩空間轉換為 NCC(Normalized Color Coordinates)色彩空間中，將亮度
對色彩的影響降低。公式如下： 
 
 
 
根據膚色在 RG 平面的分布，我們可以發現他分布的範圍在兩個界線之間，因此我們利用
兩個二次方程式分別代表它的上界與下界： 
 
 
 
由於白色也在此範圍之中，必須予以排除，因此加上以下條件： 
 
 
最後再將範圍縮小，並且加入排除黃綠色像素 R - G > 5，以及膚色中的 RGB 分布 R>G>B
 5
其中： 
 
 
 
 
接著作連接元區域標定，選取面積最大且呈現水平長方形者為嘴唇的部分。若在此搜尋區
域內沒有嘴唇區域，則判定此物件不含人臉。 
 
 
 
 
 
 
 
圖六 嘴唇偵測的結果 
 眼睛搜尋的部分，首先根據眼睛在臉部的分布來定義眼睛的搜尋範圍，如下圖： 
 
 
 
 
 
 
 
 
 
圖七 眼睛位置的搜索範圍 
 
其中： 
 
 
 
 
將搜尋範圍內的像素轉換為灰階值，由於眼睛的顏色通常是最深的，因此我們可以取一個
門檻值，將不夠暗的像素過濾掉。接著以連接元件標定取得物件，接著去計算每個物件的
 7
接著根據所得的剖面圖作最小值分析。一開始先對垂直方向的剖面圖作處理，分別從上到
下和從下到上，在範圍[0,d]之間找出最小值，d 為剖面圖長度的 1/3。接著將邊界設在找出
來的兩個位置，把兩個位置之間的內容剪下，接著在計算水平方向的剖面圖，同樣找出兩
個最小值的位置，將中間的部分剪下。在重複運算以後，就可以得到精確的唇形位置。這
個演算法可以在 3~4 個重複後，得到收斂的結果。 
    演算法如下： 
 
Begin iteration 
k=0;lip_ROI=[yt,0,tB,0,xL,0,xR,0] 
Calculate the vertical profile in CE(x,y) plane 
   Find the local minima from the top end of the profile with [0,d] 
   Set the boundary yT,k at this point with the lip ROI cropped accordingly 
  Proceed at the other end of the profile and locate yB,k 
Calculate the horizontal profile in CE(x,y) plane 
   Locate xL,k and xR,k on the horizontal profile sequentially 
k=k+1 
 
 
 
 
 
 
 
      圖十 逐步刪除多餘區域的過程                    圖十一 嘴唇定位的結果 
3.3 臉部追蹤 
 當無法定位出嘴唇範圍，則臉部偵測的結果將臉部的中心位置和大小傳遞到臉部追蹤
系統。追蹤系統會根據這些資訊產生出感興趣區域（Region Of Interest, ROI） ，此部分的
用意在於縮小搜尋範圍及減少運算量。在感興趣區域裡面，我們將提出適應性膚色搜尋找
出最佳的膚色色彩分佈，並且將臉部的範圍框選出來，接著若符合以下兩個條件就把此刻
的臉部位置及大小傳遞到下一時刻輸入影像中，以設定下一時刻感興趣區域：第一，利用
臉部投影長寬而產生感興趣區域，故臉部區域投影出來的面積會占感興趣區域面積一定的
比例，若投影的面積大於或小於此感興趣區域面積某一程度的話，即表示前一時刻選擇的
臉部位置及大小不是最佳的，導致此刻臉部的位置沒有在設定之感興趣區域中心附近，即
表示追蹤將失敗；第二，假設臉部的移動在一定的速度以內，我們認為臉部投影寬度的變
 9
                       圖十二  多人臉部追蹤的結果 
3.4 嘴唇特徵擷取 
當嘴唇定位成功之後，我們使用嘴唇與臉部邊緣對比的關係，進而定位出嘴唇的中心
點和四個角點，再根據這些點的位置估算出內外唇的寬度和高度，以及內外唇的寬高比。
首先我們將嘴唇範圍的 RGB 彩色影像轉換為灰階影像，當影像轉換完成之後，我們先用中
間值濾波器(Median Filter)來去除雜訊，接著利用水平 Sobel 濾波器取出嘴唇水平方向
的邊，再利用邊緣二值化將濾波之後的灰階影像轉換成二值影像，以便進行水平投影
(Projection)的處理，並根據投影的最大值的位置視為中心點的水平位置。再根據嘴唇左
右角點具有最高的對比資料，我們從嘴唇範圍的最右邊開始向中間搜尋直到找到最大對比
量，其位置視為最右的角點；同樣方法搜尋左邊的角點。對於定位出嘴唇的最頂點，開始
以嘴唇左邊的角點沿嘴唇的邊緣往上找並發現較大對比值而且落點需落在左右角點的中心
位置處。同樣方法可找尋嘴唇的底點。假若唇形式張開，通常上下各有兩條對比較大的邊
緣，因此用相同的方法進一步取得內唇的頂點和底點的位置。這六點視為嘴唇特徵點。再
根據這些點的位置計算出如圖十三 各參數的值 h1 , h2 , h3 , h4 , w0 , w1，而這些參數視
為唇形的特徵資料。 
 
 
 
 
 
 
 
 
圖十三特徵點的位置 
3.4.1 嘴唇輪廓 
一般而言，唇形區域顏色與膚色相比較是略紅。嘴型區域擷取基於左右的角點(corner 
points) 和上下的角點所組成的長方形。經過處理後，目視可以很容易看清楚嘴唇輪廓雛
形。圖十四，圖十五為了方便處理影像，影像儲存為 JPG 檔案，此時的灰階圖為 256 色，
唇形輪廓還是有凹凹凸凸不規則形狀，並有一部份的雜訊包含於其中。 
                           
圖十四 唇形擷取圖                 圖十五 放大唇形擷取圖 
因目前的影像圖為RGB彩色影像，為了方便進行細部分析，首先我們將RGB彩色影像轉換為
灰階影像(gray level)，使用2-D線性空間濾波器，於轉轉換過程中進行影像處理，並選用
 11
 
 
圖十八菱形結構元素 
其中參數 R=1，指名結構元素原點到菱形極端點的距離為 1。此元素沿著水平和垂直軸延展
+-1 個像素。輪廓像素以形態學上來做平滑處理。決定唇形的邊緣輪廓，有許多以之方法
可使用，實驗中，採取了著名 canny 方式找出唇形邊緣。內、外唇形輪廓如圖十九。 
     
圖十九內外唇輪廓 
利用儲存於陣列中的唇形輪廓座標，使其還原於原始影像圖 3-16 中，可以看出經過平滑處
理，邊緣處理，膨脹和侵蝕等等，型態學的處理方法，再與以對應(mapping)原影像圖後，
所顯示的曲線不至於失真。 
 
圖二十唇形輪廓邊緣對應圖 
3.4.2 建立唇形曲線 
唇形曲線是由所分析過後的座標組合。要如何正確的區分出上下唇的形狀曲線表示，
從各種文獻當中，唇形表示方法眾多，也有學著利用傅立葉描述子表示做研究，實驗裡採
用曲線作為唇形表示法。 
橢圓配置(ellipse fitting)[36]於文獻中可以區分為:1 聚集(如 Hough-based 方法)，2 
最小平方法(least-squares fitting)[37]。最小平方法曲線配置技術為量測點座標，點
與點座標距離最小化使其曲線最佳化。圓錐體二次多項式的數學表示方式為:  
( ) 0, 22 =+++++=⋅= feydxcybxyaxF xaxa  
[ ]Tfedcba      a = ， [ ]Tyxyxyx 1    x 22=  
( )ixa;F 稱為:點到圓錐體 ( ) 0x;a =F  ＂代數距離＂(algebraic distance)。基於此理
論，由於分析得到的座標為相對坐標，不同大小的影像會得到不同座標軸，為了使其得到
正確座標值，必須將相對座標轉換為絕對座標，避免與原影像產生位移狀況。得到多項式
 13
因世界上每個人的唇形，唇肉厚度完全不一樣，藉由二次多項式拋物線代表唇形，包含內
外唇形全部藉由二次方程式資料來表示。不同的人有不同的唇形，說話時的唇部動作，相
同音也完全不一樣。唇的寬厚的變化度(variant)是相當的大。內唇的變化更是典型代表嘴
型的變化。外上唇的二次方程式表示如下:  
011
2
1 =++ cxbxa  
外下唇的二次方程式表示如下: 
022
2
2 =++ cxbxa  
內上唇的二次方程式表示如下: 
033
2
3 =++ cxbxa  
內下唇的二次方程式表示如下: 
044
2
4 =++ cxbxa  
每個人的唇形可由向量(vector)來代表( 111 ,, cba , 222 ,, cba , 333 ,, cba , 444 ,, cba ) 
                   
圖二十四外唇二次多項式曲線            圖二十五內唇二次多項式曲線 
四、實驗結果 
4.1 嘴唇追蹤 
為了取得一連串的唇形變化，以便提供唇語辨認所需要的資料。因此，我們需要進一
步進行嘴唇追蹤處理。本計劃我們採用 Lucas&Kanade[31]所提出運動向量估計方法。 
 
 
4.2 唇形分類 
基於以上論點，對於幾種基本口型作處理，處理後結果如下圖所示，均可得到良好的
內外型唇形並將這些曲線資料轉換為資料向量組合作後續分析用。 
                   
 15
 
 
k-mean 演算法(Lloyd，1982)[44]是較常使用的動態聚集演算法。這種方法計算簡單有效
又快速。但其缺點是須先確定數入數目，且準確性較低，計算結果受初始聚集中心選擇的
影響較大。其演算法一開始需決定關於有多少群集必須在資料中被呈現。演算法隨機選擇
k個資料當作最初的群集中心，每個範例被分配到最相似的群集中。但其缺點是須先確定
數入數目且準確性較低計算結果受初始聚集中心選擇的影響較大。相似性可以用很多方法
來定義，最經常使用的是歐姬里德距離。因實驗分類項目中，因已知預先分類的種類數目，
雖不是最佳法，但也是可用分類法之一。 
 
4.3 訓練樣本實驗結果 
從影像圖中嘴型擷取出輪廓後，除了閉嘴嘴型外，其餘的嘴型都有兩個封閉多邊形圓。
可以在做分類時先選出閉嘴嘴型而不用繼續做後續處理動作，而直接斷定為閉嘴嘴型類
別，如圖 4-1 所示。 
       
(a)                                   (b) 
閉口口型  
緊閉口口型 
正常閉口口型 
嘟嘴閉口 
開口口型
微開口不露齒型
露上齒口型
露下齒口型
露上下齒口型
 17
嘴部狀態 測試數目 正確數目 成功率 
閉口嘴型 50 50 100% 
微開口嘴型 50 43 86% 
半開口露上齒嘴型 50 30 60% 
半開口露下齒嘴型 50 32 64% 
半開口露上下齒嘴型 50 42 84% 
開口上下齒分離嘴型 50 41 82% 
全開口嘴型 50 47 94% 
 
 
4.4 連續唇形辨識 
本計劃為了達成唇語的辨識，我們使用動態貝氏網路(Dynamic Bayesian Network)推
演唇形的變化，也就是利用動態貝氏網路建構高低階特徵橋樑，進而達到得知唇形的變化
的意涵。最上層節點為時序中所偵測唇形的特徵資料- h1 , h2 , h3 , h4 , w0 , w1，代表嘴
唇的變化，中層為狀態變化，最下層代表時序中發生唇語事件，在定義事件中所輸出之觀
察機率。基本上，HMM 辨識方法是先建立各類唇形的特徵資料的統計模型。辨識時，再計
算由各模型產生對輸入唇形的特徵資料的機率大小，以決定辨識結果。當未知的唇形影像
經由特徵抽取，其特徵向量經由編碼簿(code book)對應產生一連串的符號，並透過Viterbi 
algorithm[33]找出最佳路徑並得到最大的輸出機率。也就是此一連串的符號輸入到每一唇
語事件的HMM 參數模型(由訓練產生)透過Viterbi algorithm 求出每一個唇語事件模型的
輸出機率，取出最大的輸出機率，其相對應的唇語事件模型即為輸出結果。 
 
                                               
五、未來工作 
 嘴唇定位和臉部追蹤部份，我們希望本系統能夠適用於不同大小、形狀和位置的人臉，
增強系統可自動嘴唇的定位，最後希望能夠達到自動即時偵測視訊影像框。嘴唇特徵擷取
和嘴唇追蹤部份，我們希望可以發展快速有效的嘴唇追蹤方法，並且擷取嘴唇的特徵，建
立特徵模式，加強辨認結果。  
 在嘴唇分類和唇語辨識部份，我們希望能夠發展適用於臉部視訊中，低階特徵資料的
擷取，以決定何種唇語事件的發生。 
六、具體成果 
在此一計畫中，我們已經提出一套多人臉部偵測系統及嘴唇辨識系統。 
 完成戶外的環境下，針對多人臉部偵測以及嘴唇偵測。 
 完成嘴唇模組的建立以及嘴唇的分類。 
 
 
 
 
 19
電機工程研究所/92/碩士論文 
[18]邵文斌, 謝君偉,即時人臉辨識系統, 元智大學/電機工程學系/94/碩士論文 
[19]李忠驊, 張元翔運用類神經網路於人臉表情辨識中原大學/資訊工程研究所/94/碩士論
文 
[20]謝怡竹, 蘇木春以光流為基礎之自動化表情辨識系統國立中央大學/資訊工程研究所
/93/碩士論文 
[21] M.-H. Yang, D. Kriegman, and N. Ahuja, “Detecting faces in images: A survey,” IEEE Trans. 
on Pattern Anal. Mach. Intell., 24(1), 34-58, 2002.  
[22] G. Yang and T. S. Huang, “Human Face Detection in Complex Background,” Pattern 
Recognition, vol. 27, no. 1, 53-63, 1994  
[23] T. Sakai, M. Nagao, and S. Fujibayashi, “Line Extraction and Pattern Detection in a 
Photograph,” Pattern Recognition, vol. 1, pp. 233-248, 1969.  
[24] S. L. Phung, D. Chai, and A. Bouzerdoum, “A universal and robust human skin color model 
using neural networks,” in Proc. Of Int’l Joint Conf. on Neural Networks, vol. 4, 2844-2849,  
2001.  
[25] Juergen Luettin,Neil A.Thacker,Steve W.Beet, Visual speech recognition using active shape 
models and hidden markov models [R].University of Sheffield,Electronic Systems Group Report 
No.95/47,1996.  
[26] T.F.Cootes,G.J.Edwards,and C.J.Taylor, Active appearance models, Proc.European 
Conference on Computer Vision [C],June 1998:484-498.  
[27] P.Duchnowski, M .Hunke, D. Büsching, U. Meier and A. Waibel , Toward 
Movement-Invariant  
Automatic Lipreading and Speech Recognition, Proc. Intern. Conference on Acoustics, Speech 
and  
Signal Procesing 1995  
[28] K.D. Lee, M.J. Lee, and S.Y. Lee, "Extraction of Frame-Difference Features based on PCA 
and ICA  
for Lip-Reading", International Joint Conference on Neural Networks, Montreal, Canada, pp. 
232-237, 2005.  
[29] Viola Paul, and J.Jones. Michael“Rapid Object Detection Using a Boosted Cascade of 
Simple Features ＂ IEEE CVPR ,Vol.1, NO. 2, pp 511-518, Dec. 2001.  
[30] Freund, Y., and Schapire, R.,“A Decision-Theoretic Generalization of On-Line Learning and 
an Application to Boosting＂Journal of Computer and System Sciences, 55(1), pp119–139, Aug 
1997.  
ABSTRACT- This study presents an integrating decision 
approach, based on a model-based and rule-based decision 
approach, to detect and classify highlight events in baseball 
games. The model-based approach is proposed to model the 
relationship between the change statuses of the caption data 
and some events. The approach uses some binary bits to 
represent the amount of the changes. The rule-based 
approach is proposed to use the conditions of the caption 
data to elicit the empirical knowledge and to decide what 
some events is happened. Finally, the proposed approach 
integrates the complementary and redundant resulting of 
the two approaches to enhance the classification 
performance.  Experimental results demonstrate that the 
proposed approach is very efficient for classifying highlight 
events. Furthermore, the performance of the proposed 
approach can be improved by 6.58% over the average of the 
model-based and rule-based approaches. 
 
I. INTRODUCTION 
An automatic highlight extraction system is increasingly 
needed to enhance multimedia services because the number of 
sports videos has increased rapidly. Furthermore, the system 
applied in sports videos is useful for analysis and understand the 
video content. Additionally, baseball games have recently 
become quite popular. However, an entire baseball game is quite 
long, with few highlight portions. Therefore, this study initially 
develops a highlight extraction system for baseball games. Eight 
highlight events are first considered for the baseball games: one-
base hit (1B), two-base hit (2B), three-base hit (3B), home run 
(HR), steal base (SB), double play (DP), sacrifice fly (SF) and 
base on ball/walk (W). 
Detecting the highlight events of sports videos typically 
involves two phases, namely semantic feature extraction and 
semantic event decision. Related approaches to semantic feature 
extraction are roughly divided into three types, namely (1) 
visual features (i.e., color distribution, edge distribution, and 
camera motion) from pitch, infield, outfield, close-up, audience, 
transition effect and other scenes [1, 3, 4, 6]; (2) audio features 
(i.e., MFCCs, ZCR and MPEG-7) from ball hitting, applause 
and excited sound [2, 4, 5]; (3) textual features (i.e., scoring, out, 
inning, and base) from the caption information [1, 4]. Using 
single feature for event decision is usually weak, because some 
event cases have the same decision result. For instance, one-base 
hit (1B) and base on ball/walk (W) have the same change status 
from the caption information. Therefore, most highlight event 
detection approaches utilize multiple features to distinguish 
among the confused event cases. Related highlight-event 
decision approaches are classified as rule-based and model-
based decision approaches. Rule-based approaches use a set of 
heuristic rules to construct a decision tree [1, 6]. The major 
benefits of this approach are the relatively low computational 
cost and ease of implementation. However, rule-based 
approaches are not very flexible or adaptable. Additionally, a 
highlight event indicates that some situations happened orderly, 
but the order of the situations is not absolute rule. Finally, most 
rule-based decision approaches lack learning ability. The model-
based decision approach models the relationship between 
semantic features and highlight events, using probabilistic 
models such as GMM [2], HMM [3, 6], maximum entropy 
model [4], and other probabilistic model [5]. Moreover, most 
model-based decision approaches based on a learning 
processing technique are appropriate for knowledge 
maintenance and decision accuracy. However, the major 
limitations of the decision approaches are the need for large 
learning sets to cover all the possible degrees of accuracy of a 
certain event, and a high computational cost during the learning 
process.  
Therefore, this study proposes an integrating decision 
approach to enhance the performance of the highlight events of 
baseball videos, using the model-based and rule-based 
approaches. This proposed approach not only is more flexible 
and adaptable and could take the advantages of two decision 
approaches. The highlight extraction system has several stages, 
namely caption extraction, caption identification, content 
recognition and event decision stages, as shown in Fig. 1. 
The remainder of this paper is organized as follows. Section 2 
describes some preliminary treatments about caption extraction, 
caption identification, content recognition stages. Section 3 
presents an event decision processes, integrating the model-
based and rule-based approaches. Section 4 summarizes 
Semantic Events Detection and Classification for 
Baseball Videos 
 
1Yih-Ming Su, 2Chaur-Heh Hsieh 
1Department of Electronic Engineering, I-Shou University, Kaohsiung County, Taiwan. 
2 Dept. of Computer and Communication Engineering, Ming-Chuan University , Taoyuan, Taiwan. 
ymsu@isu.edu.tw 
IEEE International Symposium on Industrial Electronics (ISIE 2009) 
Seoul Olympic Parktel, Seoul, Korea  July 5-8, 2009 
 
978-1-4244-4349-9/09/$25.00 ©2009 IEEE 
 
 
1332
shown in Fig. 2. The change status of the out numbers is used in 
the first level decision because it can be easily to category event 
classes- double play (DP) where 2=ΔO , one-base hit (1B) 
and sacrifice fly (SF) where 1=ΔO , and other events where 
0=ΔO . Some parameters are added in order to precisely 
determine event classes, including the status of the base 
1][ =iBS  where the ith base is occupied, the number of on-base 
before events happened (R1), and the number of on-base after 
events happened (R2). 
Finally, when the events are detected by the two decision 
approaches, an integrating approach is used to further enhance 
the performance of the event detection. The integrating approach 
uses a joint operation to select an optimal event. If one of two 
results from two event decision stages, the final event is 
regarded as non-event. The integrating process can reduce 
confused events except for on-base hit (1B), sacrifice fly (SF), 
and on-base walk (W) because of the same status in the caption. 
 
IV. EXPERIMENTAL RESULTS 
Some experiments were performed to confirm the 
effectiveness of the highlight-event decision system. The 
proposed approach was applied to a database set of four 
baseball films forming 11 hours of MPEG-1 videos. The source 
videos were captured from television broadcasting using a 
capture device. The experimental interface designed for this 
research enables users simply to import the baseball video that 
they wish to search. 
 
A. Performance Analysis 
The score, outs and innings do not change quickly during 
baseball games. Therefore, real-time processing (30 frames per 
second) of the caption contents could be achieved, a capture rate 
of 2.5 frames per second in order was used in order to 
coordinate with the time required to update the caption after the 
occurrence of an event (about 3 to 3.5 seconds).  
Four complete baseball game videos, comprising 11 hours of 
video content, were utilized to test the performance of the 
proposed system. Observation results yielded 98 events. Table 2 
illustrates the performance of the highlight event decision 
system in terms of the recall (R) and precision (P). The model-
based, rule-based, and integrating approaches had recall rates of 
92.8%, 85.1%, and 92.8%, and precision rates of 81.2%, 
73.65%, and 84%, respectively. The table indicates that only 
two highlight events, namely the one-base hit (1B) and base on 
ball/walk (W), were not detected accurately. This is because 
these two events are easily confused from caption information. 
Additionally, the single base hit (1B) occurs because a news 
ticker running on screen following the single base hit interferes 
with the system, causing a missed event. Furthermore, the recall 
rate of double play (DP) was low because this inning after a 
double play happened is immediately over and the caption 
information is disappeared, so the proposed approach employed 
could not immediately detect the double play. Finally, the rule-
based approach utilizes the rule decision, and the order in which 
rules occur affects the result of the event decision. Therefore, 
the proposed approach is visually superior to the model-based 
and rule-based approach.  
 
B. Discussion 
In the proposed system, the system begins to detect a 
highlight event only when numbers in the caption other than the 
amount of balls and strikes are changed. This decision was made 
because a change in the number of strikes or balls does not itself 
amount to a highlight event. Our main consideration was that if 
a change in the numbers of balls and strikes triggered the system 
to detect an event, then it would probably detect a false alarm of 
highlight events. This is because the highlight events include 
situations involving no change in score, runners on base, or 
innings. 
The integrating approach is presented by the knowledge 
representation, including the rule-based and model-based 
approaches, and used to compare their characteristics with 
respect to their maintainability and decision accuracy. The 
model-based approach is more appropriate for knowledge 
maintainability, flexibility, and decision accuracy than the rule-
based approach.  
Although having good classification results, the proposed 
system needs other features (audio and visual information) to 
improve the performance of the system. However, this system is 
also more likely to cause a non-event to be detected and 
classified. Conversely, a model-based decision approach needs a 
clearly defined model value to detect and classify an event. This 
requirement significantly reduces the potential for a confused 
recognition or classification, which primarily occurs when a 
batter strikes out or is put out. 
 
V. CONCLUSIONS 
This study proposes an integrating decision approach for an 
automatic highlight event extraction system and takes the 
advantages of the rule-based and model-based approaches. 
Experimental results indicate that the proposed approach for 
determining the highlight events is efficient and fast when 
applied to the baseball games. Moreover, comparing the 
proposed approach with the two decision approaches indicates 
that the process of extracting the highlight event is very helpful 
for improving the decision performance. 
 
ACKNOWLEDGEMENT 
The authors would like to thank I-Shu University and the 
National Science Council of the Republic of China, Taiwan, for 
financially supporting this research under Contract No. 96-2221-
E-214-054-MY2. 
 
1334
  
Table 2. The comparative performance in terms of recall (R) and precision (P) rate via the number of correct (c), missing (m),  
and false (f) detection 
Model-based approach Rule-based approach Integrating approach HE 
c/(c+m)=R c/(c+f)=P c/(c+m)=R c/(c+f)=P c/(c+m)=R c/(c+f)=P 
1B 25/(25+2)=92.6% 25/(25+17)=59.5% 16/(16+3)=84.2 % 16/(16+25)=39% 26/(26+2)=92.8% 26/(26+16)=62%
2B 6/(6+0)=100% 6/(6+1)= 85.7% 7/(7+0)=100% 7/(7+0)=100% 7/(7+0)=100% 7/(7+0)=100% 
3B 1/(1+0)=100% 1/(1+0)=100% 1/(1+0)=100% 1/(1+0)=100% 1/(1+0)=100% 1/(1+0)=100% 
W 7/(7+0)=100% 7/(7+10)=41.2% 3/(3+1)=75% 3/(3+13)=18.8% 8/(8+0)=100% 8/(8+9)=47% 
SB 5/(5+0)=100% 5/(5+1)=83.3 % 4/(4+1)=80 % 4/(4+1)= 80% 5/(5+0)=100% 5/(5+1)=83.3 % 
DP 2/(2+2)=50% 2/(2+0)=100% 2/(2+2)=50% 2/(2+0)=100% 2/(2+2)=50% 2/(2+0)=100% 
SF 12/(12+0)=100% 12/(12+3)= 80% 5/(5+1)=83.3% 5/(5+9)=35.7% 12/(12+0)=100% 12/(12+3)= 80% 
HR 4/(4+0)=100% 4/(4+0)=100% 4/(4+0)=100% 4/(4+0)=100% 4/(4+0)=100% 4/(4+0)=100% 
ΔO<2
DP
N
ΔO =0
BS[1]=1
1B/SF/No SF/No
Y
N
R1>=ΔS
R1=ΔS+R2
SB
Y
BS[1]=1
N
N
1B/W
Y
HR
N
R1>ΔS
BS[2]=1
2B
BS[3]=1
Y
N
3B
Y
Y
SB
N
Y
BS[2]=1
2B No
N
Y N
Y
Y
BS[1]=1
1B/W
Y N
N
 
Fig. 2. A decision tree for highlight event decision 
1336
application specific IC＇s, nonlinear and adaptive control, optimal and robot control, intelligent control, 
industrial applications of neural networks, fuzzy algorithms, evolutionary computing, and intelligent 
systems, instrumentation subject to critical conditions, automotive, marine and aero-space control and all 
other control applications. 
2. Hearing and Auditory Systems: Power Electronics and Electrical Drives : Power electronic devices and 
systems, integrated power electronics, modeling simulation and control of power electronics, DC-DC 
conversion, AC/DC Modern rectifiers, distributed power system, UPS, active and hybrid filtering, power 
line conditioners, photovoltaic, electromagnetic compatibility EMI/EMC., AC and DC drives modeling 
and simulation, micro machines, special application of machines and drives, advanced traction control of 
electric vehicles and electric trains, electrical drives for ships and aerospace, electric machines reliability, 
faults and diagnostics techniques. 
3. Sensors, Actuators and Systems Integration : Intelligent sensors and actuators, multisensor fusion, 
micro/nano technology, microsensors and microactuators, instrumentation electronics, MEMS and system 
integration. 
4. Signal and Image Processing : Digital signal processing theory, methods, DSP implementation, sensor 
array and multi-channel processing, speech processing, image and multidimensional signal processing, 
real-time multimedia signal processing, computer vision, emerging signal processing areas, signal 
processing in education. 
5. Industrial Informatics : Real-time computer systems, real-time information systems, 
human-machine interfaces, CAD/CAM/CAT/CIM, virtual reality, industrial communications, 
flexible manufacturing systems, industrial process and building automation. 
 
6. Mechatronics, Robotics, and Telecommunications : Mechatronic systems, industrial robots, 
service robots, telerobotics and teleoperation, multi-robot systems, humanoid robots, cognitive 
systems, electrical vehicles, intelligent transportation, distributed collaborative systems, security 
and safety applications, wireless and telecommunication systems. 
 其中就筆者所能擇研究相關領域分述如下： 
１． Computer Vision：在電腦是絕主題中，當中有一篇論文討論在人臉偵測技術領域中，
是一項新的技術，同時結合邊資訊和皮膚色彩資訊的分析。其準確性業績仍相對低於其他主
要生物識別技術。需要進一步研究，以確定更多的新功能，可以提高準確度的熱性能面對模
式。另外有一篇討論發展提高亮度的方法讓影像更佳的清楚。當然也有其他的討論影像的增
強和影像的切割選取等。  
２．Multimedia Application：  
 隨著數位時代的來臨，各種視訊媒體內容不斷地增加，尤其在休閒娛樂中，運動影片資
ABSTRACT- This study presents an integrating decision 
approach, based on a model-based and rule-based decision 
approach, to detect and classify highlight events in baseball 
games. The model-based approach is proposed to model the 
relationship between the change statuses of the caption data 
and some events. The approach uses some binary bits to 
represent the amount of the changes. The rule-based 
approach is proposed to use the conditions of the caption 
data to elicit the empirical knowledge and to decide what 
some events is happened. Finally, the proposed approach 
integrates the complementary and redundant resulting of 
the two approaches to enhance the classification 
performance.  Experimental results demonstrate that the 
proposed approach is very efficient for classifying highlight 
events. Furthermore, the performance of the proposed 
approach can be improved by 6.58% over the average of the 
model-based and rule-based approaches. 
 
I. INTRODUCTION 
An automatic highlight extraction system is increasingly 
needed to enhance multimedia services because the number of 
sports videos has increased rapidly. Furthermore, the system 
applied in sports videos is useful for analysis and understand the 
video content. Additionally, baseball games have recently 
become quite popular. However, an entire baseball game is quite 
long, with few highlight portions. Therefore, this study initially 
develops a highlight extraction system for baseball games. Eight 
highlight events are first considered for the baseball games: one-
base hit (1B), two-base hit (2B), three-base hit (3B), home run 
(HR), steal base (SB), double play (DP), sacrifice fly (SF) and 
base on ball/walk (W). 
Detecting the highlight events of sports videos typically 
involves two phases, namely semantic feature extraction and 
semantic event decision. Related approaches to semantic feature 
extraction are roughly divided into three types, namely (1) 
visual features (i.e., color distribution, edge distribution, and 
camera motion) from pitch, infield, outfield, close-up, audience, 
transition effect and other scenes [1, 3, 4, 6]; (2) audio features 
(i.e., MFCCs, ZCR and MPEG-7) from ball hitting, applause 
and excited sound [2, 4, 5]; (3) textual features (i.e., scoring, out, 
inning, and base) from the caption information [1, 4]. Using 
single feature for event decision is usually weak, because some 
event cases have the same decision result. For instance, one-base 
hit (1B) and base on ball/walk (W) have the same change status 
from the caption information. Therefore, most highlight event 
detection approaches utilize multiple features to distinguish 
among the confused event cases. Related highlight-event 
decision approaches are classified as rule-based and model-
based decision approaches. Rule-based approaches use a set of 
heuristic rules to construct a decision tree [1, 6]. The major 
benefits of this approach are the relatively low computational 
cost and ease of implementation. However, rule-based 
approaches are not very flexible or adaptable. Additionally, a 
highlight event indicates that some situations happened orderly, 
but the order of the situations is not absolute rule. Finally, most 
rule-based decision approaches lack learning ability. The model-
based decision approach models the relationship between 
semantic features and highlight events, using probabilistic 
models such as GMM [2], HMM [3, 6], maximum entropy 
model [4], and other probabilistic model [5]. Moreover, most 
model-based decision approaches based on a learning 
processing technique are appropriate for knowledge 
maintenance and decision accuracy. However, the major 
limitations of the decision approaches are the need for large 
learning sets to cover all the possible degrees of accuracy of a 
certain event, and a high computational cost during the learning 
process.  
Therefore, this study proposes an integrating decision 
approach to enhance the performance of the highlight events of 
baseball videos, using the model-based and rule-based 
approaches. This proposed approach not only is more flexible 
and adaptable and could take the advantages of two decision 
approaches. The highlight extraction system has several stages, 
namely caption extraction, caption identification, content 
recognition and event decision stages, as shown in Fig. 1. 
The remainder of this paper is organized as follows. Section 2 
describes some preliminary treatments about caption extraction, 
caption identification, content recognition stages. Section 3 
presents an event decision processes, integrating the model-
based and rule-based approaches. Section 4 summarizes 
Semantic Events Detection and Classification for 
Baseball Videos 
 
1Yih-Ming Su, 2Chaur-Heh Hsieh 
1Department of Electronic Engineering, I-Shou University, Kaohsiung County, Taiwan. 
2 Dept. of Computer and Communication Engineering, Ming-Chuan University , Taoyuan, Taiwan. 
ymsu@isu.edu.tw 
IEEE International Symposium on Industrial Electronics (ISIE 2009) 
Seoul Olympic Parktel, Seoul, Korea  July 5-8, 2009 
 
978-1-4244-4349-9/09/$25.00 ©2009 IEEE 
 
 
1332
shown in Fig. 2. The change status of the out numbers is used in 
the first level decision because it can be easily to category event 
classes- double play (DP) where 2=ΔO , one-base hit (1B) 
and sacrifice fly (SF) where 1=ΔO , and other events where 
0=ΔO . Some parameters are added in order to precisely 
determine event classes, including the status of the base 
1][ =iBS  where the ith base is occupied, the number of on-base 
before events happened (R1), and the number of on-base after 
events happened (R2). 
Finally, when the events are detected by the two decision 
approaches, an integrating approach is used to further enhance 
the performance of the event detection. The integrating approach 
uses a joint operation to select an optimal event. If one of two 
results from two event decision stages, the final event is 
regarded as non-event. The integrating process can reduce 
confused events except for on-base hit (1B), sacrifice fly (SF), 
and on-base walk (W) because of the same status in the caption. 
 
IV. EXPERIMENTAL RESULTS 
Some experiments were performed to confirm the 
effectiveness of the highlight-event decision system. The 
proposed approach was applied to a database set of four 
baseball films forming 11 hours of MPEG-1 videos. The source 
videos were captured from television broadcasting using a 
capture device. The experimental interface designed for this 
research enables users simply to import the baseball video that 
they wish to search. 
 
A. Performance Analysis 
The score, outs and innings do not change quickly during 
baseball games. Therefore, real-time processing (30 frames per 
second) of the caption contents could be achieved, a capture rate 
of 2.5 frames per second in order was used in order to 
coordinate with the time required to update the caption after the 
occurrence of an event (about 3 to 3.5 seconds).  
Four complete baseball game videos, comprising 11 hours of 
video content, were utilized to test the performance of the 
proposed system. Observation results yielded 98 events. Table 2 
illustrates the performance of the highlight event decision 
system in terms of the recall (R) and precision (P). The model-
based, rule-based, and integrating approaches had recall rates of 
92.8%, 85.1%, and 92.8%, and precision rates of 81.2%, 
73.65%, and 84%, respectively. The table indicates that only 
two highlight events, namely the one-base hit (1B) and base on 
ball/walk (W), were not detected accurately. This is because 
these two events are easily confused from caption information. 
Additionally, the single base hit (1B) occurs because a news 
ticker running on screen following the single base hit interferes 
with the system, causing a missed event. Furthermore, the recall 
rate of double play (DP) was low because this inning after a 
double play happened is immediately over and the caption 
information is disappeared, so the proposed approach employed 
could not immediately detect the double play. Finally, the rule-
based approach utilizes the rule decision, and the order in which 
rules occur affects the result of the event decision. Therefore, 
the proposed approach is visually superior to the model-based 
and rule-based approach.  
 
B. Discussion 
In the proposed system, the system begins to detect a 
highlight event only when numbers in the caption other than the 
amount of balls and strikes are changed. This decision was made 
because a change in the number of strikes or balls does not itself 
amount to a highlight event. Our main consideration was that if 
a change in the numbers of balls and strikes triggered the system 
to detect an event, then it would probably detect a false alarm of 
highlight events. This is because the highlight events include 
situations involving no change in score, runners on base, or 
innings. 
The integrating approach is presented by the knowledge 
representation, including the rule-based and model-based 
approaches, and used to compare their characteristics with 
respect to their maintainability and decision accuracy. The 
model-based approach is more appropriate for knowledge 
maintainability, flexibility, and decision accuracy than the rule-
based approach.  
Although having good classification results, the proposed 
system needs other features (audio and visual information) to 
improve the performance of the system. However, this system is 
also more likely to cause a non-event to be detected and 
classified. Conversely, a model-based decision approach needs a 
clearly defined model value to detect and classify an event. This 
requirement significantly reduces the potential for a confused 
recognition or classification, which primarily occurs when a 
batter strikes out or is put out. 
 
V. CONCLUSIONS 
This study proposes an integrating decision approach for an 
automatic highlight event extraction system and takes the 
advantages of the rule-based and model-based approaches. 
Experimental results indicate that the proposed approach for 
determining the highlight events is efficient and fast when 
applied to the baseball games. Moreover, comparing the 
proposed approach with the two decision approaches indicates 
that the process of extracting the highlight event is very helpful 
for improving the decision performance. 
 
ACKNOWLEDGEMENT 
The authors would like to thank I-Shu University and the 
National Science Council of the Republic of China, Taiwan, for 
financially supporting this research under Contract No. 96-2221-
E-214-054-MY2. 
 
1334
