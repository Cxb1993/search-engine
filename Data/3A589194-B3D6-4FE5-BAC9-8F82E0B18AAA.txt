i 
 
目錄 
中文摘要 ................................................................................................................................... 1 
英文摘要 ................................................................................................................................... 1 
一、計畫動機和背景 ............................................................................................................... 2 
二、計畫創新與重要性 ........................................................................................................... 4 
2.1  移動式機器人平台 .................................................................................................. 4 
2.2  網路資料傳遞 .......................................................................................................... 5 
2.3  Android 系統手機程式製作 ................................................................................... 5 
三、文獻回顧 ........................................................................................................................... 5 
3.1  『行動載具』國內外相關研究 .............................................................................. 5 
3.2  『手機作業系統應用程式』國內外相關研究 ...................................................... 6 
四、進行步驟 ........................................................................................................................... 8 
4.1  研究流程圖 .............................................................................................................. 8 
4.2  研究方法與原因 ...................................................................................................... 9 
五、成果與測試 ..................................................................................................................... 13 
六、結論 ................................................................................................................................. 13 
參考文獻 ................................................................................................................................. 14 
 
 
 
2 
 
一、計畫動機和背景 
隨著手持式通訊設備(Hand-on Communicator)和個人數位助理(PDA)的結合，
許多智慧型手機紛紛上市，從 Nokia 公司慣用的 Symbian 作業系統[1]，以及早
期市場至有率比較高的 Palm 作業系統[1]，將人們對手機功能使用提升到另外一
個境界，接著各個大廠紛紛推出應用於手持式裝置上的作業系統，例如 Microsoft
的 Win CE，以及更新的 Pocket 2002，Pocket 2003，接著則是最後定案的 Windows 
Mobile 作業系統，目前最新為 Windows Mobile 6.5 版本[2]，由於與 Microsoft 的
PC 上面的作業系統相近，因此很快的及成為市場使用率最高的智慧型手機系
統。 
之後由 Apple 公司推出的 iPhone 手機[3]，由於多點觸控，指尖滑動等親和
性的介面操作，很快的即虜獲了大眾的喜愛，很快的成為市場上佔有率最高的智
慧型手機。然而上述的作業系統大多屬於封閉式的作業系統，也就是核心部分程
式並未全部公開，因此對應用程式開發者有一定的入門門檻。 
Google 公司以全開放式原始碼的方式，正式宣佈了 Android 作業系統[4]，
並開發了搭配了 Android 作業系統的智慧型手機 Google G1，國內則有 HTC 的
Magic 手機和 Hero 手機，以及最新的 Tattoo 手機。由於開放的原始碼，因此許
多應用程式開發者紛紛投入，使得 Google Market 上面各式各樣的應用程式應有
盡有，也造成 Android 作業系統一股新風潮。 
此外自從遠雄建設推出遠雄二代宅以來，數位化生活的相關研究開始蓬勃發
展，許多支援數位生活方式的科技紛紛被推出，分別應用於家居保全、居家照護
等等，例如家電的遠端遙控，居家安全的遠端監控，老人的居家生理監控等等，
利用數位技術於家庭生活中的應用研究，已成為當今一項重要的應用研究課題。
試想以下的場景： 
【場景一】在一個有老人的家庭中，年輕人都外出上班，只剩家中生病或是行動
 二
體製
傳遞
 
2.1 
台功
、計畫創新
本計劃結
作，因此在
，Android
移動式機
本計劃中
 
該機器人
能，不同於
與重要
合移動式機
計畫中主
系統手機
器人平台 
將創新以 W
圖
平台為 Wo
以往的居
性 
器人平台
要有幾項重
程式製作
owWee 公
一、WowW
wWee 公司
家保全機器
4 
，網路，語
點，分別
，而其創新
司的 Rovi
ee 公司 R
 
於 2009 年
人，其體
音與影像傳
為：移動平
性與重要性
o 為主要發
ovio 平台[
的新產品
積小，功能
輸，智慧
台之控制
茲分別敘
展平台，如
5] 
，結合了玩
齊全，更
型手機平台
，網路之資
述如下： 
下圖所示
具與機器人
適合於一般
軟
料
: 
 
平
家
6 
 
出鄉間道路的路面，控制車輛行進於道路上面，並辨識出前方車輛，以
避免碰撞，達到行車安全。 
C. 1996 年 Dr. Youself [8]則是提出以預測控制來預先估測無人駕駛車輛的
行進位置，藉以控制車輛的行進路線，修正行車擺盪的缺點。 
D. 2001 年 Dr. Yun [9]等人則是發展出以無線電介面遙控無人駕駛車輛的
行車模擬系統，位無人駕駛提供一個軟體模擬的方向，減少實驗所浪費
的時間。 
E. 2001 年的 Dr. Setchell [10]等人則是提出再道路十字路口中裝置許多的
CCD，並以影像辨識車輛，藉以推算道路流量，藉以作為遠端交通監控
的依據。 
F. 2000 年的 Dr. Albus [11]則是以影像回授，在配合模型性能參考追蹤的
控制方式，來控制無人駕駛車的自動駕駛。 
 
3.2 『手機作業系統應用程式』國內外相關研究 
A. Symbian 系統：Symbian 作業系統是目前業界使用的手機系統標準之一
[12]，是一種開放式的作業系統，讓使用者可以自由安裝相關的應用程
式或軟體 (程式為 .sis 的副檔名)，有些類似 Java 的功用。因此我們可
以說 Symbian 之於手機的關係，就好像 Windows 作業系統之於電腦一
般。和 Java 不同的是，Symbian 的運算能力更強，能處理及下載更複雜
的應用程式。Symbian 系統的手機也支援同步多功的執行，比如說使用
者可以一邊發 MMS 多媒體訊息、一邊切換至手機遊戲、然後又開啟行
事曆查詢記事等，Symbian 系統允許多種應用程式同時在手機上執行，
且能自由的切換視窗不受影響。 
B. Windows Mobile 作業系統：Windows Mobile 作業系統[2]，簡稱 WM，
8 
 
也進入了開發階段。 
 
四、進行步驟 
4.1 研究流程圖 
 
圖二、研究流程圖 
移動式機器人平台選用
Rovio API 研讀
Android SDK/ JAVA
Android in Rovio
語音、影像、巡
邏功能測試
1. 具有語音對談功能的陪伴機器人
2. 具有影像傳遞功能的保全機器人
3. 具有巡邏功能的自走機器人
YES
NO
10 
 
 Rechargeable NiMH battery pack included  
 1 x charging dock with built-in TrueTrack beacon  
 x wheel motors  
 x omni-directional wheels  
 1 x camera motor  
 1 x VGA CMOS sensor  
 LED illumination  
 1 x speaker  
 1 x built-in microphone  
 USB connectivity  
 WiFi connectivity (802.11b and 802.11g) 
二、Rovio API 的研讀：Rovio 本身完成了底層的硬體溝通動作，並提供中介
軟體(Middle ware)介面應用的 API 讓使用者可以自行設計介面，並以 CGI
的命令方式呈現，如[15]所示，而其 API 則分為如表一所示的幾個類別呈
現，分別可以控制其行動，影像，和語音，完成計畫所需的各項功能。 
表一、Rovio API 列表[15] 
Category  CGI Commands  Description  
Movement  Rev.cgi  Refer to Movement Command 
table  
Camera 
Control  
GetData.cgi  Get MJPEG  
 GetImage *  Get Image  
 Video Streaming *  Stream Video  
 ChangeResolution.cgi  Change the resolutions of camera's 
images.  
 ChangeCompressRatio.cgi  Change the quality setting of 
camera's images.  
 ChangeFramerate.cgi  Change the frame rate setting of 
camera's images.  
 ChangeBrightness.cgi  Change the brightness of camera's 
  
Oth
 
 
 
 
 
 
 
 
三
er  
、Android
利用 ja
軟體[16
影像，
SendMail
SetName
GetName
GetStatus
GetLog.c
GetVer.cg
SetFactor
Reboot.cg
GetData.c
GetAudio
 in Rovio：
va 語法完成
]，即是透
並可以操控
.cgi  
.cgi  
.cgi  
.cgi  
gi  
i  
yDefault.cg
i  
gi  
.cgi  
此部份則是
系統所需
過 Android
與對話，
圖四、An
12 
i  
要將Rovi
的功能，例
手機操控
其畫面如圖
drovio 軟體
Send an 
images. 
Set nam
Get cam
Get run-
Get IP C
informat
Get IP C
Change 
factory-d
Reboot I
Get imag
"multipa
mime-ty
Send aud
at  
o的API透
如 Googl
Rovio 平台
四所示。
操作畫面
email with 
 
e of the cam
era's name.
time status 
amera's sys
ion.  
amera's ver
all settings 
efault.  
P Camera. 
es/status w
rt/x-mixed-
pe.  
io to serve
過Android
e Market 中
，可以觀
 
IPCam 
era.  
  
of Rovio. 
tem logs 
sion.  
to 
 
ith 
replace" 
r and playb
系統的SD
的 Androv
看其 webc
 
ack 
K，
io
am
14 
 
資料傳遞，透過無線網路，將機器人上面 webcam 的影像和麥克風的語音傳遞到
遠端操控者畫面，允許操控者遠端控制 Snapshot，以及語音交談。透過 Android
系統手機程式製作，WowWee 提供 Rovio 程式設計 API，可以輕易轉移到智慧型
使池系統。預計將來將再開發更郭功能軟體，並放置於自由軟體平台，提供自由
使用。 
 
參考文獻 
[1] http://sj.91.com 
[2] http://www.microsoft.com/taiwan/windowsphone/?WT.mc_id=windowsmob
ile 
[3] http://www.apple.com/tw/iphone/apps-for-iphone/ 
[4] http://www.android.com/ 
[5] http://www.wowwee.com 
[6] Naranjo, J.E., González, C., Reviejo, J., García, R. and Pedro, T.D., “Adaptive 
Fuzzy Control for Inter-Vehicle Gap Keeping,” IEEE Trans. on Intelligent 
Transportation Systems, pp. 132-142, 2003 
[7] Kato, S., Tomita, K. and Tsugawa, S., “Visual Navigation Along Reference 
Lines and Collision Avoidance for Autonomous Vehicles,” IEEE Proc., pp. 1-6, 
1996. 
[8] Youself, A., “Predictive Control Strategy for Unmanned Vehicle Navigation,” 
American Control Conference, pp. 4111-4115, 1996. 
[9] Yun, D.S., Shim, J.H., Kim, M.S., Park, Y.H. and Kim, J.H., “The System 
Development of Unmanned Vehicle for The Tele-Operated System Interfaced 
With Driving Simulator,” IEEE International Conference on Robotics and 
16 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
   █   達成目標 
□ 未達成目標（請說明，以 100字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表  □未發表之文稿  █撰寫中  □無 
專利：□已獲得  □申請中  █無 
技轉：□已技轉  □洽談中  █無 
其他：（以 100字為限） 
 
        上傳自由軟體平台，提供自由下載使用。 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
 
本計畫完成之 Rovio機器人之應用軟體具有以下的功能： 
 居家巡邏：自動於家中巡邏，並可檢視影像。 
 居家照護：可傳遞影像，檢視家中老人或小孩之活動情形。 
 居家保全：可傳遞影像，檢視家中環境狀況。 
 居家娛樂：可遙控操作，提供娛樂遊戲。 
預計可推行於社會老年化—橘色科技盛行，應用於 
 居家照護 
 居家保全 
 居家陪伴 
 
 
皆可以窺見機器人未來的發展與研究趨勢，對於機器人研究的學者是一個非常好的
交流學習場所。 
 
三、建議 
上海交通大學人數眾多，在國際上的學術地位雖然已很高，但是仍保有強烈的
企圖心，並追求高度的國際化，例如此次的 ICIRA2010 是一個機器人研究綜合性的
研討會，包含各個領域，因此與會人員也特別多，此次會議於高級飯店舉行，效果
良好，給予人深刻的印象。建議國內學校可以爭取舉辦，增加學校知名度，並透展
國際視野。 
 
四、攜回資料名稱及內容 
論文集和光碟。 
 
UAV moves along the predefined road, usually marked by black taps. Hence, it is 
difficult to change the designed route. In recent decades, the machine vision is great 
developed. In robotics and automation, the application of vision guided has also been 
widely used in many practical aspects. Such as Ref. [1], the CCD is installed in the 
operation robotic arm bottom. The fine-tuning makes the accuracy operation finished. 
The CCD is also used in the cross road to monitor the road-traffic [2]. In Ref. [3-4], 
the mobile robotic uses the mechanical vision to complete the target tracking. In Ref. 
[5], the unmanned vehicle successfully went on urban-like road. In these relevant 
researches, the vision-based application is proven to be feasible and practical. 
In this paper, a machine vision based UAV is developed to examine the capability 
of vision-servo. A web cam is installed in the notebook. This notebook placed upon 
the UAV is used to handle the calculation of relevant image process. Use the image 
processing strategy to distinguish the obvious target at the both side of the lane. Then, 
find the middle point of targets of both side and follow it to finish the unmanned 
driving. By vision guidance, the UAV can cooperate with the flexible manufacturing 
systems and alternate the route anytime. However, due to the complicate calculation 
of image process, it will take a long calculation time from fetching image to making 
image information. As shown in Fig. 1, the position 1 is the position at the time of 
fetching image. The real position after image process is position 2. Hence, the real 
position error is position error 2 not position error 1. In the application of vision-based 
following, this incorrect of position error will cause the automatic vehicle to produce 
the swinging phenomenon [3-4]. In order to eliminate the swinging phenomenon, 
most of researches reduce the vehicles’ speed. The other method is to reduce the 
revising rate of angle of vehicles while target tracking. No matter what kind of 
mentioned above methods, it will reduce the practicability while in application. 
Position (1)
Set Point
Position (2)
Position error (1)
Position error (2)
 
Fig. 1. Diagram of Error of the Image 
In order to improve the above mentioned drawback, a novel two-layer fuzzy 
control rule is proposed in this paper to guide the UAV based on vision servo 
feedback. The base-layer controller consists of the classical fuzzy controller. The 
upper-layer controller consists of the grey prediction based fuzzy controller. The two-
layer fuzzy controller will guide the UAV based on vision feedback under the 
conditions of not to decrease driving speed and the revising rate of angle. The 
 Fig. 2. Experimental Result of Image Processing 
Grey-Fuzzy-Fuzzy Control 
Fuzzy Control 
The proposed controller is based on the classical fuzzy rule. Hence, the design 
procedures of the fuzzy rule are Fuzzification, Fuzzy Inference and Defuzzification. 
In order to fuzzify the input variables, the membership functions should be defined 
firstly. To simplify the relevant calculation, the triangular and trapezoidal 
membership functions are used in this paper. The range of the angle error from -75 to 
+75 is equally divided into five triangular membership functions and two trapezoidal 
membership functions. The range of the angle error difference (-50~+50) and the 
output voltage (-10V~+10V) of revising angle are divided by the same rules. 
The Mamdani typed fuzzy inference is used in this paper, that is the MIN-MAX 
method. Use the linguistic description, that is the rule of If-Then, to decide the output 
relationship. The eq. (1) is one example of those descriptions. 
(
a)
(
b)
(
c)
(
d)
Accumulated Generating Operation (IAGO) is the inverse operation of the integral 
approximation. According to the AGO and IAGO, the time-series data can be 
described as  
   ieie )0()1( AGO  
where 
    3,2,1,0for33
3
)0()1(  

ijkeike
i
j
 
and 
   ieie )1()0( IAGO  
      2for1)1()1()0(  iikeikeike  
    3for33 )1()0(  ikeke  
In Ref. [9], the Grey Model which is the first order and has one variable is defined 
as eq. (1). 
    ba )1()1(  ikmike  (1) 
where 
       1,2,3for1
2
11 )1()1()1(  iikeikeikm  
By the Least-Square method, the parameters of the Grey Model can be figured out, 
like eq. (2). 
 
 
 
 
 
 
 
 
 
 
 
  






















































kE
kE
kE
km
km
km
km
km
km
km
km
km
TT
)0(
)0(
)0(
)1(
)1(
)1(
1
)1(
)1(
)1(
)1(
)1(
)1(
1
2
1
11
12
1
11
12
1
11
12
b
a
 (2) 
Once obtaining the parameters of the Grey Model, the next status can be estimated 
like eq. (3). 
   
a5.01
ab1~
)0(
)0(

 keke  (3) 
and 
    Bias1~1~ )0(  keke  
 Fig. 5. Experimental UAV 
The notebook of the Pentium grade deals with the hardware input/output control 
and the necessary software calculation of the image processing and the proposed 
controller. The human machine interface is programmed by the software of 
LabVIEW1 and Matlab/Simulink2. A web cam is connected with the notebook by the 
USB connector, which is used to grab image of front direction of vehicle. Through the 
printer port, the 8-bits pulse width modulator prototype board is used to control the 
both DC motors drive the both-side wheels. Two headlights are installed in the front 
of the vehicle. They will be turn-on to increase the color contrast when the driving 
direction detection failed. 
Experimental Results 
The experiment is carried out in the corridor of the teaching building of I-Shou 
University in Taiwan. The moving ahead speed of the UAV is maintained at the 
maximum speed that is 2.5km/hr. By mechanical vision-based distinguishing the 
baseboard of both side-walls, the UAV moves along the center of the corridor.  
Three controllers of Grey-Fuzzy-Fuzzy, Fuzzy and PID are compared under 
different environment. The parameters of the PID controller are: 3PK , 
1.0IK  and 3.0DK . When the light is bright and the AGV walks along the 
clean corridor, the experimental results are shown in Fig. 6. Obviously, the Grey-
Fuzzy-Fuzzy controller can offer the more comfortable auto-driving. The Fuzzy 
controller also has the perfect performance. However, the PID controller will shows 
the great swinging driving phenomenon. 
                                                          
1 The LabVIEW is the trademark of NI CO. 
2 Matlab and Simulink are the trademark of Mathworks CO. 
Conclusion 
The Grey-based two-layer fuzzy controller is applied to vision guided UAV. The 
detailed design procedures are described in this paper. Due to the long time from 
fetching image to make image information, applying the classical controller, such as 
the PID controller, will have the swinging phenomenon. Hence, the Grey prediction is 
used to estimate the position at the time finishing making image information. 
Combining the Grey prediction with the fuzzy control rule, the novel two-layer fuzzy 
controller is proposed in this paper. The experimental results show the significant 
performance in eliminating the swinging phenomenon. More smoothly following lane 
driven can be observed in the experimental results compared with the PID and Fuzzy 
controllers. 
References 
1. S.J. Ralis, B. Vikramaditya, and B.J. Nelson, “Micropositioning of a Weakly Calibrated 
Microassembly System Using Coarse-to-Fine Visual Servoing Strategies,” IEEE Trans. 
on Electronics Packing Manufacturing, pp. 123-131, 2000. 
2. C. Setchell and E.L. Dagless, “Vision-Based Road-Traffic Monitoring Sensor,” IEE 
Proc.-Vis. Image Signal Process, pp. 78-84, 2001. 
3. R.C. Luo and T.M. Chen, “Autonomous Mobile Target Tracking System Based on Grey-
Fuzzy Control Algorithm,” IEEE Trans. on Industrial Electronics, pp. 920-931, 2000. 
4. R.C. Luo, T.M. Chen and K.L. Su, “Target Tracking Using Hierarchical Grey-Fuzzy 
Motion Decision-Making Method,” IEEE Trans. on Systems, Man, and Cybernetics—
Part A: Systems and Humans, pp. 179-186, 2001. 
5. M.A. Sotelo, F.J. Rodriguez and L. Magdalena, “VIRTUOUS: Vision-Based Road 
Transportation for Unmanned Operation on Urban-Like Scenarios,” IEEE Trans. on 
Intelligent Transportation Systems, pp.69-83, 2004. 
6. L.A. Zadeh, “Outline of a new approach to the analysis of complex systems and decision 
processes,” TEEE Trans. on Systems, Man, and Cybernetics, pp. 28-44, 1973. 
7. C.C. Lee, “Fuzzy logic in control systems: fuzzy logic controller – Part I,” IEEE Trans. 
on Systems, Man, and Cybernetics, pp.401-418, 1990. 
8. C.C. Lee, “Fuzzy logic in control systems: fuzzy logic controller – Part II,” IEEE Trans. 
on Systems, Man, and Cybernetics, pp.419-435, 1990. 
9. J.L. Deng, “Control problems of grey systems,” Systems & Control Letters, pp. 288-294, 
1982. 
10. H.M. Feng and C.C. Wong, “An on-line rule tuning grey prediction fuzzy control system 
design,” Proceeding of IEEE, pp.1316-1321, 2002. 
11. Y.P. Huang and C.C. Huang, “The integration and application of fuzzy and grey 
modeling method,” Fuzzy Sets and Systems, pp.107-119, 1996. 
12. C.W. Chuang and C.H. Chou, "Motion Control of X-Y Table by Sliding Mode Control 
with Position Compensator in Feedback Loop," The Sixth International Conference on 
Automation Technology, pp. 677-682, 2000. 
13. S.J. Huang and C.L. Huang, “Control of an Inverted Pendulum Using Grey Prediction 
Model,” IEEE Trans. on Industry Applications, pp.452-458, 2000. 
14. Y. Lee and S.H. Zak, “Uniformly Ultimately Bounded Fuzzy Adaptive Tracking 
Controllers for Uncertain Systems,” IEEE Transactions on Fuzzy Systems, pp. 797-811, 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/07/08
國科會補助計畫
計畫名稱: 結合Android系統上具影像、巡邏、語音的家用遊戲保全機器人軟體平台製作
(開放軟體元件開發分項)
計畫主持人: 莊景文
計畫編號: 99-2220-E-214-002- 學門領域: 自由軟體暨嵌入式系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
