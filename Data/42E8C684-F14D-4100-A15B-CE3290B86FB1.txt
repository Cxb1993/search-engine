 2
行政院國家科學委員會專題研究計畫成果報告 
 
使用投影不變量作人臉特徵擷取、表示與辨識的研究 
 
計畫編號：NSC 94－2213－E－130－018－ 
執行期間： 94 年 8 月 1 日至 95 年 7 月 31 日 
計畫主持人：賈叢林教授 
計畫參與人員： 林家全、林俊達、李紋毅 
 
ABSTRACT 
A new fast method for verifying human faces 
using geometric invariant is proposed. The proposed 
method has the properties of geometric invariants in 
background changes, illumination, translation, 
scaling, and rotating problems. The method includes 
locating and segmenting the facial image, extracting 
the facial features, and implementing recognition 
processes. Only 25 sets of cross ratios are needed to 
compare faces in the matching process in order to 
identify whether the query image exists in the 
database or not. The computational cost of the 
proposed method is significantly reduced in both 
processing and matching time for real time 
application. Several experimental results are given 
that show the proposed method is feasible and 
effective for real time application to face detection. 
 
1. INTRODUCTION 
 
Biometrics is an authentication system using 
personal biometric nature to verify user access rights. 
Some unique and physiological natures are 
measurable and applicable to perform authentication 
procedure for human recognition in real time 
application. In general, a password and personal 
identification code is easy to guess or steal, resulting 
in some stealthy lawbreaking activities in intranet or 
the Internet. A magnetic card or smart card may also 
be stolen, lost, damaged, duplicated, or rendered 
unreadable, causing security problems. A person may 
lose his identification card or forget his login 
password but, under normal circumstances, it’s 
impossible to lose fingers, eyes, or some other facial 
features. Hence, biometrics is widely applied for 
medical examination, banking, communication, and 
security systems. 
Biometrics includes faces, fingerprints, 
palm-prints, voice, signature, eyeball iris recognition, 
and DNA sorted matching, etc. In this report, a 
non-invasive method of human face recognition that 
doesn’t involve touch is proposed in order to capture 
information for recognition. Capturing human face 
information for detection is easier than for fingerprint 
or retina. Face recognition is a visual task that 
humans can do effortlessly. However, this task is 
difficult in biometrics. Features of humans such as 
age, gender, or face appearance are important and 
effective factors for authentication. Since facial 
features are symmetrical in nature, their sizes, colors, 
shapes, and locations may result in high degree of 
variability in a person’s appearance. Facial features 
such as eyebrows, eyes, nose, and mouth are more 
noticeable than other facial areas. Consequently, the 
solution of face recognition involves segmentation, 
extraction and verification of facial features. 
Face recognition is currently a very difficult and 
attractive research issue in which technology has 
come a long way since the beginning of the 1970s. A 
wide variety of techniques have been proposed, 
ranging from image-based approaches to complex 
computational geometric-based approaches.  During 
the last decade, considerable progress has been made 
in face recognition research [1-2]. Several major 
developments in face recognition approaches can be 
further described as follows: 
(1) Template matching [3-5] 
Template matching is an image-based technique. The 
gray level distribution of human facial image is 
extracted as a template model. Each query is 
conducted according the method of the template 
model to yield a facial feature. Comparing the 
features of the query image with the given feature 
base, the best matching result is returned according 
the similarity and correlation of facial features. This 
approach can preserve the information of facial shape, 
frame, and features but the cost of matching time and 
storage space are very high. 
(2) Deformable template [6-7] 
The deformation mechanism involves the steepest 
gradient descent minimization of a combination of 
external energy due to valley, edge, peak, and image 
brightness [6]. A deformable eye or mouth template 
based on salient features uses several parameters to 
control and align it in order to improve the reliability 
of the extraction result and use those parameters to 
indicate facial features. However, a deformable 
template is sensitive to its initial position. The 
computational cost is also very high due to the 
sequential implementation of the minimization step. 
Contemporary research in this approach has mainly 
concentrated on issues such as computational cost 
reductions, template modifications, and energy term 
considerations [1]. 
(3) Eigenfaces [8-9] 
Using an N×N dimensional image as an 
N2-dimensional vector to indicate a facial image, in 
other words a human face, can be considered as 
 4
2.2. Characteristics of cross ratio on polygon 
Because the sensed images of a polygon will vary 
with different viewpoints or angles, it is important to 
looking for a comprehensive solution that will not be 
affected by environment changes. The cross ratio is a 
good method to apply to two very similar polygons 
and can exactly classify their differences. In this 
section, the geometric relationships of the cross ratios 
of a polygon in a three-dimensional spatial plane and 
a two-dimensional image plane are provided. In order 
to describe the polygon in a three-dimensional spatial 
plane and its projection, Figs 2 and 3 show the 
definition of the spatial plane and the projective plane, 
respectively. For polygon ABCDEF, starting from 
point A, going counterclockwise to connect AB , 
AC , AD , and AE , their projections are '' BA , 
''CA , ''DA , and '' EA , respectively. In Fig 2, let 
ACR  be the cross ratio of focal point A, and 'ACR  
the cross ratio of focal point A’. So, 'AA CRCR =  
needs to be proved.  
Assume that a line L in Fig 2 intersects with 
lines AB , AE , AC , AD  and their focal points are 
P1, P2, P 3, and P4, respectively. Accordingly, the 
geometric projection of polygon ABCDEF from 
viewpoint O is given in Fig 4. Thus the following 
equation is obtained. 
)',',','(),,,( 43214321 PPPPCRPPPPCR OO =       (5) 
Likewise, view point A is a focal point of four 
lines AB , AE , AC , and AD . Viewpoints A and O 
indicate two different views on the four points P1, P2, 
P3, and P4, such that 
),,(),,,( 3214321 θθθAO CRPPPPCR =       (6) 
Hence,  
)',','()',',','( 321'4321 θθθAO CRPPPPCR =       (7) 
One gets from Equations (6) and (7), that  
)',','(),,( 321'321 θθθθθθ AA CRCR =         (8) 
From (8), it is proven that a cross ratio of a 
three-dimensional spatial plane can be obtained if the 
cross ratio of the two-dimensional sensed image 
plane is given. 
 
2.3. The relationship between facial feature point 
and cross ratio 
Equation (8) indicates that we can use the 
characteristic of cross ratio of geometric invariant to 
identify the spatial plane of polygon. Facial features 
such as nose, eyes, mouth, etc., can be considered as 
several feature points lying on the sensed image plane. 
The facial features can be extracted according their 
differences in size, location, and distance. After facial 
feature points are obtained, given one certain point as 
a base point and taking an additional four 
non-collinear points, this yields a facial feature in 
terms of a polygon. Hence, the cross ratios of vertices 
of the polygon are invariant. This invariant 
characteristic is applied for face detection.  
3. The extraction of human facial features 
Some useful feature points must be given first 
before the values of cross ratios are calculated. The 
interesting facial features include the four points at 
the corners of the eyes, two points at the corners of 
the mouth, and two points of earlobes. Those features 
are reliable and have noticeable difference in each 
facial appearance. Although the eyebrows show a 
high degree of feature individuality, they are useless 
for cross ratio calculation because it is not easy to 
find a representative feature point. The nostril feature 
is also unsuitable as a feature point because the 
slanting pose results in this feature becoming 
invisible. Fig 5 shows the system flow of feature 
point extraction.  
 
 
3.1. Preprocessing of facial image 
In general, the face detection process can be 
Preprocessing Feature 
Extractio
Input 
imag
Feature 
points given
Fig 5. The flowchart of feature points extraction 
 
 
 
 
 
   
 
 
 
'
1θ
'
2θ
'
3θ
'
1P
'
2P
'
3P
'
4P
'E
'A
'B
'C
'D
'F
'L
Fig 3. Projective plane of polygon 
A 
B C 
D 
P1 
P2  
P4 
3θ
2θ
E 
Fig 2. Spatial plane of polygon 
P3 
Fig 4. Geometric relationships of planar projection of 
polygon 
A
B
C
DE
F
L
L’ 
Image 
Plane 
O 
 6
, 1 , 1
1( , ) ( , ), ( , )
n n
C C
x y x y
X Y x M x y y M x y
m = =
⎡ ⎤= ∗ ∗⎢ ⎥⎣ ⎦∑ ∑
  (12) 
B. Calculation of the angle of principle axis 
Since facial features are symmetrical in nature 
and the shape of face is similar to an ellipse, it is easy 
to find a principle axis passing through the centroid 
of facial area. Consequently, the slanting angle of 
principle axis can be calculated. First, a central 
moment is given according to the following equation. 
( ) ( ) ( , )p qpq c cu x X y Y M x y dxdy
∞ ∞
−∞ −∞= − −∫ ∫      (13) 
  p,q = 0,1,2,…,∞   
The orientation of principle axis can be given by 
2 2
( , ) 1 ( , ) 1
( ) ( , ) [( ) sin ( ) cos ]c cM x y M x yI D x y x X y Yθ θ θ= == = − − −∑ ∑    
(14) 
From [30], the angle is given by 
]
2
[tan
2
1
2,00,2
1,11
uu
u
−=
−θ                    (15) 
, ( , ) 1
( ) ( )p qp q c cM x yu x X y Y== − −∑          (16) 
When given the slanting angle of facial image, rotates 
the facial image to θdegree in order to get a straight 
pose of facial image for feature points extraction. The 
transformation of coordinates can be conducted by 
the following equation.  
⎥⎦
⎤⎢⎣
⎡⎥⎦
⎤⎢⎣
⎡ −=⎥⎦
⎤⎢⎣
⎡
1
1
2
2
cossin
sincos
y
x
y
x
θθ
θθ                 (17) 
 
3.2 Feature extraction 
Preprocessing is conducted in order to enhance 
the quality of a facial image for features extraction. 
The process of facial features extraction is provided 
in this section. Fig 9 shows the flowchart of human 
facial features extraction. 
 
 
 
Fig 9. The flowchart of facial feature points 
extraction 
 
(1) Binary thresholding 
 Assume an image R is the preprocessed resulting 
image with size n×n and the value of gray level is in 
the range from 0 to k. In this study, using 
segmentation to extract facial features follows 
preprocessing operations. Binary thresholding is a 
good solution in image segmentation. The goal of 
binary thresholding is locating the facial features and 
using white color to indicate these features’ area. 
Black replaces all other areas. Before proceeding to 
binary thresholding, the brightness of facial features 
is darker than that of other areas. Hence, when a 
threshold value of T is given, it is easy to identify the 
area of facial features if the value of R(x,y) is less 
than T. The resulting image RB(x,y) of binary 
thresholding can be expressed as follows. 
[ ]0, ( , )( , ) , 1,...,
255, ( , )B
if R x y T
R x y x y n
if R x y T
>⎧= ∈⎨ ≤⎩
(18) 
where the value of T can be decided according the 
gray level distribution if it is in dual peak mode, and 
the gray level distribution can be considered as a 
probability density function of gray level fR (k), that it 
can be defined by 
    fR(k) = Aa(k) + Bb(k)   A+B=1 
Assume a(k) and b(k) are a Gaussian distribution, 
given by 
   
2
1
2
11
1 ( )( ) exp
22
k ua k δπδ
⎡ ⎤−= −⎢ ⎥⎣ ⎦
2
2
2
22
1 ( )( ) exp
22
k ub k δπδ
⎡ ⎤−= −⎢ ⎥⎣ ⎦
         
 (19) 
where 1δ , 2δ , 1u , and 2u are variances and mean 
values of R, respectively. If 22
2
1
2 δδδ == , the 
optimum value of T can be given by 
2
1 2
1 2
ln( )
2
u u BT
u u A
δ+= + −
        (20) 
If A equal to B, then the value of T is the mean value 
of the two means.  
(2) Horizontal projection 
Image projection is one good solution for features 
extraction. It transforms two-dimensional image into 
one-dimensional linear space. So, the binary image is 
created by horizontal projection in order to find the 
horizontal location of facial features due to those 
features having high luminance and their horizontal 
projective values being higher than those of others. 
Besides, the eye and mouth shape is a long narrow 
strip that results in some higher peak value of 
horizontal projective result appearing. Those 
horizontal projective peak values mean that eyes, 
nose, and mouth exist in there. Assume RB(x, y) to be 
the binary value at coordinate (x, y); the horizontal 
projective result H(x) can be given by 
(a) The original image         (b) The background image 
Fig 8. The preprocessing flow and results 
(c) The difference image           (d) Closing 
operation
(e) Labeling connected 
component 
(f) Final result of preprocessing 
Binary  
Thresholding 
Preprocessed 
result 
Horizontal 
Projection
Vertical 
Projection
Facial 
feature 
points  
 8
feature points as the vertices of hexagon in terms of 
graphic expressions and our proposed 25 sets of cross 
ratios for face detection in (a) and (b), respectively. 
The vertices of the hexagon indicates the facial 
feature points that include the four points of the 
corners of the eyes (c, d, e, and f), the two points of 
the earlobes (b and g), and the two points of the 
corners of the mouth (a and h). 
 
4.2 The data type transformation  
     The data value range of cross ratio in real data 
type is wide and easily affected by the noise. So, the 
value of cross ratio in real data type may need a data 
transformation and the integer value bounded in an 
acceptable range for computational cost reduction. 
From our experiments, the possible integer value is 
equally divided into S pieces (s=100, for example); 
the boundary of each piece will be decided by the 
following procedure. For cross ratio be expressed in 
terms of angle, the bounds on three angles are given 
by 
  
⎩⎨
⎧
≤++≤
≤≤
oo
oo
1800
180,,0
321
321
θθθ
θθθ          (23) 
First, the three angles start from 0 degree and 
increase θΔ  each time to find the angle 
combination that can meet Equation (23) and 
calculate their cross ratio. The resulting cross ratio 
values are divided into S parts along the real value 
axis. The probability of each part is equal; therefore, 
a table of cross ratios of real values and their 
corresponding integer values is yielded. Using this 
mapping table, the cross ratio in terms of real data 
type is easy to transform in terms of integer data type. 
In our experiments, only 25 of 192 sets of cross ratios 
are stored in the features base according their priority 
order (see Fig 14(b)). Hence, the cost of mapping 
time is cheap because the order of cross ratio in 
mapping time is the same as that in the features base.    
4.3 Matching Process 
    There are two steps in our matching process. 
The first step is to try to delete some useless data and 
then try to find the best matching result from the 
given candidates in the second step. For the first step, 
four sets of useful cross ratios are applied and shown 
in Fig 15. Four points projected on a straight line in 
the facial area for cross ratio calculation are based on 
their feature point projections. In Fig 15(a), four 
points in a straight line are projected by the locations 
of eyebrows, eyes, earlobes, and mouth, respectively. 
The horizontal locations of the two earlobes and the 
corners of the mouth yield a four-point projection 
shown in Fig 15(b). The other projections are decided 
by the four corners of the eyes, two point of the 
earlobes, and the two points of the inner corners of 
the eyes that are shown in Fig 15(c) and Fig 15(d), 
respectively.  
In the second step, the method of voting is applied. 
When feature points are given, 25 sets of cross ratios 
are obtained according their largest value of 
variances. By matching each set of cross ratios, the 
top 10 smallest differences of possible cross ratios are 
assigned values one and up, iteratively proceeding 
until 25 sets of cross ratios are computed. Finally, 
counting the voting results of 25 sets of cross ratios, 
the candidate facial image with the largest score of 
voting result is output as a query response. However, 
if the scores of voting results do not reach a 
reasonable criterion, that means the query image does 
not currently exist in the database. So, the system 
rejects the query input.  
Fig 15. Four useful sets of cross ratios are used in 
the first matching step. 
(a)                      (b) 
(c)                   (d) 
Fig 14.  25 sets of cross ratios of evaluation 
measurements for face detection 
(b) 25 sets of cross ratios in terms of graphic 
expression 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11
12
13
15
16 
17 
18 
19 
20 
21
22
23
24
25
(a) The construction of facial 
ab
c d e f
g 
h
 10
6. Conclusion 
A fast method for verifying human faces using 
cross ratio has been proposed. The proposed method 
includes the following steps: (1) giving a background 
image, (2) conducting a facial image extraction, (3) 
preprocessing the extracted result, (4) extracting 
feature points, (5) calculating cross ratios, and (6) 
matching. Face detection is currently a very active 
research area but there is still a long way to go to 
develop a new approach since the survey of Hjelmas 
and Low [1]. Currently, several approaches have 
shown great advances in algorithms dealing with 
complex environments. Some of the best algorithms 
are still too expensive in computational cost for real 
time application. The human face is a dynamic object 
because of the difficulties posed by changes in faces 
over time together with variations in pose. It is still 
hard to develop a robust face detection algorithm for 
computer vision systems. A geometric projective 
invariant method applicable for real time application 
is proposed in this study. Cross ratios of a facial 
image’s feature points are applied to yield a 
geometric configuration of facial features that vary 
within a great noticeable range. The proposed method 
indeed solves some of the problems encountered such 
as glasses, slanting pose, complex background, 
scaling, and varied illumination. The main 
advantages of the proposed method can be 
summarized as follows: (1) the theory of projecting a 
three-dimensional object into a two-dimensional 
sensed image is extended to face detection. (2) The 
geometric relationship of feature points can be 
obtained from cross ratios calculation but not from 
three-dimensional coordinate calculation. (3) A 
geometric invariant method solves the problems of 
rotation, translation, and scaling. (4) Storage of only 
25 sets of cross ratios can reduce the computational 
cost and matching time in the features base. (5) The 
proposed method is applicable not only to face 
detection but can also be a preprocessor in biometrics 
which can further combine voice, fingerprints, retina 
and lip movement recognition for user access 
authentication. The experiment results reveal the 
feasibility and efficiency of the proposed approach. 
 
References 
1. Hjelmas, E and Low, B. K., “Face detection: a 
survey,” Computer Vision and Image 
Understanding, vol. 83, pp. 236-274, 2001. 
2. Kouzani, A. Z., He, F., and Sammut, K., 
“Towards invariant face recognition,” Information 
Sciences, vol. 123, pp. 75-101, 2000. 
3. Brunelli, R., and Poggio, T., “Face recognition: 
features versus templates,” IEEE Trans. Pattern 
Analysis and Machine Intelligence, pp.1042-1052, 
1993. 
4. Holst, G., “Face detection by facets: combined 
bottom-up and top-down search using compound 
templates,” in Proceedings of the 2001 
International Conference on Image Processing, p. 
TA07.08, 2000. 
5. Uang, L.-K., and Wang, M.-J., “Efficient shape 
matching through model-based shape 
recognition,” Pattern Recognition, vol. 29, pp. 
207- 215, 1996. 
6. Yuille, A. L., Hallinan, P. W., and Cohen, D. S., 
“Feature extraction from faces using deformable 
templates,” International Journal of Computing 
Vision, vol. 8, pp. 99-111, 1992. 
7. Tistarelli, M. and Grosso, E., “Active vision-based 
face authentication,’’ Image and Vision 
Computing, vol. 18, pp. 299-314, 2000. 
8. Turk, M., and Pentland, A., “Eigenfaces for 
recognition,” Journal of Cognitive Neuroscience, 
vol. 3, no. 1, pp. 71-86, 1991. 
9. Sung, K. K. and Poggio, T., “Example-based 
learning for view-based human face detection,” 
IEEE Trans. Pattern Analysis and Machine 
Intelligence, vol. 20, pp. 39-51, 1998. 
10. Samal, A. and Iyengar, P. A., “Human face 
detection using silhouettes,” International 
Journal of Pattern Recognition and Artificial 
Intelligence, vol. 9, no. 6, pp. 845-867, 1995. 
11.Shum, H. Y., Ikeuchi, K., and Reddy, R., 
“Principal component analysis with missing data 
and its application to polyhedral object 
modeling,” IEEE Trans. Pattern Analysis and 
Machine Intelligence, vol. 17, no. 9, pp. 854-867, 
Sept. 1995. 
12. Martinez, A. M. and Kak, A. C., “PCA versus 
LDA,” IEEE Trans. Pattern Analysis and 
Machine Intelligence, vol. 23, no. 2, pp. 228-233, 
Feb. 2001. 
13. Pentland et al., “View-based and modular 
eigenspaces for face recognition,” Tech. Rep 245., 
0
20
40
60
80
100
1 4 7 10 13 16 19 22 25
q u ery  image
datab ase image
0
20
40
60
80
100
1 4 7 10 13 16 19 22 25
query image
database
0
20
40
60
80
100
1 4 7 10 13 16 19 22 25
q uery  image
database image
Fig 19. The matching results in terms of 
cross ratios according to three possible 
regular appearance changes. 
(a) Without glasses 
(b) With glasses 
(c) With slanting pose 
 12
可供推廣之研發成果資料表 
▓ 可申請專利  ▓ 可技術移轉                          日期：95 年 8 月 15 日 
國科會補助計畫 
計畫名稱：使用投影不變量作人臉特徵擷取、表示與辨識的研究
計畫主持人：賈叢林教授 
計畫編號：NSC 94－2213－E－130－018－          
學門領域：圖形識別 
技術/創作名稱 使用投影不變量的人臉特徵擷取、表示與辨識 
發明人/創作人 賈叢林 
本技術為一套新的人臉辨識方法，利用交比值的幾何不變量特性，而能不受
背景、燈光、平移、稍微歪斜和臉部大小等因素所影嚮。此系統主要分為臉
部的定位和切割、臉部特徵之擷取及辨識三部份。人臉的定位和切割的方法
主要是運用數位影像處理的技術，將兩張影像相減及型態學的閉合運算等處
理，去除背景而留下臉部區域 。此外也計算其質量中心、對稱中軸和歪斜角
度，以將人臉轉正。第二階段，則是利用人臉五官左右對稱的特性，以及頭
髮、眼睛、鼻子與嘴巴等彼此之間的相關位置與灰階值變化的特性，找出各
部位初略的位置，再分別作水平與垂直投影，以求取更精確的特徵位置。第
三階段，則是將第二階段所擷取的特徵點，採用交比值的計算，做為辨識的
依據。實驗結果顯示以交比值的方法來作辨識，較不受外在環境的影響且增
進了比對速度。 技術說明 
A new fast method for verifying human faces using geometric invariant is 
proposed. The proposed method has the properties of geometric invariants in 
background changes, illumination, translation, scaling, and rotating problems. The 
method includes locating and segmenting the facial image, extracting the facial 
features, and implementing recognition processes. Only 25 sets of cross ratios are 
needed to compare faces in the matching process in order to identify whether the 
query image exists in the database or not. The computational cost of the proposed 
method is significantly reduced in both processing and matching time for real time 
application. Several experimental results are given that show the proposed method 
is feasible and effective for real time application to face detection. 
可利用之產業 
及 
可開發之產品 
IC smart card 的使用身份驗證。 
家庭或小型企業之門禁管理系統。 
技術特點 
1. 僅使用極少量的數值即可描述人臉的資訊。 
2. 具有抵抗多種幾何變形之能力。 
3. 比對計算時間極短，僅需要約 25 筆數字之比較。 
4. 使用生物認證與影像處理技術，具高度可攜性並符合人性需求。
