結合細菌優化與粒子群最佳化演算法設計雙眼立體視覺行動機器人 
Binocular Stereo Vision-Based Mobile Robot System Design by the Hybrid 
Bacterial Foraging and Particle Swarm Optimization Learning Algorithms 
計畫編號：NSC 100-2221-E-507-004 
執行期間：100年 8月 1日至 101年 7月 31日 
主持人  ：馮玄明   國立金門大學資訊工程學系 
 
摘要 
本計畫利用細菌優化粒子群最佳化演算法
(Bacterial Foraging optimization particle swarm 
optimization)、雙眼立體視覺 (Binocular stereo 
vision)、模糊推論系統 (Fuzzy Inference System)、
影像向量量化與分類 (Image Vector Quantization 
and Classification) 等理論與技術，完成立體視覺行
動機器人設計。  
立體影像辨識系統設計先以雙組 CCD 同時攫
取雙影像並透過雙眼立體影像深度公式估測第三
維度的距離，輔以影像處理技術重建物體影像之外
圍輪廓特徵，逐步回饋外在視覺資訊以建置空間資
訊。另外，本計畫以空間資訊中各障礙物在行進路
徑中位置與各種不同角度，辨識出其正確方位座
標，建立機器人路徑地圖，利用 BFPSO 完成模糊
的建立工作，完成系統立體影像模擬與避障實
驗。 
關鍵詞：行動機器人；雙眼立體視覺；細菌優
化粒子群最佳化演算法；模糊系統。 
Abstract 
The binocular stereo vision-based mobile robot 
systems are developed by the bacterial foraging 
particle swarm optimization (BFPSO) and stereo 
image processing technologies to design the fuzzy 
mobile robot control system.  
Two CCD image modules are proposed to estimate 
the three dimensional deep of the captured images 
objects. The proposed fuzzy-type color space 
quantization learning is applied with BFPSO to reduce 
the amount of image data and generate the labeled 
image data. The feature shape of the 
three-dimensional object will be generated by the 
concept of region matching to rebuild the outside of 
the vision. The stereo information is gradually 
constructed by the disparity mapping and region 
detection. The BFPSO algorithm is proposed to 
recognize the pose and angle of the discussed object 
and build the routing path of the mobile robot.  
Keywords：Mobile robot, Binocular stereo vision, 
Bacterial foraging particle swarm optimization; Fuzzy 
system.   
1. 前言 
行動機器人的快速發展，帶給人類工作與生活
上的無限便利，例如工業性質的機器手臂，它可取
代人類工作在危險的環境底下，協助搬運貨物或是
組裝設備，增加安全性及提高工作效率；另外智慧
型清潔服務機器人，可協助打掃居家環境、戶外除
草等工作，使人類生活變得輕鬆，本文是利用兩組
簡單且便宜的 CCD 感測元件模擬人類雙眼看物體
的立體情境，具備立體視覺辨識能力的行動機器
人。行動機器人最常依照據人類指令完成被要求的
動作，例如及時追蹤物體的防盜與保全型機器人、
夾取物件與放置物件到達定點的工業生產型與醫
療保健型機器人等[1]，一般 2D平面影像處理技術
無法辨識出物體影像深度，缺少第三維度的影像估
測，常常造成定位誤差使機器人無法完成精確的行
為與動作，立體視覺辨識能力的服務性機器人能夠
改善上述缺失。 
對於機器人在雙眼立體視覺的相關研究指
出，位置視覺性伺服控制需要兩台以上攝影機加上
大量電腦運算，才能達到精確的位置控制[2]。隨模
擬雙眼立體影像技術發展與精進，目前許多學者將
此應用在機器人視覺系統，研究論文提出以兩部攝
影機建構立體視覺影像追蹤系統，透過模糊控器及
時校正系統參數，成功完成特定顏色物體追蹤[3]。
研究者以雙眼立體視覺為基礎之機械手臂定位系
統，以 2台CCD攫取影像，利用多層感知機校正原
來估測立體目標物之重心位置，使用基因演算法推
算機器手臂馬達角度，完成機器手臂目標物正確夾
取動作[1]。Vincenzo Lippiello等人[4]利用雙固定
CCD為視覺感測器，透過立體視覺運算前往夾取零
件並返回到固定位置區，完成工業用途之零件組
裝。Xu 與 Luger提出一主動式視覺系統並建立機
器 人 運 動 模 型 ， 特 過  Denavit–Hartenberg 
transformation matrix方式對機器人運動誤差分析，
所提出在設計端降低誤差方法，可以適用在任何工
業製造中機器人的操作，並實現在主動式系統減少
誤差校正時間[5]，此TRICLOPS設計架構已成功應
用在具有四個自由度的行動機器人。Zhao 等多位
學者利用一簡單立體視覺之影像幾何公式推導出
機器人行走路徑，使用Point Grey Research中的 
Triclops SDK軟體，完成行動機器人避障實驗。
Kanda 學者 使用提出心理學理論、語意式差異法
與因素分析為基礎的理論，結合雙眼立體視覺、全
色彩空間與 YCbCr 色彩空間的方式如下公式轉換
[17]: 
     (1) 































B
G
R
21.18
00.112
96.24
78.9300.112
20.7479.37
55.12848.65
128
128
16




Cr
Cb
Y
轉換完程的區塊先使用二值化方式依選取得到的
灰度闕值(Threshold)，將影像灰度分劃成兩種灰度
值，若影像本身的灰度大於此門檻值時判定為亮
點，反之低於的就判定為暗點。利用影像處理的二
值化方式，將一個複雜圖像化簡。其公式如下[17]: 
( , )
1
n
m G x
i
  y                        (2) 
其中 m 為二值化閥值( threshold value)，n是代表所
有像素數目，G為輸入的影像，G(x, y)是表示座標
(x, y)位置上各像素的灰階值。 
本論文用一中值濾波器除去影像的雜質訊
號。中值濾波器屬於非線性數字的濾波器技術，中
值數就是將一遮罩的所有數值排序後，將數列的中
間值做為輸出。如果裡的數值個數為偶數的話，就
是將數列中間的兩個值做平均後再輸出。本文以
3 3 的遮罩設計中值濾波器，公式如下：       1 1M x, y MED G x - k, y - , k, w   (3)         
其中( x,y )為影像索引值， G x, y 為像素的灰階
值， 中值化後的灰階值， 。 x,yM  101 ,,-k,l
立體影像成相的原理說明如圖三所示，其主要是依
據類雙人眼成像原理加上三角幾何的原理建立，對
於兩台平行架設的CCD攝影機，假設追蹤的點P 則
數 學 運 算 方 程 式 分 別 顯 示 如 下 式 [18]: 
,
/ 2 / 2
F Z F Z F F
and
Z
x X b x X b y y Yrl
  
  rl
 ，其
中X, Y 與Z 是目標點 P的實際座標，xl, yl, xr 與 
yr 是左邊影像與右邊影像座標，F是攝影機焦點，b
是攝影機間的距離。 d rl xx   是Disparity值，
所以可以估測出P點三軸位置座標。P點與原點的距
離 2 2 2 與 地R X 面 的 仰 角 角 度 Y Z
1tan
2
x xrX l
Z f
    。對於障礙物大小之估
測，本文利用一有效率的K-mean演算法建立障礙物
中心位置當起點，從本點上下左右等方向分別逐步
尋找與中心點相同灰階像素區塊，將上下左右極限
位置標示出來，完成對應區塊長寬大小估算與位置
確認。最後選取相近最大區塊。 
接著進行邊緣偵測的程序，先透過型態學的斷
開 (open)[17]運算，讓影像先完成侵蝕後再用膨
脹的處理方法，可使影像輪廓達到平滑，達到
截斷窄的細頸，清除細突支等效果。假設
( , )1 1A M x y 且 ，若 B 斷開 A 可表示為 AoB，其定義如下 [17]：  
( , )2 2B M x y
AoB＝(AΘB) B                          (4)♁  
最後依據多級邊緣檢測的演算法，設計 Canny 邊
緣檢測器，先對每個點都需計算出局部梯度[17]， 
2 2 1/( , ) [ ]g x y G Gx y  2                      (5) 
再求各邊緣的變化方向[4] 
1( , ) tan ( / )x y Gy x G                   (6) 
本方法設定抑制閾值，將原圖像邊緣中連續的曲線
設成曲線中的模糊部分，可以避免將沒組成曲線的
雜訊當成邊緣。首先從具備高閾值的區域開始，標
示出較確定的邊緣，然後從此真實邊緣開始搜尋，
在影像搜索過程中再用低閾值搜尋整個影像圖形
邊緣，直到回起點，當完成後就可得到一個二值圖
像。為得到精確邊緣圖像，一改進實現的方式是以
梯度方向來檢測二階方向導數的過零點，公式如下
[17]： 
2 2 0L L L L L L Lx xx x y xy y yy
2  
 (8) 
 
           (7) 
並在梯度方向的三階方導數滿足下列條件[4] 
033 3223  LLLxLLLLLLL yyyyyyyxxxyyxxxxx
其中 Lx, Ly Lyyy 表示用高斯平滑原始圖像得到尺
度空間，其表示 L因計算得到偏導數，此法確保得
到邊緣是一連續的曲線，完成邊緣特徵攫取。 
障礙物距離的估算中將利用左右兩眼 Disparity map
值建立一組距離估測函數，假 若 Disparity 值為 x
時 ， 距 離 估 測 函 數 的 輸 出 Y 為
589.035* 0.983xY  ，模糊控制器即可依據與障礙
物的距離、相對應的相位角輸出控制訊號完成機器
人的控制。  
3、
 
全向式機器人系統架構與模糊系統設計 
本文提出全向式輪型移動機器人是由微控制器
模組和 DC馬達驅動模組構成的，機器人的外觀如
圖四所示。下層是由三顆全向輪加上驅動馬達所做
成的移動平台，筆記型電腦可以即時依據 CCD 處
理影像訊號，判斷障礙物大小與距離，對微控制器
做出相對應的行進方向指揮。中層為放置微控制器
和電池的內部空間，並裝設一雙 CCD 當作雙眼，
此部分是機器人的控制核心，在實驗時所用電腦與
移動平台間的通訊是經由 Bluetooth 做為無線溝通
管道，建立控制流程。所使用的馬達控制器型號為
HB-25，馬達結合了功率 H橋與簡單伺服架構。HB- 
25 不只是馬達驅動芯片連接到些許邏輯和高電
流。還有一質量 H橋的有效散熱設計，並且採用了
熱粘接劑來傳遞電機驅動芯片上散熱片的熱量也
就是大電流電機控制器以極大熱特性和無需額外
硬件就可進行冷卻。 
本文使用BFPSO演算法建立模糊辨識與控制系
      
2
1
1
1
1
m
i iM d i
mk
i
i
HE x k w
RMSE y k
M HE x k



         
    
 
（16）
 dy k 為第 k組的目標輸出值， i為第 i個規則
之規屬函數值，我們的目標是使 RMSE之值愈小愈
好，即得到最大的適應值
HE
pF ： 
 pMAX F  （17）
步驟三: 執行公式 (12) 細菌趨向性學習。 
步驟四: 執行公式 (13)，群聚散佈(dispersal)學習。 
步驟五：選擇個別粒子最佳值 
  
   
1 1
1
1
k k
p pk
p k k
p p
Y if F Y F pBest
BP
kp
k
pPB if F Y F pBest
 


   
 （18）
步驟六：選擇群體最佳值 
  
  
1
1 1
1
k
k k
p p
k k
p
GB


k
k
PB if F PB F GB
GB if F PB F GB

 


  
 （19）
步驟七：執行公式(11)，學習更新粒子的位置。 
步驟八：重複步驟二至步驟七直到滿足迭代條件。 
 
4.實驗結果 
 首先、第一個實驗先進行原始影像處理前處
理，模擬結果顯示在圖五，5(a)顯示為原 RGB彩色
圖，圖 5(b) 是進行灰階轉換後的實驗結果，接著進
行二值化與中值濾波處理，結果顯示如圖 5(c)。對
於左右兩眼拍出的照片透過前面處理程後，分別顯
現在圖 5(d)左上方與右上方，利用圖三的觀念與公
式，進行左右兩眼圖樣的位置估測，計算兩者
disparity 不對稱點的分析響應，其響應結果顯現在
圖 5(d)的正下方。依此結果產生之 disparity map 顯
現在於圖 5(e)。透過障礙物外圍大小估算與大區域
選取結果顯現在圖 5(f)。最後物邊偵測方式建置障
礙物外圍邊界，透過距離估測函數決定障礙物的空
間資訊。另外，本文以空間資訊中各障礙物在行進
路徑中位置與各種不同角度，辨識出其正確方位座
標，建立機器人路徑地圖，利用 BFPSO 完成模糊
的建立工作，完成軟體系統避障模擬與實際機
器人的行走驗證。本次在學校環境下模擬的實驗
環境佈建與機器人行走路徑，可即時避障，實驗之
路徑分格分析結果如圖六所示，實驗結果顯示機器
人從起始點出發後經過多障礙物並及時避開許多
不同位置的障礙物回到原點。 
 
5. 結論 
本計畫提出影像處理技術為基礎的立體影像
特徵擷取與障礙物物件大小與距離估測方式，進行
最佳化模糊識別與控制系統的建置與實驗。所提各
種影像處理實驗中，已可成功建立雙眼立體圖像的
disparity map，並已完成一些複雜的避障實驗，本
身在多次不同的實驗結果中可以發現，環境光線的
變化仍會影響實際結果的成功率，如何在將來加入
更多樣的影像特徵辨識技術與其它環境感測的辨
別能力，以提高物體在資訊空間的正確強建性，提
高機器人的情境感知能力，將是未來值的發展與研
究的方向。 
六. 參考文獻 
[1]徐子勝，以立體視覺為基礎之機械手臂應用系
統，中央大學資訊工程所，碩士論文，2009。 
[2] A. C. Sanderson, L. E. Weiss, Image-Based Visual 
Servo Control Using Relational Graph Error Signals, 
Proceedings of the International Conference on 
Cybernetics and Society, pp. 1074-1077, 1980. 
[3] 錢鉦津，模糊控制之立體視覺影像追蹤系統，
中原大學機械工程研究所，碩士論文，2004。 
[4] V. Lippiello, B. Siciliano, L. Villani, 
Position-Based Visual Servoing in Industrial 
Multirobot Cells Using a Hybrid Camera 
Configuration, IEEE Transactions on Robotics ,Vol. 
23, no.1, pp.73-86, 2007. 
[5] K. Xu, G. F. Luger, 
, Image and Vision Computing, Vol. 25, no. 
7, pp. 1185-1193, 2007. 
The model for optimal design 
of robot vision systems based on kinematic error 
correction
[6] T. Kanda, H. Ishiguro, T. Ishida, Psychological 
analysis on human-robot interaction, 
Robotics and Automation, 
pp. 4166-4173, 2001. 
IEEE 
International Conference on 
[7] L.-F. Gao, Y.-X. Gai, S. Fu, Simultaneous 
Localization and Mapping for Autonomous Mobile 
Robots Using Binocular Stereo Vision System, 
International Conference on Mechatronics and 
Automation, pp. 326 – 330, 2007. 
[8] H. Li, M. Jin, L. Zou, A New Binocular Stereo 
   
  
  
  
  
  
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 右邊 CCD  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
右影區 
RGB彩色影像攫取 色彩轉換與特徵
攫取
左影標記 
區域 
色彩空間量化程序 
左邊 CCD  
右影標記 
區域 
PSO
彩色影像攫取 色彩空間模糊量化程
序 
色彩轉換與特徵
攫取 
RGB 
左影區 
BFPSO 
障礙物深度
(距離)估測 
 
 
 
 
 
 
 
 
 
立體成相與不
對稱區域計算 
障礙物區域估
算與選取 
模糊系統 
Driver  
全向輪 
全向輪
全向輪
 
 
圖一:立體影像行動機器人障礙物辨識系統流程圖 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
解碼 
量化後影像 
色彩轉換 
PSO  
原始 
影像 
模糊 
分割
碼簿產生 
適應函數 
圖二:色彩量化流程圖 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(1) 
 
(2) 
 
(3) 
 
(4) 
 
(5) 
 
(6) 
 
(7) 
 
(8) 
 
(9) 
 
(10) 
 
(11) 
 
(12) 
 
(13) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(14) 
 
(15) 
 
(16) 
 
(17) 
 
(18) 
 
(19) 
 
(20) 
 
(21) 
 
(22) 
 
(23) 
 
(24) 
 
圖六. 避障實驗分格圖 
路徑圖 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
100年度國科會計畫執行相關論文著述表(續)
 
 [C3] H.-C. Chen, H.-M. Feng, D.-h. GUO, Cross-Layer Regulation Algorithm in MPEG-4 Video Wireless 
Networks Applications, The 5th IET International Conference on Ubi-Media Computing, Xining China, 
pp. 242-247, AUG. 16-18, 2012. 
[C4] H.-C. Chen, H.-M. Feng, D.-h. GUO and Ji-Hwei Horng, Wireless Networks Designs through 
Advanced Regulation Machine, Proceedings 2012 IEEE International Conference on 
Anti-Counterfeiting, Security and Identification, pp, 101-105, Taipei, AUG. 24-26, 2012.  
[C5] S.-M. Jou, H.-M. Feng and D.-. GUO, Self-Generation RBFN Vision-Based Robot System Through 
Bacterial Foraging Particle Swarm Optimization Learning Algorithm, 2nd International Conference on 
Engineering and Technology Innovation 2012 (ICETI2012), Kaohsiung, Nov. 2-6, 012. (NSC 
99-2221-E-507-004 & NSC 100-2221-E-507-004) 
[C6]馮玄明、曾偉勝、何銘輝，進化式學習法設計立體視覺行動機器人， 中興大學，第二十屆模糊
理論及其應用研討會，Nov. 16-18，2012。(NSC 100-2221-E-507-004) 
 
 
100 年度專題研究計畫研究成果彙整表 
計畫主持人：馮玄明 計畫編號：100-2221-E-507-002- 
計畫名稱：結合細菌優化與粒子群最佳化演算法設計雙眼立體視覺行動機器人 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 5 3 250%  
研究報告/技術報告 0 0 100%  
研討會論文 3 2 150% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
