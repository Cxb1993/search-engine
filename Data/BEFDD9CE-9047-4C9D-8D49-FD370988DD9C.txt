2 
中文摘要 
科技的快速演進除帶給人們更大的便利外，也造成了產業鏈上公司間更大的競爭與合
作，促進了科技採用的機會與威脅。但在缺乏資訊科技的協助，要去追蹤企業生態系
統中科技演化和產品創新，顯得緩不濟急。因此，本研究計畫旨在發展一個植基於雲
端平台上的科技監測系統以自動化蒐集來自不同新聞媒體的資料來呈現企業生態系統
的演進。一個企業系統包括了公司、產品、科技。本研究除從文件中擷取其間的關係
外，更增進了專有名詞擷取的效能，以增加關係擷取的準確度。從系統的實驗測試結
果顯示所改良的系統效能優於原型系統。我們進一步將完成的科技檢測雛型系統佈建
在一個 UniCloud 上發展的雲端資料管理系統：SQLMR(子計畫 C3)和虛擬主機管理系
統(子計畫 A1)上。本計畫所發展的資料監測系統可視為一個軟體即服務(SaaS)，運行
於整合型計畫所建置的平台即服務(PaaS)和基礎即服務(IaaS)的平台上。增進了科技監
測服務的效能和可靠。 
關鍵詞：企業生態系統、科技監測、關係擷取、雲端運算。 
4 
Introduction 
It is now beyond human cognitive capacities to keep track of the information on the 
speed of technological progress and on the variety of new technological applications by 
manually collecting all relevant information. Due to the intense competition in the 
information and communication technologies (ICT) industry, firms that want to maintain 
their competitiveness have to keep up to date on the business context in terms of companies, 
products, technologies, and the relations among them. However, it is time consuming to 
update this kind of information from various data sources and to analyze it manually, which 
could potentially delay the companies' ability to react to the changing technology and 
business environments. Therefore, it is imperative to develop techniques to collect huge 
amount of business information automatically from various sources and to extract business 
ecosystems consisting of relations among companies, products, and technologies. The 
techniques for discovering the business ecosystem may include tools such as text mining, 
relation extraction, and cloud computing. 
Several studies have developed methods for extracting relations in different domains 
such as bioinformatics (Friedman, Kra, Yu, Krauthammer, & Rzhetsky, 2001; Fundel, 
Kuffner, & Zimmer, 2007; Li, Zhang, Li, & Chen, 2008; Rebholz-Schuhmann, Jimeno-Yepes, 
Arregui, & Kirsch, 2010; Rindflesch, Tanabe, Weinstein, & Hunter, 2000). Few studies, 
however, have reported on discovering the business ecosystem. Jin, Ishizuka, & Matsuo 
(2008) proposed a technique to discover the relations between companies. In this study, we 
consider not only companies, but also products and technologies. Therefore, we extracted six 
types of name entity pairs as the relations. This study presents a novel technology monitoring 
system in the Cloud that delivers three major services: information source, text mining, and 
visualization.  
6 
rapidly, even as it reduces the need for huge upfront investments that characterize enterprise 
IT setups today. Therefore, we utilize two components from Unicloud to enhance the agility 
and reliability of our system. The rest of the paper is organized as follows. We first discuss 
related work in technology mining and monitoring, information extraction, as well as cloud 
computing. Then we present the proposed system and prototype. The proposed relation 
extraction approach and its evaluation are provided. Finally, we conclude with closing 
discussions and directions for future research. 
Related Work 
Technology Monitoring and Mining 
Monitoring is defined by Ellis & Haugan  (1997) as ‘‘maintaining awareness of 
technology developments in a field.” Nosella, Petroni, & Salandra (2008) observed that 
companies need to acquire the technology observation and assessment capabilities to respond 
to threats and to exploit opportunities arising from their technological environment. Dang et 
al. (2009) design and implement an integrated approach to monitor and analyze global 
bioterrorism research literature, which allows users to gain timely, comprehensive 
understanding of bioterrorism research. Yuan & Zhu (2004) defined technology monitoring 
as “a new cross-disciplinary subject that involves the study of science, science and 
technology management and information technology.”  Technology mining consists of a 
procedure to analyze information on emerging technologies to support technology managers 
in developing policies and strategies dealing with new technologies (Porter & Cunningham, 
2005).  In this study, we have developed a system to monitor the evolution of business 
ecosystems within the ICT industry by using text mining and visualization techniques for 
decision makers. 
 
8 
tagging, to shallow parsing and identifying nominal and verbal phrases), and they are also 
using lexicons. This hybrid approach allows OpenCalais to identify an entity even if most of 
the world (including the people writing the rules) never heard of it, and to disambiguate an 
entity meaning according to the context it appears in (How does Calais "learn"? , 2008). 
Therefore, this study uses OpenCalais1  to recognize named entities.  Heuristic rules in 
OpenCalais are also used to identify facts and events derived from multiple documents.  
OpenCalais does this by identifying commonly used verbs to describe facts or events. 
For example, the pattern "A was acquired by B" indicates an acquisition event between the A 
and B companies. However, these rules can also match more complicated expressions. For 
acquisitions, OpenCalais recognizes variations, including: "announced," "planned," 
"cancelled," "postponed," and "rumored." Each of these is triggered by a variety of English 
verbs and tenses (Leigh, 2008). 
Relation Extraction 
Relation extraction approaches can be categorized into three types: co-occurrence 
analysis, supervised statistical learning, and rule-based approaches. 
Co-occurrence analysis. 
The co-occurrence of entities on the web is commonly used as evidence of the strength 
of the relation between them, and it can be used to infer relations between entities based on 
their probabilities of occurrence in articles (Jenssen, Laegreid, Komorowski, & Hovig, 2001; 
Kautz, Selman, & Shah, 1997; Ku, Ho, & Chen, 2009; Matsuo et al., 2006). These 
approaches are based on the assumption that if two entities repeatedly occur together in the 
same document, there is an underlying relationship between them. These approaches can 
achieve high levels of recall. However, the pure co-occurrence of terms in sentences is less 
                                                           
1 http://opencalais.com 
10 
classification problem in an information extraction framework with a variety of different 
machine learning strategies, from strictly supervised to weakly supervised. His method used 
various lexical and syntactic features that it automatically extracted and computed from the 
linguistic context in which the two entities co-occurred. They introduced random-subspace-
based algorithms and then demonstrated their empirical advantages over both bootstrapping 
and active learning. (b) Kernel-based methods. Kernel methods preserve the original 
representations of data instances and use these instances in algorithms only via computing a 
kernel function between a pair of instances. Prior studies have explored structured 
representations, such as parse trees and dependency trees, and directly computed the kernel 
function between trees. The kernel function computes the similarity between objects without 
enumerating all the features. In this way, the kernel function can explore an implicit feature 
space when calculating the similarity between two instances.  Therefore, an advantage of 
kernel methods is that they can search a feature space that is much larger than that which 
could be represented by a feature-based approach. The performance of kernel-based methods 
is mainly determined by the selection and design of the kernel functions. The learning 
algorithms become less practical if there are a large number of patterns. Approaches that use 
tree kernels, such as Culotta & Sorensen (2004) and Zelenko, Aone, & Richardella (2003), 
have good precision but low recall because of their relatively strict matching criteria. The 
task may become even more difficult as the structure of the patterns becomes more complex. 
In addition, overly complex pattern models that contain more information than necessary, 
such as Support Vector Machines, are likely to cause over-fitting of supervised algorithms 
(Stevenson & Greenwood, 2009). Bunescu & Mooney (2005) used the information found in 
dependency trees to build a shortest path kernel for relation extraction. This kernel also 
suffers from low recall for the same reason. 
 
12 
developed RelEx, which mainly used dependency parse trees to extract relations. They 
defined three rules of English grammar that are most commonly used to describe relations, 
and then their system extracted relations between NEs according to these rules. Their 
approach is too domain-specific because they used an explicit list of all the relation terms 
they considered.  
In this study, however, it is impossible to enumerate all possible relations because we 
cannot foresee what terms news reports will use to indicate a type of relation. RelEx can 
precisely extract relations from sentences and achieve high performance using the more 
formal grammar of testing data and the well-defined subjects (genes or proteins) in 
biologically related domains.  However, in this study, the documents from which we want to 
extract the relations are news articles. The subjects of the sentences that contain relations are 
not named entities. For example, the subject could be the author of a news article.  Moreover, 
a term recognized as a named entity could have more than two types of entity, and we need to 
extract the mutual relations among these named entity types.  
Unlike the aforementioned approaches, we not only consider syntactical structure by 
using Natural Language Processing (NLP) techniques but also use semantic matching without 
manually constructing an ontology, which is time consuming.  This study uses a trigger word 
list built by business analysts for its semantic matching. Hence, each business analyst can 
build the trigger word list according to his or her specific needs. In retrieving the candidate 
relations, we extract words tagged not only as nouns but also as verbs. 
Cloud Computing 
Cloud computing is defined as “Internetbased computing, whereby shared resources, 
software and information are provided to computers and other devices on demand, like the 
electricity grid (Fiammante, 2009).” The term cloud refers to the collection of hardware and 
14 
solutions rather than developing their own. In Software as a Service (SaaS), companies 
evaluate existing software SaaS solutions based on how close they meet their functional and 
non-functional requirements.  In SaaS solutions, only a browser and an Internet connection 
are the only requirements to become a user. This model will have the most impact on how we 
develop software since it poses new questions to software developers and architects on how 
to handle the realization of requirements, traceability, versioning, multi-tenancy of companies 
that are using the same software package (Hirzalla, 2010).  
Virtualization 
In general the architecture behind cloud computing is a massive network of servers 
which are linked together and able to dynamically provide, configure and update computing 
and storage resources to achieve the requirements of the running applications (Boss, Malladi, 
Quan, Legregni, & Hall, 2007). Returned to the limelight in recent years, the virtualization is 
often used in this scenario in order to minimize the costs related to hardware and energy. It is 
estimated that 50 percent of energy costs in running a large data center are derived from 
cooling needs alone. Aside from the power needed to drive thousands of processors and 
peripherals, in fact, all these machines generate lots of heat. The chance represent by more 
virtual machine instances running simultaneously on a single resource allow, instead, to 
reduce the number of physical systems and so space, administration, power and cooling 
requirements (Weiss, 2007). 
Cloud Database 
Current commercial Cloud DB products such as Amazon’s Simple Storage Service (S3), 
SimpleDB and Relational Database Service (RDS), Microsoft’s SQL server and SDS  Cloud 
database, all claim to support SQL. However, most of them do not satisfy many of the 
desirable properties of Cloud DBMS. For example, Amazon’s SimpleDB only supports a 
small subset of SQL queries. It does not support aggregation and joins types of complex 
16 
System Overview 
The aim of a technology monitoring system was to provide domain experts with 
information on the relations among the technologies, products, and companies involved in 
certain technology intensive product markets to represent the trends in those product markets.  
We have developed a technology monitoring system to collect related news reports from 
various sources and to extract relations among the technologies, products, and companies 
involved to identify and present business ecosystems. The system, as shown in Figure 1, has 
three major components: information source service, text mining service, and customized 
visualization service. The relation extraction in the text mining service is the core of the 
proposed technology monitoring system, and the sources of information will affect the 
coverage of the relations extracted. This system is deployed in the cloud architecture that 
utilizes the techniques of virtual machine and cloud database. 
Information Source Service 
The information on the internet was collected by the information source service. The 
Really Simple Syndication (RSS) mechanism is a useful way to capture the latest articles 
automatically without visiting each site. Therefore, a RSS reader was developed in this 
service to automatically receive the latest information on the topics of interest. We could then 
parse the information using HTML parsers customized for each information source to extract 
the news content and save it in a news repository. This exploited the great scalability of the 
service; that is, if we were interested in a new information source, we could develop a new 
HTML parser and subscribe to this information source with the RSS reader. 
Text Mining Service 
The text mining service was mainly designed to extract the following information:  
18 
Amazon.com would be aggregated. Users can use the synonym service to define two terms as 
synonymous. When displaying the final results, the synonymous terms will be treated 
semantically as the same term. If users consider a certain term unimportant, or if they are not 
interested in the term, they can use the filter service to move this term to the filtered list so 
that it will not appear in the final results. The Google image, trend, and definition services are 
used to broaden the users’ knowledge about the term they queried.  
Cloud Architecture 
As the size of data set in cloud increases rapidly, how to process large amount of data 
efficiently has become a critical issue. MapReduce provides a framework for large data 
processing and is shown to be scalable and fault-tolerant on commondity machines. However, 
it has higher learning curve than SQL-like language and the codes are hard to maintain and 
reuse. On the other hand, traditional SQL-based data processing is familiar to user but is 
limited in scalability. The C3 subproject of Unicloud propose a hybrid approach to fill the 
gap between SQL-based and MapReduce data processing. Therefore, all the extracted 
information from our system is stored in this data management system for cloud, named 
SQLMR. SQLMR complies SQL-like queries to a sequence of MapReduce jobs. Existing 
SQL-based applications are compatible seamlessly with SQLMR and users can manage Tera 
to PataByte scale of data with SQL-like queries instead of writing MapReduce codes. The C3 
subproject also devises a number of optimization techniques to improve the performance of 
SQLMR. In our system the SQLMR can enhance the query performance for SQL join query 
of two large database tables. For better management the servers where our services are 
deployed, we utilize the A1 subproject of Unicloud, a virtual machine management system 
for cloud. A1 subproject provides a friendly web interface for users to easily create, delete, 
backup, turn on, and shutdown virtual machines. The status of running virtual machines is 
also monitored by software agents and it can be displayed to users by their management web 
20 
ecosystem. For example in Figure 4, the query term “HTML5” has several connections 
extracted by the system to other entities (direct neighbors of HTML5). One of them is tagged 
as ‘develop’ to Apple, and the system will further connect the entities that have relationships 
to these direct neighbors. Furthermore, we obtained the top n topics from the extracted 
relations by counting the most relevant terms corresponding to the query. 
We can further view the business ecosystem of HTML5 (Figure 4). Although HTML5 is 
tagged as a product, this incorrect tag will not affect the quality of the result. We know that 
many important internet companies are interested in HTML5. Android, iPhone, iPad, and 
other products use this technology, and HTML5 is related to streaming video and mobile 
phones. With Figure 4, domain experts can judge whether or not HTML5 will be involved in 
a given trend. 
Relation Extraction and Evaluation 
We developed a framework of relation extraction for discovering business ecosystems, 
as shown in Figure 5. This framework can be decomposed into three major components: 
sentence extraction, data preprocessing, and relation extraction. Relation extraction is the 
core service in this study. Because we wanted to discover business ecosystems consisting of 
companies, products, and technologies, there were six possible types of named entity pairs 
from which to extract relations, as shown in Figure 6: company-company, technology-
technology, product-product, company-technology, company-product, and technology-
product.  
 
 
 
22 
sentences. We used the Stanford Parser to covert sentences to Penn Trees and then extracted 
verb phrases from the field that were tagged as VP. Within this field, we extracted from the 
first word to the word whose part-of-speech was tagged as a preposition. 
Extracting Relations 
In business analysis, domain experts usually concentrate on specific interactions among 
companies, products, and technologies. Therefore, relation keywords can be extracted from 
domain experts. Although we use the term relation extraction, what we extracted were the 
interactions between named entities. For example the words “acquisition” and “deal” refer to 
interactions between companies rather than to relations between companies. Thus, our notion 
of relation not only represents relations but also interactions. We used the same method to 
extract the relations regardless of the named entity types they relate. Algorithm 2 in 
Appendix B shows the pseudo-code of the extraction path. 
 We first extracted paths from a node that contains one or more named entity to another 
node that also contains one or more named entity. However, we excluded paths in which 
nodes other than the endpoints contain named entities. Figure 8 shows why we excluded this 
kind of path. 
In Figure 8, we only extracted the following paths: Microsoft to Yahoo, Microsoft to 
Ask.com, Yahoo to Ask.com and Ask.com to Google. Because the path from Microsoft to 
Google passes through Ask.com, we considered this path to represent the relation between 
Microsoft and Ask.com and the relation between Ask.com and Google. The path from Yahoo 
to Google is the same, so we did not extract these two paths. This represents the fact that 
Yahoo and Microsoft are irrelevant to Google in this sentence. 
24 
automatically extract semantic relations between arbitrary objects from the web, and 
computationally feasible. Therefore, we purpose to hybrid these two relatedness measures to 
calculate the distance between terms. Eq. (1) represents the method we used to extract 
relation terms:  
 , (1) 
where we set threshold = 0.35 by our experiment, and D(x, y) = NWD(x, y) + NGD(x, y). 
NWD(x, y) represents the normalized synonym distance in WordNet between terms x and y, 
NGD(x, y) denotes the normalized Google distance between terms x and y, X is a term set in 
the candidate relations, and Y is a term set in the restriction list. 
From the paths extracted in the path extraction algorithm, we extracted all terms tagged 
as nouns and verbs in the path nodes as candidate relations. We built a synonym graph in 
WordNet and used it to calculate the distance between two terms. Each node in the synonym 
graph represents a term, and an edge between two nodes indicates that these two terms are 
mutual synonyms. We calculated the sum of the NWD and the NGD between each term in the 
candidate relations and the terms in the restriction list. 
We chose the terms from the candidate relations that were at a minimal distance below 
the threshold. A higher threshold produces a wider the scope of the relations extracted, and 
vice versa. Here, we set the threshold to 0.35, which included most wanted relations and 
excluded unwanted relations. 
Table 1 lists the examples of relation extraction from the paths in Figure 8.  According 
to Eq. (1), we extracted the term with minimal distance for each path. If there was a tie, for 
example, between “combination” and “deal” for the Microsoft-Ask.com path, we chose the 
relation that was the least common term. The Stanford Parser generates a score that 
26 
was to evaluate the performance of the refined named entity recognition based on the named 
entities tagged by OpenCalais. Because the accuracy of the named entity recognized by 
OpenCalais affected the accuracy of the relation extraction, we have to reduce the error 
caused by OpenCalais using the voting mechanism to increase the accuracy of the named 
entity recognition. The purpose of this experiment was to study the effectiveness of the 
refined mechanism for named entity recognition.  
When given a sentence that may have contained relations, five testers were asked to 
choose the right type for the refined names entities. They were offered four options to choose 
from: company, product, technology, and other. For each named entity in a sentence, we 
asked them to check which type it belonged to. If the named entity did not belong to one of 
the first three types, they were asked to choose the fourth option: other. If there were named 
entities in the sentence that were not tagged by OpenCalais, they could tag these named 
entities themselves. Therefore, we evaluated the refined named entity recognition and the 
original tags provided by OpenCalais by comparing them with the true set annotated by 
testers. 
The second phase of the experiment was to evaluate the performance of the relation 
extraction. We selected three news websites with different expressions and word usage in 
order to evaluate whether or not the use of different sources will affect the extraction results.  
After the first phase of the evaluation, the testers were asked to correct the relations in the 
same sentences given in the first phase. For each relation, they were given three options: (a) 
correct, the system correctly extracted the relation existing in a given sentence; (b) incorrect, 
the system incorrectly extracted the relation existing in a given sentence; (c) no relation, there 
is no relation between two named entities in the given sentence. If the system failed to extract 
a relation that existed between two name entities, the testers could tag the relation 
accordingly.  
28 
Therefore, the relation extraction method proposed in this study is more suitable for 
extracting relations among products, technologies, and companies.  In terms of the 
correctness of relation extraction, testers identified 20% of relations in the sentences as 
incorrectly identified. 
Discussion of results. Note that the 20% of relations incorrectly extracted by the system 
refers to cases in which there existed a relation between two named entities, but the system 
extracted this relation incorrectly. Although the system identified relations with a 20% error 
rate, it did identify the existence of a relation between the two named entities. Thus, domain 
experts can judge whether the relation between these named entities corresponds to that 
discovered by the system. We further examined these sentences to analyze the causes of the 
20% error rate.  We discovered that the main reason was that in these cases it was clear to the 
experts that there was a relation in the sentence, but they could not extract a word to represent 
the relation. Moreover, we restricted the distance between terms to lie within 0.35, which 
may exclude some relations.  Finally, at times the relation was not expressed clearly in 
sentences. 
As shown in Table 6, the system obtained the best performance if it only extracted 
relations from Red Herring. One reason for this is that the grammar of the articles in Red 
Herring is more formal than that of Business Week and Wired. The other reason is that the 
relations in the Red Herring articles are more clearly expressed. Therefore, using Red Herring 
as a source of information produces better results than the other two sites. 
Conclusions and Future Directions 
In this study, we have developed a technology monitoring system that can automatically 
collect and analyze data on the internet more effectively. We combined the processed data 
extracted from the information sources with other information on the internet, including 
30 
extracted by text mining techniques. Future studies include the adoption of machine learning 
or relevance feedback to replace the list of terms of interest. We can thus further reduce the 
manual efforts required for extracting relations from other domains that lack the support of 
domain experts. 
32 
Li, J., Zhang, Z., Li, X., & Chen, H. (2008). Kernel-based learning for biomedical relation extraction. 
Journal of the American Society for Information Science and Technology, 59(5), 756-769. 
Mansouri, A., Affendey, L. S., & Mamat, A. (2008). Named entity recognition approaches. 
International Journal of Computer Science and Network Security, 8(2), 339-344. 
Marneffe, M.-C. d., MacCartney, B., & Manning, C. D. (2006). Generating typed dependency parses 
from phrase Structure Parses, Proceedings of 5th International Conference on Language 
Resources and Evaluation (LREC2006) (pp. 449-454). Paris: European Language Resources 
Association. 
Matsuo, Y., Hamasaki, M., Nakamura, Y., Nishimura, T., Hasida, K., Takeda, H., et al. (2006). 
Spinning multiple social networks for semantic web. In A. Cohn (Ed.), Proceedings of the 
21st National Conference on Artificial Intelligence - Volume 2 (pp. 1381-1386). Boston, 
Massachusetts: AAAI Press. 
McDonald, D. M., Chen, H., Su, H., & Marshall, B. B. (2004). Extracting gene pathway relations 
using a hybrid grammar: The Arizona Relation Parser. Bioinformatics, 20(18), 3370-3378. 
Nosella, A., Petroni, G., & Salandra, R. (2008). Technological change and technology monitoring 
process: Evidence from four Italian case studies. Journal of Engineering and Technology 
Management, 25(4), 321-337. 
Ono, T., Hishigaki, H., Tanigami, A., & Takagi, T. (2001). Automated extraction of information on 
protein-protein interactions from the biological literature. Bioinformatics, 17(2), 155-161. 
Park, J. C., Kim, H. S., & Kim, J. J. (2001). Bidirectional incremental parsing for automatic pathway 
identification with combinatory categorial grammar. Pacific Symposium on Biocomputing, 6, 
396-407. 
Porter, A. L., & Cunningham, S. W. (2005). Tech mining exploiting new technologies for competitive 
advantage. Hoboken, NJ: John Wiley & Sons. 
Rebholz-Schuhmann, D., Jimeno-Yepes, A., Arregui, M., & Kirsch, H. (2010). Measuring prediction 
capacity of individual verbs for the identification of protein interactions. Journal of 
Biomedical Informatics, 43(2), 200-207. 
Rindflesch, T. C., Tanabe, L., Weinstein, J. N., & Hunter, L. (2000). EDGAR: extraction of drugs, 
genes and relations from the biomedical literature. Pacific Symposium on Biocomputing, 5, 
517-528. 
Roehrig, P. (2009). New Market Pressures Will Drive Next-Generation IT Services Outsourcing 
(Technical Report): Forrester Research, Inc. 
Seidler, K., & Schil, A. (2011). Service-oriented information extraction. In S. Müller-Feuerstein, B. 
Volz, K. Orsborn & S. Stefanova (Eds.), Proceedings of the 2011 Joint EDBT/ICDT Ph.D. 
Workshop (pp. 25-31). New York, NY: ACM. 
Stevenson, M., & Greenwood, M. A. (2009). Dependency pattern models for information extraction. 
Research on Language and Computation, 7(1), 13-39. 
Weiss, A. (2007). Computing in the clouds. netWorker, 11(4), 16-25. 
Yuan, J., & Zhu, D. (2004). A study on technology monitoring based on text mining to support 
science and technology management (pp. 47-51). Beijing, China: China  Science  and  
Technology  Press. 
Zelenko, D., Aone, C., & Richardella, A. (2003). Kernel methods for relation extraction. The Journal 
of Machine Learning Research, 3, 1083-1106. 
Zhang, Z. (2008). Mining relational data from text: From strictly supervised to weakly supervised 
learning. Information Systems, 33(3), 300-314. 
Zhou, G., Qian, L., & Fan, J. (2010). Tree kernel-based semantic relation extraction with rich 
syntactic and semantic information. Information Sciences, 180(8), 1313-1325. 
Zhou, G., & Zhang, M. (2007). Extracting relation information from text documents by exploring 
various types of knowledge. Information Processing & Management, 43(4), 969-982. 
Zhou, G., Zhang, M., Ji, D., & Zhu, Q. (2008). Hierarchical learning strategy in semantic relation 
extraction. Information Processing & Management, 44(3), 1008-1021. 
Zimmermann, M., Fluck, J., Thi le, T. B., Kolarik, C., Kumpf, K., & Hofmann, M. (2005). 
Information extraction in the life sciences: Perspectives for medicinal chemistry, 
pharmacology and toxicology. Current Topics in Medicinal Chemistry, 5(8), 785-796. 
 
34 
 
 
 
 
 
 
 
Algorithm 2. Path extraction algorithm 
Input: chunk dependency parse trees split by subject dependency 
Output: Paths 
Set extractPath = true 
For each input tree 
 Set Nodes to nodes in input tree that contain NE 
 For each stratNode in Nodes 
For each endNode in Nodes 
       If stratNode != endNode 
            extractPath = true 
            For each node between startNode and endNode 
                                         If node contains NE and dependency type != “conj_and” 
                                              extractPath = false 
                                              Break 
                                    If extractPath ==true 
                                          Add path from startNode to endNode to Paths        
 
36 
TABLE 5. The refined results of named entity recognition for each information source 
 Precision Recall f1-measure 
Business Week 92.77% 88.00% 90.32% 
Wired 99.29% 90.91% 94.92% 
Red Herring 96.10% 92.79% 94.42% 
 
TABLE 6. The relation extraction results for each information source 
 Precision Recall f1-measure 
Business Week 74.73% 67.48% 70.92% 
Wired 67.33% 59.65% 63.26% 
Red Herring 80.12% 74.30% 77.10% 
Total 75.06% 68.14% 71.43% 
Total (OpenCalais) 86.00% 25.85% 39.75% 
 
38 
 
FIG 3. An example of technology monitoring system – the result of querying HTML5 
 
 
FIG 4. The business ecosystem of HTML5 
 
 
 
40 
 
FIG 7. The chunk dependency parse tree for “''Cisco is saying that they can program all these 
functions into the network rather than rely on servers and storage,'' said Charles King, 
principal analyst with Pund-IT Research.” 
 
 
FIG 8. The chunk dependency parse tree for “From a search-advertising perspective, 
Ask.com in combination with Microsoft's Yahoo deal makes a better ''next-best alternative'' 
in competing with search leader Google, said Kevin Lee, CEO of search 
42 
成果自評 
We elaborate the outcomes of this project in three dimensions: 
1. Academic accomplishment: This project enhanced the relation extraction from news 
content by refined name entity identification method. The resulting system demonstrates 
its effectiveness in portraying the relations among companies, products, and technologies 
via experiments.  The results were written as a research paper submitted to Journal of 
American Society of Information Science and Technology (JASIST), a top journal in 
information science discipline.  It is under the first round of review while turning this 
project report. 
2. Technology innovation:  The techniques adopted and invented in this project has been 
composed as a prototyping system on a cloud platform.  This can be used for regular task 
in monitoring technology issued by users.  We are developing advanced models to 
enhance its usage for individuals based on individually corresponding knowledge 
structures. 
3. Social impacts: The resulting technology monitoring system can mitigate the cost and 
reduce the time to monitor the evolution and business ecosystems in the online and real 
time fashion.  This will impact the decision making process for companies in analyzing 
their relative benefits and strategic positions in business ecosystem.  
99 年度專題研究計畫研究成果彙整表 
計畫主持人：林福仁 計畫編號：99-2218-E-007-015- 
計畫名稱：大學雲：分散式雲端運算中介軟體--子計畫八:科技監測服務 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 ■未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
We elaborate the outcomes of this project in three dimensions: 
1. Academic accomplishment: This project enhanced the relation extraction from
news content by refined name entity identification method. The resulting system 
demonstrates its effectiveness in portraying the relations among companies, 
products, and technologies via experiments.  The results were written as a 
research paper submitted to Journal of American Society of Information Science 
and Technology (JASIST), a top journal in information science discipline.  It is 
under the first round of review while turning this project report. 
2. Technology innovation:  The techniques adopted and invented in this project 
has been composed as a prototyping system on a cloud platform.  This can be used 
for regular task in monitoring technology issued by users.  We are developing 
advanced models to enhance its usage for individuals based on individually 
corresponding knowledge structures. 
3. Social impacts: The resulting technology monitoring system can mitigate the 
cost and reduce the time to monitor the evolution and business ecosystems in the 
online and real time fashion.  This will impact the decision making process for 
companies in analyzing their relative benefits and strategic positions in business 
ecosystem.  
