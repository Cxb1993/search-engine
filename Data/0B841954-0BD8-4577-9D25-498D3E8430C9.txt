1廣義型線性分式規劃–理論、演算法與應用(I)
Generalized Linear Fractional Programming - Theory, Algorithms and Applications (I)
NSC94-2213-E-239-005
國立聯合大學經營管理學系吳光耀
一、中英文摘要
廣義型線性分式規劃(GLFP)是處理多個線性函數型比值問題的最佳化模式，從中使
比值最小者能夠最大化(或最大者最小化)。此模式常見於經濟、管理科學與工程領域的
應用研究中，同時其問題特性也常被引用於廣義型凸性與廣義型單調性的理論發展中，
此趨勢使得 GLFP 在應用面與理論面皆有日益顯著的重要性。因此，本研究計畫將以三
年時間分別就理論、演算法與應用等層面，完整地探討廣義型線性分式規劃技術。
本文為第一年計畫的研究成果報告。首先我們將分式規劃問題參數化後，形成一個
等式系統的擴張模式，從中所謂基解及其可行性與最佳性可被探發。繼而我們提出基底
式方法來搜尋基解，反覆找尋直到最佳解被找到。另一方面，基底式方法也延用到求解
此分式規劃的對偶問題。
我們的數值實驗結果顯示所提的原始基底式方法比既有標準的 Dinkelbach 法來得有
效率。其它顯著的結果也一併在最後匯整討論，包括一般線性限制最佳化的延用性與演
算循環避免、產出率最佳化的應用性與敏感度分析、以及對偶基底式方法的前瞻性。
關鍵詞：分式規劃；多個線性函數型比值；單形型法；原始和對偶問題
Abstract
Generalized linear fractional programming (GLFP) is a ratio optimization approach to the
problems with multiple ratios of affine functions, in which the minimum (maximum) of ratios is
to be maximized (minimized). Many applications of GLFP can be found in the fields of economy,
engineering, and management science. Moreover, the GLFP problem is commonly cited in the
literature of generalized convexity and generalized monotonicity. Therefore, the development of
GLFP appears to be critical in theory and applications. The 3-year plan focuses on the
development of theory, algorithms and applications of GLFP.
In this study, the results of the first year are presented. The concerned GLFP problem is
augmented to a standard form of minimizing a single parameter subject to parametric linear
equations, from which basic solutions with feasibility and optimality are revealed. Subsequently,
a basis-based approach is proposed for exploring basic solutions iteratively, until the optimal
point is reached. In extension, we derive the dual model of GLFP, in which the basis-based
approach is also adequate for solution.
From our numerical results, it is shown that the proposed primal basis-based algorithm
significantly outperforms Dinkelbach-type algorithms which are the standard method for GLFP.
Furthermore, significant results on the adaptability to linearly constrained optimization with
cycling prevented, the applicability to throughput optimization with sensitivity analysis, and the
promising of the dual basis-based approach are summarized and discussed.
Keywords: Fractional programming; Multiple ratios of affine functions; Simplex-type methods;
Primal and dual problems
3in which we assume
(H1) Y is a polytope with nonvoid and bounded;
(H2) For all yY, Gk(y)>0,kL.
Therefore from (H2), it follows that the function  is semistrictly quasiconvex (Avriel, et al.,
1988) on Y. In addition to (H1) for the convexity of Set Y, any local minimum of the functionis
a global minimum ofon Y (see Stancu-Minasian (1997), Theorem 2.3.5).
To facilitate subsequent analysis on the properties of the basis of epigraphic structure, (P1) is
rearranged into an augmented form as follow:
(P2) inf{: A()x=d(),x0,R },
where
(1) A()=A0A1 and d()=d1d0;
(2) A0= 



0H
IF R mn, A1= 



00
0G R mn, d0= 



0
0
h
f R m, d1= 



0
g 0 R m, xR n andR ;
(3) m=l+u, n=l+v, N={1,2,…,n} and M={1,2,…,m}.
It can be shown that both problems of (P1) and (P2) are equivalent. Thus, owing to the equality
form in (P2), we shall use it for our analysis.
2.2.2 Basic Solutions and Optimality
Let={(x,): A()x=d() and x0} be the feasible region to (P2). An augmented solution (x,)
in which nm+1 x-variables are zero is called a basic solution of. For a basic solution of, its
nm+1 zero x-variables are called nonbasic variables, whereas the other m1 nonzero x-variables
are basic variables (Fang and Puthenpura, 1993). Let B={b1,b2,…,bm1} and Z={z1,z2, …,znm+1}
denote the sets of indices of basic and nonbasic x-variables, respectively. To obtain a basic
solution denoted by (Z,B), a system of m non-linear equations in m unknowns, i.e. AB()xB=d(),
needs to be solved. Furthermore, it is a basic feasible solution if xB>0. Fundamental property
referred to basic feasible solutions is depicted in the following theorem which proof can be
completed by Cramer’s Rule and the property of first-order derivative.
Theorem 1 (Wu and Wang, 2006). The optimal value of (P2) is obtained by a basic feasible
solution of.
From the proof of Theorem, it can be shown that if a basic feasible (x*,*) with (Z,B) is not
optimal, there exists a nonbasic variable which value can be increased from zero to positive such
that the value of can be decreased from *. Therefore, we shall evaluate the possible
improvement based on the nm+1 bases by exchanging a nonbasic variable and a basic one
(namely, so-called pivoting).
Now we choose an x for Z as the entering basic variable for pivoting and arrange two
index sets of P=B{} and R=Z\{}, in which=p, i.e. arrange nonbasic xas the-th variable
of xP. In this partitioning way, the solution is identified as a basic feasible (x*,*) with (R,P,,),
5Lemma 1 (Wu, 2006b). Suppose that [y*T s*T] and [*T*T*T*] are optimal for (P2) and (D1),
respectively. Then it holds that yi*i*=0 for all iV and si*i*=0 for all iL.
Lemma 1 facilitates the development of a solution procedure for solving (D1) with basis concept
as described in Section 2.2.3. Wu (2006b) has proposed a dual simplex-type algorithm for
exploring basic solutions iteratively, until an optimal point is reached. The dual approach appears
to be highly adaptive to solve the primal fractional problem with a considerable number of linear
ratios.
2.3 Results and Discussions
2.3.1 Numerical Results
The efficiency of the proposed solution procedure (Wu and Wang, 2006) and three
Dinkdelbach-type algorithms are compared with 60 problems. These 60 problems (Ferland and
Potvin, 1985) are characterized by six variable scales (w=10,20,30,50,70,100), two ratio scales
(l=10,20), and five domain types (Y1, Y2, Y3, Y4, Y5). For each problem, 120 instances were
generated randomly according to predetermined uniform distributions. These four algorithms
were coded with the Matlab 6.5 software and implemented on a Pentimum-IV 3G machine.
In our simulation results, the maximal difference of the optimal values achieved by the four
algorithms is less than 6107 for each instance of problems. That is, the converged effectiveness
of all algorithms is not significantly different. Thus, we can compare the relative efficiency of the
algorithms in terms of average number of solved solutions (NS) with respect to each problem.
From our plotted figures beyond this report, it is shown that (1) whatever the ratio scales and the
domain types the problem is, for each algorithm, its curves of NS with respect to variable scale
are towards a similar trend; (2) the proposed algorithm significantly outperforms all tested
Dinkelbach-type algorithms. This conclusion is also supported by the results in terms of average
execution time in second listed in Table 1.
It is significant that the existence of optimality at parametric basic solutions is what makes the
basis-based algorithm so efficient. The concept of basis is illustrated in Figure 1.
Table 1. The average execution time performed by four algorithms in different problems
Algorithm Number of variables (w) Ratios (l) Domain types Overall
10 20 30 50 70 100 10 20 Y1 Y2 Y3 Y4 Y5 average
MAX 0.20 0.57 1.18 3.43 7.75 20.81 5.65 5.67 2.72 2.86 6.48 7.54 8.69 5.66
MAXMODM 0.08 0.20 0.40 1.12 2.49 6.36 1.67 1.88 1.19 1.01 1.99 2.16 2.53 1.78
NEWMAXM 0.08 0.20 0.39 1.07 2.38 6.09 1.62 1.78 1.18 1.00 1.96 2.04 2.33 1.70
BASIS 0.02 0.04 0.06 0.14 0.29 0.62 0.11 0.28 0.01 0.02 0.28 0.31 0.34 0.19
Remark: BASIS means the primal basis-based algorithm, MAX the standard Dinkelbach method,
MAXMODM and NEWMODM the refined versions of the Dinkelbach method.
7(ii) On the dual basis-based approach
 The dual approach appears to be highly adaptive to solve the fractional problem with a
considerable number of linear ratios (see Wu, 2006b). However, numerical results remain to
be done.
2.4 References
1. Avriel, M., Diewert, W.E., Schaible, S. and Zang, I. (1988). Generalized Concavity, Plenum
Press, New York.
2. Barros, A.I., Frenk, J.B.G., Schaible, S. and Zhang, S. (1996). A new algorithm for
generalized fractional programs, Mathematical Programming 72 147-175.
3. Crouzeix, J.P., Ferland, J.A. and Schaible, S. (1985). An algorithm for generalized fractional
programs, Journal of Optimization Theory and Applications 47 35-49.
4. Crouzeix, J. P., Ferland, J. A. and Schaible, S. (1986). A note on an algorithm for generalized
fractional programs, Journal of Optimization Theory and Applications 50 183-187.
5. Crouzeix, J.P. and Ferland, J.A. (1991). Algorithms for generalized fractional programming,
Mathematical Programming 52 191-207.
6. Dinkelbach, W. (1967). On nonlinear fractional programming, Management Science 13
492-498.
7. Fang, S.-C. and Puthenpura, S. (1993). Linear Optimization and Extensions: Theory and
Algorithms, Prentice-Hall, New Jersey.
8. Ferland, J.A. and Potvin, J.Y. (1985). Generalized fractional programming: algorithms, and
numerical experimentation, European Journal of Operational Research 20 92-101.
9. Frenk, H. and Schaible, S. (2001). Fractional Programming, In: Floudas, C.A., Pardalos, P.M.
(Eds.), Encyclopedia of Optimization 2, Kluwer Academic Publishers, Dordrecht, pp.
162-172.
10. Freund, R.W. and Jarre, F. (1995). An interior-point method for multi-fractional programs
with convex constraints, Journal of Optimization Theory and Applications 85 125-161.
11. Jagannathan, R., and Schaible, S. (1983). Duality in generalized fractional programming via
Farkas' lemma, Journal of Optimization Theory and Applications 41 417-424.
12. Phuong, N.T.H. and Tuy, H. (2003). A unified monotonic approach to generalized linear
fractional programming, Journal of Global Optimization 26 229-259.
13. Stancu-Minasian, I.M. (1997). Fractional Programming: Theory, Methods and Applications,
Kluwer Academic Publishers, Dordrecht.
14. Swarup, K., 1965. Linear fractional functional programming, Operations Research 13
1029-1036.
15. Tigan, S., Stancu-Minasian, I.M. and Tigan, I. (2001). Specific numerical methods for solving
some special max-min programming problems involving generalized convex functions. In:
Hadjisavvas, N., Martinez-Legaz, J.E., Penot, J-P. (Eds.), Generalized Convexity and
Generalized Monotonicity, Springes-Verlag, Berlim, pp. 349-361.
16. Wang, H.F. and Wu, K.Y. (2005). Preference approach to fuzzy linear inequalities and
optimizations, Fuzzy Optimization and Decision Making 4 7-23.
