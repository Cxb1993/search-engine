Abstract
In a wireless sensor network, sensors are usually in the sleep state to prolong the
network life. The tracking system in a wireless sensor network usually uses a prediction
model to predict the next location of the object and activates the appropriate sensors
to keep monitoring the object. Once the prediction fails to track the object, additional
sensors are activated in order to recapture the lost object. Therefore, a better prediction
model can signiﬁcantly reduce power consumption because fewer redundant sensors will
be activated. The Gauss-Markov mobility model is one of the best mobility models
to describe object trajectory because it can capture the correlation of object velocity
in time. Traditionally, Gauss-Markov parameters are estimated using autocorrelation
technique or recursive least square estimation technique; either of these techniques,
however, requires a large amount of historical movement information of the mobile object,
which is not suitable for tracking objects in a wireless sensor network because they
demand a considerable amount of message communication overhead between wireless
sensors which are usually battery-powered. In this project, we aim to develop a message-
eﬃcient location prediction method, a Gauss-Markov parameter estimator, for wireless
sensor networks. This method will be designed to estimate Gauss-Markov parameters
with few requirements in terms of message communication overhead.
Keywords: Wireless sensor network, Gauss-Markov mobility model, Gauss-Markov
parameter estimation, object tracking, message-eﬃcient location prediction.
II
1 計畫的緣由與目的
A wireless sensor network is composed of multiple wireless sensors. Each sensor can
collect, process, and store environmental information as well as communicate with others
via inter-sensor communication. The rapid development of wireless communications and
embedded micro-sensing technologies has facilitated the use of wireless sensor networks in
our daily lives; the study of wireless sensor networks has become one of the most important
areas of research [1, 2, 10, 16, 24, 28, 29, 34, 36, 42]. A wide range of applications exist
for wireless sensor networks, including environmental monitoring, battleﬁeld surveillance,
health care, nuclear, biological, and chemical (NBC) attack detection, intruder detection,
and so on. Another application–and one of the most important areas of research–is
object tracking, in which sensors monitor and report the locations of mobile objects
[4, 7, 20, 25, 33, 38, 45].
In a wireless sensor network, sensors are usually in the sleep state to save energy to
prolong the network life. The tracking system in a wireless sensor network usually includes
three components: 1) a monitoring mechanism, 2) a prediction model, and 3) a recovery
mechanism [14, 35, 39]. A monitoring mechanism activates selected sensors to monitor
and collect the location information of the mobile object using acoustic signal [7, 8, 27]
or images of objects [11, 15, 37]. Once the object moves away from the activated sensors,
the primary sensor among the activated sensors uses a prediction model to predict the
next location of the object and activates the appropriate sensors to continue monitoring
the object. One of the activated sensors receives knowledge of being assigned to be the
next primary sensor. If the prediction fails to track the object, the recovery mechanism
activates additional sensors in order to re-capture the lost object. Therefore, a better
prediction model can signiﬁcantly reduce power consumption because fewer redundant
sensors will be activated.
Many methods for predicting object trajectory have been proposed. The methods
in [22, 23] predict object trajectory using Kalman ﬁlters. In [19, 44], extended Kalman
ﬁlters are proposed because Kalman ﬁlters process non-linear variations in non-trivial
systems with diﬃculty. In [12, 41], sequential Monte Carlo ﬁlters are adopted because
the use of extended Kalman ﬁlters may lead to divergence due to the non-linear nature
of the system. All of these ﬁlters, however, require storage of many parameters, which
are updated by the measured location, velocity, and acceleration of the object, in order
to predict the next location of the object. Therefore, these ﬁlters are not suitable for
tracking objects in a wireless sensor network because multiple parameters (messages)
must be transmitted between the primary sensors, placing a heavy power consumption
burden on wireless sensors, which are usually battery-powered.
Some methods for predicting object trajectory produce little message communication
overhead in a wireless sensor network. The instant prediction model [21, 39, 40] and
the average prediction model [14, 26, 39] predict the subsequent velocity of the object
using the current velocity and the mean of previous velocity measurements, respectively.
1
2 研究方法
Our system model and assumptions are ﬁrst demonstrated. Then, we describe how
the Gauss-Markov parameters μ, σ, and α are estimated in the GMPE MLH model.
Moreover, the prediction location of a mobile object using the estimated values of μ, σ,
and α is given. Finally, theoretical analysis for the GMPE MLH model is provided.
2.1 System Model and Assumptions
It is assumed that each sensor has a region of detection and is capable of measuring the
velocity vectors of the target. In our system model, once an object moves into the sensing
range of the wireless sensor network, a monitoring mechanism activates sensors to monitor
and collect the location information of the object and selects one of the activated sensors
to be the primary sensor. Once the object moves away from the activated sensors, the
primary sensor uses the GMPE MLH model to predict the next location of the object,
activates the appropriate sensors to continue monitoring the object, and designates the
next primary sensor among the activated sensors.
In the Gauss-Markov mobility model, n Gauss-Markov equations are used to describe
the movement of an object in n-dimensional space. In each dimension, the velocity of a
mobile object at time slot t, vt, is modeled by the following Gauss-Markov equation:
vt = αvt−1 + (1− α)μ+
√
1− α2Xt−1, (1)
where Xt−1 is the (t− 1)-th random variable chosen from a normal distribution having
a mean equal to zero and a standard deviation equal to σ, α (0 ≤ α ≤ 1) denotes
the parameter used to vary the randomness of Eq. 1, μ denotes the parameter used to
represent the mean velocity as t → ∞, and σ denotes the parameter used to represent
the standard deviation of velocity as t → ∞. Additionally, μ, σ, and α are called Gauss-
Markov parameters. A normal distribution having a mean equal to μ and a standard
deviation equal to σ is denoted by N(μ, σ2).
In the Gauss-Markov mobility model, when an object moves, the future location is
expected to be accurately predicted by the estimation of its Gauss-Markov parameters,
μ, σ, and α, in n dimensions. Here, we only consider the estimation of μ, σ, and α in
one of the n dimensions due to the similarities of the calculations. Fig. 1 illustrates the
GMPE MLH model in one dimension. The primary sensor uses the parameter estimator
to evaluate μˆt, σˆt, αˆt, and ¯˜αt after it measures vt and receives μˆt−1, σˆt−1, ¯˜αt−1, vt−1,
and t − 1 from the previous sensor, where μˆt, σˆt, and αˆt denote the estimated values
of μ, σ, and α at time slot t, respectively, and ¯˜αt denotes the mean of α˜1, α˜2, . . ., α˜t,
where α˜t denotes the most likely value of α at time slot t, as discussed later. For each
dimension, 4 messages of μˆt, σˆt, ¯˜αt, and vt must be transmitted between the primary
sensors. Therefore, a total of 9 messages are required to be transmitted between the
primary sensors in 2-dimensional space.
3
DD
˃ˁˆˈˆˆˋ
˃ˁˇˇˉ˃˅
˃
˃ˁ˄
˃ˁ˅
˃ˁˆ
˃ˁˇ
˃ˁˈ
˃ˁˉ
˃ˁˊ
˃ˁˋ
˃ˁˌ
˄
˃ ˃ˁ˄ ˃ˁ˅ ˃ˁˆ ˃ˁˇ ˃ˁˈ ˃ˁˉ ˃ˁˊ ˃ˁˋ ˃ˁˌ ˄
˥˸˴˿ʳ˖̈̅̉˸ ˥˸˺̅˸̆̆˼̂́ʳ˖̈̅̉˸
Figure 2: A plot of ¯˜α versus α.
sample of a random variable Vt. Let LVt(α) be the likelihood function of α for sample
vt. It follows that α˜t, the maximum likelihood estimation for α, is the α (0 ≤ α ≤ 1)
value which maximizes LVt(α).
Given vt−1, vt, μ, and σ, LVt(α) is calculated as follows: Substitution into Eq. 1
yields Vt = b + aXt−1, where a =
√
1− α2 and b = αvt−1 + (1 − α)μ. Because
Xt−1 ∼ N(0, σ2), we have Vt ∼ N(b, a2σ2). Therefore, the conditional probability
density function of Vt given A = α, fVt|A(v|α) = 1aσ√2πe−
(v−b)2
2a2σ2 . Thus, LVt(α) is
established in Eq. 5.
LVt(α) = fA|Vt(α|vt) =
1
aσ
√
2π
e−
(vt−b)2
2a2σ2 . (5)
Here, α˜t is calculated by a simple method as follows: The interval [0, 1] is split into
a ﬁnite number of subintervals [α0, α1], [α1, α2], . . ., [αm−1, αm] with α0 = 0 <
α1 < . . . < αm = 1. Subsequently, α˜t is set to
αi+αi+1
2 if
∫ αi+1
αi
LVt(α)dα ≥∫ αj+1
αj
LVt(α)dα for 0 ≤ j < m.
In the GMPE MLH model, once the t-th primary sensor has vt−1, vt, μˆt, σˆt, and
¯˜αt−1, the sensor ﬁrst evaluates α˜t as the α (0 ≤ α ≤ 1) value which maximizes
1√
1−α2σˆt
√
2π
e
− (vt−αvt−1−(1−α)μˆt)
2
2(1−α2)σˆ2t , and subsequently, evaluates ¯˜αt according to Eq. 4.
2.3.2 Evaluation of αˆt
Let Vt−1 denote the random variable of vt−1, fVt−1,Xt−1(v, x) denote the probability
density function of Vt−1 andXt−1, and α˜t(v, x) denote the α (0 ≤ α ≤ 1) value which
maximizes LVt(α) given that Vt−1 = v andXt−1 = x. Then, ¯˜α, the mean of α˜t(v, x)
for all possible values of v and x, is equal to
∫∞
−∞
∫∞
−∞ fVt−1,Xt−1(v, x)α˜t(v, x)dxdv.
Theorem 1, in Section 2.5.1, shows the following equation exists for ¯˜α of a mobile object
5
2.5 Analysis of the GMPE MLH Model
The evaluation of ¯˜α described in Eq. 6 is ﬁrst shown to be correct. Subsequently, the
convergence rates of the estimation of μ, σ, and α are studied. Finally, the accuracy of
the estimation of μ, σ, and α is provided.
2.5.1 Correctness of Evaluation of ¯˜α
Lemma 1 demonstrates the evaluation of fVt−1(v), fXt−1(x), and α˜t(v, x), where
fVt−1(v) and fXt−1(x) denote the probability density functions of Vt−1 and Xt−1,
respectively. Lemma 1 is necessary for the proof of Lemma 2, in which it is shown
that ¯˜α is invariant with respect to μ and σ of the mobile object. Then, with the help
of Lemma 2, ¯˜α of the mobile object having the Gauss-Markov parameters μ, σ, and
α = α1 can be evaluated by setting μ = 0 and σ = 1, as concluded in Theorem 1.
Lemma 1. LetO1 be a mobile object having the Gauss-Markov parameters
μ = μ1, σ = σ1, and α = α1. For object O1, fVt−1(v) =
1√
2πσ1
e
− (v−μ1)2
2σ21 ,
fXt−1(x) =
1√
2πσ1
e
− x2
2σ21 , and α˜t(v, x) is equal to the α (0 ≤ α ≤ 1) value
which maximizes 1√
2π(1−α2)σ1
e
−
(
α1v+(1−α1)μ1+
√
1−α21x−αv−(1−α)μ1
)2
2(1−α2)σ21 .
Proof. Vt−1 ∼ N(μ1, σ21); therefore, fVt−1(v) = 1√2πσ1e
− (v−μ1)2
2σ21 . Xt−1 ∼
N(0, σ21); therefore, fXt−1(x) =
1√
2πσ1
e
− x2
2σ21 . Given Vt−1 = v and Xt−1 = x,
vt = α1v + (1 − α1)μ1 +
√
1− α21x according to Eq. 1. Thus, LVt(α) =
1√
2π(1−α2)σ1
e
−
(
α1v+(1−α1)μ1+
√
1−α21x−αv−(1−α)μ1
)2
2(1−α2)σ21 according to Eq. 5. This implies
that α˜t(v, x) is the α (0 ≤ α ≤ 1) value that maximizes 1√
2π(1−α2)σ1
×
e
−
(
α1v+(1−α1)μ1+
√
1−α21x−αv−(1−α)μ1
)2
2(1−α2)σ21 .
Lemma 2. Let O1 and O2 be two mobile objects having the Gauss-Markov
parameters μ = μ1, σ = σ1, and α = α1 and the Gauss-Markov parameters
μ = μ2, σ = σ2, and α = α2, respectively. If α1 = α2, ¯˜α of object O1 is
equal to ¯˜α of object O2.
Proof. Because random variables Vt−1 and Xt−1 are independent, ¯˜α =∫∞
−∞
∫∞
−∞ fVt−1(v)fXt−1(x)α˜t(v, x)dxdv. So, ¯˜α = lim→∞
∫ μ+σ
μ−σ
∫ σ
−σ fVt−1(v)
fXt−1(x) α˜t(v, x) dx dv. That is, the value of ¯˜α of object O1 is lim→∞
7
√
1− α21x1,j − αv1,i − (1 − α)μ1 = k
(
α2v2,i + (1 − α2)μ2 +
√
1− α22x2,j −
αv2,i − (1 − α)μ2
)
, if α1 = α2. So,
Y
Z =
σ2
σ1
, if α1 = α2. Because
σ2
σ1
is a
constant, the validity of Eq. 11 is established. According to Eqs. 10 and
11, limm→∞ limn→∞
∑m
i=1
∑n
j=1 fVt−1(v1,i) fXt−1(x1,j) α˜t(v1,i, x1,j) Δx1 Δv1
= limm→∞ limn→∞
∑m
i=1
∑n
j=1 fVt−1(v2,i) fXt−1(x2,j) α˜t(v2,i, x2,j) Δx2 Δv2,
if α1 = α2.
Theorem 1. LetO1 be a mobile object having the Gauss-Markov parameter
α = α1. Then, ¯˜α of object O1 is equal to
∫∞
−∞
∫∞
−∞
1
2πe
− v2+x22 α˜t(v, x)dxdv,
where α˜t(v, x) is equal to the α (0 ≤ α ≤ 1) value which maximizes
1√
2π(1−α2)e
−
(
α1v+
√
1−α21x−αv
)2
2(1−α2) .
Proof. Because random variables Vt−1 and Xt−1 are independent, ¯˜α =∫∞
−∞
∫∞
−∞
1√
2πσ1
e
− (v−μ1)2
2σ21
1√
2πσ1
e
− x2
2σ21 α˜t(v, x)dxdv according to Lemma 1, where
α˜t(v, x) is equal to the α value which maximizes
1√
2π(1− α2)σ1
e
−
(
α1v+(1−α1)μ1+
√
1−α21x−αv−(1−α)μ1
)2
2(1−α2)σ21 .
Because ¯˜α is invariant with respect to the values of the Gauss-Markov
parameters μ and σ of the mobile object according to Lemma 2, ¯˜α =∫∞
−∞
∫∞
−∞
1
2πe
− v2+x22 α˜t(v, x)dxdv, where α˜t(v, x) is equal to the α value which
maximizes 1√
2π(1−α2)e
−
(
α1v+
√
1−α21x−αv
)2
2(1−α2) , by setting μ1 = 0 and σ1 = 1, as
desired.
2.5.2 Convergence Rates of Estimation of μ, σ, and α
Theorem 2 shows that the convergence rates of μˆt and σˆt are 1/
√
n, where n denotes
the number of samples, using a similar argument described in [32]. In addition, because
αˆt is evaluated by ¯˜αt by Eq. 8, we demonstrate that the convergence rate of ¯˜αt is
1/
√
n in Theorem 3. Let Wi denote a random variable, α˜t(Vt−1, Xt−1). To prove
Theorem 3, it is suﬃcient to show 1n
∑n
i=1Wi ∼ N( ¯˜α, ( σ√n)2) as n → ∞. Let
X1, X2, · · · , Xn denote a sequence of speciﬁc random variables, and let Fn(x) and
Φ(x) be the cumulative distribution functions of random variable Z = Tn−nμ
σ
√
n
and
N(0, 1), respectively, where Tn =
∑n
i=1Xi, and μ and σ
2 denote the mean and
variance of X1, respectively. Lemma 3, as proved in [32], describes that the least upper
bound of the absolute diﬀerence ofFn(x) and Φ(x) for x ∈ R is bounded byO(1/
√
n),
implying that the distribution of Tn =
∑n
i=1Xi approximates to N(nμ, (σ
√
n)2)
9
on the order of 1/
√
n. Because W1,W2, · · · ,Wn are a sequence of speciﬁc random
variables described in Lemma 3 andE[W1] = ¯˜α,
∑n
i=1Wi approximates toN(n
¯˜α, (σ
√
n)2)
on the order of 1/
√
n. This implies that 1n
∑n
i=1Wi ∼ N( ¯˜α, ( σ√n)2) as n → ∞,
and hence Theorem 3 follows.
Theorem 2. The convergence rates of μˆt and σˆt are 1/
√
n, where n denotes
the number of samples.
Proof. Let Vi, i ≥ 1, denote the random variable of vi, V¯n = 1n
∑n
i=1 Vi,
and S2n =
1
n
∑n
i=1(Vi − V¯n)2. The convergence rate of μˆt is 1/
√
n because
V¯n ∼ N(μ, ( σ√n)2) as n → ∞, as proved in [32]. In addition, it is shown
in [32] that
√
n(
√
n√
n−1Sn−σ)
(2σ)−1γ ∼ N(0, 1) as n → ∞, where γ2 = μ4 − σ4 and
μ4 = E[(V1−μ)4]. Furthermore, as n → ∞,
√
n√
n−1 → 1, implying
√
n(Sn−σ)
(2σ)−1γ ∼
N(0, 1), and thus Sn ∼ N(σ, ( γ2σ√n)2). Therefore, the convergence rate of
σˆt is 1/
√
n.
Lemma 3. Let {Xn} be a sequence of independent and identically-distributed
(i.i.d.) random variables with E[X1] = μ, variance of X1 equal to σ
2 and
suppose that E[|X1 − μ|2+δ] = ν2+δ < ∞ for some 0 < δ ≤ 1. Also
let Tn =
∑n
i=1Xi, Fn(x) = Pr{Tn−nμσ√n ≤ x}, x ∈ R. Then there exists a
constant C such that
Δn = sup
x∈R
|Fn(x)− Φ(x)| ≤ Cν2+δn
−δ/2
σ2+δ
, (12)
where supx∈R g(x) denotes the least upper bound or supremum of g(x) for
x ∈ R and Φ(x) is the cumulative distribution function of N(0, 1).
Theorem 3. The convergence rate of ¯˜αt is 1/
√
n, where n denotes the
number of samples.
Proof. Let O1 be a mobile object having the Gauss-Markov parameter α =
α1. Because ¯˜α of O1 is equal to E[α˜t(Vt−1, Xt−1)] with random variables
Vt−1 ∼ N(μ1, σ21) and Xt−1 ∼ N(0, σ21), it suﬃces to show 1n
∑n
i=1Wi ∼
N( ¯˜α, ( σ√
n
)2) as n → ∞, whereWi denotes a random variable, α˜t(Vt−1, Xt−1).
First note that Wi and Wj, 1 ≤ i 	= j ≤ n, are identically distributed
because Pr{Wi ≤ x} = Pr{Wj ≤ x} for all x. Because Wi and Wj are
mutually independent, {Wn} is a sequence of i.i.d. random variables. In
addition, E[|W1−E[W1]|3] =
∫∞
−∞
∫∞
−∞
1√
2πσ1
e
− (v−μ1)2
2σ21 · 1√
2πσ1
e
− x2
2σ21 · |α˜t(v, x)−
E[W1]|3dxdv ≤
∫∞
−∞
∫∞
−∞
1√
2πσ1
e
− (v−μ1)2
2σ21 · 1√
2πσ1
e
− x2
2σ21 · 13dxdv = 1 < ∞
because 0 ≤ α˜t(v, x) ≤ 1 and 0 ≤ E[W1] ≤ 1. According to Lemma 3,
11
95% conﬁdence interval for y at x = x0 is given by
yˆ0 ± t0.025k s
√
1 + fT0 (F
TF)−1f0, (13)
where yˆ0 = f(x0; Θˆ), t0.025k = 1.645 denotes the upper 0.025 critical value
of the t-distribution with k degrees of freedom, s =
√∑n
i=1 (yi − yˆi)2/k,
fi =
(∂f(xi;Θ)
∂θ1
, ∂f(xi;Θ)∂θ2 , . . . ,
∂f(xi;Θ)
∂θp
)T
for 0 ≤ i ≤ n, and F = (f1, f2, . . . , fn)T .
Theorem 5. The approximate 95% conﬁdence interval for α is within
0.00812 of αˆt as t → ∞.
Proof. We ﬁrst show the approximate 95% conﬁdence interval for α is
within 0.00812 ofG( ¯˜α). According to Eq. 7, we need to show the approximate
95% conﬁdence interval for α is within 0.00812 of G( ¯˜α) if C1) 0.35338 <
¯˜α ≤ 0.44602 and C2) 0.44602 < ¯˜α ≤ 1. The proof of C1 is omitted due
to its similarity with the proof of C2. For C2, Θˆ = (0.37492,−0.55069).
According to Lemma 4, the approximate 95% conﬁdence interval for α is
given by
G( ¯˜α)±1.645×0.00493
√
2.58456× ( ln((x− 0.2)/x) + 0.40848)2 + 1.0001.
It is easy to verify that
1.645× 0.00493
√
2.58456× ( ln((x− 0.2)/x) + 0.40848)2 + 1.0001
is concave up on [0.44602, 1], and has maximum value 0.00812, implying
that the approximate 95% conﬁdence interval for α is given by G( ¯˜α) ±
0.00812. In addition, since limt→∞ ¯˜αt = ¯˜α (because 1n
∑n
i=1Wi ∼ N( ¯˜α, ( σ√n)2)
as n → ∞, whereWi denotes a random variable, α˜t(Vt−1, Xt−1), as demonstrated
in Theorem 3) and αˆt = G( ¯˜αt), the approximate 95% conﬁdence interval
for α is within 0.00812 of αˆt as t → ∞.
13
tˆ
t
P
P

˃
˄
˅
ˆ
ˇ
ˈ
ˉ
ˊ
ˋ
ˌ
˄˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(a)
t
ˆ
t
V
V

˃
˄
˅
ˆ
ˇ
ˈ
ˉ
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(b)
t
ˆ
t
D
D

˃
˃ˁ˃ˆ
˃ˁ˃ˉ
˃ˁ˃ˌ
˃ˁ˄˅
˃ˁ˄ˈ
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(c)
˚̅̂̈̃ʳ˔ ˚̅̂̈̃ʳ˖ ˚̅̂̈̃ʳ˗ ˚̅̂̈̃ʳ˙ ˚̅̂̈̃ʳ˚ ˚̅̂̈̃ʳ˛˚̅̂̈̃ʳ˘˚̅̂̈̃ʳ˕
Figure 4: The diﬀerences between the actual and estimated values of parameters (a) μ,
(b) σ, and (c) α for the GMPE MLH model.
15
İȝ
co
nv
_t
ȝ
˃
˄˃˃
˅˃˃
ˆ˃˃
ˇ˃˃
ˈ˃˃
ˉ˃˃
ˊ˃˃
ˋ˃˃
ˌ˃˃
˄˃˃˃
˃ˁ˄ ˃ˁ˅ ˃ˁˆ ˃ˁˇ ˃ˁˈ ˃ˁˉ ˃ˁˊ ˃ˁˋ ˃ˁˌ ˄
(a)
İı
co
nv
_t
ı
˃
˄˃˃
˅˃˃
ˆ˃˃
ˇ˃˃
ˈ˃˃
ˉ˃˃
ˊ˃˃
ˋ˃˃
ˌ˃˃
˄˃˃˃
˃ˁ˄ ˃ˁ˅ ˃ˁˆ ˃ˁˇ ˃ˁˈ ˃ˁˉ ˃ˁˊ ˃ˁˋ ˃ˁˌ ˄
(b)
İĮ
co
nv
_t
Į
˃
˄˃˃
˅˃˃
ˆ˃˃
ˇ˃˃
ˈ˃˃
ˉ˃˃
ˊ˃˃
ˋ˃˃
ˌ˃˃
˄˃˃˃
˃ˁ˄ ˃ˁ˅ ˃ˁˆ ˃ˁˇ ˃ˁˈ ˃ˁˉ ˃ˁˊ ˃ˁˋ ˃ˁˌ ˄
(c)
˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲ˠ˟˛ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃˃ʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃ʼ
Figure 5: Convergence rates of the estimated values of (a) μ, (b) σ, and (c) α for the
GMPE MLH model, the GMPE ACR model, and the GMPE RLSE model in the Gauss-
Markov mobility model having parameters of Group A.
17
tR
M
S
E
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
ˋˈ
ˌ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(a)
t
R
M
S
E
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
ˋˈ
ˌ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(b)
t
R
M
S
E
ˆ˃
ˆˈ
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(c)
t
R
M
S
E
ˆ˃
ˆˈ
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(d)
˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲ˠ˟˛ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃˃ʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃ʼ
Figure 6: Measurement of RMSE for the GMPE MLH model, the GMPE ACR model,
and the GMPE RLSE model in the Gauss-Markov mobility model. Parameters used in
Group A: (a); Group B: (b); Group C: (c); and Group D: (d).
19
Figure 7: The Markov chain.
prediction model provides a poor performance of RMSE in the random walk mobility
model due to the fact that a mobile object has a great opportunity to make a sharp turn.
3.5 Measurement ofRMSE in the Dynamic Gauss-Markov Mobility
Model
In the simulation, each mobile object changed the Gauss-Markov parameters, which were
randomly chosen from the parameter ranges of the mobility models at k, 1 ≤ k ≤ 10,
time slots, which were randomly chosen from 5000 time slots. The GMPE MLH Dynamic
model, which is equivalent to the GMPE MLH model except for the functionality of
indicating changes in the Gauss-Markov parameters, was compared with the GMPE ACR
model and the GMPE RLSE model. The GMPE MLH Dynamic model indicates a
change inα based on the fact that the distribution of the random variable of ¯˜αt approximates
to a normal distribution with a mean equal to ¯˜α, as demonstrated in Theorem 3. In time
slot 5i+5, i is an integer in the interval [0, 999], the mean of 5 α˜t in time slots 5i+1
through 5i+5 is obtained to be one sample datum of ¯˜αt. In time slot 25j+25, j is an
integer in the interval [0, 199], the means and variances of the history samples and the
recent samples are evaluated; the history samples comprise all sample data of ¯˜αt from
the beginning of the prediction model, or the last time slot in which the prediction model
is reset, and the recent samples comprise the last 5 sample data of ¯˜αt. Then, if an F -test
[9] with a level of signiﬁcance of 5% indicates equality (or, inequality) of the variances
of the history samples and the recent samples, a t-test [9] (or, Welch’s t-test [30]) with a
level of signiﬁcance of 5% is used. If the t-test or Welch’s t-test indicates inequality of the
means of the history samples and the recent samples, the GMPE MLH Dynamic model
indicates a change in α and resets the prediction model. The GMPE MLH Dynamic
model requires 4 messages to indicate a change in α. 1 message is required to obtain
one sample datum of ¯˜αt in time slot 5i + 5, and 3 messages are required to obtain
the variance of the history samples and the mean and variance of the recent samples in
time slot 25j + 25. Note that the mean of the history samples is obtained without an
additional message because it is equal to ¯˜αt.
The GMPE MLH Dynamic model indicates changes in μ and σ based on the fact that
the distribution of random variable Vt is a normal distribution in a manner analogous
21
kR
M
S
E
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
ˋˈ
ˌ˃
ˌˈ
˄˃˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(a)
k
R
M
S
E
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
ˋˈ
ˌ˃
ˌˈ
˄˃˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(b)
k
R
M
S
E
ˆ˃
ˆˈ
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(c)
k
R
M
S
E
ˆ˃
ˆˈ
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(d)
˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲ˠ˟˛˲˗̌́˴̀˼˶ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ːЌʼ
Figure 9: Measurement of RMSE for the GMPE MLH Dynamic model, the GMPE ACR
model, and the GMPE RLSE model in the dynamic Gauss-Markov mobility model.
Parameters used in Group A: (a); Group B: (b); Group C: (c); and Group D: (d).
23
model, the value ofD and the probability of a transition from state 0, 1, or 2 to the same
state were randomly chosen from the intervals [0 m, 100 m] and [0, 1], respectively.
In the dynamic random waypoint mobility model, − m ≤ Δx, Δy ≤  m, where
 was randomly chosen from the interval [0, 600]. In the dynamic ETSI vehicular
mobility model, the velocity and the probability of changing direction were randomly
chosen from the intervals [100 km/hr, 140 km/hr] and [0, 40%], respectively, and the
direction interval was a subinterval randomly chosen from the interval [−π/2, π/2]. In
the dynamic smooth random mobility model, the probabilities of changing velocity and
direction were randomly chosen from the intervals [0, 8%] and [0, 4%], respectively, and
the acceleration and deceleration intervals were subintervals randomly chosen from the
intervals (0, 5] and [−8, 0), respectively.
As illustrated in Fig. 10, in all dynamic mobility models, the larger the value of k,
the worse the ﬁt in the values of RMSE in each of the three prediction models. In all
dynamic mobility models, except for the dynamic ETSI vehicular mobility model and
the dynamic smooth random mobility model, the GMPE RLSE model provides poor
prediction, and the GMPE MLH Dynamic model provides comparable prediction to the
GMPE ACR model. In the dynamic ETSI vehicular mobility model, or the dynamic
smooth random mobility model, each of the three prediction models provides a good
performance of RMSE. More speciﬁcally, the GMPE MLH Dynamic model provides
worse prediction than either the GMPE ACR model or the GMPE RLSE model in the
dynamic ETSI vehicular mobility model and the dynamic smooth random mobility model.
This stems from the observation that the history information concerning object trajectory
is useful for location prediction, because a mobile object has little opportunity to make a
big change in either the velocity or the direction in these two dynamic mobility models.
25
4 結果與討論
In this project, we have proposed a method to predict object trajectory. Since the
Gauss-Markov mobility model is one of the best mobility models to describe object
trajectory, we developed a Gauss-Markov parameter estimator, GMPE MLH, using a
maximum likelihood technique. The GMPE MLH model requires the transmission of
only 9 messages between the primary sensors in a 2-dimensional space and generates
negligible diﬀerences between the actual and estimated values of the Gauss-Markov
parameters, therefore we believe that it is a novel method for a wireless sensor network
to predict object trajectory. In addition, the method can be easily extended to 3-
dimensional space in which 13 messages are transmitted between the primary sensors.
Also, the GMPE MLH model can be used to predict object trajectory in wireless personal
communication service networks and mobile ad hoc networks as well. Furthermore, an
extention of the GMPE MLH model, termed GMPE MLH Dynamic, is proposed to
predict object trajectory in the dynamic Gauss-Markov mobility model in which the
object may change Gauss-Markov parameters along with time.
Using simulations, we compared the performance of the GMPE MLH model with the
Gauss-Markov parameter estimators using an autocorrelation technique (GMPE ACR)
and a recursive least square estimation technique (GMPE RLSE). Either the GMPE ACR
model or the GMPE RLSEmodel needs a large amount of historical trajectory information
to provide good estimation of the Gauss-Markov parameters. As compared to the GMPE
ACRmodel and the GMPE RLSE model, simulations show that the GMPE MLHmodel
provides comparable prediction for object trajectory while requiring much less message
transmission overhead. Nevertheless, simulations show that the GMPE MLH Dynamic
model can well-predict object trajectory in the dynamic Gauss-Markov mobility model.
27
[12] B. Dong and X. Wang, “Adaptive mobile positioning in WCDMA networks,”
EURASIP Journal on Wireless Communications and Networking, vol.
5, no. 3, pp. 343–353, 2005.
[13] K.T. Feng, C.H. Hsu, and T.E. Lu, “Velocity-assisted predictive mobility and
location-aware routing protocols for mobile ad hoc networks,” IEEE Trans. on
Vehicular Technology, vol. 57, no. 1, pp. 448–464, 2008.
[14] Z. Guo, M. Zhou, and L. Zakrevski, “Optimal tracking interval for predictive tracking
in wireless sensor network,” IEEE Communications Letters, vol. 9, no. 9, pp.
805–807, 2005.
[15] B.H. Kim, D.K. Roh, J.M. Lee, M.H. Lee, K. Son, M.C. Lee, J.W. Choi, and
S.H. Han, “Localization of a mobile robot using images of a moving target,” IEEE
ICRA, pp. 253–258, 2001.
[16] S.P. Kuo, H.J. Kuo, and Y.C. Tseng, “The beacon movement detection problem in
wireless sensor networks for localization applications,” IEEE Trans. on Mobile
Computing, vol. 8, no. 10, pp. 1326–1338, 2009.
[17] B. Liang and Z.J. Haas, “Predictive distance-based mobility management for
multidimensional PCS networks,” IEEE/ACM Trans. on Networking, vol.
11, no. 5, pp. 718–732, 2003.
[18] B. Liang and Z.J. Haas, “Predictive distance-based mobility management for PCS
networks,” IEEE INFOCOM, pp. 1377–1384, 1999.
[19] T. Liu, P. Bahl, and I. Chlamtac, “Mobility modeling, location tracking, and
trajectory prediction in wireless ATM networks,” IEEE Journal on Selected
Areas in Communications, vol. 16, no. 6, pp. 922–936, 1998.
[20] B.H. Liu, W.C. Ke, C.H. Tsai, and M.J. Tsai, “Constructing a message-pruning
tree with minimum cost for tracking moving objects in wireless sensor networks is
NP-complete and an enhanced data aggregation structure,” IEEE Trans. on
Computers, vol. 57, no. 6, pp. 849-863, 2008.
[21] X. Luo, T. Camp, and W. Navidi, “Predictive methods for location services in mobile
ad hoc networks,” IEEE WMAN, pp. 246–252, 2005.
[22] D. McErlean and S. Narayanan, “Distributed detection and tracking in sensor
networks,” IEEE ACSSC, pp. 1174–1178, 2002.
[23] M. McGuire and K.N. Plataniotis, “Dynamic model-based ﬁltering for mobile
terminal location estimation,” IEEE Trans. on Vehicular Technology, vol.
52, no. 4, pp. 1012–1031, 2003.
29
[36] Y.C. Wang, Y.Y. Hsieh, and Y.C. Tseng, “Multiresolution spatial and temporal
coding in a wireless sensor network for long-term monitoring applications,” IEEE
Trans. on Computers, vol. 58, no. 6, pp. 827–838, 2009.
[37] X. Wang and S. Wang, “Collaborative signal processing for target tracking in
distributed wireless sensor networks,” Journal of Parallel and Distributed
Computing, vol. 67, no. 5, pp. 501–515, 2007.
[38] J. Xu, X. Tang, and W.C. Lee, “A new storage scheme for approximate location
queries in object-tracking sensor networks,” IEEE Trans. on Parallel and
Distributed Systems, vol. 19, no. 2, pp. 262–275, 2008.
[39] Y. Xu, J. Winter, and W.C. Lee, “Prediction-based strategies for energy saving in
object tracking sensor networks,” IEEE MDM, pp. 346–357, 2004.
[40] H. Yang and B. Sikdar, “A protocol for tracking mobile targets using sensor
networks,” IEEE SNPA, pp. 71–81, 2003.
[41] Z. Yang and X. Wang, “Joint mobility tracking and handoﬀ in cellular networks via
sequential Monte Carlo ﬁltering,” IEEE Trans. on Signal Processing, vol. 51,
no. 1, pp. 269–281, 2003.
[42] Z. Ye, A.A. Abouzeid, and J. Ai, “Optimal stochastic policies for distributed data
aggregation in wireless sensor networks,” IEEE/ACM Trans. on Networking,
vol. 17, no. 5, pp. 1494–1507, 2009.
[43] W.L. Yeow, C.K. Tham, and W.C. Wong, “Energy eﬃcient multiple target tracking
in wireless sensor networks,” IEEE Trans. on Vehicular Technology, vol. 56,
no. 2, pp. 918–928, 2007.
[44] Z.R. Zaidi and B.L. Mark, “Real-time mobility tracking algorithms for cellular
networks based on Kalman ﬁltering,” IEEE Trans. on Mobile Computing,
vol. 4, no. 2, pp. 195–208, 2005.
[45] W. Zhang and G. Cao, “Optimizing tree reconﬁguration for mobile target tracking
in sensor networks,” IEEE INFOCOM, pp. 2434–2445, 2004.
31
7 附錄
執行本計畫期間相關之發表論文陳列如下：
[附錄一] Bing-Hong Liu, Min-Lun Chen, and Ming-Jer Tsai, “Message-Eﬃcient location
prediction for mobile objects in wireless sensor networks using a maximum likelihood
technique,” IEEE Transactions on Computers, vol. 60, no. 6, pp. 865—878,
2011.
[附錄二] Chia-Hung Lin, Jian-Jhih Kuo, Bing-Hong Liu, and Ming-Jer Tsai, “GPS-free,
boundary-recognition-free, and reliable double-ruling-based information brokerage
scheme in wireless sensor networks,” accepted by IEEE Transactions on
Computers.
[附錄三] 周達鈞, 廖斌毅, 劉炳宏, “應用於無線感測網路資料蒐集之以軸為導向的繞
徑方法,”第一屆網路智能與應用研討會(NCWIA 2011), pp. 377—381, 2011.
[附錄四] 侯柏宇,邱士維,劉炳宏, “在3D無線感測網路以虛擬座標為基礎的繞徑協定,”
第一屆網路智能與應用研討會(NCWIA 2011), pp. 382—386, 2011.
33
1Message-Efficient Location Prediction for Mobile
Objects in Wireless Sensor Networks Using a
Maximum Likelihood Technique
Bing-Hong Liu, Min-Lun Chen, and Ming-Jer Tsai
Abstract—In the tracking system, a better prediction model can significantly reduce power consumption in a wireless sensor network
because fewer redundant sensors will be activated to keep monitoring the object. The Gauss-Markov mobility model is one of the
best mobility models to describe object trajectory because it can capture the correlation of object velocity in time. Traditionally, the
Gauss-Markov parameters are estimated using an autocorrelation technique or a recursive least square estimation technique; either
of these techniques, however, requires a large amount of historical movement information of the mobile object, which is not suitable
for tracking objects in a wireless sensor network because they demand a considerable amount of message communication overhead
between wireless sensors which are usually battery-powered. In this paper, we develop a Gauss-Markov parameter estimator for
wireless sensor networks (GMPE MLH) using a maximum likelihood technique. The GMPE MLH model estimates the Gauss-Markov
parameters with few requirements in terms of message communication overhead. Simulations demonstrate that the GMPE MLHmodel
generates negligible differences between the actual and estimated values of the Gauss-Markov parameters and provides comparable
prediction of the mobile object’s location to the Gauss-Markov parameter estimators using an autocorrelation technique or a recursive
least square estimation.
Index Terms—Wireless sensor network, Gauss-Markov mobility model, Gauss-Markov parameter estimation, object tracking,
message-efficient location prediction.
F
1 INTRODUCTION
AWIRELESS sensor network is composed of multiplewireless sensors. Each sensor can collect, process,
and store environmental information as well as com-
municate with others via inter-sensor communication.
The rapid development of wireless communications and
embedded micro-sensing technologies has facilitated the
use of wireless sensor networks in our daily lives; the
study of wireless sensor networks has become one of the
most important areas of research [1], [2], [10], [16], [24],
[28], [29], [34], [36], [42]. A wide range of applications
exist for wireless sensor networks, including environ-
mental monitoring, battlefield surveillance, health care,
nuclear, biological, and chemical (NBC) attack detection,
intruder detection, and so on. Another application–and
one of the most important areas of research–is object
tracking, in which sensors monitor and report the loca-
tions of mobile objects [4], [7], [20], [25], [33], [38], [45].
In a wireless sensor network, sensors are usually in
the sleep state to save energy to prolong the network life.
The tracking system in a wireless sensor network usually
includes three components: 1) a monitoring mechanism,
• B.H. Liu is with the Department of Electronic Engineering, National Kaoh-
siung University of Applied Sciences, 415, Chien Kung Rd., Kaohsiung
80778, Taiwan, ROC. E-mail: bhliu@cc.kuas.edu.tw.
• M.L. Chen and M.J. Tsai are with the Department of Computer Sci-
ence, National Tsing Hua University, 101, Kuang Fu Rd., Sec. 2,
Hsinchu 30013, Taiwan, ROC. E-mail: alen@dclab.cs.nthu.edu.tw, mjt-
sai@cs.nthu.edu.tw.
2) a prediction model, and 3) a recovery mechanism [14],
[35], [39]. A monitoring mechanism activates selected
sensors to monitor and collect the location information
of the mobile object using acoustic signal [7], [8], [27] or
images of objects [11], [15], [37]. Once the object moves
away from the activated sensors, the primary sensor
among the activated sensors uses a prediction model to
predict the next location of the object and activates the
appropriate sensors to continue monitoring the object.
One of the activated sensors receives knowledge of being
assigned to be the next primary sensor. If the prediction
fails to track the object, the recovery mechanism activates
additional sensors in order to re-capture the lost object.
Therefore, a better prediction model can significantly
reduce power consumption because fewer redundant
sensors will be activated.
Many methods for predicting object trajectory have
been proposed. The methods in [22], [23] predict object
trajectory using Kalman filters. In [19], [44], extended
Kalman filters are proposed because Kalman filters pro-
cess non-linear variations in non-trivial systems with
difficulty. In [12], [41], sequential Monte Carlo filters are
adopted because the use of extended Kalman filters may
lead to divergence due to the non-linear nature of the
system. All of these filters, however, require storage of
many parameters, which are updated by the measured
location, velocity, and acceleration of the object, in order
to predict the next location of the object. Therefore,
these filters are not suitable for tracking objects in a
wireless sensor network because multiple parameters
3t
v
1
ˆ
t
P 
1t
v 
1t
D 
1
ˆ
t
V 
1t  ˆtD
ˆ
t
P
t
v
t
D
ˆ
t
V
t
Fig. 1: The GMPE MLH model.
and
αˆt =
 1, if σˆt ≈ 0,max{0, σˆ′2tσˆ2t
}
, otherwise, (4)
where σˆ′2t =
1
west−1
∑west−1
i=1 (v
′
i − µˆt)(v′i+1 − µˆt).
In each dimension, the predicted location of the mobile
device at time slot t + n, xˆt+n, is calculated by the
following equation:
xˆt+n = xt +
1− αˆnt
1− αˆt vt +
(
1− 1− αˆ
n
t
1− αˆt
)
µˆt, (5)
where xt denotes the actual location of the mobile device
at time slot t.
2.2 The GMPE RLSE Model
In the GMPE RLSE model, the velocity and the moving
direction with respect to the positive x-axis are used to
describe the movement of an object in 2-dimensional
space. The velocity and the moving direction of a mobile
object at time slot t, denoted by vt and θt, respectively,
are modeled by the Gauss-Markov equation shown in
Eq. 1.
Given the previous west samples of the device velocity
v′1, v′2, . . ., v′west , the estimated value of µ at time slot t,
µˆt, is calculated by Eq. 2. The estimated value of α at
time slot t, αˆt, is calculated by the following recursive
least square estimation:
γˆ
west
= γˆ
west−1 −Kwest(Hwest γˆwest−1 − ywest), (6)
where γˆ
west
=
[
αˆt
1− αˆt
]
, Hk =
[
v′k−1 µˆt
]
, y
k
=[
v′k
]
, Kk = PkH
T
k , Pk =
1
λ
[
Pk−1 − Pk−1H
T
kHkPk−1
λ+HkPk−1HTk
]
,
P0 is an identity matrix, and λ is a tunable parameter.
The estimated velocity of the mobile object at time slot
t+ 1, vˆt+1, is calculated by the following equation:
vˆt+1 = αˆtvt + (1− αˆt)µˆt. (7)
The estimated moving direction of the mobile object at
time slot t + 1, θˆt+1, can be calculated in the manner
analogous to that of vˆt+1. The predicted location of the
mobile object at time slot t+1, (xˆt+1, yˆt+1), is calculated
by the following equations:
xˆt+1 = xt + vˆt+1 cos θˆt+1 (8)
and
yˆt+1 = yt + vˆt+1 sin θˆt+1, (9)
where (xt, yt) denotes the actual location of the mobile
object at time slot t.
3 THE GMPE MLH MODEL
Our system model and assumptions are first demon-
strated. Then, we describe how the Gauss-Markov pa-
rameters µ, σ, and α are estimated in the GMPE MLH
model. Finally, the prediction location of a mobile object
using the estimated values of µ, σ, and α is given.
3.1 System Model and Assumptions
It is assumed that each sensor has a region of detection
and is capable of measuring the velocity vectors of
the target. In our system model, once an object moves
into the sensing range of the wireless sensor network,
a monitoring mechanism activates sensors to monitor
and collect the location information of the object and
selects one of the activated sensors to be the primary
sensor. Once the object moves away from the activated
sensors, the primary sensor uses the GMPE MLH model
to predict the next location of the object, activates the ap-
propriate sensors to continue monitoring the object, and
designates the next primary sensor among the activated
sensors.
In the Gauss-Markov mobility model, when an object
moves, the future location is expected to be accurately
predicted by the estimation of its Gauss-Markov parame-
ters, µ, σ, and α, in n dimensions. Here, we only consider
the estimation of µ, σ, and α in one of the n dimensions
due to the similarities of the calculations. Fig. 1 illustrates
the GMPE MLH model in one dimension. The primary
sensor uses the parameter estimator to evaluate µˆt, σˆt, αˆt,
and ¯˜αt after it measures vt and receives µˆt−1, σˆt−1, ¯˜αt−1,
vt−1, and t−1 from the previous sensor, where µˆt, σˆt, and
αˆt denote the estimated values of µ, σ, and α at time slot
t, respectively, and ¯˜αt denotes the mean of α˜1, α˜2, . . .,
α˜t, where α˜t denotes the most likely value of α at time
slot t, as discussed later. For each dimension, 4 messages
of µˆt, σˆt, ¯˜αt, and vt must be transmitted between the
primary sensors. Therefore, a total of 9 messages are
required to be transmitted between the primary sensors
in 2-dimensional space.
3.2 Estimation of µ and σ
In the GMPE MLH model, the following recurrence
exists for µˆt:
µˆ1 = v1;
µˆt =
t− 1
t
µˆt−1 +
1
t
vt, if t ≥ 2;
(10)
and, the following recurrence exists for σˆt:
σˆ21 = 0;
σˆ22 =
(v1 − µˆ2)2 + (v2 − µˆ2)2
2
;
σˆ2t =
t− 1
t
σˆ2t−1 +
1
t− 1(vt − µˆt)
2, if t ≥ 3.
(11)
5denotes the expected value of vˆt+1. Because vˆt+1 = αˆtvt+
(1− αˆt)µˆt+
√
1− αˆ2tXt by Eq. 1 and E[Xt] = 0 (because
Xt ∼ N(0, σ2)), xˆt+1 can be calculated by the following
equation:
xˆt+1 = xt + αˆtvt + (1− αˆt)µˆt. (17)
4 ANALYSIS OF THE GMPE MLH MODEL
The evaluation of ¯˜α described in Eq. 14 is first shown
to be correct. Subsequently, the convergence rates of
the estimation of µ, σ, and α are studied. Finally, the
accuracy of the estimation of µ, σ, and α is provided. In
the paper, all lemmas and theorems are proved in the
appendix.
4.1 Correctness of Evaluation of ¯˜α
Lemma 1 demonstrates the evaluation of fVt−1(v),
fXt−1(x), and α˜t(v, x), where fVt−1(v) and fXt−1(x) de-
note the probability density functions of Vt−1 and Xt−1,
respectively. Lemma 1 is necessary for the proof of
Lemma 2, in which it is shown that ¯˜α is invariant with
respect to µ and σ of the mobile object. Then, with the
help of Lemma 2, ¯˜α of the mobile object having the
Gauss-Markov parameters µ, σ, and α = α1 can be
evaluated by setting µ = 0 and σ = 1, as concluded
in Theorem 1.
Lemma 1: Let O1 be a mobile object having the
Gauss-Markov parameters µ = µ1, σ = σ1, and
α = α1. For object O1, fVt−1(v) =
1√
2πσ1
e
− (v−µ1)2
2σ21 ,
fXt−1(x) =
1√
2πσ1
e
− x2
2σ21 , and α˜t(v, x) is equal to
the α (0 ≤ α ≤ 1) value which maximizes
1√
2π(1−α2)σ1
e
−
(
α1v+(1−α1)µ1+
√
1−α21x−αv−(1−α)µ1
)2
2(1−α2)σ21 .
Lemma 2: Let O1 and O2 be two mobile objects having
the Gauss-Markov parameters µ = µ1, σ = σ1, and α =
α1 and the Gauss-Markov parameters µ = µ2, σ = σ2,
and α = α2, respectively. If α1 = α2, ¯˜α of object O1 is
equal to ¯˜α of object O2.
Theorem 1: Let O1 be a mobile object having the
Gauss-Markov parameter α = α1. Then, ¯˜α of object O1 is
equal to
∫∞
−∞
∫∞
−∞
1
2π e
− v2+x22 α˜t(v, x)dxdv, where α˜t(v, x)
is equal to the α (0 ≤ α ≤ 1) value which maximizes
1√
2π(1−α2)e
−
(
α1v+
√
1−α21x−αv
)2
2(1−α2) .
4.2 Convergence Rates of Estimation of µ, σ, and α
Theorem 2 shows that the convergence rates of µˆt and
σˆt are 1/
√
n, where n denotes the number of samples,
using a similar argument described in [32]. In addition,
because αˆt is evaluated by ¯˜αt by Eq. 16, we demonstrate
that the convergence rate of ¯˜αt is 1/
√
n in Theorem
3. Let Wi denote a random variable, α˜t(Vt−1, Xt−1). To
prove Theorem 3, it is sufficient to show 1n
∑n
i=1Wi ∼
N( ¯˜α, ( σ√
n
)2) as n → ∞. Let X1, X2, · · · , Xn denote a
sequence of specific random variables, and let Fn(x)
and Φ(x) be the cumulative distribution functions of
random variable Z = Tn−nµ
σ
√
n
and N(0, 1), respectively,
where Tn =
∑n
i=1Xi, and µ and σ
2 denote the mean
and variance of X1, respectively. Lemma 3, as proved in
[32], describes that the least upper bound of the absolute
difference of Fn(x) and Φ(x) for x ∈ R is bounded by
O(1/
√
n), implying that the distribution of Tn =
∑n
i=1Xi
approximates to N(nµ, (σ
√
n)2) on the order of 1/
√
n.
Because W1,W2, · · · ,Wn are a sequence of specific ran-
dom variables described in Lemma 3 and E[W1] = ¯˜α,∑n
i=1Wi approximates to N(n ¯˜α, (σ
√
n)2) on the order
of 1/
√
n. This implies that 1n
∑n
i=1Wi ∼ N( ¯˜α, ( σ√n )2) as
n→∞, and hence Theorem 3 follows.
Theorem 2: The convergence rates of µˆt and σˆt are
1/
√
n, where n denotes the number of samples.
Lemma 3: Let {Xn} be a sequence of independent
and identically-distributed (i.i.d.) random variables with
E[X1] = µ, variance of X1 equal to σ2 and suppose that
E[|X1 − µ|2+δ] = ν2+δ < ∞ for some 0 < δ ≤ 1. Also
let Tn =
∑n
i=1Xi, Fn(x) = Pr{Tn−nµσ√n ≤ x}, x ∈ R. Then
there exists a constant C such that
∆n = sup
x∈R
|Fn(x)− Φ(x)| ≤ C ν2+δn
−δ/2
σ2+δ
, (18)
where supx∈R g(x) denotes the least upper bound or
supremum of g(x) for x ∈ R and Φ(x) is the cumulative
distribution function of N(0, 1).
Theorem 3: The convergence rate of ¯˜αt is 1/
√
n, where
n denotes the number of samples.
4.3 Accuracy of Estimation of µ, σ, and α
Theorem 4 shows that µˆt = µ and σˆt = σ as t → ∞,
and Theorem 5 demonstrates the asymptotic confidence
interval for α. As n → ∞, because 1n
∑n
i=1Wi ∼
N( ¯˜α, ( σ√
n
)2), ¯˜αt = ¯˜α, where Wi denotes a random vari-
able, α˜t(Vt−1, Xt−1). In addition, αˆt = G( ¯˜αt). Therefore,
as t → ∞, the difference between α and αˆt can be
obtained by evaluating the difference between the real
curve and the regression curve in Fig. 2. Lemma 4, as
proved in [31], provides a statistical analysis of the data
of these two curves, and helps us to complete the proof
of Theorem 5.
Theorem 4: limt→∞ µˆt = µ and limt→∞ σˆt = σ.
Lemma 4: Assume that yi = f(xi;θ) + ϵi and yˆi =
f(xi; θˆ) for given n samples (x1, y1), (x2, y2), · · · ,
(xn, yn), where θ = (θ1, θ2, . . . , θp)T is the true value of
the parameter vector, ϵi are independent and identically-
distributed (i.i.d.) N(0, σ2), and θˆ = (θˆ1, θˆ2, . . . , θˆp)T . The
approximate 95% confidence interval for y at x = x0 is
7t
R
M
S
E
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
ˋˈ
ˌ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(a)
t
R
M
S
E
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
ˋˈ
ˌ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(b)
t
R
M
S
E
ˆ˃
ˆˈ
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(c)
t
R
M
S
E
ˆ˃
ˆˈ
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(d)
˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲ˠ˟˛ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃˃ʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃ʼ
Fig. 5: Measurement of RMSE for the GMPE MLH model, the GMPE ACR model, and the GMPE RLSE model in
the Gauss-Markov mobility model. Parameters used in Group A: (a); Group B: (b); Group C: (c); and Group D: (d).
and |α − αˆt|. Additionally, it was observed that the
smaller the value of e, the smaller the average value of
|µ− µˆt|. If an object has the smaller expected value of σ
(as the value of e is smaller), the expected absolute dif-
ference between vt and µ is smaller, making the absolute
difference between µ and µˆt smaller. It was also observed
that the smaller the value of f , the smaller the average
value of |µ − µˆt|. If an object has the smaller expected
value of α (as the value of f is smaller), according to
Eq. 1 the expected absolute difference between vt and
µ is smaller. Moreover, as can be seen in Figs. 3a and
3b, for 8 groups of parameters the larger the average
value of |µ− µˆt|, the larger the average value of |σ− σˆt|
because as t → ∞, |σˆt − σ| =
√
σ2 + |µˆt − µ|2 − σ or√
σ2 + |µˆt − µ|2 + σ (because σ2 = 1t
∑t
i=1 (vi − µ)2 and
µ = 1t
∑t
i=1 vi as t → ∞). Nevertheless, it is believed
that the smaller the expected value of α, the smaller
the expected value of ¯˜α. Because the slope of the curve
in Fig. 2 is less for smaller values of ¯˜α, the absolute
difference between the actual and estimated values of
α is larger as ¯˜αt is smaller. Therefore, the smaller is the
expected value of α (the smaller value of f ), the larger
is the average value of |α− αˆt|, as illustrated in Fig. 3c.
5.2 Convergence Rates of Estimated Parameters
Let∆|µ−µˆt|,∆|σ−σˆt|, and∆|α−αˆt| denote ||µ−µˆt|−|µ−
µˆt+100||, ||σ−σˆt|−|σ−σˆt+100||, and ||α−αˆt|−|α−αˆt+100||,
respectively, if t < 1000; otherwise, let∆|µ−µˆt|,∆|σ−σˆt|,
and ∆|α − αˆt| be equal to 0. In addition, let conv tµ,
conv tσ, and conv tα denote the smallest time slots t
such that for all time slots t′ ≥ t, ∆|µ − µˆt′ | ≤ ϵµ,
∆|σ − σˆt′ | ≤ ϵσ, and ∆|α− αˆt′ | ≤ ϵα, respectively, where
t and t′ are multiples of 100, and ϵµ, ϵσ , and ϵα are the
given constants. Smaller values of conv tµ, conv tσ , and
conv tα indicate greater convergence rates of estimated
values of µ, σ, and α, respectively. In the simulation,
the convergence rates of estimated values of µ, σ, and
α were not investigated in the Gauss-Markov mobility
model having parameters of Groups B, C, D, E, F, G, and
H, because the differences in the convergence rates of
estimated values of µ, σ, and α among 8 groups are not
significant, as can be seen in Fig. 3. In addition, for the
GMPE RLSE model, in the second dimension, µ, σ, and
α are randomly chosen, respectively, from the intervals
[0, 2π], [0, 2π], and [0, 1]. Moreover, the convergence
rates of estimated values of µ and σ were not studied
for the GMPE RLSE model because the method of esti-
mating µ used for the GMPE RLSE model is the same
as that for the GMPE ACR model and because the value
of σ is not estimated in the GMPE RLSE model. In Fig.
4, west = 10, 100, and ∞ means 10, 100, and all samples
of history information concerning object trajectory are
used to estimate the parameters, respectively. It can
be seen that the GMPE ACR model had the smallest
convergence rates of estimated values of µ, σ, and α
as west = 10. The observation is reasonable because the
average values of |µ − µˆt|, |σ − σˆt|, and |α − αˆt| each
fluctuate as the value of t increases due to the fact that a
small amount of information concerning object trajectory
is used to estimate the values of µ, σ, and α. By contrast,
in the GMPE ACR model with west = 100, the average
values of |µ − µˆt|, |σ − σˆt|, and |α − αˆt| each fluctuate
slightly as the value of t increases because a constant and
large amount of information concerning object trajectory
is used to estimate the values of µ, σ, and α as t ≥ 100. In
the GMPE ACR model with west =∞ (which means that
all the history information concerning object trajectory
is used to estimate the parameters), or the GMPE MLH
model, the larger the value of t, the smaller the average
values observed for |µ−µˆt|, |σ−σˆt|, and |α−αˆt| were be-
cause all information concerning object trajectory is used
to estimate the values of µ, σ, and α, resulting in smaller
convergence rates of estimated values of µ, σ, and α
compared to the GMPE ACR model with west = 100.
Nevertheless, compared to the GMPE RLSE model, the
GMPE ACR model had a greater convergence rate of
estimated value of α in most cases.
5.3 Measurement of RMSE in the Gauss-Markov Mo-
bility Model
Let xi and xˆi denote the actual and estimated values
of the i-th x coordinate of the object, respectively, and
yi and yˆi denote the actual and estimated values of the
i-th y coordinate of the object, respectively. Also, let x¯
9t
R
M
S
E
ˈ˃
ˈˈ
ˉ˃
ˉˈ
ˊ˃
ˊˈ
ˋ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(a)
t
R
M
S
E
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
ˊ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(b)
t
R
M
S
E
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
ˉˈ
ˊ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(c)
t
R
M
S
E
˅˃
˅ˈ
ˆ˃
ˆˈ
ˇ˃
ˇˈ
ˈ˃
ˈˈ
ˉ˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(d)
t
R
M
S
E
˃
˄
˅
ˆ
ˇ
ˈ
ˉ
ˊ
ˋ
ˌ
˄˃
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(e)
t
R
M
S
E
˃
˄
˅
ˆ
˄˃˃ ˅˃˃ ˆ˃˃ ˇ˃˃ ˈ˃˃ ˉ˃˃ ˊ˃˃ ˋ˃˃ ˌ˃˃ ˄˃˃˃
(f)
˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲ˠ˟˛ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃˃ʼ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃ʼ
Fig. 7: Measurements of RMSE for the GMPE MLH model, the GMPE ACR model, and the GMPE RLSE model
in (a) the random walk mobility model, (b) the Markovian random path mobility model, (c) the simple individual
mobility model, (d) the random waypoint mobility model, (e) the ETSI vehicular mobility model, and (f) the smooth
random mobility model.
performance of RMSE in the ETSI vehicular mobility
model and the smooth random mobility model. This
observation results from the fact that a mobile object
has little opportunity to make a sharp turn in these
two mobility models. By contrast, each prediction model
provides a poor performance of RMSE in the random
walk mobility model due to the fact that a mobile object
has a great opportunity to make a sharp turn.
5.5 Measurement of RMSE in the Dynamic Gauss-
Markov Mobility Model
In the simulation, each mobile object changed the Gauss-
Markov parameters, which were randomly chosen from
the parameter ranges of the mobility models at k,
1 ≤ k ≤ 10, time slots, which were randomly cho-
sen from 5000 time slots. The GMPE MLH Dynamic
model, which is equivalent to the GMPE MLH model
except for the functionality of indicating changes in
the Gauss-Markov parameters, was compared with the
GMPE ACR model and the GMPE RLSE model. The
GMPE MLH Dynamic model indicates a change in α
based on the fact that the distribution of the random
variable of ¯˜αt approximates to a normal distribution with
a mean equal to ¯˜α, as demonstrated in Theorem 3. In
time slot 5i+5, i is an integer in the interval [0, 999], the
mean of 5 α˜t in time slots 5i+1 through 5i+5 is obtained
to be one sample datum of ¯˜αt. In time slot 25j + 25,
j is an integer in the interval [0, 199], the means and
variances of the history samples and the recent samples
are evaluated; the history samples comprise all sample
data of ¯˜αt from the beginning of the prediction model, or
the last time slot in which the prediction model is reset,
and the recent samples comprise the last 5 sample data
of ¯˜αt. Then, if an F -test [9] with a level of significance
of 5% indicates equality (or, inequality) of the variances
of the history samples and the recent samples, a t-test
[9] (or, Welch’s t-test [30]) with a level of significance
of 5% is used. If the t-test or Welch’s t-test indicates
inequality of the means of the history samples and
the recent samples, the GMPE MLH Dynamic model
indicates a change in α and resets the prediction model.
The GMPE MLH Dynamic model requires 4 messages
to indicate a change in α. 1 message is required to
obtain one sample datum of ¯˜αt in time slot 5i + 5, and
3 messages are required to obtain the variance of the
history samples and the mean and variance of the recent
samples in time slot 25j + 25. Note that the mean of
the history samples is obtained without an additional
message because it is equal to ¯˜αt.
The GMPE MLH Dynamic model indicates changes
in µ and σ based on the fact that the distribution
of random variable Vt is a normal distribution in a
manner analogous to that for indicating a change in
α. The history samples comprise all vt from the be-
ginning of the prediction model, or the last time slot
in which the prediction model is reset, and the recent
samples comprise 25 vt in time slots 25j + 1 through
25j + 25. In time slot 25j + 25, if an F -test (or, t-test)
with a level of significance of 5% indicates inequality
of the variances (or, means) of the history samples and
the recent samples, the GMPE MLH Dynamic model
indicates a change in σ (or, µ) and resets the pre-
diction model. The GMPE MLH Dynamic model re-
11
k
R
M
S
E
ˋ˃
ˋˈ
ˌ˃
ˌˈ
˄˃˃
˄˃ˈ
˄˄˃
˄˄ˈ
˄˅˃
˄˅ˈ
˄ˆ˃
˄ˆˈ
˄ˇ˃
˄ˇˈ
˄ˈ˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(a)
k
R
M
S
E
ˇ˃
ˈ˃
ˉ˃
ˊ˃
ˋ˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(b)
k
R
M
S
E
ˆ˃
ˇ˃
ˈ˃
ˉ˃
ˊ˃
ˋ˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(c)
k
R
M
S
E
ˈ˃
ˉ˃
ˊ˃
ˋ˃
ˌ˃
˄˃˃
˄˄˃
˄˅˃
˄ˆ˃
˄ˇ˃
˄ˈ˃
˄ˉ˃
˄ˊ˃
˄ˋ˃
˄ˌ˃
˅˃˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(d)
k
R
M
S
E
˃
˄
˅
ˆ
ˇ
ˈ
ˉ
ˊ
ˋ
ˌ
˄˃
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(e)
k
R
M
S
E
˃
˄
˅
ˆ
˄ ˅ ˆ ˇ ˈ ˉ ˊ ˋ ˌ ˄˃
(f)
˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˔˖˥ʳʻ˪˸̆̇ ːЌʼ˚ˠˣ˘˲ˠ˟˛˲˗̌́˴̀˼˶ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃ʼ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ː˄˃˃ʼ ˚ˠˣ˘˲˥˟˦˘ʳʻ˪˸̆̇ ːЌʼ
Fig. 9: Measurements of RMSE for the GMPE MLH Dynamic model, the GMPE ACR model, and the GMPE RLSE
model in (a) the dynamic random walk mobility model, (b) the dynamic Markovian random path mobility model, (c)
the dynamic simple individual mobility model, (d) the dynamic random waypoint mobility model, (e) the dynamic
ETSI vehicular mobility model, and (f) the dynamic smooth random mobility model.
prediction than either the GMPE ACR model or the
GMPE RLSE model in the dynamic ETSI vehicular mo-
bility model and the dynamic smooth random mobility
model. This stems from the observation that the history
information concerning object trajectory is useful for
location prediction, because a mobile object has little
opportunity to make a big change in either the velocity
or the direction in these two dynamic mobility models.
5.7 Comparison of Prediction Models
As shown in TABLE 2, neither the GMPE ACR model
nor the GMPE RLSE model provides analytical bounds
for the estimation of the Gauss-Markov Parameters.
In addition, the time complexities of the GMPE MLH
model, the GMPE ACR model, and the GMPE RLSE
model are O(1), O(west), and O(west), respectively. The
message overhead is ranked by the number of mes-
sages required to be transmitted. In a 2-dimensional
space, the GMPE MLH model requires 9 messages to
be transmitted. Either the GMPE ACR model or the
GMPE RLSE model has comparable prediction for ob-
ject trajectory with the GMPE MLH model only when
west is at least 100, which requires at least 200 mes-
sages to be transmitted. The location prediction is
ranked by the simulation results for the measurement
of RMSE in the Gauss-Markov mobility model. Because
the GMPE MLH model has low time complexity, low
message overhead, and good location prediction, the
GMPE MLH model is suitable for location prediction
in wireless sensor networks (WSN), wireless personal
communication service (PCS) networks, and mobile ad
hoc networks (MANET).
6 CONCLUSIONS
In this paper, we have proposed a method to predict
object trajectory. Since the Gauss-Markov mobility model
is one of the best mobility models to describe object
trajectory, we developed a Gauss-Markov parameter
estimator, GMPE MLH, using a maximum likelihood
technique. The GMPE MLH model requires the trans-
mission of only 9 messages between the primary sen-
sors in a 2-dimensional space and generates negligible
differences between the actual and estimated values of
the Gauss-Markov parameters, therefore we believe that
it is a novel method for a wireless sensor network to
predict object trajectory. In addition, the method can
be easily extended to 3-dimensional space in which 13
messages are transmitted between the primary sensors.
Also, the GMPE MLH model can be used to predict
object trajectory in wireless personal communication
service networks and mobile ad hoc networks as well.
Furthermore, an extention of the GMPE MLH model,
termed GMPE MLH Dynamic, is proposed to predict
object trajectory in the dynamic Gauss-Markov mobility
model in which the object may change Gauss-Markov
parameters along with time.
Using simulations, we compared the performance of
the GMPE MLH model with the Gauss-Markov pa-
rameter estimators using an autocorrelation technique
(GMPE ACR) and a recursive least square estimation
technique (GMPE RLSE). Either the GMPE ACR model
or the GMPE RLSE model requires a large amount of
13
1
P
1 1
P V A
1 1
P V A1v'
1
1 1
1
( ) ( ) ( , )
t tV X t
f v f x v x dx
V
V D ³ AA 
v
1,1
v
1,m
v
(a)
01VA 1VA1x'
x
1 1
( ) ( ) ( , )
t tV X t
f v f x v xD  
1,1
x
1,n
x
(b)
2
P
2 2
P V A
2 2
P V A2v'
2
1 1
2
( ) ( ) ( , )
t tV X t
f v f x v x dx
V
V D ³ AA 
v
2,1
v
2,m
v
(c)
02VA 2VA2x'
x
1 1
( ) ( ) ( , )
t tV X t
f v f x v xD  
2,1
x
2,n
x
(d)
Fig. 10: Subdivision of intervals. In (a), (b), (c), and (d),
the intervals [µ1 − ℓσ1 − ∆v12 , µ1 + ℓσ1 + ∆v12 ], [−ℓσ1 −
∆x1
2 , ℓσ1 +
∆x1
2 ], [µ2 − ℓσ2 − ∆v22 , µ2 + ℓσ2 + ∆v22 ], and
[−ℓσ2− ∆x22 , ℓσ2+ ∆x22 ] are subdivided into subintervals
of lengths ∆v1, ∆x1, ∆v2, and ∆x2, respectively.
equal to the α value which maximizes
1√
2π(1−α2)σ1
e
−
(
α1v+(1−α1)µ1+
√
1−α21x−αv−(1−α)µ1
)2
2(1−α2)σ21 .
Because ¯˜α is invariant with respect to the
values of the Gauss-Markov parameters µ and
σ of the mobile object according to Lemma
2, ¯˜α =
∫∞
−∞
∫∞
−∞
1
2π e
− v2+x22 α˜t(v, x)dxdv, where
α˜t(v, x) is equal to the α value which maximizes
1√
2π(1−α2)e
−
(
α1v+
√
1−α21x−αv
)2
2(1−α2) , by setting µ1 = 0 and
σ1 = 1, as desired.
Proof of Theorem 2: Let Vi, i ≥ 1, denote the random
variable of vi, V¯n = 1n
∑n
i=1 Vi, and S
2
n =
1
n
∑n
i=1(Vi −
V¯n)
2. The convergence rate of µˆt is 1/
√
n because V¯n ∼
N(µ, ( σ√
n
)2) as n→∞, as proved in [32]. In addition, it
is shown in [32] that
√
n(
√
n√
n−1Sn−σ)
(2σ)−1γ ∼ N(0, 1) as n→∞,
where γ2 = µ4− σ4 and µ4 = E[(V1−µ)4]. Furthermore,
as n→∞,
√
n√
n−1 → 1, implying
√
n(Sn−σ)
(2σ)−1γ ∼ N(0, 1), and
thus Sn ∼ N(σ, ( γ2σ√n )2). Therefore, the convergence rate
of σˆt is 1/
√
n.
Proof of Theorem 3: Let O1 be a mobile object having
the Gauss-Markov parameter α = α1. Because ¯˜α of
O1 is equal to E[α˜t(Vt−1, Xt−1)] with random variables
Vt−1 ∼ N(µ1, σ21) and Xt−1 ∼ N(0, σ21), it suffices to
show 1n
∑n
i=1Wi ∼ N( ¯˜α, ( σ√n )2) as n → ∞, where Wi
denotes a random variable, α˜t(Vt−1, Xt−1). First note
that Wi and Wj , 1 ≤ i ̸= j ≤ n, are identically
distributed because Pr{Wi ≤ x} = Pr{Wj ≤ x} for all x.
BecauseWi andWj are mutually independent, {Wn} is a
sequence of i.i.d. random variables. In addition, E[|W1−
E[W1]|3] =
∫∞
−∞
∫∞
−∞
1√
2πσ1
e
− (v−µ1)2
2σ21 · 1√
2πσ1
e
− x2
2σ21 ·
|α˜t(v, x) − E[W1]|3dxdv ≤
∫∞
−∞
∫∞
−∞
1√
2πσ1
e
− (v−µ1)2
2σ21 ·
1√
2πσ1
e
− x2
2σ21 · 13dxdv = 1 < ∞ because 0 ≤ α˜t(v, x) ≤ 1
and 0 ≤ E[W1] ≤ 1. According to Lemma 3, there
exists a constant C such that ∆n = supx∈R |Fn(x) −
Φ(x)| ≤ C ν3n−1/2σ3 , where Fn(x) = Pr{
∑n
i=1Wi−nµ
σ
√
n
≤ x},
Φ(x) is the cumulative distribution function of N(0, 1),
ν3 = E[|W1 − µ|3], µ = E[W1] = ¯˜α, and σ is the variance
of W1. Because C, ν3, and σ are constants, Fn(x)→ Φ(x)
on the order of 1/
√
n. As n→∞, we have
∑n
i=1Wi−n ¯˜α
σ
√
n
∼
N(0, 1). Therefore,
∑n
i=1Wi ∼ N(n ¯˜α, (σ
√
n)2) as n→∞.
We then have 1n
∑n
i=1Wi ∼ N( ¯˜α, ( σ√n )2) as n→∞.
Proof of Theorem 4: µ and σ denote the mean and
the standard deviation of velocity as t → ∞, respec-
tively. Therefore, it suffices to show that µˆt = 1t
∑t
i=1 vi
and σˆ2t =
1
t
∑t
i=1 (vi − µˆt)2. It is easy to verify that
µˆt =
1
t
∑t
i=1 vi. According to Eq. 11, σˆ
2
1 = 0 and
σˆ22 =
(v1−µˆ2)2+(v2−µˆ2)2
2 ; therefore, σˆ
2
t =
1
t
∑t
i=1 (vi − µˆt)2
holds for both t = 1 and t = 2. We prove σˆ2t =
1
t
∑t
i=1 (vi − µˆt)2 holds for t ≥ 3 by induction on t. As
an induction assumption, we take σˆ2t =
1
t
∑t
i=1 (vi − µˆt)2
holds for all t ≤ k − 1. According to Eq. 11, σˆ2k =
k−1
k σˆ
2
k−1 +
1
k−1 (vk − µˆk)2. Then, by induction hypoth-
esis, σˆ2k−1 =
1
k−1
∑k−1
i=1 (vi − µˆk−1)2; therefore, σˆ2k =
1
k
(∑k−1
i=1 v
2
i−2µˆk−1
∑k−1
i=1 vi+(k−1)µˆ2k−1
)
+ 1k−1 (vk−µˆk)2.
So, σˆ2k =
1
k
∑k−1
i=1 v
2
i − k−1k µˆ2k−1 + 1k−1 (vk − µˆk)2 be-
cause µˆk−1 = 1k−1
∑k−1
i=1 vi. Because µˆk−1 =
kµˆk−vk
k−1 ,
σˆ2k =
1
k
(∑k−1
i=1 v
2
i − 1k−1 (kµˆk − vk)2 + kk−1 (vk − µˆk)2
)
.
Therefore, σˆ2k =
1
k
(∑k
i=1 v
2
i − kµˆ2k
)
= 1k
∑k
i=1 (vi − µˆk)2
because µˆk = 1k
∑k
i=1 vi. Using a similar argument, it can
be shown that σˆ2t =
1
t
∑t
i=1 (vi − µˆt)2 holds for t = 3;
therefore a basis for the proof exists. This implies that
σˆ2t =
1
t
∑t
i=1 (vi − µˆt)2 holds for t ≥ 3.
Proof of Theorem 5: We first show the approximate
95% confidence interval for α is within 0.00812 of G( ¯˜α).
According to Eq. 15, we need to show the approximate
95% confidence interval for α is within 0.00812 of G( ¯˜α)
if C1) 0.35338 < ¯˜α ≤ 0.44602 and C2) 0.44602 < ¯˜α ≤ 1.
The proof of C1 is omitted due to its similarity with
the proof of C2. For C2, θˆ = (0.37492,−0.55069).
According to Lemma 4, the approximate 95%
confidence interval for α is given by G( ¯˜α) ± 1.645 ×
0.00493
√
2.58456× ( ln((x− 0.2)/x) + 0.40848)2 + 1.0001.
It is easy to verify that 1.645 ×
0.00493
√
2.58456× ( ln((x− 0.2)/x) + 0.40848)2 + 1.0001
is concave up on [0.44602, 1], and has maximum value
0.00812, implying that the approximate 95% confidence
interval for α is given by G( ¯˜α) ± 0.00812. In addition,
since limt→∞ ¯˜αt = ¯˜α (because 1n
∑n
i=1Wi ∼ N( ¯˜α, ( σ√n )2)
as n → ∞, where Wi denotes a random variable,
α˜t(Vt−1, Xt−1), as demonstrated in Theorem 3) and
αˆt = G( ¯˜αt), the approximate 95% confidence interval
for α is within 0.00812 of αˆt as t→∞.
15
[44] Z.R. Zaidi and B.L. Mark, “Real-time mobility tracking algorithms
for cellular networks based on Kalman filtering,” IEEE Trans. on
Mobile Computing, vol. 4, no. 2, pp. 195–208, 2005.
[45] W. Zhang and G. Cao, “Optimizing tree reconfiguration for
mobile target tracking in sensor networks,” IEEE INFOCOM, pp.
2434–2445, 2004.
Bing-Hong Liu received the BSc and Phd de-
grees in computer science from National Tsing
Hua University in 2001 and 2008, respectively.
In 2009, he joined the Department of Electronic
Engineering at National Kaohsiung University of
Applied Sciences, where he is currently an as-
sistant professor. His research interests include
mobile computing, distributed computing, mobile
ad hoc networks, and wireless sensor networks.
He is a member of the IEEE.
Min-Lun Chen received the MSc degree in com-
puter science from National Tsing Hua Univer-
sity in 2006. He is currently a senior software
engineer at Compal Communications, Inc. His
research interests include mobile computing and
distributed computing.
Ming-Jer Tsai received the PhD degree in
electrical engineering from the National Taiwan
University in 1997. Since then, he has been
with the Computer and Communication Labo-
ratory, Industrial Technology Research Institute.
He joined Department of Computer Science and
Institute of Communications Engineering at Na-
tional Tsing Hua University in 2003 and 2009,
respectively, where he is currently an associate
professor. His research interests include dis-
tributed systems and mobile computing. He is a
member of the IEEE.
1GPS-Free, Boundary-Recognition-Free, and
Reliable Double-Ruling-Based Information
Brokerage Scheme in Wireless Sensor Networks
Chia-Hung Lin, Jian-Jhih Kuo, Bing-Hong Liu, and Ming-Jer Tsai
Department of Computer Science
National Tsing Hua University
Hsinchu, Taiwan, ROC
E-mail: mjtsai@cs.nthu.edu.tw
Abstract—We study the information brokerage schemes in wireless sensor networks, which allow consumers to obtain data from
producers by replicating and retrieving data in a certain set of sensors, and propose a novel information brokerage scheme, termed
RDRIB. Unlike existing information brokerage schemes, RDRIB guarantees successful data retrieval without using any boundary
detection algorithm and the geographic location information acquired by the global positioning system (GPS). In RDRIB, the double-
ruling technique is used to replicate and retrieve the data within a constructed virtual boundary, and simulations show that RDRIB has
good performance in terms of the replication memory overhead, the replication message overhead, the retrieval message overhead,
the retrieval latency, and the construction message overhead.
Index Terms—Information brokerage scheme, GPS-free, boundary-recognition-free, wireless sensor network.
F
1 INTRODUCTION
AWireless sensor network consists of several sensors,each of which has the ability to collect, process, and
store environmental information as well as to communi-
cate with others via inter-sensor communication. These
characteristics allow wireless sensor networks to be used
in a wide range of applications, including environmental
monitoring, battlefield surveillance, health care, and so
on. In these applications, the data sensed by sensors
are processed and interpreted within the network such
that information exchange between sensors is necessary.
In addition, many routing protocols, which forward
data from a source node to a destination node, are
proposed for wireless sensor networks [1], [2], [3], [4],
[5], [6]; each of them requires a reliable information
exchange scheme that can provide the source node with
the location information of the destination node. In this
paper, we undertake the development of the methods of
information exchange in wireless sensor networks.
Consider the data that is collected or generated by a
node (a producer) and that, later, a node (a consumer) is
interested in. To exchange the data between the producer
and the consumer, since the consumer does not know
which node has the data-of-interest, one trivial scheme
is to flood a query throughout the network and retrieve
the data-of-interest by receiving the response generated
from the producer. By contrast, another trivial scheme is
to replicate the data of the producer to all nodes in the
network such that each consumer can retrieve the data-
of-interest immediately. However, each trivial scheme
demands a great deal of message or memory overhead
to replicate or retrieve the data.
For efficient information exchange, many information
brokerage schemes, such as GLS [7], GHT [8], FMMS [9],
XYLS [10], iMesh [11], Double Rulings [12], 3DLS [13],
HD [14], LBIB [15], and Hop/SHU [16], are proposed.
However, these schemes each have at least one of the
following problems:
(1) GPS is needed. In GLS, GHT, FMMS, XYLS, iMesh,
and Double Rulings, each sensor node is required to
possess the geographic location information, which is
obtained with difficulty in wireless sensor networks
because the global positioning system (GPS) consumes
a large amount of power and does not work indoors.
(2) Distance-sensitivity is not provided. GLS, GHT, and
3DLS are not distance-sensitive because the path of the
data retrieval for a consumer may not be proportional
to the distance between the producer and the consumer.
By contrast, FMMS, XYLS, iMesh, Double Rulings, and
Hop/SHU use the double-ruling technique to approach
this problem.
(3) Successful data retrieval is not guaranteed. In FMMS,
XYLS, 3DLS, LBIB, and Hop/SHU, it is not guaranteed
that a consumer can always retrieve the data-of-interest.
(4) Global topology information is required. In HD and
LBIB, each node is required to obtain rather complex
global topology information, which incurs a great deal
of message and memory overhead.
(5) Network boundary detection is necessitated. In
3cp
XY
Z
Z'
(a)
XY
Z
Z'
c
p
(b)
Fig. 1. Intuition of DRIB, where the virtual boundary con-
sists of the first, second, third, and fourth axes denoted
by the line segments from Z to X, from X to Z ′, from
Z ′ to Y , and from Y to Z, respectively. Blue and green
arrows denote the paths of the data retrieval for consumer
c and of the data replication for producer p, respectively.
Consumer c and producer p lie in the interior and exterior
of the virtual boundary in (a) and (b), respectively.
DRIB, from axes Z ↔ X , X ↔ Z ′, Z ′ ↔ Y , and Y ↔
Z, respectively. Two challenges need to be addressed.
First, the nodes in the interior or exterior of the virtual
boundary need to be identified. Because for any two
intersecting edges a and b, at least one end node of a
is a neighbor of at least one end node of b, DRIB sepa-
rates the nodes in the interior of the virtual boundary,
called inner nodes, from the nodes in the exterior of
the virtual boundary, called outer nodes, by the nodes
on axes, called boundary nodes, and the neighbors of
the nodes on axes, called near-boundary nodes. Second,
the data in the interior of the virtual boundary must
be prevented from being forwarded to a node in the
exterior of the virtual boundary. In order to achieve
this goal, DRIB avoids that an inner/boundary/near-
boundary node, u, has a neighboring outer node, v, with
v.ZX = u.ZX−1, v.XZ ′ = u.XZ ′−1, v.Z ′Y = u.Z ′Y −1,
or v.Y Z = u.Y Z − 1. In DRIB, u.ZX , u.XZ ′, u.Z ′Y , and
u.Y Z are evaluated by the lengths of the outer-succeed-
outer paths (as defined in Definition 1), rather than the
lengths of the shortest paths, from axes Z ↔ X , X ↔ Z ′,
Z ′ ↔ Y , and Y ↔ Z, respectively. In this section, a
guide to replicate and retrieve the data is established in
Section 3.1. DRIB is proposed in Section 3.2. An example
of the data replication and retrieval using DRIB is given
in Section 3.3.
Definition 1. On a path (u1, u2, · · · , un), ui+1 (or ui) is
called the succeeding (or preceding) node of ui (or ui+1)
for 1 ≤ i ≤ n− 1. A path is an outer-succeed-outer path
if the succeeding node of an outer node is an outer node.
3.1 The Guide
The establishment of the replication and retrieval guide
is to identify the nodes in the interior or exterior of
the virtual boundary, and evaluate the lengths of the
outer-succeed-outer paths from each of the four axes
to each node. In the first phase, a virtual boundary is
constructed, as described in subsection A.1. In the second
phase, nodes are classified into four types: inner, outer,
X
Y
Z
Z'
Fig. 2. A snapshot of the construction of the virtual
boundary and the classification of nodes. Red line seg-
ments denote the virtual boundary. X, Y , Z, and Z ′
denote anchors X, Y , Z, and Z ′, respectively. Red,
green, black, and blue solid circles denote boundary,
near-boundary, inner, and outer nodes, respectively.
boundary, and near-boundary, as described in subsection
A.2. Finally, each node evaluates the lengths of the outer-
succeed-outer paths from each of the four axes in the
third phase, as described in subsection A.3. A snapshot
of the construction of the virtual boundary and the
classification of nodes are illustrated in Fig. 2.
A.1 Construction of the Virtual Boundary
The virtual boundary consists of four anchors X , Y ,
Z, and Z ′, and four axes Z ↔ X , X ↔ Z ′, Z ′ ↔ Y , and
Y ↔ Z, which are the shortest paths from Z to X , from
X to Z ′, from Z ′ to Y , and from Y to Z, respectively;
X (or Y ) is the node with the maximum hop distance
from W (or X), or, in the case of a tie, the node having
the maximum ID, and Z (or Z ′) is the node with the
maximum hop distance from W (or Z), or, in the case of
a tie, the node having the maximum ID, among all nodes
whose hop distances from X and Y differ by 1, whereW
denotes the preprogrammed node. Anchors are elected
and axes are constructed in the same manner as those
for anchors and axes in ABVCap Uni [21] and ABVCap
[22], described as follows.
Each node, u, first evaluates the hop distance from W ,
Hop(u,W ), implemented as follows. W generates and
broadcasts a W SET message containing a hop counter
that is initially set to 1 and advanced in increments
by the forwarding nodes. Once a node, u, receives a
W SET message that contains the smallest hop counter
among all W SET messages received, u broadcasts the
W SET message, and sets Hop(u,W ) to the hop counter
contained in the W SET message.
Subsequently, anchor X is elected, and each node, u,
evaluates the hop distance from X , Hop(u,X), imple-
mented as follows. Each node, u, having a greater hop
distance from W , or, in the case of a tie, that has a
greater ID, than each neighbor generates and broadcasts
an X SET message containing u’s ID, Hop(u,W ), and a
hop counter that is initially set to 1 and advanced in
increments by the forwarding nodes. Once a node, u,
receives an X SET message generated by the node, v,
that has the maximum hop distance from W , or, in the
case of a tie, that has the maximum ID, among all X SET
5Algorithm 3
1. For any producer, u:
a) u generates ZX and Z’Y messages containing the
data if u is a non-outer node.
b) u generates an Axis APPROACH message con-
taining the data if u is an outer node.
2. For any non-outer node, u, receiving an
Axis APPROACH message:
a) u generates ZX and Z’Y messages containing the
data.
3. For any outer node, u, generating or receiving an
Axis APPROACH message:
a) u forwards the message to a neighbor
v with min(v.ZX, v.XZ ′, v.Z ′Y, v.Y Z) <
min(u.ZX, u.XZ ′, u.Z ′Y, u.Y Z).
4. For any non-outer node, u, generating or receiving a
ZX (or Z’Y) message:
a) u forwards the ZX (or Z’Y) message to a non-
outer neighbor v with v.ZX = u.ZX−1 (or v.Z ′Y =
u.Z ′Y − 1).
respectively, as implemented in the following. A
producer, u, generates ZX and Z’Y messages containing
the data and forwards the messages to two non-outer
neighbors v and w with v.ZX = u.ZX − 1 and
w.Z ′Y = u.Z ′Y − 1, respectively, if u is a non-outer
node; otherwise, u generates an Axis APPROACH
message containing the data and forwards the message
to a neighbor v with min(v.ZX, v.XZ ′, v.Z ′Y, v.Y Z) <
min(u.ZX, u.XZ ′, u.Z ′Y, u.Y Z), where min(a, b, c, d)
equals the smallest value of a, b, c, and d.
Once a node, u, receives an Axis APPROACH
message, u forwards the message to a neighbor
v with min(v.ZX, v.XZ ′, v.Z ′Y, v.Y Z) <
min(u.ZX, u.XZ ′, u.Z ′Y, u.Y Z) if u is an outer node;
otherwise, u generates ZX and Z’Y messages containing
the data and forwards the messages to two non-
outer neighbors v and w with v.ZX = u.ZX − 1 and
w.Z ′Y = u.Z ′Y −1, respectively. In addition, if a node, u,
receives a ZX (or Z’Y) message, u forwards the message
to a non-outer neighbor v with v.ZX = u.ZX − 1 (or
v.Z ′Y = u.Z ′Y − 1). Algorithm 3 describes how a node
replicates the data using DRIB in a distributed manner.
Data retrieval is implemented in a manner analogous to
that for data replication.
3.3 An DRIB Example
An example of DRIB is presented in Fig. 3, where node
32 is the preprogrammed node W . In the construction
of the guide, nodes 33, 39, 36, and 35 are selected as
anchors X , Y , Z, and Z ′, respectively, and the shortest
paths from node 36 to node 33, from node 33 to node
35, from node 35 to node 39, and from node 39 to node
36 are established as the axes Z ↔ X , X ↔ Z ′, Z ′ ↔ Y ,
and Y ↔ Z, respectively, in the first phase. In the second
phase, node 18 is a boundary node because node 18 lies
ˆ
ˇ
ˆˇ
ˊ
ˌ
˄
˄˄
˄˅
˄ˉ
˄ˇ
˄ˊ
˄ˋ
˄ˌ
˅˅
˅ˆ
˅ˉ
ˆ˅ ˆ˄
˅
˄ˆ
ˉ X
Y
Z'
˄˃
˅ˈ
ˈ
ˆˈ
ˆˌ
˅˃ ˅ˋ
(0,4,5,0)
(1,4,4,0)
(0,3,5,1)
(0,2,4,2)
(0,1,4,3)
(1,1,5,3)
(0,0,4,4)
(1,2,6,2)
(2,4,3,0)
(2,3,3,1)
(1,2,3,2)
(1,3,4,1)
(1,0,3,4)
(3,4,2,0)
(3,3,2,1)
(2,2,2,2)
(2,2,2,3)
(2,1,2,3)
(2,0,2,4)
(3,0,1,4)
(3,2,1,2)
(4,5,1,0)
(4,0,0,4)
(4,1,0,3)
(4,2,0,2)
(5,3,0,2)(5,4,0,1)
(5,5,0,0)
(1,3,6,1) (2,3,7,2)
(1,4,4,1)
(4,3,1,1)
(4,4,1,1)
(3,1,1,3)
(1,1,3,3)
ˆˋˆ˃
(2,5,5,1)(3,6,3,2)(4,6,3,2) ˄ˈˇ˃
: Boundary Node : Near-Boundary Node : Inner Node : Outer Node
(4,5,2,1)
˅˄
˅ˊ
ˆˊ ˋ
˅ˇ
Z
˅ˌ
ˆˆ
ˆˉ
(1,2,3,2)
W
Fig. 3. Example of DRIB. The 1st, 2nd, 3rd, and 4th
entries in the parentheses denote the hop distances,
using DRIB, from axes Z ↔ X, X ↔ Z ′, Z ′ ↔ Y , and
Y ↔ Z, respectively. Pink, purple, and orange arrows
denote the paths of the data replication for node 2, of the
data retrieval for node 4, and of the data retrieval for node
38, respectively.
on an axis, and node 32 is a near-boundary node because
node 32 is a neighbor of the boundary node 18. Node
35 generates an Inner SET message. The message is first
forwarded to node 22 because node 22 has a smaller
hop distance from Z than node 35. Subsequently, the
message is forwarded to node 17. Because node 17 is not
a boundary node nor a near-boundary node, node 17 is
marked as an inner node and broadcasts the Inner SET
message. Node 3 is marked as an inner node after it
receives the Inner SET message from node 17. Nodes
9, 38, and 30 are marked as outer nodes because each
of them is not a boundary node nor a near-boundary
node and does not receive the Inner SET message. In
the third phase, because node 19 lies on axis Z ↔ X ,
19.ZX = 0. Node 19 generates and broadcasts a ZX SET
message containing a hop counter equal to 1. After node
31 receives the ZX SET message from node 19, node 31
sets 31.ZX to the hop counter contained in the message,
increases the hop counter by 1, and broadcasts the
updated message. It is noted that 40.Z ′Y = 5 although
node 40 has a neighbor, node 38, with 38.Z ′Y = 3,
because nodes 38 and 40 are outer and non-outer nodes,
respectively. Consider the ZX and Z’Y messages gener-
ated by node 2 (a producer). The ZX message containing
the data of node 2 is first forwarded to non-outer node
17 because 17.ZX = 2.ZX − 1. Subsequently, the ZX
message is forwarded to node 31, and then forwarded
to node 19. The Z’Y message is forwarded to non-outer
node 12 because 12.Z ′Y = 2.Z ′Y − 1. In addition, node
4 (a consumer) generates the XZ’ and YZ messages
containing the type of the data-of-interest (the data of
node 2). The XZ’ message is forwarded to node 10 along
the path 4, 21, 27, 6, 10; the YZ message is forwarded to
node 15. During the transmission of the XZ’ message
from node 21 to node 27, node 31 receives the XZ’
message, and sends the data of node 2 to node 21. The
7ˆ
ˇ
ˆˇ
ˊ
ˌ
˄
˄˄
˄˅
˄ˉ
˄ˇ
˄ˊ
˄ˋ
˄ˌ
˅˅
˅ˆ
˅ˉ
ˆ˅ ˆ˄
˅
˄ˆ
ˉ X
Y
Z'
˄˃
˅ˈ
ˈ
ˆˈ
ˆˌ
˅˃ ˅ˋ
(0,4,5,0)
(1,5,4,0)
(0,3,5,1)
(0,2,4,2)
(0,1,5,3)
(1,1,5,3)
(0,0,4,4)
(1,4,6,2)
(2,6,3,0)
(2,4,3,1)
(1,3,3,3)
(1,4,4,1)
(1,0,3,5)
(3,7,2,0)
(3,7,4,1)
(2,3,2,2)
(2,2,3,3)
(3,1,3,4)
(2,0,2,5)
(3,0,1,6)
(3,3,1,3)
(4,6,1,0)
(4,0,0,5)
(5,1,0,4)
(4,2,0,3)
(5,3,0,2)(6,4,0,1)
(5,5,0,0)
(1,4,6,1) (2,5,7,2)
(1,4,4,1)
(4,3,1,1)
(4,4,1,1)
(3,1,1,3)
(1,1,3,4)
ˆˋˆ˃
(2,6,5,1)(3,7,3,2)(4,8,3,2) ˄ˈˇ˃
: Boundary Node : Near-Boundary Node : Inner Node : Outer Node
(4,7,2,1)
˅˄
˅ˊ
(1,3,5,3)
ˆˊ ˋ
˅ˇ
Z
˅ˌ
ˆˆ
ˆˉ
W
Fig. 5. Example of RDRIB. The 1st, 2nd, 3rd, and 4th
entries in the parentheses denote the hop distances,
using RDRIB, from axes Z ↔ X, X ↔ Z ′, Z ′ ↔ Y ,
and Y ↔ Z, respectively. Pink, purple, and orange arrows
denote the paths of the data replication for node 2, of the
data retrieval for node 34, and of the data retrieval for node
16, respectively.
the XZ’, Z’Y, and YZ messages due to their similar-
ities. If u is an outer node, u forwards the message
to a neighbor v with min(v.ZX, v.XZ ′, v.Z ′Y, v.Y Z) <
min(u.ZX, u.XZ ′, u.Z ′Y, u.Y Z). If u is an inner node, u
forwards the message to a non-outer neighbor v with
v.ZX = u.ZX − 1. If u is a near-boundary node, u
forwards the message to a neighbor v with v.ZX =
u.ZX − 1 that is neither an outer node nor a near-
boundary node. If u is a boundary node, u forwards the
message to a neighbor v with v.ZX = u.ZX − 1 that is
neither an outer node nor a boundary node on a different
axis. The algorithm for replicating the data using RDRIB
(Algorithm 6) can be obtained by modifying Line 4 of
Algorithm 3, described as follows.
4. For any non-outer node, u, generating or receiving a
ZX (or Z’Y) message:
a) u forwards the ZX (or Z’Y) message to a non-
outer neighbor v with v.ZX = u.ZX− 1 (or v.Z ′Y =
u.Z ′Y − 1), where:
1) v is not a near-boundary node, if u is a near-
boundary node, and
2) v is not a boundary node on a different axis, if u
is a boundary node.
4.3 An RDRIB Example
An example of RDRIB is presented in Fig. 5. For node
34, node 15 is the neighboring boundary node, and
nodes 18 and 36 are the neighboring boundary nodes of
the neighboring boundary node. Because nodes 15, 18,
and 36 lie on the same axis and node 34 has only one
neighboring boundary node, node 34 is a near-boundary
node. By contrast, node 37 is an outer node because it
has two neighboring boundary nodes 14 and 20; node
28 is an outer node because node 33, the neighboring
boundary node, and nodes 10 and 29, the neighboring
boundary nodes of the neighboring boundary node, do
not lie on the same axis. 27.Z ′Y = 5 although node
27 has a neighbor, node 31, with 31.Z ′Y = 3. The
observation results from the fact that node 27 ignores the
Z’Y SET message received from node 31 because nodes
27 and 31 are both near-boundary nodes. Nodes 10 and
29 are neighbors with 10.Z ′Y = 3 and 29.Z ′Y = 5,
respectively. Nodes 10 and 29 are boundary nodes on
different axes; therefore, node 29 ignores the Z’Y SET
message received from node 10. Similarly to DRIB, the
ZX message generated by node 2 (a producer) is for-
warded to node 19 along the path 2, 17, 31, 19, and
the Z’Y message generated by node 2 is forwarded to
node 12. Consider the XZ’ and YZ messages generated
by node 34 (a consumer). The XZ’ message is forwarded
to node 5 along the path 34, 17, 3, 11, 5 and the YZ
message is forwarded to node 15. After node 17 receives
the XZ’ message, it sends the data-of-interest (the data
of node 2) to node 34. In addition, consider the XZ’ and
YZ messages generated by node 16 (a consumer). The YZ
message is first forwarded to node 8 because node 16 is a
near-boundary node and node 8 with 8.Y Z = 16.Y Z−1
is neither an outer node nor a near-boundary node.
Subsequently, node 8 forwards the YZ message to node
36 because node 8 is a boundary node and node 36
with 36.Y Z = 8.Y Z − 1 is neither an outer node nor
a boundary node on a different axis. Similarly, the XZ’
message is forwarded to node 33 along the path 16, 8, 19,
29, 33. After node 19 receives the XZ’ message, it sends
the data-of-interest (the data of node 2) to node 16 by
backtracking the path traversed by the XZ’ message. By
contrast, the XZ’ and YZ messages generated by node
16 may be forwarded along the path 16, 28, 33 and the
path 16, 13, 36, respectively, in DRIB, in which case node
16 cannot retrieve the data of node 2.
5 ANALYSIS AND DISCUSSION OF RDRIB
In Section 5.1, we first show that each node can always
forward the data using the RDRIB guide in Theorem
1. Subsequently, we show that RDRIB guarantees suc-
cessful data retrieval if the virtual boundary is a simple
cycle (a cycle with no repeated nodes or edges aside
from the necessary repetition of the first and last node)
without intersecting edges in Theorem 2. Finally, we
show that RDRIB is distance-sensitive in a continuous
domain with a convex shape if both the consumer and
the producer are non-outer nodes in Theorem 3. In
Section 5.2, successful data retrieval is discussed.
5.1 Analysis of RDRIB
In RDRIB, all sensors are assumed to be static and have
the same transmission range. In the following proofs,
without loss of generality, we assume that anchors Z,
X , Z ′, and Y lie in the counterclockwise direction on
the virtual boundary, and that the first node that is
marked as an inner node lies in the interior of the virtual
boundary. We also assume that the virtual boundary is
9P1, is a non-exterior-replication path, and C4) there exists
a path, consisting of the parts of Prp, passing through
only near-boundary nodes in the interior of the virtual
boundary, inner nodes, and boundary nodes. For C3, all
near-boundary nodes and boundary nodes in P1 does
not lie in the exterior of the virtual boundary. By C2, it
suffices to show all inner nodes on P1 lie in the interior
of the virtual boundary. For any inner node, there is a
path passing through only inner nodes, denoted by P2,
from the first node that is marked as an inner node. We
need to show any edge on P2 does not intersect with
an edge on the virtual boundary. Suppose that there is
an edge (vk−1, vk) on P2 intersects with an edge on the
virtual boundary. By C2, one of vk−1 and vk is a near-
boundary node, which is a contradiction because both
vk−1 and vk are inner nodes. For C4, if Prp does not
pass through any near-boundary node in the exterior of
the virtual boundary, Prp is the desired path. Let ui−1
be a near-boundary node on Prp that lies in the exterior
of the virtual boundary. It suffices to show ui−1 is the
first non-outer node on the path of the data replication
for the producer and ui−2 = ui, in which case the
path, (u0, · · · , ui−3, ui−2 = ui, ui+1, · · · , un), consisting
the part of Prp, (u0, · · · , ui−3, ui−2), and the part of
Prp, (ui, ui+1, · · · , un), is the desired path. Because two
successive near-boundary nodes are not allowed in Prp,
ui is a boundary node or an inner node. This implies that
edge (ui−1, ui)must intersect with an edge on the virtual
boundary because ui−1 and ui lie in the exterior and
interior of the virtual boundary, respectively. By C2, ui
is a boundary node. Similarly, ui−2 is a boundary node.
Because ui−1 can have only one neighboring boundary
node, ui−2 = ui. This implies that ui−1 is the first non-
outer node on the path of the data replication for the
producer.
Theorem 2. If the virtual boundary is a simple cycle without
intersecting edges, then a consumer, c, can always retrieve the
data of a producer, p.
Proof: Let Prp and Prt denote the path of the data
replication for a producer and the path of the data re-
trieval for a consumer, respectively. According to Lemma
3, there exist a non-exterior-replication path, P ′rp, consist-
ing of the parts of Prp and a non-exterior-retrieval path,
P ′rt, consisting of the parts of Prt. According to Lemma
2, P ′rp and P ′rt intersects. We, therefore, conclude that
consumer c can retrieve the data of producer p according
to Lemma 1.
Theorem 3. For a continuous domain with a convex shape,
the path of the data retrieval for a consumer is proportional to
the distance between the producer and the consumer if both the
consumer and the producer lie in the interior of the virtual
boundary that is a simple cycle without intersecting edges.
Specifically, if the convex shape of the continuous domain
is a circle, the path of the data retrieval for a consumer is
not greater than the distance between the producer and the
consumer in the interior of the virtual boundary that is a
c
p
Y Z'
X
Z
(a)
c
p
X
Y
Z
Z'
(b)
Fig. 6. Two unreliable cases utilizing RDRIB.
simple cycle without intersecting edges.
Proof: In a continuous domain, we use the Euclidean
distance between two nodes as the hop distance between
two nodes in RDRIB (as used in [20]). Because the
continuous domain has a convex shape, the shortest path
between two nodes u and v is the line segment between
u and v, denoted by uv. Thus, the virtual boundary con-
structed by RDRIB is a quadrangle ZXZ ′Y . In addition,
because anchors X , Y , Z, and Z ′ established by RDRIB
must lie in the boundary of the continuous domain, the
radians of the interior angles ̸ Z, ̸ X , ̸ Z ′, and ̸ Y in
quadrangle ZXZ ′Y are each not greater than pi.
Let cc1 and cc2 be the shortest path from the consumer,
c, to axes X ↔ Z ′ and Y ↔ Z, respectively, and let pp1
and pp2 be the shortest path from the producer, p, to axes
Z ↔ X and Z ′ ↔ Y , respectively. Because at least one
of cc1 and cc2 intersects with at least one of pp1 and pp2,
we assume, without loss of generality, that cc1 intersects
with pp1 at a node, i. It suffices to show cicp ≤ 1sin(pi−θ) for
C1) ci > cp and C2) ci ≤ cp, where θ denotes the radian
of the maximum interior angle of quadrangle ZXZ ′Y .
For C1, ̸ cip < pi2 . Let cj be the shortest path from c to
the line containing p and i. Clearly, cicp ≤ cicj = 1sin ̸ cip .
Because ̸ cip = pi − ̸ X ≥ pi − θ, cicp ≤ 1sin(pi−θ) . For C2,
ci
cp ≤ 1 ≤ 1sin(pi−θ) .
Consider a continuous domain with a circle shape. The
distance between anchors X and Y equals the diameter
of the circle because in RDRIB, Y is the node with the
maximum distance from X . Also, the distance between
anchors Z and Z ′ equals the diameter of the circle. This
implies that quadrangle ZXZ ′Y is a rectangle, and thus,
θ = pi2 . Therefore,
ci
cp ≤ 1sin(pi−θ) = 1.
5.2 Extension of RDRIB
If the virtual boundary is not a simple cycle without
intersecting edges, Prp and Prt may not intersect, result-
ing in unsuccessful data retrieval, as illustrated in Fig. 6.
To avoid this situation, an extended version of RDRIB,
denoted by RDRIB+, is discussed here. In RDRIB+, if the
first non-outer node, u, on the path of the data retrieval
for a consumer fails to retrieve the data-of-interest of
the consumer using RDRIB, u generates a ZX RETRIEVE
message and a Z’Y RETRIEVE message if u.ZX ≤ u.Z ′Y
and u.ZX > u.Z ′Y , respectively. The ZX RETRIEVE
message and the Z’Y RETRIEVE message are forwarded
11
(a) (b) (c)
(d) (e) (f)
Fig. 7. Performance simulation results on the packet-level simulator in the UDG model.
which is the hop distance between the preprogrammed
node W and anchor X , in the phase of Construction
of the Virtual Boundary. In addition, the waiting time
for marking a node as an outer node (t) in Algorithm
4 is set to (0.0065 + 0.2515) × 2 × Hop(W,X) because
before a node marks itself as an outer node, the node
should first wait for the unmarked Inner SET message
forwarded from anchor Z ′ to the first inner node marked
(which may take up to 0.0065×2×Hop(W,X)), and then
wait for a marked Inner SET message broadcast from the
first marked inner node to itself (which may take up to
0.2515 × 2 × Hop(W,X)). Sections 6.1–6.6 describe the
first simulation results illustrated in Fig. 7, and Sections
6.7–6.9 describe the second simulation results illustrated
in Fig. 8.
6.1 Retrieval Rate
As expected, RDRIB and HD each guarantee successful
data retrieval in all cases. In Hop/SHU, the retrieval rate
is nearly 100% in a network with a high density. As the
network density decreases from 31 to 16, the retrieval
rate decreases because it is more difficult to obtain a
perfect network boundary in a network with a lower
density. In a network with a density equal to 16, a long
path is often identified as the network boundary. Thus,
the paths of the data retrieval and the data replication
intersect with difficulty, resulting in a considerably low
retrieval rate. By contrast, a node or a short path is
identified as the network boundary in a network with
a density equal to 6 or 11, in which case the data are
replicated and retrieved toward a node or a short path,
resulting in a high retrieval rate. LBIB cannot guarantee
successful data retrieval, which is reasonable because a
good set of landmarks is difficult to obtain. The higher
the network density, the lower the retrieval rate because
more boundary nodes are shared by neighboring tiles in
a network with a higher density.
6.2 Replication Memory Overhead
The difference between RDRIB, LBIB, and Hop/SHU is
negligible. In Hop/SHU, the replication memory over-
head in a network with a density equal to 6, 11, or 16 is
astonishingly low, which occurs because two replication
messages toward the first and third pieces of the network
boundary encounter many nodes in common due to the
fact that a node, a short path, or a long path is identified
as the network boundary. In HD, the data are replicated
in the hashed nodes in all neighboring clusters of the
producer at all levels. Because a node has a total of
approximately 110–220 neighboring clusters at all levels
in networks with densities ranging from 6 to 31, HD
has a greater replication memory overhead, compared
with RDRIB, LBIB, and Hop/SHU. In addition, the
higher the network density, the smaller the replication
memory overhead in RDRIB, LBIB, and Hop/SHU. This
is because the progress distance between two nodes is
greater in a network with a higher density. In HD, as the
network density increases, the number of neighboring
clusters of a node dramatically increases, leading to a
greater replication memory overhead in a network with
a higher density.
6.3 Replication Message Overhead
For each scheme, the replication message overhead is
greater than the replication memory overhead. This re-
13
(a) (b) (c)
(d) (e) (f)
Fig. 8. Performance simulation results on the packet-level/network simulator in the UDG/QUDG model.
overhead, the retrieval latency, and the construction mes-
sage overhead all dramatically increase because the av-
erage sizes of the face boundaries constructed by CLDP
increase sharply. Note that GHT has a great replication
message overhead, a great retrieval message overhead,
and a great retrieval latency in the network with density
6, which results from the observation that the message
for data replication/retrieval traverses a face boundary
with a higher probability in a network with a lower
density.
6.9 Simulation Results in NS-2
The retrieval latency is characterized by hops (the left-
side scale) in the packet-level simulation, and by sec-
onds (the right-side scale) in the NS-2 simulation, as
illustrated in Fig. 8(e); the left-side scale for 1 hop
corresponds to the right-side scale for 0.004 seconds,
which is the average time for forwarding a message
per hop equal to the average delay for forwarding a
message (0.0025 seconds) plus the packet transmission
time for 32-byte data in IEEE 802.11 (0.0015 seconds).
Except for the retrieval rate, the simulation results of
RDRIB (or GHT) in NS-2 are analogous to that of RDRIB
(or GHT) in the packet-level simulation. As anticipated,
neither RDRIB nor GHT guarantees successful data re-
trieval due to the packet loss resulting from the packet
collisions. The retrieval rate of RDRIB fluctuates as the
network density increases. By contrast, as the network
density decreases from 31 to 6, the retrieval rate of
GHT decreases noticeably. This result occurs because
in a network with a lower density, GHT has a greater
number of packet collisions due to a longer path of the
message for data replication/retrieval. In a network with
a density equal to 6, compared with GHT in the UDG
model on the packet-level simulator, GHT in NS-2 has
a smaller replication memory/message overhead due to
the loss of the messages for data replication, and con-
versely, has a greater retrieval message overhead because
the message for data retrieval traverses the whole face
boundary surrounding the hashed geographic location
with a greater probability. In addition, with GHT in NS-
2, the retrieval message overhead is greater than the
number of hops corresponding to the retrieval latency,
which occurs because the hops traversed by the message
for data retrieval are not counted in the retrieval latency
if the message traverses the whole face boundary sur-
rounding the hashed geographic location such that the
consumer fails to retrieve the data-of-interest in the NS-2
simulation.
7 CONCLUSION
In this paper, we propose a reliable double-ruling-based
information brokerage scheme, RDRIB, to replicate and
retrieve the data, in which each node is not required
to possess the geographic location information and no
boundary detection algorithms are used. In RDRIB, the
virtual boundary consisting of a cycle of four axes is
constructed. The data are first replicated (or retrieved)
toward the interior of the virtual boundary until a
node in the interior of the virtual boundary is reached;
subsequently, the data are replicated (or retrieved) along
two paths in the interior of the virtual boundary toward
the first and third axes (or the second and fourth axes).
As a result, RDRIB guarantees successful data retrieval,
附錄三
36
目的地有 n躍距數的節點在平面子圖中，封包會傳
向該節點，否則封包會使用右手開掌定理或左手開
掌定理沿著平面的邊界走，直到有一個節點靠近目
的地只有 n躍距數的距離。在類似 GPSR繞送方法
中，有人先用 Gabriel Graph[8] (GG) 或 Relative 
Neighborhood Graph[9](RNG) 得到平面子圖。在
GSR 繞徑的方法中，繞平面子圖 RDG (Restricted 
Delaunay Graph) 使得其繞徑距離(幾何距離或是躍
距數)為來源和目的地之間最短距離的常數倍，然而
此改善的方法所得到的平面子圖只能在 2D 且有
GPS輔助的無線感測網路中使用。由於在水中或是
室內等環境不容易接收到 GPS 的信號，所以需要
GPS輔助的方法是不適合在這些環境下使用的。 
 在本論文中，我們提出一個不需使用 GPS 輔
助的 3D無線感測網路的虛擬座標系統(3ABVCap)，
並提出能藉由此系統來繞送封包的方法。其餘各節
架構如下:在第 2節中我們描述了一個適用於 2D無
線感測網路的虛擬座標系統—ABVCap及其繞徑方
法，在第 3 節中，我們提出一個應用於 3D 無線感
測網路的虛擬座標系統—3ABVCap，並於第 4節中
提出利用此座標系統的繞徑方法，在第 5節中，我
們將 3ABVCap 與其它知名方法做效能比較，並於
第 6節中做最後總結。 
2. 相關研究 
 在 ABVCap 中，假設節點的狀態在網路中是
靜止的，且所有的節點都有相同的傳輸範圍，每一
個節點都有獨一無二的 ID。ABVCap會選出四個定
位點X、Y、Z和Z′，每一個節點會被分配到一組虛
擬座標，其中包含 5 個座標項目。接收到匯聚點 
(sink) W所發出的信息，每個點都知道距離W有幾
個躍距，選出離W最遠的那個節點為定位點X，距
離X最遠的會被選為Y，而在距離X和距離Y之間差距
為 1躍距數的節點中，找出一個距離W最遠的為Z，
離Z最遠的為Z′，如果差距相同，則選編號最大的為
定位點。 
 ABVCap 使用三個歩驟來分配虛擬座標給每
一個節點。首先在X和Y的最短路徑中建立一條赤道
線，並沿線分配座標。第二，在赤道線上的每一個
節點建立到Z和Z′點的最短路經為經線，並沿途分配
座標，往Z′點為負數，往Z點為正數。如此一來，主
軸上的點都會被分配到座標，而不在軸線上的節點，
則選擇離自己最近的一個軸點加入，並成為同一個
群組的節點，這樣就可以將每個節點都分配到至少
一組虛擬座標。 
3. 3ABVCap 
 假設在 3ABVCap中，每一個節點都是靜止的
狀態，獨一無二的 ID 和相同的傳輸範圍。在
3ABVCap 中，共有四個處理階段且每一個節點至
少會被分配到一組虛擬座標 (u. Circle, u. Offset, 
u.Height, u. Ripple) 。第一階段，需找到定位點，
描述在第 3.1.節。第二階段，利用定位點來建立軸
線，描述在第 3.2.節。第三階段，分配虛擬座標給
在軸線上的每一個節點，描述在第 3.3.節。第四階
段，在網路中沒有被分配到虛擬座標的節點則找一
個最接近自己的軸點加入，並與此軸點成為擁有同
一組虛擬座標群組的節點，最後在鄰近不同群組橋
接點上分配座標，描述在第 3.4.節。本篇論文中，
每一個節點都至少會有一組虛擬座標。 
3.1. 選擇定位點 
 首先要選出Xଵ和Xଶ兩個定位點，利用和
ABVCap 相同的方法，同樣由匯聚點W廣播訊息給
每一個節點，而每一個節點就可以知道自己和匯聚
點W之間的躍距數，離W最遠的節點設為Xଵ，離Xଵ最
遠的節點設為Xଶ，在Xଵ和Xଶ之間最短路徑的節點中，
找距離Xଵ和距離Xଶ兩個距離差距最小的節點設為O。
令u. x及u. x′分別為節點u到Xଵ及Xଶ的躍距數，對所
有滿足|u. x − u. x′| ≤ 1的節點u中，選出距離定位點
O最遠的節點設為Yଵ，距離Yଵ最遠的節點設為Yଶ。令
u. y及u. y′分別為節點u到Yଵ及Yଶ的躍距數，對所有
滿足ඥ(u. x − u. x′)ଶ + (u. y − u. y′)ଶ ≤ √2的節點v
中，選出距離定位點O最遠的節點設為Zଵ，距離Zଵ最
遠的節點設為Zଶ。 
3.2. 建立軸線 
1. 建立CircleAxis：從Xଵ開始，Circle座標
的初始值為 1，選擇一條到Yଵ的最短路
383
?????????? 2011??屆??????用???
較接近目的地的鄰近節點出現再以貪婪法做繞徑。
如果接收封包的節點 u其虛擬座標與目的地之虛擬
座標相同，但是u ≠ d，我們可以使用像 ABVCap
繞徑中所使用的先應式繞徑法(proactive routing)，
根據繞送表來找尋同一個群組內的節點。 
 在以貪婪法來做繞徑時，會根據虛擬座標選擇
較接近目的地 d 的節點來傳送，假設有一節點u收
到封包，在節點u的鄰近節點中，以節點v的虛擬座
標最靠近節點d，且也比節點u更靠近節點d，則節
點u會選擇傳送封包到節點v。 
 當無法找到比自己更接近目的地的節點時，這
時就會使用邊界繞徑法。在邊界繞徑法中，假設節
點u為非軸點且欲傳送封包時，節點u就會試著傳送
封包到與節點u同一群組且 Ripple為 0的節點，在
傳送過程中，如無遇到比節點u更靠近目的地的節
點時，則封包最後會傳向 Ripple為 0的節點，接下
來根據此節點的 Height座標，封包會向上或向下來
尋找軸上的節點是否有存在其它更靠近目的地的
節點，我們可以不斷使用邊界繞徑法，直到可以使
用貪婪法找到下一個節點。 
如圖一所示，假設節點 6欲傳送一封包至節點
33。首先，節點 6 以貪婪法來繞徑會選擇節點 31 
(10 4⁄ , 10 12⁄ , 1 3⁄ )來轉送封包，因為節點 31是節
點 6所有鄰近節點中最接近目的地節點 33，當封包
傳送到節點 31時，節點 31並沒有其它鄰近節點更
接近目的地，根據邊界繞徑法，以Ripple座標找到
下一個節點 23(11 4⁄ , 9 12⁄ , 1 3⁄ )，同理，封包經過
節點 12 到節點 34，此時根據貪婪法可得到節點 9
較接近目的地，如此經過節點 32、16到節點 2，已
經沒有其它節點較接近目的地，也沒有相同的
Ripple座標，最後就以先應式繞徑(proactive routing)
找尋節點2的繞送表找到下一個節點，得到節點33，
並傳送過去，即結束繞徑。 
5. 效能評估 
 在我們的模擬中，我們以 ABVCap、GRG、
GHG和 3ABVCap來做比較，因為 GHG和 GRG是
在 3D 無線感測網路中採用實際位置來繞徑，而
ABVCap 是在虛擬座標系統中做傳輸，且不需要
GPS輔助。我們假設所有節點在網路中都有唯一的 
ID，而且都為靜止的，我們不考慮封包遺失、封包
延遲…等因素，我們建立一個10 × 10 × 10的立體
網路空間且密度為 6~14 之間的網路，每一個網路
建立 100 條連線以評估網路效能，在下列實驗中，
首先會比較在 ABVCap和 3ABVCap中，擁有共同
虛擬座標的群組中節點的個數，接著是比較平均繞
送路徑和最短路徑長的百分比，平均傳送的路徑越
長，所需要耗費的能量就越大。 
圖二是同一個群組中平均節點的個數，可以得
知在 ABVCap中同一個群組有許多的節點，也因此
有較多用於建立先應式繞徑法的能量消耗，然而在
3ABVCap 中，群組中的節點較少，分布的也較為
平均。 
圖三則是平均路徑的長度，一般來說，網路密
度高，相對路徑長度就比較小，3ABVCap 的路徑
長度明顯比 GHG 和 ABVCap 還長，這是因為
 
圖三、延伸路徑 
 
圖二、在同一群組中平均節點的個數 
385
?????????? 2011??屆??????用???
附錄四
37
動，網路上各節點的傳輸與感測範圍皆相同，此外，
感測器可以將多筆收集到的資料整合為一[7][8]，節
點擁有自己、鄰近節點與匯集點的地理資訊，其中
節點的位置座標可以透過 GPS 或其他研究所提出
的定位演算法[9][10]獲得。 
在我們所提出的 ESAOR方法中，首先利用棋
盤式的切割來建立分群，以匯集點為原點，將整個
網路相對於匯集點的東西南北方位分成四個象限，
再針對每個象限做細部切割，偵測到事件時節點利
用 ESAOR 的繞徑方式往匯集點傳送，在資料繞徑
方面，設計每個象限的角平分軸線當作資料匯集方
向，以聚集此象限的感測資料，於 2.1 節有切割方
法詳細說明，繞徑方式則於 2.2節有詳細說明。 
2.1 網格式分群 
此分群方法包含兩個階段，在第一階段中，我
們根據匯集點將整個網路區分為四個象限，在第二
階段中，則依照網路設定的網格邊長ℓ進行分群
[11][12]，同一個網格內的節點屬於同一群組  
在第一階段中，我們將匯集點當作原點，把網
路依照方位分成東北、西北、西南與東南等四個象
限，在此匯集點的東北方向為Ⅰ象限、西北方向為
Ⅱ象限、西南方向為Ⅲ象限、東南方向為Ⅳ象限，
給定一網路 G (VG , EG)，VG代表所有節點集合，對
於 任 一 節 點 u ∈  VG 的 座 標 表 示 為
( 𝑢. 𝑝𝑜𝑠_𝑥 , 𝑢. 𝑝𝑜𝑠_𝑦 ) ， 匯 集 點 𝑆𝑖𝑛𝑘 的 座 標 為
(𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥 , 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑦)，在此節點 u 所處的象
限表示為 u.𝑞𝑢𝑎，u.𝑞𝑢𝑎可根據方程式(1)算出： 
u.𝑞𝑢𝑎 =
{
 
 
 
 Ⅰ, 𝑖𝑓 (𝑢. 𝑝𝑜𝑠_𝑥 ≥ 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥 ＆ 𝑢. 𝑝𝑜𝑠_𝑦 ≥ 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑦 ) 
Ⅱ, 𝑖𝑓 (𝑢. 𝑝𝑜𝑠_𝑥 < 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥 ＆ 𝑢. 𝑝𝑜𝑠_𝑦 ≥ 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑦 )
Ⅲ, 𝑖𝑓 (𝑢. 𝑝𝑜𝑠_𝑥 < 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥 ＆ 𝑢. 𝑝𝑜𝑠_𝑦 < 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑦 )
Ⅳ, 𝑖𝑓 (𝑢. 𝑝𝑜𝑠_𝑥 ≥ 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥 ＆ 𝑢. 𝑝𝑜𝑠_𝑦 < 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑦 )
 (1) 
以圖 1為例，匯集點的座標為(49 , 49)，節點𝑎的座
標為 (57 , 77)，將節點𝑎的座標代入方程式(1)，由
於𝑎. 𝑝𝑜𝑠_𝑥 ≥ 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥且𝑎. 𝑝𝑜𝑠_𝑦 ≥ 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥，
故節點𝑎所處的象限為Ⅰ象限。 
在第二階段中，針對每個象限內的節點做網格
式的分群，網路根據邊長ℓ ×  ℓ的網格做分割，網
格(𝑞, 𝑚, 𝑛)代表在𝑞象限內網格範圍為(
ℓ
2
× 𝑚 ± 
ℓ
2
 ,
ℓ
2
× 𝑛 ± 
ℓ
2
) 的區域。在網路中，任一節點 u的網格 
 
位 置 為 (𝑢. 𝑞𝑢𝑎, 𝑢. 𝑔𝑟𝑖𝑑_𝑥, 𝑢. 𝑔𝑟𝑖𝑑_𝑦)  ， 在 此 將
(𝑢. 𝑔𝑟𝑖𝑑_𝑥, 𝑢. 𝑔𝑟𝑖𝑑_𝑦)稱為在𝑢. 𝑞𝑢𝑎象限內的網格
(𝑢. 𝑞𝑢𝑎, 𝑢. 𝑔𝑟𝑖𝑑_𝑥, 𝑢. 𝑔𝑟𝑖𝑑_𝑦)  的 網格座標 。 而
 𝑢. 𝑔𝑟𝑖𝑑_𝑦的計算方式與𝑢. 𝑔𝑟𝑖𝑑_𝑥相同，𝑢. 𝑔𝑟𝑖𝑑_𝑥可
根據方程式(2)算出： 
 
舉例來說，圖 2為經過網格式分群(ℓ =  10)後的網
路圖，其匯集點的實際座標位置為 (49 , 49)，網路
中有𝑎、b與c三個節點的座標，分別為(57 , 77)、(51 , 
75)與(60 , 51)。根據方程式(2)，得知節點 a、b與 c
所屬網格依序為網格(Ⅰ, 1 , 3)、網格(Ⅰ, 1 , 3)與網
格(Ⅰ, 2 , 1)，由此可知，a與 b為同一群組，c與 a、
b為不同群組。  
在此定義四條角平分軸線，此四條軸線皆從匯
集點出發分別往東北方、西北方、西南方與東南方
所延伸的線，分別為𝐴𝑥𝑖𝑠_Ⅰ、𝐴𝑥𝑖𝑠_Ⅱ、𝐴𝑥𝑖𝑠_Ⅲ與
𝐴𝑥𝑖𝑠_Ⅳ表示。以圖 2 為例，軸線𝐴𝑥𝑖𝑠_Ⅰ從匯集點
出發向東北方向延伸，凡該軸線通過的網格其
𝑔𝑟𝑖𝑑_𝑥與𝑔𝑟𝑖𝑑_𝑦皆相等。 
我們使用集中節點負責收集與整合網格內所
有節點的資訊，集中節點的選擇方式依網格種類分
成兩種，第一種為軸線所通過的網格，另一種為非
軸線上的網格，此兩種網格中皆有一個參考座標，
集中節點會是網格內較靠近參考座標的節點。假設
Ⅰ象限內有一網格 u，則該網格內的參考座標為
(𝑢. 𝑟𝑒𝑓_𝑥 , 𝑢. 𝑟𝑒𝑓_𝑦)，若 u為軸線所通過的網格，參
考座標公式如方程式(3)所示： 
 
匯集點 集中節點 節點 
  圖 1. 原始網路圖    圖 2. 分群後網路圖 
𝑢.𝑔𝑟𝑖𝑑_𝑥 =  
𝑢. 𝑝𝑜𝑠_𝑥 − 𝑆𝑖𝑛𝑘. 𝑝𝑜𝑠_𝑥
ℓ
  (2) 
378
?????????? 2011??屆??????用???
 會選擇其鄰近節點中最靠近匯集點的節點當作新
的傳輸路徑，收到資訊的節點再根據網格內傳輸將
資料傳給該網格的集中節點，傳輸路徑則依照新選
的網格根據方程式(5)來規畫新的路徑，直到傳送回
匯集點為止。以圖 4為例，網格(Ⅰ, 1 , 5)欲傳送資
訊回匯集點，根據方程式(5)得知傳輸路徑應傳向軸
線所通過的網格(Ⅰ, 3 , 3)，故網格(Ⅰ, 1 , 5)會先將
資訊傳往網格(Ⅰ, 2 , 4)，當網格(Ⅰ, 2 , 4)欲將資訊
傳向網格(Ⅰ, 3 , 3)，但是網格(Ⅰ, 2 , 4)的集中節點
發現並無任何鄰近節點在網格(Ⅰ, 3 , 3)，故網格(Ⅰ, 
2 , 4)的集中節點改選擇距離匯集點較近節點傳送，
此時最近的鄰近節點在網格(Ⅰ, 2 , 3)中，因此將訊
息傳往網格(Ⅰ, 2 , 3)，網格(Ⅰ, 2 , 3)再依照方程式
(5)繼續傳往網格(Ⅰ, 2 , 2)，當抵達軸線上的網格後
就轉往匯集點方向傳送，網格(Ⅰ, 2 , 2)將資訊傳給
網格(Ⅰ, 1 , 1)，網格(Ⅰ, 1 , 1)的參考座標即為匯集
點，故完成此傳輸任務。 
3. 實驗與結果 
在本實驗的網路模型中，假設此網路範圍為
100 × 100，1000個感測器隨機散佈於此網域中，節
點的感測與傳輸範圍皆為 10，預設匯集點所在位置
於網域的中心點。產生 n 個網路事件的方法如下：
於此網域中隨機選出 n個位置，並以每一個位置為
中心，10為半徑，半徑內的感測器有 0.8的機率會
感測到此訊息。本實驗評估 ESDC[6]與 ESAOR 在
事件發生後所需的傳送封包總和，在此實驗中，每
個實驗數據為平均 50次實驗的結果。 
圖 5 為 ESDC 與 ESAOR(ℓ = 10 , ℓ = 20 , 
ℓ = 30, ℓ = 40, ℓ = 50)在不同事件個數下的效率 
 
比較結果。由此實驗結果得知，當事件數目增加時
ESDC與 ESAOR(ℓ = 10, ℓ = 20, ℓ = 30, ℓ = 40, 
ℓ = 50)的封包傳輸總數會隨之增加，主要是因為事
件數增加，所需要回傳的封包數也會隨之增加。另
外，ESDC 的封包傳輸總數都較 ESAOR(ℓ = 10, 
ℓ = 20, ℓ = 30, ℓ = 40, ℓ = 50)多，主要原因為
ESDC 在事件發生後會對事件節點做群組的建構，
建構時節點必須與其他節點互相溝通，以致增加許
多封包傳輸的數量。在ESAOR方法中，當ℓ變大時，
所需的傳輸封包總數也會隨之變多，主要原因為ℓ
變大時，集中節點個數變少，所以封包有較大機率
需較長傳遞路徑才得以匯聚，因此需較多節點傳輸
並導致較多封包傳輸次數。 
4. 結論 
本篇提出一個應用於無線感測網路資料蒐集
的繞徑方法 ESAOR，利用網格式分群以整合網格
內的節點資訊，並以軸為導向方式，聚集不同網格
中資訊。在實驗中我們比較了 ESAOR與 ESDC所
需的封包傳輸個數，由實驗數據顯示，ESAOR 有
較好的效率。 
5. 致謝 
本研究為「在無線感測網路一種用來追蹤物件
有效率的位置預測方法」之計畫(計畫編號：NSC 
98-2218-E-151-007-MY2)之部分研究成果，在此謹
向國科會致謝。 
  
事件網格 傳輸路徑 匯集點 
圖 3. 原始傳輸路徑圖    圖 4.特殊狀況路徑圖  
圖 5. 封包個數比較圖(ESDC vs ESAOR) 
380
?????????? 2011??屆??????用???
國科會補助專題研究計畫項下出席國際學術會議心得報告 
 
                                     日期：100年4月20日 
計畫編號 NSC 98－2218－E－151－007－MY2 
計畫名稱 在無線感測網路一種用來追蹤物件有效率的位置預測方法 
出國人員
姓名 劉炳宏 
服務機構
及職稱 國立高雄應用科技大學 助理教授 
會議時間 
100 年 4 月 10 日
至 100 年 4 月 15
日 
會議地點 中國上海 
會議名稱 
The 30th IEEE International Conference on Computer 
Communications 
 
一、參加會議經過 
  INFOCOM 2011 會議於 2011 年 4 月 10 日至 4月 15 日在大陸上海陸家嘴的上海國
際會議中心舉行。4 月 10 日及 15 日有舉辦附屬的 workshop 行程，4 月 11 日則為
mini-conference。主要的 INFOCOM 2011 會議則在 4 月 12 日至 14 日舉行。在這幾
天的會議中，我鎖定了與我本身所作領域為主的相關 sessions，如 wireless sensor 
networks、wireless sensor network design、routing in wireless networks 等。
在這些 sessions 中也發現了相當有趣的研究題目，如”CABET: Connectivity-based 
Boundary Extraction of Large-Scale 3D Sensor Networks＂、＂Continuous 
Multi-dimensional Top-k Query Processing in Sensor Networks＂ 、 ＂A 
distributed Triangulation Algorithm for Wireless Sensor Networks on 2D and 
3D Surface＂、＂Construction of Directional Virtual Backbones with Minimum 
Routing Cost in Wireless Networks＂、＂Maximizing Lifetime for the Shortest 
Path Aggregation Tree in Wireless Sensor Networks＂、＂On Full-View Coverage 
in Camera Sensor Networks＂、＂Minimizing Service Delay in Directional Sensor 
Networks＂ 、 ＂Energy Provisioning in Wireless Rechargeable Sensor 
Networks＂ 、 ＂Robust Coverage under Uncertainty in Wireless Sensor 
Networks＂、＂Connected Coverage in Wireless Networks with Directional 
Antennas＂、＂Optimal Multiple-coverage of Sensor Networks＂、＂Energy 
Efficient Clustering for WSN-based Structural Health 
 1
  
 
Figure 2. Keynote speech會場照片 
 
Figure 3. 聆聽張正尚教授報告照片 
 
 
 3
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/08
國科會補助計畫
計畫名稱: 在無線感測網路一種用來追蹤物件有效率的位置預測方法
計畫主持人: 劉炳宏
計畫編號: 98-2218-E-151-007-MY2 學門領域: 平行與分散處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
