systems； 2) VLSI designs of H.264/SVC compression kernel； 3) 
Scalable audio compression techniques and its P2P data streaming 
system； 4) DVB-H combined DVB-MHP multimedia data 
streaming.In this joint project, we plan to establish a complete set of 
techniques, which could achieve multimedia receiver and decoder 
kernel in ARM core and VLSI integrated design for next generation 
mobile television systems. We will develop an advanced multimedia 
mobile TV system and realize kernel system for the next generation 
mobile TV in three years. 
 
 1
計畫之背景及目的 
行動電視建立於數位視訊廣播系統為基礎上，可將影音數位內容及多媒體服
務以廣播的方式將電視服務呈現於手持式之行動終端機。與3G 手機之行動通訊
系統相比，行動廣播電視技術的將可提供品質穩定與價格便宜，將帶起了行動電
視的風潮。目前全球行動電視技術標準，目前有四個主要行動電視標準被世界各
國所採用，計有泛歐規的手持式數位視訊廣播 (DVB-H)、韓國與英國的行動電
視採數位多媒體廣播 (T-DMB) 規格，美國高通公司所開發的專有規格之媒體前
向鏈路技術 (MediaFLO)，以及日本自創整合服務數位廣播 (ISDB-T) 規格之再
延伸。由數位電視系統結合既有手機行動通訊系統，將成為未來行動多媒體影音
平台的主流。目前行動數位電視標準規格，視訊以先進視訊H.264/AVC，音訊以
先進音訊AAC 為主流。然而，國際通訊匯流已蔚為趨勢，盱衡國際多媒體壓縮
標準如H.264 可階式視訊 (H264/SVC) 及H.264 多視角視訊 (H.264/MVC) 標
準亦有長足進步，我們相信可前瞻的研究行動數位電視標準採用可階式視訊與可
階式音訊之編碼技術之可行性，並研究相關之應用之以改進編碼技術之可能性。
同時，編碼技術結合串流網路技術之設計亦應加以考慮。新一代的數位多媒體服
務隨著數位電視的開播將有劃時代的演進，經無線或有線的方式大量傳送至所需
的個人或家庭。 
歐洲數位視訊廣播 (DVB) 訂定一個新的共同多媒體應用平臺，稱為數位電
視多媒體平臺 (MHP)以支援許多新興的多媒體服務，例如，新聞收報機，股票
行情指示器，投票，本地付費遊戲，電子商務，電子政府等應用。數位電視多媒
體平臺的目的即為允許數位內容提供者在各種不同的消費性電子產品，如數位機
上盒、數位電視、多媒體電腦及手持式裝置上提供不同的應用與服務。然而，數
位廣播電視系統之多媒體共通平台 (DVB-MHP) 在全世界推廣並不十分順暢。
因行動電視已具備回傳通道，為於有限資源下提升行動電視之互動服務，結合數
位電視多媒體家庭平台 (DVB-MHP) 技術於行動電視系統 (DVBH) 之應用，亦
應於未來前瞻行動電視應加以考量。 
尤其 DVB-H 在未來必然會與隨選視訊系統 (Video on Demand) 做結合，在
此前提之下可階式多媒體編碼之相關技術之前瞻規劃研究更顯為重要，使得本計
劃將變的更有價值。研究應用層自動重傳要求 (ARQ) 與向前錯誤更正 (FEC) 
之機制以滿足視訊資料群播 (multicast) 所需的服務品質，而在MHP 標準中提供 
IP 封裝的群播服務是選擇性的功能而且並沒有定義其傳輸機制，在未來提供視
訊群播服務在數位家庭網路是一項重要的服務。對於群播影像服務，為保證接收
端在傳輸之延遲上限之前能正確接收多媒體資料，研究應用層結合自動重傳要求
與向前錯誤更正之機制並以數學最佳化來描述該機制。透過此一最佳化模型我們
可算出重傳上限之次數與所要加的多餘的錯誤更正碼以滿足多媒體資料在 
DVB-H 系統之服務品質要求。為了在 MHP 相容的裝置上提供新的服務，DVB 
計畫定義了在以 IP 為基礎的網路上傳輸的通訊規約。特別的，DVB-H 被定義
 3
Scalability)的架構，為了實現時間可階 (Temporal Scalability) ， H.264/SVC 以
動態補償時間濾波器 (Motion-Compensation Temporal Filter，簡稱MCTF) 或 
Hierarchical B Pictures 的編碼方式完成，為了達到SNR Scalability 的特性上，使
用Coarse-Grain Scalability (CGS)和Medium-Grain Scalability (MGS) 的方式。另外
在Entropy Coding 中，以Context-based Variable Length Code (CAVLC) 或
Context-based Adaptive Binary Arithmetic Code (CABAC) 的方法來降低所需傳輸
的資料量，各單元部份之計算量龐大，需適當考慮用VLSI 電路來設計其壓縮及
解壓縮核心。 
已  知 之 音  訊 壓 縮  演 算 法  MPEG-1 Layer 3 (MP3) 、MPEG-2 
Advance Audio Coding (AAC)…等屬於所謂的失真壓縮法 (Lossy Coding)，這種
利用人類感官知覺的特性作的失真壓縮法，又叫做感知編碼  (Perceptual 
Coding)，其壓縮流程大體遵循，先將所欲壓縮的聲音訊號由時間領域 (Time 
domain) 表示法轉換到頻率領域 (Frequency domain) 表示法，再利用音響心理學
模型 (Psychoacoustic Model) 分析之後的結果，進行量化 (Quantization) 以及無
失真壓縮 (Lossless Coding)，成為最後的壓縮訊號。目前廣泛地使用在需要高音
質低 bit-rate 的應用。由於 MP3 及AAC 音訊壓縮法丟失了大量的資料，在高
壓縮比下，儘管有音響心理學模型保證其在感知上近似原音，在音質表現則明顯
地呈現晦暗、單調和低沈等令人不快的感覺；故而近幾年來，高頻重建 (High 
Frequency Reconstruction (HFR))研究如火如荼地展開，以加強目前感知 
(Perceptual Based) 壓縮法不足之處。高頻重建是基於利用低頻訊號成份組成來推
估重建其高頻訊號成份，以達到較寬廣的頻譜表現來改善音質。最著名的高頻重
建方法非頻帶複製 (Spectral Band Replication(SBR)) 莫屬，它被使用在 MP3 新
一代的演算法 MP3 Pro 以及 AAC 的增強版本 AAC Plus (High Efficiency 
MPEG AAC) 中，並已在 2001 年12 月正式成為 MPEG-4 標準的參考模型。 
 
 
 
 
 
 
 
 5
子計畫二:  H.264/SVC 多媒體視訊之系統晶片設計 
子計畫二將以 RISC-Based 之 VLSI 設計為目標來設計 H.264/SVC 多媒
體壓縮核心，利用可重複使用的 IP，並藉由完整的電路設計及驗證流程，來完
成 H.264/SVC 多媒體晶片系統設計 (SoC)。由於視訊編解碼複雜度相對地高，
利用 VLSI 的設計方式以降低處理器所需的運算量，進而能達到即時視訊效
果。由於本計畫採用 Platform-base 設計所有壓縮核心，將有助於設計 IP，可透
過 Memory Bus 與現有系統晶片結合應用。以 RISC 架構之多媒體壓縮核心之
VLSI 方塊圖，如圖（二）所示。 
 
 
圖（二）RISC 架構之多媒體壓縮核心之示意圖 
 
子計畫三: 具備可調適性之音訊壓縮演算法與點對點串流系統設計 
子計畫三旨在探討可調適性之音訊壓縮演算法於點對點串流系統的應用。傳
統的壓縮演算法若要達到可調適性，通常透過 trans-coding 的方式達成，也就是
傳輸端必須同時具備有編碼器與解碼器，透過重新編碼產生出符合現在網路狀況
的音訊位元碼，或是預先準備好數份不同壓縮率的檔案，在傳輸過程中，動態挑
選合適的壓縮率檔案內容來傳送。而本計畫之具備可調適性之音訊壓縮演算法，
可讓同屬一個框架的位元流任意切割而不需額外的預先運算，因此可大大降低儲
存空間的需求、即時有效率地變動頻寬需求，讓使用者聆聽到平滑流暢的音訊，
而又不浪費頻寬。 
點對點串流系統將是下一代無線網路電視系統必備之傳輸模式。由於行動裝
置具備高度行動性，使得固定無線基礎設施的傳輸方式不再適用。移動的節點，
 7
最後我們考慮在 DVB-H 系統下設計一協同式 (Collaborative) 影像串流
(Video Streaming) 分享機制。在此機制下，只有少數手持式裝置經由基地台接收
部影像資料。其它手持式裝置則透過其他系統 (如Wi-Fi, UWB 等等) 來交換彼
此的影像資料，讓使用者可以減少接收影像串流之花費與節省廣播系統之頻寬。
此外每一個手持式裝置可自行決定是否要與鄰近的手持式裝置交換影像資料。此
機制之特徵還包括有: 強健性，高擴展性與完全分散性。子計畫三在於發展具備
可調適性能力之音訊壓縮格式，以分層編碼（Layered Coding）的方式壓縮音訊，
壓縮過後的位元碼將區分為基本層（Basic Layer）以及許多的細部層（Detail 
layer）；解碼基本層可產生最低可接受聆聽品質的音訊，細部層則用來細緻化基
本層，越完整得接收細部層，可讓聆聽品質越加完美。此外，透過與子計畫四的
整合，可在無線點對點網路上，實現具可調適性之串流系統；子計畫四的傳輸協
定模組，可提供即時網路傳輸頻寬、封包遺失及節點連結等資訊，幫助系統決定
網路傳輸拓樸，提高頻寬的有效利用性、串流的即時性。下圖為子計畫三與子計
畫四的軟體合作架構圖。同理，子計畫一中之視訊可階壓縮與子計畫四的軟體合
作架構圖，亦與圖(四)相似。 
 
 
圖(四)子計畫三與子計畫四的軟體合作架構圖 
 
 
 
 
 
 
 
 
 9
不同的影響，因此針對不同的功能區塊設計其演算法，並同時配合 VLSI 實現，
改良演算法設計，達到軟硬體共同設計的特性。整體而言，子計畫二在學術及實
用上都有一定的價值與貢獻。研究成果亦已完成原先預定目標的七成左右。研究
成果已有 8 篇期刊論文及 11 篇會議論文。 經由子計畫二「H.264/SVC多媒體
視訊之系統晶片設計」三年來所補助之經費提供了三位博士班與九位碩士班學生
針對各自研發的議題進行深入之研究。子計畫二參與人員除了在學理上可充分了
解視訊處理電路設計、測試、整合所面臨的各種問題，開發解決之道外；在實際
應用方面，計畫參與人員將電路與驗證平台整合，實際進行硬體的量測及驗證工
作，亦獲取晶片系統實現諸多之技術與經驗。因此，透過本計畫理論與實際相結
合的訓練，已順利為我國培育相當多之積體電路設計及測試相關之人才。 
子計畫三在計畫第三年主要完成工作為: 1) 完成建構於「具備通訊基礎設備
之無線網路環境」的串流系統；2) 利用前述所建置的環境，完成無線網路環境
下的音訊串流數據的蒐集、分析；3) 建立可調適性之音訊壓縮演算法的調適機
制；4) 完成可調適性之音訊串流及雙向控制機制；5) 確定音訊網路層通訊介
面，提供相關子計畫完成開發及測試；6) 完成規劃於「不具備通訊基礎設備之
無線網路環境」的串流系統的規格、所需應用程式介面以及點對點串流系統容錯
機制，並協助相關子計畫完成設計。 
除此之外，由於DVB-H技術規格於2004年11月正式成為歐洲電信標準學會
(European Telecommunications Standards Institute；ETSI) 之標準，使得行動裝置
收看數位電視已成為一種可行的服務。手持式數位視訊廣播  (Digital Video 
Broadcasting - Handheld；DVB-H) 是以地面數位視訊廣播  (Digital Video 
Broadcasting - Terrestrial；DVB-T) 為基礎，為了降低行動裝置的功率消耗及通道
雜訊的容忍力，在資料鏈結層新增時間切片 (Time-Slicing) 及多重協定封裝-向
前錯誤更正機制  (Multi-Protocol Encapsulation - Forward Error Correction；
MPE-FEC) 兩項關鍵技術，並且可以向後相容於現有的DVB-T系統。子計畫四
在計畫第三年研究針對 DVB-H 在鏈結層新增的兩項關鍵技術，提出一個可同
時最佳化這兩項技術的演算法。其中演算法主要是針對實體層的影響 (如干擾與
雜訊等) 與應用層編碼的特性去設計在 DVB-H 鏈結層的傳輸機制。首先我們
利用 Greedy Approach 在一有限的頻寬下將每一部影片做時間排程，同時經由
每一組的時間排程及通道傳輸速率得到每一部影片在鏈結層所能傳送的資料
量，接著再估計每一部影片在鏈結層所能傳送的影像 (frame) 張數，此時需考
慮接收端位於應用層的 video buffer，應避免傳送的資料量造成 buffer overflow
及 underflow，接著在鏈結層考慮當影像的封包遺失所造成的影像失真度來決定
每個封包的重要程度，並利用動態規劃 (Dynamic Programming) 的方法依據這
些重要程度來決定每個 MPE-FEC 要加多少保護，透過此排程結果來傳送影
片，讓使用者可以接收到最好的影像品質。 
 
 
 11
15. Video Coding for Low Bit Rate Communication, ITU-T Rec. H.263, 1998.  
16. Joint Video Team, Draft ITU-T Recommendation and Final Draft International 
Standard of Joint Video Specification, ITU-T Rec. H.264 and ISO/IEC 14496-10 
AVC, May 2003.  
17. ITU-T Rec. H.264 and ISO/IEC 14496-10 (MPEG-4 AVC), ITU-T and ISO/IEC 
JTC 1, Advanced Video Coding for Generic Audiovisual Services, Version 1: 
May 2003, Version 2: May 2004, Version 3: Mar. 2005, Version 4: Sept. 2005, 
Version 5 and Version 6: June 2006, Version 7: Apr. 2007, Version 8 (including 
SVC extension): Consented in July 2007.  
18. J. Reichel, H. Schwarz, and M. Wien, Joint Scalable Video Model JSVM-11, 
Doc. JVT-X202, Joint Video Team, June 2007.  
19. H. Schwarz, D. Marpe, and T. Wiegand, Comparison of MCTF and Closed-Loop 
Hierarchical B Pictures, Joint Video Team, Doc. JVT-P059, July 2005.  
20. X. Wang, Y. Bao, M. Karczewicz, and J. Ridge, Implementation of Closed-Loop 
Coding in JSVM, Joint Video Team, Doc. JVT-P057, July 2005.  
21. C. D. Creusere, A new method of robust image compression based on the 
embedded zerotree wavelet algorithm,IEEE Transactions on Signal 
Processing ,1997, 
22. A. Said and W.A. Pearlman, A new fast and efficient image codec based on set 
partitioning in hierarchical trees,IEEE Transactions on Circuits and Systems for 
Video Technology ,1996, 
23. W. B. Huang and W. Y. Su and Y. H. Kuo, VLSI implementation of a modified 
efficient SPIHT encoder,IEICE Trans. Fundam. Electron., Commun., Comput. 
Sci. ,2006, 
24. M. Raad, A. Mertins, and I. Burnett, Audio compression using the MLT and 
SPIHT,Proceedings of DSPCS’ 02 ,2002, 
25. W.-C. Chang and J.-X. Wang and Alvin W.Y. Su, Harmonic Structure 
Reconstruction in Audio Compression Method Based on Spectral Oriented 
Trees,AES Convention ,2006, 
26. Wei-Chen Chang, On the Use of Bit-plane Audio Coding in MDCT 
Domain, ,2008,http://etdncku.lib.ncku.edu.tw/ETD-db/ETD-search/view_etd?U
RN=etd-0826108-123143 
27. Yu-Lin Wang  Wei-Hsiang Liao  Su, A.W.-Y., A SOT based digital audio 
coder using reference frame ordering method,Circuits and Systems (ISCAS), 
Proceedings of 2010 IEEE International Symposium on ,2010, 
28. Schijndel, Nicolle H. van; Bensa, Julien; Christensen, Mads G.; Colomes, 
Catherine; Edler, Bernd; Heusdens, Richard; Jensen, Jesper; Jensen, Søren Holdt; 
Kleijn, W. Bastiaan; Kot, Valery; Kövesi, Balázs; Lindblom, Jonas; Massaloux, 
 13
研究成果相關發表 
1. J. R. Ding, J. Y. Chen, F. C. Yang, and J. F. Yang . “Two-layer and Adaptive 
Entropy Coding Algorithms for H.264-based Lossless Image Coding,” IEEE 
International Conference on Acoustics, Speech, and Signal Processing, 
pp.1369-1372 ,2008. 
2. Wei-Ta Chien, Jun-Ren Ding and Jar-Ferr Yang . “H.264/AVC Based 
Hierochycal Two-Layer Lossless Coding Methods,” National Symposium on 
Telecommunication 2009 (NST 2009), Dec., Kaohsiung.  
3. S. T. Wei, S. R. Shen, B. D. Liu, and J. F.Yang, “Lossless image and video 
coding based on H.264/AVC intra predictions with simplified interpolations,” in 
Proc. IEEE ICIP, Nov. 2009, pp. 633-636. 
4. Karunanithi, B. D. Liu, J. F. Yang, and W. C. Tsai, “A low complexity detection 
of discrete cross differences for fast H.264/AVC intra prediction,” IEEE Trans. 
Multimedia, vol. 10, pp. 1250-1260, Nov. 2008.  
5. Y. C. Chao, S. T. Wei, B. D. Liu, and J. F. Yang, “Combined CAVLC decoder, 
inverse quantizer and transform kernel in compact H.264/AVC decoder,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 19, pp. 53-62, Jan. 2009.  
6. C. H. Kuo, L. C. Chang, K. W. Fan, and B. D. Liu, “Hardware/software 
co-design of a low cost rate control scheme for H.264/AVC,” IEEE Trans. 
Circuits Syst. Video Technol., vol. 20, pp. 250-261, Feb. 2010.  
7. C. H. Kuo, L. C. Chang, H. C. Chiu, and B. D. Liu, “Efficient two-pass rate 
control scheme based on adjusting distribution of DCT coefficients,” IET Image 
Process., vol. 4, pp. 211-222, June 2010.  
8. H. Y. Lin, K. H. Wu, B. D. Liu, and J. F. Yang, “An efficient VLSI architecture 
for transform-based intra prediction in H.264/AVC,” IEEE Trans. Circuits Syst. 
Video Technol., vol. 20, pp. 894-906, June 2010.  
9. L. C. Chang, C. H. Kuo, and B. D. Liu, “A two stage rate control mechanism for 
RDO-based H.264/AVC encoders,” IEEE Trans. Circuits Syst. Video Technol., 
vol. 21, pp. 660-673, May 2011.  
10. S. T. Wei, C. W. Tien, B. D. Liu, and J. F. Yang, “Adaptive truncation algorithm 
for Hadamard-transformed H.264/AVC lossless video coding,” IEEE Trans. 
Circuits Syst. Video Technol., vol. 21, pp. 538-549, May 2011.  
11. Y. C. Chao, C. H. Kao, B. D. Liu, and J. F. Yang, “Efficient inverse transform 
architectures for multi-standard video coding applications,” accepted for 
publication in IET Image Process..  
12. H. Y. Lin, K. H. Wu, B. D. Liu, and J. F. Yang, “Transformed-based mode 
decision algorithm for H.264/AVC intra-prediction,” in Proc. IEEE APCCAS, 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/31
國科會補助計畫
計畫名稱: 下一代行動電視之多媒體與網路整合核心系統設計
計畫主持人: 楊家輝
計畫編號: 97-2221-E-006-131-MY3 學門領域: 訊號處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
