2 
 
第六章、系統說明與實驗結果 ............................................................................................. 45 
6.1 系統環境及使用者介面 ....................................................................................... 45 
6.2 實驗結果與討論 ................................................................................................... 47 
第七章、結論與未來展望 ..................................................................................................... 53 
參考文獻 ................................................................................................................................. 54 
 
4 
 
圖目錄
 
 
圖 2-1、MPEG-1 串流結構。 .............................................................................................. 12 
圖 2-2、MPEG-1 編碼流程圖 [6] 。 ................................................................................. 13 
圖 2-3、影像頻率圖。 .......................................................................................................... 14 
圖 2-4、MPEG-1 壓縮編碼流程。 ....................................................................................... 15 
圖 2-5、運動向量示意圖。 .................................................................................................. 15 
圖 2-6、移動補償編碼圖。 .................................................................................................. 16 
圖 2-8、MPEG-1 編碼順序與播放順序對應圖。 .............................................................. 17 
圖 2-9、視訊分割之階層關係圖 [3]。 ................................................................................ 18 
圖 3-1、系統架構圖。 .......................................................................................................... 20 
圖 4.1、I 影格取樣序列。 .................................................................................................... 22 
圖 4-2、色彩描述分類圖。 .................................................................................................. 24 
圖 4-3、HSV 模型。 ............................................................................................................. 25 
圖 4-4、色彩統計。 .............................................................................................................. 26 
圖 4-5、色彩結構。 .............................................................................................................. 26 
圖 4-6、Feature channels [36]。 ............................................................................................ 27 
圖 4-7、邊緣直方圖取樣模式。 .......................................................................................... 28 
圖 4-8、移動偵測示意圖。 .................................................................................................. 29 
圖 4-9、單張影格內 macroblock 移動向量圖。 ............................................................... 30 
圖 4-10、移動向量方向分區圖。 ........................................................................................ 30 
圖 4-11、Temporal distribution of activity 示意圖。 .......................................................... 31 
圖 5-1、SOM 網路拓撲類型圖。 ......................................................................................... 34 
圖 5-2、自我組織映射圖架構。 .......................................................................................... 34 
圖 5-3、學習訓練示意圖。 .................................................................................................. 36 
圖 5-4、候選投票機制示意圖。 .......................................................................................... 39 
圖 5-5、序列時間正規化示意圖。 ...................................................................................... 41 
圖 5-6、序列 x、y 正規化成調整後二維空間對應示意圖。 .......................................... 41 
圖 5-7、無端點限制路徑示意圖。 ...................................................................................... 42 
圖 5-9、局部路徑限制表示法。 .......................................................................................... 43 
圖 5-10、局部路徑法則下二維總體路徑限制圖。 ............................................................ 44 
6 
 
中文摘要 
 
內容檢索 (video content retrieval) 的主要目的是讓使用者可以從龐大多視訊資料庫
中，快速且準確的搜尋到所要的視訊片段 (video clip)。一般來說，要建置一套供使用者下
達查詢範例 (query-by-example) 搜尋視訊片段的視訊內容檢索系統，主要分為三大部份：
(1) 分鏡偵測 (shot detection) (2) 分鏡表示法 (shot representation) (3) 分鏡比對  (shot 
matching)。由此可知，分鏡偵測是視訊內容檢索中非常重要的部份，然而，分鏡偵測本質
上就是具有挑戰性的視訊分割 (video segmentation) 問題，有鑑於此，本研究提出一套不需
分鏡偵測的視訊內容檢索系統，並提出一個由粗到細的快速搜尋策略，首先，我們利用自
我組織映射圖 (self-organizing map, SOM) 將高維的特徵向量降成低維，再建立每一項特徵
的索引映射圖 (indexing map)，使用者也可針對查詢範例的特性，自行選擇所需的主要特
徵，再利用索引映射圖之投票機制，快速的產生一些候選的視訊片段，最後我們利用局部
路徑限制的動態時間校正 (dynamic time warping, DTW)，對候選片段之相似度計算與排
序，以達到更正確且更快速的視訊內容檢索。 
 
關鍵詞：視訊內容檢索、分鏡偵測、視訊分割、自我組織映射、動態時間校正。 
 
8 
 
第一章、緒論 
 
現今多媒體技術發展快速，有許多資料都是以數位化方式儲存，例如數位相機、DV、
手機等多媒體擷取設備的日漸普遍，加上近年來網際網路，3G 行動技術蓬勃發展，現今
人們要取得多媒體資料已經相當容易，而人們依賴多媒體的活動也與日俱增。在擁有如此
大量多媒體資訊的同時，如何建立一套機制來有效管理、分類及搜尋，便成為近年來很重
要的研究課題。 
在分秒必爭時代中，考量能夠快速取得想要的資訊，現今視訊資料內容多以壓縮格式
儲存在網路上傳輸，多媒體格式五花八門，MPEG 是其中一個最主要且常被使用格式，由
於 MPEG 視訊標準的編碼方式能有效減少儲存空間，因此本研究選擇 MPEG 當測詴媒
體，分別在頻率域 (frequency domain) 與空間域 (spatial domain) 對資料擷取與計算具有鑑
別度的特徵，以進行視訊內容檢索。 
在多媒體資料檢索上，大致可分成兩種方法，一種是用文字或關鍵字 (text-based) 搜
尋多媒體資料，然而此方法有缺點：首先，使用者必頇以人工輸入所欲搜尋文字或關鍵字。
以視訊來說，需仰賴大量人力對大量視訊作註解，例如：大家耳熟能詳的 Yahoo! Video 
[1]、Google Video [2, 3]、YouTube [4]等服務，就是利用網路上的大量人力或是上傳者主觀
命名，為視訊註解 (tag)，使用者只要鍵入「關鍵文字」(keywords)，系統就會比對視訊的
註解，並將視訊列出。然而，使用文字仍舊難以針對視訊定下客觀而詳盡的描述，進而滿
足視訊內容搜尋上的需求，除了耗費許多的時間與人力成本，且容易因訂定的人主觀而產
生不一的結果；此外，多媒體視訊的視覺特質，像色彩 (color)、紋理 (texture) 與動作 
(motion) 等，常常很難用文字描述。俗語說：「文不如表，表不如圖」。影像又比不上視
訊能提供更多的資訊，為了克服以文字為主的搜尋方法之缺點，有學者提出了以多媒體資
料本身的視覺內容 (content-based)，如色彩、紋理、形狀等做為特徵來搜尋。雖然以多媒
體內容特性作為特徵已能充分描述內容本質，然而就實際在檢索上的應用，仍然必頇要以
人的觀點進行考量，即語意上 (semantic) 的概念。因此 ISO’s MPEG Group 在 1997 年訂
定了 MPEG-7，作為多媒體內容特徵描述標準，使得多媒體內容在特徵描述上有了統一且
比較高階具語意的標準，方便對多媒體資料內容描述、檢索與搜尋。現今以內容導向 
(content-based) 為主的方式，分析視訊特徵，首先會先對視訊作分鏡偵測 (shot detection)。
一般來說，視訊中物件運動在時間序列上並非靜止，同一分鏡的內容可視為連續且相似。
現今分鏡偵測方法都事先將視訊先進行切割，成為固定長度的分鏡，然而實際上在許多視
訊，經過這樣處理，根據視訊連續性，某些分鏡內容是屬於切割兩段分鏡共有內容。而這
10 
 
第二章、背景知識與文獻探討 
 
本章將詳細說明本研究中所用到的相關背景知識，並對過去方法與系統進行整理與探
討。第 2.1 節介紹 MPEG-1 串流；第 2.2 節說明視訊檢索系統發展。 
2.1 MPEG-1 串流 
本節分為三個部分作討論，第 2.1.1 節介紹 MPEG-1 背景知識與發展；因為要直接從 
MPEG-1 視訊解碼，必頇對 MPEG-1 串流組成有所了解，我們在第 2.1.2 節說明 MPEG-1 
串流結構；為了從串流當中取得所要分析內容，根據第 2.1.3 節編碼所使用的壓縮模型，
解碼出所需要的資訊。 
2.1.1 MPEG-1 背景知識 
視訊格式有很多，因為視訊格式不一，造成應用上的困難，因此成立 MPEG (Moving 
Picture Experts Groups) 組織，為視訊格式制定統一標準。1992 年制定 MPEG-1，1994 年
制定 MPEG-2，之後幾年對於標準細部修改，直到在 1999 年制定了 MPEG-4，2001 年
制定 MPEG-7，之後還有 MPEG-21 的制定 [5]。本研究主要採用壓縮的 MPEG 格式當作
分析對象，所以必頇對 MPEG 的串流與壓縮格式有所了解，以便在前處理時，能夠正確
取得所要分析資訊。因為本論文實驗中以  MPEG-1 視訊格式作為範例，以下以介紹 
MPEG-1 串流為主。 
MPEG-1 標準即 ISO/IEC11172，詳細說明視訊串流中影像和聲音壓縮與解壓方法，以
及播放 MPEG 串流時影像與聲音對應，主要是應用在 VCD 光碟上。一開始 MPEG-1 採
用演算法解析度為 352*240，傳輸速度為每秒 30 張影格 (frame per second, fps)，可將原始
大小約 2Mbytes，透過 MPEG-1 格式壓縮至 1.2Mbit/s 串流中傳送，現在已經可以支援更
高解析度與位元率。 
MPEG-1 內容主要分為五個部份： 
 
1. 系統 (Systems)：MPEG-1 把影像和聲音複合成同一段串流，並儲存之，也可分解個別
儲存，稱為同步和多重複合 (multiplex) 技術。本研究因為無使用到聲音部分，所以在
訓練測詴將聲音與影像分隔，只採用影像部分。MPEG-1 影像和聲音複合位元壓縮率
可達 1.5Mbits/s，標準名稱是 ISO/IEC 11172-1。 
12 
 
5. 巨方塊分層 (Macro-block Layer，MB layer)：巨方塊分層為一個 16x16 區塊，是色
彩取樣、動態估計及動態補償的基本單位。其中存有運動向量，是影格間編碼時使用
的基本結構。 
6. 區塊分層 (Block Layer)：區塊分層包含影格量化後，由 8x8 像素組成，是離散餘弦
轉換的最小單位。 
 
Sequence 1 Sequence 2 Sequence 3 Sequence 4 ………
Header GOP 1 GOP 2 GOP 3 ………
Header Picture 1 ……… Picture 1 …………
Header Slice 1 ……… Slice 8 ………
Header Macro Block 1 Macro Block 2 ……… ………
AddInc Type MV QScale OPB Block  0 …… Block  5
 
圖 2-1、MPEG-1 串流結構。 
2.1.3 MPEG-1 視訊壓縮模型 
MPEG-1 視訊壓縮使用許多的演算法來達到高壓縮率，由於影像串流之間，在時間上
與空間上，有許多冗贅 (redundancy) 資訊，甚至單格影像本身結構也有冗贅的情形，而視
訊壓縮目的，就是利用一系列的數學轉換和編碼演算法，來減少這樣冗贅情形，降低儲存
空間。MPEG-1 還採用了許多特殊技術增加效率和擴展性。圖 2-2 為 MPEG-1 視訊編碼
流程，以下說明重要演算法與壓縮概念： 
14 
 
1 1
0 0
2 2
1 0 1 0
if u if v
Cu Cv
if u if v
 
  
  
   
 
圖 2-3 代表離散餘弦轉換後影像頻率分佈圖，左上角係數稱為 DC 係數，其餘稱
為 AC 係數。DC 係數往下代表逐漸增高的垂直空間頻率係數，往右代表逐漸增高的
水平空間頻率係數，其他係數則代表垂直水平空間頻率的不同組合。 
 
8
8
DC
低頻
中頻
高頻
 
圖 2-3、影像頻率圖。 
 
圖 2-4 為 MPEG-1 的壓縮編碼流程。離散餘弦轉換後的係數因為重要性的不同，
透過量化表格進行量化。之後，再經由 zig-zag 掃描得到一維的陣列。DC 部份透過誤
差訊號編碼 (differential pluse code modulation, DPCM)，其他 AC 值則經過可變長度編
碼 (run length encoding)，最後再經過霍夫曼 (Huffman) 編碼即完成編碼。 
影格的編碼方式主要分為以下兩種： 
 
(1)  影格內壓縮編碼 (intra frame coding)：JPEG 壓縮也採用此演算法，即以 DCT 為
基礎變換將空間域至頻率域編碼技術，用來減少空間冗贅資訊，而影格內的壓縮
編碼全都是獨立編碼。 
(2)  影格間壓縮編碼 (inter frame coding)：在連續影格間，相同位置周圍，像素值很
有可能是相似的，因此可以用進行預測的工作，預測參考會比原本獨立編碼快，
因為藉由預測可以有更高壓縮比，節省儲存空間。影格間編碼，主要以移動估測 
(motion estimation) 和移動補償 (motion compensated) 來達到降低視訊時間上冗
贅目的。 
 
16 
 
理論上，如果每一個像素的運動軌跡，透過圖 2-6 移動補償編碼流程，都能利用
移動估測的方式得到對應的運動向量，那我們只需要編碼與送出第一張影格，以及每
一個像素的運動軌跡，就能紀錄一段 MPEG-1 視訊資訊，這樣的處理過程稱為移動
補償 (motion compensation)。 
 
畫面編輯器
參考影格
移動補償預測移動估計
目前影格
MV
誤差
 
圖 2-6、移動補償編碼圖。 
 
4. 影格編排：MPEG-1 中根據編碼方式不同，將影像分成三種類型： (1) I 影格 
(intra-frame)、(2) P 影格 (predicted-frame )、(3) B 影格 (bidirectional-frame)。視訊可以
看成連續影格組成，MPEG-1 視訊實際上就是這三種影格交錯排列而成。I 影格編碼只
有利用到影格內編碼來降低空間冗贅，並沒有參考其他影格來編碼；編碼與圖片編碼是
相同的，都是利用取樣 (sub-sampling) 及量化 (quantization) 來減少資訊量，達到壓縮
資料目的。如圖 2-7 所示，I 影格可以用來預測 P 影格，而 B 影格則可透過雙向參
考 P 影格與 I 影格，提高預測的正確率，並達到更高壓縮比。但是也因為預測的需求，
影格的編排要重新處理。圖 2-8 為影格顯示順序對應編碼順序，由於影格會利用到 P 
影格資訊，因此 P 影格編碼順序就要在 B 影格之前，如此一來解碼的時候，才可以
透過 P 影格資訊來還原 B 影格。 
Time axis
  Order    I   B   B   P   B   B   P   B   B   P   B   B   P   B   B   I
Bidirectional
Predicted
圖 2-7、影格預測示意圖。 
18 
 
層級 (level)：分鏡 (shot)、場景 (scene)、故事 (story)。我們也可以再對全部的分鏡作
分場景偵測 (scene detection) 與分故事偵測 (story detection)，如圖 2-9 所示，或者，可
以將若干個場景編排成故事 [18, 19]。而視訊分割的方法有許多種，如：以像素比對為
基礎方法 [20]、以直方圖為基礎方法、以區塊為基礎方法等，是在未壓縮領域下方法。
而壓縮領域下最常用的是利用 DC 值 [5]，因為 DC 值是壓縮資訊中，最直接與像素值
大小相關的部份。 
傳統方法是從每段分割片段中，找出最能代表片段的關鍵畫面 (key frame)來代替
分鏡。每段分鏡關鍵畫面可以有很多個，然後可以利用這些關鍵畫面作其他應用，例
如代表視訊，或者比較分鏡相似度 (similarity) 等。但取出關鍵畫面，不一定真的能夠
代表分鏡，準確度會影響到分析結果，所以有許多擷取關鍵畫面的方法提出來[6, 21, 
22]。 
 
 
圖 2-9、視訊分割之階層關係圖 [3]。 
 
2. 視訊內容表示方式 (video-content representation)：早期都以人工命名方式說明內容表
示這些分割分鏡，現今都以內容導向為主，個別取出需要的特徵值，進一步分析。以紋
理特徵來說，Tamura et al. [23] 於 1978 年，以人類視覺的心理學角度提出六種不同的
方法來描述紋理特徵，包含：粗糙性  (coarseness)、對比性  (contrast)、方向性 
(directionality)、線性 (line likeness)、規律性 (regularity) 和粗略性 (roughness)。Tamura 
特徵相似 Haralick et al. [24] 於 1973 年提出的共生矩陣 (co-occurrence matrix, CM)，
該方法研究紋理的空間灰階值相關性,構造出一個基於影像像素間方向和距離的共生矩
20 
 
第三章、系統架構 
 
本論文系統架構如圖 3-1，分為 (1) 離線運算與 (2) 線上運算等兩大部分，離線部分
主要先對測詴視訊進行資料前處理，再進行分類建置索引；線上部份提供使用者進行檢索，
提交查詢內容，透過系統比對機制，產生符合使用者需求的視訊片段。 
 
特徵萃取
MPEG 格式
視訊資料
自我組織映射圖
分類
索引映射圖建置
索引圖
使用者介面
結果
輸入
影格取樣選擇
比對起始
與結尾影格
視訊資料解碼
線上運算
離線運算
候選影格投票
與視訊片段產生
動態時間校正
排名比對
使用者
 
圖 3-1、系統架構圖。 
 
本系統首先對於 MPEG-1 測詴資料進行解碼，對不同型態影格進行選擇取樣，選擇取
樣策略於第 4.1 節探討說明，將分析產生的資料內容進行特徵萃取，選取特徵內容於第 4.2 
節說明。到此完成資料前處理，產生出具有鑑別力特徵代表對應影格，接下來將這些特徵
透過自我組織映射圖進行分類與訓練，生成多個叢集，叢集內的資料點具有高相似度。自
我組織映射圖概念將於第 5.1 節詳述。第 5.2 節說明利用視訊影格特徵向量建立自我組織
映射圖叢集索引，將高維度特徵降至低維度索引映射圖，提高使用者在線上檢索的效率。 
本系統在線上部份提供使用者介面，使用者可以輸入查詢範例並選取所需的特徵根據
使用者訂定的查詢內容，本研究提出的候選影格投票與片段 (clip) 產生方法，將於第 5.3 
節詳述。接下來將搜尋出候選片段，使用動態時間校正進行更詳細比對進行相似度排序，
產生使用者所需視訊片段。 
 
22 
 
縮；P 影格壓縮率比 I 影格高，P 影格可以做為其他影格的參考影格，但不能做為隨機讀
取依據。B 影格編碼時可以參考前後最近的 I 影格或 P 影格再結合動作估計與轉換編碼
進行壓縮，壓縮率比 P 影格更高，但 B 影格不能做為其他影格編碼時的參考影格，也不
能做為隨機讀取的依據。由於 B 影格可以參考未來影格，因此會造成編碼延遲，比較不
適合視訊電話及視訊會議等即時性的應用。 
由以上 I 影格、P 影格與 B 影格三種影格相對關係及特性，取樣決定採用所有 I 影
格為樣本，原因如下：(1) 相對於鄰近 P 影格與 B 影格都以 I 影格為參考；(2) I 影格在
整段視訊中變化過大時，才會獨立編碼；(3) 可以避免固定取樣時視訊片段變化不一，取
樣的結果並不符合。基於上述原因，我們可以從圖 4-1 秀出實際取樣的 I 影格，底下的
數字代表視訊中第幾張影格，取樣率約 1:15，取樣出結果，從圖 4-1 仍可以知道清楚此
片段內容，我們利用此機制，將原本所有影格的計算量降低 15 倍。 
 
 
圖 4.1、I 影格取樣序列。 
4.2 特徵選取 
本節說明本研究應用的特徵，本研究所採用的取特徵主要參考 MPEG-7，因此我們在
第 4.2.1 節先簡介 MPEG-7 內容描述標準，第 4.2.2 節說明 MPEG-7 特徵，第 4.2.3 段
描述我們所採用 Tamura 紋理特徵： 
24 
 
4.2.2 MPEG-7 特徵 
本文採取 MPEG-7 特徵中的部份描述子，說明如下：一段完整視訊可以內容分割為四
部分：(1) 影像、(2) 靜止區域、(3) 移動區域及 (4) 聲音，各特徵存在於不同內容，MPEG-7 
主要特徵的分類如下表格： 
 
表 4-1、特徵與內容關係表 [33] 。 
                    內容 
特徵 
影像 靜止區域 移動區域 聲音 
時間 (time) V  V V 
形狀 (shape)  V V  
色彩 (color) V V V  
紋理 (texture)  V   
移動 (motion) V  V  
攝影機移動 (camera motion) V    
聲音 (audio )   V V 
 
由於各個特徵包含一個以上描述子，本研究採用 MPEG-7 標準色彩、紋理與移動特徵為
檢索依據。 
 
1. 色彩特徵 (color feature)：色彩特徵分類如圖 4-2 所示，包含色彩空間 (color space)、
色彩量化  (color quantization)、主要色彩  (dominant colors)、延展性色彩  (scalable 
color)、色彩分佈 (color Layout)、GoF (group of frames)與 GoP (group of pictures)，詳述
如下： 
 
Color feature
Color QuantizationColor Space Dominant Colors Scalable Color Color Layout Color Structure
 
圖 4-2、色彩描述分類圖。 
26 
 
(6) 色彩結構：從影像內容中萃取出色彩描述類似色彩直方圖和結構資訊。主要功能
為影像與影像之間的內容比對，常見於靜態影像的擷取。色彩結構主要利用結構
元素 (structure element) 描述色彩內容在空間結構，如圖 4-4 影像中色彩量化基
本單位 (color bin) C1 至 C7 可記錄七種不同的色彩，結構元素的大小是 8*8 區
塊 (block)，此結構元素包含了三種色彩 C1、C3、C7，所以在基本單位欄位中分
別對 C1、C3、C7 加一，以此類推。當兩張影像具有相同色彩直方圖  (color 
histogram)，單純使用直方圖並無法表示空間結構，我們可以利用結構直方圖不同
來判別，但是，例如圖 4-5(a) 高結構性與圖 4-5(b) 右邊低結構性，在直方圖統
計下結果是一致，所以利用結構元素記錄空間性，藉此鑑別色彩在空間分佈。 
 
 
圖 4-4、色彩統計。 
高結構性
Structuring 
element
Pixel with image 
having colorm
低結構性
Structuring 
element
Pixel with image 
having colorm
 
 (a) (b) 
圖 4-5、色彩結構。 
 
2. 紋理特徵(texture feature)：MPEG-7 紋理特徵主要有三種描述子：(1) Homogeneous 
Texture、(2) Local Edge Histogram 和 (3) Texture Browsing Descriptors。Homogeneous 
Texture Descriptor 和 Local Edge Histogram Descriptor 則主要用於紋理檢索的應用
上，本研究在 MPEG-7 紋理特徵上只使用 Local Edge Histogram 描述子，並借重 
Tamura 紋理特徵，來補足紋理更細微的部分。 
28 
 
Edge direction
Image Sub-Image Image-block
(0,0) (0,1) (0,2) (0,3) 
(1,0) (1,1) (1,2) (1,3) 
(2,0) (2,1) (2,2) (2,3) 
(3,0) (3,1) (3,2) (3,3) 
 
圖 4-7、邊緣直方圖取樣模式。 
 
表 4-2、Local Edge Histogram Descriptor [35] 。 
 水平邊 垂直邊 135 度斜邊 45 度斜邊 無方向性邊 
視 
覺 
化      
濾 
波 
器     
其餘無方向
部分 
 
(3) Texture Browsing ：主要為紋理的  (1) 規律性  (regularity) 、 (2) 方向性 
(directionality) 及 (3) 粗糙度 (coarseness)。規律性以 2 位元 (bit) 記錄規律性，
範圍介於 0 至 3 ，數值越大代表越具有規律性。方向性量化為 6 個基本單位 
(bin)，每個基本單位為 30 度。粗糙度將粗糙等級分為 4 等分，範圍介於 0 至 
3，數值越大代表越有粗糙 [36]。 
 
3. 移動特徵 (motion feature)：在上節提到取樣只取 I 影格，而 I 影格並無運動像量，
因此必頇定義 I 影格所具有移動描述子。先前研究會在空間域進行移動向量估測，如
圖 4-7(a)，假設空間中一點 A，灰色的框線代表時間 t 時的位置，黑色框線表示時間 t+1 
時的位置。A 點對於兩框線中心 O  和 'O  的座標分別為  0 0,x y  和  1 1,x y ，移動
向量為  ,x yv v ，如圖 4-7 (b) 所示。 
30 
 
表 4-3、移動強度層級表。 
Activity Level Range of σ(Stand deviation of MV magnitude) 
1 0<=σ<3.9 
2 3.9<=σ< 
3 10.7<=σ< 
4 17.1<=σ< 
5 32<=σ 
 
(2) 行為方向：顧名思義，此特徵是指在單張影格中移動向量的主要方向。圖 4-9 中
可以看到巨區塊移動向量方向大多朝向右上方，所以我們可以記錄這張畫面行為
方向是右上方。我們在本研究中將 360 度角分為八大方向及一個靜止無方向共九
個量化基本單位，如圖 4-10 所示，而靜止無方向指的是畫面中巨區塊的移動向
量為零者。我們紀錄這八個方向中巨區塊數目前三多者當作行為方向特徵，以便
之後特徵的比對使用。 
 
 
圖 4-9、單張影格內 macroblock 移動向量圖。 
1
2
3
45
6
7
8
 
圖 4-10、移動向量方向分區圖。 
32 
 
4
1
4
4 









conf  
其中   表示影像的標準差， 4  表示影像的第四個量 (moment)。 
3. 方向性：方向性表示紋理圖元的形狀和分佈的規則，方向性紋理可有一個或多個可辨別
方向的圖元; 不具方向性紋理沒有可辨別方向的圖元。(fdir) 算式如下： 
   


p
p
n
p w
Dppdir Hnrf


2
1  
其中 HD 為局部方向直方圖，np 為 HD 的坡峰數， p  為 HD 的第 p 個正波峰，wp 為
第 p 個坡峰和坡谷間的範圍，r 為正規因子 (normalizing factor)，  為數值化的方向
編碼 (quantized direction code)。本研究的實驗設定值：HD＝16、正規因子=0~15 和 
r=0.025。 
4. 線性：線性只表示紋理的圖元形狀，線性紋理可能為直線或像波形的圖元沒有固定的類
型，通常線性紋理都具有相同的方向性。(flin) 算式如下。 
   
 
 






 n
i
n
j
Dd
n
i
n
j
Dd
lin
jiP
n
jijiP
f
,
2
cos,

 
其中  jiPDd ,  是指在 (i,j) 的位置，代入 nn  大小的局部方向共生矩陣，可得到一
個距離 d 的值。 
5. 規律性：規律性為紋理圖元分佈的變化，規律性紋理是由同樣或相似的圖元構成; 不規
律紋理由不同圖元構成。(freg) 算式如下。 
 lindirconcrsreg rf  1  
其中 r 正規因子 (normalizing factor)，   為 f  的標準差。本研究的實驗設定值：
r=0.25。 
6. 粗略性：粗略性表示物體表面的外形變化，粗略性紋理由有角圖像構成；平滑紋理由圓
形圖像構成。(frgh) 算式如下。 
concrsrgh fff   
 
34 
 
2. 層間連結：輸入層內的神經元彼此間沒有連結，但在輸入層與輸出層之間則有完全連
結，屬於激發型連結。 
3. 網路拓撲：拓撲中神經元的相對位置是具有意義的，通常神經元映射於一維或二維的
空間中，三維以上也可以。圖 5-1 中所示為二維矩形的網路拓撲的輸出層，形狀可分
成矩形圖 5-1(a)、三角形圖 5-1 (b)、圓形、甚至任意形狀圖 5-1(c)。 
4. 輸出層：表示網路輸出變數，即訓練樣本群集，神經元數目依應用而定。 
 
 
（a）矩形 （b）三角形 
 
（c）任意圖形 
圖 5-1、SOM 網路拓撲類型圖。 
x1 x2 x3 xp
wj1 wj2 wj3 wjp
yj
 
T
pxxxxx ,,, 321
 
T
jpjjjj wwwww ,,, 321
輸入層
輸出層
層間連結
網格拓撲
 
圖 5-2、自我組織映射圖架構。 
36 
 
Before training
After training
Winner node
j*
 
圖 5-3、學習訓練示意圖。 
5.2 索引映射圖 
我們為實現高效率和有效檢索因此必頇制定良好索引機制。在第 4.2 節取得影格描述
子向量，以描述子向量比較少的資訊代表此張影格，但是實際上如果利用這些描述子向量
進行檢索，計算量仍然太龐大，不符合實際檢索效益，因此我們利用自我組織映射圖將高
維特徵降到低維，並透過訓練跟分析對影格進行分類。上一節介紹自我組織映射圖訓練與
分類概念，本節將第 4.2 節所萃取色彩、紋理與移動特徵中每個描述子，利用自我組織映
射圖建立索引映射圖。索引圖當中在同一個節點 (winner node) 或是鄰近節點，表示在該
描述子特性當中，具有較高相似度，所以經由自我組織映射圖建立索引映射圖在離線先行
分類，首要的目的就是提高檢索效能。在第 4.2 節當中我們介紹有鑑別度的描述子，這些
描述子向量的集合也就幾乎代表著整張影像的重要資訊，將這些描述子向量代表此影格，
以下式表示： 
 ( ) ( ) 1,2,....,j jiD F i n   
其中 ( )jD  為描述子向量集合，j 為第幾個描述子， ( )jiF  表示在第 j 個描述子下視訊資料
庫第 i 張影格，而 n 表示視訊影格取樣數量。在自我組織映射圖索引架構圖下，第 j 個
描述子表示如下式： 
 ( ) ( ) 1,2,....,j jkM C k m   
其中 k 表示第幾個節點或稱為叢集，m 為此自我組織映射圖節點個數， ( )jkC  第 j 個描述
子第 k 個節點具有影格，目標是利用 ( )jD  訓練分類得到 ( )jM ，利用自我組織映射圖訓
練調整這些節點中心，演算法如下： 
 
38 
 
束影格相似度極高，將這些候選的起始影格與結束影格萃取出來，產生各段候選片段。但
根據實際視訊內容，一段片段長度有合理範圍長度，太短與太長都不符合檢索結果，在此，
設立另一個門檻值，去除長度超過合理範圍的候選片段。在這我們將查詢片段例子定義為： 
 1, 2,...,iQ f i t t t n      
其中  t  表示視訊資料庫絕對位置，為查詢範例  Q 長度，查詢範例  Q 起始影格 
1start t   結束影格 end t n  ， if  表示查詢片段第 i 張影格。影格所屬節點定義如下
式： 
(1) (2) ( j)( , ,..., )i i i if d d d  
其中 ( j)id  為第 i  影格在第 j  個描述子索引映射圖中所屬節點位置。透過候選片段投票
機制得到候選片段集合  1 2, ,..., nC v v v ， n  為集合內的片段數量，接下來介紹整個候選
片段整個演算法： 
 
演算法 5.2. 候選片段搜尋 
輸入：Q  查詢片段範例； ( )jD  視訊所有取樣影格描述子向量集合；
( )jM 視訊描述子 
像量集合建立自我組織映射索引圖。 
輸出：C 候選片段集合。 
 
步驟一：初始化直方圖陣列 (1: )H n ， ( )H i  記錄統計整段視訊影格 i  頻率與得到的 
票數。 
步驟二：以下列函式計算第 j 描述子索引圖計算候選起始影格於統計之方圖 ( )H i ： 
( ) ( ) ( ) ( )_ arg min ,j j j jstart k k
k
k start d C C M    
從索引架構圖 ( )jM 找到最近的所屬節點。得到將 ( )_
j
k startC  集合內的影格 i ，進
行統計 ( )  ( ) 1H i H i  。 
步驟三：假如 ( )H i 大於門檻值，門檻值設定選取特徵總數之一半並採取無條件進入 
法，則將此影格訂定為候選影格，得到候選起始影格陣列 { 2,8....}start iC f i  ，
並標記為候選起始影格 sF 。 
步驟四：尋找候選結束影格陣列 { 9,12....}end iC f i  ，並標記為候選起始影格 eF  (相 
似於步驟一至三)。 
40 
 
本研究利用自我組織映射圖，將高維特徵向量轉換成低維索引，減少鄰近相似影格搜
索時間複雜度，此外，候選片段搜索算法可避免大量計算所有影格，這些優勢可以有效地
縮短搜尋時間，然而，候選片段數量不少，本研究再利用動態時間校正進行比對 (matching) 
將相似度較高的片段，呈現給使用者。 
5.4 動態時間校正 
假設兩段視訊要做比較，必需將這兩段分別做特徵參數抽取進行比較，本研究利用動
態時間校正的特徵參數，為各描述子的向量參數，亦即變成兩個序列的特徵參數做比對，
目標在於要找出參數間最短距離進行比對。我們在第 5.4.1 節說明為何採用動態時間校正
並說明其定理；第 5.4.2 節針對視訊特性，加上限制與法則，減少比對資料量，並大幅降
低比對時間。 
5.4.1 動態時間校正定理 
我們檢索出的視訊片段長短不一，首先解決候選片段長度相異比對問題。一般來說，
比對兩筆長短不一資料最常用為時間規劃調整，作法為將兩組樣本  x 和  y 以
1 2 3 4 T( x ,x ,x ,x ,...,x )  及 1 2 3 4 T( y ,y ,y ,y ,...,y )  分別表示特徵參數向量，其中 ,x yT T  分別代表特
徵樣本 x 和 y 的時間長度，且 
ix  和 iy  是 x 和 y 的第 i 個時間特徵向量參數，現在
我們假設求 x 和 y 在時間點 
xi  和 yi  下的差異性，以  (   ,    )x yd i i  代表之，我們將整
體向量差異以  ( ,  )d x y  表示則可用下式： 
1
( , ) ( , )
x
x
T
x y
i
d x y d i i

  
如果我們採用時間規劃調整，雖然可以解決候選片段長度相異比對問題，但是使用此
方法，表示將兩筆資料呈現線性比例對照，但是實際上檢索出的視訊片段內容不會呈現線
性比例對照。因此，我們採用以時間規劃調整基礎延生的動態時間校正，我們將原本兩組 x 
和 y 樣本資料，改為調整函數 x   和 y ，如圖 5-5 兩個調整函數 x   和 y  正規化
調整後的結果，將兩段片段序列 ( ), 1,2,3,...,x xi k k T   和 ( ), 1,2,3,...,y yi k k T    的
時間點  xi  和 yi  正規化調整到總長度 T 的時間軸 k 上。 
 
 
42 
 
5.4.2 動態時間校準的限制與法則 
兩段視訊在動態時間校準步驟上，若在沒有任何限制的情況下 ( , ) min ( , )d x y d x y

 可
以取得最理想路徑，實際上如果查詢片段範例針對候選片段進行所有路徑比對，運算量將
非常龐大，也可能造成選擇路徑並無完整比對兩段資料所有的資訊，故根據視訊特性，採
用一些限制與法則減少計算量，加快比對效率。主要限制與法則有以下幾點： 
 
1. 端點限制：兩段視訊在比對時，如果要完整比對這兩段片段，必頇做端點限制，影格
一定是從 1 開始到時間 
xT 、 yT  結束，所以我們的調整函數 x   和 y  會有以下的
限制： 
起始點  ( 1 ) 1 , ( 1 ) 1x y     
結束點 ( ) , ( )x yT T T T     
上面的限制代表了影格的開始及結束時間的位置，如無限制，比對的路徑可能如圖 5-7 
路線，並無經過中空的起始點與結束點，只有比對兩段片段當中部份影格，為避免不
完整比對，限制開始及結束時間的位置，是在動態時間校準完整比對上最基本的限制。 
 
Tx
1
Ty
iy
ix
1
 
圖 5-7、無端點限制路徑示意圖。 
 
2. 單一性限制：這個限制主要是因為順序的問題，就是因為不管如何的調整，視訊內容
應該是往後或維持不變的，不會回到之前的，所以必頇將兩組調整函數 
x   和 y  進
行以下的限制: 
( 1) ( )x xk k   ， ( 1) ( )y yk k    
 
44 
 
 
根據端點限制、單一性限制與設定局部路徑法則，得到總路徑範圍如圖 5-10，灰色區域限
制內才會進行計算，比原本沒有設限制，藍色框線內區域所要計算的量大大減少。 
 
 ( ) 2 ( ) 1 1y xk k    
 ( ) 2 ( )y x x yk k T T    
( ) 1
( ) 1
2
x
y
k
k
 
  
( )
( )
2
x x
y y
k T
k T
 
  
(1,1)
(1, )yT ( , )x yT T
( ,1)xT
 
圖 5-10、局部路徑法則下二維總體路徑限制圖。 
46 
 
 
圖 6-2、系統介面顯示區。 
 
2. 選擇區：我們在第 4.2 節介紹色彩、紋理與移動等三種特徵共 16 個描述子。使用者
可以根據查詢片段選擇需要的描述子進行比對。 
 
 
圖 6-3、系統介面選擇區。 
 
3. 執行區：我們在執行部份分為七個按鈕。使用者透過移動捲軸、輸入秒數或影格數到所
指定影格點，按下 Set start frame 設定起始影格與 Set end frame 設定結束影格決定查
詢範例。使用者決定好查詢範例與在選擇區選定描述子後，按下 Query 按鈕將設定查
詢範例利用第 5.3 節投票機制產生候選片段。使用者按下 DTW 按鈕將候選片段利用
第 5.3 節動態時間校正進行候選片段相似度排名。使用者按下 Replay Query 按鈕可以
重複播放使用者設定的檢索範例片段。使用者按下 Top 10 clips 按鈕將 DTW 排序過後
片段，取出前 10 名，顯示前 10 名片段的起始影格、中間影格與結束影格，快速瀏覽
檢索結果。使用者按下 Reset 按鈕將先前檢索結果清除，以便重新檢索。 
 
48 
 
不相似的候選片段，縮短搜尋時間 (query time) 與比對時間 (DTW time)，也大量減少較不
相似的候選片段。 
表 6-1、票數門檻值比照表。 
 Query time (s) DTW time (s) Searched clips 
無門檻值 0.5150 7.2612 342 
有門檻值 0.3456 1.2845 49 
 
 
(a) 
 
(b) 
圖 6-6、票數門檻值比較之實驗結果。 
50 
 
 
(a) 
 
(b) 
圖 6-7、候選片段長度門檻值比較之實驗結果。 
 
表 6-2、候選片段長度門檻值比照表。 
 Query time (s) DTW time (s) Searched clips 
無門檻值 0.3918 3.7782 67 
有門檻值 0.3580 0.8351 22 
 
 
52 
 
 
圖 6-10、以移動特徵為主之檢索實驗結果。 
 
 
圖 6-11、以全部特徵之檢索實驗結果。 
 
54 
 
參考文獻 
 
[1] "Yahoo Video Search," http://search.yahoo.com. 
[2] "Google Video," http://video.google.com/. 
[3] J. Sivic and A. Zisserman, "Video Google: A text retrieval approach to object matching in 
videos," 2003, pp. 1470-1477. 
[4] "Youtube Video Search," http://www.youtube.com. 
[5] B. Yeo and B. Liu, "A unified approach to temporal segmentation of motion JPEG and 
MPEGcompressed video," 1995, pp. 81-88. 
[6] J. Lee and B. Dickinson, "Hierarchical video indexing and retrieval for subband-coded 
video," IEEE Transactions on Circuits and Systems for Video Technology, vol. 10, pp. 
824-829, 2000. 
[7] H. Zhang, C. Low, S. Smoliar, and J. Wu, "Video parsing, retrieval and browsing: an 
integrated and content-based solution," 1995, pp. 15-24. 
[8] O. Amft, M. Lauffer, S. Ossevoort, F. Macaluso, P. Lukowicz, and G. Troster, "Design of 
the QBIC wearable computing platform," 2004, pp. 398-410. 
[9] A. Hampapur, A. Gupta, B. Horowitz, C. Shu, C. Fuller, J. Bach, M. Gorkani, and R. Jain, 
"Virage video engine," 1997, p. 188. 
[10] A. Pentland, R. Picard, and S. Sclaroff, "Photobook: Content-based manipulation of image 
databases," International Journal of Computer Vision, vol. 18, pp. 233-254, 1996. 
[11] N. Van House, M. Butler, V. Ogle, and L. Schiff, "User-centered iterative design for digital 
libraries," D-lib Magazine, vol. 2, 1996. 
[12] J. Smith and S. Chang, "Querying by color regions using the VisualSEEk content-based 
visual query system," in Intelligent Multimedia Information Retrieval, 1997. 
[13] S. Chang, J. Smith, and J. Meng, "Efficient techniques for feature-based image/video access 
and manipulation," Proc. 33rd Ann. Clinic on Library Applications of Data Processing 
Image Access and Retrieval. 
[14] A. Lee, R. Hong, and M. Chang, "An approach to content-based video retrieval," 2004. 
[15] Y. Deng and B. Manjunath, "NeTra-V: Toward an object-based video representation," IEEE 
Transactions on Circuits and Systems for Video Technology, vol. 8, pp. 616-627, 1998. 
[16] W. Aref, A. Catlin, A. Elmagarmid, J. Fan, M. Hammad, I. Ilyas, M. Marzouk, S. Prabhakar, 
Y. Tu, and X. Zhu, "VDBMS: A testbed facility for research in video database 
benchmarking," Multimedia Systems, vol. 9, pp. 575-585, 2004. 
