 1
一、前言 
隨著國人安全意識提高及科技進步，監視系統已走向智慧化應用，現今的監視系統除了以手動
方式操控外，有效率地自動化監視，有其急迫性之需求，監視系統除要幫助人們不受空間限制外，
監視系統也必須主動即時進行入侵者監視，發現入侵者時並能自動進行追蹤，監視系統在未來將擔
任保全人員角色，執行監視入侵者和警告的任務。 
二、研究目的 
本研究目的主要發展一套影像監視系統，利用 PTZ網路攝影機來監視現場狀況，當入侵者侵入時
時，利用紅外線感測器環狀陣列偵測出入侵者位置，並立即以 PTZ進行入侵者影像追蹤，追蹤物體影
像時，本系統將依據物體影像之位置來控制 PTZ方位，讓物體影像持續於畫面中被追蹤。為了使遠端
使用者也能監控現場畫面，所研發之系統增加遠端監控功能。 
本研究所研製之系統分成入侵者搜索模組、移動物體影像偵測模組及物體影像追蹤模組，系統先
利用入侵者搜索模組與移動物體影像偵測模組進行入侵者追蹤初始化之設定參數擷取，然後物體影像
追蹤模組即時進行追蹤。入侵者搜索模組將八顆紅外線感測器安裝於八角型機構上，構成環型陣列，
以偵測是否有入侵者進入，並可判斷入侵者方位，模組並依據入侵者方位，控制伺服馬達轉動旋轉台，
讓旋轉台上之 PTZ攝影機對準入侵者。移動物體影像偵測模組估測出移動物體影像大小及位置，本研
究所採用之方法為連續影像相減法，偵測在畫面中移動物體影像，移動物體影像之位置及尺寸資訊做
為物體影像追蹤初始化之設定參數。物體追蹤模組進行入侵者追蹤，本研究利用Mean Shift追蹤法則，
為了確保移動物體影像能維持在畫面中，而不會脫離畫面，我們利用 Fuzzy 控制理論依據移動影像來
決定 PTZ旋轉方向及速度，為了達成即時控制，我們以離線方式，分析位置來建立出對應表，透過查
表方式來控制 PTZ攝影機轉動速度，使物體能保持在畫面中央位置。另外，本研究以資料庫溝通方式
完成遠端監控，讓使用者透過網路直接操控 PTZ攝影機旋轉，透過 PTZ網路攝影機來進行遠端監視。 
三、文獻探討 
影像處理的技術可追溯至 1970 年，國外學者 Leese，Novak 和 Taylor 等人[1]，利用影像灰階
值統計技術分析雲層的衛星照片資料，成功分離背景與物體。在影像監視系統中，最主要之目的是
進行物體的偵測與追蹤，利用移動物體偵測技術可偵測出畫面中是否有移動中之影像，因移動的物
體是畫面中最值得分析的部份，畫面背景依據攝影機的固定與否，分成靜態背景與動態背景，固定
式攝影機之下的移動物體偵測比較容易處理，方法很多，最簡單的為背景相減法[2][3]，首先擷取
會產生一張背景影像[4]，背景影像再與目前影像相減，進行二值化處理，就可得到前景影像，也就
是移動物體；如果背景會改變，可利用高斯混合 (Gaussian mixed model ,GMM)法動態求得每一像
素的背景模型[5][6]，以灰階影像為例，如果像素的灰階值不屬於背景模型，將被當成前景處理；
另外也可以利用差分影像法[7][8]，使欲追蹤的目標物與背景分離，以進行移動物體偵測，直接將
兩張時域上連續影像進行相減，如果相減結果為零，表示無移動物體，如果不為零，二值化處理後
可以得到移動物體；移動式攝影機則無法利用減法的方式來偵測前景，一般需要去算出因鏡頭移動
而產生的全域移動量[9]，再設法對畫面進行補償，而使背景類似靜態背景，便可利用背景相減移除
方法，由畫面中分離出物體，但此法計算量很大；有些研究就利用移動物體上的特徵，如形狀或色
彩資訊，進行比對[10][11]，亦可得到移動物體於畫面中之位置，但是，物體特徵如果不事先知道便
無法進行比對。 
一般偵測出來結果可以利用不同方式來呈現出，如點，特殊形狀或不規則形狀，當移動物體太
小，則利用點表示其中心位置即可[12][13]，如果物體是特殊形狀，如三角形、橢圓形、長方形，
這些形狀在畫面中的平移或旋轉[14][15]，均可利用座標轉換求得變形後之形狀，標示出移動物體；
當物體會變形時，如手或樹葉，則可利用主動式輪廓法圍繞物體外框[16][17]，其它標示方法還有
骨幹(Skeletal models)[18][19]與鉸接式的組合(Articulated shape models)[20][21]。 
 3
 
位置 感測器 編碼器數值
POS1 S8、S1、S2 0 
POS2 S1、S2 31250 
POS3 S1、S2、S3 62500 
POS4 S2、S3 93750 
POS5 S2、S3、S4 125000 
POS6 S3、S4 156250 
POS7 S3、S4、S5 187500 
POS8 S4、S5 218750 
POS9 S4、S5、S6 250000 
POS10 S5、S6 281250 
POS11 S5、S6、S7 312500 
POS12 S6、S7 343750 
POS13 S6、S7、S8 375000 
POS14 S7、S8 406250 
POS15 S7、S8、S1 437500 
POS16 S8、S1 468750  
(a)感測器位置 (b)感測區 (c)對應表 
Fig. 2 紅外線感測器陣列圖 
者方位，再控制伺服馬達旋轉帶動 PTZ網路攝影機旋轉到此方位，使攝影機面對入侵者。本研究使
用之紅外線感測器陣列如 Fig. 2(a)所示，將感測器依上方以順時鐘命名為 S1、S2、S3、S4、S5、S6、
S7及 S8。此紅外線感測器的感測距離為 5m，感測範圍 120度，如此一來我們可以畫出 Fig. 2(b)之
圖，可發現會有 16 組區域，我們將依上方以順時鐘命名為 POS1、POS2、POS3、POS4、POS5、
POS6、POS7、POS8、POS9、POS10、POS11、POS12、POS13、POS14、POS15 及 POS16。所採
用之伺服馬達旋轉一圈，編碼器數值為 500000，我們依先前定義的 16個位置來區分，每一個位置
相距為 31250，我們利用絕對位置值觀念來定義出絕對位置對應表，完整之對應表如 Fig. 2(c)所示。 
而我們帶動攝影機旋轉的方式，是將伺服馬達的軸心透過連軸裝置與我們 PTZ 網路攝影機底部
作固定，而伺服馬達固定於八角型平台下，所以伺服馬達做旋轉定位時，PTZ網路攝影機也會跟著
轉到定位，來朝向入侵物體，使我們可以立即掌握入侵者動態。 
4.2 移動物體影像偵測  
當系統偵測出入侵者，攝影機會轉向對準入侵者，此時利用影像擷取裝置，將攝影機類比型式
轉為數位形式且透過 USB 方式傳至電腦，電腦將取出連續三張影像作移動物體影像偵測，因物體
在畫面中如有移動，利用連續影像相減法的方式，即可偵測出物體影像的尺寸大小及位置，移動物
體影像之位置及尺寸資訊做為物體影像追蹤初始化之設定參數，並進行 PTZ攝影機之放大縮小控制，
以期讓移動物體影像可以完全在畫面中出現。 
系統進行物體影像追蹤時，物體接近或離開鏡頭，將導致物體影像於畫面中變化，影像過大或
過小均會影像追蹤效果，本系統每隔一段時間，會再進行一次移動物體影像偵測，進行初始化設定
及 PTZ攝影機放大縮小調整。 
4.3 物體追蹤 
在本系統物體追蹤的方法是使用了 Mean Shift演算法來達成物體影像之追蹤[30]。Mean Shift追
蹤法則是利用樣板色彩分佈密度進行比對，本影像追蹤執行過程如下： 
1. 設定追蹤起始位置 
在執行 Mean Shift演算法之前必須定義出一個起始位置，以供樣板比對之依據，在此我們
利用移動物體影像偵測後取得的中心位置，來當我們追蹤起始位置。 
2. 設定比對樣板大小 
 5
 
 
(a) 水平距離隸屬函數 
 
(b) 垂直距離隸屬函數 
Fig. 3 輸入隸屬函數 
 
(a) 左右轉動角速度大小隸屬函數 
 
(b) 傾斜角速度大小隸屬函數 
Fig. 4 輸出隸屬函數 
4.4.3模糊推論 
本研究模糊推論工廠採用最小推論工廠進行計算模糊集合，再利用重心解模糊法，可分別依據
不同之移動影像水平位置或垂直位置，決定 PTZ攝影機之左右轉動角速度或傾斜角速度，為了簡
化計算，事先利用模糊推論，求出每一可能位置之對應旋轉角度，建立 Decision Table。 
4.4.4離線型模糊控制 
電腦執行上，將建立好之 Decision Table存於記憶體中，影像追蹤時所得之移動影像位置，將成為
控制器之輸入，然後只需要經過查表方式，便能決定輸出角速度，此法可縮短電腦運算時間。  
4.5 網端監控系統端監控之介面 
為了達成遠端監控之目的，本研究部採取電腦對電腦之直接控制，而採取資料庫溝通之模式，
首先利用 Apache 建立伺服站，建立 MySQL 資料庫，以 PHP 撰寫網頁程式，以資料取得與修改，
當遠端要控制時，僅需於遠端上網，藉由改變MySQL資料庫內資料表之資料，控制 PTZ之電腦讀
取資料庫資料後，即可依據遠端下達之命令，控制攝影機鏡頭調整至適當位置。 
為完成上述目的，本研究在資料庫中建立一組資料表，資料表內建立有控制欄位，遠端可以透
過網路瀏覽器之按鈕，來更改控制欄位之控制代碼，控制 PTZ之電腦再透過 ODBC來取得 MySQL
 7
        
      (a)系統等待入侵者進入       (b)攝影機面對物體     (c)移動物體影像偵測結果 
Fig. 7 入侵者定位及移動物體影像偵測結果 
 
(a) 
 
(b) 
 
(c) 
 
(d) 
 
(e) 
 
(f) 
 
(g) 
 
(h) 
 
(i) 
Fig. 8 物體影像由右向左移動之追蹤 
首先測試入侵者進入感測區域時，鏡頭是否朝向入侵者，並估算出入侵者畫面尺寸。接著進行
追蹤測試，當入侵者影像，系統自動須轉動攝影機讓入侵者影像位於畫面中央位置。入侵者先在紅
色圈感測範圍外先行停留，此時畫面如 Fig. 7(a)。如有入侵者進到感測範圍內時，伺服馬達旋轉攝
影機成功地對準入侵者，如 Fig. 7(b)，轉到定位時，開始進行移動物體影像偵測，結果如 Fig. 7(c)
內之紅色框所示，系統成功偵測出移動物體影像。   
偵測出移動物體影像後，系統利用 Mean Shift 追蹤法則算出入侵者影像中心移動過後位置，而
根據物體移動後位置進行追蹤，在追蹤過程中物體會離開畫面，我們透過離線模糊控制方式來控制
攝影機水平轉動方向及速度，Mean Shift追蹤過程我們以紅色框表示移動影像範圍。 
 9
參考文獻 
[1] Leese, J. A., Novak, C. S., and Taylor, V. R. “The determination of cloud motion patterns from 
geosynchronous satellite image data,” Pattern Recognition, Clustering, Statistics, Grammars, 
Learning, Vol.2, pp. 272-292,1970. 
[2] R. Jain and H. Nagel, “On the accumulative difference pictures for the analysis of real world scene 
sequences,” IEEE Transactions on PAMI, 206-21. April 1979. 
[3] C. R. Wren, A. Azarbayejani, T. Darrell, A. Pentland, “Real-Time tracking of the human body”, 
IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol.19, No.7, pp.780-785, 1997.
[4] C. Eveland, K. Konolige, and R. Bolles, “Background modeling for segmentation of video-rate 
stereo sequences,” in Proceedings of the IEEE Computer Society Conference on Computer Vision 
and Pattern Recognition, 1998, pp. 266-271. 
[5] C. Stauffer and W. E. L. Grimson, “Learning patterns of activity using real-time tracking,” IEEE 
Transactions on Pattern Analysis and Machine Intelligence, Vol. 22, 2000, pp. 747-757. 
[6] D. Butler, S. Sridharan, and V. M. Bove, “Real-time adaptive background segmentation,” in 
Proceedings of IEEE International Conference on Acoustics, Speech, and Signal, 2003, pp. 
349-352. 
[7] A.J. Lipton, H. Fujiyoshi, and R.S. Patil, “Moving target classification and tracking from real-time 
video,” Fourth IEEE Workshop on Applications of Computer Vision, pp. 8-14, 1998. 
[8] C. Kim and J-N Hwang, “Fast and automatic video object segmentation and tracking for 
content-based applications,” IEEE transaction on circuits and systems for video technology, vol. 
12, Feb. 2002. 
[9] 鍾宜岑，應用於動態背景中的移物體影像之偵測與及時追蹤系統 國立交通大學電機學院IC
設計產業專班碩士論文，2007. 
[10] G. Paschos , “Perceptually uniform color spaces for color texture analysis: An empirical 
evaluation, ” IEEE Transactions on Image Processing, Vol. 10, No. 6, June 2001, pp. 932-937. 
[11] K. Y. Song, J. Kittler and M. Petrou, “Defect detection in random color textures,” Image and 
Vision Computing, Vol. 14, Issue 9, October 1996, pp. 667-683. 
[12] C. Veenman, M. Reinders, and E. Backer. “Resolving motion correspondence for densely moving 
points,” IEEE Transactions on Pattern Analysis and Machine Intelligence, pages 54–72, 2001. 
[13] D. Serby, E. Koller-Meier, and L. V. Gool. “ Probabilistic object tracking using multiple features, ” 
In IEEE International Conference on Pattern Recognition, 2004. 
[14] D. Comaniciu and P. Meer, “Kernel-based object tracking,” IEEE Trans. Pattern Anal. Machine 
Intell, vol. 25, no. 5, pp. 564–577, May 2003. 
[15] 吳添寶 以形狀資訊進行目標追蹤之影像伺服自走車 聖約翰技術學院自動化及機電整合研
究所碩士論文 
[16] Baumberg, A.M., and Hogg, D.C., “An efficient method for contour tracking using active shape 
models,” in IEEE Workshop , pp.194-199, Nov. 1994. 
[17] Andreas Koschan, Sang Kyu Kang, Joonki Paik, Besma Abidi, and Mongi Abidi, “Video object 
tracking based on extended active shape models with color information, ” Proceedings of the 1st 
European Conference on Color in Graphics, Imaging and Vision, Poitiers, France, 2002, 
pp.126131. 
[18] D. Ballard and C. Brown , 1982. Computer Vision Prentice-Hall 
[19] A. Ali and J.K. Aggarwal, “Segmentation and recognition of continuous human activity, ” in IEEE 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
本研究結果將於十一月初投稿於 2011 2nd World Congress on Computer Science and 
Information Engineering (CSIE 2011)，另外也會將結果整理，投稿於 SCI 期刊。 
 
 
 
 
