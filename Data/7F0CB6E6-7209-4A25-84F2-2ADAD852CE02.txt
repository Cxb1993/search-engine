issue. Bengio [7] proposed a sequence kernel-based 
decision function as follows: 
,)|(log)λ|(log)( 21Bengio bUpaUpaUL +Ω−=  (4) 
where a1, a2, and b are adjustable parameters 
estimated using SVM. The input to SVM is a two-
dimension vector TUpUp )]|(log-  )λ|([log Ω . An 
extended version of Eq. (4) using the Fisher kernel 
and the LR score-space kernel for SVM was 
investigated in [8]. The supervector kernel [6,9] is 
another kind of sequence kernel that is formed by 
concatenating the parameters of a GMM or 
maximum likelihood linear regression (MLLR) 
matrices. All the above-mentioned methods have to 
convert a variable-length utterance into a fixed-
dimension vector before a kernel function is 
computed. Since the fixed-dimension vector is 
formed independent of the kernel computation, this 
process is not optimal in terms of overall design. In 
this paper, we propose a new kernel, named the 
LLR-based sequence kernel, which attempts to 
compute the kernel function without representing 
utterances into fixed-dimension vectors in advance. 
Our goal is to integrate SVM-based methods with 
LLR-based speaker verification approaches by 
embedding an LLR in the sequence kernel.  
The remainder of the paper is organized as 
follows. Section II introduces the support vector 
machine. Section III describes the proposed LLR-
based sequence kernel. Section IV, contains the 
experimental results. Finally, in Section V, we 
present our conclusions. 
II. SUPPORT VECTOR MACHINE 
Kernel techniques [10] have been widely applied 
to pattern recognition and classification problems. 
Among the techniques, support vector machine 
(SVM) is the most prevalent method. The goal of 
SVM is to find a separating hyperplane that 
maximizes the margin between classes. Following 
[11], the decision function of SVM is expressed as 
bUUkyUL
J
j
jjj +∑= =1SVM ),()( α ,                         (5) 
where each training samples Uj, j = 1, 2,…, J, is 
labeled by either yj = 1 (the hypothesis H0) or yj = -1 
(the hypothesis H1); k(Uj ,U) is the kernel function. 
The coefficients αj and b can be solved by using the 
quadratic programming techniques [12]. Note that 
most αj are equal to zero, and training samples 
associated with non-zero αj are called support 
vectors. A few support vectors play a key role in 
deciding the optimal margin between classes in 
SVM.   
III. LLR-BASED SEQUENCE KERNELS 
A. Mercer Kernels 
The effectiveness of SVM depends crucially on 
how the kernel function k(⋅) is designed. A kernel 
function represents a certain measurement of 
similarities between samples in a mapped feature 
space. It must be symmetric, positive definite, and 
conform to Mercer’s condition [10]. There are a 
number of kernel functions [10] used in different 
applications. One special form of kernel, named 
sequence kernel, is represented by 
)(Φ)(Φ),( 2121 UUUUk
T= ,                         (6) 
where U1 and U2 are two sequences, and Φ(⋅) is a 
nonlinear function that implicitly maps each 
variable-length sequence into a fixed-dimension 
vector in feature space F. Such a kernel function is 
expressed by the inner product of two vectors Φ(U1) 
and Φ(U2). However, Φ(⋅) might be incomputable in 
most kernels since the dimension of F could be 
infinite. Under this circumstance, the choice of Φ(⋅) 
becomes tricky and far from optimal in terms of the 
overall design for the kernel function.  
In this work, we try to represent a sequence 
kernel as the inner product of two computable 
quantities instead of function Φ(⋅) that is usually 
incomputable. We define a new form of sequence 
kernel in accordance with the property of Mercer 
kernels [10] as 
)()(),( 2121 UfUfUUk ⋅= ,                       (7) 
where f(⋅) is any function that satisfies ℜ→Uf : . In 
this case, each variable-length sequence is converted 
into a real number rather than an implicit higher-
dimension vector. It is our hope to design a function 
f(⋅) that can reflect the speaker voice characteristics 
sessions at approximately one-month intervals, and 
each recording session consisted of 2 shots. In a 
shot, every speaker was prompted to utter 3 
sentences “0 1 2 3 4 5 6 7 8 9”, “5 0 6 9 2 8 1 3 7 4”, 
and “Joe took father’s green shoe bench out”. Each 
utterance, sampled at 32 kHz, was converted into a 
stream of 24-order feature vectors, each consisting 
of 12 mel-frequency cepstral coefficients (MFCCs) 
[15] and their first time derivatives, by a 32-ms 
Hamming-windowed frame with 10-ms shifts. 
We used 12 (2×2×3) utterances/client from 
sessions 1 and 2 to train the client model, 
represented by a GMM with 64 mixture components. 
For each client, the other 198 clients’ utterances 
from sessions 1 and 2 were used to generate the 
UBM, represented by a GMM with 256 mixture 
components; 50 closest speakers were chosen from 
these 198 clients as a cohort. Here, the degree of 
closeness is measured in terms of the pairwise 
distance defined in [1]:  
,
)λ|(
)λ|(
log
)λ|(
)λ|(log)λ,λ(
ij
jj
ji
ii
ji Up
Up
Up
Upd +=              (13) 
where λi and λj were speaker models trained using 
the i-th speaker’s utterances Ui and the j-th 
speaker’s utterances Uj, respectively. Then, we used 
6 utterances/client from session 3, along with 24 
(4×2×3) utterances/evaluation-impostor, which 
yielded 1,194 (6×199) client examples and 119,400 
(24×25×199) impostor examples, to estimate αj, b 
and θ. However, recognizing the fact that the kernel 
method can be intractable when a huge amount of 
training examples involves, we downsized the 
number of impostor examples from 119,400 to 
2,250 using a uniform random selection method. In 
the performance evaluation, we tested 6 
utterances/client in session 4 and 24 utterances/test-
impostor, which produced 1,194 (6×199) client 
trials and 329,544 (24×69×199) impostor trials.  
B. Experimental results 
We implemented three SVM systems using the 
individual LLR-based sequence kernel functions in 
the following:  
1) kUBM(U1 ,U2) in Eq. (11) (“UBMKernel”),  
2) kTnorm(U1 ,U2) in Eq. (12) with 50 closest 
cohort models   (“TnormKernel”), and  
3) kcom(U1 ,U2) in Eq. (10) (“Compositekernel”). 
For the purpose of performance comparison, we 
used three systems as our baselines: 
1)  LUBM(U) in Eq. (2) (“GMM-UBM”),  
2) LTnorm(U) in Eq. (3) with 50 closest cohort 
models (“Tnorm_50c”), and  
3) LBengio(U) in Eq. (4) using an RBF kernel 
function with σ = 10 (“GMM-UBM/SVM”). 
Fig. 1 shows the results of speaker verification 
evaluated on the “Test” subset in terms of DET 
curves [16]. From Fig. 1, we observe that 
“Compositekernel” obviously outperforms all the 
baseline systems. It can also been seen that the 
curve “UBMKernel” overlaps the curve “GMM-
UBM” while the curve “TnormKernel” overlaps the 
curve “Tnorm_50c”. We speculate that the SVM 
system with the kernel function represented by a 
single LLR, LUBM(U) or LTnorm(U), will degenerate 
to the prime LLR system, LUBM(U) or LTnorm(U), 
respectively. Table III summarizes the experimental 
results based on the minimum detection cost 
function (DCF) [17], defined as 
)1( TargetFaFaTargetMissMissDET PPCPPCC −××+××= ,   (14) 
where PMiss and PFa are the miss probability and the 
false-alarm probability, respectively; CMiss and CFa 
are the respective relative costs of the detection 
errors; and PTarget is the a priori probability of the 
target speaker. In our experiments, CMiss and CFa 
were both set to 1, and PTarget = 0.5. This special 
case of DCF is known as the half total error rate 
(HTER) [18]. From Table III, it is clear that 
“Compositekernel” achieves the best performance 
with a 3.85% relative improvement in terms of the 
minimum DCF for the “Test” subset, compared to 
“GMM-UBM/SVM”, which was the best result of 
the baseline systems. 
V. CONCLUSION 
In this paper, we have presented a new kernel, 
named the log-likelihood ratio (LLR)-based 
sequence kernel, for SVM-based speaker 
verification. The proposed sequence kernel can be 
computed without needing to represent the variable-
length speech into a fixed-dimensional vector in the 
sequence kernel in advance. This allows the state-
of-the-art LLR-based speaker verification 
Speaker Verification Using LR-based Composite Sequence Kernel for Improving 
the Characterization of the Alternative Hypothesis 
 
Yi-Hsiang Chao 
Department of Applied Geomatics 
Ching Yun University 
Taoyuan, Taiwan 
yschao@cyu.edu.tw 
 
 
Abstract—The likelihood ratio (LR)-based speaker verification 
is usually difficult to characterize the alternative hypothesis 
precisely. To better characterize the alternative hypothesis, we 
propose to incorporate two effective speaker verification 
approaches based on weighted geometric combination (WGC) 
and weighted arithmetic combination (WAC) into the support 
vector machine (SVM) via a new sequence kernel function, 
named the LR-based composite sequence kernel. This new 
kernel can be regarded as a unified framework for 
characterizing the alternative hypothesis by virtue of the 
complementary information that the WGC and WAC 
approaches can contribute. Our experiment results show that 
the proposed sequence kernel method outperforms the 
conventional speaker verification approaches. 
Keywords-likelihood ratio, speaker verification, sequence 
kernels, support vector machine 
I.  INTRODUCTION 
In essence, speaker verification is a statistical hypothesis 
testing problem that is commonly solved by using a 
likelihood ratio (LR) test [1]. Given an input utterance U, the 
goal is to determine whether or not U was spoken by the 
target (hypothesized) speaker. Consider the following two 
hypotheses: 
H0: U was spoken by the target speaker, 
H1: U was not spoken by the target speaker. 
The LR test can be expressed as 
⎩⎨
⎧
<
≥=
, )reject  ( accept   
                    accept   
  
)|(
)|()(
01
0
1
0
HH
H
HUp
HUpUL θ
θ
      (1) 
where ,1 ,0  ),|( =iHUp i  is the likelihood of hypothesis Hi 
gives the utterance U, and θ  is a decision threshold. H0 and 
H1 are called the null hypothesis and the alternative 
hypothesis, respectively. Mathematically, H0 and H1 can be 
characterized by some parametric models such as Gaussian 
mixture models (GMMs) [1, 2]. Though H0 can be modeled 
straightforwardly using speech utterances from the target 
speaker, H1 does not involve any specific speaker, and thus 
lacks explicit data for modeling. Many approaches that have 
been developed to characterize H1 can be collectively 
expressed in the following general form [2]: 
)),λ|( ),...,λ|(()|( 11 NUpUpHUp Ψ=              (2) 
where Ψ(⋅) represents a certain function of the likelihood 
values from a set of so-called background models {λ1, λ2,…, 
λN}. For example, Ψ(⋅) can be a maximum function [3], an 
arithmetic mean [1] or a geometric mean function [3]. The 
background model set can be obtained from N 
representative speakers, called a cohort [4], which simulates 
potential impostors. A special case arises when Ψ(⋅) is an 
identity function and N = 1, in which one single universal 
background model (UBM) is trained by pooling all the 
available data from a large number of background speakers. 
This is the so-called GMM-UBM method [2]. 
Obviously, a simple function for Ψ(⋅), such as the 
maximum, the arithmetic mean, or the geometric mean, is a 
heuristic that does not include an optimization process. Thus, 
the resulting system is far from optimal in terms of 
verification accuracy. A more effective and robust LR 
method can be obtained by characterizing H1 as a weighted 
geometric combination (WGC) [5] or a weighted arithmetic 
combination (WAC) [6] of the likelihood values of the 
background models. The WGC or WAC scheme not only 
quantifies the unequal nature of the background models by a 
set of weights optimized using the support vector machine 
(SVM) [7], but also converts each variable-length speech 
utterance into a fixed-dimension characteristic vector, which 
is easily processed by the sequence kernels [8]. 
In recent years, SVM is a well-known kernel technique 
that has been widely discussed and successfully applied to 
pattern recognition problems. SVM based on sequence 
kernels [8-11] is an appropriate way to handle variable-
length sequence data since it overcomes the limitation that 
the conventional SVM is awkward to handle the dynamic 
patterns like speech. However, constructing a proper 
sequence kernel tied in with speaker verification cleverly is 
still an issue. The WGC or WAC method translates the goal 
of solving an LR test problem into one of solving an SVM 
classifier with the inferable LR-based sequence kernel [5, 6]. 
Recognizing the fact that both WGC and WAC have similar 
powerful abilities to improve the characterization of the 
alternative hypothesis, we propose to integrate them into a 
new sequence kernel function, named the LR-based 
composite sequence kernel. This new kernel can be regarded 
as a unified framework for characterizing H1 by virtue of the 
complementary information that WGC and WAC can 
contribute.  
composite sequence kernel. We use the closure property of 
Mercer kernels [12] to form this kernel as 
),(),(),( WACWGCcom UUkUUkUUk jjj += .        (15) 
This composite kernel used for SVM in Eq. (10) is viewed as 
a unified framework for characterizing H1 by virtue of the 
complementary information that WGC and WAC can 
contribute. 
IV. EXPERIMENTS 
A. Experimental Setup 
Our speaker verification experiments were conducted on 
the speech data extracted from the XM2VTSDB multi-
modal database [13]. In accordance with “Configuration II” 
described in Table I [14], the database was divided into 
three subsets: “Training”, “Evaluation”, and “Test”. In our 
experiments, we used “Training” to build each target 
speaker’s model and the background models, and 
“Evaluation” to estimate the decision threshold θ of LR in 
Eq. (1), and the parameters αj and b of SVM in Eq. (10). 
The performance of speaker verification was then evaluated 
on the “Test” subset. 
TABLE I.  CONFIGURATION OF THE SPEECH DATABASE 
Session Shot 199 clients 25 impostors 69 impostors
1 1 2 
1 2 2 
Training 
1 3 2 Evaluation 
1 4 2 Test 
Evaluation Test 
 
As shown in Table I, a total of 293 speakers 1 in the 
database were divided into 199 clients (target speakers), 25 
“evaluation impostors”, and 69 “test impostors”. Each 
speaker participated in 4 recording sessions at 
approximately one-month intervals, and each recording 
session consisted of 2 shots. In a shot, every speaker was 
prompted to utter 3 sentences “0 1 2 3 4 5 6 7 8 9”, “5 0 6 9 
2 8 1 3 7 4”, and “Joe took father’s green shoe bench out”. 
Each utterance, sampled at 32 kHz, was converted into a 
stream of 24-order feature vectors, each consisting of 12 
mel-frequency cepstral coefficients (MFCCs) [15] and their 
first time derivatives, by a 32-ms Hamming-windowed 
frame with 10-ms shifts. 
We used 12 (2×2×3) utterances/client from sessions 1 
and 2 to train the client model, represented by a GMM with 
64 mixture components. For each client, the other 198 
clients’ utterances from sessions 1 and 2 were used to 
generate the UBM, represented by a GMM with 256 
mixture components; B closest speakers were chosen from 
                                                          
1  We discarded 2 speakers (ID numbers 313 and 342) because of 
partial data corruption. 
these 198 clients as a cohort. Here, the degree of closeness 
is measured in terms of the pairwise distance defined in [1]: 
,
)λ|(
)λ|(
log
)λ|(
)λ|(log)λ,λ(
ij
jj
ji
ii
ji Up
Up
Up
Upd +=        (16) 
where λi and λj were speaker models trained using the i-th 
speaker’s utterances Ui and the j-th speaker’s utterances Uj, 
respectively. Then, we used 6 utterances/client from session 
3, along with 24 (4×2×3) utterances/evaluation-impostor, 
which yielded 1,194 (6×199) client examples and 119,400 
(24×25×199) impostor examples, to estimate αj, b and θ. 
However, recognizing the fact that the kernel method can be 
intractable when a huge amount of training examples 
involves, we downsized the number of impostor examples 
from 119,400 to 2,250 using a uniform random selection 
method. In the performance evaluation, we tested 6 
utterances/client in session 4 and 24 utterances/test-impostor, 
which produced 1,194 (6×199) client trials and 329,544 
(24×69×199) impostor trials. 
B. Experimental Results 
We implemented three SVM systems using the 
individual LR-based sequence kernel functions in the 
following: 
1) kWGC(Uj ,U) in Eq. (13) (“WGC”),  
2) kWAC(Uj ,U) in Eq. (14) (“WAC”), and  
3) kcom(Uj ,U) in Eq. (15) (“WGC+WAC”). 
For the purpose of performance comparison, we also 
implemented three LR systems: 
1) The GMM-UBM system (“GMM-UBM”),  
2) The LR system using the arithmetic mean function 
for Ψ(⋅) in Eq. (2) (“Ari”), and  
3) The LR system using the geometric mean function 
for Ψ(⋅) in Eq. (2) (“Geo”). 
In our experiments, we used the B closest cohort models 
for “Ari” and “Geo”, and B+1 background models, 
consisting of the B closest cohort models and an UBM for 
“WGC”, “WAC” and “WGC+WAC”. B was empirically set 
to 20. Fig. 1 shows the results of speaker verification 
evaluated on the “Test” subset in terms of DET curves [16]. 
From Fig. 1, we observe that “WGC+WAC” not only 
outperforms all the LR systems, “GMM-UBM”, “Ari”, and 
“Geo”, it is also better than two individual SVM systems, 
“WGC” and “WAC”. Table II summarizes the experimental 
results based on the minimum detection cost function (DCF) 
[17], defined as 
)1( TargetFaFaTargetMissMissDET PPCPPCC −××+××= ,  (17) 
where PMiss and PFa are the miss probability and the false-
alarm probability, respectively; CMiss and CFa are the 
respective relative costs of the detection errors; and PTarget is 
the a priori probability of the target speaker. In our 
experiments, CMiss and CFa were both set to 1, and PTarget = 
0.5. This special case of DCF is known as the half total error 
 1
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                日期：100 年 5 月 25 日 
一、 參加會議經過 
本人於 2011 年 5 月 13 日中午搭乘長榮航空班機，經香港轉機，於晚間 6
點半左右抵達目的地 – 中國桂林。入境後隨即前往會場完成報到手續及取得
會議資料，當天晚上再轉往投宿的旅館下榻休息及準備接連二天的會議活動。 
 
The 2011 International Conference on Multimedia and Signal Processing 
(CMSP’11)為第一屆的國際會議，規模還不是很大，今年並與 The 2011 
International Conference on Network Computing and Information Security 
(NCIS’11)研討會一起合辦。這次 CMSP’11 共收到 528 篇來自 20 個國家的論
文投稿，最後只有 144 篇論文被接受，接受率(acceptance rate)只有 27%。
CMSP’11 會議含蓋的議題非常廣，包括了: 
 
計畫編號 NSC 99-2218-E-231-003 
計畫名稱 基於序列核心函數之支持向量機器於語者驗證之研究 
出國人員
姓名 趙怡翔 
服務機構
及職稱 
清雲科技大學應用空
間資訊系 助理教授 
會議時間 2011年 5月 14日至2011 年 5 月 15 日 會議地點 
中國 
桂林 
會議名稱 
(中文) 2011 年國際多媒體與訊號處理研討會 
(英文) The 2011 International Conference on Multimedia and 
Signal Processing (CMSP’11) 
發表論文
題目 
(中文) 語者驗證使用基於似然比例合成序列核心函數改良
替代假說描述之方法 
(英文) Speaker Verification Using LR-based Composite 
Sequence Kernel for Improving the Characterization of the 
Alternative Hypothesis 
 3
二、 與會心得 
本人所發表的論文：Speaker Verification Using LR-based Composite 
Sequence Kernel for Improving the Characterization of the Alternative Hypothesis
是於 5 月 14 日下午 4:30 的 Session : Image and Signal Processing II 中發表，由
於是屬於 poster session，可與參觀者互動交談，發表過程中有多位參觀者對本
論文充滿興趣，提出問題並與之討論，過程還算順利。除了發表論文外，本人
也充份利用時間參與其他與會的論文研討，獲益良多。以下為所參與裡面，令
我印象較深讓我想再更深入研究的會議論文： 
 
1. Improved boosting algorithm using combined weak classifiers  
Yuke Fang, Yan Fu, Chongjing Sun, Junlin Zhou  
2. A Fast SIFT Feature Matching Algorithm for Image Registration  
Kun Li, Shangbo Zhou  
3. Projection Kernel Regression for Image Registration and Fusion in Video-Based 
Criminal Investigatio  
Benyong Liu, Jing Zhang, Xiang Liao  
4. A multimodal Biometric Recognition of Touched Fingerprint and Finger-vein  
Young Ho Park, Dat Nguyen Tien, Hyeon Chang Lee, Kang Ryoung Park, Eui 
Chul Lee, Sung Min Kim, Ho Chul Kim  
5. Object recognition and selection method by gaze tracking and SURF algorithm  
Hwan Heo, Won Oh Lee, Ji Woo Lee, Kang Ryoung Park, Eui Chul Lee, 
Mincheol Whang  
6. A Modified Wiener Filtering Method for DT-CWT Domain Image Denoising  
Hongxia Wang, Bo Chen  
7. Speech signal representation via dictionary learning in STFT transformed 
domain  
Jing Xu, Benyong Liu, Xiang Liao  
8. A hybrid reliable Algorithm for Speaker Recognition based on improved DTW 
and VQ by Genetic Algorithm in noisy environment  
 5
速增長外，對於補助與鼓勵研究人員出席國際會議的策略也是促使其日益活躍
國際學術舞台的主要因素，對於此點我方宜加以重視。 
本人非常感謝國科會對於這次研討會的機票與論文註冊費的補助，讓我能
順利參加 2011 年國際多媒體與訊號處理研討會，獲益良多。 
五、 攜回資料名稱及內容 
1. Program and Abstracts 
2. Proceedings CD 
六、 其他(無) 
Speaker Verification Using LR-based Composite Sequence Kernel for Improving 
the Characterization of the Alternative Hypothesis 
 
Yi-Hsiang Chao 
Department of Applied Geomatics 
Ching Yun University 
Taoyuan, Taiwan 
yschao@cyu.edu.tw 
 
 
Abstract—The likelihood ratio (LR)-based speaker verification 
is usually difficult to characterize the alternative hypothesis 
precisely. To better characterize the alternative hypothesis, we 
propose to incorporate two effective speaker verification 
approaches based on weighted geometric combination (WGC) 
and weighted arithmetic combination (WAC) into the support 
vector machine (SVM) via a new sequence kernel function, 
named the LR-based composite sequence kernel. This new 
kernel can be regarded as a unified framework for 
characterizing the alternative hypothesis by virtue of the 
complementary information that the WGC and WAC 
approaches can contribute. Our experiment results show that 
the proposed sequence kernel method outperforms the 
conventional speaker verification approaches. 
Keywords-likelihood ratio, speaker verification, sequence 
kernels, support vector machine 
I.  INTRODUCTION 
In essence, speaker verification is a statistical hypothesis 
testing problem that is commonly solved by using a 
likelihood ratio (LR) test [1]. Given an input utterance U, the 
goal is to determine whether or not U was spoken by the 
target (hypothesized) speaker. Consider the following two 
hypotheses: 
H0: U was spoken by the target speaker, 
H1: U was not spoken by the target speaker. 
The LR test can be expressed as 
⎩⎨
⎧
<
≥=
, )reject  ( accept   
                    accept   
  
)|(
)|()(
01
0
1
0
HH
H
HUp
HUpUL θ
θ
      (1) 
where ,1 ,0  ),|( =iHUp i  is the likelihood of hypothesis Hi 
gives the utterance U, and θ  is a decision threshold. H0 and 
H1 are called the null hypothesis and the alternative 
hypothesis, respectively. Mathematically, H0 and H1 can be 
characterized by some parametric models such as Gaussian 
mixture models (GMMs) [1, 2]. Though H0 can be modeled 
straightforwardly using speech utterances from the target 
speaker, H1 does not involve any specific speaker, and thus 
lacks explicit data for modeling. Many approaches that have 
been developed to characterize H1 can be collectively 
expressed in the following general form [2]: 
)),λ|( ),...,λ|(()|( 11 NUpUpHUp Ψ=              (2) 
where Ψ(⋅) represents a certain function of the likelihood 
values from a set of so-called background models {λ1, λ2,…, 
λN}. For example, Ψ(⋅) can be a maximum function [3], an 
arithmetic mean [1] or a geometric mean function [3]. The 
background model set can be obtained from N 
representative speakers, called a cohort [4], which simulates 
potential impostors. A special case arises when Ψ(⋅) is an 
identity function and N = 1, in which one single universal 
background model (UBM) is trained by pooling all the 
available data from a large number of background speakers. 
This is the so-called GMM-UBM method [2]. 
Obviously, a simple function for Ψ(⋅), such as the 
maximum, the arithmetic mean, or the geometric mean, is a 
heuristic that does not include an optimization process. Thus, 
the resulting system is far from optimal in terms of 
verification accuracy. A more effective and robust LR 
method can be obtained by characterizing H1 as a weighted 
geometric combination (WGC) [5] or a weighted arithmetic 
combination (WAC) [6] of the likelihood values of the 
background models. The WGC or WAC scheme not only 
quantifies the unequal nature of the background models by a 
set of weights optimized using the support vector machine 
(SVM) [7], but also converts each variable-length speech 
utterance into a fixed-dimension characteristic vector, which 
is easily processed by the sequence kernels [8]. 
In recent years, SVM is a well-known kernel technique 
that has been widely discussed and successfully applied to 
pattern recognition problems. SVM based on sequence 
kernels [8-11] is an appropriate way to handle variable-
length sequence data since it overcomes the limitation that 
the conventional SVM is awkward to handle the dynamic 
patterns like speech. However, constructing a proper 
sequence kernel tied in with speaker verification cleverly is 
still an issue. The WGC or WAC method translates the goal 
of solving an LR test problem into one of solving an SVM 
classifier with the inferable LR-based sequence kernel [5, 6]. 
Recognizing the fact that both WGC and WAC have similar 
powerful abilities to improve the characterization of the 
alternative hypothesis, we propose to integrate them into a 
new sequence kernel function, named the LR-based 
composite sequence kernel. This new kernel can be regarded 
as a unified framework for characterizing H1 by virtue of the 
complementary information that WGC and WAC can 
contribute.  
composite sequence kernel. We use the closure property of 
Mercer kernels [12] to form this kernel as 
),(),(),( WACWGCcom UUkUUkUUk jjj += .        (15) 
This composite kernel used for SVM in Eq. (10) is viewed as 
a unified framework for characterizing H1 by virtue of the 
complementary information that WGC and WAC can 
contribute. 
IV. EXPERIMENTS 
A. Experimental Setup 
Our speaker verification experiments were conducted on 
the speech data extracted from the XM2VTSDB multi-
modal database [13]. In accordance with “Configuration II” 
described in Table I [14], the database was divided into 
three subsets: “Training”, “Evaluation”, and “Test”. In our 
experiments, we used “Training” to build each target 
speaker’s model and the background models, and 
“Evaluation” to estimate the decision threshold θ of LR in 
Eq. (1), and the parameters αj and b of SVM in Eq. (10). 
The performance of speaker verification was then evaluated 
on the “Test” subset. 
TABLE I.  CONFIGURATION OF THE SPEECH DATABASE 
Session Shot 199 clients 25 impostors 69 impostors
1 1 2 
1 2 2 
Training 
1 3 2 Evaluation 
1 4 2 Test 
Evaluation Test 
 
As shown in Table I, a total of 293 speakers 1 in the 
database were divided into 199 clients (target speakers), 25 
“evaluation impostors”, and 69 “test impostors”. Each 
speaker participated in 4 recording sessions at 
approximately one-month intervals, and each recording 
session consisted of 2 shots. In a shot, every speaker was 
prompted to utter 3 sentences “0 1 2 3 4 5 6 7 8 9”, “5 0 6 9 
2 8 1 3 7 4”, and “Joe took father’s green shoe bench out”. 
Each utterance, sampled at 32 kHz, was converted into a 
stream of 24-order feature vectors, each consisting of 12 
mel-frequency cepstral coefficients (MFCCs) [15] and their 
first time derivatives, by a 32-ms Hamming-windowed 
frame with 10-ms shifts. 
We used 12 (2×2×3) utterances/client from sessions 1 
and 2 to train the client model, represented by a GMM with 
64 mixture components. For each client, the other 198 
clients’ utterances from sessions 1 and 2 were used to 
generate the UBM, represented by a GMM with 256 
mixture components; B closest speakers were chosen from 
                                                          
1  We discarded 2 speakers (ID numbers 313 and 342) because of 
partial data corruption. 
these 198 clients as a cohort. Here, the degree of closeness 
is measured in terms of the pairwise distance defined in [1]: 
,
)λ|(
)λ|(
log
)λ|(
)λ|(log)λ,λ(
ij
jj
ji
ii
ji Up
Up
Up
Upd +=        (16) 
where λi and λj were speaker models trained using the i-th 
speaker’s utterances Ui and the j-th speaker’s utterances Uj, 
respectively. Then, we used 6 utterances/client from session 
3, along with 24 (4×2×3) utterances/evaluation-impostor, 
which yielded 1,194 (6×199) client examples and 119,400 
(24×25×199) impostor examples, to estimate αj, b and θ. 
However, recognizing the fact that the kernel method can be 
intractable when a huge amount of training examples 
involves, we downsized the number of impostor examples 
from 119,400 to 2,250 using a uniform random selection 
method. In the performance evaluation, we tested 6 
utterances/client in session 4 and 24 utterances/test-impostor, 
which produced 1,194 (6×199) client trials and 329,544 
(24×69×199) impostor trials. 
B. Experimental Results 
We implemented three SVM systems using the 
individual LR-based sequence kernel functions in the 
following: 
1) kWGC(Uj ,U) in Eq. (13) (“WGC”),  
2) kWAC(Uj ,U) in Eq. (14) (“WAC”), and  
3) kcom(Uj ,U) in Eq. (15) (“WGC+WAC”). 
For the purpose of performance comparison, we also 
implemented three LR systems: 
1) The GMM-UBM system (“GMM-UBM”),  
2) The LR system using the arithmetic mean function 
for Ψ(⋅) in Eq. (2) (“Ari”), and  
3) The LR system using the geometric mean function 
for Ψ(⋅) in Eq. (2) (“Geo”). 
In our experiments, we used the B closest cohort models 
for “Ari” and “Geo”, and B+1 background models, 
consisting of the B closest cohort models and an UBM for 
“WGC”, “WAC” and “WGC+WAC”. B was empirically set 
to 20. Fig. 1 shows the results of speaker verification 
evaluated on the “Test” subset in terms of DET curves [16]. 
From Fig. 1, we observe that “WGC+WAC” not only 
outperforms all the LR systems, “GMM-UBM”, “Ari”, and 
“Geo”, it is also better than two individual SVM systems, 
“WGC” and “WAC”. Table II summarizes the experimental 
results based on the minimum detection cost function (DCF) 
[17], defined as 
)1( TargetFaFaTargetMissMissDET PPCPPCC −××+××= ,  (17) 
where PMiss and PFa are the miss probability and the false-
alarm probability, respectively; CMiss and CFa are the 
respective relative costs of the detection errors; and PTarget is 
the a priori probability of the target speaker. In our 
experiments, CMiss and CFa were both set to 1, and PTarget = 
0.5. This special case of DCF is known as the half total error 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/26
國科會補助計畫
計畫名稱: 基於序列核心函數之支持向量機器於語者驗證之研究
計畫主持人: 趙怡翔
計畫編號: 99-2218-E-231-003- 學門領域: 自然語言處理與語音處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
