routing information from being dropped. To com-
bat the problem of topology instability in wireless
networks, a multi-path routing scheme was pro-
posed and investigated in [10]. The scheme allows
the sender to add extra overhead to each packet
that is to be transmitted over multiple paths. The
goal is to find the optimal way to fragment the
packet into smaller blocks and deliver them over
multiple paths. The focus of [9, 10] is on the prob-
lem of missing some of the messages but not mod-
ification of them.
In [11], an efficient information dispersal mech-
anism was developed to provide security, load bal-
ance, and fault tolerance for communication net-
works. The mechanism uses Reed-Solomon codes
to recover link faults and to provide security. In
this technique, all redundancy is sent along with
the information symbols, increasing transmission
overhead significantly.
Reed-Solomon codes were used in a similar way
for the key establishment of wireless sensor net-
works by Huang and Mehdi [12]. The technique
was proposed to combat Byzantine attacks on the
multi-hop paths. With the use of the (n, k) Reed-
Solomon codes, the proposed scheme is resilient to
t = (n−k)/2 faulty paths, which may drop or alter
the information sent through. Furthermore, the re-
ceiver can identify faulty paths as far as their num-
ber is not great than t. In this scheme, k(2t + 1)
symbols need to be transmitted, limiting its appli-
cations of Reed-Solomon codes for large k or t.
MDS codes have been used in the Automatic-
Repeat-reQuest (ARQ) protocols to reduce the
transmission overhead on communication sys-
tems [13, 14]. In [13], a family of MDS codes, Reed-
Solomon codes, was used in a type-II hybrid ARQ
protocol. In the first transmission, a relatively high
rate Reed-Solomon code with fewer redundancy is
used. When an additional transmission is needed,
only the redundant symbols are sent. With such
a technique, the overall code rate is reduced. This
scheme increases the system throughput by reduc-
ing the transmission overhead. In [14], punctured
MDS codes were used for the type-II hybrid ARQ
protocol and a modified version (with fewer decod-
ing operations) of the scheme proposed in [13] was
presented.
In this report, we address the problem of com-
promised sensors modifying and eavesdropping on
the secret information on such multi-hop paths.
We use the powerful Maximum Distance Separa-
ble (MDS) codes to develop a Just Enough Re-
dundancy Transmission (JERT) scheme to provide
protection for information delivery. In the JERT
scheme, the secret link key is encoded in (n, k) MDS
code and transmitted through multiple multi-hop
paths. To reduce the total information that needs
to be transmitted, the redundant symbols of the
MDS codes are transmitted only if the destination
fails to decode the secret. Since paths with differ-
ent hop-counts may be compromised with different
probabilities, we further differentiate the number of
symbols sent through these paths. One salient fea-
ture of the JERT scheme is its flexibility of trading
transmission for lower information disclosure. The
proposed technique is shown by analysis and sim-
ulation to be highly efficient and resilient against
node capture.
Then we extend our work to investigate the issue
of delivering secret link keys to each of the source’s
neighbors in wireless sensor networks. We propose
a scheme that tries to find a common bridge node
to deliver one key to each of the to-be-connected
neighbors. In the process, the source node broad-
casts the challenges based on Message Authentica-
tion Codes (MACs) of all keys stored on itself and
the to-be-connected neighbors.
In this report, we also propose a data forward-
ing scheme, termed Dynamic Energy-based Relay-
ing (DER) for Wireless Sensor Networks (WSNs).
In the DER scheme, all nodes try to forward their
data packets toward the nodes that are optimal dis-
tance closer to the data sink. They also take the
relaying node’s estimated lifetime into considera-
tion in the selection process. When necessary, they
will choose nodes that are closer to the data sink as
relays or even the data sink itself. This distributed
approach equalizes energy consumption of differ-
ent relaying nodes based on their residual energy,
balancing their expected lifetimes. We analyze our
proposed scheme in both one-dimensional and two-
dimensional networks with different setups includ-
ing different residual energy, traffic rate, and net-
work regions. Our study shows that the proposed
scheme achieves a network lifetime close to the
scheme based on linear programming techniques
and global information or centralized processing.
[13] M. B. Pursley and S. D. Sandberg,
“Incremental-redundancy transmission
for meteor-burst communications,” IEEE
Trans. on Communications, vol. 39, no. 5, pp.
689–702, May 1991.
[14] S. B. Wicker and M. J. Bartz, “Type-II hybrid-
ARQ protocols using punctured MDS codes,”
IEEE Trans. on Communications, vol. 42, no.
2/3/4, pp. 1431–1440, February/March/April
1994.
disclosed to the adversary and 2) the adversary can modify
or drop the information passing through.
In this work, we address the problem of compromised
sensors modifying and eavesdropping on the secret
information on such multihop paths. We use the powerful
Maximum-Distance Separable (MDS) codes to develop the
Just-Enough Redundancy Transmission (JERT) scheme to
provide protection for information delivery. In the
JERT scheme, the secret link key is encoded in ðn; kÞ
MDS code and transmitted through multiple multihop
paths. To reduce the total information that needs to be
transmitted, the redundant symbols of the MDS codes are
transmitted only if the destination fails to decode the secret.
Since paths with different hop counts may be compromised
with different probabilities, we further differentiate the
number of symbols sent through these paths. One salient
feature of the JERT scheme is its flexibility of trading
transmission for lower information disclosure. Our analysis
and simulation results show that the proposed technique is
highly efficient and resilient against node capture.
This paper is organized as follows: In Section 2, we
overview related work. The secret link key delivery
problem is formulated in Section 3. In Sections 4 and 5,
we present the JERT scheme and our analysis. The
performance evaluation results are provided in Section 6.
We summarize and conclude this work in Section 7.
2 RELATED WORK
Eschenauer and Gligor [1] proposed a random key estab-
lishment technique for WSNs. In this technique, each sensor
is preloaded a number of keys that are randomly selected
from a large key pool. After deployment, two neighbors can
establish a secure communication if they share a common
key. Otherwise, they need to exchange a secret key via a
multihop secure path. Chan et al. [2] extended the technique
into q-composite random key establishment technique,
which forces two neighbors to establish a secure commu-
nication only when they share q common keys, where q  2.
Based on [1], two similar random key predistribution
techniques that used multispace key pool to improve
network resilience and memory usage efficiency were
developed independently in [3] and [4].
A multipath key reinforcement technique was proposed
in [2] to enable two nodes to establish secure communica-
tion, even if they do not share enough common keys (with
the use of the q-composite technique). These two neighbors
first identify all secure paths between themselves. Then,
one node generates a set of random numbers (of the same
size) for all the paths and sends one number to the other
node through each of the paths. After the destination
receives all the numbers, it exclusive-ORs all of them to
obtain the secret link key. The multipath key reinforcement
scheme significantly improves the protection of the secret
link key from being disclosed to the adversary. This scheme
takes care of only information disclosure to the adversary
but not information modification. It fails if any of the paths
is compromised by the adversary and the number is
modified or dropped.
In [8] and [9], combinatorial set was used to distribute
keys to sensors prior to deployment. Such a deterministic
combinatorial set technique allows each key in the key pool
to be assigned to a constant number of sensor nodes.
Therefore, the number of nodes that each sensor shares a
common key is fixed.
A Secure Routing Protocol (SRP) was proposed in [10] to
send additional information to protect routing information
from being dropped. To combat the problem of topology
instability in wireless networks, a multipath routing scheme
was proposed and investigated in [11]. The scheme allows
the sender to add extra overhead to each packet that is to be
transmitted over multiple paths. The goal is to find the
optimal way of fragmenting the packet into smaller blocks
and delivering them over multiple paths. The focus of [10]
and [11] is on the problem of missing some of the messages
but not on the modification of them.
In [12], an efficient information dispersal mechanism was
developed to provide security, load balance, and fault
tolerance for communication networks. The mechanism
uses Reed-Solomon (RS) codes to recover link faults and to
provide security. In this technique, all redundancy is sent
along with the information symbols, increasing the trans-
mission overhead significantly.
RS codes were used in a similar way for the key
establishment of WSNs by Huang and Mehdi [13]. The
technique was proposed to combat Byzantine attacks on
the multihop paths. With the use of the ðn; kÞ RS codes,
the proposed scheme is resilient to t ¼ ðn kÞ=2 faulty
paths, which may drop or alter the information sent
through. Furthermore, the receiver can identify faulty
paths, as long as their number is not greater than t. In this
scheme, kð2tþ 1Þ symbols need to be transmitted, limiting
its applications of RS codes for large k or t.2 Compared with
[13], our scheme employs an efficient incremental informa-
tion transmission technique that lowers the expected overall
overhead significantly, and it can also be performed with
RS codes of large k or large t. Extra symbols are transmitted
only when they are necessary. We argue that with the
source and the destination being direct neighbors, the cost
of acknowledgment transmission is low. We further take
advantage of the fact that different paths have different
probabilities of being compromised or becoming faulty.
Therefore, different amounts of symbols are sent through
paths of different lengths in the JERT scheme.
MDS codes have been used in the Automatic-Repeat-
Request (ARQ) protocols to reduce the transmission over-
head on communication systems [16], [17]. In [16], RS codes
were used in a type-2 hybrid ARQ protocol. In the
first transmission, a relatively high rate RS code with fewer
redundancy is used. When an additional transmission is
needed, only the redundant symbols are sent. With such a
technique, the overall code rate is reduced. This scheme
increases the system throughput by reducing the
transmission overhead. In [17], punctured MDS codes were
used for the type-2 hybrid ARQ protocol, and a modified
178 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 5, NO. 3, JULY-SEPTEMBER 2008
2. The ðn; kÞ codes are used to share secrets among n users, any k of
which can recover the secret cooperatively. The Shamir scheme [14] is one
of such schemes. As pointed out in [15], an RS code may be treated as a
special ðn; kÞ secret-sharing scheme with tamper-resistant capability,
because it can correct errors. Also pointed out in the same work, the
complexity of the decoding algorithm of the RS code is similar to that of the
Shamir scheme.
. pðJERT Þx and p
ðSP Þ
x : the secret disclosure probabilities
of the JERT scheme and the SP scheme, respectively.
. ðJERT Þ and ðSP Þ: the expected numbers of trans-
mitted symbols of the JERT scheme and the
SP scheme, respectively.
4.2 Maximum-Distance Separable Codes
We first review the MDS codes [16], [17] that will be used
in the JERT scheme. Let the Hamming distance between
two vectors (code words) be the number of distinct
positions between two vectors. An ðn; k; dminÞ MDS code
is a linear block code whose minimum Hamming distance
dmin between any pair of distinct code words must satisfy
dmin ¼ n kþ 1, where n is the code length, and k is the
dimension of the code. Therefore, each code word in the
ðn; k; n kþ 1Þ MDS code has exactly n symbols, among
which there are k information symbols. Usually, the extra
n k symbols are called parity checks or the redundancy of
the code. Furthermore, an ðn; k; n kþ 1Þ MDS code will
be able to recover any v errors if
v  n k
2
 
:
MDS codes are optimal in the sense that they provide the
largest possible minimum Hamming distance between code
words and hence can correct the most number of errors. The
most famous family of MDS codes are RS codes. Efficient
decoding algorithms for MDS codes have been studied
extensively in [19] and [20]. In the following, we give a brief
description of the encoder and the decoder of RS codes.
Let GF ð2 Þ be the finite field of order 2 such that each
element in GF ð2 Þ can be represented by  bits. An ðn; kÞ
RS code is a linear code, where each symbol is in GF ð2 Þ,
with the following parameters:
n ¼ 2  1;
and
n k ¼ 2t;
where n is the total number of symbols in a code word,
k is the total number of information symbols, and t is
the symbol-error-correcting capability of the code. Let
the sequence of k information symbols in GF ð2 Þ be
m ¼ ðm0;m1; . . . ;mk1Þ and let mðxÞ be the information
polynomial of m represented as
mðxÞ ¼ m0 þm1xþ    þmk1xk1:
The code word polynomial cðxÞ corresponding to mðxÞ can
be encoded as
cðxÞ ¼ mðxÞgðxÞ;
where gðxÞ is a generator polynomial of the RS code. It is
well known that gðxÞ can be obtained as
gðxÞ ¼ ðxþ Þðxþ 2Þ    ðxþ 2tÞ
¼ g0 þ g1xþ g2x2 þ    þ g2tx2t;
ð1Þ
where  is a primitive element in GF ð2 Þ, and gi 2 GF ð2 Þ.
Note that gðxÞ has ; 2; . . . ; 2t as roots.
Another way of encoding cðxÞ is to use polynomial
division as
cðxÞ ¼ x2tmðxÞ þ pðxÞ;
where
pðxÞ ¼ x2tmðxÞmod gðxÞ:
Since each symbol is represented by  bits, an ðn; kÞ
RS code can be expanded to a ðn; kÞ binary linear block
code. For example, a (1,023,255) RS code with 384 symbol-
error-correcting capabilities is of 10 255 ¼ 2;550 informa-
tion bits. The computational cost of the encoder is roughly
kðn kÞ additions and kðn kÞ multiplications.3
The decoding processes of RS codes are more
complex. Let rðxÞ be the received polynomial and let
rðxÞ ¼ cðxÞ þ eðxÞ, where eðxÞ ¼ Pn1
j¼0
ejx
j is the error poly-
nomial. Since gðxÞ (and, hence, cðxÞ) has ; 2; . . . ; 2t as
roots, the syndromes Si can be calculated as
Si ¼ rðiÞ ¼ eðiÞ ¼
Xn1
j¼0
ej
ij for i ¼ 1; . . . ; 2t: ð2Þ
Assume that v  t errors occur in unknown locations
j1; j2; . . . ; jv of the received polynomial. Then
eðxÞ ¼ ej1xj1 þ ej2xj2 þ    þ ejvxjv ;
where ej‘ is the value of the ‘th error, ‘ ¼ 1;    ; v. The
decoding process finds all j‘ and ej‘ . Instead of solving
the set of the above 2t syndrome equations, an intermediate
polynomial, called the error-locator polynomial, is
introduced as
ðxÞ ¼
Yv
‘¼1
ð1 xj‘Þ ¼ 1þ 1xþ    þ vxv:
The coefficients of the error-locator polynomial can be
determined by the Berlekamp-Massy algorithm or
euclidean algorithm that are of time complexity Oðt2Þ [19],
[20], [21]. Once all coefficients of the error-locator poly-
nomial are found, j‘ can be determined by successive
substitution through the Chien search [21]. Finally, ej‘ can
be calculated by the Forney formula [21].
Each of the RS decoding processes can be implemented
in either hardware or software. Hardware implementations
with moderate/high speed but small/large hardware have
been proposed [19], [20], [21]. Software implementation of
the RS decoding process can be programmed on a general-
purpose processor [21]. The first step in the decoding of
an RS code is to compute the 2t syndromes. Combining
with the Horner rule, this step requires ðn 1Þt additions
and nt multiplications. Finding the coefficients of the
error-locator polynomial requires roughly 2t2 additions
and 2t2 multiplications. In the worst case, the Chien search
needs to substitute n field elements into the error-location
polynomial of degree t to determine its roots. This requires
180 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 5, NO. 3, JULY-SEPTEMBER 2008
3. Addition and multiplication are performed on GF ð2 Þ, which can be
implemented by a table lookup method.
path j for 1  j  m. If qjri is not an integer, a
round-off value will be used instead.
3. Assume that the destination receives all symbols from
them paths as yi ¼ ðyb; ybþ1; . . . ; ysÞ.6 The destination
appends yi to all the previously received symbols to
form a longer code word. Then, it tries decoding this
code word in order to obtain the k symbols. If the
decode process fails due tomore than i errors, then go
to step 4 directly; otherwise, it verifies this result with
the source through the challenge-response technique
(recall that the source and the destination are direct
physical neighbors). If the regenerated secret link key
is verified, the transmission of the secret link key has
succeeded; otherwise, go to step 4.
4. If i ¼ e, then the key establishment fails due to
too many compromised paths. Otherwise, the
destination asks for another round of additional
transmission.
5. The source sets i ¼ iþ 1, b ¼ sþ 1, and s ¼ sþ ri
and repeats step 2.
Therefore, compared with [16] and [17], which have only
one additional transmission, the JERT scheme sends multi-
ple retransmissions when necessary.
Note that the JERT scheme does not need to know the
identification of the compromised paths to decode the
secret successfully. The MDS decoder at the receiver will
automatically correct any modification by the compromised
nodes in these paths and request for additional transmis-
sion when necessary.
4.4 Multihop Paths
Before we present our analysis of the JERT scheme, we
discuss the path selection process and its effect on the
performance of the JERT scheme. In this work, we assume
that a source node identifies m multihop paths between
itself and the destination. Such m paths could be chosen
from the node-disjoint paths, in which none of the multihop
paths shares any common node other than the source and
the destination [23], [24], [25]. Another option is to allow the
source node to randomly select among all available paths.
The result is that some paths may have common nodes, and
thus, the security performance worsens. The benefit of such
a selection technique is that it does not rely on the
availability of node-disjoint multihop paths and eliminates
the cost of identifying such paths.7
As suggested by Chan et al. [2], it is always beneficial to
choose short multihop paths instead of long multihop
paths. As the length of a multihop path increases, the
possibility of path compromise is higher. As we limit
ourselves to short multihop paths, however, the number of
available paths may be limited. We evaluate the values of
m under various network conditions and the effect of such
m paths on the security performance of our scheme in
Section 6. The proposed JERT scheme works with any set of
multihop paths and node-disjoint multihop paths.
5 ANALYSIS
In this section, we derive formulas for the fractions of
symbols to be transmitted through each path qj, 1  j  m,
and the number of additional symbols to be transmitted in
each round ri, 0  i  e, for the JERT scheme. We will also
investigate three performance aspects of the JERT scheme
and the SP scheme, which sends the secret link key through
a single multihop path: secret information disclosure,
transmission overhead, and computation overhead.
5.1 Selection of q1; q2; . . . ; qm
Due to the lack of the knowledge of which paths may be
compromised, the source node has the best option of
making sure that the expected number of symbols
compromised on each path is more or less the same.
Let hj be the hop count of path j, 1  j  m, and x the
probability of nodes being compromised. Then, the prob-
ability that path j is compromised, given that the source
and the destination are not compromised,8 is
Pr½at least one router in between is compromisedj
the source and the destination are not compromised
¼ Pr½at least one router in between is compromised
¼ 1 Pr½none of the routers is compromised
¼ 1 ð1 xÞhj1;
where 1  j  m.
The expected number of symbols being compromised for
path j is
qj  ½1 ð1 xÞhj1;
and the source node needs to make sure that
qj  ½1 ð1 xÞhj1 ¼ C; for all j: ð4Þ
Since
Pm
j¼1 qj ¼ 1, the constant C should satisfy
C ¼ 1Pm
i¼1
1
1ð1xÞhi1
:
When x is small, 1 ð1 xÞhj1 may be approximated as
1 ð1 xÞhj1  1 ½1 ðhj  1Þx ¼ ðhj  1Þx:
Therefore, C becomes
C  xPm
i¼1
1
hi1
;
and we have
qj  Cðhj  1Þx ¼
1
hj1Pm
i¼1
1
hi1
: ð5Þ
Thus, we have derived a closed form for qj, 1  j  m,
that is unrelated to x when x	 1.
182 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 5, NO. 3, JULY-SEPTEMBER 2008
6. The source can notify the destination regarding the number of
transmitted symbols over plaintext (recall that the source and the
destination nodes are direct physical neighbors). Therefore, the event of
symbols being dropped is similar to that of symbols being modified along
the multihop paths.
7. The procedure of establishing such secure paths is out of the scope of
this paper. See [23], [24], and [25] for more details.
8. A compromised source or destination makes the key exchange
meaningless.
Section 6. Since all found paths are node disjoint and
m ¼ s2 þ    þ sL, the total number of routers is
nT ¼
XL
i¼2
ði 1Þsi: ð14Þ
We denote Bxc as the event that xc out of the nT routers
are compromised. Based on an independent compromised
probability x, the probability of event Bxc taking place is
PrðBxcÞ ¼
nT
xc
 
xxcð1 xÞnTxc : ð15Þ
Let Amx be the event that mx among the m available
paths are compromised by the adversary.9 Next, we
evaluate Pr½Amx jBxc \ S. Let Dn2;...;nL be the event that the
mx compromised paths contain n2 paths among the s2 paths
with length 2; . . . and the nL paths among the sL paths
with length L. When xc < mx, Pr½Amx jBxc \ S is zero, since
it is impossible to have more compromised paths than
compromised sensors when all paths are node disjoint.
When xc  mx,
Pr½Amx jBxc \ S
¼
X
n2þn3þþnL¼mx
YL
i¼2
si
ni
 
Pr½Dn2;...;nL jBxc \ S; ð16Þ
where 0  ni  si for 2  i  L.
Now, we need to derive Pr½Dn2;...;nL jBxc \ S. Assume that
nj1 ; nj2 ; . . . ; njg , 0  g  L 1 are the nonzero terms of
n2; . . . ; nL. Therefore, there are nj1 paths of length j1
compromised, nj2 paths of length j2 compromised,
. . . ; njg paths of length jg compromised. Then, we need to
consider all possibilities to select xc compromised nodes
from xn ¼
Pg
i¼1 njiðji  1Þ nodes on the mx compromised
paths. Since all these mx paths are compromised, at least
one node on each path must be compromised. Hence,
Pr½Dn2;...;nL jBxc \ S
¼
P
y1;1þþy1;nj1þy2;1þþy2;nj2
þ
þyg;1þþyg;njg ¼xc
Qg
i¼1
Qnji
‘¼1
ji1
yi;‘
 	
nT
xcð Þ ; if xn  xc;
0; otherwise;
8>>><
>>>:
ð17Þ
where 1  yi;‘  ji  1 for 1  i  g.
We now derive the secret disclosure probability px, which is
defined as the probability of disclosing enough symbols to
the adversary so that it can obtain the key with relative ease
when the node-compromised probability is x.
In the SP scheme, the  symbols are transmitted through
one randomly chosen path among the m available paths. If
the SP scheme selects a compromised path to transmit, then
all  symbols are revealed. Hence, when there are mx
compromised paths, the secret disclosure probability is
mx=m. The overall secret disclosure probability can be
calculated as
pðSP Þx ¼
X
S
Pr½Ps2;s3;...;sL 
XnT
xc¼1
nT
xc
 
xxc

(
ð1 xÞnTxc
Xm
mx¼1
Pr½Amx jBxc \ S
mx
m
 	#)
;
ð18Þ
where nT is given by (14).
When the JERT scheme is used, the source transmits only
r0 ¼ k symbols, and the destination gets all of these symbols
successfully, because no information is modified. Such
k symbols are transmitted through the m paths with
qj fraction for path j, 1  j  m, where qj is given by (5).
For fair comparison between the JERT scheme and the
SP scheme, we define the secret disclosure probability of the
JERT scheme as the probability of at least k symbols being
disclosed to the adversary, where 0 <   1. Therefore, the
secret disclosure probability can be calculated as
pðJERT Þx ¼
X
S
Pr½Ps2;s3;...;sL 
XnT
xc¼1
nT
xc
 
xxcð1 xÞnTxc
(
Xm
mx¼1
Pr½Amx \ EjBxc \ S
" #)
;
ð19Þ
where E is the event that the fraction of symbols
transmitted through the compromised paths are greater
than or equal to  and is given by
PL
i¼2
niqi
PL
i¼2
siqi
¼
PL
i¼2
ni
i1
PL
i¼2
si
i1
 : ð20Þ
Pr½Amx \ EjBxc \ S is given as
Pr½Amx \ EjBxc \ S
¼
X
n2þn3þþnL¼mx
E
YL
i¼2
si
ni
 
Pr½ðAmx \Dn2;...;nL jBxc \ S; ð21Þ
where 0  ni  si for 2  i  L. Note the additional condi-
tion of E in (21) compared to (16).
The value of  depends largely on how the  symbols
of the secret link key information are encoded into the
k symbols. Therefore, it depends on the selection of
function f in the scheme.
5.4 Transmission Overhead
In this section, we reuse some of the analysis in Section 5.3
to evaluate the transmission overhead (cost) of the JERT and
the SP schemes. We assume that all compromised nodes
modify the symbols passing through in our analysis in
this section.
For the SP scheme, only the mxm term in (18) needs to be
modified in order to derive the transmission overhead.
When there are mx out of m paths that are compromised,
the chance of successful transmission in the first round
is mmxm . The chance of successful transmission in the
second round is mmxm1  mxm (recall that the sender randomly
184 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 5, NO. 3, JULY-SEPTEMBER 2008
9. We use a different variable from e in order to distinguish the
two different kinds of compromises: information modification and
information disclosure.
6 PERFORMANCE EVALUATION
Simulations have been performed in Matlab to evaluate the
efficiency of the proposed scheme. Unless specified other-
wise, our simulations were set up with the following
parameters: We randomly place N ¼ 400 nodes on a square
area of 1,000 m by 1,000 m. The radio transceiver range is
100 m. The MDS code is assumed to be ðn; kÞ ¼ ð1;023;255Þ.
We investigate the performance of the JERT scheme
and other related schemes. These schemes include the
Incremental Redundancy Transmission (IRT) scheme,10 the
SP scheme, the H-M scheme proposed by Huang and
Mehdi [13], and the scheme proposed by Chan et al. [2]. In
our discussions, we vary  for the SP scheme instead of
changing ðn; kÞ for the JERT scheme.
6.1 Path Availabilities
In Fig. 3, we demonstrate the need for multihop paths to
connect two physical neighbors. In this figure, we present
the probability of connecting two physical neighbors ps
with up to one-hop, two-hop, three-hop, and four-hop
paths for increasing the local connectivity plocal. When we
only include one-hop paths, ps ¼ plocal. As we include paths
with more hops, the connectivity probability increases and
approaches 1 when plocal increases. For example, when
plocal ¼ 0:5, up to two-hop paths can connect about
80 percent of the physical neighbors. However, we can
connect about 97 percent and 99 percent of the physical
neighbors when we use up to three-hop and four-hop paths,
respectively.
In Fig. 4, we show the number of paths with secure
connections that are exactly h hops from a source to a
destination (assuming that they do not share a common
key). The average number of paths is presented, corre-
sponding to various plocal. We also present the number of
paths for a similar network with half the nodes ðN ¼ 200Þ
for comparison purposes. As shown in Fig. 4, the number of
available paths increases with the local connectivity plocal.
When the node density increases, there are more paths as
well. The number of h-hop paths also increases with h. Note
that these paths may have common nodes other than the
source and the destination.
We show the number of node-disjoint paths in Fig. 5.
Note that we chose two-hop paths first and then eliminated
all other paths with nodes that have appeared in the
previously counted paths. The total available node-disjoint
paths are rather limited, as shown in Fig. 5. One interesting
observation based on Fig. 5 is that the number of exactly
h-hop node-disjoint paths decreases as h increases after 3.
This could be due to our path selection process and the
larger number of nodes needed in h-hop node-disjoint paths
in the neighborhood of the source and the destination when
h is larger.
186 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 5, NO. 3, JULY-SEPTEMBER 2008
10. The IRT scheme is an early version of the JERT scheme [29]. The
IRT scheme uses all two-hop and three-hop paths, including those with
common routers. Another major difference between the IRT and the
JERT schemes is that the JERT scheme sends different fractions of symbols
through different paths, whereas the IRT scheme always sends qj ¼ 1=m for
all available paths.
Fig. 3. Probability of finding secure paths between two physical
neighbors with up to one-hop, two-hop, three-hop, and four-hop paths.
Fig. 4. Number of paths with exactly h hops between the source and the
destination.
Fig. 5. Number of node-disjoint paths with exactly h hops between the
source and the destination.
Chan et al. [2]. In this scheme, a reinforcement technique is
used to make sure that the adversary needs to compromise
all paths in order to obtain the key. For fair comparison,
the extra symbol transmission of the scheme is calculated
based on sending keys through eþ 1 paths. Note that JERT
performs additional transmission when it is necessary such
that the computational cost of JERT depends on the number
of compromised paths between the source and the destina-
tion. In this figure, the extra computational cost of JERT has
been converted to equivalent extra symbol transmissions
and added to the results (see (27)). According to this figure,
the extra symbol transmission of the JERT scheme is much
smaller than that of the scheme given in [2].
6.3 Security Performance
The flexibility of the secret-disclosure probability of the
JERT scheme is presented in Fig. 10. In this figure,we vary the
value of  and show the secret-disclosure probability px for
different node-compromised probabilities x. It can be
observed that the JERT scheme has a much lower px
than the SP scheme when  < 1. As  increases within the
range between 0 and 1, the px value is smaller. For a fixed , 
may be lowered by increasing k and n. Therefore, the
JERT scheme provides a nice property of flexibility: a
predefined threshold of the probability of secret key
disclosure can be guaranteed by varying ðn; kÞ. The numer-
ical results of (18) and (19) are compared with the simulation
results in Fig. 10 as well. The numerical results (curves)
match with the simulation results (symbols) quite well.
We present the secret disclosure probability from
another angle in Fig. 11, where we show px as a function
of  for different x. The stepped curves shown in Fig. 11
suggest that px has some abrupt changes when  varies.
This is because each path sends an integer number of
symbols, and when one path is compromised, all these
symbols are disclosed. Thus, the ratio of disclosed symbols
is not continuous when  varies. When this value is
compared with a secret ratio, step functions may appear.
In Fig. 12, we compare the expected number of
transmitted symbols in the JERT scheme, the IRT scheme,
and another related scheme termed JERTe. The
JERTe scheme is similar to the JERT scheme, except
that qj ¼ 1=m for all paths. The performance of the
JERTe scheme is presented to show the effectiveness of
the technique of sending different amounts of symbols to
paths of different lengths. Based on Fig. 12, we conclude
that the JERT scheme outperforms the IRT and JERTe
schemes with much lower transmission cost. We can further
conclude that the selection of qj has major effects on
transmission overhead in the JERT scheme.
We present the secret-disclosure probability of the JERT,
IRT, and JERTe schemes in Fig. 13. In order to distinguish the
performance of different schemes, we artificially increased 
to 128 and 192. Such values of  result in higher secret-
disclosure probabilities. Based on Fig. 13, it can be concluded
that the JERT scheme outperforms the IRT and
JERTe schemes with lower secret-disclosure probability.
188 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 5, NO. 3, JULY-SEPTEMBER 2008
Fig. 10. The flexible secret-disclosure probability of the JERT scheme
ðN ¼ 400; plocal ¼ 0:5Þ. Numerical results are compared with simulation
results. All cases with m  1 paths are studied.
Fig. 11. The secret-disclosure probability as a function of secret ratio 
for different compromised probabilities x for the JERT scheme.
Fig. 9. Transmission overhead of the JERT scheme and a related
scheme from [2]. The additional computation of the JERT scheme has
been converted to an equivalent symbol transmission and included in
this figure.
[14] A. Shamir, “How to Share a Secret,” Comm. ACM, vol. 22, no. 11,
pp. 612-613, Nov. 1979.
[15] R.J. McEliece and D.V. Sarwate, “On Sharing Secrets and
Reed-Solomon Codes,” Comm. ACM, vol. 24, no. 9, pp. 583-584,
Sept. 1981.
[16] M.B. Pursley and S.D. Sandberg, “Incremental-Redundancy
Transmission for Meteor-Burst Communications,” IEEE Trans.
Comm., vol. 39, no. 5, pp. 689-702, May 1991.
[17] S.B. Wicker and M.J. Bartz, “Type-II Hybrid-ARQ Protocols Using
Punctured MDS Codes,” IEEE Trans. Comm., vol. 42, nos. 2-4,
pp. 1431-1440, Feb.-Apr. 1994.
[18] W. Du, J. Deng, Y.S. Han, S. Chen, and P.K. Varshney, “A Key
Management Scheme for Wireless Sensor Networks Using
Deployment Knowledge,” Proc. IEEE INFOCOM ’04, pp. 586-597,
Mar. 2004.
[19] S.B. Wicker and V.K. Bhargava, Reed-Solomon Codes and Their
Applications. IEEE Press, 1994.
[20] I.S. Reed and X. Chen, Error-Control Coding for Data Networks.
Kluwer Academic, 1999.
[21] S. Lin and D.J. Costello, Jr., Error Control Coding: Fundamentals and
Applications, second ed. Prentice Hall, 2004.
[22] G.C. Clark, Jr. and J.B. Cain, Error-Correction Coding for Digital
Comm. Plenum Press, 1981.
[23] W. Lou and Y. Fang, “A Multipath Routing Approach for Secure
Data Delivery,” Proc. IEEE Military Comm. Conf. (MILCOM ’01),
pp. 1467-1473, Oct. 2001.
[24] P. Papadimitratos, Z.J. Haas, and E.G. Sirer, “Path Set Selection
in Mobile Ad Hoc Networks,” Proc. ACM MobiHoc ’02, pp. 1-11,
June 2002.
[25] P. Papadimitratos and Z.J. Haas, “Secure Data Transmission in
Mobile Ad Hoc Networks,” IEEE J. Selected Areas in Comm., vol. 24,
no. 2, pp. 343-356, Feb. 2006.
[26] T.K. Truong, W.L. Eastman, I.S. Reed, and I.S. Hsu, “Simplified
Procedure for Correcting Both Errors and Erasures of Reed-
Solomon Code Using Euclidean Algorithm,” IEE Proc., vol. 135,
no. 6, pp. 318-324, Nov. 1988.
[27] S.-L. Shieh, S.-G. Lee, and W.-H. Sheen, “A Low-Latency Decoder
for Punctured/Shortened Reed-Solomon Codes,” Proc. 16th IEEE
Int’l Symp. Personal, Indoor and Mobile Radio Comm. (PIMRC ’05),
pp. 2547-2551, Sept. 2005.
[28] G.J. Pottie and W.J. Kaiser, “Wireless Integrated Network
Sensors,” Comm. ACM, vol. 43, no. 5, pp. 51-58, May 2000.
[29] J. Deng and Y.S. Han, “Using MDS Codes for the Key Establish-
ment of Wireless Sensor Networks,” Proc. Int’l Conf. Mobile Ad Hoc
and Sensor Networks (MSN ’05), pp. 732-744, Dec. 2005.
Jing Deng received the BE and ME degrees in
electronic engineering from Tsinghua University,
Beijing, in 1994 and 1997, respectively, and the
PhD degree in electrical and computer engineer-
ing from Cornell University, Ithaca, New York, in
2002. From 2002 to 2004, he was with the CASE
Center and the Department of Electrical En-
gineering and Computer Science, Syracuse
University, Syracuse, New York, as a research
assistant professor, supported by the Syracuse
University Prototypical Research in Information Assurance (SUPRIA)
Program. He was a teaching assistant from 1998 to 1999 and a research
assistant from 1999 to 2002 in the School of Electrical and Computer
Engineering, Cornell University. He is currently an assistant professor in
the Department of Computer Science, University of New Orleans. He is
an associate editor for the International Journal of Mobile Communica-
tions, Networks, and Computing (JMCNC). He was a cochair of the
IEEE International Workshop on Ad Hoc and Ubiquitous Computing
(AHUC 2006) and the sponsorship chair of the First International
Conference on Multimedia Services Access Networks (MSAN 2005). He
has served on the technical program committees of several IEEE
conferences, including the Second IEEE International Conference on
Mobile Ad Hoc and Sensor Systems (MASS 2005), MASS 2006, 2006
IEEE Global Telecommunications Conference (GLOBECOM), and 2007
IEEE Wireless Communications and Networking Conference (WCNC).
His research interests include mobile ad hoc networks, wireless sensor
networks, wireless network security, energy efficient wireless networks,
and information assurance. He is a member of the IEEE, the IEEE
Computer Society, the IEEE Communications Society, and the ACM.
Yunghsiang S. Han received the BS and MS
degrees in electrical engineering from the Na-
tional Tsing Hua University, Hsinchu, Taiwan, in
1984 and 1986, respectively, and the PhD
degree from Syracuse University, Syracuse,
New York, in 1993. From 1993 to 1997, he was
an associate professor in the Department of
Electronic Engineering, Hua Fan College of
Humanities and Technology, Taipei. From 1997
to 2004, he was with the Department of Compu-
ter Science and Information Engineering, National Chi Nan University,
Nantou, Taiwan, where he was promoted as a full professor in 1998.
From June to October 2001, he was a visiting scholar in the Department
of Electrical Engineering, University of Hawaii, Manoa. From September
2002 to January 2004, he was a SUPRIA visiting research scholar in the
Department of Electrical Engineering and Computer Science and the
CASE Center, Syracuse University, New York. He is currently with the
Graduate Institute of Communication Engineering, National Taipei
University, Taipei. His research interests include wireless networks,
security, and error-control coding. He is the recipient of the 1994
Syracuse University Doctoral Prize. He is a senior member of the IEEE.
. For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.
190 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 5, NO. 3, JULY-SEPTEMBER 2008
I. INTRODUCTION
Wireless Sensor Networks (WSNs) are formed by large number of wireless micro-sensors that
can sense the environment and send data toward information sinks autonomously [1]. WSNs
have attracted significant interests from the research community due to their potentials in a
wide range of applications such as environmental sensing, battlefield sensing, and hazard leak
detection. When these miniature sensor devices are deployed to environment with potential
eavesdroppers, information delivery must be protected with keys. Due to lack of trusted servers
nearby (for public/private key schemes), secret key schemes are considered to be more viable
to protect such local communications. The question is how to deliver such secret keys to the
communicating nodes.
In 2002, Eschenauer and Gligor proposed a random key pre-distribution technique allowing
sensors to pre-load a subset of keys (key ring) from a large key pool. It has been shown that,
when the size of the key ring and the size of the key pool are chosen carefully, the neighboring
sensors will have a relatively high probability of sharing common keys. With such shared keys,
the neighboring nodes can establish secret link key securely [2]. The scheme has been extended
by researchers in several research groups [3]–[5]. However, there are some local links that
are still disconnected on the security plane. The lack of such secure links can be thought as
intentional. This is because a higher local connectivity (on the security plane) would mean higher
vulnerability and lower network resilience, as shown in [2], [4].
In this work, we focus on the issue of delivering secret link keys from a source to multiple
neighbors that are disconnected from the source on the security plane. We call such neighbors of
the source as insecure neighbors. Eschenauer and Gligor suggested to use the secure multi-hop
path scheme to deliver such secrets [2]. In their scheme, the secret is disclosed to all the nodes
on the path. If any of these nodes is compromised, the secret is disclosed to the adversary.
Instead, we propose a new technique called Collective Secret Delivery (CSD) that identifies
several bridge nodes to help deliver secret link keys to these neighbors. The novelty of our
scheme is to deliver multiple keys with the use of these bridge nodes and regular paths instead
2
efficient and secure secret delivery from one node to multiple neighbors. By coordinating the
tasks of secret delivery toward several insecure neighbors and identifying best bridge nodes, we
increase the chance of finding bridge nodes, which are only required to share keys with some of
such insecure neighbors. Furthermore, with the use of Hamming code, our scheme protects the
delivered secret from eavesdropping and secret modification by the compromised nodes in the
network. The receiver can detect and correct such errors given that the error number is lower
than a certain threshold.
To combat the problem of topology instability in wireless networks, a multi-path routing
scheme was proposed and investigated in [7]. The scheme allows the sender to add extra overhead
to each packet that is to be transmitted over multiple paths. The goal is to find the optimal way to
fragment the packet into smaller blocks and deliver them over multiple paths. A Secure Routing
Protocol (SRP) was proposed in [8] to send additional information to protect routing information
from being dropped. Secure Message Transmission (SMT) and Secure Single Path (SSP) have
been proposed to send message over unreliable mobile ad hoc networks [9].
The maximum distance separable (MDS) codes are used to establish link keys between
neighbors without common keys through multiple paths [10], [11]. Different from these works,
we focus on the delivery of multiple link keys from one source to multiple immediate physical
neighbors.
Traynor et al. proposed to use a few more powerful sensors to achieve key establishment [12].
Since these sensors are expected to have tamper-resistant hardware, the keys on these sensors are
considered safe. Miller and Vaidya proposed to use Bloom filter and Merkel trees to distribute
key information so that the chance of neighboring nodes establishing a key can be close to
1 [13]. Their scheme takes advantage of the multiple available channel and perform random
switching among these channels in the initialization process.
In [14], a new pairwise key establishment technique was introduced. The technique uses
“friends”, which are the nodes who share a key with the receiver, in addition to “proxies”, each
of which shares a key with the sender and the receiver. Each of the “friend” nodes sends a
4
links connecting to node S. In Fig. 1, the secret link key between node S and nodes A, C, D,
and F can be set up easily with the shared keys. However, it is more difficult for node S to
establish secret link keys with nodes B, E, and G.
Problem Statement: (Delivery of Multiple Secret Link Keys)
When random key pre-distribution techniques are employed in WSNs, it is possible that
sensor nodes do not share keys with several neighboring nodes. In order to establish secure
communication for these links, secret link keys must be delivered to these neighbors. How should
these secret link keys be delivered efficiently so that the chance of secret disclosure is as small
as possible?
Note that some existing delivery techniques, e.g., the multi-hop secure path technique [2], [3]
and the Babel scheme [16], can deliver these secret link keys from the source to the insecure
neighbors. However, some of these schemes can be easily disrupted by a single compromised
node (e.g., [3]). Others may suffer from Denial-of-Service attacks (e.g., the Babel scheme in [16]).
Instead, an efficient scheme that is resilient toward node compromise and eavesdropping should
be designed.
B. The CSD Scheme
In this work, we propose the CSD scheme to deliver multiple secret link keys toward the
insecure neighbors. Our main idea is to find several bridge nodes that share keys with the source
node and some of its insecure neighbors. These nodes are termed bridge nodes, which will be
employed to deliver secret keys. All nodes in between only serve as passive routers without
knowing the secrets that they help to forward. We will show that this approach lowers the secret
disclosure probability and protection against eavesdropping and DoS attacks.
We introduce the CSD scheme through the example shown in Fig. 1. Denote the set of keys
stored on node i as Ki, as explained in [2]. We use the notations given in Table I in our example
and in pseudo-codes.
Node S collects the Message Authentication Codes (MACs) of a challenge message based
6
encrypted secret components to nodes B and G, which decrypt the secret link key components.
Assume that τ of these bridge nodes exist and denote them as node Z1, Z2, ... Zτ . We further
assume that bridge node Zj , j ∈ {1, 2, · · · τ}, shares keys with node S and nj nodes in Nin and
denote them as ij,1, ij,2, · · · ij,nj . The details of the CSD scheme are explained in the following:
Node S sends all the challenges from each i ∈ Nin to the entire neighborhood. Assuming
that each node Zj , j ∈ {1, 2, · · · τ}, shares a key with node S and at least ϵ percent nodes in
Nin, it submits responses to the nodes in Nin that it shares a key with. In particular, it submits
a response to nodes ij,1, ij,2, · · · ij,nj .
When these responses are received by node S, it distributes them to each node in Nin, which
will verify the response and report results to node S. Node S then prepares a matrix of codes
to be transmitted through these bridge nodes toward Nin. We denote this matrix as M and its
dimension is τ ×m, where m = |Nin|. In specific, M(j, i) represents the codes to be sent to
Zj towards i ∈ Nin. Note that only when Zj and i ∈ Nin share a key and Zj shares a key with
node S, the element M(j, i) is encoded. Otherwise, it is empty. The preparation of the matrix
M is basically an encoding process, which we will explain in Section III-D.
Node S concatenates all non-empty elements on row j and encrypts the result with the shared
key between itself and node Zj . This encrypted information is transmitted to node Zj , which
will decrypt and separate the elements. Zj then encrypts the elements with the shared key with
the corresponding receiver of each of the elements, i ∈ Nin. The encrypted results are then
concatenated and encrypted with the shared key between node Zj and S and sent back to node
S.3 Node S decrypts the secret and distributes each encrypted element to their corresponding
receiver, i ∈ Nin. The new shared secret between node S and node i ∈ Nin will be computed as
k(S, i) = F (I(i)) , (1)
where Zj and i share a key, I(i) contains all nonempty elements in the column corresponding
3While sending such encrypted shared secret components directly back to the nodes in Nin may be more efficient, the cost
of identifying such new paths can eliminate any of such benefits. Therefore, we design our scheme to allow these nodes to send
encrypted shared secret components back to node S, which will forward them to the nodes in Nin.
8
communication overhead caused by packet headers and trailers. In addition, we argue that our
proposed scheme will only be used when a source node needs to send secret to multiple insecure
neighbors, which usually occur in key initialization process. Such an infrequent usage limits the
extra transmission overhead caused by our scheme. Furthermore, communication cost will be
investigated in Section V.
Packet Transmission Failures: Wireless communication may experience transient transmis-
sion/reception failures. Therefore, the bridge node searching packets or replies may fail to reach
their destination. In order to alleviate such failures, retransmissions of the bridge node search
packets should be sent. The number of retransmissions and timing depends on the TTL value of
each query and the chance of transmission failure. Note that such retransmissions will naturally
increase transmission overhead and secret delivery delay.
Defense Against Eavesdroppers: The intention of the eavesdroppers is to obtain the secret
key information. The CSD scheme makes eavesdropping very difficult due to two mechanisms
that it employs: secret components are delivered to bridge nodes instead of any multi-hop secure
paths, in which all routers get to know the contents that they forward; the receiver (insecure
neighbor) XOR’es all the received key components into a single secret link key. Because of
the XOR procedure, the eavesdroppers must compromise all the bridge nodes that are helping
to deliver the key components to a particular insecure neighbor in order to re-construct the
secret link key. Compromising any of the regular routers will not help (except that they would
compromise more keys from the key space).
Defense Against DoS Attacks: DoS attackers can modify or interrupt secret component
deliveries. Interestingly, the CSD scheme is able to identify and ignore any modified secret
components. The procedure can be explained as follows: after receiving the secret components
from the bridge nodes, an insecure neighbor performs a challenge-response check on each of the
components with the source. This will make sure that none of the secret components has been
modified. If any secret component is suspected to have been modified, the source and the insecure
neighbor will simply ignore it in the XOR process, i.e., they will only XOR other key components
10
procedure for m = 7 is demonstrated as follows. The node i and node S both exclusive OR the
keys received from nodes Z4, Z5, Z6, and Z7. Then they check for if both resultant keys are
matched or not. If they are matched, then set s1 = 0; otherwise, set s1 = 1. Both nodes perform
the same procedure for keys received from Z2, Z3, Z6, and Z7 which determines the value of
s2, and keys received from Z1, Z3, Z5, and Z7 which determines the value of s3. Then the value
of s1, s2, s3 is the binary representation of the index of common bridge who sent the modified
key. For example, if s1 = 1, s2 = 1, s3 = 0, Z6 sent the modified key to node i. Actually, the
rule to determine the values of si, 1 ≤ i ≤ 3 comes from the parity-check matrix H of the (7, 4)
Hamming code as follows:
H =

0 0 0 1 1 1 1
0 1 1 0 0 1 1
1 0 1 0 1 0 1
 .
In general, for 2r−1−1 < m ≤ 2r, a parity-check matrix of the (2r−1, 2r−1−r) Hamming code
(or its shorten version) is required. The ith column of the parity-check matrix H can be arranged
as the transpose of the binary representation of i. For example, when i = 6, the sixth column of
H is (6)T2 = (1 1 0)
T . By arranging in this way, the decimal representation of (s1, s2, · · · , sr)
is the index of the erroneous key. The way to calculate si is to exclusive OR the keys received
from nodes which are corresponding to nonzero elements in ith row of H .
Once the modified elements are identified and eliminated, both node S and node i will exclusive
OR the rest of the elements transmitted and received successfully and use the result as the new
secret shared between themselves. If there are more than one modified keys the key match
procedure between S and i will fail. Node i then performs key identification for each key with
node S.
The above scheme also helps node S to identify a potential compromised bridge. When node
S performs challenge-and-response with next insecure node it can eliminate the keys forwarded
by the potential compromised bridge. Hence, for each compromised bridge, at most one insecure
node must perform the procedure to identify modified elements.
12
The second set of nodes that we need to consider is the set of securely connected neighbors
of node S. Denote one of them as node n among these Ng −m nodes, each of which shares
at least one key with node S. Let Dℓn be the event that there are ℓn number of shared keys
between node n and node S. Therefore, node n carries only λ − ℓn different keys from the λ
keys carried on node S.
Let Ani, where i ∈ {1, 2, · · ·m}, be the event that node n does not share a common key with
i-th insecure neighbor and S. The probability of Ani given Bm is
Pr(Ani|Bm) =
λ∑
ℓn=1
Pr(Dℓn |Bm) · Pr(Ani|Bm, Dℓn) . (3)
The first conditional probability in (3) is the chance that node n shares exactly ℓn keys with
node S given Bm, where Bm assures that there are at least one key shared between n and S.
Thus, for ℓn ∈ {1, 2, · · · , λ},
Pr(Dℓn |Bm) =
(
λ
ℓn
) · (Np−λ
λ−ℓn
)(
Np
λ
)− (Np−λ
λ
) . (4)
The second conditional probability in (3) is the chance that node n and node i share no key
given Dℓn and Bm. The number of ways that node n chooses λ−ℓn keys from the rest of the key
pool from those chosen from node S and node i (Np − 2λ keys) after choosing the ℓn common
keys from S is (
λ
ℓn
)
·
(
Np − 2λ
λ− ℓn
)
.
Thus,
Pr(Ani|Bm, Dℓn) =
(
λ
ℓn
) · (Np−2λ
λ−ℓn
)(
λ
ℓn
) · (Np−λ
λ−ℓn
) = (Np−2λλ−ℓn )(
Np−λ
λ−ℓn
) . (5)
Therefore, Pr(Ani|Bm) can be computed as:
Pr(Ani|Bm) =
λ∑
ℓn=1
(
λ
ℓn
) · (Np−λ
λ−ℓn
)(
Np
λ
)− (Np−λ
λ
) · (Np−2λλ−ℓn )(
Np−λ
λ−ℓn
) = λ∑
ℓn=1
(
λ
ℓn
) · (Np−2λ
λ−ℓn
)(
Np
λ
)− (Np−λ
λ
) . (6)
Let Tj be the subset of Nin with exact ϵ′ = ⌈ϵm⌉ elements, where j = 1, 2, . . . ,
(
m
ϵ′
)
and ⌈·⌉
the ceiling function. Let AzTj be the event that non-neighboring node z of S does not share
14
for intra-cluster communication that should be protected from all outsiders, the disclosure of any
secret link key (hence communication) will lead to security compromise in the cluster.
Our security analysis is based on the assumption that a ratio of 0 ≤ xc < 1 sensors are
compromised by the adversary.5 We assume that adversaries compromise sensor nodes randomly.
When a sensor is compromised, all information attached to the sensor is disclosed. We further
assume that the source node S and the insecure neighbors will not be compromised, since the
compromise of any of these nodes makes the security analysis trivial.
When only one bridge node is employed in the CSD scheme, the chance of the secret link
keys being compromised is simply xc (the chance the bridge node is compromised) plus pe(xc),
where pe(xc) is the probability that any of the shared keys between the source node S, the bridge
node, and the insecure neighbors is disclosed. That is,
P (Babel)c = xc + pe(xc) . (12)
Note that pe(xc) depends on the random key pre-distribution scheme employed in the network.
If we consider the multiple-space scheme proposed in [4], pe(xc) is quite small when xc is less
than a threshold.
When multiple bridge nodes are employed in our CSD scheme, the security analysis is
more complex. The compromise probability is seemingly higher because more bridge nodes are
involved. However, each insecure neighbor will exclusive-OR all the received key components
into a single secret. For example, bridge nodes Z1, Z3, and Z6 may each be responsible to deliver
one part of the key from the source node S to node B in Fig. 1. When node B receives all three
components, it re-generates the secret key by exclusive-OR’ing the three parts into one key. The
adversary must compromise all three bridge nodes in order to compromise the key between node
S and node B.
5In comparison, a localized compromise that affect a close region of nodes seems more realistic but its security analysis can
be quite arbitrary. We follow the same assumption of random compromise in several related work [3], [5], [6].
16
TTL because more nodes are considered. For instance, when TTL is extended from 2 to 4,
the number of eligible bridge nodes almost triples. Note that the total number of nodes within
TTL-hops should quadruple if TTL doubles because of the 2-D region.
B. Transmission Overhead
Since the transmission overhead of our scheme depends largely on how far the bridge nodes
are away from the source node and the insecure neighbors, we recorded the total hop count from
the source toward all the insecure neighbors and showed them in Fig. 5. Based on Fig. 5, the
transmission cost is higher when we extend the region (increasing TTL) to search for bridge
nodes and lower the key sharing requirement (decreasing ϵ). When ϵ > 0.7, the difference in
transmission costs for different ϵ is small.
C. Security Evaluation
We present the secret disclosure probability of the CSD scheme under the condition of node
compromise. In our simulations, we randomly picked xc portion of the nodes as compromised
nodes (except the source and the insecure neighbors). Once a node is compromised, all in-
formation on it is disclosed. Then we computed the probability of the secret delivery being
compromised (or secret disclosed to any third party). Secret disclosure probability is defined as
the chance of a secret link key of an insecure neighbor is disclosed to the adversary.
In Fig. 6, the secret disclosure probability of the CSD scheme with different TTL is shown
and compared. As node compromise probability, xc, increases, secret disclosure probability is
higher. Since each insecure neighbor XOR’es all received components that are sent through the
bridge nodes, the adversary needs to compromise all the bridge nodes helping to deliver keys
toward this node in order to compromise the secret delivery. As a result, when there are more
bridge nodes in use (due to an increased TTL), the chance of secret disclosure is lower.
We compared the secret disclosure probability of CSD and several related schemes in Fig. 7.
In CSD, the adversary needs to compromise all the bridge nodes that help forwarding key
18
[3] H. Chan, A. Perrig, and D. Song, “Random key predistribution schemes for sensor networks,” in Proc. of IEEE Symposium
on Security and Privacy, Berkeley, California, May 11-14 2003, pp. 197–213.
[4] W. Du, J. Deng, Y. S. Han, P. K. Varshney, J. Katz, and A. Khalili, “A pairwise key pre-distribution scheme for wireless
sensor networks,” ACM Transactions on Information and System Security, vol. 8, no. 2, pp. 228–258, May 2005.
[5] D. Liu and P. Ning, “Establishing pairwise keys in distributed sensor networks,” in Proc. of the 10th ACM Conference on
Computer and Communications Security (CCS ’03), Washington, DC, USA, October 27-31 2003, pp. 52–61.
[6] G. Li, H. Ling, and T. Znati, “Path key establishment using multiple secured paths in wireless sensor networks,” in Proc.
of CoNEXT ’05, 2005, pp. 43–49.
[7] A. Tsirigos and Z. J. Haas, “Multipath routing in the presence of frequent topological changes,” IEEE Communication
Magazine, pp. 132–138, November 2001.
[8] P. Papadimitratos and Z. J. Haas, “Secure message transmission in mobile ad hoc networks,” Elsevier Ad Hoc Networks,
vol. 1, no. 1, pp. 193–209, July 2003.
[9] P. Papadimitratos and Z. J. Haas, “Secure data transmission in mobile ad hoc networks,” IEEE Journal on Selected Areas
in Communications, vol. 24, no. 2, pp. 343–356, February 2006.
[10] D. Huang and D. Medhi, “A byzantine resilient multi-path key establishment scheme and its robustness analysis for sensor
networks,” in Proc. of 19th IEEE International Parallel and Distributed Processing Symposium, Colorado, USA, April
4-8 2005, pp. 240b–240b.
[11] J. Deng and Y. S. Han, “Using MDS codes for the key establishment of wireless sensor networks,” in Proc. of the
International Conference on Mobile Ad-hoc and Sensor Networks (MSN ’05), X. Jia, J. Wu, and Y. He, Eds., Wuhan, P.
R. China, December 13-15 2005, vol. 3784 of Lecture Notes in Computer Science (LNCS), pp. 732–744, Springer-Verlag.
[12] P. Traynor, H. Choi, G. Cao, S. Zhu, and T. LaPorta, “Establishing pair-wise keys in heterogeneous sensor networks,” in
Proc. of the 25th Conference of the IEEE Communications Society (Infocom ’06), Barcelona, Spain, April 23-29 2006.
[13] M. J. Miller and N. H. Vaidya, “Leveraging channel diversity for key establishment in wireless sensor networks,” in Proc.
of the 25th Conference of the IEEE Communications Society (Infocom ’06), Barcelona, Spain, April 23-29 2006.
[14] Abhishek Gupta, Joy Kuri, and Pavan Nuggehalli, “A new scheme for establishing pairwise keys for wireless sensor
networks,” in Distributed Computing and Networking. 2006, vol. 4308 of Lecture Notes in Computer Science (LNCS), pp.
522–533, Springer.
[15] Jang-Ping Sheu and Jui-Che Cheng, “Pair-wise path key establishment in wireless sensor networks,” Computer
Communications, vol. 30, no. 11-12, pp. 2365 – 2374, 2007, Special issue on security on wireless ad hoc and sensor
networks.
[16] J. Deng and Y. S. Han, “Babel: Using a common bridge node to deliver multiple keys in wireless sensor networks,” in
Proc. of IEEE Global Telecommunications Conference - General Symposium (GLOBECOM ’07), Washington, DC, USA,
November 26-30 2007, pp. 161–165.
20
Algorithm 1 Pseudo-code to Find Bridge Nodes
1: S obtainsMAC(i, a) based on Ki,a for each tuple of (i, a), i ∈ {S}∪Nin, a ∈ {1, 2, · · · , λ}
2: S broadcasts a msg with MACs and TTL
◃ When node z overhears the msg, it performs:
3: n← 0, Rz ← ∅
4: if ∃a, b ∈ {1, · · · , λ}, such that MAC(z, ta) = MAC(S, tb) then
5: Rz ← Rz ∪ {(S, ta, tb)}
6: for each i ∈ Nin do
7: if ∃a, b ∈ {1, · · · , λ}, such that MAC(z, ta) = MAC(i, tb) then
8: n← n+ 1
9: Rz ← Rz ∪ {(i, ta, tb)}
10: end if
11: end for
12: end if
13: if n ≥ ϵm then
◃ z can serve as a bridge node
14: z prepares responses to MAC(i, tb) for each (i, ta, tb) tuple in Rz
15: z encrypts responses with Kz,ta , where ta is from Rz
16: z sends the encrypted responses to S
17: end if
18: TTL ← TTL-1
19: if TTL > 0 then
20: z adds its ID to the end of msg
21: z forwards msg
22: end if
22
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0
5
10
15
20
25
30
35
Key sharing percentage with insecure neighbors, ε
N
um
be
r o
f e
lig
ib
le
 b
rid
ge
 n
od
es
, N
e
 
 
N=600
N=400
N=200
Fig. 3. Number of eligible bridge nodes, Ne. ϵ represents the percentage of insecure neighbors must share keys with before
they become eligible. These nodes must share a key with the source node as well. Np = 1000, λ = 20, and TTL = 3 in these
curves, i.e., only the nodes within 3-hops from the source were considered.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0
5
10
15
20
25
30
35
40
45
Key sharing percentage with insecure neighbors, ε
N
um
be
r o
f e
lig
ib
le
 b
rid
ge
 n
od
es
, N
e
 
 
TTL=5
TTL=4
TTL=3
TTL=2
Fig. 4. Number of eligible bridge nodes, Ne. ϵ represents the percentage of insecure neighbors must share keys with before
they become eligible. These nodes must share a key with the source node as well. Np = 1000, λ = 20, and N = 400.
24
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
Node compromised probability, x
c
Se
cr
et
 d
isc
lo
su
re
 p
ro
ba
bi
lity
, p
x
 
 
SMSP
MMSP
Babel
CSD
Fig. 7. Secret disclosure probability for CSD and several related schemes. N = 400, Np = 1000, λ = 20, ϵ = 0.5, TTL = 3.
We compare CSD with SMSP: Single Multi-hop Secure Path scheme [2]; MMSP: Multiple Multi-hop Secure Path scheme [3];
and Babel [16].
26
autonomous event detection and data gathering. The sensed results should be transmitted toward
data sinks, which serve as the interface between the network and a human. Depending on the
nature of WSN applications, single or multiple data sinks are possible.
Large wireless networks, such as WSNs, are expected to have profound technological and
economic impacts on our society. Their success is nonetheless determined by whether they can
efficiently deliver information from target areas toward data sinks. This task is complicated by
severe energy constraints of sensors in WSNs. In the tiny sensors, the size and energy reserve
of the sensor battery are extremely limited. Battery replacement or recharge can be difficult.
Therefore, use of the limited energy should be planned carefully [2].
In this work, we focus on the delivery of sensing data from the sensors toward a data sink
in WSNs. We investigate the types of WSNs with relatively low rate of data generation so that
transmission competition is not an issue or can be resolved by other mechanisms [3]. While a
sleeping technique may be useful to put some sensors to a state of minimum energy usage, we
believe that the fundamental problem of data forwarding remains in WSNs. In other words, how
should the active sensors deliver sensing data toward the data sink?
Our main contribution in this work is a new data forwarding scheme. Our scheme takes
advantage of the information that sensor nodes find out during previous one-hop transmissions.
These include one node’s estimated lifetime and those of the potential relays, one of which is the
optimal relay based on the overall energy consumption of the traffic by the sender alone. With the
use of such information, nodes can make their local decisions to choose which of the potential
relays to help them forward data packets. Our dynamic and distributed router selection technique
can balance the node lifetime on the fly regardless of traffic generation, residual energy, or even
node movements. On the contrary, linear programming solutions require global information and
centralized processing, which are commonly considered difficult and costly to obtain in WSNs.
For example, any change in node sleep/active status, membership, or failure will trigger a new
round of global information update and traffic forwarding pattern re-computation and distribution.
2
where ω is the path loss exponent and assumed to be 2 in this work. We call k0 the
energy constant, which includes all power consumption of transmission that are unrelated
to transmission distance, such as circuit processing consumption;2
• Ei: the energy consumption of node i (to send out data packets),
Ei =
N∑
j=0
Ti,j [k0 + [d(i, j)]
ω] ; (2)
• E : the maximum node energy consumption;
• E: the average energy consumption of all nodes.
We assume that packet reception does not consume extra energy. This is justified by the fact
that receiving nodes and idle nodes consume much less energy compared to that consumed by
transmitting node. Hence, we only consider transmission energy consumption in our analysis.
We will justify this assumption by simulating the proposed scheme on power consumption data
from [4] (see Fig. 13). We further assume that each node is able to change its transmission
range by adjusting the transmission power. Their maximum transmission range is limited by a
threshold, Rmax [4]. This parameter will affect the selection of ℓ to be defined in Section III.
We first introduce our definition of network lifetime, which is measured as the time when the
first node runs out of battery energy. Other network lifetime definitions are possible, such as
the time when α, 0 < α ≤ 1, of all nodes run out of battery energy. We will investigate these
different network lifetimes in Section IV.
Let Einitiali be the initial energy at node i. It is clear that network lifetime L is bounded by
L ·Ei ≤ Einitiali for all i = 1, 2, · · ·N, (3)
where Ei is given by (2) and i = 1, 2, · · · , N .
2Note that k0 has been normalized in such a way that the coefficient of the [d(i, j)]ω term is 1. In this case, the time unit
has been modified accordingly.
4
destination, consuming more energy because of the term k0. We will exploit such an optimal
transmission range in our proposed scheme in Section III.
The above optimal transmission range minimizes the total energy consumption to send data
packets from one node toward the data sink. However, it does not provide insights in network
lifetime defined as the time when the first node runs out of energy.
Consider the node with i unit distance to the data sink in an N-node chain network. When a
transmission range of h is employed by all nodes, the total traffic rate forwarded by node i is⌊
N−i
h
⌋
+ 1. The total energy consumption of this node is
Ei =
(⌊
N − i
h
⌋
+ 1
)
(k0 + h
ω) ≈
(
N − i
h
+ 1
)
(k0 + h
ω) . (6)
Thus, the average energy consumption of all nodes can be calculated as the average of Ei
E =
(
1
h
(N − 1)
2
+ 1
)
(k0 + h
ω) ≈ 1
h
(N − 1)
2
(k0 + h
ω) , (7)
since N is usually large. Optimizing E with respect to h, we obtain the optimal transmission
range h∗ as given by (4). Thus, (4) indeed minimizes the average energy consumption.
Next we calculate the optimal transmission for those nodes in hotspot. One can observe that
those nodes close to the source will forward large amounts of packets and may consume a lot
of energy. Thus, it is reasonable to assume that, for those nodes in hotspot, (N − i)/h ≫ 1.
Then (6) reduces to N−i
h
(k0 + h
ω). Again, optimizing E with respect to h, we obtain the optimal
transmission range h∗ as given by (4).
C. Some Special Forwarding Schemes
We study several special forwarding schemes in an N-node chain network summarized in
Table I (see Fig. 1). These results have been published in [7]. We include them here for the
completeness of our work.
6
from the data sink. The maximum node energy consumption is
E (MF ) = max [(q + 1)(k0 + pω), q(k0 + hω)] ,
where p is the remainder and q the quotient when N is divided by h.
In the Genie Forwarding (GF) scheme, there exists a genie who is able to redistribute the
energy among the N nodes without any extra cost. Therefore, the residual energy of all N
nodes is always balanced. The GF scheme is similar to the MF scheme, except that the GF
scheme has a cost-free energy-balancing genie. We can imagine this scheme to be operating in
a network where all nodes share a virtual massive battery. Its node energy consumption serves
as an unrealistic lower bound in our study.
Similarly to the MF scheme, the pre-balanced energy consumption of node i is
E
(GF )
i = [k0 + min(h, i)
ω] ·
(⌊
N − i
h
⌋
+ 1
)
,
where i = 1, 2, · · · , N . Due to the energy-balancing activity performed by the genie, all the
nodes consume the same amount of energy. Therefore, the maximum and average node energy
consumption are the same, as
E (GF ) = E(GF ) =
N∑
i=1
E
(GF )
i /N .
We calculated energy consumption of different nodes in four of these special forward rules (the
CF, the DF, the MF, and the GF schemes) and showed them in Fig. 2. Node energy consumption
of the DF scheme increases exponentially with node index (distance from the data sink). The
CF scheme exhibits a reversed trend, i.e., node energy consumption decreases as node index
increases.4 Compared to the CF and the DF scheme, the MF scheme leads to a much more
balanced energy consumption for the nodes. Still, a declining trend as i increases can be seen.
The GF scheme results in an efficient and balanced energy consumption for all nodes. This,
however, is achieved by the genie.
4Haenggi and Puccinelli [8] suggested against the use of short-hop routings.
8
The above argument suggests that when one deploys the sensors with the same transmission
range, the optimal transmission range given in (4) should be used to minimize energy consump-
tion, especially, for those nodes in hotspot.6 Thus, we will present our technique with h∗ in (4)
as the initial transmission range for each node and allow it to adjust the range independently.
Such an adjustment is necessary to reduce the energy consumption of the nodes in hotspot and
extend the overall network lifetime.
III. THE DER SCHEME
We observe that the MF scheme, while energy efficient in forwarding the traffic for each of
the nodes, suffers from the “hotspot” issue. That is to say, nodes that are closer to the data sink
generally send out more traffic than those that are farther away. In order to balance this energy
consumption and maintain energy efficiency, we propose the DER scheme.
A. Operational Details of the DER Scheme
The main idea of the DER scheme is that each node will send packets to a relay that is h∗
distance closer to the data sink.7 This relaying node serves as the optimal relay. However, when
the optimal relay has a shorter estimated lifetime than the sender, the sender should send to nodes
that are even closer to the data sink than the optimal relay. The underlying reason of doing so
is to balance the lifetime of the sender and the optimal relay, which has been demonstrated
through our analysis in Section II. For the sender, an increased forwarding distance consumes
more energy, lowering its estimated lifetime. For the optimal relay, the decreased incoming traffic
6It is possible that no relay is h∗ distance closer to the data sink from the sender in the 2-D network. Instead, one can find
one in the neighborhood to serve as the relay.
7Note that we have chosen h∗ based on the MF scheme. Such a distance might not be optimal in the DER scheme because
of the different traffic split schedule. However, as we will show in Section IV, our selection leads to a DER performance that is
close to the LPF scheme, which is considered optimal but limited by its linear programming and global computation requirement.
10
where τ = 2, 3, · · · , ℓ and 1{.} is the set indicator function.
The relay update should be performed periodically, but randomly for each node. The best
frequency for such updates depends on the cost of residual energy estimation as well as extra
cost to obtain the estimated lifetime of the optimal relay. While a high frequency may introduce
extra cost, a low frequency may risk energy depletion of the optimal relay or forwarding traffic
to non-optimal relays unnecessarily. We investigate the update frequency on the performance of
the DER scheme in Section IV.
B. Identifying Potential Relays
In the DER scheme, each node, i, should identify its potential relays, ID(i, τ), τ = 1, 2, · · · , ℓ.
This can be achieved by sending out query messages with a transmission range slightly larger
than τh∗ and nodes with the closest distance toward the data sink will respond first.8 Note that
h∗ is the optimal forwarding distance toward the data sink even for nodes that are far away from
the sink. The far-away nodes simply forward their traffic toward a node that is h∗ distance closer
to the sink than itself. h∗ can be computed based on energy consumption constant through (4).
Such a value can be stored on the sensors before they are deployed or the sensor can calculate
it on the fly.
When such a query message is heard from node i, the sensor that is closest to the data sink
among all sensors overhearing the query message should respond and volunteer to serve as the
τ -th relay for node i. A competition mechanism can be administered in order to allow the best
relay to respond. This process is similar to geographical routing [9].
8The exact range of such query message depends on node density and tolerated delay.
12
If nodes have different traffic generation rates or rate fluctuation, such rates will affect their
estimated lifetimes. Thus, when a node has more traffic than other nodes and higher energy
consumption rate, its estimated lifetime will be shorter than other nodes in the neighborhood.
This will in turn reduce its energy consumption in the coming rounds.
Irregular network shapes affect the identification of potential relays in the DER scheme.
However, the dynamic feature of the DER scheme makes sure that the best set of relays will be
found and used to forward data traffic toward the data sink. We present our simulation results
in non-circular network areas in Section IV.
IV. PERFORMANCE EVALUATION
We used Matlab to simulate and evaluate our proposed scheme and several related ones
including the MF, the LPF, and the GF schemes. Unless specified otherwise, the network setup
is the following: We deploy N nodes in a WSN and each of the nodes generates λ = 1 packet
in each second. These packets will be forwarded toward the data sink. The network lifetime and
other performance metrics are measured and compared for different data forwarding schemes.
We calculated the normalized lifetime of each scheme as its lifetime divided by that of the GF
scheme. The energy constant k0 is 1. The initial energy reserve of each of the nodes is assumed
to be 1×103 J. ℓ = 8 is used in the DER scheme. Furthermore, we have assumed that the nodes
always obtain estimated lifetime of the potential relay nodes (i.e., an update cycle of 1 unit, see
Fig. 8.) Note that these parameters (except ℓ) and results only have relative significance. Other
values would lead to similar conclusions.
A. 1-D Chain Network
We first investigate the performance of the DER scheme in 1-D chain networks. In 1-D
networks, the N nodes are distributed evenly, with the distance between consecutive nodes
being 1 unit, e.g., meter (see Fig. 1).
14
change the lifetime for networks with relatively small N. When this update cycle is increased to
100 units, a large network may experience a drop of lifetime by about 25%. This demonstrates
that the DER scheme does not require frequent updates of estimated lifetime of the potential
forwarding nodes. This is mainly due to the flexibility of our scheme.
We also compared the DER scheme with the LPF scheme in networks with dynamic node
membership. In a 1-D network of 100 nodes, some of the nodes will move away and never come
back. Therefore, in the LPF scheme, the node which has forwarded traffic to the moved-away
node has to randomly choose a new destination to forward its traffic. We use this simulation
setup to demonstrate the benefit of the DER scheme’s intrinsic capability to react to network
dynamics. The node movement was simulated as a simple move-away probability Pdyn in each
slot. In each time slot, each node randomly decides whether it will leave the current 1-D network.
Moved-away nodes never come back. The network lifetime comparison in the unit of slots is
presented in Fig. 9. The results are the average of 50 runs with different random seeds.
Based on Fig. 9, we can see that the DER scheme offers a much better network lifetime than
the LPF scheme. This is because of its natural reaction towards the estimated lifetime of the
routers. It might be argued that, in a network where LPF is employed, the forwarding rules
should be recomputed once node(s) moved away. However, this will significantly increase the
overhead of sending the topology to the central node for computation and distributing the traffic
forwarding rules back to every node. In the DER scheme, however, each node reacts to the
change based on the estimated lifetime and modifies its forwarding rule accordingly. As such,
the overhead is much lower (note that the estimated lifetime can be piggy-backed to the sender
through acknowledgment packets).
B. 2-D Network
We have also investigated the performance of the DER scheme in 2-D networks. In our default
simulations, N nodes are distributed on a circular network region with a radius of n units. On an
16
these data packets.
We have also used matlab to simulate the lifetime of WSNs with practical energy consumption
data. The results are presented in Fig. 13. The energy consumption rates were obtained from [4].
As N increases, the network lifetime significantly decreases. The DER scheme performs slightly
worse than the LPF scheme, both of which are much better than the MF scheme. A small ℓ does
slightly shorten the network lifetime, as can be observed in the figure, especially when N = 10.
V. RELATED WORK
Sensor networks have been an active research field in recent years. Many studies focused
on routing, such as Sensor Protocols for Information via Negotiation (SPIN) scheme by Kulik
et al. [10], Geographic and Energy Aware Routing (GEAR) by Yu et al. [11], and the Low-
Energy Adaptive Clustering Hierarchy (LEACH) protocol by Heinzelman et al. [4]. Directed
Diffusion [12] employs initial data flooding and gradual reinforcement of better paths to deliver
information from sensors toward observers. Chang and Tassiulas [13] combined two metrics,
residual power and energy cost of sending packets, to evaluate and choose routes for data
forwarding in sensor networks. Their main idea is to avoid nodes with low residual energy and
to favor short hops. Different to their approach, our proposed technique chooses an appropriate
transmission distance (range) based on the comparison of estimated lifetime among the sender
and the potential relays. Elhafsi and Simplot-Ryl proposed Orthogonal Routing (ORouting) [14],
which is a localized energy efficient greedy routing scheme. ORouting allows a sender to choose
a forwarding node that is closest to the line connecting the sender and destination pair. Being a
greedy algorithm, ORouting is energy efficient but suffers from the hotspot problem [15], which
is the main focus in our work.
Our approach is also different from [16], [17], which focus on the design of medium access
control techniques and sleeping schedules in low-duty WSNs. Interestingly, our DER scheme
can be implemented in low-duty WSNs, where some of the sensors should be put to sleep in
18
the knowledge of each node’s distance toward the data sink and that of the farthest node. We
argue that such distance information is unavailable in many WSNs, especially networks that are
more dynamic. The proposed DER scheme in our paper is expected to work well in dynamic
networks.
Our work is also closely related to the problem of optimizing transmission range in wireless
networks [6], [24]. In these work, the wireless network was assumed to have high node density,
and consisting of nodes with relatively low mobility and short transmission range. As justified
by the assumption of high node density, the authors further assumed that intermediate router
nodes are always available at the desired location whenever they are needed.
VI. CONCLUSIONS
The severe resource constraints of the sensor nodes in Wireless Sensor Networks (WSNs)
call for carefully designed data forwarding techniques. A successful technique should balance
the energy consumption of most nodes while lowering the overall power consumption in the
source-to-sink data delivery. In this work, we have focused on the problem of optimizing the
energy consumption among nodes with different energy and overall traffic load. Based on our
observations, we have proposed a Dynamic Energy-based Relaying (DER) scheme for WSNs.
In the DER scheme, each node makes its own decision on data relay selections. Such a
decision is made with the help of the extra information piggy-backed from the communication
that it has performed with its potential relays. Each of the nodes continuously asks the same
question, “Will I live longer than my relay?” If a node figures that the optimal relay has a
shorter estimated lifetime, it will forward its traffic further instead of forwarding traffic to the
optimal relay. This is the key technique in our DER scheme that is responsible of balancing
the energy consumption of nodes and equalizing lifetimes of the nodes in the network. The
main draw-back of employing the optimal transmission distance, as in the MF scheme, is that,
while it minimizes the overall energy consumption, it causes a serious hot-spot problem. In the
20
[12] C. Intanagonwiwat, R. Govindan, D. Estrin, J. Heidemann, and F. Silva, “Directed diffusion for wireless sensor networking,”
IEEE/ACM Trans. on Networking, vol. 11, no. 1, pp. 2–16, February 2003.
[13] J.-H. Chang and L. Tassiulas, “Maximum lifetime routing in wireless sensor networks,” IEEE/ACM Trans. on Networking,
vol. 12, no. 4, pp. 609–619, 2004.
[14] E. H. Elhafsi and D. Simplot-Ryl, “Flattening the gap between source-destination paths in energy efficient greedy georouting
in wireless sensor networks,” in Proc. of the 3rd International Conference on Mobile Ad-hoc and Sensor Networks (MSN
’07), H. Zhang et al., Ed., Beijing, P. R. China, December 12-14 2007, vol. 4864 of Lecture Notes in Computer Science
(LNCS), pp. 56–65, Springer-Verlag.
[15] M. Perillo, Z. Cheng, and W. Heinzelman, “An analysis of strategies for mitigating the sensor network hot spot problem,”
in Proc. of the 2nd Annual Int. Conf. on Mobile and Ubiquitous Systems: Networking and Services, San Diego, CA, USA,
July 17-21 2005, pp. 474–478.
[16] W. Ye, J. Heidemann, and D. Estrin, “Medium access control with coordinated adaptive sleeping for wireless sensor
networks,” IEEE/ACM Trans. on Networking, vol. 12, no. 3, pp. 493–506, June 2004.
[17] Y. Nam, T. Kwon, H. Lee, H. Jung, and Y. Choi, “Guaranteeing the network lifetime in wireless sensor networks: A MAC
layer approach,” Computer Communications, vol. 30, no. 13, pp. 2532–2545, September 2007.
[18] R. Madan and S. Lall, “Distributed algorithms for maximum lifetime routing in wireless sensor networks,” IEEE Trans.
on Wireless Communications, vol. 5, no. 8, pp. 2185–2193, Aug 2006.
[19] W. Wang, V. Srinivasan, and K.-C. Chua, “Using mobile relays to prolong the lifetime of wireless sensor networks,” in
MobiCom ’05: Proc. of the 11th annual international conference on Mobile computing and networking, New York, NY,
USA, 2005, pp. 270–283.
[20] J. Luo, J. Panchard, M. Piorkowski, Matthias Grossglauser, and Jean-Pierre Hubaux, “MobiRoute: Routing towards a
mobile sink for improving lifetime in sensor networks,” in In Pro. of the 2nd IEEE/ACM DCOSS, 2006.
[21] H. Rivas, T. Voigt, and A. Dunkels, “A simple and efficient method to mitigate the hot spot problem in wireless sensor
networks’,” in Proc. of Performance Control in Wireless Sensor Networks, Coimbra, Portugal, 2006.
[22] O. Powell, P. Leone, and J. Rolim, “Energy optimal data propagation in wireless sensor networks,” J. Parallel Distrib.
Comput., vol. 67, pp. 302–317, 2007.
[23] C. Efthymiou, S. Nikoletseas, and J. Rolim, “Energy balanced data propagation in wireless sensor networks,” Wireless
Networks, vol. 12, pp. 691–707, May 2006.
[24] M. Sanchez, P. Manzoni, and Z. J. Haas, “Determination of critical transmission range in ad hoc networks,” in Multiaccess
Mobility and Teletraffic for Wireless Communications 1999 Workshop, October 1999.
22
0 20 40 60 80 100 120 140 160 180 200
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
x 104
Node index, i
En
er
gy
 c
on
su
m
pt
io
n,
 E
i
CF
DF
MF
GF
Fig. 2. Comparison of node energy consumption for the CF, the DF, the MF, and the GF schemes (N = 200, k0 = 100).
d
δx
θ
inner arc
outer 
arc
source
Fig. 3. A 2-D network deployed as a circular sector
0
...
... ...
i i− h∗ i− 2h∗ i− 3h∗ i− lh∗
Fig. 4. Illustration of the DER scheme in 1-D networks. Node i forwards traffic to node ID(i, 1) = i−h∗ or ID(i, τ ) = i−τh∗,
where τ = 2, 3, · · · , ℓ and ℓ = 2, 3, · · · .
24
100 101 102
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of nodes, N
N
or
m
al
iz
ed
 lif
et
im
e,
 T
 
 
r
e
=0
r
e
=0.25
r
e
=0.5
r
e
=0.75
Fig. 7. Normalized lifetime of the DER scheme in 1-D chain network with different initial energy. The initial battery energy
of each node is randomly chosen from 1 − re and 1 multiplied by emax, the maximum initial energy. Therefore, larger re
represents more randomness in the initial battery energy.
100 101 102
0.4
0.5
0.6
0.7
0.8
0.9
1
Update Period, T
u
Li
fe
tim
e,
 T
 
 
N=2
N=5
N=10
N=20
N=50
N=100
Fig. 8. Lifetime of the DER scheme in 1-D network. It can be observed that, even with an update cycle of one per 20 messages,
the lifetime of the network remains unchanged. Only when the update cycle is increased to 100, a large network may experience
a drop of lifetime by about 25%.
26
10−3 10−2 10−1 100 101 102 103
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Energy constant, k0
Li
fe
tim
e 
co
m
pa
ris
on
 o
f D
ER
 a
nd
 L
PF
, r
 
 
L=10
L=8
L=6
Fig. 11. Lifetime comparison of the DER and the LPF schemes in 2-D networks. The network radius is assumed to be n = 20.
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
55
60
65
70
75
80
85
90
95
100
105
Lifetime definition, α
Li
fe
tim
e,
 T
(α)
 
 
N=200
N=500
N=800
N=1200
Fig. 12. Performance of the DER scheme with different lifetime definition. The lifetime is defined as the time at which α
portion of nodes run out of battery energy. N nodes are randomly distributed in circular networks.
28
出席國際學術會議心得報告  
                                                             
計畫編號 NSC 96-2221-E-305-002-MY3 
計畫名稱 利用MDS碼在無線感測器網路上有效率建立保密通道（第 3 年） 
出國人員姓名 
服務機關及職稱 
韓永祥 
國立台北大學教授 
會議時間地點 11/30/2009-12/4/2009 Honolulu 
會議名稱 IEEE GLOBECOM 2009 
發表論文題目 Fairness Index Based on Variational Distance 
 
一、參加會議經過 
本人於當地時間 11 月 30 日上午七時抵達， 隨即赴開會所在的地點報到註冊。論文發表會
是從 11 月 30 日至 12 月 4 日每天早上八時三十分開始舉行。學者就根據自己的專長及興趣，
到各個不同的場次聽論文發表，或與相識的國內外教授學者相互交談、交換意見。 
本人論文於 12 月 3 日下午發表，在場各方彥碩給於熱烈的討論及意見，令本人獲益良多。12
月 4 日上午結束所有議程，於 12 月 5 日下午六時返抵台灣。 
 
二、與會心得 
本次 GLOBECOM2009 所發表的論文函蓋通訊理論領域各層面，是個相當具規模的國際會議。
與本人相關或本人深感興趣之研究，主要為解碼 (decoding)的相關研究。解碼的相關論文在
本次會議中共有一個 section，其中多數的論文均與本人的研究有密切的相關性。例如國外
教授所提出的數篇有關 LDPC codes 論文，從不同的角度來討論 LDPC codes 的問題，特別引
起本人的興趣。這些觀念對我們的研究可提供一些不同的思考方向，的確令人受益菲淺。 編
碼理論在工業或學術研究上都是一個非常重要的領域，全世界均有許多學者投入這個領域的
研究。本人由於會議的參與，認識不少國內外學者，並使本人之論文得以與他人充分溝通及
交換意見，收穫自然不少。只是由於政府預算緊縮，因此在補助國內學者出國開會的經費上
並不充裕。建議國科會能多補助學者出國開會發表論文， 以提高國內學術研究的風氣。 
 
 
 
guidelines for fair resource allocation in practical systems.
The rest of this paper is organized as follows. Section II
summarizes the related work. In Section III, we define FIVD
and present its properties. Comparative and simulation studies
are given in Section IV. Finally, we give concluding remarks
in Section V.
II. RELATED WORK
The concept of fairness is prevalent in communication
networks and computer systems. See for example a survey
in [9], where it is suggested that a main problem in intra-
networking is to eliminate unfairness inherent in the MAC
mechanisms. The most direct fairness definitions such as GPS
[1] and basic fairness [2] have binary outcomes. Under these
definitions, a resource allocation schedule is either fair or not.
In this work, we are interested in quantifying the fairness level
when the schedule is not perfectly fair.
Toward this goal, various fairness measurements have been
proposed that are derived from several different distance
measures between the allocation schedule and an idealized
schedule. Often the idealized schedule is network topology,
application, and cost dependent. Examples of these include
direct data flow throughput comparison [10][11], delay varia-
tion [12], normalized throughput and delay differentials [8],
proportional fairness based on pricing [12][13], and utility
based fairness [14]. In this work, our goal is to design a
fairness metric based on a resource allocation sequence alone
and independent of the system operation considerations.
One of the most often used long-term fairness metric is
Jain’s Index [3]. As shown in (1), it approximates the ratio
between the squares of the first and second moments of access
share xi. Since xi is aggregated over time, Jain’s index does
not quantify short-term fairness. The max-min index is also
commonly used in the literature [4][5]. It is clear that this
index cannot be used in a very short time period, since the
minimum access share approaches zero in this case.
From an information theoretic point of view, short-term
fairness measures the randomness of the resource allocation
schedule. Hence, the joint entropy [15] of the allocation
sequence could be used as a fairness index. However, it would
require multiple realizations of the allocation sequence to
compute the joint entropy. Therefore, this metric could be used
to quantify only the fairness of a scheduler, not a scheduling
sequence.
A solution to adapt Jain’s index for short-term fairness is to
evaluate the average of Jain’s index for sliding windows with
a short duration [6]. However, there is no formal analysis on
the suitability of this approach. In particular, as the window
size becomes smaller, the access share estimation becomes
increasingly inaccurate. An alternative is to count the number
of resource accesses by other hosts between two consecutive
accesses by a host. In [7], it is proposed that the distribution
of such inter-access count should be compared with an ideal
distribution. However, the comparison is quantified only by a
few simple statistics, such as the mean value, drawn from those
two distributions. In this work, we systematically study FIVD,
demonstrating its intrinsic properties such as symbol-level
granularity, perfect representation, boundedness, independence
of the population size, and independence of the unit of
measurement.
III. FAIRNESS INDEX BASED ON VARIATIONAL DISTANCE
A. Definition of FIVD
Let X be the set of all hosts and N = |X| > 1 be the
number of elements ofX . Let T be a sequence of the elements
of X with length L and T (b) be the sub-sequence of T that
contains the b elements starting from position 1 in T , b =
1, 2, . . . , L.
Define a probability distribution P T (b)(x) on T (b) as fol-
lows:
P T (b)(x) =
the number of occurrence of x in T (b)
b
,
where x ∈ X . We call P T (b)(x) the occurrence probability
of x.
We define the Occurrence Fairness Index (OFI)1 of T (b)
with the help of variational distance [15] between P T (b)(x)
and the uniform distribution,
U(x) = 1/N for all x ∈X ,
which is considered the most fair sequence.
The OFI of sequence T (b) is defined as
OFI(T (b)) =
∑
x∈X
|P T (b)(x)−U(x)|
=
∑
x∈X
∣∣∣∣P T (b)(x)− 1N
∣∣∣∣ , (2)
where | · | calculates the absolute values. It is easy to see that
OFI(T (b)) is always non-negative and is zero if and only if
P T (b)(x) is the uniform distribution.
We have the following observations upon OFI:
1) The OFI of a sequence T is the same as that of any
permutation of T . Therefore, OFI only captures the
occurrence frequency of each element, but not their
positions in the sequence.
2) The OFI of a sequence with length b = kN , where k
is a non-negative integer, reaches its minimum value 0
when each of the elements appears k times.
A resource access sequence T of length L is generated
sequentially in time, starting from one element to L elements,
where each element denotes the host that is allocated the re-
source. The sub-sequences, T (1), T (2), . . . , T (L−1), T (L) =
T , are generated subsequently. This suggests that the fairness
of the sequence T should be taken as the average of the
OFI values of the above subsequences. Hence, we define the
1A more precise term should be the Occurrence Unfairness Index, but we
follow the definitions of other earlier works and use the term “fairness.”
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.
978-1-4244-4148-8/09/$25.00 ©2009
Proof: It is sufficient to prove that OFI(T ("N + j)) is
smallest among OFIs of all sequences with length "N + j,
where 0 < j < N .
Let T (0)("N + j) be any arbitrary sequence which is not in
AT ("N + j). Recall that P T ("N+j)(x) is "/("N + j) or ("+
1)/("N + j) for any x ∈X . Let a and b be elements with the
largest and the smallest occurrence probabilities in T (0)("N+
j), respectively. Clearly, P T (0)("N+j)(a) > ("+1)/("N+j) >
1/N and P T (0)("N+j)(b) < " /("N+j) < 1/N . Then we con-
struct a new sequence T (1)("N + j) by replacing every occur-
rence of a with b in T (0)("N+j). Then P T (1)("N+j)(a) ≥ ("+
1)/("N+j) > 1/N and P T (1)("N+j)(b) ≤ "/("N+j) < 1/N .
By Lemma 1, OFI(T (1)("N + j)) < OFI(T (0)("N + j)) since
P T (0)("N+j)(b) still does not contribute to OFI(T (1)("N+j))
and P T (1)("N+j)(a) is smaller. We can continue to lower
OFI(T (n)("N+j)) to OFI(T (n+1)("N+j)) in the same fash-
ion until a sequence T (m)("N + j) whose largest occurrence
probability of any element is equal to ("+1)/("N+j). In this
case, OFI(T (m)("N + j)) = OFI(T ("N + j)). In combining
with the fact that OFI(T ("N)) = 0, the FIVD of T is the
smallest among all sequences with length L.
Theorem 4: The value of FIVD for any sequence T of
length of L with N competing hosts satisfies
FIVD(T ) ≤ 1 . (10)
Proof: We need to prove that the upper bound of FIVD
is achieved when the sequence contains only one out of the
N hosts. First we prove that the OFI of any length is bounded
above by 2−2/N . Let T be an arbitrary sequence overX with
length L. If T contains L of the same elements, by Lemma 1,
OFI(T ) = 2(1−1/N) = 2−2/N . Assume that there are more
than one elements from X in T . Let a and b be elements
with the largest and the smallest occurrence probabilities in
T , respectively. Then P T (a) ≥ 1/N and 0 < P T (b) ≤ 1/N .
We then replace every occurrence of b in T with a to obtain a
new sequence T ′. According to Lemma 1, OFI(T ′) > OFI(T )
since nonzero P T (b) does not contribute to OFI(T ), and
P T ′(a), which contributes to OFI(T ′), is larger than P T (a).
We can continue to construct a sequence with larger OFI in
the same manner until the sequence has only element a (L
of them). Hence, 2 − 2/N is an upper bound on OFI. FIVD
value of such a sequence can then be computed as
1
(L− 1)
L∑
i=2
2− 2/N − ψ(i,N)
Ψ(N)− ψ(i,N) =
1
(L− 1)
L∑
i=2
1 = 1 .
C. Discussions
Since FIVD reflects short-term fairness, it implies the re-
flection of long-term fairness. According to the definition of
FIVD given in (3), it is easy to see that FIVD can be applied
to any population size except one, whose fairness issue is
trivial. Hence, FIVD is independent of population size. By
the definition of FIVD and Theorem 1, FIVD is good for any
length of sequence (except L = 1) and follows the intuition
that the host with the lowest occurrence probability should
TABLE I
COMPARISON OF MAX/MIN FAIRNESS INDEX, JAIN’S INDEX, AND FIVD
IN SEVERAL SETS OF SEQUENCES
Sequence (T) M/m JN J2N FIVD
T1: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ∞ 0.25 0.25 1.00
T2: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 ∞ 0.26 0.25 0.99
T3: 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 ∞ 0.29 0.31 0.92
T4: 1 1 1 1 1 1 1 2 3 4 1 1 1 1 1 1 13 0.45 0.51 0.80
T5: 1 1 1 1 1 2 3 4 1 2 3 4 1 2 3 4 2.3 0.81 0.86 0.56
T6: 1 1 2 3 4 1 1 2 3 4 1 1 2 3 4 1 2.3 0.82 0.85 0.27
T7: 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 1 0.37 0.58 0.47
T8: 1 2 3 1 2 3 1 2 3 1 2 3 4 4 4 4 1 0.63 0.79 0.17
T9: 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4 1 1.00 1.00 0
be served in order to improve fairness. Hence, FIVD has the
properties of symbol-level granularity. Furthermore, Theorems
2 and 3 show that FIVD assigns the minimum value 0 to
any ideally fair sequence in AT (L). We term this property
perfect representation. Finally, since FIVD uses occurrence
probabilities and is tightly bounded between 0 and 1, it is
independent of the unit of measurement on the resource.
IV. PERFORMANCE EVALUATION
In this section, we compare the max/min fairness index,
Jain’s index, and FIVD. We present our evaluations in numer-
ical computations and ns2 simulations.
A. Numerical Computations
In our first numerical results, we compare FIVD with
max/min fairness and Jain’s indices in Table I. The max/min
fairness index was computed as the maximum occurrence
among all elements divided by the minimum occurrence
among all elements. Jain’s indices, JN and J2N , were based
on the sliding window Jain’s index [6] with window size of
N and 2N , respectively. In these sequences, there are four
hosts sharing a service (N = 4) and the sequence length is 16
(L = 16). While the max/min fairness index shows infinity for
sequences T1, T2, and T3, FIVD correctly shows that T3 is
the most fair among these three. This is because host 1 defers
to host 2 in the middle of the sequence T3. FIVD confirms
that T4 is the most fair among the first four sequences.
The comparison between T5 and T6 further illustrates
the effectiveness of FIVD to distinguish fairness among se-
quences. In T6, the access of host 1 to the service is separated
by those of the other hosts. Thus, T6 is more fair than T5, even
though both have the same occurrence frequency as reported
by max/min fairness and Jain’s indices. Interestingly, the
sliding window Jain’s index demonstrates some contradicting
conclusions with different window sizes.
Sequences T7, T8, and T9 provide insights on different
ways to arrange the same set of elements. FIVD shows T9 as
the most fair sequence among the three, as one would expect.
In contrast, the max/min fairness index treats them the same.
In Fig. 1, we present the changes of the OFI lower bounds
ψ(L,N) as a function of sequence length L and number of
hosts N . ψ(L,N) demonstrates cycles of drops to zero coin-
ciding with the cases when L is a multiple of N . Furthermore,
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.
978-1-4244-4148-8/09/$25.00 ©2009
101 102 103 104
0
0.05
0.1
0.15
0.2
0.25
Length of the Sequence, L
Fa
irn
es
s 
In
de
x 
ba
se
d 
on
 V
ar
ia
tio
na
l D
ist
an
ce
, F
IV
D
 
 
DCF simulation
Random sequence
Optimum sequence
Fig. 4. FIVD of IEEE 802.11 DCF MAC scheme. We compare the FIVD
values of a fully connected network with N = 5 active senders for 100
seconds. The FIVD values are compared with that of random sequences of
the same length and optimum sequences as suggested in Theorem 1. Note
that different position of the curve for IEEE 802.11 DCF MAC compared to
N = 30.
802.11 DCF MAC are smaller than those of random sequences.
The DCF transmission sequence of length L = 42 and N = 5
has an FIVD value around 0.15. According to our discussions
in Fig. 2 of Section IV-A, this value lies within the FIVD
values for randomly generated sequences. Therefore, we can
conclude that the IEEE 802.11 DCF MAC scheme is fair to
networks with small numbers of competing hosts, but not those
with large numbers of competing hosts.
This result can be explained with the values of the minimum
contention window (CWmin) in the IEEE 802.11 standard.
CWmin is the initial contention window each competing host
uses before it is doubled upon collisions. When the number of
competing hosts is comparable to CWmin, channel dominance
is likely to take place. This, however, is unlikely to happen
when there are only a few competing hosts, e.g., N = 5.
V. CONCLUSIONS
We have presented a new fairness index, termed Fairness
Index based on Variational Distance. FIVD computes the
average of the occurrence fairness index that is based on the
variational distance of the appearance frequency of different
hosts and that of a uniform distribution, which is considered to
give the most fair sequence. Through analysis and evaluations,
we have shown that FIVD provides a much better fairness
indication for competing hosts. Furthermore, since FIVD has
the property of symbol-level granularity, it is possible to
modify the resource allocation scheme on the fly based on
the measured fairness. We leave this as a future work.
ACKNOWLEDGMENT
This work was supported in part by UNCG new faculty
grant and by the National Science Council of Taiwan, R.O.C.,
under grants NSC 96-2221-E-305-002-MY3. Y. S. Han’s work
was partially support by his visit to LIVE lab at University of
Texas at Austin.
REFERENCES
[1] A. K. Parekh and R. G. Gallager, “A generalized processor sharing
approach to flow control in integrated services networks: the single-node
case,” IEEE/ACM Trans. Netw., vol. 1, no. 3, pp. 344–357, 1993.
[2] H. Luo, S. Lu, and V. Bharghavan, “A new model for packet scheduling
in multihop wireless networks,” in Proc. of the 6th annual ACM/IEEE
international conference on Mobile computing and networking (Mobi-
Com), August 2000.
[3] R. K. Jain, D.-M. W. Chiu, and W. R. Hawe, “A quantitative mea-
sure of fairness and discrimination for resource allocation and shared
computer system,” Technical Report DEC-TR-301, Digital Equipment
Corporation, 1984.
[4] T. Ozugur, M. Naghshineh, P. Kermani, C. M. Olsen, B. Rezvani, and
J. A. Copeland, “Balanced media access methods for wireless networks,”
in Proc. of the 4th annual ACM/IEEE international conference on
Mobile computing and networking (MobiCom), 1998.
[5] S. Chan and M. Zukerman, “A new max-min fairness definition to
neutralize malicious users,” in Proc. of the 2000 IEEE International
Conference on Communications (ICC), June 18-22 2000, vol. 3.
[6] C. E. Koksal, H. Kassab, and H. Balakrishnan, “An analysis of short-
term fairness in wireless media access protocols (poster session),” in
Proceedings of the 2000 ACM SIGMETRICS international conference
on Measurement and modeling of computer systems (SIGMETRICS),
New York, NY, USA, 2000, pp. 118–119, ACM.
[7] G. Berger-Sabbatel, A. Duda, O. Gaudoin, M. Heusse, and F. Rousseau,
“Fairness and its impact on delay in 802.11 networks,” in Proc of
the IEEE Global Telecommunications Conference (GLOBECOM), Nov.
2004, vol. 5, pp. 2967–2973.
[8] J. Eshet and B. Liang, “Randomly ranked mini slots for fair and efficient
medium access control in ad hoc networks,” IEEE Transactions on
Mobile Computing, vol. 6, no. 5, pp. 481–493, 2007.
[9] C. Douligeris and L. N. Kumar, “Access to a network channel: a
survey into the unfairness problem,” in Proc. of SUPERCOMM/ICC
’92. Discovering a New World of Communications, 1992, vol. 3.
[10] T. Nandagopal, T.-E. Kim, X. Gao, and V. Bharghavan, “Achieving MAC
layer fairness in wireless packet networks,” in Proc. of the 6th Annual
ACM International Conference on Mobile Computing and Networking
(MobiCom), August 6-11 2000.
[11] V. Kanodia, A. Sabharwal, B. Sadeghi, and E. Knightly, “Ordered packet
scheduling in wireless ad hoc networks: mechanisms and performance
analysis,” in Proceedings of the 3rd ACM International Symposium on
Mobile Ad Hoc Networking and Computing (MobiHoc), New York, NY,
USA, 2002, pp. 58–70, ACM.
[12] J. Wong, J. Sauve, and J. Field, “A study of fairness in packet-switching
networks,” IEEE Trans. on Communications, vol. 30, no. 2, pp. 346–353,
February 1982.
[13] F. P. Kelly, A. K. Maulloo, and D. K. H. Tan, “Rate control in commu-
nication networks: shadow prices, proportional fairness and stability,”
Journal of the Operational Research Society, vol. 49, 1998.
[14] M. Dianati, X. Shen, and S. Naik, “A new fairness index for radio
resource allocation in wireless networks,” in Proc. of the IEEE Wireless
Communications and Networking Conference (WCNC), March 2005,
vol. 2, pp. 712–717.
[15] T. M. Cover and J. A. Thomas, Elements of Information Theory, New
York, NY: John Wiley and Sons, 1991.
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.
978-1-4244-4148-8/09/$25.00 ©2009
Survivable Distributed Storage with Progressive
Decoding
Yunghsiang S. Han∗, Soji Omiwade‡ and Rong Zheng‡
∗ Graduate Institute of Communication Engineering, National Taipei University, Taiwan, yshan@mail.ntpu.edu.tw
∗ Department of Computer Science and Information Engineering, National Chi Nan University, Taiwan
‡ Department of Computer Science, University of Houston, Houston, TX 77204, {ooo00a,rzheng}@cs.uh.edu
Abstract—We propose a storage-optimal and computation effi-
cient primitive to spread information from a single data source
to a set of storage nodes, to allow recovery from both crash-
stop and Byzantine failures. A progressive data retrieval scheme
is employed, which retrieves minimal amount of data from live
storage nodes. The scheme adapts the cost of successful data
retrieval to the degree of errors in the system. Implementation
and evaluation studies demonstrate comparable performance to
that of a genie-aid decoding process.
Index Terms—Network storage, Byzantine failures, Reed-
Solomon code, Error-detection code
I. INTRODUCTION
Many existing approaches to survivable storage assume
crash-stop behaviors, i.e., a storage device becomes unavail-
able if failed (also called “erasure”). Solutions such as various
RAID configurations [1] and their extensions are engineered
for high read and write data throughput. Thus, typically low-
complexity (replication or XOR-based) coding mechanisms
are employed to recover from limited degree of erasure. We
argue that Byzantine failures, where devices fail in arbitrary
manner and cannot be trusted, are becoming more pertinent
with the prevalence of cheap storage devices, software bugs
and malicious attacks. Efficient encode and decode primitives
that can detect data corruption and handle Byzantine failures
serve as a fundamental building block to support higher
level abstractions such as multi-reader multi-writer atomic
register [2] in distributed systems.
In this paper, we provide a design and implementation of
a novel progressive data retrieval mechanism that is optimal
in storage and communication, and computationally efficient.
It handles Byzantine failures in storage nodes gracefully as
the probability of failures increases. The rest of the paper is
organized as follows. Background and related work is given in
Section II. Details of the incremental RS decoding algorithm
are provided in Section III. An analysis of our coding and
communication complexity is provided in Section IV. Evalu-
ation results are presented in Section V. Finally, we conclude
the paper in Section VI.
II. BACKGROUND
Our redunancy scheme is based on (n, k) MDS codes,
which can recover from any v errors if v ≤ t − # s2$,
where s is the number of erasures (unretrievable symbols) and
t = (n− k)/2 is the error-erasure correcting capability of the
code. Without loss of generality, assume that a file is divided
into k symbols, encoded into n symbols and stored at n storage
nodes, one symbol per storage node.
Encoding: Let the sequence of k information symbols in
GF (2m) be u = (u0, u1, . . . , uk−1) and u(x) be the infor-
mation polynomial of u represented as u(x) =
∑k−1
i=0 uix
i
.
The codeword polynomial, c(x), corresponding to u(x) can
be derived by multiplying u(x) with g(x), where g(x) is a
generator polynomial of an RS code [3].
Decoding: The decoding process of RS codes is more com-
plex. A complete description of decoding of RS codes can be
found in [4].
Let r(x) be the received polynomial and r(x) = c(x) +
e(x) + γ(x) = c(x) + λ(x), where e(x) =
∑n−1
j=0 ejx
j
,
γ(x) =
∑n−1
j=0 γjx
j and λ(x) =
∑n−1
j=0 λjx
j = e(x) + γ(x)
are the error, erasure and errata polynomials, respectively. Note
that g(x) and (hence) c(x) have αb,αb+1, . . . ,αb+2t−1 as
roots. This property is used to determine the error locations
and recover the information symbols.
The basic procedure of RS decoding is shown in Figure 1.
The last step of the decoding procedure involves solving a
linear set of equations, and can be made efficient by the use
of Vandermonde generator matrices [5]. Several XOR-based
erasure codes (in a field of GF(2)) have been used in storage
systems [6], [7]. But the gain in computation efficiency of
these codes is achieved by trading off fault tolerance. Also,
RAID-6 systems can recover from the loss of exactly two
disks but cannot handle Byzantine failures.
III. INCREMENTAL RS DECODING
In this section, we present the incremental RS decoding
algorithm. Compared to classic RS decoding, it utilizes in-
termediate computation results and decodes incrementally as
more symbols become available.
A. The basic algorithm
Given the received coded symbols (r0, r1, . . . , rn−1) with
erasures set to be zero, the generalized syndrome polynomial
S(x) can be calculated as [8],
S(x) =
n−1∑
j=0
rjα
jb T (x)− T (αj)
x− αj =
n−1∑
j=0
λjα
jb T (x)− T (αj)
x− αj , (1)
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
978-1-4244-5837-0/10/$26.00 ©2010 IEEE
S(!)(αi) =
n−1∑
j=0
j /∈U0
Fj
αj − αi + riα
iT ′(αi) , (9)
where T ′(x) is the derivative of T (x) and Fj = rjαjT (αj).
Details of the derivation of (9) are available [3]. Note that
T ′(αi) =
∏
j∈U0
mj "=i
(
αi − αmj) . It is easy to see that S(!)(αi)
is not related to any rj , where j ∈ U0 and j *= i. Hence,
S(!−1)(αi) = S(!)(αi) for all i ∈ U0\U!−1. This fact implies
that all sampled values in previous iterations can be directly
used in current iteration of the W-B algorithm.
Define rank[N(x),W (x)] = max[2 deg(W (x)), 1 +
2deg(N(x))]. The incremental RS decoding algorithm is
described in Algorithm 1. Upon success, the incremental
RS decoding algorithm returns k non-error symbols. The
procedure will report failure either as the result of mismatched
degree of the error locator polynomial, or insufficient number
of roots found by Chien search (Line 2). In both cases, no
further erasure decoding is required. This reduces the decoding
computation time.
IV. COMPLEXITY ANALYSIS
A. Computation complexity of decoding
In the subsequent complexity analysis, the worst case is
assumed, namely, no failure on decoding is reported in Algo-
rithm 1 (Line 2), and the algorithm runs to completion.
One polynomial division is performed in CRC checking.
Since the dividend is of degree T − 1 and the divider is of
degree r, the computation complexity of CRC checking is
O(Tr).
Let v be the number of errors when the decoding procedure
is completed. In the $th iteration, $ errors are assumed in
the data and the number of erasures is n − k − 2$. We
first need to calculate two syndrome values. This can be
obtained by the Fj calculated initially. For instance, in the
first iteration, according to (9), the computation complexity
is of O(k(n − k)) since there are k Fj’s to be calculated
and each is a product of n − k terms. In the next iteration,
two more symbols are added to (1). Hence, the updated
syndrome values can be obtained by an extra O(k)+O(n−k)
computations. To find the error-locator polynomial, the W-B
algorithm is performed two steps in each iteration with com-
plexity O($). Since we only consider software implementation,
the Chien search can be replaced by substituting a power
of α into the error-locator polynomial. It needs to test for
at most k + $ positions to locate k non-error positions such
that it takes O((k + $)$) computations. Finally, inversion of
Vandermonde matrix Gˆ requires O(k log2(k)) time [10]. In
summary, the computation in the $th iteration for $ > 1 is
Lv($) = O(k log2 k) + O(n − k) + O(k$ + $2) . Counting
for v iterations and the complexity of calculating Fj we have
O(vk log2 k)+O(k(n−k))+O(v2k)+O(v(n−k))+O(v3) .
Note the computation complexity is measured by finite field
multiplications, which is equivalent to m2 bit exclusive-ORs.
Since the correctable number of errors v is at most (n−k)/2,
Algorithm 1: Incremental RS Decoding IncrRSDecode
init : Calculate Fj given in (9) for all j /∈ U0.
$← 0; Λ˜(0)(x)← 1;
Ω˜(0)(x)← 0; Φ(0)(x)← 0,Θ(0)(x)← 1.
input : stage l, two new symbols at the (j(!)1 + 1)th, and (j
(!)
2 + 1)th
nodes
output: FAIL or non-error symbols r
begin
foreach i = 1, 2 do
x(!)i ← αj
(!)
i and y(!)i ← S(!)(x(!)i )1
end
for i = 1 to 2 do
b(!−1)i ← Ω˜(!−1)(x(!)i )− y(!)i Λ˜(!−1)(x(!)i );
if b(!−1)i = 0 then
Λ˜T (x)← Λ˜(!−1)(x); Ω˜T (x)← Ω˜(!−1)(x);
ΘT (x)← (x− x(!)i )Θ(!−1)(x);
ΦT (x)← (x− x(!)i )Φ(!−1)(x)
else
a(!−1)i ← Θ(!−1)(x(!)i )− y(!)i Φ(!−1)(x(!)i );
ΘT (x)← (x− x(!)i )Ω˜(!−1)(x);
ΦT (x)← (x− x(!)i )Λ˜(!−1)(x);
Ω˜T (x)← b(!−1)i Θ(!−1)(x)− a(!−1)i Ω˜(!−1)(x);
Λ˜T (x)← b(!−1)i Φ(!−1)(x)− a(!−1)i Λ˜(!−1)(x).
end
if rank[Ω˜T (x), Λ˜T (x)] > rank[ΘT (x),ΦT (x)] then
swap [Ω˜T (x), Λ˜T (x)]↔ [ΘT (x),ΦT (x)].
end
if i = 1 then
Ω˜(!−1)(x)← Ω˜T (x); Λ˜(!−1)(x)← Ω˜T (x);
Θ(!−1)(x)← ΘT (x), Φ(!−1)(x)← ΦT (x);
else
Ω˜(!)(x)← Ω˜T (x); Λ˜(!)(x)← Ω˜T (x);
Θ(!)(x)← ΘT (x); Φ(!)(x)← ΦT (x).
end
end
if deg(Λ˜(!)(x)) &= $ then
return FAIL;
end
NumErrorLoc = ChienSearch(Λ˜(!)(x)).
if NumErrorLoc > n− k ‖ NumErrorLoc &= deg(Λ˜(!)(x))2
then
return FAIL;
end
return k non-error symbols r;
end
the decoding complexity is at most O(k(n−k)2). For small v,
The second term O(k(n− k)) dominates, which corresponds
to syndrome computation.
B. Average communication cost of decoding
In this section, we provide a probabilistic analysis of the
cost of communication by determining the number of stages
the algorithm needs to take, and the probability of successful
execution. Given n storage nodes and (n, k) RS codes, it is
easy to see that the fewest number of storage nodes to be
accessed in the proposed scheme is k and the most is n. We
assume that the CRC checking can always detect an error if it
occurs. Without loss of generality, we assume that all failures
are Byzantine failures. s crash-stop failures can be easily
modeled by replacing n with n−s. An important metric of the
decoding efficiency is the average number of accessed storage
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
N¯(n, k) =
n−k∑
v=0
(n
v
)
pv(1− p)n−v
min(v,#n−k2 $,n−v−k)∑
i=0
(k + 2i)
( n−v
i+k−1
)(v
i
)( n
2i+k−1
) × k
i+ k
× n− v − (i+ k − 1)
n− (2i+ k − 1)
+
n−k∑
v=0
n
(n
v
)
pv(1− p)n−v
1− min(v,#
n−k
2 $,n−v−k)∑
i=0
( n−v
i+k−1
)(v
i
)( n
2i+k−1
) × k
i+ k
× n− v − (i+ k − 1)
n− (2i+ k − 1)

+
n∑
v=n−k+1
n
(n
v
)
pv(1− p)n−v . (10)
Prsuc(n, k) =
n−k∑
v=0
(n
v
)
pv(1− p)n−v
min(v,#n−k2 $,n−v−k)∑
i=0
( n−v
i+k−1
)(e
i
)( n
2i+k−1
) × k
i+ k
× n− v − (i+ k − 1)
n− (2i+ k − 1) . (11)
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35
10−3
10−2
10−1
100
101
Error probability p
to
ta
l−
tim
e 
(s)
 
 
BMA
BMA−genie
IncrRSDecode
(a) Comparing to BMA; k = 101 (b) IncrRSDecode breakdown; p = 1% (c) IncrRSDecode breakdown; p = 20%
Fig. 2. Decoding performance of IncrRSDecode
VI. CONCLUSIONS
In this paper, we developed a solution using RS codes
to spread information distributedly and redundantly for the
handling of Byzantine failures. The data retrieval procedure
is carried out in a progressive manner such that the com-
munication cost is minimized while intermediate computation
results can be utilized to greatly reduce computation cost. In
another work, we develop an analytical model to evaluate
the communication cost of our incremental data retrieval
scheme [3]. That analysis agrees with the experimental results
in this paper.
Note that the proposed scheme guarantees latency of real
time applications by collecting more data in each data retrieval,
depending on the probability that a storage node is Byzantine.
For many real time systems, energy minimization is critical,
making our scheme suitable for energy constrained devices.
Also, our scheme is desirable under high data rates as it
minimizes communication costs by retrieving only necessary
symbols.
ACKNOWLEDGMENT
Han’s work was supported by the National Science Council
of Taiwan, under grants NSC 96-2221-E-305-002-MY3 and
his visit to LIVE lab at University of Texas at Austin.
Omiwade and Zheng’s work is supported in part by NSF CNS
0546391.
REFERENCES
[1] “RAID, Redundant Array of Independent Disks,”
http://en.wikipedia.org/wiki/Redundant array of independent disks.
[2] G. R. Goodson, J. J. Wylie, G. R. Ganger, and M. K. Reiter, “Efficient
byzantine-tolerant erasure-coded storage,” in DSN ’04: Proceedings
of the 2004 International Conference on Dependable Systems and
Networks, 2004, p. 135.
[3] Y. S. Han, S. Omiwade, and R. Zheng, “Survivable distributed storage
with progressive decoding,” Technical Report UH-CS-09-17, Depart-
ment of Computer Science, University of Houston, 2009.
[4] T. K. Moon, Error Correction Coding: Mathematical Methods and
Algorithms, Hoboken, NJ: John Wiley & Sons, Inc., 2005.
[5] H. William, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery,
Numerical Recipes in C: The art of scientific computing, Cambridge
university press New York, NY, USA, 1988.
[6] Y. Lin, B. Liang, and B. Li, “Data persistence in large-scale sensor
networks with decentralized fountain codes,” in Proceedings of the 26th
IEEE INFOCOM, 2007, pp. 6–12.
[7] J. S. Plank, J. Luo, C. D. Schuman, L. Xu, and Z. Wilcox-O’Hearn, “A
performance evaluation and examination of open-source erasure coding
libraries for storage,” in FAST ’09: Proccedings of the 7th conference
on File and storage technologies, 2009, pp. 253–265.
[8] K. Araki, M. Takada, and M. Morii, “On the efficient decoding of Reed-
Solomon codes based on GMD criterion,” in Proc. of the International
Symposium on Multiple-Valued Logic, Sendai, Japan, May 1992, pp.
138–145.
[9] S. Lin and D. J. Costello, Jr., Error Control Coding: Fundamentals and
Applications, Englewood Cliffs, NJ: Prentice-Hall, Inc., 2rd edition,
2004.
[10] I. Gohberg and V. Olshevsky, “Fast algorithms with preprocessing for
matrix-vector multiplication problem,” J. Complexity, vol. 10, pp. 411–
427, December 1994.
[11] A. G. Dimakis, V. Prabhakaran, and K. Ramchandran, “Decentralized
erasure codes for distributed networked storage,” IEEE Trans. Inform.
Theory, vol. 52, no. 6, pp. 2809–2816, June 2006.
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
Fault-Tolerant and Reliable Computation
in Cloud Computing
Jing Deng† Scott C.-H. Huang‡ Yunghsiang S. Han∗ and Julia H. Deng§
†Department of Computer Science, University of North Carolina at Greensboro, Greensboro, NC 27412, USA.
‡Department of Computer Science, City University of Hong Kong, Hong Kong SAR, China.
∗Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, 106 Taiwan.
§Intelligent Automation, Inc., Rockville, MD, USA.
Abstract—Cloud computing, with its great potentials in low
cost and on-demand services, is a promising computing platform
for both commercial and non-commercial computation clients.
In this work, we investigate the security perspective of scientific
computation in cloud computing. We investigate a cloud selection
strategy to decompose the matrix multiplication problem into
several tasks which will be submitted to different clouds. In
particular, we propose techniques to improve the fault-tolerance
and reliability of a rather general scientific computation: matrix
multiplication. Through our techniques, we demonstrate that
fault-tolerance and reliability against faulty and even malicious
clouds in cloud computing can be achieved.
Index Terms—
I. INTRODUCTION
Cloud computing is heavily based on a more traditional
technology: grid computing, which has been researched for
more than 20 years. Cloud computing focuses on the shar-
ing of information and computation in a large network of
nodes, which are quite likely to be owned by different ven-
dors/companies. It is believed that cloud computing has been
one of the sources for success in several major companies such
as Google and Amazon.
Cloud computing is expected to be the platform for next
generation computing, in which users carry thin clients such
as smart phones while storing most of their data in the cloud
and submitting computing tasks to the cloud. A web browser
serves as the interface between clients and the cloud. Operating
system in web browsers allows the users to manage their data
and computation tasks.
One of the main drivers for the interest in cloud comput-
ing is cost and reliability. As personal computers and their
OS and software are becoming more and more complex,
the installation, configuration, update, and removal of such
computer systems require a significant amount of intervention
time from the users or system managers. Instead, outsourcing
the computation tasks eliminates most of such concerns. The
cloud of computer grids provides such services on fee-based,
which can be more cost-efficient for the users than purchasing,
maintaining, and upgrading powerful servers. Furthermore,
resource sharing improves overall resource usage.
Another reason is the adaptation of large number of mobile
devices including smart phones, PDAs, and Netbooks. Such
computing devices usually have high mobility and may only
be powerful enough to run just a web browser. Currently, the
users of these devices are not allowed to perform the full list
of tasks that they normally do on regular computing devices
such as desktop computers and servers. Cloud computing can
provide a seamless interface to allow the users to point their
web browsers to an address and perform the full list of usual
computing tasks such as document preparation, data query,
image processing, and scientific computation.
Overall, cloud computing brings the following three new
aspects in computing resource management: infinite comput-
ing resources available on demand for the perspective of the
end users; zero up-front commitment from the cloud users; and
short-term usage of any high-end computing resources [1], [2].
When a client submits computation tasks toward the cloud,
security of such computation naturally becomes a great con-
cern. This is mainly because the data leave the client and the
computation results will be returning from the cloud, which
are usually considered out of the client’s control. Computation
security has many perspectives [3]. In this work, we focus
on fault tolerance and reliability of scientific computation, in
particular, matrix multiplication. Matrix multiplication serves
as the foundation for many complex problem solving and
optimization. An interesting point of privacy concern arises
when the user does not want to send all computation tasks
toward a single cloud.
We investigate the question of ensuring the correctness of
matrix multiplication in cloud computing with the existence of
faulty or even malicious clouds. In particular, we focus on the
problem of dividing a complex matrix multiplication task into
several subtasks and submitting them to different clouds for
computation. Because different clouds have different cost and
reliability, the selection of such clouds becomes an interesting
problem for cost and reliability concerns.
This paper is organized as follows: in Section II, we
summarize important related works. In Sections III, IV, and
V, we investigate the issues of cloud selection and protection
against faulty and malicious clouds. Section VI, we conclude
the work.
II. RELATED WORK
The landmark paper on fault-tolerant matrix operation was
published in 1984 by Huang and Abraham [4], in which
an Algorithm-Based Fault Tolerance (ABFT) method was
proposed. ABFT uses matrix or vector level checksum in row
TABLE I
EXAMPLE OF DISPATCHING JOBS TO THREE CLOUDS WITH DIFFERENT
RELIABILITY AND COST. THE JOB HAS ℓ = 10 ROWS OF MULTIPLICATION
AND THE RELIABILITY REQUIREMENT Rs = 2.6. IT TURNS OUT THAT THE
BEST ASSIGNMENT IS (2, 8, 0) AS SHOWN IN ASSIGNMENT 6. THESE
NUMBERS ARE FOR ILLUSTRATION PURPOSE ONLY. REAL RELIABILITY
VALUES COULD BE DIFFERENT TO WHAT ARE SHOWN HERE.
Cloud1 Cloud2 Cloud3
(R, C) (1,1) (3,2) (4,3) Overall
Assignment 1 2 0 8 (3.4, 26)
Assignment 2 10 0 0 (1, 10)
Assignment 3 5 0 5 (2.5, 20)
Assignment 4 0 10 0 (3, 20)
Assignment 5 4 2 4 (2.6, 20)
Assignment 6 2 8 0 (2.6, 18)
ming problem as follows:
Minimize C =
∑L
i=1 Ciℓi
Subject to R =
(∑L
i=1Riℓi
)/
ℓ ≥ Rs (4)∑L
i=1 ℓi = ℓ ℓi is integer .
Any standard tool for solving integer programming can be
used to solve (4), e.g., lp solve [9].
We present an example of three clouds in Table I, which
shows several different assignments. Next we present some
properties of our integer programming problem which can help
to fasten the search procedure.
We have the following lemma regarding to those clouds
with higher cost but lower reliability:
Lemma 1: If there exist two clouds i and j such that
Rj ≥ Ri and Cj < Ci, then cloud i should be ignored in
the assignment process.
Proof: Without loss of generality, we assume i <
j. Assume that there is an optimal assignment A =
{ℓ1, · · · , ℓi, · · · , ℓj , · · · , ℓL} such that ℓi > 0. Construct a
new assignment A′ = {ℓ′1, · · · , ℓ′i, · · · , ℓ′j , · · · , ℓ′L}, where all
elements are the same with A except ℓi and ℓj :
ℓ′j = ℓi + ℓj
ℓ′i = 0 . (5)
Therefore, the cost and reliability of assignment A′ can be
expressed as
C(A′) =
L∑
k=1
Ckℓ
′
k =
L∑
k=1
Ckℓk + Cjℓi − Ciℓi < C(A) (6)
and
R(A′) =
L∑
k=1
Rkℓ
′
k/ℓ
=
L∑
k=1
Ckℓk/ℓ+Rjℓi/ℓ−Riℓi/ℓ
= R(A) + (Rj −Ri)ℓi/ℓ
≥ R(A) , (7)
where we have used the inequalities of Cj < Ci and Rj ≥ Ri.
Since assignment A′ has a lower cost and a reliability that
is at least as good as A, it contradicts to the assumption that
A is an optimal assignment. Hence, it is obvious that cloud i
should be ignored.
Corollary 1: If there exist two clouds i and j such that
Rj > Ri and Cj ≤ Ci, then cloud i can be ignored in the
assignment process.
The proof of Corollary 1 is similar to that of Lemma 1
and therefore omitted. Please note that the difference between
Lemma 1 and Corollary 1 is the location of the equal sign.
Therefore, we can assume a strictly increasing function in Ci
and Ri, where i ∈ {1, 2, · · · , L}. That is, C1 < C2 < · · · <
CL and R1 < R2 < · · · < RL.
It is obvious that there is no solution if Rs > RL. Hence,
in this section we assume that Rs ≤ RL. Denote the optimal
assignment A∗ = {ℓ∗1, · · · , ℓ∗L}. If Rs ≤ R1, then ℓ∗1 = ℓ and
ℓ∗i = 0 for i ̸= 1. We have the following lemmas regarding to
the case R1 < Rs ≤ RL.
Lemma 2: Given Rs ≥ Rt, t ∈ {1, 2, · · · , L− 1}. Then
t∑
i=1
ℓ∗i ≤
⌊
RL −Rs
RL −Rt ℓ
⌋
, (8)
where ⌊x⌋ is the largest integer that is no more than x.
Proof: The reliability of the assignment A∗ can be
computed as
R =
L∑
i=1
ℓ∗iRi/ℓ
=
t∑
i=1
ℓ∗iRi/ℓ+
L∑
i=t+1
ℓ∗iRi/ℓ
≤
t∑
i=1
ℓ∗iRt/ℓ+
L∑
i=t+1
ℓ∗iRL/ℓ
=
(
t∑
i=1
ℓ∗i
)
·Rt/ℓ+
[
ℓ−
(
t∑
i=1
ℓ∗i
)]
·RL/ℓ . (9)
Using inequality R ≥ Rs and re-arranging (9), we have
t∑
i=1
ℓ∗i ≤
RL −Rs
RL −Rt ℓ . (10)
And we have the following lemma:
Lemma 3: Given Rs ≤ Rt+1, t ∈ {1, 2, · · · , L− 1}. Then
t∑
i=1
ℓ∗i ≥
⌈
Rt+1 −Rs
Rt+1 −R1 ℓ
⌉
, (11)
where ⌈x⌉ is the smallest integer that is no less than x.
Proof: Detailed proof is omitted due to page limit, but
outlined below: an optimum assignment is assumed first. Then
a new assignment will be constructed based on the optimum
assignment but with a lower cost.
In the example discussed in Table I, we can see from
Lemma 2 that ℓ∗1 <
4−2.6
4−1 ×10 = 4.3. Therefore, the maximum
3
such that the number of solutions to (16) is no more than half
of the total number of possible values for (rim1 , . . . , rimq ).
That is, the probability that Cloud i to successfully forge the
computational results is no more than 1/2. Next we consider
the case |∆j | = |∆k| for j, k = 1, 2, · · · , q. It is easy to
see that if (rim1 , . . . , rj , . . . , rimq ) is a solution of (16), then
(rim1 , . . . , rj , . . . ,−rimq ) is a solution of
q−1∑
j=1
xj∆si−1+mj + xq(−∆si−1+mq ) = 0 .
Hence, we only need to evaluate the number of solutions to
q∑
j=1
xj∆ = 0 ,
where ∆ = |∆si−1+mj | for j = 1, 2, · · · , q which is
at most half of the total number of possible values for
(rim1 , . . . , rimq ). That is, a malicious cloud i can modify
computation results and trick the client to accept it with a
probability as high as 1/2.
Note that this does not mean that the malicious cloud can
always trick the client to accept any arbitrary result with
probability of 1/2. The result has to be maneuvered in a
certain way in order to achieve such a surprisingly high success
probability, e.g., modifying several rows in a certain way.
In order to protect the client’s computation from such
attacks from malicious clouds, we propose to extend the parity-
check row given in (12) to k rows. Similarly to (12), we define
a matrix Ri with dimension of k × ℓi.
Ci = Ri[asi−1+1 asi−1+2 · · · asi−1+ℓi ]T , (17)
where Ri = [rmj ], m = 1, 2, · · · k, j = 1, 2, · · · , ℓi, and
superscript T represents transposition operation. Note that the
computation of CiB can be sent to another cloud for the sake
of error isolation and malicious cloud detection. For example,
these k rows of contents can be simply attached to the end of
the ℓj row of A matrix for cloud j.
Since now there are k parity checks instead of 1, it is more
difficult for a malicious cloud to tamper with the computation
results and trick the client to accept them. Similarly, a mali-
cious cloud’s best chance is to change two rows in the results.
Without loss of generality, we can assume that the malicious
Cloud i modifies the first two rows of A sent to it with quantity
∆. By a similar argument to one parity check case,
rm1∆+ rm2∆ = 0, for m = 1, 2, . . . , k (18)
is a necessary condition for the client to accept the tampered
results. Since all rmj , m = 1, 2, · · · , k, j = 1, 2, · · · , ℓi,
are randomly generated with values 1,−1, the probability to
satisfy (18) is (1/2)k. In fact, we have the following theorem:
Theorem 2: Assume the k-parity check is implemented by
the client. If a malicious cloud tries to tamper with the
computation results, the chance that it succeeds is at most
(1/2)k.
Proof:
Assume that |∆si−1+j | ̸= |∆si−1+k| for k = 1, 2, · · · , q
and k ̸= j. By an argument similar to the case of one parity
check, we know that the probability of successfully forging
computational results is no more than
1
1 + 2q(k−1)
, (19)
where q is the number of rows of A that are modified by the
malicious cloud. Since q, k ≥ 2,
1
1 + 2q(k−1)
≤ 1
1 + 22(k−1)
≤ 1
1 + 2k
. (20)
Therefore, (19) is no greater than (1/2)k. Similarly, we can
prove that the probability is no more than (1/2)k when ∆ =
|∆si−1+mj | for j = 1, 2, · · · , q. We have just proven that the
best chance of a malicious cloud tricking the client to accept
a tampered result is (1/2)k.
VI. CONCLUSIONS
Cloud computing is expected to the next generation com-
putation platform for commercial and non-commercial users.
In this work, we have investigated the fault tolerance and
reliability issues of cloud computing in scientific computation,
in particular matrix multiplication. Our analysis showed that,
with careful design and cloud selection, computation in the
cloud can be fault-tolerant and reliable.
In our future work, we will provide simulation performance
of our scheme and compare it with other related schemes. We
will also investigate the fault tolerance and reliability issues
in a broader range of computations. The issue of privacy
protection of the client’s data and results will be studied as
well.
REFERENCES
[1] M. Armbrust, A. Fox, and et al., “Above the clouds: A berkeley view
of cloud computing,” UC Berkeley, Tech. Rep. UCB/EECS-2009-28,
February 2009.
[2] K. Birman, G. Chockler, and R. van Renesse, “Toward a cloud computing
research agenda,” SIGACT News, vol. 40, no. 2, pp. 68–80, 2009.
[3] C. Cachin, I. Keidar, and A. Shraer, “Trusting the cloud,” ACM SIGACT
News, vol. 40, no. 2, pp. 81–86, June 2009.
[4] K.-H. Huang and J. A. Abraham, “Algorithm-based fault tolerance for
matrix operations,” IEEE Transactions on Computer, vol. 33, no. 6, pp.
518–528, 1984.
[5] L. Mei, W. Chan, and T. Tse, “A tale of clouds: Paradigm comparisons and
some thoughts on research issues,” Asia-Pacific Conference on Services
Computing. 2006 IEEE, vol. 0, pp. 464–469, 2008.
[6] A. Chakrabarti, A. Damodaran, and S. Sengupta, “Grid computing
security: A taxonomy,” IEEE Security and Privacy, vol. 6, no. 1, pp.
44–51, 2008.
[7] M. J. Miller and N. H. Vaidya, “Leveraging channel diversity for key
establishment in wireless sensor networks,” in Proc. of the 25th Con-
ference of the IEEE Communications Society (Infocom ’06), Barcelona,
Spain, April 23-29 2006.
[8] C. Wang, Q. Wang, K. Ren, and W. Lou, “Ensuring data storage security
in cloud computing,” IIT, Tech. Rep., 2009.
[9] http://lpsolve.sourceforge.net/5.5/.
5
96年度專題研究計畫研究成果彙整表 
計畫主持人：韓永祥 計畫編號：96-2221-E-305-002-MY3 
計畫名稱：利用 MDS 碼在無線感測器網路上有效率建立保密通道 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 8 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 2 0 100% 
人次 
 
期刊論文 1 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
