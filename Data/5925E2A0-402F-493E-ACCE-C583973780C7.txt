 
中 文 摘 要 ： 有鑒於文件摘要的研究越來越受到重視，加上近年來以圖形
網路結構為基礎之自然語言處理技術的蓬勃發展，我們提出
「以圖形網路模型為基礎之文件摘要方法設計與研究」研究
計畫，將以三年為期的時間提出一套完整的多文件摘要技術
方法。研究重點為透過圖形化網路結構做為文件主題描述的
核心模型，利用圖形結構節點向心性(Graph-based 
Centrality)分析，達到語句排序的目的，並實際應用該技術
於摘錄式(Extraction-based)多文件摘要之研究。此外，結
合語句特徵與語句關係網路結構所形成的擴散激發機制，藉
由遞迴式網路向心性的推論，進一步得到最適當之語句排序
依據。最後，提出一套整合單文件摘要與多文件摘要技術的
彙整式文件摘要器(Meta-Summarizer)架構。實驗的部分使用
公認的 DUC 2004 測試資料集，同時比較過去比賽的結果作為
輔助，以評估本研究所提出之摘要方法的可行性。摘要方法
好壞的評估採納 ROUGE-1 作為比較的指標。結果發現本研究
所提出的各種摘要模型皆有不錯的成效。 
 
中文關鍵詞： 一般性摘要； 摘錄式摘要； 多文件摘要； 圖形網路文件模
型；網路節點向心性； 擴散激發；語句排序； 語句摘錄； 
彙整式摘要器； 
英 文 摘 要 ： Inspired that, recently, graph-based approaches have 
mushroomed and proven successful in natural language 
processing, we propose a 3-year research project, ＇A 
Study on Text Summarization Based on Network Graph 
Model,＇ to investigate and to develop graph-based 
summarization methods in MDS. The main idea is to 
model document topics in a network graph structure, 
based on which different methods (e.g., random walks) 
to assess the graph-based centrality of each node 
will be evaluated and discussed. In addition, we 
propose a meta-summarizer which integrates methods of 
SDS and MDS that had been proven effective in the 
literature. The experiments were conducted using the 
DUC 2004 data set from DUC (Document Understanding 
Conference) to examine the effectiveness of the 
proposed summarization method. Machine-generated 
summaries were evaluated on ROUGE-1 using ROUGE 
(Recall-Oriented Understudy for Gisting Evaluation) 
automatic n-gram matching. The results showed that 
the proposed methods are practical workable with 
行政院國家科學委員會補助專題研究計畫 ■成果報告   □期中進度報告 
 
 
以圖形網路模型為基礎之文件摘要方法設計與研究 
 
 
計畫類別：■個別型計畫   □整合型計畫 
計畫編號：NSC 99－2221－E－259－018－MY3 
執行期間：2010 年 8 月 1 日至 2013 年 7 月 31 日 
 
執行機構及系所：國立東華大學資訊管理學系 
 
計畫主持人：楊維邦 
共同主持人： 
計畫參與人員： 
參與時間 參與人員 
2010/8/1 – 2011/7/31 陳韋廷、戴珮汶、沈劭庭 
2011/8/1 – 2012/7/31 許筌淇、潘汝璧、紀東羿、陳珮馨 
2012/8/1 – 2013/7/31 紀嘉桐、廖皓翔、林兆宇、古宇馨、陳玫琴 
 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
□出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
 
 
 
中   華   民   國 102 年 10 月 31 日 
2 
 
最後，考量摘要長度，擷取適當數量的語句形成摘錄式摘要。在摘要萃取與生成
的過程當中，結合 CSIS(Cross-Sentence Information Subsumption)理論來處理多文
件摘要中多餘資訊量的問題，以避免在有限的摘要內容長度中納入過多重複性的
資訊。 
實驗的部分使用公認的 DUC 2004 測試資料集，同時比較過去比賽的結果作
為輔助，以評估本研究所提出之摘要方法的可行性。摘要方法好壞的評估採納
ROUGE-1 作為比較的指標。由實驗的結果發現：iSpreadRank 演算法具有最好的
結果，在各種 ROUGE 評估的結果皆得到最高的分數。當比較非遞迴式的演算
法，即 Degree 與 Normalized Similarity-based Degree 時，發現後者具有較佳的結
果；在 ROUGE-1 的指標下，Normalized Similarity-based Degree 的方法比 Degree
的方法高出 6.46%。當比較遞迴式的演算法，即 HITS、PageRank 與 iSpreadRank
時，可以發現 iSpreadRank 與 PageRank 具有較佳的結果。在 ROUGE-1 的指標下，
iSpreadRank 比 PageRank 高出 2.41%。然而，在三種演算法之中，HITS 的表現
最差。 
2. 第二年計畫: 結合語句關係網路與特徵擴散激發機制之語句排序方法及其
於文件摘要的應用 
第二年的研究計畫則延續第一年的成果，整合包含語句語意向心性
(Centroid)、語句位置 (Position)及語句與首具的相似度 (Similarity With First 
Sentence)等三種語句特徵，提出結合語句特徵與語句關係網路結構所形成的擴散
激發機制：以語句關係網路作為文件模型，各個語句節點則透過語句特徵值賦予
初始重要程度，然後藉由遞迴式網路向心性的推論，經由兩兩語句相連的網路結
構將語句的表徵重要性傳遞出去，進而影響且改變其他相連通的網路節點之語句
重要性，得到最適當之語句排序依據。 
實驗使用公認的 DUC 2004 測試資料集，以驗證本研究所提出之摘要方法的
可行性，而摘要方法的評估則採用 ROUGE-1 作為比較的指標。實驗結果發現：
(1) 使用語句特徵作為遞迴式語句向心性演算法的初始值時， iSpreadRank 比起
HITS 或 PageRank 皆具有較佳的成效；(2) 考慮不同語句特徵與其組合作為
iSpreadRank 語句向心性演算法的初始值時，在使用 Centroid、Position 與
SimWithFirst 的情況下，使用 iSpreadRank 比沒有使用 iSpreadRank 的結果分別高
4 
 
總結來說，研究發現彙整式文件摘要器的架構確實是可行的，此架構的好處
在於針對單文件進行摘要的方式，其對於資訊的保存能較著重於單一文件的主題
內容，並不會因為同時考量所有的文件而造成失真。 
關鍵詞：一般性摘要; 摘錄式摘要; 多文件摘要; 圖形網路文件模型;網路節點向
心性; 擴散激發;語句排序; 語句摘錄; 彙整式摘要器; 
6 
 
Summarization based on the Sentence Similarity Network 
The principle objective of the first-year project is to develop graph-based 
summarization methods for multidocument summarization. We propose a sentence 
similarity network, which is constructed based on the relationship between any two 
sentences, to model document topics into a network. Then, according to the network 
graph structure, five methods are developped to assess the graph-based centrality of 
each node, including: (1) Degree; (2) Normalized Similarity-based Degree; (3) HITS; 
(4) PageRank; and (5) iSpreadRank. The graph-based centrality achieves the 
possiblity of senence ranking. Finally, a summary extraction process sequentially 
examines sentences in the rank order, and adds one sentence at a time into the 
summary if it is not too similar to any sentences already in the summary, which is a 
strategy based on cross-sentence information subsumption (CSIS). 
The experiments were conducted using the DUC 2004 data set from DUC 
(Document Understanding Conference) to examine the effectiveness of the proposed 
summarization method. Machine-generated summaries were evaluated using ROUGE 
(Recall-Oriented Understudy for Gisting Evaluation) automatic n-gram matching. The 
official 1-gram, 2-gram, 3-gram, 4-gram, and the LCS- ROUGE scores were reported. 
The results showed that: (1) Normalized Similarity-based Degree is of better 
performance than Degree. The average increasement over Degree is 6.46% while 
ROUGE-1 is taken into account; (2) iSpreadRank and PageRank have similar results, 
both much superior to HITS. While ROUGE-1 is considered, iSpreadRank performs 
the best, with an average increasement of 2.41% over PageRank; (3) overall, 
iSpreadRank has the best results, compared to all the other methods. To sum up, our 
proposed methods are at the average position and obtained competitive results, when 
compared with the official results of DUC 2004. 
2. Research of the Second Year: Sentence Ranking Using Feature-Weight 
Propagation based on the Sentence Similarity Network and Its Application 
on Multidocument Summarization 
The second part of the research is an extension of the first-year project and has the 
8 
 
The experiments were conducted using the DUC 2004 data set from DUC. 
Machine-generated summaries were evaluated using ROUGE automatic n-gram 
matching. Consider ROUGE-1: The results showed that: 
(1) The length of summaries produced by single-document summarizers affects the 
quality of the meta-summary. It shows that a better setting of the length of 
single-document summaries is 5. 
(2) Among different settings of the proposed methods, it shows that P.L5_C.P has 
the best performance on ROUGE-1; C.P.SF.L5_C.SF has the best performance 
on ROUGE-2, ROUGE-3, and ROUGE-4; and finally, C.P.L5_C.SF has the best 
performance on ROUGE-L and ROUGE-W1.2. 
(3) While compared to the results of DUC 2004, around 16 systems of the proposed 
methods outperforms that of the system (SYSID=124) which was ranked the 
fifth in DUC 2004. Overall, more than 1/3 of the proposed systems demonstrate 
the good performance on the DUC 2004 dataset. 
In summary, it has been found that the proposed meta-summarizer for 
multidocument summarization is practically workable. It benefits from the 
preservation of information during the process of single-document summarization, 
which avoids information distortion while compared to the application of 
multidocument summarization directly. 
Keywords: Generic summaries; Extraction-based Summarization; Multidocument 
Summarization; Network-based Topic Model; Graph-based Node Centrality; Feature 
Weight Propagation; Sentence Ranking; Sentence Extraction; Meta-Summarizer; 
 
10 
 
統一檢索介面Google
Alta Vista
檢索結果
加值服務
檢索結果分群
…
數位典藏
文件摘要
個人化摘要
呈現
 
圖 1：資訊摘要系統運作情境示意圖 
自動摘要乃是從原始資料中精鍊出最重要資訊的過程，其結果即為該原始資
料的精簡化版本，且可作為人們或其他資訊系統的判斷與決策依據[29]。廣義來
說，自動摘要系統依原始資料之性質可以分為： 
(1) 文件摘要(Text Summarization) —原始資料為純文字； 
(2) 多媒體摘要(Multimedia Summarization) —原始資料為影像及聲音； 
(3) 複合性摘要(Hybrid Summarization) —原始資料綜合純文字和多媒體。 
然而，一般提到自動摘要通常意指文件摘要，即是將文件進行精簡化與重點化，
萃取出與文件主題相關且具有重要性的字詞或語句形成摘要內容。 
文件摘要起源於 1950 年代[9]，起初為自然語言處理(NLP, Natural Language 
Processing)的研究議題。文件摘要的技術大致可分為下列幾種： 
(1) 1950 年代至 1960 年代，研究方法著重於寫作格式的分析，例如，若語句中
含有提示片語(Cue Phrase)，如：in summary、in conclusion，該語句便會被
視為摘要語句；其優點在於簡單容易，然而此方法與文件類型相關，因此技
術的重複利用性不高。 
(2) 1970 年代至 1980 年代初期，研究方法轉而利用人工智慧來建構知識的表示
12 
 
(7) Summary Updates：具有追蹤時間性事件發展能力，以提供使用者最新的資
訊。 
(8) Effective User Interface：提供與使用者互動的介面，如個人化摘要及呈現的
模式。 
若從語言的角度來看，文件摘要也可分為單語言摘要 (Mono-lingual 
Summarization)及多語言摘要(Multi-lingual Summarization)[5][68][70]。所謂多語
言摘要係指文件來源可能為不同語言或單文件中包含不同語言等，此類摘要著重
於克服各語言在型態、結構及用語習慣的差異，並提供各語言間互相轉譯的能力。 
 
圖 2：PERSIVAL 系統的使用者介面[39] 
近年來，文件摘要除了考慮文件中的文字內容外，更致力於探討摘要內容與
圖片或影音的關係，朝向 3M 的方向前進，亦即，多語言(Multilingual)、多文件
(Multidocument)與多媒體 (Multimedia)。舉例來說，美國哥倫比亞大學發展
PERSIVAL (Personalized Search and Summarization over Multimedia Information)
系統[39]，自動將病人的就醫紀錄及資料庫中相關的醫學影像和聲音作關聯，並
且經過適當的版面設計將結果以摘要的形式呈現出來，如圖 2 所示。由圖中可以
看到文件摘要不再只侷限於純文字資訊摘取，更包括內容上下文(Context)與影
像、聲音的關係以及呈現(Presentation)。另外，該系統還考慮到個人化環境的設
計；舉例來說，病人及親屬所看到的摘要內容便與醫療人員所看到的摘要內容，
14 
 
要。國外具體的研究成果，如圖 3 與圖 4 所示。 
 
圖 4：NewsInEssence [37] 
有鑒於文件摘要的研究越來越受到重視，加上近年來以圖形網路結構為基礎
之自然語言處理技術的蓬勃發展，除了應用於資訊擷取之搜尋檢索外，同時於語
義辨析(Word Sense Disambiguity)、關鍵字抽取(Keyword Extraction)、語意關聯
(Semantic Network)等於相關的研究議題上亦有相當大的突破。因此，我們提出
「以圖形網路模型為基礎之文件摘要方法設計與研究」研究計畫。此研究將以三
年為期提出一套完整的多文件摘要技術方法，前兩年的研究重點為透過圖形化網
路結構做為文件主題描述的核心模型，利用圖形結構節點向心性(Graph-based 
Centrality)分析技術，達到語句排序的目的；同時，實際應用該技術於摘錄式
(Extraction-based)多文件摘要之研究。第三年的研究中，有感於彙整式分類系統
(Meta-Classifier)透過不同分類器的整合得到最佳的分類效果，我們引用彙整技術
的概念，首先對於每一篇文件進行摘要，再針對所有摘要進行統整產生最後的多
文件摘要內容，因而提出一套整合單文件摘要與多文件摘要技術的彙整式文件摘
要器(Meta-Summarizer)架構。 
本研究的研究成果，預期將有以下幾項重要性及好處： 
16 
 
 第二年：結合語句關係網路與特徵擴散激發機制之語句排序方法及其於文件
摘要的應用 
研究範疇：(1) 語句及文件結構特徵選取與萃取，透過機器學習與機率統計
的方法進行語句特徵的選取與萃取，設計特定的特徵幫助計算語句的權重；(2) 
整合語句特徵之 Score Function 設計，藉由特徵組合的方式設計一可用來計算語
句整體權重的 Score Function，以評估各個語句的重要性；(3) 結合語句關係網路
與語句特徵推論語句向心性，以語句關係網路作為文件的模型，各個語句節點亦
可透過特徵值賦予重要性，修改分析向心性的演算法。 
 第三年：彙整式文件摘要器(Meta-Summarizer)之研究 
研究範疇：(1) 單文件摘要器的設計，討論及分析相關文獻中單文件摘要器
的優缺點，並且設計適當的單文件摘要器；(2) 整合型摘要器(Meta-Summarizer)
的設計，結合單文件摘要器所產生的結果，進行多文件摘要器的整合設計。 
18 
 
一般領域的多文件摘要通用模組，並提供下載及線上摘要服務。NewsInEssence
是個應用於新聞領域的摘要系統，提供新聞文章的群集(Clustering)、即時搜尋、
文章摘要及視覺化(Visualization)等功能。WebInEssence 則是個整合摘要技術及
搜尋技術的通用搜尋引擎。 
 
圖 5：GLEANS 系統架構圖[7] 
南加州大學實作一套摘要系統為 GLEANS[7]。該系統將文件集中所有文件
所描述的物件及物件間關聯抽取出來，並以資料庫表格的表示法儲存；接著將文
件集分為四種不同的類別：單人物(Single Person)、單事件(Single Event)、多事件
(Multiple Event)及天然災害(Natural Disaster)；根據不同的類別，依據事先定義好
的模板產生長度較短的內容提要；最後，依照不同的類別，根據一致性(Coherence)
的關係來產生最後的摘要內容。GLEANS 最大的特點在於利用既有的模板產生
品質較佳的摘要(Abstract)。圖 5 為其系統架構，包含 Database Constructor、
Collection Classifier、Core Entity/Relation Extractor、Headline Generator、Lead 
Sentence Generator、Abstractor Generator 及 Postprocessor。 
南加州大學還發展另一套名為 NeATS (Next Generation Automated 
Summarization)[25][26]的摘要系統。該系統處理的對象為英文新聞文件，主要將
文件集中與主題相關的部分擷取出來，並且將結果以一致性的順序呈現。到目前
為止，NeATS 系統可以產生一般性摘要結果，且其結果會依序使用者所喜好的
20 
 
的順序排序以產生摘要。該方法的好處在於利用統計與機器學習的技術，並且透
過語彙鏈結將文字的語意納入考量，因此可以產生連貫性較佳的摘要。 
 
圖 7：GISTexter 系統架構[15][16] 
德州大學(The University of Texas)發展 GISTexter 摘要系統[15][16]，該系統
利用 IE(Information Extraction)的技術與外在的知識，如 WordNet 及 CICERO[6]
來分析文件中所提到的物件與事件，並且建構物件與事件間的關聯模型。摘要的
產生方式則是透過 Content Planning，套用既有的模板來產生內容連貫性與一致
性高的摘要。對單文件來說，主要是透過語句抽取(Sentence Extraction)的方式；
對多文件來說，則是將分散於多文件中的相同主題(Shared Topics)抽取出來。圖
7 為 GISTexter 的系統架構圖。 
馬里蘭大學(Maryland University)發展適用於大型文件集的摘要系統，名為
XDoX[17]，其處理的文件集大小約為 50-500 篇文章。該系統首先利用分群技術
將文件集分為幾個有意義的主題，接著以段落為單位，依據段落與主題群集間的
相關程度作分類，最後依據不同的群集產生摘要，其流程如圖 8 所示。另外，
XDoX 提供使用者兩種不同的摘要結果，一為詳細的摘要，提供較豐富的資訊；
另一個則依據使用者的需求，如壓縮比等等，提供資訊量較少的摘要。 
22 
 
相關的商業產品，如 IBM 公司發展的 Text Miner 系統[19]，該系統可以將文
件中與主題具有最相關的語句抽取出來；此外，該系統亦考慮到不同的排序策
略，分別可以在語句的層面(Sentence Level)或是字的層面(Word Level)來考慮語
句與主題的關聯程度。TextWise 公司發展 CRS(Content Repurposing Suit)套件
[47]，主要應用的範疇包含電子郵件訊息、網頁及新聞文章等等，針對不同的文
件類型及應用環境，提供使用者不同的摘要內容。Mitre 公司將文件表示為圖形，
他們將文件中所提到的概念表示成圖形中的節點，概念間的關聯表示成圖形中的
邊，並且透過圖形的配對，將相關文件中相似及相異的地方抽取出來作摘要
[27][28]。 
2.1. 以圖形結構為基礎的摘要方法 
Salton et al.[44]提出利用主題關係地圖(Text Relationship Map)作為單文件摘
要的文件模型可視為以圖形結構為基礎的摘要方法之始祖。在主題關係地圖中，
以每個段落為單位，計算兩兩段落的相似度來建構關聯地圖。當某個節點具有的
連結數目愈多，則代表該節點所對應的段落與整篇文件中的主題相關度愈高。以
此為基礎，依據連結數目的多寡決定摘錄段落的順序，且提出以下三種方法來產
生單文件摘要，分別說明如下： 
(1) Global Bushy Path 
首先定義任一節點的 Bushiness 為該節點與其他節點的連結數目；擁有越多
關聯連結的節點，表示該節點所對應的段落與其他段落所討論的主題相似，因
此，該段落可視為討論文件主題的段落。Global Bushy Path 將段落依照原本出現
在文件中的順序以及其連結個數由大而小的排列。接著，挑選排名前 K 個段落
(Top-K)，即為該文件的摘要。 
(2) Depth-Frist Path 
Depth-first Path 選取某個節點 – 可能為第一個節點或是具有最多連結的節
點，接著每次選取於原始文件中順序與該節點最接近且與該節點相似度最高的節
點當作下一個節點，依此原則選取出重要而且連續的段落以形成文件摘要。 
24 
 
挑選出重要的語句當成摘要結果。語句重要性的計算方式，如 Eq. (1)： 
  |)(| 1 }|{)(),(|)(| 1)( sci i sCommonwwscwherewweightscsscore  (1)
另一個代表是[3]使用語彙鏈結(Lexical Chains)以萃取出文件中的概念。語彙
鏈結乃是文件中具有相同意義或關聯的字詞所構成的集合，如圖 10 所示；利用
WordNet[48]中定義的字義與字詞關係決定語彙連結的類別，包括： (1) 
Extra-Strong (定義字詞與其同義字詞的關係)，(2) Strong (定義兩個字詞在
WordNet 中存在直接關聯的關係)，及(3) Medium-Strong (定義兩個字詞在
WordNet 中存在間接關聯的關係)。 
 
圖 10：語彙鏈結範例 [3]，其中{Mr., Person}表示「人」的概念，{Machine, Micro-computer, Device, 
Pump}表示「機器」的概念。 
過去以圖形結構為模型的研究一直未能引起共鳴，其原因歸咎於圖形模型的
建構過程繁瑣不易；若採用字詞關係的解析方式，更需要藉由領域知識(Domain 
Knowledge)或字典(Thesaurus)的輔助，但這類資源常因領域的差異而難以取得。
因此，傳統的文件摘要研究著重於使用語句特徵來評估語句或段落的重要性，鮮
少將文件的模型建構為網路圖形結構。近年來由於 PageRank[54]與 HITS[55]的
問世，運用網路結構來排序網頁的重要性，以獲得更佳的搜尋引擎查詢結果的排
序，相關的研究亦帶動資訊檢索和自然語言處理領域。在文件摘要的領域當中，
已有學者引用 PageRank 與 HITS 來增進文件摘要的效能和正確性；舉例來說，
LexRank[61]以 PageRank 作為多文件摘要的核心模型，經由 PageRank 的運算賦
予語句重要性，從而標示語句為摘要與非摘要語句。[60]擴充 LexRank，利用個
26 
 
3. 第一年研究：以語句關係網路為基礎之文件摘要技術研
究 
依據過去國內外相關研究的經驗，文件模型的好壞會深深影響文件摘要的結
果。過去雖然有許多建構文件模型的方法被提出，例如：語彙鏈結(Lexical 
Chain)、主題樹結構(Topic Tree Structure)、主題地圖(Text Relationship Map)等，
然就其完整性而言仍有許多需要進行突破的地方。因此，本研究的重點在於研究
如何建構完整的文件描述模型與表示法，以便於有組織性地將文件主題結構化，
奠定文件摘要技術研發的基礎。 
我們採用語句關係網路模型為基礎建構文件模型，以達到描述文件主題的目
的。同時，透過圖形結構中向心性(Centrality)分析法則，例如：Social Network 
Analysis、PageRank 等圖形演算法的輔助，判別語句的重要性及進行語句排序
(Sentence Ranking)。 
圖 11：以語句關係網路為基礎之多文件摘要架構圖 
3.1. 以語句關係網路為基礎之多文件摘要架構 
圖 11 為本研究所提出之「以語句關係網路為基礎的多文件摘要」架構，其
Topic-related 
documents 
Text Analysis 
Topic Modeling: 
Sentence Similarity 
Network 
Sentence Ranking 
Sentence Extraction 
Sentence-based 
Centrality Analysis 
Summary 
28 
 
wi, j之計算方式如 Eq. (2)所示： 
ijll
ji
ji n
N
tf
tf
w log
  max ,
,
,   
(2)
其中，tfi,j為 ti出現於 sj中的次數，maxl tfl,j代表 sj中出現最多次數之關鍵詞的次
數。log(N/ni)表示 ti的 IDF 值，其中 ni為擁有 ti的語句數量，而 N 是所有語句的
數量。關鍵詞 ti的 IDF 值越小，則代表 ti出現在越多的語句中，換句話說其重要
性越低。 
 
圖 12：語句關係網路模型範例 
3.3. 語句關係網路主題模型 
語句關係網路主題模型以語句為單位，利用前節中所描述的語句向量計算兩
兩語句間的相似程度，並且透過關聯相似度的強弱程度決定任兩語句間是否存在
連結。藉此建構語句關係網路，形成文件主題描述模型。實作上，藉由兩兩語句
向量的 cosine 值可以得到語句的關聯相似度，如 Eq. (3)所示： 
||||
),(
ji
ji
ji ss
ss
sssim 


  
(3)
30 
 
Similarity-based Degree 進一步考慮每條連結的相似度權重，其定義如下： 



),(, )(
),(
)deg(sim
ji sssimjij j
ji
i sAggSim
sssim
s
且
 
(5)
其中， 


),(,
),()(
kj sssimjkk
kjj sssimsAggSim
且
。 
Normalized Similarity-based Degree代表 si從 sj得到的投票數與其連結的相似
度總和(即，AggSim(sj))成反比。換句話說，sj的投票是平均分配給所有連結所指
向的節點，並非只獨厚節點 si。由前述可知，Normalized Similarity-based Degree
的優點在於除了考慮到每個節點的連結個數之外，亦考慮到連結的權重值貢獻。 
(3) HITS Centrality 
HITS (Hyperlink-Induced Topic Search)考慮網頁間的正向連結(forward link)
與反向連結(backlink)結構，藉此定義網頁型態的 Hubs 與 Authorities 作為網頁重
要度的依據[55]。其中，Hubs 代表連結到其他網頁的節點，而 Authorities 則為被
連結的網頁節點。HITS 的基本原理是基於一個好的 Hub 具有多個正向連結連到
好的 Authorities，且一個好的 Authority 擁有許多好的 Hubs 連結到它。 
auth(k)(p)與 hub(k)(p)分別代表網頁 p 的 Authorities 與 Hubs 的權重，假若
auth(0)(p)與 hub(0)(p)皆初始為 1，則藉由遞迴的方式計算 Eq. (6)與 Eq. (7)可得到
網頁 p 的重要性。 
Authority Update Rule: 


n
i
kk ihubpauth
1
)1()( )()(  
(6)
  
Hub Update Rule: 


n
i
kk iauthphub
1
)1()( )()(  
(7)
本研究利用 HITS 的演算法來評估語句關係網路中各個節點的重要程度。然
而考量到 HITS 所分析的網頁超連結結構具有方向性，此處我們假設語句關係網
路中的連結為雙向連結以符合 HITS 演算法的特性。 
(4) PageRank Centrality 
32 
 
接著，推論步驟中假設 X(0)為一 n×1 的向量，代表 si 的初始化重要程度，則
藉由遞迴的方式計算，最後可以得到所有語句節點在第 t 時間點的重要程度
X(t)，如 Eq. (10)所示： 
TRMtMXXtX       ),1()0()(  (10)
其中，為一擴散因子(Spreading Factor)，用來控制節點間投票的有效性。考慮
節點 A 投了一票給節點 B，若為 0.5 的話，則表示 A 投給 B 的那一票僅具有一
半的效力，即相當於 0.5 張票。實作上，我們將  設定為 0.7。R 為一隨機矩陣
(Stochastic Matrix)，如 Eq. (11)所示，其功用類似於 PageRank 用來平均分配票數
給所有正向連結所指向的節點。 









nnn
n
rr
rr
R
,1,
,11,1



 (11)
其中，  k ki
ji
ji a
a
r
,
,
, 。 
推論步驟的停止條件如下： 

i
ii tXtX |)1()(|  (12)
在實作上，我們將  設定為 0.001。 
最後，預測的步驟中，前述推論過程最後所得到的節點重要性 X(t)向量值，
即可視為所有語句最後具有的重要程度。 
3.5. 語句排序 
前節中我們介紹多種利用語句關係網路的圖形結構來評估網路節點重要性
的方法。此節的語句排序模組，即是利用前節所獲得的語句重要性將語句進行排
序，藉此作為有效地組織語句，且作為摘要語句萃取的依據。實作上，語句的排
34 
 
4. 第二年研究：結合語句關係網路與特徵擴散激發機制之
語句排序方法及其於文件摘要的應用 
 
圖 13：結合語句關係網路與語句特徵之多文件摘要架構圖 
本研究計畫為第二年期計畫「結合語句關係網路與特徵擴散激發機制之語句
排序方法及其於文件摘要的應用」，其工作重點在於擴充及整合第一年計畫的研
究成果。考量過去相關文件摘要的研究工作已大量地運用語句或文件結構等相關
的代表性特徵(Surface-level Features)，例如：語句長度、段落位置、主題字詞的
使用、與標題的相似度等等，藉由不同的方法抽取不同的特徵且假設這些特徵彼
此獨立，可以藉由整合評估的方式來評估摘錄語句或段落的資訊代表性。因此，
本年度的研究重點在於探討語句關係網路及語句特徵的關聯，以及整合語句特徵
於圖形化向心性分析演算的可能性。 
圖 13 為本計畫所提出之多文件摘要架構圖，相較於第一年研究計畫所提出
的摘要架構(參考圖 11)，其中語句特徵萃取模組(Surface-Level Feature Extraction)
與語句特徵組合(Feature Combination)模組為新增的擴充模組。由於該摘要架構
Topic-related 
documents 
Text Analysis 
 
Topic Modeling: 
Sentence Similarity 
Network 
Sentence Ranking 
Sentence Extraction 
Surface-Level 
Feature Extraction  
Summary 
Feature 
Combination 
36 
 
到每個字的 TF*IDF 值，當該值大於某個臨界值時，收集這些 TF*IDF 值大於臨
界值的字詞時，則可將此時所獲得的集合視為 Centroid 代表字詞集合。而計算語
句向心性即是計算某語句中具有的 Centroid 代表字詞的 TF*IDF 總和，如下公式
所示： 

w
iwi CC ,  (13)
其中，Ci代表語句 Si的語句向心性特徵值，Cw,i則是語句 Si中任一個 Centroid 字
詞。 
(2) 語句位置(Position) 
從文件內容結構的角度來看，文件中重要的語句通常出現於某幾個特定的位
置；舉例來說，每一段落的第一句常常會點出該段落的主題，因此，它的重要性
會比同段落中其他位置的語句還要高。因此，此語句特徵的計算方式設計如下： 
n
inPi
)1(   (14)
其中，n 代表語句 Si所屬文件的語句數量，i 則代表語句 Si於該文件中所在的位
置。舉例來說，文件中的第一句語句其 i 值為 1，第二句語句其 i 值為 2，以此
類推。 
(3) 語句與首句的相似度(Similarity With Frist-Sentence) 
延續語句位置的特徵設計概念，假設文件中第一句即破題點出文件的中心主
題，此種文章的描述方式在新聞類文章尤其常見，屬於金字塔型的描述方式。正
因如此，我們可以假設若某語句與第一句的相似度越高，其重要性也就越高。此
語句特徵的計算方式設計如下： 
ii SSSF
  1  
(15)
其中， iS

即是語句 Si於語句向量模型中所得到的語句向量。 
38 
 
分析方法；而第二種方法則試用於 iSpreadRank 語句向心性分析方法。簡單來說，
此兩種方法皆是使用語句特徵值作為遞迴式演算法的初始語句重要性，再藉由遞
迴的方式求得最後的語句節點重要性。 
40 
 
5.1. 單文件摘要器 
圖 14 的架構中可以同時選擇使用不同的單文件摘要器；例如，設計 n 種不
同的單文件摘要器，而文件 Documenti 則應用摘要器 Summarizeri 來產生單文件
摘要。考量到多種單文件摘要器的適用性，若要依據不同的文件特性選擇不同的
單文件摘要器，可能需要有事先收集的訓練資料集供分類與比對；因此，目前在
實作上本研究僅設計單一種單文件摘要器。 
單文件摘要器的目的在於針對單一文件產生摘要，以作為多文件摘要器的輸
入。因此，單文件摘要器所產生的摘要好壞會直接影響到最後彙整式摘要的品
質。有鑑於此，本研究採用文獻中已被驗證具有良好成效的模式，藉由摘要特徵
的輔助，進行語句重要性的分析與評估。本研究使用的語句特徵包含有：(1) 語
句向心性 (Centroid)； (2) 語句位置 (Position)；及  (3) 語句與首句的相似度
(Similarity With First-Sentence)等三種特徵[56]，相關說明請參考第 4.1 節的介紹，
計算語句特徵值的方法分別是 Eq. (13)、Eq. (14)與 Eq. (15)。在這些語句特徵中，
語句位置、語句與首句的相似度皆以單文件的範圍來考量，而語句向心性的計算
則是從整個輸入的文件群來萃取重要的關鍵字詞，並賦予其向心性權重值，最後
加總成為語句的向心性。考量到目前處理的範圍是單文件，本研究將語句向心性
的計算範圍修改成以單文件來萃取重要的關鍵字詞，而非以文件群來計算。 
由前述可知，每個語句特徵僅代表由各個不同的面向分析所獲得的語句重要
程度。因此，必須藉由特徵組合的方式設計一可用來計算語句整體權重的 Score 
Function，以評估各個語句的重要性。我們採用線性組合(Linear Combination)的
方式組合各個特徵值，以達到設計 Score Function 的目的。同時藉由特徵權重的
調整獲得最佳 Score Function 的解。詳請參考 Eq. (16)。 
5.2. 多文件摘要器與彙整式摘要生成 
多文件摘要器將單文件摘要器產生的所有摘要當作輸入，其所產生的摘要稱
之為「摘要的摘要(Summary of Summaries)」。此種做法的好處在於透過單文件
摘要器的處理，已經將原始的文件去蕪存菁僅保留最重要的資訊；因此，在多件
摘要的過程當中可以降低大量資訊中隱含的雜訊對於摘要器的影響，進而增進多
文件摘要的效能與摘要的品質。另外，在摘要效率方面，考量單文件摘要器可以
同時針對不同文件進行處理，再加上多文件摘要器處理的輸入已經是長度較短的
摘要，因而可大大增進摘要生成的處理速度。 
42 
 
6. 結果與討論 
6.1. 測試資料 
本研究採用 DUC (Document Understanding Conference)所公開的 DUC 2004
資料集合作為實驗的測試資料。DUC 2004 的評比共分為五個項目，依序：(1) Task 
1 – very short summaries (<= 75 bytes) for TDT English document clusters；(2) 
Task – short summaries (<= 665 bytes) for TDT English document clusters；(3) very 
short summaries (~ 10 words) for Arabic document clusters；(4) short summaries (~ 
100 words) for Arabic document clusters；(5) focused short summaries (<= 665 bytes) 
for “Who is X?” questions。其中，Task 2 及 Task 3 為多文件摘要的評比，考量我
們的方法並沒有針對極短的摘要生成進行處理，因此在實驗的部分使用 Task 2
的測試資料來評估摘要演算法的好壞。 
Task 2 的資料集包含 50 個英文新聞文件群，每個文件群約有 10 篇新聞文
章，皆取自於 AP 與 New York Times 兩家報社的新聞，且屬於同一個文件群的
新聞文章皆是討論相同的新聞事件發展，此點符合本研究的多文件摘要假設輸入
為多篇主題相關的文件(詳請參考：圖 11、圖 13 及圖 14)。Task 2 要求針對這 50
個新聞文件群個產生約 665 bytes 大小的摘要內容。DUC 2004 的資料中，每個
文件群皆由四個專家閱讀過所有文章後，針對該文件群所討論的事件主題等資
訊，以人工方式產出約 665 bytes 的短摘要作為評估用途的參考答案。 
在資料的特性方面，每個文件群平均有 266.86 個語句，每篇文章平均有 26.69
個語句。在字數方面，每個文件群平均有 6,726.88 個字，每篇文章平均有 672.69
個字，而每個語句平均有 25.21 個字。在人工摘要方面，每篇摘要平均有 3.88
個語句，換算為平均 106.48 個字。而平均每個摘要語句具有 28.21 個字。根據上
述資料統計，可換算多文件摘要壓縮比約為 1.5%。 
6.2. 評估方法 
DUC 從 DUC 2004 起採用 ROUGE (Recall-Oriented Understudy for Gisting 
Evaluation)[58]為評估工具，因此我們亦已該工具來評估演算法的好壞。ROUGE 
44 
 
由表中可知，iSpreadRank 演算法具有最好的結果，在各種 ROUGE 評估的
結果皆得到最高的分數。當僅考慮非遞迴的演算法，即比較 Degree 與 Normalized 
Similarity-based Degree，可以發現後者具有較佳的結果；在 ROUGE-1 的指標下，
Normalized Similarity-based Degree 的方法比 Degree 的方法高出 6.46%。此外，
Normalized Similarity-based Degree 的方法其各項 ROUGE 的表現皆接近於
PageRank 的方法。 
當考慮遞迴式的演算法時，亦即比較 HITS、PageRank 與 iSpreadRank 時，
可以發現 iSpreadRank 與 PageRank 具有較佳的結果，且在 ROUGE-1 的指標下，
iSpreadRank 比 PageRank 高出 2.41%。在三種演算法之中，HITS 表現最差，甚
至比 Rand. Baseline 的結果還要糟糕。猜測其原因是 HITS 的演算法以計算節點
的 indegree 與 outdegree 為基礎，然而在本研究中的語句網路結構將連結視為雙
向連結，無法有效反應出出正向與反向連結的差異，使得 HITS 得到最差的結果。 
表 2: DUC 2004 的部分比賽結果(ROUGE-1) 
SYSID ROUGE-1 95% Conf. Interval 
H 0.41828 [0.40193,0.43463] 
F 0.41246 [0.39161,0.43331] 
E 0.41038 [0.38817,0.43259] 
D 0.40594 [0.38700,0.42488] 
B 0.40428 [0.37946,0.42910] 
A 0.39325 [0.37218,0.41432] 
C 0.39039 [0.37149,0.40929] 
G 0.38902 [0.36793,0.41011] 
65 0.38224 [0.36941,0.39507] 
104 0.37443 [0.36354,0.38532] 
35 0.37430 [0.36121,0.38739] 
19 0.37386 [0.36080,0.38692] 
124 0.37064 [0.35782,0.38346] 
2 (NIST Baseline) (Rank: 25/35) 0.32419 [0.30922,0.33916] 
Best Machine (SYSID=65) 0.38224 [0.36941,0.39507] 
Median Machine (SYSID=138) 0.34299 [0.32805,0.35793] 
Worst Machine (SYSID=111) 0.24190 [0.23038,0.25342] 
Avg. of Human Assessors 0.40300 [0.38247,0.42353] 
表 2 列出 DUC 2004 的比賽結果，其中 SYSID 代表不同的參賽系統，字母
A-H 代表專家所作的摘要與其他專家的摘要比較結果，數字代表當年度參賽的摘
要系統代碼。由此表可知，我們所提的摘要方法中，iSpreadRank 的結果介於 Best 
Machine 與 Median Machine 之間，評估的結果約為中等以上。總結來說，本研究
的方法當中，Normalized Similarity-based Degree、PageRank 及 iSpreadRank 皆有
不錯的表現，其結果比 DUC 2004 的 Median Machine 的表現皆來得佳。 
46 
 
表 5: 線性結合遞迴式語句向心性分析與語句位置特徵的文件摘要演算法實驗結果 
Models ROUGE-1 ROUGE-2 ROUGE-3 ROUGE-4 ROUGE-L ROUGE-W1.2 
HITS+Position 0.34876 
[+- 0.01755] 
0.07524 
[+- 0.01109]
0.02644 
[+- 0.00602]
0.01225 
[+- 0.00426]
0.36076 
[+- 0.01548] 
0.12398 
[+- 0.00558] 
PageRank+Position 0.38088 
[+- 0.01375] 
0.09669 
[+- 0.00940]
0.03625 
[+- 0.00628]
0.01681 
[+- 0.00426]
0.38552 
[+- 0.01274] 
0.13350 
[+- 0.00464] 
iSpreadRank+Position 0.37976 
[+- 0.01244] 
0.09559 
[+- 0.00932]
0.03595 
[+- 0.00638]
0.01665 
[+- 0.00450]
0.38335 
[+- 0.01141] 
0.13256 
[+- 0.00416] 
 
表 6: 使用 Centroid(C), Position(P)及 SimWithFirst(SF)語句特徵作為遞迴式語句向心性演算法之
初始值，並比較 PageRank 與 iSpreadRank 兩種語句向心性分析的文件摘要演算法實驗結果 
Models ROUGE-1 ROUGE-2 ROUGE-3 ROUGE-4 ROUGE-L ROUGE-W1.2 
PageRank(C) 0.35891 
[+- 0.01610] 
0.08034 
[+- 0.01147]
0.02636 
[+- 0.00622]
0.01149 
[+- 0.00386]
0.36229 
[+- 0.01558] 
0.12474 
[+- 0.00577] 
PageRank(P) 0.36993 
[+- 0.01449] 
0.08523 
[+- 0.01033]
0.02861 
[+- 0.00556]
0.01171 
[+- 0.00366]
0.37488 
[+- 0.01463] 
0.12939 
[+- 0.00516] 
PageRank(SF) 0.37146 
[+- 0.01289] 
0.09035 
[+- 0.00955]
0.03232 
[+- 0.00637]
0.01421 
[+- 0.00435]
0.37402 
[+- 0.01233] 
0.12950 
[+- 0.00454] 
iSpreadRank(C) 0.36722 
[+- 0.01414] 
0.08269 
[+- 0.00925]
0.02686 
[+- 0.00542]
0.01137 
[+- 0.00371]
0.36732 
[+- 0.01466] 
0.12612 
[+- 0.00507] 
iSpreadRank(P) 0.37756 
[+- 0.01432] 
0.09201 
[+- 0.00969]
0.03268 
[+- 0.00599]
0.01433 
[+- 0.00403]
0.38027 
[+- 0.01331] 
0.13134 
[+- 0.00485] 
iSpreadRank(SF) 0.37052 
[+- 0.01149] 
0.09052 
[+- 0.00909]
0.03321 
[+- 0.00589]
0.01527 
[+- 0.00410]
0.37932 
[+- 0.01153] 
0.13132 
[+- 0.00425] 
 
表 7: 使用 Centroid(C), Position(P)及 SimWithFirst(SF)三種語句特徵與其組合作為 iSpreadRank 遞
迴式語句向心性演算法之初始值的文件摘要演算法實驗結果 
Models ROUGE-1 ROUGE-2 ROUGE-3 ROUGE-4 ROUGE-L ROUGE-W1.2 
C 0.35033 
[+- 0.01679] 
0.07411 
[+- 0.00991]
0.02546 
[+- 0.00563]
0.01179 
[+- 0.00381]
0.34905 
[+- 0.01523] 
0.12011 
[+- 0.00529] 
iSpreadRank (C) 0.36722 
[+- 0.01414] 
0.08269 
[+- 0.00925]
0.02686 
[+- 0.00542]
0.01137 
[+- 0.00371]
0.36732 
[+- 0.01466] 
0.12612 
[+- 0.00507] 
P 0.36524 
[+- 0.01234] 
0.08373 
[+- 0.00743]
0.02990 
[+- 0.00458]
0.01298 
[+- 0.00289]
0.37823 
[+- 0.01177] 
0.13071 
[+- 0.00473] 
iSpreadRank (P) 0.37756 
[+- 0.01432] 
0.09201 
[+- 0.00969]
0.03268 
[+- 0.00599]
0.01433 
[+- 0.00403]
0.38027 
[+- 0.01331] 
0.13134 
[+- 0.00485] 
SF 0.36524 
[+- 0.01234] 
0.08373 
[+- 0.00743]
0.02990 
[+- 0.00458]
0.01298 
[+- 0.00289]
0.37823 
[+- 0.01177] 
0.13071 
[+- 0.00473] 
iSpreadRank (SF) 0.37052 
[+- 0.01149] 
0.09052 
[+- 0.00909]
0.03321 
[+- 0.00589]
0.01527 
[+- 0.00410]
0.37932 
[+- 0.01153] 
0.13132 
[+- 0.00425] 
C+P 0.36974 
[+- 0.01167] 
0.09383 
[+- 0.00898]
0.03491 
[+- 0.00558]
0.01562 
[+- 0.00399]
0.37210 
[+- 0.01103] 
0.12200 
[+- 0.00395] 
iSpreadRank (C+P) 0.37701 
[+- 0.01272] 
0.08930 
[+- 0.00831]
0.03148 
[+- 0.00520]
0.01372 
[+- 0.00378]
0.37564 
[+- 0.01301] 
0.12998 
[+- 0.00455] 
C+SF 0.36923 
[+- 0.01176] 
0.09270 
[+- 0.00882]
0.03425 
[+- 0.00527]
0.01533 
[+- 0.00390]
0.37220 
[+- 0.01099] 
0.12229 
[+- 0.00403] 
iSpreadRank (C+SF) 0.37821 
[+- 0.01270] 
0.09067 
[+- 0.00870]
0.03258 
[+- 0.00548]
0.01494 
[+- 0.00394]
0.37740 
[+- 0.01232] 
0.13046 
[+- 0.00454] 
P+SF 0.36524 
[+- 0.01234] 
0.08373 
[+- 0.00743]
0.02990 
[+- 0.00458]
0.01298 
[+- 0.00289]
0.37823 
[+- 0.01177] 
0.13071 
[+- 0.00473] 
iSpreadRank (P+SF) 0.37355 
[+- 0.01292] 
0.09153 
[+- 0.00900]
0.03308 
[+- 0.00586]
0.01526 
[+- 0.00416]
0.37861 
[+- 0.01262] 
0.13104 
[+- 0.00463] 
C+P+SF 0.37333 
[+- 0.01151] 
0.09189 
[+- 0.00834]
0.03417 
[+- 0.00516]
0.01562 
[+- 0.00394]
0.37716 
[+- 0.01126] 
0.13063 
[+- 0.00416] 
iSpreadRank (C+P+SF) 0.38068 
[+- 0.01264] 
0.09281 
[+- 0.00946]
0.03324 
[+- 0.00623]
0.01523 
[+- 0.00456]
0.37985 
[+- 0.01280] 
0.13147 
[+- 0.00471] 
48 
 
2.27%。最後當考慮 C+P+SF 的組合時，使用 iSpreadRank 比沒有使用 iSpreadRank
的結果高出 1.97%。由此可知，本研究所提出的結合語句特徵作為 iSpreadRank
演算法之初始設定的方法，其對於文件摘要的結果能夠獲得較佳的結果。 
表 8 列出 DUC 2004 的比賽結果，其中 SYSID 代表不同的參賽系統，字母
A-H 代表專家所作的摘要與其他專家的摘要比較結果，數字代表當年度參賽的摘
要系統代碼。由此表可知，我們所提的摘要方法中，iSpreadRank 的結果介於 Best 
Machine 與 Median Machine 之間，評估的結果約為中等以上。總結來說，實驗結
果可以歸納出本研究所提出的結合語句特徵與 iSpreadRank 遞迴式語句向心性的
文件摘要方法，其結果比 DUC 2004 的 Median Machine 的表現皆來得佳。 
6.5. 第三年研究實驗結果 
彙整式摘要的產生是將單文件摘要視為單一文件，並且對於所有單文件摘要
進行多文件摘要處理，進而產生最後的摘要輸出。若是單文件摘要的長度過短，
則多文件摘要的過程中用以分析的資訊便可能不足；若是單文件摘要的長度過
長，則多文件摘要的過程中可能會因為資訊的重複性高而導致品質不佳的摘要產
出。考量到單文件摘要的長度可能會影響到彙整式摘要的品質，實驗中將探討找
出適當的單文件摘要長度。根據第 6.1 節的說明，輸入的文件每篇平均有 26.69
個語句；考量單文件摘要適用的壓縮比約為 1%  30%左右[22][14]，以此為標準
計算設定可能的單文件摘要壓縮比約 5% (約 1.35 句)、10% (約 2.7 句)、20% (約
5.4 句)、30% (約 8.1 句)，最後設定單文件摘要的語句總數約 1、3、5、10 句。 
考量到實驗過程中設定各種變數，包含：(1) 單文件摘要的語句總數；(2) 單
文件摘要器的種類；及(3) 多文件摘要器的種類。各種不同的組合會影響到最後
產生摘要的品質。為了分辨起見，在進行實驗結果討論之前，首先說明摘要模型
的種類。本研究定義摘要模型為 Eq. (17) 
SDS.LK_MDS (17)
其中， SDS  {SDS_C, SDS_P, SDS_SF, SDS_C.P, SDS_C.SF, SDS_P.SF, 
SDS_C.P.SF}，K  {1, 3, 5, 10}，MDS  {MDS_C, MDS_P, MSD_SF, MSD_C.P, 
MDS_C.SF, MDS_P.SF, MDS_C.P.SF}。舉例來說，SDS_P 代表以語句位置為特
50 
 
表 11、表 12、表 13、表 14、表 15 及表 16 共六個表格，分別是在 K = 5 的
設定下，搭配各種單文件摘要及多文件摘要模型的 ROUGE-1、ROUGE-2、
ROUGE-3、ROUGE-4、ROUGE-L 及 ROUGE-W1.2 的數值。舉例來說，表 11
的第 5 欄第 8 列是 C.P.SF.L5_C.P 模型，其 ROUGE-1 是 0.37068。整體來看，
P.L5_C.P 在 ROUGE-1 的標準下表現最佳；C.P.SF.L5_C.SF 在 ROUGE-2、
ROUGE-3 及 ROUGE-4 的標準下表現最佳；C.P.L5_C.SF 在 ROUGE-L 和
ROUGE-W1.2 的標準下表現最佳； 
表 11: 在 K = 5 的設定下，搭配各種單文件摘要及多文件摘要模型的 ROUGE-1 
Model *_C *_P *_SF *_C.P *_C.SF *_P.SF *_C.P.SF Avg. 
C.L5_* 0.36054 
[+- 0.01765] 
0.36671 
[+- 0.01506] 
0.36705 
[+- 0.01508]
0.36374 
[+- 0.01548]
0.36294 
[+- 0.01507]
0.36543 
[+- 0.01424] 
0.36415 
[+- 0.01510]
0.36437 
[+- 0.01538]
P.L5_* 0.37038 
[+- 0.01234] 
0.36621 
[+- 0.01381] 
0.36626 
[+- 0.01407]
0.37554 
[+- 0.01296]
0.37151 
[+- 0.01319]
0.36504 
[+- 0.01401] 
0.37248 
[+- 0.01390]
0.36963 
[+- 0.01347]
SF.L5_* 0.36138 
[+- 0.01387] 
0.36527 
[+- 0.01314] 
0.36568 
[+- 0.01268]
0.37300 
[+- 0.01241]
0.37312 
[+- 0.01218]
0.36566 
[+- 0.01279] 
0.37033 
[+- 0.01421]
0.36778 
[+- 0.01304]
C.P.L5_* 0.36567 
[+- 0.01600] 
0.36782 
[+- 0.01355] 
0.36863 
[+- 0.01361]
0.37262 
[+- 0.01213]
0.37515 
[+- 0.01089]
0.36736 
[+- 0.01374] 
0.37368 
[+- 0.01190]
0.37013 
[+- 0.01312]
C.SF.L5_* 0.36049 
[+- 0.01490] 
0.36440 
[+- 0.01506] 
0.36446 
[+- 0.01513]
0.36573 
[+- 0.01537]
0.37127 
[+- 0.01283]
0.36357 
[+- 0.01513] 
0.37072 
[+- 0.01287]
0.36581 
[+- 0.01447]
P.SF.L5_* 0.37142 
[+- 0.01344] 
0.36447 
[+- 0.01373] 
0.36287 
[+- 0.01345]
0.37349 
[+- 0.01291]
0.37058 
[+- 0.01352]
0.36323 
[+- 0.01378] 
0.37170 
[+- 0.01380]
0.36825 
[+- 0.01352]
C.P.SF.L5_* 0.36377 
[+- 0.01537] 
0.36538 
[+- 0.01486] 
0.36516 
[+- 0.01420]
0.37067 
[+- 0.01469]
0.37297 
[+- 0.01292]
0.36509 
[+- 0.01471] 
0.37308 
[+- 0.01333]
0.36802 
[+- 0.01430]
Avg. 0.36481 
[+- 0.01480] 
0.36575 
[+- 0.01417] 
0.36573 
[+- 0.01403]
0.37068 
[+- 0.01371]
0.37108 
[+- 0.01294]
0.36505 
[+- 0.01406] 
0.37088 
[+- 0.01359]
0.36771  
[+- 0.01390]
 
表 12: 在 K = 5 的設定下，搭配各種單文件摘要及多文件摘要模型的 ROUGE-2 
Model *_C *_P *_SF *_C.P *_C.SF *_P.SF *_C.P.SF Avg. 
C.L5_* 0.07902 
[+- 0.01071] 
0.08373 
[+- 0.00827] 
0.08388 
[+- 0.00826]
0.08525 
[+- 0.01022]
0.08483 
[+- 0.01005]
0.08321 
[+- 0.00813] 
0.08418 
[+- 0.00945]
0.08344 
[+- 0.00930]
P.L5_* 0.08389 
[+- 0.00812] 
0.08124 
[+- 0.00781] 
0.08152 
[+- 0.00778]
0.08980 
[+- 0.00802]
0.08984 
[+- 0.00930]
0.08091 
[+- 0.00780] 
0.08943 
[+- 0.00947]
0.08523 
[+- 0.00833]
SF.L5_* 0.08178 
[+- 0.00873] 
0.07997 
[+- 0.00749] 
0.08003 
[+- 0.00765]
0.09127 
[+- 0.00822]
0.09013 
[+- 0.00858]
0.08014 
[+- 0.00771] 
0.08851 
[+- 0.00921]
0.08455 
[+- 0.00823]
C.P.L5_* 0.08281 
[+- 0.01007] 
0.08122 
[+- 0.00876] 
0.08157 
[+- 0.00841]
0.09052 
[+- 0.00786]
0.09085 
[+- 0.00841]
0.08110 
[+- 0.00861] 
0.08965 
[+- 0.00861]
0.08539 
[+- 0.00868]
C.SF.L5_* 0.08032 
[+- 0.00953] 
0.08286 
[+- 0.00848] 
0.08264 
[+- 0.00803]
0.08803 
[+- 0.00958]
0.08945 
[+- 0.00835]
0.08230 
[+- 0.00840] 
0.08781 
[+- 0.00861]
0.08477 
[+- 0.00871]
P.SF.L5_* 0.08512 
[+- 0.00887] 
0.08062 
[+- 0.00853] 
0.07948 
[+- 0.00829]
0.09035 
[+- 0.00832]
0.08951 
[+- 0.00913]
0.07970 
[+- 0.00847] 
0.08879 
[+- 0.00935]
0.08480 
[+- 0.00871]
C.P.SF.L5_* 0.08096 
[+- 0.00920] 
0.08226 
[+- 0.00758] 
0.08195 
[+- 0.00765]
0.08951 
[+- 0.00838]
0.09192 
[+- 0.00873]
0.08197 
[+- 0.00778] 
0.08981 
[+- 0.00918]
0.08548 
[+- 0.00836]
Avg. 0.08199 
[+- 0.00932] 
0.08170 
[+- 0.00813] 
0.08158 
[+- 0.00801]
0.08925 
[+- 0.00866]
0.08950 
[+- 0.00894]
0.08133 
[+- 0.00813] 
0.08831 
[+- 0.00913]
0.08481 
[+- 0.00862]
 
 
 
52 
 
表 16: 在 K = 5 的設定下，搭配各種單文件摘要及多文件摘要模型的 ROUGE-W1.2 
Model *_C *_P *_SF *_C.P *_C.SF *_P.SF *_C.P.SF Avg. 
C.L5_* 0.12465 
[+- 0.00586] 
0.12961 
[+- 0.00508] 
0.12980 
[+- 0.00503]
0.12795 
[+- 0.00551]
0.12778 
[+- 0.00562]
0.12926 
[+- 0.00482] 
0.12807 
[+- 0.00532]
0.12816 
[+- 0.00532]
P.L5_* 0.12880 
[+- 0.00433] 
0.13208 
[+- 0.00456] 
0.13209 
[+- 0.00453]
0.13181 
[+- 0.00492]
0.13209 
[+- 0.00439]
0.13144 
[+- 0.00439] 
0.13213 
[+- 0.00444]
0.13149 
[+- 0.00451]
SF.L5_* 0.12558 
[+- 0.00458] 
0.13060 
[+- 0.00435] 
0.13064 
[+- 0.00461]
0.13218 
[+- 0.00467]
0.13259 
[+- 0.00463]
0.13068 
[+- 0.00442] 
0.13174 
[+- 0.00446]
0.13057 
[+- 0.00453]
C.P.L5_* 0.12676 
[+- 0.00524] 
0.13098 
[+- 0.00431] 
0.13148 
[+- 0.00422]
0.13061 
[+- 0.00516]
0.13266 
[+- 0.00444]
0.13101 
[+- 0.00424] 
0.13219 
[+- 0.00429]
0.13081 
[+- 0.00456]
C.SF.L5_* 0.12502 
[+- 0.00501] 
0.13103 
[+- 0.00459] 
0.13103 
[+- 0.00463]
0.12796 
[+- 0.00532]
0.13169 
[+- 0.00451]
0.13067 
[+- 0.00464] 
0.13149 
[+- 0.00407]
0.12984 
[+- 0.00468]
P.SF.L5_* 0.12875 
[+- 0.00492] 
0.12978 
[+- 0.00487] 
0.12911 
[+- 0.00472]
0.13192 
[+- 0.00465]
0.13227 
[+- 0.00432]
0.12915 
[+- 0.00454] 
0.13245 
[+- 0.00440]
0.13049 
[+- 0.00463]
C.P.SF.L5_* 0.12620 
[+- 0.00461] 
0.12991 
[+- 0.00486] 
0.12974 
[+- 0.00493]
0.13070 
[+- 0.00540]
0.13239 
[+- 0.00473]
0.12970 
[+- 0.00485] 
0.13224 
[+- 0.00428]
0.13013 
[+- 0.00481]
Avg. 0.12654 
[+- 0.00494] 
0.13057 
[+- 0.00466] 
0.13056 
[+- 0.00467]
0.13045 
[+- 0.00509]
0.13164 
[+- 0.00466]
0.13027 
[+- 0.00456] 
0.13147 
[+- 0.00447]
0.13021 
[+- 0.00472]
表 11、表 12、表 13、表 14、表 15 及表 16 的最右邊欄及最後一列代表不同
模型的 ROUGE 平均值。例如：表 11 的第 4 列之最右邊欄 Avg.值為 0.36778，
代表 SF.L5_* 在各種多文件摘要模型下的平均 ROUGE-1；表 11 的第 3 欄之最
後一列 Avg.值為 0.36575，代表  *_P 在各種單文件摘要模型下的平均
ROUGE-1。依據前述的平均值來進行各種摘要模型的排行，如表 17 與表 18 所
示，分別是在 K = 5 的設定下，各種單文件摘要搭配不同多文件摘要模型之平均
值，以及各種多文件摘要搭配不同單文件摘要模型之平均值，其在各種不同評比
標準之排名。由表 17 得知，以單文件摘要模組來說，其表現依序是 P.L5_* > 
C.P.L5_* > C.P.SF.L5_* > P.SF.L5_* > SF.L5_* > C.SF.L5_* > C.L5；而以表 18
來看，各種多文件摘要模組類型的表現依序是*_C.SF > *_C.P.SF > *_C.P > *_P > 
*_SF > *_P.SF = *_C。 
表 17: 在 K = 5 的設定下，各種單文件摘要搭配不同多文件摘要模型之平均值，其在各種不同評
比標準之排名 
 Rank on 
ROUGE-1 
Rank on 
ROUGE-2 
Rank on 
ROUGE-3
Rank on 
ROUGE-4
Rank on 
ROUGE-L
Rank on 
ROUGE-W1.2 
Avg. Rank
C.L5_* 7 7 7 6 7 7 6.83 
P.L5_* 2 3 1 1 1 1 1.50 
SF.L5_* 5 6 6 7 3 3 5.00 
C.P.L5_* 1 2 4 4 2 2 2.50 
C.SF.L5_* 6 5 5 4 6 6 5.33 
P.SF.L5_* 3 4 3 2 4 4 3.33 
C.P.SF.L5_* 4 1 2 2 5 5 3.17 
 
 
 
 
54 
 
表 20: 以各種多文件摘要模型搭配不同單文件摘要模型之平均值排名為基準，計算不同多文件摘
要模型的 Pearson 相關係數 
*_C *_P *_SF *_C.P *_C.SF *_P.SF *_C.P.SF 
*_C 1.00 
*_P -0.87 1.00 
*_SF -0.66 0.91 1.00 
*_C.P 0.67 -0.92 -0.96 1.00 
*_C.SF -0.63 0.55 0.42 -0.55 1.00 
*_P.SF -0.87 0.75 0.45 -0.58 0.55 1.00 
*_C.P.SF -0.71 0.82 0.93 -0.85 0.45 0.41 1.00 
 
表 21: 以各種單文件摘要模型搭配不同多文件摘要模型之平均值排名為基準，計算不同單文件摘
要模型的 Spearman 相關係數 
C.L5_* P.L5_* SF.L5_* C.P.L5_* C.SF.L5_* P.SF.L5_* C.P.SF.L5_* 
C.L5_* 1.00 
P.L5_* 0.31 1.00 
SF.L5_* -0.67 0.16 1.00 
C.P.L5_* -0.57 -0.58 0.62 1.00 
C.SF.L5_* 0.71 0.02 -0.95 -0.78 1.00 
P.SF.L5_* 0.71 0.20 -0.72 -0.45 0.58 1.00 
C.P.SF.L5_* 0.27 -0.52 -0.86 -0.38 0.81 0.33 1.00 
 
表 22: 以各種多文件摘要模型搭配不同單文件摘要模型之平均值排名為基準，計算不同多文件摘
要模型的 Pearson 相關係數 
*_C *_P *_SF *_C.P *_C.SF *_P.SF *_C.P.SF 
*_C 1.00 
*_P -0.87 1.00 
*_SF -0.67 0.90 1.00 
*_C.P 0.74 -0.91 -0.94 1.00 
*_C.SF -0.63 0.55 0.42 -0.66 1.00 
*_P.SF -0.87 0.75 0.45 -0.61 0.55 1.00 
*_C.P.SF -0.71 0.82 0.95 -0.89 0.45 0.41 1.00 
表 23 列出 DUC 2004 的比賽結果，其中 SYSID 代表不同的參賽系統，字母
A-H 代表專家所作的摘要與其他專家的摘要比較結果，數字代表當年度參賽的摘
要系統代碼。由此表可知，我們所提的摘要方法中，P.L5_C.P 與 C.P.L5_C.SF 表
現佳，兩者的評比結果雖然比當年度的第 1 名系統(SYSID=65)差，但卻都比當
年度的第 2 名系統(SYSID=104)優。整體來看，在所有我們所提出的摘要方法中，
共有 16 個模型評比結果都比當年度的第 5 名系統(SYSID=124)來得好；而這 16
個系統約佔全部系統的 32.65%，換句話說，在所有我們所提出的摘要方法中共
有超過 1/3 強的系統表現都不錯。 
 
 
56 
 
7. 結論 
第一年研究 
第一年計畫：以語句關係網路為基礎之文件摘要技術研究，我們利用兩兩
語句間的關聯程度決定語句間是否存在網路連結，進而建立語句關係網路作為文
件主題的模型，達到描述文件主題的塑模目的。接著以圖型網路結構為基礎，提
出包含：(1) Degree；(2) Normalized Similarity-based Degree；(3) HITS；(4) 
PageRank；(5) iSpreadRank 等五種的網路節點向心性評估的方法，用以判別語句
節點的重要性，進而達成語句排序的效果。最後，考量摘要長度擷取適當數量的
語句形成摘錄式摘要。在摘要萃取與生成的過程當中，結合 CSIS(Cross-Sentence 
Information Subsumption)理論處理多文件摘要中多餘資訊量的問題，以避免在有
限的摘要內容長度中納入過多重複性的資訊。 
實驗的部分使用公認的 DUC 2004 測試資料集，同時比較過去比賽的結果作
為輔助，以評估本研究所提出之摘要方法的可行性。摘要方法好壞的評估採納
ROUGE-1 作為比較的指標。ROUGE 以專家所產出的摘要當參考答案，對照機
器所產出的摘要內容，主要計算有平均有多少個字(Word)被專家與機器所產生的
摘要所共同包含。由實驗的結果發現：iSpreadRank 演算法具有最好的結果，在
各種 ROUGE 評估的結果皆得到最高的分數。當比較非遞迴式的演算法，即
Degree 與 Normalized Similarity-based Degree 時，發現後者具有較佳的結果；在
ROUGE-1 的指標下，Normalized Similarity-based Degree 的方法比 Degree 的方法
高出 6.46%。當比較遞迴式的演算法，即 HITS、PageRank 與 iSpreadRank 時，
可以發現 iSpreadRank 與 PageRank 具有較佳的結果。在 ROUGE-1 的指標下，
iSpreadRank 比 PageRank 高出 2.41%。然而，在三種演算法之中，HITS 的表現
最差。  
第二年研究 
第二年計畫：結合語句關係網路與特徵擴散激發機制之語句排序方法及其於
文件摘要的應用，主要是擴充及整合第一年計畫的研究成果。考量在第一年所提
出的語句排序方法僅以網路結構來評估語句的重要性，然而過去相關文件摘要的
58 
 
SimWithFirst 時，使用 iSpreadRank 比沒有使用 iSpreadRank 的結果分別高出
4.82%、3.37%及 1.45%。考慮 C+P、C+SF、P+SF 時，使用 iSpreadRank 比
沒有使用 iSpreadRank 的結果分別高出 1.97%、2.44%及 2.27%。最後當考慮
C+P+SF 的組合時，使用 iSpreadRank 比沒有使用 iSpreadRank 的結果高出
1.97%。 
總結來說，研究發現藉由擴散激發的網路傳遞效應，可以有效地將由單文件
中萃取得到的特徵值轉化為多文件語意主題層面的特徵重要性，進而得到比僅由
網路節點向心性的語句排序方法更佳的語句排序效果與摘要的品質。 
第三年研究 
第三年計畫：彙整式文件摘要器(Meta-Summarizer)之研究，有感於分類系統
常用的彙整式分類(Meta-Classification)概念的成功，在分類的過程中採用各種不
同的分類演算法進行初步的分類，再藉由整合的方式獲得最終的分類結果。依此
想法，本研究提出彙整式文件摘要器的架構，由多個單文件摘要器(SingleDoc 
Summarizer)及一個多文件摘要器(MultiDoc Summarizer)所組成；其中，單文件摘
要器依不同目的對於單一輸入文件產生單文件摘要，而所有的單文件摘要則當成
是多文件摘要器的輸入，從而產生最後的摘要內容。 
在單文件與多文件摘要模組的設計部分，本研究採用文獻中已被驗證具有良
好成效的模式，藉由摘要特徵的輔助，進行語句重要性的分析與評估。本研究使
用的語句特徵包含有：(1) 語句向心性(Centroid)；(2) 語句位置(Position)；及 (3) 
語句與首句的相似度(Similarity With First-Sentence)等三種特徵[56]，最後利用線
性組合的方式形成語句重要性分析的計算。藉由特徵組合的方式設計一可用來計
算語句整體權重的 Score Function，以評估各個語句的重要性。單文件摘要與多
文件摘要模組的差異在於：(1) 單文件摘要使用的語句向心性，其計算範圍以單
文件來萃取重要的關鍵字詞，而非以文件群來計算。而多文件摘要中的語句向心
性，主要以摘要文件群為分析範圍，從中萃取重要的關鍵字詞，並賦予其向心性
權重值，最後加總成為語句的向心性。(2) 單文件摘要不需處理資訊重複的問
題，而多文件摘要則引用 CSIS [56]理論來過濾重複性的資訊。 
實驗的部分使用公認的 DUC 2004 測試資料集，同時比較過去比賽的結果作
60 
 
內容，並不會因為同時考量所有的文件而造成失真。 
7.1. 成果自評 
關於成果效益的部分，說明如下： 
(1) 學術成就方面 
第一年的研究提出一套完整的以圖形網路模型為基礎之文件摘要方法，研究
的範疇涵蓋包含：文件主題模型的塑模、圖形結構中節點向心性的評估、以及結
合圖形網路結構的特性，且針對多文件摘要研發適切的摘要技術。 
第二年的研究延伸第一年以圖形網路模型為基礎之文件摘要方法的研究成
果，探討語句關係網路及語句特徵的關聯，並提出適當的方法整合語句特徵於圖
形化向心性分析，以獲得較佳的語句排序方法。 
第三年的研究引用分類系統採用各種不同的分類演算法進行初步的分類，再
藉由整合的方式獲得最終的分類結果之概念，提出彙整式文件摘要器的架構，將
所有文件的單文件摘要視為多文件摘要器的輸入，從而產生最後的摘要內容。 
(2) 技術創新方面 
在第一年的研究中提出以語句關係網路的圖形結構作為文件主題模型，此種
做法有別於傳統文件摘要研究，對於文件主題模型的建構採用語句分群的技術來
萃取主題。另外，過去大多數文件摘要技術的研發均利用語句或段落的特徵擷取
來進行語句重要性的評估，例如：語句於文中的出現位置、語句與首句的語意相
似度等，本研究結合圖形結構來評估網路節點的向心性，進而賦予語句相對應的
重要性。 
第二年的研究延續第一年的成果，考量過去大多數文件摘要技術的研發均利
用語句或段落的特徵擷取來進行語句重要性的評估，例如：語句於文中的出現位
置、語句與首句的語意相似度等，藉由不同的方法抽取不同的特徵且假設這些特
徵彼此獨立，可以藉由整合評估的方式來評估摘錄語句或段落的資訊代表性。本
62 
 
參考文獻 
[1] C. Aone, M. E. Okurowski, J. Gorlinsky, and B. Larsen (1999), "A Trainable 
Summarizer with Knowledge Acquired from Robust NLP Techniques," In I. 
Mani and M. Maybury (eds), Advances in Automated Text Summarization, MIT 
Press, pp. 71-80, 1999. 
[2] S. Azzam, K. Humphreys, and R. Gaizauskas (1999), "Using Coreference 
Chains for Text Summarization," In Proceedings of the ACL'99 Workshop on 
Coreference and Its Applications, Baltimore, June, 1999. 
[3] R. Barzilay, and M. Elhadad (1997), "Using Lexical Chains for Text 
Summarization," In Proceedings of the Workshop on Intelligent Scalable Text 
Summarization, Madrid, Spain, August, 1997. 
[4] H. H. Chen and S. J. Huang (1999), "A Summarization for Chinese News from 
Multiple Sources," In Proceedings of 4th International Workshop on 
Information Retrieval with Asia Language, pp. 1-7, 1999. 
[5] H. H. Chen, and C. J. Lin (2000), "A Multilingual News Summarizer," In 
Proceedings of 18th International Conference on Computational Linguistics, pp. 
159-165, 2000. 
[6] CICERO. Available at 
http://www.utexas.edu/depts/classics/documents/Cic.html. 
[7] Daume III, A. Echihabi, D. Marcu, D. S. Munteanu, and R. Soricut (2002), 
"GLEANS: A Generator of Logical Extracts and Abstracts for Nice 
Summaries," In DUC Workshop on Text Summarization, Philadelphia, 
Pennsylvania, USA, 2002. 
[8] DUC (Document Understanding Conference). Available at 
http://www-nlpir.nist.gov/projects/duc/index.html. 
[9] H. P. Edmundson (1968), "New Methods in Automatic Extracting," In I. Mani 
and M. Maybury (eds), Advances in Automated Text Summarization, MIT Press, 
pp. 23-42, 1999. 
[10] J. Goldstein, M. Kantrowitz, V. Mittal, and J. Carbonell (1999), "Summarizing 
64 
 
Workshop Information Retrieval with Asian Languages, ACM, 2000. 
[22] J. Kupiec, J. Pedersen, and F. Chen (1995), "A Trainable Document 
Summarizer," In SIGIR, ACM, Seattle, WA, USA, 1995. 
[23] T. K. Landauer, P. W. Foltz, and D. Laham (1998), "An Introduction to Latent 
Semantic Analysis," In Discourse Processes, Vol. 25, pp. 259-284, 1998. 
[24] C. Y. Lin (1999), "Training A Selection Function for Extraction," In CIKM, 
ACM, Kansas City, MO, USA, 1999. 
[25] C. Y. Lin, and E. Hovy (2001), "NEATS: A Multidocument Summarizer," In 
DUC Workshop on Text Summarization, New Orleans, Louisiana, USA, 2001. 
[26] C. Y. Lin, and E. Hovy (2002), "NeATS in DUC 2002," In DUC Workshop on 
Text Summarization, Philadelphia, Pennsylvania, USA, 2002. 
[27] I. Mani, and E. Bloedorn (1997), "Multi-document Summarization by Graph 
Search and Matching," In Proceedings of the 10th National Conference on 
Artificial Intelligence, Providence, RI, pp. 623-628, 1997. 
[28] I. Mani, and E. Bloedorn (1998), "Multi-document Summarization by Graph 
Search and Matching," In AAAI, 1998. 
[29] I. Mani, and M. Maybury (1999), "Advances in Automated Text 
Summarization," MIT Press, 1999. 
[30] K. R. McKeown, R. Barzilay, D. Evans, V. Hatzivassiloglou, M. Yen Kan, B. 
Schiffman, S. Teufel (2001), "Columbia Multi-Document Summarization: 
Approach and Evaluation," In DUC Workshop on Text Summarization, New 
Orleans, Louisiana, USA, 2001. 
[31] K. McKeown, D. Evans, A. Nenkova, R. Barzilay, V. Hatzivassiloglou, B. 
Schiffman, S. Blair-Goldensohn, J. Klavans, and S. Sigelman (2002), "The 
Columbia Multi-Document Summarizer for DUC 2002," In DUC Workshop on 
Text Summarization, Philadelphia, Pennsylvania, USA, 2002. 
[32] K. McKeown, J. Klavens, V. Hatzivassiloglou, R. Barzilay, and E. Eskin (1999), 
"Towards Multidocument Summarization by Reformulation: Progress and 
Prospects," In AAAI, 1999. 
[33] K. R. McKeown, and D. R. Radev (1995), "Generating Summaries of Multiple 
News Articles," In SIGIR, ACM, Seattle Washington, USA, 1995. 
66 
 
[45] H. G. Silber, and K. R. McCoy (2000), "Efficient Text Summarization Using 
Lexical Chains," In IUI, ACM, New Orleans, LA, USA, 2000. 
[46] SUMMAC (TIPSTER Text Summarization Evaluation Conference). Available 
at http://www.itl.nist.gov/iaui/894.02/related_projects/tipster_summac/. 
[47] TextWise CRS. Availablt at http://www.textwise.com/solutions/crs/. 
[48] WordNet. Available at http://www.cogsci.princeton.edu/~wn/. 
[49] Y. Yang, T. Pierce, and J. Carbonell (1998), "A Study on Retrospective and 
On-Line Event Detection," In Proceedings of the 21st Annual International 
ACM SIGIR Conference on Research and Development in Information 
Retrieval, Melbourne, Australia, August 1998. 
[50] J. Y. Yeh, H. R. Ke, and W. P. Yang (2002), "Chinese Text Summarization Using 
A Trainable Summarizer and Latent Semantic Analysis," In Proceedings of the 
5th  International Conference on Asian Digital Libraries, Singapore, 2002. 
[51] Z. Zhang, S. Blair-Goldensohn, and D. R. Radev (2002), "Towards 
CST-enhanced Summarization," In AAAI2002, August 2002. 
[52] M. F. Porter, “An Algorithm for Suffix Stripping,” Program, 14(3), 130-137, 
1980. 
[53] Language Technology Group, “LT TTT2,” 
http://www.ltg.ed.ac.uk/software/lt-ttt2/.  
[54] Brin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual Web 
search engine. Computer Networks and ISDN Systems, 30(1-7), 107-117. 
[55] Kleinberg, J. (1999). Authoritative sources in a hyperlinked environment. 
Journal of the ACM, 46(5), 604-632. 
[56] Radev, D. R., Jing, H., Styś, M., & Tam, D. (2004). Centroid-based 
summarization of multiple documents. Information Processing & Management, 
40(6), 919-938. 
[57] Anderson, J. R. (1983). A spreading activation theory of memory. Journal of 
Verbal Learning and Verbal Behavior, 22, 261-295. 
[58] Lin, C-Y. 2004. ROUGE: a Package for Automatic Evaluation of Summaries. 
Proc. of the Workshop on the Text Summarization Branches Out (WAS), 
Barcelona, Spain, 2004. 
68 
 
[70] 蘇哲君, 與陳信希 (2001), "中英雙語多文件自動摘要系統研究," 碩士論文, 
國立台灣大學資訊工程研究所, 台北, 台灣, 2001. 
99年度專題研究計畫研究成果彙整表 
計畫主持人：楊維邦 計畫編號：99-2221-E-259-018-MY3 
計畫名稱：以圖形網路模型為基礎之文件摘要方法設計與研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際
已達成數)
本計畫
實際貢
獻百分
比 
單位 
備註（質化說明：如
數 個 計 畫 共 同 成
果、成果列為該期刊
之封面故事...等）
期刊論文 1 1 100% 
1. 葉鎮源、楊維邦、柯
皓 仁 、 鄭 培
成, ＇＇＇＇＇＇＇＇
應用語句關係網路計算
語句向心性之新聞事件
摘 要 方
法＇＇＇＇＇＇＇＇, 
Submitted to 資訊管
理學報. 
研究報告/技術報告 3 3 100% 
1. 第一年計畫精簡報
告 (2011.5) 
2. 第二年計畫精簡報
告 (2012.5) 
3. 第三年計畫完整報
告 (2013.10) 
研討會論文 1 1 100% 
篇 
1. 葉鎮源、楊維邦、柯
皓仁、鄭培成、游正
豪, ＇＇＇＇＇＇＇＇
以圖形網路模型為基礎
之新聞事件摘要方
法＇＇＇＇＇＇＇＇, 
2013 資訊管理實務研
討會, pp. 323-340. 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 8 8 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
國外 
論文著作 
專書 0 0 100% 章/本  
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
(1)學術成就方面 
第一年的研究提出一套完整的以圖形網路模型為基礎之文件摘要方法，研究的範疇涵蓋包
含：文件主題模型的塑模、圖形結構中節點向心性的評估、以及結合圖形網路結構的特性，
且針對多文件摘要研發適切的摘要技術。 
第二年的研究延伸第一年以圖形網路模型為基礎之文件摘要方法的研究成果，探討語句關
係網路及語句特徵的關聯，並提出適當的方法整合語句特徵於圖形化向心性分析，以獲得
較佳的語句排序方法。 
第三年的研究引用分類系統採用各種不同的分類演算法進行初步的分類，再藉由整合的方
式獲得最終的分類結果之概念，提出彙整式文件摘要器的架構，將所有文件的單文件摘要
視為多文件摘要器的輸入，從而產生最後的摘要內容。 
 
(2)技術創新方面 
在第一年的研究中提出以語句關係網路的圖形結構作為文件主題模型，此種做法有別於傳
統文件摘要研究，對於文件主題模型的建構採用語句分群的技術來萃取主題。另外，過去
大多數文件摘要技術的研發均利用語句或段落的特徵擷取來進行語句重要性的評估，例
如：語句於文中的出現位置、語句與首句的語意相似度等，本研究結合圖形結構來評估網
路節點的向心性，進而賦予語句相對應的重要性。 
第二年的研究延續第一年的成果，考量過去大多數文件摘要技術的研發均利用語句或段落
