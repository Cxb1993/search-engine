II 
 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■  達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他：（以 100 字為限） 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
本計劃研發以視覺為基礎之虛擬觸控人機互動介面技術，如期完成下列之成
果：虛擬觸控、虛擬滑鼠、虛擬鍵盤。 
本計畫的成果為遠距協同作業提供智慧型的人性化互動介面，可以做為高齡
者遠距居家照護高齡者更便捷的人機互動介面，以提升生活品質。 
這些成果將可直接或間接助益資訊通訊產業，包含：視訊會議、遠距照護等
遠距協同作業應用之技術提升與應用開發；另外，對於結合投影機與攝影機
的裝置，開發以視覺為基礎之虛擬觸控人機互動介面的新興應用，也可透過
計畫的執行，在此技術領域搶得先機。 
 
 
附件二 
IV 
 
英文關鍵詞 
Virtual touché, human-computer interaction interface, Computer vision, virtual mouse, 
Kernel density estimation, Hidden Markov model, Hough transform, virtual 
keyboards. 
英文摘要 
Touch technology is a trend in many consumer electronic products. Most of 
touch technologies use the touch screen as input device. However, many limitations 
exist in touch screen, such as screen size, cost, portability, and scalability. Handheld 
projector (also known as a pocket projector or mobile projector or pico projector) is 
an emerging technology. Through the handheld projector, the image or video can be 
projected to anywhere. Based on the integration of cameras and projectors, this 
project proposes a novel human-computer interaction (HCI) interface. The new HCI 
interface uses projectors to project image or video on anywhere. Then, cameras are 
used to capture the fingertip images. Computer vision techniques detect and track the 
fingertip to recognize the finger behaviors. Based on the fingertip behaviors, virtual 
touch, virtual mouse, and virtual keyboard can be developed. Additionally, based on 
the portability and scalability of projectors, the new HCI interface can be used in 
anytime and anywhere. Thus, mobile computing can be realized. 
We propose two new HCI interface technology:[1] First, We use webcam to 
capture hand gesture pictures and simulate mouse manipulation. The system employs 
moving object detection, shadow detection, and skin color detection to obtain the 
hand region from captured images. Kernel density estimation (KDE) and many 
features on hand contour are used to recognize the mouse manipulation based on hand 
gestures. Additionally, the system also includes the mouse gesture recognition. It is 
able to recognize four kinds of mouse gestures by a mouse gesture recognition system 
based on hidden Markov model (HMM.)[2] Secondly, we use a webcam to analyze 
fingertip touching actions. Firstly, we use hough transform to locate the virtual 
keyboard. Then, we separate the finger and the shadow to get the information such as 
trajectory, direction, speed and the distance between the fingertip and the shadow. 
Afterwards, we consider touches under two different conditions when shadow exists 
and shadow does not exist. We use the distance between the finger and the shadow to 
detect touches when shadow exists, and use the variation of trajectory and the time 
property to detect touches when shadow does not exist. Finally, we validate these 
touches by their locations and the frequency of touches. 
Experimental results show that the proposed method provides two feasible way to 
detect touches on several kinds of the virtual keyboards and virtual mouse. Moreover, 
the proposed method can be used in real-time applications.   
VI 
 
圖     目     錄 
 
圖 一，微型投影機，(a) Microvision  Mobile Device with Picop display，(b) Optoma 
行動投影機。 資料來源：Microvision, Inc. [3] and Optoma Corp. [4] ............ 2 
圖 二，滑鼠手勢定義 .................................................................................................. 3 
圖 三，Visual Panel System. ........................................................................................ 4 
圖 四，Virtual keyboard ............................................................................................... 4 
圖 五，vision gesture based virtual keyboard system .................................................. 5 
圖 六，Virtual Keyboard (a) Virtual Devices, Inc. (b) Virtual Laser Keyboard. ......... 5 
圖 七，WUW-Wear Ur World- A Wearable Gestural Interface and applications。 .... 6 
圖 八，A N95 mobile phone and a PK101 projector ................................................... 6 
圖 九，Plasma Display with a Machine Vision Interface ............................................ 7 
圖 十，系統技術關聯圖 .............................................................................................. 8 
圖 十一，Codebook Background Modeling Algorithm ............................................... 9 
圖 十二，指尖偵測，(a) 移動物件偵測結果，(b) 膚色偵測結果，(c) 指尖偵測
結果。 .................................................................................................................. 10 
圖 十三，指尖與投影平面座標幾何關係 ................................................................ 11 
圖 十四，投影平面指尖觸控偵測示意圖。(a) 原始影像，(b) segmentation 結果。
 .............................................................................................................................. 11 
圖 十五，筆勢 Pen-Down, Pen-Up 的分析。 ......................................................... 12 
圖 十六，模擬滑鼠指令系統流程圖。 .................................................................... 12 
圖 十七，KDE 使用不同頻寬對機率密度函數的影響。(a) Bandwidth = 0.1。(b) 
Bandwidth = 0.25。[44] ...................................................................................... 14 
圖 十八，滑鼠指令判斷的系統流程圖。 ................................................................ 15 
圖 十九，長軸參考點 ................................................................................................ 16 
圖 二十，四種滑鼠手勢，圓點為筆劃起點。(a) 上一頁。(b) 下一頁。(c) 重新
整理。(d) 關閉分頁。 ....................................................................................... 16 
圖 二十一，滑鼠手勢辨識系統流程圖。 ................................................................ 16 
圖 二十二，手寫軌跡前處理程序流程圖。 ............................................................ 18 
圖 二十三，Five-point area [48]。 ............................................................................ 18 
圖 二十四，模擬滑鼠動作之實驗環境。 ................................................................ 25 
圖 二十五，四種滑鼠手勢，圓點為筆劃起點。(a) 上一頁。(b) 下一頁。(c) 重
新整理。(d) 關閉分頁。 ................................................................................... 26 
圖 二十六，背景圖 (a)3*3 數字鍵盤；(b)5*6 英文字母鍵盤。 .......................... 27 
 
  
 1. 
 
一、 前言 
在現有的協同作業技術當中，傳統的視訊會議是最為普遍使用的工具，但這
僅能提供聲音與影像的傳輸與播放，缺乏智慧型的互動支援能力。然而，通訊
(telecommunication)的概念正逐漸由傳統的電話(telephony)進展到遠距協同作業
(tele-collaboration)，再進展到沈浸式協同作業(immersive collaboration)；沈浸式
協同作業指的是提供使用者一個接近真實的協同作業環境，而要提供接近真實的
環境，則需要多種智慧型互動機制的支援；而以視覺為基礎之虛擬觸控人機互動
介面技術，在近幾年來則廣為各方所注意，也是更接近人性化的一種互動機制。 
根據市調機構國際數據資訊公司（IDC）的資料顯示，蘋果的 iPhone 推出短
短幾年間，到 2009 年上半年，iPhone 市占率已達 11.7%。IDC 分析師指出，市
占率不高的蘋果公司，因為擅長技術創新，領先業界推出智慧型人機介面觸控式
螢幕，使得 iPhone 所向無敵。智慧型人機介面使得 iPhone 手機興起，蘋果 2009
年第三季利潤激增 47%，而 Nokia 則陷入虧損。由此可知人機互動與介面技術大
幅提昇行動裝置之可用性(Usability)與使用者可親性，也同時創造其價值差異。 
而另一方面，微型投影機(Handheld projector, also known as a pocket projector 
or mobile projector or pico projector) [1]的發展則是顯示(display)產業的重要趨勢，
其可取代面板做輸出，國內外所有重要相關公司都看好其未來；根據科技產品市
調機構 iSuppli 最近發表的研究報告指出，由於微型投影機能克服智慧型手機等
行動電子裝置的顯示面板體積限制問題，可放映大尺寸影像，預期至 2013 年，
內建式微型投影機的出貨量，將可望由 2009 年的不到 5 萬顆，大幅成長 60 倍，
變成超過 300 萬顆[2]；美商 TI（ 德儀）、3M、Microvison 等 3 大陣營的下游
廠商紛紛推出口袋型微投影機（Pico Projector），包括手機、數位相機、筆電品
牌廠商也開始或計畫導入內建式微投影機，藉此提高產品的附加價值，可以想像
未來會有許多手機、Netbook、Notebook、PDA、PC 等資訊產品，將會連同攝
影機一樣，也把微型投影機當做標準配備，如此可允許使用者自筆記型電腦、智
慧型手機或 PDA 直接作投影簡報，如圖一所示。 
  
  
之上
辨識
past
不用
合虛
影在
而虛
(sel
合攝
的應
 
三
型運
偵測
透過
乃是
動作
Com
三種
會議
作來
者介
尖，
尖的
，可開發
(virtual p
e, undo, re
透過滑鼠
擬觸控技
平面上(白
擬滑鼠則
ect)、拖曳
配合本計
影機的電
用。 
、 文獻
在過去已
算與判斷
(motion d
攝影機擷
一項可行
虛擬滑鼠
，也就是
puter & G
的滑鼠手
 
Robertson
論文，但
模擬滑鼠
面--Visua
透過 pane
3D 資訊
虛擬滑鼠(v
en gesture
do, insert, 
操控瀏覽器
術，可進一
板或布幕)
是使用者可
(drag)、點擊
畫的研發項
腦視覺與投
探討
有不少研究
，以進行有
etection)擷
取影像，並
的辦法。 
乃是利用攝
由手指直接
raphics 期
勢，如圖二
 et al. [19] 
該篇論文只
的行為。Z
l Panel 的概
l 的幾何關
，以實現虛
irtual mou
)，可將一篇
換頁、放大
，只要動動
步研發虛
，使用者直
利用指尖
(click)、
目，我們將
影機的輸
 
團隊，透過
關手勢辨識
取到手部區
結合電腦視
影機擷取
取代滑鼠
刊裡面，就
所示，透過
圖 二
於 2004 年
是 hand g
hang et al. 
念，透過
係，可以決
擬鍵盤、虛
3. 
se) 做滑鼠
投影文章
、縮小、
食指尖往
擬鍵盤(vir
接在投影
，直接在投
雙擊(doubl
可提供協
出，則可創
攝影機做
的研究[5
域，再透
覺技術以
手指影像，
功能，Ko 
曾經提出
不同的手指
，滑鼠手勢
也提出 Vi
esture 的應
[20] 於 20
攝影機持續
定出 pan
擬滑鼠等
游標(curs
用指尖做
點選網頁等
上往下就
tual keybo
平面上用指
影平面上
e click)等功
同作業環境
造與實現
為輸入裝置
]-[16]，其
過分類器進
實現虛擬鍵
由手指的形
and Yang 
這樣的人機
形狀變化
定義 
rtual mous
用，並未真
01 年也提出
偵測與追
el 的擺放位
功能，如圖
or) 定位，
 copy, de
功能，或
能夠瀏覽網
ard)，將鍵
尖做文字
模擬滑鼠行
能。 
的互動關
更多 Mob
，及電腦
通常透過膚
行手勢的
盤、虛擬
狀變化直
[18] 在其
介面出來
，代表不同
e vision bas
正透過手
一套 visi
蹤一個矩形
置與角度
三所示。
加上指尖筆
lete, transp
讓使用者可
頁。另外
盤影像直接
輸入及控
為，如：選
鍵技術；而
ile Compu
視覺執行智
色[17]與移
辨識；因此
滑鼠等功能
接對應到滑
1997 年發表
，他們定義
的滑鼠動作
ed interfac
指的形狀與
on-based 使
的 panel 與
，進而決定
 
勢
ose, 
以
，結
投
制；
取
結
ting
慧
動
，
，
鼠
在
了
。 
 
e 的
動
用
指
指
  
攝影
辨識
[27]
生一
鍵盤
等電
圖
互動
等人
辨識
並在
該系
來，
在牆
 
而在業界
機的虛擬
使用者敲
 也研發出
張虛擬的
上做輸入
腦或行動
 六，Vir
 
而有關結
介面，目
[28], [29]
人機介面
指尖上套
統，可以在
並利用指尖
上，用手指
圖 五，v
產品的研發
鍵盤，投影
到哪個按鍵
一種 Virtu
laser keyb
，該產品可
裝置上。 
(a) 
tual Keybo
合攝影機與
前國際上只
 於 2009 年
系統，如圖
上不同顏色
任何時間
的動作偵
的動作對
ision gestur
上，Virtu
設備將鍵盤
做輸入，
al Laser Ke
oard，如圖
搭配用在
ard (a) Virt
投影機的
有少部分
發表了一
七所示，該
的套環(co
、任何地點
測，直接做
地圖做操作
5. 
e based vir
al Devices,
圖像投影
如圖六(a)所
yboard 產品
六(b)所示
Blackberry
ual Device
硬體設備，
單位有投入
套名為 WU
系統結合
lor marke
，將影像
輸入，如
；圖七左
tual keyboa
 Inc. [26] 研
至桌面，然
示；另外
，它使用
，使用者便
, Smartpho
s, Inc. (b) V
開發以視覺
發展；M
W-Wear U
了穿戴式的
rs)，以利指
、視訊、或
圖七右上角
下角，則是
 
rd system 
發出了一
後，攝影
，I-Tech V
laser beam
可直接在
ne and PD
(b)
irtual Lase
為基礎之
IT Media 
r World- 
微型投影
尖的偵測
是應用程
所示，可
把計算機
項利用投影
機擷取指尖
KB techno
打在桌面上
該虛擬的雷
A, MAC or
r Keyboard
虛擬觸控人
Lab. 的 M
的穿戴式手
機與攝影機
與辨識，透
式投影顯示
以把地圖投
的程式介面
及
，
logy 
產
射
 PC
 
. 
機
istry
勢
，
過
出
影
投
  
SIG
幕的
以偵
置，
而也
的討
是簡
(tou
為基
虛擬
究均
計畫
遠距
術則
術，
而是
關懷
GRAPH 會
方法，如圖
測手指是
 
圖
 
經由上述
開發以視覺
可以知道
論中可以
單地投影
ch wall)平台
礎之指尖
滑鼠、及子
可於該虛
一的多模
協同作業
可用以支
使高齡著的
能提供更
。 
 
議中，Mor
九所示，
否碰觸螢幕
 九，Pla
的文獻介紹
為基礎之
基於視覺的
發現，這些
在桌面上、
的研發則
虛擬觸控的
計畫三之
擬觸控技術
態語者辨識
之多模態人
援應用於子
居家照護
人性化的溝
rison [32]提
其在顯示器
及軌跡追
sma Displa
與討論，我
虛擬觸控人
指尖虛擬
系統不是
或是戴一個
是更為少見
研發，則為
指尖筆勢辨
平台上實
技術與子
機智慧型
計畫五高
功能，不只
通工具，使
7. 
出了結合
四個角落
蹤。 
y with a M
們可以了
機互動介
觸控，還是
需要指尖操
容易辨識
。因此，
本計畫的
識、手寫
現，如圖十
計畫四所提
互動技術；
齡者遠距居
是簡單地
老人更能
顯示器與攝
裝設攝影機
achine Visi
解到，結合
面，乃是目
一項相當有
作在預先
的指環；而
在本計畫的
重點關鍵
文字辨識
所示。這些
供的網路
最後，本計
家照護系
與冰冷的生
與在外地工
影機以偵
，透過影
on Interfac
了投影機
前一項新興
挑戰性的
設定的 pan
國內外對
規劃研究
技術；之後
、多重螢幕
技術的開
服務，以整
畫之人機
統，以提供
理監控設
作的子女
測手指觸控
像處理技術
 
e 
與攝影機的
的研究領
技術，在上
el 上、不然
於大型觸控
重點裡，視
，虛擬鍵盤
互動等技術
發，將結合
合成可應用
智慧型互動
所需的互動
備對話而已
互動，感受
螢
，
裝
域，
述
就
牆
覺
、
研
子
於
技
技
，
到
  
模型
背景
背景
型的
型建
[35]
法中
易去
mod
際應
Rea
得既
演算
裡面
著每
(i.e.
資料
back
已有
一簡
spac
 (backgro
的變動，使
模型建立
區域稱之
立的方法
與核密度估
，需要事
modelin
eling 解決
用上會有
l-time fore
保有 KDE
本計畫擬
法如圖十
的 PDF m
一次 itera
, mode)的距
加入已有
ground mo
 
 
在偵測出
許多學者
單的 skin
e，在透過
und model
其不僅具
後，移動物
為前景 (fo
中，最主要
測法 (ke
先決定 Ga
g，對於 s
了 MoG 
困難，因此
ground-bac
-based met
採用 codeb
一所示，co
ode，在一
tion，重新
離，若距
的 codewo
del。 
圖 十一，
移動物件之
提出許多方
-color spa
Eq. (1)過濾
)已經成為一
有抗雜訊的
件的偵測即
reground)
的方法有混
rnel density
ussian mo
ensitive d
的一些缺點
，Kim 等
kground se
hods 的優
ook mode
debook 角
開始訓練階
估算新的
離太遠，則
rd，並更新
Codebook 
後，我們擬
法[40]，這
ce threshol
出膚色區
9. 
種主流方
能力，對
是比較現
，亦即有物
合高斯模
 estimation
del 的個數
etection 也
，但其需
人[39] 即提
gmentation
點，又降低
l 的方式來
色像是 M
段，codeb
pixel 的顏
新加入一
，透過此
Backgroun
透過膚色
此，為了
ding 方式
域。 
法[33]，因
於動態的環
在影像與背
體發生移動
型 (mixtur
, KDE) [36
，且其對於
不好；KD
要大量的記
出了一種
 方法，其
了記憶體
建立背景
oG 裡的 G
ook 為 em
色資訊與
個 codewo
方式所建立
d Modeling
偵測，抓取
能夠達到即
，將影像的
為其利用
境亦有不
景模型，
現象的區
e of Gaussi
]-[38]兩大類
快速變化
E-based 的
憶體，也
基於 codeb
採用 codeb
的需求。 
模型，以偵
aussian mo
pty，在 st
codebook 裡
rd，否則即
的 codeb
 Algorithm
出手部區
時的應用
color spa
過去資訊描
錯的效果
不屬於背景
域。在背景
an, MoG) [
；在MoG
的背景，不
backgro
使得在一些
ook mode
ook mode
測移動物
del 或是 K
ep II 裡面
的 codew
將此 pixe
ook 即可當
 
域；膚色偵
，我們擬採
ce 轉成 H
述
；在
模
模
34], 
 方
容
und 
實
l 的
l 使
件，
DE 
，隨
ord 
l 的
作
 
測
取
SV 
  
透視
面，
影機
(2) 
偵測
影機
機所
訊，
ROI
尖部
值，
圖 
(3) 
們透
圖十
機與
而由
的陰
投影(pers
它們之間
與投影平
 
 
邊緣取像方
利用多顆
步驟可以
影像，以偵
投影出的
藉以降低
，再針對此
位，如圖
以決定是
十四，投影
 
指尖細部影
在 Munic
過攝影機
五所示。藉
追蹤技術
於簡報時
影，因此
 
pective proj
的關係可以
面座標之間
圖 十
式觸控偵
攝影機裝設
得知指尖位
測是否碰
影像顏色所
計算的複雜
區域進行
十四所示
否發生碰觸
平面指尖觸
像之觸控
h 與 Peron
擷取筆尖的
由這樣的
，透過攝影
，投影機是
，我們可以
ection, pin
被描述成
的幾何轉
三，指尖
測 
在投影平
置，如此
觸到平面
干擾，但由
度。在此
影像強化(
，最後，在
。 
控偵測示
偵測 
a 的 Visua
細部的影
概念，我們
機的高倍變
架設在前面
針對細部
11. 
hole model
plane pers
換計算即可
與投影平面
面的四周，
系統便可只
；指尖影像
前一步驟
，我們可以
enhanceme
根據前述幾
(a) 
(b) 
意圖。(a) 
l input for 
像，進行筆
可以利用
焦(zoom)
，指尖在
影像進行陰
) [41]，布幕
pectivity [4
算出 c 的
座標幾何
以取得指尖
擷取該位
在偵測上相
的指尖偵測
先對指尖
nt)與分割(
何關係，
原始影像
pen-based c
勢 Pen-Do
高解析的
直接取得指
正面投影所
影分析，
與擷取出
2] ，則可
值。 
關係 
觸控影像
置的 X,Y 
對複雜，
，可提供
可能的位
segmentatio
定位出指尖
，(b) segmen
omputers 
wn, Pen-U
PTZ (pan/t
尖細部影
產生的光
以確認指尖
的影像都是
透過已知的
 
；前面的指
軸相對應的
因為會受投
重要的位置
置區域，設
n)，以取得
向量中 c
tation 結果
論文中[7]
p 的分析
ilt/zoom) 攝
像，進行分
之下會有明
的觸控。
平
攝
尖
攝
影
資
定
指
 的
 
 
。 
，他
，如
影
析。
顯
 
 13. 
 
(1) 核密度估計法為基礎的背景相減法 
核密度估計法 (KDE)是先利用一段時間去建立一個背景模型，對於每個像
素點，統計這段時間內所出現的像素值之後，利用機率的概念，轉換成像素值分
佈的機率密度函數 (Probability Density Function, PDF)，也就是說，背景模型描
述在這段建立背景的時間裡，每個像素點中像素值的機率分佈，透過一個固定半
徑及選定的核函數 (Kernel function) 來近似每一個像素點中像素值分佈的機率
密度函數。 
在以 KDE 為基礎的背景偵測上可以分成兩個階段，第一個階段是建立一個
背景模型，在一段建立背景的時間裡，我們利用 KDE 估計每個像素點中像素值
分佈的機率密度函數，建立我們所謂的背景模型。第二個階段則是利用建立好的
背景模型對之後的影像進行前景的判斷，假設當前影像中某個像素點的像素值，
在背景模型中的機率低於某一個門檻值 (Threshold)，則將此像素點被判定為前
景，反之則為背景。 
假設 x1, x2, x3, …, xN是在 N 張影像中，某個像素點像素值的時間序列，利用
此序列，則此像素點在時間 t的時候，出現像素值xt的機率密度函數被估計如下： 
( ) 
=


 −
=
N
i
it
Dt h
xxK
Nh
x
1
1Pr
,          (2) 
這裡 K(.)為一個核函數，本論文裡，我們選用 Epanechnikov function 做為核
函數，其 Epanechnikov function 的定義如下： 
( ) 

 ≤−
=
otherwise,              0
1x if,     1 2xxKE
,          (3) 
其中 h 指的是核函數的頻寬 (Bandwidth) 大小，頻寬愈大，則核函數影響的
範圍愈大，所建立出來的機率密度函數曲線也就愈平滑，頻寬愈小，則平滑效果
愈小，如圖十七所示，而 D 指的是影像的通道數；例如，RGB 彩色影像的有三
個通道，灰階影像則只有一個通道。 
在建立好背景模型後，我們開始判斷影像中的每個像素點屬於前景或者背 
景，當 Pr(xt)小於門檻值，則我們判斷此像素點屬於前景，也就是移動物體，反
之則為背景。這裡選用的門檻值並不是固定的常數，而是依據百分比來決定，我
們由小到大排列每種像素值的機率並累加，當累加機率到達一定的百分比，
Percentagemotion，則設定此像素值的機率為門檻值 thmotion，因此，每個像素點
的門檻值都不盡相同[43]。 
 15. 
 
體。α 是用來定義陰影對背景影響程度的最大範圍，β 則是避免因為一點點光源
變暗就被當成陰影，而 α 與 β 的範圍都應落在 0 到 1 之間，在我們的系統中，α、
β、τS及 τH都由實驗中找出最佳的值。 
之後，為了使偵測出的手部區域更加的準確，在移動區域濾除陰影的部份後，
我們同樣利用在 HSV 色彩空間上的資訊，從中找出屬於膚色的區域[46]，進而
得到完整的手部區域，判斷的條件式如下： 
( )
( ) ( )
( )


≤≤∧
≤≤∧≤≤
=
otherwise0
 if
1
UL
ULUL
RVV.pIRV
RSS.pIRSRHH.pIRH
pSkin ,     (6) 
若 Skin(p)為 1，則表示此像素為膚色區塊，RHL與 RHU的範圍在 0 到 360
之間， RSL、RSU、RVL、RVU的範圍則在 0 到 1 之間，在我們的系統中，這些
參數同樣地由實驗中找出最佳值。 
(3) 滑鼠指令判斷 
從連續影像上獲得完整的手部區域後，接著我們觀察手部區域的變化，判斷
所模擬的滑鼠動作。圖十八為整個滑鼠指令判斷的系統流程圖。一開始，在我們
的系統中，先偵測出手部區域輪廓的指尖點、指縫點以及長軸參考點，此長軸參
考點為手部區域輪廓與影像下方邊界兩個交接點的中心點，如圖十九中以半圓形
點標示。接著判斷指縫點的數量，若指縫點數量大於 2，表示手掌張開，則再偵
測手掌是否靜止，靜止表示可能在執行左右鍵的點擊，否則表示在執行游標的移
動；倘若指縫點數量小於等於 2，則判斷除了拇指外的其餘四指，是否只有食指
單獨伸出，若是，則進行左右鍵拖曳的偵測，反之則判斷是否執行滑鼠滾輪指令。
此外在我們的系統中，都是以右手模擬滑鼠動作作為基準。 
 
圖 十八，滑鼠指令判斷的系統流程圖。 
 17. 
 
(1) 軌跡前處理 
當右鍵拖曳指令開始時，我們依序紀錄執行右鍵拖曳時食指指尖的位置，結
束右鍵拖曳指令時，則停止紀錄軌跡，表示已完成滑鼠手勢的軌跡紀錄。從紀錄
的手寫軌跡中擷取特徵之前，手寫軌跡應先經過一段前處理的程序，包括：濾除
重複的點、連接斷點、尺寸正規化、平滑化和重新取樣。圖二十二為前處理程序
的流程圖。 
A. 濾除重複的點：在軌跡中所紀錄的點，有時會出現連續相同的座標點，在辨
識上，重複的點並沒有提供有用的資訊，所以應該濾除這些不必要的座標
點。 
B. 連接斷點：由於各種的寫手習慣、情緒、手寫速度和取樣速率的關係，造成
紀錄的軌跡不連續，這有可能影響到軌跡的特徵，所以我們使用線性內插法，
插入這些遺失的點。 
C. 尺寸正規化：為了移除不同手寫尺寸的大小變化，尺寸的正規化是必要的，
在我們的實驗裡，手寫軌跡都被正規化到一個 100*100 的大小裡。 
D. 平滑化：由於手寫動作、指尖位置的偵測和系統操作的熟練度等原因，都會
造成手寫軌跡有稍微的抖動，這些抖動雜訊有可能影響辨識的正確率，所以
平滑化的處理是必要的。 
E. 重新取樣：在軌跡中順序相鄰的兩點的位置都相當的接近，然而座標點間位
置過於相近並無法提供有用的特徵資訊，不但增加辨識上的時間，也可能降
低辨識上的正確率，因此對於每筆手寫軌跡，我們重新取樣出固定數量的取
樣點，在各個軌跡中的取樣點距離是相等的。 
 19. 
 
 
1. 正規化的一階導數 (Normalized first derivatives)：正規化的一階導數 ( )txˆ' ,
( )tyˆ' 分別被計算如下： 
( ) ( ) ( )( )

=
=
⋅
−−+⋅
= 2
1
2
2
1
2
i
i'
i
itxitxi
tx ; ( ) ( ) ( )( )

=
=
⋅
−−+⋅
= 2
1
2
2
1
2
i
i'
i
ityityi
ty , 
( ) ( )( ) ( )22 tytx
txtxˆ
''
'
'
+
= ; ( ) ( )( ) ( )22 tytx
tytyˆ
''
'
'
+
= .    (7) 
2. 正規化的二階導數 (Normalized second derivatives)：正規化的二階導數 ( )txˆ '' ,
( )tyˆ '' 的計算類似 Eq.(7)，其公式如下： 
( ) ( ) ( )( )

=
=
⋅
−−+⋅
= 2
1
2
2
1
2
i
i
''
''
i
itxitxi
tx ; ( ) ( ) ( )( )

=
=
⋅
−−+⋅
= 2
1
2
2
1
2
i
i
''
''
i
ityityi
ty ,
   
( ) ( )( ) ( )22 tytx
txtxˆ
''''
''
''
+
= ; ( ) ( )( ) ( )22 tytx
tytyˆ
''''
''
''
+
= .    (8) 
3. 曲率 (Curvature)：曲率是描述曲線彎曲的程度，其計算如下： 
( ) ( ) ( ) ( ) ( )
( ) ( )( ) 2322 tytx
tytxtytxtk
''
''''''
+
⋅−⋅
= .         (9) 
4. 方向 (Aspect)：描述一個五點區域內高對於寬的比列，其計算如下： 
( ) ( ) ( )( ) ( )txty
txtytA
Δ+Δ
Δ−Δ
= .          (10) 
其中， 
( ) ( ) ( )22 +−−=Δ txtxtx , 
( ) ( ) ( )22 +−−=Δ tytyty . 
5. 筆跡方向 (Writing direction)：在目前的點上的局部筆跡方向，使用 cosine
和 sine 計算如下： 
( ) ( ) ( )( ) ( )( )
=
+−−
+−−
=
yxk
tktk
txtxt
,
211
11cosα ,           
( ) ( ) ( )( ) ( )( )
=
+−−
+−−
=
yxk
tktk
tytyt
,
211
11sinα .        (11) 
 
(3) 量化編碼 
當我們從軌跡中截取出特徵向量後，我們接著要把每個特徵向量進行量化，
 21. 
 
而 xi,k 為靠 xi¬最近的第 k 個樣本點。 
 
(5) PBM-index 
雖然 mean shift 是能夠自動的決定分群的數量，但其核函數頻寬的選擇會影
響分群的結果，而在我們使用的 adaptive mean shift 中，每個樣本點都有各自的
頻寬，其頻寬為距離各自最近的第 k個樣本點的距離，不同的 k所產生的分群結
果將會直接影響系統的辨識率，因此我們利用 PBM-index 來決定 k的選擇[52]。 
PBM-index 是用來表示分群的有效性，其定義如下： 
( )
2
11 



××= L
L
D
E
E
L
LPBM ,          (19) 
其中 L是分群的數目，這裡， 

=
=
L
l
lL EE
1
,             (20) 
lj
n
j
ljl uE zx −=
=1
,           (21) 
ji
L
j,iL
zzmaxD −=
=1
.            (22) 
n指的是整個資料的資料筆數，另外，當第 j筆資料屬於第 l群時，ulj為 1，否則
為 0， zl為第 l群的群聚中心。而當所求得的 PBM-index 的值愈大時，代表我們
分群的數量愈接近資料實際上的分群數量，因此，我們使用 adaptive mean shift
對特徵向量資料分群，並在使用不同k下的分群結果中，找出最大的PBM-index，
將其分群結果作為量化的依據。 
 
(6) 隱藏式馬可夫模型 
HMM 是一種雙重隨機程序，由兩個部份組成，一個是馬可夫鏈，描述狀態
的轉移，由狀態轉移機率表示，其輸出為一狀態序列；另一個部份也是一個隨機
程序，利用觀測符號機率來描述狀態與觀察符號之間的關係，由觀測符號機率表
示，其輸出為一觀察序列。在 HMM 的程序中，能夠直接觀察的只有觀察序列，
狀態是不可見的，只有透過觀察序列的隨機程序才能表現出來。 
 
A. HMM 主要的參數定義 
一個 HMM 可以被表示為 λ = (N, M, A, B, π)或簡單記為 λ = (A, B, π)，以下是
HMM 主要的參數定義[53]： 
(1) N：此模型中的狀態個數，模型中的狀態集合表示為 S = {S1, S2, …, SN}，
Si表示第 i個狀態，qt則表示為時間 t時的狀態。 
(2) M：每一個狀態中的觀察符號個數，觀察符號的集合表示為 V = {v1, v2, …, 
vM}。 
(3) π：初始狀態的機率分布；π = {πi}，其中 
 23. 
 
( ) ( ) ( ) NjTtObaij tj
N
i
ijtt ≤≤−≤≤


= +
=
+  1     ,11     ,1
1
1 αα . 
(3) 終止： 
( )
=
=
N
i
T iOP
1
)|( αλ . 
後向演算法： 
 定義： 
  ( ) ( )λβ | ,21 itTttt SqOOOPi == ++   
步驟： 
(1) 初始化： 
( ) NiiT ≤≤= 1     ,1β . 
(2) 歸納： 
( ) ( ) ( ) NiTTtjObai ttjijt ≤≤−−== ++ 1     ,1 , ,2 ,1     ,11 ββ . 
由前向和後向演算法可得： 
( ) ( )
( ) ( )
( ) ( )


=
=
+
=
=
=⋅==
===
N
i
tt
N
i
tTttt
N
i
tT
ii
iqOOPiqOOOP
TtiqOOOPOP
1
1
121
1
21
|, ,
,,2,1     , ,|
βα
λ


 
D. 維特比演算法 (Viterbi Algorithm) 
對於問題(2)，換句話說，就是從所有可能的狀態序列中，找出最大的 P(O|S,λ)，
若我們直接計算每一種可能的狀態序列發生的機率，所耗費的計算時間會相當的
大，而使用維特比演算法除了能找出最佳的狀態序列外，還減少了許多的計算
量。 
維特比演算法： 
定義： 
( ) ( )λδ | ,,,,max 2121,, 121 ttqqqt OOOiqqqPi t  == − . 
步驟： 
(1) 初始化： 
( ) ( )
( ) .0
1     ,
1
11
=
≤≤=
i
NiObi ii
ψ
πδ
 
(2) 遞迴： 
( ) ( )[ ] ( )
( ) ( )[ ] .1     ,2          , maxarg
1     ,2     , max
11
11
NjTtajj
NjTtObajj
ijtNit
tjijtNit
≤≤≤≤=
≤≤≤≤=
−≤≤
−≤≤
δψ
δδ
 
(3) 終止： 
 25. 
 
本計劃研發以視覺為基礎之虛擬觸控人機互動介面技術，其不僅可以為遠距
協同作業提供智慧型的人性化互動介面，也可應用在多方領域，例如: 高齡者遠
距居家照護，提供高齡者更便捷的人機互動介面，以提升生活品質。本計畫如期
完成下列之成果：虛擬觸控、虛擬滑鼠[54]、虛擬鍵盤[55]。 
在虛擬滑鼠實驗過程中，我們採用的網路攝影機規格為Microsoft VX-7000，
以每秒擷取 30 張畫面的頻率，拍攝影像大小為 320 × 240 的 AVI 格式視訊影片。
其拍攝的環境為一光源穩定的室內環境，拍攝時，鏡頭由上往下並固定位置與方
向，如圖 二十四所示。 
 
圖 二十四，模擬滑鼠動作之實驗環境。 
 
我們錄製數段實驗影片，做為驗證我們系統的實驗數據，其影片內容根據本
論文所定義之滑鼠動作包含：左鍵點擊 1 次，連續地左鍵點擊 2 次，右鍵點擊 1
次，左鍵拖曳，右鍵拖曳，滑鼠滾輪往上滾動，滑鼠滾輪往下滾動。分別由 12
位使用者錄製，每位使用者在每段指令影片中皆錄製該指令動作 10 次。 
表格一紀錄每段影片中，滑鼠指令是否正確地被偵測，在點擊指令的辨識上，
左鍵連點 2 次的指令為 2 次都被偵測才算成功，而我們發現連續點擊的辨識率明
顯的比單點擊來得低，其原因在於有些使用者作連續點擊動作時，手指點擊速度
太快，手指舉起的高度也較低，因此造成辨識上的錯誤。而在拖曳指辨識上，偵
測拖曳指令是否為連續不中斷，這樣偵測的目的是因為拖曳動作執行時，只要指
令一中斷，則拖曳動作就會結束，如此一來，像是我們利用右鍵拖曳紀錄的手勢
軌跡便會不完整。而實驗上，我們的拖曳動作和滾輪指令都是可以正確執行的。 
 
表格 一，滑鼠指令辨識統計 
執行指令 辨識率 
左鍵點擊 1 次 113/120 94.17% 
左鍵連點 2 次 111/120 92.5% 
右鍵點擊 1 次 115/120 95.83% 
左鍵拖曳 120/120 100% 
 27. 
 
驗資料的取得是以 Logitech QuickCam 作為拍攝器材，視訊格式為 320*240 像素
點，程式執行時間每張影像平均需要 0.026 秒。 
本實驗共有兩種不同大小的虛擬鍵盤，分別為 3*3 數字鍵盤與 5*6 英文字母
鍵盤。3*3 的虛擬鍵盤我們找了十個不同的使用者來測詴，分別在鏡頭拍攝距離
10 公分、15 公分、20 公分下進行了十組指定的輸入，每一組的輸入都具有九次
觸碰，總計有 2700 次觸碰。5*6 的虛擬鍵盤我們也找了十個不同的使用者來測
詴，分別在鏡頭距離 15 公分、20 公分、25 公分下進行十組指定的輸入，這十組
的總共觸碰為 88 次，總計 2640 次觸碰。 
 
(a) (b) 
圖 二十六，背景圖 (a)3*3 數字鍵盤；(b)5*6 英文字母鍵盤。  
 
在 3*3 數字鍵盤中，我們針對了十個不同的使用者，三種不同的拍攝距離，
每種距離進行了十段輸入的拍攝，而每段輸入皆有九次的觸碰，所以整個實驗資
料庫中共有三百段影片、兩千七百次觸碰，我們得到表格三的偵測結果。 
 
表格 三，3*3 數字鍵盤觸碰偵測之 miss 次數。 
Miss次數 False Alarm次數 
52 0 
總共觸碰 2700 次 觸碰準確率 
98.07% 
 
在 5*6 英文字母鍵盤中，我們針對了十個不同的使用者，三種不同的拍攝距
離，每個距離進行了十段輸入的拍攝，而每個使用者輸入的十段影片共有八十八
次的觸碰，所以整個實驗資料庫中共有三百段影片、兩千六百四十次觸碰，根據
上表 4.17 的參數設定，我們可以得到下頁表 4.18 的偵測結果。 
 
表格 四，5*6 英文字母鍵盤觸碰偵測之 miss 次數。 
Miss次數 False Alarm次數 
26 12 
總共觸碰 2640 次 觸碰準確率 
99.02% 
 29. 
 
六、 參考文獻 
[1] Handheld projector, http://en.wikipedia.org/wiki/Handheld_projector 
[2] 龔招健, “微投影新商機 5 年將成長 60 倍,” Money 錢雜誌, Sept. 2009. 
[3] Microvision, Inc.; http://www.microvision.com/ 
[4] 奧圖碼科技公司; http://www.optoma.com.tw 
[5] V. I. Pavlovic, R. Sharma, and T. S. Huang, “Visual interpretation of hand 
gestures for human-computer interaction: A review,” IEEE Trans. Pattern Anal. Mach. 
Intell., vol. 19, no. 7, pp. 677-695, July 1997. 
[6] A. Jaimes and N. Sebe, “Multimodal human–computer interaction: A survey,” 
Computer Vision and Image Understanding, vol. 108, no. 1-2, pp. 116-134, Oct.-Nov. 
2007. 
[7] M. E. Munich and P. Perona, “Visual input for pen-based computers,” IEEE Trans. 
Pattern Anal. Mach. Intell., vol. 24, no. 3, pp. 313-328, March 2002. 
[8] K. Oka, Y. Sato, and H. Koike, “Real-time fingertip tracking and gesture 
recognition,” IEEE Computer Graphics & Applications, Vol. 22, No. 6, Nov. 2002. 
[9] V. I. Pavlovic, R. Sharma, and T. S. Huang, “Visual interpretation of hand 
gestures for human-computer interaction: A review,” IEEE Trans. on Pattern Analysis 
and Machine Intelligence, pp. 677-695, Vol. 19, No. 7, July 1997. 
[10] J. Yamato, J. Ohya, and K. Ishii, “Recognizing human action in time-sequential 
images using hidden markov models,” In Proc. 1992 IEEE Conf. on Computer Vision 
and Pattern Recognition, pages 379-385, 1992. 
[11] D. Kim, J. Song, and D. Kim, “Simultaneous gesture segmentation and 
recognition based on forward spotting accumulative HMMs,” in Pattern Recognition, 
vol. 40, pp. 3012-3026, 2007. 
[12] W. N. Chan and S. Ranganath, “Real-time gesture recognition system and 
application,” in Image and Vision Computing, vol. 20, pp. 993-1007, 2002. 
[13] K. Nickel and R. Stiefelhagen, “Visual recognition of pointing gestures for 
human-robot interaction,” in Image and Vision Computing, vol. 25, pp. 1875-1884, 
2007. 
[14] C. L. Huang and S. H. Jeng, “A model-based gesture recognition system,” in 
Machine Vision and Applications, vol. 12, pp. 243-258, 2001. 
[15] C. L. Huang, M. S. Wu, and S. H. Jeng, “Gesture recognition using the 
multi-PDM method and hidden Markov model,” in Image and Vision Computing, vol. 
18, pp. 865-879, 2000. 
[16] F. S. Chen, C. M. Fu, and C. L. Huang, “Hand gesture recognition using a 
real-time tracking method and hidden Markov models,” in Image and Vision 
Computing, vol. 21, pp. 745-758, 2003. 
[17] P. Kakumanu, S. Makrogiannis and N. Bourbakis, A survey of skin-color 
 31. 
 
Large-Format Interactive Displays,” SIGGRAPH, 2007. 
[33] M. Piccardi, “Background Subtraction Techniques: A Review,” in Proc. IEEE Int. 
Conf. System, Man, and Cybernetics, vol. 4, pp. 3099-3104, 2004. 
[34] C. Stauffer and W.E.L. Grimson, “Adaptive Background Mixture Models for 
Real-time Tracking,” in Proc. IEEE CVPR, pp. 246-252, June 1999. 
[35] D. S. Lee, “Effective Gaussian Mixture Learning for Video Background 
Subtraction,” IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 27, no. 5, 
pp. 827-832, 2005. 
[36] A. Elgammal, R. Duraiswami, D. Harwood, and L. S. Davis, “Background and 
Foreground Modeling Using Nonparametric Kernel Density Estimation for Visual 
Surveillance,” in Proceedings of IEEE, vol. 90, no. 7, pp. 1151-1163, 2002  
[37] A. Elgammal, D. Harwood, and L.S. Davis, “Nonparametric Model for 
Background Subtraction,” in Proc. ECCV, pp. 751-767, June 2000. 
[38] A. Mittal and N. Paragios, “Motion-based background subtraction using adaptive 
kernel densityestimation,” in Proc. of IEEE Conference in Computer Vision and 
Pattern Recognition, 2004. 
[39] K. Kim, T. H. Chalidabhongse, D. Harwood, and L. Davis, “Real-time 
foreground–background segmentation using codebook model,” Real-Time Imaging, 
vol. 11, pp. 172-185, 2005. 
[40] P. Kakumanu, S. Makrogiannis, and N. Bourbakis, “A survey of skin-color 
modeling and detection methods,” Pattern Recognition, vol. 40, pp. 1106-1122, 2007. 
[41] O. Faugeras. Three-Dimensional Computer Vision: a Geometric Viewpoint. MIT 
Press, 1993. 
[42] J.G. Semple and L. Roth. Introduction to Algebraic Geometry. Oxford: 
Clarendon Press, 1949. Reprinted 1987. 
[43] Alireza Tavakkoli, Mircea Nicolescu, George Bebis, and Monica Nicolescu, 
“Non-parametric statistical background modeling for efficient foreground region 
detection,” Machine Vision and Applications, vol. 20, no. 6, pp. 395-409, 2009. 
[44] 
http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV0405/MISHRA/kde
.html 
[45] R. Cucchiara, C. Grana, M. Piccardi, and A. Prati, “Detecting moving objects, 
ghosts, and shadows in video streams,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 25, no. 10, pp. 1337-1442, 2003. 
[46] P. Kakumanu, S. Makrogiannis, and N. Bourbakis, “A Survey of Skin-color 
Modeling and Detection Methods,” Pattern Recognition, vol. 40, pp. 1106-1122, 
2007. 
[47] Brijesh Verma, Jenny Lu, Moumita Ghosh, and Ranadhir Ghosh “A Feature 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/26
國科會補助計畫
計畫名稱: 子計畫二：以視覺為基礎之虛擬觸控人機互動介面技術研發(I)
計畫主持人: 鄭伯順
計畫編號: 99-2219-E-155-003- 學門領域: 應用服務(網通國家型)
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
