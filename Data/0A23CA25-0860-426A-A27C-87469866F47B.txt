2前言
近年來光電產業蓬勃發展，如光儲存、光顯示、…等光資訊與光學設計密不
可分。然而數位相機、數位攝影機…等都需要光學設計來引導才會有絕佳的品質
呈現在我們的眼前。光學設計的實驗方法自古以來很少有光學設計專家真正專研
探討這問題，直到 1940 年後人工智慧被廣泛地討論，以人的思維模式的架構發
展更新的一套語法。因此田口法、模擬退火法、模糊控制、反應曲面法、基因演
算法…等方法提出並應用[7]-[11]。光學系統的領域隨著時代不斷的變化與進步，
光學設計理論也有著不同創新與應用，而光學系統搭配其它實驗方法為光學設計
衍生的新方法。於進行 CODE V 光學模擬軟體模擬實驗時，常出現像差不符合預
期的效果，如色差、球差、彗差、像散、場曲、畸變…等，且光學設計相當仰賴
其經驗法則，因此若沒有合適的實驗方法，則光學設計最佳化模擬僅能算是徒勞
無功。
自 1995 年光機電整合系統及數位影像系統的快速發展，光學設計及量測在
理論和優化方面因為數位化，輕量化，小型化和整合化而有許多需要強化之處，
許多大廠如 Varioptic 陸續推出液態透鏡以及微小型的光學變焦模組，預計也將
成為未來市場的主流，而手機、數位相機等科技產品蓬勃發展，人工智慧的應用
功不可沒，於光學設計領域更為重要。若能將光學設計搭配人工智慧方法，將可
使光學設計者事半功倍。
4文獻探討
基因演算法（Genetic Algorithm，GA）[1]，這是一個可同時搜尋多變數與多
模態空間的演算法，可以成功的解決複雜與不連續的問題（Goldberg, 1989; Gen
and Cheng, 1997），是最佳化工程計算常用的一種演算工具，是於 1975 年由密西
根大學 John Holland 與他的學生所提出的演算法則[2]。基因演算法（GA）乃是
基於達爾文在物種起源[3]此著作中提到的進化論所發展出來的演算法，也就是依
自然界中「物競天擇」及「適者生存」的特性，模擬生物間的生存競爭，倖存者
得以繁衍下一代的觀念，應用於最佳化工程之計算時，以隨機方式同時產生多組
解，較佳的解將被留下運算，如此多次疊代即可求出最佳解。
一般傳統之演算法往往由幾個起始點，依照一定的數學模式產生下一次疊代
值，如此反覆計算求得最佳解；而基因演算法則是以隨機方式產生許多的點，同
時搜尋最佳解，因為在每一次疊代過程皆是取相對最佳的點，因此只能找到最接
近之最佳解，而且每次搜尋的最佳解可能不一樣。不過因為其他演算可能也只找
到局部最佳解（Local Optimum）而不能保證是真正的全域最佳解（Global
Optimum），如圖 1 所示。所以基因演算法是相當不錯的最佳化運算工具。
圖 2 搜尋空間
基因演算法大抵上可以拆解成五個重要之執行步驟：(一)產生初始值、(二)
挑選染色體、(三)複製染色體並將基因交換、(四)進行基因突變及(五)淘汰不適應
之染色體。
6結果與討論
本計畫提出以 DSP 非線性補償之技術來提升系統之 MTF。且模擬實驗指
出，利用 GA 進行優化搭配 DSP 非線性補償之效果，確實可有效地改善其鏡頭
性能。僅鏡頭廣角端色差稍大，使得 1.0 field 之 MTF 曲線較不理想。我們可利
用加入非球面，調整鏡片之非球面係數來改善此問題。然而對於三百萬畫素之影
像感測器(本計畫以 OV3640 為主)而言，其 CMOS 最高可解析至 286 對線(Line
Pair)。由 MTF 曲線圖可得知，在 100 對線除廣角端僅 1.0 field 之 MTF 介於 0.2
至 0.3 之間，其餘焦段在 100 對線，MTF 皆大於 0.4 以上，且相對照度皆大於 85%，
其鏡頭成像品質已是可接受之標準範圍。另外由於此變焦鏡頭之鏡片材質均為玻
璃材質，考慮鏡頭成本與品質問題，故本計畫認為此變焦鏡頭不需加入非球面，
即能擁有相當不錯之效能。
以下表 1-3 分別為最初以 CODE V 優化之兩倍光學變焦鏡頭與最後 DSP 非
線性補償搭配 GA 優化之鏡頭，針對色差、場曲、光斑尺寸做比較。
表 1 以 DSP 非線性補償搭配 GA 優化色差之成果
原始鏡頭 GA 優化
AX LAT AX LAT
Total 0.046982 0.070429 0.028339
(39.68%)
0.016186
(77.02%)
表 2 以 DSP 非線性補償搭配 GA 優化場曲之成果
原始鏡頭 GA 優化
x-focus y-focus x-focus y-focus
Total 11.378897 11.361999 1.710281
(84.97%)
2.736427
(75.92%)
表 3 以 DSP 非線性補償搭配 GA 優化光斑尺寸之成果
原始鏡頭
Field 1 Field 2 Field 3 Field 4 Field 5
Total 0.034268 0.031259 0.031645 0.047114 0.077424
GA 優化
Field 1 Field 2 Field 3 Field 4 Field 5
Total 0.01416809
(58.65%)
0.01531801
(51.00%)
0.0227388
(28.14%)
0.0305455
(35.17%)
0.0306081
(60.47%)
8圖 9 MTF (Zoom 5) 圖 10 MTF (Zoom 6)
圖 11 MTF (Zoom 7) 圖 12 MTF (Zoom 8)
圖 13 MTF (Zoom 9)
10
參考文獻
[1] Levenberg, K., “A Method for the Solution of Certain Problems in Least
Squares”, Quart. Appl. Math, vol. 2, pp.164-168, (1994)
[2] S. Kuiper et al., Proc. of SPIE Vol. 5523, (2004)
[3] G. Beni and S. Hackwood, Appl. Left. 38, 4, pp.207-209, (1981)
[4] Vasiljevic, and Darko, 1999, “Optimization ofthe Cooke triplet with the various
evolution strategies and the damped least squares” , Proceedings of SPIE - The
International Society for Optical Engineering Vol.3780, pp. 207-215.
[5] K. Levenberg, 1944, “A method for the solution of certain nonlinear problems in
least squares” , Q. J. Appl. Math., Vol.2, pp. 164-168.
[6] Vasiljevic, D. and Golobic J., 1996. “Comparison of the classical damped least 
squares and genetic algorithm in the optimization of the doublet” , Proceedings 
of the First Workshop on soft computing, Nagoya, Japan, pp.200-204.
[7] 蔡憲霖，2006，“混合型田口基因演算法應用於光學系統消初階色差設計”，
國立高雄第一科技大學光電工程研究所，碩士論文。
[8] 黃彥傑，2005年7月，“光學系統多目標最佳化參數設計”，國立高雄第一科
技大學機械與自動化工程所，碩士論文。
[9] 張維中，2003，“以基因區域搜尋演算法設計繞射型濾波元件”，國立交通大
學光電工程研究所，碩士論文。
[10] 曹志任，2002年7月，“遺傳基因演算法在繞射光學元件設計之應用”，國立
台北科技大學光電技術研究所，碩士論文。
[11] 林瀚青，2008年2月，“多目標光學最佳化設計法應用於光學繞射鏡頭設計”，
國立高雄第一科技大學機械與自動化工程所，碩士論文。
12
可供推廣之研發成果資料表
■ 可申請專利 □ 可技術移轉 日期：98年 07 月 31 日
國科會補助計畫
計畫名稱：前瞻數位液態, 液晶透鏡光學設計及優化之研究
計畫主持人：方怡欽
計畫編號：NSC 97－2221－E－327－002－
學門領域：光學工程
技術/創作名稱 液態鏡頭及具有液態鏡頭之鏡頭總成
發明人/創作人 方怡欽
中文：本計劃提出利用 DSP 控制鏡頭內部步進馬達完成非線性補償
並搭配基因演算法優化鏡頭之概念，可謂成功且有效地優化整個光
學變焦系統。DSP 非線性補償搭配 GA 優化，此優化法已突破 CODE V
模擬軟體之 LDS 優化法。最關鍵之因素為：以往光學設計中以一維
方式來尋找變焦曲線最佳解，而本論文利用 DSP 非線性補償搭配
GA 優化，將搜尋變焦曲線最佳解之方法拓展成二維方式搜尋之，
且最佳解彼此間為非連續之關係，亦即最佳解的分布為離散之觀
念。技術說明
英文：A design of three Mega-pixels cell-phone 2X optical zoom
camera with liquid lens elements is invented in this research. Genetic
Algorithms (GA) is applied to find out the best curvatures of liquid
lenses and the compensative aberration value of other lenses in each
zoom. Digital Signal Processor (DSP) is used for promoting the
performance in nonlinear compensative way and optimizes the camera.
According to the result of experiment, it is proved that GA will get
batter solution than Least Damping Square (LDS) effectively.
可利用之產業
及
可開發之產品
1. 手機鏡頭。
2. 鏡頭內建步進馬達。
技術特點
1. 步進馬達控制。
2. 利用基因演算法提升鏡頭成像品質。
推廣及運用的價值
1. 使光學設計者更快速挑選玻璃材質與完成鏡頭設計。
2. 以二維方式搜尋變焦曲線最佳解。
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送
貴單位研發成果推廣單位（如技術移轉中心）。
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
※ 3.本表若不敷使用，請自行影印使用。
附件二
Study on the Improvement of Overall Optical Image 
Quality via Digital Image Processing 
aCheng-Mu Tsai, bYi Chin Fang, and bHan-Ching Lin  
aDepartment of Computer and Communication, Kun Shan University, Taiwan, R.O.C.  
Email: jmutsai@mail.ksu.edu.tw  
bInstitute of Electro-Optical Engineering, National Kaohsiung University of Science and Technology, 
Taiwan, R.O.C.  
Email: corresponding author: yfang@ccms.nkfust.edu.tw  
Abstract 
This paper studies the effects of improving overall optical image quality via Digital Image 
Processing (DIP) and compares the promoted optical image with the non-processed optical image. Seen 
from the optical system, the improvement of image quality has a great influence on chromatic 
aberration and monochromatic aberration. However, overall image capture systems—such as 
cellphones and digital cameras—include not only the basic optical system but also many other factors, 
such as the electronic circuit system, transducer system, and so forth, whose quality can directly affect 
the image quality of the whole picture. Therefore, in this thesis Digital Image Processing technology is 
utilized to improve the overall image. It is shown via experiments that system modulation transfer 
function (MTF) based on the proposed DIP technology and applied to a comparatively bad optical 
system can be comparable to, even possibly superior to, the system MTF derived from a good optical 
system.  
Keywords: Digital Image Processing (DIP), modulation transfer function (MTF), Point Spread 
Function (PSF), Line Spread Function (LSF), Edge Function. 
 
1. Introduction  
To any designer or manufacturer, it is natural that one challenge follows another because 
cellphones stride forward in a tendency toward high-definition images and light, thin, small outlook. In 
the optimal design of traditional optical zoom lens, increasing in the quantity of zoom lenses, special 
material glasses, and aspherical technology can lead to an effective improvement upon optical MTF 
curve. Under a badly conditioned optical system MTF, can any other technologies improve it? 
Generally speaking, images in the cellphone camera and digital camera cannot be formed by the optical 
system alone; many others, briefly called MTFs such as the transducer MTF, electronic circuit MTF, 
and digital–analog converter, are also involved.   
With a focus on the interaction between image processing and optical design, this thesis is 
significant for manufacturers and optical designers. Digital image processing can (1) release the burden 
of layer design, (2) solve the problems of spherical aberration, coma, and distortion in aberration, (3) 
optimize the remaining aberration via traditional optical design, and (4) maintain image quality 
Hmon(u, v)、Hopt(u, v)、Hdet(u, v) and Hele(u, v) in Figure 1 respectively refer to monitor, optics, 
transducer, and electronic signal transfer functions. MTFs can be derived from Equation 7, so no 
thorough explanation of transfer functions will be made. Refer to references [3–6] for detailed 
explanation. When the image capture system is applied to take a photo, in addition to the transfer 
function, object distance, noise, and the A/D converter will have an influence. These factors are an 
integral part of MTFs. MTFs are calculated as follows  
f(x, y) refers to input image, hsys(x, y) stands for the transfer function of the space domain, and the 
convolution of them can lead to an output image g(x, y): 
( , ) ( , ) * ( , )sysg x y f x y h x y=                                          (5) 
Then the frequency domain equation can be derived from Fourier transformation of Equation (5): 
( , ) ( , ) ( , )sysG u v F u v H u v=                                           (6) 
where G(u, v) and F(u, v) refer to the output image and input image transfer function in the frequency 
domain respectively. In addition, Hsys(u, v) represents the frequency domain transfer function in the 
whole system. 
MTFs can be derived from Equation (6) as follows: 
( , )
( , )
( , )s sys
G u v
MTF H u v
F u v
= =
                                       (7)  
When basic knowledge of MTFs and digital image processing is acquired, correlations can be 
arrived at from the pattern represented by four MTF curves in Figure 2. Curves of the image MTF are 
marked purple, blue, green, and red from left to right. It is shown in the image with purple curve that 
except for the major outline, the boundary details are relatively blurred; in the image with blue curve 
the major outline is better than that in purple curve and the boundary details are also clearer but some 
noise can be vaguely discerned. The green and red curves show better clarity than the former ones, but 
the more details are emphasized, the more noise they will encounter.  
 
    Figure 2 Digital Images Represented by Four MTF Curves. 
Averaging  Processing  
An original image f(x, y) superposed on noise will result in an image g(x, y) with noise. Then  
border and other discontinuities. Opposite to the Gaussian lowpass filter, the Gaussian highpass filter 
has the following equation: 
2 2
0( , ) / 2( , ) 1 D u v DH u v e−= −                                               (12) 
Figures 5 and 6 indicate respectively the original chart and the resulting chart sharpened by the 
Gaussian highpass filter.  
         
Figure 5 Original Drawing              Figure 6  Resulting Chart Sharpened by  
D0 is set at 5.                           Gaussian Highpass Filter. 
   
Refer to references [7–9] for the detailed setting and application of the image processing methods 
mentioned above.  
  
4. Experiment Configuration and Analysis  
Experiments in this thesis are mainly structured to measure the system MTFS. At the beginning, 
the image capture system is applied to measure and derive the MTFS curve chart of the overall system. 
However, because the electronic noise disturbance in the image capture system has some effect on the 
accuracy of MTF curve chart, the real system MTF curve chart must be derived from microscan and 
averaging processing and after that the system MTF curve can be improved via digital image 
processing. Finally, the system MTF curve obtained for the camera lens in focus is compared with the 
system MTF curve obtained for the camera lens out of focus but with an application of digital image 
processing to improve image quality, and the former system MTF curve can be compared to the latter. 
The experimental equipment and supplies are introduced as follows: 
A: optical platform; B: linear slide rail; C: supporting stand; D: holding device; E: NOKIA N82; F: 
triaxial platform 460A-XYZ with micron adjustor; G: homotaxial platform support; H: 1080P 
telescreen HITACHI 42PD9500TA; I: mainframe that produces electronic patterns with an operating 
system of Windows XP and an ASUS EAH3870 display established inside; J: NOKIA N82 cellphone. 
The actual pictures are shown in Figures 7, 8, and 9. Figure 10 shows the experimental installation 
diagrams. 
 
Flow Chart Outline of Experimental Objective  
 
   
start
1080p telescreen displays electron
patterns with no aliasing effect.
choose schubweg of micron adjustor
and conduct microscan processing
Knife-edge light source electron
patterns are produced
Pictures are captured and analyzed
via image capture system
if the aliasing
effect has been removed
or not
when camera lens is
out of focus
Image captured is
conducted gray-scale and
tailoring processing
averaging processing
microscan processing
Image captured is
conducted gray-scale and
tailoring processing
averaging processing
microscan processing
digital image processing
Compare these two system MTF curves and tell which is better
 experimental result
No Yes
Yes
No
                      Figure 11 Flow Chart of Experimental Procedure 
   
        
images after being averaged
and micro scanned
Contrast processing
blur processing
sharpening processing
done with processing  
             Figure 12 Flow Chart of Digital Image Processing 
Although simple, the digital image processing improves the image quality. In addition, methods 
for digital image processing include Contrast processing, Fuzzification processing, and Sharpening 
processing.  
 
Comparison between system MTF with and without Digital Image Processing  
To what degree has efficacy been improved by application of digital image processing? Different 
digital image processing methods will lead to different results. Table 1 shows a parallel fable of system 
MTF values derived from different parameter settings of digital image processing. Among these values, 
it is found that the optimum system MTF curve will be derived when the cutoff frequency radius is set 
at 80 and digital Laplace filter shielding template is set at 5×5. Refer to Figure 13 for the results from 
other parameter settings.  
 
cut off frequencty d0 =80 digital Laplace filter mask 5x5o
real MTF curve (under out of focus)
  
Figure 14  System MTF curve diagram when camera lens is out of focus, cutoff frequency radius  is set at 80, 
and digital Laplace filter shielding is set at 5×5.  
 
For the sake of convenience, it is shown in the parallel fable that the optimum system MTF can 
be derived when the cutoff frequency radius d0 is set at 80 and digital Laplace filter shielding is set at 
5×5. Refer to Table 2 for details. In addition, by comparison with the system MTF under the condition 
that camera lens is out of focus, it is discovered that digital image processing improves the system 
MTF curve diagram, as indicated in Table 2 and Figure 14.  
 
5. Summary  
Can a system MTF with optical lens out of focus and with digital image processing in collocation 
be comparable to the system MTF with lens in focus?? The answer is yes and could be proved by 
comparison of Table 3 and Figure 15.   
 
 Spatial Frequency  
 20 lp/pixel 40 lp/pixel 60 lp/pixel 80 lp/pixel 100 lp/pixel
System MTF without 
out-of-focus lens 
64.55% 57.99% 52.27% 46.97% 43.11% 
System MTF when cutoff 
frequency radius d0 is set 
at 80 and digital Laplace 
filter shielding is set at 
5×5 
98.35% 93.21% 85.00% 74.39% 62.24% 
Table 3:  Parallel fable of system MTF values when camera lens is out of focus, cutoff frequency 
radius d0 is set at 80, and digital Laplace filter shielding is set at 5×5.   
loss of image quality, optical design in combination with digital image processing promises a future 
trend. However, image processing methods vary in accordance with different images. This is one tough 
problem that should be challenged in future.  
iii. When researching and developing new model cellphones and cameras in future, consideration 
should be given to writing microscan processing program into chip to improve the image quality.  
iv. The function of the present image process programs is not complete. Image recovery technology 
will be introduced to promote image quality in future, such as wavelet conversion and Wiener filter.  
 
 
REFERENCES 
 [1]F. Abbott, 1968, “Practical Aspects of Transfer Function Measurement,” SPIE Proceedings, vol. 13, 
p. 143. 
[2]J. W. Goodman, 2002, Introduction to Fourier Optics, McGraw-Hill, New York. 
[3]Y. C. Fang, 2000, Performance Evaluation of Discrete IR Optical System, The University of 
Reading, Department of Physics, Doctoral Thesis. 
[4]M. C. Dudzik, Jan. 1993, Electro-Optical Systems Design, Analysis, and Testing, SPIE Press. 
[5]T. Florin, 2006, “Simple image acquisition system optoelectronic analysis,” Automation, Quality 
and Testing, Robotics 2006 IEEE International Conference, vol. 2, pp. 365–370. 
[6]H. S. Jang, and Y. S. Kim, 2002, “MTF Analysis on the MSC Design,” Geoscience and Remote 
Sensing Symposium, 2002. IGARSS '02. 2002 IEEE International, vol. 6, pp. 3167–3169. 
[7] R. E. Woods, 2002, Digital Image Processing, 2nd ed., Prentice Hall. 
[8]W. K. Pratt, Jul.2001, Digital Image Processing: PIKS Inside, 3rd, New York. 
[9]K. R. Castleman, 1996, Digital Image Processing, Reading.  
 
Analysis of Human Vision Models and Its Application to Flat Panel Display 
 
Bo-Wen Wu, Yi-Chin Fang, Wei-Da Chen 
Nat. Kaohsiung First Univ. of S&T, Taiwan 
ABSTRACT  
This study explores thermal imaging recognition, and 
presents a method for effectively choosing the features and 
processing the images fully. Neural network technology is 
successfully applied to recognize thermal imaging and 
predict MRTD (minimum resolvable temperature 
difference), exceeding thermal imaging recognition under 
fatigue and the limits of the human eye. 
1. INTRODUCTION  
The MRTD is the general performance parameter of the 
Thermal-Imager[1-2]. Four-bars as in Fig. 1 of different 
spatial frequencies and of height and width ratio of 7:1 are 
placed in front of a uniform background when 
Thermal-Imager is utilized to observe the standard four-bar 
test pattern. 
2. METHOD 
The background is then gradually cooled down from a high 
temperature to a low temperature, or heated from a low 
temperature to a high temperature. the temperature 
difference between the target and the background at a 
particular spatial frequency, at the moment when the 
observer can clearly distinguish four- bars of thermal 
imaging, is called the MRTD at that spatial frequency, and 
is derived as follows Eq. (1). 
1 2
1 1 0 2 2 0
ΔT ΔT
MRTD(f) Φ  , ΔT T T   , ΔT T T
2
+= = − = − ...…(1) 
T0: Effective environment temperature 
T1: Temperature when four-bars of white wrinkles can be 
distinguished by human vision.  
T2: Temperature when four-bars of black wrinkles can be 
distinguished by human vision. 
ΔT1: When four-bars of white wrinkles can be 
distinguished by human vision, where ΔT1 represents the 
minimum temperature difference between target and 
background.  
ΔT2: When four-bars of black wrinkles can be 
distinguished by the human vision, ΔT2 represents the 
minimum temperature difference between target and 
background. 
Φ: Thermal-Imager correction coefficient 
f: Spatial frequency 
In this experiment, an experienced observer continuously 
performed the observation and judgment of thermal 
imaging. During the test, four-bars with a spatial frequency 
of ‘f’ were selected first, then the temperature difference 
was gradually reduced. The temperature difference at this 
moment when the observer clearly saw each of the 
four-bars, was recorded as the MRTD of this 
spatial frequency. Ten consecutive observations were made 
in this experiment, and the picture of thermal imaging was 
taken. The procedure was then performed in reverse: the 
temperature was increased gradually, and same observation 
and judgment steps were performed. The absolute average 
obtained in both stages was then defined as shown in 
Eq.(1). Moreover, the MRTD overall average at this 
spatial frequency is found and recorded as in Table 1. 
Table 1 MRTD temperature difference for four-bars of 
thermal imaging 
Spatial Frequency 
cy/mrad 
No.1 bar 
0.3704
No. 2 bar 
0.5388 
No. 3 bar 
0.7730 
No. 4 bar 
1.0935
No. 5 bar 
1.5707
1 MRTD 0.2 0.3 0.5 0.7 0.9 
2 MRTD 0.3 0.3 0.4 0.6 0.9 
3 MRTD 0.3 0.3 0.4 0.7 0.9 
4 MRTD 0.3 0.3 0.5 0.7 0.8 
5 MRTD 0.3 0.3 0.5 0.7 0.8 
6 MRTD 0.3 0.4 0.5 0.8 0.9 
7 MRTD 0.2 0.3 0.5 0.7 0.8 
8 MRTD 0.2 0.3 0.5 0.8 0.9 
9 MRTD 0.3 0.3 0.5 0.8 0.9 
10 MRTD 0.3 0.3 0.5 0.8 0.9 
Air temperature of 
average 26.819 26.889 27.096 27.403 27.565
MRTD of total 
average 0.270 0.310 0.470 0.740 0.880 
Each of the four-bars, corresponds to a different spatial 
frequency, from the easily recognized low frequency to the 
not easily recognized high frequency. Each four-bar has 20 
images (10 each for the black and the white wrinkles), 
which can be divided into five categories (No.1-5). 
Therefore, a total of 100 images were utilized, of which 60 
images were provided for BPNN(Back Propagation Neural 
Network) for training and learning purposes, and the 
remaining 40 images were utilized for test purposes. 
Additionally, the obtained MRTD overall average 
temperature difference were adopted as the output of 
BPNN and effective features were obtained as inputs to 
BPNN [3]. The BPNN parameter setting in Table2.  
Table 2 Network parameter setting 
Input unit 7 unit (Φ1,Φ2,Φ3,Φ4,Φ5,Φ6,Φ7) 
Hide unit 9 unit 
Out unit 11 unit (MRTD of average) 
Number of times 50000 
Learning rate 0.5 
Momentum term 0.5 
Training and test 60 Training samples, 40 test samples 
The BPNN was then trained to recognize objects based on 
the features. The results from human vision and BPNN 
