2一、中文摘要
醫院是進行救治傷病患、安置住院病人的重要場所，各種異常現象的偵測與警報是醫院
安全性的重要一環。本子計畫中，歸納了數種醫院內部可能會發生的異常現象，設計出各自
對應的偵測方法，提出警報讓院方進行應變。整理出的異常現象包括：病人於走廊或病房內
跌倒、監視系統遭受破壞、不明遺留物、區域異常溫度升高、與突發混亂場面等等。本子計
畫第一年中，將透過監視系統取得的畫面中，判斷是否有病人於走廊或病房內跌倒的狀況，
在行動不便的病人發生跌倒的情形時能及時提出警報，醫護人員便能立刻前往處理，本年度
也將研發影像前處理技術，以解決醫院內某些監視系統須透過玻璃進行錄影，影像內容可能
會有光影和反光等雜訊，有時甚至會產生扭曲現象等等的問題。第二年預計研究如何偵測監
視系統是否遭受破壞，以及研究如何偵測區域異常溫度升高，將之視為火災前兆，而非等到
已經起火才發出警報。第三年則研究如何偵測突發混亂場面，立即通知警衛和保全前往處理，
而不必等待人為通知，有效降低混亂情形擴大的機會，另外，醫院內部的不明遺留物可能為
爆裂物，或是病患家屬所遺失的隨身物，在本年度中也將針對不明遺留物的偵測進行研究，
最後綜合三年的研究成果，整合出一套醫院內部異常情形偵測之警報系統，提昇醫院內部整
體之安全性。
關鍵詞：異常事件、火焰偵側、跌倒行為分析、遺留物偵測
二、英文摘要
Hospital is a place to cure, heal, and settle down patients. The detection and precausion of various
abnormal events plays a very important role to ensure the security of hospitals. In this project, we
summarize all possible abnormal events that can be detected by video surveillance and design the
corresponding applicable event detection algorithms. The purpose is to issue precausion message of
each event in advance so that the hospital can take appropriate reactions to alleviate the damage.
These abnormal surveillance events include the falling of patients or visitors in corridors, the
destruction of surveillance system, unknown left objects, abnormal temperature change in certain
areas, and sudden or abrupt chaos in some areas. In the first year of this subproject, we plan to
develop algorithm that can detect the falling or dangerous action (or behavior) reacted by patients or
non-patients (such as doctor, nurse, visitor…) in the hospitals so that the emergence team can take 
care of the events immediately. Sometimes, surveillance equipments may be mounted outside the
glass. The video sequences takes inside the glass will definitely contain some unwanted effects,
such as the glare, reflection, and distortion brought by glass. These problems have to be resolved in
4using a modified ICP algorithm from multiple views. Fujiyoshi et al. [11] presented a framework
to recognize postures by extracting their skeletons along their boundary points. The contour-based
method is simple and efficient for making a coarse classification of human postures. However, it
is easily disturbed by noise, imperfect contour extraction, or occlusions.
This report presents a novel approach to recognize human behaviors using the techniques of
deformable triangulations and string matching. Since a human behavior is an action result of a
series of human postures appearing at different time, this report first presents a new posture
classification scheme to classify different postures. The scheme first uses the technique of Delaunay
triangulation [34] to decompose a body posture to different triangle meshes. Then, a depth-first
search is applied to obtaining a dfs spanning tree from the result of triangulation and thus different
skeleton features can be extracted as the synthetic meanings for describing the analyzed posture.
Since a triangle can capture more information than a boundary pixel, the proposed scheme of
skeleton extraction has more robustness and effectiveness than the silhouette-based methods [11].
In addition to skeleton features, the spanning tree also can provide important information for
decomposing a posture to different body parts like head, hands, or feet. Thus, we can define a new
posture descriptor, i.e., the centroid context to describe a posture up to a semantic level. The
centroid context records different visual characteristics viewed from the centroids of the analyzed
posture and its corresponding body parts. Since the two descriptors are complement to each other,
we can compare and classify all desired human postures very accurately. According to these two
descriptors, a clustering technique is further proposed to automatically generate a set of key
postures from training sample for human behavior modeling. Then, each human behavior can be
converted to a set of symbols including posture types and their temporal information. Based on
this string representation, a novel string matching scheme is proposed to analyze different human
behaviors. With this scheme, even though behaviors have different time-scaling changes, all
desired types can still be well recognized. Extensive experimental results reveal the feasibility and
superiority of the proposed approach, even in the case of challenging conditions.
四、系統架構
Details of the system are shown in Fig. 1. First of all, we use the method of background
subtraction to extract different body postures from video sequences. After that, a triangulation
technique [34] is then used to divide a body posture into different triangle meshes. From the
triangulation result, we propose a graph search method to find a spanning tree for capturing the
skeleton feature of the analyzed body posture. Then, the skeleton-based method can be proposed
for segmenting a posture to different body parts by removing the branching points from its
corresponding spanning tree. It is a coarse search to find a rough result of body part segmentation.
6Fig. 3 shows one example of triangulation result.
(a) (b)
Fig. 3 Triangulation result of a body posture.
5.1 Skeleton Extraction Using Triangulation
2
Pb
0
Pb1
Pb
0n
1n
(a) (b)
Fig. 4: Body component extraction. (a) Triangulation Result of a posture. (b) A
spanning tree of (a).
Assume that P is a binary posture. According to the technique of triangulation, P will be
decomposed to a set P of triangle meshes, i.e., 0,1,..., -1{ } TPP i i N  . Each triangle mesh i in
P has the centroid iC . Given two triangulation meshes i and j , they are connected if
they share one common edge. Then, according to this connectivity, P can be converted to a
undirected graph PG , where all centroids iC in P are the nodes in PG and an edge exists
between
i
C and jC if i and j are connected. Then, we can perform a graph searching
scheme on PG for extracting its skeleton feature.
First, we seek a node H whose degree is one and position is the highest for all the nodes in PG .
H is defined the head of P. Then, starting from H, we perform a depth-first search to find a
spanning tree PbfsT . The tree PbfsT will capture the skeleton feature of P. Fig. 4(a) shows the
result of skeleton extraction (a spanning tree) obtained by a depth first search.
5.2 Body Part Segmentation
According to the above skeleton extraction result, this section will propose a coarse-to-fine scheme
to segment a posture to different body parts.
5.2.1 Body Part Segmentation Using Skeletons
In the previous section, we have presented a tree searching method to find a dfs tree PbfsT from P
using a depth-first searching scheme. In this tree, if a node contains more than one children, we
call it as a branching node. The branching node is an important key to decomposing P to different
body parts. Like Fig. 4, (b) is the dfs tree obtained from (a). There are three branch nodes in Fig.
8Once the initial values of ,i k and ,i k can be obtained, the EM (Expectation maximization)
algorithm [35] is used to find the prior probability ( )
iQ k
  . Let ,={( ,i i k  , , ( ))}ii k Q k  be the set
of parameters of the K-component GMM. The EM algorithm performs the E-step and M-step
iteratively to find an accurate solution of i . Once the Gaussian mixture model ( )iQp v has been
established, we can then reclassify each pixel v in the analyzed posture P by a maximum a
posteriori (MAP) classifier. The MAP classifier assigns v to class l (the lth body part) when
, ( | ) ( | )l ii l P Q v P Q v  . (4)
According to the Bayesian theory, the rule of (4) to assigns v to class l can become:
, ( ) ( )
l iQ Q
i l p v p v  . (5)
5.2.3 Model-driven Body Part Segmentation
(a) (b)
Fig.5 (a) Occlusion between two legs. (b) Models for solving the failure of body part
segmentation.
In practice, one body parts sometimes will occlude another one due to their similar color or
shadows. Like Fig.5, the two legs occlude together due to the similar color of trousers between
them. This project will propose a model-driven method for tackling the above occlusion problem.
Thus, in what follows, we will first use a distance map for posture classification. Then, a proper
posture model can be driven chosen for well segmenting a body posture to different body parts.
5.2.4 Model Selection Using Skeleton
Assume that PS and DS are two skeletons extracted from a testing posture P for testing and
another posture model D in database, respectively. In what follows, we will use a distance
transform to compare the similarity between PS and DS .
(a) (b)
Fig. 6: Distance Transform of a body skeleton. (a) Triangulation polygon. (b) Chamfer map of (a).
Assume that
PS
DT is the distance map of PS . The value of a pixel r in PSDT is its shortest
distance to all foreground pixels in PS , i.e.,
10
method still works well to extract desired body parts. Fig. 8 (d) shows the result of (c) when
another person was handled. Due to the similar colors of body parts, many occlusions happed
along the boundaries of hands. Experimental results have shown our method is superior in terms
of accuracy, robustness, and stability in body part segmentation.
Fig. 7: Body part segmentation. (a) and (c) Original images. (b) and (d) Segmentation
results of (a) and (c).
Fig. 8: Body part segmentation. (a) and (c) Original images. (b) and (d)
Segmentation results of (a) and (c).
七、計畫成果自評
本計畫研究內容與原計畫相符約95%，未來將結合視訊監控行為分析技術，並搭配遺留物分
析，作有效的醫院中異常監控事件之偵測。目前的結果具有學術價值（已被IEEE Trans. on
Systems, Man, and Cybernetics--Part A接受）以及應用價值(例如安全監控系統)。另一篇論文
“Carried Object Detection Using Ratio Histogram and Its Application to Suspicious Event
Analysis”已被 IEEE Transactions on Circuits and Systems for Video Technology 接受並已刊出.
此篇論文中可以對遺留物與異常事件分析做正確的分析。
參考文獻
[1] T. B. Moeslund and E. Granum, “A survey of computer vision-based human motion capture,”
Computer Vision and Image Understanding, vol. 81, no. 3, pp. 231-268, Mar. 2001.
[2] R. Cucchiara, C. Grana, A. Prati, and R. Vezzani, “Probabilities posture classification for
human-behavior analysis,”IEEE Transactions on Systems, Man, and Cybernetics-Part A:
System and Humans, vol. 35, no. 1: pp. 42-54, Jan. 2005.
[3] Haritaoglu, D. Harwood, and L.S. Davis, “W4: real-time surveillance of people and their
activities,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 22, no. 8, pp.
809-830, 2000.
[4] S. Maybank, and T. Tan, “Introduction to special section on visual surveilance,” 
International Journal of Computer Vision, vol. 37, no. 2, pp. 173-173, 2000.
12
[24] E.-J. Ong and  R. Bowden, “A boosted classifier tree for hand shape detection,” 
International Conference on Automatic Face and Gesture Recognition, pp.889-894, 17-19
May 2004.
[25] Y. Song, L. Goncalves, P. Perona, “Unsupervised learning of human motion,”IEEE
Transactions on Pattern Recognition and Machine Intelligence, vol. 25, no. 7, pp. 814-827,
2003.
[26] G. Mori, X. Ren, A. A. Efros, and J. Malik, “Recovering Human Body Configuration: 
Combining Segmentation and Recognition,”Proceedings of the 2004 IEEE Computer
Society Conference on Computer Vision and Pattern Recognition, vol. 2, pp.326-333, 2004.
[27] S. X. Ju, M. J. Black, and Y. Yaccob, “Cardboard people: a parameterized model of
articulated image motion,”International Conference on Automatic Face and Gesture
Recognition, pp. 38-44, Killington, Vermont, 1996.
[28] D. Ayers, R. Ramura, and K. Fukunaga, “Monitoring human behavior from video taken in
an office environment,”Image and Vision Computing, vol. 19, no. 22, pp.833-846, Oct.
2001.
[29] E. Horowitz, S. Sahni, and S. A. Freed, Fundamentals of data structure in C, W. H. Freeman
and Company, New York, USA.
[30] G. Borgefors, “Distance transformations in digital images,” Computer Vision, Graphics, and
Image Processing, vol. 34, no. 3, pp. 344-371, Feb. 1986.
[31] M. Bern and D. Eppstein, Mesh generation and optimal triangulation, Computing in
Euclidean Geometry, 2nd Ed., World Scientific, 1995, pp.47-123.
[32] Chris Staufer and Eric Grimson, “Learning patterns of activity using real-time tracking,” 
IEEE Transactions on Pattern Recognition and Machine Intelligence, vol. 22, no. 8, pp.
747-757, 2000.
[33] D. Chetverikov and Z. Szabo “A simple and efficient algorithm for detection of high
curvature points in planar curves,”Proc. 23rd Workshop of the Austrian Pattern Recognition
Group, pp.175-184, 1999.
[34] L. P. Chew, “Constrained delaunay triangulations,” Algorithmica, vol. 4, no.1, pp.97-108,
1989.
[35] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classification (2nd Edition),
Wiley-Interscience, 2000.
可與其他學者或業界專家進行學術或實務上之交流。因此，對於學生未來進行
論文撰寫、相關學術研究與實務上之應用等方面，可謂受益良多。 
 
三、考察參觀活動(無是項活動者省略) 
略 
 
 
四、建議 
由參加這次會議，發覺許多優秀與有深度的論文都會用到許多的統計數
學，但對於統計或數學的駕馭力，多數的台灣研究生似乎都很欠缺，尤其是現
補習教育的盛行，許多研究生能考上好學校，是因從大二或大三就開始補習，
對同樣的習題與科目一直磨練，雖然研究所考試能獲得高分，但不代表真的有
對應的能力來解決問題，只能說當時的運氣及記憶力比較好，創造能力並無跟
著增長，有點令人感嘆，希望國內教育能多加強數學與統計知訓練。 
   另一方面，目前台灣學生，由於有國防役與進入科技公司有股票及獎金可以
領取，因此越來越少人願意留學，這以後可能造成台灣人才的斷層，反之隔岸
的大陸，留學幾乎是大陸學子的第一優先選擇，因此，在可預見的將來，有很
大的可能在影像視覺、控制這個領域，越來越多的大陸的學生冒出頭來，不論
是量或質都可能超越台灣，實令人警惕與擔心。 
 
五、攜回資料名稱及內容 
 
攜帶回一片論文光碟片，可供研讀與發展新技術 
 
六、其他 
 
 
 
 
and spatial consistencies between each segmented regions.  
Then, each desired pedestrian can be more accurately 
extracted for content analysis even though they are occluded 
with other objects or in complex backgrounds.  
Experimental results have shown the effectiveness and 
superiority of the proposed method in pedestrian 
segmentation.  
2. System Overview 
The method proposed in this paper is shown in Fig. 1.  First 
of all, we use the Adaboost algorithm to train a detector for 
detecting all possible pedestrians from the input image.  
Then, we segment the query image into different regions 
using the triangulation-based algorithm and Watershed 
transform.  Then, we can generate new labeled regions 
from the two segmentation results obtained using a labeling 
technique.  According to the normal appearance and 
rectangle obtained by pedestrian detection, we divided the 
parts into foreground and background as an initial 
segmentation of each pedestrian.  Then, parts of pedestrian 
regions are more accurately estimated and extracted from the 
new labeled regions using the kernel density estimation. 
 
Fig. 1  Flowchart of the proposed scheme. 
3. Pedestrian Detection 
        
(a)          (b)         (c) 
Fig. 2: Different kinds of rectangle features. 
This section presents a learning method to learn a 
strong classifier from a set of training images for pedestrian 
detection.  The learning method we use is the Adaboost 
algorithm which combines a set of ‘important’ weak 
classifier to form a strong classifier for object detection.  
Each weak classifier uses a specific feature for quickly 
filtering out impossible candidates. Fig. 2 shows three kinds 
of rectangle features generated for pedestrian detection. 
Then, the Adaboost algorithm is applied to learning a strong 
classifier from the set of simple features by iteratively 
adding features to the strong classifier.  When more 
features are added, the adding technique will directly 
increase lots of computation time for the designed classifier 
to detect objects.  However, if a cascaded structure [9]is 
used for training the strong classifier, its efficiency will be 
significantly improved.  With the cascade, the original 
classification process will become a series of stage-wise 
rejections of non-object patterns.  The cascade can quickly 
reject most of non-object regions but pass all of desired 
object patterns stage by stage.  Each classifier in the 
cascade is required having a very high detection rate, but 
only a moderate false positive rate.  An input region is 
passed from Ht to Ht+1 if it is classified as an object, 
otherwise it is rejected.  The detection error will be 
significantly reduced if more classifiers Ht are used.  Since 
most non-object patterns are rejected quickly, the designed 
detector can extremely fast detect all desired objects. 
4. Segmentation using Triangulation and Watershed 
Algorithm 
Once different pedestrians have been detected, to more 
precisely extract pedestrians from background, we employ 
color and edge features to segment an image into different 
regions.  
4.1 Watershed Transform 
The most popular algorithm for color segmentation is the 
so-called Morphological Watersheds segmentation [3].  The 
concept of watersheds is based on visualizing an image in 
three dimensions: two spatial coordinates versus gray level.  
In such a “topographic＂interpretation, the algorithm tries 
to find the watershed lines.  Assume that a hole is punched 
in each regional minimum and that the entire topography is 
flooded from below by letting water rise through the holes at 
a uniform rate.  When the rising water in distinct catchment 
basins is about to merge, a dam is built to prevent the 
merging.  The flooding will eventually reach a stage when 
only the tops of the dams are visible above the water line.  
The dam boundaries correspond to the divide lines of the 
watersheds.  Therefore, they are the (continuous) 
boundaries extracted by a watershed segmentation algorithm. 
The local minima are derived from homogeneous intensity 
regions.  When the surface of the water in each catchment 
basin reached the crest, a dam is made for warding off the 
water overflow into the nearby catchment basins.  Lastly, 
the surface of water in each catchment basin reached the 
same level but is confined within the region surrounded by 
the crest lines or dams in the gradient image.  Then, each 
region will be assigned a unique label. 
4.2 Segmentation using Triangulation 
Although color is a useful feature for object segmentation, it 
often fails to work if objects have similar color to the 
background.  Like Fig. 3, due to the similar color between 
the object’s foot and the background, they were not well 
segmented and merged together.  In this case, edge will 
provide useful information for making objects be better 
segmented from frames.  In this paper, the Canny’s edge 
detector is first applied to extract all possible edges from 
each current frame.  After that, the Watson-Bowyer 
algorithm [7] [8] is used proposed for segmenting the query 
image into different regions from its edge map.   
      
Fig. 3. Bad results of image segmentation using colors.  
