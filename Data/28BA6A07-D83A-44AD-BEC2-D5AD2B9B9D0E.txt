行政院國家科學委員會專題研究計畫成果報告 
新興的通用啟發法應用於排程問題 
Application of emerging meta-heuristics to scheduling problems  
計畫編號：NSC－96－2221－E－011－025－MY3 
執行期限：96 年 8 月 1 日至 99 年 7 月 31 日 
主持人：廖慶榮 教授   台灣科技大學工業管理系 
計畫參與人員：鍾翠萍  台灣科技大學工業管理系博士班 
鄒馨慧 台灣科技大學工業管理系博士班 
郭紋伶  台灣科技大學工業管理系碩士班 
劉宜婷  台灣科技大學工業管理系碩士班 
王聖瑋  台灣科技大學工業管理系碩士班 
 
中文摘要 
蟻群最佳化（Ant Colony Optimization；ACO）與粒子群演算法（Particle Swarm 
Optimization；PSO）為具有潛力的兩種新興通用啟發法，透過轉換，可以應用於各種問
題。在本研究中，我們依序探討在供應鏈、越庫作業與混合流程型工廠下，三種不同生
產環境的排程問題，透過引入派工法則以及混合其它通用啟發法的方式，提出更有效的
ACO 與 PSO，希望未來有機會能應用在實務問題上。研究主要區分為以下三個部分： 
Part I: 應用蟻群最佳化協調兩階段生產系統之整備時間 
在第一年度中，我們應用 ACO 於排程問題。ACO 是一個啟發自螞蟻群體合作行為
之新興共通啟發式演算法。目前蟻群最佳化已廣泛應用於各種最佳化組合問題上，如銷
售員問題（Traveling Salesman Problems；TSP）、二次指派問題（Quadratic Assignment 
Problems；QAP）及車輛派遣問題（Vehicle Routing Problems；VRP），但蟻群最佳化
應用於排程問題之研究上仍相當稀少。因此，本研究將應用蟻群最佳化於協調兩階段供
應鍊之時間成本問題。 
本研究考量協調兩階段供應鍊之時間成本問題。此問題是由一個廚房家具工廠其製
造鍊之實際應用延伸而來。工廠包含兩連續加工階段，即切割與塗漆作業。在不同階段
中，所有屬性皆相同之物品組成一批量。同一階段內，當一組新批量的屬性類別和前一
批量的屬性類別不同時，即產生整備成本，此成本與批量先後次序無關。本研究之目標
為決定所有批量之順序，以最小化總整備時間成本。本研究中，我們首度提出一派工法
則，可相當有效率地產生比基因演算法（Genetic Algorithm；GA）更好的解。此演算法
結合派工法則與產生初始解之方法，發展一 ACO 以更進一步改善此解，並在極短的運
算時間下，得到顯著優於其他之共通啟發式演算法，實驗結果顯示我們提出之 ACO 演
算法有很好的求解效果。 
Part II: 粒子群演算法應用於越庫作業系統之時窗車輛指派問題 
越庫作業被認為是一個在供應鏈管理中能夠有效控制存貨流動的方法，在第二年度
中，我們將探討粒子群最佳化演算法（PSO）應用於越庫作業系統之時窗車輛指派問題。
在這個模型之中，每台車輛都有時間窗的限制，且車輛數超過現有的碼頭數。問題主要
受三個因素影響：(1) 車輛到達和離開時間窗，(2) 碼頭間的運輸成本，(3) 越庫作業系
 2
In the second year, we consider a truck dock assignment problem with an operational 
time constraint in a crossdock where the number of trucks exceeds the number of docks 
available. The objective of the problem is to find an optimal truck dock assignment to 
minimize the sum of the total dock operational cost and the penalty cost for all the unfulfilled 
shipments. The problem feasibility is affected by three factors: the arrival and departure time 
windows of each truck, the operational time for the cargo shipments among the docks, and the 
total capacity available to the crossdock. We propose fast and effective heuristics for 
determining very good solutions for the problem. To further improve the solution, a Particle 
Swarm Optimization (PSO) algorithm combined with the heuristics is also developed. 
Computational experiments show that the heuristics themselves perform better than an 
existing tabu search (TS) algorithm in terms of computation time and solution quality. 
Considering only the metaheuristic itself, the PSO algorithm also outperforms the TS 
algorithm when both employing the heuristics. 
Part III: An approach using particle swarm optimization and bottleneck heuristic to solve 
hybrid flow shop scheduling problem  
The hybrid flow shop (HFS) is a common manufacturing environment in many industries, 
such as the glass, steel, paper and textile industries. In this research, we present a particle 
swarm optimization (PSO) algorithm for the HFS scheduling problem with minimum 
makespan objective. The main contribution of this paper is to develop a new approach 
hybridizing PSO with bottleneck heuristic to fully exploit the bottleneck stage, and with 
simulated annealing to help escape from local optima. A restart procedure is also employed to 
avoid premature convergence. The proposed PSO algorithm is tested on the benchmark 
problems provide by Carlier and Néron. Experiment results show that the proposed algorithm 
outperform all the compared algorithms in solving the HFS problem.  
Keywords: Ant colony optimization; Particle swarm optimization; Simulated annealing;  
Scheduling; Supply chain; Crossdock; Hybrid flow shop  
 4
B  set of batches 
| |B  number of batches 
jA  set of all possible levels of attribute j  
| |jA  number of levels of attribute j  
ib  batch , 1,2, ,| |i i B= ⋅⋅⋅  
( )j ia b  level of attribute j  for ib  
[ ]kb  batch scheduled in the kth position, 1, 2, | |k B= ⋅⋅⋅  
( )if b  flexibility index of ib  (defined as the number of batches with a level of attribute 
same as ib ) 
[ ] [ ]1( ), ( )j jk ka b a bs +  setup time between batches k  and 1k +  in stage jD   
U  set of unscheduled batches 
jZ  total setup time in stage jD  in a sequence 
( )Z σ  total setup time of partial sequence σ  
( , )Z iσ  total setup time after batch ib  is appended to partial sequence σ   
The two-stage coordination problem with sequence-dependent setup times consists in 
scheduling a set of batches B  on the two stages 1D  and 2D . Because no buffer is available 
between the two consecutive stages, the sequence Q  in which each stage processes all batches is 
identical on the two stages. Hence, we need only to determine a permutation of batches for the 
problem.  
Each batch is characterized by two attributes 1a  and 2a . Let 1A  and 2A  denote the sets of 
all possible levels of 1a  and 2a , respectively. Let [ ]kb  denote the batch scheduled in the k th 
position of a sequence. For two consecutive batches [ ]kb  and [ ]1kb + , a setup time [ ] [ ]1( ), ( )j jk ka b a bs +  is 
required in stage jD  if [ ] [ ]1( ) ( )j jk ka b a b +≠  . Following [6], the sequence-dependent setup time for 
each couple of different levels of attribute ja  is generated from a discrete uniform distribution 
(1,| |)jU A . Thus, there exists a square setup time matrix for each of the two attributes.  
For a given sequence Q , we can calculate the setup times incurred in the two stages, denoted 
by 1( )Z Q  and 2 ( )Z Q , as follows: 
[ ] [ ]
[ ] [ ]
1 1 1
2 2 1
| | 1
1 ( ), ( )
1
| | 1
2 ( ), ( )
1
( )
( )
k k
k k
B
a b a b
k
B
a b a b
k
Z Q s
Z Q s
+
+
−
=
−
=
=
=
∑
∑
 
The objective of the problem can be expressed as 
Min 1 2( ) ( )Z Z Q Z Q= +  
Actually, the problem is a Traveling Salesman Problem (TSP), a well known optimization problem. 
Since the matrixes of setup times are not symmetric, it is an asymmetric TSP. 
3. Proposed Algorithms 
In this section, we first propose a dispatching rule for the problem. Incorporating the 
dispatching rule, an ACO algorithm is then developed to obtain a near-optimal solution. 
3.1  Dispatching rule 
 6
Step 2.2  Local update of pheromone trail  
To avoid premature convergence, a local trail update is performed. The update reduces the 
amount of pheromone for the newly added batch so as to discourage the following ants from 
choosing the same batch. This is achieved by the following local updating rule: 
0( , ) (1 ) ( , )t ti j i jτ ρ τ ρτ= − +  
where (0 1)ρ ρ< ≤ . 
Step 2.3  Local search 
The local search used in our ACO algorithm is the Random Job Insertion Local Search (RJILS) 
proposed by Gajpal and Rajendran [8]. The RJILS rule can be described as follows: 
1.  Set initial sequence kS . 
2. Randomly choose a batch from B  and insert it in all possible positions of kS . Choose the best 
sequence cS  with minimum total setup time. Update kS  by cS  if the latter is better and 
retain kS  otherwise. 
3.  Randomly choose another batch from B  and repeat Step 2 until all batches in B  are selected 
once and only once. 
In order to evaluate the performance of RJILS in our ACO, computational experiments will be 
conducted to compare with two popular local searches: 2-OPT (Nillson [9]) and SWAP (Liao and 
Cheng [10]) in Section 4. 
Step 2.4  Global update of pheromone trail  
The global updating rule is applied after each ant has completed a feasible solution and the 
local search has been implemented. Following the rule, the pheromone trail is added to the path of 
the incumbent global best solution. If the path of batch i  to batch j  belongs to one part of 
incumbent global best solution, then 
1( , ) (1 ) ( , ) ( , )t ti j i j i jτ α τ α τ+ = − ⋅ + Δ  
where (0 1)α α< ≤  is a parameter representing the evaporation of pheromone. The amount 
( , )t i jτΔ  equals *1/ Z , where *Z  is objective value of the global best solution. However, our 
experimental analyses show that this setting of ( , )t i jτΔ  result in premature convergence for our 
problem. To improve this situation, we try to add more pheromone density in the path of global best 
solution leaving more effect of elitist strategy. So the modified global update function becomes  
1( , ) (1 ) ( , ) ( , )t ti j i j i jτ α τ τ+ = − ⋅ + Δ  
where *( , ) /t i j R ZτΔ = . The amount R  is parameter which increases more amount of pheromone 
density. The resulting performance will be shown in Section 4. Moreover, to avoid the solution 
falling into a local optimum that results from the pheromone evaporating to zero, we introduce a 
lower bound to the pheromone trail value by letting 0( , ) (1/ 5)t i jτ τ=  (Stützle and Hoos [11]). 
4. Computational results 
To verify the performance of the LFS rule and the ACO algorithm, two sets of computational 
experiments were conducted. The first one is for the parameter settings, including 0τ , global 
updating rule, and local search. The second one is to compare the proposed algorithm with the 
genetic algorithm of Naso et al. [6], denoted by GA hereafter, and two other ACO algorithms. The 
test problem instances were generated using the same scheme as Naso et al. [6].  
Three different sizes of attributes were tested (i.e., 1 2| | | | 10,20,30A A= = ), and each size was 
assigned a density from 0.1 to 0.4. The setup times for each couple of different levels of attributes 
were generated from a discrete uniform distribution ( )1,| |jU A , 1, 2j =  (Naso et al. [6]). This 
 8
Table 3.  Comparison of some local searches 
Characteristics of problems  2-OPT SWAP  RJILS 
B  1A  2A  Density  Average Best Time Average Best Time  Average Best Time
11 10 10 0.1  45.0+ 45.0+ 0.4 45.0+ 45.0+ 0.4 45.0+ 45.0+ 0.4
20 10 10 0.2  50.0+ 50.0+ 1.6 50.0+ 50.0+ 1.4 50.0+ 50.0+ 1.6
30 10 10 0.3  94.8 94.0 4.2 95.6 94.0 4.0 92.6+ 92.0+ 4.0
40 10 10 0.4  85.2 84.0+ 9.4 86.4 84.0+ 8.4 85.0+ 85.0 9.0
40 20 20 0.1  217.4 214.0 8.8 214.0 210.0+ 7.8 211.4+ 210.0+ 8.8
80 20 20 0.2  314.8 310.0 51.2 313.6 308.0 44.2 306.6+ 300.0+ 46.4
120 20 20 0.3  382.0 374.0 155.4 373.6 370.0 130.4 364.4+ 359.0+ 139.4
160 20 20 0.4  395.6 385.0 349.6 383.4 375.0+ 288.4 379.0+ 375.0+ 304.4
90 30 30 0.1  519.6 511.0 71.0 514.8 500.0 61.2 505.2+ 497.0+ 64.6
180 30 30 0.2  743.6 725.0 480.6 714.6+ 697.0+ 403.8 718.4.0 714.0 424.8
270 30 30 0.3  1020.8 1000.0 1537.6 1011.4 980.0 1276.6 997.2+ 973.0+ 1338.4
360 30 30 0.4  1009.0 975.0 3596.6 1008.4 993.0 2870.2 984.8+ 977.0+ 3066.8
+The proposed approach is best 
 
In the second set of experiments, we first tested a case provided by Naso et al. [6]. The instance 
describes a weekly product demand based on the actual customer orders in a furniture plant. Table 4 
shows a weekly production plan consisting of 251 production batches with 32 cutting classes and 
11 color classes. The setup times for each couple of different levels of attributes are random 
numbers selected in the range [1,| 32 |]  for the cutting department and [1,|11|]  for the painting 
department. There are 251! possible sequences in the instance. We compare the solutions obtained 
by GA, LFS, and ACO. The results are summarized in Table 5, which shows that for this real case 
the LFS rule presents a better performance than GA while using much less computation time. The 
ACO algorithm can further improve the solutions from LFS with more computational requirements.  
To further evaluate the performance of the proposed algorithm, we established a comparison 
among LFS, GA, GA/LFS (using LFS as one seed), and ACO on a large sample of experimental 
data. For a fair comparison, all the four algorithms were coded in C++ and run on the same PC 
environment. The maximum iteration of ACO was set as 500 while the maximum iterations of GA 
and GA/LFS were set flexible to make the three algorithms have roughly the same computation 
time. From Table 6, it can be observed that the LFS rule yields results significantly better than GA 
while using much less computation time (except for some small problems). Besides, the GA/LFS 
outperforms GA for all the instances, which indicates the advantage of using LFS in GA. The ACO 
algorithm can further improve the solution from the LFS dispatching rule and it performs best for 
all the instances. 
Finally, we made a comparison of our ACO with two new ACO algorithms of Hossein and 
Nima [12], i.e., KCC-Ants and ELU-Ants, that were designed for solving the traveling salesman 
problem (TSP). The two ACO algorithms contain new and reasonable local updating rules that 
make them more efficient in solving TSP. As mentioned earlier, our problem is equivalent to an 
asymmetric TSP problem, so KCC-Ants and ELU-Ants can be used to solve our problem. To make 
a fair comparison, we use the LFS rule and the new local search in both KCC-Ants and ELU-Ants. 
Both KCC-Ants and ELU-Ants were run 700 iterations and ACO was run 500 iterations so as to 
achieve roughly the same computational time. From Table 7, it can be observed that KCC-Ants 
outperforms ELU-Ants. ACO and KCC-Ants have similar performance for small problems, but 
ACO is always superior to KCC-Ants when the number of batches exceeds 40 batches. 
 
 
 
 10
Table 7.  Comparison of ELU-Ants, KCC-Ants, and ACO 
Characteristics of 
problems  ELU-Ants KCC-Ants ACO 
B  1A  2A Density  Average Time Average Time Average Time 
11 10 10 0.1  45.0+ 0.1 45.0+ 0.2 45.0+ 0.2 
20 10 10 0.2  52.0 0.9 50.0+ 1.1 50.0+ 0.8 
30 10 10 0.3  96.0 2.3 94.4 2.7 93.4+ 1.8 
40 10 10 0.4  87.0 4.1 84.2+ 4.3 85.2 3.4 
40 20 20 0.1  217.0 4.0 215.8 4.5 213.4+ 3.6 
80 20 20 0.2  319.4 21.2 319.2 23.1 312.8+ 20.4 
120 20 20 0.3  389.8 61.5 388.4 64.2 369.8+ 61.0 
160 20 20 0.4  403.0 133.2 403.2 139.5 384.2+ 135.8 
90 30 30 0.1  519.6 31.2 523.8 33.2 508.6+ 29.0 
180 30 30 0.2  762.8 194.3 772.6 208.3 732.0+ 192.4 
270 30 30 0.3  1098.6 632.1 1071.2 640.7 1005.2+ 606.0 
360 30 30 0.4  1094.01504.3 1086.81619.1 994.4+ 1389.8 
+The best algorithm for the instance 
5. Conclusions and future research 
This paper has investigated the setup coordination problem in a two-stage production system 
where the setup times are sequence independent. The objective is to minimize the total setup time in 
the two stages. First, we have proposed an LFS dispatching rule, which combines the flexibility 
index and the setup times into a single index. Then, an ACO algorithm is developed to obtain a 
near-optimal solution. ACO is chosen as the solution approach because the problem is equivalent to 
an  asymmetric Traveling Salesman Problem (TSP). The developed ACO algorithm has several 
features that make it effective for the problem.  
To evaluate the LFS rule and the ACO algorithm, they have been compared with an existing 
genetic algorithm and two new ACO algorithms for solving TSP. Computational results show that 
the LFS rule is quite useful and the ACO algorithm performs significantly better than the genetic 
algorithm and the two ACO algorithms.  
References 
[1] Agnetis A, Detti P, Meloni C, Pacciarelli D. Set-up coordination between two stages of a 
supply chain. Annals of Operation Research 2001; 107: 15–32. 
[2] Meloni C. An Evolutionary algorithm for the sequence coordination in furniture production. 
Lecture Notes of Computer Science 2001; 2264: 91–106. 
[3] Mansouri S A. Coordination of set-ups between two stages of a supply chain using 
multi-objective genetic algorithms. International Journal of Production Research 2005; 43: 
3163–3180. 
[4] Mansouri S A. A simulated annealing approach to a bi-criteria sequencing problem in a 
two-stage supply chain. Computers and Industrial Engineering 2006; 50: 105–119. 
[5] Detti P, Meloni C, Pranzo M, Minimizing and balancing setups in a serial production system. 
International Journal of Production Research 2007; 45: 5769–5788. 
[6] Naso D, Turchiano B, Meloni C. Single and multi-objective evolutionary algorithms for the 
coordination of serial manufacturing operations. Journal of Intelligent Manufacturing 2006; 
17: 251–270. 
 12
Part II. An approach using particle swarm optimization to solve truck dock 
assignment problem in cross docking systems with operational time constraint. 
1. Introduction 
In today’s distribution environment, it is always a pressing matter how the operations can be 
made more efficiently. To address the need, most companies are reducing costs by reducing 
inventory at every step of the operation, including logistics and distribution. From another vantage 
point of operational efficiency, customers demand a better service, which translates into more 
accurate and timely shipments. Crossdocking is considered as one innovative warehousing strategy 
that is of great potential for better controlling the logistics and distribution costs while 
simultaneously enhancing the level of customer service Apte et al. [1]. Crossdocking is a material 
handling and distribution concept in which items move directly from the receiving dock to the 
shipping dock, without being stored in a warehouse or distribution center. This concept is usually 
achieved by a crossdock terminal which is a distribution center exclusively dedicated to the 
transshipment of truck loads. In comparison to traditional warehouses, a crossdock carries no or at 
least a considerably reduced amount of stock Boysen [2].   
In a typical crossdock system, the primary objective is to eliminate storage and excessive 
material handling Yu et al. [3]. Lim et al. [4] worked on various transshipment problems in a 
crossdock distribution network to show how to achieve the minimum total transportation and 
inventory costs by consolidating the transported items. They found that the costs can be reduced by 
fewer trucks used and less inventory holding time if the trucks are more efficiently scheduled. By 
scheduling efficiently, it means that the right amount of cargos can reach crossdocks at the right 
time and then be consolidated in the right way within crossdocks. Napolitano [5] described various 
crossdock operations in manufacturing, transportation, distribution and retailing, all of which have 
the common feature of consolidation and thus short cycle times are made possible by known pickup 
and delivery times. 
In this paper, we consider an over-constrained truck dock assignment problem with time 
window, operational time, and crossdock capacity constraint, proposed by Miao et al. [6]. This 
problem involves the number of trucks exceeding the number of docks available and the capacity of 
the crossdock being limited. The objective of the problem is to minimize the sum of the total dock 
operational cost and the total penalty cost for the unfulfilled shipments. The problem is NP-hard 
because the air gate assignment problem, a special case of the problem, is NP-hard [5, 6]. Since the 
problem is NP-hard, Miao et al. [6] have developed two meta-heuristics, Tabu Search (TS) and 
Genetic Algorithm (GA). Experiments show that TS dominates GA in terms of both solution quality 
and the solving runtime, and hence TA will be used for comparison in this paper.  
The rest of the paper is organized as follows. The proposed heuristics and Particle Swarm 
Optimization (PSO) algorithm are presented in sections 2 and 3. Computational results of test 
problems are shown in section 4. Finally, section 5 summarizes the concluding remarks. 
2. The proposed heuristics  
For the considered problem, all trucks have the time limit and the capacity constraint, which 
means that the number of cargos inside the crossdock is limited by its total capacity. The objective 
is to minimize the sum of the operational cost and the penalty cost. Based on these factors, we 
propose two heuristics for obtaining near optimal solutions for the problem. The two heuristics have 
the same basic idea but different factors to be considered, which will be described later. In the 
following description, the notations are used: 
 14
Step 1: Define , 1i jh =  if ,j ia d i j≥ ≠ ( 1,2, , ; 1,2, , ),i n j n= =K K  and 0 otherwise. 
Step 2: If max{ }a ix x= , then set aq n= ; if min{ }a ix x= , then set aq =1; the number of iq  is 
decided by order.  
Step 3:  Set ,1 /( / 3) ( 1, 2, , ; 1, 2, , ).
n
i i j iiy h q n i n j n== + = =∑ K K  
Step 4: Assign the truck with max{ }iy  ( 1,2, ,i n= K ) to dock k  ( 1,2, ,k m= K ). If there is more 
than one truck with max{ }iy , choose the one with max{ }ix . When truck A  has been 
assigned, set 0,Ay = , 0,i Ah =  , 0.A jh =   
Step 5: Suppose truck A  is assigned to dock k . Then we need to consider iy  of the rest trucks 
with ,i Ah  equal to 1. Assign the truck with max{ }iy  to dock k  if it is allowed. If there 
is more than one truck with max{ }iy , choose the one with max{ }ix .  
Step 6:  Repeat Step 5 until no trucks can be assigned at the same dock. 
Step 7:  Return to Step 2. Schedule anther dock ( 1)k k= +  until k m> . The remaining trucks 
will be assigned to dock 0. 
2.3 Adjusting infeasible solutions 
Every solution must satisfy the condition that the occupied capacity at boundary time points of 
all time windows is less than the capacity of crossdock C . Due to this restriction, the solution 
obtained by the heuristics needs to be properly adjusted by the following rule: 
Step 0: If 0,is = ,set  0i jf = and calculate ,0 0 ( 1, 2, , ; 1, 2, , ).n n i ji j f i n j n= = = =∑ ∑ K K  
Step 1: If ,0 0
n n
i ji j f C= = >∑ ∑ , let X  be the truck with max{ }ix . 
Step 2: Assign 0Xs = . Do Step 0 until ,0 0n n i ji j f C= = ≤∑ ∑ .
 
 
3. Meta-heuristic: particle swarm optimization  
Particle Swarm Optimization (PSO) is a population-based stochastic optimization technique 
developed by Eberhart and Kennedy [7]. It was inspired by common social behavior of bird 
flocking or fish schooling. With PSO, the system is initialized with a population of random 
solutions and searches for optima by updating generations Allahverdi et al. [8]. It considers the 
performance of all particles and each particle’s direction of movement. In the following, we first 
describe the velocity of PSO and then sketch the framework used for the problem. 
3.1 Velocity of PSO 
During each generation each particle is accelerated toward the previous best position and the 
global best position Settles et al. [9]. A new velocity value for each particle is calculated based on 
its current velocity at each iteration, the distance from its previous best position, and the distance 
from the global best position. The new velocity value is used to calculate the next position of the 
particle in the search space Settles et al. [9]. The particle updates its velocity with the following 
three equations:  
1 1 2 2( ) ( )V Vw c r pbest present c r gbest present= + − + −  (1)
  ,V m V V m> = −  (2)
  present present V= +  (3)
  In the above equations, V  is the particle velocity, present  is the current particle (solution), 
pbest  is the best solution of that particle in history and gbest  is the best solution of all 
generation. The parameter w
 
is the weight of previous particle velocity, and 1r  and 2r  are 
 16
same dock randomly, and swap move the two trucks’ assigned docks.  
The shaking rule in Step 5 is defined as follows: If gbest  does not change within 20 iterations, 
generate a solution by changing an assigned truck on gbest . Then find the worst solution in 
particles and replace the particle with the new one.  
4. Computational study  
Two experiments are conducted in this section. The first experiment is to evaluate the 
performance of the proposed heuristics and PSO algorithm. The second experiment is to compare 
the PSO algorithm with a tabu search (TS), the existing best metaheuristic, developed by Miao et at. 
[6]. To have a fair comparison, both algorithms were coded in C++ and executed on a Pentium Dual 
CPU at 3.4 GHz under Windows XP with 0.99 GB RAM. 
We used the same problem generating scheme as Miao et al. [6]. We chose a representative 
layout of a crossdock that has two parallel sets of terminals, as shown in Fig. 2 (Miao et al. [6]). 
This layout is quite common in crossdocks today. We denote the distance between two adjacent 
docks within one terminal (e.g., dock 1 and dock 3) to be 1 unit and the distance between two 
parallel docks in different terminals (e.g., dock 1 and dock 2) to be 3 units. It is assumed that only 
horizontal and vertical walk is allowed. For example, if a carriage hoist wants to transfer one pallet 
from dock 3 to dock 2, the walking distance is 1 3 4+ =  units.  
The test data generation program requires two parameters: the number of trucks ( n ) and the 
number of docks ( m ). The start points of truck time window ia  (1 i n≤ ≤ ) were uniformly 
generated in the interval [1,70 /n m ]. The end points of truck time window id  were uniformly 
generated as i id a= + [45,74]. The rectilinear walking distances between dock k  and l  were 
calculated and then proportionally converted to the corresponding operational time ,k lt . The 
number of shipping pallets ,i jf  was randomly generated in the interval [6,60] if j id a≥  (0 
otherwise). The operational cost per unit time from dock k  to dock l  ( ,k lc ) was uniformly 
generated in the interval [1,4]. The penalty cost per unit cargo from truck i  to truck j  ( ,i jp ) was 
generated in the interval [8,12]. The total capacity of the crossdock was set to ,i ji n j nC fβ ≤ ≤= ∑ ∑ , 
where β  was generated in the interval [0.6,0.9]. 
Before conducting a formal experiment, we determine the appropriate parameter values for the 
PSO algorithm as follows. Maximum number of iterations is 510  and each time 15 particles are 
generated. The algorithm is terminated if the best solution is not improved within 500 iterations. 
Three categories of instances were designed and created to test the algorithms. The detailed 
results are presented in Tables 1-3. Each category has 40 test cases, sorted into 8 groups. In each 
group, the dock number, truck number and truck setup are the same, but the crossdock capacity is 
different according to the random parameter β . The first row of the each table specifies the 
instance size, where  n m×  denotes that there are n  trucks and m  docks for this instance group. 
The rest of rows provide the results of various algorithms proposed in this paper. Algorithm H 
denotes the algorithm that selects the better solution from the two proposed heuristics, and the TS-H 
algorithm denotes the TS algorithm of Miao et al. [6] with a better initial solution from Algorithm 
H. Each result cell contains three values: the average objective value, the gap to the best objective 
value of all, and the average computational time in seconds. 
The “gap” is used as the performance measure and is computed according to the following 
equation: 
 18
Table 1.  Computatonal Result for small size instances 
Instance size 12 4× 14 4× 16 4×  18 4×  12 6×  14 6× 16 6×  18 6×  Average
H1 Obj 12550.2 18106 20784 28582 22280 7651 13561 8743 16532.15
Time(s) 0 0 0 0 0 0 0 0 0
Gap 18.72% 0.05% 25.66% 2.84% 2.48% 0.35% 115.32% 365.40% 66.35%
H2 Obj 12550.2 21404 20784 28582 22280 7651 8080.2 14045 16922.05
Time(s) 0 0 0 0 0 0 0 0 0
Gap 18.72% 18.27% 25.66% 2.84% 2.48% 0.35% 28.30% 647.63% 93.03%
H Obj 12550.2 18106 20784 28582 22280 7651 8080.2 8743 15847.05
Time(s) 0 0 0 0 0 0 0 0 0
Gap 18.72% 0.05% 25.66% 2.84% 2.48% 0.35% 28.30% 365.40% 55.47%
PSO Obj 10571 18097 16540 27793 21741 7624.2 6298 1878.6 13817.85 
Time(s) 5.465 6.281 9.688 12.644 4.003 6.888 8.288 10.713 7.996 
Gap 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00%
TS Obj 11245.8 18904.4 19878.8 28238 22350.6 10324 8282 3378.8 15325.30 
Time(s) 12.681 15.897 19.744 28.515 11.250 15.241 20.853 21.922 18.263 
Gap 6.38% 4.46% 20.19% 1.60% 2.80% 35.41% 31.50% 79.86% 22.78%
TS-H Obj 11510.2 18103 16540 28388.2 22039.4 7635.2 7455.6 1879 14193.83 
Time(s) 12.850 16.025 22.325 28.447 12.087 18.166 18.788 30.785 19.934 
Gap 8.88% 0.03% 0.00% 2.14% 1.37% 0.14% 18.38% 0.02% 3.87%
 
 20
Table 3.  Computatonal Result for large size instances 
Problem size 50 10×  60 10×  70 10×  80 10×  50 12×  60 12×  70 12×  80 12×  Average 
H1 Obj 220100 139609 312781 479825 99529 167733 287498 308426 251937.63
Time(s) 0 0 0 0 0 0 0 0 0
 Gap 10.88% 18.73% 11.67% 19.25% 22.10% 1.17% 2.40% 0.26% 10.81%
H2 Obj 199378 159039 332917 500393 116961 206653 306912 308705 266369.75
Time(s) 0 0 0 0 0 0 0 0 0
 Gap 0.44% 35.25% 18.86% 24.36% 43.49% 24.65% 9.32% 0.36% 19.59%
H Obj 199378 139609 312781 479825 99529 167733 287498 308426 249347.38
Time(s) 0 0 0 0 0 0 0 0 0
Gap 0.44% 18.73% 11.67% 19.25% 22.10% 1.17% 2.40% 0.26% 9.50%
PSO Obj 198506 117589 280081.8 402378 81513 165785.4 280753 307612.6 229277.35
Time(s) 97.534 124.975 243.541 105.612 90.497 154.606 477.918 161.578 182.033 
 Gap 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00%
TS Obj 219479.4 130683.6 346613.6 431187 105000.6 182333.2 309287.6 336365.6 257618.83
Time(s) 189.794 692.879 666.838 960.272 278.428 462.925 607.403 1243.067 637.701 
 Gap 10.57% 11.14% 23.75% 7.16% 28.81% 9.98% 10.16% 9.35% 13.87%
TS-H Obj 198748.4 117731.2 312394.2 465151.8 81607.4 166093.2 285675 307944.4 241918.2
Time(s) 191.928 336.728 480.709 609.169 229.809 381.019 652.656 575.772 432.224 
 Gap 0.12% 0.12% 11.54% 15.60% 0.12% 0.19% 1.75% 0.11% 3.69%
 
 22
Part III. An approach using particle swarm optimization and bottleneck 
heuristic to solve hybrid flow shop scheduling problem. 
1. Introduction 
Production scheduling is a decision-making process that plays an important role in most 
manufacturing and production systems. Effective scheduling can lead to improvements in 
throughput, customer satisfaction, inventory costs, utilization of bottleneck resources, and other 
performance measures. In this paper, we consider a hybrid flow shop (HFS) scheduling problem 
with minimum makespan objective. In real industries, HFS is more commonly seen than traditional 
flow shop, e.g., in glass, steel, paper and textile industries. In a HFS, machines are arranged into 
several stages in series, and each of which has one or more identical machines in parallel. A job has 
to pass through all stages and must be processed by exactly one machine at every stage. 
Many different approaches have been proposed to solve the HFS problem, such as exact 
solution, heuristic and metaheuristic. One of the exact solution methods mostly used for the HFS 
problem is the branch and bound approach. Brah and Hunsucker [1] proposed such a branch and 
bound algorithm, and Portmann et al. [2] presented an improvement based on the introduction of 
genetic algorithm (GA) in the algorithm. Néron et al. [3] proposed a procedure based on energetic 
reasoning and global operations that can enhance the efficiency of branch and bound procedures. 
Riane et al. [4] also presented another branch and bound approach for a three-stage HFS. 
Several heuristics have been developed for the HFS problem. Gupta [5, 6, 7] developed several 
heuristics for the two-stage HFS to minimize the makespan and other objectives. Lin and Liao [8] 
presented a case study of a two-stage HFS in a label manufacturing company to minimize the total 
weighted maximal tardiness. Gupta and Tunc [9] developed four heuristics for a two-stage HFS 
with separable setup and removal times to minimize the makespan. Also, Heydari and Fakhrzad [10] 
proposed a heuristic for a HFS to minimize the sum of the earliness and tardiness costs. 
In recent years, metaheuristics become a popular approach to solve the HFS scheduling 
problem. Janiak and Kozan [11] applied simulated annealing (SA) and tabu search (TS) to solve 
HFS with a cost related objective. Abiri et al. [12] proposed a TS algorithm to solve HFS with 
sequence-dependent setup time. Genetic algorithm (GA) was applied by many authors for solving 
HFS with the objective of minimizing the makespan [13, 14, 15, 16]. It is worth mentioning that the 
benchmark problems generated by Carlier and Néron [17] were used as test problems by many 
metaheuristics, such as artificial immune system (AIS) [18, 19], genetic algorithm [16] and ant 
colony optimization (ACO) [20, 21].  
Particle swarm optimization (PSO), inspired by the flocking behavior of birds, is an emerging 
population-based metaheuristic. In the past few years, PSO has been successfully applied to a large 
number of combinatorial optimization problem, such as traveling salesman problem [22], and the 
vehicle routing problem [23]. PSO has also been applied successfully to scheduling problem such 
as flow shop [24-27] and open shop [28] problems. In this paper, we will present a PSO algorithm 
combined with a bottleneck heuristic and a SA algorithm for the HFS with minimum makespan 
objective. The developed PSO algorithm will also be tested on the benchmark problems of Carlier 
and Néron [17]. 
The rest of the paper is organized as follows. Section 2 introduces the HFS scheduling problem, 
particle swarm optimization and simulated annealing. The proposed PSO, as well as the 
mathematical formulation of HFS, bottleneck heuristic and local search, are presented in section 3. 
In section 4, we provide the experimental results tested on the benchmark problems. Finally, 
conclusions and future research are given in section 5. 
 24
particles are neighbors of each other; thus, the position of the best overall particle in the swarm is 
used in the social term of the velocity update equation [31]. It is assumed that gbest swarms 
converge fast, as all the particles are attracted simultaneously to the best part of the search space 
[31]. However, if the global optimum is not close to the best particle, it may be impossible for the 
swarm to explore other areas, which means that the swarm may be trapped in local optima. On the 
other hand, the local best PSO, or lbest PSO, uses a ring social network topology where only a 
specific number of particles (neighbor count) can affect the velocity of a given particle [31]. The 
swarm will converge slower but can locate the global optimum with a greater chance. 
2.3. Simulated annealing 
SA is a simple local search method introduced by Kirkpatrick et al. [32]. SA algorithm starts 
with an initial solution and moves around the neighbors to generate a new solution. The movement 
of the solution is accepted if the objective value is better, but often a poor solution is accepted with 
some probability controlled by a temperature parameter T . In the annealing process, the 
temperature gradually decreases during the process 0( ) ( ) ,
kT k t alpha= ×  which is called the 
cooling schedule. The cooling schedule is processed repeatedly until it reaches the final temperature. 
The speed of the cooling schedule is important; if it is too fast, it most likely will lead to a local 
optimum. In every temperature, there is an inner iteration which allows enough iteration so that the 
solution stabilizes at that temperature. The following is a pseudo-code for SA algorithm (for 
minimization problem): 
Select an initial solution 0 ;s  initial temperature 0t  
Select a temperature reduction function (cooling schedule) ( )T k   
Outer: While temperature > final temperature                                                  
Inner: While iteration limit itern  is not reached 
Select s  as neighbors of 0s  
0 ( ) ( )f s f sδ = −  
 If 0δ <  
0s s=   
Else    
 Generate ~ (0,1)r U  
If r < exp( / ) tδ− then 0 Ss =  
End Inner 
  ( )t T k=  
End Outer 
Return 0s  
3. Formulation and proposed algorithms 
In this section, we first introduce the mathematical formulation of the problem. Then, we 
present each of the components of the proposed PSO algorithm, including the pure PSO, bottleneck 
heuristic, local search, restart procedure and SA. Finally, we provide the procedure of the proposed 
algorithm.  
There are several assumptions that are commonly made regarding this problem: 
• The n  jobs are independent and available to be processed at time 0.  
• The travel time between consecutive stages and the machine setup time are included in 
the processing time. 
 26
position of the particle sequence is updated according to the following equation [27]: 
          
1 1 1
2 3 1 2 1( ( ( ), ), )
t t t t
i i iX c F c F w F X P G
− − −= ⊗ ⊗ ⊗              (9) 
The update equation consists of three components: the first component is 11( ),ti
t
iw F XA
−= ⊗  
which represents the velocity of the particle and 1F  represents the mutation operator with the 
probability of w . The second component is 11 2 ( , ),ti
t t
i ic F A PB
−= ⊗  which represents the 
“cognition” part of the particle. In this component, 2F  represents the crossover operator with the 
probability of 1,c  and tiA  and 1tiP −  are the first and second parents for the crossover, respectively. 
The third component is 12 3( , ),ti
t t
ic F B GX
−= ⊗  which represent the “social” part of the particle. In 
this component, 3F  represents the crossover operator with the probability of 2,c  and tiB  and 
1t
G
−
 
are the first and second parents for the crossover, respectively. 
3.2.3 Crossover operator 
Pan et al. [27] proposed a new crossover operator, named PTL crossover. The PTL crossover 
is used here because it has an advantage to generate a different offspring even from two identical 
parents. The PLT crossover works as follows: 
Step 1: Choose two different points randomly from the first parent.  
Step 2: Copy the block of jobs from the first parent determined by two-cut points. This block is 
either moved to the right or left corner of the offspring.  
Step 3: Place the empty elements of jobs from the remaining jobs of the second parent. 
3.2.4 Mutation operators 
In the proposed algorithm, two types of mutation procedures are used to sequence jobs and 
each is chosen with a 50% probability. 
Insert mutation. Given a sequence ,q  let x  and y  be two positions in the sequence. A 
neighbor of q  is obtained by inserting the job in x  position to y  position. In the insert 
mutation process, it has a wider search space so it can help to construct a good sequence in the early 
step because the solution is still far from a good solution. 
Swap mutation. Given a sequence ,q  let x  and y  be two positions in the sequence. A 
neighbor of q  is obtained by interchanging the jobs in positions x  and .y  The swap mutation is 
needed when there is already a good solution and only small changes are required to obtain a better 
solution. 
3.3. Bottleneck heuristic 
The initial swarm population is constructed by a given number of particles denoted by swarm 
size. These particles are randomly generated except one, which is obtained by the proposed 
bottleneck heuristic. Bottleneck is a phenomenon by which the performance or capacity of an entire 
system is severely limited by a single component. The bottleneck heuristic procedure is as follows 
[33]: 
Step 1: Identify the bottleneck stage 
• Calculate the flow ratio between the total processing time and the available machines at each 
stage. 
• Select the stage with maximum flow ratio. 
• Calculate the total processing time for each job at every stage before the bottleneck stage and 
denote it as .jR  
• Calculate the difference between the total flow ratio at every stage with the total processing 
time at every stage after the bottleneck stage and denote it as .jD  
 28
bottleneck stage. Then the jobs at the third stage are scheduled as soon as it is completed by the 
second stage. The final sequence is given in Table 4. 
 
Table 3.  Schedule for stage 1 
Job 1M jR jD
1M 1M
1jP [ ,s ]c
1 [3] 0 15 5 5 10
2 [1] 0 2 2 0 2
3 [2] 0 3 3 2 5
4 [4] 0 17 6 10 16
 
Table 4.  Schedule for stage 3. 
Job 1M  jR
 
jD
 1M   1M  
1jP   [ ,s  ]c
1 [3] 25 33 6  25 31
2 [1] 15 43 3  15 18
3 [2] 19 39 2  19 21
4 [4] 34 24 5  34 39
 
3.4. Local search 
In this section, we incorporate a local search into the proposed PSO algorithm to improve its 
performance. The basic idea is as follows. The jobs that sequenced from stage 1 until the bottleneck 
stage mostly have the same sequence because jobs were ranked in increasing order of ,  j jD R  and 
processing time. This may generate more machine idle time because each job at every stage has a 
different processing time but it is ranked first by .jD  Thus, we can randomly change (mutate) the 
particle position in the precedent stage for several iterations to further obtain a better particle 
position (job sequence). The best particle will be selected as the solution particle at that stage. Two 
types of neighborhoods are employed in our local search:  
• Swap mutation: Swap any two positions. 
• Shift mutation: Swap the position with the left or right neighbor. 
As an illustration, consider the bottleneck (i.e., stage 3) in Figure 1. According to the 
bottleneck heuristic, we sequence the particle position at stage 2 by ranking ,  j jD R  and 
processing times at stage 3 and obtain the sequence (7,6,5,3, 2,1, 4).  With several mutations, we 
obtain a better sequence (7,6,5,3, 2, 4,1) . The procedure is repeated until stage 1.  
3.5. Restart procedure 
This is an additional procedure to avoid premature convergence, where the SA algorithm is 
incorporated to avoid being trapped in local optima. At each iteration, we store the minimum 
makespan and increment the counter value if the minimum makespan is not changed in the next 
iteration. We apply the following restart procedure until a preset restart value is reached:  
Step 1: Sort the particles in the population in increasing order of fitness value ( maxC ). 
Step 2:  Choose the first 10% of the particles and optimize them by using SA in the following way: 
• The solution is moved around the neighborhood by insert or shift mutation  
Final Sequence: 
Stage I  – 1M  Æ  [2] [3] [1] [4] 
Stage II  – 1M  Æ  [2] [1] 
        – 2M  Æ  [3] [4] 
Stage III – 1M  Æ  [2] [3] [1] [4] 
 
 30
preset restart value is reached (section 3.5). 
Step 12:  (Fitness) Evaluate the fitness of each solution particle in the population.  
Step 13:  (Find) Find pbest and gbest from the solutions.  
Step 14: (Termination) Stop the algorithm if the stopping criterion is satisfied; return to step 7 
otherwise. 
4. Design of experiment 
There are 77 problems in Carlier and Néron’s benchmark problems [17]. The three 
characteristics that define the problem are the number of jobs, number of stages, and number of 
identical machines at each stage. For example, the notation 15 10 1j c b  means a 15-job, 10-stage 
problem. The letters j  and c  are abbreviations for job and stage, respectively. The letter b  
defines the structure of the machine layout at the stages. The last number 1 is the problem index for 
a specific type. The meanings of the letters for machine layouts are given below [20]: 
a. There is one machine at the middle stage (bottleneck) and three machines at the other stages 
b. There is one machine at the first stage (bottleneck) and three machines at the other stages 
c. There are two machines at the middle stage (bottleneck) and three machines at the other 
stages 
d. There are three machines at each stage (no bottleneck) 
The parameter setting in PSO is very important. The PSO search process is controlled by 
multiple variable factors (parameters) that have to be optimized in order to achieve good solution 
quality. The parameters were determined by full factorial experimental design, where all the 
parameters in the algorithm were tested (see Table 5). There are nine parameters needed to be 
considered with a total number of 2187 7 2( 3 1 )= ×  different combinations.  
 
Table 5.  Parameters of the PSO algorithm. 
Parameter Factor Level 
Swarm size (A) 3 levels: 5, 15, 30 
Restart generation (B) 3 levels: 5, 10, 25 
Inner SA iteration (C) 3 levels: 1, 10, 25 
Initial temperature of SA (D) 3 levels: 25, 50, 100 
Final temperature of SA (E) 1 levels: 0.01 
Alpha SA (F) 1 levels: 0.99 
Mutation rate (G) 3 levels: 0.05, 0.08, 0.1 
Crossover rate (H) 3 levels: 0.3, 0.5 , 0.8 
Inner iteration local search (I) 3 levels: 1, 5, 10 
 
The total 77 problems can be classified into 13 groups according to their characteristics. Two 
problems from each group were tested to choose the best parameter setting, based on the mean 
valued of CPU times and max ,C  among all the possible parameter values (see Table 6). 
5. Experiment results 
5.1 Preliminary experiment 
 32
Table 7.  Parameter settings in preliminary experiments 
Parameter PSO PSO-SA PSO-SA-BH 
Swarm size 5 5 5 
Restart generation 5 5 5 
Inner SA iteration - 1 1 
Initial temperature of SA - 25 25 
Final temperature of SA - 0.01 0.01 
Alpha SA - 0.9 0.9 
Mutation rate 0.1 0.1 0.1 
Crossover rate 0.8 0.8 0.8 
Inner iteration local 
search 
- - 1 
 
Table 8.  Performance of PSO with different versions 
Problem 
PSO PSO-SA PSO-SA-BH LB % deviation 
Best   
N* 
CPU Best  
N
CPU Best  
N
CPU PSO PSO- 
SA
PSO- 
SA-BH
maxC  time maxC  time maxC  time 
j10c5c1 69 0 0.1 69 0 0.1 68 1 0.098 68 1.47 1.47 0 
j10c5c3 72 0 0.1 72 0 0.1 71 1 0.1 71 1.41 1.41 0 
j10c5c6 69 1 0.084 69 3 0.062 69 3 0.07 69 0 0 0 
j10c5d2 74 0 0.1 74 0 0.1 74 0 0.1 73 1.37 1.37 1.37
j10c5d5 67 0 0.1 66 1 0.094 66 1 0.084 66 1.51 0 0 
j10c10c2 120 0 0.1 120 0 0.1 119 0 0.1 116 3.45 3.45 2.59
j10c10c5 127 0 0.1 125 0 0.1 125 0 0.1 121 4.96 3.31 3.31
j15c5c1 87 0 0.1 86 0 0.1 86 0 0.1 85 2.35 1.18 1.18
j15c5c2 93 0 0.1 92 0 0.1 92 0 0.1 90 3.33 2.22 2.22
j15c5c5 78 0 0.1 78 0 0.1 77 0 0.1 73 6.85 6.85 5.48
j15c5d3 85 0 0.1 84 0 0.1 84 0 0.1 77 10.39 9.09 9.09
j15c5d5 82 0 0.1 81 0 0.1 81 0 0.1 67 22.38 20.9 20.9
j15c5d6 84 0 0.1 83 0 0.1 83 0 0.1 79 6.33 5.06 5.06
* N = Number of times (out of 5) the LB was reached 
 
5.2 Experiment results 
In the comparison study, the run time was limited to 1600 seconds or until the LB was reached. 
If the LB was not found within the time limit, the search was stopped and the best solution was 
accepted as the solution. The performance of the algorithms was calculated by the percentage 
deviation between the solution and the lower bound as follows: 
maxbest C LB% deviation
LB
−=              (11) 
The proposed PSO algorithm was programmed in Java and run on a PC with an Intel Core 2 
 34
worthwhile to develop new ways of updating the velocity and determining the parameter setting 
optimally in a dynamic environment while the algorithm is running. 
 
Table 9. Comparison results on benchmark problems (bold represented problems  
are hard problems) 
Problem PSO QIA ACO AIS B&B  
LB 
% Deviation 
maxC  CPU maxC CPU maxC  CPU maxC CPU maxC CPU PSO QIA ACO AIS B&B
j10c5a2 88 0.001 88 - 88 - 88 1 88 13 88 0 0 0 0 0
j10c5a3 117 0.001 117 - 117 - 117 1 117 7 117 0 0 0 0 0
j10c5a4 121 0.001 121 - 121 - 121 1 121 6 121 0 0 0 0 0
j10c5a5 122 0.005 122 - 124 - 122 1 122 11 122 0 0 1.64 0 0
j10c5a6 110 0.019 110 - 110 - 110 4 110 6 110 0 0 0 0 0
j10c5b1 130 0.003 130 - 131 - 130 1 130 13 130 0 0 0.77 0 0
j10c5b2 107 0.001 107 - 107 - 107 1 107 6 107 0 0 0 0 0
j10c5b3 109 0.005 109 - 109 - 109 1 109 9 109 0 0 0 0 0
j10c5b4 122 0.003 122 - 124 - 122 2 122 6 122 0 0 1.64 0 0
j10c5b5 153 0.001 153 - 153 - 153 1 153 6 153 0 0 0 0 0
j10c5b6 115 0.001 115 - 115 - 115 1 115 11 115 0 0 0 0 0
j10c5c1 68 0.147 69 - 68 - 68 32 68 28 68 0 1.47 0 0 0
j10c5c2 74 0.535 76 - 76 - 74 4 74 19 74 0 2.7 2.7 0 0
j10c5c3 71 4.97 74 - 72 - 72 a 71 240 71 0 4.23 1.41 1.41 0
j10c5c4 66 0.236 75 - 66 - 66 3 66 1017 66 0 13.6 0 0 0
j10c5c5 78 0.05 79 - 78 - 78 14 78 42 78 0 1.28 0 0 0
j10c5c6 69 0.041 72 - 69 - 69 12 69 4865(b) 69 0 4.35 0 0 0
j10c5d1 66 0.068 69 - - - 66 5 66 6490(b) 66 0 4.55 - 0 0
j10c5d2 73 0.56 76 - - - 73 31 73 2617(b) 73 0 4.11 - 0 0
j10c5d3 64 0.058 68 - - - 64 15 64 481 64 0 6.25 - 0 0
j10c5d4 70 0.132 75 - - - 70 5 70 393 70 0 7.14 - 0 0
j10c5d5 66 0.295 71 - - - 66 1446 66 1627(b) 66 0 7.58 - 0 0
j10c5d6 62 0.07 64 - - - 62 8 62 6861(b) 62 0 3.23 - 0 0
j10c10a1 139 0.026 139 - - - 139 1 139 41 139 0 0 - 0 0
j10c10a2 158 0.374 158 - - - 158 18 158 21 158 0 0 - 0 0
j10c10a3 148 0.004 148 - - - 148 1 148 58 148 0 0 - 0 0
j10c10a4 149 0.033 149 - - - 149 2 149 21 149 0 0 - 0 0
j10c10a5 148 0.027 148 - - - 148 1 148 36 148 0 0 - 0 0
j10c10a6 146 0.097 146 - - - 146 4 146 20 146 0 0 - 0 0
 36
Table 9 (Continued) 
Problem PSO QIA ACO AIS B&B 
LB
% Deviation 
maxC  CPU maxC  CPU maxC  CPU maxC CPU maxC CPU PSO QIA ACO AIS B&B
j15c5d1 167 0 - - 167 - 167 1 167 24 167 0 - 0 0 0
j15c5d2 84 a - - 86 - 84 a 85 c 82 2.44 - 4.88 2.44 3.66
j15c5d3 82 a - - 83 - 83 a 96 c 77 6.49 - 7.79 7.79 24.68
j15c5d4 84 a - - 84 - 84 a 101 c 61 37.7 - 37.7 37.7 65.57
j15c5d5 79 a - - 80 - 80 a 97 c 67 17.91 - 19.4 19.4 44.78
j15c5d6 81 a - - 79 - 82 a 87 c 79 2.53 - 0 3.8 10.13
j15c10a1 236 0.006 236 - 236 - 236 1 236 40 236 0 0 0 0 0
j15c10a2 200 0.163 200 - 200 - 200 30 200 154 200 0 0 0 0 0
j15c10a3 198 0.135 198 - 198 - 198 4 198 45 198 0 0 0 0 0
j15c10a4 225 0.047 225 - 228 - 225 12 225 78 225 0 0 1.33 0 0
j15c10a5 182 0.098 182 - 182 - 182 2 183 c 182 0 0 0 0 0.55
j15c10a6 200 0.038 200 - 200 - 200 2 200 44 200 0 0 0 0 0
j15c10b1 222 0.005 222 - 222 - 222 3 222 70 222 0 0 0 0 0
j15c10b2 187 0.002 187 - 188 - 187 1 187 80 187 0 0 0.53 0 0
j15c10b3 222 0 222 - 224 - 222 1 222 80 222 0 0 0.9 0 0
j15c10b4 221 0.002 221 - 221 - 221 1 221 84 221 0 0 0 0 0
j15c10b5 200 0.008 200 - - - 200 1 200 84 200 0 0 - 0 0
j15c10b6 219 0.005 219 - - - 219 1 219 67 219 0 0 - 0 0
a. PSO & AIS could not reach LB in 1600 sec. 
b. B&B reaches LB more than 1600 sec. 
c. B&B could not reach LB. 
 
Table 10.  Performance summary of different algorithms 
Algorithm Easy Problem Hard Problem 
% Solved % Deviation Number of 
Problems 
%  Solved % Deviation Number of 
Problems
PSO 88.7 0.95 53 75 2.85 24 
QIA 100 0 29 0 5.04 12 
ACO 64.4 0.92 45 66.7 3.88 18 
AIS 88.7 0.99 53 66.7 3.13 24 
B&B 88.7 2.17 53 70.8 6.88 24 
References 
[1] Brah SA, Hunsucker JL. Branch and bound algorithm for the flow shop with multiple 
processors. European Journal of Operational Research 1991; 51: 88–99. 
[2] Portmann MC, Vignier A, Dardilhac D, Dezalay D. Branch and bound crossed with GA to 
solve hybrid flowshops. European Journal of Operational Research 1998; 107: 389–400. 
 38
[23] Ai J, Kachitvichyanukul V. A particle swarm optimization for the vehicle routing problem 
with simultaneous pickup and delivery. Computers & Operations Research 2009; 36: 
1693–1702. 
[24] Liao CJ, Tseng CT, Luarn P. A discrete version of particle swarm optimization for flowshop 
scheduling problems. Computer & Operations Research 2007; 34: 3099–3111. 
[25] Liu B, Wang L, Jin Y. An effective hybrid PSO-based algorithm for flow shop scheduling with 
limited buffers. Computers & Operations Research 2008; 35: 2791–2806. 
[26] Pan QK, Wang L, Qian B. A novel differential evolution algorithm for bi-criteria no-wait flow 
shop scheduling problems. Computers & Operations Research 2009; 36: 2498–2511. 
[27] Pan QK, Tasgetiren MF, Liang YC. A discrete particle swarm optimization algorithm for the 
no-wait flowshop scheduling problem. Computers and Operations Research 2008; 35: 
2807–2839. 
[28] Sha DY, Hsu CY. A new particle swarm optimization for the open shop scheduling 
problem. Computers and Operations Research 2008; 35: 3243–3261. 
[29] Kennedy J, Eberhart RC. Particle swarm optimization. In: Proceedings of IEEE International 
Conference on Neural Network. NJ:Piscataway; 1995. p. 1942–1948. 
[30] Clerc M. Particle Swarm Optimization. London: ISTE; 2006. 
[31] Engelbrecht AP. Fundamentals of Computational Swarm Intelligent. John Wiley & Sons; 
2005. 
[32] Kirkpatrick S, Gelatt Jr CD, Vecchi, MP. Optimization by simulated annealing. Science 1983; 
220: 67l–680. 
[33] Arboleda CDP, Torres JRM, M Dominguez JA, Hernandez MCH. Scheduling jobs on k-stage 
flexible flow-shop. Annals of Operations Research 2008; 164: 29–40. 
[34] Wang X, Xiao J. PSO-based model predictive control for nonlinear processes. Lecture Notes 
in Computer Science 2005; 3611: 196–203. 
[35] Triki E, Collette Y, Siarry P. A theoretical study on the behavior of simulated annealing 
leading to a new cooling schedule. European Journal of Operational Research 2005; 166: 
77–92. 
 
 
96年度專題研究計畫研究成果彙整表 
計畫主持人：廖慶榮 計畫編號：96-2221-E-011-025-MY3 
計畫名稱：新興的通用啟發法應用於排程問題 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
