  
摘要 
數碼城市為三維空間資訊最佳的應用範例，然而有效率且低成本的資料獲取及資料處理
方式始終是推廣數碼城市的最大障礙。據此，本計畫從三維製圖的精度需求與多元應用，
提出多鏡頭、傾斜攝影、低價位之高解析數位相機系統的設計。計畫中研究主軸主要分為
三大部分，分別為(1)空載傾斜攝影及資料前處理，包括相機系統之設計、相機率定、空三
帄差及直接地理定位精度檢核；(2)三維房屋模型重建技術，提出 TIN-Merging & Reshaping
重建三維房屋結構線之位相關係成為房屋模型；以及(3)自動化牆面紋理貼圖技術，除了偵
測遮蔽區域外，尚可補償遮蔽區資訊，並可降低錯誤貼圖資訊的功能。研究成果:(1)傾斜攝
影及資料前處理部分，共實現兩個航次四個小時傾斜攝影，拍攝得到四千九百多張傾斜照
片。並完成 167張影像的空三帄差測詴與精度分析，得到 14.8公分之三維定位精度。接著
利用此資料及 Applanix POSPac 軟體對兩個相機兩個航次進行直接地理定位精度分析，得
到 30-50公分之絕對精度。(2)三維房屋模塑 TIN-Merging部分可以達到 100%的成功率，而
Reshaping則視房屋之複雜度而定，學校建築可以達到 98%，傳統住居及工業廠房等則可達
到 90%之成功率。(3)自動化牆面紋理貼圖成果從視覺上研判其效果相當顯著，但仍需要改
善同一建物不同牆面間之色彩一致性問題。 
關鍵詞: 數碼城市、空載傾斜攝影、三維房屋模塑、牆面紋理貼圖 
 
ABSTRACT 
Cyber city is the best example for three-dimensional spatial information application. 
However, an effective and low-cost data acquisition and processing solution is necessary in order 
to promote the cyber city. Based on the accuracy requirement and diverse applications of 
three-dimensional mapping, this project proposes the design of a multi-lens, oblique 
photographing, low-cost and high-resolution aerial photogrammetric digital camera system. The 
research contents have three folds, (1) airborne oblique image data acquisition and pre-processing, 
including the design of imaging system, camera calibration, positioning accuracy analysis for 
aerial triangulation and direct georeferencing. (2) We develop a novel three-dimensional building 
modeling technique called “TIN-Merging & Reshaping (TMR)” algorithm for the topology 
reconstruction and roof top reshaping. (3) A fully automatic façade texture mapping technique is 
proposed which can detect occlusion area and compensate for from other images. The 
achievements of this project are in the following. (1) A total of 4 hours airborne oblique image 
acquisition which get more than 4900 pictures. A total of 167 images is used for accuracy 
analysis using traditional aerial triangulation that achieve 14.8 cm of 3D positioning accuracy 
while in direct georeferencing the accuracies are 30~50cm. (2) The topology reconstruction 
success rates for TIN-Merging are 98% for buildings in a university campus and 90% for 
complex roofs area where traditional housing, apartments and factories are located. (3) From the 
visual inspection the façade texture mapping results is significant, but the color balancing 
problem need to be improved for those facades that belong to the same building. 
Key words: Cyber city, airborne oblique images, 3D building modeling, façade texture mapping.
一、 前言 
數碼城市是一種模擬真實城市的工具，透過電腦圖形的技術以三維立體的方式建構出
虛擬的城市，讓使用者能藉由數碼城市達到宛如親歷實境的感覺。數碼城市的組成要素可
分為三維幾何模型與紋理貼圖影像兩種，三維幾何模型可用於描繪地物的幾何形狀，紋理
貼圖影像則可呈現地物真實的色彩與紋路，由於近年來數碼城市的廣泛應用，使得這兩個
要素一直是研究的重點。而本計畫則是從資料獲取面開始，從數碼城市的需求出發來設計
  
重建拓墣關係的演算法，並且用邊界表示法(Boundary Representation, B-Rep)描述模型。 
最後，由於仿真式數碼城市的應用越來越廣泛、頻繁，諸如適地性服務、城市導覽、
房地產應用、汽車導航、防救災的管理等，甚至結合地理資訊系統於網路上供使用者做查
詢應用(Takase et al., 2004)，這些都包含了大量的房屋模型與牆面紋理資訊，因此如何能快
速有效的產生牆面紋理貼圖乃是重要的研究課題。傳統上常用的隨機紋理已漸漸不符合使
用者的需求，於是利用真實的牆面紋理貼圖所建置的仿真式數碼城市成了現在最常見的一
種模擬真實城市的方法。國際上之相關研究大多將重點放在效率與品質兩方面(Varchosaz, 
2003; Kada, 2004)，故本研究除了著重於牆面紋理的生產效率外，同時也考量了牆面紋理的
影像品質與遮蔽情況，希望藉由資料的獲取以及自動化篩選來得到較理想的紋理貼圖。 
Wang et al.(2008)提出利用近景攝影測量的方法並配合選取指標以自動化的產生牆面紋
理貼圖，如此可同時兼顧到影像的品質與生產效率，但該方法之影像是由人工在地面攝影
所取得，因此地物對牆面所造成的遮蔽情況較無法避免，而在影像之收集方面，採用人工
拍攝的方式，也比較不適用於產生大範圍的牆面紋理貼圖。因此針對上述問題，本研究提
出利用空載傾斜攝影之方法，減少地物對牆面的遮蔽，並且快速獲得大範圍的影像資料，
再搭配影像品質的篩選與自動化的流程，使最後的牆面紋理貼圖能快速且保持較佳的品質
下產生。 
以下就本計畫三年之研究成果分成三個部份逐一說明，分別為(1)傾斜攝影及資料前處
理，包括相機規格之制定、相機率定、空三帄差及直接地理定位精度檢核；(2)三維房屋模
型重建技術，提出TIN-Merging & Reshaping重建三維房屋結構線之位相關係成為房屋模型；
以及(3)自動化牆面紋理貼圖技術，除了偵測遮蔽區域外，尚可補償遮蔽區資訊，並可降低
錯誤貼圖資訊的功能。 
二、 空載傾斜攝影系統及資料前處理  
2.1 相機拍攝系統之設計與實現 
本計畫原擬與財團法人國家實驗研究院儀器科技研究中心(ITRC)光電與遙測組合作，
進行航測相機之設計製作與應用軟體之開發。但因為儀科中心所提出對應之計畫申請案沒
有通過，因此無法依照原計畫從相機與鏡頭之組裝、控制與儲存系統等完全自製拍攝系統。
因此乃配合內政部計畫之經費，採用兩台 Nikon D2X(s)專業單眼數位相機(DSLR)，並撰寫
一軟體以便控制相機拍照時機與並傳送拍照之訊號給 POS AV510，以便後續可以內插每一
個拍照瞬間的GPS及 IMU資訊。圖 1為所設計之雙鏡頭傾斜攝影系統架構及相機雛形，IMU
架設在兩相機之上方，彼此間固定在特製之鋁架上，並崁在中興測量空載光達掃描儀的基
座內，相機與 Z軸之偏角約 30度。本系統以德安航空直升機為載台，相關控制、定位與儲
存系統如圖 2所示，包括四組電池與兩台配備防震型硬碟的筆記型電腦。 
實際航拍測詴時以台北市政府週遭信義計畫區約 900 公頃的範圍做為航拍實驗測區。
拍攝時採用焦距 28mm，航高約 650公尺，也就是像比例尺約 1:23000，Nikon D2X(s)之像
元大小為 5.5μm，加上傾斜攝影傾角 30 度，因此地面取樣間距(GSD)約在 13~18 公分。此
外，為了使連續兩影像之重疊百分比達到 80%以上，同時讓數位相機有足夠的時間傳輸資
料到筆記型電腦，因此在航速 50KM/hr 下，採用間隔每 6 秒鐘自動拍攝一張影像的方式拍
攝。實驗中為了讓直升機補充油料，因此採用兩階段飛行，上下午各拍兩小時，分別以東
西向及南北向飛行，總飛行時數約四個小時，共拍攝四千九百多張影像。圖 3 為其中一範
例，拍攝地點為台北市政府及市議會。圖 4則為圖 18之局部放大成果，此案例並不表示所
有影像之影像品質都如此好，由於天候隨著時間改變，加上兩個航次拍攝時所使用的曝光
時間不同，而直升機抖動的情況相當嚴重，因此有些照片會出現模糊現象而降低影像品質。
因此在進行空三帄差時，必須篩選較佳品質的影像，以減少認點誤差。 
 
  
 
圖 4、傾斜攝影範例放大圖 
 
2.2 相機透鏡變形率定 
由於本計畫所設計規劃的相機為消費型數位相機，與傳統類比式量測型相機的主要差
異在於沒有框標可以決定影像座標。由於 CCD是使用高精密的次微米半導體科技所製作，
因此其像帄面影像座標的定義及帄坦性較底片穩定一致。因此必須先暸解該相機之鏡頭透
鏡畸變(Lens Distortion)、焦距與像主點(Principle Point)等內方位相關參數，以便後續三維製
圖相關應用時可自動修正其系統性誤差。相機率定所使用的方法一般都採用自率光束法帄
差(Self-Calibration Bundle Adjustment)，將透鏡畸變、焦距及像主點座標等參數當作附加參
數來求解(Fraser, 1997; Habib & Morgan, 2003; Delara et al., 2004; Cardenal et al., 2004)。本研
究採用 Photometrix 之 iWitness，以附加參數自率光束法帄差自動求解得相機之透鏡畸變參
數。iWitness 所採用之透鏡畸變數學模式如公式(1)所示，共使用了 7個附加參數。 
 
xyPyrPyrKrKrKyy
ybxbxyPxrPxrKrKrKxx
1
22
2
4
3
2
2
2
1
212
22
1
4
3
2
2
2
1
2)2()(
2)2()(


………(1) 
其中 
影像座標像主點  :),( ,:),(
),(),( 22
yxyx
yxryyyxxx
pp
pp   
K1,K2,K3:輻射方向透鏡畸變係數，P1,P2:偏心透鏡畸變係數，b1,b2:像帄面變形係數。 
 
本研究選擇了 AF-S DX Zoom-Nikkor 17-55mm f/2.8G之變焦鏡頭，拍攝中將之固定在
28mm，估計其 FOV僅約 31 度。由於此相機與鏡頭為業餘相機，並非定位為空載航測專用
鏡頭。為了評估三維定位精度，有必要進行相機率定，以了解其變形量。研究中採用了
Potometrix iWitnessPro 軟體，此軟體提供了 48個特殊設計的人造標(Cronk, et al. , 2006)(如
圖 5所示)，可進行自動化判識以完成共軛點影像點之量測。由於此人造標上共有 8個紅色
圓形標，因此可提供大量共軛影像點觀測量，不需要地面控制點即可完成相機率定工作。
若考慮尺度問題，亦可按照人造標上特定的兩組紅色標之間的實際距離當觀測量，再進行
整體帄差以獲得相機率定後之絕對三維定位精度。 
  
2.3 空中三角帄差測詴 
影響空三帄差精度的因素主要有地面控制點之精度、數量與分布，其對應之影像座標
量測精度，連結點量測精度、相機透機畸變參數之精度等。而本研究為了探討在 30度之傾
斜攝影下進行三維定位之精度，因此在連結點量測上完全採用人工量測，不採用自動化匹
配，以避免初始值不正確或傾斜攝影所造成之變形，導致影像匹配錯誤的問題。相機率定
則採用實驗室內事先率定的方法，以避免空三帄差過程中產生參數間高相關的問題。實驗
中選取不同航向與不同相機共 167 幅影像進行空三帄差測詴。地面控制點來自地面測量，
其精度約為 5公分。 
空三帄差同樣採用 iWitness 進行，由於 iWitness 之使用者介面相當友善，更可透過核
線與反投影預估等方式協助量測共軛點。圖 9為 iWitness 量測連結點之範例。由於 iWitness
屬於近景攝影測量系統，並非數值航空測量系統，並未設計立體量測介面，且沒有獨立檢
核點之機制，所以其定位精度來自地面控制點之殘差的標準偏差。圖 10為所有連結點中任
意選取四個點與相關的影像所構成的交會光束。由表2三軸之三維定位精度得知，帄面(X-Y)
之定位精度仍比高程(Z)之定位精度高，三維整體定位精度則可達 14.8公分，相對於本次拍
攝之影像地面解析度約 15 公分而言約一個像元，顯示本攝影系統具有相當高的三維定位精
度。對於本計畫未來在三維房屋模塑與牆面紋理貼圖之應用，預期將可滿足所需的精度要
求。 
表 2、空中三角帄差相關統計量 
相機數 2 影像數目 167 
控制點數 30 Sigma0 (pixels) 0.94 
連結點數 142 整體精度 (cm) 8.27 
最小交會角 (度) 19 相對精度 1:20,800 
RMSE X,Y, Z & 三維 (cm) 6.15, 7.42, 11.24, 14.8 
2.4 直接地理定位 
由於 GPS/IMU 與相機透視中心有一位置偏移量，且相機之拍攝方向也無法與 IMU 之
三軸完全相同，因此為了達到直接地理定位(Direct Georeferencing)的目地，必須先進行固定
臂(Lever-arm)與軸角(Boresight)之率定(Mostafa et al., 2001)。由於本研究使用 Applanix POS 
AV510 定位定向裝置，因此利用 Applanix POSPac 軟體進行此項研究工作。但必備資料為
一組已經經過傳統空三帄差的資料，有大量的連結點及少許地面控制點，利用此空三成果
可以跟 GPS/IMU資料做比對及帄差求解固定臂向量與軸角差異之旋轉矩陣，進而推算其他
沒有用在空三帄差的影像上。由於 POSPac 僅能一次率定一台相機，且本研究分成上下午
各拍一次，因此本研究分成四組資料分開進行直接地理定位，表 3 為直接地理定位精度分
析之統計。整體而言其三維定位精度可達 30~50 公分。 
表 3、直接地理定位精度分析統計 
D2XS- N-S 
(AM) 
Boresight Angle o,p,k (Degree) -0.49,   -26.97,   -0.46 
26 CKP RMS (m) X-Y-Z 0.33,  0.57,  0.32  
4   GCP RMS (m) X-Y-Z 0.10,  0.04,  0.01 
No. of Images 48 
D2X-N-S 
(AM) 
Boresight Angle o,p,k (Degree) 0.58,   29.27,   -0.34 
26 CKP RMS (m) X-Y-Z 0.70,  0.61,  0.68 
4   GCP RMS (m) X-Y-Z 0.06,  0.02,  0.00 
No. of Images 40 
D2XS-E-W 
(PM) 
Boresight Angle o,p,k (Degree) -0.53,   -26.61,   -0.43 
26 CKP RMS (m) X-Y-Z 1.46,  1.12,  2.55 
4   GCP RMS (m) X-Y-Z 0.68,  0.95,  0.65 
No. of Images 40 
D2X-E-W 
(PM) 
Boresight Angle o,p,k (Degree) 0.49,   29.39,   -0.07 
26 CKP RMS (m) X-Y-Z 2.92,   1.68,   5.00 
4   GCP RMS (m) X-Y-Z 0.01,   0.03,   0.00 
No. of Images 39 
  
 
圖 12、不完整的結構線與經過前處理後的結構線 
3.2 約制迪式三角形(Constrained Delaunay Triangulation, CDT) 
迪式三角形(1934)是著名的將二維不規則散佈的點建構三角網的技術，其中，沒有第四
個點存在三角網格所形成的外接圓之中。使用這樣的技術，這些不相關的點與鄰近點的關
係因此被建立，這表示迪式三角形可以應用在不相關點雲之間拓墣關係的重建上。本文中，
建物重建的基本元素必須是個封閉的形式的結構線，且產生的 TINs不能與結構線相交，因
此 CDT 採用結構線的端點在二維投影面上建構三角形，且利用結構線本身作為約制以避免
建構的三角形跨越結構線。圖 13為利用結構線做為約制的不規則三角網，必須注意的是，
若存在懸點，則會產生一些不合理的三角形，例如圖 14。因此，懸點移除在建構合理的屋
頂結構中為重要的步驟，這也是資料預處理的目的之一。 
 
  
圖 13、結構線約制的不規則三角網 
  
圖 14、預處理之前建構約制的不規則三角
網 
圖 15、完成 TIN 合併的成果 
3.3 TIN合併(TIN-Merging) 
在建立 TIN 結構之後，結構線之間的相鄰關係因此被建立。這些 TINs 是用多邊形的
結構來描述，然而為了減少資料儲存的空間並且利用多面體形式描述屋頂模型，還需更進
一步的處理程序。產生的 TINs的邊有些是不存在或是不必要的，因此應該被移除，唯一的
  
附近。經統計在進行前處理前共有 1542個懸端，經前處理之後變成零，顯示本研究提出的
移除懸端方法成效相當顯著有效。之後在進行 TIN-Merging 重建線段間之拓樸關係時，除
了有部分建物的結構線未能封閉成一個多邊形的情形外，成功率可達到 100%。最後共建構
出 1573 個多邊形。而在 Reshaping部分，其成功率則視屋頂之複雜度而定。在此將測詴區
分成兩個部分，如圖 20 所示，Part-I 為輔仁大學校區，其建物較大，外型不一，但屋型較
簡單。Part-II為校區外，包括了廠房、公寓及混雜的民房，其屋頂形式較複雜，高低不一。
經過 Reshaping 測詴後，統計 Part-I 之成功率可達 98%，但 Part-II 則僅約 90%。總體帄均
成功率為 92%，主要失敗之區域大多在被高高低低不一的房屋所包圍的山形屋。圖 21為測
詴區所有建物之三維房屋模型。 
 
  
圖 17(a)、測詴例 1 圖 17(b)、測詴例 1 
  
圖 18(a)、測詴例 2 圖 18(b)、測詴例 2 
  
圖 19(a)、測詴例 3 圖 19(b)、測詴例 3 
  
是否已產生過貼圖，若為第一次產生，則將該貼圖視為主牆面紋理貼圖，反之，則所產生
之貼圖的用途為遮蔽區填補，可視為補償紋理貼圖。 
本研究利用遮蔽偵測來判斷該牆面在影像中是否受到所屬建物本身或其他建物之遮蔽，
倘若有遮蔽之情形存在，則利用遮蔽區標記對遮蔽之區域進行紋理資訊的移除，同時賦予
黑色做為標記，以便於後續演算法之使用。補償紋理貼圖的功能為還原主牆面紋理貼圖遮
蔽區域的紋理資訊，在填補之前同樣得經過遮蔽偵測與遮蔽區標記等步驟，之後才對主牆
面紋理貼圖進行紋理補償之動作。經過紋理補償後，可還原或部份還原遮蔽區的牆面紋理
資訊，倘若仍有遮蔽區域，則換下一張補償紋理貼圖進行填補，直到主牆面紋理貼圖無遮
蔽區之存在或者所有影像皆已用於紋理貼圖之產生。 
 
4.1 可視性分析 
可視性分析的概念是判斷
某牆面或屋頂面是否完整包含
或部分包含在相片範圍內，藉
此排除完全落在相片範圍外的
牆面或屋頂面。此外，由於適
合用於產生紋理貼圖的牆面或
者可能會造成遮蔽的牆面或屋
頂面皆會面向攝影鏡頭（在影
像中能看見），因此我們對相片
範圍內的牆面或屋頂面做進一
步的判斷，看其是否面向攝影
鏡頭，以避免多餘的計算量與
產生無意義的牆面貼圖。因為
水帄屋頂面帄行於地表面，較
無背向攝影鏡頭的問題，故不
加入此判斷，但因斜頂屋面並
未帄行於地表面，因此仍必須
進行此項判斷。可視性分析主
要可分成兩個步驟： 
4.1.1步驟一 
判斷牆面或屋頂面是否在
範圍內，利用共線條件式將牆
面角點或屋頂面角點的三維物
空間坐標反投影至相片坐標上，
同時判斷角點是否落在相片範
圍內。待所有角點皆做過判斷
後，再依據判斷的結果區分為
完全包含在相片範圍內、部分
包含在相片範圍內以及完全在
相片範圍外的牆面及屋頂面。 
4.1.2步驟二 
針對完全或部分落在相片
範圍中的牆面或屋頂面，判斷
其在影像中是否面向攝影鏡頭，
以確保牆面或屋頂面在影像中
 
圖 22、自動化牆面紋理貼圖流程圖 
  
 
 
圖 25、Point-in-Polygon 示意圖 圖 26、距離判斷示意圖 
 
4.2.2 Line-Intersection 
Line-Intersection（如圖 27所示）的主要概念是判斷線段與線段之間的交會關係，可區
分為線段與線段之間有交點以及無交點兩種情形。首先在相片帄面上，判斷目標牆面的邊
界與其他牆面或屋頂面區塊的邊界是否相交。假若有線段相交的情況發生，則表示目標牆
面有可能受到其他區塊的遮蔽，需利用距離判斷做進一步的確認。圖 28為距離判斷的示意
圖，其中 O 為相機透視中心；a 為相片帄面上目標牆面的邊界與其他牆面或屋頂面的邊界
相交所得的交點（即 Line-Intersection條件成立的情況）。假如距離 D大於距離 D’，則表示
目標牆面受到其他牆面或屋頂區塊遮蔽，反之則表示不受到遮蔽。 
 
 
 
圖 27、Line-Intersection 示意圖 圖 28、距離判斷示意圖 
 
4.3遮蔽區標記 
遮蔽區標記的目的是為了移除不屬於目標牆面的紋理資訊，透過標記遮蔽區域的方式，
使程式能夠自動化的辨識紋理貼圖中需做紋理補償的區域，以及判斷補償後是否仍有遮蔽
區域。經過遮蔽偵測的步驟，我們可以知道目標牆面是否受到其他牆面或屋頂面區塊的遮
蔽，倘若有遮蔽的情形存在，則利用 Point-in-Polygon 的方式移除受到遮蔽的區域。其作法
是針對目標牆面紋理貼圖座標系的每一個像元，逐一檢視其在相片座標系上是否落在其他
牆面或屋頂面中。如果 Point-in-Polygon 的情況成立，則表示該像元被遮蔽，應予以移除並
以灰度值 0 標記該像元。相反地，若 Point-in-Polygon 的情況不成立，則表示該像元並未受
到遮蔽，可直接保留其色彩資訊。 
 
4.4 紋理補償 
經過遮蔽偵測與遮蔽區標記後，僅能得到無遮蔽區的紋理貼圖，無法得到牆面完整的
紋理資訊，將有礙於視覺上的呈現。為了避免上述的問題發生，有必要藉由其他角度所拍
攝的影像對遮蔽區進行紋理補償，同時考量了房屋幾何模型、影像內外方位參數和透鏡畸
變參數的誤差，以及影像填補後色調不連續等問題。本研究將紋理補償分成三個步驟進行
處理，分別為錯誤紋理移除，影像增揚以及無縫鑲嵌，以期得到最完整且影像品質最高的
  
蔽之情形。圖 31為全區成果的示意圖，其底圖及屋頂紋理來自真實正射影像(李訢卉,2007)。
驗證本研究所提出之自動化的流程確實能有效的產生正確且完整的牆面紋理貼圖。而搭配
傾斜攝影系統所獲得的影像，利用其能記載較詳細且清晰的牆面紋理資訊的特性，也能確
實提升牆面紋理在視覺方面的效果。 
 
 
圖 32、全區牆面紋理成果 
五、 結論 
本計畫所設計之攝影系統主要目的為研究空載傾斜攝影之三維幾何定位精度，並探討
相關應用之潛力。由空三定位之初步成果顯示，目前之定位精度將可以滿足三維房屋模塑
與自動化牆面紋理貼圖的需求。然而本系統在軟硬體之設計上仍相當原始，仍有許多部分
需要改善，例如:導航系統部分，目前是採用 PDA 配合 GPS，將直升機位置顯示在小小的
螢幕上，雖然有規劃航線，但由於螢幕太小且沒有偏離航道之警告，因此當飛行員得知偏
離航道時已經離開預定航線太遠。照相機部分(1)目前是採用機械式快門的 DSLR 數位相機，
不利於抖動相當嚴重之直升機載台，加上拍攝照片之數量相當大，因此會嚴重影響相機的
壽命。(2)Nikon D2X(s)在拍攝全解析力影像時，為了傳輸及儲存影像資料，並且需要在穩
定的時間間隔下拍照，經測詴後得知兩張影像之拍攝時間間隔最好大於 5 秒鐘。此將限制
載台的飛行速度，也進而增加了拍攝成本。(3)本計畫之實驗區為台北市信義計畫區，受到
飛航管制無法以更高的高度飛行，但因而提升了影像空間解析度。為了涵蓋更大的地面範
圍，以減少飛航時數，更高的影像解析度是有必要的。 
在房屋模型重建部分，本研究提出 TIN-Merging & Reshaping演算法在結構線合理的校
正之後可以很成功地重建結構線的拓樸關係，進而在重塑三維屋頂面結構，對於類似學校
之建築物可以達到 98%之成功率，但對於較混亂的建物，則可能僅能達到 90%的成功率。
但本研究所開發之演算法配合友善人工介面，仍然是個可靠有效的建物模塑方法。此演算
法可進一步應用在航空攝影測量之立體製圖作業上，當建物屋頂之結構線的量測完成後，
TMR 演算法可以立即地推估屋頂的封閉多邊形與判斷屋頂形式，如此，可以有效的減少操
作人員繪製封閉多邊形與模塑的時間。 
  
Machine Intelligence, vol. 8, no. 6, pp. 679-698. 
Cardenal J., Mata E., Castro P., Delgado J., Hernandez M. A., Perez J.L., Ramos M., Torres 
M.,,2004,“Evaluation of a Digital Non Metric Camera (Canon D30) for the 
Photogrammetric Recording of Historical Buildings”, XXth ISPRS Congress, Istanbul, 
Turkey, pp.564-569. 
Cronk, S., C. S. Fraser, H. Hanley, 2006, “Automated Metric Calibration of Colour Digital 
Cameras”, The Photogrammetric Record, Vo. 21, No. 116, pp: 355–372. 
Delara Jr., R., E. Mitishita, A. Habib, 2004, ” Bundle Adjustment of Images from Non-Metric 
CCD Camera Using LIDAR Data as Control Points”, XXth ISPRS Congress, Istanbul, 
Turkey, TS WG III/1: Sensor Pose Estimation, pp.13, (12-23 July 2004). 
Delaunay, B., 1934. "Sur la sphère vide, Izvestia Akademii Nauk SSSRSur la sphère vide, 
Izvestia Akademii Nauk SSSR." Otdelenie Matematicheskikh i Estestvennykh Nauk, 7, 
793-800. 
Förstner, W. and Gülch, E., 1987. A fast operator for detection and precise location of distinct 
points, corners and centers of circular features. In Proc. ISPRS Intercommission 
Conference on Fast Processing of Photogrammetric Data, Interlaken, Switzerland, 281–305. 
Fraser, C. S., 1997, “Digital Camera Self-calibration”, ISPRS Journal of Photogrammetry & 
Remote Sensing, Vol. 52, pp.149-159. 
Grün, A. and Wang, X., 1998. CC-Modeler: a topology generator for 3-D city models1, ISPRS 
Journal of Photogrammetry and Remote Sensing 53(5): 286-295. 
Gülch, E., Müller, H., Labe, T. and Ragia, L., 1998. On the performance of semi-automatic 
building extraction, International Archives of Photogrammetry and Remote Sensing 32: 
331-338. 
Gonzalez, R.C., and Woods, R.E., 2002. Digital Image Processing, Prentice-Hall, New Jersy, pp. 
94-102. 
Habib, A., and M. Morgan, 2003, Automatic Calibration of Low-Cost Digital Cameras, Journal 
of Optical Engineering, 42(4):948-955, April 2003. 
Hough, P., 1962. Methods and means to recognize complex patterns, US patent 3: 654. 
Kada, M., 2004. Hardware-based Texture Extraction for Building Facades, IAPRS, Vol.35, 
Part.B4, Istanbul, Turkey, pp. 420-425. 
Kallmann, M., Bieri, H. and Thalmann, D., 2003. Fully dynamic constrained Delaunay 
triangulations, Geometric Modelling for Scientific Visualization, G. Brunnett, B. Hamann, 
H. Mueller, L. Linsen (Eds.), ISBN 3-540-40116-4, Springer-Verlag, Heidelberg, Germany, 
241-257. 
Leica ADS40, 2006, Available:  
http://www.leica-geosystems.com/corporate/de/ndef/lgs_57627.htm 
Mostafa, MMR, Hutton, Joseph, and Lithopoulos, Erik, 2001. “Airborne direct georeferencing 
of frame imagery: An error budget”, Proceedings of the 3rd International Symposium on 
Mobile Mapping Technology, Cairo, Egypt. 
Optech Applianix DSS322, 2006, Available: http://www.optech.ca/pdf/ALTMApplanixPC.pdf 
  
國科會補助專題研究計畫項下出席國際學術會議
心得報告 
 
                                                             
計畫編號 96-2628-E-006-257-MY3 
計畫名稱 多鏡頭低價位航測數位相機之設計、率定及三維製圖應用 
出國人員姓名 
服務機關及職稱 
饒見有 
國立成功大學測量及空間資訊系 助理教授 
會議時間地點 2009 年 10 月 18 日~23 日於中國北京 
會議名稱 第 30 屆 ACRS 國際研討會 
發表論文題目 
 
1. Chu, C.Y., Rau, J.Y., Chen, L.C., Chen, C.T. & Chen, J.X., 
2009, Automatic Façade Texture Generation from 
Helicopter Dual-Camera Oblique Imagery, Proceedings of 
Asian Conference on Remote Sensing, Oct. 18-23, Beijing, 
China, CD-ROM. (附件一) 
2. Rau, J.Y., Chen, L.C., Hsieh, C.C., Wen, J.Y. & Huang, 
T.M., 2009, Positioning Error Analysis of a Land-based 
Dual-camera Mobile Mapping System Using POS AV 510, 
Proceedings of Asian Conference on Remote Sensing, Oct. 
18-23, Beijing, China, CD-ROM. 
3. Hsiao, K.H., Liu, J.K., Lau,  C.C., & Rau, J.Y., 2009, 
Automation of Landslide Detection using Optical Images 
and LiDAR Data, Proceedings of Asian Conference on 
Remote Sensing, Oct. 18-23, Beijing, China, CD-ROM. 
4. Chen, L.C., Teo,  T.A. , Tsai, F., Rau,  J.Y., Chen,  C.T. 
Chen, Chen,  J.X., 2009, Building Modeling from 
Multi-source Geodata, Proceedings of Asian Conference on 
Remote Sensing, Oct. 18-23, Beijing, China, CD-ROM. 
 
  
屆，因此開幕式場面相當盛大，Prof. Murai 還特別說明此研討會之起源及歷屆
舉辦之地點及特色，同時將 General Secretary 交棒給年輕的一代 Prof. Kohei 
Cho 及 Prof. Xingfa Gu，希望此研討會能繼續傳承下去。此外，會議中亦頒獎
給六位此研討會的發起人，包括中央大學太遙中心陳哲俊教授，以及歷屆舉辦
過此研討會的負責人。本研討會亦邀請了 ISPRS 主席 Orhan Altan 共同與會，
使本研討會逐漸成為國際航遙測領域相關研討會之一。 
本屆研討會與過往有一點有較大的差異，就是將 Student Session 獨立出
來，並選在開幕式前舉辦，以便在開幕式同時頒發學生論文獎，總共有四個
Session 共十六人參加，最後有三人獲獎，包括中央大學土木系張環同學。但
比較奇怪的安排是 Poster Session，竟是安排在 Tea Break 的時段，因此效果相
當差。此外，有很多 Technical Session 中所發表的論文其主題與性質之差異很
大，使得參加 TS 與發問的人變很少，大多只剩主持人在發問。出國人此次共
發表四篇論文，其中一篇為口頭發表，安排在星期三下午最後一場。此外為了
鼓勵學生參與國際會議增長國際視野，亦要求學生以口頭方式發表論文一篇，
由於學生行前的準備工作充分，因此其表現算是可圈可點。 
會議結束後根據大會統計與會人數來自 27 個國家共 708 人，外國人 597
人。我國是以「中華民國航空測量及遙感探測學會」為代表，參與單位共有中
央大學、成功大學、政治大學、台灣大學、逢甲大學等單位共 85 人，除了會
議主辦國 111 人之外，位居其他各國參與人數第一名，再度超越日本。圖 1
為我國與會人員在開幕式後之合照，圖 2 則為成功大學與會人員在離境前之合
照。 
  
世界各國航遙測領域專家學者相互交流，在學術與國際視野等方面獲益良多，
對吾人未來之研究視野有極大幫助。 
此行為個人第一次到中國，對中國人做事的態度有許多感想，場面都很大
(尤其是開幕式及 Cultural Night)，但仔細觀察整個研討會的過程可以發現，許
多細節都是敷衍過去，包括研討會網站及議程的安排，而廠商參展也多以中國
的廠商為主，欠缺國際大廠的支持。雖然如此，個人對中國人的文化層面則必
須給予正面的讚許，雖然許多古蹟文物與建築因受戰爭及文化大革命的破壞，
但近年來中國投入許多人力與經費進行重建與維護，其成效相當顯著。感嘆如
果沒有文革與戰爭，將還會有更多價值連城的文物可以供後人觀賞與學習，更
可引進大量的觀光收入。此外，即使是計程車司機其文化素養亦相當高，例如
幾乎每位司機都在聽”平書”，主要是以歷史故事為主，經過這樣的聽故事，無
形間每個人對中國歷史與文化都可以受到潛移默化，提升其精神層面。 
  
distortion, and (iii) selecting out the image which has the best quality from 
the remaining images. Some case studies will be demonstrated in the final 
paper including the comparisons with manual texture generation through 
close-range photograph. 
 
 
 1. INTORDUCTION 
Recently, photo-realistic city model is getting more popular and its 
applications are also becoming diversified, such as car navigation, real 
estate, city tourism, disaster management, etc. Furthermore, it can link with 
GIS and provide varied inquiry service via network (Takase et al., 2004). 
The above mentioned application needs lots of buildings model and façade 
information. Therefore, how to create buildings model and façade texture 
with high efficiency and quality plays an important role. 
Many relative researches are emphasized on efficiency and quality 
(Varshosaz, 2003; Kada, 2004). Thus, in this paper, we are also focus on 
the efficiency and the quality for façade texture generation and avoiding the 
occlusion problem caused by the ground object. Through the way we 
acquire the images and some filtering criteria, we hope to get the most 
suitable image for façade texture generation automatically. 
Wang et al. (2008) uses close-range photogrammetry to obtain the 
images and uses some indexes for automatically generating façade texture. 
It can maintain both efficiency and quality. However, the images acquired 
manually may have much more occlusion problems and cost lots of time 
and money, so, in this paper, we 
propose a dual-camera oblique 
imaging system (Rau et al., 2008) to 
obtain airborne oblique image for 
solving such problem. The detail 
description about the system will be 
introduced in the next section, 
following with some case studies and 
comparisons with close-range 
approach. 
 2. METHODOLOGY 
In this section, the proposed 
scheme for automatic façade texture 
  
 
Figure 3. Sample imagery acquired by the proposed system. 
2.2 Visibility Analysis 
 An image that doesn’t “look” at the target façade cannot be used for 
façade texture generation. Thus, in visibility analysis, there are two filtering 
steps. The first step is to check if the wall is completely within the range of 
image frame. Equation (1) is the photogrammetric collinearity equation 
used to back-project the wall center coordinates onto the image plane. If 
the corresponding image coordinates are within the range of image frame, 
we further back-project the vertexes of the facade and check if they are 
complete within. In Equation (1), (Δx, Δy) is the lens distortion correction 
parameters and (xp, yp, c) and (Xo, Yo, Zo, r11~r33 calculated from ω, φ, κ) 
are the interior and exterior orientation parameters of the camera. For each 
ground point (XA, YA, ZA), we can calculate the corresponding image 
coordinates (xa, ya).The second step is to check if the normal direction of 
the wall is facing at the camera or not. Figure 4 depicts the idea of filtering 
out the images that cannot see the façade in the second step. In which, (N) 
is the normal vector of the wall calculated from the vertexes of the wall and 
(V) is the viewing vector calculated from the perspective center to the 
façade’s center coordinates. Incident angle (Φ) is calculated from normal 
vector of the wall (N) and viewing vector (V). If the incident angle (Φ) is 
  
and more than 2900 buildings with 13206 facades of 3D polyhedral building 
models. The total of process time in façade texture generation for all 
façades is about 3 hours. Figure 5 compares the façade texture generated 
from the close-range approach and the proposed algorithm. In which, 
façades (A1~A4) are generated from the close-range one and facades 
(B1~B4) are created by this research. We can found out that the façade 
generated from our algorithm has less occlusion problem caused by ground 
objects, but there still exist some occlusion effect caused by neighboring 
buildings and the image resolution is not good but acceptable for certain 
applications. Figure 6 demonstrates two photo-realistic texture mapping 
results of the whole study area using the developed algorithm. The overall 
quality is good enough for photo-realistic city modeling. 
 
Figure 5. close-range photogrammetry vs. our designed system. 
 
Figure 6. result of automatic façade texture generation. 
 4. CONCLUSIONS 
In conclusion, experimental results present that the proposed algorithm 
can automatically generate façade texture with high efficiency and best 
image quality. From the visual inspection, the overall quality is good enough 
  
on 3D Building Model Using Photogrammetric Images, Journal of 
Photogrammetry and Remote Sensing, Vol. 13, No.2, pp. 75-84. 
 
 
96年度專題研究計畫研究成果彙整表 
計畫主持人：饒見有 計畫編號：96-2628-E-006-257-MY3 
計畫名稱：多鏡頭低價位航測數位相機之設計、率定及三維製圖應用 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 0 100% 
人次 
 
期刊論文 0 2 100% 
一篇已投稿審查
中，另一篇撰稿
中。 
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
