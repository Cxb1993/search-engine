1 
 
行政院國家科學委員會專題研究計畫成果報告 
強健式模式比對與嵌入式快速立體視覺系統 
 
計畫編號：NSC 99-2218-E-241-002 
 
執行期限：99 年 8 月 1 日至 100 年 7 月 31 日 
計畫主持人： 魏守德 助理教授   弘光科技大學資訊工程系 
 
一、 中文摘要 
 
樣型比對與立體對應都是電腦視
覺與影像處理中非常基礎且重要的方
法，基礎方法的改良，會對整個領域有
著深遠的影響。其中樣型比對常用於物
件追蹤、物件偵測、樣型識別與視訊壓
縮等等不同的應用。而立體對應可以應
用在許多方面，像是機器人視覺、省電
型家電、互動性電玩等等。在本研究
中，擬先從發展出更強健的樣型比對方
法開始，進一步應用到立體對應上以能
發展出一個即時且精確的立體對應演
算法，最後則是針對此立體對應演算法
做簡化改良以利硬體化的實現。本計劃
的最終目的是做出一個快速低價的硬
體化版本，以使立體視覺能早日應用在
生活上與工業上。其中強健式的 NCC 
是利用迭代式的分割策略找出遮蔽的
區域，再求出其各分割區塊的權重值，
以進行運算。而即時的立體對應方法則
是將此問題轉變成多樣版影像與多候
選區域的問題，藉由相鄰的樣版影像與
候選區域之間的重複運算，以更新一個
部份相關係數表來達到即時的要求。此
兩個方法可以進一步結合，以求得更精
確的深度圖。最後對此演算法針對運算
瓶頸與資源消耗做改良，以進行最後的
硬體化實現。 
 
 
 
關鍵詞：樣型比對，正規化相關匹配
法，立體重建，嵌入式系統。 
 
 
Abstract 
Pattern matching and stereo matching are the 
fundamental problems in computer vision. 
Improving the fundamental method will has 
large impact for the whole area. Pattern 
matching is widely used in many applications 
related to computer vision and image 
processing, such as object tracking, object 
detection, pattern recognition and video 
compression. The stereo matching also has a 
wide range of potential application areas, 
including robotic, intelligent energy-saving 
appliance, interactive games. This project 
starts from developing a more robust pattern 
matching algorithm base on NCC for solving 
the occlusion problem, and then a real-time 
and accurate stereo matching algorithm will 
be proposed. Finally, a simplified version of 
real-time stereo matching will be proposed 
for hardwired implementation. The final 
purpose of this project is to complete a low 
price, real-time hardwired version of stereo 
matching for practical application. The 
possible way to achieve robust NCC is using 
iterative partition scheme to find the region 
of occlusion, and then estimating the weight 
of partitioned sub-block for calculation of 
NCC. The real-time stereo matching 
algorithm may be accomplished by skipping 
redundancy of calculation between adjacent 
templates, and updating the partial cross 
correlation table for real-time request. 
Further joining there two method can get 
more accurate depth map. For hardwired 
 3 
 
化。相反的，區塊太大則不同的深度的點
將會被包含在同一個比對區塊中，如此將
導 致 太過 平滑 的結果 。 Kanade and 
Okutomi[23] 提出了一個可調區塊大小的
方法來減輕這問題。這個方法的優勢是快
速但是結果不夠精準。另一方面，全域法
定義了一個包含了影像資料與平滑兩個
項目的能量函數，再套用一個 global cost 
minimization 的方法。能量函數最小化是
一個 NP hard 問題，所以目前都用一些逼
近方法，像是於 graph cut [24] 或是 belief 
propagation [25]等。雖然全域法一般來說
能產生比較精確的結果，但是目前還無法
達到即時運算。 
最近不少人開始想利用 GPU 實現即
時的立體對應[21][22]。Wang et al.[21] 使
用 改 良 式 的 動 態 規 劃 法 (dynamic 
programming method)。[22]則是基於 belief 
propagation。在他們修改的 BP 中，只需
要少量的迭代。另外還有一些整合型立體
對應演算法 [8][9]，結合了多個方法以大
幅增加精確度。這類的方法的計算量非常
的高。 
立體重建有兩個常遇見的問題，一是
遮蔽，二是平坦區域，這兩個問題都會造
成比對時 disparity 不正確。在本計劃中，
擬先從發展出更強健的樣型比對方法開
始，進一步應用到立體對應上以能發展出
一個快速且精確的立體對應演算法，最後
則是對此立體對應演算法做簡化改良以
利硬體化的實現。 
樣型比對與立體對應都是電腦視覺
與影像處理中非常基礎且重要的方法，基
礎方法的改良，會對整個領域有著深遠的
影響。立體對應可以應用在許多方面，像
是機器人視覺、智慧型節能家電、互動性
電玩等等。機器人可以利用深度圖來追蹤
辨識物體，也可讓機器人能判斷物體的遠
近。智慧型節能電視透過深度圖建立的背
景之後，可以用來判斷是否已沒人在電視
前，進而自動判斷是否關機以節省電源。
深度背景同樣也可以應用在冷氣機上，利
用深度背景與深度前景可以得知人的位
置，以決定冷氣的風量(距離)與風向(方
位)，以最少的能源，達到冷氣的效果。
深度圖同樣也可運用於互動式電玩上，透
過追蹤人類的手勢與肢體動作，以達到自
然與直覺的人機介面。 
由產業界的觀察可知以電腦為平台
的演算法的用途會受到很大的限制，在實
際應用上最終還是要做成嵌入式系統才
有利推廣。因此我們在此計畫中，發展了
強健模式比對與一個快速而適合嵌入式
系統的立體視覺方法，因為我們快速的立
體視覺方法是基於區塊方式，我們所使用
的資料結構使得我們在改變區塊的寬度
並不會增加太多的計算量，利用該方法的
優勢，然而我們也發展了比單純區塊立體
視覺的方式更精確的階層融合的立體視
覺演算法。 
 
三、 結果與討論 
（1）強健模式比對 
  我們這邊展示強健模式比對的結果，
在我們的實驗中我們使用 32x32 大小的模
版，而原始影像大小為 180x144。我們僅使
用紅色的頻道來實驗，為了證明我們的方
法對於遮蔽是強健的，我們在原始影像上
加了橘色區塊當做是遮蔽的影像（如下圖
一所示）。我們也利用影像編輯軟體對樣板
的亮度做了改變，以證明我們的方法在亮
度有變化的情況下仍然是強健的。圖二展
示了我們方法的結果，第一行是不同亮度
下的樣板，第二行是找到最佳的影像區
塊，第三行是我們方法所產生的權重遮
罩。圖三是另一個實驗結果。 
 
圖一、加上人為遮蔽的原始影像 
 
 5 
 
 
 
 
圖六、五種方法在不同區塊大小下的運算
速度，其包含了最大 disparity為 30及最
大 disparity為 70兩種。 
 
<b> 立體視覺匹配準確度分析 
 首先我們想要分析不同的區塊大小
下，立體視覺匹配的準確度，因此我們先
擷取了右圖正確 disparity，為了避免邊界
及沒有出現在左右兩圖的區域，我們選取
了如圖七的範圍當成我們評估準確度的基
準。 
 
圖七、蘆薈圖右圖的正確 disparity（為了
顯示所以 diparity值已被乘以 3），第二張
圖是我們用來評估準確度的區域。 
 
 
圖八、影像的區域變異量，在此使用 5x5
區塊分析。 
 
圖九、變異量的直方圖並將最小的 25%、25%
至 50%、50%至 75%、75%以上的各歸為一類，
因此所有點是這四個等級的其中一個。 
 
 
圖十、影像區域變異量的四個等級，從坐
上右上左下右下分別是，是最小到最大的
變異量。 
 
在蘆薈測試圖中，我們可以發現整個背景
的變異量是非常大的，只有在植物與盆栽
些許的部份較為平滑，因此對進行立體視
覺匹配是較為容易的例子，其他不同型態
的測試圖如圖十一的 Baby1是較為困難的
例子，而圖十三的 Plastic大部分都是均
勻的，因此對於基於區塊的立體匹配方法
是極為困難的。 
 
 
 7 
 
 
圖十六、經過簡單的階層融合的結果 
 
四、計畫成果自評 
 
本計劃發展了強健式模式比對與嵌
入式快速立體視覺系統，在強健模式比對
中，我們利用了 NCC 可以克服些許亮度
變化的問題，並將傳統的 NCC 改成迭代
切割的方式，以便處理當原始影像受到遮
蔽，或是樣板受到遮蔽的問題，更進一步
從我們的強健式模式比對還可以發現遮
蔽部分以及未遮蔽部分，最後輸出最佳對
應影像區塊與其遮蔽的遮罩。 
快速立體視覺系統中我們是屬於區
塊比對的方法，儘管目前區塊比對的方法
已經比全域立體視覺比對快速許多，我們
的方法進一步比傳統的基於區塊比對實
作快了數十倍，而我們方法的對於區塊寬
度是不敏感的，增加區塊的寬度，我們立
體視覺比對的計算時間並不會增加多
少。因為這個理由，我們還發展了階層融
合的立體視覺演算法。 
 
五、參考文獻 
 
[1] S. Zhu, and K. K. Ma, "A new diamond 
search algorithm for fast block-matching 
motion estimation," IEEE Trans. Image 
Processing, Vol. 9, No. 2, pp. 287-290, Feb. 
2000. 
[2] R. Li, B. Zeng and M.L. Liou, "A new 
three-step search algorithm for block motion 
estimation," IEEE Trans. Circuits Systems 
Video Technology, Vol. 4, No. 4, pp. 
438-442, Aug. 1994. 
[3] L. M. Po and W. C. Ma, "A novel four-step 
search algorithm for fast block motion 
estimation," IEEE Trans. Circuits Systems 
Video Technology, Vol. 6, No. 3, pp. 
313-317, June, 1996. 
[4] W. Li and E. Salari, "Successive elimination 
algorithm for motion estimation," IEEE 
Trans. Image Processing, Vol. 4, No. 1, pp. 
105-107, Jan. 1995. 
[5] X. Q. Gao, C. J. Duanmu, and C. R. Zou, "A 
multilevel successive elimination algorithm 
for block matching motion estimation," 
IEEE Trans. Image Processing, Vol. 9, No. 3, 
pp. 501-504, Mar. 2000. 
[6] C.-H. Lee and L.-H. Chen, "A fast motion 
estimation algorithm based on the block sum 
pyramid," IEEE Trans. Image Processing, 
Vol. 6, No. 11, pp. 1587-1591, 1997.  
[7] C. Zhu, W. S. Qi, and W. Ser, 
"Predictive Fine Granularity Successive 
Elimination for Fast Optimal 
Block-Matching Motion Estimation," 
IEEE Transactions on Image Processing, 
Vol14, Feb, 2005 
[8] A. Klaus, M. Sormann, and K. Karner 
(2006) Segment-Based Stereo Matching 
Using Belief Propagation and a 
Self-Adapting Dissimilarity Measure in 
Proceedings of ICPR (International 
Conference on Pattern Recognition). 
[9] Q.X. Yang, L. Wang, R. Yang, H. 
Stewénius and D. Nistér, Stereo 
Matching with Color-Weighted 
Correlation, Hierarchical Belief 
Propagation and Occlusion Handling, 
IEEE Trans. on Pattern Analysis and 
Machine Intelligence,31:492-504,2009 
[10] L. Di Stefano, S. Mattoccia, "Fast template 
matching using bounded partial correlation," 
Machine Vision and Applications, Vol. 13, 
No. 4 pp 213-221,  February 2003 
[11] L. Di Stefano, S. Mattoccia, "A sufficient 
condition based on the Cauchy-Schwarz 
inequality for efficient template matching," 
Proc. IEEE International Conf. Image 
Processing. Barcelona, Spain, Sep. 14-17, 
2003 
[12] J. P. Lewis, "Fast template matching," Vision 
Interface, pp. 120-123, 1995. 
[13] M. Mc Donnel, "Box-filtering techniques," 
國科會補助專家學者出席國際學術會議心得報告 
                                     日期：100年7月 20日 
補助編號 NSC 99 － 2218 － E － 241 － 002－ 
計畫名稱 強健式模式比對與嵌入式快速立體視覺系統 
出國人員
姓名 魏守德 
服務機構
及職稱 弘光科技大學資工系助理教授 
會議時間 
100 年 6 月 20 日
至 
100 年 6 月 22 日 
會議地點 韓國首爾 
會議名稱 
(中文)第三屆國際 3D 系統與應用研討會 
(英文)3rd International Conference on 3D Systems and 
Applications 
發表論文
題目 
(中文)由階層式分割從未校正的影像做深度估測 
(英文)Depth Estimation from Uncalibrated Stereo Images via 
Hierarchical Over-Segmentation 
一、參加會議經過 
這次出國的目的是參加 3DSA 發表論文。會議在 Korean Hall of Science and 
Technology 舉行，位在首爾的江南地區，與市中心隔了條漢江。從市中心出發，地
鐵轉搭三條線，繞了半個首爾才到達。不同於觀光客常去的明洞、東大門等，江南
地區是辦公大樓林立的地方，大部份都是行色匆匆的上班族。 
一般大型研討會主題豐富，收錄的論文很多，為讓大會順利在幾天內執行完畢，會
分很多 session 同時舉行，為了有趣的論文趕場常有遺珠之憾。由於 3DSA 研討會的
主題明確，集中在 3D 相關的系統與應用，收錄的論文較少，會場只有一個 session，
能從頭參與到尾，可以充份欣賞與 3D 相關的技術。 
Monday, June 20
Plenary Session
Keynotes
6/20(Mon ) 14:30-17:45 Auditorium I, B1F
Time
14:30-14:45
14:45-15:35
15:50-16:40
16:55-17:45
18:00
Tuesday, June 21
Time
Paper
ID
Title Authors Affiliation
08:40-09:00 S1-1
Gradient weighted joint bilateral filtering
for depth map upsampling
Jaekwang Kim, Jaeho Lee, and
Changick Kim
Korea Advanced Institute of
Science and Technology
09:00-09:20 S1-2
Multiview calibration of a ring-shaped camera array based on essential
matrices reliability
Daniel Moldovan, Masahiro Kawakita,
and Hiroshi Ando
NICT
09:20-09:40 S1-3
Application of long range depth camera for generating virtual-viewpoint
videos of sporting events
Yuko Uematsu, Takanori Hashimoto,
Noki Shimizu, Takuya Inoue, Yuki
Takaya, Francois de Sorbier, and
Hideo Saito
Keio University
09:40-10:00 S1-4
Depth estimation from uncalibrated stereo images via hierarchical over-
segmentation
Li-Hsuan Chin, Yi-Ling Chen,  Yi-Hsien
Li, Jia-Jie Hung, Shang-Hong Lai, and
Shou-Der Wei
National Tsing Hua University,
ITRI, and  Hungkuang University
10:00-10:20 S1-5
Image processing in an integral imaging pickup system with dual-green
pixel-offset
Hitoshi Hiura, Jun Arai, Takayuki
Yamashita and Makoto Okui
Japan Broadcasting Corporation
10:20-10:40 S1-6
A parallelepiped calibration method between high-resolution color camera
and low-resolution depth camera using cubic calibration box
Fumiharu Tomiyasu, Takafumi
Marutani, Toshiaki Fujii,Shoji Kajita,
and Kenji Mase
Nagoya University
Time
Paper
ID
Title Authors Affiliation
10:50-11:20 S2-1
[ Invited paper]
Clinical research on the ophthalmic factors affecting 3D asthenopia
Seung-Hyun Kim, Young-Woo Suh,
Jong-Suk Song,Ji Hye Park, Yong
Yeon Kim, Kuhl Huh, Jaebum Son,
Keetaek kham, Taeuk Jeong, and
Kyung Soo Pyo
Korea University College of
Medicine, Kangwon National
University, Korea Radio
Assocaition, and Dong-A
University
Title
Keynote speech I
Glasses-free 3D display systems being developed at NICT
Dr. Naomi Inoue
NICT, Japan
Keynote speech II
Intelligent and interactive 3D display system
Prof. Yi-Pai Huang
National Chiao Tung University, Taiwan
Keynote speech III
Future 3D technology – focusing on integral imaging, holography and see-through display
Prof.  Byoungho Lee
Seoul National University, Korea
break
Oral Session
Opening Ceremony
Session I: 3D Capturing & Processing I
6/21(Tue ) 08:40-10:40 Auditorium I, B1F
break
Session II: 3D Human Factor
Session Chair : Prof. Jisang Yoo (Kwangwoon University, Korea)
Reception (Committee Chairs & VIPs)
Session Chair : Prof. Namik Cho (Seoul National University, Korea)
Session Chair : Dr. Takanori Senoh (NICT, Japan)
break
6/21(Tue ) 10:50-12:40 Auditorium I, B1F
Time
Paper
ID
Title Authors Affiliation
10:10-10:40 S6-1
[Invited paper]
Image quality improvement for full-color viewing-zone-angle-expanded
electronic holography system
Takanori Senoh, Kenji Yamamoto,
Ryutaro Oi,Yasuyuki Ichihashi, and
Taiichiro Kurita
NICT
10:40-11:00 S6-2
Disparity estimation at virtual viewpoint for real-time intermediate view
generation
In-Yong Shin and Yo-Sung Ho
Gwangju Institute of Science and
Technology
11:00-11:20 S6-3 Methods for generating 8K holograms from 4K integral photography images
Yasuyuki Ichihashi, Ryutaro Oi,
Takanori Senoh, Kenji Yamamoto, and
Taiichiro Kurita
NICT
11:20-11:40 S6-4 Image inpainting for DIBR-based system
I. Daribo, R. Furukawa, H. Saito, S.
Hiura, and N. Asada
Hiroshima City University and
Keio University
Time
Paper
ID
Title Authors Affiliation
14:00-14:20 S7-1 Derivation of gray to gray crosstalk from crosstalk cancellation
Fu-Hao Chen, Kuo-Chung Huang,
Jinn-Cherng Yang, Jian-Chiun Liou,
and Kuen Lee
ITRI
14:20-14:40 S7-2
Experimental evaluation of hybrid 3D sound field reproduction integrating
multi-point sound field control and wave field synthesis
Noriyoshi Kamado, Hiroshi Saruwatari,
and Kiyohiro Shikano
Nara Institute of Science and
Technology
14:40-15:00 S7-3
Pixel design and driving method of
three dimensional pattern retarder displays
Cheng-Han Tsao, Chao-Yuan Chen,
Te-Sheng Chen, and Alan Lien
AU Optronics Corp.
15:00-15:20 S7-4
Fast computation of computer-generated-hologram
 using multi-GPU cluster system
Naoki Takada,Tomoyoshi
Shimobaba,Hirotaka Nakayama,
Minoru Oikawa, Yasuyuki Ichihashi,
Nobuyuki Masuda, and Tomoyoshi Ito
Shohoku college,
Chiba University,
National Astronomical
Observatory of Japan, and
NICT
15:20-15:40 S7-5
Overdriving method for fast switching liquid crystal lenses
on 2D/3D switchable display
Chih-Wei Chen, Po-Chuan Chen, Yi-
Pai Huang, and Jian-Jun Li
National Chiao Tung University
and SuperD Co., Ltd.
Time
Poster
ID
Title Authors Affiliation
P1-1
Trilateral-filter-based depth interpolation for occlusion handling in stereo
vision
Yen-Chieh Lai, Chung-Te Li, Chien
Wu,  Chao-ChungCheng, and Liang-
Gee Chen
National Taiwan University
P1-2
Integral images compression based on
 multi-view video plus depth(MVD) representation
Shasha Shi, Patrick Gioia, Gérard
Madec, and Shinya Terasaki
France Télécom  and Télécom-
Bretagne
P1-3
Automatic alpha matting with adaptive trimap generation using depth
camera
Ji-Ho Cho, Min Ki Park, Kwan H. Lee,
and Kiyoharu Aizawa
The University of Tokyo, and
Gwangju Institute of Science and
Technology
P1-4 3D imaging using two illumination sources and one CCD camera Sabri Gurbuz and Masahiro kawakita NICT
P1-5 Fast depth map upsampling based on region classification
Jiwon Choi, Changick Kim, Hyungsub
Lim, and Euiyeol Oh
Korea Advanced Institute of
Science and Technology, and LG
Display
P1-6 Depth and texture imaging using visible structured light
Hyon-gon Choo, Jinsu Choi, and
Jinwoong Kim
ETRI
P1-7 A simple depth extraction method for hardware implementation
Chan Kim, Gi-Mun Eom, and Won-Sik
Cheong
ETRI
P1-8
Object-based depth map adjustment method for three dimensional video
systems
Yu-Cheng Fan, Chi-Cheng Lin,
Wei-Chun Ting, and Bing-Lian Lin
National Taipei University of
Technology
P1-9
Depth different temporal filtering CGH algorhithm
for digital holographic video
Hyun-Jun Choi, Yoon-Hyuk Lee,
Young-Ho Seo, and Dong-Wook Kim
Anyang University and
Kwangwoon University
P2-1 High efficiency CODEC for multi-view video
Woong Lim, JungHak Nam, Hyomin
Choi, and Donggyu Sim
Kwangwoon University
P2-2 A modified histogram based illumination compensation algorithm Dong Seok Lee and Jisang Yoo Kwangwoon University
P2-3
Stereoscopic video interview coding for HDTV compatible 3DTV
broadcasting service
Sukhee Cho, Young-su Heo, Seyoon
Jeong, Gwang Hoon Park, and Jin Soo
Choi*
ETRI and  Kyunghee University
P2-4
Stereoscopic video coding using adaptive loop filter for non-real-time 3DTV
services
Byung-Tak Lee, BongHo Lee, Jae-Gon
Kim, Won-Sik Cheong, and Namho Hur
Korea Aerospace University and
ETRI
P2-5 Multi-view video distributed encoding and streaming system
Hideaki Kimata, Shinya Shimizu,
Katsuhiko Fukazawa, and Norihiko
Matsuura
NTT Corporation
Lunch Break
Special event : 3D film,  6/22(Wed) 11:50-14:00 Auditorium II, B1F
Treasure  (by Dong-Ah Institute of Media and Arts)
DAMYANG (by Dong-Ah Institute of Media and Arts)
Hengel and Gretel (by BigI Co.,Ltd.)
Internationl Beach Volleyball (by SKY3D)
Poster Session
SessionVI: 3D Caputre & Processing II
15:40-17:40
6/22(Wed ) 14:00-15:40 Auditorium I, B1F
SessionVII: 3D Displays & Systems II
6/22(Wed ) 10:10-11:40 Auditorium I, B1F
6/22(Wed ) 15:40-17:40 Auditorium II, B1F
Session Chair : Prof. Jong-Il Park (Hanyang University, Korea)
Session Chair : Dr. Lopez-Gulliver Roberto (NICT, Japan)
Session Chair : Prof. Dongwook Kim (Kwangwoon University, Korea)
Depth Estimation from Uncalibrated Stereo Images 
via Hierarchical Over-Segmentation 
 
Li-Hsuan Chin
1
, Yi-Ling Chen
2
, Yi-Hsien Li
1
, Jia-Jie Hung
1
, Shang-Hong Lai
1*
, and Shou-Der Wei
3 
1
Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan 
2
Industrial Technology Research Institute, Hsinchu, Taiwan 
3
Department of Computer Science and Information Engineering, Hungkuang University, Taichung, Taiwan 
*
Email: lai@cs.nthu.edu.tw 
 
 
Abstract—Stereo reconstruction has been widely used for 
obtaining depth maps from 2D images. In practice, the 
stereo images are often acquired from uncalibrated stereo 
cameras. In this paper, we propose an accurate system for 
depth estimation from uncalibrated stereo images. The 
proposed system consists of a robust image rectification 
procedure and a hierarchical over-segmentation based 
stereo matching algorithm. The robust image rectification 
procedure determines image transformation from a set of 
interest point correspondences. In the stereo matching 
algorithm, we propose a stereo reconstruction algorithm 
that combines image over-segmentation and belief 
propagation in a hierarchical framework. We show 
improved quality of the depth map estimation by applying 
the proposed algorithm to real stereo image pairs. 
 
Keywords- stereo reconstruction, depth estimation, 
image rectification 
1. Introduction 
Stereo matching has been one of the kernel topics in 
3D computer vision. With the development of three-
dimensional display industry, such as 3DTV, 
stereoscopic movies, and so on, stereo vision is 
becoming more and more mature. An extensive amount 
of work on this topic has been surveyed and evaluated by 
Scharstein and Szeliski [1]. If we study the state-of-the-
art stereo methods on the Middlebury website [2], we 
can find most of the top-ranked methods share a common 
framework. That is, they perform some image over-
segmentation, followed by some sort of global 
optimization. Segmentation, in a nutshell, is used as a 
way to reduce the effects of image noise and matching 
ambiguities on the stereo results. In addition, these 
segmentation-based algorithms are usually combined 
with a global energy minimization approach, such as 
Belief Propagation (BP) [3] or Graph Cuts [3]. 
In stereo reconstruction, image rectification 
simplifies the search of match points between binocular 
images in 1D space constrained by the epipolar geometry, 
so as to search along the corresponding horizontal 
scanline. Traditional stereo systems assume fixed camera 
parameters that can be obtained through a careful camera 
calibration procedure in advance. However, modern 
devices and applications, such as pan/tilt cameras, 
autostereoscopic displays, and robot vision systems, may 
encounter the case of uncalibrated cameras or varying 
camera motions or zooming in/out effects. Thus, the 
demand of calibrating cameras and rectifying images 
from image content itself is strongly required in practice 
[5-6]. 
The proposed image rectification algorithm aims to 
rectify images for uncalibrated stereo images, thus 
providing rectified stereo images for depth estimation. In 
this work, we formulate an objective function that jointly 
considers the geometric errors and rigidity constraints to 
estimate the affine transformation for image rectification. 
Thus, the proposed algorithm has the advantages of 
reduced rectification distortion and robustness against 
outliers. 
After the image rectification, the proposed stereo 
matching algorithm is applied to the rectified stereo 
videos to estimate the disparity maps. Our algorithm is 
based on a hierarchically over-segmented belief 
propagation framework [7]. The hierarchical belief 
propagation is performed in conjunction with a multi-
level over-segmentation of the stereo images, which is 
accomplished by modifying the affinity propagation 
algorithm [8]. 
2. Proposed Algorithm 
2.1. Image Rectification 
Before the stereo matching, we need to rectify the 
input image pairs, because image rectification simplifies 
the search of match points between binocular images in 
1D space so as to search along the corresponding 
horizontal scanline. Affine transformation has been 
popularly used in computer vision due to its linearity and 
generality in practical applications. To reduce the 
complexity of the online rectification problem, we 
propose to apply affine transformations for image 
rectification. 
First we assume that (  
   
   
   
) is the i-th feature 
point on the left image and (   
   
   
   
) is the 
corresponding feature point on the right image. The 
S1-4 3rd International Conference on 3D Systems and Applications
Seoul, Korea, 20~22 June 2011.
99
2.3. Depth Estimation by BP Optimization 
After the hierarchical over-segmentation, we apply 
our stereo matching algorithm using the modified HBP 
to estimate disparity maps. Here we employ a symmetric 
stereo model similar to the [8], given a stereo image pair 
       , we want to estimate the disparities         and 
occlusion maps         for left view    and right view 
  . Now we formulate the stereo matching problem as 
follows: 
                                     
                                       (7) 
where the data term          measures how well the 
disparity    fits the given stereo image pair  , the 
smoothness term        encodes a smoothness 
assumption on disparity, and    is a weight to balance 
these two terms. The occlusion is either considered 
implicitly or treated as an outlier process. The disparity 
   of the right image is computed independently.  
In the stereo configuration, pixel   in    corresponds 
to pixel      in    by disparity   . Similarly,   in    
corresponds to      in   . All possible disparity values 
for    and    are integers between   and  , where   is 
the maximum positive disparity value. The color of pixel 
  in    (or   ) is denoted as       (or      ). We define 
the data term                 on the left image as 
                                        
 
        
where             is a binary variable,       is a 
truncated L1 norm function that is robust to outliers due 
to noise, occlusions, specularities, and so on: 
                      
   
  
      
where parameters    and    control the shape of robust 
function. For the matching cost, we use the sampling-
insensitive absolute difference of Birchﬁeld and 
Tomasi’s pixel dissimilarity [9]          , which 
computes the absolute distance between the extrema of 
linear interpolations of the corresponding pixels of 
interest with their neighbors. On the right image, the data 
term                 is defined in the similar way. 
Some methods, like [10], assume that depth varies 
smoothly over the entire image except at object 
boundaries, and [8] only enforces smoothness within 
occluded and unoccluded regions. We combine these two 
schemes, and the smoothness cost becomes 
                                          (8) 
where      is the set of neighbors of the pixel   and 
                   is the set of all adjacent pixel 
pairs.                           is the set of 
discontinuities at the boundaries between occluded and 
unoccluded pixels. Here we consider the situation at the 
finest level (pixel level) in HBP because the occlusion 
map is generated only at this level. For other levels, all 
adjacent nodes will be taken into consideration to 
compute the smoothness terms. Note that     is the 
truncation point for the L2 norm function. For each 
neighboring pair of nodes (segments), the truncation 
point is set such that pairs with large color differences 
have a small impact on the discontinuity cost, and pairs 
with small differences have a large impact. We use 
                   
       
 
   
                (9) 
where    and    are the mean color of nodes (segments) 
  and  . The parameter    controls the influence of the 
segments’ color difference.      is chosen to be a small 
value to ensure that each node has at least some 
influence on its neighboring nodes. 
We apply the HBP optimization process to solve 
the optimization problem for stereo matching. At the first 
iteration, the value of occlusion are set to zeros. Once the 
disparities have been estimated, we can obtain the 
corresponding occlusion maps by warping each pixel in 
the reference view to the target view according to its 
disparity. If the corresponding pixel in the target view 
exists, set the value of occlusion to 0, otherwise it is set 
to 1. We also apply the median filter to remove small 
noises on the occlusion maps. The number of levels in 
HBP depends on the total level      of structure, and we 
ran five message update iterations at each level. 
2.4. Refinement Process 
The estimated disaprity maps may still have some 
errors in textureless regions because it is hard to find the 
actual correspondence. In these regions, we apply plane 
fitting to disparity maps. The basic idea is that each 
segment represents a 3D plane, so the disparity plane 
corresponding to a segmented region is expressed by the 
following function :                 , where   
and   are image coordinates, and  ,   and   are plane 
parameters. The refinement procedure contains two 
major steps, color segmentation and plane fitting. 
In the color segmentation step, we merge small 
segments from our over-segmentation result by adopting 
the mean-shift segmentation method [11] to our over-
segmentation result of level 1. In the plane fitting step, 
for each segment, we estimate these parameters by using 
Iteratively Reweighted Least Squares (IRLS) algorithm 
[12] to solve the linear system defined as follows: 
       
where                    
     
 
  
 
  
 
 
 , and 
   
 
 
 
     
        
 
        
 . 
For each iteration, the diagonal matrix  is updated 
according to the current residuals as follows:  
S1-4 3rd International Conference on 3D Systems and Applications
Seoul, Korea, 20~22 June 2011.
101
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/21
國科會補助計畫
計畫名稱: 強健式模式比對與嵌入式快速立體視覺系統
計畫主持人: 魏守德
計畫編號: 99-2218-E-241-002- 學門領域: 圖形辨識
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
