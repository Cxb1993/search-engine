a criterion such as minimum squared errors and maximum canon-
ical correlation [26]. While the kernels in most multiple kernel
learning differ in parameters and types, they share a common
information resource (or a feature set); moreover, they may have
distinct inputs. The study in [27] divides the input feature set into
subsets of local features to construct multiple kernels. Summing
the kernels will reduce the incorrect recognition rate caused by
partially contaminated features (e.g., the object of interest is par-
tially occluded). A related method, KPCA plus LDA [28], shares
the similarity of needing decision fusion for more than one resul-
tant feature space, though the work is, strictly speaking, not in
the catalog of multiple kernels. KPCA plus LDA maps one input
onto two feature spaces. Rather than in the input feature space,
the division for features occurs in the kernel feature space (which
is produced by KPCA), in which LDA is applied individually to two
orthogonal complement subspaces, resulting in two feature spaces.
When data carry auxiliary information, it is worth exploring
such information as a resource for discrimination. In applications
with images, the spatial context is often embedded with abundant
discriminative information [29,30]. The spatial context information
can thus be deﬁned as another input to a kernel function, which
forms multiple resources. A composite kernel is constructed by
combining a polynomial kernel and an RBF kernel based on spec-
tral and spatial features, respectively [31]. The spatial features
are expressed in terms of the mean and the standard deviation in
the neighborhood of a pixel.
The main focus of this study is related to a new design of the
kernel function suitable for classiﬁcation of image data. The pro-
posed kernel function is a composite kernel that integrates two
additional resources of information – class membership and spatial
context – while preserving the concept of the kernel trick. Spatial
context information is explored by means of Markov random ﬁeld
models (MRFs) [32,33]. Two pixels are compared based on the
characteristics of the spatial neighborhood. Class membership is
taken into account in terms of the mutual closeness deﬁned in this
study. Two samples are deemed similar if they belong to same
class with a high probability. The proposed kernel function allows
two samples to be distinguished based on dissimilar spatial con-
texts and low mutual closeness in class membership, even if they
are close in the Euclidean distance measure. A function is said to
be a valid kernel function if it obeys Mercer’s conditions [34–36].
We give a proof to show that the proposed kernel function is a
Mercer kernel.
The rest of the paper is organized as follows. Section 2 reviews
the kernel trick and its application to feature extraction. Section 3
describes the proposed kernel function and proves its validity as a
Mercer kernel. Section 4 presents the experimental results. Finally,
conclusions are presented in Section 6.
2. Kernel trick and kernel-based feature extraction
A kernel-based feature extraction is, conceptually, composed of
two transformations: a nonlinear mapping / from an input space
X to the kernel space H, / : X! H, and a linear projectionL from
H onto a lower dimensional space Y, L : H ! Y . The objective of
the mapping / is to transform data in X to a much higher dimen-
sional kernel space H [9] that possesses possibly higher data sepa-
rability than the original space. If m features, v1; . . . ; vm, are
involved in the linear projection L, the kernel-based feature
extraction for a given input data sample x 2 X can be expressed
as s
Lð/ðxÞÞ ¼
hv1;/ðxÞi
..
.
hvm;/ðxÞi
2
664
3
775: ð1Þ
The linear mappingL, such as PCA and LDA, is basically derived
based on the training samples. Given n observation training sam-
ples x1; . . . ;xn 2 Xn > dimðXÞ, any resulting feature vj will be in
span f/ðx1Þ; . . . ;/ðxnÞg and can be expressed in matrix form as
vj ¼ Uaj; ð2Þ
where U ¼ ½/ðx1Þ   /ðxnÞ. Let
A ¼ ½a1    am; ð3Þ
then
Lð/ðxÞÞ ¼ AT
h/ðx1Þ;/ðxÞi
..
.
h/ðxnÞ;/ðxÞi
2
664
3
775: ð4Þ
Note that there is a relationship between the distance metric and
the inner products,
k/ðxiÞ  /ðxjÞk2 ¼ h/ðxiÞ;/ðxiÞi  2h/ðxiÞ;/ðxjÞi
þ h/ðxjÞ;/ðxjÞi: ð5Þ
While the distance metric is often used as a similarity measure, this
relationship implies that inner products are highly associated with
the similarity between two samples. By introducing
Kðxi;xjÞ ¼ h/ðxiÞ;/ðxjÞi; ð6Þ
the kernel trick implicitly computes an inner product in H based on
resubstitution with a kernel function K that represents a similarity
measure between two mapped vectors in H but can be executed
explicitly in the input space X [22]. Hence, Lð/ðxÞÞ can be carried
out based on an a priori chosen kernel function,
Lð/ðxÞÞ ¼ AT
Kðx1; xÞ
..
.
Kðxn;xÞ
2
664
3
775: ð7Þ
Prior to performing the kernel-based feature extraction, one needs
to consider (i) the choice of kðx1;x2Þ and (ii) the determination of
A. Once a kernel function has been chosen, the kernel matrix
K ¼ hU;Ui can be constructed from Kðxi;xjÞ; i; j ¼ 1; . . . ;n, based
on the given n training samples, x1; . . . ;xn. Next, a linear feature
extraction algorithm L whose criterion can be expressed in terms
of inner products is chosen as the base algorithm for the derived
kernel method. If PCA is used as the base algorithm, the derived cri-
terion for KPCA is
JðaÞ ¼ a
TMa
aTa
; ð8Þ
where
M ¼ K 1
n
1nK 1nK1n þ
1
n2
1nK1n; ð9Þ
and 1n is an n nmatrix of all ones. Solving the eigenvalue problem
Ma ¼ ka ð10Þ
yields the m most signiﬁcant eigenvectors to form A ¼ ½a1    am for
KPCA.
If LDA is considered as the base algorithm, the criterion for KDA
is derived as
JðaÞ ¼ a
TMba
aTMwa
; ð11Þ
where Mb; Mw are associated with the between-class and within-
class scatter matrices in H,
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502–517 503
PFðxTÞ ¼ 1Z exp 
1
T0
X
c
VcðxTÞ
( )
; ð25Þ
where VcðxTÞ denotes the potential function of clique c, T0 is the
temperature, and Z is the normalizing constant for the sum-to-
one constraint. For the sake of simplicity, Vc is deﬁned herein using
the pair-wise multi-level logistic (MLL) model [42], with a level for
a label. Assume that the MRF is a homogeneous and isotropic ﬁeld,
then Vc is independent of site and orientation. For a pair-wise clique
c ¼ fs; tg;VcðxTÞ ¼ bcdðxs–xtÞ, where bc is the neighborhood inﬂu-
ence associated with the clique type. It follows thatX
c
VcðxTÞ ¼
X
s2T
X
t2Hs
bcdðxs–xtÞ: ð26Þ
By substituting (26) into (25), and (25) into (24), the potentials of
the cliques not containing site s will be cancelled from the denom-
inator and the numerator. It follows that the conditional probability
P xsjxTfsg
	 

depends only on the cliques containing site s as
follows:
P xsjxTfsg
	 
 ¼ PðxsjxHs Þ
¼
exp  1T0
P
t2Hsbcdðxs–xtÞ
n o
PL
~xs¼1 exp  1T0
P
t2Hsbcd ~xs–xtð Þ
n o : ð27Þ
3.3. Formulation of the MRF-based kernel function
Let us deﬁne a contextual vector, rðsÞ ¼ ½r1ðsÞ    rxðsÞ    rLðsÞT ,
where rxðsÞ conveys the spatial context information of site sassoci-
ated with class x. rxðsÞ is deﬁned by
rxðsÞ ¼
X
t2Hs
bcpðxjxt;xHt Þ; x 2 f1; . . . ; Lg; ð28Þ
where pðxjxt;xHt Þ is the a posteriori probability as given in (22).
Furthermore, consider a contextual distance dCðsi; sjÞ representing
the similarity of spatial context between the samples at sites
si and sj. Let us deﬁne the contextual distance dCðsi; sjÞ as
dCðsi; sjÞ ¼ krðsiÞ  rðsjÞk: ð29Þ
In addition to spatial context information, we exploit the discrimi-
native resource from the class memberships of samples. Let
xj ¼ argmax
x¼1;...;L
pðxjxj;xHsi Þ be the optimum label assigned to the
sample xj at site sj. The value of pðxj jxi;xHsi Þ reﬂects how closely
a sample xi is related to another sample xj with respect to class
membership. The mutual closeness in class membership is deﬁned
by
gðxi;xjÞ ¼ pðxj jxi;xHsi Þp xi jxj;xHsj
  1=2
: ð30Þ
In an L-class problem, a sample is assigned an optimum label with
pðxjx;xHÞP 1=L. If two samples xi and xj are classiﬁed into the
same class, pðxj jxi;xHsi Þ¼pðxi jxi;xHsi ÞP1=L, and pðxi jxj;xHsj Þ¼
pðxj jxj;xHsj ÞP1=L. This leads to 1=L 6 gðxi;xjÞ 6 1. Otherwise, if
two samples xi and xj are assigned with different class labels, we
have 0 6 gðxi;xjÞ 6 1=L. A pair of samples assigned with the same
class label enjoys a larger value of class-membership similarity than
those with different class labels.
By combining the resources from the spatial context and class
membership, a new kernel function for samples xi and xj at sites
si and sj is designed as
Kðxi;xjÞ ¼ gðxi; xjÞq
 exp  1
r2
ad2Eðxi;xjÞ þ ð1 aÞd2Cðsi; sjÞ
  
; ð31Þ
where dEðxi; xjÞ ¼ kxi  xjk is the Euclidean distance, r controls the
width of kernel, 0 6 q 6 1 controls the signiﬁcance of the class-
membership similarity, and a is a parameter to balance between
the Euclidean distance and the contextual distance. When the
class-membership similarity is not signiﬁcant and negligible, one
can set q to be 0. In image applications, we often see
gðxi; xjÞ and dC render a similar effect, since both are related to
the MRF-based contextual information. In this case, one can choose
a small number for q to reduce the redundancy. This kernel function
can be generally applied to classiﬁcation problems, not limited to
the applications of image data. If spatial context information is
not available, labels are simply assigned by xi ¼ argmax
x¼1;...;L
pðxjxiÞ.
The kernel function for samples x and y degenerates to
Kðxi;xjÞ ¼ gðxi;xjÞ exp  d
2
Eðxi;xjÞ
r2E
( )
; ð32Þ
where gðxi; xjÞ ¼ Pðxj jxiÞPðxi jxjÞ
 1=2
.
Since a kernel function can be viewed as a measure of similarity
between samples, two samples xi and xj are said to be of high sim-
ilarity if Kðxi;xjÞ is close to 1, and of low similarity if Kðxi; xjÞ takes
on a value near 0. Consider the following scenario: two samples
xi and xj of distinct classes are withdrawn from an image. Suppose
that the samples are located near the boundary between classes in
the original feature space. They are misclassiﬁed by a pixel-wise
classiﬁer. Also, suppose that each of the samples is surrounded
by samples of its own class in the image. Thus, they can be cor-
rectly relabeled by using an MRF-based classiﬁer. If the samples
are separated by a small Euclidean distance, dE, the basic RBF ker-
nel in (17) will fail to discriminate between the samples. However,
their spatial contexts are quite different, leading to a large contex-
tual distance dC . The probability of a sample belonging to the class
of the other sample tends to be low, resulting in a small value of
class-membership similarity gðxi;xjÞ. In this case, either a large
dC or a small gðxi;xjÞ will force the value of Kðxi;xjÞ to approach
zero, thus properly representing the dissimilar relationship be-
tween the samples.
3.4. Proof of a mercer kernel
The RBF kernel has been proven to be a positive deﬁnite kernel
[43], and therefore it is a Mercer kernel according to Mercer’s the-
orem. Similarly, we will prove in the following that the proposed
kernel is a Mercer kernel because of the positive deﬁniteness. A
real symmetric matrix ½Aij is called almost negative deﬁnite pro-
vided that
Xn
i¼1
Xn
j¼1
cicjAij 6 0 ð33Þ
whenever
P
i¼1;...;nci ¼ 0 [43]. Note that if
Aij ¼ 1r2E
kxi  xjk2 þ 1r2C
XL
x¼1
krxðsiÞ  rxðsjÞk2 ð34Þ
for some training sample set fðx1; s1;x1Þ; . . . ; ðxn; sn;xnÞg;xi 2
X; si 2 T;xi 2 f1; . . . ; Lg, then the matrix ½Aij is almost negative def-
inite because
Xn
i¼1
Xn
j¼1
cicjAij ¼  2r2E
Xn
j¼1
cjxj


2
 2
r2C
XL
x¼1
Xn
j¼1
cjrxðsjÞ


2
6 0 ð35Þ
whenever
P
i¼1;...;nci ¼ 0. Furthermore, let
Bij ¼ 12 ln pðxjjxiÞ 
1
2
ln pðxijxjÞ: ð36Þ
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502–517 505
Theproposedkernel functionprovides away to improvediscrim-
ination based on spatial context information. If yi and yj have the
same Euclidean distance to a training sample x, the RBF kernel func-
tion fails to distinguish yi and yj. If yi and yj have different contex-
tual distances tox, the degree of discrimination between yi and yj
can be increased. In the worst case, classes are severely overlapped
in the input feature space. The proposed method can overcome the
overlapping problem if discriminative information about the spatial
context is present in the image. Dataset 3 is characterized by high
class separability in the spatial domain, but low class discrimination
in theoriginal three-dimensional feature space, as shown in Fig. 6(a).
Two classes are normally distributed with slightly different mean
vectors, ½0 0 0T and ½0:1 0 0T , and a common identity covariance
matrix. Fig. 6(b) shows that methods such as PCA, LDA, KPCA and
KDA give rather poor classiﬁcation accuracy, even using the original
three features, due to low discrimination in the original feature
space. In contrast, the resulting distributions of MrfKPCA and
MrfKDAbecomeseparable. Using classmembership and spatial con-
text information leads to an improvement of 45% in classiﬁcation
accuracy over other feature extraction methods.
Fig. 3. Distributions of Dataset 1 resulting from various feature extraction methods. (a) KPCA; (b) KDA; (c) MrfKPCA; and (d) MrfKDA.
Fig. 4. (a) Distribution of Dataset 2. (b) Performance of feature extraction.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502–517 507
4. For the chosen base feature extraction algorithm, the eigen-
value problem is solved. m ðm 6 dÞ optimum features are
selected to form a transform matrix A.
5. For each sample x in the image, the corresponding feature vec-
tor, w ¼ ½kðx1;xÞ    kðxn;xÞT , is obtained by pairing x with each
training sample xi. Feature extraction is performed by using
z ¼ ATw to generate an m-variate image data set.
6. In the test stage, the resulting m-variate image is classiﬁed
using a pixel-wise or an MRF-based ML classiﬁer. The classiﬁca-
tion accuracy is assessed based on test samples.
7. The above steps are repeated for the new m-variate image data
set if iteration is requested. The iteration terminates if the test
accuracy becomes stable.
4. Experimental results
4.1. Data description
We used synthetic and natural images to perform a comparative
study. Synthetic images are composed of texture patterns selected
from the Brodatz album [45]. The experiment aims to separate tex-
ture patterns from each other and to extract an animal silhouette
(Zebra, Squirrel, and Tiger) from a natural image. In these cases,
classes cannot be described appropriately by unimodal distribu-
tions. An overlap of the distributions between classes in the origi-
nal feature space makes it difﬁcult to separate one class from the
others, as seen in Fig. 7(a). It is quite difﬁcult to separate the
Fig. 7. Color image Zebra and the classiﬁcation maps based on various methods: (a) Image and its distribution in the RGB space (Class1: Zebra. Class2: Background, x1:R, x2:G,
x3:B). (b) kNN-MRF; (c) LDA; (d) KDA; (e) SVM; (f) MKL; (g) CKFD; (h) C-KDA; and (i) MrfKDA. Methods LDA, KDA, CKFD, C-KDA, and MrfKDA are followed by a kNN and an
MRF-based contextual classiﬁer. (For interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this paper.)
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502–517 509
provides a common ground for comparison of SVM to KDA and
LDA. Tables 3 and 4 show that SVM and KDA outperform LDA, thus
conﬁrming the feasibility of the basic RBF kernel.
Multiple kernel learning (MKL) is basically an extension of SVM.
The MKL [26] used in this comparative study combines a linear
kernel, a polynomial kernel, and a Gaussian RBF kernel based on
a minimum-error criterion regularized by maximizing correlation
among multiple kernels (called canonical correlation analysis).
However, under the constraint of agreement among kernels, a
poorly operated kernel will likely cause the overall performance
of MKL to deteriorate. The correlation-based MKL sometimes pro-
duces poorer results than SVM (Table 3) because the MKL includes
an incompetent linear kernel. In the design of multiple kernels,
requirements should be set to highlight the kernels of good perfor-
mance and to suppress the kernels of poor performance. We thus
slightly modiﬁed the MKL formulation in [26] by loosening the
constraint of full agreement among kernels and assigning small
weights to poorly operated kernels. For example, the linear, the
polynomial, and the Gaussian RBF kernels were assigned a weight
of 0, 0.3, and 0.7, respectively, for the image Tiger. Table 3 shows
Table 4
kNN classiﬁcation accuracy of various feature extraction algorithms in the reduced (L  1) dimensional space.
Image Reduced
dimension, L  1
LDA Standard
deviation
KDA Standard
deviation
CKFD Standard
deviation
Mrf
CKFD
Standard
deviation
C-
KDA
Standard
deviation
Mrf
KDA
Standard
deviation
Zebra 1 86.6 0.9 86.7 2.0 89.5 1.4 89.3 2.1 94.1 2.1 97.2 1.4
Tiger 1 87.0 4.3 93.9 0.6 92.1 2.2 94.1 2.6 99.0 1.0 98.7 1.0
Squirrel 3 94.9 0.5 95.5 0.6 94.8 1.2 94.7 1.0 99.5 0.5 97.6 0.6
Rocks 1 88.0 0.4 87.8 1.3 89.0 0.6 89.9 1.1 93.7 1.2 97.7 0.9
T5 4 86.1 0.7 86.4 0.6 86.5 1.0 87.9 3.5 93.3 1.1 97.2 0.6
Average 88.5 90.1 90.4 91.2 95.9 97.7
Table 5
kNN-MRF contextual classiﬁcation accuracy of various feature extraction algorithms.
Image Reduced
dimension, L  1
LDA Standard
deviation
KDA Standard
deviation
CKFD Standard
deviation
Mrf
CKFD
Standard
deviation
C-
KDA
Standard
deviation
Mrf
KDA
Standard
deviation
Zebra 1 90.6 1.4 91.6 2.2 91.3 1.7 91.3 2.5 95.5 1.6 96.0 3.4
Tiger 1 95.7 1.9 96.9 1.4 96.2 2.2 97.5 1.3 99.1 1.0 98.6 1.3
Squirrel 3 97.8 0.6 97.7 0.6 98.9 0.3 99.1 0.4 100.0 0.0 98.3 0.3
Rocks 1 94.4 1.0 92.6 1.3 94.7 1.3 94.5 1.1 96.2 1.2 98.4 0.9
T5 4 91.6 1.1 91.7 0.7 92.5 1.3 93.2 2.5 95.8 0.6 97.6 0.6
Average 94.0 94.1 94.7 95.1 97.3 97.8
Fig. 8. Image Tiger and the classiﬁcation maps based on various methods: (a) Image; (b) kNN-MRF; (c) LDA; (d) KDA; (e) SVM; (f) MKL; (g) CKFD; (h) C-KDA; and (i) MrfKDA.
Methods LDA, KDA, CKFD, C-KDA, and MrfKDA are followed by a kNN and an MRF-based contextual classiﬁer.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502–517 511
discriminant features from the nullspace of the within-class
covariance matrix. In Table 4, CKFD does not consistently perform
better than KDA. That is probably because the summed normalized
distance for fusing two sets of features is not appropriate in some
cases. Like the canonical correlation analysis used in MKL, the
summed normalized distance used in CKFD tends to suffer from
an ineffective feature set.
Table 3 shows that using an MRF-based classiﬁer exhibits an in-
crease in classiﬁcation accuracy, compared to that of using a kNN
classiﬁer. With the aid of spatial context information, a misclassi-
ﬁed pixel is correctly relabeled if it is surrounded by pixels of the
same class. This establishes the role of the spatial context as an
auxiliary discriminative resource for the test images. The methods,
MrfKDA and C-KDA, additionally incorporate spatial context
Fig. 11. Image T5 and the classiﬁcation maps based on various methods: (a) Image T5 is synthesized from ﬁve Brodatz texture patterns ð300 300Þ. The gray image is
combined with six wavelet features to generate a seven-dimensional image. The lowpass ﬁltered seven-dimensional image is used for textual classiﬁcation. (b) kNN-MRF; (c)
LDA; (d) KDA; (e) SVM; (f) CKFD; (g) C-KDA; and (h) MrfKDA. Methods LDA, KDA, CKFD, C-KDA, and MrfKDA are followed by a kNN and an MRF-based contextual classiﬁer.
Fig. 12. The results obtained by using various window widths to deﬁne the neighborhood in MrfKDA and the MRF-based classiﬁer. The test classiﬁcation accuracy for various
window widths: (a) 91.4% for window width 3; (b) 95.9% for window width 7; and (c) 97.3% for window width 15.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502–517 513
Fig. 14. Classiﬁcation accuracy using the MRF-based contextual classiﬁer. (a) Dataset 1; (b) Dataset 2; and (c) Dataset 3.
Fig. 15. Performance of the iterative MrfKDA for image T5. (a) 94.3% for the ﬁrst iteration; (b) 96.1% for three iterations; (c) 95.7% for ﬁve iterations; (d) 96.9% for seven
iterations; and (e) 97.3% for nine iterations.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502–517 515
