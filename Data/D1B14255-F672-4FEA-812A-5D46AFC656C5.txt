  
Abstract 
 
Artificial neural networks have been applied to many application areas and have gained 
remarkable success. Many evolutionary algorithms including evolutionary strategies, evolutionary 
programming, particle swarm optimization and genetic algorithms had been proposed to train the 
connection weights of neural networks, the architectures of neural networks, or both. 
In this report, the systematic trajectory search algorithm (STSA) is proposed to train the 
connection weights of the feedforward neural networks. The STSA utilizes the orthogonal array (OA) 
to uniformly generate the initial population in order to globally explore the solution space; it then 
applies a novel trajectory search method that can exploit the promising area thoroughly. The 
performance of the proposed STSA is evaluated by applying it to train a class of feedforward neural 
networks to solve the n-bit parity problem and the classification problem on two medical datasets from 
the UCI machine learning repository. By comparing with the previous studies, the experimental results 
revealed that the neural networks trained by the STSA have very good classification ability.  
 
Keyword：Feedforward neural network, systematic trajectory search algorithm, orthogonal array, n-bit 
parity problem.  
  
值。但是，倒傳遞演算法存在兩個主要問題：(a)可能陷於區域最佳解而無法找到全域最佳解；
(b)Activation function 一定要是可微分的函數。因此，演化式演算法的出現，為類神經網路的訓練
提供了另外的研究方向，圖一為三層式的多層式感知機的例子。 
 
Output LayerInput Layer
Hidden 
Layer  
(a) 
 
(b) 
圖一 (a) 為三層式的 multilayer perceptron 架構；(b)為隱藏層的單一節點內部的運作方式 
 
 文獻回顧 
由於訓練類神經網路的架構與權重值可視為在解空間中找尋最佳解，近年來，有一些研究
[1][2][3][4][5][6][7][8][9]利用演化式演算法 (Evolutionary Algorithm)以及群體智慧 (Swarm 
Intelligence)的相關技術來訓練類神經網路，也獲致不錯的成果，其中，基因演算法(Genetic 
Algorithm)、演化式規劃 (Evolution Programming)、蟻群最佳化(Ant Colony Optimization)、粒子群
最佳化(Particle Swarm Optimization)等具備全域搜尋 (Global Search)能力的演算法都被提出來探
討；這其中也包含混合多種策略的演化架構。此外，為了可以儘快收歛並獲得更好的搜尋結果，
有些研究也加入了部份局部搜尋(Local Search)的機制，如：Tabu Search、Simulated Annealing。研
究結果顯示：若有效地結合具有全域搜尋與局部搜尋能力的演算法將能獲得不錯的成果[2][10]。
然而，因為類神經網路的特性，我們尚未發現有效的區域搜尋能力的演算法被提出來。 
傳統的多層式感知機網路架構只允許相鄰兩層之間的節點可以有鏈結存在，圖二(a)是個例
子，在先前學者的研究成果中[2]與我們的研究實驗中都發現，若存在跨層節點間的鏈結(shortcut)
更可增加類神經網路的能力。因此，我們計劃利用兩種基本的一般化前饋式網路架構來作為我們
的分類器的基礎架構，例如：可以利用三層隱藏層的網路來解 n-bit parity 問題，我們採用了：
n-1-1-1-1(圖二(b)是個 n=4的例子), n-2-2-2-1等網路架構來驗證其能力。在我們先前的研究成果中
[10]：我們發現隱藏層只需包含單一節點就可以解 7-bit parity 的問題；而當隱藏層的節點數為 2
時，可以解 9-bit parity的問題。因此，我們推論：假如這些一般化的前饋式網路架構即可解決大
部分的問題，那麼，我們只要根據問題事前先選定網路架構，讓演算法只訓練權重即可，如此可
以大大降低訓練所需的時間。 
  
有學者針對較大的 n-bit parity 問題進行實驗。而這也引起我們的研究興趣，因為，若所提出
的方法可以訓練類神經網路來解較大的 n-bit parity問題，就代表該演算法應該具備非常強的
訓練能力。 
 
(B) UCI classification Problems 
在實務的分類問題方面，加州大學爾灣分校(UCI)所維護管理的機器學習資料集[11]常被
當成分類的代表性問題。其中，有部分是實際的醫療臨床方面的診斷資料，裡面包含著病患的
各種實際量測的數值(心跳、血壓、性別、年齡，… 等)與實際罹病狀況(有無病症)。本計劃即
以該資料集內的乳癌與心臟病資料集進行分類效能的實驗。其中，乳癌資料集(Breast Cancer - 
Wisconsin)中的資料主要是由威爾康辛大學附設醫院所收集的相關病患資料，每筆資料有九個
輸入特徵值，一個輸出值代表是否罹患乳癌(benign or malignant)，共有 699個樣本，其中共有
241 個樣本是乳癌病患；不過，部分病患的資料有部分屬性遺失(共有 16 筆單一屬性資料遺
失)。心臟病資料集(Statlog/Heart Disease)中的資料主要是由 Cleveland Clinic所收集的相關病患
資料，每筆資料有 14個輸入特徵值(其中一個屬性是病患 ID，因此只有 13個有意義的屬性值)，
一個輸出值代表是否罹患心臟病，共有 270個樣本，其中共有 120個樣本是心臟病患。 
 文獻回顧 
UCI 資料集早已成為機器學習領域的重要比較基礎，也早已經有許多方法被學者提出來
解 UCI資料集的分類問題。要比較哪一種方法(演算法)所產生的分類器比較好，就有各種比較
的方式被提出來，較常見的是利用 Cross Validation 方式來(如：leave-one-out, k-fold validation
等)比較平均的分類正確率。 
當利用類神經網路來解 UCI 分類與預測問題時，大部分都採用 Prechelt 技術報告中[20]
所提出的建議，將原始資料分為 training, validation 以及 test 三個資料子集，其中 validation
資料子集是用來檢驗一般性能力(Generalization)以避免網路的過度訓練；而 test 資料子集就是
在最後階段用以測試分類器對於未知資料的分類能力，並藉以判定各種演算法的優劣。 
 
4. 研究方法 
利用基因演算法來解最佳化的問題一直都是熱門的課題，如：排程問題、旅行推銷員問題、
二次分配問題、p-中位問題等[1][2][3][4][5][6][7][8][9][12][13][14]。也有學者例用基因演算法來訓
練類神經網路的架構與權重以解各種預測、回歸與分類問題。基於先前研究所累積的經驗得知：
有效地結合全域搜尋與局部搜尋能力的演算法來訓練類神經網路應該是一個可行的方案，因此，
我們曾提出了一個「兩階段式的基因區域搜尋演算法(Two-phase Genetic Local Search Algorithm)」
來訓練一般化的前饋式類神經網路[10]：第一階段的基因演算法搭配較為粗糙的局部搜尋演算法
來進行大範圍的概略搜尋以避免搜尋所有的解空間而花費太多計算時間，當解的品質到達一定程
度時就進入第二階段的基因演算法，此時的局部搜尋演算法就會較為細緻的在小區域內進行搜尋。 
然而，根據我們先前的研究實驗[10]得知：當所訓練的類神經網路接近最佳解時，區域搜尋
方法的有效性就成為關鍵。根據實驗經驗得知傳統基因演算法中的單切點交配運算子在類神經網
路的演化後期並無法提供有效的改進空間，因此，在此計畫中，我們提出一個新的演算法，稱之
為「系統化軌跡搜尋演算法」(systematic trajectory search algorithm， STSA)，主要的目的有兩個： 
(A) 具備全域搜尋的能力，儘可能地搜尋解空間的所有可能的區域。 
(B) 具備有效的區域搜尋能力，能夠完整的搜尋有潛力區域。 
 
圖三為完整的 STSA 演算法的架構圖： 
  
Step 4.利用 RALS 對每一種子個體附近進行詳盡的區域搜尋 
4-1.若是 n-bit parity 問題，在區域搜尋中有找到更好的解，就直接更新該種子 
4-2.若為 UCI分類問題，在區域搜尋過程中，我們利用Elitism的方式保留較好的前幾名(存
為 EliteGroup)，以便後續可以利用 validation dataset 來挑選一般化較佳的個體，而不
是由 training dataset 之中挑最好的而已。 
Step 5.若有進步的話，就更新區域最佳解(localBest)，若比總體最佳解(globalBest)還好，也同時更
新總體最佳解； 
5-1. 若為 n-bit parity 問題，直接以 fitness 來決定是否有進步，同時檢查是否已經找到
最佳解（fitness=1.0），若找到最佳解就停止程式的執行。 
5-2. 若為 UCI 分類問題，fitness 是同時參考 training dataset 與 validation dataset 的 
fitness 來決定是否有進步。若兩者均可訓練到完全分類正確(fitness為 1.0)，也可以
提早中止程式的執行，不過，這種情形在實驗過程未曾發生過。 
Step 6. 若沒有進步，增加 stuck計數器(stuckCounter)，當 stuck計數器超過一個預設值時，代表該
區域應該不可能找到最佳解，因此就停止該種子個體附近區域的搜尋。回到 Step 4.重覆
執行。 
 
 STSA演算法相關的細節： 
A. The solution representation 
每個解均代表一個類神經網路架構的鏈結集合，因此，我們以一個由權重組成的向量來表
示每一個解(w1,w2, … , wn) . 每一個 wi 就對應到類神經網路的某一個鏈結.每一個 wi 是介於 
[-10, 10] 的一個浮點數值. 
B. The global search phase 
為了產生均勻分布於解空間的初始解，我們利用 OA的特性來產生初始族群的個體. Leung 
[10]等人也曾利用相同的方法來產生初始解。假設 n 為類神經網路的鏈結數。我們利用以下的
方法來產生 initial popualtion，然後從其中挑選部分個體成為 seed population。 
Step 1. 挑選一個適當的正交陣列 OA( m, f, L, t) 並將相關資料儲存在二維陣列 OA[m, f]. 此
外，執行時，系統會隨機兩兩交換整個欄的值，以便可以產生不同的初始解。 
Step 2. 將 1..n 隨機分割為 f 個族群. (Step 2 & 3 的實作詳細可以參考[23]) 
Step 3. 利用 OA[m, f] 產生 m 初始解當為 initial population.  
Step 4. 計算每個個體的 fitness, 挑選前面 k 個較佳解當為 seed population.  
在我們的實驗中, 我們採用了 OA( 243, 20, 3, 3) 來產生 initial population. 
C. The random array local search method (RALS) 
整個 random array local search 方法是由Orthogonal Array 所引發的想法和靈感.主要是因
為要產生任意大小和任意level的OA 是不容易的；若要動態臨時產生OA又非常花時間。因此，
我們提出一個簡化版的 random array (RA) 來取代 OA. 詳細說明可以參考附件發表於2007年
International Joint Conference on Neural Networks之論文The Systematic Trajectory Search Algorithm 
for Feedforward Neural Network Training 的 Section IV. 
在先前的研究成果中[10]，我們提出了 TPGLS 來訓練類神經網路。在經過許多的實驗後發
現，對於一個類神經網路的權重向量 w，所謂 w 的鄰近區域 w’ 應該是較大範圍的變動部分權
重值，而不是對每個維度去做小幅度的變動而已。 
因此，RALS 就是以單一種子(weight vector)出發，利用 RA來產生種子附近的均勻分布的
解，然後逐一評估；有進步就更新種子的 weight vector。為了充分的搜尋種子個體附近的區域，
  
花時間。 
 
 
2) The UCI classification problems 
為了和先前的成果比較[2]，我們以下述的網路架構進行實驗，每種實驗均進行 30 次，以
便比較結果: 
(1) breast cancer dataset 採用 9-1-1-2  
(2) heart disease dataset 採用 13-1-1-2  
相關的 STSA的參數設定，可以參考表 II，其中 RALS 的鄰近區域的尋找次數遠比 n-bit 
parity 多，主要是因為 UCI 分類問題較為敏感，因此，區域分割也比較細緻(20)之故，如
此可以較為完整的搜尋鄰近區域。當然，為了避免花太多時間，RALS 搜尋的次數較比較少。 
 
表 II 
PARAMETERS USED IN THE STSA FOR UCI CLASSIFICATION PROBLEMS 
parameters value 
Size of the seed population (k) 20 
Orthogonal Array OA( 243, 20, 3, 3) 
Number of neighbors in 
the neighborhood  
( i.e. rows of RA) 
500 
Levels of each dimension 20 
Number of iterations of 
RALS  
3 
minDim 1  
maxDim 3 
vRatio 0.2 
RALS 
Size of elite group 10 
Max. stuck count 5 
 
表 I 
PARAMETERS USED IN THE STSA FOR THE N-BIT PARITY PROBLEM 
Parameters value 
Size of the seed population (k) 30 
Orthogonal Array OA( 243, 20, 3, 3) 
Number of neighbors in 
the neighborhood  
( i.e. rows of RA) 
300 
Levels of each 
dimension 
10 
Number of iterations of 
RALS  
50 for N= 6, 7 
100 for N= 8, 9 
200 for N=10, 11 
minDim 1 
maxDim 3 
RALS 
vRatio 0.3 
Max. stuck count 5 
  
 
 
表  III 
COMPARISON BETWEEN THE STSA AND THE TPGLS 
ALL RESULTS OF THE STSA WERE AVERAGED OVER TEN RUNS AND THE RESULTS OF THE TPGLS WERE AVERAGED OVER 
FOUR RUNS 
N-1-1-1-1 N-2-2-2-1 
TPGLS[10] STSA TPGLS[10] STSA 
 
Average CPU time Average CPU time Average CPU time Average CPU time 
N=6 4 min. 44 sec. 0 min. 19 sec. 4 min. 23 sec. 0 min. 15 sec. 
N=7 15 min. 59 sec. 3 min. 18 sec. 5 min. 13 sec. 2 min. 14 sec. 
N=8 24 min. 10 sec.
 (*1)
 6 min. 50 sec.
 (*1)
 1 hour 39 min. 0 hour 8 min. 
N=9 2 hour 37 min. 0 hour 25 min. 
N=10 19 hour 11 min. 
(*2)
  3 hour 33 min. 
(*3)
 
N=11 
N/A 
N/A 9 hour 37 min. 
(*4)
 
(*1) Both the TPGLS and the STSA cannot find out the optimal solution for 8-1-1-1-1 network. The 
computation time given is that with one error out of 256 training samples. 
(*2) In the previous study [10], there was just one successful run out of two complete experiments in the TPGLS. 
(*3) The value is the average of nine successful runs out of ten complete experiments in the STSA. 
(*4) The value is the average of five successful runs out of ten complete experiments in the STSA. 
 
 
表  IV 
COMPARISON BETWEEN THE STSA AND THE EPNET[2]. ALL RESULTS WERE AVERAGED OVER THIRTY RUNS 
EPNet[2] STSA   
Training 
error rate 
Validation 
error rate 
Test 
error rate 
Training 
error rate 
Validation 
error rate 
Test 
error rate 
Mean 0.03773 0.00590 0.01376 0.02636 0.01447 0.00876 
SD 0.00694 0.00236 0.00938 0.00518 0.00359 0.00514 
Min 0.01719 0.00000 0.00000 0.01719 0.00571 0.00000 
Breast 
Cancer 
dataset 
Max 0.04585 0.01143 0.04000 0.04011 0.02285 0.01714 
Mean 0.13632 0.17304 0.16765 0.07901 0.11343 0.17108 
SD 0.01517 0.01995 0.02029 0.01434 0.01081 0.02953 
Min 0.09702 0.13235 0.13235 0.04444 0.08955 0.11765 
Heart 
Disease 
dataset 
Max 0.16418 0.20588 0.19118 0.10370 0.13433 0.25000 
 
 
表 V 
COMPARISON AMONG FNNCA[25] , HDANNS[20], EPNET[2], AND STSA  
Algorithm Results of 
FNNCA  
in 50 runs 
Results of 
HDANNS by 
Trial-and-Error  
Results of 
EPNet  
over 30 runs 
Results of 
STSA  
over 30 runs 
#hidden Nodes 2 6 2.0 2 (fixed) 
Best 0.0145 0.01149  0.00000 0.00000 
Breast 
Cancer 
dataset 
Testing Error 
Rate Mean N/A N/A 0.01376 0.00876 
#hidden Nodes N/A 4 4.1 2 (fixed) 
Best N/A 0.1478 0.13235 0.11765  
Heart 
Disease 
dataset 
Testing Error 
Rate Mean N/A N/A 0.16767 0.17108 
 
  
[23] Y. W. Leung, and Y. Wang, “An orthogonal genetic algorithm with quantization for global 
numerical optimization.” IEEE Transactions on Evolutionary Computation, Vol. 5, Feb. 2001, 
pp. 41-53. 
[24] J.-T. Tsai, T.-K. Liu, and J.-H. Chou, “Hybrid Taguchi-Genetic algorithm for global numerical 
optimization,” IEEE Transaction on Evolutionary Computation, vol. 8, no. 4, Aug 2004, 
pp.365-377. 
[25] R. Setiono and L. C. K. Hui, “Use of a quasi-newton method in a feedforward neural-network 
construction algorithm,” IEEE Transaction on Neural Network, vol. 6, pp. 273-277, 1995 
 
 
  
出席國際學術會議心得報告 
 
承蒙國科會與國立中興大學的補助得予參加 2007年 6月 25日至 28日在美國拉斯維加斯舉辦
的 The 2007 World Congress in Computer Science, Computer Engineering, and Applied Computing國
際會議，這個會議總共有二十五個與資訊科學和工程相關的會議同時舉行，是一個相當盛大的國
際學術會議，估計有近千人參加，我主要參加的是基因演算法與演化式演算法會議 (The 2007 
International Conference on Genetic and Evolutionary Methods)，但也去聽了幾堂生物資訊會議、人
工智慧會議和資料探勘會議的論文報告，玆將出席此一會議的心得略述如下: 
6月 25日從台灣直飛到洛杉磯，再從洛杉磯轉機到拉斯維加斯，在第一天的晚宴中遇到同樣
台灣來的中央大學資工系的周立德教授，來開會之前我查過掛名台灣的論文有三十多篇，可能因
為人太多了，又分散在各個會議，以至於沒碰到幾個台灣來的學者。Keynote Speech請了三位，
都很不錯，其中包括了基因演算法的創始者 John Holland，可見主辦單位很用心要把會議辦好，
我聽的一些論文報告品質都不錯，大多數的講者也都能講得很清楚，特別在基因演算法與演化式
演算法會議中有一篇論文”Particle Swam Optimization for Cluster-Based Classification of Breast 
Cancer Data”激發了我ㄧ些想法，對我正在作的研究很有幫助，我想這也是參加學術會議的好處，
一方面彼此分享最新的研究成果，一方面彼此腦力激盪，而能產生新而好的想法，在此也建議國
科會與教育部可以多多補助國內的教授或研究人員出國開會，藉此提昇研究的質與量。我的論文
發表安排在 6 月 26 日的下午，論文題目是”A Genetic Local Search Algorithm for the Floorplan 
Problem with Boundary Constraints”， 論文發表中也與好幾位各國學者有很好的討論與切磋。 
我在拉斯維加斯開會那幾天，拉斯維加斯的最高溫是攝氏 40度，我要離開的時候，看到氣象
預報，接下來的的最高溫是攝氏 43度，當我回到台灣，看到新聞報導，拉斯維加斯的最高溫是攝
氏 47度，而我在美國那幾天，德州下大雨作水災，可見全球暖化的現象確實愈來愈嚴重，每個人
都應該開始用真實的行動來減少二氧化碳的排放與能源的消耗。 
回程我搭機到舊金山，預備從舊金山返國，在舊金山我參加了一天的旅遊團到 Yosemite國家
公園，風景非常漂亮，是一個休閒放鬆身心的好地方，可惜的是因為這時節水比較少，所以瀑布
只有一點水，看起來不夠壯觀。 
 III. THE GENETIC LOCAL SEARCH ALGORITHM 
 The genetic algorithm is suitable for the 
global search. The genetic local search algorithm 
combines a genetic algorithm as the global search 
algorithm and a local search algorithm and hence 
enhances the searching capability. In this section, 
we first describe the encoding of the chromosome. 
Then, we describe the genetic local search 
algorithm. 
 
A. The Encoding of the Chromosome 
 In a genetic algorithm, a chromosome 
represents a solution in the solution space. The 
encoding of a chromosome in this paper is based 
on the sequence pair. A sequence pair (Γ+, Γ-) is a 
2-tuple, where Γ+ and Γ- are sequence that 
represent permutations of the n blocks b1, b2, …, 
bn. A sequence pair can be used to represent a 
floorplan because it defines the relative positions 
of blocks as shown in the following: 
(…bi…bj…, …bi…bj…) means that block bi is to 
the left of block bj. 
(…bi…bj…, …bj…bi…) means that block bi is 
above block bj. 
(…bj…bi…, …bi…bj…) means that block bi is 
below block bj. 
(…bj…bi…, …bj…bi…) means that block bi is to 
the right of block bj. 
 Therefore, given a sequence pair the relative 
positions of all n blocks and hence the placement 
can be determined. 
 Because a block can be rotated 0° or 90°, 
there are two kinds of rotation of a block. So the 
encoding of a chromosome is defined as a 3-tuple 
(Γ+, Γ-, D), where (Γ+, Γ-) is a sequence pair and 
D is an array of n bits. The ith element of D is 0 
or 1 denoting respectively that block bi is rotated 
0° or 90°. 
B. The Genetic Local Search Algorithm 
 The genetic local search (GLS) algorithm 
combines a genetic algorithm as the global search 
algorithm and a local search algorithm to enhance 
the searching capability. The whole algorithm is 
described as follows. Crossover operators, local 
search operators and mutation operators are 
described following the algorithm. 
Step 1. Randomly generate N chromosomes. 
Step 2. Execute Step3 and Step4 T times. 
Step 3. [Apply the crossover operator and then 
apply the local search operator to 
children L1 times] 
Randomly choose one of the three 
crossover operators and apply it to two 
randomly chosen chromosomes so that 
two child chromosomes can be obtained. 
For each child chromosome 
For I = 1 to L1 
Randomly choose one of the nine 
local search operators and apply it to 
the current chromosome. If the 
fitness of the current chromosome is 
improved after the local search, then 
replace the current chromosome by 
the new one. Otherwise, do the 
following M times: Randomly 
choose one of the four mutation 
operators and apply the mutation 
operator to the current chromosome. 
End For 
Step 4. If the fitness of the child chromosome is 
better than that of the parent 
chromosome, then replace the parent by 
the child. 
Step 5. Iteratively, apply the local search operator 
to the best chromosome L2 times as 
follows: 
For I = 1 to L2 
Randomly choose one of the nine 
local search operators and apply it to 
the current chromosome. If the 
fitness of the new chromosome is 
improved after the local search, then 
replace the current chromosome by 
the new one. Otherwise, do the 
following M times: Randomly 
choose one of the four mutation 
operators and apply the mutation 
operator to the current chromosome. 
End For 
Step 6. Output the best chromosome found in the 
whole process. 
 Whenever the fitness is calculated in the 
above mentioned GLS algorithm, the boundary 
checking algorithm will be executed. The 
algorithm is described in the following. 
 c) Crossover operator 3 
 This crossover operator is a kind of mapping 
as illustrated by the following example. Suppose 
Γ+ of parent 1 and Γ+ of parent 2 are (abcd) and 
(bcad) respectively. Then Γ+ of child 1 will be 
(dcab). How it is derived is described as follows. 
The first element in parent 1’s Γ+ is a and the 
element next to a in parent 2’s Γ+ is d, then the 
first element of child 1’s Γ+ is d. The second 
element in parent 1’s Γ+ is b and the element next 
to b in parent 2’s Γ+ is c, then the second element 
of child 1’s Γ+ is c, and so on. Using this mapping, 
parent 1’s Γ+ and parent 2’s Γ+ will generate child 
1’s Γ+. Parent 1’s Γ- and parent 2’s Γ- will 
generate child 1’s Γ-. Likewise, parent 2’s Γ+ and 
parent 1’s Γ+ will generate child 2’s Γ+. Parent 2’s 
Γ- and parent 1’s Γ- will generate child 2’s Γ-. As 
for D (direction), child 1 inherits parent 1’s D and 
child 2 inherits parent 2’s D. 
 
Fig. 3. Crossover operator 2. 
3) Mutation and Local Search Operators 
 Four basic perturbation operators, namely 
swap, rotation, insertion and reverse are defined. 
The mutation operators and local search operators 
are based on these four operators. These four 
operators are described in the following. 
a) Swap 
 This operator swaps two block in both Γ+ 
and Γ- as illustrated by the following example. 
(Γ+, Γ-, D) = (abc, cab, 000) becomes (bac, cba, 
000) after swap(a, b). 
b) Rotation 
 This operator is to rotate a block 90°. 
c) Insertion 
 This operator moves a block in Γ+ (or Γ- ) to 
another position. For example (Γ+, Γ-, D) = 
(abcdef, bcadfe, 100101) becomes (aebcdf, 
bcadfe, 100101) after move the 5
th
 block in Γ+ to 
the second position. 
d) Reverse 
 This operator reverses the order of two block 
in Γ+ (or Γ-). For example (Γ+, Γ-, D) = (abc, cba, 
000) becomes (bac, cba, 000) after apply reverse 
(a, b) on Γ+. 
 The mutation operations are exactly the four 
perturbation operators just introduced. There are 
nine local search operators. In addition to these 
four perturbation operators, other five operators 
are swap + rotation, swap + insertion, rotation + 
insertion, reverse + rotation and reverse + 
insertion. But for local search, the chromosome 
will be replaced only when the fitness has been 
improved after applying the local search operator. 
 
IV. EXPERIMENTAL RESULTS 
 The genetic local search algorithm running 
on a PC with Pentium III 1.2G CPU and 1GB 
main memory had been tested on MCNC 
instances. The programming language used is 
Visual C++. The parameter values and the 
floorplan of the instance ami49 are shown in 
Table 1 and Fig. 4, respectively. The GLS 
algorithm was executed five times for each test 
data. As shown in Table 2, there are two numbers 
in the “area” column of the GLS algorithm, the 
first one is the average of the areas, and the 
second one is the minimum area of the five runs. 
In the first table of Table 2, the results of the GLS 
are compared with those of [1] and [2]. Some 
specific blocks are required to be located on 
boundaries. In this table, it is noted that the GLS 
obtained the smaller floorplan areas than the other 
two methods did. In the second table of Table 2, 
the results of the GLS are compared with those of 
[8], [4] and [5]. Some randomly chosen  blocks 
are required to be located on boundaries. Except 
 [4] J.M. Lin, H.E. Yi, and Y.W. Chang, “Module 
placement with boundary constraints using B*-trees”; 
Proceedings--Circuits, Devices and Systems, Vol. 149, No. 
4, pp. 251-256, August 2002. 
[5] T.M. Lin, and Y.W. Chang, “TCG-S: Orthogonal 
coupling of P*-admissible representations for general 
floorplans”; Proc. IEEE Design Automation Conf., pp. 
842-847, New Orleans, LA, USA, 10-14 June 2002. 
[6] Z.Y. Yang, W.G. Wang, T. Mihara, C. Liu, and H.A. 
Zhao, “Floorplan design with boundary constraints”; 
Proceedings of the IEICE General Conference, Vol. 2005, 
2005. 
[7] H. Murata, K. Fujiyoshi, S. Nakatake, and Y. 
Kajitani, “VLSI module placement based on 
rectangle-packing by the sequence-pair”; IEEE Trans. 
Computer-Aided Design, vol. 15, pp.1518-1524, 1996 
[8] J. Lai, M.S. Lin, T.C. Wang, and L.C. Wang, 
“Module placement with boundary constraints using the 
sequence-pair representation”; Proc. IEEE Asia and South 
Pacific Design Automation Conf., pp.515-520, Yokohama, 
Japan, 30 Jan.-2 Feb. 2001. 
 
 
 
 
 
 IX. ORTHOGONAL ARRAY AND RANDOM ARRAY 
In this section, we briefly introduce the concept of 
orthogonal arrays which are used in experimental design 
methods. For more details, the reader may refer to [14]. 
After introducing the orthogonal array, we describe the 
concept of the random array which will be used in the 
random array local search (RALS) described in Section IV. 
A. The Orthogonal Array (OA) 
Orthogonal arrays, introduced by C. R. Rao in 1947, have 
been used extensively in experiment designs. Suppose in an 
experiment, there are k factors and each factor has q levels. 
In order to find the best setting of each factor’s level, q
k
 
experiments must be done. Very often, it is not possible or 
cost effective to test all q
k
 combinations. It is desirable to 
sample a small but representative sample of combinations 
for testing. The orthogonal arrays were developed for this 
purpose. In an experiment that has k factors and each factor 
has q levels, an orthogonal array OA(n,k,q,t) is an array with 
n rows and k columns which is a representative sample of n 
testing experiments that satisfies the following three 
conditions. (1) For the factor in any column, every level 
occurs the same number of times. (2) For the t factors in any 
t columns, every combination of q levels occurs the same 
number of times. (3) The selected combinations are 
uniformly distributed over the whole space of all the 
possible combinations. In the notation OA(n,k,q,t), n is 
number of experiments, k is the number of factors, q is the 
number of levels of each factor and t is called the strength. 
Another often used notation for the orthogonal array is Ln(q
k
). 
In this notation, t is omitted and is always set to 2. A L8(2
7
) 
orthogonal array is shown in Table I as an illustrating 
example. Orthogonal arrays can be generated automatically 
or manually. Due to the time-consuming computation, most 
applications usually produce or select some suitable 
orthogonal arrays before doing the experiment. 
 
B. The Random Array (RA) 
Although the OA has been successfully applied to many 
applications, it has two drawbacks. The first drawback is that 
it is not easy to construct an OA for any combination of n, k, 
and q in order to satisfy the strength constraint. The second 
one is that it will be time-consuming if we need to use many 
OAs of different sizes. In this study, we propose the Random 
Array (RA) which possesses only the first of the three 
conditions that are satisfied by the OA, namely, for the 
factor in any column, every level occurs the same number of 
times. We use the notation RA( n, k, q) for the random array, 
where n, k, q have the same meaning as those in the OA. A 
powerful local search method utilizing the random array will 
be introduced in the next section. As an illustrating example, 
Table II shows a random array RA( 9, 7, 3). 
 
 
Fig. 1.  The adopted architectures in this study: (a) N-1-1-1-1 neural 
network for N=4 (b) N-2-2-2-1 neural network for N=4 
TABLE I 
AN ORTHOGONAL ARRAY L8(2
7)  
Test No. Factors 
1   2   3   4   5   6   7 
1 0   0   0   0   0   0   0 
2 0   0   0   1   1   1   1 
3 0   1   1   0   0   1   1 
4 0   1   1   1   1   0   0 
5 1   0   1   0   1   0   1 
6 1   1   0   0   1   1   0 
7 1   1   0   1   0   0   1 
8 1   0   1   1   0   1   0 
 
 
TABLE II 
A RANDOM ARRAY RA( 9, 7, 3)  
Test No. dimensions 
1   2   3   4   5   6   7 
1 0   1   0   2   1   0   0 
2 1   2   1   2   0   2   2 
3 1   1   2   1   1   1   1 
4 2   0   1   0   2   2   2 
5 0   2   2   1   1   0   0 
6 2   1   0   2   0   1   0 
7 2   0   2   1   2   1   1 
8 1   2   0   0   2   0   1 
9 0   0   1   0   0   2   2 
 
 
 search thoroughly, the RALS will repeat this process l times 
where l is a user defined parameter.  
 The detail of the RALS is described in Fig. 3. When 
RALS is applied to solve the classification problem with the 
validation dataset, it will store some good solutions in the 
elite group instead of just keeping the best solution in order 
to apply the validation dataset to choose the one with the 
best generalization ability. 
 
XI. EXPERIMENTS AND RESULTS 
The n-bit parity problem, which is not linearly separable, is 
a difficult classification problem. So we used the n-bit parity 
problem to test the classification ability of the feedforward 
neural networks trained by the proposed algorithm. 
Furthermore, the proposed STSA is applied to train the 
feedforward neural network to do the classification work on 
two datasets from the UCI machine learning repository in 
order to clarify its generalization ability. In order to compare 
with the previous study by Yao [11], we apply the same 
method used by Yao to partition the dataset into three parts 
for training, validation and testing. The program was coded 
in Java and run on a personal computer with Intel 1.7Ghz 
CPU and 512 MB memory.  
A. The Settings of Experiments 
1) The n-bit parity problem 
  In order to compare with the previous study [13], ten 
runs were conducted for each of the following neural 
network architectures: 
      (1) N-1-1-1-1 for N= 6, 7, 8, 
      (2) N-2-2-2-1 for N= 6, 7, 8, 9, 10, 11. 
All the hidden nodes and output nodes use the step 
activation function. For the n-bit parity problems, all 2
n
 
patterns were used in training. The parameters used in the 
systematic trajectory search algorithm are shown in Table 
III. The number of iteration of RALS varies for different n. 
As can be seen, for bigger n, the number of iteration of 
RALS is larger in order to search the neighborhood more 
thoroughly. Each dimension will be partitioned into 10 
levels.  
 
2) The UCI classification problems 
In order to evaluate the generalization ability of the 
neural networks trained by the STSA, the STSA was 
applied to train neural networks for classifying two 
real-world medical datasets from the UCI machine 
learning repository [16], namely, the breast cancer dataset 
and the heart disease dataset. The breast cancer dataset 
was originally obtained from W. H. Wolberg at the 
University of Wisconsin Hospitals. It contains nine 
attributes and 699 instances, where 458 instances are 
benign and 241 instances are malignant. The heart 
disease dataset came from the Cleveland Clinic 
Foundation. The purpose of this dataset is to predict the 
presence or absence of the heart disease. The size of the 
original heart disease dataset is 303, and the number of 
attributes is 14. Actually, there are only 13 attributes as 
the last attribute is the identification of the class. 
Because some records contain missing class values and 
some records may cause dispute, we adopted the same 
dataset used by Yao [11]. As indicated by Prechelt [17], 
the missing data which is marked with ‘?’ will be 
replaced by the mean of the same attributes. The 
attribute of the test datasets were rescaled to values 
TABLE III 
PARAMETERS USED IN THE STSA FOR THE N-BIT PARITY PROBLEM 
Parameters value 
Size of the seed population (k) 30 
Orthogonal Array OA( 243, 20, 3, 3) 
Number of neighbors 
in the neighborhood  
( i.e. rows of RA) 
300 
Levels of each 
dimension 
10 
Number of iterations 
of RALS  
50 for N= 6, 7 
100 for N= 8, 9 
200 for N=10, 11 
minDim 1 
maxDim 3 
RALS 
vRatio 0.3 
Max. stuck count 5 
 
// RALS will start from a weight vector W 
// and exploits the neighborhood of W by using the RA 
Procedure RALS(WeighVector W, int l, float vRatio, int level,  
int R, int minDim, int maxDim [, int sizeOfEliteGroup ] )  
Begin 
    // Randomly generate an integer between minDim and maxDim. 
    int  varDim = U(minDim, maxDim);  
repeat l times 
    Dynamically generate a random array RA( R, varDim, 
 level) and save level values in the array RA[R, varDim]. 
//Each element of RA[R,varDim] is between 0 to (level-1) 
for m=1 to R do // search the neighors one by one. 
            oldW = W; 
            // Update some components of W  
      for k=1 to varDim do 
Dynamically choose some component wi of W  
wi=wi+(10-(-10))*vRatio*((RA[m,k]-level/2)/level); 
          // (10-(-10))*vRatio is the range for the local search 
      end of for 
      // Evaluate the fitness of this neighbor. 
      if W is better than the old one, then  
        keep W; // Move to the new solution 
      else if W is as good as the old one && (U(0, 1)< 0.5) 
// Move to the new solution with probability 0.5 
    keep W;   
      else // Restore the original one  
W = oldW; 
// Optional for the classification problem  
//               with the validation dataset 
[* Save W in EliteGroup  
if W is better than the worst one in EliteGroup ] 
end of for 
  end of repeat 
End. 
Fig. 3.  The random array local search method 
 [7] J.-T. Tsai, T.-K. Liu, and J.-H. Chou, “Hybrid Taguchi-Genetic 
algorithm for global numerical optimization,” IEEE Transaction on 
Evolutionary Computation, vol. 8, no. 4, Aug 2004, pp.365-377. 
[8] J.-T. Tsai, J.-. Chou, and T.-K. Liu, “Tuning the structure and 
parameters of a neural network by using hybrid Taguchi-Genetic 
algorithm,” IEEE Transaction on Neural Networks, vol. 17, no. 1, 
Jan 2006, pp.69-80. 
[9] A. Georgieva and I. Jordanov, “Supervised neural network training 
with a hybrid global optimization technique,” in 2006 International 
Joint Conference on Neural Networks, Jul 2006, pp. 6433-6440. 
[10] Y. W. Leung, and Y. Wang, “An orthogonal genetic algorithm 
with quantization for global numerical optimization.” IEEE 
Transactions on Evolutionary Computation, Vol. 5, Feb. 2001, pp. 
41-53. 
[11] X. Yao and Y. Liu, “A new evolutionary system for evolving 
artificial neural networks,” IEEE Transaction on Neural Networks, 
vol. 8, no. 3, pp. 694–713, May 1997 
[12] H.-L. Chao, Feedforward Neural Network Learning Using 
Genetic Algorithms, Master thesis, Dept. Applied Math., National 
Chung-Hsing University, Taiwan, 2001. 
[13] L.-Y. Tseng and W.-C. Chen, “A two-phase genetic local search 
algorithm for feedforward neural network training,” in 2006 
International Joint Conference on Neural Networks, Jul 2006, pp. 
5221-5225. 
[14] D. C. Montgomery, Design and Analysis of Experiments, 3rd ed. 
New York: Wiley, 1991. 
[15] A. S. Hedayat, N. J. A. Sloane and J. Stufken, Orthogonal Arrays: 
Theory and Applications, Springer-Verlag, NY, 1999. 
[16] C.L. Blake and C.J. Merz, “UCI repository of machine learning 
databases,” Univ. of California, Irvine, Dept. of Information and 
Computer Science, 
http://www.ics.uci.edu/~mlearn/MLRepository.html, 1998. 
[17] L. Prechelt, “Proben1-A set of neural network benchmark 
problems and benchmarking rules,” Technical Report 21, 
University of Karlsruhe, 1994. 
[18] R. Setiono and L. C. K. Hui, “Use of a quasi-newton method in a 
feedforward neural-network construction algorithm,” IEEE 
Transaction on Neural Network, vol. 6, pp. 273-277, 1995. 
 
 
出席國際學術會議心得報告 國立中興大學資工系 曾怜玉
承蒙國科會與國立中興大學的補助得予參加 2007 年 6 月 25 日至 28 日在美國拉
斯維加斯舉辦的 The 2007 World Congress in Computer Science, Computer Engineering,
and Applied Computing 國際會議，這個會議總共有二十五個與資訊科學和工程相關的
會議同時舉行，是一個相當盛大的國際學術會議，估計有近千人參加，我主要參加的
是基因演算法與演化式演算法會議 (The 2007 International Conference on Genetic and
Evolutionary Methods)，但也去聽了幾堂生物資訊會議、人工智慧會議和資料探勘會
議的論文報告，玆將出席此一會議的心得略述如下:
6 月 25 日從台灣直飛到洛杉磯，再從洛杉磯轉機到拉斯維加斯，在第一天的晚
宴中遇到同樣台灣來的中央大學資工系的周立德教授，來開會之前我查過掛名台灣的
論文有三十多篇，可能因為人太多了，又分散在各個會議，以至於沒碰到幾個台灣來
的學者。Keynote Speech 請了三位，都很不錯，其中包括了基因演算法的創始者 John
Holland，可見主辦單位很用心要把會議辦好，我聽的一些論文報告品質都不錯，大
多數的講者也都能講得很清楚，特別在基因演算法與演化式演算法會議中有一篇論
文”Particle Swam Optimization for Cluster-Based Classification of Breast Cancer Data”激
發了我ㄧ些想法，對我正在作的研究很有幫助，我想這也是參加學術會議的好處，一
方面彼此分享最新的研究成果，一方面彼此腦力激盪，而能產生新而好的想法，在此
也建議國科會與教育部可以多多補助國內的教授或研究人員出國開會，藉此提昇研究
的質與量。我的論文發表安排在 6 月 26 日的下午，論文題目是”A Genetic Local Search
Algorithm for the Floorplan Problem with Boundary Constraints”， 論文發表中也與好
幾位各國學者有很好的討論與切磋。
我在拉斯維加斯開會那幾天，拉斯維加斯的最高溫是攝氏 40 度，我要離開的時
候，看到氣象預報，接下來的的最高溫是攝氏 43 度，當我回到台灣，看到新聞報導，
拉斯維加斯的最高溫是攝氏 47 度，而我在美國那幾天，德州下大雨作水災，可見全
球暖化的現象確實愈來愈嚴重，每個人都應該開始用真實的行動來減少二氧化碳的排
放與能源的消耗。
回程我搭機到舊金山，預備從舊金山返國，在舊金山我參加了一天的旅遊團到
Yosemite 國家公園，風景非常漂亮，是一個休閒放鬆身心的好地方，可惜的是因為這
時節水比較少，所以瀑布只有一點水，看起來不夠壯觀。
combines a genetic algorithm as the global search
algorithm and a local search algorithm and hence
enhances the searching capability. In this section,
we first describe the encoding of the chromosome.
Then, we describe the genetic local search
algorithm.
A. The Encoding of the Chromosome
In a genetic algorithm, a chromosome
represents a solution in the solution space. The
encoding of a chromosome in this paper is based
on the sequence pair. A sequence pair (+,-) is a
2-tuple, where + and - are sequence that
represent permutations of the n blocks b1, b2, …, 
bn. A sequence pair can be used to represent a
floorplan because it defines the relative positions
of blocks as shown in the following:
(…bi…bj…, …bi…bj…) means that block bi is to
the left of block bj.
(…bi…bj…, …bj…bi…) means that block bi is
above block bj.
(…bj…bi…, …bi…bj…) means that block bi is
below block bj.
(…bj…bi…, …bj…bi…) means that block bi is to
the right of block bj.
Therefore, given a sequence pair the relative
positions of all n blocks and hence the placement
can be determined.
Because a block can be rotated 0or 90,
there are two kinds of rotation of a block. So the
encoding of a chromosome is defined as a 3-tuple
(+, -, D), where (+, -) is a sequence pair and
D is an array of n bits. The ith element of D is 0
or 1 denoting respectively that block bi is rotated
0or 90.
B. The Genetic Local Search Algorithm
The genetic local search (GLS) algorithm
combines a genetic algorithm as the global search
algorithm and a local search algorithm to enhance
the searching capability. The whole algorithm is
described as follows. Crossover operators, local
search operators and mutation operators are
described following the algorithm.
Step 1. Randomly generate N chromosomes.
Step 2. Execute Step3 and Step4 T times.
Step 3. [Apply the crossover operator and then
apply the local search operator to
children L1 times]
Randomly choose one of the three
crossover operators and apply it to two
randomly chosen chromosomes so that
two child chromosomes can be obtained.
For each child chromosome
For I = 1 to L1
Randomly choose one of the nine
local search operators and apply it to
the current chromosome. If the
fitness of the current chromosome is
improved after the local search, then
replace the current chromosome by
the new one. Otherwise, do the
following M times: Randomly
choose one of the four mutation
operators and apply the mutation
operator to the current chromosome.
End For
Step 4. If the fitness of the child chromosome is
better than that of the parent
chromosome, then replace the parent by
the child.
Step 5. Iteratively, apply the local search operator
to the best chromosome L2 times as
follows:
For I = 1 to L2
Randomly choose one of the nine
local search operators and apply it to
the current chromosome. If the
fitness of the new chromosome is
improved after the local search, then
replace the current chromosome by
the new one. Otherwise, do the
following M times: Randomly
choose one of the four mutation
operators and apply the mutation
operator to the current chromosome.
End For
Step 6. Output the best chromosome found in the
whole process.
Whenever the fitness is calculated in the
above mentioned GLS algorithm, the boundary
checking algorithm will be executed. The
algorithm is described in the following.
Step 1. The first block v of+ is used to
determine the setthat consists of v and
the blocks before v in-. The first block
+ of parent 1 and + of parent 2 are (abcd) and
(bcad) respectively. Then + of child 1 will be
(dcab). How it is derived is described as follows.
The first element in parent 1’s + is a and the
element next to a in parent 2’s + is d, then the
first element of child 1’s + is d. The second
element in parent 1’s + is b and the element next
to b in parent 2’s + is c, then the second element
of child 1’s + is c, and so on. Using this mapping,
parent 1’s + and parent 2’s + will generate child
1’s +. Parent 1’s - and parent 2’s - will
generate child 1’s -. Likewise, parent 2’s + and
parent 1’s + wil generate child 2’s +. Parent 2’s 
- and parent 1’s - wil generate child 2’s -. As
for D (direction), child 1 inherits parent 1’s D and 
child 2 inherits parent 2’s D.
Fig. 3. Crossover operator 2.
3) Mutation and Local Search Operators
Four basic perturbation operators, namely
swap, rotation, insertion and reverse are defined.
The mutation operators and local search operators
are based on these four operators. These four
operators are described in the following.
a) Swap
This operator swaps two block in both +
and - as illustrated by the following example.
(+, -, D) = (abc, cab, 000) becomes (bac, cba,
000) after swap(a, b).
b) Rotation
This operator is to rotate a block 90.
c) Insertion
This operator moves a block in+ (or- ) to
another position. For example (+, -, D) =
(abcdef, bcadfe, 100101) becomes (aebcdf,
bcadfe, 100101) after move the 5th block in + to
the second position.
d) Reverse
This operator reverses the order of two block
in+ (or-). For example (+,-, D) = (abc, cba,
000) becomes (bac, cba, 000) after apply reverse
(a, b) on+.
The mutation operations are exactly the four
perturbation operators just introduced. There are
nine local search operators. In addition to these
four perturbation operators, other five operators
are swap + rotation, swap + insertion, rotation +
insertion, reverse + rotation and reverse +
insertion. But for local search, the chromosome
will be replaced only when the fitness has been
improved after applying the local search operator.
III. EXPERIMENTAL RESULTS
The genetic local search algorithm running
on a PC with Pentium III 1.2G CPU and 1GB
main memory had been tested on MCNC
instances. The programming language used is
Visual C++. The parameter values and the
floorplan of the instance ami49 are shown in
Table 1 and Fig. 4, respectively. The GLS
algorithm was executed five times for each test
data. As shown in Table 2, there are two numbers
in the “area”column of the GLS algorithm, the
first one is the average of the areas, and the
second one is the minimum area of the five runs.
In the first table of Table 2, the results of the GLS
are compared with those of [1] and [2]. Some
specific blocks are required to be located on
boundaries. In this table, it is noted that the GLS
obtained the smaller floorplan areas than the other
two methods did. In the second table of Table 2,
the results of the GLS are compared with those of
[8], [4] and [5]. Some randomly chosen blocks
are required to be located on boundaries. Except
the instance apte, for which all the four methods
obtained the same area, the GLS obtained smaller
areas for all other instances. From Table 2, it is
concluded that in comparison with other methods’
IV. CONCLUSIONS
A genetic local search algorithm for
floorplan optimization with boundary
constraints is presented. A genetic algorithm is
good at doing the global search. Hence
combining a genetic algorithm, which acts as a
global search algorithm and a local search
algorithm will enhance the search capability.
The experimental results reveal that in
comparison with other methods’results, the
genetic local search algorithm achieves the best
solutions for minimizing the area in the
non-slicing floorplan problem with boundary
constraints. In addition, the algorithm can
efficiently fix the sequence pair based on the
boundary checking heuristic without using the
constraint graphs and hence effectively reduce
the time to locate boundary blocks. In the
future work, we plan to handle other kinds of
constrains in the floorplan problem.
V. ACKNOWLEDGEMENTS
This paper was partially supported by the
National Science Council of ROC under
contract NSC-94-2213-E005-020.
7 REFERENCES
[1] F.Y. Young, D.F. Wong, and H.H. Yang, “Slicing
floorplans with boundary constraints”; IEEE Trans. on
Computer-Aided Design, Vol.18, No.9, pp.1385-1389,
1999.
[2] D.S. Chen, C.T. Lin, and Y.W. Wang,
“Non-slicing floorplans with boundary constraints using
generalized Polish expression”; Proc. IEEE Asia and
South Pacific Design Automation Conf., pp.342-345,
Kitakyushu, Japan, 21-24 Jan. 2003.
[3] Y. Ma, S. Dong, X. Hong, Y. Cai, C.-K. Cheng,
and J. Gu, “VLSI Floorplanning with Boundary
Constraints Based on Corner Block List”; Proc. IEEE
Asia and South Pacific Design Automation Conf., pp.
509-514, Yokohama, Japan, 30 Jan.-2 Feb. 2001.
[4] J.M. Lin, H.E. Yi, and Y.W. Chang, “Module
placement with boundary constraints using B*-trees”;
Proceedings--Circuits, Devices and Systems, Vol. 149,
No. 4, pp. 251-256, August 2002.
[5] T.M. Lin, and Y.W. Chang, “TCG-S: Orthogonal
coupling of P*-admissible representations for general
floorplans”; Proc. IEEE Design Automation Conf., pp.
842-847, New Orleans, LA, USA, 10-14 June 2002.
[6] Z.Y. Yang, W.G. Wang, T. Mihara, C. Liu, and
H.A. Zhao, “Floorplan design with boundary
constraints”; Proceedings of the IEICE General
Conference, Vol. 2005, 2005.
[7] H. Murata, K. Fujiyoshi, S. Nakatake, and Y.
Kajitani, “VLSI module placement based on
rectangle-packing by the sequence-pair”; IEEE Trans.
Computer-Aided Design, vol. 15, pp.1518-1524, 1996
[8] J. Lai, M.S. Lin, T.C. Wang, and L.C. Wang,
“Module placement with boundary constraints using the
sequence-pair representation”; Proc. IEEE Asia and
South Pacific Design Automation Conf., pp.515-520,
Yokohama, Japan, 30 Jan.-2 Feb. 2001.
Abstract - A genetic local search algorithm is presented in this
paper to handle the boundary constraints on non-slicing
floorplans. This algorithm combines a global search algorithm
(genetic algorithm) and a local search algorithm. In addition, a
new boundary checking heuristic without using
horizontal/vertical constraint graphs is also presented to
effectively reduce the time to locate boundary blocks. The
experimental results achieve promising area utilization with
reasonable computation time that will satisfy the boundary
constraints as required.
Keywords: VLSI floorplan, sequence pair, genetic
algorithm, boundary constraints.
INTRODUCTION
Floorplanning is an important step in VLSI
physical design. It is to place a set of circuit
blocks on a chip to minimize the total area and
the interconnection cost. If some circuit blocks
are specified to reside along the boundaries for
the input or output connections, it is always
useful to allow the users to specify that these
blocks are required to be located along one of the
four sides of the final floorplan. Several previous
works had been proposed to handle boundary
constraints [1-6]. The issues regarding boundary
constraints on floorplan, using Polish expression,
had been studied in [1-2]. In [3], the boundary
constraint algorithm was implemented by
extending corner block list. In [4] the floorplan
design with boundary constraints was devised
using B*-tree representation. Recently, a
representation of non-slicing structure, called
TCG-S, was proposed [5]. It consists of two kinds
of representations and requires more complicated
data structure.
In this paper, a genetic local search
algorithm is proposed to solve the general
non-slicing floorplan problem with boundary
constraints using sequence pair representation [7].
The experimental results show that this algorithm
achieves best solutions for minimizing the area at
the cost of more computation time. Although
similar representation is also proposed in [8], it
requires a complicated transformation method to
transform an infeasible sequence pair into a
feasible one so that it conforms to the boundary
constraints.
The remaining parts of the paper are
organized as follows. Problem formulation is
given in section 2. The genetic local search
algorithm is described in section 3. Experimental
results and conclusions are stated in section 4 and
5 respectively.
I. PROBLEM FORMULATION
A set },...,,{ 21 nbbbB of rectangular blocks is
given. A block represents a module and is placed
parallel to axes. Each block ib has width iw and
height ih . A floorplan }1|),{( niyxCFP ii  is
an assignment of coordinates to the lower left
corners of the rectangular blocks of B such that
no two blocks of B overlap. The blocks in F have
freedom to move while the blocks in C are
constrained to be packed along one of the four
sides of the final floorplan.
In this paper, the objective function is to
minimize the area of the rectangle that encloses
all blocks in B.
II. THE GENETIC LOCAL SEARCH ALGORITHM
The genetic algorithm is suitable for the
global search. The genetic local search algorithm
A Genetic Local Search Algorithm for the Floorplan Problem with
Boundary Constraints
Lin-Yu Tseng*
Department of Computer Science
National Chung Hsing University
Taichung, Taiwan, R.O.C
E-mail: lytseng@cs.nchu.edu.tw
Tuan-Yung Han
Department of Apply Mathematics
National Chung Hsing University
Taichung, Taiwan, R.O.C
E-amil: arthurhan@ctu.edu.tw
於 2007 International Conference on Genetic and Evolutionary Methods所發表的論文
w of- is used to determine the setthat
consists of w and the blocks before w in
+. The last block x of+ is used to
determine the setthat consists of x and
the blocks after x in-. The last block y
of- is used to determine the setthat
consists of y and the blocks after y in+.
Lastly, the intersections,,,
will respectively decide the left,
right, top, bottom boundary candidate
sets as depicted in Fig. 1. If a block is on
the left (right, top or bottom) boundary,
it is in the left (right, top or bottom)
boundary candidate set but not vice
versa.
Fig. 1. (+,-)=(ecadfb,fcbead),= (fcbe),=
(ecadf),= (cef) is left boundary
candidate set.
Step 2. Form the real left, right, top, bottom
boundary set from the above boundary
candidate sets.
Step 3. If one of the blocks in the floorplan
violates the boundary constraint, it is
exchange with a similar block on the
boundary. The degree of similarity
between two blocks, A and B, is defined
by d = |||| BABA wwhh  , Any two blocks
are considered as similar if d is less than
the predefined threshold.
Step 4. There is a possibility that some constraints
are violated after Step 3. If so, a penalty
term will be added to the fitness function.
For example, if block z is restricted to be
located on the right boundary but it is not
so placed in the current floorplan, the
penalty term is the dead area caused by
locating z to the right boundary of the
current floorplan.
1) The Fitness Function
Our objective is to construct a feasible
floorplan P that minimizes the total area. Hence
the fitness function is defined to be the area and it
is the smaller the better.
2) Crossover Operators
There are three crossover operators designed
for our algorithm. We describe these three
crossover operators by illustration in the
following.
a) Crossover operator 1
Randomly choose a cut point in + of
parents and randomly choose to preserve either
the first or the second piece in the corresponding
child. The same elements in - will also be
preserved. The remaining part of the child
chromosome is obtained from the other parent
with the sequence order preserved. The crossover
operator 1 is illustrated in Fig. 2.
a b c d a c b d 0 1 0 1
b d a c c a b d 1 1 1 1
a b a b 0 1
b d b d 1 1
a b d c a c b d 0 1 1 1
b d a c a c b d 0 1 0 1
Fig. 2. Crossover operator 1.
b) Crossover operator 2
Randomly generate a sequence of length n
that consists of 0’s and 1’s. Use this sequence to 
decide which elements in + of parents are going
to be preserved in the corresponding child. The
same elements in - will also be preserved. The
remaining part of the child chromosome takes
from the other parent with the sequence order
preserved. The crossover operator 2 is illustrated
as Fig. 3.
c) Crossover operator 3
This crossover operator is a kind of mapping
as illustrated by the following example. Suppose
results, the GLS algorithm achieves the best
solutions for minimizing the area by using
reasonably larger computation time.
Table 1. Parameter values. (n: block number of circuit)
Parameter N T L1 L2 M
value 4.5n 5n 0.5N 6000 0.14n
Table 2. The comparison of the GLS algorithm with other methods on minimizing the area. (PE[1] and GPE[2] were run
on 300MHz PII, B*-tree[4] was run on 200MHz SUN Ultra I, TCG-S[5] was run on Sparc Ultra60, Lai et al.[8]
was run on 350MHz PII, GLS was run on 1.2GHz Intel PIII).
PE[1] GPE[2] GLSCircuit Constraint blocks {(L),(B),(R),(T)}
area time area time area time
{(3,11),(7),(1,9),(5)} 1.21 41.4 1.21 80.57 1.199/1.186 72
{(3,13),(7,17),(1,11),(5,15)} 1.25 46.61 1.21 113.12 1.202/1.185 96ami33
{(9,27),(15,19,32),(3,17,30),(6,24)} 1.28 50.02 1.23 137.74 1.207/1.194 133
{(4),(15,19),(14,22),(1)} 37.48 73.03 37.11 232.71 36.57/36.36 447
{(13),(15,19),(3,42),(1,9,35)} 38.2 69.77 37.4 189.56 36.73/36.27 436ami49
{(13,14,22),(15,19),(3,42),(1,9,35)} 39.56 65.52 37.24 270.61 37.00/36.63 864
Lai et al.[8] B*-tree[4] TCG-S[5] GLSCircuit (#|T|,#|B|,#|L|,#|R|)
area time area time area time area time
apte (1,1,1,1) 46.92/46.92 15 46.92 19 46.92 3 46.92/46.92 1
xerox (1,1,1,1) 20.96/20.4 19 19.91 22 19.977 33 19.88/19.83 10
hp (1,1,1,1) 9.4/9.24 23 9.27 38 9.158 26 9.157/9.11 5
ami33 (2,2,2,2) 1.22/1.21 287 1.20 144 1.190 238 1.202/1.186 100
ami49 (3,3,2,3) 37.54/36.84 584 36.91 324 36.765 584 36.80/36.44 628
