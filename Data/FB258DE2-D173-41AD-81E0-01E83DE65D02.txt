NSC Project Report  July 16, 2010 
2 
 
complete message in time. (2) A sudden breakdown of some peers or links won’t disrupt the 
reception of downstream peers. (3) Streaming data can be retrieved only by the peers subscribing to 
the ALM service, but not by the peers helping to provide the service. 
 
Figure 1 : Application Layer Multicast (ALM) System 
We solve the asymmetric connectivity issue by making full use of peers’ upstream bandwidth and 
increasing the total upstream bandwidth of the service. To reach the purpose we described, we use 
three approaches, which are described in the following paragraphs. 
(A) 19BInformation Dispersion 
Rabin’s Information Dispersal Algorithm (IDA) [4] is used to process the message generated from 
source peer and a message will be divided into several stripes. The peers can’t know any content 
without receiving sufficient number of stripes. There are two meanings. First, it means you can’t 
know any content of the message from one or few stripes. Therefore, if some peers have no authority 
to read the message, we only need to make sure not to let them receive too many different stripes of 
the message. Second, it means peers don’t need to receive whole stripes of a message and they can 
still know the complete message. By this characteristic, we can improve the fault tolerance and 
robustness of data transmission. 
(B) 20BMultiple Path Transport 
Each message transported from source peer that provide streaming data will be divided into several 
stripes [5]. In the multicasting tree formation, we not only construct one tree, we construct as many 
different trees as the number of stripes that one message is divided into. And each tree transmits 
different stripe of the message. This approach will lead to two advantages. First, each stripe will pass 
through different path. When one peer leaves or crashed, descendants of the peer will only lose one 
stripes and they still can receive other stripes. Furthermore, when a hop of the path is congested, it 
only influences on the reception of one stripe. Second, a stripe is much smaller than a message. The 
advantage is that a peer with low upstream bandwidth can also support several children because the 
data it needs to retransmit is small enough. Therefore, every peer can fully utilize their upstream 
bandwidth. 
(C) 21BHelper Recruitment 
Because the lack of upstream bandwidth, even we use multiple stripes approach to fully utilize every 
peer’s upstream bandwidth; it is still possible that new peers cannot find the parent in the tree that 
can provide them smooth streaming data. Therefore, the service will request some peers called helper 
that still have unnecessary bandwidth to join and share their bandwidth to increase the total upstream 
bandwidth of the service. With the aid of the helpers, the service can accept more peers and each peer 
can receive the streaming data smoothly. 
NSC Project Report  July 16, 2010 
4 
 
The first experiment aimed at finding the proper settings of Qp for the sake of obtaining good R-D 
performance. Two SVC layers are encoded with fixed Qp values for the enhancement-layer while the 
Qp value of the base layer sweeps from 0 to 51. Both CGS and spatial scalability were examined. 
Their R-D performances are shown in Figure 5 (a) and (b) respectively.  
These experiment results made clear that in order to achieve good R-D performance, an SVC layer 
should depend on another layer of inferior visual quality. This implies that proper Qp setting should 
ensure a monotonic decrease of distortion levels as the SVC layers are decoded following their 
dependence relations.  
(B) 23BProper Choices of Inter-layer Dependency 
In the second experiment, the correlation of inter-layer dependencies with both video contents and 
Qp settings was examined. Two test bitstreams (Mobile and Forman) consists of two spatial layers 
(QCIF and CIF), each of which in turn has three CGS layers (QCIF: A0, A1, A2; CIF: B0, B1, B2) 
and four temporal levels (3.75Hz – 30Hz). Each bitstream was encoded with the following four 
dependency settings: 
 Setting #1: (A0A1A2), (A2B0B1B2) 
 Setting #2: (A0A1A2), (A1B0B1B2)  
 Setting #3: (A0A1A2), (A0B0B1B2)  
 Setting #4: (A0A1A2), (A1B1B2) 
The R-D performance of each encoded bitstream is shown in Figure 6. For the sake of fair 
comparison, QCIF videos were enlarged to CIF format before their PSNR values were measured. 
Those measurements are displayed as A0’, A1’ and A2’ in the figure. 
 
Figure 5: R-D performance of (a) CGS and (b) spatially scalable bitstreams with different Qp values 
 
Figure 6: R-D performance of test sequences (a) Mobile and (b) Forman with different dependency settings 
NSC Project Report  July 16, 2010 
6 
 
In our experiments, the optimal extraction paths for 
three viewing devices of CIF@30Hz, CIF@15Hz, 
and QCIF@30Hz formats were constructed by 
exhaustive search for the four test sequences: Mobile, Forman, Akiyo and Football.  
It is worth noting that the optimal extraction paths for different viewing devices actually reveal 
regular predictable patterns for the same video. The optimal paths for the devices with lower spatial-
temporal resolutions are likely to be the projections or truncation of the ones for higher resolutions. 
III.3 10BSearch for Optimal/Near-Optimal Extraction Paths 
Our proposed method consists of two steps: (1) find out all extraction paths that suit for convex rate-
distortion curves; (2) pick out the one has the smallest area below the rate-distortion curve, which 
will be the target optimal extraction path.  
(A) 26BGraphical Tools  
We proposed two kinds of graphical tools for searching the optimal extraction path: RD Mesh and 
Trellis Diagram.  
In order to examine how many benefits will be acquired while receiving different parts of bitstreams 
at each refinement steps, we draw all the rate-distortion curves of extraction paths which fulfill the 
characteristics of successive refinement in the same graph, and name it as the RD Mesh for the SVC 
bitstream [Figure 10]. In this figure the horizontal axis denotes for bit rate, and the vertical axis 
denotes for distortion. Points in the grid represent different scalable layers that can be extracted, and 
those layers are marked as spatial layer L and temporal layer T. Line segments in the grid represents 
for refinement steps along spatial or temporal dimension, and their slopes indicate the rate-distortion 
performance of the corresponding extraction paths. 
Figure 9: Comparison between (1) ill-adapted and (2) well-
adapted SVC bitstreams 
Figure 8: Comparison of coding efficiency based on 
different inter-layer dependencies 
NSC Project Report  July 16, 2010 
8 
 
In addition to fulfilling Global Condition, there must be at least one Convex Segment in each single 
grid to ensure the existence of optimal extraction path for the SVC bitstream. If there is only one 
convex extraction path in every single grid in the Trellis Diagram represented by the SVC bitstream, 
the bitstream is called to satisfy Strong Local Conditions. This condition is met when one of time and 
space dimension in a single grid can dominate the local rate-distortion performance. 
The study found that for bitstreams that meet the Global Condition and Strong Local Conditions, 
since some extraction path styles do not exist due to the confliction of limitation of two conditions, 
convex sections in every grids show the same concentration trends. If we put the ones with better 
performance while receiving temporal scalable layer in the up left corner, put the ones with better 
performance while receiving spatial scalable layer in the bottom right corner, the line intersecting the 
two is the solution [Figure 12].  
In this ideal situation, the search strategy of best extraction path can be simplified as Steepest 
Descent, which at each of the extraction procedures takes the one with highest current rate-distortion 
performance. Therefore the optimal extraction path can be acquired without additional future 
information. This search strategy is the most streamlined algorithm considering complexity. The 
more scalable layer exists, the more savings on bitstream extraction and decoding complexity. In our 
experiments, on average the reduction of scalable layer decoding requirements is about half.  
 
Figure 12: he Trellis Diagram of the bitstream meets 
the Strong Local Conditions 
 
Figure 13: The Trellis Diagram of the bitstream meets 
the Weak Local Conditions 
(3) 33BWeak Local Conditions  
If the convex extraction paths are existed in every grid in the Trellis Diagram of the SVC bitstream, 
but for some regions there are two available path with convex-type Characteristics to choose since 
there is no dominance in neither space nor time dimension for the rate-distortion performance in 
single grid, the bitstream is called to satisfy Weak Local Conditions [Figure 13]. In this case, the grids 
with two convex extraction paths often gather at the intersecting line generated by the Strong Local 
Conditions. Also, the rate-distortion performances within the single grid are close. At this time 
although the Steepest Descent algorithm cannot guaranteed to find the best extraction path, it can 
also obtain the sub-optimal extraction path with the same or similar performance as brute force.  
(4) 34BViolation of Local Conditions  
Although the Global Condition may be designed to fulfill, local conditions might locally cause the 
situation that there is no convex extraction path in single grid that violates the local condition. That is 
due to effect of image characteristics, distortion measurement, or time and space interpolation. 
Violation of local conditions may not only make the best extraction path does not exist, but also 
mislead the Steepest Descent algorithm’s judgment, as a result optimal solution cannot be obtained 
Temporal (T)
Layer (L)
0                 1                  2                 3
 0
1
2
 3
),( TLS
)ˆ,ˆ( TLS
Temporal (T)
Layer (L)
0                 1                  2                 3
 0
1
2
 3
),( TLS
)ˆ,ˆ( TLS
NSC Project Report  July 16, 2010 
10 
 
We also propose transmission policy optimization algorithms. For a given bit rate, we can find the 
optimal transmission policy with minimum expected distortion through our optimization algorithms. 
IV.1 Rate-distortion Estimation Model 
In this research, our Rate-Distortion Estimation Model is based on Chou’s model. First at all, we 
consider two kinds of retransmission mechanism.  
 Receiver-driven Retransmission 
The retransmission is controlled by receiver. When receiver wants to receive a multimedia data 
unit, receiver will send a request message to sender ask for the data unit. If in next time slot, 
receiver dose not receive the data unit, receiver will decide whether resend a request message to 
sender or not depends on the transmission policy.   
 Receiver-driven Aggressive Retransmission 
 The different with Receiver-driven Retransmission is that sender will send the data unit 
continuously until receiver sends an ACK message which represents receiver received the data 
unit. 
 Rate-distortion Estimation 
Expected Distortion Value 
                                       
                                     
        
Expected Transmission Cost Value 
                                
                
         
IV.2 Transmission Policy Optimization 
 Optimization Algorithm 1 
We used Greedy algorithm to find next possible policies according to extraction path. And then 
compute the expected rate and distortion choose the optimal improvement from these policies as 
our next policy. Find out the next policy step by step. Finally, we can get the optimized policy. 
 Optimization Algorithm 2 
Algorithm 2 is also greedy but it did not take the extraction paths into account. When we tried to 
find the next policy, the algorithm will regard all possible policies as candidates even if some of 
them do not have any dependency with the data units that receiver has already received. Use this 
algorithm we find out another possible optimized solution. 
NSC Project Report  July 16, 2010 
12 
 
V. 4BOPTIMAL DEGREE DISTRIBUTION FOR SHORT-LENGTH LT CODES VIA CMA-ES 
An important step in the development of Rateless UEP Channel Codes is to design short data length 
Rateless Erasure Corrections Codes that exhibit good tradeoff between received symbol counts and 
decoding failure rates. Since the beginning of 2009, the research team has been trying to design these 
codes by searching for the optimal degree distribution of short data length LT codes using an 
evolutionary strategy based on covariance matrix adaptation (CMA-ES). 
(A) 14BAlgorithm Design 
In our initial experiments with the goal to find the optimal degree distribution we set the number of 
tags equal to 10. The tag values (e.g. 1, 2, 3, 4, 5, 7, 9) represent the number of input symbols 
connected to one output symbol and were assigned to numbers (mainly primes) between 1 and 200 
with dense distribution at the beginning. As the values of tags become higher the tag distribution is 
becoming more and more spars (according to empirical results this pattern seems to be the most 
suitable). In all our experiments were LT blocks consisting of 1000 symbols. 
(B) 15BOptimization Attributes and Parameter Adjustment 
We performed experiments with various optimization criteria and parameter values. Four 
experiments with the promising results are summarized in the table below. 
No Optimization (minimization) attribute   
1 Failure rate (number of undecoded symbols within block) of LT blocks, which after 
decoding had at least half of the symbols correct (500 out of 1000). 
0.05 
2 Failure rate (number of undecoded symbols within block) of all the LT blocks. 0.15 
3 Cumulative failure rate after taking into consideration following weights: 
Failure Rate <200 <200 <200 <200 >200 >200 >200 >200 
  0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 
Weight 1 2 3 4 6 7 8 10 
 
0.05, 0.1, 
0.15, 
0.2 
4 Cumulative failure rate after taking into consideration following weights: 
Failure Rate <200 <150 <100 <50 >200 >150 >100 >50 
  0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 
Weight 1 1 1 1 4 4 4 4 
 
0.05, 0.1, 
0.15, 
0.2 
(C) Preliminary Results 
Following diagrams show in the same vcertical order the failure rates of the four cases mentioned in 
the previous section.  
NSC Project Report  July 16, 2010 
14 
 
 
The degree distributions produced by the four experiments as well as that of the Soliton 
distribution are shown in the following diagram. 
 
0
200
400
600
800
1000
.05
0.25
0.45
0.65
0.85
O
cc
u
ra
n
ce
 C
o
u
n
t 
(o
ve
r 
1
0
0
0
 T
ri
al
s)
Failure 
Rates
1.0E-03
1.0E-02
1.0E-01
1.0E+00
0
.0
5
0
.0
7
0
.0
9
0
.1
1
0
.1
3
0
.1
5
0
.1
7
0
.1
9
Rates (ALL) Rates (<25%)
0.00
0.10
0.20
0.30
0.40
0.50
0.60
1 2 3 4 5 7 9 19 59 179
Failure Rate <0.5 Failure Rate ALL Arith Weights Diff Regions Soliton
 1 
國科會補助專題研究計畫項下赴國外(或大陸地區)出差或研習心得報告 
                                 日期：99(2010)年 7 月 21 日 
                                 
一、 國外(大陸)研究過程 
This project team began our collaboration with Prof. Robert S.Y. Li’s Network Coding Research Center at the 
Chinese University of Hong Kong (CUHK) since the summer of 2008. During the period of this project, Prof. 
John K. Zao (PI) visited the research center twice to discuss technical ideas and research plan with Prof. Li 
and his colleague, Prof. Raymond Young, and their students. Each visit lasted three days with an open lecture 
on the research being delivered in the 1
st
 or 2
nd
 day. Extensive discussions were conducted after the lecture. 
二、 研究成果 
The first visit in the early August of 2008 along with Prof. Wen-Hsiao Peng (Co-PI) and Prof. Chung-Hsuan 
Wang (Co-PI) was meant to establish basic understanding of the two project teams. Prof. Zao, Prof. Peng and 
Prof. Wang delivered lectures on heterogeneous multimedia multicasting, H.264 SVC video compression 
standard and punctured convolutional codes with unequal erasure protection (UEP) capability respectively on 
the first day. Discussions on possible ways to develop Network Codes with Unequal Erasure Protection (UEP) 
capability and employ these codes in heterogeneous multimedia multicasting were held on 2
nd
 and 3
rd
 days. A 
road map for collaboration was drawn during this visit. 
The second visit at the end of 2009 was a trip to launch the exchange of researchers between the two project 
teams. Specifically, a PhD candidate from our project team, Mr. Kuo-Kuang Yen (顏國光), began his two 
three-month research internship at CUHK immediately after this visit. In this visit, we proposed three concrete 
approaches to develop Randomized Linear Network Codes (RLNC) with Unequal Erasure Protection (UEP) 
capability and started the work on the first two approaches. The results of this research effort will be pu-
blished by the end of this year. 
三、 建議 
I sincerely hope that the procedures to establish research collaboration with the universities in Hong Kong 
will be greatly simplified in the near future. 
計畫編號 NSC 97-2221-E-009-076 
計畫名稱 
兼具高傳輸效率與容錯韌力之異質多層次多媒體群播服務 
Transport Efficient and Loss Resilient Heterogeneous Multilayer 
Multimedia Multicasting 
出國人員
姓名 
邵家健 
服務機構
及職稱 
國立交通大學 資訊工程學系(所) 
出國時間 2008/7/30 – 2008/8/2 
2009/11/2 – 2009/11/4 
出國地點 香港 (Hong Kong) 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
Real-time video multicasting over public wired and wireless Internet is widely 
acclaimed to produce the next wave of Internet “killer apps＂. This project, along 
with its predecessor and successors, aimed at developing the key technology for 
bandwidth efficient and error resilient multicasting applications using the 
emerging H.264/SVC video compression standard. 
