2 
 
應用於 Argo海洋資訊的資源認知行動知識網格之設計與研究 
計畫主持人：張玉山 國立台北大學資訊工程系 
計畫參與人員：陳宏志、洪永栓、鄭翔太、賴宣任 
摘要 
在本研究中我們首先利用資料網格之
技術及資料採礦技術建構一個應用於 ARGO 
的知識網格，這個知識網格可以提供 ARGO 
相關的知識給 ARGO 的會員國及關心海洋資
訊的使用者。接者我們考量 ARGO 為無線及
無線設備，具有行動裝置固有的特性及問
題，將利用行動代理人、行動計算及行動資
料網格的技術將整合知識網格，開發行動知
識網格，此行動知識網格必需考量行動裝置
的資源，以決定資料採礦的演算法最佳的執
行位置及策略，提高行動知識網格的存活時
間、系統效能及精確性。最後我們將經由系
統效能的分析、測試及調整，建構一個完整
的 ARGO 知識網格平台，並將此平台應用於
其他領域，例如商業、工業及其他科學領
域。 
關鍵詞: 網格, 行動網格, Argo, 資源認
知, 海洋資訊 
Abstract 
In the research, we first apply data grid 
technologies and data mining technologies to 
construct an Argo knowledge grid 
environment This Argo knowledge grid 
environment can provide oceans information 
and knowledge to the members of Argo and 
devotee of oceans. Next, we will consider the 
characteristics of wireless device and integrate 
the mobile agent, mobile computing and 
mobile data grid technologies to adjust Argo 
knowledge grid as a mobile version. In the 
version, we will evaluate the resource of 
mobile (Argo) device for making decision of 
the policy and the place where the data mining 
algorithms running is to enhance the survival 
rate, efficiency, and effective of mobile 
knowledge grid. And finally, we will analyze, 
test and turn the performance of overall 
system, and then apply the Argo mobile 
knowledge grid environment and platform to 
other fields, such as business, industry, and 
sciences. 
Keywords: Grid Computing, Mobile Grid, 
ARGO, Resource Awareness,Ocean Data 
一、 前言 
目前全世界愈來愈關心全球氣候的改
變及對區域性的影響，海水的準位也以每年
3mm的高度上昇，北極海冰含蓋的範圍漸漸
減小，高緯度的區域快速受暖化影響，極度
的氣候變遷造成某些生物死亡，這些是由長
期的氣候改變及自然的變化所造成的影
響。ARGO1 計畫是由全世界 23 個國家所組
成的一個跨國計畫，主要是以一即時海洋浮
動觀測及研究陣列，使用自動的浮標方式收
集沒有結冰的海洋下温度、鹽分及其他相關
的資料，以了解海洋之生態及環境變化。
ARGO 裝置將固定時間浮出水面，透過衛星
傳送所收集到的資料送回到監控中心，以便
進行資料分析。 
另外, 網格計算(Grid Computing)[10, 
11]在1990年代被提出，主要是在科學及工
程應用上的分散式計算架構上，現今已經逐
漸成為下一世代網路的主要應用，它可以讓
我們分享及以合作的方式共用異質及地理
分散的資源。網格技術中，知識網格是一個
並行及分散軟體架構，它整合資料採礦技術
及網格技術。在知識網格的架構中，資料採
礦的工具是與一般及資料網格機制及服務
整合在一起。因此知識網格可以被建立來在
很大型的資料集上執行資料採礦，來執行科
學的發現、改善工業的程序及組織的模型、
以及在商業上未被發現的價值。目前的知識
網格及資料網格上的資料採礦技術可以發
現，目前的知識網格及資料採礦技術所存在
的問題，我們可以歸納如下： 
1. 目前並無海洋相關的知識網格 
2. 目前的知識網格技術都應用於有線的環
境中 
4 
 
4.1 建立資源評估模式 
在行動網格中每一個行動節點的資源
都是有限的，如何評估行動網格節點可以執
行的何種工作，是一個重要的課題，在本計
劃中我們提出了行動網格上節點的時間評
估模式(Time Estimation Model)及能量評
估模式(Energy Estimation Model)，來評
估行動節點所需要的時間及使用的能量。在
每一種模式中，我們針對三種 cases來探討
可能所需要的時間及能源。另外, 我們設計
一個 Saving factor的指標供行動格網伺服
器使用，行動格網伺服器可以依據三種中的
那一種具有最佳的時間及能量消耗來決定
節點應該採有那一種 case，以便獲得較佳
的效能及較低的能量消耗。決定的演算法如
下: 
1. /*Dispatching Algorithm*/ 
2. Get Mobile Retrieving Agent; 
3. Get all candidate nodes from Execution Plan Agent; 
4. Get the list of candidate nodes; 
5. For i=1 to n { 
6.   Calculate the TSM(i), TNM(i), ESM(i), ENM(i); 
7.   SFT(i)=TSM(i)/TNM(i);  
8.   SFE(i)=ESM(i)/ENM(i);  
9.   If (SFE(i)>=δ or (SFT(i)*SFE(i))>=1.5) { 
10.       Dispatch a Mobile Retrieving Agent to mobile 
grid i for retrieving; 
11.   } 
12.  Else { 
13.     Send a request to mobile grid i for getting raw data; 
14. } 
15. } 
圖一: Raker演算法 
 
詳細請參考[4]，結果顯示我們提出的
方法有不錯的結果，如下圖，case 4 是我
們提出的方法，系統的 availability 比其
他三種都好。 
 
圖二: RAKER的系統可用性評估結果 
 
4.2 設計行動網格上資源認知的資料複本
及共同配置方式 
 在行動資料網格經常需要資料複本的
傳輸，如何在行動網格中選擇能源較佳的節
點來傳輸複本是一個重要的問題，在此我們
參考資料網格中經常被提及的共同配置及
方式，提出一個行動網格上資源認知的資料
複本及共同配置方式，其演算法詳如[7]，
其模擬結果如圖三及圖四所示，結困顯示所
提出的 RARS 方法比其他的方法不論在效能
上及節點存活率上都有較好的結果。 
 
圖三:RARS效能模擬結果 
 
圖四: RARS的節點存活率 
 
4.3 行動網格上行動代理人及本體論為基
礎的資訊檢索架構 
建構一個資源有限的行動網格上的自動
資訊檢索及擷取架構在行動知識網格中一
個重要的議題，為了克服資源有限的問題，
行動網格伺服器必需可以動態的分析及決
定資訊或知識擷取之策略，何時要將資訊擷
取代理人送到行動網格節點，何時要從行動
網格節點擷取資料到網格伺服器執行資料
檢索或知識擷取之工作。在此我們利用行動
6 
 
 
 
圖十: 不同 granularity時的效能分析 
 
4.5 Argo海洋 portal的建立 
 另一個是利用上述所建構的 metadata
分類方式建構一個資訊檢索架構，以便使用
者可以利用快速查詢 argo的海洋資訊，如
圖十一所示。這個架構目前只是一個雛形，
並未全部建構完成，我們也利用這個架構與
現有的系統 GODAE來做一比較，如圖十二所
示。從效能分析圖中可以發現我們的系統在
找尋資料上確實快了很多。這個部份我們己
經整理投稿到今年的全國計算機會議中。 
 
圖十一: ARGO海洋資訊系統 
0
0.5
1
1.5
2
2.5
3
3.5
30 60 90 120
number of days
qu
er
y 
tim
e(
se
co
nd
)
GODAE
OUR SYSTEM
 
圖十二：系統的效能分析 
 
五、 結果與討論 
由以上今年五個主要的方向及成果我
們可以發現，前面三者是以行動網格計算為
主的研究，主要是建構行動網格中資源認知
的相關議題，主要是因為在行動網格中行動
節點的資源是很有限的，無法像一般的網格
計算一樣可以隨意的使用，因此如何找到最
適當的行動網格節點來執行所要的工作是
重要的。另外，如何自動的在行動網格環境
中找到所要的知識或資料，也是一個重要的
議題，在這個計畫中我們亦有相關的成果。 
後二者則是針對 ARGO 海洋資料做深入
的研究，我們除了找到一個可以快速找尋
ARGO 海洋資料的方法，並且利用這個方法
建構一個 ARGO 海洋資料的網站，以便讓使
用者可以快速的找尋相關的資料，並可以進
而分析這些珍貴的海洋資料。另外從上述的
結果，我們都可以發現這些研究都有不錯的
成果。 
 
六、 成果自評 
本成果自評部份，我們將分三個部份來
說明，如下： 
以計畫產出而言，本計畫中我們已經獲
得一些成果，如第七節的參考文獻中的 1~9
可以發現，其中有二篇是已經被 SCIE 等級
的國際期刊所接收刊登。另外，共有六篇國
際研討會接受並發表論文，有一篇是國內研
討會論文。這些研討會論文中，也增加並整
理成期刊等級論文，有一篇已經投稿，另外
一篇也已經撰寫完畢，近期將投稿。另外, 
還有多篇正整理中，準備投稿。可見本計畫
論文產出而言，有相當不錯的成果。 
從人材培訓而言，本年度共有二位碩士
班學生因本計畫之補助得以二年順利畢
業，還有二位目前還在持續進行本計畫之後
續研究。而且由於本計畫中除了理論的推導
外，尚有系統的實作，學生得以學習到新的
技術，並從中獲得相關的系統開發經驗，確
實為國家社會培訓所需的人材。 
從成果與計畫目標的關聯度而言，前面
三個方向都是行動格網中資源認知相關的
研究及成果，後二者則是 ARGO 海洋資料相
關的研究成果，這些成困可以說完全與計畫
國科會補助出席國際學術會議心得報告 
 
計畫編號 NSC 97－2221－E－305－004－ 
計畫名稱 應用於 Argo 海洋資訊的資源認知行動知識網格之
設計與研究 
出國人員
姓名 
服務機關
及職稱 
張玉山 
國立台北大學資訊工程系 
會議時間
地點 
Dong Hoi, Vietnam, 1-3 April 2009, 
會議名稱 第一屆亞洲智慧型資訊及資料庫系統研討會 
1st Asian Conference on Intelligent Information and Database Systems 
(ACIIDS09) 
發表論文
題目 
RAKER: Resource-Aware Knowledge Extraction aRchitecture on 
Mobile Grid, 
 
一、 參加會議經過 
本會議為第一屆亞洲智慧型資訊及資料庫系統研討會，雖然是亞洲地區的研討會，但
參與者除亞洲地區國家(中華民國、越南、韓國、中國大陸、日本、澳洲…等)外，亦有很
多來自於歐美各國。本次會議共有投稿者 230餘篇，接受 83篇，接受率為 35%，其中來自
於歐美各國的論文共有 29篇，可見本次會議之學術水準相當高。 
本會議舉辦地點位於越南中部的一個城市-同合市，由於越南的交通並不是很發達，同
合市每週只有二班飛機，因此大會建議我們搭飛機到順化，再由大會的接駁車接到同合，
由於路途遙遠，到順化到同合大約要 5個小時。 
大部份出席者都是 3月 31日到同合市，4 月 1日大會開始有一個 opening，同合大學
的全體師生都出席該會，opening之後有一個 keynotes，由 Conference Chair, N.T. Nguyen 
教授主持, Dr. Robert J. Howlett主講，題目是:Smart Sustainability: The link between 
intelligent systems and sustainability。接下來是三個 parallel 的 sessions，本人
亦接受大會邀請主持了其中一個 session，session的主題是 Technologies for Autonomous 
Systems and Implementation，這個 session共有四篇優秀的論文發表。 
本人所發表的論文被排在 4月 1日下午的 Session 3C: Technologies for Autonomous 
Systems and Implementation，發表了由本計畫的一個重要結果。另外，本人亦參加了幾
場由大會安排的 keynotes，接收到很多新的研究方向及成果，而且認識了多位這方面領域
的學者，包括中國大陸的金海教授、越南同合大學的主辦人 Huynh Phan Nguyen 教授，
以及台灣的多位相關的學者，可說收獲良多。大會總共 2 天半的時間，最後半天有一個
tour，然後散會。 
 
二、 與會心得 
本次除了發表論文外，亦受大會邀請主持一個 session，該 session 名稱
為 ”Technologies for Autonomous Systems and Implementation”，這個 session共有
RAKER: Resource-Aware Knowledge Extraction aRchitecture on Mobile
Grid
Yue-Shan Chang
Dept. of CSIE,
National Taipei U.,
Taiwan, R.O.C
ysc@mail.ntpu.edu.tw
Pei-Chun Shih
Inst. of Comm. Eng.,
National Taipei U.,
Taiwan, R.O.C.
sapren528@yahoo.com.tw
Tong-Ying Juang
Dept. of CSIE,
National Taipei U.,
Taiwan, R.O.C
juang@mail.ntpu.edu.tw
Abstract
In this paper, we, based on mobile agent
technology, propose a Resource-Aware Knowledge
Extraction aRchitecture on mobile grid, named
RAKER. RAKER can dynamically determine the
processing and policy for achieving high
performance and high availability of knowledge
extracting based on our previous proposed Resource
Estimation Model. On the RAKER, users can
extract information or knowledge in efficient,
effective and transparent way that kept on the mobile
grid without caring about the energy consumption
that is most important issue in mobile computing. We
show the implementation and an example to
demonstrate the use of RAKER. In addition, we also
measure the latency and the energy consumption and
simulate the system availability to show that the
performance of RAKER.
1. Introduction
Wireless grid [1] and mobile grid [13] extends the
capability of grid computing that connects and shares
existing resources that is distributed over wireless
networks. Some researches related to mobile data
grid and their applications had been initiated, such as
Mobile Data Grid in Telemedicine initiated by Intel’s 
Digital Health Group and Akogrimo funded by the
EC(The Council of the European Union) [2, 3] for
acquiring useful information.
In some applications, mobile grid usually
continues to collect data during a long time. For
example, the salesman of a real estate company
usually stores some house objects in his mobile grid
node (device) for selling. A customer received by
another salesman needs a special object which the
received salesman does not have one. The received
This work was supported by National Science Council of the
Taiwan, Republic of China under Grant No.
NSC97-2221-E-305-004
salesman can acquire the mobile grid immediately to
know which salesman hold the special object.
Another example is that there are increasingly mobile
users who had kept many files of music in mobile
device and then joined the mobile grid community.
How to acquire useful information from the mobile
grid community, such as, “Who is the most popular
singer in the Asia in 2008?”.
Sharing the large number of data with others in
wireless environment for acquiring useful
information is not an easy work. In addition, the
mobile devices in wireless environment are with
some inherent characteristics: limited energy, lower
and variable bandwidth, and intermittent
connection [4]. These will cause perplexity while
mobile grid nodes in collaboration with others.
Therefore, extracting information or discovering
knowledge from mobile grids is increasingly an
important issue. Obviously, one of most important
work of extracting information or knowledge from
mobile data grid is to improve the efficiency,
availability and flexibility.
Most of knowledge discovery projects in grid
community [7-9] were focused the performance
improving only. Wang et al. [9] proposed a mobile
agent based architecture for service-oriented
knowledge grid to implement KG-services by
utilizing mobile agent technology. Luo et al. [8]
proposed an Agent Grid model. It connects
heterogeneous resources and provides a uniform
service interface for data mining agents to access and
process data. In the Agent Grid, a data mining tool
was integrated with generic and data grid
mechanisms and services. Thus the Agent Grid can
be exploited to perform data mining on very large
data sets available over grids, to make scientific
discoveries, improve industrial processes and
organization models, and uncover valuable business
information.
Krishnaswamy et al. [7] proposed a hybrid
model that integrates client-server and mobile
agent model for optimizing response time since
studies had shown that such a combination improves
Resource Estimation Model presented in [10].
The Resource Management Module consists of
Information Service Agent (ISA), Analyzing Agent
(AA), and Metadata Repository. We will present the
function of these agents as following. ISA is
responsible for collecting resource metadata of
mobile grid and monitoring status of mobile grid
nodes. The resource involves some instantaneous
information, such as CPU loading, remaining energy,
bandwidth and performance of processor etc., and
will be kept into the Metadata Repository. In
addition, ISA will also periodically monitor and
inquire the instantaneous information of mobile grid
node when a request sent from AA to get the
information of mobile grid nodes. In other words, the
ISA need to keep the instantaneous information of
mobile grid nodes into the Metadata Repository for
serving the request from AA or other agents.
AA can analyze the resource of mobile grid by
inquiring metadata in the ISA to decide the retrieving
policy according to Resource Estimation Model
(REM) [10]. The REM involves a Time Estimation
Model (TEM) and an Energy Estimation Model
(EEM). The TEM is aiming to estimate the latency of
knowledge discovering while the EEM estimating the
energy consumption. Here we will roughly depict
these models. Detailed please refer [10]. AA will
apply TEM to estimate the latency of knowledge
discovering or data retrieving from mobile grid nodes.
We can divide the scenario into three cases as
following.
1. Knowledge discovering run on grid server, so
that server need to retrieve data from mobile
grid without data compression.
2. Knowledge discovering run on grid server, so
that server need to retrieve data from mobile
grid with data compression.
3. Knowledge discovering run on the mobile grids,
so that server need to dispatch a MRA to mobile
grid and then the MRA responds the discovered
knowledge to server.
The AA will calculate the latency for these three
cases for determining the policy of knowledge
discovering. Because the resource of mobile grid
nodes, such as bandwidth, data size, and CPU
loading, are frequently varying from time to time, the
latency are also varying. AA can analyze the best case
of latency at the moment by calculating the time
consumption. Similarly, AA can also apply EEM to
estimate the energy consumption of knowledge
discovering or data retrieving from mobile grid nodes
for these three cases. The analyzed result will be sent
to the Execution Plan Agent (EPA) for planning the
knowledge extracting process. Before stating the
action of EPA, here we introduce a term, Saving
Factor (SF). The SF can be classified into SFT
(Saving Factor of Time) and STE (Saving Factor of
Energy Consumption), and be defined as following.
The detailed also please refer [10].
Definition 1: Saving Factor of Time (SFT) is the
factor of minimum mining time on the server (TSM)
compared to mining time on mobile grid (TNM). SFT =
TSM/TNM
Definition 2: Saving Factor of Energy
Consumption (SFE) is the factor of minimum energy
consumption of mobile node that run mining on the
server (ESM) compared to mining energy consumption
of mobile node that run mining on mobile grid (ENM).
SFE = ESM/ENM
The Saving Factor means that how many times of
resources including time and energy consumption
can be saved compared the case that data mining run
on the server with the case that data mining run on
mobile grid. It is larger SF more resource can be
saved.
The knowledge extracting policy is done by the
EPA according to the analyzed result. EPA will
decide the mobile nodes where the MRA dispatched
is. If knowledge extracting run on the mobile grid
nodes is superior to run on grid server in term of the
efficiency and energy consumption, the EPA will ask
for the Dispatching Agent (DA) to dispatch a MRA to
associated mobile grid nodes; otherwise DA will send
a request to those mobile grid nodes for getting data
from mobile grid nodes to grid server. The
dispatching decision algorithm is shown in Figure 2.
DA dispatches a MRA to mobile grid nodes according
to the time-energy tradeoff matrices, if it is satisfied
certain conditions: CPU loading<60%, remaining
energy > 20%, SFE(i) >=1, and SFT(i) * SFE(i) >= 1.5,
DA will dispatch a MRA to mobile grid node i. The
reason to setting the tradeoff, SFT(i) * SFE(i), larger
than 1.5 is in order to obtain a saving warranty. For
example, if the SFE = 1.5 and the SFT = 0.7, that
mean that dispatch a MRA to mobile grid will earn
the 50% energy consumption, but spend 30% latency.
We hope that the RAKER architecture can obtain not
only latency saving but also energy consumption
saving, or obtain an enough saving warranty.
The Knowledge Collection Module consists of
Knowledge Collection Agent (KCA) and, somehow,
MRA. If the DA sends a request to get original data
from mobile grid node to grid server, it will also
dispatch a MRA to the Knowledge Collection Module
for extracting knowledge from those original data.
The KCA is responsible for collecting the original
data and mined result from mobile grid nodes. KCA
merges two kinds of mined result into one and send
the final merged result to UA.
grid nodes have much music-related data to be mined.
Any mobile users joining into the community can
query information or knowledge about music-related
information or knowledge. For example, “Who is the
most popular singer in the Asia in 2008?”The request
is simplified into a few terms to be query. The
sequences of operations in the example are same as the
Figure 1.
Figure 3 shows a mobile user using a mobile agent
to input a request. After UA receive the request, it
starts to get a MRA. Then UA informs EPA at
MG-Server to start making an execution plan for
dispatching MRA. Figure 4 shows that the DA clones a
MRA to be dispatched to associated mobile grid nodes.
Figure 5 shows the final result merged by KCA and
responded to UA.
4. Measurement result
Due to limited mobile grid nodes, the latency and
system availability of RAKER system are simulated to
demonstrate the performance. The parameters used in
simulation are gotten from three kind of mobile
devices that are HP iPAQ 512 Mobile Phone,
FUJITSU LifeBook-U1010 UMPC (UMPC-FU), and
Kohjinsha SH8WP12ATW UMPC (UMPC-KO)
respectively. The comparisons we made are based on
four cases which are Case 1~3 mentioned in section
2-2 and Case 4 which is utilizing the resource-aware
approach used in the RAKER to dynamically
determine the place of knowledge discovering.
The first experiment we made is to compare the
latency between all of cases. The comparison in
latency between various cases is shown in Table 1.
Each mobile device gives one job to be executed and
the data size of each mobile device is 1 MBytes. In the
Case4, the lower computing power of mobile device,
such as Mobile Phone, will adopt the Case 3 while the
high computing power mobile device, such as UMPC,
adopting the Case 2 for reducing the latency.
Based on the TEM and dispatching decision
algorithm, we simulate the Case 1~4 and compare their
efficiency. The total latency of considerable job
submitted is shown in Figure 6, we find that the Case 1
> Case 2 > Case 4 > Case 3. The latency in Case 1,
Case 2, and Case 4 will rise with the number of nodes
increasing while the Case 3 is keeping almost constant.
It is obvious that the Case 3 is more efficient than other
cases because all knowledge discovering process is run
on mobile grid nodes while other case may run on the
server. The reason is that the Case 1 and Case 2 need to
collect data from all of mobile devices before
Figure 4. DA clones MRA to be dispatched to mobile
grid nodes
Table 2. Energy consumption of various cases
on each device (%/MB)
Device
Case
Mobile
phone-HP
UMPC
-FU
UMPC
-KO
Case1 1.6376% 0.0406% 0.1218%
Case2 0.5156% 0.0146% 0.0407%
Case3 0.1917% 0.2203% 0.4157%
Case4 0.1917% 0.0146% 0.0407%
Figure 6. Latency (10 nodes)
Table 1. Latency of various cases on three devices
(sec)
Case
Device Mobile
phone-HP
UMPC-
FU
UMPC-
KO
Case1 590.43 2.25 8.32
Case2 179.22 0.86 2.80
Case3 86.37 16.41 32.85
Case4 86.37 0.86 2.80
Figure 5. Mobile-User got the retrieving result
Figure 3. Mobile user send retrieving request to UA
