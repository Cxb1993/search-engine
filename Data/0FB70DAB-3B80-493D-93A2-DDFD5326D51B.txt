對於視訊內容的定義上，不再以畫格為基本的單位，而是
將畫格之中的資料以物件(Video Object Plan)的方式加以
描述，在描述的內容細項上則是以各式各樣的低階描述子
定義之，本論文在實做的過程中，也將利用各種MPEG系
列定義的特徵值加以實現我們的目標。影片內容的搜尋及
索引之管理機制是未來多媒體發展的趨勢，可以讓使用者
利用詞彙抑或是其他的描述方式來找尋到他想要的資
訊，正是資訊工程中多媒體相關領域的重要挑戰；在我們
的研究構想中，多媒體影片中情節與故事(High- level 
Semantic)如果可以以不同條件的描述子(Descriptor)及加
上其本身低階的特徵(Low level feature)來找到其相關性，
就像DNA中的特殊特徵可以找到某個人的遠親近鄰，未
來多媒體的世界亦應能嘗試解決這個Semantic Gap；基於
處理低階的色彩 (Color)，動量 (Movement)，換鏡 (Shot 
Changing)…為基礎，從其中定義出相似類別的媒體群
組，並進ㄧ步嘗試使其貼近人類感官知覺的意涵，龐大多
媒體的儲存資料將不會是沉重的管理負擔，進而可成為易
於存取的知識。 
 
 
Figure 1:  Video Content Management System Architecture  
本論文研究方法包含三個部分，分別為分鏡本體論
定 義 (Shot Ontology Definition) 、 特 徵 擷 取 (Feature 
Extraction)，以及影片索引(Video Indexing)。在分鏡本體
論定義的部份，我們將利用觀察四部籃球影片得到的結
果，針對換鏡時機、換鏡順序、換鏡時間、得分板的變
化、主要顏色、以及動量的統計分別對於球場上的事件
作統計及歸納，藉以得到分鏡本體論的時間軸描述子
(Temporal descriptors)。在特徵擷取部份，我們必需先利
用直方圖(Histogram)分量統計法將一部影片切割成不同
的分鏡(Shot)，接著利用投票策略(Voting scheme)將時間
序列最長的分鏡中的主要顏色抓取出來將之定義為球場
顏色，並且抓取時間序列較短的分鏡，利用有效的膚色偵
測方法將膚色區域抓取，最後利用球場顏色與膚色比例來
區分出分鏡的類別；而在影片事件的偵測上我們以得分事
件為探勘重點，因此我們以偵測得分板字幕的變化來偵測
出何時發生得分的事件，在得分板字幕的變化偵測上，我
們利用長分鏡與特寫分鏡作影像邊緣的相減，並找出得分
板區塊的座標，最後利用動量統計的方式偵測出得分板改
變的時間。 
在最後的影片索引階段，我們將特徵擷取之後得到的分鏡
內容，以及將事件的時間標注於影片的時間軸上，之後便
可以透過本系統所開發之影片事件檢索系統將籃球影片
中的得分事件、長分鏡、以及特寫分鏡抓取出來。本論文
的貢獻有以下幾點。基於本體論的分鏡描述，使得本系統
具有可擴張性。提出一個新的分鏡分類方法，不需經過類
神經訓練或者畫面的ROI切割，即可適用於籃球影片的分
鏡分類。對於籃球影片中的得分事件可直接檢索，對於時
間與人力的節省有著很大的幫助。針對籃球影片的內容索
引，並且開發方便性的檢索軟體，可供使用者進行事件檢
索行為。 
 
2 The Video Indexing 
 
Figure 2: Shot Ontology 
分鏡本體論 (Shot Ontology)運動節目與一般的電視
節目最大不同的地方在於運動節目並無所謂的編劇，比賽
的過程及結果是不可預測的，正是因為這種不可預測性，
因而吸引了許多熱愛各式運動的球迷；「比賽」這個名詞
在英文的名稱上稱之為「Game」，而只要是Game就一定
有遊戲規則(Game Rule)，因此也會有許多的術語來輔助
比賽過程中發生事件的定義，例如:籃球比賽中是以把球
投入對方的籃框為得分要件，最後決定勝負的關鍵是累積
整場比賽的得分，多的一方為勝利者；在得分的區分上，
可分為許多種不同的方式，兩分球、三分球、罰球…等等；
我們把籃球比賽的各種術語，依照比賽過程以序列圖表
示，則可以推化為以下的過程如圖3-1，由運球(Dribble)、
傳球(Pass)、三分球(Three Pointer)再到得分(Goal)的一連
串序列，以下的序列狀態只是可能發生的狀況之
ㄧ。 
 
Figure 3:  game sequences 
在運動節目中，導播會依據比賽的過程來變換分鏡的拍攝
方法，例如:在足球場上如果有某一個隊伍在一連串的抄
截、快攻之後把球踢進對方的球門，則導播則會把得分分
鏡，觀眾歡呼，球員互相擁抱…等等一連串換鏡的過程組
合成為一個精采的片斷，因此我們認為換鏡的過程是一種
語意的表現，在本論文中，我們把分鏡的種類區分為長分
鏡與特寫分鏡，長分鏡通常是拍攝比賽的內容，特寫分鏡
Shot Ontology 
Content-Change Motion Shot Type Temporal Relation
{Yes, No} {Low, High} {Long,  
Close Up} 
Goal Event With
{Meets, Before, 
Completes, 
Starts 
…..} 
…… 
 
 
Foul Free throw Rebounds Pass
Step1. 本身分鏡狀態與下一個分鏡狀態相同，則可以簡化
為同一序列，但事件 必須保留。 
Step2. 重複Step1至全部序列化簡完畢。 
Step3. 擴大化簡單位為兩個序列，如本身單位序列與下一
個序列的分鏡狀態相同，則可以化簡為同一個單位序列，
但事件必須保留。 
Step4. 重複Step3至全部序列化簡完畢。 
例如發生特寫分鏡之後接下來也是特寫分鏡，則可把
此序列化簡為同一序列，化簡全部序列之後，我們可以得
到 Figure 8 之 簡 化 序 列 圖 。
 
Figure8:  分鏡類型及事件序列 
簡化序列的過程可以讓我們更加了解籃球節目的分
鏡事件、以及分鏡類別的關係；時間上的事件偵測還可包
含濾除小時段的分鏡，因為在我們統計之中發現有許多的
分鏡時間相當短，如果可以不考慮這些小時段的分鏡，則
對於整個系統的準確度將會有很大的幫助。 
分鏡本體論為籃球比賽的索引內涵，在上一節中我們利用
各項低階特徵來描述每一個分鏡描述子，分鏡描述子在實
際運作上我們會給予不同的權重，在比值上分鏡分類以及
得分板變化的權重我們給予最大值，這是因為從分鏡本體
論的定義上長分鏡與特寫分鏡可以區分整場比賽的片段
為比賽片段及非比賽片段，A.Ekin提出的Play-Break影片
偵測法已經證實透過比賽及非比賽片段的分類可以將兩
個小時的球賽精簡為一小時，而本體論應用階層所定義的
各種術語也都是發生在比賽片段之中，因此分鏡分類的權
重值我們給予最大，而得分板變化的事件則是可以直接指
定到某個分鏡的內容，因此在權重的比值上我們也給予最
大值；將各項特徵值標記於影片的時間軸，則可以利用分
鏡本體論的知識，以關聯式搜尋將球賽事件取出，Figure9
為本系統之分鏡索引流程圖，以下將分別介紹流程圖中的
各區塊於系統中的作用以及先後秩序的關係。Step1: 分鏡
偵測為分鏡索引的第一步驟，此步驟可將一部影片的所有
分鏡切割，在分鏡的判斷上，除了利用色彩直方圖(Color 
Histogram)將不同的分鏡分割，在分鏡點的判斷上，距離
過短的畫格數我們將它視同一分鏡，將各分鏡分別切割偵
測之後，最後將每一個分鏡的開始畫格、結束畫格、以及
分鏡總畫格數紀錄於資料庫之中。Step2: 取得所有分鏡的
總畫格數之後，接著對所有分鏡作大小排序，並取出時間
長度最常的分鏡，以此分鏡當作球場顏色範本，取時間長
度最常的分鏡是因為在一場球賽中除了正常的比賽鏡頭
外，還包含了特寫鏡頭，場邊花絮，罰球..等等，我們觀
察的結果，發現正常比賽的畫面長度會遠大於其他的畫
面，而比賽畫面中，又以球場的顏色佔整個畫面的比值最
大；因此我們從所有分鏡中挑選時間最長的分鏡當作我們
的球場顏色範本片段(Court Color Sample)，如Figure10球
場顏色範本示意圖。 
 
 
Figure 9:  Shot Indexing Process 
 
 
 
 
 
 
 
 
Figure10:以最長時間片段當作球場顏色範本 
 
 
 
Hue statistics
0
5000
10000
15000
-18
0 -49 -35 -21 -7 7 21 36 57 91 10
5
11
9
13
3
14
7
16
1
17
6
Hue Value
Vote
 
Figure 11: Hue數值投票結果，最高值為146 
Intensity Statistics
0
1000
2000
3000
0 19 35 51 67 83 99 11
5
13
1
14
7
16
3
17
9
19
5
21
1
22
7
24
4
Intensity Value
Vote
 
Figure 12:  Intensity數值投票結果，最高值為164 
統計主要顏色的方法我們使用投票法則，顧名思義，投
票法則的意義為將畫格中所有的Hue及Intensity作統計，
經由RGB色彩空間轉換為HSI色彩空間之後，Hue可以區
分為360個色階(如Figure 11)，如果畫格中某一個區域的顏
色相同，該區域的Hue色階在理論上也是相同的，差異的
部份則為Intensity的程度，如果整個畫格中某個區域顏色
的比例為最高，則統計完畫格之後必會得到一個最高數目
的Hue以及Intensity值，我們輸入一張208*272維度的畫格
cmeO cmeL 
ful|ft|stop|gol 
ind|ft 
ft|ind|stop 
Input Video 
Shot 
Detection 
Shot Type 
Classification
SB Change 
Detection 
Motion 
Statistics 
Mark Shot 
Number  
Get Shot Number 
Update Shot Type 
Get Shot Number 
Update SB Event to Shot 
Get Shot Number 
Update Motion Information 
Shot 
Ontolog
y 
不想要的分鏡刪除，在時間的縮短以及使用者可調適性
上，為分鏡編織的最重要目的 
 
3   系統實作 
表1  測試影片的分鏡數量、長分鏡及特寫分鏡數量、得分
板改變數量 
Video File Total 
Clips 
cmeL cmeO Goal 
Cavaliers vs. 
Denver 
476 146 330 109 
Dallas vs. 
Houston. 
492 151 341 111 
Miami vs. Los 
Angeles 
504 175 329 115 
Detroit vs. 
Miami 
498 156 342 107 
 
在本實驗中我們以偵測的精確率(Precision Rate)來評估長
分鏡與特寫分鏡的結果，在得分片段的評估上我們採取
利用精確率(Precision Rate)與正確率(Recall Rate)兩個評
估方式來評估得分片段偵測的效能。 
 
falsemisscorrect
correct recall  
 
falsecorrect
correct ecision 
++=
+=Pr  
Correct代表的是正確偵測到的數目，False代表的為誤判的
數目，在長分鏡與特寫分鏡的判別上，指的是該判為長分
鏡卻誤判為特寫分鏡，或該判為特寫分鏡卻判為長分鏡，
而在得分片段的判別上指的是該片段實際上並無得分卻
判為有得分，整體來講Precision可以用來評估誤判的比
例；Miss代表的是實際上有得分板改變事件但是卻無偵測
出來，因此Recall的計算方式可以用來評估偵測得分事件
的準確率，表2為偵測影片中長分鏡與特寫分鏡的結果。 
 
表2  分鏡分類實驗結果  
 
Video File Precision 
Rate( 10   and 25 ==∂ σ ) 
Cavaliers vs. 
Denver 
93.2% 
Dallas vs. 
Houston. 
92.3% 
Miami vs. Los 
Angeles 
85.5% 
Detroit vs. Miami 93.8% 
 
在分鏡分類的準確度上，本論文的研究方法可以得到不錯
的結果，而在得分事件的偵測上，我們發現當畫格間隔時
間減少時，可以得到較佳的準確度與精確度，但是計算時
間卻會增加，因此在時間成本與準確率的平衡上可以作一
取捨而得到最佳的結果。 
 
 
5. 結論 
在本論文中，我們利用了本體論的知識定義出了分
鏡本體論，並且利用各種低階特徵分析分鏡本體論
的描述子；在空間關係上，我們利用膚色、主要顏
色，得分板變化將籃球影片的時間軸作標注，在時
間的關係上，我們利用分鏡類別的時間關係推論出
得分的片段，並且經過四部影片的測試之後證實本
論文的研究方法可以達到不錯的結果。籃球影片經
過本系統的索引之後，已經可以得到得分事件的偵
測，未來可以發展的方向為可以嘗試偵測過程事
件，並且將現有的各個終止事件予以強化；在系統
展示部份，可以在系統檢索之後提供更方便的編
織，以及權重功能，這樣一來使用者可以依照系統
給予的權重階級選擇最重要的觀賞部份，並且將有
興趣的部份予以編織成為一個新的片段。 
 
References: 
[1] M.R.Naphade,et.al "A factor graph framework 
for semantic video indexing," IEEE Trans. on 
Circuits and Syst. for VideoTechnol., vol. 12, 
no. 1, pp. 40-52, Jan. 2002.  
[2] M.R.Naphade,et.al "Modeling semantic 
concepts to support query by keywords in 
video," in Proc. IEEE Int. Conf. on Image 
Processing ICIP '02, vol. 1, pp. 145-148, 
Rochester, NY,Sept. 2002.  
[3] Min Xu et.al.” Event Detection in Basketball 
Video Using Multiple Modalities” Information, 
Communications and Signal Processing, 2003 
and the Fourth Pacific Rim Conference on 
Multimedia. Proceedings of the 2003 Joint 
Conference of the Fourth International 
Conference on Volume 3,  15-18 Dec. 2003 
Page(s):1526 - 1530 vol.3 
[4] J.R. Bach, et.al “The Virage image search 
engine: An oprn framework for image 
management,“ in Proc. SPIE Conf. On Vis. 
Commun,and Image Proc.  
[5] M. Flicker, et.al “Query by Image and Video 
Content: The QBIC System,” IEEE  Computer, 
Vol.28,No9,pp.23~32, 1995 
[6] A.Pentland, et.al “Photobook: Content-based 
manipulation of image databases,” 
