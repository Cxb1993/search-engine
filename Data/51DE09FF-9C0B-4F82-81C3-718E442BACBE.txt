 2
目錄 
一、報告內容 
  1-1. 前言 3 
  1-2. 研究目的 3 
  1-3. 文獻探討 3 
  1-4. 研究方法 4 
  1-5. 結果與討論      5 
二、參考文獻 10 
三、計畫成果自評 13 
四、發表的論文 14 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 4
高斯參考背景模型必須將標準差門檻值設得很高，這樣才能有比較好的前景切割效果，
然而效果還是很有限。這是一個很常見之場景，因此要採用高斯參考背景模型，必須先
驗證此場景之亮度分佈，是否符合高斯分佈。另一方面，若是為了去除雜訊或是背景而
一味地將標準差提高，最後只會讓前景之細節也因此而遺失。高斯參考背景模型必須將
標準差門檻值設得很高，這樣才能有比較好的前景切割效果，然而效果還是很有限。這
是一個很常見之場景，因此要採用高斯參考背景模型，必須先驗證此場景之亮度分佈，
是否符合高斯分佈。另一方面，若是為了去除雜訊或是背景而一味地將標準差提高，最
後只會讓前景之細節也因此而遺失。 
 
1-3-4. 混合高斯參考背景模型 
混合高斯參考背景模型是高斯參考背景模型之改良，此種模型假設一個場景可以由一個
以上的高斯分佈所涵蓋。 
 
1-3-5. 直方圖參考背景模型 
直方圖參考背景模型之概念在於選擇最常出現的那些像素當作參考背景值，也就是認為
背景上的像素應該是在一段時間內出現最久的那個值。直方圖參考背景模型的問題在於
要替每一個像素都儲存一個亮度統計直方圖，這會消耗非常多的電腦記憶體。例如，大
小為 320×240 的影像，亮度共有 256 階，則需要 18.75MB 的記憶體空間來儲存所有的亮
度直方統計表，這對於比較低階的硬體設備會形成很大的負擔。 
 
 
1-4. 研究方法 
由於背景切割的技術應用廣泛，所以相關探討的議題眾多。為了詳盡探討這些相
關議題之關聯性並將他們做有效的分類，最後再發展新的參考背景切割模型與更新方
法，所以，此計畫將分為三個部分： 
 
第一部分：實作文獻中之系統 
蒐集相關之文獻，除了研讀、探討之外，最重要的是重建文獻中的參考背景模
型系統，如此才能真正了解其優缺點。本計畫預計重建目前 3-4 種主流的參考背景
模型，從中分析與探討其優缺點，並藉此發展新的參考背景模型理論與設計方法。 
第二部分：發展新的參考背景模型與設計方法 
從第一部分所得之經驗與分析結果，發展新的參考背景模型與參考背景的設計
方法。本計畫將從統計之方法為基礎，配合人工智慧之理論，預期所設計之參考背
景模型能達到快速建立、降低噪音比（背景雜訊/前景）、不限架設環境之成果。因
此，為了能達到即時快速建立參考背景模型，因此在統計方法上排除複雜的多變數
模型（例如混合高斯模型）與遞迴模性（線性/非線性回歸方程式），取而代之的是
以線性之機率方法。 
第三部分：發展參考背景更新演算法 
許多相關研究或應用並不討論更新的方法，因為參考背景的更新牽涉到很多會
改變場景的變因，這些變因需要被各自討論、分類；若無法被歸類的變因，則需要
 6
   
Mixture Gaussian model 
   
MRV model 
圖一、四種參考背景模型對於前景完整度與雜訊抑制的結果。 
 
 
   
圖二、用本計畫開發的 MRV 參考背景模型在夜晚時的前景切割結果。 
 
 
   
Original clips 
   
Histogram model 
   
Single Gaussian model 
 8
   
(b-1)                (b-2)                (b-3) 
圖五、 停止的車輛融入背景。 (a) 三張連續的畫面：2740, 2820, and 2977. (b) 對應(a)的前
景切割。 
 
 
 
 
 
0
10
20
30
40
50
60
70
80
90
100
10 30 50 70 90 110
MR
NR
 
圖六、Histogram background model 的MR-NR圖 
 
0
10
20
30
40
50
60
70
80
90
100
10 30 50 70 90 110
MR
NR
 
 10
 
二、參考文獻 
[1] D. Butler, S. Sridharan, V. M. Bove, Jr, “Real-time adaptive background segmentation”, 
in Proc. of Conf. on Acoustics, Speech, and Signal Processing, pp. 349-352, vol. 3, 
2003. 
[2] A. Cavallaro, T. Ebrahimi, “Change detection based on color edges”, IEEE 
International Symposium on Circuits and Systems, pp. 141-144, vol. 2, 2001. 
[3] C. J. Chen, C. C. Chiu, B. F. Wu, S. P. Lin, C. D. Huang, “The Moving Object 
Segmentation Approach to Vehicle Extraction”, in Conf. on ICNSC, 2004. 
[4] R. Cucchiara, C. Grana, M. Piccardi, A. Prati, “Detecting moving objects, ghosts, and 
shadows in video streams”, IEEE Transactions on Pattern Analysis and Machine 
Intelligence, pp. 1337-1342, vol. 25, issue: 10, 2003. 
[5] T. H. Cormen, C. E. Leiserson, R. L. Rivest, Introduction to Algorithm, McGraw-Hill, 
1994. 
[6] J. W. Davis, V. Sharma, “Fusion-Based Background-Subtraction using Contour 
Saliency”, in IEEE Conf. on Computer Vision and Pattern Recognition, pp. 11-16, vol. 
3, 2005.5 
[7] A. Elgammal, D. Harwood, L. Davis, "Non-parametric Model for Backgroud 
Subtraction", in European Conf. on Computer Vision, pp. 751-767, vol. 11, 2000. 
[8] A. Elgammal, R. Duraiswami, D. Harwood, L. S. Davis, “Background and foreground 
modeling using nonparametric kernel density estimation for visual surveillance”, in 
Proc. on IEEE, pp. 1151-1163, vol. 90, issue: 7, 2002. 
[9] N. Friedman, S. Russell, “Image segmentation in video sequences: A probabilistic 
approach”, in 13th Proc. of Conf. on Uncertainty in Artificial Intelligence, 1997. 
[10] D. Guo, Y. C. Hwang, Y. C. L. Adrian, C. Laugier, “Traffic monitoring using 
short-long term background memory”, in Proc. of 5th Conf. on Intelligent 
Transportation Systems, pp. 124-129, 2002. 
[11] R. C. Gonzales, R. E. Woods, Digital Image Processing, 2nd ed., Prentice-Hall, 2002. 
[12] D. Hong, W. Woo, “A background subtraction for a vision-based user interface”, in 
conf. on 4th Pacific Rim Conference on Multimedia, and in Joint Conf. on Information, 
Communications and Signal Processing, pp. 263-267, vol. 1, 2003. 
[13] E. Hayman, J. O. Eklundh, “Statistical background subtraction for a mobile observer”, 
in Proc. of Conf. on Computer Vision, pp. 67-74, 2003. 
[14] H. Han, Z. Wang, J. Liu, Z. Li, B. Li, Z. Han, "Adaptive background modeling with 
shadow suppression", in proc. IEEE Intelligent Transportation Systems, pp.720-724, 
vol. 1, 2003. 
[15] I. Haritaoglu, D. Harwood, L. S. Davis, “A fast background scene modeling and 
maintenance for outdoor surveillance”, in 15th Conf. on Pattern Recognition, pp. 
179-183, vol. 4, 2000. 
[16] M. Harville, G. Gordon, J. Woodfill, “Adaptive video background modeling using 
color and depth”, in Proc. of Conf. on Image Processing, pp. 90-93, vol. 3, 2001. 
 12
[33] C. Stauffer, W. E. L. Grimson, “Learning patterns of activity using real-time 
tracking”, IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 
747-757, vol. 22, issue: 8, 2000. 
[34] C. Stauffer, W. E. L. Grimson, “Adaptive background mixture models for real-time 
tracking”, in IEEE Conf. on Computer Vision and Pattern Recognition, pp. 246-252, 
vol. 2, 1999. 
[35] D. S. Lee, J. J. Hull, B. Erol, “A Bayesian framework for Gaussian mixture 
background modeling”, in Conf. on Image Processing , pp. 973-976, vol. 2, 2003. 
[36] L. D. Stefano, A. Bulgarelli, "A simple and efficient connected components labeling 
algorithm", in conf. on Image Analysis and Processing, pp. 322-327, 1999. 
[37] L. D. Stefano, S. Mattoccia, M. Mola, “A change-detection algorithm based on 
structure and colour”, in Proc. of Conf. on Advanced Video and Signal Based 
Surveillance, pp. 252-259, 2003. 
[38] M. Sonka, V. Hlavac, R. Boyle, Image Processing, Analysis, and Machine Vision, 
2nd ed., PWS, 1999. 
[39] Y. Sun, B. Yuan, "Hierarchical GMM to handle sharp changes in moving object 
detection", Electronic Letters, pp. 801-802, vol. 40, issue: 13, 2004. 
[40] D. Toth, T. Aach, “Detection and recognition of moving objects using statistical 
motion detection and Fourier descriptors”, in Proc. of 12th Conf. on Image Analysis and 
Processing, pp. 430-435, 2003. 
[41] J. C. Tai, K. T. Song, “Background Segmentation and its Application to Traffic 
Monitoring Using Modified Histogram”, in Conf. on ICNSC, 2004. 
[42] A. R. Webb, Statistical Pattern Recognition, 2nd ed., Wiley, 2002 
[43] Q. Z. Wu, H. Y. Cheng, K. C. Fan, “Motion Detection Based on Two-Piece Linear 
Approximation for Cumulative Histogram of Ratio Image in Intelligent Transportation 
Systems”, in Conf. on ICNSC, pp. 309-311, 2004. 
[44] H. Yinghua, H. Wang, B. Zhang, ” Background updating in illumination-variant 
scenes”, in Proc. on Intelligent Transportation Systems, pp. 515-19, vol. 1, 2003. 
[45] W. Yiming, X. Yang, K. L. Chan, “Unsupervised color image segmentation based on 
Gaussian mixture model “, in Proc. on Information, Communications and Signal 
Processing, and in Conf. on 4th Pacific Rim Multimedia, pp. 541-544, vol. 1, 2003. 
 
 
 
 
 
 
 
 
 
 
 14
四、發表的論文 
本研究計畫已發表於 2009 年的 IEEE International Conference on Networking, Sensing and 
Control，完整的訊息及論文內容如下： 
 
Jian-Wen Peng, Wen-Bing Horng, “Real-time Dynamic Background Segmentation Based on 
a Statistical Approach”, in Proceedings of the 2009 IEEE International Conference on 
Networking, Sensing and Control, Okayama, Japan, March 26-29, 2009. Accepted. Contract 
No. NSC 97-2218-E-263 -001. 
 
 
論文內容見下頁 
 
 
 
 
histograms that are calculated over a circular region around 
the pixel. 
Although many background models have been proposed 
for various situations, they seldom discussed the causes of 
scene variations and how to handle them. In this paper, we 
propose a new reference background model, called the 
multiple reference value (MRV) background model, to deal 
with the above problems. The major difference between the 
proposed MRV model and other background models is that 
every pixel’s value within the MRV background model not 
only consists of a single value but of several values. This 
feature shows high tolerance to the shaking of the mounted 
camera and background objects such as branches or leaves. In 
addition, it also preserves more details of foreground and 
presents good performance on noise suppression. 
II. CONSTRUCTING AN RBI 
Constructing an RBI of the MRV model includes four 
major steps: sampling, choosing candidates, deciding the RBI, 
and non-convergent pixel processing. Throughout this paper, 
the pixel value is represented by the color in the HSI model. 
A. Sampling 
The sampling step is to record and classify every pixel’s 
values of consecutive input images during some period of 
time. Let S(Px,y) be the set of classified values of pixel P at 
location (x, y). For the first frame, S(Px,y) contains only one 
element, the value of pixel Px,y. 
Considering a new frame, the new value v of Px,y is com-
pared with each value vj in S(Px,y), 1 ≤  j ≤ n, where n is the 
number of elements in S(Px,y). If |v – vj| < thtole, the two values 
will be regarded as the same, where thtole is some tolerant 
threshold. And, then, vj is updated as follows 
vj = α × vj + (1 – α) × v (1) 
where α = (cj – 1)/cj and cj is the count (frequency) of vj. 
Otherwise, v is directly added to S(Px,y). 
B. Choosing Candidates 
After the sampling step, the candidate set CAx,y of Px,y of 
the RBI can be defined as follows 
CAx,y = {vj | cj ≥ thca, 1 ≤  j ≤ n} (2) 
where thca is some candidate threshold. Two situations will 
result in invalid candidates: 1) Each cj count is too small. 2) 
The chosen candidates do not have strong representativeness. 
The first case means that too many values of a pixel are 
recorded; it results in all counts being too small to pass the 
candidate test. Nonetheless, this can be resolved in the non- 
convergent processing step. For the second case, it indicates 
that wrong candidates are chosen and it relies on background 
updates (in Section IV) for correction. 
C. Deciding the RBI 
After choosing candidates of the RBI, we further filter out 
unsuitable smaller candidates by a ratio thref (< 1). The final 
number, refx,y, of candidates of Px,y is defined as  
refx,y = ⎡|CAx,y| × thref⎤ (3) 
where ⎡·⎤ represents the ceiling function. Then, the reference 
value set, RCx,y, of Px,y of the RBI can be expressed as 
RCx,y = {vk | vk ∈ sort(CAx,y), 1 ≤ k ≤ refx,y } (4) 
where sort(CAx,y) is the set of elements vk in CAx,y sorted in 
descending order according to the count value [2]. That is, 
RCx,y consists of the topmost refx,y elements in the sorted set of 
CAx,y. Finally, the initial RBI, BGref, can be defined as 
BGref = { RCx,y | 1≤  x ≤ width, 1≤  y ≤ height} (5) 
where width and height are the width and the height of the 
scene image. 
D. Non-convergent Pixel Processing 
After the initial RBI has obtained, some pixels may have no 
reference values, which are called non-convergent pixels. For 
each such pixel, we perform at most three times of 
re-sampling for parameters (thresholds, such as thtole, thca, and 
thref) adjustment. Let Mcx,y be the average of some parameter 
(threshold) of the convergent neighbors of a non-convergent 
pixel Px,y. The general formula of parameter adjustment can 
be expressed as 
thnew = thold × (1 – Mcx,y / thold) + r (6) 
where th is any of the above threshold, and r is some random 
value. After three times of re-sampling, if some pixel still has 
no reference values, we will directly adjust the parameters as 
follows 
thnew = Mcx,y + r (7) 
An RBI is complete when all non-convergent pixels have 
their own reference values. Figs. 1(a) and 1(b) shows the 
same part of an RBI at the initial state and the final state, 
respectively. The numbers in Fig. 1 stand for the number of 
reference values of each pixel Px,y in these two states. Note 
that most of the values in Fig. 1(a) are much less than those in 
Fig. 1(b); this shows that the remaining values have more rep-
resentativeness to the real background. 
  
(a)                                                           (b) 
Fig. 1.  (a) The initial state and (b) the final state of the same part of an RBI 
III. FOREGROUND SEGMENTATION  
The proposed foreground segmentation includes three 
steps: segmenting foreground, removing noises, and 
enhancing foreground details. 
 
 
 
This order indicates that if a higher and a lower priority 
situations occur at the same time, then the higher priority 
situation is executed first, and the lower priority situation 
should wait until the higher priority situation completes. 
V. ERRONEOUS BACKGROUND UPDATES 
Many factors cause variations in the monitored scene, 
which will result in erroneous foreground segmentations. We 
categorize most of the frequent cases of scene variations into 
six types, as listed in Table II. These cases need to be dealt 
with during the update procedures to ensure that the RBI is 
consistent with the real background. 
TABLE II 
TYPES OF SCENE VARIATIONS 
Type Scene Variations 
T1 Many objects passing 
T2 Big objects passing 
T3 Jam of objects 
T4 Moving states of objects 
T5 Slowly moving objects 
T6 Illumination variations 
A. Many Objects Passing 
This situation consists of too many objects passing through 
the scene while the update is in progress. It causes erroneous 
updates. The following two strategies can be used for dealing 
with this situation: 
• Skip the current frame. 
• Only update the areas of non-moving objects. 
The first strategy is suitable for the global update, because 
the sampling process must record values of each pixel equally. 
If there are too many objects passing through the scene during 
the global update, the sampling process will obtain more 
object values than background values, and this will result in 
wrong sampling. On the other hand, the local update 
emphasizes fast reflection for scene variations, so that the 
second strategy is suitable for it. 
Let mr be the ratio of the number of foreground pixels to 
the number of all pixels in a frame. If mr is greater than a 
predefined threshold, thflow, it indicates that many objects are 
passing through the scene. 
B. Big Objects Passing 
When a big and bright object is passing through the scene, 
the exposure of a camera will suddenly decrease such that 
smaller objects will result in insufficient exposure. On the 
contrary, when a big and dark object is passing through the 
scene, the exposure of a camera will suddenly increase such 
that small objects will get too much exposure. Therefore, this 
situation will result in erroneous foreground segmentation 
and RBI update. The following two strategies can be used to 
overcome this problem. 
• Increase the update rate and update the RBI immediately. 
• Do nothing and wait for the big object to pass. 
The first strategy of increasing update rate can quickly 
reflect the illumination variations. Once the big object has 
passed, the update rate is returned to its original value. 
Although the time the big object passes through the scene is 
short, it results in the RBI being in an unstable state by 
increasing and decreasing the update rate repeatedly. In this 
paper, we adopt the second method in the MRV model to deal 
with continuous big objects passing through the scene. 
C. Jam of Objects 
This situation is similar to a traffic jam or people blocked at 
an entrance. Therefore, the RBI must be updated when this 
situation occurs. Let jr be the ratio of two foreground areas at 
time t and t + Δt, as shown below 
jr = area(FGt) / area(FGt + Δt) (10) 
where FGt stands for the foreground image at time t, and 
area(FG) stands for the number of foreground pixels in the 
FG image. If jr > 1, then the number of moving object pixels 
at time t is greater than that at time t + Δt, and vise versa. 
Now, we consider the following three cases: 
1) The object flow is stable. If the areas occupied by objects 
in successive frames are almost the same, jr remains the 
same and approximates to one. 
2)  No object is in the scene. Both area(FGt) and area(FGt + 
Δt) approximate to zero. In this case, we let jr be zero. 
3) The jam occurs over a period of time. If objects gradually 
increase and finally result in a jam, jr increases and 
eventually equals to one. 
Therefore, estimating a jam can be performed by monitoring 
the variation of the values of jr. If it changes from small to 
large and finally approximates to one, it can be regarded that 
there is a jam occurred. 
D. Moving States of Objects 
If an object changes its state from stop to move or from 
move to stop, the RBI needs to be modified to reflect this 
change; otherwise, erroneous foreground segmentations will 
occur. If a car moves into the scene and finally stops, it should 
be regarded as a part of the background when it completely 
stops. However, without updating the RBI, the stopped car 
will still be viewed as an object rather than the background. 
Similarly, a leaving object will have the same problem. 
To overcome these problems, we must know which objects 
are preparing to stop or to leave. Let thst be the predefined 
stay time. If an object staying at the same position exceeding 
thst time, then it is regarded as a static object. We then use a 
table to record all static objects to update the RBI. When an 
object is recognized as static, it will be inserted into the table. 
After some observation period, all the static objects recorded 
in the table are used to update the RBI immediately. 
Fig. 4 shows the process in which a black car gradually 
becomes a part of the background and finally disappears after 
it stops completely. The first two foregrounds (Figs. 4(d) and 
4(e)) are correct because the black car is still moving. The 
black car does not appear in the third foreground (Fig. 4(f)) 
because it already stops for some period of time. 
