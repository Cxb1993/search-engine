 
中 文 摘 要 ： 本計畫基於第一階段的研究成果，在第二階段時加入韻律屬
性與語音事件的偵測，並與音段屬性整合，以建立語音辨識
模型為目的。從聲學訊息的角度，釐清語音信號中小單位音
段恆態成分及音位配列結構特徵所造成的音段語境，其相互
關係所造成的變異；以及辨識較大單位相對韻律語境及其與
音段互動所造成的變異。因此，本計畫之重點是選取語音辨
識單位、偵測各單位的韻律屬性、經由韻律屬性自動偵測語
意焦點並建立語意優選權重，及建立韻律辨識模型。 
語音訊號中，並非所有的信號都一樣重要，反而是存有相當
可省略而不影響辨識的成分，因此韻律屬性偵測可提供的協
助，正可與音段恆態的偵測互補，強調單位選取及各韻律單
位間的特徵表達及計算。韻律訊息是透過超音段訊息的相對
特徵表達的，這些相對性是通過韻律動態變化呈現。語音識
別研究階段分為「粗分後細辨」二階段進行。第一階段利用
韻律特徵，進行大單位輪廓的辨識，也同時將語流分成「必
須辨識」及「或可略去」的成分的粗分，第二階段再就「必
須辨識」的成分進行音段恆態的辨識。我們擬從連續語音的
基頻高低及走勢、音節長短於時程的配置、進行一系列的實
驗，階段性整合音段訊息，建立基於聲學語音參數的韻律辨
識模型。 
中文關鍵詞： 音段不變成分、相對韻律訊息、韻律屬性、音段語境、韻律
語境、語意優選權重 
英 文 摘 要 ： The project aims to derive prosodic attributes from 
speech data that would be use to (1.) analyze 
interaction effects between invariant segmental 
attributes, lower level phonotactic effects and 
higher level relative supra-segmental attributes, 
(2.) derive focal semantic information via default as 
well as speaker-intended prosodic focuses, both 
default and speaker intended, (3.) establish semantic 
weighting and semantic concept hierarchy via prosodic 
characteristics and (4.) integrate invariant phonetic 
attributes and relative prosody attributes to 
construct models of recognition weighting that 
divides speech flow into primary optimal concept and 
secondary-to-optional information. Prosodic 
attributes included are acoustic correlates F0 
contour patterns, syllable duration adjustment along 
the temporal course, amplitude/intensity distribution 
patterns, boundary break durations, and boundary 
行政院國家科學委員會補助專題研究計畫 █研究成果報告 
新世代自動語音辨識技術之研究第二階段（子計畫五）── 
韻律屬性與語音事件偵測之研究 
計畫類別： □個別型計畫  █ 整合型計畫 
計畫編號：NSC 97－ 2221 － E － 0001 － 017 － MY3 
執行期間： 97 年 8 月 1 日至 100 年 10 月 31 日 
計畫主持人：鄭秋豫 
共同主持人：王新民、廖元甫 
計畫參與人員：王文煜、陳意婷、蘇昭宇、蔡建榮、李文森、呂紹禾、吳明龍、
王佩銀、陳詩涵 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
本成果報告包括以下應繳交之附件： 
■出席國際學術會議心得報告及發表之論文各一份 
附件一 Tseng, Chiu-yu and Chun-Hsiang Chang, 2008. Pause or No Pause ? –Prosodic Phrase Boundaries 
Revisited. Tsinghua Science and Technology, 13.4: 500-509. 
附件二 Tseng, Chiu-yu and Zhao-yu Su, 2008. What’s in the F0 of Mandarin Speech –Tones, Intonation and 
beyond. ISCSLP 2008, (December 16-19, 2008), Kunming, China. 45-48. 
附件三 Tseng, Chiu-yu, Lin-shan Lee and Zhao-yu Su, 2008. Spontaneous Mandarin Speech Prosody—the NTU 
DSP Lecture Corpus. Oriental COCOSDA 2008, (Nov. 25-27, 2008), Kyoto, Japan. 171-174. 
附件四 Tseng, Chiu-yu and Zhao-yu Su, 2009. Boundary and Lengthening—On Relative Phonetic Information. in 
Frontiers in Phonetics and Speech Science (現代語音學前沿文集 ) edited by G. Fant, H. Fujisaki and J. Shen, 北
京商務印書館, 369-379, 北京. 
附件五 Tseng, Chiu-yu, Zhao-yu Su and Lin-shan Lee, 2009. Mandarin Spontaneous Narrative 
Planning—Prosodic Evidence from National Taiwan University Lecture Corpus. Interspeech 2009, (Sep. 6-10, 
2009), Brighton, U.K. 2943-2946. 
附件六 Tseng, Chiu-yu, Zhao-yu Su and Lin-shan Lee, 2010. Prosodic Patterns of Information Structure in Spoken 
Discourse—a Preliminary Study of Mandarin Spontaneous Lecture vs. Read Speech. Speech Prosody 2010, (May 
11-14, 2010), Chicago, U.S.A. 
附件七 Tseng, Chiu-yu and Zhao-yu Su, 2011. Dynamic Discourse Speech Tempo and Phonological Timing. 
ICPhS (International Congress of Phonetic Sciences) 2011, 4 pages. Aug. 17-21, Hong Kong, China. 
附件八Tseng, Chiu-yu, Chao-yu Su and Chi-Feng Huang, 2011. Prosodic Highlights in Mandarin Continuous 
Speech—Cross-genre Attributes and Implications. Interspeech 2011, the 12th
附件九 出席國際學術會議心得報告 
 Annual Conference of Speech 
Communication Association, 4 pages. Aug. 28-31, Florence, Italy. 
 
 
       
執行單位：中央研究院語言學研究所、資訊科學研究所、 
     台北科技大學電子工程學系 
中   華   民   國  100  年  11  月   3  日
  II 
計畫英文摘要。（五百字以內） 
The project aims to derive prosodic attributes from speech data that would be use to (1.) analyze 
interaction effects between invariant segmental attributes, lower level phonotactic effects and 
higher level relative supra-segmental attributes, (2.) derive focal semantic information via default 
as well as speaker-intended prosodic focuses, both default and speaker intended, (3.) establish 
semantic weighting and semantic concept hierarchy via prosodic characteristics and (4.) integrate 
invariant phonetic attributes and relative prosody attributes to construct models of recognition 
weighting that divides speech flow into primary optimal concept and secondary-to-optional 
information. Prosodic attributes included are acoustic correlates F0 contour patterns, syllable 
duration adjustment along the temporal course, amplitude/intensity distribution patterns, 
boundary break durations, and boundary related properties. Analyses are designed to extract the 
relative relationship of the above supra-segmental acoustic correlates in contrast with the 
invariant properties at the segment and phone levels, and the obligatory interacting effects 
between the invariant and the relative cues co-existing in the speech signals. Models constructed 
will be used to help improve automatic speech recognition of Mandarin Chinese. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Keywords: Prosodic attributes, invariant segmental attributes, relative supra-segmental attributes, 
default prosodic focus, speaker-intended prosodic focus, prosodic weighting, semantic weighting, 
weighting hierarchy 
  1 
一、 研究背景及理論架構 
自動語音辨識(automatic speech recognition, 語音識別)一直是資訊領域中的關鍵性技術
之一，經過 40年的發展，現在已經有一些語音辨識的產品或展示系統，例如聽寫機、語音
查號、語音擷取資訊等，雖然可以得到不錯的語音辨識效果，但是與人類聽辨語音的能力
相比，還是有一段不小的差距。就技術層面而言，現在採用的是資料驅動(data-driven)與機
器從資料中學習的做法，因此要針對某一個語言設計語音辨識系統，不需要有對於該語言
的了解與知識，只要收集夠多該語言的語音與文句資料，就可以建立該語言的聲學模型與
語言模型，是基於語料庫(corpus-based)的做法，以統計學的觀念來建立一個語音辨識系統。
目前這樣的做法可以滿足某些特定的應用，但是在說話環境複雜與說話人發音變化大時，
就面臨語音辨識正確率大幅下降的窘境。相對的，人類的聽語能力就強得多，在吵雜的環
境或說話人發音不正確的情形下，仍然有很好的聽辨能力。顯然人類在聽別人說話時，會
抓住語音中的關鍵點，而這些關鍵點與某些聲學事件的出現有關，這些聲學事件在複雜環
境中比較不會受到干擾。 
因為資料驅動模式的方法是採用了忽略知識的模型方法(Knowledge ignorant 
modeling)，模型參數是由大量語音與語言資料來估測，模型參數不見得能對應到發音的過
程，這樣的模型難以描述語言上的細節，因此要了解問題之所在變得很困難，能再改進者
有限。所以近年來國際上許多學者認為需要將語音與語言的知識帶進來，建立一個以知識
為基礎(Knowledge-Based)加上資料驅動的(data-driven)模式，以發展新世代的語音辨識技
術。 
國內從事語音辨識研究的人不多，若要發展新世代的語音辨識技術，必須整合起來，
建立一個合作團隊，作長期的投入，才有可能獲得較有影響力的成果。從 2005年起，我們
結合國內在語音辨識研究有經驗的學術與研究單位，執行一個整合型計畫「新世代自動語
音辨識技術研究」，在這個三年的計畫中，我們組成合作研究團隊，建立一個合作設計與共
享資源的共享平台，對於新世代語音辨識的一些基本技術進行研究。當時所提出的系統架
構如圖 1所示； 
 
語音屬性與
事件之偵測 
 
語音事件及
相關知識整
合 
語音證據之
確認 
知識、模型、資料庫、以及工具設計 
語音
訊號 
供決策
用之證
據序列 
 
圖 1 新世代自動語音辨識系統規劃 
團隊成員分別針對架構圖中各功能方塊所標示的議題進行研究，探討新的語音辨識技
術，著力較多的是在語音屬性與事件偵測，以及語料庫的自動標音(automatic Labeling)與整
理，同時也建立了一個可以分享程式與語料庫的共享平台，提供一個合作研究與資源分享
的機制。 
  3 
功能方塊(五)──外加知識 
在新的語音辨識系統中，語言與語音知識必然扮演更為重要的角色，這些外加知識將支援
功能方塊(四)的需要，在未來的研究中必然會因此而引入更多不同領域的學者，參與建立知
識庫方面的研究。 
 
共享平台 
共享平台的建立，是要讓參與計畫的研究人員可以在此平台上分享程式與語音資料，
同時也公開研究成果，這個平台必須持續發展與維護。目前已經建立的兩個功能正在試用
中，後續工作將是繼續改進，也藉此平台達成各個功能方塊的整合，以及研究團隊的持續
合作。 
 
二、 研究重點 
本計畫為「新世代自動語音辨識技術之研究－第二階段」的一部份，在第一階段時，
語音屬性與事件偵測的重點是音段，基於第一階段的研究成果，我們計劃在第二階段時加
入韻律屬性與語音事件的偵測（子計畫五），即語音信號中的超音段成分，並階段性的與音
段屬性整合，以建立語音辨識模型為目的。主持人鄭秋豫將負責韻律屬性的偵測。整合音
段、聲調研究及建構加入韻律成分後改進辨識結果的模型，則由共同主持人北科大副教授
廖元甫、中研院資訊所研究員王新民二位負責。 
語音信號的成分並非只有音段訊息，而是音段訊息與超音段訊息的混合。也就是說，
音段訊息和超音段訊息是同時同步存在的。音段訊息無論在口語中如何多變，都必須維持
相當的不變恆態，才能維持音位的對立、音韻體系運作，再透過詞法、句法的結構，體現
語意的傳達，因此音段的語音屬性主要以語音事件中不變的恆態成分為目標，也是 HMM
的基本精神。在連續語音中，各音段必須維持了一定程度的不變，才能傳達該音段的訊息，
這也是我們可以在語音事件中，透過音段特徵與音位配列結構特徵(phonotactic features)的
語境，找尋並界定恆態成分屬性，再將之應用到語音識別的主因。不過，語音信號中也同
時存有以相對關係所表達的超音段訊息，造成跨單語音單位的韻律變異，因此若從 HMM
的角度及音位配列特徵所造成語境角度切入，自然無法迎刃而解。原因至少有三：一、語
流中任何一個單音節的字調(tone)會因與者個人的音質以及其在語句、語段的位置不同，接
受不同的上層訊息規範，而產生基頻、音節長度的相對改變，從語料訓練的模型必須因語
者、語料的改變一再訓練。二、所謂的語境，並不僅是音位配列結構特徵及音段線性串接
的平滑、連併、縮減而已，同時也包括句調、句子的韻律訊息，更兼表達連續語音中比字、
詞、句子更大的語意關聯的單位及語篇訊息（Tseng et al, 2004; 2005; Tseng, 2006）。三、語
流中充滿了語者自由或隨機決定的連併與省略（林燾，1963），是口語中很常見的現象。例
如當今的台灣口語中：把「然後」說成「南噢」、「今天」說成「間」、「現在」說成「現」、
「大家」說成稍微拉長的「搭」、以致於「現在大家」就說成「現搭」等。音段本身的變異，
並非以音位（phoneme）的語音表徵變化(phonetic output variations)即可完全涵蓋，必須增
加語音合併、縮減的規則。也就是說，音段必須有承載的工具，口語輸出的表達才能達成。
  5 
這些相對性是通過韻律動態變化呈現的。換言之，基頻的高低、音節的長短、能量大小的
分佈、邊界效應的特徵，都是語音識別時韻律屬性的偵測目標，必須以如何系統性的捕捉
這些參數的相對特性為主，這也是本計畫的思考依據。韻律訊息所表達的，是語意的重點
所在、相關與連貫，以及語流中的篇章訊息。從文本的角度，印刷體的每一個中文方塊字
雖有筆畫的多寡卻沒有大小的分別，所表達的視覺訊息沒有權重。從語音的角度，韻律訊
息卻透過了音高變化的對比、節奏長短的配置、響度強弱的對比，清楚的傳達了語流中訊
息的權重。語者在語言語音的產製中表達了這部分的訊息；聽者在即時的語音處理中接受
並利用這些訊息輕易的將語音中的重點訊息取出。語音識別的研究，一向並不注重語音信
號權重的考慮，其實這極有可能是無法抓住人的聽感特性處理語音信號最大的瓶頸。其實，
人與人的口語溝通，並不要求百分之百的識別，反而是透過焦點訊息、甚至焦點訊息中的
關鍵詞便可達成絕大部分的訊息溝通。因此，我們提出權重式的語音識別，將語音識別分
為「粗分後細辨」，分二階段進行。第一階段利用韻律特徵，進行大單位輪廓的辨識，找到
語段、短語、韻律詞等將上層的韻律單位，也同時將語流分成「必須辨識」及「或可略去」
的成分的粗分，第二階段再就「必須辨識」的成分整合本計畫第一階段的研究成果，進行
音段恆態的辨識。我們的假設是：必須辨識的成分必然是信號清晰的部分為主，音段辨識
的結果必佳，此階段的辨識率必高，關鍵詞也必定被辨識，無論是 keyword spotting，IR
（information retrieval）、語意擷取（summarization）都已解決，基本上已達成概念辨識(concept 
recognition and consolidation) (Hori et al, 2007)，在範疇上屬宏觀辨識。其後再從概念辨識錯
誤的部分求取特徵，作為進一步提升辨識的參考。換言之，宏觀部份：對於語流的語義焦
點所在，可透過韻律邊界、基頻的相對高低掌握語意重音與語調重音，做為語流的語意焦
點指標。找出連續語音處理時韻律特徵的參與成分後，則可建構韻律辨識的模型。微觀部
份分為二部分，一部份是釐清選取句法及語義單元的的模糊性。例如：透過韻律邊界釐清
句法節點，則可分辨「語音實驗是分析聲學參數與感知之間的不一致。」與「語音實驗室
分析聲學參數語感之之間的不一致。」的混淆。另一部份則是就韻律填充性高的「或可略
去」成分進行語音信號本身及對應文本的比對分析，進一步導出語音信號權重的模型。我
們擬從連續語音的基頻高低及走勢、音節長短於時程的配置、進行一系列的實驗，從微觀
與宏觀兩方面加以落實。 
 
三、 研究目的 
我們研究課題的重點，是如何釐清語音成分中不變的恆態成分和動態的相對成分如何
共同達成語音信號中的大部分表意，使口語溝通順利達成。包括以下五個方向，依次進行： 
1. 偵測語流中的韻律邊界，提供韻律單位的辨識資訊。我們將量化邊界效應，利用先前研
究語流韻律的結果及韻律架構(Tseng et al., 2004; 2005; Tseng, 2006)，偵測不同等級的聽
感邊界，包括語流中(1.) Pause 兩端音節長短分佈與邊界效應的對應關係, (2.) pause 
duration, (3.) F0 reset, (4.) amplitude distribution，配合對應於單字、詞以上的可辨識單
位。此部分我們已有相當的研究成果，可直接開發辨識應用。區別語流中韻律短語間停
頓長度的差異性，觀察在多短語韻律句群 PG (Prosodic Phrase Group, Tseng et al., 2005) 
的中段韻律短語 PG-medial PPh 中，是否可找到組成特定語義之區塊的相對超音段特
徵，作為偵測韻律事件的參考。建構韻律短語模型：結合兩端的邊界效應組成一含有上
  7 
節奏基型模版，二者結合，應可提供語音識別方面的應用。 
5. 偵測語流中承載語意的主要成分。除去語流中或可省略的成分後，我們分析語段開始時
的相對音高、語速、音節長度及各韻律邊界的相對的 F0 降低及各韻律邊界的延長，尤
其是語段結束時最終短語的相對延長效應(final lengthening)的範圍及其語篇成分，進行
口語篇章中的詞重音、語句重音及語意重音的研究，找出偵測語流中主要的語意成分所
在，可能透過的韻律途徑包括(1.) speaking rate 轉換，(2.) F0 變化於口語篇章中句調
intonation的相對交互關係 等，尤其是 Fujisaki model中的 Phrase component所對應的成
分，是否表達了主要語意成分，並透過語流韻律 PG的成分表達，將語流中的「必須辨
識」主要成分進行分類及排序。 
目前語音辨識仍以單句且語速較慢的語料為主，然而在實際的應用中，快語速的連續
語流是未來語音辨識所需解決的課題，然而在連續語流中，存在著相當大的信號的失真，
因此我們預期韻律特徵可用來提升快語速且較模糊的語音辨識，擬分析的課題如下: 
1 辨識前的預分析：從語音信號得到快語速連續語流的階層性架構。若將語流視為不同
程度的「必須辨識」及「或可略去」的組合，則可建立一階層式架構的語音辨識系統，
我們擬以韻律短語為單位，假設不同語意焦點程度的「必須辨識」「或可略去」成分將
會有不同的辨識率，給予「必須辨識」較高的權重，而「或可略去」則允許有較高的
自由度及較多的候選單位，換句話說，以「必須辨識」為節點，「或可略去」為聯結，
有效率的串聯出語段的辨識結果。 
1.1 透過自主性重音的表徵定義出語意焦點的階層性。語流中的韻律特徵存在著自主
性附加成分與非自主性的內在特性；非自主的內在特性方面，除了相對延長效應
(final lengthening)，計劃共同主持人鄭秋豫也提出對應中文連續語流架構各層的音
長模型(Tseng et al., 2005)。雖然我們尚未對自主性的附加成分進行深入研究，但
已對非自主的內在特性有一定程度的了解，期望藉著掌握非自主的內在特性，來
找出自主性的附加成分表現在韻律上的特徵，並深入探討是否這些附加成分可表
現在前後文的相對性或大範圍的韻律特徵參數的變化，包括: (1.) speaking rate轉
換，(2.) Phrase component的相對交互關係，(3)其他信號的相對特徵。若可以找到
自主性的附加成分特徵，則可在相同文本的多人次語料中統計自主性附加成分的
一致性，期望從不規則的附加成分表徵中找到共同的基型及解釋性，而這些共同
的特性，為語流中語意訊息承載量較高的部份，因此將是語音辨識的重點區塊。 
1.2 找出韻律短語以上大範圍的語意焦點區塊。我們也可延伸「必須辨識」區塊的範
圍，希望在 PG (Prosodic Phrase Group, Tseng et al., 2005) 的中段 PG-medial中，找
到大於句子的語意關聯單位，希望這些特定語義之區塊的相對超音段特徵，能夠
提供 PG-medial 中的次語意焦點區塊，我們可利用次語意焦點區塊內各單位間的
前後文關係(Chen et al., 2006 )，找出將區塊內各單位間的關連性並進行辨識，希
望能提高辨識率。 
以動態的韻律單位來增進連續語流中「必須辨識」區塊的辨識率。在傳統語音辨識的
語言模型中，N-gram被視為前後文等資訊來提高語音辨識正確率，並呈現不錯的效果
(Huang, Acero and Hon, 2001)，但在快語速的語料中，常常因為語者說話的策略與強調，語
音信號常有合併或縮減等現象，這些現象使得語音間的邊界變得模糊不清，造成辨識上的
混淆，例如，韻律短語間存在非常不規則的停頓時長，如此效應對快語速語流的辨識會造
  9 
漢語的韻律課題中，最缺乏輕聲和輕音在聽辨方面的意義，在語音識別中也從未被觸及。
其實，語流輕音的種類，包括：（1.）經過不同層次的語音結構與句法結構之間對應或不對
應的相互關係，至少可找出語流中有兩種不同性質的輕音（林燾，1962）；（2.）語流音變
的產生主要在輕音中實現，在連續話語中，輕音可以在不同的詞類和句子中不同的語流成
分中體現。（3.）由於語流輕音不僅涉及相關音節聲、韻、調的全面弱化，而且通過它與重
讀音節或邊界發音增強的反差，直接對話語的韻律結構作出貢獻。所以，如果只注意一般
的重音設置，而缺乏對語流輕音的適當處理，就必然導致合成韻律結構上的某種失調（曹
劍芬，2007）。而我們研究音節長短配置發現（Tseng et al., 2004; 2005），透過音節的長短配
置而非音高或響度可釐清輕重音的特徵。若能進一步釐清漢語輕音在語流中的的種種聲學
特性，對其來源得到系統性的解釋，更進一步提出各韻律單位的節奏基型模版，二者結合，
應可提供語音識別方面的應用。（4.）以上對漢語韻律的知識，應亦可供其他子計畫做偵測
國語語音屬性、台灣英語口音之重要參考，及建立共享語音平台的重要依據。 
 
五、 研究成果 
本子計畫研究的重點，是釐清連續語流中不變的恆態成分，與動態的相對成分如何共
組語音信號中的表意成分，順利達成口語溝通的目的。三年研究成果包括： 
(1)偵測語流中的韻律邊界特性，可供辨識韻律單位所需的資訊。 
(2)提出不同於以往單一字調正確率辨識的研究觀點，找出「連續語流中整體韻律脈絡（global 
prosodic context）」，有助語音辨識率的提升。 
(3)分析自發性課程口語篇章的韻律特性及跨語體韻律屬性比較，應有助辨識快語速連續語
流時可能遇到的信號失真問題。 
(4)比較跨語體朗讀語料與自發性課程口語語料感知強調/韻律突顯（prosodic highlight）組
型，增進語篇結構與資訊結構對應的瞭解。 
研究成果詳述如下： 
1. 偵測語流中的韻律邊界特性，可供辨識韻律單位所需的資訊。 
在韻律邊界特性方面，我們以先前研究語流中邊界特徵及量化邊界效應的結果（Tseng 
and Fu, 2005）為基礎，利用語流韻律的結果及韻律架構（Tseng et al., 2005; Tseng, 2006），
偵測不同等級的聽感邊界特性，包括語流中不同範圍的聲學參數 pause兩端音節長短分佈
與邊界效應的對應關係,  pause duration,  F0 reset,  amplitude distribution，配合對應於
單字、詞以上的可辨識單位。透過跨語體、語者的語料分析，針對韻律邊界與相鄰韻律單
位的系統性關係進行驗證研究，以大批語料檢驗各級韻律單位分層貢獻度的統計數據，證
明語段中韻律短語邊界後的停頓時長變化多端的來源並導出對比組型，得到以下結果：韻
律短語邊界前後的韻律詞時長與音強的明顯對比性，與邊界停頓時長無關。由此可見，相
鄰韻律狀態的相對性是韻律短語邊界更加重要的聲學語音特徵得到證明；同時，口語語流
中韻律短語的停頓時長變化如此多端也因此獲得更具系統性的解釋 (Tseng & Chang 
  11 
CNA 
f051 80.17% 81.46% 87.71% 
m051 81.53% 82.72% 88.20% 
 
3. 分析自發性課程口語篇章的韻律特性及跨語體韻律屬性比較，應有助辨識快語速連續語
流時可能遇到的信號失真問題。 
在跨語體韻律屬性比較方面，考量到目前語音辨識仍以單句且語速較慢的語料為主，
而在實際的應用中，快語速的連續語流是未來語音辨識所需解決的課題。從信號分析的角
度，連續語流中存有相當大程度的信號失真，我們因而預期若能獲得自發性口語韻律特徵，
應可用來提升辨識快語速且較模糊語音的正確率。本計畫執行期間，我們取得臺大電機系
李琳山老師「數位語音處理」的課程口語語料 NTU DSP Lecture Corpus（簡稱 NDLC，共
計 45小時），屬於自發性語料。課程講課的口語在性質上是準備充分的自發性語料，有別
於朗讀語料，多了自發性語料的特性；但相較於口語對話語料，課程口語語料不但少了許
多情感表達性副語言成分（如：笑、哭等情緒表現與情感交流意圖），課程口語還具有流
暢度高、篇章韻律訊息極為明確、語速快、強調成分多等特性。此外，語者咬字清晰、語
段分明，語音中使用上層語篇單位（higher level discourse unit）規劃的證據極為明確，是利
用 prosody研究 discourse unit、discourse speech planning、discourse automatic segmentation
極好的素材。由於資料量極為龐大，取得時只有文本轉寫，沒有任何語音標註。我們投入
許多人力，進行文本聽校、HTK文本轉音標以及音段邊界人工等語料前處理上，除此之外，
還有訓練有素的標音員依聽感完成韻律邊界停延標記，才得以進行量化分析。分析課題如
下，主要為跨語體自發性口語語料 NDLC與朗讀語料的比較分析： 
(1) 跨語體、跨韻律格式韻律組織比較。語體有自發性口語語料與朗讀語料二類，韻律格式
則有自發性口語 NDLC/ SpnNS、朗讀散文 CNA（平鋪直敍長段落）與古典詩詞 CL三
類。比較以下 HPG架構特性：語篇規劃範圍，語篇邊界中短語層的語速調節，
主題轉換的整體短語基頻走勢組型等。獲得自發性口語語料與朗讀敍事語料的一致性與
差異性組型，及自發性語篇韻律的韻律特徵。結果顯示：與朗讀語料相比，自發性課程
口語語料是由較大範圍語段所構成（NDLC/ SpnNS: 654音節；RS: 77-90音節），語句
段落的韻律構組較朗讀複雜，語速是朗讀語料的 2-3倍，表示語者可運用較大的規劃尺
度（planning scale）傳遞主題明確組織完整的敍事訊息，支持了規劃尺度與認知閾限靈
活性的研究假說。亦即規劃良好的自發性口語語料的資訊結構性具清晰主題，因而與且
戰且走的朗讀語料不同。此外，分析相關聲學參數後也發現：複雜語句形成長篇語段時，
語段內表「主題持續效應」（topic on-going effect）關連性的特徵，與語句間語速的快
慢調節有關；而語段間表主題轉換（topic change）的特徵，則與上層韻律邊界特性及韻
律單位結尾之基頻組型、停頓時長有關。簡言之，以上表語段關連性及主題轉換性之韻
律特徵，均與階層式的語篇韻律單位有關，呈系統性對應，共構出韻律輸出的變異。
（Tseng et al 2008）。 
(2) 區辨跨語體自發性課程口語語料與朗讀語料的韻律邊界聲學參數有何不同?我們分別檢
驗自發性口語語料與朗讀語料中的(a.) 獨立(單一)語音聲學參數與相依(成組)語音聲學
參數的邊界區辨力，包括：  邊界停頓 邊界前音節時長邊界前音強時長反差
  13 
highlight）的節拍（tempo）組型（如圖 4所示），而且，在短語 PPh層以及更上一層
BG層的音高與音強組型也不盡相同。在 RS中，大多數與短語突顯（phrasal prominence）
對應的感知強調並無明顯的節拍變化，仍保持語篇的連貫性，而 SpnNS在不同的韻律
層因為關鍵訊息不同的分布與位置則具有更加複雜的節拍調節組型。其中最值得注意的
是在段落結尾是關鍵訊息分布最多的地方，造成韻律邊界成分出現沒有單位結尾延長
（unit-final lengthening）的輸出變異(Tseng et al. 2010)。 
 
 
圖 4自發性口語語料 SpnNS（上圖）與朗讀敍事語料 RS（下圖）節拍（tempo）組型 
 
4. 比較跨語體朗讀語料與自發性課程口語語料感知強調/韻律突顯（prosodic highlight）組
型，增進語篇結構與資訊結構對應的瞭解。 
在跨語體韻律感知強調方面，上述透過跨語體資訊結構比較分析，得到：朗讀語料與
自發性口語語料具有不同的感知強調/韻律突顯組型，我們便進一步想瞭解：口語連續語流
中的韻律突顯組型是否語體相關（genre related）？如何與語篇結構（DS）產生交互作
用？如何顯示語言深層的資訊結構？是否可由大量的語料分析得出系統性的聲學組
型？是否分層疊加於語篇結構之上？所獲結果顯示：韻律突顯組型與語體相關，不同語
體具有不同的韻律突顯組型；連續語流中關鍵信息分布的不同可歸因於語言內容與溝通需
求；韻律突顯是疊加於語篇韻律結構之上、額外的語言訊息。韻律突顯功能在於傳達口語
語流中的重要資訊，而語篇韻律結構則表達著語言關連性，二者各有所指，因而並不衝突
(Tseng et al. 2011)。 
  15 
5. Shriberg, E., A. Stolcke, D. Hakkani-Tur, & G. Tur (2000). “Prosody-Based Automatic 
Segmentation of Speech into Sentences and Topics”, Speech Communication 32(1-2), 
127-154 (Special Issue on Accessing Information in Spoken Audio). 
6. Tseng, Chiu-yu, Pin, Shao-huang and Lee, Yeh-lin (2004). “Speech prosody: Issues, 
approaches and implications” in From Traditional Phonology to Modern Speech Processing 
(語音學與言語處理前沿), edited by Fant, G., Fujisaki, H., Cao, J. and Xu, Y., Foreign 
Language Teaching and Research Press (外語教學與研究出版社), 417-437, Beijing, China.  
7. Tseng, Chiu-yu, Pin, ShaoHuang and Lee, Yeh-lin, Wang, Hsin-min and Chen,Yong-cheng 
(2005). “Fluent Speech Prosody: Framework and Modeling”, Speech Communication 
(Special Issue on Quantitative Prosody Modeling for Natural Speech Description and 
Generation), Vol. 46:3-4, 284-309. 
8. Tseng, Chiu-yu and Fu,Bau-Ling (2005). “Duration, Intensity and Pause Predictions in 
Relation to Prosody Organization” Interspeech 2005, (September 4-8, 2005), Lisbon, Portugal, 
1405-1408. 
9. Tseng, Chiu-yu (2006). “Prosody Analysis” in Advances in Chinese Spoken Language 
Processing, edited by Chin-Hui Lee, Haizhou Li, Lin-shan Lee, Ren-Hua Wang, Qiang Huo, 
World Scientific Publishing, 57-76, Singapore. 
10. Tseng, Chiu-yu, Su, Zhao-Yu, Chang, Chun-Hsiang and Tai, Chia-Hung (2006). “Prosodic 
Fillers and Discourse Markers—Discourse Prosody and Text Prediction” TAL 2006 (The 
Second International Symposium on Tonal Aspects of Languages), (April 27-29, 2006), La 
Rochelle, France. 109-114. 
11. Tseng, Chiu-yu and Chang, Chun-Hsiang (2007). “Pause or No Pause?–Prosodic Phrase 
Boundaries Revisited.” Accepted to 清華大學學報—2007第九屆全國人機語音通訊學術
會議 NCMMSC特刊.  
12. Tur, G., Hakkani-Tur, D., Stolcke, A. & Shriberg, E. (2001). ”Integrating Prosodic and Lexical 
Cues for Automatic Topic Segmentation”, Computational Linguistics 27(1), 31-57.  
13. Yamazaki, H., Iwano, K., Shinoda, K., Furui, S. and Yokota, H. (2007). “Dynamic Language 
Model Adaptation Using Presentation Slides for Lecture Speech Recognition.” Interspeech 
2007, August 27-31, Antwerp, Belgium. 
  17 
八、 計畫自評 
1. 研究內容與原計畫相符程度及達成預期目標情況 
本計畫為三年期研究計畫（97.8-100.10），原計畫書擬申請總經費為新台幣 4,299,721
元，核准經費為新台幣 2,101,000元，為原申請額之 48.86％。分三年發放，第一年新台幣
678,000元，第二年新台幣 680,000元，第三年新台幣 743,000元。 
我們以不及原計畫提案二分之一的經費，盡最大努力，在先前的研究基礎上，配合原
執行規劃進行，得到不少具體的研究成果。無論是為偵測語流中的韻律邊界特性，可供辨
識韻律單位所需的資訊，提出新的答案（2008附件一）。或者在韻律邊界和韻律語境方面，
提出「連續語流中整體韻律脈絡（global prosodic context）」新觀點，有助語音辨識率的提
升（2008附件二）。還有分析自發性課程口語篇章的韻律特性及跨語體韻律屬性方面，比
較自發性課程口語語料與朗讀語料在語篇規劃以及語速上的差異（2008附件三），找出不
同聲學參數在區辨自發性課程口語語料與朗讀語料的語篇韻律邊界的不同之處（2009附件
四、附件五）。最後口語語篇中資訊結構組型比較分析方面，得到自發性課程口語語料與
朗讀語料各自具有不同的感知強調/韻律突顯（prosodic highlight）的節拍（tempo）組型（2010
附件六、2011附件七），而且韻律突顯組型與語體相關，不同語體具有不同的韻律突顯組
型（2011附件八）。整體而言，就能夠執行的部分，所達到的結果較預期為高。無法執行
的部分則為：透過韻律突顯的表徵，定義出口語語篇中語意焦點的階層性，主因是刪減後
的經費不允許我們在人力上做原先規劃的配置。 
2. 研究創獲的理論意義及應用 
以上研究成果，在以下幾方面對已知的現象增加了新的知識：（1）對文獻中為人熟知
的邊界前的延長現象，在語篇的架構下獲知，延長的單位不僅限一個音節，而是對應語篇
單位有系統性各有其模版。（2）所謂的韻律語境，並不僅限於文獻中所稱的線性的 co-location
訊息，其實，也同時了包含上層管轄單位的階層性訊息。（3）文獻中將突顯、強調都單純
的視作小單位現象，卻不知在不同語篇單位、所處較大單位的位置，都對整個語篇單位的
行進速度息息相關，不能將其抽離所在單位獨立檢視，否則無法瞭解行進時整體快慢調整
的由來。（4）通過標準化的測試，我們更精確的獲得突顯是疊加到語篇架構上的證據。以
上種種，都使我們對語音信號中的整體訊息(global information)與局部訊息(local information)
有了文獻中前所未有的瞭解。我們認為，這些瞭解對於解決辨識快語速連續語流時可能遇
到的信號失真問題，以及提取出口語語流中的重要關鍵訊息，具有關鍵性的知識意義。  
執行本計畫所獲之韻律邊界研究結果：（1）可應用在語流的自動語音切分（automatic 
speech segmentation）。（2）從相對或對比性的角度，為語音學重要課題「邊界停頓」、「邊
界延長」對其定義加以提出對立性區辨修訂。（3）提出語段內的邊界與語篇組織相關的證
據，對於增進韻律邊界的瞭解，是重要的研究結果。 
韻律邊界及資訊結構研究結果：（1）可應用於語流中的關鍵詞擷取（Keyword 
Spotting）、主題轉換（topic change）與訊息權重（information weighting）技術發展。（2）
提出自發性口語語料語段內邊界與語篇組織相關韻律特性的研究證據，增進自發性口語語
料韻律邊界特性的瞭解。（3）在語篇架構的基礎上，成功的從信號中釐清語篇結構 DS 
TSINGHUA SCIENCE AND TECHNOLOGY 
ISSN 1007-0214 12/22 pp500-509 
Volume 13, Number 4, August 2008 
 
Pause or No Pause?—Prosodic Phrase Boundaries Revisited 
TSENG Chiu-Yu (郑秋豫)**, CHANG Chun-Hsiang (张俊祥) 
 
Phonetics Lab, Institute of Linguistics, Academia Sinica, Taipei 11529 
 
Abstract: This study presents evidence from analyses of the acoustic parameters of fluent continuous 
speech to show that within-paragraph prosodic phrase boundaries are related more to contrasts of 
neighborhood prosodic states rather than between-phrase pause durations; prosodic states receive more 
constraints from higher level discourse information. By revising a modular acoustic model by Tseng’s hier-
archical prosodic phrase grouping framework and examining the much varied prosodic phrase (PPh) 
boundary B3 within speech paragraph, we show that statistical accounts of layered contributions reveal dis-
tinct contrasts between boundary immediate duration and intensity patterns irrespective of pause duration. 
Contrasts of F0 contour patterns were also observed in these locations. Evidence was also obtained to illus-
trate how PPh boundary states are specified more by higher level discourse information than by lower level 
prosodic word construction. These combined results suggest that contrastive neighboring prosodic states 
are more significant cues to PPh boundaries than boundary pause duration. The results also help explain 
why in fluent speech between-phrase pause durations vary greatly, and can be applied to automatic speech 
segmentation.  
Key words: fluent speech prosody; hierarchical prosody group; prosodic state; prosodic phrase; boundary  
break; discourse prosody; linear regression model  
 
Introduction 
In previous work we have collected various types of 
fluent Mandarin speech data from read narratives in 
COSPRO[1] and designed annotations on the basis of 
perceived boundary breaks in relation to prosodic units. 
Our hierarchical prosodic phrase grouping (HPG)[2-4] 
specifies multiple-phrase speech paragraphs as a sig-
nificant discourse prosody unit above phrases. The 
COSPRO annotation[5] specifies 5 levels of within- 
paragraph boundary breaks, i.e., from lower levels 
upward the syllable (Syl) boundary B1, the prosodic 
words (PW) boundary B2, the prosodic phrase (PPh) 
boundary B3, the change-of-breath (breath group  
(BG)[6]) boundary B4, and the prosodic-group (PG) 
terminal boundary B5, where physical pauses apply 
from B2 to B5. We have shown from quantitative 
analyses of speech corpora that output prosody of mul-
tiple-speech paragraphs is not unrelated phrase strings, 
but rather the cumulative outcome of contributions 
from all prosodic layers specified by HPG[3,4]. Further, 
central to fluent speech prosody is the contribution 
from above-phrase higher level information related to 
discourse organization, in which phrases and sentences 
are all prosodic subunits of each speech paragraph, 
where speech paragraphs are subunits of spoken dis-
course. Among each and every prosodic level, prosodic 
boundaries in relation to discourse prosody organiza-
tion are significant cues. Perceived boundary breaks 
are therefore significant prosodic units as well. 
However, in a previous study[7] it was discovered 
 
 
 Received: 2007-10-24 
** To whom correspondence should be addressed. 
E-mail: cytling@sinica.edu.tw; Tel: 886-2-26525000-6143 
  Tsinghua Science and Technology, August 2008, 13(4): 500-509 
 
502 
Table 1 Derived acoustic features by speaker 
Speaker μPause σPause μDuration σDuration μIntensity σIntensity
F051P 37 106 200 65 3.65 0.07 
M051P 45 138 190 60 3.62 0.05 
1.3 Speech data normalization 
In order to eliminate between-speaker variations, each 
set of data was normalized with the mean and standard 
deviation of the entire class. The original method of 
normalization[4] is sensitive to extreme data, causing a 
shift in the normalized data distribution, and thereby 
making comparisons between speakers meaningless. 
To overcome the problem, the normalization was 
modified as follows: 
nor
nor nor nor nor
( ) ( ( ) ( )) / ( ),
{ (1), (2), ..., ( )},
Y i Y i Y Y
Y Y Y Y n
μ σ= −
=  
where Y(i) and Ynor(i) represent each datum in class Y 
and normalized class Y, and μ(Y) and σ(Y) represent the 
mean and standard deviation in class Y. The same 
modification was made for each of the three acoustic 
features under consideration. 
1.4 Revising the duration model 
A syllable duration model corresponding to the HPG 
framework was constructed previously[7] to predict and 
locate boundary breaks B2 to B5 across continuous 
speech rather than simply predicting pauses. The pre-
dictions thus bear discourse information in relation to 
prosody organization specified by HPG. Higher level 
BG and PG boundary breaks (B4 and B5, respectively), 
which indicate multiple-phrase speech paragraphs 
across fluent continuous speech, could be easily lo-
cated using pause durations alone, whereas lower level 
within-paragraph boundary breaks (B3 and B2 corre-
sponding to PPh and PW, respectively) were predicted 
using both boundary break pause and duration infor-
mation of one immediate neighboring syllable. 
The goal of the present study is to revise the syllable 
duration model by altering both the syllable (the bot-
tom) layer and the PW (the immediate higher) layer of 
the previous regression model to allow a better predic-
tion of the PPh boundary B3. Using the same step-wise 
regression technique[2,3], a linear model with four lay-
ers[9,10] was modified and developed to predict speak-
ers’ timing behavior through temporal allocation of 
syllable duration modification. At the syllable layer, 
we used 6 consonant groups and 6 vowel groups to 
decrease the difference between groups. The revised 
syllable layer model could be written as Eq. (1): 
Ynor = Const+CCt+CVt+CTt+PCt+PVt+PTt+FCt+FVt+ 
FTt+2-way factors of each factor above+ 
3-way factors of each syllable above+ 
PW boundary constraint of each factor above+ 
Deltal (1) 
In Eq. (1), we added a new condition that is con-
strained for each factor in the PW boundary to include 
co-articulation effects, such as tone sandhi, at the PW 
layer. The prefixes C, P, and F represent the current, 
preceding, and following syllable, respectively. Ct, Vt, 
and Tt represent consonant, vowel, and tone type, re-
spectively. Residuals (Delta1) that cannot be predicted 
by the syllable layer are analyzed in the immediate 
higher layer. 
Figure 2 shows the distribution of Delta1 (the re-
siduals of the syllable layer) of the revised duration 
model from the speech data. The horizontal axis repre-
sents breaks from B1 to B5, and the vertical axis 
represents the residual value from –2 to 3. A significant 
difference (p < 0.001) was found with respect to the 
durations between the distributions of B2 and those 
 
Fig. 2 Distribution of Delta1 of the revised duration 
model for speakers F051P and M051P. The block indi-
cates the interval of standard deviation for one dura-
tion distribution and the beeline in the block denotes 
the mean value of the distribution. 
  Tsinghua Science and Technology, August 2008, 13(4): 500-509 
 
504 
subsequently. 
We also analyzed the distribution of B3 pauses in 
relation to punctuation marks in the text used. B3 oc-
currences in the speech data in relation to punctuations 
of comma, period, and zero punctuation in text were 
analyzed; and their distributions were calculated 
(Fig. 5). The results indicate that the value of the B3 
pause is indeed affected by the presence of punctuation 
marks, and that the mean values of B3 follow the se-
quence period > comma > no punctuation mark. In 
other words, although both speakers paused where no 
punctuation marks appeared in the text, the presence of 
punctuation marks resulted in more B3 occurrences in 
the speech data. 
 
Fig. 5 Distribution of pauses as punctuation mark in 
B3 for F051P and M051P 
According to these results, we categorized three 
groups of punctuation marks according to the mean 
values. In this way we can use punctuation marks as a 
feature of the PPh layer model, as shown in Eq. (6). 
Delta1 (mark group, PPh length, PPh sequence)f= +  
        Delta2  (6) 
The BG layer model is the same as our previous 
model, 
Delta2 (BGIMF, PPh length, PPh sequence)f= +  
           Delta3  (7) 
2  Results 
2.1 Comparison of duration predictions 
Figure 6 shows the duration patterns of PW (1-4 sylla-
bles in length) along the temporal course by syllable 
number and by speakers from the previous model[7], 
while Fig. 7 shows patterns from the current revised 
model. Each line represents the corresponding regres-
sion coefficient of one syllable at the specific position 
in a prosodic word. From Figs. 6 and 7 we can see that 
the PW patterns from the previous model show an op-
posite behavior to the revised models. In particular, the 
previous model showed final syllable lengthening of 
PW by syllable number and across speakers, whereas 
the revised model shows the reverse, namely, final syl-
lable shortening PW by syllable number and across 
speakers. In general the results from the revised model 
attribute less contribution from the PW layer to the 
total output prediction. 
 
Fig. 6 PW patterns of the previous duration model 
for speakers F051P and M051P. PW’s are from 1 to 4 
syllables. 0 on vertical axis is defined as the mean of 
syllable duration. Each line represents the corre-
sponding regression coefficient of one syllable at the 
specific position in a prosodic word.  
  Tsinghua Science and Technology, August 2008, 13(4): 500-509 
 
506 
2.2 Comparison of intensity predictions 
Figure 10 shows the intensity patterns of PW (1-4 syl-
lables in length) along the temporal course by syllable 
number and by speaker from the previous model, and 
Fig. 11 shows patterns from the current revised model. 
Similar to the results from the revised duration model, 
the revised intensity prediction patterns at the PW layer 
are also opposite to the previous predictions. Figures 
12 and 13 show the intensity distribution of PPh pat-
terns from both the previous and revised models. In 
each case the PPh’s range from 6 to 11 syllables. Note 
that the PPh patterns from the revised model decay 
more sharply towards each boundary, thus matching 
the tendency of the intensity attenuation for PPh final 
weakening, especially for speaker M051P. Once again 
the cross-boundary contrast is more pronounced in the 
intensity predictions. Coupled with the increased phrase- 
final syllable lengthening found in Section 2.1, the 
prediction is closer to physical speech data. Therefore, 
we believe that the cross-boundary contrasts in both 
duration and intensity patterns are significant cues to 
boundary perception regardless of the boundary pause 
duration. 
 
Fig. 10 PW patterns of the previous intensity model 
for speakers F051P and M051P. 0 on vertical axis is de-
fined as the mean of syllable intensity. Each line repre-
sents the corresponding regression coefficient of one 
syllable at the specific position in a prosodic word.  
 
Fig. 11 PW patterns of the revised intensity model for 
speakers F051P and M051P. 0 on vertical axis is de-
fined as the mean of syllable intensity. Each line repre-
sents the corresponding regression coefficient of one 
syllable at the specific position in a prosodic word.  
 
Fig. 12 PPh patterns of the previous intensity model 
for speakers F051P and M051P. 0 on vertical axis is 
defined as the mean of syllable intensity. 
  Tsinghua Science and Technology, August 2008, 13(4): 500-509 
 
508 
above, we also studied B3 in more detail. We further 
analyzed the performance of duration and intensity 
predictions for cases where between-PPh pause B3 
values were smaller than the B2 values. These are 
cases that contradict the annotation definition but are 
still consistently perceived by transcribers. Accord-
ingly, we defined two conditions to analyze short B3 
pauses: (1) where the lengths of the preceding and fol-
lowing PPhs are equal to or over 6 syllables, and (2) 
where the maximum pause of B2 is used as a B3 
threshold. 
The analysis of short B3 pauses for duration and in-
tensity distributions is depicted in Figs. 15 and 16. In 
Figs. 15 and 16, we chose to include the last 4 syllables 
of the preceding PPh and the first 3 syllables of the 
following PPh at B3 for analysis. Except for the first 3 
syllables of the following PPh of intensity for M051P, 
there are significant differences between the preceding 
and following syllables of B3. These results also indi-
cate that our previous model attributed more contribu-
tion from the lower PW layer to output prosody, 
whereas the revised model entails instead more con-
tribution from the higher PPh layer. Since the revised 
model yielded better overall predictions,  it is clear that 
 
Fig. 15 PPh patterns of the duration model for F051P and 
M051P. PW’s are from 1 to 4 syllables. 0 on vertical axis is 
defined as the mean of syllable duration.  
increased contribution from higher level information 
accounts for the speech data better, hence proving fur-
ther the significance of higher level contribution to the 
prosody output and showing how such information is 
perceived. 
 
Fig. 16 PPh patterns of the intensity model for F051P and 
M051P. 0 on vertical axis is defined as the mean of syllable 
intensity.  
3 Discussion 
Instead of analyzing the duration and intensity patterns 
of one syllable before and after each annotated PW and 
PPh boundary break, as in a previous model[5,7], here 
we have analyzed the B3 boundary immediate prosodic 
states, in terms of the duration and intensity distribu-
tion along the time domain, using PW (4 syllables be-
fore and 3 syllables after). A comparison with the 
analysis from only immediate neighboring B2 state 
reveals different yet corresponding patterns in these 
two acoustic parameters. Accordingly, we have in-
cluded factors of duration and intensity to revise and 
fine-tune the linear regression model[7], and recalcu-
lated the predicted contributions from the PW layer to 
the final prosody output under the HPG framework. 
The TRE of duration and intensity at the PW layer is 
What’s in the F0 of Mandarin Speech 
--Tones, Intonation and beyond 
Chiu-yu Tseng 
Institute of Linguistics, Academia Sinica 
Taipei 
cytling@gateˁsinica.edu.tw
Abstract—We analyzed F0 contours of fluent Mandarin speech 
using a modified command-response model. Adopting the 
multiple-phrase speech paragraph as a discourse prosodic unit, 
we investigated the composition of F0 contours to see whether 
additional prosodic information beyond tones and intonation 
exists. Testing F0 contributions with a previously constructed 
prosody hierarchy the HPG (Hierarchy of Prosodic Phrase 
Grouping), results showed that tone identities only make up 40-
45% of output F0 while other higher layers of information 
contributes to the rest. Final F0 output is cumulative of all 
layers combined. The results thus provide an account of why 
prosodic context consists of both adjacent and cross-over 
associations and how global prosodic context is reflected in the 
formation of output F0. We believe these results shed new lights 
on speech technology development. 
Keywords HPG, tones, intonation, higher-level contributions, 
prosody context, F0 contour, cross-over, adjacency. 
I. Introduction 
Mandarin tones by syllable have been considered the most 
significant prosodic feature of Mandarin speech. Most 
Mandarin ASR efforts aim mainly at tone identification. 
However, we have studied the prosody of fluent Mandarin 
speech extensively and found even tones and intonation 
combined is insufficient to characterize fluent Mandarin 
prosody, and prosody units require re-definition. We have 
constructed a prosody framework the HPG (Hierarchy of 
Prosodic Phrase Group) by adopting the multiple-phrase 
speech paragraph as a prosodic unit, and demonstrated how 
each prosodic unit from prosodic word (PW), prosodic 
phrase (PPh), and phrase groups (PG) contributes to output 
prosody. [1] [2] [3] Most importantly, the HPG framework 
specifies layer-dependent prosodic contributions, thus 
accommodating more source of overall prosody information 
from different size of unit. In particular, how at the phrase 
level, a three-way patterned specification indicating the 
initiation, continuation and termination of a paragraph forms 
the obligatory prosodic context in output prosody that 
contains both adjacent and cross-over associations of within-
paragraph phrases, as well as paragraph association that 
forms the larger discourse. It was evident that prosodic 
context goes beyond tone and intonation concatenation and 
smoothing. Breaking down fluent speech into units of tones 
and intonation only makes it impossible for higher level 
prosodic context to surface. 
In the following study, we will present corpus analysis the 
F0 contours by the HPG prosodic units the Syllable (SYL), 
PW, PPh and PG to illustrate F0 patterns could be derived at 
each and every unit and why no single unit accounts for 
output prosody. In particular, how quantitatively these units 
contribute to output F0. Finally, we will discuss the 
implication of better understanding of F0 composition to 
speech technology development. 
Zhao-yu Su 
Institute of Linguistics, Academia Sinica 
Taipei 
morison@gateˁsinica.edu.tw
II. Speech material 
Two types of text were used: (1.) Plain text of 26 random 
discourse pieces (CNA, approximately 6700 syllables), and 
(2.) three rhyme formats of Chinese Classics (CL 
approximately 1600 syllables). One male and one female 
read each text type at sound proof chambers into 
microphones. A total of 4 sets of speech corpora were 
obtained, namely, M051 and F051 for CNA and M056 and 
F054 for CL. Pre-analysis included automatic annotation of 
segmental labeling by the HTK toolkit were first obtained 
using the SAMPA-T notations [4], then spot-checked for 
segmental alignments by trained transcribers. Manual 
tagging of perceived prosodic units and boundary breaks was 
performed using the Sinica COSPRO Toolkit [5]. The mean 
syllable duration is 199ms and 189 ms for F051 and M052 
(data type CNA); and 265ms and 202ms for F054 and M056 
(data type CL), indicating positive cross-speaker correlation 
of duration style and format may be inherently related to 
speaking rate regulation.  
III. F0 Analysis
A. Analyze F0 contour using the command-response model 
The physiology based command-response model, commonly 
known as the Fujisaki model, was used to analyze F0 
contours. [6] The model can be decomposed into three 
components and major corresponding parameters including 
base frequency, a Phrase command Ap indicating the 
magnitude of global contour of a phrase and Accent 
command Aa indicating local humps of smaller domain. Aa 
is superimposed onto Ap to derive the ultimate output F0 
contour. The model inherently assumes that F0 is generated 
from more than one component differing in size and scale, as 
defined as below. 
When the model is used to analyze tone languages, it has 
been commonplace that the Ap command is applied to 
phrase units to represent the intonation contour pattern, and 
the Aa command to the syllable to represent tones. We 
modified methods by Mixdorff [7] [8] to auto extract the Ap 
commands,  fitting one Aa to the syllable only while the 
scale selected for Ap is one PPh each time [9]. In the 
45978-1-4244-2942-4/08/$25.00 (c) 2008 IEEE
Pro
of
ˀ˃ˁˈ
˃
˃ˁˈ
˧̂́˸˄ ˧̂́˸˅ ˧̂́˸ˆ ˧̂́˸ˇ ˧̂́˸ˈ
˖˟ʳ˙˃ˈˇ ˖˟ʳˠ˃ˈˉ ˖ˡ˔ʳ˙˃ˈ˄ ˖ˡ˔ʳˠ˃ˈ˄
Figure2. Tone model of Aa. The horizontal and vertical-axis 
indicate the tone index and average Aa value, respectively.  
C. PW model of Aa 
We classified the PW by three PG positions –Initial, -Medial 
and -Final to observe the PW model of Aa irrespective of 
tone effects. Figure 3 shows PW-final syllables exhibited 
pre-boundary F0 lowering while no obvious reset was found 
in other positions. Similar pre-boundary declination is found 
in all three PG-initial positions across speakers except for 
speaker f051 though the degree of declination differs by PG 
positions. However, the second syllable into PW at –initial 
and –final positions may vary, perhaps due to stress and/or 
other prosody effects that merit further investigation in the 
figure.  
Figure3. PW model of Aa by PG positions. Each trajectory denotes 
PW model for specific PW length. The horizontal and vertical-axis 
indicate the Syl sequence index in PW and average Aa value, 
respectively.  
Figure 4 shows PW model of Aa by PPh-position. 
Declination of Aa is found in PW-final of PPh-medial 
positions while   PPh-medial positions exhibited a more 
general pattern across speakers. In addition, the sharpest 
declination slope is found at PPh-final positions across the 
board, indicating pre-boundary declination is systematic by 
prosodic unit.  
Figure4. PW model of Aa by PPh position. Each trajectory denotes 
PW model for specific PW length. The horizontal and vertical-axis 
indicate the SYL sequence index in PW and average Aa value, 
respectively.  
D. BG & PG model of Ap 
Figures 5 and 6 shows higher level Ap models above the PPh, 
namely, the PG & BG models. Both models show similar 
tendency across the 4 speakers. Figure 5 shows the within-
PG adjacent as well as cross-over association of phrases by 
PG-position, namely, adjacency from PG-initial to –medial 
to –final and cross-over between -initial and –final.  Figure 6 
shows between-paragraph association and the –final to –
initial contrasts in pitch.  
ˀ˃ˁˇ
ˀ˃ˁ˅
˃
˃ˁ˅
˃ˁˇ
ˣ˚ˀ˜́˼̇˼˴˿ʳ ˣ˚ˀˠ˸˷˼˴˿ ˣ˚ˀ˙˼́˴˿
˙˃ˈ˄ ˠ˃ˈ˄ ˙˃ˈˇ ˠ˃ˈˉ
Figure5. PG model of Ã by PG position. The horizontal and 
vertical-axis indicate the PG-position index and average Ap value, 
respectively. 
ˀ˃ˁ˅
˃
˃ˁ˅
˕˚ˀ˜́˼̇˼˴˿ʳ ˕˚ˀˠ˸˷˼˴˿ ˣ˚ˀ˙˼́˴˿ ˦˼́˺˿˸ˀˣˣ˻ʳ˕˚
˙˃ˈ˄ ˠ˃ˈ˄ ˙˃ˈˇ ˠ˃ˈˉ
Figure6. BG model of Ã by BG position. The horizontal and 
vertical-axis indicate the BG-position index and average Ap value, 
respectively.  
47978-1-4244-2942-4/08/$25.00 (c) 2008 IEEE
Pro
of



BOUNDARY AND LENGTHENING                                 
— ON RELATIVE PHONETIC INFORMATION 
TSENG Chiu-yu, SU Zhao-yu  
ABSTRACT 
The aim of the present study is to better understand the temporal structure of discourse prosody 
through relative phonetic information, in particular, phrase final lengthening and discourse 
boundary discrimination. Using data of fluent Mandarin narrative speech, we tested two 
assumptions to compare their contributions to discourse boundary discrimination, namely, 
independent/single vs. integrated/paired acoustic cues. Single factors included five acoustic features 
to see whether the identities of discourse boundaries can be discriminated, namely, (1) boundary 
pause (BP), (2) pre-boundary duration (PrDu), (3) pre-boundary intensity (PrIn), (4) duration 
contrast (DuCon) and (5) syllable intensity contrast (InCon). Relative factors were ten paired 
combinations from the above five features to test their respective contributions to discourse 
boundary discrimination as well. The results demonstrated that single discrete cues were not as 
discriminative as paired ones, suggesting that boundary information is related to relative combined 
cues. Among the paired combinations, the combined cue of pre-boundary syllable duration and the 
following pause, PreDu+BP, is most discriminative. We further examined pre-boundary 
lengthening in relation to discourse organization by three discourse prosody units: the syllable, the 
prosodic word (PW) and the prosodic phrase (PPh), and found pre-boundary global lengthening by 
the PPh is systematically related to higher-level discourse specifications. The results suggest that 
discourse constrained tempo modulation across speech flow is default within the same speaking 
rate. Therefore, we argue that temporal planning is constrained by higher-level discourse planning; 
higher level planning induces overall lengthening; global lengthening reflects cognitive load. In 
addition to phone- and syllable-contributed factors, discourse temporal organization is also 
constrained by discourse unit. 
Keywords: discourse boundary, boundary discrimination, final lengthening, relative phonetic 
information. 
1. INTRODUCTION 
In previous work on narrative prosody, we have established a hierarchical discourse framework the 
HPG (Hierarchy of Prosodic Phrase Group) through corpus analysis [8]. The discourse perspective 
allows examination of fluent speech prosody from top-down; it also makes possible clarifications 
of terms used for phonetic, phonological and prosody investigations. While the segments are 
phonetic terms [6][5], terms like syllable, prosodic word, intonation phrase (IP) are phonological 
terms [4][7] often used interchangeably as phonetic units or prosodic units as well [3][1]. However, 
in a discourse prosody framework pitch (perceived relative F0), rhythm and tempo (temporal 
structure and distribution), loudness (perceived relative strength), boundary lengthening (rather 
than phrase final lengthening) and boundary pause are all but relative prosodic phenomena in 
relation to discourse organization. Therefore, by default the syllable (Syl), prosodic word (PW), 
369 
C.Tseng, et al.                                                        Boundary and Lengthening—On Relative Phonetic Information 
by professional transcribers for identities and alignments. Table1 summarizes the speech material 
by corpus type, speaker, and the number of the HPG prosodic units and boundaries.  
Table 1: Summary of speech data by corpus type, speaker, and the HPG prosodic units and boundaries. 
The HPG prosodic units are the syllable (SYL), prosodic word (PW), prosodic phrase (PPh), breath 
group (BG) and phrase group (PG).Corresponding HPG boundaries following each of the prosodic 
units are B1, B2, B3 B4 and B5 respectively. 
corpus speaker SYL/B1 PW/B2 PPh/B3 BG/B4 PG/B5 
F051 6583 3468 1092 297 151 
CNA 
M051 6661 3332 1207 270 129 
F054 1444 599 290 135 58 
CL 
M056 1551 619 318 142 47 
The mean syllable durations for speakers F051 and M052 are 199ms and 189 ms; the mean 
syllable durations for speakers F054 and M056 are 265ms and 202ms. Taken as a reference to 
speaking rate, we found a positive correlation by speech material than by speaker. The above 
materials were used for all three experiments in the present study.  
2.2 Experiment 1 
We have stated in Section 1 that discourse prosody is mainly about semantic cohesion through 
relative associative information manifested in the supra-segmental domain. The rationale implies 
that using relative acoustic information would result in better generalized pattern and 
discrimination of discourse information than discrete acoustic information. Given that boundaries 
are important discourse information, three discourse boundaries, PPh boundary B3, BG boundary 
B4 and PG boundary B5, were selected as the categories of generalization and discrimination. 
Three discrete acoustic variables were chosen to test the generalization and discrimination. They 
are (1) boundary pause (BP), (2) pre-boundary syllable duration (PrDu) and (3) pre-boundary 
syllable intensity (PrIn). The following two steps were employed to examine patterns of 
generalization and boundary discrimination. 
Procedure 1. Whether a single acoustic factor is sufficient to generalize and discriminate 
discourse boundary identities  
The procedure involved testing whether generalization and discrimination could be achieved by 
any single acoustic factor. The average values of specified acoustic feature for B3, B4 and B5 were 
derived from the speech materials by speaker and by speech type. These derived mean values 
across B3, B4 and B5 were plotted as reference that denotes the tendency among boundaries by 
speech data type and speaker. We then compared the trajectories among different speech data to 
look for whether the best single acoustic factor with most generalized pattern could be identified. 
We also tested whether discrimination of discourse boundary identities could be attributed to any 
one of these single discrete factors.  
Procedure 2. Whether a relative acoustic factor is sufficient to generalize and discriminate 
discourse boundary identities 
The same rationale from Procedure 1 was utilized to test boundary generalization and 
discrimination, but using one relative acoustic factor at a time. Between-boundary duration contrast 
(BwDuCon) and between-boundary intensity contrasts (BwInCon) were calculated and used as the 
contributing factors. Between-boundary duration contrasts were defined by subtracted outcome of 
cross-boundary syllables. The same subtraction was applied to derive the between-boundary 
intensity contrasts as well. Both duration and intensity contrasts specify cross-unit as well as cross-
boundary relative acoustic information. The same averaging and comparison methods used in 
371 
C.Tseng, et al.                                                        Boundary and Lengthening—On Relative Phonetic Information 
pre-boundary intensity alone. In other words, although using paired single factors to bring out 
minimum relative information does not produce better discrimination across the board; paired 
factors still perform better than single features. 
 
 
Figure 1: Cross boundary discrimination by single acoustic features. Each panel denotes one specific 
acoustic feature. The horizontal axis represents the prosodic boundary indexes B3, B4 and B5. The 
vertical axis represents the coefficient of normalized values of boundary pause (BP), pre-boundary 
duration (PrDu) and pre-boundary intensity (PrIn), respectively. Zero at the vertical axis is defined as 
the mean of syllable duration. 
 
Figure 2: Cross boundary discrimination by single contrastive factors. Each panel denotes one specific 
contrastive feature. The horizontal axis represents the prosodic boundary indexes B3 to B5. The 
vertical axis represents the coefficient of normalized values between boundary duration contrasts 
(DuCon) and between boundary intensity contrasts (InCon). Zero at the vertical axis is defined as the 
mean of syllable duration and intensity. 
373 
C.Tseng, et al.                                                        Boundary and Lengthening—On Relative Phonetic Information 
Table 3: A list of average sum of final syllable duration and pause (sec by speech data type and 
speaker)  
corpus speaker B3 B4 B5 
F051 0.499738 0.607713 0.684998 
CNA 
M051 0.519527 0.800465 0.880004 
F054 0.52102 0.833563 1.007355 
CL 
M056 0.456447 0.679508 0.774484 
3.3 Experiment 3 
Figure 3 shows the phrase final duration patterns by HPG prosodic units--the syllable, the PW and 
the PPh across speech data and speaker. We noted that by analyzing the pre-boundary duration 
pattern of the final syllable alone, it revealed that consistent and patterned lengthening occurs 
before the B3 boundary, but not before higher boundaries B4 and B5. This result does not explain 
why discourse boundary identities could be consistently perceived across listeners. However, if the 
same inconsistency was found across all boundaries, which happened to patterns found for the PW, 
then lengthening may not be a reliable boundary cue and is related to the lower level phrase 
boundary only. However, when pre-boundary duration patterns were examined by PPh, similar 
patterns are found across speaker and data-type, as shown in the lower panel of Figure 3.  
Furthermore, the lengthening patterns of pre-boundary PPh are also consistent with discourse 
boundary type. Such consistency can be seen as evidence of higher level overall slowing down or 
lengthening by phrase, thus suggesting calculation of tempo, rhythm and speaking rate merits more 
sophisticated considerations. 
 
 
Figure 3: Cross boundary comparison of duration patterns by prosodic units--the syllable (SYL), the 
PW and the PPh. The horizontal axis represents indices of the speech data and speaker. The vertical 
axis denotes normalized average duration of prosodic units. 
375 
C.Tseng, et al.                                                        Boundary and Lengthening—On Relative Phonetic Information 
above segments and the syllable. Studies on boundary and lengthening were no exception. For 
example, a comprehensive investigation on Mandarin segment lengthening made important 
observations of how prosodic boundaries and pause occur between prosodic units instead of within 
units, and manifestation of pre-boundary lengthening bear prosodic functions to the phrase [14]. 
More recent studies reported on the role of lengthening with reference to prosodic boundary and its 
perceptual significance in continuous speech using the pre-boundary syllable [20][13], thus 
inadvertently suggested the syllable as the default unit of lengthening. Another study reported that 
lengthening is complemented by pause duration at prosodic boundaries, but the units did not go 
beyond the intonation phrase [17]. Perceptual studies reported that although the pause duration at 
sentence-final positions is significantly longer than that of phrase-final ones, the syllable duration at 
sentence- and prosodic-phrase-final positions was not significantly different [18]. Furthermore, 
although more recent studies reported how the degree of final lengthening is modulated by 
boundary types [2] and how segmental strengthening is relative to prosodic functions [15], little 
discussion with reference to discourse units and structure is discussed. In short, almost all of the 
previous studies have focused on modulation of segmental duration at the syllabic level. We noted 
also that even when the discourse factor was considered, there has been less reported account in 
relation to discourse organization. In particular, the relative aspect of timing structure with respect 
to boundary features and boundary identities in discourse prosody has been overlooked. We think 
that one reason of the oversight could be due to taking the phonetic or phonological unit IP 
(intonation phrase) as an independent prosodic unit, whereas by HPG account, an IP corresponds to 
a PPh which is a discourse and speech-paragraph sub-unit and therefore requires further discourse 
specifications by default. 
Interestingly, in one of the recent studies on the PPh boundary B3, we studied the much varied 
B3 pause duration not by the duration of pauses, but with respect to cross-unit contrastive patterns 
in the acoustic signals, and discovered that within PG phrase boundaries can be accounted for by 
boundary immediate contrastive patterns of duration and intensity without any pause information 
[12]. The findings thus explained why the within-PG phrase boundary B3 was consistently 
perceived across listeners irrespective of pause duration, even when there was no pause at the 
boundary. We discussed when processing fluent speech on-line, the listener makes use of crucial 
relative phonetic information related to prosody organization. In short, both neighboring and cross-
over prosodic references provide cues to global prosody; higher-level discourse organization is 
reflected in global units and boundaries in relation to each other. Therefore, discourse prosodic 
units should not be taken as discrete ones, nor should they be investigated when discourse context 
is removed and discourse organization/information absent.  
The results from Experiments 1 show that single factors are not discriminative of discourse 
boundaries. The results of Experiment 2 show that the identities of discourse boundaries can be 
discriminated when pre-boundary syllabic duration or intensity is combined with the following 
boundary pause. In other words, pre-boundary syllabic information by itself is not sufficient for the 
discrimination of boundary identities, but when coupled with the following pause, the combined 
feature proved to be adequate. The results suggest that when prosodic context is limited, a little 
extra relative information goes a long way. We believe that more high-level relative information is 
utilized by the listener to facilitate faster and easier on-line top-down processing.  
The results from Experiment 3 are most interesting because it provided evidence of how global 
lengthening could be represented and what its discourse function is. The results thus make direct 
reference to how overall timing modulation can be represented quantitatively and how lengthening 
occurs to the entire pre-discourse-boundary phrase. The evidences also show why in fluent speech 
lengthening is applied by prosody unit instead of by the syllable, and how global temporal planning 
is manifested. Consistent perceptual identification of discourse boundary identities echoes the 
finding, because listeners must make use of global relative information to facilitate on-line 
processing. Alternatively, the same results also imply that overall modulation of temporal 
377 
C.Tseng, et al.                                                        Boundary and Lengthening—On Relative Phonetic Information 
[16] 林焘（1983）探讨北京话轻音性质的初步实验。语言学论丛， 第 10辑。北京：商务印书馆。 
[17] 钱瑶、初敏、潘悟云 （2001）普通话韵律单元边界的声学分析。第五届全国现代语音学会议。中
国：北京，70-74。 
[18] 王蓓、杨玉芳、吕士楠 （2001）汉语韵律层级边界结构的声学相关物。第五届全国现代语音学会
议。中国：北京，161-165。 
[19] 郑秋豫 （2001） 语流中韵律结构的主要征信。 第 6 届全国语音通讯学术会议 (NCMMSC-6)， 
(Nov. 19-24, 2001)。中国：深圳，169-172。 
[20] 祖漪清、陈肖霞 （1999） 连续语流中的音节延长及其作用。第四届全国现代语音学学术会议。中
国：北京，58-63。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
379 


planning of the speaker who reads out loud to express mostly 
discourse coherence (DC); SpnL requires more elaborate 
planning of information structure (IS) in addition to DC. By IS 
we adopt a broad view to mean roughly structural and 
semantic properties of utterances relating to the discourse 
content, the actual and attributed attention states of the 
discourse participants, and the participants' attitudes, thus 
notions like focus, presupposition, given vs. new, theme vs. 
rheme and the various dichotomies such as topic vs. comment 
or focus, ground or background vs. focus, etc. are subsumed. 
[5] Our goal is to derive IS related prosodic patterns through 
perceptual and acoustic analysis of emphasis. Since patterns of 
pitch reset, duration modulation and loudness control are 
directly related to perceptual contrasts; their respective 
acoustic correlates the F0, duration and amplitude patterns will 
be examined. We further hypothesize that keywords and their 
occurrence in speech is syntax and discourse governed as well 
as speaker intended, thus reflecting more complex interaction 
of phrase-level (syntactic) and higher-level (discourse) 
planning of IS. The following analyses are thus two-fold, one 
analysis aims to compare the similarity and diversity between 
RS and SpnL for information distribution; another to derive 
acoustic and prosodic patterns that are directly related to 
allocation of information. 
 
Figure1 shows the distribution of perceived emphasis in RS 
and SpnL by 3 relative positions at the phrase level, namely, at 
the PPh-Initial, -Medial and –Final; as well as in relation to 
same-level prosodic boundaries B3 and higher-level 
boundaries B4 and B5.  
 
 
 
Figure 1 .The distribution of emphasis by discourse 
associative position, boundary location and speech 
data type.  The outer circle shows the distribution of 
emphasis by associative positions PPh-Initial,-Medial 
and Final. The inner circle shows the distribution of 
emphasis before and after PPh- local boundary B3 
and higher-level boundaries B4 and B5, respectively. 
 
In the following sections, we will focus on acoustic analysis of 
emphasis with respect to duration and tempo patterns by 
phrase and by speech paragraph, but less on F0 and intensity 
patterns. 
3.2. Normalized position of emphasis  
Due to different sizes of both the PPhs and BGs in the data 
sets, we first normalized the position of emphasis and plotted 
the distribution of number of emphasis in PPhs and BGs 
analyzed (Figure2). The normalization results enable us to 
better examine the location as well as allocation of emphasis 
in various PPhs/BGs. The equation of normalization is as 
follows. 
 
                                                                                            (1) 
 
where Emp and NEmp denotes original and converted 
emphasis position. BGS and BGD represent the onset time of 
BG and the duration of BG, respectively.    
3.3. Tempo modulation of emphasis regarding 
discourse information 
By tempo modulation we mean overall change of speaking 
rate by phrase in relation to each change of breathing cycle. 
Tempo modulation was examined by each phrase and by the 
number of emphases contained, length of the phrase, phrase 
position in a breathing cycle, and the duration of the one 
breath. A linear regression (LR) model of syllable duration 
was adopted to extract duration pattern by phrase [1], and 
parameters were modified to accommodate phrase level 
features. The rate by PPh is extracted and compared with the 
number of emphasis contained, PPh length, PPh position 
within BG and BG length. Below is the LR model for PPh 
tempo features. 
 
(2) 
 
where f denotes linear regression by multiple variables, T 
denotes the regression values for tempo feature of a current 
PPh and res denotes error in comparison with original values; 
EMN, PPhLen and BGP BGL denote the number of emphasis 
contained in the current PPh, the length of current PPh, the 
position in current BG and the length of current BG, 
respectively.     
3.4. Tempo of emphasis regarding rate of phrase  
In addition to tempo feature of emphasis defined in relation to 
discourse information (3.3.), a relative tempo feature of the 
emphasis itself is also defined by measuring the normalized 
rate of emphasis against the overall rate of its embedding 
phrase. The proposed relative measurements have been proven 
to better account the contrastive nature of supra-segmental 
features [6] and provide clearer picture of the speech data.  
 
                                                                                             (3) 
 
where TPEM and RTPEM denote the original tempo (derived 
in 3.3.) and relative tempo for emphasis, respectively. TPPPH 
is the original tempo feature of PPh in which the emphasis is 
embedded in.  
4. Results 
4.1. Emphasis (perceived keyword) distribution in 
BGs 
Patterns of emphasis  distribution between RS and SpnL are 
derived and shown in Figure 2. In RS, maximum distribution 
of emphasis is at the BG onset of BG and descends with BG 
positions, with least emphasis at the offset. In SpnL, the 
distribution of emphasis in SpnL assumes a pattern similar to 
Gaussian mixture model, where minimum emphasis occurs at 
the BG onset, two peak distributions in BG medium positions, 
and maximum distribution at the BG offset. In other words, 
two distinct patterns are found: emphasis in RS is at the 
beginning of the paragraph, and never at the end. Whereas in 
SpnL the pattern is almost reverse where emphasis never 
occurs at the beginning but with two high occurrences in the 
middle, spread across the speech paragraph, and marks the 
paragraph end. These results are interpreted as indication of 
key information distribution. BGDBGSEmPNEmP /)( −=
resBGLBGPPPhLenEMNfT += ),,,(
TPPPhTPEMRTPEM −=
 
RS 
-1
-0.5
0
0.5
1
Post-B4 Post-B5 Medium Pre-B3 Pre-B4
Post-Boun Medium Pre-Boun
 
Figure6. The relative tempo of emphasis by position in 
PPh and discourse boundary type. The upper and 
lower panels denote tempo relative tempo of emphasis 
for SpnL and RS respectively. The horizontal axis 
represents position PPh and boundary type. The 
vertical axis represents the relative tempo of emphasis 
and zero means the tempo of emphasis is equal to 
current PPh tempo. 
4.5. The distribution of F0 and intensity of BGs in 
SpnL 
In relation to results of tempo analysis of SpnL ( see 4.3 and 
lower panel of Figure 4) in which the slowest rate implies a 
dividing point corresponding to two high occurrences of  
perceived emphasis distribution (4.1), the distribution of mean 
F0 and intensity are also analyzed in search of corresponding 
dividing points (Figure 7). However, the results showed only 
overall declination of F0 and intensity by relative BG position, 
while no correlating patterns are found. These results suggest 
that perceived emphasis in Mandarin monologue is related 
mostly to tempo modulations rather than to F0 or intensity 
settings. 
 
Figure7. Distributions of mean F0 and intensity by BG 
positions. The horizontal axis represents relative 
position in BGs. The vertical axis represents the 
percentage of values larger than mean in current 
position. 
5. Discussion  
The patterns of emphasis in RS are simpler and similar at both 
the emphasis-local and higher layers. Most of the emphasis 
coincides with paragraph prominence at the onset a discourse 
unit. Prosodically phrasal prominence is the most explicit slot 
by default, and phrase end is the least explicit slot where only 
less than 25% occurred due most likely to syntactic and/or 
semantic make-up. RS tempo modulations are the same with 
or without account of emphatic portions; indicating default 
emphasis does not trigger prosodic alternations in addition to 
discourse coherence. In turn, emphasis itself is not marked by 
tempo modulation. On the contrary, emphasis in SpnL speech 
exhibited distinctly different patterns. Instead of occurring at 
the prosodically most explicit position by default, it occurs 
from the mid-paragraph and across the board, and marks the 
paragraph end by its high distribution at the paragraph end. In 
other words, the occurrences mark the most explicit prosodic 
expressions at the least explicit locations; making the (the 
occurrences) stand out by the sharper contrasts they create. 
The highest occurrence at the pre-boundary (terminal) position 
is the prosodic highlight to reiterate most explicitly the most 
important information at the least explicit slot; hence overrides 
boundary lengthening regardless of phrase or paragraph 
ending. Much more complicated tempo modulations 
accompany such prosodic highlights, both by the emphasis 
itself and by the phrases that embeds them. An emphasis 
always assumes the slowest rate; the entire embedding phrase 
also slows down. This suggests the speaker’s intended loading 
and weighting of information, expressed via prosodic explicit 
means, is a direct reflection of IS [7] planning on top of DS. 
Our results clearly suggest that systematic prosodic 
manipulations to signal the implicit/explicit, given vs. new, 
theme vs. rheme contrasts can be located in the speech signal. 
Furthermore, in acoustic terms, information structuring in the 
prosodic domain appears to have most to do with tempo 
modulations, and much less with F0 and intensity.  
 
6. Conclusions 
Different tempo patterns of prominence, represented by 
perceived emphasis, are found for RS and SpnL by tempo, 
pitch and intensity features, both in the emphasis-local PPh 
level and the higher-level BG level. Acoustic patterns of 
emphatic portions in RS and SpnL monologues are analyzed in 
relation to discourse structure. In RS most of the emphasis 
coincides with phrasal prominence with no noted tempo 
change; discourse coherence remains the predominant feature. 
Contrastively, SpnL is featured by more intricate tempo 
modulation patterns at various levels to signal explicitly and 
unambiguously at the more implicit locations, most notably at 
the paragraph end, done at the trade-off of unit-final 
lengthening. These results showed that IS and speaker’s 
intensions would override DS. We believe these findings have 
furthered our understanding of the organization of SpnL in the 
prosodic domain. In particular, the fact that tempo patterns 
extracted at various prosodic domains could be applied to 
keyword spotting and topic change. Future work will focus on 
more detailed parallel analysis of prosodic patterns and IS. 
7. References 
[1] Tseng, C., Pin, S., Lee, Y., Wang, H., and Chen, Y., 2005. “Fluent 
Speech Prosody: Framework and Modeling”, Speech 
Communication, Special Issue on Quantitative Prosody 
Modeling for Natural Speech Description and Generation, Vol. 
46:3-4, 284-309. 
[2] Nakamura, M., Furui, S., and I, Koji., “Acoustic and linguistic 
characterization of spontaneous speech”, Proc. Symposium on 
Large-Scale Knowledge Resources (LKR2007), 163-168, Tokyo, 
Japan, 2007. 
[3] Tseng, C. Su, Z. and Lee, L. 2009. Mandarin Spontaneous 
Narrative Planning—Prosodic Evidence from National Taiwan 
University Lecture Corpus . Proc. Interspeech2009, Brighton, 
UK. 2943-2946.  .   
[4] Tseng, C., Cheng, Y., and Chang, C., 2005. Sinica COSPRO and 
Toolkit—Corpora and Platform of Mandarin Chinese Fluent 
Speech, Oriental COCOSDA 2005, Jakarata, Indonesia, 2005. 
[5] Kruijff-Korbayava, I. and Steedman, M. “Discourse and 
Information Structure”, J. of Logic, Language and Information 
12:249-259, 2003 
 [6] Tseng, C., and Su, Z., 2008. “Boundary and Lengthening—On 
Relative Phonetic Information”, The 8th Phonetics Conference 
of China and the International Symposium on Phonetic Frontiers, 
Beijing, China.  
[7]  La mbrecht, K. Information Structure and Sentence Form—Topic, 
focus and the mental representations of discourse referents. 
Cambridge Studies in Linguistics, 1994. 
panel of Figure 1). We note that the longest 
syllable is the last unstressed syllable –tion instead 
of the stressed syllable –ma. However, we then 
normalized the number of phones in each syllable, 
and the derived pattern (Figure 1, lower panel) 
shows the longest syllable is in fact the stressed 
syllable –ma. 
Figure1: Normalized relative duration pattern of 
syllable sequences of the word INFORMATION. The 
upper and lower panels indicate the normalization by 
speakers and the number of phones, respectively. The 
X-axis represents the syllable index; the Y-axis 
represents the normalized duration.  A, B C and D 
represent speakers. 
 
The results suggest that though segmental duration 
contributes to output tempo, a duration pattern 
independent from segmental contribution can be 
derived from the speech data and better represents 
stress defined prosodic timing. The same rationale 
is then applied to analyze Mandarin speech data 
where the normalizations are further refined to 
derive discourse tempo cadence patterns (Sec.5). 
3. DISCOURSE AS PROSODY 
FRAMEWORK AND UNIT 
To account for discourse contribution to speech 
tempo and discourse timing, a hierarchical 
discourse prosody framework the HPG (Hierarchy 
of Prosodic Phrase Group) [10] is used. The 
framework specifies levels of perceived chunking 
and phrasing units located inside each level of 
perceived boundary breaks (B). The layered HPG 
prosodic units and corresponding boundary breaks 
are the syllable (SYL)/B1, the prosodic word 
(PW)/B2, the prosodic phrase (PPh)/B3, the breath 
group (BG)/B4 and the multiple phrase paragraph 
(PG)/B5.  
4. SPEECH DATA  
The speech data are read L1 Taiwan Mandarin 
microphone speech recorded in sound proof 
chambers differing by two speech genres: (1) plain 
text of 26 discourse pieces from Sinica COSPRO 1 
coded as CNA (approximately 6700 syllables, 
produced by 1 male and 1 female radio announcers) 
and (2) three types of Chinese Classics varying in 
degrees of rhyme regularity from regular, semi-
regular to irregular  and coded as CL 
(approximately 3,500 syllables, produced by 1 
male and 1 female untrained speakers). 
Preprocessing of speech data includes (1) 
automatically labeled segments followed by 
manual spot checking for forced alignments and (2) 
manual tagging of perceived boundary breaks by 
the HPG specifications (Sec. 3) using the Sinica 
COSPRO Toolkit [11]. Only consistently tagged 
data (over 83%) across transcribers are selected for 
analysis.  
5. METHODOLOGY 
Multi-layered normalization methods are 
developed to remove attributes that may contribute 
and affect duration modulations in output speech 
and to derive duration patterns by discourse units. 
The general function is listed below.  
iii factorfactorx εμ ++++= ....21  
At the word level (as illustrated in Sec. 2), Factor1 
represents segmental information at the Syllable 
level, Factor2 represents respective syllable position 
by word, thus taking into account word-final 
boundary lengthening, while iε  represents all 
other unpredictable values. The same rationale is 
applied for further extracting discourse tempo 
where factor1, factor2…etc. in turn represents the 
attributes of prosodic boundary in each layer by the 
HPG protocol thus removing the effects of 
boundary  lengthening by discourse units [12]. The 
attributes are removed layer by layer till all 
possibilities are considered. Residuals at each layer 
are regarded as contributions from its immediate 
higher layers and included in the next round of 
predictions. Predictions of sequential ratio of 
syllable duration sequences by perceived discourse 
units the PW and PPh are derived and presented in 
Sec. 6.   
6. RESULTS 
6.1. Duration Predictions by PW and PPh 
without Segmental Contributions 
Predictions by linear regression derived from 
discourse units the SYL, PW and PPh layers are 
derived by normalizing the contribution of 
segments. The predictions at the SYL layer is not 
presented here due to large amount of classes 
defined [13]. Figure 2 shows plotting of sequential 
ratio of syllable duration of PW (1-4 syllables, left 
panel) and PPh (1-11 syllables, right panel). The 
7. DISCUSION 
The results of removing segmental information 
(Sec. 6.1.) revealed independent cadence patterns 
by discourse units the PW and PPh, suggesting that 
prosodic timing can be derived from output speech 
by discourse units instead of by the syllable only. 
The same results also demonstrate that though 
contributions from segmental information appear 
to affect output tempo, the effect is not 
phonological. In addition, the results of boundary 
effects (Sec. 6.2.) showed systematic and 
predictable cadence patterns by discourse units the 
PW and PPh, thus demonstrating that the syllable 
alone is not sufficient to account for output speech 
tempo while timing by other discourse units must 
be taken into account. The same reasoning can also 
be applied to account for boundary effects which 
by its systematic pattern is a functioning part of 
discourse timing as well. The results of systematic 
pre-boundary lengthening by the larger and higher-
level discourse units PPh (Sec. 6.3) rather than 
lower-level units the Syl and the PW further 
suggest that the production planning of continuous 
speech include simultaneously scheming of higher-
level chunking and phrasing and lower-level 
articulatory planning by the phones or segments. 
The same results can also be interpreted as 
modulations of speaking rate by the phrase which 
in turn is at least one reason of the seemingly 
highly varied surface tempo. We believe that the 
commonly adopted speaking rate analysis by 
averaged duration across the board, whether by the 
vowels, the syllable, or the number of words, in a 
given time frame is at best a rough reference only 
[17], and should be further refined. Collectively, 
syllable-timing, discourse tempo and boundary 
effects constitute the dynamic tempo of Mandarin 
discourse speech.   
8. CONCLUSION 
The obtained evidence from the present study 
demonstrates why the surface dynamic tempo of 
continuous speech can not be sufficiently 
accounted for either by fine-grained measurement 
of segmental duration patterns, word level 
rhythmic patterns, or averaged duration of one 
single unit. In addition to segmental duration due 
to the physical composition, discourse 
contributions, as seen in derived cadence patterns 
by discourse units, as well as systematic boundary 
modulations, must also be attributed in order to 
account for the surface dynamics. We believe the 
systematic nature of discourse attributes is why 
phonological processing of timing from continuous 
speech is possible. We also suspect that these 
higher level cadence patterns may be cross-
linguistic, and merits future studies of languages 
other than English and Mandarin. 
9. REFERENCES 
[1] Abercrombie, D. 1967. Elements of General Phonetics. 
Edinburgh: Edinburgh University Press. 
[2] Lehiste, I. 1971. The timing of utterances and linguistic 
boundaries. J. Acoust. Soc. Am. 51(6B), 2018-2024. 
[3] Gibbon, D., Gut, U. 2001. Measuring speech rhythm. 
Proc. Eurospeech 2001, Scandinavia, 95-98. 
[4] Dellwo, V., Wanger, P. 2003. Relations between 
language rhythm and speech rate. Proc. ICPhS 2003, 
Barcelona, 471-474. 
[5] White, L., Mattys, S.L., Series, L., Gage, S. 2007. 
Rhythm metrics predict rhythmic discrimination. Proc. 
ICPhS 2007, Saarbrücken, 1009-1012. 
[6] Cao, J. 2004. Restudy of segmental Lengthening in 
Mandarin Chinese. Proc. of Speech Prosody 2004, Nara, 
3 pages. 
[7] Sagisaka, Y. 2003. Modeling and perception of temporal 
characteristics in speech. Proc. ICPhS 2003, Barcelona, 
1-6. 
[8] Chen, J.-Y., Chen, T.-M., Dell, G.S. 2002. Word-form 
encoding Mandarin Chinese as assessed by the implicit 
priming task. J. Memory and Language 46(4), 751-781. 
[9] O’Seaghdha, P.G., Chen, J.-Y., Chen, T.-M. 2010. 
Proximate units in word production: Phonological 
encoding begins with syllables in Mandarin Chinese but 
with segments in English. Cognition 115(2), 282-302. 
[10] Tseng, C., Pin, S., Lee, Y., Wang, H., Chen, C. 2005. 
Fluent speech prosody: Framework and modelling. 
Speech Communication 46(3-4), 284-309. 
[11] Tseng, C., Cheng, Y., Chang, C. 2005. Sinica COSPRO 
and Toolkit—Corpora and platform of Mandarin Chinese 
fluent speech. Proc. Oriental COCOSDA 2005, Jakarata, 
23-28. 
[12] Zellner, B. 1994. Pauses and the temporal structure of 
speech. In: Keller, E. (ed.), Fundamentals of Speech 
Synthesis and Speech Recognition. Chichester: John 
Wiley, 41-62. 
[13] Tseng, C., Fu, B. 2005. Duration, intensity and pause 
predictions in relation to prosody organization. Proc. 
Interspeech 2005, Lisbon, 1405-1408. 
[14] Tseng, C., Chang, C. 2008. Pause or no pause ? –
Prosodic phrase boundaries revisited. Tsinghua Science 
and Technology 13(4), 500-509. 
[15] Tseng, C., Su, Z. 2008. Boundary and lengthening—On 
relative phonetic information. Proc. 8th Phonetics 
Conference of China and the International Symposium on 
Phonetic Frontiers, Beijing, 6 pages. 
[16] Edwards, J.,  Beckman, M.E. 1987. Perception of final 
lengthening. Proc. Annual Meeting of the Linguistic 
Society of America, 13 pages. 
[17] Tseng, C. 2010. Beyond sentence prosody. Proc. 
Interspeech 2010, Makuhari, 10 pages. 
SYL<PW<PPh<BG<PG and B1<B2<B3<B4<B5 whereas 
paragraph and discourse specifications are inherent [6]. We 
note that by default the top-down perspective also specifies 
how discourse prosody context is both single-unit 
neighborhood concatenation as well as cross-unit association. 
2.1.2. Tagging perceived emphasis 
Perceived emphasis is defined as follows and tagged by 
trained transcribers independent of discourse tagging:  
• E0-unstressed portions marked by reduced pitch, volume 
and/or segment contractions 
• E1-normal pitch, volume with no segmental contractions 
• E2-higher pitch or louder volume irrespective of 
speaker’s tone of voice   
• E3-higher pitch or louder volume marked by speaker’s 
tone of voice 
In other words, E2 relates to perceived focus due to syntactic 
or structural information whereas E3 relates to speaker 
intended focus and tone of voice.  
3. Methodology 
To analyze the distribution patterns of tagged emphases, three 
steps of tailored quantization are developed. The first step 
aims to obtain the relative positions of emphasis/no-emphasis 
portions in every PPh; quantization is adopted by nine relative 
positions. The second step aims to plot the distribution of 
emphasis by histograms (Figure 1, Sec. 4.2.) in which the 
probability Pro is described as    
                     
)(/)()(Pr eNutnto ee =
                    
(1) 
where e and te represent emphasis categories and relative PPh 
positions given e, respectively. Nu and n denotes the number 
count of e and te, respectively. The distribution of emphasis is 
plotted first by e = E2∪E3, then further broken down by 
emphasis status E2 and E3. In addition, to normalize the 
effects from emphases, the same weight is assigned to each of 
the tagged portion of E1/E2/E3, and canonical distribution (E1
∪E2∪E3) was plotted. The third step aims to model possible 
information attributed weighting of perceived emphases 
whereby degrees of emphasis are defined by the three tags as 
shown in (3) below while the sum of information weighting by 
PPh/PG position  is defined in (4) below. 



=
=
=
=
E3label if ,3
E2label if ,2
E1label if ,1
)( ntScore
                                 (2)
 
NtScoretS
N
n
nn /)()(
1
∑
=
=                             (3)  
in which S and tn represent weighting sum and position index 
given n-th phrase respectively.       
To observe possible interaction between discourse positions 
and the perceived emphases, the PPhs from the speech data 
were further classified into three correlating HPG paragraph 
position PG-initial, -medial and –final. 
                         (4) 
4. Distribution of perceived highlights  
4.1.  Emphasis distribution by genres   
In order to see whether the perceived emphasis is genre related, 
the distributions of emphasis by genres are compared and 
plotted in Figure1. The left panel shows distribution patterns 
when E2 and E3 are collapsed into one category (E2∪E3); 
speech genre appears to have no correlation with the 
distribution of emphasis. However, by further breaking down 
the emphases by degrees E2 and E3, the E3/E2 ratio shows 
that LEC (0.24) is distinctly different from CNA (0.05) and 
WB (0.02), and marked by more tone-of-voice type of 
emphases E3. 
 
    
Figure 1: Distribution of Perceived Emphasis by speech 
genres CNA, WB and LEC. The left panel show the 
emphasis/no emphasis distribution; the right panel shows 
distribution of E1, E2 and E3.  
4.2.  Emphasis distribution by discourse structure 
In order to compare the distribution of emphasis with respect 
to paragraph positions PG-initial, -Medial and –Final, the 
same kind of comparison was plotted in Figure 2. The left 
panel shows the difference between canonical distributions 
(E1∪E2∪E3), namely, the distribution of all emphasis/no-
emphasis portions while the right panel shows the distribution 
of emphases by degree (E2∪E3). As found in Sec. 4.1., the 
canonical distributions are similar across genres and PG 
positions. The effect of PG-positions is similar across all three 
genres. Emphasis distribution is phrase initial>final> medial>; 
the number of phrase initial and final emphases are almost the 
same. In other words, discourse effect is almost identical. 
However, the distribution of E2∪E3 by PG positions is 
distinctly different. CNA is marked by phrase initial emphasis; 
WB marked by phrase final emphasis while LEC marked by 
phrase initial and phrase final emphases. Discourse effect is 
different. 
                 
 
Figure 2: Distribution of (E1∪E2∪E3) and (E2∪E3) by 
genres CAN, WB, LEC and discourse structure PG-initial, -
medial and -final.  
4.3.  Information weighting by emphasis category 
The following analysis aims to further model whether the 
weighting of information is related to genre, discourse 
  
Figure 6: Perceived emphases are normalized and compared with units without emphases in relation to discourse structure. 
Acoustic patterns by discourse associative positions PG-Initial, -medial and –final and speech genres prose reading CNA, 
simulating reading of weather broadcast WB and spontaneous university classroom lecture LEC are derived and plotted. 
Unit of analysis is PPh. 
6. Discussion 
The above results collectively suggest that prosodic 
highlighting is genre related. Spontaneous classroom lecture is 
distinctly different from read speech, most notably marked by 
more occurrence of speaker intended emphasis, and is clearly 
more expressive and communicative (Sec. 4.1). The 
distribution of perceived emphasis also varies by genre: 
reading prose is the most passive mode, marked by phrase 
initial emphasis, while simulating weather forecast is marked 
by phrase final emphasis and LEC marked by both phrase 
initial and phrase final emphases (Sec.4.2). More difference is 
found for unit PPh than for discourse positions (Sec.4.3). 
Correlative analyses between the perceptually identified 
emphases and their acoustic characteristics showed that LEC 
is different from CNA and WB in every acoustic feature 
examined. Significant differences of acoustic contrasts are 
found for all four acoustic features, namely, duration, average 
F0, F0 range and intensity. Nevertheless, emphases in passive 
reading (CAN) are realized by contrasts in average F0 and 
intensity while the style of WB is realized through contrasts in 
duration and intensity (Sec. 5.1, 5.2.). These results suggest 
that prosodic highlighting can be realized in different 
combinations of acoustic features. Finally, a simple procedure 
that normalized the identified prosodic highlights from the 
speech signal revealed an underlying pattern that is almost 
identical to canonical discourse prosody patterns (Sec. 5.3). 
The results imply that the surface prosodic twists and turns 
caused by different locations and needs of emphatic 
expressions in no way interferes with the underlying discourse 
structure which is obligatory to deliver core linguistic content.            
7. Conclusions 
The goal of this paper is to examine perceived prosodic 
highlights in three genres of fluent continuous Mandarin and 
see how they can be explained by systematic patterns by genre, 
discourse structure, information weighting acoustic 
manifestations. Results of cross-genre patterns demonstrate 
that prosodic highlighting is indeed genre related; distribution 
of key information can be attributed to both linguistic content 
and communicative needs. Prosodic highlighting can be 
analyzed as an extra layer over discourse structure, the former 
signals key information while the latter underlying linguistic 
association. Therefore, the prosodic realization of output 
continuous speech may appear to be strewed with emphases 
and highly different from canonical forms. However, beneath 
the acoustic deviations and discrepancies, the underlying 
structure in fact remains intact.  Future work will focus on 
more detailed analysis of information structure and its 
prosodic realization.   
8. References 
[1] [1] Terken, J. 1991. Fundamental frequency and perceived 
prominence. JASA, vol. 89, pp. 1768–1776. 
[2] Obin, N. Rodet, X. and Lacheret-Dujour, A. 2008. French 
prominence: A probabilistic framework. ICASSP 2008: 3993-
3996 
[3] Tamburini, F. and Caini, C. 2005. An automatic system for 
detecting prosodic prominence in American English continuous 
speech. International Journal of Speech Technology, Vol. 8, No. 
1, pp. 33-44.  
[4] Avanzi, M., Lacheret, A and Victorri, B. 2010. A corpus-based 
learning method for prominences detection in spontaneous 
Speech. Proceedings Speech Prosody 2010, Chicago. 
[5] Keen, E and Schieffelin, B. 1976. Topic as a discourse notion. 
in C. Li and S.Tompson Eds, Subject and Topic. New York: 
Academic Press, pp. 335-84. 
[6] Tseng, C., Cheng, Y., and Chang, C., 2005. Sinica COSPRO 
and Toolkit—Corpora and Platform of Mandarin Chinese 
Fluent Speech, Oriental COCOSDA 2005, Jakarata, Indonesia, 
2005. 
[7] Tseng, C., Pin, S., Lee, Y., 2004. Speech prosody: issues, 
approaches and implications. in Fant, G., H. Fujisaki, J. Cao 
and Y. Xu Eds. From Traditional Phonology to Mandarin 
Speech Processing, Foreign Language Teaching and Research 
Process, pp. 417-438. 
[8] Tseng, C., Pin, S., Lee, Y., Wang, H. and Chen, C. 2005. Fluent 
speech prosody: Framework and modeling, Speech 
Communication (Special Issue on Quantitative Prosody 
Modeling for Natural Speech Description and Generation), Vol. 
46:3-4, pp. 284-309. 
[9] Tseng, C. 2008. Corpus Phonetic Investigations of Discourse 
Prosody and Higher Level Information (in Chinese). Language 
and Linguistics, 9(3): 659-719. 
[10] Tseng, C. 2002. The prosodic status of breaks in running speech: 
Examination and Evaluation. Proceedings of the 1st 
International Conference on Speech Prosody 2002, (Apr. 11-13, 
2002), Aix-en-Provence, France, pp. 667-670. 
[11] Tseng, C., Su, Zh., Chang, C. and Tai, C. 2006. Prosodic filers 
and discourse markers—Discourse prosody and text prediction. 
TAL 2006 (The Second International Symposium on Tonal 
Aspects of Languages), (April 27-29, 2006), La Rochelle, 
France. 
 
Mandarin. Results show that L1 Taiwan Mandarin speakers produce a much smaller increase 
in average F0 and amplitude for on-focus words and a much smaller decrease in average F0 
and amplitude on post-focus words than L1 English speakers do. Moreover, post-focus 
compression of F0 range and duration, very strongly realized by L1 English speakers, were 
entirely absent in L2 speakers’ production. Failure to perform post-focus compression of F0 
range and duration may be attributable to transfer of L1 prosodic patterns. However, transfer 
cannot account for L2 speakers’ weak realization of on-focus F0 range and amplitude 
expansion. We argue that the weakness of L2 speakers’ on-focus/post-focus contrast 
realization reflects limitations on L2 speech processing, and that weak realization of focus 
contrasts may also contribute to listeners’ difficulty in interpreting the intended focus of L2 
utterances.  
3. Prosodic Highlights in Mandarin Continuous Speech-Cross-Genre Attributes and 
Implications-- The present study examines perceived prosodic highlights in three genres of 
fluent continuous Mandarin to test (1) whether prosodic highlights are genre related, (2) how 
they interact with discourse structure, (3) how they signal information status, (4) whether 
systematic acoustic patterns could be obtained from speech data analysis, and (5) whether 
prosodic highlights is layered over to discourse structure. Results demonstrate that prosodic 
highlighting is genre related; distribution of key information can be attributed to linguistic 
content and communicative needs. Prosodic highlighting is an extra layer over discourse 
structure, the former signals key information while the latter underlying linguistic association. 
 
 
 
二、 敘述學術活動內容、例如會議經過、講學大綱、研究、進修內容等；並請詳述本次活 
        動之心得，以供相關領域研究人員學術交流，並請勿敘述非關學術或文化活動內容。 
1. ICPhS （International Congress of Phonetic Sciences） 
會期五天（2011.08.17-21），是每四年舉行一次國際會議，2011年為第 17次會議，也
是該會第一次在亞洲舉辦，由香港城市大學主辦，該校教授徐雲陽為本次大會主席；本院語
言學研究所與中國社會科學院語言所為合辦單位，本人與社科院語言所李愛軍教授為大會副
主席。所有論文均為全文投稿送審，每篇經三位同行匿名審查。本次會議共有五百餘篇論文
發表，紙本資料為 Conference Guidebook，僅收入會議議程及論文摘要，所有論文電子版則
以 CD形式發放。參加人數為七百餘人，來自四十餘國家。本人從 1995年起參加會議，規
模大約均為如此，表示語音學學門的從業人員並無大幅增減。 
    此次會議共邀請七位資深學者擔任主題講員(keynote speakers)，分別為 Klaus Kohler, 
Louis Pols, Sarah Hawkins, Randy Diehl, Jacqueline Vaissière, Ian Maddieson,及現任 IPA 
（International Phonetics Association）理事長 Daniel Recasens。這些資深學者的報告涉及了課
題包括了音段分析的方法、語音學及本大會的歷史、語音感知的新典範及意義，語音學結合
語音科技的教學突破與意義，語音田調的類型學意義等。這七場主題報告中，最能代表新的
研究方向的是英國的 Sarah Hawkins教授所展現的結合眼動與語音感知的突破性研究，法國
的 Jacqueline Vaissière教授展示的如何結合語音科技教授語音學的新方法及 Ian Maddieson教
授一生調查了 703種語言後在語言類型方面打破許多語言學傳統迷思的新證據。 
無法提供語音科技發展、語言教學、生理語音方面的基礎研究貢獻，我們談了許久，很擔心
語音學的前景。  
2. SLaTE 
會議全程三天（2011.08.24-26），ISCA下有不少特別興趣小組，其中最活躍的有三個
小組，分別是 SLaTE (Speech and Language Technology in Education)、SPro（Speech Prosody）
與CSLP（Chinese Spoken Language Processing）。SLaTE近數年都以 ISCA年度會議 Interspeech
的衛星研討會的方式，每年在大會附近地區另組研討會，自行收費；SPro及 CSLP則是每二
年獨立舉辦國際研討會。這三個會議也都是全文論文投稿、匿名審查，並出論文集，其中又
以 CSLP最具規模，會議論文集已於 2008年開始進入 IEEE Xplore資料庫。本人並非 SLaTE
的會員，參加這個研討會也只因為從 2009年開始收集台灣地區二語英語的語料後開始涉及，
去年(2010)投出第一篇相關論文給 SLaTE研討會開始。未料去年由日本早稻田大學主辦的
SLaTE研討會內容多元、論文品質非常高、在語音學研究和語言教學發展的研究間搭起對
話的橋樑，討論熱烈，是本人參加國際研討會多年少見的高品質研討會。由於此次研討會的
主題是與二語相關的語音科技開發，而我多年來一直從事與語音科技開發相關的跨學科語音
學研究，因此特別前往威尼斯參加。如前文所言，雖然只是一個衛星會議，卻也是全文論文
投稿送審，每篇經二位同行匿名審查，所有論文的電子版以 CD形式收為論文集。共發表 23
篇口頭論文和 25篇壁報論文及 7個現場展示，共有 80人左右參加，內容非常豐富。 
這次發表的論文，語音學及語言學的較少，其中以早稻田大學Mariko Kondo 及其博士
生 HajimeTsubaki 發表的論文 Analysis of L2 English Speech corpus by Automatic Phoneme 
Alignment 與本人進行中的蔣基會國際合作計畫 TWNAESOP有直接的關係，Kondo教授也
是合作人，因此可直接在本人收集的台灣 L2英語測試。此外，Hansjoerg Mixdorff發表德語
及台灣國語的語音特性比較研究，也有直接的關連。展示的語音科技也多有大幅進步。不過，
多數與教學相關語音科技的論文，雖來自名校團隊如MIT，CMU，論文的學術水準和研究
方法的嚴謹都無可挑剔，但顯示出工程團隊的研究仍以直觀式的研究出發點為主，真正缺乏
的語言學、語音學的基本知識以及與第一線語言教師的交集，因此所開發出的科技產品並未
注意到與教師的配合面，也不知是否真能配合課堂教學。只不過語言學者如果大多數是有如
本人在 ICPhS中所見的語音學者，仍以描述典型現象為主，不願面對自然語言現象，那麼無
法對話也是可預期的。 
由於本人曾擔任二屆 CSLP的副主席（2002-2006）、主席二屆（2006-2010），與 SLaTE
的主席美國 Carnegie Mellon大學資訊系 Institute of Language Technology教授Maxine 
Ezkinnazi多年來一起出席 ISCA特別興趣小組的會議，因此特別與她討論此事。她表示，
SLaTE每年一度的研討會確實會因為主辦單位、主辦人及區域性在內容上有所差異，不過
對我所提出的科技與語言教育的關連深表同意，表示會納入下年度組織研討會的的考慮。本
人期待明年的 SlaTE研討會能有新的面向。 
 
3. Interspeech2011 
 會期五天（2011.08.27-31），出席人數 1,500餘人。Interspeech國際會議源自 Eurospeech
及 ICSLP (International Conference on Spoken Language Processing)二項雙年度國際會議，至今
已有 20年的歷史，2004年成為 ISCA的年度會議，合併以上二雙年會改稱 Interspeech。截
至 2011年，ICSA的會員已超過 2,000人，舉行會議的地點則遍及全球。Interspeech出席人
數每年增加，去年註冊人數超過 1,400餘位，超過前年；今年則超過 1,500餘人。由此可見
本人提出的壁報論文，則以分析大批語料的建模，解析語音輸出中的重點表達
（prominence）與信息結構權重的對應，以及與語篇結構為平行結構、堆疊而共構的解釋，
解釋了信息與語篇共容，二者毫無抵觸的證據。 
最後，綜合出席以上三項會議，個人認為四年舉辦一次的國際語音學大會 ICPhS語音
學需要開發更寬廣的研究角度與視野，SLaTE研討會需強調語音科技與語言學習、語言教育
的結合，如能獲得更多基礎研究及第一線語言教學從業人員的加入將更為實際，Interspeech
所展現的學術包容性、寬廣性及前瞻性，則令人十分振奮。 
 
 
三、   出國成果  
出國類別：參加國際學術會議 
1. 參加會議任務： 
□(1)主講人 
□(2)受邀演講 
□(3)會議主席  
□(4)論文口頭發表 
■(5)論文壁報發表 
□(6)評論人 
□(7)主辦人 
 
2. 學術交流、合作事項: 
 （1）受邀擔任 ICPhS2011大會副主席，自 2007年起，四年來協助大會主席香港城市大學徐雲
陽教授籌組會議，該校文學院院長在開幕典禮致詞時，特別向二位副主席及合辦單位致謝。 
 
（2）當選 ISCA學會 2011-15年國際諮詢委員會 International Advisory Council (IAC)委員，08/27
出席年度 IAC與 ISCA board聯席會議，08/29出詞 IAC會議。主要任務是如何推廣 ISCA的會
務，議決項目包括：（1）確認 2012至 2014年的 Interspeech會議將在美國 Portland,法國 Lyons
及新加坡舉行外，並將開始徵詢 2015年起的主辦地點及單位, （2）提名並選舉 ISCA Fellow，（3）
繼續提供學生會員出席會議旅費補助，（4）本人提案提供亞洲地區開發中國家學者免年費及提
供旅費協助，使該地區學者得以參加 ISCA及 Interspeech會議，獲全票通過。 08/31並全程出
席 ISCA會員大會，支持會務的運作。 
 
 
 
and amplitude on post-focus words than L1 English speakers do. Moreover, post-focus 
compression of F0 range and duration, very strongly realized by L1 English speakers, were 
entirely absent in L2 speakers’ production. Failure to perform post-focus compression of F0 
range and duration may be attributable to transfer of L1 prosodic patterns. However, transfer 
cannot account for L2 speakers’ weak realization of on-focus F0 range and amplitude 
expansion. We argue that the weakness of L2 speakers’ on-focus/post-focus contrast 
realization reflects limitations on L2 speech processing, and that weak realization of focus 
contrasts may also contribute to listeners’ difficulty in interpreting the intended focus of L2 
utterances.  
3. Prosodic Highlights in Mandarin Continuous Speech-Cross-Genre Attributes and 
Implications-- The present study examines perceived prosodic highlights in three genres of 
fluent continuous Mandarin to test (1) whether prosodic highlights are genre related, (2) how 
they interact with discourse structure, (3) how they signal information status, (4) whether 
systematic acoustic patterns could be obtained from speech data analysis, and (5) whether 
prosodic highlights is layered over to discourse structure. Results demonstrate that prosodic 
highlighting is genre related; distribution of key information can be attributed to linguistic 
content and communicative needs. Prosodic highlighting is an extra layer over discourse 
structure, the former signals key information while the latter underlying linguistic association.
 
 
 
二、 敘述學術活動內容、例如會議經過、講學大綱、研究、進修內容等；並請詳述本次活
        動之心得，以供相關領域研究人員學術交流，並請勿敘述非關學術或文化活動內容。
1. ICPhS （International Congress of Phonetic Sciences） 
會期五天（2011.08.17-21），是每四年舉行一次國際會議，2011 年為第 17 次會議，也
是該會第一次在亞洲舉辦，由香港城市大學主辦，該校教授徐雲陽為本次大會主席；本院語
言學研究所與中國社會科學院語言所為合辦單位，本人與社科院語言所李愛軍教授為大會副
主席。所有論文均為全文投稿送審，每篇經三位同行匿名審查。本次會議共有五百餘篇論文
發表，紙本資料為 Conference Guidebook，僅收入會議議程及論文摘要，所有論文電子版則
以 CD 形式發放。參加人數為七百餘人，來自四十餘國家。本人從 1995 年起參加會議，規
模大約均為如此，表示語音學學門的從業人員並無大幅增減。 
    此次會議共邀請七位資深學者擔任主題講員(keynote speakers)，分別為 Klaus Kohler, 
Louis Pols, Sarah Hawkins, Randy Diehl, Jacqueline Vaissière, Ian Maddieson,及現任 IPA 
（International Phonetics Association）理事長 Daniel Recasens。這些資深學者的報告涉及了課
題包括了音段分析的方法、語音學及本大會的歷史、語音感知的新典範及意義，語音學結合
語音科技的教學突破與意義，語音田調的類型學意義等。這七場主題報告中，最能代表新的
研究方向的是英國的 Sarah Hawkins 教授所展現的結合眼動與語音感知的突破性研究，法國
的 Jacqueline Vaissière教授展示的如何結合語音科技教授語音學的新方法及 Ian Maddieson教
授一生調查了 703 種語言後在語言類型方面打破許多語言學傳統迷思的新證據。 
    會議論文依照本大會多年來的形式，以平行場次發表分口頭論文及壁報論文，本次會議
共有口頭論文三百餘篇，每天以七個平行場次進行。其餘的壁報論文也以平行場次進行。本
2. SLaTE 
會議全程三天（2011.08.24-26），ISCA 下有不少特別興趣小組，其中最活躍的有三個
小組，分別是 SLaTE (Speech and Language Technology in Education)、SPro（Speech Prosody）
與CSLP（Chinese Spoken Language Processing）。SLaTE近數年都以 ISCA年度會議 Interspeech
的衛星研討會的方式，每年在大會附近地區另組研討會，自行收費；SPro 及 CSLP 則是每二
年獨立舉辦國際研討會。這三個會議也都是全文論文投稿、匿名審查，並出論文集，其中又
以 CSLP 最具規模，會議論文集已於 2008 年開始進入 IEEE Xplore 資料庫。本人並非 SLaTE
的會員，參加這個研討會也只因為從 2009 年開始收集台灣地區二語英語的語料後開始涉及，
去年(2010)投出第一篇相關論文給 SLaTE 研討會開始。未料去年由日本早稻田大學主辦的
SLaTE 研討會內容多元、論文品質非常高、在語音學研究和語言教學發展的研究間搭起對
話的橋樑，討論熱烈，是本人參加國際研討會多年少見的高品質研討會。由於此次研討會的
主題是與二語相關的語音科技開發，而我多年來一直從事與語音科技開發相關的跨學科語音
學研究，因此特別前往威尼斯參加。如前文所言，雖然只是一個衛星會議，卻也是全文論文
投稿送審，每篇經二位同行匿名審查，所有論文的電子版以 CD 形式收為論文集。共發表 23
篇口頭論文和 25 篇壁報論文及 7 個現場展示，共有 80 人左右參加，內容非常豐富。 
這次發表的論文，語音學及語言學的較少，其中以早稻田大學 Mariko Kondo 及其博士
生 HajimeTsubaki 發表的論文 Analysis of L2 English Speech corpus by Automatic Phoneme 
Alignment 與本人進行中的蔣基會國際合作計畫 TWNAESOP 有直接的關係，Kondo 教授也
是合作人，因此可直接在本人收集的台灣 L2 英語測試。此外，Hansjoerg Mixdorff 發表德語
及台灣國語的語音特性比較研究，也有直接的關連。展示的語音科技也多有大幅進步。不過，
多數與教學相關語音科技的論文，雖來自名校團隊如 MIT，CMU，論文的學術水準和研究
方法的嚴謹都無可挑剔，但顯示出工程團隊的研究仍以直觀式的研究出發點為主，真正缺乏
的語言學、語音學的基本知識以及與第一線語言教師的交集，因此所開發出的科技產品並未
注意到與教師的配合面，也不知是否真能配合課堂教學。只不過語言學者如果大多數是有如
本人在 ICPhS 中所見的語音學者，仍以描述典型現象為主，不願面對自然語言現象，那麼無
法對話也是可預期的。 
由於本人曾擔任二屆 CSLP 的副主席（2002-2006）、主席二屆（2006-2010），與 SLaTE
的主席美國 Carnegie Mellon 大學資訊系 Institute of Language Technology 教授 Maxine 
Ezkinnazi 多年來一起出席 ISCA 特別興趣小組的會議，因此特別與她討論此事。她表示，
SLaTE 每年一度的研討會確實會因為主辦單位、主辦人及區域性在內容上有所差異，不過
對我所提出的科技與語言教育的關連深表同意，表示會納入下年度組織研討會的的考慮。本
人期待明年的 SlaTE 研討會能有新的面向。 
 
3. Interspeech2011 
 會期五天（2011.08.27-31），出席人數 1,500 餘人。Interspeech 國際會議源自 Eurospeech
及 ICSLP (International Conference on Spoken Language Processing)二項雙年度國際會議，至今
已有 20 年的歷史，2004 年成為 ISCA 的年度會議，合併以上二雙年會改稱 Interspeech。截
至 2011 年，ICSA 的會員已超過 2,000 人，舉行會議的地點則遍及全球。Interspeech 出席人
數每年增加，去年註冊人數超過 1,400 餘位，超過前年；今年則超過 1,500 餘人。由此可見
此項學術會議的重要性。 
此次會議前所未有的共收到 1,439 篇全文論文投稿，每篇都由三位審查人匿名審查，因
解釋了信息與語篇共容，二者毫無抵觸的證據。 
最後，綜合出席以上三項會議，個人認為四年舉辦一次的國際語音學大會 ICPhS 語音
學需要開發更寬廣的研究角度與視野，SLaTE 研討會需強調語音科技與語言學習、語言教育
的結合，如能獲得更多基礎研究及第一線語言教學從業人員的加入將更為實際，Interspeech
所展現的學術包容性、寬廣性及前瞻性，則令人十分振奮。 
 
 
三、   出國成果  
出國類別：參加國際學術會議 
1. 參加會議任務： 
□(1)主講人 
□(2)受邀演講 
□(3)會議主席  
□(4)論文口頭發表 
■(5)論文壁報發表 
□(6)評論人 
□(7)主辦人 
 
2. 學術交流、合作事項: 
 （1）受邀擔任 ICPhS2011 大會副主席，自 2007 年起，四年來協助大會主席香港城市大學徐雲
陽教授籌組會議，該校文學院院長在開幕典禮致詞時，特別向二位副主席及合辦單位致謝。 
 
（2）當選 ISCA 學會 2011-15 年國際諮詢委員會 International Advisory Council (IAC)委員，08/27
出席年度 IAC 與 ISCA board 聯席會議，08/29 出詞 IAC 會議。主要任務是如何推廣 ISCA 的會
務，議決項目包括：（1）確認 2012 至 2014 年的 Interspeech 會議將在美國 Portland,法國 Lyons
及新加坡舉行外，並將開始徵詢 2015 年起的主辦地點及單位, （2）提名並選舉 ISCA Fellow，（3）
繼續提供學生會員出席會議旅費補助，（4）本人提案提供亞洲地區開發中國家學者免年費及提
供旅費協助，使該地區學者得以參加 ISCA 及 Interspeech 會議，獲全票通過。 08/31 並全程出
席 ISCA 會員大會，支持會務的運作。 
 
 
 
97 年度專題研究計畫研究成果彙整表 
計畫主持人：鄭秋豫 計畫編號：97-2221-E-001-017-MY3 
計畫名稱：新世代自動語音辨識技術之研究 – 第二階段--韻律屬性與語音事件偵測之研究 
量化 
成果項目 
實際已達
成數（被接
受或已發
表） 
預期總達成
數(含實際
已達成數)
本計畫
實際貢
獻百分
比 
單位
備註（質化說明：如數
個計畫共同成果、成果
列 為 該 期 刊 之 封 面 故
事...等） 
期刊論文 0 0 100%  
研究報告 /技術報
告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 0 20%  
博士生 1 0 10%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 4 0 70% 
人次
 
期刊論文 1 0 20% 
國科會專題研究計畫「語音
科技開發導向的口語篇章
韻律研究」(計畫編號：NSC 
96-2221-E-0001-025-MY3)
共同研究成果 
研究報告 /技術報
告 0 0 100%  
研討會論文 6 0 100% 
篇 
 
論文著作 
專書 1 0 40% 章/本
國科會專題研究計畫「語音
科技開發導向的口語篇章
韻律研究」(計畫編號：NSC 
96-2221-E-0001-025-MY3)
共同研究成果 
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
本計畫研究成果，在以下幾方面對已知的現象增加了新的知識：（1）對文獻中為人熟知的
邊界前的延長現象，在語篇的架構下獲知，延長的單位不僅限一個音節，而是每一層級的
語篇單位不同等級的延長，有系統性並各有其模版。（2）所謂的韻律語境，並不僅限於文
獻中所稱的線性的 co-location 訊息，其實，也同時了包含上層管轄單位的階層性訊息。
（3）文獻中將突顯、強調都單純的視作小單位現象，卻不知在不同語篇單位、所處較大
單位的位置，都對整個語篇單位的行進速度息息相關，不能將其抽離所在單位獨立檢視，
否則無法瞭解行進時整體快慢調整的由來。（4）通過標準化的測試，我們更精確的獲得突
顯是疊加到語篇架構上的證據。以上種種，都使我們對語音信號中的整體訊息(global 
information)與局部訊息(local information)有了文獻中前所未有的瞭解。我們認為，
這些瞭解對於解決辨識快語速連續語流時可能遇到的信號失真問題，以及提取出口語語流
中的重要關鍵訊息，具有關鍵性的知識意義。  
執行本計畫所獲之韻律邊界研究結果：（1）可應用在語流的自動語音切分（automatic 
speech segmentation）。（2）從相對或對比性的角度，為語音學重要課題「邊界停頓」、「邊
界延長」對其定義加以提出對立性區辨修訂。（3）提出語段內的邊界與語篇組織相關的證
據，對於增進韻律邊界的瞭解，是重要的研究結果。 
韻律邊界及資訊結構研究結果：（1）可應用於語流中的關鍵詞擷取（Keyword Spotting）、
主題轉換（topic change）與訊息權重（information weighting）技術發展。（2）提出
自發性口語語料語段內邊界與語篇組織相關韻律特性的研究證據，增進自發性口語語料韻
