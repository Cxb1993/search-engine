2只需將滑鼠按在想知道的魚上，系統就會立
即將這條魚的相關資訊回應給使用者。這個
功能除可以提供民眾進一步了解魚類知識，
同時也可以提供真實生動的視訊影片給予學
童作為魚類知識學習的教材；另外也可以應
用於大型水族館自動導覽系統的開發，提供
快速與自動的導覽說明功能，以解決目前大
部分的大型水族館如墾丁海生館、澎湖海生
館，因為人力缺乏，無法針對每一個觀眾群
體，派一名解說員的窘境。
二、相關文獻探討
近年來，由於視訊監控(video surveillance)
的發達，使得視訊監控之相關的研究紛紛受
到重視，而視訊物件追蹤成為一個很重要的
議題，透過物件的追蹤可以將物件的移動軌
跡(trajectory)記錄下來，藉由這些軌跡的分
析，可以找出物體獨有的一些特性，以利後
續的應用。
物體追蹤的方法大致可以區分為四類：基
於區域特性的追蹤(Region-based tracking)、
基於輪廓特性的追蹤 (Active Contour-based
tracking) 、特徵基礎的追蹤 (Feature-based
tracking) 以 及 模 式 基 礎 (Model-based
racking)。
基於區域特性的追蹤原理是根據移動物體
所在的區域會產生變動來做追蹤，Wren 等
人[1]將人的身體區分成許多小區塊(blobs)，
藉由這些小區塊所對應到人的手、腳、頭部
等區域的移動，來追蹤人類的移動。基於輪
廓特性的追蹤的原理是使用輪廓追蹤演算
法，動態更新每一個持續影格中物件的外
形，這些輪廓追蹤演算法有Geodesic active
contours[2] 、 Kalman filter snake[3] ，另外
Isard 等人利用變形樣本(deformable templates)
來套用人的追蹤[4]。特徵基礎的追蹤則利用
全域特徵(global feature)如centroids、面積、
顏色等[5][6]或是區域特徵如線段、曲線、和
角(corner)等[7][8]來追蹤物體。模式基礎的追
蹤是根據鎖定的已知物體如人類或汽車的運
動予以標準模式化，利用對人體活動模式如
手腳的追蹤[9][10]，以及交通環境的模式化
[11][12]。另外移動物體一般可以分為剛體
(rigid)和非剛體(nonrigid)，剛體的物體像是運
載工具，如貨車、汽車及卡車之類的物體，
由於他們有固定的角(corner)與邊(edge)，所
以學者[13]提出利用輪廓為特徵去追蹤就可
以達到很精確的結果，但如果是非剛體的物
體像是人類、魚類之類的物體，用輪廓為特
徵去追蹤，可能會導致物體追蹤發生錯誤，
因為他們的肢體動作很容易產生輪廓的變
化，所以有些學者[14][15]提出用顏色的特徵
來做非剛體的追蹤，因為它有以下幾種好
處：比起輪廓追蹤的方法，使用顏色特徵追
蹤較為簡單，而且容易計算和比對。H.H.
Hsu等人[16]提出以物件表格(object table)來
maintain 多個魚類物件，以顏色直方圖與魚
類物件移動向量來解決多物件追蹤時的重疊
問題。因此在本專題計畫中魚類物件的追
蹤，我們將利用顏色特徵為主要比對方法，
再加上魚類相對位置資訊的相輔來進行。
平均位移演算法(Mean-shift)是現今最受歡
迎的物件追蹤方法之ㄧ，本系統將會採用此
方法來進行魚類的行動偵測與追蹤。相關平
均位移演算法，詳細介紹如下：
平均位移演算法最早是由Fukunaga等人[17]
在1975年在一篇關於概率密度梯度函數的估
計中提出來，1995年 ,另外一篇關於Mean
Shift的重要文獻[18]才發表，在這篇重要的文
獻中，Yizong Cheng對基本的Mean Shift算法
在以下兩個方面做了推廣,首先Yizong Cheng
定義了一個核函數,使得隨著樣本與被偏移點
的距離不同,其偏移量對均值偏移向量的貢獻
也不同,其次Yizong Cheng還設定了一個權重
係數,使得不同的樣本點重要性不一樣,這大大
擴大了Mean Shift的適用範圍 .另外Yizong
4成立，δ(x)為Kronecker delta function。而色彩
密度函數的精確性，源自於色彩的索引範
圍，色彩的索引範圍愈廣，則精確度將愈
高，但是也會造成運算量過大，而候選影像
色彩分佈密度函數的定義p(u,y)它與物體區域
色彩分佈密度函數q(u)最大的差別在於，q(u)
以y為中心，以 表示候選影像所有
像素位置的集合，其p(u,y)的定義如下：
(4)
Ch 是 正 規 化 常 數 ， 讓
式子成立，h為核心函數的半徑
大小。
有了p(u)與p(u,y)之後，將兩者進行比
較，得到Bhattacharyya 係數愈大者，則代表
愈相似，當係數達到最大，且疊代移動的距
離小於T時，則停止疊代，代表追蹤成功。以
下將進行核心函數與Bhattacharyya 係數進行
說明。
2-2 Bhattacharyya 係數
Bhattacharyya係數錯誤! 找不到參照來
源。]是一種錯誤量的估計，當兩個資料集愈
相似時，它們在進行分群動作時，所產生的
錯誤量將會愈高，因為兩個資料集愈相似，
愈 難 進 行 分 群 動 作 ， 因 此 在 Mean-shift
tracking演算法進行影像i的樣版與影像i+1樣
版進行比較時，採Bhattacharyya係數來進行
估計，找出係數最大，代表最相似，
Bhattacharyya係數定義如下：
(5)
如果要運用在色彩密度函數上，則可以調整
為
(6)
三、所提出結合區域預測之 Mean-shift 方法
3-1、系統架構與流程
圖 3a 系統架構圖
圖 4b 系統流程圖
上圖中，可看出我們的系統分為辨識流程與
追蹤流程兩種。辨識流程分為移動物件偵測
與辨識，追蹤流程分為移動向量預測與
Modified Mean-Shift Tracking。我們將在以下
小節進行說明：
6Ha 為辨識的魚類直方圖特徵，Hb 為資料庫
的魚類直方圖特徵。
處理完辨識之後，要進行追蹤特徵的萃取
動作，供往後進行追蹤時使用。追蹤特徵我
們採 RGB 512 bin 方式進行量化動作，公式
如下：
   32/256*32/256*32/256
256*256*256
BGR
BGR 
(10)
只取前景部份，當作追蹤特徵。
3-4、移動區域預測
移動區域預測主要是預測魚在下一個影格
將往那一個方向的區域移動，因為以傳統
Mean-Shift 的方式進行追蹤，如果魚游的太
快，容易導致追蹤物件遺失，因為 Mean-
Shift 主要是從前一個 Frame 所追蹤到的位
置，當成下一個 Frame 要追蹤疊代的初始位
置以進行追蹤，如以下左圖紅框部份為前一
個 Frame 魚的位置，而目前 Frame 要追蹤的
初始疊代位置則為右圖紅框的部份，但是如
果魚游的太快的話，右圖的紅框將會框不
到，也就是追蹤物件遺失，因此我們提出一
個區域預測的方法來進行預測以補強傳統方
法的不足，以下圖 5 來進行說明之。
圖 5 預測示意圖
左圖紅框部份為前一個 frame，魚所在的位
置，而在下一個 frame 我們不知道魚會往那
一個方向游動，因此在下一個 frame 我們以
紅框大小，把紅框當成中心點向左上 (白
框)、左下(綠框)、右上(藍框)、右下(紫框)，
做四個方向的預測，將這四個區塊屬於前景
的部份色彩空間量化成 RGB 512 色，並且跟
Front frame 紅框部份的追蹤直方圖進行比較
動作，即可預測出魚往那一個方向游動，因
此在做 Mean-Shift 追蹤的初始疊代位置時，
第一次疊代的位置直接移動到最相似的地
方，也就是紫框的部份，此方法可以改善
Mean-Shift 在物件移動太快而導致追蹤遺失
的缺點，在預測比較上，因為 Mean-Shift 追
蹤的相似度比較是採用 Bhattacharyya 係數來
進行比較，並且可以達到很好的效果，所以
我們在預測時，也採用 Bhattacharyya 係數來
進行比較。預測結束後，在以我們提出的方
法進行追蹤，我們的方法是 Mean-shift 為原
理進行修改來達到更好的效果，我們的方法
將在下個小節進行說明。
3-5、Modified Mean-Shift Tracking
經過上一小節移動向量預測之後，接下來
將進行物件追蹤，追蹤方式採用Mean-Shift平
均位移演算法的概念進行，我們的做法是取
用它的概念來進行追蹤動作，而不是完全取
用Mean-shift的做法;從前一個Frame中，我們
可以得到追蹤用的直方圖特徵，在目前Frame
中，我們透過移動向量預測得到第一次疊代
的初始位置，取得該位置的直方圖特徵(前景
部份)，持續進行追蹤疊代動作，最後完成追
蹤動作，其流程圖如下所示：
圖 6 Modified Mean-Shift Tracking 流程圖
83-6、Region-based Tracking
Region-based 追蹤方法與一般移動向量預
測的方法大致相同，差別在於預測後的範
圍，以下圖為例：
圖 8 局部 Region-based 示意圖
上圖 a 為 Front frame 追蹤物件的位置，圖
b、c、d、e、f 為 Current frame，圖 b 紅、
藍、綠、紫框為預測的範圍，如果預測的位
置為紅框部份，則所採用的局部範圍為圖 c;
預測的位置為藍框部份，則採用的局部範圍
為圖 d; 預測的位置為綠框部份，則採用的局
部範圍為圖 e; 預測的位置為紫框部份，則採
用的局部範圍為圖 f;最後將局部的範圍以
Region-based 的方式取出該範圍所有的物件
以進行比對。流程圖如下所示：
圖 9 局部 Region-based Tracking 流程圖
移動向量預測同 session 3-4 之方法，有了
預測範圍之後，接下來往預測值最高的方向
進行局部 Region-based 的方法抓出物件，此
處需抓出所有物件，方法同 3-2 的背景相
減、後處理動作、物件擷取與 3-3 魚類物件
辨識，差別在於只針對預測範圍進行上述相
關動作。當特徵值比對小於 T 門檻值時，則
回到步驟二，往預測值第二高的範圍進行局
部 Region-based，當比對特徵值再次小於特
徵值時，則持續回到步驟二，往預測值第三
高、第四高進行。
四、實驗結果
本研究採用 Inter Core2 Duo 1.66G CPU、
2G memory、Windows xp professional 作業系
統來進行各項實驗，開發工具為 JAVA
JDK6.0 和 Eclipse，我們使用 Logitech 公司
所出產型號 QuickCam Pro 3000 的 webcam
來進行即時拍攝，在此模式中，我們將魚限
制在一個空間內，因為現在的水族館通常都
會把魚分開加以區別，避免不同種魚群之間
互相攻擊而造成死亡，拍攝的畫面大小為
340*240 pixels，每秒設為 15 frames。
4-1 系統介面展示
進行即時魚類檢索時，必須先做背景的註
冊，若使用過程中發現背景亂掉，按背景重
新註冊按鈕即可，如圖10。本系統可以做多
物件的追蹤，在按下多物件追蹤紐後，再點
多隻魚進行多物件的追蹤，魚的詳細資訊也
會顯示在下方。
圖 10 即時魚類檢索系統介面展示
4-2 辨識正確率實驗評估
我們資料庫的魚類種類有 50 種，以下系統將
對魚類進行辨識率的準確分析，分別對每一
10
端大約 7 個 Frame，即可接近無延遲效果，
在所提供的架構上，可以成功地實作出同時
提供 8 到 9 個客戶端同時進行視訊監控。
結論
在本研究中，我們結合區域預測以修改傳
統Mean-shift方法，提出ㄧ套完整的魚類導覽
與追蹤監控的模式，達到以魚類視訊為輸入
的魚種辨識，相關本研究的應用包含水族箱
環境的分析與建構、魚類的偵測、魚類的追
蹤、魚類的辨識、以及魚類知識庫的建置，
最後完成即時的魚類檢索系統。使用者透過
電腦螢幕的顯示，只需將滑鼠按在想知道的
魚上，系統就會立即將這條魚的相關資訊回
應給使用者。這個功能除可以提供民眾進一
步了解魚類知識，同時也可以提供真實生動
的視訊影片給予學童作為魚類知識學習的教
材；另外也可以應用於大型水族館自動導覽
系統的開發，提供快速與自動的導覽說明功
能。
參考文獻
[1] Wren C R and Azarbayejani A and Darrell
T and Pentland A P (1997) , inder: real-
time tracking of the human body, IEEE
Trans. Pattern Anal. Machine Intell.,
19:780–785.
[2] Paragios N and Deriche R (2000),
Geodesic active contours and level sets for
the detection and tracking of moving
objects, IEEE Trans. Pattern Anal.
Machine Intell., 22:266-280.
[3] Peterfreund N(1999), Robust tracking of
position and velocity with Kalman snakes,
IEEE Tran.Pattern Anal.Machine Intell,
22:564-569.
[4] Isard M and Blake A(1996), Contour
tracking by stochastic propagation of
conditional density, in Proc. European
Conf. Computer Vision, 343-356.
[5] Coifman B and Beymer D and
McLauchlan P and Malik J, A real-time
computer vision system for vehicle
tracking and traffic surveillance, SDOS
Trans Res Part C, 6(4):271-288.
[6] Malik J. and Russell S.(1996), Traffic
surveillance and detection technology
development (new traffic sensor
technology), Univ. of California, Berkeley.
[7] Pau C. A. and Barber A.(1996), Traffic
sensor using a color vision method, in Proc.
SPIE—Trans Sensors and Controls:
Collision Avoidance, Traffic Management,
and ITS,2902:156-165.
[8] Schiele B(2000), Vodel-free tracking of
cars and people based on color regions,
IEEE Int. Workshop Performance
Evaluation of Tracking and Surveillance,
Grenoble, France,61-71.
[9] Karaulova I A and Hall P M and Marshall
A. D.(2000), A hierarchical model of
dynamics for tracking people with a single
video camera, in Proc. British Machine
Vision Conf.,262-352.
[10] Rohr K(1994), Toward model-based
recognition of human movements in image
sequences, CVGIP:Image
Understanding,59(1):94-115.
[11] Tan TN and Sullivan GD and Baker
KD(1998), Model-based localization and
recognition of road vehicles, Int. J. Comput.
Vis., 29(1): 22–25.
[12] Gardner WF and Lawton DT(1996),
Interactive model-based vehicle tracking,
IEEE Trans. Pattern Anal. Machine
Intell.,18:1115–1121.
[13] Wang H and Brady M(1995), Real-time
corner detection algorithm formotion
estimation, Image Vision
Comput.,13:695–703.
[14] Khan S and Shah M(2000), Tracking
people in presence of occlusion, in Proc.
Asian Conf.Computer Vision, Taipei,
Taiwan.
[15] Cavallaro A and Steiger O and Ebrahimi
T(2005), Tracking video objects in
clutteredbackground, IEEE Trans on
Circuits and Systems for Video
Technology,15(4): 575-584.
[16] Huang H and Shih TK and Tang CT and
Liao YC(2005), Real-time Multiple
Tracking Using a Combined Technique,
Proceedings of the 19th International
Conference on Advanced Information
Networking and Applications.
[17] Fukunaga K and Hostetler L(1975), The
estimation of the gradient of a density
function, with applications in pattern
recognition. IEEE Transactions on
12
出席國際學術會議心得報告
計畫編號 NSC98-2220-E-327-001
計畫名稱 (中文) 智慧型魚類追蹤與分類系統
(英文) A Intelligent Fish Tracking and Classification System
出國人員姓名
服務機關及職稱
李 嘉 紘
國立高雄第一科技大學 資訊管理系 副教授
會議時間地點 2010年七月九日到十一日, 中國, 成都市
9
th
~ 11
th
, July, 2010, Chengdu, China
會議名稱 (中文) 2010 國際電腦科學及資訊技術研討會
(英文) The 3rd IEEE International Conference on Computer
Science and Information Technology (IEEE ICCSIT 2010)
發表論文題目 (中文) 基於電腦視覺技術之魚缸魚類辨識與追蹤系統
(英文) A Tank Fish Recognition and Tracking System Using
Computer Vision Techniques
一、參加會議經過
本次出國主要的目的是去參加 IEEE ICCSIT 2010 (第三屆 IEEE國際會議計算機
科學與信息技術) 報告論文 - A Tank Fish Recognition and Tracking System Using
Computer Vision Techniques，並藉由報告論文的空檔，觀摩國際間在影像、視訊
處理及應用領域上的發展趨勢、方法、以及目前的現況。
這次國際會議由IACSIT協會、IEEE中國理事會、IEEE北京分會和四川省計算
機學會主辦，中國電子學會，北京大學，四川省電子學會，期刊電子科學與技術，
大學電子科學與技術，東北大學，華中師範大學共同協辦。
本人參加報告的Session屬於資訊系統與應用，是在第三天上午的九點開始，順
位是第四個，有許多此一領域的學者參與，也與本人做簡短的討論交流。 這篇論
文主要是使用電腦視訊技術中移動區域的預測以改良傳統Mean-shift方法，並提出
ㄧ套完整的魚類導覽與追蹤監控的模式，達到以魚類視訊為輸入的魚類辨識，實驗
結果顯示本研究的高正確率以及良好的追蹤效能，相關的應用包含水族箱環境的分
析與建構、魚類的偵測、魚類的追蹤、魚類的辨識、以及魚類知識庫的建置，並成
功實現即時的魚缸魚類檢索系統。每個作者的報告大約只有10分鐘，不足以讓人對
其研究有徹底的了解，我在簡報上刻意準備更多圖片以介紹研究的成果，會議主席
針對本人報告提出幾個問題，表示很有興趣，包含可否安裝在網站上推廣使用。另
外此次session安排的論文所歸屬的領域差異過大，導致報告人與提問人的背景知識
與認知有一些差距，在我下一位報告的學者，只因其論文題目冠上optimal，就跟
A Tank Fish Recognition and Tracking System Using Computer Vision Techniques 
Jia-Hong Leel, Mei-Yi Wu2 and Zhi-Cheng Guo3 
IDept. of Information Management, National Kaohsiung First University of Science and Technology 
2Dept. of Information Management, Chang Jung University 
3Dept. of Information Management, Kun Shan University 
Taiwan, R.O.C. China 
jhlee @ccms.nkfust.edu.tw 
Abstract-Aquarium usually provides the visitors with pictures 
and some description of the fishes in the exhibition tank. In this 
paper, an intelligent fish recognition system using computer 
vision is proposed to help aquarium to educate people about 
the fishes in the tank. The designed system provides a 
convenient and friendly interface to help the users to retrieve 
the related fish information they are interested. The system 
includes three SUb-systems: (1) fish object detection system (2) 
fish object tracking system (3) fish object recognition system. 
Two types of fish indexing system (offline and real time) have 
been designed and implemented. 
Tank fish recongniton; object detection; object tracking; 
computer vision(key words) 
1. INTRODUCTION 
Aquarium usually provides the visitors with pictures and 
some description of the fishes in the exhibition tank. 
However, if the aquarium with an automatic fish recognition 
system, it can add attractions and help aquarium to educate 
people about these fishes. In addition, a fish surveillance 
system is very important for management in some marine 
parks. 
The rapid development III video, compression, 
communication and storage technology have resulted in an 
explosion of video data in recent years. Many surveillance 
systems have been widely used in industry applications, 
traffic and people monitor. The operations in most 
surveillance systems are based on object segmentation and 
tracking. Many researches about this topic have been 
presented and implemented[1][4][5][1O][1l][12][14]. Video 
segmentation methods can be roughly divided into three 
categories. The first category is homogeneity-based 
rule[4][1O], a morphological filtering is applied to smooth 
the input image frame and the watershed algorithm is then 
used to mark different regions according to the surface 
homogeneity. However, the performance of the watershed 
algorithm is time consuming. The second category is based 
on change detection. Contiguous frame difference is 
computed to detect the moving objects in the frame[1][5][16]. 
This kind of methods can be easily implemented. However, 
this kind of methods work not very well when the speed of 
moving objects is very low. The third category is based on 
background registration[ll], which can improve the 
drawback of change detection methods. Background is pre-
978-1-4244-5540-9/10/$26.00 ©2010 IEEE 
528 
defined and the difference of current frame and the 
background image is computed to detect moving objects[14]. 
In the object tracking, the moving objects can be divided 
into two categories: rigid and non-rigid. In general, object 
shape can play a good feature to obtain good recognition 
results for rigid moving object tracking[8]. But using shape 
as features can not work well in tracking non-rigid objects 
such like people and fishes[13][15]. Hsu et, al.[9] apply color 
information and object table to maintain fish object tracking 
and achieve very good results. 
In this paper, a tank fish recognition and tracking system 
is developed and implemented using computer vision 
techniques. The proposed system has a potential application 
to educate people for fish knowledge. 
II. THE SYSTEM FRAMEWORK OF THE PROPOSED 
METHOD 
The proposed fish indexing system can be divided into 
two different sub-systems: off-line and real-time processes. 
The off-line system is shown in Figure 1. The system 
administrator should build the fish database and uses a semi­
automatic tracking algorithm to track each fish in each frame 
in a video chip and record the location information into an 
information table. Then the user can replay the video and 
query the obiects in the video using the indexing interface. 
Video object 
information 
database 
Database 
intcrl'ace 
System interface 
Admin. 
Figure 1. The architecture of the proposed off-line fish recognition system. 
Figure 5. The flowchart of the object tracking process. 
1) Object feature extraction: After the procedure of 
moving object detection and segmentation in the previous 
section, connected component labelling algorithm is applied 
to identify each segmented object but withdrawing the 
smaller area objects. We define the location infromation of 
an object with a Minimal Bounding Rectangle (MBR) and 
the color information of an object with the average color in 
Lab color sapce. Assume that R is the object area in a 
bounding rectangle, the center point coordinates and the 
color information are denoted as follows. 
(Ji )R � L (x-x"jp(y-y)q p,q (x,Y)ER 
L x L Y 
(X y) �((x,Y)ER (x,Y)ER) , R IRI '  IRI 
L (x,y).L L (x,y).a 
(I a b) = ((x,y) E R (x,y) E R 
, , R IRI IRI 
L (x,y).b 
(x,y) E R 
We also record the left-up and right-down comer 
coordinates of the bounding rectangle to represent the region 
of the object. 
The distance of two objects, i andj using position feature 
is denoted as the Euclidean distance between the two center 
points, respectively. 
l.r(p) - .I� (p)1 = �(ice",,, -' - j"",,, _,)' + (i"",e,'_Y - j,e"',, _y)' 
The distance using color feature is denoted as follows. 
1.r(C)-�(C)I = (imLL - ja'LL)2 + (im,"-" - jm'v)2 + (im'Lb - ja,g_b)2 
2) Semi-automatic object tracking: The semi-automatic 
object tracking procedure is used to tracking objects in a test 
video. Figure 6 displays the operations of the procedure. 
The manager select one object in the first frame at a time, 
give the object an identification number and compute the 
corresponding position and color information for the object. 
Repeat tracking the object by applying the minimum 
distance rule on the focus object and the candidate ones. If 
the distance of an object between two continous frame is 
too larger, it means the overlap(occlusion) status is 
occurred. Then a manual process to define the correct 
location of the focus object is required; otherwise, save the 
object information and repeat tracking until the end of the 
video flames. Then select the second object in the first 
frame of the video and reapeat the tracking operation untile 
completing the second object tracking. Finally, we can 
finish the object tracking for all objects and generate the 
information tables in Figure 7. 
530 
�ew frame Getobi"t information 
Manual match 
No (omlap obJecti 
Match object 't 
Yes(sin�leobjecl\ 
Updateobj"t 
infonnation 
Use color and 
position 
infoITIlation 
Figure 6. The operations in semi-automatic object tracking. 
<;egmenlation track fish 
frame_id - fn.me_id 
V 
fish_id 
object_id - objccl_ id name 
eentcr_x fish _id location 
eentcry slate body 
avg I category 
avg a introduction 
8vg b 
mbrl 
mbrl y 
mbr2 -
mbr2_y 
Figure 7. The relationship between different information tables. 
C. Real-time Fish Recognition 
In the real-time fish recognition system (Figure 2), the 
capture frame from CCD is used as input and applied with 
object segmentation operations. In addition, two major 
operations, the object HMMD color feature computation and 
the k-means classification are included in the real-time fish 
recognition procedure. HMMD color model (MPEG-7-
compatible) is a descriptor for quantized colors, which is 
claimed to be more uniform than the HSV color space, was 
proposed by Kim et al. [2]. The HMMD color model was 
developed from the RGB and the HSV color spaces. We use 
128 bins color histogram as the object feature for 
classification. Figure 8 shows two different fishes 
Labidochromis caeruleus and Aequidens Rivulatus, and their 
color histograms using 128-bins HMMD histograms. The 
difference of these two histograms means that HMMD 
histograms play good color features for classification. In our 
experiments, K-means algorithm is applied for fish 
recognition. Let hA and hB represent the corresponding 
HMMD histograms, the distance between two objects can be 
denoted as 
128 
dist(A,B)= L Ih A (i)-hB(i) 1 
i�1 
o REFERENCES 
==========:::::::::::::::::::::::::::::::::::::::::::.I===� 23< 
Figure II. Examples of the proposed system interfaces (a) Off-line fish 
recognition without occlusion (b) Off-line fish recognition with occlusion. 
••• ""IWIIfIIiJle,· .. ... 
__ 6tAt . �  
.. . . . "' �ft';tlJ. 
ceDi" ... ,,.. 
Figure 12. An examples of the proposed system interface of real-time fish 
recognition. 
V. CONCLUSION 
In this paper, an intelligent fish recognition system using 
computer vision techniques is proposed to help aquarium to 
educate people about the fishes in the tanle The designed 
system provides a convenient and friendly interface to help 
the users to retrieve the related fish information they are 
interested. The proposed system also provides a potential use 
for fish management in Marine Parks. 
ACKNOWLEDGMENT 
This work was supported by National Science Council, 
R.O.C., under grant NSC98-2220-E-327-001. 
532 
[I] A. Cavallaro. T. Ebrahimi, "Change detection based on color edges," 
IEEE International Symposium on Vol. 2, pp. 141-144 May 2001. 
[2] Kim, H. 1., Lee, J. S., Jun, S. 8., Song, J. M., Lee, H. Y., "Descriptor 
for quantized color using HMMD color model," 
ISO/IEC/JTCI/SC291 WG II, Lancaster, UK, Feb. pp. 669 (1999). 
[3] A. Cavallaro, O. Steiger and T. Ebrahimi,"Tracking video objects in 
cluttered background," IEEE Trans. Circuits and Systemsfor Video 
Technology, vol. 15, no. 4, Apr. 2005. 
[4] D. Wang, "Unsupervised video segmentation based on watersheds 
and temporal tracking," IEEE Trans. Circuits Syst. Video Technol., 
vol. 8, pp. 539-546, Sept. 1998. 
[5] E.P. Ong, BJ. Tye, W.S. Tye, M. Etoh, "An efficient video object 
segmentation scheme," IEEE International Conference on Vol. 4, pp. 
IV-3361- IV-3364 May 2002. 
[6] Efford, Nick. Digital Image Processing: A Practical Introduction 
Using Java. Addison-Wesley. Essex: 2000. pp. 254-255 
[7] Gonzalez, Richard E. Woods, Digital image processing, 
N.J. :Prentice-Hall, Upper Saddle River, 2002, 2nd ed. 
[8] H. Wang and M. Brady, "Real-time corner detection algorithm 
formotion estimation," Image Vision Comput., vol. 13, pp. 695-703, 
Nov.1995. 
[9] Hui-Huang, Timothy K. Shih, Chi a-Tong Tang and Yi-Chun 
Liao,"Real-time Multiple Tracking Using a Combined Technique", 
Proceedings of the 19th International Conference on Advanced 
Information Networking and Applications, 2005. 
[10] J. C. Choi, S.-W. Lee, and S.-D. Kim, "Spatio-temporal video 
segmentation using a joint similarity measure," IEEE Trans. Circuits 
Syst. Video Technol., vol. 7, pp. 279-286, Apr. 1997. 
[II] J. Pan, COW. Lin, C. Gu and M-T. Sun, " A robust video object 
segmentation scheme with prestored background information," IEEE 
International Symposium on Vol. 3, pp. 803-806 May 2002. 
[12] J. Zhang, L. Zhang, H-M. Tai, "Efficient video object segmentation 
using adaptive background registration and edge-based change 
detection techniques," IEEE International Conference on Vol. 2, pp. 
1467-1470 June 2004. 
[13] S. Liapis, E. Sifakis, and G. Tziritas, "Color and/or Texture 
Segmentation using Deterministic Relaxation and Fast Marching 
Algorithms," in Intern. Conf. on Pattern Recognition, September 
2000, vol. 3, pp. 617-620. 
[14] S-Y. Chien, S-Y. Ma, L-G. Chen, " Efficient moving object 
segmentation algorithm using background registration technique," 
IEEE Trans. Circuits Syst. Video Technol., vol. 12, no. 7, pp. 577-
586, July 2002. 
[15] S. Khan and M. Shah, "Tracking people inpresence of occlusion," in 
Proc. Asian Conf.Computer Vision, Taipei, Taiwan, 2000. 
[16] Y. Zhao, Z. Zhang, Z. Gao, "A simple and workable moving objects 
segmentation method," Electronics in Marine, 2004. Proceedings 
Elmar 2004. 46th International Symposium pp. 585-590 June 2004. 
與主持人爭論optimal的定義，浪費許多時間，這在往後辦研討會時，一定要注意，
同個session內論文歸屬領域的相關性問題。
與會心得
關於這次研討會的地點，選在成都市的電子科技大學(University of Electronics
Science and Technology of China)國際會議中心，位於成都市中心，交通方便。電子
科技大學是中國西南部重點大學之一，也屬於「九八五工程」「二一一工程」學校，
列為教育部第一波開放承認大陸學歷之大學，校園純樸，學生認真，目前全校約有
25000名日間部學生，其中約有9000位碩博士學生，規模相當龐大。我訂的旅館為
Holiday Inn，距離會議會場大約是15公里路程，因為會議報告在早上九點，因此我
選擇自旅館早上七點半搭計程車，大約二十分鐘後到達電子科技大學，成都計程車
費比台灣便宜一些。約在八點鐘抵達會場，註冊完後，與現場負責接待的大學生們，
談論大陸與台灣大學生的生活，在成都市一般大學生畢業起薪月薪不到一千元人民
幣(台幣不到五千元)，但是唸一年大學生活費以及其他費用不算，光是註冊費就超
過五千人民幣，所以能夠就讀大學的人幾乎是全家(包含祖父母的贊助)一起付出才
可能。所以大陸學生大多很用功學習。反觀國內許多大學生，在校期間拼命打工，
不好好讀書，導致畢業後反而找不到好工作。
這次的session，共計有15篇論文，但大會只安排90分鐘報告，令人不敢置信，但
是現場只有8篇的論文報告，缺席者多為大陸學者，8篇的論文報告中，來自台灣的
學者就有4人，顯然國內學者比較負責，本人報告完後，現場來賓發問十分踴躍，有
學者提問我們的研究可以套用在對於人的監控，另外主持人對我們這篇論文的應用
也十分有興趣，本人也都詳加解釋，感覺這次簡報十分成功。
本次與會十分感謝國科會的補助，使本人有機會走向國際接觸相同領域的學者，互
相交流與討論，增進專業領域的視野以及深度。
攜回資料
會議論文光碟片一片，研討會論文如附件。
Feature daaabase 
S temintmace 
Admin. 
Figure 2. The architecture of the proposed off-line fish recognition system. 
In the real-time fish recognition system (Figure 2), the 
capture frame from CCD is used as input and applied with 
object segmentation operation. In addition, the color features 
of the extracted object are computed to match the fish 
features in fish database. Then the related information to 
introduce the query fish is shown on the system interface. 
The detailed designs of these two systems are described in 
the following sections. 
III. THE USED COMPUTER VISION TECHNIQUES 
A. Moving Object Detection and Segmentation 
The moving object detection and segmentation is the 
preprocessing in our system. The fish image object is 
extracted via the difference between the current video frame 
and a background reference model. The process can be 
divided into four main procedures: 
1) Constrction of the background reference frame: The 
background reference frame B is achieved using the midian 
of N continous frames with time interval f...f and denoted as 
follows. 
B(x,y) = median {I k (x,y)lk = 1,1 + At, ... ,l + (N - l)At } 
Where B is the reference background and Ik is the k-th 
image frame. 
2) Background subtraction: For a current frame C, the 
following formula is applied to obtain the initial object 
masks(IOM). 
10M = {I, if(IBS(B,C)1 > T) 
0, otherwise 
Where T is the threshold computed using the Optimal 
threshold algorithm[6]. 
3) Shadow elimination:The 10M image contains 
shadows on the object's border, a shadow elimination 
operation is used to obtain a more corrected object image 
and shown as follows. 
I 11, ifa,s, d (p).L ,s,/lA lclcp).a-Blcp).al ,s" I\ ldCp).b-BICP).bl,s, 'b SP (p) = BI (p).L a 
o , otherwise 
529 
Where SplCp) is the shadow value on the position p in the 
t-th frame and a , f3 ' T a' Tb are theshold parameters for 
limiting the range of shadow and L, a, b are the values in 
the CIE Lab color space[13]. If the value is 1, it means that 
the position p is under shadow, otherwise, it mean p is under 
the object image. Figure 3 shows an example of the shadow 
elimination. 
Current fTame 
Figure 3. An example of shadow elimination for fish objects. 
4) Post-processing: To reduce the noise effect, a median 
filtering operation is performed[7]. The result is shown in 
the following Figure. 
Figure 4. An example of noise removal using a median filter. 
B. Fish Object Trackingfor Off-line Fish Recognition 
Since the fish body is non-rigid, the use of shape as 
features is not appropriate. In this study, color and location 
information of objects are selected as features to achieve the 
object tracking. In our fish object tracking, two major 
procedures including (1) Object feature extraction and (2) 
Semi-automatic object tracking are applied. Figure 5 shows 
the flowchart of the tracking process. A pre-selected fish 
video chip is used for demo. For each frame, the object 
detection and segmentation are performed to obtain the 
object mask. Then the corresponding image content 
according to the mask is extracted as object features. Semi­
automatic object tracking is applied to build object 
information table. This output table can be used to the fish 
recognition in our off-line system. 
extraction 
Semi-automatic 
object tracking 
Object tracking .. 
.. 
f 05 - " 
" 1\ ,fv ,� J " " ., .. .. " . "'-
Figure 8. An example of two fishes and their color histograms using 128-
bins HMMD histograms.(a) Labidochromis caeruleus (yellow lab) (b) 
Aequidens Rivulatus. 
IV. EXPERIMENTAL RESULTS 
In our real-time recognition experiments, six different 
fishes with 100 different image frames (80 frames for 
training and 20 frames for testing) are used. We compute the 
corresponding HMMD histograms for the 600 fish objects. 
Then k-means method is applied to the HMMD histograms 
of training objects to obtain k represented histograms for 
each fish. Then K-NN classification is applied to test objects. 
Table 1 shows the experimental results with different k 
values. When the k value is greater than 6, the results with I­
NN, 3-NN and 5-NN are all above 0.9 accuracy. Figure 9 
shows the object segmentation results using background 
subtraction and shadow elimination and Figure 10 shows the 
object tracking results for two different fishes. 
TABLE I. 
k cluster 
2 
3 
4 
5 
6 
7 
8 
9 
10 
THE CLASSIFICATION ACCURACY RATE FOR SIX DIFFERENT 
FISH RECOGNITION. 
K-NN 
3 5 
0.92 0.63 0.8 
0.93 0.89 0.63 
0.97 0.89 0.82 
0.95 0.92 0.83 
0.95 0.91 0.88 
0.95 0.93 0.93 
0.95 0.93 0.93 
0.97 0.93 0.90 
0.95 0.93 0.92 
531 
, .. . . 
- , 
Z � __ 
Figure 9. Fish object segmentation results using background subtraction 
and shadow elimination 
Figure 10. , Fish object tracking results for two different fishes 
Figure 11 shows the examples of the proposed system 
interfaces (a) Off-line fish recognition without occlusion (b) 
Off line fish recognition with occlusion. Figure 12 shows an 
example of the proposed system interface of real-time fish 
recognition 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
