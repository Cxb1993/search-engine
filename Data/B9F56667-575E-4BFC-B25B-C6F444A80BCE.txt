2 
 
Stuckman[7]用主動式紅外線感測器來感應駕駛
者盲點區域出現之車輛，並採用 DSP 平台來控
制感測器；[8]提出適應性樣版比對(Adaptive 
template matching, AdTM)演算法來偵測盲點區
域之車輛，針對進入盲點區域的車輛進行樣版
比對分數計算，當符合樣版的物體靠近自車
時，此分數會增加，而遠離時此分數會遞減，
當分數過低時，則消除此物件，如此便可減少
樣版比對錯誤的物件。Tohru [9]用 CCD 感測器
來監看車輛盲點區域，此感測器之特色為利用
兩片鏡頭之視差，可得知影像中像素點之距離
與高度，並藉此判斷具有高度的車輛物體；[10]
是利用 IPM 轉換，再配合影像輪廓擷取，進行
樣版比對與分析，來偵測盲點區域車輛，[11]
攝影機組成的系統監視前方、左後方與右後方
三個區域是否有車輛存在，[12]會將原始影像分
割為數十個區塊，以灰階特徵判斷屬於背景或
前景，接著透過定比例特徵轉換來判定障礙物
存在與否。 
國內論文對車輛盲點區域警示系統的研究
包括[13]中以低成本超音波雷達組成雷達陣
列，偵測視線死角以及側邊車輛距離的遠近，
並利用偵測距離與側邊碰撞時間，進行側邊防
撞警示策略之設計與研發；[14]提出利用兩個以
上超音波感測器到障礙物間不同距離之幾何關
係，精確的解析出實驗車輛與障礙物間的距離
與方位，進行設計側邊防撞警示策略；[15]是利
用攝影機做為偵測用的感測器，先尋找路面邊
線的特徵，以此定義出車側視覺死角的偵測範
圍，若系統偵測出有其它車輛的存在，便會發
出警示以提示駕駛者注意；[16]提出一種車用全
景影像裝置，以克服視覺死角，將設置於車輛
外側的 CCD 攝影機，擷取車柱外側的車外影
像，直接顯示於相對應之車柱內側的 LCD 螢幕
上，讓駕駛者可以直接監看盲點區域，[17]以尋
找車輛底部特徵，透過攝影機透視轉換計算兩
側接近車輛的距離，並根據接近程度的不同加
以警示。 
 
二 系統說明 
在正常情況下，人類雙眼的水平可視角度
約為 180 度，配合頭部左右旋轉，可於兩個方
向各增加約 60 度的單眼視覺範圍，因此結合頭
部轉動和眼球平掃，人類約有 300 度的可視範
圍(field of vision)。但是考慮駕駛者的行車車速
及專注於前方的行車狀況時，將會產生狹視效
應(tunnel vision)，減少視野範圍，如圖 1 所示。 
參考圖 2，當駕駛者在靜止車內時，其視
野範圍為圖中 LN 與 RN 連線以右的區域，若駕
駛者在行車時，考慮狹視效應造成的影響，會
形成圖中 HLNLV與 HRNRV兩個三角形盲點區。 
 
圖 1 駕駛者視野範圍 
 
圖 2狹視盲點區域俯視圖 
4 
 
本車道線演算法分成搜尋、追蹤、副搜尋
三種模式，三者的差別主要在於搜尋範圍和啟
動時間，搜尋模式會在演算法剛啟動或追蹤模
式追蹤失敗時執行，主要目的是對全畫面進行
搜尋，判定車道線存在的可能性；追蹤模式則
是繼承搜尋模式搜尋到的車道線資訊，在前一
張影像車道線位置的附近進行搜尋，其中，副
搜尋模式在車道線偵測中具有防止過度追蹤的
功能，執行時間接續在追蹤模式之後，當影像
中出現位於追蹤模式追蹤區以外的車道線時，
副搜尋模式將會加以尋找，當追蹤模式偵測失
敗時，若影像中另存在一條車道線且已被副搜
尋模式發現，將可以減少搜尋模式中追蹤模組
累積資訊的時間，增加系統的反應速度，此外，
若本模式搜尋到的車道線位置比追蹤中車道線
位置離自身車輛更近的話，將會以本模式的車
道線資訊將追蹤模式的資訊取代，使本演算法
得以一直對最近的車道線進行追蹤，副搜尋模
式以近端車道線取代追蹤模式中遠端車道線的
例子可參見圖 7。 
 
(a)遠方車道線追蹤中 
 
 (b)副搜尋模式搜尋到近端車道線 
   
(c)近端車道線取代遠端車道線 
圖 7 副搜尋模式切換追蹤車道線 
 車輛偵測結果 
本演算法針對車輛位置分析區間之劃分如
圖 8 所示，在側方影像中，車輛移動方向大部
分為橫向，因此演算法將影像依水平方向分割
為五個偵測區：最左與最右為車輛進入區，其
次為車輛接近區，最中間為側方車輛偵測區。 
 
 (a)左側影像  (b)右側影像 
圖 8 車輛偵測區劃分 
搜尋方法將由上而下，由進入區和接近區
的交界處為起點向影像外側搜尋，當遇到已追
蹤物件存在的列時，會跳至已追蹤物件的下方
搜尋，搜尋模式與追蹤模式最大的差別在於，
追蹤模式的目標只有一個，而搜尋模式則會盡
可能將此區域新出現的物件都搜尋出來。參考
圖 9，當物件進入本追蹤模式，依其在前張影
像中陰影頂部的位置向影像內側上方設立搜尋
起點，以搜尋起點開始向影像外側下方搜尋該
物件於此張影像中的頂部位置，若搜尋到前張
影像中上下位置的垂直中點高度仍未發現物件
起點時則偵測失敗，若有尋找到起點則繼續往
下搜尋到垂直方向陰影結束。 
 
圖 9 前後進入區追蹤模式示意圖 
在本區的物件可以同時看到物件側身與頭或尾
的某一端，因此本區的物件兼具垂直與水平的
特性，追蹤的方法仍然以垂直特徵為主，接近
6 
 
輛在影像中會以黑白相間的水平橫條標示其底
部位置，位於接近區的車輛除標示底部位置
外，尚會標記其左(右方接近區)右(左方接近區)
側某一邊的垂直邊界。 
 
圖 12 車輛右側偵測結果 
偵測成果如下: 
 
雨天機車 縱向車輛 縱向雜訊干擾
 
標線複雜 大客車 標線複雜 
 
遮蔽斑馬線 路面狀況複雜 複雜標線 
 
陰影遭縱向切
割 
縱向遮蔽物件
偵測 
安全島偵測 
接下來針對偵測結果進行數據分析，數據
計算方法如下： 
A：事件發生且系統偵測到事件發生之畫面數。 
B：事件發生但系統未偵測事件發生之畫面數。 
C：事件未發生但系統偵測事件發生之畫面數。 
D：事件未發生且系統未偵測事件之畫面數。 
偵測率：A/(A+B) 
誤報率：C/(C+D) 
準確率：(A+D)/(A+B+C+D) 
 車道線偵測結果 
車道線偵測結果請參見表 1。首先比較車
輛左右方可以發現，左方偵測率在各天候狀況
下都比右方來得低，分析原因是因為第二章中
建立的平行等距模型是以右方影像建立，左方
影像在使用上直接取其映射，作為左側之模
型，在左右不完全對稱的情況下，造成左右偵
測率的差異；另外分析不同天候狀況，結果為
陰天準確率略低於晴天，而雨天受到路面反光
的影響，準確率較其他天氣低，且誤報率較高。
在斑馬線偵測的部分，在表中所有影像共計出
現 32 個，其中 25 個有偵測成功，且偵測成功
時確實大幅降低車道線於路口處偵測失誤比
例。 
表 1 車道線偵測結果 
 
車輛右側 車輛左側 
晴 陰 雨 晴 陰 雨 
取樣張數 2500 1200 1700 2000 1000 1300
偵測率 95.9% 95.4% 95.2% 94.3% 93.6% 89.1%
誤報率 0.1% 0.6% 1.4% 0.4% 0.3% 1.7%
準確率 96.0% 95.3% 94.2% 94.3% 93.5% 88.4%
表 2 右側影像車輛偵測結果 
 
側方偵測區 接近區 
晴 陰 雨 晴 陰 雨 
取樣張數 2500 1200 1700 2500 1200 1700
偵測率 97.6% 91.6% 90.5% 95.6% 90.1% 85.0%
誤報率 6.2% 5.9% 28.5% 14.9% 19.5% 49.7%
準確率 98.7% 96.9% 92.1% 96.5% 93.8% 84.9%
表 3 左側影像車輛偵測結果 
 
側方偵測區 接近區 
晴 陰 雨 晴 陰 雨 
取樣張數 2000 1000 1300 2000 1000 1300
偵測率 95.7% 92.9% 87.0% 91.2% 89.5% 83.9%
誤報率 2.8% 7.1% 30.6% 15.3% 29.2% 50.0%
準確率 98.6% 97.4% 91.5% 95.6% 92.8% 83.3%
 
 
 車輛偵測結果 
