 2
Efficient Geometric Measure of Music Similarity 
 
1. Introduction  
With the rapid growth of digital audio data, contend-based music retrieval has become a popular 
research topic in the past few years. When searching for digital music one must do so by text. This 
means that some information such as the name of the song or the name of the artist must be remembered. 
In many cases, a user may not remember such information, even though they might be able to hum or 
sing a fragment of the song. In that case query by humming or singing would be a more reasonable 
search method. Many different music retrieval systems have been created for academic research or 
business in recent years. Some of these systems allow users to search for music by inputting a fragment 
of the query melody by singing or humming. 
Similarity measurement in music matching is all important for a music retrieval system, whose 
effectiveness is directly affected by feature selection and distance metric. Although pitch is the most 
commonly used feature, it alone is not sufficient for search in a large database [3]. Many researchers 
[10][11] indicated that pitch and duration are the most important attributes, and their findings will be 
followed in this research.  
Techniques based on string matching have been extensively explored in the literature, including 
edit distance [9] and n–gram [2][5]. However, their use of pitch sequences as feature has the drawback 
of retrieving too many irrelevant music documents with similar pitch sequences but rather different 
rhythm. 
Clifford et al. [4] considered the music notes in a melody as a set of points in a two-dimensional 
Euclidean space. The music matching problem is equivalent to finding the partial subset match of two 
point sets. However, its discrete point representation has the drawback of low tolerance to slight 
displacement of points.  
D. Ó. Maidín [8] proposed a geometric matching technique for music similarity measurement, 
considering both the pitch and rhythm information Each note is represented as a horizontal line segment 
so that a sequence of notes can be described as a rectangular contour in a 2-D coordinate system, in 
which the horizontal and vertical coordinates correspond to time and pitch value, respectively. This 
approach juxtaposed two melodies of equal duration and transposed one melody in the vertical direction 
(in pitch values) to evaluate the minimum area between them. Francu and Nevill–Manning [6] followed 
the geometric matching technique, except that both the query and the reference are sampled and 
quantized into a sequence of notes of equal small period (of 20 milliseconds). They rescaled and 
transposed the query in vertical and horizontal directions to find the minimum difference between the 
query and the reference. Aloupis et al. [1] improved the above two geometric matching techniques by 
using a binary search tree to achieve efficient search for the best match of two melodies. Our previous 
work [7] improved the efficiency of geometric matching by using pitch intervals instead of pitches to 
achieve key invariance and to avoid searching in the vertical direction, and utilizing a branch–and–prune 
mechanism to quickly discard most of the incorrect horizontal positions of the query. In this work, we 
further improve our previous work by constructing a balanced binary search tree to provide both quick 
determination of the step size of each move of the query melody and quick update of the area after each 
move. 
 4
then represented as >< jr , rt j  and >< iq , qt i , respectively, where ][ 1+= jr Rstartt j  is the starting time of 
note Rj+1 but θ+= + ][ 1iq Qstartt i  is the starting time of note Qi+1 plus a the time replacement θ , which is 
the total step size at the moment whenever it is referred, since the reference melody is fixed whereas the 
query melody is dynamical. For easy implementation, we define a dummy item >< mq , qt m , where =mqt  
the ending time of Qm plus θ  and qm = 0, with assumption that the ending time of one note is the same 
as the starting time of the next note. Then melody Q can be represented as the PID sequence 
miiq , qt i  ,,2 ,1)( L=>< . The PID sequence for the reference R is defined in the same fashion by 
njjr , rt j  ,,2 ,1)( L=>< . 
2.2. Geometric Matching using A Binary Search Tree 
After a move of the query, at least one pair of vertical edges coincide, some rectangles grow in width, 
some become narrower or even varnishing, and some are unaffected, and thus the area must be 
reevaluated. In this work, we utilize a balanced binary search tree to efficiently indicate all the changes 
and reevaluate the area. 
2.2.1. Binary Search Tree Construction 
As depicted in Figure 1, the query and the reference are modeled as monotonic pitch interval rectilinear 
functions of time. The region between two melodies is partitioned into rectangles Cα, k ,,2 ,1 L=α . Each 
rectangle can be specified by its four edges, each of the left side and the right side is formed by a vertical 
edge of the query or the reference; the top and the bottom edges are formed by a pitch interval of the 
query and a pitch interval of the reference. The distance between the two melodies is defined as the total 
area of these rectangles ∑∑ == ⋅== kk hwCA 11 )(|| α ααα α , where αw  and hα= || αα ji rq −  are the width and the 
height of the α-th rectangle Cα formed by pitch intervals αiq  and .αjr  The type of a rectangle can be 
determined by its vertical edges; that is, it is growing if its left edge and right edge are from the 
reference and the query, respectively; it is shrinking if its left edge and right edge are from the query and 
the reference, respectively; it is unaffected if the two edges are both from the query or both from the 
reference. As depicted in Figure 1, the rectangles between the query and the reference are categorized 
into 3 types by the sets }4 ,1{=−TW , }7 ,5 ,3{0 =TW , and }6 ,2{=+TW . 
 
 6
and right, say Ci-1 and Ci+1, must be either unaffected or growing. If Ci+1 is growing or unaffected, then 
the move would change its type to “unaffected” or “shrinking”, respectively. The type of Ci-1 is updated 
in a similar manner. 
   
(a) (b) (c) 
Figure 2. (a) A shrinking rectangle Ci. (b) The rectangle Ci in (a) is vanishing and the rectangle Cj with 
zero area is created after the query  
make a move of 1θ∆ . (c) The rectangle Cj in (b) grows up into a new rectangle Ck after another move of 
2θ∆ . 
Consider the example depicted in Figure 3(a), since the widths of the shrinking rectangles C3 and 
C5 are both equal to θ∆ , they would be vanishing and two rectangles C3’ and C5’ with zero area would 
be created, after the move of step size θ∆ , as shown in Figure 3(b). Moreover, the rectangles adjacent 
to C3 or C5, say C2, C4, and C6, would change their types. While checking the neighbors of C3, the 
rectangles C2 and C4 change their types from unaffected and growing to shrinking and unaffected, 
respectively. And then while checking the neighbors of C5, the rectangles C4 and C6 change their types 
from unaffected and growing to shrinking and unaffected, respectively. Note that during this move C4 
changes types twice. To keep the order of rectangles, we use a linked list to link the leaves 
corresponding to the rectangles from left to right in the region enclosed by the two melodies. In such a 
way, neighbors of a rectangle can be easily referred to. 
  
(a) (b) 
Figure 3. (a) The region between the query and the reference is partitioned into 7 rectangles. (b) After a 
move, the rectangle C3 and C5 are vanishing, and their neighboring rectangles change types. 
Finding the step size θ∆  for next move requires O(log m) time. On average, the number of leaves 
to be inserted or deleted in each step is a constant. For each newly inserted or deleted leaf, it requires 
O(log m) time to update its ancestors. After each move, each growing rectangle increases its width by 
the step size and each shrinking rectangle decreases its width by the step size, and thus the area between 
the two melodies can be recalculated immediately. Since −TH , 0TH , and +TH  are recorded in the root of 
the tree, the area can be updated easily by adding the value θ∆⋅− −+ )( TT HH  to the current value of area A; 
that is, θ∆⋅−+← −+ )( TT HHAA . At most O(mn) moves are required, and thus the total time required to 
compute the minimum area is O(mn log m). The algorithm Pitch–Interval–Area with BST for 
 8
Sequences, Journal of Computers (2007), to appear. 
[8] D. Ó. Maidín, A geometrical algorithm for melodic difference, Computing in Musicology 11 (1998) 
65–72. 
[9] M. Mongeau and D. Sankoff, Comparison of musical sequences, Computers and the Humanities 24 
(1990) 161–175. 
[10] L. A. Smith, R. J. McNab, and I. H. Witten, Sequence–based melodic comparison: A dynamic 
programming approach, Computing in Musicology 11 (1998) 101–117. 
[11] F. Wiering, R. Typke, and R. C. Veltkamp, Transportation distances and their application in 
music–notation retrieval, Computing in Musicology 13 (2004) 113–128. 
Face Detection Based on Skin Color Segmentation and SVM Classification 
 
 
Hwei-Jen Lin, Shwu-Huey Yen, Jih-Pin Yeh, and Meng-Ju Lin 
Department of Computer Science and Information Engineering, Tamkang University 
hjlin@cs.tku.edu.tw 
 
Abstract 
 
This paper proposes an improved version of our 
previously introduced face detection system based on 
skin color segmentation and neural networks. The 
new system uses a support vector machine (SVM) 
based method for verification.  
 
1. Introduction 
 
Recently, face detection has received much 
attention and has been an extensive research topic 
[1~4]. It is the important first step of many applications 
such as the face recognition system, facial expression 
analysis, surveillance systems. We previously 
proposed an approach for detecting human faces in 
color images under different illumination condition, 
scale, rotation, with/without glasses, based on 
classification by neural networks. In this paper, we 
modify the approach by using SVM for classification. 
Firstly, skin color segmentation is performed to find 
skin color regions. Secondly, possible face blocks are 
located by using some restrictions on these regions. 
Thirdly, eye detection and matching are carried out on 
each possible face blocks to obtain face candidates, 
which are then verified by an SVM classifier. 
 
2. Face Candidate Searching 
 
We obtain face candidates through three steps: skin 
color segmentation, locating possible face blocks using 
geometry property of faces, and eye detection for 
filtering out some non-face blocks 
 
2.1. Skin color segmentation 
 
The distribution of skin colors clusters in a small 
region of the chromatic color space and thus skin color 
detection is firstly performed to reduce the 
computational complexity. Among numerous color 
spaces, RGB color space is sensitive to the variation of 
intensity, and thus it alone is not sufficient to use only 
RGB color space to detect skin color.  
Due to the fact that both the normalized RGB space 
and HSV color space can reduce the lighting effect, we 
combine them with the RGB color space to detect skin 
pixels. Since it suffices to represent color using only 
two values in the normalized RGB color space, we use 
the values of r = R/(R+G+B) and g = G/(R+G+B). A 
pixel is labeled as a skin pixel if its color values 
conform to the following constraints: 
 
50)0or    359340( and ,0130 ,70120
 0.37,g0.25 ,60330 ,11 || ,
≤≤≤≤≤≤≤≤
≤≤≤≤≥−>
HH.V..S.
.r.GRGR
 
As a result, we can generate a binary skin map where 
the white points represent the skin pixels and the black 
points represent the non-skin pixels. Then, we apply 
median filter and morphological opening operation to 
the skin map to eliminate small skin blocks. Afterward, 
utilizing connected component operation to find out all 
connected skin regions and each of the skin regions is 
labeled by a bounding box. 
 
2.2. Locating possible face blocks 
 
To check if a skin region contains a face, we use the 
following three constraints: (1). The area of the region 
is greater than 30×30, (2). The ratio of the height to the 
width of the bounding box, denoted by Aspect Ratio, is 
between 0.8 and 2.6, and (3). The percentage of the 
skin pixels in the bounding box is greater than 40%. 
Any skin region satisfying these constraints is regarded 
as a possible face block; otherwise, a non-face region. 
 
2.3. Eye detection 
 
In general, the intensity of eye is darker than that of 
other facial features in a face and it does not belong to 
skin region. Utilizing this property of eyes, we can find 
out some eye pixels and present them with white points 
in the possible face block. Median filter is applied to 
remove noises and then connected component 
operation is performed to find all so-called eye-like 
blocks circumscribed with a bounding box, and then 
examined by the three following conditions to verify if 
it contains an eye: (1). The first condition is that the 
Aspect Ratio of the block is between 0.2 and 1.67, (2). 
