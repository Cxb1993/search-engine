exemplar-based inpainting technique or matting, are 
used to develop the new types of forged image.  
This project focuses on the detecting images forged 
by the techniques of exemplar-based inpainting. We 
propose a fast and effective forgery detection 
algorithm for exemplar-based inpainting forged image. 
Our algorithm consists of two major parts: suspicious 
region detection and forged region identification. In 
the first part, we compute the similarity among 
regions in the image to find the region pairs with 
high similarity, and then the proposed corresponding 
vector field is applied to find the suspicious 
regions. This vector field is especially forged image 
with uniform background by using corresponding 
vector. In the second part, we present a multi-region 
correlation (MRC) technique to analyze the relation 
between all the suspicious regions, and then identify 
the forged regions. Moreover, a fast searching 
algorithm based on weight transformation is proposed 
to speed up the similarity detection. 
 
英文關鍵詞： Digital image forensics, digital forgery detection, 
exemplar-based inpainting technique 
 
  1 
 
一、前言 
由於網路普及化、電腦效能提升及相關軟硬體快速更新，使得數位多媒體科技迅速發展，由於數
位影像已經逐漸成為我們生活中獲取重要資訊或是新聞媒體傳播的管道，進步迅速的影像處理技術創
造出更多種類的數位偽造影像。因此數位影像偽造偵測(Digital Image Forgery Detection)受到人們的關
注，此領域正處於迅速發展階段，這些技術可應用在許多地方，如：保險處理、新聞雜誌照片的真偽
識別、犯罪現場照片的真偽辨識…等。目前存在的數位影像偽造偵測的方法分成Active-based approach 
[1][2][3] 和Passive-based approach [8]-[25]。Active-based approach其主要特徵為在數位影像中必須預先
置入某些資訊，如浮水印，而偵測時再從影像中取出事先置入的資訊進行識別之工作；Passive-based 
approach則為不依賴任何預先置入某些資訊下，針對影像的真偽及來源進行識別工作。Active-based 
approach的缺點是一般數位裝置並沒有支援預先置入資訊之功能，因此要使用這類的方法必須有特殊裝
置或後處理置入資訊到數位影像中，所以無法廣泛使用。 
 
二、研究目的 
有別於目前大部分的研究，我們將以自動產生的偽造影像作為研究主軸，此類型的偽造方式我們
專注在偵測exemplar-based inpainting technique，因為exemplar-based inpainting technique具有良好修補影
像缺損區域的能力，此類型影像真實性的問題值得被注意。本研究提出一個有效且快速的影像偽造偵
測演算法，針對Digital Image Inpainting technique所產生的數位偽造影像進行偵測，根據相關特徵偵測
能夠協助使用者進行數位影像真偽判斷，實驗結果證明我們提出的影像偽造偵測演算法確實具有高準
確率識別真實影像與偽造影像。 
 
三、文獻探討 
數位影像偽造偵測越來越受到注意，許多相關研究已經有一定的成果，因此已經有Survey paper 
[4][5][6][7] 整理相關研究之結果，根據Mahdian et al.[5] 提出一般偽造影像的種類可以分為三類， (1) 
Removing-based forgery: removing or concealing region of interest in the digital image ； (2) 
Compositing-based forgery: compositing region of interest into the digital image；(3) Misrepresenting-based 
forgery: misrepresenting the image information。大部分的數位偽造偵測相關研究都是針對上述分類所產
生的偽造影像進行偵測，我們依據擷取不同重要特徵來回顧相關研究：  
（一）Identification of image source([20][21][22][23])：數位影像都是來自不同的數位影像裝置，由於不
同的數位影像裝置，在影像裝置內部皆有不同的參數設定或影像處理核心，因此通常經由這些同一裝
置所產生的影像會有特殊的特徵，當影像中有不一致的特徵出現時，極可能此影像為偽造影像。 
（二）Re-sampling[18][19]：在創造影像合成時，通常需要作re-sampling的操作(如 : resize、rotate、
translate)，而re-sampling也會伴隨interpolation，因此像素之間的關連性會發生變化，其產生特殊的週期
關係可作為判斷偽造的依據。 
（三） Lighting direction[15][16][17]：一般常見合成影像通常是由兩張以上的來源影像所合成而成，
但通常很難保持一致的光源條件，因此不同來源影像其拍攝環境不一樣也會導致光源的方向不一樣，
所以光源不一致性能夠用來檢視是否為偽造影像。 
（四）Region duplication (copy-move or copy-paste)[8][9]10][11]：Region duplication是一般常見的影像偽
造方法，其偽造的方式是在影像中複製一個區域然後貼到同一影像中另一個區域，它可能是要隱藏一
個物件或一個場景，一些研究者提出不同方法去偵測Region duplication 的問題。 
  3 
 
Figure 1. Illustration of relation group. 
我們使用 key value的方式群聚相似 color intensity feature 的 blocks，利用 binary search尋找最相似
的 key value，透過 matching相似 color intensity feature 的 blocks能夠準確尋找到 best match block，如此
可以不必浪費時間在 matching color intensity feature相似度低的 blocks上，有效提升 srarching 效能。 
在我們提出的方法中，目的希望將 target block 的 color intensity feature 保留，因此 weight value扮
演非常重要的角色。另外，key value的決定與 search range的大小是息息相關的，search range的大小
影響整個 matching algorithm的執行效能，因此我們也將分析不同 search range的大小對於效能的影響。 
為決定能夠代表 target block的 color intensity feature，因此我們定義一個 measure function，我們依
據 exhaustive search的 similarity detection結果為標準，定義一個完整性(Completeness)measure function，
完整性越高表示所選擇的 intensity feature越具代表 target block的 color intensity feature，公式定義如下： 
%e d
e
R R
Completeness
R

                          (1) 
where eR 為 exhaustive search 的 similarity detection 結果， dR 為不同 weight transformation 的 similarity 
detection結果。 
 在此我們測試四種不同 weight transformation所產生的效果，個別為相同 weight、偶數 weight 和奇
數weight，及質數(prime number) weight transformation，我們針對key value盡量能夠唯一代表 target block
的 color intensity feature 之特性進行分析，我們定義一個 measure function 來量測 key value 的唯一性
(Uniqueness)，公式定義如下:  
1 1 %
B
N
Uniqueness
N
                             (2) 
where 1 1N  為總共唯一 key value對應到一個 target block的個數， BN 為所有 target block的個數。 
Figure 2 呈現 prime numbers weight transformation具有最高的 one-to-one效果，另外，奇數 weight 
transformation也具有一定程度的 one-to-one效果。  
  5 
好的 key value 能夠以最小 search range 達到最佳效能，因此 search range 將影響執行的效能與
matching 效果，search range大有較佳的 matching 效果，時間複雜度接近 exhaustive search，search range
小有較佳的時間複雜度，但 matching 效果較差，我們必須在兩個目標中取得平衡，因此我們分析每一
種 weight transformation的最佳 search range設定。我們的目標是希望在速度與完整度取得平衡，因此
我們要求完整度達 90%以上的相對應的 search range所執行的時間，為此演算法的最佳效能。 
 
五、結果與討論 
 本章節將驗證我們提出偽造偵測演算法的有效性，程式開發環境為 Visual Studio 2005 搭配使用
OpenCV library，實驗設備為桌上型電腦(Intel Core 2 Duo CPU E8400 3.0GHz, 2GB RAM)，實驗參數為
Block Size = 5 5 、  = 0.5、 ,  = 0.7、 cT = 3，測試影像為使用 Criminisi’ algorithm所產生的偽造
影像，另外 copy-move forgery是使用 PhotoImpact 所產生的偽造影像。 
 本實驗的目的是驗證提出演算法的有效性，我們使用五種不同的實驗來驗證，實驗 1為 single forged 
region和沒有 uniform background的偽造偵測結果，實驗 2為 single forged region和有 uniform background
的偽造偵測結果。Figure 4.的結果為針對 single forged region和沒有 uniform background 的測試影像進
行偵測，如 Figure 4.(a)所示，影像中 woman 為 target region，Figure 4.(b)將 woman移除； Figure 4.(c)
為 example-based inpainting techniquen 所產生的偽造影像；Figure 4.(d) 顯示初步運算出的可疑區域的部
分，我們可以看到在部分的背景區域有許多被判定為可疑區域。Figure 4.(e)顯示我們提出的演算法能夠
準確偵測出 forged region 並且有效排除其他 non-forged region 產生的 false alarm；而另一方法 Wu’s 
algorithm的結果只能顯示粗略的 forged region並且無法排除其他 non-forged(Figure 4.(f))。Figure 5則顯
示另外一個具有均勻背景的影像。Figure 5.(a)為原始影像，而 Figure 5.(b)為經過 inpainting 處理後的偽
造影像。Figure 5.(c) 為相似區塊搜尋的結果，可以觀察到在背景的地方有很大的一部份成為可疑區域，
這是一般用相似度來處理的方法會遇到的問題，因為均勻背景很容易造成這種現象；而我們的方法之
結果(Figure 5.(d))可大幅度改善這種現象，找出相當正確的偽造區域。 
 
   
(a)                          (b)                       (c) 
   
(d)                          (e)                        (f) 
  7 
[5] B. Mahdian and S. Saic, “Blind methods for detecting image fakery”, in IEEE International Carnahan Conference on Security 
Technology, page(s): 280 - 286, 2008. 
[6] Z. Zhang, Y. Ren, X. J. Ping, Z. Y. He and S. Z. Zhang,“A Survey on passive-blind image forgery by doctor method detection”, 
in International Conference on Machine Learning and Cybernetics, page(s): 3463 - 3467, 2008. 
[7] W. Luo, Z. Qu , F. Pan and J. Huang, “A survey of passive technology for digital image forensics”, in Frontiers of Computer 
Science, page(s): 166 - 179, 2007. 
[8] J. Fridrich, D. Soukal and J. Lukas, “Detection of copy-move forgery in digital images”, in Proceedings of Digital Forensic 
Research Workshop, page(s): 55 - 61, 2003. 
[9] A. Langille and M. Gong, “An Efficient Match-based Duplication Detection Algorithm”, in Proceedings of the 3rd Canadian 
Conference on Computer and Robot Vision, page(s): 63 - 71, 2006. 
[10] B. Mahdian and S. Saic, “ Detection of copy–move forgery using a method based on blur moment invariants”, in Forensic 
science international, page(s): 180 - 189, 2007. 
[11] H. L. Huang, W. Q. Guo and Y. Zhang, “C. Rey and J. L. Dugelay, “A survey of watermarking algorithms for image 
authentication”, in EURASIP Journal on applied Signal Processing, special issue on image analysis for multimedia 
interactive services, page(s): 613 - 621, 2002. 
[12]  F. Hartung and M. Kutter,” Multimedia watermarking techniques”, in Proc. IEEE, page(s):1079 - 1107, 1999.  
[13] C. S. Lu and H. M. Liao, “Structural digital signature for image authentication: an incidental distortion resistant scheme”, in 
IEEE Transactions on Multimedia, page(s): 161 - 173, 2003. 
[14] H. Farid, “Image forgery detection”, in IEEE Signal Processing Magazine, page(s): 16 - 25, 2009. 
[15] B. Mahdian and S. Saic, “Blind methods for detecting image fakery”, in IEEE International Carnahan Conference on Security 
Technology, page(s): 280 - 286, 2008. 
[16] Z. Zhang, Y. Ren, X. J. Ping, Z. Y. He and S. Z. Zhang,“A Survey on passive-blind image forgery by doctor method detection”, 
in International Conference on Machine Learning and Cybernetics, page(s): 3463 - 3467, 2008. 
[17] W. Luo, Z. Qu , F. Pan and J. Huang, “A survey of passive technology for digital image forensics”, in Frontiers of Computer 
Science, page(s): 166 - 179, 2007. 
[18] J. Fridrich, D. Soukal and J. Lukas, “Detection of copy-move forgery in digital images”, in Proceedings of Digital Forensic 
Research Workshop, page(s): 55 - 61, 2003. 
[19] A. Langille and M. Gong, “An Efficient Match-based Duplication Detection Algorithm”, in Proceedings of the 3rd Canadian 
Conference on Computer and Robot Vision, page(s): 63 - 71, 2006. 
[20] B. Mahdian and S. Saic, “ Detection of copy–move forgery using a method based on blur moment invariants”, in Forensic 
science international, page(s): 180 - 189, 2007. 
[21] H. L. Huang, W. Q. Guo and Y. Zhang, “Detection of copy-move forgery in digital images using SIFT algorithm”, in IEEE 
Pacific-Asia Workshop on Computational Intelligence and Industrial Application, page(s): 272 - 276, 2008. 
[22] W. Li, N. Yu and Y. Yuan, “Doctored JPEG image detection”, in IEEE International Conference on Multimedia and Expo, 
page(s): 253 - 256, 2008. 
[23] J. Lukas and J. Fridrich, “Estimation of primary quantization matrix in double compressed jpeg images”, in Proc. Digital 
Forensic Research Workshop, page(s): 67 - 84, 2003. 
[24] Z. Qu, W. Luo and J. Huang, “A convolutive mixing model for shifted double JPEG compression with application to passive 
image authentication”, in IEEE International Conference on Acoustics, Speech and Signal Processing, page(s):1661 - 1664, 
2008. 
 1 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：101年 8月 20日 
                                 
一、參加會議經過 
 
計畫編號 NSC  100-2221-E-259-033 
計畫名稱 
以影像修補偽造圖片為目標之基於多區域關連技術的偽造偵測研究 
出國人員
姓名 
張意政 
服務機構
及職稱 
國立東華大學資工系副教授 
會議時間 
101年 7月 18日
至 
101年 7月 20日 
會議地點 Piraeus-Athens, Greece 
會議名稱 
The Eighth International Conference on 
Intelligent Information Hiding and Multimedia Signal Processing 
(IIH-MSP 2012) 
發表論文
題目 
 Multi-Camera Based Social Network Analysis 
 3 
 
圖 3 會議會場報到現況 
 
 
圖 4 會議會場一隅 
 
我所發表的論文抬頭為Multi-Camera Based Social Network and Personality Analysis，內容旨在將多攝影
機所拍攝的人員行為的影片，透過分析人們之間的互動行為來建立社交網路及人格分析。建立社交網
路的資訊包含互動的對象、所表達的肢體語言與情緒資訊，進而根據分析團體內所有成員之間的行為
及對彼此的態度，來建立這團體的社交網路。我們提出的分析方式，除了友好的互動關係之外，我們
還考量了厭惡的互動關係，並結合態度方向性來表達人員之間的互動，讓分析結果能更貼切現實的互
動情況。此外，透過分析一個人所有的社交互動行為，可以歸納其行為模式，而這行為模式即可轉換
成相關的人格特質，圖 5為系統的示意圖。 
本論文發表的英文摘要為： 
Social network and personality analysis are popular topics in social science. However, it needs a lot of human 
labor to get the information in psychological analysis. In this paper, we propose a multi-camera based 
evaluation system which can automatically track and recognize the human activities in an environment, and 
then build the corresponding social network and personality graph. The proposed system contains three major 
 5 
 
圖 6 論文發表會場 
 
 
圖 7 論文發表會場 
 
 7 
 
圖 9 Keynote Speaker 投影片之一。 
 
 
圖 10 Keynote Speaker 投影片之二。 
 
圖 11 Keynote Speaker 投影片之三。 
 9 
圖 14 Keynote Speaker 投影片之六。 
此次參與會議瞭解相關領域在這一年內技術的發展，也和相遇的學者互相討論，增進彼此的交流，
感覺收穫良多。 
三、攜回資料名稱及內容 
IIH-MSP 2012會議論文光碟片 
 
 
 
Multi-Camera Based Social Network Analysis 
I-Cheng Chang*, Jia-Hong Yang and Yi-Hsiang Liao 
Department of Computer Science and InformationʳEngineering 
National Dong Hwa University, Hualien, Taiwan, R.O.C. 
E-mail: icchang@mail.ndhu.edu.tw* 
 
 
Abstract—Social network analysis is a popular topic in social 
science. However, it needs a lot of human labor to get the 
information in psychological analysis. In this paper, we propose a 
multi-camera based evaluation system which can automatically 
track and recognize the human activities in an environment, and 
then build the corresponding social network and personality 
graphs. The proposed system contains three major parts: human 
detection, social behavior detection, and social interaction 
analysis. Experimental results show that the proposed system can 
discover the social network through analyzing people’s social 
interactions and provide a good result approximated to ground 
truth.  
Keywords- Social network analysis; Personality analysis; 
Posture recognition; Emotion recognition 
I. INTRODUCTION  
Social network analysis is a popular topic in social science. 
A social network can be regarded as a collection of social 
interactions constructed by relations between members of 
group. We can understand social interactions between members 
through the social network analysis, and it can be applied to all 
people related fields. For example, teachers can take care of the 
isolated students by understanding their social behaviors in 
sub-groups. Personality analysis is also an important issue in 
the related fields. However, traditional psychological social 
network analysis and personality analysis needs a lot of labor 
to get the information. 
Research about social network analysis can be found in 
different fields. Thomas [1] studied students’ social space in 
schooling by analyzing students’ social network. Using data 
from high school and beyond, Thomas derived eight curricular 
positions from an analysis of students’ profiles of course work 
in high school. Kumar et al. [2] studied structure and evolution 
of online social networks. They presented a series of 
measurements of two large real networks, Flickr-photo sharing 
and Yahoo! 360. Moncur [3] discovered recovery situations of 
psychotic patients by analyzing social networks of patients. Yu 
et al. [4] constructed the social network with technologies of 
computer vision. They used the appearing frequency of people 
as the features for their relationship and presented relations 
with non-directional connections.  
Most works about personality analysis are only found in 
psychological field. Murray [5] found the relationship between 
teacher’s personality and student’s instructional ratings. 
Caldwell and Burger [6] studied human personality 
characteristics of job applicants. Caspi [7] worked on 
discovering relations between personality and crime. The 
concept of Sociogram [8], which defines special nodes and 
relationship between nodes, is used in psychological social 
network analysis. Lai’s personality analysis [9] was a usual 
tool used in psychological personality analysis, and it classified 
people into five personality types. 
This work proposes a system which constructs a social 
network of a group of people by analyzing people’s behaviors 
from monitoring videos and generates each individual’s 
personality. Figure 1 shows the system flowchart. The 
proposed system consists of three parts: human detection, 
social behavior detection and social interactions analysis. The 
system obtains human posture images from static cameras and 
the face images from active cameras in human detection, and 
then identifies human social behaviors through recognizing 
their behaviors. Finally, we model the social network by 
analyzing the relationship among the people and generate the 
personality graphs from their social behaviors. 
 
 
Figure 1. The flow chart of system overview. 
The remainder of this paper is organized as follows. 
Sec.II describes scene selection with max separation. Sec.III 
introduces social behavior detection which includes target 
determination, posture recognition and emotion recognition. 
2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing
978-0-7695-4712-1/12 $26.00 © 2012 IEEE
DOI 10.1109/IIH-MSP.2012.48
174
with i neurons, the hidden layer with h neurons, and the output 
layer with j neurons. We use six neurons (i=6) in the input 
layer, which contains six angles. These six angles stand for the 
degree of opening the upper right eye, the lower right eye, the 
upper left eye, the lower left eye, the upper lip, and the lower 
lip, respectively. The angles of opening are calculated from the 
four horizontal and vertical corners of eyes and lips. The output 
layer has three neurons (j=3), such that all facial images are 
classified into three emotions, which are no emotion, happy, 
and sad. 
E. Facial Feature Extraction 
1) Eye detection 
We exploit Haar Cascade [10] eye classifier to detect eyes 
on face image. There are three kinds of Haar-like features, 
which are edge Haar-like feature, line Haar-like feature and 
Center-surround Haar-like feature. Haar-like feature is a mask, 
and the difference between pixels on its black and white areas 
is used as the features. Eye pictures and non-eye pictures are 
used to train an eye classifier. 
2) Lip detection 
Active shape model (ASM) [17] is used to track the lip 
contour and get the four end points of lip contour as the lip 
feature. To differentiate the lips and skin, we adopt the 
pseudo-hue model to describe the color distribution. Besides 
the pseudo-hue model, the luminance information is also used 
to enhance the edge detection, which is defined as 
( ) ( ) ( )
( ) ( ) ( )
upper y
lower y
Edge x H x L x
Edge x H x L x
	 = ∇ −
 

 

= ∇ +
 

 
                              
(5)
 
where Edgeupper(x) represents edge strength between upper lips 
and skin, Edgelower(x) represents edge strength between lower 
lips and skin and L(x) represents the luminance value of x. 
IV. SOCIAL NETWORK AND PERSONALITY ANALYSIS 
After collecting all social behaviors, we get the information 
about the social interactions happening in the group. The 
section describes how we model the social network and get the 
personality. 
A. Social Network Construction 
Three emotion types (no emotion, happy and sad) and 
seven posture types (hands hold the chest, hands on the hips, 
hands tied behind, hands hang down, hand points at people, 
shake hands with people and wave hand to people) are defined 
in this work. We assign a score to each interaction attitude. 
For example, the shaking hand with people is the friendly 
body sign and it gets score 3.0; however, pointing at people is 
the hostile posture, so this interaction gets score -3.0. The 
interaction attitude score (IA) is evaluated as follow:  
( )
1
M
i i
i
IA E Pα β
=
= +

                         (6) 
where  and £ are weights of emotion and posture, Ei denotes 
the emotion of the ith social behavior, Pi denotes the posture 
of the ith social behavior. We divide interaction attitude into 
five scales from hostile to friendly, and then the score is 
normalized from -2.0 to 2.0. Figure 3 shows the example of a 
social network which is represented as a sociogram. A node 
denotes a person and the edges between two nodes represent 
the interactions. The green number [2]1.1 in node A denotes 
that person A receives two friendly interactions and the score 
of friendly interactions is 1.1. The red number [1]2.7 denotes 
that node A receives one hostile interaction and the score of 
hostile interactions is 2.7. There are two types of social 
networks:  global social network and personal social network. 
A global social network includes all the social interactions, 
and a personal social network is a part of a global social 
network, which only related to one single person. 
 
 
Figure 3.  Example of  a social network. The green line depicts the friendly 
interaction and red line depicts the hostile interaction. The width of line 
denotes the strength of interaction. 
B. Personality Construction  
A person’s social behaviors are stored in his personal social 
network, and this network can further derive the 
corresponding personality. We weight all his behaviors on the 
filtered scales of Lai’s personality analysis, so that we could 
classify his personality type with Lai’s criterions. The 
personality score (PS) is described as follows:  
1
( )
N
i ij j
j
PS Scale W IA
=
=

                            (7) 
where PS(Scalei) denotes the score of the ith scale. Ten scales 
are uses here, i.e., ascendancy, social extraversion, thinking 
extraversion, rhathymia, cyclic tendency, inferiority feeling, 
anxiety, cooperativeness, aggressiveness and general activity. 
N denotes the amount of features of social behaviors, Wij 
denotes the weights of the ith scale and the jth feature of social 
behaviors, IAj denotes the unsigned interaction attitude value 
of the jth feature of social behaviors.  
V. EXPERIMENTAL RESULTS AND DISCUSSION 
In the experiments, we setup three static cameras and three 
active cameras in a classroom, and there are six persons 
appearing in the recorded videos. We prepare a story includes 
the common situations that might happen in a developing 
group. Tuckman [18] proposed five stages from the group 
development, which are forming stage, storming stage, 
norman stage, performing stage and adjourning stage. Since 
adjourning stage means that the group finishes its job and is 
going to disband and it doesn’t have obvious changes, so we 
perform the first four stages in our experiments. Ten persons 
are invited to watch the recorded videos and score each actor’s 
176
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/29
國科會補助計畫
計畫名稱: 以影像修補偽造圖片為目標之基於多區域關連技術的偽造偵測研究
計畫主持人: 張意政
計畫編號: 100-2221-E-259-033- 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
協助辦理 ICS2012 國際研討會 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
