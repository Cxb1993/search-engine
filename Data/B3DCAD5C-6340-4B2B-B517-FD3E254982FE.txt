摘 要 
動態系統所引發的特性一直困擾著工程設計人員，而只在靜態系統模式下，採用最佳
化設計方法所求得的設計，則往往在實際的應用上有所不足。本研究計畫主要依據最佳
設計與最佳控制理論基礎，結合動態分析與數值分析求解技巧，發展一套通用之動態系
統最佳設計方法與軟體。 
一般動態系統之最佳化問題可以轉換成標準的最佳控制問題，再透過離散技術轉換成
非線性規劃問題，如此便可利用現有之最佳化軟體進行求解。在本研究計畫中，首先將
動態系統的解題方法與流程發展為最佳控制分析模組，再將該模組與最佳化分析軟體 
(MOST) 整合得到整合最佳控制軟體，可以用來解決各種類型的最佳控制問題。為驗證
軟體的效能與準確性，利用本研究計畫所發展之整合最佳控制軟體求解文獻資料中所提
出之各類型最佳控制問題。藉由分析結果之數值與控制軌跡曲線的比對，整合最佳控制
軟體所求出之數值解，在效能與準確性上都能與文獻資料所獲得的最佳解吻合，確認該
整合最佳控制軟體的確可以用來解決我們工程應用上的最佳控制問題。 
另外，針對工程設計中存在的離散（整數）最佳控制問題，本研究計畫依據混合整數
非線性規劃法(mixed integer nonlinear programming) 做進一步的研究。猛撞型控制 
(bang-bang type control) 是常見的離散最佳控制問題，其複雜與難解的特性更是吸引諸
多文獻探討的主因。許多文獻針對此一問題所提出的方法多在控制函數的切換點數量為
已知的假設條件下所推導，但這並不符合實際工程上的應用需求，因為控制函數的切換
點數量大多在求解完成後才會得知。因此，本研究計畫針對此類型問題發展出兩階段求
解的方法，第一階段先粗略求解該問題在連續空間下的解，並藉此求得控制函數可能的
切換點資訊，第二階段再利用混合整數非線性規劃法求解該問題的真實解。發展過程
中，加強型的分支界定演算法 (enhanced branch-and-bound method)被實際應用並且納入
1 
ABSTRACT 
The nonlinear behaviors of dynamic system have been of continual concern to both 
engineers and system designers. In most applications, the designs – based on a static model 
and obtained by traditional optimization methods – can never work perfectly in dynamic cases. 
Therefore, researchers have devoted themselves to find an optimal design that is able to meet 
dynamic requirements. This project focuses on developing a general-purpose optimization 
method, based on optimization and optimal control theory, one that integrates dynamic system 
analysis with numerical technology to deal with dynamic system design problems. 
A dynamic system optimal design problem can be transformed into an optimal control 
problem (OCP). Many scholars have proposed methods to solve optimal control problems and 
have outlined discretization techniques to convert the optimal control problem into a 
nonlinear programming problem that can then be solved using extant optimization solvers. 
This project applies this method to develop a direct optimal control analysis module that is 
then integrated into the optimization solver, MOST. The numerical results of the study 
indicate that the solver produces quite accurate results and performs even better than those 
reported in the earlier literatures. Therefore, the capability and accuracy of the optimal control 
problem solver is indisputable, as is its suitability for engineering applications.  
A second theme of this project is the development of a novel method for solving 
discrete-valued optimal control problems arisen in many practical designs; for example, the 
bang-bang type control that is a common problem in time-optimal control problems. 
Mixed-integer nonlinear programming methods are applied to deal with those problems in this 
project. When the controls are assumed to be of the bang-bang type, the time-optimal control 
problem becomes one of determining the switching times. Whereas several methods for 
determining the time-optimal control problem (TOCP) switching times have been studied 
extensively in the literature, these methods require that the number of switching times be 
3 
目      錄 
摘要 ..............................................................................................................................1 
ABSTRACT .............................................................................................................................3 
目錄 ..............................................................................................................................5 
LIST OF TABLES ...................................................................................................................6 
LIST OF FIGURES.................................................................................................................7 
1. INTRODUCTION ...............................................................................................................8 
2. Literature Review and Objectives......................................................................................9 
Methods for Optimal Control Problems ............................................................................9 
Time-Optimal Control Problems ..................................................................................... 11 
Objectives ........................................................................................................................12 
3. METHODS.........................................................................................................................12 
3.1 Developing Process of an Multi-Function OCP Solver.............................................12 
3.1.1 Problem formulation.......................................................................................12 
3.1.2 NLP Methods for dynamical optimization .....................................................13 
3.1.3 Computational Algorithm...............................................................................14 
3.1.4 Systematic Procedure for Solving OCP .........................................................15 
3.2 Mixed-Integer NLP Algorithm for Solving Discrete-valued OCPs ..........................15 
3.3 Algorithm for Solving Discrete-valued OCPs...........................................................17 
3.4 Two-Phase Scheme for Solving TOCP......................................................................18 
4. Illustrative Examples.........................................................................................................20 
4.1 Third-Order System...........................................................................................20 
4.2 F-8 Fighter Aircraft............................................................................................21 
5. Conclusions ........................................................................................................................22 
REFERENCES ......................................................................................................................24 
計畫成果自評 .........................................................................................................................33 
附錄 ............................................................................................................................36 
5 
LIST OF FIGURES 
Figure 1 flow chart of the NLP method for solving OCP........................................................27 
Figure 2 Conceptual layout of the branching process. ............................................................28 
Figure 3 Flow chart of the algorithm for solving discrete-valued optimal control problems. 29 
Figure 4 Control trajectories for the third-order system..........................................................30 
Figure 5 Control trajectories for the F-8 fighter aircraft. ........................................................31 
Figure 6 Trajectories of the states and control input for the F-8 fighter aircraft. ....................32 
7 
as switched systems consisting of several subsystems and switching laws that orchestrate the 
active subsystem at each time instant. Optimal control problems (OCPs) for switched systems, 
which require solution of both the optimal switching sequences and the optimal continuous 
inputs, have recently drawn the attention of many researchers. The primary difficulty with 
these switched systems is that the range set of the control is discrete and hence not convex. 
Moreover, choosing the appropriate elements from the control set in an appropriate order is a 
nonlinear combinatorial optimization problem. In the context of time optimal control 
problems, as pointed out by Lee et al. (1997), serious numerical difficulties may arise in the 
process of identifying the exact switching points. Therefore, an efficient numerical method is 
still needed to determine the exact control switching times in many practical engineering 
problems. 
This study focuses on developing a numerical method to solve discrete-valued optimal 
control problems and the time-optimal control problem that is one of their special cases. The 
proposed algorithm, which integrates the admissible optimal control problem formulation 
(AOCP) with an enhanced branch-and-bound method (Tseng et al., 1995), is implemented and 
applied to some example systems. 
 
2. Literature Review and Objectives 
 Methods for Optimal Control Problems 
Optimal control problems can be solved by a variational method (Pontryagin et al., 1962) 
or by nonlinear programming approaches (Huang and Tseng, 2003, 2004; Hu et al., 2002; 
Jaddu and Shimemura, 1999). The variational or indirect method is based on the solution of 
first-order necessary conditions for optimality obtained from Pontryagin’s maximum principle 
(Pontryagin et al., 1962). For problems without inequality constraints, the optimality 
conditions can be formulated as a set of differential-algebraic equations, often in the form of a 
9 
serious numerical difficulties may arise in the process of identifying the exact switching 
points. Therefore, an efficient numerical method is still needed to determine the exact control 
switching times in many practical engineering problems. 
 Time-Optimal Control Problems 
The TOCP is one of most common types of OCP, one in which only time is minimized 
and the control is bounded. In a TOCP, a TPBVP is usually derived by applying Pontryagin’s 
maximum principle (PMP). In general, time-optimal control solutions are difficult to obtain 
(Pinch, 1993) because, unless the system is of low order and is time invariant and linear, there 
is little hope of solving the TPBVP analytically (Kirk, 1970). Therefore, in recent research, 
many numerical techniques have been developed and adopted to solve time-optimal control 
problems. 
One of the most common types of control function in time-optimal control problems is the 
piecewise-constant function by which a sequence of constant inputs is used to control a given 
system with suitable switching times. Additionally, when the control is bounded, a very 
commonly encountered type of piecewise-constant control is the bang-bang type, which 
switches between the upper and lower bounds of the control input. When the controls are 
assumed to be of the bang-bang type, the time-optimal control problem becomes one of 
determining the switching times, several methods for which have been studied extensively in 
the literature (see, e.g., Kaya and Noakes, 1996; Bertrand and Epenoy, 2002; Simakov et al., 
2002). However, as already mentioned, in contrast to practical reality, these methods require 
that the number of switching times be known before their algorithms can be applied. To 
overcome the numerical difficulties arising during the process of finding the exact switching 
points, Lee et al. (1997) proposed the control parameterization enhancing transform (CPET), 
which they also extended to handle the optimal discrete-valued control problems (Lee et al., 
1999) and applied to solve the sensor-scheduling problem (Lee et al., 2001). 
11 
 
subject to the system equations 
( , ( ), ( ), ),t t t=x f b u x&  fttt ≤≤0  (2)
with initial conditions 
0 0( ) ( )t =x x b , (3)
functional constraints 
0
( , ( ), )
0; 1,.........,
( , ( ), ( ), )
0; 1,....,
f
i i f f
t
it
J t t
i r
F t t t dt
i r r
ψ=
′= =⎧+ ⎨ ′≤ = +⎩∫
b x
b u x  
(4)
and dynamic point-wise constraints 
( , ( ), ( ), ) 0; 1,....,j t t t j qφ ≤ =b u x  (5)
where b ∈ Rk is a vector of the design variables, u(t) ∈ Rm is a vector of the control functions, 
and x(t) ∈ Rn is a vector of the state variables. The functions f, Ψ0, F0, Ψi, Fi and φj are 
assumed to be at least twice differentiable. 
3.1.2 NLP Methods for dynamical optimization 
By applying modeling and optimization technologies, a dynamic system optimization 
problem can be re-formulated as an optimal control problem (OCP). Hence, many approaches 
used to deal with the OCPs can be also applied to solve the dynamical optimization problems. 
Most popular approach in this field turned to be reduction of the original problem to a NLP. 
Sequential Quadratic Programming (SQP), one of the best NLP methods for solving 
large-scale nonlinear optimization, is applied to solve optimal control problems (see, e.g., Gill 
et al. 2002, Betts 2000). Before applying the SQP methods, optimal control problems in 
which the dynamics are determined by a system of ordinary differential equations (ODEs) are 
usually transcribed into nonlinear programming (NLP) problems by discretization strategies. 
Due to the consideration of efficiency, the sequential discretization strategy which only the 
control variables are discretized is applied. The resulting formulation is then called the 
13 
( 1) ( ) ( )k k α+ = + ⋅P P d k  (8)
11. Increase iteration counter, k ← k+1, go back to step 1. 
3.1.4 Systematic Procedure for Solving OCP 
The following steps describe a systematic procedure for solving the OCP with the proposed 
OCP solver: 
1. Program formulation: The original optimal control problem must be formulated according 
to the extended Bolza formulation. 
2. Preparing two parameter files: One of the parameter files describes the numerical schemes 
used to solve the OCP and also the relationships between performance index, constraint 
functions, dynamic functions, state variables and control variables. The other parameter 
file includes the information on SQP parameters, such as convergence parameter, 
upper/lower bound and initial guess of design variables, etc.  
3. Implementing user-defined subroutines. 
4. Execute the optimization: The user defined subroutines are compiled and then linked with 
the SQP solver, MOST (Tseng et al., 1996).  
5. Execute the optimization. 
With the proposed OCP solver, engineers can focus their efforts on formulating their problems 
and then follow an efficient and systematic procedure to solve their optimal control problems. 
3.2 Mixed-Integer NLP Algorithm for Solving Discrete-valued OCPs 
The algorithm developed in this study consists of three major processes: branching, the 
AOCP, and bounding. Initially, all discrete-valued restrictions are relaxed and the resulting 
continuous NLP problem is solved using the AOCP. If the solution of continuous optimum 
design problem occurs when all discrete-valued variable values are in the discrete set Ud, 
which is preset by the user to meet practical requirements, then an optimal solution is 
15 
3.3 Algorithm for Solving Discrete-valued OCPs 
In this study, the AOCP algorithm is used as the core iterative routine of the enhanced 
branch-and-bound method. All candidates will be evaluated and finally an optimal solution 
can be found. Here, symbol S is used to represent the discretized control variable set and the P 
is the design variable vector. Assuming that the problem at least has one feasible solution, it 
can then be proven that an optimal solution exists and can be found by the proposed method. 
The details of the proposed algorithm are as follows and Figure 3 presents a schematic flow 
chart of the algorithm for solving discrete-valued optimal control problems. 
 
Initialization: 
Relax all discrete-valued restrictions and then place the resulting continuous NLP problem on 
the branching tree. 
Set the cost bound Jmax = ∞. 
while (there are pending nodes in the branching tree) do 
1. Select an unexplored node from the branching tree. 
2. Control discretization. 
3. Repeat (for k-th AOCP iteration ) 
(1). Solve the initial value problem for state variable x(k) of AOCP. 
(2). Calculate the values of the cost function, J0, and the constraints. 
(3). Solve the QP(k) problem by applying the BFGS method to obtain the descent 
direction d(k). 
(4). if (QP(k) is feasible and convergent) then exit AOCP. 
(5). Find the step size α(k) of the SQP method by using the line search method. 
(6). Update the design variable vector: PP(k+1) = P(k)P + α(k) d(k). 
4. if (NLP is optimal) and (J0<Jmax) then 
17 
Phase I: Find the information about the switching times and terminal time. 
1. Solve the time-optimal control problem using continuous controls by following the 
steps of the AOCP method. 
2. Based on the numerical results, extract information about the switching times and 
terminal time, tf. 
Phase II: Calculate the exact solutions 
3. Based on the information about switching times obtained in Phase I, treat the 
switchings as design variables and add them into the time grid vector T. It should be 
noted that each interval between the upper and lower bounds on each of those design 
variables must include one switching. 
4. Insert the terminal time, tf, into the design variable vector P. 
5. Discretize each control variable into the number of switchings plus one. Then the 
discrete control vector, S, can be added to the design variable vector P and the 
corresponding upper and lower bounds be limited by the original bounds of the 
controls. 
6. Solve the problem by applying the mixed integer NLP method, and then find the 
optimal discrete-type control trajectories. 
A third-order system shown in following section is used to demonstrate the processes of this 
numerical scheme. 
 
 
19 
consistent with the results obtained by Wu (1999). 
As stated in previous section, several assumptions must be made when the mixed integer 
NLP method is applied to solving TOCP directly. Unfortunately, these assumptions cannot be 
guaranteed to hold in practical cases. Consequently, the two-phase scheme proposed in this 
project is needed. For illustration, the third-order system is again solved using this two-phase 
scheme. In Phase I, the two switching times are found to be [0.330, 0.725]T and the terminal 
time tf is 0.7864. In the first phase, these switching data need not be accurate because they are 
only used to help users decide on the number of switching times, the control arcs and their 
corresponding boundaries. Thus, in Phase II, the design variable vector P is re-formed as [T1, 
T2, tf, Ud1, Ud2, Ud3]T; the numerical result obtained by applying the mixed integer NLP 
method is as presented in Figure 4(b). In Phase II, the switching times of the discrete control 
input are [0.323, 0.713]T, and the terminal time tf is 0.7813 seconds. The control trajectory 
also agrees with that obtained by Wu (1999). 
4.2 F-8 Fighter Aircraft 
The F-8 fighter aircraft has been considered in several pioneering studies (e.g., Kaya and 
Noakes, 1996; Banks and Mhana, 1992; Simakov et al., 2002) and has become a standard for 
testing various optimal control strategies. A nonlinear dynamic model of the F-8 fighter 
aircraft is considered below. The model is represented in state space by the following 
differential equations: 
2 2 2
1 1 3 1 3 1 2 1 30.877 0.088 0.47 0.019 3.846
3
1x x x x x x x x x x= − + − + − − +&  
2 2
1 10.215 0.28 0.47 0.63u x u x u− + − + 3u , 
(15)
2 3x x=& , (16)
2 3
3 1 3 1 14.208 0.396 0.47 3.564 20.967x x x x x= − − − − −& u  (17)
21 
This project also presents a novel method for solving discrete-valued optimal control 
problems. Most traditional methods focus on the continuous optimal control problems and fail 
when applied to a discrete-valued optimal control problem. One common type of such 
problems is the bang-bang type control problem arising from time-optimal control problems. 
When the controls are assumed to be of the bang-bang type, the time-optimal control problem 
becomes one of determining the TOCP switching times. Several methods for such 
determination have been studied extensively in the literature; however, these methods require 
that the number of switching times be known before their algorithms can be applied. As a 
result, they cannot meet practical situations in which the number of switching times is usually 
unknown before the control problem is solved. Therefore, to solve discrete-valued optimal 
control problems, this dissertation has focused on developing a computational method 
consisting of two phases: (a) the calculation of switching times using existing optimal control 
methods and (b) the use of the information obtained in the first phase to compute the 
discrete-valued control strategy. 
The proposed algorithm combines the proposed OCP solver with an enhanced 
branch-and-bound method.  To demonstrate the proposed computational scheme, the study 
applied third-order systems and an F-8 fighter aircraft control problem considered in several 
pioneering studies. Comparing the results of this study with the results from the literature 
indicates that the proposed method provides a better solution and the accuracy of the terminal 
constraints is acceptable. 
 
 
23 
Kaya, C.Y., and Noakes, J.L., “Computations and Time-Optimal Controls,” Optimal Control 
Applications and Methods, Vol. 17, pp. 171-185, 1996. 
Lee, H.W., Jennings, L.S., Teo, K.L., and Rehbock, V., “Control Parameterization Enhancing 
Technique for Time Optimal Control Problems,” Dynamic Systems and Applications, Vol. 
6, pp. 243-262, 1997. 
Lucas, S.K., and Kaya, C.Y., “Switching-Time Computation for Bang-Bang Control Laws,” 
Proceedings of the 2001 American Control Conference, pp. 176-181, 2001. 
Simakov, S.T., Kaya, C.Y., and Lucas, S.K., “Computations for Time-Optimal Bang-Bang 
Control Using A Lagrangian Formulation,” 15th Triennial World Congress, Barcelona, 
Spain, 2002. 
Pontryagin, L. S., Boltyanskii, V. G., Gamkrelidze, R. V., and Mischenko, E. F., 1962, The 
Mathematical Theory of Optimal Processes, Wiley. 
Tseng, C.H., Wang, L.W., and Ling, S.F., “Enhancing Branch-And-Bound Method for 
Structural Optimization,” Journal of Structural Engineering, Vol. 121, No. 5, pp. 831-837, 
1995. 
Wu, S.T., “Time-Optimal Control and High-Gain Linear State Feedback,” International 
Journal of Control, Vol. 72, No.9, pp. 764-772, 1999. 
 
25 
  
Figure 1 flow chart of the NLP method for solving OCP 
27 
Initialization
1. Relax all discrete-valued restrictions
2. Place the resulting continuous NLP 
problem on the branching tree.
3. Set the cost bound Jmax = 
Is  the branching tree 
empty?
A
Select an unexplored node from 
branching tree
Solve subproblem by applying 
the OCP Solver (AOCP)
(NLP is optimal) && 
(J0<Jmax)
B
B
Yes
NO
NO
Is feasible ?
Drop this node
NO
Yes
Yes
Evaluate the values of criteria for selecting 
branch object
Decide the branch of design variable
Branching process
Two new nodes 
are added into 
branching tree
Subdomain that 
does not contain 
any allowable value
Add a new 
upper and 
lower bounds
                Bounding process
Add the new 
node to feasible 
node matrix
Set new cost bound 
Jmax= J0
Show results  
Figure 3 Flow chart of the algorithm for solving discrete-valued optimal control problems. 
29 
0.0 1.0 2.0 3.0 4.0 5.0 6.0
Time(sec.)
-0.06
-0.05
-0.04
-0.03
-0.02
-0.01
0.00
0.01
0.02
0.03
0.04
0.05
0.06
Ta
il 
de
fle
ct
io
n 
an
gl
e 
(r
ad
.)
Phase I (tf = 5.74173)
Phase II (tf = 5.74216)
 
Figure 5 Control trajectories for the F-8 fighter aircraft. 
31 
計畫成果自評 
傳統最佳化設計方法單靠靜態分析所得到產品在實際動態工作環境下往往表現不
佳，甚至有時會面臨無法正常動作的窘境。因此，本研究計畫主要發展目標是依據動態
系統分析與最佳化理論，整合數值分析技巧，發展一套有效率的方法與軟體來協助設計
者處理動態系統最佳設計問題，其中必須將非線性與離散參數設計問題皆需納入考量，
以因應實際工程需求。 
 
本研究計畫分兩年實施，第一年研究重點在於發展出一套整合動態分析與最佳化技
巧的方法，並將之實作成一套泛用型之動態最佳化軟體，此軟體的發展將有助於動態系
統設計者縮短分析及設計的時程，並對產品的更新與市場佔有率的提升提供顯著的幫
助。而要發展一套整合動態分析與最佳化技巧的方法，首先必須解決工程系統非線性的
問題，系統動態特性分析時所解得的系統方程式常常是高度非線性的微分方程組，此時
通常無法求得解析解，而藉助電腦數值分析技巧來求得收斂解是必要的。 第二個困難
點是在於許多動態分析必須藉助專業的分析軟體來進行，此時如何整合最佳化與分析軟
體便成為另一項挑戰。 
 
本計畫利用數值分析方法與程式設計技巧，順利完成預期目標中所要發展的泛用型
之動態最佳化軟體，並利用許多文獻上著名的動態設計與控制問題來進行驗證，從軟體
求得的數值解與文獻的結果作比對，發現本計畫所發展之軟體所得的結果與文獻的結果
是吻合的，甚至有些問題利用本計畫所發展出來的軟體求得的解優於文獻上的結果，由
這些結果我們得到的初步的驗證，也順利完成本計畫中第一年所預期想要達到的目標。 
 
本研究計畫第二年除了延續第一年的主題外，更將工程設計常會遭遇到某些設計尺
33 
本研究目前已發表兩篇國際期期刊及兩篇研討會論文 
 
期刊論文 
 1. C.H. Huang and C.H. Tseng, “An Integrated Two-Phase Scheme for Solving 
Bang-Bang Control Problems,” Accepted for publication in Optimization and 
Engineering (SCI Expended/ISI).  
 2. C.H. Huang and C.H. Tseng, “A Convenient Solver for Solving Optimal Control 
Problems,” Journal of the Chinese Institute of Engineers, Vol. 28, pp. 727-733, 2005 
(Ei/SCI).  
研討會論文 
 1. C.H. Huang, and Tseng, C.H., “Numerical Approaches for Solving Dynamic System 
Design Problems: An Application to Flight Level Control Problem,” Proceedings of 
the Fourth IASTED International Conference on Modelling, Simulation, and 
Optimization (MSO2004), Kauai, Hawaii, USA, 2004, pp. 49-54.  
 2. C.H. Huang, and Tseng, C.H., “Computational Algorithm for Solving A Class of 
Optimal Control Problems,” IASTED International Conference on Modelling, 
Identification, and Control (MIC2003), Innsbruck, Austria, 2003, pp. 118-123.  
  
35 




Numerical Approaches for Solving Dynamic System Design Problems:  
An Application to Flight Level Control Problem 
 
C.H. Huang* and C.H. Tseng**  
Department of Mechanical Engineering, National Chiao Tung University 
Hsinchu 30056, Taiwan, R. O. C.  E-mail: chtseng@mail.nctu.edu.tw 
TEL: 886-3-5726111 Ext. 55155  FAX: 886-3-5717243 
 
(*Research Assistant, **Professor) 
 
 
ABSTRACT 
The optimal control theory can be applied to solve 
the optimization problems of dynamic system. Two major 
approaches which are used commonly to solve optimal 
control problems (OCP) are discussed in this paper. A 
numerical method based on discretization and nonlinear 
programming techniques is proposed and implemented an 
OCP solver. In addition, a systematic procedure for 
solving optimal control problems by using the OCP solver 
is suggested. Two various types of OCP, A flight level 
tracking problem and minimum time problem, are 
modeled according the proposed NLP formulation and 
solved by applying the OCP solver. The results reveal that 
the proposed method constitutes a viable method for 
solving optimal control problems. 
  
KEY WORDS 
optimal control problem, nonlinear programming, flight 
level tracking problem, minimum time problem, SQP, 
AOCP. 
 
1. INTRODUCTION 
Over the past decade, applications in dynamic 
system have increased significantly in the engineering. 
Most of the engineering applications are modeled 
dynamically using differential-algebraic equations 
(DAEs). The DAE formulation consists of differential 
equations that describe the dynamic behavior of the 
system, such as mass and energy balances, and algebraic 
equations that ensure physical and dynamic relations. By 
applying modeling and optimization technologies, a 
dynamic system optimization problem can be re-
formulated as an optimal control problem (OCP). There 
are many approaches can be used to deal with these OCPs. 
In particular, OCPs can be solved by a variational method 
[1, 2] or by Nonlinear Programming (NLP) approaches 
[3-5].  
The indirect or variational method is based on the 
solution of the first order necessary conditions for 
optimality that are obtained from Pontryagin’s Maximum 
Principle (PMP) [1]. For problems without inequality 
constraints, the optimality conditions can be formulated as 
a set of differential-algebraic equations which is often in 
the form of two-point boundary value problem (TPBVP). 
The TPBVP can be addressed with many approaches, 
including single shooting, multiple shooting, invariant 
embedding, or some discretization method such as 
collocation on finite elements. On the other hand, if the 
problem requires the handling of active inequality 
constraints, finding the correct switching structure as well 
as suitable initial guesses for state and co-state variable is 
often very difficult. 
Much attention has been paid to the development of 
numerical methods for solving optimal control problems 
[6, 7]. Most popular approach in this field turned to be 
reduction of the original problem to a NLP. A NLP 
consists of a multivariable function subject to multiple 
inequality and equality constraints. The solution of the 
nonlinear programming problem is to find the Kuhn-
Tucker points of equalities by the first-order necessary 
conditions. This is the conceptual analogy in solving the 
optimal control problem by the PMP. NLP approaches for 
OCPs can be classified into two groups: the sequential 
and the simultaneous strategies. In simultaneous strategy 
the state and control variable are fully discretized, but in 
the sequential strategy only discretizes the control 
variables. The simultaneous strategy often leads the 
optimization problems to large-scale NLP problems 
which usually require special strategies to solve them 
efficiently. On the other hand, instability questions will 
arise if the discretizations of control and state profiles are 
applied inappropriately. Comparing to the simultaneous 
NLP, the sequential NLP is more efficient and robust 
when the system contains stable modes. Therefore, the 
admissible optimal control problems which bases on the 
sequential NLP strategy is propose to solve the dynamic 
optimization problems in this paper. To facilitate 
engineers to solve their optimal control problems, a 
general optimal control problem solver which integrates 
proposed method with SQP algorithm is developed. 
In spite of extensive use of nonlinear programming 
methods to solve optimal control problems, engineers still 
spend much effort reformulating nonlinear programming 
problems for different control problems. Moreover, 
implementing the corresponding programs of the 
429-062 49
 
SYSTEMATIC PROCEDURE FOR SOLVING OCP 
In this paper, the OCP is converted into NLP 
problem with admissible optimal control formulation and 
then the optimizer based on SQP method is used to solve 
the NLP problem numerically. Most of the numerical 
schemes are implemented in the OCP solver and the 
complicated details of the transformation and 
programming will be completed in the OCP solver 
automatically. The optimal control and state trajectories 
will be obtained and recorded in the output files. 
Therefore, engineers can follow an efficient and 
systematic procedure to solve various optimal control 
problems. The procedure for solving the OCP with the 
OCP solver is described as follows. 
1. Program formulation: The original optimal control 
problem must be formulated according to the 
extended Bolza formulation. 
2. Preparing two parameter files: One of the parameter 
files describes the numerical schemes used to solve 
the OCP and also the relationships between 
performance index, constraint functions, dynamic 
functions, state variables and control variables. The 
other parameter file includes the information on SQP 
parameters, such as convergence parameter, 
upper/lower bound and initial guess of design 
variables, etc.  
3. Implementing two user-defined subroutines. 
4. Execute the optimization: The user-defined 
subroutines are compiled and then linked with the 
SQP solver, MOST. Then, execute the optimization. 
Obviously, the proposed OCP solver simplifies the 
computational procedure for solving OCP and facilitates 
engineers and students in solving optimal control 
problems. 
,i jJ f 
 
Fig.1 Conceptual flow chart of the AOCP method 
3. AIRCRAFT MODEL 
Many ATC researches [11, 12] apply a point mass 
model to describe the aircraft motion and only the 
movement of the aircraft in the lateral-directional is 
considered. In Figure 2, three coordinate frames are used 
to describe the motion of the aircraft: Xg-Yg denotes the 
ground frame, the body frame denoted by Xb-Yb and the 
Xw-Yw denotes the wind frame. Besides, q, g, and  a 
denote the rotation angle between the frames. V Î  
represents the speed of the aircraft which is aligned with 
the positive Xw direction and h is the altitude of the 
aircraft.  
 
Fig. 2  The aircraft model (Lygeros 2003). 
 
The equations of the motion can be derived from force 
balance relationships: 
cos sin
sin cos
mV T D mg
mV L T mg
a g
g a g
= - -
= + -


 (16) 
Herein, T is the thrust exerted by the engine, D is the 
aerodynamic drag, and L is the aerodynamic lift. By 
applying basic aerodynamics, the lift (L) and drag (D) can 
be approximated by  
2
2
2
2
(1 ) (1 )
2
2
L
L
D
D
C S VL c a V c
C S VD a V
r
a a
r
= + = +
= =
 (17) 
where CL, CD, and c are dimension-less lift and drag 
coefficients, S is the wing surface area, r is the air density. 
According to the admissible optimal control formulation 
described in Section 3, the air model can be formulated by 
a three state model with state variable vector x(t) = [x1, x2, 
x3]T = [V, g, h]T and control input vector u(t) = [u1, u2]T = 
[T, q]T. By approximating a with a small angle, the 
equations of the motion (system equations) can be written 
as  
51
of optimal control problems for flight level control are 
presented and solved by proposed method successfully. 
Numerical results show the proposed method can 
facilitate engineers in solving optimal control problems 
with a systematic and efficient procedure. 
 
6. ACKNOWLEDGEMENTS 
The research reported in this paper was supported under a 
project sponsored by the National Science Council Grant, 
Taiwan, R.O.C., NSC90-2212-E009-039, is greatly 
appreciated.  
 
REFERENCES 
[1] L.S. Pontryagin, V.G. Boltyanskii, R.V Gamkrelidze, 
and E.F. Mischenko, The Mathematical Theory of 
Optimal Processes (Wiley, 1962). 
[2] D.E. Kirk, Optimal Control Theory: An Introduction 
(Prentice-Hall, 1970). 
[3] C.H. Huang, and C.H. Tseng, Computational 
Algorithm for Solving A Class of Optimal Control 
Problems, IASTED International Conference on 
Modelling, Identification, and Control (MIC2003), 
Innsbruck, Austria, 2003, pp. 118-123. 
[4] G.S. Hu, C.J. ONG, and C.L. Teo, An Enhanced 
Transcribing Scheme for The Numerical Solution of 
A Class of Optimal Control Problems, Engineering 
Optimization, 34(2), 2002, 155-173. 
[5] H. Jaddu, and E. Shimemura, Computational Method 
Based on State Parameterization for Solving 
Constrained Nonlinear Optimal Control Problems, 
International Journal of Systems Science, 30(3), 
1999, 275-282. 
[6] Polak E. Computation Method in Optimization (New 
York and London: Academic Press, 1971). 
[7] K.L. Teo, and Z.S. Wu, Computation Methods for 
Optimizing Distributed Systems (Academic Press, 
Orlando, 1984). 
[8] J. Lygeros, Minimum Cost Optimal Control: An 
Application to Flight Level Tracking, IEEE 11th 
Mediterranean Conference on Control and 
Automation (MED’03), Rhodes, Greece, June 18-20, 
2003. 
[9] C. Tomlin, J. Lygeros, and S. Sastry, Aerodynamic 
envelope protection using hybrid control, Computer 
Vision, and Materials Science (Cambridge University 
Press, New York, 1996). 
[10] J. Lygeros, C. Tomlin, and S. Sastry, Controllers for 
Reachability Specifications for Hybrid Systems, 
Automatica, 1999, 349-370. 
[11] B. Etkin, and L.D. Redi, Dynamics of Flight: 
Stability and Control, 3rd Ed. (New York: Wiley, 
1996). 
[12] M.V. Cook, Flight Dynamics Principles (New York: 
Wiley, 1997). 
[13] C.H. Tseng, W.C. Liao, and T.C. Yang, MOST 1.1 
User's Manual, Technical Report No. AODL-93-01, 
Department of Mechanical Engineering, National 
Chiao Tung Univ., Taiwan, R.O.C., 1996. 
[14] W. Press, S.A. Teukolsky, W.T. Vetterling, and B. 
Flannery, Numerical Recipes in C: The Art of 
Scientific Computing, 2nd Edition (New York: 
Cambridge, 1992). 
[15] P. T. Boggs and J. W. Tolle, Sequential Quadratic 
Programming, Acta Numerica, 1996, 1-52. 
[16] C. Büskens, H. Maurer, SQP-methods for solving 
optimal control problems with control and state 
constraints: adjoint variables, sensitivity analysis and 
real-time control, Journal of Computational and 
Applied Mathematics, 120, 2000, 85-108. 
 
Table 1. User subroutines for flight level tracking problem 
//-------Program parameters ---------------------------------------------- 
 //B: Discrete design parameters of design variable vector. (INPUT) 
// U: Admissible control function vector. (INPUT)  
// Z: State variable vector. (INPUT)  
// T: Given time grid point. (INPUT)   
// G: First term of performance index or functional constraint or   
//      dynamic constraint. (OUTPUT)  
// NV: Number of design variables for optimizer (INPUT)  
// NU: Number of control functions. (INPUT)     
// NEQ: Number of state equations (INPUT)  
// N: Index of current number of function evaluation. (INPUT)  
// 
// --------------------------------FFN()--------------------------------------- 
// Routine to calculate the integral term of the performance index 
// or functional constraint 
void ffn(double *B, double *U, double *Z, double *T, double *F,  
int NV, int NU, int NEQ, int N, int NBJ) 
{ 
   if (N==0)  
*F = 0.5*((Z[0]-150.0)*(Z[0]-150.0)) + (Z[1]*PI/180.0) * 
( Z[1] * PI/180.0 ) + (Z[2]*Z[2]); 
   else 
 *F = 0.0; 
} 
//----------------------- GFN() ------------------------------------------------- 
// Routine to calculate the first term of the performance index or  
// functional constraint or dynamic constraint 
void gfn(double *B, double *U, double *Z, double *T, double *G,  
int NV, int NU, int NEQ, int N, int NBJ) 
{ 
   switch (N) 
   { 
      case 0: 
*G = 0.0;   break; 
      case 1: 
               *G = -1 * Z[0] + 92.0; break; 
case 2: 
               *G = Z[0] – 170.0; break; 
  case 3: 
               *G = -1 * Z[1] -20.0; break; 
  case 4: 
        *G = Z[1] – 25.0; break; 
  case 5: 
        *G = -1 * Z[2] -150.0; break; 
  case 6: 
        *G = Z[2] – 150.0;  break; 
   };   
} 
//---------------------- HFN() -------------------------------------------------- 
//Routine to calculate the state trajectory. 
void hfn(double *B, double *U, double *Z, double *DZ, double *T,  
int NV, int NU, int NEQ )  
{      
DZ[0] = -1*((aD*Z[0]*Z[0]/m) + (g*sin(Z[1]*PI/180.0))) + U[0] *  
10000 / m; 
 DZ[1] = (aL*Z[0]*(1-c*Z[1])/m) - (g*cos(Z[1]*PI/180.0)/Z[0]) + 
aL*c*Z[0]*U[1]/m; 
   DZ[2] = Z[0]*sin(Z[1]*PI/180.0); 
53
COMPUTATIONAL ALGORITHM FOR SOLVING A CLASS OF OPTIMAL 
CONTROL PROBLEMS 
 
C.H. Huang* and C.H. Tseng**  
Department of Mechanical Engineering, National Chiao Tung University 
Hsinchu 30056, Taiwan, R. O. C.  E-mail: chtseng@mail.nctu.edu.tw 
TEL: 886-3-5726111 Ext. 55155  FAX: 886-3-5717243 
 
(*Graduate Student, **Professor) 
 
 
ABSTRACT 
This paper focuses on the numerical methods for solving 
the optimal control problems. An optimal control problem 
(OCP) solver is proposed to solve efficiently the optimal 
control problems in the engineering applications. In last 
two decades, discretization and parameterization 
techniques had been used to convert the optimal control 
problem into the nonlinear programming problem and 
then it can be solved it by using the standard optimization 
software. In this paper, a developed optimal control 
analytical module, an OCP solver, is integrated with the 
optimization software, MOST. A systematic procedure for 
solving optimal control problem by using the OCP solver 
is also proposed. Two various types of the optimal control 
problems presented in the literatures are chosen to verify 
the accuracy and efficiently for the OCP solver. From the 
numerical results in this paper, the trajectories for state 
and control variables agree with literatures’ results. 
Therefore, the capability and accuracy of the OCP solver 
is demonstrated and it can facilitate engineers to solve 
various optimal control problems with a systematic and 
efficient procedure. 
  
KEY WORDS 
optimal control problem, nonlinear programming, 
discretization and parameterization techniques, admissible 
optimal control formulation. 
 
1. INTRODUCTION 
 
Optimal control problems (OCP) have a large number of 
applications in many different fields, e.g. mechanical 
system [1], automotive vehicle design [2,3] and 
manufacturing process [4]. However, finding the solution 
is often a difficult and time-consuming task, particularly 
for nonlinear and state constrained problems. The optimal 
control problems can be solved by the classical calculus 
of variations approach or by the dynamic programming 
method. On the other hand, many practical problems are 
described by strongly nonlinear differential equations and 
cannot easily get the analytical solutions. Hence, many 
approximation methods [5-8] based on nonlinear 
programming method are used to solve the nonlinear 
optimal control problem. 
A nonlinear programming problem consists of a 
multivariable function subject to multiple inequality and 
equality constraints. The solution of the nonlinear 
programming problem is to find the Kuhn-Tucker points 
of equalities by the first-order necessary conditions. This 
is the conceptual analogy in solving the optimal control 
problem by the Pontryagin maximum principle [18]. 
Various discretization and parameterization techniques for 
state and control variables allow having an optimal 
solution for the OCP via the nonlinear programming. 
Jaddu and Shimemura [7] used the quasilinearization and 
state parameterization by using Chebyshev polynomials to 
solve constrained nonlinear optimal control problems. Hu 
et al. [8] applied an enhanced scheme based on the Direct 
Collocation and Nonlinear Programming Problem 
(DCNLP) to transform the system dynamics into 
constraints of the nonlinear programming. Many 
numerical examples are solved successfully by those 
methods.  
In this paper, a different approach for solving the OCP is 
proposed and integrated with various numerical schemes 
to implement a general optimal control problem solver 
that facilitate engineers to solve their optimal control 
problems with a systematic and efficient procedure. With 
the solver, the OCP can be converted into the nonlinear 
programming problem automatically and then be solved 
by a general constrained optimization solver-MOST. The 
OCP solver allows the designer to control both of the 
optimization process and the analysis as well as design 
sensitivity analysis using his owning experience and 
intuition. Two numerical examples in the recent 
literatures will be used to demonstrate and verify the OCP 
solver in this paper. The numerical results show the OCP 
solver is effective and accurate for solving the optimal 
control problem. 
 
2. PROBLEM FORMULATION 
 
A general problem of continuous time optimal control 
system can be defined as follows:  
377-062 118
variables on the performance of the NLP problem is self-
evident. Furthermore, many well-developed subroutines 
exist for numerical integration that is needed in the 
admissible optimal control problems. Therefore, the 
admissible optimal control problem is more efficient and 
easy implementation than DCNLP and it has been 
adopted in this paper. 
 
4. ADMISSIBLE OPTIMAL CONTROL 
FORMULATION 
 
Consider now a typical functional that may be the 
performance index or a functional constraint: 
0
[ , ( ), ] [ , ( ), ( ), ]f
t
f f t
J t t F t t t dtψ= + ∫b x b u x  (11)
 
where the first term involves only design variables and the 
state of the system at terminal time and the second term 
contains mean behavior over entire interval of motion. As 
noted earlier, the control functions u are treated as a 
subset of the vector P. The terminal time tf can be treated 
as one of the design variables in T, for example, 
0
1
N
f i
i
t T t
=
= +∑ . The dependence on design variable in Eq. 
(11) arises both explicitly and implicitly through the 
control and state variables. The admissible control 
function is represented in the form u(t) = I(U, T, t) and 
the state variable is written the form x(b, U, T, t) to 
emphasize that it is a function of design variables P. 
Therefore, equation (11) can be rewritten as follows: 
[ , ( , , , ), ]f fJ x t tψ= b b U T  
0
[ , ( , , ), ( , , , ), ]f
t
t
F I t t t dt+∫ b U T x b U T  (12)
 
The state equation in Eq. (2) is transformed as  
[ , ( , , ), ( , , , ), ] ,t x t t dt=x f b I U T b U T&  fttt ≤≤0  (13)
 
and a typical dynamic constraint function in Eq. (5) as 
[ , ( , , ), ( , , , ), ]t t tφ b I U T x b U T  (14)
 
Now, it can express the admissible optimal control 
problem in an NLP formulation as follows: 
Find the design variables P = [ bT, TT, UT]T to minimize a 
performance index 
 
0 0[ , ( , , , ), ]f fJ t tψ= b x b U T  
0
0[ , ( , , ), ( , , , ), ]
ft
t
F t t t dt+∫ b I U T x b U T  (15)
    
subject to state equations 
[ , ( , , ), ( , , , ), ] ,t x t t dt=x f b I U T b U T&  fttt ≤≤0  (16)
 
with initial conditions 
0( ) ( )t =x h b  (17)
 
functional constraints as  
[ , ( , , , ), ]i i f fJ t tψ= b x b U T  
0
0; 1,.........,
[ , ( , , ), ( , , , ), ]
0; 1,....,
ft
it
i r
F t t t dt
i r r
′= = +  ′≤ = + ∫ b I U T x b U T
(18)
 
and dynamic constraints as  
0; 1,.........,
[ , ( , , ), ( , , , ), ]
0; 1,....,j
j q
t t t
j q q
φ ′= =  ′≤ = + b I U T x b U T
 (19)
 
With admissible optimal control, some good first order 
differential equation methods having variable step size 
and error control are available to integrate the state 
equations in Eqs. (16) and (17), e.g. Adams method and 
Runge-Kutta-Fehlberg method [11]. These solvers can 
give accurate results with user desired error control. The 
state trajectories are internally approximated using 
interpolation functions in the differential equation solvers. 
Values of the state and control variables between the grid 
points can be also obtained with different kinds of 
interpolation schemes.  
 
5. NUMERICAL SCHEMES 
 
Ordinary Differential equation (ODE) solver: With the 
admissible optimal control formulation, the state 
equations (13) and design sensitivity equations need to be 
integrated by the ODE solver. In this paper, DDERKF, 
DDEABM and DDEBDF that developed by Sandia 
Laboratory are selected to integrate state or design 
sensitivity equations [12]. DDEBDF is based on the 
variable-order (1-5) backward-differention formula. 
DDERKF is a fifth-order Runge-Kutta code and 
DDEABM is a variable-order (1-12) Adams-Bashforth 
code. Those equation solvers use variable-step-size 
algorithms and have good error control.  
 
Numerical Integration Scheme: Two integration schemes, 
Simpson’s rule and Gaussian quadrature formula, are 
adopted in this paper. Those schemes are used to integrate 
the integral part of the functional constraints. 
 
Interpolation Schemes: For the admissible optimal control 
formulation, interpolation schemes are needed at several 
places. The zero-order, first-order and piecewise cubic-
spline interpolation functions can be used in this paper. 
 
Optimization Solver: In the admissible optimal control 
formulation, the optimal control problem is converted into 
a NLP program and then a standard optimization solver 
can solve the NLP problem numerically. A great deal of 
attention has been paid to the NLP problems by using the 
Sequential Quadratic Programming (SQP) method [7, 13]. 
In this paper, an optimization solver-MOST [14] based on 
the SQP method is chosen to solve the NLP problem. 
 
120
with boundary conditions xT(0) = [0,  0,  0,  0]T and xT(tf) 
= [1,  0,  1,  0]T.  
With admissible control formulation, the control variables 
are converted into the design variables and the control 
constraints are treated as the dynamic constraint. In this 
work, the system is solved by the OCP solver with 
following parameters: k = 1N-m-rad-1, m1 = m2 = 1kg-m2, 
and M = 1N-m. The numbers of time grid points for the 
control function (NGP) are selected as 5, 11 and 51 to 
study the effect of coarser or finer mesh. Two initial 
guesses, u (t) = 0.0 and u (t) = 1.0, for the control function 
with three piecewise interpolation schemes – zero order, 
first order, and cubic spline are used in this problem. The 
hybrid method that combines the DDM and AVM for 
design sensitivity analysis is used to calculate the design 
sensitivity coefficients.  
The optimal solution for this problem is given in Table 2 
and the trajectories of state variables are shown in Fig.2. 
All the 18 test runs are successfully solved with the 
proposed method, but the runs with small number of 
control grid points (NGP) give higher optimum values 
and less CPU time. The terminal time, tf, and the 
trajectories obtained in this work are agreed with the 
results, tf ≅ 4.3, obtained by Wu [17]. The numerical 
results also show that the proposed method has the 
capability to deal with the high order time-optimal control 
problem.  
 
8. CONCLUSIONS 
The admissible control formulation combines with SQP 
method used to solve the optimal control problem is 
presented. The theoretical basis of nonlinear programming 
approach for the optimal control problem is also described. 
An optimal control problem solver, the OCP solver, based 
on the nonlinear mathematical programming techniques 
and integrated with many well-developed numerical 
routines is implemented. A systematic procedure for 
solving optimal control problem is also proposed. Two 
various types of optimal control problems are used to 
evaluate the capability and accuracy of the OCP solver. 
The results show that the OCP solver can facilitate 
engineers to solve the optimal control problems with a 
systematic and efficient procedure. 
 
9. ACKNOWLEDGEMENTS 
 
The research reported in this paper was supported under a 
project sponsored by the National Science Council Grant, 
Taiwan, R.O.C., NSC90-2212-E009-039, is greatly 
appreciated. 
 
REFERENCES 
[1] Kim, T.H. and Ha, I.J., Time-Optimal Control of a 
Single-DOF Mechanical System with Friction, IEEE 
Trans. Automat. Contr., 46(5), 2001, 751-755. 
[2] Tsiotras, P., On the Optimal Braking of Wheeled 
Vehicles, Proc. of the American Control Conference, 
Chicago, 2000, 569-573. 
[3] Jalili, N. and Esmailzadeh, E., Optimum Active 
Vehicle Suspensions with Actuator Time Delay, 
Transcations of the ASME. Journal of Dynamic Systems, 
Measurement and Control, 123, 2001, 54-61. 
[4] Samaras, N.S. and Simaan, M.A., Optimized 
Trajectory Tracking Control of Multistage Dynamic 
Metal-Cooling Processes, IEEE Tran. Ind. Applicat., 
27(3), 2001, 920-927. 
[5] Lin, S.Y., Complete Decomposition Algorithm for 
Nonconvex Separable Optimization Problems and 
Applications, Automatica, 28, 1992, 249-254. 
[6] Pytlak, R., Numerical Methods for Optimal Control 
Problems with State Constraints (Lecture Notes in 
Mathematics 1707, Springer-Verlag, 1999). 
[7] Jaddu, H. and Shimemura, E., Computational Method 
Based on State Parameterization for Solving Constrained 
Nonlinear Optimal Control Problems, International 
Journal of Systems Science, 30(3), 1999, 275-282. 
[8] Hu, G.S., ONG, C.J. and Teo, C.L., An Enhanced 
Transcribing Scheme for The Numerical Solution of A 
Class of Optimal Control Problems, Engineering 
Optimization, 34(2), 2002, 155-173. 
[9] Bock, H.G. and Plitt, K.J., A Multiple Shooting 
Algorithm for Direct Solution of Optimal Control 
Problems, Proceedings of the 9th IFAC World Congress, 
Budapest, 1984. 
[10] Sage, A.P. and White, C.C. III, Optimum systems 
Control, 2nd Edition (Prentic Hall, 1977). 
[11] Press, W., Teukolsky, S.A., Vetterling, W.T., and 
Flannery, B., Numerical Recipes in C: The Art of 
Scientific Computing, 2nd Edition (Cambridge, New 
York, 1992). 
[12] Shampine, L.F. and Watts, H.A., DEPAC-Design of 
User Oriented Package of ODE Solvers, SAND 79-2347, 
Sandia Laboratory, 1979. 
[13] Tseng, C.H., Optimal Design for Dynamics and 
Control Using a Sequential Quadratic Programming 
Algorithm (PhD dissertation, Department of Mechanical 
Engineering, Iowa University, 1987). 
[14] Tseng, C. H., Liao, W. C. and Yang, T. C., MOST 
1.1 User's Manual. Technical Report No. AODL-93-01, 
Department of Mechanical Engineering, National Chiao-
Tung Univ., Taiwan, R.O.C., 1993. 
[15] Hsieh, C.C. and Arora, J.S., Design Sensitivity 
Analysis and Optimization of Dynamic Response, 
Computer Methods in Applied Mechanics and 
Engineering, 43, 1984, 195-219. 
[16] Bullock, T.E. and Franklin, G.F., A Second-order 
Feedback Method for Optimal Control computations, 
IEEE Transactions on Automatic Control, 12, 1967,666-
673. 
[17] Wu, S.T., Time-Optimal Control and High-Gain 
Linear State Feedback, International Journal of Control, 
72(9), 1999, 764-772. 
[18] Pontryagin, L.S., Boltyanskii, V.G., Gamkrelidze, 
R.V. and Mischenko, E.F., The Mathematical Theory of 
Optimal Processes (Wiley, 1962). 
122
