I 
 
摘要 
隨著監視系統普及、設置數量及密度不斷上升，考量空間與顯示器之數量及成本，傳統
監視系統多以分割畫面方式，將數個縮小之監視影像於同一螢幕顯示，惟於大範圍監控區域
配置數以百計監控攝影機，如校園、城市路口等場合，若沿用傳統之分割畫面，必須同時監
控上百個即時影像，並不合理，監視人員難以自如此大數量之監控影像推知其對應之實際場
景位置，不能對突發事件快速進行處理，監控效能不佳。 
為改善上述傳統監視系統之缺失，本計畫提出事件觸發之虛擬實境監控系統
（Event-Trigged Virtual Surveillance Environment）將多個監控視訊加以融合、進行事件分析，並
於三維場景內呈現之立體場景監控技術，另搭配多攝影機協同偵測技術，進行入侵者移動路
徑偵察、預測，虛擬巡邏路徑之規劃；各階段研究內容概述如下： 
第一階段：建構三維靜態場景及物件模型。將各攝影機擷取之即時視訊融合至場景模
型，成為一三維動態場景模型，包括三個重點：1.建構三維監控場景：以監視區域之衛星影
像為基礎，結合建物高度、樓層數、各樓面、房間配置等資訊，視監控需求，建立詳細程度
不等之監視區域三維靜態場景及具監控意義之物件模型；2.三維物件模型建構：建立監控場
景中具監控重要性之三維物件模型，俾利進行沿續二維視訊與三維場景及物件模型之對應；
3.動態視訊融合：將監視區域中各攝影機擷取之即時二維影像映對至所建構之三維場景及物
件模型，以單一監控環境呈現所有攝影機畫面，建構立體動態監控場景，使監控者彷彿置身
於監控區域內，進行具臨場感之三維監控場景之觀視。 
第二階段：多攝影機間之協同偵測。將攝影機各自所提供之區域資訊整合為全域資訊，
利用圖形空間觀念，於共同時間點對不同空間狀態加以識別，建立橫跨時間之移動分析，提
升物件偵測與追蹤效能、單一中控主機統籌管理多支攝影機、由使用者自行定義監控場景範
圍、進行即時且有效之異常事件通報等功能。藉以進行大範圍之事件分析，如：入侵者移動
路徑偵察與預測等。 
第三階段：加值應用。於所建置之虛擬實境中進行動態警戒配置、攝影機全景瀏覽、虛
擬巡邏路徑之規劃與巡邏、影像除霧、可疑物智慧偵測、遺失物智慧偵測、夜間影像增強…
等加值應用。 
關鍵字：事件觸發之虛擬實境監控系統、視訊融合、三維監控場景、多攝影機協同偵測。
1 
 
第一章、前言與研究目的 
傳統監視系統多以分割畫面方式，將數個縮小之監視影像顯示於同一螢幕，標示場景名
稱於各分割畫面，供事件發生時辨識場景之用，並允許使用者觀察不同部分或相同部分不同
視角之場景，隨著監視系統逐漸普及，監視器設置數量及密度不斷上升，考量空間與顯示器
之數量、成本，欲配置數以百計監控攝影機於校園、城市路口、建築物各樓層走道等大範圍
監控區域，傳統分割畫面之監控系統已不敷使用，並存有以下缺失：1.分割畫面相關性低：
監視人員必須同時監控上百個即時影像，當事件發生於某一場景，難以不相鄰之分割畫面推
導其空間及場景關係，以有兩突發事件發生於「電梯 1 左側」與「樓層 5 中廊」為例，若使
用者對場景空間及相關地理概念不熟悉，單就兩監視螢幕所截取之影像，無法斷定兩突發事
件之距離遠近及是否存有密切關係；2.突發事件追蹤困難：若監視物體以特定方向移出分割
畫面，則使用者僅能以物體移動方向及監視器顯示之相關地標推得其可能出現之場景位置，
若非預知場景空間關係，難以自大數量之監控影像中準確預測新位置，隨著監視器數量增加，
不同場景間亦存在相似地標，增加辨識困難度，無法有效對突發事件快速進行處理；3.監視
影像解析度低：即使廣角監視器提供廣域影像，日後若欲增加監視器數量與設置密度，將新
影像容納至監控螢幕中，勢必降低分割畫面解析度，若將某一分割畫面放大進行高解析度細
部觀測，將導致同時忽略其他分割畫面，無法即時監控全域場景，降低整體監控效能。4.全
域監控困難：在數量如此龐大之分割監視影像中，使用者無法同時全神貫注於全部畫面，易
因專注於某特定分割畫面而忽略其他影像，無法即時偵測所有突發事件。 
為改善前述傳統監視系統之缺失，本計畫提出事件觸發之虛擬實境監控系統
（Event-Trigged Virtual Surveillance Environment），計畫區分為三階段：1.結合三維場景暨物件模
型建構及視訊融合，2.多攝影機間之協同偵測，3.加值應用。首先以監視區域之衛星影像為基
礎，結合建築物高度、樓層數、各樓面、房間配置等資訊，視監控需求，建立詳細程度不等
之監視區域三維靜態場景模型，再將監視區域中各攝影機擷取之即時二維影像映對至所建構
之三維場景及物件模型，以單一監控環境呈現所有攝影機畫面，建構立體動態監控場景，此
系統為結合三維空間模型、二維視訊與事件處理之統一而直觀之監視系統。結合以上技術，
配合多攝影機協同偵測與事件偵測，可協助監控人員處理事件，將每個攝影機各自所提供的
之區域資訊，加以識別及分析，整合成為具有涵蓋完整空間之全域監控資訊，除能將全域視
訊同步顯示之外，亦能快速進行大範圍之事件檢索、事件分析與預警，如：入侵者移動路徑
偵察、異常狀況預測等等，提供整合資訊給監控人員，並可於虛擬實境中以第一人稱之觀點
進行沉浸式（Teleimmersive）虛擬之巡邏，以利規劃巡邏路徑、協助保安人員搜索之行動，系
統亦可依照統合資訊進行協同偵測，如：廣角攝影機與望遠鏡頭之協同偵測，以靜止之廣角
鏡頭對大範圍場景進行動態偵測，並轉動變焦長鏡頭持續追蹤並鎖定入侵者，或控制多個轉
動變焦長鏡頭鎖定同一目標以進行無死角之追蹤，統合上述之功能將開發出更有效益應用影
像資訊之監視系統，在此階段之研究將開發系統之高協同性、整合性，以改善舊有系統資訊
應用效率不佳之缺失。最後於所建置之虛擬實境系統中進行動態警戒配置、攝影機全景瀏覽、
虛擬巡邏、影像除霧、可疑物智慧偵測、遺失物智慧偵測、視覺化控制、夜間影像增強等加
值應用。 
3 
 
與 二 維 視 訊 之 結 合 ： ， 其 中 ，
，關鍵在於二維之材質和視訊投影於三維模型必須完整
融合。 
透過增強虛擬實境，雖可獲得二維視訊與三維場景模型整合之動態立體環境，惟大多缺
乏於三維模型中以三維物件方式融合及呈現動態移動物件之能力。結合影像處理暨電腦圖
學，事件觸發之虛擬實境監控系統將可於三維場景中重建二維視訊物件之立體模型並予以動
態顯示。本計劃在此階段之研究將開發完備而直觀之三維監視場景，以利後續之研究階段進
行協同偵測、事件處理等加值應用。 
2.2 多攝影機間之協同偵測 
 2.2.1 前景偵測 (Salient Object Detection) 
Ying-Li Tian等人[6]利用 Temporal Difference 與過濾 Lucas-Kanade 演算法所計算出之光
流做交集得到 salient map，Lucas-Kanade 演算法假設物件之 intensity 資訊不隨時間變動而
有所改變，故在下一張 frame 針對每一個 pixel以 intensity 資訊不變得前提下尋求最短移動
距離 d 作為該 pixel之光流資訊（圖 2-2-b），針對 d 之預測函式如下： 
 
 
1
1 1| ( ) ( ) |n n
T T
n n x d t t x d
x x
I I I
d d I x I x
x x x

   
 
         
         
          
  ， (2.1) 
Temporal Filter 假設物件皆以固定方向移動，過濾 x與 y 方向不規則移動之光流以消除不
必要之光流（圖 2-2-c）；此方式前提假設限制過大，若有物體以不規則方向行走（例如，
zigzag），則正負方向抵銷無法偵知移動物件，若移動物體突然停止亦無法偵知， 
 
 
圖 2-2. (a)隨風搖曳之樹葉與行人，(b) Lucas-Kanade 光流，(c) Temporal-filtered 
Lucas-Kanade 光流，(d) Temporal Difference 交集 Temporal-filtered Lucas-Kanade 光流。 
 2.2.2 多攝影機人物追蹤 (Multi-camera Human Tracking) 
Jiman Kim等人[17] 利用前景區塊數與物件與各監視器之角度資訊來判斷何時應該進
行遞交以及應該遞交至哪隻監視器，首先使用 SKDA(Sequential Kernel Density Approximation)
背景相減法估測背景，接下來依據 brightness-distortion 與 chromaticity-distortion 過濾相減後
之前景以移除陰影：計算前景向量 F(Rf,Gf,Bf)與背景向量 B(Rb,Gb,Bb)之夾角 與 F 投影至 B
之向量長度，任何介於|F-B|與 所圍成之圓錐區域之(R,G,B)區塊皆可視為陰影，再針對這
些前景以首腳位置及 RGB 顏色資訊與其跟上一張 frame 之相對關係做分類，隨著物件在
場景中移動，勢必跨越許多監視器，然而監視器有各自 Field Of View（FOV），各 FOV
彼此亦有重疊與不重疊之分，當人由監視器 1 之 FOV 移至監視器 2 之 FOV 時，系統勢
必要跟著轉換才能繼續監控，所以如何讓系統知道人由監視器 1 移動至監視器 2 之 FOV
成為一個重大關鍵，因此 Jiman Kim等人提出以前景區塊數與物件與各監視器之角度資訊
來判斷遞交發生情況，系統逐一計算第 i 個人與第 j 個監視器之前景區塊數與角度，如圖
2-3-a 所示，若人逐漸往某一監視器靠近，則此時前景區塊數將越來越多，相對與該監視
a b c d 
5 
 
第三章、研究方法 
3.1 三維場景暨物件模型建構及視訊融合 
 立體模型建構之方式主要分為電腦圖學和電腦視覺，兩者皆需花費大量時間及人力取得
場景中各物件之精確參數，方能建構場景，且於場景完成後，其彈性較低，無法依使用者需
求快速更動設計，一旦架構翻修便須再度花費許多成本及人力；本計畫為改善前述缺失，以
OpenGL為基礎，提出一快速而具彈性之場景建構方式： 
3.1.1 立體建築物模型建構 
先藉衛星影像空照圖取得欲監控區域之二維影像，由使用者操作建築建立工具，選取
欲監測地區，輸入建築物名稱、形式與樓層數（圖3-1）即可以電腦圖學技術快速產生三
維立體建築模型（圖3-2），再利用樓層建構工具，輸入各個欲建置之樓層之牆壁結構完
成室內場景之牆壁（圖3-3）， 
  
 
 
3.1.2 內外牆材質貼圖 
利用材質對應工具（圖3-4），將二維靜態建築物材質經修正透視變形後，於立體場
景之對應地點貼上對應之二維靜態材質，依上述步驟逐一建立場景中之建築並貼上相對
應之材質，即可得三維靜態室內外場景（圖3-5，3-6）， 
  
 
 
 
 
 
 
 3.1.3 動態立體場景 
將三維靜態場景（圖3-7-a）與其監視之區域中各攝影機擷取之即時二維動態影像（圖
3-7-b）對應，使動態二維影像透過變形修正後，與所建構之三維場景融合（圖3-7-c），
建構立體動態監控場景，監控人員便可依單一監控環境，以符合人類視覺習慣同時觀看
圖 3-1. 輸入建築物資訊， 圖 3-2. 立體建築模型， 圖 3-3. 樓層建構。 
圖 3-4. 材質貼圖，左上：三
維場景模型、右上：欲貼上
之建築材質、左下：材質與
建築模型對應、右下：對應
結果， 
圖 3-5. 建築物模型材質貼圖， 圖 3-6. 室內樓層材質貼圖。 
7 
 
 
 3.2.2 多攝影機人物追蹤 (Multi-camera Human Tracking) 
3.2.2.1 特徵擷取 
以 Connected Component Labeling 影像處理方式將小區域濾除（圖 3-9），保留完
整大區塊，同時記錄各區塊之編號、面積（所佔像素多寡）、腳座標（區塊底部座
標）、長寬大小、RGB 各 256 色於此區塊之對應位置等資訊，以便每張 2D Frame
做辨識之用，假設人物於場景內移動並不會瞬間改變身上顏色資訊，擷取處理後之
Salient Map 各區塊對應之 R:[0,255] G:[0,255] B:[0,255]，分別累加區塊內相對位置之
顏色資訊，再除以各區塊大小做正規化獲得相對位置 R、G、B 顏色比例資訊，伴隨
物件 ID 與位置一同儲存於資料庫內，未來所有 Input Frame 可依此資訊做辨識。 
3.2.2.2 狀態定義與處理方式 
人物於各場景內走動之狀態可分成四種 State：Enter、Leaving、Match、Disappear，
其中 Disappear 又可細分成 Occlusion 與 Fraction 兩種狀態，圖 3-9 為各人物 state 轉換
圖，各 State 詳細定義與說明如下： 
 
 
 
 
 
 
 
 
State Enter Leave Match Occlusion Fraction 
定義 
1.面積不斷增
加 2.RGB 顏色
百分比持穩定
狀態 
3.資料庫中無
資料與此區塊
符合 
1.腳座標點已
觸及 FOV 邊界  
2. RGB 顏色百
分比呈現明顯
遞減狀態 
於資料庫中找
到近似於目前
RGB 顏色百分
比分量之物件 
1.不可能只有
一人發生 
2.畫面中同位
置必定會出現
一個新物件 
1. 同位置區塊
驟增 
2.前景被切割 
處理
方式 
1.儲存相關資
訊於資料庫 
2. 開始追蹤 
結束追蹤 
1.計算新腳座
標點並與前一
座標點相連 
2.更新資料庫
中對應區塊相
關資訊 
1.依各人物先
前行走之平均
座標決定路徑  
2.新物件不存
入資料庫 
略過不處理 
  3.2.2.3 Association  
當人物於場景中行走時勢必跨越多監視器視野，此時可藉由各 Camera 之間來推
得物件彼此關係，因同一時間同一空間位置不可能出現兩個不同人，此時物件若處
於兩監視器之重疊視野範圍內且屬 Enter、Match、Leave 此三種狀態，則系統可得知
物件於 3D 即時沉浸式監視系統場景中之 3 維座標，即可藉此推得此物件於另一監
○5  ○4  
○4  
○4  ○
1  
○1  
○3  
○3  
○2  
○1  
Enter 
Leav
Match Fraction 
Occlusion 
圖 3-9. State 轉換圖， 
○1 ：符合資料庫資訊。 
○2 ：無符合資料庫資訊且同位置區塊數
驟增。 
○3 ：消失且同位置出現新物件。 
○4 ：RGB 顏色百分比明顯遞減或腳座標
觸及邊界。 
○5 ：再次進入畫面(re-match)。 
 
表 3-2. State 定義與處理方式。 
9 
 
取出夜間移動物體將有利提昇整體監控安全性， 
 
 
 
 
 
 
  
圖 3-13-a. 夜間
影像， 
圖 3-13-b. Fuzzy 
Image 
Enhancement， 
圖 3-13-c. 圖
3-13-b 前景擷取結
果， 
圖 3-13-d. 以夜間
強化過之前景貼
上白天背景完成
Fusion 動作， 
圖 3-13-e. Fusion 前以原始夜間影像
當成材質貼上對應 3D 場景， 
圖 3-13-f. Fusion完成以結果當成材質
貼上對應 3D 場景。 
11 
 
參考文獻 
[1]  Juan Zhu, Yong-ping Kong, “A Fast Method for Building and Updating Background Model,” IEEE 
Conf. on ISA’09, Pages 1-4, May 23-24, 2009. 
[2]  T.K. Kim, J.H. Im, and J.K. Paik, “Video Object Segmentation and Its Salient Motion Detection 
using Adaptive Background Generation,” IET JNL Digital Object Identifier, Vol. 45, No. 11, Pages 
542-543, May 21, 2009. 
[3]  Shan Li, Moon-Chuen Lee, “An Efficient Spatio-temporal Attention Model and Its Application to 
Shot Matching,” IEEE Trans. on Circuits and System for Video Technology, Vol. 17, No. 10, Oct., 
2007. 
[4]  D. Roqueiro, V. A. Petrushin, “Counting People using Video Cameras,” Intl. Journal of Parallel, 
Emergent and Distributed Systems, Vol. 22, No. 3, Pages 193-209, Jan., 2007. 
[5]  Yeon-sung Choi, Piao Zaijun, Sun-woo Kim, Tae-hun Kim, and Chun-bae Park, “Salient Motion 
Information Detection Technique using Weighted Subtraction Image and Motion Vector,” ICHIT’06, 
Vol. 1, Pages 263-269, Nov. 9-11, 2006. 
[6]  Ying-Li Tian, Arun Hampapur, “Robust Salient Motion Detection with Complex Background for 
Real-time Video Surveillance,” Intl. Conf. on WACV/MOTIONS'05, Vol. 2, Pages 30-35, Jan., 
2005. 
[7]  Sen-Ching S. Cheung, Chandrika Kamath, “Robust Techniques for Background Subtraction in Urban 
Traffic Video,” Proc. of Video Communications and Image Processing, Pages 881-892, Jan., 
2004. 
[8]  George V. Paul, Glenn J. Beach, and Charles J. Cohen, “A Realtime Object Tracking System using a 
Color Camera,” IEEE Conf. on Applied Imagery Pattern Recognition Workshop 30th, Pages 
137-142, Oct. 10-12, 2001. 
[9]  Laurent Itti, Christof Koch, and Ernst Niebur, “A Model of Saliency-Based Visual Attention for Rapid 
Scene Analysis,” IEEE Trans. on Pattern Analysis and Machine Intelligence, Vol. 20, No. 11, 
Pages 1254-1259, Nov., 1998. 
[10] Alexis M. Tourapis, “Enhanced Predictive Zonal Search for Single and Multiple Frame Motion 
Estimation,’’ Proc. of SPIE Visual Communications and Image Processing, Vol. 4671, Pages 
1069-1079, Jan., 2002. 
[11] Ramesh Rasker, Adrian Ilie, and Jingyi Yu, “Image Fusion for Context Enhancement and Video 
Surrealism,” The 3rd International Symposium on Non-Photo Realistic and Rendering, Pages 
747-757, 2004. 
[12] Jing Li, Stan Z.Li, Quan Pan, and Tao Yang, “Illumination and Motion-Based Video Enhancement for 
Night Surveillance,” 2nd Joint IEEE Intl. Workshop on Visual Surveillance and Performance 
Evaluation of Tracking and Surveillance, Pages 169-175, Oct. 15-16, 2005. 
[13] Oliver Rockinger, “Image Sequence Fusion using a Shift Invariant Wavelet Transform,” IEEE Intl. 
Conf. on Image Processing, Pages 288-291, Oct. 26-29, 1997. 
[14] Yin Chen, Rick S. Bium, “Experimental Tests of Image Fusion for Night Vision,” 7th Intl. Conf. on 
Information Fusion, Pages 488-498, July 25-28, 2005. 
[15] Liangrui Tang, Jing Zhang, and Bing Qi. “An Improved Fuzzy Image Enhancement Algorithm,” 5th Intl. 
Conf. on Fuzzy Systems and Knowledge Discovery, Pages 186-189, 2008. 
[16] Madasu Hanmandlu, Devendra Jha, “An Optimal Fuzzy System for Color Image Enhancement,” 
IEEE Trans. on Image Processing, Vol. 15, No. 10, Pages 2956-2966, Oct., 2006. 
[17] Jiman Kim, Daijin Kim, “Probabilistic Camera Hand-off for Visual Surveillance,” Intl. Conf. on 
Digital Smart Cameras, Pages 1-8, 7-11 Sept., 2008. 
13 
 
Segmentation using Codebook Model,” Real-time Imaging, Pages 172-185, 2005. 
[37] M. Heikkila, M. Pietikainen, “A Texture-based Method for Modeling the Background and Detecting 
Moving Objects,” IEEE Trans. Pattern Anal. Mach. Intell., Vol. 28, No. 4, Pages 657-652, 
2006. 
[38] Ranjan Rahul, Singh Harpreet, Meitzler Thomas, Sohn E. J., Singh, and Kuldip, “Video Image Fusion 
Process using Fuzzy Technique,” Signal Processing, Sensor Fusion, and Target Recognition XV, 
Vol. 6235, Page 62350Y, June, 2006. 
[39] Neumann U., You S., Hu J., Jiang B., and Lee J. “Augmented Virtual Environments (AVE): Dynamic 
Fusion of Imagery and 3D Models,” VR03, March, 2003. 
[40] Ismail Oner Sebe , Jinhui Hu , Suya You , and Ulrich Neumann, “3D Video Surveillance with 
Augmented Virtual Environments,” 1st ACM SIGMM Intl. Workshop on Video Surveillance, 
Berkeley, California, Nov. 02-08, 2003. 
[41] Hsun-Chun Lee, Daw-Tung Lin, “Intelligent Surveillance System for Halt Detection and People 
Counting,” Journal of Information Technology and Applications, Vol. 2, No. 3, Pages 141-150, 
2007. 
 
2 
 
著重於影像資訊在空間關係之比對，以衡量影像在空間關係上之相似程度，提供使用者適當
利用感興趣之影像於資料庫搜尋出符合需求之影像，藉由輸入多張與目標影像正、負相關之
查詢影像，透過MIL法則動態搜尋正相關影像相似特徵及與負相關影像不相似部份，使搜尋
特徵更加明確，以MIL後之空間關係特徵作為檢索標準，不僅符合使用者期望，同時增加影
像搜尋之正確性及多樣性。會議中並未見其他以空間關係做為影像特徵進行檢索之相關論文，
將整理加強內容後，投稿相關journal。 
三、考察參觀活動(無是項活動者略) 
四、建議 
高雄、西安間並無直航班機，必須透過香港中轉，惟因大陸開放來台旅遊，台灣及香
港間之機票一位難求，被迫必須較預定提早一天抵達，並於香港 機場等待極長之轉機時間，
耗時費力，很不方便。 
五、攜回資料名稱及內容 
會議並未提供紙本 ACM proceeding，而以 USB 隨身碟儲存所有資料，環保又方便，
值得嘉許學習。 
六、其他 
感謝國科會補助相關經費，使我得以參加 CIVR 2010，與各國 image 及 video retrieval
之研究人員交換心得，受益良多。 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：蔣依吾 計畫編號：98-2221-E-110-068- 
計畫名稱：事件觸發之虛擬實境監控系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際
已達成數)
本計畫
實際貢
獻百分
比 
單位 
備註（質化說明：如
數 個 計 畫 共 同 成
果、成果列為該期刊
之封面故事...等）
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100% 由五人次輪流執行 
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
會 議 名
稱  :International 
Conference on Image 
and    
          Video 
Retrieval, 2010 
論 文 題
目:Multiple-instance 
Image Database 
Retrieval by Spatial 
Similarity based on 
Interval Neighbor 
Group 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
博士後研究員 0 0 100% 
人次 
 
 
