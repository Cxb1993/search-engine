Proceedings of the 2006 Winter Simulation Conference
L. F. Perrone, F. P. Wieland, J. Liu, B. G. Lawson, D. M. Nicol
EL
a
en
gc
3,A NEW APPROACH FOR PARALL
Ming-hu
Department of Managem
National Chen
Taipei, 1162
ABSTRACT
We propose a new procedure for building confidence interval
estimators of steady-state parameters in discrete event sim-
ulations. The procedure uses parallel processors to generate
independent replications and constructs the confidence inter-
val estimator by solving a generalized least square problem.
The most appealing theoretical feature of the proposed pro-
cedure is that the precision of the resulted estimator can be
improved by simply increasing the number of processors (or
independent replications) while the simulated time length
is fixed on an appropriate level on each processor. Experi-
ments conducted on M/M/1 queue waiting time processes
in heavy traffic confirm this theoretical property.
1 INTRODUCTION
Let Y = (Y (t) : t ≥ 0) be a real-valued stochastic process
representing the output of a discrete event simulation. Sup-
pose that Y satisfies a law of large number (LLN) of the
form
α(t)≡ 1
t
∫ t
0
Y (s)ds⇒ α (1)as t→∞, for some constant α , where ⇒ denotes conver-
gence in distribution. The steady-state simulation problem
is concerned with the efficient estimation of the steady-state
mean of α , and the construction of associated confidence
intervals (CIs).
As suggested by (1), the time-averageα(t) is an obvious
point estimator of α . Suppose that p processors are available
for simulation, and each processor simulates the process Y
independently up to (deterministic) time t. Let αi(t) denote
the time-average α(t) generated by processor i. Set
α(t, p) =
1
p
p∑
i=1
αi(t), (2)
1921-4244-0501-7/06/$20.00 ©2006 IEEE, and R. M. Fujimoto, eds.
STEADY-STATE SIMULATIONS
Hsieh
t Information Systems
hi University
TAIWAN
and
S2(t, p) =
1
p−1
p∑
i=1
(αi(t)−α(t, p))2. (3)
Then one might expect
α(t, p)± t1−γ/2,p−1S(t, p) (4)
is an asymptotically valid 100(1− γ)% CI for α , and the
absolute precision of the estimator (usually defined by the
half-length of the CI) is proportional to the order of
√
p.
We call estimator (4) the standard estimator. The standard
estimator will converge to a wrong value if simulated time t
and the number of processors p are not chosen appropriately
(Glynn and Heidelberger 1991b, Glynn and Heidelberger
1992a, and Glynn and Heidelberger 1992b.) Such statistical
problems basically arise because any bias effects on a single
replication are magnified on multiple replications. This type
of problems also arise in transient simulation context; see
(Heidelberger 1988) and (Glynn and Heidelberger 1991a),
for example.
The process Y is typically initialized via a distribution
forY (0) that is not characteristic of the steady-state behavior.
As a consequence, α(t) is biased as an estimator of α . In
other words, Eα(t) 6=α . For the same reason, Eα(t, p) 6=α .
The bias in α(t) as an estimator of α is known as the
“initial bias”. The initial bias problem, in the single pro-
cessor context, can be mitigated in two different ways. One
approach is to delete that initial segment of the simulation
that is “contaminated” by initial bias. Such an initial bias
deletion approach has been studied by many authors; see,
for example, Cash et al. (1992), Glynn (1995), Goldsman,
Schruben, and Swain (1994), Schruben (1982), Schruben
et al. (1983), White (1997), and White et al. (2000). An
alternative is to consider an estimator, based on simulatingY
over [0, t], that attempts to compensate for the bias present
in α(t). We refer to such estimators as “bias reducing”
estimators. The bias reducing estimators usually need to
siehH
Let S be the covariance matrix of the random column
vector (α(t1),α(t2), . . . ,α(tn))
T , then the covariance matrix
of α˜(p) is S/p. Note that α˜(p) is an approximate multi-
variate normal random variable by the CLT (10). Thus, we
have the following linear model
α˜(p) = Ab+ ε, (11)
where ε is normally distributed error vector with mean 0
and covariance matrix S/p. The linear model (12) is the
vehicle for building the confidence interval for α . Before
we proceed to the procedure of constructing he confidence
interval for α , we need the following proposition.
Proposition 1 Given a full rank univariate linear
model
θ = Ab+ ε (12)
for the n×1 random vector a, where A is an n× k matrix
of rank k ≤ n, b is an k× 1 (unknown) parameter vector,
and ε is the n× 1 normally distributed error vector with
mean 0. If the covariance matrix of ε is Σ and consider θ
a single observation from the linear model (12), then:
1. The maximum likelihood estimator of b is
bˆ= (ATΣ−1A)−1ATΣ−1θ . (13)
Estimator bˆ is also known as generalized least
square estimator.
2. Estimator bˆ is an unbiased estimator for b, i.e.,
Ebˆ= b.
3. The covariance matrix of the generalized least
square estimator bˆ is
Σ
bˆbˆ
= (ATΣ−1A)−1.
4. For 1≤ i≤ n,
bˆ(i)−b(i)√
Σ
bˆbˆ
(i, i)
∼ tn−k,
where tn denotes t-distributed random variable with
n degrees of freedom.
We are now ready to describe the proposed procedure:
1. Input p, T , 0 < t1 < t2 < · · · < tn = T , and the
required confidence level 1− γ .
2. Generate independent replicate ofY up to time T on
each processor and collect αi(t1),αi(t2), . . . ,αi(tn)
on each processor i, 1≤ i≤ p.
3. Compute the sample covariance matrix Sˆ of
(α(t1),α(t2), . . . ,α(tn))
T by the data collected in
step 2.1944. Compute bˆ and Σ
bˆbˆ
according to Proposition 1.
5. Output the confidence interval of α by
bˆ(1)± t1−γ/2,n−3
√
Σ
bˆbˆ
(1,1). (14)
The most appealing theoretical feature of the procedure
above is that the precision of the resulted estimator can be
improved by simply increasing p while the simulated time
T is fixed. This theoretical feature can be summarized in
the following theorem.
Theorem 1 Suppose that 0< t1 < t2 < · · ·< tn = T
and |b(t)− (b1/t+b2/t2)| is negligible for t ≥ t1. Assume
Σ
bˆbˆ
(p) denotes the covariance matrix of bˆ when the number
of processors is p and m a positive integer. Then
Σ
bˆbˆ
(mp) =
1
m
Σ
bˆbˆ
(p).
Let hl(p) denote the half length of CI when the number of
processors is p. By (14), above equation implies
hl(mp) =
1√
m
hl(p).
Proof Since
Σ
bˆbˆ
(mp) = (AT (S/mp)−1A)−1 =
1
m
(AT (S/p)−1A)−1,
we have
Σ
bˆbˆ
(mp) =
1
m
Σ
bˆbˆ
(p).
2
3 EMPIRICAL RESULTS
We chose the waiting time process in the M/M/1 queue
with server utilization ρ = 0.9 and an empty-and-idle initial
condition as the test problem. This is a particularly difficult
test problem. Steiger et al. (2005) state several reasons:
1. the initialization bias is large and decays relatively
slowly;
2. in steady-state operation the autocorrelation func-
tion of the waiting time process decays very slowly
with increasing lags; and
3. in steady-state operation the marginal distribution
of waiting times has an exponential tail and is
therefore markedly nonnormal.
Thus we expect the proposed estimator will perform well
on most of real world applications if it does well on this
test problem.
HsiehTable 1: Empirical Performance of the Proposed Pro-
cedure for the M/M/1 Queue Waiting Time Process
with ρ = 0.9 and Simulated Time T = 1000 Based on
1000 Independent Replications of Nominal 90% and
95% Confidence Intervals
Nominal Nominal
p= 512; n= 6,12, or 18 90% CIs 95% CIs
(t1, . . . , tn) = (250,400, . . . ,T )
coverage 89.1% 94.3%
avg. CI half-length 0.718 0.972
s.d. CI half-length 0.317 0.428
(t1, . . . , tn) = (230,300, . . . ,T )
coverage 90.2% 95.0%
avg. CI half-length 0.528 0.652
s.d. CI half-length 0.134 0.165
(t1, . . . , tn) = (235,280, . . . ,T )
coverage 85.7% 92.0%
avg. CI half-length 0.507 0.616
s.d. CI half-length 0.103 0.125
p= 2048; n= 6,12, or 18
(t1, . . . , tn) = (250,400, . . . ,T )
coverage 89.4% 93.5%
avg. CI half-length 0.357 0.483
s.d. CI half-length 0.155 0.209
(t1, . . . , tn) = (230,300, . . . ,T )
coverage 91.2% 96.4%
avg. CI half-length 0.269 0.331
s.d. CI half-length 0.066 0.082
(t1, . . . , tn) = (235,280, . . . ,T )
coverage 88.1% 93.6%
avg. CI half-length 0.256 0.311
s.d. CI half-length 0.049 0.059
p= 8192; n= 6,12, or 18
(t1, . . . , tn) = (250,400, . . . ,T )
coverage 90.6% 95.6%
avg. CI half-length 0.185 0.250
s.d. CI half-length 0.078 0.106
(t1, . . . , tn) = (230,300, . . . ,T )
coverage 89.9% 94.4%
avg. CI half-length 0.140 0.173
s.d. CI half-length 0.034 0.042
(t1, . . . , tn) = (235,280, . . . ,T )
coverage 89.3% 94.5%
avg. CI half-length 0.132 0.161
s.d. CI half-length 0.025 0.030
REFERENCES
Cash, C. R., B. L. Nelson, D. G. Dippold, J. M. Long,
and W. P. Pollard. 1992. Evaluation of tests for initial-
condition bias. In Proceedings of the 24th Winter Sim-
ulation Conference (WSC’92), 577–585.196Table 2: Empirical Performance of the Proposed Pro-
cedure for the M/M/1 Queue Waiting Time Process
with ρ = 0.9 and Simulated Time T = 2000 Based on
1000 Independent Replications of Nominal 90% and
95% Confidence Intervals
Nominal Nominal
p= 512; n= 6,12, or 18 90% CIs 95% CIs
(t1, . . . , tn) = (250,600, . . . ,T )
coverage 89.4% 95.1%
avg. CI half-length 0.489 0.661
s.d. CI half-length 0.201 0.272
(t1, . . . , tn) = (350,500, . . . ,T )
coverage 88.4% 94.0%
avg. CI half-length 0.404 0.499
s.d. CI half-length 0.100 0.124
(t1, . . . , tn) = (300,400, . . . ,T )
coverage 88.0% 94.3%
avg. CI half-length 0.362 0.439
s.d. CI half-length 0.073 0.089
p= 2048; n= 6,12, or 18
(t1, . . . , tn) = (250,600, . . . ,T )
coverage 89.1% 94.7%
avg. CI half-length 0.244 0.329
s.d. CI half-length 0.102 0.137
(t1, . . . , tn) = (350,500, . . . ,T )
coverage 90.5% 94.7%
avg. CI half-length 0.207 0.255
s.d. CI half-length 0.050 0.062
(t1, . . . , tn) = (300,400, . . . ,T )
coverage 90.8% 95.7%
avg. CI half-length 0.187 0.227
s.d. CI half-length 0.035 0.042
p= 8192; n= 6,12, or 18
(t1, . . . , tn) = (250,600, . . . ,T )
coverage 88.5% 94.0%
avg. CI half-length 0.125 0.168
s.d. CI half-length 0.054 0.072
(t1, . . . , tn) = (350,500, . . . ,T )
coverage 86.8% 93.4%
avg. CI half-length 0.103 0.127
s.d. CI half-length 0.024 0.030
(t1, . . . , tn) = (300,400, . . . ,T )
coverage 89.8% 93.7%
avg. CI half-length 0.092 0.112
s.d. CI half-length 0.018 0.021
Glynn, P. W. 1984. Some asymptotic formulas for markov
chain with applications to simulation. Journal of Sta-
tistical Computation and Simulation 19:97–112.
Glynn, P. W. 1995. Some new results on the initial transient
problem. In Proceedings of the 27th Winter Simulation
Conference (WSC’95), 165–170.
