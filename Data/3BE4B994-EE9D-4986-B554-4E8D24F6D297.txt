2 
 
可達到影像的可階性編解碼，同時除了具有可階性的特性外，在壓縮效率上，亦可達到不錯的
效果。 
除了頻寬的限制外，在無線視訊系統中，因為在接收端通常為手持式的裝置，故必頇考慮
功率消耗的問題，因此 H.264/SVC 亦提供了一個可加以應用的壓縮方式。當有低功率消耗需
求時，調降系統的播放頻率，即可降低所需解碼的視訊畫面張數，以較低的功率消耗，達到視
訊畫面的即時撥放。然而在 H.264/AVC 的編解碼上，由於所有資料皆編碼於同一串資料流中，
且並無具有可階性的傳輸方式，故當傳輸頻寬或接收端的解碼效能不足時，即無法立即播放出
視訊畫面，如圖(一)所示。相反地，和 H.264/AVC 不同的是，由於 H.264/SVC 具有可階性編解
碼的特性，在接受端資源有限的狀況下，雖然無法以最高品質的方式呈現視訊畫面，但仍可以
解碼出可接受的完整影像，這更符合接受端所需。 
 
圖一、Non-scalable V.S. Scalable 
本子計畫即配合總計畫「下一代行動電視之多媒體與網路整合核心系統設計」，進行
H.264/SVC 多媒體視訊之系統晶片設計。由於 SOC 的進步與發展，要在單一晶片上實現
H.264/SVC 高複雜度的影像處理的可能性變得越來越高，在此子計畫中，著重在每塊功能區塊
上演算法的設計與實現，並且利用 SIP 的可重複使用特性，加速 SOC 的開發，根據所需求的
規格，搭配演算法的改進，進而實現出 VLSI 硬體架構。由於不同的演算法，在 VLSI 實現複
雜度上便有不同的影響，因此針對不同的功能區塊設計其演算法，並同時配合 VLSI 實現，改
良演算法設計，達到軟硬體共同設計的特性。 
II. 文獻探討 
H.264/SVC 是新一代影像編碼標準，且提供極大的編碼效率及 network friendly 
functionalities。在未來 video streaming 及通訊中，H.264/SVC 將會是大眾最推崇的標準。然而
H.264/SVC 的編碼效能固然佳，但由於其高複雜度，為了達到即時運算需求，必頇採用軟硬體
4 
 
1) Temporal Scalability 
Temporal scalability 可以使 frame rate 具有可階式編解碼，H.264/SVC 主要採用兩種方式以
達到 temporal scalability 的特性，一種為 MCTF，另一種為 Hierarchical B pictures，圖(三)為
MCTF 的示意圖，在解碼端中，level 0 的資料為最低的 temporal resolution，根據解碼端應用的
需求，假設 full resolution 為 60 fps 的情況下，若只解碼 level 3 的資訊量僅需 5 fps，解碼至 level 
2 則需 15 fps，而解碼至 level 1 將達 30 fps，也可在高畫質需求之下，完全解碼至 level 0，即
達到原本播放速度 60 fps。MCTF 是一種基於 lifting scheme 的編碼方式，在編碼端使用 analysis 
filterbank，在解碼端使用 synthesis filterbank，如圖(四)所示，主要包含三種部份：polyphase 
decomposition、 prediction 和 update unit。在大部份的 MCTF 中，限制只會使用一組 prediction
和 update unit。 
 
圖三、以 MCTF 實現之 temporal scalability 
 
圖四、Lifting scheme for MCTF 
為了達到 temporal scalability 的特性，除了使用 MCTF 的方法外，另一種方式為 hierarchical 
B pictures，其架構如圖(五)所示，此為兩個GOP＝8的編解碼架構，圖中編號為 0、8 和 16 的
pictures 為 key pictures，key pictures 使用 I 或 P 的編碼預測方式，除了 key pictures 外，其餘為
B pictures。當用戶端只解碼 key pictures 時，可達到最低的 temporal scalability。以 full resolution 
為 60 fps 而言，可利用 temporal scalability 方式達到 7.5 fps。每張 B picture 利用兩張 pictures
6 
 
3) SNR Scalability 
在 SNR scalability 的部分，可被視為 spatial scalability 的一個特例。其差別只是 SNR 
scalability 的 base layer 和 enhancement layer 採用了同樣的畫面大小。直接從 spatial scalability
支援過來的方式，稱為 coarse grain scalability(CGS)。在 CGS，預測的機制是直接使用轉換域
的 inter-layer intra or residual prediction 的資訊。不同 layer 之間 texture information 的 refinement 
是靠採用不一樣的量化係數，且 enhancement  layer 的量化係數比較小。 
然而，使用 CGS 有其缺點。在 CGS 的編碼中，提供不同 bitrates 的點受限於不同 layer 的
數目，因此無法達到可提供任意 bitrates 的編碼。另外，CGS 在比較高層的 layer 時，不同 layer
之間的 bitrates 會相差越來越少。除了 CGS 之外，fine grain scalability(FGS)和 medium grain 
scalability(MGS)也都是可以達到 SNR scalability 的方法。 
III. 研究方法、結果與討論 
如前所述，本子計畫過去三年著重在每塊功能區塊上演算法的設計與實現，根據所需求的
規格，搭配演算法的改進，進而實現出 VLSI 硬體架構。由於不同的演算法，在 VLSI 實現複
雜度上便有不同的影響，因此針對不同的功能區塊設計其演算法，並同時配合 VLSI 實現，改
良演算法設計，達到軟硬體共同設計的特性，以下就 H.264/SVC 各個核心元件的研究方法與
結果說明如下。 
1) 內框預測之離散十字誤差演算法 
內框決策機制是利用鄰近像素來預測區塊內部方向，分析區塊內像素的關連性，利用離散
十字誤差演算法先過濾可能的預測模式，圖(七)是離散十字誤差的示意圖，利用圖上兩個十字
上下左右的誤差值，帶入決策演算法中，如圖(八)所示，選出最有可能的預測模式，兩個鄰近
的預測模式也被選出以增加準確度，除此之外，由於離散十字誤差演算法無法判斷 DC 模式，
所以 DC 模式也一併列入可能的預測模式。模擬結果顯示，所節省之編碼時間為原來編碼器所
需要的 56%，且達到和原來非常相似的影像品質。 
 
圖七、計算水平垂直誤差之十字圖樣 
8 
 
 
圖十、整合 run_before 解碼和反量化器架構 
在反轉換器的架構設計上，為了降低硬體面積，將反轉換矩陣公式進行化簡，經由觀察原
始的反轉換矩陣，進行共同項的提出與簡化，可以獲得一個僅需比較少加法器的計算流程，最
後並將 inverse DCT 和 inverse Hadamard 兩種轉換整合在一起。為了加快反轉換的硬體操作頻
率，其架構採用兩極管線化的技術，架構圖如圖(十一)所示。 
 
圖十一、反轉換器架構 
3) 轉換域內框預測演算法及其硬體實現 
離散餘弦轉換是視訊領域中最常被使用的元件之一，除了將區塊內的能量集中到左上角部
分外，同時也能將區塊中能量分解到不同的垂直水平餘弦頻率基本圖樣中，如圖(十二)所示。
因此藉由分析離散餘弦轉換係數來偵測區塊內部的紋理方向，以減少內框編碼中所需要的模式
個數。觀察離散餘弦轉換的基本圖樣，將同類型的係數合併再一起，總共可分為六類，由於
10 
 
 
圖十四、轉換域內框編碼器之 VLSI 硬體架構 
4) 低成本位元率控制系統軟硬體共同設計 
為了使得在編碼時，位元率能夠適當且平均的分配，編碼器需要一個位元率控制方法。因
此設計了一個位元率控制的方法，此方法能夠使 H.264 實作於嵌入式系統中。在設計中，除了
要求位元率控制的效果，同時也考量實現的複雜度。在實現上，使用了有效率的軟硬體共同設
計方式，以硬體實現區塊層級位元率控制模組，及以軟體實現畫面層級位元率控制模組，分割
後如圖(十五)所示。由於設計的整體演算法比 H.264 所採用的方法擁有更少的計算複雜度，如
此一來，可應用於嵌入式系統中。 
 
圖十五、位元率控制系統軟硬體分割區塊圖 
12 
 
5) 應用於 RDO 編碼器之二階段位元率控制機制 
位元率控制的問題，當編碼器使用 RDO 的技巧進行編碼時，會更加複雜。因此提出了一
個同時考慮 RDO 和位元率控制的編碼器演算法及硬體架構。在硬體架構設計上，將整個計算
過程分為四個階段，如圖(十八)所示。此方法及架構使用了五個 RD cost 計算器及兩個位元率
控制模組來增加位元率的控制效果及可靠度。另外，由於在 RDO 時計算所有預測模式的位元
率時，其複雜度很高，因此為了降低複雜度，如圖(十九)所示，可將所有的預測模式進行分組，
先進行估測位元率來決定最後哪些預測模式需要進行精確的位元率計算。圖(二十)所示則為位
元率控制演算法流程圖。 
 
圖十八、RDO 編碼硬體架構區塊圖 
 
圖十九、RDO 為基礎的預測模式決策流程圖 
14 
 
由於經過轉換過的殘值係數之間具有相關性，因此係數切割出來的餘數部分需先去除冗餘
的位元，精簡過後的餘數部分才進行固定長度編碼。根據二維 4×4 Hadamard transform 的特性，
可以得知轉換過殘值係數的冗餘位元，如圖(二十二)所示，分別在第一、二、三和四的位元平
面有 1、 5、11 和 15 個冗餘位元。除此之外，演算法獲得的商數部分也不是直接將低位元去
除得到，而是去除完低位元後加入餘數部分的最高位元進行補償。此補償方法對於絕對值比較
小的係數比較有利，對於絕對值大的係數反而會增加編碼後的長度，如圖(二十三)所示，但由
於轉換後的殘值係數通常絕對值會比較小，因此整體來說這個方法還是可以得到比沒有補償還
要較好的效果。為了能夠將轉換後的殘值係數適當的分成商數和餘數兩部分，同時提出了一個
適應性演算法，此演算法根據鄰近區塊的資訊來預測及決定切割的位元數，之後會用已經編碼
的結果來更新切割位元數資訊，使用此方法可以不需要傳輸另外多餘的資訊來告訴解碼器需要
進行切割的位元數。整體的演算法架構如圖(二十四)所示，實驗顯示此方法可以明顯改善原始
H.264 無失真壓縮方式的壓縮效率。 
 
圖二十二、殘值係數的冗餘位元示意圖 
 
圖二十三、殘值係數商數部分補償後的編碼長度改變圖 
 
圖二十四、演算法架構圖 
16 
 
 
圖二十七、Even Unit 和 Odd Unit 詳細硬體架構圖 
 
圖二十八、Composition Unit 詳細硬體架構圖 
18 
 
Joint Video Team, June 2007. 
[9] H. Schwarz, D. Marpe, and T. Wiegand, Comparison of MCTF and Closed-Loop Hierarchical B 
Pictures, Joint Video Team, Doc. JVT-P059, July 2005. 
[10] X. Wang, Y. Bao, M. Karczewicz, and J. Ridge, Implementation of Closed-Loop Coding in 
JSVM, Joint Video Team, Doc. JVT-P057, July 2005. 
[11] R. Xiong, J. Xu, F. Wu, and S. Li, “Barbell-lifting based 3-D wavelet coding scheme,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 17, pp. 1256-1269, Sept. 2007. 
[12] P. Amon, T. Rathgen, and D. Singer, “File format for scalable video coding,” IEEE Trans. 
Circuits Syst. Video Technol., vol. 17, pp. 1174-1185, Sept. 2007. 
[13] S. H. Kim and Y. S. Ho, “Fine granular scalable video coding using context-based binary 
arithmetic coding for bit-plane coding,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, pp. 
1301-1310, Sept. 2007. 
[14] E. Francois, J. Vieron, and V. Bottreau, “Interlaced coding in SVC,” IEEE Trans. Circuits Syst. 
Video Technol., vol. 17, pp. 1136-1148, Sept. 2007. 
[15] H. Xu, J. Xu, and F. Wu, “Lifting-based directional DCT-like transform for image coding,” 
IEEE Trans. Circuits Syst. Video Technol., vol. 17, pp. 1325-1335, Sept. 2007. 
[16] T. Schierl, T. Stockhammer, and T. Wiegand, “Mobile video transmission using scalable video 
coding,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, pp. 1204-1217, Sept. 2007. 
[17] I. Amonou, N. Cammas, S. Kervadec, and S. Pateux, “Optimized rate-distortion extraction with 
quality layers in the scalable extension of H.264/AVC,” IEEE Trans. Circuits Syst. Video 
Technol., vol. 17, pp. 1186-1193, Sept. 2007. 
[18] H. Schwarz, D. Marpe, and T. Wiegand, “Overview of the scalable video coding extension of 
the H.264/AVC standard,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, pp. 1103-1120, 
Sept. 2007. 
[19] M. Wien, H. Schwarz, and T. Oelbaum, “Performance analysis of SVC,” IEEE Trans. Circuits 
Syst. Video Technol., vol. 17, pp. 1194-1203, Sept. 2007. 
[20] M. Wien, R. Cazoulat, A. Graffunder, A. Hutter, and P. Amon, “Real-time system for adaptive 
video streaming based on SVC,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, pp. 
1227-1237, Sept. 2007. 
[21] D. Song and C. W. Chen, “Scalable H.264/AVC video transmission over MIMO wireless 
systems with adaptive channel selection based on partial channel information,” IEEE Trans. 
Circuits Syst. Video Technol., vol. 17, pp. 1218-1226, Sept. 2007. 
[22] C. A. Segall and G. J. Sullivan, “Spatial scalability within the H.264/AVC scalable video 
coding extension,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, pp. 1121-1135, Sept. 
2007. 
[23] N. Adami, A. Signoroni, and R. Leonardi, “State-of-the-art and trends in scalable video 
compression with wavelet-based approaches,” IEEE Trans. Circuits Syst. Video Technol., vol. 
17, pp. 1238-1255, Sept. 2007. 
20 
 
[38] R. Atta and M. Ghanbari, “Spatio-temporal scalability-based motion-compensated 3-D 
subband/DCT video coding,” IEEE Trans. Circuits Syst. Video Technol., vol. 16, pp. 43-55, Jan. 
2006. 
[39] R. Xiong, J. Xu, and F. Wu, “A lifting-based wavelet transform supporting non-dyadic spatial 
scalability,” in Proc. IEEE ICIP, Oct. 2006, pp. 1861-1864. 
[40] Z. Wang and J. Liu, “A new intra coding method for spatial scalability in scalable video 
coding,” in Proc. IEEE WiCOM, Sept. 2006, pp. 22-24. 
[41] Y. Yamamoto, K. Kawamura, and H. Watanabe, “A study on spatial scalable coding using 
vector representation,” in Proc. IEEE ICME, July 2006, pp. 145-148. 
[42] W. Yao, Z. Li, and S. Rahardja, “Balanced inter-layer prediction for combined coarse granular 
scalability and spatial scalability,” in Proc. IEEE ISCAS, May 2007, pp. 1759-1762. 
[43] E. Francois and J. Vieron, “Extended spatial scalability: a generalization of spatial scalability 
for non dyadic configurations,” in Proc. IEEE ICIP, Oct. 2006, pp. 169-172. 
[44] H. Li, Z. G. Li, C. Wen, and L. P. Chau, “Fast mode decision for spatial scalable video coding,” 
in Proc. ISCAS, May 2006, pp. 3005-3008. 
[45] Z. Wang, J. Liu, and J. Tian, “H.264-based scalable intra coding scheme,” in Proc. IEEE 
ICOSP, Nov. 2006, pp. 1-4. 
[46] W. Yang, G. Rath, and C. Guillemot, “Improved interlayer prediction for scalable video 
coding,” in Proc. IEEE ICASSP, Apr. 2007, pp. 649-652. 
[47] R. Xiong, J. Xu, F. Wu, and S. Li, “In-scale motion aligned temporal filtering,” in Proc. IEEE 
ISCAS, May 2006, pp. 3017-3020. 
[48] S. T. Hsiang, “Intra-frame dyadic spatial scalable coding based on a subband/wavelet 
framework for MPEG-4 AVC/H.264 scalable video coding,” in Proc. IEEE ICIP, Sept. 2007, 
pp. 73-76. 
[49] C. An and T. Q. Nguyen, “Low complexity scalable video coding,” in Proc. IEEE ICIP, Sept. 
2007, pp. 73-76. 
[50] N. Bozinovic and J. Konrad, “Modeling motion for spatial scalability,” in Proc. IEEE ICASSP, 
May 2006, pp. 29-32. 
[51] D. Liu, Y. He, S. Li, D. Zhao, and W. Gao, “Motion aligned spatial scalable video coding,” in 
Proc. IEEE ICME, July 2006, pp. 117-120. 
[52] Y. Piao and H. W. Park, “New forming scheme of reference of LL band for in-band video 
coding with spatial scalability,” in Proc. IEEE ICIP, Oct. 2006, pp. 1877-1880. 
[53] Z. G. Li, W. Yao, S. Rahardja, and S. Xie, “New framework for encoder optimization of 
scalable video coding,” in Proc. IEEE SIPS, Oct. 2007, pp. 527-532. 
[54] Y. Liu, Y. C. Soh, and Z. G. Li, “Rate control for spatial/CGS scalable Extension of 
H.264/AVC,” in Proc. ISCAS, May 2007, pp. 1746-1750. 
[55] A. Segallt and A. Katsaggelosl, “Resampling for spatial scalability,” in Proc. ICIP, Oct. 2006, 
pp. 181-184. 
22 
 
[74] M. Hiki, T. Ishida, S. Muramatsu, and H. Kikuchi, “Suppression of PSNR fluctuation in 
motion-compensated temporal 1/3-transform through non-separable sub-sampling,” in Proc. 
IEEE ICIP, Oct. 2006, pp. 2153-2156. 
[75] C. C. Lin, Y. T. Hwang, K. H. Tseng, and S. W. Chen, “Wavelet based lossless video 
compression using motion compensated temporal filtering,” in Proc. IEEE SIPS, Oct. 2007, pp. 
686-691. 
[76] B. Karunanithi, B. D. Liu, J. F. Yang, and W. C. Tsai, “A low complexity detection of discrete 
cross differences for fast H.264/AVC intra prediction,” IEEE Trans. Multimedia, vol. 10, pp. 
1250-1260, Nov. 2008. 
[77] Y. C. Chao, S. T. Wei, B. D. Liu, and J. F. Yang, “Combined CAVLC decoder, inverse quantizer 
and transform kernel in compact H.264/AVC decoder,” IEEE Trans. Circuits Syst. Video 
Technol., vol. 19, pp. 53-62, Jan. 2009. 
[78] C. H. Kuo, L. C. Chang, K. W. Fan, and B. D. Liu, “Hardware/software co-design of a low cost 
rate control scheme for H.264/AVC,” IEEE Trans. Circuits Syst. Video Technol., vol. 20, pp. 
250-261, Feb. 2010. 
[79] C. H. Kuo, L. C. Chang, H. C. Chiu, and B. D. Liu, “Efficient two-pass rate control scheme 
based on adjusting distribution of DCT coefficients,” IET Image Process., vol. 4, pp. 211-222, 
June 2010. 
[80] H. Y. Lin, K. H. Wu, B. D. Liu, and J. F. Yang, “An efficient VLSI architecture for 
transform-based intra prediction in H.264/AVC,” IEEE Trans. Circuits Syst. Video Technol., vol. 
20, pp. 894-906, June 2010. 
[81] L. C. Chang, C. H. Kuo, and B. D. Liu, “A two stage rate control mechanism for RDO-based 
H.264/AVC encoders,” IEEE Trans. Circuits Syst. Video Technol., vol. 21, pp. 660-673, May 
2011. 
[82] S. T. Wei, C. W. Tien, B. D. Liu, and J. F. Yang, “Adaptive truncation algorithm for 
Hadamard-transformed H.264/AVC lossless video coding,” IEEE Trans. Circuits Syst. Video 
Technol., vol. 21, pp. 538-549, May 2011. 
[83] Y. C. Chao, C. H. Kao, B. D. Liu, and J. F. Yang, “Efficient inverse transform architectures for 
multi-standard video coding applications,” accepted for publication in IET Image Process.. 
[84] H. Y. Lin, K. H. Wu, B. D. Liu, and J. F. Yang, “Transformed-based mode decision algorithm 
for H.264/AVC intra-prediction,” in Proc. IEEE APCCAS, Nov. 2008, pp. 1344-1347. 
[85] K. Bharanitharan, B. D. Liu, and J. F. Yang, “A low complexity fast inter prediction algorithm 
for H.264/AVC,” in Proc. IEEE ICCEE, Dec. 2008, pp. 73-77. 
[86] K. Bharanitharan, B. D. Liu, and J. F. Yang, “An efficient region based intra prediction 
algorithm for H.264/Advanced video coding,” in Proc. IEEE ICCEE, Dec. 2008, pp. 393-397. 
[87] C. W. Tien, H. Y. Lin, B. D. Liu, and J. F. Yang, “Transform-domain partial prediction algorithm 
for intra prediction in H.264/AVC,” in Proc. IEEE ISCAS, May 2009, pp. 1245-1248. 
[88] S. T. Wei, S. R. Shen, B. D. Liu, and J. F. Yang, “Lossless image and video coding based on 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/05
國科會補助計畫
計畫名稱: 子計畫二:H.264/SVC多媒體視訊之系統晶片設計
計畫主持人: 劉濱達
計畫編號: 97-2221-E-006-135-MY3 學門領域: 訊號處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
