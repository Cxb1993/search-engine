idiom, etc. Another is the algorithm for real-time 
very large ASR. 
英文關鍵詞： Very large vocabulary speech recognition, DM compound 
word, Morphologically- Derived (MD) word, Prosody-
assisted ASR, Speaking rate 
 
 2
目錄 
中文摘要                    3 
Abstract                     3 
一、研究目的                  4 
二、文獻探討                  4 
三、研究方法及實驗結果               5 
    3.1 考慮定量複合詞/人名/詞綴構詞之 ASR           5 
      3.1.1 構詞及構詞結構分類               6 
      3.1.2 建立結構化語言模型               7 
      3.1.3 以 WFST 建立結構化語言模型                8 
      3.1.4 以 two-stage ASR 建立結構化語言模型           8 
      3.1.5 實驗結果                 8 
    3.2 考慮詞綴構詞之語音辨認              9 
    3.3 使用韻律信息協助語音辨認之方法              13 
    3.4 考慮語速影響之中文語音辨認               14 
      3.4.1 語速相依韻律模型之建立               15 
      3.4.2 The Second Stage 之實作                17 
      3.4.3 鑑別式模型組合                 19 
    3.5 使用韻律訊息於中文語音辨認之聲學模型建立            21 
      3.5.1 模型訓練結果分析                 23 
      3.5.2 韻律停頓對於音節中所有音素影響之探討            26 
      3.5.3 音節辨認之實驗結果及分析               28 
      3.5.4 以有限狀態機實現大詞彙語音辨認             31 
四、結論與討論                    36 
五、計畫成果自評                   36 
六、參考文獻                     37 
 
 
 
 
 
 
 
 
 
 
 
 4
 
一、 研究目的 
本計畫的目的是發展中文極大詞彙語音辨認技術，將不包含在一般 ASR 詞典的人名專有名詞、數
量複合詞、詞綴構詞等大量 OOV (out of vocabulary)詞在辨認過程中能加入考慮，使其能被辨認，並嘗
試使用韻律信息來協助辨認，以解決 OOV 問題及增進辨認率，並讓電腦逐漸可以辨識詞組 (word 
chunk)，以作為未來進一步發展包含更大量詞組之語音問答系統或語音資料搜尋系統之基礎。 
 
二、 文獻探討 
近年來語音辨認的研究已朝大詞彙語音辨認(Large-vocabulary Automatic Speech Recognition, 
LVASR)系統發展，一般LVASR採用triphone (或initial/final for Mandarin) HMM 聲學模型(Acoustic 
Model, AM)、60,000 詞字典(Lexicon)、及 n-gram (bigram 或 trigram)語言模型(Language Model, LM)，
這樣的系統對一般的應用是足夠的，尤其是英語的 dictation，但對許多語言的 dictation 及其他應
用則顯現許多不足，主要問題是詞的涵蓋率不足以及 n-gram LM 缺乏 syntactic/semantic 
information，前者稱為 out-of-vocabulary (OOV)問題，近幾年已有許多嘗試擴大 lexicon 成為極大
詞彙的語音辨認研究，後者則嘗試使用語法分析(parser)作為 LM 來了解輸入語音或是以 parsing 
information 來改進 n-gram LM。 
中文詞彙在[1]已經被充分定義，包含了 Lexicon Word(LW)、Morphologically Derived Word 
(MDW)、Factoid Word(FT)、Name Entity(NE)及 New Word(NW)五類。從此詞彙定義我們可以發現，以
傳統依據詞頻所收錄的辨認用辭典存在著一些收錄上的限制。首先，中文包含很多由前後詞綴和一般
Lexical Word 組合而成的 MDW words，除高頻詞有大量 MDW words 無法收錄於一般詞典中。在拼音系
統複雜的語言中，morphology 一直是研究的重點對象。語言學裡語族分類中的斯拉夫語族(捷克語
[ 2]、斯洛伐客語[3])、日耳曼語族(德語[4])、閃語族(阿拉伯語[5][6][7])等語言在近幾年的語音
辨認系統中開始以 morphology 的觀點改善 word based language model 中 coverage 不足的問題。這
類 rich morphology 的語言有一個共同特性，就是一個詞彙會隨著語法、語境、時態、陰陽上的變化
而有不同的詞首、詞中或詞尾的變化，有些時候這些變化有簡單的規則，但大部分的變化都是非常錯
綜複雜，以致於同一個詞彙可能同時擁有五、六種或更多種變化型，造成辨認辭典收集上的困難。於
是對於如何將 morphology 的概念加入傳統的 word based language model 中就成了近幾年來此類語言
共同的研究目標。 
[8]提出將一個詞彙拆解成主要部分(stem)及詞綴(affix)，將訓練語料裡所有無法收錄在辭典內
的詞彙全部拆解成 morphological segments，將這些 segment 視為 word sequence 並加入統計模型或
規則以限制詞彙的組成方式，產生一個 Joint Morphological Lexical Language model(JMLLM)，以
增加 word coverage 及減少 OOV rate，以此方式所得的 language model 在 perplexity、OOV rate 及
word error rate 上均有顯著的改善。[9] 考慮在將 morphological segments 和 lexical item 混合
訓練成一個 JMLLM 時所遭遇的兩個問題：acoustic confusion 和 lexicon coverage，提出決定適當
morphological segments 的方法，以解決當選用的 morphological segments 太短時，會造成 acoustic 
confusion，以及當選用的 morphological segments 過長時，每一個 segment 在 word overage 上所能
提供的貢獻降低，造成詞彙的整體 coverage 下降的問題。對於中文 NE 部分，在中文文字處理方面已
有許多成熟的偵測技術[1]，在英文語音辨認中已有針對複合詞(compound word)做研究的先例[10]，
而在中文語音辨認中仍舊少有此類研究。 
 
 6
構化語言模型的目的。 
3.1.1 構詞及構詞結構分類 
我們針對三種主要構詞型態(人名、定量複合詞、詞綴詞)，分析其語意類別、結構類型等，分別建
立結構化構詞規則，並依據此分類原則建立結構化語言模型。 
A. 定量複合詞構詞與結構分類 
我們依據中研院詞庫小組對於定量複合詞的定義及量詞分類，加入結構與數詞特性的分析，分別
建構了四十組 DM 類別。表一列出重要的 DM 語意類別與其所偏好的數詞類型及結構類型，結構類型
的示意圖則如圖二、圖三所示。圖二顯示一個基本的 DM 詞所包含的 POS 成分及組成關係，圖三則顯
示基本 DM 詞與前後修飾詞關係。可以發現雖然 DM 詞組的組合複雜且無法窮舉，但以 POS 結構的角
度來看便有了較簡化的構詞規則。表二則列出了 DM 類別分類下，各類別中所存在的階層化構詞關係。
建立階層化構詞關係將有助於建立階層化構詞語言模型。 
表一：定量複合詞分類 
語意類別 子分類 數詞類型 結構類型 範例 
時間 年份、日期、時
間 
特定範圍整數 簡單、複雜、
階層 
二零一一年、 
十點二十分、兩分十五秒 
地址 路名、特定地點 小範圍整數 簡單、階層 十五巷、光復路二段 
比例 百分比、比例、
比數 
一般整數 簡單 五分之三、六成、一比三 
金錢 金錢 整數、小數 簡單、複雜 十五美元 
度量 重量、長度、容
量、面積 
整數、小數 簡單、複雜 三公斤、一點五公升 
一般量詞 個體、群體 整數 簡單、複雜 五個、約十五件左右 
 
  
圖二：簡單 DM POS 結構 
 
 
圖三：複雜 DM 詞組 POS 結構 
 
表二：DM 階層結構 
語意類別 階層結構 範例 
Date / time year + month + day + 
hour + minute 
民國九十九年三月 
Price per unit unit + price 每公斤十五元 
Area / Volume length + length 長十五公尺寬五公尺 
 8
名構詞 subword，並以簡單的 word n-gram 建構內部構詞機率。另外在定量複合詞方面，我們將每個
DM 的構詞成分視為一個 subword，並將變化性強的數詞部分亦拆解成 subword 詞串(譬如將「一千五
百」拆解成「一千」+「五百」)，以增加數詞構詞後涵蓋率。詞綴構詞方面，目前的作法僅將不同詞
綴各自視為一個 class，並將每個詞綴詞拆解成「詞+詞綴」或「詞綴+詞」，再將每個拆解單元視為 subword
集合。 
對於上述各項類別，我們建構以 tri-gram 為基礎的語言模型如下式： 
1 2( ) ( | , )i i i
i
P W p w w w    if  lexicon wordiw           (1) 
1 2( ) ( | ) ( | , ) i i i i i
i
P W p w C p C w w   if -iw i th  class        (2) 
1 2
1
( | ) ( | , )
k
i i j j j
j
p w C p s s s 

 ,              (3) 
where is  is the i-th fragment of iw , k is the number of fragments of iw . 
在進行語音辨認時，我們做了兩個嘗試：以一個 one-pass WFST ASR 系統達成一階段構詞及辨認，
以及將構詞模組整合至 two-stage prosody-assisted ASR 系統。我們嘗試將結構化語言模型搭配韻律模
型，在原有的系統架構下建立具有局部詞組資訊的辨認系統。 
 
3.1.3 以 WFST 建立結構化語言模型 
WFST 辨認系統的優點在於能夠將聲學模型、語言模型等以一個有限狀態機建構，使得語音辨認
能夠在 one-pass 下進行 decoding。由於是在單一模型下進行解碼，要在 WFST 建立構詞模型時便有一
些限制，即所有構詞動作必須在建立 WFST 模型時同時建立，這會讓整個 WFST 變得非常龐大。因此
我們先只將人名結構納入 WFST 模型中，在 tri-gram 語言模型上建構人名結構子模組，使得 WFST 在
做 ASR decoding 時，能在得到詞辨認結果的同時得到構詞資訊。 
 
圖四：WFST 下的人名結構 rescoring FSM 模組 
 
3.1.4 以 two-stage ASR 建立結構化語言模型 
目前的 two-stage ASR 系統包含了一個 lattice extension 模組，將第一級辨認輸出的 bi-gram word 
lattice 依據 word trigram LM 展開成 trigram word lattice。我們將結構化語言模型加入 lattice extension 模
組，在展成 word/class trigram word lattice 的同時，即可得到各項構詞資訊及 class 內部機率。 
  
3.1.5 實驗結果 
在 WFST 實驗中，我們針對人名建構階層式語言模型，並進行 one-pass decoding。目前我們僅將
人名(personal nam, PN)本身建立 3 個 class，並未涵蓋人名前後頭銜等資訊，並且在 intra class 的機率上
僅使用 character unigram (受限於在 WFST 架構下無法將 intra class subword n-gram 完全展開)。測試語
料中共含有 369 個人名，其中 161 個人名屬於 OOV，並且有 33 個為外國人名。整體辨認率以及 OOV
人名的 precision 和 recall rate 如表五。 
 10
表八：詞幹詞性範例 
綴詞類別 詞幹詞性(46 類) 範例 
們 Na 親友們、情侶們 
記、物 Na、VA、VB、VC、VE、VH、VK 復仇記、漂遊記 
賽、會、制、式 Na、VA、VC、VE、VG 邀請賽、責任制 
 
本研究先對目前所收錄的 148 個常見詞綴建出一個綴詞表，之後在 word lattice 上透過查表方式查
詢哪些詞彙可構回綴詞，此時將會產生新的辨識路徑，而後將重新計算該詞與前後詞彙間的機率。我
們依 148 個常見詞綴各自分為 148 個類別，將具有相同詞綴的新詞放置同一類別中，綴詞則依據其詞
綴代表的類別做取代，最後透過一般詞與類別間的機率與在其類別內出現長詞之機率，藉由這兩種外
部機率(Inter-word probability)和內部機率(Intra-word probability)來重新配置語言模型分數。原先 tri-gram
的機率預估式如下式(4)所示，bi-gram 與 uni-gram 類推之： 
1 2 1 1 2
3
( ) ( ) ( | ) ( | , )
N
i i i
i
P W P w P w w P w w w 

             (4) 
利用下式(5)將重新計算綴詞語言模型分數： 
2 1
2 1
2 1
( | ) ( | )  if  
( | )
( | ) 1                 otherwise 
n n n n n n
n n n
n n n
P C W W P W C W MD
P W W W
P W W W
 
 
 
   
       (5) 
以下我們將深入探討這兩種外部機率和內部機率的計算方式： 
A. 外部機率(Inter-word probability)的預估： 2 1( | )n n nP C W W   
我們將綴詞依據其詞綴將之以其代表的類別標記，透過統計類別與前後詞彙的關聯性，採用
tri-gram 模型預估之，可得到所有詞彙的機率值，包括如：詞與類別之間、類別與類別之間、詞與詞之
間的 class tri-gram 機率，如下式(6)所示。 
2 1 1 2
2 1 2
2 1 1
2 1
2 1
2 1 1 2
2 1 2
( | )  if  , ,
( | )  if  ,
( | )  if  ,
( | )  if  
 ( | )
( | )  if  ,
( | )  if  
( |
n n n n n n
n n n n n
n n n n n
n n n n
n n n
n n n n n
n n n n
n
P C C C W W W MD
P C C W W W MD
P C W C W W MD
P C W W W MD
P W W W
P W C C W W MD
P W C W W MD
P W
   
  
  
 
 
   
  



 

2 1 1
2 1
)  if  
( | )  otherwise
n n n
n n n
W C W MD
P W W W
  
 
          
(6) 
B. 內部機率(Intra-word probability)的預估： ( | )n nP W C  
 統計綴詞出現在該所屬類別內出現的機率，採用 uni-gram 模型預估之，搭配 good-turing smoothing 
作為此內部機率，若為高詞頻的綴詞與一般詞情況下，則此內部機率為 1，如下式(7)所示。 
( | )  if  
( | )=
      1          otherwise
n n n
n n
P W C W MD
P W C
             
(7) 
圖五為此階層式系統的整體架構，首先第一級中先利用文字規則特性找出綴詞的文字規則並依據
 12
第一級語言模型 3 109.126 117.099 
 
針對傳統式語言模型與第一級語言模型產生的 word lattice 進行分析，統計在理想最佳路徑上有多
少數量可以辨識回原先的綴詞，並加以計算其涵蓋率。 
表十二：word lattice 上綴詞涵蓋率 
語言模型 TCC300 最佳路徑 涵蓋率 
傳統式語言模型 309 298 96.44% 
第一級語言模型 309 304 98.38% 
 
以下我們比較傳統式語言模型與階層式語言模型之辨識效能，分別以詞、字元、音節為辨識單元
來評估其辨識效能，並由第一級語言模型產生出來的 word lattice 觀察詞、字及音節之涵蓋率。由表十
四可看出使用使用傳統 trigram LM 詞辨認率達到 86%，這是因為我們對文字語料庫做了許多修正使得
LM 變得有效率，而階層式 LM 可以進一步提升詞辨認率。表十四顯示階層式 LM 的字辨認率也有提
升，但表十五則顯示階層式 LM 之基本音節辨認率稍微降低。表十六顯示 word lattice 之詞、字及音節
的涵蓋率，它代表辨認率的上限。 
表十三：搭配語言模型之詞辨認率 
 Deletion Substitution Insertion Accuracy (%) 
傳統式語言模型 269 1531 364 86.00% 
階層式語言模型 283 1505 355 86.14% 
 
表十四：搭配語言模型之字元辨認率 
 Deletion Substitution Insertion Accuracy (%) 
傳統式語言模型 206 2453 138 89.44% 
階層式語言模型 220 2435 129 89.49% 
 
表十五：搭配語言模型之音節辨認率 
 Deletion Substitution Insertion Accuracy (%) 
傳統式語言模型 212 1705 145 92.21% 
階層式語言模型 226 1714 137 92.16% 
 
表十六：word lattice 之詞、字及音節涵蓋率 
詞(word) 93.79% 
字(character) 93.72% 
音節(syllable) 94.51% 
 
在辨識結果中對綴詞進行分析，觀察傳統式做法與本研究所提出之方法對於綴詞在辨認上的影響
並進行說明，在此將對辨認結果分成三種不同情況來進行討論： 
    Case A：正確答案應為綴詞，但辨識結果錯誤的部分。  
Case B：正確答案不為綴詞，但辨識結果判斷成綴詞的部分。 
Case C：辨識答案辨認出正確答案的部分。 
表十七：綴詞辨識分析 
 Case A Case B Case C
傳統式語言模型 27 6 282 
階層式語言模型 8 12 301 
 14
表上層韻律單元的 syllable pitch level, syllable duration, and syllable energy level 變化，換言之，利用 break 
type 以及 prosodic state 便可以表示韻律架構之變化，本研究採用之韻律架構為由中研院鄭秋豫博士所
提出之 HPG [1]進而修改之架構（如圖七所示），其中 B4、B3 以及 B2 分別代表 BG/PG、PPh 以及 PW
的邊界，B1 和 B0 分別代表 normal syllabic 邊界及連音邊界，B2 進而分成三個類別：B2-1, B2-2 及 B2-3
分別代表 pitch reset, short pause, and lengthening 之 PW 邊界。 
 
 
圖七：中文語音階層式韻律結構示意圖 
 
在 Prosody-assisted ASR 實驗中，我們採用六萬詞辭典，選取方式為自動由文字語料中抽取前六萬
筆高頻詞， HPM model 則由 TCC300 的訓練語料中取出一部分來產生。表十八為 baseline 系統(trigram 
LM)與分別加入 6 個 break-related sub-models，以及完整 HPM 的 12 個 sub-models 所獲得的辨認結果。
由表中可發現韻律資訊的確能達到可觀的效果，和 Baseline 系統比較詞/字/基本音節的錯誤率分別改
進了 4.1%, 4.04%, 2.44%，以相對錯誤率降低(relative error reduction)來看，分別改進了 16.9%, 22.6%, 
20.6%，這是目前我們所知使用韻律信息幫助語音辨認最好的結果。表十九顯示聲調辨認結果，Precision, 
Recall, 及 F-Measure 都有大幅改進，達到 92.11%, 92.07%, 及 92.09%。 
 
表十八：PA-ASR 之辨認結果 
 詞辨認率 字辨認率 基本音節辨認率 
帶聲調音
節辨認率 
Baseline 75.78% 82.11% 88.18% 83.99% 
+Prosodic 
break 79.00% 85.29% 89.88% 86.99% 
+Prosodic 
break 
+Prosodic 
state 
79.88% 86.15% 90.62% 88.06% 
 
表十九：聲調辨認率 
 Precision Recall F-Measure 
Baseline 88.00% 87.66% 87.83% 
+Prosodic break 90.98% 90.58% 90.78% 
+Prosodic break 
+Prosodic state 92.11% 92.07% 92.09% 
 
 
3.4 考慮語速影響之中文語音辨認 
本研究考慮語速對中文語音辨認之影響，傳統上使用兩種 approaches，一是對快和慢的語料和正
常語速之語料分開，個別建立聲學模型，在使用於語音辨認中，另一作法是產生 multi-pronunciation 
network for words，讓速度快及慢的 word 使用不同的發音網路結構。本研究則採用不同的 approach，
先考量語速對韻律的影響來產生一個語速相依韻律模型，再來考量語速相依韻律模型對語音辨認的影
響。 
 16
 22 2 2( )pd SR a SR b SR c                (13) 
及 
 23 3 3( )pd SR a SR b SR c               (14) 
為語速控制的停頓長度平滑平均值和標準差； pdg 和 pdg 分別為訓練韻律模型時所統計出的停頓長度伽
瑪分佈的參數平均值。 
C. 音節音高軌跡之語速正規化 
首先針對不同語者做 frame-based normalization 以消除不同語者先天發音上的差異，其正規化數學
式如(3.24)式所示： 
( ) ( )( )  
( )
fsp
fsp fspn
n g gfsp
fsp k kfsp k
k
  
   
          
(15) 
其中 k 為 speaker index， nfsp 表示第 n 個音框的原始基頻對數值； nfsp 表示第 n 個音框做完 frame-based 
normalization 的基頻對數值； fspg 和 fspg 分別為訓練韻律模型時所統計出的結果，代表所有語料庫的基
頻對數值之總體平均值與平均標準差， fsp 和 fsp 分別為第 k 個語者基頻對數值的平均值和標準差。 
接著再針對音節基頻軌跡進行正交展開(orthogonal expansion)，投影到四個 Legendre 多項式基底，
用所得到的四維正交參數 0 1 2 3   Tn n n n na a a a   sp 表示其基頻軌跡，第一維正交參數代表此基頻軌跡的平均
值，後三維正交參數則用來描述此基頻軌跡分佈。由於基頻軌跡分佈相對於聲調不同而有相異性 ，故
我們在此將基頻軌跡依據不同聲調做正規化動作，其正規化數學式如(3.25)式所示： 
( ) ( ( ), , )( ) ( , ) ( , )
( ( ), , )
sp
sp spn n
n g n g nsp
n
sp i SR k t isp i t i t i
SR k t i
  
   
        
(16) 
其中 1 ~ 5t  表示聲調類型； 1 ~ 4i  表示維度； nsp 表示語速正規化後的第 i 維基頻軌跡參數； 
4 4( ( ), , ) ( , ) ( , )
sp SR k t i b t i SR c t i   
            
(17) 
和 
5 5( ( ), , ) ( , ) ( , )
sp SR k t i b t i SR c t i   
             
(18)
  為語速控制的聲調及維度相依的基頻軌跡參數的平滑平均值和標準差； spg 和 spg 分別為訓練韻律模型
時所統計出的結果，代表所有語料庫中四維正交參數之總體平均值與平均標準差。 
D. 音節能量強度之語速正規化 
 18
在第二個 stage 開始之後，加入的韻律模型及 joint syntax model 種類高達 16 種之多，為了瞭解每
個模型對於辨識系統的影響力，本研究將針對 the second stage 再細分成三個小階段，逐次加入模型資
訊並觀察實驗結果，其詳細流程圖如下所示： 
 
 
圖八：辨認器第二級三階段實作流程圖 
A.  第一階段：加入多種語言資訊 
如圖八所示，辨認器第二級第一階段是引入多種語言參數資訊(POS 及 PM)，在這裡需要加入的模
型為 joint syntax model，此時在 word lattice 上每個 node 所帶有的 word 資訊會根據 factored POS model
找出其最佳對應的詞性(POS)，搭配 4 種標點符號標記(PM)；無標點符號(NONE)、頓號(DOT)、逗號
(COM)、句點或驚嘆號等具有句子結束意義的標點符號(OTH)，將 node 部分展開成 4 倍；其 arc 部分
則展開為 4*4=16 倍。在此階段辨識結果將會解碼出多種語言參數，如詞(word)、詞性(POS)及標點符
號(PM)。 
B.  第二階段：加入韻律邊界停頓資訊 
第二個階段我們主要是引入韻律邊界停頓的資訊，要加入的韻律模型分別是 break syntax model 及
停頓聲學模型，由於韻律基本單元為音節，針對 word lattice 上各個 node，觀察其 arc 中所帶有的 word
資訊中最後一個音節長度做展開，也就是 interword syllable 部份，至於 word 中第一個音節長度資訊部
分，因為此階段做重新評分時，其方式採用 backward viterbi search 的緣故，利用資訊傳遞的特性，已
經存入下一個 word 中第一個音節長度資訊，故不需對此做展開的動作。 
 20
其中 1( ,..., )trM   代表各種模型 jP 分數組合時的權重； ( )C  代表正規化因子(normalization factor)。
依據 decision error rate，我們要從 discriminant function 找出一組最佳的權重Λ，而且 1 1( | )S TP w x 可拆成
M 個不同模型，故(23)式將改寫成下式：  
' '
1 1 1 1 1 1 1
1
( , , ' ) (log ( | ) log ( ' | ))
M
T S S S T S T
j j j
j
g x w w P w x P w x

 
        
(25) 
最後將定義一個 smooth misclassification function 0( , , )n nx k  ，搭配 Generalized Probabilistic Descent 
(GDP) algorithm[14]求出各種模型的權重值Λ，首先針對會使用到的符號作些定義： 
定義一：詞串 1Sw 表示為 class k；而每個句子 1Tx 表示為特徵參數向量 x。 
定義二：訓練資料表示為 ( , ), 1,..., , 0,..., ,n nrx k n N r K  其中 N 代表句子數目； 0nk 代表特徵參數向量 nx
的標準答案； , 1,...,nrk r K 互為彼此的競爭者，意即 K-best 序列。 
定義三： 0( , )nr nLD k k 代表 Levenshtein-distance，意即 hypothesis nrk 的錯誤數量，錯誤包含插入性、
刪除性、取代性等。 
定義四：訓練語料(或 held-out data)的 smoothed empirical error rate ( )L  為： 
0
1
1( ) ( , , )
N
n n
n
L x k
N 
  
              
(26) 
其中 
 
 
{ } 0
0
{ }
|
( , ) log
|1
0
1
1( , , ) 1
B
n n
nr n
nr n
p k x
LD k kK
p k x
n n
r
x k A e
K





      

        
         (27) 
A 0,  B 0,  and 0   . 最後利用下面的遞迴架構即可求出權重值 j ：
 
For  =1,...,j M   
(0) 1j   
 
 
 
0
( )
0
( )
( 1) ( ) ( ) ( )
0 0
1
( , )
0
0 { }
1
( , )
{ }
1
( , , ) 1 ( , , )
( | )
( , ) log |
( | )
|
nr n
I
nr n
I
N
I I I I
j j n n n n
n
LD k k
K
j n n
nr n nr n
r j nr n
K LD k k
nr n
r
x k x k
p k x
LD k k p k x
p k x
p k x


  





     
        
  



 
      (28) 
 
( 1) ( 1) ( 1)
1( ,..., )
I I I tr
M                   (29) 
 22
之韻律停頓對其造成的影響。訓練時文本(text)由音節層級(syllable level)展開至音素層級(phone level)
的方式將如圖九所示，僅位於音節邊界的音素會受到相鄰之韻律停頓的影響。 
 
圖九：訓練過程文本由音節層級展開至音素層級示意圖 
 
short pause(sp)的 HMM 將依照 break type 個別訓練，分別為 sp_BT0、sp_BT1、sp_BT2 及 sp_BT3，
其結構如圖十所示。sp_BT0 採用 1 個狀態，可以跳過(skip)且不能停留(non-recurring)，以達到其
tightly-coupled 的特性；sp_BT1 採用 1 個狀態，可以跳過且可以停留，以達到其不停頓或有極短暫停
頓的特性；sp_BT2採用 3個狀態，其第 2個狀態可以跳過且可以停留，以達到其短暫停頓的特性；sp_BT3
採用 3 個狀態，以達到其長停頓的特性。 
 
圖十：short pause models 結構示意圖。其中黑色的狀態為 null state 
 
由於訓練語料中不可能包含所有三連音素與韻律停頓之組合，加上某些組合出現的次數過少，其
資料並不可靠，因此採用分類回歸決策樹(Classification and Regression Trees, CART)做為參數分享之方
法，並使用語言學及韻律停頓相關之問題做為問題集。本研究採用的標音系統中共有 38 個音素，因此
總共有 114 顆樹。與韻律相依之聲學模型(PD-AM)的訓練流程如圖十一所示。 
 24
加速辨認的時間。 
若進一步觀察，可發現前三層沒有出現韻律相關問題的模型為: 
1. 母音的第 1 個狀態。 
2. 子音的第 2 個狀態。 
3. 子音的第 3 個狀態。 
而這也非常符合我們的認知，音節中間的狀態的確較不容易受到韻律停頓的影響，這也是為什麼我們
僅在音節邊界時有考慮運停頓的影響。 
進一步分析，在所有的決策樹中，每顆樹的前 1/3 問題與韻律停頓相關的以 BT3 最多，如表二十
四所示。由於明顯的停頓可區分連音效應，而連音效應對於發音聲學參數又有的極大的影響，因此與
BT3 相關的韻律問題出現較多次也是合理的。 
 
表二十四：音素單元決策樹其前 1/3 問題中，與韻律停頓相關之問題的數量統計 
                             韻律停頓 BT0 BT1 BT2 BT3 
數量 6 32 6 99 
 
B. 不同韻律停頓對 MFCC 造成之影響 
由前一節的分析得知，不僅韻律停頓確實會影響頻譜，不同的韻律停頓對頻譜也會有不同的影
響。根據表二十四的分析，足見 BT3 對於發音聲學參數造成的影響更為明顯，因此若將相同的 tri-phone
在 BT3 和其他韻律停頓下的 MFCC 分布畫出，應該也可看出受到 BT3 影響的 MFCC 分布會與受到其
他韻律停頓影響的分布不同。 
為了驗證此想法，首先利用訓練好的 PD-AM 對訓練語料做強制對齊(forced-alignment)，並抽出我
們欲觀察模型的 MFCC。在此將以 a-ng+d 第 3 個狀態其 MFCC 為例子，因為其模型在決策樹的結構中
與 BT3 相關的問題出現在第二層，說明 BT3 對其發音聲學參數的影響很大。將 a-ng+d 第 3 個狀態其
MFCC 分為兩組，一組為受到 BT3 的影響，一組為受到其他韻律停頓的影響，接著將其 MFCC 的第一
維及第二維畫出，如圖十二所示。 
 
圖十二：a-ng+d 第 3 個狀態在 BT3 和其他韻律停頓條件下其 MFCC 之分布。圓形空心的點為受 BT3
影響之 MFCC；星狀實心的點為受其他韻律停頓影響之 MFCC 
 26
由此圖可看出 PD-AM 在訓練的過程中其平均每個音框的 log-likelihood 演進較 PI-AM 來的好，說
明在加入韻律停頓的資訊後，PD-AM 能較 PI-AM 學到更好的模型分布。 
 
3.5.2  韻律停頓對於音節中所有音素影響之探討 
本研究認為韻律停頓對於頻譜會造成影響，且直觀的認定音節邊界之音素受到其相鄰之韻律停頓
的影響應是最為明顯的。音節內之音素，如介音，並不太會受到跨音素之韻律停頓的影響。子音及韻
尾也較不會分別受到音節後及音節前之韻律停頓的影響。然而，我們在此仍然訓練了一種聲學模型進
行了實驗以驗證我們的想法。下面將介紹此聲學模型是如何建立的，以及由決策樹分析該模型。 
 
A.  模型之建立 
在前一節中訓練的聲學模型，僅有音節邊界的音素會受到相鄰之韻律停頓的影響；在此，要建立
一個聲學模型是構成音節所有的音素皆會受到音節前、後之韻律停頓之影響。其文本由音節層級展開
至音素層級的展開的方式將如圖十四所示，接著一樣照圖十一的流程來訓練。 
 
 
圖十四：訓練過程文本由音節層級展開至音素層級示意圖 
B. 模型分析 
在前一節中曾提及，在決策樹中越上層被問到的問題代表其對整體資料的分群影響越大。因此，
我們將觀察該模型以下幾點: 
1. 子音的決策樹中，其前三分之一的問題中與音節後之韻律停頓相關之個數。 
2. 韻尾的決策樹中，其前三分之一的問題中與音節前之韻律停頓相關之個數。 
3. 介音的決策樹中，其前三分之一的問題中與音節前、後之韻律停頓相關之問題個數。 
若是欲觀察的韻律停頓相關問題並沒有在訓練模型的決策樹上層就出現，則證明該韻律停頓對於
 28
yu1 第 1 個狀態 0 
yu1 第 2 個狀態 0 
yu1 第 3 個狀態 0 
 
由此證明，音素並不太會受到跨音素的韻律停頓影響，因此在建立聲學模型時，僅需使音節邊界
的音素受到相鄰之韻律停頓之影響即可。 
 
3.5.3  音節辨認之實驗結果及分析 
本研究進行大詞彙語音辨認分為兩個階段，第一階段先利用聲學模型進行音節的辨認產生音節圖
(syllable lattice)，因此本節將使用與韻律停頓相依之聲學模型(PD-AM)進行音節辨認的實驗，同時比較
其與非韻律停頓相依之聲學模型(PI-AM)的優劣，最後會評估 PD-AM 解碼出之 BT3 是否可幫助辨認句
子的邊界，以縮小辨認的搜尋網路。以下將介紹詞典(lexicon)的建立方式，說明音節辨認時的 grammar，
介紹辨認時模型的路徑如何展開以構成音節，比較 PD-AM 與 PI-AM 之音節辨認率(recognition rate)及
涵蓋率(coverage rate)，最後分析 PD-AM 解碼出之 BT3 是否可幫助辨認呼吸群組句的邊界。 
 
A. 詞典之建立 
詞典包含了中文的 411 個音節，及其對應的音素序列(phone sequence)，並針對四種韻律停頓做展
開，使辨認的結果能輸出每個音節後的韻律停頓資訊。展開後的詞典共有 1644 個辨認單元。表二十八
以兩個音節做為詞典建立的範例。  
表二十八：詞典建立之範例 
詞典單元(SYL_BT)   P1 P2 P3 P4 
yin_BT0 yi e en_BT0  
yin_BT1 yi e en_BT1  
yin_BT2 yi e en_BT2  
yin_BT3 yi e en_BT3  
bian_BT0 b yi a en_BT0 
bian_BT1 b yi a en_BT1 
bian_BT2 b yi a en_BT2 
bian_BT3 b yi a en_BT3 
...
 
B. Grammar 設計 
當人在說話時，為了保持語音之流暢性，音節間的韻律停頓其出現機率是不相等的，例如連續出
現兩個音節其後皆為長停頓(BT3)的可能性極低，因此在辨認時，應把韻律停頓相接之機率考量近來，
刪除一些機率較低的路徑，縮小辨認的空間。藉由訓練語料中 PLM 標記出之韻律停頓，統計出韻律停
頓相接之機率，以 bi-gram 的方式結合至辨認的網路中，如圖十五所示。 
1( | )n nP BT BT 
 
 30
xian  8.43% 166 
ling  10.39% 77 
ming  10.00% 80 
wang  7.62% 105 
yue   9.72% 72 
由此表可看出，辨識率改善較多之音節不乏含鼻音韻尾及爆破音之音節，而這也符合語言學上的
知識。因為在發鼻音韻尾時，若其後沒有停頓會破壞其發音方式；而在發爆破音時，因嘴唇需先緊閉，
前面也需要停頓。因此，在加入韻律停頓後，能將訓練語料中之鼻音韻尾或爆破音有效區分有無停頓
的兩群，使其不互相汙染，進而訓練出較好的聲學模型，改善辨識率。 
此外，我們也比較的 PD-AM 和 PI-AM 在不同的音節圖大小下(以 arc 的數量計算)的音節涵蓋率，
如圖十六。由圖可看出， PD-AM 仍略優於 PI-AM。 
 
圖十六：PD-AM 與 PI-AM 在不同的音節圖大小下，音節涵蓋率之比較 
雖然整體的效能是有改善的，但其幅度並不大。由決策樹之分析中，可發現出現在上層之韻律停
頓問題以 BT3 為主，其餘之韻律停頓對於頻譜之影響似乎並不明顯。這可能是 PLM 標記出之韻律停
頓在同一類別中仍有少部分是 outlier，如標記為 BT1 的仍有少部分的停頓時間過長，標記為 BT2 的有
少部分的停頓時間過短，甚至是不可察覺之停頓，使模型在訓練時產生混淆。也有可能是停頓不明顯
之韻律停頓對頻譜的影響幾乎是相同的，在訓練模型時，只需將其標記為 BT3 和非 BT3 的兩群。 
 
E. 呼吸群組句邊界辨認之分析 
本研究加入韻律停頓資訊至訓練聲學模型除了期望能使聲學模型的效能變好以外，也期望其解碼
出的 BT3，能幫助判斷何處為句子的邊界，縮小辨認的搜尋空間。因此在本節中，將會討論 PD-AM 在
進行音節辨認時，所解碼出的 BT3 是否能幫助辨認呼吸群組句的邊界。 
假設以停頓時間超過 200ms 的做為呼吸群組句的邊界，其出現數量及在這之中 PD-AM 的能解碼
出 BT3 的次數如表三十一所示。由表三十一可觀察出有 97.4%停頓時間超過 200ms 的停頓皆能解碼出
BT3，證明 PD-AM 解碼出之 BT3 的確可幫助辨認句子的邊界，可用其將長句切割成數個短句，縮小
在辨認時展開之搜尋網路。 
 
 32
 
圖十八：音節圖之 WFST 
C. 詞典 
藉由聲學模型解碼出音節圖以後，必須藉由詞典，同時搭配組合演算法將其展開成詞圖。在此，
我們將依照詞頻挑選出的六萬詞詞典，依照韻律停頓的種類展開，其中 intra-word 有三種韻律停頓，分
別為 BT0、BT1 及 BT2，inter-word 有四種韻律停頓，分別為 BT0、BT1、BT2 及 BT3。Intra-word 之
所以不將 BT3 一併展開是因為詞內不應出現長停頓，如此一來稍後在音節圖上構詞時，並不會跨過長
停頓做構詞，達到我們欲使用韻律停頓來判斷何處為詞的邊界之目的。表三十二提供一詞典建立範例。 
表三十二：以”語音”這個詞為詞典建立之範例 
詞典單元    SYL1 SYL2 
語_BT0 音_BT0 yu_BT0 yin_BT0 
語_BT0 音_BT1 yu_BT0 yin_BT1 
語_BT0 音_BT2 yu_BT0 yin_BT2 
語_BT0 音_BT3 yu_BT0 yin_BT3 
語_BT1 音_BT0 yu_BT1 yin_BT0 
 … … …
語_BT2 音_BT3 yu_BT2 yin_BT3 
接著我們將詞典轉成 WFST 之格式，圖十九為一範例。在該範例中包含了“語_BT1” ， “語_BT3” ， 
“音_BT2” ， “語_BT1 音_BT2” 及 “語_BT1 言_BT3”等五個詞。在終止狀態至起始狀態的空轉移，是
為了在音節圖上每構完一個詞後，能繼續構詞。 
0 1|0
2
3
yu_BT3:語_BT3
ε :ε
yin_BT2:εyu_BT1:語_BT1音_BT2
yu_BT1:語_BT1言_BT3 yan_BT3:ε
yin_BT2:音_BT2
yu_BT1:語_BT1
 
圖十九：詞典之 WFST 
若以圖十八為例子，其與圖十九組合之結果將如圖二十所示，轉移上的輸出字元即為能構成的
 34
聲學模型 詞辨認率 詞涵蓋率 音節涵蓋率 
PI-AM 70.01% 80.27% 94.72% 
PD-AM 70.25% 83.26% 94.85% 
 
由表三十三可發現， PD-AM 在詞的辨認率略優於 PI-AM。除了聲學模型的改善有助於其提高辨
認率以外，PD-AM 產生之音節圖會利用解碼出的韻律停頓資訊 BT3，使其無法跨過 BT3 做構詞，達
到以韻律停頓刪除音節符合構成詞典的詞但韻律不合理的搶詞狀況。表三十四列出了一些搶詞狀況的
改善範例。其中 a)為正確文本，b)為 PI-AM 之詞辨認結果，c)為 PD-AM 之詞辨認結果，包含其解碼出
之 BT3。 
 
表三十四：搶詞狀況的改善 
a) ……改良 的 新 賭法 既 不 怕 作弊…… 
b) ……大量 的 刑度 罰金 不 怕 作弊…… 
c) ……大量 的 刑度 法(BT3) 既 不 怕 作弊…… 
a) ……協助 他 防止 危險 的 外人…… 
b) ……協助 套房 此 危險 的 外人…… 
c) ……協助 他(BT3) 放置 危險 的 外人…… 
a) ……吳桐潭 兩名 要角 竟 在…… 
b) ……巫統 他倆 民謠 較勁 再…… 
c) ……不動產 兩名 要角(BT3) 竟 在…… 
a) ……選手 訓練站 但 八月…… 
b) ……選手 去年 炸彈 八月…… 
c) ……選手 去年 在(BT3) 但 八月…… 
 
此外，由表三十四也可看出，即使 PD-AM 在構詞時加入了 BT3 無法出現在詞內的限制，但其與 PI-AM
的詞涵蓋率是差不多的，足見 PD-AM 解碼出之 BT3 有一定的準確性。 
由於 PD-AM 需將詞典依照韻律停頓做展開，詞的數量過多，而受限於記憶體的大小，使 PD-AM
並無法直接結合詞典、與語言模型結合進行詞的辨認，這也是本研究採用兩階段式辨認的主要原因；
然而，PI-AM 則無此限制。若我們將 PI-AM 結合詞典及 bi-gram 的語言模型產生詞圖後，再以 tri-gram
之語言模型重新評分，其詞辨認率及涵蓋率如表三十五所示。 
表三十五：PI-AM 之一階段式詞辨認率及涵蓋率 
詞辨認率 詞涵蓋率 
76.13% 89.11% 
若將表三十三之 PD-AM 兩階段式的辨認結果與其相比，可發現 PD-AM 的詞辨認率低了 5.88%，
兩者的詞涵蓋率差了 5.85%，而這也是辨認率下降的主要原因。經檢查發現，詞涵蓋率降低的主要的
原因為： 
1. PD-AM 在進行兩階段式辨認時，僅靠聲學模型產生發音相近之音節圖，若是語者發音不清楚，單
靠聲學模型無法補救，在該時間點就無法構出該詞。PI-AM 因採用一階段式辨認，直接結合聲學
 36
聲學模型 arc 數 
PI-AM 26534 
PD-AM 980625 
     
因此，在沒有詞典及語言模型的協助下，在有限的音節圖大小下，無法展開所有可能的相近音，
若是語者發音不清楚單靠聲學模型更無法補救。此外，觀察音節圖上也可發現相鄰之時間點容易產生
出許多相同音節；在停頓不明顯的時間點上更容易出現許多有 BT0 及 BT1 的相同音節。這些因素都導
致詞的涵蓋率無法有效提高，進而降低本研究之兩階段式的詞辨認率。 
 
四、 結論與討論 
本計畫在過去三年進行了五個有關大詞彙中文語音辨認方法的探討，同時對大量中文文字語料進
行了深度分析整理，讓我們對如何在語音辨認中考慮定量複合詞/人名/詞綴構詞以改進 OOV 的辨認有
所進展，同時在使用韻律信息來協助語音辨認上有長足進步，韻律信息的使用對詞組的 discrimiantion
也有幫助，具體的成果是對詞的辨認率由大約 70%上升至 88%，這是我們所知中文語音辨認目前最好
的結果，因此本研究讓我們在極大詞彙中文語音辨認上往前邁進一大步。  
在未來研究上尚須解決的問題主要有兩個，一是大量詞組的收集，例如組織名稱、地址、時間、
成語俚語等，另一是及時辨認方法，例如 Weighted Finite State Transducer (WFST)演算法。 
 
五、 計畫成果自評 
本計畫在過去三年進行了大詞彙中文語音辨認方法的探討，以及進行了大量中文文字語料的深度
分析整理，讓我們在極大詞彙中文語音辨認上往前邁進一大步，詞的辨認率由大約 70%上升至 88%，
這是我們所知中文語音辨認目前最好的結果，因此本計畫之成果算是相當不錯。 
本計畫之研究成果發表於下列一篇國際期刊以及三篇國際會議論文，另有一個專利申請中： 
[1] Sin-Horng Chen, Jyh-Her Yang, Chen-Yu Chiang, Ming-Chieh Liu and Yih-Ru Wang, "A New 
Prosody-Assisted Mandarin ASR System,"  IEEE Trans. on Audio, Speech and Language Processing, Vol. 
20, No. 6, pp. 1669-1684, August 2012 
[2] Jyh-Her Yang, Ming-Chieh Liu, Hao-Hsiang Chang, Chen-Yu Chiang, Yih-Ru Wang, and Sin-Horng Chen, 
“Enriching mandarin speech recognition by incorporating a hierarchical prosody model,” in Proc. ICASSP 
2011, Plaque, Czech, May, 2011, pp 5052-5055. 
[3] Chen-Yu Chiang, Jyh-Her Yang, Ming-Chieh Liu, Yih-Ru Wang, Yuan-Fu Liao and Sin-Horng Chen, “A 
New Model-based Mandarin-speech Coding System,” in Proc. Interspeech 2011, Florence, Italy, Sept. 
2011, pp 2561-2564. 
[4] Tzu-Hsuan Chiu, Chen-Yu Chiang, Yuan-Fu Liao, Jyh-Her Yang, Yih-Ru Wang and Sin-Horng Chen, 
“Prosody-dependent Acoustic Modeling for Mandarin Speech Recognition,” Speech Prosody 2012, 
Shanghai, China 
 
 1
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                  日期： 101 年 10 月 21 日 
一、參加會議經過 
Interspeech 為 ISCA(International Speech Communication Association)  主 辦 的 國際會議，為語音
處理及語言處理的重要會議，於每年的 9 月左右為期一周在歐洲及世界各洲輪流舉辦。本屆已是舉辦
此會議的第 12 年，會議地點為義大利佛羅倫斯舉的 Firenze Fiera Congress & Exhibition Center，會期包
含 2011/8/27 的 Tutorial 以及 2011/8/28~2012/8/31 四天的會議議程。本人完整參加四天的議程，每天早
上第一場會議皆為世界重要學者之專題演講 (keynote speech)，依順序包含：1) 美國哥倫比亞大學
Computer Science 學系 Prof. Julia Hirschberg 的 “Speaking More Like You: Entrainment in Conversational 
Speech”、2) Pro. Tom M. Mitchell 的 “Neural Representations of Word Meanings”、3) Prof. Alex 'Sandy' 
Pentland 的 “Honest Signals”、以及 4) Round table 討論專題 “Future and Applications of Speech and 
Language Technologies for the Good Health of Society”。第一場由 Prof. Julia Hirschberg 介紹該團隊一系
列有關人與人對話中 Entrainment 現象之實驗及其語言現象之分析，包含聲學參數、韻律參數、語言參
數等各角度的廣泛分析，展現出人與人在對話中，如何造出新詞彙來表示一個新事物，同時探討對話
中的 Discourse 結構。第二場由美國 Carnegie Mellon University Computer Science 學系的 Prof. Tom M. 
Mitchell 演講有關人腦如何記憶及表示 “詞”的意義，研究方向為三部分：a)由人腦神經活動的信號來
預估人在思考哪個詞彙、b)訓練由詞彙來預估腦神經信號的產生機制、以及 c)分析人理解一個句子時
腦神經活動的信號。第三場由美國 MIT 的 Prof. Alex Pentland 討論人在一些雙向互動中(如約會、談判)，
一些較不受自主控制的現象，也就是所謂 “最誠實的信號”，這些信號不是目前語音處理中的所提到的
聲學信號，而是以必須以更大範圍時間來處理的事件，這些事件的表現為人與人溝通的 back-channel，
如：a) Influence – 在對話中，人與人的之間的說話風格、方法互相影響的程度、b) Mimicry – 在對話
計畫編號 NSC 98-2221-E-009-075-MY3 
計畫名稱 中文極大詞彙語音辨認技術之研究 
出國人員
姓名 江振宇 
服務機構
及職稱 
國立交通大學電機工程學系博士
後研究員 
會議時間 
100 年 8 月 28 日
至 
100 年 8 月 31 日 
會議地點 義大利佛羅倫斯 
會議名稱 
(中文) 2011 國際語音通訊協會年度研討會 
(英文) Interspeech 2011 
發表論文
題目 
(中文) 一個新式中文語音編碼系統 
(英文) A New Model-based Mandarin-speech Coding System 
 3
五、攜回資料名稱及內容 
會議手冊 
會議議程及論文摘要本 
會議論文集光碟：其中包含 Keynote speech 的相關論文、Oral 及 Poster 相關論文等。 
 
六、其他 
無 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳信宏 計畫編號：98-2221-E-009-075-MY3 
計畫名稱：中文極大詞彙語音辨認技術之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 6 100%  
博士生 2 2 100%  
博士後研究員 1 1 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
