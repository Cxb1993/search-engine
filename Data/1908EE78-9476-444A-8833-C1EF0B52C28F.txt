I 
 
計畫中文摘要 
關鍵詞：視覺伺服系統、視覺回授控制、影像轉換矩陣 
隨著機械與資電科技的進步，電腦視覺已成為一項熱門的研究領域，凡舉日
常生活的視訊會議與防盜監視、工業生產線的自動化視覺檢測與條碼判讀等都已
成為應用中不可缺少的一部份。電腦視覺系統特別能勝任繁複而需人工全神灌注
的工作上，對於追蹤、攔截、監督、檢測、定位與紀錄等工作特別有效率。本子
計畫完成以影像為基礎的視覺伺服系統，並已推導影像轉換矩陣(即影像速度與
機械臂終端速度的關係矩陣)來設計此系統的控制器，使用的理論基礎為最小方
根誤差以遞迴運算求出每個取樣時間內系統的影像轉換矩陣，藉由影像轉換矩陣
的收斂使得系統穩定且估算正確的控制命令。我們以里阿普諾函式(Lyapunov 
function)證明此視覺伺服系統的穩定性，並且討論系統包含不確定因素
(uncertainties)時的穩定性極限，由模擬的結果得知系統穩定性極限的數據並且以
實驗的經驗數據，來提供架設此適應性控制系統的依據。本子計畫的視覺伺服系
統主要的優點為避開繁雜的攝影機校正與推導機械臂的動態方程式，並可由即時
的影像的回授與控制法則計算出此時的機械臂控制命令(Robot Command)正確追
蹤、抓取與移動目標物到指定位置。 
 
計畫英文摘要 
Keywords: computer vision, visual sensory feedback control, Image Jacobian matrix 
As technology progress, people invent the robot to perform movement, transport, 
paint spray, welding, etc.. Those will face the same problem that is how to confirm the 
relative position between robot and object. Most solving methods is using CCD to 
orientate, shape, and outline of object. Visual servoing algorithms have been 
extensively developed in the robotics field. Visual sevro system may be divided into 
two main classes: position-based visual servo (PBVS) involves reconstruction of the 
target pose with respect to the robot and leads to a Cartesian motion planning problem. 
Image-based visual sevro (IBVS) aims to control the dynamics of features in the 
image plane directly. 
In mounting cameras, it divide into two parts . One is mounting cameras in fixed 
positions which should conform the working space of robot. Another is fixing end 
effector called eye-in hand. In this study, we adopt the first and avoid the camera 
calibration.  
In this project, we used a automatic control scheme with visual sensory feedback 
called image-based visual servo, in which the control values are the image features of 
the object.(is also called feature-based).We use a Jacobian matrix called the image 
Jacobian, which transforms the camera motion to the change of the object position in 
the image plane. Some paper use a binocular stereo vision that enables us to calculate 
an exact image Jacobian around at desired location, but in our project we do not want 
to calculate the element in the Jacobian matrix since it is time-consuming and 
miscellaneous. 
In general, people would deduce the robot dynamics in the visual system. In this 
project we substitute it with the rigid body motion of the end effector. Comparing 
with them, our system would be more simple than others. To the end, we have 
designed and built a computer-vision based system to automatically track the object 
for robot or automatically orientate for robot. 
 
 2 
coordinate systems, 
1111
ZYXC ,
2222
ZYXC and
3333
ZYXC , are denoted by  
111
,,
ccc
ZYX ,  
222
,,
ccc
ZYX  and 
 
333
,,
ccc
ZYX , respectively. According to the pin-hole model and the relationship between camera coordinate 
systems and image reference planes shown in Figure 1, the image coordinates, ),(
ii
vu , i=1, 2, 3, of a 
projected 3D point on three image planes are given by [1]: 
1
11
1
1
11
1
,
c
c
c
c
Y
Zf
v
Y
Xf
u                                    (1) 
2
22
2
2
22
2
,
c
c
c
c
X
Zf
v
X
Yf
u                                    (2) 
3
33
3
3
33
3
,
c
c
c
c
Z
Xf
v
Z
Yf
u                                    (3) 
where 
1
f , 
2
f  and 
3
f  are the focal lengths of camera 1, 2 and 3 respectively. Consider the end-effector is moving 
with an angular velocity ),,(
ZYX
  and a translational velocity ),,(
TTT
Z
dt
d
Y
dt
d
X
dt
d  relative to the base coordinate 
system. Let us assume that the target point P  with base frame coordinate ),,( ZYX  is rigidly attached to the 
end-effector within each sampling period. The derivatives of the coordinates of P  with respect to time in the base 
coordinates are given by 
YzT
ZYX
dt
d
X
dt
d
                               (4) 
ZXT
XZY
dt
d
Y
dt
d
                               (5) 
XYT
YXZ
dt
d
Z
dt
d
                               (6) 
Let ),,(
cicici
ZYX  denote the coordinates of P  in the i-th camera coordinate system, i=1, 2, 3. It is noted that the 
derivatives ),,( Z
dt
d
Y
dt
d
X
dt
d  can be replaced by ),,(
cicici
Z
dt
d
Y
dt
d
X
dt
d  since the camera coordinate systems have the same 
orientation with the world coordinate system. 
Image Jacobian Matrix 
A target and tip of the manipulator were tracked in each camera view using the tracking algorithm described in 
previous section. Let us denote with ),,(
iii
ZYX , i=1, 2, 3, three feature points on the target with respect to the base 
coordinate system. We assume each feature point 
i
P  can be seen only in the i-th camera view and its image 
coordinates and 3D coordinates relative to the i-th camera reference frame are (
i
u ,
i
v ) and ),,(
cicici
ZYX , respectively.  
The relationship of image velocities between target and end-effector, known as image Jacobian matrix, can be derived 
by taking the derivative of 
i
u  and
i
v  in equations (1)-(3) and substituting kinematics in equations (4)-(6) into the 
derivative results which is given by 

 
66
Gq               (7) 
where 
                      
 T
ZYXTTT
T
ZYX
vuvuvuq
 ,,,,,
,,,,,,
332211





                  (8) 
 4 
 
 
 
 
 
 
 
 
 
 
 
 
Figure1:The visual sevro control system 
 
 
Invers 
K inem aties
Robot 
Controller
V ision System  TT GRQ GG
T
11 


Recursive Estim ation
G
-
)(kq
robot

)(kq

)(k

 )(k

 
 
               Figure2: Block diagram of visual servoing system 
Recursive Least-Squared Estimation of Image Jacobian G(k)  
To track the target in real time, the image Jacobian matrix needs to be estimated with no delay. To avoid tedious 
camera calibration and 3D position estimation in the Jacobian matrix, we use an on-line recursive least-squares 
estimator, based on known control inputs and the tracked image features, to estimate the image Jacobian rather than 
compute it directly. To simplify the derivation, we define 
][)(
654321
ggggggkTG
T 
                          (13)  
i.e., 
i
g

, 6,,1 i , are column vectors of the transpose of matrix TG(k).  Equation (10) can be rewritten into the 
following form  
6,,1),()()()1( 

 ikgkkqkq
i
T
ii
                          (14) 
where 
i
q  is the i-th entry of vector  kq

 in equation (17), and 
i
g

, 6,,1 i , are the unknown to be estimated.  
The recursive estimate of the Jacobian matrix at time instant k can be obtained by first minimizing the following 
quadratic cost function with respect to )(kg
i

: 
     
1
2
1
0
0
( ( )) 1 / 2 ( 1) ( ) ( ) ( ) 1 / 2 ( ) (0) ( ) (0)
k
TT
i i i i i i i i
j
J g k q j q j j g j g k g P g k g



 
        
 
             (15) 
          
The above cost function represents the sum of squares of errors between the observations and predicted values, 
i.e., )()()()1( jgjjqjq
i
T
ii

 . The second term in the right-hand side of equation (15) has been 
included to take the initial conditions into account, where the weighting matrix 
0
P  is positive definite. 
Taking the derivative of equation (15) with respect to )(kg
i

 and substituting the following two forms 
 6 
where the S is a constant and positive definite matrix. Taking the derivative or difference of V we yield  
     
       
   
  )()(
)()()()(
)()()()(
11
1
kqQSGBGGGBQQSGBGSGGBQkq
kqSkqkqQGBGISGGBQIkq
kqSkqkqSAAkq
kSqkqkqSkq
kqVkqVV
TTTTTTTTT
TTTTTT
TTT
TT










            (31) 
Let us define KQGBG T   and substitute it into (31) to have 
  )()( kqSKKSKSKkqV TTT                           (32) 
It can be seen that if  
  0 SKKSKSK TT                              (33) 
which implies 0V  and ensures the system is stable. 
Now we consider a perturbed system with uncertainty G  : 
)())(()()1( kkGGkqkq                      (34) 
By substituting the control law (28) into (34) to achieve 
       
    
  )()(
)(
)(1
1
1
kqkEA
kqQGRQGGGGI
kqQGRQGGGGkqkq
TT
TT








                     (35) 
                   (34) 
where 1)(,)(  RQGGBQGBGkE TT . 
Similarly, we calculate the difference of Lyapunov function for the perturbed system 
     
)())((
1
kqSEESEASAEUkq
kqVkqVV
TTTT 



               (35) 
It can be seen that if the following condition holds 
 0 SEESEASAEU TTT  
which implies 0V  and ensures the perturbed system is stable. 
 
Experiments Using a MITSUBISHI RV-1 Manipulator 
 In our experiment, the 6-link MITSUBISHI RV-1 manipulator (Figure 3) was used to stack three toy blocks 
together and to pour water from one cup to the other. The 3D workspace of the manipulator is 
mmmmmm 110360190  . The size of rectangular log is mm200  mm50  mm50 .  The overall visual-servo 
system is shown in Figure 1. The vision system includes a personal computer (Pentium4 2.4G CPU), three CCDs 
cameras, and three NI (National Instruments) frame grabbers equipped with NI-2.6 library. All the vision and control 
routines were implemented using C++. The performance of vision algorithm in tracking 6 landmarks (three on target 
and three on end-effector) on three views is 30 frames per second. The tracking threshold for the values of correlation 
coefficient is 0.9. The focal length of each camera was initialized as 1800 and the sampling period T for the control 
system is 33.3ms. The symmetric positive-definite weighting matrices Q and R in equations were chosen as diagonal 
with identical entries 0.25 and 0.75, respectively. In our experiment, we can estimate initial ratio between (110 pixels: 
50mm) the unit of our feature and the unit of the world coordinate system. Constrains of the robot inverse 
kinematics in the experiment of stacking up the building blocks is ,180
532

  and in the experiment of 
the watering is
2 3 5
90 ~ 180     . 
Forward and Inverse Kinematics of MITSUBISHI RV-1 Manipulator 
The forward kinematics problem can be stated as follows: Given the joint variables of the robot, determine the position 
and orientation of the end-effector. On the other hand, given a desired position and orientation for the end-effector of the 
robot, the inverse kinematics problem is to determine a set of joint variables that achieve the desired position and 
orientation. The objective of forward kinematic analysis is to determine the cumulative effect of the entire set of joint 
variables. Suppose a robot has n+1 links numbered from 0 to n starting from the base of robot, which is taken as link 0. 
The joints are numbered from 1 to n, and the i-th joint is the point in space where links i and i-1 are connected. A 
coordinate frame is attached rigidly to each link where the joint is the origin of the coordinate frame. Suppose 
i
A  is the 
homogenous matrix that transforms the coordinates of a point from frame i to frame i-1. Each homogenous 
 8 
,
642365236542331
ssscsccccsR                                              (39) 
,
6416423165231654165423112
sccsscscsssccscccccsR                              (40) 
,
6416423165231654165423122
ccccscsssssccscscccsR                            (41) 
,
52315415423132
csssscsccsR                                                (42) 
,
642365236542313
ssscsccccsR                                              (43) 
,
642365236542323
cssssccccsR                                               (44) 
,
523542333
ccscsR                                                        (45) 
),()(
2223323323416523154154231
sbsbcasdcdcscsssscccp
x
                    (46) 
),()(
2223323323416523154154231
sbsbcasdsdcsssscsccsp
y
                    (47) 
12223323342365235423
)( dcbcbsadcdccscsp
z
                           (48) 
Now given the desired position and orientation for the end-effector of the robot, we need to determine a set of joint 
variables. The solution, however, is not unique without additional constrains.  In our implementation, we consider the 
following constrains  
 0,0,
4611532
  k  (49) 
where 
1
k  is a pre-specific constant. By substituting the constrain (49) into equations (37)-(47) and with some algebraic 
manipulation, we can solve for the joint variables uniquely. For example, when 
0
1
180k , we obtain  
        










x
y
p
p
1
1
t a n  





















2
31
222
2
2
2
222
34
2
31
2
tan
)(
)(
sin
k
k
Akb
bAkbda

,  










))()(())()((
))()(())()((
tan
22234232223423
234232223423221
3
cbAcbdsasbksbdca
sbdcacbAcbdsasbk
  
)(
22233233234161
sbsbcasdcondcp
x
  
)(
22233233234161
sbsbcasdcondsp
y
  
12223323342326
dcbcbsadccondp
z
   
where, 
222332332342
sbsbcasdk  , and 
163
ddpk
z
 . 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: MITSUBISHI RV-1                  Figure 4: Link coordinates 
 10 
 
 
 
 
 
 
 
 
Figure 6: Stacking up building blocks 
 
Pouring the Water from one Cup to the other 
This experiment was to control the manipulator for picking up a cup and pouring the water from it into 
the other.  The locations of three cameras in the world coordinates were (0, -190, 40), (145, 0, 40) and (40, 0, 
145), respectively. The initial location of end-effector was (30, 0, 38).   Figures 7, 8 and 9 demonstrate the 
consecutive images from three camera views. This task has been repeated several times with different initials 
in which satisfactory results were obtained.  
 
Figure7: Consecutive views from camera one 
 
Figure 8: Consecutive views from camera two 
 
Figure 9: Consecutive views from camera three 
 
Conclusion 
This project has developed a visual feedback real time adaptive control system which directly employed 
the image information to guide the robot motion. The controller was devised based on the visual Jacobin 
matrix that was estimated recursively on-line. It has been proved by Lyapunov method and demonstrated in 
our experiments that the trajectory of the manipulator can converge to the specified location. Our experiments 
have indicated that the relative position and orientation between the end-effect of robot arm and the target 
were within 1-2 pixels. The sampling period of visual servoing was about 33msec for recursive image 
Jacobian and calculating robot command. Experiments on MITSUBISHI RV-1 manipulator have 
demonstrated the effectiveness of proposed method. 
 
References 
[1]. S. Hutchinson, G. D. Hager, and P. I. Corke, “A tutorial on visual servo control,” IEEE Trans. Robot. 
Automation, vol. 12, no. 5, pp. 651-670, Oct. 1996. 
[2]. L. Sciavicco, and B. Sicilliano, “Modeling and control of robot manipulators,” McGraw-Hill Companies, 
Inc. 1996. 
[3]. N. P. Papanikolopoulos, P. K. Khosla, and T. Kanade, “Visual Tracking of a Moving Traget by a Camera 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■  達成目標 
□  未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
    視覺伺服控制是利用視覺所得到的影像資訊進而控制機械臂達到期望的
位置上，一個良好的視覺伺服控制架構所牽涉的涵蓋高速影像處理架構、機
械的運動與動力學、控制理論與即時運算…等部分。本計畫採用影像為基礎
的視覺回授控制架構，將視覺回授能力加入機械臂系統，其具有 3D軌跡追蹤
能力，本系統建構的立體視覺不需對攝影機建立精確模型，可避免繁瑣的攝
影機校正工作。藉由此視覺伺服控制系統，在未來希望可以幫助病人完成如
拿取物品、遞茶倒水、翻身、餵食或是擦洗…等十分複雜具不容易定位之動
作。本計畫之研究成果，已發表於 2011 年 International Conference on Service 
and Interactive Robotics(SIRCon)。 
 
 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：吳育德 計畫編號：99-2221-E-010-014- 
計畫名稱：腦波導引自走式看護系統設計與實現--子計畫一：腦波導引自走式看護系統之視覺伺服系
統設計與實現 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 100% 撰寫中 
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 0 100%  
博士生 2 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 0 100%  
博士生 2 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
