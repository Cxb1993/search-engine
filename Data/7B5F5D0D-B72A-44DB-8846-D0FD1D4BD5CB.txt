 2
 
行政院國家科學委員會專題研究計畫成果報告 
 
計算智慧研究應用於多媒體浮水印、多媒體檢索與 cDNA 微陣列影像濾波器並
實現其行動網路服務系統 
A study of computational intelligence for multimedia watermarking, multimedia 
retrieval, and cDNA microarray image filter and realize them with mobile web 
services 
 
計畫編號：NSC 96-2221-E-150-062 
執行期限：96 年 8 月 1 日至 97 年 7 月 31 日 
計畫主持人：蔡鴻旭教授 國立虎尾科技大學 資訊管理系 
共同主持人：游寶達教授 國立中正大學 資訊工程系 
 
一、中文摘要 
 
在本計畫中延續 95 年研究成果，共獲
得五項令人滿意的研究成果。在第一項研
究成果是設計無失真智慧型影像浮水印技
術，主要利用 alpha-trimmed filter 及
SVM，即利用 SVM 記住 owner copyright
與 image features 之間關係，不需修改原
圖。使得影像浮水印技術 transparency 目
標可完全達成，同時也兼顧 robustness to 
attacks。另外，第二項研究結果研發
content-based image retrieval (CBIR) 技
術。第三項研究成果是研發混合式決策型
的影像濾器(A median-based image filter 
with adaptive hybrid detectors for impulse 
noise)，第四項是利用網路服務技術實現上
述的影像浮水印系統，達到網路資源共
享，快速系統整合及分散式計算環境建
置。共有 1 篇論文已投稿於國際期刊論文
[3]，2 篇已發表於國際會議論文[4]-[5]及 2
篇已發表於國內會議論文[6,7]，  
 
關鍵詞：影像處理、影像濾波器、資料隱
藏，無失真浮水印，浮水印，軟式計算，
類神經網路，模糊推論系統，適性能力，
韌性能力，推廣能力，小波理論，支援向
量器，網路服務，人類視覺系統、分散式
計算。 
 
Abstract: 
 
Four main parts of research results are 
presented in this report. First, we developed 
a lossless watermarking method, based on 
alpha-trimmed filtering and support vector 
machines, for image protection. It does not 
modify original images. Experimental 
results demonstrate that the proposed 
technique not only possesses adaptive and 
robust capabilities to resist on 
image-manipulation attacks under 
consideration but also is superior to other 
existing methods. Second, a color-based 
CBIR technique has been proposed. A set of 
features were extracted on HVS domain. 
K-means is employed in the design of the 
technique to reduce searching computational 
complexity. Third, A median-based image 
filter with adaptive hybrid detectors for 
impulse noise, which can restore images 
corrupted by impulse noises. The filter first 
detects whether the pixels in a slide window 
are corrupted by impulse noises or not. The 
filter then output the result of the median 
filter if pixles are corrupted. Otherwise, the 
center pixel of the window is unchanged and 
 4
程式資源共享及快速系統整合。 
 
三、研究方法及成果 
令 X=[xij]M× N 表示一個 M×N 灰階影
像，xij∈{0, 1,…, 255}表示一個位於(i, j)的
灰階像素值。X 可被分割為許多 3×3 的區
塊集合 S。令 S={Xij}，每個區塊 Xij之中心
像素為 xij，Xij表示如下： 
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
+++−+
+−
+−−−−
1,1,11,1
1,1,
1,1,11,1
jijiji
jiijji
jijiji
ij
xxx
xxx
xxx
X
       (1) 
本計畫的第一個研究成果延續 95 年
的研究成果，提出 a lossless watermarking
稱 SVMLIW 技術，其共有下列幾個特點： 
1. 不需修改到受保護的影像，因此影像
品質並沒有任何降低。 
2. 在抽取使用者簽章時，不需使用到原
始影像。 
3. 可額外承載使用者的簽章。 
4. 高承載資訊能力。 
圖 1 為 SVMLIW 技術設計概念。圖 2 為
藏入使用者簽章之流程圖，其中，特徵選
擇 (feature selection) 中，將上個步驟所求
得的特徵值
k
U ρ ，判斷這些特徵值的關係
比，來得到由影像產生的浮水印 OW 。對
於一個 64 × 64 的區塊在 4 階小波轉換
後，其 r1、 r2、r3 和 r4 分別等於 31、15、
7、 3。接著將每個
k
b ρ' Block 中 4 個低頻
區的 1,,' lkU ρ 分別利用 α-trimmed mean 取得
其特徵值 lkF ,' 如下表示 
)'(' 1,,, llk kUtrimmedF ρα −=  
for l=1, …,4 and k=1, …, m 
(2) 
在取得所有特徵值 lkF ,' 後之集合ξ' (3)
後，再利用定義(4)的方程式來產生原始影
像不變量之特徵。 
},,1 and,,4,,1
),1(4|''{' ,
mkl
kltF lkt
LL ==
−+=== ξξ  (3) 
 
IF htt >− +1'' ξξ  then ftw' = 1 else 
f
tw' = -1. 
(4) 
接著將當初所用的 seeds(S2 = (s21, s22))輸
入至 PRNG 來亂數產生序列，將影像特徵
浮水印Ξ'重新排列其位置後，再將影像特
徵浮水印Ξ'輸入至 TPC，上述方法如圖
3-4。在 TPC 階段是利用之前所產生的Γ'
集合來挑選影像特徵區塊的位置，接著將
挑選到影像特徵區塊當成一筆支向量機測
試資料的特徵如此便可完成一筆訓練資
料，如圖 5。而在完成 TPC 階段後便可得
到訓練集合Φ'。即可造成完整的支向量機
所需的訓練樣本，定義如下 
Φ' = ( ){ }4096,...,2,1|, =kDT
kk swsw  (3) 
其中 
( )kmkksw tttT k ,,, 21 K=  
( )kmkksw dddD k ,,, 21 K=  (4) 
在圖 6 中說明浮水印抽出的流程。將可能
受到破壞的後影像 X′輸入至系統，一樣使
用種子 S2 = (s21, s22)來得來當初所挑選的
特徵值區塊
k
bρ′ ，並將這些區塊經過四階離
散小波轉換得到
k
Bρ′ ，以特徵挑選演算法
來產生浮水印 OW 。接著利用 TPC 來產生
支向量機所需的輸入樣本
kswT ′ ，再利用已
訓練的支向量則可用來估計出 Ŵc。把 Ŵc
及 OW 做互斥或，即可估計出原本使用者
的簽章 Ŵ。故本方法在抽取使用者簽章
時，不需額外儲存載體資訊 CW 。實驗時
利用 20 張影像來測試 SVMLIW 技術效
能，由圖 7 表所有實驗攻擊，圖 8-9 說明
SVMLIW 技術效能確實優於其他技術，圖
10-11 說明 SVMLIW 技術確實能將收集到
的受攻擊樣本(含 error bits)有效地還原為
正確值。 
本 計 畫 的 第 二 個 研 究 成 果 研 發
content-based image retrieval (CBIR) 技
術，應用 HSV 分割法與 K-means 於影像
檢索，本技術之架構如圖 12，影像特徵擷
取部分，使用 HSV 切割方法，將色相的範
圍量化成 8 等分，飽和度的範圍量化成 4
等分，亮度的範圍量化成 4 等分，換言之
每個色相的單位範圍是 360÷8=45，飽和度
與亮度的單位範圍是 1÷4=0.25，整體 HSV
共會有 128 種排列組合。使用的 HSV 分割
參數皆不盡相同，例如 H=18、 S=3、V=3，
H=8、S=4、V=4 等等，依據以上參數分割
結果，H=8、S=4、V=4 的分割結果以人類
 6
(EI) NSC 96-2221-E-150-062 
[5]  H.-H. Tsai, H.-C. Tseng and Y.-S. Lai, "Lossless 
watermarking based on alpha-trimmed mean 
algorithm and SVM," 2008 IEEE World 
Congress on Computational Intelligence (WCCI 
2008), Workshop on Applications of 
Computational Intelligence to Benefit Society, 
Hong-Kong, 1-7 June, 2008. (EI) (NSC 
96-2221-E-150-062) 
[6]  陳維凱,蔡鴻旭, "應用 HSV 分割法與 K-means
於 影 像 檢 索 , " the 19th Workshop on 
Object-Oriented Technology and Applications 
(2008 OOTA), 國立虎尾科技大學, 26th Sept.  
[7]  蔡鴻旭, 林軒平, "基於脈衝雜訊偵測之混合型
影像濾波器," 2008 第四屆網際網路暨通訊科
技研討會, 聖約翰科技大學, Taiwan, April 16, 
2008. 
[8]  H.-H. Tsai and K.-C. Wang, "Wavelet-domain 
image watermarking based on rank order and 
classification approach optimized by genetic 
algorithm," Imaging Science Journal, vol. 56, no. 
16, pp. 201-216, Aug. 2008. (SCI, EI) NSC 
94-2213-E-150 -029. NSC 93-2213-E-150-009 
[9]  H.-H. Tsai, "Decision-based hybrid image 
watermarking in wavelet domain using HVS and 
neural networks," ISNN 2007, Nanjing, China, 
June 3-7, 2007, Proceedings, Part III. Lecture 
Notes in Computer Science 4493 Springer 2007, 
ISBN 978-3-540-72394-3. (EI) NSC 
95-2221-E-150-084 
[10] H.-H. Tsai, H.-C. Tseng, C.-C. Liu, "A lossless 
image watermarking using support vector 
machine," the 17th Information Security 
Conference, ISC2007, Chiayi, National Chiayi 
University, June 7-8, 2007. (NSC 
95-2221-E-150-084) 
[11] H.-H. Tsai, C.-C. Liu, and K.-C. Wang, "Blind 
Wavelet-based Image Watermarking Based on 
HVS and Neural Networks," the 7th 
International Conference on Computer Vision, 
Pattern Recognition and Image Processing, 
Kaohsiung, Taiwan, ROC, October 9-11, 2006 
(EI) NSC 94-2213-E-150 -029 
[12] H.-H. Tsai, K.-C. Kao, and C.-C. Liu, "Robust 
watermarking in wavelet domain using rank 
order and genetic algorithm for image 
authorization," the 2006 International Joint 
Conference on Neural Networks (IJCNN 2006), 
Vancouver, BC, Canada, July 16-21, 2006. (EI) 
NSC 94-2213-E-150 -029 
 
 
original image 
feature 
selection 
 
owner's 
signature 
 
protected image
 
image-dependent 
watermark 
watermark 
embedding 
feature 
selection 
KEY 
watermark 
extraction 
 
extracted  
owner's signature  
圖 1：SVMLIW 技術之架構。 
Φ
ξ
owner's signature 
original image 
X 
DWT 
W 
seeds: ),( 12111 ss=s  PRNG
α-trimmed 
mean 
kw  
SVM 
BS
kρ
kBρ
kbρ
TPC 
f
tw
seeds: ),( 22212 ss=s  
FS 
PRNG
 
圖 2：藏入使用者簽章之流程圖。 
-1 1 1 … 1 1 1 1 1 -1 1 -1 -1 1 1 … -1
1 1 -1 … -1 1 1 -1 1 -1 1 1 -1 1 1 … 1
sliding window 
mapping 
carried information WC 
image-dependent watermark 
 
圖 3：利用 sliding windows 產生訓練樣本 
IF 1+> tt ξξ and htt >− +1ξξ  then  O ikw , = 1 else O ikw , = -1.
 
 
 
 
。。。。。。。。。。。。。。。。。。。。。。。。。。。。  100200 1290 5133 6033785838165
。。。。。。。。。。。。。。。。。。。。。。。。。。。。  -11 -11 11 -1-11-111  
圖 4：產生影像特徵資訊 
1 -1 1 1 1 -1 1 1 1 
          
1 1 1 -1 1 1 -1 1 1 -1
-1 -1 -1 1 -1 1 -1 -1 -1 -1
          
kw kT
 
kT
v
v
kw
image-dependent watermark Ξ 
owner  signature 
training pattern 
W
training pattern k 
training pattern k+1 
SVM 
 
圖 5：製造訓練資料樣本示意圖 
ξ ′
extracted  
owner’s signature 
p rotected image 
X ' 
DWT 
Wˆ  
seeds: ),( 12111 ss=s  PRNG
α -trimmed 
mean 
TSVM  
BS
kρ ′
'
k
Bρ
'
k
b ρ
TPC 
f
tw ′
Φ ′
seeds: ),( 22212 ss=s  
FS 
PR NG
 
圖 6：使用者簽章抽出流程圖  
index attacks  index attacks 
00 Attack-free  09 Blurring 
01 JPEG 10%  10 Brighten (+30) 
02 Median 3*3  11 Darken (-30) 
03 Median 5*5  12 Sharpen 
04 Median 7*7  13 Histogram Equalization 
05 Noising 5%  14 Cropping (surround)25% 
06 Gaussian Noising  15 Painting 
07 SaltPepper Noising  16 Average 
08 Scaling 1/4    
 8
32
33
34
35
36
37
38
39
40
41
42
43
44
8% 10% 12% 14% 16% 18% 20%
Noise density (%)
Av
era
ge
 P
SN
R 
(d
B)
Detector_u
Detector_v
Detector_q
Detector_p
Detector_h
Proposed
Median filer
 
圖 17：復原受污染後七張影像平均 PSNR。 
  
(a) (b) (c) 
  
(d) (e) (f) 
  
(g) (h) (i) 
  
圖 18： (a)原始影像 (b)Fixed value 雜訊汙
染 20% (c)Median Filter (d)Detector u, 
PSNR=38.82 (e)Detector v, PSNR=33.19 (f) 
Detector p, PSNR=38.821 (g) Detector q, 
PSNR=37.05 (h) Detector h, PSNR=39.48 (i) 
Proposed, PSNR=39.92 
 
(a) 
 
(b) 
圖 18：web services 上傳介面 
 
圖 19：本系統提供影像浮水印相關的
service
 10
可供推廣之研發成果資料表 
5 可申請專利  5 可技術移轉                        日期： 年 月 日 
國科會補助計畫 
計畫名稱：計算智慧研究應用於多媒體浮水印、多媒體檢索與
cDNA 微陣列影像濾波器並實現其行動網路服務系統 (A study of 
computational intelligence for multimedia watermarking, multimedia 
retrieval, and cDNA microarray image filter and realize them with 
mobile web services)  
計畫主持人：蔡鴻旭  國立虎尾科技大學 資訊管理系 
計畫編號：NSC 96-2221-E-150-062 學門領域：資訊工程 EB 
技術/創作名稱 決策型影像濾波系統 
發明人/創作人 蔡鴻旭、林軒平 
中文： 
混合式決策型的影像濾器(A median-based image filter with 
hybrid detectors for impulse noise)，利用多個 impulse noise detector
來偵測是否有 impulse noise corruption，再利用 meiadn filter 來還原
corrupted images。。 
（100~500 字） 
技術說明 英文： 
The filter first detect whether the pixels in a slide window are 
corrupted by impulse noises or not. The filter then output the result of 
the median filter if they are corrupted. Otherwise, the center pixel of 
the window is unchanged and outputted. The experimental results show 
that the proposed filter can effectively recovery the degraded images, 
and also can possess better performance then that of other existing 
filters. 
可利用之產業 
及 
可開發之產品 
資訊工程相關產業 
CCD 照相機消除雜訊元件。 
數位衛星影像消除雜訊元件。 
機器人視覺模組中影像消除雜訊元件。 
技術特點 效能比傳統方法佳。硬體設計教為簡單。 
推廣及運用的價值 具推廣價值於 CCD 照相機消除雜訊、數位衛星影像、機器人視覺模組中影像消除雜訊。 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
附件二 
 12
5 可申請專利  5 可技術移轉                        日期： 年 月 日 
國科會補助計畫 
計畫名稱：計算智慧研究應用於多媒體浮水印、多媒體檢索與
cDNA 微陣列影像濾波器並實現其行動網路服務系統 (A study of 
computational intelligence for multimedia watermarking, multimedia 
retrieval, and cDNA microarray image filter and realize them with 
mobile web services)  
計畫主持人：蔡鴻旭  國立虎尾科技大學 資訊管理系 
計畫編號：NSC 96-2221-E-150-062 學門領域：資訊工程 EB 
技術/創作名稱 以網路服務技術實現數位影像浮水印系統 
發明人/創作人 蔡鴻旭、曾厚強 
中文： 
利用 Web Services 來研製數位影像浮水印系統，因此，本系統
具跨平台、跨裝置及分散式計算的能力。由於 Web Services 技術提
供異質平台間應用程式的相互溝通，本系統可以整合其它具 Web 
Services 數位影像浮水印技術，讓使用者能簡易地重複使用網際網
路上的應用程式，達到資源共享目的。此外，當數位影像浮水印的
研發者要評比各類浮水印技術之效能時，不需花時間撰寫應用程式
來模擬其它數位影像浮水印技術，可大大縮短研發時程。 
（100~500 字） 
技術說明 
英文： 
A digital image watermarking system is implemented with Web 
Services. The proposed system provides services requested by clients 
in distinct platforms and devices, and work in distributed-computing
fashion. Because the technique of Web Services offers interoperability
among applications programs in heterogeneous platforms, the system 
can readily integrate the digital image watermarking method, 
implemented in the system, with other image watermarking methods. 
The application programs with Web Services in the Internet can be 
simply reused by users or researchers, therefore, the resources can be 
easily shared. In addition, the system helps the researchers to greatly 
reduce the time in comparing the performance of their image 
watermarking methods with that of other proposed methods. 
Specifically, the researchers need not create simulation programs for 
other proposed methods that were implemented with Web Services. 
Hence we can readily integrate the proposed methods by Web Services 
into the proposed system. 
可利用之產業 
及 
可開發之產品 
資訊工程相關產業 
網路服務應用，電子安全簽章系統、智慧財產權鑑識系統 
技術特點 跨平台使用軟體，易於資源分享，共享軟件設計簡單，易於實施分散式網路計算。 
推廣及運用的價值 具推廣價值於跨平台使用軟體、智慧財產權鑑識功能上 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
3.本表若不敷使用，請自行影印使用。 
 計畫編號 NSC 96-2221-E-150-062 
計畫名稱 計算智慧研究應用於多媒體浮水印、多媒體檢索與 cDNA 微陣列影像濾波器並實現其行動網路服務系統 
出國人員姓名 
服務機關及職稱 
蔡鴻旭 國立虎尾科技大學 資訊管理系 教授 
會議時間地點 Kunming, China, 12-15 July 2008 
會議名稱 Proceedings of the Seventh International Conference on Machine Learning and Cybernetics (EI) 
發表論文題目 Robust Lossless Watermarking using ALPHA-Trimmed Mean and SVM 
 
三、參加會議經過 
 
ICMLC每年的投稿 papers量快速增加, 其涵蓋學術領域是人工智慧、資訊科技及資
訊處理領域重要的學術會議之一。其接受的論文集由 IEEE 出版 ISBN 
978-1-4244-2095-7，此論文期刊已被 EI 收錄。擔任此 conference 中 Session Code: 
OSA2,Title: Applications of Intelligent Systems II之 Session Chair. 此 session發表的論文主
要是應用智慧型系統，與會學者互相提問，討論熱烈，與會人員收穫不少。 
 
 
 
 
四、與會心得 
 
經由參加此 conference 可學習到如何舉辦聯合性國際會議的經驗。這次缺點是
conference地點之 Hotel，交通較不方便。不過各 session出席發表論文的情況踴躍大部分
是大陸台灣學者，大會的服務人員稍嫌不夠造成無賓至如歸感覺。優點是認識一些學者
曾 cite their papers and ask questions to them，還有此 conference topics涵蓋範圍廣，學到
其他領域的應用概念，對於學習新學術領域及未來有潛力研究題材、理論與技術有很大
的助益 
 
 
 
 
 
 
the row-major method, the watermark W and its extracted 
version can be, respectively, denoted by 
W = (w1, w2, …, wk, …, wm) (1)
and 
( )mk wwwwW ˆ,,ˆ,,ˆ,ˆ 21ˆ KK=  (2)
where wk and kwˆ ∈ {-1, 1}. 
A. DWT 
Fig. 1 (a) depicts that X be segmented into non-overlapped 
blocks ⎥⎦
⎥⎢⎣
⎢×⎥⎦
⎥⎢⎣
⎢
88
KL
 with size 8 × 8. Fig. 1(b) illustrates that each 
non-overlapped block bij in X is decomposed through the 
DWT. Let Bij represent the corresponding wavelet block 
consisting of 64 coefficients. Moreover, Bij(r, c) stands for the 
coefficient at the position (r, c) on the block Bij. Fig. 1(c) 
shows bij is transformed through DWT with two levels. First, 
each wavelet block Bij at each level consists of four bands 
(components): low- low band (LL1), low-high band (LH1), 
high-low band (HL1), and high-high band (HH1). LL1 band 
can be further divided into four subbands: low-low subband 
(LL2), low-high subband (LH2), high-low subband (HL2), 
and high-high subband (HH2). Generally, HL2, LH2, HH2, 
HL1, and LH1 are called middle-frequency components (or 
detailed subbands). 
 
 
 
 11b  12b  
 
⎥⎦
⎥⎢⎣
⎢
8
,1
Kb  
21b  22b  
 
⎥⎦
⎥⎢⎣
⎢
8
,2
Kb  
M 
M  
 M  
1,
8 ⎥⎦
⎥⎢⎣
⎢ Lb  2,
8 ⎥⎦
⎥⎢⎣
⎢ Lb  
 
⎥⎦
⎥⎢⎣
⎢⎥⎦
⎥⎢⎣
⎢
8
,
8
KLb  
        
        
        
        
        
        
        
        
),( kkk j i
b =σ  )8,8(21b  ),(21 crb  
original image in spatial domain 
)1,1(21b  )8,1(21b  
… 
… 
… 
 
(a) 
 
 
 
 11B  12B  
 
⎥⎦
⎥⎢⎣
⎢
8
,1 K
B  
21B  22B  
 
⎥⎦
⎥⎢⎣
⎢
8
,2 K
B  
M  
  
M    M  
1,
8 ⎥⎦
⎥⎢⎣
⎢ LB  2,
8 ⎥⎦
⎥⎢⎣
⎢ LB  
 
⎥⎦
⎥⎢⎣
⎢⎥⎦
⎥⎢⎣
⎢
8
,
8
KLB  
        
        
        
        
        
        
        
        
) ,( kkk ji
B =ρ  )8,8(21B  )c,(21 rB  
blocks in original image X are decomposed by wavelet transform 
)1,1(21B  )8,1(21B  
… 
… 
… 
 
(b) 
 
( )0,02,2,kBρ  
HH2 LH2 
LL2 
LH1 HH1 
HL1 
( )0,12,2,kBρ  
 
(c) 
Fig. 1 (a) X is segmented into ⎥⎦
⎥⎢⎣
⎢×⎥⎦
⎥⎢⎣
⎢
88
KL
 non-overlapped 
blocks with size 8 × 8. (b) bij is transformed through DWT. (c) 
Components are constituted of a wavelet image block with 
size 8 × 8 at level 2. 
B. SVM 
Let F = {(xi, di) |i = 1, 2, · · · , N } be a set of N training 
patterns, where xi = (xi1, xi2, · · · , xin) ∈ Rn denotes an input 
vector in the input space and di ∈ {−1, 1} represents the label 
class of xi. Assume F be a linear separable. A linear SVM 
seeks an optimal separating hyperplane with maximum 
margin so that the linear SVM has good generalization. More 
specially, the SVM searches a pair (w, b) for an optimal 
hyperplane by maximizing the margin 
w
2  between 
1=+ btiwx  and 1−=+ btiwx  where w ∈ Rn, b ∈ R, and t 
denotes the transpose operation. Assume the pair (wo, bo) is an 
optimal solution for a corresponding separating hyperplane 
for F, the linear SVM can be performed by the decision 
function f defined as  
 
)sgn()( o
t
o bf += xwx  (3)
 
where sgn(⋅) stands for the sign function. 
While classifying a set of linearly nonseparable data, slack 
variables ξi are added into the derivation of a linear 
non-separable SVM. Namely, linear SVMs have the 
following optimization problem [9]. 
 
Minimize ∑
=
+
N
i
iC
T
12
1 ξww  
Subject to 
ii bd ξ−≥+ 1)( tiwx , ξi ≥ 0, i = 1, ..., N. 
(4)
 
Additionally, C denotes the penalty for vectors incorrectly 
classified or inside the margin. While minimizing the first 
term in (4), ww T
2
1  plays the role of controlling the capacity 
of the SVMs and avoiding the overfitting of the SVMs. 
Minimizing the second term is to minimize the empirical risk. 
It controls the tradeoff between the maximization of the 
margin and the minimization of incorrect classification on 
training patterns. The Wolfe dual programming of (4) is 
 
Maximize ( ) ∑ ∑−∑=
= ==
N
i
N
l
lil
t
ili
N
i
i ddαL
1 11 2
1 ααα xx  
Subject to .,,1],,0[,0
1
NiCd i
N
i
ii K=∈∑ == αα  
(5)
 
Assume ( )oNo αα ,,1 L=oα  is an optimal solution for (5). 
The pair ( )b,w can be computed by using oα . The decision 
function f can be expressed as the following form. 
 
( ) ( ) ⎟⎠⎞⎜⎝⎛ ∑ +=+= =Ni tiiit bdbf 1sgnsgn xxxwx α . (6)
 
A linear SVM, however, is inadequate for nonlinear data. 
Thus, kernel functions, K(⋅,⋅), are introduced in the linear 
SVMs to construct the nonlinear SVMs [9]: 
 
IEEE World Congress on Computational Intelligence 2008: Workshop on  
Applications of Computational Intelligence to Benefit Society 7th June 2008
ISBN 978-1-905476-35-0 39
 
 
 
1 -1 1 1 1 -1 1 1 1 
 
 
),( vvk
T  
v  
v  
kw  
image-dependent watermark Ξ 
owner  signature 
training pattern 
W  
 
Fig. 3 the construction of a training pattern by using W and Ξ. 
 
Φ = ( ){ }mkwT kk vv ,...,2,1|,),( =  where ( )
)1,1()1,0()0,0(),(
,,, −−= vvvv kkkk tttT K , }1,1{),( −∈vvkt . 
(14) 
 
The embedding algorithm is summarized as follows. 
step 1. Input X and W. 
step 2. Feed the PRNG component with (s1 , s2) to generate Γ 
= ),,,,1( mk ρρ LL . 
step 3. Collect Ψ of m target blocks after feeding the BS 
component with X and Γ.  
step 4. For each 
k
bρ  where k = 1, 2,…, m. 
step 5. Transform 
k
bρ to be kBρ by using DWT with four 
levels. 
step 6. For 
k
Bρ , compute ),( ikU ρ using (10) and (11) for all i. 
step 7. Apply the α-trimmed mean operator to calculate 
),( ik
U ρ and then construct tξ  using (12) for all t.  
step 8. Produce the feature information Ξ using (13). 
step 9. Feed the TPC component with W, Ξ, and seeds to get 
the training pattern set Φ . 
step 10. Utilize Φ to train an SVM to obtain a trained SVM. 
B. Watermark extraction 
Fig. 4 the structure of the watermark extraction illustrates 
the structure of the watermark extraction of the proposed 
technique. The PRNG, DWT, BS, feature selection, and TPC 
components are the same as those used in the watermark 
embedding algorithm of the proposed technique. Also, the 
seeds (s1 , s2) are identical to the seeds in the watermark 
embedding algorithm of the proposed technique. 
Let X ′ and Ξ′ denote the protected image (or damaged image) 
and its corresponding image-dependent 
watermark. Φ′ represents a set of input vectors which are 
computed by feeding the TPC component with Ξ′ and the 
seeds. Here the original watermark is unavailable. That is, the 
orignal watermark is estimated by using a trained SVM 
(TSVM). The TSVM component performs watermark 
estimation. After feeding the TSVM component with Φ′ , it 
outputs the estimated watermark Ŵ expressed as a form in 
(2).  
 
ξ ′
extracted 
owner’s signature 
protected image 
X ' 
DWT 
Wˆ
seeds: ),( 12111 ss=s  PRNG
α -trimmed 
mean 
TSVM 
BS 
kρ
'
k
B ρ
'
k
bρ
TPC 
f
tw Φ ′
seeds: ),( 22212 ss=s  
FS 
PRNG
 
Fig. 4 the structure of the watermark extraction. 
 
The watermark estimation algorithm is summarized as 
follows. 
step 1. input X′ and the seeds (s1 , s2). 
step 2. Feed the PRNG component with (s1 , s2) to generate Γ 
= ),,,,1( mk ρρ LL . 
step 3. Collect Ψ′ of m target blocks after feeding the BS 
component with X′ and Γ. 
step 4. For each 
k
bρ′  where k = 1, 2,…, m. 
step 5. Transform 
k
bρ′ to be kBρ′ by using DWT with four 
levels. 
step 6. For 
k
Bρ , compute ),( ikU ρ using (10) and (11) for all i. 
step 7. Apply the α-trimmed mean operator to calculate 
),( ik
U ρ and then construct tξ  using (12) for all t.  
step 8. Produce the feature information Ξ′  using (13). 
step 9. Feed the TPC component with Ξ′ and seeds to get the 
set Φ′ of input vectors. 
step 10. Feed the TSVM component with Φ′ . The TSVM 
component estimatesWˆ . The algorithm outputs the Wˆ .  
 
IEEE World Congress on Computational Intelligence 2008: Workshop on  
Applications of Computational Intelligence to Benefit Society 7th June 2008
ISBN 978-1-905476-35-0 41
 
 
 
 
 
Lena 
Attacks our scheme SVMLIW Chen Sang Attacks 
our 
scheme SVMLIW Chen Sang 
ttack-free 
    
Brighten 
 
JPEG 
50% 
    
Darken 
 
Median 
 3×3 
    
Histogram 
Equalization 
 
Noising 
1% 
    
Crop25% 
 
Scaling 
    
Painting 
 
Blurring 
    
 
 
   
  
Fig. 7 The comparison results with visual perception for 
extracted watermarks Wˆ  estimated by using the four 
methods while Lena is the test image. 
V. CONCLUSION 
An effective lossless watermarking technique, based on the 
α-trimmed mean operation and SVM, has been proposed in 
this paper to protect image copyrights. The technique does 
not damage the contents of original images during watermark 
embedding, because it uses a trained SVM to memorize the 
watermark or owner signature and then exploits the trained 
SVM to estimate the watermark. Meanwhile, its robustness 
can be enhanced using the α-trimmed mean operation against 
attacks. Experimental results demonstrate that the technique 
not only possesses the robust ability to resist on 
image-manipulation attacks under consideration but also, in 
average, is superior to other existing methods being 
considered in the paper. 
ACKNOWLEDGMENT 
Authors would like to thank the National Science Council of 
Taiwan, R.O.C., for financially supporting this research 
under Contract No. NSC 96-2221-E-150-062. 
REFERENCES 
[1] C.-Y. Chang and S.-J. Su, "A neural-network-based robust 
watermarking scheme," IEEE International Conference on Systems, 
Man and Cybernetics, vol. 3, pp. 2482-2487, 2005. 
[2] C.-D. Vleeschouwer, J.-F. Delaigle and B. Macq, "Circular 
interpretation of bijective transformations in lossless watermarking for 
media asset management," IEEE Transactions on Multimedia, vol. 5, 
no. 1, 2003. 
[3] B.-G. Mobasseri and R.-J. Berger, "A foundation for watermarking in 
compressed domain," IEEE Signal Processing Letters, vol. 12, no. 5, 
2005. 
[4] M.-U. Celik, G. Sharma and A.-M. Tekalp, "Lossless watermarking for 
image authentication: a new framework and an implementation," IEEE 
Trans. on Image Processing, vol. 15, no. 4, 2006. 
[5] J.-M. Shieh, D.-C. Lou and H.-K. Tso, "A robust watermarking scheme 
for digital image using self similarity," Information Technology: 
Research and Education, pp. 115-119, 2005. 
[6] T.-H. Chen, G.-B. Horng and W.-B. Lee, "A publicly verifiable 
copyright-proving scheme resistant to malicious attacks," IEEE Trans. 
on Industrial Electronics, vol. 52, issue 1, pp. 327-334, 2005. 
[7] J. Sang and M. S. Alam, "A neural network based lossless digital image 
watermarking in the spatial domain," Lecture Notes in Computer 
Science, vol. 3497, pp. 772-776, 2005. 
[8] H.-H. Tsai, C.-C. Liu and H.-C. Tseng, "SVM-based lossless image 
watermarking," Information Security Conference R.O.C., 2007. 
[9] C.J.C. Burges, "A Tutorial on support vector machines for pattern 
recognition, " Data Min. Knowledge Discovery, pp. 121–167, 1998. 
[10] I. Pitas and A.-N. Venetsanopoulos, Nonlinear Digital Filters 
Principles and Applications, Kluwer Academic Publishers, pp. 131-134, 
1990. 
[11] C.-C. Chang and C.-J. Lin, LIBSVM: a library for support vector 
machines, Software available at 
http://www.csie.ntu.edu.tw/~cjlin/libsvm. 
IEEE World Congress on Computational Intelligence 2008: Workshop on  
Applications of Computational Intelligence to Benefit Society 7th June 2008
ISBN 978-1-905476-35-0 43
Proceedings of  the Seventh International Conference on Machine Learning and Cybernetics, Kunming, 12-15 July 2008 
method technique using the α-trimmed mean operation and 
SVMs. It does not damage the original image during 
watermark embedding because it first uses a set of trained 
SVMs to memorize the watermark and then exploits the 
trained SVMs to estimate the watermark. Moreover, the 
RLW method utilities α-trimmed mean operator against 
noise attacks so that its can be enhanced robustness. 
Experimental results demonstrate that the RLW method not 
only possesses the robust ability to resist on 
image-manipulation attacks under consideration but also, in 
average, is superior to other existing methods being 
considered in the paper. 
The rest of the paper is organized as follows. Section 2 
reviews the discrete wavelet transformation (DWT) and the 
SVM. Section 3 then describes the feature-selection, 
signature-embedding, and signature-extraction algorithms 
used in the design of the RLW method. Section 4 shows 
experimental results. Finally, Section 5 draws conclusions. 
2. A Review of DWT and SVM 
Let X = [xρ]M×N denote a gray-level image with size L × 
K where xρ ∈{0, 1, · · · , 255} represents a gray level of the 
pixel at position ρ = (i, j) ∈ {1, · · · , L}×{1, · · · , K}. Here a 
stamp binary image with size m is taken as the watermark 
W. Using the row-major method, the watermark W and its 
extracted version can be, respectively, denoted by 
W = (w1, w2, …, wk, …, wm) (1)
and 
( )mk wwwwW ˆ,,ˆ,,ˆ,ˆ 21ˆ ……=  (2)
where wk and ∈ {-1, 1}. kwˆ
2.1. DWT 
Figure 1 (a) depicts that X be segmented into 
non-overlapped blocks ⎥⎦
⎥⎢⎣
⎢
×⎥⎦
⎥⎢⎣
⎢
88
KL
 with size 8 × 8. Figure 
1(b) illustrates that each non-overlapped block bij in X is 
decomposed through the DWT. Let Bij represent the 
corresponding wavelet block consisting of 64 coefficients. 
Moreover, Bij(r, c) stands for the coefficient at the position 
(r, c) on the block Bij. Figure 1(c) shows bij is transformed 
through DWT with two levels. First, each wavelet block Bij 
at each level consists of four bands (components): low- low 
band (LL1), low-high band (LH1), high-low band (HL1), 
and high-high band (HH1). LL1 band can be further 
divided into four subbands: low-low subband (LL2), 
low-high subband (LH2), high-low subband (HL2), and 
high-high subband (HH2). Generally, HL2, LH2, HH2, 
HL1, and LH1 are called middle-frequency components (or 
detailed subbands). 
 
 
 
 11b  12b  
 
⎥⎦
⎥⎢⎣
⎢
8
,1 K
b  
21b  22b  
 
⎥⎦
⎥⎢⎣
⎢
8
,2
Kb  
# 
#  
 #  
1,
8 ⎥⎦
⎥⎢⎣
⎢Lb  2,
8 ⎥⎦
⎥⎢⎣
⎢Lb
 
⎥⎦
⎥⎢⎣
⎢⎥⎦
⎥⎢⎣
⎢
8
,
8
KLb
        
        
        
        
        
        
        
        
),( kkk j i
b
=σ)8,8(21b),(21 crb  
original image in spatial domain 
)1,1(21b )8,1(21b
…
…
…
 
 
 
 
 11B  12B  
 
⎥⎦
⎥⎢⎣
⎢
8
,1
KB  
21B  22B  
 
⎥⎦
⎥⎢⎣
⎢
8
,2
KB  
#   
  
#    #  
1,
8 ⎥⎦
⎥⎢⎣
⎢LB 2,
8 ⎥⎦
⎥⎢⎣
⎢ LB
 
⎥⎦
⎥⎢⎣
⎢⎥⎦
⎥⎢⎣
⎢
8
,
8
KLB
        
        
        
        
        
        
        
        
) ,( kkk ji
B
=ρ)8,8(21B  )c,(21 rB  
blocks in original image X are decomposed by wavelet transform 
)1,1(21B  )8,1(21B  
…
)8,8(1,2B
)1,1(1,2B
…
…
 
(a)  (b) 
 
( )0,02,2,kBρ  
HH2 LH2 
LL2 
LH1 HH1 
HL1 
( )0,12,2,kBρ  
 
(c) 
Figure 1. (a) X is segmented into ⎥⎦
⎥⎢⎣
⎢
×⎥⎦
⎥⎢⎣
⎢
88
KL
 non-overlapped 
blocks with size 8 × 8. (b) bij is transformed through DWT. 
(c) Components are constituted of a wavelet image block 
with size 8 × 8 at level 2. 
2.2. SVM 
Let F = {(xi, di) |i = 1, 2, · · · , N } be a set of N 
training patterns, where xi = (xi1, xi2, · · · , xin) ∈ Rn denotes 
an input vector in the input space and di ∈ {−1, 1} 
represents the label class of xi. Assume F be a linear 
separable. A linear SVM seeks an optimal separating 
hyperplane with maximum margin so that the linear SVM 
has good generalization. More specially, the SVM searches 
a pair (w, b) for an optimal hyperplane by maximizing the 
margin 
w
2  between  and  where 
w ∈ R
1=+ btiwx 1−=+ b
t
iwx
n, b ∈ R, and t denotes the transpose operation. 
Assume the pair (wo, bo) is an optimal solution for a 
corresponding separating hyperplane for F, the linear SVM 
can be performed by the decision function f defined as  
)sgn()( o
t
o bf += xwx  (3)
where sgn(⋅) stands for the sign function. 
While classifying a set of linearly nonseparable data, 
slack variables ξi are added into the derivation of a linear 
non-separable SVM. Namely, linear SVMs have the 
following optimization problem [9]. 
Minimize ∑
=
+
N
i
iC
T
12
1 ξww  
Subject to , ξii bd ξ−≥+ 1)( tiwx i ≥ 0, i = 1, ..., N. 
(4)
Additionally, C denotes the penalty for vectors 
incorrectly classified or inside the margin. While 
3348 
Authorized licensed use limited to: IEEE Xplore. Downloaded on October 28, 2008 at 12:46 from IEEE Xplore.  Restrictions apply.
Proceedings of  the Seventh International Conference on Machine Learning and Cybernetics, Kunming, 12-15 July 2008 
ξ is expanded to a binary image Ξ with size L × K. Here the 
binary image Ξ is called the feature information or 
image-dependent watermark for the original image X. 
Then, the TPC component generates the training 
patterns by using W and Ξ. Figure 3. The construction of a 
training pattern by using depicts the construction of a 
training pattern by using W and Ξ. A set Φ of trainig 
patterns can be represented as (14) where the input vector 
and the coresponding desired output denote and , 
respectively. Finally, the set  is used to train an SVM. 
In order to improve the estimate performance of the SVM, 
the set Φ is divided into P partitons and then these partitons 
are separately employed to train P distinct SVMs. Note that 
these partitons are disjoin sets and the union of the partitons 
is the set Φ. 
( )vvkT , kw
Φ
Φ = ( ){ }mkwT kk vv ,...,2,1|,),( =  where ( )
)1,1()1,0()0,0(),(
,,,
−−
=
vvvv kkkk
tttT … , . }1,1{
),(
−∈
vvk
t
(14)
1 -1 1 1 1 -1 1 1 1 
 
 
),( vvk
T  
v  
v
kw  
image-dependent watermark Ξ 
owner  signature 
training pattern 
W  
 
Figure 3. The construction of a training pattern by using W 
and Ξ. 
The embedding algorithm of the RLW method is 
summarized as follows. 
Step 1. Input X and W. 
Step 2. Feed the PRNG component with (s1 , s2) to generate 
Γ = ),,,,1( mk ρρ "" . 
Step 3. Collect Ψ of m target blocks after feeding the BS 
component with X and Γ.  
Step 4. For each  where k = 1, 2,…, m. 
k
bρ
Step 5. Transform to be by using DWT with four 
levels. 
k
bρ kBρ
Step 6. For , compute using (10) and (11) for 
all i. 
k
Bρ ),( ikU ρ
Step 7. Apply the α-trimmed mean operator to calculate 
and then construct  using (12) for all t.  
),( ik
U ρ tξ
Step 8. Produce the feature information Ξ using (13). 
Step 9. Feed the TPC component with W, Ξ, and seeds to 
get the training pattern set . Φ
Step 10. Divide  into P disjoin subsets and separately 
utilize P subsets to obtain P trained SVMs. 
Φ
extracted 
owner signature 
protected image 
X ' 
DWT 
Wˆ
seeds: ),( 21 sss =  PRNG 
α -trimmed 
mean 
---------------
feature 
selection 
TSVM 
BS 
kρ  
'
k
B ρ
'
k
bρ
TPC 
O
ikw , Φ′
  
Figure 4. The structure of the watermark extraction 
3.2. Watermark extraction 
Figure 4 illustrates the structure of the watermark 
extraction of the RLW method. The PRNG, DWT, BS, 
feature selection, and TPC components are the same as 
those used in the watermark embedding algorithm of the 
proposed technique. Also, the seeds (s1 , s2) are identical to 
the seeds in the watermark embedding algorithm of the 
proposed technique. Let X ′ and denote the protected 
image (or damaged image) and its corresponding 
image-dependent watermark. represents a set of input 
vectors which are computed by feeding the TPC component 
with and the seeds. Here the original watermark is 
unavailable. That is, the orignal watermark is estimated by 
using P SVMs. The TSVM component performs watermark 
estimation. After feeding TSVM component with P 
partitions of individually, it outputs the estimated 
watermark Ŵ expressed as a form in (2).  
Ξ′
Φ′
Ξ′
Φ′
The watermark estimation algorithm of the RLW 
method is summarized as follows. 
Step 1. Input X′ and the seeds (s1 , s2). 
Step 2. Feed the PRNG component with (s1 , s2) to 
generate Γ = ),,,,1( mk ρρ "" . 
Step 3. Collect of m target blocks after feeding the BS 
component with X′ and Γ. 
Ψ′
Step 4. For each  where k = 1, 2,…, m. k
bρ′
Step 5. Transform to be by using DWT with four 
levels. 
k
bρ′ kBρ′
Step 6. For , compute using (10) and (11) for 
all i. 
k
Bρ ),( ikU ρ
Step 7. Apply the α-trimmed mean operator to calculate 
3350 
Authorized licensed use limited to: IEEE Xplore. Downloaded on October 28, 2008 at 12:46 from IEEE Xplore.  Restrictions apply.
Proceedings of  the Seventh International Conference on Machine Learning and Cybernetics, Kunming, 12-15 July 2008 
proposed in this paper to protect image copyrights. The 
RLW method does not damage the contents of original 
images during watermark embedding, because it uses 
trained SVMs to memorize the watermark or owner 
signature and then exploits the trained SVMs to estimate 
the watermark. Meanwhile, its robustness can be enhanced 
using the α-trimmed mean operation against attacks. 
Experimental results demonstrate that the RLW method not 
only possesses the robust ability to resist on 
image-manipulation attacks under consideration but also, in 
average, is superior to other existing methods being 
considered in the paper. 
 
(a) 
 
(b) 
 
(c) 
 
(d) 
 
(e) 
 
(f) 
 
(g) 
 
 
Figure 5. (a) the original watermark W (b) Lena (c) Baboon 
(d) Barbara (e) Peppers (f) Couple (g) Stream bridge 
0.7
0.75
0.8
0.85
0.9
0.95
1
0 1 2 3 4 5 6 7 8 9 10 11
Attacks
BC
R our scheme_97.94%SVMLIW_96.18%
Chen_95.46%
 
Figure 6. Comparison results of the robustness evaluation 
for the three methods 
Lena 
Attacks SVMLIW Chen our scheme Attacks SVMLIW Chen our scheme
Attack-free
 
Brighten 
 
JPEG 50%
 
Darken 
 
Median filter
 3×3 
 
Histogram 
Equalization 
 
Noising 
1% 
 
Crop25% 
 
Scaling 
 
Painting 
 
Blurring 
 
 
   
 
  
Figure 7. The comparison results with visual perception for 
extracted watermarks estimated by using the three methods 
while Lena is the test image 
Acknowledgements 
Authors would like to thank the National Science 
Council of Taiwan, R.O.C., for financially supporting this 
research under Contract No. NSC 96-2221-E-150-062. 
References 
[1] C.-Y. Chang and S.-J. Su, "A neural-network-based 
robust watermarking scheme," IEEE International 
Conference on Systems, Man and Cybernetics, Vol. 3, 
pp. 2482-2487, 2005. 
[2] C.-D. Vleeschouwer, J.-F. Delaigle and B. Macq, 
"Circular interpretation of bijective transformations in 
lossless watermarking for media asset management," 
IEEE Transactions on Multimedia, Vol. 5, No. 1, 
2003. 
[3] B.-G. Mobasseri and R.-J. Berger, "A foundation for 
watermarking in compressed domain," IEEE Signal 
Processing Letters, Vol. 12, No. 5, 2005. 
[4] M.-U. Celik, G. Sharma and A.-M. Tekalp, "Lossless 
watermarking for image authentication: a new 
framework and an implementation," IEEE Trans. on 
Image Processing, Vol. 15, No. 4, 2006. 
[5] J.-M. Shieh, D.-C. Lou and H.-K. Tso, "A robust 
watermarking scheme for digital image using self 
similarity," Information Technology: Research and 
Education, pp. 115-119, 2005. 
[6] T.-H. Chen, G.-B. Horng and W.-B. Lee, "A publicly 
verifiable copyright-proving scheme resistant to 
malicious attacks," IEEE Trans. on Industrial 
Electronics, Vol. 52, issue 1, pp. 327-334, 2005. 
[7] J. Sang and M. S. Alam, "A neural network based 
lossless digital image watermarking in the spatial 
3352 
Authorized licensed use limited to: IEEE Xplore. Downloaded on October 28, 2008 at 12:46 from IEEE Xplore.  Restrictions apply.
