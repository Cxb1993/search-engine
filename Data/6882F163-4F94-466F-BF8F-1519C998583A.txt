coding results. In the adjustment of network 
parameters and the algorithm parameters, optimization 
method developed in the previous project will be 
adopted to find the sub-optimal solutions. 
Principal component analysis (PCA), a statistical 
processing technique, transforms the data set into a 
lower dimensional feature space, yet retains most of 
the intrinsic information content of the original 
data. In this report, we apply PCA for image 
compression. The approach is not feasible when the 
dimensions of the covariance matrix become too large. 
To overcome this problem, we adopt the neural network 
architecture in which the synaptic weights, served as 
the principal components, are trained through 
generalized Hebbian algorithm (GHA). Moreover, we 
partition the training set into clusters using K-
means method in order to obtain better retrieved 
image qualities. A conference paper, ＇Image 
compression using PCA with clustering＇, has been 
published and included in IEEE Xplore and EI 
Compendex. 
Based on the super-resolution method using ANN, we 
proposed a classification strategy which can divide a 
patch into five categories. According to the 
classification results, each category will be trained 
and tested by its own ANN. In the classification 
phase, the enhancement of visual quality in the 
super-resolved frame can be expected. To improve the 
learning capability of ANN, the trilateral filter is 
used to pre-process the collected training data. 
After this process, the subjective and objective 
quality of super-resolved frame can be further 
improved. A conference paper, ＇Fast Video Super-
resolution using Artificial Neural Network＇, has 
been published and included in IEEE Xplore and EI 
Compendex. 
 
英文關鍵詞： Artificial neural network, Image coding, Principal 
component analysis； Generalized Hebbian algorithm, 
Video super-resolution, Motion estimation, Bilateral 
filter 
Image compression using PCA with clustering 
 
Chih-Wen Wang 
Dept. of Inform. Eng., I-Shou University 
Kaohsiung, Taiwan 
gk1487@gmail.com 
Jyh-Horng Jeng 
Dept. of Inform. Eng., I-Shou University 
Kaohsiung, Taiwan 
jjeng@isu.edu.tw 
 
 
Abstract—Principal component analysis (PCA), a statistical 
processing technique, transforms the data set into a lower 
dimensional feature space, yet retain most of the intrinsic 
information content of the original data. In this paper, we apply 
PCA for image compression. In the PCA computation, we adopt 
the neural network architecture in which the synaptic weights, 
served as the principal components, are trained through 
generalized Hebbian algorithm (GHA). Moreover, we partition 
the training set into clusters using K-means method in order to 
obtain better retrieved image qualities. 
Keywords-Image compression; K-means algorithm; Principal 
component analysis; Generalized Hebbian algorithm 
I.  INTRODUCTION 
Clustering algorithm [1] is to partition a data set into some 
clusters such that data of the same cluster have some similarity 
properties. K-means algorithm, proposed by Mac Queen, 1967, 
minimizes the sum of distance from each data to its cluster 
center. Because of its ability to efficiently group huge data set, 
K-means algorithm [2-4] is a very popular method of clustering. 
The aim of data reduction techniques [5] is to provide an 
efficient representation of the data. Such as the Karhunen-
Loeve Transform (KLT), the procedure consists of mapping 
higher dimensional input space to a lower dimensional 
representation space by means of linear transformation. In 
principal component analysis (PCA), the KLT needs to 
compute the covariance matrix of input data [6] and then 
extract eigenvalues and corresponding eigenvectors by solving 
the eigen problem. The dimension reduction is achieved by 
using the eigenvectors with the most significant eigenvalues [7] 
as a new orthonormal basis. But the approach is not feasible 
when the dimensions of the covariance matrix become too 
large to be evaluated. To overcome this problem, algorithms 
based on neural networks are proposed. 
Neural principal component analysis is firstly proposed by 
Oja (1982) [8-11] who uses a single neuron to extract the first 
principal component from the input. The Oja's rule can be 
viewed as the modified Hebbian (1949) rule that is the simplest 
unsupervised learning. To extract more than one principal 
component, Sanger (1989) [12] proposes the generalized 
Hebbian algorithm (GHA) which extracts a specified number 
of principal components. In this paper, we partition the training 
set into some clusters using K-means method and apply GHA 
to each of the clusters to achieve the purpose of image 
compression. 
II. K-MEANS ALGORITHM FOR CLUSTERING 
K-means is one of the well known clustering techniques 
which is an iterative hill climbing algorithm. Let liixS 1}{ == , 
n
ix ℜ∈  be the data set of l  points of dimension n . Assume 
we require to partition the data set S  into k  clusters jC , 
},,2,1{ kj "∈ . First, we choose k  data points kzzz ,,, 21 "  
randomly as the initial cluster centers. Then, each of the points 
ix  in the data set is assigned to a cluster jC  if 
piji zxzx −≤− , kp ,,2,1 "=  and pj ≠ . 
After all of the points are assigned to a corresponding 
cluster, we calculate the new cluster centers **2
*
1 ,,, kzzz "  by 
kjx
n
z
ji Cx
i
j
j ",2,1,1* == ∑
∈
 
where jn  is the number of elements belonging to the cluster 
jC . We then assign the new centers 
*
jz  to the variables jz  and 
the iteration proceeds. The iteration terminates subject to some 
proper stopping criterions. 
Although K-means is one of the widely used clustering 
methods, it is known that the solution depends on the choice of 
the initial cluster centers. Therefore, several trials are required 
to obtain a better solution. 
III. PRINCIPAL COMPONENT ANALYSIS 
Principal component analysis (PCA) can be defined as the 
orthogonal projection of the given data onto a lower 
dimensional linear space, called the principal subspace, such 
that the variance of the projected data is maximized. 
For a given data set liixS 1}{ == , nix ℜ∈ , we consider an 
m  dimensional projection subspace where nm < , the optimal 
linear projection is defined by the m  eigenvectors computed 
from the covariance matrix of the data set corresponding to the 
first m  largest eigenvalues. 
PCA provides a simple and efficient method for image 
compression. For instance, an image block of size 88×  can be 
regarded as a 64-dimensional vector. In encoding process, the 
inner product of a 64 dimensional vectors and eigenvector is 
called a compression code for all image blocks. Moreover, a 
The similarity between two image blocks u and v of the 
same size LL×  is measured in terms of the MSE (mean 
squared error) defined as follows:  
( ) ( ) ( )[ ]∑−
=
−=
1
0,
2
2 ,,
1,MSE
L
ji
jivjiu
L
vu , 
and the distortion between the original image f and the 
retrieved image fˆ  caused by lossy compression is measured 
in peak signal to noise ratio (PSNR) defined by 
( ) ( ) ⎟⎟⎠
⎞
⎜⎜⎝
⎛
⋅=
ff
ff
ˆ,MSE
255log10:ˆ,PSNR
2
10 . 
We compare the quality of reconstructed images between 
the GHA method and direct computation of the first m  
principal components from the covariance matrix for 
16,8,4=m . Results shown in Fig. 4 and Fig. 5 indicate that 
more extracted components exhibits better visual effects. 
For clustering study, we partition the training set into 10 
clusters using K-means. In the network, the number of output 
nodes is set as 16=m . For each of clusters, PCA is performed 
separately. The MSE and PSNR evaluated inside each cluster 
using the trained weights are shown in Table 1 and Table 2. 
The retrieved images are shown in Fig. 6 and Fig. 7. It is clear 
that the reconstructed images have very good qualities. We 
have MSE=25.89 and PSNR=34.00 dB for Lena and 
MSE=53.59 and PSNR=30.84 dB for F16. However, for this 
case, there are 10,240 weights required to record. 
For 5-cluster case the results are shown in Table 3 and 
Table 4. The retrieved images are shown in Fig. 8 and Fig. 9 
for Lena with MSE=37.42 and PSNR=32.40 dB and F16 with 
MSE=81.86 and PSNR=29.00 dB. Although the quality 
decays, fewer weights are required to record where the total 
number of used weights is 5,120. 
Figure 2.  Training image (Lena) 
 
Figure 3.  Training image (F16) 
 
  
(a) MSE=213.87, 
PSNR=24.83 
 
(b) MSE=213.88, 
PSNR=24.83 
 
  
(c) MSE=111.03, 
PSNR=27.68;  
 
(d) MSE=111.00, 
PSNR=27.68; 
 
  
(e) MSE=50.48, PSNR=31.10 (f) MSE=56.65, PSNR=30.60
Figure 4.  Image (Lena) sequence obtained with eigenvectors as (a)(c)(e) and 
final weights as (b)(d)(f). 
 
TABLE IV.  Comparison on training 5 clusters (F16) 
No. 
Cluster # Blocks MSE PSNR 
1 98 203.41 25.05
2 116 181.10 25.55
3 95 194.52 25.24
4 460 8.92 38.63
5 255 79.28 29.14
 
Figure 8.  Image (Lena) reconstructed by all of 5 clusters 
 
Figure 9.  Image (F16) reconstructed by all of 5 clusters 
 
ACKNOWLEDGMENT 
This work has been supported by the National Science 
Council of Taiwan, under grants NSC 99-2221-E-214-053-
MY2. 
REFERENCES 
[1] Murat Erisoglu, Nazif Calis, and Sadullah Sakallioglu, "A new 
algorithm for initial cluster centers in k-means algorithm," Elsevier 
Science, Pattern Recognition Letters 32 (2011) 1701-1705. 
[2] J.T. Tou and R.C. Gonzalez, Pattern Recognition Principles, Addison-
Wesley, Reading, MA, 1974. 
[3] S.Z. Selim and M.A. Ismail, "K-means type algorithms: a generalized 
convergence theorem and characterization of local optimality," IEEE 
Trans. Pattern Anal. Mach. Inteli 6 (1984) 81–87. 
[4] H. Spath, Cluster Analysis Algorithms, Ellis Horwood, Chichester, UK, 
1989. 
[5] S. Costa and S. "Fiori, Image compression using principal component 
neural networks," Elsevier Science, Image and Vision Computing 19 
(2001) 649-668. 
[6] L. Xu, "Least mean square error reconstruction principle for self-
organizing neural-nets," Neural Networks 6 (1993) 627-648. 
[7] K.I. Diamantaras and S.Y. Kung, Principal Component Neural Networks: 
Theory and Applications, Wiley, New York, 1996. 
[8] E. Oja, "A simplified neuron model as a principle component analysis," 
J. Math. Biol. 15 (1982) 267-273. 
[9] E. Oja, "Neural networks, principle components and subspaces," Int J. 
Neural System 1 (1989) 61-68. 
[10] E. Oja, "principle components, minor components, and linear neural 
networks," Neural networks 5 (1992) 927-935. 
[11] E. Oja, "A simplified neuron model as a principal component analyzer," 
J. Math. Biol. 15 (1982) 267-273. 
[12] T. D. Sanger, "Optimal unsupervised learning in a single-layer linear 
feed-forward neural network," Neural Networks 2 (1989) 459-473.-441, 
498-520. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
二、與會心得 
會議中與其他學者交換有關以類神經網路學習方法為基礎的視訊超解析度提升方法心得如
下：可利用移動式視訊運動估測搜尋方法，對視訊影像收集適當的訓練資料，供 ANN 進行訓練，
依據訓練結果所得之參數與權重，可以有效提升視訊影像的解析度，再加入適當的分類方法，對
要提升的視訊影像進行分類處理，以改善超解析度視訊影像中，物體邊緣的視覺影像品質。此外，
一個以三向濾波器為基礎的方法，將可運用來對收集的訓練資料進行前處理，以進一步改善 ANN
的學習效果。最後，我們亦將修改 ANN 輸出資料的收集方式，以提升超解析度視訊影像邊緣結構
的影像品質。 
視訊超解析度近幾年，已被廣泛應用於多媒體通訊、影像辨識、衛星影像與醫學影像等領域。
機器學習中的 ANN，應用於視訊超解析度(video super-resolution)提升方法中。視訊超解析度提升
主要是將視訊中的影像進行解析度提升(放大)，其必須對空間軸與時間軸上的三度空間影像資訊進
行考慮，方能使放大後的影像有較佳的品質，由於視訊資料的複雜性，恰好適合由具有非線性資
料預測能力的 ANN，來加以開發其中可用的有效資訊。而 ANN 的主要優點是利用 BP(back 
propagation)或是其他最陡坡降法(steepest descent method)，來學習影像放大前的低解析度影像與放
大後的高解析度影像資料間的關係，同時也會選擇非線性活化函數(activation function)以及相關核
心函數(kernel function)進行非線性權重運算，使得學習與預測效果可以進一步的提升，利用這個軟
式計算方法的優點，來開發視訊超解析度提升時的可用資訊。 
針對運動估測方法與專家討論後提出一個可移動式的(mobile search center)運動估測方法
(motion estimation)，有別於傳統運動估測方法，此方法可在相同的運算複雜度下，提升運動估測效
果。接著在所提運動估測方法基礎下，收集視訊中影像在三度空間(分別為 x 軸、y 軸與 t 軸)上的
像素點資料，形成三維的運動軌跡立方體(motion-trace volume)，並以此為 ANN 訓練處理的輸入資
料，而每一個立方體於放大後之高解析度視訊影像中相對應的像素值，則為 ANN 訓練處理時的輸
出資料，經由 ANN 學習輸入與輸出資料之間的關係後，算出相對應的權重值。對於要進行超解析
度提升的視訊影像，只要收集其各像素點相對應的運動軌跡立方體，交由 ANN 測試處理進行非線
性運算後，即可預測出各像素點在超解析度提升(放大)後於高解析度影像的像素值。 
 
三、發表論文全文 
(論文全文列於本報告後段) 
  
四、建議 
CSNDSP 2012 是國際性的大型會議，也是 IEEE Computers and Communications 的年會，固定
每年舉行。這是一個全球性的會議，與會國家約 17 國共 300 多人參加，其中知名學者專家有 Prof. 
Z Ghassemlooy (Univ. of Northumbria, UK), Prof. R A Carrasco (Newcastle Univ. UK), Prof. E Leitgeb 
(Graz Univ. Austria), Prof. M D Logothetis (Patras Univ. Greece), Dr M Glabowski (Poznan Univ. of 
Tech), Dr P Zwierzykowski (Poznan Univ. of Tech)等 40 多位，其範圍理論和應用並重，包含各方面
領域，是個很多元化的研討會，適合產學界各專長參與。該研討會也將收錄優選論文於相關期刊
上，為全球各圖書館所收藏，且筆者參與此次研討會後獲益良多故極力推薦同仁、先進參加 CSNDSP 
2012 的研討會。 
 
 
Fast Video Super-resolution using  
Artificial Neural Networks 
 
Ming-Hui Cheng*, Nai-Wei Lin*, Kao-Shing Hwang**, and Jyh-Horng Jeng*** 
* Department of Computer Science and Information Engineering 
** Department of Electrical Engineering 
National Chung Cheng University 
Chiayi 621, Taiwan 
*** Information Engineering Department 
University of I-Shou University 
Kaohsiung 84001, Taiwan 
cmhvince@gmail.com, naiwei@cs.ccu.edu.tw, kshwang@ccu.edu.tw, jjeng@isu.edu.tw 
 
 
Abstract—In this study, video super-resolution using 
artificial neural network (ANN) is proposed to enlarge low-
resolution (LR) frames. The proposed super-resolution 
method consists of three main modules, i.e., motion-trace 
volume collection, ANN training, and ANN prediction. In 
the proposed method, the LR frames are super-resolved to 
HR frames through ANN. The traditional motion estimation 
is used to catch the motion-trace volume which eliminates 
the unfathomable object motion in the video. Then, the 
complex spatio-temporal detail between LR and HR data is 
learned by ANN. Using the ANN training results, the 
optimal weights can be determined for frame resolution 
enhancement in video. Simulation results show that the 
proposed method successfully improves the average peak 
signal-to-noise ratio (PSNR) and perceptual quality in 
super-resolved frames. 
I. INTRODUCTION 
Video super-resolution methods construct a high-
resolution (HR) frame from a set of successive low-
resolution (LR) frames in a video sequence by using 
image/video processing techniques. The application of 
video super-resolution has gained significant attention in 
both academia and consumer electronics industries, such 
as video surveillance [1], medical imaging [2], and 
satellite imaging [3]. However, how to explore the useful 
HR information from limited LR data to generate better 
super-resolved HR frame plays an important issue. In the 
recent years, many machine learning algorithms have been 
applied in image/video super-resolution [4,6].  
For machine learning based image super-resolution, K. 
Ni et al. [4] proposed an image super-resolution algorithm 
using support vector regression (SVR) to learn the relation 
between HR image and LR image in the transform 
domain. The input LR image is DCT transformed and 
extracted its feature vector in the transform domain. To 
yield better results, a classification method by using 
Gaussian mixture model is employed to find 
corresponding parameters. Based on the parameters, the 
super-resolved HR image is estimated by mix several 
SVR prediction results. 
In video, object motion plays a crucial role in modeling 
video signals. Classic video super-resolution methods [5] 
usually rely on the accurate (pixel and sub-pixel) motion 
estimation to explore the spatio-temporal information for 
HR frame generation. Takeda et al. [6] proposed a video 
super-resolution framework for enlarging of LR frames in 
the video without using sub-pixel motion estimation. 
Alternatively, instead of using sub-pixel motion 
estimation, which requires higher complexity, 
multidimensional kernel regression has been proposed to 
approximate the super-resolved HR frames. 
In this study, the motion-trace volume is caught by 
using motion estimation to eliminate the object motion. 
Then, ANN is employed to learn the detail of the spatio-
temporal correlation between LR data and HR data. Based 
on the ANN training results, a fast super-resolution 
method can be obtained by using ANN prediction. 
The present paper is organized as follows. In Section 2, 
artificial neural network (ANN) is briefly described. The 
details of the proposed method using ANN are described 
in Sections 3. Simulation results are presented in Section 
4, followed by the conclusion remarks. 
II. ARTIFICIAL NEURAL NETWORK 
Artificial neural network (ANN) is a biologically 
motivated learning machine inspired by the way of 
biological neurons and the nervous systems [7]. ANN 
serves as powerful computational tool for nonlinear 
prediction problem. In the feed-forward ANN, the 
artificial neurons are arranged in layers and all neurons in 
each layer have connections to all the neurons in the next 
layer. The connection process is multiply the given 
neurons by its weight.  
Consider an feed-forward ANN with an input layer of 
1+n  nodes, one hidden layer of 1+m  nodes with 
activation function f , and an output layer with p  nodes 
as shown in Fig.1. Here, x  is the input vector with n-
dimension ],...,2,1,[: nixi ==x  and y  is the output vector 
with p-dimension ],...,2,1,[: pkyk ==y . The connection 
weights vector are denotes as v  and w , respectively. The 
basic structure of a neuron can be theoretically modeled as 
shown in Fig. 2, where ix  represent the inputs to the 
neuron and Y  represents the output. Each input is 
multiplied by its weights iw  and their sum goes through a 
activation function f . The activation function can be a 
linear or nonlinear function. The identity function usually 
8th IEEE, IET International Symposium on Communication Systems, Networks and Digital Signal Processing978-1-4577-1473-3/12/$26.00 ©2012 IEEE
which including, the 555 ××  motion-trace volume from 
LR frames and corresponding ll ×  HR pixels value from 
HR frames. In this study, K pairs training data will be 
collected. In ANN training process, the 555 ××  motion-
trace volume and ll ×  HR pixels data are regarded as an 
125-dimensional (125-D) input vector x and 2l -
dimensional ( 2l -D) output vector y, respectively. All the 
training data will be normalized to [1,0] before feed into 
ANN training process. After ANN training, the weights 
vector v and w for connection process of each neuron will 
be got. 
C. ANN prediction 
In ANN prediction, each pixel in the LR frame to be 
super-resolved will collect its own 555 ××  motion-trace 
volume. The 555 ××  motion-trace volume is regarded as 
125-D input vector and connection process with the given 
weights v and w. Finally, the 9-D output vector is 
approximated and regarded as the 33×  HR pixels data in 
the super-resolved frame. After all volume in LR frame 
are processed, an HR super-resolved framed can be 
reconstructed. 
 
IV. SIMULATION RESULTS 
In the current study, the experiments are conducted 
using Borland C++ Builder on an Intel Core i5 CPU 2.5 
GHz-Microsoft Windows platform. Three test video 
sequences, i.e., Miss American, Mother-daughter, and 
Foreman, are used to evaluate the performance of the 
proposed method. For comparison purposes, the proposed 
method and two other methods, i.e., bicubic interpolation 
(Bicubic), and the modified NLM SR algorithm (modified 
NLM), are implemented [5]. The magnification factor l is 
set to three. The LR frames are obtained as follows: (1) 
each original HR frame is decimate by a magnification 
factor of three and (2) added by an additive Gaussian 
noise with zero mean and variance with four. The 
numbers of frames in the three test video sequences are 
identically 100. 
In this study, the search range R for motion estimation 
is set to 7. The total numbers of training data K is equal to 
13500. The quantity of input data n, output data p, and 
hidden nodes m, is set to 125, 9, and 34, respectively, such 
that, 34126×  weights v and 935×  weights w will be 
optimal approximated in ANN. The peak signal-to-noise 
ratio (PSNR) of a super-resolved frame is defined as 
),MSE/255(log20PSNR 10 ⋅⋅=  (1) 
where MSE is the mean square error between the super-
resolved frame and the original full-resolution frame. The 
average PSNR of a video sequence is the average PSNR 
value over all super-resolved frames in the video 
sequence. 
The performance of the average PSNR of the three 
methods with the magnification factor of three for the 
Miss American, Mother-daughter and Foreman clips is 
shown in Table I, respectively. The performance of the 
proposed method is “much” better than those of the two 
comparison methods for all video sequences. For visual 
comparison, the super-resolved results of the 43th frame 
of the Foreman video sequence are shown in Fig. 5. Fig. 
5(a) shows the ground truth, and Fig. 5(b)-(d) shows 
Bicubic, Modified NLM, and the proposed method, 
respectively. For overall comparison, the proposed 
method is not stiff like modified NLM and more better 
than Bicubic. To emphasize the visual effect, some details, 
such as the face parts, are shown in Fig. 6. As observed, 
the visual effect of the image edges of the proposed 
method [Fig. 6(d)] is superior to that of all the other 
methods. 
 
(a) (b) 
(c) (d)
Figure 5. The 43th LR frame of the Foreman video sequence with 
magnification factor of three: (a) ground truth, (b) Bicubic, (c) Modified 
NLM, and (d) the proposed method. 
 
(a) (b)
(c) (d)
Figure 6. Face part of the 43th frame of the Foreman video sequence: (a) 
ground truth, (b) Bicubic, (c) Modified NLM, and (d) the proposed method. 
TABLE I. Comparison of the averaged PSNR of the four methods on the 
three video sequences with magnification factor of three. 
 Bicubic Modified- NLM Proposed 
Miss American 33.82 33.90 37.77
Mother-daughter 29.62 29.12 33.29
國科會補助計畫衍生研發成果推廣資料表
日期:2013/01/25
國科會補助計畫
計畫名稱: 非線性類神經網路於影像編碼之應用
計畫主持人: 鄭志宏
計畫編號: 99-2221-E-214-053-MY2 學門領域: 視訊與影像分析
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
