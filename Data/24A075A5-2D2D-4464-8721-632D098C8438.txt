important parameter especially for increasing 
multimedia applications. The reason is no clue of 
packet delay can be easily given. In literature 
survey, we found a few works that analyze the average 
packet delay but only for a single QoS type, e.g. 
UGS. A general analysis of delay for all five QoS 
service classes under multiple users and connections 
is still unseen. It is the issues that trigger the 
proposal.  
 
The objective of this research proposal has two 
folds. Firstly, the project is about to build up 
appropriate queuing models and derive the general 
framework for delay analysis. Secondly, we propose a 
dynamic bandwidth reallocation concept, and design 
call admission control and bandwidth allocation 
algorithms with bandwidth and delay guarantee that 
may fulfill users＇ requests, in considering both the 
timely and fair basis. With dynamic reallocation 
mechanism, the resource utilization can definitely 
increase but the blocking probability will decrease. 
The final results are to be verified through 
intensive computer simulation since it can not only 
confirm the correctness of mathematical modeling but 
also help evaluating the performance of proposed 
algorithms.  
 
英文關鍵詞： WiMAX, Bandwidth and Delay guarantee, Dynamic 
bandwidth reallocation, QoS architecture, Admission 
control and resource allocation. 
 
 
 
摘要 
自 IEEE 802.16 系列標準規格問世來，投入相關研究者不知凡幾，最新的 IEEE 802.16m
規格雖未正式完成，但已被國際電信聯盟(ITU)視為 IMT-Advanced Technology、預期也將成為
第四代(4G)主要行動通訊技術之一。規格書中未提及的 MAC/PHY 管理模組，是影響整體系
統效能的因素，其中無線資源管理更是一項重要課題，所以有許多研究者投入 QoS 架構、允
入控制、頻寬配置與排程設計等課題。經過文獻研析發現絕大部分只考慮滿足使用者連線的
頻寬需求，另一個重要的參數-傳輸延遲(packet delay)限制都未考慮到，也發現缺乏能同時估
測多個排程服務的封包延遲的數學模型，這個問題觸發了本研究之動機。 
本研究計畫分做兩個階段。首先本計畫將建構排隊模型，推導 WiMAX 無線寬頻網路的
系統延遲，然後再以此估測之系統延遲時間，依據 IEEE 802.16-2009 規格書之 QoS 描述，提
出一個動態頻寬重分配機制(dynamic bandwidth reallocation)機制，設計出一套完整的允入控制
(admission control)與頻寬分配(bandwidth allocation)演算法，期能在盡量滿足使用者頻寬與延
遲以及資料傳輸服務品質的要求下，同時充分有效地運用系統資源，兼顧資源配置的及時性
與公平性，達到提升整體網路運作效能之目標。除了數學建模與分析外，本計畫也會以電腦
模擬的方式來驗證數學模型的正確性，以及評估所設計的演算法之效能。   
 
關鍵詞：全球互通微波存取技術(WiMAX)，頻寬與延遲保證，動態可重分配機制，QoS 架構，
允入控制與資源配置。 
 
Abstract 
There are tremendous scholars devoted themselves to WiMAX related research topics since 
IEEE 802.16 standard presented to the public. The latest standard IEEE 802.16m has not finalized 
yet, but it has been chosen as a candidate technology for 4th generation (4G) mobile 
communications. Among interesting research areas, those issues in radio resource management such 
as QoS architecture, admission control, bandwidth allocation, and packet scheduling defined 
unclearly in the standard draw much attention. Although there are many wireless technologies with 
QoS support proposed, the definition on QoS for WiMAX is the most complete one. In terms of 
QoS, most studies concerned only the bandwidth requirement but not the delay – an important 
parameter especially for increasing multimedia applications. The reason is no clue of packet delay 
can be easily given. In literature survey, we found a few works that analyze the average packet 
delay but only for a single QoS type, e.g. UGS. A general analysis of delay for all five QoS service 
classes under multiple users and connections is still unseen. It is the issues that trigger the proposal.  
 
The objective of this research proposal has two folds. Firstly, the project is about to build up 
appropriate queuing models and derive the general framework for delay analysis. Secondly, we 
propose a dynamic bandwidth reallocation concept, and design call admission control and 
bandwidth allocation algorithms with bandwidth and delay guarantee that may fulfill users’ requests, 
in considering both the timely and fair basis. With dynamic reallocation mechanism, the resource 
 
 
(packet delay)。因為資料封包經過網際網路的延遲無法預估，而WiMAX又屬於接取網路
技術，因此所謂的延遲保證考慮的就是使用者到基地台這一段。如果能合理準確的推導
出WiMAX網路系統中的各種服務之封包延遲，並運用此資訊設計允入與頻寬配置演算
法則（如此就不必擔心排程(packet scheduling)機制為何），確保兼顧頻寬與延遲之需求，
充分利用無線傳輸頻寬，提高通訊系統之效能，也可以作為WiMAX基地台佈建以及規
劃的參考。 
 
二、 計畫目的 
在細胞式(cellular)無線通訊系統之資源管理技術中，有數個主要探討的領域，分別
是允入控制(call admission contro1)、頻寬分配(bandwidth allocation)、封包排程(packet 
scheduling)、遞交（或換手）控制(handover control)、功率控制(power control)及負載平
衡(Load Balance)。這些技術領域彼此相關連，一個模組的決定結果都可能會影響到其他
模組之決定策略。例如：允入控制、頻寬分配以及封包排程所使用的演算法，往往是決
定整個網路系統效能優劣的主要因素。一般所使用的允入控制及頻寬分配都是根據規格
書中所定義的基本QoS參數，設計出一個演算法使其能在不同的網路環境下做出最合適
的決定。舉例來說，最常被使用的QoS參數是最大持續流量(maximum sustained traffic rate)
以及最小保留流量(minimum reserved traffic rate)，而最簡單的允入控制法則即是檢視這
兩個QoS參數，若要保留的資源小於目前剩餘的資源，即可接受此連線要求。然而，若
只檢視最大持續流量或最小保留流量，當可滿足這兩個參數之後就接受此連線要求而忽
略其他QoS參數，可能會使得在後續資料的傳輸上無法滿足最大延遲時間(maximum 
latency)或可忍受延遲變動率(tolerated jitter)等其他QoS參數。為了盡量滿足所有的QoS參
數，大多數的研究文獻中，在探討允入控制以及頻寬分配時，常加入排程(scheduling)
機制配合，但這同時也增加了設計之複雜度。因此，若能簡化排程機制，同時又可設計
出一套可滿足頻寬需求以及延遲需求的允入控制以及頻寬分配演算法則，則將可讓BS
在運行資源管理演算法時更有效率。 
因此，本研究計畫之目的主要分為兩部份。首先，我們將利用適當的排隊模型
(queuing model)以及馬可爾夫鏈理論(Markov Chain)，建立分析及設計出一套完整的數學
模型。利用此數學模型，只要輸入適當的網路參數，即可得到此網路系統對不同的排程
服務的系統延遲。本計畫也將利用電腦模擬的方式來驗證數學模型的正確性。第二部份
則將根據第一部份的研究成果，在已經可預知系統延遲的情況下，再配合動態頻寬重分
配機制(dynamic bandwidth reallocation)機制，設計出一套完善的允入控制及頻寬分配演
算法，期能在盡量滿足使用者頻寬與延遲以及資料傳輸服務品質的要求與有效地配置系
統資源下，兼顧資源配置的及時性與公平性，達到提升整體網路運作效能之目標。 
 
三、 文獻探討 
 
 
SDP (Single-access Direct-estimate Prob.), SEB (Single-access Exponential Backoff)；文獻
[26]提出了在無線網路下以正交互補編碼法，來解決相關問題。本計畫希望能從中找出
適合於WiMAX架構下的碰撞解析機制，以求在建立數學模型時，能有效的描述碰撞發
生時系統的運作。 
綜觀文獻可知，在分析WiMAX系統的封包延遲議題上，雖然已有文獻呈現出很好
的結果，但大多數都是只針對單獨一種排程服務去做數學分析，還沒有學者提出一套完
善的數學模型可以同時計算出多個排程服務的封包延遲，這也將是本計畫所達成的目標
之一。而在允入控制與封包排程方面，目前只有文獻[22]所提出的機制能同時滿足服務
流的頻寬以及延遲要求。本計畫也將利用類似的概念，一方面利用本計畫所推導出的封
包系統延遲，另一方面改善文獻[22]所提的機制之缺點，設計出一套允入控制與頻寬重
分配的機制。 
   
四、 研究方法、結果與討論 
本研究計畫同時使用理論推導以及電腦模擬的方式。首先將利用適當的排隊模型以
及馬可爾夫鏈理論，建立分析及設計出一套用來預測系統延遲的數學模型。而後再從目
前可得的模擬軟體平台中選擇最適合的一種作為模擬工具，發展出符合本計畫的
WiMAX系統模組，並利用此模組來驗證先前設計出的數學模型，以及對整體運作效能
評估進行分析。本計畫將分以下五個項目分別進行：錯誤! 找不到參照來源。錯誤! 找
不到參照來源。；錯誤! 找不到參照來源。錯誤! 找不到參照來源。；錯誤! 找不到參
照來源。錯誤! 找不到參照來源。；錯誤! 找不到參照來源。錯誤! 找不到參照來源。；
錯誤! 找不到參照來源。錯誤! 找不到參照來源。。 
圖一是封包如何從MS(mobile station)傳送到BS(base station)的示意圖，圖的上半部
份是封包的傳輸過程，而下半部則是TDD的訊框，也畫出TDD訊框的用意是做為時序的
參考。在圖一的上半部中，水平線代表封包傳輸過程中經過的邏輯或實體單元，可能是
佇列、緩衝器或是其他傳輸介面；由下往上的箭頭代表在該時間點時，封包從下方的邏
輯或實體單元傳輸到上方的邏輯或實體單元。因此，由圖一中可以得知，對單獨一個封
包而言，假設Cn封包在到達MS之後，會先暫存在MS 的佇列中。而後，當一個新的訊
框開始之後，MS接收到由BS廣播出的UL-MAP，得知BS分配的上傳區間以及可傳送的
封包數量，因此將目前佇列中的Cn封包送到傳輸緩衝器中等待傳送。等到上傳鏈路子訊
框開始之後，MS可在自己分配到的時間點開始傳送Cn封包，經過一段傳輸時間後，Cn
封包會到達BS的接收緩衝器。而後，BS在上傳鏈路子訊框結束之後才開始處理它所收
到的Cn封包，處理完畢之後則將其放置在BS Queue中，等待後續的傳送。 
 
 
服務b個封包，則在IEEE 802.16網路中的上傳鏈路封包傳輸即可使用M/Db/1排隊模型來
表示。 
必須一提的是，上述的解釋是以UGS連線為例，若MS是使用其他種類的排程服務，
則封包傳輸的流程將會有些許不同。舉例來說，若是使用rtPS排程服務時，BS會週期性
的利用polling的方式，在UL-MAP中配置Request IE詢問MS是否有頻寬的需求；若有，
則MS會在上傳鏈路子訊框中傳送頻寬要求，BS收到之後才在下一個訊框中，配置資源
給該MS。因此，此時的傳輸媒介同樣可視為一個固定服務時間的server，但其服務時間
將變成兩個訊框的長度。 
若是使用nrtPS或是BE排程服務時，由於有可能是使用基於競爭方式的頻寬要求方
式，因此有可能會發生因競爭而造成的訊號碰撞，進而使得BS無法正確的接收到頻寬要
求。為了能正確的描述出這種現象，前述的排隊模型必須加以修改，進而使得推導出的
數學模型變得更為複雜，這也是本計畫所必須要克服的問題之一。本計畫後續將深入研
究當使用其它排程服務，如何設計出一個適合的排隊模型以利分析。雖然不同的排程服
務會有不同的封包傳輸流程，但我們相信最後都可利用M/Db/1排隊模型或其變形(例如
M/Da,b/1排隊模型)來表示，這些都是本計畫後續所要繼續研究探討的。 
 
五、 計畫成果自評 
本計畫執行順利，與原計畫書預定完成項目相符，另有延伸成果產出。參與之研
究生中有一位碩士生以本計畫相關成果為其碩士畢業論文 [23]。計畫部分成果彙整成
論文發表於 2011 年「全國電信研討會」[24]，另有兩位博士生參與發表 EI 期刊論文[25]
及 EI 國際會議論文[26]各一篇。 
  
六、 參考文獻 
[1] Draft Amendment to IEEE Standard for Local and Metropolitan Area Networks Part 16: 
Air Interface for Fixed and Mobile Broadband Wireless Access Systems, IEEE 
P802.16m/D10, 2010. 
[2] IEEE Standard for Local and Metropolitan Area Networks Part 16: Air Interface for 
Broadband Wireless Access Systems, IEEE Std 802.16-2009, 2009. 
[3] IEEE Standard for Local and Metropolitan Area Networks Part 16: Air Interface for 
Fixed Broadband Wireless Access Systems, IEEE Std 802.16-2004, 2004. 
[4] IEEE Standard for Local and Metropolitan Area Networks Part 16: Air Interface for 
Fixed and Mobile Broadband Wireless Access Systems Amendment 2: Physical and 
Medium Access Control Layers for Combined Fixed and Mobile Operation in Licensed 
Bands, IEEE Std 802.16e-2005, 2005. 
[5] IEEE Standard for Local and Metropolitan Area Networks Part 16: Air Interface for 
Fixed Broadband Wireless Access Systems- Amendment 1: Management Information 
 
 
[19] S. H. Wong and I. J. Wassell, “Dynamic channel allocation for interference avoidance in 
a broadband fixed wireless access network,” in 3rd International Symposium on 
Communication Systems Networks and Digital Signal Processing (CSNDSP02), 2002, 
pp. 352–355. 
[20] G. Song and Y. Li, “Adaptive resource allocation based on utility optimization in ofdm,” 
in IEEE Global Telecommunications Conference, 2003. GLOBECOM ’03, vol. 2, 2003, 
pp. 586–590. 
[21] K. Gakhar, M. Achir, and A. Gravey, “Dynamic resource reservation in ieee 802.16 
broadband wireless networks,” in 14th IEEE International Workshop on Quality of 
Service, 2006. IWQoS 2006, 2006, pp. 140–148. 
[22] S. Kalikivayi, I. Misra, and K. Saha, “Bandwidth and delay guaranteed call admission 
control scheme for qos provisioning in ieee 802.16e mobile wimax,” in IEEE Global 
Telecommunications Conference, GLOBECOM ’08, Dec. 2008, pp. 1–6. 
[23] 黃筱婷、柯開維*、吳和庭，行動式 WiMAX 中具動態頻寬重配置之可適性允入控
制設計與效能，NST 2011 全國電信研討會，Nov. 18-19，花蓮，台灣。 
[24] 黃筱婷著，行動式 WiMAX 中具動態頻寬重配置之可適性允入控制架構，碩士論 
文，國立台北科技大學資訊工程系碩士班，台北，2011。 
[25] Chen-Nien Tsaia, Kai-Wei Ke* and Ho-Ting Wu, “Approximate Packet Delay Analysis 
for IEEE 802.16 Networks,” Advanced Materials Research: Materials Science and 
Information Technology, Vols. 433-440, pp 5063-5067, 2012. (EI) 
[26] Chia-Hui Huang, Kai-Wei Ke* and Ho-Ting Wu, “The Design of Multisource 
Application Layer Multicast with Fast Route Recovery,” The 9th IEEE International 
Conference on Ubiquitous, Intelligence and Computing (UIC 2012), Sept. 4-7, 2012, 
Fukuoka, Japan. (EI) 
System Operation and Modeling 
In a typical IEEE 802.16 network operating in point-to-multipoint (PMP) mode, several mobile 
stations (MSs) and subscriber stations (SSs) served by a single base station (BS). We suppose there 
are one BS and N MSs in the network. The MAC layer in the IEEE 802.16 networks is 
connection-oriented, and many connections may be created between MSs and the BS during the 
system is running. During the creating of a connection, the BS has to examine the QoS parameters 
associated with the connection. The connection is admitted to the system only if the BS can satisfy 
these QoS parameters. Otherwise, the connection will be rejected. This procedure is also known as 
the admission control. 
After the connection is admitted, it is able to follow the IEEE 802.16 protocol to send or receive 
packets. In this paper, we consider only the uplink traﬃc; that is, the packets are transmitted from a 
MS to the BS. We deﬁne that a connection using UGS scheduling service is a UGS connection, in 
which several QoS parameters are associated with, such as maximum sustained rate (MSR) and 
minimum reserved rate (MRR). 
Assuming that there are Ui UGS connections in processing between MS i and the BS. Each MS 
maintains separate buﬀers with inﬁnite capacity for each connection. To satisfy the QoS of the UGS 
connections, the BS has to grant suﬃcient bandwidth to MS i. The number of bandwidth allocated to 
MS i is depending on the admission control and/or bandwidth allocation algorithms. 
No matter what the admission control or bandwidth allocation algorithms are used, we suppose 
that the BS will allocate Bi bits to MS i per frame. Since there are Ui connections in MS i, the MS has 
to allocate Bi bits to those connections with a proper scheduling algorithm. It follows that the 
bandwidth allocated to a connection j is 
i
i
ji
U
B
b =,   bits if wireless fair queueing is used. We further 
assume that the packet length l is ﬁxed, the number of packets can be transmitted per frame for 
connection j in MS i will be 
l
b
n
ji
ji
,
, =   . In other words, the connection j in MS i can transmit at most 
ni,j packets in every frame; or equivalently, the air interface can serve a batch of packets with size ni,j 
for connection j in MS i in every frame. 
The time diagram for packet transmission via a connection can be illustrated in Fig. 1. In the figure, 
the horizontal time lines represent logical or physical entities. An arrow approaching the lines from 
below indicates that a packet (e.g., Cn) arrives to the entity. Arrows emanating from the line indicate 
the departure of a packet from the entity. To illustrate the relative timing with the frames, the bottom 
part of the figure shows the WiMAX frame structure. 
Fig. 1a shows the actual time diagram for packet transmission. For any MS, there may have many 
packets arrive and wait for transmission. The MS classifies these packets to a proper connection 
according to the predefined rules. The classified packets (Cn, Cn+1, and Cn+2 in Fig. 1) are put in the 
queue. When a MS received the UL-MAP, it examines the UL-MAP to know the time to send packets, 
runs the scheduling algorithm to decide which of its data to transmit during this allocation, and puts 
the scheduled packets in the transmission buffer waiting for transmitting. Note that the packets enter 
the transmission buffer only after the MS received the UL-MAP. The packet will stay in the 
connection queue if no UL-MAP received. Also note that according to the standard, the UL-MAP can 
describe the allocations in the UL subframe of either the current or the next frame. For the sake of 
simplicity, this paper assumes on the former case. 
After all, the packets in the transmission buffer will be transmitted to the BS through the air 
interface. Despite of the packets may arrive at the BS sequentially, the BS processes all received 
packets only after the end of the UL subframe. The packets those arrived earlier are stored in the BS's 
reception buffer and waiting for further process. Before the packets are processed, the packets are 
unable to be transported to other nodes in the network. In this sense, it is equivalent that the received 
packets are still being “served” even they are already in the BS. The service is completed after the BS 
processed the packets. 
5064 Materials Science and Information Technology
where b is the batch size and dk indicates the probability with k packets arrivals during a service 
phase. Since we have a Poisson arrival process and the duration of a service phase, T, is fixed, dk can 
be obtained as tk e
k
t
d λ
λ −=
!
. 
It is worthy noting that the embedded Markov chain involves an infinite state space and the infinite 
set of equilibrium equations. What one usually does to solve the infinite set of equilibrium equations 
of a Markov chain is to approximate the infinite-state Markov model by a truncated model with finite 
states. The probability mass of the deleted states from the original Markov model should be very 
small. However, such brute-force approximation often leads to a finite but very large linear system. 
To obtain the numerical solution of such system requires large computation power and is 
time-consuming. In this study, therefore, we use a different way called “geometric tail approach” to 
obtain the steady-state probabilities [7]. The geometric tail approach results in a finite system of 
linear equations whose size is much smaller than the size of the finite system obtained from the 
brute-force approach.  
We can prove that the steady-state probabilities of the embedded Markov chain exhibit geometric 
tail behavior and therefore obtain the steady-state probabilities with the procedure stated in [7]. Due 
to the space limitation, hoverer, the proof is skipped. After we obtained the steady-state probabilities, 
the average queue length L can be obtained as ∑ ==
M
k jq
kL
0
π , where M is the number of linear 
equations after applied geometric tail approach. From Little's Law, the approximated average packet 
queuing delay Dq can be calculated as 
λ
q
q
L
W = . 
We can use Dq to obtain the system delay D. Note that the system delay is defined as a time period 
between the time that the tagged packet entered the queue and the time that the tagged packet arrived 
at the BS. For a UGS connection, the duration of a service phase is T. Therefore, the system delay will 
be W = Wq + Tf. 
Numerical Results: Computation and Simulation 
This section presents the numerical results obtained from the mathematical model presented in the 
previous section. To verify the model, we also conducted simulations for comparisons, which was 
done with OMNeT++ 4.1 [8]. The simulation scenario consists of a BS and multiple MSs. Every MS 
is connected to the BS with a UGS connection. Since UGS connections are independent to each other, 
we can just focus on one MS.  
The simulation model follows the frame structure defined in the standard. The BS allocates the 
bandwidth in the UL-MAP and broadcasts this information at the beginning of the DL subframes. The 
MS can transmit the data to the BS only during the UL subframes. We set the frame duration T as 
5ms. The MSR for the UGS connection is 1,921,000 bps, which is the highest value in the standard 
(Table 187 in [2]), and is high enough to hold multiple packets in a frame. The packet length is set to 
600 bits, resulting in 16
600
005.0000,921,1
=


 ×
  packets can be transmitted per frame. For every 
simulation run, we also present the confident intervals with the 95 % confident level and 5 % relative 
error [9]. 
The difference between the theoretical values obtained from the mathematical model and those 
obtained from the computer simulation is shown in Fig. 2. The vertical bars around the simulation 
values are the confident intervals. We can see that the theoretical values are within the confident 
intervals. Furthermore, their differences are very subtle. This comparison would be helpful to 
persuade the correctness of the mathematical model done in Section 3. 
 
 
5066 Materials Science and Information Technology
Materials Science and Information Technology 
10.4028/www.scientific.net/AMR.433-440 
 
 
Approximate Packet Delay Analysis for IEEE 802.16 Networks 
10.4028/www.scientific.net/AMR.433-440.5063 
 低 level 就能夠接受，此時如果降到最低 level 時，剩餘
頻寬仍小於新連線所要求的頻寬，就表示 BS 無法滿足
此連線請求，就只能拒絕此要求。若經過計算後發現降
階之後就夠，就會開始從 nrtPS 的連線一個一個開始降，
若是只降 nrtPS 的連線就夠了的話，就會做降階的動作
之後接受此連線；若是發現降完 nrtPS 的連線還是不夠，
就要把 nrtPS 的連線們都降到最低 level 後，開始對 rtPS
的連線個別作降階的動作，直到剩餘頻寬大於新連線所
要求的頻寬，始可接受新連線的請求。 
 
圖一： 動態調適頻寬之允入控制架構流程圖 
 
當有一個 ertPS 連線對 BS 提出連線請求時，會先看
此請求是遞交連線或是新連線提出的；若是新連線提出
的請求,就要看剩餘頻寬是否大於 b2/2，若是新連線提出
的請求且剩餘頻寬小於 b2/2，就會直接拒絕此連線請求。
否則若是新連線提出的請求且剩餘頻寬大於等於 b2/2，
或是此時提出頻寬請求的是遞交連線，則會看剩餘頻寬
是否大於所要求頻寬。若剩餘頻寬大於所要求頻寬時，
表示系統目前能不做任何動作，直接接受此頻寬要求；
否則就要檢查是否將 rtPS 和 nrtPS 的連線都降到各自的
最低 level 就能夠接受，此時如果降到最低 level 時，剩
餘頻寬仍小於新連線所要求的頻寬，就表示 BS 無法滿
足此連線請求，就只能拒絕此要求。若經過計算後發現
降階之後就夠，就會開始從 nrtPS 的連線一個一個開始
降，若是只降 nrtPS 的連線就夠了的話，就會做降階的
動作之後接受此連線；若是發現降完 nrtPS 的連線還是
不夠，就要把 nrtPS 的連線們都降到最低 level 後，開始
對 rtPS 的連線個別作降階的動作，直到剩餘頻寬大於新
連線所要求的頻寬，始可接受新連線的請求。 
對於 QoS 類別為 rtPS 的遞交連線，由於是即時性服
務又是遞交用戶，因此我們設計此種類型的連線可調降
nrtPS 與 rtPS 的連線頻寬，因此當收到此種連線請求時， 
BS 端會檢查所提出的頻寬需求是否合理(介於 rtPS1 與
rtPS3 之間)，若不合理就會直接拒絕此連線請求。若是
合理的頻寬需求，就會接著檢察系統目前的剩餘頻寬是
否大於提出的連線請求頻寬，如果剩餘頻寬大於請求頻
寬，就會接受此連線請求；否則就會開始調降 nrtPS 連
線的頻寬，若是調降 nrtPS 連線的頻寬之後挪出的可用
頻寬即大於請求頻寬，就會接受此連線請求；否則就會
繼續調降 rtPS 連線的頻寬，若是經過調降 rtPS 連線的頻
寬仍無法滿足此連線需求，就會拒絕此連線請求，反之
則會接受此連線請求。 
對於 QoS 類別為 rtPS 的新連線而言，因為 rtPS 為即
時性服務，因此我們設計此種類型的連線可調降 nrtPS
的連線頻寬，當這種類型的連線提出連線請求時，BS
會先檢查所提出的頻寬需求是否合理，如果是合理的頻
寬請求，就會檢查剩餘頻寬是否大於提出的頻寬請求，
是否能直接接受此連線，若是頻寬需求不合理，則會直
接拒絕此連線請求。如果剩餘頻寬大於連線請求頻寬，
就會直接接受此連線請求；反之則會計算是否調降
nrtPS 的連線頻寬就能夠接受此連線，如果經過降階就
有足夠頻寬給此連線就接受，否則就拒絕此連線請求。 
對於 QoS 類別為 nrtPS 的遞交連線而言，因為是屬於
遞交用戶但是並非即時性服務，由於遞交用戶不希望服
務被中斷，因此在這裡我們設計此種類型的連線可調降
nrtPS 的連線頻寬。當有一個 nrtPS 的遞交連線對 BS 提
出頻寬請求的時候，BS 一開始會檢查所提出的頻寬需
求是否合理(介於 nrtPS1 與 nrtPS3 之間)，若是提出的頻
寬要求是合理的，則會開始看目前剩餘頻寬是否大於等
於所要求頻寬；否則就會拒絕此連線請求。如果剩餘頻
寬大於等於所要求頻寬，就會接受此連線請求；反之，
若是剩餘頻寬小於所請求的頻寬，就會看是否將 nrtPS
的連線降階就可以接受此連線，如果降階之後便足夠就
會接受，否則就會拒絕此連線要求。 
對於 New Call nrtPS 的連線而言，因為是屬於非即時
性服務，雖然對於頻寬有要求，但是對連線的延遲沒有
要求，而在 IEEE 802.16 的規範中，其優先權僅大於 BE，
因此如果當系統接近滿載時，當有即時性的服務需要進
入，因為此種服務並未對延遲性有要求，因此可減少這
種類型服務的頻寬，做降階的動作，提供即時性服務的
連 線 要 求 ， 所 以 我 們 設 計 對 於 此 種 連 線 請 求 採 取
Complete Sharing 的方式，也就是不能做降階的動作來
使自己增加建立連線的機會。一旦 BS 收到此種頻寬需
求的連線要求時，如果提出的頻寬要求是合理的，就會
進一步檢查目前剩餘的頻寬是否足夠提供給此連線，若
是足夠就會接受此連線請求，不夠則會予以拒絕。 
另外，當有連線服務完成要離開系統時，就會啟動
頻寬重配置機制，系統會先將要離開的連線數扣掉，之
後計算新的剩餘頻寬，接著計算新的剩餘頻寬能分配給
幾個 rtPS3 的連線使其升至具較大頻寬的 rtPS 服務層級， 
若是將 rtPS3 的連線升完之後還有剩餘頻寬，則會給
rtPS2 的連線使用。當 rtPS 的連線都升完之後，若是還
有剩餘頻寬，則會依循 nrtPS3 先升之後 nrtPS2 的原則，
直到剩餘頻寬全部用完或者所有連線都已是其 QoS 等級
的最高服務層級為止。 
三、 系統描述與分析模型 
假設是根據卜松程序對系統新通話的要求(connection 
request)，且遞交用戶的資料傳輸類型為 UGS、ertPS、
rtPS 與 nrtPS 的請求到達率分別為 λhu、λhe、λhr 與 λhn，
而新用戶的資料傳輸類型為 UGS、ertPS、rtPS 與 nrtPS
的請求到達率分別為 λnu、λne、λnr 與 λnn，此外我們在假
設系統中每種 QoS 的呼叫持續時間與呼叫存在時間是呈
 入資源重配置的結果(BD_CAC)與完全分配(CS)做比較，
其中橫軸是系統負載，由於我們給予遞交用戶較高的優
先權，因此從這圖二至圖五中可以看出交遞中斷率都是
低於阻斷機率的，並且對於沒有做允入控制的 CS 來說，
其交遞中斷率都遠高於另外兩者的交遞中斷率，因此從
這裡可以看出我們提出的允入控制機制並不會因為持續
降階或是頻寬回復的因素就造成乒乓球效應，無論是
BD_CAC 或是 BDU_CAC 都是有效且偏好遞交用戶的，
並且在 BDU_CAC 中也得到了較好的頻寬使用率。 
圖六顯示了在不同的系統負載下，系統無線頻寬資
源的使用率，從圖上可以看出，加入了頻寬重配置的演
算法(BDU_CAC)能達到最高的頻寬資源使用率，在系統
接近滿載時，可以達到 82%的頻寬使用率，但 CS 只有
68%，BD_CAC 更是只有 65%。 
 
 
圖二： UGS 連線之阻斷機率和交遞中斷率的比較 
 
 
圖三： ertPS 連線之阻斷機率和交遞中斷率的比較 
 
圖四： rtPS 連線之阻斷機率和交遞中斷率的比較 
 
 
圖五： nrtPS 連線之阻斷機率和交遞中斷率的比較 
 
 
圖六：不同的系統負載下，系統頻寬資源使用率情況 
 
五、 結論 
由數值分析的結果可知，在此種通訊網路架構中，
隨時為系統頻寬資源作動態重配置的處理，才可將無線
資源做充分利用。為了提升頻寬使用率，除了允入控制
的機制之外，還需要加上頻寬重配置的機制，當有連線
要離開時將重新分配目前連線使用的頻寬，讓珍貴的頻
寬資源得以充分利用，同時也因為重分配的關係拿到較
多頻寬的連線就能縮短在系統中的服務時間，提升系統
效能，滿足 QoS 的需求。 
 
參考文獻 
[1] IEEE Std 802.16-2004, “IEEE Standard for Local and Metropolitan 
Area Networks Part 16: Air Interface for Fixed Broadband Wireless 
Access Systems,” October, 2004. 
[2] IEEE Std 802.16-2009, “IEEE Standard for Local and Metropolitan 
Area Networks Part 16: Air Interface for Broadband Wireless Access 
Systems,” May, 2009 
[3] H. Wang, W. Li, and D.P. Agrawal, “Dynamic admission control and 
QoS for 802.16 wireless MAN,” Wireless Telecommunications 
Symposium, pp. 60 - 66, Apr. 2005. 
[4] K. Wongthavarawat and A. Ganz, “Packet scheduling for QoS 
support in EEEE 802.16 broadband wireless access systems,” Military 
Comunications Conference, IEEE 2003. 
[5] S. Kalikivayi, I.S. Misra, and K. Saha, “Bandwidth and Delay 
Guaranteed Call Admission Control Scheme for QOS Provisioning in 
IEEE 802.16e Mobile WiMAX,” IEEE conference on Global 
telecommunications, pp. 1-6, 2008. 
[6] Jia-Hao Hsu, Kai-Wei Ke, Ho-Ting Wu, and Chen-Nien Tsai, “行動
數據通訊網路基於理論之動態重配置與可適性資源管理機制及效
能分析,”Proceedings of National Computer Symposium, NCS’2005, 
MC-19, 15-16 Dec. 2005. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.07 0.55 1.03 1.51 1.99 2.47 2.95 3.43
B
lo
ck
in
g 
an
d 
D
ro
pp
in
g 
Pr
ob
ab
ili
ty
Offered Load
CS_DP/BP
BD_DP
BDR_DP
BD_BP
BDR_BP
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.07 0.55 1.03 1.51 1.99 2.47 2.95 3.43
B
lo
ck
in
g 
an
d 
D
ro
pp
in
g 
Pr
ob
ab
ili
ty
Offered Load
CS_DP/BP
BD_DP
BDR_DP
BD_BP
BDR_BP
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.07 0.55 1.03 1.51 1.99 2.47 2.95 3.43
B
lo
ck
in
g 
an
d 
D
ro
pp
in
g 
Pr
ob
ab
ili
ty
Offered Load
CS_DP/BP
BD_DP
BDR_DP
BD_BP
BDR_BP
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.07 0.55 1.03 1.51 1.99 2.47 2.95 3.43
B
lo
ck
in
g 
an
d 
D
ro
pp
in
g 
Pr
ob
ab
ili
ty
Offered Load
CS_DP/BP
BD_DP
BDR_DP
BD_BP
BDR_BP
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.07 0.55 1.03 1.51 1.99 2.47 2.95 3.43
B
an
dw
id
th
 U
til
iz
at
io
n
Offered Load
CS
BD_CAC
BDR_CAC
 2
筆者在其餘之時間也參加了不同 workshop 之議程，雖然在領域上的不同而對這些
論文之目的及方法或多或少會有一些疑惑，但藉由與作者的交流，不僅能夠獲得其它
領域上的知識，也能夠交到一些有著與我們不同文化的新朋友。在參與此次會議的過
程中，筆者也認識來自不同國家之學者。 
 
三、建議 
       此次會議場地在九州產業大學，筆者所投宿之旅館與會場之間之距離以搭電車之
方式可在 15 分鐘內到達，因此，在交通上算是相當的便利，而會場也相當寬敞，能
夠讓發表者與聽眾都能夠有一個舒適的空間，但在會場中必須提供給海報發表的作者
的文具如膠水等稍嫌不足，必須由發表者自己攜帶或向其它發表者借用。 
 
四、攜回資料名稱及內容 
1. 「UIC 2012 Final Program 手冊」：內含會議所有議程之時間序、論文發表/口頭報
告題目及作者姓名，可總覽整個會議安排及論文/專題研討之架構，對欲安排大型
學術研討會議者甚具參考價值。 
2. 「UIC 2012 Abstract 手冊」: 內含所有論文之摘要，可供與會者快速閱讀所有論文
之目的及成果。  
3. 相關學術會議資訊及徵稿啟事，例如： 
(1)「AINA 2013」：Mar 25 - 28，2013，Barcelona, Spain。 
(2)「ICIIN 2013」：Feb 2 - 3, 2013，Malé, Maldives。 
(3)「ICC 2013」：Jun 9 - 13, 2013，Budapest, Hungary。 
(4)「ACM ICUIMC (IMCOM) 2013」：Jan 17, - 19, 2013，Kota Kinabalu, Malaysia。 
(5)「MMSys 2013」：Feb 27, - Mar 1, 2013，Oslo, Norway。 
(6)「PDCN 2013」：Feb 11, - 13, 2013，Innsbruck, Austria。 
 
links to these members (control topology). Protocols using
the implicit approach first create a control topology with
some specific properties, such as delay or hop count, and
then a data delivery path is implicitly defined upon this
control topology by packet forwarding rules.
For single source ALM recovery schemes, they fall
into two categories: reactive approach [13] and proactive
approach[5][6][7]. In the reactive approach, the restoration
process for a delivery tree starts once after a node departure
is awarded. It takes longer time to response to the node
failure. On the other hand, for the proactive approach, each
non-leaf node in the delivery tree will precompute one or
more backup routes. When a node departure is detected, the
backup route is applied in the first place. The recovery time
can thus be reduced.
III. PROPOSED MULTISOURCE ALM ROUTING
PROTOCOL
A. Assumptions
In this paper, we maked the following two assumptions:
(1) the path of minimum number of hops between two
network nodes is symmetric, that is, for two network ndoes
A and B, the path of minimum number of hops from A to
B is equivalent to that from B to A; (2) the information
related to a multicast group can be advertised by multicast
group creator and discovered by network node with some
advertisement mechanisms, e.g., the advertisement mecha-
nism proposed in [14].
With cluster-based group management, all multicast group
members are grouped into different clusters and each cluster
has a cluster head which is responsible for managing cluster
members and forwarding multicast data. The join and leave
processes of a multicast group member are described as
follows.
B. Member Join
Figure 1 illustrates the procedure of member join. When a
network node knows a multicast group from a advertisement
mechanism and wants to join the multicast group (i.e., join
requestor in Fig. 1), it will discover the existed cluster
head(s) (CH) of that group by probing its neighbors within
radius hops, where radius is a parameter that specifies the
radius of a cluster. If the requestor discovers one or more
cluster heads, it will send a cluster member join request to
the closest cluster head (i.e., the one that has the smallest
number of hops to itself) and the cluster head will reply a
cluster member join response. In contrast, if the requestor
discovers nothing, it will become a cluster head and send a
cluster head join request to the multicast group creator. The
creator then reply the cluster head join request by sending
a cluster head join response which piggybacks address list
of existed cluster heads in the multicast group. Upon the
received address list, the requestor probes each of the cluster
head and a cluster head which receives the probe request
IPCH Hops
IP address of 
cluster head
Number of hops between 
itself and the cluster head
IPBCH
IP address of  backup 
cluster head
.
.
.
.
.
.
Cluster #1
Cluster #2
IPMEM Hops
IP address of 
cluster member
Number of hops between 
itself and the cluster member
.
.
.
Cluster Member #1
Cluster Member #2
(a)
(b)
Cluster #n
Cluster Member #n
Hops
Number of hops between 
itself and the BCH
Figure 2. The structure of (a) cluster head table; (b) cluster member table.
will reply the probe request by sending a cluster head probe
response to the requestor.
For robustness consideration, each cluster has a backup
cluster head (BCH). The member of secondly joined in a
cluster will be selected as BCH by the cluster head of that
cluster. In addition, when a requestor becomes a new cluster
head and sends a cluster head probe request to each existed
cluster head, the new cluster head will learn the BCH of
each existed cluster from the received cluster head probe
response.
Each cluster head and BCH maintains two tables: cluster
head table (CHT) and cluster member table (CMT). CHT
stores the information of cluster heads in the multicast
group and CMT stores information of cluster members in
its cluster. As seen in Fig. 2(a), an entry of CHT consists
of a tuple (IPCH ,Hops, IPBCH ,Hops). IPCH is the IP
address of the cluster head,Hops is the number of hops from
itself to the cluster head, and IPBCH is the IP address of the
backup cluster head of that cluster. An entry of CMT consists
of a tuple (IPMEM , Hops). IPMEM is the IP address of
cluster member and Hops is the number of hops from itself
to the cluster member.
Figure 3 illustrates the member join and the resulting ta-
bles at each multicast group member, where R1 through R5
are routers and A through F are multicast group members
that join the multicast group sequentially.
C. Member Leave
A cluster member leaves a multicast group by sending
a leave message to its cluster head. A cluster head leaves
a multicast group by sending a leave message to all other
cluster heads. When a cluster head receives a leave message
from its cluster member or other cluster head, it will remove
the left node from its CHT or CMT.
D. Data Delivery scheme
Figure 4 illustrates the proposed multisource data delivery
scheme. We considered that both cluster head and cluster
AB E
C F
D
A
B
E
C F
D
C
E D
A F
B
D
C
E
A F
B
E
A C F
B D
F
E
C A
D B
FCHL:  C, D, F
FCHL:  DFCHL:  D
Prune
Prune
Prune
PrunePrune
Prune
FCHL:  C, D, F
FCHL:  DFCHL:  D
FCHL:  A, FFCHL:  A, F
FCHL:  Null
FCHL:  Null
FCHL:  Null
FCHL:  A, E, F
FCHL:  A, F
FCHL:  Null FCHL:  Null
FCHL:  D FCHL:  D
FCHL:  D
FCHL:  Null
FCHL:  A, C, D
FCHL:  D FCHL:  D
FCHL:  Null
(a) (b) (c)
(a) (b) (c)
Multicast data flow Prune message flow
Figure 5. The delivery trees constructed by the proposed delivery scheme.
and D choose A and F as NHCH. Consequently, the paths
D → A and D → F are unnecessary.
A cluster head who receives duplicate transmissions from
different cluster heads (which is called parent cluster head)
sends a prune message to each of the parent cluster head
but the one which is closest to itself (i.e., smallest number
of hops between the parent cluster head and itself). For
instance, in Fig. 5(c), when the cluster heads A and F
receive multicast data originating from C through parent
cluster heads E and D, A and F send a prune message to
D. Upon the receipt of prune message, D will stop forward
multicast to A and F .
E. Recovery Scheme
Since multicast group members of an ALM routing pro-
tocol are required to forward multicast data, departure of
multicast group member might interrupt the data delivery.
A recovery scheme is capable of re-organizing multicast
data delivery tree and recovering the data transmission from
the interruption. The proposed recovery scheme is initiated
by the parent cluster head of the departed cluster head.
There are two types of the departure: leave and failure. The
recovery scheme for each type of the departures is described
as follows.
1) Recovery scheme for leave: As mentioned in section
III-C, a cluster member informs its cluster head before
leaving. When a cluster head receives a leave message from
its cluster member, it will erase the entry corresponding
to the leaving cluster member from its CMT. Since cluster
member does not participate in the forwarding of multicast
data, the leave of a cluster member does not interrupt the
transmission of multicast data.
A
B E
C F
D
C
E D
A F
B
FCHL:  C, D, F
FCHL:  DFCHL:  D
FCHL:  A, F
FCHL:  Null
(a) (b) (c)
C
E D
A F
B
FCHL:  A, FFCHL:  A, F
Left or failed member
FCHL:  Null
FCHL:  Null
Failed link
FCHL:  Null
Figure 6. The resulting multicast trees after multicast member leaves or
fails; the original multicast trees are given in Fig. 5.
When a cluster head wants to leave a multicast group,
it will inform all cluster heads. Upon the receiving of the
leave message, the parent of the left cluster head performs
recovery by looking up its CHT to find the BCH of the
left cluster head. If the BCH exists, the parent cluster
head uses the tuple (IPBCH ,Hops) to replace the tuple
(IPCH , Hops), where IPCH is the IP address of the left
cluster head and IPBCH is the IP address of the BCH .
In contrast, if the BCH does not exist, the parent cluster
head erases the tuple (IPCH ,Hops) from its CHT. After the
CHT of the parent cluster head is updated, when multicast
data arrives at the parent cluster head, it executes the data
delivery scheme, that is, it selects new next-hop cluster head
and constructs a new FCHL based on the received FCHL,
and forwards the multicast data with piggybacking the new
FCHL to the selected new next-hop cluster head.
In the first case (i.e., BCH exists), the BCH is on the
CHT of the parent cluster head, the BCH might be selected
as new next-hop cluster head of the parent cluster head or be
added into the new FCHL. By either way, the BCH will be
eventually selected as next-hop cluster head somewhere in
the descendant of the parent cluster head. When the BCH
is selected as next-hop cluster head by a new parent cluster
head, it can receive multicast data from the new parent
cluster head and forward the data to its cluster members
and the child cluster heads of the left cluster head (we
assumed that a BCH maintains the same information as its
cluster head, e.g., CMT, CHT, and child cluster heads). Thus,
multicast tree is recovered.
In the second case, since all the child cluster heads of the
left cluster head are on the CHT of the parent cluster head
and the new FCHL was constructed based on the CHT and
the received FCHL, it means that the child cluster heads
might be selected as next-hop cluster head of the parent
cluster head or be added into the new FCHL. By either
way, all the child cluster heads will be selected as new
next-hop cluster head. When they are selected as next-hop
cluster head, each of them can receive multicast data from
different new parent cluster head and thus the multicast tree
is recovered.
 0
 5
 10
 15
 20
 25
 30
 35
 40
 45
 50
 55
 60  80  100  120  140  160  180  200
Co
nt
ro
l O
ve
rh
ea
d 
(M
Bt
ye
s)
Group Size
Proposed-ControlOverhead-5HB
Proposed-ControlOverhead-3HB
Figure 9. The average control overhead.
size remains in a low value. It is because the proposed
group management scheme employed clustering technique.
By clustering, the join and leave message from a cluster
member can be localized in a cluster and thus the number of
control messages is greatly reduced. In addition, it is obvious
that when the period of sending the heartbeat is shorter, the
control overhead will be higher.
V. CONCLUSION
We proposed the multisource ALM routing algorithm and
verified that the recovery time is short when a node fails
or a node is leaving from a multicast group. Although we
verify the improvement through simulations, it calls for more
simulative study and comparison to other proposals, which
is currently undergoing.
REFERENCES
[1] Y.-h. Chu, S. Rao, S. Seshan, and H. Zhang, “A case for
end system multicast,” IEEE Journal on Selected Areas in
Communications, vol. 20, no. 8, pp. 1456–1471, 2002.
[2] M. Kwon and S. Fahmy, “Topology-aware overlay networks
for group communication,” Proc. of 12th international work-
shop on network and operation systems support for digital
audio and video, May 2002, pp. 127–136. [Online]. Available:
http://citeseer.ist.psu.edu/kwon02topologyaware.html
[3] M. Hosseini, D. T. Ahmed, S. Shirmohammadi, and N. D.
Georganas, “A survey of application-layer multicast proto-
cols,” IEEE Communications Surveys and Tutorials, vol. 9,
no. 3, pp. 58–74, 2007.
[4] L. Baiqiang, T. Takeshi, and K. Keiichi, “Honeycomb: A
novel approach for construction of stable alm overlay,” in
Proceedings of Fifth International Conference on Information
Technology: New Generations ITNG 2008, 2008, pp. 402–
407.
[5] M. Yang and Z. Fei, “A proactive approach to reconstructing
overlay multicast trees,” in Proceedings of INFOCOM 2004.
Twenty-third AnnualJoint Conference of the IEEE Computer
and Communications Societies, vol. 4, 2004, pp. 2743–2753
vol.4.
[6] T. Kusumoto, Y. Kunichika, J. Katto, and S. Okubo, “Proac-
tive route maintenance and overhead reduction for applica-
tion layer multicast,” in Proceedings of Joint International
Conference on Autonomic and Autonomous Systems and
International Conference on Networking and Services ICAS-
ICNS 2005, 2005, pp. 17–17.
[7] S. Banerjee, S. Lee, B. Bhattacharjee, and A. Srinivasan,
“Resilient multicast using overlays,” IEEE/ACM Transactions
on Networking, vol. 14, no. 2, pp. 237–248, 2006.
[8] S. Ratnasamy, M. Handley, R. M. Karp, and
S. Shenker, “Application-level multicast using content-
addressable networks,” in Proceedings of the Third
International COST264 Workshop on Networked Group
Communication, ser. NGC ’01. London, UK, UK:
Springer-Verlag, 2001, pp. 14–29. [Online]. Available:
http://dl.acm.org/citation.cfm?id=648089.747491
[9] R. Zhang and Y. C. Hu, “Borg: A hybrid protocol for scalable
application-level multicast in peer-to-peer networks,” in In
Proc. of NOSSDAV. ACM, 2003, pp. 172–179.
[10] Y. hua Chu, S. G. Rao, S. Seshan, and H. Zhang, “Enabling
conferencing applications on the internet using an overlay
multicast architecture,” in Proceedings of ACM SIGCOMM,
2001, pp. 55–67.
[11] B. Zhang, S. Jamin, and L. Zhang, “Host multicast: a frame-
work for delivering multicast to end users,” Proceedings of
Twenty-First Annual Joint Conference of the IEEE Computer
and Communications Societies, vol. 3, pp. 1366–1375, 23-27
June 2002.
[12] S. Banerjee, B. Bhattacharjee, and C. Kommareddy,
“Scalable application layer multicast,” 2002. [Online].
Available: http://citeseer.ist.psu.edu/banerjee02scalable.html
[13] H. Deshpande, M. Bawa, and H. Garcia-Molina, “Streaming
live media over a peer-to-peer network,” Stanford InfoLab,
Technical Report 2001-30, April 2001. [Online]. Available:
http://ilpubs.stanford.edu:8090/501/
[14] S. Microsystems, “Jxta protocol.” [Online]. Available:
http://jxta.kenai.com/index.html
[15] E. W. Zegura, K. L. Calvert, and S. Bhattacharjee, “How
to model an internetwork,” in Proceeding of IEEE Fifteenth
Annual Joint Conference of the IEEE Computer Societies,
vol. 2, 1996, pp. 594–602.
 2
筆者在其餘之時間也參加了不同 workshop 之議程，雖然在領域上的不同而對這些
論文之目的及方法或多或少會有一些疑惑，但藉由與作者的交流，不僅能夠獲得其它
領域上的知識，也能夠交到一些有著與我們不同文化的新朋友。在參與此次會議的過
程中，筆者也認識來自不同國家之學者。 
 
三、建議 
       此次會議場地在九州產業大學，筆者所投宿之旅館與會場之間之距離以搭電車之
方式可在 15 分鐘內到達，因此，在交通上算是相當的便利，而會場也相當寬敞，能
夠讓發表者與聽眾都能夠有一個舒適的空間，但在會場中必須提供給海報發表的作者
的文具如膠水等稍嫌不足，必須由發表者自己攜帶或向其它發表者借用。 
 
四、攜回資料名稱及內容 
1. 「UIC 2012 Final Program 手冊」：內含會議所有議程之時間序、論文發表/口頭報
告題目及作者姓名，可總覽整個會議安排及論文/專題研討之架構，對欲安排大型
學術研討會議者甚具參考價值。 
2. 「UIC 2012 Abstract 手冊」: 內含所有論文之摘要，可供與會者快速閱讀所有論文
之目的及成果。  
3. 相關學術會議資訊及徵稿啟事，例如： 
(1)「AINA 2013」：Mar 25 - 28，2013，Barcelona, Spain。 
(2)「ICIIN 2013」：Feb 2 - 3, 2013，Malé, Maldives。 
(3)「ICC 2013」：Jun 9 - 13, 2013，Budapest, Hungary。 
(4)「ACM ICUIMC (IMCOM) 2013」：Jan 17, - 19, 2013，Kota Kinabalu, Malaysia。 
(5)「MMSys 2013」：Feb 27, - Mar 1, 2013，Oslo, Norway。 
(6)「PDCN 2013」：Feb 11, - 13, 2013，Innsbruck, Austria。 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：柯開維 計畫編號：100-2221-E-027-076- 
計畫名稱：第四代無線寬頻網路延遲分析與具頻寬與延遲保證之動態可重分配機制 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
本計畫之執行成
果 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100% 本計畫之執行成果 
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
本計畫之衍生成
果 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
